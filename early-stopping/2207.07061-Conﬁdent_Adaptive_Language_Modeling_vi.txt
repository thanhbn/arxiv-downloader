# Mô hình Ngôn ngữ Thích ứng Tự tin

Tal Schuster1;Adam Fisch2;Jai Gupta1
Mostafa Dehghani1Dara Bahri1Vinh Q. Tran1Yi Tay1Donald Metzler1
1Google Research2CSAIL, MIT

Tóm tắt
Những tiến bộ gần đây trong các mô hình ngôn ngữ lớn (LLMs) dựa trên Transformer đã dẫn đến những cải thiện hiệu suất đáng kể trên nhiều tác vụ. Những thành tựu này đi kèm với sự gia tăng mạnh mẽ về kích thước của các mô hình, có thể dẫn đến việc sử dụng chậm và tốn kém tại thời điểm suy luận. Tuy nhiên, trong thực tế, chuỗi các thế hệ được tạo ra bởi LLMs bao gồm các mức độ khó khăn khác nhau. Trong khi một số dự đoán thực sự hưởng lợi từ toàn bộ khả năng của mô hình, các tiếp tục khác thì tầm thường hơn và có thể được giải quyết với tính toán ít hơn. Trong công trình này, chúng tôi giới thiệu Mô hình Ngôn ngữ Thích ứng Tự tin (CALM), một khung làm việc để phân bổ động các lượng tính toán khác nhau cho mỗi đầu vào và bước thời gian sinh. Giải mã thoát sớm bao gồm một số thách thức mà chúng tôi giải quyết ở đây, chẳng hạn như: (1) nên sử dụng thước đo tin cậy nào; (2) kết nối các ràng buộc ở cấp độ chuỗi với các quyết định thoát cục bộ từng token; và (3) chú ý trở lại các biểu diễn ẩn bị thiếu do thoát sớm trong các token trước đó. Thông qua phân tích lý thuyết và thí nghiệm thực nghiệm trên ba tác vụ sinh văn bản đa dạng, chúng tôi chứng minh hiệu quả của khung làm việc của chúng tôi trong việc giảm tính toán—tăng tốc lên đến 3 lần—trong khi duy trì hiệu suất cao một cách có thể chứng minh.

1 Giới thiệu
Những tiến bộ gần đây trong Mô hình Ngôn ngữ Lớn (LLMs) đã dẫn đến những bước đột phá trong hiểu ngôn ngữ và sinh ngôn ngữ trên hầu hết mọi tác vụ Xử lý Ngôn ngữ Tự nhiên (NLP) được sử dụng rộng rãi được xem xét trong lĩnh vực này ngày nay. Mô hình ngôn ngữ tự hồi quy cung cấp một khung làm việc linh hoạt để giải quyết các tác vụ phức tạp với định dạng đầu vào và đầu ra ngôn ngữ tự nhiên thống nhất, đồng thời cũng giảm bớt nhu cầu thu thập và huấn luyện dữ liệu quy mô lớn dành riêng cho tác vụ. Tuy nhiên, kích thước lớn của LLMs dẫn đến tải tính toán khổng lồ có thể hạn chế đối với một số ứng dụng thực tế (ví dụ, dịch máy). Điều này đặc biệt rõ ràng trong quá trình giải mã tự hồi quy khi toàn bộ chồng các lớp Transformer được tính toán lặp đi lặp lại cho mỗi token đầu ra.

Mặc dù các mô hình lớn nhìn chung hoạt động tốt hơn, cùng một lượng tính toán có thể không cần thiết cho mọi đầu vào để đạt được hiệu suất tương tự (ví dụ, tùy thuộc vào đầu vào dễ hay khó). Thoát sớm là một cách tiếp cận đầy hứa hẹn để giảm chi phí tính toán của các kiến trúc đa lớp như những kiến trúc được sử dụng trong LLMs dựa trên Transformer, trong đó số lượng lớp được sử dụng bởi mô hình được quyết định một cách động trên cơ sở từng đầu vào. Trong bối cảnh này, một LLM có thể chọn sinh ra một token mới dựa trên biểu diễn tại một lớp trung gian thay vì sử dụng toàn bộ mô hình, và tiết kiệm tính toán do đó. Tuy nhiên, một câu hỏi tự nhiên nảy sinh là khi nào là quyết định tốt để thoát sớm, thay vì chờ đợi? Việc chọn một cách ngây thơ khi nào thoát có thể không tối ưu về mặt tiết kiệm thời gian tính toán, và cũng dẫn đến sự suy giảm hiệu suất mô hình không thể dự đoán được, đặc biệt khi các dự đoán phụ thuộc lẫn nhau, như trong sinh ngôn ngữ tự hồi quy.

Trong công trình này, chúng tôi phân tích mô hình thoát sớm cho LLMs, và trình bày một phương pháp có nguyên tắc để tăng hiệu quả mô hình trong khi vẫn tự tin về chất lượng của các dự đoán kết quả. Cụ thể, chúng tôi phát triển một phương pháp để hiệu chỉnh các quyết định thoát cục bộ, từng token, sao cho các ràng buộc toàn cục, ở cấp độ chuỗi—được xác định bởi các thước đo ở cấp độ chuỗi về từ vựng hoặc ngữ nghĩa như điểm ROUGE hoặc BLEURT—được duy trì một cách có thể chứng minh với xác suất cao tùy ý (ví dụ, 95%). Quá trình này, mà chúng tôi gọi là Mô hình Ngôn ngữ Thích ứng Tự tin (CALM), được minh họa trong Hình 1.

Cách tiếp cận của chúng tôi tận dụng các kỹ thuật gần đây trong kiểm soát rủi ro không phân phối để tạo ra các thế hệ tự tin với đảm bảo thống kê mạnh. Cụ thể, giả sử chúng ta đã được cung cấp một tập hiệu chỉnh Scal := {Pi}^n_{i=1} ⊂ P^n của các lời nhắc độc lập và cùng phân phối (i.i.d.) cho LLM của chúng ta (ví dụ, các đoạn văn cần tóm tắt, câu cần dịch, hoặc câu hỏi cần trả lời thông qua mô hình ngôn ngữ). Cho Ptest là một lời nhắc i.i.d. mới cho LLM của chúng ta, trong đó Yearly := LLM_early(Ptest) và Yfull := LLM_full(Ptest) là các đầu ra thích ứng và tiêu chuẩn của LLM của chúng ta, tương ứng. Để hài lòng với Yearly, chúng ta có thể yêu cầu nó phải nhất quán về mặt văn bản với Yfull. Cho bất kỳ hàm bất đồng văn bản bị chặn D nào, chúng ta hướng đến hiệu chỉnh LLM thoát sớm sao cho các dự đoán của nó đồng ý đến một mức dung sai với mô hình đầy đủ về kỳ vọng với xác suất cao,

P[E_Scal[D(Yearly, Yfull)] ≤ δ] ≥ 1 - α, (1)

trong đó tính ngẫu nhiên nằm trên các lần rút của Scal, và α ∈ (0,1). Phương trình (1) có lợi thế đáng kể là có thể đạt được chỉ bằng cách sử dụng dữ liệu hiệu chỉnh không nhãn Scal (một chất lượng quan trọng đối với các tác vụ few-shot, chẳng hạn). Tuy nhiên, việc thực thi nhất quán văn bản với Yfull gốc có thể quá nghiêm ngặt không cần thiết đối với một số tác vụ, đặc biệt là khi có thể chấp nhận nhiều thế hệ. Như một thay thế, cho một tập hiệu chỉnh các lời nhắc được ghép đôi với một tập các tham chiếu mục tiêu (có thể nhiều), Scal := {(Pi, Zi)}^n_{i=1} ⊂ (P × Z)^n, và bất kỳ hàm rủi ro bị chặn R nào, chúng ta cũng xem xét một mục tiêu thực thi nhất quán rủi ro bằng cách hạn chế sự gia tăng tương đối trong rủi ro của các dự đoán Yearly so với Yfull, liên quan đến tập các tham chiếu thời gian thử nghiệm Ztest, tức là,

P[E_Scal[R(Yearly, Ztest) - R(Yfull, Ztest)] ≤ ε] ≥ 1 - α. (2)

Trong các ràng buộc của Phương trình (1) hoặc Phương trình (2), mục tiêu của công việc chúng tôi là tìm Yearly hiệu quả nhất về mặt tính toán, tức là các thế hệ thoát càng sớm càng tốt trong khi vẫn duy trì các đảm bảo hiệu suất mong muốn của chúng ta. Để đạt được điều này, cần phải phát triển một tín hiệu đáng tin cậy về mức độ khả năng các quyết định thoát sớm cục bộ, từng token có thể phá vỡ các tính chất toàn cục của chuỗi hoàn chỉnh.

Ở đây, trước tiên chúng tôi phân tích cách các lỗi được truyền trong LLMs dựa trên Transformer, và sau đó trình bày một cơ chế ghi điểm hiệu quả và hiệu suất để gán điểm tin cậy "thoát sớm nhất quán" sau mỗi lớp được sử dụng trong quá trình sinh ra một token mới. Quyết định thoát hay không dựa trên các điểm này, và được hiệu chỉnh cẩn thận bằng cách sử dụng Scal sao cho các giới hạn hiệu suất của chúng ta được thỏa mãn một cách có thể chứng minh.

Cuối cùng, chúng tôi xác thực thực nghiệm phương pháp của mình trên nhiều tác vụ sinh NLP đa dạng, bao gồm tóm tắt văn bản, dịch máy và trả lời câu hỏi. Các thí nghiệm của chúng tôi chứng minh tiềm năng của CALM trong việc giảm độ phức tạp trung bình của mô hình và tăng tốc suy luận khoảng 3 lần trong khi kiểm soát đáng tin cậy để có hiệu suất cao.

Đóng góp. Tóm lại, các đóng góp chính của chúng tôi như sau:
• Một khung làm việc (CALM) để tăng tốc đáng tin cậy các thế hệ LLM dựa trên Transformer.
• Một phân tích có hệ thống về cơ chế thoát sớm theo token thúc đẩy một lớp các thước đo tin cậy và hàm ngưỡng đơn giản nhưng hiệu quả được sử dụng như một phần của khung làm việc CALM.
• Một chứng minh thực nghiệm về lợi ích hiệu quả của CALM trên ba tập dữ liệu sinh đa dạng.

2 Công trình liên quan
Cải thiện hiệu quả thời gian suy luận của LLMs đã là một nỗ lực liên tục của cộng đồng nghiên cứu trong vài năm qua, tận dụng các kỹ thuật như chưng cất kiến thức, lượng hóa điểm nổi, cắt tỉa lớp, bỏ vector, và các kỹ thuật khác. Một hướng nghiên cứu khác liên quan đến tính toán có điều kiện để huấn luyện các mô hình lớn hơn chỉ sử dụng một tập con thưa thớt hơn của mạng đầy đủ trong quá trình suy luận, ví dụ bằng cách định tuyến qua hỗn hợp các chuyên gia, các mô-đun lặp lại, hoặc truy cập bộ nhớ ngoài. Tuy nhiên, các mô hình này vẫn sử dụng cùng một lượng tính toán cho tất cả các ví dụ đầu vào.

Ở đây, chúng tôi tập trung vào tính toán thích ứng, một loại tính toán có điều kiện cụ thể nhằm phân bổ động sức mạnh tính toán khác nhau cho từng ví dụ, với mục tiêu giảm độ phức tạp tổng thể trong khi duy trì hiệu suất cao. Cách tiếp cận này, thường được gọi là thoát sớm, bổ sung cho nhiều giải pháp trên và có thể được kết hợp với chúng. Nhiều kỹ thuật thoát sớm cho Transformers chỉ có bộ mã hóa (ví dụ, BERT) đã được đề xuất gần đây. Hầu hết các phương pháp này dựa vào các thước đo tin cậy nội tại (ví dụ, dựa trên phân phối softmax), trong khi các phương pháp khác cố gắng dự đoán định tuyến trước, hoặc huấn luyện một bộ phân loại thoát sớm nhỏ, như chúng tôi cũng kiểm tra ở đây. Các thước đo này có thể được hiệu chỉnh để đảm bảo đáng tin cậy tính nhất quán của dự đoán sớm với mô hình đầy đủ. Tuy nhiên, các kỹ thuật được sử dụng cho các bộ phân loại chỉ có bộ mã hóa không phù hợp cho các ràng buộc nhất quán toàn cục với một chuỗi các dự đoán phụ thuộc, vốn có trong quá trình giải mã của các mô hình ngôn ngữ tự hồi quy, mà chúng tôi giải quyết ở đây.

Công việc của chúng tôi cũng được thúc đẩy bởi những phát hiện gần đây về sự tồn tại của các sự kiện bão hòa trong LMs, trong đó dự đoán được xếp hạng cao nhất không thay đổi sau một lớp nào đó và được truyền lên trên. Geva và cộng sự đã kiểm tra các tương tác của trạng thái ẩn với các lớp feed-forward để dự đoán các sự kiện này. Tuy nhiên, họ chỉ xem xét các dự đoán đơn lẻ cục bộ và không giải quyết các thách thức liên quan đến sinh chuỗi. Kiến trúc LM thoát sớm của chúng tôi liên quan gần nhất đến Elbayad và cộng sự, những người đã tìm thấy một bộ phân loại thoát sớm ở cấp token để cung cấp các sự đánh đổi hiệu quả-hiệu suất tốt nhất trên dịch máy.

Ở đây, chúng tôi giới thiệu một phương pháp hiệu chỉnh có nền tảng lý thuyết để kiểm soát một cách có thể chứng minh chất lượng của toàn bộ chuỗi. Bằng cách làm như vậy, chúng tôi cung cấp lợi ích hiệu quả đáng tin cậy—rút ra các quyết định thoát sớm cục bộ từ các ràng buộc mong muốn toàn cục. Hơn nữa, chúng tôi giới thiệu một số cải tiến mô hình và phân tích thực nghiệm, bao gồm (1) phân tích các nguồn chính của suy giảm hiệu suất, dẫn chúng tôi đề xuất một hàm ngưỡng giảm dần để kiểm soát sự đánh đổi tốt hơn mà không làm tăng không gian tìm kiếm; (2) cải thiện việc huấn luyện bộ phân loại thoát sớm; và (3) thử nghiệm với hai tác vụ mới.

Quy trình hiệu chỉnh của chúng tôi để kết nối các ràng buộc toàn cục với các quyết định cục bộ, liên quan đến nghiên cứu gần đây xung quanh lượng hóa không chắc chắn không phân phối. Một số phương pháp đã được phát triển trong các nghiên cứu gần đây để mở rộng và điều chỉnh khung lý thuyết để có được lợi ích hiệu quả thực tế trên các ứng dụng mục tiêu. Ở đây, chúng tôi đóng khung các yêu cầu nhất quán của mình xung quanh khung Learn then Test (LTT), và tận dụng hành vi đơn điệu gần đúng của các thước đo tin cậy của chúng tôi và cấu trúc lồng nhau của vấn đề của chúng tôi, theo định nghĩa đảm bảo tính nhất quán với ngưỡng đủ lớn, để tạo thành các giới hạn chặt chẽ và hiệu quả.

3 Thoát sớm cho Mô hình Ngôn ngữ Thích ứng
Trong phần sau, chúng tôi mô tả và phân tích Transformer LM thoát sớm. Chúng tôi bắt đầu với một bản tóm tắt ngắn gọn về kiến trúc Transformer (§3.1) và thoát sớm (§3.2) để thuận tiện, theo công trình trước đó. Sau đó chúng tôi điều tra các tác động của thoát sớm đối với hiệu suất mô hình, và xác định các nguồn chính của suy giảm hiệu suất và cách giảm thiểu chúng (§3.3)—điều này hướng dẫn thiết kế kiến trúc và huấn luyện của chúng tôi (§3.4) và các thước đo tin cậy từng token được đề xuất (§3.5).

3.1 Kiến trúc Transformer
Chúng tôi sử dụng mô hình chuỗi-đến-chuỗi Transformer, dựa trên triển khai T5x. Ở đây, chúng tôi chỉ xem xét các chi tiết đơn giản của kiến trúc Transformer liên quan đến thoát sớm, và giới thiệu người đọc đến Vaswani và cộng sự để biết chi tiết đầy đủ. Ở mức độ cao, cả mạng bộ mã hóa và bộ giải mã đều chứa L lớp xếp chồng, trong đó mỗi lớp bao gồm một lớp con đa đầu tự chú ý, tiếp theo là một lớp con feedforward, mỗi lớp có kết nối dư và chuẩn hóa lớp. Mạng bộ giải mã có một lớp con chú ý đa đầu bổ sung chú ý đến các trạng thái bộ mã hóa.

Xem xét một lời nhắc x = (x1, ..., xp), được xử lý bởi bộ mã hóa để tạo ra các trạng thái bộ mã hóa (e1, ..., ep), và phản hồi được sinh một phần hiện tại (y1, ..., yt). Khi sinh token tiếp theo yt+1, bộ giải mã tính toán một trạng thái bộ giải mã d^i_t cho lớp i trong số L như:

h^i_t := Attention(d^{i-1}_t, d^{i-1}_{1:t-1}); a^i_t := Attention(h^i_t, e_{1:p}); d^i_t := FeedForward(a^i_t). (3)

Bên trong mỗi cơ chế chú ý, được viết là Attention(x, z_{1:m}) cho một số đầu vào x và chuỗi m trạng thái z_{1:m}, x trước tiên được chiếu thành một vector truy vấn q := W_Q x ∈ ℝ^{d_{k}}, trong khi z được chiếu thành một ma trận các vector khóa-giá trị, K := W_K z_{1:m} ∈ ℝ^{m×d_{k}} và V := W_V z_{1:m} ∈ ℝ^{m×d_v}. Đầu ra o sau đó được tính như o := softmax(qK^T/√d_k)V.

Các thành phần đa đầu và chuẩn hóa được bỏ qua để ngắn gọn. Mỗi lớp sử dụng các phép chiếu khác nhau W^i_Q, W^i_K, và W^i_V (cũng độc nhất cho việc tính h^i_t so với a^i_t).

Cuối cùng, sau lớp L, một phân phối trên các token từ vựng y_{t+1} ∈ Y được tính thông qua một bộ phân loại tuyến tính được chuẩn hóa softmax W_L, trong đó p(y_{t+1}|d^L_t) = softmax(W_L d^L_t).

3.2 Giải mã với thoát sớm
Thay vì luôn luôn đưa ra dự đoán dựa trên biểu diễn tại lớp cuối, d^L_t, ý tưởng chính trong thoát sớm là chọn y_{t+1} nhanh hơn, nếu tự tin, bằng cách tính p(y_{t+1}|d^i_t) = softmax(W_i d^i_t) cho một lớp trung gian i < L nào đó. Cụ thể, cho c^i_t ∈ [0,1] biểu thị một số điểm tin cậy cục bộ cho lớp i khi xử lý token t, trong đó các giá trị cao hơn chỉ ra xu hướng cao hơn để thoát sớm (chúng tôi sẽ đề xuất các thể hiện hiệu quả của c^i_t trong §3.5). Cho τ^i_t ∈ [0,1] biểu thị một ngưỡng thoát sớm cục bộ nào đó, trong đó mô hình thoát sớm nếu c^i_t ≥ τ^i_t, hoặc ngược lại tiến hành tính toán biểu diễn tiếp theo, d^{i+1}_t. Dự đoán (được chọn một cách tham lam) y_{t+1} sau đó có thể được viết như:

y_{t+1} := {
  arg max p(y_{t+1}|d^1_t) nếu c^1_t ≥ τ^1_t;
  arg max p(y_{t+1}|d^2_t) nếu c^2_t ≥ τ^2_t;
  ...
  arg max p(y_{t+1}|d^L_t) ngược lại.
} (4)

Lưu ý rằng do cơ chế tự chú ý của Transformer, việc tính toán trạng thái ẩn đầu vào h^i_t cho lớp i phụ thuộc vào d^{i-1}_{1:t-1}, tức là các trạng thái ẩn đầu ra của lớp trước đó cho tất cả các token đã được sinh ra cho đến nay. Do đó, nếu mô hình đã thoát sớm tại một lớp j < i-1 nào đó cho một token s < t, thì d^{i-1}_s không có sẵn. Như một xấp xỉ, chúng tôi đặt d^k_s = d^j_s cho tất cả các lớp k > j theo Elbayad và cộng sự, với hiểu biết rằng điều này sẽ gây ra một số lỗi. Trong phần tiếp theo, ngoài các yếu tố khác, chúng tôi sẽ phân tích tác động của trạng thái được sao chép này đối với hiệu suất.

3.3 Các tác động của thoát sớm đối với truyền lỗi
Chúng tôi thực hiện một số thí nghiệm được kiểm soát để điều tra hành vi và tiềm năng của thoát sớm trong quá trình giải mã. Chúng tôi sử dụng một T5 bộ mã hóa-bộ giải mã 8 lớp và tập dữ liệu CNN/DM cho các thí nghiệm này. Xem §5 để biết thêm chi tiết về mô hình và dữ liệu này.

3.3.1 Truyền trạng thái
Đầu tiên, chúng tôi kiểm soát tính đúng đắn của các token được dự đoán để kiểm tra tác động của việc sao chép trạng thái (§3.2), và cũng đo lường một giới hạn trên gần đúng cho việc giảm tính toán. Chúng tôi sử dụng một thước đo tin cậy oracle thoát tại lớp sớm nhất đồng ý với dự đoán hàng đầu (tức là thay thế các điều kiện trong Phương trình 4 bằng arg max p(y_{t+1}|d^i_t) = arg max p(y_{t+1}|d^L_t)). Do đó, yếu tố duy nhất có thể gây ra sự phân kỳ trong việc sinh là cơ chế sao chép trạng thái cho các lớp bị bỏ qua. Kết quả của thí nghiệm này rất khuyến khích. Oracle này đạt được điểm ROUGE-L là 38.24, so với 38.32 với mô hình đầy đủ, trong khi chỉ sử dụng trung bình 1.53 lớp mỗi token. Chúng tôi cũng thử một oracle luôn sử dụng d^1_{1:t-1} và nó đạt 38.31 ROUGE-L. Những kết quả này chỉ ra rằng (1) mô hình mạnh mẽ đối với việc sao chép trạng thái từ các lớp thấp hơn, và (2) có tiềm năng đáng kể để tiết kiệm tính toán—lên đến 5.2 lần—trong khi bảo tồn hiệu suất, cho một thước đo tin cậy tốt.

Chúng tôi cũng thử nghiệm với việc sao chép các trạng thái được chiếu K_j, V_j đến các lớp bị bỏ qua k > j. Phiên bản oracle này dẫn đến sự sụt giảm đáng kể về hiệu suất xuống 23.02 ROUGE-L. Nhìn chung, chúng tôi phỏng đoán rằng tự chú ý tại lớp i cho token t có thể an toàn sử dụng các trạng thái ẩn d^j_s cho j < i-1 như khóa-giá trị của các token s < t, miễn là các phép chiếu W^i_{K/V} của lớp i được sử dụng. Đáng chú ý, phép chiếu này giờ có thể được tính đồng thời cho tất cả các lớp bị bỏ qua vì tất cả chúng đều sử dụng cùng một d từ lớp đã thoát.

3.3.2 Độ nhạy đối với lỗi cục bộ
Tiếp theo, chúng tôi kiểm tra tác động của các sửa đổi token cục bộ—có thể xảy ra do thoát sớm—đối với toàn bộ chuỗi được sinh. Chúng tôi thử nghiệm với hai loại nhiễu loạn: dựa trên lấy mẫu, trong đó chúng tôi chọn token được xếp hạng thứ 10 theo lớp L; và dựa trên lớp, trong đó chúng tôi chọn dự đoán của lớp đầu tiên tại bước thời gian t. Tất cả các token khác được dự đoán một cách tham lam bởi lớp L. Như được hiển thị trong Hình 2a, các nhiễu loạn sớm hơn dẫn đến điểm số cấp chuỗi thấp hơn vì có nhiều token hơn có thể chịu tác động từ sự phân kỳ. Tuy nhiên, sự suy giảm nhỏ hơn nhiều với các nhiễu loạn dựa trên lớp so với dựa trên lấy mẫu vì, trong thực tế, các dự đoán thoát sớm hầu hết là chính xác.

Ngưỡng giảm dần. Theo quan sát trên, chúng tôi giới thiệu một ngưỡng thoát sớm giảm dần cho phép thoát nhiều hơn khi quá trình giải mã tiếp tục. Được thúc đẩy bởi hành vi logarit trong Hình 2a, chúng tôi sử dụng một hàm mũ với nhiệt độ do người dùng định nghĩa α:

τ'(τ, t) := clip_{[0,1]}[9τ/10 + 1/10 · e^{-t/N}], (5)

trong đó N là độ dài đầu ra tối đa. Hình 2b minh họa hàm này. Về cơ bản, hàm này trình bày một sự thỏa hiệp hiệu quả giữa việc chỉ đơn giản sử dụng cùng một ngưỡng cho tất cả các token, và tìm kiếm trong một không gian khổng lồ của các ngưỡng khác nhau theo từng vị trí. Trên thực tế, nó hỗ trợ kiểm soát tinh tế và tốt hơn đối với sự đánh đổi hiệu quả-hiệu suất so với một ngưỡng duy nhất. Hình 2c trình bày kết quả của một tìm kiếm trên α với các bước 0.01 và tin cậy dựa trên softmax (§3.5).

Với biến thể ngưỡng đơn (α = 0), cố gắng cải thiện hiệu quả sẽ dẫn đến sự sụt giảm mạnh mẽ hơn 10 điểm trong tương tự văn bản so với dự đoán của mô hình đầy đủ. Ngược lại, các ngưỡng giảm dần tiết lộ một số điểm trung gian với các sự đánh đổi mong muốn để xem xét.

3.4 Huấn luyện các bộ phân loại thoát sớm cho tính nhất quán cục bộ
Mặc dù mục tiêu của chúng tôi là bảo tồn chất lượng của chuỗi đầu ra hoàn chỉnh, chúng tôi lưu ý rằng điều này không nhất thiết đòi hỏi tính nhất quán ở cấp độ token cục bộ. Xem xét chuỗi mục tiêu "buổi hòa nhạc thật tuyệt vời và dài." Một đầu ra chuyển đổi thứ tự của các tính từ thành "buổi hòa nhạc thật dài và tuyệt vời" sẽ được gọi là nhất quán bởi hầu hết các thước đo ngữ nghĩa (và đạt được 100 điểm F1 token). Tuy nhiên, các câu phân kỳ tại tính từ đầu tiên dài khác về mặt ngữ nghĩa với tuyệt vời.

Tuy nhiên, việc huấn luyện cho tính nhất quán toàn cục có thể thách thức vì nó phụ thuộc vào các tín hiệu có thể nhiễu có thể ảnh hưởng đến việc học, và cũng phá vỡ chiến lược huấn luyện teacher-forcing hiệu quả của LMs dựa vào các quyết định cục bộ. Mặt khác, tính nhất quán cục bộ hoàn hảo ngụ ý tính nhất quán toàn cục. Do đó, chúng tôi chọn huấn luyện cho tính nhất quán cục bộ, điều này đòi hỏi những thay đổi tối thiểu đối với quy trình huấn luyện, và giảm bớt yêu cầu cục bộ thành yêu cầu toàn cục trong quá trình suy luận.

Cụ thể, tương tự như Elbayad và cộng sự, chúng tôi tính trung bình các mất mát cho mỗi lớp để có được mục tiêu L = ∑^L_{i=1} ω_i L_i, trong đó ∑^L_{i=1} ω_i = 1. (6)

L_i là mất mát negative log-likelihood. Chúng tôi đặt ω_i = i/∑^L_{j=1} j để ưu tiên các lớp cao hơn, và thấy rằng mục tiêu này hầu hết bảo tồn hiệu suất của mô hình đầy đủ so với huấn luyện thông thường. Chúng tôi lưu ý rằng có một số sự không đồng bộ giữa hành vi huấn luyện và suy luận này do các trạng thái ẩn của các lớp bị bỏ qua. Tuy nhiên, như đã thảo luận trong §3.3.1, hiệu suất không bị ảnh hưởng nếu trạng thái ẩn được sao chép.

3.5 Các thước đo tin cậy cục bộ
Chúng tôi thử nghiệm với ba thước đo tin cậy cho Phương trình (4) khác nhau về hiệu quả thông số và hoạt động tính toán của chúng. Các thí nghiệm của chúng tôi (§6) cũng sẽ cho thấy rằng chúng khác nhau về sức mạnh dự đoán.

Phản ứng Softmax. Chúng tôi lấy sự khác biệt giữa hai giá trị hàng đầu của Softmax(W_i d^i_t). Với một từ vựng đầu ra lớn, điều này dẫn đến nhiều hoạt động điểm nổi (FLOPs)—tuy nhiên, lớp tiếp theo i+1 có thể bắt đầu tính toán song song, tránh thời gian chạy bổ sung.

Bão hòa trạng thái ẩn. Như một thay thế đơn giản không tham số và nhanh tính toán, chúng tôi lấy tương tự cosine sim(d^i_t, d^{i-1}_t) cho i > 1. Theo định nghĩa, thoát có thể đầu tiên là tại lớp thứ hai (trừ khi α = 0). Thước đo này cố gắng xác định các sự kiện bão hòa sớm của trạng thái ẩn.

Bộ phân loại thoát sớm. Chúng tôi huấn luyện một bộ phân loại tuyến tính chuyên dụng M để dự đoán khả năng thoát với tính nhất quán cục bộ cho trạng thái ẩn hiện tại: c^i_t = M(d^i_t). Thước đo này rất nhanh để tính toán tại suy luận, và chỉ thêm |d| + 1 tham số mới. Để tránh bất kỳ tác động nào đến hiệu suất của mô hình cốt lõi, chúng tôi huấn luyện nó như một bước thứ hai trong đó chúng tôi đóng băng tất cả các tham số khác ngoài M. Chúng tôi chỉ đơn giản sử dụng mất mát cross-entropy độc lập cho mỗi lớp chống lại một oracle nhất quán 1[arg max(p(y_{t+1}|d^i_t) = arg max(p(y_{t+1}|d^L_t)], và tính trung bình qua các lớp L-1. Chúng tôi cũng thử nghiệm với việc huấn luyện giống hình học của Elbayad và cộng sự, nhưng thấy nó kém hiệu quả hơn ở đây (xem App. D). Hai mục tiêu liên quan chặt chẽ, nhưng mục tiêu hình học bỏ qua bất kỳ tín hiệu nào từ các trạng thái sau lần thoát oracle đầu tiên.

4 Hiệu chỉnh Thoát sớm cục bộ từ Ràng buộc toàn cục
Bây giờ chúng tôi mô tả quy trình hiệu chỉnh của mình để tìm một ngưỡng thoát chung τ ∈ [0,1] có thể được sử dụng trực tiếp trong Phương trình (4), hoặc thông qua Phương trình (5), sao cho chúng ta có thể chứng minh thỏa mãn các ràng buộc toàn cục mong muốn của chúng ta trên các chuỗi được sinh hoàn toàn. Ở mức độ cao, cách tiếp cận của chúng tôi sử dụng công thức cơ bản sau:

1. Chúng tôi chỉ định một lưới các giá trị có thể của τ = (τ_1, ..., τ_k) có thể dẫn đến các thế hệ chấp nhận được;
2. Chúng tôi chọn τ_* ∈ τ hợp lệ thấp nhất mà chúng tôi có thể xác định bằng các công cụ kiểm tra thống kê nghiêm ngặt.

Cho P_test là một lời nhắc i.i.d. được đưa cho LLM tại thời điểm thử nghiệm, và cho Y_full := LLM_full(P_test) ∈ Y và Y_early := LLM_early(P_test, τ) ∈ Y biểu thị các phản hồi đầy đủ và thích ứng, tương ứng. Tùy chọn, cho Z_test là một tập các tham chiếu vàng cho tác vụ của chúng ta, nếu được giả định. Mục tiêu của chúng ta, như được giới thiệu trong §1, là tìm một τ hợp lệ sử dụng S_cal sao cho chúng ta thỏa mãn một trong hai loại ràng buộc "nhất quán" toàn cục:

Định nghĩa 1 (Nhất quán văn bản). Một LLM thích ứng là nhất quán văn bản nếu cho bất kỳ hàm bất đồng văn bản bị chặn, D: Y × Y → ℝ, và dung sai δ ∈ ℝ, E[D(Y_early, Y_full)] ≤ δ.

Định nghĩa 2 (Nhất quán rủi ro). Một LLM thích ứng là nhất quán rủi ro nếu cho bất kỳ hàm rủi ro bị chặn, R: Y × 2^Y → ℝ, và dung sai ε ∈ ℝ, E[R(Y_early, Z_test)] ≤ E[R(Y_full, Z_test)] + ε.

Không mất tính tổng quát, chúng tôi sẽ giả sử rằng D và R luôn được chuẩn hóa về khoảng đơn vị [0,1], và do đó sẽ chỉ xem xét các dung sai δ, ε ∈ (0,1). Nhìn thoáng qua, để tìm một τ tạo ra một LLM_early nhất quán, chúng tôi đưa vấn đề của mình thành một vấn đề kiểm tra giả thuyết bội với một mảng lớn k ngưỡng thoát bộ phân loại ứng viên, τ = (τ_1, ..., τ_k), và áp dụng khung Learn then Test (LTT) của Angelopoulos và cộng sự để xác định một tập con các ngưỡng thỏa mãn ràng buộc, hợp lệ thống kê τ_valid. τ_* cuối cùng của chúng tôi sau đó được chọn là τ_* := min(τ_valid ∪ {1}).

4.1 Khung hiệu chỉnh Learn then Test
Việc chọn một giá trị τ thỏa mãn nghiêm ngặt các mục tiêu nhất quán của chúng ta là thách thức, vì tác động hiệu suất của việc tăng hoặc giảm τ không nhất thiết đơn điệu. Việc đặt τ một cách ngây thơ, ví dụ, chỉ dựa trên hiệu suất tập hiệu chỉnh trung bình, có thể dẫn đến kết quả không hợp lệ thống kê trong bối cảnh mẫu hữu hạn, không phân phối của chúng ta. Khung LTT được đề xuất bởi Angelopoulos và cộng sự giải quyết vấn đề này bằng cách đóng khung việc lựa chọn siêu tham số như một vấn đề kiểm tra bội.

Cho τ = (τ_1, ..., τ_k) là một lưới hữu hạn các giá trị siêu tham số có thể, hoặc có thể không, đạt được tính nhất quán hợp lệ. Ví dụ, khi tìm kiếm một giá trị τ ∈ [0,1], chúng ta có thể xem xét tập được chia đều τ = {i/(k+1) : i = 1, ..., k}. LTT sau đó xác định một tập con các giá trị, τ_valid, trong đó

P[∃τ ∈ τ_valid : LLM_early(P_test, τ) và LLM_full(P_test) không nhất quán] ≤ α. (7)

Ở đây, chúng tôi sử dụng nhất quán để chỉ nhất quán văn bản hoặc nhất quán rủi ro. Phương trình (7) có thể được thỏa mãn bằng cách áp dụng các kỹ thuật kiểm tra giả thuyết bội tiêu chuẩn miễn là các p-value siêu đồng dạng, p_j, được cung cấp cho mỗi giá trị τ_j ∈ τ hỗ trợ giả thuyết null

H_j : LLM_early(P_test, τ_j) và LLM_full(P_test) không nhất quán. (8)

τ_j được đặt trong τ_valid nếu H_j bị từ chối, và bị loại bỏ ngược lại. Điều này tạo ra một LLM_early nhất quán.

Mệnh đề 1 (LTT cho CALM). Giả sử p_j là siêu đồng dạng cho tất cả τ_j dưới H_j cho một dung sai δ, ε ∈ (0,1) được chỉ định. Cho A là bất kỳ quy trình kiểm soát tỷ lệ lỗi family-wise (FWER) nào ở mức α ∈ (0,1), trong đó A(p_1, ..., p_k) chọn H_j để từ chối. Việc chọn τ_* := min(τ_valid ∪ {1}) sau đó tạo ra một LLM_early nhất quán với xác suất ít nhất 1-α.

Lưu ý rằng một quy trình kiểm soát FWER ở mức α là một thuật toán quyết định chấp nhận hoặc từ chối các giả thuyết {H_i}^k_{i=1}, trong khi đảm bảo rằng xác suất từ chối sai bất kỳ H_j nào nhỏ hơn α. Chứng minh của Mệnh đề 1, được đưa ra trong Phụ lục A.1, theo trực tiếp từ Định lý 1 của Angelopoulos và cộng sự, và thực tế là LLM_early(P_test, 1) = LLM_full(P_test) theo cấu trúc theo Phương trình (4), sao cho chúng ta luôn có thể sử dụng τ = 1 như một dự phòng hợp lệ nếu chúng ta không thể xác định τ_valid không rỗng. Trong các phần tiếp theo, chúng tôi mô tả cách chúng tôi tính toán các p-value hợp lệ sử dụng S_cal, và lựa chọn quy trình kiểm soát FWER của chúng tôi.

4.2 Định nghĩa p-values cho thoát sớm nhất quán
LTT dựa vào các p-value hợp lệ p_j, trong đó p_j là một biến ngẫu nhiên thỏa mãn P(p_j ≤ u) ≤ u dưới H_j cho tất cả u ∈ [0,1]. Đối với mục đích của chúng tôi, chúng ta có thể có được các p-value hợp lệ từ tính nhất quán thực nghiệm của LLM_early(P_i, τ) được đo trên mẫu hiệu chỉnh ngẫu nhiên, S_cal. Vì chúng tôi đã giả sử w.l.o.g. rằng một trong các hàm nhất quán bị chặn D và R của chúng tôi từ Định nghĩa 1 và 2 đã được chuẩn hóa để nằm trong [0,1], chúng ta có thể, ví dụ, có được một p-value hợp lệ bằng cách đơn giản đảo ngược bất đẳng thức Hoeffding:

p^{Hoeffding}_j := e^{-2n(max(0, \hat{E}(τ_j) - δ))^2}, (9)

trong đó \hat{E}(τ_j) := (1/n)∑^n_{i=1} L_i(τ_j) là trung bình thực nghiệm của biến ngẫu nhiên L_i(τ_j) ∈ [0,1], với

L_i(τ_j) := D(LLM_early(P_i, τ_j), LLM_full(P_i)) hoặc (10)
L_i(τ_j) := max(0, R(LLM_early(P_i, τ_j), Z_i) - R(LLM_full(P_i), Z_i)); (11)

cho nhất quán văn bản so với nhất quán rủi ro, tương ứng. Lưu ý rằng, như một kỹ thuật của việc thực thi biến ngẫu nhiên L_i(τ_j) nằm trong [0,1], Phương trình (11) tính toán một ước lượng bảo thủ của sự khác biệt trong rủi ro thực nghiệm không khen thưởng các trường hợp trong đó rủi ro của mô hình thoát sớm thấp hơn.

4.3 Kiểm tra chuỗi cố định hiệu quả
Càng nhiều giá trị τ chúng ta kiểm tra, càng cao khả năng chúng ta có thể vô tình chọn một τ thực sự không dẫn đến các thế hệ nhất quán, bất chấp bất kỳ hiệu suất gây hiểu lầm nào chúng ta có thể đã đo được tình cờ trên S_cal. Như một phần của LTT, chúng ta phải chọn một quy trình kiểm tra bội điều chỉnh cho điều này (tức là kiểm soát FWER ở mức α). Mặc dù sự phụ thuộc chính xác giữa hiệu suất của LLM thoát sớm và τ không được biết, trong thực tế chúng tôi thấy rằng nó có xu hướng khá mượt mà và gần đúng đơn điệu. Tức là, các ngưỡng gần đó τ' ≈ τ có xu hướng hoạt động tương tự, trong khi τ > τ' có xu hướng dẫn đến hiệu suất tương đối nhất quán hơn. Tận dụng cấu trúc này, chúng tôi chọn sử dụng kiểm tra chuỗi cố định (FST) như quy trình kiểm soát FWER của chúng tôi.

Ở đây chúng tôi định nghĩa một chuỗi các ngưỡng giảm dần τ_1 > τ_2 > ... > τ_k với kích thước bước tương đối thô (ví dụ, tăng 0.05). Đối với mỗi τ_j theo thứ tự, chúng tôi tính p_j, và từ chối H_j nếu p_j ≤ α. Lần đầu tiên chúng ta không từ chối H_j, chúng ta ngay lập tức kết thúc tìm kiếm của mình, và trả về τ_{j-1} để sử dụng như ngưỡng hiệu chỉnh của chúng ta (hoặc τ_1, nếu chúng ta không từ chối H_1). Một Thuật toán của toàn bộ quy trình được cung cấp trong Phụ lục E.

5 Thiết lập Thí nghiệm
Chúng tôi đánh giá thực nghiệm các phương pháp của mình trên ba tác vụ sinh văn bản phổ biến khác nhau về độ dài sinh mục tiêu và mức độ trích xuất so với đầu vào. CNN/DM là một tập hợp các bài báo tin tức cần được tóm tắt trong vài câu. WMT15 EN-FR chứa các câu tiếng Anh (một câu mỗi ví dụ) cần được dịch máy sang tiếng Pháp. SQuAD 1.1 sách mở là một tập dữ liệu QA với các đoạn văn Wikipedia được ghép đôi với các câu hỏi, trong đó câu trả lời mục tiêu là một đoạn văn bản từ đầu vào. Thống kê độ dài của các tập xác thực được tóm tắt trong Bảng 1.

Mô hình. Chúng tôi triển khai CALM trên mô hình T5 bộ mã hóa-bộ giải mã đã cho thấy hiệu suất tốt trên các tác vụ trên, sử dụng khung T5X. Chúng tôi sử dụng mô hình T5 1.1 8 lớp không chia sẻ embeddings đầu vào và đầu ra. Chúng tôi chia sẻ tất cả embeddings đầu ra cho các dự đoán softmax, và bộ phân loại thoát sớm qua tất cả các lớp bộ giải mã. Dựa trên kết quả xác thực, chúng tôi đặt nhiệt độ của ngưỡng giảm dần của chúng tôi là α = 4 cho các thước đo softmax và bộ phân loại của CNN/DM và WMT. Trong các thiết lập khác, chúng tôi sử dụng α = 0. Xem App. C để biết thêm chi tiết, và App. B.3 cho mô hình T5 12 lớp.

Thước đo đánh giá. Chúng tôi sử dụng các thước đo tiêu chuẩn cho mỗi tác vụ: ROUGE-L cho CNN/DM, BLEU cho WMT, và Token-F1 cho SQUAD. Chúng tôi dựa vào cùng các thước đo để tính toán rủi ro và khoảng cách văn bản, ngoại trừ BLEU là thước đo cấp corpus không trực tiếp cho phép kiểm soát kỳ vọng. Thay vào đó, chúng tôi sử dụng thước đo học được BLEURT. Đối với một thước đo cho trước m(y_early, y_full hoặc z_test) ∈ [0,1], chúng tôi sử dụng 1-m cho tính toán khoảng cách hoặc rủi ro, tương ứng.

Thước đo hiệu quả chính của chúng tôi là số lượng lớp bộ giải mã trung bình được sử dụng cho mỗi token đầu ra, vì nó đo trực tiếp việc giảm độ phức tạp mà không trộn lẫn với các chi tiết cụ thể về triển khai hoặc cơ sở hạ tầng. Để tham khảo, chúng tôi cũng báo cáo việc giảm FLOPs bộ giải mã trung bình cho mỗi token. Ngoài ra, chúng tôi tính toán một tăng tốc ước lượng của toàn bộ mô hình bộ mã hóa-bộ giải mã để sinh toàn bộ chuỗi, dựa trên đánh giá chuẩn TPUv3 với 200 ví dụ trong Colab (xem App. C để biết chi tiết).

Thí nghiệm hiệu chỉnh. Đối với mỗi tác vụ, chúng tôi sử dụng các tập xác thực và kiểm tra để đánh giá phương pháp hiệu chỉnh của chúng tôi (§4) (đối với SQUAD chúng tôi chỉ sử dụng tập xác thực vì các câu trả lời kiểm tra bị ẩn). Chúng tôi chạy 50 thử nghiệm ngẫu nhiên cho mỗi dung sai mục tiêu và mục tiêu nhất quán (văn bản hoặc rủi ro), trong đó chúng tôi phân chia dữ liệu thành 80% hiệu chỉnh (S_cal) và 20% kiểm tra (P_test). Chúng tôi đặt α = 0.05 cho tất cả các thí nghiệm.

Baseline. Chúng tôi nhấn mạnh rằng khung CALM là tổng quát cho bất kỳ LM tự hồi quy đa lớp nào với bất kỳ thước đo tin cậy nào, cho phép kiểm soát nhất quán bởi Phương trình (1) hoặc Phương trình (2). Để đánh giá thực nghiệm các lợi ích hiệu quả được tạo ra bởi các thước đo tin cậy được đề xuất của chúng tôi, chúng tôi so sánh với các baseline tĩnh sử dụng cùng số lượng lớp cho tất cả các token. Chúng tôi cũng so sánh việc huấn luyện bộ phân loại thoát sớm của chúng tôi với phương pháp hình học trong Phụ lục D. Ngoài ra, chúng tôi tính toán một thước đo cục bộ oracle (§3.3.1) như một ước lượng giới hạn trên của sự đánh đổi hiệu quả-hiệu suất.

6 Kết quả Thí nghiệm
Trước tiên chúng tôi báo cáo sự đánh đổi hiệu quả-hiệu suất thực nghiệm đạt được với mỗi thước đo tin cậy. Đối với mỗi tác vụ và thước đo, chúng tôi đánh giá toàn bộ phạm vi τ trên tập xác thực, với các bước 0.05.

Kết quả, được trình bày trong Hình 3, cho thấy sức mạnh của thước đo phản ứng softmax, chỉ cho phép mất mát hiệu suất nhỏ trong khi giảm hơn một nửa số lớp trong cả ba tác vụ. Bộ phân loại thoát sớm, hiệu quả hơn về FLOP, cũng hiệu quả, chủ yếu khi nhắm mục tiêu hiệu suất cao (phía bên phải của biểu đồ). Thước đo bão hòa trạng thái đơn giản và không tham số có khả năng cạnh tranh, nhưng thường rơi xuống dưới baseline tĩnh, bất chấp việc cho phép các quyết định thoát từng token.

Oracle động đạt được lợi ích hiệu quả hấp dẫn, chỉ sử dụng trung bình 1.5, 1.3, và 1.2 lớp cho tóm tắt, WMT, và QA, tương ứng, mà không mất bất kỳ hiệu suất nào. Điều này minh họa tiềm năng đầy đủ của CALM và để lại thêm chỗ cho cải thiện với các thước đo tin cậy tốt hơn. Nó cũng cho thấy hiệu quả của truyền trạng thái thời gian suy luận cho các lớp bị bỏ qua (§3.3.1).

6.1 Hiệu suất được hiệu chỉnh với nhất quán văn bản hoặc rủi ro được đảm bảo
Tiếp theo, chúng tôi kiểm tra kết quả của quá trình hiệu chỉnh. Vì rủi ro thu được được đảm bảo là hợp lệ (tức là ít nhất 95% thời gian), chúng tôi tập trung ở đây vào lợi ích hiệu quả cho mỗi δ, ε được chọn. Chúng tôi giới thiệu người đọc đến Phụ lục B để xác thực thực nghiệm và cho kết quả bổ sung và ví dụ định tính.

Bảng 2 trình bày lợi ích hiệu quả cho mỗi lựa chọn δ, ε cho mỗi mục tiêu nhất quán và thước đo tin cậy. Chúng tôi kiểm tra các giá trị lớn hơn cho nhất quán văn bản vì đây thường là một yêu cầu nghiêm ngặt hơn vì lỗi của mô hình đầy đủ không được xem xét.

Trên tất cả δ, ε, thước đo tin cậy softmax dẫn đến sự giảm lớn nhất về số lượng lớp bộ giải mã cần thiết. Tương ứng, softmax chủ yếu cho phép lợi ích tăng tốc cao nhất lên đến khoảng ba lần nhanh hơn so với chạy qua tất cả các lớp của mô hình. Bộ phân loại thoát sớm rất nhẹ đôi khi cung cấp lợi ích tốt hơn softmax, ngay cả khi nhiều lớp giải mã hơn được sử dụng. Vì tăng tốc được tính toán trên toàn bộ đầu ra được sinh, chúng ta thấy nhiều lợi ích hơn trên các đầu ra dài hơn của tóm tắt và dịch trong đó việc giải mã chiếm hầu hết thời gian, so với các đầu ra QA ngắn trong đó toàn bộ thời gian giải mã không dài hơn nhiều so với thời gian mã hóa.

Những lợi ích hiệu quả đáng khuyến khích này được tạo ra ngay cả với các đảm bảo hiệu suất nghiêm ngặt đôi khi bảo thủ (ví dụ, Phương trình (11)). Chúng tôi lưu ý rằng việc giảm bớt các ràng buộc này, hoặc thắt chặt các khoảng tin cậy (ví dụ, với các tập hiệu chỉnh lớn hơn), có thể cải thiện thêm các lợi ích thực nghiệm.

Hoạt động softmax trên toàn bộ từ vựng đầu ra nặng về FLOPs (tuy nhiên, tính toán này có thể được song song hóa), đôi khi dẫn đến tăng tổng FLOPs, ngay cả với ít lớp được sử dụng hơn. Các thước đo dựa trên trạng thái và bộ phân loại thoát sớm đòi hỏi FLOPs tối thiểu và cung cấp một thay thế tốt với lợi ích hiệu quả hấp dẫn, nếu tổng FLOPs (có thể song song hóa, hoặc không) là mối quan tâm.

6.2 Ví dụ đầu ra: phân bổ hiệu quả khả năng của mô hình qua các bước thời gian
Hình 4 trình bày hai thế hệ tóm tắt CALM cho một bài báo từ tập dữ liệu CNN/DM, so với đầu ra của mô hình đầy đủ (Xem Hình B.5 trong Phụ lục cho ví dụ từ các tác vụ khác). Y^(2)_early sử dụng ngưỡng tin cậy thấp hơn cho thoát sớm so với Y^(1)_early. Các màu sắc, mô tả số lượng lớp bộ giải mã được sử dụng cho mỗi token đầu ra, minh họa cách CALM đạt được lợi ích hiệu quả. Chỉ một vài token được chọn sử dụng toàn bộ khả năng của mô hình (tô màu đỏ), trong khi đối với hầu hết các token mô hình thoát sau một hoặc vài lớp giải mã (tô màu xanh lá cây).

Ví dụ trong Hình 4 cũng chứng minh một sự khác biệt giữa hai loại ràng buộc nhất quán, cho một đầu ra tham chiếu Z_test. Nhất quán văn bản D(Y_early, Y_full) thường (mặc dù không phải lúc nào cũng) suy giảm (tức là tăng) khi giảm ngưỡng tin cậy vì các đầu ra có xu hướng phân kỳ đáng kể hơn từ Y_full. Tuy nhiên, xu hướng của nhất quán rủi ro phụ thuộc cũng vào đầu ra tham chiếu Z_test. Nếu Y_full ≈ Z_test thì hai ràng buộc gần giống nhau. Trong ví dụ này, chúng đủ khác nhau để Y^(2)_early đạt được rủi ro tốt hơn (thấp hơn) mặc dù khoảng cách văn bản từ Y_full cao hơn. Một mặt, cho tính khả dụng của các đầu ra tham chiếu để hiệu chỉnh, điều này gợi ý rằng đối với một mô hình không hoàn hảo, nhất quán rủi ro có thể dẫn đến thoát sớm tích cực hơn trong khi duy trì chất lượng của các thế hệ. Mặt khác, vì Relu trong Phương trình (11) không khen thưởng sự khác biệt rủi ro âm, lợi ích có thể không hoàn toàn hiện thực hóa. Nhìn chung, hai ràng buộc cung cấp các thay thế khác nhau cho người dùng chọn lựa tùy thuộc vào tính khả dụng của các đầu ra tham chiếu, hiệu suất của mô hình đầy đủ, và các đảm bảo hiệu suất mong muốn chính xác.

7 Kết luận
Chúng tôi trình bày mô hình ngôn ngữ thích ứng tự tin (CALM) để phân bổ động các lượng tính toán khác nhau cho mỗi token được sinh, theo các mức dung sai được định nghĩa rõ ràng trên đầu ra sinh hoàn chỉnh. Bài báo này bao gồm cả các giải pháp mô hình và phân tích hướng tới mục tiêu này, cũng như một khung có nền tảng lý thuyết để kiểm soát một cách có thể chứng minh chất lượng của đầu ra đầy đủ để đáp ứng các mức dung sai do người dùng chỉ định. Chúng tôi điều tra các tác động của thoát sớm cục bộ trong quá trình giải mã đối với đầu ra cuối cùng, dẫn chúng tôi đề xuất một hàm giảm dần trên ngưỡng ban đầu cho phép kiểm soát tinh tế hơn đối với các sự đánh đổi hiệu quả-hiệu suất mà không làm tăng không gian tìm kiếm. Chúng tôi cũng nghiên cứu các giải pháp khác nhau để giải quyết các tính toán bị thiếu của các token thoát sớm mà các token tương lai phụ thuộc vào. Nhìn chung, khung tính toán thích ứng hoàn chỉnh của chúng tôi cho LMs đòi hỏi những sửa đổi tối thiểu đối với mô hình cơ bản và cho phép lợi ích hiệu quả trong khi thỏa mãn các đảm bảo chất lượng nghiêm ngặt cho đầu ra. Ngoài ra, các thí nghiệm oracle và phân tích thời gian chạy của chúng tôi chứng minh tiềm năng đầy đủ của khung này và để lại chỗ cho nghiên cứu tương lai để cải thiện thêm hiệu quả một cách có thể kiểm soát.

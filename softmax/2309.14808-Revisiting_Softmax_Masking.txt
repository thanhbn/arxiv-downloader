# 2309.14808.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/softmax/2309.14808.pdf
# File size: 5216441 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Revisiting Softmax Masking:
Stop Gradient for Enhancing Stability in Replay-based
Continual Learning
Hoyong Kim1, Minchan Kwon2, Kangil Kim1∗
Artificial Intelligence Graduate School1, Graduate School of AI2
Gwangju Institute of Science and Technology1, KAIST2
Republic of Korea
hoyong.kim.21@gm.gist.ac.kr, {kmc020700, kangil.kim.01 }@gmail.com
Abstract
In replay-based methods for continual learning, replaying input samples in episodic
memory has shown its effectiveness in alleviating catastrophic forgetting. However,
the potential key factor of cross-entropy loss with softmax in causing catastrophic
forgetting has been underexplored. In this paper, we analyze the effect of softmax
and revisit softmax masking with negative infinity to shed light on its ability to
mitigate catastrophic forgetting. Based on the analyses, it is found that negative
infinity masked softmax is not always compatible with dark knowledge. To improve
the compatibility, we propose a general masked softmax that controls the stability
by adjusting the gradient scale to old and new classes. We demonstrate that utilizing
our method on other replay-based methods results in better performance, primarily
by enhancing model stability in continual learning benchmarks, even when the
buffer size is set to an extremely small value.
1 Introduction
In continual learning, catastrophic forgetting is a challenging problem. It refers to the difficulty
of preserving previously trained information in a model when learning from future task data [ 1].
Recent works have focused on utilizing episodic memory to stably transfer information, allowing for
accurate recall of previous task information without sacrificing adaptation on current tasks [ 2–15].
This feature is also known as stability [ 16]. For instance, a well-performing model [ 4] stores real
samples along with their confidence outputs at each update iteration, while balancing their size across
tasks. However, this methodology does not directly modify the training dynamics of a neural network.
In particular, the gradient from cross-entropy loss with softmax is one of the main factors that can
cause catastrophic forgetting, but it has not yet been extensively studied.
In numerous works [ 17–21], the use of cross-entropy loss with softmax results in the model being
overconfident in its pretrained knowledge. This is achieved by increasing the confidence of a target
class while decreasing the confidence of other classes. The pullandpush effects [ 22] exacerbate
catastrophic forgetting in continual learning. This occurs because the gradients towards target classes
in the current task pull last-layer features towards their respective class weight vectors while pushing
other class weight vectors in previous tasks, without any access to input samples of those tasks,
as illustrated in Figure 1. In terms of the push effect of softmax, prior replay-based methods have
alleviated it by replaying the input samples of previous tasks in external memory and retraining their
respective class weight vectors. However, the prior replay-based method of using the re-aligning
features and class weight vectors implicitly relieves the push effect of softmax.
∗corresponding author
Preprint. Under review.arXiv:2309.14808v2  [cs.LG]  24 Jan 2024

--- PAGE 2 ---
Figure 1: Relation between Catastrophic Forgetting and Cross-Entropy Loss with Softmax in Contin-
ual Learning.
To explicitly control the pullandpush effect of softmax, we revisit the common masked softmax
and propose using a general masked softmax approach. While masking is a widely used technique in
literature, its implications for model stability have been under-investigated. By using masked softmax,
we can ensure stability while still achieving our desired results. This approach utilizes negative infinity
value or any real value to mask probability for the classes in previous and future tasks, effectively
enhancing stability. In this study, we empirically analyze the confidence change, plasticity (overall
accuracy across tasks), and stability (accuracy of previous tasks at each training step) of split datasets
in class and task incremental continual learning. We vary the memory size in replay-based methods
and demonstrate that masking in softmax is effective in adjusting model stability. Our results show
that replay-based methods with general masked softmax outperform various datasets in continual
learning scenarios.
Our contribution is:
•We revisit the use of softmax masking and highlight its ability to preserve previously trained
confidence information in continual learning.
•We propose a general masked softmax approach and demonstrate its effectiveness in utilizing
the confidence holding, even with an extremely low buffer size.
•Empirical results show that our approach enhances stability on well-known replay-based
continual learning models and benchmarks while maintaining sufficiently large plasticity.
2 Related Work
Cross-entropy with Softmax in Replay-based Continual Learning. Similar to common image
classification settings, replay-based continual learning employs cross-entropy loss with softmax.
Experience Replay (ER) [ 6] uses buffer samples in episodic memory and it has the effect of offsetting
the catastrophic forgetting to some extent by canceling out the push effect of current samples via the
gradients from these samples. GEM [ 9] and A-GEM [ 2] utilize inequality constraints to prevent an
increase in the gradients of previous tasks while allowing their decrease through the storage and replay
of these gradients in episodic memory. In addition to buffer samples, some prior works have employed
a distillation loss term to retain previous knowledge. iCaRL [ 10] trains images from a current task and
exemplars from previous tasks using cross-entropy and distillation loss. The exemplars are updated
and stored in episodic memory. Dark Experience Replay (DER) and DER++ [ 4] store the logits
of previous tasks in episodic memory and use them for distillation loss in the current task. These
replay-based methods are simple but effective in preventing catastrophic forgetting by recovering
2

--- PAGE 3 ---
(a)Confidence and Accuracy on S-MNIST
(Experiments w/o distillation)
(b)Confidence and Accuracy on S-MNIST
(Experiments w/ distillation)
(c)Confidence and Accuracy on S-CIFAR10
(Experiments w/ distillation)
(d)Change in Accuracy on S-MNIST
(Experiments w/o distillation)
(e)Change in Accuracy on S-MNIST
(Experiments w/ distillation)
(f)Change in Accuracy on S-CIFAR10
(Experiments w/ distillation)
Figure 2: Comparison Experiments between baseline and masked softmax in class-incremental learn-
ing. (1strow) Confidence of each classes and accuracy of each tasks after the final task. Confidence is
measured by the output of the softmax function from the logits of input samples. (2ndrow) Change
in average accuracy for each task as the models are trained up to the N-th task. Task-wise average
accuracy is defined as the mean of accuracies of each class in the task. The dataset and methods
used in each experiment are described in the title and caption. (Acc: task-wise average test accuracy,
Tn:n-th task, red: higher than baseline, blue: lower than baseline, FAA: Final Average Accuracy,
Class-IL: Class-Incremental Learning, Task-IL: Task-Incremental Learning, bold : best FAA)
buffer samples and, in some cases, their logits from previous tasks. However, while the losses related
to buffer samples cancel out the push effect of softmax on current samples, they do not consider the
push andpulleffects of softmax and do not directly control them.
Some replay-based methods have focused on the classifier to alleviate the forgetting caused by the
push effect [ 12,22]. One such method is Regular Polytope Classifier (RPC) [ 12], which fixes the
classifier of models as regular polytope shapes to escape the influence of the push effect. Another
method [22], inspired by neural collapse, also fixes the classifier but in a different shape - a simplex
equiangular tight frame - which occurs in post-training after zero training error. However, neither
of these methods directly controls the softmax. In contrast, the use of softmax masking is a simple
and direct method to prevent the push effect of softmax. It is effective in alleviating catastrophic
forgetting by increasing the stability of models in continual learning scenarios.
Masked Softmax in Continual Learning. Although the benefits of softmax masking in improving
continual learning are recognized, the exact mechanisms behind these benefits are not well understood.
There are various approaches to continual learning [ 23], but our paper focuses on the scenario of task
and class incremental continual learning in offline, where the model learns new classes progressively
with or without task ids [ 4,15,24]. In the scratch-initiated setting, researchers have explored the use
of negative infinity masking on the softmax function to enhance performance [ 25]. Additionally, their
findings were limited to an online environment where data is accessed only once. Many recent studies
use visual prompts to mitigate forgetting in pre-trained models by employing softmax masking [ 26–
28]. Previous studies have shown that visual prompts often rely on the masking approach. The
softmax masking technique, even when used alone, can produce impressive results with large pre-
trained models [ 27]. Building on prior research on softmax masking, we revisit the softmax masking
approach and expand it into a general form. We then integrate the general masked softmax with a
state-of-the-art continual learning framework, starting from scratch, and explore its implications.
3 Effects of Softmax Masking in Continual Learning
Continual Learning Setting. LetD= (X,Y)datasets with Npairs of input samples Xand
one-hot encoding vectors Yassociated with Xwhere the element at the input sample’s class label
is 1 and the others are 0. When there is a class label set K={1,2, . . . , K }andTtasks, we denote
3

--- PAGE 4 ---
N(t)
kas the number of pairs (X(t)
k,Y(t)
k)ink-th class belong to t-th task, i.e.,N(t)=P
k∈K(t)N(t)
k,
where K(t)is a set of class labels in the t-th task.
3.1 Analyses on Masked Softmax in Continual Learning
Change in Confidence and Task-wise Average Accuracy of Model. In common masking methods,
they set the masking value to negative infinity and multiply it to logits from input samples before
softmax. Thus, we also use a negative infinity mask to implement masked softmax in continual
learning setting, i.e.,
M(t)= (Mi,j)1≤i≤N(t),1≤j≤K,
p(t)=SOFTMAX (M(t)⊙(W⊺H(t)+b1⊺
N(t))),(1)
where Mis a negative infinity mask, Mi,j= 1ifj∈K(t)otherwise −∞ ,His last-layer features of
input samples, and pis their confidence interpreted to probabilistic distribution by softmax function.
W∈RD×Kandb∈RKare weight parameters of the classifier, 1n∈Rnis the ones vector, and ⊙
is the Hadamard product.
Upon the definition of masked softmax, we conducted comparison experiments between ER and
ER with masked softmax (MSER) and visualized the results, as shown in Figure 2a and Figure 2d.
In Figure 2a, the use of masked softmax results in increased confidences of classes in the initial
tasks, while the confidences of others in recent tasks decreased slightly. This indicates that setting
the masked softmax to a negative infinity value is an effective way to maintain confidence in old
classes by preventing gradients from flowing towards them. The Figure 2d also supports the effect
of masked softmax with a negative infinity value. It shows that the initial accuracy of each class in
the task is inferior, but it maintains better than before. In addition, MSER has demonstrated their
superior final average accuracy in both class-incremental learning (ER: 78.27% <MSER: 82.98%)
and task-incremental learning (ER: 97.73% <MSER: 98.33%). Therefore, we conclude that masking
a negative infinity value to the logits of old and new classes can improve the model performance by
increasing stability of models.
Masked Softmax with Dark Knowledge. However, an increment in stability does not always work
result in improved model. For instance, when the logits of input samples from old classes were trained
with negative infinity masked softmax and then transferred to the future tasks, the model exhibited
inferior performance compared to its previous performance, as illustrated in Figure 2b and Figure 2e.
In Figure 2b, the confidence of classes in the initial tasks are well preserved after training all tasks,
while the confidences of posterior tasks are lower than DER++. This phenomenon is likely caused
by transferring wrongly trained logits with negative infinity masked softmax and distilling them to
the model training on the current task. In addition, the model trains new input samples of the current
task with negative infinity masked softmax, which ensures the class weight vectors of old classes
remain unchanged. As a result, the realignment of the class weight vectors of old classes with current
knowledge is solely dependent on buffer samples. However, these samples are restricted by the size
of episodic memory, which can lead to overfitting and finally result in a low inductive bias about
previous tasks. It means that extremely increasing the model stability from negative infinity masked
softmax is not always beneficial for continual learning to achieve high performance. This is because it
can hinder the model’s ability to adapt new knowledge from future tasks. The Figure 2f demonstrates
this trend, where the initial average accuracy of each task is lower than DER++. To the best of our
knowledge, the model only has superior performance with masked softmax in class-incremental and
task-incremental learning if the improvement of stability increment is larger than the decrement of
plasticity, as compared to the results in Figure 2e and Figure 2f.
Motivation. The research question we address is how to control the trade-off between stability and
plasticity in masked softmax . To answer this question, we propose a general masked softmax that
replaces the logits of old and new classes in previous and future tasks with not only a negative infinity
but also any real values, thus controlling the push effect of softmax. We introduce our approach
with explanation in terms of gradients (section 3.2), demonstrate the effectiveness of our method in
comparison experiments with ER and DER++ on continual learning benchmarks (section 4.1), even
in extremely low buffer size environment (section 4.2), and lastly studies about how the stability is
changed as the masking values (section 4.3).
4

--- PAGE 5 ---
3.2 General Masked Softmax
Figure 3: Overview of general masked softmax.
First, make masked logits zby replacing the logits
of old and new classes to a masking value m. Sec-
ond, apply softmax function on the masked logits
and achieve their confidence p. Lastly, backward
the loss while stop-gradient on replaced logits.In the same setting to section 3, we can define
general masked softmax att-th task as illustrated
in Figure 3:
Z(t)=W⊺H(t)+b1⊺
N(t)
Z(t)′= (Z′
i,j)1≤i≤N(t),1≤j≤K,
p(t)=SOFTMAX (Z(t)′),(2)
where Z(t)′is a masked logits, Z′
i,j =
Zi,jifj∈K(t)otherwise m∈[-∞,0].
Inter-task Interference. The softmax func-
tion is a probabilistic activation function that
ensures all elements in the output vector are pos-
itive and their sum equals 1, i.e.,
pi=exp (zi)PK
j=1exp (zj), (3)
where zi=w⊺
ih+bi.
In classification models utilizing cross-entropy
loss with softmax, the cost function and gradient
are defined as:
LSCE(x,y) =−KX
i=1yilog (pi)
∂LSCE
∂z=p−y,(4)
which indicates that all input samples invoke gradients which not only affect their own respective
class weight vectors, but also others.
Thanks to these gradients, classifiers using cross-entropy loss with softmax can achieve a max-margin
in decision. However, these pullandpush effects of softmax [ 22] impede the maintenance of the
classifier trained on previous tasks in continual learning. We call the flow of gradients from a target
class towards other classes as inter-task interference . General masked softmax can alleviate the
inter-task interference by replacing the logits from input samples of old and new classes, which are
not in a current task, to a specific masking value, i.e.,
LMSCE (x,y) =−KX
i=1yilog(p(t)
i),where
p(t)
i=

exp(zi)P
j∈K(t)exp(zj)+(K−|K(t)|)·exp(m),ifi∈K(t)
exp(m)P
j∈K(t)exp(zj)+(K−|K(t)|)·exp(m),otherwise ,(5)
where |·|denotes the cardinality of a set.
Eq. 5 means that class weight vectors except for those of the classes in the current task have a gradient
of 0. This stop gradient maintains the class weight vectors in previous and future tasks. As a result,
all gradients are calculated as below:
∂LMSCE
∂zk=p(t)
k−1,
∂LMSCE
∂zi=p(t)
k,∀i∈Kt\{k},
∂LMSCE
∂zj= 0,∀j /∈Kt.(6)
5

--- PAGE 6 ---
Table 1: Final Average Accuracy ↑(%) for standard continual learning benchmarks. All experiments
were conducted using 10 trials with random seeds except S-Tiny-ImageNet, where the experiment
utilized 5 triasls with random seeds. Best in bold. (The performance notation: mean std) (Please refer
to the performance of commonly used methods in Table 5 (Appendix A))
B MethodS-MNIST S-CIFAR-10 S-CIFAR-100 S-Tiny-ImageNet
Class-IL Task-IL Class-IL Task-IL Class-IL Task-IL Class-IL Task-IL
200ER[6] 80.43 1.89 97.86 0.35 44.79 1.86 91.19 0.94 - - 8.49 0.16 38.17 2.00
DER [4] 84.55 1.64 98.80 0.15 61.93 1.79 91.40 0.92 - - 11.87 0.78 40.22 0.67
DER++ [4] 85.61 1.40 98.76 0.28 64.88 1.17 91.92 0.60 - - 10.96 1.17 40.87 1.16
ER†78.27 1.37 97.73 0.26 49.38 2.15 91.54 0.81 14.88 0.47 66.75 1.06 8.580.19 38.39 0.72
MSER( m=-∞)†82.98 1.03 98.13 0.16 61.75 6.07 91.39 2.13 28.51 0.44 68.51 0.87 15.47 0.67 44.11 0.50
DER++†85.64 1.02 98.84 0.11 63.67 1.01 91.61 0.73 24.85 1.69 67.69 1.39 11.59 1.07 41.00 0.88
MSDER++( m=-∞)†84.45 0.88 99.03 0.09 66.35 1.52 93.17 0.54 28.57 1.11 74.02 0.76 13.21 0.56 49.75 0.99
MSDER++( m=-1)†88.21 0.49 99.07 0.12 64.38 3.42 92.34 1.76 28.70 1.35 74.33 0.72 13.25 0.51 51.24 0.78
500ER[6] 86.12 1.89 99.04 0.18 57.74 0.27 93.61 0.27 - - 9.99 0.29 48.64 0.46
DER [4] 90.54 1.18 98.84 0.13 70.51 1.67 93.40 0.39 - - 17.75 1.14 51.78 0.88
DER++ [4] 91.00 1.49 98.94 0.27 72.70 1.36 93.88 0.50 - - 19.38 1.41 51.91 0.68
ER†85.99 1.52 99.14 0.07 62.38 1.40 94.12 0.31 21.53 0.69 73.97 0.30 10.12 0.22 48.06 0.80
MSER( m=-∞)†89.35 0.59 99.20 0.16 70.64 1.28 94.22 0.41 35.68 0.89 74.77 0.71 20.43 0.38 53.21 0.84
DER++†91.01 0.46 98.95 0.07 73.15 0.80 94.07 0.39 37.41 1.40 76.07 0.60 19.82 0.87 52.24 0.94
MSDER++( m=-∞)†83.10 1.22 99.08 0.09 71.85 3.76 94.28 1.49 37.80 0.92 80.52 0.60 17.71 0.58 59.86 1.08
MSDER++( m=-1)†88.41 1.05 99.06 0.07 73.53 0.78 94.52 0.47 38.76 1.23 80.96 0.41 17.68 0.54 60.85 0.91
5120ER[6] 93.40 1.29 99.33 0.22 82.47 0.52 96.98 0.17 - - 27.40 0.31 67.29 0.23
DER [4] 94.90 0.57 99.29 0.11 83.81 0.33 95.43 0.33 - - 36.73 0.64 69.50 0.26
DER++ [4] 95.30 1.20 99.47 0.07 85.24 0.49 96.12 0.21 - - 39.02 0.97 69.84 0.63
ER†93.42 1.08 99.41 0.15 84.31 0.38 97.02 0.26 50.51 0.94 85.53 0.73 27.30 0.51 67.69 0.33
MSER( m=-∞)†93.51 0.60 99.38 0.12 82.63 1.34 96.45 0.27 52.95 0.73 84.20 0.58 35.73 0.41 67.50 0.53
DER++†95.09 0.56 99.50 0.08 85.56 0.38 96.30 0.22 59.62 0.63 86.61 0.32 39.66 0.89 69.95 0.32
MSDER++( m=-∞)†93.75 0.23 99.62 0.05 84.71 0.65 96.78 0.16 58.18 0.43 87.97 0.33 34.72 0.46 72.40 0.25
MSDER++( m=-1)†94.36 0.22 99.57 0.07 85.66 0.54 96.91 0.16 59.09 0.38 88.41 0.22 35.30 0.31 73.11 0.12
4 Experimental Results
Common Settings. We calculated the mean and standard deviation of experimental results in
multiple times using different random seeds. The number of seeds used in each experiment will
be described in the corresponding table. †means that the experiments was conducted on the same
environmental setting to ours.
Evaluation Metrics. Two commonly used evaluation metrics for quantitatively assessing model
performance in continual learning settings are Final Average Accuracy (AT)and Final Average
Forgetting (FT). Following [29], we denote them as Eq. 7.
AT=1
TTX
t=1aT,t,
FT=1
T−1TX
t=1max
i∈{1,...T−1}(ai,t−aT,t),(7)
where aj,tdenotes the test accuracy on the task Ttafter the model has been trained on all tasks up to
the task Tj. A higher test accuracy on each task after training is indicative of a higher AT, while a
lower reduction of test accuracy on each task after training is indicative of a lower FT.
Datasets. We followed [ 4] and conducted comparison experiments on a split datasets of the MNIST,
CIFAR-10, CIFAR100, and Tiny-ImageNet. The split-MNIST dataset consists of 5 tasks with 2
classes sequencially divided to each task, i.e., the task T0has 0 and 1 digits and the last task T4has 8
and 9 digits. In the same way, the split-CIFAR10 dataset is composed to 5 tasks with 2 classes. For
the split-CIFAR100 and split-Tiny-ImageNet, we set 10 tasks with 10 classes and 20 tasks with 10
classes, respectively.
Architectures. For comparison experiments with [ 4] in equivalent conditions, we follow [ 4] and
conducted the experiments by employing a fully-connected network with two hidden layers, each
6

--- PAGE 7 ---
Table 2: Final Average Forget ↓(%) for standard continual learning benchmarks. All experiments
were conducted using 10 trials with random seeds except S-Tiny-ImageNet, where the experiment
utilized 5 trials with random seeds. Best in bold. (The performance notation: mean std) (Please refer to
the performance of commonly used methods in Table 6 (Appendix A))
B MethodS-MNIST S-CIFAR-10 S-CIFAR-100 S-Tiny-ImageNet
Class-IL Task-IL Class-IL Task-IL Class-IL Task-IL Class-IL Task-IL
200ER[6] 21.36 2.46 0.840.41 61.24 2.62 7.080.64 - - - -
DER [4] 17.66 2.10 0.570.18 40.76 0.42 6.570.20 - - - -
DER++ [4] 16.27 1.73 0.660.28 32.59 2.32 5.160.21 - - - -
ER†24.09 1.61 0.890.24 58.97 2.70 6.490.90 81.61 0.61 24.18 1.12 76.62 0.48 43.52 0.85
MSER( m=-∞)†10.22 1.20 0.690.12 26.30 6.18 6.181.56 46.51 1.36 20.92 0.79 50.86 0.79 34.97 0.61
DER++†16.34 1.23 0.530.12 34.80 1.68 6.451.07 68.80 2.76 24.20 1.26 72.77 2.13 41.11 0.97
MSDER++( m=-∞)†4.290.75 0.320.09 23.10 1.46 4.820.71 48.52 0.62 17.34 0.77 52.96 0.72 32.20 1.21
MSDER++( m=-1)†5.000.51 0.320.10 22.84 2.00 5.501.47 48.48 1.59 17.09 0.77 55.22 0.56 30.32 0.93
500ER[6] 15.97 2.46 0.390.20 45.35 0.07 3.540.35 - - - -
DER [4] 9.581.52 0.450.13 26.74 0.15 4.560.45 - - - -
DER++ [4] 8.851.86 0.350.15 22.38 4.41 4.661.15 - - - -
ER†16.28 1.99 0.380.11 42.83 1.89 3.510.40 73.90 0.82 16.17 0.40 74.82 0.08 32.17 1.01
MSER( m=-∞)†7.181.37 0.390.17 17.31 1.58 3.090.36 39.74 1.36 13.94 0.64 51.25 0.35 27.73 0.80
DER++†9.000.50 0.410.05 23.12 1.88 3.560.38 52.74 2.65 15.13 0.74 59.04 1.27 27.96 0.72
MSDER++( m=-∞)†2.070.89 0.230.09 16.95 3.77 3.030.76 35.98 0.79 10.39 0.68 47.00 0.75 21.53 1.00
MSDER++( m=-1)†4.000.78 0.270.07 14.70 1.31 3.210.61 35.82 0.99 10.00 0.38 47.25 1.04 20.20 1.40
5120ER[6] 6.081.84 0.250.23 13.99 0.12 0.270.06 - - - -
DER [4] 4.530.83 0.320.08 10.12 0.80 2.590.08 - - - -
DER++ [4] 4.191.63 0.230.06 7.270.84 1.180.19 - - - -
ER†6.261.56 0.210.10 14.44 0.65 0.460.21 39.25 0.62 4.530.36 54.54 0.47 11.60 0.25
MSER( m=-∞)†3.121.10 0.240.10 7.571.31 0.810.28 22.01 0.40 4.100.35 30.03 0.58 9.500.52
DER++†4.590.79 0.240.10 7.500.80 1.050.34 25.28 0.71 4.560.50 31.60 1.79 9.630.53
MSDER++( m=-∞)†0.900.18 0.090.06 5.020.69 0.710.27 14.79 0.83 2.900.44 20.30 0.48 7.230.20
MSDER++( m=-1)†1.200.31 0.130.05 5.430.56 0.510.14 15.34 0.52 2.600.27 21.39 0.74 6.860.35
Table 3: Hyperparameter settings on all experiments in continual learning scenarios. ( B: buffer size,
lr: learning rate, α: weight hyperparameter for the cross-entropy loss from buffer samples, β: weight
hyperparameter for distillation loss from buffer samples.)
Method B S-MNIST S-CIFAR10 S-CIFAR100 S-TinyImg
ER200 lr: 0.01 lr: 0.1 lr: 0.1 lr: 0.1
500 lr: 0.1 lr: 0.1 lr: 0.1 lr: 0.03
5120 lr: 0.1 lr: 0.1 lr: 0.1 lr: 0.1
DER++200lr: 0.03, lr: 0.03, lr: 0.03, lr: 0.03,
α: 0.2, α: 0.1, α: 0.1, α: 0.1,
β: 1.0 β: 0.5 β: 0.5 β: 1.0
500lr: 0.03, lr: 0.03, lr: 0.03, lr: 0.03,
α: 1.0, α: 0.2, α: 0.1, α: 0.2,
β: 0.5 β: 0.5 β: 0.5 β: 0.5
5120lr: 0.1, lr: 0.03, lr: 0.03, lr: 0.03,
α: 0.2, α: 0.1, α: 0.1, α: 0.1,
β: 0.5 β: 1.0 β: 0.5 β: 0.5
one comprising of 100 ReLU units for the split-MNIST. We also use other split datasets with
ResNet18 [30].
4.1 Continual Learning Benchmarks
Implementation Details. We followed the best hyperparameter settings from [ 4], where compre-
hensive hyperparameter search was conducted. We summarize them in Table 3 and our method uses
the same hyperparameter settings to each method. Batch sizes are fixed to each dataset: 10 in the split
MNIST dataset, 32 in split CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets.
Results and Analyses. As illustrated in Table 1 and Table 2, our method has outperformed in
both class-incremental learning and task-incremental learning. In class-incremental learning, our
approach also showed superior performance in most cases, particularly in scenarios with low buffer
sizes and more complex datasets (refer to buffer size set to 200 in S-CIFAR100 and S-Tiny-ImageNet
in Table 1). Even in task-incremental learning, the masked replay method consistently outperformed
7

--- PAGE 8 ---
Table 4: Classification results for extremely low buffer sizes in standard continual learning benchmarks.
All experiments were conducted using 10 trials with random seeds. (·)means the masking value used
in each experiment. Best in bold. ( AT: Final Average Accuracy ↑(%),FT: Final Average Forgetting
↓(%))
B MethodS-MNIST S-CIFAR-10
Class-IL Task-IL Class-IL Task-IL
AT FT AT FT AT FT AT FT
10DER++†32.91 3.45 82.79 4.30 95.12 4.20 5.085.26 28.50 4.05 71.00 8.62 71.31 3.60 31.26 4.77
MSDER++(- ∞)†58.80 4.47 10.27 3.45 98.82 0.12 0.590.14 30.33 2.59 48.06 12.00 73.76 6.53 28.71 8.37
MSDER++(- 1)†53.29 4.12 17.59 5.85 96.95 1.94 2.832.39 20.16 2.62 32.77 7.67 72.15 4.65 29.90 5.72
50DER++†63.66 2.58 44.27 3.21 98.26 0.42 1.290.51 47.08 2.79 54.57 3.40 85.29 2.46 14.15 3.33
MSDER++(- ∞)†76.81 2.43 8.493.19 99.04 0.10 0.330.07 49.79 7.19 37.49 4.97 86.82 5.96 11.96 6.70
MSDER++(- 1)†79.07 2.63 10.34 2.70 98.79 0.19 0.620.21 41.21 5.81 29.40 4.17 82.65 3.29 17.75 4.01
100DER++†76.31 2.50 28.21 3.14 98.57 0.17 0.860.24 55.25 1.33 45.82 2.35 88.88 1.03 9.971.32
MSDER++(- ∞)†81.06 1.46 4.831.30 99.02 0.06 0.350.10 58.95 1.53 30.86 1.83 91.33 0.89 6.521.21
MSDER++(- 1)†84.16 1.90 6.831.02 98.91 0.14 0.460.19 53.90 1.92 28.14 2.78 88.49 2.80 10.21 3.51
in all experiments. This indicates that the masked softmax effectively maintains previously trained
information by alleviating inter-task interference.
Distillation with Masked Softmax is Dangerous. As shown in Table 1 and Table 2, the use
of masked softmax with negative infinity significantly improves model stability, especially when
used with ER. However, when used with knowledge distillation, the performance of most cases
has decreased compared to the baseline, even lower than MSER, where there is no danger due to
distillation (refer to MSDER++( m=-∞)).
Control Model Stability by Masking Value Adjustment. As shown in Table 1, in particular, this
danger stands out in simple and low buffer size settings. However, when the masking value is set to
-1, the performance of most models improves. Therefore, we conclude that controlling the masking
value is helpful in mitigating the extreme increase in model stability.
4.2 Continual Learning in Low Buffer Size
Implementation Details. Based on the findings from the results of softmax masking experiments on
continual learning benchmarks, it was found that softmax masking is more effective when the buffer
size is lower. We demonstrated this by conducting various experiments with extremely constrained
buffer sizes on the split MNIST and CIFAR10 datasets. The episodic memory buffer size was reduced
to 10, 50, and 100, and the model was trained with and without masked softmax. The results were
then quantitatively compared. All experimental settings, except for the buffer size, are equivalent to
those used in continual learning benchmarks.
Results and Analyses. As shown in Table 4, MSDER++(-1) outperforms DER++ and MSDER++(-
∞) in 10 and 50 buffer size on the split MNIST dataset. However, MSDER++(- ∞) consistently
shows its superior performance in other experiments. This suggests that when the replay samples are
insufficient to recover the previous knowledge, increasing the model’s stability is a more effective
method for improving performance in continual learning scenarios than transferring knowledge from
previous tasks.
4.3 Ablation Study for Masking Values
Implementation Details. To validate that the impact of general masked softmax is indeed reg-
ulated by controlling the masking value, we conducted experiments on split MNIST and CI-
FAR10 datasets with buffer sizes of 200, 500, and 5120, using various masking value m, where
m∈ {-∞,-109,-106,-103,-10,-5,-2,-1,0}. All experimental settings, except for the masking value,
were identical to those in continual learning benchmarks.
Results and Analyses. As illustrated in Figure 4d, masked softmax with dark knowledge outper-
forms DER++ in all masking values while MSDER++ shows inferior performance in all masking
8

--- PAGE 9 ---
(a) S-MNIST ( B: 200 )
 (b) S-MNIST ( B: 500 )
 (c) S-MNIST ( B: 5120 )
(d) S-CIFAR10 ( B: 200 )
 (e) S-CIFAR10 ( B: 500 )
 (f) S-CIFAR10 ( B: 5120 )
Figure 4: Change in final average accuracy according to the masking value. All experiments were
conducted using 10 trials with random seeds. The mean and standard deviation of final average
accuracy are represented as line and band, respectively. ( B: buffer size, dotted line: the final average
accuracy of the baseline - DER++)
values, as shown in Figures 4b and 4c. However, even in these inferior cases, the performance of the
model with masked softmax increases as the scale of the masking value decreases. This indicates that
controlling the masking value is effective in adjusting the push effect of softmax. Furthermore, as
illustrated in Figures 4a, 4e, and 4f, the model using masked softmax outperforms DER++ in certain
masking values. This means that by identifying the appropriate masking value for each setting, the
model’s performance in continual learning can be improved.
5 Conclusion and Future Work
In this paper, we shed light on the pullandpush effects of the softmax function when used with
cross-entropy loss in continual learning settings. The push effect of softmax exacerbates catastrophic
forgetting by flowing gradients toward the class weight vectors in previous tasks. To address this
issue, we revisit a well-known softmax masking approach to investigate maintaining confidence
against the push effect of softmax. The use of negative infinity masked softmax has been found
to be effective in achieving the desired purpose by producing zero gradients on both old and new
classes, thereby increasing model stability. However, it has been observed that this approach exhibits
inferior performance when transferring previous knowledge to the current task. To address the issue,
we suggest a general masked softmax that regulates the push effect of softmax. This is achieved by
setting the mask value to negative infinity or real values, while also preventing the gradient flow to
old and new classes. The effectiveness of our method in adjusting the trade-off between stability
and plasticity of the model in continual learning is demonstrated, and it improves prior replay-based
methods in continual learning benchmarks, even when the buffer size of episodic memory is set to
extremely small values. In future work, this method can be extended to provide more fine control in
terms of plasticity to reduce memory reliance more effectively.
References
[1]Robert M French. Catastrophic forgetting in connectionist networks. Trends in cognitive sciences ,
3(4):128–135, 1999.
[2]Arslan Chaudhry, Marc’Aurelio Ranzato, Marcus Rohrbach, and Mohamed Elhoseiny. Efficient lifelong
learning with a-gem. arXiv preprint arXiv:1812.00420 , 2018.
9

--- PAGE 10 ---
[3]Yue Wu, Yinpeng Chen, Lijuan Wang, Yuancheng Ye, Zicheng Liu, Yandong Guo, and Yun Fu. Large
scale incremental learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern
recognition , pages 374–382, 2019.
[4]Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, and Simone Calderara. Dark experience
for general continual learning: a strong, simple baseline. Advances in neural information processing
systems , 33:15920–15930, 2020.
[5]Eden Belouadah and Adrian Popescu. Il2m: Class incremental learning with dual memory. In Proceedings
of the IEEE/CVF international conference on computer vision , pages 583–592, 2019.
[6]Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish, Yuhai Tu, and Gerald Tesauro.
Learning to learn without forgetting by maximizing transfer and minimizing interference. arXiv preprint
arXiv:1810.11910 , 2018.
[7]Lucas Caccia, Rahaf Aljundi, Nader Asadi, Tinne Tuytelaars, Joelle Pineau, and Eugene Belilovsky.
New insights on reducing abrupt representation change in online continual learning. arXiv preprint
arXiv:2104.05025 , 2021.
[8]Ameya Prabhu, Philip HS Torr, and Puneet K Dokania. Gdumb: A simple approach that questions our
progress in continual learning. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow,
UK, August 23–28, 2020, Proceedings, Part II 16 , pages 524–540. Springer, 2020.
[9]David Lopez-Paz and Marc’Aurelio Ranzato. Gradient episodic memory for continual learning. Advances
in neural information processing systems , 30, 2017.
[10] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H Lampert. icarl: Incremental
classifier and representation learning. In Proceedings of the IEEE conference on Computer Vision and
Pattern Recognition , pages 2001–2010, 2017.
[11] Saihui Hou, Xinyu Pan, Chen Change Loy, Zilei Wang, and Dahua Lin. Learning a unified classifier
incrementally via rebalancing. In Proceedings of the IEEE/CVF conference on computer vision and pattern
recognition , pages 831–839, 2019.
[12] Federico Pernici, Matteo Bruni, Claudio Baecchi, Francesco Turchini, and Alberto Del Bimbo. Class-
incremental learning with pre-allocated fixed classifiers. In 2020 25th International Conference on Pattern
Recognition (ICPR) , pages 6259–6266. IEEE, 2021.
[13] David Isele and Akansel Cosgun. Selective experience replay for lifelong learning. In Proceedings of the
AAAI Conference on Artificial Intelligence , 2018.
[14] Tyler L Hayes, Nathan D Cahill, and Christopher Kanan. Memory efficient experience replay for streaming
learning. In 2019 International Conference on Robotics and Automation (ICRA) , pages 9769–9776. IEEE,
2019.
[15] Matteo Boschini, Lorenzo Bonicelli, Pietro Buzzega, Angelo Porrello, and Simone Calderara. Class-
incremental continual learning into the extended der-verse. IEEE Transactions on Pattern Analysis and
Machine Intelligence , 45(5):5497–5512, 2022.
[16] A. Robins. Catastrophic forgetting in neural networks: the role of rehearsal mechanisms. In Proceedings
1993 The First New Zealand International Two-Stream Conference on Artificial Neural Networks and
Expert Systems , pages 65–68, 1993.
[17] Hongxin Wei, Renchunzi Xie, Hao Cheng, Lei Feng, Bo An, and Yixuan Li. Mitigating neural network
overconfidence with logit normalization. In International Conference on Machine Learning , pages 23631–
23644. PMLR, 2022.
[18] Andreas Nugaard Holm, Dustin Wright, and Isabelle Augenstein. Revisiting softmax for uncertainty
approximation in text classification. Information , 14(7):420, 2023.
[19] Min Liu, Lanlan Hu, Ying Tang, Chu Wang, Yu He, Chunyan Zeng, Kun Lin, Zhizi He, and Wujie Huo. A
deep learning method for breast cancer classification in the pathology images. IEEE Journal of Biomedical
and Health Informatics , 26(10):5025–5032, 2022.
[20] Aleksandr Vladimirovich Petrov and Craig Macdonald. gsasrec: Reducing overconfidence in sequen-
tial recommendation trained with negative sampling. In Proceedings of the 17th ACM Conference on
Recommender Systems , pages 116–128, 2023.
10

--- PAGE 11 ---
[21] Jishnu Mukhoti, Andreas Kirsch, Joost van Amersfoort, Philip H. S. Torr, and Yarin Gal. Deep deterministic
uncertainty: A simple baseline, 2022.
[22] Yibo Yang, Haobo Yuan, Xiangtai Li, Zhouchen Lin, Philip H. S. Torr, and Dacheng Tao. Neural collapse
inspired feature-classifier alignment for few-shot class-incremental learning. In The Eleventh International
Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023 . OpenReview.net,
2023.
[23] Gido M van de Ven, Tinne Tuytelaars, and Andreas S Tolias. Three types of incremental learning. Nature
Machine Intelligence , 4(12):1185–1197, 2022.
[24] Hyuntak Cha, Jaeho Lee, and Jinwoo Shin. Co2l: Contrastive continual learning. In Proceedings of the
IEEE/CVF International conference on computer vision , pages 9516–9525, 2021.
[25] Lucas Caccia, Rahaf Aljundi, Nader Asadi, Tinne Tuytelaars, Joelle Pineau, and Eugene Belilovsky. New
insights on reducing abrupt representation change in online continual learning, 2022.
[26] Zifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang, Ruoxi Sun, Xiaoqi Ren, Guolong Su, Vincent
Perot, Jennifer Dy, and Tomas Pfister. Learning to prompt for continual learning. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 139–149, 2022.
[27] James Seale Smith, Leonid Karlinsky, Vyshnavi Gutta, Paola Cascante-Bonilla, Donghyun Kim, Assaf
Arbelle, Rameswar Panda, Rogerio Feris, and Zsolt Kira. Coda-prompt: Continual decomposed attention-
based prompting for rehearsal-free continual learning. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition (CVPR) , pages 11909–11919, June 2023.
[28] Zifeng Wang, Zizhao Zhang, Sayna Ebrahimi, Ruoxi Sun, Han Zhang, Chen-Yu Lee, Xiaoqi Ren, Guolong
Su, Vincent Perot, Jennifer Dy, et al. Dualprompt: Complementary prompting for rehearsal-free continual
learning. In European Conference on Computer Vision , pages 631–648. Springer, 2022.
[29] Lilly Kumari, Shengjie Wang, Tianyi Zhou, and Jeff A Bilmes. Retrospective adversarial replay for
continual learning. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors,
Advances in Neural Information Processing Systems , volume 35, pages 28530–28544. Curran Associates,
Inc., 2022.
[30] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition.
CoRR , abs/1512.03385, 2015.
[31] Jonathan Schwarz, Wojciech Czarnecki, Jelena Luketina, Agnieszka Grabska-Barwinska, Yee Whye Teh,
Razvan Pascanu, and Raia Hadsell. Progress & compress: A scalable framework for continual learning. In
International conference on machine learning , pages 4528–4537. PMLR, 2018.
[32] Friedemann Zenke, Ben Poole, and Surya Ganguli. Continual learning through synaptic intelligence. In
International conference on machine learning , pages 3987–3995. PMLR, 2017.
[33] Zhizhong Li and Derek Hoiem. Learning without forgetting. IEEE transactions on pattern analysis and
machine intelligence , 40(12):2935–2947, 2017.
[34] Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Ko-
ray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. Progressive neural networks. arXiv preprint
arXiv:1606.04671 , 2016.
[35] Ari S Benjamin, David Rolnick, and Konrad Kording. Measuring and regularizing networks in function
space. arXiv preprint arXiv:1805.08289 , 2018.
[36] Rahaf Aljundi, Min Lin, Baptiste Goujaud, and Yoshua Bengio. Gradient based sample selection for online
continual learning. Advances in neural information processing systems , 32, 2019.
[37] Arslan Chaudhry, Albert Gordo, Puneet Dokania, Philip Torr, and David Lopez-Paz. Using hindsight
to anchor past knowledge in continual learning. In Proceedings of the AAAI conference on artificial
intelligence , pages 6993–7001, 2021.
11

--- PAGE 12 ---
A Additional Experimental Results
Table 5: Classification results for standard continual learning benchmarks including the performance
of commonly used methods in these benchmarks. All experiments were conducted using 10 trials
with random seeds except S-Tiny-ImageNet, where the experiment utilized 5 triasls with random
seeds. Best in bold for each buffer setting. (Final Average Accuracy ↑(%): mean std)
B MethodS-MNIST S-CIFAR-10 S-CIFAR-100 S-Tiny-ImageNet
Class-IL Task-IL Class-IL Task-IL Class-IL Task-IL Class-IL Task-IL
-JOINT 95.57 0.24 99.51 0.07 92.20 0.15 98.31 0.12 - - 59.99 0.19 82.04 0.10
SGD 19.60 0.04 94.94 2.18 19.62 0.05 61.02 3.33 - - 7.92 0.26 18.31 0.68
-oEWC [31] 20.46 1.01 98.39 0.48 19.49 0.12 68.29 3.92 - - 7.58 0.10 19.20 0.31
SI[32] 19.27 0.30 96.00 2.04 19.48 0.17 68.05 5.91 - - 6.58 0.31 36.32 0.13
LwF[33] 19.62 0.01 94.11 3.01 19.61 0.05 63.29 2.35 - - 8.46 0.22 15.85 0.58
PNN [34] - 99.23 0.20 - 95.13 0.72 - - - 67.84 0.29
200GEM [9] 80.11 1.54 97.78 0.25 25.54 0.76 90.44 0.94 - - - -
A-GEM [2] 45.72 4.26 98.61 0.24 20.04 0.34 83.88 1.49 - - 8.07 0.08 22.77 0.03
iCaRL [10] 70.51 0.53 98.28 0.09 49.02 3.20 88.99 2.13 - - 7.53 0.79 28.19 1.47
FDR [35] 79.43 3.26 97.66 0.18 30.91 2.74 91.01 0.68 - - 8.70 0.19 40.36 0.68
GSS[36] 38.90 2.49 95.02 1.85 39.07 5.59 88.80 2.89 - - - -
HAL [37] 84.70 0.87 97.96 0.21 32.36 2.70 82.51 3.20 - - - -
ER[6] 80.43 1.89 97.86 0.35 44.79 1.86 91.19 0.94 - - 8.49 0.16 38.17 2.00
DER [4] 84.55 1.64 98.80 0.15 61.93 1.79 91.40 0.92 - - 11.87 0.78 40.22 0.67
DER++ [4] 85.61 1.40 98.76 0.28 64.88 1.17 91.92 0.60 - - 10.96 1.17 40.87 1.16
ER†78.27 1.37 97.73 0.26 49.38 2.15 91.54 0.81 14.88 0.47 66.75 1.06 8.580.19 38.39 0.72
MSER( m=-∞)†82.98 1.03 98.13 0.16 61.75 6.07 91.39 2.13 28.51 0.44 68.51 0.87 15.47 0.67 44.11 0.50
DER++†85.64 1.02 98.84 0.11 63.67 1.01 91.61 0.73 24.85 1.69 67.69 1.39 11.59 1.07 41.00 0.88
MSDER++( m=-∞)†84.45 0.88 99.03 0.09 66.35 1.52 93.17 0.54 28.57 1.11 74.02 0.76 13.21 0.56 49.75 0.99
MSDER++( m=-1)†88.21 0.49 99.07 0.12 64.38 3.42 92.34 1.76 28.70 1.35 74.33 0.72 13.25 0.51 51.24 0.78
500GEM [9] 85.99 1.35 98.71 0.20 26.20 1.26 92.16 0.69 - - - -
A-GEM [2] 46.66 5.85 98.93 0.21 22.67 0.57 89.48 1.45 - - 8.06 0.04 25.33 0.49
iCaRL [10] 70.10 1.08 98.32 0.07 47.55 3.95 88.22 2.62 - - 9.38 1.53 31.55 3.27
FDR [35] 85.87 4.04 97.54 1.90 28.71 3.23 93.29 0.59 - - 10.54 0.21 49.88 0.71
GSS[36] 49.76 4.73 97.71 0.53 49.73 4.78 91.02 1.57 - - - -
HAL [37] 87.21 0.49 98.03 0.22 41.79 4.46 84.54 2.36 - - - -
ER[6] 86.12 1.89 99.04 0.18 57.74 0.27 93.61 0.27 - - 9.99 0.29 48.64 0.46
DER [4] 90.54 1.18 98.84 0.13 70.51 1.67 93.40 0.39 - - 17.75 1.14 51.78 0.88
DER++ [4] 91.00 1.49 98.94 0.27 72.70 1.36 93.88 0.50 - - 19.38 1.41 51.91 0.68
ER†85.99 1.52 99.14 0.07 62.38 1.40 94.12 0.31 21.53 0.69 73.97 0.30 10.12 0.22 48.06 0.80
MSER( m=-∞)†89.35 0.59 99.20 0.16 70.64 1.28 94.22 0.41 35.68 0.89 74.77 0.71 20.43 0.38 53.21 0.84
DER++†91.01 0.46 98.95 0.07 73.15 0.80 94.07 0.39 37.41 1.40 76.07 0.60 19.82 0.87 52.24 0.94
MSDER++( m=-∞)†83.10 1.22 99.08 0.09 71.85 3.76 94.28 1.49 37.80 0.92 80.52 0.60 17.71 0.58 59.86 1.08
MSDER++( m=-1)†88.41 1.05 99.06 0.07 73.53 0.78 94.52 0.47 38.76 1.23 80.96 0.41 17.68 0.54 60.85 0.91
5120GEM [9] 95.11 0.87 99.44 0.12 25.26 3.46 95.55 0.02 - - - -
A-GEM [2] 54.24 6.49 98.93 0.20 21.99 2.29 90.10 2.09 - - 7.96 0.13 26.22 0.65
iCaRL [10] 70.60 1.03 98.32 0.11 55.07 1.55 92.23 0.84 - - 14.08 1.92 40.83 3.11
FDR [35] 87.47 3.15 97.79 1.33 19.70 0.07 94.32 0.97 - - 28.97 0.41 68.01 0.42
GSS[36] 89.39 0.75 98.33 0.17 67.27 4.27 94.19 1.15 - - - -
HAL [37] 89.52 0.96 98.35 0.17 59.12 4.41 88.51 3.32 - - - -
ER[6] 93.40 1.29 99.33 0.22 82.47 0.52 96.98 0.17 - - 27.40 0.31 67.29 0.23
DER [4] 94.90 0.57 99.29 0.11 83.81 0.33 95.43 0.33 - - 36.73 0.64 69.50 0.26
DER++ [4] 95.30 1.20 99.47 0.07 85.24 0.49 96.12 0.21 - - 39.02 0.97 69.84 0.63
ER†93.42 1.08 99.41 0.15 84.31 0.38 97.02 0.26 50.51 0.94 85.53 0.73 27.30 0.51 67.69 0.33
MSER( m=-∞)†93.51 0.60 99.38 0.12 82.63 1.34 96.45 0.27 52.95 0.73 84.20 0.58 35.73 0.41 67.50 0.53
DER++†95.09 0.56 99.50 0.08 85.56 0.38 96.30 0.22 59.62 0.63 86.61 0.32 39.66 0.89 69.95 0.32
MSDER++( m=-∞)†93.75 0.23 99.62 0.05 84.71 0.65 96.78 0.16 58.18 0.43 87.97 0.33 34.72 0.46 72.40 0.25
MSDER++( m=-1)†94.36 0.22 99.57 0.07 85.66 0.54 96.91 0.16 59.09 0.38 88.41 0.22 35.30 0.31 73.11 0.12
12

--- PAGE 13 ---
Table 6: Classification results for standard continual learning benchmarks including the performance
of commonly used methods in these benchmarks. All experiments were conducted using 10 trials
with random seeds except S-Tiny-ImageNet, where the experiment utilized 5 trials with random seeds.
Best in bold for each buffer setting. (Final Average Forgetting ↓(%): mean std))
B MethodS-MNIST S-CIFAR-10 S-CIFAR-100 S-Tiny-ImageNet
Class-IL Task-IL Class-IL Task-IL Class-IL Task-IL Class-IL Task-IL
- SGD 99.10 0.55 5.152.74 96.39 0.12 46.24 2.12 - - - -
-oEWC [31] 97.79 1.24 0.440.16 91.64 3.07 29.33 3.84 - - - -
SI[32] 98.89 0.86 5.152.74 95.78 0.64 38.76 0.89 - - - -
LwF[33] 99.30 0.11 5.152.74 96.69 0.25 32.56 0.56 - - - -
PNN [34] - 0.00 0.00 - 0.00 0.00 - - - -
200GEM [9] 22.32 2.04 1.190.38 82.61 1.60 9.272.07 - - - -
A-GEM [2] 66.15 6.84 0.960.28 95.73 0.20 16.39 0.86 - - - -
iCaRL [10] 11.73 0.73 0.280.08 28.72 0.49 2.633.48 - - - -
FDR [35] 21.15 4.18 0.520.18 86.40 2.67 7.360.03 - - - -
GSS[36] 74.10 3.03 4.302.31 75.25 4.07 8.561.78 - - - -
HAL [37] 14.54 1.49 0.530.19 69.11 4.21 12.26 0.02 - - - -
ER[6] 21.36 2.46 0.840.41 61.24 2.62 7.080.64 - - - -
DER [4] 17.66 2.10 0.570.18 40.76 0.42 6.570.20 - - - -
DER++ [4] 16.27 1.73 0.660.28 32.59 2.32 5.160.21 - - - -
ER†24.09 1.61 0.890.24 58.97 2.70 6.490.90 81.61 0.61 24.18 1.12 76.62 0.48 43.52 0.85
MSER( m=-∞)†10.22 1.20 0.690.12 26.30 6.18 6.181.56 46.51 1.36 20.92 0.79 50.86 0.79 34.97 0.61
DER++†16.34 1.23 0.530.12 34.80 1.68 6.451.07 68.80 2.76 24.20 1.26 72.77 2.13 41.11 0.97
MSDER++( m=-∞)†4.290.75 0.320.09 23.10 1.46 4.820.71 48.52 0.62 17.34 0.77 52.96 0.72 32.20 1.21
MSDER++( m=-1)†5.000.51 0.320.10 22.84 2.00 5.501.47 48.48 1.59 17.09 0.77 55.22 0.56 30.32 0.93
500GEM [9] 15.57 1.77 0.540.15 74.31 4.62 9.120.21 - - - -
A-GEM [2] 65.84 7.24 0.640.20 94.01 1.16 14.26 4.18 - - - -
iCaRL [10] 11.84 0.73 0.300.09 25.71 1.10 2.662.47 - - - -
FDR [35] 13.90 5.19 1.352.40 85.62 0.36 4.800.00 - - - -
GSS[36] 60.35 6.03 0.890.40 62.88 2.67 7.733.99 - - - -
HAL [37] 9.971.62 0.350.21 62.21 4.34 5.411.10 - - - -
ER[6] 15.97 2.46 0.390.20 45.35 0.07 3.540.35 - - - -
DER [4] 9.581.52 0.450.13 26.74 0.15 4.560.45 - - - -
DER++ [4] 8.851.86 0.350.15 22.38 4.41 4.661.15 - - - -
ER†16.28 1.99 0.380.11 42.83 1.89 3.510.40 73.90 0.82 16.17 0.40 74.82 0.08 32.17 1.01
MSER( m=-∞)†7.181.37 0.390.17 17.31 1.58 3.090.36 39.74 1.36 13.94 0.64 51.25 0.35 27.73 0.80
DER++†9.000.50 0.410.05 23.12 1.88 3.560.38 52.74 2.65 15.13 0.74 59.04 1.27 27.96 0.72
MSDER++( m=-∞)†2.070.89 0.230.09 16.95 3.77 3.030.76 35.98 0.79 10.39 0.68 47.00 0.75 21.53 1.00
MSDER++( m=-1)†4.000.78 0.270.07 14.70 1.31 3.210.61 35.82 0.99 10.00 0.38 47.25 1.04 20.20 1.40
5120GEM [9] 4.301.16 0.160.09 75.27 4.41 6.912.33 - - - -
A-GEM [2] 55.10 10.79 0.630.21 84.49 3.08 11.36 1.68 - - - -
iCaRL [10] 11.64 0.72 0.260.06 24.94 0.14 1.590.57 - - - -
FDR [35] 11.58 3.97 0.951.61 96.64 0.19 1.930.48 - - - -
GSS[36] 7.901.21 0.180.11 58.11 9.12 7.712.31 - - - -
HAL [37] 6.551.63 0.130.07 27.19 7.53 5.210.50 - - - -
ER[6] 6.081.84 0.250.23 13.99 0.12 0.270.06 - - - -
DER [4] 4.530.83 0.320.08 10.12 0.80 2.590.08 - - - -
DER++ [4] 4.191.63 0.230.06 7.270.84 1.180.19 - - - -
ER†6.261.56 0.210.10 14.44 0.65 0.460.21 39.25 0.62 4.530.36 54.54 0.47 11.60 0.25
MSER( m=-∞)†3.121.10 0.240.10 7.571.31 0.810.28 22.01 0.40 4.100.35 30.03 0.58 9.500.52
DER++†4.590.79 0.240.10 7.500.80 1.050.34 25.28 0.71 4.560.50 31.60 1.79 9.630.53
MSDER++( m=-∞)†0.900.18 0.090.06 5.020.69 0.710.27 14.79 0.83 2.900.44 20.30 0.48 7.230.20
MSDER++( m=-1)†1.200.31 0.130.05 5.430.56 0.510.14 15.34 0.52 2.600.27 21.39 0.74 6.860.35
13

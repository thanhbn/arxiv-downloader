# Xem xét lại Che Phủ Softmax:
Dừng Gradient để Tăng Cường Ổn Định trong Học Liên Tục Dựa trên Phát Lại

Hoyong Kim1, Minchan Kwon2, Kangil Kim1∗
Trường Đại học Trí tuệ Nhân tạo1, Trường Đại học AI2
Viện Khoa học và Công nghệ Gwangju1, KAIST2
Cộng hòa Hàn Quốc
hoyong.kim.21@gm.gist.ac.kr, {kmc020700, kangil.kim.01 }@gmail.com

Tóm tắt
Trong các phương pháp dựa trên phát lại cho học liên tục, việc phát lại các mẫu đầu vào trong bộ nhớ tập đoạn đã chứng minh hiệu quả trong việc giảm thiểu quên thảm khốc. Tuy nhiên, yếu tố chính tiềm năng của hàm mất mát cross-entropy với softmax trong việc gây ra quên thảm khốc vẫn chưa được khám phá đầy đủ. Trong bài báo này, chúng tôi phân tích tác động của softmax và xem xét lại việc che phủ softmax với âm vô cực để làm sáng tỏ khả năng giảm thiểu quên thảm khốc của nó. Dựa trên các phân tích, chúng tôi phát hiện rằng softmax được che phủ âm vô cực không phải lúc nào cũng tương thích với kiến thức tối. Để cải thiện tính tương thích, chúng tôi đề xuất một softmax che phủ tổng quát kiểm soát độ ổn định bằng cách điều chỉnh thang gradient cho các lớp cũ và mới. Chúng tôi chứng minh rằng việc sử dụng phương pháp của chúng tôi trên các phương pháp dựa trên phát lại khác mang lại hiệu suất tốt hơn, chủ yếu bằng cách tăng cường độ ổn định mô hình trong các benchmark học liên tục, ngay cả khi kích thước buffer được đặt ở mức cực kỳ nhỏ.

1 Giới thiệu
Trong học liên tục, quên thảm khốc là một vấn đề thách thức. Nó đề cập đến khó khăn trong việc bảo tồn thông tin đã được đào tạo trước đó trong mô hình khi học từ dữ liệu nhiệm vụ tương lai [1]. Các nghiên cứu gần đây đã tập trung vào việc sử dụng bộ nhớ tập đoạn để chuyển giao thông tin một cách ổn định, cho phép gọi lại chính xác thông tin nhiệm vụ trước đó mà không hy sinh khả năng thích ứng với các nhiệm vụ hiện tại [2–15]. Tính năng này còn được gọi là độ ổn định [16]. Ví dụ, một mô hình hoạt động tốt [4] lưu trữ các mẫu thực tế cùng với các đầu ra độ tin cậy của chúng tại mỗi lần lặp cập nhật, đồng thời cân bằng kích thước của chúng qua các nhiệm vụ. Tuy nhiên, phương pháp này không trực tiếp sửa đổi động lực đào tạo của mạng nơ-ron. Đặc biệt, gradient từ hàm mất mát cross-entropy với softmax là một trong những yếu tố chính có thể gây ra quên thảm khốc, nhưng nó vẫn chưa được nghiên cứu rộng rãi.

Trong nhiều nghiên cứu [17–21], việc sử dụng hàm mất mát cross-entropy với softmax dẫn đến mô hình quá tự tin vào kiến thức đã được đào tạo trước. Điều này đạt được bằng cách tăng độ tin cậy của lớp mục tiêu trong khi giảm độ tin cậy của các lớp khác. Các hiệu ứng kéo và đẩy [22] làm trầm trọng thêm quên thảm khốc trong học liên tục. Điều này xảy ra vì các gradient hướng về các lớp mục tiêu trong nhiệm vụ hiện tại kéo các đặc trưng lớp cuối về phía các vector trọng số lớp tương ứng của chúng trong khi đẩy các vector trọng số lớp khác trong các nhiệm vụ trước đó, mà không có bất kỳ truy cập nào đến các mẫu đầu vào của những nhiệm vụ đó, như được minh họa trong Hình 1. Về hiệu ứng đẩy của softmax, các phương pháp dựa trên phát lại trước đó đã giảm thiểu nó bằng cách phát lại các mẫu đầu vào của các nhiệm vụ trước đó trong bộ nhớ ngoài và đào tạo lại các vector trọng số lớp tương ứng của chúng. Tuy nhiên, phương pháp dựa trên phát lại trước đó của việc sử dụng việc tái căn chỉnh các đặc trưng và vector trọng số lớp ngầm giải quyết hiệu ứng đẩy của softmax.

Để kiểm soát một cách rõ ràng hiệu ứng kéo và đẩy của softmax, chúng tôi xem xét lại softmax che phủ phổ biến và đề xuất sử dụng phương pháp softmax che phủ tổng quát. Mặc dù che phủ là một kỹ thuật được sử dụng rộng rãi trong tài liệu, nhưng những hàm ý của nó đối với độ ổn định mô hình vẫn chưa được điều tra đầy đủ. Bằng cách sử dụng softmax che phủ, chúng ta có thể đảm bảo độ ổn định trong khi vẫn đạt được kết quả mong muốn. Phương pháp này sử dụng giá trị âm vô cực hoặc bất kỳ giá trị thực nào để che phủ xác suất cho các lớp trong các nhiệm vụ trước đó và tương lai, hiệu quả tăng cường độ ổn định. Trong nghiên cứu này, chúng tôi phân tích thực nghiệm sự thay đổi độ tin cậy, tính dẻo dai (độ chính xác tổng thể qua các nhiệm vụ), và độ ổn định (độ chính xác của các nhiệm vụ trước đó tại mỗi bước đào tạo) của các tập dữ liệu phân chia trong học liên tục tăng dần lớp và nhiệm vụ. Chúng tôi thay đổi kích thước bộ nhớ trong các phương pháp dựa trên phát lại và chứng minh rằng che phủ trong softmax có hiệu quả trong việc điều chỉnh độ ổn định mô hình. Kết quả của chúng tôi cho thấy các phương pháp dựa trên phát lại với softmax che phủ tổng quát vượt trội trên nhiều tập dữ liệu khác nhau trong các tình huống học liên tục.

Đóng góp của chúng tôi là:
• Chúng tôi xem xét lại việc sử dụng che phủ softmax và làm nổi bật khả năng bảo tồn thông tin độ tin cậy đã được đào tạo trước đó trong học liên tục.
• Chúng tôi đề xuất phương pháp softmax che phủ tổng quát và chứng minh hiệu quả của nó trong việc sử dụng việc giữ độ tin cậy, ngay cả với kích thước buffer cực kỳ thấp.
• Kết quả thực nghiệm cho thấy phương pháp của chúng tôi tăng cường độ ổn định trên các mô hình và benchmark học liên tục dựa trên phát lại nổi tiếng trong khi duy trì tính dẻo dai đủ lớn.

2 Nghiên cứu liên quan

Cross-entropy với Softmax trong Học Liên tục Dựa trên Phát lại. Tương tự như các thiết lập phân loại hình ảnh thông thường, học liên tục dựa trên phát lại sử dụng hàm mất mát cross-entropy với softmax. Experience Replay (ER) [6] sử dụng các mẫu buffer trong bộ nhớ tập đoạn và nó có tác dụng bù đắp quên thảm khốc ở một mức độ nhất định bằng cách triệt tiêu hiệu ứng đẩy của các mẫu hiện tại thông qua các gradient từ những mẫu này. GEM [9] và A-GEM [2] sử dụng các ràng buộc bất đẳng thức để ngăn chặn sự gia tăng gradient của các nhiệm vụ trước đó trong khi cho phép chúng giảm thông qua việc lưu trữ và phát lại các gradient này trong bộ nhớ tập đoạn. Ngoài các mẫu buffer, một số nghiên cứu trước đây đã sử dụng thành phần hàm mất mát chưng cất để giữ lại kiến thức trước đó. iCaRL [10] đào tạo hình ảnh từ nhiệm vụ hiện tại và các mẫu điển hình từ các nhiệm vụ trước đó bằng cách sử dụng cross-entropy và hàm mất mát chưng cất. Các mẫu điển hình được cập nhật và lưu trữ trong bộ nhớ tập đoạn. Dark Experience Replay (DER) và DER++ [4] lưu trữ các logit của các nhiệm vụ trước đó trong bộ nhớ tập đoạn và sử dụng chúng cho hàm mất mát chưng cất trong nhiệm vụ hiện tại. Các phương pháp dựa trên phát lại này đơn giản nhưng hiệu quả trong việc ngăn chặn quên thảm khốc bằng cách khôi phục các mẫu buffer và, trong một số trường hợp, các logit của chúng từ các nhiệm vụ trước đó. Tuy nhiên, trong khi các hàm mất mát liên quan đến mẫu buffer triệt tiêu hiệu ứng đẩy của softmax trên các mẫu hiện tại, chúng không xem xét các hiệu ứng đẩy và kéo của softmax và không kiểm soát trực tiếp chúng.

Một số phương pháp dựa trên phát lại đã tập trung vào bộ phân loại để giảm thiểu việc quên gây ra bởi hiệu ứng đẩy [12,22]. Một phương pháp như vậy là Regular Polytope Classifier (RPC) [12], cố định bộ phân loại của các mô hình thành hình dạng đa diện đều để thoát khỏi ảnh hưởng của hiệu ứng đẩy. Một phương pháp khác [22], lấy cảm hứng từ neural collapse, cũng cố định bộ phân loại nhưng ở hình dạng khác - một khung chặt đều góc simplex - xảy ra trong quá trình hậu đào tạo sau lỗi đào tạo bằng không. Tuy nhiên, cả hai phương pháp này đều không kiểm soát trực tiếp softmax. Ngược lại, việc sử dụng che phủ softmax là một phương pháp đơn giản và trực tiếp để ngăn chặn hiệu ứng đẩy của softmax. Nó hiệu quả trong việc giảm thiểu quên thảm khốc bằng cách tăng độ ổn định của các mô hình trong các tình huống học liên tục.

Softmax Che phủ trong Học Liên tục. Mặc dù những lợi ích của việc che phủ softmax trong cải thiện học liên tục được công nhận, nhưng các cơ chế chính xác đằng sau những lợi ích này vẫn chưa được hiểu rõ. Có nhiều phương pháp tiếp cận học liên tục khác nhau [23], nhưng bài báo của chúng tôi tập trung vào tình huống học liên tục tăng dần nhiệm vụ và lớp trong môi trường ngoại tuyến, nơi mô hình học các lớp mới một cách tiến bộ với hoặc không có id nhiệm vụ [4,15,24]. Trong thiết lập bắt đầu từ đầu, các nhà nghiên cứu đã khám phá việc sử dụng che phủ âm vô cực trên hàm softmax để tăng cường hiệu suất [25]. Ngoài ra, những phát hiện của họ chỉ giới hạn trong môi trường trực tuyến nơi dữ liệu chỉ được truy cập một lần. Nhiều nghiên cứu gần đây sử dụng gợi ý trực quan để giảm thiểu việc quên trong các mô hình đã được đào tạo trước bằng cách sử dụng che phủ softmax [26–28]. Các nghiên cứu trước đây đã chỉ ra rằng gợi ý trực quan thường dựa vào phương pháp che phủ. Kỹ thuật che phủ softmax, ngay cả khi được sử dụng một mình, có thể tạo ra kết quả ấn tượng với các mô hình đã được đào tạo trước lớn [27]. Dựa trên nghiên cứu trước đây về che phủ softmax, chúng tôi xem xét lại phương pháp che phủ softmax và mở rộng nó thành dạng tổng quát. Sau đó, chúng tôi tích hợp softmax che phủ tổng quát với khung học liên tục hiện đại, bắt đầu từ đầu, và khám phá những hàm ý của nó.

3 Tác động của Che phủ Softmax trong Học Liên tục

Thiết lập Học Liên tục. Gọi D = (X,Y) là tập dữ liệu với N cặp mẫu đầu vào X và vector mã hóa một nóng Y liên kết với X trong đó phần tử tại nhãn lớp của mẫu đầu vào là 1 và các phần tử khác là 0. Khi có tập nhãn lớp K = {1,2, . . . , K} và T nhiệm vụ, chúng ta ký hiệu N_k^(t) là số cặp (X_k^(t), Y_k^(t)) trong lớp thứ k thuộc nhiệm vụ thứ t, tức là N^(t) = Σ_{k∈K^(t)} N_k^(t), trong đó K^(t) là tập các nhãn lớp trong nhiệm vụ thứ t.

3.1 Phân tích về Softmax Che phủ trong Học Liên tục

Thay đổi trong Độ tin cậy và Độ chính xác Trung bình theo Nhiệm vụ của Mô hình. Trong các phương pháp che phủ thông thường, họ đặt giá trị che phủ thành âm vô cực và nhân nó với logit từ các mẫu đầu vào trước softmax. Do đó, chúng tôi cũng sử dụng mặt nạ âm vô cực để thực hiện softmax che phủ trong thiết lập học liên tục, tức là,

M^(t) = (M_{i,j})_{1≤i≤N^(t),1≤j≤K},
p^(t) = SOFTMAX(M^(t) ⊙ (W^⊺H^(t) + b1_{N^(t)}^⊺)), (1)

trong đó M là mặt nạ âm vô cực, M_{i,j} = 1 nếu j ∈ K^(t) ngược lại -∞, H là các đặc trưng lớp cuối của mẫu đầu vào, và p là độ tin cậy của chúng được diễn giải thành phân phối xác suất bởi hàm softmax. W ∈ R^{D×K} và b ∈ R^K là các tham số trọng số của bộ phân loại, 1_n ∈ R^n là vector toàn một, và ⊙ là tích Hadamard.

Dựa trên định nghĩa của softmax che phủ, chúng tôi đã tiến hành các thí nghiệm so sánh giữa ER và ER với softmax che phủ (MSER) và trực quan hóa kết quả, như được thể hiện trong Hình 2a và Hình 2d. Trong Hình 2a, việc sử dụng softmax che phủ dẫn đến tăng độ tin cậy của các lớp trong các nhiệm vụ ban đầu, trong khi độ tin cậy của các lớp khác trong các nhiệm vụ gần đây giảm nhẹ. Điều này cho thấy rằng việc đặt softmax che phủ thành giá trị âm vô cực là một cách hiệu quả để duy trì độ tin cậy trong các lớp cũ bằng cách ngăn chặn gradient chảy về phía chúng. Hình 2d cũng hỗ trợ hiệu ứng của softmax che phủ với giá trị âm vô cực. Nó cho thấy rằng độ chính xác ban đầu của mỗi lớp trong nhiệm vụ kém hơn, nhưng nó duy trì tốt hơn so với trước đây. Ngoài ra, MSER đã chứng minh độ chính xác trung bình cuối cùng vượt trội của họ trong cả học tăng dần lớp (ER: 78.27% < MSER: 82.98%) và học tăng dần nhiệm vụ (ER: 97.73% < MSER: 98.33%). Do đó, chúng tôi kết luận rằng việc che phủ giá trị âm vô cực cho các logit của các lớp cũ và mới có thể cải thiện hiệu suất mô hình bằng cách tăng độ ổn định của các mô hình.

Softmax Che phủ với Kiến thức Tối. Tuy nhiên, sự gia tăng độ ổn định không phải lúc nào cũng dẫn đến cải thiện mô hình. Ví dụ, khi các logit của mẫu đầu vào từ các lớp cũ được đào tạo với softmax che phủ âm vô cực và sau đó được chuyển đến các nhiệm vụ tương lai, mô hình thể hiện hiệu suất kém hơn so với hiệu suất trước đó, như được minh họa trong Hình 2b và Hình 2e. Trong Hình 2b, độ tin cậy của các lớp trong các nhiệm vụ ban đầu được bảo tồn tốt sau khi đào tạo tất cả các nhiệm vụ, trong khi độ tin cậy của các nhiệm vụ sau thấp hơn DER++. Hiện tượng này có thể do việc chuyển các logit được đào tạo sai với softmax che phủ âm vô cực và chưng cất chúng cho mô hình đào tạo trên nhiệm vụ hiện tại. Ngoài ra, mô hình đào tạo các mẫu đầu vào mới của nhiệm vụ hiện tại với softmax che phủ âm vô cực, đảm bảo các vector trọng số lớp của các lớp cũ không thay đổi. Kết quả là, việc tái căn chỉnh các vector trọng số lớp của các lớp cũ với kiến thức hiện tại hoàn toàn phụ thuộc vào các mẫu buffer. Tuy nhiên, những mẫu này bị hạn chế bởi kích thước của bộ nhớ tập đoạn, có thể dẫn đến overfitting và cuối cùng dẫn đến độ thiên vị quy nạp thấp về các nhiệm vụ trước đó. Điều này có nghĩa là việc tăng độ ổn định mô hình một cách cực đoan từ softmax che phủ âm vô cực không phải lúc nào cũng có lợi cho học liên tục để đạt hiệu suất cao. Điều này là do nó có thể cản trở khả năng thích ứng kiến thức mới từ các nhiệm vụ tương lai của mô hình. Hình 2f chứng minh xu hướng này, nơi độ chính xác trung bình ban đầu của mỗi nhiệm vụ thấp hơn DER++. Theo hiểu biết tốt nhất của chúng tôi, mô hình chỉ có hiệu suất vượt trội với softmax che phủ trong học tăng dần lớp và tăng dần nhiệm vụ nếu cải thiện độ gia tăng ổn định lớn hơn sự giảm của tính dẻo dai, so với kết quả trong Hình 2e và Hình 2f.

Động lực. Câu hỏi nghiên cứu mà chúng tôi giải quyết là làm thế nào để kiểm soát sự đánh đổi giữa độ ổn định và tính dẻo dai trong softmax che phủ. Để trả lời câu hỏi này, chúng tôi đề xuất một softmax che phủ tổng quát thay thế các logit của các lớp cũ và mới trong các nhiệm vụ trước đó và tương lai không chỉ bằng âm vô cực mà còn bằng bất kỳ giá trị thực nào, do đó kiểm soát hiệu ứng đẩy của softmax. Chúng tôi giới thiệu phương pháp của mình với giải thích về gradient (phần 3.2), chứng minh hiệu quả của phương pháp của chúng tôi trong các thí nghiệm so sánh với ER và DER++ trên các benchmark học liên tục (phần 4.1), ngay cả trong môi trường kích thước buffer cực kỳ thấp (phần 4.2), và cuối cùng là nghiên cứu về cách độ ổn định thay đổi theo các giá trị che phủ (phần 4.3).

3.2 Softmax Che phủ Tổng quát

Trong cùng thiết lập với phần 3, chúng ta có thể định nghĩa softmax che phủ tổng quát tại nhiệm vụ thứ t như được minh họa trong Hình 3:

Z^(t) = W^⊺H^(t) + b1_{N^(t)}^⊺
Z^(t)' = (Z'_{i,j})_{1≤i≤N^(t),1≤j≤K},
p^(t) = SOFTMAX(Z^(t)'), (2)

trong đó Z^(t)' là logit che phủ, Z'_{i,j} = Z_{i,j} nếu j ∈ K^(t) ngược lại m ∈ [-∞,0].

Nhiễu loạn Liên-nhiệm vụ. Hàm softmax là một hàm kích hoạt xác suất đảm bảo tất cả các phần tử trong vector đầu ra đều dương và tổng của chúng bằng 1, tức là,

p_i = exp(z_i) / Σ_{j=1}^K exp(z_j), (3)

trong đó z_i = w_i^⊺h + b_i.

Trong các mô hình phân loại sử dụng hàm mất mát cross-entropy với softmax, hàm chi phí và gradient được định nghĩa là:

L_{SCE}(x,y) = -Σ_{i=1}^K y_i log(p_i)
∂L_{SCE}/∂z = p - y, (4)

điều này cho thấy tất cả các mẫu đầu vào gọi các gradient không chỉ ảnh hưởng đến các vector trọng số lớp tương ứng của chúng, mà còn ảnh hưởng đến các vector khác.

Nhờ các gradient này, các bộ phân loại sử dụng hàm mất mát cross-entropy với softmax có thể đạt được margin tối đa trong quyết định. Tuy nhiên, những hiệu ứng kéo và đẩy của softmax [22] này cản trở việc duy trì bộ phân loại được đào tạo trên các nhiệm vụ trước đó trong học liên tục. Chúng tôi gọi dòng chảy của gradient từ một lớp mục tiêu về phía các lớp khác là nhiễu loạn liên-nhiệm vụ. Softmax che phủ tổng quát có thể giảm thiểu nhiễu loạn liên-nhiệm vụ bằng cách thay thế các logit từ mẫu đầu vào của các lớp cũ và mới, không thuộc nhiệm vụ hiện tại, thành một giá trị che phủ cụ thể, tức là,

L_{MSCE}(x,y) = -Σ_{i=1}^K y_i log(p_i^(t)), trong đó

p_i^(t) = {
exp(z_i) / [Σ_{j∈K^(t)} exp(z_j) + (K-|K^(t)|)·exp(m)], nếu i ∈ K^(t)
exp(m) / [Σ_{j∈K^(t)} exp(z_j) + (K-|K^(t)|)·exp(m)], ngược lại
}, (5)

trong đó |·| biểu thị cardinality của một tập hợp.

Phương trình 5 có nghĩa là các vector trọng số lớp ngoại trừ những vector của các lớp trong nhiệm vụ hiện tại có gradient bằng 0. Việc dừng gradient này duy trì các vector trọng số lớp trong các nhiệm vụ trước đó và tương lai. Kết quả là, tất cả các gradient được tính như sau:

∂L_{MSCE}/∂z_k = p_k^(t) - 1,
∂L_{MSCE}/∂z_i = p_k^(t), ∀i ∈ K_t\{k},
∂L_{MSCE}/∂z_j = 0, ∀j ∉ K_t. (6)

4 Kết quả Thực nghiệm

Thiết lập Chung. Chúng tôi tính toán mean và độ lệch chuẩn của kết quả thực nghiệm trong nhiều lần sử dụng các random seed khác nhau. Số lượng seed được sử dụng trong mỗi thí nghiệm sẽ được mô tả trong bảng tương ứng. † có nghĩa là thí nghiệm được tiến hành trong cùng thiết lập môi trường với chúng tôi.

Chỉ số Đánh giá. Hai chỉ số đánh giá được sử dụng phổ biến để đánh giá định lượng hiệu suất mô hình trong thiết lập học liên tục là Độ chính xác Trung bình Cuối cùng (A_T) và Quên Trung bình Cuối cùng (F_T). Theo [29], chúng tôi ký hiệu chúng như Phương trình 7.

A_T = (1/T) Σ_{t=1}^T a_{T,t},
F_T = (1/(T-1)) Σ_{t=1}^T max_{i∈{1,...T-1}}(a_{i,t} - a_{T,t}), (7)

trong đó a_{j,t} biểu thị độ chính xác kiểm tra trên nhiệm vụ T_t sau khi mô hình đã được đào tạo trên tất cả các nhiệm vụ cho đến nhiệm vụ T_j. Độ chính xác kiểm tra cao hơn trên mỗi nhiệm vụ sau đào tạo cho biết A_T cao hơn, trong khi việc giảm độ chính xác kiểm tra thấp hơn trên mỗi nhiệm vụ sau đào tạo cho biết F_T thấp hơn.

Tập dữ liệu. Chúng tôi theo [4] và tiến hành thí nghiệm so sánh trên các tập dữ liệu phân chia của MNIST, CIFAR-10, CIFAR100, và Tiny-ImageNet. Tập dữ liệu split-MNIST bao gồm 5 nhiệm vụ với 2 lớp được chia tuần tự cho mỗi nhiệm vụ, tức là nhiệm vụ T_0 có các chữ số 0 và 1 và nhiệm vụ cuối cùng T_4 có các chữ số 8 và 9. Tương tự, tập dữ liệu split-CIFAR10 được tạo thành 5 nhiệm vụ với 2 lớp. Đối với split-CIFAR100 và split-Tiny-ImageNet, chúng tôi đặt 10 nhiệm vụ với 10 lớp và 20 nhiệm vụ với 10 lớp, tương ứng.

Kiến trúc. Để so sánh thí nghiệm với [4] trong các điều kiện tương đương, chúng tôi theo [4] và tiến hành thí nghiệm bằng cách sử dụng mạng kết nối đầy đủ với hai lớp ẩn, mỗi lớp bao gồm 100 đơn vị ReLU cho split-MNIST. Chúng tôi cũng sử dụng các tập dữ liệu phân chia khác với ResNet18 [30].

4.1 Benchmark Học Liên tục

Chi tiết Thực hiện. Chúng tôi theo các thiết lập siêu tham số tốt nhất từ [4], nơi tìm kiếm siêu tham số toàn diện đã được tiến hành. Chúng tôi tóm tắt chúng trong Bảng 3 và phương pháp của chúng tôi sử dụng cùng thiết lập siêu tham số cho mỗi phương pháp. Kích thước batch được cố định cho mỗi tập dữ liệu: 10 trong tập dữ liệu split MNIST, 32 trong các tập dữ liệu split CIFAR-10, CIFAR-100, và Tiny-ImageNet.

Kết quả và Phân tích. Như được minh họa trong Bảng 1 và Bảng 2, phương pháp của chúng tôi đã vượt trội trong cả học tăng dần lớp và học tăng dần nhiệm vụ. Trong học tăng dần lớp, phương pháp của chúng tôi cũng cho thấy hiệu suất vượt trội trong hầu hết các trường hợp, đặc biệt trong các tình huống với kích thước buffer thấp và tập dữ liệu phức tạp hơn (tham khảo kích thước buffer được đặt thành 200 trong S-CIFAR100 và S-Tiny-ImageNet trong Bảng 1). Ngay cả trong học tăng dần nhiệm vụ, phương pháp phát lại che phủ luôn vượt trội trong tất cả các thí nghiệm. Điều này cho thấy rằng softmax che phủ hiệu quả duy trì thông tin đã được đào tạo trước đó bằng cách giảm thiểu nhiễu loạn liên-nhiệm vụ.

Chưng cất với Softmax Che phủ là Nguy hiểm. Như được thể hiện trong Bảng 1 và Bảng 2, việc sử dụng softmax che phủ với âm vô cực cải thiện đáng kể độ ổn định mô hình, đặc biệt khi được sử dụng với ER. Tuy nhiên, khi được sử dụng với chưng cất kiến thức, hiệu suất của hầu hết các trường hợp đã giảm so với baseline, thậm chí thấp hơn MSER, nơi không có nguy hiểm do chưng cất (tham khảo MSDER++(m=-∞)).

Kiểm soát Độ ổn định Mô hình bằng Điều chỉnh Giá trị Che phủ. Như được thể hiện trong Bảng 1, đặc biệt, nguy hiểm này nổi bật trong các thiết lập đơn giản và kích thước buffer thấp. Tuy nhiên, khi giá trị che phủ được đặt thành -1, hiệu suất của hầu hết các mô hình được cải thiện. Do đó, chúng tôi kết luận rằng việc kiểm soát giá trị che phủ hữu ích trong việc giảm thiểu sự gia tăng cực đoan trong độ ổn định mô hình.

4.2 Học Liên tục trong Kích thước Buffer Thấp

Chi tiết Thực hiện. Dựa trên những phát hiện từ kết quả của các thí nghiệm che phủ softmax trên benchmark học liên tục, người ta thấy rằng che phủ softmax hiệu quả hơn khi kích thước buffer thấp hơn. Chúng tôi chứng minh điều này bằng cách tiến hành nhiều thí nghiệm khác nhau với kích thước buffer bị hạn chế cực kỳ trên các tập dữ liệu split MNIST và CIFAR10. Kích thước buffer bộ nhớ tập đoạn đã được giảm xuống 10, 50, và 100, và mô hình được đào tạo có và không có softmax che phủ. Sau đó, kết quả được so sánh định lượng. Tất cả các thiết lập thí nghiệm, ngoại trừ kích thước buffer, đều tương đương với những thiết lập được sử dụng trong benchmark học liên tục.

Kết quả và Phân tích. Như được thể hiện trong Bảng 4, MSDER++(-1) vượt trội hơn DER++ và MSDER++(-∞) trong kích thước buffer 10 và 50 trên tập dữ liệu split MNIST. Tuy nhiên, MSDER++(-∞) liên tục cho thấy hiệu suất vượt trội trong các thí nghiệm khác. Điều này cho thấy rằng khi các mẫu phát lại không đủ để khôi phục kiến thức trước đó, việc tăng độ ổn định của mô hình là một phương pháp hiệu quả hơn để cải thiện hiệu suất trong các tình huống học liên tục so với việc chuyển kiến thức từ các nhiệm vụ trước đó.

4.3 Nghiên cứu Loại bỏ cho Giá trị Che phủ

Chi tiết Thực hiện. Để xác nhận rằng tác động của softmax che phủ tổng quát thực sự được điều chỉnh bằng cách kiểm soát giá trị che phủ, chúng tôi đã tiến hành thí nghiệm trên các tập dữ liệu split MNIST và CIFAR10 với kích thước buffer 200, 500, và 5120, sử dụng nhiều giá trị che phủ m khác nhau, trong đó m ∈ {-∞,-10^9,-10^6,-10^3,-10,-5,-2,-1,0}. Tất cả các thiết lập thí nghiệm, ngoại trừ giá trị che phủ, đều giống hệt với những thiết lập trong benchmark học liên tục.

Kết quả và Phân tích. Như được minh họa trong Hình 4d, softmax che phủ với kiến thức tối vượt trội hơn DER++ ở tất cả các giá trị che phủ trong khi MSDER++ cho thấy hiệu suất kém trong tất cả các giá trị che phủ, như được thể hiện trong Hình 4b và 4c. Tuy nhiên, ngay cả trong những trường hợp kém này, hiệu suất của mô hình với softmax che phủ tăng khi quy mô của giá trị che phủ giảm. Điều này cho thấy rằng việc kiểm soát giá trị che phủ hiệu quả trong việc điều chỉnh hiệu ứng đẩy của softmax. Hơn nữa, như được minh họa trong Hình 4a, 4e, và 4f, mô hình sử dụng softmax che phủ vượt trội hơn DER++ ở một số giá trị che phủ nhất định. Điều này có nghĩa là bằng cách xác định giá trị che phủ phù hợp cho mỗi thiết lập, hiệu suất của mô hình trong học liên tục có thể được cải thiện.

5 Kết luận và Nghiên cứu Tương lai

Trong bài báo này, chúng tôi làm sáng tỏ các hiệu ứng kéo và đẩy của hàm softmax khi được sử dụng với hàm mất mát cross-entropy trong các thiết lập học liên tục. Hiệu ứng đẩy của softmax làm trầm trọng thêm quên thảm khốc bằng cách chảy gradient về phía các vector trọng số lớp trong các nhiệm vụ trước đó. Để giải quyết vấn đề này, chúng tôi xem xét lại phương pháp che phủ softmax nổi tiếng để điều tra việc duy trì độ tin cậy chống lại hiệu ứng đẩy của softmax. Việc sử dụng softmax che phủ âm vô cực đã được tìm thấy là hiệu quả trong việc đạt được mục đích mong muốn bằng cách tạo ra gradient bằng không trên cả các lớp cũ và mới, do đó tăng độ ổn định mô hình. Tuy nhiên, người ta đã quan sát thấy rằng phương pháp này thể hiện hiệu suất kém khi chuyển kiến thức trước đó đến nhiệm vụ hiện tại. Để giải quyết vấn đề này, chúng tôi đề xuất một softmax che phủ tổng quát điều chỉnh hiệu ứng đẩy của softmax. Điều này đạt được bằng cách đặt giá trị mặt nạ thành âm vô cực hoặc giá trị thực, đồng thời ngăn chặn dòng chảy gradient đến các lớp cũ và mới. Hiệu quả của phương pháp của chúng tôi trong việc điều chỉnh sự đánh đổi giữa độ ổn định và tính dẻo dai của mô hình trong học liên tục được chứng minh, và nó cải thiện các phương pháp dựa trên phát lại trước đó trong benchmark học liên tục, ngay cả khi kích thước buffer của bộ nhớ tập đoạn được đặt ở các giá trị cực kỳ nhỏ. Trong nghiên cứu tương lai, phương pháp này có thể được mở rộng để cung cấp kiểm soát tinh vi hơn về mặt tính dẻo dai để giảm sự phụ thuộc vào bộ nhớ một cách hiệu quả hơn.

# 2311.18257.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/diffusion/2311.18257.pdf
# Kích thước file: 18616789 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Mô hình Khuếch tán Không có Attention
Jing Nathan Yan1∗, Jiatao Gu2∗, Alexander M. Rush1
1Cornell University,2Apple
{jy858, arush}@cornell.edu, jgu32@apple.com
Hình 1. Các mẫu được chọn lọc được tạo ra bởi D IFFU SSM có điều kiện lớp được huấn luyện trên ImageNet 256 ×256 và 512 ×512 độ phân giải.
Tóm tắt
Trong những tiến bộ gần đây về tạo ảnh có độ trung thực cao, Mô hình Xác suất Khuếch tán Khử nhiễu (DDPM) đã nổi lên như một nhân tố quan trọng. Tuy nhiên, việc ứng dụng chúng ở độ phân giải cao đặt ra những thách thức tính toán đáng kể. Các phương pháp hiện tại, như phân mảnh, đẩy nhanh quá trình trong kiến trúc UNet và Transformer nhưng phải đánh đổi khả năng biểu diễn. Giải quyết vấn đề này, chúng tôi giới thiệu Mô hình Không gian Trạng thái Khuếch tán (D IFFU SSM ), một kiến trúc thay thế cơ chế attention bằng backbone mô hình không gian trạng thái có khả năng mở rộng hơn. Cách tiếp cận này xử lý hiệu quả độ phân giải cao hơn mà không cần nén toàn cục, do đó bảo toàn biểu diễn ảnh chi tiết trong suốt quá trình khuếch tán. Tập trung vào kiến trúc hiệu quả FLOP trong huấn luyện khuếch tán của chúng tôi đánh dấu một bước tiến quan trọng. Đánh giá toàn diện trên cả bộ dữ liệu ImageNet và LSUN ở hai độ phân giải cho thấy DiffuSSM ngang bằng hoặc thậm chí vượt trội hơn các mô hình khuếch tán hiện có với mô-đun attention trong các chỉ số FID và Inception Score trong khi giảm đáng kể tổng sử dụng FLOP.
1. Giới thiệu
Tiến bộ nhanh chóng trong tạo ảnh được thúc đẩy bởi các mô hình xác suất khuếch tán khử nhiễu (DDPM) [ 7,20,37]. DDPM đặt quá trình tạo sinh như việc lặp lại khử nhiễu các biến tiềm ẩn, tạo ra các mẫu có độ trung thực cao khi thực hiện đủ các bước khử nhiễu. Khả năng nắm bắt các phân phối thị giác phức tạp làm cho DDPM trở nên hứa hẹn để thúc đẩy tổng hợp ảnh chân thực có độ phân giải cao.
Tuy nhiên, vẫn còn những thách thức tính toán đáng kể trong việc mở rộng DDPM lên độ phân giải cao hơn. Một điểm nghẽn chính là sự phụ thuộc vào self-attention [ 62] để tạo ra độ trung thực cao. Trong kiến trúc U-Net, điểm nghẽn này xuất phát từ việc kết hợp ResNet [ 17] với các lớp attention [ 48,61]. DDPM vượt trội hơn mạng đối nghịch tạo sinh (GAN) nhưng yêu cầu các lớp multi-head attention [ 7,37]. Trong kiến trúc Transformer [ 62], attention là thành phần trung tâm, và do đó rất quan trọng để đạt được kết quả tổng hợp ảnh hiện đại gần đây [ 1,38]. Trong cả hai kiến trúc này, độ phức tạp của attention, bậc hai theo độ dài, trở nên cấm khi làm việc với ảnh độ phân giải cao.
Chi phí tính toán đã thúc đẩy việc sử dụng các phương pháp nén biểu diễn. Kiến trúc độ phân giải cao thường sử dụng phân mảnh [ 1,38], hoặc độ phân giải đa tỷ lệ [ 20,22,37]. Phân mảnh tạo ra các biểu diễn thô sơ giảm tính toán với chi phí giảm thông tin không gian tần số cao quan trọng và tính toàn vẹn cấu trúc [ 1,38,51]. Độ phân giải đa tỷ lệ, trong khi làm giảm tính toán tại các lớp attention, có thể giảm chi tiết không gian thông qua lấy mẫu xuống [ 68] và có thể gây ra các tạo tác [65] khi áp dụng lấy mẫu lên.
Mô hình Không gian Trạng thái Khuếch tán ( D IFFU SSM ), là một kiến trúc khuếch tán không có attention, được thể hiện trong Hình 2, nhằm tránh các vấn đề của việc áp dụng attention cho tổng hợp ảnh độ phân giải cao. D IFFU SSM sử dụng backbone mô hình không gian trạng thái có cổng (SSM) trong quá trình khuếch tán. Công trình trước đây đã chỉ ra rằng các mô hình chuỗi dựa trên SSM là một mô hình chuỗi neural mục đích chung hiệu quả [ 14]. Bằng cách sử dụng kiến trúc này, chúng tôi có thể kích hoạt lõi SSM xử lý các biểu diễn ảnh tinh tế hơn bằng cách loại bỏ phân mảnh toàn cục hoặc các lớp đa tỷ lệ. Để cải thiện thêm hiệu quả, D IFFU SSM sử dụng kiến trúc đồng hồ cát cho các thành phần dày đặc của mạng. Cùng nhau, những cách tiếp cận này nhắm đến độ phức tạp tiệm cận của độ dài cũng như hiệu quả thực tế trong phần theo vị trí của mạng.
Chúng tôi xác thực D IFFU SSM trên các độ phân giải khác nhau. Thí nghiệm trên ImageNet cho thấy cải thiện nhất quán trong FID, sFID, và Inception Score so với các cách tiếp cận hiện có trong các độ phân giải khác nhau với ít Gflops tổng hơn.
2. Công trình liên quan
Mô hình Khuếch tán Mô hình Xác suất Khuếch tán Khử nhiễu (DDPM) [ 20,22,37,54] là một tiến bộ trong họ mô hình khuếch tán. Trước đây, Mạng Đối nghịch Tạo sinh (GAN) [ 12] được ưa chuộng cho các tác vụ tạo sinh. Các mô hình khuếch tán và tạo sinh dựa trên điểm [ 24,56–59] đã cho thấy cải thiện đáng kể, đặc biệt trong các tác vụ tạo ảnh [ 44–46]. Các cải tiến chính trong DDPM phần lớn được thúc đẩy bởi phương pháp lấy mẫu cải tiến [ 20,28,37], và việc tích hợp hướng dẫn không phân loại [ 19]. Ngoài ra, Song et al. [55] đã đề xuất một thủ tục lấy mẫu nhanh hơn được gọi là Mô hình Khuếch tán Khử nhiễu Ẩn (DDIM). Mô hình hóa không gian tiềm ẩn là một kỹ thuật cốt lõi khác trong các mô hình tạo sinh sâu. Bộ mã hóa tự biến đổi (V AE) [ 30] tiên phong học các không gian tiềm ẩn với kiến trúc bộ mã hóa-giải mã để tái tạo. Ý tưởng nén tương tự được áp dụng trong các mô hình khuếch tán như Mô hình Khuếch tán Tiềm ẩn (LDM) gần đây [ 45] giữ chất lượng mẫu hiện đại bằng cách huấn luyện các mô hình tạo sinh sâu để đảo ngược quá trình tham nhũng nhiễu trong không gian tiềm ẩn khi lần đầu được đề xuất. Ngoài ra, các cách tiếp cận gần đây cũng phát triển các thủ tục huấn luyện có mặt nạ, bổ sung các mục tiêu huấn luyện khử nhiễu với tái tạo token có mặt nạ [ 10,69]. Công trình của chúng tôi được xây dựng cơ bản trên DDPM hiện có, đặc biệt là mô hình hướng dẫn không phân loại.
Kiến trúc cho Mô hình Khuếch tán Các mô hình khuếch tán sớm sử dụng kiến trúc kiểu U-Net [ 7,20]. Các công trình tiếp theo tăng cường U-Net với các kỹ thuật như nhiều lớp attention hơn ở mức độ phân giải đa tỷ lệ [ 7,37], kết nối dư [ 2], và chuẩn hóa [ 40,66]. Tuy nhiên, U-Net gặp thách thức trong việc mở rộng lên độ phân giải cao do chi phí tính toán ngày càng tăng của cơ chế attention [ 52]. Gần đây, vision transformer (ViT) [ 8] đã nổi lên như một kiến trúc thay thế do tính chất mở rộng mạnh mẽ và khả năng mô hình hóa tầm xa chứng minh rằng bias quy nạp tích chập không phải lúc nào cũng cần thiết. Transformer khuếch tán [ 1,38] đã thể hiện kết quả hứa hẹn. Các kiến trúc lai CNN-transformer khác được đề xuất [ 32] để cải thiện tính ổn định huấn luyện. Công trình của chúng tôi phù hợp với việc khám phá các mô hình chuỗi và các lựa chọn thiết kế liên quan để tạo ra ảnh chất lượng cao nhưng tập trung vào kiến trúc hoàn toàn không có attention.
Kiến trúc Chuỗi Tầm xa Hiệu quả Kiến trúc transformer tiêu chuẩn sử dụng attention để hiểu tương tác của từng token riêng lẻ trong một chuỗi. Tuy nhiên, nó gặp thách thức khi mô hình hóa các chuỗi dài do yêu cầu tính toán bậc hai. Một số phương pháp xấp xỉ attention [ 23,33,53,60,64] đã được giới thiệu để xấp xỉ self-attention trong không gian dưới bậc hai. Mega [ 34] kết hợp trung bình động mũ với đơn vị attention đơn giản hóa, vượt trội hơn hiệu suất của các baseline transformer. Mạo hiểm vượt ra ngoài kiến trúc transformer truyền thống, các nhà nghiên cứu cũng đang khám phá các mô hình thay thế thành thạo trong việc xử lý các chuỗi dài. Kiến trúc dựa trên mô hình không gian trạng thái (SSM) [ 14–16] đã mang lại những tiến bộ đáng kể so với các phương pháp hiện đại trên benchmark LRA và âm thanh [ 11]. Hơn nữa, Dao et al. [5], Peng et al. [39], Poli et al. [42], Qin et al. [43] đã chứng minh tiềm năng của kiến trúc không có attention trong việc đạt được hiệu suất đáng khen ngợi trong mô hình hóa ngôn ngữ. Công trình của chúng tôi lấy cảm hứng từ xu hướng phát triển này của việc chuyển hướng từ thiết kế lấy attention làm trung tâm và chủ yếu sử dụng backbone của SSM.
3. Kiến thức chuẩn bị
3.1. Mô hình Khuếch tán
Mô hình Xác suất Khuếch tán Khử nhiễu (DDPM) [ 20] là một loại mô hình tạo sinh lấy mẫu ảnh bằng cách lặp lại khử nhiễu một đầu vào nhiễu. Nó bắt đầu từ một quá trình ngẫu nhiên trong đó một ảnh ban đầu x0 dần dần bị tham nhũng bởi nhiễu, biến đổi nó thành một trạng thái đơn giản hơn, bị chi phối bởi nhiễu. Quá trình tạo nhiễu tiến này có thể được biểu diễn như sau:
q(x1:T|x0) =TY
t=1q(xt|xt−1), (1)
q(xt|x0) =N(xt;√¯αtx0,(1−¯αt)I), (2)
trong đó x1:T biểu thị một chuỗi ảnh nhiễu từ thời gian t= 1 đến t=T. Sau đó, DDPM học quá trình nghịch đảo phục hồi ảnh gốc sử dụng µθ và Σθ đã học:
pθ(xt−1|xt) =N(xt−1;µθ(xt),Σθ(xt)), (3)
trong đó θ là các tham số của bộ khử nhiễu, và được huấn luyện để tối đa hóa cận dưới biến phân [ 54] trên log-likelihood của dữ liệu quan sát x0:max θ−logpθ(x0|x1)+P
tDKL(q∗(xt−1|xt, x0)||pθ(xt−1|xt)). Để đơn giản hóa quá trình huấn luyện, các nhà nghiên cứu tham số hóa lại µθ như một hàm của nhiễu dự đoán εθ và tối thiểu hóa lỗi bình phương trung bình giữa εθ(xt) và nhiễu Gaussian thực εt:
minθ||εθ(xt)−εt||2
2. Tuy nhiên, để huấn luyện một mô hình khuếch tán có thể học một hiệp phương sai quá trình nghịch đảo biến thiên Σθ, chúng ta cần tối ưu hóa L đầy đủ. Trong công trình này, chúng tôi theo DiT [ 38] để huấn luyện mạng nơi chúng tôi sử dụng mục tiêu đơn giản để huấn luyện mạng dự đoán nhiễu εθ và sử dụng mục tiêu đầy đủ để huấn luyện mạng dự đoán hiệp phương sai Σθ. Sau khi huấn luyện xong, chúng tôi theo quy trình lấy mẫu ngẫu nhiên để tạo ảnh từ εθ và Σθ đã học.
3.2. Kiến trúc cho Mô hình Khuếch tán
Chúng tôi xem xét các phương pháp tham số hóa µθ ánh xạ RH×W×C→RH×W×C trong đó H, W, C là chiều cao, chiều rộng, và kích thước của dữ liệu. Đối với các tác vụ tạo ảnh, chúng có thể là pixel thô, hoặc một số biểu diễn không gian tiềm ẩn được trích xuất từ bộ mã hóa V AE đã được huấn luyện trước [ 45]. Khi tạo ảnh độ phân giải cao, thậm chí trong không gian tiềm ẩn, H và W lớn, và yêu cầu kiến trúc chuyên biệt để hàm này có thể xử lý được.
U-Net với Self-attention Kiến trúc U-Net [ 20,22, 37] sử dụng tích chập và lấy mẫu phụ ở nhiều độ phân giải để xử lý đầu vào độ phân giải cao, trong đó các lớp self-attention bổ sung được sử dụng tại mỗi khối độ phân giải thấp. Theo hiểu biết tốt nhất của chúng tôi, không có mô hình khuếch tán dựa trên U-Net nào đạt được hiệu suất hiện đại mà không sử dụng self-attention. Gọi t1, . . . t T là một chuỗi bản đồ đặc trưng độ phân giải thấp hơn được tạo bởi lấy mẫu xuống ảnh.1 Tại mỗi tỷ lệ, một ResNet [ 17] được áp dụng cho RHt×Wt×Ct. Chúng sau đó được lấy mẫu lên và kết hợp thành đầu ra cuối cùng. Để tăng cường hiệu suất của U-Net trong tạo ảnh, các lớp attention được tích hợp tại các độ phân giải thấp nhất. Bản đồ đặc trưng được làm phẳng thành một chuỗi các vector HtWt. Ví dụ, khi xem xét H= 256 ×W= 256 giảm xuống các lớp attention của 16×16 và 32×32, dẫn đến các chuỗi có độ dài 256 và 1024 tương ứng. Áp dụng attention sớm hơn cải thiện độ chính xác với chi phí tính toán lớn hơn. Gần đây hơn, [ 22,41] đã chỉ ra rằng sử dụng nhiều lớp self-attention hơn ở độ phân giải thấp là chìa khóa của việc mở rộng các mô hình khuếch tán dựa trên U-Net độ phân giải cao.
Transformer với Phân mảnh Như đã đề cập ở trên, việc ngữ cảnh hóa toàn cục sử dụng self-attention là chìa khóa cho các mô hình khuếch tán hoạt động tốt. Do đó, cũng tự nhiên khi xem xét kiến trúc hoàn toàn dựa trên self-attention. Kiến trúc Transformer sử dụng attention xuyên suốt, nhưng xử lý ảnh độ phân giải cao thông qua phân mảnh [ 8]. Cho kích thước mảnh P, transformer phân chia ảnh thành các mảnh P×P tạo ra biểu diễn RH/P×W/P×C′ mới. Kích thước mảnh P này trực tiếp ảnh hưởng đến độ chi tiết hiệu quả của ảnh và nhu cầu tính toán tiếp theo. Để đưa các mảnh vào Transformer, ảnh được làm phẳng và một lớp nhúng tuyến tính được áp dụng để thu được một chuỗi (HW)/P2 vector ẩn [ 1,8,22,38]. Do bước nhúng này, chiếu từ C′ đến kích thước mô hình, các mảnh lớn có nguy cơ mất chi tiết không gian và mô hình hóa không hiệu quả các mối quan hệ cục bộ do sự chồng chéo giảm. Tuy nhiên, phân mảnh có lợi ích giảm chi phí bậc hai của attention cũng như các mạng feed-forward trong Transformer.
4. D IFFU SSM
Mục tiêu của chúng tôi là thiết kế một kiến trúc khuếch tán học các tương tác tầm xa ở độ phân giải cao mà không yêu cầu "giảm độ dài" như phân mảnh. Tương tự như DiT, cách tiếp cận hoạt động bằng cách làm phẳng ảnh và xử lý nó như một bài toán mô hình hóa chuỗi. Tuy nhiên, không giống như Transformer, cách tiếp cận này sử dụng tính toán dưới bậc hai trong độ dài của chuỗi này.
4.1. Mô hình Không gian Trạng thái (SSM)
SSM là một lớp kiến trúc xử lý các chuỗi thời gian rời rạc [14]. Các mô hình hoạt động như một mạng nơ-ron tái phát tuyến tính (RNN) xử lý một chuỗi đầu vào của các số vô hướng u1, . . . u L để đầu ra y1, . . . y L với phương trình sau,
xk=Axk−1+Buk, yk=Cxk.
Trong đó A∈RN×N,B∈RN×1,C∈R1×N. Lợi ích chính của cách tiếp cận này, so với các kiến trúc thay thế như Transformer và RNN tiêu chuẩn, là cấu trúc tuyến tính cho phép nó được triển khai sử dụng tích chập dài thay vì tái phát. Cụ thể, y có thể được tính từ u với FFT mang lại độ phức tạp O(LlogL), cho phép nó được áp dụng cho các chuỗi dài hơn đáng kể. Khi xử lý đầu vào vector, chúng ta có thể xếp chồng D SSM khác nhau và áp dụng D FFT batch.
Tuy nhiên, một RNN tuyến tính, tự nó, không phải là một mô hình chuỗi hiệu quả. Thông tin chính từ công trình trước đây là nếu các giá trị thời gian rời rạc A,B,C được dẫn xuất từ các mô hình không gian trạng thái thời gian liên tục thích hợp, cách tiếp cận RNN tuyến tính có thể được làm ổn định và hiệu quả [ 13]. Do đó, chúng tôi học một tham số hóa SSM thời gian liên tục A,B,C cũng như tỷ lệ rời rạc hóa ∆, được sử dụng để tạo ra các tham số thời gian rời rạc cần thiết. Phiên bản gốc của việc chuyển đổi này khó thực hiện, tuy nhiên gần đây các nhà nghiên cứu [ 15,16] đã giới thiệu các phiên bản chéo hóa đơn giản hóa của mạng nơ-ron SSM đạt được kết quả tương đương với một xấp xỉ đơn giản của tham số hóa thời gian liên tục. Chúng tôi sử dụng một trong số này, S4D [ 15], làm mô hình backbone.
Giống như với RNN tiêu chuẩn, SSM có thể được làm hai chiều bằng cách nối các đầu ra của hai lớp SSM và truyền chúng qua MLP để tạo ra đầu ra L×2D. Ngoài ra, công trình trước đây cho thấy rằng lớp này có thể được kết hợp với cổng nhân để tạo ra lớp SSM Hai chiều cải tiến [ 35,63] như một phần của bộ mã hóa, đây là động lực cho kiến trúc của chúng tôi.
4.2. Khối D IFFU SSM
Thành phần trung tâm của D IFFU SSM là một SSM hai chiều có cổng, nhằm tối ưu hóa việc xử lý các chuỗi dài. Để tăng cường hiệu quả, chúng tôi kết hợp kiến trúc đồng hồ cát trong các lớp MLP. Thiết kế này thay phiên giữa mở rộng và co lại độ dài chuỗi xung quanh SSM Hai chiều, trong khi cụ thể giảm độ dài chuỗi trong MLP. Kiến trúc mô hình hoàn chỉnh được thể hiện trong Hình 2.
Cụ thể, mỗi lớp đồng hồ cát nhận một chuỗi đầu vào được rút ngắn, làm phẳng I∈RJ×D trong đó M=L/J là tỷ lệ giảm và tăng tỷ lệ. Cùng lúc đó, toàn bộ khối bao gồm SSM hai chiều được tính toán với độ dài gốc để tận dụng đầy đủ các ngữ cảnh toàn cục. Chúng tôi sử dụng σ để biểu thị các hàm kích hoạt. Chúng tôi tính toán như sau cho l∈ {1. . . L} với j=⌊l/M⌋, m=lmodM, D m=
2D/M .
Ul=σ(W↑
kσ(W0Ij) ∈RL×D
Y=Bidirectional-SSM (U) ∈RL×2D
I′
j,Dmk:Dm(k+1)=σ(W↓
kYl) ∈RJ×2D
Oj=W3(σ(W2I′
j)⊙σ(W1Ij)) ∈RJ×D
Chúng tôi tích hợp khối Gated SSM này trong mỗi lớp với một kết nối bỏ qua. Ngoài ra, theo công trình trước đây, chúng tôi tích hợp một sự kết hợp của nhãn lớp y∈RL×1 và timestep t∈RL×1 tại mỗi vị trí, như minh họa trong Hình 2.
Tham số Số lượng tham số trong khối DIFFUSSM bị chi phối bởi các biến đổi tuyến tính, W, chúng chứa 9D2+ 2MD2 tham số. Với M= 2 điều này cho 13D2 tham số. Khối transformer DiT có 12D2 tham số trong lớp transformer cốt lõi của nó; tuy nhiên, kiến trúc DiT có nhiều tham số hơn trong các thành phần lớp khác (adaptive layer norm). Chúng tôi khớp các tham số trong các thí nghiệm bằng cách sử dụng một lớp D IFFU SSM bổ sung.
FLOP Hình 3 so sánh Gflops giữa DiT và D IFFU SSM. Tổng Flops trong một lớp của D IFFU SSM là 13L
MD2+LD2+α2LlogLD trong đó α đại diện cho một hằng số cho việc triển khai FFT. Với M= 2 và lưu ý rằng các lớp tuyến tính chi phối tính toán, điều này cho khoảng 7.5LD2 Gflops. Để so sánh, nếu thay vì sử dụng SSM, chúng tôi đã sử dụng self-attention với độ dài đầy đủ với kiến trúc đồng hồ cát này, chúng tôi sẽ có thêm 2DL2 Flops.
Xem xét hai tình huống thí nghiệm của chúng tôi: 1) D≈ L= 1024 điều này sẽ cho thêm 2LD2 Flops, 2) 4D≈L= 4096 điều này sẽ cho 8LD2 Flops và tăng đáng kể chi phí. Vì chi phí cốt lõi tại SSM Hai chiều nhỏ so với việc sử dụng attention, và kết quả là sử dụng kiến trúc đồng hồ cát sẽ không hoạt động cho các mô hình dựa trên attention. DiT tránh những vấn đề này bằng cách sử dụng phân mảnh như đã thảo luận trước đây, với chi phí nén biểu diễn.
5. Nghiên cứu Thí nghiệm
5.1. Thiết lập Thí nghiệm
Bộ dữ liệu Các thí nghiệm chính của chúng tôi được thực hiện trên ImageNet[ 6]2 và LSUN[ 67]3. Cụ thể, chúng tôi sử dụng bộ dữ liệu ImageNet-1k với 1.28 triệu ảnh và 1000 lớp đối tượng. Đối với bộ dữ liệu LSUN, chúng tôi chọn hai danh mục: Church (126k ảnh) và Bed (3M ảnh), và huấn luyện các mô hình không điều kiện riêng biệt cho chúng. Các thí nghiệm của chúng tôi được thực hiện với bộ dữ liệu ImageNet ở độ phân giải 256×256 và 512×512, và LSUN ở độ phân giải 256×256. Chúng tôi sử dụng mã hóa không gian tiềm ẩn [ 45] cho kích thước hiệu quả 32×32 và 64×64 với L= 1024 và L= 4096 tương ứng. Chúng tôi cũng bao gồm ImageNet không gian pixel ở độ phân giải 128×128 trong tài liệu bổ sung nơi L= 16,384.
Giải mã Tuyến tính và Khởi tạo Trọng số Sau khối cuối cùng của Gated SSM, mô hình giải mã biểu diễn ảnh tuần tự về kích thước không gian gốc để đầu ra dự đoán nhiễu và dự đoán hiệp phương sai chéo. Tương tự như Gao et al. [10], Peebles và Xie [38], chúng tôi sử dụng bộ giải mã tuyến tính và sau đó sắp xếp lại các biểu diễn để có được kích thước gốc. Chúng tôi theo DiT để sử dụng cách tiếp cận khởi tạo lớp tiêu chuẩn từ ViT [8].
Cấu hình Huấn luyện Chúng tôi theo cùng công thức huấn luyện từ DiT [ 38] để duy trì một thiết lập giống hệt nhau trên tất cả các mô hình. Chúng tôi cũng chọn theo tài liệu hiện có để giữ một trung bình động mũ (EMA) của trọng số mô hình với một sự suy giảm không đổi. Các bộ mã hóa V AE có sẵn từ4 được sử dụng, với các tham số được cố định trong quá trình huấn luyện. DIFFU SSM -XL của chúng tôi sở hữu khoảng 673M tham số và bao gồm 29 lớp khối Bidirectional Gated SSM với kích thước mô hình D= 1152. Giá trị này tương tự như DiT-XL. Huấn luyện mô hình của chúng tôi sử dụng cách tiếp cận huấn luyện độ chính xác hỗn hợp để giảm thiểu chi phí tính toán. Chúng tôi tuân thủ cấu hình giống hệt nhau của khuếch tán như được nêu trong ADM [7], bao gồm lịch trình phương sai tuyến tính của chúng, nhúng nhãn thời gian và lớp, cũng như tham số hóa hiệp phương sai Σθ của chúng. Thêm chi tiết có thể tìm thấy trong Phụ lục.
Đối với tạo ảnh không điều kiện, DiT không báo cáo kết quả và chúng tôi không thể so sánh với DiT trong cùng thiết lập huấn luyện. Thay vào đó, mục tiêu của chúng tôi so sánh DIFFUSSM, với một chế độ huấn luyện có thể so sánh với LDM[ 45] có thể tạo ra ảnh chất lượng cao cho các danh mục trong bộ dữ liệu LSUN. Để thích ứng mô hình với bối cảnh không điều kiện, chúng tôi đã loại bỏ nhúng nhãn lớp.
Chỉ số Để định lượng hiệu suất tạo ảnh của mô hình, chúng tôi sử dụng Khoảng cách Inception Frechet (FID) [ 18], một chỉ số phổ biến đo lường chất lượng ảnh được tạo ra. Chúng tôi theo quy ước khi so sánh với các công trình trước đây và báo cáo FID-50K sử dụng 250 bước lấy mẫu DDPM. Chúng tôi cũng báo cáo điểm sFID [ 36], được thiết kế để mạnh mẽ hơn với biến dạng không gian trong ảnh được tạo ra. Để có cái nhìn toàn diện hơn, chúng tôi cũng trình bày Điểm Inception [ 47] và Precision/Recall [ 31] như các chỉ số bổ sung. Lưu ý rằng không kết hợp hướng dẫn không phân loại trừ khi được đề cập rõ ràng (chúng tôi sử dụng −G cho việc sử dụng hướng dẫn không phân loại hoặc nêu rõ ràng CFG).
Triển khai và Phần cứng Chúng tôi triển khai tất cả các mô hình trong Pytorch và huấn luyện chúng sử dụng NVIDIA A100. DIFFU SSM -XL, mô hình tính toán thâm dụng nhất của chúng tôi huấn luyện trên 8 GPU A100 80GB với kích thước batch toàn cục là 256. Thêm chi tiết tính toán và tốc độ có thể tìm thấy trong tài liệu bổ sung.
5.2. Baseline
Chúng tôi so sánh với một tập hợp các mô hình tốt nhất trước đây, bao gồm: các cách tiếp cận kiểu GAN trước đây đạt được kết quả hiện đại, kiến trúc UNet được huấn luyện với biểu diễn không gian pixel, và Transformer hoạt động trong không gian tiềm ẩn. Thêm chi tiết có thể tìm thấy trong Bảng 5.3. Mục tiêu của chúng tôi là so sánh, thông qua một quá trình khử nhiễu tương tự, hiệu suất của mô hình của chúng tôi so với các baseline khác. Một số nghiên cứu gần đây [10,69] tập trung vào tạo ảnh ở mức độ phân giải 256×256 đã kết hợp dự đoán token có mặt nạ với các mục tiêu huấn luyện DDPM hiện có để thúc đẩy hiện đại. Tuy nhiên, những công trình này trực giao với so sánh chính của chúng tôi, vì vậy chúng tôi không bao gồm chúng trong Bảng 1. Đối với bộ dữ liệu LSUN, chúng tôi thấy các phương pháp dựa trên DDPM hiện có không vượt trội hơn các phương pháp dựa trên GAN. Mục tiêu của chúng tôi là so sánh trong khung DDPM thay vì cạnh tranh với các phương pháp hiện đại.
5.3. Kết quả Thí nghiệm
Tạo Ảnh Có Điều kiện Lớp Chúng tôi so sánh DIFFUSSM với các mô hình tạo sinh có điều kiện lớp hiện đại, như được mô tả trong Bảng 1. Khi hướng dẫn không phân loại không được sử dụng, DIFFU SSM vượt trội hơn các mô hình khuếch tán khác trong cả FID và sFID, giảm điểm tốt nhất từ các mô hình khuếch tán tiềm ẩn không phân loại trước đây từ 9.62 xuống 9.07, trong khi sử dụng ~3× ít bước huấn luyện hơn. Về Tổng Gflops của huấn luyện, mô hình không nén của chúng tôi mang lại 20% giảm tổng Gflops so với DiT. Khi hướng dẫn không phân loại được kết hợp, các mô hình của chúng tôi đạt được điểm sFID tốt nhất trong tất cả các mô hình dựa trên DDPM, vượt trội hơn các chiến lược hiện đại khác, chứng minh ảnh được tạo ra bởi DIFFU SSM mạnh mẽ hơn với biến dạng không gian. Về điểm FID, DIFFU SSM vượt trội hơn tất cả các mô hình khi sử dụng hướng dẫn không phân loại, và duy trì một khoảng cách khá nhỏ (0.01) so với DiT. Lưu ý rằng DIFFUSSM được huấn luyện với 30% ít Gflops tổng hơn đã vượt trội hơn DiT khi không áp dụng hướng dẫn không phân loại.
U-ViT [ 1] là một kiến trúc dựa trên transformer khác nhưng sử dụng kiến trúc dựa trên UNet với các kết nối bỏ qua dài giữa các khối. U-ViT sử dụng ít FLOP hơn và mang lại hiệu suất tốt hơn ở độ phân giải 256 ×256, nhưng điều này không đúng với bộ dữ liệu 512 ×512. Vì so sánh chính của chúng tôi là với DiT, chúng tôi không áp dụng kết nối bỏ qua dài này để so sánh công bằng. Chúng tôi thừa nhận rằng việc thích ứng ý tưởng của U-Vit có thể có lợi cho cả DiT và DIFFU SSM. Chúng tôi để việc xem xét này cho công trình tương lai.
Chúng tôi tiếp tục so sánh trên benchmark độ phân giải cao hơn sử dụng hướng dẫn không phân loại. Kết quả từ DIFFUSSM ở đây tương đối mạnh và gần một số mô hình độ phân giải cao hiện đại, đánh bại tất cả các mô hình nhưng DiT về sFID và đạt được điểm FID tương đương. DIFFUSSM được huấn luyện trên 302M ảnh, thấy 40% ít ảnh hơn và sử dụng 25% ít Gflops hơn so với DiT.
Tạo Ảnh Không Điều kiện Chúng tôi so sánh khả năng tạo ảnh không điều kiện của mô hình với các baseline hiện có. Kết quả được thể hiện trong Bảng 2. Phát hiện của chúng tôi cho thấy DIFFU SSM đạt được điểm FID tương đương với LDM (với khoảng cách −0.08 và 0.07) với ngân sách huấn luyện tương đương. Kết quả này làm nổi bật khả năng ứng dụng của DIFFU SSM trên các benchmark khác nhau và các tác vụ khác nhau. Tương tự như LDM, cách tiếp cận của chúng tôi không vượt trội hơn ADM cho LSUN-Bedrooms vì chúng tôi chỉ sử dụng 25% tổng ngân sách huấn luyện như ADM. Đối với tác vụ này, các mô hình GAN tốt nhất vượt trội hơn khuếch tán như một lớp mô hình.
6. Phân tích
Ảnh Bổ sung Các ảnh bổ sung được tạo ra bởi DIFFUSSM được bao gồm từ Hình 7 đến Hình 14.
Mô hình FID↓ P↑ FID↓ P↑
LSUN-Church LSUN-Bedroom
ImageBART [9] 7.32 5.51 -
PGGAN [25] 6.42 - - -
StyleGAN [26] 4.21 - 2.35 0.59
StyleGAN2 [27] 3.93 0.39 - -
ProjGAN [49] 1.59 0.61 1.52 0.61
DDPM [20] 7.89 - 4.90 -
UDM [29] - - 4.57 -
ADM [7] - - 1.90 0.66
LDM [45] 4.02 0.64 2.95 0.66
DIFFU SSM 3.94 0.64 3.02 0.62
Bảng 2. Đánh giá tạo ảnh không điều kiện của DIFFUSSM và các cách tiếp cận hiện có trên LSUN-Church và LSUN-Bedroom ở 256×256.
Mở rộng Mô hình Chúng tôi huấn luyện ba kích thước DIFFU SSM khác nhau để hiệu chỉnh hiệu suất được tạo ra bởi việc mở rộng mô hình. Chúng tôi tính toán FID-50k cho các checkpoint của 400k bước đầu tiên. Kết quả được thể hiện trong Hình 6 (Trái). Chúng tôi thấy rằng tương tự như các mô hình DiT, các mô hình lớn sử dụng FLOP hiệu quả hơn và mở rộng DIFFU SSM sẽ cải thiện FID ở tất cả các giai đoạn huấn luyện.
Tác động của Đồng hồ cát Chúng tôi huấn luyện mô hình với các thiết lập lấy mẫu khác nhau để đánh giá tác động của nén trong không gian tiềm ẩn: sử dụng tỷ lệ lấy mẫu xuống M= 2 (mô hình thường xuyên của chúng tôi), và một mô hình khác với P= 2 áp dụng kích thước mảnh bằng 2, tương tự như những gì DiT đã làm. Chúng tôi tính toán FID-50k của chúng cho 400k bước đầu tiên và vẽ nó trên thang log. Kết quả được thể hiện trong Hình 6 (Phải). Chúng tôi thấy rằng mô hình của chúng tôi cho điểm FID tốt hơn so với khi áp dụng phân mảnh, và khoảng cách giữa hai cái cũng mở rộng khi số bước huấn luyện tăng. Điều này cho thấy rằng việc nén thông tin có thể làm hại khả năng tạo ra ảnh chất lượng cao của mô hình.
Phân tích Định tính Mục tiêu của DIFFU SSM là tránh nén các biểu diễn ẩn. Để kiểm tra xem điều này có lợi hay không, chúng tôi so sánh ba biến thể của DIFFU SSM với tỷ lệ giảm tỷ lệ M và kích thước mảnh P khác nhau. Chúng tôi huấn luyện tất cả ba biến thể mô hình trong 400K bước với cùng kích thước batch và các siêu tham số khác. Khi tạo ảnh, chúng tôi sử dụng nhiễu ban đầu giống hệt nhau và lịch trình nhiễu trên các nhãn lớp. Kết quả được trình bày trong Hình 5. Đáng chú ý, việc loại bỏ phân mảnh tăng cường độ mạnh mẽ trong tái tạo không gian ở cùng giai đoạn huấn luyện. Điều này dẫn đến cải thiện chất lượng thị giác, có thể so sánh với các mô hình không nén, nhưng với tính toán giảm.
7. Kết luận
Chúng tôi giới thiệu DIFFUSSM, một kiến trúc cho các mô hình khuếch tán không yêu cầu sử dụng Attention. Cách tiếp cận này có thể xử lý các trạng thái ẩn tầm xa mà không yêu cầu nén biểu diễn. Kết quả cho thấy rằng kiến trúc này có thể đạt được hiệu suất tốt hơn so với các mô hình DiT sử dụng ít Gflops hơn ở 256x256 và kết quả cạnh tranh ở độ phân giải cao hơn thậm chí với ít huấn luyện hơn. Công trình có một số hạn chế còn lại. Thứ nhất, nó tập trung vào tạo ảnh (không) có điều kiện thay vì các cách tiếp cận text-to-image đầy đủ. Ngoài ra, có một số cách tiếp cận gần đây như huấn luyện ảnh có mặt nạ có thể cải thiện mô hình. Tuy nhiên, mô hình này cung cấp một cách tiếp cận thay thế để học các mô hình khuếch tán hiệu quả ở quy mô lớn. Chúng tôi tin rằng việc loại bỏ điểm nghẽn attention sẽ mở ra khả năng ứng dụng trong các lĩnh vực khác yêu cầu khuếch tán tầm xa, ví dụ như âm thanh, video, hoặc mô hình hóa 3D có độ trung thực cao.
Tài liệu tham khảo
[1]Fan Bao, Shen Nie, Kaiwen Xue, Yue Cao, Chongxuan Li, Hang Su, and Jun Zhu. All are worth words: A vit backbone for diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 22669–22679, 2023.
[2]Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high fidelity natural image synthesis. arXiv preprint arXiv:1809.11096 , 2018.
[3]Huiwen Chang, Han Zhang, Lu Jiang, Ce Liu, and William T Freeman. Maskgit: Masked generative image transformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 11315–11325, 2022.
[4]Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, and Mubarak Shah. Diffusion models in vision: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence , 2023.
[5]Tri Dao, Daniel Y Fu, Khaled K Saab, Armin W Thomas, Atri Rudra, and Christopher Ré. Hungry hungry hippos: Towards language modeling with state space models. arXiv preprint arXiv:2212.14052 , 2022.
[6]Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition , pages 248–255. Ieee, 2009.
[7]Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. Advances in neural information processing systems , 34:8780–8794, 2021.
[8]Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929 , 2020.
[9]Patrick Esser, Robin Rombach, Andreas Blattmann, and Bjorn Ommer. Imagebart: Bidirectional context with multinomial diffusion for autoregressive image synthesis. Advances in neural information processing systems , 34:3518–3532, 2021.
[10] Shanghua Gao, Pan Zhou, Ming-Ming Cheng, and Shuicheng Yan. Masked diffusion transformer is a strong image synthesizer. arXiv preprint arXiv:2303.14389 , 2023.
[11] Karan Goel, Albert Gu, Chris Donahue, and Christopher Ré. It's raw! audio generation with state-space models. In International Conference on Machine Learning , pages 7616–7633. PMLR, 2022.
[12] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems , 27, 2014.
[13] Albert Gu, Tri Dao, Stefano Ermon, Atri Rudra, and Christopher Ré. Hippo: Recurrent memory with optimal polynomial projections. Advances in neural information processing systems, 33:1474–1487, 2020.
[14] Albert Gu, Karan Goel, and Christopher Ré. Efficiently modeling long sequences with structured state spaces. arXiv preprint arXiv:2111.00396 , 2021.
[15] Albert Gu, Karan Goel, Ankit Gupta, and Christopher Ré. On the parameterization and initialization of diagonal state space models. Advances in Neural Information Processing Systems , 35:35971–35983, 2022.
[16] Ankit Gupta, Albert Gu, and Jonathan Berant. Diagonal state spaces are as effective as structured state spaces. Advances in Neural Information Processing Systems , 35:22982–22994, 2022.
[17] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 770–778, 2016.
[18] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems , 30, 2017.
[19] Jonathan Ho and Tim Salimans. Classifier-free diffusion guidance. arXiv preprint arXiv:2207.12598 , 2022.
[20] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems , 33:6840–6851, 2020.
[21] Jonathan Ho, Chitwan Saharia, William Chan, David J Fleet, Mohammad Norouzi, and Tim Salimans. Cascaded diffusion models for high fidelity image generation. The Journal of Machine Learning Research , 23(1):2249–2281, 2022.
[22] Emiel Hoogeboom, Jonathan Heek, and Tim Salimans. simple diffusion: End-to-end diffusion for high resolution images. arXiv preprint arXiv:2301.11093 , 2023.
[23] Weizhe Hua, Zihang Dai, Hanxiao Liu, and Quoc Le. Transformer quality in linear time. In International Conference on Machine Learning , pages 9099–9117. PMLR, 2022.
[24] Aapo Hyvärinen and Peter Dayan. Estimation of non-normalized statistical models by score matching. Journal of Machine Learning Research , 6(4), 2005.
[25] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196 , 2017.
[26] Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative adversarial networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 4401–4410, 2019.
[27] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improving the image quality of stylegan. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 8110–8119, 2020.
[28] Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space of diffusion-based generative models. Advances in Neural Information Processing Systems , 35:26565–26577, 2022.
[29] Dongjun Kim, Seungjae Shin, Kyungwoo Song, Wanmo Kang, and Il-Chul Moon. Soft truncation: A universal training technique of score-based diffusion model for high precision score estimation. arXiv preprint arXiv:2106.05527 , 2021.
[30] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 , 2013.
[31] Tuomas Kynkäänniemi, Tero Karras, Samuli Laine, Jaakko Lehtinen, and Timo Aila. Improved precision and recall metric for assessing generative models. Advances in Neural Information Processing Systems , 32, 2019.
[32] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision transformer using shifted windows. In Proceedings of the IEEE/CVF international conference on computer vision , pages 10012–10022, 2021.
[33] Xuezhe Ma, Xiang Kong, Sinong Wang, Chunting Zhou, Jonathan May, Hao Ma, and Luke Zettlemoyer. Luna: Linear unified nested attention. Advances in Neural Information Processing Systems , 34:2441–2453, 2021.
[34] Xuezhe Ma, Chunting Zhou, Xiang Kong, Junxian He, Liangke Gui, Graham Neubig, Jonathan May, and Luke Zettlemoyer. Mega: moving average equipped gated attention. arXiv preprint arXiv:2209.10655 , 2022.
[35] Harsh Mehta, Ankit Gupta, Ashok Cutkosky, and Behnam Neyshabur. Long range language modeling via gated state spaces. arXiv preprint arXiv:2206.13947 , 2022.
[36] Charlie Nash, Jacob Menick, Sander Dieleman, and Peter W Battaglia. Generating images with sparse representations. arXiv preprint arXiv:2103.03841 , 2021.
[37] Alexander Quinn Nichol and Prafulla Dhariwal. Improved denoising diffusion probabilistic models. In International Conference on Machine Learning , pages 8162–8171. PMLR, 2021.
[38] William Peebles and Saining Xie. Scalable diffusion models with transformers. arXiv preprint arXiv:2212.09748 , 2022.
[39] Bo Peng, Eric Alcaide, Quentin Anthony, Alon Albalak, Samuel Arcadinho, Huanqi Cao, Xin Cheng, Michael Chung, Matteo Grella, Kranthi Kiran GV , et al. Rwkv: Reinventing rnns for the transformer era. arXiv preprint arXiv:2305.13048 , 2023.
[40] Ethan Perez, Florian Strub, Harm De Vries, Vincent Dumoulin, and Aaron Courville. Film: Visual reasoning with a general conditioning layer. In Proceedings of the AAAI conference on artificial intelligence , 2018.
[41] Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna, and Robin Rombach. Sdxl: Improving latent diffusion models for high-resolution image synthesis. arXiv preprint arXiv:2307.01952 , 2023.
[42] Michael Poli, Stefano Massaroli, Eric Nguyen, Daniel Y Fu, Tri Dao, Stephen Baccus, Yoshua Bengio, Stefano Ermon, and Christopher Ré. Hyena hierarchy: Towards larger convolutional language models. arXiv preprint arXiv:2302.10866 , 2023.
[43] Zhen Qin, Songlin Yang, and Yiran Zhong. Hierarchically gated recurrent neural network for sequence modeling. arXiv preprint arXiv:2311.04823 , 2023.
[44] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125 , 2022.
[45] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 10684–10695, 2022.
[46] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al. Photorealistic text-to-image diffusion models with deep language understanding. Advances in Neural Information Processing Systems , 35:36479–36494, 2022.
[47] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. Advances in neural information processing systems , 29, 2016.
[48] Tim Salimans, Andrej Karpathy, Xi Chen, and Diederik P Kingma. Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications. arXiv preprint arXiv:1701.05517 , 2017.
[49] Axel Sauer, Kashyap Chitta, Jens Müller, and Andreas Geiger. Projected gans converge faster. Advances in Neural Information Processing Systems , 34:17480–17492, 2021.
[50] Axel Sauer, Katja Schwarz, and Andreas Geiger. Stylegan-xl: Scaling stylegan to large diverse datasets. In ACM SIGGRAPH 2022 conference proceedings , pages 1–10, 2022.
[51] Patrick Schramowski, Manuel Brack, Björn Deiseroth, and Kristian Kersting. Safe latent diffusion: Mitigating inappropriate degeneration in diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 22522–22531, 2023.
[52] Uri Shaham, Kelly Stanton, Henry Li, Boaz Nadler, Ronen Basri, and Yuval Kluger. Spectralnet: Spectral clustering using deep neural networks. arXiv preprint arXiv:1801.01587 , 2018.
[53] Zhuoran Shen, Mingyuan Zhang, Haiyu Zhao, Shuai Yi, and Hongsheng Li. Efficient attention: Attention with linear complexities. In Proceedings of the IEEE/CVF winter conference on applications of computer vision , pages 3531–3539, 2021.
[54] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In International conference on machine learning , pages 2256–2265. PMLR, 2015.
[55] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. arXiv preprint arXiv:2010.02502 , 2020.
[56] Yang Song and Prafulla Dhariwal. Improved techniques for training consistency models. arXiv preprint arXiv:2310.14189 , 2023.
[57] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. Advances in neural information processing systems , 32, 2019.
[58] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456 , 2020.
[59] Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever. Consistency models. arXiv preprint arXiv:2303.01469 , 2023.
[60] Yi Tay, Dara Bahri, Liu Yang, Donald Metzler, and Da-Cheng Juan. Sparse sinkhorn attention. In International Conference on Machine Learning , pages 9438–9447. PMLR, 2020.
[61] Aaron Van den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex Graves, et al. Conditional image generation with pixelcnn decoders. Advances in neural information processing systems , 29, 2016.
[62] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems , 30, 2017.
[63] Junxiong Wang, Jing Nathan Yan, Albert Gu, and Alexander M Rush. Pretraining without attention. arXiv preprint arXiv:2212.10544 , 2022.
[64] Sinong Wang, Belinda Z Li, Madian Khabsa, Han Fang, and Hao Ma. Linformer: Self-attention with linear complexity. arXiv preprint arXiv:2006.04768 , 2020.
[65] Zhihao Wang, Jian Chen, and Steven CH Hoi. Deep learning for image super-resolution: A survey. IEEE transactions on pattern analysis and machine intelligence , 43(10):3365–3387, 2020.
[66] Yuxin Wu and Kaiming He. Group normalization. In Proceedings of the European conference on computer vision (ECCV) , pages 3–19, 2018.
[67] Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas Funkhouser, and Jianxiong Xiao. Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop. arXiv preprint arXiv:1506.03365 , 2015.
[68] Syed Waqas Zamir, Aditya Arora, Salman Khan, Munawar Hayat, Fahad Shahbaz Khan, Ming-Hsuan Yang, and Ling Shao. Multi-stage progressive image restoration. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 14821–14831, 2021.
[69] Hongkai Zheng, Weili Nie, Arash Vahdat, and Anima Anandkumar. Fast training of diffusion models with masked transformers. arXiv preprint arXiv:2306.09305 , 2023.

--- TRANG 8 ---
Hình 5. Nghiên cứu định tính về phân mảnh và tỷ lệ giảm/tăng của DIFFU SSM. P đề cập đến phân mảnh, M đề cập đến tỷ lệ giảm/tăng. P= 1 là trường hợp không có phân mảnh và M= 1 là trường hợp không có giảm/tăng tỷ lệ.

--- TRANG 9 ---
Hình 6. Nghiên cứu loại bỏ. Trái: DIFFUSSM với các kích thước chiều ẩn D khác nhau ( −S/D = 384 ,−L/D = 786 ,−XL/D = 1152 ). Phải: Điểm FID của DIFFU SSM với kích thước mảnh khác nhau (P= 2) và tỷ lệ giảm mẫu ( M= 1).

--- TRANG 10 ---
Hình 7. Mẫu từ các mô hình D IFFU SSM trên ImageNet 256 ×256.

--- TRANG 11 ---
Hình 8. Mẫu từ các mô hình D IFFU SSM trên ImageNet 256 ×256.

--- TRANG 12 ---
Hình 9. Mẫu từ các mô hình D IFFU SSM trên ImageNet 256 ×256.

--- TRANG 13 ---
Hình 10. Mẫu từ các mô hình D IFFU SSM trên ImageNet 256 ×256.

--- TRANG 14 ---
Hình 11. Mẫu từ các mô hình D IFFU SSM trên ImageNet 512 ×512.

--- TRANG 15 ---
Hình 12. Mẫu từ các mô hình D IFFU SSM trên ImageNet 512 ×512.

--- TRANG 16 ---
Hình 13. Mẫu từ các mô hình D IFFU SSM trên ImageNet 512 ×512.

--- TRANG 17 ---
Hình 14. Mẫu từ các mô hình D IFFU SSM trên ImageNet 512 ×512.

--- TRANG 18 ---
Hình 14. Mẫu từ các mô hình D IFFU SSM trên ImageNet 512 ×512.

# 2210.08933.pdf
# ÄÃ£ chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/diffusion/2210.08933.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 1021637 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================

--- TRANG 1 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
DIFFU SEQ: SINH Táº O VÄ‚N Báº¢N Tá»ª Cá»¬A KHáº¨U Äáº¾N Cá»¬A KHáº¨U
Vá»šI MÃ” HÃŒNH KHUáº¾CH TÃN
Shansan Gong1, Mukai Li1, Jiangtao Feng1, Zhiyong Wu1, Lingpeng Kong2
1Shark-NLP, PhÃ²ng thÃ­ nghiá»‡m AI ThÆ°á»£ng Háº£i2Äáº¡i há»c Há»“ng KÃ´ng
fgongshansan,limukai,fengjiangtao,wuzhiyong g@pjlab.org.cn
lpk@cs.hku.hk
TÃ“M Táº®T
Gáº§n Ä‘Ã¢y, cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n Ä‘Ã£ ná»•i lÃªn nhÆ° má»™t mÃ´ hÃ¬nh má»›i cho cÃ¡c mÃ´ hÃ¬nh sinh táº¡o. Máº·c dÃ¹ thÃ nh cÃ´ng trong cÃ¡c lÄ©nh vá»±c sá»­ dá»¥ng tÃ­n hiá»‡u liÃªn tá»¥c nhÆ° thá»‹ giÃ¡c vÃ  Ã¢m thanh, viá»‡c Ä‘iá»u chá»‰nh cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n cho ngÃ´n ngá»¯ tá»± nhiÃªn váº«n chÆ°a Ä‘Æ°á»£c khÃ¡m phÃ¡ Ä‘áº§y Ä‘á»§ do tÃ­nh cháº¥t rá»i ráº¡c cá»§a vÄƒn báº£n, Ä‘áº·c biá»‡t lÃ  Ä‘á»‘i vá»›i sinh táº¡o cÃ³ Ä‘iá»u kiá»‡n. ChÃºng tÃ´i giáº£i quyáº¿t thÃ¡ch thá»©c nÃ y báº±ng cÃ¡ch Ä‘á» xuáº¥t D IFFU SEQ: má»™t mÃ´ hÃ¬nh khuáº¿ch tÃ¡n Ä‘Æ°á»£c thiáº¿t káº¿ cho cÃ¡c nhiá»‡m vá»¥ sinh táº¡o vÄƒn báº£n tá»« chuá»—i Ä‘áº¿n chuá»—i (S EQ2SEQ). ThÃ´ng qua Ä‘Ã¡nh giÃ¡ rá»™ng rÃ£i trÃªn má»™t loáº¡t cÃ¡c nhiá»‡m vá»¥ S EQ2SEQ, chÃºng tÃ´i tháº¥y D IFFU SEQ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng hoáº·c tháº­m chÃ­ tá»‘t hÆ¡n so vá»›i sÃ¡u mÃ´ hÃ¬nh cÆ¡ sá»Ÿ Ä‘Ã£ Ä‘Æ°á»£c thiáº¿t láº­p, bao gá»“m má»™t mÃ´ hÃ¬nh hiá»‡n Ä‘áº¡i dá»±a trÃªn cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c. NgoÃ i cháº¥t lÆ°á»£ng, má»™t tÃ­nh cháº¥t thÃº vá»‹ cá»§a D IFFU SEQ lÃ  tÃ­nh Ä‘a dáº¡ng cao trong quÃ¡ trÃ¬nh sinh táº¡o, Ä‘iá»u nÃ y Ä‘Æ°á»£c mong muá»‘n trong nhiá»u nhiá»‡m vá»¥ S EQ2SEQ. ChÃºng tÃ´i cÅ©ng bao gá»“m má»™t phÃ¢n tÃ­ch lÃ½ thuyáº¿t tiáº¿t lá»™ má»‘i liÃªn há»‡ giá»¯a D IFFU SEQ vÃ  cÃ¡c mÃ´ hÃ¬nh tá»± há»“i quy/khÃ´ng tá»± há»“i quy. Káº¿t há»£p phÃ¢n tÃ­ch lÃ½ thuyáº¿t vÃ  báº±ng chá»©ng thá»±c nghiá»‡m, chÃºng tÃ´i chá»©ng minh tiá»m nÄƒng to lá»›n cá»§a cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n trong cÃ¡c nhiá»‡m vá»¥ sinh táº¡o ngÃ´n ngá»¯ cÃ³ Ä‘iá»u kiá»‡n phá»©c táº¡p.1
1 GIá»šI THIá»†U
Trong sá»‘ cÃ¡c mÃ´ hÃ¬nh sinh táº¡o hiá»‡n cÃ³, GAN (Goodfellow et al., 2014) gáº·p pháº£i váº¥n Ä‘á» báº¥t á»•n Ä‘á»‹nh (Salimans et al., 2016), pháº£i chá»‹u sá»± sá»¥p Ä‘á»• cháº¿ Ä‘á»™ (Metz et al., 2017); V AE (Kingma & Welling, 2014) pháº£i dá»±a vÃ o cÃ¡c má»¥c tiÃªu thay tháº¿ Ä‘á»ƒ xáº¥p xá»‰ viá»‡c huáº¥n luyá»‡n kháº£ nÄƒng cá»±c Ä‘áº¡i vÃ  cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn Flow (Dinh et al., 2017) pháº£i sá»­ dá»¥ng cÃ¡c kiáº¿n trÃºc chuyÃªn biá»‡t Ä‘á»ƒ xÃ¢y dá»±ng biáº¿n Ä‘á»•i cÃ³ thá»ƒ Ä‘áº£o ngÆ°á»£c. CÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n (Ho et al., 2020; Nichol & Dhariwal, 2021) Ä‘Ã£ vÆ°á»£t qua má»™t sá»‘ háº¡n cháº¿ nÃ y vÃ  ná»•i lÃªn nhÆ° má»™t mÃ´ hÃ¬nh má»›i cho cÃ¡c mÃ´ hÃ¬nh sinh táº¡o, Ä‘Æ°á»£c há»— trá»£ lÃ½ thuyáº¿t bá»Ÿi nhiá»‡t Ä‘á»™ng há»c phi cÃ¢n báº±ng (Sohl-Dickstein et al., 2015) vÃ  máº¡ng khá»›p Ä‘iá»ƒm (Song & Ermon, 2019). Cho Ä‘áº¿n nay, cÃ¡c Ä‘á»™t phÃ¡ lá»›n lÃ  trong cÃ¡c lÄ©nh vá»±c sá»­ dá»¥ng tÃ­n hiá»‡u liÃªn tá»¥c, nhÆ° thá»‹ giÃ¡c (Saharia et al., 2022a;b; Ramesh et al., 2022) vÃ  Ã¢m thanh (Kong et al., 2020). Tuy nhiÃªn, viá»‡c má»Ÿ rá»™ng cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n liÃªn tá»¥c cho ngÃ´n ngá»¯ tá»± nhiÃªn váº«n lÃ  má»™t thÃ¡ch thá»©c má»Ÿ do tÃ­nh cháº¥t rá»i ráº¡c vá»‘n cÃ³ cá»§a vÄƒn báº£n.

Dá»±a trÃªn viá»‡c sinh táº¡o khÃ´ng cÃ³ Ä‘iá»u kiá»‡n trong khÃ´ng gian liÃªn tá»¥c Ä‘Æ°á»£c minh há»a trong HÃ¬nh 1(a), cÃ¡c ná»— lá»±c hiá»‡n táº¡i (Hoogeboom et al., 2021; Austin et al., 2021) báº¯t Ä‘áº§u tÃ¹y chá»‰nh cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n cho vÄƒn báº£n trong khÃ´ng gian rá»i ráº¡c vá» mÃ´ hÃ¬nh ngÃ´n ngá»¯ khÃ´ng cÃ³ Ä‘iá»u kiá»‡n (tá»©c lÃ  sinh táº¡o vÄƒn báº£n tá»± do). Diffusion-LM (Li et al., 2022), nhÆ° trong HÃ¬nh 1(b), mÃ´ hÃ¬nh hÃ³a vÄƒn báº£n trong khÃ´ng gian liÃªn tá»¥c vÃ  Ä‘á» xuáº¥t sá»­ dá»¥ng má»™t bá»™ phÃ¢n loáº¡i Ä‘Æ°á»£c huáº¥n luyá»‡n thÃªm lÃ m hÆ°á»›ng dáº«n (tá»©c lÃ  tÃ­n hiá»‡u Ä‘iá»u kiá»‡n x) Ä‘á»ƒ Ã¡p Ä‘áº·t cÃ¡c thay Ä‘á»•i tinh táº¿ (thÆ°á»ng lÃ  cÃ¡c rÃ ng buá»™c phá»©c táº¡p, chi tiáº¿t) trÃªn cÃ¡c cÃ¢u Ä‘Æ°á»£c sinh táº¡o. Tuy nhiÃªn, cÃ¡c mÃ´ hÃ¬nh nÃ y khÃ´ng khÃ¡i quÃ¡t hÃ³a má»™t cÃ¡ch tá»± nhiÃªn cho mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ Ä‘iá»u kiá»‡n (tá»©c lÃ  mÃ´ hÃ¬nh gÃ¡n xÃ¡c suáº¥t p(wjx) cho cÃ¡c chuá»—i tá»« w cho trÆ°á»›c x). Trong cÃ i Ä‘áº·t chuá»—i Ä‘áº¿n chuá»—i (S EQ2SEQ) tá»•ng quÃ¡t hÆ¡n, nÆ¡i Ä‘iá»u kiá»‡n x cÅ©ng lÃ  má»™t chuá»—i tá»«, viá»‡c Ã¡p dá»¥ng Diffusion-LM cÃ³ thá»ƒ khÃ³ khÄƒn. LÃ½ do lÃ  cÃ¡c bá»™ phÃ¢n loáº¡i hÆ°á»›ng thuá»™c tÃ­nh, vÃ  chÃºng ta khÃ´ng thá»ƒ huáº¥n luyá»‡n hÃ ng trÄƒm nghÃ¬n bá»™ phÃ¢n loáº¡i Ä‘á»ƒ mÃ´ hÃ¬nh hÃ³a Ã½ nghÄ©a ngá»¯ nghÄ©a giá»¯a cÃ¡c Ä‘iá»u kiá»‡n vÃ  cÃ¡c cÃ¢u Ä‘Æ°á»£c sinh táº¡o.

SEQ2SEQ lÃ  má»™t cÃ i Ä‘áº·t thiáº¿t yáº¿u trong NLP bao gá»“m má»™t loáº¡t cÃ¡c nhiá»‡m vá»¥ quan trá»ng nhÆ° sinh táº¡o cÃ¢u má»Ÿ, Ä‘á»‘i tí™”, paraphrase, vÃ  chuyá»ƒn Ä‘á»•i phong cÃ¡ch vÄƒn báº£n. Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i Ä‘á» xuáº¥t
1MÃ£ nguá»“n cÃ³ sáºµn táº¡i https://github.com/Shark-NLP/DiffuSeq
1arXiv:2210.08933v3  [cs.CL]  14 Feb 2023

--- TRANG 2 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
t=0 t=T/2 t=T
t=0 t=T/2 t=Tt=0 t=T/2 t=T
(a) (b)
(c)
quÃ¡ trÃ¬nh tiáº¿n ğ‘(â‹…) quÃ¡ trÃ¬nh ngÆ°á»£c ğ‘ğœƒ(â‹…)
(a)QuÃ¡ trÃ¬nh khuáº¿ch tÃ¡n Gaussian khÃ´ng Ä‘iá»u kiá»‡n trong khÃ´ng gian liÃªn tá»¥c
(b) QuÃ¡ trÃ¬nh khuáº¿ch tÃ¡n cÃ³ hÆ°á»›ng dáº«n báº±ng bá»™ phÃ¢n loáº¡i (Diffusion -LM)
(c) Khuáº¿ch tÃ¡n khÃ´ng cáº§n bá»™ phÃ¢n loáº¡i Ä‘Æ°á»£c hÆ°á»›ng dáº«n bá»Ÿi cÃ¡c Ä‘iá»ƒm trong khÃ´ng gian ( DiffuSeq )tÃ­n hiá»‡u Ä‘iá»u kiá»‡n khÃ´ng gian áº©n cá»§a vÄƒn báº£n hÆ°á»›ng dáº«n
HÃ¬nh 1: MÃ´ táº£ vá» cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n khÃ´ng Ä‘iá»u kiá»‡n, cÃ³ hÆ°á»›ng dáº«n bá»™ phÃ¢n loáº¡i, vÃ  khÃ´ng cáº§n bá»™ phÃ¢n loáº¡i.
DIFFU SEQ, Ä‘Æ°á»£c miÃªu táº£ trong HÃ¬nh 1(c), má»™t mÃ´ hÃ¬nh khuáº¿ch tÃ¡n khÃ´ng cáº§n bá»™ phÃ¢n loáº¡i há»— trá»£ cÃ¡c nhiá»‡m vá»¥ sinh táº¡o vÄƒn báº£n S EQ2SEQ. Báº±ng cÃ¡ch mÃ´ hÃ¬nh hÃ³a xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n cá»§a cÃ¢u Ä‘Ã­ch w cho trÆ°á»›c ngá»¯ cáº£nh x sá»­ dá»¥ng má»™t mÃ´ hÃ¬nh duy nháº¥t, má»™t lá»£i tháº¿ cá»§a D IFFU SEQ lÃ  mÃ´ hÃ¬nh nÃ y cho phÃ©p má»™t mÃ´ hÃ¬nh hoÃ n chá»‰nh phÃ¹ há»£p vá»›i phÃ¢n phá»‘i dá»¯ liá»‡u vÃ  sá»­ dá»¥ng hÆ°á»›ng dáº«n cÃ³ Ä‘iá»u kiá»‡n, thay vÃ¬ phá»¥ thuá»™c vÃ o má»™t bá»™ phÃ¢n loáº¡i riÃªng biá»‡t.

KhÃ¡c vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p sinh táº¡o chuáº©n theo cÃ¡ch tá»± há»“i quy (AR) tá»« trÃ¡i sang pháº£i (Radford et al., 2019), D IFFU SEQ sinh táº¡o cÃ¡c token vÄƒn báº£n song song theo cÃ¡ch khÃ´ng tá»± há»“i quy (NAR). Äá»ƒ chá»©ng thá»±c hiá»‡u quáº£ cá»§a D IFFU SEQ, chÃºng tÃ´i tiáº¿n hÃ nh thÃ­ nghiá»‡m trÃªn bá»‘n nhiá»‡m vá»¥ S EQ2SEQ. So vá»›i cÃ¡c mÃ´ hÃ¬nh AR vÃ  NAR, vá»‘n gáº·p pháº£i váº¥n Ä‘á» "suy thoÃ¡i" (Holtzman et al., 2019) vÃ  phá»¥ thuá»™c vÃ o cÃ¡c chiáº¿n lÆ°á»£c giáº£i mÃ£, D IFFU SEQ cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c tÃ­nh Ä‘a dáº¡ng á»Ÿ cáº¥p Ä‘á»™ cÃ¢u Ä‘Ã¡ng ká»ƒ mÃ  khÃ´ng hy sinh cháº¥t lÆ°á»£ng (xem Â§ 4.2).

TÃ³m láº¡i, chÃºng tÃ´i Ä‘Æ°a ra má»™t loáº¡t cÃ¡c Ä‘Ã³ng gÃ³p ká»¹ thuáº­t vÃ  khÃ¡i niá»‡m: (a) chÃºng tÃ´i lÃ  nhá»¯ng ngÆ°á»i Ä‘áº§u tiÃªn triá»ƒn khai mÃ´ hÃ¬nh khuáº¿ch tÃ¡n cho sinh táº¡o vÄƒn báº£n S EQ2SEQ, vÃ  D IFFU SEQ Ä‘Æ°á»£c Ä‘á» xuáº¥t cá»§a chÃºng tÃ´i nhÆ° má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ Ä‘iá»u kiá»‡n Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘áº§u cuá»‘i Ä‘áº¿n cuá»‘i theo cÃ¡ch khÃ´ng cáº§n bá»™ phÃ¢n loáº¡i; (b) chÃºng tÃ´i thiáº¿t láº­p má»™t má»‘i liÃªn há»‡ lÃ½ thuyáº¿t giá»¯a cÃ¡c mÃ´ hÃ¬nh AR, NAR vÃ  D IFFU SEQ, vÃ  chá»©ng minh D IFFU SEQ nhÆ° má»™t má»Ÿ rá»™ng cá»§a cÃ¡c mÃ´ hÃ¬nh iterative-NAR; (c) vá»›i báº±ng chá»©ng thá»±c nghiá»‡m máº¡nh máº½, chÃºng tÃ´i chá»©ng minh tiá»m nÄƒng to lá»›n cá»§a cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n trong cÃ¡c nhiá»‡m vá»¥ sinh táº¡o ngÃ´n ngá»¯ cÃ³ Ä‘iá»u kiá»‡n phá»©c táº¡p.

2 KIáº¾N THá»¨C CÆ  Báº¢N VÃ€ PHÃT BIá»‚U BÃ€I TOÃN
Kiáº¿n thá»©c cÆ¡ báº£n. Má»™t mÃ´ hÃ¬nh khuáº¿ch tÃ¡n thÆ°á»ng chá»©a cÃ¡c quÃ¡ trÃ¬nh tiáº¿n vÃ  ngÆ°á»£c. Cho má»™t Ä‘iá»ƒm dá»¯ liá»‡u Ä‘Æ°á»£c láº¥y máº«u tá»« má»™t phÃ¢n phá»‘i dá»¯ liá»‡u thá»±c táº¿ z0q(z), quÃ¡ trÃ¬nh tiáº¿n dáº§n dáº§n lÃ m há»ng z0 thÃ nh má»™t nhiá»…u Gaussian chuáº©n zTN (0;I). Äá»‘i vá»›i má»—i bÆ°á»›c tiáº¿n t2[1;2;:::;T ], nhiá»…u loáº¡n Ä‘Æ°á»£c Ä‘iá»u khiá»ƒn bá»Ÿi q(ztjzt1) =N(zt;p1tzt1;tI), vá»›i t2(0;1) lÃ  cÃ¡c tá»· lá»‡ phÆ°Æ¡ng sai khÃ¡c nhau. Khi quÃ¡ trÃ¬nh tiáº¿n hoÃ n táº¥t, quÃ¡ trÃ¬nh khá»­ nhiá»…u ngÆ°á»£c cá»‘ gáº¯ng dáº§n dáº§n tÃ¡i táº¡o dá»¯ liá»‡u gá»‘c z0 thÃ´ng qua viá»‡c láº¥y máº«u tá»« zT báº±ng cÃ¡ch há»c má»™t mÃ´ hÃ¬nh khuáº¿ch tÃ¡n f.

PhÃ¡t biá»ƒu bÃ i toÃ¡n. Nhiá»u ná»— lá»±c gáº§n Ä‘Ã¢y Ä‘Ã£ Ä‘Æ°á»£c dÃ nh cho viá»‡c Ä‘iá»u chá»‰nh cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n cho vÄƒn báº£n rá»i ráº¡c (Xem Â§ 5). Tuy nhiÃªn, táº¥t cáº£ Ä‘á»u táº­p trung vÃ o mÃ´ hÃ¬nh chuá»—i khÃ´ng Ä‘iá»u kiá»‡n. Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i nháº¯m vÃ o cÃ¡c nhiá»‡m vá»¥ sinh táº¡o vÄƒn báº£n chuá»—i Ä‘áº¿n chuá»—i. Cá»¥ thá»ƒ, cho má»™t chuá»—i nguá»“n cÃ³ Ä‘á»™ dÃ i m wx=fwx1;:::;wxmg, chÃºng tÃ´i muá»‘n há»c má»™t mÃ´ hÃ¬nh khuáº¿ch tÃ¡n cÃ³ thá»ƒ táº¡o ra má»™t chuá»—i Ä‘Ã­ch cÃ³ Ä‘á»™ dÃ i n wy=fwy1;:::;wyngcÃ³ Ä‘iá»u kiá»‡n trÃªn chuá»—i nguá»“n.

3 D IFFU SEQ
ChÃºng tÃ´i Ä‘á» xuáº¥t D IFFU SEQ Ä‘á»ƒ má»Ÿ rá»™ng cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n vanilla Ä‘á»ƒ há»c sinh táº¡o vÄƒn báº£n cÃ³ Ä‘iá»u kiá»‡n (nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 2), liÃªn quan Ä‘áº¿n kiáº¿n trÃºc mÃ´ hÃ¬nh vÃ  má»¥c tiÃªu huáº¥n luyá»‡n.

QuÃ¡ trÃ¬nh tiáº¿n vá»›i nhiá»…u má»™t pháº§n. á» Ä‘áº§u quÃ¡ trÃ¬nh tiáº¿n, chÃºng tÃ´i lÃ m theo Diffusion-LM (Li et al., 2022) Ä‘á»ƒ thiáº¿t káº¿ má»™t hÃ m embedding E MB(w) Ä‘á»ƒ Ã¡nh xáº¡ vÄƒn báº£n rá»i ráº¡c w vÃ o khÃ´ng gian liÃªn tá»¥c. Cá»¥ thá»ƒ, cho má»™t cáº·p chuá»—i wx vÃ  wy, DIFFU SEQ há»c má»™t
2

--- TRANG 3 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
Nhiá»…u Gaussian má»™t pháº§n zğ‘‡zğ‘¡zğ‘¡âˆ’1z0â€¦ â€¦ğ‘ğœƒ(zğ‘¡âˆ’1|zğ‘¡)
ğ‘(zğ‘¡|zğ‘¡âˆ’1)
Word Embeddings VÄƒn báº£n wğ‘¥
wğ‘¦
Ãnh xáº¡ embedding ğ‘ğœƒ(w|z0)
ğ‘ğœ™(z0|w)Chuyáº¿n Ä‘i kÃ©o dÃ i
bao lÃ¢u?
Má»™t nÄƒm.
Chuá»—i Ä‘áº¿n chuá»—i VÃ­ dá»¥: Äá»‘i thoáº¡i má»Ÿ E.g. Open-Domain DialogueQuÃ¡ trÃ¬nh tiáº¿n QuÃ¡ trÃ¬nh ngÆ°á»£c Nhiá»…u Gaussian LÃ m trÃ²n
HÃ¬nh 2: QuÃ¡ trÃ¬nh khuáº¿ch tÃ¡n cá»§a mÃ´ hÃ¬nh ngÃ´n ngá»¯ khuáº¿ch tÃ¡n cÃ³ Ä‘iá»u kiá»‡n D IFFU SEQ. Cho nguá»“n wx vÃ  Ä‘Ã­ch wy, chÃºng tÃ´i biáº¿n Ä‘á»•i chÃºng theo cáº·p vÃ o khÃ´ng gian liÃªn tá»¥c z0. Nhiá»…u Gaussian má»™t pháº§n Ä‘Æ°á»£c láº·p láº¡i thÃªm vÃ o khÃ´ng gian Ä‘Ã­ch cá»§a zt.

khÃ´ng gian Ä‘áº·c trÆ°ng thá»‘ng nháº¥t cá»§a wx vÃ  wy báº±ng biáº¿n Ä‘á»•i embedding vÃ  ná»‘i nhÆ° E MB(wxy) = [EMB(wx1);:::;EMB(wxm);EMB(wy1);:::;EMB(wyn)]2R(m+n)d. Biáº¿n Ä‘á»•i cho phÃ©p chÃºng tÃ´i Ä‘iá»u chá»‰nh Ä‘áº§u vÃ o vÄƒn báº£n rá»i ráº¡c vÃ o quÃ¡ trÃ¬nh tiáº¿n chuáº©n, báº±ng cÃ¡ch má»Ÿ rá»™ng chuá»—i tiáº¿n ban Ä‘áº§u thÃ nh má»™t chuyá»ƒn tiáº¿p Markov má»›i q(z0jwxy) =N(EMB(wxy);0I).

ChÃºng tÃ´i kÃ½ hiá»‡u zt=xtyt Ä‘á»ƒ Ä‘Æ¡n giáº£n hÃ³a cÃ¡ch diá»…n Ä‘áº¡t, trong Ä‘Ã³ xt vÃ  yt Ä‘áº¡i diá»‡n cho cÃ¡c pháº§n cá»§a zt thuá»™c vá» wx vÃ  wy, tÆ°Æ¡ng á»©ng. Äá»‘i vá»›i má»—i bÆ°á»›c tiáº¿n q(ztjzt1), chÃºng tÃ´i dáº§n dáº§n tiÃªm nhiá»…u vÃ o tráº¡ng thÃ¡i áº©n cá»§a bÆ°á»›c cuá»‘i zt1 Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c zt. KhÃ´ng nhÆ° cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n thÃ´ng thÆ°á»ng lÃ m há»ng toÃ n bá»™ zt (cáº£ xt vÃ  yt) khÃ´ng phÃ¢n biá»‡t, chÃºng tÃ´i chá»‰ Ã¡p Ä‘áº·t nhiá»…u lÃªn yt. Sá»± sá»­a Ä‘á»•i nÃ y (Ä‘Æ°á»£c gá»i lÃ  nhiá»…u má»™t pháº§n) cho phÃ©p chÃºng tÃ´i Ä‘iá»u chá»‰nh cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n cho mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ Ä‘iá»u kiá»‡n.

QuÃ¡ trÃ¬nh ngÆ°á»£c vá»›i khá»­ nhiá»…u cÃ³ Ä‘iá»u kiá»‡n. Má»¥c tiÃªu cuá»‘i cÃ¹ng cá»§a quÃ¡ trÃ¬nh ngÆ°á»£c lÃ  khÃ´i phá»¥c z0 gá»‘c báº±ng cÃ¡ch khá»­ nhiá»…u zt:p(z0:T) :=p(zT)QTt=1p(zt1jzt). ChÃºng tÃ´i mÃ´ hÃ¬nh hÃ³a quÃ¡ trÃ¬nh há»c p(zt1jzt) =N(zt1;(zt;t);(zt;t)) sá»­ dá»¥ng mÃ´ hÃ¬nh khuáº¿ch tÃ¡n Ä‘Æ°á»£c Ä‘á» xuáº¥t DIFFU SEQ:f(zt;t), trong Ä‘Ã³ () vÃ  () lÃ  tham sá»‘ hÃ³a cá»§a trung bÃ¬nh vÃ  Ä‘á»™ lá»‡ch chuáº©n dá»± Ä‘oÃ¡n cá»§a q(zt1jzt) trong quÃ¡ trÃ¬nh tiáº¿n, Ä‘Æ°á»£c suy ra sá»­ dá»¥ng quy táº¯c Bayes. CÃ¡c derivation chi tiáº¿t cÃ³ trong Phá»¥ lá»¥c A. Vá»›i chiáº¿n lÆ°á»£c nhiá»…u má»™t pháº§n Ä‘Æ°á»£c Ã¡p dá»¥ng trong quÃ¡ trÃ¬nh tiáº¿n, chÃºng tÃ´i cÃ³ thá»ƒ Ã¡p Ä‘áº·t Ä‘áº§u vÃ o nhÆ° Ä‘iá»u kiá»‡n khi khá»­ nhiá»…u nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 1. Viá»‡c khá»­ nhiá»…u cÃ³ Ä‘iá»u kiá»‡n Ä‘Æ°á»£c Ä‘á» xuáº¥t lÃ  khÃ´ng cáº§n bá»™ phÃ¢n loáº¡i theo báº£n cháº¥t: chÃºng tÃ´i khÃ´ng yÃªu cáº§u cÃ¡c bá»™ phÃ¢n loáº¡i Ä‘Æ°á»£c huáº¥n luyá»‡n thÃªm Ä‘á»ƒ Ä‘iá»u khiá»ƒn quÃ¡ trÃ¬nh khá»­ nhiá»…u.

Cá»¥ thá»ƒ, chÃºng tÃ´i sá»­ dá»¥ng kiáº¿n trÃºc transformer Ä‘á»ƒ mÃ´ hÃ¬nh hÃ³a f, tá»± nhiÃªn mÃ´ hÃ¬nh hÃ³a má»‘i quan há»‡ ngá»¯ nghÄ©a giá»¯a xt vÃ  yt. ChÃºng tÃ´i tÃ­nh toÃ¡n cáº­n dÆ°á»›i biáº¿n thiÃªn ( LVLB) theo quÃ¡ trÃ¬nh khuáº¿ch tÃ¡n gá»‘c. Lround tÆ°Æ¡ng á»©ng vá»›i phÃ©p toÃ¡n lÃ m trÃ²n trong HÃ¬nh 2.

LVLB=Eq(z1:Tjz0)"
logq(zTjz0)
p(zT)|{z}
LT+TX
t=2logq(zt1jz0;zt)
p(zt1jzt)|{z}
Lt1
+ logq(z0jwxy)
p(z0jz1)|{z}
L0logp(wxyjz0)
|{z}
Lround#
:(1)

ChÃºng tÃ´i tiáº¿p tá»¥c Ä‘Æ¡n giáº£n hÃ³a má»¥c tiÃªu huáº¥n luyá»‡n nhÆ° sau (chi tiáº¿t trong Phá»¥ lá»¥c A):
min
LVLB= min
"TX
t=2jjz0f(zt;t)jj2+jjEMB(wxy)f(z1;1)jj2logp(wxyjz0)#
!min
"TX
t=2jjy0~f(zt;t)jj2+jjEMB(wy)~f(z1;1)jj2+R(jjz0jj2)#
; (2)

á»Ÿ Ä‘Ã¢y chÃºng tÃ´i sá»­ dá»¥ng ~f(zt;t) Ä‘á»ƒ kÃ½ hiá»‡u cÃ¡c pháº§n cá»§a z0 Ä‘Æ°á»£c khÃ´i phá»¥c tÆ°Æ¡ng á»©ng vá»›i y0. LÆ°u Ã½ ráº±ng máº·c dÃ¹ trong sá»‘ háº¡ng Ä‘áº§u tiÃªn, chÃºng tÃ´i chá»‰ tÃ­nh toÃ¡n máº¥t mÃ¡t w.r.t y0, do cÆ¡ cháº¿ attention trong transformer, viá»‡c tÃ¡i táº¡o y0 cÅ©ng tÃ­nh Ä‘áº¿n x0, do Ä‘Ã³ gradient tá»« sá»‘ háº¡ng Ä‘áº§u tiÃªn
3

--- TRANG 4 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
cÅ©ng sáº½ áº£nh hÆ°á»Ÿng Ä‘áº¿n viá»‡c há»c x0. Sá»‘ háº¡ng regularization tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá» máº·t toÃ¡n há»c R(jjz0jj2)) Ä‘iá»u chá»‰nh viá»‡c há»c embedding. ChÃºng tÃ´i cÅ©ng chia sáº» hÃ m embedding giá»¯a cÃ¡c chuá»—i nguá»“n vÃ  Ä‘Ã­ch, cho phÃ©p huáº¥n luyá»‡n hai khÃ´ng gian Ä‘áº·c trÆ°ng khÃ¡c nhau cÃ¹ng nhau. Äiá»u nÃ y Ä‘áº·t D IFFU SEQ tÃ¡ch biá»‡t vá»›i cÃ¡c giáº£i phÃ¡p hiá»‡n cÃ³ trong thá»‹ giÃ¡c nhÆ° GLIDE (Nichol et al., 2022).

PhÆ°Æ¡ng phÃ¡p huáº¥n luyá»‡n vÃ  suy luáº­n. Trong cÃ¡c thÃ­ nghiá»‡m sÆ¡ bá»™, chÃºng tÃ´i tháº¥y ráº±ng tÃ­nh Ä‘a dáº¡ng cao trong cÃ¡c táº­p dá»¯ liá»‡u NLP vÃ  cÃ¡c bÆ°á»›c khuáº¿ch tÃ¡n dÃ i thÆ°á»ng dáº«n Ä‘áº¿n huáº¥n luyá»‡n khÃ´ng Ä‘á»§. ChÃºng tÃ´i giáº£ thuyáº¿t lÃ½ do lÃ  viá»‡c láº¥y máº«u bÆ°á»›c t Ä‘á»“ng nháº¥t gÃ¢y ra nhiá»…u khÃ´ng cáº§n thiáº¿t trong má»¥c tiÃªu LVLB. Do Ä‘Ã³ chÃºng tÃ´i sá»­ dá»¥ng láº¥y máº«u cÃ³ trá»ng sá»‘ quan trá»ng (Nichol & Dhariwal, 2021) Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» nÃ y.

LVLB=EtptLt
pt
; pt/q
E[L2
t];PT1
t=0pt= 1: (3)

Theo trá»±c giÃ¡c, thuáº­t toÃ¡n láº¥y máº«u cÃ³ trá»ng sá»‘ quan trá»ng sáº½ dÃ nh nhiá»u bÆ°á»›c hÆ¡n cho cÃ¡c bÆ°á»›c khuáº¿ch tÃ¡n cÃ³ Lt lá»›n hÆ¡n, vÃ  ngÆ°á»£c láº¡i.

Äá»ƒ thá»±c hiá»‡n sinh táº¡o S EQ2SEQ cho trÆ°á»›c Ä‘iá»u kiá»‡n E MB(wx), chÃºng tÃ´i láº¥y máº«u ngáº«u nhiÃªn yT
N(0;I) vÃ  ná»‘i yT vá»›i E MB(wx) Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c zT. BÃ¢y giá» chÃºng tÃ´i cÃ³ thá»ƒ láº·p láº¡i quÃ¡ trÃ¬nh ngÆ°á»£c cho Ä‘áº¿n khi Ä‘áº¿n z0. Táº¡i má»—i bÆ°á»›c láº¥y máº«u, má»™t hÃ m neo Ä‘Æ°á»£c thá»±c hiá»‡n hÆ°á»›ng vá» zt Ä‘Æ°á»£c tham sá»‘ hÃ³a láº¡i. Cá»¥ thá»ƒ, hÃ m neo: (a) thá»±c hiá»‡n lÃ m trÃ²n trÃªn zt Ä‘á»ƒ Ã¡nh xáº¡ nÃ³ trá»Ÿ láº¡i khÃ´ng gian word embedding theo Li et al. (2022); (b) thay tháº¿ pháº§n cá»§a zt1 Ä‘Æ°á»£c khÃ´i phá»¥c thuá»™c vá» wx báº±ng x0 gá»‘c, xem xÃ©t ráº±ng pháº§n nÃ y Ä‘Æ°á»£c khÃ´i phá»¥c tá»« zt bá»‹ há»ng qua f vÃ  khÃ´ng nghiÃªm ngáº·t báº±ng x0. LÆ°u Ã½ ráº±ng (b) Ä‘Æ°á»£c thiáº¿t káº¿ cho D IFFU SEQ.

Äá»ƒ cáº£i thiá»‡n cháº¥t lÆ°á»£ng sinh táº¡o, chÃºng tÃ´i Ã¡p dá»¥ng chiáº¿n lÆ°á»£c giáº£i mÃ£ Minimum Bayes Risk (MBR) Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i (Koehn, 2004). Äáº§u tiÃªn chÃºng tÃ´i sinh táº¡o má»™t táº­p há»£p cÃ¡c máº«u á»©ng viÃªn S tá»« cÃ¡c seed ngáº«u nhiÃªn khÃ¡c nhau cá»§a D IFFU SEQ vÃ  chá»n chuá»—i Ä‘áº§u ra tá»‘t nháº¥t Ä‘áº¡t Ä‘Æ°á»£c rá»§i ro ká»³ vá»ng tá»‘i thiá»ƒu dÆ°á»›i má»™t hÃ m máº¥t mÃ¡t cÃ³ Ã½ nghÄ©a (vÃ­ dá»¥: BLEU hoáº·c cÃ¡c metric ráº» hÆ¡n khÃ¡c nhÆ° precision). Trong thá»±c táº¿, chÃºng tÃ´i sá»­ dá»¥ng Ä‘iá»ƒm BLEU Ã¢m trong triá»ƒn khai cá»§a mÃ¬nh.

Má»‘i liÃªn há»‡ vá»›i cÃ¡c mÃ´ hÃ¬nh AR, Iter-NAR, vÃ  Fully-NAR. Äá»ƒ hiá»ƒu rÃµ hÆ¡n vá» hÃ nh vi cá»§a DIFFU SEQ, chÃºng tÃ´i Ä‘Æ°a ra má»‘i liÃªn há»‡ lÃ½ thuyáº¿t vá»›i cÃ¡c mÃ´ hÃ¬nh tá»± há»“i quy (AR), khÃ´ng tá»± há»“i quy láº·p (iter-NAR), vÃ  khÃ´ng tá»± há»“i quy hoÃ n toÃ n (fully-NAR). ChÃºng tÃ´i láº­p luáº­n ráº±ng D IFFU SEQ cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° má»™t má»Ÿ rá»™ng cá»§a mÃ´ hÃ¬nh iter-NAR. CÃ¡c sá»± khÃ¡c biá»‡t há»c táº­p Ä‘á»“ há»a chi tiáº¿t cá»§a bá»‘n trÆ°á»ng há»£p nÃ y Ä‘Æ°á»£c tháº£o luáº­n trong Phá»¥ lá»¥c B Ä‘á»ƒ tham kháº£o.

CÃ¡c mÃ´ hÃ¬nh AR há»c p(wy1:njwx) báº±ng phÃ¢n tÃ­ch tá»± há»“i quy dá»±a trÃªn ngá»¯ cáº£nh trÃ¡i:
pAR(wy1:njwx) =p(wy1jwx)
|{z}
dá»± Ä‘oÃ¡n ban Ä‘áº§u Y
i=1;:::;n1p(wyi+1jwy1:i;wx)
|{z}
dá»± Ä‘oÃ¡n ngá»¯ cáº£nh trÃ¡i tiáº¿n bá»™; (4)

trong khi cÃ¡c mÃ´ hÃ¬nh fully-NAR (Gu et al., 2018; Qian et al., 2021) há»c xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n cho trÆ°á»›c giáº£ Ä‘á»‹nh Ä‘á»™c láº­p Ä‘á»ƒ suy luáº­n nhanh:
pfully-NAR (wy1:njwx) =Y
i=1;:::;np(wyijwx): (5)

Äá»ƒ lÃ m má»™t phÃ©p tÆ°Æ¡ng tá»± tá»‘t hÆ¡n vá»›i cÃ¡c mÃ´ hÃ¬nh AR vÃ  NAR, chÃºng tÃ´i sá»­ dá»¥ng má»™t cÃ¡ch khÃ´ng máº¥t mÃ¡t Ä‘á»ƒ cÃ´ng thá»©c hÃ³a cÃ¡c mÃ´ hÃ¬nh iterative NAR (Gu et al., 2019; Ghazvininejad et al., 2019) báº±ng cÃ¡ch giá»›i thiá»‡u má»™t loáº¡t cÃ¡c chuá»—i trung gian wy1:K1;wyK=wy vá»›i K láº§n láº·p cÃ³ thá»ƒ chá»‰nh sá»­a:
piter-NAR (wy1:njwx) =X
wy1;:::;wyK1Y
i=1:::np(wy1;ijwx)
|{z}
dá»± Ä‘oÃ¡n ban Ä‘áº§u Y
k=1::K1Y
i=1:::np(wyk+1;ijwyk;1:n;wx)
| {z }
dá»± Ä‘oÃ¡n ngá»¯ cáº£nh Ä‘áº§y Ä‘á»§ tiáº¿n bá»™:
(6)

NghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y (Huang et al., 2022) cho tháº¥y cÃ³ má»™t khoáº£ng cÃ¡ch gá»i lÃ  tÆ°Æ¡ng quan tá»•ng cÃ³ Ä‘iá»u kiá»‡n giá»¯a cÃ¡c mÃ´ hÃ¬nh há»c AR Eq. (4) vÃ  fully-NAR Eq. (5), vÃ¬ phÃ¢n tÃ­ch máº¥t mÃ¡t cá»§a cÃ¡c mÃ´ hÃ¬nh NAR. Tuy nhiÃªn, khi so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh iter-NAR Eq. (6) vá»›i AR Eq. (4), cáº£ hai Ä‘á»u cÃ³ thá»ƒ Ä‘Æ°á»£c phÃ¢n tÃ­ch thÃ nh má»™t sá»‘ háº¡ng dá»± Ä‘oÃ¡n ban Ä‘áº§u vÃ  má»™t quÃ¡ trÃ¬nh dá»± Ä‘oÃ¡n tiáº¿n bá»™ dá»±a trÃªn ngá»¯ cáº£nh khÃ¡c nhau (tá»©c lÃ  ngá»¯ cáº£nh trÃ¡i trong AR vÃ  ngá»¯ cáº£nh Ä‘áº§y Ä‘á»§ trong iter-NAR), vÃ  sá»± khÃ¡c biá»‡t Ä‘Æ°á»£c chá»‰ ra bá»Ÿi
4

--- TRANG 5 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
Huang et al. (2022) do Ä‘Ã³ Ä‘Æ°á»£c Ä‘Ã³ng láº¡i trong iter-NAR giáº£ Ä‘á»‹nh Ä‘á»§ bÆ°á»›c. Báº±ng cÃ¡ch hiá»ƒn thá»‹ D IF-
FUSEQ lÃ  má»™t má»Ÿ rá»™ng cá»§a mÃ´ hÃ¬nh iter-NAR, chÃºng tÃ´i Ä‘Æ°a ra má»™t lá»i biá»‡n minh ráº±ng nÃ³ sáº½ khÃ´ng gáº·p pháº£i tÆ°Æ¡ng quan tá»•ng cÃ³ Ä‘iá»u kiá»‡n vÃ¬ cÃ¹ng lÃ½ do.

Má»™t cÃ¡ch tháº³ng tháº¯n Ä‘á»ƒ cÃ´ng thá»©c hÃ³a cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n liÃªn tá»¥c thuáº§n tÃºy lÃ  giá»›i thiá»‡u má»™t loáº¡t cÃ¡c Ä‘áº·c trÆ°ng bá»‹ há»ng bá»Ÿi nhiá»…u Gaussian cÃ¹ng vá»›i cÃ¡c bÆ°á»›c khuáº¿ch tÃ¡n: y1:T1;y0=y;yTN(0;I).
pdiffusion (wyjwx) =Z
yT;:::;y0p(wyjy0;wx)
|{z}
dá»± Ä‘oÃ¡n cuá»‘i cÃ¹ng Y
t=T;:::; 1p(yt1jyt;wx)
|{z}
khuáº¿ch tÃ¡n ngá»¯ cáº£nh Ä‘áº§y Ä‘á»§ tiáº¿n bá»™; (7)

trong Ä‘Ã³ p(yt1jyt;wx) mÃ´ táº£ bÆ°á»›c khuáº¿ch tÃ¡n trÃªn cÃ¡c biá»ƒu diá»…n liÃªn tá»¥c y. PhÃ©p toÃ¡n lÃ m trÃ²n trong D IFFU SEQ Ã¡nh xáº¡ cÃ¡c vector liÃªn tá»¥c y thÃ nh wy rá»i ráº¡c cho má»—i bÆ°á»›c thá»i gian t, chÃºng tÃ´i cÅ©ng giá»›i thiá»‡u Ä‘iá»u nÃ y vÃ o Eq. (7):
pDIFFU SEQ(wyjwx) =X
wyT;:::;wy1Z
yT;:::;y0p(wyjy0;wx)Y
t=T;:::; 1p(wytjyt;wx)p(yt1jwy
t) (8)

=X
wyT;:::;wy1Z
yT;:::;y0p(wyTjyT;wx)Y
t=T1;:::;0p(ytjwyt+1)p(wytjyt;wx):(9)

Báº±ng cÃ¡ch sáº¯p xáº¿p láº¡i Eq. (8) thÃ nh Eq. (9), chÃºng ta cÃ³ thá»ƒ tháº¥y D IFFU SEQ cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° má»™t dáº¡ng tá»•ng quÃ¡t hÃ³a hÆ¡n cá»§a iter-NAR Eq. (6) trÆ°á»›c khi marginalize fyT;:::;y0g, máº·c dÃ¹ khá»Ÿi táº¡o khÃ¡c nhau cá»§a yT2. Má»™t derivation chi tiáº¿t hÆ¡n Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Phá»¥ lá»¥c C.

4 THÃ NGHIá»†M
ChÃºng tÃ´i tiáº¿n hÃ nh thÃ­ nghiá»‡m Ä‘á»ƒ xÃ¡c thá»±c hiá»‡u quáº£ cá»§a D IFFU SEQ trÃªn bá»‘n nhiá»‡m vá»¥ khÃ¡c nhau, so vá»›i sÃ¡u baseline AR/NAR máº¡nh.

4.1 THIáº¾T Láº¬P THÃ NGHIá»†M
Nhiá»‡m vá»¥ vÃ  táº­p dá»¯ liá»‡u. Sinh táº¡o SEQ2SEQ bao gá»“m má»™t loáº¡t cÃ¡c nhiá»‡m vá»¥, trong Ä‘Ã³ chÃºng tÃ´i chá»n bá»‘n nhiá»‡m vá»¥ Ä‘iá»ƒn hÃ¬nh vÃ  phá»• biáº¿n. Äá»‘i thoáº¡i miá»n má»Ÿ yÃªu cáº§u cÃ¡c mÃ´ hÃ¬nh sinh táº¡o pháº£n há»“i thÃ´ng tin cho trÆ°á»›c má»™t ngá»¯ cáº£nh Ä‘á»‘i thoáº¡i. ChÃºng tÃ´i sá»­ dá»¥ng Commonsense Conversation Dataset (Zhou et al., 2018), Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« cÃ¡c cuá»™c Ä‘á»‘i thoáº¡i Reddit má»™t lÆ°á»£t, vá»›i hÆ¡n 3 triá»‡u cáº·p há»™i thoáº¡i. Sinh táº¡o cÃ¢u há»i (QG) nháº±m sinh táº¡o cÃ¢u há»i cho trÆ°á»›c má»™t ngá»¯ cáº£nh Ä‘áº§u vÃ o. Äá»ƒ cÃ³ Ä‘Æ°á»£c Ä‘á»§ máº«u huáº¥n luyá»‡n, chÃºng tÃ´i sá»­ dá»¥ng táº­p dá»¯ liá»‡u Quasar-T (Dhingra et al., 2017) Ä‘Æ°á»£c tiá»n xá»­ lÃ½ bá»Ÿi Lin et al. (2018), vÃ  sau Ä‘Ã³ sinh táº¡o cÃ¡c cáº·p tÃ i liá»‡u-cÃ¢u há»i Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c 119K máº«u huáº¥n luyá»‡n (chi tiáº¿t trong Phá»¥ lá»¥c D.1). ÄÆ¡n giáº£n hÃ³a vÄƒn báº£n nháº±m sá»­a Ä‘á»•i vÄƒn báº£n phá»©c táº¡p thÃ nh cÃ¡c chuá»—i vá»›i ngá»¯ phÃ¡p vÃ  lá»±a chá»n tá»« Ä‘Æ¡n giáº£n. Jiang et al. (2020) xÃ¢y dá»±ng má»™t corpus gá»“m 677K cÃ¢u phá»©c táº¡p-Ä‘Æ¡n giáº£n vá»›i sá»± liÃªn káº¿t sá»­a Ä‘á»•i. Nhiá»‡m vá»¥ paraphrase sinh táº¡o má»™t dáº¡ng bá» máº·t thay tháº¿ trong cÃ¹ng ngÃ´n ngá»¯ thá»ƒ hiá»‡n cÃ¹ng ná»™i dung ngá»¯ nghÄ©a. ChÃºng tÃ´i Ã¡p dá»¥ng QQP3 Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i cÃ³ nguá»“n gá»‘c tá»« diá»…n Ä‘Ã n há»i Ä‘Ã¡p cá»™ng Ä‘á»“ng Quora, vá»›i 147K cáº·p tÃ­ch cá»±c.

Baseline. ChÃºng tÃ´i xem xÃ©t ba nhÃ³m mÃ´ hÃ¬nh lÃ m baseline, bao gá»“m cáº£ kiáº¿n trÃºc AR vÃ  NAR. NhÃ³m phÆ°Æ¡ng phÃ¡p Ä‘áº§u tiÃªn Ã¡p dá»¥ng kiáº¿n trÃºc encoder-decoder (Cho et al., 2014) Ä‘Æ°á»£c nghiÃªn cá»©u ká»¹ cho cÃ¡c nhiá»‡m vá»¥ S EQ2SEQ, vÃ  chÃºng tÃ´i tiáº¿n hÃ nh thÃ­ nghiá»‡m trÃªn hai mÃ´ hÃ¬nh phá»• biáº¿n: GRU vá»›i attention vÃ  Transformer (Vaswani et al., 2017). NhÃ³m thá»© hai lÃ  mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c (PLM) Ä‘Æ°á»£c tinh chá»‰nh, trong Ä‘Ã³ GPT2 (Radford et al., 2019) Ä‘Ã£ chá»©ng minh thÃ nh cÃ´ng lá»›n trong háº§u háº¿t táº¥t cáº£ cÃ¡c nhiá»‡m vá»¥ S EQ2SEQ. ChÃºng tÃ´i tiáº¿p tá»¥c so sÃ¡nh vá»›i GPV AE (Du et al., 2022), tÄƒng cÆ°á»ng T5 Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c (Raffel et al., 2020) vá»›i V AE Ä‘á»ƒ cáº£i thiá»‡n tÃ­nh Ä‘a dáº¡ng sinh táº¡o. Äá»‘i vá»›i nhÃ³m baseline cuá»‘i cÃ¹ng, chÃºng tÃ´i xem xÃ©t LevT (Gu et al., 2019), má»™t mÃ´ hÃ¬nh iterative NAR máº¡nh Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i. Táº¥t cáº£ cÃ¡c baseline Ä‘Æ°á»£c huáº¥n luyá»‡n theo hÆ°á»›ng dáº«n trong cÃ¡c bÃ i bÃ¡o cá»§a há», vÃ  chi tiáº¿t cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y trong Phá»¥ lá»¥c D.2.

2Äá»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh NAR, yT Ä‘Æ°á»£c sao chÃ©p Ä‘á»“ng nháº¥t tá»« cÃ¢u nguá»“n hoáº·c embedding token unk (Gu et al., 2018); Ä‘á»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n, yT Ä‘Æ°á»£c láº¥y máº«u tá»« phÃ¢n phá»‘i chuáº©n N(0;I).
3https://www.kaggle.com/c/quora-question-pairs
5

--- TRANG 6 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
Báº£ng 1: Káº¿t quáº£ tá»•ng thá»ƒ cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhau trÃªn cÃ¡c nhiá»‡m vá»¥ S EQ2SEQ khÃ¡c nhau. NhÃ³m phÆ°Æ¡ng phÃ¡p Ä‘áº§u tiÃªn Ã¡p dá»¥ng kiáº¿n trÃºc encoder-decoder tá»± há»“i quy vÃ  nhÃ³m thá»© hai lÃ  mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c Ä‘Æ°á»£c tinh chá»‰nh (cÅ©ng theo cÃ¡ch tá»± há»“i quy) trong khi nhÃ³m cuá»‘i cÃ¹ng lÃ  khÃ´ng tá»± há»“i quy. Káº¿t quáº£ tá»‘t nháº¥t Ä‘Æ°á»£c in Ä‘áº­m , vÃ  káº¿t quáº£ tá»‘t nháº¥t khÃ´ng cÃ³ PLM Ä‘Æ°á»£c gáº¡ch dÆ°á»›i .
Nhiá»‡m vá»¥ PhÆ°Æ¡ng phÃ¡p BLEU"R-L" Score" dist-1"selfB#/ div-4" Len
Äá»‘i thoáº¡i
miá»n má»Ÿ GRU-attention0.0068 0.1054 0.4128 0.8998 0.8008/0.1824 4.46
Transformer-base0.0189 0.1039 0.4781 0.7493 0.3698/0.6472 19.5
GPT2-base FT0.0108 0.1508 0.5279 0.9194 0.0182/0.9919 16.8
GPT2-large FT0.0125 0.1002 0.5293 0.9244 0.0213/0.9938 16.8
GPV AE-T50.0110 0.1009 0.4317 0.5625 0.3560/0.5551 20.1
NAR-LevTz0.0158 0.0550 0.4760 0.9726 0.7103/0.1416 4.11
DIFFU SEQ(Ours)z0.0139 0.1056 0.5131 0.9467 0.0144 /0.9971 13.6
Sinh táº¡o
cÃ¢u há»i GRU-attention0.0651 0.2617 0.5222 0.7930 0.9999/0.3178 10.1
Transformer-base0.1663 0.3441 0.6307 0.9309 0.3265/0.7720 10.3
GPT2-base FT0.0741 0.2714 0.6052 0.9602 0.1403 /0.9216 10.0
GPT2-large FT0.1110 0.3215 0.6346 0.9670 0.2910/0.8062 9.96
GPV AE-T50.1251 0.3390 0.6308 0.9381 0.3567/0.7282 11.4
NAR-LevTz0.0930 0.2893 0.5491 0.8914 0.9830/0.4776 6.93
DIFFU SEQ(Ours)z0.1731 0.3665 0.6123 0.9056 0.2789 /0.8103 11.5
ÄÆ¡n giáº£n hÃ³a
vÄƒn báº£n GRU-attention0.3256 0.5602 0.7871 0.8883 0.9998/0.3313 18.9
Transformer-base0.2693 0.4907 0.7381 0.8886 0.6924/0.5095 18.5
GPT2-base FT0.3083 0.5461 0.8021 0.9439 0.5444/0.6047 16.1
GPT2-large FT0.2693 0.5111 0.7882 0.9464 0.6042/0.5876 15.4
GPV AE-T50.3392 0.5828 0.8166 0.9308 0.8147/0.4355 18.5
NAR-LevTz0.2052 0.4402 0.7254 0.9715 0.9907/0.3271 8.31
DIFFU SEQ(Ours)z0.3622 0.5849 0.8126 0.9264 0.4642 /0.6604 17.7
Paraphrase GRU-attention0.1894 0.5129 0.7763 0.9423 0.9958/0.3287 8.30
Transformer-base0.2722 0.5748 0.8381 0.9748 0.4483/0.7345 11.2
GPT2-base FT0.1980 0.5212 0.8246 0.9798 0.5480/0.6245 9.67
GPT2-large FT0.2059 0.5415 0.8363 0.9819 0.7325/0.5020 9.53
GPV AE-T50.2409 0.5886 0.8466 0.9688 0.5604/0.6169 9.60
NAR-LevTz0.2268 0.5795 0.8344 0.9790 0.9995/0.3329 8.85
DIFFU SEQ(Ours)z0.2413 0.5880 0.8365 0.9807 0.2732 /0.8641 11.2

ÄÃ¡nh giÃ¡. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ cÃ¡c chuá»—i Ä‘Æ°á»£c sinh táº¡o tá»« hai khÃ­a cáº¡nh: cháº¥t lÆ°á»£ng vÃ  tÃ­nh Ä‘a dáº¡ng. Äá»ƒ Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng, chÃºng tÃ´i sá»­ dá»¥ng metric chuáº©n BLEU (Papineni et al., 2002) vÃ  Ä‘iá»ƒm ROUGE (Lin, 2004). VÃ¬ cÃ¡c metric dá»±a trÃªn Ä‘á»™ tÆ°Æ¡ng tá»± chuá»—i cÃ³ thá»ƒ khÃ´ng thá»a mÃ£n Ä‘á»‘i vá»›i sinh táº¡o má»Ÿ, chÃºng tÃ´i cÅ©ng bÃ¡o cÃ¡o BERTScore (Zhang et al., 2019) Ä‘Ã¡nh giÃ¡ Ä‘á»™ tÆ°Æ¡ng tá»± ngá»¯ nghÄ©a giá»¯a cÃ¡c cÃ¢u Ä‘Æ°á»£c sinh táº¡o vÃ  tham chiáº¿u. Chi tiáº¿t cÃ³ trong Phá»¥ lá»¥c D.4. Äiá»ƒm cao hÆ¡n cá»§a BLEU, ROUGE vÃ  BERTScore pháº£n Ã¡nh hiá»‡u suáº¥t tá»‘t hÆ¡n. Äá»‘i vá»›i tÃ­nh Ä‘a dáº¡ng, chÃºng tÃ´i sá»­ dá»¥ng unigram riÃªng biá»‡t (dist-1) Ä‘á»ƒ Ä‘o tÃ­nh Ä‘a dáº¡ng ná»™i bá»™ trong má»—i cÃ¢u Ä‘Æ°á»£c sinh táº¡o, trong Ä‘Ã³ dist-1 tháº¥p hÆ¡n chá»‰ ra ráº±ng cÃ¢u Ä‘Æ°á»£c sinh táº¡o chá»©a nhiá»u tá»« láº·p láº¡i hÆ¡n. Äá»‘i vá»›i Ä‘Ã¡nh giÃ¡ tÃ­nh Ä‘a dáº¡ng cáº¥p Ä‘á»™ cÃ¢u, chÃºng tÃ´i xem xÃ©t self-BLEU cáº¥p Ä‘á»™ cÃ¢u (Zhu et al., 2018) Ä‘á»ƒ Ä‘o sá»± chá»“ng chÃ©o n-gram giá»¯a táº­p há»£p Ä‘áº§u ra w.r.t má»™t cÃ¢u nguá»“n, vÃ  chÃºng tÃ´i thÃªm vÃ o sá»­ dá»¥ng 4-gram Ä‘a dáº¡ng (div-4) (Deshpande et al., 2019) Ä‘á»ƒ Ä‘o tá»· lá»‡ 4-gram riÃªng biá»‡t trong táº­p há»£p Ä‘áº§u ra trÃªn má»—i cÃ¢u nguá»“n. Self-BLEU tháº¥p hÆ¡n vÃ  div-4 cao hÆ¡n gá»£i Ã½ tÃ­nh Ä‘a dáº¡ng sinh táº¡o cao hÆ¡n. Äá»‘i vá»›i má»—i phÆ°Æ¡ng phÃ¡p bao gá»“m DIFFU SEQ, chÃºng tÃ´i sinh táº¡o 3 máº«u cho má»—i cÃ¢u nguá»“n Ä‘á»ƒ tÃ­nh toÃ¡n cÃ¡c metric Ä‘a dáº¡ng.

Chi tiáº¿t triá»ƒn khai. D IFFU SEQ cá»§a chÃºng tÃ´i dá»±a trÃªn 12 lá»›p Transformer vá»›i 12 attention head, trong Ä‘Ã³ time step embedding Ä‘Æ°á»£c cáº¯m tÆ°Æ¡ng tá»± nhÆ° position embedding. Äá»™ dÃ i chuá»—i tá»‘i Ä‘a lÃ  128, vá»›i chiá»u embedding d= 128, cÃ¡c bÆ°á»›c khuáº¿ch tÃ¡n T= 2;000 vÃ  lá»‹ch nhiá»…u cÄƒn báº­c hai. Äá»ƒ giáº£m sinh táº¡o ngoÃ i tá»« vá»±ng, chÃºng tÃ´i Ã¡p dá»¥ng Byte Pair Encoding (Sennrich et al., 2016) Ä‘á»ƒ xÃ¢y dá»±ng tá»« vá»±ng. Sau khi thá»±c hiá»‡n diversity beam
6

--- TRANG 7 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
Báº£ng 2: Äáº§u ra máº«u trong táº­p kiá»ƒm tra QQP, cÃ³ Ä‘iá»u kiá»‡n trÃªn cÃ¹ng x.
CÃ¢u gá»‘c : LÃ m tháº¿ nÃ o Ä‘á»ƒ tÃ´i káº¿t báº¡n. Tham chiáº¿u paraphrase : LÃ m tháº¿ nÃ o Ä‘á»ƒ káº¿t báº¡n ?
GPT2-large tinh chá»‰nh GPV AE-T5 DIFFU SEQ
LÃ m tháº¿ nÃ o tÃ´i cÃ³ thá»ƒ káº¿t báº¡n? LÃ m tháº¿ nÃ o tÃ´i cÃ³ thá»ƒ káº¿t báº¡n? LÃ m tháº¿ nÃ o tÃ´i cÃ³ thá»ƒ káº¿t báº¡n tá»‘t hÆ¡n?
LÃ m tháº¿ nÃ o tÃ´i cÃ³ thá»ƒ káº¿t báº¡n? LÃ m tháº¿ nÃ o Ä‘á»ƒ tÃ´i káº¿t báº¡n? LÃ m tháº¿ nÃ o tÃ´i cÃ³ thá»ƒ káº¿t báº¡n?
LÃ m tháº¿ nÃ o tÃ´i cÃ³ thá»ƒ káº¿t báº¡n? LÃ m tháº¿ nÃ o tÃ´i cÃ³ thá»ƒ káº¿t báº¡n? Báº¡n káº¿t báº¡n nhÆ° tháº¿ nÃ o?
LÃ m tháº¿ nÃ o tÃ´i cÃ³ thá»ƒ káº¿t báº¡n? CÃ¡ch tá»‘t nháº¥t Ä‘á»ƒ káº¿t báº¡n lÃ  gÃ¬? CÃ¡ch tá»‘t nháº¥t Ä‘á»ƒ káº¿t báº¡n lÃ  gÃ¬?
LÃ m tháº¿ nÃ o Ä‘á»ƒ tÃ´i káº¿t báº¡n vÃ 
giá»¯ há»?CÃ¡ch tá»‘t nháº¥t Ä‘á»ƒ káº¿t báº¡n
vÃ  táº¡o ra báº¡n bÃ¨ lÃ  gÃ¬?LÃ m tháº¿ nÃ o tÃ´i cÃ³ thá»ƒ káº¿t báº¡n vÃ  lÃ m gÃ¬
Ä‘Ã³ hÆ¡n?

search (DBS) (Vijayakumar et al., 2016) cho mÃ´ hÃ¬nh Transformer-base vÃ  mÃ´ hÃ¬nh GPT, chÃºng tÃ´i tháº¥y ráº±ng DBS khÃ´ng pháº£i lÃºc nÃ o cÅ©ng thÃºc Ä‘áº©y tÃ­nh Ä‘a dáº¡ng hÆ¡n temperature sampling vÃ  do Ä‘Ã³ chÃºng tÃ´i liá»‡t kÃª cÃ¡c káº¿t quáº£ tÃ­nh Ä‘a dáº¡ng tá»‘t nháº¥t. ChÃºng tÃ´i tÃ­nh toÃ¡n cÃ¡c metric Ä‘á»™ chÃ­nh xÃ¡c cá»§a D IFFU SEQ sá»­ dá»¥ng MBR vá»›i kÃ­ch thÆ°á»›c máº«u á»©ng viÃªn jSj= 10. ThÃ­ nghiá»‡m Ä‘Æ°á»£c triá»ƒn khai trÃªn NVIDIA A100 Tensor Core GPU, vÃ  chÃºng tÃ´i sá»­ dá»¥ng 4 GPU Ä‘á»ƒ huáº¥n luyá»‡n vÃ  GPU Ä‘Æ¡n Ä‘á»ƒ láº¥y máº«u.

4.2 Káº¾T QUáº¢ CHÃNH
NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 1, chÃºng tÃ´i káº¿t luáº­n ráº±ng D IFFU SEQ Ä‘áº¡t Ä‘Æ°á»£c cháº¥t lÆ°á»£ng sinh táº¡o tÆ°Æ¡ng Ä‘Æ°Æ¡ng hoáº·c tháº­m chÃ­ cao hÆ¡n so vá»›i cÃ¡c baseline máº¡nh. Äá»“ng thá»i, D IFFU SEQ liÃªn tá»¥c chá»©ng minh tÃ­nh Æ°u viá»‡t trong viá»‡c sinh táº¡o cÃ¡c Ä‘áº§u ra Ä‘a dáº¡ng cho cÃ¹ng má»™t chuá»—i Ä‘áº§u vÃ o.

NhÆ° chÃºng ta cÃ³ thá»ƒ tháº¥y tá»« Báº£ng 1, D IFFU SEQ tháº¯ng cuá»™c thi trÃªn Ã­t nháº¥t má»™t metric cháº¥t lÆ°á»£ng so vá»›i 6 baseline4 nhiá»‡m vá»¥. Máº·c dÃ¹ cÃ¡c mÃ´ hÃ¬nh NAR nhÆ° LevT Ä‘Ã´i khi cÅ©ng cÃ³ thá»ƒ vÆ°á»£t trá»™i hÆ¡n cÃ¡c baseline AR, chÃºng váº«n tá»¥t láº¡i sau D IFFU SEQ vá»›i khoáº£ng cÃ¡ch lá»›n (tá»©c lÃ  cáº£i thiá»‡n tÆ°Æ¡ng Ä‘á»‘i hÆ¡n 50% cho BLEU trong nhiá»‡m vá»¥ QG vÃ  R-L trong nhiá»‡m vá»¥ Dialogue). Tháº­m chÃ­ so vá»›i cÃ¡c mÃ´ hÃ¬nh GPT2 Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c rá»“i tinh chá»‰nh, D IFFU SEQ váº«n Ä‘áº¡t hiá»‡u suáº¥t vÆ°á»£t trá»™i hÆ¡n biáº¿n thá»ƒ base, vÃ  cÃ³ thá»ƒ so sÃ¡nh vá»›i biáº¿n thá»ƒ large, cÃ³ 8:2 láº§n tham sá»‘ hÆ¡n D IFFU SEQ. Nhá»¯ng káº¿t quáº£ thá»±c nghiá»‡m nÃ y há»— trá»£ Ä‘áº§y Ä‘á»§ cho cÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i trong Â§ 3, nÆ¡i chÃºng tÃ´i phÃ¢n tÃ­ch lÃ½ thuyáº¿t vá» tiá»m nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n trong viá»‡c mÃ´ hÃ¬nh hÃ³a cÃ¡c chuá»—i vÄƒn báº£n so vá»›i cÃ¡c mÃ´ hÃ¬nh AR cho Ä‘á»§ bÆ°á»›c khuáº¿ch tÃ¡n.

DIFFU SEQ, nhÆ° má»™t thÃ nh viÃªn cá»§a há» mÃ´ hÃ¬nh sinh táº¡o sÃ¢u, cÅ©ng thá»ƒ hiá»‡n kháº£ nÄƒng sinh táº¡o cÃ¡c chuá»—i cÃ³ tÃ­nh Ä‘a dáº¡ng cao. NhÆ° Ä‘Æ°á»£c gá»£i Ã½ bá»Ÿi self-BLEU (tháº¥p hÆ¡n lÃ  tá»‘t hÆ¡n) vÃ  div-4 (cao hÆ¡n lÃ  tá»‘t hÆ¡n), trong háº§u háº¿t táº¥t cáº£ cÃ¡c trÆ°á»ng há»£p, D IFFU SEQ vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i 4 baseline AR vá» tÃ­nh Ä‘a dáº¡ng cáº¥p Ä‘á»™ cÃ¢u (tá»©c lÃ  táº¡o ra cÃ¡c Ä‘áº§u ra Ä‘a dáº¡ng cho cÃ¹ng má»™t Ä‘áº§u vÃ o). Äá»‘i vá»›i tÃ­nh Ä‘a dáº¡ng trong lá»±a chá»n tá»« trong má»™t cÃ¢u, chÃºng tÃ´i xem xÃ©t dist-1: dist-1 cao hÆ¡n chá»‰ ra Ã­t láº·p láº¡i hÆ¡n trong má»™t cÃ¢u. NhÆ° chÃºng ta cÃ³ thá»ƒ tháº¥y tá»« Báº£ng 1, D IFFU SEQ cÃ³ Ã­t láº·p láº¡i hÆ¡n so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p encoder-decoder, nhÆ°ng váº«n tá»¥t láº¡i sau cÃ¡c mÃ´ hÃ¬nh GPT2 Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c (tÃ¬nh huá»‘ng tÆ°Æ¡ng tá»± vá»›i BERTScore). Nhá»¯ng káº¿t quáº£ nÃ y gá»£i Ã½ váº«n cÃ²n chá»— Ä‘á»ƒ cáº£i thiá»‡n (vÃ­ dá»¥: sá»­ dá»¥ng ká»¹ thuáº­t huáº¥n luyá»‡n trÆ°á»›c) trong lá»±a chá»n token cáº¥p Ä‘á»™ cá»§a cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n. KhÃ¡c vá»›i NAR-LevT, D IFFU SEQ khÃ´ng dá»±a vÃ o má»™t mÃ´-Ä‘un dá»± Ä‘oÃ¡n Ä‘á»™ dÃ i thÃªm mÃ  tá»± Ä‘á»™ng quyáº¿t Ä‘á»‹nh báº±ng padding token thay vÃ o Ä‘Ã³ vÃ  cÃ³ thá»ƒ sinh táº¡o cÃ¡c cÃ¢u Ä‘áº§u ra dÃ i hÆ¡n, Ä‘Æ°á»£c chá»‰ ra bá»Ÿi cá»™t cuá»‘i cÃ¹ng cho Ä‘á»™ dÃ i sinh táº¡o trung bÃ¬nh.

Trong Báº£ng 2, chÃºng tÃ´i cung cáº¥p vÃ­ dá»¥ Ä‘á»ƒ thá»ƒ hiá»‡n kháº£ nÄƒng sinh táº¡o máº«u Ä‘a dáº¡ng cá»§a D IFFU SEQ. Nhiá»u vÃ­ dá»¥ hÆ¡n cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y trong Phá»¥ lá»¥c D.5.

1 3 5 7 10 15 20
kÃ­ch thÆ°á»›c á»©ng viÃªn ||
0.300.310.320.330.340.350.36 BLEU
ÄÆ¡n giáº£n hÃ³a vÄƒn báº£n
DiffuSeq
GPT2-base
1 3 5 7 10 15 20
kÃ­ch thÆ°á»›c á»©ng viÃªn ||
0.190.200.210.220.230.240.25
Paraphrase
DiffuSeq
GPT2-large
HÃ¬nh 3: Sá»± tÄƒng cá»§a Ä‘iá»ƒm BLEU vá»›i
cÃ¡c kÃ­ch thÆ°á»›c á»©ng viÃªn khÃ¡c nhau jSj.
0.5 0.6 0.7 0.8 0.9div-40.060.080.100.120.140.16 BLEU
Sinh táº¡o cÃ¢u há»i
DiffuSeq
GPT2-base
GPT2-largeNAR-LevT
GPVAE-T5HÃ¬nh 4: Sá»± Ä‘Ã¡nh Ä‘á»•i giá»¯a cháº¥t lÆ°á»£ng vÃ 
tÃ­nh Ä‘a dáº¡ng (chi tiáº¿t trong Phá»¥ lá»¥c D.3).
7

--- TRANG 8 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
0 20 40 60 80 100QuÃ¡ trÃ¬nh sinh táº¡o %0.000.050.100.150.200.250.30 BLEU
DiffuSeq
NAR-LevT
DiffuSeq
NAR-LevT
0.00.20.40.60.81.0
div-4
ÄÆ¡n giáº£n hÃ³a vÄƒn báº£n
HÃ¬nh 5: ÄÆ°á»ng cong Ä‘iá»ƒm BLEU/div-4 theo
quÃ¡ trÃ¬nh sinh táº¡o (pháº§n trÄƒm cÃ¡c bÆ°á»›c).
100 500 1000 2000
BÆ°á»›c láº¥y máº«u0.0000.0250.0500.0750.1000.1250.150 BLEUGPT2-large BLEU
02468101214
Máº«u sinh táº¡o/giÃ¢y
GPT2-large speedSinh táº¡o cÃ¢u há»i HÃ¬nh 6: BLEU vÃ  tá»‘c Ä‘á»™ suy luáº­n
cá»§a D IFFU SEQ vÃ  GPT2-large.

4.3 PHÃ‚N TÃCH
ChÃºng tÃ´i tiáº¿n hÃ nh má»™t loáº¡t phÃ¢n tÃ­ch Ä‘á»ƒ Ä‘iá»u tra hiá»‡u quáº£ cá»§a cÃ¡c khÃ­a cáº¡nh khÃ¡c nhau trong D IFFU SEQ.

TÃ­nh Ä‘a dáº¡ng Ä‘áº£m báº£o cháº¥t lÆ°á»£ng. Sinh táº¡o vÄƒn báº£n cháº¥t lÆ°á»£ng cao vá»›i tÃ­nh Ä‘a dáº¡ng cao lÃ  má»™t yÃªu cáº§u quan trá»ng cho nhiá»u á»©ng dá»¥ng sinh táº¡o vÄƒn báº£n vÃ  sá»± Ä‘Ã¡nh Ä‘á»•i giá»¯a cháº¥t lÆ°á»£ng vÃ  tÃ­nh Ä‘a dáº¡ng luÃ´n lÃ  má»‘i quan tÃ¢m quan trá»ng trong cÃ¡c nhiá»‡m vá»¥ NLG má»Ÿ (Zhang et al., 2021). KhÃ¡c vá»›i cÃ¡c mÃ´ hÃ¬nh AR phá»¥ thuá»™c vÃ o chiáº¿n lÆ°á»£c giáº£i mÃ£ nhÆ° temperature vÃ  nucleus sampling (Holtzman et al., 2019) vÃ  cÃ¡c mÃ´ hÃ¬nh V AE láº¥y máº«u biáº¿n latent tá»« Gaussian Prior, lá»£i tháº¿ tá»± nhiÃªn cá»§a D IFFU SEQ lÃ  sinh táº¡o cÃ¡c cÃ¢u khÃ¡c nhau cÃ¹ng vá»›i má»™t loáº¡t nhiá»…u Gaussian ngáº«u nhiÃªn. Trong HÃ¬nh 4, chÃºng tÃ´i lÃ m sÃ¡ng tá» ráº±ng D IFFU SEQ cÃ³ sá»± Ä‘Ã¡nh Ä‘á»•i tá»‘t hÆ¡n giá»¯a cháº¥t lÆ°á»£ng sinh táº¡o (BLEU) vÃ  tÃ­nh Ä‘a dáº¡ng cáº¥p Ä‘á»™ cÃ¢u (div-4). á» Ä‘Ã¢y chÃºng tÃ´i tiáº¿p tá»¥c chá»©ng minh ráº±ng tÃ­nh Ä‘a dáº¡ng cao Ä‘Æ°á»£c cung cáº¥p bá»Ÿi D IFFU SEQ cÃ³ thá»ƒ Ä‘Æ°á»£c biáº¿n thÃ nh cháº¥t lÆ°á»£ng tá»‘t hÆ¡n.

MBR lÃ  má»™t chiáº¿n lÆ°á»£c phá»• biáº¿n Ä‘á»ƒ cáº£i thiá»‡n cháº¥t lÆ°á»£ng sinh táº¡o báº±ng cÃ¡ch tá»•ng há»£p vÃ  xáº¿p háº¡ng cÃ¡c chuá»—i á»©ng viÃªn, vÃ  chÃºng tÃ´i tháº¥y ráº±ng cáº­n trÃªn cá»§a MBR Ä‘Æ°á»£c quyáº¿t Ä‘á»‹nh bá»Ÿi má»™t táº­p há»£p á»©ng viÃªn Ä‘a dáº¡ng. Äá»ƒ xÃ¡c thá»±c Ä‘iá»u nÃ y, chÃºng tÃ´i Ä‘á»“ng thá»i Ã¡p dá»¥ng MBR trÃªn cáº£ D IFFU SEQ vÃ  GPT2 vá»›i cÃ¡c kÃ­ch thÆ°á»›c á»©ng viÃªn khÃ¡c nhau jSj. Káº¿t quáº£ Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 3. NhÆ° chÃºng ta cÃ³ thá»ƒ tháº¥y, D IFFU SEQ tá»¥t láº¡i sau GPT2 khi khÃ´ng sá»­ dá»¥ng MBR (jSj= 1) hoáº·c vá»›i má»™t táº­p há»£p á»©ng viÃªn nhá» (jSj= 3). Tuy nhiÃªn, khi jSj tÄƒng, D IFFU SEQ báº¯t Ä‘áº§u vÆ°á»£t trá»™i hÆ¡n GPT2 vá»›i khoáº£ng cÃ¡ch ngÃ y cÃ ng tÄƒng. LÃ½ do lÃ  cÃ¡c mÃ´ hÃ¬nh tá»± há»“i quy nhÆ° GPT2 cÃ³ xu hÆ°á»›ng sinh táº¡o cÃ¡c á»©ng viÃªn ráº¥t giá»‘ng nhau (nhÆ° Ä‘Ã£ tháº£o luáº­n trong Â§ 4.2), Ä‘iá»u nÃ y cáº£n trá»Ÿ hiá»‡u quáº£ cá»§a MBR. Khi jSj tÄƒng lÃªn 20, DIFFU SEQ váº«n cho tháº¥y xu hÆ°á»›ng tÄƒng tá»‘t hÆ¡n GPT2. CÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i cÅ©ng nháº¥n máº¡nh táº§m quan trá»ng cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p xáº¿p háº¡ng tá»‘t hÆ¡n trong nghiÃªn cá»©u khuáº¿ch tÃ¡n.

PhÃ¢n tÃ­ch theo tá»«ng bÆ°á»›c so vá»›i Iterative NAR. Cho má»‘i liÃªn há»‡ lÃ½ thuyáº¿t cÆ¡ báº£n giá»¯a iterative NAR vÃ  D IFFU SEQ Ä‘Æ°á»£c tháº£o luáº­n trong Â§ 3, chÃºng tÃ´i Ä‘iá»u tra thá»±c nghiá»‡m hÃ nh vi cá»§a LevT vÃ  D IFFU SEQ báº±ng cÃ¡ch phÃ¢n tÃ­ch cÃ¡c Ä‘Æ°á»ng cong cháº¥t lÆ°á»£ng (tá»©c lÃ  BLEU) vÃ  tÃ­nh Ä‘a dáº¡ng (tá»©c lÃ  div-4) theo tá»«ng bÆ°á»›c cá»§a chÃºng. NhÆ° Ä‘Æ°á»£c gá»£i Ã½ trong HÃ¬nh 5, LevT tÄƒng máº¡nh vá» cháº¥t lÆ°á»£ng ngay tá»« Ä‘áº§u quÃ¡ trÃ¬nh sinh táº¡o, vÃ  nhanh chÃ³ng cháº­m láº¡i trong quÃ¡ trÃ¬nh tinh chá»‰nh káº¿ tiáº¿p. NhÆ°ng D IFFU SEQ hÃ nh xá»­ khÃ¡c biá»‡t, vá»›i Ä‘iá»ƒm BLEU tÄƒng cháº­m lÃºc Ä‘áº§u, tÄƒng nhanh khi quÃ¡ trÃ¬nh khuáº¿ch tÃ¡n tiáº¿n triá»ƒn vÃ  cuá»‘i cÃ¹ng vÆ°á»£t qua LevT. CÅ©ng quan sÃ¡t tháº¥y ráº±ng tÃ­nh Ä‘a dáº¡ng cá»§a cáº£ LevT vÃ  D IFFU SEQ Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh á»Ÿ giai Ä‘oáº¡n ráº¥t sá»›m báº¥t ká»ƒ viá»‡c tinh chá»‰nh hoáº·c khuáº¿ch tÃ¡n tÆ°Æ¡ng lai, nÆ¡i D IFFU SEQ liÃªn tá»¥c vÆ°á»£t trá»™i hÆ¡n LevT vá» tÃ­nh Ä‘a dáº¡ng á»Ÿ báº¥t ká»³ giai Ä‘oáº¡n nÃ o cá»§a quÃ¡ trÃ¬nh sinh táº¡o. ChÃºng tÃ´i Ä‘oÃ¡n ráº±ng D IFFU SEQ khÃ¡m phÃ¡ nhiá»u káº¿t quáº£ cÃ³ thá»ƒ hÆ¡n á»Ÿ ná»­a Ä‘áº§u cá»§a quÃ¡ trÃ¬nh sinh táº¡o, vÃ  sá»›m há»™i tá»¥ vá» má»™t sá»‘ á»©ng viÃªn tiá»m nÄƒng khi nÃ³ gáº§n cuá»‘i cÃ¡c bÆ°á»›c. Trong trÆ°á»ng há»£p nÃ y, D IFFU SEQ cho tháº¥y kháº£ nÄƒng tÃ­nh Ä‘áº¿n cáº£ cháº¥t lÆ°á»£ng sinh táº¡o vÃ  tÃ­nh Ä‘a dáº¡ng, vÃ  Ä‘Ã¢y lÃ  kháº£ nÄƒng mÃ  cÃ¡c mÃ´ hÃ¬nh iterative-NAR vÃ  tháº­m chÃ­ AR khÃ´ng thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c, do cÃ¡c mÃ´ hÃ¬nh há»c khÃ¡c biá»‡t.

Tá»‘c Ä‘á»™ suy luáº­n. Tá»‘c Ä‘á»™ láº¥y máº«u cháº­m lÃ  má»™t trong nhá»¯ng má»‘i quan tÃ¢m lá»›n vá» cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n. á» Ä‘Ã¢y chÃºng tÃ´i cá»‘ Ä‘á»‹nh sá»‘ bÆ°á»›c khuáº¿ch tÃ¡n trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n cho D IFFU SEQ trong khi thu háº¹p cÃ¡c bÆ°á»›c suy luáº­n theo DDIM (Song et al., 2020). NhÆ° chÃºng ta cÃ³ thá»ƒ tháº¥y tá»« HÃ¬nh 6, khi giáº£m suy luáº­n xuá»‘ng 1.000 bÆ°á»›c khuáº¿ch tÃ¡n trÃªn GPU Ä‘Æ¡n, D IFFU SEQ Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»ƒm BLEU cao hÆ¡n GPT2-large nhÆ°ng Ä‘Äƒng kÃ½ tá»‘c Ä‘á»™ suy luáº­n gáº§n hÆ¡n vá»›i GPT2-large.

Hiá»‡u quáº£ cá»§a huáº¥n luyá»‡n chung. Trong D IFFU SEQ, cÃ¡c biá»ƒu diá»…n cá»§a wx vÃ  wy Ä‘Æ°á»£c huáº¥n luyá»‡n chung sá»­ dá»¥ng cÃ¹ng hÃ m embedding E MB() (Ä‘Æ°á»£c nÃªu trong Â§ 3). Äá»ƒ xÃ¡c thá»±c hiá»‡u quáº£
8

--- TRANG 9 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
Báº£ng 3: Káº¿t quáº£ cÃ³ hoáº·c khÃ´ng cÃ³ huáº¥n luyá»‡n chung cho nhiá»‡m vá»¥ Sinh táº¡o cÃ¢u há»i.
CÃ i Ä‘áº·t BLEU"R-L" Score"selfB#/ div-4"
DIFFU SEQ(w/o reranking) 0.1567 0.3484 0.5947 0.2789/0.8103
Cá»‘ Ä‘á»‹nh E MB(wx) nhÆ° Ä‘Ã£ huáº¥n luyá»‡n trÆ°á»›c 0.0110 0.0687 0.3769 0.0174/0.9376

cá»§a chiáº¿n lÆ°á»£c huáº¥n luyá»‡n chung nÃ y, chÃºng tÃ´i so sÃ¡nh nÃ³ vá»›i chiáº¿n lÆ°á»£c huáº¥n luyá»‡n thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n text-to-image (Nichol et al., 2022; Ramesh et al., 2022). Cá»¥ thá»ƒ, chÃºng tÃ´i tÃ¡ch rá»i viá»‡c huáº¥n luyá»‡n E MB(wx) vÃ  E MB(wy) báº±ng cÃ¡ch thay tháº¿ E MB(wx) báº±ng cÃ¡c biá»ƒu diá»…n Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« mÃ´ hÃ¬nh BERT-tiny Ä‘Ã£ huáº¥n luyá»‡n trÆ°á»›c (Turc et al., 2019). Tá»« Báº£ng 3, chÃºng tÃ´i tháº¥y ráº±ng chiáº¿n lÆ°á»£c huáº¥n luyá»‡n tÃ¡ch rá»i dáº«n Ä‘áº¿n hiá»‡u suáº¥t kÃ©m.

5 CÃ”NG TRÃŒNH LIÃŠN QUAN
CÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n cho mÃ´ hÃ¬nh hÃ³a vÄƒn báº£n. Sinh táº¡o Text-to-Image sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n Ä‘Ã£ phÃ¡t triá»ƒn nhiá»u á»©ng dá»¥ng tiá»m nÄƒng. CÃ¡c mÃ´ hÃ¬nh nhÆ° Imagen (Saharia et al., 2022b) vÃ  DALL-E (Ramesh et al., 2022) thÆ°á»ng lÃ  hai giai Ä‘oáº¡n dá»±a vÃ o cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c, yÃªu cáº§u sá»± liÃªn káº¿t giá»¯a cÃ¡c vector embedding tá»« hai nguá»“n. GLIDE (Nichol et al., 2022) khÃ¡m phÃ¡ mÃ´ hÃ¬nh khuáº¿ch tÃ¡n vá»›i hÆ°á»›ng dáº«n khÃ´ng cáº§n bá»™ phÃ¢n loáº¡i (Ho & Salimans, 2022) báº±ng cÃ¡ch thiáº¿t láº­p thang hÆ°á»›ng dáº«n trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. KhÃ´ng gian Ä‘Ã­ch cá»§a cÃ¡c mÃ´ hÃ¬nh nÃ y khÃ´ng pháº£i lÃ  khÃ´ng gian vÄƒn báº£n rá»i ráº¡c mÃ  lÃ  cÃ¡c vector á»•n Ä‘á»‹nh cá»§a giÃ¡ trá»‹ pixel. CÃ³ nhá»¯ng cÃ´ng trÃ¬nh khÃ¡c vá» khuáº¿ch tÃ¡n trong sinh táº¡o vÄƒn báº£n, nhÆ°ng chÃºng bÃ¡m vÃ o kiáº¿n trÃºc encoder-decoder gá»‘c vÃ  quÃ¡ trÃ¬nh khuáº¿ch tÃ¡n Ä‘Æ°á»£c xen káº½ trÃªn decoder (Savinov et al., 2021), hoáº·c khÃ´ng gian latent (Yu et al., 2022).

Äá»‘i vá»›i sinh táº¡o vÄƒn báº£n sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n, Hoogeboom et al. (2021) giá»›i thiá»‡u khuáº¿ch tÃ¡n Ä‘a thá»©c cho sinh táº¡o vÄƒn báº£n cáº¥p Ä‘á»™ kÃ½ tá»±, nhiá»…u phÃ¢n loáº¡i tiáº¿n Ä‘Æ°á»£c Ã¡p dá»¥ng thÃ´ng qua ma tráº­n chuyá»ƒn tiáº¿p Markov. Austin et al. (2021) tá»•ng quÃ¡t hÃ³a cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n vÄƒn báº£n rá»i ráº¡c báº±ng cÃ¡ch giá»›i thiá»‡u tráº¡ng thÃ¡i háº¥p thá»¥ ([MASK]). Tuy nhiÃªn, cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n rá»i ráº¡c cÃ³ thá»ƒ gáº·p pháº£i váº¥n Ä‘á» vá» tá»· lá»‡ cá»§a cÃ¡c vector hÃ ng one-hot, vÃ  chÃºng chá»‰ sinh táº¡o máº«u vÄƒn báº£n má»™t cÃ¡ch khÃ´ng Ä‘iá»u kiá»‡n trong khÃ´ng gian rá»i ráº¡c. Diffusion-LM (Li et al., 2022) vÃ  Analog Bits (Chen et al., 2022) Ä‘á» xuáº¥t má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ má»›i Ä‘Æ°á»£c khuáº¿ch tÃ¡n trÃªn cÃ¡c biá»ƒu diá»…n latent liÃªn tá»¥c, vá»›i cÃ¡c hÃ m Ã¡nh xáº¡ khÃ¡c nhau káº¿t ná»‘i khÃ´ng gian rá»i ráº¡c vÃ  liÃªn tá»¥c cá»§a vÄƒn báº£n. So vá»›i cÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i, chÃºng tÃ´i táº­p trung vÃ o cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n S EQ2SEQ cho sinh táº¡o vÄƒn báº£n trong khÃ´ng gian liÃªn tá»¥c vÃ  cÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i lÃ  Ä‘áº§u tiÃªn khÃ¡m phÃ¡ cÃ i Ä‘áº·t nÃ y theo hiá»ƒu biáº¿t tá»‘t nháº¥t cá»§a chÃºng tÃ´i.

CÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n cho sinh táº¡o cÃ³ Ä‘iá»u kiá»‡n. LiÃªn quan Ä‘áº¿n conditional-V AE (Zhao et al., 2017), chÃºng ta cÃ³ thá»ƒ xem xÃ©t Ä‘áº§u vÃ o x Ä‘Æ°á»£c mÃ£ hÃ³a latent nhÆ° má»™t Ä‘iá»u kiá»‡n. Diffusion-LM (Li et al., 2022) Ã¡p dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p plug-and-play (Dathathri et al., 2020) Ä‘á»ƒ tá»•ng há»£p cÃ¡c rÃ ng buá»™c chi tiáº¿t trÃªn cÃ¡c cÃ¢u Ä‘Æ°á»£c sinh táº¡o, nhÆ°ng nÃ³ tháº¥t báº¡i trong viá»‡c Ä‘iá»u kiá»‡n trÃªn toÃ n bá»™ cÃ¢u nguá»“n trong cÃ¡c nhiá»‡m vá»¥ S EQ2SEQ. LÆ°u Ã½ ráº±ng phÆ°Æ¡ng phÃ¡p sinh táº¡o cÃ³ thá»ƒ Ä‘iá»u khiá»ƒn nÃ y lÃ  trá»±c giao vá»›i D IFFSEQ cá»§a chÃºng tÃ´i, nÃ³i cÃ¡ch khÃ¡c, chÃºng tÃ´i cÃ³ thá»ƒ tiáº¿p tá»¥c thÃªm cÃ¡c rÃ ng buá»™c cÃ³ hÆ°á»›ng dáº«n bá»™ phÃ¢n loáº¡i trÃªn Ä‘áº§u ra S EQ2SEQ Ä‘á»ƒ tiáº¿p tá»¥c Ä‘iá»u khiá»ƒn sinh táº¡o vÄƒn báº£n. CÃ³ nhá»¯ng mÃ´ hÃ¬nh khuáº¿ch tÃ¡n cÃ³ Ä‘iá»u kiá»‡n khÃ¡c vá» dá»± Ä‘oÃ¡n chuá»—i thá»i gian nhÆ° CSDI (Tashiro et al., 2021) hoáº·c sinh táº¡o Ã¢m thanh nhÆ° WaveGrad (Chen et al., 2021), nhÆ°ng cÃ¡c Ä‘iá»u kiá»‡n lá»›p cá»§a chÃºng thÆ°á»ng lÃ  cÃ¡c thuá»™c tÃ­nh dá»… mÃ´ hÃ¬nh hÃ³a, trong khi cÃ¡c vÄƒn báº£n ngá»¯ cáº£nh nhÆ° Ä‘iá»u kiá»‡n phá»©c táº¡p hÆ¡n nhiá»u.

6 Káº¾T LUáº¬N
ChÃºng tÃ´i Ä‘á» xuáº¥t D IFFU SEQ Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c nhiá»‡m vá»¥ S EQ2SEQ theo cÃ¡ch khuáº¿ch tÃ¡n, cÃ³ chá»©a tiá»m nÄƒng máº¡nh máº½ Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c sá»± Ä‘Ã¡nh Ä‘á»•i cháº¥t lÆ°á»£ng vÃ  tÃ­nh Ä‘a dáº¡ng sinh táº¡o tá»‘t hÆ¡n. Kháº£ nÄƒng nÃ y cho phÃ©p cÃ¡c Ä‘áº·c tÃ­nh thuáº­n lá»£i cá»§a D IFFU SEQ Ä‘á»ƒ tiáº¿p tá»¥c nÃ¢ng cao cháº¥t lÆ°á»£ng káº¿t quáº£ cuá»‘i cÃ¹ng, báº±ng cÃ¡ch táº­n dá»¥ng thuáº­t toÃ¡n giáº£i mÃ£ rá»§i ro Bayes tá»‘i thiá»ƒu. BÃªn cáº¡nh Ä‘Ã³, chÃºng tÃ´i káº¿t ná»‘i lÃ½ thuyáº¿t cÃ¡c mÃ´ hÃ¬nh AR vÃ  NAR vá»›i D IF-FUSEQ, vÃ  cho tháº¥y ráº±ng D IFFU SEQ lÃ  má»™t má»Ÿ rá»™ng máº¡nh máº½ cá»§a mÃ´ hÃ¬nh iterative-NAR. CÃ¡c káº¿t quáº£ thá»±c nghiá»‡m chá»©ng minh ráº±ng D IFFU SEQ cÅ©ng lÃ  má»™t mÃ´ hÃ¬nh máº¡nh máº½ cho sinh táº¡o vÄƒn báº£n, khá»›p hoáº·c tháº­m chÃ­ vÆ°á»£t qua cÃ¡c mÃ´ hÃ¬nh AR, iterative NAR, vÃ  mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c quy mÃ´ lá»›n cáº¡nh tranh vá» cháº¥t lÆ°á»£ng vÃ  tÃ­nh Ä‘a dáº¡ng. Cho tiáº¿n bá»™ háº¡n cháº¿ cá»§a cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n hiá»‡n táº¡i vá» sinh táº¡o vÄƒn báº£n, nghiÃªn cá»©u cá»§a chÃºng tÃ´i Ä‘á» cáº­p Ä‘áº¿n nhá»¯ng thÃ nh tá»±u Ä‘áº§y há»©a háº¹n bá»Ÿi má»™t mÃ´ hÃ¬nh há»c chuá»—i Ä‘áº¿n chuá»—i má»›i nhÆ° váº­y.
9

--- TRANG 10 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
Lá»œI Cáº¢M Æ N
ChÃºng tÃ´i muá»‘n cáº£m Æ¡n cÃ¡c reviewer áº©n danh vÃ  cÃ¡c Ä‘á»“ng nghiá»‡p khÃ¡c vÃ¬ lá»i khuyÃªn quÃ½ bÃ¡u cá»§a há», vÃ  chÃºng tÃ´i cÅ©ng thá»«a nháº­n nhá»¯ng ná»— lá»±c cá»§a Chenxin An trong viá»‡c cáº­p nháº­t káº¿t quáº£ sinh táº¡o cho mÃ´ hÃ¬nh Transformer-base trÃªn cÃ¡c nhiá»‡m vá»¥ QG vÃ  Paraphrasing. CÃ´ng trÃ¬nh nÃ y Ä‘Æ°á»£c há»— trá»£ má»™t pháº§n bá»Ÿi á»¦y ban Khoa há»c vÃ  CÃ´ng nghá»‡ ThÆ°á»£ng Háº£i (Sá»‘ hiá»‡u Grant 21DZ1100100) vÃ  lÆ°á»£c Ä‘á»“ nghiÃªn cá»©u chung cá»§a Quá»¹ Khoa há»c Tá»± nhiÃªn Quá»‘c gia Trung Quá»‘c (NSFC) vÃ  Há»™i Ä‘á»“ng TÃ i trá»£ NghiÃªn cá»©u (RGC) dÆ°á»›i sá»‘ hiá»‡u grant N HKU714/21.

TÃ€I LIá»†U THAM KHáº¢O
Jacob Austin, Daniel D Johnson, Jonathan Ho, Daniel Tarlow, vÃ  Rianne van den Berg. Structured denoising diffusion models in discrete state-spaces. Advances in Neural Information Processing Systems, 2021.

Nanxin Chen, Yu Zhang, Heiga Zen, Ron J Weiss, Mohammad Norouzi, vÃ  William Chan. Wavegrad: Estimating gradients for waveform generation. Trong International Conference on Learning Representations, ICLR, 2021.

Ting Chen, Ruixiang Zhang, vÃ  Geoffrey Hinton. Analog bits: Generating discrete data using diffusion models with self-conditioning. arXiv preprint arXiv:2208.04202, 2022.

Kyunghyun Cho, Bart van Merrienboer, Ã‡aglar GÃ¼lÃ§ehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, vÃ  Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. Trong Conference on Empirical Methods in Natural Language Processing, EMNLP, 2014.

Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank, Piero Molino, Jason Yosinski, vÃ  Rosanne Liu. Plug and play language models: A simple approach to controlled text generation. Trong 8th International Conference on Learning Representations, ICLR, 2020.

Aditya Deshpande, Jyoti Aneja, Liwei Wang, Alexander G Schwing, vÃ  David Forsyth. Fast, diverse and accurate image captioning guided by part-of-speech. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 10695â€“10704, 2019.

Bhuwan Dhingra, Kathryn Mazaitis, vÃ  William W Cohen. Quasar: Datasets for question answering by search and reading. arXiv preprint arXiv:1707.03904, 2017.

Laurent Dinh, Jascha Sohl-Dickstein, vÃ  Samy Bengio. Density estimation using real nvp. Trong International Conference on Learning Representations, ICLR, 2017.

Wanyu Du, Jianqiao Zhao, Liwei Wang, vÃ  Yangfeng Ji. Diverse text generation via variational encoder-decoder models with gaussian process priors. Trong Proceedings of 6th Workshop on Structured Prediction for NLP of the Association for Computational Linguistics, ACL, 2022.

Marjan Ghazvininejad, Omer Levy, Yinhan Liu, vÃ  Luke Zettlemoyer. Mask-predict: Parallel decoding of conditional masked language models. Trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 6112â€“6121. Association for Computational Linguistics, 2019.

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, vÃ  Yoshua Bengio. Generative adversarial nets. Trong Advances in Neural Information Processing Systems, 2014.

Jiatao Gu, James Bradbury, Caiming Xiong, Victor OK Li, vÃ  Richard Socher. Non-autoregressive neural machine translation. Trong International Conference on Learning Representations, ICLR, 2018.

Jiatao Gu, Changhan Wang, vÃ  Junbo Zhao. Levenshtein transformer. Advances in Neural Information Processing Systems, 2019.

10

--- TRANG 11 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
Jonathan Ho vÃ  Tim Salimans. Classifier-free diffusion guidance. arXiv preprint arXiv:2207.12598, 2022.

Jonathan Ho, Ajay Jain, vÃ  Pieter Abbeel. Denoising diffusion probabilistic models. Advances in Neural Information Processing Systems, 2020.

Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, vÃ  Yejin Choi. The curious case of neural text degeneration. Trong International Conference on Learning Representations, ICLR, 2019.

Emiel Hoogeboom, Didrik Nielsen, Priyank Jaini, Patrick ForrÃ©, vÃ  Max Welling. Argmax flows and multinomial diffusion: Learning categorical distributions. Advances in Neural Information Processing Systems, 2021.

Fei Huang, Tianhua Tao, Hao Zhou, Lei Li, vÃ  Minlie Huang. On the learning of non-autoregressive transformers. Trong International Conference on Machine Learning, ICML, 2022.

Chao Jiang, Mounica Maddela, Wuwei Lan, Yang Zhong, vÃ  Wei Xu. Neural crf model for sentence alignment in text simplification. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL, 2020.

Diederik P. Kingma vÃ  Max Welling. Auto-Encoding Variational Bayes. Trong International Conference on Learning Representations, ICLR, 2014.

Philipp Koehn. Statistical significance tests for machine translation evaluation. Trong Proceedings of the 2004 conference on empirical methods in natural language processing, pp. 388â€“395, 2004.

Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, vÃ  Bryan Catanzaro. Diffwave: A versatile diffusion model for audio synthesis. Trong International Conference on Learning Representations, ICLR, 2020.

Xiang Lisa Li, John Thickstun, Ishaan Gulrajani, Percy Liang, vÃ  Tatsunori B Hashimoto. Diffusion-lm improves controllable text generation. arXiv preprint arXiv:2205.14217, 2022.

Chin-Yew Lin. Rouge: A package for automatic evaluation of summaries. Trong Text summarization branches out, 2004.

Yankai Lin, Haozhe Ji, Zhiyuan Liu, vÃ  Maosong Sun. Denoising distantly supervised open-domain question answering. Trong Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL, 2018.

Luke Metz, Ben Poole, David Pfau, vÃ  Jascha Sohl-Dickstein. Unrolled generative adversarial networks. Trong International Conference on Learning Representations, ICLR, 2017.

Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, vÃ  Mark Chen. Glide: Towards photorealistic image generation and editing with text-guided diffusion models. Trong International Conference on Machine Learning, ICML, 2022.

Alexander Quinn Nichol vÃ  Prafulla Dhariwal. Improved denoising diffusion probabilistic models. Trong International Conference on Machine Learning, ICML, 2021.

Kishore Papineni, Salim Roukos, Todd Ward, vÃ  Wei-Jing Zhu. Bleu: a method for automatic evaluation of machine translation. Trong Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, ACL, 2002.

Lihua Qian, Hao Zhou, Yu Bao, Mingxuan Wang, Lin Qiu, Weinan Zhang, Yong Yu, vÃ  Lei Li. Glancing transformer for non-autoregressive neural machine translation. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), 2021.

Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, vÃ  Ilya Sutskever. Language models are unsupervised multitask learners. 2019.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, vÃ  Peter J. Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140):1â€“67, 2020.

11

--- TRANG 12 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, vÃ  Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 2022.

Chitwan Saharia, William Chan, Huiwen Chang, Chris Lee, Jonathan Ho, Tim Salimans, David Fleet, vÃ  Mohammad Norouzi. Palette: Image-to-image diffusion models. Trong ACM SIGGRAPH 2022 Conference Proceedings, 2022a.

Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S Sara Mahdavi, Rapha Gontijo Lopes, vÃ  cá»™ng sá»±. Photorealistic text-to-image diffusion models with deep language understanding. arXiv preprint arXiv:2205.11487, 2022b.

Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen, vÃ  Xi Chen. Improved techniques for training gans. Trong Advances in Neural Information Processing Systems, 2016.

Nikolay Savinov, Junyoung Chung, Mikolaj Binkowski, Erich Elsen, vÃ  Aaron van den Oord. Step-unrolled denoising autoencoders for text generation. Trong International Conference on Learning Representations, ICLR, 2021.

Rico Sennrich, Barry Haddow, vÃ  Alexandra Birch. Neural machine translation of rare words with subword units. Trong Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1715â€“1725. Association for Computational Linguistics, 2016.

Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, vÃ  Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. Trong International Conference on Machine Learning, ICML, 2015.

Jiaming Song, Chenlin Meng, vÃ  Stefano Ermon. Denoising diffusion implicit models. Trong International Conference on Learning Representations, ICLR, 2020.

Yang Song vÃ  Stefano Ermon. Generative modeling by estimating gradients of the data distribution. Advances in Neural Information Processing Systems, 32, 2019.

Yusuke Tashiro, Jiaming Song, Yang Song, vÃ  Stefano Ermon. Csdi: Conditional score-based diffusion models for probabilistic time series imputation. Advances in Neural Information Processing Systems, 2021.

Iulia Turc, Ming-Wei Chang, Kenton Lee, vÃ  Kristina Toutanova. Well-read students learn better: The impact of student initialization on knowledge distillation. CoRR, abs/1908.08962, 2019.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Åukasz Kaiser, vÃ  Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 2017.

Ashwin K Vijayakumar, Michael Cogswell, Ramprasath R Selvaraju, Qing Sun, Stefan Lee, David Crandall, vÃ  Dhruv Batra. Diverse beam search: Decoding diverse solutions from neural sequence models. arXiv preprint arXiv:1610.02424, 2016.

P Yu, S Xie, X Ma, B Jia, B Pang, R Gao, Y Zhu, S-C Zhu, vÃ  YN Wu. Latent diffusion energy-based model for interpretable text modeling. Trong International Conference on Machine Learning, ICML, 2022.

Hugh Zhang, Daniel Duckworth, Daphne Ippolito, vÃ  Arvind Neelakantan. Trading off diversity and quality in natural language generation. Trong Proceedings of the Workshop on Human Evaluation of NLP Systems (HumEval), pp. 25â€“33. Association for Computational Linguistics, 2021.

Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, vÃ  Yoav Artzi. Bertscore: Evaluating text generation with bert. Trong International Conference on Learning Representations, ICLR, 2019.

12

--- TRANG 13 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
Tiancheng Zhao, Ran Zhao, vÃ  Maxine Eskenazi. Learning discourse-level diversity for neural dialog models using conditional variational autoencoders. Trong Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, 2017.

Hao Zhou, Tom Young, Minlie Huang, Haizhou Zhao, Jingfang Xu, vÃ  Xiaoyan Zhu. Commonsense knowledge aware conversation generation with graph attention. Trong International Joint Conference on Artificial Intelligence, IJCAI, 2018.

Yaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan Zhang, Jun Wang, vÃ  Yong Yu. Texygen: A benchmarking platform for text generation models. Trong The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, pp. 1097â€“1100, 2018.

13

--- TRANG 14 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
A DERIVATION Má»¤C TIÃŠU Cá»¦A DIFFU SEQ
MÃ´ hÃ¬nh khuáº¿ch tÃ¡n ná»•i tiáº¿ng vÃ¬ kháº£ nÄƒng Ä‘áº¡t Ä‘Æ°á»£c sá»± Ä‘Ã¡nh Ä‘á»•i giá»¯a tÃ­nh linh hoáº¡t vÃ  tÃ­nh tractable cá»§a phÃ¢n phá»‘i xÃ¡c suáº¥t cá»§a mÃ´ hÃ¬nh, so vá»›i GAN, V AE vÃ  cÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn Flow. Theo Ho et al. (2020); Nichol & Dhariwal (2021); Song et al. (2020), chÃºng tÃ´i Ä‘á»‹nh nghÄ©a má»™t cÃ¡ch cÃ³ há»‡ thá»‘ng quÃ¡ trÃ¬nh nhiá»…u tiáº¿n vÃ  quÃ¡ trÃ¬nh khá»­ nhiá»…u ngÆ°á»£c trÃªn khÃ´ng gian latent liÃªn tá»¥c z.

QuÃ¡ trÃ¬nh nhiá»…u tiáº¿n lÃ  Ä‘á»ƒ lÃ m loáº¡n cáº¥u trÃºc cá»§a dá»¯ liá»‡u z0. z0 cuá»‘i cÃ¹ng Ä‘Æ°á»£c thay Ä‘á»•i thÃ nh nhiá»…u Gaussian má»™t pháº§n vá»›i yTN(0;I) thÃ´ng qua nhiá»…u loáº¡n ngáº«u nhiÃªn tiáº¿n T-bÆ°á»›c
q(ztjzt1) =N(zt;p
1tzt1;tI); (10)

vá»›i t= 1;2;:::;T vÃ  ft2(0;1)gT
t=1 lÃ  lá»‹ch phÆ°Æ¡ng sai. Gá»i t= 1t vÃ  t=Qt
i=1i, chÃºng ta cÃ³:
zt=ptzt1+p
1tt1=ptt1zt2+p
1tt1t2
=:::=ptz0+p
1t;(11)

trong Ä‘Ã³  biá»ƒu thá»‹ nhiá»…u Gaussian. Cuá»‘i cÃ¹ng, q(ztjz0) =N(zt;ptz0;(1t)I). ChÃºng tÃ´i sá»­ dá»¥ng lá»‹ch nhiá»…u sqrt trong Diffusion-LM (Li et al., 2022), tá»©c lÃ , t= 1p
t=T+s vá»›i s lÃ  má»™t háº±ng sá»‘ nhá» á»Ÿ Ä‘áº§u má»©c nhiá»…u. QuÃ¡ trÃ¬nh ngÆ°á»£c sau Ä‘Ã³ khá»­ nhiá»…u zt, nháº±m khÃ´i phá»¥c z0 gá»‘c, vÃ  Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ :
p(z0:T) :=p(zT)TY
t=1p(zt1jzt); p(zt1jzt) =N(zt1;(zt;t);(zt;t)): (12)

Viá»‡c há»c p Ä‘Æ°á»£c dá»±a trÃªn mÃ´ hÃ¬nh khuáº¿ch tÃ¡n DIFFU SEQ cá»§a chÃºng tÃ´i: f(zt;t), trong Ä‘Ã³ () vÃ  () lÃ  tham sá»‘ hÃ³a dá»± Ä‘oÃ¡n cá»§a mean vÃ  standard variation cá»§a q(ztjzt1) trong quÃ¡ trÃ¬nh tiáº¿n. Sá»­ dá»¥ng quy táº¯c Bayes:
q(zt1jzt;z0) =q(ztjzt1;z0)q(zt1jz0)
q(ztjz0)(13)

Thay tháº¿ Eq. (11) vÃ o Ä‘Ã³ vÃ  chÃºng ta cÃ³ thá»ƒ nháº­n Ä‘Æ°á»£c mean Ä‘Æ°á»£c tham sá»‘ hÃ³a cá»§a q(zt1jzt;z0):
t(zt;z0) =pt(1t1)
1tzt+pt1t
1tz0; (14)

vÃ  Ä‘á»ƒ ngáº¯n gá»n, chÃºng tÃ´i rÃºt ngáº¯n há»‡ sá»‘ cá»§a zt vÃ  z0 thÃ nh U vÃ  E tÆ°Æ¡ng á»©ng.

ChÃºng tÃ´i cÃ³ thá»ƒ sá»­ dá»¥ng cáº­n dÆ°á»›i biáº¿n thiÃªn Ä‘á»ƒ tá»‘i Æ°u hÃ³a negative log-likelihood E[logp(x0)]
LVLB. Má»¥c tiÃªu cÃ³ thá»ƒ Ä‘Æ°á»£c viáº¿t láº¡i thÃ nh má»™t tá»• há»£p cá»§a má»™t sá»‘ term KL-divergence vÃ  entropy theo Sohl-Dickstein et al. (2015).

LVLB=LT+LT1++L0=Eq(z1:Tjz0)"
logq(zTjz0)
p(zT)+TX
t=2logq(zt1jz0;zt)
p(zt1jzt)
+ logq(z0jwxy)
p(z0jz1)logp(wxyjz0)#
:(15)

Vá»›i 1tT1, chÃºng tÃ´i tÃ­nh toÃ¡n tham sá»‘ hÃ³a cá»§a Lt báº±ng cÃ¡ch thay tháº¿ Eq. (14) Ä‘á»ƒ minimize sá»± khÃ¡c biá»‡t tá»« t vÃ  f theo Ho et al. (2020):
Lt=Ez0
logq(ztjz0;zt+1)
p(ztjzt+1)
=Ez01
Cjjt(zt;z0)(zt;t)jj2
=Ez01
CjjUzt+Ez0(Uzt+Ef(zt;t))jj2
=E
CEz0[jjz0f(zt;t)jj2];(16)

14

--- TRANG 15 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
trong Ä‘Ã³ C= 2jjjj2 lÃ  má»™t háº±ng sá»‘ Ä‘á»™c láº­p máº¥t mÃ¡t. Sau Ä‘Ã³ viá»‡c tá»‘i Æ°u hÃ³a máº¥t mÃ¡t huáº¥n luyá»‡n minLVLB cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘Æ¡n giáº£n hÃ³a hÆ¡n nhÆ° sau:
min
"
jj(zT)jj2+TX
t=2jjz0f(zt;t)jj2+jjEMB(wxy)f(z1;1)jj2logp(wxyjz0)#
!min
"TX
t=2jjz0f(zt;t)jj2+jjEMB(wxy)f(z1;1)jj2logp(wxyjz0)#
!min
"TX
t=2jjy0~f(zt;t)jj2+jjEMB(wy)~f(z1;1)jj2+R(jjz0jj2)#
:
(17)

B CÃC MÃ” HÃŒNH Äá»’ Há»ŒA Cá»¦A AR, FULLY NAR, ITERATIVE NAR VÃ€ DIFFU SEQ
ChÃºng tÃ´i báº¯t Ä‘áº§u tá»« bÃ i toÃ¡n sinh táº¡o chuá»—i cÃ³ Ä‘iá»u kiá»‡n, nháº±m há»c má»™t xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n p(wy1:njwx) vá»›i wx vÃ  wy. CÃ¡c mÃ´ hÃ¬nh AR há»c p(wy1:njwx) báº±ng phÃ¢n tÃ­ch tá»± há»“i quy dá»±a trÃªn ngá»¯ cáº£nh trÃ¡i:
pAR(wy1:njwx) =p(wy1jwx)
|{z}
dá»± Ä‘oÃ¡n ban Ä‘áº§u Y
i=1;:::;n1p(wyi+1jwy1:i;wx)
|{z}
dá»± Ä‘oÃ¡n ngá»¯ cáº£nh trÃ¡i tiáº¿n bá»™; (18)

bao gá»“m má»™t dá»± Ä‘oÃ¡n ban Ä‘áº§u vÃ  má»™t quÃ¡ trÃ¬nh dá»± Ä‘oÃ¡n ngá»¯ cáº£nh trÃ¡i tá»± há»“i quy, trong khi cÃ¡c mÃ´ hÃ¬nh fully-NAR (Gu et al., 2018; Qian et al., 2021) há»c xÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n cho trÆ°á»›c giáº£ Ä‘á»‹nh Ä‘á»™c láº­p Ä‘á»ƒ suy luáº­n nhanh:
pfully-NAR (wy1:njwx) =Y
i=1;:::;np(wyijwx): (19)

Äá»ƒ lÃ m má»™t phÃ©p tÆ°Æ¡ng tá»± tá»‘t hÆ¡n vá»›i cÃ¡c mÃ´ hÃ¬nh AR vÃ  NAR, chÃºng tÃ´i sá»­ dá»¥ng má»™t cÃ¡ch khÃ´ng máº¥t mÃ¡t Ä‘á»ƒ cÃ´ng thá»©c hÃ³a cÃ¡c mÃ´ hÃ¬nh iterative NAR (Gu et al., 2019; Ghazvininejad et al., 2019) báº±ng cÃ¡ch giá»›i thiá»‡u má»™t loáº¡t cÃ¡c chuá»—i trung gian wy1:K1;wyK=wy nhÆ°:
piter-NAR (wy1:njwx) =X
wy1;:::;wyK1p(wy1jwx)Y
k=1:::K1p(wyk+1jwy
k;wx)
=X
wy1;:::;wyK1p(wy1jwx)Y
k=1:::K1p(wyk+1jwy
k;wx)
=X
wy1;:::;wyK1Y
i=1:::np(wy1;ijwx)
|{z}
dá»± Ä‘oÃ¡n ban Ä‘áº§u Y
k=1::K1Y
i=1:::np(wyk+1;ijwyk;1:n;wx)
| {z }
dá»± Ä‘oÃ¡n ngá»¯ cáº£nh Ä‘áº§y Ä‘á»§ tiáº¿n bá»™ (20)

NghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y (Huang et al., 2022) cho tháº¥y cÃ³ má»™t khoáº£ng cÃ¡ch gá»i lÃ  tÆ°Æ¡ng quan tá»•ng cÃ³ Ä‘iá»u kiá»‡n giá»¯a cÃ¡c mÃ´ hÃ¬nh há»c AR vÃ  fully-NAR, vÃ¬ phÃ¢n tÃ­ch máº¥t mÃ¡t cá»§a cÃ¡c mÃ´ hÃ¬nh NAR. Khoáº£ng cÃ¡ch nÃ y chá»‹u trÃ¡ch nhiá»‡m chÃ­nh cho viá»‡c giáº£m hiá»‡u suáº¥t tá»« mÃ´ hÃ¬nh AR sang NAR. Tuy nhiÃªn, khi so sÃ¡nh iter-NAR, Eq. (20), vá»›i cÃ¡c mÃ´ hÃ¬nh AR, cáº£ hai Ä‘á»u cÃ³ thá»ƒ Ä‘Æ°á»£c phÃ¢n tÃ­ch thÃ nh má»™t term dá»± Ä‘oÃ¡n ban Ä‘áº§u vÃ  má»™t quÃ¡ trÃ¬nh dá»± Ä‘oÃ¡n tiáº¿n bá»™ dá»±a trÃªn ngá»¯ cáº£nh khÃ¡c nhau (tá»©c lÃ  ngá»¯ cáº£nh trÃ¡i trong AR vÃ  ngá»¯ cáº£nh Ä‘áº§y Ä‘á»§ trong iter-NAR). Sá»± khÃ¡c biá»‡t nhÆ° Ä‘Æ°á»£c chá»‰ ra bá»Ÿi Huang et al. (2022) do Ä‘Ã³ Ä‘Æ°á»£c Ä‘Ã³ng láº¡i trong iter-NAR giáº£ Ä‘á»‹nh Ä‘á»§ bÆ°á»›c. Báº±ng cÃ¡ch hiá»ƒn thá»‹ D IFFU SEQ lÃ  má»™t má»Ÿ rá»™ng cá»§a mÃ´ hÃ¬nh iter-NAR, chÃºng tÃ´i Ä‘Æ°a ra má»™t lá»i biá»‡n minh ráº±ng nÃ³ sáº½ khÃ´ng gáº·p pháº£i tÆ°Æ¡ng quan tá»•ng cÃ³ Ä‘iá»u kiá»‡n vÃ¬ cÃ¹ng lÃ½ do.

15

--- TRANG 16 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
Má»™t cÃ¡ch tháº³ng tháº¯n Ä‘á»ƒ cÃ´ng thá»©c hÃ³a cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n naive lÃ  giá»›i thiá»‡u má»™t loáº¡t cÃ¡c Ä‘áº·c trÆ°ng bá»‹ há»ng bá»Ÿi nhiá»…u Gaussian y1:T1;y0=y;yTN(0;I) trÃªn khÃ´ng gian liÃªn tá»¥c nhÆ°:
pdiffusion (wyjwx) =Z
yT;:::;y0p(wyjy0;wx)
|{z}
dá»± Ä‘oÃ¡n bÆ°á»›c cuá»‘i cÃ¹ng Y
t=T;:::; 1p(yt1jyt;wx)
|{z}
khuáº¿ch tÃ¡n ngá»¯ cáº£nh Ä‘áº§y Ä‘á»§ tiáº¿n bá»™ (21)
=Z
yT;:::;y0Y
i=1;:::;np(wyijy0;i;wx)Y
t=T;:::; 1Y
i=1;:::;np(yt1;ijyt;wx) (22)

trong Ä‘Ã³ p(yt1jyt;wx) mÃ´ táº£ quÃ¡ trÃ¬nh khuáº¿ch tÃ¡n trÃªn cÃ¡c biá»ƒu diá»…n liÃªn tá»¥c y. Tá»•ng sá»‘ bÆ°á»›c khuáº¿ch tÃ¡n Ä‘Æ°á»£c kÃ½ hiá»‡u lÃ  T. Sau Ä‘Ã³ chÃºng tÃ´i bá» qua phÃ¢n tÃ­ch Ä‘á»™c láº­p trÃªn wy vÃ  yt. Äá»ƒ Ã¡p dá»¥ng cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n trÃªn khÃ´ng gian rá»i ráº¡c, phÃ©p toÃ¡n lÃ m trÃ²n trong D IFFU SEQ Ã¡nh xáº¡ cÃ¡c vector liÃªn tá»¥c y thÃ nh wy rá»i ráº¡c cho má»—i bÆ°á»›c thá»i gian t, do Ä‘Ã³ chÃºng tÃ´i cÅ©ng giá»›i thiá»‡u cáº£ Ä‘áº·c trÆ°ng liÃªn tá»¥c y vÃ  vÄƒn báº£n rá»i ráº¡c wy Ä‘á»ƒ biá»ƒu diá»…n vÄƒn báº£n rá»i ráº¡c vÃ o Eq. (21):
p(wyjwx) =X
wyT;:::;wy1Z
yT;:::;y0p(wyTjyT;wx)Y
t=T1;:::;0p(wytjyt;wx)p(ytjwyt+1) (23)
=X
wyT;:::;wy1Z
yT;:::;y0p(wyjy0;wx)Y
t=T;:::; 1p(yt1jwyt)p(wytjyt;wx) (24)
=Z
yT;:::;y0p(wyjy0;wx)X
wyT;:::;wy1Y
t=T;:::; 1p(yt1jwyt)p(wytjyt;wx) (25)
=Z
yT;:::;y0p(wyjy0;wx)Y
t=T;:::; 1X
wytp(yt1jwyt)p(wytjyt;wx) (26)

Báº±ng cÃ¡ch sáº¯p xáº¿p láº¡i Eq. (23) vÃ  Eq. (24), chÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng D IFFU SEQ cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° má»™t dáº¡ng tá»•ng quÃ¡t hÃ³a hÆ¡n cá»§a iter-NAR trÆ°á»›c khi marginalize fyT;:::;y0g, trong Ä‘Ã³ Eq. (23) vÃ  Eq. (24) lÃ  tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i thá»© tá»± tÃ­nh toÃ¡n khÃ¡c nhau, máº·c dÃ¹ khá»Ÿi táº¡o khÃ¡c nhau cá»§a yT. Äá»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh NAR, yT Ä‘Æ°á»£c sao chÃ©p Ä‘á»“ng nháº¥t tá»« cÃ¢u nguá»“n hoáº·c embedding token unk (Gu et al., 2018); Ä‘á»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n, yT Ä‘Æ°á»£c láº¥y máº«u tá»« phÃ¢n phá»‘i chuáº©n N(0;I).

Cáº§n lÆ°u Ã½ ráº±ng khÃ´ng giá»‘ng nhÆ° cÃ¡c mÃ´ hÃ¬nh AR vÃ  fully NAR sinh táº¡o vÄƒn báº£n táº¥t cáº£ cÃ¹ng má»™t lÃºc, cÃ¡c mÃ´ hÃ¬nh iterative NAR vÃ  khuáº¿ch tÃ¡n cÃ³ Ä‘áº·c Ä‘iá»ƒm lÃ  má»™t quÃ¡ trÃ¬nh sinh táº¡o vÄƒn báº£n tá»± sá»­a chá»¯a. Viá»‡c so sÃ¡nh Ä‘á»“ há»a Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 7.

C Tá»ª DIFFU SEQ Äáº¾N ITERATIVE NAR VÃ€ CÃC MÃ” HÃŒNH KHUáº¾CH TÃN
Tá»« D IFFU SEQ Ä‘áº¿n Iterative NAR ChÃºng tÃ´i cho tháº¥y cÃ¡ch derive D IFFU SEQ thÃ nh mÃ´ hÃ¬nh non-autoregressive láº·p trÃªn khÃ´ng gian rá»i ráº¡c.

16

--- TRANG 17 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
...
.........
...AR
Fully-NAR
Iter -NARDif fuSeq
......
......
............
......
.........
...
...............
...
......
HÃ¬nh 7: CÃ¡c mÃ´ hÃ¬nh Ä‘á»“ há»a cá»§a AR, Fully NAR, iterative NAR vÃ  cÃ¡c mÃ´ hÃ¬nh D IFFU SEQ. Äá»ƒ Ä‘Æ¡n giáº£n, chÃºng tÃ´i bá» qua node nguá»“n wx. CÃ¡c node xÃ¡m chá»‰ ra sá»± phá»¥ thuá»™c vÃ o node nguá»“n trong khi cÃ¡c node tráº¯ng Ä‘á»™c láº­p vá»›i node nguá»“n.

pDIFFU SEQ(wyjwx)
=X
wyT;:::;wy1Z
yT;:::;y0p(wyjy0;wx)Y
t=T;:::; 1p(yt1jwyt)p(wytjyt;wx)
=X
wyT;:::;wy1Z
yT;:::;y0p(wyTjyT;wx)Y
t=T1;:::;0p(wytjyt;wx)p(ytjwyt+1)sáº¯p xáº¿p láº¡i tÃ­nh toÃ¡n
=X
wyT;:::;wy1p(wyTjyT;wx)Y
t=T1;:::;0Z
ytp(wytjyt;wx)p(ytjwyt+1)
=X
wyT;:::;wy1p(wyTjyT;wx)Y
t=T1;:::;0p(wytjwyt+1;wx)) marginalize qua y
=X
wy1;:::;wyK1p(wy1jwx)Y
k=1:::K1p(wyk+1jwyk;wx) liÃªn káº¿t t vÃ  k ngÆ°á»£c láº¡i.
=piter-NAR (wyjwx)

Tá»« D IFFU SEQ Ä‘áº¿n mÃ´ hÃ¬nh khuáº¿ch tÃ¡n ChÃºng tÃ´i cho tháº¥y cÃ¡ch derive D IFFU SEQ thÃ nh mÃ´ hÃ¬nh khuáº¿ch tÃ¡n tháº³ng tháº¯n trÃªn khÃ´ng gian liÃªn tá»¥c.

17

--- TRANG 18 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
pDIFFU SEQ(wyjwx)
=X
wyT;:::;wy1Z
yT;:::;y0p(wyjy0;wx)Y
t=T;:::; 1p(yt1jwyt)p(wytjyt;wx)
=Z
yT;:::;y0p(wyjy0;wx)Y
t=T;:::; 1X
wytp(yt1jwyt)p(wytjyt;wx)
=Z
yT;:::;y0p(wyjy0;wx)Y
t=T;:::; 1p(yt1jyt;wx) marginalize qua wy
=pdiffusion (wyjwx)

D CHI TIáº¾T THÃ NGHIá»†M
D.1 Xá»¬ LÃ Táº¬P Dá»® LIá»†U SINH Táº O CÃ‚U Há»I
Äá»ƒ xÃ¢y dá»±ng cÃ¡c cáº·p tÃ i liá»‡u-cÃ¢u há»i cháº¥t lÆ°á»£ng cao tá»« táº­p dá»¯ liá»‡u Quasar-T, bao gá»“m cÃ¡c triplet hdocument i;question;answer i, chÃºng tÃ´i trÃ­ch xuáº¥t cÃ¡c cáº·p hdocument i;question i náº¿u answer khá»›p chÃ­nh xÃ¡c vá»›i document i. Sau khi tiá»n xá»­ lÃ½, chÃºng tÃ´i cÃ³ Ä‘Æ°á»£c 119K cáº·p huáº¥n luyá»‡n tÃ i liá»‡u-cÃ¢u há»i.

D.2 CÃ€I Äáº¶T Cá»¦A CÃC BASELINE
ChÃºng tÃ´i so sÃ¡nh cÃ¡c cÃ i Ä‘áº·t cá»§a cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau, bao gá»“m sá»‘ lÆ°á»£ng tham sá»‘ vÃ  cÃ¡ch láº¥y máº«u cÃ¡c cÃ¢u Ä‘áº§u ra khÃ¡c nhau, nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 4. Äá»‘i vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p encoder-decoder dá»±a trÃªn GRU thuáº§n tÃºy, chÃºng tÃ´i khÃ´ng triá»ƒn khai thuáº­t toÃ¡n tÃ¬m kiáº¿m Ä‘a dáº¡ng trÃªn Ä‘Ã³, do Ä‘Ã³ tÃ­nh Ä‘a dáº¡ng cáº¥p Ä‘á»™ cÃ¢u cá»§a nÃ³ cÃ³ thá»ƒ ráº¥t kÃ©m. Äá»‘i vá»›i NAR-LevT, chÃºng tÃ´i Ä‘áº·t max iteration lÃ  9 vÃ  theo Ä‘iá»u kiá»‡n káº¿t thÃºc Ä‘Æ°á»£c Ä‘á» cáº­p trong bÃ i bÃ¡o gá»‘c. Äá»‘i vá»›i GPV AE-T5, chÃºng tÃ´i tune scalar Ä‘á»ƒ tÃ¬m sá»± Ä‘Ã¡nh Ä‘á»•i tá»‘t nháº¥t giá»¯a cháº¥t lÆ°á»£ng vÃ  tÃ­nh Ä‘a dáº¡ng trÃªn táº­p dev. CÃ¡c scalar cá»§a táº¥t cáº£ bá»‘n nhiá»‡m vá»¥ Ä‘Æ°á»£c Ä‘áº·t thÃ nh 2. ChÃºng tÃ´i triá»ƒn khai cÃ¡c baseline GPT2 sá»­ dá»¥ng HuggingFace Transformers vÃ  Ä‘á»‘i vá»›i baseline Transformer-base, chÃºng tÃ´i sá»­ dá»¥ng Fairseq.

Báº£ng 4: So sÃ¡nh cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau
MÃ´ hÃ¬nh # Tham sá»‘ MÃ´ hÃ¬nh há»c Nguá»“n Ä‘a dáº¡ng
GRU-attention 65M encoder-decoder -
Transformer-base 80M encoder-decoder Temperature/DBS
GPT2-base FT 117M pretrain-finetune Chiáº¿n lÆ°á»£c lai4
GPT2-large FT 774M pretrain-finetune Chiáº¿n lÆ°á»£c lai
GPV AE-T5 220M pretrain+V AE Gaussian sampling
NAR-LevT 80M non-autoregressive -
DIFFU SEQ 91M non-autoregressive Gaussian sampling

D.3 CÃ€I Äáº¶T ÄÃNH Äá»”I TÃNH ÄA Dáº NG VÃ€ CHáº¤T LÆ¯á»¢NG
ChÃºng tÃ´i liá»‡t kÃª cÃ¡c chi tiáº¿t Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c HÃ¬nh 4. Äá»‘i vá»›i GPV AE-T5, chÃºng tÃ´i Ä‘áº·t cÃ¡c scalar khÃ¡c nhau lÃ  1;2;3;4. Äá»‘i vá»›i DIFFU SEQ, chÃºng tÃ´i chá»n cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n á»Ÿ cÃ¡c bÆ°á»›c huáº¥n luyá»‡n khÃ¡c nhau Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c cÃ¡c Ä‘iá»ƒm Ä‘Ã¡nh Ä‘á»•i khÃ¡c nhau. Äá»‘i vá»›i cÃ¡c baseline khÃ¡c, khÃ´ng cÃ³ yáº¿u tá»‘ rÃµ rÃ ng Ä‘á»ƒ Ä‘iá»u khiá»ƒn sinh táº¡o Ä‘a dáº¡ng, vÃ¬ váº­y chÃºng tÃ´i Ä‘á»ƒ chÃºng nhÆ° cÃ¡c Ä‘iá»ƒm Ä‘Æ¡n trong hÃ¬nh.

4Bao gá»“m top-p sampling, temperature, diversity beam search (DBS) vÃ  v.v. Triá»ƒn khai sá»­ dá»¥ng HuggingFace Transformers https://github.com/huggingface/transformers
18

--- TRANG 19 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
D.4 METRICS
Äiá»ƒm BLEU Ä‘Æ°á»£c sá»­ dá»¥ng lÃ  sentence-level smoothed tá»« BLEU-1 Ä‘áº¿n 4, vÃ  Ä‘iá»ƒm ROUGE-L Ä‘Æ°á»£c sá»­ dá»¥ng lÃ  thá»‘ng kÃª dá»±a trÃªn longest common subsequence. Viá»‡c triá»ƒn khai dá»±a trÃªn NLTK5 vÃ  torchmetrics. CÃ¡c metric dá»±a trÃªn n-gram cÃ³ thá»ƒ tháº¥t báº¡i trong viá»‡c náº¯m báº¯t Ã½ nghÄ©a ngá»¯ nghÄ©a cá»§a cÃ¢u, vÃ¬ váº­y chÃºng tÃ´i xem xÃ©t sá»­ dá»¥ng BERTScore6. Cá»¥ thá»ƒ, chÃºng tÃ´i sá»­ dá»¥ng microsoft/deberta-xlarge-mnli Ä‘á»ƒ giÃºp BERTScore tÆ°Æ¡ng quan tá»‘t hÆ¡n vá»›i Ä‘iá»ƒm sá»‘ cá»§a con ngÆ°á»i.

D.5 Káº¾T QUáº¢ SINH Táº O
Äá»‘i vá»›i cÃ¡c nhiá»‡m vá»¥ khÃ¡c nhau, chÃºng tÃ´i liá»‡t kÃª má»™t sá»‘ vÃ­ dá»¥ sinh táº¡o. NhÆ° chÃºng ta cÃ³ thá»ƒ tháº¥y trong Báº£ng 5, Báº£ng 6 vÃ  Báº£ng 7, DIFFU SEQ cÃ³ xu hÆ°á»›ng sinh táº¡o Ä‘áº§u ra Ä‘a dáº¡ng, nhÆ°ng Ä‘Ã´i khi cÃ¢u khÃ´ng trÃ´i cháº£y nhÆ° GPT2 Ä‘Æ°á»£c tinh chá»‰nh.

Báº£ng 5: Äáº§u ra máº«u vá»›i seed ngáº«u nhiÃªn khÃ¡c nhau trong táº­p kiá»ƒm tra Dialogue.
PhÃ¡t ngÃ´n : MÃ u nhuá»™m kÃ©o dÃ i bao lÃ¢u?
Pháº£n há»“i : Chá»‰ lÃ m cÃ¡i nÃ y hai ngÃ y trÆ°á»›c, chÆ°a cháº¯c nÃ³ sáº½ phai nhÆ° tháº¿ nÃ o!
GPV AE-T5 NAR-LevT
*TÃ´i khÃ´ng cháº¯c, tÃ´i khÃ´ng cháº¯c. TÃ´i Ä‘Ã£ thá»­ nÃ³ vÃ i láº§n, nhÆ°ng tÃ´i khÃ´ng biáº¿t cháº¯c cháº¯n. TÃ´i Ä‘Ã£* ná»­a .
*TÃ´i khÃ´ng cháº¯c. TÃ´i khÃ´ng cháº¯c nÃ³ kÃ©o dÃ i bao lÃ¢u, tÃ´i cháº¯c nÃ³ sáº½ tá»‘t hÆ¡n. ÄÃ£ lÃ¢u rá»“i ká»ƒ tá»« khi* ná»­a .
*TÃ´i Ä‘Ã£ sá»­ dá»¥ng nÃ³ khoáº£ng má»™t nÄƒm rÆ°á»¡i. TÃ´i Ä‘Ã£ sá»­ dá»¥ng nÃ³ khoáº£ng má»™t nÄƒm rÆ°á»¡i.* ná»­a .
GPT2-large tinh chá»‰nh DIFFU SEQ
* Hai tuáº§n trong trÆ°á»ng há»£p cá»§a tÃ´i. * Khoáº£ng má»™t giá», 5 ngÃ y hoáº·c hÆ¡n.
* TÃ´i Ä‘Ã£ cÃ³ nÃ³ khoáº£ng má»™t nÄƒm. * 4 ngÃ y.
*MÃ u nhuá»™m cÃ³ thá»ƒ Ä‘á»ƒ khoáº£ng má»™t thÃ¡ng rá»“i báº¡n cÃ³ thá»ƒ rá»­a nÃ³.*TÃ´i khÃ´ng cháº¯c vá» Ä‘iá»u nÃ y, vá» cÃ¹ng loáº¡i thá»i gian.

Báº£ng 6: Äáº§u ra máº«u vá»›i seed ngáº«u nhiÃªn khÃ¡c nhau trong táº­p kiá»ƒm tra Question Generation.
PhÃ¡t biá»ƒu : YÃªn Nháº­t lÃ  Ä‘á»“ng tiá»n chÃ­nh thá»©c vÃ  duy nháº¥t Ä‘Æ°á»£c cÃ´ng nháº­n á»Ÿ Nháº­t Báº£n.
CÃ¢u há»i : Äá»“ng tiá»n Nháº­t Báº£n lÃ  gÃ¬?
GPV AE-T5 NAR-LevT
* Äá»“ng tiá»n nháº­t báº£n lÃ  gÃ¬ * ÄÆ¡n vá»‹ tiá»n tá»‡ cÆ¡ báº£n cá»§a Nháº­t Báº£n lÃ  gÃ¬ ?
* Äá»“ng tiá»n nháº­t báº£n lÃ  gÃ¬ * ÄÆ¡n vá»‹ tiá»n tá»‡ cÆ¡ báº£n cá»§a Nháº­t Báº£n lÃ  gÃ¬ ?
* Äá»“ng tiá»n nháº­t báº£n lÃ  gÃ¬ * ÄÆ¡n vá»‹ tiá»n tá»‡ cÆ¡ báº£n cá»§a Nháº­t Báº£n lÃ  gÃ¬ ?
GPT2-large tinh chá»‰nh DIFFU SEQ
* ÄÆ¡n vá»‹ tiá»n tá»‡ cÆ¡ báº£n cá»§a Nháº­t Báº£n lÃ  gÃ¬? * Äá»“ng tiá»n Nháº­t Báº£n lÃ  gÃ¬
* Äá»“ng tiá»n Nháº­t Báº£n lÃ  gÃ¬ * Quá»‘c gia nÃ o sá»­ dá»¥ng "yÃªn yÃªn" lÃ m tiá»n tá»‡
* ÄÆ¡n vá»‹ tiá»n tá»‡ cÆ¡ báº£n cá»§a Nháº­t Báº£n lÃ  gÃ¬? * ÄÆ¡n vá»‹ tiá»n tá»‡ cÆ¡ báº£n lÃ  gÃ¬?

5https://www.nltk.org/_modules/nltk/translate/bleu_score.html
6https://github.com/Tiiiger/bert_score
19

--- TRANG 20 ---
Xuáº¥t báº£n nhÆ° má»™t bÃ i bÃ¡o há»™i nghá»‹ táº¡i ICLR 2023
Báº£ng 7: Äáº§u ra máº«u vá»›i seed ngáº«u nhiÃªn khÃ¡c nhau trong táº­p kiá»ƒm tra Text Simplification.
CÃ¢u phá»©c táº¡p : Má»i ngÆ°á»i cÃ³ thá»ƒ tráº£i qua sá»± cÃ´ Ä‘Æ¡n vÃ¬ nhiá»u lÃ½ do, vÃ  nhiá»u sá»± kiá»‡n trong Ä‘á»i cÃ³ thá»ƒ gÃ¢y ra nÃ³, cháº³ng háº¡n nhÆ° thiáº¿u quan há»‡ báº¡n bÃ¨ trong thá»i thÆ¡ áº¥u vÃ  tuá»•i teen, hoáº·c sá»± váº¯ng máº·t vá» máº·t váº­t lÃ½ cá»§a nhá»¯ng ngÆ°á»i cÃ³ Ã½ nghÄ©a xung quanh má»™t ngÆ°á»i.
ÄÆ¡n giáº£n : Má»™t nguyÃªn nhÃ¢n cá»§a sá»± cÃ´ Ä‘Æ¡n lÃ  thiáº¿u báº¡n bÃ¨ trong thá»i thÆ¡ áº¥u vÃ  tuá»•i teen.
GPV AE-T5 NAR-LevT
*Má»i ngÆ°á»i cÃ³ thá»ƒ tráº£i qua sá»± cÃ´ Ä‘Æ¡n vÃ¬ nhiá»u lÃ½ do, vÃ  nhiá»u sá»± kiá»‡n trong Ä‘á»i cÃ³ thá»ƒ gÃ¢y ra nÃ³, cháº³ng háº¡n nhÆ° thiáº¿u quan há»‡ báº¡n bÃ¨ trong thá»i thÆ¡ áº¥u vÃ  tuá»•i teen, hoáº·c sá»± váº¯ng máº·t vá» máº·t váº­t lÃ½ cá»§a nhá»¯ng ngÆ°á»i cÃ³ Ã½ nghÄ©a xung quanh má»™t ngÆ°á»i*Má»i ngÆ°á»i cÃ³ thá»ƒ tráº£i qua reashapphapphapphapphapphappabout life reasit.
*Má»i ngÆ°á»i cÃ³ thá»ƒ tráº£i qua sá»± cÃ´ Ä‘Æ¡n vÃ¬ nhiá»u lÃ½ do, vÃ  nhiá»u sá»± kiá»‡n trong Ä‘á»i cÃ³ thá»ƒ gÃ¢y ra nÃ³, cháº³ng háº¡n nhÆ° thiáº¿u quan há»‡ báº¡n bÃ¨ trong thá»i thÆ¡ áº¥u vÃ  tuá»•i teen, hoáº·c sá»± váº¯ng máº·t vá» máº·t váº­t lÃ½ cá»§a nhá»¯ng ngÆ°á»i cÃ³ Ã½ nghÄ©a xung quanh má»™t ngÆ°á»i*Má»i ngÆ°á»i cÃ³ thá»ƒ tráº£i qua reashapphapphapphapphapphappabout life reasit.
*Má»i ngÆ°á»i cÃ³ thá»ƒ tráº£i qua sá»± cÃ´ Ä‘Æ¡n vÃ¬ nhiá»u lÃ½ do, vÃ  nhiá»u sá»± kiá»‡n trong Ä‘á»i cÃ³ thá»ƒ gÃ¢y ra nÃ³, cháº³ng háº¡n nhÆ° thiáº¿u quan há»‡ báº¡n bÃ¨ trong thá»i thÆ¡ áº¥u vÃ  tuá»•i teen, hoáº·c sá»± váº¯ng máº·t vá» máº·t váº­t lÃ½ cá»§a nhá»¯ng ngÆ°á»i cÃ³ Ã½ nghÄ©a xung quanh má»™t ngÆ°á»i*Má»i ngÆ°á»i cÃ³ thá»ƒ tráº£i qua reashapphapphapphapphapphappabout life reasit.
GPT2-large tinh chá»‰nh DIFFU SEQ
* Sá»± cÃ´ Ä‘Æ¡n cÃ³ thá»ƒ Ä‘Æ°á»£c gÃ¢y ra bá»Ÿi nhiá»u thá»©. * Nhiá»u sá»± kiá»‡n trong Ä‘á»i cÃ³ thá»ƒ gÃ¢y ra sá»± cÃ´ Ä‘Æ¡n
* Sá»± cÃ´ Ä‘Æ¡n cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n má»i ngÆ°á»i theo nhiá»u cÃ¡ch. *Má»i ngÆ°á»i cÅ©ng cÃ³ thá»ƒ ráº¥t tráº£i qua sá»± cÃ´ Ä‘Æ¡n vÃ¬ nhiá»u lÃ½ do.
* Sá»± cÃ´ Ä‘Æ¡n cÃ³ thá»ƒ Ä‘Æ°á»£c gÃ¢y ra bá»Ÿi nhiá»u thá»©. *Má»i ngÆ°á»i cÃ³ thá»ƒ tráº£i qua sá»± cÃ´ Ä‘Æ¡n vÃ¬ nhiá»u lÃ½ do, vÃ  nhiá»u sá»± kiá»‡n trong Ä‘á»i cÃ³ thá»ƒ, gÃ¢y ra nÃ³.

20

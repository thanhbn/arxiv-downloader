# 2308.12219.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/diffusion/2308.12219.pdf
# Kích thước tệp: 2176483 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Preprint
CÁC MÔ HÌNH NGÔN NGỮ KHUẾCH TÁN CÓ THỂ THỰC HIỆN NHIỀU 
NHIỆM VỤ VỚI VIỆC MỞ RỘNG QUY MÔ VÀ TINH CHỈNH THEO HƯỚNG DẪN
Jiasheng Ye1,2∗, Zaixiang Zheng†1, Yu Bao1, Lihua Qian1, Quanquan Gu‡1
1ByteDance Research2Fudan University
jsye23@m.fudan.edu.cn {zhengzaixiang,quanquan.gu}@bytedance.com
†Trưởng dự án‡Tác giả liên hệ
Mã nguồn có sẵn tại: https://github.com/yegcjs/DiffusionLLM

TÓM TẮT
Sự bùng nổ gần đây của AI tạo sinh được thúc đẩy bởi sức mạnh tạo sinh của các mô hình xác suất khuếch tán và khả năng mở rộng của các mô hình ngôn ngữ lớn (LLMs). Mặc dù có tiềm năng, vẫn chưa rõ liệu DIFFUSION-LLM có thể giải quyết các nhiệm vụ ngôn ngữ tổng quát tương đương với các đối tác tự hồi quy của chúng hay không. Bài báo này chứng minh rằng việc mở rộng quy mô các mô hình khuếch tán rời rạc có che dấu theo dữ liệu, kích thước và nhiệm vụ có thể hiệu quả làm cho chúng trở thành những người học ngôn ngữ mạnh mẽ. Chúng tôi giới thiệu DIFFUSION-LLMs ở quy mô lớn bằng cách đầu tiên thu thập kiến thức từ dữ liệu khổng lồ thông qua việc tiền huấn luyện mô hình ngôn ngữ có che dấu nhờ vào các kết nối nội tại của chúng. Sau đó, chúng tôi tái lập trình các Masked LMs đã được tiền huấn luyện thành DIFFUSION-LLMs thông qua thích ứng khuếch tán, trong đó việc tinh chỉnh theo nhiệm vụ cụ thể và tinh chỉnh theo hướng dẫn được khám phá để mở khóa tính linh hoạt của chúng trong việc giải quyết các nhiệm vụ ngôn ngữ tổng quát. Các thí nghiệm cho thấy rằng việc mở rộng quy mô DIFFUSION-LLMs liên tục cải thiện hiệu suất trên các nhiệm vụ ngôn ngữ downstream. Chúng tôi cũng phát hiện ra rằng việc tinh chỉnh theo hướng dẫn có thể kích hoạt khả năng học trong ngữ cảnh zero-shot và few-shot giúp giải quyết nhiều nhiệm vụ chưa từng thấy bằng cách tuân theo cả hướng dẫn bằng ngôn ngữ tự nhiên và thậm chí là hướng dẫn trực quan cho hiểu biết đa phương thức, đồng thời cho thấy triển vọng trong các khả năng nâng cao và thách thức như lý luận.

1 GIỚI THIỆU
Những tiến bộ gần đây trong mô hình tạo sinh đã dẫn đến sự tiến bộ đáng kể trong lĩnh vực AI tạo sinh. Trong các lĩnh vực tín hiệu liên tục, các mô hình xác suất khuếch tán đã thể hiện sự thành công lớn trong việc tạo ra hình ảnh chân thực (Rombach et al., 2021; Ramesh et al., 2022), video sống động (Bar-Tal et al., 2024) và tổng hợp âm thanh chất lượng cao (Kong et al., 2020) thông qua việc khử nhiễu lặp đi lặp lại, vượt trội hơn GANs và các mô hình tự hồi quy (AR), thậm chí góp phần vào sự bùng nổ của nghệ thuật AI.

Câu chuyện khác nhau trong các lĩnh vực tín hiệu rời rạc bao gồm các chuỗi ký hiệu như ngôn ngữ tự nhiên, nơi các mô hình ngôn ngữ lớn tự hồi quy (mô hình ngôn ngữ lớn hoặc LLMs, Brown et al., 2020; OpenAI, 2023) đã thống trị bối cảnh, cung cấp khả năng ngôn ngữ tổng quát ấn tượng trong việc hiểu ngôn ngữ và tạo ra văn bản giống con người, và thậm chí có thể tuân theo hướng dẫn ngôn ngữ tự nhiên để thực hiện các nhiệm vụ chưa từng thấy.

Trong khi nhiều nỗ lực gần đây cố gắng thống nhất các mô hình tạo sinh bằng cách cho phép các mô hình ngôn ngữ lớn vẽ (Ge et al., 2023) hoặc nói (Zhang et al., 2023), rất ít khám phá việc tạo ra các chuỗi rời rạc như ngôn ngữ bằng các mô hình khuếch tán. Chúng tôi đề xuất rằng khả năng tạo sinh cách mạng hóa của các mô hình khuếch tán mang lại lời hứa về sự bổ sung mạnh mẽ cho các LMs tự hồi quy vì một số lý do thuận lợi, bao gồm (1) trường nhận thức toàn cục so với ngữ cảnh một phía, và (2) cách thức soạn thảo rồi sửa đổi phi tự hồi quy so với việc tạo sinh/tự hồi quy một chiều hạn chế.

Do đó, một câu hỏi hấp dẫn nảy sinh: liệu các mô hình khuếch tán có thể nói ngôn ngữ tốt không?

Chìa khóa cho sự thành công lớn của các LLMs hiện đại nằm ở khả năng mở rộng quy mô của chúng, điều này nuôi dưỡng các khả năng tổng quát mạnh mẽ. Câu hỏi về khả năng của DIFFUSION-LLMs do đó lần lượt là hỏi về khả năng mở rộng quy mô của chúng, điều này có thể được rút gọn thành các câu hỏi nghiên cứu cụ thể sau đây liên quan đến ba thành phần chính của sự thành công của các LMs quy mô lớn, tức là dữ liệu, kích thước mô hình và nhiệm vụ:

∗Công việc được thực hiện trong thời gian thực tập của Jiasheng tại ByteDance Research.
1arXiv:2308.12219v3 [cs.CL] 24 Feb 2025

--- TRANG 2 ---
Preprint
Autoregressive LMs Dịch "Diffusion language models có thể rất tuyệt vời." Trả lời bằng tiếng Trung.
ĐẦU VÀO (hướng dẫn/prompt)
扩散ĐẦU RA (tạo sinh tuần tự)扩散语⾔扩散语⾔模型扩散语⾔模型太扩散语⾔模型太酷啦

Diffusion LMs Dịch "Diffusion language models có thể rất tuyệt vời." Trả lời bằng tiếng Trung.
ĐẦU VÀO (hướng dẫn/prompt)
[M][M][M][M]模型[M][M][M]ĐẦU RA (tinh chỉnh/khử nhiễu lặp đi lặp lại)[M]M]语⾔模型[M][M][M]扩散语⾔模型[M][M][M]扩散语⾔模型[M][M]了扩散语⾔模型太酷啦

Specialist Diffusion LM cho nhiệm vụ A Generalist Diffusion LM cho nhiều nhiệm vụ
Tinh chỉnh theo Nhiệm vụ Cụ thể Tinh chỉnh theo Hướng dẫn

PHẪU THUẬT TẠO SINH: Từ MLMs đến Diffusion LMs
A
⓶ Thích ứng Khuếch tán
B
Các mô hình ngôn ngữ - Dịch thuật -Tóm tắt -Gấp nếp protein ngược -v.v.. --Tuân theo hướng dẫn -Học trong ngữ cảnh -Lý luận CoT -v.v..

⓵ Thu thập Kiến thức
Tiền huấn luyện MLM trên dữ liệu quy mô lớn
MLM Tiền huấn luyện Lớn: BERT, RoBERTa XLM-RoBERTa, v.v.

Hình 1: Tổng quan. (A) Minh họa so sánh các mô hình LM, tức là ARLMs so với Diffusion LMs. (B) Minh họa tổng thể về DIFFUSION-LLM được đề xuất trong đó các masked LMs tiền huấn luyện quy mô lớn được tái lập trình thành DIFFUSION-LLMs thông qua phẫu thuật tạo sinh.

(i) Về mở rộng dữ liệu. Việc thu thập kiến thức tổng quát thông qua tiền huấn luyện tự giám sát từ dữ liệu không gán nhãn khổng lồ đóng vai trò quan trọng trong thành công của các mô hình NLP hiện đại (Radford et al., 2018; Devlin et al., 2018), do đó việc cho phép Diffusion LMs học từ dữ liệu khổng lồ cũng quan trọng. Liệu DIFFUSION-LLMs có thể tận dụng kiến thức từ dữ liệu quy mô lớn không?

(ii) Về mở rộng kích thước mô hình. Đã được quan sát rộng rãi rằng mô hình càng lớn thì LMs càng có năng lực hơn. Liệu việc mở rộng DIFFUSION-LLMs có thể cải thiện hiệu quả các nhiệm vụ downstream không?

(iii) Về mở rộng nhiệm vụ. Điều làm cho LLMs hấp dẫn nhất là chúng có thể giải quyết các nhiệm vụ mới mà chúng chưa từng được tiếp xúc trong quá trình huấn luyện bằng cách tuân theo hướng dẫn ngôn ngữ tự nhiên và thậm chí đa phương thức với ít hoặc không có minh chứng. Liệu DIFFUSION-LLMs có thể thể hiện khả năng học trong ngữ cảnh zero-shot và few-shot tổng quát để khái quát hóa cho các nhiệm vụ chưa từng thấy không?

Trong bài báo này, chúng tôi đi sâu vào tiềm năng của DIFFUSION-LLMs thông qua ba câu hỏi nghiên cứu. Chúng tôi nêu bật các đóng góp và phát hiện của chúng tôi như sau:

(1) Trước tiên, chúng tôi chứng minh mối liên hệ nội tại giữa các masked LMs và các mô hình khuếch tán rời rạc, điều này cho phép chúng tôi coi các masked LMs tiền huấn luyện ở nhiều quy mô khác nhau như các DIFFUSION-LLMs tiền huấn luyện, mà không cần học từ đầu tốn kém. Sau đó, chúng tôi tái lập trình các masked LMs tiền huấn luyện thành DIFFUSION-LLMs thông qua thích ứng khuếch tán, trong đó việc tinh chỉnh theo nhiệm vụ cụ thể và tinh chỉnh theo hướng dẫn (Wei et al., 2021) được khám phá để giải quyết các nhiệm vụ downstream nhất định hoặc các vấn đề ngôn ngữ tổng quát, cho thấy DIFFUSION-LLMs được hưởng lợi từ tiền huấn luyện trên dữ liệu quy mô lớn.

(2) Chúng tôi tiết lộ rằng DIFFUSION-LLMs quy mô lớn có thể phục vụ như các mô hình tạo sinh chuỗi mạnh mẽ để giải quyết đa nhiệm vụ, thể hiện hiệu suất cạnh tranh so với các ARLMs. Và hiệu suất liên tục cải thiện khi kích thước mô hình mở rộng.

(3) Chúng tôi tiếp tục kích hoạt khả năng zero-shot và few-shot cho DIFFUSION-LLMs để giải quyết nhiều nhiệm vụ chưa từng thấy, trải dài từ ngôn ngữ đến thị giác, thông qua cả việc tinh chỉnh theo hướng dẫn ngôn ngữ và thị giác. Đáng chú ý, DIFFUSION-LLMs thể hiện các hành vi lý luận có cấu trúc đầy hứa hẹn nhờ vào thứ tự tạo sinh phi tự hồi quy linh hoạt của chúng. Tuy nhiên, khả năng giải quyết các nhiệm vụ lý luận phức tạp của chúng vẫn là một thách thức đang diễn ra chờ được giải quyết.

Tóm lại, chúng tôi hy vọng rằng các khám phá của chúng tôi cung cấp những hiểu biết có giá trị về khả năng mở rộng quy mô của DIFFUSION-LLMs và tiềm năng của chúng như một sự bổ sung khả thi trong việc giải quyết các nhiệm vụ ngôn ngữ tạo sinh trên toàn bộ bảng.

2 KIẾN THỨC NỀN TẢNG: CÁC MÔ HÌNH KHUẾCH TÁN CHO VIỆC TẠO SINH CHUỖI

Các nhiệm vụ xử lý ngôn ngữ có thể được thống nhất như các bài toán chuỗi-tới-chuỗi (Raffel et al., 2020), mô hình hóa phân phối có điều kiện pθ(x|c), trong đó x = (x[1], x[2], ..., x[N]) là một chuỗi đích bao gồm N tokens và c là ngữ cảnh được cho. Ví dụ, chúng ta có thể muốn tạo ra phản hồi x có điều kiện trên prompt c, hoặc nó có thể là tạo sinh vô điều kiện nếu không có ngữ cảnh nào được cung cấp (tức là c = ϕ). Kết quả là, một điều chúng ta quan tâm là khả năng của các mô hình tạo sinh cho dữ liệu chuỗi x, ví dụ, các mô hình tự hồi quy phổ biến hoặc các mô hình khuếch tán. Trong phần này, chúng tôi cung cấp kiến thức nền cần thiết về các mô hình tạo sinh chuỗi dựa trên khuếch tán, trong đó chúng tôi lạm dụng ký hiệu và sử dụng pθ(x) cho cả pθ(x|c) có điều kiện và pθ(x|c=ϕ) vô điều kiện để ngắn gọn.

--- TRANG 3 ---
Preprint
Các Mô hình Khuếch tán (Sohl-Dickstein et al., 2015) là một lớp các mô hình tạo sinh được đặc trưng bởi một cặp quá trình Markov, tức là quá trình khuếch tán tiến và quá trình khử nhiễu lùi. Quá trình tiến q(x1:T|x0) = ∏T t=1 q(xt|xt−1) dần dần làm nhiễu dữ liệu x0 ∼ q(x0) thành một phân phối dừng q(xT) với T bước ngày càng nhiễu x1:T = x1, x2, ..., xT. Quá trình lùi đã học pθ(x0:T) = p(xT)∏T t=1 pθ(xt−1|xt), ngược lại, dần dần khử nhiễu các mẫu về phía phân phối dữ liệu. Để khớp mô hình pθ(x0) với phân phối dữ liệu q(x0), mô hình khử nhiễu thường được tối ưu hóa bởi cận biến phân của log-likelihood âm (Ho et al., 2020):

Eq(x0)[−log pθ(x0)] ≤ Eq(x0:T)[−log pθ(x0:T)/q(x1:T|x0)] = L0 + ∑T t=2 Lt + const. (1)

trong đó L0 = Eq[−log pθ(x0|x1)], và Lt = Eq[KL[q(xt−1|xt, x0)∥pθ(xt−1|xt)]] cho t ∈ [1, T].

Nói chung, các mô hình khuếch tán có thể được phân loại thành các mô hình khuếch tán liên tục và rời rạc theo loại phân phối cho việc làm nhiễu dữ liệu. Các mô hình khuếch tán liên tục với nhiễu Gaussian đã chứng minh hiệu suất ấn tượng trong việc tạo ra các tín hiệu liên tục (Rombach et al., 2021; Ho et al., 2022; Kong et al., 2020) nhưng vẫn gặp khó khăn với chất lượng tạo sinh thỏa mãn trong ngôn ngữ tự nhiên (Li et al., 2022; Gong et al., 2022; Gao et al., 2022; Yuan et al., 2022; Ye et al., 2023). Một thách thức quan trọng ở đây là cạm bẫy của tính rời rạc (Ye et al., 2023) làm cho việc nhiễu Gaussian trên embeddings khó có thể cung cấp các tín hiệu huấn luyện hiệu quả. Ngược lại, các mô hình khuếch tán rời rạc hoạt động trực tiếp trên không gian trạng thái rời rạc của tokens, cung cấp một lựa chọn hấp dẫn cho việc học tạo sinh chuỗi. Do đó trong bài báo này, chúng tôi khám phá việc phát triển DIFFUSION-LLMs dựa trên khuếch tán rời rạc.

Các Mô hình Khuếch tán Rời rạc (Hoogeboom et al., 2021; Austin et al., 2021) bao gồm một tập con của các mô hình khuếch tán mà trong đó xác suất chuyển đổi giữa các timesteps là các phân phối rời rạc. Vì quá trình khuếch tán tiến được áp dụng độc lập cho mỗi token của một chuỗi x, vì lý do ngắn gọn, chúng tôi lạm dụng ký hiệu xt cho các tokens tùy ý tại timestep khuếch tán t. Chính thức, xt ∈ {0,1}|V| là một token được biểu diễn như một vector one-hot, trong đó V là từ vựng của tất cả các tokens có thể. Cho Cat(x; p) là một phân phối categorical trên x với xác suất được cho bởi vector p trên đơn hình xác suất |V| − 1 chiều, và chuyển đổi tiến là q(xt|xt−1) = Cat(xt; p = βtxt−1 + (1−βt)qnoise), trong đó 0 ≪ βt < 1 là lịch trình nhiễu kiểm soát mức độ nhiễu tại timestep t, và qnoise là vector xác suất của phân phối dừng q(xT), tức là q(xT) = Cat(xT; p = qnoise). Trong trường hợp này, phân phối của mẫu bị làm hỏng xt cho dữ liệu gốc x0 của nó có một biểu thức dạng đóng:

q(xt|x0) = Cat(xt; p = αtx0 + (1−αt)qnoise),

trong đó αt = ∏t i=1 βi. Điều này cho thấy rằng quá trình khuếch tán về trực quan là một sự kết hợp lồi giữa dữ liệu và nhiễu trong đó αt kiểm soát mức độ bị hỏng tại các timesteps khác nhau. Đặc biệt, αt giảm khi timestep tăng. Với đủ timesteps lớn, chúng ta có αT ≈ 0, điều này không bảo tồn thông tin nào từ dữ liệu ở cuối quá trình khuếch tán.

Các phân phối dừng qnoise khác nhau dẫn đến các công thức khác nhau của các mô hình khuếch tán rời rạc. Một thiết kế điển hình là khuếch tán hấp thụ với q(xT) = {1 nếu xT = [MASK]; 0 nếu xT ≠ [MASK]}, trong đó [MASK] là một trạng thái hấp thụ. Theo Eq. (2), công thức này dẫn đến xt hoặc bị che dấu hoặc giống như x0, với tỷ lệ che dấu (1−αt). Điều này làm cho khuếch tán hấp thụ giống với các masked LMs (MLM, Devlin et al., 2018) như He et al. (2023) chỉ ra.

Các Mô hình Khuếch tán Rời rạc Tái tham số hóa (RDM, Zheng et al., 2023a) tái tham số hóa chuyển đổi lùi của DIFFUSION-LLMs để tái công thức hóa mục tiêu huấn luyện của các mô hình khuếch tán rời rạc thành

Lt = E[−λ(2) t−1(1−1(xt = x0)) log pθ(x0|xt)] (2)

trong đó 1(·) là hàm chỉ thị. Dưới công thức của khuếch tán hấp thụ, Eqn. 2 giống với một mục tiêu MLM có trọng số (Devlin et al., 2018). Zheng et al. (2023a) chứng minh rằng Eqn. 2 là một giao thức huấn luyện hiệu quả hơn so với Eqn. 1 cho các mô hình khuếch tán rời rạc tạo sinh, cho thấy hiệu suất ngang bằng với các ARLMs (Vaswani et al., 2017) trên các benchmark dịch máy đại diện lần đầu tiên. Trong bài báo này, chúng tôi sử dụng RDM làm mục tiêu huấn luyện chính để xây dựng DIFFUSION-LLMs của chúng tôi (xem §A để biết thêm chi tiết).

Quá trình Tạo sinh của Các Mô hình Khuếch tán Rời rạc. Các mô hình khuếch tán tạo ra các mẫu mới bằng quá trình tạo sinh ngược của việc khử nhiễu lặp đi lặp lại. Dưới công thức của khuếch tán hấp thụ, quá trình khử nhiễu có thể được đặc trưng theo cách che-dự đoán lặp đi lặp lại (Ghazvininejad et al., 2019). Cụ thể, chuỗi bắt đầu được khởi tạo bằng tất cả các tokens [MASK], và trong mỗi lần lặp, một số tokens bị che dấu được thay thế bởi các dự đoán mô hình từ pθ(xt−1|xt) trong khi một số tokens không bị che dấu được che dấu lại, theo các chiến lược/lịch trình cụ thể (Ghazvininejad et al., 2019; Savinov et al., 2021; Chang et al., 2022; Zheng et al., 2023a). Trong bài báo này, chúng tôi theo Zheng et al. (2023a) để bỏ che dấu các vị trí với top-k dự đoán log pθ(x0|xt), và che dấu tất cả các vị trí còn lại trong mỗi bước khử nhiễu¹.

--- TRANG 4 ---
Preprint

3 MỞ RỘNG QUY MÔ CÁC MÔ HÌNH NGÔN NGỮ KHUẾCH TÁN THEO DỮ LIỆU, KÍCH THƯỚC VÀ NHIỆM VỤ

Việc phát triển DIFFUSION-LLMs tận dụng các lợi thế của cả sức mạnh tạo sinh của các mô hình khuếch tán và khả năng mở rộng quy mô của các LMs tiền huấn luyện lớn là một nỗ lực đầy hứa hẹn nhưng thách thức. Chìa khóa cho sự thành công của mô hình chuẩn hiện tại của các LMs tạo sinh lớn là thu thập kiến thức thông qua tiền huấn luyện khổng lồ và tạo sinh theo cách prompt-response cho đầu ra ưa thích cho nhiều nhiệm vụ. Đối với DIFFUSION-LLMs, (1) làm thế nào để hưởng lợi từ tiền huấn luyện ở quy mô lớn, và (2) làm thế nào để phù hợp nhất với mô hình prompt-response, là những câu hỏi mở quan trọng. Trong phần này, chúng tôi sẽ trình bày chi tiết về cách tăng cường DIFFUSION-LLMs với kiến thức từ tiền huấn luyện dữ liệu quy mô lớn cũng như kích thước mô hình, và mở rộng khả năng tạo sinh của chúng cho các nhiệm vụ downstream rộng rãi.

3.1 THU THẬP KIẾN THỨC THÔNG QUA TIỀN HUẤN LUYỆN MLM

Khung lý thuyết của các mô hình khuếch tán rời rạc có mối liên hệ nội tại với việc mô hình hóa ngôn ngữ có che dấu (MLM), điều này đã được thảo luận trong Austin et al. (2021); Gong et al. (2022) và He et al. (2023). Trong số các loại mô hình khuếch tán rời rạc khác nhau, khuếch tán hấp thụ (Austin et al., 2021) giống với việc mô hình hóa ngôn ngữ có che dấu tổng quát, điều này đã được chứng minh là một mục tiêu huấn luyện hiệu quả trong việc tiền huấn luyện các mô hình nền tảng (Devlin et al., 2018; Liu et al., 2019). Cụ thể, khuếch tán hấp thụ định nghĩa một phân phối dừng: q(xT) = {1 nếu xT = [MASK]; 0 nếu xT ≠ [MASK]}, trong đó [MASK] là một token hấp thụ. Theo Eq. (2), công thức này dẫn đến xt hoặc bị che dấu hoặc giống như x0, với tỷ lệ che dấu (1−αt). Do đó, xt = x0 khi và chỉ khi xt ≠ [MASK], điều này làm cho mục tiêu huấn luyện tái tham số hóa trong Eq. (2) khớp chính xác với mục tiêu mô hình hóa ngôn ngữ có che dấu.

Mối liên hệ này cho phép chúng tôi thiết lập DIFFUSION-LLMs bằng cách tiền huấn luyện với các mục tiêu MLM từ dữ liệu văn bản thô khổng lồ. Chúng tôi thậm chí có thể coi các MLMs tiền huấn luyện có sẵn trong cộng đồng (Devlin et al., 2018; Liu et al., 2019; Conneau et al., 2019) như các DIFFUSION-LLMs tiền huấn luyện, và có thể khởi hành từ chúng cho các nhiệm vụ downstream với chi phí rất thấp, bỏ qua giai đoạn tiền huấn luyện tốn kém.

3.2 THÍCH ỨNG KHUẾCH TÁN: TÁI LẬP TRÌNH CÁC MLMs TIỀN HUẤN LUYỆN THÀNH DIFFUSION-LLMs

Các masked LMs hiện có chủ yếu được thiết kế để phục vụ như các bộ mã hóa chuỗi, và không thể tạo sinh chuỗi theo mặc định. Mặc dù có mối liên hệ với khuếch tán rời rạc hấp thụ, việc lấy mẫu một cách ngây thơ từ các masked LMs thông qua quá trình khử nhiễu lặp đi lặp lại của khuếch tán hấp thụ là không tầm thường. Một lý do chính là khuếch tán hấp thụ tạo ra việc lấy mẫu bằng cách áp dụng lặp đi lặp lại pθ(xt−1|xt) từ nhiễu hoàn toàn đến dự đoán cuối cùng (tức là dần dần từ 100% xuống 0% tokens [MASK]) thông qua các timesteps khác nhau, trong khi các masked LMs vanilla chỉ được tiền huấn luyện với tỷ lệ che dấu hạn chế và không đổi (ví dụ 15%).

Để kích hoạt khả năng tạo sinh chuỗi của các masked LMs tiền huấn luyện, chúng tôi đề xuất thích ứng khuếch tán để loại bỏ khoảng cách giữa các masked tiền huấn luyện và DIFFUSION-LLMs, trong đó chúng tôi tiếp tục tinh chỉnh các Masked LMs tiền huấn luyện với mục tiêu huấn luyện khuếch tán sao cho việc lấy mẫu với quá trình khử nhiễu trở nên khả thi. Đặc biệt, chúng tôi theo phương pháp huấn luyện và lấy mẫu tái tham số hóa trong Zheng et al. (2023a) như được mô tả trong §2. Tương tự như thiết kế time agnostic trong He et al. (2023), chúng tôi không giới thiệu bất kỳ tham số bổ sung nào để phân biệt các timesteps khuếch tán khác nhau.

Cho các mục đích khác nhau, chúng tôi thực hiện thích ứng khuếch tán cho DIFFUSION-LLMs theo hai cách:

• Tối ưu hóa khả năng chuyên gia trên các nhiệm vụ downstream nhất định thông qua tinh chỉnh theo nhiệm vụ cụ thể. Để xác minh tính khả thi của thích ứng khuếch tán, chúng tôi tinh chỉnh các masked LMs tiền huấn luyện trên các tập dữ liệu cụ thể cho mỗi nhiệm vụ downstream. Hơn nữa, chúng tôi tiếp tục thực hiện tinh chỉnh trên các mô hình tiền huấn luyện ở các quy mô khác nhau để nghiên cứu khả năng mở rộng quy mô của DIFFUSION-LLMs.

¹Xem §A để biết các lịch trình nhiễu cụ thể, và Zheng et al. (2023a) để biết lý do của chiến lược lấy mẫu này.

--- TRANG 5 ---
Preprint

Bảng 1: SacreBLEU (Post, 2018) trên IWSLT14 DE→EN và WMT14 EN→DE, và Rouge-L trên Gigaword-10k. Chúng tôi sử dụng 10 length beams cho tất cả kết quả với dự đoán độ dài. Kết quả ngoài (trong) ngoặc đơn được thu được với dự đoán độ dài (độ dài đích oracle). Kết quả của DiffusionLM và DINOISER được trích dẫn từ Ye et al. (2023). Và kết quả của GENIE là việc tái hiện của chúng tôi thu được với mã nguồn mở và checkpoint của bài báo gốc. "#Params.": Số lượng tham số không phải embedding. "Type": liệu mục tiêu huấn luyện và phương pháp lấy mẫu có phải là tự hồi quy (AR, Vaswani et al., 2017) hay theo các mô hình khuếch tán tái tham số hóa (RDM, Zheng et al., 2023a). "pre-trained": liệu có được khởi tạo từ các mô hình tiền huấn luyện hay không. "†": Kiến trúc có định dạng # layers / hidden dimension. Đối với các mô hình có encoder, # layers bao gồm các layers trong cả encoder và decoder. "‡": Đối với IWSLT14, chúng tôi theo thực hành trước đây (Vaswani et al., 2017) và sử dụng phiên bản nhỏ hơn (39M) của Transformer-BASE, có chiều trong các layers feed-forward là 1024 và 4 attention heads.

[THIS IS TABLE: A detailed performance comparison table with columns for Method, Architecture, #Params, Pre-trained, IWSLT14, WMT14, Gigaword-10K, and Gigaword, showing various model performances]

• Kích hoạt khả năng tổng quát trên các nhiệm vụ rộng rãi thông qua tinh chỉnh theo hướng dẫn. Tinh chỉnh trên một tập hợp các nhiệm vụ được diễn đạt như hướng dẫn (tức là tinh chỉnh theo hướng dẫn) cho phép LMs phản hồi tốt hơn với các prompts hướng dẫn và khái quát hóa cho các nhiệm vụ chưa từng thấy (Wei et al., 2021; Chung et al., 2022). Được truyền cảm hứng bởi điều này, chúng tôi áp dụng thích ứng khuếch tán cho các masked LMs tiền huấn luyện bằng tinh chỉnh theo hướng dẫn để nghiên cứu liệu DIFFUSION-LLMs có thể thu được khả năng few-shot và zero-shot như các LLMs tự hồi quy hay không.

Các cân nhắc kỹ thuật để mở rộng quy mô. Cả hai kịch bản trên đều xử lý các nhiệm vụ tạo sinh chuỗi có điều kiện từ đầu vào đến đầu ra, yêu cầu mô hình tạo ra các chuỗi đích theo các prompts đã cho. Thay vì kết hợp một encoder bổ sung, chúng tôi xử lý việc tạo sinh có điều kiện bằng cách tổ chức dữ liệu theo định dạng prompt-response². Điều này cho phép mô hình của chúng tôi chia sẻ cùng một cơ sở hạ tầng huấn luyện như các ARLMs decoder-only lớn phổ biến (Brown et al., 2020; Touvron et al., 2023a;b; Jiang et al., 2023) trong khi việc kết hợp encoder bổ sung sẽ làm tăng độ phức tạp trong các kỹ thuật chính để mở rộng quy mô LLMs như song song pipeline (Harlap et al., 2018; Huang et al., 2019; Li & Hoefler, 2021). Quyết định thiết kế của chúng tôi đảm bảo khả năng mở rộng quy mô của DIFFUSION-LLMs trong kỹ thuật.

Ngoài ra, chúng tôi kết hợp một bộ dự đoán độ dài, một thực hành phổ biến trong tạo sinh văn bản phi tự hồi quy (Gu et al., 2018), để xác định độ dài của các chuỗi dự đoán. Chúng tôi chọn các dự đoán độ dài top-k của nó cho tìm kiếm beam độ dài song song, trong đó k được gọi là kích thước beam độ dài. Trong quá trình tinh chỉnh, chúng tôi chỉ áp dụng quá trình khuếch tán cho các tokens phản hồi đích và tính toán loss trên chúng. Trong quá trình suy luận, chúng tôi nối các chuỗi bị che dấu hoàn toàn ban đầu vào các prompts và khử nhiễu từ chúng.

4 THỰC NGHIỆM

Trong phần này, trước tiên chúng tôi giới thiệu các thiết lập thí nghiệm tổng quát trong §4. Sau đó, chúng tôi tiến hành ba phần thí nghiệm một cách tiến bộ liên quan đến mở rộng quy mô theo dữ liệu (§4.2), kích thước mô hình (§4.3), và số lượng nhiệm vụ (§4.4).

Mô hình. Trong suốt các thí nghiệm, chúng tôi sử dụng XLM-RoBERTa (XLM-R; Conneau et al., 2019; Goyal et al., 2021) làm mô hình nền tảng của chúng tôi, được tiền huấn luyện trên CC100 (Wenzek et al., 2020), một kho dữ liệu đa ngôn ngữ chứa 167B tokens của 100 ngôn ngữ, với bốn kích thước mô hình (số lượng tham số không phải embedding) ở các quy mô khác nhau, tức là 86M, 304M, 2.8B, và 9.7B.

²Một ví dụ định dạng prompt-response cho dịch từ tiếng Đức → tiếng Anh (Vielen dank → Thank you): "Translate the German sentence to English. German: Vielen dank. English: Thank you."

--- TRANG 6 ---
Preprint

Dữ liệu & nhiệm vụ. Chúng tôi điều tra phương pháp của chúng tôi về khả năng chuyên gia trong các nhiệm vụ downstream tương ứng và khả năng tổng quát để giải quyết các nhiệm vụ khổng lồ chưa từng thấy bằng cách sử dụng hướng dẫn ngôn ngữ tự nhiên. Các tập dữ liệu chúng tôi sử dụng để tinh chỉnh mô hình của chúng tôi như sau:

(1) Tập dữ liệu nhiệm vụ downstream. Chúng tôi đánh giá liệu phương pháp của chúng tôi có thể giúp DIFFUSION-LLMs phục vụ như các mô hình chuyên biệt mạnh mẽ trên nhiều nhiệm vụ downstream đại diện: (1) IWSLT14 cho dịch DE→EN; (2) WMT14 cho dịch EN→DE; (3) Gigaword-10K cho tóm tắt văn bản; và (4) Gigaword tóm tắt đầy đủ.

(2) Tập dữ liệu tinh chỉnh theo hướng dẫn. Chúng tôi theo Chung et al. (2022) và tinh chỉnh các mô hình XLM-R ở các quy mô khác nhau với Bộ sưu tập Flan 2022 (Chung et al., 2022; Longpre et al., 2023) với mục tiêu huấn luyện khuếch tán. Đây là phiên bản có sẵn công khai của dữ liệu huấn luyện hướng dẫn cho Flan-T5 và Flan-PaLM, bao gồm hơn 1.8K nhiệm vụ. Nó kết hợp một số tập dữ liệu học đa nhiệm vụ với hướng dẫn (Wei et al., 2021; Sanh et al., 2021; Wang et al., 2022), kết hợp với một số dữ liệu chain-of-thought và đối化 bổ sung.

4.1 KHÁM PHÁ KHÔNG GIAN THIẾT KẾ CỦA DIFFUSION-LLMs

Trước tiên, chúng tôi xác minh rằng các quyết định thiết kế của chúng tôi dẫn đến một DIFFUSION-LLM có khả năng cạnh tranh, bao gồm (1) RDM time-agnostic và (2) không kết hợp encoder bổ sung. Như được thể hiện trong Bảng 1:

• RDM là DIFFUSION-LLM hiệu suất nhất, là ứng cử viên lý tưởng để mở rộng quy mô. Nó vượt trội hơn cả các mô hình ngôn ngữ khuếch tán liên tục, DiffusionLM và DINOISER. Hơn nữa, nó thực hiện ngang bằng với mô hình AR trên IWSLT14 và WMT14, vượt trội hơn AR trên Gigaword-10K, cho thấy rằng RDM là một mô hình khuếch tán đủ mạnh để khai thác.

• Sử dụng kiến trúc không có encoders có tác động nhỏ đến hiệu suất mô hình. Mặc dù mô hình không có encoders hoạt động hơi kém hơn đối tác có encoders, nhận thức hai chiều của các mô hình khuếch tán và mở rộng quy mô trong dữ liệu có thể giảm thiểu khoảng cách này, tương tự như các phát hiện trong Zhang et al. (2022); Patel et al. (2022). Như kết quả trong Bảng 1 cho thấy, so với các mô hình AR, RDM có khoảng cách hiệu suất nhỏ hơn giữa các mô hình có và không có encoders. Sự khác biệt như vậy trở nên không đáng kể trên các tập dữ liệu lớn như WMT14 và các mô hình được khởi tạo từ các mô hình XLM-R tiền huấn luyện.

Các kết quả xác minh năng lực của mô hình chúng tôi ở quy mô vừa phải mà không cần tiền huấn luyện, chuẩn bị nó để trở thành ứng cử viên lý tưởng cho mở rộng quy mô. Sau đó, chúng tôi xây dựng dựa trên điều này để điều tra khả năng mở rộng quy mô của nó theo dữ liệu, kích thước mô hình và nhiệm vụ.

4.2 TĂNG CƯỜNG DIFFUSION-LLMs VỚI DỮ LIỆU QUY MÔ LỚN

Chúng tôi áp dụng thích ứng khuếch tán trên kiến trúc mô hình XLM-R-BASE (Conneau et al., 2019) trên các benchmark tạo sinh chuỗi. Bằng cách này, chúng tôi xác minh tính khả thi của thích ứng khuếch tán. Đồng thời, bằng cách so sánh hiệu suất của các RDMs thích ứng khuếch tán với các mô hình được huấn luyện từ đầu, chúng tôi xác nhận rằng DIFFUSION-LLM của chúng tôi tận dụng lợi thế của việc học tự giám sát quy mô lớn, cụ thể là mở rộng quy mô với dữ liệu.

Tiền huấn luyện ở quy mô lớn có lợi cho DIFFUSION-LLMs. Các kết quả trong Bảng 1 chứng minh rằng việc huấn luyện RDM thông qua thích ứng khuếch tán từ các MLMs tiền huấn luyện tăng cường hiệu suất mô hình so với các mô hình được huấn luyện từ đầu, tác động của nó đặc biệt đáng kể trên các tập dữ liệu nhỏ

--- TRANG 7 ---
Preprint

Hình 2: Một quá trình tạo sinh ví dụ của DIFFUSION-LLM cho dịch máy. Chú ý rằng bản dịch đích chứa ba phân đoạn, được tạo ra đồng thời bởi mô hình ngôn ngữ khuếch tán.

như Gigaword-10K. So với GENIE, một DIFFUSION-LLM tiền huấn luyện dựa trên các mô hình khuếch tán liên tục, RDM thích ứng từ XLM-R cũng mạnh hơn, tiếp tục xác nhận lợi thế của DIFFUSION-LLM rời rạc. Như được thể hiện định tính trong Hình 2, DIFFUSION-LLMs tạo ra bản dịch trôi chảy và chính xác về mặt ngữ nghĩa³, tiếp tục xác nhận tính khả thi của phẫu thuật tạo sinh của chúng tôi đối với các MLMs tiền huấn luyện. Với những phát hiện này, chúng tôi xác nhận tính khả thi của phương pháp thích ứng khuếch tán và xác minh khả năng mở rộng quy mô của DIFFUSION-LLMs liên quan đến dữ liệu huấn luyện.

4.3 MỞ RỘNG QUY MÔ KÍCH THƯỚC CỦA DIFFUSION-LLMS TĂNG CƯỜNG CÁC NHIỆM VỤ DOWNSTREAM

Bây giờ chúng tôi chuyển sang khả năng mở rộng quy mô liên quan đến kích thước mô hình. Chúng tôi tinh chỉnh các mô hình XLM-R ở các quy mô khác nhau (Conneau et al., 2019; Goyal et al., 2021), có các tham số hiệu quả (tức là số lượng tham số không phải embedding) từ <100M đến 10B. Đáng chú ý, khi mở rộng quy mô lên 10B, mô hình cho thấy hiệu suất ấn tượng vượt trội hơn các mô hình kích thước cơ bản với một biên độ đáng kể (Bảng 1).

Hình 3 cho thấy đường cong mở rộng quy mô của hiệu suất mô hình liên quan đến kích thước mô hình. Nó chứng minh rằng hiệu suất của các mô hình khuếch tán được tinh chỉnh tăng lên đáng kể khi kích thước mô hình tăng. Điều này cho thấy quy luật mở rộng quy mô của DIFFUSION-LLMs về mặt kích thước mô hình. Ngoài ra, chúng tôi cũng bao gồm hiệu suất của (m)T5 (Raffel et al., 2020; Xue et al., 2020) ở các quy mô tương tự như tài liệu tham khảo để hiểu trực quan về mức độ mở rộng quy mô của DIFFUSION-LLMs của chúng tôi. Lưu ý rằng hiệu suất của các mô hình khác nhau bị ảnh hưởng phức tạp không chỉ bởi kích thước mô hình mà còn bởi nhiều yếu tố khác bao gồm thiết kế mô hình, ngân sách tiền huấn luyện, mục tiêu tiền huấn luyện, cũng như dữ liệu tiền huấn luyện (Shazeer, 2020; Raffel et al., 2020; Tay et al., 2022; Scao et al., 2022; Hoffmann et al., 2022). Trong Hình 3, mặc dù chúng tôi thấy có khoảng cách hiệu suất giữa các mô hình (m)T5 và XLM-R được tinh chỉnh ở các quy mô tương tự, sự khác biệt này là nhỏ và dường như không bị khuếch đại khi các mô hình mở rộng quy mô. Do đó, mặc dù vẫn còn nhiều chỗ để cải thiện các DIFFUSION-LLMs tiền huấn luyện quy mô lớn, chúng tôi tin rằng con đường mở rộng quy mô những mô hình này rất có triển vọng.

Hình 3: Đường cong mở rộng quy mô của tinh chỉnh theo nhiệm vụ cụ thể trên IWSLT14, WMT14 và Gigaword-10K. Chúng tôi thu được kết quả của mT5 (Xue et al., 2020) trên IWSLT14 bằng chính chúng tôi. Kết quả của T5 trên WMT14 từ Raffel et al. (2020). "OL": kết quả thu được với độ dài đích oracle. "LB=10": kết quả dự đoán độ dài với 10 length beams. "#Params.": Số lượng tham số hiệu quả (tức là tham số không phải embedding).

4.4 TINH CHỈNH THEO HƯỚNG DẪN GIÚP KHÁI QUÁT HÓA CHO CÁC NHIỆM VỤ CHƯA TỪNG THẤY

Bảng 2: SacreBLEU zero-shot của các DIFFUSION-LLMs được tinh chỉnh theo hướng dẫn trên dịch IWSLT14 DE→EN. Đối với Flan 2021, chúng tôi loại bỏ rõ ràng tất cả dữ liệu tiếng Đức để đánh giá nghiêm ngặt. Kết quả được thu được với độ dài oracle.

[THIS IS TABLE: Shows performance comparison with columns for Architecture, Strict Flan'21, and Flan'22, with various XLM-R model sizes and their corresponding scores]

Một tính chất hấp dẫn thúc đẩy việc mở rộng quy mô LMs là LLMs có thể tuân theo hướng dẫn và cho thấy hiệu suất few-shot hoặc thậm chí zero-shot ấn tượng (Wei et al., 2021). Bây giờ chúng tôi điều tra liệu các mô hình khuếch tán có thể cũng thể hiện hiệu suất zero-shot và few-shot khi được mở rộng quy mô hay không.

4.4.1 TINH CHỈNH THEO HƯỚNG DẪN KÍCH HOẠT HIỆU SUẤT ZERO-SHOT CÓ THỂ MỞ RỘNG QUY MÔ

Đánh giá zero-shot nghiêm ngặt trên IWSLT14 DE→EN. Trước tiên, chúng tôi tiến hành đánh giá zero-shot nghiêm ngặt để nghiên cứu liệu DIFFUSION-LLMs có thể thu được khả năng zero-shot thông qua tinh chỉnh theo hướng dẫn hay không. Cụ thể, chúng tôi

³Các bước trung gian chứng minh rằng các mô hình tạo ra ba mệnh đề đồng thời, ngụ ý một nhận thức toàn cục lập kế hoạch cho việc tạo sinh toàn bộ chuỗi. Chúng tôi coi điều này có lợi cho mô hình trên các nhiệm vụ tạo sinh phức tạp hơn, điều mà chúng tôi thảo luận trong §4.5.2.

--- TRANG 8 ---
Preprint

đánh giá trên nhiệm vụ dịch IWSLT14 DE→EN, mà chúng tôi tinh chỉnh theo hướng dẫn DIFFUSION-LLMs trên Bộ sưu tập Flan 2021 (Wei et al., 2021) với tất cả dữ liệu tiếng Đức đã được loại bỏ để đảm bảo rằng dịch DE→EN trở thành một nhiệm vụ hoàn toàn chưa từng thấy. Như được thể hiện trong Bảng 2, các DIFFUSION-LLMs được tinh chỉnh theo hướng dẫn thể hiện hiệu suất zero-shot có thể mở rộng quy mô ngay cả khi không tinh chỉnh với dữ liệu tiếng Đức, cho thấy rằng DIFFUSION-LLMs có thể tuân theo hướng dẫn.

Đánh giá zero-shot rộng rãi với tinh chỉnh hướng dẫn quy mô lớn. Sau đó, chúng tôi theo các thiết lập được khuyến nghị và tiến hành tinh chỉnh hướng dẫn quy mô lớn hơn trên toàn bộ Bộ sưu tập Flan 2022 (Longpre et al., 2023) và chạy đánh giá rộng rãi⁴. Theo Chung et al. (2022), chúng tôi đặt tên các checkpoints được tinh chỉnh theo hướng dẫn của chúng tôi trên Bộ sưu tập Flan 2022 là Flan-XLM-R. Kết quả trong Hình 4 cho thấy rằng các mô hình Flan-XLM-R thực sự là những người học zero-shot đa năng, và hiệu suất zero-shot của chúng cải thiện đáng kể khi mô hình mở rộng quy mô. Đặc biệt, chúng tôi nêu bật kết quả trên IWSLT14. Mô hình lớn nhất, Flan-XLM-R-XXL thậm chí đạt được điểm ScareBLEU zero-shot 30.90, chỉ thấp hơn 2.4 so với hiệu suất của baseline transformer được giám sát rộng rãi (33.30 như được thể hiện trong Bảng 2). Điều này cho thấy các mô hình Flan-XLM-R tạo ra chất lượng tạo sinh ngôn ngữ rất tốt.

Hình 4: Hiệu suất zero-shot của các DIFFUSION-LLMs được tinh chỉnh theo hướng dẫn (Flan-XLM-Rs) ở các quy mô khác nhau. OL có nghĩa là kết quả được thu được với độ dài oracle, trong khi LB có nghĩa là số lượng length beams để lấy mẫu đích với dự đoán độ dài. Kích thước mô hình đề cập đến số lượng tham số không phải embedding.

4.4.2 DIFFUSION-LLMs CÓ THỂ HỌC TRONG NGỮ CẢNH

Bảng 3: SacreBLEU của các DIFFUSION-LLMs được tinh chỉnh theo hướng dẫn trên IWSLT14 DE→EN dưới độ dài oracle với hướng dẫn đã loại bỏ, trong đó mô hình chỉ có thể tìm ra mục tiêu của nhiệm vụ thông qua các minh chứng.

[THIS IS TABLE: Shows DIFFUSION-LLM performance with and without demonstration for different model sizes]

Chúng tôi cũng đánh giá khả năng học trong ngữ cảnh của các DIFFUSION-LLMs. Chúng tôi xây dựng một thí nghiệm trên IWSLT14 với các hướng dẫn đã loại bỏ. Trong trường hợp này, mô hình chỉ có thể dựa vào minh chứng để tìm ra mục tiêu nhiệm vụ.

Kết quả hỗ trợ rằng DIFFUSION-LLMs có thể học trong ngữ cảnh. Mô hình không thể tạo ra kết quả mong muốn mà không có kiến thức trước về nhiệm vụ. Tuy nhiên, khi được cho một minh chứng, nó có thể học cách coi nhiệm vụ như một nhiệm vụ dịch, cho thấy cải thiện hiệu suất rõ ràng, điều này cũng mở rộng quy mô với kích thước mô hình.

4.5 KHÁM PHÁ LÝ LUẬN VỚI DIFFUSION-LLMs

Chúng tôi cũng quan tâm đến việc khám phá khả năng lý luận của DIFFUSION-LLMs vì đây là một khả năng nổi bật quan trọng phân biệt LLMs với những mô hình nhỏ (Wei et al., 2022; Fu et al., 2023). Hiểu cách các mô hình này phát triển khả năng lý luận có thể cung cấp hiểu biết về khả năng mở rộng quy mô, khái quát hóa và các ứng dụng tiềm năng của chúng trong các nhiệm vụ giải quyết vấn đề phức tạp. Hơn nữa, việc điều tra cơ chế lý luận của chúng có thể giúp thu hẹp khoảng cách giữa các LLMs tự hồi quy truyền thống và các kiến trúc dựa trên khuếch tán, làm sáng tỏ điểm mạnh và hạn chế tương ứng của chúng trong các lĩnh vực khác nhau. Trong phần này, chúng tôi sẽ nêu bật các phát hiện chính và bao gồm thảo luận chi tiết.

⁴Chúng tôi tiếp tục đánh giá trên tập dữ liệu IWSLT14. Ngoài ra, chúng tôi cũng đánh giá một số tập dữ liệu được sử dụng trong Chung et al. (2022). Chi tiết, MMLU (Hendrycks et al., 2020) bao gồm các câu hỏi thi trắc nghiệm từ 57 nhiệm vụ bao gồm nhân văn, khoa học xã hội, STEM, và nhiều hơn nữa. TyDiQA (Clark et al., 2020) là một benchmark hỏi đáp sách mở trên 8 ngôn ngữ đa dạng về mặt loại hình học.

--- TRANG 9 ---
Preprint

4.5.1 KẾT QUẢ ĐỊNH LƯỢNG

Như được thể hiện trong Hình 5, chúng tôi thấy rằng, chỉ bằng tinh chỉnh theo hướng dẫn đơn giản, ngay cả Flan-XLM-R-XXL cũng không thể xuất hiện hiệu suất lý luận không tầm thường trên GSM8K (Cobbe et al., 2021), một tập dữ liệu benchmark cho lý luận toán học, và phiên bản dịch sang tiếng Đức của nó trong MGSM (Shi et al., 2022).

(A)
(B)
Hình 5: Đánh giá lý luận trên các tập dữ liệu GSM. (A) Hiệu suất của DIFFUSION-LLM (Flan-XLM-R) và các LLMs tự hồi quy (Flan-T5) ở các quy mô khác nhau. Mặc dù Flan-XLM-R-XXL không thể xuất hiện với hiệu suất không tầm thường, hiệu suất cải thiện với (B) tinh chỉnh theo nhiệm vụ cụ thể trên tập huấn luyện GSM8K hoặc mô hình nền tảng tốt hơn (thích ứng từ LLaMa3.1 8B Instruct bằng cách tiếp tục huấn luyện trên RedPajama). Chúng tôi cũng bao gồm kết quả của việc tinh chỉnh LLaMa3.1 8B tự hồi quy trên GSM8k để tham khảo.

Chúng tôi tiến hành các phân tích thêm để hiểu hiệu suất không thỏa mãn và kết luận rằng điều này là do hạn chế của công thức tiền huấn luyện thay vì mô hình DIFFUSION-LLM.

• DIFFUSION-LLM có thể thực hiện các nhiệm vụ lý luận. Cho rằng tinh chỉnh theo nhiệm vụ cụ thể cung cấp một chiến lược hiệu quả để dự đoán sự tồn tại của khả năng nổi bật (Snell et al., 2024), chúng tôi tinh chỉnh Flan-XLM-R-XXL trên tập huấn luyện của GSM8K. Chúng tôi thấy rằng hiệu suất mô hình tăng vọt lên độ chính xác không tầm thường 26.73%, xác nhận khả năng của DIFFUSION-LLMs trong lý luận.

• Hiệu suất lý luận của DIFFUSION-LLMs có thể được cải thiện với các công thức tiền huấn luyện tốt hơn. Chúng tôi đề xuất rằng hiệu suất lý luận của Flan-XLM-R-XXL bị hạn chế bởi công thức tiền huấn luyện của nó, điều này kém hơn đáng kể so với các thiết kế hiện đại (Warner et al., 2024). Như một xác minh sơ bộ, chúng tôi thích ứng một LLaMa3.1 8B thành DIFFUSION-LLMs bằng cách tinh chỉnh trên RedPajama⁵ và thu được 13.48 sau tinh chỉnh hướng dẫn trên Flan 2022 và 42.77⁶ sau tinh chỉnh theo nhiệm vụ cụ thể trên GSM8K. Cả hai đều vượt trội hơn đáng kể so với XLM-R-XXL với cùng thiết lập tinh chỉnh.

Những phát hiện này hỗ trợ rằng DIFFUSION-LLMs cũng có thể thực hiện lý luận như các LMs tự hồi quy trong khi chúng tôi cần các mô hình tiền huấn luyện cải tiến để hoàn toàn tiết lộ tiềm năng.

4.5.2 PHÂN TÍCH ĐỊNH TÍNH

Trong các nhiệm vụ lý luận, một mô hình cần tạo ra các bước lý luận trung gian để tiếp cận các câu trả lời cuối cùng, nơi mô hình phụ thuộc nhiều vào các kết quả trung gian được tạo ra bởi chính nó để dự đoán câu trả lời cuối cùng. Điều này dẫn đến các ràng buộc về thứ tự tạo sinh khi thực hiện các nhiệm vụ lý luận. Cho tính chất phi tự hồi quy của DIFFUSION-LLMs, chúng tôi tự hỏi liệu chúng có thể hiện các hành vi khác nhau trong thứ tự tạo sinh so với lý luận tự hồi quy từ trái sang phải cố định hay không.

Hiểu phụ thuộc đích với đồ thị nhân quả. Hình 6(a) mô tả đồ thị nhân quả cho bài toán ví dụ và giải pháp của nó được thể hiện trong Hình 6(b). Chúng tôi lập luận rằng để giải quyết nhiệm vụ với lý luận, các mô hình ngôn ngữ phải tạo ra các tokens theo thứ tự tuân thủ một phép sắp xếp tô pô của đồ thị nhân quả. Cụ thể, điều này có nghĩa là các yêu cầu sau đây cho thứ tự tạo sinh: (1) kết quả cuối cùng phải đến sau kết quả trung gian cuối cùng; (2) các kết quả trung gian phải đến sau việc liệt kê phương trình tương ứng; (3) để liệt kê chính xác một phương trình, các mô hình cần có ý tưởng cho phương trình này, sao chép kết quả tính toán từ các bước trước đó hoặc các số được cung cấp bởi câu hỏi; và (4) trước những điều này, các mô hình cần đề xuất ý tưởng cho mỗi bước trước.

DIFFUSION-LLMs có thể tìm ra các phép sắp xếp tô pô khả thi trên đồ thị nhân quả. Một câu hỏi tiếp theo là liệu quá trình tạo sinh của các mô hình tự hồi quy và các mô hình ngôn ngữ khuếch tán của chúng tôi có tuân thủ các phép sắp xếp tô pô có thể hay không. Một phép sắp xếp tô pô khả thi chính xác là duyệt từ trái sang phải trên văn bản chain-of-thought và được cung cấp ngầm cho các mô hình tự hồi quy trong quá trình huấn luyện. Mặt khác, các mô hình ngôn ngữ khuếch tán học mà không có thứ tự tạo sinh cố định do việc che dấu ngẫu nhiên. Hình 6(c) thể hiện quá trình tạo sinh của nó để giải quyết câu hỏi ví dụ. Mặc dù có câu trả lời cuối cùng không chính xác, quá trình tạo sinh vẫn tuân thủ một phép sắp xếp tô pô của đồ thị nhân quả trong Hình 6(a). Mô hình tạo ra các ý tưởng trước, sau đó viết các công thức, và cuối cùng tính toán các câu trả lời. Chúng tôi ngẫu nhiên lấy mẫu 30 mẫu được tạo ra bởi DIFFUSION-LLMs và thấy rằng 21 trong số những mẫu này tuân thủ một thứ tự tô pô. Điều này ngụ ý rằng các mô hình ngôn ngữ khuếch tán học cách tìm ra các phép sắp xếp tô pô khả thi, cụ thể là khả năng lý luận có cấu trúc.

DIFFUSION-LLMs lý luận với tư duy linh hoạt. Đáng chú ý, các mô hình ngôn ngữ khuếch tán có thể khám phá các phép sắp xếp tô pô khác nhau khác với các mô hình tự hồi quy nhờ vào các thứ tự tạo sinh ít bị hạn chế hơn. Chúng tôi nêu bật một số mẫu thú vị do điều này mang lại.

• Dễ trước. Hình 6(c) cho thấy rằng mô hình điền vào mẫu cố định (tức là "the final answer is") trước, thể hiện hành vi tạo sinh từ dễ đến khó khá thông minh.

• Lập kế hoạch trước. Trong Hình 6(c), mô hình xây dựng khung cho giải pháp trước khi đi vào số học. Thực tế, chúng tôi đã thấy hành vi tương tự trong Hình 2 nơi mô hình tạo ra ba mệnh đề đồng thời. Cả hai trường hợp đều chứng minh nhận thức toàn cục của mô hình giúp lập kế hoạch cho việc tạo sinh toàn bộ chuỗi.

• Lý luận tiến và lùi. Trong quá trình lý luận trong Hình 2, ở BƯỚC 31, mô hình bắt đầu giải pháp với ý tưởng cho bước lý luận cuối cùng. Điều này cho thấy hành vi lý luận lùi, một hành vi con người rất phổ biến đặc biệt hữu ích cho các hoạt động lý luận thách thức như tìm bằng chứng toán học (Kazemi et al., 2022).

• Truy ngược. Chuyển đổi lùi của các mô hình khuếch tán chính thức hỗ trợ việc truy ngược bằng cách che dấu lại. Trong Hình 6(c), BƯỚC 47 xóa một token "the". Khả năng này giúp tránh tích lũy lỗi trong các tokens được dự đoán (Arora et al., 2022).

⁵Chúng tôi thích ứng LLaMa tự hồi quy thành DIFFUSION-LLM bằng cách thay thế các attentions nhân quả bằng các attentions hai chiều và tiếp tục tiền huấn luyện mô hình với mục tiêu khuếch tán. Đồng thời, chúng tôi cũng hậu xử lý các logits đầu ra bằng cách dịch chuyển phải một token để lấp đầy khoảng cách rằng đầu ra của các mô hình tự hồi quy dự đoán token tiếp theo trong khi đầu ra của DIFFUSION-LLMs dự đoán token tại cùng vị trí với các tokens che dấu (Gong et al., 2024).

⁶Hiệu suất này có thể so sánh với việc tinh chỉnh LLaMa 3.1 tự hồi quy với tập huấn luyện GSM8K, đó là 40.36. Mặc dù chúng tôi lưu ý rằng việc tinh chỉnh trên GSM8K thực sự làm giảm hiệu suất của LLaMa 3.1 8B từ gần 80, chúng tôi coi các kết quả tinh chỉnh có thể đại diện cho hiệu suất mô hình với đủ huấn luyện dưới phân phối huấn luyện và ngụ ý khả năng tương tự giữa tự hồi quy và DIFFUSION-LLMs.

--- TRANG 10 ---
Preprint

1. Câu hỏi (1) 2. Ý tưởng Bước-1 (3) 5. Ý tưởng Bước-2 (4) 8. Ý tưởng Bước-3 (2) 3. Công thức Bước-1 6. Công thức Bước-2 (5) 9. Công thức Bước-3 (7) 4. Kết quả Bước-1 7. Kết quả Bước-2 (6) 10. Kết quả Bước-3 (8) 11. Kết quả Cuối cùng (9)

"1.": Phép sắp xếp tô pô tương ứng với duyệt từ trái sang phải của câu trả lời tham khảo. "(1)": Phép sắp xếp tô pô tương ứng với Flan-XLM-R-XXL.

Câu trả lời Từng bước (Flan-XLM-R-XXL)

BƯỚC 16 (Dễ trước.) _______________________________________________________________________________________________________________________________________Do đó, câu trả lời cuối cùng là __.

BƯỚC 31 (Lý luận lùi.) Đếm _____________________________________ ____________________________________ $ __ = $ __. Do đó, chi phí của đôi boots là $ __ * $ 33 = $ __. Do đó, câu trả lời cuối cùng là __.

BƯỚC 47 (Xây dựng khung.) Đếm chi phí của hai đôi gót __ hai đôi gót sẽ tốn Gloria tổng cộng $ 33 + $ 33 = $ __. Do đó, chi phí của ___ boots là $ __ * $ 33 = $ __. Do đó, câu trả lời cuối cùng là __.

BƯỚC 48 (Tính toán.) Đếm chi phí của hai đôi gót. hai đôi gót sẽ tốn Gloria tổng cộng $ 33 + $ 33 = $ 66. Do đó, chi phí của __ boots là $ 33 * $ 33 = $ __. do đó, câu trả lời cuối cùng là __.

BƯỚC 50 (Điền câu trả lời cuối cùng.) Đếm chi phí của hai đôi gót. hai đôi gót sẽ tốn Gloria tổng cộng $ 33 + $ 33 = $ 66. Do đó, chi phí của boots là $ 33 * $ 33 = $ 66. Do đó, câu trả lời cuối cùng là 66.

(a) (b) (c)

Câu hỏi: Gloria đang mua sắm giày khi cô ấy bắt gặp một đôi boots phù hợp với ngân sách giày của cô ấy. Tuy nhiên, cô ấy phải lựa chọn giữa đôi boots và hai đôi giày cao gót mà cùng nhau có giá rẻ hơn đôi boots năm đô la. Nếu một đôi giày cao gót có giá $33 và đôi kia có giá gấp đôi, thì đôi boots có giá bao nhiêu đô la?

Câu trả lời Từng bước (Tham khảo):
Bước 1: Chi phí của đôi giày cao gót thứ hai là 2 * $33 = $66.
Bước 2: Tổng chi phí của hai đôi giày cao gót là $33 + $66 = $99.
Bước 3: Đôi boots có giá $99 + $5 = $104.
Do đó, đôi boots có giá $104.

Câu trả lời Từng bước (Flan-T5-XXL):
Đôi giày cao gót thứ hai có giá $33 x 2 = $66. Hai đôi giày cao gót có giá $33 + $66 = $87. Đôi boots có giá $87 - $5 = $86. Câu trả lời là 86.

Câu trả lời Từng bước (LLaMA-13B được tinh chỉnh theo hướng dẫn):
Đôi giày cao gót thứ nhất có giá $33 và đôi thứ hai có giá gấp đôi, $33 * 2 = $66. Tổng chi phí của cả hai đôi giày cao gót là $66 + $33 = $99. Đôi boots có giá $99 - $5 = $94. Câu trả lời là 94.

Hình 6: Điều tra định tính về khả năng lý luận của các mô hình ngôn ngữ khuếch tán. (a) Một đồ thị nhân quả (Pearl, 1998) đại diện cho các phụ thuộc giữa các bước lý luận. (b) Một câu hỏi ví dụ, câu trả lời tham khảo của nó, và câu trả lời từ các mô hình tự hồi quy. (c) Câu trả lời từ DIFFUSION-LLM (Flan-XLM-R-XXL) và quá trình tạo sinh của nó.

4.5.3 DIFFUSION-LLMs THỂ HIỆN ƯU THẾ VỚI LÝ LUẬN YÊU CẦU LẬP KẾ HOẠCH NGẦM

431672958
(Độ = 4; Chiều dài = 3)

Câu hỏi: Đây là các cạnh trên đồ thị sao:
4,3 | 3,1 | 4,7 | 7,9 | 4,5 | 5,8 | 4,6 | 6,2
Tìm đường đi từ 4 đến 1
Trả lời: 4, 3, 1

Hình 7: Một ví dụ của Tìm đường trên Đồ thị Sao-Đường (Bachmann & Nagarajan) với độ của sao trung tâm là 4 và chiều dài của mỗi đường là 3. Nhiệm vụ nhập vào đồ thị cũng như các chỉ số nút của sao trung tâm (Nút 4 trong ví dụ) và nút đích (Nút 1 trong ví dụ), và yêu cầu mô hình tìm ra đường đi từ sao trung tâm đến nút đích ("Nút 4, Nút 3, Nút 1" trong ví dụ). Nhiệm vụ này phục vụ như một nhiệm vụ lập kế hoạch tối thiểu vì nó có thể được giải quyết đơn giản chỉ khi các mô hình nhìn trước để xem bước đầu tiên nào dẫn đến mục tiêu.

Được truyền cảm hứng bởi các quan sát định tính, chúng tôi coi rằng DIFFUSION-LLMs có thể hữu ích khi quá trình lý luận logic khác với thứ tự tuần tự (tức là từ trái sang phải) của từ trong văn bản. Điều này phổ biến, đặc biệt là đối với các nhiệm vụ lý luận thách thức, các quá trình suy nghĩ ngầm là cần thiết để lập kế hoạch trước khi đưa ra lý luận kết quả, điều này cũng được biết đến như meta-CoT (Xiang et al., 2025).

Tìm đường trên Đồ thị Sao-Đường. Để xác minh điều này, chúng tôi thí nghiệm để xem liệu DIFFUSION-LLMs có thể giải quyết Tìm đường trên Đồ thị Sao-Đường (Bachmann & Nagarajan), một bài toán liên quan đến lập kế hoạch đơn giản mà các mô hình tự hồi quy gặp khó khăn⁷. Như được thể hiện trong Hình 7, một đồ thị sao-đường chứa một nút sao trung tâm với nhiều đường có chiều dài bằng nhau tỏa ra từ nó, trong đó một trong những đường dẫn đến nút đích được chỉ định. Nhiệm vụ cho mô hình ở đây là tìm đường đi chính xác từ điểm bắt đầu đến mục tiêu. Nhiệm vụ chỉ đơn giản nếu mô hình có thể nhìn trước để khám phá bước đầu tiên nào dẫn đến mục tiêu. Chế độ thất bại đơn giản làm cho nó đại diện cho việc nghiên cứu khả năng lập kế hoạch của các mô hình.

Hình 8: So sánh giữa tự hồi quy và DIFFUSION-LLMs trên Tìm đường trên Đồ thị Sao-Đường (Bachmann & Nagarajan). Chúng tôi thí nghiệm trên hai thiết lập trong đó độ của sao trung tâm là 2 và 4, tương ứng. "Random": một bộ dự đoán bước đi ngẫu nhiên ngẫu nhiên chọn một đường trên đồ thị sao; "Autoregressive": LLaMa3.1-8B-Instruct được tinh chỉnh; "Diffusion": DIFFUSION-LLM được tinh chỉnh từ Flan-XLM-R-XXL.

So sánh với AR-LMs. Sự so sánh giữa các mô hình tự hồi quy và DIFFUSION-LLMs trong Hình 8 tiết lộ một lợi thế đáng kể của DIFFUSION-LLMs trong việc giải quyết các nhiệm vụ lý luận yêu cầu lập kế hoạch ngầm. Để điều tra điều này sâu hơn, chúng tôi tinh chỉnh hai mô hình đại diện - LLaMa3.1-8B-Instruct và Flan-XLM-R-XXL - trên các nhiệm vụ Tìm đường trên Đồ thị Sao-Đường và đánh giá hiệu suất khái quát hóa của chúng trên các cấu trúc đồ thị chưa từng thấy. Đánh giá của chúng tôi bao gồm hai thiết lập thí nghiệm khác nhau được thiết kế để kiểm tra khả năng lý luận đa bước và lập kế hoạch ngầm của các mô hình. Trong cả hai trường hợp, các mô hình tự hồi quy thể hiện thành công hạn chế, gặp khó khăn trong việc nắm bắt cấu trúc đồ thị cơ bản và lập kế hoạch hiệu quả. Hiệu suất của chúng giống như một bước đi ngẫu nhiên, cho thấy niềm tin vào không thể tận dụng thông tin cấu trúc để dự đoán chính xác. Ngược lại, DIFFUSION-LLMs nhất quán

⁷Chúng tôi giới thiệu độc giả đến Ye et al. (2024) mà trình bày chi tiết về khả năng lập kế hoạch của DIFFUSION-LLM.

--- TRANG 11 ---
Preprint

tạo ra các dự đoán gần như hoàn hảo, thể hiện khả năng đáng chú ý trong việc xử lý các nhiệm vụ lập kế hoạch ngầm.

Sự khác biệt hiệu suất này nêu bật một khác biệt kiến trúc chính: trường nhận thức hai chiều trong DIFFUSION-LLMs cho phép mô hình nắm bắt các phụ thuộc toàn cục trên đầu vào một cách hiệu quả hơn. Điều này không chỉ tạo điều kiện cho lý luận tốt hơn trong môi trường có cấu trúc mà còn mang lại cho DIFFUSION-LLMs một lợi thế rõ ràng trong các nhiệm vụ yêu cầu lập kế hoạch và suy luận đa bước. Những phát hiện này cho thấy rằng DIFFUSION-LLMs được trang bị tốt hơn để mô hình hóa các phụ thuộc phức tạp, phi tuần tự, mở ra những khả năng mới cho các ứng dụng dựa trên lý luận vượt quá khả năng của các mô hình tự hồi quy thông thường.

4.6 DIFFUSION-LLMs NHƯ NHỮNG NGƯỜI HỌC ĐA PHƯƠNG THỨC

Những tiến bộ gần đây trong các mô hình ngôn ngữ lớn mở rộng vượt quá xử lý ngôn ngữ, hướng đến việc thống nhất nhiều phương thức end-to-end cho các tương tác đa phương thức liền mạch (Zhan et al., 2024). Cho sự thống trị của các mô hình khuếch tán trong việc tạo ra tín hiệu liên tục Dhariwal & Nichol (2021); Bar-Tal et al. (2024) và khả năng ngôn ngữ xuất sắc được thể hiện trong nghiên cứu này, chúng tôi tin rằng DIFFUSION-LLMs đóng góp vào một mô hình đầy hứa hẹn để phát triển các mô hình đa phương thức thống nhất. Điều này thúc đẩy chúng tôi khám phá DIFFUSION-LLMs cho các nhiệm vụ đa phương thức.

Đặc biệt, chúng tôi điều tra liệu DIFFUSION-LLMs có thể giải quyết trả lời câu hỏi trực quan (VQA) hay không. Chúng tôi theo LLaVa (Liu et al., 2024) để tiến hành huấn luyện hai giai đoạn trên FLAN-XLM-R-XXL. Trong giai đoạn đầu tiên, chúng tôi đóng băng backbone mô hình ngôn ngữ và huấn luyện một projector để ánh xạ đặc trưng thị giác được trích xuất từ bộ mã hóa thị giác CLIP tiền huấn luyện ViT-L/14 (Radford et al., 2021) thành embeddings bằng cách sử dụng tập con 558k của LAION-CC-SBU (Liu et al., 2024). Sau đó, chúng tôi cùng tinh chỉnh backbone LM và các projectors cho VQA với dữ liệu LLaVA-v1.5-mix665k (Liu et al., 2024).

Bảng 4: Hiệu suất exact match zero-shot của DIFFUSION-LLM và AR-LLMs trên tập dev của GQA (Hudson & Manning, 2019).

[THIS IS TABLE: A simple table showing performance comparison between DIFFUSION-LLM (Flan-XLM-R-XXL) with 39.93 and AR-LLM (Flan-T5-XXL) with 44.71 exact match scores]

Bảng 4 cho thấy hiệu suất zero-shot của các mô hình chúng tôi trên tập dev của GQA (Hudson & Manning, 2019). Để tham khảo, chúng tôi tương ứng tăng cường một mô hình Flan-T5-XXL với khả năng hiểu thị giác bằng cùng một công thức. Kết quả cho thấy hiệu suất có ý nghĩa hỗ trợ khả năng hiểu thị giác của mô hình chúng tôi, gần với khả năng thích ứng từ Flan-T5. Nghiên cứu trường hợp trên Hình 9 cho thấy rằng mô hình thể hiện hành vi tương tự như những gì chúng tôi thấy trong nghiên cứu định tính cho các nhiệm vụ lý luận (Phần 4.5.2) khi tạo ra câu trả lời cho các nhiệm vụ thị giác. Trong ba trường hợp, các mô hình trả lời theo thứ tự dễ-trước nơi chúng trước tiên tạo ra nội dung có thể được sao chép từ câu hỏi để xây dựng khung của câu và sau đó điền vào các câu trả lời chính ở cuối. Trong Hình 9(C), nơi câu trả lời chính chứa nhiều thực thể, DIFFUSION-LLMs điền chúng đồng thời, cho thấy khả năng xử lý song song thông tin thị giác khác nhau.

Câu hỏi: Có bao nhiêu máy bay nhìn thấy trong hình ảnh?
Trả lời (bước 42): Có _____ máy bay ____ nhìn thấy trong hình ảnh.
Trả lời (bước 50): Có hai máy bay nhìn thấy trong hình ảnh.

Câu hỏi: Con chó trong hình ảnh có màu gì?
Trả lời (bước 43): Con chó trong hình ảnh là ____.
Trả lời (bước 50): Con chó trong hình ảnh là màu đen.

Câu hỏi: Loại động vật nào được trưng bày sau kính trong bảo tàng?
Trả lời (bước 43): Trong bảo tàng, có _______ động vật, như ____ và_____, được trưng bày sau kính.
Trả lời (bước 50): Trong bảo tàng, có nhiều động vật khác nhau, như ngựa vằn và hươu cao cổ, được trưng bày sau kính.

(A) (B) (C)

Hình 9: Trả lời câu hỏi trực quan với DIFFUSION-LLMs. Chúng tôi đặt các bước lặp cho DIFFUSION-LLMs để tạo ra đầu ra cuối cùng là 50. Tương tự như thảo luận trong Phần 4.5.2, mô hình trước tiên tạo ra nội dung dễ và điền câu trả lời ở cuối.

Những kết quả này chứng minh DIFFUSION-LLMs cũng có thể hiểu thông tin đa phương thức tương tự như các LMs tự hồi quy gần đây. Cùng với khả năng tạo sinh, cho cả tạo sinh thị giác được kiểm tra tốt (Dhariwal & Nichol, 2021; Rombach et al., 2022; Bar-Tal et al., 2024) cũng như khả năng tạo sinh ngôn ngữ được xác minh trong nghiên cứu của chúng tôi, các mô hình khuếch tán làm sáng tỏ một mô hình thống nhất hấp dẫn cho các mô hình nền tảng đa phương thức.

--- TRANG 12 ---
Preprint

5 THẢO LUẬN

Trong công trình này, chúng tôi tiên phong trong việc nghiên cứu khả năng mở rộng quy mô của DIFFUSION-LLMs để bắt kịp những tiến bộ gần đây của LLMs và tạo điều kiện cho việc khám phá tiềm năng của chúng. Các thí nghiệm của chúng tôi xác minh khả năng mở rộng quy mô của chúng liên quan đến dữ liệu, kích thước mô hình và nhiệm vụ. Hơn nữa, chúng tôi thể hiện triển vọng tích cực về khả năng lý luận của chúng như tạo sinh theo thứ tự nhân quả và lập kế hoạch ngầm để khai thác thêm.

Tiến bộ mới nhất về các mô hình ngôn ngữ khuếch tán. Sau lần phát hành đầu tiên của nghiên cứu DIFFUSION-LLM của chúng tôi, các mô hình ngôn ngữ khuếch tán đã thu hút sự chú ý rộng rãi và rất nhiều nghiên cứu liên quan mật thiết đã xuất hiện. Như vậy, chúng tôi muốn nêu bật tiến bộ mới nhất để tạo điều kiện cho nhiều tiến bộ sắp tới hơn trong lĩnh vực này.

• Nền tảng. Để công thức hóa một mô hình ngôn ngữ khuếch tán, Ou et al. (2024); Sahoo et al. (2024); Shi et al. (2024); Wang et al. (2024a;b) cũng nghiên cứu các mục tiêu giống như mô hình hóa ngôn ngữ có che dấu tương tự như của chúng tôi và xác minh hiệu quả của chúng. Thay vào đó, Lou et al. khám phá việc học các mô hình ngôn ngữ khuếch tán rời rạc bằng cách học tỷ lệ xác suất như phần mở rộng của score matching và Gat et al. (2025) mở rộng công thức flow matching. Tất cả những nghiên cứu này xác nhận tính thực tế của việc xây dựng các mô hình ngôn ngữ khuếch tán có năng lực để phục vụ như một mô hình thay thế cho các mô hình ngôn ngữ tự hồi quy, với các cách thức cụ thể phát triển.

• Xác minh mở rộng quy mô. Khả năng mở rộng quy mô của các mô hình ngôn ngữ khuếch tán dưới các mục tiêu giống như mô hình hóa ngôn ngữ có che dấu có tiến bộ nhanh chóng. Gong et al. (2024) thành công xây dựng các mô hình ngôn ngữ khuếch tán quy mô lớn bằng cách thích ứng từ các mô hình ngôn ngữ tự hồi quy, cung cấp một lộ trình đầy hứa hẹn khác để có được các mô hình ngôn ngữ khuếch tán lớn với chi phí tương đối thấp. Nie et al. (2024) điều tra việc tiền huấn luyện các mô hình ngôn ngữ khuếch tán từ đầu và cho thấy một quy luật mở rộng quy mô song song với các mô hình ngôn ngữ tự hồi quy, cho thấy xu hướng mở rộng quy mô tương tự của hai mô hình. Nie et al. (2025) tiếp tục mở rộng quy mô các mô hình ngôn ngữ khuếch tán tiền huấn luyện lên 8B tham số và 2.3T tokens tiền huấn luyện với các công thức cập nhật, với kết quả nêu bật khả năng cạnh tranh của các mô hình ngôn ngữ khuếch tán với các mô hình tự hồi quy mã nguồn mở tiên tiến trên các benchmarks được công nhận rộng rãi cho các mô hình ngôn ngữ lớn và thể hiện một chatbot hữu ích được xây dựng dựa trên các mô hình ngôn ngữ khuếch tán lớn. Ngoài ngôn ngữ tự nhiên, Wang et al. (2024a) mở rộng quy mô các mô hình ngôn ngữ khuếch tán để tăng cường mô hình tạo sinh protein.

• Khả năng và ứng dụng. Các mô hình ngôn ngữ khuếch tán có trường nhận thức hai chiều và có thể thực hiện tinh chỉnh bằng bản chất. Vì lý do này, tiến bộ gần đây đã xác nhận rằng các mô hình ngôn ngữ khuếch tán thể hiện ưu thế trong các tình huống mà thứ tự tạo sinh từ trái sang phải là không tối ưu. Ví dụ, Ye et al. (2024) cho thấy lợi thế của chúng trong các nhiệm vụ yêu cầu lập kế hoạch ngầm và Nie et al. (2024; 2025) cho thấy các mô hình ngôn ngữ khuếch tán có thể sửa lỗi reversal curse của các mô hình tự hồi quy (Berglund et al., 2023). Đáng chú ý, các ứng dụng của các mô hình ngôn ngữ khuếch tán thể hiện những tiến bộ đáng kể trong các lĩnh vực khoa học. Với các mô hình ngôn ngữ khuếch tán, DPLM (Wang et al., 2024a) xây dựng các mô hình nền tảng tiên tiến cho protein và DPLM-2 (Wang et al., 2024b) tiếp tục điều tra các mô hình ngôn ngữ khuếch tán đa phương thức để thống nhất mô hình tạo sinh của các chuỗi và cấu trúc protein.

Chúng tôi hy vọng rằng các phát hiện của chúng tôi cũng như thảo luận về tiến bộ mới nhất có thể thúc đẩy sự thành công của các mô hình khuếch tán trong các lĩnh vực rộng lớn hơn và cũng khuyến khích đầu tư vào sự bổ sung hấp dẫn này cho các LLMs tự hồi quy, điều này có thể đẩy lùi ranh giới của các kỹ thuật để theo đuổi trí tuệ máy tiên tiến hơn.

TÀI LIỆU THAM KHẢO

Kushal Arora, Layla El Asri, Hareesh Bahuleyan, và Jackie Chi Kit Cheung. Why exposure bias matters: An imitation learning perspective of error accumulation in language generation. arXiv preprint arXiv:2204.01171, 2022.

Jacob Austin, Daniel D Johnson, Jonathan Ho, Daniel Tarlow, và Rianne van den Berg. Structured denoising diffusion models in discrete state-spaces. Advances in Neural Information Processing Systems, 34:17981–17993, 2021.

--- TRANG 13 ---
Preprint

Gregor Bachmann và Vaishnavh Nagarajan. The pitfalls of next-token prediction. In Forty-first International Conference on Machine Learning.

Omer Bar-Tal, Hila Chefer, Omer Tov, Charles Herrmann, Roni Paiss, Shiran Zada, Ariel Ephrat, Junhwa Hur, Yuanzhen Li, Tomer Michaeli, et al. Lumiere: A space-time diffusion model for video generation. arXiv preprint arXiv:2401.12945, 2024.

Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, và Owain Evans. The reversal curse: Llms trained on" a is b" fail to learn" b is a". arXiv preprint arXiv:2309.12288, 2023.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020.

Huiwen Chang, Han Zhang, Lu Jiang, Ce Liu, và William T Freeman. Maskgit: Masked generative image transformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 11315–11325, 2022.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, và Noah Fiedel. Palm: Scaling language modeling with pathways, 2022.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022.

Jonathan H Clark, Eunsol Choi, Michael Collins, Dan Garrette, Tom Kwiatkowski, Vitaly Nikolaev, và Jennimaria Palomaki. Tydi qa: A benchmark for information-seeking question answering in typologically diverse languages. Transactions of the Association for Computational Linguistics, 8:454–470, 2020.

Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021.

Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, và Veselin Stoyanov. Unsupervised cross-lingual representation learning at scale. arXiv preprint arXiv:1911.02116, 2019.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.

Prafulla Dhariwal và Alexander Nichol. Diffusion models beat gans on image synthesis. Advances in neural information processing systems, 34:8780–8794, 2021.

Yao Fu, Hao Peng, Litu Ou, Ashish Sabharwal, và Tushar Khot. Specializing smaller language models towards multi-step reasoning. arXiv preprint arXiv:2301.12726, 2023.

Zhujin Gao, Junliang Guo, Xu Tan, Yongxin Zhu, Fang Zhang, Jiang Bian, và Linli Xu. Difformer: Empowering diffusion model on embedding space for text generation. arXiv preprint arXiv:2212.09412, 2022.

--- TRANG 14 ---
Preprint

Itai Gat, Tal Remez, Neta Shaul, Felix Kreuk, Ricky TQ Chen, Gabriel Synnaeve, Yossi Adi, và Yaron Lipman. Discrete flow matching. Advances in Neural Information Processing Systems, 37:133345–133385, 2025.

Yuying Ge, Sijie Zhao, Ziyun Zeng, Yixiao Ge, Chen Li, Xintao Wang, và Ying Shan. Making llama see and draw with seed tokenizer. arXiv preprint arXiv:2310.01218, 2023.

Marjan Ghazvininejad, Omer Levy, Yinhan Liu, và Luke Zettlemoyer. Mask-predict: Parallel decoding of conditional masked language models. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 6112–6121, 2019.

Shansan Gong, Mukai Li, Jiangtao Feng, Zhiyong Wu, và LingPeng Kong. Diffuseq: Sequence to sequence text generation with diffusion models. arXiv preprint arXiv:2210.08933, 2022.

Shansan Gong, Shivam Agarwal, Yizhe Zhang, Jiacheng Ye, Lin Zheng, Mukai Li, Chenxin An, Peilin Zhao, Wei Bi, Jiawei Han, et al. Scaling diffusion language models via adaptation from autoregressive models. arXiv preprint arXiv:2410.17891, 2024.

Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, và Alexis Conneau. Larger-scale transformers for multilingual masked language modeling. arXiv preprint arXiv:2105.00572, 2021.

Jiatao Gu, James Bradbury, Caiming Xiong, Victor OK Li, và Richard Socher. Non-autoregressive neural machine translation. In International Conference on Learning Representations, 2018.

Aaron Harlap, Deepak Narayanan, Amar Phanishayee, Vivek Seshadri, Nikhil Devanur, Greg Ganger, và Phil Gibbons. Pipedream: Fast and efficient pipeline parallel dnn training. arXiv preprint arXiv:1806.03377, 2018.

Zhengfu He, Tianxiang Sun, Kuanning Wang, Xuanjing Huang, và Xipeng Qiu. Diffusionbert: Improving generative masked language models with diffusion models. 2023.

Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, và Jacob Steinhardt. Measuring massive multitask language understanding. arXiv preprint arXiv:2009.03300, 2020.

Jonathan Ho, Ajay Jain, và Pieter Abbeel. Denoising diffusion probabilistic models. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, và H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 6840–6851. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf.

Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko, Diederik P Kingma, Ben Poole, Mohammad Norouzi, David J Fleet, et al. Imagen video: High definition video generation with diffusion models. arXiv preprint arXiv:2210.02303, 2022.

Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. Training compute-optimal large language models. arXiv preprint arXiv:2203.15556, 2022.

Emiel Hoogeboom, Didrik Nielsen, Priyank Jaini, Patrick Forré, và Max Welling. Argmax flows and multinomial diffusion: Learning categorical distributions. Advances in Neural Information Processing Systems, 34:12454–12465, 2021.

Yanping Huang, Youlong Cheng, Ankur Bapna, Orhan Firat, Dehao Chen, Mia Chen, HyoukJoong Lee, Jiquan Ngiam, Quoc V Le, Yonghui Wu, et al. Gpipe: Efficient training of giant neural networks using pipeline parallelism. Advances in neural information processing systems, 32, 2019.

Drew A Hudson và Christopher D Manning. Gqa: A new dataset for real-world visual reasoning and compositional question answering. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 6700–6709, 2019.

--- TRANG 15 ---
Preprint

Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. Mistral 7b. arXiv preprint arXiv:2310.06825, 2023.

Seyed Mehran Kazemi, Najoung Kim, Deepti Bhatia, Xin Xu, và Deepak Ramachandran. Lambada: Backward chaining for automated reasoning in natural language. arXiv preprint arXiv:2212.13894, 2022.

Diederik P. Kingma và Jimmy Ba. Adam: A method for stochastic optimization. In Yoshua Bengio và Yann LeCun (eds.), 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015. URL http://arxiv.org/abs/1412.6980.

Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, và Bryan Catanzaro. Diffwave: A versatile diffusion model for audio synthesis. In International Conference on Learning Representations, 2020.

Shigang Li và Torsten Hoefler. Chimera: efficiently training large-scale neural networks with bidirectional pipelines. In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, pp. 1–14, 2021.

Xiang Lisa Li, John Thickstun, Ishaan Gulrajani, Percy Liang, và Tatsunori Hashimoto. Diffusion-lm improves controllable text generation. ArXiv, abs/2205.14217, 2022.

Zhenghao Lin, Yeyun Gong, Yelong Shen, Tong Wu, Zhihao Fan, Chen Lin, Weizhu Chen, và Nan Duan. Genie: Large scale pre-training for text generation with diffusion model. arXiv preprint arXiv:2212.11685, 2022.

Haotian Liu, Chunyuan Li, Qingyang Wu, và Yong Jae Lee. Visual instruction tuning. Advances in neural information processing systems, 36, 2024.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 2019.

Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V Le, Barret Zoph, Jason Wei, et al. The flan collection: Designing data and methods for effective instruction tuning. arXiv preprint arXiv:2301.13688, 2023.

Aaron Lou, Chenlin Meng, và Stefano Ermon. Discrete diffusion modeling by estimating the ratios of the data distribution. In Forty-first International Conference on Machine Learning.

Shen Nie, Fengqi Zhu, Chao Du, Tianyu Pang, Qian Liu, Guangtao Zeng, Min Lin, và Chongxuan Li. Scaling up masked diffusion models on text. arXiv preprint arXiv:2410.18514, 2024.

Shen Nie, Fengqi Zhu, Zebin You, Xiaolu Zhang, Jingyang Ou, Jun Hu, Jun Zhou, Yankai Lin, Ji-Rong Wen, và Chongxuan Li. Large language diffusion models, 2025. URL https://arxiv.org/abs/2502.09992.

OpenAI. Gpt-4 technical report, 2023.

Jingyang Ou, Shen Nie, Kaiwen Xue, Fengqi Zhu, Jiacheng Sun, Zhenguo Li, và Chongxuan Li. Your absorbing discrete diffusion secretly models the conditional distributions of clean data. arXiv preprint arXiv:2406.03736, 2024.

Ajay Patel, Bryan Li, Mohammad Sadegh Rasooli, Noah Constant, Colin Raffel, và Chris Callison-Burch. Bidirectional language models are also few-shot learners. arXiv preprint arXiv:2209.14500, 2022.

Judea Pearl. Graphical models for probabilistic and causal reasoning. Quantified representation of uncertainty and imprecision, pp. 367–389, 1998.

Matt Post. A call for clarity in reporting bleu scores. In Proceedings of the Third Conference on Machine Translation: Research Papers, pp. 186–191, 2018.

--- TRANG 16 ---
Preprint

Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Improving language understanding by generative pre-training. 2018.

Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In International conference on machine learning, pp. 8748–8763. PMLR, 2021.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, et al. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 21(140):1–67, 2020.

Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, và Mark Chen. Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125, 2022.

Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, và Björn Ommer. High-resolution image synthesis with latent diffusion models, 2021.

Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, và Björn Ommer. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 10684–10695, 2022.

Subham Sekhar Sahoo, Marianne Arriola, Yair Schiff, Aaron Gokaslan, Edgar Marroquin, Justin T Chiu, Alexander Rush, và Volodymyr Kuleshov. Simple and effective masked diffusion language models. arXiv preprint arXiv:2406.07524, 2024.

Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Stella Biderman, Leo Gao, Tali Bers, Thomas Wolf, và Alexander M. Rush. Multitask prompted training enables zero-shot task generalization, 2021.

Nikolay Savinov, Junyoung Chung, Mikolaj Binkowski, Erich Elsen, và Aaron van den Oord. Step-unrolled denoising autoencoders for text generation. In International Conference on Learning Representations, 2021.

Teven Le Scao, Thomas Wang, Daniel Hesslow, Lucile Saulnier, Stas Bekman, M Saiful Bari, Stella Bideman, Hady Elsahar, Niklas Muennighoff, Jason Phang, et al. What language model to train if you have one million gpu hours? arXiv preprint arXiv:2210.15424, 2022.

Noam Shazeer. Glu variants improve transformer. arXiv preprint arXiv:2002.05202, 2020.

Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won Chung, Yi Tay, Sebastian Ruder, Denny Zhou, et al. Language models are multilingual chain-of-thought reasoners. arXiv preprint arXiv:2210.03057, 2022.

Jiaxin Shi, Kehang Han, Zhe Wang, Arnaud Doucet, và Michalis K Titsias. Simplified and generalized masked diffusion for discrete data. arXiv preprint arXiv:2406.04329, 2024.

Charlie Snell, Eric Wallace, Dan Klein, và Sergey Levine. Predicting emergent capabilities by finetuning. arXiv preprint arXiv:2411.16035, 2024.

Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, và Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In Francis Bach và David Blei (eds.), Proceedings of the 32nd International Conference on Machine Learning, volume 37 of Proceedings of Machine Learning Research, pp. 2256–2265, Lille, France, 07–09 Jul 2015. PMLR. URL https://proceedings.mlr.press/v37/sohl-dickstein15.html.

Yi Tay, Mostafa Dehghani, Vinh Q Tran, Xavier Garcia, Jason Wei, Xuezhi Wang, Hyung Won Chung, Dara Bahri, Tal Schuster, Steven Zheng, et al. Ul2: Unifying language learning paradigms. In The Eleventh International Conference on Learning Representations, 2022.

--- TRANG 17 ---
Preprint

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, và Guillaume Lample. Llama: Open and efficient foundation language models, 2023a.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023b.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.

Xinyou Wang, Zaixiang Zheng, Fei Ye, Dongyu Xue, Shujian Huang, và Quanquan Gu. Diffusion language models are versatile protein learners. arXiv preprint arXiv:2402.18567, 2024a.

Xinyou Wang, Zaixiang Zheng, Fei Ye, Dongyu Xue, Shujian Huang, và Quanquan Gu. Dplm-2: A multimodal diffusion protein language model. arXiv preprint arXiv:2410.13782, 2024b.

Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. Super-naturalinstructions: generalization via declarative instructions on 1600+ tasks. In EMNLP, 2022.

Benjamin Warner, Antoine Chaffin, Benjamin Clavié, Orion Weller, Oskar Hallström, Said Taghadouini, Alexis Gallagher, Raja Biswas, Faisal Ladhak, Tom Aarsen, et al. Smarter, better, faster, longer: A modern bidirectional encoder for fast, memory efficient, and long context finetuning and inference. arXiv preprint arXiv:2412.13663, 2024.

Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, và Quoc V Le. Finetuned language models are zero-shot learners. In International Conference on Learning Representations, 2021.

Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682, 2022.

Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco Guzmán, Armand Joulin, và Édouard Grave. Ccnet: Extracting high quality monolingual datasets from web crawl data. In Proceedings of The 12th Language Resources and Evaluation Conference, pp. 4003–4012, 2020.

Violet Xiang, Charlie Snell, Kanishk Gandhi, Alon Albalak, Anikait Singh, Chase Blagden, Duy Phung, Rafael Rafailov, Nathan Lile, Dakota Mahan, et al. Towards system 2 reasoning in llms: Learning how to think with meta chain-of-thought. arXiv preprint arXiv:2501.04682, 2025.

Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, và Colin Raffel. mt5: A massively multilingual pre-trained text-to-text transformer. arXiv preprint arXiv:2010.11934, 2020.

Jiacheng Ye, Jiahui Gao, Shansan Gong, Lin Zheng, Xin Jiang, Zhenguo Li, và Lingpeng Kong. Beyond autoregression: Discrete diffusion for complex reasoning and planning. arXiv preprint arXiv:2410.14157, 2024.

Jiasheng Ye, Zaixiang Zheng, Yu Bao, Lihua Qian, và Mingxuan Wang. Dinoiser: Diffused conditional sequence learning by manipulating noises. arXiv preprint arXiv:2302.10025, 2023.

Hongyi Yuan, Zheng Yuan, Chuanqi Tan, Fei Huang, và Songfang Huang. Seqdiffuseq: Text diffusion with encoder-decoder transformers. arXiv preprint arXiv:2212.10325, 2022.

Jun Zhan, Junqi Dai, Jiasheng Ye, Yunhua Zhou, Dong Zhang, Zhigeng Liu, Xin Zhang, Ruibin Yuan, Ge Zhang, Linyang Li, et al. Anygpt: Unified multimodal llm with discrete sequence modeling. arXiv preprint arXiv:2402.12226, 2024.

--- TRANG 18 ---
Preprint

Biao Zhang, Behrooz Ghorbani, Ankur Bapna, Yong Cheng, Xavier Garcia, Jonathan Shen, và Orhan Firat. Examining scaling and transfer of language model architectures for machine translation. In International Conference on Machine Learning, pp. 26176–26192. PMLR, 2022.

Dong Zhang, Shimin Li, Xin Zhang, Jun Zhan, Pengyu Wang, Yaqian Zhou, và Xipeng Qiu. Speechgpt: Empowering large language models with intrinsic cross-modal conversational abilities. arXiv preprint arXiv:2305.11000, 2023.

Lin Zheng, Jianbo Yuan, Lei Yu, và Lingpeng Kong. A reparameterized discrete diffusion model for text generation. arXiv preprint arXiv:2302.05737, 2023a.

Zaixiang Zheng, Yifan Deng, Dongyu Xue, Yi Zhou, Fei YE, và Quanquan Gu. Structure-informed language models are protein designers. In International Conference of Machine Learning (ICML), 2023b.

--- TRANG 19 ---
Preprint

A CHI TIẾT THỰC HIỆN

A.1 MÔ HÌNH

Trong suốt công việc này, chúng tôi chủ yếu theo Zheng et al. (2023a) để huấn luyện và lấy mẫu từ các mô hình ngôn ngữ khuếch tán của chúng tôi. Cụ thể, chúng tôi đặt λ(2) t−1 = 1−t−1 T trong mục tiêu huấn luyện trong đó t là timestep hiện tại và T là số lượng timesteps tổng cộng là 50 trong các thí nghiệm của chúng tôi. Ngoài ra, chúng tôi áp dụng label smoothing với hệ số 0.1 khi chúng tôi huấn luyện một mô hình mà không có tiền huấn luyện. Trong quá trình lấy mẫu, chúng tôi cũng theo Ghazvininejad et al. (2019); Savinov et al. (2021); Zheng et al. (2023b) và khử nhiễu các tokens với điểm số cao trong mỗi bước thay vì lấy mẫu ngây thơ từ các phân phối Bernoulli. Chúng tôi sử dụng cùng lịch trình cosine như trong Zheng et al. (2023a) để quyết định số lượng tokens được khử nhiễu trong mỗi bước k = ⌊N·cos πt 2T ⌋, trong đó N là chiều dài chuỗi. Để biết chi tiết đầy đủ, chúng tôi giới thiệu độc giả đến mã giả trong bài báo gốc (Zheng et al., 2023a, Algorithm 2). Để dự đoán độ dài, chúng tôi đưa đầu ra mô hình vào một transformer một lớp, áp dụng pooling trung bình cho các đặc trưng và đưa đặc trưng được pooled vào một đầu phân loại MLP. Để tinh chỉnh theo nhiệm vụ cụ thể, chúng tôi loại bỏ cả embeddings đầu vào và đầu ra của các tokens không xuất hiện trong tập huấn luyện.

A.2 DỮ LIỆU

Đối với các nhiệm vụ dịch máy IWSLT14 và WMT14, chúng tôi tải xuống và tiền xử lý dữ liệu theo các script ví dụ được cung cấp bởi Fairseq⁸, và chúng tôi sử dụng SacreBleu (Post, 2018) để đánh giá⁹. Và chúng tôi tải xuống dữ liệu Gigaword-10K từ repository của LGEB¹⁰. Đối với (M)GSM, chúng tôi theo hướng dẫn¹¹ trong repository chính thức của Shi et al. (2022) để xử lý dữ liệu và prompts. Ngoài ra, chúng tôi thu được Flan 2021¹² đã được tiền xử lý, Flan 2022¹³, MMLU¹⁴, và TydiQA¹⁵ từ các tập dữ liệu được chia sẻ trên HuggingFace¹⁶. Trong quá trình huấn luyện với Flan 2022, chúng tôi theo các tỷ lệ được khuyến nghị trong Chung et al. (2022) để lấy mẫu dữ liệu huấn luyện từ các tập con khác nhau. Chúng tôi theo Chung et al. (2022) để báo cáo hiệu suất MMLU trên tập validation và áp dụng thiết lập GoldP cho TyDiQA như trong Chowdhery et al. (2022); Chung et al. (2022). Về các thiết lập few-shot, chúng tôi chọn ngẫu nhiên các minh chứng. Chúng tôi cũng sẽ phát hành mã và dữ liệu của chúng tôi để tái tạo tốt hơn.

A.3 CHI TIẾT HUẤN LUYỆN

Chúng tôi sử dụng bộ tối ưu hóa Adam (Kingma & Ba, 2015) trong suốt nghiên cứu của chúng tôi. Tỷ lệ dropout phù hợp với cấu hình gốc của các mô hình là 0.1. Để tinh chỉnh theo nhiệm vụ cụ thể, chúng tôi sử dụng 8 GPU Nvidia A100. Để tinh chỉnh theo hướng dẫn, chúng tôi sử dụng 8 GPU Nvidia V100 cho các mô hình kích thước BASE và LARGE, 32 cho XL, và 64 cho XXL. Kích thước batch tổng thể và các siêu tham số chi tiết khác cho hai thiết lập lần lượt trong Bảng 5 và Bảng 6.

⁸https://github.com/facebookresearch/fairseq/tree/main/examples/translation
⁹Chữ ký của sacrebleu cho IWSLT14 DE→EN là nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.3.1, và cho WMT14 EN→DE nrefs:1|case:mixed|eff:no|tok:intl|smooth:exp|version:2.3.1, tương ứng.
¹⁰https://github.com/CLUEbenchmark/LGEB
¹¹https://github.com/google-research/url-nlp/tree/main/mgsm
¹²https://huggingface.co/datasets/Muennighoff/flan
¹³https://huggingface.co/datasets/SirNeural/flan_v2
¹⁴https://huggingface.co/datasets/cais/mmlu
¹⁵https://huggingface.co/datasets/khalidalt/tydiqa-goldp
¹⁶https://huggingface.co/datasets

--- TRANG 20 ---
Preprint

Bảng 5: Các siêu tham số huấn luyện cho tinh chỉnh theo nhiệm vụ cụ thể.

[THIS IS TABLE: Training hyperparameters for task-specific finetuning, showing Dataset, Pretrained model, Batch size, Learning rate, and Training steps for various datasets including IWSLT14, WMT14, and Gigaword-10K with different XLM-R model sizes]

Bảng 6: Các siêu tham số huấn luyện cho tinh chỉnh theo hướng dẫn.

[THIS IS TABLE: Training hyperparameters for instruction finetuning, showing Training data, Pretrained model, Batch size, Learning rate, and Training steps for Flan 2021 and Flan 2022 datasets with different XLM-R model sizes]

--- TRANG 21 ---
Preprint

Hình 10: Hiệu suất few-shot của các mô hình Flan-XLM-R và Flan-T5. "OL" có nghĩa là kết quả được thu được với độ dài oracle, trong khi "LB" có nghĩa là số lượng length beams để lấy mẫu đích với dự đoán độ dài. Kích thước mô hình đề cập đến số lượng tham số không phải embedding.

B KẾT QUẢ THỰC NGHIỆM ĐẦY ĐỦ

Kết quả thực nghiệm cho tinh chỉnh theo nhiệm vụ cụ thể và tinh chỉnh theo hướng dẫn trên Flan 2022 lần lượt trong Bảng 7 và Bảng 8.

Bảng 7: Kết quả thực nghiệm đầy đủ của tinh chỉnh theo nhiệm vụ cụ thể. OL: kết quả được thu được với độ dài oracle. LB: kích thước của length beam cho dự đoán độ dài.

[THIS IS TABLE: Shows experimental results for task-specific finetuning across different datasets (IWSLT14, WMT14, Gigaword-10K) with various XLM-R model sizes, including OL and LB=10 settings]

Bảng 8: Kết quả thực nghiệm đầy đủ của tinh chỉnh theo hướng dẫn trên Flan 2022. OL: kết quả được thu được với độ dài oracle. LB: kích thước của length beam cho dự đoán độ dài.

[THIS IS TABLE: Shows experimental results for instruction tuning on Flan 2022 across different datasets (IWSLT14, MMLU, TyDiQA, MGSM, GSM8K) with various XLM-R model sizes, including different shot settings and evaluation metrics]

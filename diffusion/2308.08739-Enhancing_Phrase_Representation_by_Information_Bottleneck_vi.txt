# Nâng cao Biểu diễn Cụm từ bằng Quá trình Khuếch tán Văn bản được Hướng dẫn bởi Nút thắt Thông tin cho Trích xuất Cụm từ Khóa

Yuanzhen Luo1†, Qingyu Zhou2∗, Feng Zhou2
1Đại học Dầu khí Trung Quốc, Bắc Kinh
2Viện Nghiên cứu OPPO
strugglingluo@gmail.com, qyzhgm@gmail.com, zhoufeng1@oppo.com

Tóm tắt
Trích xuất cụm từ khóa (KPE) là một nhiệm vụ quan trọng trong Xử lý Ngôn ngữ Tự nhiên cho nhiều tình huống, nhằm trích xuất các cụm từ khóa có mặt trong một tài liệu cho trước. Nhiều phương pháp giám sát hiện tại xem KPE như gán nhãn tuần tự, phân loại cấp độ đoạn, hoặc các nhiệm vụ sinh. Tuy nhiên, các phương pháp này thiếu khả năng sử dụng thông tin cụm từ khóa tham chiếu trong quá trình trích xuất, có thể dẫn đến kết quả kém hơn. Trong nghiên cứu này, chúng tôi đề xuất Diff-KPE, sử dụng Nút thắt Thông tin Biến phân có giám sát (VIB) để hướng dẫn quá trình khuếch tán văn bản nhằm tạo ra các biểu diễn cụm từ khóa được nâng cao. Diff-KPE đầu tiên tạo ra các embedding cụm từ khóa mong muốn có điều kiện trên toàn bộ tài liệu và sau đó tiêm các embedding cụm từ khóa được tạo vào mỗi biểu diễn cụm từ. Một mạng xếp hạng và VIB sau đó được tối ưu hóa cùng với tổn thất xếp hạng và tổn thất phân loại, tương ứng. Thiết kế này của Diff-KPE cho phép chúng tôi xếp hạng mỗi cụm từ ứng viên bằng cách sử dụng cả thông tin của cụm từ khóa và tài liệu. Các thí nghiệm cho thấy Diff-KPE vượt trội hơn hầu hết các phương pháp KPE hiện có trên một chuẩn mực trích xuất cụm từ khóa miền mở rộng, OpenKP, và một bộ dữ liệu miền khoa học, KP20K.

Từ khóa: Trích xuất Cụm từ Khóa, Khuếch tán, Nút thắt Thông tin

1. Giới thiệu

Trích xuất cụm từ khóa (KPE) nhằm trích xuất một số cụm từ khóa có mặt từ một tài liệu có thể tóm tắt cao tài liệu đã cho, điều này hữu ích cho nhiều ứng dụng như tóm tắt văn bản và truy xuất thông tin.

Nhiều mô hình trích xuất cụm từ khóa thần kinh mô hình hóa KPE như một vấn đề gán nhãn tuần tự cấp độ token bằng cách dự đoán một nhãn duy nhất cho mỗi token (Sahrawat et al., 2020; Alzaidy et al., 2019; Luan et al., 2017). Để sử dụng thông tin ngữ nghĩa cấp độ cụm từ, một số phương pháp (Zhang et al., 2016; Xiong et al., 2019; Mu et al., 2020; Wang et al., 2020; Sun et al., 2021) mô hình hóa KPE như một nhiệm vụ phân loại cụm từ bằng cách gán nhãn cho mỗi đoạn văn bản.

Khác với các phương pháp trên, các mô hình KPE gần đây học trực tiếp để xếp hạng mỗi cụm từ (Mu et al., 2020; Song et al., 2021; Sun et al., 2021; Song et al., 2022). Các phương pháp này chủ yếu bao gồm hai quá trình: xây dựng biểu diễn cụm từ ứng viên và xếp hạng tầm quan trọng cụm từ khóa. Cụ thể, các biểu diễn cụm từ ứng viên được trích xuất từ các embedding token được tạo ra bởi các mô hình ngôn ngữ được huấn luyện trước như BERT (Devlin et al., 2018), và xếp hạng tầm quan trọng cụm từ khóa thường dự đoán một điểm số cho mỗi biểu diễn cụm từ ứng viên và sau đó sử dụng tổn thất biên để sắp xếp điểm số của các ứng viên tích cực trước các ứng viên tiêu cực. Vì biểu diễn cụm từ ứng viên quan trọng đối với mô hình để chấm điểm chúng, có một số cách để trích xuất biểu diễn cụm từ: (Mu et al., 2020) và (Sun et al., 2021; Song et al., 2021) phát triển Bi-LSTM và CNN để nắm bắt thêm các đặc trưng cảm nhận cục bộ của cụm từ, tương ứng. HyperMatch (Song et al., 2022) trích xuất biểu diễn cụm từ trong không gian hyperbolic.

Mặc dù các phương pháp này đã đạt được thành công lớn trong nhiều chuẩn mực KPE, chúng tôi chỉ ra rằng biểu diễn cụm từ ứng viên của chúng vẫn thiếu việc sử dụng thông tin cụm từ khóa tham chiếu. Điều này được lấy cảm hứng từ trực giác về cách con người trích xuất cụm từ ứng viên: Họ sẽ đầu tiên xem xét toàn bộ tài liệu và tóm tắt một vài cụm từ khóa mơ hồ trong tâm trí, và sau đó xem xét cả cụm từ ứng viên và các cụm từ khóa mơ hồ để đưa ra quyết định trích xuất. Tuy nhiên, để đạt được quá trình này trong mô hình thần kinh, thách thức là làm thế nào để tạo ra thông tin cụm từ khóa tham chiếu mơ hồ trong thời gian suy luận.

Để giải quyết vấn đề trên, chúng tôi đề xuất Diff-KPE, một mô hình KPE dựa trên khuếch tán mới lạ. Đầu tiên chúng tôi sử dụng mô hình khuếch tán để tạo ra một danh sách thông tin cụm từ khóa mơ hồ bằng cách khôi phục các embedding cụm từ khóa tham chiếu có điều kiện trên toàn bộ tài liệu, sau đó chúng tôi nâng cao biểu diễn cụm từ bằng cách tiêm các embedding cụm từ khóa mơ hồ vào mỗi cụm từ. Để xếp hạng các cụm từ ứng viên, chúng tôi áp dụng một mạng xếp hạng để xếp hạng mỗi biểu diễn cụm từ được nâng cao. Bằng cách này, chúng tôi có thể trích xuất k cụm từ khóa hàng đầu mong muốn từ danh sách các cụm từ được xếp hạng. Ngoài ra, chúng tôi giới thiệu một Nút thắt Thông tin Biến phân có giám sát (VIB) để tối ưu hóa tổn thất phân loại cho mỗi cụm từ. VIB có giám sát nhằm bảo tồn thông tin về các lớp đích trong không gian tiềm ẩn trong khi lọc bỏ thông tin không liên quan từ biểu diễn cụm từ đầu vào (Tishby et al., 2000), giúp quá trình học cho embedding cụm từ khóa mơ hồ. Học đa nhiệm vụ của VIB có giám sát có thể hướng dẫn mô hình tạo ra các biểu diễn cụm từ thông tin, từ đó cải thiện hiệu suất của mạng xếp hạng. Nhìn chung, Diff-KPE kết hợp các mô-đun này bằng cách huấn luyện đồng thời các thành phần này.

Được trao quyền bởi thiết kế kiến trúc của Diff-KPE, nó thể hiện ba lợi thế sau. Đầu tiên, mô hình khuếch tán cho phép tiêm thông tin cụm từ khóa mơ hồ vào mỗi biểu diễn cụm từ, ngay cả trong quá trình suy luận, từ đó mang lại cho mô hình khả năng sử dụng thông tin cụm từ khóa. Thứ hai, mạng xếp hạng xếp hạng mỗi cụm từ, cho phép chúng tôi linh hoạt trích xuất k cụm từ khóa ứng viên hàng đầu. Cuối cùng, VIB có giám sát được giới thiệu hướng dẫn mô hình tạo ra các biểu diễn cụm từ thông tin, dẫn đến cải thiện hiệu suất xếp hạng. Chúng tôi chứng minh tầm quan trọng của mỗi thành phần trong các thí nghiệm của mình. Tóm lại, các đóng góp chính của bài báo này như sau:

• Chúng tôi đề xuất Diff-KPE, một mô hình KPE dựa trên khuếch tán. Theo hiểu biết của chúng tôi, đây là nỗ lực đầu tiên sử dụng mô hình khuếch tán cho nhiệm vụ KPE.

• Bằng cách kết hợp mô hình khuếch tán, mạng xếp hạng và VIB vào một hệ thống, chúng tôi trao quyền cho Diff-KPE sử dụng thông tin của cụm từ khóa và tài liệu để trích xuất cụm từ khóa ứng viên.

• Kết quả thí nghiệm cho thấy Diff-KPE vượt trội hơn hầu hết các phương pháp KPE hiện có trên hai chuẩn mực trích xuất cụm từ khóa lớn, OpenKP và KP20K. Ngoài ra, Diff-KPE thể hiện hiệu suất mạnh mẽ hơn trên năm bộ dữ liệu khoa học nhỏ khác.

2. Công trình Liên quan

2.1. Trích xuất Cụm từ Khóa

Trích xuất Cụm từ Khóa Tự động (KPE) nhằm trích xuất một tập hợp các cụm từ quan trọng và chủ đề từ một tài liệu cho trước, sau đó có thể được sử dụng trong các nhiệm vụ khác nhau như tóm tắt (Li et al., 2020), giải quyết vấn đề (Huang et al., 2017, 2018b,a), các nhiệm vụ sinh (Zhou and Huang, 2019; Li et al., 2021), và vân vân.

Các công nghệ KPE hiện có có thể được phân loại thành các phương pháp không giám sát và có giám sát. Các phương pháp không giám sát chủ yếu dựa trên thông tin thống kê (El-Beltagy and Rafea, 2009; Florescu and Caragea, 2017a; Campos et al., 2018), đặc trưng embedding (Mahata et al., 2018; Sun et al., 2020; Liang et al., 2021; Zhang et al., 2021; Ding and Luo, 2021), và các thuật toán xếp hạng dựa trên đồ thị (Mihalcea and Tarau, 2004; Florescu and Caragea, 2017b; Boudin, 2018). Các phương pháp có giám sát thường mô hình hóa KPE như các phương pháp gán thẻ tuần tự (Sahrawat et al., 2020; Alzaidy et al., 2019; Kulkarni et al., 2022), phân loại cấp độ đoạn (Zhang et al., 2016; Xiong et al., 2019; Mu et al., 2020; Sun et al., 2021) hoặc xếp hạng (Mu et al., 2020; Song et al., 2021; Sun et al., 2021; Song et al., 2022), hoặc các nhiệm vụ sinh (Meng et al., 2017; Chen et al., 2018; Yuan et al., 2018; Kulkarni et al., 2022). Mặc dù các phương pháp KPE có giám sát yêu cầu nhiều dữ liệu được chú thích, hiệu suất của chúng cao hơn đáng kể so với các phương pháp không giám sát trong nhiều chuẩn mực KPE (Sun et al., 2021; Meng et al., 2017).

Gần đây, một số công trình đã tập trung vào xây dựng một bộ trích xuất cụm từ khóa zero-shot bằng cách nhắc các mô hình ngôn ngữ lớn được huấn luyện trước (LLM). Ví dụ, (Song et al., 2023) đã xác minh hiệu suất của ChatGPT (OpenAI, 2022) và ChatGLM-6b (Zeng et al., 2022) cho nhiệm vụ KPE và phát hiện rằng chúng vẫn có nhiều chỗ để cải thiện trong nhiệm vụ KPE so với các mô hình có giám sát SOTA hiện có. Kết quả tương tự cũng có thể quan sát thấy trong (Martínez-Cruz et al., 2023).

2.2. Mô hình Khuếch tán cho Văn bản

Các mô hình khuếch tán đã được áp dụng trong nhiều thế hệ miền liên tục như hình ảnh, video và âm thanh (Kong et al., 2020; Rombach et al., 2022; Ho et al., 2022; Yang et al., 2022). Gần đây, có một số công trình tập trung vào việc áp dụng mô hình khuếch tán cho dữ liệu văn bản rời rạc. Chúng thường tạo ra các biểu diễn liên tục cho các văn bản/từ mong muốn. Ví dụ, Diffusion-LM (Li et al., 2022) đầu tiên cố gắng phát triển một mô hình khuếch tán liên tục để tạo văn bản bằng bước căn cứ embedding. Theo công trình của Diffusion-LM, DiffuSeq (Gong et al., 2022) và SeqDiffuSeq (Yuan et al., 2022) đã thiết kế một mô hình tuần tự-đến-tuần tự dựa trên khuếch tán cho nhiệm vụ tạo văn bản. Để thích ứng mô hình khuếch tán với việc tạo chuỗi dài hơn, (Zhang et al., 2023) đã đề xuất một mô hình tạo khuếch tán cấp độ câu cho các nhiệm vụ tóm tắt, trực tiếp tạo ra các embedding cấp độ câu và khớp từ embedding trở lại văn bản gốc.

Trái ngược với các công trình trước, chúng tôi áp dụng mô hình khuếch tán cho KPE, một nhiệm vụ trích xuất cấp độ cụm từ. Để xem xét thông tin cụm từ khóa trong quá trình trích xuất, chúng tôi trực tiếp tiêm thông tin cụm từ khóa được tạo ra bởi mô hình khuếch tán vào mỗi biểu diễn cụm từ.

2.3. Nút thắt Thông tin Biến phân trong NLP

Nút thắt Thông tin Biến phân (VIB) là một trong nhóm các phương pháp Nút thắt Thông tin (IB). Nó nhằm tìm các biểu diễn compact của dữ liệu bảo tồn thông tin liên quan nhất trong khi lọc bỏ thông tin không liên quan hoặc dư thừa (Tishby et al., 2000).

Có nhiều nghiên cứu áp dụng VIB cho nhiều nhiệm vụ NLP. Ví dụ, (Li and Eisner, 2019) đã sử dụng VIB cho phân tích cú pháp, và (West et al., 2019) đã sử dụng nó cho tóm tắt văn bản. Gần đây, VIB cũng được sử dụng trong Nhận dạng Thực thể Có tên (NER) (Wang et al., 2022; Nguyen et al., 2023), phân loại văn bản (Zhang et al., 2022), dịch máy (Ormazabal et al., 2022) và vân vân.

3. Phương pháp

Trong phần này, chúng tôi trình bày thiết kế chi tiết của mô hình Trích xuất Cụm từ Khóa (KPE) của chúng tôi, được đặt tên là Diff-KPE. Tổng quan về Diff-KPE được mô tả trong Hình 1. Với tài liệu D={w1, w2, ..., wn}, chúng tôi bắt đầu bằng cách liệt kê tất cả các biểu diễn cụm từ có thể và các embedding cụm từ khóa tham chiếu. Mô-đun Khuếch tán sau đó được sử dụng để tái tạo các embedding cụm từ khóa và tiêm chúng vào mỗi biểu diễn cụm từ. Ngoài ra, chúng tôi kết hợp một Nút thắt Thông tin Biến phân có giám sát (VIB) cho phân loại cụm từ và một mạng xếp hạng cho mục đích xếp hạng. Các thành phần này hoạt động cùng nhau để nâng cao hiệu suất của mô hình KPE của chúng tôi.

3.1. Biểu diễn Cụm từ

Để liệt kê và mã hóa tất cả các biểu diễn cụm từ có thể, đầu tiên chúng tôi sử dụng mô hình ngôn ngữ được huấn luyện trước BERT (Devlin et al., 2018) để mã hóa tài liệu D={w1, w2, ..., wn}, tạo ra các embedding từ ngữ cảnh E={e1,e2, ...,en}. Các embedding từ sau đó được tích hợp vào các biểu diễn cụm từ bằng cách sử dụng một tập hợp các Mạng Thần kinh Tích chập (CNN):

sk_i=CNNk(ei,ei+1, ...,ei+n−1)    (1)

trong đó 1≤k≤N và N biểu thị độ dài tối đa được định nghĩa trước của cụm từ. Biểu diễn cụm từ k-gram thứ i sk_i được tính toán bởi CNNk tương ứng của nó.

3.2. Tạo Embedding Cụm từ Khóa

Để tiêm thông tin cụm từ khóa tham chiếu vào mỗi biểu diễn cụm từ, chúng tôi sử dụng một mô-đun khuếch tán liên tục để tạo ra các embedding cụm từ khóa mong muốn.

3.2.1. Mã hóa Đầu vào

Để cho phép mô-đun khuếch tán tạo ra các embedding cụm từ khóa mong muốn có điều kiện trên toàn bộ tài liệu, đầu tiên chúng tôi sử dụng một mô hình BERT khác để thu được các embedding tài liệu và cụm từ khóa ban đầu. Tham chiếu đến m cụm từ khóa và embedding tài liệu như Ekp={ekp_i}^m_i và eD, mã hóa đầu vào của mô-đun khuếch tán được định dạng như:

Hin=hD||Hkp
=TransformerEncoder(eD||Ekp)    (2)

trong đó Hkp={hkp_i}^m_i và hD là embedding tiềm ẩn của tài liệu và m cụm từ khóa, TransformerEncoder là một bộ mã hóa Transformer xếp chồng nhúng vector đầu vào vào không gian tiềm ẩn, và eD là embedding tài liệu, tức là embedding token [CLS] trong mô hình BERT, và || biểu thị phép toán nối. Mã hóa đầu vào như vậy cho phép mô-đun khuếch tán liên tục của chúng tôi tạo ra các embedding cụm từ khóa mong muốn có điều kiện với các embedding tài liệu hiện tại eD.

3.2.2. Quá trình Tạo Khuếch tán

Một khi mã hóa đầu vào Hin được thu được, mô hình khuếch tán nhằm làm nhiễu Hin dần dần và sau đó khôi phục Hin gốc bằng cách học một quá trình ngược. Để đạt được điều này, một chuyển đổi Markov một bước q(x0|Hin) được thực hiện để thu được trạng thái ban đầu x0:

x0=x^D_0||x^kp_0 ∼ N(Hin, β0I)    (3)

trong đó βt∈(0,1) điều chỉnh quy mô của phương sai, x^D_0∼N(hD, β0I) và x^kp_0∼N(Hkp, β0I) là embedding tài liệu tiềm ẩn và các embedding cụm từ khóa, tương ứng. Sau đó chúng tôi bắt đầu quá trình tiến bằng cách dần dần thêm nhiễu Gaussian vào các embedding cụm từ khóa tiềm ẩn x^kp_t. Theo công trình trước (Zhang et al., 2023), chúng tôi giữ embedding tài liệu tiềm ẩn x^D_0 không thay đổi, để mô-đun khuếch tán có thể tạo ra các embedding cụm từ khóa có điều kiện với tài liệu nguồn. Chính thức, tại bước t của quá trình tiến q(xt|xt−1), embedding tiềm ẩn nhiễu là xt:

xt=x^D_0||N(x^kp_t;√(1−βt)x^kp_{t−1}, βtI)    (4)

trong đó t∈{1,2, ..., T} cho tổng cộng T bước khuếch tán. Để biết thêm chi tiết về quá trình tạo khuếch tán, vui lòng tham khảo (Sohl-Dickstein et al., 2015).

Sau khi thêm nhiễu dần dần tại một bước thời gian cụ thể t (thường chọn ngẫu nhiên giữa [1, T]), quá trình lùi được thực hiện để khôi phục các embedding cụm từ khóa x^kp_t bằng cách loại bỏ nhiễu. Chúng tôi sử dụng một mô hình bộ mã hóa Transformer xếp chồng khác fθ để tiến hành quá trình lùi này để khôi phục mã hóa đầu vào ban đầu Hkp:

H̃kp=fθ(x^kp_t, t)    (5)

trong đó fθ(x^kp_t, t) là mạng Transformer xếp chồng để tái tạo Hkp tại bước thời gian t.

Vì mục tiêu chính của mô-đun tạo khuếch tán là tái tạo mã hóa đầu vào ban đầu, tổn thất mục tiêu của mô-đun khuếch tán liên tục có thể được định nghĩa bởi:

Ldif=∑^T_{t=1}||Hkp−fθ(x^kp_t, t)||^2+R(x0)    (6)

trong đó R(x0) là một số hạng điều hòa cho x0.

3.3. Xếp hạng Cụm từ Khóa

Sau quá trình tạo khuếch tán, các embedding cụm từ khóa được tạo H̃kp được nối vào mỗi biểu diễn cụm từ sk_i. Điều này nhằm tiêm thông tin từ các cụm từ khóa vào mỗi cụm từ, dẫn đến cải thiện hiệu suất của xếp hạng cụm từ khóa. Cụ thể, mô hình hóa biểu diễn cụm từ cuối cùng như:

s̃sk_i=sk_i||flat(H̃kp)    (7)

trong đó flat(x) có nghĩa là x được làm phẳng thành một vector. Phương trình 7 có nghĩa là biểu diễn cụm từ cuối cùng không chỉ chứa biểu diễn cụm từ ban đầu mà còn tất cả thông tin cụm từ khóa được tái tạo.

Để huấn luyện mô hình xếp hạng mỗi cụm từ, chúng tôi giới thiệu một tổn thất xếp hạng tương phản. Theo công trình trước (Sun et al., 2021), đầu tiên chúng tôi lấy một lớp feedforward để chiếu biểu diễn đầu vào s̃sk_i thành một điểm số vô hướng:

r(s̃sk_i) = FeedForward(s̃sk_i)    (8)

Sau đó tổn thất xếp hạng biên được giới thiệu để học xếp hạng cụm từ khóa s̃s+ trước cụm từ không phải khóa s̃s− cho tài liệu D đã cho:

Lrank = ∑_{s̃s+,s̃s−∈D} max(0, 1−r(s̃s+)+r(s̃s−))    (9)

3.4. Phân loại Cụm từ Khóa

Kết hợp nhiệm vụ phân loại cụm từ khóa trong quá trình huấn luyện có thể nâng cao đo lường tính cụm từ của cụm từ (Sun et al., 2021; Song et al., 2021). Tương tự như công trình trước (Xiong et al., 2019; Sun et al., 2021; Song et al., 2021), chúng tôi giới thiệu một tổn thất phân loại cho mỗi biểu diễn cụm từ cuối cùng cho học đa nhiệm vụ. Chúng tôi thấy rằng việc sử dụng VIB có giám sát cải thiện đáng kể hiệu suất xếp hạng (Xem Nghiên cứu Loại bỏ). VIB có giám sát nhằm bảo tồn thông tin về các lớp đích trong không gian tiềm ẩn trong khi lọc bỏ thông tin không liên quan từ đầu vào (Voloshynovskiy et al., 2019). Với biểu diễn cụm từ cuối cùng s̃sk_i, VIB có giám sát đầu tiên nén đầu vào thành một biến tiềm ẩn z∼qϕ1(z|s̃sk_i). Chúng tôi áp dụng hai lớp tuyến tính để xây dựng các tham số q bằng cách sử dụng các phương trình sau:

μ=Wμs̃sk_i+bμ
σ^2=Wσs̃sk_i+bσ    (10)

trong đó μ và σ là các tham số của một Gaussian đa biến, biểu thị không gian đặc trưng tiềm ẩn của cụm từ; W và b là trọng số và bias của lớp tuyến tính, tương ứng. Phân phối hậu nghiệm z∼qϕ1(z|s̃sk_i) được xấp xỉ qua thủ thuật tham số hóa lại (Kingma and Welling, 2013):

z=μ+σε, trong đó ε∼N(0,1)    (11)

Vì mục tiêu chính của VIB là bảo tồn thông tin lớp đích trong khi lọc bỏ thông tin không liên quan từ đầu vào, hàm tổn thất mục tiêu cho VIB có giám sát dựa trên tổn thất phân loại và tổn thất nén. Ký hiệu bởi y là nhãn thực của cụm từ đầu vào, tổn thất mục tiêu của VIB có giám sát được định nghĩa là:

Lvib(ϕ) = Ez[−log pϕ2(y|z)] + αEs̃sk_i[DKL(qϕ1(z|s̃sk_i), pr(z))]    (12)

trong đó pr(z) là một ước lượng của xác suất tiên nghiệm qϕ1(z), α trong khoảng [0,1], ϕ là các tham số mạng thần kinh, và DKL là phân kỳ Kullback-Leibler. Chúng tôi sử dụng một perceptron đa lớp với một lớp tuyến tính và hàm softmax để tính toán pϕ2(y|z). Lưu ý rằng Phương trình 12 có thể được xấp xỉ bằng phương pháp lấy mẫu Monte Carlo với kích thước mẫu M.

3.5. Tối ưu hóa và Suy luận

Chúng tôi tối ưu hóa kết hợp mô-đun khuếch tán, mạng xếp hạng và VIB có giám sát từ đầu đến cuối. Cụ thể, tổn thất mục tiêu huấn luyện tổng thể có thể được biểu diễn như:

L=Ldif+Lvib+Lrank    (13)

Đối với suy luận, bộ mã hóa Transformer đầu tiên thu được các embedding tài liệu ban đầu hD, và sau đó chuyển đổi Markov một bước q(x^D_0|hD) được thực hiện. Để xây dựng embedding cụm từ khóa nhiễu x^kp_T, chúng tôi lấy mẫu ngẫu nhiên m embedding nhiễu Gaussian sao cho x^kp_T∼N(0,I). Sau đó quá trình ngược được áp dụng để loại bỏ nhiễu Gaussian của xT=x^D_0||x^kp_T lặp lại và nhận được các embedding cụm từ khóa đầu ra H̃kp=[h̃kp_1, h̃kp_2, ..., h̃kp_m]. Sau đó, mỗi biểu diễn cụm từ ban đầu sk_i được nối với các embedding cụm từ khóa được làm phẳng H̃kp và đưa vào mạng xếp hạng để thu được điểm số cuối cùng cho mỗi cụm từ.

4. Thí nghiệm

4.1. Bộ dữ liệu

Trong bài báo này, chúng tôi sử dụng bảy bộ dữ liệu chuẩn KPE trong các thí nghiệm của mình.

• OpenKP (Xiong et al., 2019) bao gồm khoảng 150K tài liệu web từ công cụ tìm kiếm Bing. Chúng tôi tuân theo phân chia chính thức của tập huấn luyện (134K), phát triển (6.6K) và kiểm thử (6.6K). Mỗi tài liệu trong OpenKP được gán nhãn với 1-3 cụm từ khóa bởi các chuyên gia chú thích.

• KP20K (Meng et al., 2017) bao gồm một lượng lớn siêu dữ liệu khoa học chất lượng cao trong lĩnh vực khoa học máy tính từ các thư viện số trực tuyến khác nhau (Meng et al., 2017). Chúng tôi tuân theo phân vùng ban đầu của tập huấn luyện (528K), phát triển (20K) và kiểm thử (20K).

• SemEval-2010 (Kim et al., 2013) chứa 244 tài liệu khoa học. Phân chia chính thức của 100 tài liệu kiểm thử được sử dụng để kiểm thử trong các thí nghiệm của chúng tôi.

• SemEval-2017 (Augenstein et al., 2017) chứa 400 tài liệu khoa học. Phân chia chính thức của 100 tài liệu kiểm thử được sử dụng để kiểm thử trong các thí nghiệm của chúng tôi.

• Nus (Nguyen and Kan, 2007) chứa 211 tài liệu học thuật. Chúng tôi xem tất cả 211 tài liệu như dữ liệu kiểm thử.

• Inspec (Hulth, 2003) chứa 2000 tóm tắt bài báo. Chúng tôi sử dụng 500 bài báo kiểm thử ban đầu và các cụm từ khóa được kiểm soát (trích xuất) tương ứng của chúng để kiểm thử.

• Krapivin (Krapivin et al., 2009) chứa 2305 bài báo từ các bài báo khoa học trong ACM. Chúng tôi xem tất cả 2305 bài báo như dữ liệu kiểm thử.

Lưu ý rằng để xác minh tính mạnh mẽ của mô hình, chúng tôi kiểm thử mô hình được huấn luyện với KP20K trên dữ liệu kiểm thử của SemEval-2010, SemEval-2017, Nus, Inspec và Krapivin. Đối với tất cả các bộ dữ liệu, chỉ các cụm từ khóa có mặt được sử dụng để huấn luyện và kiểm thử. Thống kê của tập huấn luyện của OpenKP và KP20k được hiển thị trong Bảng 1.

4.2. Cơ sở so sánh

Để giữ nhất quán với công trình trước (Meng et al., 2017; Xiong et al., 2019; Mu et al., 2020; Sun et al., 2021), chúng tôi so sánh mô hình của mình với hai loại phương pháp KPE: Cơ sở so sánh KPE truyền thống và Cơ sở so sánh KPE thần kinh.

Cơ sở so sánh KPE truyền thống bao gồm hai phương pháp KPE không giám sát phổ biến, phương pháp dựa trên đặc trưng thống kê TF-IDF (Sparck Jones, 1972) và phương pháp dựa trên đồ thị TextRank (Mihalcea and Tarau, 2004), và hai hệ thống KPE dựa trên đặc trưng PROD (Xiong et al., 2019) và Maui (Medelyan et al., 2009).

Cơ sở so sánh KPE thần kinh bao gồm một mô hình dựa trên sinh tuần tự-đến-tuần tự có tên CopyRNN (Meng et al., 2017). Phương pháp tiên tiến trước đây trên OpenKP và KP20K, KIEMP (Song et al., 2021) kết hợp ước lượng đa góc độ cho xếp hạng cụm từ. Một cơ sở so sánh mạnh khác, JointKPE (Sun et al., 2021), bao gồm hai biến thể ChunkKPE và RankKPE được tái tạo theo mã nguồn mở của họ. HyperMatch (Song et al., 2022), một phương pháp khớp mới để trích xuất cụm từ khóa trong không gian hyperbolic. Hai mô hình phân loại cấp độ cụm từ có tên SKE-Base-Cls (Mu et al., 2020) và BLING-KPE (Xiong et al., 2019). Chúng tôi cũng so sánh mô hình của mình với các phương pháp trích xuất đoạn dựa trên BERT và gán thẻ tuần tự, cả hai đều đến từ việc thực hiện của (Sun et al., 2021). Lưu ý rằng vì cả KeyBart và KBIR (Kulkarni et al., 2022) đều được huấn luyện trước với một chiến lược huấn luyện trước được xác định rõ ràng cụ thể trên RoBERTa-large (Liu et al., 2019), chúng tôi không so sánh Diff-KPE của mình với chúng để so sánh công bằng.

Ngoài ra, chúng tôi cũng thêm kết quả của hai mô hình ngôn ngữ lớn (LLM) với cài đặt zero-shot: ChatGLM2-6b (Zeng et al., 2022) và ChatGPT (OpenAI, 2022). Để hạn chế định dạng đầu ra của ChatGPT, chúng tôi thiết kế mẫu nhắc sau:

[Hướng dẫn]
Vui lòng trích xuất 1 đến 15 cụm từ khóa từ tài liệu đã cho. Các cụm từ khóa được trích xuất của bạn nên đại diện hợp lý cho chủ đề của tài liệu và phải xuất hiện trong văn bản gốc. Bạn phải đưa ra các cụm từ khóa bằng cách tuân thủ nghiêm ngặt định dạng này: "[cụm từ khóa được trích xuất]", ví dụ: "[machine learning, neural networks, NLP]"

[Tài liệu]
{tài liệu}

Cần lưu ý rằng việc thiết kế các nhắc phức tạp hơn có thể cải thiện hiệu suất của LLM, điều này nằm ngoài phạm vi của bài báo này.

4.3. Các chỉ số Đánh giá

Chúng tôi sử dụng Recall (R) và F-measure (F1) của K cụm từ khóa được dự đoán hàng đầu để đánh giá hiệu suất của các mô hình KPE. Theo nghiên cứu trước (Meng et al., 2017; Xiong et al., 2019), chúng tôi sử dụng K={1,3,5} trên OpenKP và K={5,10} trên các bộ dữ liệu khác. Khi xác định sự khớp chính xác của các cụm từ khóa, đầu tiên chúng tôi chuyển thành chữ thường các cụm từ khóa ứng viên và cụm từ khóa tham chiếu, và sau đó chúng tôi áp dụng Porter Stemmer (Porter, 1980) cho cả hai.

4.4. Chi tiết Thực hiện

Chúng tôi cắt ngắn hoặc đệm zero cho mỗi tài liệu do giới hạn độ dài đầu vào (512 token). Chúng tôi sử dụng phiên bản base của BERT để tạo ra các embedding từ ban đầu. Chúng tôi cũng sử dụng phiên bản base của Sentence-BERT (Reimers and Gurevych, 2019) để tạo ra các embedding cụm từ cố định ban đầu cho mô-đun khuếch tán. Độ dài tối đa của k-gram được đặt thành N=5 cho tất cả các bộ dữ liệu. Số bước thời gian khuếch tán tối đa T được đặt thành 100, α=2.8e−6. Kích thước ẩn và số lớp trong bộ mã hóa Transformer trong mô-đun khuếch tán được đặt thành 8 và 6 tương ứng. Chiều tiềm ẩn của mô hình VIB được đặt thành 128. Kích thước mẫu M=5. Chúng tôi tối ưu hóa Diff-KPE bằng AdamW với tốc độ học 5e-5, tỷ lệ warm-up 0.1 và kích thước batch 32. Quá trình huấn luyện sử dụng 8 GPU NVIDIA Tesla V100 và mất khoảng 20 giờ trong 5 epoch. Trong quá trình huấn luyện Diff-KPE, chúng tôi cũng đặt một chiến lược dừng sớm đơn giản sao cho mô hình sẽ dừng huấn luyện nếu hiệu suất validation (F1@3 cho OpenKP, F1@5 cho KP20K) không cải thiện sau 5 lần đánh giá liên tiếp (Chúng tôi đánh giá mô hình mỗi 200 bước tối ưu), và chúng tôi chọn mô hình có hiệu suất validation tốt nhất. Chúng tôi chạy mô hình với 5 seed ngẫu nhiên khác nhau và báo cáo điểm số trung bình của chúng.

5. Kết quả và Phân tích

Trong phần này, chúng tôi trình bày kết quả đánh giá của Diff-KPE được đề xuất trên bảy bộ dữ liệu chuẩn được sử dụng rộng rãi (OpenKP, KP20k, SemEval-2010, SemEval-2017, Nus, Inspec, Krapivin).

5.1. Hiệu suất Tổng thể

Bảng 2 hiển thị kết quả đánh giá của Diff-KPE và các cơ sở so sánh. Dựa trên kết quả, rõ ràng là các phương pháp KPE thần kinh vượt trội hơn tất cả các thuật toán KPE truyền thống. Trong số các phương pháp truyền thống, các phương pháp không giám sát TF-IDF và TextRank cho thấy hiệu suất ổn định trên cả bộ dữ liệu OpenKP và KP20k, trong khi các phương pháp dựa trên đặc trưng PROD và Maui vượt trội hơn chúng trên OpenKP và KP20k tương ứng. Điều này không đáng ngạc nhiên, vì các phương pháp có giám sát được hưởng lợi từ dữ liệu chú thích lớn trong quá trình huấn luyện.

Đối với các phương pháp KPE thần kinh, CopyRNN thể hiện tệ nhất vì nó cũng tập trung vào việc tạo ra các cụm từ khóa trừu tượng. HyperMatch, JointKPE và biến thể RankKPE của nó cho thấy hiệu suất mạnh mẽ, vượt trội hơn các cơ sở so sánh khác như các mô hình phân loại cụm từ dựa trên BLING-KPE, SKE-Base-Cls, BERT-Span và phương pháp gán thẻ tuần tự BERT-SeqTag. Đáng chú ý là BERT-SeqTag và ChunkKPE thể hiện hiệu suất cạnh tranh so với RankKPE, cho thấy tính mạnh mẽ và hiệu suất tốt của chúng.

Nhìn chung, Diff-KPE vượt trội hơn tất cả các cơ sở so sánh ngoại trừ KIEMP trên cả bộ dữ liệu OpenKP và KP20K. So với JointKPE, Diff-KPE cho thấy cải thiện nhẹ trong F1@3 và F1@5 nhưng cải thiện đáng kể trong F1@1. So với phương pháp cơ sở so sánh thần kinh SOTA trước đây KIEMP, KIEMP vượt trội hơn Diff-KPE của chúng tôi trong hầu hết các điểm số F1@k trên OpenKP và KP20k. Tuy nhiên, Diff-KPE vẫn thể hiện cải thiện hiệu suất trong F1@1, R@1, R@3 và R@5 trên OpenKP. Chúng tôi giả thuyết rằng các cải thiện trong Recall được hưởng lợi từ mô-đun khuếch tán của chúng tôi, có thể tiêm các embedding cụm từ khóa được tạo vào các biểu diễn cụm từ, từ đó nâng cao hiệu suất recall.

Hơn nữa, để xác minh tính mạnh mẽ của Diff-KPE, chúng tôi cũng đánh giá mô hình được huấn luyện với bộ dữ liệu KP20k trên năm bộ dữ liệu khoa học nhỏ bổ sung, như được hiển thị trong Bảng 3. Diff-KPE thể hiện kết quả tốt hơn hoặc cạnh tranh trên tất cả các bộ dữ liệu so với cơ sở so sánh tốt nhất JointKPE. Chúng tôi tin rằng hiện tượng này phát sinh từ lợi ích của mô-đun khuếch tán: trong quá trình suy luận, mô hình khuếch tán có thể tạo ra các embedding cụm từ khóa ứng viên, cung cấp thông tin cụm từ khóa cho mạng xếp hạng để xếp hạng mỗi cụm từ tốt hơn.

5.2. Nghiên cứu Loại bỏ

Để hiểu ảnh hưởng của mỗi thành phần trên mô hình Diff-KPE của chúng tôi. Chúng tôi thực hiện nghiên cứu loại bỏ trên tập phát triển OpenKP với các cài đặt sau:

• -w/oVIB: thay thế mô hình VIB bằng một lớp feedforward duy nhất cho phân loại cụm từ khóa.

• -w/odiffusion: mô hình khuếch tán được loại bỏ, và chỉ sử dụng các biểu diễn cụm từ thu được từ CNN để xếp hạng và phân loại.

• Diff-KPE: mô hình kết hợp đầy đủ ban đầu.

Như được hiển thị trong Bảng 4, sự vắng mặt của mô hình khuếch tán hoặc mô hình VIB dẫn đến sự sụt giảm đáng kể trong hiệu suất trên tất cả các chỉ số, đặc biệt là trong F1@1 (1.2 và 1.3 tương ứng). Sự sụt giảm hiệu suất này cho thấy vai trò quan trọng của cả mô hình khuếch tán và VIB trong xếp hạng cụm từ khóa. Hiệu suất mạnh mẽ của Diff-KPE có thể được quy cho hai lợi thế chính. Đầu tiên, mô-đun khuếch tán trực tiếp kết hợp thông tin ngữ nghĩa của các cụm từ khóa vào các biểu diễn cụm từ cuối cùng. Thứ hai, mô-đun VIB có giám sát giới thiệu một tổn thất phân loại bên ngoài trong quá trình huấn luyện, gián tiếp nâng cao mô-đun khuếch tán hoặc CNN để tạo ra các embedding n-gram thông tin hơn. Do đó, rõ ràng là việc bổ sung mô-đun khuếch tán và VIB có giám sát đóng góp lớn cho cải thiện hiệu suất tổng thể.

6. Nghiên cứu Tình huống

Để chứng minh thêm hiệu quả của mô-đun khuếch tán trong Diff-KPE, chúng tôi cung cấp các ví dụ về các cụm từ khóa được trích xuất từ các mô hình khác nhau của chúng tôi (Diff-KPE và Diff-KPE không có mô-đun khuếch tán). Hai trường hợp điển hình từ tập phát triển của OpenKP được hiển thị trong Bảng 5.

Trong trường hợp (1), cả Diff-KPE và Diff-KPE không có khuếch tán đều thành công trích xuất các cụm từ khóa tham chiếu mong muốn "adventure time" và "ryan north" trong top 5 cụm từ dự đoán được xếp hạng của chúng. Tuy nhiên, Diff-KPE xếp hạng cụm từ "ryan north" cao hơn, dẫn đến điểm số F1@3 cao hơn trong trường hợp này. Điều này minh họa rằng việc thêm mô-đun khuếch tán giúp biểu diễn cụm từ khóa mong muốn thu được điểm số xếp hạng cao hơn.

Tương tự, trong trường hợp (2), Diff-KPE xếp hạng các cụm từ khóa mong muốn "codesnip" và "oracle script" cao hơn so với mô hình không có khuếch tán. Kết quả là, Diff-KPE thành công trích xuất tất cả các cụm từ khóa tham chiếu trong trường hợp (2). Lý do chính cho những kết quả này có thể là các embedding cụm từ khóa được tạo ra bởi mô-đun khuếch tán được tiêm trực tiếp vào mỗi biểu diễn cụm từ, cho phép mạng xếp hạng xếp hạng mỗi cụm từ tốt hơn bằng cách sử dụng thông tin cụm từ khóa.

Chúng tôi cũng phân tích chất lượng embedding cụm từ khóa được tạo ra. Chúng tôi áp dụng T-SNE (Van der Maaten and Hinton, 2008) để giảm tất cả các chiều biểu diễn cụm từ xuống 2 trong Hình 2. Chúng tôi có thể thấy rằng các cụm từ khóa oracle (chấm xanh lá) và các cụm từ khóa được tạo (chấm xanh dương) được nhóm lại với nhau và cách xa hầu hết các embedding không phải cụm từ khóa (chấm đỏ). Phát hiện này chứng minh rằng mô hình khuếch tán của chúng tôi mạnh mẽ trong việc khôi phục các embedding cụm từ khóa.

7. Kết luận

Trong bài báo này, chúng tôi đề xuất Diff-KPE, một mô hình trích xuất cụm từ khóa kết hợp mới lạ (KPE) bao gồm ba mô-đun thiết yếu: mô-đun khuếch tán, mạng xếp hạng và một mô-đun VIB có giám sát. Mỗi thành phần đóng vai trò quan trọng trong việc học các biểu diễn cụm từ biểu cảm. Mô-đun khuếch tán chịu tr책nhiệm tạo ra các embedding cụm từ khóa, hiệu quả truyền thông tin ngữ nghĩa cụm từ khóa vào biểu diễn cụm từ cuối cùng. Đồng thời, VIB có giám sát giới thiệu một tổn thất phân loại cho mỗi cụm từ, khuyến khích mô hình tạo ra các biểu diễn thông tin hơn và cuối cùng cải thiện hiệu suất xếp hạng. Kết quả thí nghiệm trên bảy bộ dữ liệu chuẩn trích xuất cụm từ khóa chứng minh tính hiệu quả và vượt trội của Diff-KPE.

Tuy nhiên, vì mô hình của chúng tôi yêu cầu nhiều bước tiêm nhiễu tiến và khử nhiễu lùi, Diff-KPE của chúng tôi chậm hơn khoảng 2 lần so với mô hình SOTA trước đây JointKPE trong quá trình suy luận. Hơn nữa, mô hình của chúng tôi cũng thiếu khả năng tạo ra các cụm từ khóa trừu tượng. Trong công việc tương lai, chúng tôi dự định cải thiện hiệu quả tính toán và khám phá ứng dụng của Diff-KPE trong tạo cụm từ khóa trừu tượng, tận dụng kiến trúc mạnh mẽ và tính linh hoạt của nó để tạo ra các cụm từ khóa súc tích và thông tin.

8. Tuyên bố Đạo đức

Chúng tôi quan tâm nghiêm túc đến các vấn đề đạo đức và tuân thủ nghiêm ngặt Chính sách Đạo đức. Bài báo này tập trung vào nỗ lực ứng dụng mô hình khuếch tán cho trích xuất cụm từ khóa. Cả bộ dữ liệu và các mô hình cơ sở được sử dụng trong bài báo này đều có sẵn công khai và đã được các nhà nghiên cứu chấp nhận rộng rãi. Chúng tôi đảm bảo rằng các phát hiện và kết luận của bài báo này được báo cáo chính xác và khách quan.

# 2402.05608.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/diffusion/2402.05608.pdf
# Kích thước file: 4118711 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Các mô hình khuếch tán có thể mở rộng với
khung xương không gian trạng thái
Zhengcong Fei, Mingyuan Fan, Changqian Yu
Junshi Huang*
{feizhengcong}@gmail.com
Kunlun Inc.
Tóm tắt. Bài báo này trình bày một khám phá mới về một danh mục các mô hình khuếch tán được xây dựng trên kiến trúc không gian trạng thái. Chúng tôi nỗ lực để huấn luyện các mô hình khuếch tán cho dữ liệu hình ảnh, trong đó khung xương U-Net truyền thống được thay thế bằng khung xương không gian trạng thái, hoạt động trên các miếng vá thô hoặc không gian tiềm ẩn. Với hiệu quả đáng chú ý trong việc thích ứng với các phụ thuộc tầm xa, Các mô hình không gian trạng thái khuếch tán (DiS) được phân biệt bằng cách xử lý tất cả các đầu vào bao gồm thời gian, điều kiện và các miếng vá hình ảnh nhiễu như là các token. Đánh giá của chúng tôi về DiS bao gồm cả các tình huống tạo hình ảnh không điều kiện và có điều kiện lớp, tiết lộ rằng DiS thể hiện hiệu suất tương đương, nếu không muốn nói là vượt trội, so với các kiến trúc U-Net dựa trên CNN hoặc Transformer có kích thước tương xứng. Hơn nữa, chúng tôi phân tích khả năng mở rộng của DiS, được đánh giá bởi độ phức tạp chuyển tiếp tiến được định lượng bằng Gflops. Các mô hình DiS với Gflops cao hơn, đạt được thông qua tăng cường độ sâu/chiều rộng hoặc tăng cường các token đầu vào, liên tục thể hiện FID thấp hơn. Ngoài việc thể hiện các đặc tính khả năng mở rộng đáng khen ngợi, các mô hình DiS-H/2 trong không gian tiềm ẩn đạt được mức hiệu suất tương tự như các mô hình khuếch tán trước đó trên các benchmark ImageNet có điều kiện lớp ở độ phân giải 256 ×256 và 512 ×512, trong khi giảm đáng kể gánh nặng tính toán. Mã nguồn và các mô hình có sẵn tại: https://github.com/feizc/DiS .
Từ khóa: Không gian trạng thái ·mô hình khuếch tán ·tổng hợp hình ảnh

1 Giới thiệu
Các mô hình khuếch tán [4,26,60,64] đã nổi lên như những mô hình sinh sâu mạnh mẽ trong những năm gần đây [9,27,54], nhờ khả năng tạo hình ảnh chất lượng cao. Sự phát triển nhanh chóng của chúng đã dẫn đến ứng dụng rộng rãi trong các lĩnh vực khác nhau, bao gồm tạo hình ảnh từ văn bản [21,53–55], tạo hình ảnh từ hình ảnh [6,70,71], tạo video [25,45,45], tổng hợp giọng nói [5,36], và tổng hợp 3D [52,72]. Cùng với sự phát triển của các thuật toán lấy mẫu [10,32,41,42,62,66], cuộc cách mạng về các khung xương đứng như một khía cạnh quan trọng trong sự tiến bộ của các mô hình khuếch tán. Một ví dụ tiêu biểu là U-Net dựa trên mạng nơ-ron tích chập (CNN) [26,63], đã được nổi bật trong nghiên cứu trước đây. UNet dựa trên CNN được đặc trưng bởi một nhóm các khối lấy mẫu xuốngarXiv:2402.05608v3  [cs.CV]  28 Mar 2024

--- TRANG 2 ---
2 Fei et al.
Khối SSM
...
Lớp nhúngKhối SSM
...Tuyến tính
...
Bỏ qua
ChuẩnTiến
Conv1dTiến
SSM
Lùi
Conv1dLùi
SSM
Kích hoạt
Khối SSM
Bước thời gian
Điều kiện
Hình 1: Các mô hình khuếch tán dựa trên không gian trạng thái được đề xuất. Nó xử lý tất cả các đầu vào bao gồm thời gian, điều kiện và các miếng vá hình ảnh nhiễu như là các token và sử dụng các kết nối bỏ qua giữa các lớp nông và sâu. Khác với Mamba gốc cho mô hình hóa chuỗi văn bản, khối SSM của chúng tôi xử lý chuỗi trạng thái ẩn với cả hướng tiến và lùi.

khối, một nhóm các khối lấy mẫu lên, và các kết nối bỏ qua dài giữa hai nhóm [9,53–55]. Tương tự, kiến trúc dựa trên Transformer thay thế khối lấy mẫu bằng self-attention trong khi giữ nguyên phần còn lại [1,51,68], dẫn đến hiệu suất được sắp xếp hợp lý nhưng hiệu quả.

Mặt khác, các mô hình không gian trạng thái (SSM) với thiết kế nhận thức phần cứng hiệu quả, đã thể hiện tiềm năng lớn trong lĩnh vực mô hình hóa chuỗi dài [19, 20,22,29,49,59]. Khi cơ chế self-attention trong Transformer tỷ lệ bậc hai với kích thước đầu vào, khiến chúng tốn nhiều tài nguyên khi xử lý các phụ thuộc thị giác tầm xa, tức là, hình ảnh độ phân giải cao. Những nỗ lực gần đây, được minh họa bởi công trình về Mamba [15,16], đã tìm cách giải quyết bằng cách tích hợp các tham số thay đổi theo thời gian vào SSM và đề xuất một thuật toán nhận thức phần cứng để cho phép huấn luyện và suy luận hiệu quả. Hiệu suất mở rộng đáng khen ngợi của Mamba nhấn mạnh triển vọng của nó như một con đường khả thi để xây dựng các khung xương hiệu quả và linh hoạt trong lĩnh vực SSM. Được thúc đẩy bởi những thành công quan sát được trong mô hình hóa ngôn ngữ với Mamba, một câu hỏi thích hợp xuất hiện: liệu chúng ta có thể xây dựng U-Net dựa trên SSM trong các mô hình khuếch tán không?

Trong bài báo này, chúng tôi nhằm mục đích thiết kế một kiến trúc dựa trên không gian trạng thái đơn giản và tổng quát cho các mô hình khuếch tán, được gọi là DiS. Theo các nguyên tắc thiết kế của [51], DiS xử lý tất cả các đầu vào bao gồm thời gian, điều kiện và các miếng vá hình ảnh nhiễu như là các token rời rạc. Quan trọng nhất, chúng tôi tiến hành một nghiên cứu ablation có hệ thống bao gồm việc kết hợp các yếu tố điều kiện và tối ưu hóa kiến trúc mô hình trên tất cả các thành phần. Đáng chú ý là việc DiS tuân thủ các thực hành tốt nhất đã được thiết lập của các mô hình không gian trạng thái, nổi tiếng với khả năng mở rộng vượt trội trong các nhiệm vụ tạo hình ảnh khi so sánh với CNN hoặc Transformer, tất cả trong khi duy trì chi phí tính toán thấp hơn.

--- TRANG 3 ---
DiS 3
Về mặt thực nghiệm, chúng tôi đánh giá hiệu suất DiS trên cả các nhiệm vụ tạo hình ảnh không điều kiện và có điều kiện lớp. Trong tất cả các cài đặt, DiS thể hiện hiệu quả tương đương, nếu không muốn nói là vượt trội, khi so sánh với các U-Net dựa trên CNN hoặc Transformer có kích thước tương tự. Ngoài ra, chúng tôi cung cấp bằng chứng cho thấy DiS là các kiến trúc có thể mở rộng cho các mô hình khuếch tán, trong đó một mối tương quan có thể nhận ra được quan sát giữa độ phức tạp mạng và chất lượng mẫu. Hơn nữa, các thí nghiệm mang lại kết quả ấn tượng, với DiS đạt được điểm FID tương đương trong tạo hình ảnh có điều kiện lớp được tiến hành trên ImageNet ở độ phân giải 256 ×256 và 512 ×512. Nghiên cứu này nỗ lực để làm rõ tính quan trọng của việc lựa chọn kiến trúc trong lĩnh vực các mô hình khuếch tán, đồng thời cung cấp các benchmark thực nghiệm có thể thông báo cho nghiên cứu sắp tới trong mô hình hóa sinh. Khát vọng của chúng tôi là những hiểu biết thu được từ DiS sẽ phục vụ như kiến thức nền tảng cho các điều tra tương lai liên quan đến các kiến trúc khung xương trong các mô hình khuếch tán, cuối cùng làm phong phú cảnh quan của mô hình hóa sinh, đặc biệt trong bối cảnh các bộ dữ liệu đa phương thức quy mô lớn.

2 Phương pháp
2.1 Kiến thức cơ bản
Mô hình khuếch tán. Trước khi trình bày kiến trúc của chúng tôi, chúng tôi cung cấp một tổng quan ngắn gọn về các khái niệm cơ bản liên quan đến cuộc thảo luận của chúng tôi. Các mô hình khuếch tán [26,60] dần dần tiêm nhiễu vào dữ liệu, và sau đó đảo ngược quá trình này để tạo dữ liệu từ nhiễu. Quá trình tiêm nhiễu, còn được gọi là quá trình tiến, có thể được chính thức hóa như chuỗi Markov như sau:
q(x1:T|x0) =TY
t=1q(xt|xt−1),
q(xt|xt−1) =N(xt|√αtxt−1, βtI),(1)
Ở đây x0 là dữ liệu, αt và βt đại diện cho lịch trình nhiễu, đảm bảo αt+βt= 1.
Để đảo ngược quá trình này, một mô hình Gaussian p(xt−1|xt) =N(xt−1|µt(xt), σ2
tI) được sử dụng để xấp xỉ chuyển tiếp đảo ngược sự thật q(xt−1|xt), trong đó việc học tương đương với một nhiệm vụ dự đoán nhiễu. Một cách chính thức, một mạng dự đoán nhiễu ϵθ(xt, t) được kết hợp bằng cách tối thiểu hóa một mục tiêu dự đoán nhiễu, tức là, minθEt,x0,ϵ||ϵ−ϵθ(xt, t)||2
2, trong đó t được phân phối đều giữa 1 và T. Để học các mô hình khuếch tán có điều kiện, ví dụ, có điều kiện lớp [9] hoặc các mô hình văn bản-thành-hình ảnh [2,53], thông tin điều kiện bổ sung được tích hợp vào mục tiêu dự đoán nhiễu như sau:
min
θEt,x0,c,ϵ||η−ηθ(xt, t,c)||2
2, (2)
trong đó c là chỉ số điều kiện hoặc nhúng liên tục của nó.

--- TRANG 4 ---
4 Fei et al.
Khung xương không gian trạng thái. Các mô hình không gian trạng thái thường được định nghĩa như các hệ thống tuyến tính bất biến theo thời gian xây dựng một ánh xạ kích thích x(t)∈RN đến phản hồi y(t)∈RN bởi một trạng thái tiềm ẩn h(t)∈RN. Quá trình có thể được công thức hóa như sau:
h′(t) =Ah(t) +Bx(t),
y(t) =Ch(t),(3)
trong đó A∈RN×N và B,C∈RN biểu thị ma trận trạng thái, ma trận đầu vào, và ma trận đầu ra, tương ứng. Trong việc tìm cách suy ra chuỗi đầu ra y(t) tại thời điểm t, giải pháp phân tích để thu được h(t) chứng minh là một thách thức to lớn. Ngược lại, dữ liệu thực tế thường biểu hiện dưới dạng rời rạc chứ không phải liên tục. Như một lựa chọn thay thế, chúng ta có thể rời rạc hóa hệ thống trong Phương trình 3 như sau:
ht=Aht−1+Bxt,
yt=Cht,(4)
trong đó A:= exp( ∆·A) và B:= (∆·A)−1(exp( ∆·A)−I)·∆B là các tham số trạng thái rời rạc hóa và ∆ là kích thước bước rời rạc hóa.

Trong khi SSM tự hào có các tính chất lý thuyết phong phú, chúng thường bị ảnh hưởng bởi chi phí tính toán cao và bất ổn định số. Những thiếu sót này đã thúc đẩy sự phát triển của các mô hình chuỗi không gian trạng thái có cấu trúc (S4), tìm cách giảm thiểu những thách thức này bằng cách áp đặt định dạng có cấu trúc trên ma trận trạng thái A thông qua việc sử dụng ma trận HIPPO. Cải tiến cấu trúc này đã dẫn đến những tiến bộ đáng chú ý trong cả hiệu suất và hiệu quả. Đáng chú ý, S4 đã thể hiện lợi thế hiệu suất đáng kể so với Transformer, điều này cần thiết để mô hình hóa hiệu quả các phụ thuộc tầm xa [19]. Gần đây hơn, Mamba [16] tiến bộ hơn nữa tiềm năng của nó thông qua cơ chế lựa chọn phụ thuộc đầu vào và thuật toán nhận thức phần cứng nhanh hơn.

2.2 Thiết kế cấu trúc mô hình
Chúng tôi giới thiệu Mô hình không gian trạng thái khuếch tán, được ký hiệu là DiS, một kiến trúc đơn giản và tổng quát cho các mô hình khuếch tán trong tạo hình ảnh. Cụ thể, DiS tham số hóa mạng dự đoán nhiễu ϵθ(xt, t,c), nhận bước thời gian t, điều kiện c và hình ảnh nhiễu xt làm đầu vào và dự đoán nhiễu được tiêm vào xt. Mục tiêu của chúng tôi là tuân thủ chặt chẽ kiến trúc không gian trạng thái tiên tiến để bảo tồn các đặc tính khả năng mở rộng của nó, do đó, DiS dựa trên kiến trúc Mamba hai chiều [16,73] hoạt động trên các chuỗi token. Hình 1 cung cấp tổng quan về kiến trúc DiS hoàn chỉnh. Trong phần này, chúng tôi trình bày về chuyển tiếp tiến của DiS, cũng như các thành phần của không gian thiết kế của lớp DiS.

Patchnify hình ảnh. Lớp đầu tiên của DiS thực hiện chuyển đổi hình ảnh đầu vào I∈RH×W×C thành các miếng vá 2-D phẳng X∈RJ×(p2·C). Sau đó,

--- TRANG 5 ---
DiS 5
chuyển đổi nó thành một chuỗi J token, mỗi token có chiều D, bằng cách nhúng tuyến tính từng miếng vá trong đầu vào. Phù hợp với [11], chúng tôi áp dụng các nhúng vị trí có thể học cho tất cả các token đầu vào. Số lượng token J được tạo bởi patchify được xác định bởi siêu tham số kích thước miếng vá p thành H×W
p2. Patchnify hỗ trợ cả pixel thô và không gian tiềm ẩn. Chúng tôi đặt p= 2,4,8 cho không gian thiết kế.

Khối SSM. Sau lớp nhúng, các token đầu vào được xử lý bởi một chuỗi các khối SSM. Ngoài đầu vào hình ảnh nhiễu, các mô hình khuếch tán đôi khi xử lý thông tin điều kiện bổ sung như bước thời gian nhiễu t, điều kiện c như nhãn lớp hoặc ngôn ngữ tự nhiên. Cho rằng khối Mamba gốc được thiết kế cho chuỗi 1-D, chúng tôi dùng đến [73], kết hợp mô hình hóa chuỗi hai chiều được thiết kế cho các nhiệm vụ thị giác. Các thiết kế giới thiệu những thay đổi tinh tế nhưng quan trọng đối với thiết kế khối SSM chuẩn. Như được hiển thị trong Hình 1 phần bên phải, chuyển tiếp tiến của các khối SSM kết hợp cả hướng tiến và lùi.

Kết nối bỏ qua. Cho một loạt L khối SSM, chúng tôi phân loại khối SSM ngăn xếp thành nhóm nông nửa đầu ⌊L
2⌋, một lớp giữa, và nhóm sâu nửa thứ hai ⌊L
2⌋. Gọi hshallow ,hdeep∈RJ×D là các trạng thái ẩn từ nhánh chính và nhánh bỏ qua dài tương ứng. Chúng tôi xem xét việc nối trực tiếp chúng và thực hiện một phép chiếu tuyến tính, tức là, Linear(Concat( hshallow ,hdeep)), trước khi đưa chúng vào khối SSM tiếp theo.

Bộ giải mã tuyến tính. Sau khối SSM cuối cùng, chúng tôi cần giải mã chuỗi trạng thái ẩn của chúng tôi thành một dự đoán nhiễu đầu ra và dự đoán hiệp phương sai đường chéo. Cả hai đầu ra này đều giữ một hình dạng giống hệt với đầu vào không gian gốc. Chúng tôi sử dụng một bộ giải mã tuyến tính chuẩn, tức là, chúng tôi áp dụng chuẩn hóa lớp cuối cùng và giải mã tuyến tính từng token thành một tensor p2·C. Cuối cùng, chúng tôi sắp xếp lại các token đã giải mã vào bố cục không gian gốc của chúng để có được dự đoán nhiễu và hiệp phương sai.

Kết hợp điều kiện. Để tích hợp hiệu quả các điều kiện bổ sung, chúng tôi áp dụng một chiến lược đơn giản là nối các nhúng vector của bước thời gian t và điều kiện c như hai token bổ sung trong chuỗi đầu vào. Những token này được xử lý tương đương như các token hình ảnh, tương tự như cách tiếp cận với token cls trong Vision Transformer [11]. Cách tiếp cận này cho phép sử dụng các khối SSM mà không cần thiết bất kỳ thay đổi nào. Sau khối cuối cùng, các token điều kiện được loại bỏ khỏi chuỗi. Chúng tôi cũng khám phá lớp chuẩn hóa thích ứng, trong đó thay thế lớp chuẩn hóa chuẩn bằng lớp chuẩn hóa thích ứng. Nghĩa là, thay vì học trực tiếp các tham số tỷ lệ và dịch chuyển theo chiều, chúng tôi hồi quy chúng từ tổng của các vector nhúng của t và c, điều này sẽ được thảo luận trong Phần Thí nghiệm.

--- TRANG 6 ---
6 Fei et al.
Bảng 1: Kích thước mô hình quy luật mở rộng. Các kích thước mô hình và cài đặt siêu tham số chi tiết cho các thí nghiệm mở rộng.
#Params #Blocks L Chiều ẩn D #Expand E Gflops
Small 28.4M 25 384 2 0.43
Base 119.1M 25 768 2 1.86
Medium 229.4M 49 768 2 3.70
Large 404.0M 49 1024 2 6.57
Huge 900.6M 49 1536 2 14.79

2.3 Phân tích tính toán
Tóm lại, các siêu tham số của kiến trúc chúng tôi bao gồm những điều sau đây: số lượng khối L, chiều trạng thái ẩn D, chiều trạng thái mở rộng E, và chiều SSM N. Các cấu hình khác nhau của DiS được phác thảo trong Bảng 1. Chúng bao gồm một phạm vi rộng các kích thước mô hình và phân bổ flop, từ 28M đến 900M, do đó cung cấp các hiểu biết toàn diện về hiệu suất khả năng mở rộng. Phù hợp với [51], chỉ số Gflop được đánh giá trong tạo hình ảnh không điều kiện 32 ×32 với kích thước miếng vá p= 4 với gói python thop. Theo [16] chúng tôi cũng đặt chiều SSM của tất cả các biến thể mô hình thành 16.

Cả khối SSM trong DiS và self-attention trong Transformer đều đóng vai trò quan trọng trong việc mô hình hóa bối cảnh dài một cách thích ứng. Chúng tôi tiến hành cung cấp phân tích lý thuyết liên quan đến hiệu quả tính toán. Cho một chuỗi X∈R1×J×D và cài đặt mặc định E= 2, độ phức tạp tính toán của một thao tác self-attention và SSM được phác thảo như sau:
O(SA) = 4JD2+ 2J2D, (5)
O(SSM) = 3J(2D)N+J(2D)N2, (6)
trong đó chúng ta có thể thấy rằng self-attention là bậc hai đối với độ dài chuỗi J, và SSM là tuyến tính đối với độ dài chuỗi J. Đáng chú ý là N là một tham số cố định, thường được đặt thành 16 theo mặc định. Hiệu quả tính toán này làm cho DiS phù hợp với khả năng mở rộng trong các tình huống cần thiết tạo với độ dài chuỗi lớn, như các ứng dụng gigapixel.

3 Thí nghiệm
Chúng tôi đi sâu vào không gian thiết kế và xem xét kỹ lưỡng các tính chất mở rộng của lớp mô hình DiS của chúng tôi. Mô hình của chúng tôi được đặt tên theo cấu hình của chúng và kích thước miếng vá p; ví dụ, DiS-L/2 đề cập đến cấu hình phiên bản Large và p= 2.

3.1 Cài đặt thí nghiệm
Bộ dữ liệu. Cho học tập hình ảnh không điều kiện, chúng tôi xem xét CIFAR10 [37], bao gồm 50K hình ảnh huấn luyện, và CelebA 64x64 [40], chứa 162,770

--- TRANG 7 ---
DiS 7
Hình 2: Thí nghiệm ablation với DiS-S/2 trên bộ dữ liệu CIFAR10. Chúng tôi báo cáo chỉ số FID trên 10K mẫu được tạo. (a) Kích thước miếng vá. Một kích thước miếng vá nhỏ hơn có thể cải thiện hiệu suất tạo. (b) Bỏ qua dài. Kết hợp nhánh bỏ qua dài có thể tăng tốc quá trình huấn luyện cũng như tối ưu hóa kết quả được tạo.

hình ảnh huấn luyện của khuôn mặt người. Cho học tập hình ảnh có điều kiện lớp, chúng tôi xem xét ImageNet [8] ở độ phân giải 256 ×256 và 512 ×512, chứa 1,281,167 hình ảnh huấn luyện trên 1,000 lớp khác nhau. Việc tăng cường dữ liệu duy nhất là lật ngang. Chúng tôi huấn luyện 500K lần lặp trên CIFAR10 và CelebA 64 ×64 với kích thước batch 128. Chúng tôi huấn luyện 500K và 1M lần lặp trên ImageNet 256 ×256 và 512×512, với kích thước batch 1024.

Chi tiết thực hiện. Chúng tôi sử dụng bộ tối ưu hóa AdamW [33] không có weight decay trên tất cả các bộ dữ liệu. Chúng tôi duy trì tốc độ học 1e-4 với lịch trình cosine. Trong các thí nghiệm ban đầu, chúng tôi đã thử tốc độ học từ 1e-4 đến 5e-4, và thấy rằng loss có thể trở thành NAN nếu tốc độ học được đặt lớn hơn 3e-4. Phù hợp với thực hành trong tài liệu [51], chúng tôi sử dụng trung bình động mũ của trọng số DiS trong suốt quá trình huấn luyện với độ suy giảm 0.9999. Tất cả kết quả được báo cáo bằng mô hình EMA. Các mô hình của chúng tôi được huấn luyện trên GPU Nvidia A100. Khi huấn luyện trên bộ dữ liệu ImageNet ở độ phân giải 256 ×256 và 512 ×512, chúng tôi áp dụng hướng dẫn không có bộ phân loại [28] theo [54] và sử dụng mô hình bộ tự động mã hóa biến thiên (VAE) được huấn luyện trước có sẵn [35] từ Stable Diffusion [54] được cung cấp trong huggingface1. Bộ mã hóa VAE có hệ số lấy mẫu xuống là 8. Chúng tôi huấn luyện lại các siêu tham số khuếch tán từ [51], sử dụng lịch trình phương sai tuyến tính tmax = 1000 từ 1×10−4 đến 2×10−2 và tham số hóa của hiệp phương sai.

Chỉ số đánh giá. Chúng tôi đo hiệu suất tạo hình ảnh với Khoảng cách Inception Frechet (FID) [24], một chỉ số được áp dụng rộng rãi để đánh giá chất lượng của hình ảnh được tạo. Chúng tôi tuân theo quy ước khi so sánh với các công trình trước đó và báo cáo FID-50K sử dụng 250 bước lấy mẫu DDPM [50] theo quy trình
1https://huggingface.co/stabilityai/sd-vae-ft-ema

--- TRANG 8 ---
8 Fei et al.
Hình 3: Phân tích mô hình cho các thiết kế khác nhau. (a) Các biến thể của kết hợp điều kiện. Đưa thời gian như token vào mạng là hiệu quả. (b) Mở rộng tham số mô hình. Như chúng tôi mong đợi, giữ kích thước miếng vá không đổi, tăng kích thước mô hình có thể cải thiện hiệu suất tạo một cách liên tục.

của [9]. Đáng chú ý, các giá trị FID được trình bày trong phần này được tính toán mà không có hướng dẫn không có bộ phân loại, trừ khi được chỉ định khác. Chúng tôi bổ sung báo cáo Điểm Inception [56], sFID [47] và Precision/Recall [38] như các chỉ số thứ cấp.

3.2 Phân tích mô hình
Trong phần này, chúng tôi thực hiện một cuộc điều tra thực nghiệm có hệ thống về các thành phần cơ bản của các mô hình DiS. Cụ thể, chúng tôi ablate trên bộ dữ liệu CIFAR10, đánh giá điểm FID mỗi 50K lần lặp huấn luyện trên 10K mẫu được tạo, thay vì 50K mẫu để hiệu quả giống hệt với [1], và xác định các chi tiết thực hiện mặc định tối ưu.

Hiệu ứng của kích thước miếng vá. Chúng tôi huấn luyện phạm vi kích thước miếng vá trên (8, 4, 2) với cấu hình DiS-S trên bộ dữ liệu CIFAR10. Như được mô tả trong Hình 2(a) hiển thị chỉ số FID dao động trong phản hồi với việc giảm kích thước miếng vá khi duy trì kích thước mô hình nhất quán. Chúng tôi quan sát thấy rằng các cải tiến FID có thể nhận ra được quan sát thấy trong suốt quá trình huấn luyện bằng cách tăng số lượng token được xử lý bởi DiS, giữ tham số gần như cố định. Do đó, hiệu suất tối ưu cần thiết một kích thước miếng vá nhỏ hơn, như 2. Chúng tôi giả định rằng yêu cầu này xuất phát từ bản chất vốn dĩ cấp thấp của nhiệm vụ dự đoán nhiễu trong các mô hình khuếch tán, ưu tiên các miếng vá nhỏ hơn, trái ngược với các nhiệm vụ cấp cao hơn như phân loại. Hơn nữa, cho rằng chi phí tính toán liên quan đến việc sử dụng kích thước miếng vá nhỏ cho hình ảnh độ phân giải cao, một cách tiếp cận thay thế liên quan đến việc chuyển đổi những hình ảnh này thành các biểu diễn tiềm ẩn chiều thấp, sau đó cũng được mô hình hóa bằng cách sử dụng chuỗi DiS.

Hiệu ứng của bỏ qua dài. Để đánh giá hiệu quả của thao tác bỏ qua, chúng tôi xem xét ba biến thể bao gồm: (i) Nối, tức là, Linear(Concat( hshallow,

--- TRANG 9 ---
DiS 9
Bảng 2: Benchmarking tạo hình ảnh không điều kiện trên CIFAR10. Mô hình DiS-S/2 thu được kết quả tương đương với ít tham số hơn.
Không điều kiện CIFAR10
Mô hình #Params FID ↓
Diff. dựa trên U-Net
DDPM [26] 36M 3.17
EDM [30] 56M 1.97
Diff. dựa trên Transformer
GenViT [68] 11M 20.20
U-ViT-S/2 [1] 44M 3.11
Diff. dựa trên SSM
DiS-S/2 28M 3.25

Bảng 3: Benchmarking tạo hình ảnh không điều kiện trên CelebA 64 ×64. DiS-S/2 duy trì hiệu suất tạo vượt trội trong cài đặt mô hình nhỏ.
Không điều kiện CelebA 64 ×64
Mô hình #Params FID ↓
Diff. dựa trên U-Net
DDIM [61] 79M 3.26
Soft Trunc. [31] 62M 1.90
Diff. dựa trên Transformer
U-ViT-S/4 [1] 44M 2.87
Diff. dựa trên SSM
DiS-S/2 28M 2.05

hdeep)); (ii) Phép cộng, tức là, hshallow +hdeep; (iii) Không có kết nối bỏ qua. Như hiển thị trong Hình 2(b), việc cộng trực tiếp các trạng thái ẩn từ các lớp nông và sâu không mang lại bất kỳ lợi ích có thể nhận ra nào. Cho rằng khối SSM đã kết hợp các kết nối bỏ qua dư thừa bên trong, các trạng thái ẩn của lớp sâu vốn dĩ bao gồm một số thông tin từ lớp nông theo cách tuyến tính. Do đó, thao tác cộng trong bỏ qua dài chỉ đơn giản là khuếch đại sự đóng góp của trạng thái ẩn lớp nông, mà không thay đổi cơ bản hành vi của mạng. Ngược lại, việc sử dụng nối liên quan đến phép chiếu tuyến tính có thể học trên các trạng thái ẩn nông và hiệu quả cải thiện hiệu suất so với việc thiếu kết nối bỏ qua dài.

Hiệu ứng của kết hợp điều kiện. Chúng tôi khám phá hai cách để tích hợp bước thời gian điều kiện t vào mạng: (i) xử lý bước thời gian t như một token và nối trực tiếp nó với các miếng vá hình ảnh trong tiền tố. (ii) kết hợp nhúng thời gian sau chuẩn hóa lớp trong khối SSM, tương tự như chuẩn hóa nhóm thích ứng [9] được sử dụng trong U-Net. Cách thứ hai được gọi là chuẩn hóa lớp thích ứng (AdaLN). Một cách chính thức, AdaLN( h, s)=ysLayerNorm (h)+yb, trong đó h là một trạng thái ẩn bên trong khối SSM, và ys và yb được thu được từ phép chiếu tuyến tính của nhúng thời gian. Như được minh họa trong Hình 3 (a), trong khi đơn giản và trực tiếp, cách thứ nhất xử lý thời gian như một token hoạt động tốt hơn AdaLN.

Mở rộng kích thước mô hình. Chúng tôi điều tra các tính chất mở rộng của DiS bằng cách nghiên cứu hiệu ứng của độ sâu, tức là, số lượng lớp SSM, chiều rộng, ví dụ như kích thước ẩn. Cụ thể, chúng tôi huấn luyện 5 mô hình DiT trên bộ dữ liệu ImageNet với độ phân giải 256 ×256, trải dài các cấu hình mô hình từ nhỏ đến lớn như được chi tiết trong Bảng 1, được ký hiệu là (S, B, M, L, H) cho đơn giản. Như được hiển thị trong Hình 3 (b), hiệu suất

--- TRANG 10 ---
10 Fei et al.
Bảng 4: Benchmarking tạo hình ảnh có điều kiện lớp trên ImageNet 256×256. DiS-H/2 đạt được chỉ số FID tối tân hướng tới các đối thủ tốt nhất.
Có điều kiện lớp ImageNet 256 ×256
Mô hình FID ↓sFID↓IS↑Precision ↑Recall↑
GAN
BigGAN-deep [3] 6.95 7.36 171.4 0.87 0.28
StyleGAN-XL [57] 2.30 4.02 265.12 0.78 0.53
Diff. dựa trên U-Net
ADM [9] 10.94 6.02 100.98 0.69 0.63
ADM-U 7.49 5.13 127.49 0.72 0.63
ADM-G 4.59 5.25 186.70 0.82 0.52
ADM-G, ADM-U 3.94 6.14 215.84 0.83 0.53
CDM [27] 4.88 - 158.71 - -
LDM-8 [54] 15.51 - 79.03 0.65 0.63
LDM-8-G 7.76 - 209.52 0.84 0.35
LDM-4 10.56 - 103.49 0.71 0.62
LDM-4-G 3.60 - 247.67 0.87 0.48
VDM++ [34] 2.12 - 267.70 - -
Diff. dựa trên Transformer
U-ViT-H/2 [1] 2.29 5.68 263.88 0.82 0.57
DiT-XL/2 [51] 2.27 4.60 278.24 0.83 0.57
Diff. dựa trên SSM
DiS-H/2 2.10 4.55 271.32 0.82 0.58

cải thiện khi độ sâu tăng từ 25 lên 49. Tương tự, tăng chiều rộng từ 384 lên 768 mang lại lợi ích hiệu suất. Đáng chú ý, hiệu suất của mô hình vẫn chưa đạt đến sự hội tụ. Nhìn chung, trên tất cả năm cấu hình, những cải tiến đáng kể trong FID được quan sát thấy trên tất cả các giai đoạn huấn luyện bằng cách tăng độ sâu và chiều rộng của cấu trúc SSM.

3.3 Kết quả chính
Tạo hình ảnh không điều kiện. Chúng tôi tiến hành phân tích so sánh giữa mô hình DiT-S/2 và các mô hình khuếch tán trước đó dựa trên U-Net cũng như các mô hình khuếch tán dựa trên Transformer. Phù hợp với tài liệu trước đó [1], chúng tôi đánh giá chất lượng hình ảnh bằng điểm FID, dựa trên 50K mẫu được tạo. Như được tóm tắt trong Bảng 2 và 3, DiS thể hiện hiệu suất tương đương với U-Net và U-ViT-S/2 trên các bộ dữ liệu CIFAR10 và CelebA 64 ×64 không điều kiện, trong khi vượt trội đáng kể so với GenViT. Hơn nữa, đáng chú ý, mô hình của chúng tôi đạt được giảm khoảng 50% tham số mô hình.

Tạo hình ảnh có điều kiện lớp. Để chứng minh hiệu suất trong không gian tiềm ẩn, nơi hình ảnh ban đầu được chuyển đổi thành các biểu diễn tiềm ẩn của chúng trước khi áp dụng các mô hình khuếch tán, chúng tôi đã tiến hành các thí nghiệm bổ sung. Việc đánh giá

--- TRANG 11 ---
DiS 11
Bảng 5: Benchmarking tạo hình ảnh có điều kiện lớp trên ImageNet 512×512. DiS-H/2 thể hiện hiệu suất triển vọng so với cả UNet dựa trên CNN và Transformer cho khuếch tán.
Có điều kiện lớp ImageNet 512 ×512
Mô hình FID ↓sFID↓IS↑Precision ↑Recall↑
GAN
BigGAN-deep [3] 8.43 8.13 177.90 0.88 0.29
StyleGAN-XL [57] 2.41 4.06 267.75 0.77 0.52
Diff. dựa trên U-Net
ADM [9] 23.24 10.19 58.06 0.73 0.60
ADM-U 9.96 5.62 121.78 0.75 0.64
ADM-G 7.72 6.57 172.71 0.87 0.42
ADM-G, ADM-U 3.85 5.86 221.72 0.84 0.53
VDM++ [34] 2.65 - 278.10 - -
Diff. dựa trên Transformer
U-ViT-H/4 [1] 4.05 6.44 263.79 0.84 0.48
DiT-XL/2 [51] 3.04 5.02 240.82 0.84 0.54
Diff. dựa trên SSM
DiS-H/2 2.88 4.74 272.33 0.84 0.56

kết quả được liệt kê trong Bảng 4 và 5. Trên bộ dữ liệu ImageNet 256 ×256 có điều kiện lớp, DiS-H/2 của chúng tôi đạt được FID là 2.10, vượt trội so với tất cả các mô hình trước đó. Đáng chú ý, DiS-H/2 cũng vượt trội hơn DiT-XL/2, một mô hình khuếch tán cạnh tranh sử dụng transformer làm khung xương. Hơn nữa, trên bộ dữ liệu ImageNet 512 ×512 có điều kiện lớp, DiS-H/2 của chúng tôi vượt trội hơn ADM-G, một mô hình mô hình hóa trực tiếp pixel hình ảnh. Cuối cùng, chúng tôi cũng quan sát thấy rằng DiS-H/2 đạt được các giá trị recall cao hơn trên tất cả các thang đo hướng dẫn không có bộ phân loại được thử nghiệm so với LDM-4 và LDM-8 trong các cài đặt khác nhau.

3.4 Nghiên cứu tình huống
Hình 4 trình bày một lựa chọn các mẫu từ các bộ dữ liệu ImageNet ở độ phân giải 256 ×256 và 512 ×512, cùng với các mẫu ngẫu nhiên từ các bộ dữ liệu khác, thể hiện ngữ nghĩa rõ ràng và tạo chất lượng cao. Để khám phá thêm, các mẫu được tạo bổ sung, bao gồm cả có điều kiện lớp và ngẫu nhiên, có sẵn trên trang dự án.

4 Công trình liên quan
4.1 Khung xương không gian trạng thái cho mô hình hóa chuỗi
Các mô hình không gian trạng thái, một bổ sung gần đây vào lĩnh vực học sâu, đã thu hút sự chú ý vì khả năng biến đổi không gian trạng thái của chúng [19,20,31]. Lấy cảm hứng từ các mô hình không gian trạng thái liên tục trong hệ thống điều khiển và tận dụng khởi tạo HiPPO [17], LSSL [20] đã thể hiện triển vọng trong việc giải quyết các vấn đề phụ thuộc tầm xa. Tuy nhiên, các yêu cầu tính toán và bộ nhớ liên quan đến biểu diễn trạng thái làm cho LSSL không thực tế cho các ứng dụng thực tế. Để giảm thiểu thách thức này, S4 [19] đề xuất chuẩn hóa các tham số thành cấu trúc đường chéo. Sau đó, các lần lặp khác nhau của các mô hình không gian trạng thái có cấu trúc đã xuất hiện, có các cấu trúc đa dạng như cấu hình đường chéo phức tạp [18,22], hỗ trợ nhiều đầu vào nhiều đầu ra [59], phân tích các thao tác đường chéo cộng hạng thấp [23], cơ chế lựa chọn [16]. Những mô hình này đã được tích hợp vào các mô hình biểu diễn lớn [15,43,44], chủ yếu tập trung vào các ứng dụng liên quan đến dữ liệu tầm xa và nhân quả như ngôn ngữ và giọng nói, bao gồm các nhiệm vụ như hiểu ngôn ngữ

--- TRANG 12 ---
12 Fei et al.
Hình 4: Kết quả hình ảnh được tạo từ mô hình DiS. Các mẫu được chọn trên ImageNet 256×256, và các mẫu ngẫu nhiên trên CIFAR10, CelebA 64 ×64. Chúng ta có thể thấy rằng DiS có thể tạo ra hình ảnh chất lượng cao trong khi duy trì sự liên kết điều kiện tích hợp.

[43] và lập luận dựa trên nội dung [16]. Công trình tiêu biểu [67] liên quan nhất với chúng tôi, họ phân tích cấu trúc không có attention cho tổng hợp hình ảnh. Trong bài báo này, chúng tôi tập trung vào các tính chất mở rộng của cấu trúc Mamba tiên tiến khi được sử dụng làm khung xương của các mô hình khuếch tán hình ảnh.

4.2 Tạo hình ảnh trong khuếch tán
Các mô hình khuếch tán [7,9,26,48,60] đại diện cho một danh mục các mô hình xác suất sinh được thiết kế để xấp xỉ các phân phối dữ liệu và tạo điều kiện thuận lợi cho các thủ tục lấy mẫu đơn giản. Thông thường, các mô hình này hoạt động bằng cách lấy một đầu vào nhiễu Gaussian và loại bỏ nhiễu nó lặp đi lặp lại thông qua một loạt các bước dần dần cho đến khi nó phù hợp với phân phối mục tiêu. Các chi tiết cụ thể của quá trình loại bỏ nhiễu, bao gồm số lượng bước và tham số hóa biến đổi, khác nhau giữa các nghiên cứu khác nhau [39,41,42,60,61]. Gần đây, các mô hình khuếch tán đã nổi lên như những bộ tạo hàng đầu nổi tiếng với khả năng học các phân phối phức tạp và tạo ra các mẫu đa dạng, chất lượng cao. Những mô hình này đã tìm thấy ứng dụng thành công trong các lĩnh vực khác nhau, bao gồm hình ảnh [9,12–14,48,53–55], video [58], cảnh 3D [46], chuỗi chuyển động [65,69], v.v. Chúng tôi theo con đường tạo hình ảnh với khuếch tán, nhưng xem xét tác động của các cấu trúc hiệu quả cao.

5 Kết luận
Bài báo này trình bày Mô hình không gian trạng thái khuếch tán (DiS), một framework dựa trên không gian trạng thái đơn giản và tổng quát cho tạo hình ảnh sử dụng các mô hình khuếch tán. DiS áp dụng cách tiếp cận thống nhất để xử lý tất cả các đầu vào, bao gồm thời gian, điều kiện và các miếng vá hình ảnh nhiễu, xử lý chúng như các token được nối. Kết quả thí nghiệm cho thấy DiS so sánh thuận lợi, nếu không muốn nói là vượt trội, so với các mô hình U-Net dựa trên CNN hoặc Transformer trước đó trong khi kế thừa đặc tính khả năng mở rộng đáng chú ý của lớp mô hình không gian trạng thái. Chúng tôi cho rằng DiS có thể cung cấp các hiểu biết có giá trị cho các điều tra tương lai về các khung xương trong các mô hình khuếch tán và đóng góp vào những tiến bộ trong mô hình hóa sinh trên các bộ dữ liệu đa phương thức quy mô lớn. Cho rằng các kết quả khả năng mở rộng khuyến khích được trình bày trong nghiên cứu này, các nỗ lực tương lai nên tập trung vào việc mở rộng thêm DiS đến các mô hình lớn hơn và số lượng token nhiều hơn.

Tài liệu tham khảo
1. Bao, F., Nie, S., Xue, K., Cao, Y., Li, C., Su, H., Zhu, J.: All are worth words: A vit backbone for diffusion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 22669–22679 (2023) 2, 8, 9, 10, 11
2. Betker, J., Goh, G., Jing, L., Brooks, T., Wang, J., Li, L., Ouyang, L., Zhuang, J., Lee,J.,Guo,Y.,etal.:Improvingimagegenerationwithbettercaptions.Computer Science. https://cdn. openai. com/papers/dall-e-3. pdf 2(3), 8 (2023) 3
3. Brock, A., Donahue, J., Simonyan, K.: Large scale gan training for high fidelity natural image synthesis. arXiv preprint arXiv:1809.11096 (2018) 10, 11

--- TRANG 13 ---
DiS 13
4. Cao, H., Tan, C., Gao, Z., Xu, Y., Chen, G., Heng, P.A., Li, S.Z.: A survey on generative diffusion models. IEEE Transactions on Knowledge and Data Engineering (2024) 1
5. Chen, N., Zhang, Y., Zen, H., Weiss, R.J., Norouzi, M., Chan, W.: Wavegrad: Estimating gradients for waveform generation. arXiv preprint arXiv:2009.00713 (2020) 1
6. Choi, J., Kim, S., Jeong, Y., Gwon, Y., Yoon, S.: Ilvr: Conditioning method for denoising diffusion probabilistic models. arXiv preprint arXiv:2108.02938 (2021) 1
7. Croitoru, F.A., Hondru, V., Ionescu, R.T., Shah, M.: Diffusion models in vision: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence (2023) 13
8. Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: A large-scale hierarchical image database. In: 2009 IEEE conference on computer vision and pattern recognition. pp. 248–255. Ieee (2009) 7
9. Dhariwal, P., Nichol, A.: Diffusion models beat gans on image synthesis. Advances in neural information processing systems 34, 8780–8794 (2021) 1, 2, 3, 8, 9, 10, 11, 13
10. Dockhorn, T., Vahdat, A., Kreis, K.: Score-based generative modeling with critically-damped langevin diffusion. arXiv preprint arXiv:2112.07068 (2021) 1
11. Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et al.: An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929 (2020) 5
12. Duan, X., Cui, S., Kang, G., Zhang, B., Fei, Z., Fan, M., Huang, J.: Tuning-free inversion-enhanced control for consistent image editing. arXiv preprint arXiv:2312.14611 (2023) 13
13. Fei, Z., Fan, M., Huang, J.: Gradient-free textual inversion. arXiv preprint arXiv:2304.05818 (2023) 13
14. Fei, Z., Fan, M., Huang, J., Wei, X., Wei, X.: Progressive denoising model for fine-grained text-to-image generation. arXiv preprint arXiv:2210.02291 (2022) 13
15. Fu, D.Y., Dao, T., Saab, K.K., Thomas, A.W., Rudra, A., Ré, C.: Hungry hungry hippos: Towards language modeling with state space models. arXiv preprint arXiv:2212.14052 (2022) 2, 12
16. Gu, A., Dao, T.: Mamba: Linear-time sequence modeling with selective state spaces. arXiv preprint arXiv:2312.00752 (2023) 2, 4, 6, 12, 13
17. Gu, A., Dao, T., Ermon, S., Rudra, A., Ré, C.: Hippo: Recurrent memory with optimalpolynomialprojections.Advancesinneuralinformationprocessingsystems 33, 1474–1487 (2020) 12
18. Gu, A., Goel, K., Gupta, A., Ré, C.: On the parameterization and initialization of diagonal state space models. Advances in Neural Information Processing Systems 35, 35971–35983 (2022) 12
19. Gu, A., Goel, K., Ré, C.: Efficiently modeling long sequences with structured state spaces. arXiv preprint arXiv:2111.00396 (2021) 2, 4, 11, 12
20. Gu, A., Johnson, I., Goel, K., Saab, K., Dao, T., Rudra, A., Ré, C.: Combining recurrent,convolutional,andcontinuous-timemodelswithlinearstatespacelayers. Advances in neural information processing systems 34, 572–585 (2021) 2, 11, 12
21. Gu, S., Chen, D., Bao, J., Wen, F., Zhang, B., Chen, D., Yuan, L., Guo, B.: Vectorquantizeddiffusionmodelfortext-to-imagesynthesis.In:Proceedingsofthe IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10696–10706 (2022) 1

--- TRANG 14 ---
DiS 14
22. Gupta, A., Gu, A., Berant, J.: Diagonal state spaces are as effective as structured state spaces. Advances in Neural Information Processing Systems 35, 22982–22994 (2022) 2, 12
23. Hasani, R., Lechner, M., Wang, T.H., Chahine, M., Amini, A., Rus, D.: Liquid structural state-space models. arXiv preprint arXiv:2209.12951 (2022) 12
24. Heusel,M.,Ramsauer,H.,Unterthiner,T.,Nessler,B.,Hochreiter,S.:Ganstrained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems 30(2017) 7
25. Ho, J., Chan, W., Saharia, C., Whang, J., Gao, R., Gritsenko, A., Kingma, D.P., Poole, B., Norouzi, M., Fleet, D.J., et al.: Imagen video: High definition video generation with diffusion models. arXiv preprint arXiv:2210.02303 (2022) 1
26. Ho, J., Jain, A., Abbeel, P.: Denoising diffusion probabilistic models. Advances in neural information processing systems 33, 6840–6851 (2020) 1, 3, 9, 13
27. Ho, J., Saharia, C., Chan, W., Fleet, D.J., Norouzi, M., Salimans, T.: Cascaded diffusion models for high fidelity image generation. The Journal of Machine Learning Research23(1), 2249–2281 (2022) 1, 10
28. Ho, J., Salimans, T.: Classifier-free diffusion guidance. arXiv preprint arXiv:2207.12598 (2022) 7
29. Kalman, R.E.: A new approach to linear filtering and prediction problems (1960) 2
30. Karras,T.,Aittala,M.,Aila,T.,Laine,S.:Elucidatingthedesignspaceofdiffusion-based generative models. Advances in Neural Information Processing Systems 35, 26565–26577 (2022) 9
31. Kim, D., Shin, S., Song, K., Kang, W., Moon, I.C.: Soft truncation: A universal training technique of score-based diffusion model for high precision score estimation. arXiv preprint arXiv:2106.05527 (2021) 9, 11
32. Kingma, D., Salimans, T., Poole,B., Ho, J.:Variational diffusionmodels. Advances in neural information processing systems 34, 21696–21707 (2021) 1
33. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014) 7
34. Kingma, D.P., Gao, R.: Understanding diffusion objectives as the elbo with simple data augmentation. In: Thirty-seventh Conference on Neural Information Processing Systems (2023) 10, 11
35. Kingma, D.P., Welling, M.: Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013) 7
36. Kong, Z., Ping, W., Huang, J., Zhao, K., Catanzaro, B.: Diffwave: A versatile diffusion model for audio synthesis. arXiv preprint arXiv:2009.09761 (2020) 1
37. Krizhevsky, A., Hinton, G., et al.: Learning multiple layers of features from tiny images (2009) 6
38. Kynkäänniemi, T., Karras, T., Laine, S., Lehtinen, J., Aila, T.: Improved precision and recall metric for assessing generative models. Advances in Neural Information Processing Systems 32(2019) 8
39. Liu, L., Ren, Y., Lin, Z., Zhao, Z.: Pseudo numerical methods for diffusion models on manifolds. arXiv preprint arXiv:2202.09778 (2022) 13
40. Liu, Z., Luo, P., Wang, X., Tang, X.: Deep learning face attributes in the wild. In: Proceedings of the IEEE international conference on computer vision. pp. 3730–3738 (2015) 6
41. Lu, C., Zheng, K., Bao, F., Chen, J., Li, C., Zhu, J.: Maximum likelihood training for score-based diffusion odes by high order denoising score matching. In: International Conference on Machine Learning. pp. 14429–14460. PMLR (2022) 1, 13

--- TRANG 15 ---
DiS 15
42. Lu, C., Zhou, Y., Bao, F., Chen, J., Li, C., Zhu, J.: Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps. Advances in Neural Information Processing Systems 35, 5775–5787 (2022) 1, 13
43. Ma, X., Zhou, C., Kong, X., He, J., Gui, L., Neubig, G., May, J., Zettlemoyer, L.: Mega: moving average equipped gated attention. arXiv preprint arXiv:2209.10655 (2022) 12, 13
44. Mehta, H., Gupta, A., Cutkosky, A., Neyshabur, B.: Long range language modeling via gated state spaces. arXiv preprint arXiv:2206.13947 (2022) 12
45. Mei, K., Patel, V.: Vidm: Video implicit diffusion models. In: Proceedings of the AAAI Conference on Artificial Intelligence. vol. 37, pp. 9117–9125 (2023) 1
46. Müller, N., Siddiqui, Y., Porzi, L., Bulo, S.R., Kontschieder, P., Nießner, M.: Diffrf: Rendering-guided 3d radiance field diffusion. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4328–4338 (2023) 13
47. Nash, C., Menick, J., Dieleman, S., Battaglia, P.W.: Generating images with sparse representations. arXiv preprint arXiv:2103.03841 (2021) 8
48. Nichol, A.Q., Dhariwal, P.: Improved denoising diffusion probabilistic models. In: International Conference on Machine Learning. pp. 8162–8171. PMLR (2021) 13
49. Orvieto, A., Smith, S.L., Gu, A., Fernando, A., Gulcehre, C., Pascanu, R., De, S.: Resurrecting recurrent neural networks for long sequences. arXiv preprint arXiv:2303.06349 (2023) 2
50. Parmar, G., Zhang, R., Zhu, J.Y.: On aliased resizing and surprising subtleties in gan evaluation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 11410–11420 (2022) 7
51. Peebles, W., Xie, S.: Scalable diffusion models with transformers. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 4195–4205 (2023) 2, 6, 7, 10, 11
52. Poole, B., Jain, A., Barron, J.T., Mildenhall, B.: Dreamfusion: Text-to-3d using 2d diffusion. arXiv preprint arXiv:2209.14988 (2022) 1
53. Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., Chen, M.: Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:2204.06125 1(2), 3 (2022) 1, 2, 3, 13
54. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent diffusion models. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 10684–10695 (2022) 1, 2, 7, 10, 13
55. Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E.L., Ghasemipour, K., Gontijo Lopes, R., Karagol Ayan, B., Salimans, T., et al.: Photorealistic text-to-image diffusion models with deep language understanding. Advances in Neural Information Processing Systems 35, 36479–36494 (2022) 1, 2, 13
56. Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen, X.: Improved techniques for training gans. Advances in neural information processing systems29(2016) 8
57. Sauer, A., Schwarz, K., Geiger, A.: Stylegan-xl: Scaling stylegan to large diverse datasets. In: ACM SIGGRAPH 2022 conference proceedings. pp. 1–10 (2022) 10, 11
58. Singer, U., Polyak, A., Hayes, T., Yin, X., An, J., Zhang, S., Hu, Q., Yang, H., Ashual, O., Gafni, O., et al.: Make-a-video: Text-to-video generation without text-video data. arXiv preprint arXiv:2209.14792 (2022) 13
59. Smith, J.T., Warrington, A., Linderman, S.W.: Simplified state space layers for sequence modeling. arXiv preprint arXiv:2208.04933 (2022) 2, 12

--- TRANG 16 ---
DiS 16
60. Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., Ganguli, S.: Deep unsupervised learning using nonequilibrium thermodynamics. In: International conference on machine learning. pp. 2256–2265. PMLR (2015) 1, 3, 13
61. Song, J., Meng, C., Ermon, S.: Denoising diffusion implicit models. arXiv preprint arXiv:2010.02502 (2020) 9, 13
62. Song, Y., Durkan, C., Murray, I., Ermon, S.: Maximum likelihood training of score-based diffusion models. Advances in Neural Information Processing Systems 34, 1415–1428 (2021) 1
63. Song, Y., Ermon, S.: Generative modeling by estimating gradients of the data distribution. Advances in neural information processing systems 32(2019) 1
64. Song,Y.,Sohl-Dickstein,J.,Kingma,D.P.,Kumar,A.,Ermon,S.,Poole,B.:Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456 (2020) 1
65. Tevet, G., Raab, S., Gordon, B., Shafir, Y., Cohen-Or, D., Bermano, A.H.: Human motion diffusion model. arXiv preprint arXiv:2209.14916 (2022) 13
66. Vahdat, A., Kreis, K., Kautz, J.: Score-based generative modeling in latent space. Advances in Neural Information Processing Systems 34, 11287–11302 (2021) 1
67. Yan, J.N., Gu, J., Rush, A.M.: Diffusion models without attention. arXiv preprint arXiv:2311.18257 (2023) 13
68. Yang, X., Shih, S.M., Fu, Y., Zhao, X., Ji, S.: Your vit is secretly a hybrid discriminative-generative diffusion model. arXiv preprint arXiv:2208.07791 (2022) 2, 9
69. Yuan, Y., Song, J., Iqbal, U., Vahdat, A., Kautz, J.: Physdiff: Physics-guided human motion diffusion model. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 16010–16021 (2023) 13
70. Zhang, L., Rao, A., Agrawala, M.: Adding conditional control to text-to-image diffusion models. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 3836–3847 (2023) 1
71. Zhao, M., Bao, F., Li, C., Zhu, J.: Egsde: Unpaired image-to-image translation via energy-guided stochastic differential equations. Advances in Neural Information Processing Systems 35, 3609–3623 (2022) 1
72. Zhou, Z., Tulsiani, S.: Sparsefusion: Distilling view-conditioned diffusion for 3d reconstruction. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 12588–12597 (2023) 1
73. Zhu,L.,Liao,B.,Zhang,Q.,Wang,X.,Liu,W.,Wang,X.:Visionmamba:Efficient visual representation learning with bidirectional state space model. arXiv preprint arXiv:2401.09417 (2024) 4, 5

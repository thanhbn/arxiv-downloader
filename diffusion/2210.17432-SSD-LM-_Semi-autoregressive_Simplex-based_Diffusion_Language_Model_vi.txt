# SSD-LM: Mô hình Ngôn ngữ Khuếch tán Simplex-based Bán tự động hồi quy cho Tạo văn bản và Kiểm soát Mô-đun

Xiaochuang Han♠Sachin Kumar♣Yulia Tsvetkov♠
♠Trường Khoa học Máy tính & Kỹ thuật Paul G. Allen, Đại học Washington
♣Viện Công nghệ Ngôn ngữ, Đại học Carnegie Mellon
{xhan77, yuliats}@cs.washington.edu♠sachink@cs.cmu.edu♣

## Tóm tắt

Mặc dù thành công ngày càng tăng của các mô hình khuếch tán trong các miền có giá trị liên tục (ví dụ, hình ảnh), những nỗ lực tương tự cho các miền rời rạc như văn bản vẫn chưa thể sánh được với hiệu suất của các mô hình ngôn ngữ tự động hồi quy. Trong công trình này, chúng tôi giới thiệu SSD-LM - một mô hình ngôn ngữ dựa trên khuếch tán với hai lựa chọn thiết kế chính. Thứ nhất, SSD-LM là bán tự động hồi quy, lặp lại tạo ra các khối văn bản, cho phép độ dài đầu ra linh hoạt tại thời điểm giải mã đồng thời cho phép cập nhật ngữ cảnh hai chiều cục bộ. Thứ hai, nó dựa trên simplex, thực hiện khuếch tán trên không gian từ vựng tự nhiên thay vì không gian tiềm ẩn đã học, cho phép chúng tôi kết hợp hướng dẫn phân loại và kiểm soát mô-đun bằng cách sử dụng các bộ phân loại sẵn có mà không cần bất kỳ thích ứng nào. Chúng tôi đánh giá SSD-LM trên các điểm chuẩn tạo văn bản không hạn chế và cho thấy nó sánh được hoặc vượt trội so với các mô hình GPT-2 tự động hồi quy mạnh mẽ trên các chỉ số chất lượng và đa dạng chuẩn, đồng thời vượt trội hơn hẳn so với các đường cơ sở dựa trên khuếch tán. Trong việc tạo văn bản có kiểm soát, SSD-LM cũng vượt trội so với các đường cơ sở cạnh tranh, với lợi thế bổ sung về tính mô-đun.

## 1 Giới thiệu

Các mô hình khuếch tán (Sohl-Dickstein et al., 2015), được huấn luyện để lặp lại cải thiện các đầu vào có nhiễu, gần đây đã nổi lên như những công cụ mạnh mẽ cho mô hình tạo sinh trong một số miền có giá trị liên tục như hình ảnh (Ho et al., 2020), âm thanh (Kong et al., 2021), video (Ho et al., 2022), trong số những miền khác. Tuy nhiên, những nỗ lực thích ứng chúng cho các miền rời rạc như dữ liệu văn bản chỉ có thành công hạn chế: các công trình trước đây đã chỉ ra là triển vọng trong các trường hợp chuyên biệt và tập dữ liệu nhỏ (Hoogeboom et al., 2021; Austin et al., 2021; Li et al., 2022; Chen et al., 2022), nhưng các mô hình khuếch tán cho văn bản vẫn hoạt động kém hơn (và do đó không được áp dụng rộng rãi) so với các mô hình ngôn ngữ tự động hồi quy (AR-LMs) vẫn là những máy tạo văn bản đa năng tiên tiến nhất (Radford et al., 2019; Brown et al., 2020).

Mặc dù có những lợi thế tiềm năng của các mô hình khuếch tán cho văn bản, có hai thách thức chính. Thứ nhất, các mô hình khuếch tán tạo văn bản không tự động hồi quy, tức là chúng tạo ra (và cập nhật) toàn bộ chuỗi đồng thời thay vì từng token từ trái sang phải. Mặc dù tính chất này hữu ích trong thực tế vì mỗi token đầu ra được thông báo bởi ngữ cảnh hai chiều rộng hơn (Lee et al., 2018; Ghazvininejad et al., 2019), nó đòi hỏi phải định trước độ dài chuỗi đầu ra. Điều này hạn chế tính linh hoạt và khả năng ứng dụng của các mô hình đã huấn luyện. Mặt khác, huấn luyện không tự động hồi quy với các chuỗi dài tốn kém và khó tối ưu hóa. Trong công trình này, chúng tôi đề xuất một giải pháp bán tự động hồi quy cân bằng giữa tính linh hoạt về độ dài và khả năng thay đổi các token đã tạo trước đó.

Một lợi thế lớn của các mô hình khuếch tán so với tiêu chuẩn hiện tại của AR-LMs là khả năng kiểm soát hậu hoc của chúng bằng cách sử dụng hướng dẫn từ các mô hình phụ trợ như bộ phân loại kiểu cách (Dhariwal và Nichol, 2021). Tuy nhiên, khả năng kiểm soát khó đạt được mà không có sự thỏa hiệp về tính mô-đun trong các LM dựa trên khuếch tán cho văn bản. Để cho phép tạo sinh khuếch tán thành văn bản rời rạc thay vì các phương thức liên tục, các phương pháp trước đây đã sử dụng các xấp xỉ khác nhau, ví dụ, huấn luyện với embeddings, ký tự, hoặc phương pháp cấp byte (Li et al., 2022; Hoogeboom et al., 2021; Austin et al., 2021; Chen et al., 2022). Ngược lại, các LM chính thống hiện có và các bộ phân loại hướng dẫn chúng tạo ra thường hoạt động ở cấp độ từ phụ với các biểu diễn từ phụ được huấn luyện cùng với mô hình ngôn ngữ (Devlin et al., 2019; Liu et al., 2019; Raffel et al., 2020). Sau đó, việc thay đổi biểu diễn đầu vào thành ký tự hoặc embeddings đòi hỏi phải phát triển các mô hình hướng dẫn từ đầu, điều này có thể tốn kém hoặc không khả thi trong nhiều trường hợp. Trong công trình này, chúng tôi đề xuất một giải pháp dựa trên simplex cho phép khuếch tán trên văn bản rời rạc trong khi vẫn duy trì những lợi thế của các mô hình khuếch tán với các mô hình hướng dẫn kiểm soát cắm và chơi.

Tóm lại, để cho phép các LM dựa trên khuếch tán cho văn bản, chúng tôi trình bày SSD-LM (§3), giải quyết hai thách thức trên. SSD-LM được huấn luyện để tạo văn bản bán tự động hồi quy - tạo ra các khối token từ trái sang phải với ngữ cảnh hai chiều trong khối - mang lại lợi ích của cả AR-LMs và các mô hình khuếch tán. Nó hỗ trợ huấn luyện với và tạo ra các chuỗi có độ dài thay đổi. Đồng thời, nó cho phép tinh chỉnh trong khối token, trái ngược với việc giải mã tự động hồi quy cấp độ token nơi các token đã tạo trước đó hoàn toàn không thể sửa đổi. SSD-LM sử dụng cùng một tokenization như các AR-LM phổ biến, biểu diễn văn bản rời rạc thông qua một phân phối (hoặc simplex) được định nghĩa trên từ vựng và được huấn luyện để tái tạo văn bản từ các phiên bản nhiễu của các phân phối. Do biểu diễn cơ bản của nó, phương pháp của chúng tôi cũng cung cấp một cách dễ dàng và mô-đun để tạo sinh có hướng dẫn (có kiểm soát) bằng cách sử dụng các bộ phân loại văn bản sẵn có dưới giả định tối thiểu về tokenizer chung.

Các thí nghiệm đánh giá của chúng tôi cho thấy, lần đầu tiên, rằng một LM dựa trên khuếch tán sánh được hoặc vượt trội so với các AR-LM mạnh mẽ trên các điểm chuẩn tạo văn bản tiêu chuẩn (§4). Chúng tôi đánh giá SSD-LM trên hai nhiệm vụ: (1) tạo sinh dựa trên gợi ý không hạn chế vượt trội đáng kể so với các phương pháp LM khuếch tán hiện có và hoạt động ngang bằng với hoặc vượt trội so với LM tự động hồi quy mạnh mẽ GPT-2 (Radford et al., 2019) trên cả chất lượng và đa dạng (§4.2); và (2) tạo văn bản có kiểm soát với hướng dẫn từ các bộ phân loại sẵn có (không cần huấn luyện/thích ứng hậu hoc) vượt trội so với các đường cơ sở tạo văn bản có kiểm soát cạnh tranh (§4.3).

## 2 Nền tảng

### 2.1 Mô hình khuếch tán

Kể từ khi ra đời với tư cách là máy tạo hình ảnh, các mô hình khuếch tán (và các mô hình dựa trên điểm số anh em của chúng (Song và Ermon, 2019)) đã được áp dụng rộng rãi như các mô hình tạo sinh chất lượng cao cho nhiều phương thức dữ liệu. Ở đây, chúng tôi mô tả ngắn gọn một góc nhìn đơn giản hóa về một phương pháp chuẩn, các mô hình xác suất khuếch tán khử nhiễu (Ho et al., 2020, DDPM) mà chúng tôi thích ứng trong công trình này cho tạo văn bản. Chúng tôi giả sử một tập dữ liệu cho trước D = {1x0, ..., Nx0} của các mục có giá trị liên tục ix0 (ví dụ, giá trị pixel của một hình ảnh) từ đây được gọi là x0 cho đơn giản.

**Huấn luyện** Huấn luyện một mô hình khuếch tán đầu tiên bao gồm việc thêm một loạt nhiễu Gaussian vào dữ liệu gốc x0, thông qua T bước thời gian:

xt = √α̅t x0 + √(1-α̅t) εt     (1)

trong đó t ∈ (1, T) và εt ∼ N(0,I). α̅t = ∏(t'=1 to t) αt', trong đó αt' tuân theo một lịch trình định trước sao cho α̅t → 0 khi t → T. Quá trình này được gọi là khuếch tán tiến. Một mô hình khuếch tán (được tham số hóa bởi θ) được huấn luyện để đảo ngược quá trình tiến này bằng cách dự đoán nhiễu đã thêm εt cho trước xt với hàm mất mát sau:

L(θ) = Et∼U(1,T)[||εθ(xt, t) - εt||²]     (2)

**Suy luận** Để có được đầu ra từ mô hình này, chúng ta lấy mẫu xT ∼ N(0,I) và lặp lại tái tạo một mẫu x0 bằng cách quay ngược thời gian,

xt-1 = (1/√αt)(xt - (1-αt)/√(1-α̅t) εθ(xt, t))     (3)

cho t = T, ..., 1. Trở ngại chính trong việc sử dụng các mô hình khuếch tán vanilla trực tiếp như máy tạo văn bản là ngôn ngữ bao gồm các token rời rạc, tức là một x0 không liên tục mà nhiễu Gaussian có giá trị liên tục không thể được thêm vào. Chúng tôi đề xuất một giải pháp đơn giản và hiệu quả bằng cách coi các token như các simplex có giá trị liên tục trên từ vựng (Hoang et al., 2017). Các phương pháp hiện có khác giải quyết vấn đề này được thảo luận trong §5.

### 2.2 LM tự động hồi quy

Một mô hình AR-LM tối ưu hóa cho khả năng xảy ra của một chuỗi token w0, ..., wL-1.

pθ(w0:L) = ∏(c=0 to L-1) pθ(wc|w<c)     (4)

Để giải mã từ AR-LMs, ta có thể cung cấp một ngữ cảnh w<c và giải mã token tiếp theo wc một cách lặp lại bằng cách dự đoán pθ(wc|w<c) và lấy mẫu từ nó để có được token rời rạc (Fan et al., 2018; Holtzman et al., 2020). Các công trình trước đây đã chỉ ra rằng những phương pháp giải mã này (và mở rộng ra các LM bản thân chúng) dễ bị suy giảm khi tạo ra các chuỗi dài và thường chuyển thành việc lặp lại các chuỗi con (Holtzman et al., 2020; Meister et al., 2022). Ngoài ra, các LM như vậy không cung cấp cách tự nhiên để kết hợp kiểm soát cấp chuỗi vì các token được tạo ra từng cái một mà không có khả năng sửa đổi các token đã tạo trước đó (Dathathri et al., 2020; Kumar et al., 2022b). Trong công trình này, chúng tôi trình bày một phương pháp để huấn luyện một LM bán tự động hồi quy giải mã từng khối B token một lần, giảm thiểu các vấn đề đã nêu với sự hỗ trợ của các mô hình khuếch tán. Tài liệu hiện có giải quyết riêng lẻ hai vấn đề được thảo luận trong §5.

## 3 SSD-LM

Chúng tôi giới thiệu SSD-LM - Semi-autoregressive Simplex-based Diffusion Language Model - thích ứng các thành phần chính từ cả LM tự động hồi quy và các mô hình khuếch tán vanilla. Về mặt khái niệm, SSD-LM sử dụng mô hình khuếch tán để giải mã wc:c+B, một khối token có độ dài B, cho trước một nhiễu Gaussian và một ngữ cảnh w<c có độ dài c. Chúng tôi hiển thị một sơ đồ trực quan và mã giả cho thuật toán huấn luyện và giải mã của SSD-LM trong Hình 1, Hình 2 và Hình 3.

### 3.1 Huấn luyện

**Biểu diễn dữ liệu liên tục** Để xây dựng một biểu diễn liên tục cho các token rời rạc, chúng tôi áp dụng biểu diễn simplex gần như one-hot trên từ vựng V của mô hình. Chúng tôi định nghĩa một phép toán đơn giản logits-generation(.) để ánh xạ một token w thành w̃ ∈ {-K, +K}|V| như sau:

w̃(i) = {
  +K khi w = V(i)
  -K khi w ≠ V(i)
}     (5)

trong đó i là chỉ số của từ vựng. Chúng tôi gọi w̃ là logits cho token w, và softmax(w̃) cho một simplex xác suất trên từ vựng V, với một khối lượng xác suất tập trung vào token w. Không có tham số có thể học được trong ánh xạ này.

**Khuếch tán tiến** Theo Ho et al. (2020), chúng tôi thêm một nhiễu Gaussian phụ thuộc thời gian vào logits.

w̃c:c+B_0 = logits-generation(wc:c+B)     (6)
w̃c:c+B_t = √α̅t w̃c:c+B_0 + √(1-α̅t) εt     (7)

trong đó t ∈ (1, T), εt ∼ N(0, K²I), và α̅t → 0 khi t → T. Ở bước cuối cùng T, softmax(w̃c:c+B_T) là các simplex hoàn toàn nhiễu trên V, với một phân phối logit-normal (Atchison và Shen, 1980).

**Hàm mất mát** Trong Eq. 2, một mô hình khuếch tán được huấn luyện để dự đoán nhiễu đã thêm từ các biểu diễn nhiễu. Vì quá trình khuếch tán tiến có thể được tính toán trong một bước duy nhất (Eq. 1), khái niệm ở đây tương đương với việc dự đoán biểu diễn dữ liệu gốc (Song et al., 2021; Li et al., 2022). Mục tiêu của chúng tôi tuân theo cùng một trực giác nhưng ước tính một khả năng thay vì khoảng cách L2 trong khi điều kiện hóa trên ngữ cảnh bổ sung:

L(θ) = E[-log pθ(wc:c+B|w̃c:c+B_t, w<c)]     (8)
     = E[∑(j=c to c+B-1) -log pθ(wj|w̃c:c+B_t, w<c)]     (9)

E[·] là viết tắt cho Ec∼U(1,L-B),t∼U(1,T)[·]. Kiến trúc cho θ xuyên suốt công trình này là một bộ mã hóa Transformer hai chiều (Vaswani et al., 2017). Cụ thể, đầu vào cho mô hình là một sự nối của ngữ cảnh w<c và một chuỗi các simplex từ vựng nhiễu softmax(w̃c:c+B_t) có độ dài B. Đầu ra đích là các token gốc wc:c+B tại các vị trí c đến c+B.

Một sửa đổi tối thiểu được thực hiện cho mô hình Transformer là ngoài việc tra cứu embedding thông thường cho w<c, chúng tôi sửa đổi lớp embedding để lấy làm đầu vào một phân phối trên từ vựng, softmax(w̃c:c+B_t), và tính toán vector embedding như một tổng có trọng số của bảng embedding. Một embedding timestep cũng được thêm vào trước khối Transformer đầu tiên để thông báo cho mô hình về timestep hiện tại.

Trong §A, chúng tôi trình bày một cách hiểu khác về mục tiêu huấn luyện như một hàm mất mát contrastive trực quan.

### 3.2 Giải mã

**Phép chiếu logits** Tương tự như các mô hình khuếch tán có giá trị liên tục, việc lấy mẫu từ SSD-LM bao gồm khuếch tán ngược từ t = T, ..., 1 bắt đầu với một nhiễu Gaussian. Tại bất kỳ timestep t nào, mô hình θ của chúng tôi lấy làm đầu vào logits nhiễu w̃c:c+B_t và ước tính phân phối xác suất của các token gốc trong dữ liệu bằng cách đầu tiên dự đoán logits:

wc:c+B_logits,t = logitsθ(wc:c+B|w̃c:c+B_t, w<c)     (10)

sau đó được chuyển đổi thành một phân phối thông qua softmax. Để đưa đầu ra này vào bước tiếp theo của khuếch tán ngược, t-1, chúng tôi định nghĩa một phép toán logits-projection để xây dựng một biểu diễn dữ liệu dự đoán gần với biểu diễn dữ liệu ban đầu (ánh xạ gần như one-hot; Eq. 5). Chúng tôi xem xét ba phép toán chiếu.

• **Greedy**: tạo ra một logit gần như one-hot tập trung tại token có xác suất cao nhất.

ŵ(i) = {
  +K nếu i = argmax(wlogits)
  -K khác
}     (11)

• **Sampling**: tạo ra một logit gần như one-hot tập trung xung quanh một token được lấy mẫu từ phân phối đầu ra bằng top-p sampling (Holtzman et al., 2020). p là một siêu tham số.

ŵ(i) = {
  +K nếu i = top-p-sample(wlogits)
  -K khác
}     (12)

• **Multi-hot**: tạo ra một logit gần như one-hot tập trung xung quanh tất cả các token trong nucleus top-p.

ŵ(i) = {
  +K nếu i ∈ top-p-all(wlogits)
  -K khác
}     (13)

**Lặp giải mã** Bắt đầu từ nhiễu thuần túy w̃c:c+B_T ∼ N(0, K²I), trong mỗi timestep giải mã chúng ta tính toán:

ŵc:c+B_t = logits-projection(wc:c+B_logits,t)     (14)
w̃c:c+B_t-1 = √α̅t-1 ŵc:c+B_t + √(1-α̅t-1) z     (15)

cho t = T, ..., 1 và z ∼ N(0, K²I).

Tại t = 1, khối B-token cuối cùng được tính toán đơn giản là argmax w̃c:c+B_0. Để tạo ra khối tiếp theo, chúng ta nối khối đã tạo với ngữ cảnh trước đó để tạo ra một ngữ cảnh mới có độ dài c+B và tuân theo quá trình khuếch tán ngược một lần nữa như được mô tả ở trên. Quá trình này có thể được lặp lại cho đến khi đạt được độ dài tối đa mong muốn.

Đáng chú ý rằng thuật toán giải mã đề xuất của chúng tôi là mới và khác với việc giải mã DDPM (Eq. 3). Việc giải mã DDPM được thiết kế cho khuếch tán trong không gian liên tục và thất bại trong việc tạo ra đầu ra có ý nghĩa trong các thí nghiệm sơ bộ của chúng tôi dựa trên simplex. Trong §B, chúng tôi vẽ một kết nối lý thuyết giữa thuật toán giải mã của chúng tôi và việc giải mã DDPM, và cũng nhấn mạnh sự khác biệt trực quan giữa hai phương pháp.

**Kiểm soát có tính mô-đun cao** Một tính chất hữu ích của các mô hình khuếch tán liên tục tự nhiên phát sinh từ định nghĩa của chúng là khả năng hướng dẫn các mẫu được tạo ra để có các thuộc tính do người dùng định nghĩa tại thời điểm thử nghiệm. Điều này có thể được thực hiện bằng cách sử dụng gradients từ các mô hình phụ trợ như bộ phân loại (Dhariwal và Nichol, 2021), ví dụ, hướng dẫn đầu ra của một LM để có cảm xúc tích cực bằng cách sử dụng một bộ phân loại cảm xúc. Có một cộng đồng sôi động của các nhà phát triển trên các nền tảng như HuggingFace nơi nhiều bộ phân loại văn bản như vậy có sẵn công khai. Biểu diễn dữ liệu cơ bản của SSD-LM dựa trên simplex từ vựng. Do đó, miễn là một bộ phân loại chia sẻ cùng tokenizer với LM, nó có thể được sử dụng để kiểm soát theo cách sẵn có mà không cần sửa đổi. Điều này trái ngược với các công trình trước đây trong các mô hình ngôn ngữ khuếch tán không hỗ trợ các bộ phân loại như vậy do sự khác biệt trong không gian biểu diễn đầu vào của chúng (Hoogeboom et al., 2021; Austin et al., 2021; Li et al., 2022; Chen et al., 2022) và yêu cầu huấn luyện lại các bộ phân loại từ đầu. Khả năng này làm cho SSD-LM có tính mô-đun cao cho việc tạo văn bản có kiểm soát và mang lại những lợi ích chính: (1) Huấn luyện các bộ phân loại chính xác cho nhiều nhiệm vụ đòi hỏi lượng lớn dữ liệu nơi việc huấn luyện lại chúng có thể khá tốn kém, và (2) phương pháp này cho phép kiểm soát từ các bộ phân loại mở để sử dụng nhưng đã được huấn luyện trên dữ liệu nguồn đóng.

Để hướng dẫn SSD-LM tạo ra văn bản với thuộc tính mục tiêu y thông qua một mô hình thuộc tính độc lập fϕ(·), chúng tôi cập nhật wc:c+B_logits,t (Eq. 10) tại mỗi timestep t thành dạng dưới đây, trôi theo các gradient từ bộ phân loại thuộc tính.

wc:c+B_logits,t + λ∇wc:c+B_logits,t fϕ(y|wc:c+B_logits,t, w<c)     (16)

trong đó λ là một siêu tham số cân bằng trọng số của việc kiểm soát. Các tham số của mô hình thuộc tính độc lập ϕ được đóng băng. Chúng tôi thực hiện một sửa đổi nhỏ cho việc tính toán embedding như trong §3.1, để cho phép bộ phân loại lấy làm đầu vào một simplex.

### 3.3 Chi tiết bổ sung

**Hệ số khuếch tán tiến α̅t** Chúng tôi tuân theo Nichol và Dhariwal (2021) cho một lịch trình cosine của α̅t:

α̅t = r(t)/r(0), r(t) = cos((t/T + s)/(1 + s) · π/2)²     (17)

trong đó s là offset nhỏ được đặt là 1e-4 trong công trình của chúng tôi và αt = α̅t/α̅t-1.

**Ít timestep T hơn trong giải mã** Việc giải mã từ các mô hình khuếch tán đòi hỏi một loạt timestep (T) có thể tốn kém về mặt tính toán nếu T lớn. Theo Li et al. (2022), chúng tôi xem xét việc sử dụng một giá trị T nhỏ hơn tại thời điểm thử nghiệm để cải thiện tốc độ giải mã. Trong công trình này, chúng tôi chủ yếu thí nghiệm với Tdecode = Ttrain/2 và Tdecode = Ttrain/5.

**Kích thước khối giải mã linh hoạt B** SSD-LM của chúng tôi được huấn luyện với kích thước khối token cố định Btrain. Tuy nhiên, thuật toán giải mã có quyền tự do sử dụng một Bdecode khác. Trong các thí nghiệm của chúng tôi, chúng tôi xem xét cả hai kịch bản Btrain = Bdecode và Btrain ≠ Bdecode. Tuy nhiên, chúng tôi để lại cho công trình tương lai một phân tích chi tiết hơn về tác động của sự khác biệt giữa Btrain và Bdecode đối với hiệu suất mô hình.

## 4 Thí nghiệm

### 4.1 Thiết lập huấn luyện trước SSD-LM

**Kiến trúc mô hình** Chúng tôi sử dụng một bộ mã hóa Transformer hai chiều RoBERTa-large (Liu et al., 2019) (0.4B, kích thước tương đương với GPT2-medium) làm kiến trúc cơ bản của SSD-LM. Lưu ý rằng RoBERTa sử dụng tokenization BPE tổng quát (Sennrich et al., 2016), giống như nhiều LM khác như GPT-2 (Radford et al., 2019), GPT-3 (Brown et al., 2020), OPT (Zhang et al., 2022), v.v. Bất kỳ bộ phân loại thuộc tính nào sử dụng cùng chiến lược tokenization đều có thể được sử dụng để kiểm soát SSD-LM theo cách có tính mô-đun cao.

**Dữ liệu huấn luyện trước, hằng số và tài nguyên** Chúng tôi huấn luyện SSD-LM trên cùng dữ liệu với GPT2 để có thể so sánh công bằng: OpenWebText (Gokaslan và Cohen, 2019) chứa 9B token. Theo Zhang et al. (2022), chúng tôi xem xét dữ liệu này như một chuỗi token liên tục duy nhất và chia nó thành các chuỗi có độ dài 200 (giống như độ dài chuỗi tối đa mà mô hình của chúng tôi chấp nhận). Chúng tôi ngẫu nhiên lấy mẫu 99% các chuỗi này để huấn luyện trước trong khi để lại phần còn lại để đánh giá. Chúng tôi sử dụng các siêu tham số mô hình sau:

L = 200, Btrain = 25, Ttrain = 5000, K = 5

Chúng tôi sử dụng kích thước batch tổng hợp là 6,144 và tốc độ học 1e-4 với bộ tối ưu hóa AdamW (Loshchilov và Hutter, 2019). Chúng tôi huấn luyện SSD-LM trong 100K bước, mất khoảng 6 ngày trên 32 GPU Nvidia V100.

**Mất mát huấn luyện trước** Perplexity thời gian huấn luyện chuẩn của các LM không tương thích với các LM khuếch tán do sự khác biệt trong các đầu vào cho các mô hình (Eq. 4 và Eq. 9). Mất mát huấn luyện trước của chúng tôi là một negative log-likelihood (NLL) per-token phụ thuộc vào lịch trình nhiễu cụ thể được sử dụng. SSD-LM đạt được NLL trung bình là 3.87 khi kết thúc huấn luyện trước. Chúng tôi hiển thị đường cong mất mát huấn luyện trước trong phụ lục (§D).

### 4.2 Tạo văn bản không hạn chế

**Thiết lập** Đầu tiên, chúng tôi đánh giá SSD-LM với các LM tự động hồi quy được huấn luyện trên cùng dữ liệu (GPT2) về chất lượng tạo văn bản. Chúng tôi ngẫu nhiên lấy mẫu 1000 chuỗi từ dữ liệu thử nghiệm OpenWebText được tách ra, trích xuất các tiền tố của chúng làm gợi ý (ngữ cảnh), và tạo ra các phần tiếp theo từ các LM. Chúng tôi xem xét ba thiết lập: với độ dài gợi ý 25, 50 và 100 với độ dài đầu ra tương ứng là 25, 50 và 100 token. Trong mỗi thiết lập, chúng tôi lấy mẫu 5 phần tiếp theo cho mỗi ngữ cảnh đầu vào, do đó so sánh chất lượng của 5,000 thế hệ từ các mô hình GPT-2 cơ sở và SSD-LM của chúng tôi.

Chúng tôi so sánh SSD-LM với các mô hình GPT2-medium, large và xl (chứa 0.4B, 0.8B và 1.6B tham số tương ứng) làm đường cơ sở. Để tham khảo, kích thước mô hình của chúng tôi có thể so sánh với GPT2-medium. Chúng tôi thí nghiệm với hai chiến lược giải mã phổ biến cho các mô hình GPT-2 cơ sở với các tham số chuẩn: nucleus sampling (Holtzman et al., 2020) với top-p là 0.9 và 0.95, và typical sampling (Meister et al., 2022) với typical-τ là 0.2 và 0.95.

Đối với SSD-LM, chúng tôi xem xét ba chiến lược chiếu logits, sampling và multi-hot với top-p ∈ {0.0, 0.1, 0.2, 0.5, 0.7, 0.9, 0.95, 0.99}, và greedy (về mặt chức năng tương đương với sampling với top-p = 0). Chúng tôi sử dụng kích thước khối thử nghiệm (Bdecode) là 25. Khi tạo ra các mẫu có độ dài 50 hoặc 100, chúng tôi lấy mẫu bán tự động hồi quy theo khối 25 và đưa chúng làm ngữ cảnh bổ sung để tạo ra khối tiếp theo như được mô tả trong §3.2.

Chúng tôi đánh giá các phần tiếp theo được tạo ra trên hai trục: chất lượng và đa dạng. Làm chỉ số chất lượng tự động, chúng tôi báo cáo perplexity được đo bởi một mô hình ngôn ngữ riêng biệt, lớn hơn (GPT-Neo-1.3B, Black et al., 2021). Tuy nhiên, các công trình trước đây đã chỉ ra rằng perplexity thấp của văn bản được tạo ra không nhất thiết là dấu hiệu của chất lượng cao mà là của hành vi thoái hóa (Nadeem et al., 2020; Zhang et al., 2021) và đã đề xuất sự gần gũi với perplexity của văn bản do con người viết như một đánh giá tốt hơn. Do đó, chúng tôi cũng báo cáo sự khác biệt của log perplexity giữa văn bản được tạo ra và các phần tiếp theo do con người viết (|ΔlogPPL|). Để đánh giá đa dạng, chúng tôi báo cáo hệ số Zipf (Zipf) và distinct n-gram trung bình trong các mẫu đầu ra (Li et al., 2016, Dist-n). Ngoài ra, chúng tôi cũng báo cáo tỷ lệ lặp lại (Welleck et al., 2020; Holtzman et al., 2020, Rep), đo lường tỷ lệ các mẫu đầu ra kết thúc bằng các cụm từ lặp lại. Cuối cùng, chúng tôi báo cáo MAUVE (Pillutla et al., 2021) đánh giá cả chất lượng và đa dạng cùng nhau bằng cách xấp xỉ khoảng cách thông tin giữa các mẫu được tạo ra và các phần tiếp theo do con người viết (từ tập OpenWebText được tách ra).

**Kết quả** Bảng 1 tóm tắt kết quả chính của chúng tôi về thiết lập gợi ý và đầu ra 50-token. Chúng tôi báo cáo các số liệu cho ba thiết lập hoạt động tốt nhất cho chiếu logits và các bước giải mã T trong SSD-LM. Chúng tôi báo cáo thiết lập tốt nhất cho các đường cơ sở. Kết quả cho các độ dài tạo sinh khác có xu hướng tương tự và có thể được tìm thấy trong phụ lục (§D).

Chúng tôi thấy rằng SSD-LM, mặc dù có kích thước nhỏ hơn, vượt trội so với các mô hình GPT-2 lớn hơn trên chỉ số thống nhất MAUVE. Về đa dạng, SSD-LM vượt trội so với GPT-2 trong Dist-n trong khi đạt được tỷ lệ lặp lại thấp hơn. Về perplexity, kết quả hơi trộn lẫn. Chúng tôi quan sát một sự đánh đổi giữa MAUVE và perplexity cho các thiết lập khác nhau mà chúng tôi xem xét, cho thấy việc điều chỉnh thêm các siêu tham số có thể cần thiết. Tuy nhiên, một trong những thiết lập hoạt động tốt nhất của chúng tôi (sampling top-p = 0.9, T = 2500) vẫn đạt được perplexity gần nhất với phần tiếp theo vàng.

Trong §D, chúng tôi hiển thị ảnh hưởng của các chiến lược chiếu logits khác nhau và các tham số liên quan đến chất lượng văn bản đầu ra trong Hình 4. Chúng tôi cũng hiển thị các ví dụ định tính về các thế hệ của SSD-LM trong Bảng 8 và một quỹ đạo của các trạng thái trung gian trong quá trình giải mã trong Bảng 9.

**So sánh với Li et al. (2022)** Một công trình trước chúng tôi, Li et al. (2022) đề xuất Diffusion-LM, một mô hình khuếch tán dựa trên embedding được huấn luyện trên hai tập dữ liệu đồ chơi nhỏ, E2E (Novikova et al., 2017) và ROCStories (Mostafazadeh et al., 2016). Trong tiểu mục này, chúng tôi tạo ra một sự chuyển hướng để so sánh Diffusion-LM dựa trên embedding với SSD-LM dựa trên simplex, bán tự động hồi quy của chúng tôi. Theo Li et al. (2022), chúng tôi huấn luyện một Diffusion-LM trên ROCStories với kích thước embedding mặc định là 128, 0.1B tham số dưới cấu trúc BERT-base (Devlin et al., 2019), và độ dài chuỗi là 100. Để so sánh công bằng, chỉ trong tiểu mục này, chúng tôi huấn luyện một SSD-LM với các chuỗi ROCStories có 100 token, kích thước khối giải mã là 25, và khởi tạo BERT-base. Chi tiết thêm về thiết lập có thể được tìm thấy trong §C.

Trên 2,700 chuỗi ROCStories được tách ra, chúng tôi sử dụng 50 token đầu tiên của mỗi chuỗi làm gợi ý và yêu cầu mô hình tạo ra 50 token tiếp theo. Trong Bảng 2, chúng tôi hiển thị điểm MAUVE và perplexity của cả hai mô hình. Chúng tôi quan sát một điểm MAUVE cao hơn đáng kể và perplexity thấp hơn với SSD-LM.

### 4.3 Tạo văn bản có kiểm soát

**Thiết lập** Để đánh giá khả năng kiểm soát có tính mô-đun cao của SSD-LM, chúng tôi xem xét nhiệm vụ tạo sinh có kiểm soát cảm xúc nơi cho một gợi ý, mục tiêu là tạo ra một phần tiếp theo có cực tính tích cực (hoặc tiêu cực). Chúng tôi sử dụng một tập hợp 15 gợi ý ngắn như trong Dathathri et al. (2020) và tạo ra 20 mẫu cho mỗi gợi ý cho mỗi danh mục cảm xúc, làm cho tổng số mẫu được tạo ra là 600. Theo Mireshghallah et al. (2022), chúng tôi tạo ra các mẫu với 3 độ dài đầu ra khác nhau: 12, 20 và 50. Để hướng dẫn, chúng tôi đơn giản nhập một bộ phân loại cảm xúc phổ biến từ HuggingFace được huấn luyện với dữ liệu cảm xúc Twitter với hơn 58M ví dụ huấn luyện (Barbieri et al., 2020). Mô hình này phục vụ như fϕ(·) như được hiển thị trong Eq. 16. Ngoài chất lượng và đa dạng của các mẫu được tạo ra, chúng tôi cũng đánh giá chúng về kiểm soát (tức là đo lường nếu đầu ra được tạo ra thực sự tích cực hay tiêu cực về cực tính). Để làm điều này, chúng tôi sử dụng một bộ phân loại cảm xúc bên ngoài được huấn luyện trên một tập dữ liệu khác. Cụ thể, chúng tôi sử dụng một bộ phân loại được huấn luyện với đánh giá Yelp (Zhang et al., 2015; Morris et al., 2020) theo thiết lập đánh giá trong các đường cơ sở mà chúng tôi xem xét.

Một lần nữa, chúng tôi xem xét các chiến lược giải mã sampling và multi-hot với top-p ∈ {0.2, 0.5, 0.9}, Tdecode ∈ {1000, 2500, 5000}, và số nhân cho kiểm soát λ ∈ {0, 100, 500, 2000}. Để tạo ra 12/20/50 token, chúng tôi sử dụng Bdecode = 12/20/25 và áp dụng thuật toán giải mã cho m = 1/1/2 lần lặp tương ứng.

**Kết quả** Chúng tôi hiển thị chất lượng của các thế hệ có kiểm soát từ ba góc độ: thuộc tính mục tiêu thông qua độ chính xác của bộ phân loại bên ngoài, tính trôi chảy thông qua perplexity, và đa dạng thông qua các chỉ số đặc biệt. Trong Bảng 3, chúng tôi hiển thị kết quả thí nghiệm cho độ dài đầu ra 50. Kết quả ở độ dài 12 và 20 có xu hướng tương tự và có thể được tìm thấy trong phụ lục (§D).

Trong số các phương pháp cơ sở, DAPT (Gururangan et al., 2020), GeDi (Krause et al., 2021), và DExperts (Liu et al., 2021) đòi hỏi huấn luyện các mô hình ngôn ngữ tùy chỉnh biết về các thuộc tính mong muốn (được ký hiệu là CM trong Bảng 7). PPLM (Dathathri et al., 2020), FUDGE (Yang và Klein, 2021), và MuCoLa (Kumar et al., 2022b) đòi hỏi huấn luyện một bộ phân loại thuộc tính tùy chỉnh (CC). Trong khi phương pháp đề xuất SSD-LM và M&M LM (Mireshghallah et al., 2022) của chúng tôi có thể trực tiếp nhập các bộ phân loại thuộc tính chính thống hiện có từ các nền tảng như HuggingFace và do đó có tính mô-đun cao (HMC). Chúng tôi hiển thị kết quả cơ sở như được báo cáo trong Mireshghallah et al. (2022) và Kumar et al. (2022b).

SSD-LM cho thấy khả năng kiểm soát mạnh mẽ trong khi sở hữu tính mô-đun tuyệt vời. SSD-LM vượt trội so với M&M LM, phương pháp HMC khác với biên độ lớn. Ngay cả khi so sánh với các phương pháp CC và CM, phương pháp của chúng tôi đạt được sự cân bằng tốt trong kiểm soát, tính trôi chảy và đa dạng.

Trong §D, chúng tôi hiển thị tác động của trọng số kiểm soát λ và top-p đến độ chính xác thuộc tính và perplexity trong Hình 5. Chúng tôi cũng hiển thị các ví dụ định tính về các thế hệ có kiểm soát của SSD-LM trong Bảng 8.

## 5 Công trình liên quan

**Mô hình khuếch tán** Các mô hình khuếch tán đã chứng minh hiệu suất ấn tượng trong các miền có giá trị liên tục phổ biến như hình ảnh (Ho et al., 2020), âm thanh (Kong et al., 2021), video (Ho et al., 2022) và gần đây cũng được áp dụng cho hình dạng 3D, cấu trúc protein, và nhiều hơn nữa (Zhou et al., 2021; Trippe et al., 2022; Wu et al., 2022). Vì chúng dựa trên việc thêm nhiễu Gaussian, những phương pháp này không đơn giản để áp dụng cho các miền có giá trị rời rạc như văn bản. Hoogeboom et al. (2021); Austin et al. (2021) đề xuất khuếch tán trong không gian rời rạc bằng cách sử dụng các phân phối phân loại được sửa đổi bằng các ma trận chuyển tiếp. Tuy nhiên, những phương pháp này không hỗ trợ kiểm soát một cách đơn giản và cho kết quả tệ hơn so với các mô hình tự động hồi quy có thể so sánh được.

Li et al. (2022) đề xuất biểu diễn mỗi token như một embedding liên tục và áp dụng khuếch tán trong không gian embedding. Họ huấn luyện LM để tạo ra một chuỗi có độ dài cố định trong khi SSD-LM cho phép linh hoạt trong độ dài chuỗi được tạo ra bằng cách tạo ra theo khối. Hơn nữa, LM của họ được huấn luyện với các tập dữ liệu chuyên biệt và không được đánh giá so với các LM tự động hồi quy đa năng trong việc tạo văn bản không hạn chế. Phương pháp của họ hỗ trợ kiểm soát hậu hoc nhưng đòi hỏi huấn luyện một bộ phân loại thuộc tính tùy chỉnh, vì khuếch tán hoạt động trên không gian embedding đã học. Gong et al. (2022), một công trình đồng thời với chúng tôi, mở rộng Li et al. (2022) thành một thiết lập sequence-to-sequence với một phương pháp dựa trên embedding tương tự cơ bản. Công trình của chúng tôi liên quan gần nhất với Chen et al. (2022) chuyển đổi dữ liệu rời rạc thành một chuỗi bit và biểu diễn mỗi bit là +1 hoặc -1 chuyển đổi nó thành một miền có giá trị liên tục. Tuy nhiên, đối với dữ liệu văn bản, nó có thể dẫn đến các chuỗi cực kỳ dài khó tối ưu hóa. Trong công trình này, chúng tôi thay vào đó duy trì một từ vựng dựa trên từ phụ nhưng biểu diễn mỗi token như một chuỗi logits được định nghĩa thủ công.

**Mô hình ngôn ngữ** Phần lớn các mô hình ngôn ngữ hiện có cho việc tạo văn bản được huấn luyện tự động hồi quy, tức là chúng dự đoán token tiếp theo cho trước ngữ cảnh đã tạo trước đó. Mô hình này được mở rộng cả về kích thước mô hình và kích thước dữ liệu huấn luyện đã dẫn đến khả năng ấn tượng trên nhiều điểm chuẩn (Brown et al., 2020; Chowdhery et al., 2022). Tuy nhiên, chúng tạo ra văn bản từng token một lần không cung cấp kiểm soát linh hoạt đối với các thuộc tính của văn bản được tạo ra. Các mô hình không tự động hồi quy tạo ra toàn bộ chuỗi đầu ra cùng một lúc cũng đã được khám phá trong các công trình trước đây khác với các mô hình khuếch tán (Lee et al., 2018; Ghazvininejad et al., 2019). Tuy nhiên, chúng chủ yếu tập trung vào việc cải thiện hiệu quả giải mã và được áp dụng cho các nhiệm vụ chuyên biệt như dịch thuật (Gu et al., 2018; Kaiser et al., 2018; Wang et al., 2019) và chỉnh sửa văn bản (Gu et al., 2019). Nhiều công trình này có các quy trình lặp trong không gian rời rạc, với một số khám phá các biểu diễn liên tục (Ma et al., 2019; Lee et al., 2020). Để giải quyết sự suy giảm chất lượng với các phương pháp không tự động hồi quy so với các mô hình tự động hồi quy, các công trình trước đây cũng đã khám phá các phương pháp bán tự động hồi quy (Wang et al., 2018; Qi et al., 2021). Trong cùng tinh thần, công trình của chúng tôi tìm cách giải quyết những nhược điểm của các mô hình ngôn ngữ tự động hồi quy và các mô hình khuếch tán không tự động hồi quy với một giải pháp trung gian.

**Tạo văn bản có thể kiểm soát** Các giải pháp sớm để kiểm soát các thuộc tính của văn bản được tạo ra tập trung vào việc huấn luyện hoặc tinh chỉnh các AR-LM với các mã kiểm soát cụ thể (Keskar et al., 2019; Gururangan et al., 2020; Chan et al., 2021). Những phương pháp này khó mở rộng cho các kiểm soát mới vì nó đòi hỏi huấn luyện lại các mô hình. Các công trình gần đây hơn bao gồm các phương pháp giải mã từ các AR-LM đã huấn luyện trước mà không sửa đổi các mô hình, thông qua việc thay đổi phân phối xác suất đầu ra tại mỗi bước bằng cách sử dụng các mục tiêu kiểm soát khác nhau (Dathathri et al., 2020; Krause et al., 2021; Yang và Klein, 2021; Liu et al., 2021; Lu et al., 2021; Pascual et al., 2021). Tuy nhiên, những phương pháp này không cho phép sửa đổi một token khi nó đã được tạo ra và do đó không tối ưu cho các kiểm soát ở phạm vi của toàn bộ chuỗi. Liên quan chặt chẽ đến SSD-LM là Kumar et al. (2021); Qin et al. (2022); Kumar et al. (2022b), đề xuất các thuật toán giải mã dựa trên gradient từ các AR-LM. Chúng đòi hỏi tính toán một lần truyền ngược qua các LM cho mỗi lần lặp, một phép toán tốn kém. Ngược lại, SSD-LM với thiết lập bán tự động hồi quy của nó cho phép chỉnh sửa các token quá khứ thông qua khuếch tán. Ngoài ra, hầu hết các phương pháp này đòi hỏi huấn luyện các hàm kiểm soát từ đầu trong khi mô hình của chúng tôi cho phép sử dụng các bộ phân loại sẵn có. Mireshghallah et al. (2022) đề xuất một LM không tự động hồi quy dựa trên lấy mẫu Metropolis-Hastings. Nó cũng hỗ trợ các bộ phân loại sẵn có để kiểm soát, và chúng tôi do đó sử dụng nó như một đường cơ sở trực tiếp cho SSD-LM.

## 6 Kết luận

Chúng tôi trình bày SSD-LM, một mô hình ngôn ngữ khuếch tán bán tự động hồi quy được huấn luyện để khử nhiễu các simplex bị hỏng trên từ vựng đầu ra. So với các công trình trước đây trong khuếch tán dựa trên văn bản, SSD-LM cung cấp tính linh hoạt hơn trong độ dài đầu ra bằng cách tạo ra các khối văn bản và khả năng sử dụng các bộ phân loại thuộc tính sẵn có để kiểm soát mà không cần điều chỉnh bổ sung. Trong việc tạo văn bản không hạn chế, SSD-LM hoạt động ngang bằng với hoặc vượt trội so với các đường cơ sở tự động hồi quy mạnh mẽ và lớn hơn (GPT-2) trong chất lượng và đa dạng tạo sinh, đồng thời vượt trội hơn hẳn so với các đường cơ sở khuếch tán (Diffusion-LM). Trong việc tạo văn bản có kiểm soát, SSD-LM vượt trội so với các đường cơ sở trong khi sở hữu một thiết kế mô-đun dễ sử dụng. Chúng tôi tin rằng SSD-LM mở ra một hướng nghiên cứu thú vị cho tương lai trong việc tạo ngôn ngữ dựa trên khuếch tán linh hoạt và mô-đun.

## Hạn chế

**Hiệu quả mẫu** Trong các AR-LM, một mất mát NLL được tính toán tại thời gian huấn luyện cho mỗi token trong chuỗi có độ dài L (Eq. 4). Tuy nhiên, trong SSD-LM, mỗi lần một ví dụ huấn luyện trước được lấy mẫu, mất mát chỉ được tính toán trên B token (Eq. 9) dẫn đến hiệu quả mẫu thấp hơn so với AR-LM. Hướng tới việc cải thiện hiệu quả này, các công trình tương lai có thể khám phá các kiến trúc mô hình chuyên dụng cho khuếch tán bán tự động hồi quy thay vì bộ mã hóa Transformer vanilla mà chúng tôi sử dụng trong công trình này.

**Tốc độ giải mã** Vì mỗi khối được tạo ra bằng cách tinh chỉnh qua nhiều lần lặp, SSD-LM có tốc độ giải mã chậm hơn đáng kể so với các mô hình tự động hồi quy. Ví dụ, cho một ngữ cảnh 50 token (single instance, unbatched), SSD-LM mất 25 giây để tạo ra khối 25 token tiếp theo (Tdecode = 1000). Trong khi công trình của chúng tôi tập trung vào việc thiết lập hiệu quả của các LM dựa trên khuếch tán và tạo sinh có kiểm soát mô-đun, các công trình tương lai có thể khám phá việc điều chỉnh Tdecode để cân bằng hiệu suất mô hình và tốc độ giải mã, hoặc các thuật toán huấn luyện và giải mã hiệu quả hơn mở rộng ý tưởng từ các công trình trước đây về các mô hình khuếch tán cho các miền liên tục (Song et al., 2021; Nichol và Dhariwal, 2021; Rombach et al., 2022; Meng et al., 2022).

**Kích thước khối giải mã** Trong công trình này, mặc dù chúng tôi cho phép các thiết lập nơi Btrain ≠ Bdecode, kích thước khối giải mã Bdecode vẫn giữ nguyên qua m lần lặp giải mã, để lại không gian cho một lịch trình giải mã linh hoạt hơn. Các công trình tương lai cũng có thể khám phá việc học Bdecode (và Btrain) thay vì sử dụng các độ dài được định trước cố định.

Các thí nghiệm quy mô lớn hơn với các loại kiểm soát khác nhau và sự kết hợp của chúng có thể được thực hiện, cũng như các cách tinh vi hơn để kết hợp chúng (Kumar et al., 2021). Ngoài ra, chúng tôi dự định khám phá các phương pháp thay thế để biểu diễn liên tục và thêm nhiễu vào văn bản rời rạc (Bakosi và Ristorcelli, 2013). Công trình này thí nghiệm với dữ liệu huấn luyện trước chủ yếu bằng tiếng Anh. Các công trình tương lai cũng có thể khám phá các thách thức và lợi ích của các LM dựa trên khuếch tán trong thiết lập đa ngôn ngữ.

## Tuyên bố đạo đức

Các mô hình ngôn ngữ được huấn luyện trên dữ liệu từ web có thể duy trì các thiên kiến xã hội và tương tác độc hại, và có thể dễ tạo ra ngôn ngữ có hại (Gehman et al., 2020; Wallace et al., 2019, 2020; Sheng et al., 2021; Weidinger et al., 2022). Hơn nữa, các mô hình tạo ngôn ngữ có thể ghi nhớ và khuếch đại các mẫu trong dữ liệu mà không có sự hiểu biết ngôn ngữ sâu sắc hơn hoặc kiểm soát, vì vậy chúng có thể không nhất quán về mặt sự thật và tạo ra thông tin sai lệch (Maynez et al., 2020; Pagnoni et al., 2021; Zellers et al., 2019), hoặc có thể xâm phạm quyền riêng tư của người dùng (Carlini et al., 2021). Các công trình trước đây đã phác thảo những rủi ro này (Sheng et al., 2021; Weidinger et al., 2021), thảo luận về các điểm khởi nguồn của chúng, và ủng hộ nghiên cứu tương lai về phát triển đạo đức của các LM (Bender et al., 2021; Solaiman et al., 2019).

Mặc dù những nghiên cứu này đã được thực hiện cho các LM tự động hồi quy, LM dựa trên khuếch tán của chúng tôi cũng gặp phải những vấn đề này. Tuy nhiên, vì phương pháp của chúng tôi tự nhiên kết hợp khả năng kiểm soát, các công trình tương lai có thể khám phá các hàm kiểm soát có thể giảm thiểu những vấn đề này (Liu et al., 2021; Kumar et al., 2022b). Một rủi ro là khả năng kiểm soát cũng có thể bị lạm dụng một cách độc hại, với các mô hình bị khai thác cố ý để tạo ra nội dung thiên vị, độc hại hoặc không thực tế (Bagdasaryan và Shmatikov, 2022; Pagnoni et al., 2022). Do đó, ngoài tạo sinh có kiểm soát, các công trình tương lai nên nhắm đến việc phát hiện các thế hệ dưới sự kiểm soát cũng như để bảo vệ chống lại việc sử dụng độc hại (Kumar et al., 2022a).

## Lời cảm ơn

Các tác giả muốn cảm ơn Tianxiao Shen, Tianxing He, Jiacheng Liu, Ruiqi Zhong, Sidney Lisanza, Jacob Gershon, các thành viên của TsvetShop, và các nhà phản biện ẩn danh ACL vì những thảo luận và phản hồi hữu ích của họ. X.H. biết ơn nhận được tài trợ từ chương trình UW-Meta AI Mentorship. S.K. biết ơn nhận được học bổng Google Ph.D. Fellowship. Y.T. biết ơn nhận được học bổng Alfred P. Sloan Foundation Fellowship. Nghiên cứu này được hỗ trợ một phần bởi Quỹ Khoa học Quốc gia (NSF) dưới các Grant số IIS2203097, IIS2125201, và NSF CAREER Grant số IIS2142739. Nghiên cứu này được hỗ trợ một phần bởi Văn phòng Giám đốc Tình báo Quốc gia (ODNI), Hoạt động Nghiên cứu Tiên tiến Tình báo (IARPA), thông qua hợp đồng Chương trình HIATUS #2022-22072200004. Các quan điểm và kết luận có trong tài liệu này là của các tác giả và không nên được hiểu là nhất thiết đại diện cho các chính sách chính thức, dù được thể hiện hay ngụ ý, của ODNI, IARPA, hoặc Chính phủ Hoa Kỳ. Chính phủ Hoa Kỳ được ủy quyền tái tạo và phân phối các bản sao lại cho mục đích chính phủ mặc dù có bất kỳ chú thích bản quyền nào trong đó.

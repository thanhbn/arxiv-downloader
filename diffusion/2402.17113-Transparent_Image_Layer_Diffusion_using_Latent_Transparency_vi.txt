# Khuếch tán tầng hình ảnh trong suốt sử dụng độ trong suốt tiềm ẩn

LVMIN ZHANG, Đại học Stanford, Hoa Kỳ
MANEESH AGRAWALA, Đại học Stanford, Hoa Kỳ

"Phụ nữ với tóc rối, trong phòng ngủ" "Gỗ đang cháy, trên bàn, ở vùng nông thôn"

Đầu ra hỗn hợp Tầng đầu ra 1 Tầng đầu ra 2 Đầu ra hỗn hợp Tầng đầu ra 1 Tầng đầu ra 2

Hình 1. Tạo ra hình ảnh và tầng trong suốt. Với các lời nhắc văn bản đã cho (phía trên), khung công tác của chúng tôi có khả năng tạo ra nhiều tầng với độ trong suốt. Các tầng này có thể được hỗn hợp để tạo ra hình ảnh tương ứng với các lời nhắc. Phóng to để xem chi tiết bao gồm tóc rối và lửa bán trong suốt.

Chúng tôi trình bày một phương pháp cho phép các mô hình khuếch tán tiềm ẩn được tiền huấn luyện quy mô lớn tạo ra hình ảnh trong suốt. Phương pháp này cho phép tạo ra hình ảnh trong suốt đơn lẻ hoặc nhiều tầng trong suốt. Phương pháp học một "độ trong suốt tiềm ẩn" mã hóa độ trong suốt kênh alpha vào đa tạp tiềm ẩn của mô hình khuếch tán tiềm ẩn đã được tiền huấn luyện. Nó bảo toàn chất lượng sẵn sàng sản xuất của mô hình khuếch tán lớn bằng cách điều chỉnh độ trong suốt được thêm vào như một offset tiềm ẩn với những thay đổi tối thiểu đối với phân phối tiềm ẩn ban đầu của mô hình đã được tiền huấn luyện. Theo cách này, bất kỳ mô hình khuếch tán tiềm ẩn nào cũng có thể được chuyển đổi thành một bộ tạo hình ảnh trong suốt bằng cách tinh chỉnh nó với không gian tiềm ẩn được điều chỉnh. Chúng tôi huấn luyện mô hình với 1 triệu cặp tầng hình ảnh trong suốt được thu thập bằng sơ đồ thu thập có con người trong vòng lặp. Chúng tôi cho thấy rằng độ trong suốt tiềm ẩn có thể được áp dụng cho các bộ tạo hình ảnh nguồn mở khác nhau, hoặc được thích ứng với các hệ thống kiểm soát có điều kiện khác nhau để đạt được các ứng dụng như tạo tầng có điều kiện tiền cảnh/nền, tạo tầng chung, kiểm soát cấu trúc của nội dung tầng, v.v. Một nghiên cứu người dùng cho thấy rằng trong hầu hết các trường hợp (97%) người dùng ưa thích nội dung trong suốt được tạo ra bản địa của chúng tôi hơn các giải pháp ad-hoc trước đó như tạo ra và sau đó matting. Người dùng cũng báo cáo rằng chất lượng của hình ảnh trong suốt được tạo ra của chúng tôi có thể so sánh với các tài sản trong suốt thương mại thực tế như Adobe Stock.

Khái niệm CCS: •Tin học ứng dụng →Nghệ thuật tạo hình; Nghệ thuật truyền thông.

Từ khóa và cụm từ bổ sung: Hình ảnh trong suốt, chỉnh sửa hình ảnh, tầng hình ảnh, khuếch tán văn bản thành hình ảnh

Địa chỉ tác giả: Lvmin Zhang, lvmin@stanford.edu, Đại học Stanford, Hoa Kỳ; Maneesh Agrawala, maneesh@cs.stanford.edu, Đại học Stanford, Hoa Kỳ.

Được phép tạo bản sao kỹ thuật số hoặc bản cứng của tất cả hoặc một phần công việc này để sử dụng cá nhân hoặc lớp học mà không phải trả phí với điều kiện các bản sao không được tạo ra hoặc phân phối để kiếm lợi nhuận hoặc lợi thế thương mại và các bản sao phải mang thông báo này và trích dẫn đầy đủ trên trang đầu tiên. Bản quyền cho các thành phần của công việc này thuộc sở hữu của những người khác ngoài (các) tác giả phải được tôn trọng. Trích dẫn với tín dụng được cho phép. Để sao chép theo cách khác, hoặc xuất bản lại, để đăng trên máy chủ hoặc phân phối lại danh sách, cần có sự cho phép trước cụ thể và/hoặc phí. Yêu cầu quyền từ permissions@acm.org.

©2024 Bản quyền thuộc về (các) chủ sở hữu/tác giả. Quyền xuất bản được cấp phép cho ACM.
ACM 0730-0301/2024/7-ART100
https://doi.org/10.1145/3658150

Định dạng tham chiếu ACM:
Lvmin Zhang và Maneesh Agrawala. 2024. Khuếch tán tầng hình ảnh trong suốt sử dụng độ trong suốt tiềm ẩn. ACM Trans. Graph. 43, 4, Bài báo 100 (tháng 7 năm 2024), 38 trang. https://doi.org/10.1145/3658150

1 GIỚI THIỆU

Mặc dù các mô hình quy mô lớn để tạo ra hình ảnh đã trở thành nền tảng trong thị giác máy tính và đồ họa, nhưng đáng ngạc nhiên là rất ít chú ý nghiên cứu được dành cho việc tạo nội dung phân tầng hoặc tạo hình ảnh trong suốt. Tình huống này trái ngược hoàn toàn với nhu cầu thị trường đáng kể. Phần lớn phần mềm và quy trình chỉnh sửa nội dung thị giác dựa trên tầng, phụ thuộc nhiều vào các yếu tố trong suốt hoặc phân tầng để tạo ra và sáng tạo nội dung.

Các yếu tố chính góp phần vào khoảng cách nghiên cứu này là thiếu dữ liệu huấn luyện và khó khăn trong việc thao tác biểu diễn dữ liệu của các bộ tạo hình ảnh quy mô lớn hiện có. Các yếu tố hình ảnh trong suốt chất lượng cao trên Internet thường được lưu trữ bởi các kho hình ảnh thương mại với quyền truy cập hạn chế (và tốn kém), trái ngược với các bộ dữ liệu văn bản-hình ảnh đã bao gồm hàng tỷ hình ảnh (ví dụ, LAION [Schuhmann et al.2022]). Các bộ dữ liệu hình ảnh trong suốt nguồn mở lớn nhất thường có kích thước dưới 50K (ví dụ, DIM [Xu et al.2017] bao gồm 45.500 hình ảnh trong suốt). Trong khi đó, hầu hết các mô hình tạo hình ảnh nguồn mở, ví dụ, Stable Diffusion, là các mô hình khuếch tán tiềm ẩn nhạy cảm với biểu diễn dữ liệu không gian tiềm ẩn của chúng. Ngay cả những thay đổi nhỏ đối với phân phối tiềm ẩn cũng có thể làm suy giảm nghiêm trọng việc suy luận hoặc tinh chỉnh. Ví dụ, Stable Diffusion 1.5 và XL sử dụng các không gian tiềm ẩn khác nhau, và việc tinh chỉnh với các tiềm ẩn không khớp có thể gây ra sự suy giảm đáng kể trong chất lượng hình ảnh đầu ra [Stability 2022b]. Điều này thêm vào thách thức của việc thao tác biểu diễn dữ liệu của các mô hình hiện có để hỗ trợ các định dạng bổ sung như hình ảnh trong suốt.

Chúng tôi trình bày một phương pháp "độ trong suốt tiềm ẩn" cho phép các mô hình khuếch tán tiềm ẩn được tiền huấn luyện quy mô lớn tạo ra hình ảnh trong suốt cũng như nhiều tầng trong suốt. Phương pháp này mã hóa độ trong suốt hình ảnh thành một offset tiềm ẩn được điều chỉnh một cách rõ ràng để tránh làm gián đoạn phân phối tiềm ẩn. Độ trong suốt tiềm ẩn được mã hóa và giải mã bởi các mô hình độc lập bên ngoài, đảm bảo rằng bộ mã hóa/giải mã tiềm ẩn ban đầu đã được tiền huấn luyện được bảo toàn, để duy trì kết quả chất lượng cao của các mô hình khuếch tán tiên tiến. Để tạo ra nhiều tầng cùng nhau, chúng tôi sử dụng một cơ chế chú ý chia sẻ đảm bảo tính nhất quán và hỗn hợp hài hòa giữa các tầng hình ảnh, và chúng tôi huấn luyện LoRA để thích ứng các mô hình với các điều kiện tầng khác nhau.

Chúng tôi sử dụng một sơ đồ có con người trong vòng lặp để huấn luyện khung công tác của chúng tôi và thu thập dữ liệu đồng thời. Chúng tôi hoàn thiện quy mô bộ dữ liệu của chúng tôi ở mức 1 triệu hình ảnh trong suốt, bao gồm sự đa dạng về chủ đề nội dung và phong cách. Sau đó, chúng tôi sử dụng các phương pháp tiên tiến nhất để mở rộng bộ dữ liệu thành các mẫu đa tầng. Bộ dữ liệu này không chỉ cho phép huấn luyện các bộ tạo hình ảnh trong suốt mà còn có thể được sử dụng trong các ứng dụng khác nhau như tạo có điều kiện nền/tiền cảnh, tạo có hướng dẫn cấu trúc, chuyển đổi phong cách, v.v.

Các thí nghiệm cho thấy rằng trong phần lớn các trường hợp (97%), người dùng ưa thích nội dung trong suốt được tạo ra bản địa bởi phương pháp của chúng tôi hơn các giải pháp ad-hoc trước đó như tạo-sau-đó-matting. Khi chúng tôi so sánh chất lượng của kết quả được tạo ra của chúng tôi với kết quả tìm kiếm từ các trang tài sản trong suốt thương mại như Adobe Stock, tỷ lệ ưa thích của người dùng cho thấy rằng chất lượng có thể so sánh được.

Tóm lại, chúng tôi (1) đề xuất "độ trong suốt tiềm ẩn", một phương pháp cho phép các mô hình khuếch tán tiềm ẩn được tiền huấn luyện quy mô lớn tạo ra hình ảnh trong suốt đơn lẻ hoặc nhiều tầng trong suốt, (2) chúng tôi trình bày một cơ chế chú ý chia sẻ để tạo ra các tầng với hỗn hợp nhất quán và hài hòa, và (3) chúng tôi trình bày một mô hình đã được tiền huấn luyện để tạo hình ảnh trong suốt, hai LoRA đã được tiền huấn luyện để tạo nhiều tầng, cũng như một số kiến trúc ablative bổ sung cho việc tạo đa tầng.

2 CÔNG VIỆC LIÊN QUAN

2.1 Ẩn hình ảnh bên trong nhiễu loạn

Nghiên cứu trong nhiều lĩnh vực chỉ ra một hiện tượng: mạng nơ-ron có khả năng "ẩn" các đặc trưng trong nhiễu loạn bên trong các đặc trưng hiện có mà không thay đổi phân phối đặc trưng tổng thể, ví dụ, ẩn một hình ảnh bên trong một hình ảnh khác thông qua các nhiễu loạn pixel nhỏ, không thể nhìn thấy. Một thí nghiệm CycleGAN [Zhu et al.2017] điển hình giới thiệu face-to-ramen, nơi nhận dạng khuôn mặt con người có thể được ẩn trong một bức ảnh mì ramen. Tương tự, downscaling có thể đảo ngược [Xiao et al.2020] và grayscale có thể đảo ngược [Xia et al.2018] cho thấy rằng mạng nơ-ron có thể ẩn một hình ảnh lớn bên trong một hình ảnh nhỏ hơn, hoặc ẩn một hình ảnh đầy màu sắc bên trong một hình ảnh grayscale, và sau đó tái tạo lại hình ảnh ban đầu. Trong một thí nghiệm khác được xác minh rộng rãi, Goodfellow et al.[2015] cho thấy rằng các tín hiệu ví dụ đối nghịch có thể được ẩn bên trong nhiễu loạn đặc trưng để ảnh hưởng đến hành vi của các mạng nơ-ron khác. Trong bài báo này, "độ trong suốt tiềm ẩn" được đề xuất của chúng tôi sử dụng các nguyên tắc tương tự: ẩn các đặc trưng độ trong suốt hình ảnh bên trong một nhiễu loạn nhỏ được thêm vào không gian tiềm ẩn của Stable Diffusion [Stability 2022a], trong khi cùng lúc tránh thay đổi phân phối tổng thể của không gian tiềm ẩn.

2.2 Mô hình xác suất khuếch tán và khuếch tán tiềm ẩn

Mô hình xác suất khuếch tán [Sohl-Dickstein et al.2015] và các phương pháp huấn luyện và lấy mẫu liên quan như Mô hình xác suất khuếch tán khử nhiễu (DDPM) [Ho et al.2020], Mô hình ngầm khuếch tán khử nhiễu (DDIM) [Song et al.2021], và khuếch tán dựa trên điểm số [Song et al.2020] đóng góp vào nền tảng của các bộ tạo hình ảnh quy mô lớn gần đây. Các phương pháp khuếch tán hình ảnh sớm thường trực tiếp sử dụng màu sắc pixel làm dữ liệu huấn luyện [Kong and Ping 2021; San-Roman et al.2021; Song et al.2021]. Trái lại, Mô hình khuếch tán tiềm ẩn (LDM) [Rombach et al.2022] hoạt động trong không gian tiềm ẩn và đã được chứng minh cho phép huấn luyện dễ dàng hơn trong khi giảm yêu cầu tính toán. Phương pháp này đã được mở rộng thêm để tạo ra Stable Diffusion [Stability 2022a]. Gần đây, eDiff-I [Balaji et al.2022] đã sử dụng một ensemble của nhiều điều kiện bao gồm bộ mã hóa văn bản T5 [Raffel et al.2019], bộ mã hóa embedding văn bản và hình ảnh CLIP [Ilharco et al.2021]. Versatile Diffusion [Xu et al.2022] áp dụng một khung khuếch tán đa mục đích để xử lý văn bản, hình ảnh, và các biến thể trong một mô hình duy nhất.

2.3 Mô hình khuếch tán tùy chỉnh và chỉnh sửa hình ảnh

Các phương pháp sớm để tùy chỉnh mô hình khuếch tán đã tập trung vào hướng dẫn văn bản [Avrahami et al.2022; Kim et al.2022a; Nichol et al.2021]. Các thuật toán khuếch tán hình ảnh cũng tự nhiên hỗ trợ inpainting [Avrahami et al.2022; Ramesh et al.2022]. Textual Inversion [Gal et al.2022] và DreamBooth [Ruiz et al.2022] có thể cá nhân hóa nội dung của kết quả được tạo ra dựa trên một tập nhỏ các hình ảnh mẫu về cùng một chủ đề hoặc đối tượng. Gần đây, các mô hình kiểm soát cũng đã được sử dụng để thêm các điều kiện bổ sung cho việc tạo ra các mô hình văn bản thành hình ảnh, ví dụ, ControlNet [Zhang and Agrawala 2023], T2I-adapter nhẹ [Mou et al.2023], v.v. IP-Adapter [Ye et al.2023] sử dụng cơ chế chú ý chéo để tách biệt các đặc trưng văn bản và hình ảnh, cho phép các tín hiệu kiểm soát của hình ảnh tham chiếu như một prompt thị giác. [Li et al.2023a] sử dụng mặt nạ trong các đặc trưng mạng nơ-ron để đạt được kiểm soát vùng ngữ nghĩa. Các phương pháp dựa trên inversion cũng phổ biến trong chỉnh sửa hình ảnh. Lý thuyết DDPM [Ho et al.2020] chỉ ra rằng thuật toán khuếch tán xây dựng dữ liệu với các biến thể nhỏ tích lũy và những biến thể đó, có điều kiện trên nhiễu, có thể được thao tác với tối ưu hóa đảo ngược. Mokady et al.[2023] cho thấy rằng DDIM inversion có thể tối ưu hóa hình ảnh mà không cần đầu vào được tạo ra bởi một quá trình khuếch tán đã biết trước đó (null-text embedding). Cao et al.[2023] và Narek et al.[2023] thao tác các đặc trưng chú ý chéo không gian của các tầng Stable Diffusion cùng với DDPM inversion. Hertz et al.[2023] chỉnh sửa các kích hoạt chú ý của hình ảnh đầu vào với các prompt văn bản do người dùng cung cấp và đưa chúng trở lại mô hình khuếch tán. DiffEdit [2023] tạo ra mặt nạ vùng để chỉnh sửa hình ảnh, với hình ảnh đầu vào và prompt người dùng. Diffusion-CLIP [Kim et al.2022b] tinh chỉnh các mô hình khuếch tán với loss CLIP chống lại prompt. Imagic [Kawar et al.2023] đồng thời tối ưu hóa embedding văn bản của prompt người dùng và gradient mô hình để tái tạo hình ảnh cho các ứng dụng chỉnh sửa hình ảnh.

2.4 Xử lý tầng hình ảnh trong suốt

Xử lý hình ảnh trong suốt có liên quan chặt chẽ đến phân tách hình ảnh, trích xuất tầng, xử lý bảng màu, cũng như matting hình ảnh [Aksoy et al.2017a, 2016; Tang et al.2019]. Phân tách dựa trên màu sắc điển hình có thể được xem như một bài toán hình học không gian màu RGB [Du et al.2023; Tan et al.2019, 2015, 2018, 2016]. Những ý tưởng này cũng đã được mở rộng đến việc hỗn hợp nâng cao hơn của các tầng hình ảnh [Koyama and Goto 2018]. Tách màu dựa trên unmixing cũng đóng góp vào phân tách hình ảnh [Aksoy et al.2017b], và các đặc trưng ngữ nghĩa có thể được sử dụng trong phân đoạn mềm hình ảnh [Aksoy et al.2018]. Chúng tôi so sánh phương pháp của chúng tôi với một số phương pháp matting dựa trên deep learning tiên tiến trong các thí nghiệm và thảo luận của chúng tôi. PPMatting [Chen et al.2022] là một mô hình matting hình ảnh mạng nơ-ron được huấn luyện từ đầu sử dụng các bộ dữ liệu matting tiêu chuẩn. Matting Anything [Li et al.2023b] là một mô hình matting hình ảnh sử dụng Segment Anything Model (SAM) [Kirillov et al.2023] làm backbone. VitMatte [Yao et al.2024] là một phương pháp matting dựa trên tri-map sử dụng Vision Transformer (ViT). Text2Layer [Zhang et al.2023] cố gắng sử dụng hướng dẫn phân đoạn tiền cảnh để đạt được hiệu ứng phân tầng trong các mô hình khuếch tán, và chỉ ra rằng nút thắt cổ chai chính của nó là chất lượng phương pháp matting tiền cảnh vì mục tiêu học tập của nó được xây dựng từ phân đoạn hình ảnh của các mô hình matting. Phương pháp của chúng tôi bắt đầu từ việc tạo ra hình ảnh trong suốt bản địa thay vì xử lý hậu kỳ của matting hình ảnh, và về cơ bản khác biệt với các phương pháp trước đó sử dụng matting như xử lý hậu kỳ của đầu ra mô hình hoặc sử dụng matting để tổng hợp bộ dữ liệu.

2.5 Hài hòa hình ảnh

Hỗn hợp hài hòa của các tầng hình ảnh trong suốt có liên quan chặt chẽ đến nghiên cứu hài hòa hình ảnh. Đạt được "sự hài hòa" thường được xem như một bài toán tương quan màu sắc, độ tương phản, và các thành phần phong cách giữa tiền cảnh và nền để đảm bảo diện mạo tự nhiên và thành phần nhất quán. Các phương pháp deep learning [Chen et al.2023; Guerreiro et al.2023; Guo et al.2021; Tan et al.2023; Tsai et al.2017; Zhu et al.2015] đã được đề xuất để hài hòa hình ảnh, sử dụng các bộ dữ liệu được chú thích [Cong et al.2020; Niu et al.2023]. Những công trình này sử dụng khả năng học tập của mạng nơ-ron để thu được kiến thức tiền nghiệm về hài hòa.

3 PHƯƠNG PHÁP

Phương pháp của chúng tôi cho phép một Mô hình khuếch tán tiềm ẩn (LDM), như Stable Diffusion, tạo ra hình ảnh trong suốt, và sau đó mở rộng mô hình để tạo ra nhiều tầng trong suốt cùng nhau. Trong phần 3.1, chúng tôi giới thiệu phương pháp điều chỉnh không gian tiềm ẩn LDM để hỗ trợ mã hóa/giải mã hình ảnh trong suốt. Trong phần 3.2, chúng tôi thích ứng các mô hình khuếch tán tiềm ẩn đã được tiền huấn luyện với không gian tiềm ẩn được điều chỉnh để tạo ra hình ảnh trong suốt. Trong phần 3.3, chúng tôi mô tả phương pháp để tạo tầng chung hoặc có điều kiện. Cuối cùng, chúng tôi trình bày chi tiết về chuẩn bị bộ dữ liệu và chi tiết triển khai cho huấn luyện mạng nơ-ron trong phần 3.4.

Định nghĩa. Để làm rõ việc trình bày, trước tiên chúng tôi định nghĩa một số thuật ngữ. Đối với bất kỳ hình ảnh trong suốt nào 𝑰𝑡∈Rℎ×𝑤×4 với các kênh RGBA, chúng tôi ký hiệu 3 kênh màu RGB đầu tiên là 𝑰𝑐∈Rℎ×𝑤×3 và kênh alpha là 𝑰𝛼∈Rℎ×𝑤×1. Vì các màu sắc không được xác định về mặt vật lý tại các pixel nơi giá trị alpha bằng không nghiêm ngặt, trong bài báo này, tất cả các khu vực không xác định trong 𝑰𝑐 luôn được đệm bằng một bộ lọc Gaussian lặp (xem thêm tài liệu bổ sung) để tránh aliasing và các mẫu cạnh không cần thiết. Chúng tôi gọi 𝑰𝑐 là "hình ảnh RGB được đệm" (Hình 2). 𝑰𝑡 có thể được chuyển đổi thành "hình ảnh được nhân trước" như 𝑰 = 𝑰𝑐 ∗ 𝑰𝑎 trong đó ∗ biểu thị phép nhân theo từng pixel. Trong bài báo này, tất cả các giá trị RGB đều trong phạm vi [−1,1] (nhất quán với Stable Diffusion) trong khi tất cả các giá trị alpha đều trong phạm vi [0,1]. Hình ảnh được nhân trước 𝑰 có thể được xem như một hình ảnh RGB không trong suốt thông thường có thể được xử lý bởi bất kỳ mạng nơ-ron định dạng RGB nào. Các hình ảnh hóa của những hình ảnh này được thể hiện trong Hình 2.

3.1 Độ trong suốt tiềm ẩn

Mục tiêu của chúng tôi là thêm hỗ trợ độ trong suốt cho các mô hình khuếch tán tiềm ẩn quy mô lớn, như Stable Diffusion (SD), thường sử dụng bộ mã hóa tiềm ẩn (VAE) để chuyển đổi hình ảnh RGB thành hình ảnh tiềm ẩn trước khi đưa vào mô hình khuếch tán. Ở đây, VAE và mô hình khuếch tán phải chia sẻ cùng một phân phối tiềm ẩn, vì bất kỳ sự không khớp lớn nào cũng có thể làm suy giảm đáng kể việc suy luận/huấn luyện/tinh chỉnh của khung khuếch tán tiềm ẩn. Khi chúng tôi điều chỉnh không gian tiềm ẩn để hỗ trợ độ trong suốt, phân phối tiềm ẩn ban đầu phải được bảo toàn càng nhiều càng tốt. Những mục tiêu dường như mâu thuẫn này (thêm hỗ trợ độ trong suốt trong khi bảo toàn phân phối tiềm ẩn ban đầu) có thể được xử lý với một phép đo đơn giản: chúng ta có thể kiểm tra xem phân phối tiềm ẩn được sửa đổi có thể được giải mã tốt như thế nào bởi bộ giải mã tiềm ẩn đã được tiền huấn luyện và đông lạnh ban đầu — nếu việc giải mã một hình ảnh tiềm ẩn được sửa đổi tạo ra các artifact nghiêm trọng, phân phối tiềm ẩn bị lệch hoặc bị hỏng.

Chúng ta có thể viết phép đo "độ có hại" này theo toán học như sau. Với một hình ảnh RGB 𝑰, bộ mã hóa tiềm ẩn Stable Diffusion đã được tiền huấn luyện và đông lạnh E∗𝑠𝑑(·) và bộ giải mã D∗𝑠𝑑(·), trong đó ∗ chỉ ra các mô hình đông lạnh, chúng ta ký hiệu hình ảnh tiềm ẩn là 𝒙 = E∗𝑠𝑑(𝑰). Giả sử hình ảnh tiềm ẩn này 𝒙 được sửa đổi bởi bất kỳ offset 𝒙𝜖 nào, tạo ra một tiềm ẩn được điều chỉnh 𝒙𝑎 = 𝒙 + 𝒙𝜖. Việc tái tạo RGB được giải mã sau đó có thể được viết là ˆ𝑰 = D∗𝑠𝑑(𝒙𝑎) và chúng ta có thể đánh giá mức độ "có hại" của offset 𝒙𝜖 là

Lidentity = ||𝑰 − ˆ𝑰||2 = ||𝑰 − D∗𝑠𝑑(E∗𝑠𝑑(𝑰) + 𝒙𝜖)||2, (1)

trong đó ||·||2 là khoảng cách chuẩn L2 (sai số bình phương trung bình). Trực quan, nếu Lidentity tương đối cao, 𝒙𝜖 có thể có hại và có thể đã phá hủy chức năng tái tạo của bộ mã hóa-giải mã SD, ngược lại nếu Lidentity tương đối thấp, offset 𝒙𝜖 không phá vỡ việc tái tạo tiềm ẩn và tiềm ẩn được sửa đổi vẫn có thể được xử lý bởi Stable Diffusion đã được tiền huấn luyện.

Bên cạnh đó, vì hầu hết VAE chính thống cho các mô hình khuếch tán là các mô hình KL-Divergence hoặc Diagonal Gaussian Distribution, những mô hình này thường có một tham số được huấn luyện một cách đơn giản cho độ lệch chuẩn như một offset trong không gian tiềm ẩn. Xét độ lệch như vậy được ký hiệu là 𝒙std, chúng ta có thể sử dụng tham số đã được tiền huấn luyện này để xây dựng 𝒙𝜖 = 𝜆offset𝒙std𝒙offset trong đó 𝒙offset là đầu ra thô từ bộ mã hóa mới được thêm vào, 𝒙std là đầu ra độ lệch của VAE đã được tiền huấn luyện, và 𝜆offset là một tham số trọng số với mặc định 𝜆offset = 1𝑒−2.

Chúng tôi sử dụng offset tiềm ẩn 𝒙𝜖 để thiết lập "độ trong suốt tiềm ẩn" cho việc mã hóa/giải mã hình ảnh trong suốt. Cụ thể hơn, chúng tôi huấn luyện từ đầu một bộ mã hóa độ trong suốt tiềm ẩn E(·,·) nhận các kênh RGB 𝑰𝑐 và kênh alpha 𝑰𝛼 làm đầu vào để chuyển đổi độ trong suốt không gian pixel thành một offset tiềm ẩn

𝒙𝜖 = E(𝑰𝑐, 𝑰𝛼). (2)

Sau đó chúng tôi huấn luyện từ đầu một bộ giải mã độ trong suốt tiềm ẩn khác D(·,·) nhận tiềm ẩn được điều chỉnh 𝒙𝑎 = 𝒙 + 𝒙𝜖 và việc tái tạo RGB được đề cập ở trên ˆ𝑰 = D∗𝑠𝑑(𝒙𝑎) để trích xuất hình ảnh trong suốt từ không gian tiềm ẩn được điều chỉnh

[ˆ𝑰𝑐ˆ𝑰𝛼] = D(ˆ𝑰, 𝒙𝑎), (3)

trong đó ˆ𝑰𝑐, ˆ𝑰𝛼 là các kênh màu và alpha được tái tạo. Kiến trúc lớp mạng nơ-ron của E(·,·) và D(·,·) có trong tài liệu bổ sung. Chúng tôi đánh giá việc tái tạo với

Lrecon = ||𝑰𝑐 − ˆ𝑰𝑐||2 + ||𝑰𝑎 − ˆ𝑰𝑎||2, (4)

và chúng tôi tìm thấy thông qua thí nghiệm rằng chất lượng kết quả có thể được cải thiện thêm bằng cách giới thiệu một loss discriminator PatchGAN

Ldisc = Ldisc([ˆ𝑰𝑐, ˆ𝑰𝑎]), (5)

trong đó Ldisc(·,·) là một mục tiêu GAN từ một discriminator patch 5 lớp (chi tiết trong tài liệu bổ sung). Mục tiêu cuối cùng có thể được viết chung là

Lvae = 𝜆reconLrecon + 𝜆identityLidentity + 𝜆discLdisc, (6)

trong đó 𝜆... là các tham số trọng số: theo mặc định chúng tôi sử dụng 𝜆recon = 1, 𝜆identity = 1, 𝜆disc = 0.01. Bằng cách huấn luyện khung này với Lvae, tiềm ẩn được điều chỉnh 𝒙𝑎 có thể được mã hóa từ hình ảnh trong suốt hoặc ngược lại, và những hình ảnh tiềm ẩn đó có thể được sử dụng trong việc tinh chỉnh Stable Diffusion. Chúng tôi hình ảnh hóa pipeline trong Hình 2.

3.2 Mô hình khuếch tán với độ trong suốt tiềm ẩn

Vì không gian tiềm ẩn thay đổi với độ trong suốt tiềm ẩn được điều chỉnh một cách rõ ràng để phù hợp với phân phối tiềm ẩn đã được tiền huấn luyện ban đầu (Phương trình 1), Stable Diffusion có thể được tinh chỉnh trực tiếp trên không gian tiềm ẩn thay đổi. Với tiềm ẩn được điều chỉnh 𝒙𝑎, các thuật toán khuếch tán từ từ thêm nhiễu vào hình ảnh và tạo ra một hình ảnh nhiễu 𝒙𝑡, với 𝑡 biểu thị số lần nhiễu được thêm vào. Khi 𝑡 đủ lớn, hình ảnh tiềm ẩn xấp xỉ nhiễu thuần túy. Với một tập hợp các điều kiện bao gồm bước thời gian 𝑡 và prompt văn bản 𝒄𝑡, các thuật toán khuếch tán hình ảnh học một mạng 𝜖𝜃 dự đoán nhiễu được thêm vào hình ảnh tiềm ẩn nhiễu 𝒙𝑡 với

L = E𝒙𝑡,𝑡,𝒄𝑡,𝜖∼N(0,1)[∥𝜖 − 𝜖𝜃(𝒙𝑡, 𝑡, 𝒄𝑡))∥2₂] (7)

trong đó L là mục tiêu học tập tổng thể của toàn bộ mô hình khuếch tán. Việc huấn luyện này được hình ảnh hóa trong Hình 3-(a).

3.3 Tạo nhiều tầng

Chúng tôi mở rộng thêm mô hình cơ sở thành một mô hình đa tầng sử dụng chia sẻ attention và LoRA [Hu et al.2021], như thể hiện trong Hình 3-(b). Chúng tôi ký hiệu tiềm ẩn nhiễu tiền cảnh là 𝒙𝑓 và nền là 𝒙𝑏, và huấn luyện hai LoRA, một LoRA tiền cảnh được tham số hóa bởi 𝜃f và một LoRA nền bởi 𝜃b, để khử nhiễu hình ảnh tiềm ẩn. Nếu hai mô hình độc lập khử nhiễu hai hình ảnh, chúng ta có hai mục tiêu với

{E𝒙𝑓,𝑡,𝒄𝑡,𝜖𝑓∼N(0,1)[∥𝜖𝑓 − 𝜖𝜃,𝜃f(𝒙𝑓, 𝑡, 𝒄𝑡))∥2₂]
E𝒙𝑏,𝑡,𝒄𝑡,𝜖𝑏∼N(0,1)[∥𝜖𝑏 − 𝜖𝜃,𝜃b(𝒙𝑏, 𝑡, 𝒄𝑡))∥2₂]} (8)

trong đó 𝜖𝑓, 𝜖𝑏 là nhiễu tiềm ẩn cho tiền cảnh và nền. Sau đó chúng tôi hợp nhất hai quá trình khuếch tán độc lập để đạt được việc tạo ra nhất quán. Đối với mỗi lớp attention trong mô hình khuếch tán, chúng tôi nối tất cả các vector {key, query, value} được kích hoạt bởi hai hình ảnh, để hai lần chạy có thể được hợp nhất thành một mô hình lớn được tối ưu hóa chung 𝜖𝜃,𝜃f,𝜃g(·). Chúng tôi ký hiệu nhiễu được hợp nhất là 𝜖𝑚 = [𝜖𝑓, 𝜖𝑏] được nối, và chúng ta có mục tiêu cuối cùng

Llayer = E𝒙𝑓,𝒙𝑏,𝑡,𝒄𝑡,𝜖𝑚∼N(0,1)[∥𝜖𝑚 − 𝜖𝜃,𝜃f,𝜃g(𝒙𝑓, 𝒙𝑏, 𝑡, 𝒄𝑡))∥2₂] (9)

để tạo ra nhiều tầng cùng nhau một cách nhất quán. Chúng tôi cũng có thể thực hiện những sửa đổi đơn giản đối với mục tiêu này để hỗ trợ việc tạo tầng có điều kiện (ví dụ, tạo nền có điều kiện tiền cảnh hoặc tạo tiền cảnh có điều kiện nền). Cụ thể hơn, bằng cách sử dụng một tiềm ẩn sạch cho tiền cảnh thay vì tiềm ẩn nhiễu (tức là, bằng cách luôn đặt 𝜖𝑓 = 0), mô hình sẽ không khử nhiễu tiền cảnh, và khung trở thành một bộ tạo có điều kiện tiền cảnh. Tương tự, bằng cách đặt 𝜖𝑏 = 0, khung trở thành một bộ tạo có điều kiện nền. Chúng tôi triển khai tất cả các biến thể có điều kiện này trong các thí nghiệm.

3.4 Chuẩn bị bộ dữ liệu và chi tiết huấn luyện

Bộ dữ liệu cơ sở. Chúng tôi sử dụng phương pháp có con người trong vòng lặp để thu thập một bộ dữ liệu hình ảnh trong suốt và huấn luyện các mô hình của chúng tôi. Bộ dữ liệu ban đầu chứa 20k hình ảnh PNG trong suốt chất lượng cao được mua hoặc tải xuống miễn phí từ 5 kho hình ảnh trực tuyến (tất cả hình ảnh đều bao gồm quyền sử dụng thương mại (ví dụ trong Hình 4-(a)). Sau đó chúng tôi huấn luyện SDXL VAE với độ trong suốt tiềm ẩn sử dụng các hình ảnh được lấy mẫu ngẫu nhiên với xác suất bằng nhau (ở kích thước batch 8), và sau đó huấn luyện mô hình khuếch tán SDXL sử dụng cùng dữ liệu với các tiềm ẩn được điều chỉnh. Tiếp theo chúng tôi lặp lại các bước sau trong tổng cộng 25 vòng. Ở đầu mỗi vòng, chúng tôi tạo ra 10k mẫu ngẫu nhiên sử dụng mô hình cuối cùng trong vòng trước đó. và các prompt ngẫu nhiên từ LAIONPOP [Schuhmann and Bevan 2023]. Sau đó chúng tôi thủ công chọn 1000 mẫu để thêm trở lại vào bộ dữ liệu huấn luyện. Các mẫu mới được thêm vào được cho xác suất cao hơn 2 lần xuất hiện trong các batch huấn luyện ở vòng tiếp theo. Sau đó chúng tôi huấn luyện các mô hình mã hóa-giải mã độ trong suốt tiềm ẩn và khuếch tán một lần nữa. Sau 25 vòng, kích thước của bộ dữ liệu tăng lên 45K. Sau đó, chúng tôi tạo ra 5 triệu cặp mẫu mà không có tương tác của con người và sử dụng ngưỡng thẩm mỹ LAION [Schuhmann et al.2022] thiết lập ở mức 5.5 và sắp xếp điểm số clip để có được 1 triệu cặp mẫu. Chúng tôi tự động loại bỏ các mẫu không chứa bất kỳ pixel trong suốt nào cũng như những mẫu không chứa bất kỳ pixel có thể nhìn thấy nào. Cuối cùng, tất cả hình ảnh được gắn chú thích với LLaVA [Liu et al.2023] (một GPT đa phương thức nguồn mở tương tự như GPT4v) để có được các prompt văn bản chi tiết. Việc huấn luyện cả VAE và mô hình khuếch tán được hoàn thiện với thêm 15k lần lặp sử dụng bộ dữ liệu 1 triệu cuối cùng.

Phân tích thống kê. Chúng tôi phân tích ngắn gọn ở đây cách việc lựa chọn dữ liệu của con người cải thiện chất lượng của bộ dữ liệu cũng như khả năng mô hình. Như thể hiện trong Hình 5, chúng tôi hình ảnh hóa các mẫu được giữ lại hoặc loại bỏ trong mỗi vòng lựa chọn có con người trong vòng lặp. Chúng ta có thể thấy rằng nỗ lực của con người loại bỏ một số khuyết điểm rõ ràng (ví dụ, hình ảnh trống, màu sắc hoàn toàn mờ đục cho kính, v.v.) và tăng cường sự đa dạng của nội dung bộ dữ liệu (ví dụ, hiệu ứng phát sáng trên sách ma thuật, v.v.). Trong Bảng 1, chúng tôi tiếp tục checkpoint từ mỗi vòng thu thập dữ liệu để lấy mẫu hình ảnh, và yêu cầu người dùng xem lại hình ảnh và đếm hình ảnh có khuyết điểm rõ ràng. Chúng ta có thể thấy rằng khi số vòng tăng lên, tỷ lệ đầu ra có khuyết điểm giảm dần.

Bộ dữ liệu đa tầng. Chúng tôi mở rộng thêm bộ dữ liệu {văn bản, hình ảnh trong suốt} của chúng tôi thành một bộ dữ liệu {văn bản, tầng tiền cảnh, tầng nền}, để huấn luyện các mô hình đa tầng. Như thể hiện trong Hình 4-(b), chúng tôi yêu cầu GPT (chúng tôi đã sử dụng ChatGPT cho 100k yêu cầu và sau đó chuyển sang LLAMA2 cho 900k yêu cầu) tạo ra các cặp prompt có cấu trúc cho tiền cảnh như "một con mèo dễ thương", toàn bộ hình ảnh như "mèo trong vườn", và nền như "không có gì trong vườn" (chúng tôi yêu cầu GPT thêm từ "không có gì" vào prompt nền). Prompt tiền cảnh được xử lý bởi bộ tạo hình ảnh trong suốt đã được huấn luyện của chúng tôi (Phần 3.2) để có được hình ảnh trong suốt. Sau đó, chúng tôi sử dụng mô hình Diffusers Stable Diffusion XL Inpaint [diffusers 2024] để inpaint tất cả các pixel có alpha nhỏ hơn một để có được hình ảnh trung gian sử dụng prompt cho toàn bộ hình ảnh. Cuối cùng, chúng tôi đảo ngược mặt nạ alpha, erode 𝑘 = 8 pixel và inpaint lần nữa với prompt nền để có được tầng nền. Chúng tôi lặp lại quá trình này 1 triệu lần để tạo ra 1 triệu cặp tầng.

Chi tiết huấn luyện. Chúng tôi sử dụng optimizer AdamW với learning rate 1e-5 cho cả VAE và mô hình khuếch tán. Mô hình Stable Diffusion đã được tiền huấn luyện là SDXL [Podell et al.2023]. Đối với việc huấn luyện LoRA [Hu et al.2021], chúng tôi luôn sử dụng rank 256 cho tất cả các tầng. Chúng tôi sử dụng tiêu chuẩn của Diffusers để đặt tên và trích xuất các khóa LoRA. Trong việc thu thập dữ liệu có con người trong vòng lặp, mỗi vòng chứa 10k lần lặp ở kích thước batch 16. Các thiết bị huấn luyện là 4x A100 80G NV-link, và toàn bộ việc huấn luyện mất một tuần (để giảm ngân sách, việc huấn luyện được tạm dừng khi con người đang thu thập dữ liệu cho vòng tối ưu hóa tiếp theo) và thời gian GPU thực tế là khoảng 350 giờ A100. Phương pháp của chúng tôi thân thiện với huấn luyện cho quy mô cá nhân hoặc quy mô phòng thí nghiệm vì 350 giờ GPU thường có thể được xử lý trong vòng 1K USD.

4 CÁC THÍ NGHIỆM

Chúng tôi trình bày chi tiết các thí nghiệm định tính và định lượng với hệ thống của chúng tôi. Trước tiên chúng tôi trình bày kết quả định tính với hình ảnh đơn lẻ (Phần 4.1), nhiều tầng (Phần 4.2), cũng như tạo ra lặp lại (Phần 4.3), và sau đó cho thấy rằng khung của chúng tôi cũng có thể được kết hợp với các mô-đun kiểm soát cho các ứng dụng rộng hơn (Phần 4.4). Sau đó chúng tôi phân tích tầm quan trọng của từng thành phần với nghiên cứu ablative (Phần 4.5), và sau đó thảo luận về sự khác biệt và kết nối giữa phương pháp của chúng tôi và matting hình ảnh (Phần 4.6). Cuối cùng, chúng tôi tiến hành nghiên cứu người dùng nhận thức (Phần 4.7) và trình bày một loạt các thảo luận để nghiên cứu thêm về hành vi của khung của chúng tôi (Phần 4.8, 4.10, 4.12).

4.1 Kết quả định tính

Chúng tôi trình bày kết quả định tính trong Hình 6 với một tập hợp đa dạng các hình ảnh trong suốt được tạo ra bằng mô hình cơ sở hình ảnh đơn lẻ của chúng tôi. Những kết quả này thể hiện khả năng của mô hình trong việc tạo ra hình ảnh trong suốt bản địa mang lại độ trong suốt kính chất lượng cao, tóc, lông, và hiệu ứng bán trong suốt như ánh sáng phát sáng, lửa, hiệu ứng ma thuật, v.v. Những kết quả này cũng thể hiện khả năng tổng quát hóa của mô hình đối với các chủ đề nội dung đa dạng.

Chúng tôi trình bày thêm kết quả đa tầng trong Hình 7 với các tầng trong suốt được tạo ra bởi mô hình đa tầng của chúng tôi và hình ảnh được hỗn hợp. Những kết quả này thể hiện khả năng của mô hình trong việc tạo ra các thành phần hài hòa của các đối tượng có thể được hỗn hợp cùng nhau một cách liền mạch. Các tầng không chỉ nhất quán về chiếu sáng và mối quan hệ hình học, mà còn thể hiện chất lượng thẩm mỹ của Stable Diffusion (ví dụ, việc lựa chọn màu sắc của nền và tiền cảnh theo một phân phối đã học trông hài hòa và thẩm mỹ).

4.2 Tạo tầng có điều kiện

Chúng tôi trình bày kết quả tạo tầng có điều kiện (tức là, tạo nền có điều kiện tiền cảnh và tạo tiền cảnh có điều kiện nền) trong Hình 8. Chúng ta có thể thấy rằng mô hình có khả năng tạo ra thành phần nhất quán với hình học và chiếu sáng mạch lạc. Trong ví dụ "bóng đèn trong nhà thờ", mô hình cố gắng tạo ra một thiết kế đối xứng thẩm mỹ để phù hợp với tiền cảnh. Các ví dụ "ngồi trên ghế băng"/"ngồi trên ghế sofa" chứng tỏ rằng mô hình có khả năng suy luận tương tác giữa tiền cảnh và nền và tạo ra hình học tương ứng.

4.3 Tạo ra lặp lại

Hình 9 cho thấy rằng chúng ta có thể lặp lại sử dụng mô hình tạo tiền cảnh có điều kiện nền để đạt được thành phần hoặc số lượng tầng tùy ý. Đối với mỗi tầng mới, chúng tôi hỗn hợp tất cả các tầng được tạo ra trước đó thành một hình ảnh RGB và đưa nó vào mô hình tạo tiền cảnh có điều kiện nền. Chúng tôi cũng quan sát thấy rằng mô hình có khả năng diễn giải ngôn ngữ tự nhiên trong bối cảnh của hình ảnh nền, ví dụ, tạo ra một cuốn sách trước con mèo. Mô hình thể hiện khả năng thành phần hình học mạnh mẽ, ví dụ, tạo ra một con người ngồi trên hộp.

4.4 Tạo ra có thể kiểm soát

Như thể hiện trong Hình 10, chúng tôi chứng minh rằng các mô hình kiểm soát hiện có như ControlNet [Zhang and Agrawala 2023] có thể được áp dụng vào mô hình của chúng tôi để có chức năng phong phú hơn. Chúng ta có thể thấy rằng mô hình có khả năng bảo toàn cấu trúc toàn cầu theo tín hiệu ControlNet để tạo ra các thành phần hài hòa với hiệu ứng chiếu sáng nhất quán. Chúng tôi cũng sử dụng một ví dụ "quả cầu phản chiếu" để cho thấy rằng mô hình có khả năng tương tác với nội dung của tiền cảnh và nền để tạo ra chiếu sáng nhất quán như phản chiếu.

4.5 Nghiên cứu Ablative

Chúng tôi tiến hành một nghiên cứu ablative để đánh giá sự đóng góp của từng thành phần trong khung của chúng tôi. Chúng tôi quan tâm đến một kiến trúc có thể không sửa đổi bộ mã hóa/giải mã latent VAE của Stable Diffusion, mà chỉ thêm kênh vào UNet. Trong Stable Diffusion ban đầu, một hình ảnh 512×512×3 được mã hóa thành một hình ảnh tiềm ẩn có kích thước 64×64×4. Điều này chỉ ra rằng nếu chúng ta nhân đôi kênh alpha 512×512×1 thành 3 lần thành một ma trận 512×512×3, alpha có thể được mã hóa trực tiếp thành một hình ảnh tiềm ẩn 64×64×4. Bằng cách nối điều này với hình ảnh tiềm ẩn ban đầu, hình ảnh tiềm ẩn cuối cùng sẽ tạo thành một ma trận 64×64×8. Điều này có nghĩa là chúng ta có thể thêm 4 kênh vào Stable Diffusion UNet để buộc nó hỗ trợ kênh alpha. Chúng tôi trình bày kết quả của phương pháp này trong Hình 11-(a). Chúng ta có thể thấy rằng phương pháp này làm suy giảm nghiêm trọng chất lượng tạo ra của mô hình lớn đã được tiền huấn luyện, vì phân phối tiềm ẩn của nó bị thay đổi; mặc dù VAE không thay đổi (nó được đông lạnh), 4 kênh bổ sung thay đổi đáng kể phân phối đặc trưng sau lớp convolution đầu tiên trong VAE UNet. Lưu ý rằng điều này khác với việc thêm tín hiệu kiểm soát vào UNet — UNet phải tạo ra và nhận ra các kênh được thêm vào cùng một lúc vì khuếch tán là một quá trình lặp lại, và đầu ra của bất kỳ bước khuếch tán nào trở thành đầu vào của bước khuếch tán tiếp theo.

Trong Hình 11-(b), chúng tôi thử nghiệm một kiến trúc khác thêm trực tiếp một kênh vào bộ mã hóa và giải mã VAE. Chúng tôi huấn luyện VAE để bao gồm một kênh alpha, và sau đó huấn luyện thêm UNet. Chúng tôi quan sát thấy rằng việc huấn luyện như vậy rất không ổn định, và kết quả gặp phải các loại sụp đổ khác nhau từ thời gian này sang thời gian khác. Lý do cốt lõi dẫn đến hiện tượng này là phân phối tiềm ẩn bị thay đổi quá nhiều trong quá trình tinh chỉnh VAE.

Chúng tôi cũng giới thiệu một số kiến trúc thay thế trong Hình 12 cho các quy trình làm việc phức tạp hơn. Chúng ta có thể thêm các kênh được khởi tạo bằng không vào UNet và sử dụng VAE (có hoặc không có độ trong suốt tiềm ẩn) để mã hóa tiền cảnh, hoặc nền, hoặc kết hợp tầng thành điều kiện, và huấn luyện mô hình để tạo ra tiền cảnh hoặc nền hoặc trực tiếp tạo ra hình ảnh được hỗn hợp (ví dụ, Hình 12-(a, b, c)). Chúng tôi hình ảnh hóa các ví dụ của pipeline hai giai đoạn này trong Hình 12-(d, e).

4.6 Mối quan hệ với Image Matting

Chúng tôi thảo luận về sự khác biệt và kết nối giữa việc tạo ra hình ảnh trong suốt bản địa và matting hình ảnh. Cụ thể, chúng tôi thử nghiệm các phương pháp matting sau: (1) PPMatting [Chen et al.2022] là một mô hình matting hình ảnh mạng nơ-ron tiên tiến nhất. Mô hình này báo cáo đạt được độ chính xác cao nhất trong tất cả các phương pháp matting dựa trên mạng nơ-ron "cổ điển", tức là, các mô hình nơ-ron được huấn luyện từ đầu trên một bộ dữ liệu hình ảnh trong suốt được thu thập. Mô hình này hoàn toàn tự động và không cần tri-map do người dùng chỉ định. (2) Matting Anything [Li et al.2023b] là một loại mô hình matting hình ảnh mới dựa trên Segment Anything Model (SAM) [Kirillov et al.2023] được phát hành gần đây. Mô hình này sử dụng SAM đã được tiền huấn luyện làm cơ sở và tinh chỉnh nó để thực hiện matting. Mô hình này cũng không cần tri-map do người dùng chỉ định. Chúng tôi cũng bao gồm một phương pháp dựa trên tri-map để nghiên cứu tiềm năng trích xuất matte có hướng dẫn từ người dùng. (3) VitMatte [Yao et al.2024] là một mô hình matting tiên tiến nhất sử dụng tri-map. Kiến trúc là Vision Transformer (ViT) và đại diện cho chất lượng cao nhất của các mô hình matting có hướng dẫn từ người dùng hiện tại.

Như thể hiện trong Hình 13, chúng ta có thể thấy rằng một số loại mẫu khó đối với các phương pháp matting, ví dụ, hiệu ứng bán trong suốt như lửa, lông trắng thuần túy trên nền trắng thuần túy, tách bóng, v.v. Đối với nội dung bán trong suốt như lửa và bóng, một khi những mẫu này được hỗn hợp với nền phức tạp, việc tách chúng trở thành một nhiệm vụ gần như không thể. Để có được các yếu tố hoàn hảo sạch sẽ, có lẽ phương pháp duy nhất là tổng hợp các yếu tố từ đầu, sử dụng một bộ tạo tầng trong suốt bản địa. Chúng tôi cũng chú ý đến tiềm năng sử dụng đầu ra của khung của chúng tôi để huấn luyện các mô hình matting.

4.7 Nghiên cứu người dùng nhận thức

Để đánh giá và so sánh phương pháp của chúng tôi với các phương pháp hiện có về mặt nhận thức, chúng tôi thực hiện một nghiên cứu người dùng nhận thức tập trung vào các khía cạnh của con người đối với kết quả trong suốt bản địa của chúng tôi và các phương pháp ad-hoc như Stable Diffusion + tạo ra và matting. Chúng tôi nhắm mục tiêu đến các trường hợp sử dụng thực tế nơi người dùng muốn có được các yếu tố trong suốt với các yêu cầu cụ thể (prompt). Nghiên cứu của chúng tôi thử nghiệm nhiều loại phương pháp (tạo ra trong suốt bản địa, tạo ra và matting, kho thương mại trực tuyến) để xem chúng đáp ứng các yêu cầu như vậy như thế nào (bằng cách hỏi người dùng họ thích cái nào hơn).

Cụ thể, nghiên cứu người dùng của chúng tôi bao gồm 14 cá nhân, trong đó 11 cá nhân là nhân viên crowd-source trực tuyến, 1 là sinh viên khoa học máy tính, và 2 còn lại là những nhà sáng tạo nội dung chuyên nghiệp. Chúng tôi lấy mẫu 100 kết quả sử dụng 3 phương pháp (prompt được lấy mẫu ngẫu nhiên từ PickaPic [Kirstain et al.2023]), và điều này dẫn đến 100 nhóm kết quả, với mỗi nhóm chứa 3 kết quả từ 3 phương pháp. Những người tham gia được mời xếp hạng kết quả trong mỗi nhóm. Khi xếp hạng kết quả trong mỗi nhóm, chúng tôi hỏi người dùng câu hỏi - "Bạn thích kết quả nào sau đây nhất? Vui lòng xếp hạng các yếu tố trong suốt sau đây theo sở thích của bạn". Chúng tôi sử dụng tỷ lệ ưa thích làm thước đo kiểm tra. Quá trình này được lặp lại 4 lần để tính toán độ lệch chuẩn. Sau đó, chúng tôi tính toán tỷ lệ ưa thích trung bình của từng phương pháp. Chúng tôi gọi nghiên cứu người dùng này là "nhóm 1".

Chúng tôi so sánh phương pháp của chúng tôi với SD+PPMatting [Chen et al.2022], SD+Matting Anything [Li et al.2023b]. Ở đây, "SD+" có nghĩa là trước tiên chúng tôi sử dụng Stable Diffusion XL để tạo ra một hình ảnh RGB, và sau đó thực hiện matting sử dụng phương pháp tương ứng. Kết quả được thể hiện trong Bảng 2, nhóm 1. Chúng tôi tìm thấy rằng người dùng ưa thích phương pháp của chúng tôi hơn tất cả các phương pháp khác (trong hơn 97% trường hợp). Điều này chứng tỏ ưu thế của việc tạo ra hình ảnh trong suốt bản địa so với giải pháp ad-hoc như tạo ra sau đó matting.

Chúng tôi cũng thực hiện một thí nghiệm ưa thích người dùng khác trong "nhóm 2", so sánh kết quả của chúng tôi với việc tìm kiếm tài sản trong suốt thương mại từ Adobe Stock, sử dụng cùng thước đo ưa thích người dùng được đề cập ở trên. Trong Bảng 2, nhóm 2, chúng tôi báo cáo rằng tỷ lệ ưa thích của phương pháp chúng tôi gần với kho thương mại (45.3% so với 54.7%). Mặc dù nội dung trả phí chất lượng cao từ kho thương mại vẫn được ưa thích hơn một chút. Kết quả này cho thấy rằng nội dung trong suốt được tạo ra của chúng tôi có thể cạnh tranh với các nguồn thương mại yêu cầu người dùng trả tiền cho mỗi hình ảnh.

4.8 Kênh RGBA thô

Hình 14 cho thấy các đầu ra thô với từng kênh trong hình ảnh trong suốt được tạo ra của chúng tôi. Chúng ta có thể thấy rằng mô hình tránh aliasing bằng cách đệm kênh RGB với màu sắc "chảy máu" mịn. Phương pháp này đảm bảo chất lượng màu tiền cảnh cao trong các khu vực hỗn hợp alpha.

4.9 Bộ giải mã mạnh mẽ với tăng cường dữ liệu

Hình 15 cho thấy rằng chúng ta có thể sử dụng các phương pháp tăng cường dữ liệu để đạt được bộ giải mã mạnh mẽ hơn để xử lý các tình huống khi UNet không thể khuếch tán các offset tiềm ẩn mong muốn. Điều này có thể hữu ích khi một số mô hình cộng đồng nhất định (ví dụ, anime, hoạt hình, v.v.) không thể tạo ra offset tiềm ẩn mong muốn trong quá trình khuếch tán, và chúng ta vẫn muốn giải mã hình ảnh trong suốt hữu ích từ những không gian tiềm ẩn hơi không khớp đó được tạo ra bởi những mô hình được tinh chỉnh đó. Cụ thể, Hình 15 đơn giản là dropout 30% offset khi huấn luyện bộ giải mã.

4.10 Mô hình cộng đồng

Như thể hiện trong Hình 16, phương pháp của chúng tôi có thể được áp dụng cho các mô hình cộng đồng, LoRA, và phong cách prompt khác nhau, mà không cần huấn luyện bổ sung. Cụ thể hơn, chúng tôi thử một LoRA Minecraft, một LoRA pixel art, một mô hình anime [cagliostrolab 2024], và một số phong cách prompt cộng đồng. Chúng ta có thể thấy rằng việc áp dụng cho các mô hình khác nhau không làm suy giảm chất lượng của mô hình/LoRA đích cũng như không làm suy giảm chất lượng của độ trong suốt hình ảnh. Khả năng tích hợp này cho thấy tiềm năng của mô hình để sử dụng rộng rãi hơn trong các lĩnh vực sáng tạo và chuyên nghiệp đa dạng.

4.11 Tốc độ suy luận

Trong Bảng 3, chúng tôi báo cáo tốc độ suy luận với các mô hình khuếch tán cơ sở và kiến trúc khác nhau. Tất cả các thử nghiệm đều dựa trên các thiết bị tính toán cấp độ cá nhân. Chúng tôi đã thử nghiệm SD1.5 và SDXL với Nvidia RTX 3070 và RTX 4090. Các thử nghiệm của chúng tôi bao gồm tạo ra hình ảnh trong suốt đơn lẻ, tạo ra nhiều tầng cùng nhau, và tạo ra nhiều tầng sử dụng các pipeline hai giai đoạn.

4.12 Hạn chế

Như thể hiện trong Hình 17, một sự đánh đổi với khung của chúng tôi là giữa việc tạo ra "yếu tố trong suốt sạch sẽ" và "hỗn hợp hài hòa". Ví dụ, nếu hình ảnh trong suốt là một đối tượng sạch sẽ và có thể tái sử dụng mà không có bất kỳ hiệu ứng chiếu sáng hoặc bóng đổ nào, việc tạo ra một nền có thể được hỗn hợp hài hòa với tiền cảnh có thể rất thách thức và mô hình có thể không thành công trong mọi trường hợp (Hình 17-(c) là một trường hợp thất bại). Hiện tượng này có thể được chữa trị ở một mức độ nào đó nếu chúng ta chỉ sử dụng nền làm điều kiện để tạo ra tiền cảnh để buộc một sự hỗn hợp hài hòa (Hình 17-(d)). Tuy nhiên, điều này cũng sẽ dẫn đến chiếu sáng ảnh hưởng đến đối tượng trong suốt, làm cho các đối tượng trong suốt ít có thể tái sử dụng hơn. Người ta có thể lập luận rằng hình ảnh trong Hình 17-(a) có thể tái sử dụng nhiều hơn cho các nhà thiết kế và trong các ứng dụng thực tế so với hình ảnh trong suốt trong Hình 17-(d) chứa nhiều mẫu cụ thể gắn liền với nền.

5 KẾT LUẬN

Tóm lại, bài báo này giới thiệu "độ trong suốt tiềm ẩn", một phương pháp để tạo ra hình ảnh trong suốt cá nhân hoặc một loạt các tầng trong suốt nhất quán. Phương pháp mã hóa kênh alpha trong suốt vào phân phối tiềm ẩn của Stable Diffusion. Quá trình này đảm bảo đầu ra chất lượng cao của các mô hình khuếch tán hình ảnh quy mô lớn, bằng cách điều chỉnh một offset được thêm vào không gian tiềm ẩn. Việc huấn luyện các mô hình bao gồm 1 triệu cặp tầng hình ảnh trong suốt, được thu thập bằng sơ đồ thu thập có con người trong vòng lặp. Chúng tôi trình bày một loạt các ứng dụng, chẳng hạn như tạo ra các tầng có điều kiện tiền cảnh/nền, kết hợp các tầng, tạo ra tầng có kiểm soát cấu trúc, v.v. Kết quả nghiên cứu người dùng cho thấy rằng trong phần lớn các trường hợp, người dùng ưa thích nội dung trong suốt được tạo ra bản địa bởi phương pháp của chúng tôi hơn các phương pháp truyền thống như tạo ra sau đó matting. Chất lượng của hình ảnh trong suốt được tạo ra được tìm thấy là có thể so sánh với các tài sản trong các kho thương mại.

LỜI CẢM ƠN

Công việc này được hỗ trợ một phần bởi Google thông qua liên kết của họ với Stanford Institute for Human-centered Artificial Intelligence (HAI).

TÀI LIỆU THAM KHẢO

[Các tài liệu tham khảo được giữ nguyên định dạng gốc]

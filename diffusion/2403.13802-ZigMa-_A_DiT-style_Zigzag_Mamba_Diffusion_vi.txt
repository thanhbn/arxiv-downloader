# ZigMa: Mô hình Khuếch tán Mamba Zigzag theo phong cách DiT

Vincent Tao Hu, Stefan Andreas Baumann, Ming Gui,
Olga Grebenkova, Pingchuan Ma, Johannes Schusterbauer, và Björn Ommer
CompVis @ LMU Munich, MCML
https://compvis.github.io/zigma/

Tóm tắt Mô hình khuếch tán từ lâu đã bị ảnh hưởng bởi các vấn đề về khả năng mở rộng và độ phức tạp bậc hai, đặc biệt trong các cấu trúc dựa trên transformer. Trong nghiên cứu này, chúng tôi nhằm tận dụng khả năng mô hình hóa chuỗi dài của Mô hình Không gian Trạng thái được gọi là Mamba để mở rộng khả năng ứng dụng của nó trong việc tạo dữ liệu thị giác. Đầu tiên, chúng tôi xác định một sự bỏ sót quan trọng trong hầu hết các phương pháp thị giác dựa trên Mamba hiện tại, đó là việc thiếu xem xét tính liên tục không gian trong sơ đồ quét của Mamba. Thứ hai, dựa trên hiểu biết này, chúng tôi giới thiệu Zigzag Mamba, một giải pháp đơn giản, có thể cắm-và-chạy, gánh nặng tham số tối thiểu, theo phong cách DiT, vượt trội hơn các baseline dựa trên Mamba và chứng minh cải thiện tốc độ và sử dụng bộ nhớ so với các baseline dựa trên transformer, đồng thời việc quét theo lớp không đồng nhất này cho phép không có gánh nặng bộ nhớ và tốc độ khi chúng ta xem xét thêm các đường dẫn quét. Cuối cùng, chúng tôi tích hợp Zigzag Mamba với khung Stochastic Interpolant để điều tra khả năng mở rộng của mô hình trên các bộ dữ liệu thị giác có độ phân giải cao, chẳng hạn như FacesHQ 1024×1024 và UCF101, MultiModal-CelebA-HQ, và MS COCO 256×256.

Từ khóa: Mô hình Khuếch tán · Mô hình Không gian Trạng thái · Stochastic Interpolants

1 Giới thiệu
Các mô hình khuếch tán đã chứng minh những tiến bộ đáng kể trong nhiều ứng dụng khác nhau, bao gồm xử lý hình ảnh [45,48,84], phân tích video [44], xử lý đám mây điểm [109], học biểu diễn [30] và ước tính tư thế con người [32]. Nhiều mô hình này được xây dựng dựa trên Latent Diffusion Models (LDM) [84], thường dựa trên backbone UNet. Tuy nhiên, khả năng mở rộng vẫn là một thách thức đáng kể trong LDM [50]. Gần đây, các cấu trúc dựa trên transformer đã trở nên phổ biến do khả năng mở rộng [9,80] và hiệu quả trong đào tạo đa phương thức [10]. Đáng chú ý, cấu trúc dựa trên transformer DiT [80] thậm chí đã góp phần nâng cao mô hình tạo video độ trung thực cao SORA [78] của OpenAI. Mặc dù có những nỗ lực để giảm bớt độ phức tạp bậc hai của cơ chế attention thông qua các kỹ thuật như windowing [71], sliding [13], sparsification [19,56], hashing [20,93], Ring Attention [15,66], Flash Attention [23] hoặc sự kết hợp của chúng [8,124], nó vẫn là một nút thắt cổ chai cho các mô hình khuếch tán.

Mặt khác, State-Space Models [34,35,39] đã chứng minh tiềm năng đáng kể cho việc mô hình hóa chuỗi dài, có thể sánh bằng với các phương pháp dựa trên transformer. Sự tương tự sinh học [95] và trạng thái bộ nhớ hiệu quả của chúng cũng ủng hộ việc sử dụng mô hình State-Space thay vì transformer. Một số phương pháp [29,33,35,88] đã được đề xuất để tăng cường tính bền vững [116], khả năng mở rộng [33], và hiệu quả [35,36] của State-Space Models. Trong số này, một phương pháp được gọi là Mamba [33] nhằm giảm bớt những vấn đề này thông qua việc quét song song hiệu quả và các cải tiến phụ thuộc dữ liệu khác. Tuy nhiên, ưu điểm của Mamba nằm ở việc mô hình hóa chuỗi 1D, và việc mở rộng nó sang hình ảnh 2D là một câu hỏi thách thức. Các nghiên cứu trước đây [70,123] đã đề xuất làm phẳng token 2D trực tiếp theo thứ bậc máy tính như thứ tự row-and-column-major, nhưng cách tiếp cận này bỏ qua Tính Liên tục Không gian, như được thể hiện trong Hình 1. Các nghiên cứu khác [67,73] xem xét nhiều hướng khác nhau trong một khối Mamba duy nhất, nhưng điều này giới thiệu thêm tham số và gánh nặng bộ nhớ GPU. Trong bài báo này, chúng tôi nhằm nhấn mạnh tầm quan trọng của Tính Liên tục Không gian trong Mamba và đề xuất một số phương pháp trực quan và đơn giản để cho phép ứng dụng các khối Mamba vào hình ảnh 2D bằng cách kết hợp các thiên hướng quy nạp dựa trên tính liên tục trong hình ảnh. Chúng tôi cũng tổng quát hóa các phương pháp này sang 3D với phân tách không gian-thời gian trên chuỗi 3D.

Cuối cùng, Stochastic Interpolant [3] cung cấp một khung tổng quát hơn có thể thống nhất các mô hình tạo sinh khác nhau bao gồm Normalizing Flow [17], mô hình khuếch tán [43,89,91], Flow matching [4,64,69], và Schrödinger Bridge [65]. Trước đây, một số nghiên cứu [74] khám phá Stochastic Interpolant trên độ phân giải tương đối nhỏ, ví dụ 256×256, 512×512. Trong nghiên cứu này, chúng tôi nhằm khám phá nó trong các kịch bản phức tạp hơn nữa, ví dụ độ phân giải 1024×1024 và thậm chí trong video.

Tóm lại, đóng góp của chúng tôi như sau: Đầu tiên, chúng tôi xác định vấn đề quan trọng của Tính Liên tục Không gian trong việc tổng quát hóa khối Mamba từ mô hình hóa chuỗi 1D sang mô hình hóa hình ảnh 2D và video 3D. Dựa trên hiểu biết này, chúng tôi đề xuất một mô hình quét theo lớp không đồng nhất plug-and-play đơn giản, không tham số được gọi là Zigzag Mamba (ZigMa) tận dụng tính liên tục không gian để tối đa hóa việc kết hợp thiên hướng quy nạp từ dữ liệu thị giác. Thứ hai, chúng tôi mở rộng phương pháp từ 2D sang 3D bằng cách phân tách các chuỗi không gian và thời gian để tối ưu hóa hiệu suất. Thứ hai, chúng tôi cung cấp phân tích toàn diện xung quanh khối Mamba trong phạm vi các mô hình khuếch tán. Cuối cùng, chúng tôi chứng minh rằng Zigzag Mamba được thiết kế vượt trội hơn các baseline dựa trên Mamba có liên quan, đại diện cho việc khám phá đầu tiên về Stochastic Interpolants trên dữ liệu hình ảnh quy mô lớn (1024×1024) và video.

2 Các nghiên cứu liên quan
Mamba. Một số nghiên cứu [102,103,103] đã chứng minh rằng State-Space Model sở hữu khả năng xấp xỉ phổ quát trong một số điều kiện nhất định. Mamba, như một State-Space Model mới, có tiềm năng vượt trội để mô hình hóa các chuỗi dài một cách hiệu quả, điều này đã được khám phá trong nhiều lĩnh vực khác nhau như hình ảnh y tế [73,86,108,111], video [58,79], phục hồi hình ảnh [38,122], đồ thị [12], byte từ NLP [100], dữ liệu bảng [2], đám mây điểm [61], chuyển động con người [106,120], đa nhiệm [62] và tạo hình ảnh [27]. Trong số đó, liên quan nhất đến chúng tôi là VisionMamba [70,123], S4ND [77] và Mamba-ND [59]. VisionMamba [70,123] sử dụng SSM hai chiều trong các nhiệm vụ phân biệt dẫn đến chi phí tính toán cao. Phương pháp của chúng tôi áp dụng một giải pháp khuếch tán mamba thay thế đơn giản trong các mô hình tạo sinh. S4ND [77] giới thiệu convolution cục bộ vào quá trình lý luận của Mamba, vượt ra ngoài việc chỉ sử dụng dữ liệu 1D. Mamba-ND [59] tính đến tính đa chiều trong các nhiệm vụ phân biệt, sử dụng nhiều lần quét khác nhau trong một khối duy nhất. Trái lại, trọng tâm của chúng tôi là phân phối độ phức tạp quét trên mỗi lớp của mạng, do đó tối đa hóa việc kết hợp thiên hướng quy nạp từ dữ liệu thị giác với gánh nặng tham số bằng không. Đường cong quét là một hướng quan trọng trong SSM, PointMamba [61] là một công trình tiêu biểu sử dụng SSM với các đường cong không gian (ví dụ Hilbert) để phân tích đám mây điểm, đạt hiệu suất đáng kể. Trái ngược với họ, kết quả sơ bộ của chúng tôi cho thấy rằng đường cong Hilbert không hoạt động tốt với phương pháp của chúng tôi (xem Phụ lục), trong khi phương pháp của chúng tôi có thể được coi là đường cong Peano đơn giản nhất. Để biết thêm thông tin liên quan đến công việc của Mamba, vui lòng tham khảo khảo sát [105].

Backbone trong Mô hình Khuếch tán. Các mô hình khuếch tán chủ yếu sử dụng backbone dựa trên UNet [43,84] và ViT [9,80]. Trong khi UNet được biết đến với yêu cầu bộ nhớ cao [84], ViT có lợi từ khả năng mở rộng [18,24] và học đa phương thức [10]. Tuy nhiên, độ phức tạp bậc hai của ViT hạn chế việc xử lý token thị giác, thúc đẩy các nghiên cứu hướng tới việc giảm thiểu vấn đề này [13,23,104]. Công trình của chúng tôi, được truyền cảm hứng bởi Mamba [33], khám phá mô hình dựa trên SSM như một backbone khuếch tán chung, duy trì các ưu điểm về khả năng mô hình hóa tuần tự và bất khả tri phương thức của ViT.

Đồng thời, DiffSSM [112] tập trung vào điều kiện vô điều kiện và lớp trong mô hình S4 [35]. DIS [27] chủ yếu khám phá mô hình không gian trạng thái trên độ phân giải tương đối nhỏ, điều này không phải là trọng tâm chính xác của công việc chúng tôi. Công việc của chúng tôi khác biệt đáng kể so với họ vì nó chủ yếu tập trung vào thiết kế backbone sử dụng khối Mamba và mở rộng nó sang điều kiện văn bản. Hơn nữa, chúng tôi áp dụng phương pháp của mình vào dữ liệu thị giác phức tạp hơn.

SDE và ODE trong các mô hình khuếch tán. Lĩnh vực Score-based Generative Models bao gồm những đóng góp đáng kể từ các nghiên cứu nền tảng như Score Matching with Langevin Dynamics (SMLD) của Song et al. [90], và sự ra đời của Diffusion Models với Denoising Score Matching (DDPMs) được đề xuất bởi Ho et al. [43]. Những phương pháp này hoạt động trong khuôn khổ Stochastic Differential Equations (SDEs), một khái niệm được tinh chỉnh thêm trong nghiên cứu của Song et al. [91]. Những bước tiến nghiên cứu gần đây, được minh họa bởi Karras et al. [52] và Lee et al. [57], đã chứng minh hiệu quả của việc sử dụng các bộ lấy mẫu Ordinary Differential Equation (ODE) cho SDE khuếch tán, cung cấp giảm đáng kể chi phí lấy mẫu so với các cách tiếp cận truyền thống đòi hỏi rời rạc hóa SDE khuếch tán. Hơn nữa, trong lĩnh vực Flow Matching [64] và Rectified Flow [68], cả SMLD và DDPMs đều xuất hiện như các trường hợp chuyên biệt dưới các đường dẫn khác nhau của khung Probability Flow ODE [91], với các ứng dụng rộng rãi trong thị giác [22,28,49], độ sâu [37], chuyển động con người [47], thậm chí ngôn ngữ [46]. Những mô hình này thường sử dụng tham số hóa trường vận tốc sử dụng interpolant tuyến tính, một khái niệm tìm thấy các ứng dụng rộng hơn trong khung Stochastic Interpolant [3], với các tổng quát hóa tiếp theo mở rộng sang các cài đặt manifold [14]. Mô hình SiT [74] xem xét kỹ lưỡng sự tương tác giữa các phương pháp nội suy trong cả bối cảnh lấy mẫu và đào tạo, mặc dù trong bối cảnh độ phân giải nhỏ hơn như 512×512. Nghiên cứu của chúng tôi nỗ lực mở rộng những hiểu biết này sang quy mô lớn hơn, tập trung vào khả năng tổng quát hóa cho hình ảnh 2D 1024×1024 và dữ liệu video 3D.

3 Phương pháp
Trong phần này, chúng tôi bắt đầu bằng cách cung cấp thông tin nền về State-Space Models [34,35,39], với sự tập trung đặc biệt vào một trường hợp đặc biệt được biết đến là Mamba [33]. Sau đó chúng tôi làm nổi bật vấn đề quan trọng của Tính Liên tục Không gian trong khung Mamba, và dựa trên hiểu biết này, chúng tôi đề xuất Zigzag Mamba. Sự cải tiến này nhằm cải thiện hiệu quả của việc mô hình hóa dữ liệu 2D bằng cách kết hợp thiên hướng quy nạp tính liên tục vốn có trong dữ liệu 2D. Hơn nữa, chúng tôi thiết kế một khối cross-attention cơ bản dựa trên khối Mamba để đạt được điều kiện văn bản. Tiếp theo, chúng tôi đề xuất mở rộng cách tiếp cận này sang dữ liệu video 3D bằng cách phân tách mô hình thành các chiều không gian và thời gian, do đó tạo điều kiện cho quá trình mô hình hóa. Cuối cùng, chúng tôi giới thiệu các khía cạnh lý thuyết của nội suy ngẫu nhiên để đào tạo và lấy mẫu, là nền tảng cho kiến trúc mạng của chúng tôi.

3.1 Nền tảng: State-Space Models
State Space Models (SSMs) [34,35,39] đã được chứng minh là có thể xử lý các phụ thuộc tầm xa về mặt lý thuyết và thực nghiệm [36] với việc mở rộng tuyến tính w.r.t chiều dài chuỗi. Trong dạng tổng quát của chúng, một mô hình không gian trạng thái tuyến tính có thể được viết như sau:
x′(t) = A(t)x(t) + B(t)u(t)
y(t) = C(t)x(t) + D(t)u(t),
ánh xạ một chuỗi đầu vào 1-D u(t) ∈ R sang một chuỗi đầu ra 1-D y(t) ∈ R thông qua một chuỗi trạng thái tiềm ẩn N-D ngầm x(t) ∈ Rn. Cụ thể, các SSM sâu tìm cách sử dụng các chồng của mô hình đơn giản này trong một kiến trúc mô hình hóa chuỗi neural, trong đó các tham số A, B, C và D cho mỗi lớp có thể được học thông qua gradient descent.

Gần đây, Mamba [33] đã cải thiện đáng kể tính linh hoạt của SSM trong Language Modelling bằng cách nới lỏng ràng buộc bất biến thời gian trên các tham số SSM, đồng thời duy trì hiệu quả tính toán. Một số nghiên cứu [70,123] đã được thực hiện để thích ứng việc sử dụng Mamba từ dữ liệu ngôn ngữ một chiều sang dữ liệu thị giác đa chiều. Trong khi hầu hết các nghiên cứu này cố gắng nhân bản A để tạo điều kiện cho hướng mới (đảo ngược), cách tiếp cận này có thể dẫn đến thêm tham số và tăng gánh nặng bộ nhớ. Trong bài báo này, chúng tôi tập trung vào việc khám phá sơ đồ quét của Mamba trong các mô hình khuếch tán để hiệu quả tối đa hóa việc sử dụng thiên hướng quy nạp từ dữ liệu thị giác đa chiều với gánh nặng tham số và bộ nhớ bằng không.

3.2 Backbone Khuếch tán: Zigzag Mamba
Mạng Phong cách DiT. Chúng tôi chọn sử dụng khung DiT bằng AdaLN [80] thay vì cấu trúc U-ViT tập trung vào skip-layer [9], vì DiT đã được xác nhận là một cấu trúc có thể mở rộng trong tài liệu [10,18,78]. Ngoài ra, cấu trúc Hourglass với downsampling [76,85] yêu cầu lựa chọn độ sâu và chiều rộng dựa trên độ phức tạp của bộ dữ liệu và nhiệm vụ. Yêu cầu này hạn chế tính linh hoạt của giải pháp. Xem xét những điểm đã nêu, nó thông báo cho thiết kế mạng Mamba của chúng tôi được mô tả trong Hình 4. Thành phần cốt lõi của thiết kế này là Zigzag Scanning, sẽ được giải thích trong đoạn sau.

Zigzag Scanning trong Mamba. Các nghiên cứu trước đây [101,112] đã sử dụng quét hai chiều trong khung SSM. Cách tiếp cận này đã được mở rộng để bao gồm thêm các hướng quét [67,70,115] để tính đến các đặc điểm của dữ liệu hình ảnh 2D. Những cách tiếp cận này mở rộng các patch hình ảnh theo bốn hướng, dẫn đến bốn chuỗi khác biệt. Mỗi chuỗi này sau đó được xử lý cùng nhau thông qua mọi SSM. Tuy nhiên, vì mỗi hướng có thể có các tham số SSM khác nhau (A, B, C, và D), việc mở rộng số lượng hướng có thể dẫn đến các vấn đề về bộ nhớ. Trong công trình này, chúng tôi điều tra tiềm năng phân bổ độ phức tạp của Mamba vào từng lớp của mạng.

Cách tiếp cận của chúng tôi tập trung xung quanh khái niệm sắp xếp lại token trước khi đưa chúng vào khối Forward Scan. Đối với một đặc trưng đầu vào zi từ lớp i, đặc trưng đầu ra zi+1 của khối Forward Scan sau khi sắp xếp lại có thể được biểu diễn như:
zΩi = arrange(zi, Ωi), (1)
z̄Ωi = scan(zΩi), (2)
zi+1 = arrange(z̄Ωi, Ω̄i), (3)
Ωi biểu diễn hoán vị 1D của lớp i, sắp xếp lại thứ tự của các token patch bằng Ωi, và Ωi và Ω̄i biểu diễn phép toán ngược. Điều này đảm bảo rằng cả zi và zi+1 đều duy trì thứ tự mẫu của các token hình ảnh gốc.

Bây giờ chúng tôi khám phá thiết kế của phép toán Ωi, xem xét các thiên hướng quy nạp bổ sung từ hình ảnh 2D. Chúng tôi đề xuất một thuộc tính chính: Tính Liên tục Không gian. Về Tính Liên tục Không gian, các cải tiến hiện tại của Mamba trong hình ảnh [67,70,123] thường nén các token patch 2D trực tiếp theo thứ bậc máy tính, như thứ tự row-and-column-major. Tuy nhiên, cách tiếp cận này có thể không tối ưu để kết hợp thiên hướng quy nạp với các token lân cận, như được minh họa trong Hình 3. Để giải quyết vấn đề này, chúng tôi giới thiệu một sơ đồ quét mới được thiết kế để duy trì tính liên tục không gian trong quá trình quét. Ngoài ra, chúng tôi xem xét space-filling, có nghĩa là đối với một patch có kích thước N×N, chiều dài của sơ đồ quét liên tục 1D nên là N2. Điều này giúp kết hợp hiệu quả các token để tối đa hóa tiềm năng của việc mô hình hóa chuỗi dài trong khối Mamba.

Quét Theo Lớp Không Đồng Nhất. Để đạt được thuộc tính đã nêu, chúng tôi thiết kế heuristic tám sơ đồ liên tục space-filling có thể, ký hiệu là Sj (trong đó j ∈ [0,7]), như được minh họa trong Hình 3. Mặc dù có thể có các sơ đồ khác có thể hình dung được, để đơn giản, chúng tôi giới hạn việc sử dụng tám sơ đồ này. Do đó, sơ đồ cho mỗi lớp có thể được biểu diễn là Ωi = S{i%8}, trong đó % biểu thị toán tử modulo.

Triển khai điều kiện văn bản trên Zigzag Mamba. Trong khi Mamba cung cấp ưu thế về việc mô hình hóa chuỗi dài hiệu quả, nó làm như vậy với cái giá của cơ chế attention. Kết quả là, đã có ít khám phá về việc kết hợp điều kiện văn bản trong các mô hình khuếch tán dựa trên Mamba. Để giải quyết khoảng trống này, chúng tôi đề xuất một khối cross-attention đơn giản với các lớp skip được xây dựng dựa trên khối Mamba, như được minh họa trong Hình 4. Thiết kế này không chỉ cho phép mô hình hóa chuỗi dài mà còn tạo điều kiện cho điều kiện đa token, chẳng hạn như điều kiện văn bản. Hơn nữa, nó có tiềm năng cung cấp khả năng diễn giải [16,42,94], vì cross-attention đã được sử dụng trong các mô hình khuếch tán.

Tổng quát hóa sang video 3D bằng cách phân tách thông tin không gian và thời gian. Trong các phần trước, trọng tâm của chúng tôi đã ở trên Mamba 2D không gian, nơi chúng tôi thiết kế một số sơ đồ quét 2D liên tục không gian, space-filling. Trong phần này, chúng tôi nhằm tận dụng kinh nghiệm này để hỗ trợ thiết kế các cơ chế tương ứng cho xử lý video 3D. Chúng tôi bắt đầu quá trình thiết kế bằng cách ngoại suy từ Mamba hướng thông thường, như được mô tả trong Hình 5. Cho một đầu vào đặc trưng video z ∈ RB×T×C×W×H, chúng tôi đề xuất ba biến thể của Video Mamba Block để tạo điều kiện cho việc tạo video 3D.

(a) Sweep-scan: Trong cách tiếp cận này, chúng tôi trực tiếp làm phẳng đặc trưng 3D z mà không xem xét tính liên tục không gian hoặc thời gian. Đáng chú ý rằng quá trình làm phẳng theo thứ tự thứ bậc máy tính, có nghĩa là không có tính liên tục nào được bảo tồn trong biểu diễn làm phẳng.

(b) 3D Zigzag: So với công thức của zigzag 2D trong các phần phụ trước, chúng tôi theo thiết kế tương tự để tổng quát hóa nó sang 3D Zigzag để giữ tính liên tục trong 2D và 3D đồng thời. Có thể, sơ đồ có độ phức tạp cao hơn nhiều. Chúng tôi liệt kê heuristic 8 sơ đồ cũng như vậy. Tuy nhiên, chúng tôi nhận thấy thực nghiệm rằng sơ đồ này sẽ dẫn đến tối ưu hóa dưới mức tối ưu.

(c) Factorized 3D Zigzag = 2D Zigzag + 1D Sweep: Để giải quyết vấn đề tối ưu hóa dưới mức tối ưu, chúng tôi đề xuất phân tách các tương quan không gian và thời gian thành các khối Mamba riêng biệt. Thứ tự ứng dụng của chúng có thể được điều chỉnh theo mong muốn, ví dụ "sstt" hoặc "ststst", trong đó "s" biểu thị spatial-zigzag Mamba và "t" biểu thị temporal-zigzag Mamba. Đối với quét thời gian 1D, chúng tôi chỉ đơn giản chọn quét tiến và lùi, vì chỉ có một chiều trên trục thời gian.

Phân tích Tính toán. Đối với một chuỗi thị giác T ∈ R1×M×D, độ phức tạp tính toán của global self-attention và k-direction mamba và zigzag mamba của chúng tôi như sau:
ζ(self-attention) = 4MD2 + 2M2D, (4)
ζ(k-mamba) = k × [3M(2D)N + M(2D)N2], (5)
ζ(zigzag) = 3M(2D)N + M(2D)N2, (6)
trong đó self-attention thể hiện độ phức tạp bậc hai đối với chiều dài chuỗi M, trong khi Mamba thể hiện độ phức tạp tuyến tính (N là một tham số cố định, được đặt mặc định là 16). Ở đây, k biểu thị số lượng hướng quét trong một khối Mamba duy nhất. Do đó, k-mamba và zigzag chia sẻ độ phức tạp tuyến tính so với self-attention. Hơn nữa, phương pháp zigzag của chúng tôi có thể loại bỏ chuỗi k, giảm thêm độ phức tạp tổng thể.

Sau khi hoàn thành thiết kế mạng Zigzag Mamba để cải thiện tích hợp thiên hướng quy nạp thị giác, chúng tôi tiến hành kết hợp nó với một khung khuếch tán mới, như được minh họa bên dưới.

3.3 Khung Khuếch tán: Stochastic Interpolant
Lấy mẫu dựa trên vector v và score s. Theo [3, 96], phân phối xác suất phụ thuộc thời gian pt(x) của xt cũng trùng với phân phối của reverse-time SDE [6]:
dXt = v(Xt, t)dt + (1/2)wts(Xt, t)dt + √wtdW̄t, (7)
trong đó W̄t là một quá trình Wiener thời gian ngược, wt > 0 là hệ số khuếch tán phụ thuộc thời gian tùy ý, s(x, t) = ∇log pt(x) là score, và v(x, t) được cho bởi kỳ vọng có điều kiện
v(x, t) = E[ẋt|xt = x],
= α̇tE[x*|xt = x] + σ̇tE[ε|xt = x], (8)
trong đó αt là một hàm giảm của t, và σt là một hàm tăng của t. Ở đây, α̇t và σ̇t biểu thị đạo hàm thời gian của αt và σt, tương ứng.

Miễn là chúng ta có thể ước tính các trường velocity v(x, t) và/hoặc score s(x, t), chúng ta có thể sử dụng nó cho quá trình lấy mẫu bằng probability flow ODE [91] hoặc reverse-time SDE (7). Giải SDE ngược (7) ngược trong thời gian từ XT = ε ~ N(0,I) cho phép tạo mẫu từ phân phối dữ liệu được xấp xỉ p0(x) ~ p(x). Trong quá trình lấy mẫu, chúng ta có thể thực hiện lấy mẫu trực tiếp từ ODE hoặc SDE để cân bằng giữa tốc độ lấy mẫu và độ trung thực. Nếu chúng ta chọn thực hiện lấy mẫu ODE, chúng ta có thể đạt được điều này đơn giản bằng cách đặt thuật ngữ noise s bằng không.

Trong [3], nó cho thấy rằng một trong hai đại lượng sθ(x, t) và vθ(x, t) cần được ước tính trong thực tế. Điều này tuân theo trực tiếp từ ràng buộc
x = E[xt|xt = x],
= αtE[x*|xt = x] + σtE[ε|xt = x], (9)
có thể được sử dụng để biểu diễn lại score s(x, t) theo velocity v(x, t) như
s(x, t) = σt^(-1)[(αtv(x, t) - α̇tx)/(α̇tσt - αtσ̇t)]. (10)

Do đó, v(x, t) và s(x, t) có thể được chuyển đổi lẫn nhau. Chúng tôi minh họa cách tính toán chúng trong phần sau.

Ước tính score s và velocity v. Đã được chứng minh trong các mô hình khuếch tán dựa trên score [91] rằng score có thể được ước tính parametrically như sθ(x, t) sử dụng hàm mất mát
Ls(θ) = ∫₀ᵀ E[‖σtsθ(xt, t) + ε‖²]dt. (11)

Tương tự, velocity v(x, t) có thể được ước tính parametrically như vθ(x, t) thông qua hàm mất mát
Lv(θ) = ∫₀ᵀ E[‖vθ(xt, t) - α̇tx* - σ̇tε‖²]dt, (12)
trong đó θ biểu thị mạng Zigzag Mamba mà chúng tôi đã mô tả trong phần trước, chúng tôi áp dụng đường dẫn tuyến tính để đào tạo, do tính đơn giản và quỹ đạo tương đối thẳng của nó:
αt = 1 - t, σt = t. (13)

Chúng tôi lưu ý rằng bất kỳ trọng số phụ thuộc thời gian nào cũng có thể được bao gồm dưới các tích phân trong cả (11) và (12). Những yếu tố trọng số này đóng vai trò quan trọng trong các mô hình dựa trên score khi T trở nên lớn [54,55]. Do đó, chúng cung cấp một dạng tổng quát xem xét cả trọng số phụ thuộc thời gian và tính ngẫu nhiên.

4 Thực nghiệm
4.1 Bộ dữ liệu và Chi tiết Đào tạo
Bộ dữ liệu Hình ảnh. Để khám phá khả năng mở rộng ở độ phân giải cao, chúng tôi thực hiện thực nghiệm trên FacesHQ 1024×1024. Bộ dữ liệu chung mà chúng tôi sử dụng để đào tạo và ablation là FacesHQ, một tập hợp của CelebA-HQ [110] và FFHQ [53], như được sử dụng trong công việc trước đó như [26,28].

Bộ dữ liệu Video. Bộ dữ liệu UCF101 bao gồm 13.320 video clip, được phân loại thành 101 danh mục. Tổng chiều dài của những video clip này là hơn 27 giờ. Tất cả các video này được thu thập từ YouTube và có tốc độ khung hình cố định 25 FPS với độ phân giải 320×240. Chúng tôi lấy mẫu ngẫu nhiên 16 khung hình liên tục và thay đổi kích thước các khung hình thành 256×256.

Chi tiết Đào tạo. Chúng tôi sử dụng đồng nhất bộ tối ưu hóa AdamW [72] với tốc độ học 1e-4. Để trích xuất các đặc trưng tiềm ẩn, chúng tôi sử dụng các bộ mã hóa VAE có sẵn. Để giảm chi phí tính toán, chúng tôi áp dụng cách tiếp cận đào tạo độ chính xác hỗn hợp. Ngoài ra, chúng tôi áp dụng gradient clipping với ngưỡng 2.0 và weight decay 0.01 để ngăn chặn sự xuất hiện NaN trong quá trình đào tạo Mamba. Hầu hết thực nghiệm của chúng tôi được thực hiện trên 4 GPU A100, với khám phá khả năng mở rộng được mở rộng đến 16 và 32 GPU A100. Để lấy mẫu, chúng tôi áp dụng lấy mẫu ODE để xem xét tốc độ. Để biết thêm chi tiết, vui lòng tham khảo Phụ lục 8.8.

4.2 Nghiên cứu Ablation
Ablation Sơ đồ Quét. Chúng tôi cung cấp một số phát hiện quan trọng dựa trên các nghiên cứu ablation của chúng tôi trên bộ dữ liệu MultiModal-CelebA ở nhiều độ phân giải khác nhau trong Bảng 1. Đầu tiên, chuyển đổi sơ đồ quét từ sweep sang zigzag dẫn đến một số cải thiện. Thứ hai, khi chúng tôi tăng sơ đồ zigzag từ 1 lên 8, chúng tôi thấy những cải thiện nhất quán. Điều này cho thấy rằng việc thay đổi sơ đồ quét trong các khối khác nhau có thể có lợi. Cuối cùng, cải thiện tương đối giữa Zigzag-1 và Zigzag-8 nổi bật hơn ở độ phân giải cao hơn (512×512, hoặc số lượng token chuỗi dài hơn) so với độ phân giải thấp hơn (256×256, hoặc số lượng token chuỗi ngắn hơn), điều này cho thấy tiềm năng lớn và việc kết hợp thiên hướng quy nạp hiệu quả hơn trong số lượng chuỗi dài hơn.

Ablation về Position Embedding. Như được hiển thị trong Bảng 2, learnable embedding hoạt động tốt hơn Sinusoidal embedding, mà lần lượt hoạt động tốt hơn so với không có position embedding. Trong nhiều trường hợp khác nhau, các phương pháp zigzag của chúng tôi vượt trội hơn các baseline. Đáng chú ý, hiệu suất của chúng tôi gần như không thay đổi cho dù chúng tôi sử dụng Sinusoidal position embedding hay không có position embedding. Điều này cho thấy rằng phương pháp của chúng tôi có thể kết hợp thiên hướng quy nạp không gian tốt hơn so với baseline của chúng tôi. Cuối cùng, việc sử dụng learnable position embedding mang lại những cải thiện thêm, mặc dù nhỏ, cho thấy rằng position embedding tốt hơn tồn tại ngay cả trong sơ đồ quét zigzag của chúng tôi. Chúng tôi thấy rằng [79] chia sẻ cùng kết luận như chúng tôi trong các nhiệm vụ liên quan đến video.

Nghiên cứu Ablation về Mạng và FPS/GPU-Memory. Trong Hình 6 (a,b), chúng tôi phân tích tốc độ forward và sử dụng bộ nhớ GPU trong khi thay đổi kích thước patch toàn cầu từ 32×32 đến 196×196. Để phân tích tốc độ, chúng tôi báo cáo Frame Per Second (FPS) thay vì FLOPS, vì FPS cung cấp đánh giá tốc độ rõ ràng và thích hợp hơn. Để đơn giản, chúng tôi áp dụng đồng nhất sơ đồ quét zigzag-1 Mamba và sử dụng batch size=1 và patch size=1 trên GPU A100 với bộ nhớ 80GB. Đáng chú ý rằng tất cả các phương pháp chia sẻ số lượng tham số gần như giống hệt nhau để so sánh công bằng. Chúng tôi chủ yếu so sánh phương pháp của chúng tôi với hai backbone Khuếch tán dựa trên transformer phổ biến, U-ViT [9] và DiT [80]. Rõ ràng là phương pháp của chúng tôi đạt được FPS tốt nhất và sử dụng GPU khi tăng dần số lượng patching. U-ViT thể hiện hiệu suất tệ nhất, thậm chí vượt quá giới hạn bộ nhớ khi số lượng patch là 196. Đáng ngạc nhiên, sử dụng GPU của DiT gần với phương pháp của chúng tôi, điều này hỗ trợ lựa chọn backbone DiT của chúng tôi từ góc độ thực tế.

Order Receptive Field. Chúng tôi đề xuất một khái niệm mới trong cấu trúc dựa trên Mamba cho dữ liệu đa chiều. Cho rằng nhiều đường dẫn zigzag liên tục không gian khác nhau có thể tồn tại trong dữ liệu đa chiều, chúng tôi giới thiệu thuật ngữ Order Receptive Field biểu thị số lượng đường dẫn zigzag được sử dụng rõ ràng trong thiết kế mạng.

Nghiên cứu Ablation về Order Receptive Field và FPS/GPU-Memory. Như được mô tả trong Hình 6 (c,d), Zigzag Mamba liên tục duy trì tiêu thụ bộ nhớ GPU và tỷ lệ FPS của nó, ngay cả với Order Receptive Field tăng dần. Ngược lại, baseline chính của chúng tôi, Parallel Mamba, cùng với các biến thể như Bidirectional Mamba và Vision Mamba [70,123], trải qua sự giảm nhất quán trong FPS do tăng tham số. Đáng chú ý, Zigzag Mamba, với Order Receptive Field là 8, có thể hoạt động nhanh hơn mà không thay đổi tham số.

So sánh với các phương pháp dựa trên transformer. Chúng tôi hiển thị kết quả trong Bảng 5 về nhiệm vụ tạo sinh vô điều kiện. Phương pháp của chúng tôi đạt hiệu suất tương đương với các phương pháp dựa trên Transformer, với tiêu thụ bộ nhớ ít hơn đáng kể và ít FLOPS hơn.

4.3 Kết quả Chính
Kết quả Chính trên FacesHQ 1024×1024. Để làm rõ khả năng mở rộng của phương pháp chúng tôi trong khung Mamba và Stochastic Interpolant, chúng tôi cung cấp so sánh trên bộ dữ liệu độ phân giải cao (FacesHQ 1024×1024) trong Bảng 3. So sánh chính của chúng tôi là với Bidirectional Mamba, một giải pháp thường được sử dụng để áp dụng Mamba vào dữ liệu hình ảnh 2D [70,123]. Với mục đích điều tra khả năng mở rộng của Mamba ở độ phân giải lớn lên đến 1.024, chúng tôi sử dụng mô hình khuếch tán trên không gian tiềm ẩn 128×128 với kích thước patch là 2, dẫn đến 4.096 token. Mạng được đào tạo trên 16 GPU A100. Đáng chú ý, phương pháp của chúng tôi chứng minh kết quả vượt trội so với Bidirectional Mamba. Chi tiết về loss, đường cong FID, và visualization có thể được tìm thấy trong Phụ lục. Mặc dù bị hạn chế bởi hạn chế tài nguyên GPU, ngăn cản thời gian đào tạo dài hơn, chúng tôi dự đoán sự vượt trội nhất quán của Bidirectional Mamba với thời gian đào tạo mở rộng.

Bộ dữ liệu COCO. Để so sánh thêm hiệu suất của phương pháp chúng tôi, chúng tôi cũng đánh giá nó trên bộ dữ liệu phức tạp hơn và phổ biến hơn MS COCO. Chúng tôi so sánh với Bidirection Mamba làm baseline trong Bảng 4. Cần lưu ý rằng tất cả các phương pháp chia sẻ số lượng tham số gần như giống hệt nhau để so sánh công bằng. Chúng tôi đào tạo tất cả các phương pháp sử dụng 16 GPU A100. vui lòng kiểm tra Phụ lục 8.8 để biết chi tiết. Như được mô tả trong Bảng 4, phương pháp Zigzag-8 của chúng tôi vượt trội hơn Bidirectional Mamba cũng như Zigzag-1. Điều này cho thấy rằng việc phân bổ các sơ đồ quét khác nhau có thể mang lại những cải thiện đáng kể, do việc kết hợp thiên hướng quy nạp tốt hơn cho hình ảnh 2D trong Mamba.

Bộ dữ liệu UCF101. Trong Bảng 6, chúng tôi trình bày kết quả của mình trên bộ dữ liệu UCF101, đào tạo tất cả các phương pháp sử dụng 4 GPU A100, với khám phá khả năng mở rộng thêm được thực hiện sử dụng 16 GPU A100. Chúng tôi chủ yếu so sánh phương pháp của mình một cách nhất quán với Vision Mamba [123]. Để lựa chọn 3D Zigzag Mamba, vui lòng tham khảo Phụ lục 8.8. Đối với Factorized 3D Zigzag Mamba trong xử lý video, chúng tôi triển khai sơ đồ ssts để phân tách mô hình hóa không gian và thời gian. Sơ đồ này ưu tiên độ phức tạp thông tin không gian hơn thông tin thời gian, giả thuyết rằng sự dư thừa tồn tại trong miền thời gian. Kết quả của chúng tôi liên tục chứng minh hiệu suất vượt trội của phương pháp chúng tôi trong nhiều kịch bản khác nhau, nhấn mạnh tính phức tạp và hiệu quả của cách tiếp cận của chúng tôi.

5 Kết luận
Trong bài báo này, chúng tôi trình bày Mô hình Khuếch tán Zigzag Mamba, được phát triển trong khung Stochastic Interpolant. Trọng tâm ban đầu của chúng tôi là giải quyết vấn đề quan trọng của tính liên tục không gian. Sau đó chúng tôi thiết kế một khối Zigzag Mamba với quét theo lớp không đồng nhất để sử dụng tốt hơn thiên hướng quy nạp trong hình ảnh 2D. Hơn nữa, chúng tôi phân tách 3D Mamba thành 2D và 1D Zigzag Mamba để tạo điều kiện tối ưu hóa. Chúng tôi thiết kế thực nghiệm nhiều nghiên cứu ablation khác nhau để xem xét các yếu tố khác nhau. Cách tiếp cận này cho phép khám phá sâu hơn về lý thuyết Stochastic Interpolant. Chúng tôi hy vọng nỗ lực của mình có thể truyền cảm hứng cho việc khám phá thêm trong thiết kế mạng Mamba.

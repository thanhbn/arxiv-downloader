Học Không Giám Sát Dựa Trên Proxy Anchor cho Khám Phá Danh Mục Tổng Quát Liên Tục

Hyungmin Kim1,2 Sungho Suh3,4 Daehwan Kim2 Daun Jeong2 Hansang Cho2 Junmo Kim1

1Viện Khoa Học và Công Nghệ Tiên Tiến Hàn Quốc, Daejeon, Hàn Quốc
2Samsung Electro-Mechanics, Suwon, Hàn Quốc  
3Trung Tâm Nghiên Cứu Trí Tuệ Nhân Tạo Đức (DFKI), Kaiserslautern, Đức
4Khoa Khoa Học Máy Tính, RPTU Kaiserslautern-Landau, Kaiserslautern, Đức

{hyungmin83, junmo.kim}@kaist.ac.kr, sungho.suh@dfki.de
{daehwan85.kim, du33.jeong, hansang.cho}@samsung.com

Tóm tắt
Những tiến bộ gần đây trong học sâu đã cải thiện đáng kể hiệu suất của các ứng dụng thị giác máy tính khác nhau. Tuy nhiên, việc khám phá các danh mục mới trong kịch bản học tăng dần vẫn là một vấn đề thách thức do thiếu kiến thức trước về số lượng và bản chất của các danh mục mới. Các phương pháp hiện tại cho khám phá danh mục mới bị hạn chế bởi sự phụ thuộc vào các tập dữ liệu có nhãn và kiến thức trước về số lượng danh mục mới và tỷ lệ mẫu mới trong batch. Để giải quyết những hạn chế này và phản ánh chính xác hơn các kịch bản thực tế, trong bài báo này, chúng tôi đề xuất một phương pháp học tăng dần lớp không giám sát mới để khám phá các danh mục mới trên các tập không có nhãn mà không cần kiến thức trước. Phương pháp đề xuất tinh chỉnh bộ trích xuất đặc trưng và proxy anchor trên các tập có nhãn, sau đó chia các mẫu thành danh mục cũ và mới và phân cụm trên tập dữ liệu không có nhãn. Hơn nữa, exemplar dựa trên proxy anchor tạo ra các vector danh mục đại diện để giảm thiểu quên thảm khốc. Kết quả thí nghiệm chứng minh rằng phương pháp đề xuất của chúng tôi vượt trội hơn các phương pháp hiện đại trên các tập dữ liệu chi tiết dưới các kịch bản thực tế.

1. Giới thiệu
Các mạng neural sâu đã đạt được hiệu suất đáng kể trong các nhiệm vụ thị giác máy tính khác nhau. Tuy nhiên, các hệ thống hiện tại vẫn chịu những ràng buộc được giám sát thủ công và không xem xét các danh mục tăng dần liên tục. Để mở rộng đến môi trường thực tế, vẫn còn những khoảng cách cần khắc phục bằng cách vượt qua các ràng buộc và cải thiện khả năng của chúng trong các nhiệm vụ cơ bản. Cụ thể, con người vẫn thực hiện tốt hơn máy móc trong các kỹ năng nhận thức và nhóm đối tượng (ví dụ: nhận diện sản phẩm mới hoặc quần áo khi mua sắm và phân loại các đối tượng di chuyển không xác định khi lái xe).

Nhiều phương pháp khác nhau đã được đề xuất để giải quyết những hạn chế của các nhiệm vụ bằng cách xem xét hoàn cảnh thực tế, như được trình bày trong Hình 1 và Bảng 1. Cụ thể, Khám Phá Danh Mục Mới (NCD) [11, 12, 45] và Khám Phá Danh Mục Tổng Quát (GCD) [38, 7] nhằm nhận diện không chỉ các danh mục được huấn luyện trước mà còn khám phá các danh mục mới bằng cách sử dụng một tập dữ liệu cho trước. NCD xem xét một tập dữ liệu rời rạc trong đó các mẫu mới có nhãn và không có nhãn không có giao điểm với nhau. Ngược lại, GCD khai thác tập hợp chung với các danh mục giao nhau, làm cho GCD trở thành một nhiệm vụ phức tạp hơn NCD. Tuy nhiên, những phương pháp này không xem xét sơ đồ tăng dần lớp. NCD tăng dần lớp (class-iNCD) [34, 16] đã được đề xuất để áp dụng các danh mục tăng dần trên nhiệm vụ NCD, nhưng chúng vẫn tập trung vào việc cải thiện hiệu suất khám phá danh mục mới bằng cách sử dụng tập rời rạc, đây là một ràng buộc không thực tế. Để giải quyết vấn đề này, Grow and Merge (GM) [44] đề xuất một kịch bản khai thác tập dữ liệu chung không có nhãn trong nhiệm vụ khám phá danh mục mới tăng dần, được gọi là Khám Phá Danh Mục Liên Tục Tăng Dần Hỗn Hợp (CCD-MI). Tuy nhiên, hầu hết các phương pháp hiện tại đều yêu cầu kiến thức trước, chẳng hạn như số lượng lớp không có nhãn cho NCD và class-iNCD, hoặc tỷ lệ các mẫu mới trong batch cho CCD-MI. Những yêu cầu kiến thức trước như vậy không đủ để mô phỏng thế giới thực, vì chúng ta thiếu thông tin về các tập không có nhãn.

Để vượt qua những ràng buộc này, chúng tôi đề xuất một kịch bản mới đại diện tốt hơn cho hoàn cảnh thế giới thực bằng cách loại bỏ các ràng buộc về dữ liệu có sẵn. Chúng tôi giả định rằng các tập dữ liệu cho trước là các tập chung không có nhãn mà không cung cấp kiến thức trước về dữ liệu. Sử dụng kịch bản này, chúng tôi đề xuất một phương pháp học tăng dần lớp không giám sát mới để đồng thời giải quyết các vấn đề khám phá các danh mục mới tăng dần và giảm thiểu quên thảm khốc. Ngoài ra, chúng tôi tập trung vào việc nhận diện các đối tượng chi tiết, đây là một trường hợp sử dụng thực tế hơn cho các ứng dụng khác nhau trong ứng dụng thế giới thực.

Phương pháp đề xuất khai thác một sơ đồ học metric sâu, proxy anchor (PA) [19] trình bày sự hội tụ nhanh và đáng tin cậy và độ bền chống lại các mẫu nhiễu, và cũng xem xét mối quan hệ giữa các mẫu. Sau đó, chúng tôi chia dữ liệu không có nhãn thành các danh mục cũ và mới bằng cách sử dụng PA, kế thừa các đặc trưng phân biệt của các danh mục cũ. Độ tương tự cosine được đo giữa PA và các mẫu, sau đó các tập dữ liệu được tách ban đầu được thu được trên một tiêu chí. Để tách thêm, chúng tôi áp dụng một sơ đồ học nhãn nhiễu, và sau đó gán các dự đoán của mô hình trước đó và kết quả phân cụm bằng một phương pháp phi tham số cho các mẫu được phân loại cũ và mới, tương ứng. Để giảm thiểu quên, chúng tôi sử dụng một exemplar dựa trên PA, kế thừa các đặc trưng đại diện hơn. Trong kết quả thí nghiệm, chúng tôi chứng minh rằng phương pháp đề xuất vượt trội hơn hiện đại trong việc khám phá các danh mục mới và giảm thiểu quên trên các tập dữ liệu chi tiết khác nhau. Cụ thể, phương pháp đề xuất không yêu cầu bất kỳ kiến thức trước nào và xem xét học liên tục trên các tập dữ liệu chung không có nhãn, làm cho nó trở thành một giải pháp thực tế và thực tiễn hơn cho các kịch bản thế giới thực.

Những đóng góp chính của phương pháp đề xuất có thể được tóm tắt như sau:

• Chúng tôi giới thiệu một kịch bản mới, được gọi là Khám Phá Danh Mục Mới Tổng Quát Liên Tục (CGCD), rất phù hợp để giải quyết các thách thức của việc khám phá các danh mục mới trong các kịch bản thế giới thực bằng cách loại bỏ ràng buộc rằng dữ liệu không có nhãn chỉ thuộc về các danh mục mới.

• Chúng tôi đề xuất một phương pháp học không giám sát mới cho khám phá danh mục mới tăng dần không yêu cầu kiến thức trước về số lượng danh mục mới hoặc tỷ lệ dữ liệu lớp mới.

• Chúng tôi trình bày một phương pháp học nhãn nhiễu và học metric sâu để chia dữ liệu không có nhãn thành các danh mục cũ và mới, và cũng cho thấy việc giảm thiểu quên thảm khốc bằng cách sử dụng một exemplar dựa trên metric sâu.

• Phương pháp đề xuất vượt trội hơn các phương pháp hiện đại trong khám phá danh mục mới và giảm thiểu quên trên các tập dữ liệu chi tiết khác nhau.

2. Định nghĩa Vấn đề

2.1. Khám Phá Danh Mục Tổng Quát Liên Tục

Như được trình bày trong Hình 1 và Bảng 1, các sơ đồ môi trường khác nhau đã được đề xuất để mô phỏng hoàn cảnh thế giới thực. Các phương pháp đáng chú ý bao gồm NCD [11, 12, 45], GCD [38], class-iNCD [34, 16], và CCD [44]. NCD xem xét các tập dữ liệu rời rạc giữa các tập có nhãn và không có nhãn (tức là Yl ∩ Yu = ∅) và yêu cầu kiến thức trước về số lượng danh mục không có nhãn |Yu|. Ngược lại, GCD khai thác tập hợp chung (tức là Yl ∩ Yu ≠ ∅). Mặc dù GCD là một nhiệm vụ thách thức hơn NCD, nó vẫn không xem xét khám phá danh mục tăng dần liên tục.

Class-iNCD là một phần mở rộng của NCD cho sơ đồ học liên tục. Tuy nhiên, phương pháp này huấn luyện trên tập dữ liệu rời rạc dưới các giai đoạn tăng dần lớp và có yêu cầu về |Yu|. CCD cũng huấn luyện về khám phá các lớp mới dưới sơ đồ học liên tục với tập dữ liệu chung. Mặc dù CCD không yêu cầu |Yu|, nó vẫn cần tỷ lệ dữ liệu lớp mới trong một batch như kiến thức trước, được sử dụng để lọc dữ liệu.

Để giải quyết những hạn chế này, chúng tôi đề xuất một vấn đề thách thức hơn, được đặt tên là Khám Phá Danh Mục Mới Tổng Quát Liên Tục (CGCD), gần gũi hơn với hoàn cảnh thế giới thực. Trong CGCD, chúng tôi khai thác tập dữ liệu chung không có nhãn trong các bước tăng dần mà không cung cấp bất kỳ kiến thức trước nào và nhằm khám phá các lớp mới. Công thức này đại diện hơn cho các kịch bản thế giới thực, nơi chúng ta không biết về số lượng danh mục không có nhãn và đặc điểm của tập dữ liệu.

2.2. Thiết lập Khám Phá Danh Mục Tổng Quát Liên Tục

Các tập dữ liệu chi tiết bao gồm các đối tượng tương tự, chẳng hạn như chó [17], cảnh trong nhà [31], xe cộ [26], và chim [39], trong hoàn cảnh bị ràng buộc. So với các tập dữ liệu thô như CIFAR [20] và ImageNet [21], các tập dữ liệu chi tiết gần gũi hơn với các kịch bản thế giới thực. Do đó, chúng tôi tập trung vào huấn luyện và khám phá các lớp mới với các tập dữ liệu chi tiết để mô phỏng tốt hơn hoàn cảnh thế giới thực.

CGCD sử dụng tập dữ liệu chung không có nhãn trong các bước tăng dần, và Bảng 2 mô tả việc phân chia tập dữ liệu được sử dụng trong khám phá danh mục tăng dần một lần. Đầu tiên, tập hợp các lớp được phân chia thành các lớp cũ và các lớp mới với một tỷ lệ nhất định, ví dụ, 8:2. Bước ban đầu sử dụng tập dữ liệu có nhãn D0 chỉ bao gồm các lớp cũ. Sau đó, bước tăng dần tiếp theo sử dụng tập dữ liệu không có nhãn D1 bao gồm cả các lớp cũ và các lớp mới, phản ánh các kịch bản thế giới thực thực tế và thách thức hơn. Yếu tố chính của phương pháp đề xuất là quyết định xem điểm dữ liệu không có nhãn thuộc về các lớp cũ (đã thấy) hay các lớp mới (chưa thấy). Các mẫu thuộc về các lớp cũ được gán cho tập dữ liệu có nhãn D0 và tập dữ liệu không có nhãn D1, và phần còn lại của tất cả các mẫu lớp mới được gán cho D1. Ở đây việc chọn 8:2 là một ví dụ tùy ý, và điều quan trọng cần lưu ý là tỷ lệ này chỉ để tạo dữ liệu và không được tiết lộ cho các phương pháp học.

3. Phương pháp

Như được mô tả trong Hình 2, phương pháp đề xuất của chúng tôi bao gồm ba bước: bước ban đầu, bước khám phá danh mục mới, và bước tăng dần danh mục. Trong bước ban đầu, chúng tôi tinh chỉnh một mô hình được huấn luyện trước trên tập dữ liệu có nhãn D0 = {(x, y) ∈ Xl × Yl}, và thu được vector nhúng z bằng cách sử dụng mô hình f(·), ký hiệu là z = f0(x). Sau đó chúng tôi sử dụng các vector này để huấn luyện PA [19] của mỗi danh mục, được biểu diễn là p = g0(z), và cũng xây dựng các exemplar đại diện tốt. Trong bước khám phá danh mục mới tiếp theo, các tập dữ liệu chung không có nhãn cho trước được ký hiệu là D1 = {x|x ∈ Xu}. Chúng tôi đầu tiên tách chúng thành các danh mục cũ và mới thông qua việc tách ban đầu và việc tách tinh. Vì các tập được tách không có nhãn, chúng tôi gán nhãn giả cho các lớp cũ và mới bằng cách sử dụng dự đoán mô hình trước đó và kết quả phân cụm phi tham số, tương ứng.

Trong bước tăng dần danh mục, tập thu được được huấn luyện để cải thiện hiệu suất khám phá các danh mục mới. Để tránh quên thảm khốc, chúng tôi khai thác các đặc trưng được tạo ra bởi exemplar và chưng cất đặc trưng giữa các mô hình sớm hơn và mới. Mô hình đề xuất không yêu cầu bất kỳ kiến thức trước nào, chẳng hạn như |Yu| và tỷ lệ các mẫu lớp mới trong một batch. Chúng tôi đánh giá hiệu suất của phương pháp đề xuất bằng cách sử dụng tập dữ liệu xác thực, bao gồm tất cả các danh mục.

3.1. Bước Ban đầu: Tinh chỉnh

Các phương pháp NCD hiện tại không tính đến các danh mục nhiễu, chẳng hạn như những danh mục được phân loại từ cũ thành mới hoặc từ mới thành cũ, có thể làm suy giảm hiệu suất khám phá mới và tích lũy lỗi trong quy trình liên tục. Để giải quyết những hạn chế này, trong công trình này, chúng tôi đề xuất một phương pháp mới tận dụng lợi ích của PA để bổ sung và cải thiện các phương pháp hiện tại. PA là một phương pháp học metric kết hợp các phương pháp dựa trên proxy và cặp để đạt được sự hội tụ nhanh chóng và đáng tin cậy, và độ bền chống lại các mẫu nhiễu, và xem xét mối quan hệ giữa dữ liệu để trích xuất thông tin ngữ nghĩa có ý nghĩa.

Theo phương pháp này, vector nhúng z từ mô hình ban đầu f0 được huấn luyện để ánh xạ đến mỗi proxy anchor p = g0(z). Đặt tập hợp tất cả các proxy anchor là P0 trong dữ liệu có nhãn D0. Theo cách này, số lượng proxy anchor của D0 là số lượng lớp của tập có nhãn (tức là |P0| = |Yl|) trong bước ban đầu. Chúng tôi huấn luyện mô hình và proxy anchor bằng cách sử dụng hàm mất mát sau được định nghĩa trong [19]:

L0pa(Z0) = 1/|P0+| ∑p∈P0+ log(1 + ∑z∈Z0+p e^(-α(s(z,p)-δ))) + 1/|P0| ∑p∈P0 log(1 + ∑z∈Z0-p e^(α(s(z,p)+δ))) (1)

trong đó δ > 0 là một margin và α > 0 là một hệ số tỷ lệ. Hàm s(·,·) chỉ điểm số tương tự cosine. P0+ đại diện cho các PA cùng lớp (ví dụ: tích cực) trong batch. Mỗi proxy p chia tập vector nhúng Z0 thành Z0+p và Z0-p = Z0 - Z0+p. Z0+p ký hiệu các điểm nhúng cùng lớp với proxy anchor p. Số hạng đầu nhằm kéo p và dữ liệu tích cực khó tương tự nhưng khác biệt lại gần nhau, trong khi số hạng cuối là để đẩy p và các negative tương tự nhưng khó ra xa.

3.2. Bước Khám Phá Danh Mục Mới

Tách biệt: Trong quy trình này, chúng tôi nhằm chia tập dữ liệu chung D1 cho trước thành các danh mục mới và cũ mà không cần bất kỳ kiến thức trước nào. Chúng tôi tiến hành nhiệm vụ này trong hai giai đoạn: tách ban đầu và tách tinh. Trong tách ban đầu, chúng tôi tính toán độ tương tự cosine giữa p và mỗi vector nhúng zi ∈ Z1, trong đó zi = f0(xi) và xi ∈ D1. Vì tập hợp các proxy anchor P0 đại diện cho các danh mục cũ, chúng tôi phân loại một mẫu vào lớp cũ nếu điểm số tương tự tối đa của zi lớn hơn một ngưỡng ε. Chúng tôi đặt ε = 0 vì nó là trung vị của phạm vi điểm số. Tách ban đầu được định nghĩa là:

ỹi = {0, nếu maxp∈P0(s(zi, p)) ≥ ε = 0; 1, ngược lại} (2)

Để có được một tập dữ liệu mới và cũ sạch hơn, chúng tôi đề xuất một sơ đồ gán nhãn nhiễu, tách tinh, bao gồm một huấn luyện lặp của một bộ phân loại dựa trên perceptron đa lớp đơn giản (MLP) m(·) trên tập dữ liệu nhị phân. Tách ban đầu dẫn đến việc tách nhiễu và không chính xác, như được hiển thị trong Hình 3 (a). Trong số đó, chỉ có dữ liệu ở cả hai đầu của phổ được giả định là sạch và được sử dụng để huấn luyện bộ phân loại. Mất mát của mạng tách m(·) được định nghĩa như sau:

Lsp = -Ezc∈Z1c[ỹc log(m(zc)) + (1 - ỹc) log(1 - m(zc))] (3)

trong đó zc ký hiệu các vector nhúng sạch, và Z1c đại diện cho tập hợp các vector sạch. ỹc chỉ nhãn giả của dữ liệu sạch. Sau huấn luyện khởi động, bộ phân loại được huấn luyện với các nhãn giả được gán lại và dữ liệu sạch hơn, được chia với mô hình hỗn hợp Gaussian (GMM). Kết quả là, Hình 3 (b) cho thấy kết quả tách sạch hơn.

Gán nhãn giả: Sau việc tách, cả danh mục cũ D1old và danh mục mới D1new vẫn không có nhãn. Do đó, chúng tôi sử dụng nhãn giả để gán nhãn cho mỗi mẫu. Đối với D1old, chúng tôi sử dụng các dự đoán của mô hình trước đó và proxy anchor để gán nhãn giả. Ngược lại, chúng tôi sử dụng một phương pháp phân cụm phi tham số có tên Affinity propagation [9] để gán nhãn giả cho D1new. Theo cách này, phương pháp đề xuất của chúng tôi không yêu cầu bất kỳ kiến thức trước nào. Cuối cùng, từ kết quả phân cụm, chúng tôi thu được một ước tính về số lượng danh mục mới, ký hiệu là |Ŷn|.

3.3. Bước Tăng Dần Danh Mục

Huấn luyện mô hình và PA đã sửa đổi: Để cải thiện hiệu suất khám phá các danh mục mới, chúng tôi sửa đổi mô hình vì mô hình trước đó chỉ có PA cho |Yl| lớp và không thể phân loại các lớp mới. Chúng tôi thêm p mới cho |Ŷn| lớp, tăng tổng số PA như |P1| = |Yl| + |Ŷn|. Hàm mất mát để huấn luyện mô hình đã sửa đổi f1 và PA p = g1(z) được công thức hóa lại như sau:

L1pa(Z1) = 1/|P1+| ∑p∈P1+ log(1 + ∑z∈Z1+p e^(-α(s(z,p)-δ))) + 1/|P1| ∑p∈P1 log(1 + ∑z∈Z1-p e^(α(s(z,p)+δ))) (4)

Tránh quên: Trong sơ đồ học liên tục, việc giảm thiểu quên thảm khốc là điều cần thiết. Chúng tôi áp dụng phát lại đặc trưng, tận dụng thông tin PA thuộc về các danh mục cũ. Mỗi p được huấn luyện tốt kế thừa sức mạnh biểu diễn cho mỗi danh mục. Chúng tôi sử dụng mỗi p để tạo ra các đặc trưng bằng cách tuân theo phân phối Gaussian N(p0, σ²), p0 ∈ P0. Số lượng đặc trưng được tạo ra được xác định dựa trên cân bằng dữ liệu, ví dụ, số lượng mẫu được phân loại mới trong một batch. Các đặc trưng được tạo ra được nối thành một batch, và mô hình và PA được huấn luyện bằng cách sử dụng hàm mất mát sau:

L1ex(Z̃) = L1pa(Z̃), Z̃ = {z̃ ~ N(p0, σ²)} (5)

Ngoài ra, chúng tôi sử dụng chưng cất các vector nhúng được trích xuất từ f1 hiện tại và mô hình trước đó f0. Mất mát chưng cất Lkd được mô tả như sau:

L1kd(zo) = -Ezo∈Z1old ||z⁰o - zo||² = -Exo∈D1old ||f0(xo) - f1(xo)||² (6)

trong đó z⁰ đại diện cho vector nhúng cho mạng đặc trưng trước đó cố định f0. Z1old ký hiệu dữ liệu đã thấy từ Z1 = {Z1old ∪ Z1new}.

Kết luận, mất mát bao gồm ba mất mát khác nhau trong bước khám phá danh mục liên tục. Một mất mát là để huấn luyện PA và mô hình trên D1, những mất mát khác là để tránh quên bằng cách sử dụng các đặc trưng được tạo ra và chưng cất kiến thức. L1 được mô tả như sau:

L1 = L1pa(Z1) + L1ex(Z̃) + L1kd(zo) (7)

4. Kết quả Thí nghiệm

4.1. Chi tiết Triển khai

Chúng tôi sử dụng các kỹ thuật augmentation được sử dụng rộng rãi, bao gồm cắt ngẫu nhiên sau padding và lật ngang ngẫu nhiên. Tất cả các thí nghiệm được huấn luyện trong 60 epoch bằng cách sử dụng optimizer AdamW với weight decay được đặt là 0.0001. Tỷ lệ học ban đầu được đặt là 0.0001 cho mô hình f(·), trong khi đối với PA, nó được đặt là 0.01. Tỷ lệ học được giảm với hệ số 0.5 mỗi năm epoch. Chúng tôi sử dụng ngưỡng ε chỉ một lần cho việc tách ban đầu để chia tập thành các danh mục cũ và mới, và chúng tôi đặt nó là 0 cho tất cả các tập dữ liệu và mạng. Đối với tách tinh, chúng tôi sử dụng kiến trúc mạng dựa trên MLP bao gồm hai lớp dày đặc với một lớp chuẩn hóa batch. Mô hình được huấn luyện trong ba epoch bằng cách sử dụng AdamW với tỷ lệ học 0.0001. Các siêu tham số cho PA, α và δ, được đặt lần lượt là 32 và 0.1.

Để so sánh công bằng các phương pháp khác nhau, chẳng hạn như NCD, class-iNCD, và CCD, chúng tôi tuân theo các siêu tham số và kiến trúc mạng của các triển khai gốc, tham khảo các bài báo để biết chi tiết. Tất cả các hiệu suất được báo cáo là kết quả trung bình qua ba lần chạy.

4.2. Các Thước đo Đánh giá

Chúng tôi đánh giá các phương pháp bằng cách sử dụng các thước đo dựa trên đo lường độ chính xác cụm, được gọi là thuật toán gán Hungarian [22]. Thước đo đánh giá được định nghĩa như sau:

Mt = 1/|D| ∑i=1^|D| I(yi = h*(yi*)) (8)

trong đó |D| là kích thước của tập dữ liệu xác thực D và h* là gán tối ưu. Vậy, Mt đo lường độ chính xác cụm tại bước t trên D. Theo cách này, Mall và Mo chỉ các thước đo độ chính xác cụm của toàn bộ và các danh mục cũ bằng cách sử dụng Mt, tương ứng. Hơn nữa, chúng tôi sử dụng hai thước đo khác, Mf và Md, được đề xuất trên GM [44] và được mô tả như sau:

Mf = maxt{M⁰o - Mto}, (9)
Md = 1/|T| ∑i=T Min. (10)

trong đó M⁰o và Mto là độ chính xác cụm lớp cũ tại bước ban đầu và bước tăng dần danh mục t, tương ứng. Vậy Mf đo lường các giá trị quên tối đa cho các danh mục cũ trong toàn bộ bước và nên đủ thấp; nếu không, phương pháp không có giá trị trong các ứng dụng thực tế. Trong Phương trình (10), |T| là số bước tăng, và Md đánh giá hiệu suất trung bình của khám phá danh mục mới trong các tập dữ liệu chung không có nhãn trong mỗi bước. Điều đó có nghĩa là phương pháp cao hơn, phương pháp phù hợp hơn trong các ứng dụng thế giới thực.

4.3. So sánh với Các Phương pháp Hiện đại

Chúng tôi tiến hành một loạt thí nghiệm để so sánh hiệu suất độ chính xác cụm của phương pháp đề xuất với các phương pháp hiện đại, như được trình bày trong Bảng 1. Trong các thí nghiệm, chúng tôi loại trừ nhiệm vụ GCD, bao gồm XCon, vì nó tập trung vào việc khám phá các danh mục mới được pha trộn với các tập dữ liệu có nhãn và không có nhãn và đánh giá hiệu suất khám phá không biết chỉ trên các tập dữ liệu huấn luyện, không phải tập dữ liệu xác thực, trong các bài báo của họ. Do đó, chúng tôi so sánh phương pháp đề xuất của chúng tôi với các phương pháp khác, bao gồm Dual rank NCD (DRNCD) [45], FRoST [34], và GM, đây là các phương pháp đại diện ghi lại kết quả hiện đại của mỗi nhiệm vụ.

Chúng tôi đầu tiên đánh giá thiết lập danh mục tăng dần một bước và báo cáo kết quả so sánh trong Bảng 3. Phương pháp có giám sát là thiết lập của một cách học liên tục có giám sát, theo nghĩa đen. Chúng tôi quan sát thấy quên thảm khốc trong học có giám sát. DRNCD là một trong những phương pháp NCD và ghi lại hiệu suất xuất sắc của Md trên MIT67, Stanford Dogs, và FGVC aircraft. Tuy nhiên, phương pháp này yêu cầu kiến thức trước về số lượng danh mục mới và không xác định các lớp cụ thể, mà chỉ biết liệu các mẫu có được bao gồm trong danh mục mới hay không. Do đó, kết quả không được coi là vượt trội. Thay vào đó, phương pháp cho thấy kết quả cao nhất của Mf, có nghĩa là phương pháp tập trung vào việc học các danh mục mới mà không xem xét việc ngăn chặn quên kiến thức danh mục trước đó. Về mặt này, NCD không đủ để mở rộng các sơ đồ học tăng dần lớp mới. FRoST cho thấy kết quả cạnh tranh của việc khám phá các lớp mới và kết quả quên giảm Mf trên tất cả các tập dữ liệu so với DRNCD. Tuy nhiên, xem xét kiến thức cần thiết, các kết quả thước đo khác, Mall và Mo không cạnh tranh. GM đề xuất thiết lập CCD, tương tự nhất với CGCD, từ góc độ số lượng danh mục mới không biết và khám phá các danh mục mới và cũ trên các tập dữ liệu không có nhãn mới. Tuy nhiên, phương pháp này yêu cầu một tham số quan trọng, đó là tỷ lệ các mẫu danh mục mới trên tập dữ liệu mới. Mà không xem xét tỷ lệ, GM ghi lại kết quả thấp nhất của Mall, Mo, và Md.

Phương pháp đề xuất cho thấy hiệu suất xuất sắc trên các tập dữ liệu khác nhau mà không yêu cầu bất kỳ thông tin trước nào về các tập dữ liệu không có nhãn mới đến. Phương pháp của chúng tôi ghi lại Mf tốt thứ hai trên tập dữ liệu CUB-200 và Mf tốt nhất trên các tập dữ liệu khác, chẳng hạn như MIT67, Dogs, và FGVC aircraft, bởi các hiệu ứng của exemplar dựa trên PA. Về Md, phương pháp này cũng cạnh tranh và so với GM, có thiết lập tương tự nhất với phương pháp của chúng tôi.

Để đánh giá phương pháp đề xuất một cách định tính, chúng tôi đã phân cụm tập dữ liệu đánh giá bằng cách sử dụng tập dữ liệu CUB-200. Trong Hình 4, phương pháp của chúng tôi đã khám phá tốt các danh mục mới và phân cụm chúng một cách chính xác. Mỗi hàng được phân cụm thành cùng một danh mục, và các lớp là các danh mục mới trên tập dữ liệu đánh giá. Năm cột bên trái được phân cụm tốt, trong khi hai cột cuối thì không. Hình ảnh cột thứ sáu vẫn hợp lý, nhưng các cột cuối là trường hợp tệ nhất.

4.4. Khám Phá Danh Mục Mới Hai Bước

Chúng tôi trình bày một thí nghiệm khám phá danh mục tăng dần hai bước trên tập dữ liệu CUB-200 bằng cách sử dụng ResNet-18. Cấu hình tập dữ liệu phức tạp hơn vì các tập dữ liệu là các tập chung trong các bước tăng dần. Bước ban đầu, bước tăng dần đầu tiên, và bước tăng dần thứ hai có các lớp mới trong mỗi bước, với tỷ lệ 8:1:1, tương ứng. Mỗi bước có tập dữ liệu riêng và được chỉ định là D0, D1, và D2. Các mẫu thuộc về các lớp có nhãn mới trong bước ban đầu được gán cho D0, D1, và D2 với tỷ lệ 8:1:1. Tương tự, các mẫu thuộc về các lớp mới trong bước tăng dần đầu tiên được gán cho D1, và D2 với tỷ lệ 8:2. Cuối cùng, phần còn lại của các mẫu được gán cho D2.

Hình 5 mô tả hiệu suất của các thí nghiệm. Vì mỗi bước tăng dần được huấn luyện trong 60 epoch, có những giảm sâu tại epoch thứ 60 khi các PA mới được thêm vào. Ngoài ra, độ chính xác cụm của các danh mục cũ, thuộc về D0, giảm khoảng 20%. Lý do là số lượng danh mục cũ trong bước tăng dần thứ hai tăng so với bước đầu tiên. Exemplar không thể tập trung chỉ vào việc tạo ra các đặc trưng của D0. Tuy nhiên, hiệu suất của Md tăng đều đặn.

4.5. Nghiên cứu Ablation

Hiệu quả của việc tách: Chúng tôi tiến hành một nghiên cứu ablation để cho thấy hiệu quả của bộ tách đề xuất của chúng tôi, bao gồm sự kết hợp của hai phương pháp khác nhau: điểm số tương tự cosine và một bộ tách nhị phân sử dụng phương pháp nhãn nhiễu. Các thí nghiệm ablation được thiết kế sao cho một chỉ sử dụng điểm số tương tự cosine, và một cái khác sử dụng cả hai phương pháp. Như được hiển thị trong Bảng 4, phương pháp sử dụng cả hai phương pháp trình bày cải thiện trong cả hiệu suất khám phá cũ và mới. Kết quả tiết lộ hiệu quả của gán nhãn nhiễu cho việc tách dữ liệu.

Hiệu quả của Exemplar Proxy anchor: Để giảm thiểu quên thảm khốc, các phương pháp khác nhau, chẳng hạn như replay [2], prototype [32, 34], và pseudo-latents [16], đã được đề xuất. Hầu hết các phương pháp này khai thác trung bình được tính toán của các vector nhúng đặc trưng hoặc các giá trị dựa trên dữ liệu đầu vào. Tuy nhiên, chúng tôi đề xuất một phương pháp exemplar dựa trên PA mới và đánh giá hiệu quả của nó. Như được hiển thị trong Bảng 5, phương pháp không có exemplar ghi lại hiệu suất khám phá mới cao nhất nhưng cũng cho thấy quên cao nhất. Áp dụng một phương pháp exemplar chung sử dụng các giá trị trung bình và độ lệch chuẩn từ tập dữ liệu trước đó, Mf giảm nhẹ, nhưng Md là thấp nhất. Tuy nhiên, phương pháp đề xuất của chúng tôi với exemplar dựa trên PA ghi lại Mf tốt nhất và Md cạnh tranh. Chúng tôi phân tích rằng các PA có đại diện của mỗi cụm vì PA kế thừa mối quan hệ giữa dữ liệu với dữ liệu và sau đó các con số đại diện của mỗi lớp. Do đó, phương pháp dựa trên PA của chúng tôi dẫn đến việc giảm thiểu quên, và chúng tôi xác nhận rằng đó là một phương pháp phù hợp.

Độ bền của các biến thể tỷ lệ pha trộn lớp và mẫu: Nói chung, khả năng nhận diện các danh mục mới phụ thuộc phần lớn vào một mô hình ban đầu mạnh mẽ và được huấn luyện tốt với các tập dữ liệu mục tiêu. Càng nhiều lớp và mẫu được bao gồm trong tập dữ liệu huấn luyện ban đầu D0, mô hình càng học tốt các đặc trưng đại diện để phù hợp với các tập. Để đánh giá độ bền của mô hình đề xuất, chúng tôi tiến hành các thí nghiệm với các biến thể của số lượng mẫu và lớp trong D0. Như được mô tả trong Bảng 6, việc giảm số lượng lớp và dữ liệu trong tập có nhãn đã giảm việc khám phá các lớp mới và độ chính xác phân cụm khi số lượng dữ liệu mới không có nhãn tăng. Mặt khác, quên thảm khốc có thể tăng vì số lượng dữ liệu mới tăng. Tuy nhiên, quên được duy trì trong một ranh giới hợp lý, cho thấy hiệu quả của exemplar dựa trên PA của chúng tôi. Kết quả cho thấy rằng phương pháp của chúng tôi có độ bền của các biến thể.

5. Nghiên cứu liên quan

5.1. Khám Phá Danh Mục Mới

Các kỹ thuật NCD đã được đề xuất để phân loại dữ liệu với các ràng buộc khác nhau trên dữ liệu không có nhãn. Một danh mục của các phương pháp trình bày huấn luyện trước mô hình trên tập có nhãn và tinh chỉnh nó trên tập không có nhãn bằng cách sử dụng các mất mát phân cụm không giám sát [43, 14, 13, 24, 25]. Một danh mục khác giả định tính khả dụng của cả dữ liệu có nhãn và không có nhãn, và huấn luyện mạng chung với mất mát lớp mới có nhãn trong sơ đồ bán giám sát [11, 46, 47, 15, 8, 45]. Han et al. [12] đề xuất chuyển giao kiến thức từ dữ liệu có nhãn sang không có nhãn bằng cách sử dụng thống kê xếp hạng trong giai đoạn học chung. Gần đây, GCD [38] và XCon [7] giải quyết kịch bản thực tế hơn của các tập dữ liệu chung và phân biệt các lớp đã biết và không biết bằng cách sử dụng kiến thức trước. Tuy nhiên, những phương pháp này không xem xét sơ đồ học liên tục. Để giải quyết hạn chế, FRoST [34] và NCDwF [16] đóng băng các bộ trích xuất đặc trưng và thêm đầu thứ hai cho mỗi lớp mới, nhiều như số lượng danh mục mới cho trước. Tuy nhiên, các phương pháp sử dụng các tập rời rạc. GM [44] đề xuất xem xét khám phá danh mục mới trên các tập dữ liệu chung, nhưng vẫn yêu cầu kiến thức trước, chẳng hạn như tỷ lệ các mẫu mới.

5.2. Truy xuất Hình ảnh

Hầu hết các phương pháp truy xuất hình ảnh đã sử dụng học metric và có thể được phân loại thành hai phương pháp. Các phương pháp dựa trên cặp khai thác mất mát contrastive [3, 5, 10] và mất mát triplet [35, 40], kéo các cặp dữ liệu trong cùng một lớp lại gần nhau và đẩy những cặp trong các lớp khác nhau ra xa. Các phương pháp dựa trên nhiều dữ liệu [36, 29] đề xuất xem xét mối quan hệ giữa nhiều dữ liệu. Các phương pháp dựa trên toàn bộ dữ liệu [42, 41] trình bày xem xét tất cả dữ liệu trong một batch, tận dụng mối quan hệ ngữ nghĩa chi tiết giữa chúng trong khi yêu cầu chi phí tính toán cao và hội tụ chậm. Ngược lại, các phương pháp dựa trên proxy [27, 30, 1] sử dụng ít proxy hơn so với tập huấn luyện, giảm độ phức tạp huấn luyện. Trong khi những phương pháp này cải thiện hội tụ huấn luyện, chúng không xem xét mối quan hệ dữ liệu-với-dữ liệu, vì mỗi dữ liệu được liên kết với proxy của nó. PA [19] kế thừa sức mạnh của các phương pháp dựa trên cặp và proxy, đạt được hội tụ nhanh và đáng tin cậy, độ bền chống lại dữ liệu nhiễu, và tận dụng mối quan hệ dữ liệu-với-dữ liệu phong phú.

5.3. Nhãn Nhiễu

Các phương pháp được đề xuất gần đây cho việc học với nhãn nhiễu đã nổi bật tầm quan trọng của việc phân biệt giữa dữ liệu có nhãn sạch và nhiễu để cải thiện hiệu suất. DivideMix [23] sử dụng GMM để phân biệt giữa dữ liệu có nhãn sạch và nhiễu và coi cái sau là không có nhãn cho học bán giám sát. AugDesc [28] sử dụng augmentation dữ liệu để tăng cường sự khác biệt giữa dữ liệu có nhãn sạch và nhiễu, trong khi INCV [4] giới thiệu cross-validation để tách dữ liệu sạch khỏi dữ liệu huấn luyện nhiễu. SplitNet [18] tận dụng một mạng compact để cảm nhận sự khác biệt giữa nhãn sạch và nhiễu, cải thiện hiệu suất mô hình bằng cách phân biệt nhiễu chính xác hơn.

6. Kết luận

Trong bài báo này, chúng tôi trình bày một kịch bản học liên tục mới, xem xét NCD trên các tập dữ liệu chung không có nhãn mà không có bất kỳ kiến thức trước nào về tập dữ liệu. Khung của chúng tôi sử dụng PA để chia các danh mục đã biết và mới, dẫn đến các danh mục được phân cụm tốt và được gán nhãn giả tốt giúp giảm thiểu quên thảm khốc. Chúng tôi tiếp tục tinh chỉnh việc chia tập dữ liệu bằng cách áp dụng một sơ đồ gán nhãn nhiễu. Phương pháp đề xuất của chúng tôi vượt trội hơn các phương pháp hiện đại về khám phá danh mục mới và quên. Trong khi DeepDPM [33] gần đây đã cho thấy hiệu suất xuất sắc trên các nhiệm vụ phân cụm phi tham số, chúng tôi tin rằng phương pháp đề xuất của chúng tôi có thể đạt được hiệu suất tốt hơn bằng cách áp dụng các cách phân cụm tốt hơn. Trong công việc tương lai, chúng tôi dự định đánh giá phương pháp của chúng tôi bằng cách áp dụng một cách phân cụm tốt hơn.

Lời cảm ơn
Công trình này được tài trợ bởi Samsung Electro-Mechanics và được hỗ trợ một phần bởi Carl-Zeiss Stiftung dưới dự án Sustainable Embedded AI (P2021-02-009).

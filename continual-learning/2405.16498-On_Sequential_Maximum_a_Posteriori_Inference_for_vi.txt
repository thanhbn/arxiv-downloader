# Về Suy luận Maximum a Posteriori Tuần tự cho Học liên tục

Menghao Waiyan William Zhu
Tsinghua Shenzhen International Graduate School
Shenzhen, Trung Quốc
zhumh22@mails.tsinghua.edu.cn

Ercan Engin Kuruoğlu
Tsinghua Shenzhen International Graduate School
Shenzhen, Trung Quốc
kuruoglu@sz.tsinghua.edu.cn

**Tóm tắt** — Chúng tôi công thức hóa suy luận maximum a posteriori tuần tự như một đệ quy của các hàm mất mát và rút gọn bài toán học liên tục thành việc xấp xỉ hàm mất mát trước đó. Sau đó chúng tôi đề xuất hai phương pháp không dùng coreset: hợp nhất bậc hai autodiff, sử dụng xấp xỉ bậc hai chính xác và đầy đủ, và hợp nhất neural, sử dụng xấp xỉ mạng neural. Các phương pháp này không có khả năng mở rộng theo kích thước mạng neural, và chúng tôi nghiên cứu chúng cho các tác vụ phân loại kết hợp với một bộ trích xuất đặc trưng cố định đã được huấn luyện trước. Chúng tôi cũng giới thiệu các chuỗi tác vụ cổ điển đơn giản nhưng đầy thử thách dựa trên bộ dữ liệu Iris và Wine. Chúng tôi thấy rằng hợp nhất neural hoạt động tốt trong các chuỗi tác vụ cổ điển, nơi chiều đầu vào nhỏ, trong khi hợp nhất bậc hai autodiff hoạt động nhất quán tốt trong các chuỗi tác vụ hình ảnh với bộ trích xuất đặc trưng cố định đã được huấn luyện trước, đạt được hiệu suất tương đương với huấn luyện maximum a posteriori kết hợp trong nhiều trường hợp.

**Từ khóa** — Suy luận Bayesian, học tăng dần theo lớp, học liên tục, học tăng dần theo miền, mạng neural

## I. GIỚI THIỆU

Khi một mạng neural (bao gồm mô hình tuyến tính tổng quát, về cơ bản là một mạng neural không có lớp ẩn) được huấn luyện trên một tác vụ và tinh chỉnh trên một tác vụ mới, nó mất hiệu suất dự đoán trên tác vụ cũ. Điều này được gọi là quên thảm khốc [1] và có thể được ngăn chặn bằng cách huấn luyện kết hợp trên tất cả các tác vụ, nhưng dữ liệu trước đó có thể không truy cập được do các hạn chế về tính toán hoặc quyền riêng tư. Do đó, chúng ta muốn học từ một chuỗi các tác vụ với quyền truy cập hạn chế hoặc không có quyền truy cập vào dữ liệu trước đó. Điều này được gọi là học liên tục hoặc học tăng dần hoặc học suốt đời.

Đối với các tác vụ phân loại, ba loại cài đặt học liên tục thường được nghiên cứu [2]:
1) Học tăng dần theo tác vụ, trong đó ID tác vụ được cung cấp và các lớp thay đổi giữa các tác vụ
2) Học tăng dần theo miền, trong đó ID tác vụ không được cung cấp và các lớp vẫn giữ nguyên giữa các tác vụ nhưng phân phối dữ liệu đầu vào thay đổi giữa các tác vụ
3) Học tăng dần theo lớp, trong đó ID tác vụ không được cung cấp và các lớp thay đổi giữa các tác vụ

Ví dụ, Split MNIST là một chuỗi năm tác vụ được tạo từ bộ dữ liệu MNIST, trong đó tác vụ đầu tiên bao gồm hình ảnh của số không và số một, tác vụ thứ hai bao gồm hình ảnh của số hai và số ba, v.v. Trong cài đặt tăng dần theo tác vụ, ID tác vụ 1-5 được cung cấp, và mạng neural chỉ cần quyết định giữa hai lớp cho mỗi ID tác vụ. Thông thường, một mạng neural đa đầu với năm đầu (một đầu cho mỗi tác vụ) được sử dụng trong cài đặt này. Trong cài đặt tăng dần theo miền, tác vụ là phân loại chữ số chẵn và lẻ mà không có quyền truy cập vào ID tác vụ. Trong cài đặt tăng dần theo lớp, tác vụ là phân loại tất cả mười chữ số mà không có quyền truy cập vào ID tác vụ. Trong các cài đặt này, một mạng neural đơn đầu thường được sử dụng.

Học tăng dần theo tác vụ đã bị chỉ trích vì ID tác vụ làm cho bài toán học liên tục trở nên dễ dàng hơn [3]. Thực tế, nếu chỉ có một lớp cho mỗi tác vụ, thì ID tác vụ có thể được sử dụng để đưa ra dự đoán hoàn hảo. Hơn nữa, trong thực tế, không có khả năng ID tác vụ có thể truy cập được. Ví dụ, trong Split MNIST, chúng ta muốn phân loại tất cả mười chữ số cuối cùng thay vì chỉ cho biết hai chữ số nào trong mỗi tác vụ. Phù hợp với các tiêu chí được đề xuất trong [3], chúng tôi tập trung vào học tăng dần theo miền và theo lớp với các mạng neural đơn đầu trên các chuỗi tác vụ có hơn hai tác vụ tương tự và không có quyền truy cập vào dữ liệu trước đó.

Đối với một mạng neural đơn đầu với kiến trúc cố định, bài toán học có thể được công thức hóa như suy luận Bayesian trên các tham số mạng neural. Sau đó, suy luận Bayesian tuần tự cung cấp một cách tiếp cận thanh lịch cho học liên tục. Cụ thể, học liên tục có thể được thực hiện bằng cách sử dụng phân phối posterior trước đó như phân phối prior hiện tại. Nếu dự đoán Bayesian đầy đủ được sử dụng, thì cách tiếp cận được gọi là mạng neural Bayesian. Trong công trình của chúng tôi, chúng tôi tập trung vào dự đoán maximum a posteriori (MAP), chỉ sử dụng điểm tối đa của phân phối posterior. Bằng cách định nghĩa hàm mất mát như hàm mật độ xác suất kết hợp âm log (PDF), điều này dẫn đến một công thức đệ quy của các hàm mất mát, và bài toán được rút gọn thành xấp xỉ hàm mất mát trước đó.

Khi con người trưởng thành học nhận dạng các đối tượng mới, họ đã học các đối tượng tương tự trước đó, và họ không cần học liên tục các đặc trưng cấp thấp như cạnh, góc và hình dạng. Điều này gợi ý rằng các lớp cấp thấp của một mạng neural nên được cố định sau khi học trên một tác vụ tương tự, và sau đó mạng neural có thể được sử dụng như một bộ trích xuất đặc trưng. Ví dụ, một mạng neural được huấn luyện trước trên chữ viết tay có thể được sử dụng như một bộ trích xuất đặc trưng cho học liên tục trên chữ số viết tay.

Mục tiêu của chúng tôi là điều tra hiệu suất học liên tục của một xấp xỉ bậc hai đầy đủ và một xấp xỉ mạng neural của các hàm mất mát trước đó và ảnh hưởng của việc sử dụng một bộ trích xuất đặc trưng được huấn luyện trước cho suy luận MAP tuần tự.

## II. SUY LUẬN MAXIMUM A POSTERIORI TUẦN TỰ

Chúng tôi mô tả mô hình xác suất của chúng tôi cho học liên tục và cách suy luận MAP tuần tự dựa trên nó dẫn đến một đệ quy của các hàm mất mát. Sau đó, chúng tôi đề xuất hai phương pháp để xấp xỉ hàm mất mát trước đó: hợp nhất bậc hai autodiff (AQC), sử dụng xấp xỉ bậc hai chính xác và đầy đủ, và hợp nhất neural (NC), sử dụng xấp xỉ mạng neural. Cuối cùng, chúng tôi thảo luận về các hạn chế của chúng.

### A. Mô hình Xác suất

Hình 1: Mạng Bayesian cho học liên tục. θ là tập hợp các tham số của mạng neural, x₁:t là các đầu vào và y₁:t là các đầu ra.

Gọi θ là tập hợp các tham số của mạng neural và x₁:t và y₁:t là các đầu vào và đầu ra từ thời điểm 1 đến t, tương ứng. x₁:t được giả định là độc lập, và y₁:t được giả định là độc lập có điều kiện cho θ và x₁:t. Các giả định này được mô tả trong Hình 1.

(x,y)₁:t không nhất thiết phải phân phối đồng nhất. Tuy nhiên, được giả định rằng các tác vụ tương tự, tức là dạng của hàm likelihood lt(yt|θ, xt) giống nhau cho tất cả các tác vụ. Ví dụ, trong phân loại đa lớp, đó là hàm likelihood phân loại cho tất cả các tác vụ.

Sau khi quan sát (x,y)₁:t = (x, y)₁:t tại thời điểm t, PDF posterior là

pt(θ|x₁:t, y₁:t) = (1/zt)pt-1(θ|x₁:t-1, y₁:t-1)lt(yt|θ, xt)    (1)

trong đó zt = ∫Θ pt-1(θ|x₁:t-1, y₁:t-1)lt(yt|θ, xt)dθ là một số hạng chuẩn hóa không phụ thuộc vào θ. Dự đoán MAP sử dụng giá trị tối đa của PDF posterior để đưa ra dự đoán f(x;θ*t), trong đó f là hàm mạng neural, x là đầu vào và θ*t là ước lượng MAP tại thời điểm t.

Vì nhân với một hằng số không ảnh hưởng đến giá trị tối thiểu, hàm mất mát Lt tại thời điểm t có thể được định nghĩa như PDF kết hợp âm log −ln jt(θ, y₁:t|x₁:t) tại thời điểm t. Sau đó, giá trị tối thiểu của hàm mất mát tương đương với ước lượng MAP, và chúng ta có một đệ quy của các hàm mất mát cho t = 1,2, ...:

Lt(θ) = Lt-1(θ) + lt(θ)    (2)

trong đó lt là negative log likelihood (NLL) tại thời điểm t. Đối với phân loại nhị phân, trong đó likelihood được giả định là Bernoulli, lt là entropy chéo nhị phân hoặc Bernoulli, trong khi đối với phân loại đa lớp, trong đó likelihood được giả định là phân loại. lt là entropy chéo phân loại. L₀ là prior âm log (không chuẩn hóa) tại thời điểm 1, ví dụ, ½‖θ‖² cho prior Gaussian chuẩn.

Trong Phương trình (2), Lt-1 phụ thuộc vào dữ liệu trước đó (x,y)₁:t-1 và lt phụ thuộc vào dữ liệu hiện tại (x,y)t. Quên xảy ra khi chúng ta chỉ tối thiểu hóa lt mà bỏ qua Lt-1 như trong tinh chỉnh. Trong huấn luyện MAP kết hợp, tất cả dữ liệu được sử dụng, vì vậy Lt được tối thiểu hóa một cách hiệu quả. Nếu không có quyền truy cập vào dữ liệu trước đó, thì Lt-1 phải được xấp xỉ. Chúng tôi điều tra hai cách để xấp xỉ nó, cụ thể là xấp xỉ bậc hai và xấp xỉ mạng neural.

### B. Hợp nhất Bậc hai Autodiff

Một xấp xỉ bậc hai của Lt-1 tương ứng với một xấp xỉ Laplace của PDF posterior tại thời điểm t−1. Xấp xỉ bậc hai là một xấp xỉ chuỗi Taylor bậc hai quanh θ*t-1, trong đó gradient bằng không, vì vậy số hạng tuyến tính biến mất. Hơn nữa, số hạng hằng số không ảnh hưởng đến PDF. Do đó, xấp xỉ bao gồm một số hạng bậc hai duy nhất có dạng ½(θ−θ*t-1)ᵀH(lt-1)(θ*t-1)(θ−θ*t-1), trong đó H(lt-1)(θ*t-1) là ma trận Hessian của NLL của tác vụ t−1 tại θ*t-1. [4] cho thấy rằng xấp xỉ bậc hai liên tiếp dẫn đến việc cộng các ma trận Hessian của NLL của các tác vụ trước đó tại các giá trị tối thiểu tương ứng. Do đó, hàm mất mát xấp xỉ là

L̂t(θ) = (λ/2)(θ−θ*t-1)ᵀ(∑ᵢ₌₀ᵗ⁻¹H(li)(θ*i))(θ−θ*t-1) + lt(θ)    (3)

trong đó λ là một số thực dương được giới thiệu như một siêu tham số.

Ma trận Hessian là chuyển vị của ma trận Jacobian của gradient: H(f)(x) = (J(∇f)(x))ᵀ cho bất kỳ điểm khả vi hai lần x nào của một hàm f. Trong hầu hết các trường hợp, NLL lt-1 khả vi liên tục hai lần, vì vậy ma trận Hessian tại giá trị tối thiểu của nó là đối xứng xác định dương. Sau đó, nó có thể được triển khai như J(∇lt-1)(θ*t-1), ma trận Jacobian của gradient của nó tại giá trị tối thiểu, bằng cách sử dụng vi phân tự động.

Vì toán tử Hessian là tuyến tính, ma trận Hessian của negative log likelihood theo batch bằng tổng các ma trận Hessian của negative log likelihood mini-batch:

H(lt-1)(θ*t-1) = H(∑ⱼ₌₁ᵇlt-1,j)(θ*t-1) = ∑ⱼ₌₁ᵇH(lt-1,j)(θ*t-1)    (4)

trong đó lt-1,j là negative log likelihood mini-batch của mini-batch thứ j tại thời điểm t−1.

Thủ thuật trên cho phép làm việc với một bộ dữ liệu lớn bằng cách chia nó thành các mini-batch nhỏ. Tuy nhiên, nếu mạng neural lớn, tức là θ có một lượng lớn tham số, thì tính toán có thể trở nên không thể xử lý được.

Huấn luyện cho mỗi tác vụ do đó bao gồm ba bước:
1) Nếu đó là tác vụ đầu tiên, thì hàm mất mát được đặt thành ½‖θ‖² + l₁(θ) giả định một prior Gaussian chuẩn; ngược lại, nó được cập nhật như trong Phương trình (3) với ước lượng MAP θ*t-1 và ma trận Hessian Ht-1 = ∑ᵢ₌₀ᵗ⁻¹H(li)(θ*i) của tác vụ trước đó.
2) Huấn luyện được thực hiện trên hàm mất mát sử dụng gradient descent mini-batch, và số hạng điều hòa được chia tỷ lệ bằng cách chia cho số lượng mini-batch trong bộ dữ liệu.
3) Ma trận Hessian cho tác vụ hiện tại được tính toán và thêm vào của tác vụ trước đó Ht = Ht-1 + H(lt)(θ*t), và ước lượng MAP hiện tại θ*t và ma trận Hessian Ht được lưu trữ để sử dụng để cập nhật hàm mất mát tiếp theo.

Phương pháp này được gọi là Hợp nhất Bậc hai Autodiff (AQC).

### C. Hợp nhất Neural

Một xấp xỉ mạng neural sử dụng một mạng neural hợp nhất κ với các tham số ϕ*t-1. Hàm mất mát xấp xỉ là

L̂t(θ) = λκ(θ;ϕ*t-1) + lt(θ)    (5)

trong đó λ là một số thực dương được giới thiệu như một siêu tham số và ϕ*t-1 là tập hợp các tham số đã huấn luyện của mạng neural hợp nhất tại thời điểm t−1.

Mạng neural hợp nhất được huấn luyện bằng cách tối thiểu hóa một hàm mất mát Huber điều hòa L2 để khớp nó với hàm mất mát trước đó với một mẫu được tạo đồng đều trong một quả cầu có bán kính r quanh θ*t-1 tại mỗi bước gradient descent. Nếu n điểm được tạo, thì hàm mất mát hợp nhất là

Lt-1,κ(ϕ) = (1/2)β‖ϕ‖²₂ + ∑ᵢ₌₁ⁿht-1,i(ϕ)    (6)

trong đó β là một số thực dương được giới thiệu như một siêu tham số và ht-1,i(ϕ) là hàm mất mát Huber đối với L̂t-1(θᵢ) và κ(θᵢ;ϕ). Nếu bộ dữ liệu rất lớn, L̂t-1 có thể được tính toán trên mẫu theo mini-batch và cộng lại.

Huấn luyện cho mỗi tác vụ do đó bao gồm ba bước:
1) Nếu đó là tác vụ đầu tiên, thì hàm mất mát được đặt thành ½‖θ‖² + l₁(θ) giả định một prior Gaussian chuẩn; ngược lại, nó được cập nhật như trong Phương trình (5) với các tham số ϕ*t-1 của mạng neural hợp nhất của tác vụ trước đó.
2) Huấn luyện được thực hiện trên hàm mất mát sử dụng gradient descent mini-batch, và số hạng điều hòa được chia tỷ lệ bằng cách chia cho số lượng mini-batch trong bộ dữ liệu.
3) Mạng neural hợp nhất được huấn luyện bằng cách thực hiện gradient descent trên Phương trình (6) với một mẫu n điểm của θ được tạo đồng đều trong một quả cầu có bán kính r quanh θ*t tại mỗi bước như được mô tả ở trên, và các tham số ϕ*t của mạng neural hợp nhất được lưu trữ để sử dụng để cập nhật hàm mất mát tiếp theo.

Phương pháp này được gọi là Hợp nhất Neural (NC).

### D. Hạn chế

Như trong tất cả các cách tiếp cận đơn đầu, tổng số lớp phải được biết trước. Hạn chế chính của AQC và NC là chúng không có khả năng mở rộng theo kích thước mạng neural mặc dù chúng có thể được sử dụng khi các bộ dữ liệu lớn. Hạn chế này có thể được khắc phục bằng cách sử dụng một bộ trích xuất đặc trưng cố định được huấn luyện trước trên một tác vụ tương tự và thực hiện học liên tục với một lớp dày đặc trên các đặc trưng. Cuối cùng, cả hai phương pháp học liên tục đều nhạy cảm với các siêu tham số, vì vậy một chuỗi bộ dữ liệu xác thực nên được sử dụng để thực hiện điều chỉnh siêu tham số.

## III. CÔNG TRÌNH LIÊN QUAN

Có một số phương pháp học liên tục dựa trên suy luận MAP tuần tự và sử dụng xấp xỉ bậc hai của hàm mất mát trước đó. Elastic weight consolidation (EWC) xấp xỉ ma trận Hessian bằng cách sử dụng một xấp xỉ đường chéo của ma trận thông tin Fisher thực nghiệm (eFIM) [5]. EWC gốc thêm một số hạng bậc hai vào mục tiêu cho mỗi tác vụ. [6] đề xuất một mục tiêu đã được sửa chữa với một số hạng bậc hai duy nhất mà eFIM có thể được cộng dồn. Có một biến thể khác gọi là EWC++ [7], thực hiện một kết hợp lồi của eFIM trước đó và hiện tại thay vì cộng chúng. Synaptic intelligence (SI) thực hiện một xấp xỉ đường chéo của ma trận Hessian bằng cách sử dụng sự thay đổi trong mất mát trong gradient descent [8]. Online structured Laplace approximation sử dụng phân tích Kronecker để thực hiện một xấp xỉ đường chéo khối của ma trận Hessian, trong đó các khối đường chéo của ma trận tương ứng với một lớp của mạng neural [9].

Một lớp phương pháp khác không dựa trên suy luận MAP tuần tự mà dựa trên suy luận Bayesian tuần tự là suy luận biến phân tuần tự. Nó xấp xỉ phân phối posterior với một phân phối biến phân, là một phân phối tham số đơn giản, thường là phân phối Gaussian hoặc hỗn hợp Gaussian, bằng cách tối thiểu hóa một mục tiêu gọi là năng lượng tự do biến phân hoặc cận dưới bằng chứng âm đối với các tham số của phân phối biến phân. Nó sử dụng toàn bộ phân phối posterior thay vì một điểm từ nó để đưa ra dự đoán. Gaussian variational continual learning (G-VCL) [10] và Gaussian mixture variational continual learning (GM-VCL) [11] xấp xỉ phân phối posterior trên các tham số với một phân phối Gaussian và một phân phối hỗn hợp Gaussian, tương ứng. Gaussian sequential function space variational inference (G-SFSVI) [12] xấp xỉ phân phối posterior trên các đầu ra (trước hàm kích hoạt cuối cùng) của một số lượng đầu vào được chọn gọi là điểm cảm ứng với một phân phối Gaussian.

Huấn luyện trước để khởi tạo và huấn luyện trước để trích xuất đặc trưng đều đã được chứng minh thực nghiệm là cải thiện học liên tục. Trong trường hợp trước, các tham số được huấn luyện trước được sử dụng như các tham số ban đầu cho học liên tục [13], [14]. Trong trường hợp sau, mạng neural được huấn luyện trước được sử dụng như một bộ trích xuất đặc trưng [15]–[17].

Chúng tôi điều tra hiệu suất học liên tục của AQC, đây là dạng chính xác nhất của xấp xỉ bậc hai của hàm mất mát trước đó, và NC, đây là một xấp xỉ mạng neural của hàm mất mát trước đó. Trong các tác vụ phân loại hình ảnh, chúng tôi sử dụng một bộ trích xuất đặc trưng cố định được huấn luyện trước trên một tác vụ tương tự và thực hiện học liên tục với một lớp dày đặc trên các đặc trưng.

## IV. THỰC NGHIỆM

Các thực nghiệm được thực hiện trên các chuỗi tác vụ cổ điển cũng như các chuỗi tác vụ hình ảnh. Trong mỗi thực nghiệm, độ chính xác trung bình cuối cùng của AQC và NC được so sánh với các phương pháp tham chiếu, phương pháp suy luận biến phân tuần tự và phương pháp suy luận MAP tuần tự. Mỗi chuỗi tác vụ có một chuỗi bộ dữ liệu huấn luyện, chuỗi bộ dữ liệu xác thực và chuỗi bộ dữ liệu kiểm tra. Chuỗi bộ dữ liệu xác thực được sử dụng để thực hiện điều chỉnh siêu tham số thông qua tìm kiếm lưới. Mô tả dữ liệu được sử dụng và các phương pháp được so sánh cũng như thảo luận về kết quả được cung cấp dưới đây, và chi tiết hơn được cung cấp trong Phụ lục A.

### A. Dữ liệu

Các chuỗi tác vụ cho học liên tục cũng như các tác vụ để huấn luyện trước được liệt kê dưới đây. Các chuỗi tác vụ cổ điển mà chúng tôi giới thiệu ở đây có thể có vẻ đơn giản, nhưng chúng là các chuỗi tác vụ đầy thử thách cho học liên tục. Trong tất cả các chuỗi tác vụ, CI chỉ ra rằng nó dành cho học tăng dần theo lớp, trong khi DI chỉ ra rằng nó dành cho học tăng dần theo miền.

• **Chuỗi Tác vụ Cổ điển**
– **CI Split Iris**: Iris là một tác vụ phân loại 3 loài hoa dựa trên 4 đặc trưng. Nó được chia thành 3 tác vụ để học 1 loài tại một thời điểm. CI Split 2D Iris là một chuỗi tác vụ để hiển thị được dẫn xuất từ nó bằng cách chọn hai đặc trưng "chiều dài cánh hoa" và "chiều rộng cánh hoa".
– **CI Split Wine**: Wine là một tác vụ phân loại 3 lớp rượu dựa trên 13 đặc trưng. Nó được chia thành 3 tác vụ để học 1 lớp tại một thời điểm.

• **Chuỗi tác vụ hình ảnh**
– **CI Split MNIST**: MNIST là một tác vụ phân loại 10 lớp chữ số dựa trên hình ảnh thang xám của chữ số viết tay. Nó được chia thành 5 tác vụ để học 2 lớp tại một thời điểm.
– **CI Split CIFAR-10**: CIFAR-10 là một tác vụ phân loại 10 lớp đối tượng tự nhiên dựa trên hình ảnh. Nó được chia thành 5 tác vụ để học 2 lớp tại một thời điểm.
– **CI Split HAM-8**: HAM10000 là một tác vụ phân loại 8 lớp tình trạng da dựa trên hình ảnh da liễu. Nó được đổi tên thành HAM-8 dựa trên số lượng lớp và được chia thành 4 tác vụ để học 2 lớp tại một thời điểm.
– **DI Split MNIST**: MNIST được chia thành 5 tác vụ với 2 lớp tại một thời điểm, nhưng mỗi tác vụ là phân loại nhị phân chữ số chẵn và lẻ.
– **DI Split CIFAR-8**: CIFAR-10 có 6 loại động vật và 4 loại phương tiện, vì vậy 2 loại động vật ("chim" và "ếch") được loại bỏ để tạo CIFAR-8, sau đó được chia thành 4 tác vụ với 2 lớp tại một thời điểm, nhưng mỗi tác vụ là phân loại nhị phân phương tiện và động vật.
– **DI Split HAM-6**: HAM-8 có 4 loại tình trạng da lành tính, 1 loại tình trạng da không xác định và 3 loại tình trạng da ác tính, vì vậy 1 loại tình trạng da lành tính ("tổn thương mạch máu") và 1 loại tình trạng da không xác định ("sừng hóa quang tuyến") được loại bỏ để tạo HAM-6, sau đó được chia thành 3 tác vụ với 2 lớp tại một thời điểm, nhưng mỗi tác vụ là phân loại nhị phân tình trạng da lành tính và ác tính.

• **Tác vụ Huấn luyện Trước**
– **EMNIST Letters**: EMNIST Letters là một tác vụ phân loại 26 lớp chữ cái dựa trên hình ảnh thang xám của chữ cái viết tay. Nó không có lớp chung với MNIST và được sử dụng để huấn luyện trước cho CI Split MNIST và DI Split MNIST.
– **CIFAR-100**: CIFAR-100 là một tác vụ phân loại 100 lớp đối tượng tự nhiên dựa trên hình ảnh. Nó không có lớp chung với CIFAR-10 và được sử dụng để huấn luyện trước cho CI Split CIFAR-10 và DI Split CIFAR-10.
– **BCN-12**: BCN20000 là một tác vụ phân loại 8 lớp tình trạng da dựa trên hình ảnh da liễu. Nó được đổi tên thành BCN-12 dựa trên số lượng lớp. Hầu hết các lớp chung với HAM-8, nhưng hình ảnh từ các quần thể khác nhau. Nó được sử dụng để huấn luyện trước cho CI Split MNIST và DI Split MNIST.

### B. Phương pháp

Chúng tôi so sánh AQC và NC với các phương pháp tham chiếu, phương pháp suy luận biến phân tuần tự và phương pháp suy luận MAP tuần tự. Huấn luyện MAP kết hợp và tinh chỉnh đóng vai trò như các phương pháp tham chiếu tốt nhất và tệ nhất, tương ứng. Trong trường hợp trước, tất cả dữ liệu trước đó được sử dụng cùng với dữ liệu hiện tại để huấn luyện mạng neural, trong khi trong trường hợp sau, mạng neural được huấn luyện trước chỉ đơn giản được tinh chỉnh cho tác vụ hiện tại. Các phương pháp suy luận biến phân được so sánh là G-VCL [10], GM-VCL [11] và G-SFSVI [12], và các phương pháp suy luận MAP tuần tự được so sánh là EWC với hình phạt đã được sửa chữa của Huszár [4], [6] và SI [8]. Các phương pháp này được mô tả trong Phần III. Để thực hiện so sánh công bằng, chỉ các phương pháp không dùng coreset, tức là các phương pháp không lưu trữ bất kỳ dữ liệu trước đó nào, được xem xét.

Mỗi phương pháp chạy qua mỗi chuỗi bộ dữ liệu huấn luyện, các siêu tham số của nó được chọn dựa trên độ chính xác trung bình cuối cùng trên chuỗi bộ dữ liệu xác thực, và nó được đánh giá dựa trên độ chính xác trung bình cuối cùng trên chuỗi bộ dữ liệu kiểm tra. Độ chính xác trung bình cuối cùng trên một chuỗi bộ dữ liệu được định nghĩa là trung bình của tất cả các độ chính xác trên tất cả các bộ dữ liệu trong chuỗi.

### C. Kết quả

Vì AQC dựa vào vi phân tự động rất chính xác để tính toán Hessian, chúng tôi mong đợi rằng nó có độ chính xác trung bình cuối cùng tốt hơn EWC và SI, và chúng tôi quan tâm đến việc quan sát nó hoạt động tốt hơn bao nhiêu. Vì các mạng neural là các bộ xấp xỉ hàm mạnh mẽ, và các hàm mất mát trước đó trong thực nghiệm của chúng tôi không phải là bậc hai, chúng tôi mong đợi rằng NC có trung bình cuối cùng tốt hơn các phương pháp xấp xỉ bậc hai. Chúng tôi cũng quan tâm đến việc một bộ trích xuất đặc trưng được huấn luyện trước giúp ích bao nhiêu trong suy luận MAP tuần tự.

Hình 2: Hình ảnh hóa xác suất dự đoán cho các phương pháp trên CI Split 2D Iris. Trục x là chiều dài cánh hoa (cm) và trục y là chiều rộng cánh hoa (cm). Biểu đồ màu giả cho thấy xác suất dự đoán, trong đó 3 xác suất lớp được ánh xạ tới các giá trị đỏ, xanh lá cây và xanh dương, tương ứng, và các chấm cho thấy dữ liệu quan sát. NC hoạt động tốt nhất và tốt hơn với hồi quy softmax.

Hình ảnh hóa các xác suất dự đoán cho các phương pháp trên CI Split 2D Iris cho hồi quy softmax và một mạng neural hoàn toàn kết nối được hiển thị trong Hình 2. Chúng tôi thấy rằng AQC hoạt động tốt hơn EWC và SI, và NC hoạt động tốt nhất, nhưng nó hoạt động tốt hơn cho hồi quy softmax.

Độ chính xác trung bình cuối cùng kiểm tra cho các phương pháp trên các chuỗi tác vụ cổ điển và hình ảnh được hiển thị trong Bảng I. Chúng tôi thấy rằng AQC hoạt động tốt hơn EWC và SI, và NC hoạt động tốt nhất trong hầu hết các chuỗi tác vụ cổ điển. Chúng tôi cũng thấy rằng NC hoạt động tốt hơn với hồi quy softmax hơn với một mạng neural hoàn toàn kết nối có lẽ vì hàm mất mát trong trường hợp trước là lồi và dễ khớp hơn. Trong các chuỗi tác vụ hình ảnh, nơi một bộ trích xuất đặc trưng được sử dụng, AQC nhất quán hoạt động tốt nhất và có hiệu suất tương đương với huấn luyện MAP kết hợp trong một số chuỗi tác vụ. Tuy nhiên, chúng tôi thấy rằng NC không hoạt động tốt như AQC, nhưng tốt hơn EWC và SI trong một số chuỗi tác vụ.

Điều đáng chú ý là EWC hoạt động kém như tinh chỉnh trong học tăng dần theo lớp trên toàn bộ mạng neural từ đầu [2], nhưng việc sử dụng một bộ trích xuất đặc trưng được huấn luyện trước cải thiện đáng kể nó. Hơn nữa, trong DI Split CIFAR-8, việc sử dụng một bộ trích xuất đặc trưng được huấn luyện trước một mình giảm đáng kể việc quên, và thậm chí tinh chỉnh hoạt động khá tốt.

Một lý do có thể mà NC không hoạt động tốt trong các chuỗi tác vụ hình ảnh là chiều của không gian đặc trưng cao (64 trong CI Split MNIST và DI Split MNIST và 512 trong các chuỗi tác vụ khác), và việc lấy mẫu ngẫu nhiên trở nên không hiệu quả trong chiều cao.

### D. Tính Sẵn có của Dữ liệu

Tất cả các bộ dữ liệu được sử dụng trong công trình này đều có sẵn công khai. Iris và Wine có sẵn từ gói scikit-learn [18], được phát hành dưới giấy phép BSD 3-clause. MNIST, EMNIST, CIFAR-10 và CIFAR-100 có sẵn từ gói pytorch [19], cũng được phát hành dưới giấy phép BSD 3-clause. HAM10000 [20] được phát hành bởi Hospital Clinic ở Barcelona dưới CC BY-NC, và BCN20000 [21] được phát hành bởi ViDIR Group, Department of Dermatology, Medical University of Vienna, cũng dưới CC BY-NC.

### E. Tính Sẵn có của Mã

Mã được ghi chép và có thể tái tạo có sẵn dưới Giấy phép MIT tại https://github.com/blackblitz/bcl.

## V. KẾT LUẬN

Chúng tôi đã công thức hóa học liên tục dựa trên suy luận maximum a posteriori tuần tự như một đệ quy của các hàm mất mát và rút gọn bài toán thành xấp xỉ hàm. Sau đó chúng tôi đề xuất hai phương pháp không dùng coreset dựa trên nó: hợp nhất bậc hai autodiff và hợp nhất neural, sử dụng một xấp xỉ bậc hai đầy đủ và một xấp xỉ mạng neural, tương ứng, để xấp xỉ hàm mất mát trước đó. Hơn nữa, chúng tôi đã chỉ ra thực nghiệm rằng huấn luyện trước mạng neural trên một tác vụ tương tự có thể giảm đáng kể việc quên với các phương pháp suy luận maximum a posteriori tuần tự. Hợp nhất neural hoạt động tốt nhất trong các chuỗi tác vụ cổ điển, nơi chiều đầu vào nhỏ. Hợp nhất bậc hai autodiff nhất quán hoạt động rất tốt trong các chuỗi tác vụ hình ảnh với huấn luyện trước trên một tác vụ tương tự, đạt được hiệu suất tương đương với huấn luyện maximum a posteriori kết hợp trong nhiều trường hợp. Trong tương lai, chúng tôi có thể xem xét các kiến trúc mạng neural đặc biệt cho hợp nhất neural cũng như nhiều ứng dụng hơn trong phân loại hình ảnh y tế, hiểu biết hình ảnh tài liệu [22] và khoa học vật liệu [23].

## LỜI CẢM ƠN

Chúng tôi cảm ơn Pengcheng Hao, Giáo sư Yang Li từ Tsinghua Shenzhen International Graduate School và các nhà đánh giá ẩn danh về phản hồi của họ.

## TÀI LIỆU THAM KHẢO

[1] M. McCloskey và N. J. Cohen, "Catastrophic interference in connectionist networks: The sequential learning problem," Psychology of Learning and Motivation - Advances in Research and Theory, vol. 24, C 1989.

[2] G. M. van de Ven, T. Tuytelaars, và A. S. Tolias, "Three types of incremental learning," Nature Machine Intelligence, vol. 4, no. 12, pp. 1185–1197, 2022.

[3] S. Farquhar và Y. Gal, Towards robust evaluations of continual learning, 2019. arXiv: 1805.09733.

[4] F. Huszár, On quadratic penalties in elastic weight consolidation, 2017. arXiv: 1712.03847.

[5] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins, A. A. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska, D. Hassabis, C. Clopath, D. Kumaran, và R. Hadsell, "Overcoming catastrophic forgetting in neural networks," Proceedings of the National Academy of Sciences of the United States of America, vol. 114, no. 13, pp. 3521–3526, 2017.

[6] F. Huszár, "Note on the quadratic penalties in elastic weight consolidation," Proceedings of the National Academy of Sciences of the United States of America, vol. 115, no. 11, E2496–E2497, 2018.

[7] A. Chaudhry, P. K. Dokania, T. Ajanthan, và P. H. S. Torr, "Riemannian walk for incremental learning: Understanding forgetting and intransigence," trong Computer Vision – ECCV 2018, V. Ferrari, M. Hebert, C. Sminchisescu, và Y. Weiss, Eds., Cham: Springer International Publishing, 2018, pp. 556–572.

[8] F. Zenke, B. Poole, và S. Ganguli, "Continual learning through synaptic intelligence," trong Proceedings of the 34th International Conference on Machine Learning, D. Precup và Y. W. Teh, Eds., ser. Proceedings of Machine Learning Research, vol. 70, PMLR, 2017, pp. 3987–3995.

[9] H. Ritter, A. Botev, và D. Barber, "Online structured Laplace approximations for overcoming catastrophic forgetting," trong Advances in Neural Information Processing Systems, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, và R. Garnett, Eds., vol. 31, Curran Associates, Inc., 2018.

[10] C. V. Nguyen, Y. Li, T. D. Bui, và R. E. Turner, "Variational continual learning," trong International Conference on Learning Representations, 2018.

[11] H. Phan, A. P. Tuan, S. Nguyen, N. V. Linh, và K. Than, "Reducing catastrophic forgetting in neural networks via Gaussian mixture approximation," trong Advances in Knowledge Discovery and Data Mining, J. Gama, T. Li, Y. Yu, E. Chen, Y. Zheng, và F. Teng, Eds., Cham: Springer International Publishing, 2022, pp. 106–117.

[12] T. G. J. Rudner, F. B. Smith, Q. Feng, Y. W. Teh, và Y. Gal, "Continual learning via sequential function-space variational inference," trong Proceedings of the 39th International Conference on Machine Learning, K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvari, G. Niu, và S. Sabato, Eds., ser. Proceedings of Machine Learning Research, vol. 162, PMLR, 2022, pp. 18 871–18 887.

[13] K.-Y. Lee, Y. Zhong, và Y.-X. Wang, "Do pre-trained models benefit equally in continual learning?" trong Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2023, pp. 6485–6493.

[14] S. V. Mehta, D. Patil, S. Chandar, và E. Strubell, "An empirical investigation of the role of pre-training in lifelong learning," Journal of Machine Learning Research, vol. 24, no. 214, pp. 1–50, 2023.

[15] W. Hu, Q. Qin, M. Wang, J. Ma, và B. Liu, "Continual learning by using information of each class holistically," vol. 35, pp. 7797–7805, 2021.

[16] X. Li, H. Li, và L. Ma, "Continual learning of medical image classification based on feature replay," trong 2022 16th IEEE International Conference on Signal Processing (ICSP), vol. 1, 2022, pp. 426–430.

[17] Y. Yang, Z. Cui, J. Xu, C. Zhong, W.-S. Zheng, và R. Wang, "Continual learning with Bayesian model based on a fixed pre-trained feature extractor," Visual Intelligence, vol. 1, no. 1, p. 5, 2023.

[18] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, và E. Duchesnay, "Scikit-learn: Machine learning in Python," Journal of Machine Learning Research, vol. 12, pp. 2825–2830, 2011.

[19] J. Ansel, E. Yang, H. He, N. Gimelshein, A. Jain, M. Voznesensky, B. Bao, P. Bell, D. Berard, E. Burovski, G. Chauhan, A. Chourdia, W. Constable, A. Desmaison, Z. DeVito, E. Ellison, W. Feng, J. Gong, M. Gschwind, B. Hirsh, S. Huang, K. Kalambarkar, L. Kirsch, M. Lazos, M. Lezcano, Y. Liang, J. Liang, Y. Lu, C. Luk, B. Maher, Y. Pan, C. Puhrsch, M. Reso, M. Saroufim, M. Y. Siraichi, H. Suk, M. Suo, P. Tillet, E. Wang, X. Wang, W. Wen, S. Zhang, X. Zhao, K. Zhou, R. Zou, A. Mathews, G. Chanan, P. Wu, và S. Chintala, "PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation," trong 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS '24), ACM, 2024.

[20] P. Tschandl, C. Rosendahl, và H. Kittler, "The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions," Scientific data, vol. 5, no. 1, pp. 1–9, 2018.

[21] C. Hernández-Pérez, M. Combalia, S. Podlipnik, N. C. Codella, V. Rotemberg, A. C. Halpern, O. Reiter, C. Carrera, A. Barreiro, B. Helba, et al., "BCN20000: Dermoscopic lesions in the wild," Scientific Data, vol. 11, no. 1, p. 641, 2024.

[22] E. E. Kuruoğlu và A. S. Taylor, "Using annotations for summarizing a document image and itemizing the summary based on similar annotations," US7712028B2, 2010.

[23] F. Saffarimiandoab, R. Mattesini, W. Fu, E. E. Kuruoglu, và X. Zhang, "Insights on features' contribution to desalination dynamics and capacity of capacitive deionization through machine learning study," Desalination, vol. 515, p. 115 197, 2021.

## PHỤ LỤC A
CHI TIẾT THỰC NGHIỆM

### A. Chuẩn bị Dữ liệu

Đối với các chuỗi tác vụ dựa trên Iris và Wine, bộ dữ liệu được chia thành bộ dữ liệu huấn luyện và kiểm tra với kích thước kiểm tra 20%, và sau đó bộ dữ liệu huấn luyện thành bộ dữ liệu huấn luyện và xác thực với kích thước xác thực 20%, vì vậy tỷ lệ huấn luyện, xác thực và kiểm tra lần lượt là 64%, 16% và 20%. Cuối cùng, mỗi bộ dữ liệu được chia theo lớp thành một chuỗi bộ dữ liệu.

Đối với EMNIST Letters, CIFAR-100 và các chuỗi tác vụ dựa trên MNIST và CIFAR-10, bộ dữ liệu huấn luyện và kiểm tra có sẵn từ PyTorch, vì vậy bộ dữ liệu huấn luyện được chia thành bộ dữ liệu huấn luyện và xác thực với kích thước xác thực 20%. Mỗi bộ dữ liệu sau đó được chia theo lớp thành một chuỗi bộ dữ liệu.

Đối với BCN-12 và HAM-8, các hình ảnh 640×450 được thay đổi kích thước thành 32×32 với phép nội suy Lanczos. Đối với tất cả dữ liệu hình ảnh, các giá trị pixel được chia cho 255 để chúng có giá trị giữa 0 và 1. Tăng cường dữ liệu (ví dụ lật và cắt) không được thực hiện.

### B. Kiến trúc Mạng Neural

Mạng neural hoàn toàn kết nối được sử dụng cho CI Split 2D Iris và CI Split Iris có 1 lớp ẩn gồm 4 nút, trong khi đó được sử dụng cho CI Split Wine có 1 lớp ẩn gồm 16 nút. Tất cả các nút ẩn sử dụng kích hoạt swish.

Mạng neural được huấn luyện trước cho cả CI Split MNIST và DI Split MNIST có 2 lớp tích chập và 2 lớp dày đặc, tổng cộng 4 lớp. Mỗi lớp tích chập có 32 bộ lọc 3×3 và được theo sau bởi chuẩn hóa nhóm với 32 nhóm, kích hoạt swish và pooling trung bình với kích thước 2×2. Lớp dày đặc ẩn có 64 nút với kích hoạt swish. Do đó, chiều đặc trưng là 64.

Mạng neural được huấn luyện trước cho CI Split CIFAR-10, CI Split HAM-8 DI Split CIFAR-8 và DI Split HAM-6 có 17 lớp tích chập và 1 lớp dày đặc, tổng cộng 18 lớp. Mỗi lớp tích chập được theo sau bởi chuẩn hóa nhóm với 32 nhóm và kích hoạt swish. Các lớp tích chập thứ 2 đến thứ 17 được sắp xếp thành 8 khối dư, mỗi khối có 2 lớp tích chập, và cứ 2 khối dư được theo sau bởi pooling trung bình với kích thước 2×2. Số lượng bộ lọc cho 17 lớp tích chập lần lượt là 32, 64, 64, 64, 64, 128, 128, 128, 128, 256, 256, 256, 256, 512, 512, 512 và 512, và các kích thước bộ lọc đều là 3×3. Do đó, chiều đặc trưng là 512.

Trong tất cả các thực nghiệm, mạng neural hợp nhất được sử dụng trong NC là một mạng neural hoàn toàn kết nối với 2 lớp ẩn, mỗi lớp có 256 nút. Tất cả các nút ẩn sử dụng kích hoạt swish.

### C. Huấn luyện

Trong tất cả các thực nghiệm, PDF prior tại thời điểm 1 là một PDF Gaussian chuẩn (của một chiều thích hợp), và một bộ tối ưu hóa Adam được sử dụng với lịch trình tốc độ học một chu kỳ. Các tham số mạng neural được khởi tạo bằng cách sử dụng bộ khởi tạo Lecun normal cho các trọng số và đặt bằng không cho các bias. Đối với các tác vụ huấn luyện trước và các chuỗi tác vụ tăng dần theo lớp, mỗi tác vụ là phân loại đa lớp, vì vậy entropy chéo phân loại được sử dụng, trong khi đối với các chuỗi tác vụ tăng dần theo miền, mỗi tác vụ là phân loại nhị phân, vì vậy entropy chéo nhị phân hoặc Bernoulli được sử dụng. BCN-12 là một tác vụ với mất cân bằng lớp nghiêm trọng, vì vậy để huấn luyện trước trên BCN-12, thay vì entropy chéo chuẩn, một entropy chéo có trọng số −∑ᵢ₌₁ᵏm/nᵢpᵢlnqᵢ được sử dụng, trong đó pᵢ là chỉ báo nhãn thực và qᵢ là xác suất dự đoán, nᵢ là tần suất của lớp thứ i và m = min {n₁, n₂, ..., nₖ}.

Đối với CI Split 2D Iris và CI Split Iris, huấn luyện cho mỗi tác vụ được thực hiện trong 100 epoch với tốc độ học cơ sở là 0.1 và kích thước batch là 16. Đối với CI Split Wine, huấn luyện cho mỗi tác vụ được thực hiện tương tự nhưng với tốc độ học cơ sở là 0.01.

Đối với CI Split MNIST và DI Split MNIST, huấn luyện trước được thực hiện trên EMNIST Letters trong 20 epoch với tốc độ học cơ sở là 0.01 và kích thước batch là 64, và huấn luyện cho mỗi tác vụ được thực hiện tương tự. Đối với CI Split MNIST và DI Split CIFAR-8, huấn luyện trước được thực hiện trên CIFAR-100 trong 20 epoch với tốc độ học cơ sở là 0.001 và kích thước batch là 64, và huấn luyện cho mỗi tác vụ được thực hiện tương tự nhưng với tốc độ học cơ sở là 0.01. Đối với CI Split HAM-8 và DI Split HAM-6, huấn luyện trước được thực hiện trên BCN-12 trong 20 epoch với tốc độ học cơ sở là 0.0001 và kích thước batch là 64, và huấn luyện cho mỗi tác vụ được thực hiện tương tự nhưng với tốc độ học cơ sở là 0.001.

Đối với G-SFSVI, các điểm cảm ứng được tạo ngẫu nhiên từ một phân phối đồng đều trong một siêu hình chữ nhật có ranh giới được xác định bởi các giá trị tối thiểu và tối đa của dữ liệu đầu vào huấn luyện trên tất cả các tác vụ trong chuỗi tác vụ. Đối với các chuỗi tác vụ hình ảnh với huấn luyện trước, ranh giới cho mỗi thành phần đặc trưng được đặt thành -1 và 6.

### D. Điều chỉnh Siêu tham số

Trong EWC, SI, AQC và NC, có một siêu tham số λ xác định cường độ điều hòa. SI có một siêu tham số giảm xóc bổ sung ξ và NC có một siêu tham số bán kính bổ sung r. Điều chỉnh siêu tham số được thực hiện dựa trên độ chính xác trung bình cuối cùng xác thực thông qua tìm kiếm lưới trong các giá trị sau:
• **EWC**: λ ∈ {1,10,100,1000,10000}
• **SI**: λ ∈ {1,10,100,1000,10000}, ξ ∈ {0.1,1.0,10}
• **AQC**: λ ∈ {1,10,100,1000,10000}
• **NC**: λ ∈ {1,10,100,1000,10000}, r ∈ {1,10,100}

**BẢNG I**: Độ chính xác trung bình cuối cùng kiểm tra cho các phương pháp trên các chuỗi tác vụ cổ điển và hình ảnh. Đối với các chuỗi tác vụ cổ điển, kết quả cho hồi quy softmax (SR) và một mạng neural hoàn toàn kết nối (FCNN) được hiển thị. Huấn luyện trước trên một tác vụ tương tự được sử dụng cho các chuỗi tác vụ hình ảnh. NC hoạt động tốt nhất trong hầu hết các chuỗi tác vụ cổ điển trong khi AQC hoạt động tốt nhất trong tất cả các chuỗi tác vụ hình ảnh với một bộ trích xuất đặc trưng cố định được huấn luyện trước.

**(a) Chuỗi tác vụ cổ điển**

| Phương pháp | CI Split Iris | CI Split Wine |
|-------------|---------------|---------------|
|             | SR    | FCNN  | SR    | FCNN  |
| Huấn luyện MAP kết hợp | 96.6667 | 100.0000 | 91.1111 | 91.1111 |
| Tinh chỉnh | 33.3333 | 33.3333 | 33.3333 | 33.3333 |
| G-VCL | 33.3333 | 33.3333 | 33.3333 | 33.3333 |
| GM-VCL | 33.3333 | 33.3333 | 33.3333 | 33.3333 |
| G-SFSVI | 66.6667 | 33.3333 | 33.3333 | 33.3333 |
| EWC | 63.3333 | 33.3333 | 46.6667 | 33.3333 |
| SI | 33.3333 | 33.3333 | 33.3333 | 33.3333 |
| AQC | 66.6667 | 63.3333 | 49.6032 | 33.3333 |
| NC | 93.3333 | 63.3333 | 62.6984 | 48.2540 |

**(b) Chuỗi tác vụ hình ảnh**

| Phương pháp | CI Split MNIST | CI Split CIFAR-10 | CI Split HAM-8 | DI Split MNIST | DI Split CIFAR-8 | DI Split HAM-6 |
|-------------|----------------|-------------------|----------------|----------------|------------------|----------------|
| Huấn luyện MAP kết hợp | 95.1077 | 76.2500 | 43.0531 | 93.4338 | 96.6250 | 68.3237 |
| Tinh chỉnh | 19.8382 | 19.0400 | 21.9512 | 64.4789 | 89.6250 | 63.8068 |
| G-VCL | 25.8657 | 19.0100 | 21.6463 | 80.1092 | 92.9000 | 63.3071 |
| GM-VCL | 25.2141 | 18.9800 | 21.0366 | 77.3996 | 92.6000 | 63.6112 |
| G-SFSVI | 51.1918 | 32.8000 | 34.6563 | 72.5471 | 91.2375 | 63.3381 |
| EWC | 73.3744 | 31.9400 | 30.8636 | 82.9540 | 94.6625 | 63.8068 |
| SI | 30.2364 | 27.0500 | 21.6463 | 79.4063 | 95.0750 | 64.0020 |
| AQC | 92.5394 | 61.3100 | 41.6660 | 90.9951 | 96.2000 | 66.1442 |
| NC | 77.5334 | 40.2500 | 24.1040 | 89.9168 | 93.8000 | 62.2400 |

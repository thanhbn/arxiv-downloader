# 2106.09563.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/continual-learning/2106.09563.pdf
# Kích thước tệp: 916008 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Được xuất bản tại Hội nghị thứ 1 về Các tác tử học tập suốt đời, 2022
VỀ HỌC TẬP BẤT KỲ LÚC NÀO Ở QUY MÔ LỚN
Lucas Caccia
Đại học McGill, Mila
Facebook AI Research
Jing Xu
Facebook AI Research
Myle Ott
Facebook AI Research
Marc'Aurelio Ranzato†
Facebook AI Research
Ludovic Denoyer‡
Facebook AI Research

TÓM TẮT
Trong nhiều ứng dụng thực tế của học máy, dữ liệu đến tuần tự theo thời gian thành từng khối lớn. Các nhà thực hành sau đó phải quyết định cách phân bổ ngân sách tính toán của họ để đạt được hiệu suất tốt nhất tại bất kỳ thời điểm nào. Lý thuyết học tập trực tuyến cho tối ưu hóa lồi gợi ý rằng chiến lược tốt nhất là sử dụng dữ liệu ngay khi nó đến. Tuy nhiên, điều này có thể không phải là chiến lược tốt nhất khi sử dụng mạng nơ-ron sâu phi tuyến, đặc biệt khi chúng thực hiện nhiều lần qua mỗi khối dữ liệu làm cho phân phối tổng thể không i.i.d.. Trong bài báo này, chúng tôi hình thức hóa cài đặt học tập này trong kịch bản đơn giản nhất trong đó mỗi khối dữ liệu được rút ra từ cùng một phân phối cơ bản, và thực hiện một nỗ lực đầu tiên để trả lời thực nghiệm các câu hỏi sau: Người học nên đợi bao lâu trước khi huấn luyện trên các khối mới đến? Kiến trúc nào mà người học nên áp dụng? Người học có nên tăng khả năng theo thời gian khi quan sát được nhiều dữ liệu hơn không? Chúng tôi khảo sát cài đặt học tập này bằng cách sử dụng mạng nơ-ron tích chập được huấn luyện trên các điểm chuẩn thị giác máy tính cổ điển cũng như một mô hình transformer lớn được huấn luyện trên nhiệm vụ mô hình hóa ngôn ngữ quy mô lớn. Mã nguồn có sẵn tại www.github.com/facebookresearch/ALMA.

1 GIỚI THIỆU
Trong nhiều ứng dụng thực tế của học máy, dữ liệu không tĩnh mà đến tuần tự thành từng khối lớn (hoặc mega-batch). Ví dụ, các hệ thống mô hình hóa ngôn ngữ được triển khai cần được cập nhật vài tháng một lần để thích ứng với các bản chụp nhanh mới của bộ dữ liệu Common Crawl¹. Tương tự, các hệ thống nhận dạng đối tượng thị giác cần được cập nhật khi dữ liệu được gán nhãn mới được thu thập nhờ người dùng tương tác với hệ thống. Hơn nữa, khi các cụm tính toán được trang bị thêm bộ nhớ và khả năng tính toán, các nhà thực hành học máy muốn huấn luyện các mô hình ngày càng lớn hơn trên lượng dữ liệu ngày càng tăng, vì các mô hình lớn hơn thường chính xác hơn. Trong bối cảnh này, họ đối mặt với một tình huống tiến thoái lưỡng nan: Làm thế nào để tối đa hóa hiệu suất của hệ thống tại bất kỳ thời điểm nào trong khi thỏa mãn một ngân sách tính toán nhất định?

Câu hỏi này chắc chắn đã được nghiên cứu trước đây, đáng chú ý nhất trong văn học học tập trực tuyến (Cesa-Bianchi & Lugosi, 2006). Ví dụ, trong bối cảnh contextual bandit, người học quan sát một ví dụ tại một thời điểm và nhận được phần thưởng sau khi đưa ra dự đoán. Tất nhiên, điều này có thể được mở rộng cho trường hợp đầu vào không chỉ là một ví dụ duy nhất mà là một tập hợp các ví dụ (sau đây được gọi là mega-batch).

Trong khi các nghiên cứu trước về học tập trực tuyến thiết lập một khuôn khổ lý thuyết chắc chắn, có một số vấn đề tinh tế làm cho nó không hoàn toàn áp dụng được cho bối cảnh thực tế được mô tả ở trên. Đầu tiên, tính toán hiếm khi được tính đến một cách rõ ràng, trong khi trên thực tế các thuật toán quá tính toán thâm dụng không thể được xem xét ở quy mô lớn. Thứ hai, phần lớn các nghiên cứu này giả định tính tuyến tính của các bộ dự đoán và tính lồi của các bài toán tối ưu hóa, theo đó thứ tự của các ví dụ không thay đổi nghiệm tối ưu. Thay vào đó, trong nhiều ứng dụng thực tế (như mô hình hóa ngôn ngữ) chúng ta quan tâm đến việc sử dụng mạng nơ-ron sâu có tính phi tuyến cao và ánh xạ đến các bài toán tối ưu hóa phi lồi. Sự thiếu tính tuyến tính cản trở phân tích lý thuyết và có những tác động thực tế sâu sắc. Ví dụ, theo lý thuyết học tập trực tuyến, tình huống tốt nhất đạt được khi không có độ trễ (Joulani et al., 2016;

* Các tác giả đóng góp như nhau
†Hiện tại ở DeepMind
‡Hiện tại ở Ubisoft
¹https://commoncrawl.org/the-data/

--- TRANG 2 ---
Được xuất bản tại Hội nghị thứ 1 về Các tác tử học tập suốt đời, 2022

[Biểu đồ so sánh ALMA với các framework học tập khác và ví dụ về đường cong học tập CIFAR 10]

Hình 1: Trái: ALMA so với các framework học tập khác. Trong ALMA, các mega-batch dữ liệu được rút ra từ cùng một phân phối (không có drift) và đến tuần tự, nhưng người học có thể quyết định đợi bao lâu trước khi huấn luyện trên chúng. Trong giới hạn, nếu người học đợi đến cuối luồng thì việc học trở về học tập có giám sát batch tiêu chuẩn. Phải: Ví dụ về đường cong học tập CIFAR 10 thay đổi thời gian đợi trước khi cập nhật mô hình. Đợi một số lượng nhỏ mega-batch trước khi cập nhật các tham số dẫn đến tỷ lệ lỗi anytime thấp hơn (diện tích nhỏ hơn dưới đường cong học tập).

Flaspohler et al., 2021), có nghĩa là các ví dụ và tín hiệu lỗi của chúng tốt nhất nên được tiêu thụ ngay lập tức mà không có bất kỳ sự cũ nào trong các tham số mô hình. Sử dụng ngôn ngữ của nhà thực hành huấn luyện mô hình ngôn ngữ, điều này có nghĩa là theo học tập trực tuyến lồi, chiến lược tốt nhất là huấn luyện từng mega-batch một. Tuy nhiên, điều này có thể không phải là một chiến lược tốt.

Hãy xem xét điều gì sẽ xảy ra nếu mạng nơ-ron sâu thực hiện nhiều lần qua mỗi mega-batch trước khi xử lý batch tiếp theo, và so sánh hiệu suất của nó với người học đợi tất cả các mega-batch đến trước khi xáo trộn tất cả dữ liệu và áp dụng cùng một thuật toán tối ưu hóa gradient ngẫu nhiên như được hiển thị ở phần bên phải của Hình 1. Cài đặt sau là quy trình tiêu chuẩn được sử dụng trong học tập có giám sát (đường cong xanh): thuật toán học tập tối ưu hóa một mục tiêu cố định (tức là rủi ro thực nghiệm trên toàn bộ tập dữ liệu huấn luyện) được biết là tạo ra các bộ dự đoán tốt. Trong khi bộ dự đoán này đạt được hiệu suất cuối cùng tốt nhất, nó cũng đạt được hiệu suất anytime tồi tệ nhất vì các dự đoán của nó là ngẫu nhiên trong suốt trải nghiệm học tập. Trong cài đặt trước, bằng cách cập nhật sau mỗi mega-batch mới (đường cong tím), chúng ta có thể mong đợi duy trì một bộ dự đoán tốt trong suốt trải nghiệm huấn luyện, khắc phục vấn đề được mô tả trước đây. Tuy nhiên trong trường hợp này, người học đang đối mặt với một mục tiêu học tập thay đổi, vì mỗi mega-batch mới xác định một rủi ro thực nghiệm hơi khác nhau (Jothimurugesan et al., 2018). Trong khi chúng ta có thể mong đợi hiệu ứng này không đáng kể khi sử dụng các mô hình tuyến tính cuối cùng sẽ hội tụ đến cùng một optimum toàn cục khi tất cả mega-batch đều có sẵn, điều này không đúng khi sử dụng các bộ dự đoán phi tuyến như mạng nơ-ron sâu. Trong trường hợp đó, chuỗi các bài toán tối ưu hóa được tạo ra bởi chuỗi các mega-batch có thể dẫn người học đến một optimum (cục bộ) hoàn toàn khác so với cài đặt học tập có giám sát, và do đó đến một bộ dự đoán hoàn toàn khác. Do đó có một câu hỏi mở về cách các mô hình khác nhau hoạt động khi thực hiện học tập tuần tự trên một luồng mega-batch.

Trong bài báo này, chúng tôi phân tích thực nghiệm một số mô hình học sâu (§4) dưới giả định rằng dữ liệu đến như một chuỗi các mega-batch, tất cả được rút ra từ cùng một phân phối để đơn giản. Vì chúng tôi quan tâm đến các mô hình đạt được hiệu suất tốt tại bất kỳ thời điểm nào và vì chúng tôi chỉ đánh giá sau khi học trên mỗi mega-batch chứ không phải trong quá trình học của mỗi mega-batch riêng lẻ, chúng tôi gọi cài đặt học tập này là Học tập Bất kỳ lúc nào ở quy mô lớn (ALMA) (§3).

Thông qua phân tích thực nghiệm mở rộng (§5), chúng tôi cung cấp bằng chứng hỗ trợ rằng đợi một vài mega-batch trước khi cập nhật mô hình thường là chiến lược tốt nhất, mặc dù thời gian đợi phụ thuộc vào một số yếu tố như horizon thời gian và kích thước mô hình so với lượng dữ liệu trong mỗi mega-batch. Thứ hai, các mô hình lớn hơn có hiệu quả thống kê hơn và tổng quát hóa tốt hơn. Thứ ba, không có phương pháp nào chúng tôi thử để phát triển kiến trúc hiệu quả hơn các phương pháp thay thế đơn giản hơn sử dụng kiến trúc cố định, như ensembling. Nhìn chung, nghiên cứu này cung cấp hướng nghiên cứu tương lai rõ ràng, và cũng là một nền tảng để đo điểm các phương pháp mới so với các baseline được tinh chỉnh tốt (mã nguồn có sẵn trong tài liệu bổ sung).

2 CÔNG TRÌNH LIÊN QUAN
ALMA liên quan đến một số framework học tập khác như được minh họa ở bên trái Hình 1. i) Nó chia sẻ cùng giả định của học tập có giám sát batch cổ điển (Vapnik, 1998) ở cấp độ của mỗi mega-batch. Tuy nhiên, nó tổng thể vi phạm các giả định về quan sát i.i.d., vì các điểm dữ liệu đến trong một luồng mega-batch và vì người học thường thực hiện nhiều lần qua mỗi mega-batch. Hơn nữa, trong ALMA người học có thể chọn đợi bao lâu trước khi huấn luyện. Theo nghĩa này, học tập có giám sát batch có thể được coi là một trường hợp cực đoan của ALMA (mega-batch đơn vì người học đợi đến cuối luồng để huấn luyện). ii) Như đã đề cập trong phần trước,

--- TRANG 3 ---
Được xuất bản tại Hội nghị thứ 1 về Các tác tử học tập suốt đời, 2022

ALMA liên quan đến học tập trực tuyến (Bottou, 1998) vì dữ liệu đến tuần tự và vì trong cả hai trường hợp chúng ta đo hiệu suất theo regret (mặc dù trong §3.1 lỗi tích lũy của chúng ta thiếu một oracle tham chiếu vì điều này không được biết trong cài đặt của chúng ta). Tuy nhiên, trong ALMA chúng ta cũng rõ ràng về ngân sách tính toán được sử dụng bởi mô hình và nhắm đến việc đạt được sự cân bằng tốt giữa regret và chi phí tính toán. Trong nghiên cứu hiện tại, chúng tôi hạn chế ALMA đến các phân phối dừng, trong khi học tập trực tuyến tổng quát hơn và bao gồm cả các phân phối không dừng. Cuối cùng và quan trọng nhất, trong ALMA chúng ta tập trung vào các bộ dự đoán phi tuyến trong khi văn học điển hình về học tập trực tuyến xem xét các bộ dự đoán tuyến tính. iii) Tương tự, ALMA liên quan đến concept drift (Lu et al., 2018) vì tính chất tuần tự của các quan sát. Tuy nhiên, văn học về concept drift thường tập trung vào các bộ dự đoán tuyến tính. iv) ALMA có thể được xem như một trường hợp thoái hóa của học tập liên tục có giám sát, nơi phân phối nhiệm vụ là dừng. Tuy nhiên, trong học tập liên tục có giám sát thường có sự tập trung vào việc đạt được một bộ dự đoán đại diện cho toàn bộ phân phối nhiệm vụ vào cuối quá trình học tập, trong khi trong ALMA chúng ta đo lỗi tích lũy như trong prequential learning. v) ALMA liên quan rộng rãi hơn đến transfer learning (Pan & Yang, 2010), vì vấn đề thích ứng với một batch dữ liệu mới có thể được hiểu như việc tận dụng kiến thức thu được trên các batch trước đó để học hiệu quả hơn từ batch dữ liệu mới. vi) Cuối cùng, ALMA liên quan đến anytime learning (Grefenstette & Ramsey, 1992; Ramsey & Grefenstette, 1994), điều này gần đây đã được áp dụng để so sánh các framework autoML khác nhau (Liu et al., 2020). Tuy nhiên, không giống như anytime learning truyền thống, trong công trình này chúng ta không quan tâm đến việc đánh giá khả năng anytime learning ở cấp độ của mỗi mega-batch, mà chỉ ở độ chi tiết thô hơn, ở cấp độ của toàn bộ luồng mega-batch. Cuối cùng, chúng tôi lưu ý rằng trong khi anytime learning hoạt động trong cài đặt tương tự như học tập trực tuyến (xem Hình 1), nó thường được sử dụng với các bộ dự đoán phi tuyến trong cài đặt học tập có giám sát.

Theo hiểu biết tốt nhất của chúng tôi, công trình liên quan nhất là của Sahoo et al. (2018) xem xét một cài đặt tương tự như của chúng tôi, ngoại trừ luồng của họ được cấu thành bởi các ví dụ riêng lẻ và trong cài đặt của họ không có khái niệm về thời gian chờ cũng như không xem xét lại các điểm dữ liệu nhiều lần. Tuy nhiên, họ cũng đo điểm so với các phương pháp tăng khả năng theo thời gian, mặc dù phân tích của họ được giới hạn ở các mạng kết nối đầy đủ.

3 CÀI ĐẶT HỌC TẬP
Trong anytime learning ở quy mô lớn (ALMA), chúng ta giả định rằng tồn tại một phân phối dữ liệu cơ bản p(x,y) với đầu vào x ∈ R^D và nhãn mong muốn y ∈ {1,...,C}. Để đơn giản trong trình bày, trong công trình này chúng tôi giới hạn bản thân với các bài toán phân loại, nhưng các lập luận tương tự có thể được đưa ra cho hồi quy, chẳng hạn. Tính chất chủ yếu của ALMA là dữ liệu được trình bày cho người học như một luồng S_B của B batch liên tiếp các ví dụ. Gọi D_i là một bộ sưu tập N_0 mẫu i.i.d. được rút ngẫu nhiên từ p(x,y), cho i ∈ {1,...,B}. Luồng sau đó được định nghĩa là chuỗi có thứ tự S_B = {D_1,...,D_B}. Chúng tôi gọi mỗi tập dữ liệu D_i là mega-batch, vì nó được cấu thành bởi một số lượng lớn các ví dụ.

Thông thường một người học m: R^D → {1,...,C} cập nhật các tham số của nó bằng cách xử lý một mini-batch gồm n << N ví dụ tại một thời điểm từ mỗi mega-batch D_i theo cách để tối thiểu hóa hàm mục tiêu của nó. Vì dữ liệu được quan sát như một luồng mega-batch, người học không thể tiếp cận các mega-batch trong tương lai, và cross-validation các siêu tham số mô hình chỉ có thể được thực hiện bằng cách sử dụng một tập con của mega-batch hiện tại. Nói cách khác, người học chỉ có thể thực hiện một lần qua luồng. Tuy nhiên, người học thường thực hiện nhiều lần qua mega-batch hiện tại nếu điều này cải thiện khả năng tổng quát hóa của nó. Trên thực tế, người học có thể thực hiện nhiều lần qua mega-batch hiện tại và một số mega-batch trước đó, mặc dù replay quá nhiều có thể cuối cùng làm cạn kiệt ngân sách tính toán của nó.

Dù thế nào, vì người học thực hiện nhiều lần qua mỗi mega-batch, phân phối dữ liệu tổng thể được quan sát bởi người học vào cuối luồng không phải là i.i.d., mặc dù các mega-batch được rút từ cùng một phân phối cơ bản p(x,y) và các mẫu được rút từ mỗi mega-batch là i.i.d. Ví dụ, trong trường hợp giới hạn nơi mỗi mega-batch bao gồm một ví dụ duy nhất từ một tập n ví dụ và một người học thực hiện k lần qua mỗi mega-batch, luồng sẽ bao gồm một chuỗi các ví dụ (theo một thứ tự nhất định) mỗi cái được nhân bản k lần, điều này khác với việc rút đồng đều ngẫu nhiên kn ví dụ từ tập gốc n ví dụ. Điều này ngụ ý một sự cân bằng giữa việc khớp dữ liệu hiện tại tốt so với tổng quát hóa tốt vào cuối luồng.

Trong ALMA, người học có một siêu tham số bổ sung so với các framework học tập khác: Nó có thể quyết định đợi bao lâu trước khi cập nhật các tham số của nó. Chúng tôi đo thời gian chờ đợi này theo số lượng mega-batch liên tiếp. Ví dụ, một mô hình có thời gian chờ bằng k, tổng hợp k mega-batch liên tiếp trước khi cập nhật các tham số của nó. Điều này sẽ hy sinh một chút hiệu suất của nó trong thời gian chờ đợi, nhưng có thể cuối cùng mang lại sự tổng quát hóa tốt hơn vì mô hình có thể xáo trộn dữ liệu tốt hơn và tiến gần hơn đến phân phối dữ liệu i.i.d. lý tưởng cần thiết bởi tối ưu hóa gradient ngẫu nhiên.

--- TRANG 4 ---
Được xuất bản tại Hội nghị thứ 1 về Các tác tử học tập suốt đời, 2022

Thuật toán 1 Huấn luyện trong cài đặt ALMA
1: procedure TRAIN(m, w, replay, grow) . m là mô hình, w là thời gian chờ
2: t ← 1
3: D ← ∅
4: while t < B do . Cho mỗi giai đoạn
5:   if replay then . Thu thập w mega-batch
6:     D ← D ∪ D_t ∪ ⋯ ∪ D_{t+w-1}
7:   else
8:     D ← D_t ∪ ⋯ ∪ D_{t+w-1}
9:   t ← t + w
10:  if grow then
11:    m.grow() . Phát triển mô hình nếu mô hình là mô hình phát triển
12:  m.train(D) . Fine-tune hoặc huấn luyện lại từ đầu m trên tập dữ liệu được thu thập

3.1 CHỈ SỐ
Chúng tôi đánh giá người học trong cài đặt ALMA theo ba trục, cụ thể là: tỷ lệ lỗi, bộ nhớ và tính toán. Gọi t là thời điểm mà mega-batch thứ t đến; dữ liệu này có thể được sử dụng bởi mô hình để cập nhật các tham số của nó hoặc nó chỉ đơn giản được tổng hợp với các mega-batch trước đó để sử dụng sau này.

Chúng tôi tính toán tỷ lệ lỗi của mô hình m tại thời điểm t (sau khi đến và cập nhật tiềm năng trên mega-batch thứ t) và tính toán diện tích dưới đường cong thu được khi thay đổi t từ 0 đến tổng số mega-batch B; tỷ lệ lỗi tích lũy (CER) kết quả là:

CER = ∑_{t=1}^B (1/|D_{Ts}|) ∑_{(x,y)∈D_{Ts}} |m(x,t) ≠ y|     (1)

trong đó m(x,t) là mô hình tại thời điểm t được trang bị các tham số θ_t, D_{Ts} là tập kiểm tra (chung cho tất cả mega-batch trong luồng), |D_{Ts}| là số lượng ví dụ trong tập kiểm tra, và |m(x,t) ≠ y| là một nếu dự đoán mô hình không khớp với nhãn sự thật cơ bản và không nếu ngược lại. Tổng ngoài tính toán tích phân rời rạc của tỷ lệ lỗi theo thời gian. CER sẽ nhỏ chỉ khi tỷ lệ lỗi nhỏ trong suốt toàn bộ luồng. CER thay vào đó lớn cho một mô hình muộn màng đợi đến mega-batch cuối cùng để cập nhật mô hình, mặc dù cuối cùng điều này có thể đạt được tỷ lệ lỗi cuối cùng rất thấp.

Tương tự, chúng tôi tính toán việc sử dụng bộ nhớ tích lũy và tính toán như:

Mem = ∑_{t=0}^B |θ_t|; Comp = ∑_{t=0}^B O(m(·,t))     (2)

trong đó |θ_t| là số lượng tham số tự do của mô hình tại thời điểm t, và O(m(·,t)) là số lượng flops được sử dụng bởi mô hình để xử lý mega-batch thứ t.

Lưu ý rằng các chỉ số trên được đo bởi môi trường khi huấn luyện tiến triển, và sẽ được sử dụng trong đánh giá thực nghiệm của chúng tôi (§5). Tuy nhiên, người học không có quyền truy cập vào tập kiểm tra. Người học chỉ có quyền truy cập vào tập validation của mega-batch hiện tại, và chỉ có thể sử dụng điều đó để chọn các siêu tham số của riêng mình.

4 THUẬT TOÁN HỌC TẬP
Trong phần này, chúng tôi mô tả các phương pháp chúng tôi đã thử nghiệm trong cài đặt ALMA. Chúng nhìn chung tuân theo quy trình học tập được hiển thị trong Thuật toán 1. Ở mức độ cao, chúng tôi xem xét hai họ mô hình, những mô hình có kiến trúc nguyên khối và những mô hình có kiến trúc mô-đun (ví dụ: ensembling). Họ sau có thể phát triển theo thời gian bằng cách thêm các mô-đun mới vào tập hiện có. Chúng tôi sẽ bắt đầu bằng cách mô tả các kiến trúc cố định (§4.1) và sau đó kết thúc với các kiến trúc phát triển (§4.2). Chúng tôi cũng đánh giá các mô hình trong cài đặt nơi chúng có thể replay các mega-batch trước đó.

4.1 KIẾN TRÚC CỐ ĐỊNH
Họ phương pháp đầu tiên huấn luyện các mô hình với kiến trúc cố định. Những mô hình này được huấn luyện tuần tự trên các mega-batch mới và thể hiện dấu chân bộ nhớ cố định. Chúng tôi xem xét ba mô hình:

--- TRANG 5 ---
Được xuất bản tại Hội nghị thứ 1 về Các tác tử học tập suốt đời, 2022

Mô hình Đơn (SM): Đây là một mạng nơ-ron đa lớp tiêu chuẩn (ví dụ: mạng nơ-ron kết nối đầy đủ hoặc transformer) được huấn luyện bằng gradient descent ngẫu nhiên và khởi tạo từ các tham số của mô hình được huấn luyện trên mega-batch trước đó, trừ khi được chỉ định khác.

Ensemble các Mô hình (Ens): Phương pháp thứ hai là phương pháp mô-đun đơn giản nhất, bao gồm một ensemble của N mạng nơ-ron với cùng kiến trúc nhưng khác seed khởi tạo ngẫu nhiên, mỗi mạng được huấn luyện độc lập trên cùng dữ liệu. Đầu ra của mô hình tổng thể tại thời điểm kiểm tra là phân phối xác suất trung bình được tạo ra bởi mỗi thành phần². Ưu điểm của Ens là huấn luyện và suy luận có thể được song song hóa một cách tầm thường, cho phép mở rộng các tham số mô hình rất dễ dàng. Nhược điểm là suy luận đòi hỏi nhiều hơn N lần tính toán so với những gì được yêu cầu bởi mỗi thành phần.

Hỗn hợp Đồng nhất các Mô hình (UMix): Một nhược điểm tiềm năng của Ens là đánh giá và huấn luyện không nhất quán, có nghĩa là huấn luyện và kiểm tra sử dụng các bộ dự đoán mô hình khác nhau. UMix giải quyết điều này bằng cách huấn luyện một mô hình có dự đoán là trung bình (trong không gian logit) của các dự đoán được tạo ra bởi N mạng. Mặc dù điều này đòi hỏi đồng bộ hóa trong quá trình huấn luyện, bây giờ cả huấn luyện và đánh giá đều sử dụng cùng một mô hình.

4.2 KIẾN TRÚC PHÁT TRIỂN
Trong phần trước, số lượng tham số và kiến trúc của mô hình được cố định trong suốt vòng đời của mô hình. Tuy nhiên, khi quan sát được nhiều dữ liệu hơn, thật thú vị khi xem xét các kiến trúc động phát triển theo thời gian, vì chúng có thể tiết kiệm tính toán và bộ nhớ trong các giai đoạn đầu của việc học trong khi cung cấp nhiều sức mạnh dự đoán hơn trong các giai đoạn sau. Chúng tôi xem xét ba phương pháp phát triển:

Ensemble Phát triển (gEns): Giống như mô hình Ens, gEns cũng là sự kết hợp của các mạng nơ-ron được huấn luyện độc lập. Trong khi Ens xem xét một số cố định các mạng được, tại mỗi giai đoạn, huấn luyện trên chunk dữ liệu mới, gEns thay thế bước này bằng một bước phát triển nơi k mạng nơ-ron mới được thêm vào. Trong triển khai của chúng tôi, chỉ những k mạng nơ-ron này được huấn luyện trên dữ liệu mới, trong khi các mạng nơ-ron khác (được huấn luyện trên các mega-batch trước đó) được giữ cố định. Do đó, khi bắt đầu với một thành phần duy nhất và cho đến bước phát triển tiếp theo, chi phí huấn luyện gEns bằng SM cho cùng kiến trúc mô hình. Trừ khi được chỉ định khác, chúng tôi sử dụng k = 1 cho các thí nghiệm trong bài báo.

Hỗn hợp Phát triển các Chuyên gia (gMoE): Một mô hình hỗn hợp chuyên gia phân cấp (MoE) là một kiến trúc nơi tại lớp l đầu ra biểu diễn z^l là: z^l = ∑_{j=1}^k g(j|z^{l-1})h(z^{l-1}|θ_j), trong đó g là hàm gating hoặc routing và h(·|θ_j) là chuyên gia thứ j. So với Ens, MoE có nhiều thành phần hơn theo cấp số nhân mặc dù có nhiều chia sẻ tham số. Một ưu điểm khác là khi chỉ chọn một (hoặc một vài) chuyên gia, chi phí tính toán độc lập với số lượng chuyên gia, giả sử chi phí gating không đáng kể so với chi phí thực thi các chuyên gia. Vấn đề chính là MoE nổi tiếng khó huấn luyện hơn (Eigen et al., 2014; Denoyer & Gallinari, 2015; Lepikhin et al., 2020). Trong công trình này, chúng tôi xem xét một phiên bản phát triển của MoE, mà chúng tôi ký hiệu là gMoE, theo đó các chuyên gia được thêm vào dần dần theo thời gian. Điều này có hàm gating cấu trúc cây nơi các lá tương ứng với các chuyên gia. Tại mỗi lớp, chúng tôi tính toán đóng góp của mỗi chuyên gia vào tổng loss bằng cách tổng hợp các loss của các ví dụ được định tuyến qua chuyên gia đó. Sau đó chúng tôi "tách" chuyên gia chịu trách nhiệm cho đóng góp lớn nhất vào loss. Việc tách được thực hiện bằng cách thêm một chuyên gia với cùng tham số, và biến nút lá tương ứng của gate thành nút nội bộ nhị phân với lá con cho chuyên gia cũ và mới. Quá trình này đảm bảo rằng ngay trước và ngay sau một bước phát triển, loss là như nhau. Xem Phụ lục A để biết thêm chi tiết.

Firefly (Wu et al., 2020) (FF): FF là một phương pháp phát triển dần dần các mạng nơ-ron, tối ưu hóa đồng thời cả kiến trúc mô hình và tham số. Sự phát triển bao gồm cả mở rộng chiều rộng bằng cách thêm các đơn vị ẩn mới (hoặc feature maps) cũng như mở rộng chiều sâu bằng cách thêm các lớp mới. Quan trọng là, đây là một ví dụ về phương pháp phi mô-đun không giống như Ens hoặc gMoE, có khả năng biểu đạt hơn nhưng cũng kém hiệu quả hơn tại thời gian suy luận vì không có tính thưa thớt có cấu trúc có thể được tận dụng để tăng tốc tính toán.

5 THÍ NGHIỆM
Trong phần này, trước tiên chúng tôi mô tả cách các điểm chuẩn tiêu chuẩn có thể được tái sử dụng cho ALMA, sau đó chúng tôi cung cấp các chi tiết của các mô hình chúng tôi đã thử nghiệm, và cuối cùng chúng tôi kết thúc với phân tích các kết quả chúng tôi đã đạt được, nhắm đến việc hiểu phương pháp nào đạt được sự cân bằng tốt nhất giữa thời gian, độ chính xác, tính toán và sử dụng bộ nhớ.

² Các phương pháp bagging cổ điển và chiến lược bỏ phiếu đa số cũng đã được khám phá mà không có sự khác biệt đáng kể.

--- TRANG 6 ---
Được xuất bản tại Hội nghị thứ 1 về Các tác tử học tập suốt đời, 2022

Tập dữ liệu Chúng tôi xem xét nhiều tập dữ liệu khác nhau. Tập dữ liệu đầu tiên là CIFAR 10 (Krizhevsky, 2009) có tập huấn luyện với 50,000 hình ảnh kích thước 32x32 pixel thuộc 10 lớp như chim, ô tô, ngựa, tàu, xe tải, v.v. Tập dữ liệu thứ hai là MNIST (LeCun et al., 1998), bao gồm tập huấn luyện với 60,000 chữ số viết tay gần nhị phân kích thước 28x28 pixel, và tập kiểm tra với 10,000 ví dụ. Tập dữ liệu thứ ba, được sử dụng cho đánh giá mô hình hóa ngôn ngữ quy mô lớn của chúng tôi, là một phần của bộ sưu tập văn bản tiếng Anh được giới thiệu trong Liu et al. (2019), bao gồm Books, Wikipedia và Common Crawl. Chúng tôi xem xét 4 mega-batch (lớn) để huấn luyện và một mega-batch bổ sung để đánh giá, mỗi cái bao gồm khoảng 440M từ; chúng tôi cũng giữ lại một tập validation với khoảng 0.5M từ Common Crawl để lựa chọn mô hình. Chúng tôi sử dụng mã hóa byte-pair (BPE) (Sennrich et al., 2016) với từ vựng 50,000 đơn vị, theo Radford et al. (2019). Tập dữ liệu này khá đại diện cho những gì các nhà thực hành có thể đối mặt khi duy trì một hệ thống được triển khai với dữ liệu mới đến vài tháng một lần.

Cho một tập dữ liệu như bất kỳ tập nào ở trên, chúng tôi xây dựng một điểm chuẩn cho đánh giá ALMA như sau: 1) chúng tôi phân vùng ngẫu nhiên tập huấn luyện thành B mega-batch với số lượng bằng nhau các ví dụ huấn luyện (B = 100 cho CIFAR, B = 500 cho MNIST và B = 4 cho tập dữ liệu văn bản), 2) từ mỗi mega-batch chúng tôi trích xuất 10% dữ liệu để xây dựng tập validation mega-batch (ngoại trừ tập dữ liệu mô hình hóa ngôn ngữ quy mô lớn nơi chúng tôi sử dụng tập validation được cung cấp), và 3) chúng tôi tạo ra trải nghiệm học tập bằng cách thực hiện một lần qua chuỗi các mega-batch. Đối với mỗi mega-batch, người học có thể truy vấn bao nhiêu mini-batch tùy ý. Người học cũng có thể quyết định không huấn luyện trên dữ liệu của một mega-batch ngay lập tức mà thay vào đó đợi và tích lũy dữ liệu qua một vài mega-batch liên tiếp. Trong khi người học quan sát dữ liệu, nó cũng được kiểm tra trên tập kiểm tra. Điều này không được sử dụng cho mục đích validation, mà chỉ để báo cáo cuối cùng như được hiển thị trong §6.

Mô hình Chúng tôi đánh giá sáu phương pháp được trình bày trong §4, và đối với mỗi phương pháp chúng tôi xem xét các thời gian chờ khác nhau, một phiên bản có và không có replay, và ít nhất bốn kích thước mô hình. Đối với các phương pháp có kiến trúc mở rộng, chúng tôi thử các cấu hình khác nhau của siêu tham số kiểm soát khi nào phát triển và phát triển bao nhiêu. Để đơn giản, chúng tôi giới hạn các giai đoạn mở rộng chỉ xảy ra giữa các mega-batch. Tiếp theo, chúng tôi mô tả chi tiết kiến trúc được sử dụng trên mỗi tập dữ liệu. Các chi tiết thí nghiệm bổ sung để hỗ trợ tái tạo được báo cáo trong Phụ lục B.

Trên MNIST, kiến trúc backbone của SM là một mạng nơ-ron kết nối đầy đủ ba lớp với các đơn vị ReLU. Chúng tôi xem xét các kích thước đơn vị ẩn khác nhau, từ 4 đến 64 (mà chúng tôi gọi là [small] và [large], tương ứng), cho phép chúng tôi mô phỏng chế độ dữ liệu lớn so với kích thước của mạng và khám phá cách phát triển kiến trúc mà không cần lo lắng về overfitting. Tương tự, các thành phần của Ens, gEns và UMix là các mạng SM có cùng kích thước như đã nêu ở trên; gMoE cũng bắt đầu như SM và thêm các mô-đun (tại hai lớp đầu tiên) có cùng kích thước như lớp gốc của SM.

Trên CIFAR 10, các phương pháp và ký hiệu giống như trong MNIST. Sự khác biệt duy nhất là kiến trúc backbone là phiên bản thu nhỏ của mạng nơ-ron tích chập VGG19 (Simonyan & Zisserman, 2015) như trong (Wu et al., 2020), nơi số lượng feature maps trung gian giống nhau cho mỗi lớp, từ 4 đến 64. Trên tập dữ liệu này, chúng tôi cũng xem xét FF bắt đầu từ cùng backbone VGG19.

Đối với nhiệm vụ mô hình hóa ngôn ngữ, SM là một Switch Transformer (Fedus et al., 2021), đây là một mô hình hỗn hợp chuyên gia cứng với một thuật ngữ loss cân bằng tải bổ sung và ràng buộc khả năng cứng được áp dụng trong quá trình huấn luyện để ngăn chặn việc sử dụng chuyên gia không đều. Theo Fedus et al. (2021), chúng tôi cố định trọng số của thuật ngữ loss cân bằng thành 0.01 và sử dụng hệ số khả năng là 1, đảm bảo việc sử dụng chuyên gia tương đối đồng nhất. Chúng tôi huấn luyện mô hình sử dụng Adam (Kingma & Ba, 2015) và tinh chỉnh learning rate và dropout trên tập validation. Trong cài đặt phát triển, chúng tôi sao chép trọng số chuyên gia và trọng số mạng gating tương ứng với k chuyên gia hàng đầu chịu loss lớn nhất, nơi k thường từ 2 đến 4. Quy trình phát triển này duy trì một hỗn hợp phẳng và thêm nhiều chuyên gia tại một thời điểm. Mặc dù phương pháp này hoạt động hơi kém hơn so với phương pháp được mô tả trong §4.2, nó dễ triển khai hơn ở quy mô lớn. Chúng tôi xem xét hai kích thước mô hình: một mô hình cơ bản với 6 lớp và chiều mô hình 512, tổng cộng 40M tham số chia sẻ và 6M tham số bổ sung cho mỗi chuyên gia; và một mô hình lớn với 12 lớp và chiều mô hình 768, tổng cộng 96M tham số chia sẻ và 28M tham số bổ sung cho mỗi chuyên gia. Chúng tôi sử dụng độ dài chuỗi đầu vào 512 token và không sử dụng replay do kích thước mega-batch lớn. Trong mỗi mega-batch, chúng tôi huấn luyện tất cả các mô hình ngôn ngữ trong chính xác 120000 bước gradient (kết quả trong Hình 5) trừ khi được chỉ định khác (ví dụ: Bảng 1). Điều này giúp so sánh các mô hình dễ dàng hơn cho cùng ngân sách tính toán ở cấp độ mega-batch.

6 KẾT QUẢ
6.1 NHẬN DẠNG THỊ GIÁC
Vì các kết luận khá tương tự, chúng tôi tập trung phân tích trên tập dữ liệu CIFAR 10 thách thức hơn, và báo cáo kết quả cũng trên MNIST trong Phụ lục C.

Thời gian chờ nhỏ nhất có thể không tối ưu: Chúng tôi bắt đầu phân tích trong cài đặt không có replay, được hiển thị trong Hình 2. Đầu tiên chúng tôi quan sát rằng thời gian chờ trung gian (trong trường hợp này bằng 10) đạt được sự cân bằng tốt nhất giữa Tỷ lệ Lỗi Tích lũy (CER) và cả chi phí huấn luyện (trái) và chi phí bộ nhớ (phải). Như được hiển thị trong Hình 3-trên, nơi tỷ lệ lỗi kiểm tra được vẽ như một hàm của số lượng mega-batch nhận được, các phương pháp tham lam sử dụng thời gian chờ bằng 2 đạt được tỷ lệ lỗi thấp hơn chỉ trong giai đoạn đầu của luồng, nhưng bị vượt qua sau đó. Các bộ dự đoán muộn màng đợi tất cả 100 mega-batch trước khi huấn luyện đạt được độ chính xác cuối cùng tốt nhất, nhưng không có khả năng dự đoán trong suốt 99 mega-batch đầu tiên. Thay vào đó, các phương pháp với thời gian chờ trung gian (được hiển thị bằng màu cam) có thể nhanh chóng cung cấp một bộ dự đoán hợp lý sớm trong luồng, và đạt được tỷ lệ lỗi cuối cùng rất gần với giới hạn dưới thu được bởi các phương pháp muộn màng. Do đó, thời gian chờ 10 mang lại CER thấp nhất (hoặc diện tích dưới đường cong) trên CIFAR 10.

Tuy nhiên trên MNIST, thời gian chờ trung gian chỉ tốt nhất cho các mô hình nhỏ, như được hiển thị trong Hình 3-dưới. Các mô hình rất tham lam không hội tụ tốt trong cài đặt này, dẫn đến một hình phạt đáng kể về CER. Tuy nhiên, các mạng lớn hơn hội tụ rất nhanh chỉ trong một vài mega-batch, làm cho thời gian chờ nhỏ hơn trở nên mong muốn hơn. Do đó, thời gian chờ tối ưu phụ thuộc vào một số yếu tố như kích thước mô hình, horizon thời gian, độ khó của nhiệm vụ và tốc độ học của mô hình. Trong cài đặt phi lồi như vậy, chắc chắn không nhất thiết đúng rằng học trên dữ liệu ngay khi nó có sẵn luôn đạt được sự cân bằng tốt nhất giữa tỷ lệ lỗi và tính toán.

Các mô hình lớn hơn có hiệu quả thống kê hơn: Thứ hai, chúng tôi quan sát rằng các mô hình lớn hơn (SM và Ens) không chỉ tổng quát hóa tốt hơn mà còn có hiệu quả thống kê hơn: Ens nhỏ đạt được gần 40% tỷ lệ lỗi vào cuối trải nghiệm học tập của nó (Hình 3-trên trái), tệ hơn tỷ lệ lỗi thu được bởi Ens lớn chỉ sau khi quan sát một phần mười của toàn bộ luồng. Hiệu quả thống kê của các mô hình lớn không chỉ áp dụng cho các transformer lớn (Kaplan et al., 2020), mà còn cho các mô hình kết nối đầy đủ (chúng tôi thu được kết quả tương tự trên MNIST, xem Hình 3-dưới) và mô hình tích chập.

Phát triển không cải thiện: Nếu chúng ta tập trung sự chú ý vào ba phương pháp với kiến trúc phát triển, cụ thể là gMoE, gEns và FF, chúng ta thấy rằng không có người chiến thắng rõ ràng nào trong số họ. Khi so sánh qua một ngân sách tính toán cố định (Hình 2 trái), gEns nhìn chung hoạt động tốt hơn gMoE và FF. Tuy nhiên, khi chúng ta cố định ngân sách bộ nhớ thay vào đó (Hình 2 phải), gEns trung bình là phương pháp hoạt động tồi tệ nhất.

Tiếp theo, chúng tôi điều tra hiệu quả của việc phát triển, vì về nguyên tắc, chúng ta mong đợi rằng việc thích ứng khả năng mô hình với lượng dữ liệu nên đạt được sự cân bằng tốt hơn giữa độ chính xác và sử dụng bộ nhớ/tính toán. Đối với một ngân sách tính toán hoặc bộ nhớ cố định, luôn luôn tốt hơn khi bắt đầu với một mô hình lớn hơn, thay vì phát triển nó theo thời gian. Thật vậy, chúng tôi thấy rằng trên cả hai đồ thị của Hình 2, SM hầu như luôn vượt trội hơn gMoE và FF, một xu hướng đặc biệt hiển thị cho các ngân sách cao hơn của TFLOPS và tham số. Nói cách khác, một gMoE hoặc FF bắt đầu nhỏ và kết thúc lớn thường sẽ bị vượt trội bởi một mô hình SM có kích thước trung bình.

Cuối cùng, Ens hiệu quả hơn gEns về mặt bộ nhớ, nhưng ngược lại về mặt tính toán huấn luyện. Tuy nhiên, nếu chúng ta nhìn vào chi phí suy luận của cả hai phương pháp, chúng ta sẽ thấy rằng Ens vượt trội hơn đối tác phát triển của nó, có chi phí suy luận tăng theo thời gian trong khi nó cố định đối với Ens. Một lần nữa, chiến lược tốt nhất là chọn mô hình khả năng cố định lớn nhất cho một ngân sách tính toán nhất định. Lưu ý rằng những kết luận này áp dụng cho các phương pháp được xem xét trong nghiên cứu này, và cải thiện các phương pháp thích ứng động kiến trúc của chúng theo thời gian rõ ràng là một hướng nghiên cứu tương lai đáng giá.

Điểm hoạt động quan trọng: Chúng tôi tiếp tục bằng cách đối chiếu UMix và Ens, nơi phương pháp trước trung bình hóa các dự đoán trong quá trình huấn luyện giữa các thành phần khác nhau, trong khi phương pháp sau huấn luyện mỗi thành phần độc lập. Trong tất cả các thí nghiệm của chúng tôi khi làm việc với các mô hình nhỏ hơn, UMix có một lợi thế nhỏ trên cả mặt trận bộ nhớ và tính toán; tuy nhiên khi kích thước của mỗi thành phần trở nên lớn hơn, xu hướng đảo ngược, và Ens vượt trội hơn UMix. Chúng tôi suy đoán rằng các mô hình nhỏ hơn chịu đựng nhiều nhất từ sự kém hiệu quả vốn có của ensembling buộc mỗi thành phần phải học cùng một tập hợp các tính năng. Khi khả năng bị hạn chế, tốt hơn là phối hợp việc học giữa các thành phần thay vào đó. Nhìn chung, phát hiện này nhấn mạnh cách các kết luận về mô hình nào hoạt động tốt nhất thực sự phụ thuộc vào điểm hoạt động. Chỉ khi chúng ta xem xét toàn bộ phổ kích thước mô hình, chúng ta mới có thể kết luận phương pháp nào hoạt động tốt nhất.

Ens đạt được sự cân bằng tốt nhất: Tổng quát hơn, Ens là phương pháp hoạt động tốt nhất cho các mô hình lớn hơn qua tất cả các thí nghiệm của chúng tôi, bao gồm cả các mô hình ngôn ngữ được báo cáo trong §6.2. Đây là một phát hiện đáng chú ý cho sự đơn giản của phương pháp và việc song song hóa quá trình huấn luyện của chúng dễ dàng như thế nào. Ensembling làm cho việc tăng khả năng mô hình sớm rất dễ dàng, và cho đến nay là cách tốt nhất để sử dụng tính toán ở quy mô lớn, một dấu hiệu có thể của sự kém hiệu quả trong việc huấn luyện các mô hình lớn bằng các phương pháp thay thế, điều này nhấn mạnh một hướng nghiên cứu tương lai đáng giá khác.

Replay các mega-batch trong quá khứ không cải thiện: Chúng tôi bây giờ xem xét cùng các phương pháp như trước nhưng với các mô hình được huấn luyện trên tất cả các mega-batch đã thấy cho đến nay. Do đó, tại bước huấn luyện cuối cùng, các mô hình được huấn luyện trên toàn bộ tập dữ liệu (nối tất cả các mega-batch). Trong Hình 4, chúng tôi báo cáo kết quả khi thời gian chờ bằng 10. Trong tất cả trường hợp, replay dữ liệu cho kết quả tốt hơn với chi phí tăng tính toán. Ngoại trừ gEns, những cải thiện này gần như giống nhau cho tất cả các phương pháp, vì tất cả các phân đoạn song song với nhau. gEns ít lợi ích hơn vì thành phần cuối cùng được huấn luyện trên tập dữ liệu đầy đủ có ảnh hưởng không tương xứng trong trung bình mô hình bao gồm các thành phần được huấn luyện trên ít mega-batch hơn. Tuy nhiên, thành phần cuối cùng này về cơ bản trùng khớp với SM được huấn luyện trên tập dữ liệu đầy đủ. Do đó hai phương pháp hội tụ đến cùng hiệu suất khi sử dụng replay. Chúng tôi cung cấp kết quả bổ sung với replay trong Phụ lục C.2, cho thấy rằng có lợi ích từ replay chỉ ở các ngân sách tính toán cao hơn nơi thời gian chờ tối ưu cũng giảm xuống 1.

Quan trọng hơn, chúng tôi quan sát rằng replay không mang lại sự cân bằng tốt hơn đáng kể giữa CER và tính toán. Đối với cùng ngân sách tính toán, các phương pháp sử dụng replay đạt được CER tương tự như các phương pháp không sử dụng replay. Các yếu tố khác như kích thước của kiến trúc backbone hoặc thời gian chờ quan trọng hơn.

6.2 THÍ NGHIỆM MÔ HÌNH HÓA NGÔN NGỮ
Đối với các thí nghiệm mô hình hóa ngôn ngữ quy mô lớn, chúng tôi xem xét hai kích thước mô hình (base và large, xem §5), với chi phí suy luận trên mỗi đầu vào là 42 và 126 GFLOPS, tương ứng. Số lượng chuyên gia được đặt thành 4, 8 và 12 cho SM, và nó không ảnh hưởng đến chi phí suy luận vì chỉ có một chuyên gia trên mỗi đầu vào được chọn bất kể tổng số chuyên gia.

--- TRANG 9 ---
Được xuất bản tại Hội nghị thứ 1 về Các tác tử học tập suốt đời, 2022

[Biểu đồ hiển thị các so sánh về perplexity trung bình theo cumulative TFLOPS, số lượng tham số và số lượng chuyên gia]

Hình 5: Các cân bằng mô hình hóa ngôn ngữ: perplexity trung bình (PPL) so với tính toán tích lũy, số lượng tham số và số lượng chuyên gia. Các số màu đỏ đề cập đến số lượng chuyên gia trong các lần chạy SM tương ứng.

Do gánh nặng tính toán của những thí nghiệm này (tổng cộng hơn 200 GPU ngày), chúng tôi giới hạn phân tích của mình đến bốn mega-batch. Tuy nhiên, quy mô này (của mô hình và dữ liệu) và loại ứng dụng này khá đại diện cho một cài đặt ALMA điển hình. Vui lòng tham khảo Bảng 2 trong Phụ lục D để có phân tích toàn diện, vì ở đây chúng tôi sẽ chỉ nêu bật các phát hiện chính.

Kết quả chính được trình bày trong Hình 5. Mỗi dòng là một quỹ đạo với bốn điểm, một cho mỗi mega-batch trong luồng, vì chúng tôi báo cáo perplexity trung bình thay vì tích lũy. Đối với một kích thước mô hình nhất định và đối với một ngân sách tính toán nhất định, có ba mô hình SM, một cho mỗi số lượng chuyên gia chúng tôi xem xét, cụ thể là 4, 8 và 12.

Các mô hình lớn hơn hiệu quả hơn: Phù hợp với kết quả của chúng tôi trên các nhiệm vụ thị giác máy tính, chúng tôi quan sát rằng các mô hình lớn hơn có xu hướng tổng quát hóa tốt hơn và hiệu quả mẫu hơn. Ví dụ, mô hình lớn sau một mega-batch đơn vượt trội hơn tất cả các mô hình base, bao gồm cả các mô hình base sau bốn mega-batch đã thấy gấp bốn lần dữ liệu hơn. Phát hiện này nhất quán qua tất cả các phương pháp được thử cho thí nghiệm này.

Phát triển không cải thiện: Một lần nữa, không có người chiến thắng rõ ràng nào trong các phương pháp phát triển. Đối với các mô hình lớn hơn, gEns vượt trội hơn gMoE đối với cùng tính toán, và hoạt động tương tự cho các mô hình base. Tuy nhiên, đối với tất cả kích thước mô hình, gMoE hiệu quả bộ nhớ hơn, do đó phương pháp tối ưu trong số họ sẽ phụ thuộc vào cả ngân sách tính toán và bộ nhớ.

Quan trọng hơn, chúng tôi quan sát rằng các mô hình với khả năng cố định hiệu quả hơn về tính toán và bộ nhớ so với các mô hình phát triển theo thời gian. Nhìn vào perplexity trung bình như một hàm của số lượng chuyên gia, chúng ta thấy rằng các phương pháp bắt đầu với số lượng chuyên gia nhỏ và sau đó phát triển bị vượt trội bởi kiến trúc cố định tương tự có số lượng chuyên gia trung gian. Điều này nhấn mạnh tầm quan trọng của việc có nhiều khả năng hơn ở đầu quá trình huấn luyện, thay vì ở cuối.

Ensemble hoạt động tốt nhất: Thứ ba, Ens thịnh vượng trong cài đặt khả năng lớn hơn. Nhìn vào các điểm đánh dấu màu cam trong đồ thị, chúng ta thấy rằng đối với ngân sách tính toán bằng nhau, các phương pháp Ens vượt trội hơn tất cả các phương pháp khác, điều này nhất quán với kết quả thị giác máy tính. Trong cài đặt base thay vào đó, các phiên bản của SM (xem các điểm xanh thấp nhất) đạt được sự cân bằng tốt hơn trong cả tính toán và bộ nhớ.

Học tuần tự khó hơn: Chúng tôi lập luận ban đầu rằng một khi người học thực hiện nhiều lần qua mỗi mega-batch, phân phối dữ liệu không thể được coi là i.i.d. nữa, so với phân phối thực nghiệm của hợp tất cả các mega-batch. Tuy nhiên không rõ ràng vấn đề này có tác động thực tế bao nhiêu đến hiệu suất của mô hình. Để đánh giá điều này, chúng tôi chạy một thí nghiệm cuối cùng sử dụng phương pháp hoạt động tốt nhất của chúng tôi, cụ thể là Ens. Chúng tôi so sánh một mô hình được huấn luyện trên k mega-batch tuần tự với cùng mô hình được huấn luyện cùng lúc trên tập hợp của cùng k mega-batch. Vì cả hai phương pháp đều có cùng ngân sách tính toán, cùng kiến trúc và được cung cấp cùng dữ liệu, chúng ta có thể tách biệt hiệu ứng của bản chất không i.i.d. của dữ liệu trong ALMA. Kết quả được hiển thị trong Bảng 1 xác nhận rằng huấn luyện tuần tự của ALMA (seq.) thực sự thách thức hơn. Qua tất cả bốn cấu hình, các mô hình chịu sự sụt giảm hiệu suất khi so sánh với huấn luyện i.i.d. thông thường, và thậm chí hơn nữa khi mô hình lớn hơn. Khoảng cách này cung cấp một cơ hội nghiên cứu tương lai khác về cách làm cho huấn luyện tuần tự hiệu quả hơn khi sử dụng mạng nơ-ron sâu phi tuyến.

7 KẾT LUẬN
Trong phần tóm tắt, chúng tôi đã hứa với người đọc cung cấp một câu trả lời thực nghiệm cho một số câu hỏi:

--- TRANG 10 ---
Được xuất bản tại Hội nghị thứ 1 về Các tác tử học tập suốt đời, 2022

Phương pháp | PPL k=3, iid | PPL k=3, seq. | PPL k=4, iid | PPL k=4, seq.
---|---|---|---|---
Small Ens4@2 | 24.30 | 24.57 | 24.13 | 24.35
Big Ens4@2 | 18.04 | 19.14 | 17.88 | 18.92

Bảng 1: Ablation về hiệu ứng của học tuần tự (seq.) so với học với dữ liệu i.i.d. hoàn toàn, cho cùng lượng dữ liệu và tính toán. Mô hình là một ensemble với 2 thành phần mỗi cái với 4 chuyên gia mỗi block.

1) Người học nên đợi bao lâu trước khi huấn luyện trên các mega-batch mới đến? Không có một câu trả lời duy nhất cho câu hỏi này. Chúng tôi đã thấy rằng trên CIFAR 10 nhưng cũng trên MNIST khi sử dụng các kiến trúc nhỏ hơn và khi sử dụng replay với ngân sách tính toán nhỏ hơn, một thời gian chờ trung gian đạt được sự cân bằng tốt nhất. Tuy nhiên, không có công thức nào được biết để rút ra thời gian chờ, vì nó phụ thuộc vào một số yếu tố như horizon thời gian, hiệu suất ban đầu của mô hình và tốc độ học của mô hình, để kể tên một vài. Kết luận chắc chắn là việc cập nhật mô hình một cách tham lam ngay khi dữ liệu có sẵn, như được ủng hộ bởi văn học về học tập trực tuyến lồi, có thể không phải lúc nào cũng là chiến lược tốt nhất khi sử dụng mạng nơ-ron sâu. Trong thực tế, cũng đợi quá lâu, đến mức người học thậm chí không có thời gian để thực hiện một lần qua các mega-batch tổng hợp, có thể không tối ưu.

2) Người học nên áp dụng kiến trúc nào? Nghiên cứu của chúng tôi chỉ ra rằng, trong tất cả các phương pháp chúng tôi đã thử nghiệm, ensembling đạt được sự cân bằng tốt nhất nói chung. Ensembling đơn giản và dễ song song hóa, và nó cung cấp một cách đơn giản để tăng khả năng. Bắt đầu với một mô hình lớn hơn, ví dụ thông qua ensembling, là một cách tuyệt vời để đạt được hiệu suất anytime tốt.

3) Người học có nên tăng khả năng theo thời gian khi quan sát được nhiều dữ liệu hơn không? Câu trả lời là phủ định, hiện tại. Tốt hơn là bắt đầu với kiến trúc lớn nhất phù hợp với bộ nhớ và giữ nguyên như vậy. Một cách giải thích cẩn thận của kết luận này có thể làm người đọc tin rằng việc phát triển kích thước kiến trúc không nên là một chủ đề quan tâm. Tuy nhiên, khi dữ liệu được thêm vào theo thời gian thì tính toán và bộ nhớ cũng vậy. Thường là trường hợp các nhà nghiên cứu làm việc trên học tập quy mô lớn khởi tạo (đúng là như vậy) mô hình lớn nhất có thể để huấn luyện trên nhiệm vụ của họ, nhưng vài tháng sau họ có thể quản lý để khởi động các mô hình thậm chí lớn hơn nhờ các tiến bộ tính toán và kỹ thuật. Làm thế nào mô hình lớn hơn có thể tận dụng những gì đã được học từ mô hình được huấn luyện trước đó? Có lựa chọn mô hình hóa nào đạt được sự cân bằng tốt hơn so với huấn luyện lại từ đầu không? Tổng quát hơn, những phương pháp tốt nào để trích xuất thông tin từ một batch dữ liệu mới để tích hợp nó vào một mô hình hiện có? Chúng tôi tin rằng đây là những hướng nghiên cứu tương lai tuyệt vời, và rằng framework ALMA của chúng tôi (giao thức học tập và đánh giá, codebase, baseline) cung cấp một abstraction tốt của cài đặt thực tế, và một công cụ vững chắc để theo đuổi việc điều tra như vậy.

8 TUYÊN BỐ VỀ KHẢ NĂNG TÁI TẠO
Chúng tôi đã thực hiện một số nỗ lực để đảm bảo rằng các kết quả được cung cấp trong bài báo có thể tái tạo hoàn toàn. Đầu tiên chúng tôi cung cấp một codebase dễ sử dụng từ đó tất cả các kết quả thị giác máy tính trong bài báo này được tạo ra. Trong codebase này, người ta có thể tìm thấy các siêu tham số chính xác được sử dụng cho mỗi phương pháp trong các cấu hình được cung cấp. Chúng tôi đã đính kèm readme cho mã để hướng dẫn người dùng chạy mã của chúng tôi. Đối với các thí nghiệm LM, như đã nêu trong phụ lục, chúng tôi sử dụng fairseq (Ott et al., 2019) và cung cấp thông tin cần thiết để tái tạo kết quả của chúng tôi.

9 LỜI CẢM ƠN
Chúng tôi muốn cảm ơn Csaba Szepesvari vì đã thảo luận về cách ALMA liên quan đến học tập trực tuyến, Jörg Bornschein vì thảo luận chung và vì đã chỉ ra các kết quả thí nghiệm còn thiếu, và Thang Doan vì đã phản hồi về các bản thảo trước đó.

TÀI LIỆU THAM KHẢO
[Danh sách tài liệu tham khảo được dịch tiếp tục...]

# Duy trì tính dẻo dai trong học sâu liên tục

Shibhansh Doharea, J. Fernando Hernandez-Garciaa, Parash Rahmana, A. Rupam Mahmooda,b, Richard S. Suttona,b

aDepartment of Computing Science, University of Alberta,
bCIFAR AI Chair, Alberta Machine Intelligence Institute,

## Tóm tắt

Các hệ thống học sâu hiện đại được chuyên môn hóa cho các bài toán mà việc huấn luyện chỉ xảy ra một lần và sau đó không bao giờ nữa, trái ngược với các bài toán học liên tục mà việc huấn luyện diễn ra liên tục. Nếu các hệ thống học sâu được áp dụng trong bối cảnh học liên tục, thì việc chúng có thể không nhớ được các ví dụ trước đó là điều đã được biết đến. Cơ bản hơn nhưng ít được biết đến hơn là chúng cũng có thể mất khả năng học trên các ví dụ mới, một hiện tượng được gọi là mất tính dẻo dai. Chúng tôi cung cấp các minh chứng trực tiếp về việc mất tính dẻo dai bằng cách sử dụng các bộ dữ liệu MNIST và ImageNet được điều chỉnh cho học liên tục dưới dạng chuỗi các nhiệm vụ. Trong ImageNet, hiệu suất phân loại nhị phân giảm từ 89% độ chính xác ở nhiệm vụ sớm xuống 77%, khoảng mức độ của một mạng tuyến tính, ở nhiệm vụ thứ 2000. Việc mất tính dẻo dai xảy ra với nhiều kiến trúc mạng sâu, bộ tối ưu hóa, hàm kích hoạt, chuẩn hóa batch, dropout, nhưng được giảm thiểu đáng kể bởi L2-regularization, đặc biệt khi kết hợp với nhiễu trọng số. Hơn nữa, chúng tôi giới thiệu một thuật toán mới—lan truyền ngược liên tục—sửa đổi nhẹ lan truyền ngược thông thường để tái khởi tạo một phần nhỏ các đơn vị ít được sử dụng sau mỗi ví dụ và có vẻ duy trì tính dẻo dai vô hạn.

**Từ khóa:** học liên tục, học sâu, mất tính dẻo dai, ImageNet, MNIST, lan truyền ngược

## 1. Mất tính dẻo dai

Các hệ thống học sâu hiện đại đã trở nên chuyên môn hóa cho các bài toán mà việc huấn luyện chỉ xảy ra một lần trên một bộ dữ liệu lớn và sau đó không bao giờ nữa. Các bài toán huấn luyện một lần như vậy đã được sử dụng trong tất cả các thành công ban đầu của học sâu trong nhận dạng giọng nói [1] và phân loại hình ảnh [2]. Sau đó, khi học sâu được áp dụng cho học tăng cường (ví dụ, Mnih et al. [3]), các kỹ thuật như bộ đệm phát lại và phân lô đã được giới thiệu để biến nó thành gần như một bài toán huấn luyện một lần. Các ứng dụng gần đây của học sâu như GPT-3 [4] và DallE [5] cũng được huấn luyện trên dữ liệu dưới dạng một lô lớn duy nhất. Tất nhiên, trong nhiều ứng dụng, phân phối dữ liệu thay đổi theo thời gian và việc huấn luyện phải tiếp tục dưới một hình thức nào đó; chiến lược phổ biến nhất trong những trường hợp này là liên tục thu thập dữ liệu và sau đó, thỉnh thoảng, huấn luyện một mạng mới từ đầu, một lần nữa trong bài toán huấn luyện một lần. Bài toán huấn luyện một lần đã là một phần không thể thiếu trong thiết kế và thực hành của các phương pháp học sâu hiện đại.

Ngược lại, bài toán học liên tục tập trung vào việc học liên tục từ dữ liệu mới. Bài toán học liên tục có lợi thế cho các vấn đề mà hệ thống học phải đối mặt với luồng dữ liệu thay đổi. Ví dụ, xem xét một robot được giao nhiệm vụ điều hướng trong một ngôi nhà. Trong bài toán huấn luyện một lần, robot sẽ phải được huấn luyện lại từ đầu hoặc có nguy cơ trở nên lỗi thời bất cứ khi nào bố cục ngôi nhà thay đổi. Nếu bố cục thay đổi thường xuyên, thì việc huấn luyện lại liên tục từ đầu sẽ được yêu cầu. Trong bài toán học liên tục, mặt khác, robot có thể đơn giản học từ dữ liệu mới và tiếp tục thích ứng với những thay đổi trong ngôi nhà. Học liên tục đã thu hút sự chú ý ngày càng tăng trong những năm gần đây, và các cuộc họp chuyên môn mới đang được tổ chức để tập trung vào nó, chẳng hạn như Hội nghị về Tác nhân học suốt đời (CoLLAS). Trong bài báo này, chúng tôi tập trung vào bài toán học liên tục.

Các hệ thống học sâu, khi tiếp xúc với dữ liệu mới, có xu hướng quên hầu hết những gì chúng đã học trước đó, một hiện tượng được gọi là "quên thảm khốc". Nói cách khác, các phương pháp học sâu không duy trì tính ổn định trong các bài toán học liên tục. Hiện tượng này lần đầu tiên được chỉ ra trong các mạng nơ-ron sớm vào cuối những năm 1900 [6, 7]. Gần đây, với sự ra đời của học sâu, quên thảm khốc đã nhận được sự chú ý mới khi nhiều bài báo đã được dành riêng để duy trì tính ổn định trong học sâu liên tục [8, 9, 10, 11, 12, 13, 14, 15].

Khác với quên thảm khốc, và thậm chí còn cơ bản hơn đối với học liên tục, là khả năng tiếp tục học từ dữ liệu mới. Chúng tôi gọi khả năng này là tính dẻo dai. Duy trì tính dẻo dai là thiết yếu cho các hệ thống học liên tục vì nó cho phép chúng thích ứng với những thay đổi trong luồng dữ liệu của chúng. Các hệ thống học liên tục mất tính dẻo dai có thể trở nên vô dụng nếu luồng dữ liệu của chúng thay đổi. Trong bài báo này, chúng tôi tập trung vào vấn đề mất tính dẻo dai. Sự tập trung này khác nhưng bổ sung cho sự tập trung phổ biến hơn vào quên thảm khốc.

Các hệ thống học sâu có mất tính dẻo dai trong các bài toán học liên tục không? Một số bằng chứng cho thấy chúng có mất xuất phát từ tài liệu tâm lý học đầu những năm 2000. Ellis và Lambon Ralph [16], Zevin và Seidenberg [17], và Bonin et al. [18] đã chỉ ra việc mất tính dẻo dai trong các mạng nơ-ron sớm trong các bài toán hồi quy có giám sát. Những bài báo này sử dụng một thiết lập trong đó một tập các ví dụ được trình bày cho mạng trong một số epoch nhất định, và sau đó tập huấn luyện được mở rộng với các ví dụ bổ sung và việc huấn luyện tiếp tục trong một số epoch khác. Họ phát hiện ra rằng lỗi đối với các ví dụ trong tập huấn luyện gốc thấp hơn so với các ví dụ được thêm vào sau này sau khi kiểm soát số lượng epoch. Những bài báo này cung cấp bằng chứng rằng học sâu và thuật toán lan truyền ngược [19] mà nó được xây dựng dựa trên có xu hướng tạo ra việc mất tính dẻo dai. Một hạn chế của những công trình sớm này là các mạng được sử dụng tương đối nông theo tiêu chuẩn ngày nay, và các thuật toán được sử dụng không phải là những thuật toán phổ biến nhất ngày nay. Ví dụ, họ không sử dụng hàm kích hoạt ReLU hoặc bộ tối ưu hóa Adam. Nghiên cứu tâm lý học sớm về mạng nơ-ron nhân tạo cung cấp những gợi ý hấp dẫn, nhưng không cung cấp câu trả lời rõ ràng cho câu hỏi liệu các mạng học sâu hiện đại có thể hiện việc mất tính dẻo dai hay không.

Chuyển sang tài liệu học máy, chúng ta có thể tìm thấy một số nghiên cứu gần đây gợi ý việc mất tính dẻo dai trong học sâu. Chaudhry et al. [20] đã quan sát thấy việc mất tính dẻo dai trong các bài toán phân loại hình ảnh liên tục. Thí nghiệm của họ không hoàn toàn thỏa mãn như một minh chứng về việc mất tính dẻo dai vì họ đã giới thiệu các biến gây nhiễu khác. Trong thiết lập của họ, khi một nhiệm vụ mới được trình bày, các đầu ra mới, được gọi là đầu, đã được thêm vào mạng; số lượng đầu ra tăng lên khi gặp phải các nhiệm vụ bổ sung. Việc mất tính dẻo dai do đó bị gây nhiễu với các hiệu ứng của sự can thiệp từ các đầu cũ. Chaudhry et al. phát hiện rằng khi các đầu cũ được loại bỏ ở đầu một nhiệm vụ mới, việc mất tính dẻo dai là tối thiểu, điều này gợi ý rằng việc mất tính dẻo dai mà họ quan sát được chủ yếu do sự can thiệp từ các đầu cũ. Một hạn chế thứ hai của nghiên cứu của Chaudhry et al. là nó chỉ sử dụng mười nhiệm vụ và do đó không đánh giá việc mất tính dẻo dai khi các phương pháp học sâu đối mặt với một chuỗi dài các nhiệm vụ.

Ash và Adams [21] đã chỉ ra rằng việc khởi tạo một mạng nơ-ron bằng cách huấn luyện trước nó trên một phần của bộ dữ liệu có thể dẫn đến hiệu suất cuối cùng thấp hơn nhiều so với trường hợp mạng được huấn luyện một lần trên toàn bộ bộ dữ liệu. Hiệu suất kém hơn sau huấn luyện trước là một ví dụ quan trọng về việc mất tính dẻo dai trong học sâu và gợi ý về khả năng của một điểm yếu lớn trong học liên tục đầy đủ với nhiều thay đổi nhiệm vụ hoặc tính không ổn định. Berariu et al. [22] đã mở rộng công việc của Ash và Adams để chỉ ra rằng càng có nhiều giai đoạn huấn luyện trước, hiệu suất cuối cùng càng kém. Tuy nhiên, thí nghiệm của Berariu et al. được thực hiện trong bài toán ổn định, và việc mất tính dẻo dai mà họ quan sát được là nhỏ. Mặc dù kết quả trong những bài báo này gợi ý về một việc mất tính dẻo dai cơ bản trong các hệ thống học sâu, không ai trực tiếp chứng minh việc mất tính dẻo dai trong học liên tục.

Nhiều bằng chứng hơn về việc mất tính dẻo dai trong học sâu hiện đại đã được thu thập trong cộng đồng học tăng cường, nơi các bài báo gần đây đã chỉ ra việc mất tính dẻo dai đáng kể. Nishikin et al. [23] đã chỉ ra rằng việc học sớm trong các bài toán học tăng cường có thể gây hại cho việc học sau này, một hiệu ứng mà họ gọi là "thiên kiến ưu tiên". Kết quả này có thể do việc mất tính dẻo dai của các mạng học sâu trong bài toán học liên tục, vì học tăng cường vốn dĩ là liên tục do những thay đổi trong chính sách. Lyle et al. [24] cũng đã chỉ ra rằng một số tác nhân học tăng cường sâu có thể mất khả năng học các hàm mới theo thời gian. Đây là những điểm dữ liệu quan trọng, nhưng kết luận có thể rút ra từ chúng bị hạn chế bởi sự phức tạp vốn có của học tăng cường sâu hiện đại. Tất cả những bài báo này, cả từ tài liệu tâm lý học vào đầu thế kỷ và các bài báo gần đây trong học máy và học tăng cường, đều là bằng chứng cho thấy các hệ thống học sâu mất tính dẻo dai, nhưng thiếu một minh chứng hoàn toàn thỏa mãn về hiện tượng này.

Trong bài báo này, chúng tôi cố gắng đưa ra một câu trả lời chắc chắn hơn cho câu hỏi về việc mất tính dẻo dai trong học sâu hiện đại. Chúng tôi chỉ ra rằng các phương pháp học sâu mắc phải việc mất tính dẻo dai trong các bài toán học có giám sát liên tục và rằng việc mất tính dẻo dai như vậy có thể nghiêm trọng. Đầu tiên, chúng tôi chứng minh rằng học sâu mắc phải việc mất tính dẻo dai trong một bài toán học có giám sát liên tục dựa trên bộ dữ liệu ImageNet liên quan đến hàng nghìn nhiệm vụ học. Sử dụng các nhiệm vụ học có giám sát thay vì học tăng cường loại bỏ sự phức tạp và sự gây nhiễu liên quan mà không thể tránh khỏi phát sinh trong học tăng cường. Và có hàng nghìn nhiệm vụ cho phép chúng tôi đánh giá mức độ đầy đủ của việc mất tính dẻo dai. Sau đó, chúng tôi sử dụng hai bài toán ít tốn kém tính toán hơn (một biến thể của MNIST và bài toán Hồi quy Thay đổi Chậm) để thiết lập tính tổng quát của việc mất tính dẻo dai của học sâu trên một phạm vi rộng các siêu tham số, bộ tối ưu hóa, kích thước mạng và hàm kích hoạt.

Sau khi chỉ ra mức độ nghiêm trọng và tính tổng quát của việc mất tính dẻo dai trong học sâu, chúng tôi tìm kiếm hiểu biết sâu sắc hơn về nguyên nhân của nó. Điều này dẫn chúng tôi khám phá các phương pháp hiện có có thể làm giảm việc mất tính dẻo dai. Chúng tôi phát hiện rằng một số phương pháp, như Adam [25] và dropout [26], làm trầm trọng thêm đáng kể việc mất tính dẻo dai, trong khi các phương pháp khác, như L2-regularization [27, tr. 227–230] và Shrink and Perturb [21], giảm thiểu đáng kể việc mất tính dẻo dai trong nhiều trường hợp. Cuối cùng, chúng tôi đề xuất một thuật toán mới—lan truyền ngược liên tục—giải quyết mạnh mẽ vấn đề mất tính dẻo dai trong cả các thí nghiệm có hệ thống của chúng tôi với các bài toán học có giám sát và trong một thí nghiệm sơ bộ với một bài toán học tăng cường. Thuật toán lan truyền ngược thông thường có hai thành phần quan trọng: 1) khởi tạo các trọng số kết nối của mạng với các số ngẫu nhiên nhỏ và 2) giảm gradient ngẫu nhiên trên mỗi lần trình bày một ví dụ huấn luyện [19]. Lan truyền ngược liên tục mở rộng việc khởi tạo cho tất cả các bước thời gian, bằng cách tái khởi tạo có chọn lọc một phần nhỏ các đơn vị ẩn tiện ích thấp tại mỗi lần trình bày một ví dụ huấn luyện. Lan truyền ngược liên tục thực hiện cả giảm gradient và tái khởi tạo có chọn lọc liên tục.

## 2. Mất tính dẻo dai trong ImageNet

Kết quả chính của bài báo này được chứa trong phần này. Nhớ lại rằng điểm chính của bài báo này là thiết lập một cách chắc chắn hơn rằng các phương pháp học sâu mất khả năng học trong học liên tục. Để thiết lập điều này, chúng tôi sử dụng bài toán kiểm tra cổ điển được biết đến là ImageNet và điều chỉnh nó cho học liên tục. ImageNet đã có tầm quan trọng lịch sử đối với học sâu và vẫn là một bệ thử nghiệm được sử dụng rộng rãi. Một bài toán học sâu cổ điển như ImageNet là nơi tốt nhất để chỉ ra vấn đề mất tính dẻo dai. Trong phần này, chúng tôi chỉ ra rằng học sâu mắc phải việc mất tính dẻo dai trong một bài toán học liên tục dựa trên ImageNet.

Imagenet là một cơ sở dữ liệu lớn các hình ảnh và nhãn của chúng đã có ảnh hưởng trong suốt lĩnh vực học máy [28, Image-net.org] và đã đóng vai trò then chốt trong sự trỗi dậy của học sâu [2]. ImageNet cho phép các nhà nghiên cứu chứng minh một cách thuyết phục rằng học sâu có thể giải quyết một vấn đề như nhận dạng đối tượng, một dấu hiệu của trí thông minh. Các phương pháp học máy cổ điển có tỷ lệ lỗi phân loại là 25% [29] khi các phương pháp học sâu giảm nó xuống dưới 5% [30], tỷ lệ lỗi của con người trên bộ dữ liệu.

Cơ sở dữ liệu ImageNet bao gồm hàng triệu hình ảnh được gắn nhãn bởi các danh từ (lớp) như các loại động vật và đồ vật hàng ngày. Trong bài toán huấn luyện một lần tiêu chuẩn, bộ dữ liệu được phân chia thành một tập huấn luyện và một tập kiểm tra. Hệ thống học trước tiên được huấn luyện trên tập huấn luyện, và sau đó người học được đóng băng, và hiệu suất của nó được đo trên tập kiểm tra.

Chúng tôi tìm cách điều chỉnh Imagenet từ bài toán huấn luyện một lần sang bài toán học liên tục trong khi giảm thiểu tất cả các thay đổi khác. Cơ sở dữ liệu Imagenet mà chúng tôi sử dụng bao gồm 1000 lớp, mỗi lớp có 700 hình ảnh. Chúng tôi xây dựng từ những điều này một chuỗi gần như vô tận các nhiệm vụ phân loại nhị phân. Ví dụ, nhiệm vụ đầu tiên có thể là phân biệt Lớp1 với Lớp2, và nhiệm vụ thứ hai có thể là phân biệt Lớp3 với Lớp4. Mỗi nhiệm vụ phân loại nhị phân được xử lý theo cách thông thường. 700 hình ảnh cho mỗi lớp được chia thành 600 hình ảnh cho tập huấn luyện và 100 hình ảnh cho tập kiểm tra. Trên mỗi nhiệm vụ, mạng học sâu trước tiên được huấn luyện trên tập huấn luyện gồm 1200 hình ảnh, và sau đó độ chính xác phân loại của nó được đánh giá trên tập kiểm tra gồm 200 hình ảnh. Việc huấn luyện đó bao gồm nhiều lần đi qua tập huấn luyện, được gọi là epoch. Sau khi huấn luyện và kiểm tra một nhiệm vụ, nhiệm vụ tiếp theo được bắt đầu dựa trên một cặp lớp khác. Bằng cách chọn các cặp nhiệm vụ ngẫu nhiên không thay thế, chúng tôi tạo ra một chuỗi 2000 nhiệm vụ khác nhau. Tất cả các nhiệm vụ sử dụng phiên bản thu nhỏ 32x32 của bộ dữ liệu ImageNet, như thường được thực hiện để tiết kiệm tính toán [31].

**Kiến trúc mạng cho Continual ImageNet**

| Lớp 1: Tích chập + Max-Pooling |  |
|---|---|
| Số bộ lọc | 32 |
| Kích hoạt | ReLU |
| Hình dạng bộ lọc tích chập | (5,5) |
| Bước tích chập | (1,1) |
| Hình dạng bộ lọc Max-Pooling | (2,2) |
| Bước Max-Pooling | (1,1) |

| Lớp 2: Tích chập + Max-Pooling |  |
|---|---|
| Số bộ lọc | 64 |
| Kích hoạt | ReLU |
| Hình dạng bộ lọc tích chập | (3,3) |
| Bước tích chập | (1,1) |
| Hình dạng bộ lọc Max-Pooling | (2,2) |
| Bước Max-Pooling | (1,1) |

| Lớp 3: Tích chập + Max-Pooling |  |
|---|---|
| Số bộ lọc | 128 |
| Kích hoạt | ReLU |
| Hình dạng bộ lọc tích chập | (3,3) |
| Bước tích chập | (1,1) |
| Hình dạng bộ lọc Max-Pooling | (2,2) |
| Bước Max-Pooling | (1,1) |

| Lớp 4: Kết nối đầy đủ |  |
|---|---|
| Kích thước đầu ra | 128 |
| Kích hoạt | ReLU |

| Lớp 5: Kết nối đầy đủ |  |
|---|---|
| Kích thước đầu ra | 128 |
| Kích hoạt | ReLU |

| Lớp 6: Kết nối đầy đủ |  |
|---|---|
| Kích thước đầu ra | 2 |
| Kích hoạt | Tuyến tính |

Bảng 1: Chi tiết về mạng nơ-ron nhân tạo được sử dụng cho bài toán Continual ImageNet. Mạng có ba lớp tích chập theo sau bởi ba lớp kết nối đầy đủ.

Chúng tôi gọi bài toán học liên tục kết quả là Continual ImageNet. Trong phần này, chúng tôi sử dụng Continual ImageNet để thiết lập việc mất tính dẻo dai.

Để chỉ ra rằng học sâu mất khả năng học, chúng tôi áp dụng nhiều loại mạng học sâu tiêu chuẩn khác nhau cho Continual ImageNet. Chúng tôi mô tả ở đây một mạng tích chập cụ thể, đại diện với hàm kích hoạt ReLU. Mạng có ba lớp tích chập-cộng-max-pooling theo sau bởi ba lớp kết nối đầy đủ, như được chi tiết trong Bảng 1. Mạng này hẹp hơn so với những mạng thường được sử dụng trên bộ dữ liệu ImageNet vì ở đây chúng tôi đang cố gắng phân biệt chỉ hai lớp tại một thời điểm thay vì tất cả 1000 lớp. Lớp cuối cùng bao gồm chỉ hai đơn vị, các đầu, tương ứng với hai lớp. Tại các thay đổi nhiệm vụ, trọng số đầu vào của các đầu được đặt lại về không. Việc đặt lại các đầu theo cách này có thể được xem như việc giới thiệu các đầu mới cho các lớp mới. Việc đặt lại các trọng số đầu ra này không lý tưởng để nghiên cứu tính dẻo dai, vì hệ thống học có quyền truy cập vào thông tin đặc quyền về thời điểm thay đổi nhiệm vụ (và chúng tôi không sử dụng nó trong các thí nghiệm được báo cáo sau này trong bài báo này). Chúng tôi sử dụng nó ở đây vì nó gần nhất với thực hành tiêu chuẩn trong học sâu liên tục, đó là giới thiệu các đầu mới cho các lớp mới [8, 9, 10, 11].

Chúng tôi đã thử nghiệm nhiều biến thể của kiến trúc mạng, siêu tham số và bộ tối ưu hóa để có được hiệu suất tốt trên nhiệm vụ phân loại nhị phân đầu tiên. Bây giờ chúng tôi mô tả chi tiết về một quy trình huấn luyện như vậy được áp dụng cho mạng được mô tả trong Bảng 1. Mạng được huấn luyện bằng cách sử dụng giảm gradient ngẫu nhiên (SGD) với momentum trên mất mát entropy chéo và được khởi tạo một lần trước nhiệm vụ đầu tiên. Đối với mỗi nhiệm vụ, thuật toán học thực hiện 250 lần đi qua tập huấn luyện bằng cách sử dụng mini-batch có kích thước 100. Siêu tham số momentum là 0.9. Chúng tôi đã thử nghiệm nhiều tham số tốc độ bước khác nhau nhưng chỉ trình bày hiệu suất cho các tốc độ bước 0.01, 0.001 và 0.0001 để làm rõ hình. Chúng tôi thực hiện 30 lần chạy cho mỗi giá trị siêu tham số, thay đổi chuỗi các nhiệm vụ và tính ngẫu nhiên khác. Trên các siêu tham số khác nhau, cùng một chuỗi các cặp lớp được sử dụng.

Là một thước đo hiệu suất trên một nhiệm vụ, chúng tôi sử dụng tỷ lệ phần trăm của 200 hình ảnh kiểm tra được phân loại chính xác. Thước đo này được vẽ dưới dạng hàm của số nhiệm vụ cho mười nhiệm vụ đầu tiên (bảng bên trái của Hình 1) và theo các nhóm 50 nhiệm vụ cho tất cả 2000 nhiệm vụ (bảng bên phải của Hình 1) cho các tốc độ bước tốt nhất. Điểm dữ liệu đầu tiên trong bảng bên phải là hiệu suất trung bình trên 50 nhiệm vụ đầu tiên; điểm tiếp theo là hiệu suất trung bình trên 50 nhiệm vụ tiếp theo, và cứ thế.

Mạng có hiệu suất kém trên nhiệm vụ thứ 2000 cho tất cả các giá trị siêu tham số. Tốc độ bước lớn nhất, 0.01, có hiệu suất tốt nhất trên hai nhiệm vụ đầu tiên, nhưng hiệu suất sau đó giảm trên các nhiệm vụ tiếp theo, cuối cùng đạt mức dưới đường cơ sở tuyến tính. Đối với các tốc độ bước thậm chí lớn hơn như 0.1, mạng phân kỳ sau vài nhiệm vụ đầu tiên. Ở các tốc độ bước nhỏ hơn, hiệu suất tăng ban đầu và sau đó giảm và chỉ tốt hơn một chút so với đường cơ sở tuyến tính sau 2000 nhiệm vụ. Hiệu suất cho các tốc độ bước trung gian như 0.003 tuân theo xu hướng chung của các tốc độ bước được trình bày trong Hình 1. Chúng tôi đã thấy đây là một mô hình phổ biến trong các thí nghiệm của chúng tôi: đối với một mạng được điều chỉnh tốt, hiệu suất trước tiên cải thiện, sau đó giảm đáng kể, kết thúc gần hoặc dưới đường cơ sở tuyến tính. Chúng tôi đã quan sát mô hình này cho nhiều kiến trúc mạng, siêu tham số và bộ tối ưu hóa. Các lựa chọn cụ thể về kiến trúc mạng, siêu tham số và bộ tối ưu hóa ảnh hưởng đến thời điểm hiệu suất bắt đầu giảm, nhưng chúng tôi đã quan sát một sự sụt giảm hiệu suất nghiêm trọng cho một phạm vi rộng các lựa chọn. Để tăng độ tin cậy trong kết quả và đảm bảo rằng sự sụt giảm hiệu suất không phải do một số lỗi trong việc triển khai, một trong các tác giả đã tái tạo độc lập kết quả của thí nghiệm này.

Thí nghiệm này được thiết kế để tuân theo thực hành học sâu tiêu chuẩn theo mọi cách có thể, ngoại trừ việc yêu cầu mạng tiếp tục học. Thất bại trong việc học tốt hơn một mạng tuyến tính trong các nhiệm vụ sau này là bằng chứng đáng kể cho thấy thực hành tiêu chuẩn của học sâu đơn giản không hoạt động trong các bài toán liên tục. Chúng tôi đã chỉ ra một cách có hệ thống thông qua một thí nghiệm trực tiếp rằng học sâu liên tục mất khả năng học những điều mới, tức là học sâu mất tính dẻo dai, trong bài toán học liên tục. Tuy nhiên, tất nhiên có nhiều biến thể khác của học sâu có thể được thử. Để đạt được mức độ tin cậy và hiểu biết tiếp theo, chúng tôi chuyển sang phần tiếp theo một bài toán ít phức tạp về mặt tính toán hơn, nơi chúng tôi có thể nghiên cứu các sắc thái của hiện tượng một cách kỹ lưỡng hơn.

## 3. Mất tính dẻo dai mạnh mẽ trong Permuted MNIST

Bây giờ chúng tôi sử dụng một bài toán tính toán rẻ dựa trên bộ dữ liệu MNIST [32] để kiểm tra tính tổng quát của việc mất tính dẻo dai. MNIST là một trong những bộ dữ liệu học có giám sát phổ biến nhất được sử dụng trong học sâu. Nó bao gồm 60.000 hình ảnh grayscale 28x28 của các chữ số viết tay từ 0 đến 9 cùng với nhãn chính xác của chúng. Ví dụ, hình ảnh bên trái trong Hình 2a hiển thị một hình ảnh được gắn nhãn bằng chữ số 7. Số lượng lớp nhỏ hơn và hình ảnh đơn giản hơn cho phép các mạng học sâu nhỏ hơn nhiều có hiệu suất tốt trên bộ dữ liệu này so với những mạng cần thiết trên ImageNet. Các mạng nhỏ hơn lần lượt có nghĩa là cần ít tính toán hơn nhiều để thực hiện các thí nghiệm và do đó các thí nghiệm có thể được thực hiện với số lượng lớn hơn và trong nhiều điều kiện khác nhau, cho phép chúng tôi thực hiện các nghiên cứu sâu hơn và rộng hơn về tính dẻo dai. Như với ImageNet, MNIST thường được sử dụng trong bài toán huấn luyện một lần.

Chúng tôi đã tạo ra một bài toán học có giám sát liên tục bằng cách sử dụng các bộ dữ liệu permuted MNIST [33, 34]. Một bộ dữ liệu permuted MNIST riêng lẻ được tạo ra bằng cách hoán vị các pixel trong bộ dữ liệu MNIST gốc. Ví dụ, pixel ban đầu xuất hiện ở góc trên-trái có thể được di chuyển đến góc dưới-phải, hoặc đến bất kỳ nơi cụ thể nào khác trong hình ảnh, và cứ thế cho tất cả các pixel khác. Hình ảnh bên phải trong Hình 2a là một ví dụ về hình ảnh được hoán vị như vậy cho một hình ảnh được gắn nhãn bằng chữ số 7. Cho một cách hoán vị, tất cả 60.000 hình ảnh được hoán vị theo cùng một cách để tạo ra bộ dữ liệu permuted MNIST mới. Bằng cách lặp lại việc chọn ngẫu nhiên từ khoảng 10^1930 hoán vị có thể, chúng tôi đã tạo ra một chuỗi 800 bộ dữ liệu permuted MNIST và các nhiệm vụ học có giám sát. Đối với mỗi nhiệm vụ, chúng tôi trình bày từng hình ảnh trong số 60.000 hình ảnh của nó một cách ngẫu nhiên cho mạng học. Sau đó chúng tôi chuyển sang nhiệm vụ permuted MNIST tiếp theo và lặp lại toàn bộ quy trình, và cứ thế cho đến 800 nhiệm vụ. Không có chỉ dẫn nào được đưa ra cho mạng tại thời điểm chuyển đổi nhiệm vụ. Với các pixel được hoán vị theo cách hoàn toàn không liên quan, chúng ta có thể mong đợi hiệu suất phân loại giảm mạnh tại thời điểm chuyển đổi nhiệm vụ. Tuy nhiên, qua các nhiệm vụ, có thể có một số tiết kiệm, một số cải thiện tốc độ học, hoặc ngược lại có thể có việc mất tính dẻo dai—mất khả năng học qua các nhiệm vụ. Mạng được huấn luyện trên một lần đi qua dữ liệu và không có mini-batch. Chúng tôi gọi bài toán này là Online Permuted MNIST.

Chúng tôi áp dụng các mạng nơ-ron feed-forward với ba lớp ẩn cho Online Permuted MNIST. Chúng tôi không sử dụng các lớp tích chập, vì chúng không thể hữu ích trên bài toán hoán vị vì thông tin không gian bị mất (trong MNIST, các lớp tích chập thường không được sử dụng ngay cả trên bài toán tiêu chuẩn, không hoán vị). Đối với mỗi ví dụ, mạng ước tính xác suất của mỗi lớp trong 10 lớp (0–9), so sánh chúng với nhãn chính xác, và thực hiện SGD trên mất mát entropy chéo. Là một thước đo hiệu suất, chúng tôi ghi lại tỷ lệ phần trăm số lần nhãn xác suất cao nhất của mạng là nhãn chính xác trên 60.000 hình ảnh của một nhiệm vụ. Chúng tôi vẽ thước đo hiệu suất theo nhiệm vụ này so với số nhiệm vụ trong Hình 2b. Các trọng số được khởi tạo theo phân phối Kaiming.

Bảng đầu tiên của Hình 2b hiển thị tiến trình hiệu suất qua các nhiệm vụ cho một mạng với 2000 đơn vị trên mỗi lớp, và các giá trị khác nhau của tham số tốc độ bước. Lưu ý rằng hiệu suất trước tiên tăng qua các nhiệm vụ, sau đó bắt đầu giảm đều đặn qua tất cả các nhiệm vụ tiếp theo. Sự sụt giảm hiệu suất này có nghĩa là mạng đang từ từ mất khả năng học trên các nhiệm vụ mới. Việc mất tính dẻo dai này phù hợp với việc mất tính dẻo dai mà chúng tôi quan sát thấy trong ImageNet.

Tiếp theo chúng tôi thay đổi kích thước mạng. Thay vì 2000 đơn vị trên mỗi lớp, chúng tôi thử 100, 1000 và 10.000 đơn vị trên mỗi lớp. Trong thí nghiệm này, chúng tôi chỉ chạy trong 150 nhiệm vụ, chủ yếu vì mạng lớn nhất mất thời gian chạy lâu hơn nhiều. Các quá trình thời gian của hiệu suất ở các tốc độ bước tốt cho mỗi kích thước mạng được hiển thị trong bảng giữa của Hình 2b. Việc mất tính dẻo dai với việc huấn luyện tiếp tục rõ ràng nhất ở các kích thước mạng nhỏ hơn, nhưng ngay cả các mạng lớn nhất cũng cho thấy một số mất tính dẻo dai.

Tiếp theo chúng tôi nghiên cứu hiệu ứng của tốc độ mà nhiệm vụ thay đổi. Quay lại mạng ban đầu với các lớp 2000 đơn vị, thay vì thay đổi hoán vị mỗi 60.000 ví dụ, bây giờ chúng tôi thay đổi nó sau mỗi 10.000, 100.000 hoặc 1M ví dụ, và chạy tổng cộng 48M ví dụ bất kể tần suất thay đổi nhiệm vụ. Các ví dụ trong những trường hợp này được chọn ngẫu nhiên từ bộ dữ liệu của nhiệm vụ permuted MNIST, với thay thế. Là một thước đo hiệu suất của mạng trên một nhiệm vụ, chúng tôi sử dụng tỷ lệ phần trăm chính xác trên tất cả hình ảnh của nhiệm vụ. Đó là, chỉ có 48 điểm dữ liệu ở tốc độ chậm nhất, và 4800 điểm dữ liệu ở tốc độ nhanh nhất. Tiến trình hiệu suất được hiển thị trong biểu đồ bên phải trong Hình 2b. Một lần nữa hiệu suất giảm qua các nhiệm vụ, ngay cả khi thay đổi rất hiếm. Tổng thể những kết quả này cho thấy rằng hiện tượng mất tính dẻo dai xảy ra một cách mạnh mẽ trong hình thức lan truyền ngược này.

Cuối cùng, chúng tôi kiểm tra xem các hàm kích hoạt khác nhau có loại bỏ việc mất tính dẻo dai không. Chúng tôi đã thử nghiệm các hàm kích hoạt này trong một bài toán Hồi quy Thay đổi Chậm lý tưởng hóa mới. Đó là một bài toán rẻ hơn nữa mà chúng tôi có thể chạy một thí nghiệm duy nhất trên CPU trong 15 phút, cho phép chúng tôi thực hiện các nghiên cứu rộng rãi. Chi tiết của bài toán này được đưa ra trong Phụ lục B. Trong bài toán này, chúng tôi chỉ ra việc mất tính dẻo dai cho các mạng với sáu hàm kích hoạt khác nhau: sigmoid, tanh, ELU, leaky-ReLU, ReLU và Swish.

Cho đến nay trong bài báo, chúng tôi đã thực hiện các kiểm tra trực tiếp về việc mất tính dẻo dai với lan truyền ngược. Các thí nghiệm của chúng tôi trong Continual Imagenet, online Permuted MNIST và hồi quy thay đổi chậm cho thấy rằng việc mất tính dẻo dai là một hiện tượng tổng quát, và nó có thể thảm khốc trong một số trường hợp. Nó xảy ra cho một phạm vi rộng các hàm kích hoạt, siêu tham số, tốc độ thay đổi phân phối và cho cả các mạng dưới và quá tham số hóa. Mặc dù học liên tục đã được nghiên cứu trong một thời gian dài từ [35, 36, 37], một kiểm tra trực tiếp về khả năng duy trì tính dẻo dai đã bị thiếu. Các thí nghiệm cho đến nay trong bài báo lấp đầy khoảng trống này và cho thấy rằng lan truyền ngược thông thường không hoạt động trong học liên tục.

Có hai mục tiêu chính trong học liên tục: duy trì tính ổn định và duy trì tính dẻo dai. Duy trì tính ổn định liên quan đến việc ghi nhớ thông tin hữu ích, và duy trì tính dẻo dai là về việc tìm kiếm thông tin hữu ích mới khi phân phối dữ liệu thay đổi. Rất khó cho các phương pháp học sâu hiện tại để nhớ thông tin hữu ích vì chúng có xu hướng quên thông tin đã học trước đó [6, 7, 37]. Chúng tôi tập trung vào việc liên tục tìm kiếm thông tin hữu ích, không phải vào việc nhớ thông tin hữu ích. Công việc của chúng tôi về việc mất tính dẻo dai khác nhưng bổ sung cho công việc về duy trì tính ổn định.

## 4. Hiểu về mất tính dẻo dai

Trong phần này, chúng tôi chuyển sự chú ý của mình đến việc hiểu tại sao lan truyền ngược mất tính dẻo dai trong các bài toán học liên tục. Sự khác biệt duy nhất trong thuật toán học qua thời gian là các trọng số mạng. Ban đầu, các trọng số là những số ngẫu nhiên nhỏ khi chúng được lấy mẫu từ phân phối ban đầu; tuy nhiên, sau khi học một số nhiệm vụ, các trọng số trở nên được tối ưu hóa cho nhiệm vụ gần đây nhất. Do đó, các trọng số khởi đầu cho nhiệm vụ tiếp theo về mặt chất lượng khác với những trọng số cho nhiệm vụ đầu tiên. Vì sự khác biệt này trong các trọng số là sự khác biệt duy nhất trong thuật toán học qua thời gian, phân phối trọng số ban đầu phải có một số tính chất độc đáo khiến lan truyền ngược trở nên dẻo dai từ đầu. Phân phối ngẫu nhiên ban đầu có thể có nhiều tính chất cho phép tính dẻo dai, như sự đa dạng của các đơn vị, các đơn vị không bão hòa, độ lớn trọng số nhỏ, v.v.

Như chúng tôi chứng minh bây giờ, nhiều lợi thế của phân phối ban đầu bị mất đồng thời với việc mất tính dẻo dai. Việc mất mỗi lợi thế này một phần giải thích sự suy giảm hiệu suất mà chúng tôi đã quan sát thấy. Sau đó chúng tôi cung cấp các lập luận về cách việc mất những lợi thế này có thể góp phần vào việc mất tính dẻo dai và các biện pháp định lượng mức độ phổ biến của hiện tượng. Chúng tôi cung cấp một nghiên cứu sâu về bài toán Online Permuted MNIST sẽ phục vụ như động lực cho một số phương pháp giải pháp có thể giảm thiểu việc mất tính dẻo dai.

Hiện tượng đầu tiên đáng chú ý xảy ra đồng thời với việc mất tính dẻo dai là sự gia tăng liên tục trong phần trăm các đơn vị không đổi. Khi một đơn vị trở nên không đổi, các gradient chảy ngược từ đơn vị trở thành không hoặc rất gần không, làm chậm đáng kể việc học. Trong trường hợp kích hoạt ReLU, điều này xảy ra khi đầu ra của các kích hoạt là không cho tất cả các ví dụ của nhiệm vụ; những đơn vị như vậy thường được gọi là chết [38, 39]. Trong trường hợp các hàm kích hoạt sigmoid hoặc tanh, hiện tượng này xảy ra khi đầu ra của một đơn vị quá gần một trong các giá trị cực trị của hàm kích hoạt; những đơn vị như vậy thường được gọi là bão hòa (xem [40] và [41, Chương 19]).

Để đo số lượng đơn vị chết trong một mạng với kích hoạt ReLU, chúng tôi đếm số lượng đơn vị có giá trị không cho tất cả các ví dụ trong một mẫu ngẫu nhiên gồm hai nghìn hình ảnh ở đầu mỗi nhiệm vụ mới. Một biện pháp tương tự trong trường hợp kích hoạt sigmoid hoặc tanh là số lượng đơn vị cách ε từ một trong các giá trị cực trị của hàm với một ε dương nhỏ [42]. Chúng tôi chỉ tập trung vào các mạng ReLU trong phần này.

Trong các thí nghiệm của chúng tôi trong bài toán online permuted MNIST, sự suy giảm hiệu suất online đi kèm với sự gia tăng lớn số lượng đơn vị chết (bảng bên trái của Hình 3). Đối với tốc độ bước 0.01, lên đến 25% đơn vị chết sau 800 nhiệm vụ. Sự gia tăng số lượng đơn vị chết này một phần giải thích tại sao hiệu suất của lan truyền ngược suy giảm theo thời gian. Trong phần tiếp theo, chúng tôi sẽ thấy rằng các phương pháp ngăn các đơn vị chết có thể giảm đáng kể việc mất tính dẻo dai. Điều này gợi ý rằng sự gia tăng đơn vị chết là một trong những nguyên nhân của việc mất tính dẻo dai trong lan truyền ngược.

Một hiện tượng khác xảy ra với việc mất tính dẻo dai là sự tăng trưởng đều đặn của độ lớn trọng số trung bình của mạng. Chúng tôi đo độ lớn trọng số trung bình bằng cách cộng giá trị tuyệt đối của chúng và chia cho tổng số trọng số trong mạng. Trong thí nghiệm permuted MNIST, sự suy giảm độ chính xác phân loại online của lan truyền ngược quan sát thấy trong Hình 2b được kết hợp với sự gia tăng độ lớn trọng số trung bình (bảng giữa của Hình 3).

Sự tăng trưởng của trọng số mạng có thể đại diện cho một vấn đề vì độ lớn trọng số lớn thường được kết hợp với sự bất ổn định học. Ví dụ, sự gia tăng độ lớn của các trọng số được kết hợp với vấn đề nổi tiếng về gradient nổ trong các mạng nơ-ron hồi quy [43]. Các trọng số của mạng là một yếu tố nhân của gradient, sự gia tăng đều đặn trong độ lớn của các trọng số có thể dẫn đến sự phân kỳ của các thuật toán xấp xỉ ngẫu nhiên được sử dụng để huấn luyện mạng [44, 45]. Hơn nữa, sự hội tụ của các thuật toán giảm, chẳng hạn như giảm gradient ngẫu nhiên, yêu cầu gradient phải có giới hạn [46].

Hiện tượng cuối cùng xảy ra với việc mất tính dẻo dai là sự sụt giảm hạng hiệu dụng của biểu diễn. Tương tự như hạng của ma trận, đại diện cho số chiều độc lập tuyến tính, hạng hiệu dụng xem xét cách mỗi chiều ảnh hưởng đến phép biến đổi được tạo ra bởi ma trận [47]. Hạng hiệu dụng cao báo hiệu rằng hầu hết các chiều của ma trận đóng góp đều nhau vào phép biến đổi được tạo ra bởi ma trận. Mặt khác, hạng hiệu dụng thấp tương ứng với ít chiều có bất kỳ hiệu ứng đáng kể nào đến phép biến đổi, ngụ ý rằng thông tin trong hầu hết các chiều gần như dư thừa.

Chính thức, xem xét ma trận Φ ∈ R^(n×m) với các giá trị đơn lẻ σ_k cho k = 1, 2, ..., q, và q = max(n, m). Gọi p_k = σ_k/||σ||_1, trong đó σ là vector chứa tất cả các giá trị đơn lẻ, và || · ||_1 là chuẩn ℓ1. Hạng hiệu dụng của ma trận Φ, hoặc erank(Φ), được định nghĩa là

erank(Φ) = exp{H(p_1, p_2, ..., p_q)}, trong đó H(p_1, p_2, ..., p_q) = -∑(k=1 to q) p_k log(p_k). (1)

Lưu ý rằng hạng hiệu dụng là một biện pháp liên tục nằm trong khoảng từ một đến hạng của ma trận Φ.

Trong trường hợp mạng nơ-ron, hạng hiệu dụng của một lớp ẩn đo số lượng đơn vị có thể tạo ra đầu ra của lớp. Nếu một lớp ẩn có hạng hiệu dụng thấp, thì một số lượng nhỏ đơn vị có thể tạo ra đầu ra của lớp có nghĩa là nhiều đơn vị trong lớp ẩn không cung cấp thông tin hữu ích nào. Chúng tôi xấp xỉ hạng hiệu dụng trên một mẫu ngẫu nhiên gồm hai nghìn ví dụ trước khi huấn luyện trên mỗi nhiệm vụ.

Trong các thí nghiệm của chúng tôi, việc mất tính dẻo dai đi kèm với sự giảm hạng hiệu dụng trung bình của mạng (bảng bên phải của Hình 3). Hiện tượng này tự nó không nhất thiết là một vấn đề. Sau tất cả, đã được chỉ ra rằng tối ưu hóa dựa trên gradient dường như ưu tiên các giải pháp hạng thấp thông qua chính quy hóa ngầm của hàm mất mát hoặc giảm thiểu ngầm chính hạng [48, 49]. Tuy nhiên, một giải pháp hạng thấp có thể không phải là điểm khởi đầu tốt nhất để học từ các quan sát mới vì hầu hết các đơn vị ẩn cung cấp ít hoặc không có thông tin.

Sự giảm hạng hiệu dụng có thể giải thích việc mất tính dẻo dai trong các thí nghiệm của chúng tôi theo cách sau. Sau mỗi nhiệm vụ, thuật toán học tìm một giải pháp hạng thấp cho nhiệm vụ hiện tại, sau đó phục vụ như khởi tạo cho nhiệm vụ tiếp theo. Khi quá trình tiếp tục, hạng hiệu dụng của lớp biểu diễn tiếp tục giảm sau mỗi nhiệm vụ, hạn chế số lượng giải pháp mà mạng có thể biểu diễn ngay lập tức ở đầu mỗi nhiệm vụ mới.

Trong phần này, chúng tôi đã xem xét sâu hơn các mạng mất tính dẻo dai trong bài toán Online Permuted MNIST. Chúng tôi lưu ý rằng sự khác biệt duy nhất trong thuật toán học qua thời gian là trọng số của mạng, có nghĩa là phân phối trọng số ban đầu có một số tính chất cho phép thuật toán học trở nên dẻo dai từ đầu. Và khi việc học tiến triển, trọng số của mạng tách ra khỏi phân phối ban đầu, và thuật toán bắt đầu mất tính dẻo dai. Chúng tôi phát hiện rằng việc mất tính dẻo dai có tương quan với độ lớn trọng số tăng, sự giảm hạng hiệu dụng của biểu diễn, và sự gia tăng phần trăm đơn vị chết. Mỗi tương quan này một phần giải thích việc mất tính dẻo dai mà lan truyền ngược gặp phải.

## 5. Các phương pháp học sâu hiện có để giảm thiểu mất tính dẻo dai

Bây giờ chúng tôi nghiên cứu một số phương pháp hiện có có thể giúp giảm thiểu việc mất tính dẻo dai. Chúng tôi nghiên cứu năm phương pháp hiện có: L2-regularization [27, tr. 227–230], dropout [26], chuẩn hóa online [50], shrink-and-perturb [21], và Adam [25]. Chúng tôi chọn L2-regularization, dropout, chuẩn hóa và Adam vì những phương pháp này thường được sử dụng trong thực hành học sâu. Trong khi shrink-and-perturb không phải là một phương pháp thường được sử dụng, chúng tôi chọn nó vì nó giảm thất bại của huấn luyện trước, một vấn đề là một trường hợp của việc mất tính dẻo dai. Đối với mỗi phương pháp, chúng tôi đưa ra mô tả ngắn gọn về cách phương pháp hoạt động và đưa ra lý do tại sao người ta mong đợi phương pháp hoạt động tốt nói chung. Sau đó, để đánh giá xem những phương pháp này có thể giảm thiểu việc mất tính dẻo dai không, chúng tôi áp dụng chúng trên Online Permuted MNIST. Chúng tôi cũng sử dụng ba tương quan của việc mất tính dẻo dai được tìm thấy trong phần trước để có được hiểu biết sâu sắc hơn về hiệu suất của những phương pháp này. Ở cuối phần này, chúng tôi trình bày kết quả trên Online Permuted MNIST và thảo luận về lợi ích và nhược điểm của mỗi phương pháp.

Một cách trực quan để giải quyết việc mất tính dẻo dai là sử dụng chính quy hóa tham số vì việc mất tính dẻo dai được kết hợp với sự tăng trưởng của độ lớn trọng số, được hiển thị trong Phần 4. Chúng tôi đã sử dụng L2-regularization, thêm một hình phạt vào hàm mất mát tỷ lệ với chuẩn ℓ2 của các trọng số của mạng. Các mạng được huấn luyện bằng L2-regularization được mong đợi có độ lớn trọng số nhỏ hơn các mạng được huấn luyện chỉ với lan truyền ngược vì L2-regularization trực tiếp giảm độ lớn trọng số. Ngoài ra, có thể việc ngăn chặn sự tăng trưởng của độ lớn trọng số sẽ giảm việc mất tính dẻo dai vì độ lớn trọng số tăng trưởng được kết hợp với việc mất tính dẻo dai.

Một phương pháp liên quan đến chính quy hóa tham số là shrink-and-perturb [21]. Như tên gợi ý, shrink-and-perturb thực hiện hai hoạt động, đầu tiên nó thu nhỏ tất cả các trọng số và thứ hai nó thêm nhiễu ngẫu nhiên vào những trọng số này. Do phần thu nhỏ của shrink-and-perturb, nó được mong đợi dẫn đến độ lớn trọng số trung bình nhỏ hơn so với lan truyền ngược. Hơn nữa, người ta có thể mong đợi rằng nhiễu tham số được giới thiệu bởi shrink-and-perturb sẽ giúp giảm số lượng đơn vị chết và tăng hạng hiệu dụng của mạng. Như chúng tôi quan sát trong phần trước, việc mất tính dẻo dai được kết hợp với một số lượng lớn đơn vị chết, hạng hiệu dụng thấp và trọng số lớn. Nếu shrink-and-perturb giảm thiểu cả ba tương quan với việc mất tính dẻo dai, shrink-and-perturb có thể giảm việc mất tính dẻo dai.

Một kỹ thuật quan trọng trong học sâu hiện đại được gọi là dropout [26]. Dropout ngẫu nhiên đặt mỗi đơn vị ẩn về không với một xác suất nhỏ. Động lực ban đầu cho dropout là ngăn các đơn vị ẩn từ việc đồng thích ứng—dựa vào nhau để tạo ra dự đoán chính xác [26]. Hơn nữa, dropout cũng có thể được xem như một phương pháp giới thiệu tính ngẫu nhiên trong quá trình huấn luyện, ngăn các đơn vị khỏi việc chuyên môn hóa quá mức và làm cho mạng tổng thể mạnh mẽ với nhiễu [27, tr. 255–265]. Vì các đơn vị trong các mạng được huấn luyện với dropout được huấn luyện để không dựa vào thông tin được truyền đạt bởi các đơn vị khác, người ta có thể mong đợi rằng dropout sẽ tăng hạng hiệu dụng của các lớp ẩn. Ngoài ra, sự gia tăng hạng hiệu dụng của các mạng được huấn luyện bằng dropout cũng có thể đi kèm với sự giảm việc mất tính dẻo dai.

Một kỹ thuật khác thường được sử dụng trong học sâu là batch normalization [51]. Trong batch normalization, đầu ra của mỗi lớp ẩn được chuẩn hóa và tái tỷ lệ bằng cách sử dụng thống kê được tính từ mỗi mini-batch dữ liệu. Batch normalization ban đầu được đề xuất để giải quyết vấn đề dịch chuyển covariate nội bộ trong mạng nơ-ron [51]. Sau khi được giới thiệu, nó cũng được phát hiện là batch normalization cải thiện điều kiện tối ưu hóa khi huấn luyện mạng nơ-ron bằng cách làm mịn cảnh quan tối ưu hóa của hàm mất mát [52] và bằng cách cải thiện số điều kiện, tỷ lệ của các giá trị đơn lẻ lớn nhất và nhỏ nhất, của các ma trận trọng số của mạng [50]. Chuẩn hóa được mong đợi giảm thiểu vấn đề của các đơn vị chết vì nó được thiết kế để đảm bảo rằng các đơn vị có kích hoạt trước trung bình bằng không và phương sai bằng một. Hơn nữa, vì nó cũng cải thiện số điều kiện của các ma trận trọng số của mạng [50], người ta có thể mong đợi rằng các mạng được huấn luyện với chuẩn hóa sẽ có hạng hiệu dụng cao hơn các mạng được huấn luyện chỉ với lan truyền ngược. Như hệ quả của tất cả những hiệu ứng này, các mạng được huấn luyện với chuẩn hóa có thể cho thấy việc mất tính dẻo dai giảm so với lan truyền ngược.

Không đánh giá nào về các phương pháp thay thế có thể hoàn chỉnh mà không có Adam [25] vì nó được coi là một trong những công cụ hữu ích nhất trong học sâu hiện đại. Bộ tối ưu hóa Adam là một biến thể của giảm gradient ngẫu nhiên sử dụng ước tính của moment đầu tiên của gradient được tỷ lệ nghịch đảo bởi moment thứ hai của gradient để cập nhật trọng số thay vì trực tiếp sử dụng gradient. Adam đã được quan sát hoạt động tốt với các mất mát không ổn định [25], đặc biệt trong các bài toán học tăng cường sâu [53, 54, 55]. Có thể tính mạnh mẽ của Adam đối với các mất mát không ổn định có thể giúp giảm thiểu việc mất tính dẻo dai quan sát thấy trong các bài toán học liên tục không ổn định, chẳng hạn như bài toán Permuted MNIST.

Việc triển khai đúng những phương pháp này cho bài toán Online Permuted MNIST yêu cầu chúng tôi hiểu một số chi tiết của những phương pháp này cũng như các siêu tham số mà chúng đi kèm. L2-regularization thêm một hình phạt vào hàm mất mát tỷ lệ với chuẩn ℓ2 của các trọng số của mạng. Điều này giới thiệu một siêu tham số λ điều chỉnh đóng góp của thuật ngữ hình phạt. Phiên bản tăng dần của shrink-and-perturb cũng giới thiệu cùng thuật ngữ chính quy hóa như L2-regularization, và nó cũng thêm một lượng nhỏ nhiễu ngẫu nhiên vào các trọng số trên mỗi cập nhật. Việc giới thiệu nhiễu giới thiệu một siêu tham số khác, phương sai của nhiễu. Trong dropout, xác suất mà các đơn vị ẩn được đặt về không là một siêu tham số, và chúng tôi gọi xác suất này là p. Batch normalization không phù hợp với bài toán online được sử dụng trong bài toán Online Permuted MNIST. Do đó, chúng tôi đã sử dụng chuẩn hóa online [56], một biến thể online của batch normalization. Chuẩn hóa online giới thiệu hai siêu tham số được sử dụng cho việc ước tính tăng dần của thống kê trong các bước chuẩn hóa. Adam có hai siêu tham số được sử dụng cho việc ước tính tăng dần của thống kê trong các bước chuẩn hóa. Những siêu tham số này được sử dụng để tính toán trung bình di động của moment đầu tiên và thứ hai của gradient. Chúng tôi đã sử dụng các giá trị mặc định của những siêu tham số này được đề xuất trong bài báo gốc.

Chúng tôi đã thử nghiệm những phương pháp này trong bài toán Online Permuted MNIST bằng cách sử dụng cùng kiến trúc mạng mà chúng tôi đã sử dụng trong Phần 4: một mạng kết nối đầy đủ gồm ba lớp ẩn với 2000 đơn vị mỗi lớp và mười đơn vị đầu ra. Tương tự như Phần 4, chúng tôi đo độ chính xác phân loại online trên tất cả 60k ví dụ của nhiệm vụ. Tất cả những phương pháp này đi kèm với một tập các siêu tham số, và hiệu suất chính xác của các phương pháp phụ thuộc vào giá trị của những siêu tham số này. Tuy nhiên, chúng tôi vẫn có thể tìm các giá trị siêu tham số đại diện cho cách phương pháp có thể hoạt động tốt. Đối với mỗi phương pháp, chúng tôi đã thử nghiệm các kết hợp khác nhau của siêu tham số. Trong phần này, chúng tôi chỉ trình bày kết quả cho một tập những siêu tham số này. Phụ lục A hiển thị kết quả cho ba kết hợp khác nhau của siêu tham số và cung cấp thêm chi tiết về việc lựa chọn siêu tham số. Nói chung, chúng tôi chọn giá trị siêu tham số có độ chính xác phân loại trung bình cao nhất trên 800 nhiệm vụ. Một bức tranh nổi lên khi chúng tôi vẽ đường cong cho những giá trị siêu tham số này, được hiển thị trong Hình 4a. Tương tự như các biểu đồ trong Phần 4, điểm đầu tiên trong biểu đồ là độ chính xác phân loại trung bình trên nhiệm vụ đầu tiên, điểm tiếp theo trên nhiệm vụ tiếp theo và cứ thế. Các đường tương ứng với mỗi phương pháp không phải là hiệu suất tốt nhất của phương pháp, nhưng chúng đại diện cho hiệu suất tốt nhất của các phương pháp. Có thể có được hiệu suất tốt hơn một chút cho những phương pháp này bằng việc tinh chỉnh sâu hơn những siêu tham số này, tuy nhiên, mô hình kết quả và hành vi của những phương pháp này được tóm tắt tốt bởi Hình 4a.

Thay đổi thiết lập siêu tham số đã thay đổi hiệu suất của mỗi phương pháp. Đối với Adam, các giá trị khác nhau của tham số tốc độ bước đã thay đổi tốc độ hiệu suất giảm cho Adam. Với dropout, chúng tôi phát hiện rằng xác suất dropout càng cao, việc giảm hiệu suất càng nhanh và sắc nét. Dropout với xác suất 0.01 hoạt động tốt nhất, và hiệu suất của nó gần như giống hệt với lan truyền ngược. Tuy nhiên, Hình 4a hiển thị hiệu suất cho xác suất dropout 0.1 để đại diện cho cách phương pháp hoạt động. Đối với chuẩn hóa online, thay đổi siêu tham số đã thay đổi khi hiệu suất của phương pháp đạt đỉnh và nó cũng thay đổi nhẹ tốc độ nó đạt được hiệu suất đỉnh. Tham số weight-decay trong L2-regularization kiểm soát đỉnh của hiệu suất và tốc độ nó giảm. Shrink-and-perturb cũng nhạy cảm với phương sai của nhiễu. Nếu nhiễu quá cao, việc mất tính dẻo dai nghiêm trọng hơn nhiều, và nếu quá thấp, nó không có hiệu ứng nào.

Chúng tôi cũng đã thử nghiệm cách những phương pháp này ảnh hưởng đến ba tương quan của việc mất tính dẻo dai mà chúng tôi xác định trong Phần 4. Hình 4b hiển thị tóm tắt của ba tương quan cho việc mất tính dẻo dai cho các thiết lập siêu tham số được sử dụng trong Hình 4a.

Đối với L2-regularization, độ lớn trọng số không liên tục tăng. Hơn nữa, như mong đợi, độ lớn trọng số không tăng được kết hợp với việc mất tính dẻo dai thấp hơn. Tuy nhiên, L2-regularization không hoàn toàn giảm thiểu việc mất tính dẻo dai. Chúng tôi giải thích kết quả này bằng cách sử dụng hai tương quan khác cho việc mất tính dẻo dai. Trong khi L2-regularization giảm độ lớn trọng số trung bình của mạng, nó tăng tỷ lệ phần trăm đơn vị chết và giảm hạng hiệu dụng.

Tương tự như L2-regularization, shrink-and-perturb ngăn chặn độ lớn trọng số từ việc liên tục tăng. Hơn nữa, nó cũng giảm tỷ lệ phần trăm đơn vị chết. Tuy nhiên, nó có hạng hiệu dụng thấp hơn lan truyền ngược, nhưng vẫn cao hơn L2-regularization. Không chỉ shrink-and-perturb có việc mất tính dẻo dai thấp hơn lan truyền ngược, mà nó cũng có việc mất tính dẻo dai tối thiểu, và nó có độ chính xác phân loại cao nhất trên nhiệm vụ thứ 800 trong số tất cả các phương pháp mà chúng tôi đã thử nghiệm cho đến nay.

Người ta có thể nghĩ rằng dropout sẽ tăng hạng hiệu dụng so với lan truyền ngược. Đây không phải là điều chúng tôi tìm thấy; dropout có hạng hiệu dụng khoảng giống như lan truyền ngược. Hơn nữa, dropout có độ lớn trọng số và số lượng đơn vị chết khoảng giống như lan truyền ngược. Đáng ngạc nhiên, dropout dẫn đến việc mất tính dẻo dai cao hơn lan truyền ngược. Hiệu suất kém của dropout không được giải thích bởi ba tương quan của việc mất tính dẻo dai của chúng tôi. Một cuộc điều tra kỹ lưỡng về dropout vượt quá phạm vi của bài báo này, nhưng nó sẽ là một hướng thú vị cho công việc tương lai.

Chuẩn hóa online được mong đợi dẫn đến ít đơn vị chết hơn và hạng hiệu dụng cao hơn so với các mạng được huấn luyện với lan truyền ngược. Điều này xảy ra trong các nhiệm vụ sớm hơn, nhưng cả hai biện pháp đều xấu đi theo thời gian. Trong các nhiệm vụ sau này, mạng được huấn luyện bằng chuẩn hóa online có tỷ lệ phần trăm đơn vị chết cao hơn và hạng hiệu dụng thấp hơn so với mạng được huấn luyện bằng lan truyền ngược. Độ chính xác phân loại online phù hợp với những kết quả này. Ban đầu, chuẩn hóa online dẫn đến độ chính xác phân loại online tốt hơn, nhưng đến các nhiệm vụ sau này, độ chính xác phân loại của chuẩn hóa online trở nên thấp hơn so với lan truyền ngược.

Do tính mạnh mẽ của Adam đối với các mất mát không ổn định, người ta có thể mong đợi rằng Adam sẽ dẫn đến việc mất tính dẻo dai thấp hơn so với lan truyền ngược. Đây là điều ngược lại với những gì xảy ra. Việc mất tính dẻo dai của Adam có thể được phân loại là thảm khốc vì nó giảm mạnh. Phù hợp với các kết quả trước đó của chúng tôi, Adam có điểm số kém trong ba biện pháp tương ứng với các nguyên nhân của việc mất tính dẻo dai. Có một sự sụt giảm đáng kể trong hạng hiệu dụng của mạng được huấn luyện với Adam. Chúng tôi cũng đã thử nghiệm Adam với các hàm kích hoạt khác nhau trên bài toán hồi quy thay đổi chậm và phát hiện rằng việc mất tính dẻo dai với Adam thường tệ hơn so với SGD.

Nhiều phương pháp mà người ta có thể nghĩ sẽ giúp giảm thiểu việc mất tính dẻo dai đã làm tồi tệ hóa đáng kể việc mất tính dẻo dai. Việc mất tính dẻo dai với Adam đặc biệt đáng kể, và mạng được huấn luyện với Adam nhanh chóng mất hầu hết sự đa dạng của nó, được đo bằng hạng hiệu dụng. Việc mất tính dẻo dai đáng kể này của Adam là một kết quả quan trọng cho học tăng cường sâu vì Adam là bộ tối ưu hóa mặc định trong học tăng cường sâu và học tăng cường vốn dĩ là liên tục do chính sách luôn thay đổi. Tương tự như Adam, các phương pháp thường được sử dụng khác như dropout và chuẩn hóa làm tồi tệ hóa việc mất tính dẻo dai. Chuẩn hóa có hiệu suất tốt hơn từ đầu, nhưng sau này nó có sự sụt giảm hiệu suất sắc nét hơn so với lan truyền ngược. Trong thí nghiệm, dropout chỉ làm cho hiệu suất tồi tệ hơn. Chúng tôi thấy rằng xác suất dropout càng cao, việc mất tính dẻo dai càng lớn. Những kết quả này có nghĩa là một số công cụ thành công nhất trong bài toán huấn luyện một lần không chuyển sang học liên tục và chúng ta cần tập trung vào việc phát triển trực tiếp các công cụ cho học liên tục.

Không có phương pháp hiện có nào hoàn toàn duy trì tính dẻo dai. Một số phương pháp phổ biến như chuẩn hóa, Adam và dropout làm tồi tệ hóa việc mất tính dẻo dai. Mặt khác, L2-regularization và shrink-and-perturb giảm việc mất tính dẻo dai. Shrink-and-perturb đặc biệt hiệu quả, vì nó gần như hoàn toàn giảm thiểu việc mất tính dẻo dai. Tuy nhiên, ngay cả với shrink-and-perturb, vẫn có việc mất tính dẻo dai tối thiểu. Ngoài ra, cả shrink-and-perturb và L2-regularization đều rất nhạy cảm với giá trị siêu tham số. Chúng chỉ giảm việc mất tính dẻo dai cho một phạm vi rất nhỏ các tham số, trong khi đối với các giá trị siêu tham số khác, chúng làm cho việc mất tính dẻo dai tồi tệ hơn. Sự nhạy cảm này với siêu tham số có thể hạn chế việc ứng dụng của những phương pháp này cho học liên tục. Ngoài ra, shrink-and-perturb không hoàn toàn giải quyết ba tương quan của việc mất tính dẻo dai, nó có hạng hiệu dụng thấp hơn lan truyền ngược, và nó vẫn có tỷ lệ cao các đơn vị chết. Shrink-and-perturb thu nhỏ các trọng số và thêm tính ngẫu nhiên vào chúng ở mỗi bước. L2-regularization một mình không giảm thiểu việc mất tính dẻo dai. Điều này có nghĩa là cả hai phần của shrink-and-perturb đều quan trọng để giảm việc mất tính dẻo dai. Và hơi đáng ngạc nhiên, việc tiêm tính ngẫu nhiên liên tục là quan trọng để giảm thiểu việc mất tính dẻo dai.

## 6. Lan truyền ngược liên tục: Giảm gradient ngẫu nhiên với tái khởi tạo có chọn lọc

Bây giờ chúng tôi cố gắng phát triển một thuật toán mới có thể hoàn toàn giảm thiểu việc mất tính dẻo dai trong các bài toán học liên tục cũng như giải quyết cả ba tương quan của việc mất tính dẻo dai. Trong phần trước, chúng tôi đã học rằng việc tiêm tính ngẫu nhiên liên tục là quan trọng để giảm việc mất tính dẻo dai. Tuy nhiên, việc tiêm tính ngẫu nhiên liên tục trong phần trước được gắn với ý tưởng thu nhỏ các trọng số. Tồn tại công việc trước đó [57] đã đề xuất một cách trực tiếp hơn để tiêm tính ngẫu nhiên liên tục bằng cách tái khởi tạo có chọn lọc các đơn vị tiện ích thấp trong mạng. Nhưng những ý tưởng được trình bày trong bài báo đó không được phát triển đầy đủ và chỉ có thể được sử dụng với các mạng nơ-ron có một lớp ẩn duy nhất và một đầu ra duy nhất, vì vậy chúng không thể được sử dụng với học sâu hiện đại ở dạng hiện tại của chúng. Trong phần này, chúng tôi phát triển đầy đủ ý tưởng về tái khởi tạo có chọn lọc để nó có thể được sử dụng với học sâu hiện đại. Thuật toán kết quả kết hợp lan truyền ngược thông thường với tái khởi tạo có chọn lọc. Chúng tôi gọi nó là lan truyền ngược liên tục.

Theo một nghĩa, lan truyền ngược liên tục là một phần mở rộng đơn giản và tự nhiên của thuật toán lan truyền ngược thông thường cho học liên tục. Thuật toán lan truyền ngược thông thường có hai phần chính: khởi tạo với các trọng số ngẫu nhiên nhỏ và giảm gradient ở mỗi bước thời gian. Thuật toán này được thiết kế cho bài toán huấn luyện một lần, nơi việc học xảy ra một lần và không bao giờ nữa. Nó chỉ khởi tạo các kết nối với các số ngẫu nhiên nhỏ từ đầu, nhưng lan truyền ngược liên tục làm như vậy liên tục. Lan truyền ngược liên tục làm cho lan truyền ngược thông thường trở nên liên tục bằng cách thực hiện các tính toán tương tự ở mọi thời điểm. Nguyên tắc hướng dẫn đằng sau lan truyền ngược liên tục là các thuật toán học liên tục tốt nên thực hiện các tính toán tương tự ở mọi thời điểm.

Lan truyền ngược liên tục tái khởi tạo có chọn lọc các đơn vị tiện ích thấp trong mạng. Tái khởi tạo có chọn lọc có hai bước. Bước đầu tiên là tìm các đơn vị tiện ích thấp và bước thứ hai là tái khởi tạo chúng. Mỗi bước thời gian, một phần các đơn vị ẩn ρ, được gọi là tỷ lệ thay thế, được tái khởi tạo trong mỗi lớp. Khi một đơn vị ẩn mới được thêm vào, các trọng số đầu ra của nó được khởi tạo bằng không. Khởi tạo các trọng số đầu ra bằng không đảm bảo rằng các đơn vị ẩn mới được thêm vào không ảnh hưởng đến hàm đã học. Tuy nhiên, khởi tạo trọng số đầu ra bằng không làm cho đơn vị mới dễ bị tái khởi tạo ngay lập tức vì nó có tiện ích bằng không. Để bảo vệ các đơn vị mới khỏi việc tái khởi tạo ngay lập tức, chúng được bảo vệ khỏi tái khởi tạo trong một ngưỡng trưởng thành m số lần cập nhật.

Một hạn chế chính của công việc trước đó về tái khởi tạo có chọn lọc là biện pháp tiện ích bị giới hạn cho các mạng có một lớp ẩn duy nhất và một đầu ra. Chúng tôi vượt qua hạn chế này bằng cách đề xuất một biện pháp tiện ích có thể được áp dụng cho các mạng tùy ý. Biện pháp tiện ích của chúng tôi có hai phần. Phần đầu tiên đo đóng góp của các đơn vị cho người tiêu dùng của nó. Người tiêu dùng là bất kỳ đơn vị nào sử dụng đầu ra của một đơn vị nhất định. Người tiêu dùng có thể là các đơn vị ẩn khác hoặc các đơn vị đầu ra của mạng. Và phần thứ hai của tiện ích đo khả năng thích ứng của các đơn vị.

Phần đầu tiên của biện pháp tiện ích của chúng tôi, được gọi là tiện ích đóng góp, được định nghĩa cho mỗi kết nối hoặc trọng số và mỗi đơn vị. Trực giác cơ bản đằng sau tiện ích đóng góp là độ lớn của tích của kích hoạt đơn vị và trọng số đầu ra cung cấp thông tin về giá trị của kết nối này đối với người tiêu dùng của nó. Nếu đóng góp của một đơn vị ẩn cho người tiêu dùng của nó nhỏ, đóng góp của nó có thể bị áp đảo bởi đóng góp từ các đơn vị ẩn khác. Trong trường hợp như vậy, đơn vị ẩn không hữu ích cho người tiêu dùng của nó. Cùng biện pháp tiện ích kết nối đã được đề xuất cho bài toán cắt tỉa mạng [58]. Chúng tôi định nghĩa tiện ích đóng góp của một đơn vị ẩn là tổng các tiện ích của tất cả các kết nối đầu ra của nó. Tiện ích đóng góp được đo như một trung bình chạy của các đóng góp tức thời với tỷ lệ suy giảm, η. Trong một mạng nơ-ron feed-forward, tiện ích đóng góp, c_{l,i,t}, của đơn vị ẩn thứ i trong lớp l tại thời điểm t được cập nhật như

c_{l,i,t} = η * c_{l,i,t-1} + (1-η) * |h_{l,i,t}| * ∑_{k=1}^{n_{l+1}} |w_{l,i,k,t}|, (2)

trong đó h_{l,i,t} là đầu ra của đơn vị ẩn thứ i trong lớp l tại thời điểm t, w_{l,i,k,t} là trọng số kết nối đơn vị thứ i trong lớp l với đơn vị thứ k trong lớp l+1 tại thời điểm t, n_{l+1} là số lượng đơn vị trong lớp l+1.

Chúng tôi sử dụng phiên bản được hiệu chỉnh trung bình của tiện ích đóng góp. Tiện ích đóng góp được lấy cảm hứng từ bài toán cắt tỉa mạng. Bài toán cắt tỉa mạng xuất hiện trong bài toán huấn luyện một lần, nơi các kết nối được loại bỏ sau khi việc học hoàn thành. Tuy nhiên, chúng tôi đang nghiên cứu bài toán học liên tục nơi các đơn vị ẩn phải được thay thế trong khi học, vì vậy chúng ta cần xem xét hiệu ứng của quá trình học lên đóng góp của một đơn vị. Cụ thể, chúng ta cần loại bỏ phần đóng góp từ tiện ích có tương quan với bias. Trong trường hợp đặc biệt khi một người tiêu dùng chỉ có một đơn vị đầu vào và một bias, SGD sẽ chuyển phần trung bình của đóng góp sang đơn vị bias theo thời gian khi người tiêu dùng được loại bỏ. Chúng tôi định nghĩa tiện ích đóng góp được hiệu chỉnh trung bình, z_{l,i,t}, như tích của độ lớn của trọng số kết nối và độ lớn của kích hoạt trừ đi giá trị trung bình của kích hoạt.

f_{l,i,t} = η * f_{l,i,t-1} + (1-η) * h_{l,i,t}, (3)
f̂_{l,i,t} = f_{l,i,t-1} / (1-η^{a_{l,i,t}}), (4)
z_{l,i,t} = η * z_{l,i,t-1} + (1-η) * |h_{l,i,t} - f̂_{l,i,t}| * ∑_{k=1}^{n_{l+1}} |w_{l,i,k,t}|, (5)

trong đó h_{l,i,t} là đầu ra của đơn vị ẩn, w_{l,i,k,t} là trọng số kết nối đơn vị ẩn với đơn vị thứ k trong lớp l+1, n_{l+1} là số lượng đơn vị trong lớp l+1, a_{l,i,t} là tuổi của đơn vị ẩn tại thời điểm t. Ở đây, f_{l,i,t} là trung bình chạy của h_{l,i,t} và f̂_{l,i,t} là ước tính được hiệu chỉnh bias. Ngoài ra, chúng tôi cũng chuyển đóng góp trung bình của đơn vị, f̂_{l,i,t} * w_{l,i,k,t}, đến bias của người tiêu dùng khi đơn vị được loại bỏ để người tiêu dùng ít bị ảnh hưởng bởi việc loại bỏ đơn vị. Ý tưởng chuyển đóng góp trung bình đến bias cũng đã được sử dụng cho nhiệm vụ cắt tỉa mạng [59].

Phần thứ hai của biện pháp tiện ích của chúng tôi nắm bắt tốc độ một đơn vị có thể thích ứng. Chúng tôi đo khả năng thích ứng như nghịch đảo của độ lớn trung bình của các trọng số đầu vào của đơn vị, và chúng tôi gọi nó là tiện ích thích ứng. Tiện ích thích ứng, nghịch đảo của độ lớn trọng số đầu vào trung bình, một cách trực quan cố gắng nắm bắt tốc độ một đơn vị ẩn có thể thay đổi hàm mà nó đang biểu diễn. Ngoài ra, nghịch đảo của độ lớn trọng số là một biện pháp đặc biệt hợp lý cho tốc độ thích ứng cho các bộ tối ưu hóa kiểu Adam. Trong Adam, thay đổi trong trọng số trong một cập nhật duy nhất bị giới hạn trên bởi tham số tốc độ bước hoặc một bội số nhỏ của tham số tốc độ bước [25]. Vì vậy, trong mỗi cập nhật, các đơn vị ẩn có trọng số nhỏ hơn có thể có thay đổi tương đối lớn hơn trong hàm mà chúng biểu diễn.

Cuối cùng, chúng tôi định nghĩa tiện ích tổng thể của một đơn vị ẩn như trung bình chạy của tích tiện ích đóng góp được hiệu chỉnh trung bình và tiện ích thích ứng của nó. Tiện ích tổng thể, û_{l,i,t}, trở thành

y_{l,i,t} = |h_{l,i,t} - f̂_{l,i,t}| * (∑_{k=1}^{n_{l+1}} |w_{l,i,k,t}|) / (∑_{j=1}^{n_{l-1}} |w_{l-1,j,i,t}|) (6)
u_{l,i,t} = η * u_{l,i,t-1} + (1-η) * y_{l,i,t}, (7)
û_{l,i,t} = u_{l,i,t-1} / (1-η^{a_{l,i,t}}). (8)

Tiện ích tổng thể tức thời được mô tả trong Hình 5.

Thuật toán cuối cùng kết hợp lan truyền ngược thông thường với tái khởi tạo có chọn lọc để liên tục tiêm các đơn vị ẩn ngẫu nhiên từ phân phối ban đầu. Lan truyền ngược liên tục thực hiện một bước giảm gradient và tái khởi tạo có chọn lọc tại mỗi cập nhật. Thuật toán 1 chỉ định thuật toán lan truyền ngược liên tục cho một mạng nơ-ron feed-forward. Thuật toán lan truyền ngược liên tục của chúng tôi vượt qua hạn chế của công việc trước đó ([60, 57]) về tái khởi tạo có chọn lọc và làm cho nó tương thích với học sâu hiện đại. Công việc trước đó có hai hạn chế đáng kể. Đầu tiên, thuật toán của họ chỉ áp dụng được cho các mạng nơ-ron có một lớp ẩn duy nhất và một đầu ra duy nhất. Thứ hai, nó bị giới hạn cho các kích hoạt LTU, trọng số nhị phân và SGD. Chúng tôi vượt qua tất cả những hạn chế này. Thuật toán của chúng tôi có thể áp dụng cho các mạng feed-forward tùy ý. Chúng tôi mô tả cách sử dụng nó với các kích hoạt hiện đại và bộ tối ưu hóa như Adam trong Phụ lục E. Tên "Liên tục" lan truyền ngược xuất phát từ góc độ thuật toán. Thuật toán lan truyền ngược, như được đề xuất bởi [19], có hai phần, khởi tạo với các số ngẫu nhiên nhỏ và giảm gradient. Tuy nhiên, khởi tạo chỉ xảy ra ban đầu, vì vậy lan truyền ngược không phải là thuật toán liên tục vì nó không thực hiện các tính toán tương tự ở mọi thời điểm. Mặt khác, lan truyền ngược liên tục là liên tục vì nó thực hiện các tính toán tương tự ở mọi thời điểm.

Sau đó chúng tôi áp dụng lan truyền ngược liên tục trên Continual Imagenet, Online Permuted MNIST và hồi quy thay đổi chậm. Chúng tôi bắt đầu với Online Permuted MNIST. Chúng tôi sử dụng cùng mạng như trong phần trước, một mạng với 3 lớp ẩn với 2000 đơn vị ẩn mỗi lớp. Chúng tôi huấn luyện mạng bằng SGD với tốc độ bước 0.003. Đối với lan truyền ngược liên tục, chúng tôi hiển thị độ chính xác phân loại online cho các giá trị khác nhau của tỷ lệ thay thế. Tỷ lệ thay thế là siêu tham số chính trong lan truyền ngược liên tục, nó kiểm soát tốc độ các đơn vị được tái khởi tạo trong mạng. Ví dụ, tỷ lệ thay thế 1e-4 cho mạng của chúng tôi với 2000 đơn vị ẩn trong mỗi lớp có nghĩa là thay thế một đơn vị trong mỗi lớp sau mỗi 5 ví dụ. Các siêu tham số cho L2-regularization, Shrink and Perturb, Online Norm, Adam và Dropout được chọn như được mô tả trong phần trước. Độ chính xác phân loại online của các thuật toán khác nhau trên Online Permuted MNIST được trình bày trong Hình 6a. Kết quả được tính trung bình trên ba mươi lần chạy.

Trong số tất cả các thuật toán, chỉ có lan truyền ngược liên tục có hiệu suất không suy giảm. Hiệu suất của tất cả các thuật toán khác suy giảm theo thời gian. Ngoài ra, lan truyền ngược liên tục ổn định cho một phạm vi rộng các giá trị siêu tham số. Lưu ý rằng hai thuật toán hoạt động tốt nhất là lan truyền ngược liên tục và shrink-and-perturb. Và cả hai thuật toán này đều cho phép có độ lớn trọng số nhỏ và sự đa dạng của biểu diễn theo thiết kế của chúng.

Hãy xem xét sâu hơn mạng đang học thông qua lan truyền ngược liên tục. Sự tiến hóa của các tương quan của việc mất tính dẻo dai khi sử dụng lan truyền ngược liên tục được hiển thị trong Hình 6b. Lan truyền ngược liên tục giảm thiểu cả ba tương quan của việc mất tính dẻo dai. Nó gần như không có đơn vị chết, ngăn chặn trọng số mạng khỏi tăng trưởng, và duy trì hạng hiệu dụng cao qua các nhiệm vụ. Tất cả các thuật toán duy trì độ lớn trọng số thấp đều giảm việc mất tính dẻo dai. Điều này hỗ trợ tuyên bố của chúng tôi rằng độ lớn trọng số thấp quan trọng để duy trì tính dẻo dai. Các thuật toán duy trì độ lớn trọng số thấp là lan truyền ngược liên tục, L2-regularization và shrink-and-perturb. Shrink-and-perturb và lan truyền ngược liên tục có lợi thế bổ sung so với L2-regularization: chúng tiêm tính ngẫu nhiên vào mạng. Việc tiêm tính ngẫu nhiên này dẫn đến hạng hiệu dụng cao hơn và số lượng đơn vị chết thấp hơn, điều này dẫn đến cả hai thuật toán này hoạt động tốt hơn L2-regularization. Tuy nhiên, lan truyền ngược liên tục tiêm tính ngẫu nhiên một cách có chọn lọc, loại bỏ hiệu quả tất cả các đơn vị chết khỏi mạng và dẫn đến hạng hiệu dụng cao hơn. Số lượng đơn vị chết nhỏ hơn và hạng hiệu dụng cao hơn này giải thích hiệu suất tốt hơn của lan truyền ngược liên tục.

Sau đó chúng tôi áp dụng lan truyền ngược liên tục trên Continual ImageNet. Tương tự như các thí nghiệm trên Continual ImageNet trong Phần 2, chúng tôi sử dụng SGD với momentum và cùng mạng được mô tả trong Bảng 1. Chúng tôi cũng thử nghiệm L2 regularization và shrink-and-perturb trên Continual Imanget, vì đây là hai phương pháp duy nhất giảm việc mất tính dẻo dai trong online Permuted MNIST. Đối với tất cả các thuật toán, chúng tôi trình bày hiệu suất của giá trị siêu tham số có độ chính xác phân loại trung bình lớn nhất trên 5000 nhiệm vụ. Độ chính xác phân loại của các thuật toán khác nhau trên Continual ImageNet được hiển thị trong Hình 7. Kết quả được tính trung bình trên ba mười lần chạy. Chi tiết về việc lựa chọn siêu tham số cho tất cả các thuật toán được sử dụng trong Hình 7 được trình bày trong Phụ lục A. Điểm đầu tiên trong biểu đồ là độ chính xác trung bình trên 50 nhiệm vụ đầu tiên; điểm tiếp theo là độ chính xác trung bình trên 50 nhiệm vụ tiếp theo và cứ thế.

Lan truyền ngược liên tục hoàn toàn giảm thiểu việc mất tính dẻo dai trong Continual ImageNet. Độ chính xác phân loại của nó trên nhiệm vụ thứ 5000 tốt hơn so với nhiệm vụ đầu tiên. Nó cũng vượt trội hơn các kỹ thuật hiện có như L2-regularization và shrink-and-perturb.

Trong phần này, chúng tôi đã giới thiệu lan truyền ngược liên tục, liên tục tái khởi tạo các đơn vị ẩn tiện ích thấp cùng với giảm gradient. Lan truyền ngược liên tục hoàn toàn duy trì tính dẻo dai trong Continual ImageNet, Online Permuted MNIST. Chúng tôi cũng đã thử nghiệm lan truyền ngược liên tục trên hồi quy thay đổi chậm và phát hiện rằng nó vượt qua việc mất tính dẻo dai cho tất cả các hàm kích hoạt cho cả SGD và Adam. Lan truyền ngược liên tục vượt trội hơn tất cả các phương pháp hiện có trên cả ba bài toán học liên tục. Nó ít nhạy cảm hơn nhiều với siêu tham số của nó so với các thuật toán khác như L2-regularization và shrink-and-perturb. Nó cũng giảm thiểu cả ba tương quan của tính dẻo dai vì nó duy trì độ lớn trọng số trung bình thấp, tỷ lệ rất nhỏ các đơn vị chết, và hạng hiệu dụng cao. Ngoài ra, chúng tôi đã thực hiện một nghiên cứu loại bỏ cho biện pháp tiện ích trong lan truyền ngược liên tục. Kết quả của nghiên cứu loại bỏ được trình bày trong Phụ lục D, và nó cho thấy rằng tất cả các thành phần của biện pháp tiện ích đều quan trọng cho hiệu suất tốt nhất. Ngoài ba bài toán học có giám sát, chúng tôi cũng đã thử nghiệm các thuật toán này trong một bài toán học có giám sát liên tục. Kết quả của thí nghiệm đó phần lớn phù hợp với kết quả của các thí nghiệm học có giám sát và được trình bày trong Phụ lục C.

Lan truyền ngược liên tục mở ra những hướng mới cho khám phá thuật toán. Bây giờ chúng tôi xem xét sâu hơn cách lan truyền ngược liên tục được kết nối với các ý tưởng khác trong tài liệu, và cách nó gợi ý nhiều hướng thú vị cho công việc tương lai. Chúng tôi mong đợi rằng công việc tương lai sẽ khám phá những hướng này và đề xuất các biến thể mới và mạnh mẽ hơn của lan truyền ngược liên tục.

Tái khởi tạo có chọn lọc sử dụng một biện pháp tiện ích để tìm và thay thế các đơn vị tiện ích thấp. Một hạn chế của lan truyền ngược liên tục là biện pháp tiện ích dựa trên kinh nghiệm. Mặc dù nó hoạt động tốt, công việc tương lai về các biện pháp tiện ích có nguyên tắc hơn sẽ cải thiện nền tảng của lan truyền ngược liên tục. Biện pháp tiện ích hiện tại của chúng tôi không phải là biện pháp tiện ích toàn cục vì nó không xem xét cách một đơn vị nhất định ảnh hưởng đến hàm được biểu diễn tổng thể. Một khả năng là phát triển các biện pháp tiện ích nơi tiện ích được lan truyền ngược từ hàm mất mát. Ý tưởng về tiện ích trong lan truyền ngược liên tục có liên quan chặt chẽ đến tiện ích kết nối trong tài liệu cắt tỉa mạng nơ-ron. Các bài báo khác nhau [61, 62, 63] đã đề xuất các biện pháp khác nhau về tiện ích kết nối cho bài toán cắt tỉa mạng. Việc điều chỉnh những biện pháp tiện ích này để giảm thiểu việc mất tính dẻo dai là một hướng đầy hứa hẹn cho các thuật toán lan truyền ngược liên tục mới.

Ý tưởng về tái khởi tạo có chọn lọc tương tự như ý tưởng nổi lên về huấn luyện thưa thớt động [64, 65]. Trong huấn luyện thưa thớt động, một mạng thưa thớt được huấn luyện từ đầu và các kết nối giữa các đơn vị khác nhau được tạo ra và loại bỏ trong quá trình huấn luyện. Loại bỏ kết nối yêu cầu một biện pháp tiện ích, và việc khởi tạo các kết nối mới yêu cầu một bộ tạo tương tự như tái khởi tạo có chọn lọc. Sự khác biệt chính giữa huấn luyện thưa thớt động và lan truyền ngược liên tục là huấn luyện thưa thớt động hoạt động trên các kết nối giữa các đơn vị trong khi lan truyền ngược liên tục hoạt động trên các đơn vị. Do đó, bộ tạo trong huấn luyện thưa thớt động cũng phải quyết định kết nối mới nào để phát triển. Huấn luyện thưa thớt động đã đạt được kết quả đầy hứa hẹn trong các bài toán học có giám sát và học tăng cường [66, 67], nơi các mạng thưa thớt động đạt được hiệu suất gần với các mạng dày đặc ngay cả ở mức độ thưa thớt cao. Huấn luyện thưa thớt động là một ý tưởng đầy hứa hẹn để duy trì tính dẻo dai.

Ý tưởng thêm các đơn vị mới vào mạng nơ-ron có mặt trong tài liệu học liên tục [68, 69, 9]. Ý tưởng này thường được thể hiện trong các thuật toán tăng kích thước mạng một cách động. Vì vậy, những phương pháp này không có giới hạn trên về yêu cầu bộ nhớ. Ví dụ, Rusu et al. [69] đã trình bày một phương pháp tiếp tục mở rộng kích thước của mạng khi nó nhìn thấy ngày càng nhiều dữ liệu. Phương pháp của họ mở rộng mạng bằng cách phân bổ một mạng con mới bất cứ khi nào có một nhiệm vụ mới. Mặc dù những phương pháp này có liên quan đến các ý tưởng trong lan truyền ngược liên tục, không ai phù hợp để so sánh, vì lan truyền ngược liên tục được thiết kế cho trường hợp khi hệ thống học có bộ nhớ hữu hạn. Và những phương pháp này do đó sẽ yêu cầu sửa đổi không tầm thường để áp dụng cho bài toán bộ nhớ hữu hạn của chúng tôi.

Các công trình trước đó về tầm quan trọng của khởi tạo đã tập trung vào việc tìm độ lớn trọng số chính xác để khởi tạo các trọng số. Glorot và Bengio [40] đã chỉ ra một cách phân tích và thực nghiệm rằng việc khởi tạo các trọng số để gradient không trở nên nhỏ theo cấp số nhân trong các lớp đầu của mạng với kích hoạt sigmoid và gradient được bảo toàn qua các lớp là điều cần thiết. He et al. [70] đã xây dựng dựa trên ý tưởng này cho hàm kích hoạt ReLU. Sutskever et al. [71] đã chỉ ra rằng khởi tạo với trọng số nhỏ rất quan trọng cho kích hoạt sigmoid vì chúng có thể bão hòa nếu trọng số quá lớn. Mặc dù tất cả công việc này về tầm quan trọng của khởi tạo, thực tế là lợi ích của nó chỉ có mặt từ đầu nhưng không liên tục đã bị bỏ qua vì hầu hết những bài báo này tập trung vào bài toán huấn luyện một lần, nơi việc học chỉ phải được thực hiện một lần.

Việc mất tính dẻo dai cũng có thể được kết nối với giả thuyết vé số [72]. Giả thuyết nói rằng các mạng được khởi tạo ngẫu nhiên chứa các mạng con có thể đạt được hiệu suất gần với mạng gốc với số lượng cập nhật tương tự. Những mạng con này được gọi là vé trúng thưởng. Chúng tôi phát hiện rằng trong các bài toán học liên tục, hạng hiệu dụng của biểu diễn ở đầu các nhiệm vụ giảm theo thời gian. Theo một nghĩa nào đó, mạng thu được sau khi huấn luyện trên nhiều nhiệm vụ có ít tính ngẫu nhiên và đa dạng hơn mạng ngẫu nhiên ban đầu. Tính ngẫu nhiên giảm có thể có nghĩa là mạng có ít vé trúng thưởng hơn. Và số lượng vé trúng thưởng giảm này có thể giải thích việc mất tính dẻo dai. Việc khám phá đầy đủ mối liên hệ giữa việc mất tính dẻo dai và giả thuyết vé số có thể làm sâu sắc thêm hiểu biết của chúng ta về việc mất tính dẻo dai.

Một số công trình gần đây đã tập trung vào việc nhanh chóng thích ứng với những thay đổi trong luồng dữ liệu [73, 74, 75]. Tuy nhiên, bài toán trong những bài báo này là offline vì chúng có hai giai đoạn riêng biệt, một cho học và một cho đánh giá. Để sử dụng những phương pháp này online, chúng phải được huấn luyện trước trên các nhiệm vụ đại diện cho những nhiệm vụ mà người học sẽ gặp phải trong giai đoạn đánh giá online. Yêu cầu có quyền truy cập vào các nhiệm vụ đại diện trong giai đoạn huấn luyện trước này không thực tế cho các hệ thống học suốt đời vì thế giới thực là không ổn định, và thậm chí phân phối của các nhiệm vụ có thể thay đổi theo thời gian. Những phương pháp này không thể so sánh với những phương pháp mà chúng tôi nghiên cứu trong công việc của chúng tôi, vì chúng tôi nghiên cứu các phương pháp hoàn toàn online không yêu cầu huấn luyện trước.

Trong công việc này, chúng tôi phát hiện rằng các phương pháp liên tục tiêm tính ngẫu nhiên trong khi duy trì độ lớn trọng số nhỏ đã giảm đáng kể việc mất tính dẻo dai. Nhiều công trình đã phát hiện rằng việc thêm nhiễu trong khi huấn luyện mạng nơ-ron có thể cải thiện hiệu suất huấn luyện và kiểm tra. Lợi ích chính của việc thêm nhiễu đã được báo cáo là tránh quá khớp và cải thiện hiệu suất huấn luyện [76, 77, 78]. Tuy nhiên, lợi ích của nhiễu được tiêm là gây tranh cãi vì có thể khó khăn để tiêm nhiễu để tránh hiệu suất kém. Ví dụ, Greff et al. [79] tuyên bố thêm nhiễu luôn làm tồi tệ hóa hiệu suất mạng của họ. Trong trường hợp của chúng tôi, khi phân phối dữ liệu không ổn định, chúng tôi phát hiện rằng việc liên tục tiêm nhiễu có thể giúp duy trì tính dẻo dai trong mạng nơ-ron.

Việc mất tính dẻo dai cũng cung cấp một lời giải thích thay thế cho các kết quả gần đây khác nhau trong học tăng cường sâu. Bài toán học tăng cường có nhiều nguồn không ổn định khác nhau, từ chính sách thay đổi đến hàm mục tiêu thay đổi. Do những không ổn định này, chúng ta mong đợi rằng các mạng nơ-ron sâu sẽ mắc phải việc mất tính dẻo dai trong các bài toán học tăng cường. Igl et al. [80] phát hiện rằng các hệ thống học tăng cường sâu có thể mất khả năng tổng quát hóa của chúng khi có mặt không ổn định. Việc mất khả năng tổng quát hóa này có thể là một trường hợp của việc mất tính dẻo dai, tương tự như việc mất tính dẻo dai mà chúng tôi quan sát thấy trong Continual Imagenet và online Permuted MNIST. Kumar et al. [81] quan sát thấy sự giảm hạng hiệu dụng của biểu diễn trong một số thuật toán học tăng cường sâu. Sự giảm hạng hiệu dụng đó tương tự như sự giảm hạng mà chúng tôi thấy trong bài toán online Permuted MNIST, và quan sát của họ có thể là một trường hợp khác của việc mất tính dẻo dai trong các mạng sâu. Nikishin et al. [23] đề xuất đặt lại một số lớp của mạng để vượt qua việc mất tính dẻo dai. Phương pháp giải pháp của họ, đặt lại một số lớp của mạng, phù hợp với kết quả của chúng tôi rằng khởi tạo với các số ngẫu nhiên nhỏ là cần thiết cho việc học. Phương pháp của họ thay đổi mạnh mạng bằng cách tái khởi tạo một phần lớn của mạng, trong khi lan truyền ngược liên tục chỉ thay đổi nhẹ mạng, nhưng nó làm như vậy liên tục.

## 7. Thảo luận

Trong bài báo này, chúng tôi đã chỉ ra một cách trực tiếp, kỹ lưỡng và có hệ thống hơn đáng kể so với công việc trước đó rằng các phương pháp học sâu tiêu chuẩn thất bại trong các bài toán học liên tục. Chúng tôi đã thử nghiệm các phương pháp học sâu trong các bài toán học có giám sát liên tục bắt nguồn từ các bộ dữ liệu tiêu chuẩn như Imagenet và MNIST. Đây là những thí nghiệm đơn giản nhất mà việc mất tính dẻo dai có thể xảy ra, vì các thí nghiệm được thiết kế để tuân theo thực hành học sâu tiêu chuẩn ngoại trừ việc yêu cầu hệ thống tiếp tục học trên các nhiệm vụ mới. Việc ở gần thực hành tiêu chuẩn đảm bảo không có vấn đề gây nhiễu, và các thí nghiệm trực tiếp cho thấy rằng các phương pháp học sâu mất tính dẻo dai. Các phương pháp học sâu mất tính dẻo dai trong cả bài toán phân loại và hồi quy. Việc mất tính dẻo dai xảy ra cho các hàm kích hoạt, tối ưu hóa, kích thước mạng khác nhau, và các phương pháp phổ biến khác nhau như dropout, chuẩn hóa, Adam và chính quy hóa, có nghĩa là việc mất tính dẻo dai là một hiện tượng rộng rãi. Chúng tôi đã thực hiện những thí nghiệm này một cách có hệ thống với các tiêu chuẩn phương pháp cao nhất bằng cách thực hiện quét tham số rộng và ít nhất 30 lần chạy độc lập cho tất cả các phương pháp. Bằng các phương pháp học sâu tiêu chuẩn, chúng tôi có nghĩa là các phương pháp được chuyên môn hóa cho bài toán huấn luyện một lần, và bằng thất bại, chúng tôi có nghĩa là chúng mất khả năng học những điều mới. Trong các bài toán học liên tục, các phương pháp học sâu tiêu chuẩn không hoạt động tốt.

Chúng tôi cũng có hiểu biết tốt hơn đáng kể về việc mất tính dẻo dai và các phương pháp giải pháp. Nguyên nhân gốc rễ của việc mất tính dẻo dai là các lợi ích được cung cấp bởi khởi tạo với các số ngẫu nhiên nhỏ bị mất theo thời gian. Việc đi sâu vào các mạng tiết lộ rằng nhiều tính chất hữu ích của khởi tạo như độ lớn trọng số nhỏ, ít đơn vị chết, và biểu diễn đa dạng bị mất theo thời gian. Nhiều phương pháp thường được sử dụng như Adam và dropout làm tồi tệ hóa đáng kể việc mất tính dẻo dai, trong khi L2-regularization và shrink-and-perturb được điều chỉnh đúng cách giảm thiểu việc mất tính dẻo dai trong nhiều trường hợp. Chúng tôi đã phát triển thuật toán lan truyền ngược liên tục, mở rộng thuật toán lan truyền ngược thông thường bằng cách tái khởi tạo có chọn lọc một phần nhỏ các đơn vị ẩn tiện ích thấp tại mỗi cập nhật. Lan truyền ngược liên tục hoàn toàn giảm thiểu việc mất tính dẻo dai trong tất cả các bài toán học có giám sát liên tục. Nó xếp hạng các đơn vị theo tiện ích của chúng đối với hoạt động của mạng, và nhiều cải tiến hơn có thể trong cách thực hiện xếp hạng, đặc biệt là cho các mạng hồi quy.

Công việc này mở ra nhiều hướng để hiểu và giải quyết việc mất tính dẻo dai. Mặc dù chúng tôi đã đạt được tiến bộ đáng kể trong việc hiểu việc mất tính dẻo dai, vẫn chưa rõ các tính chất cụ thể nào của khởi tạo với các số ngẫu nhiên nhỏ quan trọng để duy trì tính dẻo dai. Công việc gần đây [82, 83] đã đạt được tiến bộ thú vị theo hướng này, và nó vẫn là một con đường quan trọng cho công việc tương lai. Một mảnh ghép quan trọng còn thiếu trong tài liệu học liên tục là việc hình thức hóa các hiện tượng khác nhau như việc mất tính dẻo dai và quên thảm khốc. Các bài báo mới [84] đã cố gắng lấp đầy khoảng trống này trong tài liệu và công việc tương lai hình thức hóa những khái niệm này sẽ là đóng góp có giá trị cho hiểu biết của chúng ta về học liên tục. Một trong những người tiêu dùng chính của các ý tưởng trong học liên tục là học tăng cường. Công việc gần đây đã cải thiện hiệu suất trong nhiều bài toán học tăng cường bằng cách áp dụng các phương pháp bảo tồn tính dẻo dai [85, 86, 87, 88]. Các phương pháp học tăng cường sâu hiện đại sử dụng các kỹ thuật như mạng mục tiêu và bộ đệm phát lại để biến học tăng cường thành gần như bài toán huấn luyện một lần. Một ứng dụng trực tiếp hơn của học liên tục là trong các phương pháp không sử dụng kỹ thuật để biến học tăng cường thành bài toán huấn luyện một lần. Chúng tôi nhìn về phía trước một tương lai đầy hứa hẹn của các thuật toán học liên tục tốt hơn và mạnh mẽ hơn.

## Lời cảm ơn

Chúng tôi muốn cảm ơn Martha White và Prabhat Nagarajan về phản hồi của họ về công việc này. Chúng tôi biết ơn Digital Research Alliance of Canada vì đã cung cấp tài nguyên tính toán để thực hiện các thí nghiệm trong bài báo này. Chúng tôi cũng ghi nhận tài trợ từ Chương trình Canada CIFAR AI Chairs, DeepMind, Alberta Machine Intelligence Institute (Amii), và Natural Sciences and Engineering Research Council (NSERC) của Canada. Công việc này được thực hiện nhờ môi trường nghiên cứu kích thích và hỗ trợ được tạo ra bởi các thành viên của Phòng thí nghiệm Học tăng cường và Trí tuệ nhân tạo (RLAI), đặc biệt là các cuộc thảo luận sâu sắc được tổ chức tại nhóm trạng thái tác nhân.

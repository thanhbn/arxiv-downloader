# 2308.14831.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/continual-learning/2308.14831.pdf
# Kích thước tệp: 1137650 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Học Liên Tục với Huấn Luyện Thưa Thích Ứng:
Khám Phá Các Thuật Toán để Cập Nhật Mô Hình Hiệu Quả
Murat Onur Yildirim1, Elif Ceren Gok Yildirim1, Ghada Sokar1, Decebal Constantin Mocanu2, Joaquin
Vanschoren1
1Đại học Công nghệ Eindhoven,2Đại học Luxembourg
m.o.yildirim@tue.nl, e.c.gok@tue.nl, g.a.z.n.sokar@tue.nl,
decebal.mocanu@uni.lu, j.vanschoren@tue.nl
Học liên tục (CL) đề cập đến khả năng của một hệ thống thông minh có thể tuần tự thu thập
và lưu giữ kiến thức từ một luồng dữ liệu với chi phí tính toán ít nhất có thể.
Để đạt được điều này; các phương pháp chính quy hóa, phát lại, kiến trúc và cô lập tham số đã được
giới thiệu vào tài liệu. Cô lập tham số sử dụng mạng thưa cho phép
phân bổ các phần riêng biệt của mạng nơ-ron cho các nhiệm vụ khác nhau và cũng cho phép chia sẻ
tham số giữa các nhiệm vụ nếu chúng tương tự. Huấn Luyện Thưa Thích Ứng (DST) là một
cách nổi bật để tìm những mạng thưa này và cô lập chúng cho từng nhiệm vụ. Bài báo này là
nghiên cứu thực nghiệm đầu tiên điều tra tác động của các thành phần DST khác nhau dưới mô hình CL
để lấp đầy một khoảng trống nghiên cứu quan trọng và làm sáng tỏ cấu hình tối ưu của DST
cho CL nếu nó tồn tại. Do đó, chúng tôi thực hiện một nghiên cứu toàn diện trong đó chúng tôi điều tra
các thành phần DST khác nhau để tìm topo tốt nhất cho mỗi nhiệm vụ trên các bộ dữ liệu CIFAR100 và
miniImageNet nổi tiếng trong một thiết lập CL tăng dần theo nhiệm vụ vì trọng tâm chính của chúng tôi là
đánh giá hiệu suất của các tiêu chí DST khác nhau, thay vì quá trình lựa chọn mặt nạ.
Chúng tôi phát hiện rằng, ở mức độ thưa thấp, khởi tạo Erd˝os-Rényi Kernel (ERK) sử dụng
xương sống hiệu quả hơn và cho phép học các gia tăng nhiệm vụ một cách hiệu quả. Ở mức độ thưa cao,
trừ khi nó cực đoan, khởi tạo đồng nhất thể hiện hiệu suất đáng tin cậy và mạnh mẽ hơn. Về mặt chiến lược tăng trưởng;
hiệu suất phụ thuộc vào chiến lược khởi tạo được xác định và mức độ thưa. Cuối cùng, tính thích ứng trong các thành phần DST
là một cách đầy hứa hẹn cho những người học liên tục tốt hơn.

1. Giới thiệu
Học liên tục (CL) là một phương pháp phát triển các mô hình có thể học và thích ứng liên tục từ một
luồng dữ liệu, hoặc nhiệm vụ, không giống như học theo lô tiêu chuẩn cần truy cập đồng thời vào dữ liệu của tất cả các danh mục. Do đó, nó cho phép học tập hiệu quả và tránh lưu trữ lượng lớn dữ liệu. Tuy nhiên,
điều này thường đi kèm với một cái giá, được gọi là quên thảm khốc, sự suy giảm thông tin đã học trước đó
khi người học sâu tập trung vào việc học những thứ mới. Bốn phương pháp chính đã được khám phá để giải quyết
vấn đề này. Chính quy hóa [1–5] ngăn chặn những thay đổi đột ngột trong trọng số mạng nơ-ron. Phát lại lưu trữ một số
mẫu thực [6–8] hoặc tạo ra một số mẫu tổng hợp bằng cách học phân phối dữ liệu [9–12] cho mỗi lớp
và tập duyệt chúng. Mở rộng kiến trúc [13–17] sửa đổi kiến trúc mạng, thường bằng cách thêm
các thành phần mạng bổ sung. Cô lập tham số [18–27] phân vùng mạng nơ-ron thành các mạng con
được dành riêng cho các nhiệm vụ khác nhau và đóng băng trọng số của các mạng con cho phép bảo tồn
kiến thức đã học trước đó. Trong bài báo này1, chúng tôi tập trung vào phương pháp cô lập tham số do việc sử dụng
dung lượng mạng cố định, xu hướng quên thấp và hiệu quả về bộ nhớ và tính toán.

Cô lập tham số thường đóng băng các kết nối của các mạng con trước đó và chỉ cập nhật những cái mới được thêm vào
để có thể học mạng con hiện tại. Nó có thể được thực hiện thông qua học mặt nạ [18,19], cắt tỉa lặp
[20–22] hoặc huấn luyện thưa thích ứng (DST) [23–27]. Học mặt nạ sử dụng một xương sống dày đặc cố định, thường được huấn luyện trước,
và chỉ dự định tìm mặt nạ tốt nhất cho một nhiệm vụ cụ thể. Cắt tỉa lặp huấn luyện một mạng dày đặc
và sau đó lặp lại loại bỏ các trọng số không hứa hẹn với độ lớn nhỏ nhất trong khi DST nhằm huấn luyện
mạng thưa từ đầu và tìm topo tốt nhất đồng thời bằng cách bỏ và phát triển các
thành phần khác nhau của mạng trong quá trình huấn luyện để khám phá topo thưa tốt nhất. Nó giảm số lượng
tham số theo cấp số nhân trong cả huấn luyện và suy luận mà không ảnh hưởng đến độ chính xác [28]. DST
có thể được thực hiện ở cấp độ nơ-ron hoặc cấp độ kết nối được gọi là cắt tỉa có cấu trúc và không có cấu trúc
tương ứng. Mặc dù cắt tỉa có cấu trúc cho phép các mạng con hiệu quả hơn về mặt tính toán, nó đã được
chỉ ra là hoạt động kém hơn so với cắt tỉa không có cấu trúc ở mức độ thưa cao hơn [29] điều này dành nhiều
không gian hơn cho các nhiệm vụ tiếp theo trong mạng.

DST đã nổi lên như một kỹ thuật đầy hứa hẹn để tăng cường hiệu quả và khái quát hóa của mạng nơ-ron
bằng cách cắt tỉa và thưa hóa thích ứng các tham số mạng trong quá trình huấn luyện cho học theo lô tiêu chuẩn.
Tuy nhiên, khi áp dụng cho CL, các thiết lập tiêu chuẩn của DST cho học theo lô có thể không khai thác đầy đủ
tiềm năng của nó. Điều tra các thành phần khác nhau của DST dưới các thiết lập CL là cần thiết vì một số lý do. Thứ nhất,
học liên tục đòi hỏi việc giữ lại kiến thức thu được từ các nhiệm vụ trước đó, điều này có thể đòi hỏi
các chiến lược cắt tỉa và khởi tạo lại khác nhau. Thứ hai, các chiến lược tối ưu cho DST có thể khác nhau trong
bối cảnh học liên tục, nơi các nhiệm vụ đến tuần tự và nhiều hơn một mạng con nên được học
tăng dần, sử dụng cùng một xương sống. Cuối cùng, các tình huống học liên tục thường liên quan đến mất cân bằng lớp,
trôi khái niệm, và độ phức tạp nhiệm vụ khác nhau, điều này có thể đòi hỏi các phương pháp tùy chỉnh cho tính thưa thích ứng.
Do đó, bằng cách khám phá và thích ứng các yếu tố khác nhau của DST với học liên tục, chúng ta có thể mở khóa
tiềm năng đầy đủ của nó để giảm thiểu các thách thức của CL và cải thiện hiệu quả và hiệu suất của mạng nơ-ron
trong các tình huống học suốt đời. Do đó, trong bài báo này, chúng tôi đã tiến hành các thí nghiệm quy mô lớn trên CIFAR100
và miniImageNet với các xương sống khác nhau và số lượng nhiệm vụ khác nhau. Chúng tôi phân tích hiệu suất DST không có cấu trúc
trong CL về độ chính xác tăng dần, chuyển tiếp ngược và chuyển tiếp tiến dưới các mức độ thưa khác nhau,
khởi tạo và chiến lược tăng trưởng. Chúng tôi tập trung vào CL tăng dần theo nhiệm vụ vì chúng tôi đặc biệt muốn
quan sát hiệu suất của các tiêu chí DST khác nhau, không phải quá trình lựa chọn mặt nạ. Những phát hiện của chúng tôi là:

I. Ở mức độ thưa thấp đến vừa phải (80-90%), khởi tạo Erd˝os-Rényi Kernel (ERK) sử dụng
xương sống hiệu quả hơn bằng cách sử dụng các kết nối trong các lớp hẹp một cách tiết kiệm cho phép
học các gia tăng nhiệm vụ một cách hiệu quả.

II. Ở mức độ thưa cao (95%), trừ khi nó cực đoan (99%), khởi tạo đồng nhất thể hiện
hiệu suất tăng dần mạnh mẽ hơn bằng cách duy trì hiệu suất ổn định qua các nhiệm vụ.

III. Từ góc độ chiến lược tăng trưởng, kết quả hiệu suất phụ thuộc vào chiến lược khởi tạo được xác định,
và mức độ thưa.

IV. Chưa có giải pháp vạn năng cho DST trong CL và việc lựa chọn tiêu chí DST thích ứng cho mỗi nhiệm vụ
hứa hẹn sẽ tăng cường hiệu suất, so với các chiến lược được xác định trước cho tất cả các nhiệm vụ. Chúng tôi chỉ ra
rằng một sự thay đổi ngây thơ giữa các chiến lược tăng trưởng khác nhau tăng cường hiệu suất tăng dần.

2. Bối cảnh và Công trình Liên quan
DST cho Học Theo Lô Tiêu chuẩn. Huấn luyện thưa thích ứng là một kỹ thuật để đạt được một mạng thưa trong đó
mô hình được khởi tạo với một topo thưa ngẫu nhiên và sau đó các kết nối được cắt tỉa và phát triển thích ứng
trong quá trình huấn luyện để cải thiện hiệu quả tính toán và hiệu suất khái quát hóa [28].
Điều này liên quan đến một khoảng thời gian cập nhật topo mạng và một chiến lược bỏ/tăng trưởng để khám phá mạng
trong một mức độ thưa được xác định trước trong khi giảm thiểu hàm mất mát bằng cách bảo tồn các trọng số quan trọng cho
một nhiệm vụ cụ thể. Bằng cách giảm số lượng kết nối, huấn luyện thưa thích ứng có thể tăng tốc huấn luyện và giảm
yêu cầu bộ nhớ trong khi duy trì hoặc thậm chí cải thiện độ chính xác mô hình [30].

SET [28] là nghiên cứu tiên phong của DST và khám phá một mô hình kết nối thưa tối ưu trong quá trình huấn luyện bằng cách
giới thiệu khởi tạo Erd˝os-Rényi (ER) và tăng trưởng ngẫu nhiên. Khởi tạo ER gán nhiều kết nối hơn cho
các lớp nhỏ hơn trong khi phân bổ ít kết nối hơn cho các lớp lớn trong Perceptron Đa Lớp (MLPs) với
ϵ(nl−1+nl)/(nl−1nl) trong đó nl biểu thị số lượng nơ-ron ở lớp l và ϵ chỉ ra mức độ thưa. Tăng trưởng
ngẫu nhiên kết nối ngẫu nhiên một số lượng bằng nhau các trọng số được bỏ dựa trên độ lớn của chúng để khám phá
một topo thưa mới. Lấy cảm hứng từ SET, RigL [31] và SNFS [32] đã giới thiệu tăng trưởng gradient và tăng trưởng momentum:
ý tưởng sử dụng thông tin gradient và momentum thu được bằng truyền ngược là để phát triển
các kết nối hứa hẹn làm tăng tốc quá trình khám phá topo thưa tối ưu. Mặc dù tăng trưởng gradient và
momentum tăng tốc quá trình khám phá topo thưa tối ưu, chúng đòi hỏi một truyền ngược dày đặc

--- TRANG 2 ---
để sử dụng thông tin của cả các kết nối hiện có và không tồn tại. Để cải thiện điều này, Top-KAST [33]
đã chọn sử dụng các gradient tương ứng với một tập con của các kết nối không tồn tại. Hơn nữa, [34,35]
nghiên cứu kỹ lưỡng về huấn luyện thưa thích ứng và các topo thưa, và phát hiện rằng hiệu suất của
mạng thưa có thể vượt trội so với các đối tác dày đặc.

DST cho Học Liên Tục. Công trình trước đó [36] đã chỉ ra rằng việc thu nhỏ và mở rộng dung lượng mô hình thích ứng
có hiệu quả tránh việc cắt tỉa quá mức, so với cắt tỉa lặp qua các nhiệm vụ tuần tự.
Do đó, Huấn Luyện Thưa Thích Ứng là một phương pháp Cô lập Tham số khả thi cho Học Liên Tục vì
nó có thể gán các thành phần cụ thể cho các nhiệm vụ khác nhau trong khi khám phá mạng với các topo khác nhau.
SpaceNet [23] và AFAF [24] chọn sử dụng DST theo cách có cấu trúc khám phá topo thưa tốt nhất
ở cấp độ nơ-ron trong khi NISPA [25], WSN [26] và SparCL [27] thực hiện nó theo cách không có cấu trúc
là tìm kiếm cấp độ kết nối. SpaceNet cho phép có các đơn vị chung hạn chế giữa các mạng con để
ngăn chặn sự can thiệp giữa các nhiệm vụ trong khi NISPA, WSN, và AFAF khai thác các đơn vị từ các mạng con trước đó
đầy đủ để sử dụng xương sống hiệu quả và cũng chuyển giao kiến thức có liên quan. NISPA chọn các
kết nối ứng viên ngẫu nhiên trong khi WSN chọn chúng dựa trên các gradient. Để cho phép CL thực tế trên thiết bị,
SparCL tích hợp tính thưa trọng số với loại bỏ dữ liệu và tính thưa gradient.

Tuy nhiên, trong các tình huống CL, không có nghiên cứu nào trong số đó đã khám phá rộng rãi tác động của
khởi tạo, chiến lược bỏ và tăng trưởng khác nhau có ảnh hưởng lớn đến topo mạng nơ-ron thưa cuối cùng và
hiệu suất.

3. Phương pháp
Trong phần này, chúng tôi đưa ra tổng quan về DST và ứng dụng của nó trong bối cảnh CL nơi mục tiêu là học
và giữ lại kiến thức từ một chuỗi các nhiệm vụ mà không quên thảm khốc. Chúng tôi trình bày
công thức cơ bản và các mục tiêu tối ưu hóa hướng dẫn việc khám phá các siêu tham số và lựa chọn thiết kế
trong khung này.

Tổng quan. Như được hiển thị trong Hình 1, DST Liên Tục bắt đầu với một mạng nơ-ron được tham số hóa quá mức trong đó
chúng tôi tìm kiếm các mạng con cụ thể cho nhiệm vụ và chỉ thay đổi các trọng số không được huấn luyện trên
các nhiệm vụ trước đó. Nói cách khác, chúng tôi đóng băng các tham số của mạng con đã chọn sau khi huấn luyện để ngăn chặn
quên thảm khốc nhưng chúng tôi cho phép sử dụng những tham số đóng băng đó trong các nhiệm vụ tiếp theo. Điều này hỗ trợ việc chuyển giao
kiến thức trước đó cho các nhiệm vụ tương lai, còn được gọi là chuyển tiếp tiến. Điều này đặc biệt quan trọng cho các vấn đề
học liên tục quy mô lớn vì nó giảm thời gian cần thiết để hội tụ trong quá trình học tuần tự.

DST Liên Tục. CL liên quan đến việc cập nhật một mạng nơ-ron với một chuỗi các nhiệm vụ học T1:t=
(T1,T2, ...,Tt), mỗi nhiệm vụ có một tập dữ liệu tương ứng DT= (xi,t, yi,t)nt bao gồm nt trường hợp cho mỗi nhiệm vụ.
Khi gặp một nhiệm vụ học mới, một mạng sâu được tối ưu hóa để ánh xạ trường hợp đầu vào đến
không gian phân loại, được ký hiệu là fΘ:Xt→ Y t, trong đó Θ đại diện cho các tham số của mạng. Lưu ý rằng, các
nhiệm vụ học loại trừ lẫn nhau, tức là Yt−1∩ Yt=∅ và chúng tôi giả định rằng danh tính nhiệm vụ được đưa ra trong cả
giai đoạn huấn luyện và thử nghiệm. Mục tiêu của DST Liên Tục là học hiệu quả mạng con bằng cách giải quyết
vấn đề tối ưu hóa giảm thiểu hàm sau:

--- TRANG 3 ---
Nhiệm vụ t Nhiệm vụ t+1 Nhiệm vụ t+1 Nhiệm vụ t+1(a) (b) (c) (d)Hình 1: Minh họa DST Liên Tục. (a) Các kết nối đã học cho Nhiệm vụ t, (b) trong truyền tiến của một
nhiệm vụ mới, mô hình tự do sử dụng tất cả các kết nối, (c) nhưng trong truyền ngược nó chỉ được phép cập nhật
các kết nối chưa được gán, (d) sau khi khám phá mạng thích ứng với các bước (b) và (c) dưới mức độ thưa
s%, các mạng con tiếp theo có thể bao gồm các kết nối mới và các kết nối đã học trước đó
được thu được.

M∗t= arg min Mt L(Θs, nt) = arg min Mt ∑nt i=1[CE(f(xi,t; Θs), yi,t)] (1)

Ở đây, L(Θs, nt) là hàm mất mát, là Cross-Entropy (CE) trong các thí nghiệm của chúng tôi, với một phần
tham số Θs được xác định trước, và bằng cách giải quyết vấn đề tối ưu hóa này, mặt nạ Mt được xác định. Lưu ý rằng,
mặc dù độ thưa cho mỗi nhiệm vụ được xác định trước, việc sử dụng tổng thể của xương sống phụ thuộc vào nhiệm vụ và có liên quan nhiều
đến việc các nhiệm vụ chia sẻ kiến thức đã học như thế nào. Do đó, độ thưa tổng thể trên xương sống tăng
tự nhiên nhưng độ thưa cho mỗi nhiệm vụ sẽ giống nhau cho mỗi nhiệm vụ.

Khởi tạo Thưa. Chúng tôi xem xét các chiến lược sau để khởi tạo thưa của mạng.
Đồng nhất: Độ thưa của mỗi lớp, được ký hiệu là s, tương đương với độ thưa mạng tổng thể, được đại diện bởi S.
Erd˝os-Rényi Kernel (ERK) [31]: Lấy cảm hứng từ khởi tạo Erd˝os-Rényi [28], ERK được công thức hóa là
ϵ(nl−1+nl+wl+hl)/(nl−1nlwlhl) trong đó ϵ chỉ ra mức độ thưa, nl biểu thị số lượng nơ-ron ở lớp l, wl
và hl là chiều rộng và chiều cao của kernel tích chập thứ l. Nó phân bổ độ thưa cao hơn cho các lớp
có nhiều tham số hơn và độ thưa thấp hơn cho các lớp có ít tham số hơn trong khi giữ tổng độ thưa
ở mức S. Độ thưa của các lớp kết nối đầy đủ tuân theo các quy tắc tương tự của Erd˝os-Rényi gốc.

Cập nhật Topo. Việc cập nhật topo nên cân bằng sự đánh đổi khám phá so với khai thác để có được
các topo thưa tốt hơn. Lịch trình cập nhật được xác định bởi các tham số sau: (1) ΔT, số lần lặp
giữa các cập nhật kết nối thưa (2) Tend, lần lặp mà các cập nhật kết nối thưa
nên được dừng (3) α, tỷ lệ ban đầu của các kết nối được cập nhật, và (4) fdecay, một hàm
được gọi mỗi lần lặp ΔT để giảm dần tỷ lệ các kết nối được cập nhật theo thời gian. Tương tự như
các nghiên cứu trước đó [25,31,32,34], chúng tôi sử dụng Cosine Annealing fdecay(t, α, Tend) =α/2(1 + cos(tπ/Tend)) cho
cập nhật topo.

Bỏ và Tăng trưởng. Chúng tôi xem xét các chiến lược bỏ và tăng trưởng sau để cập nhật topo.
Bỏ dựa trên độ lớn [37]: Nó liên quan đến việc xác định và loại bỏ các kết nối có độ lớn thấp nhất
hoặc 'tầm quan trọng' dựa trên mức độ thưa hoặc ngưỡng được xác định trước.
Tăng trưởng ngẫu nhiên [28]: Nó ngẫu nhiên thêm các kết nối mới vào mạng và không tính đến
bất kỳ thông tin cụ thể nào về hành vi hoặc hiệu suất của mạng.
Tăng trưởng chưa kích hoạt: Nó ngẫu nhiên thêm các kết nối mới chưa được sử dụng hoặc 'kích hoạt' trước đó.
Tăng trưởng gradient [31]: Nó liên quan đến việc thêm các kết nối mới dựa trên các giá trị gradient của các kết nối
trong quá trình huấn luyện. Các kết nối có gradient cao hơn hoặc những kết nối đóng góp nhiều hơn vào việc giảm lỗi của mạng
được xem xét để tăng trưởng.
Tăng trưởng momentum [32]: Nó xem xét cả gradient hiện tại và gradient tích lũy từ các
cập nhật trước đó làm mịn các cập nhật theo thời gian. Các kết nối có momentum cao hơn được xem xét để
tăng trưởng vì chúng hứa hẹn hơn để giảm lỗi của mạng.

Các kỹ thuật tăng trưởng gradient và momentum có thể tăng tốc việc tìm kiếm một mạng con tối ưu nhưng
chúng đòi hỏi một truyền ngược dày đặc kết hợp thông tin từ cả các kết nối hiện có và không tồn tại.

4. Thiết lập Thí nghiệm
Trong phần này, chúng tôi mô tả ngắn gọn thiết lập thí nghiệm của chúng tôi bao gồm các tập dữ liệu được sử dụng, các chỉ số được sử dụng
để đánh giá, và các chi tiết triển khai đảm bảo tính tái tạo và tính hợp lệ của kết quả của chúng tôi.

Tập dữ liệu. Trong bài báo này, chúng tôi muốn tạo ra các tình huống với số lượng nhiệm vụ khác nhau để xem tác động
của các chiến lược DST dưới các điều kiện khác nhau. Để đạt mục đích này, chúng tôi thí nghiệm với CIFAR100 [38] và
miniImageNet [39] bao gồm các đối tượng từ 100 danh mục khác nhau. Chúng tôi chia CIFAR100 thành 5, 10
và 20 nhiệm vụ riêng biệt với 20, 10 và 5 lớp trong mỗi nhiệm vụ học và đặt tên chúng là 5-nhiệm vụ CIFAR100,

--- TRANG 4 ---
10-nhiệm vụ CIFAR100, và 20-nhiệm vụ CIFAR100 tương ứng. Cuối cùng, cho một tình huống thách thức hơn, chúng tôi sử dụng
10-nhiệm vụ miniImageNet trong đó mô hình học 10 nhiệm vụ với 10 lớp trong mỗi bước tăng dần.

Chỉ số. Chúng tôi sử dụng các chỉ số CL nổi tiếng để đánh giá. Độ chính xác (ACC) [40] đo độ chính xác cuối cùng
trung bình trên tất cả các nhiệm vụ trong đó AT,i là độ chính xác của nhiệm vụ i sau khi học nhiệm vụ T. Chuyển tiếp ngược
(BWT) [40] đo mức độ quên và thay đổi độ chính xác trung bình của mỗi nhiệm vụ sau khi học
các nhiệm vụ mới trong đó Ai,i là độ chính xác của nhiệm vụ i ngay sau khi học nhiệm vụ i. Chuyển tiếp tiến (FWT), lấy cảm hứng
từ [40], đo mức độ chuyển giao trong đó Aj,i là độ chính xác của mạng con đã học trên nhiệm vụ i thực hiện
trên nhiệm vụ j, đánh giá mô hình hoạt động tốt như thế nào trên các nhiệm vụ tiếp theo khác với các nhiệm vụ nó
được huấn luyện.

ACC = 1/T ∑T i=1 AT,i (2)
BWT = 1/(T−1) ∑T−1 i=1 (AT,i−Ai,i) (3)
FWT = 1/(T−i) ∑T i=1 ∑T j=i+1 Aj,i (4)

Chi tiết Triển khai. Chúng tôi triển khai tất cả các phương pháp trong PyTorch [41]. Chúng tôi sử dụng ResNet-18 [42], VGG-
like [43], và MobileNetV2 [44] làm xương sống cho tất cả các tập dữ liệu. Để biết kết quả VGG-like và MobileNetV2,
vui lòng tham khảo Phụ lục. Chúng tôi chọn không đóng băng chuẩn hóa theo lô trong quá trình huấn luyện vì chúng
không thể được gán làm các thành phần cụ thể cho nhiệm vụ. Chúng tôi đã xây dựng trên thư viện ITOP [34] được phát triển
cho học theo lô tiêu chuẩn. Chúng tôi sử dụng Cosine Annealing cho tỷ lệ bỏ bắt đầu từ 0.5. Chúng tôi cập nhật
topo thưa sau mỗi 50, 100, 200, và 400 lần lặp. Chúng tôi đặt số epoch thành 25 cho 20-nhiệm vụ CIFAR100
trong khi 100 cho 5-nhiệm vụ CIFAR100, 10-nhiệm vụ CIFAR100 và 10-nhiệm vụ miniImageNet. Chúng tôi sử dụng optimizer adam và
đặt tỷ lệ học ban đầu là 0.001 được giảm bởi hệ số 0.1 sau 1/2 và 3/4 tổng số
epoch. Chúng tôi đặt kích thước lô là 128. Chúng tôi chạy thí nghiệm trên ba seed khác nhau và báo cáo trung bình của chúng.

5. Kết quả
Trong phần này, chúng tôi trình bày phân tích thực nghiệm để điều tra tác động của các thành phần DST khác nhau trong
mô hình CL để hiểu cơ chế cơ bản và làm sáng tỏ cấu hình DST tối ưu cho CL. Chúng tôi
nghiên cứu trên bốn tình huống riêng biệt với các bước tăng dần khác nhau và tập dữ liệu là 5-nhiệm vụ CIFAR100, 10-
nhiệm vụ CIFAR100, 20-nhiệm vụ CIFAR100, và 10-nhiệm vụ miniImageNet để quan sát tác động của khởi tạo, tăng trưởng,
và lựa chọn thích ứng của nó giữa các nhiệm vụ. Chúng tôi cũng nghiên cứu tần suất cập nhật topo trong Phụ lục.

5.1. Các chiến lược khởi tạo khác nhau đòi hỏi các mức độ thưa khác nhau.
Kết hợp với các kỹ thuật tăng trưởng và mức độ thưa khác nhau, chiến lược khởi tạo ảnh hưởng đáng kể đến
độ chính xác tăng dần, đặc biệt là khi số lượng nhiệm vụ tăng và các nhiệm vụ trở nên phức tạp hơn
như 10-Nhiệm vụ miniImageNet, 10-Nhiệm vụ CIFAR100 và, 20-Nhiệm vụ CIFAR100. Ở mức độ thưa cao
trừ khi nó cực đoan (xem Phụ lục), chúng tôi phát hiện rằng khởi tạo đồng nhất hoạt động ổn định hơn dưới
các chiến lược tăng trưởng khác nhau so với ERK. Mặc dù các nghiên cứu cô lập tham số hiện có trong học liên tục
[25,26] chủ yếu sử dụng khởi tạo đồng nhất, phù hợp với phát hiện đầu tiên của chúng tôi, chúng tôi cũng
thú vị phát hiện rằng khởi tạo ERK thể hiện hiệu suất tổng thể tốt dưới mức độ thưa thấp đến vừa phải
(Hình 2, 3, 4, 5). Cụ thể, khởi tạo đồng nhất bão hòa sau 7 nhiệm vụ, trong khi khởi tạo ERK
hoàn thành thành công tất cả 10 nhiệm vụ (Hình 3a, 3d và Hình 4a, 4d). Hiện tượng tương tự cũng được quan sát
với 20-Nhiệm vụ CIFAR100 nơi khởi tạo đồng nhất bão hòa sau 7 nhiệm vụ một lần nữa, trong khi khởi tạo ERK
đạt sự bão hòa này sau 13 nhiệm vụ cho thấy 85% sử dụng xương sống hiệu quả (Hình 2a, 2d).

--- TRANG 5 ---
(a) đồng nhất 80% thưa.
1 10 20
Nhiệm vụ315885 Độ chính xác Top-1(%)
 (b) đồng nhất 90% thưa.
1 10 20
Nhiệm vụ315885 Độ chính xác Top-1(%)
 (c) đồng nhất 95% thưa.
1 10 20
Nhiệm vụ315885 Độ chính xác Top-1(%)
1 10 20
Nhiệm vụ315885 Độ chính xác Top-1(%)
(d) ERK 80% thưa.
1 10 20
Nhiệm vụ315885 Độ chính xác Top-1(%)
 (e) ERK 90% thưa.
1 10 20
Nhiệm vụ315885 Độ chính xác Top-1(%)
ngẫu nhiên
chưa kích hoạt
gradient
momentum (f) ERK 95% thưa.

Hình 2: Độ chính xác Top-1 (%) của 20-Nhiệm vụ CIFAR100 với các chiến lược DST khác nhau. Ở độ thưa thấp đến vừa phải,
ERK sử dụng xương sống hiệu quả hơn bằng cách sử dụng các kết nối trong các lớp hẹp một cách tiết kiệm
cho phép học các gia tăng nhiệm vụ dài hơn một cách hiệu quả và cải thiện hiệu suất tăng dần: Đồng nhất
bão hòa sau 7 nhiệm vụ khi mức độ thưa cho mỗi nhiệm vụ là 80%. ERK đạt sự bão hòa này sau 13 nhiệm vụ. Ở
độ thưa cao, tuy nhiên, đồng nhất cho thấy hiệu suất đáng tin cậy và mạnh mẽ hơn.

Bảng 1: Điểm ACC (%), BWT (%), và FWT (%) Top-1 của 20-Nhiệm vụ CIFAR100.
[Bảng được duy trì với các giá trị số gốc]

Lý do đằng sau điều này là thực tế rằng khởi tạo đồng nhất tạo ra một nút thắt cổ chai trong các lớp hẹp. Chúng ta
biết rằng khởi tạo đồng nhất gán kết nối bằng nhau cho mỗi lớp mà không xem xét kích thước lớp
và ERK phân bổ nhiều kết nối hơn cho các lớp có nhiều tham số hơn và ít kết nối hơn cho các lớp
có ít tham số hơn [28,31]. Sau một số lượng nhiệm vụ nhất định, khả năng của xương sống để duy trì
quá trình học bị tổn hại vì luồng thông tin qua xương sống bị giảm đáng kể cho
các nhiệm vụ tiếp theo. Những phát hiện của chúng tôi cung cấp hỗ trợ thực nghiệm cho mối quan hệ giữa độ thưa và luồng thông tin
trong thiết lập CL: Cụ thể, trong các tình huống mà mức độ thưa cao, chúng tôi quan sát rằng luồng thông tin
vẫn bền vững ngay cả với khởi tạo đồng nhất. Điều này cho thấy rằng mạng giữ lại đủ
kết nối để có hiệu quả đáp ứng các nhiệm vụ mới. Tuy nhiên, khi độ thưa giảm, cho thấy mật độ kết nối
được gán cho mỗi nhiệm vụ cao hơn, chúng tôi quan sát một thách thức đáng chú ý trong việc học các nhiệm vụ tương lai khi
xương sống được khởi tạo đồng nhất. Do đó, dưới các điều kiện tương tự, khởi tạo ERK tốt hơn trong việc
bảo vệ luồng thông tin bằng cách sử dụng các kết nối trong các lớp hẹp một cách tiết kiệm (xem thêm Phụ lục).

Lưu ý rằng lý do có những điểm BWT (%) nhỏ này là đóng băng tất cả các kết nối trừ chuẩn hóa theo lô
như chúng tôi đã nêu và thảo luận trong Chi tiết Triển khai.

5.2. Chiến lược tăng trưởng ảnh hưởng đến hiệu suất, gắn liền với khởi tạo và mức độ thưa.
Kết quả thí nghiệm của chúng tôi chỉ ra rằng khi mức độ thưa thấp, khởi tạo ERK với tăng trưởng ngẫu nhiên và
chưa kích hoạt vượt trội so với các lựa chọn khác (Bảng 1, 2, 3, 4). Trong khi mức độ thưa vừa phải, khởi tạo ERK
và đồng nhất đạt hiệu suất tương tự nơi khởi tạo đồng nhất kết hợp với tăng trưởng gradient (đồng nhất+gradient)
có xu hướng cho thấy hiệu suất tốt hơn một chút (Bảng 2, 3). Trong trường hợp độ thưa cao,
phương pháp phổ biến đồng nhất+gradient [26] đạt hiệu suất đáng chú ý trong khi kết hợp ERK+gradient
cũng thể hiện kết quả cạnh tranh (Bảng 2, 3, 4). Tuy nhiên, ở mức độ thưa cao, ERK+ngẫu nhiên và ERK+chưa kích hoạt
thể hiện hiệu suất độ chính xác thấp hơn (Bảng 1, 2, 3, 4). Chúng tôi cũng quan sát rằng
khởi tạo đồng nhất có khả năng phục hồi hơn đối với việc lựa chọn chiến lược tăng trưởng so với khởi tạo ERK
(Hình 2, 3, 4, 5).

Nhìn chung, đối với các chiến lược tăng trưởng trong DST, tăng trưởng dựa trên gradient và momentum cung cấp hiệu suất tốt hơn
so với tăng trưởng ngẫu nhiên và chưa kích hoạt trong trường hợp độ thưa cao nhưng tăng trưởng ngẫu nhiên và chưa kích hoạt hoạt động
cũng tốt như tăng trưởng dựa trên gradient và momentum ở độ thưa thấp-vừa phải. Lý do đằng sau điều này là
các phương pháp dựa trên gradient và momentum có thể kết hợp nhiều thông tin hơn và có thể chọn lọc thêm các kết nối mới
giữa các nơ-ron cho phép khám phá nhanh hơn so với tăng trưởng ngẫu nhiên hoặc chưa kích hoạt cần
nhiều thời gian hơn để khám phá và tìm các kết nối tốt hơn.

--- TRANG 6 ---
(a) đồng nhất 80% thưa.
12345678910
Nhiệm vụ405876 Độ chính xác Top-1(%)
 (b) đồng nhất 90% thưa.
12345678910
Nhiệm vụ405876 Độ chính xác Top-1(%)
 (c) đồng nhất 95% thưa.
12345678910
Nhiệm vụ405876 Độ chính xác Top-1(%)
ngẫu nhiên
chưa kích hoạt
gradient
momentum
12345678910
Nhiệm vụ405876 Độ chính xác Top-1(%)
(d) ERK 80% thưa.
12345678910
Nhiệm vụ405876 Độ chính xác Top-1(%)
 (e) ERK 90% thưa.
12345678910
Nhiệm vụ405876 Độ chính xác Top-1(%)
 (f) ERK 95% thưa.

Hình 3: Độ chính xác Top-1 (%) của 10-Nhiệm vụ miniImageNet với các tiêu chí DST khác nhau. ERK hoạt động tốt hơn ở độ thưa thấp:
Đồng nhất bão hòa sau 7 nhiệm vụ trong khi ERK hoàn thành tất cả các nhiệm vụ. Ở độ thưa vừa phải, tất cả các phương pháp DST
thể hiện hiệu suất có thể so sánh cao. Ở mức độ thưa cao hơn, đồng nhất nổi lên như một phương pháp vững chắc
để làm việc với các sự tăng trưởng khác nhau nhưng đáng chú ý rằng ERK có thể thực hiện gần như giống hệt nếu chọn đúng sự tăng trưởng.

Bảng 2: Điểm ACC (%), BWT (%), và FWT (%) Top-1 của 10-Nhiệm vụ miniImageNet.
[Bảng được duy trì với các giá trị số gốc]

Bảng 3: Điểm ACC (%), BWT (%), và FWT (%) Top-1 của 10-Nhiệm vụ CIFAR100.
[Bảng được duy trì với các giá trị số gốc]

--- TRANG 7 ---
(a) đồng nhất 80% thưa.
12345678910
Nhiệm vụ556984 Độ chính xác Top-1(%)
ngẫu nhiên
chưa kích hoạt
gradient
momentum (b) đồng nhất 90% thưa.
12345678910
Nhiệm vụ556984 Độ chính xác Top-1(%)
 (c) đồng nhất 95% thưa.
12345678910
Nhiệm vụ556984 Độ chính xác Top-1(%)
12345678910
Nhiệm vụ556984 Độ chính xác Top-1(%)
(d) ERK 80% thưa.
12345678910
Nhiệm vụ556984 Độ chính xác Top-1(%)
 (e) ERK 90% thưa.
12345678910
Nhiệm vụ556984 Độ chính xác Top-1(%)
 (f) ERK 95% thưa.

Hình 4: Độ chính xác Top-1 (%) của 10-Nhiệm vụ CIFAR100 với các tiêu chí DST khác nhau. Những phát hiện phù hợp với
10-Nhiệm vụ miniImageNet. Ở độ thưa cao, đồng nhất xuất hiện như một chiến lược đáng tin cậy hơn đối với
các sự tăng trưởng khác nhau nhưng ERK có thể thực hiện gần như giống hệt nếu chọn đúng sự tăng trưởng.

Bảng 4: Điểm ACC (%), BWT (%), và FWT (%) Top-1 của 5-Nhiệm vụ CIFAR100.
[Bảng được duy trì với các giá trị số gốc]

(a) đồng nhất 80% thưa.
1 2 3 4 5
Nhiệm vụ606876 Độ chính xác Top-1(%)
ngẫu nhiên
chưa kích hoạt
gradient
momentum (b) đồng nhất 90% thưa.
1 2 3 4 5
Nhiệm vụ606876 Độ chính xác Top-1(%)
 (c) đồng nhất 95% thưa.
1 2 3 4 5
Nhiệm vụ606876 Độ chính xác Top-1(%)
1 2 3 4 5
Nhiệm vụ606876 Độ chính xác Top-1(%)
(d) ERK 80% thưa.
1 2 3 4 5
Nhiệm vụ606876 Độ chính xác Top-1(%)
 (e) ERK 90% thưa.
1 2 3 4 5
Nhiệm vụ606876 Độ chính xác Top-1(%)
 (f) ERK 95% thưa.

Hình 5: Độ chính xác Top-1 (%) của 5-Nhiệm vụ CIFAR100 với các chiến lược DST khác nhau. Thú vị, những phát hiện phù hợp với
20-Nhiệm vụ CIFAR100: ERK cải thiện độ chính xác tăng dần ở độ thưa thấp đến vừa phải. Mặt khác, ở
độ thưa cao, đồng nhất xuất hiện như một chiến lược đáng tin cậy hơn nhưng ERK có thể thực hiện gần như giống hệt nếu chọn đúng sự tăng trưởng.

--- TRANG 8 ---
5.3. Tính thích ứng cải thiện hiệu suất vì không có giải pháp vạn năng.
Trong suốt các thí nghiệm của chúng tôi, chúng tôi đã quan sát rằng không có phương pháp thành công phổ biến về
số lượng nhiệm vụ và mức độ thưa khác nhau. Khi số lượng nhiệm vụ cao, việc lựa chọn cả chiến lược khởi tạo
và tăng trưởng trở nên quan trọng, phụ thuộc vào mức độ thưa. Không chắc sẽ tồn tại một thiết lập DST vạn năng
cho tất cả các tập dữ liệu hoặc nhiệm vụ, và không khả thi khi thử các lựa chọn khác nhau cho mỗi tình huống do
chi phí tính toán và thời gian. Do đó, chúng tôi đặt giả thuyết rằng một phương pháp thích ứng để lựa chọn tiêu chí DST
cho mỗi nhiệm vụ nên cải thiện hiệu suất.

12345678910
Nhiệm vụ727884 Độ chính xác Top-1(%)
ngẫu nhiên
gradient
thích ứng

Hình 6: Chiến lược tăng trưởng thích ứng trên tình huống 10-nhiệm vụ CIFAR100. Phương pháp thích ứng vượt trội so với chiến lược cố định.

Trong thí nghiệm cuối cùng của chúng tôi, chúng tôi xây dựng một chiến lược tăng trưởng thích ứng ngây thơ với
khởi tạo ERK để xác thực giả thuyết của chúng tôi, trong đó tăng trưởng ngẫu nhiên được
triển khai cho năm nhiệm vụ đầu tiên, và tăng trưởng gradient được chọn cho
năm nhiệm vụ tiếp theo trong khi độ thưa cho mỗi nhiệm vụ là 90% trên
tập dữ liệu 10-nhiệm vụ CIFAR100. Phương pháp thích ứng mang lại hiệu suất tốt hơn khi
so sánh với hai đường cơ sở là các chiến lược tăng trưởng được chọn trước và cố định
của ngẫu nhiên và gradient với khởi tạo ERK (Hình 6). Điều này là do
trong giai đoạn ban đầu của việc học, tồn tại tiềm năng đáng kể
để khám phá các tham số mô hình. Do đó, một chiến lược tăng trưởng ngẫu nhiên có xu hướng
hiệu quả và có hiệu lực hơn khi không gian khám phá đủ lớn. Tuy nhiên, khi dung lượng mô hình
trở nên bão hòa hơn, chiến lược tăng trưởng gradient trở nên ngày càng hiệu quả
và vượt trội so với tăng trưởng ngẫu nhiên dẫn đến hiệu suất tổng thể tốt hơn.

6. Thảo luận
Kết luận. Bài báo này đã trình bày một phân tích toàn diện, nhằm đánh giá các thành phần khác nhau của
Huấn Luyện Thưa Thích Ứng trong Học Liên Tục. Chúng tôi tập trung vào chiến lược Cô lập Tham số để tìm
mạng con tốt nhất cho mỗi nhiệm vụ dưới các điều kiện khác nhau ảnh hưởng lớn đến các topo cuối cùng. Thông qua các thí nghiệm quy mô lớn,
chúng tôi phát hiện rằng lựa chọn mức độ thưa, khởi tạo, và chiến lược tăng trưởng ảnh hưởng đáng kể đến
hiệu suất tăng dần. Trong những phát hiện của chúng tôi, khi độ thưa thấp, khởi tạo Erd˝os-Rényi Kernel (ERK)
khai thác xương sống hiệu quả, cho phép học liên tục. Tuy nhiên, trừ khi độ thưa cực đoan,
khởi tạo đồng nhất thể hiện hiệu suất nhất quán và ổn định hơn ở mức độ thưa cao hơn.
Hiệu suất của chiến lược tăng trưởng dựa vào phương pháp khởi tạo được chọn và mức độ thưa. Như một
quan sát cuối cùng, ngay cả việc lựa chọn thích ứng ngây thơ cho tiêu chí DST cho mỗi nhiệm vụ cải thiện hiệu suất tăng dần
so với việc sử dụng các chiến lược cố định và được xác định trước cho tất cả các nhiệm vụ. Chúng tôi hy vọng các kết quả thực nghiệm
được tìm thấy trong nghiên cứu này truyền cảm hứng cho cộng đồng đưa ra quyết định sáng suốt về
khả năng áp dụng của các chiến lược này trong các tình huống thực tế và mở đường cho các nghiên cứu tương lai trong lĩnh vực này.

Hạn chế và Công việc Tương lai. Để mở rộng phạm vi của nghiên cứu này, huấn luyện thưa thích ứng có cấu trúc cũng nên
được phân tích để nắm bắt cơ chế cơ bản của huấn luyện thưa thích ứng một cách toàn diện trong
học liên tục. Cuối cùng, những cải thiện hiệu suất được quan sát trong học tăng dần là đáng kể với một phương pháp
thích ứng đơn giản. Do đó, điều tra sâu hơn về các chiến lược DST thích ứng tinh vi hơn hứa hẹn
một hướng nghiên cứu rất đầy hứa hẹn.

Lời cảm ơn
Công trình này được hỗ trợ bởi; TAILOR, một dự án được tài trợ bởi chương trình nghiên cứu và đổi mới EU Horizon 2020
dưới GA No. 952215, cơ sở hạ tầng điện tử quốc gia Hà Lan với sự hỗ trợ của SURF Cooperative sử dụng grant no.
EINF-4568, và học bổng MoNE Thổ Nhĩ Kỳ.

Tài liệu tham khảo
[1] James Kirkpatrick et al. Overcoming catastrophic forgetting in neural networks. PNAS, 2017.
[2] Zhizhong Li and Derek Hoiem. Learning without forgetting. TPAMI, 2017.

--- TRANG 9 ---
[3] Friedemann Zenke, Ben Poole, và Surya Ganguli. Continual learning through synaptic intelligence. Trong
ICML, 2017.
[4] Saihui Hou, Xinyu Pan, Chen Change Loy, Zilei Wang, và Dahua Lin. Lifelong learning via progressive
distillation and retrospection. Trong ECCV, 2018.
[5] Minsoo Kang, Jaeyoo Park, và Bohyung Han. Class-incremental learning by knowledge distillation
with adaptive feature consolidation. Trong CVPR, 2022.
[6] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, và Christoph H Lampert. icarl: Incremental classifier and representation learning. Trong CVPR, 2017.
[7] David Lopez-Paz và Marc'Aurelio Ranzato. Gradient episodic memory for continual learning. Trong
NeurIPS, 2017.
[8] Yaoyao Liu, Qianru Sun, và Qianru Sun. Rmm: Reinforced memory management for class-incremental
learning. Trong NeurIPS, 2021.
[9] Decebal Constantin Mocanu, Maria Torres Vega, et al. Online contrastive divergence with generative
replay: Experience replay without storing data. arXiv preprint arXiv:1610.05555, 2016.
[10] Hanul Shin, Jung Kwon Lee, Jaehong Kim, và Jiwon Kim. Continual learning with deep generative
replay. Trong NeurIPS, 2017.
[11] Wenpeng Hu, Zhou Lin, Bing Liu, Chongyang Tao, Zhengwei Tao Tao, Dongyan Zhao, Jinwen Ma, và
Rui Yan. Overcoming catastrophic forgetting for continual learning via model adaptation. Trong ICLR, 2019.
[12] Chen He, Ruiping Wang, Shiguang Shan, và Xilin Chen. Exemplar-supported generative reproduction
for class incremental learning. Trong BMVC, 2018.
[13] Shipeng Yan, Jiangwei Xie, và Xuming He. der: Dynamically expandable representation for class
incremental learning. Trong CVPR, 2021.
[14] Fu-Yun Wang, Da-Wei Zhou, Han-Jia Ye, và De-Chuan Zhan. Foster: Feature boosting and compression
for class-incremental learning. Trong ECCV, 2022.
[15] Da-Wei Zhou, Qi-Wei Wang, Han-Jia Ye, và De-Chuan Zhan. A model or 603 exemplars: Towards
memory-efficient class-incremental learning. Trong ICLR, 2023.
[16] Quang Pham, Chenghao Liu, và Steven Hoi. Dualnet: Continual learning, fast and slow. Trong NeurIPS,
2021.
[17] Rahaf Aljundi, Punarjay Chakravarty, và Tinne Tuytelaars. Expert gate: Lifelong learning with a
network of experts. Trong CVPR, 2017.
[18] Mitchell Wortsman, Vivek Ramanujan, Rosanne Liu, Aniruddha Kembhavi, Mohammad Rastegari, Jason
Yosinski, và Ali Farhadi. Supermasks in superposition. Trong NeurIPS, 2020.
[19] Arun Mallya, Dillon Davis, và Svetlana Lazebnik. Piggyback: Adapting a single network to multiple
tasks by learning to mask weights. Trong ECCV, 2018.
[20] Siavash Golkar, Michael Kagan, và Kyunghyun Cho. Continual learning via neural pruning. Trong NeurIPS,
2019.
[21] Aleksandr Dekhovich, David MJ Tax, Marcel HF Sluiter, và Miguel A Bessa. Continual prune-and-
select: class-incremental learning with specialized subnetworks. Applied Intelligence, 2023.
[22] Arun Mallya và Svetlana Lazebnik. Packnet: Adding multiple tasks to a single network by iterative
pruning. Trong CVPR, 2018.
[23] Ghada Sokar, Decebal Constantin Mocanu, và Mykola Pechenizkiy. Spacenet: Make free space for
continual learning. Neurocomputing, 2021.

--- TRANG 10 ---
[24] Ghada Sokar, Decebal Constantin Mocanu, và Mykola Pechenizkiy. Avoiding forgetting and allowing
forward transfer in continual learning via sparse networks. Trong ECML PKDD. Springer, 2023.
[25] Mustafa Burak Gurbuz và Constantine Dovrolis. Nispa: Neuro-inspired stability-plasticity adaptation
for continual learning in sparse networks. Trong ICML, 2022.
[26] Haeyong Kang, Rusty John Lloyd Mina, et al. Forget-free continual learning with winning subnetworks.
Trong ICML, 2022.
[27] Zifeng Wang, Zheng Zhan, Yifan Gong, Geng Yuan, Wei Niu, Tong Jian, Bin Ren, Stratis Ioannidis,
Yanzhi Wang, và Jennifer Dy. Sparcl: Sparse continual learning on the edge. Trong NeurIPS, 2022.
[28] Decebal Constantin Mocanu, Elena Mocanu, et al. Scalable training of artificial neural networks with
adaptive sparse connectivity inspired by network science. Nature communications, 2018.
[29] Shiwei Liu và Zhangyang Wang. Ten lessons we have learned in the new "sparseland": A short
handbook for sparse neural network researchers. arXiv preprint arXiv:2302.02596, 2023.
[30] Torsten Hoefler, Dan Alistarh, Tal Ben-Nun, Nikoli Dryden, và Alexandra Peste. Sparsity in deep
learning: Pruning and growth for efficient inference and training in neural networks. JMLR, 2021.
[31] Utku Evci, Trevor Gale, Jacob Menick, Pablo Samuel Castro, và Erich Elsen. Rigging the lottery:
Making all tickets winners. Trong ICML, 2020.
[32] Tim Dettmers và Luke Zettlemoyer. Sparse networks from scratch: Faster training without losing
performance. arXiv preprint arXiv:1907.04840, 2019.
[33] Siddhant Jayakumar, Razvan Pascanu, Jack Rae, Simon Osindero, và Erich Elsen. Top-kast: Top-k
always sparse training. Trong NeurIPS, 2020.
[34] Shiwei Liu, Lu Yin, Decebal Constantin Mocanu, và Mykola Pechenizkiy. Do we actually need dense
over-parameterization? in-time over-parameterization in sparse training. Trong ICML, 2021.
[35] Shiwei Liu, Tim Van der Lee, et al. Topological insights into sparse neural networks. Trong ECML PKDD,
2021.
[36] Tianlong Chen, Zhenyu Zhang, Sijia Liu, Shiyu Chang, và Zhangyang Wang. Long live the lottery: The
existence of winning tickets in lifelong learning. Trong ICLR, 2021.
[37] Yann LeCun, John Denker, và Sara Solla. Optimal brain damage. Trong NeurIPS, 1989.
[38] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.
[39] Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Koray Kavukcuoglu, và Daan Wierstra. Matching
networks for one shot learning. Trong NeurIPS, 2016.
[40] Natalia Díaz-Rodríguez, Vincenzo Lomonaco, David Filliat, và Davide Maltoni. Don't forget, there is
more than forgetting: new metrics for continual learning. arXiv preprint arXiv:1810.13166, 2018.
[41] Adam Paszke, Sam Gross, Francisco Massa, et al. Pytorch: An imperative style, high-performance deep
learning library. Trong NeurIPS. 2019.
[42] Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun. Deep residual learning for image recognition.
Trong CVPR, 2016.
[43] Karen Simonyan và Andrew Zisserman. Very deep convolutional networks for large-scale image
recognition. ICLR, 2015.
[44] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, và Liang-Chieh Chen. Mobilenetv2: Inverted residuals and linear bottlenecks. Trong CVPR, 2018.

--- TRANG 11 ---
Phụ lục
Trong phụ lục này, chúng tôi cung cấp những hiểu biết bổ sung về tác động của các tần suất cập nhật topo khác nhau, mức độ thưa,
và các mô hình trong bối cảnh học liên tục với huấn luyện thưa thích ứng.

Tần suất Cập nhật. Khi mức độ thưa thấp hơn, tần suất cập nhật topo 400 lần lặp
thể hiện hiệu suất tối ưu. Điều này cho thấy rằng với nhiều kết nối hơn, việc cập nhật topo mạng
ít thường xuyên hơn có lợi hơn. Ngược lại, khi độ thưa cao hơn, khoảng 90-95%, một
khoảng thời gian cập nhật topo thường xuyên hơn là 100-200 lần lặp có vẻ có lợi hơn (Hình A). Quan sát này có thể
được quy cho nhu cầu khám phá tăng lên trong các mạng kết nối dày đặc. Các cập nhật thường xuyên hơn cho phép
mô hình thích ứng và khám phá các kết nối mới hiệu quả hơn để đáp ứng phân phối dữ liệu thay đổi. Những phát hiện này nhấn mạnh
tầm quan trọng của việc thích ứng các chiến lược cập nhật topo dựa trên
mức độ thưa trong quá trình học liên tục, mang lại các con đường tiềm năng để tối ưu hóa và hiệu quả thêm trong
các phương pháp huấn luyện thưa thích ứng.

(a) đồng nhất 80% thưa.
12345678910
Nhiệm vụ557085 Độ chính xác Top-1(%)
T=400
T=200
T=100
T=50
 (b) đồng nhất 90% thưa.
12345678910
Nhiệm vụ737781 Độ chính xác Top-1(%)
 (c) đồng nhất 95% thưa.
12345678910
Nhiệm vụ727578 Độ chính xác Top-1(%)
12345678910
Nhiệm vụ747983 Độ chính xác Top-1(%)
(d) ERK 80% thưa.
12345678910
Nhiệm vụ757983 Độ chính xác Top-1(%)
 (e) ERK 90% thưa.
12345678910
Nhiệm vụ657382 Độ chính xác Top-1(%)
 (f) ERK 95% thưa.

Hình A: Độ chính xác Top-1 (%) của 10-Nhiệm vụ CIFAR100 với các khởi tạo khác nhau và tần suất cập nhật topo
khi chiến lược tăng trưởng được chọn là ngẫu nhiên; sử dụng ResNet-18. Lưu ý rằng thang đo y khác nhau cho mỗi biểu đồ để
thể hiện sự khác biệt rõ ràng.

Mức độ Thưa. Những phát hiện của chúng tôi chỉ ra sự vượt trội của khởi tạo ERK ở các mức độ thưa thấp đến vừa phải,
trong khi khởi tạo đồng nhất có vẻ hiệu quả hơn ở các thiết lập độ thưa cao hơn. Sau khi tiến hành
các thí nghiệm bổ sung với mức độ thưa 70% và 85%, chúng tôi nhắc lại rằng khởi tạo ERK luôn
vượt trội so với khởi tạo đồng nhất. Tuy nhiên, đáng chú ý rằng khi chúng tôi mở rộng phân tích của mình đến
mức độ thưa cực đoan 99% nơi mạng hoạt động dưới các điều kiện bị hạn chế đáng kể, khởi tạo ERK
một lần nữa chứng tỏ là lựa chọn phù hợp hơn. Đó là bởi vì hạn chế của khởi tạo đồng nhất trở nên
rõ ràng trong học liên tục khi độ thưa đạt đến mức cực đoan. Hạn chế này cản trở khả năng của mô hình
khám phá hiệu quả nhiều mạng con, điều này, đến lượt nó, làm giảm khả năng của nó để liên tục đại diện
các hàm phức tạp. Gốc rễ của vấn đề này nằm ở phương pháp của khởi tạo đồng nhất trong việc phân phối kết nối
đồng nhất qua các lớp. Điều này dẫn đến luồng thông tin bị giảm quá mức, ngăn chặn mô hình liên tục đại diện
các hàm phức tạp. Do đó, khởi tạo đồng nhất chỉ có thể tạo ra một
mạng con thành thạo duy nhất, trong khi cản trở luồng thông tin và khả năng thích ứng của xương sống chính cho
các yêu cầu phát triển của các nhiệm vụ tuần tự. Mặt khác, bằng cách phân bổ độ thưa cao hơn cho các lớp có
nhiều tham số hơn và độ thưa thấp hơn cho các lớp có ít tham số hơn, ERK cho phép tạo ra các mạng con
hiệu quả cho phép tính liên tục của luồng thông tin qua các nhiệm vụ liên tiếp. Điều này nhấn mạnh nhu cầu
quan trọng về khả năng thích ứng trong việc chọn phương pháp khởi tạo đúng, đặc biệt khi xử lý các yêu cầu độ thưa
khác nhau, để đảm bảo thành công của các hệ thống học liên tục.

--- TRANG 12 ---
(a) đồng nhất 70% thưa.
12345678910
Nhiệm vụ416385 Độ chính xác Top-1(%)
ngẫu nhiên
chưa kích hoạt
gradient
momentum (b) đồng nhất 85% thưa.
12345678910
Nhiệm vụ416385 Độ chính xác Top-1(%)
 (c) đồng nhất 99% thưa.
12345678910
Nhiệm vụ64185 Độ chính xác Top-1(%)
12345678910
Nhiệm vụ416385 Độ chính xác Top-1(%)
(d) ERK 70% thưa.
12345678910
Nhiệm vụ416385 Độ chính xác Top-1(%)
 (e) ERK 85% thưa.
12345678910
Nhiệm vụ416385 Độ chính xác Top-1(%)
 (f) ERK 99% thưa.

Hình B: Độ chính xác Top-1 (%) của 10-Nhiệm vụ CIFAR100 với khởi tạo, tăng trưởng, và mức độ thưa khác nhau; sử dụng
ResNet-18. Trong trường hợp độ thưa cực đoan, một sự sụt giảm đáng kể xảy ra với khởi tạo đồng nhất.

Các Mô hình Khác nhau. Kết quả thí nghiệm bổ sung, sử dụng các kiến trúc MobileNetV2 và VGG-like, được
trình bày trong Hình C và D. Đối với MobileNetV2, một mạng nhỏ gọn nổi tiếng về hiệu quả, chúng tôi khám phá
các mức độ thưa 70%, 80%, và 90%. Các quan sát của chúng tôi làm nổi bật tính hiệu quả nhất quán của cả khởi tạo đồng nhất
và ERK khi mức độ thưa là 70% và 80%. Ở độ thưa 90%, là cực đoan cho
MobileNetV2, chúng tôi tìm thấy những phát hiện song song với các thí nghiệm trước đó của chúng tôi: Khởi tạo đồng nhất gặp phải
một thách thức quen thuộc; nó thể hiện khả năng học hạn chế cho nhiệm vụ đầu tiên trong khi ảnh hưởng tiêu cực đến
luồng thông tin và khả năng thích ứng với nhu cầu của các nhiệm vụ tuần tự.

Đối với kiến trúc VGG-like, chúng tôi khám phá các mức độ thưa 80%, 90%, và 95%. Tất cả các khởi tạo được thực hiện
tốt vì mạng VGG-like đủ lớn để bảo vệ luồng thông tin trong khi học nhiều hơn một
nhiệm vụ tuần tự. Tuy nhiên, hiệu suất tăng dần phụ thuộc vào chiến lược tăng trưởng ở tất cả các mức độ thưa.

(a) đồng nhất 70% thưa.
12345678910
Nhiệm vụ33771 Độ chính xác Top-1(%)
 (b) đồng nhất 80% thưa.
12345678910
Nhiệm vụ33771 Độ chính xác Top-1(%)
 (c) đồng nhất 90% thưa.
12345678910
Nhiệm vụ33771 Độ chính xác Top-1(%)
ngẫu nhiên
chưa kích hoạt
gradient
momentum
12345678910
Nhiệm vụ33771 Độ chính xác Top-1(%)
(d) ERK 70% thưa.
12345678910
Nhiệm vụ33771 Độ chính xác Top-1(%)
 (e) ERK 80% thưa.
12345678910
Nhiệm vụ33771 Độ chính xác Top-1(%)
 (f) ERK 90% thưa.

Hình C: Độ chính xác Top-1 (%) của 10-Nhiệm vụ CIFAR100 với khởi tạo, tăng trưởng và mức độ thưa khác nhau; sử dụng
MobileNetV2.

--- TRANG 13 ---
(a) đồng nhất 80% thưa.
12345678910
Nhiệm vụ587388 Độ chính xác Top-1(%)
ngẫu nhiên
chưa kích hoạt
gradient
momentum (b) đồng nhất 90% thưa.
12345678910
Nhiệm vụ587388 Độ chính xác Top-1(%)
 (c) đồng nhất 95% thưa.
12345678910
Nhiệm vụ587388 Độ chính xác Top-1(%)
12345678910
Nhiệm vụ587388 Độ chính xác Top-1(%)
(d) ERK 80% thưa.
12345678910
Nhiệm vụ587388 Độ chính xác Top-1(%)
 (e) ERK 90% thưa.
12345678910
Nhiệm vụ587388 Độ chính xác Top-1(%)
 (f) ERK 95% thưa.

Hình D: Độ chính xác Top-1 (%) của 10-Nhiệm vụ CIFAR100 với khởi tạo, tăng trưởng và mức độ thưa khác nhau; sử dụng
VGG-like.

--- TRANG 14 ---

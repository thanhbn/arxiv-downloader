# 2301.01828.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/continual-learning/2301.01828.pdf
# Kích thước tệp: 2391475 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Trích dẫn: Kessler, S.; Cobb, A.; Rudner,
T.G.J.; Zohren, S.; Roberts, S.J. Về
Suy luận Bayesian Tuần tự cho
Học liên tục. Entropy 2023 ,1, 0.
https://doi.org/
Biên tập viên học thuật: Irad E. Ben-Gal
và Amichai Painsky
Nhận: 1 tháng 5 năm 2023
Sửa đổi: 24 tháng 5 năm 2023
Chấp nhận: 28 tháng 5 năm 2023
Xuất bản:
Bản quyền: ©2023 của các tác giả.
Người cấp phép MDPI, Basel, Thụy Sĩ.
Bài báo này là một bài báo truy cập mở
được phân phối theo các điều khoản và
điều kiện của Giấy phép Creative Commons
Attribution (CC BY) (https://
creativecommons.org/licenses/by/
4.0/).
entropy
Bài báo
Về Suy luận Bayesian Tuần tự cho Học liên tục
Samuel Kessler1,*, Adam Cobb3, Tim G. J. Rudner2, Stefan Zohren1và Stephen J. Roberts1
1Đại học Oxford, Khoa Khoa học Kỹ thuật, Oxford OX2 6ED, UK;
skessler@robots.ox.ac.uk (S.K.); zohren@robots.ox.ac.uk (S.Z.); sjrob@robots.ox.ac.uk (S.J.R.)
2Đại học Oxford, Khoa Khoa học Máy tính, Oxford OX1 3QG, UK; tim.rudner@cs.ox.ac.uk
(T.G.J.R.)
3SRI International, Arlington, VA 22209, US; adam.cobb@sri.com
*Tác giả liên hệ: skessler@robots.ox.ac.uk
Tóm tắt: Suy luận Bayesian tuần tự có thể được sử dụng cho học liên tục để ngăn chặn quên thảm khốc của các nhiệm vụ trước đây và cung cấp một tiên nghiệm thông tin khi học các nhiệm vụ mới. Chúng tôi xem xét lại suy luận Bayesian tuần tự và đánh giá xem việc sử dụng hậu nghiệm của nhiệm vụ trước làm tiên nghiệm cho nhiệm vụ mới có thể ngăn chặn quên thảm khốc trong mạng nơ-ron Bayesian hay không. Đóng góp đầu tiên của chúng tôi là thực hiện suy luận Bayesian tuần tự bằng cách sử dụng Hamiltonian Monte Carlo. Chúng tôi truyền hậu nghiệm như một tiên nghiệm cho các nhiệm vụ mới bằng cách xấp xỉ hậu nghiệm thông qua việc khớp một bộ ước lượng mật độ trên các mẫu Hamiltonian Monte Carlo. Chúng tôi thấy rằng cách tiếp cận này không thể ngăn chặn quên thảm khốc, chứng minh sự khó khăn trong việc thực hiện suy luận Bayesian tuần tự trong mạng nơ-ron. Hơn nữa, chúng tôi nghiên cứu các ví dụ phân tích đơn giản về suy luận Bayesian tuần tự và CL và làm nổi bật vấn đề xác định sai mô hình có thể dẫn đến hiệu suất học liên tục dưới tối ưu mặc dù có suy luận chính xác. Hơn nữa, chúng tôi thảo luận về cách mất cân bằng dữ liệu nhiệm vụ có thể gây ra quên lãng. Từ những hạn chế này, chúng tôi lập luận rằng chúng ta cần các mô hình xác suất của quá trình sinh học liên tục thay vì dựa vào suy luận Bayesian tuần tự trên trọng số mạng nơ-ron Bayesian. Đóng góp cuối cùng của chúng tôi là đề xuất một đường cơ sở đơn giản gọi là Học liên tục Bayesian nguyên mẫu, có tính cạnh tranh với các phương pháp học liên tục Bayesian có hiệu suất tốt nhất trên các điểm chuẩn thị giác máy tính học liên tục tăng dần theo lớp.
Từ khóa: học liên tục; học suốt đời; suy luận Bayesian tuần tự; học sâu Bayesian; mạng nơ-ron Bayesian

1. Giới thiệu
Mục tiêu của học liên tục (CL) là tìm một bộ dự đoán học cách giải quyết một chuỗi các nhiệm vụ mới mà không mất khả năng giải quyết các nhiệm vụ đã học trước đây. Một thách thức chính của CL với mạng nơ-ron (NN) là các tham số mô hình từ các nhiệm vụ đã học trước đây bị "ghi đè" trong quá trình học dựa trên gradient của các nhiệm vụ mới, dẫn đến quên thảm khốc các khả năng đã học trước đây [1,2]. Một cách tiếp cận CL dựa trên việc sử dụng các ứng dụng đệ quy của Định lý Bayes; sử dụng hậu nghiệm trọng số trong mạng nơ-ron Bayesian (BNN) làm tiên nghiệm cho một nhiệm vụ mới [3]. Tuy nhiên, việc thu được một hậu nghiệm đầy đủ trên trọng số NN đòi hỏi tính toán đòi hỏi và chúng ta thường cần phải dùng đến các xấp xỉ, như phương pháp Laplace [4] hoặc suy luận biến phân [5,6] để thu được một hậu nghiệm trọng số mạng nơ-ron.

Khi thực hiện CL Bayesian, suy luận Bayesian tuần tự được thực hiện với một hậu nghiệm BNN xấp xỉ, không phải hậu nghiệm thật [7–12]. Nếu chúng ta xem xét hiệu suất của suy luận Bayesian tuần tự với một xấp xỉ biến phân trên một hậu nghiệm trọng số BNN thì chúng ta hầu như không quan sát được sự cải thiện so với việc đơn giản học các nhiệm vụ mới với stochastic gradient descent (SGD). Chúng tôi phát triển tuyên bố này hơn nữa trong phần 2.2. Vậy nếu chúng ta có quyền truy cập vào hậu nghiệm trọng số BNN thật, liệu điều này có đủ để ngăn chặn quên lãng bằng suy luận Bayesian tuần tự không?

--- TRANG 2 ---
Entropy 2023 ,1, 0 2 của 28
Đóng góp của chúng tôi trong chương này là xem xét lại CL Bayesian. 1) Về mặt thực nghiệm, chúng tôi thực hiện suy luận Bayesian tuần tự bằng cách sử dụng hậu nghiệm trọng số NN Bayesian thật. Chúng tôi làm điều này bằng cách sử dụng tiêu chuẩn vàng của các phương pháp suy luận Bayesian, Hamiltonian Monte Carlo (HMC) [13]. Chúng tôi sử dụng ước lượng mật độ trên các mẫu HMC và sử dụng mật độ hậu nghiệm xấp xỉ này như một tiên nghiệm cho nhiệm vụ tiếp theo trong quá trình lấy mẫu HMC. Đáng ngạc nhiên, phương pháp HMC của chúng tôi cho CL không mang lại lợi ích đáng chú ý nào so với một phương pháp suy luận xấp xỉ (VCL [9]) mặc dù sử dụng các mẫu từ hậu nghiệm thật. 2) Kết quả là chúng tôi xem xét một ví dụ phân tích đơn giản và làm nổi bật rằng suy luận chính xác với một mô hình được xác định sai vẫn có thể gây ra quên lãng. 3) Chúng tôi chỉ ra về mặt toán học rằng dưới các giả định nhất định, mất cân bằng dữ liệu nhiệm vụ gây ra quên lãng trong BNN Bayesian. 4) Chúng tôi đề xuất một mô hình xác suất mới cho CL và chỉ ra rằng bằng cách mô hình hóa rõ ràng quá trình sinh của dữ liệu, chúng ta có thể đạt được hiệu suất tốt, tránh được nhu cầu dựa vào suy luận Bayesian đệ quy trên trọng số NN để ngăn chặn quên lãng. Mô hình được đề xuất của chúng tôi, Học liên tục Bayesian nguyên mẫu (ProtoCL), về mặt khái niệm đơn giản, có thể mở rộng và cạnh tranh với các phương pháp CL Bayesian hiện đại trong thiết lập học tăng dần theo lớp.

2. Bối cảnh
2.1. Vấn đề Học liên tục
Học liên tục (CL) là một thiết lập học mà một mô hình phải học cách đưa ra dự đoán trên một tập hợp các nhiệm vụ một cách tuần tự trong khi duy trì hiệu suất trên tất cả các nhiệm vụ đã học trước đây. Trong CL, mô hình được hiển thị tuần tự T nhiệm vụ, ký hiệu Tt cho t=1,. . .,T. Mỗi nhiệm vụ, Tt, bao gồm một tập dữ liệu Dt={(xi,yi)}Nt i=1, mà một mô hình cần học để đưa ra dự đoán với. Tổng quát hơn, các nhiệm vụ được ký hiệu bằng các tuple riêng biệt bao gồm các phân phối dữ liệu có điều kiện và biên, {pt(y|x),pt(x)}. Sau nhiệm vụ Tt, mô hình sẽ mất quyền truy cập vào tập dữ liệu huấn luyện nhưng hiệu suất của nó sẽ được đánh giá liên tục trên tất cả các nhiệm vụ Ti cho i≤t. Để có cái nhìn tổng quan kỹ lưỡng về các kịch bản học liên tục khác nhau, xem phụ lục A.

2.2. Học liên tục Bayesian
Chúng tôi xem xét một thiết lập trong đó dữ liệu nhiệm vụ đến tuần tự tại các bước thời gian, t= 1, 2, . . .,T. Tại bước thời gian đầu tiên, t=1, tức là, đối với nhiệm vụ T1, mô hình nhận tập dữ liệu đầu tiên D1 và học phân phối có điều kiện p(yi|xi,θ) cho tất cả (xi,yi)∈ D 1 (i chỉ mục một điểm dữ liệu trong D1). Chúng tôi ký hiệu các tham số θ như có một phân phối tiên nghiệm p(θ) cho T1. Phân phối dự đoán hậu nghiệm cho một điểm kiểm tra x∗ 1∈ D 1 do đó là:
p(y∗ 1|x∗ 1,D1) =Z p(y∗ 1|x∗ 1,θ)p(θ|D1)dθ. (1)
Chúng tôi lưu ý rằng việc tính toán phân phối dự đoán hậu nghiệm này yêu cầu p(θ|D1). Đối với t=2, một mô hình CL được yêu cầu khớp p(yi|xi,θ) cho (xi,yi)∈ D 1∪ D 2. Phân phối dự đoán hậu nghiệm cho một điểm kiểm tra mới x∗ 2∈ D 1∪ D 2 là:
p(y∗ 2|x∗ 2,D1,D2) =Z p(y∗ 2|x∗ 2,θ)p(θ|D1,D2)dθ. (2)
Hậu nghiệm do đó phải được cập nhật để phản ánh phân phối có điều kiện mới này. Chúng ta có thể sử dụng ứng dụng lặp lại của quy tắc Bayes để tính toán các phân phối hậu nghiệm p(θ|D1,. . .,DT) như:
p(θ|D1, . . . ,DT−1,DT) =p(DT|θ)p(θ|D1, . . . ,DT−1) p(DT|D1, . . . ,DT−1). (3)
Trong thiết lập CL, chúng ta mất quyền truy cập vào các tập dữ liệu huấn luyện trước đây; tuy nhiên, việc sử dụng các ứng dụng lặp lại của quy tắc Bayes Phương trình (3) cho phép chúng ta kết hợp tuần tự thông tin

--- TRANG 3 ---
Entropy 2023 ,1, 0 3 của 28
từ các nhiệm vụ trước đây trong các tham số θ. Tại t=1, chúng ta có quyền truy cập vào D1 và hậu nghiệm trên các tham số là:
logp(θ|D1) =logp(D1|θ) +logp(θ)−logp(D1). (4)
Tại t=2, chúng ta yêu cầu p(θ|D1,D2) để tính toán phân phối dự đoán hậu nghiệm trong Phương trình (2). Tuy nhiên, chúng ta đã mất quyền truy cập vào D1. Theo quy tắc Bayes, hậu nghiệm có thể được viết như:
logp(θ|D1,D2) =logp(D2|θ) +logp(θ|D1)−logp(D2|D1), (5)
trong đó chúng ta đã sử dụng sự độc lập có điều kiện của D2 và D1 cho θ. Chúng tôi lưu ý rằng likelihood p(D2|θ) chỉ phụ thuộc vào tập dữ liệu nhiệm vụ hiện tại, D2, và tiên nghiệm p(θ|D1) mã hóa kiến thức tham số từ nhiệm vụ trước đó. Do đó, chúng ta có thể sử dụng hậu nghiệm được đánh giá tại t như một tiên nghiệm để học một nhiệm vụ mới tại t+1. Từ Phương trình (3), chúng ta yêu cầu rằng mô hình của chúng ta với các tham số θ là một thống kê đầy đủ của D1, tức là, p(D2|θ,D1) = p(D2|θ), làm cho likelihood độc lập có điều kiện với D1 cho θ. Quan sát này thúc đẩy việc sử dụng các bộ dự đoán có dung lượng cao, như mạng nơ-ron Bayesian, đủ linh hoạt để học từ D1.

Ví dụ Học liên tục: Split-MNIST
Đối với tập dữ liệu MNIST [14] chúng ta biết rằng nếu chúng ta huấn luyện một BNN, chúng ta sẽ đạt được hiệu suất tốt bằng cách suy luận hậu nghiệm p(θ|D) phụ lục B và tích hợp hậu nghiệm để suy luận phân phối dự đoán hậu nghiệm trên một điểm kiểm tra eq. (1). Vậy nếu chúng ta chia tập dữ liệu MNIST thành 5 nhiệm vụ phân loại hai lớp thì chúng ta sẽ có thể phục hồi đệ quy hậu nghiệm đa nhiệm vụ p(θ|D) = p(θ|D1. . .,D5) bằng cách sử dụng eq. (3). Vấn đề này được gọi là Split-MNIST [15], trong đó nhiệm vụ đầu tiên liên quan đến việc phân loại các chữ số {0, 1} sau đó nhiệm vụ thứ hai phân loại các chữ số {2, 3} và tiếp tục như vậy.

Chúng ta có thể xác định ba thiết lập CL khác nhau [16–18]. Khi chúng ta cho phép tác nhân CL đưa ra dự đoán với một định danh nhiệm vụ t, kịch bản được gọi là tăng dần theo nhiệm vụ. Định danh t có thể được sử dụng để chọn các đầu khác nhau Phần 2.1, chẳng hạn. Kịch bản này không tương thích với suy luận Bayesian tuần tự được nêu trong Phương trình (3) vì không cần định danh nhiệm vụ để đưa ra dự đoán. Học tăng dần theo miền là một kịch bản khác không có quyền truy cập vào t trong quá trình đánh giá và yêu cầu tác nhân CL thực hiện phân loại cho cùng một không gian đầu ra cho mỗi nhiệm vụ; ví dụ, đối với Split-MNIST, không gian đầu ra là {0, 1} cho tất cả các nhiệm vụ, vì vậy điều này tương đương với việc phân loại giữa các chữ số chẵn và lẻ. Học tăng dần theo miền tương thích với suy luận Bayesian tuần tự với likelihood Bernoulli. Kịch bản thứ ba là học tăng dần theo lớp cũng không có quyền truy cập vào t nhưng tác nhân cần phân loại mỗi ví dụ thành lớp tương ứng của nó. Đối với Split-MNIST, ví dụ, không gian đầu ra là {0,. . ., 9} cho mỗi nhiệm vụ. Học tăng dần theo lớp tương thích với suy luận Bayesian tuần tự với likelihood phân loại.

2.3. Học liên tục Biến phân
VCL (VCL; Nguyen et al. [9]) đơn giản hóa vấn đề suy luận Bayesian trong Phương trình (3) thành một chuỗi các cập nhật Bayesian xấp xỉ trên phân phối trên trọng số mạng nơ-ron ngẫu nhiên θ. Để làm như vậy, VCL sử dụng hậu nghiệm biến phân từ các nhiệm vụ trước đây như một tiên nghiệm cho các nhiệm vụ mới. Theo cách này, học để giải quyết nhiệm vụ đầu tiên đòi hỏi việc tìm một phân phối biến phân q1(θ|D1) tối đa hóa một mục tiêu biến phân tương ứng. Đối với nhiệm vụ tiếp theo, tiên nghiệm được chọn là q1(θ|D1), và mục tiêu trở thành học một phân phối biến phân q2(θ|D2) tối đa hóa một mục tiêu biến phân tương ứng dưới tiên nghiệm này. Ký hiệu hậu nghiệm đệ quy được suy luận từ nhiều tập dữ liệu bằng qt(θ|D1:t), chúng ta có thể biểu thị mục tiêu VCL cho nhiệm vụ thứ t như:
L(θ,Dt) =DKL[qt(θ)||qt−1(θ|D1:t−1)]−Eqt[logp(Dt|θ)]. (6)

--- TRANG 4 ---
Entropy 2023 ,1, 0 4 của 28
Khi áp dụng VCL cho vấn đề Split-MNIST Hình 1, chúng ta có thể thấy rằng VCL đơn đầu hầu như không hoạt động tốt hơn SGD khi nhớ các nhiệm vụ trước đây. VCL đa đầu hoạt động tốt hơn, mặc dù không phải là một yêu cầu từ suy luận Bayesian tuần tự Phương trình (3). Do đó, tại sao VCL đơn đầu không cải thiện so với SGD nếu chúng ta có thể xây dựng đệ quy một hậu nghiệm xấp xỉ bằng cách sử dụng Phương trình (3)? Chúng tôi giả thuyết rằng điều này có thể do việc sử dụng một xấp xỉ biến phân của hậu nghiệm và vì vậy chúng ta không thực sự nghiêm ngặt thực hiện quá trình CL Bayesian được mô tả trong Phần 2.2. Chúng tôi kiểm tra giả thuyết này trong phần tiếp theo bằng cách truyền hậu nghiệm BNN thật để xác minh xem chúng ta có thể đệ quy thu được hậu nghiệm đa nhiệm vụ thật và do đó cải thiện VCL đơn đầu và ngăn chặn quên thảm khốc hay không.

[Hình 1. Độ chính xác trên Split-MNIST cho các phương pháp CL khác nhau với BNN hai lớp, tất cả độ chính xác là trung bình và độ lệch chuẩn trên 10 lần chạy với các hạt giống ngẫu nhiên khác nhau. Chúng tôi so sánh một NN được huấn luyện với SGD (đơn đầu) với VCL. Chúng tôi xem xét các biến thể VCL đơn đầu (SH) và đa đầu (MH), tức là học tăng dần theo miền và nhiệm vụ tương ứng.]

3. Học liên tục Bayesian với Hamiltonian Monte Carlo
Để thực hiện suy luận trên trọng số BNN, chúng tôi sử dụng thuật toán HMC [13]. Sau đó chúng tôi sử dụng các mẫu này và học một bộ ước lượng mật độ có thể được sử dụng như một tiên nghiệm cho một nhiệm vụ mới (chúng tôi đã xem xét Sequential Monte Carlo, nhưng nó không thể mở rộng đến các chiều yêu cầu cho các NN mà chúng tôi xem xét [19]. Mặt khác, HMC gần đây đã được mở rộng thành công cho các BNN tương đối nhỏ có kích thước được xem xét trong bài báo này [20] và các mô hình ResNet nhưng với chi phí tính toán lớn [21]). HMC được coi là tiêu chuẩn vàng trong suy luận xấp xỉ và được đảm bảo sẽ tạo ra các mẫu từ hậu nghiệm thật một cách tiệm cận (trong Cuộc thi Học sâu Bayesian NeurIPS 2021 (https://izmailovpavel.github.io/ neurips_bdl_competition), mục tiêu là tìm một phương pháp suy luận xấp xỉ "gần" nhất có thể với các mẫu hậu nghiệm từ HMC). Chúng tôi sử dụng các mẫu hậu nghiệm của θ từ HMC và sau đó khớp một bộ ước lượng mật độ trên các mẫu này, để sử dụng như một tiên nghiệm cho một nhiệm vụ mới. Điều này cho phép chúng ta sử dụng một phân phối hậu nghiệm đa phương thức trên θ thay vì một hậu nghiệm biến phân Gaussian đường chéo như trong VCL. Cụ thể hơn, để truyền hậu nghiệm p(θ|D1), chúng tôi sử dụng một bộ ước lượng mật độ, được định nghĩa ˆp(θ|D1), để khớp một mật độ xác suất trên các mẫu HMC như một hậu nghiệm. Đối với nhiệm vụ tiếp theo T2, chúng ta có thể sử dụng ˆp(θ|D1) như một tiên nghiệm cho một chuỗi lấy mẫu HMC mới và tiếp tục như vậy (xem Hình 2). Các tiên nghiệm bộ ước lượng mật độ cần phải thỏa mãn hai điều kiện chính để sử dụng trong lấy mẫu HMC. Thứ nhất, chúng là một hàm mật độ xác suất. Thứ hai, chúng có thể vi phân được đối với các mẫu đầu vào.

[Hình 2. Minh họa quá trình truyền hậu nghiệm; các tiên nghiệm màu xanh ở hàng trên và các mẫu hậu nghiệm ở hàng dưới. Đây là một quá trình hai bước trong đó chúng ta đầu tiên thực hiện HMC với một tiên nghiệm Gaussian đẳng hướng cho T1 sau đó thực hiện ước lượng mật độ trên các mẫu HMC từ hậu nghiệm để thu được ˆp1(θ|D1). Hậu nghiệm này sau đó có thể được sử dụng như một tiên nghiệm cho nhiệm vụ mới T2 và tiếp tục như vậy.]

--- TRANG 5 ---
Entropy 2023 ,1, 0 5 của 28
Chúng tôi sử dụng một tập dữ liệu đồ chơi (Hình 3) với hai lớp và đầu vào x∈R2 [22]. Mỗi nhiệm vụ là một vấn đề phân loại nhị phân trong đó ranh giới quyết định mở rộng từ trái sang phải cho mỗi nhiệm vụ mới. Chúng tôi huấn luyện một BNN hai lớp, với kích thước trạng thái ẩn là 10. Chúng tôi sử dụng Mô hình Hỗn hợp Gaussian (GMM) như một bộ ước lượng mật độ để xấp xỉ hậu nghiệm với các mẫu HMC. Chúng tôi cũng đã thử Normalizing Flows mà lẽ ra nên linh hoạt hơn [23]; tuy nhiên, những cái này không hoạt động mạnh mẽ cho lấy mẫu HMC (RealNVP rất nhạy cảm với việc lựa chọn hạt giống ngẫu nhiên, các mẫu từ phân phối đã học không đưa ra dự đoán chính xác cho nhiệm vụ hiện tại và dẫn đến sự bất ổn định số khi được sử dụng như một tiên nghiệm trong lấy mẫu HMC). Theo hiểu biết của chúng tôi, chúng tôi là người đầu tiên kết hợp các tiên nghiệm linh hoạt vào các phương pháp lấy mẫu như HMC.

[Hình 3. Bên trái là tập dữ liệu đồ chơi của 5 nhiệm vụ phân loại 2 chiều riêng biệt liên quan đến việc phân loại hình tròn và hình vuông [22]. Hơn nữa, độ chính xác kiểm tra phân loại nhị phân học liên tục trên 10 hạt giống. Đường liền nét màu hồng là độ chính xác cơ sở đa nhiệm vụ (MT) sử dụng SGD/HMC với cùng mô hình như cho các thí nghiệm CL. Đây là một kịch bản học tăng dần theo miền, hoàn toàn nhất quán với suy luận Bayesian tuần tự phụ lục B.]

Huấn luyện một BNN với HMC trên cùng tập dữ liệu đa nhiệm vụ thu được độ chính xác kiểm tra là 1.0. Do đó, hậu nghiệm cuối cùng phù hợp cho học liên tục dưới Phương trình (3) và chúng ta sẽ có thể đạt được đệ quy hậu nghiệm đa nhiệm vụ với suy luận Bayesian đệ quy. Điều này có nghĩa là nếu chúng ta tuần tự xây dựng hậu nghiệm eq. (3) thì chúng ta cũng sẽ mong đợi độ chính xác 1.0 vì hiệu suất dự đoán hậu nghiệm đa nhiệm vụ là một cận trên cho hiệu suất của suy luận Bayesian tuần tự cho học liên tục phụ lục B.

Kết quả từ Hình 3 chứng minh rằng việc sử dụng HMC với một hậu nghiệm đa phương thức xấp xỉ không thể ngăn chặn quên lãng và kém hiệu quả hơn so với việc sử dụng VCL đa đầu. Thực tế, VCL đa đầu rõ ràng vượt trội hơn HMC, cho thấy rằng nguồn gốc của việc giữ lại kiến thức không phải thông qua việc truyền hậu nghiệm mà thông qua các đầu cụ thể theo nhiệm vụ. Đối với T2, chúng ta sử dụng ˆp(θ|D1) thay vì p(θ|D1) như một tiên nghiệm và điều này sẽ làm thiên lệch việc lấy mẫu HMC cho tất cả các nhiệm vụ tiếp theo. Trong đoạn tiếp theo, chúng tôi chi tiết các biện pháp được thực hiện để đảm bảo rằng các chuỗi HMC của chúng tôi đã hội tụ để chúng tôi có thể giả định rằng chúng tôi đang lấy mẫu từ hậu nghiệm thật. Hơn nữa, chúng tôi đánh giá độ trung thực của bộ ước lượng mật độ GMM đối với các mẫu HMC. Chúng tôi cũng lặp lại những thí nghiệm này với một tập dữ liệu đồ chơi khác gồm năm nhiệm vụ phân loại nhị phân nơi chúng tôi quan sát kết quả tương tự Phụ lục C.

Đối với HMC, chúng tôi đảm bảo rằng chúng tôi đang lấy mẫu từ hậu nghiệm bằng cách đánh giá sự hội tụ chuỗi và kích thước mẫu hiệu quả (Hình A6). Kích thước mẫu hiệu quả đo lường sự tự tương quan trong chuỗi. Kích thước mẫu hiệu quả cho các chuỗi HMC cho BNN của chúng tôi tương tự như tài liệu [20]. Hơn nữa, chúng tôi đảm bảo rằng hậu nghiệm xấp xỉ GMM là đa phương thức và có một hậu nghiệm phức tạp hơn so với VCL, và rằng các mẫu GMM tạo ra kết quả tương đương với các mẫu HMC cho nhiệm vụ hiện tại (Hình A5). Xem Phụ lục D để biết chi tiết.

Các điểm chuẩn 2-d mà chúng tôi xem xét trong phần này là từ các tác phẩm trước đây và là các vấn đề học liên tục tăng dần theo miền. Thiết lập tăng dần theo miền cũng đơn giản hơn [18] so với thiết lập tăng dần theo lớp và do đó là một điểm khởi đầu tốt khi cố gắng thực hiện suy luận Bayesian tuần tự chính xác. Mặc dù vậy, chúng tôi không thể thực hiện suy luận Bayesian tuần tự trong BNN mặc dù sử dụng HMC, được coi

--- TRANG 6 ---
Entropy 2023 ,1, 0 6 của 28
[Hình 4. Phân phối dự đoán hậu nghiệm cho một mô hình hồi quy tuyến tính Bayesian. Trái, dữ liệu đến từ một nhiệm vụ duy nhất mà mô hình tuyến tính Bayesian có thể khớp tốt. Phải, một tập dữ liệu mới được thu thập từ một phần khác của miền, và mô hình hồi quy tuyến tính Bayesian được cập nhật tuần tự của chúng tôi (chính xác dưới suy luận Bayesian) mô hình một giải pháp toàn cầu cho cả hai tập dữ liệu này mà không tối ưu cho cả hai.]

là tiêu chuẩn vàng của học sâu Bayesian. HMC và ước lượng mật độ với GMM tạo ra các hậu nghiệm phong phú hơn, chính xác hơn và đa phương thức. Mặc dù vậy, chúng tôi vẫn không thể tuần tự xây dựng hậu nghiệm đa nhiệm vụ hoặc thu được kết quả tốt hơn nhiều so với một hậu nghiệm Gaussian đẳng hướng như VCL đơn đầu. Điểm yếu của phương pháp này là ước lượng mật độ, GMM loại bỏ khối lượng xác suất trên các khu vực của không gian hậu nghiệm trọng số BNN, điều này quan trọng cho nhiệm vụ mới. Điều này chứng minh việc mô hình hóa hậu nghiệm trọng số BNN là một nhiệm vụ khó khăn như thế nào. Trong phần tiếp theo, chúng tôi nghiên cứu một ví dụ phân tích khác về suy luận Bayesian tuần tự và xem xét cách xác định sai mô hình và mất cân bằng dữ liệu nhiệm vụ có thể gây ra quên lãng trong CL Bayesian.

4. Học liên tục Bayesian và Xác định sai Mô hình
Bây giờ chúng tôi xem xét một ví dụ phân tích đơn giản trong đó chúng ta có thể thực hiện suy luận Bayesian tuần tự eq. (3) dưới dạng đóng bằng cách sử dụng liên hợp. Chúng tôi xem xét một mô hình hồi quy tuyến tính Bayesian với likelihood Gaussian cho 2 nhiệm vụ học liên tục. Ví dụ đơn giản này làm nổi bật rằng quên lãng Phương trình (A3) có thể xảy ra dưới những điều kiện nhất định mặc dù có suy luận chính xác.

Chúng tôi sử dụng một likelihood Gaussian dạng p(D|θ) =N(y;f(X;θ),β−1) sao cho y=f(X;θ) +ϵ trong đó ϵ∼ N (0,β−1) và f(X;θ) =θX⊤. Chúng tôi đặt một tiên nghiệm Gaussian trên các tham số θ sao cho p(θ) =N(θ;m0,Σ0) cho nhiệm vụ đầu tiên của chúng tôi. Thông qua liên hợp của tiên nghiệm và likelihood Gaussian, hậu nghiệm cũng là Gaussian, p(θ|D) =N(θ;m,Σ) trong đó m=Σ(Σ−1 0m0+βX⊤y) và Σ−1=Σ−1 0+βX⊤X cho nhiệm vụ 2 trở đi. Bằng cách sử dụng suy luận Bayesian tuần tự, chúng ta có thể có các phương trình cập nhật dạng đóng cho các tham số của chúng ta.

Từ dạng của hậu nghiệm hồi quy tuyến tính, mô hình của chúng ta chỉ có thể mô hình dữ liệu tuyến tính. Vậy, nếu chúng ta có dữ liệu tuyến tính và được rút ra từ một nhiệm vụ thứ hai, từ một phần riêng biệt của miền, thì mô hình mô hình chính xác một mô hình tuyến tính, đây là giải pháp Bayes của vấn đề đa nhiệm vụ phụ lục B. Ví dụ, tập dữ liệu nhiệm vụ 1 được tạo theo y=x+1+ϵ, trong đó ϵ=N(0,β−1) cho x∈[−1, 0). Từ hình 4 chúng ta có thể thấy rằng hồi quy tuyến tính Bayesian của chúng ta mô hình chính xác tập dữ liệu đầu tiên này. Bây giờ, nếu chúng ta tuần tự mô hình một tập dữ liệu thứ hai, với dữ liệu được rút ra từ y=−x+1+ϵ, trong đó ϵ=N(0,β−1) cho x∈[0, 1]. Mô hình hồi quy đến cả hai tập dữ liệu này: hồi quy học liên tục từ việc sử dụng hậu nghiệm từ nhiệm vụ 1 như một tiên nghiệm cho nhiệm vụ 2 giống như nếu chúng ta hồi quy đến tập dữ liệu đa nhiệm vụ của cả nhiệm vụ 1 và 2 (xem hình 4 bên phải)1.

Tuy nhiên, như chúng ta có thể thấy từ hình 4 (phải), đây là một giải pháp học liên tục không tối ưu, vì chúng ta muốn hiệu suất trung bình eq. (A1) cao cho tất cả các nhiệm vụ. Cụ thể hơn, hiệu suất sau khi học nhiệm vụ 2 là P2=p2,2+p2,1 trong đó pi,j là hiệu suất cho nhiệm vụ j sau khi học nhiệm vụ i và j≤i. Cao hơn là tốt hơn cho thước đo hiệu suất pi,j, đối với hồi quy pi,j có thể là log-likelihood. Tuy nhiên, chúng ta thấy rằng hiệu suất thấp đối với mô hình học liên tục hồi quy tuyến tính Bayesian tuần tự chính xác hình 4. Như với tất cả các điểm chuẩn học liên tục, chúng ta yêu cầu mô hình của chúng ta hoạt động tốt như nhau trên cả hai nhiệm vụ. Trong trường hợp này, chúng ta có thể chỉ định một mô hình tốt hơn không chỉ là một mô hình hồi quy tuyến tính Bayesian, mà là một hỗn hợp các bộ hồi quy tuyến tính [24]. Mặc dù thực hiện suy luận chính xác, một mô hình được xác định sai có thể quên. Chúng ta bị quên nhiệm vụ 1 sau khi học nhiệm vụ 2, vì thước đo quên eq. (A3), là f2 1=p1,1−p2,1>0 vì p1,1>p2,1 cho thấy quên lãng, như có thể thấy từ hình 4.

Trong trường hợp HMC, chúng tôi đã xác minh rằng mạng nơ-ron Bayesian của chúng tôi có hiệu suất hoàn hảo trên tất cả các nhiệm vụ trước đây. Trong phần 3, chúng tôi có một mô hình được xác định tốt nhưng gặp khó khăn với suy luận Bayesian tuần tự chính xác eq. (3). Với kịch bản hồi quy tuyến tính Bayesian này, chúng tôi đang thực hiện suy luận chính xác, tuy nhiên, chúng tôi có một mô hình được xác định sai và do đó không thể đạt được hiệu suất tốt trên cả hai nhiệm vụ phụ lục B. Điều quan trọng là phải tách biệt xác định sai mô hình và suy luận chính xác và làm nổi bật rằng xác định sai mô hình là một cảnh báo chưa được nêu bật trong tài liệu CL theo như chúng tôi biết. Hơn nữa, chúng ta chỉ có thể đảm bảo rằng các mô hình của chúng ta được xác định tốt nếu chúng ta có quyền truy cập vào dữ liệu từ tất cả các nhiệm vụ a priori. Vậy trong kịch bản học liên tục trực tuyến [25–27], chúng ta không thể biết liệu mô hình của chúng ta sẽ hoạt động tốt trên tất cả các nhiệm vụ quá khứ và tương lai mà không đưa ra giả định về phân phối nhiệm vụ.

5. Suy luận Bayesian Tuần tự và Dữ liệu Nhiệm vụ Mất cân bằng
Mạng Nơ-ron là những mô hình phức tạp với một không gian giả thuyết rộng và do đó là một mô hình được xác định phù hợp khi giải quyết các vấn đề học liên tục [28]. Tuy nhiên, chúng tôi gặp khó khăn trong việc khớp các mẫu hậu nghiệm từ HMC để thực hiện suy luận Bayesian tuần tự trong Phần 3.

Chúng tôi tiếp tục sử dụng lọc Bayesian và giả định một NN Bayesian trong đó hậu nghiệm là Gaussian với một hiệp phương sai đầy đủ. Bằng cách mô hình toàn bộ hiệp phương sai, chúng tôi cho phép mô hình cách mỗi trọng số riêng lẻ thay đổi đối với tất cả các trọng số khác. Chúng tôi làm điều này bằng cách diễn giải học trực tuyến trong BNN Bayesian như lọc [29]. Cách xử lý của chúng tôi tương tự như Aitchison [30], người đưa ra một bộ tối ưu hóa bằng cách tận dụng lọc Bayesian. Chúng tôi xem xét suy luận trong mô hình đồ thị được mô tả trong Hình 5. Mục tiêu là suy luận các trọng số BNN tối ưu, θ∗ t tại t cho một quan sát duy nhất và tiên nghiệm trọng số BNN. Các trọng số BNN trước đây được sử dụng như một tiên nghiệm để suy luận các tham số BNN hậu nghiệm. Chúng tôi xem xét thiết lập trực tuyến, trong đó một điểm dữ liệu duy nhất (xt,yt) được quan sát tại một thời điểm.

[Hình 5. Mô hình đồ thị cho lọc. Các nút màu xám và trắng và các biến tiềm ẩn được quan sát, tương ứng.]

Thay vì mô hình hiệp phương sai đầy đủ, chúng tôi thay vào đó xem xét mỗi tham số θi như một hàm của tất cả các tham số khác θ−it. Chúng tôi cũng giả định rằng các giá trị của trọng số gần với những giá trị của bước thời gian trước đó [31]. Để thu được các phương trình cập nhật cho các tham số BNN cho một quan sát mới và tiên nghiệm, chúng tôi đưa ra hai giả định đơn giản hóa như sau.

Giả định 1. Đối với một mạng nơ-ron Bayesian với đầu ra f(xt;θ) và likelihood L(xt,yt;θ), đạo hàm được đánh giá tại θt là zt=∂L(xt,yt;θ)/∂θ|θ=θt và Hessian là H. Chúng tôi giả định một mất mát bậc hai cho một điểm dữ liệu (xt,yt) dạng:
L(xt,yt;θ) =Lt(θ) =−1 2θ⊤Hθ+z⊤ tθ, (7)
kết quả của một khai triển Taylor bậc hai. Hessian được giả định là hằng số đối với (xt,yt) (nhưng không đối với θ).

Để xây dựng phương trình động lực cho θ, xem xét gradient cho trọng số thứ i trong khi tất cả các tham số khác được đặt thành giá trị hiện tại của chúng tại giá trị tối ưu cho θ∗ it:
θ∗ it=−1 HiiH⊤ −iiθ−it, (8)
vì zit=0 tại một mode. Phương trình trên cho chúng ta thấy rằng động lực của trọng số tối ưu θ∗ it phụ thuộc vào tất cả các giá trị hiện tại khác của các tham số θ−it. Động lực của θ−it là một quá trình ngẫu nhiên phức tạp phụ thuộc vào nhiều biến khác nhau như tập dữ liệu, kiến trúc mô hình, lịch trình tốc độ học, v.v.

Giả định 2. Vì việc lý luận về động lực của θ−it là không thể xử lý được, chúng tôi giả định rằng tại bước thời gian tiếp theo, các trọng số tối ưu gần với các bước thời gian trước đó với một quá trình Ornstein–Uhlenbeck rời rạc hóa cho các trọng số θ−it với tốc độ hoàn nguyên ϑ∈R+ và phương sai nhiễu η2 −i:
p(θ−i,t+1|θ−i,t) =N((1−ϑ)θ−it,η2 −i), (9)
điều này ngụ ý rằng động lực cho trọng số tối ưu được định nghĩa bởi
p(θ∗ i,t+1|θ∗ i,t) =N((1−ϑ)θ∗ it,η2), (10)
trong đó η2=η2 −iH⊤ −iiH−ii.

Nói một cách đơn giản, trong Giả định 2, chúng tôi giả định một mô hình tiết kiệm của động lực, và rằng giá trị tiếp theo của θ−i,t gần với giá trị trước đó của chúng theo một Gaussian, tương tự như Aitchison [30].

--- TRANG 9 ---
Entropy 2023 ,1, 0 9 của 28
Bổ đề 1. Dưới Giả định 1 và 2, động lực và likelihood là Gaussian. Do đó, chúng ta có thể suy luận phân phối hậu nghiệm trên các trọng số tối ưu bằng cách sử dụng các cập nhật Bayesian và bằng cách tuyến tính hóa BNN, các phương trình cập nhật cho hậu nghiệm của trung bình và phương sai của BNN cho một điểm dữ liệu mới là:
µt,post=σ2 t,post   µt,prior σ2 t,prior(η2)+yt σ2g(xt)!
và 1 σ2 t,post=g(xt)2 σ2+1 σ2 t,prior(η2), (11)
trong đó chúng tôi bỏ ký hiệu cho tham số thứ i, hậu nghiệm là N(θ∗ t;µt,post,σ2 t,post) và g(xt) = ∂f(xt;θ∗ it) ∂θ∗ it và σ2 t,prior là một hàm của η2.

Xem Phụ lục G để biết sự dẫn xuất của Bổ đề 1. Từ Phương trình (11), chúng ta có thể nhận thấy rằng trung bình hậu nghiệm phụ thuộc tuyến tính vào tiên nghiệm và một số hạng phụ thuộc dữ liệu và do đó sẽ hoạt động tương tự như ví dụ trước đây của chúng tôi trong Phần 4. Dưới Giả định 1 và Giả định 2, nếu có mất cân bằng dữ liệu giữa các nhiệm vụ trong Phương trình (11), thì số hạng phụ thuộc dữ liệu sẽ chiếm ưu thế so với số hạng tiên nghiệm nếu có nhiều dữ liệu hơn cho nhiệm vụ hiện tại.

Trong Phần 3, chúng tôi đã chỉ ra rằng rất khó khăn với các công cụ học máy hiện tại để thực hiện suy luận Bayesian tuần tự cho các vấn đề CL đơn giản với BNN Bayesian nhỏ. Khi chúng tôi tách biệt suy luận Bayesian và xác định sai mô hình, chúng tôi đã chỉ ra rằng các mô hình được xác định sai có thể quên mặc dù có suy luận Bayesian chính xác. Cách duy nhất để đảm bảo rằng mô hình của chúng ta được xác định tốt là chỉ ra rằng hậu nghiệm đa nhiệm vụ tạo ra các phân phối dự đoán hậu nghiệm hợp lý p(y|x,D) =R p(y|x,D,θ)p(θ|D)dθ cho ứng dụng của một người. Ngoài ra, trong phần này, chúng tôi đã chỉ ra rằng nếu có mất cân bằng kích thước tập dữ liệu nhiệm vụ, thì chúng ta có thể đạt được quên lãng dưới các giả định nhất định.

6. Công trình Liên quan
Gần đây đã có sự hồi sinh trong lĩnh vực CL [32] do sự ra đời của học sâu. Các phương pháp xấp xỉ suy luận Bayesian tuần tự Phương trình (3) đã có tầm quan trọng trong việc hồi sinh CL và đã sử dụng một xấp xỉ Laplace đường chéo [3,7]. Xấp xỉ Laplace đường chéo đã được tăng cường bằng cách mô hình hiệp phương sai giữa các trọng số mạng nơ-ron trong cùng một lớp [8]. Thay vì xấp xỉ Laplace, chúng ta có thể sử dụng một xấp xỉ biến phân cho suy luận Bayesian tuần tự, được đặt tên là VCL [9,33]. Phương sai Gaussian biến phân của mỗi tham số BNN Bayesian có thể được sử dụng để điều kiện trước các tốc độ học của mỗi trọng số và tạo một mặt nạ cho mỗi nhiệm vụ bằng cách sử dụng tỉa [10]. Việc sử dụng các tiên nghiệm phong phú hơn cũng đã được khám phá [11,34–37]. Ví dụ, một người có thể học một tỷ lệ của các tham số trọng số NN Gaussian cho mỗi nhiệm vụ bằng cách học một tham số thích ứng biến phân mới có thể tăng cường đóng góp của một nơ-ron cụ thể [38]. Xấp xỉ Laplace trực tuyến có thể được xem như một trường hợp đặc biệt của VCL trong đó số hạng KL-divergence Phương trình (6) được điều chỉnh và nhiệt độ có xu hướng 0 [12]. Quá trình Gaussian cũng đã được áp dụng cho các vấn đề CL tận dụng các điểm cảm ứng để giữ lại các hàm nhiệm vụ trước đây [39,40].

Các phương pháp Bayesian điều chỉnh trọng số không đạt được hiệu suất của các phương pháp CL dựa trên phát lại kinh nghiệm [41] về mặt độ chính xác trên các điểm chuẩn phân loại hình ảnh CL. Thay vì điều chỉnh các không gian trọng số chiều cao, việc điều chỉnh các hàm nhiệm vụ là một cách tiếp cận trực tiếp hơn để chống lại quên lãng [42]. Trọng số BNN Bayesian cũng có thể được tạo ra bởi một hypernetwork, trong đó hypernetwork chỉ cần các kỹ thuật CL đơn giản để ngăn chặn quên lãng [43]. Đặc biệt, một người có thể tận dụng tính đối ngẫu giữa xấp xỉ Laplace và quá trình Gaussian để phát triển một cách tiếp cận điều chỉnh chức năng cho CL Bayesian [44] hoặc sử dụng suy luận biến phân không gian hàm [45,46].

Trong phần tiếp theo, chúng tôi đề xuất một đường cơ sở học liên tục Bayesian đơn giản mô hình quá trình sinh học liên tục tạo ra dữ liệu và thực hiện suy luận Bayesian tuần tự chính xác trong một không gian nhúng chiều thấp. Công trình trước đây đã khám phá việc mô hình quá trình sinh dữ liệu bằng cách suy luận phân phối chung của đầu vào và đích p(x,y) và học một mô hình sinh để phát lại dữ liệu để ngăn chặn quên lãng [47],

--- TRANG 10 ---
Entropy 2023 ,1, 0 10 của 28
và bằng cách học một mô hình sinh cho mỗi lớp và đánh giá likelihood của các đầu vào cho mỗi lớp p(x|y) [48].

7. Học liên tục Bayesian Nguyên mẫu
Chúng tôi đã chỉ ra rằng Bayes tuần tự trên các tham số NN rất khó khăn (phần 3), và chỉ phù hợp cho các tình huống mà hậu nghiệm đa nhiệm vụ phù hợp cho tất cả các nhiệm vụ. Bây giờ chúng tôi chỉ ra rằng một cách tiếp cận có nhiều thành quả hơn là mô hình vấn đề CL sinh với một bộ phân loại sinh trong đó mỗi lớp được đại diện bởi một nguyên mẫu và phân loại dựa trên khoảng cách đến nguyên mẫu. Điều này đơn giản và có thể mở rộng. Đặc biệt, chúng tôi đại diện các lớp bằng nguyên mẫu [49,50] và duy trì nguyên mẫu với một bộ đệm phát lại để ngăn chặn quên thảm khốc. Chúng tôi gọi khung này là Học liên tục Bayesian Nguyên mẫu, hay ProtoCL cho ngắn gọn. Cách tiếp cận này có thể được xem như một biến thể xác suất của iCarl [50], tạo ra các hàm nhúng cho các lớp khác nhau chỉ đơn giản là trung bình lớp và dự đoán được thực hiện bởi láng giềng gần nhất. ProtoCL cũng có điểm tương đồng với mô hình học ít shot Phân cụm Xác suất cho Phân loại Trực tuyến [51] và MetaQDA [52], được phát triển cho phân loại hình ảnh ít shot. MetaQDA sử dụng các tiên nghiệm liên hợp Normal- inverse Wishart cho phân tích phân biệt bậc hai Gaussian (QDA), ProtoCL có các lựa chọn thiết kế khác nhau như sau.

[Hình 6. Tổng quan về ProtoCL.]

Mô hình. ProtoCL mô hình quá trình CL sinh. Chúng tôi xem xét các lớp j∈ {1,. . .,J}, được tạo ra từ một phân phối phân loại với một tiên nghiệm Dirichlet:
yi,t∼Cat(p1:J),p1:J∼Dir(αt). (12)
Hình ảnh được nhúng vào một không gian nhúng bởi một bộ mã hóa, z=f(x;w) với các tham số w. Các nhúng theo lớp là Gaussian có phương sai đẳng hướng. Trung bình nguyên mẫu có một tiên nghiệm cũng là Gaussian với và hiệp phương sai đường chéo:
zit|yit∼ N(¯zyt,Σϵ), ¯zyt∼ N(µyt,Λ−1 yt). (13)
Xem hình 6 để có cái nhìn tổng quan về mô hình. Để giảm bớt quên lãng trong CL, ProtoCL sử dụng một coreset của dữ liệu nhiệm vụ trước đây để tiếp tục nhúng các lớp trước đây một cách riêng biệt như nguyên mẫu. Phân phối hậu nghiệm trên xác suất lớp {pj}J j=1 và nhúng lớp {¯zyj}J j=1 được ký hiệu ngắn gọn là p(θ) với các tham số ηt={αt,µ1:J,t,Λ−1 1:J,t}. Chúng tôi mô hình các Gaussian với một hiệp phương sai đường chéo. ProtoCL mô hình mỗi nguyên mẫu lớp nhưng không sử dụng các tham số hoặc mô-đun NN cụ thể theo nhiệm vụ như VCL đa đầu. ProtoCL sử dụng một mô hình xác suất trên một không gian nhúng cho phép nó sử dụng các hàm nhúng mạnh mẽ

--- TRANG 11 ---
Entropy 2023 ,1, 0 11 của 28
Thuật toán 1 Học liên tục ProtoCL
1:Đầu vào: tập dữ liệu nhiệm vụ T1:T, khởi tạo hàm nhúng: f(·;w), coreset: M=∅.
2:cho T1 đến TT làm
3: cho mỗi batch trong Ti∪ M làm
4: Tối ưu hóa f(·;w) bằng cách tối đa hóa dự đoán hậu nghiệm p(z,y) eq. (17)
5: Thu được hậu nghiệm trên θ bằng cách cập nhật η, eqs. (14) đến (16).
6: kết thúc cho
7: Thêm tập con ngẫu nhiên từ Ti vào M.
8:kết thúc cho

f(·;w) mà không cần phải tham số hóa chúng một cách xác suất và do đó cách tiếp cận này sẽ có thể mở rộng hơn VCL, chẳng hạn.

Suy luận. Vì tiên nghiệm Dirichlet liên hợp với phân phối Phân loại và tương tự Gaussian trên nguyên mẫu với một tiên nghiệm Gaussian trên trung bình nguyên mẫu, chúng ta có thể tính toán hậu nghiệm dưới dạng đóng và cập nhật các tham số ηt khi dữ liệu mới được quan sát mà không sử dụng các cập nhật dựa trên gradient. Chúng tôi tối ưu hóa mô hình bằng cách tối đa hóa phân phối dự đoán hậu nghiệm và sử dụng softmax trên xác suất lớp để thực hiện dự đoán. Chúng tôi thực hiện học dựa trên gradient của hàm nhúng NN f(·;w) và cập nhật các tham số, ηt tại mỗi lần lặp của gradient descent cũng như, xem thuật toán 1.

Cập nhật tuần tự. Chúng ta có thể thu được các cập nhật tham số của chúng ta cho hậu nghiệm Dirichlet bằng liên hợp Categorical-Dirichlet:
αt+1,j=αt,j+Nt ∑ i=1I(yi t=j), (14)
trong đó Nt là số điểm được thấy trong quá trình cập nhật tại bước thời gian t. Ngoài ra, do liên hợp Gaussian-Gaussian, hậu nghiệm cho các nguyên mẫu Gaussian được điều chỉnh bởi:
Λyt+1=Λyt+NyΣ−1 ϵ (15)
Λyt+1µyt+1=NyΣ−1 ϵ¯zyt+Λytµyt,∀yt∈Ct, (16)
trong đó Ny là số mẫu của lớp y và ¯zyt= (1/Ny)∑Ny i=1zyi, xem phụ lục F để biết sự dẫn xuất chi tiết.

Mục tiêu. Chúng tôi tối ưu hóa phân phối dự đoán hậu nghiệm của các nguyên mẫu và lớp:
p(z,y) =Z p(z,y|θt;ηt)p(θt;ηt)dθt=p(y)Nt ∏ i=1N(zit|yit;µyt,t,Σϵ+Λ−1 yt,t). (17)
Trong đó p(y) =αy/∑J j=1αj, xem phụ lục F.3 để biết sự dẫn xuất chi tiết. Mục tiêu này sau đó có thể được tối ưu hóa bằng cách sử dụng tối ưu hóa dựa trên gradient để học hàm nhúng nguyên mẫu z=f(x;w).

Dự đoán. Để đưa ra dự đoán cho một điểm kiểm tra x∗, lớp có (log)- hậu nghiệm dự đoán tối đa được chọn, trong đó hậu nghiệm dự đoán là:
p(y∗=j|x∗,x1:t,y1:t) =p(y∗=j|z∗,θt) =p(y∗=j,z∗|θt) ∑ip(y=i,z∗|θt), (18)
xem phụ lục F.4 để biết thêm chi tiết.

Ngăn chặn quên lãng. Chúng tôi sử dụng coresets để giữ lại các nguyên mẫu lớp. Coresets là dữ liệu được lấy mẫu ngẫu nhiên từ các nhiệm vụ trước đây sau đó được lưu trữ cùng nhau trong một bộ đệm phát lại và được thêm vào tập dữ liệu huấn luyện nhiệm vụ tiếp theo. Khi kết thúc việc học một nhiệm vụ Tt, chúng tôi giữ lại một tập con Mt⊂ D t và tăng cường mỗi tập dữ liệu nhiệm vụ mới để đảm bảo rằng các tham số hậu nghiệm ηt và nguyên mẫu có thể giữ lại thông tin nhiệm vụ trước đây. Không có coreset, độ chính xác trung bình trên Split-MNIST là 33.25±0.15, hình 7 thấp hơn đáng kể so với 93.73±1.05 từ bảng 1.

--- TRANG 12 ---
Entropy 2023 ,1, 0 12 của 28
[Hình 7. Độ chính xác kiểm tra trung bình Split-MNIST trên 5 nhiệm vụ cho các kích thước bộ nhớ khác nhau. Trên trục x chúng tôi hiển thị kích thước của toàn bộ bộ đệm bộ nhớ được chia sẻ bởi tất cả 5 nhiệm vụ. Độ chính xác là trên trung bình và độ lệch chuẩn trên 5 lần chạy khác nhau với các hạt giống ngẫu nhiên khác nhau.]

Vậy cơ chế chính để ngăn chặn quên lãng là bộ đệm phát lại cho phép mạng duy trì một nguyên mẫu cho mỗi lớp, thay vì suy luận Bayesian tuần tự trong không gian nhúng nguyên mẫu tương tự như các phương pháp điều chỉnh chức năng Bayesian [53].

Học tăng dần theo lớp. Trong thiết lập CL này, chúng tôi không cho tác nhân CL biết nhiệm vụ nào nó đang được đánh giá với một định danh nhiệm vụ t. Vì vậy chúng ta không thể sử dụng định danh nhiệm vụ để chọn một đầu cụ thể để sử dụng cho việc phân loại một điểm kiểm tra, chẳng hạn. Ngoài ra, chúng tôi yêu cầu tác nhân CL xác định mỗi lớp, {0,. . ., 9} cho Split-MNIST và Split-CIFAR10 chẳng hạn, và không chỉ {0, 1} như trong học tăng dần theo miền. Học tăng dần theo lớp tổng quát hơn, thực tế hơn và khó hơn một thiết lập vấn đề và do đó quan trọng để tập trung vào thay vì các thiết lập khác, mặc dù học tăng dần theo miền cũng tương thích với suy luận Bayesian tuần tự như mô tả trong eq. (3).

Triển khai. Đối với Split-MNIST và Split-FMNIST, các đường cơ sở và ProtoCL đều sử dụng NN hai lớp với kích thước trạng thái ẩn là 200. Đối với Split-CIFAR10 và Split-CIFAR100, các đường cơ sở và ProtoCL sử dụng mạng nơ-ron tích chập bốn lớp với hai lớp được kết nối đầy đủ có kích thước 512 tương tự như Pan et al. [22]. Đối với ProtoCL và tất cả các đường cơ sở dựa vào phát lại, chúng tôi cố định kích thước của coreset thành 200 điểm cho mỗi nhiệm vụ. Đối với tất cả các mô hình ProtoCL, chúng tôi cho phép các tham số Dirichlet tiên nghiệm được học và đặt giá trị ban đầu của chúng thành 0.7 được tìm thấy bằng tìm kiếm ngẫu nhiên trên MNIST với ProtoCL. Một siêu tham số quan trọng cho ProtoCL là chiều nhúng của các nguyên mẫu Gaussian cho Split-MNIST và Split-FMNIST được đặt thành 128 trong khi đối với các tập dữ liệu thị giác lớn hơn, điều này được đặt thành 32 được tìm thấy bằng tìm kiếm lưới.

[Bảng 1. Độ chính xác trung bình trên tất cả các nhiệm vụ trên các điểm chuẩn thị giác CL cho học tăng dần theo lớp [17]. Tất cả kết quả là trung bình và lỗi chuẩn trên 10 hạt giống. ∗ Sử dụng entropy dự đoán để đưa ra quyết định về đầu nào cho học tăng dần theo lớp.]

[Bảng 2. Độ chính xác trung bình trên tất cả các nhiệm vụ trên các điểm chuẩn thị giác CL cho học tăng dần theo lớp [17]. Tất cả kết quả là trung bình và lỗi chuẩn trên 10 hạt giống. ∗ Sử dụng entropy dự đoán để đưa ra quyết định về đầu nào cho học tăng dần theo lớp. Thời gian huấn luyện đã được đo điểm chuẩn bằng GPU Nvidia RTX3090.]

Kết quả. ProtoCL tạo ra kết quả tốt trên các điểm chuẩn CL ngang bằng hoặc tốt hơn S-FSVI [46] là hiện đại nhất trong các phương pháp CL Bayesian trong khi hiệu quả hơn nhiều để huấn luyện và không yêu cầu suy luận biến phân đắt đỏ. ProtoCL có thể mở rộng linh hoạt cho các điểm chuẩn thị giác CL lớn hơn tạo ra kết quả tốt hơn S-FSVI. Mã để tái tạo tất cả các thí nghiệm có thể được tìm thấy tại đây https://github.com/skezle/bayes_cl_posterior. Tất cả các thí nghiệm của chúng tôi đều trong thiết lập học tăng dần theo lớp thực tế hơn, đây là một thiết lập khó hơn so với những gì được báo cáo trong hầu hết các bài báo CL, vì vậy kết quả trong bảng 1 thấp hơn đối với một số đường cơ sở nhất định so với trong các bài báo tương ứng. Chúng tôi sử dụng 200 điểm dữ liệu cho mỗi nhiệm vụ, xem hình 7 để biết phân tích độ nhạy của hiệu suất trên điểm chuẩn Split-MNIST như một hàm của kích thước lõi cho ProtoCL.

Mục đích đã nêu của ProtoCL không phải là cung cấp một phương pháp hiện đại mới cho CL, mà đúng hơn là đề xuất một đường cơ sở đơn giản đi theo con đường thay thế hơn là suy luận Bayesian tuần tự không gian trọng số. Chúng ta có thể đạt được kết quả mạnh mẽ giảm thiểu quên lãng, cụ thể là bằng cách mô hình quá trình CL sinh và sử dụng suy luận Bayesian tuần tự trên một vài tham số trong không gian nhúng nguyên mẫu lớp. Chúng tôi lập luận rằng việc mô hình quá trình CL sinh là một hướng có thành quả cho nghiên cứu tiếp theo thay vì cố gắng suy luận Bayesian tuần tự trên trọng số của một BNN. ProtoCL mở rộng đến 10 nhiệm vụ của Split-CIFAR100 mà theo hiểu biết của chúng tôi, là số lượng nhiệm vụ và lớp nhiều nhất đã được xem xét bởi các phương pháp học liên tục Bayesian trước đây.

8. Thảo luận và Kết luận
Trong bài báo này, chúng tôi đã xem xét lại việc sử dụng suy luận Bayesian tuần tự cho CL. Chúng ta có thể sử dụng Bayes tuần tự để xây dựng đệ quy hậu nghiệm đa nhiệm vụ Phương trình (3). Các phương pháp trước đây đã dựa vào suy luận xấp xỉ và thấy ít lợi ích so với SGD. Chúng tôi kiểm tra giả thuyết về việc liệu hiệu suất kém này có do lược đồ suy luận xấp xỉ bằng cách sử dụng HMC trong hai vấn đề CL đơn giản hay không. HMC lấy mẫu tiệm cận từ hậu nghiệm thật, và chúng tôi sử dụng một bộ ước lượng mật độ trên các mẫu HMC để sử dụng như một tiên nghiệm cho một nhiệm vụ mới trong quá trình lấy mẫu HMC. Chúng tôi thực hiện nhiều kiểm tra cho sự hội tụ HMC. Mật độ này là đa phương thức và chính xác đối với nhiệm vụ hiện tại nhưng không thể cải thiện so với việc sử dụng một hậu nghiệm xấp xỉ. Điều này chứng minh việc làm việc với hậu nghiệm trọng số BNN khó khăn như thế nào. Nguồn gốc của lỗi đến từ bước ước lượng mật độ. Sau đó chúng tôi xem xét một ví dụ phân tích về suy luận Bayesian tuần tự trong đó chúng tôi thực hiện suy luận chính xác; tuy nhiên, do xác định sai mô hình, chúng tôi quan sát quên lãng. Cách duy nhất để đảm bảo một mô hình được xác định tốt là đánh giá hiệu suất đa nhiệm vụ trên tất cả các nhiệm vụ a priori. Điều này có thể không khả thi trong các thiết lập CL trực tuyến. Sau đó chúng tôi mô hình một ví dụ phân tích trên BNN Bayesian và, dưới các giả định nhất định, chỉ ra rằng nếu có mất cân bằng dữ liệu nhiệm vụ thì điều này sẽ gây ra quên lãng; mất cân bằng dữ liệu là một vấn đề phổ biến trong nhiều lĩnh vực học máy ngoài học liên tục [54]. Suy luận Bayesian tuần tự cũng không được miễn trừ khỏi tác động của mất cân bằng dữ liệu nhiệm vụ. Bởi vì những kết quả này, chúng tôi lập luận chống lại việc thực hiện suy luận Bayesian tuần tự không gian trọng số

--- TRANG 14 ---
Entropy 2023 ,1, 0 14 của 28
và thay vào đó mô hình vấn đề CL sinh. Chúng tôi giới thiệu một đường cơ sở đơn giản gọi là ProtoCL. ProtoCL không yêu cầu tối ưu hóa biến phân phức tạp và đạt được kết quả cạnh tranh với hiện đại trong thiết lập thực tế của học tăng dần theo lớp.

Kết luận này không nên là một bất ngờ vì các bài báo CL Bayesian mới nhất đều dựa vào kiến trúc đa đầu hoặc điểm cảm ứng/coresets để ngăn chặn quên lãng, thay vì các lược đồ suy luận không gian trọng số tốt hơn. Quan sát của chúng tôi phù hợp với lý thuyết gần đây từ [55], nêu rằng CL tối ưu yêu cầu bộ nhớ hoàn hảo. Mặc dù kết quả được chỉ ra với NN xác định, kết quả tương tự cũng đúng cho BNN với một tập hợp tham số duy nhất. Nỗ lực nghiên cứu tương lai nên tập trung vào các cách tiếp cận chức năng hơn cho suy luận Bayesian tuần tự, trong đó các hàm nhiệm vụ trước đây được nhớ [22,45,53]. Điều này chuyển vấn đề nhớ các hàm nhiệm vụ trước đây thành một coreset tương tự như Quá trình Gaussian suy luận biến phân thưa [56,57].

Đóng góp của Tác giả: S.K dẫn đầu nghiên cứu bao gồm khái niệm hóa, thực hiện các thí nghiệm và viết bài báo. S.J.R giúp đỡ với khái niệm hóa. A.C giúp đỡ với việc phát triển ý tưởng và triển khai HMC với một bộ ước lượng mật độ như một tiên nghiệm. T.G.J.R chạy các đường cơ sở S-FSVI cho các thí nghiệm học liên tục tăng dần theo lớp. T.G.J.R, A.C và S.J.R giúp viết bài báo.

Tài trợ: S.K. thừa nhận tài trợ từ Viện Tài chính Định lượng Oxford-Man. T.G.J.R. thừa nhận tài trợ từ Rhodes Trust, Qualcomm, và Hội đồng Nghiên cứu Khoa học Kỹ thuật và Vật lý (EPSRC). Tài liệu này dựa trên công việc được hỗ trợ bởi Không quân Hoa Kỳ và DARPA dưới Hợp đồng số FA8750-20-C-0002. Bất kỳ ý kiến, phát hiện và kết luận hoặc khuyến nghị nào được thể hiện trong tài liệu này là của (các) tác giả và không nhất thiết phản ánh quan điểm của Không quân Hoa Kỳ và DARPA.

Tuyên bố Hội đồng Đánh giá Thể chế: Không áp dụng.

Tuyên bố Sẵn có Dữ liệu: Tất cả dữ liệu đều có sẵn công khai, mã để tái tạo tất cả các thí nghiệm có thể được tìm thấy tại đây https://github.com/skezle/bayes_cl_posterior.

Lời cảm ơn: Chúng tôi muốn cảm ơn Sebastian Farquhar, Laurence Aitchison, Jeremias Knoblauch, và Chris Holmes cho các cuộc thảo luận. Chúng tôi cũng muốn cảm ơn Philip Ball vì sự giúp đỡ trong việc viết bài báo.

Xung đột Lợi ích: Các tác giả tuyên bố không có xung đột lợi ích. Các nhà tài trợ không có vai trò trong việc thiết kế nghiên cứu; trong việc thu thập, phân tích hoặc diễn giải dữ liệu; trong việc viết bản thảo; hoặc trong quyết định xuất bản kết quả.

--- TRANG 15 ---
Entropy 2023 ,1, 0 15 của 28
Viết tắt
Các viết tắt sau được sử dụng trong bản thảo này:
CL Học liên tục
NN Mạng Nơ-ron
BNN Mạng Nơ-ron Bayesian
HMC Hamiltonian Monte Carlo
VCL Học liên tục Biến phân
SGD Stochastic Gradient Descent
SH Đơn Đầu
MH Đa đầu
GMM Mô hình Hỗn hợp Gaussian
ProtoCL Học liên tục Bayesian Nguyên mẫu

--- TRANG 16 ---
Entropy 2023 ,1, 0 16 của 28
Phụ lục
Mục lục
A Kịch bản Thí nghiệm Học liên tục . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
B Thước đo Học liên tục . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
C Tập dữ liệu Gaussian Đồ chơi . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
D Chi tiết Triển khai HMC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
E Chẩn đoán Ước lượng Mật độ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
F Học liên tục Bayesian Nguyên mẫu . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
F.1 Suy luận . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
F.2 Cập nhật Tuần tự . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
F.3 Mục tiêu ProtoCL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
F.4 Dự đoán . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
F.5 Thiết lập Thí nghiệm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
G Ước lượng Bayesian Tuần tự như Tối ưu hóa Mạng Nơ-ron Bayesian . . 24
H. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26

Phụ lục A. Kịch bản Thí nghiệm Học liên tục
Để đánh giá các phương pháp học liên tục khác nhau, chúng ta cần định nghĩa các kịch bản học liên tục thường được sử dụng trong tài liệu và xuyên suốt bài báo này.

Công trình trước đây đã giới thiệu các mô hình cho học liên tục trong đó các kiến trúc NN được sử dụng một bộ trích xuất đặc trưng được chia sẻ giữa tất cả các nhiệm vụ học liên tục, nhưng một lớp tuyến tính từ đặc trưng đến đầu ra riêng biệt được huấn luyện cho mỗi nhiệm vụ và sau đó được đóng băng [15]. Ngoài ra, các công trình khác đã tìm kiếm các phương pháp không yêu cầu việc lựa chọn thủ công này của các đầu tuyến tính từ đặc trưng đến đầu ra khác nhau và đề xuất một lớp tuyến tính từ đặc trưng đến đầu ra duy nhất được chia sẻ giữa tất cả các nhiệm vụ trong học liên tục [58]. Trong phần này, chúng tôi sẽ phân loại và diễn giải có hệ thống các kịch bản học liên tục khác nhau, tương tự như công trình quan trọng trước đây [16,17].

Về mặt ký hiệu, một nhiệm vụ Tt có thể được đặc trưng bởi các phân phối dữ liệu có điều kiện và biên pt(y|x) và pt(x) và một định danh nhiệm vụ t chúng ta ký hiệu các mẫu từ các phân phối y∼pt(y) và x∼pt(x).

Học tăng dần theo nhiệm vụ. Đây là kịch bản đầu tiên và thường là kịch bản dễ nhất cho học liên tục. Mỗi nhiệm vụ là một tập con của các lớp trong tập dữ liệu trong đó các miền đầu vào là rời rạc p1(x)̸=p2(x) trong khi các không gian đầu ra được chia sẻ giữa tất cả các nhiệm vụ p1(y) =p2(y) một định danh nhiệm vụ cũng có sẵn t. Ví dụ, đối với Split CIFAR10, tất cả các nhiệm vụ đều là các vấn đề phân loại nhị phân, và các lớp đều được ánh xạ thành {0, 1} cho mỗi nhiệm vụ. Định danh nhiệm vụ có thể được sử dụng để chọn một lớp tuyến tính khác nhau cho mỗi nhiệm vụ [3,9,15] — được mô tả như một mạng đa đầu. Định danh nhiệm vụ có thể được sử dụng trong quá trình huấn luyện và để đánh giá.

Học tăng dần theo miền. Trong kịch bản này, miền tăng rõ ràng, vì p1(x)̸=p2(x) nhưng người học được yêu cầu giữ lại kiến thức về các miền trước đây. Các không gian đầu ra vẫn được chia sẻ bởi tất cả các nhiệm vụ p1(y) =p2(y). Trái ngược với học tăng dần theo nhiệm vụ, không có định danh nhiệm vụ nào có sẵn cho tác nhân học liên tục.

Học tăng dần theo lớp. Trong kịch bản này, miền tăng p1(x)̸=p2(x) khi số lượng nhiệm vụ tăng, trong khi số lượng lớp được nhìn thấy tăng khi số lượng nhiệm vụ tăng, vì vậy p1(y)̸=p2(y). Ngoài ra, không có định danh nhiệm vụ nào có sẵn cho tác nhân. Một ví dụ được minh họa trong hình A1.

Mạng đa đầu so với đơn đầu. Một lựa chọn thiết kế phổ biến không chỉ được sử dụng trong học liên tục là có một lớp tuyến tính đầu ra cho mỗi nhiệm vụ, hoặc một đầu tuyến tính cho mỗi nhiệm vụ, h, ánh xạ thành đầu ra h:Z → Y, trong đó y∈ Y. Sao cho một tác nhân học liên tục sử dụng một đầu riêng biệt cho mỗi nhiệm vụ {hi}T i=1, những phương pháp này được gọi là đa đầu trong khi những phương pháp sử dụng một đầu được gọi là đơn đầu. Lưu ý rằng các mạng đa đầu chỉ tương thích với học tăng dần theo nhiệm vụ vì chúng yêu cầu kiến thức về một định danh nhiệm vụ, t, để chọn một đầu mới trong quá trình huấn luyện và đầu tương ứng với một nhiệm vụ cụ thể trong quá trình đánh giá. Mặt khác, mạng đơn đầu không yêu cầu kiến thức về định danh nhiệm vụ trong quá trình huấn luyện và đánh giá và do đó tương thích với học tăng dần theo miền và theo lớp.

--- TRANG 17 ---
Entropy 2023 ,1, 0 17 của 28
[Hình A1. Ba kịch bản học liên tục. Ví dụ điểm dữ liệu từ 2 nhiệm vụ từ điểm chuẩn Split CIFAR10. Nhiệm vụ đầu tiên là phân loại nhị phân máy bay so với ô tô và nhiệm vụ thứ hai là phân loại nhị phân chim so với mèo. Trong mỗi hàng chúng ta có một nhiệm vụ khác nhau, trong mỗi hàng con trong mỗi nhiệm vụ lớp chính xác y cần được dự đoán được liệt kê, và định danh nhiệm vụ, t, được hiển thị. Hỗ trợ của các nhãn lớp rời rạc được định nghĩa là supp(P(y)) ={y∈ {0, . . . , 9 }:P(y)>0}.]

Phụ lục B. Thước đo Học liên tục
Tôi sẽ định nghĩa các thước đo được sử dụng để đo hiệu suất của các tác nhân học liên tục có giám sát và được sử dụng trong các thiết lập thí nghiệm trong bài báo này.

Hiệu suất Trung bình. Cho pk,j là hiệu suất của tác nhân học liên tục, hiệu suất cao hơn là tốt hơn, như độ chính xác trên tập kiểm tra j sau khi huấn luyện tăng dần trên các nhiệm vụ 1,. . .,k và j≤k. Sau đó hiệu suất trung bình tại nhiệm vụ k được định nghĩa là:
Pk=1 k k ∑ i=1pk,i. (A1)
Hiệu suất trung bình Pk cao hơn trên tất cả các nhiệm vụ 1,. . .,j thì người học liên tục càng tốt trong việc học tất cả các nhiệm vụ T:j đã thấy cho đến nay. Đối với phân loại, hiệu suất pk,j là độ chính xác ak,j và đối với một điểm chuẩn kinh điển như Split MNIST có 5 nhiệm vụ tổng cộng thì chúng ta đo hiệu suất ở cuối việc huấn luyện trên nhiệm vụ cuối cùng tức là k=5:
P5=1 5 5 ∑ i=1a5,i (A2)
tính trung bình hiệu suất trên các tập kiểm tra j=1,. . ., 5. Đây là thước đo chính được sử dụng xuyên suốt bài báo vì nó đồng thời đo mức độ tốt của một người học liên tục có thể thực hiện một nhiệm vụ cụ thể và mức độ tốt của nó trong việc giữ lại kiến thức và ngăn chặn quên thảm khốc.

--- TRANG 18 ---
Entropy 2023 ,1, 0 18 của 28
Quên lãng Trung bình. Điều này được định nghĩa là sự khác biệt giữa hiệu suất sau khi một nhiệm vụ được huấn luyện và hiệu suất hiện tại. Sự khác biệt này định nghĩa khoảng cách hiệu suất và do đó mô hình đã quên bao nhiều cách thực hiện một nhiệm vụ. Quên lãng cho nhiệm vụ j sau khi học k nhiệm vụ 1, . . . , k và j<k được định nghĩa là:
fk j=pj,j−pk,j,∀j<k. (A3)
Quên lãng trung bình chỉ có thể được định nghĩa cho k−1 nhiệm vụ trước đó là:
Fk=1 k−1 k−1 ∑ j=1fk j. (A4)
Một Fk gần không ngụ ý ít quên lãng. Quên lãng âm ngụ ý rằng hiệu suất cải thiện trong suốt học liên tục và người học có thể chuyển giao kiến thức từ các nhiệm vụ tương lai khi được đánh giá trên các nhiệm vụ trước đây. Đây là một tính chất rất mong muốn nhưng hiếm của một người học liên tục. Fk dương cho biết quên lãng và hiệu suất trên nhiệm vụ j giảm sau khi học nhiệm vụ k. Một lưu ý thận trọng: chúng ta có thể không bị quên lãng trong khi người học của chúng ta chưa học được gì cả: và pk,j=0,∀j ngụ ý không quên lãng Fk=0 điều này cũng không mong muốn.

Cận trên Hiệu suất Một cận trên của hiệu suất là mức độ tốt của mô hình học liên tục có thể làm so với một mô hình đa nhiệm vụ có thể học từ tất cả các nhiệm vụ cùng một lúc. Một cận trên khác về hiệu suất là hiệu suất nhiệm vụ đơn; hiệu suất của việc huấn luyện một mô hình học máy khác nhau trên mỗi nhiệm vụ riêng lẻ, mô hình này sẽ không được hưởng lợi từ việc chuyển giao có sẵn cho mô hình đa nhiệm vụ.

Hiệu suất đa nhiệm vụ như một cận trên là tự nhiên đối với các điểm chuẩn thị giác máy tính học liên tục vì các nhiệm vụ được xây dựng bằng cách tạo tập con các lớp. Trong suy luận Bayesian tuần tự, cận trên về hiệu suất là hậu nghiệm đa nhiệm vụ mà hậu nghiệm tuần tự xây dựng thông qua các cập nhật Bayesian tuần tự eq. (5). Như chúng ta thảo luận trong phần 4, hiệu suất đa nhiệm vụ Bayesian có thể dưới tối ưu cho vấn đề học liên tục mà chúng ta muốn giải quyết và giải pháp học liên tục có thể vượt trội hơn giải pháp đa nhiệm vụ.

Phụ lục C. Tập dữ liệu Gaussian Đồ chơi
Xem Hình A2 để có hình ảnh trực quan về tập dữ liệu Gaussian đồ chơi, mà chúng tôi sử dụng như một vấn đề CL đơn giản. Điều này được sử dụng để đánh giá phương pháp của chúng tôi để truyền hậu nghiệm thật bằng cách sử dụng HMC cho suy luận hậu nghiệm và sau đó sử dụng một bộ ước lượng mật độ trên các mẫu HMC như một tiên nghiệm cho một nhiệm vụ mới. Chúng tôi xây dựng 5 vấn đề phân loại 2 chiều cho CL. Mỗi nhiệm vụ 2 chiều liên quan đến việc phân loại các hình tròn và hình vuông liền kề Hình A2. Với một mạng 2 lớp với 10 nơ-ron, chúng tôi đạt được độ chính xác kiểm tra 1.0 cho việc học đa nhiệm vụ của tất cả 5 nhiệm vụ cùng nhau. Do đó, theo Phương trình (3), một BNN với cùng kích thước sẽ có thể học tất cả 5 nhiệm vụ phân loại nhị phân liên tục bằng cách tuần tự xây dựng hậu nghiệm.

Phụ lục D. Chi tiết Triển khai HMC
Chúng tôi đặt tiên nghiệm cho T1, top1(θ) =N(0,τ−1I) với τ=10. Chúng tôi burn-in chuỗi HMC trong 1000 bước và lấy mẫu trong 10, 000 bước nữa và chạy 20 chuỗi khác nhau để thu được các mẫu từ hậu nghiệm của chúng tôi, sau đó chúng tôi chuyển cho bộ ước lượng mật độ của chúng tôi. Chúng tôi sử dụng kích thước bước 0.001 và độ dài quỹ đạo L=20, xem Phụ lục E để biết thêm chi tiết triển khai của quy trình ước lượng mật độ. Đối với GMM, chúng tôi tối ưu hóa số lượng thành phần bằng cách sử dụng một tập holdout của các mẫu HMC.

Phụ lục E. Chẩn đoán Ước lượng Mật độ
Chúng tôi cung cấp các biểu đồ để chỉ ra rằng các chuỗi HMC thực sự lấy mẫu từ hậu nghiệm đã hội tụ trong Hình A4 và A6. Chúng tôi chạy 20 chuỗi lấy mẫu HMC và chọn ngẫu nhiên một chuỗi để vẽ cho mỗi hạt giống (của 10). Chúng tôi chạy HMC trên 10 hạt giống và tổng hợp các

--- TRANG 19 ---
Entropy 2023 ,1, 0 19 của 28
kết quả Hình 3 và A2. Các hậu nghiệm p(θ|D1),. . . được xấp xỉ với một GMM và được sử dụng như một tiên nghiệm cho nhiệm vụ thứ hai và tiếp theo.

Chúng tôi cung cấp bằng chứng thực nghiệm để chỉ ra rằng các bộ ước lượng mật độ đã khớp với các mẫu HMC của hậu nghiệm trong Hình A3 và A5, nơi chúng tôi hiển thị số lượng thành phần của bộ ước lượng mật độ GMM, mà chúng tôi sử dụng như một tiên nghiệm cho một nhiệm vụ mới, đều là các hậu nghiệm đa phương thức. Chúng tôi hiển thị độ chính xác BNN khi lấy mẫu trọng số BNN từ GMM của chúng tôi đều phục hồi độ chính xác của các mẫu HMC đã hội tụ. Kích thước mẫu hiệu quả (ESS) của 20 chuỗi là một thước đo mức độ tương quan của các mẫu (cao hơn là tốt hơn). Các giá trị ESS được báo cáo cho các thí nghiệm của chúng tôi phù hợp với công trình trước đây sử dụng HMC cho suy luận BNN [20].

[Hình A2. Độ chính xác phân loại nhị phân học liên tục từ tập dữ liệu Gaussian đồ chơi tương tự như [43] sử dụng 10 hạt giống ngẫu nhiên. Đường liền nét màu hồng là độ chính xác cơ sở đa nhiệm vụ (MT) kiểm tra sử dụng SGD/HMC.]

[Hình A3. Chẩn đoán từ việc sử dụng một tiên nghiệm GMM khớp với các mẫu của hậu nghiệm được tạo ra từ HMC, tất cả kết quả là cho 10 hạt giống ngẫu nhiên. Trái, kích thước mẫu hiệu quả (ESS) của các chuỗi HMC kết quả của hậu nghiệm, tất cả đều lớn hơn những gì được báo cáo trong các công trình khác sử dụng HMC cho BNN [20]. Giữa, độ chính xác của BNN khi sử dụng các mẫu từ bộ ước lượng mật độ GMM thay vì các mẫu từ HMC. Phải, Số lượng thành phần tối ưu của mỗi hậu nghiệm GMM được khớp với một tập holdout của các mẫu HMC bằng cách tối đa hóa likelihood.]

[Hình A4. Biểu đồ hội tụ từ một chuỗi HMC được lấy mẫu ngẫu nhiên (của 20) cho mỗi nhiệm vụ trên 10 lần chạy khác nhau (hạt giống) cho 5 nhiệm vụ từ tập dữ liệu Gaussian đồ chơi tương tự như Henning et al. [43] (được trực quan hóa trong Hình A2). Chúng tôi sử dụng một bộ ước lượng mật độ GMM như tiên nghiệm có điều kiện trên dữ liệu nhiệm vụ trước đó.]

--- TRANG 20 ---
Entropy 2023 ,1, 0 20 của 28
[Hình A5. Chẩn đoán từ việc sử dụng GMM để khớp các mẫu của các mẫu HMC hậu nghiệm, tất cả kết quả là cho 10 hạt giống ngẫu nhiên trên tập dữ liệu đồ chơi từ Pan et al. [22] (và được trực quan hóa trong Hình 3). Trái, kích thước mẫu hiệu quả (ESS) của các chuỗi HMC kết quả của hậu nghiệm, tất cả đều lớn hơn những gì được báo cáo trong các công trình khác sử dụng HMC cho BNN [20]. Giữa trái, độ chính xác nhiệm vụ hiện tại từ lấy mẫu HMC. Giữa phải, độ chính xác của BNN khi sử dụng các mẫu từ bộ ước lượng mật độ GMM thay vì các mẫu HMC đã hội tụ. Phải, Số lượng thành phần tối ưu của mỗi hậu nghiệm GMM được khớp với một tập holdout của các mẫu HMC bằng cách tối đa hóa likelihood.]

[Hình A6. Biểu đồ hội tụ từ một chuỗi HMC được lấy mẫu ngẫu nhiên (của 20) cho mỗi nhiệm vụ trên 10 hạt giống khác nhau cho 5 nhiệm vụ từ tập dữ liệu đồ chơi từ [22] (xem Hình 3 để có hình ảnh trực quan về dữ liệu). Chúng tôi sử dụng một bộ ước lượng mật độ GMM như một tiên nghiệm.]

Phụ lục F. Học liên tục Bayesian Nguyên mẫu
ProtoCL mô hình quá trình sinh của CL trong đó các nhiệm vụ mới bao gồm các lớp mới j∈ {1,. . .,J} của tổng số J và có thể được mô hình bằng cách sử dụng một phân phối phân loại với một tiên nghiệm Dirichlet:
yi,t∼Cat(p1:J),p1:J∼Dir(αt). (A5)
Chúng tôi học một không gian nhúng chung cho dữ liệu của chúng tôi với một NN, z=f(x;w) với các tham số w. Không gian nhúng cho mỗi lớp là Gaussian có trung bình có một tiên nghiệm cũng là Gaussian:
zit|yit∼ N(¯zyt,Σϵ), ¯zyt∼ N(µyt,Λ−1 yt). (A6)
Bằng cách đảm bảo rằng chúng ta có một nhúng cho mỗi lớp và sử dụng một bộ nhớ của dữ liệu trước đây, chúng ta đảm bảo rằng nhúng không trôi. Các tham số hậu nghiệm là ηt= {αt,µ1:J,t,Λ−1 1:J,t}.

Phụ lục F.1. Suy luận
Vì tiên nghiệm Dirichlet liên hợp với phân phối phân loại và phân phối Gaussian cũng vậy với một tiên nghiệm Gaussian trên trung bình của nhúng, thì chúng ta có thể tính toán hậu nghiệm dưới dạng đóng và cập nhật các tham số của chúng ta khi chúng ta thấy dữ liệu mới trực tuyến mà không sử dụng các cập nhật dựa trên gradient. Chúng tôi thực hiện học dựa trên gradient của hàm nhúng NN f(·;w) với các tham số w. Chúng tôi tối ưu hóa mô hình bằng cách tối đa hóa log-predictive hậu nghiệm của dữ liệu và sử dụng softmax trên xác suất lớp để thực hiện dự đoán. Hậu nghiệm trên xác suất lớp {pj}J j=1 và nhúng lớp {¯zyj}J j=1 được ký hiệu là p(θ) cho ngắn gọn và có các tham số là ηt={αt,µ1:J,t,Λ−1 1:J,t} được cập nhật dưới dạng đóng tại mỗi lần lặp của gradient descent.

--- TRANG 21 ---
Entropy 2023 ,1, 0 21 của 28
Phụ lục F.2. Cập nhật Tuần tự
Chúng ta có thể thu được hậu nghiệm của chúng ta:
p(θt|Dt)∝p(Dt|θt)p(θt) (A7)
=Nt ∏ i=1p(zi t|yi t; ¯zyt,Σϵ,yt)p(yi t|p1:J)p(pi:J;αt)p(¯zyt;µyt,t,Λ−1 yt,t) (A8)
=N(µt+1,Σt+1)Dir(αt+1), (A9)
trong đó Nt là số điểm dữ liệu được thấy trong quá trình cập nhật t. Tập trung vào liên hợp Categorical-Dirichlet:
Dir(αt+1)∝p(p1:J;αt)Nt ∏ i=1p(yi t;pi:J) (A10)
∝J ∏ j=1pαj−1 j Nt ∏ i=1J ∏ j=1pI(yi t=j) j (A11)
=J ∏ j=1pαj−1+∑Nt i=1I(yi t=j) j. (A12)
Do đó:
αt+1,j=αt,j+Nt ∑ i=1I(yi t=j). (A13)
Hơn nữa, do liên hợp Gaussian-Gaussian, thì hậu nghiệm cho nguyên mẫu Gaussian của nhúng cho mỗi lớp là:
N(µt+1,Λt+1)∝Nt ∏ i=1N(zi t|yi t; ¯zyt,Σϵ)N(¯zyt;µyt,t,Λ−1 yt) (A14)
=∏ yt∈{1,..., J}N(zyt|yt; ¯zyt,1 Nyt Σϵ)N(¯zyt;µyt+1,Λ−1 yt) (A15)
=∏ yt∈{1,..., J}N(¯zyt;µt+1,Λ−1 yt+1), (A16)
trong đó Nyt là số điểm của lớp yt từ tập hợp tất cả các lớp C={1,. . .,J}. Các phương trình cập nhật cho trung bình và phương sai của hậu nghiệm là:
Λyt+1=Λyt+NytΣ−1 ϵ,∀yt∈Ct (A17)
Λyt+1µyt+1=NytΣ−1 ϵ¯zyt+Λytµyt,∀yt∈Ct. (A18)

Phụ lục F.3. Mục tiêu ProtoCL
Phân phối dự đoán hậu nghiệm mà chúng ta muốn tối ưu hóa là:
p(z,y) =Z p(z,y|θ;η)p(θ;η)dθ, (A19)

--- TRANG 22 ---
Entropy 2023 ,1, 0 22 của 28
trong đó p(θ) ký hiệu các phân phối trên xác suất lớp {pj}J j=1 và nhúng trung bình {¯zyj}J j=1,
p(z,y) =Z Nt ∏ i=1p(zit|yit; ¯zyt,Σϵ)p(yit|p1:J)p(p1:J;αt)p(¯zyt;µyt,t,Λ−1 yt,t)dp1:Jd¯zyt (A20)
=Z Nt ∏ i=1p(zit|yit;zyt,Σϵ)p(¯zyt;µyt,t,Λ−1 yt,t)d¯zyt Z Nt ∏ i=1p(yit|p1:J)p(p1:J;αt)dp1:J | {z } ∏ip(yi)=p(y) (A21)
=p(y)Nt ∏ i=1Z−1 i Z N(¯zyit;c,C)d¯zyt (A22)
=p(y)Nt ∏ i=1N(zit|yit;µyt,t,Σϵ+Λ−1 yt,t). (A23)
trong đó trong Phương trình (A22) chúng tôi sử dụng §8.1.8 trong [59]. Số hạng p(y) là:
p(y) =Z p(y|p1:J)p(p1:J;αt)dp1:J (A24)
=Z pyΓ(∑J j=1αj) ∏J j=1Γ(αj) J ∏ j=1pαj−1 j dp1:J (A25)
=Γ(∑J j=1αj) ∏J j=1Γ(αj) Z J ∏ j=1pI(y=j)+αj−1 j dp1:J (A26)
=Γ(∑J j=1αj) ∏J j=1Γ(αj) ∏J j=1Γ(I(y=j) +αj) Γ(1+∑J j=1αj) (A27)
=Γ(∑J j=1αj) ∏J j=1Γ(αj) ∏J j=1Γ(I(y=j) +αj) ∑J j=1αjΓ(∑J j=1αj) (A28)
=∏J j=1,j̸=yΓ(αj) ∏J j=1Γ(αj) Γ(1+αy) ∑J j=1αj (A29)
=∏J j=1,j̸=yΓ(αj) ∏J j=1Γ(αj) αyΓ(αy) ∑J j=1αj (A30)
=αy ∑J j=1αj, (A31)
trong đó chúng tôi sử dụng đồng nhất thức Γ(n+1) =nΓ(n).

--- TRANG 23 ---
Entropy 2023 ,1, 0 23 của 28
[Hình A7. Độ chính xác kiểm tra trung bình Split-MNIST trên năm nhiệm vụ cho các kích thước bộ nhớ khác nhau. Trên trục x, chúng tôi hiển thị kích thước của toàn bộ bộ đệm bộ nhớ được chia sẻ bởi tất cả năm nhiệm vụ. Độ chính xác là trên trung bình và độ lệch chuẩn trên năm lần chạy khác nhau với các hạt giống ngẫu nhiên khác nhau.]

[Hình A8. Sự tiến hóa của các tham số Dirichlet αt cho mỗi lớp trong các nhiệm vụ Split-MNIST cho ProtoCL. Tất cả αj được hiển thị trên 10 hạt giống với ±1 lỗi chuẩn. Vào cuối việc huấn luyện, tất cả các lớp đều có khả năng xảy ra gần như bằng nhau, vì chúng ta đã huấn luyện trên lượng bằng nhau của tất cả các lớp.]

Phụ lục F.4. Dự đoán
Để đưa ra dự đoán cho một điểm kiểm tra x∗:
p(y∗=j|x∗,x1:t,y1:t) =p(y∗=j|z∗,θt) (A32)
=p(z∗|y∗=j,θt)p(y∗=j|θt) ∑ip(z∗|y∗=i,ηt)p(y∗=i|θt) (A33)
=p(y∗=j,z∗|θt) ∑ip(y=i,z∗|θt), (A34)
trong đó θt là thống kê đầy đủ cho (x1:t,y1:t).

Ngăn chặn quên lãng. Vì chúng ta muốn giữ lại các nguyên mẫu cụ thể theo nhiệm vụ, ở cuối việc học một nhiệm vụ Tt chúng ta lấy một tập con nhỏ của dữ liệu làm bộ nhớ để đảm bảo rằng các tham số hậu nghiệm và nguyên mẫu không trôi, xem Thuật toán 1.

--- TRANG 24 ---
Entropy 2023 ,1, 0 24 của 28
Phụ lục F.5. Thiết lập Thí nghiệm
Phương sai nguyên mẫu, Σϵ được đặt thành một ma trận đường chéo với các phương sai của mỗi nguyên mẫu được đặt thành 0.05. Các độ chính xác tiên nghiệm nguyên mẫu, Λyt, cũng là đường chéo và được khởi tạo ngẫu nhiên và được exponential để đảm bảo một hiệp phương sai bán xác định dương cho các cập nhật tuần tự. Các tham số αj∀j được đặt thành 0.78, được tìm thấy bằng tìm kiếm ngẫu nhiên trên tập xác thực trên MNIST. Chúng tôi cũng cho phép αj được học trong bước cập nhật gradient ngoài bước cập nhật tuần tự (dòng 4 và 5 Thuật toán 1), xem Hình A8 để thấy sự tiến hóa của αj hoặc tất cả các lớp j trong quá trình học Split-MNIST.

Đối với các điểm chuẩn Split-MNIST và Split-FMNIST, chúng tôi sử dụng một NN với hai lớp có kích thước 200 và được huấn luyện trong 50 epoch với một bộ tối ưu hóa Adam. Chúng tôi thực hiện tìm kiếm lưới trên tốc độ học, tỷ lệ dropout, và hệ số weight decay. Chiều nhúng được đặt thành 128. Đối với các điểm chuẩn Split-CIFAR10 và Split-CIFAR100, chúng tôi sử dụng cùng mạng như Pan et al. [22], bao gồm bốn lớp tích chập và hai lớp tuyến tính. Chúng tôi huấn luyện các mạng trong 80 epoch cho mỗi nhiệm vụ với bộ tối ưu hóa Adam với tốc độ học 1×10−3. Chiều nhúng được đặt thành 32. Tất cả các thí nghiệm được chạy trên một GPU NVIDIA RTX 3090 duy nhất.

Phụ lục G. Ước lượng Bayesian Tuần tự như Tối ưu hóa Mạng Nơ-ron Bayesian
Chúng ta sẽ xem xét suy luận trong mô hình đồ thị được mô tả trong Hình A9. Mục tiêu là suy luận các trọng số BNN tối ưu, θ∗ t tại thời điểm t cho các quan sát và trọng số BNN trước đây. Chúng tôi giả định một hậu nghiệm Gaussian trên trọng số với hiệp phương sai đầy đủ; do đó, chúng tôi mô hình tương tác giữa tất cả các trọng số. Chúng ta sẽ xem xét thiết lập trực tuyến trong đó chúng ta thấy một điểm dữ liệu (xt,yt) tại một thời điểm và chúng ta sẽ không đưa ra giả định nào về việc liệu dữ liệu có đến từ cùng một nhiệm vụ hay các nhiệm vụ khác nhau trong quá trình học.

[Hình A9. Mô hình đồ thị mà dưới đó chúng tôi thực hiện suy luận trong Phần 5. Các nút màu xám được quan sát và màu trắng là các biến tiềm ẩn.]

Chúng tôi thiết lập vấn đề suy luận Bayesian tuần tự như một vấn đề lọc và chúng tôi tận dụng công trình của Aitchison [30], đúc tối ưu hóa NN như suy luận Bayesian tuần tự. Chúng tôi đưa ra giả định hợp lý rằng phân phối trên trọng số là một Gaussian với hiệp phương sai đầy đủ. Vì việc lý luận về ma trận hiệp phương sai đầy đủ của một BNN là không thể xử lý được, thay vào đó chúng tôi xem xét tham số thứ i và lý luận về động lực của các ước lượng tối ưu θ∗ it như một hàm của tất cả các tham số khác θ−it. Mỗi trọng số phụ thuộc chức năng vào tất cả các trọng số khác. Nếu chúng ta có quyền truy cập vào hiệp phương sai đầy đủ của các tham số, thì chúng ta có thể lý luận về các trọng số tối ưu chưa biết θ∗ it cho các giá trị của tất cả các trọng số khác θ−it. Tuy nhiên, vì chúng ta không có quyền truy cập vào hiệp phương sai đầy đủ, một cách tiếp cận khác là lý luận về động lực của θ∗ it cho động lực của θ−it và giả định rằng các giá trị của trọng số gần với những giá trị của bước thời gian trước đó [31] và vì vậy chúng ta đúc vấn đề như một hệ thống động lực.

Xem xét một mất mát bậc hai dạng:
L(xt,yt;θ) =Lt(θ) =−1 2θ⊤Hθ+z⊤ tθ, (A35)

--- TRANG 25 ---
Entropy 2023 ,1, 0 25 của 28
mà chúng ta có thể đạt được bằng khai triển Taylor đơn giản, trong đó H là Hessian được giả định là hằng số trên các điểm dữ liệu nhưng không trên các tham số θ. Nếu đầu ra BNN có dạng f(xt;θ), thì đạo hàm được đánh giá tại θt là zt=∂L(xt,yt;θ) ∂θ|θ=θt.

Để xây dựng các phương trình động lực cho trọng số của chúng ta, xem xét gradient cho một điểm dữ liệu duy nhất:
∂Lt(θ) ∂θ=−Hθ+zt. (A36)
Nếu chúng ta xem xét gradient cho trọng số thứ i trong khi tất cả các tham số khác được đặt thành ước lượng hiện tại của chúng:
∂L(θi,θ−i) ∂θi=−Hiiθit−H⊤ −iiθ−it+zti. (A37)
Khi gradient được đặt bằng không, chúng ta phục hồi giá trị tối ưu cho θit, ký hiệu là θ∗ it:
θ∗ it=−1 Hii H⊤ −iiθ−it. (A38)
vì zti=0 tại các mode. Phương trình trên cho chúng ta thấy rằng động lực của trọng số tối ưu θ∗ it phụ thuộc vào tất cả các giá trị hiện tại khác của các tham số θ−it. Tức là, động lực của θ∗ it được điều chỉnh bởi động lực của các trọng số θ−it. Động lực của θ−it là một quá trình ngẫu nhiên phức tạp phụ thuộc vào nhiều biến khác nhau. Vì việc lý luận về động lực là không thể xử lý được, thay vào đó chúng tôi giả định một quá trình Ornstein–Uhlenbeck rời rạc hóa cho các trọng số θ−it với tốc độ hoàn nguyên ϑ∈R+ và phương sai nhiễu η2 −i:
p(θ−i,t+1|θ−i,t) =N((1−ϑ)θ−it,η2 −i), (A39)
điều này ngụ ý rằng động lực cho trọng số tối ưu được định nghĩa bởi
p(θ∗ i,t+1|θ∗ i,t) =N((1−ϑ)θ∗ it,η2), (A40)
trong đó η2=η2 −iH⊤ −iiH−ii. Giả định tương tự được đưa ra trong Aitchison [30]. Điều này giả định một mô hình tiết kiệm của động lực. Cùng với likelihood của chúng ta:
p(yt|xt;θ∗ t) =N(yt;f(xt;θ∗ t),σ2) (A41)
trong đó f(·,θ) là một dự đoán mạng nơ-ron với trọng số θ, bây giờ chúng ta có thể định nghĩa một hệ thống động lực tuyến tính cho trọng số tối ưu θ∗ i bằng cách tuyến tính hóa BNN Bayesian [31] và bằng cách sử dụng động lực chuyển tiếp trong Phương trình (A40). Do đó, chúng ta có thể suy luận phân phối hậu nghiệm trên các trọng số tối ưu bằng cách sử dụng các cập nhật giống như bộ lọc Kalman [60]. Vì động lực và likelihood là Gaussian, thì tiên nghiệm và hậu nghiệm cũng là Gaussian, để dễ ký hiệu chúng tôi bỏ chỉ số i sao cho θ∗ it=θ∗ t:
p(θ∗ t|(x,y)t−1, . . . ,(x,y)1) =N(µt,prior ,σ2 t,prior) (A42)
p(θ∗ t|(x,y)t, . . . ,(x,y)1) =N(µt,post,σ2 t,post) (A43)
Bằng cách sử dụng động lực chuyển tiếp và tiên nghiệm, chúng ta có thể thu được các cập nhật dạng đóng:
p(θ∗ t|(x,y)t−1, . . . ,(x,y)1) =Z p(θ∗ t|θ∗ t−1)p(θ∗ t−1|(x,y)t−1, . . . ,(x,y)1)dθ∗ t−1 (A44)
N(θ∗ t;µt,prior ,σ2 t,prior) =Z N(θ∗ t;(1−ϑ)θ∗ t−1,η2)N(θ∗ t−1;µt−1,post ,σ2 t−1,post)dθ∗ t−1. (A45)

--- TRANG 26 ---
Entropy 2023 ,1, 0 26 của 28
Tích hợp θ∗ t−1 chúng ta có thể thu được các cập nhật cho tiên nghiệm cho bước thời gian tiếp theo như sau:
µt,prior= (1−ϑ)µt−1,post (A46)
σ2 t,prior=η2+ (1−ϑ)−2σ2 t−1,post . (A47)
Các cập nhật để thu được các tham số hậu nghiệm của chúng ta: µt,post và σ2 t,post, đến từ việc áp dụng định lý Bayes:
logN(θ∗ t;µt,post,σ2 t,post)∝logN(yt;f(xt;θ∗ t),σ2) +logN(θ∗ t;µt,prior ,σ2 t,prior), (A48)
bằng cách tuyến tính hóa BNN Bayesian của chúng ta sao cho f(xt,θ0)≈f(xt,θ0) +∂f(xt;θ∗ t) ∂θ∗ t (θ∗ t−θ0) và bằng cách thay thế vào Phương trình (A48) chúng ta thu được phương trình cập nhật của chúng ta cho hậu nghiệm của trung bình của các tham số BNN:
−1 2σ2 t,post (θ∗ t−µt,post)2=−1 2σ2 (y−g(xt)θ∗ t)2−1 2σ2 t,prior (θ∗ t−µt,prior)2 (A49)
µt,post=σ2 t,post   µt,prior σ2 t,prior +y σ2 g(xt)! , (A50)
trong đó g(xt) =∂f(xt;θ∗ t) ∂θ∗ t , và phương trình cập nhật cho phương sai của hậu nghiệm Gaussian là:
1 σ2 t,post =g(xt)2 σ2 +1 σ2 t,prior . (A51)
Từ các phương trình cập nhật của chúng ta, Phương trình (A50) và Phương trình (A51), chúng ta có thể nhận thấy rằng trung bình hậu nghiệm phụ thuộc tuyến tính vào tiên nghiệm và một số hạng phụ thuộc dữ liệu bổ sung. Những phương trình này tương tự như ví dụ lọc trong Phần 4. Do đó, dưới các giả định nhất định ở trên, một BNN sẽ hoạt động tương tự. Nếu tồn tại mất cân bằng dữ liệu nhiệm vụ, thì số hạng dữ liệu sẽ chiếm ưu thế so với số hạng tiên nghiệm trong Phương trình (A50) và có thể dẫn đến quên lãng các nhiệm vụ trước đây.

1. McCloskey, M.; Cohen, N.J. Catastrophic interference in connectionist networks: The sequential learning problem. In Psychology of learning and motivation ; Elsevier, 1989; Vol. 24, pp. 109–165.
2. French, R.M. Catastrophic forgetting in connectionist networks. Trends in cognitive sciences 1999 , 3, 128–135.
3. Kirkpatrick, J.; Pascanu, R.; Rabinowitz, N.; Veness, J.; Desjardins, G.; Rusu, A.A.; Milan, K.; Quan, J.; Ramalho, T.; Grabska-Barwinska, A.; et al. Overcoming catastrophic forgetting in neural networks. Proceedings of the National Academy of Sciences 2017 ,114, 3521–3526, [https://www.pnas.org/content/114/13/3521.full.pdf]. https://doi.org/10.1073/pnas.1611 835114.
4. MacKay, D.J. A practical Bayesian framework for backpropagation networks. Neural computation 1992 ,4, 448–472.
5. Graves, A. Practical variational inference for neural networks. Advances in neural information processing systems 2011 ,24.
6. Blundell, C.; Cornebise, J.; Kavukcuoglu, K.; Wierstra, D. Weight uncertainty in neural network. In Proceedings of the International Conference on Machine Learning. PMLR, 2015, pp. 1613– 1622.
7. Schwarz, J.; Czarnecki, W.; Luketina, J.; Grabska-Barwinska, A.; Teh, Y.W.; Pascanu, R.; Hadsell, R. Progress & compress: A scalable framework for continual learning. In Proceedings of the International Conference on Machine Learning. PMLR, 2018, pp. 4528–4537.
8. Ritter, H.; Botev, A.; Barber, D. Online structured laplace approximations for overcoming catastrophic forgetting. Advances in Neural Information Processing Systems 2018 ,31.

--- TRANG 27 ---
Entropy 2023 ,1, 0 27 của 28
9. Nguyen, C.V .; Li, Y.; Bui, T.D.; Turner, R.E. Variational Continual Learning. In Proceedings of the International Conference on Learning Representations, 2018.
10. Ebrahimi, S.; Elhoseiny, M.; Darrell, T.; Rohrbach, M. Uncertainty-Guided Continual Learning in Bayesian Neural Networks. In Proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, 2019, pp. 75–78.
11. Kessler, S.; Nguyen, V .; Zohren, S.; Roberts, S.J. Hierarchical indian buffet neural networks for bayesian continual learning. In Proceedings of the Uncertainty in Artificial Intelligence. PMLR, 2021, pp. 749–759.
12. Loo, N.; Swaroop, S.; Turner, R.E. Generalized Variational Continual Learning. In Proceedings of the International Conference on Learning Representations, 2020.
13. Neal, R.M.; et al. MCMC using Hamiltonian dynamics. Handbook of Markov chain Monte Carlo 2011 ,2, 2.
14. LeCun, Y.; Bottou, L.; Bengio, Y.; Haffner, P . Gradient-based learning applied to document recognition. Proceedings of the IEEE 1998 ,86, 2278–2324.
15. Zenke, F.; Poole, B.; Ganguli, S. Continual learning through synaptic intelligence. In Proceedings of the International Conference on Machine Learning. PMLR, 2017, pp. 3987–3995.
16. Hsu, Y.C.; Liu, Y.C.; Ramasamy, A.; Kira, Z. Re-evaluating continual learning scenarios: A categorization and case for strong baselines. arXiv preprint arXiv:1810.12488 2018 .
17. Van de Ven, G.M.; Tolias, A.S. Three scenarios for continual learning. arXiv preprint arXiv:1904.07734 2019 .
18. van de Ven, G.M.; Tuytelaars, T.; Tolias, A.S. Three types of incremental learning. Nature Machine Intelligence 2022 , pp. 1–13.
19. Chopin, N.; Papaspiliopoulos, O.; et al. An introduction to sequential Monte Carlo ; Vol. 4, Springer, 2020.
20. Cobb, A.D.; Jalaian, B. Scaling Hamiltonian Monte Carlo Inference for Bayesian Neural Networks with Symmetric Splitting. Uncertainty in Artificial Intelligence 2021 .
21. Izmailov, P .; Vikram, S.; Hoffman, M.D.; Wilson, A.G.G. What are Bayesian neural network posteriors really like? In Proceedings of the International conference on machine learning. PMLR, 2021, pp. 4629–4640.
22. Pan, P .; Swaroop, S.; Immer, A.; Eschenhagen, R.; Turner, R.; Khan, M.E.E. Continual deep learning by functional regularisation of memorable past. Advances in Neural Information Processing Systems 2020 ,33, 4453–4464.
23. Dinh, L.; Sohl-Dickstein, J.; Bengio, S. Density estimation using real NVP. arXiv preprint arXiv:1605.08803 2016 .
24. Bishop, C.M. Pattern recognition and machine learning ; springer, 2006.
25. Aljundi, R.; Lin, M.; Goujaud, B.; Bengio, Y. Gradient based sample selection for online continual learning. Advances in neural information processing systems 2019 ,32.
26. Aljundi, R.; Kelchtermans, K.; Tuytelaars, T. Task-free continual learning. In Proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 11254–11263.
27. De Lange, M.; Aljundi, R.; Masana, M.; Parisot, S.; Jia, X.; Leonardis, A.; Slabaugh, G.; Tuytelaars, T. A continual learning survey: Defying forgetting in classification tasks. arXiv preprint arXiv:1909.08383 2019 .
28. Wilson, A.G.; Izmailov, P . Bayesian deep learning and a probabilistic perspective of generalization. Advances in neural information processing systems 2020 ,33, 4697–4708.
29. Ciftcioglu, Ö.; Türkcan, E. Adaptive training of feedforward neural networks by Kalman filtering 1995 .
30. Aitchison, L. Bayesian filtering unifies adaptive and non-adaptive neural network optimization methods. Advances in Neural Information Processing Systems 2020 ,33, 18173–18182.
31. Jacot, A.; Gabriel, F.; Hongler, C. Neural tangent kernel: Convergence and generalization in neural networks. Advances in neural information processing systems 2018 ,31.
32. Thrun, S.; Mitchell, T.M. Lifelong robot learning. Robotics and autonomous systems 1995 ,15, 25–46.
33. Zeno, C.; Golan, I.; Hoffer, E.; Soudry, D. Task agnostic continual learning using online variational bayes. arXiv preprint arXiv:1803.10123 2018 .
34. Ahn, H.; Cha, S.; Lee, D.; Moon, T. Uncertainty-based continual learning with adaptive regularization. Advances in neural information processing systems 2019 ,32.
35. Farquhar, S.; Osborne, M.A.; Gal, Y. Radial bayesian neural networks: Beyond discrete support in large-scale bayesian deep learning. In Proceedings of the International Conference on Artificial Intelligence and Statistics. PMLR, 2020, pp. 1352–1362.

--- TRANG 28 ---
Entropy 2023 ,1, 0 28 của 28
36. Mehta, N.; Liang, K.; Verma, V .K.; Carin, L. Continual learning using a Bayesian nonparametric dictionary of weight factors. In Proceedings of the International Conference on Artificial Intelligence and Statistics. PMLR, 2021, pp. 100–108.
37. Kumar, A.; Chatterjee, S.; Rai, P . Bayesian structural adaptation for continual learning. In Proceedings of the International Conference on Machine Learning. PMLR, 2021, pp. 5850–5860.
38. Adel, T.; Zhao, H.; Turner, R.E. Continual learning with adaptive weights (claw). arXiv preprint arXiv:1911.09514 2019 .
39. Titsias, M.K.; Schwarz, J.; Matthews, A.G.d.G.; Pascanu, R.; Teh, Y.W. Functional Regularisation for Continual Learning with Gaussian Processes. In Proceedings of the ICLR, 2020.
40. Kapoor, S.; Karaletsos, T.; Bui, T.D. Variational auto-regressive Gaussian processes for continual learning. In Proceedings of the International Conference on Machine Learning. PMLR, 2021, pp. 5290–5300.
41. Buzzega, P .; Boschini, M.; Porrello, A.; Abati, D.; Calderara, S. Dark experience for general continual learning: a strong, simple baseline. Advances in neural information processing systems 2020 ,33, 15920–15930.
42. Benjamin, A.; Rolnick, D.; Kording, K. Measuring and regularizing networks in function space. In Proceedings of the International Conference on Learning Representations, 2018.
43. Henning, C.; Cervera, M.; D'Angelo, F.; Von Oswald, J.; Traber, R.; Ehret, B.; Kobayashi, S.; Grewe, B.F.; Sacramento, J. Posterior meta-replay for continual learning. Advances in Neural Information Processing Systems 2021 ,34, 14135–14149.
44. Swaroop, S.; Nguyen, C.V .; Bui, T.D.; Turner, R.E. Improving and understanding variational continual learning. arXiv preprint arXiv:1905.02099 2019 .
45. Rudner, T.G.J.; Chen, Z.; Teh, Y.W.; Gal, Y. Tractabe Function-Space Variational Inference in Bayesian Neural Networks. 2022.
46. Rudner, T.G.J.; Smith, F.B.; Feng, Q.; Teh, Y.W.; Gal, Y. Continual Learning via Sequential Function-Space Variational Inference. In Proceedings of the Proceedings of the 38th International Conference on Machine Learning. PMLR, 2022, Proceedings of Machine Learning Research.
47. Lavda, F.; Ramapuram, J.; Gregorova, M.; Kalousis, A. Continual classification learning using generative models. arXiv preprint arXiv:1810.10612 2018 .
48. van de Ven, G.M.; Li, Z.; Tolias, A.S. Class-incremental learning with generative classifiers. In Proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 3611–3620.
49. Snell, J.; Swersky, K.; Zemel, R. Prototypical networks for few-shot learning. Advances in neural information processing systems 2017 ,30.
50. Rebuffi, S.A.; Kolesnikov, A.; Sperl, G.; Lampert, C.H. ICARL: Incremental classifier and representation learning. In Proceedings of the Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, 2017, pp. 2001–2010.
51. Harrison, J.; Sharma, A.; Finn, C.; Pavone, M. Continuous meta-learning without tasks. Advances in neural information processing systems 2020 ,33, 17571–17581.
52. Zhang, X.; Meng, D.; Gouk, H.; Hospedales, T.M. Shallow bayesian meta learning for real-world few-shot recognition. In Proceedings of the Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 651–660.
53. Titsias, M.K.; Schwarz, J.; Matthews, A.G.d.G.; Pascanu, R.; Teh, Y.W. Functional Regularisation for Continual Learning. International Conference on Learning Representations 2020 .
54. Chrysakis, A.; Moens, M.F. Online continual learning from imbalanced data. In Proceedings of the International Conference on Machine Learning. PMLR, 2020, pp. 1952–1961.
55. Knoblauch, J.; Husain, H.; Diethe, T. Optimal continual learning has perfect memory and is NP-hard. In Proceedings of the International Conference on Machine Learning. PMLR, 2020, pp. 5327–5337.
56. Titsias, M. Variational learning of inducing variables in sparse Gaussian processes. In Proceedings of the Artificial intelligence and statistics. PMLR, 2009, pp. 567–574.
57. Hensman, J.; Fusi, N.; Lawrence, N.D. Gaussian processes for big data. arXiv preprint arXiv:1309.6835 2013 .
58. Farquhar, S.; Gal, Y. Towards robust evaluations of continual learning. arXiv preprint arXiv:1805.09733 2018 .
59. Petersen, K.B.; Pedersen, M.S.; et al. The matrix cookbook. Technical University of Denmark 2008 , 7, 510.
60. Kalman, R.E. A new approach to linear filtering and prediction problems 1960 .

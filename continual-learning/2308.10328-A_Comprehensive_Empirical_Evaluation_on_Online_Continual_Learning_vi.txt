# 2308.10328.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/continual-learning/2308.10328.pdf
# Kích thước tệp: 5509694 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Đánh Giá Thực Nghiệm Toàn Diện về Học Liên Tục Trực Tuyến
Albin Soutif–Cormerais
Trung tâm Thị giác Máy tính
Đại học Tự trị Barcelona
Barcelona, Tây Ban Nha
albin@cvc.uab.catAntonio Carta
Khoa Khoa học Máy tính
Đại học Pisa
Pisa, Ý
antonio.carta@unipi.it
Andrea Cossu
Trường Cao đẳng Sư phạm Scuola Normale Superiore
Pisa, Ý
andrea.cossu@sns.itJulio Hurtado
Khoa Khoa học Máy tính
Đại học Pisa
Pisa, Ý
julio.hurtado@di.unipi.it
Hamed Hemati
Đại học St. Gallen
Saint-Gallen, Thụy Sĩ
hamed.hemati@unisg.chVincenzo Lomonaco
Khoa Khoa học Máy tính
Đại học Pisa
Pisa, Ý
vincenzo.lomonaco@unipi.it
Joost van de Weijer
Trung tâm Thị giác Máy tính
Đại học Tự trị Barcelona
Barcelona, Tây Ban Nha
joost@cvc.uab.cat

Tóm tắt
Học liên tục trực tuyến nhằm tiến gần hơn đến trải nghiệm học tập sống động bằng cách học trực tiếp trên luồng dữ liệu với phân phối thay đổi theo thời gian và bằng cách lưu trữ lượng dữ liệu tối thiểu từ luồng đó. Trong đánh giá thực nghiệm này, chúng tôi đánh giá các phương pháp khác nhau từ tài liệu nghiên cứu để giải quyết học liên tục trực tuyến. Cụ thể hơn, chúng tôi tập trung vào thiết lập tăng dần theo lớp trong bối cảnh phân loại hình ảnh, nơi người học phải học các lớp mới một cách tăng dần từ luồng dữ liệu. Chúng tôi so sánh các phương pháp này trên các bộ đo lường Split-CIFAR100 và Split-TinyImagenet, và đo độ chính xác trung bình, sự quên lãng, tính ổn định và chất lượng của các biểu diễn, để đánh giá các khía cạnh khác nhau của thuật toán ở cuối nhưng cũng trong suốt toàn bộ giai đoạn huấn luyện. Chúng tôi phát hiện rằng hầu hết các phương pháp đều gặp vấn đề về tính ổn định và khớp thiếu. Tuy nhiên, các biểu diễn đã học có thể so sánh với huấn luyện i.i.d. dưới cùng ngân sách tính toán. Không có người chiến thắng rõ ràng nào xuất hiện từ kết quả và phát lại kinh nghiệm cơ bản, khi được điều chỉnh và triển khai đúng cách, là một đường cơ sở rất mạnh. Chúng tôi phát hành cơ sở mã mô-đun và có thể mở rộng của chúng tôi tại https://github.com/AlbinSou/ocl_survey dựa trên khung avalanche để tái tạo kết quả của chúng tôi và khuyến khích nghiên cứu trong tương lai.

1. Giới thiệu
Trong những năm gần đây, chúng ta đã chứng kiến sự quan tâm và tiến bộ vượt bậc trong các phương pháp học liên tục sâu. Các phương pháp này có thể học liên tục từ luồng dữ liệu không ổn định, do đó làm giảm bớt giả định chính về việc có quyền truy cập vào các mẫu độc lập và phân phối đồng nhất (i.i.d.), thường được thực hiện trong học thống kê [21]. Trong học liên tục cổ điển (hoặc theo lô), giả định phổ biến là luồng dữ liệu được tạo thành từ các tác vụ hoặc miền riêng biệt, được định nghĩa rõ ràng, và phương pháp có thể phát hiện ranh giới tác vụ hoặc dễ dàng chuyển đổi giữa các miền. Tuy nhiên, trong nhiều tình huống thực tế, luồng dữ liệu có thể không có ranh giới tác vụ rõ ràng hoặc nhãn miền, và phương pháp

--- TRANG 2 ---
có thể cần thích ứng nhanh chóng với những thay đổi trong phân phối dữ liệu [3, 23]. Hơn nữa, các phương pháp này có quyền truy cập vào một lô dữ liệu tại mỗi tác vụ, thường dưới dạng một tập dữ liệu, cung cấp cho chúng quyền truy cập i.i.d. cục bộ vào dữ liệu.

Học Liên tục Trực tuyến (OCL) [30] là một thiết lập thách thức và thực tế hơn của học liên tục, nơi tương tự như học trực tuyến [35], phương pháp học từ từng điểm dữ liệu đến trong luồng. Các phương pháp OCL cập nhật mô hình với tần suất cao, thường không có quyền truy cập vào nhãn tác vụ hoặc ranh giới, và với ngân sách tính toán và bộ nhớ hạn chế. Do bản chất không ổn định của luồng, các phương pháp OCL cần cân bằng tính ổn định và tính dẻo. Hơn nữa, vì mô hình được sử dụng để suy luận tại mỗi bước thời gian (suy luận bất cứ lúc nào), thuật toán học không được gặp vấn đề về tính ổn định tại bất kỳ điểm nào trong quá trình học.

Các phương pháp OCL tiên tiến sử dụng bộ đệm phát lại để giảm thiểu sự quên lãng [10]. Một số cải tiến của phát lại kinh nghiệm cơ bản đã được đề xuất để cải thiện việc lấy mẫu từ bộ đệm [2, 25], hàm mất mát [6, 5, 33], cập nhật trọng số [9] hoặc lớp phân loại [33]. Một hạn chế chung của các nghiên cứu này, và thậm chí cả các khảo sát thực nghiệm gần đây [32] là chúng chỉ tập trung vào sự quên lãng và độ chính xác cuối cùng. Tuy nhiên, các phương pháp OCL có một số mục tiêu khác cần được đo lường bằng các số liệu thích hợp.

Để khuyến khích tiến bộ trong Học Liên tục Trực tuyến, trong bài báo này, chúng tôi cung cấp một đánh giá thực nghiệm toàn diện về các phương pháp OCL. Chúng tôi khai thác các đề xuất gần đây cung cấp các số liệu tốt hơn để đo lường sự quên lãng [41], tính ổn định liên tục [26], và chất lượng của các biểu diễn [14, 6, 23]. Kết quả thực nghiệm trên các số liệu này làm nổi bật điểm mạnh và hạn chế của các phương pháp tiên tiến trong OCL.

Trong nghiên cứu này, chúng tôi đóng góp vào tài liệu nghiên cứu trong lĩnh vực này như sau:

• Chúng tôi định nghĩa chính thức Học Liên tục Trực tuyến (Phần 2) và một tập hợp toàn diện các số liệu (Phần 4) để đo lường hiệu suất qua các chiều khác nhau: độ chính xác, sự quên lãng, tính ổn định liên tục, và chất lượng của các biểu diễn tiềm ẩn.

• Chúng tôi tiến hành đánh giá thực nghiệm toàn diện về các tình huống Tăng dần theo Lớp trên hai bộ đo lường chính (Split-CIFAR100 và Split-TinyImagenet) đánh giá 9 phương pháp khác nhau so với 5 số liệu. Các phát hiện chính có thể được tìm thấy trong "hộp khuyến nghị" ở đầu trang này.

• Chúng tôi phát hành toàn bộ mã để tái tạo kết quả của chúng tôi, so sánh và dễ dàng tạo mẫu các chiến lược OCL mới. Mã đã được phát triển trong thư viện Deep Continual Learning Avalanche để có tính linh hoạt và khả năng tái tạo tối đa.

2. Học Liên tục Trực tuyến
Trong Học Liên tục Trực tuyến (OCL), một mô hình học từ luồng trải nghiệm dữ liệu không ổn định. Trong bài toán phân loại, tại mỗi bước thời gian t một mini-batch (xt, yt)∼pt(x, y) có sẵn, trong đó pt là phân phối cơ bản của dữ liệu và có thể thay đổi theo thời gian. Hàm f:Rn→Rc là hàm dự đoán và ánh xạ đầu vào thành xác suất lớp chưa được chuẩn hóa (logits). Một thuật toán OCL là một hàm A: (xt, yt), ft−1,Mt−1→ft,Mt, trong đó ft là mô hình tại thời điểm t và Mt={(xi, yi)} là bộ đệm phát lại, tức là một tập nhỏ các mẫu từ luồng quá khứ được lưu trữ để phát lại.

Không giống như Học Liên tục Ngoại tuyến, OCL là một thiết lập thách thức nơi chỉ có một số mẫu mới có sẵn tại mỗi bước, có thể được lưu trữ với lượng rất hạn chế. Sau đây là một số thuộc tính đặc trưng cho thiết lập OCL:

Trực tuyến. Tại mỗi bước thời gian chỉ có một mini-batch nhỏ (xt, yt) có sẵn (10 trong các thí nghiệm của chúng tôi).

Nhãn Tác vụ. Trong thiết lập nhận biết tác vụ, các mô hình biết rằng các mẫu thuộc về một tập hợp các tác vụ đã biết và một nhãn tác vụ có sẵn để liên kết mỗi mẫu với tác vụ riêng của nó. Chúng tôi giả định một thiết lập bất khả tri tác vụ nơi nhãn tác vụ không có sẵn.

Ranh giới Tác vụ. Ngay cả trong trường hợp không có nhãn tác vụ, nhiều phương pháp học liên tục giả định kiến thức về ranh giới tác vụ, mong đợi biết khi nào phân phối dữ liệu chuyển sang một tác vụ mới. Trong thiết lập bất khả tri ranh giới, thông tin này không có sẵn¹. Trong bài báo này, chúng tôi kiểm tra cả phương pháp bất khả tri ranh giới và nhận biết ranh giới.

Suy luận Bất cứ lúc nào. Trong hầu hết các ứng dụng OCL, các mô hình nên có thể huấn luyện nhưng cũng thực hiện suy luận trực tuyến, sau mỗi bước huấn luyện [23]. Kết quả là, các phương pháp yêu cầu các bước tinh chỉnh đắt đỏ trước khi suy luận như GDumb [38] không được coi là phương pháp OCL trong bài báo này.

3. Phương pháp
Tương tự như Học Liên tục Ngoại tuyến, trong OCL, hầu hết kết quả tiên tiến đều được thu được bởi các phương pháp dựa trên phát lại. Vì lý do này, hầu hết các phương pháp sử dụng phát lại, đây là lý do chính chúng tôi tập trung vào chúng cho nghiên cứu thực nghiệm của mình. Các phương pháp dựa trên phát lại giữ một bộ nhớ M riêng biệt có kích thước cố định để lưu trữ các mẫu quá khứ, được cập nhật sau mỗi mini-batch. Hầu hết các phương pháp dựa trên phát lại, và tất cả

¹Điều này thường được gọi là không có tác vụ, và đây là một giả định phổ biến trong OCL. Chúng tôi đề xuất thuật ngữ bất khả tri ranh giới để nhấn mạnh rằng nhãn tác vụ và ranh giới là hai loại kiến thức khác nhau về thuộc tính của luồng

--- TRANG 3 ---
CÁC PHÁT HIỆN CHÍNH CỦA ĐÁNH GIÁ HIỆU SUẤT CHÚNG TÔI VỀ HỌC LIÊN TỤC TRỰC TUYẾN

• Tính ổn định tốt không nhất thiết chuyển thành độ chính xác cao hơn (Xem Bảng 2, Hình 3 và Phần 6 Tính ổn định).

• Không có phương pháp OCL hoạt động tốt nhất trên tất cả các số liệu hoặc kích thước bộ nhớ (Xem Bảng 2).

• Các phương pháp OCL gặp vấn đề khớp thiếu trong thiết lập thí nghiệm phổ biến (Xem Hình 3 và Phần 6 Sự quên lãng).

• ER được điều chỉnh đúng cách là một đường cơ sở rất cạnh tranh đạt kết quả tốt hơn hầu hết các phương pháp hiện có (Xem thảo luận kích thước lô bộ nhớ 6 và Phần 5 Triển khai).

• Chất lượng của biểu diễn rất gần với biểu diễn được học trên luồng i.i.d., cho thấy rằng học một bộ phân loại tốt là một trong những vấn đề chính. (Xem Phần 6 Chất lượng biểu diễn).

Hình 1: Mã giả của các phương pháp OCL dựa trên phát lại. Mỗi phương pháp có thể được thu được từ phát lại kinh nghiệm cơ bản (ER) bằng cách sửa đổi một trong các thành phần cơ bản của nó: lấy mẫu, mất mát, bộ phân loại, cập nhật trọng số.

[THIS IS TABLE: Bảng tóm tắt các phương pháp với tên, năm phát hành và khả năng truy cập ranh giới]
Tên | Yếu tố | Năm | Ranh giới
AGEM [9] | Cập nhật đã sửa đổi | 2018 |
ER [10] | - | 2019 |
ER + LwF [28] | Mất mát Chưng cất | 2019 |
ER-ACE [6] | Mất mát Cross-Entropy đã sửa đổi | 2021 |
MIR [2] | Lấy mẫu đã sửa đổi | 2019 |
SCR [33] | Mất mát Tương phản, NMC | 2021 |
RAR [25] | Tăng cường Đối nghịch | 2022 |
DER++ [5] | Mất mát Chưng cất | 2020 |
GDumb [38] | Tinh chỉnh ngoại tuyến trên bộ đệm | 2020 |

Bảng 1: Tóm tắt các phương pháp được thử trong khảo sát cùng với đặc điểm riêng của chúng (năm phát hành, quyền truy cập ranh giới tác vụ).

các phương pháp được chọn, tuân theo mã giả được hiển thị trong Hình 1. Trong các đoạn văn sau, chúng tôi sẽ mô tả chi tiết từng dòng, giải thích một số bổ sung cụ thể của phương pháp và lý do chính để chọn mỗi phương pháp.

Lấy mẫu. Thông thường, mỗi mini-batch mới được sử dụng lại cho nhiều lần huấn luyện, mỗi lần lấy mẫu một mini-batch khác nhau từ bộ nhớ và áp dụng tăng cường ngẫu nhiên cho cả dữ liệu cũ và mới. Điều này được biện minh bởi phân tích lý thuyết trong [44]. MIR [2] tìm các mẫu bị can thiệp tối đa, tức là những mẫu làm giảm tối đa mất mát của chúng sau một bước SGD trên dữ liệu mới, và chọn những mẫu đó để phát lại. Thay vào đó, RAR [25] tạo ra các mẫu mới bằng cách sử dụng các cuộc tấn công đối nghịch có mục tiêu được thiết kế để ở gần ranh giới quyết định của bộ phân loại.

Mất mát. Hầu hết các phương pháp sử dụng mất mát có giám sát trên cả dữ liệu mới và bộ nhớ, chẳng hạn như cross-entropy. ER-ACE [6] sử dụng mất mát khác nhau trên dữ liệu mới và cũ do bản chất khác nhau của hai mẫu. DER++ [5] sử dụng chưng cất logits, lưu trữ logits cùng với dữ liệu thô trong bộ nhớ. Trong khi mục tiêu là mất mát chưng cất kiến thức, giáo viên được sử dụng để tính toán logits phụ thuộc vào thời điểm khi mẫu được lưu trữ. SCR [33] sử dụng mất mát tương phản. Trong các thiết lập CL với lô lớn, đã được chứng minh rằng mất mát tương phản chịu ít sự quên lãng hơn so với mất mát có giám sát [13, 31, 19]. Tuy nhiên, nhiều mất mát tương phản yêu cầu kích thước lô lớn, tập dữ liệu lớn và đa dạng, và nhiều thời gian hơn để hội tụ, điều này có thể không khả thi trong thiết lập trực tuyến. Lưu ý rằng chưng cất thường yêu cầu ranh giới tác vụ để biết khi nào cập nhật giáo viên.

Bộ phân loại. Hầu hết các phương pháp sử dụng bộ phân loại tuyến tính được huấn luyện bằng lan truyền ngược. Một lựa chọn phổ biến khác là bộ phân loại NCM (Nearest-Class-Mean), tính toán một nguyên mẫu cho mỗi lớp và sử dụng khoảng cách giữa các nguyên mẫu để phân loại tại thời điểm suy luận. Ví dụ, SCR sử dụng bộ phân loại NCM. Thông thường, bộ phân loại NCM chỉ được sử dụng trong quá trình suy luận, trong khi một bộ phân loại tuyến tính riêng biệt được huấn luyện thông qua lan truyền ngược trong quá trình huấn luyện.

Cập nhật mô hình. Hầu hết các phương pháp sử dụng lan truyền ngược từ đầu đến cuối sử dụng cả mẫu mới và mẫu bộ nhớ. Thay vào đó, A-GEM [9] sử dụng gradient từ bộ nhớ để áp đặt ràng buộc lên việc cập nhật mô hình, khai thác thực tế rằng sự can thiệp có thể được đo lường bằng cách sử dụng độ tương tự cosine giữa gradient của các tác vụ khác nhau.

Phương pháp cơ sở. GDumb cập nhật bộ nhớ thông qua lấy mẫu reservoir cân bằng lớp [11] và, trước mỗi bước suy luận, huấn luyện lại toàn bộ mô hình chỉ sử dụng dữ liệu bộ nhớ. GDumb không phải là một phương pháp trực tuyến hiệu quả vì nó không thể thực hiện suy luận bất cứ lúc nào do chi phí cao của việc huấn luyện lại tại mỗi bước. Tuy nhiên, đây là một đường cơ sở hữu ích có hiệu quả đáng ngạc nhiên.

4. Số liệu
Để đánh giá hiệu suất của mỗi chiến lược, chúng tôi sử dụng một tập hợp toàn diện các số liệu được giới thiệu gần đây trong tài liệu OCL. Chúng tôi đã đặc biệt chú ý đến việc bao gồm các số liệu để đo lường tính ổn định và tích lũy kiến thức. Theo [26], chúng tôi thực hiện đánh giá liên tục sau mỗi bước thời gian t từ luồng (sau khi huấn luyện trên mỗi mini-batch). Ngoài ra, chúng tôi cũng đánh giá hiệu suất tại ranh giới tác vụ. Chúng tôi biểu thị độ chính xác của một mô hình f tại lần lặp huấn luyện t trên tác vụ đánh giá Ei với A(Ei, ft), chúng tôi ký hiệu k là chỉ số tác vụ huấn luyện hiện tại.

Tính ổn định. Độ chính xác Trường hợp xấu nhất (WC-ACC) [26] cung cấp sự đánh đổi giữa độ chính xác tại lần lặp t và độ chính xác tối thiểu trung bình trên tất cả các tác vụ đã học trước tác vụ hiện tại Tk. Chính thức:

WC-ACCt=1/k A(Ek, ft) + (1-1/k) min-ACCTk. (1)

Số liệu min-ACC được định nghĩa trong [26] đối với tác vụ cuối cùng Tk và có thể được tính như:

min-ACCTk=1/(k-1) Σ(i=1 to k-1) min(|Tk|<n≤t) A(Ei, fn), (2)

trong đó |Tk| biểu thị lần lặp huấn luyện cuối cùng cho tác vụ Tk.

Độ chính xác Trung bình Bất cứ lúc nào. Độ chính xác Trung bình Bất cứ lúc nào [6] (AAA), đôi khi được gọi là độ chính xác Diện tích dưới Đường cong [23] (AAUC), là sự tổng quát hóa của độ chính xác tăng dần trung bình [39] cho thiết lập đánh giá liên tục, và được định nghĩa như:

AAAt=1/t Σ(j=1 to t) 1/k Σ(i=1 to k) A(Ei, fj), (3)

Độ chính xác/Sự quên lãng Trung bình. Tương tự như hầu hết các nghiên cứu trong CL, chúng tôi báo cáo Độ chính xác Trung bình và Sự quên lãng Trung bình như được định nghĩa bởi [30]. Độ chính xác Trung bình được tính trên k tác vụ từ một mô hình tại bước t bởi AA=1/k Σ(i=1 to k) A(Ei, ft). Tương tự, Sự quên lãng Trung bình được tính bởi AF=1/k Σ(i=1 to k) A(Ei, f|Ti|)-A(Ei, ft).

Độ chính xác/Sự quên lãng Tích lũy. Khi áp dụng cho học tăng dần theo lớp, như được thực hiện trong bài báo này, số liệu Sự quên lãng Trung bình được mô tả ở trên đo lường cả sự quên lãng và sự giảm hiệu suất do tác vụ phân loại ngày càng khó khăn. Soutif et al. [41] đề xuất một biện pháp quên lãng được thiết kế riêng cho học tăng dần theo lớp gọi là quên lãng tích lũy. Độ chính xác Tích lũy cho một mô hình ft được tính trên việc nối các tác vụ đánh giá đã thấy đến tác vụ k (EkΣ), và chỉ xem xét logits đến các lớp đã thấy trong tác vụ k (CkΣ). Nó có thể được tính như

btk=1/|EkΣ| Σ(x,y∈EkΣ) 1y(arg max(c∈CkΣ) ft(x)c), (4)

trong đó 1y(ŷ) là hàm chỉ thị bằng 1 nếu y=ŷ và 0 nếu không. Sau đó chúng tôi tính Sự quên lãng Tích lũy Trung bình [41] trên tất cả các tác vụ, được tính đơn giản từ Độ chính xác Tích lũy như FtΣ=1/(t-1) Σ(k=1 to t-1) max(i=1,...,t) bik-btk.

Chất lượng biểu diễn. Trong thiết lập này, xương sống mô hình được đóng băng và một bộ phân loại tuyến tính được huấn luyện trên đó sử dụng tất cả dữ liệu huấn luyện đã thấy cho đến nay (linear probing) [14], sau đó chúng tôi báo cáo độ chính xác thu được với bộ phân loại này (Độ chính xác Thăm dò). Số liệu này cho phép chúng tôi đánh giá chất lượng của các biểu diễn được tính toán với xương sống được học tăng dần. Số liệu này chỉ được tính tại ranh giới tác vụ.

--- TRANG 5 ---
5. Thiết lập thí nghiệm
Bộ đo lường. Chúng tôi trình bày kết quả trên hai bộ đo lường phân loại học liên tục. Split-Cifar100 được tạo từ tập dữ liệu Cifar-100 [24], chứa 50.000 hình ảnh huấn luyện và 10.000 hình ảnh kiểm tra có kích thước 32x32, được chia đều thành 100 lớp được tinh chỉnh từ 20 siêu lớp. Split-TinyImagenet [1] là phiên bản thu gọn của tập dữ liệu Imagenet [16], chứa 100.000 hình ảnh huấn luyện được thay đổi kích thước thành 64x64 và chia thành 200 lớp. Chúng tôi chia các tập dữ liệu này thành 20 tác vụ sử dụng thứ tự lớp ngẫu nhiên (thành phần tác vụ thay đổi cho mỗi hạt giống ngẫu nhiên).

Chi tiết mô hình và huấn luyện. Trong tất cả các thí nghiệm, chúng tôi sử dụng phiên bản gọn của Resnet18 như đã làm trong các nghiên cứu trước [30]. Chúng tôi sử dụng trình tối ưu hóa SGD không có momentum hoặc weight decay. Chúng tôi điều chỉnh tốc độ học cho mỗi phương pháp bằng cách sử dụng giao thức lựa chọn siêu tham số được định nghĩa sau trong phần này. Vì tất cả các phương pháp so sánh đều sử dụng bộ đệm phát lại, chúng tôi chọn tuân theo một giao thức chung để học bao gồm việc thực hiện nhiều lần huấn luyện trên cùng một lô dữ liệu, sử dụng một lô bộ nhớ khác nhau. Giao thức này đã được sử dụng trong một số nghiên cứu [2, 44, 22]. Chúng tôi chọn luôn áp dụng biến đổi đầu vào vì chúng đã được chứng minh là giảm đáng kể việc overfitting trên các mẫu bộ đệm và hiệu quả khi kết hợp với nhiều lần lặp cho mỗi lô đến [44]. Chúng tôi sử dụng kích thước lô là 10 cho dữ liệu hiện tại cho cả hai bộ đo lường. Mỗi lô huấn luyện sau đó được tạo thành từ 10 hình ảnh từ dữ liệu hiện tại và 10 hình ảnh từ bộ đệm phát lại, ngoại trừ SCR cần lấy mẫu một lô lớn hơn từ bộ nhớ (có kích thước 118). Số lần huấn luyện trên mỗi mini-batch được giữ cố định cho tất cả các phương pháp (không được điều chỉnh), và được đặt thành 3 trên Split-Cifar100 và 9 trên Split-TinyImagenet. Trên cả hai bộ đo lường, chúng tôi sử dụng cắt xén ngẫu nhiên và lật ngang ngẫu nhiên như biến đổi đầu vào, ngoại trừ SCR sử dụng biến đổi tiên tiến hơn. Trong kết quả chính, chúng tôi sử dụng kích thước bộ nhớ cố định là 2000 trên Split-Cifar100 và 4000 trên Split-TinyImagenet. Ngoài ra, chúng tôi trình bày kết quả cho lượng bộ nhớ cực đoan hơn (thấp và cao) trên Split-Cifar100 trong Hình 3.

Lựa chọn siêu tham số. Để đảm bảo mọi phương pháp được thử đều hoạt động tốt nhất, chúng tôi sử dụng cơ chế lựa chọn siêu tham số. Các ràng buộc của thiết lập trực tuyến thường không cho phép lựa chọn siêu tham số hiệu quả. Trong [32], một vài tác vụ đầu tiên của luồng huấn luyện được sử dụng làm tác vụ xác thực, điều này được mượn từ giao thức được định nghĩa trong [9]. Chúng tôi cũng tuân theo giao thức này, sử dụng 4 tác vụ đầu tiên (trong tổng số 20), để tối ưu hóa siêu tham số bằng cách xem xét độ chính xác trên tập xác thực. Trái ngược với những gì được thực hiện trong [9], chúng tôi không cho phép người học học ngoại tuyến trên 4 tác vụ này, mà đặt người học trong thiết lập học trực tuyến. Chúng tôi sử dụng thuật toán ước lượng Parzen có cấu trúc cây [4] để hướng dẫn tìm kiếm siêu tham số, bằng cách chạy 200 thử nghiệm cho mỗi phương pháp. Trong Phụ lục (Xem Phần 9.3) chúng tôi cung cấp danh sách các tham số được điều chỉnh cho mỗi phương pháp cũng như các phạm vi được sử dụng và các giá trị tốt nhất được tìm thấy.

Đánh giá. Như đã làm trong [6, 23], và được nghiên cứu sâu hơn trong [15]. Chúng tôi thực hiện đánh giá liên tục, có nghĩa là chúng tôi đánh giá mô hình trên dữ liệu xác thực được giữ lại (5% của toàn bộ luồng) sau khi học trên mỗi mini-batch mới. Trên cơ sở này, chúng tôi cũng thực hiện đánh giá cổ điển hơn trên luồng kiểm tra sau khi huấn luyện trên mỗi tác vụ.

Phương pháp. Chúng tôi báo cáo kết quả cho tất cả các phương pháp được trình bày trong Phần 3. Trên cơ sở đó, chúng tôi thêm một phương pháp tham chiếu i.i.d., sử dụng cùng phương pháp như ER nhưng học trên luồng i.i.d. thay vì luồng tăng dần theo lớp.

Triển khai. Tất cả các phương pháp đều được triển khai bằng khung Avalanche [8], một khung học liên tục mã nguồn mở cung cấp các công cụ để triển khai các chiến lược và bộ đo lường mới trong học liên tục. Trong khi một số phương pháp đã có sẵn, chúng tôi đã điều chỉnh một số phương pháp hiện có và thêm một số phương pháp mới vào khung để tiến hành nghiên cứu này. Việc triển khai mỗi phương pháp là mô-đun, cho phép tái sử dụng các thành phần chung (ví dụ: bộ đệm reservoir) và làm nổi bật sự tương đồng và khác biệt giữa các phương pháp. Mặc dù nỗ lực của chúng tôi để làm cho so sánh công bằng nhất có thể, có một số lựa chọn triển khai khiến việc điều hòa tất cả các phương pháp trở nên khó khăn. Chúng tôi liệt kê chúng trong Phụ lục (Xem Phần 9.2) và thảo luận tác động tiềm năng của chúng đối với kết quả.

6. Kết quả
Độ chính xác Trung bình Cuối cùng. Trên Split-Cifar100, chúng tôi thấy rằng hiệu suất cuối cùng của tất cả các phương pháp so sánh rất tương tự với phương pháp phát lại vanilla (ER) (Xem Bảng 2). Ngoại trừ hiệu suất của AGEM, hầu hết các phương pháp hoạt động khá cạnh tranh trong thiết lập OCL (chỉ khoảng 5% so với phương pháp tham chiếu i.i.d.), phương pháp tốt nhất là đường cơ sở được giới thiệu kết hợp ER và LwF, nhưng chỉ với biên độ rất nhỏ. Trên Split-TinyImagenet, kết quả tương tự gần nhau (Xem Bảng 2), ngoại trừ ER-ACE hoạt động tốt hơn trên bộ đo lường đó, và RAR và SCR hoạt động kém hơn.

Tính ổn định (WC-Acc và AAA). Trên Split-Cifar100, về mặt tính ổn định, kết quả thay đổi nhiều hơn giữa mỗi phương pháp, và hiệu suất cuối cùng không nhất thiết tương quan với tính ổn định của phương pháp. Ví dụ, độ chính xác cuối cùng cho MIR cao hơn 1% so với độ chính xác cuối cùng cho SCR,

--- TRANG 6 ---
[THIS IS TABLE: Bảng 2 showing results for Split-Cifar100 and Split-TinyImagenet with various methods and metrics]

tuy nhiên, SCR có WC-Acc tốt hơn khoảng 9% so với MIR. Trong Hình 3, chúng tôi minh họa sự khác biệt về tính ổn định giữa SCR và ER trên Split-Cifar100 với 2000 bộ nhớ. Trong hình này, độ chính xác trên tác vụ trước đó giảm đáng kể khi chuyển tác vụ trong trường hợp của ER, cho thấy tính ổn định thấp, điều này không xảy ra với SCR. Nói chung, chúng tôi quan sát thấy AAA có tương quan vừa phải với WC-Acc, mặc dù chúng không liên kết mạnh mẽ về mặt lý thuyết (có thể có WC-Acc thấp và AAA cao).

Chất lượng biểu diễn. Đáng ngạc nhiên, chúng tôi thấy rằng độ chính xác thăm dò cho hầu hết các phương pháp gần với phương pháp tham chiếu i.i.d. (45.8% trên Split-Cifar100 và 34.3% trên Split-Tinyimagenet). Điều này cho thấy rằng biểu diễn được học bởi các phương pháp trên luồng liên tục không tệ hơn nhiều so với biểu diễn được học trên luồng i.i.d. Do đó, sự khác biệt hiệu suất đáng kể (trong Acc) giữa các phương pháp học tăng dần và tham chiếu i.i.d. có thể được gây ra bởi sự suy giảm của bộ phân loại được học tăng dần. Trong Phụ lục (Xem Bảng 3 và 4), chúng tôi cung cấp kết quả với 500 và 8000 bộ nhớ trên Split-Cifar100. Ngay cả khi sử dụng 500 bộ nhớ, chúng tôi quan sát kết luận tương tự, với khoảng cách đến thăm dò chỉ tăng một chút (từ 1% đến 2%), cho thấy rằng chỉ một lượng bộ nhớ thấp (5 cho mỗi lớp trong trường hợp đó) là hiệu quả để có được độ mạnh biểu diễn tốt. Nói chung, chúng tôi thấy rằng độ chính xác thăm dò không liên kết mạnh mẽ với các số liệu tính ổn định. Trong Bảng 2, chúng ta thấy ER có Độ chính xác Thăm dò tốt nhất trong cả hai trường hợp, trong khi nó có số liệu tính ổn định thấp hơn trung bình so với các phương pháp khác.

Sự quên lãng. Trong Hình 3, chúng tôi hiển thị cả sự quên lãng cổ điển và sự quên lãng tích lũy được định nghĩa trong Phần 4 [41]. Chúng ta thấy rằng trong khi sự quên lãng cổ điển cho thấy một lượng quên lãng cao đang tăng qua luồng, sự quên lãng tích lũy đưa ra một bức tranh khác, cho thấy rằng đối với tất cả các phương pháp, một số chuyển giao ngược được đạt được, và điều này vẫn khá ổn định qua tất cả các tác vụ. Hai đường cong thể hiện hành vi hơi khác biệt, cụ thể là của SCR và MIR. Những hành vi đặc biệt này cũng có thể được quan sát trong Hình 2. Trong trường hợp của MIR, độ chính xác trung bình ban đầu thấp, và sau đó tăng để phù hợp với ER-ACE, dẫn đến chuyển giao ngược cao. Trong khi đó với SCR, độ chính xác ban đầu cao, nhưng sau đó gặp phải các phương pháp khác, dẫn đến sự quên lãng trung tính (không quên lãng, nhưng không có chuyển giao ngược). Tuy nhiên, sự quên lãng cổ điển không phù hợp lắm trong thiết lập học tăng dần theo lớp vì nó tăng do sự gia tăng độ khó của tác vụ (ngày càng nhiều lớp cần xem xét trong vấn đề phân loại), điều này khiến việc diễn giải trở nên khó khăn, do đó, chúng tôi khuyên không sử dụng nó trong học tăng dần theo lớp (trực tuyến hoặc không trực tuyến). Cuối cùng, những con số quên lãng này cho thấy rằng có một số chuyển giao ngược đang xảy ra, chúng tôi tin rằng điều này chủ yếu do thực tế là mạng bị khớp thiếu trong học trực tuyến, do số lần lặp huấn luyện thấp, khiến việc đạt được hiệu suất bổ sung trên một tác vụ khi huấn luyện trên các tác vụ tiếp theo trở nên dễ dàng.

Tác động của kích thước lô bộ nhớ. Như đã giải thích trong Phần 5, kích thước lô bộ nhớ được đặt giống như kích thước lô hiện tại trong các thí nghiệm của chúng tôi, ngoại trừ SCR, yêu cầu kích thước cao hơn. Chúng tôi tin rằng sự khác biệt này giải thích hiệu suất tốt của SCR trong chế độ huấn luyện sớm (xem Hình 2) và trong thiết lập kích thước bộ nhớ cao. Chúng tôi thực hiện các thí nghiệm bổ sung (Xem Bảng 4) nơi chúng tôi sử dụng cùng kích thước lô bộ nhớ cho ER như của SCR. Trên Split-Cifar100 với 8000 bộ nhớ, thay đổi kích thước lô bộ nhớ từ 10 thành 118 đủ để làm cho ER phù hợp với hiệu suất của SCR (nhảy từ 34.9% lên 43.0% độ chính xác cuối cùng). Điều này xác nhận niềm tin của chúng tôi rằng tham số này quan trọng cần tính đến khi diễn giải kết quả.

Tác động của kích thước bộ nhớ. Trong Hình 3, chúng tôi báo cáo hiệu suất cuối cùng của ER, phương pháp tham chiếu i.i.d., và đường cơ sở GDumb khi sử dụng lượng bộ nhớ cực đoan hơn (thấp và cao) trên Split-Cifar100. Khi sử dụng lượng bộ nhớ cao, đường cơ sở GDumb có thể vượt qua hiệu suất của các phương pháp học liên tục nếu không chú ý đặc biệt đến kích thước lô bộ nhớ. Kích thước này cần được điều chỉnh để có được hiệu suất tốt nhất với các phương pháp học liên tục (xem Phụ lục Phần 9.1).

7. Nghiên cứu liên quan
Các khảo sát hiện có. Các khảo sát về học liên tục đã tập trung vào các khía cạnh khác nhau. Parisi et al. [37] cung cấp một khảo sát về học suốt đời và rút ra những điểm tương đồng với cách các hệ thống sinh học ngăn chặn sự quên lãng thảm khốc. Khảo sát của Lesort et al. [27] nghiên cứu học liên tục tập trung vào các ứng dụng robot. Các khảo sát gần đây hơn đã tập trung vào các thiết lập phổ biến cho học liên tục. De Lange et al. [15] nghiên cứu học tăng dần theo tác vụ, và Masana et al. [34] điều tra học tăng dần theo lớp. Tương tự hơn với nghiên cứu được đề xuất trong bài báo này, là nghiên cứu của Mai et al. [32] người đề xuất đánh giá thực nghiệm một số phương pháp học liên tục trực tuyến. Tuy nhiên, khác với họ, bài báo của chúng tôi nhằm so sánh nhiều phương pháp phát lại cạnh tranh mà mỗi phương pháp sử dụng các phương pháp khác nhau để giải quyết thiết lập học liên tục trực tuyến (như được mô tả trong Hình 1). Trên cơ sở đó, chúng tôi đánh giá và so sánh hiệu suất của mỗi phương pháp từ các góc độ khác nhau, phân tích cả hiệu suất cuối cùng nhưng cũng tính ổn định (bằng cách đánh giá trên tập xác thực sau mỗi mini-batch). Chúng tôi cũng đánh giá biểu diễn đã học bằng cách thăm dò các đặc trưng với toàn bộ tập dữ liệu ở cuối quá trình huấn luyện, như trong [14].

Thư viện hiện có. Khảo sát này đóng góp vào việc triển khai nhiều phương pháp trong Thư viện Avalanche [8]. Avalanche là một thư viện đầu cuối đến cuối dựa trên Pytorch với mục tiêu cung cấp cơ sở mã cho việc tạo mẫu nhanh, huấn luyện và đánh giá có thể tái tạo các thuật toán học liên tục. Ngoài ra, các thư viện khác đã được triển khai với các mục tiêu và phẩm chất khác nhau. SequeL [17] là một thư viện mới tập trung vào phát triển các phương pháp không chỉ trong PyTorch, mà còn trong JAX. Nó cung cấp giao diện đơn giản để chạy thí nghiệm trong cả hai. Tuy nhiên, tính mới của thư viện và nhu cầu triển khai các phương pháp trong cả hai ngôn ngữ khiến việc sử dụng trở nên khó khăn. Mặt khác, Sequoia [36] là một thư viện cố gắng thống nhất càng nhiều thiết lập học liên tục càng tốt dưới một cây chung. Gốc là vấn đề khó học nhất, và lá và nhánh là các thiết lập khác nhau. Cuối cùng, Continuum [18] là một thư viện tập trung chủ yếu vào các khía cạnh đo lường của học liên tục và cung cấp các công cụ để dễ dàng chia tập dữ liệu và lặp lại trên các tác vụ kết quả.

Các phương pháp bổ sung. Ngoài các phương pháp được triển khai, còn có các phương pháp khác được đề xuất trong những năm gần đây. Trong Online Bias Correction [12], các tác giả giải thích cách phát lại kinh nghiệm làm thiên lệch đầu ra mô hình về phía các quan sát gần đây. Với điều này, họ đề xuất một cách để sửa đổi đầu ra bộ phân loại và giảm thiểu thiên lệch. Theo cùng ý tưởng giảm thiên lệch, Guo et al. [20] đề xuất OCM dựa trên tối đa hóa thông tin tương hỗ. Ở đây, các tác giả xử lý việc giảm thiên lệch do cross entropy gây ra và họ khuyến khích bảo tồn kiến thức trước đó. Một phương pháp khác dựa trên bộ đệm là Proxy-based Contrastive Replay [29]. Ở đây, các tác giả đề xuất một cách để bổ sung mất mát bộ đệm và mất mát tương phản. Sử dụng Visual Transformer kết hợp với chiến lược học tương phản tiêu điểm, Wang et al. [42] đề xuất giảm thiểu tiến thoái lưỡng nan tính ổn định-tính dẻo.

8. Kết luận
Trong nghiên cứu này, chúng tôi đã xem xét hiệu suất của các phương pháp Học Liên tục Trực tuyến (OCL) khác nhau, tập trung vào hiệu suất, tính ổn định, chất lượng biểu diễn và sự quên lãng. Phân tích của chúng tôi tiết lộ những hiểu biết thú vị. Thứ nhất, chúng tôi thấy rằng tính ổn định không phải lúc nào cũng chuyển thành độ chính xác cao hơn, thách thức quan niệm rằng một mô hình ổn định đảm bảo hiệu suất vượt trội trong thiết lập OCL. Ngoài ra, chúng tôi quan sát thấy rằng chất lượng của biểu diễn được học bởi các phương pháp học liên tục không khác biệt mạnh mẽ so với biểu diễn thu được bằng cách học trên luồng i.i.d., cho thấy rằng thách thức chính mà các phương pháp học liên tục phải đối mặt là học một bộ phân loại tốt. Chúng tôi cũng thấy rằng các phương pháp dễ bị khớp thiếu trong thiết lập OCL, thách thức giả định phổ biến rằng các phương pháp học liên tục gặp vấn đề quên lãng; chúng tôi ở đây khẳng định rằng chúng tiếp tục cải thiện hiệu suất trên các tác vụ trước đó khi học trên các tác vụ tiếp theo. Nói chung, chúng tôi thấy tất cả các phương pháp so sánh hoạt động rất tương tự với phương pháp Phát lại Kinh nghiệm (ER) thông thường. Chúng tôi cũng điều tra một số khác biệt triển khai nhỏ và kết luận rằng đôi khi các chi tiết nhỏ trong triển khai có thể làm cho một phương pháp tỏa sáng bằng cách sử dụng các số liệu hiện có, nhưng thường có thể đạt được những kết quả tương tự bằng cách sửa đổi nhẹ siêu tham số hoặc chi tiết triển khai ER cơ sở, làm nổi bật sự cần thiết phải triển khai các phương pháp này trong một khung thống nhất như avalanche để chúng có thể được so sánh công bằng hơn. Cuối cùng, chúng tôi thấy rằng không có phương pháp OCL nào được chứng minh là vượt trội phổ quát trên tất cả các số liệu hoặc kích thước bộ nhớ, làm nổi bật sự vắng mặt của một giải pháp phù hợp với tất cả. Xem xét những phát hiện này, chúng tôi xác định một số hướng nghiên cứu hứa hẹn cho học liên tục trực tuyến.

--- TRANG 8 ---
[Hình 2 và 3 với các biểu đồ hiệu suất và so sánh các phương pháp]

Chúng tôi ủng hộ việc kết nối mạnh mẽ hơn giữa học trực tuyến i.i.d. bình thường và học liên tục trực tuyến, do độ mạnh biểu diễn tương tự của chúng. Vì chiến lược ER đã phổ biến cho cả hai thiết lập và được chứng minh là cạnh tranh, trọng tâm nên được đặt vào việc điều chỉnh siêu tham số của nó trong quá trình huấn luyện, như đã được thử trong [43] và [7]. Điều chỉnh siêu tham số phù hợp trong học liên tục trực tuyến vẫn là một thách thức mở. Ngoài ra, chúng tôi khuyến khích khám phá thêm việc liên kết các số liệu tính ổn định với hiệu quả huấn luyện, vì chúng tôi thấy rằng tính ổn định kém không nhất thiết ảnh hưởng đến độ mạnh biểu diễn cuối cùng. Nếu không có liên kết trực tiếp nào tồn tại, việc thực thi tính ổn định tốt trong quá trình huấn luyện có thể không cần thiết, và các phương pháp tùy ý [40] có thể đủ để đạt được tính ổn định mong muốn.

--- TRANG 9 ---
Lời cảm ơn: Chúng tôi ghi nhận sự hỗ trợ từ Chính phủ Tây Ban Nha tài trợ cho các dự án PID2022-143257NB-I00, TED2021-132513B-I00. Chúng tôi cũng ghi nhận sự hỗ trợ từ Bộ Đại học và Nghiên cứu Ý (MUR) như một phần của tài nguyên FSE REACT-EU - PON 2014-2020 "Nghiên cứu và Đổi mới" – Hành động Đổi mới - DM MUR 1062/2021

Tài liệu tham khảo
[1] Stanford, "thử thách tiny imagenet, khóa học cs231n.". https://tiny-imagenet.herokuapp.com/, 2015. 5

[2] Rahaf Aljundi, Eugene Belilovsky, Tinne Tuytelaars, Laurent Charlin, Massimo Caccia, Min Lin, và Lucas Page-Caccia. Học liên tục trực tuyến với truy xuất can thiệp tối đa. Trong H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, và R. Garnett, biên tập viên, Tiến bộ trong Xử lý Thông tin Neural, tập 32. Curran Associates, Inc., 2019. 2, 3, 5

[3] Rahaf Aljundi, Min Lin, Baptiste Goujaud, và Yoshua Bengio. Lựa chọn mẫu dựa trên gradient cho học liên tục trực tuyến. Tiến bộ trong xử lý thông tin neural, 32, 2019. 2

[4] James Bergstra, Rémi Bardenet, Yoshua Bengio, và Balázs Kégl. Thuật toán cho tối ưu hóa siêu tham số. Tiến bộ trong xử lý thông tin neural, 24, 2011. 5

[5] Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, và Simone Calderara. Kinh nghiệm tối tăm cho học liên tục tổng quát: một đường cơ sở mạnh mẽ, đơn giản. Tiến bộ trong xử lý thông tin neural, 33:15920–15930, 2020. 2, 3

[6] Lucas Caccia, Rahaf Aljundi, Nader Asadi, Tinne Tuytelaars, Joelle Pineau, và Eugene Belilovsky. Hiểu biết mới về việc giảm thay đổi biểu diễn đột ngột trong học liên tục trực tuyến. Trong Hội nghị Quốc tế về Biểu diễn Học, 2021. 2, 3, 4, 5

[7] Zhipeng Cai, Ozan Sener, và Vladlen Koltun. Học liên tục trực tuyến với sự thay đổi phân phối tự nhiên: Một nghiên cứu thực nghiệm với dữ liệu thị giác. Trong Kỷ yếu hội nghị quốc tế IEEE/CVF về thị giác máy tính, trang 8281–8290, 2021. 8

[8] Antonio Carta, Lorenzo Pellegrini, Andrea Cossu, Hamed Hemati, và Vincenzo Lomonaco. Avalanche: Một thư viện pytorch cho học liên tục sâu. arXiv preprint arXiv:2302.01766, 2023. 5, 7

[9] Arslan Chaudhry, Marc'Aurelio Ranzato, Marcus Rohrbach, và Mohamed Elhoseiny. Học suốt đời hiệu quả với a-gem. Trong Hội nghị Quốc tế về Biểu diễn Học, 2018. 2, 3, 4, 5

[10] Arslan Chaudhry, Marcus Rohrbach, Mohamed Elhoseiny, Thalaiyasingam Ajanthan, Puneet K Dokania, Philip HS Torr, và Marc'Aurelio Ranzato. Về những ký ức nhỏ trong học liên tục. arXiv preprint arXiv:1902.10486, 2019. 2, 3

[11] Aristotelis Chrysakis và Marie-Francine Moens. Học liên tục trực tuyến từ dữ liệu mất cân bằng. Trong Hội nghị Quốc tế về Học Máy, trang 1952–1961. PMLR, 2020. 4

[12] Aristotelis Chrysakis và Marie-Francine Moens. Sửa chữa thiên lệch trực tuyến cho học liên tục không có tác vụ. Trong Hội nghị Quốc tế thứ Mười một về Biểu diễn Học, 2022. 7

[13] Andrea Cossu, Tinne Tuytelaars, Antonio Carta, Lucia Passaro, Vincenzo Lomonaco, và Davide Bacciu. Tiền huấn luyện liên tục giảm thiểu sự quên lãng trong Ngôn ngữ và Thị giác, Tháng 5 2022. 4

[14] MohammadReza Davari, Nader Asadi, Sudhir Mudur, Rahaf Aljundi, và Eugene Belilovsky. Thăm dò sự quên lãng biểu diễn trong học liên tục có giám sát và không giám sát. Trong Kỷ yếu Hội nghị IEEE/CVF về Thị giác Máy tính và Nhận dạng Mẫu, trang 16712–16721, 2022. 2, 4, 7

[15] Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Aleš Leonardis, Gregory Slabaugh, và Tinne Tuytelaars. Một khảo sát học liên tục: Thách thức sự quên lãng trong các tác vụ phân loại. Giao dịch IEEE về phân tích mẫu và trí tuệ máy, 44(7):3366–3385, 2021. 5, 7

[16] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, và Li Fei-Fei. Imagenet: Một cơ sở dữ liệu hình ảnh phân cấp quy mô lớn. Trong hội nghị IEEE 2009 về thị giác máy tính và nhận dạng mẫu, trang 248–255. Ieee, 2009. 5

[17] Nikolaos Dimitriadis, Francois Fleuret, và Pascal Frossard. Sequel: Một thư viện học liên tục trong pytorch và jax. arXiv preprint arXiv:2304.10857, 2023. 7

[18] Arthur Douillard và Timothée Lesort. Continuum: Quản lý đơn giản các tình huống học liên tục phức tạp, 2021. 7

[19] Enrico Fini, Victor G. Turrisi Da Costa, Xavier Alameda-Pineda, Elisa Ricci, Karteek Alahari, và Julien Mairal. Các mô hình tự giám sát là người học liên tục. Trong Hội nghị IEEE/CVF 2022 về Thị giác Máy tính và Nhận dạng Mẫu (CVPR), trang 9611–9620, Tháng 6 2022. 4

[20] Yiduo Guo, Bing Liu, và Dongyan Zhao. Học liên tục trực tuyến thông qua tối đa hóa thông tin tương hỗ.

--- TRANG 10 ---
tion. Trong Hội nghị Quốc tế về Học Máy, trang 8109–8126. PMLR, 2022. 7

[21] Trevor Hastie, Robert Tibshirani, Jerome H Friedman, và Jerome H Friedman. Các yếu tố của học thống kê: khai thác dữ liệu, suy luận và dự đoán, tập 2. Springer, 2009. 1

[22] Huiyi Hu, Ang Li, Daniele Calandriello, và Dilan Görür. Một lần qua imagenet. CoRR, abs/2111.01956, 2021. 5

[23] Hyunseo Koh, Dahyun Kim, Jung-Woo Ha, và Jonghyun Choi. Học liên tục trực tuyến về cấu hình tác vụ mờ tăng dần theo lớp với suy luận bất cứ lúc nào. Trong Hội nghị Quốc tế về Biểu diễn Học, 2022. 2, 4, 5

[24] Alex Krizhevsky. Học nhiều lớp đặc trưng từ hình ảnh nhỏ. Báo cáo kỹ thuật, 2009. 5

[25] Lilly Kumari, Shengjie Wang, Tianyi Zhou, và Jeff A Bilmes. Phát lại đối nghịch hồi tưởng cho học liên tục. Tiến bộ trong Xử lý Thông tin Neural, 35:28530–28544, 2022. 2, 3

[26] Matthias De Lange, Gido M van de Ven, và Tinne Tuytelaars. Đánh giá liên tục cho học suốt đời: Xác định khoảng cách tính ổn định. Trong Hội nghị Quốc tế thứ Mười một về Biểu diễn Học, 2023. 2, 4

[27] Timothée Lesort, Vincenzo Lomonaco, Andrei Stoian, Davide Maltoni, David Filliat, và Natalia Díaz-Rodríguez. Học liên tục cho robot: Định nghĩa, khung, chiến lược học, cơ hội và thách thức. Hợp nhất thông tin, 58:52–68, 2020. 7

[28] Zhizhong Li và Derek Hoiem. Học mà không quên lãng. Giao dịch IEEE về phân tích mẫu và trí tuệ máy, 40(12):2935–2947, 2017. 3

[29] Huiwei Lin, Baoquan Zhang, Shanshan Feng, Xutao Li, và Yunming Ye. Pcr: Phát lại tương phản dựa trên proxy cho học liên tục tăng dần theo lớp trực tuyến. Trong Kỷ yếu Hội nghị IEEE/CVF về Thị giác Máy tính và Nhận dạng Mẫu, trang 24246–24255, 2023. 7

[30] David Lopez-Paz và Marc'Aurelio Ranzato. Bộ nhớ từng đoạn gradient cho học liên tục. Tiến bộ trong xử lý thông tin neural, 30, 2017. 2, 4, 5

[31] Divyam Madaan, Jaehong Yoon, Yuanchun Li, Yunxin Liu, và Sung Ju Hwang. Tính liên tục biểu diễn cho học liên tục không giám sát. Trong ICLR, Tháng 4 2022. 4

[32] Zheda Mai, Ruiwen Li, Jihwan Jeong, David Quispe, Hyunwoo Kim, và Scott Sanner. Học liên tục trực tuyến trong phân loại hình ảnh: Một khảo sát thực nghiệm. Neurocomputing, 469:28–51, 2022. 2, 5, 7

[33] Zheda Mai, Ruiwen Li, Hyunwoo Kim, và Scott Sanner. Phát lại tương phản có giám sát: Xem xét lại bộ phân loại trung bình lớp gần nhất trong học liên tục tăng dần theo lớp trực tuyến. Trong Kỷ yếu Hội nghị IEEE/CVF về Thị giác Máy tính và Nhận dạng Mẫu, trang 3589–3599, 2021. 2, 3

[34] Marc Masana, Xialei Liu, Bartłomiej Twardowski, Mikel Menta, Andrew D Bagdanov, và Joost Van De Weijer. Học tăng dần theo lớp: khảo sát và đánh giá hiệu suất về phân loại hình ảnh. Giao dịch IEEE về Phân tích Mẫu và Trí tuệ Máy, 45(5):5513–5533, 2022. 7

[35] Mehryar Mohri, Afshin Rostamizadeh, và Ameet Talwalkar. Nền tảng của học máy. MIT press, 2018. 2

[36] Fabrice Normandin, Florian Golemo, Oleksiy Ostapenko, Pau Rodriguez, Matthew D Riemer, Julio Hurtado, Khimya Khetarpal, Ryan Lindeborg, Lucas Cecchi, Timothée Lesort, et al. Sequoia: Một khung phần mềm để thống nhất nghiên cứu học liên tục. arXiv preprint arXiv:2108.01005, 2021. 7

[37] German I Parisi, Ronald Kemker, Jose L Part, Christopher Kanan, và Stefan Wermter. Học suốt đời liên tục với mạng neural: Một đánh giá. Mạng neural, 113:54–71, 2019. 7

[38] Ameya Prabhu, Philip HS Torr, và Puneet K Dokania. Gdumb: Một phương pháp đơn giản đặt câu hỏi về tiến bộ của chúng ta trong học liên tục. Trong Thị giác Máy tính–ECCV 2020: Hội nghị Châu Âu lần thứ 16, Glasgow, UK, ngày 23–28 tháng 8 năm 2020, Kỷ yếu, Phần II 16, trang 524–540. Springer, 2020. 2, 3

[39] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, và Christoph H Lampert. icarl: Học bộ phân loại và biểu diễn tăng dần. Trong Kỷ yếu hội nghị IEEE về Thị giác Máy tính và Nhận dạng Mẫu, trang 2001–2010, 2017. 4

[40] Albin Soutif-Cormerais, Antonio Carta, và Joost Van de Weijer. Cải thiện hiệu suất và tính ổn định học liên tục trực tuyến với tập hợp thời gian, 2023. 8

[41] Albin Soutif-Cormerais, Marc Masana, Joost Van de Weijer, và Bartlømiej Twardowski. Về tầm quan trọng của các đặc trưng liên tác vụ cho học tăng dần theo lớp. arXiv: 2106.11930, 2021. 2, 4, 6

[42] Zhen Wang, Liu Liu, Yajing Kong, Jiaxian Guo, và Dacheng Tao. Học liên tục trực tuyến với transformer thị giác tương phản. Trong Hội nghị Châu Âu về Thị giác Máy tính, trang 631–650. Springer, 2022. 7

[43] Yaqian Zhang, Eibe Frank, Bernhard Pfahringer, Albert Bifet, Nick Jin Sean Lim, và Alvin Jia. Điều khiển vòng kín cho học liên tục trực tuyến, 2022. 8

--- TRANG 11 ---
[44] Yaqian Zhang, Bernhard Pfahringer, Eibe Frank, Albert Bifet, Nick Jin Sean Lim, và Yunzhe Jia. Một đường cơ sở đơn giản nhưng mạnh mẽ cho học liên tục trực tuyến: Phát lại tăng cường lặp lại. Tiến bộ trong Xử lý Thông tin Neural, 35:14771–14783, 2022. 3, 5

9. Phụ lục

9.1. Kết quả bổ sung
Trong Bảng 3 và 4, chúng tôi trình bày kết quả cho lượng bộ nhớ cực đoan hơn (thấp hơn và cao hơn) trên Split-Cifar100. Đối với thiết lập bộ nhớ thấp, chúng tôi nhận thấy rằng kết quả độ chính xác cuối cùng khác biệt nhiều hơn giữa mỗi phương pháp so với khi sử dụng 2000 bộ nhớ, với ER-ACE đạt kết quả tốt nhất cả về độ chính xác cuối cùng và tính ổn định. Tuy nhiên, độ chính xác thăm dò vẫn gần với phương pháp tham chiếu i.i.d. Khi sử dụng nhiều bộ nhớ hơn, chúng ta thấy rằng hiệu suất của đường cơ sở GDumb phù hợp với phương pháp tham chiếu i.i.d. Tuy nhiên, SCR vượt qua cả hai, cho thấy rằng vẫn có thể học được nhiều hơn từ toàn bộ luồng so với chỉ từ bộ nhớ. Chúng tôi cho rằng điều này là do việc sử dụng kích thước lô bộ nhớ lớn hơn, điều này sẽ có lợi khi sử dụng kích thước bộ nhớ lớn hơn. Để xác minh điều này, chúng tôi thực hiện một thí nghiệm bổ sung nơi chúng tôi cung cấp cho ER cùng kích thước lô bộ nhớ như SCR, chúng ta thấy rằng với sự sửa đổi này, hiệu suất của ER phù hợp với SCR, cho thấy rằng hiệu suất của SCR trong thiết lập này có lẽ là do kích thước lô bộ nhớ lớn hơn chứ không phải do mất mát tương phản có giám sát.

9.2. Chi tiết Triển khai
Mặc dù nỗ lực của chúng tôi để làm cho so sánh công bằng nhất có thể, có một số điểm khó khiến mọi phương pháp trùng khớp. Chúng tôi liệt kê chúng trong phần sau:

• Xử lý thống kê chuẩn hóa lô: Trong khi lấy mẫu một lô từ tác vụ hiện tại và bộ nhớ, có một lựa chọn cần được thực hiện khi chuyển tiếp mỗi lô đến mô hình. Giải pháp mặc định được áp dụng trong Avalanche là nối cả hai lô và thực hiện một lần qua trên mô hình sử dụng thống kê lô được nối (tùy chọn 1). Tuy nhiên, một số phương pháp ban đầu được triển khai bằng cách chuyển tiếp mỗi lô riêng biệt, điều này có thể có ảnh hưởng lớn vì trong trường hợp đó các đầu ra riêng biệt được tạo bằng cách sử dụng thống kê lô nội bộ từng cái (tùy chọn 2). Nói chung, trong khi triển khai các phương pháp, chúng tôi đã chọn tùy chọn hoạt động tốt nhất (ER: 1, DER++: 1, ER-ACE: 2, MIR: 2, SCR: 1, RAR: 2). Lưu ý rằng MIR cũng cập nhật thống kê batchnorm khi chuyển tiếp lô phát lại lớn hơn (từ đó nó chọn các mẫu để phát lại), điều này cũng có ảnh hưởng đến huấn luyện mà các phương pháp khác không có.

• Kích thước lô bộ nhớ: Ban đầu, chúng tôi muốn cố định kích thước lô bộ nhớ sử dụng giao thức xác thực siêu tham số được mô tả ở trên, để mỗi phương pháp có thể chọn kích thước lô bộ nhớ phù hợp của nó. Tuy nhiên, chúng tôi thấy rằng khi sử dụng kích thước bộ nhớ cố định và thực hiện lựa chọn siêu tham số chỉ trên 4 tác vụ, kích thước lô bộ nhớ lớn luôn được chọn vì nó đang cho kết quả có lợi hơn sau khi chỉ thấy 4 tác vụ. Điều này là do việc sử dụng tối ưu kích thước bộ nhớ đầy đủ gần như luôn lặp lại trên các mẫu từ bộ nhớ. Vì lý do này, chúng tôi chọn cũng cố định kích thước lô bộ nhớ có cùng kích thước như của lô hiện tại (như được thực hiện trong hầu hết các nghiên cứu). Tuy nhiên, do việc sử dụng mất mát tương phản, SCR yêu cầu lấy mẫu một lô lớn từ bộ nhớ, vì vậy chúng tôi cố định kích thước lô bộ nhớ thành một số cao hơn (118), điều này khiến nó hoạt động khác so với các phương pháp khác.

• Bộ phân loại động: Trong học liên tục, người học không được biết tổng số lớp mà nó sẽ gặp trong quá trình huấn luyện. Đây là lý do tại sao chúng tôi triển khai hầu hết các phương pháp sử dụng lớp phân loại động thêm các đơn vị mới bất cứ khi nào gặp một lớp mới. Tuy nhiên, một phương pháp (DER++) yêu cầu phát lại logits của các mẫu từ các lớp trước đó vào các lớp mới. Triển khai chính thức sử dụng lớp phân loại có kích thước cố định, và chúng tôi đã sử dụng tương tự trong các thí nghiệm của mình, khiến nó khác với những gì các phương pháp khác làm.

9.3. Siêu tham số
Trong mã (https://github.com/AlbinSou/ocl_survey), chúng tôi cung cấp tập lệnh được sử dụng để thực hiện lựa chọn siêu tham số (experiments/main_hptuning.py) cũng như các cấu hình tốt nhất chúng tôi tìm thấy sau 200 thử nghiệm cho mỗi phương pháp sử dụng 4 tác vụ đầu tiên của luồng. Chúng tôi cung cấp các cấu hình này cho mỗi bộ đo lường dưới thư mục config/best_configs. Các phạm vi siêu tham số được kiểm tra cho mỗi phương pháp có sẵn trong experiments/spaces.py.

--- TRANG 12 ---
[THIS IS TABLE: Bảng 3 - Kết quả bước cuối trên Split-Cifar100 (20 Tác vụ) với 500 bộ nhớ]
Phương pháp | Acc↑ | AAAval↑ | WC-Accval↑ | Probed Acc ↑
i.i.d | 28.3±1.5 | - | - | 40.0±0.9
GDumb | 8.8±0.5 | - | - | -
AGEM | 3.2±0.4 | 10.4±0.5 | 3.2±0.3 | 19.2±0.7
ER | 15.7±1.2 | 28.6±1.7 | 7.7±0.9 | 38.2±1.2
ER + LwF | 19.7±1.5 | 32.5±1.9 | 10.6±0.9 | 38.0±1.6
MIR | 15.7±1.4 | 27.4±2.4 | 9.3±7.7 | 36.2±1.0
ER-ACE | 20.8±0.9 | 32.8±2.2 | 11.5±0.5 | 36.8±1.1
DER++ | 15.2±1.4 | 28.9±3.0 | 7.9±0.6 | 37.1±1.5
RAR | 14.6±1.2 | 28.6±1.5 | 7.9±0.6 | 35.7±0.9
SCR | 13.2±0.5 | 29.4±1.9 | 8.5±0.5 | 28.4±0.5

Bảng 3: Kết quả bước cuối trên Split-Cifar100 (20 Tác vụ) với 500 bộ nhớ. Chúng tôi báo cáo trung bình và độ lệch chuẩn qua 5 thử nghiệm

[THIS IS TABLE: Bảng 4 - Kết quả bước cuối trên Split-Cifar100 (20 Tác vụ) với 8000 bộ nhớ]
Phương pháp | Acc↑ | AAAval↑ | WC-Accval↑ | Probed Acc ↑
i.i.d | 39.0±1.8 | - | - | 49.3±0.9
GDumb | 39.6±0.4 | - | - | -
AGEM | 3.1±0.3 | 10.5±0.5 | 3.1±0.2 | 18.6±0.8
ER | 34.9±1.8 | 39.1±1.7 | 13.2±0.8 | 48.7±0.7
ER + LwF | 36.7±1.3 | 41.7±1.8 | 17.2±0.9 | 48.5±0.9
MIR | 31.8±1.4 | 33.6±2.6 | 8.4±1.4 | 47.8±0.8
ER-ACE | 35.1±1.2 | 40.6±1.5 | 16.8±1.1 | 47.0±0.7
DER++ | 36.1±1.7 | 40.8±2.0 | 14.6±0.4 | 49.1±0.7
RAR | 36.9±2.0 | 42.2±1.3 | 16.1±1.2 | 48.1±1.2
SCR | 43.5±0.7 | 50.2±2.1 | 32.6±0.7 | 47.3±0.7
ER² | 43.0±0.7 | 52.7±2.2 | 30.7±0.9 | 49.5±1.4

Bảng 4: Kết quả bước cuối trên Split-Cifar100 (20 Tác vụ) với 8000 bộ nhớ. Chúng tôi báo cáo trung bình và độ lệch chuẩn qua 5 thử nghiệm

²Phiên bản ER đã sửa đổi với kích thước lô bộ nhớ là 118 (để phù hợp với kích thước của SCR)

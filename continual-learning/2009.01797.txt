# 2009.01797.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/continual-learning/2009.01797.pdf
# File size: 3053114 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
A Wholistic View of Continual Learning with Deep Neural Networks:
Forgotten Lessons and the Bridge to Active and Open World Learning
Martin Mundta,c,<, Yongwon Hongb, Iuliia Pliushchaand Visvanathan Ramesha
aDepartment of Computer Science, Goethe University, Theodor-W.-Adorno-Platz 1, 60323 Frankfurt, Germany
bDepartment of Computer Science, Yonsei University, 50 Yonsei-ro, Seodaemun-gu, 03722 Seoul, Republic of Korea
cDepartment of Computer Science, TU Darmstadt, Karolinenplatz 5, 64289 Darmstadt, Germany
ARTICLE INFO
Keywords :
Continual Deep Learning
Lifelong Machine Learning
Active Learning
Open Set Recognition
Open World LearningABSTRACT
Current deeplearning methodsareregardedasfavorable iftheyempiricallyperformwellondedicated
test sets. This mentality is seamlessly reﬂected in the resurfacing area of continual learning, where
consecutively arriving data is investigated. The core challenge is framed as protecting previously
acquiredrepresentationsfrombeingcatastrophicallyforgotten.However,comparisonofindividual
methods is nevertheless performed in isolation from the real world by monitoring accumulated
benchmark test set performance. The closed world assumption remains predominant, i.e. models
areevaluatedondatathatisguaranteedtooriginatefromthesamedistributionasusedfortraining.This
posesamassivechallengeasneuralnetworksarewellknowntoprovideoverconﬁdentfalsepredictions
on unknown and corrupted instances. In this work we critically survey the literature and argue that
notable lessons from open set recognition, identifying unknown examples outside of the observed
set, and the adjacent ﬁeld of active learning, querying data to maximize the expected performance
gain,arefrequentlyoverlookedinthedeeplearningera.Hence,weproposeaconsolidatedviewto
bridgecontinuallearning,activelearningandopensetrecognitionindeepneuralnetworks.Finally,the
established synergies are supported empirically, showing joint improvement in alleviating catastrophic
forgetting, querying data, selecting task orders, while exhibiting robust open world application.
1. Introduction
Withtheongoingmaturingofpracticalmachinelearning
systems,thecommunityhasfoundaresurfacinginterestin
continuallearning(Thrun,1996b,a).Incontrasttothebroadly
practiced learninginisolation ,wherethealgorithmictraining
phase of a system is constrained to a single stage based on a
previously collected i.i.d. dataset, continual learning entails
a learning process that leverages data as it arrives over time.
In spite of this paradigm having found various application in
manymachinelearningsystems,forareviewseetherecent
bookon lifelongmachine learningbyChen andLiu(2017),
theadventofdeeplearningseemstohavesteeredthefocus
of current research eﬀorts towards a phenomenon known
ascatastrophic interference or alternatively catastrophic
forgetting (McCloskey and Cohen, 1989; Ratcliﬀ, 1990),
as suggested by recent reviews (Farquhar and Gal, 2018b;
Parisi et al., 2019; De Lange et al., 2021; Lesort et al.,
2020) and empiricalsurveys of deep continual learning (De
Langeetal.,2021;Lesortetal.,2019;PfülbandGepperth,
2019).Thelatterisaneﬀectparticulartomachinelearning
modelsthatupdatetheirparametersgreedilyaccordingtothe
presenteddatapopulation,suchasaneuralnetworkiteratively
updatingitsweightswithstochasticgradientestimates.When
continuously arriving data is included that leads to any shift
in the data distribution, the set of learned representations
isguided unidirectionallytowardsapproximatingany task’s
solutiononthedatainstancesthesystemispresentlybeing
<Corresponding author. Main work conducted while aﬃliated with
Goethe University. Present aﬃliation is with TU Darmstadt.
martin.mundt@tu-darmstadt.de (M. Mundt); yhong@yonsei.ac.kr (Y.
Hong); pliushch@em.uni-frankfurt.de (I. Pliushch);
vramesh@em.uni-frankfurt.de (V. Ramesh)exposedto.Thenaturalconsequenceisoverwritingformer
learnedrepresentations,resultinginanabruptforgettingof
previously acquired information.
Whereas current works predominantly concentrate on
alleviatingsuchforgettingincontinualdeeplearningthrough
the design of specialized mechanisms, we argue that there
is a growing risk in the continual learning ﬁeld becoming
overly narrow. There clearly have been commendable eﬀorts
towards preserving neural network representations in contin-
uous training. However, such a high focus is given on the
practicalrequirementsandtrade-oﬀsofmetricsthatsurround
catastrophicforgetting(Kemkeretal.,2018),e.g.inclusion
ofmemoryfootprint,computationalcost,costofdatastorage,
task sequence length and amount of training iterations, §
(Díaz-Rodríguez et al., 2018; Farquhar and Gal, 2018b), that
it could almost be seen as misleading when most current
systems break immediately if unseen unknown data or minor
corruptionsareencounteredduringdeployment(Matanetal.,
1990; Boult et al., 2019; Hendrycks and Dietterich, 2019).
The assumption of a closed world seems omnipresent. In
other words, there is a common belief that the model will
always exclusively encounter data that stems from the same
data distribution as encountered during training. This is
highly unrealistic in the real open world , where data can
vary to extents that are impractical to capture into training
sets or users have the ability to give almost arbitrary input
tosystemsforprediction.Ithasbeenawellknownfactfor
decades that neural networks are wrongly overconﬁdent in
such real world settings (Matan et al., 1990). In spite of
theinevitabledangerofneuralnetworksgeneratingentirely
meaninglesspredictionswhenencounteringunseenunknown
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 1 of 37arXiv:2009.01797v3  [cs.LG]  23 Jan 2023

--- PAGE 2 ---
A Wholistic View of Continual Learning with Deep Neural Networks
data instances, current eﬀorts towards benchmarking contin-
uallearningconvenientlycircumventthischallenge.Select
exceptionsattempttosolvethetasksofrecognizingunseen
and unknown examples, rejecting nonsensical predictions
or setting them aside for later use, typically summarized
under the umbrella of open set recognition . Nevertheless,
the majority of existing deep continual learning systems
remainblackboxesthatunfortunatelydonotexhibitdesirable
robustnesstorespectivemiss-predictionsonunknowndata,
dataset outliers or common corruptions (Hendrycks and
Dietterich, 2019).
Apart from current benchmarking practices still being
constrained to the closed world, another unfortunate trend is
a lack of understanding for the nature of created continual
learning datasets. Both continual generative modeling, Shin
etal.(2017);Achilleetal.(2018);FarquharandGal(2018a);
Nguyen et al. (2018); Wu et al. (2018); Zhai et al. (2019),
as well as the bulk of class incremental continuous learning
worksLiandHoiem(2016);Kirkpatricketal.(2017);Rebuﬃ
etal.(2017);Lopez-PazandRanzato(2017);Kemkeretal.
(2018); Kemker and Kanan (2018); Xiang et al. (2019)
generallyinvestigatesequentializedversionsoftime-tested
visual classiﬁcation benchmarks. For instance, in popular
class incremental MNIST (LeCun et al., 1998), CIFAR
(Krizhevsky, 2009) or ImageNet (Russakovsky et al., 2015),
individualclassesaresimplysplitintodisjointsetsandare
shown in sequence. In favor of retaining comparability on
abenchmark,questionsabouttheeﬀectoftaskorderingor
theimpactofoverlapbetweentasksareroutinelyoverlooked.
Notably, lessons learned from the adjacent ﬁeld of active
machine learning , a particular form of semi-supervised
learning, do not seem to be integrated into modern continual
learningpractice.Inactivelearningtheobjectiveistolearn
to incrementally ﬁnd the best approximation to a task’s
solutionunderthechallengeoflettingthesystemitselfquery
what data to include next. As such, it can be seen as an
antagonist to alleviating catastrophic forgetting. Whereas
current continual learning is occupied with maintaining
the information acquired in each step without endlessly
accumulating all data, active learning has focused on the
complementary question of identifying suitable data for the
inclusion into an incrementally training system. Although
earlyseminalworksinactivelearninghaverapidlyidentiﬁed
thechallengesofrobustapplicationandpitfallsfacedthrough
the use of heuristics (Roy and McCallum, 2001; Settles and
Craven,2008;LiandGuo,2013),thelatterarenonetheless
onceagaindominantintheeraofdeeplearning(Beluchetal.,
2018; Geifman and El-Yaniv, 2019; Gal and Ghahramani,
2015; Srivastava et al., 2014) and the challenges seem to be
faced anew.
With the above challenges in mind, we can rapidly build
our intuition for why they are connected if we brieﬂy take
a look at autonomous driving, as one practical example. If
weaimtolearnhowtodriveinnewenvironments,itisnot
onlysuﬃcienttomakesurethatwearecapableoflearning
from new data while preserving existing knowledge. It issimilarly important to acknowledge that newly arriving data
may be skewed in uninteresting or potentially harmful ways.
New falsely predicted objects could appear, particularly rare
events could pose a threat, and sensors may deteriorate or
fail. Identifying what is already known and distinguishing it
withunseennovelinstancesisessential.Decidingwhichof
thisnewdataismeaningfulandwhichshouldbediscarded
for future learning provides closure to the learning cycle.
In this work we thus make a ﬁrst eﬀort towards a
principled and consolidated view of deep continual learning,
activelearningandlearningintheopenworld.Westartwitha
historicalperspectiveandbyprovidingareviewofeachtopic
in isolation. We then proceed to identify notable previous
lessonsthatappearto receivelessattentioninmoderndeep
learning. Speaking hyperbolically, they appear to have been
“forgotten”inmany recentcontinuallearning works.As we
will see throughout the survey, individual ﬁelds may have
been studied extensively by themselves in isolation, but their
impact seems to be largely overlooked when considered
together. We will continue to argue that these seemingly
separate topics do not only beneﬁt from the viewpoint of the
other, but shouldbe regarded in conjunction. In this sense,
we propose to extend current continual learning practices
towards a broader view of continual learning as an umbrella
term. Our survey thus complements existing continual learn-
ing reviews (Farquhar and Gal, 2018b; Parisi et al., 2019;
De Lange et al., 2021; Lesort et al., 2020), but instead of
surveyingthemathematicalfoundationofeveryindividual
algorithm to alleviate catastrophic forgetting in detail, we
provide a more critical overview. As a crucial diﬀerence,
we connect thought patterns towards continual learning that
naturallyencompassesandbuildsuponpriorinsightsfrom
active learning and open set recognition. To highlight the
correspondingly developed synergies and showcase their
practical potential, we complement our consolidated survey
withempiricalevidencesupportingvariousimportantaspects:
extraction of exemplars or core sets, active data queries,
robustness to open world corruptions, and choosing a task
order curriculum. For this purpose, we adapt and extend a
recently proposed approach based on variational Bayesian
inference in neural networks (Mundt et al., 2022, 2019) to
illustrateonepotentialchoicetowardsacomprehensiveframe-
work. Importantly, we emphasize that we do not propose
thisapproachasauniversaloruniquesolution,butuseitto
highlight the importance of the viewpoints developed in this
paper.
2. Preamble: continual machine learning
It is likely that the idea of continual machine learning
dates back to a similar period of time to the surfacing of
machine learning itself. There have been many attempts at
deﬁningconceptssuchascontinuous,lifelongorcontinual
machine learning. Often these terms feature negligible
nuancesandcangenerallybetakenassynonyms.However
it seems diﬃcult, and perhaps is not constructive, to attempt
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 2 of 37

--- PAGE 3 ---
A Wholistic View of Continual Learning with Deep Neural Networks
to pin-point the exact onset of when something should be
referredtoascontinualorlifelonglearning.Instead,inthis
preamble, we will present deﬁnitions and related paradigms
that have come to enjoy great popularity in the machine
learning community. Note that many of these deﬁnitions are
not necessarily formal or mathematical, but are nevertheless
illustrated here for a historical perspective. Some paradigms
are already, or if not yet, should be considered subsets of
continual learning (CL). As a standalone paradigm they
vary primarily in their current evaluation protocols. We will
brieﬂyintroduceeachoftheseparadigmsandthenproceed
to summarize and identify characteristic diﬀerences with
respect to the broader term of modern continual learning.
The ﬁrst widely circulated deﬁnition of lifelong machine
learning(LML)originatedintheworkproposedbyThrun
(1996b,a). This deﬁnition is as follows:
Deﬁnition1. Thrun(1996b,a)-LifelongMachineLearning:
The system has performed Ntasks. When faced with the
(N+1)th task, it uses the knowledge gained from the Ntasks
to help the ( N+1)th task.
Here,theunmentionedessenceisthatthedataoftheﬁrst
Ntasks is generally assumed to be no longer available at
the time of learning about the .N+1/th task. That is, the
observed data is not just endlessly accumulated and stored
explicitly. Whereas this deﬁnition captures the basic idea
behind continued learning, it is also ambiguous with respect
to the deﬁnition of task and knowledge. There have been
many attempts to ﬁnd a more concise deﬁnition across the
literatureovertheyears.Oneofthemoresuccinct,yetstill
decently generic deﬁnitions followed in the work of Chen
and Liu (2017):
Deﬁnition 2. Chen and Liu (2017) - Lifelong Machine
Learning: Lifelong Machine Learning is a continuous learn-
ing process. At any time point, the learner performed a
sequence of Nlearning tasks, T1;T2;§;TN. These tasks
can be of the same type or diﬀerent types and from the
same domain or diﬀerent domains. When faced with the
(N+1)th task TN+1(which is called the new or current
task) with its data DN+1, the learner can leverage past
knowledgeintheknowledgebase(KB)tohelplearn TN+1.
TheobjectiveofLMLisusuallytooptimizetheperformance
on the new task TN+1, but it can optimize any task by
treating the rest of the tasks as previous tasks. KB maintains
the knowledge learned and accumulated from learning the
previous task. After the completion of learning TN+1, KB is
updated with the knowledge (e.g. intermediate as well as the
ﬁnalresults)gainedfromlearning TN+1.Theupdatingcan
involve inconsistency checking, reasoning, and meta-mining
of additional higher-level knowledge.
The authors of this latter deﬁnition argue that it can
be summarized into three key characteristics: continuous
learning; knowledge accumulation and maintenance in the
knowledge base (KB); the ability to use past knowledge to
help future learning. In contrast to the previous deﬁnition
1
 Continuous learning
2
Knowledge accumulation
and maintenance in the
knowledge base (KB)
3
The ability to use past
knowledge to help future learning
4
 The ability to discover new tasks
5
The ability to learn while
working or to learn on the job
Figure 1: The ﬁve main pillars of lifelong machine learning
according to Chen and Liu (2017). Note that the ﬁrst three
pillars were originally proposed and the last two added recently
in a second edition redeﬁnition to emphasize new frontiers.
by Thrun (1996b,a), mainly the notion of a maintained
knowledgebaseisintroduced.HereLMLisnowdeﬁnedsuch
thatatanygivenpointintimeperformancecanbeoptimized
for any given task by treating all other tasks as previously
presented, irrespective of their original order. Whereas the
originaldeﬁnitionoptimizedtowardsbeneﬁting TN+1inonly
one direction, thus allowing for performance of previous
tasks to degrade over time, Chen and Liu (2017) explicitly
formulatethepreservationofallaccumulatedinformationasa
fundamentalgoalofLML.Inarecentseconditerationofthis
deﬁnition, the authors have added two additional desiderata:
theabilitytodiscovernewtasksandtheabilitytolearnwhile
working. We have visualized these ﬁve essential pillars of
LML in Figure 1.
Althoughacknowledgedbytheauthorsthemselves, this
extended deﬁnition still lacks with respect to certain aspects:
•a coherent description of domain. This is currently not
used unanimously in the literature and often applied
interchangeably with task.
•a formalization of knowledge or respective represen-
tation thereof in the KB. Typically this is practically
constrained to speciﬁc applications.
•theessentialquestionofevaluationpractice,i.e.choos-
ing,orderingandevaluatingthesequenceoftasks.This
generally requires a human in the loop and considered
evaluation scenarios can vary immensely between
individual works.
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 3 of 37

--- PAGE 4 ---
A Wholistic View of Continual Learning with Deep Neural Networks
Therearemanymoreencounteredopenquestionswith
LML in practice, especially with respect to modern machine
learning algorithms based on deep learning. As the latter
is primarily based on the use of neural networks (NN),
theywillconstitutethemainfocusofthispaper.Whilethe
presented arguments will often be of generic nature, this
has the advantage that the concept of a knowledge base and
its maintenance collapses to the question of managing the
model’slearnedrepresentationsandoptionaldatamemory
buﬀers containing past experiences. This is an important
distinction,andperhapsasimpliﬁcation,incomparisontothe
wayChenandLiu(2017)(andﬁgure1)originallyusetheterm
knowledge.Here,thelatterisadoptedinthespiritoftheolder
“never-ending learning” systems for language and images
(NELL and NEIL)(Carlson et al., 2010; Chen et al., 2013;
Mitchell et al., 2015), which take a more “traditional” AI
approach.Inadditiontolearnedparametersandoriginaldata
instances,therespectiveknowledgebasesleveragevarious
neuro-symbolictechniques,suchasaccountingforexplicit
context,extractingrelations,andinvolvingrules.Concepts
that are typically not accounted for in deep neural networks.
At the same time, the presently more collapsed notion of
knowledgeinadeepneuralnetworkcanmakethequestion
of how to leverage prior information quite involved. Rep-
resentations in NNs are densely entangled within layers as
well as distributed hierarchically across layers. Although we
constrainourselvestoNNs,weimportantlyemphasizethat
thetermsknowledgeandknowledgebasewillbeusedbeyond
a narrow interpretation of data instances or parameters
in the remainder of the manuscript, retaining a broader
interpretationforfuturework.Beforedelvingintoareview
of contemporary works, their merits and current limitations,
we will present various popular paradigms that are related
to the former deﬁnitions of LML. This will then be followed
byabriefsummaryonevaluationpracticestohighlightthe
nuances.
2.1. Related paradigms: subsets of continual
learning
Overthecourseofmachinelearningdevelopment,vari-
ousdiﬀerentparadigmsandevaluationpracticeshaveevolved.
Throughout this paper, we will come to the already apparent
conclusion that CL should ideally be deﬁned as a superset.
We will make an attempt towards a deﬁnition that is more
encompassing of the potential elements at the end of this
manuscript. For now, we start by introducing commonly
considered machine learning paradigms. As a word of
caution, the following deﬁnitions should be regarded as
non-exhaustive.Eventhoughwehavemadeaconsiderable
eﬀort to provide a comprehensive amount of references, the
practical use of certain terminology in particular may still
varylargelyfromcommunitytocommunity.Thefollowing
shall thus reﬂect the common use in modern deep learning.
We begin with transfer learning as it can intuitively be
regarded as the most related concept. Originally, transfer
learning has been proposed as converting a weak learner,
one that performs marginally better than random guessing,to one that produces stronger hypotheses (Schapire, 1990).
Thecorrespondingformulationthatismorespeciﬁctoneural
networks is how the representations obtained by learning
through backpropagation can be “recycled” for new tasks
(Prattetal.,1991;Pratt,1993).Thischallengeinitiallywasn’t
unanimously referred to as transfer learning, but often was
referredtoasboosting(FreundandSchapire,1997).Apre-
deep learning survey (Pan and Yang, 2010) has summarized
eﬀortsandformalizedtransferlearninginthewayusedtoday:
Deﬁnition3. TransferLearning PanandYang(2010):Given
a source domain and learning task, a target domain and
learning task, transfer learning aims to help improve the
learningofthetargetpredictivefunctioninthetargetdomain
using the knowledge in the source domain and task, where
the source and target domain, or the source and target task
are unequal.1
Here,PanandYang(2010)formalizetheuseoftheterms
domainandtaskin the context of supervised transfer with
datasets consisting of a ﬁnite amount of data instances. They
aredeﬁnedbythefollowing:Givenaspeciﬁcdomain,deﬁned
as the pair of marginal data distribution and a corresponding
featurespace,ataskconsistsoftwocomponents:alabelspace
andanobjectivepredictivefunction(whichmapstothelabel
spaceandisnotobserved,butcanbelearnedfromthetraining
data, consisting of pairs of data instances and respective
labels) (Pan and Yang, 2010). The concept of a domain is
thereforedeﬁnedasthepairofmarginaldatadistributionand
a corresponding feature space, where it is generally implied
that source and target feature space, or source and target
data sets are unequal. An eﬀortless translation of transfer
learningtounsupervisedorreinforcementlearningsettings
is possible. Without further extensions, this deﬁnition of
transfer learning is essentially a narrowed down version of
theprimitivelifelonglearningdeﬁnition1,withthenuance
that there typically only exist two tasks. It is similarly one
directional in the sense that the source task is only used to
improve learning the new target.
Sincethenanenormousamountofworkshassprouted,
initiated by works that have started the investigation of
transferabilityofdeepneuralnetworkfeaturesbeyondlow-
level patterns (Oquab et al., 2014; Yosinski et al., 2014), i.e.
thehigherabstractionsandtask-speciﬁcinformationbelieved
tobeencodedindeeperlayersofthehierarchy.Weissetal.
(2016) have provided a survey on recent advances. In this
context of feature transferability, a variantnamed multi-task
learning(MTL)hasemerged.Caruana(1997)summarizes
the goalof MTLsuccinctly: “MTL improvesgeneralization
byleveragingthedomain-speciﬁcinformationcontainedin
thetrainingsignalsofrelatedtasks” .Earlyworkssometimes
referredtothisasincluding“hints”(SuddarthandKergosien,
1990;Abu-Mostafa,1990)toimprovelearning.Incontrast
to transfer learning, generally multiple tasks are considered,
1Note that mathematical symbols (such as DSorDTto denote source
andtargetdomain)havebeenomittedfromtheoriginaldeﬁnitionforease
of readability. We will continue to omit these symbols in the follow-up
deﬁnitions as they do not serve a higher purpose in the current overview.
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 4 of 37

--- PAGE 5 ---
A Wholistic View of Continual Learning with Deep Neural Networks
with the requirement of the model performing well on all
ofthem.However,intheMTLsetting,tasksarealltrained
jointly and no sequence is assumed, corresponding to typical
isolated learning practice. In modern day deep networks,
MTL thus culminates in the question of how to exactly
share the abundant amount of parameters in the architectural
hierarchy, see e.g. the overview provided by Ruder (2017)
for variants of sharing architecture portions.
Morerecently,averyspeciﬁcformoftransferormulti-
task learning has evolved. Few-shot Learning (Fei-Fei et al.,
2006) developed due to the inability of deep learning tech-
niques to cope with small datasets and empirical risk opti-
mizationbeingunreliableinsmallsampleregimes.Wangetal.
(2020)summarizedfew-shotlearningasatypeofmachine
learningproblem,wherethedatasetonlycontainsalimited
number of examples with supervised information for the
target domain (and generally no constraints on the source
domain). This implies that few-shot learning also tackles the
issue of rare cases, apart from computational cost and the
issueofdatacollectionandlabelling.Whenthereisonlyone
example with a label, it is commonly referred to as one-shot
learning(Fink,2005;Fei-Feietal.,2006).Respectively,if
nosupervisedexampleisprovided,thescenarioisreferredto
aszero-shot learning (Lampert etal., 2009).Thesescenarios
are typically regarded under the hood of transfer learning
with additional constraints on data availability.
Apart from concerns about reasonably sized datasets,
a diﬀerent concern is as old as the search for stochastic
approximations itself, namely when to conduct updates.
Already in the work of Hebb (1949), online learning , i.e.
incorporating information immediately as data arrives as
opposed to collecting batches before updating a model, was
a natural requirement. This question has been elemental
in later formalization of frameworks for empirical risk
optimization(Tsypkin,1971;Vapnik,1982).Severalworks
have elaborated on challenges in: online learning in NNs
(Heskes and Kappen, 1993), more generally online learning
and stochastic approximations (Bottou, 1999; Saad, 1999),
or speciﬁcally online gradient descent (Zinkevich, 2003), the
workhorseofmodernoptimization.Giventheinstancebased
updatenature,onlinelearninginneuralnetworksisinherently
tied to the question of how to avoid catastrophic interference.
ItisthusnotsurprisingthatwiththeadventofDLimmediate
attempts have been made to consider online learning in
DNNs (Zhou et al., 2012), see a recent survey by Sahoo et al.
(2018).Nevertheless,researchtowardsonlinelearningstill
revolvesaroundtheinteractionbetweenonlinedesiderataand
stochastic approximations, or the stochastic gradient descent
with backpropagation procedure in particular.
Ultimately,eachparadigmaroseforareasonandcomes
withitsownvalue,namelythatofprovidingbetterdistinction
to other works in concrete evaluation scenarios. However,
it is important to remember that the emerging taxonomy is
fullofnuancesthatareattimesindistinguishableinamore
general framework. In consequence, evaluation protocols are
central to any discussion. We therefore proceed with details
of common evaluation methods in deep continual learning
Previous
tasks
Run machine learning algorithms
on previous tasks one at a
time. Retain knowledge in KB.
New
task
Run machine learning algorithms on
new task. Leverage knowledge in KB.
Baseline
algorithms
Run baseline algorithms: isolated
learning on only the new task
and other LML approaches.
Analyze
results
Compare the approach to other
lifelong learning approaches
and isolated learning schemes.
Figure 2: A widely used approach to evaluation of lifelong
machine learning algorithms in the literature (Chen and Liu,
2017).
and then summarize the main diﬀerences to the paradigms
introduced in this section for a compact overview.
2.2. Continual learning evaluation
In contrast to isolated machine learning, where the
evaluation scenario can often be deﬁned in a straightfor-
ward manner by employing performance or satisfying task
metrics,continuallearningdoesnotdirectlyallowforsuch
anapproach.Giventhattheinterestliesinaccumulationof
information, there are many factors to consider in evaluation
of corresponding algorithms. In general it is important to
monitor the currently introduced task, yet also investigate
semantic drift on previous tasks. One should consider the
gain and the ability to leverage representations from task
totaskinprogressiveexperimentation,yettakenoteofthe
task sequence that is crucial to the speciﬁc solution obtained.
Whenintroducingmoretasks,thetransferbehaviorshould
becarefullyexamined,yetcautiouslyinterpreted,asnotall
introducedtasksyieldimmediatebeneﬁtsandthusalarger
amount of tasks needs to be brought in to the system.
Before continuing with the discussion of evaluation
diﬃculties and metrics, let us take a brief look at some
currently employed evaluation methodology (Chen and Liu,
2017), summarized visually in Figure 2. It seems that
such an evaluation protocol is still largely inspired by the
isolatedmachinelearningpractices.Whereasthenotionof
information transferand the sequence of tasksis considered
and benchmarked against isolated learning algorithms, such
an approach to evaluating the value of continual learning
algorithms disregards the relevance of the task sequence (or
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 5 of 37

--- PAGE 6 ---
A Wholistic View of Continual Learning with Deep Neural Networks
permutationthereof),choiceoftasksorchoiceofdata.Ac-
cordingly,recentlydevelopedexperimentalprotocolsindeep
continual learning (Farquhar and Gal, 2018b; Kemker et al.,
2018; Parisi et al., 2019; De Lange et al., 2021; Lesort et al.,
2019;PfülbandGepperth,2019;Lesortetal.,2020)seemto
mainly occupy themselves with evaluation procedures that
are heavily inspired by decades of benchmarking learning
algorithms in isolation. As a reminder to the reader, we refer
toisolatedlearningasthepracticeofend-to-endtrainingona
staticdatasetandevaluationonitspredeﬁnedtestset,without
changesovertime.Assuch,themajorityofcurrentempirical
examination equates continual learning benchmarks with the
monitoring of catastrophic forgetting in scenarios that are
simple sequentialized versions of popular datasets, similarly
to the steps shown in Figure 2. With few exceptions, this
meansthatexistingdatasetsaresimplysplitinto t=1;§;T
sets,whereeachofthesesetsisreferredtoasonetask.These
task-ortime-stampedsetsarethenpresentedonebyoneto
a deep learning system. Typically, each step is assumed to
consistofadisjointsetofclassesorentiredatasets,usually
independently of whether the probed task is of supervised,
unsupervised or semi-supervised nature, see Figure 3 for
an illustration. Respectively analyzed metrics (Kemker et al.,
2018)arebasedonthisdatasetsequentializationandroutinely
monitor e.g. the degradation of a ﬁrst task’s classiﬁcation
accuracy, the ability to encode new task increments, the
overalldevelopmentofachosenmetricastasksaccumulate
orvarioussimilarmeasurestogainanintuitionforgenerative
models.Itisobvioushowthisisinspiredbyisolatedlearning
as these metrics can simply be extracted from a conventional
confusion matrix. For this reason, multiple eﬀorts have been
made to emphasize the need for more diverse evaluation
(Díaz-Rodríguezetal.,2018;FarquharandGal,2018b).Alas,
thepersistingfocusoncatastrophicforgettingremainsvisible
fromtheformulatedcriteriaandquestionsthataredeemed
necessary to compare methods (Díaz-Rodríguez et al., 2018;
Farquhar and Gal, 2018b):
•Memory consumption: amount of required memory.
•Amount of stored data: how much past data does the
method need to retain explicitly?
•Task boundaries: does the method require clear task
divisions?
•Prediction oracle: doesthemethodrequireknowingthe
task label for prediction?
•Amountofforgetting: howmuchinformationisretained
as measured through proxy metrics.
•Forward transfer: do older tasks accelerate learning of
new concepts?
•Backward transfer: do new tasks beneﬁt old tasks?
Atthisstagethereadermightalreadynoticethatsomeof
these listed items are rather particular to speciﬁc practices.
For example, the idea that a prediction oracle would be
Task 1 Task 2 Task 3
Figure 3: A typical continual learning scenario dividing common
benchmark datasets into a sequence of sub-tasks. Here, the
digits one through six from the MNIST dataset (LeCun et al.,
1998) and the Wordnet ids “n01443537”: goldﬁsh, “n01641577”:
bullfrog, “n01644900”: tailed frog, “n01910747”: jellyﬁsh,
“n09246464”: cliﬀ, “n02814860”: beacon from the ImageNet
dataset (Russakovsky et al., 2015). Common evaluation either
follows the ﬁlled dark arrows to incrementally learn one dataset
or alternatively also switches dataset, as denoted by the hollow
light arrows.
required in the ﬁrst place in order to give task labels is an
artifactofseveralworksthatconsidersocalled multi-head
scenarios.Suchamulti-headsettingmakesuseofseparate
disjointclassiﬁerspertasktocircumventexplicitlydealing
with task prediction interdependence. In other words, each
taskisprovidedaseparatelabel,whichiscommonlyassumed
to be additionally provided during inference to decide which
oftheclassiﬁersshouldbeselected.Thereexistrecentreviews
(De Lange et al., 2021) that base their entire evaluation
on such a scenario. Empirical surveys in the context of
robotics(Lesortetal.,2019),generativemodels(Lesortetal.,
2020)followsimilartrendsandconducta“comprehensive
application-oriented study of catastrophic forgetting” (Pfülb
and Gepperth, 2019). With catastrophic forgetting being
the sole focus, these works at best cover the ﬁrst three of
the ﬁve earlier formulated continual learning pillars 1, if
and only if they also conduct an analysis on how speciﬁc
tasks beneﬁt each other. The recent critiques that formulated
above questions (Díaz-Rodríguez et al., 2018; Farquhar and
Gal, 2018b) therefore present valid attempts to rid current
evaluation from such practices that can be seen as inherently
violating real continual learning scenarios. Nevertheless, we
argue that there are even larger factors at play that transcend
these arguments. Although transfer and the sequential nature
is considered and benchmarked against isolated learning,
crucial aspects such as the relevance of the task order (or
permutation thereof), choice of tasks ,choice of data and
particularly any form of robustness in an open world are
frequently overlooked or may even be disregarded altogether.
Open research areas such as curriculum learning (Bengio
etal.,2009),i.e.beneﬁtingfromadataorderingofincreasing
complexity, open world learning (Bendale and Boult, 2016),
i.e. equipping the model with awareness of unseen unknown
data, and active learning, i.e. self-selecting data to query for
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 6 of 37

--- PAGE 7 ---
A Wholistic View of Continual Learning with Deep Neural Networks
thenextstep,trytoaddressthesecrucialelements.Weargue
that it is imperative to take these perspectives into account
in the evaluation of continual learning algorithms. Before
proceeding to categorize individual works and consequently
making an attempt at connecting the paradigms, we give a
brief summary of the present evaluation diﬀerences. Here,
we capture the essence of each paradigm, point out the main
diﬀerence to continual learning if the paradigm is viewed
in isolation , and emphasize what role is contributed when
considered in context of continual learning.
•Transfer Learning: Leverage a source task’s repre-
sentations to accelerate learning or improve a current
target task.
Diﬀerence to CL when viewed in isolation: unidirec-
tional knowledge transfer between two tasks.
RoleinCL: enablesforwardtransfertobeneﬁtfuture
tasks through feature re-use.
•Multi-task Learning: Exploit tasks relatedness by
forming a joint hypothesis space.
Diﬀerence to CL when viewed in isolation: isolated
learning with multiple tasks.
RoleinCL: trainingofmultipletaskssimultaneously
before advancing to multiple new tasks continually.
•Online Learning: Retaining and improving a task
where data arrives sequentially and real-time con-
straints require online adaptation.
Diﬀerence to CL when viewed in isolation: typically
continuous learning of one task over time, however
generally applicable to any of the other paradigms.
Role in CL: rapid learning without task boundaries,
limited revisits of memory buﬀers, and encoding of
new knowledge as data instances arrive in a stream.
•Few-shot Learning: Transfer or multi-task learning
in a small data regime.
Diﬀerence to CL when viewed in isolation: unidirec-
tional transfer or isolation similar to transfer learning.
Role in CL: fast adaptation in continual learning with
very few data instances per task.
•CurriculumLearning: Findingasuitablecurriculum
thatacceleratesorimprovestrainingbymeansofintro-
ducing schedules of increasing data instance diﬃculty
or data instance task speciﬁcity.
Diﬀerence to CL when viewed in isolation: isolated
learning that prioritizes certain data instances.
RoleinCL: scoringthediﬃcultyofdatainstancesand
adapting the pacing of the learning to accelerate or
improve training.
•OpenWorldLearning: Atanyparticularpointintime
themodelneedstobeabletoidentifyandrejectunseen
databelongingtounknowntasks.Thesecouldbeset
aside and learned at a later stage.
DiﬀerencetoCLwhenviewedinisolation: CurrentCL
is typically evaluated in a closed world scenario.RoleinCL: robustlearningandinferencethatdiscards
task irrelevant data and identiﬁes novel tasks.
•Active Learning: An iterative form of supervised
learning,wherethelearnercanqueryausertoprovide
labels for a subset of unlabelled examples that are
deemed to yield the largest knowledge gain.
Diﬀerence to CL when viewed in isolation: data and
sampling eﬃciency is rarely taken into account in CL
on predeﬁned benchmarks.
RoleinCL: ﬁlteringdatainstancesthatareexpected
toyieldlargebeneﬁttolimitcomputationalresource
consumption or labelling costs in continual learning.
3. Critically surveying and bridging three
perspectives
Weprovideacriticalreviewoftheplethoraofpractices
and historically grown methods in the context of deep
continual learning, active learning and open set recognition.
Forthispurpose,westartbysurveyingthethreeperspectives
individually and categorize their respective trends. To give a
visual guideline to the reader, we show an overall taxonomy
in Figure 4, where each of the three main nodes will now
be discussed in detail in sections 3.1, 3.2, and 3.3. We
then follow up on these individual perspectives by delving
into details of potential pitfalls and shortcoming, in order
to subsequently highlight synergies and the necessity for a
consolidatedviewinsection3.4.Thatis,wewillhighlightthe
illustrated interconnections between the three perspectives
of the taxonomy diagram. This consolidated view, based on
theprimaryconjecturethatopensetrecognitionprovidesthe
natural interface between active and continual learning, is
ﬁnallypresentedtowardstheendofthissection.Whatmay
at ﬁrst seem like a tour de force review for the reader, is thus
intendedtoinitiallygainanoverviewofthevastlandscape
andthedelugeofmethodologyoptions,inordertogroundour
understanding of the interconnections between the presented
elements. As the latteris the primary focus of this work, we
re-emphasize that we limit our survey part to concise critical
summariesandwillforgolengthyelaborationsonalgorithmic
nuancesandmathematicaldetailsthatarenotessentialtoa
genericunderstanding.Forthisreasonwestronglyencourage
the reader to go through the ensuing three sections (3.1, 3.2,
and 3.3) in favor of a comprehensive and critical picture.
However, we acknowledge that a very well-versed reader
in all three paradigms may want to directly continue with
section3.4andconsecutivecontentonbridgingperspective.
3.1. Continual learning
As indicated in the introductory section, continual learn-
ing should ideally encompass a variety of research questions.
Our later sections will continue to argue that currently
considered scenarios are too reductive, resulting in potential
diﬃcultytochoseamongexistingalgorithmicoptions.For
now, we will start with a typical categorization of existing
deep continual works into the three categories of regulariza-
tion,rehearsal andarchitectural approaches,inconsistency
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 7 of 37

--- PAGE 8 ---
A Wholistic View of Continual Learning with Deep Neural Networks
Deep
Continual
Learning
Regular-
ization
StructuralFunctionalReplay
GenerativeExemplar
RehearsalArchitectural
Fixed
CapacityDynamic
Growth
Combined
Approaches
Open Set
Recog-
nitionMeta-
recognition
Prior
Knowledge
Predictive
Anomalies
Thresh-
olding
Uncer-
taintyActive
Learning
Uncertainty
Heuristics
Represen-
tationsVersion
Space
ÖEWC(Kirkpatrick et al., 2017)
ÖIMM(Lee et al., 2017)
ÖSI(Zenke et al., 2017)
ÖRWalk(Chaudhry et al., 2018)
ÖMAS(Aljundi et al., 2018)
ÖALASSO (Park et al., 2019)
ÖUCL(Ahn et al., 2019)
ÖUCB(Ebrahimi et al., 2020)ÖLWF(Li and Hoiem, 2016)
ÖEBLL(Rannen et al., 2017)ÖPseudorehearsal (Robins, 1995)
ÖPseudo-recurrent nets (French, 1997)
ÖReverberating NNs (Ans and Rousset, 1997)
ÖDGR(Shin et al., 2017)
ÖRfF(van de Ven and Tolias, 2018)
ÖOpenVAE (Mundt et al., 2022)
ÖILCAN(Xiang et al., 2019)ÖGeppNet (Gepperth and Karaoguz, 2016)
ÖGEM(Lopez-Paz and Ranzato, 2017)
ÖSER(Isele and Cosgun, 2018)
ÖCLEAR(Rolnick et al., 2018)
ÖA-GEM(Chaudhry et al., 2019)
ÖBiC(Wu et al., 2019)ÖActivation sharpening (French, 1992)
ÖPathNet (Fernando et al., 2017)
ÖHAT(Serra et al., 2018)
ÖPiggyback (Mallya et al., 2018)
ÖUCB-P(Ebrahimi et al., 2020)ÖDNC(Ash, 1989)
ÖPNN(Rusu et al., 2016)
ÖExpertGate (Aljundi et al., 2017)
ÖNDL(Draelos et al., 2017)
ÖDEN(Yoon et al., 2018)
ÖRCL(Xu and Zhu, 2018)
ÖLearn-to-Grow (Li et al., 2019a)ÖiCarl(Rebuﬃ et al., 2017)
ÖMRGAN (Wu et al., 2018)
ÖVCL(Nguyen et al., 2018)
ÖVGR(Farquhar and Gal, 2018a)
ÖVASE(Achille et al., 2018)
ÖFearNet(Kemker and Kanan, 2018)
ÖLLRNN(Sodhani et al., 2019)
ÖLLGAN(Zhai et al., 2019)
ÖCAP(Scheirer et al., 2014)
ÖOpenMax (Bendale and Boult, 2016)
ÖMahalanobis (Lee et al., 2018b)
ÖOWR-Survey (Boult et al., 2019)
ÖCROSR(Yoshihashi et al., 2019)
ÖLatent based EVT (Mundt et al., 2019)
ÖUniversum Inference (Weston et al., 2006)
ÖConﬁdence Calibration (Lee et al., 2018a)
ÖObjectosphere Loss (Dhamija et al., 2018)
ÖSCM(Feng et al., 2019)
ÖDiscrepancy Loss (Yu and Aizawa, 2019)
ÖSoftmax-Conﬁdence (Matan et al., 1990)
ÖTCM-kNN (Li and Wechsler, 2005)
ÖHinge Loss (Bartlett and Wegkamp, 2008)
ÖConﬁdence (Hendrycks and Gimpel, 2017)
ÖODIN(Liang et al., 2018)
ÖOCGAN (Perera et al., 2019)
ÖBayesSegNet (Kendall et al., 2017)
ÖImage Resynthesis (Lis et al., 2019)
ÖDeep Generative Models (Nalisnick et al., 2019)
ÖUncertainty under Dataset Shift
(Ovadia et al., 2019)
ÖEntropy, maximum discrimination
between two models (MacKay, 1992)
ÖConﬁdence (Lewis and Gale, 1994)
ÖQuery by committe (Seung et al., 1992)
ÖEnsembles (McCallum and Nigam, 1998)
ÖBALD(Gal et al., 2017)
ÖDeep Ensembles (Beluch et al., 2018)
ÖiNAS(Geifman and El-Yaniv, 2019)
ÖBGAL(Tran et al., 2019)
ÖK-medoids pre-clustering (Nguyen and Smeulders, 2004)
ÖMEB-SVM (Tsang et al., 2005)
ÖGaussian process information density (Li and Guo, 2013)
ÖGAAL(Zhu and Bento, 2017)
ÖDeep coreset AL (Sener and Savarese, 2018)
ÖEﬃcient cGAN AL (Mahapatra et al., 2018)
ÖVAAL(Sinha et al., 2019)
ÖWAAL(Shui et al., 2020)
ÖASAL(Mayer and Timofte, 2020)ÖGMM(Cohn et al., 1996)
ÖNaive Bayes (Roy and McCallum, 2001)
ÖSVM margin (Tong and Koller, 2001)
ÖMulti-class SVM margin (Joshi et al., 2009)
ÖMeta-learning active learning (Konyushkova et al., 2017)
Figure 4: Visual taxonomy of neural network based methods for continual learning, active learning and open set recognition.
withrecentreviews(Parisietal.,2019;DeLangeetal.,2021;
Lesort et al., 2020). We note that a strict organization into
these groups is not always possible and hence also provide a
forthcategoryforworksthatcombinemultiplemethods.In
latersectionswewillarguethatthisisnotonlyadvantageous,
but conceivably a necessity.
3.1.1. Regularization
Continual learning approaches based on regularization
aim to strike a balance between protecting already learned
representations,whilegrantingsuﬃcientﬂexibilityfornew
information to be encoded. Intuitively, a meaningful balance
should be attainable for tasks with suﬃcient overlap in
their high dimensional embeddings, i.e. if a considerable
amountofthelearnedrepresentationsareshareable.Existing
approaches can be further subdivided into two subgroups of
regularization.Oneoftheseexplicitlyprotectsparametersby
constraining changes on every level of a model architecture,
whichwerefertoas structural .Theotherpreservesamodel’s
output for seen tasks while ensuring full adaptability with
respect to each individual model stage that leads to the
prediction, which we refer to as functional .
Structural: Structuralregularizationapproachesdrawinspi-
ration from the neuroscientiﬁc stability-plasticity dilemma(Hebb, 1949). That is, successful use of regularization of
deep learning models for continual learning requires care-
fully balancing the trade-oﬀ between overwriting acquired
representations in favor of sensitivity to new information
and preservation of already existing formed patterns. Elastic
Weight Consolidation (EWC) (Kirkpatrick et al., 2017)
aimstoachievethisbalancebyestimatingeachparameter’s
importance through the use of Fisher information and re-
spectively discouraging updates for parameters with greatest
task speciﬁcity. Synaptic Intelligence (SI) (Zenke et al.,
2017)andMemoryAwareSynapses(MAS)(Aljundietal.,
2018), where the biologically inspired term synapse is used
synonymously with parameter, follow a similar approach
by explicitly equipping each parameter with additional im-
portancemeasuresthatkeeptrackofpastimprovementsto
the objective. Asymmetric Loss Approximation with Single-
Side Overestimation (ALASSO) (Park et al., 2019) can be
seen as a direct extension to SI and aims to mitigate its
limitationsbyintroducinganasymmetriclossapproximation
thatismotivatedfromempiricalobservations.Riemannian
Walk (RWalk) (Chaudhry et al., 2018) has generalized EWC
and SI by taking into account both the Fisher information
based importance. The latter is based on a perspective
of computing distances in the induced Riemann manifold,
and the optimization trajectory based importance score.
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 8 of 37

--- PAGE 9 ---
A Wholistic View of Continual Learning with Deep Neural Networks
Incremental Moment Matching (IMM) (Lee et al., 2017)
approaches structural regularization from a perspective of
Bayesianapproximationsandmatchingthemomentsoftasks’
posteriordistributions.UncertaintybasedContinualLearning
(UCL) (Ahn et al., 2019) makes use of Bayesian uncertainty
estimatestoadaptivelyregularize weightsonline.Similarly,
Uncertainty-guided Continual Bayesian Neural Networks
(UCB) (Ebrahimi et al., 2020) adapts the learning rate in
dependence on the uncertainty deﬁned in the probability
distribution of the weights.
Functional: Functional regularization approaches are gen-
erallyinspiredbyknowledgedistillation(Hintonetal.,2014),
anapproachoriginallyproposedformodelcompression.A
distillation loss is introduced by storing the prediction of
a data sample for future use as a so called soft target. In
learning without forgetting (LWF) (Li and Hoiem, 2016)
forclassincrementalcontinuallearning,thesofttargetsfor
existingclassesarecalculatedusingnewlyarrivingdata.The
hope lies in regularizing towards preserving the output for
oldtasks,evenifthesepredictionsmightbenonsensicalas
thefreshlyaddedclassesdonotgetcorrectlypredictedyet.
Encoderbasedlifelonglearning(EBLL)(Rannenetal.,2017)
applies this concept to the unsupervised learning scenario by
applying distillation to autoencoder reconstructions. Knowl-
edge distillation rarely seems to be employed in isolation,
but aswillbe apparentfromthelistofupcoming combined
approaches is a popular technique in conjunction with other
mechanisms.
3.1.2. Rehearsal
Asthenameimplies,rehearsaltechniquesforcontinual
learningaimtopreserveencodedinformationbyreplaying
data from already seen tasks. Trivially, continual learning
couldbesolvedbysimplystoringandreplayingallseendata,
albeit at usually intolerable memory expense and growing
computation time. Accordingly, a core aspect of rehearsal
methods is to ﬁnd a suitable subset of data that best approxi-
matestheentireobserveddatadistribution.Thisiscommonly
referred to as selection of exemplars or construction of a
coreset.Alternatively,agenerativemodelingapproachcan
be used to generate instances from a learned latent repre-
sentation, asan encoding of the observeddata distribution.
Most replay techniques indicate their inspiration to be drawn
from the complex biological interplay between hippocampus
and neocortex (often referred to as complementary learning
systems), wake + sleep cycles and dreaming in the brain
(McClelland et al., 1995; Kumaran et al., 2016).
ExemplarRehearsal: GeppNet(GepperthandKaraoguz,
2016) explores the use of a dual-memory system that imple-
ments various short and long-termmemory storages. These
serve the purpose of storing newly arriving information
or providing dedicated replay cycles of previously stored
data. Selective Experience Replay (SER) (Isele and Cosgun,
2018) concentrates on exemplar selection techniques and
investigates trade-oﬀs between preferring surprising expe-
riences over rewarding ones, or maximizing distributioncoverage. Gradient Episodic Memory (GEM) (Lopez-Paz
and Ranzato, 2017) extends the use of a memory that
getsreplayedepisodicallywithconstraintsonthegradients
to be non-conﬂicting with updates for previous tasks. A
respective extension called Averaged Gradient Episodic
Memory (A-GEM) (Chaudhry et al., 2019) has introduced
signiﬁcantimprovementsoncomputationalandmemorycost
for optimization under these constraints. CLEAR (Rolnick
etal.,2018)usesexperiencereplaytogetherwithoﬀ-policy
learningtopreserveoldinformationandon-policylearning
tolearnnewexperiencesindeepreinforcementlearning.Bias
Correction (BiC) (Wu et al., 2019) rehearses exemplars and
additionally corrects for biases in the classiﬁcation layer.
Generative: Generative replay is a speciﬁc version of
rehearsal where the data to be rehearsed consists entirely
ofinstancessampledfromagenerativemodel.Ratherthan
makinguseofanepisodicmemoryofpreviouslyseendata,
generatedsamplesofformertasksaretypicallyinterleaved
with the current task’s real data during training. The most
elementary version of this procedure was coined pseudo-
rehearsal(Robins,1995),wherethegenerativemodelisof
simplenature.Here,binarypatternsaresampledatrandom,
their target value or label computed given the current state
of the classiﬁer, and the classiﬁer then needs to maintain
the discrimination on these patterns and learn new classes.
Suchpseudo-rehearsalhas thensuccessfullybeenleveraged
in brain-inspired dual-memory architectures that use two
distinctnetworksforacquisitionandstorageofinformation
with generative rehearsal to consolidate the memory. Two
earlyexamplesincludepseudorecurrentnetworks(French,
1997)and couplingtworeverberating neuralnetworks(Ans
andRousset,1997).DeepGenerativeReplay(DGR)(Shin
etal.,2017)haveintroducedadeeplearningvariantofthis
practice,wherethegenerativemodelistakentobeaseparate
generative adversarial network (Goodfellow et al., 2014)
that gets trained in alternation with a classiﬁcation model.
Replay through Feedback (RfF) (van de Ven and Tolias,
2018)proposedgenerativereplayusingasinglemodelthat
handles both classiﬁcation and generation through the aid of
feedbackconnections.Incrementallearningusingconditional
adversarialnetworks(ILCAN)(Xiangetal.,2019)follows
asimilarapproachofusingasinglemodel,butadditionally
changes the generative replay component to rehearse feature
embeddingsinsteadofaimingatreconstructingoriginalinput
data. Open Variational Auto-Encoder (OpenVAE) (Mundt
et al., 2022) further introduces the ﬁrst approach to naturally
integrate open set recognition with deep generative replay in
asinglearchitecture.Thisworkwillbeusedasanexamplein
the empirical portion of our paper. We will demonstrate how
suggestedideascanbeextendedtoformonepotentialbasis
as means to broaden current continual learning practices.
3.1.3. Architectural
Architecturalapproachesattempttoalleviatecatastrophic
forgettingthroughmodiﬁcationoftheunderlyingarchitecture.
It might at this point be baﬄing to the reader why such
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 9 of 37

--- PAGE 10 ---
A Wholistic View of Continual Learning with Deep Neural Networks
modiﬁcationsarelisteddistinctlyfromtheworkspresented
inprevioussubsections.Theyarealmostbydeﬁnitioncom-
plementary to any method presented so far, and in fact most
methodspresentedinthispaper.Forhistoricalreasons,we
will however stay consistent with former categorization of
deepcontinuallearningalgorithms(Parisietal.,2019).We
further sub-categorize architectural approaches into implicit
andexplicitarchitecturemodiﬁcation,i.e.methodsthatusea
ﬁxedamountofrepresentationalcapacityandmethodswhich
dynamically increase capacity in the process of continued
training.
Fixedmaximumrepresentationalcapacity: Approaches
that use a static architecture rely on task speciﬁc information
routing through the architecture. Anearly example is a tech-
nique coined activation sharpening towards semi-distributed
representations(French,1992).Here,theessenceistotune
and limit the amount of high neural network activations to
a maximum of k nodes, such that there is less activation
overlap for diﬀerent representations. Consequently, there
is less potential for interference of new examples. While
ﬁxedarchitecturemethodsdiﬀerinthespeciﬁcallyemployed
technique to disambiguate the learned dense representations,
the common denominator is the assumption of an over-
parametrized architecture. The latter is needed in order to
warrantenoughinitialredundancytopermitoverridingpa-
rameterswithoutincurringcatastrophicinterference.PathNet
(Fernando et al., 2017) adopted this notion to deep neural
networks and used a genetic algorithm to determine and
freeze pathways that are deemed particularly useful for a
speciﬁc task. Instead of using a separate algorithmic layer
todetermine taskspeciﬁcsubsets, Piggyback(Mallya etal.,
2018) and hard attention to the task (HAT) (Serra et al.,
2018) directly learn binary masks and use them to gate
information propagation through the network. The UCB-
P variant of the earlier introduced regularization approach
Uncertainty-guided Continual Bayesian Neural Networks
(UCB) (Ebrahimi et al., 2020) confronts this challenge from
a Bayesian perspective. They use uncertainty to prune the
model and identify binary masks per task to index into the
weights’ Gaussian mixture distributions.
Dynamicgrowth: Dynamicgrowthapproachesadminister
representationalcapacitymuchmoreexplicitly.Thetrivial
solution would be to simply have one model per task and
devise a mechanism to select the appropriate path for an
input. Alas, such an arrangement doesn’t fully leverage
information from one task to positively transfer to another
ornewlyarrivinginformationtoaidalreadyacquiredtasks
respectively. First works in deep learning however nearly
follow this naive, but also intuitive, approach to simply
train on a task and consequently freeze all learned rep-
resentations, such as demonstrated in Progressive Neural
Networks (PNN) (Rusu et al., 2016). The amount of weights
is then increased for a new task, with the twist that formerly
learned representations laterally transmit their output to the
new tasks’ representations but not vice versa. Expert Gate(Aljundi et al., 2017) is comparable and diﬀers mainly in
the introduction of a gating mechanism that automates the
choiceofasuitableexpertinanensemble.Recent,perhaps
more practical, approaches can be viewed as once again
drawing their inspiration from decades of biological ﬁndings
and discussion on neurogenesis. The latter refers to the
process of creation and incorporation of new neurons into
the existing system, see the reviews by Aimone et al. (2014);
Vadodaria and Jessberger (2014). For the last two decades it
has now been acknowledged that this process persist beyond
early stage human development and continues its function
in adults (Gross, 2000). The seminal work of dynamic node
creation in neural networks (Ash, 1989), where additional
units are added whenever the loss plateaus, has thus found
arenaissanceinmoderndeeplearning.Neurogenesisdeep
learning to accommodate new classes (NDL) (Draelos et al.,
2017) and lifelong learning with Dynamically Expandable
Networks (DEN) (Yoon et al., 2018) have adapted this
heuristic approach for use in continual deep learning. The
former by adding units whenever the reconstruction error
of an autoencoder surpasses a predetermined threshold in
the spirit of Zhou et al. (2012), the latter based on an
empiricallyfoundvalueoftheclassiﬁcationlossinsupervised
learning.ReinforcedContinualLearning(RCL)(XuandZhu,
2018) or Learn-to-Grow (Li et al., 2019a) further attempt to
overcomethechallengeofﬁndingsuitablelosscut-oﬀsand
castdynamicunitadditionintoameta-learningframework
in order to separate the learning of the network structure and
estimation of its parameters.
3.1.4. Combined Approaches
A number of works have primarily advanced the state of
theartonasetofbenchmarkdatasetsbyblendingtechniques
from the previous categories. We list some popular works
in this category that have attempted such a blend for the
ﬁrsttime,butalsonotethattheamountofnewlyemerging
combinations grows very rapidly. One of the most popularly
cited works is iCarl (Rebuﬃ et al., 2017), which couples a
knowledge distillation based regularization approach with
rehearsal of exemplars, assembled through a greedy herding
procedure(Welling,2009).VariationalContinualLearning
(VCL)(Nguyenetal.,2018)similarlyfusesuseofanepisodic
memoryofexemplarswithparameterregularization,butfrom
a perspective of approximate Bayesian inference. FearNet
(Kemker and Kanan, 2018) has later criticized iCarl as
a viable technique due to its heavy dependency on quan-
tity of data. They have therefore additionally incorporated
generative rehearsal to compensate the need to store large
subsetsoftheoriginaldataset.VariationalGenerativeReplay
(VGR) (Farquhar and Gal, 2018a) can be seen as concurrent
to VCL, where instead of exemplar rehearsal generative
replay is made use of. Memory replay GAN (MRGAN) and
Lifelong GAN (LLGAN) (Zhai et al., 2019) are more recent
complementstotheseworksanddeviateinthattheyarebased
on GANs instead of variational inference in autoencoders.
Whereas MRGAN uses a functional regularization approach
to align the generator’s output, LLGAN further applies such
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 10 of 37

--- PAGE 11 ---
A Wholistic View of Continual Learning with Deep Neural Networks
Labelled data
XL= ^x1
L§xn
L`
Y= ^y1§yn`
Train
Model
queryMinstances
Unlabelled subset
^x1
U§xm
U`
Annotate
New labels
^y1§ym`
Add new
data toXL
(Human) Oracle
Unlabelled pool or
data stream XUrepeat
Figure 5: Active learning cycle that repeatedly expands a
labelled dataset by querying and then annotating data instances
from a larger unlabelled pool. The dashed arrow from the latter
to the training process indicates the common closed world
active learning scenario, where the presence of all data at all
times is assumed. Respective works typically include the entire
unlabelled dataset into the training procedure by employing
methods from semi-supervised learning. Shaded parts of the
diagram correspond to processes, whereas light components
represent objects.
distillationlossbasedregularizationacrossmultipleplacesin
thearchitecturetoregularizeencodersanddiscriminators.On
the architectural front, Variational Autoencoder with Shared
Embeddings(VASE)(Achilleetal.,2018)adoptsdynamicar-
chitecturegrowthinconjunctionwithgenerativereplay.Their
proposalistoallocateadditionalrepresentationalcapacityfor
new concepts, determined through larger reconstruction loss
inavariationalautoencoder,however,islimitedtoexpanding
the latent space and leaving the rest of the architecture static.
Lifelong Learning for Recurrent Neural Networks (LLRNN)
(Sodhanietal.,2019)combinestrainingoflongshort-term
memory (LSTM) (Hochreiter and Schmidhuber, 1997) with
gradient episodic memory based exemplar rehearsal and a
capacity expansion approach named Net2Net (Chen et al.,
2016).Theapproachprovidesthemeanstotransferlearned
representationsfromanarchitecturetoalargeruntrainedone
before continuing to train the latter. While some of these
works clearly exploit natural synergies, a generally desirable
practice,wenotethatthiscansometimescomeattheexpense
of detailed analysis and comprehensive understanding of
individual key ingredients. Therefore, we agree that all
approachesinthissubsectionpursuecommendabledirections,
but also wish to point out that considerable future analysis is
still required.
3.2. Active learning
Rather thanfocusing onthe questionof howto preserve
representationsinincrementalcontinuallearning,thetopicof
active learning asks the reverse question of how to pick dataincrementsforfutureinclusion.Generally,thisiscastintothe
framework of semi-supervised learning. Here, it is assumed
thatthemodelistrainedonlabelleddata XL=^x1
L;§;xn
L`,
and a larger pool of unlabelled data XUexists. This is
motivated from data acquisition being relatively cheap in the
modern world, as opposed to human intensive data labelling
that often requires highly skilled experts. The task of an
active learner is thus to extract a set of Mdata instances
^x1
U;§;xm
U`from the pool of unlabelled data, such that
a maximum gain in performance on the inspected task is
expectedifahumanintheloopprovidestheadditionallabels
^y1;§;ym`for further training. The underlying mechanism
onwhichthequeryisbasedisreferredtoastheacquisition
functionandformsthemainpillarofactivelearningresearch.
We have visualized this active learning cycle in Figure 5.
There are multiple conceivable evaluation variants to
gaugethe usefulnessofactive learning acquisitionfunction
choices.Theyeitherexplicitlyassumetheentiretyoftheunla-
belled data to be accessible and usable upfront, or contrarily
thequerybeinginformedsolelybytheavailablelabelleddata.
Independentlyofthelatter,thepracticalassessmentofactive
learningstrategiesisgenerallyconductedinaclosedworld
scenario.Thatis,theentirepoolofunlabelleddataisexpected
tostemfromthesamedatadistributionastheinitiallylabelled
set.Theoracleisrespectivelyassumedtobeinfallible.Ina
crucial distinction to continual learning, evaluation of active
learninghoweveraccumulatesdataandgrowsthelabelledset,
focusing primarilyon thecost reductionof labourintensive
annotation. In consequence, an active learner is deemed
successfulifeachdataqueryprovidessigniﬁcantbeneﬁtover
simply picking and labelling data at random.
“A probability analysis of the value of unlabelled data
forclassiﬁcationproblems”(ZhangandOles,2000)provides
an early analysis of the requirements for beneﬁting from
semi-supervisedoractivelearningapproaches.Theauthors
consider two types of models: parametric p.x;yðW/ =
p.xðW/p.yðx;W/and semi-parametric: p.x;yðW/=
p.x/p.yðx;W/. In the latter, the data probability p.x/is
decoupled and can have an unknown (or non-parametric)
formindependentoftheweights W,asiscommoninmost
discriminative models such as logistic regression or most
neuralnetworks.Theyarguethatthesemodelsareparticularly
suitedforactivelearning,asopposedtoparametricmodels
such as Gaussian mixtures being particularly suitable for
semi-supervisedlearning.Thisisbecausetheydonotneed
torelyonpotentiallyinaccurateestimatesoftheentiredata
distribution when only a fraction of the data is observable.
However, we will see in the subsequent review that both
of these model types have been used to form diﬀerent
perspectivestoaddressactivelearningandcomewiththeir
respective advantages.
As with the majority of techniques, early active learning
methods have rapidly cross-pollinated into applications with
deep neural networks. However, due to the black-box nature
ofdeepnon-linearneuralnetworks,manyoftheseapproaches
are based on simple heuristics or approximations to uncer-
tainty quantities that no longer have tractable closed-form
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 11 of 37

--- PAGE 12 ---
A Wholistic View of Continual Learning with Deep Neural Networks
solutions. We will start with these heuristic approaches, as
they are often trivial to transfer to deep learning. We then
continuetosummarizemoreprincipledapproaches,which
can turn out to be genuinely challenging in the context of
deep learning with neural networks.
3.2.1. Uncertainty Heuristics
One theoretically sound approach to querying useful
data is based on entropy (Shannon, 1948) sampling and
otherinformationtheoreticacquisitionfunctions(MacKay,
1992). An early approach based on training two neural
networks to estimate query areas in binary classiﬁcation
problems (Atlas et al., 1990) remarks that this is diﬃcult
for neural networks as they are often overly conﬁdent in
theiroutputs.Thisoverconﬁdenceisgoingtobeoneofthe
main subjects of our next major section on learning in an
open world. Interestingly, while carefully studied in early
literatureinisolation,thisaspectseemstooftenbeoverlooked
intheeraofdeeplearning,particularlywhenplacedinthe
context of continual and active learning. Here, simply using
neuralnetworkpredictionconﬁdence,predictiveentropyor
other derived heuristics (Lewis and Gale, 1994) are still
practically employed in comparisons today (Geifman and
El-Yaniv,2019).Thisisbecausemanyapproacheshavebeen
showntoempiricallyworkwellinspeciﬁccontexts,although
there is no guarantee for them to succeed. Early works have
shownuncertaintysamplingbasedactivelearningforlogistic
regression (Lewis and Gale, 1994) and neural networks
(Seungetal.,1992;McCallumandNigam,1998)basedon
“querybycommittee”,anapproachtoestimateuncertainty
by using an ensemble of neural networks. This idea has later
foundaone-to-onetranslationtodeepensemblesforactive
learning(Beluchetal.,2018).Naturally,mostblack-boxdeep
neural networks are not equipped with mechanisms to gauge
uncertaintyproperlyoutsideofusingmultipleparallelmodels.
Bayesian active learning by disagreement (BALD) therefore
providesanattemptatavoidingthenecessityofensembles
andinsteadusesMonteCarloDropout(GalandGhahramani,
2015; Srivastava et al., 2014) to calculate points of high
varianceintheoutput(Galetal.,2017).Thishasempirically
beendemonstratedtobeeﬀectiveandhasbeenextendedin
Bayesian Generative Active Learning (BGAL). Here, BALD
isusedtoquerysamplesandthenthelabelledsetisfurther
augmentedwithgeneratedexamples(Tranetal.,2019).Deep
incrementallearningwithNeuralArchitectureSearch(iNAS)
(Geifman and El-Yaniv, 2019) does not propose a new query
mechanism and instead provides an evaluation of above
acquisition functions in the context of architecture selection.
Theyincludetheoptionofprogressivearchitecturegrowth
after each query, to illustrate that small models generally
fare betterin a smalldata regime, whereaslarge models are
requiredwhenacertaindegreeoftaskcomplexityisreached.
3.2.2. Version Space and Expected Error Reduction:
A theoretically more substantiated approach to basing
the acquisition function on heuristics is to query data that
provably reduces the expected error. Clearly, such proof isbeyondthecurrentunderstandingofdeepneuralnetworks,
buthasbeenshowntobefeasibleinthecontextofparametric
models such as Gaussian mixture models (Cohn et al., 1996)
or naive Bayes (Roy and McCallum, 2001). These works
use the formal conceptof aversionspace (Mitchell, 1982).
At the example of classiﬁcation, its respective deﬁnition
is the set of all hypotheses that are consistent with the
observed data in achieving a possible separation in the
inducedfeaturespace.Anappropriateactivelearningstrategy
is to sequentially and monotonically reduce the size of
this version space, i.e. shrink the amount of conceivable
hypotheses.InmodelssuchasSVMsforbinaryclassiﬁcation
this can intuitively be explained based on the margins (Tong
and Koller, 2001). Here, new points are chosen according
to hyperplanes that maximize the restriction with respect to
the set of possible hyperplanes for correct classiﬁcation. The
latterwaslaterextendedtoamulti-classSVMbasedapproach
(Joshi et al., 2009), however still based on multiple binary
classiﬁers.Aboveeﬀortsallowedfortheoreticalguarantees
on sample complexity and necessary amount of queries
to be analyzed with respect to these binary classiﬁcation
problems with linear decision boundary in the context of
greedy active learning strategies (Dasgupta, 2005). Whereas
“learning active learning from data” (Konyushkova et al.,
2017) provides a recent eﬀort to train a meta-learning based
regressor to predict expected error reduction for binary
classiﬁcation using random forests, the idea is yet to be
broadlyadaptedtodeepneuralnetworks.Firsteﬀortsatscale
based on approximations to expected model output changes
are presented in Käding et al. (2016a,b).
3.2.3. Representation based approaches:
Althoughversionspacereductioncancomewithprovable
guarantees, respective application to deep neural networks
is inconceivable before a mature theory of how their hy-
potheses are formed has evolved. At the same time, Roy
et al. (Roy and McCallum, 2001) have pointed out that
the earlier summarized uncertainty sampling, or estimates
thereofthroughensembles,aregenerallyinsuﬃcient.They
argue that they are prone to querying outliers, as a result
ofsampledinstancesbeingviewedinisolationandwithout
regarding the underlying density of the full data distribu-
tion. Similar conclusions were empirically observed in the
large scale empirical evaluation of active learning for text
applications (Settles and Craven, 2008). As a solution, the
authorssuggestarepresentationbasedinformationdensity
measure. Although heavy to compute, it implicitly takes into
account the underlying data distribution. This can be seen
asanapproachthatisorthogonaltominimizingtheversion
space.Typicallythedistributioncoverageontheentiredataset
according to the model representations is now maximized
instead of reducingthe number ofpossible hypotheses. The
often necessary core assumption is thus the presence of
the entire unlabelled pool of data and its auxiliary use in
optimization of the labelled set. We have attributed our third
category to approaches that follow this objective.
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 12 of 37

--- PAGE 13 ---
A Wholistic View of Continual Learning with Deep Neural Networks
Activelearningusingpre-clustering(NguyenandSmeul-
ders, 2004) uses a k-medoids algorithm in conjunction
with a SVM or logistic regression to select data from the
pre-clustered embedding of the unlabelled pool. Similarly,
SVM based core vector machines (Tsang et al., 2005) use
a set of minimum enclosing balls to create a core set that
best approximates the entire distribution. Li et al. estimate
informationdensitybyusingtheunlabelleddatainaGaussian
process (Li and Guo, 2013). The idea in these works have
since been abstracted to deep neural networks. Sener and
Savarese (2018) base their active learning procedure on
construction of core sets based on a k-medians algorithm.
Shui et al. (2020) achieve distribution coverage by match-
ing distributions through minimization of the Wasserstein
distanceinAutoencoders(WAAL).Variationaladversarial
activelearning(VAAL)(Sinhaetal.,2019)approximatesthe
data distribution by learning the latent space in a variational
autoencoder (Kingma and Ba, 2015) and simultaneously
trains a latent based adversarial network to discriminate
between unlabelled and labelled data.
Incomplementtotheseworks,variousquery-synthesizing
methodshavebeenproposed(ZhuandBento,2017;Mahapa-
traetal.,2018;MayerandTimofte,2020).Here,thechallenge
ofactivelearningistackledbyusingadeepgenerativemodel
to generate informative queries. Instead of querying from
an unlabelled pool directly, generative adversarial active
learning(GAAL)(ZhuandBento,2017)and“eﬃcientactive
learning using conditional generative adversarial network”
(Eﬃcient cGAN AL) (Mahapatra et al., 2018) both train
GANs to synthesize and label queries. The core assumption
is the ability to adequately capture the data distribution
to generate meaningful instances. The usefulness of the
generated samples with respect to a classiﬁer can then either
beassessedthroughuncertaintyheuristicsorbymatchingthe
synthesizeddatawithsamplesfromthepoolandretrieving
the most similar instance, as demonstrated in Adversarial
Sampling for Active Learning (ASAL) (Mayer and Timofte,
2020).
In our upcoming discussion, we will argue that the
assumptionofupfrontpresenceofalldatashould,andinfact
can be lifted when a natural bridge to the other paradigms is
constructed.Beforethat,weﬁrstproceedtoconcludeourlast
leg of the review by delving into what will later constitute
the“glue”inourwholisticperspective:learninginanopen
world and open set recognition.
3.3. Open set recognition
The term open set recognition was formally coined
only recently (Scheirer et al., 2013; Bendale and Boult,
2015). However, its foundation and associated challenge
in neural networks dates back to at least several decades
before,whendiscriminativeneuralnetworkswerefoundto
yield overconﬁdent mispredictions on unseen unknown data
(Matan et al., 1990). To get an intuitive understanding, let us
brieﬂy consider the types of data we can expect our model
toencounter.Assoonaswemovebeyondtheclosedworld
benchmark scenario, we can no longer expect our trainedmodelstobetestedexclusivelyonsomeheld-outdatafrom
the same distribution as observed during training. In the
earlierintroducedtransferlearningparlance,forprediction,
datacanthusgenerallynotbepresumedtooriginatefromthe
samedomain.Wecannowdistinguishthreetypesofpossible
inputs to our model (Scheirer et al., 2013):
1.Knowns: examples belonging to the distribution from
which the training set was drawn. The model’s predic-
tion is accurate and conﬁdent.
2.Known unknowns :unknowninstancesthata model
cannotpredictconﬁdently.Examplescanoptionallybe
labelled as not being aﬃliated with the set of known
conceptsforexplicittrainingofnegatives.Prediction
uncertaintycanindicateamodel’sawarenessofitsown
limitation.
3.Unknown unknowns :unseeninstancesbelongingto
unexplored,unknowndistributionsorclassesforwhich
the prediction is generally overconﬁdent and false.
Thebroaderinspirationforthiscategorizationiscommonly
attributedtoanotorious,machinelearningunrelated,quote
byRumsfeld(Naylor,2010;Scheireretal.,2013): “Weknow
that there are known knowns; these are things we think we
know. We also know there are known unknowns; that is to
say we know there are some things that we do not know.
But there are also unknown unknowns; these are the ones
we don’t know, we don’t know!” . In the context of neural
networks,knownunknownscanbeidentiﬁedthroughgauging
model uncertainty or relying on derived related heuristics,
incorrespondencetomanyofthemethodsemployedinthe
activelearningsetting.However,asdetailedinarecentsurvey
(Boult et al., 2019), separating the known data from the
essentially indistinguishable high-conﬁdence mispredictions
for unknown unknowns is far from trivial.
As any machine learning model is trained on a ﬁnite
dataset, and the imaginable set of unknown unknowns is
inﬁnite, we refer to the challenge of recognizing the latter
asopensetrecognitioninanalogytopriorworks(Scheirer
et al., 2013, 2014; Bendale and Boult, 2015, 2016; Boult
etal.,2019).Formally,theseworksdeﬁnetheclosedspace
as a union of balls SKthat enclose the entire training set
XK, whereas the open space Oconstitutes the remainder of
theinput orfeature space: OÏ=X*SK.Correspondingly,
worksthatprovideattemptsataddressingopensetrecognition
aim to ﬁnd the respective boundaries between known and
unknown spaces (Scheirer et al., 2013, 2014; Bendale and
Boult, 2015; Lee et al., 2018b; Mundt et al., 2022, 2019;
Yoshihashietal.,2019).Wewillreviewtheseworkslastin
favorofhistoricallyprecedingapproachesbasedonexplicit
inclusionofnegativeclassesandrejectionthroughanomalies
inpredictionpatterns,eventhoughthelatterhavebeenargued
tobeinsuﬃcientforopensetrecognition(Matanetal.,1990;
Scheirer et al., 2013; Boult et al., 2019).
The above widespread categorization can technically be
extended to encompass a fourth category, by splitting the
knownsinto knownknowns andthesetof unknownknowns
(Munro,2020).Wedonotconsiderthisfurtherdistinctionas
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 13 of 37

--- PAGE 14 ---
A Wholistic View of Continual Learning with Deep Neural Networks
theexistenceofunknownknownscanbecondensedtoone
oftwooptions:Awillfullyignorantfalseprediction,because
we in fact know the concept but choose to nevertheless treat
it as unknown. The more charitable alternative in which our
chosenmachinelearningmodelhasaninherentinabilityto
representtheinvestigatedconceptanditsstructurealtogether.
We also note that there are other related concepts, such as
novelty detection (Bishop, 1994) or equipping classiﬁers
withrejectionoptions.Thesearediﬀerentinsuchthatthey
are typically still evaluated in the closed world and data
is generally still expected to reside in a similar domain.
The aim is to recognize outliers of the distribution that are
uninformative or represent a particularly interesting rare
event. Although these works can have considerable merit in
theirrespective closedworld applicationcontext,we donot
reviewtheminfavorofthemoregenericopensetrecognition,
whereconsideredinputsareallowedtobeofalmostarbitrary
nature.Wefurthernotethatwenaturallycannotprovideevery
examplethathaseverattemptedopensetrecognitionthrough
simpleheuristicslikeusingtheoutputvaluestodistinguish
examples.
3.3.1. Prior Knowledge
A conceivably simple eﬀort to address unknown un-
knowns is by assuming that the human modeler has enough
awareness about what forms of unknown inputs to expect
duringdeploymenttodirectlyincorporatethispriorknowl-
edge into the model. As inclusion of prior knowledge into
neural networks and other types of deep models turns out
to be remarkably complex, the natural analogue is to steer
eﬀortstowardsdatasetdesign.“Inferencewiththeuniversum”
(Westonetal.,2006)hasaccordinglyproposedtoembrace
prior knowledge by representing it through a collection of
“non-examples”. Hence, the optimization algorithm decides
how to include the presented information into the model.
Unfortunately, this does not provide a general solution for
opensetrecognitionasupfrontknowledgecanonlyevertruly
coverthe familyofknownunknowns. Atbest,amerework-
aroundformajor failure casesis therefore supplied, although
without any associated guarantees for remaining unknown
unknowns. This lack of guarantees is further enforced by the
necessitytorelyonmachinelearningalgorithmsextracting
theinformationandcomposingabstractionsfromthesupplied
“non-example” data population.
Sincethen,theideatoincludea“background”concept
has been adopted so widely across applications, that singling
out and thus giving preference to select works is diﬃcult.
Take as an example large-scale datasets surrounding the
task of material classiﬁcation and semantic segmentation.
Because there is an abundance of material types, it has
become the de-facto standard to collapse any available
imagery that is connected to less important materials or
where meager amounts of data are available into a single
“other” material (Cimpoi et al., 2015; Bell et al., 2015).
Not only is it impractical to gather data for every material
variation, but also unknown unknowns can feature other
signiﬁcant statistical deviations. These could be due toe.g.previouslyunencounteredillumination,acquisitionand
sensordiﬀerences,superpositionofdirtandsurfacemarkings,
or any type of perturbation and previously unencountered
noise.Imaginably,inrealapplicationsbeyondaclosedworld,
inclusion of an endless universe is by deﬁnition infeasible.
Nevertheless,multiplerecentworksfollowthisroute.They
proposemechanismtocalibrateoutputconﬁdencesindeep
models (Lee et al., 2018a), formulate a discrepancy loss
between knowns and known unknowns (Yu and Aizawa,
2019)ormodifytheembeddingtoexplicitlyseparatethem.
Examples include semantic categorical and contrastive map-
ping (SCM) (Feng et al., 2019) or the Objectosphere loss
(Dhamija et al., 2018). Although these approaches are not
tantamounttoacomprehensivesolution,wenotethattheycan
stillinprinciplebesuﬃcientfortasksinpartiallyconstrained
environments that naturally limit the world’s openness.
3.3.2. Predictive Anomalies
From an unsuspecting angle, a model will consistently
yieldaccuratepredictionsonlyforobserveddataandproduce
highly uncertain output otherwise. Yet, it still generalizes
correctly to data that is from the same domain but has
not been included in training. In this view, determining a
prediction threshold and obtaining an uncertainty estimate is
suﬃcient to recognize any form of unknowns. This can work
surprisingly well in models with thorough understanding
of the decision boundary and its neighborhood, such as
theTransductionConﬁdenceMachine-kNearestNeighbors
(TCM-kNN) (Li and Wechsler, 2005). Even though it is
well known that the entangled dense representations of
neural networks result in overconﬁdent predictions on any
data (Matan et al., 1990; Boult et al., 2019), a variety of
practical approaches nevertheless proposed to simply rely
on a hinge loss to reject during classiﬁcation (Bartlett and
Wegkamp, 2008) or even to take the straightforward route
and directly trust the softmax conﬁdence (Hendrycks and
Gimpel, 2017). As the quantitative outcome leaves room for
improvement, multiple works have argued that uncertainty
estimation is required to corroborate the decision to gain
awareness of the unknown. In deep networks this could be
achieved by assessing the variations of stochastic forward
passes through a neural network with dropout (Srivastava
et al., 2014; Kendall et al., 2017; Miller et al., 2018), as
a variational Bayesian approximation to a distribution on
the weights (Gal and Ghahramani, 2015). Alternatively,
onecouldempiricallyestimatetheoutput’svariabilitywith
respect to introduced perturbations, such as done in ODIN
(outlierdetectioninneuralnetworks)(Liangetal.,2018),and
calibrate the prediction accordingly (Lee et al., 2018a). In
similar spirit, an often employed argument is that generative
modeling is required to obtain meaningful prediction values
that allow to recognize out of distribution samples. For
this purpose, Lis et al. (2019) use image resynthesis and
equate detection of unknown concepts with identiﬁcation
of discrepancies in poorly reconstructed image regions.
Likewise, one-class novelty GAN (OCGAN) (Perera et al.,
2019) generates examples from sparsely populated latent
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 14 of 37

--- PAGE 15 ---
A Wholistic View of Continual Learning with Deep Neural Networks
Encoder
Classiﬁer𝑦̂ Network trained on fashion items Novel input image
It's a T -shirt with
95% conﬁdence
Figure 6: Top panel: Qualitative illustration of the challenge of
open set recognition. A neural network that has been trained to
discriminate fashion items misclassiﬁes the unknown concept
of an owl and assigns it to the t-shirt class with very high
conﬁdence. Bottom panel: A quantitative example of a deep
wide residual neural network trained on the FashionMNIST
dataset, asked to classify unrelated unencountered digits
and objects from the MNIST and CIFAR10 datasets. Even
though uncertainty is estimated using 50 Monte Carlo Dropout
passes, misclassiﬁed unseen data still overlaps signiﬁcantly
with the known dataset in prediction conﬁdence or entropy.
Knowns and unknowns are largely indistinguishable. The shown
quantitative results are a reproduced subset of our previous
work investigating the limits of deep neural network uncertainty
for open set recognition (Mundt et al., 2019). Best viewed in
color.
space regions in order to use them in explicit training of a
binary out-of-distribution classiﬁer. Although predictions
and uncertainty from generative models have been shown to
improveoutlierandadversarialattackdetectionincontrastto
purelydiscriminativemodels(Mundtetal.,2022,2019;Li
etal.,2019b),thereisstrongempiricalevidencethatthisis
stillinsuﬃcienttoprovideagenericsolution(Nalisnicketal.,
2019; Ovadia et al., 2019; Mundt et al., 2022, 2019). It is
clearthatformerreportedcasesofsuccesscanbeattributedto
thespeciﬁcconstrainedempiricalstudies.Weillustratesome
simple failure cases of prediction conﬁdence and entropy
inFigure6,evenwhenuncertaintyisassessedwithMonte
CarloDropout.Thisistoprovideanintuitivepictureofthe
challengeofopensetrecognitionwithneuralnetworksandto
summarizeandrepeattheﬁndingsofthemuchmoredetailed
experimentspresentedinnumerouspriorworks(Mundtetal.,
2022, 2019; Nalisnick et al., 2019; Ovadia et al., 2019).
3.3.3. Meta-recognition
Rather than assuming that predictions are somehow
calibratedforanydata,amorerigorousapproachistoprevent
overconﬁdent misclassiﬁcation by conﬁning the model to
the known closed space and averting any prediction from
little-known open areas in the ﬁrst place. Whereas it is
evident how to achieve this when explicitly modeling the
distribution, such as done in probabilistic mixture models,
a straightforward approachis not typicallyapplicable in theoftencomplexfeaturehierarchiesofmoderndiscriminative
machinelearningapproaches.Acommontechniqueisthus
toresorttometa-recognition.In this context,thetermmeta
istodenotearecognitionprocedureontopoftheempirically
emerged features obtained through the original black-box
optimization procedures. Scheirer et al. (2014) give an
intuitive example based on support vector machines. Here,
the menace of erratic predictions for unknown unknowns
results from examples being projected close to the linear
decision boundary, while at the same time being mapped
arbitrarily far away from the training data along a diﬀerent
dimension.Theauthorsthereforedeﬁneacompactabating
probability (CAP) model, where the key idea is to make use
ofinsightsfromextremevaluetheory(EVT).Theessential
notion is to take into account inherently present extreme
statistical diﬀerences in the long tail of an extreme value
distribution, here the Weibull distribution. Subsequently, a
datapoint’sprobability ofbelonging tothe observedclosed
setis monotonicallydecreased withincreasingdistancefrom
the observed data population. In other words, a prediction
isdiscardedinsparselypopulatedareas,independentlyofa
sample’s proximity to the decision boundary. Bendale and
Boult(2016)haveextendedthisapproachtodiscriminative
deep neural networks, where the above idea is transferred to
the network’s penultimate layer. They propose the OpenMax
algorithmthatlowerssoftmaxpredictionprobabilitieswith
increasing distance from the average penultimate layer’s
activation values. A strongly related approach has been
proposedbyLeeetal.(2018b),wheretheaﬃnityofadata
pointtotheknownsetismeasuredbasedonaMahalanobis
distanceinthefeaturespaceofthepenultimatelayer.More
recentworks havecometo theconclusionthatalthoughthe
latterapproacheshaveastrongtheoreticalfoundationforopen
setrecognition,theyarestilllimitedbyactivationvaluesin
discriminative neural networks being optimized exclusively
towards predicting a correct class (Yoshihashi et al., 2019;
Mundtetal.,2022,2019).Inparticular,thepenultimatelayer
activation values do not generally encode all the information
about the data that might be required for open set recog-
nition. “Classiﬁcation Reconstruction learning for Open-
Set Recognition” (CROSR) (Yoshihashi et al., 2019) has
thussuggestedtoadditionallyappendagenerativemodel’s
latent variable to the OpenMax classiﬁcation procedure.
Concurrently, open variational autoencoders (OpenVAE)
(Mundt et al., 2022, 2019) translate the EVT based meta-
recognition to a variational Bayesian setting. Here, the
open set recognition is based directly on the approximate
posteriorinadeepgenerativemodel,whichenablesanatural
interpretation based directly on the underlying generative
factors of the data distribution, instead of activation value
heuristics.
3.4. Bridging perspectives: notable past insights
and their synergies
Although our survey parts up to now have contained a
critical perspective, we have largely kept up the tradition
to treat continual machine learning, active learning and
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 15 of 37

--- PAGE 16 ---
A Wholistic View of Continual Learning with Deep Neural Networks
open set recognition as three distinct challenges. While
well studied in isolation, distinctly categorized approaches
are rarely coupled and synergies exploited only in select
works, such as the combined continual learning approaches.
Moreimportantly,theintersectionbetweenthethreemachine
learningparadigmsremainslargelyunexplored,ashasalso
beenmadeevidentfromourvisualsummaryinthetaxonomy
of Figure 4. Highlighting the necessity for uniﬁcation of the
latterintoasingleviewpointistheprimarypurposeofthis
work. The remainder of the section, and the overall paper as
whole, will now serve the purpose of revealing the natural
interface. In fact, by identifying former lessons, stressing
shortcomings of prevailing evaluation practices and bridging
seeminglyforgottenconnections,wedevelopawholisticview
that simpliﬁes the deluge of ongoing research questions into
asingleintuitiveframework.Tobetterunderstandwhythisis
imperative for future progress, let us brieﬂy recall the earlier
mentioned predominant evaluation routines and link insights
from prior works to their current limitations.
If we look back at Figure 2 and the corresponding
section’sdiscussion,werecallthatdeepcontinuallearning
typically collapses its practical evaluation to measuring
catastrophicforgettingbetweentaskincrements.Thesetask
increments belong to simple sequentialized versions of
existing benchmark datasets. A continual learning technique
is deemed successful if the model that is trained over time
approaches the expected performance when trained in isola-
tion.In almostcompleteanalogy, activelearningevaluation
revolvesaroundaccuracygainsbetweenquerysteps.Inthe
majority of the aforementioned related works, the focus is
exclusivelyonwhetheraspeciﬁcquerymechanismsurpasses
another in terms of quickly approaching the overall error
achieved on a complete dataset. For empirical benchmarking
purposes,themodelissimplytrainedinisolationonmultiple
selectedsubsetsofknowndata,wherethediﬀerencebetween
thesesubsetscorrespondstotheinclusionofoneactivequery.
Beforewecontinuewiththelimitationsofsuchevaluation
protocols, we emphasize that our intention at no point in
thispaperistodiscreditanddevaluethebulkofpreviously
proposed methods. However, we would argue that made
advancesofindividualmethodscanbesigniﬁcantlyimproved
beyond their present constrained benchmark evaluation to-
wards progress on a larger machine learning scale. We
believe a major contributing factor in this next step is to
revisitkeyinsightsfrompast,oftenneuralnetworkunrelated,
literature,thathavesurprisinglygoneunnoticedorhavebeen
written oﬀ in the era of deep learning. To attach a slightly
provocativeconnotation,wehavetermedtheseoverlooked
insights forgotten lessons. Although the term “forgotten”
certainly is an exaggeration with regard to the ML ﬁeld as
a whole, the absence of derived practical implications is
strongly manifested in deep continual learning evaluation
schemes.
3.4.1. Forgotten lessons from past literature
Forgottenlesson1: Machinelearningmodelsarebydeﬁ-
nitiontrainedinaclosedworld,butreal-worlddeploymentisnot similarly conﬁned. Discriminative neural networks yield
overconﬁdent predictions on any sample.
Independently of whether additional metrics such as
training speed-ups through representation transfer, computa-
tionalcostormemoryconsumptionaretakenintoaccount,
currently considered experimentationfeaturesclosed world
trainandtestsets.Thisisoccasionallyampliﬁedbycontinual
learning works assuming the presence of a task oracle
for testing or respectively the assumption of an infallible
oracletoyieldﬂawlessdatawhenlabellingactivelearning
queries.Assuch,openissuesconcerningcontinualtraining
of a model or active learning queries in an open world
are generally neglected. However, real-world deployment
almost always inhabits an open world. In the extreme case,
the model has to handle data from completely unknown
type in previously unfamiliar conditions, think outdoor
environments or uncontrolled arbitrary user inputs in web-
based applications. Instead of the common overconﬁdent
mispredictionthatfalselyattributesthisdatatoanyknown
concept, any machine learning model should at least be
equippedwiththeabilitytoidentifyunencounteredscenarios
and warn the practitioner. As a much milder, but heavily
realistic form of an open world, even commonly occurring
corruptions are frequently disregarded, think blur or camera
noiseinimages.Themenaceofthelatterhasrecentlybeen
demonstratedin deeplearningby Hendrycksand Dietterich
(2019). The authors empirically demonstrate that current
deep neural networks not only exhibit severe instability with
respect to various simple perturbations, but advances in
neural network architectures are reﬂected in only diminutive
changes in robustness. Whereas certainly this hazard is
universal to all machine learning research that is deployed in
practice, continual and active learning are particularly prone
tothethreatofcorruptedandunknowndataastheirgoalis
to accumulate knowledge from previously unseen sources
already in the training process.
Forgotten lesson 2: Uncertaintyisnotpredictiveofthe
open set. Active learning resides in an open world and
common heuristicsbased query mechanism aresusceptible
to meaningless or uninformative outliers.
Althoughearlyworkshaverapidlyidentiﬁedthefallacy
thatuncertaintysamplingisameaningfulstrategytoquery
(Roy and McCallum, 2001; Settles and Craven, 2008) in
active learning or respectively detect unknown unknowns
(Matan et al., 1990; Atlas et al., 1990), the belief that uncer-
taintyprovidesagenericsolutionseemstohaveresurgedwith
theadvancesofdeeplearning.Thisisapparentfromthemany
approaches in our previous literature review basing querying
strategies or detection of unseen examples on heuristics that
relyonoutputvariabilityorsimilarentropicquantities,seethe
branches labelled with uncertainty and predictive anomalies
inourliteraturereviewdiagram4.Indeed,thechallengeof
accurateuncertaintyquantiﬁcationindeeplearningisalready
genuinelydiﬃcultanddoesprovideadvantagesincontrast
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 16 of 37

--- PAGE 17 ---
A Wholistic View of Continual Learning with Deep Neural Networks
tolessprincipledempiricalthresholding.However,paying
homage to the detailed argumentation of the recent review
by Boult et al. (2019), any machine learning model is still
trained in a closed world scenario, independently of whether
e.g.aBayesianformalismisemployedtoobtainuncertainties.
Predictions are known to be overconﬁdent, uncertainty is not
calibratedforpointsoutsideofthetrainingdistributionand
the posterior is often unusable, regardless of how well it is
approximated.
In other words, given any parametrized model and its
latent variables, we don’t know if evaluating the posterior
(approximation)willproducesomethingmeaningfulforan
unknown unseen data input. This issue is by no means
exclusive to detecting unknown unknown examples, but
comeswiththesameimplicationsforrealisticactivelearning
scenarios. Take for example a more realistic set-up beyond a
crafted benchmark where data is scarce and the investigated
domain is demanding even for experts. The earlier reviewed
VAAL has considered such a scenario with medical imaging,
where correct oraclelabelling and a noiseless imagecannot
alwaysbeexpected.Sampleselectionbasedonuncertainty
doesnotprotectthequeryfromsuchnoiseandthereisalarge
chancethatmeaninglessoutliersareincludedintothesystem.
Forgotten lesson 3: Conﬁdence or uncertainty calibra-
tion, as well as explicit optimization of negative examples
canneverbesuﬃcienttorecognizethelimitlessamountof
unknown unknowns.
At a ﬁrst look, one might believe that impressive suc-
cesses where demonstrated with approaches that extend
the basic idea of “inference with the universum” (Weston
et al., 2006). Explicitly using prior knowledge in terms of
expectations on what form of inputs can be anticipated, or
respectiveinclusionofnegativedatathatisbelievedtoplaya
roleindeployment,arepopularlyexhibitedbyworksthathave
identiﬁed and attempt to address the ﬁrst two lessons. The
common presumption across all these works is the upfront
presence of a larger, possibly unlabelled, dataset that can
explicitlybeincludedintotheoptimizationprocess.Justas
supposed out-of-distribution examples are made use of to
modifylossfunctionsandcalibratetheoutputfordetection
ofunknownunknowns(Belletal.,2015;Leeetal.,2018b;
YuandAizawa,2019;Dhamijaetal.,2018;Fengetal.,2019),
activelearningtechniquesoftenresorttoconditioningtheir
procedure on the entire data pool (Nguyen and Smeulders,
2004;SenerandSavarese,2018;LiandGuo,2013;Shuietal.,
2020; Sinha et al., 2019), e.g. through clustering (Nguyen
and Smeulders, 2004; Sener and Savarese, 2018) or ﬁtting
a generative model to the unseen data (Li and Guo, 2013;
Shui et al., 2020). Unfortunately, this impedes evaluation
beyondaconstrainedclosedsetbenchmarkandmorerealistic
continual and active learning scenarios where data becomes
availableatdiﬀerenttimescannotbeconsidered.Inasense
theproblemseemstobeaddressedfromareverseperspective.
Insteadofacquiringexplicitknowledgeaboutthenatureof
the trained data distribution, the challenge is sidestepped byreformulating it as an optimization problem that attempts
to ﬁnd the boundary between known and an existing set of
unseen data, which by deﬁnition then does not consist of
unknown unknowns. Thus, we receive no guarantees, as the
poolofunlabelleddataatanypointintimeislimitedandcan
never truly approximate the unknown space.
The obvious argument is now that it is impossible to
includeallformsofvariationsandexceptionsupfront,elsewe
couldhavejustmodeledandhand-craftedtheentiresystem
from the start instead of falling back on purely data driven
approaches.Asasecondadditionalargument,previousworks
have also asserted that the particular form of representations
of discriminative deep neural networks can further confound
predictions. The early work of French (1992) has already
pointed out that a major complication of continually train-
ing neural networks is their distributed representations. It
has subsequently investigated mechanism to obtain semi-
distributed representations with sharp activations that are
concept speciﬁc. We argue that with the onset of deep
learningthechallengeofdistributedrepresentationsisfurther
magniﬁedduetodistributionacrossthelayerhierarchy.First,
consider as an example a neural network that is trained to
discriminatecarsfromaeroplanes.Suchascenarioisoften
assumed whenincrementally trainingthe popularCIFAR10
dataset (Krizhevsky, 2009). As the neural network is not
explicitlyencouragedtoencodeinformationaboutthedata
distribution, the obstacle of predicting overconﬁdently on
unseen data is further magniﬁed by the ubiquitous option
for any classiﬁer to diﬀerentiate a concept based on a
combination of noise patterns, the absence of a speciﬁc
pattern,orbackgroundpatternsaltogether(Xiaoetal.,2020).
In the car versus aeroplane scenario, depending on how well
and diverse the dataset is constructed, this could be as trivial
as distinguishing the two classes by identifying the presence
of some feature that describes the sky. As neural networks
havebeendemonstratedtorelyheavilyontextureratherthan
objectboundaries(Geirhosetal.,2019),thisisnotfarfetched.
In fact, a prominent recent work on “Unmasking Clever
Hans” predictors (Lapuschkin et al., 2019) has shown that
the decision making of a discriminative deep neural network
can be based on entirely trivial features, such as a certain
object always occurring at a speciﬁc location in every image
or almost imperceivable photography tags. “Adversarial
examplesarenotbugstheyarefeatures”(Ilyasetal.,2019)
takes this one step further and empirically showcases how
classes can be distinguishable solely based on noise patterns.
Inatrivialcaseofourabovecarversusaeroplaneexample,
presenting the trained model with images of ships that
feature the similarly blue background of the sea is then
not surprisingly resulting in overconﬁdent misclassiﬁcation.
Usingshipsasabackgroundclasscouldinitiallysolvethis
problem of attributing blue to aeroplanes. However, if a
signiﬁcant portion of our learned features were indeed to
be composed of noise, background and adversarial patterns,
thenwewouldarguethatoverconﬁdentmispredictionsare
impossible to overcome, as the extent of data on which these
features activate is inconceivable to any human modeler.
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 17 of 37

--- PAGE 18 ---
A Wholistic View of Continual Learning with Deep Neural Networks
This makes the approach to handle outlying and unknown
unknown data through prior knowledge even less feasible.
Forgottenlesson4: Dataandtaskorderingareessential.
Althoughthisformsthequintessenceofactivelearningitis
yet untended to in continual learning.
It is well known that each dataset instance does not
contribute equally to the overall objective. This forms the
foundationandrationalebehindactivelearning.Ingeneral,
when conducting active learning queries, there is a trade-
oﬀ between exploring the unknown space and exploiting
moreofthealreadyknowntoavoidmisclassiﬁcation(Joshi
et al., 2009). Alas, the implications of the latter statement
are more nuanced and go beyond the simple question of
whetheracertainsubsetspanstheentiredatadistribution.As
an example, Joshi et al. (2009) found certain active learning
strategiestobeneﬁtprimarilyfromcreatingaclassimbalance,
as more diﬃcult classes might require a denser sampling
than others. Bengio et al. (2009) have similarly found that
sortingdatainacurriculumthatintroducesclassesintothe
training process according to their diﬃculty improves the
obtained accuracy. Recently, Hacohen et al. (2020) have
empiricallyobservedthatdeepneuralnetworksseemtobuild
such a curriculum inherently during the training process.
Consistently across multiple architectures, they always learn
the same examples ﬁrst when given access to the entire
dataset, even though the mini-batch stochastic gradient
descentshuﬄesthedatadiﬀerentlyeverytime.Pliushchetal.
(2022)havesubsequentlyobservedthatthisphenomenoncan
becorrelatedtoincrease/decreaseinvariousimagemeasures
and statistics. This notion of learning according to some
measureofcomplexityseemsintuitive,asdescribingsome
inputs necessitates less nuanced patterns than others.
Eventhoughthereissigniﬁcantempiricalevidencethat
data selection and task order plays a vital role for any
learned algorithm, modern deep continual learning seems
to pay littleattentionto acarefulexperimental design.Out
of the numerous works of the previous review, less than
a handful of works consider the question of task order at
all.Therest remainsinthecomfortofbenchmarkdatasets,
where the classes are split and introduced in sequence for
continual learning according to a class id that often just
reﬂectsanalphabeticordering.However,thereisnorigorous
investigationoftheeﬀectoftaskorder.Twooutofthefour
worksthatexaminetaskorder(Serraetal.,2018;Iseleand
Cosgun, 2018) only randomize the order across multiple
experimental repetitions to obtain an average performance
estimate. The other two (De Lange et al., 2021; Javed and
Shafait, 2018) follow this practice, but go even further
and make the statement that task ordering has minimal
inﬂuencetowards continuallearningmethods. Wewilllater
demonstratethatthisisobviouslynotthecase,andcansimply
be attributed to the experimentation being a narrow trial
of ﬁve randomly obtained orderings without any attached
semantics. When selecting tasks from the overall pool of
available data according to their similarity or dissimilaritywith the already observed data distribution, we will observe
a major divergence of obtained results.
Whether or not having access to all future tasks in
order to select an ideal order is unrealistic in real-world
continual learning scenarios, we believe task ordering to
be an imperative factor that should be considered when
designingourbenchmarkstofurtherourunderstanding.In
particular, we note that a very common practice to reduce
the computational cost of incrementally learning large scale
datasets such as ImageNet (Russakovsky et al., 2015) is to
extractsubsets(Rebuﬃetal.,2017;Wuetal.,2019;DeLange
etal.,2021;Parketal., 2019).Themainproblemhereisthat
selectinge.g.50fromalargerpoolof1000classesheavily
inﬂuencestheachievableresultandusingrandomselection
mechanisms can essentially render works unreproducible.
3.4.2. Open set recognition forms the natural interface
between continual and active learning
As indicated in the previous sections, contemporary
continualandactivelearningarepronetoanlargeamountof
threats due to their development and evaluation inhabiting
a closed world. In this section we argue that awareness of
an open world is not only required to overcome the threat of
designinganon-robustsystem,butprovidethenaturalmeans
to merge techniques into a common perspective.
Diﬀerent sides to thesame question: First recall that a
majority of continual learning techniques alleviates the chal-
lenge of catastrophic inference by regularizing parameters
for known tasks, rehearsing a subset of data from known
tasks or respectively generating it with a generative model.
Independentofthespeciﬁcalgorithm,akeyconcernisthusto
identifyexemplars,learnthegenerativefactorsofourknown
tasksordeterminetheparametersthatareresponsibleforthe
majorityofpreviouslyseendata.Atthecore,weneedtothus
ﬁnd a good approximation of the known data distribution .
Inactivelearning,alsorecallfromoursurveyhowthetask
isverymuchalike,althoughtheunderlyingquestionseemsto
be of reversed nature. Instead of protecting or sampling from
theknowndatadistribution, aqueryisconductedwithrespect
to yet unobserved distributions . In a similar distinction to
thecontinuallearningmechanisms,query-acquiringactive
learning methods pick samples that are estimated to yield
the best model improvement, whereas query-synthesizing
methods attempt to tackle this challenge through generative
modeling by generating these most informative examples.
Interestingly, in open set recognition, the task is to
preciselygaugetheboundarybetweentheseenknowndata
distribution and yet unseen unknown data . The original
motivation stems from a perspective of outlier detection and
thusmodelrobustnessinpracticalapplicationinthepresence
ofunknownunknowns.However,knowingthisboundaryalso
givesusthemeanstorestrictacontinuallearningtechniqueto
protect the already seen knowns or respectively query active
learningexamplesthataresuﬃcientlystatisticallydiﬀerent
without the fear of selecting uninformative noise. We thus
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 18 of 37

--- PAGE 19 ---
A Wholistic View of Continual Learning with Deep Neural Networks
x
xxxxx
xxxxx xxxxx
xxxx
x
xx
xxx
xx
xxxx
x
xxxxxxxx x
xxx
xx
xxxx
xx
xx
x
x
xxxx
xxxxxxxxx
xx
xxx
xxxx?
??
??
??? ??
?
???
?
EVT bound conﬁning
the closed spaceopen space
known data and
 their mean (star)distance to class meannumber of data points
distance to class meanoutlier probability1 - 
Weibull PDFinverse sampling to approximate the
distribution of knowns to select exemplars
for continual learning rehearsalrobust active learning query that balances
exploration with diversity and exploitation
unknown unknown outliers for which
untrustworthy predictions are avertedWeibull CDF
Figure 7: Conceptual diagram to illustrate how extreme value theory based meta-recognition in neural networks can serve as a
common denominator to protect knowledge in continual learning, conduct principled queries in active data selection, while having
the capability to reject or set aside unknown unknown data at any point in time. The leftmost ﬁgure of an embedding showcases
the threat of the open space, where any examples that are very far away from known clusters always get falsely assigned to a
known class and can be arbitrarily close to the decision boundary. The mid panel shows how a Weibull distribution, which models
the extreme distance values to the mean of the correctly predicted trained data in a heavy tail, can enclose the known space
(suggested by the red circles in the embedding). The corresponding cumulative distribution function in the right panel can be
used to reject or set aside outliers and balance active learning queries to sample diverse, yet meaningful data (shaded red area).
Alternatively either curves can be sampled inversely to select a subset of inlying data to approximate the entire known distribution
in continual learning rehearsal (shaded blue area). Best viewed in color.
propose that open set recognition forms a natural general
interface between active and continual learning.
A uniﬁed framework based on meta-recognition
through EVT: Out of the previously reviewed works, we
posit that works that employ EVT based meta-recognition to
identify unknown unknowns are one particularly suitable
example to build a uniﬁed framework for our wholistic
view. We schematically illustrate this proposed framework
in Figure 7. We will delve into conceivable mathematical
details and a potential realization in deep neural networks
in the next section, where we also further corroborate our
view with empirical ﬁndings. For now, consider a generic
embeddingasaresultofsomedeepneuralnetworkencoding.
Intheﬁgure’sleftmostpanel,wehavevisualizedanexample
embedding for three classes, with their mean indicated by
a star and a potential decision boundary by dashed lines.
In order to conﬁne predictions to the known space, EVT
based meta-recognition makes use of data instances with
extreme distance values to the average embedding of a class.
Typically,aWeibulldistributionisusedtomodelthedistance
distribution for the entire dataset and capture samples that
feature stronger deviation in a heavy tail. In the original
works thathave proposed this model for open set recognition
(Scheirer et al., 2013, 2014; Bendale and Boult, 2015), the
cumulative distribution function is then used to estimate
whether a new unseen example should be regarded as an
unknown unknown, outlying data point. In our own previous
work(Mundtetal.,2022),wehaveidentiﬁedthistechniqueto
also be fundamental in judging whether a randomly sampled
latentvectoris proximateenough totheobserved datasuch
that it results in a clear output of a generated model.Wenowclosethecircleandtiethismethodtoretentionof
acoresetforcontinuallearning,aswellasaquerymechanism
foractivelearning,whileretainingthemethod’sinnateability
to reject and set aside unknown unknowns.
1.First,wepostulatethattheWeibulldistributionforeach
data point’s distance to the mean embedding equips us
withatooltoapproximatetheknowndistributionwith
asubset.Speciﬁcally,wecanemployinversesampling
fromtheWeibullprobabilitydensityfunctiontocreate
a set of distance values with an arbitrary prior on how
muchofthedistribution’stailshouldbedisregarded,i.e.
howmanyoutliersarealreadyassumedtobeinherently
presentintheoriginaldataset.Practically,wecanthen
approximate the data distribution with a subset by
selecting data instances whose embedded value lies
closesttothedrawnsample.Alternatively,asindicated
inthediagram,wecoulddiscretizethedistributionand
sample a certain number of examples from each bin.
2.Conversely,foractivelearning,wearelessinterested
in sampling from the known distribution, but much
more in the heavy tail. To our advantage, the long
tailmodelsdatathatisstatisticallydeviating,butcan
still be attributed to the distribution of interest. We
can thus balance exploitation with exploration. First
and foremost, data instances for which the outlier
probability is unity are avoided altogether in order
to prevent sampling of uninformative noise or other
corrupteddata.Recall,thatthisistheprimarypitfall
of uncertainty sampling. At the same time, we want to
avoid samples that have a minute probability of being
anoutlier,asthesesamplesaretoosimilartopreviously
observed data and are therefore also uninformative
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 19 of 37

--- PAGE 20 ---
A Wholistic View of Continual Learning with Deep Neural Networks
due to redundancy. As such, we can constrain our
query to the center area of the cumulative distribution
function (CDF), illustrated by the shaded area under
theCDFinthediagram.Therationaleforthisapproach
can intuitively be understood by looking back at the
theoretically grounded works on version spaces. We
canimplicitlyreducethespaceofpossiblehypotheses,
even in complex models such as neural networks, as
we incrementally expand the radius of the ball that
encloses the closed space by sampling carefully along
itsboundarywitheachactivelearningquery.Thisway,
we avoid the vast open space and the redundant highly
dense areas of known data, while making sure that
previously unseen information is acquired.
3.Lastly,asalreadyhintedatintheprevioussecondpoint,
we obtain a robust model, where data instances for
which the outlier probability is very high, i.e. close to
unity, can not only be discarded to favor a trade-oﬀ in
exploration versus exploitation in active learning, but
also simply to ﬂag instances where predictions should
notbetrustedifthemodelisoutsideofatrainingphase.
In the next section, we will further contextualize this
wholisticviewonthebasisofauniﬁedframeworkrealization
inneuralnetworksatthehandofempiricalexamples.Before
we proceed, we note that there are two works that have
previously initiated a bridge between active learning and
open set recognition, alas have not fully built it yet. The
recently introduced open world learning (Bendale and Boult,
2016) andthe concurrentlynamed cumulativelearning (Fei
et al., 2016) advance the pure open set identiﬁcation step by
proposing to set aside the unknown unknowns and including
them into a later active learning cycle. Whereas these works
made ﬁrst steps towards formulating learning in an open
world, they however assume the presence of labels for the
entire dataset and the addition of classes itself is in the form
ofaﬁxedsequencethatisinjectedbythehuman.Thesystem
is limited as it does not self-select which classes or instances
should be learned next, nor does it protect its knowledge for
continuallearning,wheretheassumptionofavailabilityofall
dataatalltimesislifted.Asaresult,theempiricalevaluation
issimplyaninvestigationoftheperformanceontheentiretest
setateachstateofthegrowingknowntrainingset.Finally,
thesuggestedopenworldlearning(BendaleandBoult,2016)
is based on nearest mean classiﬁers based on simple SIFT
features and is yet to be extended to the context of modern
deep neural networks.
4. Highlighting natural synergies with
empirical evidence
Inordertosupportourcriticalsurveyandmakeitsderived
proposition for a uniﬁed view practically tangible, we now
highlighttheemergednaturalsynergieswithempiricalevi-
dence. For this purpose, we conduct four sets of quantitative
experiments, which follow our previous narrative and relate
to the formulated forgotten lessons. Each experiment will be
summarizedanddiscussedinarespectivesubsectionindetail.Crucially, we emphasize that they all share the common
denominator of making use of the same uniﬁed neural
network framework. Although individual improvements over
somerelatedworkswillbeshown,thekeynoveltythusliesin
makinguse ofthe samemechanisms acrossallapplications,
whichisuntypicalinrespectiverelatedworksandprevious
reviews. More speciﬁcally, we showcase:
1.Continualexemplarselection: westartwithaquanti-
tativecomparisonofexemplarselectionmechanisms
topreventcatastrophicforgettingincontinuallearning.
Here, we will ﬁrst show that the proposed common
EVTbasedfoundationsurpassesseveralconvention-
ally employed techniques.
2.Active queries: in similarspirit, we showthe comple-
mentaryperspectivebyinvestigatingqueryingstrate-
gies in active learning. Again, we will show that the
proposed common EVT based foundation surpasses
typical approaches.
3.Corruption robustness: we then proceed to further
highlightthemethod’ssuperiorityintheopenworld.
In contrast to most methods that are developed with
a unidirectional focus on improving a speciﬁc active
learningorcontinuallearningbenchmark,ourframe-
workhasthecriticaladvantageofnotbreakingdown
in the presence of corruptions that commonly occur in
practical application in the wild.
4.Taskordering&learningcurricula: toconcludethe
experiments, weinvestigate the roleof task orderand
theeﬀectofacurriculumforevaluation.Weshowthat
a task curriculum constructed through our framework
consistently results in considerable improvements.
Thecorrespondingdetailedset-upandquantitativeeval-
uation is provided in section 4.2. Before diving into this
discussion in detail, section 4.1 ﬁrst introduces one con-
ceivable proposition for a uniﬁed framework on the basis of
deep generative models and variational inference. Although
thisspeciﬁcframeworksurelycontainspartsthatarenovel
to a certain degree, we wish to emphasize that our aim is
nottopromotethisparticularneuralnetworkrealizationor
advocate it as a unique solution to the developed view. In
contrast,themathematicaltoolsandneuralnetworkvariant
shall serve as a teaching example , valued primarily for its
interpretability in illustrating the potential of embracing a
wholisticviewgroundedinacommonmechanism.Forthis
purpose, some approximations will be made and pointed
out, to draw attention to relevant factors and promote the
reader’scomprehension.Assuch,illustratedperformances
are one important factor to take into consideration, but
the primary goal of the experimental section is not to
develop a novel state-of-the-art technique. Instead, the focus
isondevelopingpracticalintuitionandprovidingempirical
evidencetoencourageadoptionofawholisticviewbeyond
prior constrained evaluation in future research.
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 20 of 37

--- PAGE 21 ---
A Wholistic View of Continual Learning with Deep Neural Networks
Encoder Decoder
Linear  
ClassiﬁerEVT open set 
Weibull Distribution  reject  or query
inverse sampling  to pick exemplarsoutlier free
generation
Figure 8: Architecture diagram for our particular VAE based practical neural network framework realization. Here, the solid outlined
boxes represent a traditional VAE model, whereas the dashed boxes and lines correspond to the auxiliary EVT based components.
The color coding of the diagram is picked to resemble our previous ﬁgure 7, which focuses on the details behind the intuition of
the dashed components. Similar to this earlier ﬁgure, we can again see how EVT serves as a common denominator to protect
knowledge in continual learning, conduct principled queries in active data selection, while having the capability to reject or set
aside unknown unknown data at any point in time. Respectively, the blue color denotes meaningful choice of exemplars, the green
color represents outlier free generative replay (not shown in ﬁgure 7), whereas the red and grey colors represent the choice to
query or altogether reject data. Best viewed in color
4.1. One way to unite perspectives with deep
generative neural networks
Howcanwerealizeourproposeduniﬁedframeworkin
ameaningfulwayindeepneuralnetworks?Asemphasized
bypriorwork(Yoshihashietal.,2019;Mundtetal.,2019),
identiﬁcation and correlation of unseen data with average
activationpatternsofknowndataisnotnecessarilysuﬃcient
in discriminative models. This holds even when extreme val-
ues are modeled to obtain closed space boundaries, see prior
works(Mundtetal.,2022,2019)forempiricalveriﬁcation.It
isbecause aneural networkbased classiﬁerisgenerallynot
encouraged to aggregate the whole information describing
thedata,merelythefeaturesthatallowforclassdistinction.
These features themselves, come with a variety of further
pitfalls,assummarizedintheforgottenlessons.Inourown
previouswork(Mundtetal.,2022,2019),wehaveovercome
thislimitationbyformulatingtheproblemfromaperspective
of deep generative models trained with variational Bayesian
inference, i.e. variational autoencoders (VAE) (Kingma and
Welling, 2013). We will lean on this viewpoint, follow the
notationofpriorworksandextendittowardsonepotential
solution to consolidate continual and active learning through
open set recognition. To provide visual intuition behind our
practical framework realization, in addition to the earlier
genericﬁgure7,weprovideanarchitecturesketchinﬁgure
8.
The rationale to build upon VAEs is rather straightfor-
ward:theBayesianformulationletsuslearnaboutthedistribu-
tionofseendata p.x/bycapturingitthroughlatentvariables
z.However,as p.x/=p.x;z/dzisintractable,wedothisbyoptimizingalower-boundtothemarginaldistribution p.x/,
since thedensities of themarginal and joint distributionare
relatedthroughBayesrule p.zðx/=p.x;z/
p.x/.Aswedonotknow
our real posterior p.zðx/, we typically resort to variational
inferenceandintroduceavariationalapproximation q.zðx/to
the posterior. In a neural network, this approximation q.zðx/
islearnedthroughtheparametersofaprobabilistic(blackbox)
encoder, whereas a probabilistic decoder is trained for the
joint distribution p.x;z/ =p.xðz/p.z/and thus forms the
generativecomponent.Thisgenerativemodelcaneﬀortlessly
be augmented to additionally discriminate classes by includ-
ing their label into the latent variable, e.g. by enforcing a
linear class separation on z. The corresponding factorization
and generative process is then p.x;y;z/=p.xðz/p.yðz/p.z/
(Mundt et al., 2022, 2019). Such formulation of a classifying
variational autoencoder comes with the main advantage
that using latent variables zallows us to base our decision
regardingunknownunknownsontheunderlyinggenerative
factorsofvariation.Wecandeterminewhetheranexample
is close to the high density regions of our approximated data
distribution.
4.1.1. The boundary between known and unknown
The ﬁrst step towards open world aware active and
continual learning is to train the above mentioned clas-
sifying variational autoencoder, followed by determining
the boundary between the open and closed spaces for the
observed distribution with the help of EVT. For ease of
readability, we repeat the training and ﬁtting procedure
described in our previous work (Mundt et al., 2022, 2019).
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 21 of 37

--- PAGE 22 ---
A Wholistic View of Continual Learning with Deep Neural Networks
The model’s probabilistic encoder and decoder are trained
jointly by minimizing the divergence between the variational
approximation q.zðx/and a chosen prior p.z/, typically
Ní.0;I/,andtheconjunctionofreconstructionlossand
the linear classiﬁcation objective, parametrized through 
andrespectively.Foradatasetconsistingof n=1;§;N
elements, the following lower bound to the joint distribution
p.x;y/is thus optimized:
L x.n/;y.n/;;;=*KL.q.zðx.n//ððp.z//
+Eq.zðx.n//logp.x.n/ðz/+logp.y.n/ðz/(1)
Here, Eq.zðx/is generally estimated via Monte-Carlo
sampling.Atanypointintimeoftrainingthismodel,thereis
a natural discrepancy between the prior and the approximate
posterior. The added factor in above equation serves the
purpose of controlling this gap, with a  >0typically
determined through cross-validation. Whereas one could
believe this distributional mismatch to be an undesired
property, we recall the arguments conjectured in multiple
previous works (Hoﬀman and Johnson, 2016; Burgess et al.,
2017; Mathieu et al., 2019). In essence, they state that
the overlap of the encoding needs to be reduced in order
to avoid indistinguishability, but at the same time prevent
latent variables to consist of individual uncorrelated data
points that resemble a pure look-up table. In the intuitive
picture of diagram 7, think of the former as multiple classes
collapsing and thus being inseparable. Think of the latter as
the dense clusters being scattered to allow diﬀerentiation of
eachandeverysingledatapointwithoutastrongencodingof
correlations.Therefore,theactuallycapturedencodingofthe
datadistributionshouldnotsimplybeassumedtocorrespond
to the prior, but rather corresponds to an empirically deter-
minable distribution referred to as the aggregate posterior:
q.z/=Ep.x/q.zðx/ù1
NNÉ
n=1q.zðx.n//(2)
Using EVT to ﬁnd the boundaries of this distribution now
corresponds to identiﬁcation of our model’s closed space.
For emphasis, we repeat that this is necessary because VAEs
generally assign non-zero density to any point in the latent
space, the analogue of overconﬁdent classiﬁer predictions
(Nalisnick et al., 2019; Ovadia et al., 2019). The boundary is
notanalogoustotheextent ofthepriorbecauselowdensity
areasexistinsidetheprioraswell.Practically,anEVTbased
ﬁt can be obtained by empirically accumulating the mean
latent variable for each class cfor all correctly predicted
known data points m=1;§;M:
zc=1
ðMcðÉ
mËMEq.zðx.m//[z] (3)
and deﬁning a respective set of latent distances as:
c$
fd
zc;Eq.zðx.m/
t/[z]%
mËMc(4)Here,fdrepresentsachosendistancefunction,whichprior
works have typically chosen to be either euclidean or cosine
distance(Scheireretal.,2013,2014;BendaleandBoult,2015;
Mundtetal.,2022).Asthissetrepresentsthedistancestothe
class conditional aggregate posterior, we can ﬁt a Weibull
distributionwithparameters c=.c;c;c/onctomodel
the trustworthy regions of high density that represent the
observeddatadistribution,wheretheheavy-tailindicatesa
decaying reliability:
!.z/=
0ðfd.z;z/*ð
1*1
exp0
*ðfd.z;z/*ð
1
(5)
Here,deﬁnes the location, the scale and the shape of
the distribution. We can now make use of this distribution to
pinpoint the observed data distribution, as a surrogate to the
otherwisehighlycomplexaggregateposterior.Weproceed
to highlight its various use cases in the following sections,
which will in turn be used in the respective four experiments.
4.1.2. Approximate posterior based open set
recognition
Asdescribedinpreviousworks(Mundtetal.,2022,2019),
the most direct use of the aggregate posterior based Weibull
parametersis the identiﬁcation, rejection or storage of un-
knowndata.Usingthecorrespondingcumulativedistribution
function(CDF)totheprobabilitydensityfunctionofequation
5, we can now estimate any data instance’s statistical outlier
probability for every known class:

c.z/=1*expH
*ðfd zc;z*cð
cIc
(6)
Whenwehaveobservedmultipleclasses,wewilltypically
take the minimum min.
/of this equation across all
known classes cand the respective mode’s parameters c.
This expresses the basic condition that a data point should
be considered as a statistical anomaly only if its outlier
probability is large for each known class. A respective
decisionshouldthusbebasedontheclasswherethesmallest
deviationtoknowndataisobserved.Themoredissimilara
sample is with respect to the observed data distribution as
approximatedbytheaggregateposterior,themoretheoutlier
probability will approach unity. Irrespective of whether a
machine learning algorithm is developed for active learning,
continual learning or in fact any other paradigm, this ro-
bustness towards unknown unknown data is essential for any
practicallydeployedsystemthatoperatesoutsideofextremely
narrow conditions.
4.1.3. Outlier and redundancy aware active queries
Equation 6 gives us the direct means to estimate a
sample’ssimilaritywiththealreadyknowndata.Foractive
learningthisalmostdirectlytranslatestotheinformativeness
of a query. Small CDF values signify large similarity or
overlapwithalreadyexistingrepresentations,largervalues
indicate previously unobserved data. Naively, one would
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 22 of 37

--- PAGE 23 ---
A Wholistic View of Continual Learning with Deep Neural Networks
followtheearlierstrategiesdevelopedinuncertaintybased
activelearningandsimplyquerybatchesthatconsistofthe
most outlying data points. However, this would neither grant
protectionfromexploringnoisy,perturbedanduninformative
data,norbalanceitwithexploitationtofosterpartiallyknown
concepts.Ourpropositionisthustoqueryavarietyofdata
that is well distributed across the center part of the CDF.
For instance, we could chose data that surpasses an outlier
probability of e.g. 0:5and at the same time is limited on the
upper end by e.g. a value of 0:95(Note that these values
present an assumption that is not ﬁxed and simply present a
teachingexample).Asexplainedintheearlierintroduction
oftheframework,thisistantamounttosamplingontheouter
edgeofthespherethatenclosesthecurrentlyknownclosed
space.
4.1.4. Core set selection for continual learning
rehearsal
Incontrasttoactivequeriesthatneedtoselectmeaningful
unknowndata,inthecurrentlyformulatedcontinuallearning
paradigmthemaingoalistoprotecttheknownknowledge
whilelearningapredeterminednewtask.Wewillinvestigate
theroleoftheorderprearrangementinthenextsubsection.
Here,wefocusonopenworldawaretechniquestopreserve
previously acquired representations. Depending on available
memory, the most successful approaches either store and
rehearseasmallsubsetofexemplarsoralternativelygenerate
dataforformertaskswithagenerativemodel.Inourprevious
work (Mundt et al., 2022) we have shown how we can use
equation6torejectsamplesfromtheprior zíp.z/thatdo
notfallintotheobtainedboundsoftheaggregateposterior
for generative rehearsal. The choice for this sampling with
rejectionoriginatedfromthedecisiontoemploythecosine
distance, which collapses the distance to a scalar. A diﬀerent
distancefunction,suchasaeuclideandistanceperdimension
wouldallowtodirectlyinverselysampleahighlymulti-modal
Weibulldistribution,i.e.withonemodeperdimensionper
class. We will stick to the easier cosine distancecase, both
in order to remain at a level of intuitive understanding and
because it seems to suﬃce empirically. Independently of the
selecteddistancemetric,wecanleverageinversesamplingfor
the construction of a small data subset. Speciﬁcally, drawing
atuniformfromtheinverseoftheCDFinequation6yields
samples that approximate the aggregate posterior:
fd.z;z/=
*1.pð;;/=
*log.1*p/1

*(7)
The core set can now simply be obtained by picking the data
pointsthatareclosesttotheobtaineddistancevalues,ifthe
chosendistancemetriccollapsesthedistancetoascalar,or
directly to the latent vector, if the chosen distance metric
preserves the dimensionality. Note that we have chosen to
inversely sample the CDF of equation 6 in favor of a more
compactequation.Itshouldhoweverbeclearthatequation
5 can alternately be sampled equivalently. The advantage of
such a core set selection procedure is that we always attempt
to approximate the underlying distribution. The quality is
deﬁned by the desired amount of exemplars, while excludingstatistical anomalies by limiting outlier probability values to
e.g.p<0:95.Asanticipated,thelatterplaystheadditional
crucialroleofrobustapplicationwhenthesystemhasﬁnished
learning and is deployed.
4.1.5. Class incremental curricula and task order
Continual learning methods are mostly evaluated in
the context of class incremental learning. The classes of
a benchmark dataset are typically split into disjoint sets
and introduced to the learner in alphabetical or class index
sequence.Duetothelargecomputationaleﬀortoftraining
neural networks to convergence on long task sequences, sev-
eralworkschoosetoevaluateonsubsetsofclasses(Rebuﬃ
etal.,2017;Wuetal.,2019;DeLangeetal.,2021;Parketal.,
2019). An important remaining question is thus how such
evaluation aﬀects comparability and reproducibility, or more
generally therole of taskorder and curricula. Asmentioned
earlier, selecting a meaningful ordering is in most cases
non-trivial.Large-scaledatasetsuchasImageNetareoften
composedbyscrapingdatafromtheinternet,socialmediaor
throughuncontrolledacquisitionthatprioritizesaslargeas
possible datasets. We as humans thus lack the knowledge to
buildan intuitivelearning curriculumwhen pairedwith our
lackofunderstandingofdeepneuralnetworkrepresentations.
Consequently, scarcely any works have attempted to address
this challenge beyond a simple randomization of the class
order.Fortunately,wecanprovideatleastapartialremedyto
theseeminglyarbitraryclassincrementalevaluationsetting.
Although we do not have access to explicit data distributions
foranytask,equation6allowsustoassessthesimilarityof
new tasks with the aggregate posterior for known tasks. In
the spirit of our earlier formulated active learning query, we
can start with any task tand proceed to select future tasks
tËTthat feature the least overlap with already encountered
tasks (or most overlap, depending on what is desired):
tnext=argmax
tËT$
Ept.x/

Eq.zðx/[z]%
(8)
To provide an example, if our objective was to incrementally
expand a system to recognize individual animal species,
one assumption could be to accelerate training by always
including the species that is most similar to what has already
beenlearned,asthiscouldbehypothesizedtorequireonly
smallrepresentationalupdates.Analternativeobjectivecould
betodesignasystemthatexpandsitsknowledgeinanattempt
tocoverandgeneralizetoanaslargeaspossiblevarietyof
concepts.Inthisscenario,onecouldchoosetoalwaysinclude
thenexttaskwiththesmallestamountofoverlapwithexisting
tasks to maximize diversity in learning.
Notethatthesescenariospresenttwoextremes,thatare
again chosen because they will provide a good teaching
foundationinthecontextofthispaper’smessage.Inprinciple,
onecouldopttocreatemorecomplextaskorderingmeasures
beyond the max or min overlap around equation 8. We could
now also delve into a philosophical debate on when it is
reasonable to assume access to future tasks in continual
learning to undergo above selection, and when the task
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 23 of 37

--- PAGE 24 ---
A Wholistic View of Continual Learning with Deep Neural Networks
sequence is unavoidably dictated by other external factors.
We deliberately keep such a discussion short and only
emphasizethefollowingaspects. Thereexistbothscenarios
in which curricula and task order can realistically be chosen
in continual learning settings. An intuitive example of this
wouldperhapsbeschoollikelearningenvironments,where
we can ﬂexibly decide what to learn next while retaining
prior knowledge. An alternative example could be a robot
exploringandlearningaboutanunknownenvironment,think
of a diﬀerent planet. On the reverse side, some settings
will impose the order in which data arrives onto us, such
as typically encountered in many real world data streams.
Independently of these diﬀerences in the ability to alter
data curricula and task order, we wish to highlight the large
eﬀect on performance when task curricula are chosen by
above mechanism in the following empirical investigation.
At best, such analysis is relevant for two important elements
of learning: 1. the option to decide to set a task aside and
learn it at a later point in time, if the curriculum is permitted
to be controlled. 2. The eﬀect of task and curriculum choice
when considering pre-trained models. At the very least,
we hope that our eﬀorts will invoke a more careful and
consistent evaluation on existing benchmarks, instead of
picking arbitrary data subsets, selecting diﬀerent random
class ordersand neverthelessattempting tocompare results
across methods.
4.2. Empirical evidence
We base our experiments on the MNIST (LeCun et al.,
1998),CIFAR10andCIFAR100datasets(Krizhevsky,2009).
Althoughthesedatasetscouldberegardedasfairlysimple,
theyareadvocatedasthepredominantbenchmarksinallof
thepresentedcontinuallearningworksandstillpresentasig-
niﬁcant challenge in thiscontext. Theyare furthersuﬃcient
to point out major diﬀerences between methods, particularly
with respect to robustness, showcasing a disconnect with
real application and realistic evaluation. For this very reason,
we employ them as “teaching examples” (similar to our
aforementioned framework), despite being the subject of our
owninitialcritiqueearlier.Wetakethisconsciousdecision
in favor of the reader being able to directly relate to our
experimentsandunderstandtheimportanceofthedeveloped
synergiesinthediﬀerentset-ups.Adiscussiononveryrecent
developments concerning eﬀorts towards dataset creation for
continuallearningcanbefoundattheendofourpaper.We
use a 14 layer wide residual network (WRN) (Zagoruyko
and Komodakis, 2016; He et al., 2016) encoder and decoder
with a widening factor of 10, rectiﬁed linear unit activations,
weight initialization according to He et al. (2015) and batch
normalization (Ioﬀe and Szegedy, 2015) with = 10*5at
every layer, to reﬂect popular state-of-the-art practice. To
avoidﬁndingelaboratelearningrateschedulesorresorting
to other excessive hyper-parameter tuning, we use the Adam
optimizer (Kingma and Ba, 2015) with a learning rate of
0:001andasuﬃcientlyhigh-dimensionallatentspaceofsize
60foralltraining.Weusethiscommonsettingtocorroborate
our wholistic view and describe further details for speciﬁcexperiments in the consecutive subsections on: exemplars,
active queries, corruption robustness, and task ordering.
4.2.1. Exemplar selection and core set extraction
Beforewediveintoaquantitativecomparisonofmethods
that aim to alleviate catastrophic forgetting through the
selectionandmaintenanceofacoreset,weneedtoaddressa
potentialevaluationobstaclewithrespecttothenuancesof
how a core set is used for continual training.
Interleavingacoresetintraining: Incontinuallearning
works,thetypicalevaluationreliesonmonitoringthedecayof
a metric over time whentraining is conducted on new tasks
and old tasks are retained by continued training on a few
selectexemplars.However,thereseeminglyisnocommon
protocol of how these exemplars are interleaved. Apart from
obvious factors such as the amount of chosen exemplars,
workssuchasvariationalcontinuallearning(Nguyenetal.,
2018)usetheexemplarsonlyattheendofeachtask’straining
cycle to ﬁne-tune and recover old tasks. Most other works
(Rebuﬃ et al., 2017; Isele and Cosgun, 2018; Wu et al.,
2019) simply concatenate exemplars with newly arriving
data. Ultimately, the diﬀerent works make use of diﬀerent
methods for exemplar selection and attempt to compare their
eﬀectivenessthroughtheﬁnalmetric,eventhoughtheyare
generallynottriviallycomparableduetotheirdistinctchoices
of the training procedure.
To highlight this argument we have trained the typical
split MNIST and CIFAR10 scenarios, where classes are
introduced sequentially in pairs of two and only the new
task’sdataisavailabletoanincrementallygrowing(single
head) classiﬁer. The old task is approximated through a core
setofsize2400and3000respectively.Thatis,wepick240
and 300 exemplars per class that correspond to retention
of 4% and 6% of the original data. We train the model for
150 epochs per task to assure convergence and interleave
exemplarsselectedbyourproposedEVTapproachinthree
diﬀerent manners:
•Weconductthepredominantnaiveconcatenationofthe
core set with the new task’s data and continue training
with mini-batch gradient descent that samples data
uniformly (unbalanced mini-batch sampling).
•We recognize that the former combination and sam-
pling leads to a heavy imbalance as the core set size is
generallymuchsmallerthanthenewtask’savailable
data. We naively correct this through weighted sam-
pling that samples a mini-batch such that it consists
inequalportions offormertasks’exemplarsandnew
task’s data. This generally oversamples the exemplars
(balanced mini-batch sampling).
•Weidentifythatthelatterweightedbalancedsampling
alwaysresultsinanequalamountofexemplarsandnew
datainamini-batch.Thisisindependentofthenumber
ofclassesthatthecoresetorthenewtaskincrementare
comprisedof.Tocorrectforthenumberofclasses,we
furtherinvestigateclassbalancedsampling.Here,each
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 24 of 37

--- PAGE 25 ---
A Wholistic View of Continual Learning with Deep Neural Networks
2 4 6 8 10
Number of continually learned MNIST classes93949596979899100Accuracy [%]
Balanced
Class balanced
UnbalancedBalanced
Class balanced
Unbalanced
2 4 6 8 10
Number of continually learned CIFAR10 classes6065707580859095100Accuracy [%]
Balanced
Class balanced
UnbalancedBalanced
Class balanced
Unbalanced
Figure 9: Inﬂuence of mini-batch sampling in continual learning
with core sets on MNIST and CIFAR10. The green squared line
represents unbalanced sampling, the naive practice of sampling
mini-batches uniformly from the concatenated pool of the new
task’s data and the retained core set. The purple dotted line
weights the sampling to oversample the much smaller core set to
balance the mini-batch equally. The latter is further corrected
with respect to classes in the pink starred line, where the
sampling is adjusted to draw mini-batches that are comprised
of the same amount of instances per class independently of
their origin. We have repeated the experiments ﬁve times,
illustrated by the shaded regions ranging from the minimum
to the maximum obtained values. We can observe that such
training details result in very signiﬁcant performance diﬀerences
beyond the statistical deviations of a speciﬁc core set selection
strategy. This imposes an additional challenge in the evaluation
of core sets for continual learning. Core sets have been selected
with the proposed EVT based method and consist of 240 and
300 exemplars per class for MNIST and CIFAR10 respectively.
mini-batchissampledsuchthateachclassisequally
represented.Togiveanexample,ifwehaveseentwo
tasks of two classes and proceed to learn the next task,
thecoresetwithitsfourclasseswillbeoversampled
toconstitutetwothirdsofamini-batch.Theremaining
third is made up of the two classes of the third task.
We show the obtained empirical continual learning
accuracies in Figure 9. With gaps of over 5% it is evident
thatbalancingmini-batchesisessential.Moreso,itisclear
that a comparison of diﬀerent core set works, just because
they have used a similar core set size, can result in an apples
toorangescomparisonifotheraspectssuchasthedetailed
k=300, 0.5% k=600, 1.0% k=1200, 2.0% k=1800, 3.0% k=2400, 4.0%
MNIST core set size7580859095100Accuracy [%]
Random
Greedy k-center
Latent k-means
Input k-means
Latent herding
Latent EVT
k=300, 0.6% k=600, 1.2% k=1500, 3.0% k=3000, 6.0%
CIFAR10 core set size203040506070Accuracy [%]Method
Random
Greedy k-center
Latent k-means
Input k-means
Latent herding
Latent EVTFigure 10: Training accuracy on core sets constructed by
diﬀerent popular strategies. Results for diﬀerent core set sizes,
characterized through their size k and the respective percentage
of the dataset, are illustrated in a box plot to show the median,
ﬁrst and third quartile and minimum and maximum values
obtained from ﬁve experimental repetitions. If viewed without
color, methods are displayed from left to right in order of the
legend from top to bottom. Best viewed in color.
training procedure are not taken into account.
Comparison of core set selection strategies: Based
on the insights of the last paragraph and our main focus
on analysis of core set selection strategies, we proceed to
compare diﬀerent strategies in isolation from the precise
continuallearningtrainingscenario.InanalogytoBachem
etal.(2015)andthe“reverseaccuracy”evaluatedinLLGAN
(Zhai et al., 2019), we ﬁrst train the model on the entire
dataset, then select core sets of diﬀerent sizes, and ﬁnally
retrain the model exclusively on the core set to assess the
approximationqualityofourstrategy.Werepeatthisentire
procedure ﬁve times to gauge statistical consistency and
estimate deviations. Without a doubt, methods that select
a core set that yields a better approximation of the overall
population and results in larger accuracies when trained in
isolation,alsoprovide bettermeanstoalleviatecatastrophic
forgetting in continual learning. We compare six diﬀerent
methods:
1.Random: select exemplars uniformly at random.
2.Greedy k-center: greedy k-center approximation
(Gonzalez, 1985) for core set selection as used in
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 25 of 37

--- PAGE 26 ---
A Wholistic View of Continual Learning with Deep Neural Networks
4
 2
 0 2 4
z dimension 13
2
1
01234z dimension 2
4
 2
 0 2 4
z dimension 16
4
2
024z dimension 2
Figure 11: Visualization of the aggregate posterior for a model with two-dimensional latent space trained on the ﬁrst four classes
of the CIFAR10 dataset and 200selected core set exemplars. The left panel shows the greedy k-center approach, whereas the right
panel shows our proposed EVT based core set construction. Classes are color coded points and the core set elements are illustrated
through black crosses. A kernel density estimate of the per class aggregate posterior (in color) and the corresponding distributional
approximation of the selected core set elements (dashed black) are added on each dimension. In contrast to the greedy k-center
approach that features large discrepancies, insigniﬁcant diﬀerences are observable for our proposed method, painting an intuitive
picture for our methods quantitative success of Figure 10. Note that in this case the shown “improved ﬁt” is not the main goal
itself, but rather instrumental to improving long-term learning through core set selection. Best viewed in color.
Variational Continual Learning (Nguyen et al., 2018).
Inessence,exemplarsgetpickedonebyonetoobtaina
cover of the distribution by maximizing their distance
inlatentspacetoallexistingdatapointsinthecoreset.
3.Input k-means: k-means clustering with k being
equal to the number of exemplars. Raw data points
get selected that are closest to each obtained mean.
Suggested as an alternative to greedy k-center in
variational continual learning (Nguyen et al., 2018).
4.Latent k-means: analogous to above input based k-
means, but with the diﬀerence that the clustering is
conducted on the lower dimensional latent embedding.
5.Latent herding: an adaptation of the herding proce-
dure, used by Rebuﬃ et al. (2017); Wu et al. (2019),
to operate on the latent space instead of an arbitrary
neural network feature space. Herding greedily selects
exemplarsonebyonesuchthateachexemplaraddition
best approximates the overall data’smean embedding.
6.LatentEVT: ourproposedEVTbasedinverseWeibull
sampling in our common wholistic view.
We show the obtained accuracies by training on diﬀer-
ently sized core sets selected by the above mechanisms in
Figure 10. As expected, random sampling features large
variations, with the best attempts rivaling the other methods
and in the worst case yielding substantially worse results.
The k-means methods both perform similarly, with the latent
spaceversion operatingon alower-dimensional embeddingshowing minor improvements over the clustering obtained
on the original image data. The smaller the core set size, the
worse these methods seem to perform. This is not surprising
andBachemetal.(2015)havealreadyarguedthatk-means
withwellseparatedclusterswithsuﬃcientlydiﬀerentamount
of data points per cluster can be prone to inaccurately
estimating multiple cluster centers in highly populated areas
versus none in more sparsely populated clusters. This is
furtherampliﬁedbyk-meansgenerallynecessitatingasub-
sampledinitializationtooperateinhighdimensionsandat
large scale. As such, we also observe larger variations for
these methods. Latent herding is subject to much less overall
variation and seems to initially do very well. However, in
contrast to the proposed latent based EVT procedure, we
noticeanincreasinggapinaccuracywithlargercoresetsizes.
Intuitively,weattributethistoherdingpickingincreasingly
redundantsamplesduetotheobjectiverelyingexclusivelyon
thebestmeanapproximation,whichdoesnotsimultaneously
tendtodiversity.OurlatentbasedEVTapproachthataims
to approximate the underlying distribution features the least
deviation and consistently outperforms all other methods.
Intuition behindthe strategies: Toprovideabetterin-
tuition,wehavere-trainedthemodelwithatwo-dimensional
latentspacetovisualizetheaggregateposteriorandcompare
itwiththeselectedcoresets.Figure11showstheaCIFAR10
latent embedding for the ﬁrst four classes (to promote visual
clarity). The colored points correspond to the embedding of
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 26 of 37

--- PAGE 27 ---
A Wholistic View of Continual Learning with Deep Neural Networks
theentiresetofdatapointsandtherespectivecurvescorre-
spond to kernel density estimates of the aggregate posterior.
Theblackcrossesindicatethepointsselectedforasmallcore
set of size200, i.e.50per class. The left panel illustrates the
greedy k-center approach, whereas the right panel shows the
EVT aggregate posterior based approximation. Evidently,
the approximation of the distribution is adequate for our
proposedapproach,withthegreedyalternativeleavingmuch
to be desired. We argue that this is due to the greedy k-
center procedure optimizing for a cover based on maximal
distances. Such a procedure does not explicitly replicate the
densityortakeintoaccountinherentlypresentoutliersand
unrepresentative examples. While this quality of ﬁt might
not be much of an issue for the highly redundant clean
MNIST dataset, the arbitrarily collected real world data of
the CIFAR10 dataset entails complete failure for the greedy
k-center approach. In fact, by introducing a few naturally
occurring image corruptions, we will show that such lack of
robustnesscanbeobservedforallbutourproposedmethodin
alaterexperiment.Althoughanimproveddistributionﬁtmay
thusnotbethemaingoalitself,itseemstobeinstrumental
in improving long-term learning.
4.2.2. Active queries
In addition to the previous experiments showing the
advantages in construction of core sets, we empirically
demonstratethebeneﬁtswhenconductingEVTbasedqueries
for active learning. Recall that active learning is challenging
because we generally desire to query batches of informative
data at a time instead of querying, re-training and re-
evaluating one by one. This is particularly imperative for
computationallyexpensivedeeplearningandaddsafurther
constraint of not only querying meaningful samples, but also
makingsuretoquerydiverselywithouttoomuchredundancy
between the queried examples. We consider this typical deep
active learning scenario for MNIST and CIFAR10, where
we start with a random subset of 50 and 100 data points
respectively, train for 100 epochs to assure convergence
and then make a query to include 100 further data points.
We then proceed to train the network with the additional
instances before repeatedly querying and training again. In a
crucial distinction to the majority of active learning works
that only investigate the quality of the query by re-training
the entire model from scratch, we do not reset our weights in
continued incrementaltraining. This implicitlyintroduces a
stronger impact of ordering and further acknowledges that
notonly labelling,butalso trainingitself isexpensive.Each
experimentisrepeatedﬁvetimes,alwayswiththesameinitial
random subset to preserve comparability between individual
repetitions and across methods.
Comparisonofactivequerystrategies: Weinvestigate
popularmetricsandmechanismsonwhichcurrentdeepactive
learningisbased.Themajorityofthesearetechniquesthat
attempt to take optimal action without explicitly approximat-
ing the entire set of unknown data. To estimate and account
foruncertaintywemakeuseofMonteCarloDropout(MCD)(GalandGhahramani,2015)whereappropriate.Althoughwe
believethatthereisaninherentlimitationinearlierintroduced
approachesthatexplicitlyusetheentireunlabelledpoolfor
optimization, we also investigate the proposed technique
to query based on a k-means core set extracted from the
unknown data (Nguyen and Smeulders, 2004; Sener and
Savarese, 2018). Whereas we certainly regard such methods
as valuable in a closed world context, we note that these
methods are infeasible without prior knowledge outside of a
constrained pool or for sequentially arriving data subsets. As
wewillseeinthenextsection,theyfeaturelittlerobustness
tononsensicaldatathatmightbepresentinthepool,asthe
entire unlabelled pool is included andassumed to be useful.
The metrics and methods that we investigate are:
1.Random: sampling uniformly at random from the
unlabelled pool.
2.Reconstruction loss: in our particular scenario, be-
causeourproposedframeworkincludesagenerative
model, we can query examples based on largest recon-
struction loss. This is typically unavailable in a purely
discriminative neural network classiﬁer.
3.K-means core set: use the entire unlabelled pool
to base the query on an extracted core set that is
equivalent in size to the query amount. Nguyen et
al. had suggested such pre-clustering (Nguyen and
Smeulders, 2004)and it was laterused in deepactive
learningwithk-meansasthecoresetalgorithm(Sener
and Savarese, 2018).
4.MCD - classiﬁcation conﬁdence: query based on
lowest softmax conﬁdence (Lewis and Gale, 1994).
As neural network classiﬁers are known to be overcon-
ﬁdent, we additionally gauge uncertainty with MCD
as a suggested remedy by Gal et al. (2017).
5.MCD-classiﬁcationentropy: querybasedonlargest
predictive entropy (MacKay, 1992). Similar to lowest
conﬁdence, we use uncertainty from MCD to obtain
better entropy estimates (Gal et al., 2017).
6.Latent EVT: our proposed EVT based approach that
balances exploration with exploitation by querying
instances that distribute across outlier probabilities,
but limitedbyan upper rejectionprior toavoid unin-
formative outliers.
Weﬁrstnotethatwehaveincludedclassiﬁcationconﬁ-
denceandentropywithMCDbecauseomittinguncertainty
estimatesresultedinnoimprovementoftheactivelearning
query upon simple random selection. This has previously
beenarguedandcorrespondstotheempiricalobservations
madebySinhaetal.(2019).ForourproposedEVTapproach
weempiricallydistributethequeryuniformlyacrossexam-
ples that fall into the range of 0.5 to 0.95 outlier probability,
as estimated by equation 6. Although it never occurred in
practice,wenotethatitwouldlikelybepreferentialtoextend
this range to the lower end if not enough samples in the pool
were available in the mentioned range, rather than including
complete outliers. We will provide empirical evidence for
this in the next section.
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 27 of 37

--- PAGE 28 ---
A Wholistic View of Continual Learning with Deep Neural Networks
50 250 450 650 850
Number of MNIST data instances5060708090100Accuracy [%]
Random
Reconstruction loss
K-means
MCD Entropy
MCD Confidence
Latent EVTRandom
Reconstruction loss
K-means
MCD Entropy
MCD Confidence
Latent EVT
100 600 1100 1600 2100 2600
Number of CIFAR10 data instances202530354045505560Accuracy [%]
Random
Reconstruction loss
K-means
MCD Entropy
MCD Confidence
Latent EVTRandom
Reconstruction loss
K-means
MCD Entropy
MCD Confidence
Latent EVT
Figure 12: Active learning accuracy for diﬀerent methods on
the MNIST and CIFAR10 datasets. All experiments start with
the same randomly sampled 50and100dataset examples. In
each step, an additional 100data instances are queried from the
remaining unlabelled pool and included for further continued
training. Results show the average over ﬁve experiments, with
the shaded areas ranging from the minimum to the maximum
obtained values.
Figure 12 shows the quantitative results of our active
learningexperiments.Onbothdatasets,thek-meansbased
core set is either similar or slightly worse than simply
sampling at random. This reﬂects our previous observations
in the core set continual learning section. On the contrary,
the uncertainty based methods surpass random sampling.
Using largest reconstruction loss similar results can be
accomplished, although at the additional computational
expenseofcalculatingthedecoding.However,allmethods
aresigniﬁcantlyoutperformedbyourproposedlatentEVT
method at all times. The respective rationale behind this
improvement is quite intuitive. In contrast to the considered
baselines, which have a sole focus on novelty, our strategy
balancescompletelynovelexampleswithlessnovelexamples
that are still required to strengthen the existing learned
features. Moreimportantly, itrejectsuninformativeoutliers
thatareinherentlypresentinthepool,athreatthatuncertainty
based methods can be particularly prone to. This threat
is magniﬁed with even less knowledge about the acquired
dataset and even more unconstrained data acquisition.4.2.3. Robustness to open world corruptions
Thepasttwoexperimentalsubsectionshavefocusedon
showing our method’s advantage in the typical continual and
active learning benchmark perspective in the closed world
scenario,devoidofanyanalysiswithrespecttorobustness.In
ourpriorwork(Mundtetal.,2022,2019),wehaveempirically
demonstrated that the proposed EVT based approach can
successfullydistinguishbetweenknownandunknownsets
of classes (recall the earlier Figure 6), which is otherwise
diﬃcultduetooverconﬁdentmisprediction(Scheireretal.,
2013, 2014; Bendale and Boult, 2015, 2016; Boult et al.,
2019).Wewillnowinvestigateaperhapsequivalentlylarge
threat: data that is statistically deviating for other reasons,
such as corruption and perturbation. Again, we illustrate
commonlimitationsandtheadvantagesofourwholisticview.
However, we also note that robustness to corrupted data is
merely anecessity, notsuﬃcient, for robustness to trulyany
out-of-sample data. Again, we have picked the example of
corrupteddataasitprovidesasolidteachingfoundationto
highlight and support our previously made arguments.
Choice of corruptions and perturbations: In a recent
eﬀort to benchmark the performance against 15 types of
variouscorruptions,HendrycksandDietterich(2019)have
shown that none of the developed neural network models
feature any intrinsic robustness, even if they converge to
moreaccuratesolutionsontheinitialbenchmark.Thiswas
concluded from experiments where neural networks are
trained on the uncorrupted benchmark dataset and evaluated
on the corrupted data. We extend this evaluation by inves-
tigating the presence of a minor portion of corrupted data
in the training process, as can realistically be assumed for
activeorcontinuallearning.Weexaminewhethercommon
querystrategiesinactivelearningandcoresetconstruction
in continual learning are robust, or whether querying and
including this unrepresentative corrupted data into core sets
leads to performance degradation in comparison with the
clean benchmark. We believe that this is critical for two
reasons: 1.) The necessity to carefully curate every single
exampleintheunknowndatapoolcanoutweightheactive
learning human labelling eﬀort and thus renders active
learning ineﬀective in the ﬁrst place. 2.) Data cleaning itself
isextremelychallenginganditisoftennotimmediatelyclear
whether the inclusion of a data instance is beneﬁcial or is
accompanied by side eﬀects.
We make use of corruptions across four categories:
noise, blur, weather and digital corruptions, as introduced
by Hendrycks and Dietterich (2019). These can further be
distinguished into 15 types: low-lighting Gaussian noise,
electronicshotnoise,biterrorimpulsenoise,specklenoise,
Gaussian blur, defocus blur, glass blur, zoom blur, motion
blur, snow, fog, brightness, contrast, saturation and elastic
deformations.Each corruptionis algorithmicallygenerated
with ﬁve discretized levels of severity, of which the ﬁrst
two are at times barely discernible from a typical image
by a human. We accordingly corrupt 7.5% of the data
acrossthese75corruptions.Weaddtheadditionalconstraint
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 28 of 37

--- PAGE 29 ---
A Wholistic View of Continual Learning with Deep Neural Networks
Accuracy [%] : mean+difference to maximum
*difference to minimum
CIFAR10 queries, dataset size 8, 900 18, 1900 28, 2900
Dataset regular corrupted regular corrupted regular corrupted
Random 38:80+0:69
*1:7538:97+1:03
*1:8747:81+2:02
*3:9347:91+2:13
*3:5853:36+1:17
*2:3453:53+1:13
*2:42
Reconstruction loss 41:14+2:06
*3:8938:26+0:64
*1:8950:70+0:69
*1:5046:49+0:82
*2:1355:22+1:37
*1:9250:85+1:03
*1:57
K-means 38:34+1:46
*2:6336:05+1:65
*2:5345:08+1:50
*3:2342:93+1:59
*3:6550:52+0:94
*3:1547:58+1:93
*3:39
MCD Entropy 40:05+1:15
*2:9938:83+0:68
*1:0347:96+2:91
*5:2844:73+0:61
*1:0253:72+2:35
*4:7650:06+0:37
*0:75
MCD Conﬁdence 40:67+0:87
*1:8937:93+0:35
*0:8149:40+2:86
*4:4447:16+1:29
*3:2254:51+1:15
*3:1351:91+1:78
*2:67
Latent EVT 44:67+0:32
*0:6343:79+0:74
*1:7251:66+1:05
*1:6951:12+0:38
*0:9157:43+0:51
*1:0956:83+0:41
*0:78
Table 1
Active learning with and without partial dataset corruption.
Uncorrupted values correspond to those visualized in Figure 12.
Accuracy [%] : mean+difference to maximum
*difference to minimum
CIFAR10 core set size 300 600 1500
Dataset regular corrupted regular corrupted regular corrupted
Random 31:23+3:94
*9:1430:35+1:88
*5:9239:52+3:61
*7:9539:05+1:99
*5:8951:43+3:33
*6:1251:01+2:30
*4:49
Greedy k-center 22:82+3:05
*1:6522:19+1:76
*3:3729:33+1:50
*3:2329:48+1:91
*5:1142:41+1:97
*4:1342:37+1:49
*2:44
Latent k-means 32:76+2:29
*3:3529:00+2:12
*4:0539:49+1:71
*4:1735:71+1:69
*4:0850:01+1:80
*3:2848:52+2:59
*3:86
Image k-means 32:85+2:57
*3:7630:74+1:43
*3:1637:86+1:66
*3:9836:38+0:90
*2:7549:62+2:83
*8:0948:23+1:78
*2:50
Latent herding 33:92+0:61
*1:4533:81+0:82
*1:3941:13+1:18
*2:2940:77+1:34
*1:5751:87+1:12
*1:8551:06+2:43
*2:30
Latent EVT 34:16+1:10
*2:2734:18+1:07
*2:5541:78+1:34
*2:5741:67+1:37
*2:5353:35+1:48
*2:5353:28+1:06
*2:17
Table 2
Core set selection and subsequent training with and without
dataset corruption. Uncorrupted values correspond to those
visualized in Figure 10.
that each image can only be corrupted once. Note that in
principle some corruptions, such as noise resulting from low
lighting conditions and out of focus blurring, could occur
simultaneously.Wehavedeliberately chosenthisamountof
corruption to, on the one hand be small enough to not aﬀect
overall performance if trained on the entire dataset, on the
other hand be larger than the core set size or active learning
query amounts used in previous sections. Hypothetically, in
the absolute worst case this could result in only corrupted
images being selected and the entire chosen set being much
lessrepresentativeofthecompletedatasetthanaselectionof
clean exampleswould be. Werepeat the previousCIFAR10
experiments under these conditions.
Comparison of core set selection and active query
strategies in presence of corrupted data: We show the
originally obtained results in direct comparison with the
results obtained under inclusion of the corrupted data in
Tables 1 and 2. For better visualization and quantiﬁcation
we do not show plots, but have instead picked three evenly
spacedpointsofFigure10and12.Fromthesequantitative
results it is evident that only two techniques are robust in
active learning: random sampling and our proposed EVT
based approach. The logical explanation is that random
samplingonaveragewillpickroughly7.5%corrupteddata,
of which another 40% feature only minor low severities. The
small amount thus only has minor eﬀect on the optimization.
TheEVTbasedalgorithmissimilarlyunaﬀectedasitdoes
not query statistical outliers in the ﬁrst place. If it includes
corrupted examples then only those with minor severity that
arestatisticallystilllargelysimilartotheuncorrupteddata.
Allother methodsare pronetothe corruptedoutliers inone
way or another. Classiﬁer uncertainty and reconstruction
loss tend to pick very corrupted examples by deﬁnition. The
k-meansapproachwillhaveshiftedcentersorfalselyquery
fromnewclustersthatarecenteredaroundcorruptionsoftheunknownpool.Lookingatthequantitativeaccuracyvalues,
we can in fact even conclude that all these methods perform
worse than a simple random query. The continual learning
core set construction picture is quite similar. Here, we can
observe corruption robustness for random sampling, latent
herding and our proposed approach. Latent herding is robust
tooutliersbecauseitpickssamplesgreedilyonebyonetobest
approximatethemean,whichintuitivelyinvolvespickingthe
nextbestexamplethatisclosetotheclassmeananddoesnot
involveoutliers.However,theissueofincludingredundant
samples into the core set remains unaddressed, and our EVT
basedmethodneverthelessoutperformsallotherapproaches.
The qualitative intuition: Interestingly, the greedy k-
center approach also seems to be robust to the corruptions,
although it performs equally miserably to the uncorrupted
scenario. Recall that this algorithm greedily chooses the
next data point for inclusion in a farthest-ﬁrst traversal, by
maximizing the distance to all presently existing core set
elements. In other words, outliers are always queried as
they are farthest away by deﬁnition. Only after a suﬃciently
large cover is obtained will representative data be queried.
Because such unrepresentative outliers are already present
in the uncorrupted data, the performance is consequently
always low for small core set sizes. To visually illustrate this
statement we show a uniform sub-sample of the acquired
core set for the ﬁrst four classes with and without corruption
in Figure 13. In the left panel we can observe the core set
beingcomprisedofatypicalaeroplaneswithdeepgreenor
black background, a captured overexposed sunset. There are
partiallyoccludedcarsandbirdsclosetobushesandfences
or images where the animal is almost not discernible and
comprises only a fraction of the image. Arguably these do
not represent good exemplars. In the right panel, we can see
that inthe presence of corruption, the core setis comprised
ofnoisy,blurryandotherwisedistortedimages.Ultimately
neither of these core sets are particularly good dataset
approximations, intuitively explaining the poor performance
of this technique.
4.2.4. The eﬀect of task order and curricula
In a ﬁnal set of experiments, we investigate the im-
portance of orderings and whether the construction of
a curriculum beyond alphabetical class order provides
substantiallearningbeneﬁts.Webrieﬂyre-emphasizethatwe
primarilyconductthisstudytoinvestigatetheeﬀectsoforder
oncontinuallearning(orpre-training),andnotasasuggested
primarymechanismtoalleviatecatastrophicforgetting.As
previously noted, we leave the practical discussion of which
continual learning scenarios allow for the control of a
curriculum for diﬀerent works.
Comparisonoforderselectionstrategies: Weconsider
four conceivable scenarios:
1.Class sequential ordering: learn the classesin order
of their integer class label. For many datasets this is in
alphabetical order.
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 29 of 37

--- PAGE 30 ---
A Wholistic View of Continual Learning with Deep Neural Networks
Figure 13: Typically selected dataset examples in the core
set construction using a greedy k-center algorithm. Qualitative
illustration is intended to provide intuition for a method’s failure.
The left panel shows how picked exemplars from an uncorrupted
dataset are unrepresentative of the average image, with unusual
backgrounds,occlusionandscalingissues.Therightpanelshows
how the core set is comprised of many corrupted examples if a
small portion of the dataset is corrupted, a lack of robustness
that many methods in Table 1 and 2 suﬀer from.
2.Random order: randomized class order.
3.Most outlying, dissimilar tasks ﬁrst: determine the
next class to add by evaluating equation 8, i.e. pick
the next class that is most outlying and dissimilar with
respect to the already seen classes.
4.Most inlying, similar tasks ﬁrst: determinethenext
class to add by evaluating equation 8, but with a
minimum over task outlier probabilities to include the
most similar task in each increment.
Note that for all strategies we always start with the same
ﬁrst task for comparability. To make sure that obtained
results and found curricula are not just a result of sheer luck,
we repeat each experiment ﬁve times. We then report the
averageandtheminimumandmaximumobtainedaccuracies
at each step to gauge deviations. We conduct experiments
on two datasets: the CIFAR100 and the AudioMNIST
(Becker et al., 2018) dataset. We follow the typical continual
incremental learning procedure of adding classes in pairs
of two. We chose the ﬁrst dataset because it allows for the
construction of a long task sequence. We chose the latter
becauseitrepresentsanon-imagedataset.Previousworkhas
observed that some classes can provide strong retrospective
improvement (Mundt et al., 2022), an early indicator that
the class ordering should be investigated further. In order
to highlight the eﬀect ordering can have on our system,
we provide a two-fold analysis. We analyze ordering both,
when independently evaluated from, or coupled to speciﬁc
techniques that alleviate continual learning catastrophic
forgetting. As such, we evaluate CIFAR100 in what is
typically referred to as a continual learning upper-bound.
The latter describes the maximum obtainable accuracy given
a speciﬁc model choice and training procedure in which the
dataofeachtaskissimplyaccumulatedwitheachsubsequent
task. For the AudioMNIST we use generative replay to
prevent catastrophic forgetting, where old tasks’ data is
rehearsed based on the trained generative model. We donot make use of any data augmentation.
Empirically observed eﬀects of order: The achieved
accuracies at each task increment are shown in Figure 14.
We can observe that for the CIFAR100 dataset, random
sampling seems to yield a very similar accuracy trajectory
in comparison to sequentially learning the classes in order
of their alphabetical class id, resembling earlier observations
(DeLangeetal.,2021;JavedandShafait,2018).However,our
observationsbasedonourproposedframework’sselection
scheme seem to be in contrast to their conclusion that the
order in which tasks are introduced is negligible. Here,
selectingthemostdissimilartaskforinclusionconsistently
improves the accuracy by several percent, even at the end of
training. Conversely, including tasks that are very proximate
to existing concepts results in an all-time performance
decrease. We hypothesize that this is due to the classiﬁer
experiencingimmediateconfusion.Ourinitialclassesconsist
of “apples” and “aquarium ﬁsh” and the query consensus
across repeated experiments is to continue with selecting
the classes “pears” and “whale” or “shark”. The opposite
strategythatprioritizesdissimilarityinthecurriculuminstead
includes unrelated classes such as “lawnmower”, “mountain”
or “oak”. We believe that this allows the model to more
rapidly acquire a diverse set of representations.
Wecandrawalmostanalogousconclusionsforcontinu-
allylearningtheAudioMNISTdatasetwithgenerativereplay.
Here, we additionally see that the conventional order of
learning the sounds from “zero” to “nine” is accompanied
by a pattern of repeated retrospective improvement. The
ﬁrsttaskincrementresultsinalargeraccuracydrop,thatis
rectiﬁed through backwards improvement of the next task
increment.Thispatternrepeatsforthenexttwoclassesand
its consistent strong emergence is only visible when learning
sequentially in order of class id. The accuracy at any time is
againbestforourproposedmeasureofdissimilarityandworst
when selecting according to task proximity. For the latter, in
analogytotheearlierhypothesizedconfusionoftheclassiﬁer,
the generative model is faced with diﬃculty to disambiguate
the resembling classes and produce unambiguous output.
Our results indicate that using active learning techniques
and taking into account the learning order can play a critical
impactontheachievedperformanceofourcontinuallearning
set-ups. More so, the results provide an important signal for
reproducibilityandsigniﬁcanceofvariousconjuredcontinual
learningbenchmarks.Inaworldofbenchmarkingmethods
and regularly claiming advances when a method surpasses
anotherby1-2%,theobservedabsolutediscrepancybetween
thediﬀerenttaskordersforCIFAR100isaslargeas10%.This
is a substantial gap. Whereas we obviously believe that there
liesvalueinanalyzingandcontrastingdiﬀerenttechniques
toalleviatecatastrophicforgettingonacommondataset,it
is clear that there is still much we need to learn about neural
networktraining,theroleofcurricula,theimportanceofwhat
hasalreadybeentrainedincontinuallearning,andevaluation
ingeneral.Amorein-depthunderstandingislikelytodevelop
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 30 of 37

--- PAGE 31 ---
A Wholistic View of Continual Learning with Deep Neural Networks
2 22 42 62 82
Number of continually learned CIFAR100 classes556065707580859095100Accuracy [%]
Sequential class id
Outlying first
Closest first
RandomSequential class id
Outlying first
Closest first
Random
2 4 6 8 10
Number of continually learned AudioMNIST classes80.082.585.087.590.092.595.097.5100.0Accuracy [%]
Sequential class id
Outlying first
Closest first
RandomSequential class id
Outlying first
Closest first
Random
Figure 14: Continual learning accuracy of learning classes
in increments of two in dependence on the choice of task
order. Top panel shows the incremental upper-bound, i.e.
a simple accumulation of the real data, for the CIFAR100
dataset. The bottom panel shows obtained performance on the
AudioMNIST dataset with alleviated catastrophic forgetting
through generative replay. For each of the order selection
mechanisms the experiment has been repeated ﬁve times.
The corresponding average together with the maximum and
minimum deviation are reported respectively.
byadoptingmorewholisticapproachestooursystems,but
will also need to be supported by moving away from our
current rigid benchmarks.
5. Discussion: towards wholistic deep
continual learning
We have empirically corroboratedour wholistic view in
the previous experimental section, highlighted on a set of
teaching examples and one conceivable practical realization
ofauniﬁedframework.Toconcludeourpaper,wenowcircle
back to the preamble of the paper. Building on our wholistic
view’s insights, we revisit the “deﬁnitions” for continual
machine learning and its role in presenting a guideline for
evaluation protocols. We then discuss the entailed prospects
ofadoptingourwholisticviewandpresentsomeremaining
limitations.5.1. A revisited continual machine learning
deﬁnition as a guideline
Takingintoaccounttheinsightswehaveobtainedthrough
ourwholisticview,wecannowaskourselvesthenaturalques-
tion whether the initial “deﬁnitions” for continual machine
learning 1 and 2 require to be adapted. On the one hand, one
could now argue that there is nothing technically wrong with
thelatterexistingdeﬁnition.Afterall,despiteperhapshaving
a larger amount of ambiguity, observed ﬂaws and limited
evaluationareanissuewithpracticallyemployedprotocols.
Inasense,thedeﬁnitionislikelyintentionallyabstractand
not mathematically rigorous. A too intricate deﬁnition could
come with the danger of being overly speciﬁc, resulting in
conceivableexclusionofrelevantfactorsandunnecessarily
constrained scenarios. On the other hand, it may be precisely
thislingeringambiguitythatcanresultinmisinterpretation
or oversight of potentially important elements. Ultimately,
every deﬁnition, be it mathematically rigorous or not, also
plays a role in guiding research. If major factors are left to
be assumed, they may easily be missed.
As a balance between these two points, we propose to
extend the existing deﬁnition of Chen and Liu (2017), yet
keep a similar level of abstraction. In this way, we can add
severalimportantfactorsforcontinuallearning,asaguideline
to researchers that these aspects are relevant, and at the same
time avoid an excessive amount of introduced constraints.
Our proposition for such a revised description ensues:
Deﬁnition 4. Continual Machine Learning - this work:
The learner performs a sequence of Ncontinual learning tasks,
T1;T2;§;TN, that are distinct from each other in terms of shifts in
the underlying data distribution. The latter can imply a change in
objective,transitionsbetweendiﬀerentdomainsorinclusionofnew
modalities.Atanypointintime,thelearnermustbeabletorobustly
identify unseen unknown data instances. Depending on what is
permissible in application contexts, the learner can either reject
suchinstancesinanon-controllabledatastreamorsetthemaside
forlaterlearning.Inthelatterscenario,thelearnershouldbeable
to rank order unknowns according to similarity with existing tasks,
in order to actively build a meaningful learning curriculum itself.
Ifthesystemisdesiredtobesupervised,ahumanintheloopmay
group and label the set of identiﬁed unseen unknowns to explicitly
guidefuturelearning.Whenfacedwithaselected( N+1)thtask TN+1
(which is called the new or current task) with its data DN+1, the
learnershouldleverageitsdictionaryofrepresentationstoaccelerate
learning of TN+1(forward transfer), extend the dictionary with
uniquerepresentationsobtainedfromthenewtask’sdata(thiscanbe
completelynewtypesofdictionaryelements),whilesimultaneously
maintaining and improving the existing representational dictionary
with respect to former tasks (backward transfer).
In direct comparison with former continual learning
deﬁnitions, introduced in the preamble of this paper, the
description is now extended to include active data queries,
captures the importance of data choice and curricula (if
controllable by the learner), in coherence with awareness
of the open world. In particular, note that the deﬁnition now
explicitly includes the idea of an open world and required
robustness. Following our previous exposition, we deem this
to be a general requirement for any machine learner, with
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 31 of 37

--- PAGE 32 ---
A Wholistic View of Continual Learning with Deep Neural Networks
particularly manifesting importance in continual learning.
In contrast, the notion of setting aside data instances for
prospective learning to build up a self-selected learning
curriculum is included to emphasize its importance and
impact,yetleftoptionaldependingonconsideredlevelofdata
streamcontrol.Inthisway,thepotentialelementsofcontinual
learningarecapturedwithoutstrictlydictatingspeciﬁcset-
ups, following the same spirit as the original deﬁnition.
5.2. Prospects
We anticipate that our work leads to increased awareness
of the dangers of our current closed world practices and
the necessity of expanding our views towards more realistic
real-world relevant evaluation. In doing so, we believe
that further synergies between presently separately treated
machine learning paradigms will be exposed and can be
exploited. This should ultimately lead to improved, more
robust and simpler machine learning systems.
Weimaginesomeimmediatefollow-upstoeithermake
us of our VAE based framework directly or develop diﬀerent
practicalalternativestoapplyourwholisticcontinuallearning
vision tovarious applications. Toname some examplesthat
directly come to mind, one could consider medical imaging,
where new disease variants arrive and need to be included,
butdiﬀerentdevicesalsofeaturedistinctperturbationsand
data acquisition ﬂuctuates heavily. Similarly, a robot needing
to navigate and learn about the world may directly beneﬁt
fromourview,whereoldknowledgeneedstoberetained,but
new knowledge needs to be carefully acquired (e.g. in order
topreventgettingstuckinnoisyenvironmentsorprioritize
meaningless novelty that is unrelated to an overarching task).
To name a third of countless examples, autonomous driving
couldprovideaninterestingplatform.Hereunexpectedevents
can occur, sensor failure and deviations can arise, but gener-
allyneedtobedistinguishedfromlearningimportantchanges
in the environment or previously unseen objects/obstacles.
The above paragraph already indicates that develop-
menttowardssuchapplications willbeneﬁt fromrespective
datasetsthatenablerequireddetailedinvestigationswithmore
exhaustive evaluation protocols. Intuitively, we could now
listthefactthatwehaveonlyconsideredpseudo-continual
datasets ourselves, even though they have been subject of
our own critique earlier. For reasons of clarity, we repeat
that we have deliberately chosen these datasets, such as
CIFAR10/100, to have teaching examples that are very
familiartothemajorityofreadersandeasytorelateto.We
thus list the investigation of concurrently developed very
recent datasets, that are more beﬁtting of continual learning,
asaprospecttobuildupevenmoreinsights.Speciﬁcally,the
newlyestablishedNeurIPSDatasetandBenchmarksTrack
hasspawnedseveraldatasetswithcontinuallearninginmind.
The individual datasets have diﬀerent, yet complementary
priorities. For instance, CLEAR (Lin et al., 2021) and Wild-
Time (Yao et al., 2022) focus on diﬀerent tasks, but share
the idea of real-world data that naturally develops over time
(e.g. think of a laptop or vehicle changing massively over
the years and decades). CLiMB (Srinivasan et al., 2022)establishesa benchmarkthat focusesoncross-modality and
will thus be interesting to investigate in going beyond our
computer vision examples in this paper. Zhuang et al. (2022)
propose two benchmark variants to empirically analyze how
continual machine learners compare to human learners on
short and long time scales. Finally, Hess et al. (2021) has
sharedaparametrizedgraphicssimulatorinanautonomous
drivingcontext.Adetailedgenerativemodelallowsforthe
creation of sequences with various distribution shifts in
order to systematically investigate the impact on continual
learning. As detailed, we believe that each of these ﬁve
datasets has their respective prospects and their investigation
will contribute to further broaden our obtained insights to
both real-world scenarios and controlled environments.
5.3. Limitations
At this point, we re-emphasize that we do not wish to
claim that our particular neural network method provides
the generally best solution to our previously conducted ex-
periments. Although our speciﬁc neural network framework
realization clearly shows quantitative promise, our main
goal was to highlight the importance of the introduced
consolidated viewpoint. Even though our approach has its
limitations, it is therefore hard to already grasp them in
tangible ways, given that we will ﬁrst need to explore sets of
alternative practical frameworks with the same scope.
To nevertheless give the reader an impression for where
our particular VAE approach can be improved, we brieﬂy
summarizethemaincaveats.Primarily,manyoftheserevolve
around the choice of VAE. The respective limitations have
beendiscussedingreaterdetailinourpriorwork(Mundtetal.,
2022), upon which we have built our practical framework in
theexperimentalsectionofthispaper.Tokeepitconcise,the
limitations can be attributed to two groups:
Assumptions of the EVT approach: The EVT approach
makes an assumption of the existence of uni-modal clus-
ters per class in the VAE’s latent space. Whereas this is
encouragedbythelinearclassiﬁcationobjectivetoachieve
separation between classes under the constraint of following
the prior, there is no strict theoretical guarantee. It is
conceivable, particularly in higher dimensions, that there
exist scenarios in which multiple sub-clusters manifest on
one side of a decision boundary. Note that this has not yet
beenobservedempiricallyinourempiricalteachingexamples
and negative impacts on performance remain to be seen.
Limitations of the generative architecture: It is well
known that a conventional VAE may be outperformed by
other methods when it comes to “scale”. In other words,
generationqualityisoftensurpassedonverylargedatasets.
Even though they are not the direct subject of this paper,
these generated instances could be used for e.g. a generative
rehearsal strategy, as an alternative to the presented real data
core sets. Despite not being necessary yet for the teaching
examples in this work, our previous work (Mundt et al.,
2022) has shown that several newer generative modeling
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 32 of 37

--- PAGE 33 ---
A Wholistic View of Continual Learning with Deep Neural Networks
advances for VAEs (e.g. autoregression, adversarial training,
or introspection) can be used on top to largely overcome
thischallenge.Forclarity,weemphasizethatsuchadditional
advancesarerequiredinordertoscaleourframeworktolarger
realworlddata.Wenotethatsuchapproachesoftencomewith
additional computational expense. However, we are unaware
of any alternativesthat presently meet therequired criteria
to represent our wholistic view, as alternatives are subject to
future development.
6. Conclusion
We have presented a common viewpoint to naturally
unite robust continual and active learning in the presence
of the unknown. For each aspect, we have conducted an
experimental investigation to provide empirical evidence in
support of our viewpoint’s beneﬁts. Needless to say, each
ofourindividuallypresentedexperimentscanbeextended
with multiple facets and several nuanced applications can
be derived and thoroughly investigated. Consequently, we
encourage future works to adopt our framework or take a
similarly wholistic approach with diﬀerent practical instanti-
ations. At the very minimum, we would expect future works
to rethink current practices and question whether current
benchmarks are a realistic reﬂection of our desiderata for
continualmachinelearningsystems.Asillustratedthroughout
the paper, this necessitates stepping out of present closed
world benchmark routines.
7. Acknowledgements
This work was supported by the German Federal Min-
istry of Education and Research (BMBF) funded project
01IS19062“AISEL”andtheEuropeanUnion’sHorizon2020
project No. 769066 “RESIST”.
References
Abu-Mostafa, Y.S., 1990. Learning from hintsin neuralnetworks. Journal
of Complexity 6, 192–198.
Achille, A., Eccles, T., Matthey, L., Burgess, C.P., Watters, N., Lerchner,
A., Higgins, I., 2018. Life-Long Disentangled Representation Learning
with Cross-Domain Latent Homologies. Neural Information Processing
Systems (NeurIPS) .
Ahn, H., Cha, S., Lee, D., Moon, T., 2019. Uncertainty-based Continual
Learningwith AdaptiveRegularization. NeuralInformationProcessing
Systems (NeurIPS) .
Aimone, J.B., Li, Y., Lee, S.W., Clemenson, G.D., Deng, W., Gage, F.H.,
2014. Regulation and function of adult neurogenesis: from genes to
cognition. Physiological reviews 94, 991–1026.
Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M., Tuytelaars, T., 2018.
Memory Aware Synapses: Learning what (not) to forget. European
Conference on Computer Vision (ECCV) .
Aljundi, R., Chakravarty, P., Tuytelaars, T., 2017. Expert gate: Lifelong
learning with a network of experts. Computer Vision and Pattern
Recognition (CVPR) .
Ans, B., Rousset, S., 1997. Avoiding catastrophic forgetting by coupling
two reverberating neural networks. Life Sciences , 989–997.
Ash, T., 1989. Dynamic Node Creation in Backpropagation Networks.
Connection Science 1, 365–375.
Atlas, L.E., Cohn, D.A., Ladner, R., El-Sharkawi, M.A., Marks II, R.J.,
Aggoune, M.E., Park, D.C., 1990. Training connectionist networks withqueries and selective sampling. Neural Information Processing Systems
(NeurIPS) .
Bachem, O., Lucic, M., Krause, A., 2015. Coresets for Nonparametric
Estimation-theCaseofDP-Means.InternationalConferenceonMachine
Learning (ICML) 37, 209–217.
Bartlett, P.L., Wegkamp, M.H., 2008. Classiﬁcation with a reject option
using a hinge loss. Journal of Machine Learning Research 9, 1823–1840.
Becker, S., Ackermann, M., Lapuschkin, S., Müller, K.R., Samek, W., 2018.
Interpreting and Explaining Deep Neural Networks for Classiﬁcation of
Audio Signals. arXiv preprint arXiv: 1807.03418 .
Bell, S.,Upchurch, P., Snavely, N.,Bala, K., 2015. Material recognition in
thewild withtheMaterials inContextDatabase. ComputerVisionand
Pattern Recognition (CVPR) .
Beluch,W.H.,Genewein,T.,Nürnberger,A.,Köhler,J.M.,2018. ThePower
of Ensembles for Active Learning in Image Classiﬁcation. Computer
Vision and Pattern Recognition (CVPR) .
Bendale,A.,Boult,T.E.,2015.TowardsOpenWorldRecognition.Computer
Vision and Pattern Recognition (CVPR) .
Bendale,A.,Boult,T.E.,2016.TowardsOpenSetDeepNetworks.Computer
Vision and Pattern Recognition (CVPR) .
Bengio, Y., Louradour, J., Collobert, R., Weston, J., 2009. Curriculum
learning. International Conference on Machine Learning (ICML) .
Bishop, C.M., 1994. Novelty detection and neural network validation. IEE
Proceedings: Vision, Image and Signal Processing 141, 217–222.
Bottou,L.,1999.OnlineLearningandStochasticApproximations,in:Online
Learning in Neural Networks, pp. 9–42.
Boult,T.E., Cruz, S.,Dhamija,A.R.,Gunther, M.,Henrydoss,J.,Scheirer,
W.J., 2019. Learning and the Unknown : Surveying Steps Toward Open
World Recognition. AAAI Conference on Artiﬁcial Intelligence (AAAI)
.
Burgess,C.P.,Higgins, I.,Pal,A., Matthey, L.,Watters,N., Desjardins,G.,
Lerchner,A.,2017. Understandingdisentanglinginbeta-VAE. Neural
Information Processing Systems (NeurIPS), Workshop on Learning
Disentangled Representations .
Carlson, A., Betteridge, J., Kisiel, B., Settles, B., Hruschka, E.R., Mitchell,
T.M.,2010. Towardanarchitecture fornever-endinglanguagelearning.
AAAI Conference on Artiﬁcial Intelligence (AAAI) .
Caruana, R., 1997. Multitask Learning. Machine Learning 28, 41–75.
Chaudhry, A., Dokania, P.K., Ajanthan, T., Torr, P.H.S., 2018. Riemannian
WalkforIncrementalLearning:UnderstandingForgettingandIntransi-
gence. European Conference on Computer Vision (ECCV) .
Chaudhry,A.,Ranzato,M.,Rohrbach,M.,Elhoseiny,M.,2019. Eﬃcient
lifelong learning with A-GEM. International Conference on Learning
Representations (ICLR) .
Chen,T.,Goodfellow,I.,Shlens,J.,2016. Net2Net:Acceleratinglearning
via knowledge transfer. International Conference on Learning Represen-
tations (ICLR) .
Chen, X., Shrivastava, A., Gupta, A., 2013. Neil: Extracting visual
knowledgefromwebdata. InternationalConferenceonComputerVision
(ICCV) .
Chen,Z.,Liu,B.,2017. LifelongMachineLearning.volume33. Morgan
and Claypool.
Cimpoi, M., Maji, S., Vedaldi, A., 2015. Deep convolutional ﬁlter banks
for texture recognition and segmentation. Computer Vision and Pattern
Recognition (CVPR) .
Cohn, D.A., Ghahramani, Z., Jordan, M.I., 1996. Active learning with
statistical models. Journal of Artiﬁcial Intelligence Research 4, 129–145.
Dasgupta,S.,2005. Analysisofagreedyactivelearningstrategy. Neural
Information Processing Systems (NeurIPS) .
DeLange,M.,Aljundi,R.,Masana,M.,Parisot,S.,Jia,X.,Leonardis,A.,
Slabaugh,G.,Tuytelaars,T.,2021. Acontinuallearningsurvey:Defying
forgetting in classiﬁcation tasks. IEEE Transactions on Pattern Analysis
and Machine Intelligence (TPAMI) .
Dhamija, A.R., Günther, M., Boult, T.E., 2018. Reducing Network
Agnostophobia. Neural Information Processing Systems (NeurIPS) .
Díaz-Rodríguez, N., Lomonaco, V., Filliat, D., Maltoni, D., 2018. Don’t
forget, there is more than forgetting: new metrics for Continual Learning.
NeuralInformationProcessingSystems(NeurIPS),ContinualLearning
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 33 of 37

--- PAGE 34 ---
A Wholistic View of Continual Learning with Deep Neural Networks
Workshop .
Draelos, T.J., Miner, N.E., Lamb, C.C., Cox, J.A., Vineyard, C.M., Carlson,
K.D., Severa, W.M., James, C.D., Aimone, J.B., 2017. Neurogenesis
deep learning: Extending deep networks to accommodate new classes.
International Joint Conference on Neural Networks (IJCNN) , 526–533.
Ebrahimi,S.,Elhoseiny,M.,Darrell,T.,Rohrbach,M.,2020. Uncertainty-
guidedContinualLearningwithBayesianNeuralNetworks. International
Conference on Learning Representations (ICLR) .
Farquhar, S., Gal, Y., 2018a. A Unifying Bayesian View of Continual
Learning. NeuralInformationProcessingSystems(NeurIPS)Bayesian
Deep Learning Workshop .
Farquhar, S., Gal, Y., 2018b. Towards Robust Evaluations of Continual
Learning. International Conference on Machine Learning (ICML),
Lifelong Learning: A Reinforcement Learning Approach Workshop .
Fei, G., Wang, S., Liu, B., 2016. Learning cumulatively to become
moreknowledgeable. ProceedingsoftheACMSIGKDDInternational
Conference on Knowledge Discovery and Data Mining , 1565–1574.
Fei-Fei, L., Fergus, R., Perona, P., 2006. One-shot learning of object
categories. IEEE Transactions on Pattern Analysis and Machine
Intelligence (TPAMI) 28, 594–611.
Feng, Q., Kang, G., Fan, H., Yang, Y., 2019. Attract or Distract: Exploit
theMarginofOpenSet. InternationalConferenceonComputerVision
(ICCV) .
Fernando, C., Banarse, D., Blundell, C., Zwols, Y., Ha, D., Rusu, A.A.,
Pritzel,A., Wierstra,D., 2017. PathNet:EvolutionChannels Gradient
Descent in Super Neural Networks. arXiv preprint arXiv:1701.08734 .
Fink,M.,2005. Objectclassiﬁcationfromasingleexampleutilizingclass
relevance metrics. Neural Information Processing Systems (NeurIPS) .
French, R.M., 1992. Semi-distributed Representations and Catastrophic
Forgetting in Connectionist Networks. Connection Science 4, 365–377.
French, R.M., 1997. Pseudo-recurrent Connectionist Networks: An Ap-
proach to the ’Sensitivity-Stability’ Dilemma. Connection Science 9,
353–380.
Freund, Y., Schapire, R.E., 1997. A decision theoretic generalisation of
online learning and an application to boosting. Computer and System
Sciences 55, 119–139.
Gal, Y., Ghahramani, Z., 2015. Dropout as a Bayesian Approximation
: Representing Model Uncertainty in Deep Learning. International
Conference on Machine Learning (ICML) 48.
Gal,Y.,Islam,R.,Ghahramani,Z.,2017. DeepBayesianActiveLearning
withImageData. InternationalConferenceonMachineLearning(ICML)
.
Geifman, Y., El-Yaniv, R., 2019. Deep Active Learning with a Neural
Architecture Search. Neural Information Processing Systems (NeurIPS) .
Geirhos, R., Michaelis, C., Wichmann, F.A., Rubisch, P., Bethge, M.,
Brendel,W.,2019. Imagenet-trainedCNNsarebiasedtowardstexture;
increasingshapebiasimprovesaccuracyandrobustness. International
Conference on Learning Representations (ICLR) .
Gepperth, A., Karaoguz, C., 2016. A Bio-Inspired Incremental Learning
ArchitectureforAppliedPerceptualProblems. CognitiveComputation8,
924–934.
Gonzalez, T.F., 1985. Clustering to minimize the maximum intercluster
distance. Theoretical Computer Science 38, 293–306.
Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D.,
Ozair, S.,Courville, A., Bengio, Y.,2014. GenerativeAdversarial Nets.
Neural Information Processing Systems (NeurIPS) .
Gross, C.G., 2000. Neurogenesis in the adult brain: Death of a dogma.
Nature Reviews Neuroscience 1, 67–73.
Hacohen,G.,Choshen,L.,Weinshall,D.,2020. Let’sAgreetoAgree:Neural
Networks Share Classiﬁcation Order on Real Datasets. International
Conference on Learning Representations (ICLR) .
He, K., Zhang, X., Ren, S., Sun, J., 2015. Delving deep into rectiﬁers:
Surpassinghuman-levelperformanceonimagenetclassiﬁcation. Interna-
tional Conference on Computer Vision (ICCV) .
He,K.,Zhang,X.,Ren,S.,Sun,J.,2016. DeepResidualLearningforImage
Recognition. Computer Vision and Pattern Recognition (CVPR) .
Hebb, D.O., 1949. The Organization of Behavior; A Neuropsychological
Theory. John Wiley & Sons, Chapman & Hall.Hendrycks, D., Dietterich, T., 2019. Benchmarking neural network
robustness to common corruptions and perturbations. International
Conference on Learning Representations (ICLR) .
Hendrycks,D.,Gimpel,K.,2017. Abaselinefordetectingmisclassiﬁedand
out-of-distributionexamplesinneuralnetworks.InternationalConference
on Learning Representations (ICLR) .
Heskes, T.M., Kappen, B., 1993. On-line learning processes in artiﬁcial
neural networks. Mathematical Foundations of Neural Networks 51,
199–233.
Hess, T., Mundt, M., Pliushch, I., Ramesh, V., 2021. A procedural
world generation framework for systematic evaluation of continual
learning. NeuralInformationProcessingSystems(NeurIPS),Datasetand
Benchmarks Track .
Hinton, G.E., Vinyals, O., Dean, J., 2014. Distilling the Knowledge in a
Neural Network. NeurIPS Deep Learning Workshop .
Hochreiter,S.,Schmidhuber,J.,1997. LongShort-TermMemory. Neural
Computation 9, 1735–1780.
Hoﬀman, M.D., Johnson, M.J., 2016. ELBO surgery: yet another way to
carve up the variational evidence lower bound. Neural Information
Processing Systems (NeurIPS), Advances in Approximate Bayesian
Inference Workshop .
Ilyas,A.,Santurkar,S.,Tsipras,D.,Engstrom,L.,Tran,B.,Madry,A.,2019.
AdversarialExamplesarenotBugs,theyareFeatures.NeuralInformation
Processing Systems (NeurIPS) .
Ioﬀe, S., Szegedy, C., 2015. Batch Normalization: Accelerating Deep
Network Training by Reducing Internal Covariate Shift. International
Conference on Machine Learning (ICML) .
Isele,D.,Cosgun,A.,2018. Selectiveexperiencereplayforlifelonglearning.
AAAI Conference on Artiﬁcial Intelligence (AAAI) .
Javed,K.,Shafait,F.,2018. RevisitingDistillationandIncrementalClassiﬁer
Learning. Asian Conference on Computer Vision (ACCV) .
Joshi, A.J., Porikli, F., Papanikolopoulos, N., 2009. Multi-class active learn-
ingforimageclassiﬁcation. ComputerVisionandPatternRecognition
(CVPR) .
Käding,C.,Freytag,A.,Rodner,E.,Perino,A.,Denzler,J.,2016a. Large-
scale active learning with approximations of expected model output
changes. German Conference on Pattern Recognition .
Käding, C., Rodner, E., Freytag, A., Denzler, J., 2016b. Active and
continuousexplorationwithdeepneuralnetworksandexpectedmodel
output changes. ArXiv preprint arXiv:1612.06129 .
Kemker,R.,Kanan,C.,2018. FearNet:Brain-inspiredmodelforincremental
learning. International Conference on Learning Representations (ICLR)
.
Kemker, R., McClure, M., Abitino, A., Hayes, T., Kanan, C., 2018. Measur-
ingCatastrophicForgettinginNeuralNetworks. AAAIConferenceon
Artiﬁcial Intelligence (AAAI) .
Kendall, A., Badrinarayanan, V., Cipolla, R., 2017. Bayesian segnet: Model
uncertaintyindeepconvolutionalencoder-decoderarchitecturesforscene
understanding. British Machine Vision Conference (BMVC) .
Kingma, D.P., Ba, J.L., 2015. Adam: a Method for Stochastic Optimization.
International Conference on Learning Representations (ICLR) .
Kingma, D.P., Welling, M., 2013. Auto-Encoding Variational Bayes.
International Conference on Learning Representations (ICLR) .
Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G.,
Rusu,A.A.,Milan,K.,Quan,J.,Ramalho,T.,Grabska-Barwinska,A.,
Hassabis, D., Clopath, C., Kumaran, D., Hadsell, R., 2017. Overcoming
catastrophicforgettingin neuralnetworks. Proceedingsofthe National
Academy of Sciences (PNAS) 114, 3521–3526.
Konyushkova, K., Raphael, S., Fua, P., 2017. Learning active learning from
data. Neural Information Processing Systems (NeurIPS) .
Krizhevsky, A., 2009. Learning Multiple Layers of Features from Tiny
Images. Technical Report. Toronto.
Kumaran, D., Hassabis, D., McClelland, J.L., 2016. What learning systems
do intelligent agents need? complementary learning systems theory
updated. Trends in Cognitive Sciences 20, 512–534.
Lampert,C.H.,Nickisch,H.,Harmeling,S.,2009. Learningtodetectunseen
object classes by between-class attribute transfer. Computer Vision and
Pattern Recognition (CVPR) .
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 34 of 37

--- PAGE 35 ---
A Wholistic View of Continual Learning with Deep Neural Networks
Lapuschkin,S.,Wäldchen,S.,Binder,A.,Montavon,G.,Samek,W.,Müller,
K.R., 2019. Unmasking Clever Hans predictors and assessing what
machines really learn. Nature Communications 10.
LeCun,Y.,Bottou,L.,Bengio,Y.,Haﬀner,P.,1998. Gradient-basedlearning
applied to document recognition. Proceedings of the IEEE 86, 2278–
2323.
Lee,K.,Lee,H.,Lee,K.,Shin,J.,2018a. TrainingConﬁdence-Calibrated
Classiﬁers for Detecting Out-of-Distribution Samples. International
Conference on Learning Representations (ICLR) .
Lee, K., Lee, K., Lee, H., Shin, J., 2018b. A Simple Uniﬁed Framework for
Detecting Out-of-Distribution Samples and Adversarial Attacks. Neural
Information Processing Systems (NeurIPS) .
Lee, S.W., Kim, J.H., Jun, J., Ha, J.W., Zhang, B.T., 2017. Overcoming
catastrophic forgetting by incremental moment matching. Neural
Information Processing Systems (NeurIPS) , 4653–4663.
Lesort, T., Caselles-Dupré, H., Garcia-Ortiz, M., Stoian, A., Filliat, D.,
2019. Generative Models from the perspective of Continual Learning.
International Joint Conference on Neural Networks (IJCNN) .
Lesort,T.,Lomonaco,V.,Stoian,A.,Maltoni,D.,Filliat,D.,Díaz-Rodríguez,
N.,2020. Continuallearningforrobotics:Deﬁnition,framework,learning
strategies, opportunities and challenges. Information Fusion 58, 52–68.
Lewis, D.D., Gale, W.A., 1994. A sequential algorithm for training text
classiﬁers. International ACM SIGIR Conference on Research and
Development in Information Retrieval, SIGIR 1994 .
Li, F., Wechsler, H., 2005. Open set face recognition using transduction.
IEEE Transactions on Pattern Analysis and Machine Intelligence 27,
1686–1697.
Li, X., Guo, Y., 2013. Adaptive active learning for image classiﬁcation.
Computer Vision and Pattern Recognition (CVPR) , 859–866.
Li,X.,Zhou,Y.,Wu,T.,Socher,R.,Xiong,C.,2019a. LearntoGrow:A
Continual Structure Learning Framework for Overcoming Catastrophic
Forgetting. International Conference on Machine Learning (ICML) .
Li,Y.,Bradshaw,J.,Sharma,Y.,2019b. AreGenerativeClassiﬁersMore
Robust to Adversarial Attacks? International Conference on Machine
Learning (ICML) .
Li, Z., Hoiem, D., 2016. Learning without forgetting. European Conference
on Computer Vision (ECCV) .
Liang, S., Li, Y., Srikant, R., 2018. Enhancing the Reliability of Out-
of-distribution Image Detection in Neural Networks. International
Conference on Learning Representations (ICLR) .
Lin,Z.,Pathak,D., Ramanan,D.,2021. Theclearbenchmark:Continual
learning on real-world imagery. Neural Information Processing Systems
(NeurIPS), Dataset and Benchmarks Track .
Lis, K., Nakka, K., Fua, P., Salzmann, M., 2019. Detecting the Unexpected
via Image Resynthesis. International Conference on Computer Vision
(ICCV) .
Lopez-Paz,D.,Ranzato,M.,2017. GradientEpisodicMemoryforContinual
Learning. Neural Information Processing Systems (NeurIPS) .
MacKay, D.J.C., 1992. Information-BasedObjective Functions for Active
Data Selection. Neural Computation 4, 590–604.
Mahapatra, D., Bozorgtabar, B., Thiran, J.P., Reyes, M., 2018. Eﬃcient
active learning for image classiﬁcation and segmentation using a sample
selection and conditional generative adversarial network. Medical Image
Computing and Computer Assisted Intervention (MICCAI) .
Mallya, A., Davis, D., Lazebnik, S., 2018. Piggyback: Adapting a Single
Network to Multiple Tasks by Learning to Mask Weights. European
Conference on Computer Vision (ECCV) .
Matan, O., Kiang, R., Stenard, C.E., Boser, B.E., Denker, J., Henderson,
D., Hubbard, W., Jackel, L., LeCun, Y., 1990. Handwritten Character
Recognition Using Neural Network Architectures. 4th USPS Advanced
Technology Conference 2, 1003–1011.
Mathieu,E.,Rainforth,T.,Siddharth,N.,Teh,Y.W.,2019. Disentangling
disentanglementinvariationalautoencoders. InternationalConference
on Machine Learning (ICML) , 7744–7754.
Mayer, C., Timofte, R., 2020. Adversarial sampling for active learning.
Winter Conference on Applications of Computer Vision (WACV) .
McCallum, A.K., Nigam, K., 1998. Employing EM and Pool-Based Active
LearningforTextClassiﬁcation. InternationalConferenceonMachineLearning (ICML) .
McClelland, J.L., McNaughton, B.L., O’Reilly, R.C., 1995. Why there are
complementary learning systems in the hippocampus and neocortex:
insights from the successes and failures of connectionist models of
learning and memory. Psychological Review 102, 419–457.
McCloskey,M.,Cohen,N.J.,1989. CatastrophicInterferenceinConnection-
istNetworks:TheSequentialLearningProblem. PsychologyofLearning
and Motivation - Advances in Research and Theory 24, 109–165.
Miller, D., Nicholson, L., Dayoub, F., Sunderhauf, N., 2018. Dropout
Sampling for Robust Object Detection in Open-Set Conditions, in: IEEE
InternationalConferenceonRoboticsandAutomation(ICRA),pp.3243–
3249.
Mitchell,T.M.,1982. Generalizationassearch. ArtiﬁcialIntelligence18,
203–226.
Mitchell, T.M., Cohen, W., Hruschka, E.R., Talukdar, P., Betteridge, J.,
Carlson,A.,Dalvi,B.,Gardner,M.,Kisiel,B.,Krishnamurthy,J.,Lao,
N.,Mazaitis,K.,Mohamed,T.,Nakashole,N.,Platanios,E.,Ritter,A.,
Samadi, M., Settles, B., Wang, R., Wijaya, D., Gupta, A., Chen, X.,
Saparov, A., Greaves, M., Welling, J., 2015. Never-ending learning.
AAAI Conference on Artiﬁcial Intelligence (AAAI) .
Mundt, M., Majumder, S., Pliushch, I., Hong, Y.W., Ramesh, V., 2022.
Uniﬁed Probabilistic Deep Continual Learning through Generative
Replay and Open Set Recognition. Journal of Imaging 8.
Mundt, M., Pliushch, I., Majumder, S., Ramesh, V., 2019. Open Set
RecognitionThroughDeepNeuralNetworkUncertainty:DoesOut-of-
Distribution Detection Require Generative Classiﬁers? International
ConferenceonComputerVision(ICCV),FirstWorkshoponStatistical
Deep Learning for Computer Vision (SDL-CV) .
Munro, R., 2020. Human-in-the-Loop Machine Learning. Manning
Publications, Manning Early Access Program.
Nalisnick, E., Matsukawa, A., Teh, Y.W., Gorur, D., Lakshminarayanan,
B.,2019. DoDeepGenerativeModelsKnowWhatTheyDon’tKnow?
International Conference on Learning Representations (ICLR) .
Naylor,R.,2010.Knownknowns,knownunknownsandunknownunknowns:
A 2010 update on carotid artery disease. Surgeon 8, 79–86.
Nguyen,C.V.,Li,Y.,Bui,T.D.,Turner,R.E.,2018. VariationalContinual
Learning. International Conference on Learning Representations (ICLR)
.
Nguyen,H.T.,Smeulders,A.,2004. Activelearningusingpre-clustering.
International Conference on Machine Learning (ICML) .
Oquab, M., Bottou, L., Laptev, I., Sivic, J., 2014. Learning and transferring
mid-level image representations using convolutional neural networks.
Computer Vision and Pattern Recognition (CVPR) .
Ovadia,Y.,Fertig,E.,Ren,J.,Nado,Z.,Sculley,D.,Nowozin,S.,Dillon,J.V.,
Lakshminarayanan, B., Snoek, J., 2019. Can You Trust Your Model’s
Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift.
Neural Information Processing Systems (NeurIPS) .
Pan,S.J.,Yang,Q.,2010.ASurveyonTransferLearning.IEEETransactions
on Knowledge and Data Engineering (TKDE) 22.
Parisi,G.I.,Kemker,R.,Part,J.L.,Kanan,C.,Wermter,S.,2019. Continual
LifelongLearningwithNeuralNetworks:AReview. NeuralNetworks
113, 54–71.
Park, D., Hong, S., Han, B., Lee, K.M., 2019. Continual Learning
byAsymmetricLossApproximationwithSingle-SideOverestimation.
International Conference on Computer Vision (ICCV) .
Perera, P., Nallapati, R., Xiang, B., 2019. OCGAN: One-class Novelty De-
tectionUsingGANswithConstrainedLatentRepresentations. Computer
Vision and Pattern Recognition (CVPR) .
Pfülb, B., Gepperth, A., 2019. A Comprehensive, Application-Oriented
Study of Catastrophic Forgetting in DNNs. International Conference on
Learning Representations (ICLR) .
Pliushch,I.,Mundt,M.,Lupp,N.,Ramesh,V.,2022. WhenDeepClassiﬁers
Agree: Analyzing Correlations between Learning Order and Image
Statistics. European Conference on Computer Vision (ECCV) .
Pratt,L.Y.,1993. Discriminability-BasedTransferbetweenNeuralNetworks.
Neural Information Processing Systems (NeurIPS) .
Pratt, L.Y., Mostow, J., Kamm, C.A., 1991. Direct Transfer of Learned
InformationAmongNeuralNetworks. AAAIConferenceonArtiﬁcial
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 35 of 37

--- PAGE 36 ---
A Wholistic View of Continual Learning with Deep Neural Networks
Intelligence (AAAI) .
Rannen, A., Aljundi, R., Blaschko, M.B., Tuytelaars, T., 2017. Encoder
Based Lifelong Learning. International Conference on Computer Vision
(ICCV) .
Ratcliﬀ, R., 1990. Connectionist Models of Recognition Memory: Con-
straintsImposedbyLearningandForgettingFunctions. Psychological
Review 97, 285–308.
Rebuﬃ, S.A., Kolesnikov, A., Sperl, G., Lampert, C.H., 2017. iCaRL:
Incremental classiﬁer and representation learning. Computer Vision and
Pattern Recognition (CVPR) .
Robins, A.,1995. CatastrophicForgetting, Rehearsaland Pseudorehearsal.
Connection Science 7, 123–146.
Rolnick, D., Ahuja, A., Schwarz, J., Lillicrap, T.P., Wayne, G., 2018. Expe-
rience Replay for Continual Learning. Neural Information Processing
Systems (NeurIPS) .
Roy,N.,McCallum,A.,2001. Towardoptimalactivelearningthroughmonte
carlo estimation of error reduction. Proceedings of the International
Conference on Machine Learning (ICML) , 441–448.
Ruder, S., 2017. An Overview of Multi-Task Learning in Deep Neural
Networks. arXiv preprint arXiv: 1706.05098 .
Russakovsky, O., Deng,J., Su, H.,Krause, J., Satheesh,S., Ma, S.,Huang,
Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L.,
2015. ImageNetLargeScaleVisualRecognitionChallenge. International
Journal of Computer Vision (IJCV) 115, 211–252.
Rusu, A.A., Rabinowitz, N.C., Desjardins, G., Soyer, H., Kirkpatrick, J.,
Kavukcuoglu, K., Pascanu, R., Hadsell, R., 2016. Progressive Neural
Networks. arXiv preprint arXiv:1606.04671 .
Saad, D. (Ed.), 1999. On-line learning in neural networks. Cambridge
University Press, New York, NY, USA.
Sahoo, D., Pham, Q., Lu, J., Hoi, S.C.H., 2018. Online deep learning:
Learningdeepneuralnetworksontheﬂy. InternationalJointConference
on Artiﬁcial Intelligence (IJCAI) , 2660–2666.
Schapire,R.E.,1990. TheStrengthofWeakLearnability. MachineLearning
5, 197–227.
Scheirer,W.J.,Jain,L.P.,Boult,T.E.,2014. ProbabilityModelsForOpen
SetRecognition. IEEETransactionsonPatternAnalysisandMachine
Intelligence .
Scheirer, W.J., Rocha, A., Sapkota, A., Boult, T.E., 2013. Towards Open
SetRecognition. IEEETransactionsonPatternAnalysisandMachine
Intelligence (TPAMI) 35, 1757–1772.
Sener, O., Savarese, S., 2018. Active learning for convolutional neural
networks: A core-set approach. International Conference on Learning
Representations (ICLR) .
Serra, J., Suris, D., Mirón, M., Karatzoglou, A., 2018. Overcoming
Catastrophic forgetting with hard attention to the task. International
Conference on Machine Learning (ICML) .
Settles, B., Craven, M., 2008. An analysis of active learning strategies
for sequence labeling tasks. Empirical Methods in Natural Language
Processing (EMNLP) , 1070–1079.
Seung, H.S., Opper, M., Sompolinsky, H., 1992. Query by committee.
Proceedings of the Fifth Annual ACM Workshop on Computational
Learning Theory , 287–294.
Shannon, C.E., 1948. A Mathematical Theory of Communication. Bell
System Technical Journal 27, 623–656.
Shin, H., Lee, J.K., Kim, J.J., Kim, J., 2017. Continual Learning with Deep
Generative Replay. Neural Information Processing Systems (NeurIPS) .
Shui, C., Zhou, F., Gagné, C., Wang, B., 2020. Deep Active Learning:
Uniﬁed and Principled Method for Query and Training. AISTATS .
Sinha, S., Ebrahimi, S., Darrell, T., 2019. Variational adversarial active
learning. International Conference on Computer Vision (ICCV) .
Sodhani, S., Chandar, S., Bengio, Y., 2019. Towards Training Recurrent
Neural Networks for Lifelong Learning. Neural Computation .
Srinivasan, T., Chang, T.Y., Pinto Alva, L.L., Chochlakis, G., Rostami, M.,
Thomason, J., 2022. Climb: A continual learning benchmark for vision-
and-language tasks. Neural Information Processing Systems (NeurIPS),
Dataset and Benchmarks Track .
Srivastava,N.,Hinton,G.E.,Krizhevsky,A.,Sutskever,I.,Salakhutdinov,
R., 2014. Dropout : A Simple Way to Prevent Neural Networks fromOverﬁtting. JournalofMachineLearningResearch(JMRL)15,1929–
1958.
Suddarth,S.C.,Kergosien,Y.L.,1990. Rule-injectionhintsasameansof
improving network performance and learning time. Neural Networks.
EURASIP 1990. Lecture Notes in Computer Science 412.
Thrun,S.,1996a. Explanation-BasedNeuralNetworkLearning-ALifelong
Learning Approach. Springer US.
Thrun, S., 1996b. Is Learning The n-th Thing Any Easier Than Learning
The First? Advances in Neural Information Processing Systems .
Tong, S., Koller, D., 2001. Support Vector Machine Active Learning
withApplicationstoTextClassiﬁcation. JournalofMachineLearning
Research (JMLR) .
Tran, T., Do, T.T., Reid, I., Carneiro, G., 2019. Bayesian generative active
deep learning. International Conference on Machine Learning (ICML) .
Tsang,I.W.,Kwok,J.T.,Cheung,P.M.,2005. Corevectormachines:Fast
SVM training on very large data sets. Journal of Machine Learning
Research 6, 363–392.
Tsypkin, Y.Z., 1971. Adaptation and Learning in Automatic Systems.
Academic Press, New York.
Vadodaria, K.C., Jessberger, S., 2014. Functional neurogenesis in the adult
hippocampus: Then and now. Frontiers in Neuroscience 8, 1–3.
Vapnik, V., 1982. Estimation of Dependences Based on Empirical Data.
Springer-Verlag, Berlin, Heidelberg.
van de Ven, G.M., Tolias, A.S., 2018. Generative replay with feedback
connectionsasageneralstrategyforcontinuallearning. arXivpreprint
arXiv:1809.10635 .
Wang, Y., Yao, Q., Kwok, J., Ni, L.M., 2020. Generalizing from a Few
Examples: A Survey on Few-Shot Learning. ACM Computing Surveys .
Weiss, K., Khoshgoftaar, T.M., Wang, D.D., 2016. A survey of transfer
learning. Journal of Big Data 3.
Welling, M., 2009. Herding dynamical weights to learn. International
Conference On Machine Learning (ICML) , 1121–1128.
Weston,J.,Collobert,R.,Sinz,F.,Bottou,L.,Vapnik,V.,2006. Inference
with the Universum. International Conference on Machine Learning
(ICML) .
Wu, C., Herranz, L., Liu, X., Wang, Y., van de Weijer, J., Raducanu, B.,
2018. Memory Replay GANs: learning to generate images from new
categorieswithoutforgetting. NeuralInformationProcessingSystems
(NeurIPS) .
Wu, Y., Chen, Y., Wang, L., Ye, Y., Liu, Z., Guo, Y., Fu, Y., 2019. Large
Scale Incremental Learning. Computer Vision and Pattern Recognition
(CVPR) .
Xiang, Y., Fu, Y., Ji, P., Huang, H., 2019. Incremental Learning Using Con-
ditionalAdversarialNetworks. InternationalConferenceonComputer
Vision (ICCV) .
Xiao, K., Engstrom, L., Ilyas, A., Madry, A., 2020. Noise or Signal: The
RoleofImageBackgroundsinObjectRecognition. ArXivpreprintarXiv:
2006.09994 .
Xu, J., Zhu, Z., 2018. Reinforced continual learning. Neural Information
Processing Systems (NeurIPS) .
Yao,H.,Choi,C.,Lee,Y.,Koh,P.,Finn,C.,2022. Wild-time:Abenchmark
ofin-the-wilddistributionshiftovertime. NeuralInformationProcessing
Systems (NeurIPS), Dataset and Benchmarks Track .
Yoon, J., Yang, E., Lee, J., Hwang, S.J., 2018. Lifelong Learning
withDynamicallyExpandableNetworks. InternationalConferenceon
Learning Representations (ICLR) .
Yoshihashi, R., Shao, W., Kawakami, R., You, S., Iida, M., Naemura, T.,
2019. Classiﬁcation-Reconstruction Learning for Open-Set Recognition.
Computer Vision and Pattern Recognition (CVPR) .
Yosinski,J.,Clune,J.,Bengio,Y.,Lipson,H.,2014. Howtransferableare
featuresindeepneuralnetworks? NeuralInformationProcessingSystems
(NeurIPS) .
Yu, Q.,Aizawa, K.,2019. Unsupervised Out-of-DistributionDetectionby
MaximumClassiﬁerDiscrepancy. InternationalConferenceonComputer
Vision (ICCV) .
Zagoruyko, S., Komodakis, N., 2016. Wide Residual Networks. British
Machine Vision Conference (BMVC) .
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 36 of 37

--- PAGE 37 ---
A Wholistic View of Continual Learning with Deep Neural Networks
Zenke, F., Poole, B., Ganguli, S., 2017. Continual Learning Through
Synaptic Intelligence. International Conference on Machine Learning
(ICML) 70, 3987–3995.
Zhai, M., Chen, L., Tung, F., He, J., Nawhal, M., Mori, G., 2019. Lifelong
GAN: Continual Learning for Conditional Image Generation. Interna-
tional Conference on Computer Vision (ICCV) .
Zhang,T.,Oles,F.J.,2000.AProbabilityAnalysisontheValueofUnlabelled
Data for Classiﬁcation Problems. International Conference on Machine
Learning (ICML) .
Zhou, G., Sohn, K., Lee, H., 2012. Online Incremental Feature Learning
with Denoising Autoencoders. International Conference on Artiﬁcial
Intelligence and Statistics (AISTATS) 22, 1453–1461.
Zhu,J.J.,Bento,J.,2017. GenerativeAdversarialActiveLearning. NeurIPS
workshop on Teaching Machines, Robots, and Humans .
Zhuang, C., Xiang, V., Bai, Y., Jia, X., Turk-Browne, N., Norman, K.,
DiCarlo, J., Yamins, D.L., 2022. How well do unsupervised learning
algorithms model human real-time and life-long learning? Neural
Information Processing Systems (NeurIPS), Dataset and Benchmarks
Track .
Zinkevich, M., 2003. Online Convex Programming and Generalized
Inﬁnitesimal Gradient Ascent. International Conference On Machine
Learning (ICML) .
Martin Mundt et al.: Accepted at Neural Networks, ﬁnal version: https://doi.org/10.1016/j.neunet.2023.01.014 Page 37 of 37

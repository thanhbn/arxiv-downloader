# 1802.07569.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/continual-learning/1802.07569.pdf
# Kích thước tệp: 1553436 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Học Suốt Đời Liên Tục với Mạng Nơ-ron:
Một Tổng Quan
German I. Parisi1, Ronald Kemker2, Jose L. Part3, Christopher Kanan2, Stefan Wermter1
1Công nghệ Tri thức, Khoa Tin học, Đại học Hamburg, Đức
2Trung tâm Chester F. Carlson về Khoa học Hình ảnh, Viện Công nghệ Rochester, NY, Hoa Kỳ
3Khoa Khoa học Máy tính, Đại học Heriot-Watt, Trung tâm Robot Edinburgh, Scotland, Vương quốc Anh

Tóm tắt: Con người và động vật có khả năng liên tục thu nhận, tinh chỉnh
và chuyển giao kiến thức cũng như kỹ năng trong suốt cuộc đời. Khả năng này, được
gọi là học suốt đời, được điều hòa bởi một tập hợp phong phú các cơ chế thần kinh nhận thức
cùng nhau đóng góp vào sự phát triển và chuyên môn hóa của các kỹ năng cảm giác
vận động cũng như đến quá trình củng cố và truy xuất bộ nhớ dài hạn. Do đó,
khả năng học suốt đời là rất quan trọng đối với các hệ thống tính toán
và các tác nhân tự trị tương tác trong thế giới thực và xử lý các luồng
thông tin liên tục. Tuy nhiên, học suốt đời vẫn là một thách thức lâu dài
đối với machine learning và các mô hình mạng nơ-ron vì việc thu nhận liên tục
thông tin có sẵn gia tăng từ các phân phối dữ liệu không dừng
thường dẫn đến hiện tượng quên thảm khốc hoặc can thiệp. Hạn chế này đại diện
cho một nhược điểm lớn của các mô hình mạng nơ-ron sâu tiên tiến thường
học các biểu diễn từ các lô dữ liệu huấn luyện tĩnh, do đó không
tính đến các tình huống mà thông tin trở nên có sẵn gia tăng
theo thời gian. Trong tổng quan này, chúng tôi tóm tắt một cách phản biện các thách thức chính liên quan đến
học suốt đời cho các hệ thống học tập nhân tạo và so sánh các phương pháp mạng nơ-ron
hiện có làm giảm, ở các mức độ khác nhau, hiện tượng quên thảm khốc. Mặc dù
đã có những tiến bộ đáng kể trong việc học theo lĩnh vực cụ thể với mạng
nơ-ron, cần có những nỗ lực nghiên cứu rộng rãi để phát triển học suốt đời
mạnh mẽ trên các tác nhân tự trị và robot. Chúng tôi thảo luận về nghiên cứu đã được
thiết lập và mới nổi được thúc đẩy bởi các yếu tố học suốt đời trong hệ thống sinh học
như tính dẻo cấu trúc, phát lại bộ nhớ, học chương trình và chuyển giao, động lực
nội tại, và tích hợp đa cảm giác.
Từ khóa: Học liên tục, học suốt đời, quên thảm khốc, củng cố
bộ nhớ

1 Giới thiệu
Các hệ thống tính toán hoạt động trong thế giới thực được tiếp xúc với các luồng thông tin liên tục
và do đó được yêu cầu học và ghi nhớ nhiều nhiệm vụ từ các phân phối dữ liệu động. Ví dụ,
một tác nhân tự trị tương tác với môi trường được yêu cầu học từ kinh nghiệm
riêng của mình và phải có khả năng tiến bộ thu nhận, tinh chỉnh và chuyển giao kiến thức
trong thời gian dài. Khả năng học liên tục theo thời gian bằng cách tiếp nhận kiến thức mới
trong khi giữ lại các kinh nghiệm đã học trước đó được gọi là học liên tục hoặc học suốt đời.
Một nhiệm vụ học tập liên tục như vậy đã đại diện cho một thách thức lâu dài đối với machine learning và
mạng nơ-ron và, do đó, đối với sự phát triển của các hệ thống trí tuệ nhân tạo (AI) (Hassabis
et al. 2017, Thrun & Mitchell 1995).

Vấn đề chính của các mô hình tính toán liên quan đến học suốt đời là chúng dễ bị quên thảm khốc
hoặc can thiệp thảm khốc, tức là việc huấn luyện một mô hình với thông tin mới can thiệp
với kiến thức đã học trước đó (McClelland et al. 1995, McCloskey & Cohen 1989). Hiện tượng này
thường dẫn đến sự giảm hiệu suất đột ngột hoặc, trong trường hợp tồi tệ nhất, dẫn đến việc kiến thức cũ
bị ghi đè hoàn toàn bởi kiến thức mới. Các mô hình học mạng nơ-ron sâu hiện tại
xuất sắc trong một số nhiệm vụ phân loại bằng cách dựa trên một lô lớn các mẫu huấn luyện
được chú thích (một phần) (xem Guo et al. (2016), LeCun et al. (2015) để tham khảo). Tuy nhiên, một sơ đồ học như vậy

Neural Networks (2019) https://doi.org/10.1016/j.neunet.2019.01.012.arXiv:1802.07569v4 [cs.LG] 11 Feb 2019

--- TRANG 2 ---
giả định rằng tất cả các mẫu đều có sẵn trong giai đoạn huấn luyện và, do đó, đòi hỏi việc huấn luyện lại
các tham số mạng trên toàn bộ tập dữ liệu để thích ứng với những thay đổi trong phân phối dữ liệu.
Khi được huấn luyện trên các nhiệm vụ tuần tự, hiệu suất của các mô hình mạng nơ-ron thông thường
giảm đáng kể trên các nhiệm vụ đã học trước đó khi các nhiệm vụ mới được học (Kemker et al. 2018, Maltoni &
Lomonaco 2018). Mặc dù việc huấn luyện lại từ đầu có thể giải quyết hiện tượng quên thảm khốc,
phương pháp này rất không hiệu quả và cản trở việc học dữ liệu mới trong thời gian thực. Ví dụ,
trong các tình huống học phát triển nơi các tác nhân tự trị học bằng cách tích cực tương tác với
môi trường, có thể không có sự phân biệt giữa các giai đoạn huấn luyện và kiểm tra, đòi hỏi mô hình
học phải đồng thời thích ứng và kịp thời kích hoạt các phản hồi hành vi (Cangelosi & Schlesinger
2015, Tani 2016).

Để vượt qua hiện tượng quên thảm khốc, các hệ thống học phải, một mặt, thể hiện khả năng
thu nhận kiến thức mới và tinh chỉnh kiến thức hiện có dựa trên đầu vào liên tục và, mặt khác,
ngăn chặn đầu vào mới can thiệp đáng kể với kiến thức hiện có. Mức độ mà một hệ thống
phải có tính dẻo để tích hợp thông tin mới và ổn định để
không can thiệp thảm khốc với kiến thức đã củng cố được gọi là
nghịch lý ổn định-tính dẻo và đã được nghiên cứu rộng rãi trong cả hệ thống sinh học và
mô hình tính toán (Ditzler et al. 2015, Mermillod et al. 2013, Grossberg 1980, 2012). Do các khía cạnh
rất thách thức nhưng có tác động cao của học suốt đời, một tập hợp lớn các phương pháp tính toán
đã được đề xuất lấy cảm hứng từ các yếu tố sinh học của việc học từ bộ não động vật có vú.

Con người và các động vật khác xuất sắc trong việc học theo cách suốt đời, đưa ra các quyết định thích hợp
dựa trên các liên kết cảm giác vận động đã học trong suốt cuộc đời (Tani 2016, Bremner
et al. 2012). Khả năng gia tăng thu nhận, tinh chỉnh và chuyển giao kiến thức trong
thời gian dài được điều hòa bởi một tập hợp phong phú các nguyên lý xử lý thần kinh sinh lý
cùng nhau đóng góp vào sự phát triển sớm và chuyên môn hóa theo kinh nghiệm của
các kỹ năng nhận thức và vận động (Zenke, Gerstner & Ganguli 2017, Power & Schlaggar 2016, Murray et al. 2016, Lewkowicz
2014). Trong Phần 2, chúng tôi giới thiệu một tập hợp các khía cạnh sinh học được nghiên cứu rộng rãi
của học suốt đời và ý nghĩa của chúng đối với việc mô hình hóa các kiến trúc mạng nơ-ron có động lực sinh học.
Đầu tiên, chúng tôi tập trung vào các cơ chế của tính dẻo thần kinh synap điều tiết cân bằng ổn định-tính dẻo
trong nhiều vùng não (Mục 2.2 và 2.3). Tính dẻo là một đặc điểm thiết yếu của bộ não cho
tính linh hoạt thần kinh ở mức độ tế bào và mạch (xem Power & Schlaggar (2016) một khảo sát). Đối với một
quá trình suốt đời liên tục ổn định, hai loại tính dẻo được yêu cầu: (i) Tính dẻo Hebbian (Hebb
1949) cho sự bất ổn phản hồi tích cực, và (ii) tính dẻo cân bằng nội môi bù trừ để ổn định
hoạt động thần kinh. Đã được quan sát thực nghiệm rằng các cơ chế chuyên biệt bảo vệ kiến thức
về các nhiệm vụ đã học trước đó khỏi sự can thiệp gặp phải trong quá trình học các nhiệm vụ mới bằng cách
giảm tốc độ tính dẻo synap (Cichon & Gan 2015). Cùng nhau, học Hebbian và
tính dẻo cân bằng nội môi ổn định các mạch thần kinh để hình thành các mẫu tối ưu của kết nối theo kinh nghiệm,
tích hợp và chức năng (Zenke, Gerstner & Ganguli 2017, Abraham & Robins 2005).

Quan trọng là, bộ não phải thực hiện hai nhiệm vụ bổ sung: tổng quát hóa qua các kinh nghiệm và
giữ lại các ký ức cụ thể của các sự kiện giống như tập đoạn. Trong Phần 2.4, chúng tôi tóm tắt lý thuyết
hệ thống học bổ sung (CLS) (McClelland et al. 1995, Kumaran et al. 2016) mà nắm giữ phương tiện
để hiệu quả trích xuất cấu trúc thống kê của các sự kiện được nhận thức (tổng quát hóa) trong khi giữ lại
các ký ức tập đoạn, tức là tập hợp các kinh nghiệm tại một thời gian và địa điểm cụ thể. Lý thuyết CLS
định nghĩa sự đóng góp bổ sung của hippocampus và neocortex trong học và
bộ nhớ, đề xuất rằng có các cơ chế chuyên biệt trong hệ thống nhận thức con người để
bảo vệ kiến thức đã củng cố. Hệ thống hippocampal thể hiện sự thích ứng ngắn hạn và cho phép
việc học nhanh thông tin mới mà sẽ, lần lượt, được chuyển giao và tích hợp vào
hệ thống neocortical để lưu trữ dài hạn. Neocortex được đặc trưng bởi tốc độ học chậm
và chịu trách nhiệm học các tính tổng quát. Tuy nhiên, các nghiên cứu bổ sung trong các nhiệm vụ học với
đối tượng con người (Mareschal et al. 2007, Pallier et al. 2003) quan sát thấy rằng, trong những hoàn cảnh nhất định,
hiện tượng quên thảm khốc vẫn có thể xảy ra (xem Mục 2.4).

Các nghiên cứu về các khía cạnh thần kinh sinh lý của học suốt đời đã truyền cảm hứng cho một loạt rộng rãi
các phương pháp machine learning và mạng nơ-ron. Trong Phần 3, chúng tôi giới thiệu và so sánh các phương pháp tính toán
giải quyết hiện tượng quên thảm khốc. Chúng tôi tập trung vào các mô hình học gần đây mà i) điều tiết
mức độ nội tại của tính dẻo synap để bảo vệ kiến thức đã củng cố (Mục 3.2); ii) phân bổ
các tài nguyên thần kinh bổ sung để học thông tin mới (Mục 3.3), và iii) sử dụng các hệ thống học bổ sung
để củng cố bộ nhớ và phát lại kinh nghiệm (Mục 3.4). Phần lớn các

--- TRANG 3 ---
phương pháp được thiết kế để giải quyết học có giám sát suốt đời trên các tập dữ liệu được chú thích có kích thước hữu hạn
(ví dụ, Zenke, Poole & Ganguli (2017), Kirkpatrick et al. (2017) và không mở rộng tự nhiên đến các
tình huống phức tạp hơn như xử lý các chuỗi được gán nhãn một phần. Mặt khác, học suốt đời không giám sát
đã được đề xuất chủ yếu thông qua việc sử dụng các mạng nơ-ron tự tổ chức
(ví dụ, Parisi, Tani, Weber & Wermter (2018, 2017), Richardson & Thomas (2008)). Mặc dù
đã có những tiến bộ đáng kể trong việc thiết kế các phương pháp học với chính quy hóa cấu trúc
hoặc cập nhật kiến trúc động, ít chú ý hơn đáng kể đã được dành cho việc đánh giá nghiêm ngặt
các thuật toán này trong các nhiệm vụ học suốt đời và gia tăng. Do đó, trong Mục 3.5 chúng tôi thảo luận
tầm quan trọng của việc sử dụng và thiết kế các chỉ số định lượng để đo lường hiện tượng quên thảm khốc với
các tập dữ liệu quy mô lớn.

Học suốt đời gần đây đã nhận được sự chú ý ngày càng tăng do ý nghĩa của nó trong
các tác nhân học tự trị và robot. Các phương pháp mạng nơ-ron thường được thiết kế để thích ứng gia tăng
với các mẫu dữ liệu cụ thể theo phương thức, thường là tổng hợp, được thu thập trong môi trường được kiểm soát,
được hiển thị riêng lẻ và theo thứ tự ngẫu nhiên. Điều này khác biệt đáng kể so với các điều kiện sinh thái hơn mà con người
và các động vật khác được tiếp xúc trong suốt cuộc đời (Cangelosi & Schlesinger 2015, Krueger
& Dayan 2009, Wermter et al. 2005, Skinner 1958). Các tác nhân hoạt động trong thế giới thực phải đối phó
với sự không chắc chắn cảm giác, xử lý hiệu quả các luồng thông tin đa cảm giác liên tục, và
học hiệu quả nhiều nhiệm vụ mà không can thiệp thảm khốc với kiến thức đã học
trước đó. Trực giác, có một khoảng cách lớn giữa các mô hình mạng nơ-ron được đề cập ở trên và
các tác nhân học suốt đời tinh vi hơn dự kiến sẽ học gia tăng từ các kinh nghiệm
cảm giác vận động liên tục của chúng.

Con người có thể dễ dàng thu nhận các kỹ năng mới và chuyển giao kiến thức qua các lĩnh vực và nhiệm vụ (Barnett &
Ceci 2002) trong khi các hệ thống nhân tạo vẫn còn ở giai đoạn sơ khai liên quan đến cái được gọi là
học chuyển giao (Weiss et al. 2016). Hơn nữa, và trái ngược với xu hướng chủ đạo để huấn luyện
các phương pháp mạng nơ-ron với thông tin đơn cảm giác (ví dụ, thị giác hoặc thính giác), bộ não được hưởng lợi
đáng kể từ việc tích hợp thông tin đa cảm giác, cung cấp phương tiện cho sự tương tác hiệu quả
cũng trong các tình huống không chắc chắn cảm giác (Stein et al. 2014, Bremner et al. 2012, Spence
2010). Các khía cạnh đa cảm giác của sự phát triển sớm và chuyên môn hóa cảm giác vận động trong bộ não
đã truyền cảm hứng cho một lượng lớn nghiên cứu về các tác nhân thể hiện tự trị (Lewkowicz 2014, Cangelosi
& Schlesinger 2015). Trong Phần 4, chúng tôi xem xét các phương pháp tính toán được thúc đẩy bởi các
khía cạnh sinh học của học tập bao gồm các giai đoạn phát triển quan trọng và học chương trình (Mục 4.2),
học chuyển giao để tái sử dụng kiến thức trong quá trình học các nhiệm vụ mới (Mục 4.3), học
củng cố để khám phá tự trị môi trường được thúc đẩy bởi động lực nội tại và
tự giám sát (Mục 4.4), và các hệ thống đa cảm giác cho học suốt đời đa phương thức (Mục 4.5).

Tổng quan này bổ sung cho các khảo sát trước đây về hiện tượng quên thảm khốc trong các mô hình
kết nối (French 1999, Goodfellow et al. 2013, Soltoggio et al. 2017) mà không so sánh một cách phản biện
công việc thực nghiệm gần đây (ví dụ, deep learning) hoặc định nghĩa các hướng dẫn rõ ràng về cách huấn luyện và đánh giá
các phương pháp suốt đời dựa trên các cơ chế phát triển được quan sát thực nghiệm. Cùng nhau, các tổng quan
của chúng tôi và trước đây làm nổi bật học suốt đời như một thách thức có tính liên ngành cao. Mặc dù
các ngành riêng lẻ có thể có nhiều câu hỏi mở hơn câu trả lời, sự kết hợp của những
phát hiện này có thể cung cấp một bước đột phá liên quan đến các phương pháp ad-hoc hiện tại, với mạng nơ-ron
là bước đệm hướng tới các khả năng nhận thức ngày càng tinh vi được thể hiện
bởi các hệ thống AI. Trong Phần 5, chúng tôi tóm tắt các ý tưởng chính được trình bày trong tổng quan này và cung cấp một tập hợp
các hướng nghiên cứu đang diễn ra và tương lai.

2 Các Khía Cạnh Sinh Học của Học Suốt Đời

2.1 Nghịch Lý Ổn Định-Tính Dẻo

Với tư cách là con người, chúng ta có khả năng đáng kinh ngạc để thích ứng bằng cách hiệu quả thu nhận kiến thức và kỹ năng,
tinh chỉnh chúng dựa trên các kinh nghiệm mới, và chuyển giao chúng qua nhiều lĩnh vực (Bremner
et al. 2012, Calvert et al. 2004, Barnett & Ceci 2002). Mặc dù đúng là chúng ta có xu hướng dần dần
quên thông tin đã học trước đó trong suốt cuộc đời, chỉ hiếm khi việc học
thông tin mới can thiệp thảm khốc với kiến thức đã củng cố (French 1999). Ví dụ,
vỏ não cảm giác thể của con người có thể đồng hóa thông tin mới trong các nhiệm vụ học vận động
mà không làm gián đoạn sự ổn định của các kỹ năng vận động đã thu nhận trước đó (Braun et al. 2001). Học
suốt đời trong bộ não được điều hòa bởi một tập hợp phong phú các nguyên lý thần kinh sinh lý điều tiết

--- TRANG 4 ---
cân bằng ổn định-tính dẻo của các vùng não khác nhau và đóng góp vào sự phát triển và
chuyên môn hóa của hệ thống nhận thức của chúng dựa trên các kinh nghiệm cảm giác vận động (Zenke, Gerstner
& Ganguli 2017, Power & Schlaggar 2016, Murray et al. 2016, Lewkowicz 2014). Nghịch lý ổn định-
tính dẻo liên quan đến mức độ mà một hệ thống phải có xu hướng tích hợp và thích ứng với
kiến thức mới và, quan trọng là, quá trình thích ứng này nên được bù trừ như thế nào bởi các cơ chế nội bộ
ổn định và điều chỉnh hoạt động thần kinh để ngăn chặn hiện tượng quên thảm khốc (Ditzler et al.
2015, Mermillod et al. 2013)

Tính dẻo thần kinh synap là một đặc điểm thiết yếu của bộ não tạo ra những thay đổi vật lý trong
cấu trúc thần kinh và cho phép chúng ta học, ghi nhớ và thích ứng với môi trường động (xem Power &
Schlaggar (2016) để tham khảo khảo sát). Bộ não đặc biệt có tính dẻo trong các giai đoạn quan trọng của sự phát triển sớm
trong đó các mạng thần kinh thu nhận cấu trúc toàn diện của chúng được thúc đẩy bởi các kinh nghiệm cảm giác vận động.
Tính dẻo trở nên ít nổi bật hơn khi hệ thống sinh học ổn định thông qua một tập hợp
các giai đoạn phát triển được chỉ định rõ ràng, bảo tồn một mức độ tính dẻo nhất định cho sự thích ứng và tái tổ chức
ở quy mô nhỏ hơn (Hensch et al. 1998, Quadrato et al. 2014, Kiyota 2017). Các cấu hình cụ thể
của tính dẻo trong các giai đoạn quan trọng và sau phát triển khác nhau qua các hệ thống sinh học (Uylings
2006), thể hiện một xu hướng nhất quán đến giảm mức độ tính dẻo với tuổi tăng (Hensch
2004). Tính dẻo đóng một vai trò quan trọng trong sự xuất hiện của hành vi cảm giác vận động bằng cách bổ sung
thông tin di truyền cung cấp một con đường tiến hóa cụ thể (Grossberg 2012). Gen hoặc các gradient phân tử
thúc đẩy sự phát triển ban đầu để cấp một mức hiệu suất sơ bộ từ
đầu trong khi các yếu tố bên ngoài như kinh nghiệm cảm giác hoàn thiện quá trình này để đạt được độ phức tạp cấu trúc
và hiệu suất cao hơn (Hirsch & Spinelli 1970, Shatz 1996, Sur & Leamey 2001).
Trong tổng quan này, chúng tôi tập trung vào các khía cạnh phát triển và học tập của tổ chức não bộ trong khi chúng tôi
giới thiệu người đọc đến Soltoggio et al. (2017) để tham khảo tổng quan về dấu ấn tiến hóa.

2.2 Tính Dẻo và Ổn Định Hebbian

Khả năng của bộ não thích ứng với những thay đổi trong môi trường cung cấp hiểu biết quan trọng về cách
kết nối và chức năng của vỏ não được hình thành. Đã được chỉ ra rằng trong khi các mẫu kết nối
sơ bộ trong hệ thống thị giác được thiết lập trong sự phát triển sớm, đầu vào thị giác bình thường được
yêu cầu cho sự phát triển đúng đắn của vỏ não thị giác. Công trình tinh tế của Hubel & Wiesel (1967)
về sự xuất hiện của sự chi phối mắt cho thấy tầm quan trọng của thời gian của kinh nghiệm đối với sự phát triển
của các mẫu tổ chức vỏ não bình thường. Kinh nghiệm thị giác của các chú mèo con mới sinh đã được
thao tác thực nghiệm để nghiên cứu tác động của đầu vào khác nhau đối với tổ chức não bộ. Sự
gián đoạn của tổ chức vỏ não nghiêm trọng hơn khi việc thiếu hụt đầu vào thị giác bắt đầu trước mười
tuần tuổi trong khi không quan sát thấy thay đổi nào ở động vật trưởng thành. Các thí nghiệm bổ sung cho thấy rằng
các mẫu thần kinh của tổ chức vỏ não có thể được thúc đẩy bởi các yếu tố môi trường bên ngoài ít nhất trong một
giai đoạn đầu trong sự phát triển (Hubel & Wiesel 1962, 1970, Hubel et al. 1977).

Lý thuyết nổi tiếng nhất mô tả các cơ chế của tính dẻo synap cho sự thích ứng của
các nơ-ron với kích thích bên ngoài lần đầu tiên được đề xuất bởi Hebb (1949), giả định rằng khi một nơ-ron
thúc đẩy hoạt động của một nơ-ron khác, kết nối giữa chúng được tăng cường. Cụ thể hơn,
quy tắc Hebb phát biểu rằng việc kích thích lặp đi lặp lại và liên tục của tế bào sau synap từ
tế bào trước synap dẫn đến tăng hiệu quả synap. Trong suốt quá trình phát triển,
các hệ thống thần kinh ổn định để hình thành các mẫu chức năng tối ưu của kết nối thần kinh. Dạng đơn giản nhất
của tính dẻo Hebbian xem xét một độ mạnh synap w được cập nhật bởi tích của một
hoạt động trước synap x và hoạt động sau synap y:

w = ηxy; (1)

trong đó η là tốc độ học cho trước. Tuy nhiên, tính dẻo Hebbian một mình không ổn định và dẫn đến hoạt động
thần kinh mất kiểm soát, do đó đòi hỏi các cơ chế bù trừ để ổn định quá trình học (Abbott
& Nelson 2000, Bienenstock et al. 1982). Sự ổn định trong các hệ thống Hebbian thường được đạt được bằng cách
tăng cường tính dẻo Hebbian với các ràng buộc bổ sung như giới hạn trên đối với các trọng số synap
riêng lẻ hoặc hoạt động thần kinh trung bình (Miller & MacKay 1994, Song et al. 2000). Các cơ chế cân bằng nội môi
của tính dẻo bao gồm quy mô synap và meta-tính dẻo ảnh hưởng trực tiếp đến độ mạnh synap
(Davis 2006, Turrigiano 2011). Không mất tính tổng quát, tính dẻo cân bằng nội môi có thể được
xem như một hiệu ứng điều chỉnh hoặc tín hiệu điều khiển phản hồi điều tiết động lực không ổn định của
tính dẻo Hebbian (xem Hình 1.a). Bộ điều khiển phản hồi ảnh hưởng trực tiếp đến độ mạnh synap dựa trên
hoạt động thần kinh quan sát được và phải nhanh liên quan đến thang thời gian của hệ thống không ổn định
(Åström & Murray 2010). Trong dạng đơn giản nhất, tính dẻo Hebbian được điều chỉnh có thể được mô hình hóa

--- TRANG 5 ---
Bộ điều khiển
Kích thích bên ngoài Hệ thống Tín hiệu điều khiển
Tính dẻo Quan sát a) b)
Neocortex Hippocampus Lý thuyết Hệ thống Học Bổ sung (CLS) Tính Dẻo Hebbian và Cân bằng Nội môi

Học nhanh
thông tin
tùy ý Học chậm
kiến thức
có cấu trúc

Lưu trữ,
truy xuất,
phát lại Bộ nhớ
Tập đoạn Tổng quát hóa

Hoạt động thần kinh Độ mạnh Synap Hình 1: Cái nhìn sơ đồ về hai khía cạnh của sự thích ứng thần kinh synap: a) Học Hebbian với
tính dẻo cân bằng nội môi như một cơ chế bù trừ sử dụng quan sát để tính toán tín hiệu
điều khiển phản hồi (Được điều chỉnh với sự cho phép từ Zenke, Gerstner & Ganguli (2017)). b) Lý thuyết
hệ thống học bổ sung (CLS) (McClelland et al. 1995) bao gồm hippocampus
cho việc học nhanh thông tin tập đoạn và neocortex cho việc học chậm kiến thức
có cấu trúc.

bằng cách giới thiệu một tín hiệu điều chỉnh bổ sung m vào Phương trình 1 sao cho cập nhật synap được cho bởi

w = ηmxy: (2)

Phản hồi điều chỉnh trong các mạng nơ-ron Hebbian đã nhận được sự chú ý ngày càng tăng, với các
phương pháp khác nhau đề xuất học có thể thực hiện sinh học thông qua các vòng điều chỉnh (Grant et al. 2017,
Soltoggio et al. 2017). Để tham khảo tổng quan phê phán về các khía cạnh thời gian của tính dẻo Hebbian và cân bằng nội môi,
chúng tôi giới thiệu người đọc đến Zenke, Gerstner & Ganguli (2017).

Bằng chứng về chức năng vỏ não đã cho thấy rằng hoạt động thần kinh trong nhiều vùng não kết quả từ
sự kết hợp của động lực cảm giác từ dưới lên, phản hồi từ trên xuống, và kiến thức và kỳ vọng trước
(Heeger 2017). Trong bối cảnh này, hành vi thần kinh động phức tạp có thể xuất hiện từ sự tương tác dày đặc
của các mạch thần kinh được sắp xếp theo thứ bậc theo cách tự tổ chức (Tani 2016). Tự tổ chức
được thúc đẩy bởi đầu vào đóng một vai trò quan trọng trong bộ não Nelson (2000), với các bản đồ địa hình là một
đặc điểm chung của vỏ não để xử lý đầu vào cảm giác (Willshaw & von der Malsburg 1976).
Các mô hình khác nhau của tự tổ chức thần kinh đã được đề xuất tương tự với động lực của các
phát hiện sinh học cơ bản về học và tính dẻo giống Hebbian (Kohonen 1982, Martinetz et al. 1993,
Fritzke 1992, Marsland et al. 2002), chứng minh rằng tổ chức bản đồ thần kinh kết quả từ
học thống kê không giám sát với các xấp xỉ phi tuyến của phân phối đầu vào.

Để ổn định quá trình học không giám sát, tự tổ chức mạng nơ-ron có thể được
bổ sung với phản hồi từ trên xuống như các tín hiệu liên quan đến nhiệm vụ điều chỉnh tính dẻo bản đồ
nội tại (Parisi, Tani, Weber & Wermter 2018, Soltoggio et al. 2017). Trong một chế độ xử lý phân cấp,
các detector thần kinh có trường tiếp nhận không gian-thời gian ngày càng lớn để mã hóa thông tin trên
quy mô không gian và thời gian lớn hơn (Taylor et al. 2015, Hasson et al. 2008). Do đó, các lớp cấp cao hơn
có thể cung cấp bối cảnh từ trên xuống để điều chỉnh động lực cảm giác từ dưới lên trong các lớp cấp thấp hơn.
Ví dụ, xử lý từ dưới lên chịu trách nhiệm mã hóa thống kê cùng xuất hiện của
môi trường trong khi các tín hiệu được thúc đẩy bởi lỗi điều chỉnh quá trình feedforward này theo các yếu tố
từ trên xuống, cụ thể nhiệm vụ (Murray et al. 2016). Cùng nhau, các mô hình này đóng góp vào sự hiểu biết tốt hơn
về các cơ chế thần kinh cơ bản cho sự phát triển của tổ chức vỏ não phân cấp.

2.3 Các Hệ Thống Học Bổ Sung

Bộ não học và ghi nhớ. Nhiệm vụ trước được đặc trưng bởi việc trích xuất cấu trúc
thống kê của các sự kiện được nhận thức với mục đích tổng quát hóa đến các tình huống mới. Ngược lại, nhiệm vụ sau
đòi hỏi việc thu thập các sự kiện giống như tập đoạn riêng biệt. Do đó, bộ não phải bao gồm một
cơ chế để đồng thời tổng quát hóa qua các kinh nghiệm trong khi giữ lại các ký ức tập đoạn.

--- TRANG 6 ---
Các chức năng nhận thức tinh vi dựa trên các mạch thần kinh chuẩn được nhân rộng qua nhiều vùng não
(Douglas et al. 1995). Tuy nhiên, mặc dù có các đặc tính cấu trúc chung, các vùng não khác nhau
hoạt động ở nhiều thang thời gian và tốc độ học, do đó khác biệt đáng kể với nhau theo
cách chức năng (Benna & Fusi 2016, Fusi et al. 2005). Một ví dụ nổi bật là sự đóng góp bổ sung
của neocortex và hippocampus trong học và củng cố bộ nhớ (McClelland et al. 1995, O'Reilly 2002, 2004). Lý thuyết hệ thống học bổ sung (CLS) (McClelland et al. 1995) cho rằng hệ thống hippocampal thể hiện sự thích ứng ngắn hạn và cho phép
việc học nhanh thông tin mới mà sẽ, lần lượt, được phát lại theo thời gian đến hệ thống neocortical cho việc giữ lại dài hạn (xem Hình 1.b). Cụ thể hơn, hippocampus sử dụng
tốc độ học nhanh và mã hóa các biểu diễn thưa thớt của các sự kiện để giảm thiểu sự can thiệp. Ngược lại, neocortex được đặc trưng bởi tốc độ học chậm và xây dựng các biểu diễn chồng chéo
của kiến thức đã học. Do đó, sự tương tác của chức năng hippocampal và neocortical là
quan trọng để đồng thời học các quy tắc (thống kê của môi trường) và các đặc điểm cụ thể (ký ức tập đoạn).
Cả hai vùng não đều được biết là học thông qua các cơ chế Hebbian và được thúc đẩy bởi lỗi (O'Reilly &
Rudy 2000). Trong neocortex, các tín hiệu phản hồi sẽ tạo ra các biểu diễn liên quan đến nhiệm vụ trong khi,
trong trường hợp hippocampus, điều chỉnh được thúc đẩy bởi lỗi có thể chuyển đổi chức năng của nó giữa phân biệt mẫu
và hoàn thành để nhớ lại thông tin (O'Reilly 2004).

Các nghiên cứu cho thấy rằng neurogenesis người trưởng thành đóng góp vào việc hình thành ký ức mới (Altman 1963,
Eriksson et al. 1998, Cameron et al. 1993, Gage 2000). Đã có tranh luận về việc liệu người trưởng thành
có phát triển một lượng đáng kể nơ-ron mới hay không. Nghiên cứu gần đây đã đề xuất rằng neurogenesis hippocampal
giảm mạnh ở trẻ em đến mức không thể phát hiện ở người trưởng thành (Sorrells et al. 2018). Mặt khác,
các nghiên cứu khác đề xuất rằng neurogenesis hippocampal duy trì chức năng nhận thức đặc trưng của con người
trong suốt cuộc đời (Boldrini et al. 2018). Trong quá trình neurogenesis, dentate gyrus của hippocampus
sử dụng các đơn vị thần kinh mới để nhanh chóng đồng hóa và ngay lập tức nhớ lại thông tin mới (Altman
1963, Eriksson et al. 1998). Trong quá trình hình thành ký ức ban đầu, các tế bào tiền thân thần kinh mới thể hiện
mức độ tính dẻo cao; và khi thời gian trôi qua, tính dẻo giảm để làm cho ký ức mới
ổn định hơn (Deng et al. 2010). Ngoài neurogenesis, các nghiên cứu thần kinh sinh lý chứng minh
sự đóng góp của việc kết nối lại synap bởi tính dẻo cấu trúc đối với việc hình thành ký ức ở người trưởng thành (Knoblauch
et al. 2014, Knoblauch 2017), với vai trò chính của tính dẻo cấu trúc trong việc tăng hiệu quả lưu trữ thông tin
về mặt không gian và năng lượng.

Trong khi hippocampus thường được liên kết với việc nhớ lại ngay lập tức các ký ức gần đây (tức là,
ký ức ngắn hạn), vỏ não trước trán (PFC) thường được liên kết với việc bảo tồn và
nhớ lại các ký ức xa (tức là, ký ức dài hạn; Bontempi et al. (1999)). Kitamura et al. (2017)
đã chỉ ra rằng, khi bộ não học một cái gì đó mới, hippocampus và PFC ban đầu đều được
mã hóa với ký ức tương ứng; tuy nhiên, hippocampus chủ yếu chịu trách nhiệm cho
việc nhớ lại gần đây của thông tin mới. Theo thời gian, họ đã chỉ ra rằng ký ức tương ứng được
củng cố sang PFC, mà sau đó sẽ đảm nhận trách nhiệm nhớ lại ký ức (hiện tại) xa.
Người ta tin rằng việc củng cố các ký ức gần đây thành lưu trữ dài hạn xảy ra
trong giấc ngủ REM (Taupin & Gage 2002, Gais et al. 2007).

Gần đây, lý thuyết CLS đã được cập nhật để kết hợp các phát hiện bổ sung từ neuroscience (Kumaran et al. 2016). Tập hợp phát hiện đầu tiên liên quan đến vai trò của việc phát lại các ký ức được lưu trữ trong
hippocampus như một cơ chế mà, ngoài việc tích hợp thông tin mới, cũng hỗ trợ
việc thao tác thống kê kinh nghiệm theo hướng mục tiêu (O'Neill et al. 2010). Hippocampus
nhanh chóng mã hóa các sự kiện giống như tập đoạn có thể được tái kích hoạt trong giấc ngủ hoặc nhớ lại bộ nhớ
vô thức và có ý thức (Gelbard-Sagiv et al. 2008), do đó củng cố thông tin trong neocortex
thông qua việc tái kích hoạt các kinh nghiệm được mã hóa dưới dạng nhiều lần phát lại được tạo ra nội bộ (Ratcliff
1990). Hơn nữa, bằng chứng đề xuất rằng (i) hippocampus hỗ trợ các dạng tổng quát hóa bổ sung
thông qua sự tương tác lặp của các ký ức tập đoạn (Kumaran & McClelland 2012)
và (ii) nếu thông tin mới phù hợp với kiến thức hiện có, thì việc tích hợp vào
neocortex nhanh hơn so với đề xuất ban đầu (Tse et al. 2011). Nhìn chung, lý thuyết CLS nắm giữ
phương tiện để hiệu quả tổng quát hóa qua các kinh nghiệm trong khi giữ lại các ký ức cụ thể theo cách
suốt đời. Tuy nhiên, các cơ chế thần kinh chính xác vẫn được hiểu kém.

2.4 Học mà không Quên

Các phát hiện neuroscience được mô tả trong Mục 2.3 chứng minh sự tồn tại của các cơ chế thần kinh nhận thức
chuyên biệt để thu nhận và bảo vệ kiến thức. Tuy nhiên, đã được quan sát

--- TRANG 7 ---
rằng hiện tượng quên thảm khốc có thể xảy ra trong những hoàn cảnh cụ thể. Ví dụ, Mareschal et al.
(2007) đã tìm thấy hiệu ứng can thiệp bất đối xứng trong một nhiệm vụ học phân loại tuần tự với trẻ sơ sinh
3 và 4 tháng tuổi. Các trẻ sơ sinh phải học hai loại, chó và mèo, từ một loạt hình ảnh
và sau đó phải phân biệt một động vật mới trong một nhiệm vụ nhìn ưu tiên tiếp theo. Thật
ngạc nhiên, đã quan sát thấy rằng trẻ sơ sinh có thể giữ lại loại chó chỉ khi nó được học
trước mèo. Hiệu ứng bất đối xứng này được cho là phản ánh sự tương tự tương đối của hai loại
về mặt cấu trúc nhận thức.

Các hiệu ứng can thiệp bổ sung đã được quan sát đối với kiến thức dài hạn. Pallier et al. (2003) đã nghiên cứu
khả năng nhận dạng từ của người trưởng thành sinh ra ở Hàn Quốc có môi trường ngôn ngữ chuyển
hoàn toàn từ tiếng Hàn sang tiếng Pháp sau khi được nhận nuôi giữa 3 và 8 tuổi bởi các gia đình Pháp.
Các bài kiểm tra hành vi cho thấy rằng các đối tượng không có kiến thức dư thừa về từ vựng tiếng Hàn
đã học trước đó. Dữ liệu hình ảnh não chức năng cho thấy rằng phản hồi của các đối tượng này khi nghe
tiếng Hàn không khác với phản hồi khi nghe các ngôn ngữ nước ngoài khác mà họ
đã được tiếp xúc, đề xuất rằng kiến thức trước đó của họ về tiếng Hàn đã bị ghi đè hoàn toàn.
Thú vị là, các kích hoạt não cho thấy rằng các đối tượng sinh ra ở Hàn Quốc tạo ra phản hồi yếu hơn đối với
tiếng Pháp so với người nói tiếng Pháp bản địa. Đã được giả thuyết rằng, trong khi các đối tượng được nhận nuôi
không cho thấy phản hồi mạnh đối với việc tiếp xúc thoáng qua với từ vựng tiếng Hàn, kiến thức trước
về tiếng Hàn có thể đã có tác động trong quá trình hình thành kỹ năng ngôn ngữ để tạo điều kiện cho việc
thu nhận lại ngôn ngữ Hàn Quốc nếu các cá nhân được tiếp xúc lại với nó theo cách đắm chìm.

Con người thường không thể hiện các sự kiện mạnh của hiện tượng quên thảm khốc vì loại kinh nghiệm
mà chúng ta được tiếp xúc thường rất xen kẽ (Seidenberg & Zevin 2006). Tuy nhiên,
các hiệu ứng quên có thể được quan sát khi các kinh nghiệm mới có tính đắm chìm mạnh như trong
trường hợp trẻ em chuyển đổi mạnh mẽ từ tiếng Hàn sang tiếng Pháp. Cùng nhau, những phát hiện này tiết lộ một
cân bằng được điều tiết tốt trong đó, một mặt, kiến thức đã củng cố phải được bảo vệ để đảm bảo
độ bền dài hạn và tránh can thiệp thảm khốc trong quá trình học các nhiệm vụ và
kỹ năng mới trong thời gian dài. Mặt khác, trong những hoàn cảnh nhất định như các kinh nghiệm
dài hạn đắm chìm, kiến thức cũ có thể bị ghi đè để ủng hộ việc thu nhận và tinh chỉnh
kiến thức mới.

Được kết hợp lại, các khía cạnh sinh học của học suốt đời được tóm tắt trong phần này cung cấp
hiểu biết về cách các tác nhân nhân tạo có thể ngăn chặn hiện tượng quên thảm khốc và mô hình hóa việc quên nhẹ nhàng.
Trong các phần tiếp theo, chúng tôi mô tả và so sánh một tập hợp rộng rãi các mô hình mạng nơ-ron và các phương pháp AI
đã lấy cảm hứng từ các nguyên lý như vậy. Tuy nhiên, trong trường hợp các hệ thống tính toán,
các thách thức bổ sung phải được đối mặt do những hạn chế của việc học trong các tình huống hạn chế
thường nắm bắt rất ít thành phần của sự phong phú xử lý của các hệ thống sinh học.

3 Học Suốt Đời và Quên Thảm Khốc trong Mạng Nơ-ron

3.1 Machine Learning Suốt Đời

Học suốt đời đại diện cho một thách thức lâu dài đối với machine learning và các hệ thống mạng nơ-ron
(Hassabis et al. 2017, French 1999). Điều này là do xu hướng của các mô hình học quên thảm khốc
kiến thức hiện có khi học từ các quan sát mới (Thrun & Mitchell
1995). Một hệ thống học suốt đời được định nghĩa là một thuật toán thích ứng có khả năng học từ
một luồng thông tin liên tục, với thông tin như vậy trở nên có sẵn tiến bộ theo
thời gian và nơi số lượng nhiệm vụ cần học (ví dụ, các lớp thành viên trong một nhiệm vụ phân loại)
không được xác định trước. Quan trọng là, việc tiếp nhận thông tin mới nên xảy ra mà không có hiện tượng quên
thảm khốc hoặc can thiệp.

Trong các mô hình kết nối, hiện tượng quên thảm khốc xảy ra khi các trường hợp mới cần học khác
đáng kể so với các ví dụ đã quan sát trước đó vì điều này khiến thông tin mới
ghi đè kiến thức đã học trước đó trong các tài nguyên biểu diễn được chia sẻ trong mạng nơ-ron
(French 1999, McCloskey & Cohen 1989). Khi học offline, sự mất mát kiến thức này có thể
được phục hồi vì tác nhân nhìn thấy cùng những ví dụ được xáo trộn giả ngẫu nhiên lặp đi lặp lại,
nhưng điều này không thể khi dữ liệu không thể được xáo trộn và được quan sát như một luồng liên tục. Các
hiệu ứng của hiện tượng quên thảm khốc đã được nghiên cứu rộng rãi trong hơn hai thập kỷ, đặc biệt trong các mạng
được học bằng back-propagation (Ratcliff 1990, Lewandowsky & Li 1994) và trong các mạng Hopfield
(Nadal et al. 1986, Burgess et al. 1991).

--- TRANG 8 ---
Các nỗ lực sớm để giảm thiểu hiện tượng quên thảm khốc thường bao gồm các hệ thống bộ nhớ lưu trữ
dữ liệu trước đó và thường xuyên phát lại các mẫu cũ xen kẽ với các mẫu được rút ra từ dữ liệu mới
(Robins 1993, 1995), và các phương pháp này vẫn được sử dụng ngày nay (Gepperth & Karaoguz 2015,
Rebuffi et al. 2016). Tuy nhiên, một nhược điểm chung của các hệ thống dựa trên bộ nhớ là chúng yêu cầu
lưu trữ rõ ràng thông tin cũ, dẫn đến yêu cầu bộ nhớ làm việc lớn. Hơn nữa,
trong trường hợp một lượng tài nguyên thần kinh cố định, các cơ chế chuyên biệt nên được thiết kế
bảo vệ kiến thức đã củng cố khỏi bị ghi đè bởi việc học thông tin mới (ví dụ,
Zenke, Poole & Ganguli (2017), Kirkpatrick et al. (2017)). Trực giác, hiện tượng quên thảm khốc có thể
được giảm thiểu mạnh mẽ bằng cách phân bổ các tài nguyên thần kinh bổ sung bất cứ khi nào chúng được yêu cầu (ví dụ,
Parisi, Tani, Weber & Wermter (2018, 2017), Rusu et al. (2016), Hertz et al. (1991)). Tuy nhiên, phương pháp này
có thể dẫn đến các vấn đề về khả năng mở rộng với các nỗ lực tính toán tăng đáng kể cho các
kiến trúc thần kinh trở nên rất lớn. Ngược lại, vì trong một tình huống học suốt đời số lượng
nhiệm vụ và mẫu trên mỗi nhiệm vụ không thể được biết trước, việc xác định trước một lượng
tài nguyên thần kinh đầy đủ sẽ ngăn chặn hiện tượng quên thảm khốc mà không có giả định mạnh về
phân phối của đầu vào là không tầm thường. Trong bối cảnh này, ba khía cạnh chính đã được xác định để tránh hiện tượng quên
thảm khốc trong các mô hình kết nối (Richardson & Thomas 2008): (i) phân bổ các tài nguyên thần kinh bổ sung
cho kiến thức mới; (ii) sử dụng các biểu diễn không chồng chéo nếu tài nguyên cố định; và
(iii) xen kẽ kiến thức cũ khi thông tin mới được biểu diễn.

Bộ não đã phát triển các cơ chế của tính dẻo thần kinh synap và các chức năng thần kinh nhận thức phức tạp
xử lý các luồng thông tin liên tục để đáp ứng với cả những thay đổi ngắn hạn và dài hạn trong
môi trường (Zenke, Gerstner & Ganguli 2017, Power & Schlaggar 2016, Murray et al. 2016,
Lewkowicz 2014). Do đó, sự khác biệt giữa các hệ thống sinh học và nhân tạo vượt ra ngoài
sự khác biệt về kiến trúc, và cũng bao gồm cách mà các hệ thống nhân tạo này được tiếp xúc
với kích thích bên ngoài. Kể từ khi sinh ra, con người được đắm chìm trong một thế giới có tính động cao và, để đáp ứng với
kinh nghiệm nhận thức phong phú này, các chức năng thần kinh nhận thức của chúng ta dần dần phát triển để hiểu
các sự kiện ngày càng phức tạp hơn. Trẻ sơ sinh bắt đầu với khả năng tương đối hạn chế để xử lý
các đặc điểm cấp thấp và phát triển gia tăng hướng tới việc học các chức năng nhận thức, nhận thức và hành vi
cấp cao hơn.

Con người sử dụng rất nhiều các mối quan hệ không gian-thời gian và các liên kết bậc cao ngày càng phong phú
của đầu vào cảm giác để học và kích hoạt các phản hồi hành vi có ý nghĩa. Ngược lại,
các hệ thống nhân tạo thường được huấn luyện theo lô, tiếp xúc thuật toán học với nhiều lần lặp
của cùng các mẫu huấn luyện theo thứ tự (giả-)ngẫu nhiên. Sau một số lượng cố định các epoch huấn luyện,
người ta mong đợi rằng thuật toán học đã điều chỉnh các biểu diễn nội bộ của nó và có thể dự đoán
các mẫu mới tuân theo phân phối tương tự so với tập dữ liệu huấn luyện. Rõ ràng, phương pháp này
có thể hiệu quả (và điều này được hỗ trợ bởi hiệu suất tiên tiến của các kiến trúc deep learning
cho các nhiệm vụ phân loại thị giác; xem Guo et al. (2016), LeCun et al. (2015) để tham khảo),
nhưng nó không phản ánh các đặc điểm của các nhiệm vụ học suốt đời.

Trong các phần tiếp theo, chúng tôi giới thiệu và so sánh các phương pháp mạng nơ-ron khác nhau cho học suốt đời
giảm thiểu, ở các mức độ khác nhau, hiện tượng quên thảm khốc. Về mặt khái niệm, các phương pháp này
có thể được chia thành các phương pháp huấn luyện lại toàn bộ mạng trong khi chính quy hóa để ngăn chặn hiện tượng quên
thảm khốc với các nhiệm vụ đã học trước đó (Hình 2.a; Mục 3.2), các phương pháp huấn luyện có chọn lọc
mạng và mở rộng nó nếu cần thiết để biểu diễn các nhiệm vụ mới (Hình 2.b,c; Mục 3.3), và các phương pháp
mô hình hóa các hệ thống học bổ sung để củng cố bộ nhớ, ví dụ bằng cách sử dụng phát lại bộ nhớ để
củng cố các biểu diễn nội bộ (Mục 3.4). Vì ít chú ý hơn đáng kể đã được dành cho
việc đánh giá nghiêm ngặt các thuật toán này trong các nhiệm vụ học suốt đời, trong Mục 3.5 chúng tôi làm nổi bật
tầm quan trọng của việc sử dụng và thiết kế các chỉ số mới để đo lường hiện tượng quên thảm khốc với các tập dữ liệu
quy mô lớn.

3.2 Các Phương Pháp Chính Quy Hóa

Các phương pháp chính quy hóa giảm thiểu hiện tượng quên thảm khốc bằng cách áp đặt các ràng buộc lên việc cập nhật
các trọng số thần kinh. Các phương pháp như vậy thường được lấy cảm hứng từ các mô hình neuroscience lý thuyết
đề xuất rằng kiến thức đã củng cố có thể được bảo vệ khỏi việc quên thông qua các synap với
một chuỗi các trạng thái tạo ra các mức độ tính dẻo khác nhau (Benna & Fusi 2016, Fusi et al. 2005).
Từ quan điểm tính toán, điều này thường được mô hình hóa thông qua các thuật ngữ chính quy hóa bổ sung
phạt các thay đổi trong hàm ánh xạ của một mạng nơ-ron.

--- TRANG 9 ---
Huấn luyện lại với
chính quy hóa

x(t-1)
x(t) t

x(t-1)
x(t) t

x(t-1)
x(t) t

a) Huấn luyện với mở rộng
mạng b) Huấn luyện lại mạng
có chọn lọc và mở rộng c) Hình 2: Cái nhìn sơ đồ về các phương pháp mạng nơ-ron cho học suốt đời: a) huấn luyện lại trong khi
chính quy hóa để ngăn chặn hiện tượng quên thảm khốc với các nhiệm vụ đã học trước đó, b) các tham số
không thay đổi với mở rộng mạng để biểu diễn các nhiệm vụ mới, và c) huấn luyện lại có chọn lọc với
mở rộng có thể.

Li & Hoiem (2016) đề xuất phương pháp học mà không quên (LwF) bao gồm các mạng nơ-ron
tích chập (CNN) trong đó mạng với dự đoán của các nhiệm vụ đã học trước đó
được thực thi để tương tự như mạng với nhiệm vụ hiện tại bằng cách sử dụng chưng cất kiến thức, tức là
việc chuyển giao kiến thức từ một mô hình lớn, được chính quy hóa cao thành một mô hình nhỏ hơn (Hinton
et al. 2014). Theo thuật toán LwF, cho một tập hợp các tham số được chia sẻ s qua tất cả các nhiệm vụ,
nó tối ưu hóa các tham số của nhiệm vụ mới θn cùng với θs áp đặt ràng buộc bổ sung
rằng các dự đoán trên các mẫu của nhiệm vụ mới sử dụng θs và các tham số của các nhiệm vụ cũ θo không
thay đổi đáng kể để nhớ θo. Cho dữ liệu huấn luyện trên nhiệm vụ mới (Xn, Yn),
đầu ra của các nhiệm vụ cũ cho dữ liệu mới Yo, và các tham số mới được khởi tạo ngẫu nhiên θn, các tham số được cập nhật
θ*s, θ*o, θ*n được cho bởi:

θ*s, θ*o, θ*n ← argmin θ̂s,θ̂o,θ̂n λoLold(Yo, Ŷo) + Lnew(Yn, Ŷn) + R(θ̂s, θ̂o, θ̂n) ; (3)

trong đó Lold(Yo, Ŷo) và Lnew(Yn, Ŷn) giảm thiểu sự khác biệt giữa các giá trị dự đoán Ŷ và
các giá trị ground-truth Y của các nhiệm vụ mới và cũ tương ứng sử dụng θ̂s, θ̂o, θ̂n, λo được sử dụng để cân bằng
các nhiệm vụ mới/cũ, và R là một thuật ngữ chính quy hóa để ngăn chặn overfitting. Tuy nhiên, phương pháp này có
nhược điểm phụ thuộc cao vào mức độ liên quan của các nhiệm vụ và thời gian huấn luyện cho một
nhiệm vụ tăng tuyến tính với số lượng nhiệm vụ đã học. Ngoài ra, trong khi chưng cất cung cấp
giải pháp tiềm năng cho multi-task learning, nó yêu cầu một kho dữ liệu liên tục cho mỗi nhiệm vụ đã học.
Jung et al. (2018) đề xuất chính quy hóa khoảng cách l2 giữa các kích hoạt ẩn cuối cùng,
bảo tồn các ánh xạ đầu vào-đầu ra đã học trước đó bằng cách tính toán các kích hoạt bổ sung với
các tham số của các nhiệm vụ cũ. Tuy nhiên, các phương pháp này tốn kém về mặt tính toán vì
chúng yêu cầu tính toán các tham số của nhiệm vụ cũ cho mỗi mẫu dữ liệu mới. Các phương pháp khác
chọn hoàn toàn ngăn chặn việc cập nhật các trọng số được huấn luyện trên các nhiệm vụ cũ (Razavian et al. 2014) hoặc
giảm tốc độ học để ngăn chặn những thay đổi đáng kể trong các tham số mạng trong khi
huấn luyện với dữ liệu mới (Donahue et al. 2014).

Kirkpatrick et al. (2017) đề xuất mô hình củng cố trọng số đàn hồi (EWC) trong các tình huống học có giám sát và
củng cố. Phương pháp này bao gồm một phạt bậc hai về sự khác biệt
giữa các tham số cho các nhiệm vụ cũ và mới làm chậm việc học cho các trọng số liên quan đến nhiệm vụ
mã hóa cho kiến thức đã học trước đó. Mức độ liên quan của tham số đối với
dữ liệu huấn luyện của một nhiệm vụ D được mô hình hóa như phân phối posterior p(θ|D). Giả định một tình huống với
hai nhiệm vụ độc lập A với DA và B với DB, giá trị log của xác suất posterior được cho
bởi quy tắc Bayes là:

logp(θ|D) = logp(DB|θ) + logp(θ|DA) - logp(DB); (4)

trong đó xác suất posterior log p(θ|DA) nhúng tất cả thông tin về nhiệm vụ trước đó.
Tuy nhiên, vì thuật ngữ này khó xử lý, EWC xấp xỉ nó như phân phối Gaussian với trung bình
được cho bởi các tham số θ*A và precision đường chéo được cho bởi đường chéo của ma trận thông tin
fisher F. Do đó, hàm mất mát của EWC được cho bởi

L(θ) = LB(θ) + λ/2 ∑i Fi(θi - θ*A,i)2; (5)

trong đó LB là mất mát của B, λ đặt mức độ liên quan của các nhiệm vụ cũ đối với nhiệm vụ mới, và i
biểu thị các chỉ số của các tham số. Do đó, phương pháp này yêu cầu một trọng số đường chéo trên
các tham số của các nhiệm vụ đã học tỷ lệ thuận với đường chéo của metric thông tin Fisher,
với tầm quan trọng synap được tính toán offline và hạn chế ứng dụng tính toán
của nó đến các không gian đầu ra chiều thấp. Hơn nữa, các thí nghiệm bổ sung bởi Kemker et al. (2018)
đã chỉ ra rằng, mặc dù EWC vượt trội hơn các phương pháp khác cho các nhiệm vụ hoán vị, nó không có khả năng
học các loại mới một cách gia tăng.

Zenke, Poole & Ganguli (2017) đề xuất giảm thiểu hiện tượng quên thảm khốc bằng cách cho phép các synap
riêng lẻ ước tính tầm quan trọng của chúng để giải quyết một nhiệm vụ đã học. Tương tự như Kirkpatrick et al. (2017),
phương pháp này phạt các thay đổi đối với các synap liên quan nhất để các nhiệm vụ mới có thể được học với
việc quên tối thiểu. Để giảm những thay đổi lớn trong các tham số quan trọng θk khi học một nhiệm vụ mới,
các tác giả sử dụng một hàm chi phí được sửa đổi L*n với một mất mát thay thế xấp xỉ tổng
các hàm mất mát của tất cả các nhiệm vụ trước đó L*o:

L*n = Ln + c∑k Ωnk(θk - θ*k)2; (6)

trong đó c là một tham số trọng số để cân bằng các nhiệm vụ mới và cũ, θ*k là các tham số ở cuối
nhiệm vụ trước đó, và Ωnk là một độ mạnh chính quy hóa theo tham số. Tương tự như EWC bởi Kirkpatrick
et al. (2017), phương pháp này kéo các tham số có ảnh hưởng hơn về phía một trọng số tham chiếu
với hiệu suất tốt trên các nhiệm vụ trước đó. Tuy nhiên, trong trường hợp này, mức độ liên quan synap được tính toán
theo cách trực tuyến trên toàn bộ quỹ đạo học trong không gian tham số. Hai phương pháp
đã cho thấy kết quả tương tự trên benchmark Permuted MNIST (LeCun et al. 1998).

Maltoni & Lomonaco (2018) đề xuất mô hình AR1 cho các tình huống nhiệm vụ gia tăng đơn kết hợp
các chiến lược kiến trúc và chính quy hóa. Các phương pháp chính quy hóa có xu hướng tiến bộ
giảm cường độ thay đổi trọng số theo từng lô, với hầu hết các thay đổi xảy ra
trong các lớp trên cùng. Thay vào đó, trong AR1 các trọng số lớp trung gian được điều chỉnh mà không có tác động tiêu cực
về mặt quên. Kết quả được báo cáo trên CORe50 (Lomonaco & Maltoni 2017) và iCIFAR-
100 (Krizhevsky 2009) cho thấy rằng AR1 cho phép huấn luyện các mô hình tích chập sâu với ít
quên hơn, vượt trội hơn LwF, EWC và SI.

Các phương pháp ensemble đã được đề xuất để giảm thiểu hiện tượng quên thảm khốc bằng cách huấn luyện nhiều
classifier và kết hợp chúng để tạo ra dự đoán. Các nỗ lực sớm cho thấy một nhược điểm liên quan
đến việc sử dụng bộ nhớ lưu trữ tích cực tăng theo số lượng phiên (Polikar et al.
2001, Dai et al. 2007), trong khi các phương pháp gần đây hơn hạn chế kích thước của các mô hình thông qua nhiều
chiến lược. Ví dụ, Ren et al. (2017) đề xuất thích ứng điều chỉnh với phân phối dữ liệu thay đổi
bằng cách kết hợp các mô hình con sau một giai đoạn huấn luyện mới, học các nhiệm vụ mới mà không tham chiếu
đến dữ liệu huấn luyện trước đó. Coop et al. (2013) giới thiệu một perceptron đa lớp (MLP) được
tăng cường với một lớp mở rộng cố định (FEL) nhúng một lớp ẩn mã hóa thưa thớt để giảm thiểu
sự can thiệp của các biểu diễn đã học trước đó. Các ensemble của mạng FEL được sử dụng để
điều khiển mức độ tính dẻo, tạo ra khả năng học gia tăng trong khi yêu cầu bộ nhớ lưu trữ tối thiểu.
Fernando et al. (2017) đề xuất một phương pháp ensemble trong đó một thuật toán di truyền được sử dụng
để tìm đường đi tối ưu qua một mạng nơ-ron có kích thước cố định cho việc nhân rộng và đột biến. Phương pháp này,
được gọi là PathNet, sử dụng các tác nhân được nhúng trong một mạng nơ-ron để khám phá phần nào
của mạng có thể được tái sử dụng cho việc học các nhiệm vụ mới trong khi đóng băng các đường đi liên quan đến nhiệm vụ để
tránh hiện tượng quên thảm khốc. Các tác giả của PathNet đã chỉ ra rằng việc học gia tăng các nhiệm vụ mới
tăng tốc việc huấn luyện các nhiệm vụ học có giám sát và củng cố được học tiếp theo; tuy nhiên,
họ không đo lường hiệu suất trên nhiệm vụ ban đầu để xác định liệu hiện tượng quên thảm khốc có
xảy ra hay không. Ngoài ra, PathNet yêu cầu một lớp đầu ra độc lập cho mỗi nhiệm vụ mới, điều này ngăn cản
nó học các lớp mới một cách gia tăng (Kemker et al. 2018).

Tóm lại, các phương pháp chính quy hóa cung cấp một cách để giảm thiểu hiện tượng quên thảm khốc trong những
điều kiện nhất định. Tuy nhiên, chúng bao gồm các thuật ngữ mất mát bổ sung để bảo vệ kiến thức đã củng cố
mà, với một lượng tài nguyên thần kinh hạn chế, có thể dẫn đến một sự đánh đổi về hiệu suất của
các nhiệm vụ cũ và mới.

--- TRANG 10 ---

3.3 Kiến Trúc Động

Các phương pháp được giới thiệu ở đây thay đổi các thuộc tính kiến trúc để đáp ứng với thông tin mới bằng cách
động lực tiếp nhận các tài nguyên thần kinh mới, ví dụ, huấn luyện lại với số lượng nơ-ron hoặc lớp mạng
tăng.

Ví dụ, Rusu et al. (2016) đề xuất chặn bất kỳ thay đổi nào đối với mạng được huấn luyện trên kiến thức
trước đó và mở rộng kiến trúc bằng cách phân bổ các mạng con mới với dung lượng cố định để
được huấn luyện với thông tin mới. Phương pháp này, được gọi là mạng tiến bộ, giữ lại một nhóm
các mô hình được huấn luyện trước (một cho mỗi nhiệm vụ đã học Tn). Cho N nhiệm vụ hiện có, khi một nhiệm vụ mới
TN+1 được đưa ra, một mạng nơ-ron mới được tạo ra và các kết nối bên với các nhiệm vụ hiện có
được học. Để tránh hiện tượng quên thảm khốc, các tham số đã học θn cho các nhiệm vụ hiện có Tn được giữ
không thay đổi trong khi tập tham số mới θN+1 được học cho TN+1. Các thí nghiệm đã báo cáo kết quả tốt
trên nhiều nhiệm vụ học củng cố, vượt trội hơn các phương pháp baseline phổ biến mà
huấn luyện trước hoặc tinh chỉnh gia tăng các mô hình bằng cách kết hợp kiến thức trước chỉ tại
khởi tạo. Trực giác, phương pháp này ngăn chặn hiện tượng quên thảm khốc nhưng dẫn đến sự phức tạp của
kiến trúc tăng theo số lượng nhiệm vụ đã học.

Zhou et al. (2012) đề xuất huấn luyện gia tăng của một autoencoder khử nhiễu thêm nơ-ron
cho các mẫu có mất mát cao và sau đó hợp nhất các nơ-ron này với các nơ-ron hiện có để ngăn chặn
dư thừa. Cụ thể hơn, thuật toán bao gồm hai quá trình cho (i) thêm các đặc điểm mới
để giảm thiểu phần dư của hàm mục tiêu và (ii) hợp nhất các đặc điểm tương tự để có được
biểu diễn đặc điểm compact và theo cách này ngăn chặn overfitting. Mô hình này đã được chỉ ra vượt trội hơn
các autoencoder khử nhiễu không gia tăng trong các nhiệm vụ phân loại với MNIST (LeCun et al.
1998) và các tập dữ liệu CIFAR-10 (Krizhevsky 2009). Cortes et al. (2016) đề xuất thích ứng cả
cấu trúc của mạng và các trọng số của nó bằng cách cân bằng độ phức tạp mô hình và tối thiểu hóa rủi ro thực nghiệm.
Trái ngược với việc thực thi một kiến trúc được xác định trước, thuật toán học độ phức tạp mô hình
yêu cầu theo cách thích ứng. Các tác giả đã báo cáo kết quả tốt trên một số nhiệm vụ phân loại nhị phân
được trích xuất từ tập dữ liệu CIFAR-10. Trái ngược với các phương pháp được giới thiệu trước đó
không xem xét các tình huống đa nhiệm vụ, Xiao et al. (2014) đề xuất một thuật toán huấn luyện với một
mạng tăng trưởng gia tăng về dung lượng và cũng theo cách phân cấp. Các lớp được nhóm
theo sự tương tự của chúng và tự tổ chức thành nhiều cấp độ, với các mô hình kế thừa các đặc điểm
từ các mô hình hiện có để tăng tốc việc học. Tuy nhiên, trong trường hợp này, chỉ các lớp trên cùng có thể tăng trưởng
và quy trình huấn luyện back-propagation vanilla không hiệu quả.

Draelos et al. (2017) huấn luyện gia tăng một autoencoder trên các chữ số MNIST mới sử dụng lỗi
tái tạo để chỉ ra liệu các chữ số cũ hơn có được giữ lại hay không. Mô hình học sâu neurogenesis (NDL)
của họ thêm các đơn vị thần kinh mới vào autoencoder để tạo điều kiện cho việc thêm các chữ số MNIST mới,
và nó sử dụng phát lại nội tại (một mô hình sinh để pseudo-rehearsal) để bảo tồn
các trọng số cần thiết để giữ lại thông tin cũ hơn. Yoon et al. (2018) đã đưa khái niệm này đến
paradigm học có giám sát và đề xuất một mạng mở rộng động (DEN) tăng số lượng
tham số có thể huấn luyện để học gia tăng các nhiệm vụ mới. DEN được huấn luyện theo cách trực tuyến bằng cách
thực hiện huấn luyện lại có chọn lọc mở rộng dung lượng mạng sử dụng chính quy hóa thưa thớt nhóm
để quyết định thêm bao nhiêu nơ-ron tại mỗi lớp.

Part & Lemon (2016, 2017) đề xuất sự kết hợp của một CNN được huấn luyện trước với một mạng nơ-ron
gia tăng tự tổ chức (SOINN) để tận dụng sức mạnh biểu diễn tốt
của CNN và, đồng thời, cho phép mạng phân loại tăng trưởng theo yêu cầu nhiệm vụ
trong một tình huống nhận dạng đối tượng liên tục. Một vấn đề phát sinh từ các loại
phương pháp này là khả năng mở rộng vì mạng phân loại tăng trưởng với số lượng lớp
đã được học. Một vấn đề khác được xác định thông qua phương pháp này là bằng cách dựa vào
các biểu diễn cố định, ví dụ, CNN được huấn luyện trước, sức mạnh phân biệt sẽ được điều kiện bởi
tập dữ liệu được sử dụng để huấn luyện bộ trích xuất đặc điểm. Rebuffi et al. (2016) đối phó với vấn đề này bằng cách lưu trữ
các điểm dữ liệu ví dụ được sử dụng cùng với dữ liệu mới để động lực thích ứng các trọng số của
bộ trích xuất đặc điểm, một kỹ thuật được gọi là rehearsal. Bằng cách kết hợp dữ liệu mới và cũ, họ
ngăn chặn hiện tượng quên thảm khốc nhưng với chi phí dấu chân bộ nhớ cao hơn.

Cho đến nay, chúng tôi đã xem xét các phương pháp được thiết kế cho (hoặc ít nhất được đánh giá nghiêm ngặt trên) việc phân loại
các hình ảnh tĩnh. Tuy nhiên, trong các tình huống học tự nhiên hơn, đầu vào tuần tự cơ bản
mối quan hệ không gian-thời gian như trong trường hợp video phải được tính đến. Parisi, Tani, Weber
& Wermter (2017) đã chỉ ra rằng học suốt đời các chuỗi hành động của con người có thể được đạt được dưới dạng
động lực thần kinh được thúc đẩy bởi dự đoán với các biểu diễn nội bộ xuất hiện trong một hệ thống phân cấp của
các mạng tự tổ chức lặp lại. Các mạng tự tổ chức có thể động lực phân bổ các tài nguyên thần kinh
và cập nhật các mẫu kết nối theo học Hebbian cạnh tranh. Mỗi nơ-ron
của bản đồ thần kinh bao gồm một vector trọng số wj và một số K các mô tả ngữ cảnh ck,j với
wj, ck,j ∈ Rn. Kết quả là, các nơ-ron lặp lại trong bản đồ sẽ mã hóa các ảnh chụp nhanh
chọn lọc chuỗi nguyên mẫu của đầu vào. Cho một tập hợp các nơ-ron lặp lại, N, đơn vị khớp tốt nhất (BMU) wb
đối với đầu vào x(t) ∈ Rn được tính toán như:

b = arg min j∈N (α0||x(t) - wj||2 + ∑k=1^K αk||Ck(t) - cj,k||2); (7)

trong đó {αi}i=0...K là các giá trị hằng số điều chỉnh ảnh hưởng của đầu vào hiện tại đối với
hoạt động thần kinh trước đó và Ck(t) ∈ Rn là ngữ cảnh toàn cục của mạng. Mỗi nơ-ron được
trang bị một bộ đếm habituation hi biểu thị tần suất nó đã kích hoạt dựa trên một
mô hình đơn giản hóa về cách hiệu quả của một synap habituation giảm theo thời gian. Mạng được khởi tạo
với hai nơ-ron và, tại mỗi lần lặp học, nó chèn một nơ-ron mới bất cứ khi nào hoạt động của
mạng của một nơ-ron habituated nhỏ hơn một ngưỡng cho trước. Quy tắc cập nhật thần kinh được cho bởi:

wi = εihi(x(t) - wi); (8)

trong đó εi là tốc độ học hằng số và hi hoạt động như một yếu tố điều chỉnh (xem Phương trình 2) giảm
cường độ học theo thời gian để bảo vệ kiến thức đã củng cố. Phương pháp này đã chỉ ra
kết quả cạnh tranh với các phương pháp học theo lô trên các tập dữ liệu benchmark hành động Weizmann (Gorelick et al. 2005) và
KTH (Schuldt et al. 2004). Hơn nữa, nó học các ánh xạ hành động-nhãn mạnh mẽ
cũng trong trường hợp nhãn lớp thỉnh thoảng bị thiếu hoặc bị hỏng. Parisi, Ji & Wermter
(2018) đã chỉ ra rằng các mạng tự tổ chức với neurogenesis cộng thêm cho thấy hiệu suất tốt hơn
so với một mạng tĩnh với cùng số lượng nơ-ron, do đó cung cấp hiểu biết về thiết kế
các kiến trúc thần kinh trong các tình huống học gia tăng khi tổng số nơ-ron cố định.
Các phương pháp dựa trên GWR tương tự đã được đề xuất cho việc học gia tăng các mẫu chuyển động cơ thể
(Mici et al. 2017, Elfaramawy et al. 2017, Parisi et al. 2016) và tương tác người-đối tượng
(Mici et al. 2018). Tuy nhiên, các phương pháp học không giám sát này không tính đến
các tín hiệu liên quan đến nhiệm vụ từ trên xuống có thể điều tiết cân bằng ổn định-tính dẻo, có thể dẫn đến
các vấn đề về khả năng mở rộng cho các tập dữ liệu quy mô lớn. Để giải quyết vấn đề này, các tín hiệu điều chỉnh liên quan đến nhiệm vụ
đã được mô hình hóa bởi Parisi, Tani, Weber & Wermter (2018) điều tiết quá trình neurogenesis
và cập nhật thần kinh (xem Mục 3.4). Mô hình này chia sẻ một số điểm tương đồng khái niệm với
lý thuyết cộng hưởng thích ứng (ART; xem Grossberg (2012) để tham khảo) trong đó các nơ-ron được
thích ứng lặp đi lặp lại với một phân phối đầu vào không dừng theo cách không giám sát và các nơ-ron mới có thể được
tạo ra tương ứng với dữ liệu đầu vào khác biệt. Trong mô hình ART, việc học xảy ra thông qua
sự tương tác của các quá trình từ trên xuống và từ dưới lên: các kỳ vọng từ trên xuống hoạt động như các mẫu bộ nhớ
(hoặc nguyên mẫu) được so sánh với các quan sát cảm giác từ dưới lên. Tương tự như ngưỡng kích hoạt
của GWR, mô hình ART sử dụng một tham số vigilance để tạo ra các ký ức chi tiết hoặc tổng quát hơn.
Mặc dù khả năng nội tại để giảm thiểu hiện tượng quên thảm khốc trong quá trình học gia tăng, một
đánh giá rộng rãi với các benchmark học suốt đời gần đây chưa được báo cáo cho
các nhiệm vụ học liên tục. Tuy nhiên, đã được chú ý rằng kết quả của một số biến thể của mô hình ART
phụ thuộc đáng kể vào thứ tự mà dữ liệu huấn luyện được xử lý.

Trong khi các cơ chế tạo ra các nơ-ron và kết nối mới trong GWR không giống
các cơ chế có thể thực hiện sinh học (ví dụ, Eriksson et al. (1998), Ming & Song (2011), Knoblauch
(2017)), thuật toán học GWR đại diện cho một mô hình tính toán hiệu quả gia tăng
thích ứng với đầu vào không dừng. Quan trọng là, mô hình GWR tạo ra các nơ-ron mới bất cứ khi nào chúng
được yêu cầu và chỉ sau khi huấn luyện các nơ-ron hiện có. Tốc độ cập nhật thần kinh giảm khi các nơ-ron
trở nên habituated hơn, có hiệu ứng ngăn chặn đầu vào nhiễu can thiệp với các
biểu diễn thần kinh đã củng cố. Các lý thuyết thay thế đề xuất rằng một chức năng bổ sung của neurogenesis hippocampal
là mã hóa thời gian cho việc hình thành các liên kết thời gian trong bộ nhớ (Aimone
et al. 2006, 2009), ví dụ, dưới dạng các cụm thời gian của các ký ức tập đoạn dài hạn. Mặc dù các
cơ chế cơ bản của neurogenesis và tính dẻo cấu trúc vẫn cần được điều tra thêm
trong các hệ thống sinh học, những kết quả này củng cố rằng các mô hình thần kinh tăng trưởng với tính dẻo tạo thành
sự giảm thiểu hiệu quả hiện tượng quên thảm khốc trong môi trường không dừng.

--- TRANG 12 ---

3.4 Các Hệ Thống Học Bổ Sung và Phát Lại Bộ Nhớ

Lý thuyết CLS (McClelland et al. 1995, Kumaran et al. 2016) cung cấp cơ sở cho một khung tính toán
mô hình hóa củng cố và truy xuất bộ nhớ trong đó các nhiệm vụ bổ sung của việc ghi nhớ và tổng quát hóa
được điều hòa bởi sự tương tác của hippocampus và neocortex ở động vật có vú (xem Mục 2.3). Quan trọng là,
sự tương tác của một bộ nhớ tập đoạn (kinh nghiệm cụ thể) và một bộ nhớ ngữ nghĩa (kiến thức có cấu trúc tổng quát)
cung cấp hiểu biết quan trọng về các cơ chế củng cố kiến thức trong sự vắng mặt của đầu vào cảm giác.

Các hệ thống học bộ nhớ kép đã lấy cảm hứng, ở các mức độ khác nhau, từ lý thuyết CLS
để giải quyết hiện tượng quên thảm khốc. Một ví dụ tính toán sớm của khái niệm này được đề xuất
bởi Hinton & Plaut (1987) trong đó mỗi kết nối synap có hai trọng số: một trọng số dẻo
với tốc độ thay đổi chậm lưu trữ kiến thức dài hạn và một trọng số thay đổi nhanh cho kiến thức
tạm thời. Phương pháp trọng số kép này phản ánh các thuộc tính của hệ thống học bổ sung để
giảm thiểu hiện tượng quên thảm khốc trong quá trình học nhiệm vụ tuần tự. French (1997) đã phát triển một khung
bộ nhớ kép pseudo-recurrent, một cho xử lý sớm và một cho lưu trữ dài hạn, sử dụng
pseudo-rehearsal (Robins 1995) để chuyển giao ký ức giữa các trung tâm bộ nhớ. Trong pseudo-
rehearsal, các mẫu huấn luyện không được giữ rõ ràng trong bộ nhớ mà được rút ra từ một mô hình xác suất.
Trong hai thập kỷ tiếp theo, nhiều phương pháp mạng nơ-ron dựa trên các nguyên lý CLS đã được
sử dụng để giải thích và dự đoán kết quả trong các lĩnh vực học và bộ nhớ khác nhau (xem O'Reilly (2002)
để tham khảo). Tuy nhiên, không có bằng chứng thực nghiệm nào chỉ ra rằng các phương pháp này có thể mở rộng
lên một số lượng lớn nhiệm vụ hoặc các tập dữ liệu benchmark hình ảnh và video hiện tại (xem Mục 3.5).

Gần đây hơn, Soltoggio (2015) đề xuất việc sử dụng tính dẻo ngắn hạn và dài hạn để củng cố
thông tin mới dựa trên kiểm định giả thuyết nguyên nhân-kết quả khi học với phần thưởng trì hoãn.
Trong trường hợp này, sự khác biệt giữa tính dẻo ngắn hạn và dài hạn không liên quan đến
thời gian của bộ nhớ mà là đến sự tự tin của tính nhất quán của các mối quan hệ nguyên nhân-kết quả.
Quy tắc meta-plasticity này, được gọi là tính dẻo kiểm định giả thuyết (HTP), cho thấy rằng các mối quan hệ như vậy
có thể được trích xuất từ các luồng thông tin mơ hồ, do đó hướng tới việc giải thích việc học trong
môi trường phức tạp hơn (xem Mục 4).

Gepperth & Karaoguz (2015) đề xuất hai phương pháp cho học gia tăng sử dụng (i) một bản đồ
tự tổ chức được sửa đổi (SOM) và (ii) một SOM được mở rộng với bộ nhớ ngắn hạn (STM). Chúng tôi gọi
hai phương pháp này là GeppNet và GeppNet+STM tương ứng. Trong trường hợp GeppNet, phản hồi liên quan đến nhiệm vụ
từ một lớp hồi quy được sử dụng để lựa chọn liệu việc học trong lớp ẩn tự tổ chức
có nên xảy ra hay không. Trong trường hợp GeppNet+STM, STM được sử dụng để lưu trữ kiến thức mới
thỉnh thoảng được phát lại đến lớp GeppNet trong các giai đoạn ngủ xen kẽ với
các giai đoạn huấn luyện. Phương pháp sau này mang lại hiệu suất tốt hơn và hội tụ nhanh hơn trong các nhiệm vụ học
gia tăng với tập dữ liệu MNIST. Tuy nhiên, STM có dung lượng hạn chế, do đó việc học kiến thức mới
có thể ghi đè kiến thức cũ. Trong cả hai trường hợp, quá trình học được chia thành hai giai đoạn:
một cho khởi tạo và một cho việc học gia tăng thực tế. Các thí nghiệm bổ sung cho thấy
rằng phương pháp này hoạt động kém hơn đáng kể so với EWC (Kirkpatrick et al. 2017) trên các nhiệm vụ hoán vị
khác nhau (xem Mục 3.5). Cả GeppNet và GeppNet+STM đều yêu cầu lưu trữ toàn bộ tập dữ liệu huấn luyện
trong quá trình huấn luyện.

Được lấy cảm hứng từ vai trò sinh của hippocampus để phát lại các kinh nghiệm đã mã hóa trước đó,
Shin et al. (2017) đề xuất một kiến trúc mô hình kép bao gồm một mô hình sinh sâu và một
bộ giải quyết nhiệm vụ. Theo cách này, dữ liệu huấn luyện từ các nhiệm vụ đã học trước đó có thể được lấy mẫu dưới dạng
pseudo-data được tạo ra và xen kẽ với thông tin từ các nhiệm vụ mới. Do đó, không cần thiết
phải xem xét rõ ràng các mẫu huấn luyện cũ cho phát lại kinh nghiệm, giảm yêu cầu
bộ nhớ làm việc. Phương pháp này về mặt khái niệm tương tự với các phương pháp trước đó sử dụng một phương pháp pseudo-rehearsal,
tức là xen kẽ thông tin của một nhiệm vụ mới với các mẫu được tạo ra nội bộ từ
các nhiệm vụ đã học trước đó. Robins (1995) đã chỉ ra rằng xen kẽ thông tin của các kinh nghiệm mới với
các mẫu được tạo ra nội bộ của các kinh nghiệm trước đó giúp củng cố kiến thức hiện có mà không
lưu trữ rõ ràng các mẫu huấn luyện. Pseudo-rehearsal cũng được sử dụng bởi Draelos et al. (2017) cho
việc huấn luyện gia tăng của một autoencoder, sử dụng thống kê đầu ra của encoder để tạo đầu vào
cho decoder trong quá trình phát lại. Tuy nhiên, tương tự như hầu hết các phương pháp được mô tả ở trên, việc
sử dụng các phương pháp pseudo-rehearsal được đánh giá nghiêm ngặt trên hai tập dữ liệu có độ phức tạp tương đối thấp,
ví dụ MNIST và Street View House Number (SVHN) (Netzer et al. 2011). Do đó,
câu hỏi phát sinh liệu phương pháp sinh này có thể mở rộng lên các lĩnh vực phức tạp hơn hay không.

Lüders et al. (2016) đề xuất một Neural Turing Machine có thể tiến hóa (ENTM) cho phép các tác nhân
lưu trữ ký ức dài hạn bằng cách tiến bộ phân bổ các thành phần bộ nhớ ngoài bổ sung. Cấu trúc
tối ưu cho một mạng học liên tục được tìm thấy từ một cấu hình tối thiểu ban đầu
bằng cách tiến hóa topology và trọng số mạng. Các cấu hình ENTM có thể thực hiện
việc học một lần các liên kết mới và giảm thiểu các hiệu ứng của hiện tượng quên thảm khốc trong các nhiệm vụ học
gia tăng. Một tập hợp các thí nghiệm được báo cáo trong các nhiệm vụ học củng cố cho thấy rằng bản chất
động của phương pháp ENTM sẽ khiến các tác nhân liên tục mở rộng bộ nhớ theo
thời gian. Điều này có thể dẫn đến sự mở rộng bộ nhớ không cần thiết sẽ làm chậm quá trình học
đáng kể. Một giải pháp có thể để giải quyết vấn đề này có thể là việc giới thiệu các hàm chi phí cho
việc phân bổ và sử dụng bộ nhớ hiệu quả hơn.

Lopez-Paz & Ranzato (2017) đề xuất mô hình Gradient Episodic Memory (GEM) mang lại sự chuyển giao
kiến thức tích cực đến các nhiệm vụ trước đó. Đặc điểm chính của GEM để giảm thiểu hiện tượng quên
thảm khốc là một bộ nhớ tập đoạn được sử dụng để lưu trữ một tập con các ví dụ quan sát từ một
nhiệm vụ nhất định. Trong khi giảm thiểu mất mát trên nhiệm vụ hiện tại t, GEM xử lý các mất mát trên các bộ nhớ tập đoạn
của các nhiệm vụ k < t như các ràng buộc bất đẳng thức, tránh sự tăng của chúng nhưng cho phép sự giảm của chúng.
Phương pháp này yêu cầu bộ nhớ đáng kể hơn so với các phương pháp chính quy hóa khác như
EWC (Kirkpatrick et al. 2017) tại thời gian huấn luyện (với một bộ nhớ tập đoạn Mk cho mỗi nhiệm vụ k)
nhưng có thể hoạt động tốt hơn nhiều trong setting một lượt.

Kemker & Kanan (2018) đề xuất mô hình FearNet cho học lớp gia tăng được lấy cảm hứng
từ các nghiên cứu về nhớ lại và củng cố trong bộ não động vật có vú trong quá trình điều hòa sợ hãi (Kitamura
et al. 2017). FearNet sử dụng một mạng hippocampal có khả năng ngay lập tức nhớ lại các ví dụ mới,
một mạng PFC cho ký ức dài hạn, và một mạng nơ-ron thứ ba được lấy cảm hứng từ basolateral
amygdala để xác định liệu hệ thống có nên sử dụng mạng PFC hay hippocampal cho một
ví dụ cụ thể. FearNet củng cố thông tin từ mạng hippocampal đến mạng PFC
trong các giai đoạn ngủ. Mô hình PFC của FearNet là một mạng nơ-ron sinh tạo ra
các pseudo-sample sau đó được trộn với các ví dụ quan sát gần đây được lưu trữ trong mạng hippocampal.
Kamra et al. (2018) trình bày một khung bộ nhớ kép tương tự cũng sử dụng một variational
autoencoder như một mô hình sinh cho pseudo-rehearsal. Khung của họ tạo ra một module bộ nhớ ngắn hạn
cho mỗi nhiệm vụ mới; tuy nhiên, trước khi củng cố, các dự đoán được thực hiện bằng cách sử dụng một oracle
(tức là họ biết module nào chứa bộ nhớ liên quan).

Parisi, Tani, Weber & Wermter (2018) đề xuất một kiến trúc tự tổ chức bộ nhớ kép cho
việc học các biểu diễn không gian-thời gian từ video theo cách suốt đời. Các bộ nhớ bổ sung
được mô hình hóa như các mạng nơ-ron tự tổ chức lặp lại: bộ nhớ tập đoạn nhanh chóng thích ứng
với các quan sát cảm giác mới đến thông qua Học Hebbian Cạnh tranh, trong khi bộ nhớ ngữ nghĩa
tiến bộ học các biểu diễn compact bằng cách sử dụng các tín hiệu liên quan đến nhiệm vụ để điều tiết
mức độ nội tại của tính dẻo cấu trúc. Để củng cố kiến thức trong sự vắng mặt của đầu vào cảm giác,
các quỹ đạo của các tái kích hoạt thần kinh từ bộ nhớ tập đoạn được định kỳ phát lại đến
cả hai bộ nhớ. Các thí nghiệm được báo cáo cho thấy rằng phương pháp được mô tả vượt trội đáng kể
so với các phương pháp học suốt đời được đề xuất trước đó trong ba nhiệm vụ học gia tăng khác nhau với
tập dữ liệu benchmark CORe50 (Lomonaco & Maltoni (2017); xem Mục 3.5). Vì sự phát triển
của các bản đồ thần kinh không được giám sát, phương pháp này có thể được sử dụng trong các tình huống mà các chú thích
của các mẫu huấn luyện thưa thớt.

3.5 Benchmark và Chỉ Số Đánh Giá

Mặc dù có số lượng lớn các phương pháp được đề xuất giải quyết học suốt đời, không có sự đồng thuận
được thiết lập về các tập dữ liệu benchmark và chỉ số cho việc đánh giá thích hợp của chúng. Thông thường, một
so sánh trực tiếp của các phương pháp khác nhau bị cản trở bởi các sơ đồ đánh giá rất không đồng nhất và thường
hạn chế để đánh giá hiệu suất tổng thể, mức độ quên thảm khốc và chuyển giao kiến thức.
Lopez-Paz & Ranzato (2017) định nghĩa các giao thức huấn luyện và đánh giá để đánh giá chất lượng của các
mô hình học liên tục về độ chính xác cũng như khả năng chuyển giao kiến thức giữa
các nhiệm vụ. Sự chuyển giao kiến thức có thể là tiến hoặc lùi. Cái trước đề cập đến
ảnh hưởng mà việc học một nhiệm vụ TA có đối với hiệu suất của một nhiệm vụ tương lai TB, trong khi cái sau
đề cập đến ảnh hưởng của một nhiệm vụ hiện tại TB đối với một nhiệm vụ trước đó TA. Sự chuyển giao là tích cực khi
việc học về TA cải thiện hiệu suất của một nhiệm vụ khác TB (tiến hoặc lùi) và tiêu cực
ngược lại. (Xem Mục 4.3 để giới thiệu về các mô hình học giải quyết transfer learning.)

--- TRANG 14 ---

Kemker et al. (2018) đề xuất một tập hợp các hướng dẫn để đánh giá các phương pháp học suốt đời và
thực hiện các thí nghiệm bổ sung cung cấp so sánh định lượng trực tiếp của một số
phương pháp. Các hướng dẫn như vậy bao gồm việc sử dụng ba thí nghiệm benchmark: (i) hoán vị dữ liệu,
(ii) học lớp gia tăng, và (iii) học đa phương thức. Thí nghiệm hoán vị dữ liệu
bao gồm việc huấn luyện một mô hình với một tập dữ liệu cùng với một phiên bản hoán vị của cùng tập dữ liệu,
kiểm tra khả năng của mô hình để học gia tăng thông tin mới với các biểu diễn đặc điểm tương tự.
Sau đó, người ta mong đợi rằng mô hình ngăn chặn hiện tượng quên thảm khốc với dữ liệu gốc trong
quá trình học tiếp theo các mẫu dữ liệu được hoán vị ngẫu nhiên. Trong thí nghiệm học lớp gia tăng,
hiệu suất mô hình phản ánh khả năng giữ lại thông tin đã học trước đó trong khi
học gia tăng một lớp tại một thời điểm. Cuối cùng, trong thí nghiệm học đa phương thức, cùng một
mô hình được huấn luyện tuần tự với các tập dữ liệu của các phương thức khác nhau, kiểm tra khả năng của mô hình
để học gia tăng thông tin mới với các biểu diễn đặc điểm khác biệt đáng kể (ví dụ,
đầu tiên học một tập dữ liệu phân loại hình ảnh và sau đó học một tập dữ liệu phân loại âm thanh).

Trái ngược với các tập dữ liệu thường được đề xuất trong văn học để đánh giá các phương pháp học suốt đời
(ví dụ, MNIST chứa 10 lớp chữ số với hình ảnh độ phân giải thấp; Hình 3.a), các điều kiện thí nghiệm
được đề cập ở trên được tiến hành sử dụng tập dữ liệu Caltech-UCSD Birds-200 (CUB-200)
bao gồm 200 loài chim khác nhau (Wah et al. (2011); Hình 3.b) và tập dữ liệu AudioSet, được
xây dựng từ các video YouTube với các đoạn âm thanh 10 giây từ 632 lớp và hơn 2 triệu
chú thích (Gemmeke et al. 2017). Các phương pháp được xem xét được giám sát: một MLP chuẩn
được huấn luyện trực tuyến như baseline, EWC (Kirkpatrick et al. 2017), PathNet (Fernando et al. 2017),
GeppNet và GeppNet+STM (Gepperth & Karaoguz 2015), và FEL (Coop et al. 2013).
Đối với thí nghiệm hoán vị dữ liệu, kết quả tốt nhất được thu được bởi PathNet theo sau bởi EWC, đề xuất
rằng các mô hình sử dụng các cơ chế ensembling và chính quy hóa sẽ hoạt động tốt nhất trong việc học
gia tăng các nhiệm vụ/tập dữ liệu mới với các phân phối đặc điểm tương tự. Ngược lại, EWC hoạt động
tốt hơn PathNet trên thí nghiệm đa phương thức vì EWC làm tốt hơn việc tách biệt
dữ liệu không dư thừa (tức là khác biệt). Đối với nhiệm vụ học gia tăng, kết quả tốt nhất được thu được
với sự kết hợp của rehearsal và các hệ thống bộ nhớ kép (tức là GeppNet+STM), tạo ra sự thích ứng dần dần
và củng cố kiến thức (xem Hình 4). Tuy nhiên, vì rehearsal yêu cầu lưu trữ
các ví dụ huấn luyện thô, pseudo-rehearsal có thể là một chiến lược tốt hơn cho công việc tương lai.

Lomonaco & Maltoni (2017) đề xuất CORe50, một tập dữ liệu mới cho nhận dạng đối tượng liên tục
bao gồm 50 lớp đối tượng được quan sát từ các góc độ khác nhau và bao gồm các biến đổi
trong nền, chiếu sáng, làm mờ, che khuất, tư thế và quy mô (Hình 3.c). So với các
tập dữ liệu được thảo luận ở trên, CORe50 cung cấp các mẫu được thu thập trong điều kiện thí nghiệm gần hơn
với những gì các tác nhân tự trị và robot được tiếp xúc trong thế giới thực (xem Mục 4). Cùng với
tập dữ liệu, các tác giả đề xuất ba tình huống học gia tăng: (i) các trường hợp mới (NI) nơi tất cả
các lớp được hiển thị trong lô đầu tiên trong khi các trường hợp tiếp theo của các lớp đã biết trở nên có sẵn
theo thời gian, các lớp mới (NC) nơi, cho mỗi lô tuần tự, các lớp đối tượng mới có sẵn để
mô hình phải đối phó với việc học các lớp mới mà không quên các lớp đã học trước đó, và

--- TRANG 15 ---

a) b) CUB-200 MNIST
c) CORe50

Hình 3: Ví dụ hình ảnh từ các tập dữ liệu benchmark được sử dụng để đánh giá các phương pháp học suốt đời:
a) tập dữ liệu MNIST với 10 lớp chữ số (LeCun et al. 1998), b) tập dữ liệu Caltech-UCSD
Birds-200 (CUB-200) bao gồm 200 loài chim khác nhau (Wah et al. 2011), và c)
CORe50 chứa 50 đối tượng với các biến đổi trong nền, chiếu sáng, làm mờ, che khuất,
tư thế và quy mô (được điều chỉnh với sự cho phép từ Lomonaco & Maltoni (2017)).

(iii) các trường hợp và lớp mới (NIC) nơi cả các lớp và trường hợp mới được trình bày trong mỗi
lô huấn luyện. Theo kết quả được báo cáo, EWC (Kirkpatrick et al. 2017) và LwF (Li &
Hoiem 2016) hoạt động kém hơn đáng kể trong NC và NIC so với trong NI.

Có lẽ không ngạc nhiên, hiệu suất tổng thể thường giảm khi sử dụng các tập dữ liệu có độ phức tạp cao hơn
như CUB-200 và CORe50 so với khi được kiểm tra trên MNIST. Các kết quả như vậy chỉ ra rằng học suốt đời
là một nhiệm vụ rất thách thức và, quan trọng là, hiệu suất của hầu hết các
phương pháp có thể khác biệt đáng kể theo chiến lược học cụ thể. Điều này đề xuất rằng trong khi
có một số lượng lớn các phương pháp có khả năng giảm thiểu hiện tượng quên thảm khốc trong các điều kiện thí nghiệm
được kiểm soát cao, học suốt đời chưa được giải quyết cho các tình huống phức tạp hơn.
Do đó, các nỗ lực nghiên cứu bổ sung được yêu cầu để phát triển các phương pháp mạnh mẽ và linh hoạt tuân theo
các sơ đồ đánh giá benchmark kỹ lưỡng hơn.

4 Các Phương Pháp Phát Triển và Tác Nhân Tự Trị

4.1 Hướng tới Tác Nhân Tự Trị

Con người có khả năng phi thường để học và tiến bộ tinh chỉnh các kỹ năng cảm giác vận động của họ
theo cách suốt đời (Tani 2016, Bremner et al. 2012, Calvert et al. 2004). Kể từ thời điểm

--- TRANG 16 ---

sinh ra, con người được đắm chìm trong một môi trường đa phương thức có tính động cao cung cấp một nguồn
kinh nghiệm phong phú để hình thành nhận thức, nhận thức và hành vi (Murray et al. 2016, Lewkowicz
2014). Một thành phần quan trọng của học suốt đời ở trẻ sơ sinh là khả năng tự phát của họ
tạo ra mục tiêu một cách tự trị và khám phá môi trường được thúc đẩy bởi động lực nội tại (Cangelosi & Schlesinger 2015, Gopnik et al. 1999). Do đó, khả năng học các nhiệm vụ và
kỹ năng mới một cách tự trị thông qua khám phá được thúc đẩy bởi động lực nội tại là một trong những yếu tố chính
phân biệt học suốt đời sinh học với các mô hình mạng nơ-ron liên tục hiện tại của phân loại.

Trong khi đã có tiến bộ đáng kể trong việc phát triển các mô hình giải quyết các nhiệm vụ học gia tăng
(xem Mục 3), các mô hình như vậy được thiết kế để giảm thiểu hiện tượng quên thảm khốc từ một
tập hợp các mẫu dữ liệu được chú thích. Thông thường, độ phức tạp của các tập dữ liệu được sử dụng để đánh giá
các nhiệm vụ học suốt đời rất hạn chế và không phản ánh sự phong phú và mức độ không chắc chắn của
các kích thích mà các tác nhân nhân tạo có thể được tiếp xúc trong thế giới thực. Hơn nữa, các mô hình thần kinh
thường được huấn luyện với các mẫu dữ liệu được hiển thị riêng lẻ hoặc được trình bày theo thứ tự ngẫu nhiên. Điều này
khác biệt đáng kể so với cách có tổ chức cao mà con người và động vật hiệu quả học
từ các mẫu được trình bày theo thứ tự có ý nghĩa để hình thành các khái niệm và kỹ năng ngày càng phức tạp
(Krueger & Dayan 2009, Skinner 1958). Do đó, học theo cách suốt đời vượt ra ngoài
việc tích lũy gia tăng kiến thức cụ thể theo lĩnh vực, cho phép chuyển giao kiến thức và kỹ năng
tổng quát qua nhiều nhiệm vụ và lĩnh vực (Barnett & Ceci 2002) và, quan trọng là,
hưởng lợi từ sự tương tác của thông tin đa cảm giác cho sự phát triển và chuyên môn hóa của
các chức năng thần kinh nhận thức phức tạp (Murray et al. 2016, Tani 2016, Lewkowicz 2014).

Trực giác, việc cung cấp cho một tác nhân nhân tạo tất cả kiến thức tiên quyết cần thiết
để hoạt động hiệu quả trong điều kiện thế giới thực là không thực tế (Thrun & Mitchell 1995). Do đó, các tác nhân
nhân tạo phải thể hiện một tập hợp khả năng học phong phú hơn cho phép chúng tương tác trong môi trường phức tạp
với mục đích xử lý và hiểu các luồng thông tin liên tục (thường không chắc chắn)
(Hassabis et al. 2017, Wermter et al. 2005). Trong thập kỷ qua, đã có những tiến bộ đáng kể
được thực hiện để nhúng các khía cạnh sinh học của học suốt đời vào các mô hình mạng nơ-ron. Trong
phần này, chúng tôi tóm tắt các phương pháp mạng nơ-ron được thiết lập và mới nổi được thúc đẩy bởi nghiên cứu
liên ngành giới thiệu các phát hiện từ neuroscience, tâm lý học và khoa học nhận thức
cho sự phát triển của các tác nhân học suốt đời tự trị. Chúng tôi tập trung vào thảo luận các mô hình
các giai đoạn phát triển quan trọng và học chương trình (Mục 4.2), học chuyển giao để tái sử dụng
kiến thức đã củng cố trong quá trình thu nhận các nhiệm vụ mới (Mục 4.3), khám phá tự trị và
lựa chọn mục tiêu được thúc đẩy bởi tò mò và động lực nội tại (Mục 4.4), và các khía cạnh đa phương thức của
học suốt đời cho các hệ thống đa cảm giác và tác nhân thể hiện (Mục 4.5). Đặc biệt, chúng tôi thảo luận
về cách các thành phần này (xem Hình 5) có thể được sử dụng (độc lập hoặc kết hợp) để cải thiện các
phương pháp hiện tại giải quyết học suốt đời.

4.2 Học Phát Triển và Chương Trình

Học và phát triển tương tác theo cách rất phức tạp (Elman 1993). Con người cho thấy một
khả năng đặc biệt để học trong suốt cuộc đời và, so với các loài khác, thể hiện
quá trình phát triển dài nhất để đạt đến sự trưởng thành. Có một cửa sổ thời gian hạn chế trong
phát triển mà trẻ sơ sinh đặc biệt nhạy cảm với tác động của kinh nghiệm. Giai đoạn này
thường được gọi là giai đoạn nhạy cảm hoặc giai đoạn quan trọng của phát triển (Lenneberg 1967) trong đó
các kinh nghiệm sớm đặc biệt có ảnh hưởng, đôi khi với tác động không thể đảo ngược trong hành vi (Senghas et al. 2004). Trong các giai đoạn quan trọng này, bộ não đặc biệt có tính dẻo (Hình 5.a) và các
mạng thần kinh thu nhận cấu trúc toàn diện của chúng được thúc đẩy bởi các kinh nghiệm cảm giác vận động (xem Power &
Schlaggar (2016) để tham khảo khảo sát). Sau đó, tính dẻo trở nên ít nổi bật hơn và hệ thống
ổn định, bảo tồn một mức độ tính dẻo nhất định cho sự thích ứng và tái tổ chức tiếp theo tại
quy mô nhỏ hơn (Hensch et al. 1998, Quadrato et al. 2014, Kiyota 2017).

Các cơ chế cơ bản của các giai đoạn học quan trọng đã được nghiên cứu trong các mô hình
kết nối (Thomas & Johnson 2006, Richardson & Thomas 2008), đặc biệt với việc sử dụng các hệ thống học
tự tổ chức giảm mức độ tính dẻo chức năng thông qua huấn luyện hai giai đoạn
của bản đồ thần kinh địa hình (Kohonen 1982, 1995, Miikkulainen 1997). Trong một giai đoạn tổ chức
đầu tiên, bản đồ thần kinh được huấn luyện với tốc độ học cao và kích thước lân cận không gian lớn,
cho phép mạng đạt được một tổ chức địa hình thô ban đầu. Trong một giai đoạn tinh chỉnh
thứ hai, tốc độ học và kích thước lân cận được giảm lặp đi lặp lại để tinh chỉnh. Các triển khai
kiểu này đã được sử dụng để phát triển các mô hình phát triển thị giác sớm (Miller et al. 1989),

--- TRANG 17 ---

Thời gian
Tính dẻo Độ phức tạp nhiệm vụ

Môi trường
Động lực nội tại Tác nhân
Chiến lược / lựa chọn hành động Phần thưởng bên ngoài
Phần thưởng nội bộ a) Học Phát Triển & Chương Trình

c) Tò Mò và Động Lực Nội Tại b) Học Chuyển Giao Đa Nhiệm Vụ

d) Học Đa Phương Thức Thời gian

Nhiệm vụ A
Nhiệm vụ B
Chuyển giao tiến
Chuyển giao lùi

Phương thức A Phương thức B Tích hợp
Tăng cường Hình 5: Cái nhìn sơ đồ về các thành phần chính cho sự phát triển của các tác nhân tự trị có thể
học trong thời gian dài trong môi trường phức tạp: Học phát triển và chương trình
(Mục 4.2), học chuyển giao (Mục 4.3), tò mò và động lực nội tại (Mục 4.4), và học
đa phương thức (Mục 4.5).

thu nhận ngôn ngữ (Lambon Ralph & Ehsan 2006, Li et al. 2004), và phục hồi từ chấn thương não
(Marchman 1993). Các nghiên cứu gần đây về các giai đoạn quan trọng trong mạng nơ-ron sâu cho thấy rằng giai đoạn học nhanh ban đầu
đóng một vai trò quan trọng trong việc định nghĩa hiệu suất cuối cùng của mạng (Achille
et al. 2017). Vài epoch đầu tiên của huấn luyện là quan trọng cho việc phân bổ tài nguyên qua các
lớp khác nhau được quyết định bởi phân phối đầu vào ban đầu. Sau một giai đoạn quan trọng như vậy, các tài nguyên thần kinh
được phân bổ ban đầu có thể được phân phối lại thông qua các giai đoạn học bổ sung.

Các chiến lược học phát triển đã được thử nghiệm với các tác nhân nhúng để điều tiết
sự tương tác thể hiện với môi trường trong thời gian thực (Cangelosi & Schlesinger 2015, Tani
2016). Trái ngược với các mô hình tính toán được cung cấp với lô thông tin, các tác nhân phát triển
thu nhận một tập hợp kỹ năng ngày càng phức tạp dựa trên kinh nghiệm cảm giác vận động của họ theo cách
tự trị. Do đó, sự phát triển theo giai đoạn trở nên thiết yếu để khởi động các
kỹ năng nhận thức với ít kinh nghiệm dạy kèm hơn. Tuy nhiên, việc sử dụng các chiến lược phát triển
cho các hệ thống học nhân tạo đã cho thấy là một thực tiễn rất phức tạp. Đặc biệt, khó
lựa chọn một tập hợp các giai đoạn phát triển được định nghĩa rõ ràng ủng hộ hiệu suất học tổng thể
trong môi trường có tính động cao. Ví dụ, trong khung mã hóa dự đoán (Adams et al.
2015, Rao & Ballard 1999), ý định hướng tới một mục tiêu có thể được tạo ra thông qua dự đoán
hậu quả của một hành động bằng phương tiện hồi quy lỗi với lỗi dự đoán. Việc sử dụng
các mô hình sinh, ngầm trong mã hóa dự đoán, là một thành phần được nhúng trong
khung suy luận tích cực (Friston et al. 2015). Các mô hình suy luận tích cực nhằm hiểu
cách lựa chọn dữ liệu tiết lộ tốt nhất các nguyên nhân của nó trong môi trường động và không chắc chắn thông qua
việc sử dụng song phương của hành động và nhận thức. Tuy nhiên, vẫn không rõ cách định nghĩa một cách có hệ thống
các giai đoạn phát triển dựa trên sự tương tác giữa cấu trúc bẩm sinh, thể hiện,
và suy luận (tích cực).

Con người và động vật thể hiện hiệu suất học tốt hơn khi các ví dụ được tổ chức theo cách
có ý nghĩa, ví dụ, bằng cách làm cho các nhiệm vụ học dần dần khó hơn (Krueger & Dayan 2009).
Theo quan sát này, được gọi là học chương trình, Elman (1993) đã chỉ ra rằng có
một chương trình các nhiệm vụ khó hơn dần (Hình 5.a) dẫn đến hiệu suất huấn luyện nhanh hơn trong
các hệ thống mạng nơ-ron. Điều này đã truyền cảm hứng cho các phương pháp tương tự trong robotics (Sanger 1994) và các phương pháp machine learning
gần đây hơn nghiên cứu tác động của học chương trình đối với hiệu suất của
việc học (Bengio et al. 2009, Reed & de Freitas 2015, Graves et al. 2016). Các thí nghiệm trên các tập dữ liệu

--- TRANG 18 ---

có độ phức tạp hạn chế (như MNIST) cho thấy rằng học chương trình hoạt động như huấn luyện trước không giám sát,
dẫn đến tổng quát hóa được cải thiện và tốc độ hội tụ nhanh hơn của quá trình huấn luyện
hướng tới cực tiểu toàn cục. Tuy nhiên, hiệu quả của học chương trình rất nhạy cảm
đối với phương thức tiến bộ qua các nhiệm vụ. Hơn nữa, phương pháp này giả định rằng
các nhiệm vụ có thể được sắp xếp theo một trục độ khó duy nhất. Graves et al. (2017) đề xuất xử lý
vấn đề lựa chọn nhiệm vụ như một chính sách ngẫu nhiên trên các nhiệm vụ tối đa hóa tiến bộ học, dẫn đến
hiệu quả được cải thiện trong học chương trình. Trong trường hợp này, cần thiết giới thiệu các yếu tố bổ sung
như động lực nội tại (Oudeyer et al. 2007, Barto 2013), nơi các chỉ số tiến bộ học
được sử dụng như tín hiệu phần thưởng để khuyến khích khám phá (xem Mục 4.4). Các chiến lược chương trình
có thể được xem như một trường hợp đặc biệt của học chuyển giao (Weiss et al. 2016), nơi kiến thức được thu thập
trong các nhiệm vụ ban đầu được sử dụng để hướng dẫn quá trình học của những nhiệm vụ tinh vi hơn.

4.3 Học Chuyển Giao

Học chuyển giao đề cập đến việc áp dụng kiến thức đã thu nhận trước đó trong một lĩnh vực để giải quyết một vấn đề
trong một lĩnh vực mới (Barnett & Ceci 2002, Pan & Yang 2010, Holyoak & Thagard 1997). Trong
bối cảnh này, chuyển giao tiến đề cập đến ảnh hưởng mà việc học một nhiệm vụ TA có đối với hiệu suất của một
nhiệm vụ tương lai TB, trong khi chuyển giao lùi đề cập đến ảnh hưởng của một nhiệm vụ hiện tại TB đối với một nhiệm vụ
trước đó TA (Hình 5.b). Vì lý do này, học chuyển giao đại diện cho một đặc điểm có giá trị đáng kể của
các hệ thống nhân tạo để suy luận các quy luật tổng quát từ (một lượng hạn chế) các mẫu cụ thể, giả định
sự sẵn có đồng thời của nhiều nhiệm vụ học với mục đích cải thiện hiệu suất tại
một nhiệm vụ cụ thể.

Học chuyển giao vẫn là một thách thức mở trong machine learning và các tác nhân tự trị (xem
Weiss et al. (2016) để tham khảo khảo sát). Các cơ chế thần kinh cụ thể trong bộ não điều hòa
học chuyển giao cấp cao được hiểu kém, mặc dù đã được lập luận rằng việc chuyển giao kiến thức trừu tượng
có thể được đạt được thông qua việc sử dụng các biểu diễn khái niệm mã hóa thông tin quan hệ
bất biến đối với cá nhân, đối tượng hoặc các yếu tố cảnh (Doumas et al. 2008). Học zero-shot
(Lampert et al. 2009, Palatucci et al. 2009) và học one-shot (Fei-Fei et al. 2003,
Vinyals et al. 2016) nhằm hoạt động tốt trên các nhiệm vụ mới nhưng không ngăn chặn hiện tượng quên thảm khốc
trên các nhiệm vụ đã học trước đó. Một nỗ lực sớm để thực hiện học suốt đời thông qua học chuyển giao
được đề xuất bởi Ring (1997) thông qua việc sử dụng một mạng nơ-ron phân cấp giải quyết các
nhiệm vụ học củng cố ngày càng phức tạp bằng cách gia tăng thêm các đơn vị thần kinh và mã hóa một
ngữ cảnh thời gian rộng hơn mà các hành động diễn ra.

Các phương pháp deep learning gần đây hơn đã cố gắng giải quyết học chuyển giao suốt đời trong nhiều
lĩnh vực. Rusu et al. (2017) đề xuất việc sử dụng mạng nơ-ron tiến bộ (Rusu et al. 2016)
để chuyển giao các đặc điểm cấp thấp đã học và chính sách cấp cao từ một môi trường mô phỏng sang một môi trường thực.
Nhiệm vụ bao gồm việc học các chính sách học củng cố pixel-to-action với phần thưởng thưa thớt
từ đầu vào thị giác thô đến một manipulator robot vật lý. Tessler et al. (2017) giới thiệu một
mạng học củng cố sâu phân cấp sử dụng một mảng kỹ năng và chưng cất kỹ năng để tái sử dụng và
chuyển giao kiến thức giữa các nhiệm vụ. Phương pháp này được đánh giá bằng cách dạy một tác nhân giải quyết các nhiệm vụ
trong trò chơi video Minecraft. Tuy nhiên, các mạng kỹ năng cần được huấn luyện trước và không thể được học
cùng với kiến trúc toàn diện theo cách end-to-end. Lopez-Paz & Ranzato (2017)
đề xuất mô hình Gradient Episodic Memory (GEM) giảm thiểu hiện tượng quên thảm khốc và
thực hiện chuyển giao tích cực đến các nhiệm vụ đã học trước đó. Mô hình học tập con của các mối tương quan
chung với một tập hợp các phân phối hoặc nhiệm vụ, có thể dự đoán các giá trị mục tiêu liên quan đến
các nhiệm vụ trước đó hoặc mới mà không sử dụng các bộ mô tả nhiệm vụ. Tuy nhiên, tương tự như một vấn đề được chia sẻ với hầu hết
các phương pháp được thảo luận trong Mục 3, mô hình GEM được đánh giá trên các tập dữ liệu MNIST và CIFAR100.
Do đó, câu hỏi vẫn còn liệu GEM có mở rộng lên các tình huống thực tế hơn hay không.

4.4 Tò Mò và Động Lực Nội Tại

Các mô hình tính toán của động lực nội tại đã lấy cảm hứng từ cách trẻ sơ sinh và trẻ em
lựa chọn mục tiêu và tiến bộ thu nhận kỹ năng để định nghĩa các cấu trúc phát triển trong
các khung học suốt đời (Baldassarre & Mirolli (2013); xem Gottlieb et al. (2013) để tham khảo).
Trẻ sơ sinh dường như lựa chọn các kinh nghiệm tối đa hóa phần thưởng học nội tại thông qua một
quá trình khám phá thực nghiệm (Gopnik et al. 1999). Từ quan điểm mô hình hóa, đã được đề xuất
rằng việc khám phá môi trường được thúc đẩy bởi động lực nội tại, ví dụ, được thúc đẩy bởi việc tối đa hóa
tiến bộ học (Oudeyer et al. (2007), Schmidhuber (1991), xem Hình 5.c để xem sơ đồ

--- TRANG 19 ---

cái nhìn), có thể dẫn đến sự tự tổ chức của các cấu trúc phát triển giống con người nơi các kỹ năng
được thu nhận trở nên tiến bộ phức tạp hơn.

Các mô hình tính toán của động lực nội tại có thể thu thập dữ liệu và thu nhận kỹ năng gia tăng
thông qua việc (tự-)tạo ra trực tuyến một chương trình học (Baranes & Oudeyer 2013, Forestier
& Oudeyer 2016). Điều này cho phép lựa chọn hiệu quả, ngẫu nhiên các nhiệm vụ cần học với một
kiểm soát tích cực của sự tăng trưởng của độ phức tạp. Công việc gần đây trong học củng cố đã bao gồm
các cơ chế tò mò và động lực nội tại để giải quyết các tình huống mà phần thưởng thưa thớt
hoặc lừa dối (Forestier et al. 2017, Pathak et al. 2017, Tanneberg et al. 2017, Bellemare et al. 2016,
Kulkarni et al. 2016). Trong một tình huống với phần thưởng bên ngoài rất thưa thớt, khám phá được thúc đẩy bởi tò mò
cung cấp các tín hiệu phần thưởng nội tại cho phép tác nhân học một cách tự trị và tiến bộ các nhiệm vụ
có độ phức tạp tăng. Pathak et al. (2017) đề xuất một phương pháp khám phá được thúc đẩy bởi tò mò
nơi tò mò được mô hình hóa như lỗi trong khả năng của tác nhân dự đoán hậu quả của các hành động
riêng của mình. Phương pháp này đã cho thấy mở rộng lên đầu vào thị giác chiều cao, sử dụng kiến thức
thu nhận từ các kinh nghiệm trước đó để khám phá nhanh hơn các tình huống chưa thấy. Tuy nhiên,
phương pháp này dựa trên các episode tương tác chuyển đổi các tương tác bất ngờ thành phần thưởng nội tại,
không mở rộng đến các tình huống mà tương tác hiếm. Trong trường hợp này, các biểu diễn
được tạo ra nội bộ của các tương tác thưa thớt trước đó có thể được phát lại và sử dụng để hướng dẫn khám phá
(theo cách tương tự như các hệ thống sinh cho phát lại bộ nhớ; xem Mục 3.4).

4.5 Học Đa Cảm Giác

Khả năng tích hợp thông tin đa cảm giác là một đặc điểm quan trọng của bộ não tạo ra một
sự tương tác nhất quán, mạnh mẽ và hiệu quả với môi trường (Spence 2014, Ernst & Bülthoff 2004,
Stein & Meredith 1993). Thông tin từ các phương thức cảm biến khác nhau (ví dụ thị giác, âm thanh, proprioception) có thể được tích hợp thành các biểu diễn đa cảm giác hoặc được sử dụng để tăng cường các biểu diễn đơn cảm giác
(xem Hình 5.d).

Các chức năng xử lý đa cảm giác là kết quả của sự tương tác của các thuộc tính vật lý của
các kích thích đa phương thức và kiến thức và kỳ vọng trước (ví dụ, dưới dạng các liên kết đã học), hỗ trợ
nhận thức, nhận thức và hành vi (xem Murray et al. (2016), Stein et al. (2014) để
tham khảo). Quá trình học đa cảm giác là động trong suốt cuộc đời và tuân theo cả
những thay đổi ngắn hạn và dài hạn. Nó bao gồm việc tái cân bằng động của các yếu tố ngoại sinh và nội sinh
quyết định mức độ mà nhiều phương thức tương tác với nhau. Các đặc điểm kích thích cấp thấp
(ví dụ, gần gũi không gian và trùng hợp thời gian) có sẵn trước khi hình thành
các biểu diễn nhận thức đã học liên kết các đặc điểm cấp cao ngày càng phức tạp
(ví dụ, sự phù hợp ngữ nghĩa). Các cơ chế nhận thức tinh vi của tích hợp đa cảm giác
xuất hiện trong quá trình phát triển, bắt đầu từ các khả năng xử lý cơ bản và chuyên môn hóa tiến bộ
hướng tới các chức năng nhận thức phức tạp hơn dựa trên kinh nghiệm cảm giác vận động (Lewkowicz
2014, Spence 2014).

Từ quan điểm tính toán, mô hình hóa học đa cảm giác có thể hữu ích vì một số
lý do. Đầu tiên, các chức năng đa cảm giác nhằm tạo ra các phản hồi mạnh mẽ trong trường hợp đầu vào cảm giác
không chắc chắn và mơ hồ. Các mô hình suy luận nguyên nhân đã được áp dụng cho các tình huống bao gồm
việc tiếp xúc với thông tin âm thanh-thị giác không phù hợp để giải quyết các xung đột đa cảm giác (Parisi, Barros, Kerzel, Wu, Yang, Li, Liu & Wermter 2017, Parisi, Barros, Fu, Magg., Wu, Liu & Wermter
2018). Thứ hai, nếu được huấn luyện với thông tin đa cảm giác, một phương thức có thể được tái tạo từ
thông tin có sẵn trong phương thức khác. Moon et al. (2015) đề xuất xử lý đa cảm giác
cho một nhiệm vụ nhận dạng âm thanh-thị giác trong đó kiến thức trong một phương thức nguồn có thể được chuyển giao đến
một phương thức mục tiêu. Các biểu diễn trừu tượng thu được từ một mạng mã hóa phương thức nguồn
có thể được sử dụng để tinh chỉnh mạng trong phương thức mục tiêu, do đó giảm bớt sự mất cân bằng của
dữ liệu có sẵn trong phương thức mục tiêu. Barros et al. (2017) đề xuất một kiến trúc sâu mô hình hóa
học kỳ vọng đa phương thức. Sau một giai đoạn huấn luyện với thông tin âm thanh-thị giác, các kênh mạng đơn cảm giác
có thể tái tạo đầu ra mong đợi từ phương thức khác. Cuối cùng, các cơ chế chú ý
là thiết yếu trong các tình huống học suốt đời để xử lý thông tin liên quan trong môi trường phức tạp
và hiệu quả kích hoạt hành vi hướng mục tiêu từ các luồng thông tin đa cảm giác liên tục
(Spence 2014). Các cơ chế như vậy có thể được mô hình hóa thông qua sự kết hợp của các thuộc tính ngoại sinh
của đầu vào đa phương thức, các liên kết đã học và tương ứng đa phương thức, và các kỳ vọng được tạo ra nội bộ
(Chen & Spence 2017) với mục đích liên tục hình thành nhận thức, nhận thức và hành vi trong các tác nhân tự trị.

--- TRANG 20 ---

5 Kết Luận

Học suốt đời đại diện cho một thành phần hoàn toàn thú vị nhưng thách thức của các hệ thống nhân tạo
và các tác nhân tự trị hoạt động trên dữ liệu thế giới thực, thường không dừng và
tương quan thời gian. Bộ não động vật có vú vẫn là mô hình tốt nhất của học suốt đời, điều này làm cho
các mô hình học có cảm hứng sinh học trở thành một phương pháp hấp dẫn. Khái niệm tổng quát về tính dẻo cấu trúc
(Mục 2.2) được sử dụng rộng rãi trong văn học machine learning và đại diện cho một giải pháp đầy hứa hẹn
cho học suốt đời theo đúng nghĩa của nó, ngay cả khi bỏ qua các yêu cầu sinh học. Các giải pháp tính toán
được đề xuất để giảm thiểu hiện tượng quên thảm khốc và can thiệp đã tập trung vào điều tiết mức độ nội tại
của tính dẻo để bảo vệ kiến thức đã thu nhận (Mục 3.2), phân bổ động các nơ-ron mới hoặc lớp mạng
để chứa kiến thức mới (Mục 3.3), và sử dụng các mạng học bổ sung với phát lại kinh nghiệm cho
củng cố bộ nhớ (Mục 3.4). Tuy nhiên, mặc dù có những tiến bộ đáng kể, các mô hình học suốt đời hiện tại
vẫn còn xa so với việc cung cấp tính linh hoạt, mạnh mẽ và khả năng mở rộng được thể hiện bởi các hệ thống sinh học.
Các mô hình học sâu và nông phổ biến nhất của học suốt đời bị hạn chế trong lĩnh vực có giám sát,
dựa trên lượng lớn dữ liệu được chú thích thu thập trong môi trường được kiểm soát (xem Mục 3.5). Một
sơ đồ huấn luyện cụ thể theo lĩnh vực như vậy không thể được áp dụng trực tiếp cho các tác nhân tự trị hoạt động trong
môi trường có tính động cao, không có cấu trúc.

Các nỗ lực nghiên cứu bổ sung được yêu cầu để kết hợp nhiều phương pháp tích hợp nhiều
yếu tố quan sát được ở người học. Các cơ chế cơ bản của các giai đoạn quan trọng của phát triển (Mục
4.2) có thể được mô hình hóa để xác định thực nghiệm các kiến trúc mạng nơ-ron (đa lớp) thuận tiện
và các mẫu kết nối ban đầu cải thiện hiệu suất của mô hình cho các nhiệm vụ học tiếp theo.
Các phương pháp bao gồm học chương trình và chuyển giao (Mục 4.3) là một đặc điểm cơ bản
để tái sử dụng kiến thức và kỹ năng đã thu nhận trước đó để giải quyết một vấn đề trong một lĩnh vực mới
bằng cách chia sẻ các biểu diễn cấp thấp và cấp cao. Đối với các tác nhân học một cách tự trị, các phương pháp sử dụng
động lực nội tại (Mục 4.4) là quan trọng cho việc tự tạo ra mục tiêu, dẫn đến một quá trình khám phá
thực nghiệm và thu nhận tiến bộ các kỹ năng ngày càng phức tạp. Cuối cùng, tích hợp đa cảm giác
(Mục 4.5) là một đặc điểm quan trọng của các tác nhân tự trị hoạt động trong môi trường có tính động cao
và ồn ào, dẫn đến học và hành vi mạnh mẽ cũng trong các tình huống không chắc chắn.

Lời Cảm Ơn

Nghiên cứu này được hỗ trợ một phần bởi Quỹ Nghiên cứu Đức (DFG) trong dự án
Transregio Crossmodal Learning (TRR 169). Các tác giả muốn cảm ơn Sascha Griffiths,
Vincenzo Lomonaco, Sebastian Risi, và Jun Tani vì phản hồi và đề xuất có giá trị.

Tài Liệu Tham Khảo

Abbott, L. F. & Nelson, S. B. (2000), 'Synaptic plasticity: taming the beast', Nature Neuroscience
3, 1178–1183.

Abraham, W. C. & Robins, A. (2005), 'Memory retention and weight plasticity in ANN simulations',
Trends in Neurosciences 28(2), 73–78.

Achille, A., Rovere, M. & Soatto, S. (2017), Critical learning periods in deep neural networks,
arXiv:1711.08856.

Adams, R. A., Friston, K. J. & Bastos, A. M. (2015), 'Active inference, predictive coding and
cortical architecture', In M. F. Casanova and I. Opris (Eds.), Recent Advances on the Modular
Organization of the Cortex. Springer Netherlands.

Aimone, J. B., Wiles, J. & Gage, F. H. (2006), 'Potential role for adult neurogenesis in the encoding
of time in new memories.', Nature Neuroscience 9, 723–727.

Aimone, J. B., Wiles, J. & Gage, F. H. (2009), 'Computational influence of adult neurogenesis on
memory encoding.', Neuron 61, 187–202.

Altman, J. (1963), 'Autoradiographic investigation of cell proliferation in the brains of rats and cats',
The Anatomical Record 145(4), 573–591.

Åström, K. J. & Murray, R. M. (2010), Feedback Systems: An Introduction for Scientists and Engineers, Princeton University Press.

--- TRANG 21 ---

Baldassarre, G. & Mirolli, M. (2013), Intrinsically motivated learning in natural and artificial systems, Springer-Verlag, Berlin.

Baranes, A. & Oudeyer, P.-Y. (2013), 'Active learning of inverse models with intrinsically motivated goal exploration in robots', Robotics and Autonomous Systems 61(1), 49–73.

Barnett, S. & Ceci, S. (2002), 'When and where do we apply what we learn? a taxonomy for far transfer', Psychological Bulletin 128, 612–637.

Barros, P., Parisi, G. I., Fu, D., Liu, X. & Wermter, S. (2017), Expectation learning for adaptive crossmodal stimuli association, EUCog Meeting Proceedings, Zurich, Switzerland.

Barto, A. (2013), Intrinsic motivation and reinforcement learning, Baldassarre, G., Mirolli, M. (Eds.), Intrinsically Motivated Learning in Natural and Artificial Systems. Springer.

Bellemare, M., Srinivasan, S., Ostrovski, G., Schaul, T., Saxton, D. & Munos, R. (2016), Unifying count-based exploration and intrinsic motivation.

Bengio, Y., Louradour, J., Collobert, R. & Weston, J. (2009), Curriculum learning, pp. 41–48.

Benna, M. K. & Fusi, S. (2016), 'Computational principles of synaptic memory consolidation', Nature Neuroscience 19(12), 1697–1708.

Bienenstock, E., Cooper, L. & Munro, P. (1982), 'Theory for the development of neuron selectivity: orientation specificity and binocular interaction in visual cortex', The Journal of Neuroscience 2, 32–48.

Boldrini, M., Fulmore, C., Tartt, A., Simeon, L. & Pavlova, I. e. a. (2018), 'Human hippocampal neurogenesis persists throughout aging', Cell Stem Cell 22(4), 589–599.

Bontempi, B., Laurent-Demir, C., Destrade, C. & Jaffard, R. (1999), 'Time-dependent reorganization of brain circuitry underlying long-term memory storage', Nature 400, 671–675.

Braun, C., Heinz, U., Schweizer, R., Weich, K., Birbaumer, N. & Topka, H. (2001), 'Dynamic organization of the somato-sensory cortex induced by motor activity', Brain 124, 2259–2267.

Bremner, A., Lewkowicz, D. & Spence, C. (2012), 'Multisensory development', Oxford University Press, Oxford, UK.

Burgess, N., Shapiro, J. L. & Moore, M. A. (1991), 'Neural network models of list learning', Networks 2, 399–422.

Calvert, G., Spence, C. & Stein, B. (2004), The Handbook of Multisensory Processes, Cambridge, MA: The MIT Press.

Cameron, H. A., Woolley, C. S., McEwen, B. S. & Gould, E. (1993), 'Differentiation of newly born neurons and glia in the dentate gyrus of the adult rat', Neuroscience 56(2), 337–344.

Cangelosi, A. & Schlesinger, M. (2015), Developmental robotics: From babies to robots, MIT Press.

Chen, Y.-C. & Spence, C. (2017), 'Assessing the role of the unity assumption on multisensory integration: A review', Frontiers in Psychology 8(445).

Cichon, J. & Gan, W. (2015), 'Branch-specific dendritic ca(2+) spikes cause persistent synaptic plasticity', Nature 520, 180–185.

Coop, R., Mishtal, A. & Arel, I. (2013), 'Ensemble learning in fixed expansion layer networks for mitigating catastrophic forgetting', IEEE Transactions on Neural Networks and Learning Systems 24(10), 1623–1634.

Cortes, C., Gonzalvo, X., Kuznetsov, V., Mohri, M. & Yang, S. (2016), AdaNet: Adaptive structural learning of artificial neural networks, arXiv:1607.01097.

Dai, W., Yang, Q., Xue, G.-R. & Yu, Y. (2007), Boosting for transfer learning, ICML'17, Sydney, Australia, pp. 193–200.

Davis, G. W. (2006), 'Homeostatic control of neural activity: from phenomenology to molecular design', Annual Review of Neuroscience 29, 307–323.

Deng, W., Aimone, J. B. & Gage, F. H. (2010), 'New neurons and new memories: how does adult hippocampal neurogenesis affect learning and memory?', Nature Reviews Neuroscience 11(5), 339–350.

Ditzler, G., Roveri, M., Alippi, C. & Polikar, R. (2015), 'Learning in nonstationary environments: A survey', IEEE Computational Intelligence Magazine 10(4), 12–25.

--- TRANG 22 ---

Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E. & Darrell, T. (2014), Decaf: A deep convolutional activation feature for generic visual recognition, ICML'14, Beijing, China.

Douglas, R. J., Koch, C., Mahowald, M., Martin, K. A. & Suarez, H. H. (1995), 'Recurrent excitation in neocortical circuits', Science 269, 981–985.

Doumas, L., Hummel, J. & Sandhofer, C. (2008), 'A theory of the discovery and predication of relational concepts', Psychological Review 115, 1–43.

Draelos, T. J., Miner, N. E., Lamb, C. C., Vineyard, C. M., Carlson, K. D., James, C. D. & Aimone, J. B. (2017), Neurogenesis deep learning, IJCNN'17, Anchorage, Alaska, pp. 526–533.

Elfaramawy, N., Barros, P., Parisi, G. I. & Wermter, S. (2017), Emotion recognition from body expressions with a neural network architecture, Proceedings of the International Conference on Human Agent Interaction (HAI'17), Bielefeld, Germany, pp. 143–149.

Elman, J. L. (1993), 'Learning and development in neural networks: The importance of starting small', Cognition 48(1), 71–99.

Eriksson, P. S., Perfilieva, E., Bjork-Eriksson, T., Alborn, A.-M., Nordborg, C., Peterson, D. A. & Gage, F. H. (1998), 'Neurogenesis in the adult human hippocampus', Nature medicine 4(11), 1313–1317.

Ernst, M. O. & Bülthoff, H. (2004), 'Merging the senses into a robust percept', Trends in Cognitive Sciences 8(4), 162–169.

Fei-Fei, L., Fergus, R. & Perona, P. (2003), A bayesian approach to unsupervised one-shot learning of object categories, ICCV'03, Nice, France.

Fernando, C., Banarse, D., Blundell, C., Zwols, Y., Ha, D., Rusu, A. A., Pritzel, A. & Wierstra, D. (2017), Pathnet: Evolution channels gradient descent in super neural networks, arXiv:1701.08734.

Forestier, S., Mollard, Y. & Oudeyer, P.-Y. (2017), Intrinsically motivated goal exploration processes with automatic curriculum learning, arXiv:1708.02190.

Forestier, S. & Oudeyer, P.-Y. (2016), Curiosity-driven development of tool use precursors: a computational model, Proceedings of the Annual Conference of the Cognitive Science Society.

French, R. M. (1997), 'Pseudo-recurrent connectionist networks: An approach to the sensitivity-stability dilemma', Connection Science 9(4), 353–380.

French, R. M. (1999), 'Catastrophic forgetting in connectionist networks', Trends in Cognitive Sciences 3(4), 128–135.

Friston, K., Rigoli, F., Ognibene, D., Mathys, D., Fitzgerald, T. & Pezzulo, G. (2015), 'Active inference and epistemic value', Cognitive neuroscience 6, 187–214.

Fritzke, B. (1992), A growing neural gas network learns topologies, Vol. 7, NIPS'95, Denver, CO, pp. 625–632.

Fusi, S., Drew, P. J. & Abbott, L. F. (2005), 'Cascade models of synaptically stored memories', Neuron 45(4), 599–611.

Gage, F. H. (2000), 'Mammalian neural stem cells', Science 287, 1433–1438.

Gais, S., Albouy, G., Boly, M., Dang-Vu, T. T., Darsaud, A., Desseilles, M., Rauchs, G., Schabus, M., Sterpenich, V. & Vandewalle, G. e. a. (2007), 'Sleep transforms the cerebral trace of declarative memories', Proceedings of the National Academy of Sciences 104(47), 18778–18783.

Gelbard-Sagiv, H., Mukamel, R., Harel, M., Malach, R. & Fried, I. (2008), 'Internally generated reactivation of single neurons in human hippocampus during free recall', Science 322, 96–101.

Gemmeke, J. F., Ellis, D. P. W., Freedman, D., Jansen, A., Lawrence, W., Moore, R. C., Plakal, M. & Ritter, M. (2017), Audio set: An ontology and human-labeled dataset for audio events, ICASSP'17, New Orleans, LA.

Gepperth, A. & Karaoguz, C. (2015), 'A bio-inspired incremental learning architecture for applied perceptual problems', Cognitive Computation 8(5), 924–934.

Goodfellow, I. J., Mirza, M., Xiao, D., Courville, A. & Bengio, Y. (2013), An empirical investigation of catastrophic forgetting in gradient-based neural networks, arXiv:1312.6211.

--- TRANG 23 ---

Gopnik, A., Meltzoff, A. N. & Kuhl, P. K. (1999), The scientist in the crib: Minds, brains, and how children learn, William Morrow & Co.

Gorelick, L., Blank, M., Shechtman, E., Irani, M. & Basri, R. (2005), Actions as space-time shapes, ICCV'05, Beijing, China, pp. 1395–1402.

Gottlieb, J., Oudeyer, P.-Y., Lopes, M. & Baranes, A. (2013), 'Information seeking, curiosity and attention: Computational and neural mechanisms', Trends in Cognitive Science 17(11), 585–596.

Grant, W. S., Tanner, J. & Itti, L. (2017), 'Biologically plausible learning in neural networks with modulatory feedback', Neural Networks 88, 32–48.

Graves, A., Bellemare, M. G., Menick, J., Munos, R. & Kavukcuoglu, K. (2017), Automated curriculum learning for neural networks, arXiv:1704.03003.

Graves, A., Wayne, G., Reynolds, M., Harley, T., Danihelka, I., Grabska-Barwinska, A., Colmenarejo, S. G., Grefenstette, E., Ramalho, T. & Agapiou, J. e. a. (2016), 'Hybrid computing using a neural network with dynamic external memory', Nature 538, 471–476.

Grossberg, S. (1980), 'How does a brain build a cognitive code?', Psychol. Rev. 87, 1–51.

Grossberg, S. (2012), 'Adaptive resonance theory: how a brain learns to consciously attend, learn, and recognize a changing world.', Neural Networks 37, 1–41.

Guo, Y., Liu, Y., Oerlemans, A., Lao, S., Wu, S. & Lew, M. (2016), 'Deep learning for visual understanding: A review', Neurocomputing 187(8), 27–48.

Hassabis, D., Kumaran, D., Summerfield, C. & Botvinick, M. (2017), 'Neuroscience-inspired artificial intelligence', Neuron Review 95(2), 245–258.

Hasson, U., Yang, E., Vallines, I., Heeger, D. J. & Rubin, N. (2008), 'A hierarchy of temporal receptive windows in human cortex', The Journal of Neuroscience 28(10), 2539–2550.

Hebb, D. (1949), The Organization of Behavior, John Wiley & Sons.

Heeger, D. J. (2017), 'Theory of cortical function', Proceedings of the National Academy of Sciences of the United States of America 114(8), 1773–1782.

Hensch, T. (2004), 'Critical period regulation', Annual Review of Neuroscience 27, 549–579.

Hensch, T. K., Fagiolini, M., Mataga, N., Stryker, M. P., Baekkeskov, S. & Kash, S. F. (1998), 'Local gaba circuit control of experience-dependent plasticity in developing visual cortex', Science 282, 1504–1508.

Hertz, J., Krogh, A. & Palmer, R. G. (1991), Introduction to the Theory of Neural Computation, Redwood City CA: Addison-Wesley.

Hinton, G. E. & Plaut, D. C. (1987), Using fast weights to deblur old memories, Proceedings of the Annual Conference of the Cognitive Science Society, pp. 177–186.

Hinton, G., Vinyals, O. & Dean, J. (2014), Distilling the knowledge in a neural network, NIPS'14, Workshop on Deep Learning and Representation, Montreal, Canada.

Hirsch, H. & Spinelli, D. (1970), 'Visual experience modifies distribution of horizontally and vertically oriented receptive fields in cats', Science 168, 869–871.

Holyoak, K. & Thagard, P. (1997), 'The analogical mind', American Psychologist 52, 35–44.

Hubel, D. H. & Wiesel, T. H. (1962), 'Receptive fields, binocular and functional architecture in the cats visual cortex', Journal of Physiology 160, 106–154.

Hubel, D. H. & Wiesel, T. H. (1967), 'Cortical and callosal connections concerned with the vertical meridian of visual fields in the cat', Journal of Neurophysiology 30, 1561–1573.

Hubel, D. H. & Wiesel, T. H. (1970), 'The period of susceptibility to the psychological effects of unilateral eye closure in kittens', Journal of Physiology 206, 419–436.

Hubel, D. H., Wiesel, T. H. & LeVay, S. (1977), 'Plasticity of ocular dominance columns in monkey striate cortex', Philosophical Transactions of the Royal Society of London, Series B: Biological Sciences 278, 377–409.

Jung, H., Ju, J., Jung, M. & Kim, J. (2018), Less-forgetting learning in deep neural networks, AAAI'18, New Orleans, LA.

Kamra, N., Gupta, U. & Liu, Y. (2018), Deep generative dual memory network for continual learning, arXiv:1710.10368.

--- TRANG 24 ---

Kemker, R. & Kanan, C. (2018), Fearnet: Brain-inspired model for incremental learning, ICLR'18, Vancouver, Canada.

Kemker, R., McClure, M., Abitino, A., Hayes, T. & Kanan, C. (2018), Measuring catastrophic forgetting in neural networks, AAAI'18, New Orleans, LA.

Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A. A., Milan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., Hassabis, D., Clopath, C., Kumaran, D. & Hadsell, R. (2017), 'Overcoming catastrophic forgetting in neural networks', Proceedings of the National Academy of Sciences 114(13), 3521–3526.

Kitamura, T., Ogawa, S. K., Roy, D. S., Okuyama, T., Morrissey, M. D., Smith, L. M., Redondo, R. L. & Tonegawa, S. (2017), 'Engrams and circuits crucial for systems consolidation of a memory', Science 356, 73–78.

Kiyota, T. (2017), Neurogenesis and brain repair, Neuroimmune Pharmacology. Springer.

Knoblauch, A. (2017), Impact of structural plasticity on memory formation and decline, Rewiring the Brain: A Computational Approach to Structural Plasticity in the Adult Brain, eds A. van Ooyen and M. Butz, Elsevier, Academic Press.

Knoblauch, A., Körner, E., Krner, U. & Sommer, F. T. (2014), 'Structural plasticity has high memory capacity and can explain graded amnesia, catastrophic forgetting, and the spacing effect.', PLoS ONE 9:e96485.

Kohonen, T. (1982), 'Self-organized formation of topologically correct feature maps', Biological Cybernetics 43, 59–69.

Kohonen, T. (1995), Self-organizing maps, New York: Springer.

Krizhevsky, A. (2009), Learning multiple layers of features from tiny images, Master's thesis, University of Toronto.

Krueger, K. A. & Dayan, P. (2009), 'Flexible shaping: how learning in small steps helps', Cognition 110, 380–394.

Kulkarni, T., Narasimhan, K., Saeedi, A. & Tenenbaum, J. (2016), Hierarchical deep reinforcement learning: integrating temporal abstraction and intrinsic motivation, arXiv:1604.06057.

Kumaran, D., Hassabis, D. & McClelland, J. L. (2016), 'What learning systems do intelligent agents need? complementary learning systems theory updated', Trends in Cognitive Sciences 20(7), 512–534.

Kumaran, D. & McClelland, J. L. (2012), 'Generalization through the recurrent interaction of episodic memories: A model of the hippocampal system', Psychological Review 119, 573–616.

Lambon Ralph, M. & Ehsan, S. (2006), 'Age of acquisition effects depend on the mapping between representations and the frequency of occurrence: empirical and computational evidence', Visual Cognition 13(7–8), 928–948.

Lampert, C., Nickisch, H. & Harmeling, S. (2009), Learning to detect unseen object classes by between-class attribute transfer, CVPR'09, Miami Beach, Florida.

LeCun, Y., Bengio, Y. & Hinton, G. (2015), 'Deep learning', Nature 521, 436–444.

LeCun, Y., Bottou, L., Bengio, Y. & Haffner, P. (1998), Gradient-based learning applied to document recognition, In Proceedings of the IEEE.

Lenneberg, E. (1967), Biological foundations of language, New York: Wiley.

Lewandowsky, S. & Li, S. (1994), Catastrophic Interference in Neural Networks: Causes, Solutions, and Data, Dempster, F.N. & Brainerd,C. (Eds.) New Perspectives on Interference and Inhibition in Cognition. Academic Press, New York.

Lewkowicz, D. J. (2014), 'Early experience & multisensory perceptual narrowing', Developmental Psychobiology 56(2), 292–315.

Li, P., Farkas, I. & McWhinney, B. (2004), 'Early lexical development in a self-organising neural network', Neural Networks 17, 1345–1362.

Li, Z. & Hoiem, D. (2016), Learning without forgetting, ECCV'16, Amsterdam, The Netherlands, pp. 614–629.

--- TRANG 25 ---

Lomonaco, V. & Maltoni, D. (2017), CORe50: A new dataset and benchmark for continuous object recognition, CoRL, Mountain View, CA.

Lopez-Paz, D. & Ranzato, M. (2017), Gradient episodic memory for continual learning, NIPS'17, Long Beach, CA.

Lüders, B., Schläger, M. & Risi, S. (2016), Continual learning through evolvable neural turing machines, NIPS'16, Workshop on Continual Learning and Deep Networks, Barcelona, Spain.

Maltoni, D. & Lomonaco, V. (2018), Continuous learning in single-incremental-task scenarios., arXiv:1806.08568.

Marchman, V. A. (1993), 'Constraints on plasticity in a connectionist model of English past tense', Journal of Cognitive Neuroscience 5(2), 215–234.

Mareschal, D., Johnson, M., Sirios, S., Spratling, M., Thomas, M. & Westermann, G. (2007), Neuroconstructivism: How the brain constructs cognition, Oxford: Oxford University Press.

Marsland, S., Shapiro, J. & Nehmzow, U. (2002), 'A self-organising network that grows when required', Neural Networks 15(8–9), 1041–1058.

Martinetz, T., Berkovich, S. & Schulten, K. (1993), 'Neural-gas network for vector quantization and its application to time-series prediction', IEEE Transactions on Neural Networks 4(4), 558–569.

McClelland, J. L., McNaughton, B. L. & O'Reilly, R. C. (1995), 'Why there are complementary learning systems in the hippocampus and neocortex: Insights from the successes and failures of connectionist models of learning and memory', Psychological Review 102, 419–457.

McCloskey, M. & Cohen, N. J. (1989), 'Catastrophic interference in connectionist networks: The sequential learning problem', The Psychology of Learning and Motivation 24, 104–169.

Mermillod, M., Bugaiska, A. & Bonin, P. (2013), 'The stability-plasticity dilemma: Investigating the continuum from catastrophic forgetting to age-limited learning effects', Frontiers in Psychology 4(504).

Mici, L., Parisi, G. I. & Wermter, S. (2017), An incremental self-organizing architecture for sensorimotor learning and prediction, arXiv:1712.08521.

Mici, L., Parisi, G. I. & Wermter, S. (2018), 'A self-organizing neural network architecture for learning human-object interactions', Neurocomputing 307, 14–24.

Miikkulainen, R. (1997), 'Dyslexic and category-specific aphasic impairments in a self-organizing feature map model of the lexicon', Brain and Language 59, 334–366.

Miller, K., Keller, J. & Stryker, M. (1989), 'Occular dominance column development: Analysis and simulation', Science 245, 605–615.

Miller, K. & MacKay, D. J. (1994), 'The role of constraints in Hebbian learning', Neural Computation 6, 100–126.

Ming, G. L. & Song, H. (2011), 'Adult neurogenesis in the mammalian brain: Significant answers and significant questions.', Neuron 70, 687–702.

Moon, S., Kim, S. & Wang, H. (2015), Multimodal transfer deep learning with applications in audio-visual recognition, NIPS'15, Montreal, Canada.

Murray, M. M., Lewkowicz, D. J., Amedi, A. & Wallace, M. T. (2016), 'Multisensory processes: A balancing act across the lifespan', Trends in Neurosciences 39, 567–579.

Nadal, J. P., Toulouse, G., Changeux, J. P. & Dehaene, S. (1986), 'Networks of formal neurons and memory palimpsets', Europhysics Letters 1, 535–543.

Nelson, C. A. (2000), 'Neural plasticity and human development: The role of early experience in sculpting memory systems', Developmental Science 3(2), 115–136.

Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B. & Ng, A. Y. (2011), Reading digits in natural images with unsupervised feature learning, NIPS'11, Workshop on deep learning and unsupervised feature learning, Granada, Spain.

O'Neill, J., Pleydell-Bouverie, B., Dupret, D. & Csicsvari, J. (2010), 'Play it again: Reactivation of waking experience and memory', Trends in Neuroscience 33, 220–229.

O'Reilly, R. C. (2004), The Division of Labor Between the Neocortex and Hippocampus. Connectionist Modeling in Cognitive (Neuro-)Science, George Houghton, Ed., Psychology Press.

--- TRANG 26 ---

O'Reilly, R. C. and. Norman, K. A. (2002), 'Hippocampal and neocortical contributions to memory: Advances in the complementary learning systems framework', Trends in Cognitive Sciences 6(12), 505–510.

O'Reilly, R. C. & Rudy, J. W. (2000), 'Computational principles of learning in the neocortex and hippocampus', Hippocampus 10, 389–397.

Oudeyer, P.-Y., Kaplan, F. & Hafner, V. (2007), 'Intrinsic motivation systems for autonomous mental development', IEEE Transactions on Evolutionary Computation 11(2), 265–286.

Palatucci, M., Pomerleau, D. A., Hinton, G. E. & Mitchell, T. (2009), Zero-shot learning with semantic output codes, NIPS'09, Vancouver, Canada.

Pallier, C., Dehaene, S., Poline, J.-B., LeBihan, D., Argenti, A.-M., Dupoux, E. & Mehler, J. (2003), 'Brain imaging of language plasticity in adopted adults: can a second language replace a first?', Cerebral Cortex 13, 155–161.

Pan, S. J. & Yang, Q. (2010), 'A survey on transfer learning', IEEE Transactions on Knowledge and Data Engineering 22(10), 1345–1359.

Parisi, G., Barros, P., Fu, D., Magg., S., Wu, H., Liu, X. & Wermter, S. (2018), A neurorobotic experiment for crossmodal conflict resolution in complex environments, arXiv:1802.10408.

Parisi, G. I., Barros, P., Kerzel, M., Wu, H., Yang, G., Li, Z., Liu, X. & Wermter, S. (2017), A computational model of crossmodal processing for conflict resolution, ICDL-EPIROB'17, Lisbon, Portugal, pp. 33–38.

Parisi, G. I., Magg, S. & Wermter, S. (2016), Human motion assessment in real time using recurrent self-organization, Proceedings of the IEEE International Symposium on Robot and Human Interactive Communication, New York, NY, pp. 71–79.

Parisi, G. I., Tani, J., Weber, C. & Wermter, S. (2017), 'Lifelong learning of humans actions with deep neural network self-organization', Neural Networks 96, 137–149.

Parisi, G., Ji, X. & Wermter, S. (2018), On the role of neurogenesis in overcoming catastrophic forgetting., NIPS'18, Workshop on Continual Learning, Montreal, Canada.

Parisi, G., Tani, J., Weber, C. & Wermter, S. (2018), Lifelong learning of spatiotemporal representations with dual-memory recurrent self-organization, arXiv:1805.10966.

Part, J. L. & Lemon, O. (2016), Incremental on-line learning of object classes using a combination of self-organizing incremental neural networks and deep convolutional neural networks, IROS'16, Workshop on Bio-inspired Social Robot Learning in Home Scenarios, Daejeon, South Korea.

Part, J. L. & Lemon, O. (2017), Incremental online learning of objects for robots operating in real environments, ICDL-EPIROB'17, Lisbon, Portugal.

Pathak, D., Agrawal, P., Efros, A. A. & Darrell, F. (2017), Curiosity-driven exploration by self-supervised prediction, ICML'17, Sydney, Australia.

Polikar, R., Upda, L., Upda, S. S. & Honavar, V. (2001), 'Learn++: An incremental learning algorithm for supervised neural networks', IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews) 31(4), 497–508.

Power, J. D. & Schlaggar, B. L. (2016), 'Neural plasticity across the lifespan', Wiley Interdisciplinary Reviews: Developmental Biology 6(216).

Quadrato, G., Elnaggar, M. Y. & Di Giovanni, S. (2014), 'Adult neurogenesis in brain repair: Cellular plasticity vs. cellular replacement', Frontiers in Neuroscience 8(17).

Rao, R. P. N. & Ballard, D. H. (1999), 'Predictive coding in the visual cortex: A functional interpretation of some extra-classical receptive-field effects', Nature Neuroscience 2(1), 79–87.

Ratcliff, R. (1990), 'Connectionist models of recognition memory: Constraints imposed by learning and forgetting functions', Psychological Review 97(2), 285–308.

Razavian, A. S., Azizpour, H., Sullivan, J. & Carlsson, S. (2014), CNN features off-the-shelf: An astounding baseline for recognition, CVPR'14, Columbus, OH, pp. 806–813.

Rebuffi, S.-A., Kolesnikov, A., Sperl, G. & Lampert, C. H. (2016), iCaRL: Incremental classifier and representation learning, arXiv:1611.07725.

Reed, S. & de Freitas, N. (2015), Neural programmer interpreters, arXiv:1511.06279.

--- TRANG 27 ---

Ren, B., Wang, H., Li, J. & Gao, H. (2017), 'Life-long learning based on dynamic combination model', Applied Soft Computing 56, 398–404.

Richardson, F. M. & Thomas, M. S. C. (2008), 'Critical periods and catastrophic interference effects in the development of self-organising feature maps', Developmental Science 11(3), 371–389.

Ring, M. B. (1997), 'CHILD: A first step towards continual learning', Machine Learning 28, 77–104.

Robins, A. V. (1993), Catastrophic forgetting in neural networks: The role of rehearsal mechanisms, Proceedings of the First New Zealand International Two-stream Conference on Artificial Neural Networks and Expert Systems. IEEE Computer Society Press.

Robins, A. V. (1995), 'Catastrophic forgetting, rehearsal and pseudorehearsal', Connection Science 7(2), 123–146.

Rusu, A. A., Rabinowitz, N. C., Desjardins, G., Soyer, H., Kirkpatrick, J., Kavukcuoglu, K., Pascanu, R. & Hadsell, R. (2016), Progressive neural networks, arXiv:1606.04671.

Rusu, A. A., Vecerik, M., Rothörl, T., Heess, N., Pascanu, R. & Hadsell, R. (2017), Sim-to-real robot learning from pixels with progressive nets, CoRL'17, Mountain View, CA.

Sanger, T. D. (1994), 'Neural network learning control of robot manipulators using gradually increasing task difficulty', IEEE Transactions on Robotics and Automation 10.

Schmidhuber, J. (1991), Curious model-building control systems.

Schuldt, C., Laptev, I. & Caputo, B. (2004), Recognizing human actions: A local SVM approach, ICPR'04, Cambridge, UK, pp. 32–36.

Seidenberg, M. & Zevin, J. (2006), Connectionist models in developmental cognitive neuroscience: Critical periods and the paradox of success, In Y. Munakata & M.H. Johnson (Eds.) Processes of change in brain and cognitive development: Attention and Performance XXI. Oxford: Oxford University Press.

Senghas, A., Kita, S. & Özyürek, A. (2004), 'Children creating core properties of language: Evidence from an emerging sign language in Nicaragua', Science 305, 1779–1782.

Shatz, C. J. (1996), 'Emergence of order in visual system development', Proceedings of the National Academy of Sciences 93, 602–608.

Shin, H., Lee, J. K., Kim, J. & Kim, J. (2017), Continual learning with deep generative replay, NIPS'17, Long Beach, CA.

Skinner, B. F. (1958), 'Reinforcement today', American Psychologist 13, 94–99.

Soltoggio, A. (2015), 'Short-term plasticity as cause-effect hypothesis testing is distal reward learning', Biological Cybernetics 109, 75–94.

Soltoggio, A., Stanley, K. O. & Risi, S. (2017), Born to learn: the inspiration, progress, and future of evolved plastic artificial neural networks, arXiv:1703.10371.

Song, S., Miller, K. D. & Abbott, L. F. (2000), 'Competitive Hebbian learning through spike-timing-dependent synaptic plasticity', Nature Neuroscience 3, 919–926.

Sorrells, S. F., Paredes, M. F., Arantxa, C.-S., Sandoval, K., Dashi, Q. & Kelley, K. W. e. a. (2018), 'Human hippocampal neurogenesis drops sharply in children to undetectable levels in adults', Nature 555, 377–381.

Spence, C. (2010), 'Crossmodal spatial attention', Annals of the New York Academy of Sciences 1191, 182–200.

Spence, C. (2014), 'Orienting attention: A crossmodal perspective', The Oxford Handbook of Attention. Oxford, UK: Oxford University Press pp. 446–471.

Stein, B. E. & Meredith, M. A. (1993), The merging of the senses, The MIT Press, Cambridge, MA, US.

Stein, B. E., Stanford, T. R. & Rowland, B. A. (2014), 'Development of multisensory integration from the perspective of the individual neuron', Nature Reviews Neuroscience 15(8), 520–535.

Sur, M. & Leamey, C. A. (2001), 'Development and plasticity of cortical areas and networks', Nature Reviews Neuroscience 2, 251–262.

--- TRANG 28 ---

Tani, J. (2016), Exploring Robotic Minds: Actions, Symbols, and Consciousness a Self-Organizing Dynamic Phenomena, Oxford University Press.

Tanneberg, D., Peters, J. & Rueckert, E. (2017), Online learning with stochastic recurrent neural networks using intrinsic motivation signals, CoRL'17, Mountain View, CA.

Taupin, P. & Gage, F. H. (2002), 'Adult neurogenesis and neural stem cells of the central nervous system in mammals', Journal of neuroscience research 69(6), 745–749.

Taylor, P., Hobbs, J. N., Burroni, J. & Siegelmann, H. T. (2015), 'The global landscape of cognition: hierarchical aggregation as an organizational principle of human cortical networks and functions', Scientific Reports 5(18112).

Tessler, C., Givony, S., Zahavy, T., Mankowitz, D. J. & Mannor, S. (2017), A deep hierarchical approach to lifelong learning in Minecraft, AAAI'17, San Francisco, CA.

Thomas, M. & Johnson, M. (2006), 'The computational modelling of sensitive periods', Developmental Psychobiology 48(4), 337–344.

Thrun, S. & Mitchell, T. (1995), 'Lifelong robot learning', Robotics and Autonomous Systems 15, 25–46.

Tse, D., Takeuchi, T., Kakeyama, M., Kajii, Y., Okuno, H., Tohyama, C., Bito, H. & Morris, R. G. (2011), 'Schema-dependent gene activation and memory encoding in neocortex', Science 333, 891–895.

Turrigiano, G. (2011), 'Too many cooks? intrinsic and synaptic homeostatic mechanisms in cortical circuit refinement', Annual Review of Neuroscience 34, 89–103.

Uylings, H. (2006), 'Development of the human cortex and the concept of critical or sensitive periods', Language Learning 56, 59–90.

Vinyals, O., Blundell, C., Lillicrap, T. & Wierstra, D. (2016), Matching networks for one shot learning, NIPS'16, Barcelona, Spain.

Wah, C., Branson, S., Welinder, P., Perona, P. & Belongie, S. (2011), Caltech-UCSD Birds-200-2011 dataset, Tech Report: CNS-TR-2011-001.

Weiss, K., Khoshgoftaar, T. M. & Wang, D.-D. (2016), 'A survey of transfer learning', Journal of Big Data 3(9).

Wermter, S., Palm, G. & Elshaw, M. (2005), Biomimetic Neural Learning for Intelligent Robots, Intelligent Systems, Cognitive Robotics, and Neuroscience. Springer, Berlin, Heidelberg.

Willshaw, D. J. & von der Malsburg, C. (1976), 'How patterned neural connections can be set up by self-organization', Proceedings of the Royal Society of London B: Biological Sciences 194(1117), 431–445.

Xiao, T., Zhang, J., Yang, K., Peng, Y. & Zhang, Z. (2014), Error-driven incremental learning in deep convolutional neural network for large-scale image classification, Proceedings of the ACM International Conference on Multimedia, Orlando, FL, pp. 177–186.

Yoon, J., Yang, E. & Lee, J. Hwang, S. J. (2018), Lifelong learning with dynamically expandable networks, ICLR'18, Vancouver, Canada.

Zenke, F., Gerstner, W. & Ganguli, S. (2017), 'The temporal paradox of hebbian learning and homeostatic plasticity', Neurobiology 43, 166–176.

Zenke, F., Poole, B. & Ganguli, S. (2017), Continual learning through synaptic intelligence, ICML'17, Sydney, Australia.

Zhou, G., Sohn, K. & Lee, H. (2012), Online incremental feature learning with denoising autoencoders, International Conference on Artificial Intelligence and Statistics, pp. 1453–1461.

29

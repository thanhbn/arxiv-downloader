# 2305.18563.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/continual-learning/2305.18563.pdf
# Kích thước tệp: 5796296 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
SHARP: Thưa thớt và Phát lại Kích hoạt Ẩn cho
Học Liên tục Lấy cảm hứng từ Thần kinh
Mustafa Burak Gurbuz
Trường Khoa học Máy tính
Viện Công nghệ Georgia, Hoa Kỳ
mgurbuz6@gatech.eduJean Michael Moorman
Trường Khoa học Máy tính
Viện Công nghệ Georgia, Hoa Kỳ
jmoorman9@gatech.edu
Constantine Dovrolis
Trường Khoa học Máy tính
Viện Công nghệ Georgia, Hoa Kỳ
Viện Cyprus, Cyprus
constantine@gatech.edu
Tóm tắt
Mạng nơ-ron sâu (DNN) gặp khó khăn trong việc học trong môi trường động vì chúng
dựa vào các tập dữ liệu cố định hoặc môi trường tĩnh. Học liên tục (CL) nhằm giải quyết
hạn chế này và cho phép DNN tích lũy kiến thức một cách gia tăng, tương tự như việc
học của con người. Lấy cảm hứng từ cách não bộ củng cố ký ức, một chiến lược mạnh
mẽ trong CL là phát lại, bao gồm việc huấn luyện DNN trên hỗn hợp các lớp mới và
tất cả các lớp đã thấy. Tuy nhiên, các phương pháp phát lại hiện tại bỏ qua hai khía cạnh
quan trọng của việc phát lại sinh học: 1) não bộ phát lại các mẫu thần kinh đã xử lý
thay vì đầu vào thô, và 2) nó ưu tiên việc phát lại thông tin học gần đây hơn là xem lại
tất cả các kinh nghiệm trong quá khứ. Để giải quyết những khác biệt này, chúng tôi đề
xuất SHARP, một phương pháp CL hiệu quả lấy cảm hứng từ thần kinh tận dụng kết nối
động thưa thớt và phát lại kích hoạt. Không giống như các phương pháp phát lại kích
hoạt khác, giả định các lớp không phải đối tượng phát lại đã được tiền huấn luyện và
cố định, SHARP có thể liên tục cập nhật tất cả các lớp. Ngoài ra, SHARP là duy nhất
ở chỗ nó chỉ cần phát lại vài lớp gần đây đã thấy thay vì tất cả các lớp trong quá khứ.
Các thí nghiệm của chúng tôi trên năm tập dữ liệu chứng minh rằng SHARP vượt trội
so với các phương pháp phát lại tiên tiến trong học gia tăng lớp. Hơn nữa, chúng tôi
thể hiện tính linh hoạt của SHARP trong một kịch bản CL mới lạ nơi các ranh giới giữa
các tập học mờ nhạt. Mã SHARP có sẵn tại
https://github.com/BurakGurbuz97/SHARP-Continual-Learning .
1 Giới thiệu
Mạng Nơ-ron Sâu (DNN) thường được huấn luyện trên các phân phối dữ liệu tĩnh. Trong quá trình này, các
batch huấn luyện được tạo bằng cách rút mẫu từ một tập dữ liệu đã trộn và cố định hoặc bằng cách thu thập
các quan sát từ một môi trường không thay đổi. Mặc dù cách tiếp cận này đã dẫn đến tiến bộ đáng kể
trong nhiều lĩnh vực rộng rãi [ 54,33,17], DNN bỏ lỡ một khía cạnh quan trọng của trí tuệ tổng quát: khả
năng học liên tục theo thời gian trong một môi trường động. Trong kịch bản Học Liên tục (CL) như vậy,
DNN ghi đè kiến thức đã có trước đó khi học từ dữ liệu mới, dẫn đến một hiện tượng thách thức gọi là
Quên Thảm khốc (CF) [39].
Không giống như DNN, động vật thể hiện khả năng đáng kể trong việc giữ lại và tích hợp kiến thức thu
được trong môi trường luôn thay đổi [ 19,20]. Điều này truyền cảm hứng cho chúng tôi xem xét kỹ một số
cơ chế trong não bộ để giảm thiểu CF trong DNN. Mặc dù ngay cả những động vật đơn giản hơn như ruồi
giấm [35] và giun C. elegans [2, 51] cũng thể hiện một số CL, chúng tôi tập trung vào não bộ động vật có vú.
Bản thảo. Đang xem xét.arXiv:2305.18563v1  [cs.LG]  29 May 2023

--- TRANG 2 ---
Phát lại kích hoạt (Nhận thức-1): Phát lại các mẫu thần kinh là một cơ chế mạnh mẽ mà não bộ
tận dụng để học thông tin mới mà không quên kiến thức hiện tại [ 57,23]. Tương tự, nhiều
phương pháp CL sử dụng phát lại bằng cách kết hợp các ví dụ mới với những ví dụ trước đó và huấn luyện
mạng với hỗn hợp này [ 42,32]. Tuy nhiên, việc phát lại này thường được thực hiện bằng cách phát lại
các mẫu thô (ví dụ, hình ảnh ở mức pixel), điều này không hợp lý về mặt sinh học. Ngược lại, việc phát
lại trong hồi hải mã tuân theo các quỹ đạo không gian thay vì đầu vào cảm giác thô [ 29], và nó được nén
thời gian so với kinh nghiệm [15], chỉ ra rằng não bộ phát lại các biểu diễn đã được xử lý cao.
(1) Lấy cảm hứng từ não bộ, chúng tôi phát lại các kích hoạt lớp ẩn để giảm quên lãng.
Phát lại củng cố thông tin học gần đây (Nhận thức-2): Tế bào vị trí là một phân loại
các nơ-ron kích thích được tìm thấy trong hồi hải mã kích hoạt khi một động vật ở một vị trí cụ thể
trong môi trường. Phát lại tuyển dụng các tế bào vị trí theo cùng một trình tự như trong kinh nghiệm trước
đó, cho phép củng cố ký ức phụ thuộc vào kinh nghiệm. Nghiên cứu về phát lại ký ức trong não bộ
đã tìm thấy mối tương quan giữa các mẫu kích hoạt của tế bào vị trí trong giấc ngủ và những mẫu quan sát
được khi thực hiện các nhiệm vụ thức gần đây [ 43,59,23]. Việc phát lại học tập gần đây này đã được xác
nhận trong các nghiên cứu tiếp theo và cũng đã được quan sát trong các vùng não ngoài hồi hải mã [ 37,13,26,44].
Hơn nữa, động lực thời gian của việc phát lại ký ức bao gồm việc ưu tiên phát lại thông tin gần đây,
điều này dần dần giảm bớt khi việc phát lại thông tin mới thay thế nó [ 8,41,40,29].
Điều này trái ngược với thực tiễn hiện tại trong CL. Theo hiểu biết của chúng tôi, tất cả các phương pháp
CL dựa trên phát lại hiện tại đều bao gồm việc xem lại tất cả các kinh nghiệm trong quá khứ một cách đồng
đều khi học một nhiệm vụ mới [ 32,42,23]. Ví dụ, trong phân loại hình ảnh, một chiến lược phát lại điển
hình bao gồm việc tạo các batch huấn luyện không chỉ bao gồm các ví dụ từ các lớp mới mà còn từ tất cả
các lớp đã gặp trước đó.
(2) Tương tự như phát lại trong não bộ, chúng tôi phát lại một số lượng hạn chế các lớp học gần đây.
Kết nối thưa thớt và động (Nhận thức-3): DNN thường có các lớp kết nối đầy đủ. Kết nối
dày đặc trong các lớp này dễ bị quên lãng vì những thay đổi trong một kết nối duy nhất ảnh hưởng đến
các kích hoạt của tất cả các đơn vị tiếp theo. Ngược lại, não bộ dựa vào kết nối thưa thớt và động
(ví dụ, cắt tỉa và hình thành khớp thần kinh). Chẳng hạn, các nghiên cứu giải phẫu tiết lộ rằng các nơ-ron
tháp vỏ não nhận tương đối ít đầu vào kích thích từ các nơ-ron lân cận [ 25,24,38]. Hơn nữa,
sau khi cắt tỉa khớp thần kinh trong thời thơ ấu, mật độ kết nối trong não bộ vẫn tương đối
không đổi ở người lớn khỏe mạnh [ 11]. Nói cách khác, não bộ không hy sinh sự thưa thớt để học; thay vào
đó, nó sử dụng tính dẻo khớp thần kinh để hình thành các đường dẫn thần kinh hiệu quả hơn.
(3) Lấy cảm hứng từ kết nối thưa thớt của não bộ và tính dẻo khớp thần kinh, chúng tôi bắt đầu với một DNN
thưa thớt và duy trì mật độ của mạng trong khi đấu nối lại các kết nối trong suốt quá trình CL.
Ổn định khớp thần kinh (Nhận thức-4): Một cơ chế khác mà não bộ sử dụng để bảo tồn kiến thức
trong quá khứ là việc ổn định các gai nhánh cây (đầu vào khớp thần kinh đơn lẻ). Ví dụ, các thí nghiệm
trên chuột cho thấy rằng khi học các kỹ năng mới, thể tích của một số gai nhánh cây nơ-ron tăng lên. Sau
cửa sổ học, những gai nhánh cây mở rộng này vẫn tồn tại, bất chấp việc học tiếp theo các nhiệm vụ khác
[60]. Ngược lại, khi những gai này bị loại bỏ thông qua thí nghiệm, chuột quên kỹ năng liên quan
[12, 21]. Điều này ngụ ý rằng các gai ổn định đóng vai trò quan trọng trong việc lưu trữ thông tin dài hạn.
(4) Giống như các gai ổn định, chúng tôi đóng băng các kết nối đầu vào của các đơn vị ẩn cụ thể để giảm
thiểu quên lãng.
Tóm lại, các đóng góp chính của chúng tôi trong bài báo này như sau:
•Chúng tôi đề xuất một phương pháp CL mới sử dụng kết nối động và phát lại các kích hoạt
của các lớp gần đây đã thấy để đạt được hiệu suất tiên tiến trong học gia tăng lớp.
•Các phương pháp phát lại kích hoạt trước đó sử dụng bộ trích xuất đặc trưng được tiền huấn luyện/cố định.
Nhờ kết nối động thưa thớt, phương pháp của chúng tôi là trường hợp đầu tiên của phát lại kích hoạt
không cần tiền huấn luyện.
•Chúng tôi chứng minh tính linh hoạt của phương pháp trên một loại kịch bản CL mới trong đó các
ranh giới giữa các tập học khác nhau mờ nhạt, và các tập có thể chồng chéo.
2 Nghiên cứu liên quan
Phát lại đóng vai trò như một chiến lược hiệu quả để giải quyết CF và được sử dụng rộng rãi trong tài liệu
CL [32, 42, 23]. Các phương pháp phát lại hiện tại trong tài liệu có thể được nhóm thành ba loại.

--- TRANG 3 ---
Phát lại Ví dụ Thô: Hình thức phát lại phổ biến nhất bao gồm việc bảo tồn và xem xét lại các
ví dụ trước đó [ 6,48,47,7,4]. Các phương pháp này sử dụng bộ nhớ với ngân sách cố định và điền vào
nó bằng cách lấy mẫu từ các ví dụ đã gặp. Để xấp xỉ các phân phối dữ liệu tĩnh, các batch huấn luyện
được hình thành bằng cách trộn các ví dụ từ luồng đầu vào với một tập hợp các ví dụ cũ hơn được chọn
từ bộ nhớ.
Mặc dù việc phát lại các ví dụ thô giúp chống lại quên lãng, nó có một số nhược điểm. Thứ nhất,
loại phát lại này không hợp lý về mặt sinh học (xem Nhận thức-1). Người ta có thể lập luận rằng tính
hợp lý sinh học không phải là mối quan tâm đáng kể từ quan điểm thực tiễn. Tuy nhiên, phát lại thô cũng
có những hạn chế thực tiễn. Chẳng hạn, nó không phù hợp cho các ứng dụng thực tế nơi dữ liệu người
dùng trước đó không thể được lưu trữ vô thời hạn. Ngoài ra, phát lại thô thường bị chỉ trích vì việc lưu
trữ một phần của tất cả các ví dụ đã quan sát làm đơn giản hóa quá mức vấn đề. Ví dụ, một nghiên cứu
gần đây [ 45] đã giới thiệu thuật toán GDumb, lưu trữ một tập con các mẫu trong bộ nhớ khi chúng đến
và, trong quá trình kiểm tra, huấn luyện một mô hình từ đầu chỉ sử dụng các mẫu trong bộ nhớ. Đáng
ngạc nhiên, baseline đơn giản này vượt qua hầu hết tất cả các phương pháp phát lại thô. Do đó, việc lưu
trữ và huấn luyện lại trên hình ảnh thô xấp xỉ dữ liệu tĩnh thay vì cung cấp cho mô hình khả năng thích
ứng với các phân phối dữ liệu thay đổi.
Phát lại Sinh tạo: Một số nghiên cứu đã đề xuất sử dụng mô hình sinh tạo để tạo ra các mẫu
giống với các ví dụ đã gặp trước đó [ 53,3,46]. Các phương pháp này giải quyết mối quan tâm về quyền
dữ liệu người dùng và cũng có thể được hỗ trợ bởi khoa học thần kinh, vì hồi hải mã đóng vai trò sinh
tạo trong củng cố ký ức. Tuy nhiên, các phương pháp này mang lại chi phí tính toán đáng kể.
Ngoài ra, việc huấn luyện mô hình sinh tạo có thể thách thức vì nó cũng dễ bị quên lãng và
có các vấn đề bổ sung, chẳng hạn như chất lượng của các mẫu được tạo ra suy giảm theo thời gian [57].
Phát lại Kích hoạt: Một số công trình lấy cảm hứng từ thần kinh đã đề xuất giải quyết các hạn chế
của phát lại ví dụ thô hoặc được tạo ra bằng cách phát lại các kích hoạt. Điều này phù hợp với Nhận thức-1.
Chẳng hạn, Brain-inspired replay (BIR) [ 57] mô hình hóa sự tương tác giữa vỏ não mới và hồi hải mã,
cung cấp phát lại kích hoạt sinh tạo hợp lý về mặt sinh học để giảm thiểu quên lãng. Tương tự, REMIND [ 22]
phát lại các kích hoạt nén và được lấy cảm hứng từ lý thuyết chỉ mục hồi hải mã [56].
Tuy nhiên, các phương pháp này giả định các lớp không nhận phát lại được tiền huấn luyện và đóng băng.
Chẳng hạn, REMIND tiền huấn luyện 15 lớp tích chập đầu tiên của Resnet-18 và khởi tạo phát lại sau
15 lớp đóng băng đầu tiên. Điều này làm cho phát lại kích hoạt thực tế giống như phát lại thô vì ánh xạ
giữa hình ảnh thô và các kích hoạt được lưu trữ không bao giờ thay đổi. Hơn nữa, các phương pháp này
thất bại mà không có tiền huấn luyện và đóng băng vì các kích hoạt được lưu trữ trở nên lỗi thời khi các
lớp trước đó nhận cập nhật gradient. Vì vậy, thay vì giải quyết CF, chúng che giấu nó bằng cách đóng
băng tất cả các lớp không nhận phát lại.
Cuối cùng, các phương pháp phát lại hiện tại xem xét lại tất cả các lớp trong quá khứ để tạo các batch
giống như tập dữ liệu tĩnh. Do đó, phát lại trong CL không nhạy cảm với tính mới lạ của đầu vào, điều
này khác rất nhiều so với cách não bộ phát lại kinh nghiệm vì nó ưu tiên phát lại các kinh nghiệm mới
lạ. Phương pháp của chúng tôi giải quyết tất cả các hạn chế đã đề cập của các phương pháp phát lại.
Thứ nhất, chúng tôi phát lại các kích hoạt mà không cần tiền huấn luyện hoặc đóng băng hoàn toàn các
lớp trích xuất đặc trưng. Thứ hai, chúng tôi chỉ phát lại vài lớp gần đây đã thấy. Thứ ba, bằng việc đấu
nối lại kết nối thường xuyên, chúng tôi phá vỡ các đường dẫn đầu vào-đầu ra gây ra can thiệp và thúc
đẩy hình thành các đường dẫn hiệu quả hơn giúp tạo điều kiện chuyển giao kiến thức tích cực qua các
kinh nghiệm học tập khác nhau.
Các Phương pháp Khác trong CL: Phát lại không phải là chiến lược duy nhất để giảm thiểu quên lãng.
Các phương pháp chính quy hóa điều chỉnh cập nhật trọng số để bảo vệ các tham số quan trọng bảo tồn
kiến thức trong quá khứ [31,62,1,52,10]. Tuy nhiên, chúng hoạt động kém so với ngay cả các phương
pháp phát lại đơn giản nhất [58]. Mặt khác, các phương pháp cô lập tham số gán các tham số khác nhau
cho mỗi nhiệm vụ mới để giảm quên lãng. Sự tách biệt này thường được thực hiện bằng cách phát triển
các nhánh mới [ 50,61,49] hoặc phân vùng các kết nối hiện tại [ 16,28,18,55]. Các phương pháp này chủ
yếu được thiết kế cho các kịch bản trong đó một định danh nhiệm vụ được cung cấp trong quá trình kiểm
tra để loại trừ các phần mạng không liên quan. Không có định danh nhiệm vụ, chúng hoặc thất bại hoặc
hoạt động kém đáng kể so với các phương pháp phát lại [58].
SHARP và Các Phương pháp Cô lập Tham số: Phương pháp của chúng tôi được thiết kế cho một
kịch bản đòi hỏi khắt khe hơn trong đó các mô hình đưa ra dự đoán mà không có thông tin nhiệm vụ.
Tuy nhiên, nó chia sẻ một số điểm tương đồng với các phương pháp cô lập tham số, đặc biệt với NISPA [ 18].
NISPA bắt đầu với một mạng đã cắt tỉa và đấu nối lại các kết nối trong khi duy trì cùng mật độ mạng.
Ngoài ra, nó đóng băng một số kết nối. Phương pháp của chúng tôi áp dụng chiến lược tương tự để đấu
nối lại các đơn vị. Do đó, cả NISPA và phương pháp của chúng tôi đều chia sẻ Nhận thức-3 và Nhận thức-4.
Tuy nhiên, điều quan trọng cần lưu ý là NISPA yêu cầu định danh nhiệm vụ trong quá trình đánh giá để
che một số đơn vị đầu ra và thất bại trong kịch bản của chúng tôi.

--- TRANG 4 ---
Hình 1: a) Hiển thị cách SHARP phát triển theo thời gian. b) Mô tả cấu trúc mạng với một
ví dụ đồ chơi. c) Hiển thị các xếp hạng và trạng thái đơn vị có thể. d) Biểu diễn sơ đồ chuyển đổi xếp hạng.
3 SHARP: Thưa thớt và Phát lại Kích hoạt Ẩn
Phương pháp CL của chúng tôi SHARP, Thưa thớt và Phát lại Kích hoạt Ẩn, xử lý tuần tự các
tập học. Chúng tôi chia nhỏ mỗi tập thành các "giai đoạn" kéo dài trong một số epoch cố định (xem
Hình 1-a). Trước mỗi giai đoạn, chúng tôi đấu nối lại các đơn vị dựa trên các kích hoạt cục bộ. Việc
đấu nối lại nhằm giảm can thiệp tiêu cực giữa các đơn vị trong khi hình thành các đường dẫn mới.
Trong một giai đoạn, SHARP sử dụng Supervised Contrastive Loss [ 30] và phát lại các kích hoạt
ẩn được lưu trữ trong bộ nhớ ngắn hạn (xem Hình 1-b). Cuối một tập, chúng tôi ổn định một số đơn vị
và tạo các biểu diễn dài hạn được sử dụng để đưa ra dự đoán. Xem Tài liệu Bổ sung để biết mã giả hoàn chỉnh.
3.1 Công thức Vấn đề và Ký hiệu
Chúng tôi tập trung vào học gia tăng lớp (CIL) thông qua một loạt E tập trong đó mỗi tập e
có một tập dữ liệu huấn luyện De[58]. Mặc dù thuật ngữ "nhiệm vụ" thường được sử dụng trong tài liệu
CL để mô tả các tập này, chúng tôi tránh sử dụng nó do việc sử dụng thường xuyên trong các ngữ cảnh
khác nhau. Chúng tôi phân vùng DNN với L lớp thành hai mô-đun. Mô-đun đầu tiên G(·) bao gồm
K lớp đầu tiên. Nó nhận một hình ảnh đầu vào xi và xuất ra kích hoạt hi. Mô-đun thứ hai, F(·) có
L−K lớp còn lại, và nó ánh xạ hi đến kích hoạt lớp cuối zi. Hơn nữa, DNN của chúng tôi có mật độ
kết nối cố định d. Ở đây, d là tỷ lệ kết nối còn lại sau khi cắt tỉa so với trước khi cắt tỉa.
Cắt tỉa được thực hiện ngẫu nhiên khi khởi tạo và được áp dụng riêng biệt cho mỗi lớp, đảm bảo mọi
lớp có cùng mật độ d. Trong các lớp tích chập, một "đơn vị" được thay thế bằng bộ lọc tích chập 3 chiều.
Tương tự, một "kết nối" được thay thế bằng kernel 2 chiều. Tất cả các đơn vị đều được theo sau bởi ReLU.
SHARP sử dụng Bộ nhớ Ngắn hạn (STM) tạm thời giữ k kích hoạt từ m tập trước đó. Trừ khi được
chỉ định khác, chúng tôi đặt m= 1, nghĩa là STM chỉ lưu trữ k kích hoạt từ tập gần nhất. STM tuân theo
ba quy tắc đơn giản: (1) Nó phân phối đều dung lượng k giữa các lớp được lưu trữ. (2) Nó chọn ngẫu
nhiên các mẫu từ luồng đầu vào để lưu trữ. (3) Nó sử dụng lượng tử hóa tuyến tính để biểu diễn một
giá trị dấu phẩy động bằng một byte duy nhất.
3.2 Xếp hạng Đơn vị
Chúng tôi gán cho mỗi đơn vị một xếp hạng từ 0 đến e, trong đó e là số tập đã thấy. Chúng tôi ký hiệu
các đơn vị ở lớp l với Ul và sử dụng chỉ số dưới để ký hiệu các đơn vị với xếp hạng nhất định (ví dụ, Ul
r<2).
Khi khởi tạo, tất cả các đơn vị đều có xếp hạng-0. Trước mỗi giai đoạn, chúng tôi thăng cấp một số
đơn vị từ xếp hạng 0 lên 1, như được mô tả chi tiết dưới đây.

--- TRANG 5 ---
Khi một tập kết thúc, xếp hạng của tất cả các đơn vị có xếp hạng >0 được tăng lên một (xem Hình 1-d).
Chuyển đổi xếp hạng trước mỗi giai đoạn: Chúng tôi gán xếp hạng-1 cho một số đơn vị dựa trên các
kích hoạt. Bước này giống với việc lựa chọn đơn vị "ứng viên ổn định" của NISPA, nhưng NISPA
không phù hợp cho CIL [ 18]. Để làm điều này, trước tiên, chúng tôi tính toán kích hoạt ở mỗi lớp
trên một số ví dụ tập (1024 cho các thí nghiệm):
Al=X
x∼Deal(x) =X
x∼DeX
ul
i∈Ulaul
i(x) (1)
Ở đây, aul
i(x) là kích hoạt của đơn vị i ở lớp l cho mẫu x và al(x) là kích hoạt tích lũy
của lớp l cho mẫu x. Tiếp theo, chúng tôi chọn các đơn vị xếp hạng-1 được ký hiệu bởi tập Pl
1 như sau:
min
Pl
1⊆Ul
r<2|Pl
1|subject toX
x∼DeX
ul
i∈Pl
1aul
i(x)≥τAl−X
ul
i∈Ul
r≥2aul
i(x) (2)
Tất cả các đơn vị Ul
r<2 không được chọn sẽ bị hạ cấp xuống xếp hạng-0. Mục tiêu của chúng tôi là
tìm tập nhỏ nhất các đơn vị để đánh dấu là xếp hạng-1 để nắm bắt ít nhất một phần τ (sẽ giải thích
ngay) của tổng kích hoạt trong lớp l, loại trừ các kích hoạt được tạo ra bởi các đơn vị trong Ul
r≥2.
Nếu các đơn vị có xếp hạng ≥2 nắm bắt phần lớn kích hoạt, chỉ cần chọn ít đơn vị. Do đó, các đơn vị
xếp hạng cao đóng góp vào việc thỏa mãn ràng buộc mà không tăng mục tiêu tối thiểu hóa. Chúng tôi
giải quyết vấn đề này bằng thuật toán tham lam. Trước tiên, chúng tôi sắp xếp các đơn vị dựa trên
kích hoạt theo thứ tự giảm dần. Thứ hai, chúng tôi chọn các đơn vị có kích hoạt cao nhất cho đến khi
đạt được hoặc vượt quá kích hoạt mục tiêu. Thuật toán tham lam này là tối ưu cho vấn đề này, như
chúng tôi chỉ ra trong Tài liệu Bổ sung. Lưu ý rằng các đơn vị đầu vào luôn có xếp hạng cao nhất có
thể (tức là E) theo định nghĩa và không tham gia vào việc lựa chọn.
Tính toán τ: Như đã thảo luận trong [ 18], trong các giai đoạn đầu của huấn luyện, các kích hoạt có
thể thể hiện những biến động không thể dự đoán. Do đó, chúng ta nên bắt đầu với τ lớn hơn. Khi quá
trình huấn luyện tiến triển, các kích hoạt đơn vị trở nên ổn định hơn. Vì vậy, chúng ta có thể thắt chặt
tiêu chí lựa chọn sau đó. Lý luận này ngụ ý rằng chúng ta nên giảm dần τ, bắt đầu với τ1 lớn trong
giai đoạn-1 và giảm τ theo các bước tăng dần lớn hơn với mỗi giai đoạn. Chúng tôi đạt được điều này
bằng cách sử dụng lịch ủ cosine:
τp= max( τmin,1
2
1 + cosp+1
k×π
). Ở đây, p là chỉ số giai đoạn, và k (đặt thành 30) xác định
hình dạng của hàm. Ngoài ra, chúng tôi không cho phép τp nhỏ hơn τmin là một siêu tham số.
3.3 Đấu nối lại Kết nối:
Quy tắc đấu nối lại đầu tiên của chúng tôi là loại bỏ các kết nối từ tất cả các đơn vị xếp hạng-0 đến
các đơn vị xếp hạng-1 sau mỗi lần chọn Pl
1. Vì xếp hạng của các đơn vị Ul
r>0 được tăng lên một sau
mỗi tập, chúng tôi đảm bảo rằng sẽ không có kết nối từ các đơn vị xếp hạng thấp hơn đến các đơn vị
xếp hạng cao hơn. Chúng ta có thể diễn đạt lại thuộc tính này như:
Thuộc tính Đường dẫn: Không có đường dẫn có hướng nào trong DNN từ đơn vị xếp hạng- i đến
đơn vị xếp hạng- j nếu i < j .
Lưu ý rằng mỗi đơn vị trong DNN đại diện cho một hàm được đặc trưng bởi các kết nối đầu vào của
nó và các kết nối đầu vào của tất cả các đơn vị tổ tiên. Vì vậy, các cập nhật trọng số có thể thay đổi
chức năng của một đơn vị theo hai cách, trực tiếp bằng cách thay đổi trọng số của các kết nối đến đơn
vị và thứ hai, bằng cách thay đổi các kết nối đến của các đơn vị tổ tiên. Kết hợp quan sát này với
Thuộc tính Đường dẫn :
Quan sát: Xét i < j , chúng ta có thể cập nhật bất kỳ đơn vị xếp hạng- i nào mà không ảnh hưởng
đến chức năng của bất kỳ đơn vị xếp hạng- j nào, vì không có đường dẫn kết nối các đơn vị có xếp
hạng- i với những đơn vị có xếp hạng- j.
Sau khi loại bỏ một số kết nối từ lớp l, chúng tôi thêm cùng số lượng kết nối mới vào lớp l,
đảm bảo mật độ d của mỗi lớp vẫn không đổi. Chúng ta không nên phá vỡ Thuộc tính Đường dẫn vì
Quan sát tương ứng là rất quan trọng để tránh quên lãng. Do đó, chúng ta có ràng buộc sau:
Ràng buộc Phát triển: Chúng ta không thể phát triển kết nối từ xếp hạng- i đến xếp hạng- j nếu i < j.
Vì vậy, chúng ta có thể kết nối các đơn vị xếp hạng- i với các đơn vị xếp hạng- j nếi i≥j. Chúng tôi
đã quan sát thấy rằng việc đưa tất cả hạn mức kết nối vào việc tăng các kết nối đến cho các đơn vị
xếp hạng-0 mang lại hiệu suất tốt hơn. Một lý do tiềm tàng cho điều này là các đơn vị xếp hạng-0
được coi là không quan trọng bởi quá trình xếp hạng của chúng tôi. Việc thêm các kết nối đến mới
tăng cường khả năng của chúng và cho chúng cơ hội cao hơn để trở nên quan trọng trong tương lai.
Ngoài ra, các kết nối mới cho phép chúng tái sử dụng kiến thức của các đơn vị xếp hạng cao hơn, thúc
đẩy chuyển giao kiến thức. Do đó, chúng tôi tạo ngẫu nhiên các kết nối mới từ tất cả các đơn vị đến
các đơn vị xếp hạng-0 với trọng số bằng không.

--- TRANG 6 ---
3.4 Trạng thái Đơn vị và Hình thành Kết nối Ổn định
Bên cạnh xếp hạng, chúng tôi giới thiệu các trạng thái đơn vị. Các đơn vị xếp hạng-0 ở trạng thái
"Nhàn rỗi" vì chúng không được phân bổ cho tập hiện tại. Các đơn vị nhàn rỗi bị ngắt kết nối khỏi
loss, vì vậy chúng không nhận huấn luyện (xem Hình 1-b). Chúng tôi quan sát thấy rằng việc khởi
tạo lại các đơn vị nhàn rỗi này trước mỗi tập dẫn đến hiệu suất tốt hơn. Một quan sát tương tự được
thực hiện trong một công trình gần đây [ 14] cho rằng SGD mất tính dẻo khi huấn luyện tiến triển và
việc khởi tạo lại các đơn vị không quan trọng dẫn đến hiệu suất cải thiện. Các đơn vị xếp hạng-1 ở
trạng thái "Huấn luyện" vì chúng trước đây nhàn rỗi, nhưng bây giờ chúng đang được huấn luyện.
Chúng tôi có hai trạng thái bổ sung: "Tinh chỉnh" và "Đóng băng". Các trạng thái này phụ thuộc không
chỉ vào xếp hạng của đơn vị mà còn vào vị trí của đơn vị và dung lượng của STM. Nhớ lại rằng chúng
tôi chia DNN thành hai mô-đun: G(·) (trước phát lại) và F(·) (sau phát lại). Ngoài ra, nhớ lại rằng
STM của chúng tôi giữ các kích hoạt từ m tập trước đó. Nếu một đơn vị có xếp hạng r trong đó r≥2
hoặc r≤m+ 1 và nó ở trong F(·), nhận phát lại, chúng tôi gọi nó là đơn vị tinh chỉnh. Trực giác là
các đơn vị như vậy ban đầu được phân bổ cho một tập trong quá khứ, nhưng chúng vẫn có thể được
tinh chỉnh trên các lớp tập mới mà không quên lãng vì các lớp mà chúng gặp trước đó vẫn còn trong
STM nhớ m tập trước đó.
Nếu một đơn vị có xếp hạng r > m + 1 và ở trong F(·), nó có nguy cơ quên lãng vì STM có dung
lượng thời gian là m và sẽ xóa một số lớp đã được đơn vị nhìn thấy. Vì vậy, chúng ta phải ngừng huấn
luyện các đơn vị như vậy và tất cả tổ tiên của chúng để giữ lại kiến thức về các lớp sẽ bị xóa khỏi STM.
Quy tắc Đóng băng: Đóng băng tất cả các kết nối đến cho các đơn vị xếp hạng r > m + 1 trong F(·).
Quy tắc này, kết hợp với Thuộc tính Đường dẫn , xử lý tất cả tổ tiên của một đơn vị vì Thuộc tính
Đường dẫn cho thấy rằng tất cả tổ tiên của một đơn vị có cùng xếp hạng hoặc xếp hạng cao hơn. Do
đó, chúng sẽ được đóng băng hoặc sẽ được đóng băng đồng thời.
Cuối cùng, chúng tôi đóng băng các kết nối đến cho các đơn vị có xếp hạng r >1 nếu chúng ở trong
G(·)— đây là cùng Quy tắc Đóng băng , nhưng chúng tôi đặt m= 0 vì G(·) không phát lại. Xem
Hình 1-c cho sơ đồ các trạng thái và xếp hạng. Lưu ý rằng chúng tôi không đóng băng tất cả các đơn
vị tạo ra các kích hoạt mà chúng tôi lưu trữ để phát lại. Vì vậy, các chiều của kích hoạt tương ứng với
xếp hạng 0 và 1 có thể thay đổi tùy ý với các tập mới và không đáng tin cậy cho việc phát lại. Tuy
nhiên, điều này không phải là vấn đề vì các kích hoạt của chúng sẽ không được truyền đến các đơn vị
Tinh chỉnh với r >1 dựa vào phát lại để nhớ kiến thức cũ (nhớ lại Thuộc tính Đường dẫn ). Vì vậy,
chúng ta có thể an toàn phát lại các biểu diễn dịch chuyển một phần. Điều này cho phép SHARP liên
tục học trích xuất đặc trưng mà không dựa vào các lớp được tiền huấn luyện và đóng băng.
3.5 Supervised Contrastive Loss
Thông thường, DNN sử dụng cross-entropy loss và huấn luyện một lớp phân loại. Tuy nhiên, điều này
có thể dẫn đến vấn đề trong CL, vì dự đoán của mạng rất nhạy cảm với trọng số của lớp phân loại.
Ví dụ, [ 34] đề xuất một số chiến lược để giải quyết vấn đề này, chẳng hạn như chuẩn hóa trọng số
hoặc sửa đổi các số hạng bias. Ngoài ra, trong CL thường thực hiện phân vùng đơn vị đầu ra thành
nhiều đầu phân loại hoặc che một số đơn vị đầu ra để ngăn ngừa dịch chuyển lớn trong ranh giới quyết
định [58]. Chúng tôi thực hiện một cách tiếp cận khác và loại bỏ hoàn toàn lớp phân loại và thay vào
đó học các biểu diễn được phân cụm dựa trên các lớp thông qua Supervised Contrastive Learning [30].
Trong quá trình truyền xuôi, chúng tôi bắt đầu với một batch gồm n mẫu đầu vào. Sau đó, chúng tôi
đưa các mẫu này qua G(·) và nhận được n kích hoạt ẩn. Tiếp theo, chúng tôi lấy mẫu thêm n kích hoạt
từ STM và có tổng cộng 2n, được đưa vào F(·) xuất ra 2n biểu diễn (xem Hình 1-b). Hãy ký hiệu
các chỉ số của 2n biểu diễn này {z1, . . . z 2n} với tập I. Cho i∈I là chỉ số của một mẫu tùy ý trong I.
Chúng tôi định nghĩa hai tập: (1) A(i)≡I\ {i}, Tất cả trừ i, (2)P(i)≡ {p∈A(i) :yp=yi},
Tích cực so với i. Sau đó, chúng tôi tính hàm loss sau:
L=X
i∈I−1
|P(i)|X
p∈P(i)logexp(<ẑi·ẑp> /λ )P
a∈A(i)exp(<ẑi·ẑa> /λ )(3)
Ở đây chúng tôi sửa đổi zi bằng cách đặt tất cả các kích hoạt đơn vị xếp hạng-0 thành 0 và chuẩn
hóa vector kết quả để có chuẩn L2 đơn vị để có được ẑi. Ngoài ra, <·> là tích vô hướng, và λ là tham
số nhiệt độ – thường từ 0.05 đến 0.2. Loss này phân cụm các ví dụ của cùng lớp trong không gian
nhúng trong khi đẩy xa các cụm mẫu của các lớp khác nhau. Do đó, mạng của chúng tôi học các biểu
diễn nhưng không thể đưa ra dự đoán. Chúng tôi dựa vào bộ phân loại k-NN cho dự đoán, như được
giải thích tiếp theo.

--- TRANG 7 ---
Hình 2: Độ chính xác trên các lớp đã thấy cho EMNIST và CIFAR100. Chúng tôi không xem xét
hiệu suất trong các lớp tiền huấn luyện. Kết quả qua ba hạt giống ngẫu nhiên (với cùng trọng số
tiền huấn luyện). Ngân sách bộ nhớ EMNIST: 0.0392 MB. Ngân sách bộ nhớ CIFAR100: 4.096 MB.
BIR không có bộ nhớ rõ ràng nhưng có các tham số bộ mã hóa tự động biến thiên bổ sung để tạo ra
các kích hoạt cũ.
3.6 Bộ nhớ Dài hạn và Dự đoán
Sau mỗi tập, chúng tôi chọn ngẫu nhiên một tập con các kích hoạt từ STM và chuyển chúng vào
Bộ nhớ Dài hạn (LTM) bằng F(·). Tại thời điểm này, STM có các kích hoạt cho tập hiện tại cũng
như m tập trước đó. Khi tạo biểu diễn LTM cho các lớp của tập e−i, chúng tôi loại bỏ các chiều từ
các đơn vị có xếp hạng < m +i vì các đơn vị này không được huấn luyện trên các lớp của tập e−i
và về cơ bản chỉ là nhiễu. Cũng không an toàn khi sử dụng các chiều này cho dự đoán vì chúng sẽ
được cập nhật trong các tập tương lai. Ví dụ, các đơn vị xếp hạng-0 bị ngắt kết nối khỏi loss trong
quá trình học cho tập e, vì vậy chúng có thể bị loại bỏ khi dự đoán các lớp tập e. Ngoài ra, chúng sẽ
được cập nhật trong các tập tương lai, vì vậy không an toàn khi lưu trữ chúng trong LTM vì chúng sẽ
trở nên lỗi thời. Logic tương tự áp dụng đệ quy cho các xếp hạng và tập khác.
Lưu ý rằng các biểu diễn LTM chiếm không gian không đáng kể so với các kích hoạt STM vì chúng
tôi chọn một tập con ngẫu nhiên để lưu trữ, các biểu diễn được nén do giảm độ rộng lớp, và chúng tôi
chỉ lưu trữ các chiều tương ứng với các xếp hạng nhất định. Cuối cùng, SHARP ánh xạ một ví dụ kiểm
tra đã cho đến một lớp. Chúng tôi xử lý mẫu xi, tạo ra zi=F(G(xi)). Sau đó chúng tôi thực hiện phân
loại k-NN sử dụng zi và các biểu diễn LTM, sử dụng khoảng cách L2 chuẩn hóa: ∥ϕ(cj∗mj)−ϕ(zi∗mj)∥2
2
Ở đây, cj là một biểu diễn trong LTM, ϕ là chuẩn hóa L2 và mj là mặt nạ chọn các chiều được lưu trữ.
4 Kết quả Thí nghiệm
Phần này so sánh SHARP với các phương pháp CL tiên tiến trên năm chuỗi CIL. Ba chuỗi đầu tiên
bao gồm năm tập học, được tạo ra từ các tập dữ liệu MNIST, FMNIST và CIFAR10. Mỗi tập bao
gồm hai lớp liền kề. Chuỗi thứ tư dựa trên EMNIST và bao gồm 26 chữ cái tiếng Anh. Chữ thường
và chữ hoa được ánh xạ đến cùng lớp. Cuối cùng, chuỗi thứ năm dựa trên tập dữ liệu CIFAR100,
trong đó một tập học có 10 lớp liên tiếp, dẫn đến 10 tập. STM của SHARP chỉ giữ các kích hoạt từ
tập trước đó (tức là m= 1). Chúng tôi đo kích thước bộ nhớ phát lại bằng megabyte cho tất cả baseline,
như được mô tả chi tiết trong Tài liệu Bổ sung.
Đối với MNIST, FMNIST và EMNIST, mạng của chúng tôi có hai lớp tích chập (16 bộ lọc) và
một lớp tuyến tính ẩn với 500 đơn vị, theo sau là một lớp đầu ra. Trong trường hợp CIFAR10 và
CIFAR100, chúng tôi sử dụng bảy lớp tích chập và một lớp tuyến tính ẩn duy nhất với 1024 đơn vị,
dẫn đến một lớp đầu ra. Kiến trúc này dựa trên VGG-16, nhưng chúng tôi giảm độ sâu và độ rộng
của nó vì các tập dữ liệu của chúng tôi nhỏ hơn. Trong tất cả các mô hình baseline, độ rộng của lớp
đầu ra bằng số lượng lớp. Tuy nhiên, vì SHARP học các biểu diễn, lớp đầu ra của nó duy trì cùng
độ rộng với lớp trước đó. Điều này không có nghĩa là SHARP có nhiều tham số hơn. Ngược lại,
SHARP sử dụng các mạng thưa thớt và cắt tỉa 60% kết nối (siêu tham số cố định), dẫn đến ít tham
số tổng thể hơn. Để biết thêm thông tin, vui lòng tham khảo Tài liệu Bổ sung.

--- TRANG 8 ---
4.1 So sánh với Các Phương pháp Phát lại Kích hoạt
Chúng tôi so sánh SHARP với hai phương pháp phát lại kích hoạt, REMIND và Brain-inspired Replay (BIR).
Như đã đề cập trong phần Nghiên cứu liên quan, các phương pháp này giả định rằng các lớp không
phải đối tượng phát lại đã trải qua tiền huấn luyện và đóng băng. Vì vậy, chúng tôi tiền huấn luyện
chúng trên MNIST và sau đó dạy tuần tự EMNIST và CIFAR10, tiếp theo là học tuần tự CIFAR100.
Lưu ý rằng SHARP không yêu cầu tiền huấn luyện và đóng băng như vậy, vì nó có thể liên tục học
biểu diễn ngay cả trong các lớp trước đó. Tuy nhiên, điều này đặt SHARP vào một kịch bản thách
thức hơn đáng kể. Do đó, chúng tôi cũng tiền huấn luyện mô-đun G(·) cho SHARP để có sự so sánh
công bằng. Ngoài ra, chúng tôi đặt xếp hạng của các đơn vị trong G(·) đến xếp hạng tối đa có thể
(tức là E) để đảm bảo logic xếp hạng hoạt động. Cuối cùng, chúng tôi bỏ qua bước cắt tỉa cho G(·)
vì không cần thiết phải tách biệt các đơn vị đóng băng và tiền huấn luyện.
Điểm cắt phát lại của SHARP và REMIND là sau hai lớp đầu tiên cho EMNIST và sau bốn lớp đầu
tiên cho CIFAR100. Chúng tôi tiền huấn luyện/đóng băng tất cả các lớp tích chập cho BIR như được
đề xuất trong [ 57]. REMIND được đề xuất cho học trực tuyến — một epoch duy nhất và kích thước
batch là 1. Do đó, chúng tôi đã điều chỉnh nó cho cài đặt batch và nhiều epoch theo [22]. Xem Tài
liệu Bổ sung để biết chi tiết.
Hình 2 hiển thị kết quả. Thứ nhất, chúng tôi quan sát thấy rằng BIR hoạt động kém hơn cả REMIND
và SHARP. Chúng tôi nghi ngờ rằng điều này là do BIR dựa vào các biểu diễn được tạo ra. Kết quả
là, hiệu suất của BIR phụ thuộc rất nhiều vào chất lượng và đa dạng của các kích hoạt được tạo ra.
Có thể thách thức để đảm bảo rằng các kích hoạt này có chất lượng cao, đặc biệt trong cài đặt liên
tục. Ngược lại, REMIND và SHARP phát lại các kích hoạt thực tế, đáng tin cậy và mạnh mẽ hơn.
Chúng tôi tin rằng đây là lý do tại sao REMIND và SHARP có thể đạt được hiệu suất tốt hơn BIR.
Thứ hai, chúng tôi nhận thấy rằng REMIND ngang bằng hoặc vượt trội một chút so với SHARP khi
số lượng lớp đã thấy nhỏ. Tuy nhiên, khi chúng ta thấy nhiều lớp hơn, SHARP vượt qua REMIND.
Điều này là dự kiến vì khi chúng ta tiến bộ trong học tập, REMIND cần phát lại đồng đều tất cả các
lớp trong quá khứ và chia sẻ bộ nhớ cố định cho nhiều lớp hơn. Do đó, công việc của REMIND trở
nên khó khăn hơn khi chúng ta thấy nhiều lớp hơn, trong khi SHARP chỉ lưu trữ và phát lại các lớp
từ tập trước đó. Điều này làm cho việc phát lại của SHARP không phụ thuộc vào số lượng lớp đã
thấy và mạnh mẽ hơn cho các chuỗi dài hơn. Cuối cùng, điển hình cho các phương pháp CL thể hiện
hiệu suất thấp hơn so với mô hình học tất cả các lớp cùng nhau, đại diện cho giới hạn trên cho CL.
Điều này thúc đẩy nghiên cứu tương lai để thu hẹp khoảng cách hiệu suất.
4.2 So sánh với Các Phương pháp Phát lại Thô
Chúng tôi so sánh SHARP với các phương pháp phát lại thô tiên tiến. Ngược lại với REMIND và BIR,
SHARP và các phương pháp phát lại thô có thể liên tục trích xuất đặc trưng, vì vậy chúng tôi không
thực hiện tiền huấn luyện. Các baseline phát lại thô có lợi thế không công bằng vì chúng phát lại hình
ảnh thay vì kích hoạt và tất cả các lớp trong quá khứ thay vì chỉ vài lớp gần đây. Để đảm bảo so sánh
công bằng, chúng tôi sử dụng ngân sách bộ nhớ cố định, vì vậy cả SHARP và các baseline đều có
nền tảng bình đẳng về megabyte được sử dụng để lưu trữ các mẫu phát lại. Xem Tài liệu Bổ sung để
biết thêm chi tiết và kết quả bổ sung.
Bảng 1 hiển thị kết quả độ chính xác cho SHARP và năm phương pháp baseline, cùng với huấn luyện
Chung (giới hạn trên) và SGD tiêu chuẩn (giới hạn dưới), trên tất cả các lớp sau tất cả các tập. Chúng
tôi quan sát thấy rằng SHARP vượt trội đáng kể so với tất cả baseline trên tất cả các tập dữ liệu ngoại
trừ iCaRL trên CIFAR10. Theo hiểu biết của chúng tôi, đây là lần đầu tiên một phương pháp CL đã
vượt qua các phương pháp dựa trên phát lại trong bối cảnh CIL mà không yêu cầu phát lại tất cả các
lớp đã gặp trước đó. Chúng tôi hy vọng thành tựu này sẽ truyền cảm hứng cho nghiên cứu tương lai
tập trung vào phát lại lấy cảm hứng từ thần kinh thay vì cố gắng xấp xỉ các phân phối dữ liệu tĩnh
bằng cách trộn dữ liệu mới với các mẫu được chọn từ tất cả các lớp trong quá khứ.
Bên cạnh SHARP, iCaRL cũng cho thấy hiệu suất mạnh mẽ. Thú vị là, iCaRL sử dụng bộ phân loại
nearest-mean-of-exemplars, tương tự như cơ chế k-NN được sử dụng trong LTM của chúng tôi. Sự
tương đồng này thúc đẩy chúng tôi xem xét kỹ iCaRL để tìm các cải tiến tiềm năng có thể áp dụng
cho SHARP trong nghiên cứu tương lai. Ví dụ, thay vì chọn mẫu ngẫu nhiên như SHARP, iCaRL
ưu tiên chọn các mẫu làm cho kích hoạt lớp gần cuối trung bình trên tất cả các mẫu lớp được lưu trữ
xấp xỉ tốt nhất kích hoạt trung bình trên tất cả các ví dụ đã thấy của một lớp. Điều này đảm bảo rằng
iCaRL có vector trung bình lớp tốt nhất trong bộ phân loại. Một kỹ thuật tương tự có thể được áp dụng
cho SHARP. Hơn nữa, điều này có thể giải thích tại sao iCaRL vượt trội so với SHARP trên CIFAR10
vì việc chọn ngẫu nhiên có thể không cung cấp cho SHARP các biểu diễn tối ưu cho bộ phân loại
k-NN, đặc biệt trong các tập dữ liệu như CIFAR10 nơi các ví dụ trong cùng lớp có thể khác nhau đáng
kể (ví dụ, hai chữ "A" viết tay có thể xuất hiện khá giống nhau, nhưng hai hình ảnh mèo có thể khác
nhau rất nhiều).

--- TRANG 9 ---
Bảng 1: Độ chính xác trung bình trên các lớp sau tất cả các tập. MNIST/FMNIST/EMNIST bộ nhớ:
0.0392 MB (50 hình ảnh), CIFAR10 bộ nhớ: 1.6384 MB ( ≈534 hình ảnh), CIFAR100 bộ nhớ: 4.096
MB (≈1334 hình ảnh). Xem Tài liệu Bổ sung để biết kết quả với các ngân sách khác.
Phương pháp MNIST FMNIST EMNIST CIFAR10 CIFAR100
Chung 98.0 (±0.0)86.6 (±1.0)91.0 (±0.3)70.8 (±0.4)33.9 (±0.8)
SHARP 88.0 (±1.3)72.5 (±2.5)55.9 (±3.1)46.3 (±2.7)23.1 (±0.2)
iCaRL[47] 85.1 (±0.5)70.7 (±0.7)55.1 (±0.6)53.0 (±0.8)21.4 (±0.5)
DER [6] 82.7 (±2.7)72.2 (±0.4)44.6 (±4.1)37.6 (±0.9)16.6 (±0.3)
ER [48] 69.1 (±2.7)66.8 (±1.6)29.9 (±0.9)32.8 (±1.0)11.4 (±0.1)
FDR [4] 76.5 (±1.1)65.0 (±4.2)32.5 (±2.1)30.1 (±4.3)8.7 (±0.5)
A-GEM [9] 30.0 (±5.5)40.9 (±1.9)9.5 (±0.3)19.5 (±0.7)6.5 (±0.2)
SGD 19.8 (±0.1)16.6 (±4.7)3.9 (±0.0)16.0 (±4.2)6.6 (±0.1)
Hình 3: T) Độ chính xác trên tất cả các lớp. P) Các đơn vị xếp hạng-0 còn lại khi số lượng lớp tăng lên.
4.3 SHARP có Cần Ranh giới Tập không?
Trong các thí nghiệm trước đó, chúng tôi đã chứng minh kịch bản tồi tệ nhất của CIL, nơi mỗi lớp
chỉ xuất hiện một lần, và tất cả các tập chứa các lớp riêng biệt. Tuy nhiên, một số bước của SHARP,
như gán các đơn vị cụ thể cho một số tập hoặc đóng băng các kết nối nhất định, có thể được coi là
tận dụng sự sắp xếp có tổ chức cao và không chồng chéo này. Trong thế giới thực, sự khác biệt giữa
các tập có thể trở nên mờ nhạt, và chúng có thể có các lớp chồng chéo.
Để trả lời điều này, chúng tôi giới thiệu một cách đơn giản để tạo ra các chuỗi CIL nhiễu và kiểm
tra hành vi của SHARP trên chúng. Chúng tôi tạo các chuỗi nhiễu này bằng cách khởi tạo hai tập,
N và S, tập các lớp mới và đã thấy trước đó, tương ứng. Ban đầu, tất cả các lớp đều ở trong N, và
S trống. Sau đó chúng tôi có hai siêu tham số: c, số lượng lớp mỗi tập, và η, xác suất thay thế một
lớp từ tập trước đó bằng một lớp mới – chúng tôi thay thế nó bằng một lớp đã thấy với xác suất 1−η.
Trong trường hợp này, huấn luyện chung tiêu chuẩn xảy ra khi η= 0 và c= tổng số lớp. Ngược lại,
nếu η= 1, chúng ta có kịch bản CIL điển hình với các tập không chồng chéo. Nói cách khác, tăng η
chuyển cài đặt từ i.i.d. sang CIL.
Hình 3-trái hiển thị độ chính xác sau tất cả các tập cho các chuỗi khác nhau được tạo bằng cách thay
đổi η và c. Thứ nhất, giá trị η nhỏ hơn thường dẫn đến hiệu suất tốt hơn. Điều này trực quan vì giá
trị η nhỏ hơn có nghĩa là SHARP có nhiều khả năng thấy cùng lớp nhiều lần, cho phép SHARP học
lớp kỹ lưỡng hơn và cải thiện độ chính xác của nó.
Một câu hỏi quan trọng khác là liệu việc gặp cùng các lớp nhiều lần có sẽ kích hoạt tuyển dụng nhiều
đơn vị xếp hạng-1 hơn và dẫn đến việc giảm nhanh các đơn vị xếp hạng-0. Nếu điều này xảy ra,
SHARP sẽ hết dung lượng vì các đơn vị xếp hạng-0 được dành riêng cho tương lai và chỉ ra khả năng
học còn lại của mô hình. Hình 3-phải minh họa những thay đổi trong các đơn vị xếp hạng-0. Ở đây,
chúng ta thấy rằng khi SHARP trở nên thành thạo hơn trong việc phát hiện các lớp, nó cần phân bổ
ít đơn vị hơn để học nhiều lớp hơn. Nói cách khác, SHARP dựa vào kiến thức trong quá khứ để
nhanh chóng học các lớp mới mà không làm giảm khả năng học. Hơn nữa, nếu hai tập liên tiếp tương
tự (ví dụ, chỉ một lớp mới), nó sử dụng ít đơn vị xếp hạng-0 để học, có nghĩa là SHARP có khả năng
phát hiện tính mới lạ ngầm định. Nhìn chung, mặc dù một số bước thuật toán của SHARP dựa vào
ranh giới tập, nó mạnh mẽ trong các kịch bản nơi các tập trở nên mờ nhạt và có thể bao gồm các lớp
chồng chéo.

--- TRANG 10 ---
5 Kết luận và Công việc Tương lai
SHARP là một phương pháp phát lại lấy cảm hứng từ thần kinh mới lạ cho học liên tục. Theo hiểu
biết tốt nhất của chúng tôi, nó độc đáo ở chỗ có thể tránh quên lãng chỉ bằng cách phát lại các lớp
gần đây đã gặp. Hơn nữa, không giống như các phương pháp phát lại kích hoạt khác, nó không yêu
cầu bộ trích xuất đặc trưng được tiền huấn luyện; thay vào đó, nó có thể học trích xuất đặc trưng liên
tục. Chúng tôi đã chứng minh rằng SHARP vượt trội so với các phương pháp tiên tiến trên một số
tập dữ liệu chuẩn. Ngoài ra, chúng tôi đã chỉ ra rằng SHARP linh hoạt và xử lý các kịch bản nơi các
tập không có cấu trúc cao và có thể chứa các lớp chồng chéo.
Việc phát lại của SHARP tương tự như giấc ngủ NREM (Non-rapid eye movement) và phát lại thức
trong não bộ. Tuy nhiên, nó không bao gồm giấc ngủ REM, một phần thiết yếu của củng cố ký ức
trong não bộ. Trong giấc ngủ REM, não bộ tổ chức các ký ức dài hạn mà không có đầu vào bên ngoài
để ngăn ngừa can thiệp giữa các ký ức và cải thiện khả năng khái quát hóa. Trong công việc tương
lai, chúng tôi dự định kết hợp một mô-đun học metric vào LTM của chúng tôi để tăng cường khả
năng khái quát hóa của các biểu diễn LTM mà không có đầu vào bên ngoài. Mô-đun này sẽ liên tục
cập nhật hàm khoảng cách được sử dụng cho phân loại dựa trên các ký ức hiện có, tương tự như tổ
chức lại ký ức trong giấc ngủ REM.

--- TRANG 11 ---
Tài liệu tham khảo
[1]Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M., and Tuytelaars, T. (2018). Memory
aware synapses: Learning what (not) to forget. In The European Conference on Computer Vision
(ECCV) .
[2]Amano, H. and Maruyama, I. (2011). Aversive olfactory learning and associative long-term
memory in caenorhabditis elegans. Learning & memory (Cold Spring Harbor, N.Y.) ,18, 654–65.
[3]Atkinson, C., McCane, B., Szymanski, L., and Robins, A. V . (2018). Pseudo-recursal: Solving
the catastrophic forgetting problem in deep neural networks. arXiv preprint ,abs/1802.03875 .
[4]Benjamin, A. S., Rolnick, D., and Körding, K. P. (2018). Measuring and regularizing networks
in function space. CoRR ,abs/1805.08289 .
[5]Boschini, M., Bonicelli, L., Buzzega, P., Porrello, A., and Calderara, S. (2022). Class-incremental
continual learning into the extended der-verse. IEEE Transactions on Pattern Analysis and Machine
Intelligence .
[6]Buzzega, P., Boschini, M., Porrello, A., Abati, D., and Calderara, S. (2020). Dark experience
for general continual learning: a strong, simple baseline. In Advances in Neural Information
Processing Systems , volume 33.
[7]Caccia, L., Aljundi, R., Asadi, N., Tuytelaars, T., Pineau, J., and Belilovsky, E. (2022). New
insights on reducing abrupt representation change in online continual learning.
[8]Carr, M., Jadhav, S., and Frank, L. (2011). Hippocampal replay in the awake state: A potential
substrate for memory consolidation and retrieval. Nature neuroscience ,14, 147–53.
[9]Chaudhry, A., Ranzato, M., Rohrbach, M., and Elhoseiny, M. (2018a). Efficient lifelong learning
with A-GEM. CoRR ,abs/1812.00420 .
[10] Chaudhry, A., Dokania, P. K., Ajanthan, T., and Torr, P. H. (2018b). Riemannian walk for
incremental learning: Understanding forgetting and intransigence. In Proceedings of the European
Conference on Computer Vision (ECCV) .
[11] Chechik, G., Meilijson, I., and Ruppin, E. (1998). Synaptic pruning in development: A
computational account. Neural computation ,10, 1759–77.
[12] Cichon, J. and Gan, W.-B. (2015). Branch-specific dendritic ca2+ spikes cause persistent
synaptic plasticity. Nature ,520.
[13] Davidson, T., Kloosterman, F., and Wilson, M. (2009). Hippocampal replay of extended
experience. Neuron ,63, 497–507.
[14] Dohare, S., Mahmood, A. R., and Sutton, R. S. (2021). Continual backprop: Stochastic gradient
descent with persistent randomness. CoRR ,abs/2108.06325 .
[15] Dupret, D., O'Neill, J., Pleydell-Bouverie, B., and Csicsvari, J. (2010). The reorganization and
reactivation of hippocampal maps predict spatial memory performance. Nature neuroscience ,13,
995 – 1002.
[16] Golkar, S., Kagan, M., and Cho, K. (2019). Continual learning via neural pruning. arXiv
preprint ,abs/1903.04476 .
[17] Guo, Y ., Liu, Y ., Oerlemans, A., Lao, S., Wu, S., and Lew, M. S. (2016). Deep learning for
visual understanding: A review. Neurocomputing ,187.
[18] Gurbuz, M. B. and Dovrolis, C. (2022). Nispa: Neuro-inspired stability-plasticity adaptation
for continual learning in sparse networks. International Conference on Machine Learning ,30.
[19] Hadsell, R., Rao, D., Rusu, A. A., and Pascanu, R. (2020). Embracing change: Continual
learning in deep neural networks. Trends in Cognitive Sciences ,24.
[20] Hassabis, D., Kumaran, D., Summerfield, C., and Botvinick, M. (2017). Neuroscience-inspired
artificial intelligence. Neuron ,95.

--- TRANG 12 ---
[21] Hayashi-Takagi, A., Yagishita, S., Nakamura, M., Shirai, F., Wu, Y ., Loshbaugh, A., Kuhlman,
B., Hahn, K., and Kasai, H. (2015). Labelling and optical erasure of synaptic memory traces in
the motor cortex. Nature ,525.
[22] Hayes, T., Kafle, K., Shrestha, R., Acharya, M., and Kanan, C. (2020). REMIND Your Neural
Network to Prevent Catastrophic Forgetting , pages 466–483.
[23] Hayes, T. L., Krishnan, G. P., Bazhenov, M., Siegelmann, H. T., Sejnowski, T. J., and Kanan,
C. (2021). Replay in deep learning: Current approaches and missing biological elements. arXiv
preprint ,abs/2104.04132 .
[24] Holmgren, C., Harkany, T., Svennenfors, B., and Zilberter, Y . (2003). Pyramidal cell com-
munication within local networks in layer 2/3 of rat neocortex. The Journal of physiology ,551,
139–53.
[25] Hunter, K. L., Spracklen, L., and Ahmad, S. (2021). Two sparsities are better than one:
unlocking the performance benefits of sparse–sparse networks. Neuromorphic Computing and
Engineering ,2.
[26] Ji, D. and Wilson, M. (2007). Coordinated memory replay in the visual cortex and hippocampus
during sleep. Nature neuroscience ,10, 100–7.
[27] Johnson, J., Douze, M., and Jégou, H. (2019). Billion-scale similarity search with GPUs. IEEE
Transactions on Big Data ,7(3), 535–547.
[28] Jung, S., Ahn, H., Cha, S., and Moon, T. (2020). Continual learning with node-importance based
adaptive group sparse regularization. In Advances in Neural Information Processing Systems ,
volume 33.
[29] Karlsson, M. and Frank, L. (2009). Awake replay of remote experiences in the hippocampus.
Nature neuroscience ,12, 913–8.
[30] Khosla, P., Teterwak, P., Wang, C., Sarna, A., Tian, Y ., Isola, P., Maschinot, A., Liu, C., and
Krishnan, D. (2020). Supervised contrastive learning. CoRR ,abs/2004.11362 .
[31] Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A. A., Milan,
K., Quan, J., Ramalho, T., Grabska-Barwinska, A., Hassabis, D., Clopath, C., Kumaran, D., and
Hadsell, R. (2017). Overcoming catastrophic forgetting in neural networks. Proceedings of the
National Academy of Sciences ,114.
[32] Lange, M. D., Aljundi, R., Masana, M., Parisot, S., Jia, X., Leonardis, A., Slabaugh, G. G.,
and Tuytelaars, T. (2019). Continual learning: A comparative study on how to defy forgetting in
classification tasks. arXiv preprint ,abs/1909.08383 .
[33] LeCun, Y ., Bengio, Y ., and Hinton, G. (2015). Deep learning. Nature ,521.
[34] Lesort, T., George, T., and Rish, I. (2021). Continual learning in deep networks: an analysis of
the last layer. CoRR ,abs/2106.01834 .
[35] Liang, Y ., Ryali, C., Hoover, B., Grinberg, L., Navlakha, S., Zaki, M. J., and Krotov, D. (2021).
Can a fruit fly learn word embeddings? In International Conference on Learning Representations .
[36] Lomonaco, V ., Pellegrini, L., Cossu, A., Carta, A., Graffieti, G., Hayes, T. L., Lange, M. D.,
Masana, M., Pomponi, J., van de Ven, G., Mundt, M., She, Q., Cooper, K., Forest, J., Belouadah,
E., Calderara, S., Parisi, G. I., Cuzzolin, F., Tolias, A., Scardapane, S., Antiga, L., Amhad, S.,
Popescu, A., Kanan, C., van de Weijer, J., Tuytelaars, T., Bacciu, D., and Maltoni, D. (2021).
Avalanche: an end-to-end library for continual learning. In Proceedings of IEEE Conference on
Computer Vision and Pattern Recognition , 2nd Continual Learning in Computer Vision Workshop.
[37] Louie, K. and Wilson, M. (2001). Temporally structured replay of awake hippocampal ensemble
activity during rapid eye movement sleep. Neuron ,29, 145–56.

--- TRANG 13 ---
[38] Markram, H., Muller, E., Ramaswamy, S., Reimann, M., Abdellah, M., Sanchez, C., Ailamaki,
A., Alonso-Nanclares, L., Antille, N., Arsever, S., Guy Antoine, A. K., Berger, T., Bilgili, A.,
Buncic, N., Chalimourda, A., Chindemi, G., Courcol, J.-D., Delalondre, F., Delattre, V ., and
Schürmann, F. (2015). Reconstruction and simulation of neocortical microcircuitry. Cell,163,
456–492.
[39] McCloskey, M. and Cohen, N. J. (1989). Catastrophic interference in connectionist networks:
The sequential learning problem. Psychology of Learning and Motivation .
[40] Nadasdy, Z., Hirase, H., Czurkó, A., Csicsvari, J., and Buzsáki, G. (1999). Replay and time
compression of recurring spike sequences in the hippocampus. The Journal of neuroscience : the
official journal of the Society for Neuroscience ,19, 9497–507.
[41] O'Neill, J., Pleydell-Bouverie, B., Dupret, D., and Csicsvari, J. (2010). Play it again: Reactiva-
tion of waking experience and memory. Trends in neurosciences ,33, 220–9.
[42] Parisi, G. I., Kemker, R., Part, J. L., Kanan, C., and Wermter, S. (2019). Continual lifelong
learning with neural networks: A review. Neural Networks ,113.
[43] Pavlides, C. and Winson, J. (1989). Influences of hippocampal place cell firing in the awake
state on the activity of these cells during subsequent sleep episodes. The Journal of neuroscience :
the official journal of the Society for Neuroscience ,9(8), 2907—2918.
[44] Peyrache, A., Khamassi, M., Benchenane, K., Wiener, S., and Battaglia, F. (2009). Replay of
rule-learning related neural patterns in the prefrontal cortex during sleep. Nature neuroscience ,12,
919–26.
[45] Prabhu, A., Torr, P., and Dokania, P. (2020). Gdumb: A simple approach that questions our
progress in continual learning. In The European Conference on Computer Vision (ECCV) .
[46] Ramapuram, J., Gregorova, M., and Kalousis, A. (2020). Lifelong generative modeling.
Neurocomputing ,404.
[47] Rebuffi, S.-A., Kolesnikov, A., Sperl, G., and Lampert, C. (2017). icarl: Incremental classifier
and representation learning. In IEEE Conference on Computer Vision and Pattern Recognition
(CVPR) .
[48] Rolnick, D., Ahuja, A., Schwarz, J., Lillicrap, T., and Wayne, G. (2019). Experience replay for
continual learning. In Advances in Neural Information Processing Systems , volume 32.
[49] Rosenfeld, A. and Tsotsos, J. K. (2018). Incremental learning through deep adaptation. IEEE
transactions on pattern analysis and machine intelligence ,42.
[50] Rusu, A. A., Rabinowitz, N. C., Desjardins, G., Soyer, H., Kirkpatrick, J., Kavukcuoglu, K.,
Pascanu, R., and Hadsell, R. (2016). Progressive neural networks. arXiv preprint ,abs/1606.04671 .
[51] Sasakura, H. and Mori, I. (2012). Behavioral plasticity, learning, and memory in c. elegans.
Current opinion in neurobiology ,23.
[52] Serra, J., Suris, D., Miron, M., and Karatzoglou, A. (2018). Overcoming catastrophic forgetting
with hard attention to the task. In International Conference on Machine Learning .
[53] Shin, H., Lee, J. K., Kim, J., and Kim, J. (2017). Continual learning with deep generative replay.
Advances in neural information processing systems ,30.
[54] Silver, D., Huang, A., Maddison, C., Guez, A., Sifre, L., Driessche, G., Schrittwieser, J.,
Antonoglou, I., Panneershelvam, V ., Lanctot, M., Dieleman, S., Grewe, D., Nham, J., Kalchbrenner,
N., Sutskever, I., Lillicrap, T., Leach, M., Kavukcuoglu, K., Graepel, T., and Hassabis, D. (2016).
Mastering the game of go with deep neural networks and tree search. Nature ,529.
[55] Sokar, G., Mocanu, D. C., and Pechenizkiy, M. (2021). Spacenet: Make free space for continual
learning. Neurocomputing ,439.
[56] Teyler, T. and Rudy, J. (2007). The hippocampal indexing theory and episodic memory:
Updating the index. Hippocampus ,17, 1158–69.

--- TRANG 14 ---
[57] van de Ven, G., Siegelmann, H., and Tolias, A. (2020). Brain-inspired replay for continual
learning with artificial neural networks. Nature Communications ,11.
[58] van de Ven, G. M. and Tolias, A. S. (2019). Three scenarios for continual learning. arXiv
preprint ,abs/1904.07734 .
[59] Wilson, M. A. and McNaughton, B. L. (1994). Reactivation of hippocampal ensemble memories
during sleep. Science ,265(5172), 676–679.
[60] Yang, G., Pan, F., and Gan, W.-B. (2009). Stably maintained dendritic spines are associated
with lifelong memories. Nature ,462.
[61] Yoon, J., Yang, E., Lee, J., and Hwang, S. J. (2018). Lifelong learning with dynamically
expandable networks. In International Conference on Learning Representations .
[62] Zenke, F., Poole, B., and Ganguli, S. (2017). Continual learning through synaptic intelligence.

--- TRANG 15 ---
Tài liệu Bổ sung
A Chứng minh Tối ưu Thuật toán Tham lam
Nhớ lại rằng chúng tôi tính toán kích hoạt ở mỗi lớp trên một số ví dụ tập như sau:
Al=X
x∼Deal(x) =X
x∼DeX
ul
i∈Ulaul
i(x) (4)
Ở đây, aul
i(x) là kích hoạt của đơn vị i ở lớp l cho mẫu x và al(x) là tổng kích hoạt của lớp
l cho mẫu x. Hệ thống xếp hạng của chúng tôi dựa vào việc giải quyết bài toán tối ưu có ràng buộc sau:
min
Pl
1⊆Ul
r<2|Pl
1|subject toX
x∼DeX
ul
i∈Pl
1aul
i(x)≥τAl−X
ul
i∈Ul
r≥2aul
i(x) (5)
trong đó 0≤τ≤1 và Pl
1 là tập các đơn vị chúng tôi thăng cấp lên xếp hạng-1. Lưu ý rằng vế phải
của bất đẳng thức không chứa tập trong mục tiêu tối thiểu hóa. Vì vậy, chúng tôi thay thế nó bằng
một hằng số:
min
Pl
1⊆Ul
r<2|Pl
1|subject toX
x∼DeX
ul
i∈Pl
1aul
i(x)≥T (6)
Ở đây, chúng ta có một tập các đơn vị Ul
r<2 với xếp hạng nhỏ hơn 2 mà chúng ta có thể chọn. Đơn vị i
trong tập này có tổng kích hoạt là P
x∼Deaul
i(x). Mục tiêu của chúng ta là chọn số lượng tối thiểu
các đơn vị trong Ul
r<2 để đạt được hoặc vượt quá mục tiêu T. Chúng tôi đề xuất thuật toán tham lam
đơn giản sau:
• Sắp xếp các đơn vị trong Ul
r<2 dựa trên kích hoạt của chúng P
x∼Deaul
i(x) theo thứ tự giảm dần.
•Chọn đơn vị có tổng kích hoạt lớn nhất và thêm vào Pl
1 cho đến khi chúng ta đạt được hoặc vượt
quá mục tiêu T.
Chứng minh: Chúng tôi sẽ chỉ ra rằng thuật toán tham lam tìm một nghiệm với tổng kích hoạt ít nhất
T, sử dụng ít hơn hoặc bằng số đơn vị so với bất kỳ thuật toán tối ưu nào khác. Để chứng minh điều
này, chúng tôi so sánh các tổng riêng phần của kích hoạt cho cả hai thuật toán ở mỗi bước. Cho Ak
là tổng kích hoạt cho k đơn vị đầu tiên (tức là Ak=Pk
i=1ai) được chọn bởi thuật toán tham lam, và
Bk là tổng kích hoạt cho k đơn vị đầu tiên (tức là Bk=Pk
i=1bi) được chọn bởi thuật toán tối ưu.
Chúng tôi sử dụng quy nạp để chứng minh rằng Ak≥Bk cho tất cả k. Trường hợp cơ sở là tầm thường,
vì A0=B0= 0. Cho bước quy nạp, giả sử rằng Ak−1≥Bk−1. Sau đó, vì thuật toán tham lam chọn
đơn vị có kích hoạt cao nhất ở mỗi bước, chúng ta có ak≥bk. Do đó, Ak=Ak−1+ak≥Bk−1+bk=Bk.
Vì vậy, bằng quy nạp, chúng ta có Ak≥Bk cho tất cả k. Thuật toán tham lam được đảm bảo đạt được
tổng mục tiêu T bằng cách chọn ít hơn hoặc bằng số đơn vị như thuật toán tối ưu.

--- TRANG 16 ---
B Mã giả SHARP
Thuật toán 1 Thuật toán SHARP cho một Tập đơn lẻ
Require: De,G,F, STM, LTM ▷Yêu cầu Tập dữ liệu Tập, mô-đun G, mô-đun F, STM, LTM
forevery phase p trong Tập do
τp←max( τmin,1
2
1 + cosp+1
k×π
)▷Xác định τp sử dụng lịch ủ cosine
Pl
1←Selection (De, G, F, τ p) ▷Chọn các đơn vị xếp hạng-1 sử dụng kích hoạt
G, F←Drop (G, F) ▷Loại bỏ kết nối từ đơn vị xếp hạng-0 đến xếp hạng-1
G, F←Grow (G, F) ▷Phát triển một kết nối đến cho xếp hạng-0 cho mỗi kết nối đã loại bỏ
G, F←Train (G, F, D e,STM ) ▷Huấn luyện mạng trong số epoch cố định
end for
# Kết thúc một tập
G, F←Promote (G, F) ▷Tăng tất cả xếp hạng lớn hơn 0 lên một
G, F←Freeze (G, F) ▷Đóng băng kết nối đến dựa trên quy tắc đóng băng
STM←Update_STM (G,STM, De)▷Lấy mẫu các ví dụ từ De và đẩy kích hoạt vào STM
LTM ←Update_LTM (F,STM ) ▷Tạo vài biểu diễn LTM cho các lớp trong STM
STM←Purge_STM (STM ) ▷Loại bỏ các lớp cũ nhất để tạo không gian
G, F←Reinit_Rank0 (G, F) ▷Khởi tạo lại kết nối đến của các Đơn vị xếp hạng-0
# SHARP sẵn sàng xử lý tập tiếp theo
C Chi tiết Thí nghiệm
C.1 Chi tiết Kiến trúc
Trong các thí nghiệm của chúng tôi, chúng tôi sử dụng hai kiến trúc khác nhau – một cho MNIST/FashionMNIST/EM-
NIST và một cho CIFAR10/CIFAR100. Các thông số kỹ thuật đầy đủ cho mỗi kiến trúc được
cung cấp trong Danh sách 1 và Danh sách 2.
Các kiến trúc cho Brain-inspired Replay (BIR) khác một chút do tính chất sinh tạo của nó. BIR
bao gồm các trọng số sinh tạo bổ sung, bao gồm các phiên bản đảo ngược của các lớp tuyến tính và
một vài bộ trọng số bổ sung. Hơn nữa, đối với CIFAR10/100, BIR sử dụng hai lớp tuyến tính với
2000 đơn vị mỗi lớp, thay vì một lớp tuyến tính duy nhất với 1024 đơn vị được sử dụng trong các
baseline khác. Chúng tôi thực hiện sửa đổi này để đảm bảo rằng BIR có số lượng tham số học hợp
lý vì nó đóng băng tất cả các lớp tích chập sau tiền huấn luyện [ 57]. Kết quả từ các thành phần sinh
tạo và các tham số bổ sung được giới thiệu cho CIFAR10/100, BIR có nhiều tham số hơn so với
các phương pháp phát lại khác, bao gồm SHARP. Tuy nhiên, chúng tôi tin rằng điều này công bằng
vì BIR không lưu trữ kích hoạt hoặc mẫu đầu vào một cách rõ ràng. Thay vào đó, nó dựa vào các
trọng số bổ sung này để tạo ra chúng. Do đó, ngân sách bộ nhớ của nó được phân bổ cho các tham
số học bổ sung. Để biết thêm chi tiết, vui lòng tham khảo bài báo Brain-inspired Replay [57].
Đối với SHARP và REMIND [ 22], chúng tôi phân vùng kiến trúc thành các lớp nhận phát lại (tức là
F(·)) và những lớp không nhận (tức là G(·)). Như thấy trong Danh sách 1 và Danh sách 2, SHARP
và REMIND chia các mạng sau lớp tích chập thứ hai và thứ tư. Ngược lại, BIR chỉ phát lại thông
qua các lớp tuyến tính, trong khi tất cả các lớp tích chập được tiền huấn luyện và đóng băng, như
được đề xuất trong triển khai gốc.
Việc chọn nơi chia kiến trúc là rất quan trọng vì điểm cắt phát lại ảnh hưởng trực tiếp đến lượng
bộ nhớ cần thiết để lưu trữ các kích hoạt. Nếu điểm cắt được đặt quá thấp, các kích hoạt được lưu
trữ sẽ chiếm một lượng không gian lớn. Ngược lại, nếu nó được đặt quá cao, chỉ có vài lớp sẽ được
hưởng lợi từ phát lại, dẫn đến hiệu suất kém. Do đó, điều cần thiết là đạt được sự cân bằng giữa
việc lưu trữ các kích hoạt có kích thước nhỏ hơn và phát lại thông qua nhiều lớp hơn. Ngoài sự đánh
đổi này, SHARP cung cấp tính linh hoạt về cách mạng được chia thành hai. Thậm chí có thể bắt
đầu phát lại từ đầu vào, cung cấp một phiên bản phát lại thô của SHARP mà không cần sửa đổi gì.
Tuy nhiên, chúng tôi không chạy bất kỳ thí nghiệm nào với phiên bản này vì trọng tâm cốt lõi của
công việc chúng tôi là tránh phát lại các ví dụ thô.

--- TRANG 17 ---
C.2 Lượng tử hóa Tuyến tính và Ngân sách Bộ nhớ
Bộ nhớ Ngắn hạn (STM) được sử dụng bởi SHARP sử dụng lượng tử hóa tuyến tính để lưu trữ
hiệu quả các kích hoạt dấu phẩy động bằng một byte duy nhất. Lượng tử hóa tuyến tính bao gồm
việc ánh xạ các giá trị số liên tục thành một số lượng cố định các mức rời rạc, giảm độ chính xác
nhưng tăng hiệu quả lưu trữ. Để triển khai điều này, tensor được lưu trữ trước tiên được chia tỷ lệ
min-max và sau đó nhân với phạm vi lượng tử hóa 28−1 (với 8 đại diện cho số bit trong một byte).
Tensor chuẩn hóa kết quả được làm tròn đến số nguyên gần nhất và được biểu diễn bằng số nguyên
8-bit không dấu. Trong quá trình khử lượng tử hóa, các bước tương tự được thực hiện theo thứ tự
ngược lại. Mặc dù các kỹ thuật lượng tử hóa tiên tiến hơn tồn tại để giảm lỗi tái tạo và cải thiện
tỷ lệ nén, chúng tôi không tập trung vào việc tối ưu hóa quá trình này.
Bây giờ, hãy tính toán việc sử dụng bộ nhớ của một ví dụ duy nhất tính bằng megabyte cho các thí
nghiệm của chúng tôi. Đối với MNIST/FMNIST/EMNIST, chúng tôi lưu trữ các kích hoạt sau lớp
tích chập thứ hai. Trong trường hợp này, chúng ta có 16 bản đồ đặc trưng có kích thước 7×7. Mỗi
mục có thể được lưu trữ bằng một byte duy nhất. Do đó, tổng việc sử dụng bộ nhớ cho các kích hoạt
của một ví dụ duy nhất có thể được tính như sau:
16×7×7byte = 0.000784 MB
Nếu chúng tôi lưu trữ các ví dụ thô thay vì các kích hoạt, chúng tôi sẽ cần 28×28×1byte, cũng
bằng 0.000784 MB. Do đó, trong các thí nghiệm này, cả ví dụ thô và kích hoạt đều chiếm cùng
lượng bộ nhớ.
Đối với CIFAR10 và CIFAR100, chúng tôi lưu trữ các kích hoạt sau lớp tích chập thứ tư. Trong
trường hợp này, chúng ta có 64 bản đồ đặc trưng, mỗi bản có kích thước 8×8. Do đó, việc sử dụng
bộ nhớ cho một ví dụ duy nhất khi lưu trữ kích hoạt là:
64×8×8 = 0 .004096 MB
Tuy nhiên, nếu chúng tôi lưu trữ các ví dụ thô, chúng sẽ yêu cầu 32×32×3byte, tương đương với
0.003072 MB. Do đó, việc lưu trữ các ví dụ thô hiệu quả hơn trong trường hợp này. Điều quan
trọng cần lưu ý là các tính toán này cụ thể cho kiến trúc và điểm cắt phát lại. Do đó, nếu hiệu quả
bộ nhớ là mối quan tâm, điểm cắt phát lại hoặc kiến trúc của SHARP có thể được điều chỉnh cho
phù hợp.
SHARP không có lợi thế về số lượng mục được lưu trữ trong bộ nhớ trong bất kỳ thí nghiệm nào
của chúng tôi. Tuy nhiên, sức mạnh thực sự của SHARP nằm ở khả năng lưu trữ số lượng hạn chế
các lớp gần đây đã thấy. Điều này cho phép nó lưu trữ đáng kể nhiều ví dụ phát lại hơn mỗi lớp,
cung cấp một giải pháp hiệu quả để giảm thiểu quên lãng thảm khốc.
Cuối cùng, một số baseline phát lại kết hợp thông tin bổ sung cùng với các mẫu hoặc kích hoạt được
lưu trữ. Ví dụ, DER và FDR lưu trữ các đầu ra mạng cho mỗi mẫu được phát lại, trong khi SHARP
duy trì vài biểu diễn dài hạn mỗi lớp. Để duy trì sự đơn giản trong so sánh, chúng tôi không xem
xét các việc sử dụng bổ sung này như một phần của ngân sách bộ nhớ cố định. Đáng chú ý là các
việc sử dụng bổ sung này không đáng kể so với các mẫu hoặc kích hoạt được lưu trữ.
C.3 Chi tiết Thưa thớt hóa
Một chi tiết khác của SHARP là việc sử dụng kết nối thưa thớt. Ban đầu, các kiến trúc được làm
thưa thớt thông qua cắt tỉa ngẫu nhiên không có cấu trúc trên cơ sở từng lớp. Điều này có nghĩa là
mỗi kết nối trong một lớp có xác suất bằng nhau để bị loại bỏ, dẫn đến mật độ nhất quán trên tất cả
các lớp. Chúng tôi duy trì mức độ thưa thớt 60% hoặc tương đương, mật độ 40% trong tất cả các
thí nghiệm của chúng tôi. Để giữ mọi thứ đơn giản, chúng tôi không tối ưu hóa lựa chọn này cho
từng thí nghiệm riêng lẻ. Thay vào đó, chúng tôi dựa vào quyết định của mình dựa trên tinh chỉnh
siêu tham số thô trên CIFAR100 và áp dụng mức độ thưa thớt 60% một cách nhất quán trên tất cả
các tập dữ liệu. Xin lưu ý rằng tất cả các baseline khác được kết nối dày đặc và có nhiều tham số
học hơn đáng kể so với SHARP.

--- TRANG 18 ---
Trong các lớp tích chập, một "đơn vị" đề cập đến bộ lọc tích chập 3D, trong khi một "kết nối" đại
diện cho kernel 2D thay vì một trọng số riêng lẻ. Do đó, khi chúng tôi thực hiện các hành động như
loại bỏ hoặc đóng băng một kết nối, chúng tôi xem xét toàn bộ kernel 2D đại diện cho kết nối giữa
hai đơn vị. Công thức này giảm đáng kể số lượng phép toán dấu phẩy động (FLOP) bằng cách loại
bỏ các phép toán được thực hiện trên phần lớn các bản đồ đặc trưng 2D.
Điều quan trọng cần nhấn mạnh là lớp đầu tiên trong các kiến trúc tích chập không nên bị cắt tỉa.
Lý do đằng sau điều này là lớp đầu tiên nhận hình ảnh ba kênh làm đầu vào, và các đơn vị của nó
được kết nối với đầu vào chỉ thông qua ba kết nối. Nếu chúng ta cắt tỉa lớp đầu tiên, nó có thể sẽ
dẫn đến việc tạo ra nhiều "đơn vị chết" không có đầu vào ở lớp ban đầu. Ví dụ, ở mật độ 0.2, xác
suất các đơn vị trong lớp đầu tiên trở nên chết sẽ là (1−0.2)3= 0.512. Để tránh vấn đề này, nên
duy trì mật độ trong lớp đầu tiên. Quan trọng là, thay đổi này có tác động tối thiểu đến tổng số tham số.
Danh sách 1: Kiến trúc MNIST/FMNIST/EMNIST
[ G1 ] conv2d ( i n =3 , o u t =16 , k e r n e l =3 , s t r i d e =1)
[ G2 ] nn . ReLU ( )
[ G3 ] nn . MaxPool2d ( k e r n e l =2 , s t r i d e =2)
[ G3 ] conv2d ( i n =16 , o u t =16 , k e r n e l =3 , s t r i d e =1)
[ G4 ] nn . ReLU ( )
[ G5 ] nn . MaxPool2d ( k e r n e l =2 , s t r i d e =2)
−−−−−−−−−−−−−−−−−−−−−− Mô-đun Thứ hai Bắt đầu −−−−−−−−−−−−−−−−−−−−−−
[ F1 ] l i n e a r ( i n =16 *7*7 , o u t =500)
[ F2 ] nn . ReLU ( )
[ F3 ] l i n e a r ( i n =500 , o u t = n u m _ c l a s s e s (500 i f SHARP ) )
[ F4 ] nn . Sigmoid ( ) # Nếu SHARP nn . ReLU ( )
Danh sách 2: Kiến trúc CIFAR10/CIFAR100
[ G1 ] conv2d ( i n =3 , o u t =64 , k e r n e l =3 , s t r i d e =1)
[ G2 ] nn . ReLU ( )
[ G3 ] conv2d ( i n =64 , o u t =64 , k e r n e l =3 , s t r i d e =1)
[ G4 ] nn . ReLU ( )
[ G5 ] nn . MaxPool2d ( k e r n e l =2 , s t r i d e =2)
[ G6 ] conv2d ( i n =64 , o u t =64 , k e r n e l =3 , s t r i d e =1)
[ G7 ] nn . ReLU ( )
[ G8 ] conv2d ( i n =64 , o u t =64 , k e r n e l =3 , s t r i d e =1)
[ G9 ] nn . ReLU ( )
[ G10 ] nn . MaxPool2d ( k e r n e l =2 , s t r i d e =2)
−−−−−−−−−−−−−−−−−−−−−− Mô-đun Thứ hai Bắt đầu −−−−−−−−−−−−−−−−−−−−−−
[ F1 ] conv2d ( i n =64 , o u t =128 , k e r n e l =3 , s t r i d e =1)
[ F2 ] nn . ReLU ( )
[ F3 ] conv2d ( i n =128 , o u t =128 , k e r n e l =3 , s t r i d e =1)
[ F4 ] nn . ReLU ( )
[ F5 ] conv2d ( i n =128 , o u t =128 , k e r n e l =3 , s t r i d e =1)
[ F6 ] nn . ReLU ( )
[ F7 ] nn . MaxPool2d ( k e r n e l =2 , s t r i d e =2)
[ F8 ] l i n e a r ( i n =128 *4*4 , o u t =1024)
[ F9 ] nn . ReLU ( )
[ F10 ] l i n e a r ( i n =1024 , o u t = n u m _ c l a s s e s (1024 i f SHARP ) )
[ F11 ] nn . Sigmoid ( ) / / Nếu SHARP nn . ReLU ( )
C.4 Siêu tham số của SHARP
Mặc dù SHARP có một loạt các siêu tham số, các quan sát của chúng tôi chỉ ra rằng phần lớn chúng
không có tác động đáng kể đến hiệu suất của nó. Trên thực tế, các giá trị mặc định có xu hướng
mang lại kết quả thỏa đáng trên nhiều thí nghiệm. Trong phần phụ này, chúng tôi sẽ cung cấp
tổng quan toàn diện về tất cả các siêu tham số và đề xuất các giá trị mặc định được khuyến nghị
cho mỗi cái.

--- TRANG 19 ---
•Đối với kích thước cửa sổ thời gian của STM, chúng tôi đặt m= 1 cho tất cả các thí nghiệm,
nhưng bất kỳ giá trị nào cũng có thể được sử dụng mà không cần sửa đổi thuật toán.
•Số epoch mỗi giai đoạn ϵ thường được đặt thành 3 hoặc 5 để có hiệu suất tốt, nhưng các
tập dữ liệu phức tạp hơn có thể yêu cầu nhiều epoch hơn.
•Giá trị tối thiểu cho lịch ủ cosine, τmin, xác định τ có thể giảm đến mức nào. Nếu τmin nhỏ,
SHARP sẽ tuyển dụng ít đơn vị xếp hạng-0 hơn, điều này có thể ảnh hưởng đến hiệu suất
nhưng dành nhiều dung lượng hơn cho tương lai. Đối với các chuỗi dài hơn, τmin nhỏ hơn
được đề xuất, trong khi τmin lớn hơn tốt hơn cho các chuỗi ngắn hơn.
•Số giai đoạn π được xác định bởi độ phức tạp của tập dữ liệu, và π×ϵ cho tổng số epoch
huấn luyện mỗi một tập.
•Tham số k trong lịch ủ cosine xác định kích thước bước để giảm τ. Chúng tôi đặt k= 30
cho tất cả các thí nghiệm.
•Số lượng hàng xóm để sử dụng trong k-NN của LTM không rất nhạy cảm, và 5 có thể là
một siêu tham số mặc định tốt.
•Chúng tôi sử dụng 25 (MNIST/FMNIST/EMNIST) hoặc 50 (CIFAR10/100) biểu diễn LTM
mỗi lớp trong các thí nghiệm của chúng tôi, nhưng giá trị này không thể vượt quá số kích
hoạt mà STM lưu trữ mỗi lớp, vì các biểu diễn LTM được tạo bằng các mục STM.
•Supervised Contrastive Learning Loss nhiệt độ λ. Điều này không độc quyền với SHARP,
nhưng nó thường được đặt từ 0.05 đến 0.2 trong Supervised Contrastive Learning.
Bảng 2, chúng tôi cung cấp danh sách toàn diện tất cả các siêu tham số độc nhất với SHARP.
Cần lưu ý rằng chúng tôi đã thực hiện tinh chỉnh có hệ thống cho siêu tham số τmin, thử λ= 0.05,0.1,0.2
và thử 5 và 25 cho các hàng xóm k-NN của LTM, trong khi các siêu tham số còn lại được chọn dựa
trên các phỏng đoán có căn cứ. Các phần phụ sau cung cấp các siêu tham số tiêu chuẩn, bao gồm
tốc độ học, kích thước batch và chi tiết tối ưu hóa, cho cả SHARP và tất cả các baseline khác.
Bảng 2: Siêu tham số cụ thể của SHARP được sử dụng trong các thí nghiệm chính. Thú vị là đặt
số hàng xóm của LTM thành 25 cho hiệu suất tốt hơn cho FMNIST, vì vậy chúng tôi giữ nó ở 25.
Chúng tôi chỉ thử 5 hoặc 25 trong quá trình tinh chỉnh siêu tham số.
Thí nghiệm m ϵ τmin π k Hàng xóm LTM LTM mỗi lớp λ
Thí nghiệm từ Phần 4.2 của bài báo chính
MNIST 1 3 0.90 10 30 5 25 0.1
FMNIST 1 3 0.75 12 30 25 25 0.2
EMNIST 1 3 0.60 15 30 5 25 0.1
CIFAR10 1 5 0.70 15 30 5 50 0.2
CIFAR100 1 5 0.70 15 30 5 50 0.05
Dưới đây là các thí nghiệm với tiền huấn luyện (Phần 4.1 của bài báo chính)
EMNIST 1 3 0.40 15 30 5 25 0.05
CIFAR100 1 5 0.70 15 30 5 50 0.05
C.5 Chi tiết So sánh với Các Phương pháp Phát lại Kích hoạt
Trong Phần 4.1 của bài báo chính, chúng tôi so sánh SHARP với REMIND và BIR. Vì REMIND
và BIR yêu cầu tiền huấn luyện, trước tiên chúng tôi tiền huấn luyện trên MNIST trước khi dạy tuần
tự EMNIST, và trên CIFAR10 trước khi dạy tuần tự CIFAR100. Để đảm bảo so sánh công bằng,
chúng tôi lặp lại việc tiền huấn luyện cho SHARP. Chúng tôi chỉ tải trọng số tiền huấn luyện cho
các lớp không nhận phát lại và khởi tạo lại các lớp dẻo cho tất cả các phương pháp.
Cần lưu ý rằng SHARP sử dụng supervised contrastive learning loss cho tiền huấn luyện, vì nó
không có lớp phân loại. Ngoài ra, chúng tôi không thực hiện cắt tỉa cho mô-đun G(·) cho SHARP
vì không cần thiết phải tách biệt các lớp tiền huấn luyện. Cuối cùng, chúng tôi đặt các đơn vị trong
G(·) đến xếp hạng tối đa có thể, có nghĩa là các đơn vị đó được đóng băng và không loại bỏ bất
kỳ kết nối nào.
Chi tiết REMIND: REMIND là một phương pháp lấy cảm hứng từ thần kinh để phát lại các biểu
diễn nén. Nó ban đầu được thiết kế cho học trực tuyến, xử lý một ví dụ tại một thời điểm và thực
hiện một lần duyệt qua các tập dữ liệu thay vì nhiều epoch. Tuy nhiên, có thể triển khai một phiên
bản batch của REMIND và thực hiện nhiều epoch. Trên thực tế, bài báo gốc cho thấy rằng phiên
bản batch dẫn đến hiệu suất tốt hơn so với học trực tuyến. Vì cả SHARP và BIR đều học với batch,
chúng tôi triển khai phiên bản batch của REMIND để so sánh công bằng.

--- TRANG 20 ---
Batch REMIND trước tiên truyền n mẫu đầu vào qua các lớp tiền huấn luyện và đóng băng của nó.
Sau đó, nó lấy mẫu n kích hoạt lớp ẩn từ bộ nhớ, được phân phối đều trên tất cả các lớp đã thấy
trước đó. Để lưu trữ các biểu diễn nén, REMIND sử dụng Product Quantization (PQ), một kỹ thuật
học máy nén các vector chiều cao bằng cách chia chúng thành các vector con và lượng tử hóa mỗi
vector con riêng biệt. Điều này thường được thực hiện bằng thuật toán phân cụm như k-means, nhóm
các vector con tương tự lại với nhau để giảm chiều tổng thể của dữ liệu. PQ có hai siêu tham số:
kích thước của các vector con và số lượng sách mã. Chúng tôi đặt số lượng sách mã thành 256, cho
phép mỗi sách mã được biểu diễn bằng một byte duy nhất ( 28). Ngoài ra, chúng tôi thử nghiệm
với một số kích thước vector con để tìm sự đánh đổi tối ưu giữa lỗi tái tạo và tỷ lệ nén.
Trong triển khai gốc của REMIND, tăng cường dữ liệu được sử dụng cho các mẫu đầu vào, và một
biến thể của manifold mixup được áp dụng cho các tensor lượng tử hóa để tăng cường kích hoạt
phát lại. Tuy nhiên, chúng tôi không sử dụng bất kỳ hình thức tăng cường dữ liệu nào cho các
baseline của chúng tôi. Để đảm bảo so sánh công bằng, chúng tôi loại trừ cả bước tăng cường dữ
liệu và manifold mixup khỏi REMIND trong đánh giá của chúng tôi.
Đối với các thí nghiệm của chúng tôi, chúng tôi triển khai REMIND từ đầu, nhưng kho GitHub
gốc của REMIND đã giúp chúng tôi rất nhiều ( https://github.com/tyler-hayes/REMIND ) [22].
Hơn nữa, chúng tôi dựa vào thư viện FAISS của Meta Research cho PQ ( https://github.com/
facebookresearch/faiss ) [27].
Chi tiết BIR: Brain-inspired replay (BIR) là một phương pháp phát lại kích hoạt sinh tạo mô hình
hóa sự tương tác giữa Hồi hải mã và Vỏ não mới trong quá trình củng cố ký ức của não bộ. Phương
pháp này phát lại các kích hoạt ẩn của dữ liệu đã học trước đó, được tạo ra bởi các kết nối phản
hồi điều chế ngữ cảnh của chính mạng.
BIR được thiết kế cho học gia tăng lớp, giống như SHARP, và bài báo gốc đã tiến hành các thí
nghiệm trên các tập dữ liệu tương tự như chúng tôi. Kết quả là, chúng tôi có thể dễ dàng điều chỉnh
BIR cho các thí nghiệm của chúng tôi, sử dụng kho GitHub chính thức ( https://github.com/GMvandeVen/
brain-inspired-replay ) [57].
Siêu tham số: Chúng tôi thực hiện tinh chỉnh siêu tham số nghiêm ngặt cho tất cả các baseline và
báo cáo hiệu suất tốt nhất của mỗi phương pháp trên các tập kiểm tra chính thức của tất cả các tập
dữ liệu. Tìm kiếm siêu tham số của chúng tôi bao gồm bất kỳ siêu tham số được đề xuất nào trong
các bài báo gốc.
Về mặt tối ưu hóa, chúng tôi sử dụng SGD với momentum cho REMIND, ADAM cho BIR như
được khuyến nghị trong triển khai gốc, và tối ưu hóa Adadelta cho SHARP. Mặc dù SHARP hoạt
động tương tự với SGD với momentum nếu tốc độ học được đặt đúng, chúng tôi quan sát thực nghiệm
rằng Adadelta cho phép chúng tôi sử dụng một tốc độ học duy nhất (1.0) trên tất cả các thí nghiệm.
Vì sự đơn giản, chúng tôi giữ Adadelta cho SHARP. Chúng tôi cũng thử Adadelta với tốc độ học
1.0 cho REMIND và BIR, nhưng chúng không hoạt động tốt hơn. Vui lòng xem Bảng 3 cho tất cả
các siêu tham số.
Bảng 3: Siêu tham số Tốt nhất cho thí nghiệm "So sánh với Các Phương pháp Phát lại Kích hoạt".
Ở đây chúng tôi trình bày các siêu tham số chung trên tất cả các baseline. BS viết tắt của kích thước
batch. Lượng huấn luyện là mỗi tập.
Phương pháp Tối ưu hóa Tốc độ học BS Replay BS Huấn luyện
Thí nghiệm: MNIST →EMNIST
SHARP Adadelta 1.0 512 512 xem Bảng 2
REMIND SGD + Momentum 0.01 512 512 3 epochs
BIR Adam 0.0001 1024 1024 250 cập nhật
Thí nghiệm: CIFAR10 →CIFAR100
SHARP Adadelta 1.0 64 64 xem Bảng 2
REMIND SGD + Momentum 0.001 64 64 25 epochs
BIR Adam 0.0005 256 256 5000 cập nhật

--- TRANG 21 ---
C.6 Chi tiết So sánh với Các Phương pháp Phát lại Thô
Trong Phần 4.2 của bài báo chính, chúng tôi so sánh SHARP với các baseline sau:
•Experience Replay (ER): Thuật toán phát lại đơn giản này cho phép học tuần tự các lớp
mới bằng cách tăng cường các batch huấn luyện với các mẫu từ tất cả các lớp trong quá khứ
được lưu trữ trong bộ nhớ.
•Dark Experience Replay (DER) : Phương pháp này là một mở rộng đơn giản của thuật toán
ER [6], và nó cũng tận dụng phát lại mẫu thô. Sự khác biệt chính là, thay vì lưu trữ nhãn
lớp cứng, nó lưu trữ các logit của mô hình được huấn luyện làm mục tiêu cho các mẫu được
phát lại.
•Function Distance Regularization (FDR): Phương pháp này cũng bao gồm việc phát lại
các ví dụ thô từ tất cả các lớp trước đó và có sự tương đồng với DER. Nó tận dụng các ví
dụ trong quá khứ và đầu ra mạng để căn chỉnh đầu ra hiện tại và quá khứ, giống như DER.
•iCaRL : iCaRL là một phương pháp phát lại thô tinh vi cũng dựa vào việc xem lại tất cả
các lớp trong quá khứ. Đây là một trong những phương pháp phát lại nổi tiếng nhất và thường
hoạt động tốt trên các tập dữ liệu và kiến trúc khác nhau. Nó có ba thành phần chính: phân
loại bằng quy tắc nearest-mean-of-exemplars, lựa chọn mẫu ưu tiên dựa trên herding, và
học biểu diễn sử dụng chưng cất kiến thức và luyện tập nguyên mẫu.
•A-GEM : Phương pháp này khác với các phương pháp baseline khác vì nó lưu trữ các mẫu
thô nhưng không sử dụng trực tiếp chúng trong huấn luyện [ 9]. Thay vào đó, nó chiếu các
gradient của các nhiệm vụ mới dựa trên các gradient được tính cho các mẫu bộ nhớ. Ngoài
ra, nó yêu cầu lưu trữ các ví dụ thô để tính gradient tại các thời điểm cụ thể trong quá trình
huấn luyện.
Chúng tôi dựa vào https://github.com/aimagelab/mammoth [6,5] cho việc triển khai tất cả
các baseline này. Chúng tôi tinh chỉnh tất cả các baseline, tìm kiếm không gian siêu tham số để có
hiệu suất tốt nhất. Tìm kiếm của chúng tôi bao gồm bất kỳ siêu tham số được đề xuất nào trong [ 6].
Ngoài ra, chúng tôi thử sử dụng cả tối ưu hóa Adadelta và SGD. Vui lòng xem Bảng 4 cho tất cả
các siêu tham số được sử dụng trong các thí nghiệm.
C.7 Chi tiết cho SHARP có Cần Ranh giới Tập không?
Trong Phần 4.3 của bài báo chính, chúng tôi tiến hành đánh giá SHARP trong một kịch bản học
liên tục được sửa đổi nơi các tập không loại trừ lẫn nhau về các lớp mà chúng chứa. Chi tiết thí
nghiệm và siêu tham số cho các thí nghiệm này vẫn giống như trong Phần 4.2, với một ngoại lệ:
chúng tôi bỏ qua việc khởi tạo lại các đơn vị xếp hạng-0. Quyết định này được đưa ra vì, trong
kịch bản sửa đổi này, các lớp trong quá khứ có thể xuất hiện lại trong tương lai, và chúng tôi muốn
bảo tồn chuyển giao kiến thức tiến bằng cách tránh khởi tạo lại. Điều quan trọng cần lưu ý là các
đơn vị xếp hạng-0 trong bài báo được coi là nhàn rỗi và không học cho nhiệm vụ. Mặc dù điều này
đúng cho hầu hết các đơn vị xếp hạng-0, một số đơn vị có thể chuyển từ xếp hạng-0 sang xếp hạng-1
và sau đó bị hạ cấp trở lại xếp hạng-0 trong một tập học duy nhất. Các đơn vị này sẽ mã hóa một
số kiến thức cho các lớp hiện tại và có thể đóng góp vào chuyển giao kiến thức tiến.
D Kết quả Bổ sung
D.1 Kết quả Phát lại Thô qua các Tập
Trong Phần 4.2 của bài báo chính, chúng tôi báo cáo kết quả dưới dạng bảng, tập trung vào độ
chính xác cuối cùng được tính trung bình trên tất cả các lớp. Mặc dù chỉ số này cung cấp tổng quan
hữu ích về hiệu suất của các phương pháp khác nhau trong học liên tục, nó không cung cấp cái nhìn
toàn diện về kết quả. Để trình bày phân tích chi tiết hơn, Hình 4 mô tả độ chính xác trên các lớp
đã thấy khi các phương pháp gặp các tập học mới. Hình ảnh hóa này cung cấp thêm thông tin về
hiệu suất thời gian của các phương pháp. Điều quan trọng cần lưu ý là đây không phải là một thí
nghiệm độc lập; thay vào đó, chúng tôi trình bày kết quả đã thu được trước đó ở định dạng khác để
tăng cường hiểu biết và phân tích.
Như đã đề cập trong bài báo chính của chúng tôi, SHARP thể hiện độ chính xác trung bình cao nhất
trên tất cả các lớp, ngoại trừ tập dữ liệu CIFAR10. Tuy nhiên, tương tự như phát hiện của chúng
tôi trong Phần 4.1 của bài báo chính, khi so sánh SHARP với REMIND, SHARP thỉnh thoảng tụt
lại sau các phương pháp khác trong các tập đầu tiên. Điều này có thể được quy cho thực tế là nhiệm
vụ trở nên ngày càng thách thức hơn đối với các baseline khác khi chúng ta gặp thêm các tập. Chúng
được yêu cầu phát lại đồng đều tất cả

--- TRANG 22 ---
Bảng 4: Siêu tham số Tốt nhất cho thí nghiệm "So sánh với Các Phương pháp Phát lại Thô". Ở đây
chúng tôi trình bày các siêu tham số chung trên tất cả các baseline. BS viết tắt của kích thước batch.
Lượng huấn luyện là mỗi tập.
Phương pháp Tối ưu hóa Tốc độ học BS Replay BS Huấn luyện Khác
Thí nghiệm: MNIST
SHARP Adadelta 1.0 256 256 xem Bảng 2 xem Bảng 2
ER SGD+Momentum 0.001 128 128 20 —
DER SGD+Momentum 0.001 512 512 20 α= 0.2
FDR SGD+Momentum 0.0001 256 256 20 α= 0.2
iCaRL SGD+Momentum 0.01 128 128 20 —
A-GEM SGD+Momentum 0.01 128 128 20 —
Thí nghiệm: FMNIST
SHARP Adadelta 1.0 1024 1024 xem Bảng 2 xem Bảng 2
ER SGD+Momentum 0.0001 128 128 20 —
DER SGD+Momentum 0.001 256 256 20 α= 0.2
FDR SGD+Momentum 0.0001 128 128 20 α= 0.2
iCaRL SGD+Momentum 0.01 128 128 20 —
A-GEM SGD+Momentum 0.0001 256 256 20 —
Thí nghiệm: EMNIST
SHARP Adadelta 1.0 256 256 xem Bảng 2 xem Bảng 2
ER SGD+Momentum 0.0001 128 128 20 —
DER SGD+Momentum 0.001 512 512 20 α= 0.2
FDR SGD+Momentum 0.001 256 256 20 α= 0.2
iCaRL SGD+Momentum 0.01 128 128 20 —
A-GEM SGD+Momentum 0.0001 256 256 20 —
Thí nghiệm: CIFAR10
SHARP Adadelta 1.0 256 256 xem Bảng 2 xem Bảng 2
ER SGD+Momentum 0.0001 256 256 50 —
DER SGD+Momentum 0.0001 256 256 50 α= 0.2
FDR SGD+Momentum 0.0001 128 128 50 α= 0.2
iCaRL SGD+Momentum 0.01 64 64 50 —
A-GEM SGD+Momentum 0.001 64 64 50 —
Thí nghiệm: CIFAR100
SHARP Adadelta 1.0 64 64 xem Bảng 2 xem Bảng 2
ER SGD+Momentum 0.0001 256 256 50 —
DER SGD+Momentum 0.001 64 64 50 α= 0.2
FDR SGD+Momentum 0.01 64 64 50 α= 0.2
iCaRL SGD+Momentum 0.01 64 64 50 —
A-GEM SGD+Momentum 0.01 256 256 50 —
các lớp trước đó và phân phối tài nguyên bộ nhớ hạn chế trên số lượng lớp ngày càng tăng. Ngược
lại, SHARP phát lại có chọn lọc các lớp trong quá khứ và cơ chế phát lại của nó không bị ảnh hưởng
bởi số lượng tập đã thấy.
D.2 Kết quả với Các Ngân sách Bộ nhớ Khác nhau
Trong bài báo chính, chúng tôi trình bày hiệu suất của SHARP dựa trên một ngân sách bộ nhớ cố
định cụ thể, vì chúng tôi bị hạn chế bởi giới hạn trang. Tuy nhiên, để hoàn thiện, bây giờ chúng tôi
cung cấp kết quả bổ sung trong Bảng 5 và Bảng 6, tương ứng với các kịch bản nơi ngân sách bộ
nhớ được giảm một nửa và tăng gấp đôi. Xin lưu ý rằng chúng tôi đã chọn trình bày kết quả chỉ
cho SHARP, iCaRL và DER trong phân tích này. Quyết định này dựa trên khoảng cách độ chính
xác đáng kể

--- TRANG 23 ---
Hình 4: Độ chính xác trên các lớp đã thấy cho MNIST, FMNIST, EMNIST, CIFAR10 và CIFAR100.
quan sát được giữa SHARP và các phương pháp khác. Với khoảng cách đáng kể này, chúng tôi không
dự đoán rằng việc sửa đổi ngân sách bộ nhớ sẽ thu hẹp hoặc đóng khoảng cách hiệu suất một cách
đáng kể.
Như dự đoán, khi ngân sách bộ nhớ được giảm một nửa, hiệu suất của tất cả các phương pháp có
xu hướng giảm. Tuy nhiên, nói chung, SHARP thể hiện khả năng phục hồi nhiều hơn trong chế độ
bộ nhớ thấp này. Ví dụ, trên tập dữ liệu MNIST, hiệu suất của SHARP chỉ giảm 2.7%, trong khi
phương pháp hoạt động tốt nhất tiếp theo, iCaRL, bị giảm 11.7%. Tương tự, trên FMNIST, hiệu
suất của SHARP giảm 3.5%, trong khi iCaRL trải qua sự sụt giảm 7%. Xu hướng tổng thể này có
thể được quy cho thực tế là các baseline khác hiện có dung lượng rất hạn chế để lưu trữ mẫu mỗi
lớp để phát lại đồng đều tất cả các lớp đã gặp trước đó.
Điều quan trọng cần lưu ý là có những ngoại lệ đối với xu hướng chung này. Ví dụ, iCaRL thể hiện
khả năng bảo tồn hiệu suất tốt hơn trên tập dữ liệu CIFAR10. Chúng tôi tin rằng hiệu suất mạnh
mẽ của iCaRL trên các tập dữ liệu nơi các mẫu trong cùng lớp thể hiện sự khác biệt đáng kể có thể
được quy cho chiến lược lựa chọn mẫu không ngẫu nhiên của nó. Quan sát này cho thấy rằng chiến
lược lựa chọn ngẫu nhiên của SHARP có thể được thay thế bằng một chiến lược lựa chọn tinh vi
hơn để tăng cường hiệu suất của nó hơn nữa.
Ngược lại, khi ngân sách bộ nhớ được tăng gấp đôi, tất cả các phương pháp đều thể hiện sự cải
thiện về độ chính xác. Tuy nhiên, trong kịch bản này, các phương pháp phát lại thô, DER và iCaRL,
được hưởng lợi nổi bật hơn từ ngân sách bộ nhớ tăng. Ngoài ra, SHARP không còn duy trì được
vị trí dẫn đầu trên tập dữ liệu FMNIST. Kết quả này được mong đợi vì trong chế độ bộ nhớ cao,
việc phát lại các ví dụ thô của tất cả các lớp đã gặp trước đó xấp xỉ việc sử dụng dữ liệu i.i.d., và
các phương pháp phát lại thô trở nên gần hơn với huấn luyện chung, đại diện cho hiệu suất giới
hạn trên cho học liên tục.

--- TRANG 24 ---
Bảng 5: Nửa Ngân sách Bộ nhớ. Độ chính xác trung bình trên các lớp sau tất cả các tập. MNIST/FM-
NIST/EMNIST bộ nhớ: 0.0203 MB (26 hình ảnh), CIFAR10 bộ nhớ: 0.8192 MB ( ≈267 hình ảnh),
CIFAR100 bộ nhớ: 2.048 MB ( ≈667 hình ảnh).
Phương pháp MNIST FMNIST EMNIST CIFAR10 CIFAR100
Chung 98.0 (±0.0)86.6 (±1.0)91.0 (±0.3)70.8 (±0.4)33.9 (±0.8)
SHARP 85.3 (±0.8)69.0 (±2.5)55.8 (±1.3)41.3 (±1.0)21.5 (±1.5)
iCaRL 73.4 (±1.3)63.7 (±1.0)55.1 (±0.8)52.6 (±0.9)19.6 (±0.4)
DER 73.2 (±1.9)64.5 (±3.1)34.5 (±2.0)32.6 (±1.2)11.4 (±0.4)
SGD 19.8 (±0.1)16.6 (±4.7)3.9 (±0.0)16.0 (±4.2)6.6 (±0.1)
Bảng 6: Gấp đôi Ngân sách Bộ nhớ. Độ chính xác trung bình trên các lớp sau tất cả các tập. MNIST/FM-
NIST/EMNIST bộ nhớ: 0.0784 MB (100 hình ảnh), CIFAR10 bộ nhớ: 3.2768 MB ( ≈1068 hình ảnh),
CIFAR100 bộ nhớ: 8.192 MB ( ≈2668 hình ảnh).
Phương pháp MNIST FMNIST EMNIST CIFAR10 CIFAR100
Chung 98.0 (±0.0)86.6 (±1.0)91.0 (±0.3)70.8 (±0.4)33.9 (±0.8)
SHARP 91.7 (±0.9)72.8 (±2.0)61.1 (±1.6)49.3 (±0.1)23.0 (±0.7)
iCaRL 86.0 (±0.5)71.0 (±0.7)59.8 (±1.2)53.6 (±1.0)22.9 (±0.6)
DER 87.3 (±1.4)75.6 (±0.5)51.3 (±2.7)41.1 (±0.9)20.7 (±0.6)
SGD 19.8 (±0.1)16.6 (±4.7)3.9 (±0.0)16.0 (±4.2)6.6 (±0.1)
D.3 Thí nghiệm với Các Kích thước Cửa sổ Thời gian STM Khác nhau (tức là m)
Trong suốt tất cả các thí nghiệm được tiến hành, SHARP sử dụng việc phát lại các kích hoạt từ tập
trước đó. Điều này được đạt được bằng cách đặt tham số bộ nhớ ngắn hạn, ký hiệu là m, thành 1.
Tuy nhiên, điều quan trọng cần lưu ý là thuật toán của chúng tôi linh hoạt và có thể hoạt động với
bất kỳ giá trị m nào, thậm chí cho phép các kịch bản nơi m được đặt thành 0 (không phát lại). Lưu
ý rằng trong trường hợp m= 0, chúng tôi tạm thời lưu trữ các kích hoạt từ tập hiện tại để truyền
chúng vào bộ nhớ dài hạn, nhưng chúng tôi không thực hiện bất kỳ phát lại nào.
Trong phần này, chúng tôi tiến hành các thí nghiệm bổ sung với các giá trị m khác nhau để khám
phá tác động của nó đối với hiệu suất của SHARP. Điều quan trọng cần lưu ý là ngân sách bộ nhớ
được cố định ở 50 kích hoạt, phù hợp với các thí nghiệm chính của chúng tôi, bất kể giá trị của m.
Do đó, khi m tăng, SHARP được yêu cầu phân bổ cùng ngân sách cố định trên số lượng lớp ngày
càng tăng.
Hình 5 trình bày kết quả thu được cho các giá trị m khác nhau (0, 1, 2, 3, 4) trên tập dữ liệu EMNIST.
Đáng chú ý, ngay cả không có bất kỳ phát lại nào (tức là m= 0), SHARP đạt được hiệu suất không
tầm thường. Đáng chú ý, nó thậm chí vượt trội so với các phiên bản khác trong tập thứ hai và thứ
ba. Tuy nhiên, khi các tập tiếp theo diễn ra, hiệu suất của nó trải qua sự suy giảm nhanh chóng, khiến
SHARP không có phát lại tụt lại sau các phiên bản phát lại. Quan sát này nhấn mạnh rằng điểm
mạnh của SHARP không chỉ được quy cho phát lại. Thay vào đó, các thành phần kiến trúc như hệ
thống xếp hạng và đấu nối lại kết nối đóng vai trò quan trọng trong việc giữ lại kiến thức theo thời gian.
Ngược lại, khi m= 2, chúng tôi quan sát thấy hiệu suất được cải thiện nhẹ về cuối quỹ đạo học so
với khi m= 1. Tuy nhiên, khi chúng tôi tăng m lên các giá trị cao hơn 2, có sự giảm rõ rệt trong
hiệu suất tổng thể. Sự suy giảm này có thể được quy cho thực tế là SHARP hiện được yêu cầu dựa
vào một số lượng rất hạn chế mẫu mỗi lớp trong quá trình phát lại, điều này có thể dẫn đến overfitting.
Do đó, việc ưu tiên phát lại các lớp gần đây đã thấy khi việc lưu trữ một số lượng lớn mẫu mỗi lớp
không khả thi là tốt hơn. Quan sát này phù hợp với thông tin từ khoa học thần kinh. Não bộ cũng
đối mặt với sự đánh đổi tương tự, vì hiệu quả tính toán là rất quan trọng cho sự sống còn. Do đó,
não bộ ưu tiên phát lại các sự kiện được trải nghiệm gần đây thay vì xem xét lại tất cả các kinh
nghiệm trong quá khứ.

--- TRANG 25 ---
Hình 5: Độ chính xác trên các lớp đã thấy trên EMNIST cho các giá trị m khác nhau.
E Triển khai và Tài nguyên Tính toán của SHARP
Đối với tất cả các thí nghiệm, chúng tôi tiến hành chúng trên Ubuntu 20.04 sử dụng GPU NVIDIA
GeForce RTX 3090 với CUDA 12.0. Chúng tôi sử dụng PyTorch 1.13.1 và Python 3.10.9 cho
việc triển khai. Cuối cùng, chúng tôi dựa vào "Avalanche: an End-to-End Library for Continual
Learning" để tạo các kịch bản học liên tục [36].

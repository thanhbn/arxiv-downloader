Ziya2: Học tập Lấy Dữ liệu Làm Trung tâm Là Tất cả Những gì LLMs Cần

Ruyi Gan♥♠Renliang Sun♥Ziwei Wu♥Junyu Lu♥Xiaojun Wu♥
Dixiang Zhang♥Junqing He♥Yuanhe Tian♠Ping Yang♥∗Qi Yang♥∗
Kunhao Pan♥Hao Wang♥Jiaxing Zhang♥Yan Song♠
♥Học viện Kinh tế Số Quốc tế♠Đại học Khoa học và Công nghệ Trung Quốc
{zhangjiaxing, wuziwei, sunrenliang}@idea.edu.cn
ganruyi@mail.ustc.edu.cn, yhtian@uw.edu, clksong@gmail.com

Tóm tắt
Nhiều mô hình ngôn ngữ lớn (LLMs) đã được đề xuất trong những năm gần đây, bao gồm cả những mô hình mã nguồn đóng và mở, liên tục thiết lập những kỷ lục mới trên nhiều bộ đánh giá. Tuy nhiên, việc phát triển LLMs vẫn đối mặt với một số vấn đề, chẳng hạn như chi phí cao khi huấn luyện mô hình từ đầu, và việc tiếp tục tiền huấn luyện dẫn đến quên thảm khốc, v.v. Mặc dù nhiều vấn đề như vậy được giải quyết theo hướng nghiên cứu về LLMs, một hạn chế quan trọng nhưng thực tế là nhiều nghiên cứu quá mức theo đuổi việc mở rộng quy mô mô hình mà không phân tích toàn diện và tối ưu hóa việc sử dụng dữ liệu tiền huấn luyện trong quá trình học tập của chúng, cũng như tổ chức và khai thác phù hợp dữ liệu đó trong việc huấn luyện LLMs dưới các thiết lập hiệu quả về chi phí. Trong công trình này, chúng tôi đề xuất Ziya2, một mô hình có 13 tỷ tham số áp dụng LLaMA2 làm mô hình nền tảng, và được tiếp tục tiền huấn luyện trên 700 tỷ token, trong đó chúng tôi tập trung vào các kỹ thuật tiền huấn luyện và sử dụng tối ưu hóa lấy dữ liệu làm trung tâm để nâng cao quá trình học tập của Ziya2 ở các giai đoạn khác nhau. Chúng tôi định nghĩa ba thuộc tính dữ liệu và lần đầu tiên thiết lập các quy luật tỷ lệ lấy dữ liệu làm trung tâm để minh họa cách dữ liệu khác nhau tác động đến LLMs. Các thí nghiệm cho thấy Ziya2 vượt trội đáng kể so với các mô hình khác trong nhiều bộ đánh giá đặc biệt với kết quả đầy hứa hẹn so với các mô hình mã nguồn mở đại diện.

1 Giới thiệu
LLMs đã đạt được thành công lớn trong lĩnh vực trí tuệ nhân tạo (AI), đặc biệt là xử lý ngôn ngữ tự nhiên (NLP), trong vài năm qua. Nói chung, LLMs được tiền huấn luyện trên lượng lớn văn bản và cho thấy hiệu suất đầy hứa hẹn trong nhiều nhiệm vụ NLP khác nhau mà không cần điều chỉnh chuyên biệt cho nhiệm vụ cụ thể trên lượng lớn dữ liệu có nhãn. Trong số tất cả LLMs, những mô hình đại diện bao gồm GPT-3 và các mô hình kế thừa ChatGPT, GPT-4, và PaLM-2, thể hiện khả năng thích ứng và ứng dụng mạnh mẽ. Tuy nhiên, do thực tế là các LLMs nói trên được phát triển trong môi trường khá hạn chế, việc thiếu quyền truy cập vào mã nguồn và tham số của nhà phát triển trở thành rào cản đối với nhiều nhà nghiên cứu và phát triển tiếp theo trong việc tiếp tục nghiên cứu LLM dựa trên các mô hình hiệu suất tốt hiện có. Nghịch lý này dẫn đến hiện tượng nhiều nhà nghiên cứu chuyển sang huấn luyện các lựa chọn thay thế mã nguồn mở, chẳng hạn như LLaMA2 và Falcon, v.v., vì các LLMs mã nguồn mở cung cấp nền tảng cho việc học tập và cải thiện thêm dựa trên vai của những người tiền nhiệm thành công, điều này thúc đẩy tính minh bạch và trách nhiệm giải trình trong các nghiên cứu AI tiếp theo.

Tuy nhiên, ngoài những lợi ích khác nhau mà LLMs mã nguồn mở mang lại, việc phát triển LLMs hiện đang đối mặt với ba thách thức chính sau đây. Thứ nhất là việc tiền huấn luyện mô hình từ đầu đòi hỏi huấn luyện dài hạn trên nhiều GPU, khiến việc huấn luyện LLMs trở thành một quá trình cực kỳ tốn kém. Tiếp tục tiền huấn luyện đưa ra một giải pháp tương đối hiệu quả về chi phí, nhưng nó có thể đi kèm với các vấn đề như quên thảm khốc, có thể được quy cho sự khác biệt trong phân phối dữ liệu. Thứ hai là LLMs mã nguồn mở thường không đi kèm với dữ liệu mã nguồn mở. Hiệu quả của các phương pháp xử lý dữ liệu trực tiếp tác động đến hiệu suất của LLMs. Hiện tại, không có phương pháp luận hoặc tiêu chí được chuẩn hóa để làm sạch dữ liệu tiền huấn luyện. Thứ ba là nhiều nghiên cứu về LLMs ưu tiên mở rộng dung lượng tham số mô hình và dữ liệu tiền huấn luyện để nâng cao hiệu suất mô hình, thường bỏ qua tác động của chất lượng dữ liệu tiền huấn luyện đến hiệu suất mô hình. Cụ thể, theo hiểu biết tốt nhất của chúng tôi, không có nghiên cứu nào điều tra thuộc tính nào của dữ liệu tiền huấn luyện tác động đáng kể nhất đến LLMs. Dưới các ràng buộc của ngân sách tính toán và số lượng tham số nhất định, cũng đáng khám phá loại dữ liệu nào nên được ưu tiên.

Trong công trình này, chúng tôi tập trung vào các chiến lược tiếp tục tiền huấn luyện và hiểu mối quan hệ phức tạp giữa dữ liệu và hiệu suất mô hình. Trước tiên, chúng tôi đề xuất một quy trình xử lý dữ liệu mới gồm năm bước để rút ra dữ liệu tiền huấn luyện chất lượng cao từ một kho tài liệu lớn. Chúng tôi cũng liên quan đến đánh giá của con người để đảm bảo chất lượng của dữ liệu đã xử lý. Sau đó, chúng tôi sử dụng LLaMA2-13B làm mô hình cơ sở và đề xuất một chiến lược tiếp tục tiền huấn luyện ba giai đoạn. Giai đoạn huấn luyện đầu tiên sử dụng nhiều dữ liệu không giám sát bằng tiếng Anh và tiếng Trung. Giai đoạn thứ hai sử dụng một lượng dữ liệu tương đối nhỏ nhưng chứa nhiều bộ dữ liệu có giám sát. Giai đoạn thứ ba sử dụng ít dữ liệu tăng cường tập trung vào cải thiện khả năng toán học. Cuối cùng, chúng tôi có được Ziya2, và toàn bộ quá trình huấn luyện lấy dữ liệu làm trung tâm được thể hiện trong Hình 1.

Việc đánh giá Ziya2 được thực hiện trên một số bộ đánh giá đại diện, và kết quả cho thấy Ziya2 có sự cải thiện đáng kể so với LLaMA2. Đặc biệt, Ziya2 cải thiện LLaMA2 10% trên MMLU, 61% trên CMMLU, và 68% trên C-Eval, tương ứng. Đặc biệt về các bộ đánh giá toán học, Ziya2 cải thiện LLaMA2 138% trên GSM8K và 120% trên MATH, và đối với các bộ đánh giá lập trình, Ziya2 cải thiện nó 89% trên HumanEval. So với các mô hình mã nguồn mở khác cùng kích thước, Ziya2 cũng thể hiện hiệu suất vượt trội. Kết quả cho thấy Ziya2 đạt hiệu suất xuất sắc trên các bộ dữ liệu đa ngành, đặc biệt, nó vượt qua tất cả các mô hình mã nguồn mở được sử dụng để so sánh trong kỹ năng toán học và lập trình. Đáng chú ý, hiệu suất của Ziya2 trên các nhiệm vụ tiếng Trung cũng vượt qua GPT-3.5-turbo. Phân tích của chúng tôi về các checkpoint trung gian cho thấy tác động của dữ liệu từ các giai đoạn khác nhau lên khả năng của mô hình khác nhau. Do đó, chúng tôi tiến hành các thí nghiệm bổ sung và thiết lập các quy luật tỷ lệ lấy dữ liệu làm trung tâm mới. Chúng tôi rút ra hai kết luận cho thấy rằng cải thiện 'Tính nhất quán' và 'Tính dễ đọc' của dữ liệu hiệu quả hơn trong việc cải thiện khả năng của LLMs so với cải thiện 'Tính tương đồng' với các nhiệm vụ hạ nguồn.

Tóm lại, những đóng góp của chúng tôi bao gồm: (1) Chúng tôi đề xuất một quy trình xử lý dữ liệu mới và đóng góp hơn 700 tỷ token dữ liệu chất lượng cao. (2) Chúng tôi đề xuất một chiến lược tiếp tục tiền huấn luyện hiệu quả và có được mô hình Ziya2. Chúng tôi cũng thực hiện phân tích chi tiết về tác động của dữ liệu ba giai đoạn lên các checkpoint trung gian. (3) Chúng tôi định nghĩa ba thuộc tính dữ liệu và lần đầu tiên thiết lập các quy luật tỷ lệ lấy dữ liệu làm trung tâm cho nghiên cứu tương lai.

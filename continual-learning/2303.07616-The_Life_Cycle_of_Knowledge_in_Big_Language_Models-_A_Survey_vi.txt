# Chu kỳ sống của Tri thức trong các Mô hình Ngôn ngữ Lớn: Một Khảo sát

Boxi Cao1;3, Hongyu Lin1, Xianpei Han1;2B, Le Sun1;2
1Phòng thí nghiệm Xử lý Thông tin Tiếng Trung2Phòng thí nghiệm Khoa học Máy tính Trọng điểm Quốc gia
Viện Phần mềm, Viện Khoa học Trung Quốc, Bắc Kinh, Trung Quốc
3Trường Đại học Viện Khoa học Trung Quốc, Bắc Kinh, Trung Quốc
{boxi2020,hongyu,xianpei,sunle}@iscas.ac.cn

Tóm tắt
Tri thức đóng vai trò quan trọng trong trí tuệ nhân tạo. Gần đây, thành công rộng rãi của các mô hình ngôn ngữ được tiền huấn luyện (PLMs) đã làm dấy lên sự chú ý đáng kể về cách tri thức có thể được thu nhận, duy trì, cập nhật và sử dụng bởi các mô hình ngôn ngữ. Mặc dù có lượng nghiên cứu liên quan khổng lồ, vẫn thiếu một cái nhìn thống nhất về cách tri thức tuần hoàn trong các mô hình ngôn ngữ thông qua các quá trình học, điều chỉnh và ứng dụng, điều này có thể ngăn cản chúng ta hiểu sâu hơn về các kết nối giữa tiến bộ hiện tại hoặc nhận ra các hạn chế hiện có. Trong khảo sát này, chúng tôi xem xét lại PLMs như các hệ thống dựa trên tri thức bằng cách chia chu kỳ sống của tri thức trong PLMs thành năm giai đoạn quan trọng, và nghiên cứu cách tri thức tuần hoàn khi nó được xây dựng, duy trì và sử dụng. Để đạt được điều này, chúng tôi một cách có hệ thống xem xét các nghiên cứu hiện có của từng giai đoạn trong chu kỳ sống tri thức, tóm tắt những thách thức chính và hạn chế hiện tại, và thảo luận về các hướng tương lai1.

1 Giới thiệu
Về cơ bản, AI là khoa học của tri thức – cách biểu diễn tri thức và cách thu nhận và sử dụng tri thức.
Nilson (1974)

Tri thức là chìa khóa cho trí tuệ cấp cao. Cách một mô hình thu nhận, lưu trữ, hiểu và áp dụng tri thức từ lâu đã là một chủ đề nghiên cứu quan trọng trong trí tuệ máy. Những năm gần đây đã chứng kiến sự phát triển nhanh chóng của các mô hình ngôn ngữ được tiền huấn luyện (PLMs). Thông qua việc tiền huấn luyện tự giám sát trên các kho ngữ liệu lớn không được gán nhãn, PLMs cho thấy khả năng tổng quát hóa và chuyển giao mạnh mẽ qua các tác vụ/bộ dữ liệu/cài đặt khác nhau so với các phương pháp trước đây, và do đó đã đạt được thành công đáng kể trong xử lý ngôn ngữ tự nhiên (Devlin et al., 2019; Liu et al., 2019c; Raffel et al., 2020; Radford et al., 2019b; Brown et al., 2020; Lewis et al., 2020a).

Thành công của các mô hình ngôn ngữ được tiền huấn luyện đã làm dấy lên sự chú ý lớn về bản chất của tri thức mà chúng chứa đựng. Đã có nhiều nghiên cứu tập trung vào cách tri thức có thể được thu nhận, duy trì và sử dụng bởi các mô hình ngôn ngữ được tiền huấn luyện. Theo những hướng này, nhiều hướng nghiên cứu mới đã được khám phá. Ví dụ, việc tiêm tri thức dành riêng cho việc tiêm tri thức có cấu trúc rõ ràng vào PLMs (Sun et al., 2019; Zhang et al., 2019; Sachan et al., 2021). Việc thăm dò tri thức nhằm đánh giá loại và lượng tri thức được lưu trữ trong các tham số của PLMs (Petroni et al., 2019; Lin et al., 2019; Hewitt and Manning, 2019). Và việc chỉnh sửa tri thức được dành riêng cho việc sửa đổi tri thức không chính xác hoặc không mong muốn được thu nhận bởi PLMs (Zhu et al., 2020; De Cao et al., 2021; Mitchell et al., 2021).

Mặc dù có lượng lớn các nghiên cứu liên quan, các nghiên cứu hiện tại chủ yếu tập trung vào một giai đoạn cụ thể của quá trình tri thức trong PLMs, do đó thiếu một góc nhìn thống nhất về cách tri thức tuần hoàn trong toàn bộ các giai đoạn học, điều chỉnh và ứng dụng của mô hình. Việc thiếu những nghiên cứu toàn diện như vậy khiến khó có thể hiểu rõ hơn về các kết nối giữa các tác vụ dựa trên tri thức khác nhau, khám phá các mối tương quan giữa các giai đoạn khác nhau trong chu kỳ sống tri thức của PLMs, khai thác các liên kết và tác vụ còn thiếu để nghiên cứu tri thức trong PLMs, hoặc khám phá các thiếu sót và hạn chế của các nghiên cứu hiện có. Ví dụ, trong khi nhiều nghiên cứu cố gắng đánh giá tri thức trong các mô hình ngôn ngữ đã được tiền huấn luyện, có ít nghiên cứu tập trung vào việc điều tra tại sao PLMs có thể học từ văn bản thuần túy mà không có bất kỳ giám sát nào về tri thức, cũng như cách PLMs biểu diễn hoặc lưu trữ những tri thức này. Trong khi đó, nhiều nhà nghiên cứu đã cố gắng tiêm một cách rõ ràng các loại tri thức có cấu trúc khác nhau vào PLMs, nhưng ít nghiên cứu đề xuất giúp PLMs thu nhận tốt hơn các loại tri thức cụ thể từ văn bản thuần túy bằng cách khai thác các cơ chế thu nhận tri thức đằng sau. Kết quả là, nghiên cứu liên quan có thể quá tập trung vào một số hướng nhưng không thể hiểu toàn diện, duy trì và kiểm soát tri thức trong PLMs, và do đó hạn chế những cải tiến và ứng dụng tiếp theo.

Trong khảo sát này, chúng tôi đề xuất xem xét một cách có hệ thống các nghiên cứu liên quan đến tri thức trong các mô hình ngôn ngữ được tiền huấn luyện từ góc nhìn kỹ thuật tri thức. Lấy cảm hứng từ nghiên cứu trong khoa học nhận thức (Zimbardo and Ruch, 1975; Churchland and Sejnowski, 1988) và kỹ thuật tri thức (Studer et al., 1998; Schreiber et al., 2000), chúng tôi coi các mô hình ngôn ngữ được tiền huấn luyện như các hệ thống dựa trên tri thức, và nghiên cứu chu kỳ sống của cách tri thức tuần hoàn khi nó được thu nhận, duy trì và sử dụng trong các mô hình được tiền huấn luyện (Studer et al., 1998; Schreiber et al., 2000). Cụ thể, chúng tôi chia chu kỳ sống của tri thức trong các mô hình ngôn ngữ được tiền huấn luyện thành năm giai đoạn quan trọng sau đây như được thể hiện trong Hình 1:

• Thu nhận Tri thức, tập trung vào quá trình các mô hình ngôn ngữ học các tri thức khác nhau từ văn bản hoặc các nguồn tri thức khác.

• Biểu diễn Tri thức, tập trung vào cơ chế cơ bản của cách các loại tri thức khác nhau được chuyển đổi, mã hóa và phân bố trong các tham số của PLMs.

• Thăm dò Tri thức, nhằm đánh giá mức độ PLMs hiện tại chứa đựng các loại tri thức khác nhau.

• Chỉnh sửa Tri thức, cố gắng chỉnh sửa hoặc xóa tri thức chứa trong các mô hình ngôn ngữ.

• Ứng dụng Tri thức, cố gắng chưng cất hoặc tận dụng tri thức trong các mô hình ngôn ngữ được tiền huấn luyện cho ứng dụng thực tế.

Đối với mỗi giai đoạn này, chúng tôi sắp xếp các nghiên cứu hiện có, tóm tắt những thách thức chính và hạn chế, và thảo luận về các hướng tương lai. Dựa trên góc nhìn thống nhất, chúng tôi có thể hiểu và sử dụng các kết nối chặt chẽ giữa các giai đoạn khác nhau thay vì coi chúng như các tác vụ độc lập. Chẳng hạn, việc hiểu cơ chế biểu diễn tri thức của PLMs có giá trị để các nhà nghiên cứu thiết kế các mục tiêu thu nhận tri thức tốt hơn và các chiến lược chỉnh sửa tri thức. Việc đề xuất các phương pháp thăm dò tri thức đáng tin cậy có thể giúp chúng ta tìm ra các ứng dụng phù hợp cho PLMs, và có được cái nhìn sâu sắc về các hạn chế của chúng, từ đó tạo điều kiện thuận lợi cho việc cải tiến. Thông qua khảo sát này, chúng tôi mong muốn kết luận một cách toàn diện về tiến bộ, thách thức và hạn chế của các nghiên cứu hiện tại, giúp các nhà nghiên cứu hiểu rõ hơn toàn bộ lĩnh vực từ một góc nhìn mới, và soi sáng các hướng tương lai về cách điều chỉnh, biểu diễn và áp dụng tri thức trong các mô hình ngôn ngữ tốt hơn từ một góc nhìn thống nhất.

Chúng tôi tóm tắt các đóng góp của mình như sau:
• Chúng tôi đề xuất xem xét lại các mô hình ngôn ngữ được tiền huấn luyện như các hệ thống dựa trên tri thức, và chia chu kỳ sống của tri thức trong PLMs thành năm giai đoạn quan trọng.

• Đối với mỗi giai đoạn, chúng tôi xem xét các nghiên cứu hiện có, tóm tắt những thách thức chính và thiếu sót cho từng hướng.

• Dựa trên đánh giá này, chúng tôi thảo luận về các hạn chế của nghiên cứu hiện tại, và soi sáng các hướng tương lai tiềm năng.

2 Tổng quan

Trong phần này, chúng tôi trình bày cấu trúc tổng thể của khảo sát này, mô tả chi tiết phân loại của chúng tôi được thể hiện trong Hình 2, và thảo luận về các chủ đề trong mỗi giai đoạn quan trọng.

Thu nhận Tri thức là quá trình học tri thức của các mô hình ngôn ngữ. Hiện tại, có hai nguồn chính cho việc thu nhận tri thức: dữ liệu văn bản thuần túy và dữ liệu có cấu trúc. Đối với việc thu nhận tri thức từ dữ liệu văn bản, LMs thường thực hiện học tự giám sát trên các kho ngữ liệu văn bản quy mô lớn (Devlin et al., 2019; Liu et al., 2019c; Brown et al., 2020; Raffel et al., 2020). Khảo sát này sẽ tập trung vào các phương pháp và cơ chế về cách các mô hình ngôn ngữ được tiền huấn luyện thu nhận tri thức từ văn bản thuần túy (Chiang et al., 2020; Pérez-Mayos et al., 2021; Liu et al., 2021c). Đối với việc thu nhận tri thức từ dữ liệu có cấu trúc, nghiên cứu hiện tại tập trung vào việc tiêm tri thức từ các loại dữ liệu có cấu trúc khác nhau vào PLMs. Các loại chính của dữ liệu có cấu trúc bao gồm tri thức thực thể (Sun et al., 2019; Xiong et al., 2020; Peters et al., 2019), tri thức thực tế (Zhang et al., 2019; Wang et al., 2021b,a; Liu et al., 2020), tri thức thường thức (Bosselut et al., 2019; Ye et al., 2019; Guan et al., 2020; Ma et al., 2021) và tri thức ngôn ngữ học (Ke et al., 2020; Lauscher et al., 2020; Zhou et al., 2019; Bai et al., 2021). Chúng tôi sẽ thảo luận tất cả trong Phần 3.

Biểu diễn Tri thức nhằm nghiên cứu cách các mô hình ngôn ngữ mã hóa, lưu trữ và biểu diễn tri thức trong các tham số dày đặc của chúng. Việc nghiên cứu về các cơ chế biểu diễn tri thức sẽ hỗ trợ trong việc hiểu và kiểm soát tri thức trong PLMs tốt hơn, và cũng có thể truyền cảm hứng cho các nhà nghiên cứu để hiểu rõ hơn về biểu diễn tri thức trong não người. Hiện tại, các chiến lược phân tích biểu diễn tri thức trong PLMs bao gồm các phương pháp dựa trên gradient (Geva et al., 2021; Dai et al., 2022a), lấy cảm hứng từ nhân quả (Meng et al., 2022), dựa trên chú ý (Clark et al., 2019; Htut et al., 2019; Lin et al., 2019), và theo từng lớp (Lin et al., 2019; Liu et al., 2019a; Juneja and Agarwal, 2022). Chúng tôi sẽ thảo luận chúng trong Phần 4.

Thăm dò Tri thức nhằm đánh giá mức độ PLMs hiện tại chứa đựng các loại tri thức cụ thể. Hiện tại, hai chiến lược chính được sử dụng để thăm dò tri thức trong PLMs: 1) Thăm dó dựa trên prompt, thường xây dựng prompt hướng dẫn tri thức, sau đó truy vấn PLMs bằng những biểu thức ngôn ngữ tự nhiên này (Petroni et al., 2019; Jiang et al., 2020a; Sung et al., 2021; Forbes et al., 2019; Zhou et al., 2020a). Ví dụ, truy vấn PLMs với "Thủ đô của Pháp là ." để đánh giá liệu PLMs có lưu trữ tri thức tương ứng <Pháp, thủ đô, Paris>. Trong khi đó, để cải thiện hiệu suất của PLMs, một loạt nghiên cứu dành riêng cho việc tối ưu hóa prompts trong cả không gian rời rạc (Jiang et al., 2020b; Davison et al., 2019; Haviv et al., 2021; Shin et al., 2020) và liên tục (Zhong et al., 2021; Li and Liang, 2021a; Liu et al., 2021b). Mặc dù việc ứng dụng rộng rãi của thăm dò dựa trên prompt, nhiều nghiên cứu cũng chỉ ra rằng vẫn tồn tại một số vấn đề chưa giải quyết như không nhất quán (Elazar et al., 2021; Kassner and Schütze, 2020; Jang et al., 2022; Cao et al., 2022), không chính xác (Poerner et al., 2020; Zhong et al., 2021; Cao et al., 2021) và không đáng tin cậy (Cao et al., 2021; Li et al., 2022a), và đặt câu hỏi về kết quả định lượng của thăm dò dựa trên prompt. 2) Thăm dò dựa trên đặc trưng, thường đóng băng các tham số của PLMs gốc, và đánh giá PLMs trên các tác vụ thăm dò dựa trên biểu diễn nội bộ hoặc trọng số chú ý của chúng. Chúng tôi phân loại các nghiên cứu thăm dò dựa trên đặc trưng hiện có thành thăm dò dựa trên bộ phân loại (Lin et al., 2019; Tenney et al., 2019; Clark et al., 2019; Liu et al., 2019a) và thăm dò không dùng bộ phân loại (Wu et al., 2020; Zhou and Srikumar, 2021a) tùy theo việc có giới thiệu bộ phân loại bổ sung hay không. Vì hầu hết các phương pháp đều giới thiệu thêm tham số hoặc dữ liệu huấn luyện, thiếu sót chính của thăm dò dựa trên đặc trưng là liệu kết quả có nên quy cho tri thức trong PLMs hay tác vụ thăm dò được học bởi các probe bổ sung. Chúng tôi sẽ thảo luận chúng trong Phần 5.

Chỉnh sửa Tri thức nhằm sửa đổi tri thức không chính xác hoặc xóa thông tin không mong muốn trong PLMs. Do những sai lầm không thể tránh khỏi được học bởi PLMs và việc cập nhật tri thức, các phương pháp chỉnh sửa tri thức đáng tin cậy và hiệu quả là thiết yếu cho việc ứng dụng bền vững của PLMs. Các phương pháp hiện tại bao gồm điều chỉnh hạn chế (Zhu et al., 2020), dựa trên bộ nhớ (Mitchell et al., 2022; Madaan et al., 2022; Dong et al., 2022), lấy cảm hứng từ meta-learning (De Cao et al., 2021; Hase et al., 2021; Mitchell et al., 2021) và các phương pháp dựa trên vị trí (Dai et al., 2022a; Meng et al., 2022). Chúng tôi sẽ thảo luận chúng trong Phần 6.

Ứng dụng Tri thức nhằm chưng cất hoặc tận dụng tri thức cụ thể từ PLMs để mang lại lợi ích cho các ứng dụng tiếp theo. Hiện tại, có hai loại mô hình ứng dụng chính cho tri thức trong PLMs: 1) Các mô hình ngôn ngữ như cơ sở tri thức (LMs-as-KBs), coi các mô hình ngôn ngữ như các cơ sở tri thức dày đặc có thể được truy vấn trực tiếp bằng ngôn ngữ tự nhiên để thu được các loại tri thức cụ thể (Petroni et al., 2019; Heinzerling and Inui, 2021; Jiang et al., 2020b; Wang et al., 2020; Cao et al., 2021; Razniewski et al., 2021; AlKhamissi et al., 2022). Và chúng tôi cung cấp so sánh toàn diện giữa các cơ sở tri thức có cấu trúc và LMs-as-KBs (Razniewski et al., 2021) từ bốn khía cạnh, bao gồm xây dựng, phạm vi bao phủ, tương tác và độ tin cậy; 2) Các mô hình ngôn ngữ cho tác vụ downstream, sử dụng trực tiếp PLMs chứa đựng các loại tri thức cụ thể trong các tác vụ NLP downstream thông qua điều chỉnh tinh (Manning et al., 2020; Wei et al., 2021b; Yang et al., 2021; Yin et al., 2022), học prompt (Radford et al., 2019a; Brown et al., 2020; Liu et al., 2021a) và học trong ngữ cảnh (Brown et al., 2020; Zhao et al., 2021; Lu et al., 2022). Chúng tôi sẽ thảo luận chúng trong Phần 7.

3 Thu nhận Tri thức

Trong giai đoạn thu nhận tri thức, các mô hình ngôn ngữ được tiền huấn luyện học tri thức từ các nguồn tri thức khác nhau. Trong phần này, chúng tôi phân loại và mô tả các chiến lược thu nhận tri thức theo nguồn tri thức, và sau đó thảo luận về các hướng tương lai.

3.1 Học từ Dữ liệu Văn bản

Hiện tại, các mô hình ngôn ngữ được tiền huấn luyện thường thu nhận các tri thức khác nhau từ văn bản thuần túy thông qua việc học tự giám sát trên kho ngữ liệu văn bản quy mô lớn. Trong phần này, chúng tôi sẽ đầu tiên giới thiệu một số mục tiêu học được sử dụng rộng rãi (Qiu et al., 2020), và sau đó thảo luận về các cơ chế học đằng sau chúng.

Mô hình hóa Ngôn ngữ Nhân quả nhằm dự đoán token tiếp theo trong chuỗi đầu vào một cách tự hồi quy, đây là tác vụ tiền huấn luyện phổ biến nhất (Radford et al., 2019b; Brown et al., 2020; Ouyang et al., 2022; Scao et al., 2022) và đã chứng minh hiệu quả xuất sắc trong việc nắm bắt phụ thuộc ngữ cảnh và các mô hình tạo văn bản. Một hạn chế của mô hình hóa ngôn ngữ nhân quả là đơn hướng, chỉ có thể nắm bắt thông tin ngữ cảnh từ trái sang phải.

Mô hình hóa Ngôn ngữ Che nhằm che một số token trong đầu vào một cách ngẫu nhiên, và sau đó dự đoán token bị che dựa trên phần còn lại của chuỗi (Devlin et al., 2019; Liu et al., 2019c). Không giống như mô hình hóa ngôn ngữ nhân quả, chỉ có thể thu nhận thông tin theo một hướng đơn, mô hình hóa ngôn ngữ che có thể nắm bắt thông tin ngữ cảnh từ cả hai hướng trái-sang-phải và phải-sang-trái.

Mô hình hóa Ngôn ngữ Che Seq2seq sử dụng kiến trúc encoder-decoder cho việc tiền huấn luyện, đầu tiên đưa encoder chuỗi bị che, và decoder được cho là dự đoán các token bị che một cách tự hồi quy (Raffel et al., 2020; Song et al., 2019).

Bộ tự mã hóa Khử nhiễu đầu tiên làm hỏng chuỗi đầu vào bằng các ký hiệu che ngẫu nhiên, sau đó đưa đầu vào vào encoder hai chiều, và khả năng của toàn bộ đầu vào gốc được tính toán với decoder tự hồi quy (Lewis et al., 2020a).

Mặc dù PLMs được tiền huấn luyện mà không có bất kỳ giám sát nào từ các nguồn tri thức bên ngoài, chúng đã được chứng minh là nắm bắt được một loạt tri thức đa dạng trong các tham số của chúng, như tri thức ngôn ngữ học (Lin et al., 2019; Tenney et al., 2019; Liu et al., 2019b; Htut et al., 2019; Hewitt and Manning, 2019; Goldberg, 2019; Warstadt et al., 2019), tri thức ngữ nghĩa (Tenney et al., 2019; Wallace et al., 2019; Ettinger, 2020) và tri thức thế giới (Davison et al., 2019; Bouraoui et al., 2020; Forbes et al., 2019; Zhou et al., 2020b; Roberts et al., 2020; Lin et al., 2020a; Tamborrino et al., 2020).

Trực quan, PLMs học tri thức như vậy bởi vì chúng có thể trừu tượng hóa, tổng quát hóa và lưu trữ tri thức ngầm trong văn bản thông qua việc học tự giám sát. Tiếc là, cơ chế cơ bản về cách và tại sao PLMs thu nhận hoặc quên tri thức vẫn còn cần được khám phá. Và sẽ có giá trị để hiểu các hành vi của PLMs và truyền cảm hứng cho các chiến lược thu nhận tri thức tốt hơn.

Để hiểu các cơ chế cơ bản, một số nghiên cứu đi sâu vào động lực của quá trình tiền huấn luyện của LMs. Nhiều nhà nghiên cứu nghiên cứu động lực huấn luyện của mạng neural. Ví dụ, Achille et al. (2019) cố gắng tìm hiểu liệu có tồn tại các giai đoạn quan trọng trong quá trình học của mạng neural hay không. Liu et al. (2021c) dành riêng cho việc tìm giải pháp toán học cho sự phát triển ngữ nghĩa trong mạng tuyến tính sâu. Các nghiên cứu khác (Saphra and Lopez, 2019, 2020) phân tích động lực huấn luyện của LSTM (Hochreiter and Schmidhuber, 1997) với các kỹ thuật như SVCCA (Raghu et al., 2017). Trong khi hầu hết các nghiên cứu hiện có tập trung vào mạng neural với kiến trúc tương đối đơn giản. Chỉ có một số ít nghiên cứu xem xét tri thức trong các mô hình ngôn ngữ được tiền huấn luyện quy mô lớn. Chiang et al. (2020) đầu tiên một cách có hệ thống nghiên cứu quá trình thu nhận tri thức trong quá trình huấn luyện ALBERT (Lan et al., 2020). Cụ thể, họ nghiên cứu sự phát triển tri thức cú pháp, tri thức ngữ nghĩa, và tri thức thế giới trong quá trình tiền huấn luyện, và thấy rằng quá trình học khác nhau giữa các tri thức, và có nhiều bước tiền huấn luyện hơn không nhất thiết tăng tri thức trong PLMs. Pérez-Mayos et al. (2021) nghiên cứu ảnh hưởng của kích thước kho ngữ liệu tiền huấn luyện lên khả năng cú pháp của mô hình RoBERTa (Liu et al., 2019c), và thấy rằng các mô hình được tiền huấn luyện trên nhiều dữ liệu hơn thường chứa nhiều tri thức cú pháp hơn và hoạt động tốt hơn trong các tác vụ downstream liên quan. Liu et al. (2021c) cũng nghiên cứu quá trình thu nhận tri thức của RoBERTa (Liu et al., 2019c) trên các tri thức khác nhau. Và thấy rằng so với tri thức ngôn ngữ học có thể được học nhanh chóng và mạnh mẽ, tri thức thế giới được học chậm và nhạy cảm với miền.

3.2 Học từ Dữ liệu Có cấu trúc

Ngoài việc thu nhận tri thức từ văn bản thuần túy, PLMs cũng có thể thu nhận tri thức bằng cách tiêm tri thức có cấu trúc rõ ràng vào chúng. Trong phần này, chúng tôi xem xét những nghiên cứu này theo loại nguồn tri thức có cấu trúc.

Tri thức Thực thể Để học tri thức thực thể một cách rõ ràng, nhiều nghiên cứu đề xuất các tác vụ hướng dẫn thực thể cho việc tiền huấn luyện mô hình ngôn ngữ. Ví dụ, Sun et al. (2019) và Shen et al. (2020) sử dụng che cấp thực thể để tăng cường các mô hình ngôn ngữ, đầu tiên nhận ra các thực thể có tên trong một câu, sau đó tất cả các token tương ứng với những thực thể này bị che và được dự đoán cùng lúc. Xiong et al. (2020) trình bày việc phát hiện thực thể thay thế, ngẫu nhiên thay thế các thực thể có tên trong một câu bằng một đề cập khác của cùng thực thể hoặc các thực thể khác cùng loại, và LMs được cho là xác định thực thể nào bị thay thế. Yamada et al. (2020) coi từ và thực thể như các token độc lập, và thực hiện mô hình hóa ngôn ngữ che riêng biệt để học cả biểu diễn từ có ngữ cảnh và biểu diễn thực thể. Févry et al. (2020) kết hợp các mục tiêu tiền huấn luyện phát hiện đề cập và liên kết thực thể với mô hình hóa ngôn ngữ che để ghép các thực thể trong văn bản với các bộ nhớ thực thể cụ thể. Ngoài bản thân các đề cập thực thể, các nhà nghiên cứu cũng đã giới thiệu thông tin meta khác như mô tả thực thể để hỗ trợ thêm việc học tri thức thực thể (Logeswaran et al., 2019; Gillick et al., 2019). Một cách hiệu quả khác để làm giàu biểu diễn văn bản của PLMs với tri thức thực thể là sử dụng chú ý từ-đến-thực thể (Peters et al., 2019; Yamada et al., 2020).

Tri thức Thực tế Trong các cơ sở tri thức có cấu trúc, tri thức thực tế thường được biểu diễn dưới dạng bộ ba (thực thể chủ thể, quan hệ, thực thể đối tượng). Trong một thời gian dài, các nhà nghiên cứu đã dành riêng cho việc hỗ trợ PLMs thu nhận nhiều tri thức thực tế hơn để hoạt động tốt hơn trên các tác vụ downstream. Một mặt, việc giới thiệu nhúng đồ thị tri thức vào quá trình tiền huấn luyện có thể hiệu quả. Zhang et al. (2019) đề xuất một bộ tổng hợp để kết hợp nhúng tri thức tương ứng của các thực thể trong văn bản và nhúng token. Wang et al. (2021b) đồng huấn luyện các mục tiêu mô hình hóa ngôn ngữ che và nhúng đồ thị tri thức, có thể tạo ra cả nhúng văn bản và tri thức thông tin. Mặt khác, một số nghiên cứu đề xuất thiết kế các tác vụ phụ trợ hướng dẫn tri thức thực tế. Wang et al. (2021a) thêm một adapter để tiêm tri thức vào PLMs mà không cập nhật các tham số gốc. Adapter được huấn luyện với dự đoán để xác định loại quan hệ giữa các token. Qin et al. (2021) đề xuất các tác vụ phân biệt thực thể để dự đoán thực thể đối tượng cho thực thể chủ thể và quan hệ, cũng như các tác vụ phân biệt quan hệ để dự đoán kết nối ngữ nghĩa giữa các cặp quan hệ. Banerjee and Baral (2020) trực tiếp tiền huấn luyện mô hình ngôn ngữ trên đồ thị tri thức, mô hình được cho hai phần tử của một bộ ba tri thức để dự đoán phần còn lại. Liu et al. (2020) lập luận rằng việc kết hợp toàn bộ cơ sở tri thức vào PLMs có thể gây ra vấn đề nhiễu tri thức, và đề xuất học từ một đồ thị con cụ thể liên quan đến mỗi câu đầu vào. Hơn nữa, Baldini Soares et al. (2019) đề xuất học tri thức quan hệ chỉ từ văn bản liên kết thực thể thông qua mục tiêu "ghép vào chỗ trống", đầu tiên thay thế các thực thể trong văn bản bằng các ký hiệu trống và sau đó làm cho các biểu diễn quan hệ gần nhau hơn khi chúng có cùng cặp thực thể.

Tri thức Thường thức Một trong những chiến lược phổ biến nhất để PLMs học tri thức thường thức là chuyển đổi tri thức thành các biểu thức ngôn ngữ tự nhiên trước khi học. Bosselut et al. (2019); Guan et al. (2020); Shwartz et al. (2020) đầu tiên chuyển các bộ ba tri thức thường thức thành ngôn ngữ tự nhiên với prompt, sau đó tiền huấn luyện LMs trên những dữ liệu được tăng cường tri thức này. Ye et al. (2019) hậu huấn luyện LMs trên các bộ dữ liệu QA thường thức được tạo bởi AWS (căn chỉnh, che, chọn). Ma et al. (2021) chuyển đổi tri thức thường thức có cấu trúc thành các câu hỏi ngôn ngữ tự nhiên để mô hình học.

Tri thức Ngôn ngữ học Bằng cách thiết kế các tác vụ tiền huấn luyện tương ứng, PLMs cũng có thể học tri thức ngôn ngữ học một cách rõ ràng, như tri thức cảm xúc (Ke et al., 2020; Tian et al., 2020), tri thức từ vựng (Lauscher et al., 2020; Levine et al., 2020; Zhou et al., 2019), tri thức cú pháp (Zhou et al., 2019; Sachan et al., 2021; Bai et al., 2021), v.v. Ví dụ, để trang bị LMs với tri thức cảm xúc, Ke et al. (2020) đầu tiên gán nhãn mỗi từ với một thẻ POS và cực tính cảm xúc, và sau đó kết hợp cả nhãn cảm xúc cấp từ và cấp câu với mục tiêu mô hình hóa ngôn ngữ che. Tương tự, Tian et al. (2020) đầu tiên khai thác tri thức cảm xúc từ dữ liệu không được gán nhãn dựa trên thông tin tương hỗ điểm (PMI), và sau đó thực hiện các tác vụ tiền huấn luyện như che cảm xúc, dự đoán từ cảm xúc và dự đoán cực tính từ với thông tin cảm xúc này. Đối với tri thức từ vựng, Lauscher et al. (2020) đầu tiên thu nhận thông tin tương tự từ từ WordNet (Miller, 1992) và BabelNet (Navigli and Ponzetto, 2010), và sau đó thêm các tác vụ phân loại quan hệ từ ngoài các tác vụ tiền huấn luyện gốc của BERT. Levine et al. (2020) cũng giới thiệu thông tin từ vựng từ WordNet và thêm một tác vụ dự đoán từ bị che. Để kết hợp tri thức phụ thuộc với PLMs, Song et al. (2022) xây dựng một ma trận phụ thuộc để hiệu chỉnh căn chỉnh chú ý và một mô-đun hợp nhất để tích hợp thông tin phụ thuộc. Việc học rõ ràng tri thức cú pháp cũng gây ra sự chú ý của các nhà nghiên cứu, Sachan et al. (2021) nghiên cứu việc tiêm tri thức cú pháp bằng cách thêm một GNN cú pháp trên đầu ra của transformer hoặc kết hợp với nhúng văn bản bằng chú ý. Để nắm bắt thêm tri thức cú pháp, Bai et al. (2021) sử dụng nhiều mạng chú ý, với mỗi mạng mã hóa một quan hệ từ cây cú pháp.

3.3 Thảo luận và Nghiên cứu Tương lai

Như chúng tôi đã đề cập ở trên, đã có các nghiên cứu rộng rãi để thu nhận tri thức tốt hơn của các mô hình ngôn ngữ, và hầu hết chúng tập trung vào việc tiêm các nguồn tri thức có cấu trúc hiện có vào PLMs. Các phương pháp học từ dữ liệu văn bản có thể được mở rộng dễ dàng, và các nguồn tri thức được thu nhận dễ dàng. Nhưng cơ chế cơ bản vẫn chủ yếu không rõ ràng, quá trình thu nhận tri thức là ngầm định và do đó khó kiểm soát, và có thể dẫn đến dự đoán không nhất quán, thiên kiến không mong muốn và rủi ro không lường trước. Các phương pháp học từ dữ liệu có cấu trúc có thể tiêm tri thức một cách rõ ràng vào PLMs, nhưng bị hạn chế bởi chi phí, miền, quy mô và chất lượng của các nguồn tri thức. Hơn nữa, vì các phương pháp tiêm tri thức thường được chuyên hóa cho các loại tri thức cụ thể, thường khó mở rộng hoặc tạo ra tri thức mới.

Hơn nữa, vì tất cả tri thức trong PLMs đều được mã hóa ngầm định như các tham số, thường rất khó kiểm soát và xác thực quá trình thu nhận tri thức. Cũng có một số nghiên cứu như PLMs dựa trên truy xuất, tập trung vào việc truy xuất tri thức hoặc ngữ cảnh liên quan để tăng cường PLMs gốc (Guu et al., 2020; Lewis et al., 2020b; Yasunaga et al., 2022), thay vì tiêm tri thức vào các tham số của PLMs.

Một số hướng tương lai của việc thu nhận tri thức trong PLMs có thể nằm ở: 1) Đối với việc thu nhận tri thức từ các nguồn tri thức có cấu trúc hiện có, điều quan trọng là phát triển các phương pháp tiêm tri thức toàn cầu có thể tiêm một cách thống nhất các loại tri thức khác nhau từ các nguồn tri thức khác nhau, và đảm bảo học liên tục và tránh quên thảm khốc trong khi đó. 2) Đối với việc thu nhận tri thức từ dữ liệu văn bản thuần túy, sẽ hữu ích khi hiểu đầy đủ cơ chế cơ bản của việc học tri thức trong PLMs, và phát triển các thuật toán học tri thức hiệu quả có thể học tri thức cụ thể từ dữ liệu văn bản một cách có thể kiểm soát và dự đoán được. 3) Hơn nữa, cũng quan trọng là xây dựng các benchmark toàn diện để nghiên cứu và đánh giá quá trình thu nhận tri thức của PLMs.

4 Biểu diễn Tri thức

Các nghiên cứu biểu diễn tri thức nghiên cứu cách các mô hình ngôn ngữ được tiền huấn luyện mã hóa, chuyển đổi và lưu trữ tri thức đã thu nhận. Trong PLMs, tri thức được mã hóa thành các biểu diễn vector dày đặc và được giữ trong các tham số phân tán của chúng, nhưng cách mỗi loại tri thức được mã hóa, chuyển đổi và lưu trữ vào các tham số vẫn chưa rõ ràng và cần nghiên cứu thêm. Hiện tại, một số ít nghiên cứu đã điều tra biểu diễn tri thức trong các mô hình ngôn ngữ, và chúng tôi sẽ đầu tiên xem xét những nghiên cứu này theo các kỹ thuật phân tích của chúng.

4.1 Phân tích Biểu diễn Tri thức trong PLMs

Hiện tại, các phương pháp phân tích biểu diễn tri thức trong PLMs có thể được phân loại thành bốn loại: dựa trên gradient, lấy cảm hứng từ nhân quả, dựa trên chú ý và theo từng lớp. Ba phương pháp đầu nhằm định vị tri thức cụ thể trong các neuron tương ứng hoặc đầu chú ý của PLMs, và các phương pháp theo từng lớp giả định rằng tri thức được biểu diễn trong các lớp khác nhau của PLMs.

Dựa trên Gradient Dai et al. (2022a) đầu tiên giới thiệu khái niệm neuron tri thức, là các neuron trong transformer (Vaswani et al., 2017) liên quan đến tri thức thực tế nhất định. Cụ thể, họ giả định các neuron tri thức được định vị trong các mạng feed-forward, được coi là bộ nhớ khóa-giá trị (Geva et al., 2021). Sau đó bằng cách đưa LM với các prompt biểu thức tri thức như "Michael Jordan sinh ra ở [MASK]", neuron tri thức tương ứng được xác định là các neuron trong mạng feed-forward với điểm số quy kết cao hơn, được tính dựa trên gradient tích hợp.

Lấy cảm hứng từ Nhân quả Meng et al. (2022) xác định các neuron tri thức như các kích hoạt neuron trong transformer có ảnh hưởng nhân quả mạnh nhất đến việc dự đoán tri thức thực tế nhất định. Những neuron như vậy được định vị thông qua phân tích trung gian nhân quả. Cụ thể, họ tính toán ảnh hưởng nhân quả đến dự đoán thực tế bằng cách so sánh biến thiên xác suất của dự đoán đối tượng giữa nhúng token sạch và bị hỏng. Các thí nghiệm của họ cũng chứng minh rằng các mô-đun feed-forward lớp giữa đóng vai trò quyết định trong biểu diễn tri thức thực tế.

Dựa trên Chú ý Ngoài các lớp feed-forward, các đầu chú ý cũng được coi là biểu diễn có thể mã hóa thông tin liên quan đến tri thức. Clark et al. (2019); Htut et al. (2019) nghiên cứu tri thức ngôn ngữ học được mã hóa trong các đầu chú ý, và thấy rằng trong khi một số đầu chú ý cá nhân được liên kết với các khía cạnh cụ thể của cú pháp, tri thức ngôn ngữ học được phân bố và biểu diễn bởi nhiều đầu chú ý. Lin et al. (2019) thấy rằng trọng số chú ý của PLMs có thể mã hóa các thuộc tính cú pháp như thỏa thuận chủ-vị và phụ thuộc phản thân, và các lớp cao hơn biểu diễn những thuộc tính cú pháp này chính xác hơn.

Theo từng Lớp Lin et al. (2019) tiến hành thăm dò theo từng lớp cho tri thức ngôn ngữ học, huấn luyện một bộ phân loại cụ thể cho mỗi lớp, và thấy rằng các lớp thấp hơn mã hóa thông tin vị trí của các token, và các lớp cao hơn mã hóa thông tin tổng hợp hơn. Liu et al. (2019a) phân tích khả năng chuyển giao theo lớp của PLMs trên một loạt các tác vụ và thấy rằng các lớp giữa thường có hiệu suất và khả năng chuyển giao tốt hơn. Wallat et al. (2020) đề xuất thăm dò tri thức thực tế được nắm bắt với LAMA (Petroni et al., 2019) của mỗi lớp trong PLMs, và thấy rằng một lượng đáng kể tri thức được lưu trữ trong các lớp trung gian. Juneja and Agarwal (2022) cũng tiến hành phân tích tri thức thực tế theo lớp dựa trên neuron tri thức (Dai et al., 2022a), và chứng minh rằng hầu hết tri thức quan hệ (ví dụ, Paris là thủ đô của "một quốc gia nào đó".) có thể được quy cho các lớp giữa, sẽ được tinh chế thành sự kiện (ví dụ, Paris là thủ đô của Pháp.) trong vài lớp cuối.

4.2 Thảo luận và Nghiên cứu Tương lai

Các nghiên cứu trên đạt được một số đồng thuận về biểu diễn tri thức trong PLMs, bao gồm: 1) Tri thức thực tế có thể được liên kết với các mô-đun feed-forward trong các lớp giữa hoặc cao hơn. 2) Tri thức ngôn ngữ học được phân bố và biểu diễn trong nhiều đầu chú ý, trong khi một đầu chú ý đơn lẻ chỉ có thể liên kết với một khía cạnh cụ thể của ngôn ngữ học. 3) Các lớp thấp hơn của PLMs thường mã hóa thông tin thô và tổng quát của tri thức, trong khi tri thức tinh và cụ thể theo tác vụ chủ yếu được lưu trữ trong các lớp cao hơn. Những phát hiện này có giá trị để chúng ta hiểu biểu diễn tri thức trong các mô hình ngôn ngữ nhưng cũng bị hạn chế đối với các loại tri thức cụ thể hoặc kiến trúc mô hình. Do đó biểu diễn tri thức trong PLMs vẫn là một vấn đề mở cần khám phá thêm.

Trong tương lai, một số hướng biểu diễn tri thức trong PLMs có thể nằm ở những điều sau: 1) Vì biểu diễn tri thức là một mối quan tâm lâu dài trong khoa học nhận thức, khoa học thần kinh, tâm lý học và trí tuệ nhân tạo, sẽ hữu ích khi vay mượn ý tưởng từ các lĩnh vực liên quan khác và thiết kế các phương pháp phân tích lấy cảm hứng từ nhận thức. 2) Các nghiên cứu biểu diễn tri thức hiện tại trong PLMs chủ yếu tập trung vào một loại tri thức cụ thể và thường dẫn đến các kết luận cục bộ và cụ thể. Quan trọng là phải nghiên cứu toàn diện các loại tri thức khác nhau cùng nhau, ví dụ, so sánh sự khác biệt và điểm chung của biểu diễn tri thức của các loại tri thức khác nhau, tác vụ tiền huấn luyện, hoặc kiến trúc mô hình, và đưa ra những kết luận phổ quát và sâu sắc hơn.

5 Thăm dò Tri thức

Thăm dò tri thức nhằm đánh giá mức độ các mô hình ngôn ngữ được tiền huấn luyện chứa đựng các loại tri thức khác nhau. Một đánh giá toàn diện và chính xác về tri thức của PLMs có thể giúp chúng ta xác định và hiểu khả năng và thiếu sót của các mô hình ngôn ngữ, cho phép so sánh công bằng giữa các LMs với kiến trúc và tác vụ tiền huấn luyện khác nhau, hướng dẫn việc cải thiện một mô hình cụ thể, và lựa chọn các mô hình phù hợp cho các tình huống thực tế khác nhau. Trong phần này, chúng tôi sẽ đầu tiên giới thiệu các benchmark hiện có để thăm dò tri thức, sau đó giới thiệu các phương pháp thăm dò dựa trên prompt và dựa trên đặc trưng đại diện và phân tích các hạn chế tương ứng của chúng, và thảo luận về các hướng tương lai.

5.1 Benchmark để Thăm dò Tri thức

Để đánh giá tri thức trong PLMs, nhiều benchmark đã được đề xuất để thăm dò các tri thức khác nhau chứa trong PLMs, ví dụ, tri thức ngôn ngữ học (Ettinger, 2020; Warstadt et al., 2020; Lin et al., 2019; Warstadt et al., 2019; Tenney et al., 2019), tri thức cú pháp (Clark et al., 2019; Hewitt and Manning, 2019), tri thức thực tế (Petroni et al., 2019; Jiang et al., 2020a; Kassner et al., 2021; Sung et al., 2021), tri thức thường thức (Forbes et al., 2019; Zhou et al., 2020a), v.v. Bảng 1 tóm tắt một số benchmark thăm dò tri thức đại diện.

5.2 Thăm dò Tri thức Dựa trên Prompt

Thăm dò dựa trên prompt là một trong những phương pháp phổ biến nhất để thăm dò tri thức. Để đánh giá liệu LMs có biết một tri thức cụ thể như nơi sinh của Michael Jordan, chúng ta có thể truy vấn LMs với các truy vấn tri thức như "Michael Jordan sinh ra ở .", trong đó "sinh ra ở" là một prompt cho một loại tri thức cụ thể. Như được thể hiện trong Bảng 1, thăm dò dựa trên prompt đã được sử dụng rộng rãi trong các benchmark như LAMA (Petroni et al., 2019), oLMpics (Talmor et al., 2020), chẩn đoán LM (Ettinger, 2020), BIG-bench (Srivastava et al., 2022), v.v.

Đối với thăm dò dựa trên prompt, thách thức chính là cách thiết kế các prompt hiệu quả phù hợp với các loại tri thức khác nhau và các PLMs khác nhau. Trong phần sau, chúng tôi sẽ giới thiệu các loại prompt điển hình để thăm dò tri thức và thảo luận về các hạn chế của chúng.

5.2.1 Phát triển Prompt

Prompt Thủ công Các phương pháp sớm thường viết prompt thủ công cho các loại tri thức khác nhau. Có hai ưu điểm chính của prompt được tạo thủ công: khả năng đọc được và không cần bất kỳ tài nguyên hoặc huấn luyện nào khác. Ví dụ, LAMA (Petroni et al., 2019) tạo thủ công một prompt kiểu cloze cho mỗi quan hệ, được sử dụng để thăm dò tri thức thực tế trong các mô hình ngôn ngữ. CAT (Zhou et al., 2020a) tái khung các thể hiện trong các bộ dữ liệu thường thức hiện có thành các câu ghép cặp với prompt cụ thể theo tác vụ, và xác định liệu PLMs có chứa tri thức thường thức cụ thể bằng cách so sánh điểm số câu, ví dụ, "tiền có thể được sử dụng để mua xe hơi" so với "tiền có thể được sử dụng để mua sao". oLMpics (Talmor et al., 2020) chuyển đổi các tác vụ thăm dò khả năng lý luận thành các câu hỏi trắc nghiệm với prompt được tạo thủ công, và so sánh xác suất của PLMs đối với các lựa chọn ứng viên.

Prompt Rời rạc Được tối ưu Mặc dù có những ưu điểm đã đề cập, Jiang et al. (2020b) lập luận rằng prompt thủ công có thể không tối ưu. Do đó, một loạt nghiên cứu đã được đề xuất để tối ưu hóa prompt trong không gian rời rạc để PLMs có thể đạt được hiệu suất tốt hơn. Jiang et al. (2020b) đề xuất một phương pháp dựa trên khai thác để tìm prompt với hiệu suất cao hơn từ kho ngữ liệu văn bản. Họ đầu tiên truy xuất các prompt tiềm năng chứa cả thực thể chủ thể và đối tượng, sau đó chọn prompt bằng một bộ dữ liệu xác thực. Davison et al. (2019) chọn prompt từ một tập ứng viên được tạo thủ công theo log-likelihood được tính bởi LMs. Haviv et al. (2021) đề xuất một phương pháp dựa trên diễn giải, trong đó mỗi truy vấn đầu tiên được tái khung bởi một bộ viết lại được huấn luyện và sau đó được đưa vào PLMs. Shin et al. (2020) đề xuất một phương pháp tạo prompt tự động dựa trên tìm kiếm hướng dẫn gradient, trong đó một prompt được cập nhật lặp đi lặp lại từ token "[MASK]" bằng cách tối đa hóa khả năng nhãn của các thể hiện huấn luyện.

Prompt Liên tục Mặc dù các prompt được tạo bởi Shin et al. (2020) là văn bản rời rạc, chúng rất khó hiểu đối với con người. Do đó một số nghiên cứu trực tiếp tìm kiếm prompt hoạt động tốt hơn trên không gian liên tục thay vì giới hạn ở không gian rời rạc, tức là, biểu diễn prompt như các vector dày đặc. Prompt liên tục đã cho thấy hiệu suất tốt để thăm dò tri thức, và các mở rộng tiếp theo bao gồm khởi tạo prompt thủ công (Zhong et al., 2021), thêm prompt liên tục trên cả khối đầu vào và transformer (Li and Liang, 2021a) hoặc thêm các lớp LSTM phía trên nhúng đầu vào (Liu et al., 2021b).

5.2.2 Hạn chế của Thăm dò Dựa trên Prompt

Mặc dù prompt đã được sử dụng rộng rãi để thăm dò tri thức trong PLMs, vẫn có nhiều vấn đề chưa được giải quyết, khiến kết quả thăm dò không ổn định và việc đánh giá tri thức trong PLMs không đáng tin cậy.

Không nhất quán Thăm dò dựa trên prompt đã được chứng minh thường dẫn đến kết quả không nhất quán do lựa chọn prompt, cách diễn đạt thể hiện, phủ định, v.v. Thứ nhất, Elazar et al. (2021) thấy rằng các prompt tương đương về mặt ngữ nghĩa có thể dẫn đến các dự đoán khác nhau, Cao et al. (2022) tiếp tục thấy rằng PLMs sẽ ưa thích các prompt cụ thể có cùng tính thường xuyên ngôn ngữ với kho ngữ liệu tiền huấn luyện, sự ưa thích prompt như vậy sẽ ảnh hưởng đáng kể đến kết quả thăm dò, và dẫn đến so sánh không nhất quán giữa các PLMs. Ngoài prompt, quá trình diễn đạt thể hiện cũng dẫn đến dự đoán không nhất quán. Ví dụ, khi chúng ta hỏi BERT "Thủ đô của Hoa Kỳ là [MASK]", câu trả lời là Washington, nhưng khi chúng ta thay thế Hoa Kỳ bằng bí danh America, dự đoán sẽ thay đổi thành Chicago. Ngoài ra, PLMs cũng thể hiện sự không nhất quán khi đối mặt với phủ định (Kassner and Schütze, 2020; Jang et al., 2022). Chẳng hạn, PLMs sẽ tạo ra các dự đoán rất tương tự giữa một sự kiện ("Chim có thể bay") và phủ định không chính xác của nó ("Chim không thể bay") (Kassner and Schütze, 2020). Jang et al. (2022) tiến hành các thí nghiệm phủ định trên PLMs với kích thước khác nhau và các tác vụ downstream khác nhau, và thấy rằng không chỉ PLMs không thể hiểu rõ prompt phủ định, mà còn cho thấy một quy luật tỷ lệ ngược.

Không chính xác Hiệu suất của PLMs dưới thăm dò dựa trên prompt cũng có thể bị đánh giá quá cao. Poerner et al. (2020) thấy rằng nhiều mẫu trong các bộ dữ liệu thăm dò có thể dễ dàng được "đoán" chỉ bằng cách dựa vào liên kết dạng bề mặt. Ví dụ, thực thể đối tượng là một chuỗi con của thực thể chủ thể (ví dụ, "Apple Watch được sản xuất bởi Apple"). Hơn nữa, bộ dữ liệu huấn luyện để tối ưu hóa prompt có thể tương quan với bộ dữ liệu thăm dò, dẫn đến tương quan giả mạo (Zhong et al., 2021) và những cải thiện hiệu suất có thể đến từ những tương quan giả mạo này. Cao et al. (2021) cũng thấy rằng nhiều prompt với hiệu suất tốt hơn là những prompt over-fit với phân bố câu trả lời, thay vì một mô tả ngữ nghĩa tốt hơn của quan hệ đích.

Không đáng tin cậy Để đạt được kết quả thăm dò trung thực, điều cần thiết là hiểu tại sao PLMs đưa ra một dự đoán cụ thể. Tuy nhiên, các nghiên cứu thấy rằng PLMs không phải lúc nào cũng đưa ra dự đoán dựa trên tri thức cụ thể. Trong trường hợp đó, kết quả thăm dò tri thức có thể không đáng tin cậy. Cao et al. (2021) thấy rằng prompt chứ không phải câu trả lời chi phối phân bố dự đoán của PLMs, dẫn đến kết luận thăm dò thiên vị prompt nghiêm trọng. Li et al. (2022a) tiến hành phân tích lấy cảm hứng từ nhân quả và thấy rằng dự đoán của PLMs dựa nhiều hơn vào các từ gần về vị trí và thường xuyên xuất hiện cùng nhau, thay vì những từ liên quan đến tri thức.

Phân tích Thiên kiến Trong khi nhiều nghiên cứu tiến hành các thí nghiệm thực nghiệm về thiên kiến trong thăm dò dựa trên prompt, ít nghiên cứu điều tra nguồn gốc và giải thích của những thiên kiến này. Một số nghiên cứu sử dụng phân tích nhân quả để phân tích thiên kiến, đã được sử dụng rộng rãi để xác định thiên kiến không mong muốn và mối quan tâm về công bằng (Hardt et al., 2016; Kilbertus et al., 2017; Kusner et al., 2017; Vig et al., 2020; Feder et al., 2021). Cao et al. (2022) đề xuất một khung phân tích nhân quả để xác định, giải thích và loại bỏ thiên kiến tồn tại trong thăm dó dựa trên prompt với đảm bảo lý thuyết. Tương tự, Elazar et al. (2022) cũng đề xuất một khung nhân quả để ước tính ảnh hưởng nhân quả của thống kê dữ liệu trong kho ngữ liệu huấn luyện đến dự đoán thực tế của PLMs. Finlayson et al. (2021) áp dụng phân tích trung gian nhân quả để nghiên cứu các cơ chế thỏa thuận cú pháp trong PLMs.

5.3 Thăm dò Tri thức Dựa trên Đặc trưng

Thăm dò tri thức dựa trên đặc trưng cũng được sử dụng rộng rãi để thăm dò tri thức trong PLMs, trong đó các tham số của PLMs gốc được đóng băng, và các tác vụ thăm dò được hoàn thành dựa trên biểu diễn nội bộ hoặc trọng số chú ý do PLMs tạo ra. Trong phần này, chúng tôi giới thiệu và thảo luận các phương pháp thăm dò dựa trên đặc trưng.

5.3.1 Thăm dò Dựa trên Bộ phân loại

Thăm dò dựa trên bộ phân loại huấn luyện một bộ phân loại để dự đoán các thuộc tính tri thức cụ thể trên đỉnh của PLMs cố định, và đánh giá hiệu quả của PLMs bằng hiệu suất của bộ phân loại (Belinkov, 2022). Những phương pháp như vậy đầu tiên được đề xuất để đánh giá các thuộc tính ngôn ngữ học (ví dụ, hình thái, cú pháp) liên kết với nhúng tĩnh (Köhn, 2015; Gupta et al., 2015), và đã được sử dụng rộng rãi để thăm dò tri thức ngôn ngữ học (Lin et al., 2019; Tenney et al., 2019; Clark et al., 2019; Liu et al., 2019a; Hewitt and Manning, 2019) và tri thức ngữ nghĩa (Tenney et al., 2019; Wallace et al., 2019; Yaghoobzadeh et al., 2019; Liu et al., 2019a) trong PLMs. Các bộ phân loại phổ biến bao gồm bộ phân loại tuyến tính, hồi quy logistic, perceptron đa lớp, v.v.

5.3.2 Thăm dò Không dùng Bộ phân loại

Vì kết quả và kết luận của các phương pháp dựa trên bộ phân loại phụ thuộc vào chất lượng huấn luyện và lựa chọn bộ phân loại, một số nghiên cứu đã phát triển các phương pháp thăm dò dựa trên đặc trưng mà không có bộ phân loại bổ sung. Ví dụ, Wu et al. (2020) đề xuất che nhiễu loạn, tính toán ma trận tác động thông qua nhiễu loạn hai giai đoạn, trong đó ma trận nắm bắt tác động mà một token có đối với dự đoán của token khác, và được sử dụng thêm cho thăm dò cú pháp. Zhou and Srikumar (2021b) giới thiệu DirectProbe, thăm dò trực tiếp các thuộc tính hình học của biểu diễn PLMs mà không có bộ phân loại bổ sung. Clark et al. (2019) thăm dò tri thức cú pháp trong các mô hình ngôn ngữ bằng cách nghiên cứu trọng số chú ý mà không có bộ phân loại, ví dụ, phân tích từ được chú ý nhất của token đã cho.

5.3.3 Hạn chế của Thăm dò Dựa trên Đặc trưng

Có hai hạn chế chính của các phương pháp thăm dò dựa trên đặc trưng hiện tại (Rogers et al., 2020; Belinkov, 2022). Hạn chế đầu tiên liên quan đến việc quy kết quả, ban đầu được Hewitt and Manning (2019) chỉ ra. Trong khi hầu hết các probe giới thiệu dữ liệu huấn luyện và tham số bổ sung, khó quy kết quả đánh giá cho tri thức trong PLMs, hoặc bản thân probe, có thể học để thực hiện tác vụ thăm dò. Hạn chế thứ hai liên quan đến sự không nhất quán giữa các thiết kế probe khác nhau cho cùng một loại tri thức. Có nhiều lựa chọn probe khác nhau cho mỗi loại tri thức, nhưng kết quả probe giữa các probe đơn giản như bộ phân loại tuyến tính hoặc probe phức tạp có thể không nhất quán.

5.4 Thảo luận và Nghiên cứu Tương lai

Với quy mô và khả năng ngày càng tăng của các mô hình ngôn ngữ lớn, việc đo lường toàn diện, chính xác và đáng tin cậy về tri thức và khả năng thực tế của LMs trở nên ngày càng quan trọng. Tuy nhiên, phương pháp thăm dò chính xác, mạnh mẽ và đáng tin cậy vẫn là một vấn đề mở. Thứ nhất, như chúng tôi đã thảo luận ở trên, cả thăm dò dựa trên prompt và thăm dó dựa trên đặc trưng đều có hạn chế riêng, có thể dẫn đến kết luận không đáng tin cậy hoặc thậm chí mâu thuẫn. Thứ hai, hầu hết các benchmark hiện có được chuyên hóa cho các loại tri thức cụ thể và kiến trúc mô hình cụ thể.

Trong tương lai, các hướng chính của thăm dò tri thức có thể nằm ở: 1) Xây dựng benchmark toàn diện. Như chúng tôi chứng minh trong bảng 1, các benchmark thăm dò tri thức hiện tại chủ yếu quá chuyên biệt, có thể dẫn đến kết quả không nhất quán, thiên vị hoặc không đáng tin cậy. Do đó, việc xây dựng một benchmark toàn diện và không thiên vị là rất quan trọng. 2) Các phương pháp thăm dó khử thiên kiến. Hiện tại thăm dò dựa trên prompt là phương pháp thăm dó tri thức chủ đạo do tính đơn giản của nó. Tuy nhiên, vẫn tồn tại nhiều vấn đề trong thăm dò dựa trên prompt. Do đó, việc thiết kế các bộ dữ liệu không thiên vị và khung thăm dò tốt hơn là một hướng hữu ích khác đáng nghiên cứu.

6 Chỉnh sửa Tri thức

Chỉnh sửa tri thức là quá trình sửa đổi tri thức được lưu trữ trong các mô hình ngôn ngữ được tiền huấn luyện, bằng cách thay thế nó bằng tri thức mới (ví dụ, thay đổi thủ tướng hiện tại của Vương quốc Anh thành Rishi Sunak) hoặc bằng cách loại bỏ hoàn toàn (ví dụ, một số thông tin riêng tư cá nhân). Có hai động lực chính để chỉnh sửa tri thức trong các mô hình ngôn ngữ: 1) thậm chí các mô hình ngôn ngữ tiên tiến nhất (ví dụ ChatGPT2) có thể học được nhiều tri thức không chính xác; 2) nhiều sự kiện nhạy cảm với thời gian, đòi hỏi cập nhật thường xuyên tri thức tương ứng của chúng.

Tiếc là, việc chỉnh sửa tri thức trong PLMs đặt ra những thách thức đáng kể. Thứ nhất, các giải pháp ngây thơ như huấn luyện lại thường không thực tế do kích thước khổng lồ của các mô hình ngôn ngữ quy mô lớn. Thứ hai, do bản chất hộp đen và phi tuyến của PLMs, bất kỳ sửa đổi nhỏ nào cũng có thể dẫn đến thay đổi đáng kể không mong muốn trong dự đoán mô hình. Kết quả là, có thể khó chỉnh sửa chính xác tri thức đích.

Để thúc đẩy sự phát triển của các nghiên cứu liên quan, De Cao et al. (2021) đưa ra ba mong muốn cho các phương pháp chỉnh sửa tri thức: 1) Tính tổng quát: phương pháp có thể chỉnh sửa các mô hình ngôn ngữ đã được tiền huấn luyện mà không cần huấn luyện lại chuyên biệt. 2) Độ tin cậy: phương pháp được cho là chỉnh sửa thành công tri thức cần sửa đổi trong khi không ảnh hưởng đến phần còn lại của tri thức trong LMs. 3) Tính nhất quán: việc sửa đổi phải nhất quán qua các diễn giải với ngữ nghĩa tương đương (ví dụ, Michael Jordan sinh ra ở [MASK]. so với Nơi sinh của Michael Jordan là [MASK].) và tri thức liên quan cần sửa đổi tương ứng (ví dụ, Rishi Sunak trở thành thủ tướng Vương quốc Anh. so với Liz Truss không phải là thủ tướng Vương quốc Anh.).

Trong phần này, chúng tôi chia các chiến lược hiện tại để chỉnh sửa tri thức thành bốn loại và so sánh tóm tắt giữa những phương pháp này được thể hiện trong Bảng 2. Trong phần sau, chúng tôi sẽ mô tả và thảo luận những phương pháp này.

6.1 Điều chỉnh Có ràng buộc

Giải pháp ngây thơ để chỉnh sửa tri thức trong PLM là huấn luyện lại nó bằng bộ dữ liệu huấn luyện được cập nhật, nhưng giải pháp ngây thơ như vậy tốn kém về mặt tính toán và có thể không thực tế vì PLMs có liên quan. Do đó, một giải pháp tốt hơn là điều chỉnh tinh PLMs chỉ trên một tập con nhỏ chỉ chứa các mẫu đích. Tuy nhiên, phương pháp như vậy có thể gặp phải quên thảm khốc, và ảnh hưởng đến phần còn lại của tri thức không có ý định chỉnh sửa. Do đó, Zhu et al. (2020) đề xuất sửa đổi tri thức trong PLMs với điều chỉnh tinh có ràng buộc, cụ thể, họ sử dụng chuẩn hóa L2 hoặc L1 để ràng buộc thay đổi tham số của các mô hình. Hơn nữa, họ thấy rằng chỉ điều chỉnh tinh các lớp đầu và cuối trong khi giữ phần còn lại của mô hình đóng băng mang lại hiệu suất tốt hơn so với điều chỉnh tinh toàn bộ mô hình. Tuy nhiên, trong các mạng neural sâu như PLMs, thậm chí một thay đổi nhỏ của các tham số có thể thay đổi dự đoán của mô hình trên nhiều mẫu. Do đó, những phương pháp như vậy có thể ảnh hưởng đến tri thức khác được lưu trữ trong PLMs mà không cần sửa đổi.

6.2 Chỉnh sửa Dựa trên Bộ nhớ

Thay vì trực tiếp sửa đổi tham số của PLMs, một giải pháp tự nhiên khác là duy trì một bộ nhớ cache tri thức lưu trữ tất cả tri thức mới, và thay thế dự đoán gốc khi một đầu vào trúng cache. Tuy nhiên, một bộ nhớ cache tri thức ký hiệu có thể gặp vấn đề về tính mạnh mẽ, tức là, các đầu vào có cùng ý nghĩa có thể khác nhau trong biểu thức ngôn ngữ tự nhiên, do đó chúng có thể dẫn đến dự đoán khác nhau. Để giải quyết vấn đề này, Mitchell et al. (2022) đề xuất một phương pháp dựa trên bộ nhớ để chỉnh sửa tri thức. Cụ thể, mô hình chứa năm mô-đun: một bộ nhớ chỉnh sửa lưu trữ tri thức được sửa đổi, một bộ phân loại, một mô hình phản thực tế, và mô hình ngôn ngữ gốc được đóng băng. Cho một đầu vào, bộ phân loại xác định liệu nó có trúng một mẫu trong bộ nhớ chỉnh sửa hay không, và dự đoán của mô hình phản thực tế sẽ ghi đè dự đoán của mô hình ngôn ngữ gốc nếu nó trúng một bộ nhớ cache. Phương pháp này hiệu quả nhưng không thực sự chỉnh sửa tri thức được mã hóa trong các tham số của mô hình ngôn ngữ, do đó không thể mang lại lợi ích cho các tác vụ downstream. Trong khi đó, Dong et al. (2022) thêm các tham số có thể huấn luyện bổ sung trong mô-đun feed-forward của PLMs, được huấn luyện trên bộ dữ liệu tri thức được sửa đổi trong khi các tham số gốc được đóng băng. Họ cũng chứng minh rằng tri thức được sửa đổi có thể mang lại lợi ích cho các tác vụ QA liên quan. Hơn nữa, Madaan et al. (2022) giới thiệu phản hồi của người dùng để sửa lỗi PLMs. Cụ thể, họ duy trì một bộ nhớ về lỗi của mô hình và phản hồi của người dùng, tăng cường mô hình để tạo ra prompt được cập nhật và tránh những lỗi tương tự.

6.3 Chỉnh sửa Dựa trên Meta-learning

Sinitsin et al. (2020) đầu tiên đề xuất huấn luyện có thể chỉnh sửa để tiến hành chỉnh sửa mô hình dựa trên meta-learning, nhằm huấn luyện các tham số mô hình để phù hợp với chỉnh sửa mô hình. Bằng cách ràng buộc mục tiêu huấn luyện, quá trình chỉnh sửa có thể được hoàn thành dưới k bước gradient trong khi đảm bảo độ tin cậy, tính cục bộ và hiệu quả. Tuy nhiên, phương pháp như vậy không thực tế cho các mô hình ngôn ngữ được tiền huấn luyện vì nó đòi hỏi huấn luyện lại chuyên biệt đắt đỏ. Một chiến lược khác là sử dụng một mạng siêu, sử dụng một mạng để tạo ra trọng số của mạng khác (Ha et al., 2017). De Cao et al. (2021); Hase et al. (2021) huấn luyện một mạng siêu để dự đoán thay đổi tham số cho mỗi điểm dữ liệu, với ràng buộc chỉnh sửa tri thức đích mà không ảnh hưởng đến các tri thức khác. Mặc dù hiệu quả về mặt tính toán, Mitchell et al. (2021) lập luận rằng phương pháp này không thể chỉnh sửa các mô hình rất lớn, và đề xuất các mạng biên tập mô hình với phân rã gradient (MEND). Cụ thể, bằng cách phân rã gradient của điều chỉnh tinh tiêu chuẩn thành dạng hạng thấp, họ có thể huấn luyện nhiều MLP để tạo ra thay đổi tham số mô hình cục bộ, mà không làm hỏng dự đoán của mô hình trên tri thức không liên quan. Các thí nghiệm cho thấy rằng MEND có thể được áp dụng cho các mô hình được tiền huấn luyện lớn để chỉnh sửa mô hình nhanh. Một hạn chế của các phương pháp dựa trên meta-learning hiện có là tính mạnh mẽ và khả năng tổng quát của chúng vẫn còn đáng ngờ, vì chúng đảm bảo tính cục bộ bằng cách ràng buộc thay đổi không gian tham số hoặc dự đoán trên các bộ dữ liệu cụ thể. Trong trường hợp đó, tri thức không cần sửa đổi hoặc tri thức liên quan đến tri thức được chỉnh sửa nhưng không phải diễn giải cũng có thể không chính xác.

6.4 Định vị và Chỉnh sửa

Dựa trên giả định rằng "tri thức được lưu trữ cục bộ trong PLMs", chiến lược "định vị và chỉnh sửa" đầu tiên định vị các tham số tương ứng với tri thức cụ thể, và chỉnh sửa chúng bằng cách thay thế trực tiếp bằng những tham số được cập nhật. Phương pháp này cũng được giới thiệu trong Phần 4.1. Dai et al. (2022a) trình bày một nghiên cứu trường hợp về chỉnh sửa tri thức thực tế trong PLMs với các neuron tri thức tương ứng. Bằng cách trực tiếp sửa đổi giá trị của neuron tri thức, họ đạt được chỉnh sửa tri thức với tỷ lệ thành công tương đối thấp nhưng không tầm thường. Mặc dù quá trình chỉnh sửa đơn giản khi neuron tri thức tương ứng được định vị, phương pháp này chưa chứng minh hiệu quả của nó trên chỉnh sửa quy mô lớn hoặc ảnh hưởng của tri thức không liên quan. Tương tự, Meng et al. (2022) đầu tiên kết nối tri thức cần sửa đổi với một cặp khóa-giá trị trong một trong các lớp MLP giữa, và sửa đổi tri thức tương ứng bằng cách trực tiếp cập nhật cặp khóa-giá trị. Vì những phương pháp này dựa trên giả thuyết tính cục bộ của tri thức thực tế, chưa được xác nhận rộng rãi, những thay đổi trong các tham số nhất định có thể ảnh hưởng đến tri thức không liên quan và dẫn đến kết quả bất ngờ.

6.5 Thảo luận và Nghiên cứu Tương lai

Để sử dụng các mô hình ngôn ngữ được tiền huấn luyện như một nguồn tri thức bền vững, việc chỉnh sửa tri thức chính xác, hiệu quả, đáng tin cậy và nhất quán là thiết yếu. Tuy nhiên, như đã thảo luận ở trên, tất cả các phương pháp chỉnh sửa hiện tại đều có hạn chế riêng. Do đó, việc tăng cường các phương pháp hiện tại và phát triển các chiến lược chỉnh sửa tri thức mới là đáng giá.

Trong tương lai, một số hướng hữu ích của chỉnh sửa tri thức có thể nằm ở: 1) Phạm vi rộng hơn của tri thức đích. Như được thể hiện trong Bảng 2, các nghiên cứu hiện tại chủ yếu tập trung vào chỉnh sửa tri thức thực tế, tương đối dễ hình thức hóa và đánh giá. Trong tương lai, các nhà nghiên cứu có thể khám phá các phương pháp chỉnh sửa hướng tới các loại tri thức khác, và phát triển các phương pháp phổ quát có thể chỉnh sửa tất cả các loại tri thức theo cùng một cách. 2) Đánh giá toàn diện. Hầu hết các nghiên cứu chỉnh sửa tri thức hiện tại được đánh giá bằng các số liệu như tỷ lệ thành công chỉnh sửa trên tri thức đích, tỷ lệ bất biến dự đoán trên tri thức không liên quan để đánh giá tính tổng quát, và độ chính xác trên diễn giải của tri thức đích để đánh giá tính nhất quán. Tuy nhiên, chúng tôi thấy rằng những số liệu này bị hạn chế để đánh giá toàn diện khả năng chỉnh sửa tri thức của các phương pháp khác nhau. Chẳng hạn, hầu hết các đánh giá chỉ lấy mẫu tri thức không liên quan từ cùng phân phối với tri thức đích. Tuy nhiên, ảnh hưởng của một chỉnh sửa tri thức có thể rộng hơn nhiều, ví dụ, ảnh hưởng đến hiệu suất trên các tác vụ downstream hoặc tri thức từ các phân phối và loại khác. Ngoài ra, như đã đề cập trong Mitchell et al. (2021), hầu hết các nghiên cứu đo lường tính nhất quán của các mẫu được tạo thông qua dịch ngược, bỏ qua tri thức bị ảnh hưởng bởi chỉnh sửa tri thức ngoại trừ các diễn giải, ví dụ, quốc gia có dân số lớn nhất sẽ bị ảnh hưởng bởi việc sửa đổi dân số của các quốc gia. Do đó, quan trọng là thiết kế benchmark toàn diện có thể đánh giá tốt hơn khả năng của các chiến lược chỉnh sửa. 3) Các phương pháp chỉnh sửa hiệu quả hơn. Lý tưởng, một phương pháp chỉnh sửa tri thức nên thỏa mãn các mong muốn về tính tổng quát, độ tin cậy và tính nhất quán, và có thể xử lý các tác vụ chỉnh sửa tri thức quy mô lớn và cá nhân với hiệu quả cao. Để đạt được điều này, chúng ta có thể vay mượn ý tưởng từ các lĩnh vực khác, như meta-learning, học liên tục và học suốt đời. Hơn nữa, hữu ích khi kết nối các nghiên cứu chỉnh sửa tri thức với các nghiên cứu biểu diễn tri thức (§ 4).

7 Ứng dụng Tri thức

Ứng dụng tri thức nghiên cứu cách chưng cất và tận dụng hiệu quả tri thức trong PLMs cho các ứng dụng khác. Cụ thể, chúng tôi chia ứng dụng tri thức thành hai loại: các mô hình ngôn ngữ như cơ sở tri thức và các mô hình ngôn ngữ cho các tác vụ downstream, và trong phần sau chúng tôi mô tả chúng chi tiết.

7.1 Các Mô hình Ngôn ngữ như Cơ sở Tri thức

Hiệu suất ấn tượng của các mô hình ngôn ngữ được tiền huấn luyện quy mô lớn, cũng như lượng tri thức được lưu trữ ngầm có thể khổng lồ, làm dấy lên sự chú ý rộng rãi về việc sử dụng các mô hình ngôn ngữ như một sự thay thế cho các cơ sở tri thức có cấu trúc thông thường (LMs-as-KBs) (Petroni et al., 2019; Heinzerling and Inui, 2021; Jiang et al., 2020b; Wang et al., 2020; Cao et al., 2021; Razniewski et al., 2021; AlKhamissi et al., 2022).

Tiếc là, cùng với những ưu điểm và tiềm năng hứa hẹn so với các cơ sở tri thức có cấu trúc, cũng tồn tại những khuyết điểm nội tại đối với các mô hình ngôn ngữ như cơ sở tri thức (Razniewski et al., 2021), được tóm tắt trong Bảng 3. Trong phần sau, chúng tôi mô tả chúng chi tiết.

Quy trình Xây dựng là một trong những ưu điểm lớn nhất của LMs-as-KBs so với KBs có cấu trúc. Việc xây dựng KBs có cấu trúc quy mô lớn như Freebase (Bollacker et al., 2008) và Wikidata (Vrandečić and Krötzsch, 2014) thường đòi hỏi các pipeline cực kỳ phức tạp (Petroni et al., 2019), ví dụ, xây dựng ontology, thu nhận tri thức, xác minh tri thức, hợp nhất tri thức, lưu trữ tri thức và điền tri thức. Pipeline phức tạp như vậy liên quan đến nhiều kỹ thuật NLP, bao gồm kỹ thuật ontology, liên kết thực thể, nhận dạng thực thể, trích xuất quan hệ, ghép thực thể, v.v. Và mỗi kỹ thuật đòi hỏi tri thức chuyên gia tương ứng, dữ liệu được giám sát và nỗ lực của con người. Hơn nữa, do bản chất pipeline, lan truyền lỗi luôn là một vấn đề quan trọng. Ngược lại, tri thức của các mô hình ngôn ngữ có thể dễ dàng được học từ văn bản thuần túy bằng học tự giám sát, mà không có bất kỳ tín hiệu giám sát rõ ràng nào (§3.1). Hơn nữa, quy trình xây dựng là đầu cuối đến đầu cuối, do đó không cần kỹ thuật ontology, tri thức chuyên gia, hoặc chú thích con người.

Phạm vi bao phủ là một ưu điểm lớn khác của LMs-as-KBs. KBs có cấu trúc truyền thống thường bị hạn chế bởi các lược đồ được định nghĩa trước, và khó khăn trong việc thu nhận tri thức làm hạn chế thêm phạm vi bao phủ của chúng. Ngược lại, bằng cách trực tiếp biểu diễn tri thức trong các tham số, không có hạn chế lược đồ đối với LMs-as-KBs. Và tất cả tri thức được học từ kho ngữ liệu văn bản không được chú thích, do đó phạm vi bao phủ tri thức chủ yếu chỉ được xác định bởi phạm vi bao phủ của kho ngữ liệu tiền huấn luyện.

Những ưu điểm trên khiến LMs-as-KBs trở thành một ý tưởng cực kỳ hấp dẫn và hứa hẹn. Tuy nhiên, cũng có một số khuyết điểm nội tại cản trở LMs thay thế hoàn toàn KBs có cấu trúc.

Tương tác với KB có cấu trúc và LMs-as-KBs khá khác nhau. KBs có cấu trúc thường sử dụng các phương pháp truy vấn có cấu trúc như SPARQL (Pérez et al., 2009), ví dụ, truy vấn nơi sinh của Michael Jordan bằng <Michael Jordan, Birthplace, ? >. Trong trường hợp các KB dựa trên mô hình ngôn ngữ, các truy vấn chủ yếu là các biểu thức ngôn ngữ tự nhiên như "Nơi sinh của Michael Jordan là [MASK]".

So với các truy vấn có cấu trúc, các truy vấn dựa trên ngôn ngữ tự nhiên tự nhiên và thân thiện hơn với người dùng. Tuy nhiên, KBs có cấu trúc có thể trả về câu trả lời xác định (ví dụ, Brooklyn), nhưng KBs dựa trên LM chỉ có thể tạo ra các ứng viên với xác suất khác nhau (ví dụ, <Brooklyn, 0.8>). Các dự đoán xác suất có thể không chính xác, không nhất quán và gây nhầm lẫn. Hơn nữa, KBs có cấu trúc có thể xác định các truy vấn mà chúng không thể trả lời, nhưng KBs dựa trên LM hiện tại khó có thể từ chối các truy vấn mà nó không thể trả lời, do đó dẫn đến vấn đề ảo giác tri thức. Cụ thể, nếu chúng ta truy vấn một số tri thức không được lưu trữ trong KB có cấu trúc, câu trả lời có thể trống khi không có bộ ba nào được khớp. Tuy nhiên, bất kể chúng ta hỏi gì, các mô hình ngôn ngữ sẽ luôn "đoán" câu trả lời, thậm chí tri thức như vậy không bao giờ được LMs học. Mặc dù có một số giải pháp ngây thơ cho vấn đề này như từ chối câu trả lời có xác suất thấp, đây vẫn là một vấn đề mở hiện tại.

Cuối cùng, khó chỉnh sửa tri thức trong KBs dựa trên LM, như đã thảo luận trong Phần 6. Ngược lại, dễ dàng thêm, sửa đổi và xóa tri thức trong KBs có cấu trúc.

Độ tin cậy là một mối quan tâm khác đối với LMs-as-KBs. Vấn đề đầu tiên là sự mơ hồ. Trong KBs có cấu trúc, tất cả các thực thể và sự kiện đều có ID riêng (ví dụ, Q89 cho Apple quả và Q312 cho Apple Inc. trong Wikidata), do đó không có vấn đề mơ hồ. Tuy nhiên, trong KBs dựa trên LM, tất cả các phần tri thức được biểu diễn như các biểu thức ngôn ngữ tự nhiên và do đó sẽ gặp vấn đề mơ hồ của ngôn ngữ tự nhiên. Ví dụ, "Hoa Kỳ" và "Mỹ" có biểu diễn cùng một thực thể trong mô hình ngôn ngữ không? Các nghiên cứu trước đây đã quan sát thấy rằng những yêu cầu diễn đạt như vậy sẽ dẫn đến thiên kiến ưa thích prompt và thiên kiến diễn đạt thể hiện trong LMs-as-KBs (Cao et al., 2022). Tính nhất quán của dự đoán là một nhược điểm khác của LMs-as-KBs, tức là, một KB dựa trên LM có thể trả về câu trả lời khác nhau cho các truy vấn tương đương về mặt ngữ nghĩa.

7.2 Các Mô hình Ngôn ngữ cho Các tác vụ Downstream

Ngoài việc sử dụng các mô hình ngôn ngữ như cơ sở tri thức, tri thức trong PLMs cũng có thể mang lại lợi ích cho nhiều tác vụ downstream theo những cách khác nhau. Hình 3 cho thấy ba mô hình chính và chúng tôi mô tả chúng chi tiết.

7.2.1 Điều chỉnh Tinh

Điều chỉnh tinh là một cách phổ biến để tận dụng tri thức trong các mô hình ngôn ngữ, học chưng cất và tận dụng tri thức bằng cách điều chỉnh thêm PLMs bằng các bộ dữ liệu cụ thể theo tác vụ. Thứ nhất, tri thức được học ngầm từ văn bản đã được công nhận là một trong những lý do chính cho hiệu suất đáng kể của PLMs và khả năng tổng quát hóa mạnh mẽ qua nhiều tác vụ NLP (Manning et al., 2020; Wei et al., 2021b; Yang et al., 2021; Yin et al., 2022). Thứ hai, nhiều nghiên cứu đã chỉ ra rằng việc tiêm tri thức vào các mô hình ngôn ngữ có thể dẫn đến hiệu suất tốt hơn trên các tác vụ downstream. Chẳng hạn, việc tích hợp tri thức thực thể vào PLMs có thể cải thiện hiệu suất của một loạt các tác vụ hiểu ngôn ngữ Sun et al. (2019); Shen et al. (2020), việc tiêm tri thức thực tế vào PLMs có thể mang lại lợi ích cho hiệu suất của chúng trên các tác vụ như trích xuất quan hệ, gán loại thực thể, v.v. (Zhang et al., 2019; Wang et al., 2021b,a; Liu et al., 2020), và việc kết hợp tri thức ngôn ngữ học với PLMs có thể tăng hiệu suất của chúng trên các benchmark như GLUE (Levine et al., 2020; Sachan et al., 2021; Bai et al., 2021).

7.2.2 Học Prompt

Học dựa trên prompt là một cách khác để tận dụng tri thức trong PLMs cho các tác vụ downstream. Ví dụ, để phân loại cực tính cảm xúc của câu "Bộ phim hay nhất từ trước đến nay.", chúng ta có thể thêm một prompt và chuyển đổi đầu vào thành "Bộ phim hay nhất từ trước đến nay. Nó là .". Và cực tính có thể được xác định bằng cách so sánh xác suất dự đoán của PLMs giữa các câu trả lời ứng viên "tốt" và "xấu". Bằng cách chọn prompt phù hợp, PLMs đã được chứng minh có hiệu suất zero-shot cạnh tranh trên một số tác vụ downstream mà không cần bất kỳ huấn luyện có giám sát nào (Radford et al., 2019a; Brown et al., 2020; Liu et al., 2021a).

Vì prompt thủ công thường gặp hiệu suất không ổn định qua các prompt khác nhau và không thể sử dụng thông tin từ dữ liệu được giám sát, nhiều phương pháp tối ưu hóa prompt đã được đề xuất để thu được prompt hoạt động tốt hơn (Liu et al., 2021a), như diễn giải (Jiang et al., 2020b; Haviv et al., 2021), tìm kiếm dựa trên gradient (Shin et al., 2020), tạo mô hình (Gao et al., 2021), tăng cường tri thức (Hu et al., 2022), v.v. Hơn nữa, điều chỉnh prompt, thêm một số vector có thể huấn luyện vào đầu vào như prompt liên tục, trong khi giữ các tham số của LMs đóng băng, đã đạt được hiệu suất cạnh tranh với điều chỉnh tinh (Li and Liang, 2021b; Liu et al., 2021b; Hambardzumyan et al., 2021; Lester et al., 2021). Ngoài việc tối ưu hóa prompt đơn lẻ, việc tập hợp (Jiang et al., 2020b; Qin and Eisner, 2021), tổng hợp (Han et al., 2021), hoặc tách rời (Ozturkler et al., 2022) nhiều prompt cũng có thể cải thiện hiệu suất mô hình. Hơn nữa, prompt cũng đã được áp dụng cho tăng cường dữ liệu (Schick and Schütze, 2021), thích ứng miền (Ben-David et al., 2021), khử thiên kiến (Schick et al., 2021), v.v.

Gần đây hơn, điều chỉnh hướng dẫn, tiền huấn luyện LMs trên một loạt rộng các bộ dữ liệu được cung cấp mô tả ngôn ngữ tự nhiên của các tác vụ như hướng dẫn, đã đạt được cải thiện hiệu suất và khả năng tổng quát hóa đáng kể của các mô hình ngôn ngữ (Wei et al., 2021a; Sanh et al., 2021; Ouyang et al., 2022; Chung et al., 2022).

7.2.3 Học Trong ngữ cảnh

Ứng dụng Hiện tại các tham số của PLMs đã được mở rộng lên 175B (ví dụ, GPT-3 (Brown et al., 2020), OPT (Zhang et al., 2022b), BLOOM3) hoặc thậm chí lớn hơn (ví dụ, PaLM (Chowdhery et al., 2022)), khiến chi phí tính toán của điều chỉnh tinh và điều chỉnh prompt không khả thi đối với hầu hết các nhà nghiên cứu. Do đó, học trong ngữ cảnh không cần điều chỉnh đã trở thành một trong những phương pháp phổ biến nhất để áp dụng tri thức trong PLMs quy mô lớn trong các tác vụ downstream (Dong et al., 2023). Chẳng hạn, đối với tác vụ phân loại cảm xúc, học trong ngữ cảnh sẽ đầu tiên lấy mẫu một số minh họa, như (bữa ăn kinh khủng, tiêu cực), và kết hợp chúng với truy vấn gốc. Bằng cách này, đầu vào trở thành "Bữa ăn kinh khủng. Nó xấu. [SEP] Bộ phim hay nhất từ trước đến nay. Nó .". Các minh họa được cung cấp cung cấp thông tin bổ sung về tác vụ và cho phép PLMs sử dụng khả năng tương tự để dự đoán câu trả lời chính xác. Học trong ngữ cảnh đã đạt được hiệu suất tốt trên nhiều tác vụ downstream như hiểu ngôn ngữ (Brown et al., 2020; Zhao et al., 2021; Lee et al., 2022; Eisenstein et al., 2022; Zhang et al., 2022a), tạo dữ liệu (Li et al., 2022b; Dai et al., 2022b; Yu et al., 2022), hoặc lý luận (Wei et al., 2022; Lampinen et al., 2022; Zhou et al., 2022).

Vấn đề Thiên kiến Một nhược điểm của học trong ngữ cảnh là vấn đề thiên kiến, tức là, hiệu suất nhạy cảm với lựa chọn minh họa, thứ tự minh họa, phân phối nhãn của minh họa và lựa chọn prompt, v.v. (Zhao et al., 2021; Lu et al., 2022; Liu et al., 2022). Do đó, để đạt được hiệu suất tốt hơn của học trong ngữ cảnh, Zhao et al. (2021) đầu tiên đề xuất ước tính thiên kiến bằng cách đưa mô hình với một đầu vào không thông tin (ví dụ, [MASK] hoặc N/A), và sau đó hiệu chỉnh xác suất dự đoán được phân bố đều để loại bỏ thiên kiến của mô hình đối với câu trả lời cụ thể. Đối với lựa chọn minh họa, Gao et al. (2021); Liu et al. (2022) đề xuất chọn minh họa gần về mặt ngữ nghĩa với truy vấn đầu vào. Rubin et al. (2022) huấn luyện một bộ truy xuất dày đặc trên các bộ dữ liệu được ghi điểm LM để chọn minh họa. Su et al. (2022) giới thiệu một phương pháp lựa chọn dựa trên đồ thị để đảm bảo tính đa dạng và tính đại diện của minh họa. Đối với sắp xếp minh họa, Lu et al. (2022) đầu tiên xây dựng một bộ dữ liệu phát triển bằng cách lấy mẫu từ các mô hình ngôn ngữ, và sau đó sử dụng các số liệu dựa trên entropy để xác định hoán vị minh họa tối ưu. Đối với lựa chọn prompt, Gao et al. (2021) sử dụng một mô hình ngôn ngữ để tạo ra các prompt ứng viên và chọn những cái có hiệu suất tốt hơn trên tập phát triển.

Cơ chế Mặc dù học trong ngữ cảnh đã được áp dụng rộng rãi trên các tác vụ downstream khác nhau, cơ chế cơ bản của nó vẫn chưa rõ ràng. Reynolds and McDonell (2021) thấy rằng prompt zero-shot đôi khi có thể vượt trội đáng kể so với học trong ngữ cảnh, và lập luận rằng các minh họa bổ sung không giúp PLMs học một tác vụ mới, mà thay vào đó định vị tác vụ mà chúng đã học. Cao et al. (2021) nghiên cứu học trong ngữ cảnh để thăm dò tri thức, và thấy rằng các minh họa chỉ có thể cung cấp hướng dẫn cấp loại nhưng thông tin thực tế. Min et al. (2022) thấy rằng việc thay thế ngẫu nhiên nhãn của minh họa hầu như không ảnh hưởng đến hiệu suất, và cho thấy rằng hiệu quả của học trong ngữ cảnh dựa nhiều hơn vào không gian nhãn và hạn chế phân phối đầu vào được cung cấp bởi minh họa thay vì ánh xạ đầu vào-nhãn chính xác. Chan et al. (2022) thấy rằng chỉ khi dữ liệu bao gồm cả tính bùng nổ và quy mô lớn của các lớp hiếm khi xuất hiện, khả năng học trong ngữ cảnh mới có thể nổi lên trong mô hình transformer. von Oswald et al. (2022) nghiên cứu các kết nối giữa học trong ngữ cảnh và gradient descent, và chứng minh sự tương tự giữa học trong ngữ cảnh và học few-shot dựa trên gradient.

7.3 Thảo luận và Nghiên cứu Tương lai

Việc tận dụng tri thức trong PLMs vừa hứa hẹn vừa thách thức. Một mặt, rõ ràng là lượng lớn tri thức ngầm được lưu trữ trong PLMs sẽ mang lại lợi ích cho các tác vụ downstream khác nhau. Mặt khác, tất cả các mô hình ứng dụng hiện tại đều có hạn chế riêng. Chẳng hạn, tính nhất quán và độ tin cậy của LMs-as-KBs cản trở PLMs thay thế KBs có cấu trúc, Hơn nữa, các phương pháp điều chỉnh tinh, học prompt và học trong ngữ cảnh thường gặp phải quên thảm khốc, chi phí tính toán, dự đoán không nhất quán và không ổn định, thiên kiến xã hội, v.v.

Để giải quyết những thách thức này, một số hướng chính của ứng dụng tri thức có thể nằm ở những điều sau: 1) Đối với LMs-as-KBs, chúng ta cần đề xuất các phương pháp tiền huấn luyện cụ thể để giải quyết các thiếu sót hiện tại về tính nhất quán và độ tin cậy. 2) Đối với LMs cho các tác vụ downstream, chúng tôi đề xuất khám phá thêm các chiến lược ứng dụng, như các phương pháp mới không cần điều chỉnh để giải quyết vấn đề chi phí tính toán và các phương pháp điều chỉnh hộp đen (Sun et al., 2022) để điều chỉnh các mô hình ngôn ngữ được tiền huấn luyện mà không cần truy cập vào các tham số của chúng.

8 Kết luận

Trong khảo sát này, chúng tôi tiến hành một đánh giá toàn diện về chu kỳ sống của tri thức trong các mô hình ngôn ngữ được tiền huấn luyện, bao gồm thu nhận tri thức, biểu diễn tri thức, thăm dò tri thức, chỉnh sửa tri thức và ứng dụng tri thức. Chúng tôi một cách có hệ thống xem xét các nghiên cứu liên quan cho mỗi giai đoạn, thảo luận về ưu điểm và hạn chế của các phương pháp khác nhau, tóm tắt thách thức chính, và trình bày một số hướng tương lai. Chúng tôi tin rằng khảo sát này sẽ mang lại lợi ích cho các nhà nghiên cứu trong nhiều lĩnh vực như mô hình ngôn ngữ, đồ thị tri thức, cơ sở tri thức, v.v.

Lời cảm ơn
Chúng tôi chân thành cảm ơn tất cả các người đánh giá ẩn danh vì những nhận xét sâu sắc và đề xuất có giá trị của họ. Công việc nghiên cứu này được hỗ trợ bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc dưới Grantno. 62122077 và Dự án CAS cho Các nhà khoa học trẻ trong Nghiên cứu cơ bản dưới Grant No.YSBR-040.

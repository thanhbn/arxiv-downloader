# 2011.12216.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/continual-learning/2011.12216.pdf
# Kích thước tệp: 2661558 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022
CÁC MÔ HÌNH DỰA TRÊN NĂNG LƯỢNG CHO HỌC LIÊN TỤC
Shuang Li
MIT CSAIL
lishuang@mit.eduYilun Du
MIT CSAIL
yilundu@mit.eduGido M. van de Ven
Baylor College of Medicine
ven@bcm.edu
Igor Mordatch
Google Brain
igor.mordatch@gmail.com
TÓM TẮT
Chúng tôi thúc đẩy các Mô hình Dựa trên Năng lượng (EBM) như một lớp mô hình đầy hứa hẹn cho các vấn đề học liên tục. Thay vì giải quyết học liên tục thông qua việc sử dụng bộ nhớ ngoài, các mô hình mở rộng hoặc chính quy hóa, EBM thay đổi mục tiêu huấn luyện cơ bản để gây ít can thiệp hơn với thông tin đã học trước đó. Phiên bản EBM được đề xuất của chúng tôi cho học liên tục là đơn giản, hiệu quả và vượt trội hơn các phương pháp cơ sở một cách đáng kể trên nhiều bộ dữ liệu chuẩn. Hơn nữa, mục tiêu huấn luyện dựa trên phân kỳ tương phản được đề xuất của chúng tôi có thể được kết hợp với các phương pháp học liên tục khác, dẫn đến sự cải thiện đáng kể trong hiệu suất của chúng. Chúng tôi tiếp tục chỉ ra rằng EBM có thể thích ứng với một cài đặt học liên tục tổng quát hơn nơi phân phối dữ liệu thay đổi mà không có khái niệm về các nhiệm vụ được phân định rõ ràng. Những quan sát này chỉ ra EBM như một khối xây dựng hữu ích cho các phương pháp học liên tục trong tương lai. Trang dự án: https://energy-based-model.github.io/Energy-Based-Models-for-Continual-Learning/ .

1 GIỚI THIỆU
Con người có khả năng học nhanh chóng những kỹ năng mới và liên tục tích hợp chúng với kiến thức trước đó. Lĩnh vực Học liên tục (CL) tìm cách xây dựng các tác nhân nhân tạo với những khả năng tương tự (Parisi et al., 2019; Hadsell et al., 2020; De Lange et al., 2021). Trong những năm gần đây, học liên tục đã nhận được sự chú ý ngày càng tăng, đặc biệt trong bối cảnh các vấn đề phân loại. Học liên tục yêu cầu các mô hình nhớ những kỹ năng trước đó cũng như học gia tăng những kỹ năng mới, mà không nhất thiết phải có khái niệm về danh tính nhiệm vụ rõ ràng. Các mạng nơ-ron tiêu chuẩn (He et al., 2016; Simonyan & Zisserman, 2014; Szegedy et al., 2015) gặp phải việc quên thảm khốc và hoạt động kém trong cài đặt này. Các phương pháp khác nhau đã được đề xuất để giảm thiểu việc quên thảm khốc, nhưng nhiều phương pháp dựa vào việc sử dụng bộ nhớ ngoài (Lopez-Paz & Ranzato, 2017; Li & Hoiem, 2017; Hayes et al., 2020; Buzzega et al., 2020), các mô hình bổ sung (Shin et al., 2017; von Oswald et al., 2019; Liu et al., 2020), hoặc các mục tiêu phụ trợ và chính quy hóa (Kirkpatrick et al., 2017; Schwarz et al., 2018; Maltoni & Lomonaco, 2019; Zenke et al., 2017), điều này có thể hạn chế khả năng ứng dụng rộng rãi của các phương pháp này.

Trong công trình này, chúng tôi đề xuất một cách tiếp cận mới hướng tới học liên tục trên các nhiệm vụ phân loại. Hầu hết các phương pháp CL hiện có giải quyết những nhiệm vụ này bằng cách sử dụng phân phối xác suất được chuẩn hóa (tức là, lớp đầu ra softmax) và được huấn luyện với mục tiêu cross-entropy. Trong bài báo này, chúng tôi lập luận rằng bằng cách xem xét phân loại từ góc độ huấn luyện một phân phối xác suất không được chuẩn hóa, chúng ta có thể cải thiện đáng kể hiệu suất học liên tục trong các vấn đề phân loại. Đặc biệt, chúng tôi diễn giải phân loại như việc học một Mô hình Dựa trên Năng lượng (EBM) trên các lớp. Huấn luyện trở thành một quá trình thức-ngủ, nơi năng lượng của một dữ liệu đầu vào tại nhãn sự thật cơ bản của nó được giảm trong khi năng lượng của đầu vào tại (các) lớp khác được chọn được tăng lên. Một lợi thế quan trọng là khung này cung cấp tự do để chọn những lớp nào cần cập nhật trong quá trình học liên tục. Ngược lại, mục tiêu cross entropy giảm khả năng của tất cả các lớp âm khi được cho một đầu vào mới, tạo ra các cập nhật dẫn đến việc quên thảm khốc.

Hàm năng lượng, ánh xạ một cặp đầu vào-nhãn thành một năng lượng vô hướng, cũng cung cấp một cách cho mô hình chọn lọc và lọc các phần của đầu vào có liên quan đến việc phân loại hiện tại. Điều này cho phép các cập nhật huấn luyện EBM cho dữ liệu mới can thiệp ít hơn với dữ liệu trước đó. Đặc biệt, công thức hàm năng lượng của chúng tôi cho phép chúng tôi tính toán năng lượng của một đầu vào bằng cách học một độ lợi có điều kiện dựa trên nhãn lớp, điều này đóng vai trò như một bộ lọc chú ý để chọn thông tin liên quan nhất. Trong trường hợp có một lớp mới, một độ lợi có điều kiện mới có thể được học.

Tác giả liên hệ: Shuang Li <lishuang@mit.edu >
1arXiv:2011.12216v3  [cs.LG]  18 Dec 2022

--- TRANG 2 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022
Những đặc tính độc đáo này có lợi cho EBM trong việc giải quyết hai thách thức mở quan trọng trong học liên tục. 1) Đầu tiên, chúng tôi chỉ ra rằng EBM có triển vọng cho học gia tăng lớp, đây là một trong những cài đặt thách thức nhất cho học liên tục (van de Ven & Tolias, 2019; Hayes & Kanan, 2020; Masana et al., 2020; Prabhu et al., 2020). Nói chung, các phương pháp hiện có thành công cho học gia tăng lớp lưu trữ dữ liệu, sử dụng phát lại sinh tạo, hoặc tiền huấn luyện mô hình của chúng trên tập dữ liệu khác, điều này có nhược điểm về hiệu quả bộ nhớ và/hoặc tính toán. Chúng tôi chỉ ra rằng EBM hoạt động tốt trong học gia tăng lớp mà không sử dụng phát lại và không dựa vào dữ liệu được lưu trữ. 2) Thách thức mở thứ hai mà EBM có thể giải quyết là học liên tục không có ranh giới nhiệm vụ (Aljundi et al., 2019a; Lee et al., 2020; Jin et al., 2020). Thông thường, một vấn đề học liên tục được thiết lập như một chuỗi các nhiệm vụ riêng biệt với các ranh giới rõ ràng được biết đến bởi mô hình (cài đặt nhận biết ranh giới). Hầu hết các phương pháp học liên tục hiện có dựa vào những ranh giới đã biết này để thực hiện các bước hợp nhất nhất định (ví dụ, tính toán tầm quan trọng của tham số, cập nhật một bản sao được lưu trữ của mô hình). Tuy nhiên, việc giả định những ranh giới rõ ràng như vậy không phải lúc nào cũng thực tế, và thường một kịch bản tự nhiên hơn là cài đặt không có ranh giới (Zeno et al., 2018; Rajasegaran et al., 2020), trong đó phân phối dữ liệu dần dần thay đổi mà không có khái niệm rõ ràng về ranh giới nhiệm vụ. Trong khi nhiều phương pháp CL phổ biến không thể được sử dụng mà không có ranh giới nhiệm vụ rõ ràng, chúng tôi chỉ ra rằng EBM có thể được áp dụng tự nhiên cho cài đặt thách thức hơn này.

Có ba đóng góp chính của công trình chúng tôi. Đầu tiên, chúng tôi giới thiệu các mô hình dựa trên năng lượng cho các vấn đề học liên tục phân loại. Chúng tôi chỉ ra rằng EBM có thể tự nhiên xử lý các vấn đề thách thức trong CL, bao gồm cài đặt không có ranh giới và học gia tăng lớp mà không sử dụng phát lại. Thứ hai, chúng tôi đề xuất một mục tiêu huấn luyện dựa trên năng lượng đơn giản và có thể áp dụng rộng rãi cho các loại mô hình khác nhau, với những cải thiện đáng kể về hiệu suất của chúng. Mục tiêu huấn luyện dựa trên phân kỳ tương phản này có thể tự nhiên xử lý số lượng lớp tăng động và giảm đáng kể việc quên thảm khốc. Cuối cùng, chúng tôi chỉ ra rằng các EBM được đề xuất hoạt động mạnh mẽ trên bốn bộ dữ liệu chuẩn CL: split MNIST, permuted MNIST, CIFAR-10 và CIFAR-100 mà không sử dụng mô hình sinh tạo bổ sung hoặc lưu trữ dữ liệu. Những quan sát này chỉ ra EBM như một lớp mô hình tự nhiên nghiêng về chế độ CL và như một đường cơ sở quan trọng mới để xây dựng các phát triển tiếp theo.

2 CÔNG TRÌNH LIÊN QUAN

2.1 CÁC CÀI ĐẶT HỌC LIÊN TỤC

Nhận biết ranh giới so với không có ranh giới trong quá trình huấn luyện. Trong hầu hết các nghiên cứu CL hiện có, các mô hình được huấn luyện trong cài đặt nhận biết ranh giới, trong đó một chuỗi các nhiệm vụ riêng biệt với ranh giới nhiệm vụ rõ ràng được đưa ra (ví dụ, (Kirkpatrick et al., 2017; Zenke et al., 2017; Shin et al., 2017)). Không có sự chồng chéo giữa bất kỳ hai nhiệm vụ nào. Các mô hình được huấn luyện đầu tiên trên nhiệm vụ đầu tiên và sau đó chuyển sang nhiệm vụ thứ hai. Hơn nữa, các mô hình thường được thông báo khi có sự chuyển đổi từ nhiệm vụ này sang nhiệm vụ tiếp theo. Tuy nhiên, có thể lập luận rằng việc các nhiệm vụ thay đổi dần dần và các mô hình không được thông báo rõ ràng về ranh giới nhiệm vụ là thực tế hơn. Một cài đặt không có ranh giới như vậy đã được khám phá trong (Zeno et al., 2018; Rajasegaran et al., 2020; Aljundi et al., 2019b; Madireddy et al., 2020). Trong cài đặt này, các mô hình học theo cách luồng và phân phối dữ liệu dần dần thay đổi theo thời gian. Quan trọng, hầu hết các phương pháp CL hiện có không áp dụng được cho cài đặt này vì chúng yêu cầu ranh giới nhiệm vụ để quyết định khi nào thực hiện các bước hợp nhất nhất định. Trong bài báo này, chúng tôi chỉ ra rằng phương pháp của chúng tôi có thể tự nhiên xử lý cả cài đặt nhận biết ranh giới và không có ranh giới.

Học gia tăng nhiệm vụ so với học gia tăng lớp. Một sự phân biệt quan trọng khác trong CL là giữa học gia tăng nhiệm vụ (Task-IL) và học gia tăng lớp (Class-IL) (van de Ven & Tolias, 2019; Prabhu et al., 2020; Belouadah et al., 2020; Maltoni & Lomonaco, 2019; Hayes & Kanan, 2020). Trong Task-IL, còn được gọi là cài đặt đa đầu (Farquhar & Gal, 2018), các mô hình dự đoán nhãn của một dữ liệu đầu vào bằng cách chỉ chọn từ các nhãn trong nhiệm vụ mà dữ liệu đến từ đó. Trong Class-IL, còn được gọi là cài đặt đơn đầu, các mô hình chọn giữa các lớp từ tất cả các nhiệm vụ cho đến nay khi được yêu cầu dự đoán nhãn của một dữ liệu đầu vào. Class-IL thách thức hơn Task-IL vì nó yêu cầu các mô hình chọn các nhãn chính xác từ hỗn hợp các lớp mới và cũ.

Trong một số công trình trước đây, học gia tăng lớp chỉ đề cập đến cài đặt nhận biết ranh giới nơi các nhiệm vụ có ranh giới rõ ràng. Trong bài báo của chúng tôi, chúng tôi sử dụng học gia tăng lớp theo cách tổng quát hơn, cho phép nó chứa cả cài đặt nhận biết ranh giới và không có ranh giới, nơi các nhiệm vụ không nhất thiết có ranh giới rõ ràng.

2.2 CÁC PHƯƠNG PHÁP HỌC LIÊN TỤC

Các phương pháp cụ thể theo nhiệm vụ. Một cách để giảm can thiệp giữa các nhiệm vụ là bằng cách sử dụng các phần khác nhau của một mạng nơ-ron cho các nhiệm vụ khác nhau (Fernando et al., 2017; Serra et al., 2018; Masse et al., 2018; Zeng et al., 2019; Hu et al., 2019; Wortsman et al., 2020). Các phương pháp khác để các mô hình phát triển hoặc tuyển dụng tài nguyên mới khi học các nhiệm vụ mới (Rusu et al., 2016; Yoon et al., 2017; Vogelstein et al., 2020). Mặc dù các phương pháp này nói chung thành công trong việc giảm việc quên thảm khốc, một nhược điểm chính là chúng yêu cầu kiến thức về danh tính nhiệm vụ trong quá trình huấn luyện và kiểm tra. Trừ khi chúng được kết hợp với một cơ chế suy luận nhiệm vụ, chúng không phù hợp cho Class-IL.

2

--- TRANG 3 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

Các phương pháp dựa trên chính quy hóa. Chính quy hóa được sử dụng trong CL để khuyến khích tính ổn định của những khía cạnh của mạng quan trọng đối với các nhiệm vụ trước đó (Li & Hoiem, 2017; Zenke et al., 2017; Nguyen et al., 2017; Titsias et al., 2020; Kolouri et al., 2020; Kao et al., 2021). Một chiến lược phổ biến là thêm một mất mát chính quy hóa để phạt các thay đổi của các tham số quan trọng. Ví dụ, EWC (Kirkpatrick et al., 2017) và online EWC (Schwarz et al., 2018) đánh giá tầm quan trọng của các tham số dựa trên ma trận thông tin fisher. Một nhược điểm của các phương pháp dựa trên chính quy hóa là thường chúng dần dần giảm khả năng của mô hình để học các nhiệm vụ mới. Hơn nữa, trong khi về mặt lý thuyết các phương pháp này có thể được sử dụng cho Class-IL, trong thực tế chúng đã được chỉ ra là thất bại trên những vấn đề như vậy (Farquhar & Gal, 2018; van de Ven & Tolias, 2019).

Các phương pháp phát lại. Để bảo tồn kiến thức, các phương pháp phát lại định kỳ ôn tập thông tin trước đó trong quá trình huấn luyện (Robins, 1995; Rebuffi et al., 2017; Aljundi et al., 2019a; Chaudhry et al., 2019b). Các phương pháp phát lại trải nghiệm chính xác hoặc dựa trên trải nghiệm lưu trữ dữ liệu từ các nhiệm vụ trước đó và xem lại chúng khi huấn luyện trên các nhiệm vụ mới. Mặc dù đơn giản, các phương pháp như vậy đối mặt với những câu hỏi quan trọng không tầm thường, chẳng hạn như cách chọn dữ liệu để lưu trữ và cách sử dụng chúng (Lopez-Paz & Ranzato, 2017; Hou et al., 2019; Wu et al., 2019; Chaudhry et al., 2019a; Mundt et al., 2020; Pan et al., 2020). Một lựa chọn thay thế là tạo ra dữ liệu được phát lại (Shin et al., 2017). Trong khi cả hai loại phát lại đều có thể giảm thiểu việc quên, một nhược điểm quan trọng là chúng tương đối tốn kém về mặt tính toán. Ngoài ra, việc lưu trữ dữ liệu có thể không phải lúc nào cũng khả thi trong khi việc huấn luyện gia tăng một mô hình sinh tạo là một vấn đề thách thức tự nó (Lesort et al., 2019; van de Ven et al., 2020).

Ngược lại, chúng tôi đề xuất EBM cho CL giảm việc quên thảm khốc mà không yêu cầu kiến thức về danh tính nhiệm vụ, không hạn chế khả năng học của mô hình, và không sử dụng dữ liệu được lưu trữ.

3 SỬY NGHĨ LẠI HỌC LIÊN TỤC HIỆN TẠI

Cách phổ biến nhất để thực hiện phân loại với các mạng nơ-ron sâu là sử dụng một lớp đầu ra softmax kết hợp với mất mát cross-entropy. Trong học liên tục, hầu hết các phương pháp hiện có cho phân loại dựa trên bộ phân loại dựa trên softmax (SBC).

3.1 PHÂN LOẠI DỰA TRÊN SOFTMAX

Cho một đầu vào x∈RD và một tập rời rạc Y={1;...;N} gồm N nhãn lớp có thể, một bộ phân loại dựa trên softmax truyền thống định nghĩa các xác suất có điều kiện của những nhãn đó như:

p(y|x) = exp([f(x)]y) / Σ(i∈Y) exp([f(x)]i), for all y∈Y; (1)

trong đó f(x) : RD→RN là một mạng nơ-ron feed-forward, được tham số hóa bởi θ, ánh xạ một đầu vào x thành một vector N chiều của logits. []i chỉ ra phần tử thứ i của một vector.

Huấn luyện. Một bộ phân loại dựa trên softmax thường được huấn luyện bằng cách tối ưu hóa hàm mất mát cross-entropy. Đối với một đầu vào x và nhãn sự thật cơ bản tương ứng y+, mất mát cross-entropy là LCE(θ;x;y+) = -log(p(y+|x)). Một sơ đồ của SBC được hiển thị ở phần bên trái của Hình 1.

Suy luận. Cho một đầu vào x, nhãn lớp được dự đoán bởi bộ phân loại dựa trên softmax là lớp có xác suất có điều kiện lớn nhất ŷ = arg max(y∈Y) p(y|x).

3.2 TẠI SAO CÁC BỘ PHÂN LOẠI DỰA TRÊN SOFTMAX KHÔNG PHẢI LÀ CÁCH TỐT NHẤT ĐỂ THỰC HIỆN HỌC LIÊN TỤC?

Khi được sử dụng cho học liên tục, và đặc biệt khi được sử dụng cho học gia tăng lớp, các bộ phân loại dựa trên softmax đối mặt với nhiều thách thức. Trong khi mất mát cross-entropy được thiết kế cho các điểm dữ liệu và nhãn i.i.d., dữ liệu được tìm thấy trong học liên tục không tuân theo phân phối như vậy. Kết quả là, khi huấn luyện trên một nhiệm vụ mới, khả năng của các lớp được quan sát hiện tại được tăng lên, nhưng khả năng của các lớp cũ bị ức chế quá mạnh vì chúng không gặp phải trong nhiệm vụ mới. Chính thao tác softmax giới thiệu động lực cạnh tranh, người thắng cuộc nhận tất cả khiến bộ phân loại quên thảm khốc các nhiệm vụ trong quá khứ. Chúng tôi chỉ ra hiện tượng như vậy của SBC trong Phần 5.1.4.

4 HỌC LIÊN TỤC VỚI CÁC MÔ HÌNH DỰA TRÊN NĂNG LƯỢNG

Trong phần này, chúng tôi đề xuất một mục tiêu huấn luyện dựa trên năng lượng đơn giản nhưng hiệu quả có thể thành công giảm thiểu việc quên thảm khốc trong CL. Chúng tôi đầu tiên giới thiệu EBM trong phần 4.1 và sau đó chỉ ra cách EBM được sử dụng cho phân loại trong phần 4.2 và học liên tục trong phần 4.3.

3

--- TRANG 4 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

4.1 CÁC MÔ HÌNH DỰA TRÊN NĂNG LƯỢNG

EBM (LeCun et al., 2006) là một lớp các mô hình khả năng tối đa định nghĩa khả năng của một điểm dữ liệu x∈X⊆RD sử dụng phân phối Boltzmann với hàm phân hoạch Z(θ):

p(x) = exp(-E(x)) / Z(θ), Z(θ) = ∫(x∈X) exp(-E(x)) (2)

trong đó E(x) : RD→R, được biết đến như hàm năng lượng, ánh xạ mỗi điểm dữ liệu x thành một giá trị năng lượng vô hướng. Trong các ứng dụng học sâu, hàm năng lượng E là một mạng nơ-ron được tham số hóa bởi θ.

EBM là những mô hình mạnh mẽ đã được áp dụng cho các lĩnh vực khác nhau, chẳng hạn như dự đoán có cấu trúc (Belanger & McCallum, 2016; Rooshenas et al., 2019; Tu & Gimpel, 2019), tạo văn bản (Deng et al., 2020), RL (Haarnoja et al., 2017), tạo hình ảnh (Salakhutdinov & Hinton, 2009; Du & Mordatch, 2019; Du et al., 2020; Nijkamp et al., 2019), và phân loại (Grathwohl et al., 2019). Một sự khác biệt quan trọng so với các phương pháp EBM trước đây cho phân loại hình ảnh (Grathwohl et al., 2019) là chúng tôi không sử dụng các mẫu âm từ MCMC trong mục tiêu huấn luyện. Việc sử dụng MCMC để lấy mẫu hình ảnh âm khiến EBM khó mở rộng đến các tập dữ liệu phức tạp và làm cho huấn luyện chậm hơn nhiều. Phương pháp của chúng tôi sử dụng các nhãn âm trong mục tiêu huấn luyện nhanh hơn và có thể mở rộng hơn. Trong bài báo này, chúng tôi nghiên cứu học liên tục trên các nhiệm vụ phân loại. Theo như chúng tôi biết, EBM cho học liên tục cho đến nay vẫn chưa được khám phá.

4.2 CÁC MÔ HÌNH DỰA TRÊN NĂNG LƯỢNG CHO PHÂN LOẠI

Hình 1: Sơ đồ của kiến trúc mô hình của bộ phân loại dựa trên softmax (SBC) và mô hình dựa trên năng lượng (EBM). SBC nhận một hình ảnh x làm đầu vào và xuất ra một vector N chiều cố định được định nghĩa trước. EBM nhận một dữ liệu x và một lớp y làm đầu vào và xuất ra giá trị năng lượng của chúng. Các đường nét đứt là các kết nối bỏ qua tùy chọn.

Để giải quyết các nhiệm vụ phân loại, chúng tôi điều chỉnh công thức tổng quát của EBM ở trên như sau. Cho các đầu vào x∈RD và một tập rời rạc Y của các nhãn lớp có thể, chúng tôi đề xuất sử dụng phân phối Boltzmann để định nghĩa khả năng có điều kiện của nhãn y cho x:

p(y|x) = exp(-E(x,y)) / Z(θ,x), Z(θ,x) = Σ(y'∈Y) exp(-E(x,y')) (3)

trong đó E(x,y) : (RD,N)→R là hàm năng lượng ánh xạ một cặp đầu vào-nhãn (x,y) thành một giá trị năng lượng vô hướng, và Z(θ,x) là hàm phân hoạch để chuẩn hóa.

Huấn luyện. Chúng ta muốn phân phối được định nghĩa bởi E mô hình hóa phân phối dữ liệu pD, điều mà chúng ta thực hiện bằng cách tối thiểu hóa khả năng log âm của dữ liệu LML(θ) = E(x,y)~pD[-log p(y|x)] với dạng mở rộng:

LML(θ) = E(x,y)~pD[E(x,y) + log(Σ(y'∈Y) e^(-E(x,y')))] (4)

Phương trình (4) tối thiểu hóa năng lượng của x tại nhãn sự thật cơ bản y và tối thiểu hóa hàm phân hoạch tổng thể bằng cách tăng năng lượng của x tại các nhãn khác y'.

Suy luận. Cho một đầu vào x, nhãn lớp được dự đoán bởi EBM của chúng tôi là lớp có năng lượng nhỏ nhất tại x, có thể được viết là ŷ = arg min(y'∈Y) E(x,y').

4.3 MÔ HÌNH DỰA TRÊN NĂNG LƯỢNG NHƯ MỘT KHỐI XÂY DỰNG CHO HỌC LIÊN TỤC

Mục tiêu huấn luyện EBM. Trong Phương trình (4), năng lượng trên tất cả các nhãn lớp y' cho dữ liệu x được tối đa hóa. Việc trực tiếp tối đa hóa năng lượng trên tất cả các nhãn làm nảy sinh cùng vấn đề như các mô hình bộ phân loại dựa trên softmax rằng các lớp cũ bị ức chế khi huấn luyện một mô hình trên các lớp mới và do đó gây ra việc quên thảm khốc. Lấy cảm hứng từ (Hinton, 2002), chúng tôi thấy rằng xấp xỉ phân kỳ tương phản của Phương trình (4) có thể giảm thiểu vấn đề này và dẫn đến một phương trình đơn giản hơn. Để làm như vậy, chúng tôi định nghĩa mất mát phân kỳ tương phản sau:

LCD(θ;x,y) = E(x,y)~pD[E(x,y) - E(x,y^-)] (5)

trong đó y là nhãn sự thật cơ bản của dữ liệu x và y^- là một nhãn lớp âm được lấy mẫu ngẫu nhiên từ tập các nhãn lớp trong batch huấn luyện hiện tại YB sao cho y^- ≠ y.

4

--- TRANG 5 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

Khác với bộ phân loại dựa trên softmax, EBM tối đa hóa khả năng không phải bằng cách chuẩn hóa trên tất cả các lớp mà thay vào đó bằng cách tương phản tăng sự khác biệt năng lượng giữa nhãn sự thật cơ bản và một nhãn âm khác cho một điểm dữ liệu nhất định. Thao tác này gây ít can thiệp hơn với các lớp trước đó và cho phép EBM ít chịu thiệt hại hơn từ việc quên thảm khốc.

Quan trọng, chiến lược lấy mẫu như vậy cũng cho phép EBM được áp dụng tự nhiên, mà không cần bất kỳ sửa đổi nào, cho các cài đặt CL khác nhau (Phần 2.1). Vì chúng tôi chọn (các) mẫu âm từ batch hiện tại, EBM của chúng tôi không yêu cầu kiến thức về nhiệm vụ hiện tại. Điều này cho phép áp dụng EBM trong cài đặt không có ranh giới, trong đó các nhiệm vụ cơ bản hoặc ranh giới nhiệm vụ không được đưa ra. Xem Phụ lục A.2 để biết thêm chi tiết về cài đặt không có ranh giới.

Chúng tôi thấy rằng mục tiêu huấn luyện EBM được đề xuất đủ hiệu quả để đạt được hiệu suất tốt trên các tập dữ liệu CL khác nhau (Bảng 1 và Bảng 5). Tuy nhiên, chúng tôi lưu ý rằng có thể sử dụng các chiến lược khác để chọn các lớp âm trong hàm phân hoạch trong Phương trình (4). Trong Bảng 3, chúng tôi khám phá các chiến lược thay thế: 1) sử dụng tất cả các lớp trong batch huấn luyện hiện tại YB như các lớp âm, và 2) sử dụng tất cả các lớp đã thấy cho đến nay như các lớp âm. Việc sử dụng các mẫu âm trong mục tiêu huấn luyện EBM cung cấp tự do cho các mô hình để chọn lớp nào để huấn luyện, điều này quan trọng để ngăn chặn việc quên thảm khốc trong CL.

Mạng năng lượng. Một sự khác biệt quan trọng khác so với các bộ phân loại dựa trên softmax là việc lựa chọn kiến trúc mô hình trở nên linh hoạt hơn trong EBM. Các mô hình phân loại truyền thống chỉ đưa x vào làm đầu vào. Ngược lại, EBM có nhiều cách khác nhau để kết hợp x và y trong hàm năng lượng với yêu cầu duy nhất là E(x,y) : (RD,N)→R. Trong EBM, chúng ta có thể coi y như một bộ lọc chú ý hoặc cổng để chọn thông tin liên quan nhất giữa x và y.

Để tính toán năng lượng của bất kỳ cặp dữ liệu x và nhãn lớp y, chúng tôi sử dụng y để ảnh hưởng đến một độ lợi có điều kiện trên x, điều này phục vụ như một bộ lọc chú ý (Xu et al., 2015) để chọn thông tin liên quan nhất giữa x và y. Trong Hình 1 (phải), chúng tôi đầu tiên gửi x vào một mạng để tạo ra một đặc trưng f(x). Nhãn y được ánh xạ thành một đặc trưng cùng chiều g(y) sử dụng một mạng học nhỏ hoặc một phép chiếu cố định. Chúng tôi sử dụng khối cổng G để chọn thông tin liên quan nhất giữa x và y:

m(x,y) = G(f(x),g(y)) (6)

Đầu ra cuối cùng được gửi đến các lớp trọng số để tạo ra giá trị năng lượng E(x,y). Xem Phụ lục C để biết thêm chi tiết về kiến trúc mô hình của chúng tôi.

EBM của chúng tôi cho phép bất kỳ số lượng lớp nào trong các batch mới bằng cách đơn giản huấn luyện hoặc định nghĩa một độ lợi có điều kiện g(y) mới cho các lớp mới và tạo ra giá trị năng lượng của nó với điểm dữ liệu x.

Suy luận. Trong quá trình suy luận, vì chúng tôi đánh giá theo kịch bản học gia tăng lớp, mô hình phải dự đoán một nhãn lớp bằng cách chọn từ tất cả các lớp đã thấy cho đến nay. Để x là một điểm dữ liệu với một nhãn rời rạc liên quan y. Có Y nhãn lớp khác nhau trong tập dữ liệu. Ước lượng MAP là ŷ = arg min(y'∈Y) E(x,y'), trong đó y'∈Y và E là hàm năng lượng với các tham số sau khi huấn luyện trên tất cả dữ liệu huấn luyện.

Mục tiêu huấn luyện EBM thay thế. EBM không giới hạn trong việc mô hình hóa phân phối có điều kiện giữa x và y như được hiển thị trong Phương trình (3). Một cách khác để sử dụng phân phối Boltzmann là định nghĩa khả năng chung của x và y. Trong Phụ lục F, chúng tôi chỉ ra rằng việc mô hình hóa khả năng chung có thể cải thiện thêm kết quả. Vì trọng tâm chính của bài báo này là đề xuất một mục tiêu huấn luyện EBM đơn giản nhưng hiệu quả cho học liên tục, chúng tôi chỉ hiển thị kết quả của việc sử dụng Phương trình (5) trong bài báo chính này.

5 CÁC THỰC NGHIỆM

Trong phần này, chúng tôi muốn trả lời các câu hỏi sau: EBM được đề xuất hoạt động như thế nào trên các cài đặt CL khác nhau? Chúng ta có thể áp dụng mục tiêu huấn luyện EBM cho các phương pháp khác không? Và kiến trúc tốt nhất cho điều kiện nhãn là gì? Để trả lời những câu hỏi này, chúng tôi đầu tiên báo cáo các thực nghiệm trên cài đặt nhận biết ranh giới trong Phần 5.1. Sau đó chúng tôi chỉ ra rằng EBM cũng có thể được áp dụng cho cài đặt không có ranh giới trong Phần 5.2.

5.1 CÁC THỰC NGHIỆM TRÊN CÀI ĐẶT NHẬN BIẾT RANH GIỚI

Tập dữ liệu. Chúng tôi đánh giá EBM được đề xuất trên bốn tập dữ liệu CL thường được sử dụng, bao gồm split MNIST (Zenke et al., 2017), permuted MNIST (Kirkpatrick et al., 2017), CIFAR-10 (Krizhevsky et al., 2009), và CIFAR-100 (Krizhevsky et al., 2009). Split MNIST được thu được bằng cách chia MNIST gốc (LeCun et al., 1998) thành 5 nhiệm vụ với mỗi nhiệm vụ có 2 lớp. Nó có 60.000 hình ảnh huấn luyện và 10.000 hình ảnh kiểm tra. Chúng tôi tuân theo triển khai của (van de Ven & Tolias, 2019) cho permuted MNIST. Có 10 nhiệm vụ và mỗi nhiệm vụ có 10 lớp. Chúng tôi tách CIFAR-10

5

--- TRANG 6 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

Bảng 1: Đánh giá học gia tăng lớp trên cài đặt nhận biết ranh giới trên bốn tập dữ liệu. Các thực nghiệm do chúng tôi thực hiện được tiến hành 10 lần với các hạt giống ngẫu nhiên khác nhau, kết quả được báo cáo là trung bình ± SEM trên những lần chạy này. Kết quả với (-) có nghĩa là chúng không được báo cáo trong bài báo gốc của họ. Kết quả với (-) có nghĩa là SEM không được báo cáo trong bài báo gốc của họ.

Không có Phát lại       split MNIST    permuted MNIST    CIFAR-10    CIFAR-100
SBC                     19.90±0.02      17.26±0.19       19.06±0.05   8.18±0.10
EBM                     53.12±0.04      87.58±0.50       38.84±1.08   30.28±0.28
EWC (Kirkpatrick et al., 2017)     20.01±0.06      25.04±0.50       18.99±0.03   8.20±0.09
Online EWC (Schwarz et al., 2018)  19.96±0.07      33.88±0.49       19.07±0.13   8.38±0.15
SI (Zenke et al., 2017)            19.99±0.06      29.31±0.62       19.14±0.12   9.24±0.22
LwF (Li & Hoiem, 2017)             23.85±0.44      22.64±0.23       19.20±0.30   10.71±0.11
MAS (Aljundi et al., 2019b)        19.50±0.30      -                20.25±1.54   8.44±0.27
BGD (Zeno et al., 2018)            19.64±0.03      84.78±1.30       -            -

Có Phát lại            split MNIST    permuted MNIST    CIFAR-10    CIFAR-100
SBC+ER                 90.65±0.45      93.70±0.09       42.07±0.64   28.57±0.35
EBM+ER                 91.13±0.35      94.59±0.09       44.76±0.73   34.07±0.55
iCaRL (Rebuffi et al., 2017)       94.57±0.11      94.85±0.03       -            -
DGR (Shin et al., 2017)            91.30±0.60      92.19±0.09       17.21±1.88   9.22±0.24
BI-R (van de Ven et al., 2020)     94.41±0.15      -                21.51±0.25   -
GSS-Greedy (Aljundi et al., 2019c) 84.80±1.80      77.30±0.50       33.56±1.70   -
CTN (Pham et al., 2021)            -               79.01±0.65       -            -
PGMA (Hu et al., 2019)             81.70±(-)       -                40.47±(-)    -

thành 5 nhiệm vụ, mỗi nhiệm vụ với 2 lớp. CIFAR-100 được chia thành 10 nhiệm vụ với mỗi nhiệm vụ có 10 lớp. CIFAR-10 và CIFAR-100 mỗi cái có 50.000 hình ảnh huấn luyện và 10.000 hình ảnh kiểm tra.

Giao thức đánh giá. Tất cả các thực nghiệm được thực hiện theo kịch bản học gia tăng lớp, được coi là cài đặt tự nhiên nhất và cũng khó nhất cho học liên tục (Tao et al., 2020a; He et al., 2018; Tao et al., 2020b). Nhiều phương pháp CL hoạt động tốt cho học gia tăng nhiệm vụ, thất bại khi được yêu cầu thực hiện học gia tăng lớp (van de Ven & Tolias, 2019). Thêm chi tiết có thể được tìm thấy trong Phụ lục A.1.

5.1.1 SO SÁNH VỚI CÁC PHƯƠNG PHÁP HIỆN CÓ

So sánh đầu tiên được quan tâm là hiệu suất của EBM được đề xuất so sánh như thế nào với hiệu suất của bộ phân loại dựa trên softmax (SBC). Nhưng chúng tôi nhắm cao hơn, và chúng tôi bổ sung so sánh EBM được đề xuất hoạt động như thế nào so với các phương pháp được thiết kế đặc biệt cho học liên tục. Đối với điều này, chúng tôi so sánh với các phương pháp EWC (Kirkpatrick et al., 2017), Online EWC (Schwarz et al., 2018), SI (Zenke et al., 2017), LwF (Li & Hoiem, 2017), MAS (Aljundi et al., 2019b), BGD (Zeno et al., 2018), BI-R (van de Ven et al., 2020), DGR (Shin et al., 2017), iCaRL (Rebuffi et al., 2017), GSS-Greedy (Aljundi et al., 2019c), CTN (Pham et al., 2021), và PGMA (Hu et al., 2019).

So sánh với các phương pháp không có phát lại. Chúng tôi đầu tiên so sánh EBM với các phương pháp CL không sử dụng phát lại. Trong các thực nghiệm của chúng tôi, chúng tôi kiểm soát các đường cơ sở và EBM để có kiến trúc mô hình tương tự với số lượng tham số mô hình tương tự. Đối với SBC, EWC, Online EWC, Online EWC, LwF trên splitMNIST, permuted MNIST và CIFAR-100, chúng tôi sử dụng kết quả được báo cáo trong (van de Ven & Tolias, 2019; van de Ven et al., 2020). Đối với BGD, kết quả là từ (Zeno et al., 2018). Đối với MAS, chúng tôi sử dụng kết quả từ (Prabhu et al., 2020; Zhang et al., 2020). Chúng tôi thực hiện các thực nghiệm khác bằng cách sử dụng mã có sẵn công khai. Các kiến trúc mô hình chi tiết được liệt kê trong Phụ lục C.

Kết quả Class-IL trên bốn tập dữ liệu được hiển thị trong Bảng 1. Các thực nghiệm do chúng tôi thực hiện được tiến hành 10 lần với các hạt giống ngẫu nhiên khác nhau, với kết quả được báo cáo là trung bình ± SEM. Các chế độ huấn luyện tương tự được sử dụng cho EBM và các đường cơ sở. Trên split MNIST, permuted MNIST và CIFAR-10, chúng tôi huấn luyện trong 2000 lần lặp mỗi nhiệm vụ. Trên CIFAR-100, chúng tôi huấn luyện trong 5000 lần lặp mỗi nhiệm vụ. Tất cả các thực nghiệm sử dụng bộ tối ưu Adam với tốc độ học 1e-4.

Trên những bộ dữ liệu chuẩn Class-IL này, chúng tôi quan sát thấy rằng EBM có sự cải thiện đáng kể so với SBC, cũng như so với một số phương pháp CL dựa trên softmax không dựa vào một hạn ngạch bộ nhớ ngoài hoặc sử dụng phát lại sinh tạo.

Một số phương pháp gần đây (Wortsman et al., 2020; Henning et al., 2021; Yan et al., 2021; Douillard et al., 2022) cũng đạt được hiệu suất tốt trên Class-IL mà không sử dụng phát lại. Tuy nhiên, mục tiêu chính của chúng tôi là sử dụng EBM, tương tự như bộ phân loại dựa trên softmax, như một khối xây dựng cho học liên tục. Chúng tôi tin rằng việc tối ưu hóa kiến trúc mô hình, sử dụng mô hình lớn hơn, thêm các kỹ thuật bổ sung hoặc lưu dữ liệu trước đó có thể cải thiện thêm hiệu suất, nhưng đây không phải là trọng tâm của bài báo.

6

--- TRANG 7 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

Bảng 2: Kết quả Class-IL của EBM và các đường cơ sở sử dụng mục tiêu huấn luyện phân kỳ tương phản của chúng tôi và mục tiêu gốc của họ.

Tập dữ liệu    Phương pháp        CLS         EWC         Online EWC   SI          EBM
split MNIST    Mục tiêu Gốc      19.90±0.02   20.01±0.06   19.96±0.07   19.99±0.06   -
              Mục tiêu CD        44.98±0.05   50.68±0.04   50.99±0.03   49.44±0.03   53.12±0.04
CIFAR-10      Mục tiêu Gốc      19.06±0.01   18.99±0.01   19.07±0.01   19.14±0.02   -
              Mục tiêu CD        19.22±0.02   36.51±0.03   36.16±0.02   35.12±0.02   38.84±0.01

Bảng 3: Hiệu suất của EBM trên CIFAR-100 với các chiến lược khác nhau để chọn các mẫu âm.

Tập dữ liệu               CIFAR-100
All Neg Seen             8.07±0.10
All Neg Batch            29.03±0.53
1 Neg Batch              30.28±0.28

...SBC SBC*EBMT1T2T3T4T5T6T7T8T9T10T1T2T3T4T5T6T7T8T9T10T1T2T3T4T5T6T7T8T9T10Accuracy1.00.80.60.40.20.0 Hình 2: Độ chính xác kiểm tra Class-IL của SBC, SBC sử dụng mục tiêu huấn luyện của chúng tôi (SBC*), và EBM trên mỗi nhiệm vụ trên tập dữ liệu permuted MNIST.

So sánh với các phương pháp có phát lại. Chúng tôi chú ý rằng nhiều phương pháp hiện có thành công cho Class-IL dựa vào một hạn ngạch bộ nhớ ngoài (Rebuffi et al., 2017; Hayes et al., 2020) hoặc sử dụng các mô hình sinh tạo (Shin et al., 2017; van de Ven et al., 2021; 2020; Liu et al., 2020; Cong et al., 2020). Một nhược điểm của những phương pháp này là chúng tương đối tốn kém về bộ nhớ và/hoặc tính toán. Do đó không công bằng khi so sánh phiên bản cơ bản của EBM với các phương pháp sử dụng phát lại.

Tuy nhiên, điều quan trọng là EBM đủ linh hoạt để được kết hợp với các phương pháp học liên tục hiện có để cải thiện thêm hiệu suất. Trong Bảng 1, chúng tôi hiển thị kết quả của việc kết hợp EBM với phát lại chính xác, tức là EBM+ER. Vì EBM+ER sử dụng dữ liệu trước đó trong quá trình huấn luyện, để so sánh công bằng, chúng tôi thiết kế một đường cơ sở khác kết hợp SBC với phát lại chính xác, tức là SBC+ER. Xem Phụ lục D để biết chi tiết triển khai của EBM+ER và SBC+ER. Kết hợp với phát lại, cả SBC và EBM đều có cải thiện. EBM vẫn vượt trội hơn SBC, đặc biệt trên các tập dữ liệu thách thức hơn, ví dụ CIFAR-10 và CIFAR-100. Thú vị, trên CIFAR-100, chúng tôi thấy rằng EBM không sử dụng phát lại (EBM: 30.28%) hoạt động tốt hơn SBC có sử dụng phát lại (SBC+ER: 28.57%). Hơn nữa, hiệu suất của EBM+ER có thể so sánh với hiệu suất của các phương pháp dựa trên phát lại đã được thiết lập như iCaRL, DGR và BI-R.

Kết quả của chúng tôi chỉ ra rằng công thức EBM được đề xuất cung cấp một khối xây dựng đầy hứa hẹn để giải quyết các vấn đề CL. Các phương pháp khác, chẳng hạn như các phương pháp dựa trên phát lại, có thể xây dựng trên nền tảng EBM.

5.1.2 TÁC ĐỘNG CỦA MỤC TIÊU HUẤN LUYỆN PHÂN KỲ TƯƠNG PHẢN VÀ ĐIỀU KIỆN NHÃN

Mục tiêu huấn luyện phân kỳ tương phản trên các phương pháp hiện có. Mục tiêu huấn luyện phân kỳ tương phản được đề xuất đơn giản và cũng có thể được áp dụng trực tiếp cho các phương pháp CL hiện có. Chúng tôi kiểm tra điều này bằng cách sửa đổi mục tiêu huấn luyện của các mô hình đường cơ sở thành mục tiêu phân kỳ tương phản được đề xuất của chúng tôi, tính toán chuẩn hóa softmax chỉ trên lớp sự thật cơ bản y và một lớp âm i được lấy mẫu từ batch huấn luyện hiện tại: LSBC_CD(x,y) = [f(x)]y + [f(x)]i. Chúng tôi chỉ sửa đổi mục tiêu huấn luyện của họ mà không thay đổi kiến trúc mô hình của họ. Trong Bảng 2, chúng tôi thấy rằng mục tiêu huấn luyện được đề xuất của chúng tôi (Mục tiêu CD) cải thiện đáng kể hiệu suất của các phương pháp CL khác nhau. Điều này là do mục tiêu phân kỳ tương phản không ức chế xác suất của các lớp cũ khi cải thiện xác suất của các lớp mới. Mục tiêu huấn luyện của chúng tôi đơn giản để triển khai trên các phương pháp CL hiện có.

Tác động của các mục tiêu huấn luyện. Chúng tôi tiến hành một thực nghiệm trên tập dữ liệu CIFAR-100 để điều tra cách các mục tiêu huấn luyện EBM khác nhau ảnh hưởng đến kết quả CL. Chúng tôi so sánh ba chiến lược khác nhau để chọn các mẫu âm như được mô tả trong Phần 4.3. Chiến lược đầu tiên sử dụng tất cả các lớp đã thấy cho đến nay như các nhãn âm (All Neg Seen), giống nhất với cách mà bộ phân loại truyền thống được tối ưu. Chiến lược thứ hai lấy tất cả các lớp trong batch hiện tại như các nhãn âm (All Neg Batch). Chiến lược cuối cùng — mục tiêu phân kỳ tương phản mà chúng tôi đề xuất trong Phương trình (5) — ngẫu nhiên chọn một lớp từ batch hiện tại như nhãn âm (1 Neg Batch). Trong Bảng 3, chúng tôi thấy rằng sử dụng chỉ một mẫu âm tạo ra kết quả tốt nhất, và sử dụng các mẫu âm được lấy từ các lớp trong batch hiện tại tốt hơn so với từ tất cả các lớp đã thấy. Vì mục tiêu huấn luyện EBM của chúng tôi nhắm tới cải thiện năng lượng của các mẫu âm trong khi giảm năng lượng của các mẫu dương, việc lấy mẫu âm từ batch hiện tại có ít can thiệp hơn với các lớp trước đó so với việc lấy mẫu từ tất cả các lớp đã thấy. Mục tiêu huấn luyện phân kỳ tương phản được đề xuất sử dụng một mẫu âm duy nhất và gây ức chế tối thiểu trên các mẫu âm.

7

--- TRANG 8 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

Bảng 4: Hiệu suất của EBM với các kiến trúc điều kiện nhãn khác nhau trên tập dữ liệu CIFAR-10.

Kiến trúc mô hình                    Các loại chuẩn hóa
Beginning (V1)        13.69±1.12     End Fix (V4)          34.30±1.03
Middle (V2)           20.16±1.05     End Fix Norm2 (V4)    33.91±1.13
Middle (V3)           18.36±0.97     End Fix Softmax (V4)  35.97±1.09
End (V4)              38.13±0.59     End Norm2 (V4)        37.23±1.20
                                     End Softmax (V4)      38.84±1.08

Tác động của điều kiện nhãn. Tiếp theo, chúng tôi kiểm tra xem điều kiện nhãn trong EBM của chúng tôi có quan trọng đối với hiệu suất của chúng không. Như đã đề cập trong Bảng 2, chúng tôi sửa đổi các đường cơ sở sử dụng mục tiêu huấn luyện của chúng tôi. Sự khác biệt duy nhất là EBM có kiến trúc điều kiện nhãn trong khi các đường cơ sở thì không. EBM vượt trội hơn các đường cơ sở đã sửa đổi, ví dụ Online EWC — đường cơ sở tốt nhất với mục tiêu huấn luyện phân kỳ tương phản — là 50.99% trong khi EBM là 53.12% trên split MNIST. Điều này ngụ ý rằng kiến trúc điều kiện nhãn giảm thiểu việc quên thảm khốc trong EBM.

Chúng tôi tiếp tục hiển thị độ chính xác kiểm tra của mỗi nhiệm vụ khi quá trình huấn luyện tiến triển trong Hình 2. Chúng tôi so sánh bộ phân loại tiêu chuẩn (SBC), bộ phân loại sử dụng mục tiêu huấn luyện phân kỳ tương phản (SBC*), và EBM của chúng tôi trên tập dữ liệu permuted MNIST. Chúng tôi thấy rằng độ chính xác của các nhiệm vụ cũ trong SBC giảm mạnh khi học các nhiệm vụ mới, trong khi mục tiêu huấn luyện phân kỳ tương phản được sử dụng trong SBC* tốt hơn. Đường cong trên EBM giảm thậm chí chậm hơn so với SBC*.

Vì cả SBC* và EBM đều sử dụng mục tiêu huấn luyện phân kỳ tương phản, hiệu suất tốt của EBM ngụ ý tính hiệu quả của kiến trúc điều kiện nhãn trong EBM.

Tóm lại, chúng tôi chỉ ra rằng hiệu suất mạnh mẽ của EBM của chúng tôi là do cả mục tiêu huấn luyện phân kỳ tương phản và kiến trúc điều kiện nhãn. Hơn nữa, những kết quả này chỉ ra rằng một cách đáng ngạc nhiên và ngược trực giác, việc trực tiếp tối ưu hóa kiến trúc dựa trên softmax với mất mát cross-entropy được sử dụng bởi các phương pháp hiện có có thể không phải là cách tốt nhất để tiếp cận học liên tục.

5.1.3 SO SÁNH CÁC KIẾN TRÚC MÔ HÌNH KHÁC NHAU

EBM cho phép tính linh hoạt trong việc tích hợp thông tin dữ liệu và thông tin nhãn trong hàm năng lượng. Để điều tra vị trí và cách kết hợp thông tin từ dữ liệu x và nhãn y, chúng tôi tiến hành một loạt thực nghiệm trên CIFAR-10.

Bảng 4 hiển thị bốn kiến trúc mô hình (V1-V4) kết hợp x và y trong các giai đoạn sớm, giữa và muộn tương ứng (xem Phụ lục C để biết thêm chi tiết). Chúng tôi thấy rằng việc kết hợp x và y trong giai đoạn muộn (V4) hoạt động tốt nhất. Chúng tôi lưu ý rằng thay vì học một nhúng đặc trưng của nhãn y, chúng ta có thể sử dụng một ma trận chiếu cố định được lấy mẫu ngẫu nhiên từ phân phối đều U(0,1). Thậm chí việc sử dụng phép chiếu ngẫu nhiên cố định này đã có thể tạo ra kết quả tốt hơn so với hầu hết các đường cơ sở không có phát lại trong Bảng 1. Lưu ý thêm rằng số lượng tham số có thể huấn luyện trong cài đặt "Fix" thấp hơn nhiều so với các đường cơ sở. Chúng tôi chú ý rằng các bộ phân loại tiêu chuẩn phải thay đổi kiến trúc mô hình của chúng bằng cách thêm các đầu lớp mới vào lớp đầu ra softmax khi xử lý các lớp mới. Ngược lại, cài đặt "Fix" của EBM không cần sửa đổi kiến trúc mô hình hoặc thay đổi kích thước mạng khi thêm các lớp mới. Việc sử dụng một nhúng đặc trưng được học của y có thể cải thiện thêm kết quả. Chúng tôi áp dụng các phương pháp chuẩn hóa khác nhau trên kênh đặc trưng của y. Chúng tôi thấy rằng Softmax (End Softmax (V4)) tốt hơn chuẩn hóa L2 (End Norm2 (V4)) và không chuẩn hóa (End (V4)).

5.1.4 PHÂN TÍCH ĐỊNH TÍNH

Để hiểu rõ hơn tại sao EBM ít chịu thiệt hại hơn từ việc quên thảm khốc, chúng tôi so sánh định tính EBM và SBC của chúng tôi trong phần này. Chúng tôi cung cấp các phân tích bổ sung về hiệu suất CL của SBC và EBM trong Phụ lục B và Phụ lục E.

Cảnh quan năng lượng. Trong Hình 3, chúng tôi hiển thị các cảnh quan năng lượng sau khi huấn luyện trên nhiệm vụ 9 và nhiệm vụ 10 của tập dữ liệu permuted MNIST. Đối với SBC, năng lượng được cho bởi giá trị âm của xác suất được dự đoán. Mỗi điểm dữ liệu có 100 giá trị năng lượng (EBM) hoặc xác suất (SBC) tương ứng với 100 nhãn trong tập dữ liệu. Đối với mỗi điểm dữ liệu, những giá trị này được chuẩn hóa trên tất cả 100 lớp. Các phần tử tối trên đường chéo chỉ ra dự đoán chính xác. Sau khi huấn luyện trên nhiệm vụ T9, SBC gán xác suất cao cho các lớp từ T9(80-90) cho hầu hết dữ liệu từ T1 đến T9. Sau khi học nhiệm vụ T10, các xác suất cao nhất chuyển sang các lớp từ nhiệm vụ T10(90-100). SBC có xu hướng gán xác suất cao cho các lớp mới cho cả dữ liệu cũ và mới, chỉ ra việc quên. Ngược lại, EBM có năng lượng thấp trên đường chéo, có nghĩa là sau khi huấn luyện trên các nhiệm vụ mới, EBM vẫn gán năng lượng thấp cho các nhãn đúng của dữ liệu từ các nhiệm vụ trước đó. Điều này cho thấy rằng EBM tốt hơn SBC trong việc học các nhiệm vụ mới mà không quên thảm khốc các nhiệm vụ cũ.

Phân phối lớp được dự đoán. Trong Hình 4, đối với tập dữ liệu split MNIST, chúng tôi vẽ phân phối tỷ lệ của các lớp được dự đoán. Chỉ dữ liệu từ các nhiệm vụ đã thấy cho đến nay được sử dụng cho hình này. Lấy panel thứ hai trong

8

--- TRANG 9 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

Hình 3: Bản đồ năng lượng của SBC và EBM sau khi huấn luyện trên nhiệm vụ T9 và T10 trên permuted MNIST. Đường chéo càng tối, mô hình càng tốt trong việc ngăn chặn việc quên các nhiệm vụ trước đó.

Phân phối Nhãn(Class-IL) splitMNISTCLSEBM 123456789101212341234561234567812345678910 Phân phối Nhãn(Class-IL) splitMNISTCLSEBM 123456789101212341234561234567812345678910 Phân phối Nhãn(Class-IL) splitMNISTCLSEBM 123456789101212341234561234567812345678910 Phân phối Nhãn(Class-IL) splitMNISTCLSEBM 123456789101212341234561234567812345678910 Phân phối Nhãn(Class-IL) splitMNISTCLSEBM 123456789101212341234561234567812345678910EBM Phân phối Nhãn(Class-IL) splitMNISTCLSEBM 123456789101212341234561234567812345678910 Phân phối Nhãn(Class-IL) splitMNISTCLSEBM 123456789101212341234561234567812345678910

Phân phối Nhãn(Class-IL) splitMNISTCLSEBM 123456789101212341234561234567812345678910 Phân phối Nhãn(Class-IL) splitMNISTCLSEBM 123456789101212341234561234567812345678910 347891056SBC Hình 4: Phân phối nhãn được dự đoán sau khi học mỗi nhiệm vụ trên split MNIST. SBC chỉ dự đoán các lớp từ nhiệm vụ hiện tại, trong khi EBM dự đoán các lớp từ tất cả các lớp đã thấy.

Bảng 5: Đánh giá hiệu suất học gia tăng lớp trên cài đặt không có ranh giới. Mỗi thực nghiệm được thực hiện 5 lần với các hạt giống ngẫu nhiên khác nhau, độ chính xác kiểm tra trung bình được báo cáo là trung bình ± SEM trên những lần chạy này.

Phương pháp             split MNIST    permuted MNIST    CIFAR-10      CIFAR-100
SBC                     24.03±0.59     21.42±0.11       23.30±0.81    9.85±0.02
EBM                     81.78±1.22     92.35±0.11       49.47±1.25    34.39±0.24
Online EWC (Schwarz et al., 2018)  39.62±0.14     41.37±0.04       22.53±0.41    9.57±0.02
SI (Zenke et al., 2017)            28.79±0.24     35.71±0.11       26.26±0.72    10.42±0.01
BGD (Zeno et al., 2018)            21.65±1.15     26.15±0.22       17.03±0.82    8.50±0.02

hàng đầu tiên làm ví dụ, nó hiển thị phân phối của các nhãn được dự đoán trên dữ liệu kiểm tra từ hai nhiệm vụ đầu tiên sau khi hoàn thành huấn luyện trên nhiệm vụ thứ hai. Điều này có nghĩa là cho đến nay mô hình đã thấy bốn lớp: {1,2,3,4}. Vì số lượng hình ảnh kiểm tra từ mỗi lớp tương tự, phân phối tỷ lệ sự thật cơ bản phải đồng đều trên bốn lớp đó. Sau khi huấn luyện trên nhiệm vụ đầu tiên, các dự đoán của SBC thực sự phân phối gần như đồng đều trên hai lớp đầu tiên (panel đầu tiên). Tuy nhiên, sau khi học các nhiệm vụ mới, SBC chỉ dự đoán các lớp từ nhiệm vụ gần đây nhất, chỉ ra rằng SBC thất bại trong việc ghi nhớ chính xác các lớp từ các nhiệm vụ trước đó. Ngược lại, các dự đoán của EBM phân phối đồng đều hơn đáng kể trên tất cả các lớp đã thấy cho đến nay.

5.2 CÁC THỰC NGHIỆM TRÊN CÀI ĐẶT KHÔNG CÓ RANH GIỚI

Khi áp dụng học liên tục trong thực tế, ranh giới thường không được định nghĩa rõ ràng giữa các nhiệm vụ khác nhau. Tuy nhiên, hầu hết các phương pháp CL hiện có dựa vào sự hiện diện của ranh giới sắc nét, đã biết giữa các nhiệm vụ để xác định khi nào nên hợp nhất kiến thức. Chúng tôi chỉ ra rằng EBM có thể linh hoạt thực hiện CL trên các thiết lập khác nhau và hoạt động tốt trong cài đặt không có ranh giới.

5.2.1 TẬP DỮ LIỆU VÀ CÁC GIAO THỨC ĐÁNH GIÁ

Đối với cài đặt không có ranh giới, chúng tôi sử dụng cùng các tập dữ liệu như cài đặt nhận biết ranh giới trong Phần 5.1. Chúng tôi sử dụng mã của "học liên tục bất khả tri nhiệm vụ" được đề xuất bởi (Zeno et al., 2018) để tạo ra một luồng dữ liệu thay đổi liên tục trong quá trình huấn luyện. Trong cài đặt này, tần suất của mỗi lớp tiếp theo tăng và giảm tuyến tính. Xem Phụ lục A.2 để biết thêm chi tiết về cài đặt không có ranh giới. Tất cả các thực nghiệm lại được thực hiện trong thiết lập học gia tăng lớp.

5.2.2 SO SÁNH VỚI CÁC PHƯƠNG PHÁP HIỆN CÓ

Trong cài đặt này, chúng tôi hạn chế so sánh của chúng tôi với các phương pháp không sử dụng phát lại. Hầu hết các phương pháp không phát lại được so sánh trong Bảng 1 không thể áp dụng cho cài đặt không có ranh giới mà không cần sửa đổi, vì những phương pháp này dựa vào ranh giới nhiệm vụ đã biết để thực hiện các thao tác hợp nhất nhất định (ví dụ, để cập nhật số hạng chính quy hóa tham số). Một sự thích ứng tương đối đơn giản của những phương pháp này là thực hiện thao tác hợp nhất của chúng sau mỗi bước mini-batch thay vì sau mỗi nhiệm vụ (xem thêm (Zeno et al., 2018)), mặc dù sự thích ứng này không thực tế đối với một số thuật toán (ví dụ, EWC) vì độ phức tạp tính toán lớn. Chúng tôi đã quản lý để chạy các đường cơ sở Online EWC và SI theo cách này, trong khi đường cơ sở BGD được thiết kế để phù hợp với cài đặt không có ranh giới.

Chúng tôi tiếp tục lưu ý rằng có các phương pháp học liên tục có thể áp dụng cho các cài đặt trong đó ranh giới nhiệm vụ không được biết (tức là, cài đặt bất khả tri ranh giới), nhưng những phương pháp này không nhất thiết cũng áp dụng cho cài đặt không có ranh giới, vì thường những phương pháp này vẫn yêu cầu có ranh giới nhiệm vụ cơ bản. Ví dụ, phương pháp được đề xuất bởi (Wortsman et al., 2020) có thể suy luận ranh giới nhiệm vụ nếu chúng không được đưa ra (tức là, bất khả tri ranh giới), nhưng phương pháp này không thể xử lý cài đặt trong đó không có ranh giới cơ bản nào cả (tức là, không có ranh giới).

9

--- TRANG 10 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

Kết quả trên cài đặt không có ranh giới được hiển thị trong Bảng 5. Tất cả các phương pháp được so sánh sử dụng kiến trúc mô hình tương tự như trong cài đặt nhận biết ranh giới. Mỗi thực nghiệm được thực hiện 5 lần với các hạt giống ngẫu nhiên khác nhau, kết quả được báo cáo là trung bình ± SEM trên những lần chạy này. Chúng tôi quan sát thấy rằng EBM có sự cải thiện đáng kể trên tất cả các tập dữ liệu. Các thực nghiệm cho thấy rằng EBM có khả năng tổng quát hóa tốt cho các vấn đề học liên tục khác nhau vì EBM có thể tự nhiên xử lý các luồng dữ liệu có và không có ranh giới nhiệm vụ.

6 THẢO LUẬN

Trong bài báo này, chúng tôi chỉ ra rằng các mô hình dựa trên năng lượng là một lớp mô hình đầy hứa hẹn trong nhiều cài đặt học liên tục khác nhau. Chúng tôi chứng minh rằng EBM thể hiện nhiều đặc tính mong muốn để ngăn chặn việc quên thảm khốc trong học liên tục, và chúng tôi thực nghiệm chỉ ra rằng EBM đạt được hiệu suất mạnh mẽ trên kịch bản học gia tăng lớp thách thức trên nhiều bộ dữ liệu chuẩn, cả trên cài đặt nhận biết ranh giới và không có ranh giới. Một nhược điểm của công thức EBM hiện tại là chúng ta cần tính toán năng lượng giữa một điểm dữ liệu và mỗi lớp trong quá trình suy luận. Tuy nhiên, trong triển khai thực tế, chúng tôi thấy rằng sự khác biệt giữa bộ phân loại dựa trên softmax (SBC) và EBM của chúng tôi là nhỏ. Một hạn chế tiềm năng khác của công trình này là chúng tôi chỉ tập trung vào đánh giá độ chính xác trung bình, và chủ yếu chỉ sau khi huấn luyện đã hoàn thành. Có thể thú vị khi cũng tập trung vào các chỉ số đánh giá khác, chẳng hạn như chuyển giao ngược và tiến đánh giá khả năng của mô hình để chuyển giao kiến thức qua các nhiệm vụ (Lopez-Paz & Ranzato, 2017; Vogelstein et al., 2020), hoặc để thực hiện đánh giá liên tục (De Lange et al., 2022). Chúng tôi cung cấp một số kết quả và phân tích bổ sung trong phụ lục.

LỜI CẢM ỠN

Công trình này đã được hỗ trợ một phần bởi chương trình Máy Học Suốt Đời (L2M) của Cơ quan Dự án Nghiên cứu Quốc phòng Tiên tiến (DARPA) thông qua hợp đồng số HR0011-18-2-0025.

TÀI LIỆU THAM KHẢO

Rahaf Aljundi, Lucas Caccia, Eugene Belilovsky, Massimo Caccia, Min Lin, Laurent Charlin, và Tinne Tuytelaars. Online continual learning with maximally interfered retrieval. arXiv preprint arXiv:1908.04742, 2019a.

Rahaf Aljundi, Klaas Kelchtermans, và Tinne Tuytelaars. Task-free continual learning. Trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, trang 11254–11263, 2019b.

Rahaf Aljundi, Min Lin, Baptiste Goujaud, và Yoshua Bengio. Gradient based sample selection for online continual learning. Advances in neural information processing systems, 32, 2019c.

David Belanger và Andrew McCallum. Structured prediction energy networks. Trong International Conference on Machine Learning, trang 983–992, 2016.

Eden Belouadah, Adrian Popescu, và Ioannis Kanellos. Initial classifier weights replay for memoryless class incremental learning. arXiv preprint arXiv:2008.13710, 2020.

Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, và Simone Calderara. Dark experience for general continual learning: a strong, simple baseline. Trong 34th Conference on Neural Information Processing Systems (NeurIPS 2020), 2020.

Arslan Chaudhry, Marc'Aurelio Ranzato, Marcus Rohrbach, và Mohamed Elhoseiny. Efficient lifelong learning with a-gem. Trong International Conference on Learning Representations, 2019a.

Arslan Chaudhry, Marcus Rohrbach, Mohamed Elhoseiny, Thalaiyasingam Ajanthan, Puneet K Dokania, Philip HS Torr, và Marc'Aurelio Ranzato. On tiny episodic memories in continual learning. arXiv preprint arXiv:1902.10486, 2019b.

Yulai Cong, Miaoyun Zhao, Jianqiao Li, Sijia Wang, và Lawrence Carin. Gan memory with no forgetting. Advances in Neural Information Processing Systems, 33, 2020.

Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Greg Slabaugh, và Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021.

10

--- TRANG 11 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

Matthias De Lange, Gido van de Ven, và Tinne Tuytelaars. Continual evaluation for lifelong learning: Identifying the stability gap. arXiv preprint arxiv:2205.13452, 2022.

Yuntian Deng, Anton Bakhtin, Myle Ott, Arthur Szlam, và Marc'Aurelio Ranzato. Residual energy-based models for text generation. arXiv preprint arXiv:2004.11714, 2020.

Arthur Douillard, Alexandre Ramé, Guillaume Couairon, và Matthieu Cord. Dytox: Transformers for continual learning with dynamic token expansion. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, trang 9285–9295, 2022.

Yilun Du và Igor Mordatch. Implicit generation and generalization in energy-based models. arXiv preprint arXiv:1903.08689, 2019.

Yilun Du, Shuang Li, và Igor Mordatch. Compositional visual generation and inference with energy based models. arXiv preprint arXiv:2004.06030, 2020.

Sebastian Farquhar và Yarin Gal. Towards robust evaluations of continual learning. arXiv preprint arXiv:1805.09733, 2018.

Chrisantha Fernando, Dylan Banarse, Charles Blundell, Yori Zwols, David Ha, Andrei A Rusu, Alexander Pritzel, và Daan Wierstra. Pathnet: Evolution channels gradient descent in super neural networks. arXiv preprint arXiv:1701.08734, 2017.

Will Grathwohl, Kuan-Chieh Wang, Jörn-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi, và Kevin Swersky. Your classifier is secretly an energy based model and you should treat it like one. arXiv preprint arXiv:1912.03263, 2019.

Tuomas Haarnoja, Haoran Tang, Pieter Abbeel, và Sergey Levine. Reinforcement learning with deep energy-based policies. arXiv preprint arXiv:1702.08165, 2017.

Raia Hadsell, Dushyant Rao, Andrei A Rusu, và Razvan Pascanu. Embracing change: Continual learning in deep neural networks. Trends in Cognitive Sciences, 2020.

Tyler L Hayes và Christopher Kanan. Lifelong machine learning with deep streaming linear discriminant analysis. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, trang 220–221, 2020.

Tyler L Hayes, Kushal Kafle, Robik Shrestha, Manoj Acharya, và Christopher Kanan. Remind your neural network to prevent catastrophic forgetting. Trong European Conference on Computer Vision, trang 466–483. Springer, 2020.

Chen He, Ruiping Wang, Shiguang Shan, và Xilin Chen. Exemplar-supported generative reproduction for class incremental learning. Trong BMVC, trang 98, 2018.

Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun. Deep residual learning for image recognition. Trong Proceedings of the IEEE conference on computer vision and pattern recognition, trang 770–778, 2016.

Christian Henning, Maria Cervera, Francesco D'Angelo, Johannes Von Oswald, Regina Traber, Benjamin Ehret, Seijin Kobayashi, Benjamin F Grewe, và João Sacramento. Posterior meta-replay for continual learning. Advances in Neural Information Processing Systems, 34:14135–14149, 2021.

Geoffrey E Hinton. Training products of experts by minimizing contrastive divergence. Neural computation, 14(8): 1771–1800, 2002.

Saihui Hou, Xinyu Pan, Chen Change Loy, Zilei Wang, và Dahua Lin. Learning a unified classifier incrementally via rebalancing. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, trang 831–839, 2019.

Wenpeng Hu, Zhou Lin, Bing Liu, Chongyang Tao, Zhengwei Tao, Jinwen Ma, Dongyan Zhao, và Rui Yan. Overcoming catastrophic forgetting for continual learning via model adaptation. Trong International Conference on Learning Representations, 2019.

Xisen Jin, Arka Sadhu, Junyi Du, và Xiang Ren. Gradient based memory editing for task-free continual learning. arXiv preprint arXiv:2006.15294, 2020.

11

--- TRANG 12 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

Ta-Chu Kao, Kristopher Jensen, Gido van de Ven, Alberto Bernacchia, và Guillaume Hennequin. Natural continual learning: success is a journey, not (just) a destination. Advances in Neural Information Processing Systems, 34: 28067–28079, 2021.

James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, và các tác giả khác. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences, 114(13):3521–3526, 2017.

Soheil Kolouri, Nicholas A Ketz, Andrea Soltoggio, và Praveen K Pilly. Sliced cramer synaptic consolidation for preserving deeply learned representations. Trong International Conference on Learning Representations, 2020.

Alex Krizhevsky, Geoffrey Hinton, và các tác giả khác. Learning multiple layers of features from tiny images. 2009.

Yann LeCun, Corinna Cortes, và Christopher JC Burges. The mnist database of handwritten digits, 1998. URL http://yann. lecun. com/exdb/mnist, 10:34, 1998.

Yann LeCun, Sumit Chopra, Raia Hadsell, M Ranzato, và F Huang. A tutorial on energy-based learning. Predicting structured data, 1(0), 2006.

Soochan Lee, Junsoo Ha, Dongsu Zhang, và Gunhee Kim. A neural dirichlet process mixture model for task-free continual learning. Trong International Conference on Learning Representations, 2020.

Timothée Lesort, Hugo Caselles-Dupré, Michael Garcia-Ortiz, Andrei Stoian, và David Filliat. Generative models from the perspective of continual learning. Trong 2019 International Joint Conference on Neural Networks (IJCNN), trang 1–8. IEEE, 2019.

Timothée Lesort, Thomas George, và Irina Rish. Continual learning in deep networks: an analysis of the last layer. arXiv preprint arXiv:2106.01834, 2021.

Zhizhong Li và Derek Hoiem. Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence, 40(12):2935–2947, 2017.

Xialei Liu, Chenshen Wu, Mikel Menta, Luis Herranz, Bogdan Raducanu, Andrew D Bagdanov, Shangling Jui, và Joost van de Weijer. Generative feature replay for class-incremental learning. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, trang 226–227, 2020.

David Lopez-Paz và Marc'Aurelio Ranzato. Gradient episodic memory for continual learning. Trong Advances in Neural Information Processing Systems, trang 6467–6476, 2017.

Sandeep Madireddy, Angel Yanguas-Gil, và Prasanna Balaprakash. Neuromodulated neural architectures with local error signals for memory-constrained online continual learning. arXiv preprint arXiv:2007.08159, 2020.

Davide Maltoni và Vincenzo Lomonaco. Continuous learning in single-incremental-task scenarios. Neural Networks, 116:56–73, 2019.

Marc Masana, Xialei Liu, Bartlomiej Twardowski, Mikel Menta, Andrew D Bagdanov, và Joost van de Weijer. Class-incremental learning: survey and performance evaluation. arXiv preprint arXiv:2010.15277, 2020.

Nicolas Y Masse, Gregory D Grant, và David J Freedman. Alleviating catastrophic forgetting using context-dependent gating and synaptic stabilization. Proceedings of the National Academy of Sciences, 115(44):E10467–E10475, 2018.

Martin Mundt, Yong Won Hong, Iuliia Pliushch, và Visvanathan Ramesh. A wholistic view of continual learning with deep neural networks: Forgotten lessons and the bridge to active and open world learning. arXiv preprint arXiv:2009.01797, 2020.

Cuong V Nguyen, Yingzhen Li, Thang D Bui, và Richard E Turner. Variational continual learning. arXiv preprint arXiv:1710.10628, 2017.

Erik Nijkamp, Mitch Hill, Tian Han, Song-Chun Zhu, và Ying Nian Wu. On the anatomy of mcmc-based maximum likelihood learning of energy-based models. arXiv preprint arXiv:1903.12370, 2019.

Pingbo Pan, Siddharth Swaroop, Alexander Immer, Runa Eschenhagen, Richard E Turner, và Mohammad Emtiyaz Khan. Continual deep learning by functional regularisation of memorable past. Trong Advances in Neural Information Processing Systems, 2020.

12

--- TRANG 13 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

German I Parisi, Ronald Kemker, Jose L Part, Christopher Kanan, và Stefan Wermter. Continual lifelong learning with neural networks: A review. Neural Networks, 2019.

Quang Pham, Chenghao Liu, Doyen Sahoo, và HOI Steven. Contextual transformation networks for online continual learning. Trong International Conference on Learning Representations, 2021.

Ameya Prabhu, Philip HS Torr, và Puneet K Dokania. Gdumb: A simple approach that questions our progress in continual learning. 2020.

Jathushan Rajasegaran, Salman Khan, Munawar Hayat, Fahad Shahbaz Khan, và Mubarak Shah. itaml: An incremental task-agnostic meta-learning approach. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, trang 13588–13597, 2020.

Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, và Christoph H Lampert. icarl: Incremental classifier and representation learning. Trong Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, trang 2001–2010, 2017.

Anthony Robins. Catastrophic forgetting, rehearsal and pseudorehearsal. Connection Science, 7(2):123–146, 1995.

Amirmohammad Rooshenas, Dongxu Zhang, Gopal Sharma, và Andrew McCallum. Search-guided, lightly-supervised training of structured prediction energy networks. Trong Advances in Neural Information Processing Systems, trang 13522–13532, 2019.

Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, và Raia Hadsell. Progressive neural networks. arXiv preprint arXiv:1606.04671, 2016.

Ruslan Salakhutdinov và Geoffrey Hinton. Deep boltzmann machines. Trong David van Dyk và Max Welling (eds.), Proceedings of the Twelth International Conference on Artificial Intelligence and Statistics, volume 5 của Proceedings of Machine Learning Research, trang 448–455, Hilton Clearwater Beach Resort, Clearwater Beach, Florida USA, 16–18 Apr 2009. PMLR. URL http://proceedings.mlr.press/v5/salakhutdinov09a.html.

Jonathan Schwarz, Jelena Luketina, Wojciech M Czarnecki, Agnieszka Grabska-Barwinska, Yee Whye Teh, Razvan Pascanu, và Raia Hadsell. Progress & compress: A scalable framework for continual learning. arXiv preprint arXiv:1805.06370, 2018.

Joan Serra, Didac Suris, Marius Miron, và Alexandros Karatzoglou. Overcoming catastrophic forgetting with hard attention to the task. arXiv preprint arXiv:1801.01423, 2018.

Hanul Shin, Jung Kwon Lee, Jaehong Kim, và Jiwon Kim. Continual learning with deep generative replay. Trong Advances in Neural Information Processing Systems, trang 2990–2999, 2017.

Karen Simonyan và Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.

Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, và Andrew Rabinovich. Going deeper with convolutions. Trong Proceedings of the IEEE conference on computer vision and pattern recognition, trang 1–9, 2015.

Xiaoyu Tao, Xinyuan Chang, Xiaopeng Hong, Xing Wei, và Yihong Gong. Topology-preserving class-incremental learning. 2020a.

Xiaoyu Tao, Xiaopeng Hong, Xinyuan Chang, Songlin Dong, Xing Wei, và Yihong Gong. Few-shot class-incremental learning. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, trang 12183–12192, 2020b.

Michalis K Titsias, Jonathan Schwarz, Alexander G de G Matthews, Razvan Pascanu, và Yee Whye Teh. Functional regularisation for continual learning with gaussian processes. Trong International Conference on Learning Representations, 2020.

Lifu Tu và Kevin Gimpel. Benchmarking approximate inference methods for neural structured prediction. arXiv preprint arXiv:1904.01138, 2019.

Gido M van de Ven và Andreas S Tolias. Three scenarios for continual learning. arXiv preprint arXiv:1904.07734, 2019.

13

--- TRANG 14 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

Gido M van de Ven, Hava T Siegelmann, và Andreas S Tolias. Brain-inspired replay for continual learning with artificial neural networks. Nature Communications, 11:4069, 2020.

Gido M van de Ven, Zhe Li, và Andreas S Tolias. Class-incremental learning with generative classifiers. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, trang 3611–3620, 2021.

Joshua T Vogelstein, Jayanta Dey, Hayden S Helm, Will LeVine, Ronak D Mehta, Ali Geisa, Haoyin Xu, Gido M van de Ven, Chenyu Gao, Weiwei Yang, Bryan Tower, Jonathan Larson, Christopher M White, và Carey E Priebe. Representation ensembling for synergistic lifelong learning with quasilinear complexity. arXiv preprint arXiv:2004.12908, 2020.

Johannes von Oswald, Christian Henning, João Sacramento, và Benjamin F Grewe. Continual learning with hypernetworks. Trong International Conference on Learning Representations, 2019.

Mitchell Wortsman, Vivek Ramanujan, Rosanne Liu, Aniruddha Kembhavi, Mohammad Rastegari, Jason Yosinski, và Ali Farhadi. Supermasks in superposition. Advances in Neural Information Processing Systems, 33, 2020.

Yue Wu, Yinpeng Chen, Lijuan Wang, Yuancheng Ye, Zicheng Liu, Yandong Guo, và Yun Fu. Large scale incremental learning. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, trang 374–382, 2019.

Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel, và Yoshua Bengio. Show, attend and tell: Neural image caption generation with visual attention. Trong International conference on machine learning, trang 2048–2057, 2015.

Shipeng Yan, Jiangwei Xie, và Xuming He. Der: Dynamically expandable representation for class incremental learning. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, trang 3014–3023, 2021.

Jaehong Yoon, Eunho Yang, Jeongtae Lee, và Sung Ju Hwang. Lifelong learning with dynamically expandable networks. arXiv preprint arXiv:1708.01547, 2017.

Guanxiong Zeng, Yang Chen, Bo Cui, và Shan Yu. Continual learning of context-dependent processing in neural networks. Nature Machine Intelligence, 1(8):364–372, 2019.

Friedemann Zenke, Ben Poole, và Surya Ganguli. Continual learning through synaptic intelligence. Trong Proceedings of the 34th International Conference on Machine Learning-Volume 70, trang 3987–3995. JMLR. org, 2017.

Chen Zeno, Itay Golan, Elad Hoffer, và Daniel Soudry. Task agnostic continual learning using online variational bayes. arXiv preprint arXiv:1803.10123, 2018.

Song Zhang, Gehui Shen, và Zhi-Hong Deng. Self-supervised learning aided class-incremental lifelong learning. arXiv preprint arXiv:2006.05882, 2020.

14

--- TRANG 15 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

Phụ lục

Trong phụ lục này, chúng tôi cung cấp thêm chi tiết về thiết lập thực nghiệm trong Phần A. Chúng tôi hiển thị thêm kết quả thực nghiệm của EBM và các đường cơ sở của chúng tôi trong Phần B. Phần C liệt kê chi tiết kiến trúc mô hình của EBM được đề xuất và các đường cơ sở trên các tập dữ liệu khác nhau. Phần D có thêm chi tiết thực nghiệm của EBM sử dụng phát lại. Chúng tôi cung cấp phân tích bổ sung về tại sao EBM có thể giảm thiểu vấn đề quên thảm khốc trong học liên tục trong Phần E. Phần F mô tả mục tiêu huấn luyện EBM thay thế được đề cập trong phần chính của bài báo 4.3.

A THÊM CHI TIẾT THIẾT LẬP THỰC NGHIỆM

A.1 THÊM CHI TIẾT VỀ CÀI ĐẶT HỌC GIA TĂNG LỚP

Trong phần chính của bài báo Phần 2.1, chúng tôi đã nói về học gia tăng nhiệm vụ và học gia tăng lớp. Trong phần này, chúng tôi cung cấp thêm chi tiết về cài đặt học gia tăng lớp.

Học gia tăng lớp là một cài đặt học liên tục tiêu chuẩn và đã được sử dụng trong nhiều bài báo học liên tục hiện có. Trong học gia tăng lớp, mô hình được huấn luyện tuần tự trên mỗi nhiệm vụ. Trong quá trình kiểm tra, mô hình cần dự đoán lớp chính xác từ tất cả các lớp.

Huấn luyện: Lấy tập dữ liệu split MNIST dưới cài đặt nhận biết ranh giới làm ví dụ, nhiệm vụ1 có hình ảnh từ hai lớp [0, 1]; nhiệm vụ2 có hình ảnh từ hai lớp [2, 3]; ...; và nhiệm vụ5 có hình ảnh từ các lớp [8, 9]. Mô hình được huấn luyện đầu tiên trên nhiệm vụ1, và sau đó nhiệm vụ2, cho đến nhiệm vụ cuối cùng. Lưu ý rằng mô hình được huấn luyện tuần tự, vì vậy khi huấn luyện nhiệm vụ cuối cùng, mô hình chỉ thấy hình ảnh và lớp trong nhiệm vụ cuối cùng, và do đó nó có xu hướng quên các nhiệm vụ trước đó được gọi là quên thảm khốc.

Kiểm tra: Trong học gia tăng lớp, cho một hình ảnh từ một nhiệm vụ, mô hình cần dự đoán nhãn lớp của nó từ tất cả các lớp đã thấy (ví dụ 10 lớp trong split MNIST). Lưu ý rằng điều này thách thức vì 1) trong quá trình huấn luyện, mô hình chỉ cần dự đoán nhãn lớp của một hình ảnh từ các lớp trong nhiệm vụ hiện tại (ví dụ 2 lớp trong split MNIST); 2) sau khi mô hình được huấn luyện trên nhiệm vụ cuối cùng, nó có nhiều khả năng dự đoán các lớp từ nhiệm vụ cuối cùng (ví dụ các lớp [8, 9] trong split MNIST), thậm chí hình ảnh đầu vào là từ các nhiệm vụ trước đó. Vui lòng xem Hình 3 và Hình 4 trong bài báo chính để hiểu rõ hơn.

A.2 THÊM CHI TIẾT VỀ CÀI ĐẶT KHÔNG CÓ RANH GIỚI VÀ NHẬN BIẾT RANH GIỚI

Trong phần chính của bài báo Phần 2.1, chúng tôi đã nói về cài đặt không có ranh giới và nhận biết ranh giới. Trong phần này, chúng tôi cung cấp thêm chi tiết về cài đặt không có ranh giới ít được sử dụng hơn.

Không có ranh giới và nhận biết ranh giới là hai cài đặt khác nhau về cách dữ liệu được cung cấp trong quá trình huấn luyện. Chúng tôi tuân theo triển khai chung của (Zeno et al., 2018) cho cài đặt không có ranh giới. Trong cài đặt này, các mô hình học theo cách luồng và phân phối dữ liệu dần dần thay đổi theo thời gian. Lấy tập dữ liệu split MNIST làm ví dụ, nó có 10 lớp. Trong quá trình huấn luyện, tỷ lệ phần trăm của '1' trong mỗi batch huấn luyện dần dần giảm trong khi tỷ lệ phần trăm của '2' tăng, và sau đó tỷ lệ phần trăm của '2' trong mỗi batch huấn luyện dần dần giảm trong khi tỷ lệ phần trăm của '3' tăng, và cứ thế tiếp tục. Mô hình có thể quan sát dữ liệu từ các lớp khác nhau trong quá trình huấn luyện và không có ranh giới nhiệm vụ rõ ràng. Cũng có thể hữu ích khi xem Hình 2 của bài báo (Zeno et al., 2018) để hiểu trực quan tốt hơn về cài đặt không có ranh giới.

Trong mục tiêu huấn luyện phân kỳ tương phản của chúng tôi, chúng tôi ngẫu nhiên chọn 1 mẫu âm từ batch hiện tại. Nếu có nhiều mẫu âm, chúng tôi chỉ ngẫu nhiên chọn 1 từ chúng. Trong Bảng 3 của bài báo chính, mục tiêu huấn luyện phân kỳ tương phản của chúng tôi (1 Neg Batch=30.28) tốt hơn việc sử dụng tất cả các lớp âm trong batch hiện tại (All Neg Batch=29.03) và tốt hơn nhiều so với việc sử dụng tất cả các lớp âm đã thấy cho đến nay (All Neg Seen=8.07).

Trong mục tiêu huấn luyện phân kỳ tương phản, các lớp dương và âm được lấy mẫu từ batch hiện tại bất kể cách dữ liệu batch được cung cấp. Dữ liệu batch có thể được lấy mẫu dựa trên cài đặt không có ranh giới hoặc cài đặt nhận biết ranh giới. Ví dụ, Trong cài đặt nhận biết ranh giới, batch đầu tiên có thể chỉ chứa các lớp (1,2) từ nhiệm vụ đầu tiên, batch thứ hai có thể chỉ chứa các lớp (3,4) từ nhiệm vụ thứ hai, batch thứ ba có thể chỉ có các lớp (5,6) từ nhiệm vụ thứ ba, và cứ thế tiếp tục. Có ranh giới nhiệm vụ rõ ràng. Trong cài đặt không có ranh giới, batch đầu tiên có thể chứa các lớp (1), các batch sau có thể chứa các lớp (1,2), và sau đó các lớp (2,3), và cứ thế tiếp tục. Không có ranh giới nhiệm vụ.

Mất mát phân kỳ tương phản cho phép phương pháp của chúng tôi được huấn luyện mà không yêu cầu kiến thức về ranh giới nhiệm vụ, và do đó nó có thể tự nhiên xử lý cả cài đặt nhận biết ranh giới và không có ranh giới. Ngược lại, nhiều

15

--- TRANG 16 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

Bảng 6: So sánh EBM của chúng tôi với các đường cơ sở trên các biến thể khác nhau của giao thức split CIFAR-100. Kết quả của hiệu suất Class-IL trên cài đặt nhận biết ranh giới được báo cáo.

Phương pháp       CIFAR-100 được chia thành:
                  5 nhiệm vụ    10 nhiệm vụ    20 nhiệm vụ    50 nhiệm vụ
SBC               14.74±0.20    8.18±0.10      4.46±0.03      1.91±0.02
EBM               34.88±0.14    30.28±0.28     25.04±0.33     13.60±0.50
EWC (Kirkpatrick et al., 2017)  14.78±0.21    8.20±0.09      4.46±0.03      1.91±0.02
SI (Zenke et al., 2017)         14.07±0.24    9.24±0.22      4.37±0.04      1.88±0.03
LwF (Li & Hoiem, 2017)          25.75±0.14    10.71±0.11     12.18±0.16     7.68±0.16

SBC (split MNIST)  EBM (split MNIST)
SBC (permuted MNIST)  EBM (permuted MNIST)

Hình 5: Ma trận nhầm lẫn giữa nhãn sự thật cơ bản và nhãn được dự đoán vào cuối quá trình học trên split MNIST (trái) và permuted MNIST (phải). Đường chéo càng sáng, dự đoán càng chính xác.

phương pháp CL hiện có, chẳng hạn như EWC, LwF, không thể áp dụng trực tiếp cho cài đặt không có ranh giới vì chúng yêu cầu ranh giới nhiệm vụ để quyết định khi nào thực hiện các bước hợp nhất nhất định.

B KẾT QUẢ BỔ SUNG

Mở rộng kết quả được trình bày trong bài báo chính, ở đây chúng tôi tiếp tục so sánh EBM với các mô hình đường cơ sở bằng cách cung cấp thêm thực nghiệm về hiệu suất của chúng. Chúng tôi đầu tiên điều tra ảnh hưởng của số lượng nhiệm vụ khác nhau trong Phần B.1. Sau đó chúng tôi đánh giá độ phức tạp tính toán cho suy luận trong Phần B.2 và hiển thị ma trận nhầm lẫn giữa nhãn sự thật cơ bản và dự đoán mô hình trong Phần B.3.

B.1 ẢNH HƯỞNG CỦA SỐ LƯỢNG NHIỆM VỤ KHÁC NHAU

Để kiểm tra tính tổng quát của EBM được đề xuất của chúng tôi, chúng tôi lặp lại các thực nghiệm nhận biết ranh giới trên CIFAR-100 cho số lượng lớp khác nhau mỗi nhiệm vụ trong Bảng 6. Trong Bảng 1 của bài báo chính, tập dữ liệu CIFAR-100 được chia thành 10 nhiệm vụ, dẫn đến 10 lớp mỗi nhiệm vụ. Ở đây chúng tôi bổ sung chia CIFAR-100 thành 5 nhiệm vụ (tức là, 20 lớp mỗi nhiệm vụ), 20 nhiệm vụ (tức là, 5 lớp mỗi nhiệm vụ), và 50 nhiệm vụ (tức là, 2 lớp mỗi nhiệm vụ). EBM của chúng tôi vượt trội đáng kể so với các đường cơ sở trên tất cả các cài đặt.

B.2 ĐỘ PHỨC TẠP TÍNH TOÁN SUY LUẬN

Một nhược điểm của công thức EBM hiện tại là chúng ta cần tính toán năng lượng giữa một điểm dữ liệu và mỗi lớp trong quá trình suy luận. Tuy nhiên, trong triển khai thực tế, chúng tôi thấy rằng sự khác biệt giữa bộ phân loại dựa trên softmax (SBC) và EBM của chúng tôi là nhỏ.

Chúng tôi kiểm tra thời gian suy luận cần thiết cho một lần quét tiến đơn của bộ phân loại dựa trên softmax (SBC) và EBM của chúng tôi trên các tập dữ liệu split MNIST và CIFAR-10. Chúng tôi sử dụng GPU TITAN Xp 12G để kiểm tra. Chúng tôi đánh giá mỗi mô hình đơn lẻ trên 1 GPU đơn lẻ. Mỗi thực nghiệm được chạy 5 lần với các hạt giống ngẫu nhiên khác nhau.

Trên tập dữ liệu split MNIST, thời gian suy luận trung bình của SBC là 0.00022s trong khi EBM là 0.00027s. Trên CIFAR-10, thời gian suy luận trung bình của SBC là 0.00059s trong khi EBM là 0.00063s. Sự khác biệt giữa SBC và EBM ít hơn 0.0001s cho một lần chuyển tiến đơn.

B.3 MA TRẬN NHẦM LẪN LỚP VÀO CUỐI QUÁ TRÌNH HỌC

Chúng tôi hiển thị ma trận nhầm lẫn cho EBM và SBC. Ma trận nhầm lẫn minh họa mối quan hệ giữa nhãn sự thật cơ bản và nhãn được dự đoán. Hình 5 hiển thị ma trận nhầm lẫn sau khi huấn luyện trên tất cả các nhiệm vụ trên

16

--- TRANG 17 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

Bảng 7: Kiến trúc mô hình được sử dụng trên split MNIST. h = 400.

(a) Kiến trúc của EBM.
x = FC(784, h) (x)
y = Embedding (y)
x = x * Norm2 (y) + x
x = ReLU (x)
out = FC(h, 1) (x)

(b) Kiến trúc của các mô hình đường cơ sở.
x = FC(784, h) (x)
x = ReLU (x)
x = FC(h, h) (x)
x = ReLU (x)
out = FC(h, 10) (x)

Bảng 8: Kiến trúc mô hình được sử dụng trên permuted MNIST. h = 1000.

(a) Kiến trúc của EBM.
x = FC(1024, h) (x)
y = Embedding (y)
x = x * Norm2 (y) + x
x = ReLU (x)
out = FC(h, 1) (x)

(b) Kiến trúc của các mô hình đường cơ sở.
x = FC(1024, h) (x)
x = ReLU (x)
x = FC(h, h) (x)
x = ReLU (x)
out = FC(h, 100) (x)

tập dữ liệu split MNIST và tập dữ liệu permuted MNIST. Bộ phân loại tiêu chuẩn có xu hướng chỉ dự đoán các lớp từ nhiệm vụ cuối cùng (lớp 8, 9 trên tập dữ liệu split MNIST và các lớp 90-100 trên tập dữ liệu permuted MNIST). Mặt khác, EBM có giá trị cao dọc theo đường chéo, điều này chỉ ra rằng kết quả được dự đoán khớp với nhãn sự thật cơ bản cho tất cả các nhiệm vụ được học tuần tự.

Hiệu suất kém của SBC có thể được gây ra bởi sự mất cân bằng giữa độ lệch và chuẩn của các vector thiên về các lớp cuối cùng trong một lớp kết nối đầy đủ. (Wu et al., 2019) và (Hou et al., 2019) chỉnh sửa kết quả phân loại bằng cách dành mẫu cho các lớp cũ và/hoặc huấn luyện các lớp chỉnh sửa bổ sung. (Wu et al., 2019) huấn luyện một lớp chỉnh sửa độ lệch sử dụng dữ liệu từ cả các lớp cũ và các lớp mới. (Hou et al., 2019) cũng sử dụng dữ liệu cũ để cân bằng lại quá trình huấn luyện. Ngược lại, EBM có thể dự đoán các lớp chính xác mà không lưu trữ dữ liệu trước đó và không huấn luyện các lớp bổ sung để chỉnh sửa độ lệch. (Lesort et al., 2021) điều tra các nguồn khác nhau của sự giảm hiệu suất cho lớp đầu ra và đề xuất ba phương pháp khác nhau để giải quyết việc quên thảm khốc trong lớp đầu ra: một lớp chuẩn hóa trọng số đơn giản hóa, hai chiến lược che mặt nạ, và một lựa chọn thay thế cho Bộ phân loại Trung bình Gần nhất sử dụng các vector trung vị. Một số kỹ thuật cũng có thể được áp dụng cho EBM, chẳng hạn như chuẩn hóa trọng số.

C KIẾN TRÚC MÔ HÌNH

Trong phần này, chúng tôi cung cấp chi tiết về kiến trúc mô hình được sử dụng trên các tập dữ liệu khác nhau.

Hình ảnh từ các tập dữ liệu split MNIST và permuted MNIST là hình ảnh thang độ xám. Các mô hình đường cơ sở cho những tập dữ liệu này, tương tự như trong (van de Ven & Tolias, 2019), bao gồm một số lớp kết nối đầy đủ. Chúng tôi sử dụng kiến trúc mô hình với số lượng tham số tương tự cho EBM. Kiến trúc mô hình của EBM trên tập dữ liệu split MNIST và tập dữ liệu permuted MNIST giống nhau, nhưng có chiều đầu vào và đầu ra khác nhau và kích thước ẩn. Kiến trúc mô hình của EBM và các mô hình đường cơ sở trên tập dữ liệu split MNIST được hiển thị trong Bảng 7. Kiến trúc mô hình của EBM và các mô hình đường cơ sở trên tập dữ liệu permuted MNIST được hiển thị trong Bảng 8.

Hình ảnh từ các tập dữ liệu CIFAR-10 và CIFAR-100 là hình ảnh RGB. Đối với CIFAR-10, chúng tôi sử dụng một mạng tích chập nhỏ cho cả các mô hình đường cơ sở và EBM. Chúng tôi điều tra các kiến trúc khác nhau để tìm kiếm điều kiện nhãn hiệu quả trên huấn luyện EBM như được mô tả trong phần chính của bài báo Phần 5.1.3. Kiến trúc mô hình của EBM và các mô hình đường cơ sở trên tập dữ liệu CIFAR-10 được hiển thị trong Bảng 9. Kiến trúc mô hình được sử dụng trên tập dữ liệu CIFAR-100 được hiển thị trong Bảng 10.

D THÊM CHI TIẾT VỀ EBM SỬ DỤNG PHÁT LẠI

Trong phần chính của bài báo Phần 5.1.1, chúng tôi chỉ ra rằng công thức EBM được đề xuất có thể được kết hợp với các phương pháp học liên tục hiện có, chẳng hạn như phát lại chính xác. Trong phần này, chúng tôi cung cấp thêm chi tiết thực nghiệm của EBM sử dụng phát lại.

Khi huấn luyện một nhiệm vụ mới, chúng tôi trộn dữ liệu mới với dữ liệu được lấy mẫu từ một bộ đệm bộ nhớ lưu trữ các ví dụ của các nhiệm vụ đã học trước đó để huấn luyện các mô hình. Các ví dụ được lưu trữ trong bộ đệm được chọn ngẫu nhiên từ các lớp

17

--- TRANG 18 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

Bảng 9: Kiến trúc mô hình được sử dụng trên tập dữ liệu CIFAR-10.

(a) EBM: Beginning (V1)
Input: x, y
y = Embedding(N, 3) (y)
y = Softmax(dim=-1) (y)
y = y * y.shape[-1]
x = x * y
x = Conv2d(3×3, 3, 32) (x)
x = ReLU (x)
x = Conv2d(3×3, 32, 32) (x)
x = ReLU (x)
x = Maxpool(2, 2) (x)
x = Conv2d(3×3, 32, 64) (x)
x = ReLU (x)
x = Conv2d(3×3, 64, 64) (x)
x = ReLU (x)
x = Maxpool(2, 2) (x)
x = FC(2304, 1024) (x)
x = ReLU(x)
out = FC(1024, 1) (x)

(b) EBM: Middle (V2)
Input: x, y
x = Conv2d(3×3, 3, 32) (x)
x = ReLU (x)
x = Conv2d(3×3, 32, 32) (x)
x = ReLU (x)
y = Embedding(N, 32) (y)
y = Softmax(dim=-1) (y)
y = y * y.shape[-1]
x = x * y
x = Maxpool(2, 2) (x)
x = Conv2d(3×3, 32, 64) (x)
x = ReLU (x)
x = Conv2d(3×3, 64, 64) (x)
x = ReLU (x)
x = Maxpool(2, 2) (x)
x = FC(2304, 1024) (x)
x = ReLU(x)
out = FC(1024, 1) (x)

(c) EBM: Middle (V3)
Input: x, y
x = Conv2d(3×3, 3, 32) (x)
x = ReLU (x)
x = Conv2d(3×3, 32, 32) (x)
x = ReLU (x)
x = Maxpool(2, 2) (x)
x = Conv2d(3×3, 32, 64) (x)
x = ReLU (x)
x = Conv2d(3×3, 64, 64) (x)
x = ReLU (x)
y = Embedding(N, 64) (y)
y = Softmax(dim=-1) (y)
y = y * y.shape[-1]
x = x * y
x = Maxpool(2, 2) (x)
x = FC(2304, 1024) (x)
x = ReLU(x)
out = FC(1024, 1) (x)

(d) EBM: End Fix Softmax (V4)
Input: x, y
x = Conv2d(3×3, 3, 32) (x)
x = ReLU (x)
x = Conv2d(3×3, 32, 32) (x)
x = ReLU (x)
x = Maxpool(2, 2) (x)
x = Conv2d(3×3, 32, 64) (x)
x = ReLU (x)
x = Conv2d(3×3, 64, 64) (x)
x = ReLU (x)
x = Maxpool(2, 2) (x)
x = FC(2304, 1024) (x)
y = Random Projection (y)
y = Softmax(dim=-1) (y)
y = y * y.shape[-1]
x = x * y
out = FC(1024, 1) (x)

(e) EBM: End Softmax (V4)
Input: x, y
x = Conv2d(3×3, 3, 32) (x)
x = ReLU (x)
x = Conv2d(3×3, 32, 32) (x)
x = ReLU (x)
x = Maxpool(2, 2) (x)
x = Conv2d(3×3, 32, 64) (x)
x = ReLU (x)
x = Conv2d(3×3, 64, 64) (x)
x = ReLU (x)
x = Maxpool(2, 2) (x)
x = FC(2304, 1024) (x)
y = Embedding(N, 1024) (y)
y = Softmax(dim=-1) (y)
y = y * y.shape[-1]
x = x * y
out = FC(1024, 1) (x)

(f) Các mô hình đường cơ sở
Input: x
x = Conv2d(3×3, 3, 32) (x)
x = ReLU (x)
x = Conv2d(3×3, 32, 32) (x)
x = ReLU (x)
x = Maxpool(2, 2) (x)
x = Conv2d(3×3, 32, 64) (x)
x = ReLU (x)
x = Conv2d(3×3, 64, 64) (x)
x = ReLU (x)
x = Maxpool(2, 2) (x)
x = FC(2304, 1024) (x)
x = ReLU (x)
x = FC(1024, 1024) (x)
x = ReLU (x)
out = FC(1024, 10) (x)

gặp phải cho đến nay, và ngân sách bộ nhớ có sẵn k được chia đều cho tất cả các lớp gặp phải cho đến nay. Trên các tập dữ liệu split MNIST, permuted MNIST và CIFAR-10, chúng tôi sử dụng ngân sách bộ nhớ k = 1000. Trên các tập dữ liệu CIFAR-100, chúng tôi sử dụng ngân sách bộ nhớ k = 2000.

18

--- TRANG 19 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

Bảng 10: Kiến trúc mô hình được sử dụng trên tập dữ liệu CIFAR-100. Tuân theo (van de Ven et al., 2020), các lớp tích chập đã được tiền huấn luyện trên CIFAR-10 cho tất cả các mô hình. Thao tác 'BinaryMask' hoàn toàn cổng một tập con được chọn ngẫu nhiên X% của các nút, với một tập con khác nhau cho mỗi y. Siêu tham số X được thiết lập bằng cách sử dụng tìm kiếm lưới.

(a) Kiến trúc của EBM.
Input: x, y
x = Conv2d(3×3, 3, 16) (x)
x = BatchNorm (x)
x = ReLU (x)
x = Conv2d(3×3, 16, 32) (x)
x = BatchNorm (x)
x = ReLU (x)
x = Conv2d(3×3, 32, 64) (x)
x = BatchNorm (x)
x = ReLU (x)
x = Conv2d(3×3, 64, 128) (x)
x = BatchNorm (x)
x = ReLU (x)
x = Conv2d(3×3, 128, 256) (x)
x = FC(1024, 2000) (x)
x = ReLU (x)
x = BinaryMask (x, y)
x = FC(2000, 2000) (x)
x = ReLU (x)
x = BinaryMask (x, y)
out = FC(2000, 1) (x)

(b) Kiến trúc của các mô hình đường cơ sở.
Input: x
x = Conv2d(3×3, 3, 16) (x)
x = BatchNorm (x)
x = ReLU (x)
x = Conv2d(3×3, 16, 32) (x)
x = BatchNorm (x)
x = ReLU (x)
x = Conv2d(3×3, 32, 64) (x)
x = BatchNorm (x)
x = ReLU (x)
x = Conv2d(3×3, 64, 128) (x)
x = BatchNorm (x)
x = ReLU (x)
x = Conv2d(3×3, 128, 256) (x)
x = FC(1024, 2000) (x)
x = ReLU (x)
x = FC(2000, 2000) (x)
x = ReLU (x)
out = FC(2000, 100) (x)

Lấy tập dữ liệu split MNIST làm ví dụ, sau khi huấn luyện nhiệm vụ đầu tiên, chúng tôi ngẫu nhiên chọn 1000 cặp dữ liệu-nhãn từ nhiệm vụ đầu tiên và lưu chúng trong bộ đệm phát lại. Sau đó chúng tôi huấn luyện mô hình trên nhiệm vụ thứ hai. Trong mỗi batch huấn luyện, chúng tôi ngẫu nhiên lấy mẫu một tập cặp dữ liệu-nhãn từ nhiệm vụ thứ hai, và ngẫu nhiên lấy mẫu một tập cặp dữ liệu-nhãn từ bộ đệm phát lại. Chúng tôi tính toán mất mát cuối cùng bằng cách cộng mất mát của dữ liệu từ nhiệm vụ hiện tại LCD_current(θ;x,y) và mất mát của dữ liệu từ bộ đệm phát lại LCD_replay(θ;x,y) sử dụng phương trình sau:

LCD(θ;x,y) = LCD_current(θ;x,y) + LCD_replay(θ;x,y) (7)

Sau khi chúng tôi hoàn thành huấn luyện nhiệm vụ thứ hai, chúng tôi ngẫu nhiên chọn 500 cặp dữ liệu-nhãn từ bộ đệm phát lại và ngẫu nhiên lấy mẫu 500 cặp dữ liệu-nhãn từ nhiệm vụ thứ hai và cập nhật bộ đệm phát lại sử dụng các cặp dữ liệu-nhãn được lấy mẫu mới. Lưu ý chúng tôi luôn giữ số lượng cặp dữ liệu-nhãn trong bộ đệm phát lại ở 1000. Sau đó chúng tôi huấn luyện mô hình trên nhiệm vụ thứ ba. Trong mỗi batch huấn luyện, chúng tôi ngẫu nhiên lấy mẫu một tập cặp dữ liệu-nhãn từ nhiệm vụ thứ ba, và ngẫu nhiên lấy mẫu một tập cặp dữ liệu-nhãn từ bộ đệm phát lại. Chúng tôi tính toán mất mát cuối cùng sử dụng Phương trình (7). Chúng tôi sử dụng chiến lược như vậy để huấn luyện các mô hình cho đến nhiệm vụ cuối cùng.

Mô hình đường cơ sở, tức là "SBC+ER", trong Bảng 1 của bài báo chính sử dụng phát lại theo cách tương tự. Sự khác biệt duy nhất là "SBC+ER" sử dụng mất mát cross-entropy như được mô tả trong phần chính của bài báo Phần 3.1 nhưng "EBM+ER" sử dụng mục tiêu huấn luyện phân kỳ tương phản.

Chúng tôi sử dụng các chế độ huấn luyện tương tự cho EBM và SBC. Trên split MNIST, permuted MNIST và CIFAR-10, chúng tôi huấn luyện trong 2000 lần lặp mỗi nhiệm vụ. Trên CIFAR-100, chúng tôi huấn luyện trong 5000 lần lặp mỗi nhiệm vụ. Trong mỗi batch huấn luyện, chúng tôi lấy mẫu 128 cặp dữ liệu-nhãn từ nhiệm vụ hiện tại và 128 cặp dữ liệu-nhãn từ bộ đệm phát lại (bắt đầu từ nhiệm vụ thứ hai) để huấn luyện mô hình. Tất cả các thực nghiệm sử dụng bộ tối ưu Adam với tốc độ học 1e-4.

19

--- TRANG 20 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

Bảng 11: Kiến trúc mô hình được sử dụng cho phân tích khả năng mô hình. h lần lượt là 512, 1024 và 4096 cho mạng nhỏ, trung bình và lớn.

(a) Kiến trúc của EBM.
x = FC(32×32×3, h) (x)
x = ReLU (x)
y = Embedding (y)
x = x * y
x = ReLU (x)
out = FC(h, 1) (x)

(b) Kiến trúc của bộ phân loại tiêu chuẩn.
x = FC(32×32×3, h) (x)
x = ReLU (x)
x = FC(h, h) (x)
x = ReLU (x)
out = FC(h, 10) (x)

E PHÂN TÍCH BỔ SUNG

Chúng tôi hiển thị so sánh khả năng mô hình trong Phần E.1.

E.1 KHẢ NĂNG MÔ HÌNH

Một lý do được giả thuyết khác về tại sao EBM ít chịu thiệt hại hơn từ việc quên thảm khốc so với các bộ phân loại tiêu chuẩn là khả năng hiệu quả lớn hơn tiềm năng của chúng. Do đó chúng tôi kiểm tra khả năng mô hình của bộ phân loại tiêu chuẩn và EBM trên cả hình ảnh được tạo ra và hình ảnh tự nhiên.

Khả năng mô hình trên hình ảnh được tạo ra. Chúng tôi tạo ra một tập dữ liệu ngẫu nhiên hóa lớn của các hình ảnh 32×32 với mỗi giá trị pixel được lấy mẫu đồng đều từ -1 đến 1. Mỗi hình ảnh sau đó được gán một nhãn lớp ngẫu nhiên giữa 0 và 10. Chúng tôi đo khả năng mô hình bằng cách đánh giá mức độ mà mô hình có thể khớp với tập dữ liệu như vậy. Đối với cả bộ phân loại tiêu chuẩn và EBM, chúng tôi đánh giá ba kích thước khác nhau của mô hình (nhỏ, trung bình và lớn). Để so sánh công bằng, chúng tôi kiểm soát EBM và bộ phân loại có số lượng tham số tương tự. EBM và SBC nhỏ có 2,348,545 và 2,349,032 tham số tương ứng. Các mô hình trung bình có 5,221,377 (EBM) và 5,221,352 (SBC) tham số trong khi các mô hình lớn có 33,468,417 (EBM) và 33,465,320 (SBC) tham số. Kiến trúc mô hình của EBM và bộ phân loại được hiển thị trong Bảng 11.

Độ chính xác huấn luyện kết quả được hiển thị trong Hình 6 với số lượng dữ liệu từ một đến năm triệu. Cho bất kỳ số lượng điểm dữ liệu nào, EBM đạt được độ chính xác cao hơn bộ phân loại, chứng minh rằng EBM có khả năng lớn hơn để ghi nhớ dữ liệu với số lượng tham số tương tự. Khoảng cách giữa EBM và SBC tăng lên khi các mô hình trở nên lớn hơn. Khả năng lớn hơn của EBM có thể cho phép nó ghi nhớ nhiều dữ liệu hơn và giảm thiểu vấn đề quên.

Khả năng mô hình trên hình ảnh tự nhiên. Chúng tôi cũng so sánh các bộ phân loại và EBM trên hình ảnh tự nhiên từ CIFAR-10. Mỗi hình ảnh được gán một nhãn lớp ngẫu nhiên giữa 0 và 10. Chúng tôi sử dụng kiến trúc mạng tương tự như trong Bảng 11, nhưng với kích thước đơn vị ẩn h = 256. Vì chỉ có 50,000 hình ảnh trên CIFAR-10, chúng tôi sử dụng bộ phân loại và EBM nhỏ và huấn luyện chúng trên toàn bộ tập dữ liệu. Sau khi huấn luyện 100000 lần lặp, EBM đạt được độ chính xác dự đoán top-1 là 82.81%, trong khi bộ phân loại là 42.19%. Chúng tôi đạt được kết luận tương tự trên hình ảnh tự nhiên rằng EBM có khả năng lớn hơn để ghi nhớ dữ liệu với số lượng tham số tương tự.

F MỤC TIÊU HUẤN LUYỆN EBM THAY THẾ

F.1 CÁC MÔ HÌNH DỰA TRÊN NĂNG LƯỢNG CHO PHÂN LOẠI

Trong phần chính của bài báo Phần 4.3, chúng tôi giới thiệu một mục tiêu huấn luyện EBM thay thế. Ở đây chúng tôi cung cấp thêm chi tiết về mục tiêu huấn luyện này. Chúng tôi đề xuất sử dụng phân phối Boltzmann để định nghĩa khả năng chung của hình ảnh x và nhãn y:

p(x,y) = exp(-E(x,y)) / Z(θ),
Z(θ) = Σ(x'∈X,y'∈Y) exp(-E(x',y')) (8)

trong đó E(x,y) : (RD,N)→R là hàm năng lượng ánh xạ một cặp đầu vào-nhãn (x,y) thành một giá trị năng lượng vô hướng, và Z(θ) là hàm phân hoạch để chuẩn hóa.

20

--- TRANG 21 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0
Điểm Dữ liệu Huấn luyện 1e60.30.40.50.60.70.80.91.0Độ chính xác Độ chính xác Ghi nhớ so với Điểm Dữ liệu
Small SBC
Medium SBC
Large SBC
Small EBM
Medium EBM
Large EBM

Hình 6: Khả năng mô hình của bộ phân loại tiêu chuẩn (SBC) và EBM sử dụng các kích thước mô hình khác nhau.

Huấn luyện. Chúng ta muốn phân phối được định nghĩa bởi E mô hình hóa phân phối dữ liệu chung pD, điều mà chúng ta thực hiện bằng cách tối thiểu hóa khả năng log âm của dữ liệu

LML(θ) = E(x,y)~pD[-log p(x,y)] (9)

với dạng mở rộng:

LML(θ) = E(x,y)~pD[E(x,y) + log(Σ(x'∈X,y'∈Y) e^(-E(x',y')))] (10)

Phương trình (10) tối thiểu hóa năng lượng của x tại nhãn sự thật cơ bản y và tối thiểu hóa hàm phân hoạch tổng thể bằng cách tăng năng lượng của bất kỳ cặp x' và y' được ghép ngẫu nhiên nào khác.

Suy luận. Cho một đầu vào x, nhãn lớp được dự đoán bởi EBM của chúng tôi là lớp có năng lượng nhỏ nhất tại x:

ŷ = arg min(y'∈Y) E(x,y') (11)

F.2 CÁC MÔ HÌNH DỰA TRÊN NĂNG LƯỢNG CHO HỌC LIÊN TỤC

Như được mô tả trong phần chính của bài báo Phần 4.3, việc trực tiếp tối đa hóa năng lượng trên tất cả các nhãn của một điểm dữ liệu x làm nảy sinh cùng vấn đề như các mô hình bộ phân loại dựa trên softmax rằng các lớp cũ bị ức chế khi huấn luyện một mô hình trên các lớp mới và do đó gây ra việc quên thảm khốc. Lấy cảm hứng từ (Hinton, 2002), chúng tôi thấy rằng xấp xỉ phân kỳ tương phản của Phương trình (10) có thể giảm thiểu vấn đề này và dẫn đến một phương trình đơn giản hơn. Chúng tôi xấp xỉ Phương trình (10) bằng cách lấy mẫu một cặp ngẫu nhiên của hình ảnh x' và nhãn y' từ batch huấn luyện hiện tại để xấp xỉ hàm phân hoạch. Mục tiêu huấn luyện của chúng tôi được cho bởi:

LCD(θ;x,y) = E(x,y)~pD[E(x,y) - E(x',y')] (12)

trong đó y là nhãn sự thật cơ bản của dữ liệu x.

Mục tiêu huấn luyện này gợi nhớ đến mục tiêu huấn luyện phân kỳ tương phản được sử dụng để huấn luyện EBM trong Phương trình (5) của bài báo chính. Sự khác biệt chính là chúng tôi sử dụng cả hình ảnh và nhãn từ batch hiện tại như các mẫu tương phản của chúng tôi thay vì chỉ nhãn được sử dụng trong bài báo chính. Chúng tôi chỉ ra trong các thực nghiệm rằng việc sử dụng mục tiêu huấn luyện tương phản được đề xuất trong Phương trình (12) có thể cải thiện thêm hiệu suất học liên tục.

F.3 SUY LUẬN

Chúng tôi sử dụng các phương pháp suy luận tương tự như được mô tả trong bài báo chính để thực hiện đánh giá Class-IL trên các tập dữ liệu học liên tục. Mô hình dự đoán nhãn lớp ŷ của một điểm dữ liệu x từ tất cả nhãn lớp Y, trong đó x là một điểm dữ liệu với một nhãn rời rạc liên quan y∈Y. Ước lượng MAP là

ŷ = arg min(y'∈Y) E(x,y'), y'∈Y (13)

trong đó E là hàm năng lượng với các tham số sau khi huấn luyện trên tất cả dữ liệu huấn luyện.

21

--- TRANG 22 ---
Xuất bản tại Hội nghị lần thứ 1 về Tác nhân Học liên tục suốt đời, 2022

Bảng 12: Đánh giá học gia tăng lớp trên cài đặt nhận biết ranh giới trên các tập dữ liệu split MNIST và permuted. Mỗi thực nghiệm được thực hiện ít nhất 10 lần với các hạt giống ngẫu nhiên khác nhau, kết quả được báo cáo là trung bình ± SEM trên những lần chạy này. Lưu ý so sánh của chúng tôi được hạn chế cho các phương pháp không phát lại dữ liệu được lưu trữ hoặc được tạo ra.

Phương pháp          splitMNIST        permMNIST
SBC                 19.90±0.02        17.26±0.19
EBM                 53.12±0.04        87.58±0.50
EBM Alt CD          60.14±1.66        89.15±0.89
EWC (Kirkpatrick et al., 2017)  20.01±0.06        25.04±0.50
Online EWC (Schwarz et al., 2018)  19.96±0.07        33.88±0.49
SI (Zenke et al., 2017)  19.99±0.06        29.31±0.62
LwF (Li & Hoiem, 2017)  23.85±0.44        22.64±0.23
MAS (Aljundi et al., 2019b)  19.50±0.30        -
BGD (Zeno et al., 2018)  19.64±0.03        84.78±1.30

F.4 SO SÁNH VỚI CÁC PHƯƠNG PHÁP HIỆN CÓ

Chúng tôi tuân theo các thực nghiệm được thực hiện trong bài báo chính và đánh giá Class-IL trên các tập dữ liệu split MNIST (Zenke et al., 2017) và permuted MNIST (Kirkpatrick et al., 2017) trên cài đặt Nhận biết Ranh giới.

Chúng tôi so sánh EBM sử dụng các mục tiêu huấn luyện khác nhau và các phương pháp đường cơ sở trong Bảng 12. Tất cả các đường cơ sở và EBM sử dụng kiến trúc mô hình tương tự với số lượng tham số mô hình tương tự để so sánh công bằng. "EBM" có nghĩa là kết quả của mục tiêu huấn luyện được sử dụng trong Phương trình (5) của bài báo chính. "EBM Alt CD" đại diện cho mục tiêu huấn luyện thay thế được mô tả trong Phương trình (12). EBM có sự cải thiện đáng kể so với các phương pháp đường cơ sở trên tất cả các tập dữ liệu, cho thấy rằng EBM quên ít hơn khi cập nhật mô hình cho các nhiệm vụ mới. "EBM Alt CD" có thể cải thiện thêm hiệu suất học liên tục.

22

SparCL: Học Liên Tục Thưa Thớt trên Thiết Bị Edge
Zifeng Wang1;y, Zheng Zhan1;y, Yifan Gong1, Geng Yuan1, Wei Niu2, Tong Jian1,
Bin Ren2, Stratis Ioannidis1, Yanzhi Wang1, Jennifer Dy1
1Đại học Northeastern, 2Đại học William và Mary
{zhan.zhe, gong.yifa, geng.yuan, yanz.wang}@northeastern.edu ,
{zifengwang, jian, ioannidis, jdy}@ece.neu.edu ,
wniu@email.wm.edu, bren@cs.wm.edu

Tóm tắt
Các nghiên cứu hiện tại về học liên tục (CL) tập trung vào việc giảm thiểu quên thảm khốc, tức là sự suy giảm hiệu suất mô hình trên các tác vụ trước khi học một tác vụ mới. Tuy nhiên, hiệu quả huấn luyện của hệ thống CL chưa được nghiên cứu đầy đủ, điều này hạn chế việc ứng dụng thực tế của các hệ thống CL trong các tình huống hạn chế tài nguyên. Trong nghiên cứu này, chúng tôi đề xuất một khung mới gọi là Học Liên Tục Thưa Thớt (SparCL), đây là nghiên cứu đầu tiên tận dụng tính thưa thớt để cho phép học liên tục hiệu quả về chi phí trên các thiết bị edge. SparCL đạt được cả tăng tốc huấn luyện và bảo toàn độ chính xác thông qua sự kết hợp của ba khía cạnh: thưa thớt trọng số, hiệu quả dữ liệu, và thưa thớt gradient. Cụ thể, chúng tôi đề xuất che mặt nạ động nhận biết tác vụ (TDM) để học một mạng thưa thớt trong suốt toàn bộ quá trình CL, loại bỏ dữ liệu động (DDR) để loại bỏ dữ liệu huấn luyện ít thông tin hơn, và che mặt nạ gradient động (DGM) để làm thưa thớt các cập nhật gradient. Mỗi thành phần không chỉ cải thiện hiệu quả mà còn giảm thiểu thêm quên thảm khốc. SparCL liên tục cải thiện hiệu quả huấn luyện của các phương pháp CL hiện đại (SOTA) hiện có tối đa 23× ít FLOPs huấn luyện hơn, và đáng ngạc nhiên là cải thiện thêm độ chính xác SOTA tối đa 1.7%. SparCL cũng vượt trội hơn các baseline cạnh tranh thu được từ việc điều chỉnh các phương pháp huấn luyện thưa thớt SOTA cho cài đặt CL về cả hiệu quả và độ chính xác. Chúng tôi cũng đánh giá tính hiệu quả của SparCL trên điện thoại di động thực tế, cho thấy thêm tiềm năng thực tiễn của phương pháp. Mã nguồn sẽ được phát hành.

1 Giới thiệu
Mục tiêu của Học Liên Tục (CL) là cho phép một hệ thống thông minh tích lũy kiến thức từ một chuỗi các tác vụ, sao cho nó thể hiện hiệu suất thỏa mãn trên cả tác vụ cũ và mới (31). Các phương pháp gần đây chủ yếu tập trung vào giải quyết vấn đề quên thảm khốc (42) – mô hình học có xu hướng bị suy giảm hiệu suất trên các tác vụ đã thấy trước đó. Tuy nhiên, trong thế giới thực, khi các ứng dụng CL được triển khai trên các nền tảng hạn chế tài nguyên (47) như các thiết bị edge, hiệu quả học, về cả tốc độ huấn luyện và dung lượng bộ nhớ, cũng là các chỉ số quan trọng, nhưng hiếm khi được khám phá trong các nghiên cứu CL trước đây.

Các phương pháp CL hiện tại có thể được phân loại thành dựa trên chính quy hóa (2;31;36;67), dựa trên rehearsal (8;11;49;60), và dựa trên kiến trúc (30;41;51;57;58;69). Cả phương pháp dựa trên chính quy hóa và rehearsal đều trực tiếp huấn luyện một mô hình dày đặc, thậm chí có thể được tham số hóa quá mức cho sự hợp nhất của tất cả các tác vụ (18;38); Mặc dù một số phương pháp dựa trên kiến trúc (50;56;63) bắt đầu với một mạng con thưa thớt từ mô hình dày đặc, chúng vẫn tăng kích thước mô hình dần dần để học các tác vụ mới nổi. Các phương pháp nói trên, mặc dù nỗ lực để đạt hiệu suất tốt hơn với ít quên hơn, vẫn gây ra chi phí bộ nhớ và tính toán đáng kể trong suốt toàn bộ quá trình CL.

Gần đây, một dòng nghiên cứu khác, huấn luyện thưa thớt (4; 19; 34) đã nổi lên như một xu hướng huấn luyện mới để đạt được tăng tốc huấn luyện, đón nhận mô hình huấn luyện-trên-edge đầy hứa hẹn. Với huấn luyện thưa thớt, mỗi lần lặp mất ít thời gian hơn với việc giảm tính toán đạt được bằng tính thưa thớt, dưới cài đặt học i.i.d. truyền thống. Được truyền cảm hứng từ các phương pháp huấn luyện thưa thớt này, chúng tôi tự nhiên nghĩ đến việc giới thiệu huấn luyện thưa thớt vào lĩnh vực CL. Một ý tưởng đơn giản là kết hợp trực tiếp các phương pháp huấn luyện thưa thớt hiện tại, như SNIP (34), RigL (19), với một bộ đệm rehearsal dưới cài đặt CL. Tuy nhiên, các phương pháp này không xem xét các thách thức chính trong CL để giảm thiểu quên thảm khốc, ví dụ, xử lý đúng cách chuyển đổi giữa các tác vụ. Kết quả là, các phương pháp huấn luyện thưa thớt này, mặc dù tăng cường hiệu quả huấn luyện, gây ra sự sụt giảm độ chính xác đáng kể (xem Phần 5.2).

Do đó, chúng tôi muốn khám phá một chiến lược tổng quát, trực giao với các phương pháp CL hiện tại, không chỉ tận dụng ý tưởng huấn luyện thưa thớt cho hiệu quả mà còn giải quyết các thách thức chính trong CL để bảo toàn (hoặc thậm chí cải thiện) độ chính xác.

Trong nghiên cứu này, chúng tôi đề xuất Học Liên Tục Thưa Thớt (SparCL), một khung tổng quát cho học liên tục hiệu quả về chi phí, nhằm mục đích cho phép CL thực tế trên các thiết bị edge. Như được thể hiện trong Hình 1 (trái), SparCL đạt được cả tăng tốc học và bảo toàn độ chính xác thông qua sự kết hợp của ba khía cạnh: thưa thớt trọng số, hiệu quả dữ liệu, và thưa thớt gradient. Cụ thể, để duy trì một mạng thưa thớt động nhỏ trong suốt toàn bộ quá trình CL, chúng tôi phát triển một chiến lược che mặt nạ động nhận biết tác vụ (TDM) mới để chỉ giữ lại các trọng số quan trọng cho cả tác vụ hiện tại và quá khứ, với xem xét đặc biệt trong quá trình chuyển đổi tác vụ. Hơn nữa, chúng tôi đề xuất một sơ đồ loại bỏ dữ liệu động (DDR), dần dần loại bỏ các ví dụ "dễ học" từ các lần lặp huấn luyện, điều này tăng tốc thêm quá trình huấn luyện và cũng cải thiện độ chính xác của CL bằng cách cân bằng dữ liệu hiện tại và quá khứ và giữ các mẫu thông tin hơn trong bộ đệm. Cuối cùng, chúng tôi cung cấp một chiến lược che mặt nạ gradient động (DGM) bổ sung để tận dụng tính thưa thớt gradient cho hiệu quả tốt hơn và bảo toàn kiến thức của các tác vụ đã học, sao cho chỉ một tập con các trọng số thưa thớt được cập nhật.

Hình 1 (phải) chứng minh rằng SparCL thành công bảo toàn độ chính xác và cải thiện đáng kể hiệu quả so với DER++ (8), một trong những phương pháp CL SOTA, dưới các tỷ lệ thưa thớt khác nhau.

SparCL đơn giản về khái niệm, tương thích với nhiều phương pháp CL dựa trên rehearsal hiện có, và hiệu quả dưới các tình huống thực tế. Chúng tôi tiến hành các thí nghiệm toàn diện trên nhiều benchmark CL để đánh giá tính hiệu quả của phương pháp. Chúng tôi cho thấy SparCL hoạt động hợp tác với các phương pháp CL hiện có, tăng tốc rất nhiều quá trình học dưới các tỷ lệ thưa thớt khác nhau, và thậm chí đôi khi cải thiện độ chính xác hiện đại. Chúng tôi cũng thiết lập các baseline cạnh tranh bằng cách kết hợp các phương pháp huấn luyện thưa thớt đại diện với các phương pháp CL dựa trên rehearsal tiên tiến. SparCL một lần nữa vượt trội hơn các baseline này về cả hiệu quả và độ chính xác. Quan trọng nhất, chúng tôi đánh giá khung SparCL trên các thiết bị edge thực để chứng minh tiềm năng thực tiễn của phương pháp. Chúng tôi không biết về bất kỳ nghiên cứu CL nào trước đây đã khám phá lĩnh vực này và xem xét các ràng buộc của tài nguyên hạn chế trong quá trình huấn luyện.

Tóm lại, nghiên cứu của chúng tôi có những đóng góp sau:
• Chúng tôi đề xuất Học Liên Tục Thưa Thớt (SparCL), một khung tổng quát cho học liên tục hiệu quả về chi phí, đạt được tăng tốc học thông qua sự kết hợp của thưa thớt trọng số, hiệu quả dữ liệu, và thưa thớt gradient. Theo hiểu biết của chúng tôi, nghiên cứu của chúng tôi là đầu tiên giới thiệu ý tưởng huấn luyện thưa thớt để cho phép CL hiệu quả trên các thiết bị edge.

• SparCL cho thấy hiệu suất vượt trội so với cả các phương pháp CL thông thường và các phương pháp huấn luyện thưa thớt được điều chỉnh cho CL trên tất cả các tập dữ liệu benchmark, dẫn đến tối đa 23× ít FLOPs huấn luyện hơn và đáng ngạc nhiên là cải thiện 1.7% so với độ chính xác SOTA.

• Chúng tôi đánh giá SparCL trên một thiết bị edge di động thực, chứng minh tiềm năng thực tiễn của phương pháp và cũng khuyến khích nghiên cứu tương lai về CL trên-edge. Kết quả cho thấy khung của chúng tôi có thể đạt được tối đa 3.1× tăng tốc huấn luyện.

2 Nghiên cứu liên quan

2.1 Học Liên Tục
Trọng tâm chính trong học liên tục (CL) là giảm thiểu quên thảm khốc. Các phương pháp hiện tại có thể được phân loại thành ba loại chính. Các phương pháp dựa trên chính quy hóa (2;31;36;67) hạn chế cập nhật của các tham số quan trọng cho các tác vụ trước bằng cách thêm các thuật ngữ chính quy hóa tương ứng. Mặc dù các phương pháp này giảm quên thảm khốc ở một mức độ nhất định, hiệu suất của chúng suy giảm dưới các cài đặt thách thức (39), và trên các benchmark phức tạp hơn (49;60). Các phương pháp dựa trên rehearsal (12; 13; 24) lưu các ví dụ từ các tác vụ trước vào một bộ đệm kích thước nhỏ để huấn luyện mô hình cùng với tác vụ hiện tại. Mặc dù đơn giản về khái niệm, ý tưởng rehearsal rất hiệu quả trong thực tế và đã được áp dụng bởi nhiều phương pháp hiện đại (8;10;48). Các phương pháp dựa trên kiến trúc (41;50;56;58;62) cô lập các tham số mô hình hiện có hoặc gán các tham số bổ sung cho mỗi tác vụ để giảm can thiệp giữa các tác vụ. Như đã đề cập trong Phần 1, hầu hết các phương pháp này sử dụng một mô hình dày đặc mà không xem xét hiệu quả và dung lượng bộ nhớ, do đó không áp dụng được cho các cài đặt hạn chế tài nguyên. Nghiên cứu của chúng tôi, trực giao với các phương pháp này, phục vụ như một khung tổng quát để làm cho các phương pháp hiện có này hiệu quả và cho phép triển khai rộng rãi hơn, ví dụ, CL trên các thiết bị edge.

Một số ít nghiên cứu khám phá tính thưa thớt trong CL, tuy nhiên, cho các mục đích khác nhau. Một số phương pháp (40;41;52;56) kết hợp ý tưởng cắt tỉa trọng số (23) để phân bổ một mạng con thưa thớt cho mỗi tác vụ nhằm giảm can thiệp giữa các tác vụ. Tuy nhiên, các phương pháp này vẫn giảm tính thưa thớt mô hình đầy đủ dần dần cho mỗi tác vụ và cuối cùng kết thúc với một mô hình dày đặc hơn nhiều. Ngược lại, SparCL duy trì một mạng thưa thớt trong suốt toàn bộ quá trình CL, giới thiệu lợi ích hiệu quả và bộ nhớ lớn cả trong quá trình huấn luyện và tại mô hình đầu ra. Một nghiên cứu gần đây (14) nhằm mục đích khám phá các vé số may mắn (20) dưới CL, nhưng vẫn không giải quyết hiệu quả. Tuy nhiên, sự tồn tại của các vé số may mắn trong CL phục vụ như một lý do mạnh mẽ cho hiệu suất xuất sắc của SparCL.

2.2 Huấn Luyện Thưa Thớt
Có hai cách tiếp cận chính cho huấn luyện thưa thớt: huấn luyện thưa thớt mặt nạ cố định và huấn luyện thưa thớt động. Các phương pháp huấn luyện thưa thớt mặt nạ cố định (34;53;55;59) đầu tiên áp dụng cắt tỉa, sau đó thực hiện huấn luyện truyền thống trên mô hình thưa thớt với mặt nạ cố định thu được. Cấu trúc được định trước hạn chế hiệu suất độ chính xác, và giai đoạn đầu vẫn gây ra tiêu thụ tính toán và bộ nhớ khổng lồ. Để khắc phục những nhược điểm này, các phương pháp mặt nạ động (4;16;19;44;45) điều chỉnh cấu trúc thưa thớt trong quá trình huấn luyện trong khi duy trì dung lượng bộ nhớ thấp. Các phương pháp này bắt đầu với cấu trúc mô hình thưa thớt từ một mô hình dày đặc chưa được huấn luyện, sau đó kết hợp khám phá cấu trúc thưa thớt tại tỷ lệ thưa thớt đã cho với huấn luyện mô hình thưa thớt. Nghiên cứu gần đây (66) tiếp tục xem xét kết hợp hiệu quả dữ liệu vào huấn luyện thưa thớt để tăng tốc huấn luyện tốt hơn. Tuy nhiên, tất cả các nghiên cứu huấn luyện thưa thớt trước đây đều tập trung vào cài đặt huấn luyện truyền thống, trong khi CL là một tình huống phức tạp và khó khăn hơn với các đặc điểm vốn có không được khám phá bởi các nghiên cứu này. Trái ngược với các phương pháp huấn luyện thưa thớt trước đây, nghiên cứu của chúng tôi khám phá một mô hình học mới giới thiệu huấn luyện thưa thớt vào CL cho hiệu quả và cũng giải quyết các thách thức chính trong CL, giảm thiểu quên thảm khốc.

3 Thiết lập Vấn đề Học Liên Tục
Trong CL có giám sát, một mô hình f học từ một chuỗi các tác vụ D = {D1,...,DT}, trong đó mỗi tác vụ Dt = {(xt,i, yt,i)}nt_i=1 bao gồm các cặp đầu vào-nhãn, và mỗi tác vụ có một tập hợp các lớp riêng biệt. Các tác vụ đến tuần tự, và mô hình phải thích ứng với chúng. Tại bước thứ t, mô hình có quyền truy cập vào dữ liệu từ tác vụ thứ t. Tuy nhiên, một bộ đệm rehearsal M có kích thước cố định nhỏ được phép lưu dữ liệu từ các tác vụ trước. Tại thời điểm kiểm tra, cài đặt dễ nhất là giả định danh tính tác vụ được biết cho mỗi ví dụ kiểm tra đến, được gọi là học tăng dần tác vụ (Task-IL). Nếu giả định này không đúng, chúng ta có cài đặt học tăng dần lớp (Class-IL) khó khăn hơn. Trong nghiên cứu này, chúng tôi chủ yếu tập trung vào cài đặt Class-IL thách thức hơn, và chỉ báo cáo hiệu suất Task-IL để tham khảo.

Mục tiêu của CL thông thường là huấn luyện một mô hình tuần tự hoạt động tốt trên tất cả các tác vụ tại thời điểm kiểm tra. Chỉ số đánh giá chính là độ chính xác kiểm tra trung bình trên tất cả các tác vụ. Trong các tình huống thực tế hạn chế tài nguyên, chúng ta nên xem xét thêm hiệu quả huấn luyện của mô hình. Do đó, chúng tôi đo lường hiệu suất của mô hình toàn diện hơn bằng cách bao gồm FLOPs huấn luyện và dung lượng bộ nhớ.

4 Học Liên Tục Thưa Thớt (SparCL)
Phương pháp của chúng tôi, Học Liên Tục Thưa Thớt, là một khung thống nhất bao gồm ba thành phần bổ sung: che mặt nạ động nhận biết tác vụ cho thưa thớt trọng số, loại bỏ dữ liệu động cho hiệu quả dữ liệu, và che mặt nạ gradient động cho thưa thớt gradient. Toàn bộ khung được thể hiện trong Hình 2. Chúng tôi sẽ minh họa chi tiết từng thành phần trong phần này.

4.1 Che Mặt Nạ Động Nhận Biết Tác Vụ
Để cho phép CL hiệu quả về chi phí trong các tình huống hạn chế tài nguyên, SparCL được thiết kế để duy trì một cấu trúc động khi học một chuỗi các tác vụ, sao cho nó không chỉ đạt được hiệu quả cao mà còn thích ứng thông minh với luồng dữ liệu để có hiệu suất tốt hơn. Cụ thể, chúng tôi đề xuất một chiến lược có tên che mặt nạ động nhận biết tác vụ (TDM), động loại bỏ các trọng số ít quan trọng hơn và phát triển lại các trọng số chưa sử dụng cho sức mạnh đại diện mạnh hơn định kỳ bằng cách duy trì một mặt nạ trọng số nhị phân duy nhất trong suốt quá trình CL. Khác với công việc huấn luyện thưa thớt điển hình, chỉ tận dụng độ lớn trọng số (44) hoặc gradient đối với dữ liệu từ một tác vụ huấn luyện duy nhất (19;66), TDM cũng xem xét tầm quan trọng của trọng số đối với dữ liệu được lưu trong bộ đệm rehearsal, cũng như việc chuyển đổi giữa các tác vụ CL.

Cụ thể, chiến lược TDM bắt đầu từ một mặt nạ nhị phân được khởi tạo ngẫu nhiên M = M0, với một ràng buộc thưa thớt đã cho ||M||0/||θ||0 = 1-s, trong đó s ∈ [0,1] là tỷ lệ thưa thớt. Hơn nữa, nó thực hiện các điều chỉnh nội-tác vụ và liên-tác vụ khác nhau để giữ một tập hợp trọng số thưa thớt động dựa trên tầm quan trọng trọng số liên tục (CWI). Chúng tôi tóm tắt quá trình che mặt nạ động nhận biết tác vụ trong Thuật toán 1 và giải thích chi tiết các thành phần chính bên dưới.

Tầm quan trọng trọng số liên tục (CWI). Đối với một mô hình f được tham số hóa bởi θ, CWI của trọng số w được định nghĩa như sau:
CWI(w) = |w| + α|∂L̃(Dt;θ)/∂w| + β|∂L(M;θ)/∂w|, (1)
trong đó Dt biểu thị dữ liệu huấn luyện từ tác vụ thứ t, M là bộ đệm rehearsal hiện tại, và α, β là các hệ số để kiểm soát ảnh hưởng của dữ liệu hiện tại và được đệm tương ứng. Hơn nữa, L đại diện cho mất mát entropy chéo cho phân loại, trong khi L̃ là phiên bản đầu đơn (1) của mất mát entropy chéo, chỉ xem xét các lớp từ tác vụ hiện tại bằng cách che các logit của các lớp khác.

Trực quan, CWI đảm bảo chúng ta giữ (1) trọng số có độ lớn lớn hơn cho tính ổn định đầu ra, (2) trọng số quan trọng cho tác vụ hiện tại cho khả năng học, và (3) trọng số quan trọng cho dữ liệu quá khứ để giảm thiểu quên thảm khốc. Hơn nữa, được truyền cảm hứng từ thiên lệch phân loại trong CL (1), chúng tôi sử dụng mất mát entropy chéo đầu đơn khi tính điểm tầm quan trọng đối với tác vụ hiện tại để làm cho ước lượng tầm quan trọng chính xác hơn.

Thuật toán 1: Che Mặt Nạ Động Nhận Biết Tác Vụ (TDM)
Đầu vào: Trọng số mô hình θ, số tác vụ T, epoch huấn luyện của tác vụ thứ t Kt, mặt nạ thưa thớt nhị phân M, tỷ lệ thưa thớt s, tỷ lệ điều chỉnh nội-tác vụ pintra, tỷ lệ điều chỉnh liên-tác vụ pinter, khoảng cập nhật k
Khởi tạo: θ, M, s.t. ||M||0/||θ||0 = 1-s
for t = 1,...,T do
    for e = 1,...,KT do
        if t > 1 then
            /* Điều chỉnh liên-tác vụ */
            Mở rộng M bằng cách thêm ngẫu nhiên các trọng số chưa sử dụng,
            s.t. ||M||0/||θ||0 = 1-(s-pinter)
            if e = k then
                Thu hẹp M bằng cách loại bỏ các trọng số ít quan trọng nhất theo phương trình 1,
                s.t. ||M||0/||θ||0 = 1-s
            end
        end
        if e mod k = 0 then
            /* Điều chỉnh nội-tác vụ */
            Thu hẹp M bằng cách loại bỏ các trọng số ít quan trọng nhất theo phương trình 1,
            s.t. ||M||0/||θ||0 = 1-(s+pintra)
            Mở rộng M bằng cách thêm ngẫu nhiên các trọng số chưa sử dụng,
            s.t. ||M||0/||θ||0 = 1-s
        end
        Cập nhật θ⊙M qua lan truyền ngược
    end
end

Điều chỉnh nội-tác vụ. Khi huấn luyện tác vụ thứ t, một giả định tự nhiên là phân phối dữ liệu nhất quán bên trong tác vụ, do đó chúng tôi muốn cập nhật mô hình thưa thớt theo cách tương đối ổn định trong khi vẫn giữ tính linh hoạt. Do đó, trong Thuật toán 1, chúng tôi chọn cập nhật mặt nạ thưa thớt M theo cách thu hẹp-và-mở rộng mỗi k epoch. Chúng tôi đầu tiên loại bỏ pintra của các trọng số có CWI thấp nhất để giữ lại kiến thức đã học cho đến nay. Sau đó chúng tôi ngẫu nhiên chọn các trọng số chưa sử dụng để khôi phục khả năng học cho mô hình và giữ tỷ lệ thưa thớt s không thay đổi.

Điều chỉnh liên-tác vụ. Khi các tác vụ chuyển đổi, ngược lại, chúng tôi giả định phân phối dữ liệu thay đổi ngay lập tức. Lý tưởng, chúng tôi muốn mô hình giữ kiến thức đã học từ các tác vụ cũ càng nhiều càng tốt, và có đủ khả năng học để chứa tác vụ mới. Do đó, thay vì chiến lược thu hẹp-và-mở rộng cho điều chỉnh nội-tác vụ, chúng tôi theo sơ đồ mở rộng-và-thu hẹp. Cụ thể, tại đầu tác vụ thứ (t+1), chúng tôi mở rộng mô hình thưa thớt bằng cách ngẫu nhiên thêm một tỷ lệ pinter các trọng số chưa sử dụng. Trực quan, khả năng học bổ sung tạo điều kiện cho việc áp dụng nhanh kiến thức mới và giảm can thiệp với kiến thức đã học. Chúng tôi cho phép mô hình của chúng tôi có tính thưa thớt nhỏ hơn (tức là khả năng học lớn hơn) tạm thời cho k epoch đầu như một giai đoạn khởi động, và sau đó loại bỏ các trọng số pinter có CWI thấp nhất, theo cùng quy trình trong trường hợp nội-tác vụ, để thỏa mãn ràng buộc thưa thớt.

4.2 Loại Bỏ Dữ Liệu Động
Ngoài tính thưa thớt trọng số, việc giảm lượng dữ liệu huấn luyện có thể được dịch trực tiếp thành tiết kiệm thời gian huấn luyện mà không cần bất kỳ yêu cầu nào về hỗ trợ phần cứng. Do đó, chúng tôi cũng muốn khám phá hiệu quả dữ liệu để giảm khối lượng công việc huấn luyện. Một số nghiên cứu CL trước đây chọn các ví dụ thông tin để xây dựng bộ đệm rehearsal (3;6;64). Tuy nhiên, mục đích chính của chúng không phải là tăng tốc huấn luyện, do đó chúng hoặc gây ra chi phí tính toán quá mức hoặc xem xét các cài đặt vấn đề khác nhau. Bằng cách xem xét các tính năng của CL, chúng tôi trình bày một chiến lược đơn giản nhưng hiệu quả, loại bỏ dữ liệu động (DDR), để giảm dữ liệu huấn luyện để tăng tốc thêm.

Chúng tôi đo lường tầm quan trọng của mỗi ví dụ huấn luyện bằng sự xuất hiện của phân loại sai (54;66) trong CL. Trong TDM, cấu trúc thưa thớt của mô hình cập nhật định kỳ mỗi k epoch, vì vậy chúng tôi căn chỉnh quá trình loại bỏ dữ liệu với việc cập nhật mặt nạ trọng số để có hiệu quả và ổn định huấn luyện hơn. Trong Phần 4.1, chúng tôi đã phân chia quá trình huấn luyện cho tác vụ thứ t thành Nt = Kt/k giai đoạn dựa trên cập nhật mặt nạ động. Do đó, chúng tôi dần dần loại bỏ dữ liệu huấn luyện ở cuối giai đoạn thứ i, dựa trên chính sách sau: 1) Tính tổng số phân loại sai fi(xj) cho mỗi ví dụ huấn luyện trong giai đoạn thứ i. 2) Loại bỏ một tỷ lệ εi các mẫu huấn luyện có ít số phân loại sai nhất. Mặc dù mục đích chính của chúng tôi là giữ các ví dụ "khó hơn" để học để củng cố mô hình thưa thớt, chúng ta có thể nhận được lợi ích thêm cho kết quả CL tốt hơn. Đầu tiên, việc loại bỏ các ví dụ "dễ hơn" tăng xác suất các ví dụ "khó hơn" được lưu vào bộ đệm rehearsal, cho chiến lược chung, ví dụ lấy mẫu hồ chứa (13), để đệm các ví dụ. Do đó, chúng tôi xây dựng một bộ đệm thông tin hơn theo cách ngầm mà không cần tính toán nặng. Hơn nữa, vì kích thước bộ đệm nhỏ hơn nhiều so với kích thước tập huấn luyện của mỗi tác vụ, dữ liệu từ bộ đệm và tác vụ mới rất mất cân bằng, loại bỏ dữ liệu động cũng giảm nhẹ vấn đề mất cân bằng dữ liệu.

Chính thức, chúng tôi đặt tỷ lệ loại bỏ dữ liệu cho mỗi tác vụ là ε ∈ [0,1], và một giai đoạn cutoff, sao cho:
Σ(i=1 to cutoff) εi = ε; Σ(i=cutoff+1 to Nk) εi = 0 (2)

Giai đoạn cutoff kiểm soát sự đánh đổi giữa hiệu quả và độ chính xác: Khi chúng ta đặt giai đoạn cutoff sớm hơn, chúng ta giảm thời gian huấn luyện cho tất cả các giai đoạn tiếp theo; tuy nhiên, khi giai đoạn cutoff được đặt quá sớm, mô hình có thể không phù hợp với dữ liệu huấn luyện bị loại bỏ. Lưu ý rằng khi chúng ta đặt εi = 0 cho tất cả i = 1,2,...,Nt và cutoff = Nt, chúng ta đơn giản khôi phục cài đặt vanilla mà không có bất kỳ xem xét hiệu quả dữ liệu nào. Trong các thí nghiệm của chúng tôi, chúng tôi giả định εi = ε/cutoff, tức là loại bỏ tỷ lệ bằng nhau dữ liệu ở cuối mỗi giai đoạn, để đơn giản. Chúng tôi cũng tiến hành nghiên cứu khám phá toàn diện cho ε và việc chọn giai đoạn cutoff trong Phần 5.3 và Phụ lục D.3.

4.3 Che Mặt Nạ Gradient Động
Với TDM và DDR, chúng ta đã có thể đạt được hiệu quả hai cấp trong quá trình huấn luyện. Để thúc đẩy thêm hiệu quả huấn luyện, chúng tôi khám phá tính thưa thớt trong gradient và đề xuất che mặt nạ gradient động (DGM) cho CL. Phương pháp của chúng tôi tập trung vào việc giảm chi phí tính toán bằng cách chỉ áp dụng các gradient quan trọng nhất lên các tham số mô hình không bị cắt tỉa tương ứng qua một mặt nạ gradient. Mặt nạ gradient cũng được cập nhật động cùng với mặt nạ trọng số được định nghĩa trong Phần 4.1. Trực quan, trong khi nhắm đến hiệu quả huấn luyện tốt hơn, DGM cũng thúc đẩy việc bảo toàn kiến thức quá khứ bằng cách ngăn một phần trọng số khỏi cập nhật.

Chính thức, mục tiêu của chúng tôi ở đây là tìm một tập con các tham số không bị cắt tỉa (hoặc tương đương, một mặt nạ gradient MG) để cập nhật qua nhiều lần lặp huấn luyện. Đối với một mô hình f được tham số hóa bởi θ, chúng ta có ma trận gradient tương ứng G được tính trong mỗi lần lặp. Để ngăn các trọng số bị cắt tỉa khỏi cập nhật, mặt nạ trọng số M sẽ được áp dụng lên ma trận gradient G như G⊙M trong quá trình lan truyền ngược. Bên cạnh các gradient của trọng số bị cắt tỉa, chúng tôi thêm vào xem xét loại bỏ các gradient ít quan trọng hơn để huấn luyện nhanh hơn. Để đạt được điều này, chúng tôi giới thiệu tầm quan trọng gradient liên tục (CGI) dựa trên CWI để đo lường tầm quan trọng của gradient trọng số.

CGI(w) = α|∂L̃(Dt;θ)/∂w| + β|∂L(M;θ)/∂w| (3)

Chúng tôi loại bỏ một tỷ lệ q các gradient khác không từ G với tầm quan trọng ít hơn được đo bằng CGI và chúng ta có ||MG||0/||θ||0 = 1-(s+q). Mặt nạ gradient MG sau đó được áp dụng lên ma trận gradient G. Trong suốt quá trình huấn luyện, mặt nạ gradient MG được cập nhật với một khoảng cố định.

5 Thí nghiệm

5.1 Cài Đặt Thí Nghiệm
Tập dữ liệu. Chúng tôi đánh giá SparCL trên hai benchmark CL đại diện, Split CIFAR-10 (32) và Split Tiny-ImageNet (15) để xác minh hiệu quả của SparCL. Cụ thể, chúng tôi theo (8;67) bằng cách chia CIFAR-10 và Tiny-ImageNet thành 5 và 10 tác vụ, mỗi tác vụ bao gồm tương ứng 2 và 20 lớp. Thông tin giấy phép tập dữ liệu có thể được tìm thấy trong Phụ lục C.

Các phương pháp so sánh. Cụ thể, chúng tôi chọn các phương pháp CL của tất cả các loại bao gồm dựa trên chính quy hóa (EWC (31), LwF (36)), dựa trên kiến trúc (PackNet (41), LPS (56)), và dựa trên rehearsal (A-GEM (12), iCaRL (43), FDR (5), ER (13), DER++ (8)) phương pháp. Lưu ý rằng PackNet và LPS chỉ tương thích với học tăng dần tác vụ. Chúng tôi cũng điều chỉnh các phương pháp huấn luyện thưa thớt đại diện (SNIP (34), RigL (19)) cho cài đặt CL bằng cách kết hợp chúng với DER++ (SNIP-DER++, RigL-DER++).

Các biến thể của phương pháp chúng tôi. Để thể hiện tính tổng quát của SparCL, chúng tôi kết hợp nó với DER++ (một trong các phương pháp CL SOTA), và ER (đơn giản và được sử dụng rộng rãi) như SparCL-DER++ và SparCL-ER, tương ứng. Chúng tôi cũng thay đổi tỷ lệ thưa thớt trọng số (0.75; 0.90; 0.95) của SparCL để đánh giá toàn diện.

Chỉ số đánh giá. Chúng tôi sử dụng độ chính xác trung bình trên tất cả các tác vụ để đánh giá hiệu suất của mô hình cuối cùng. Hơn nữa, chúng tôi đánh giá FLOPs huấn luyện (19), và dung lượng bộ nhớ (66) (bao gồm pixel bản đồ tính năng và tham số mô hình trong quá trình huấn luyện) để chứng minh hiệu quả của mỗi phương pháp. Vui lòng xem Phụ lục D.1 để biết định nghĩa chi tiết của các chỉ số này.

Chi tiết thí nghiệm. Để so sánh công bằng, chúng tôi tuân thủ nghiêm ngặt các cài đặt trong nghiên cứu CL trước đây (8;28). Chúng tôi đặt epoch huấn luyện cho mỗi tác vụ là 50 và 100 cho Split CIFAR-10 và Tiny-ImageNet, tương ứng, với kích thước batch là 32. Đối với kiến trúc mô hình, chúng tôi theo (8;49) và áp dụng ResNet-18 (25) mà không có bất kỳ huấn luyện trước nào. Chúng tôi cũng sử dụng cài đặt siêu tham số tốt nhất được báo cáo trong (8;56) cho các phương pháp CL, và trong (19;34) cho các phương pháp huấn luyện thưa thớt được điều chỉnh cho CL. Đối với SparCL và các phương pháp huấn luyện thưa thớt được điều chỉnh cho CL cạnh tranh, chúng tôi áp dụng tỷ lệ thưa thớt đồng nhất cho tất cả các lớp tích chập. Vui lòng xem Phụ lục D để biết các chi tiết khác.

5.2 Kết Quả Chính
So sánh với các phương pháp CL. Bảng 1 tóm tắt kết quả trên Split CIFAR-10 và Tiny-ImageNet, dưới cả cài đặt tăng dần lớp (Class-IL) và tăng dần tác vụ (Task-IL). Từ Bảng 1, chúng ta có thể thấy rõ ràng rằng SparCL cải thiện đáng kể ER và DER++, đồng thời cũng vượt trội hơn các baseline CL khác, về hiệu quả huấn luyện (được đo bằng FLOPs). Với tỷ lệ thưa thớt cao hơn, SparCL dẫn đến ít FLOPs huấn luyện hơn. Đáng chú ý, SparCL đạt được cải thiện hiệu quả huấn luyện 23× so với DER++ với tỷ lệ thưa thớt 0.95. Mặt khác, khung của chúng tôi cũng cải thiện độ chính xác trung bình của ER và DER++ một cách nhất quán trong tất cả các trường hợp với tỷ lệ thưa thớt 0.75 và 0.90, và chỉ giảm hiệu suất nhẹ khi tính thưa thớt trở nên lớn hơn như 0.95. Cụ thể, SparCL-DER++ với tỷ lệ thưa thớt 0.75 thiết lập độ chính xác SOTA mới, với tất cả kích thước bộ đệm dưới cả hai benchmark. Hiệu suất xuất sắc của SparCL cho thấy các chiến lược được đề xuất của chúng tôi thành công bảo toàn độ chính xác bằng cách giảm thiểu thêm quên thảm khốc với một mô hình thưa thớt hơn nhiều. Hơn nữa, sự cải thiện mà SparCL mang lại cho hai phương pháp CL hiện có khác nhau cho thấy tính tổng quát của SparCL như một khung thống nhất, tức là nó có tiềm năng được kết hợp với một loạt rộng các phương pháp hiện có.

Chúng tôi cũng muốn xem xét kỹ hơn PackNet và LPS, cũng tận dụng ý tưởng tính thưa thớt để chia mô hình theo các tác vụ khác nhau, một động lực khác với hiệu quả huấn luyện. Đầu tiên, chúng chỉ tương thích với cài đặt Task-IL, vì chúng tận dụng danh tính tác vụ ở cả thời gian huấn luyện và kiểm tra. Hơn nữa, tính thưa thớt mô hình của các phương pháp này giảm với số lượng tác vụ tăng, điều này vẫn dẫn đến FLOPs huấn luyện tổng thể lớn hơn nhiều so với SparCL. Điều này chứng minh thêm tầm quan trọng của việc giữ một mô hình thưa thớt mà không mở rộng vĩnh viễn trong suốt quá trình CL.

So sánh với các phương pháp huấn luyện thưa thớt được điều chỉnh cho CL. Bảng 2 cho thấy kết quả dưới cài đặt Class-IL khó khăn hơn. SparCL vượt trội hơn tất cả các phương pháp huấn luyện thưa thớt được điều chỉnh cho CL về cả độ chính xác và FLOPs huấn luyện. Khoảng cách hiệu suất giữa SparCL-DER++ và các phương pháp khác trở nên lớn hơn với tính thưa thớt cao hơn. SNIP- và RigL-DER++ đạt được tăng tốc huấn luyện với chi phí là độ chính xác bị thỏa hiệp, điều này cho thấy việc giữ độ chính xác là một thách thức không tầm thường đối với các phương pháp huấn luyện thưa thớt hiện có dưới cài đặt CL. SNIP tạo ra mặt nạ ban đầu tĩnh sau khi khởi tạo mạng không xem xét tính phù hợp cấu trúc giữa các tác vụ. Mặc dù RigL áp dụng mặt nạ động, việc thiếu chiến lược nhận biết tác vụ ngăn nó tổng quát hóa tốt cho cài đặt CL.

5.3 Tính Hiệu Quả của Các Thành Phần Chính
Nghiên cứu ablation. Chúng tôi cung cấp một nghiên cứu ablation toàn diện trong Bảng 3 sử dụng SparCL-DER++ với tính thưa thớt 0.75 trên Split CIFAR10. Bảng 3 chứng minh rằng tất cả các thành phần của phương pháp đều đóng góp vào cả cải thiện hiệu quả và độ chính xác. So sánh hàng 1 và 2, chúng ta có thể thấy phần lớn giảm FLOPs từ TDM. Thú vị, TDM dẫn đến tăng độ chính xác, cho thấy TDM tạo ra một mô hình thưa thớt thậm chí phù hợp hơn để học tất cả các tác vụ so với mô hình dày đặc đầy đủ. So sánh hàng 2 và 3, chúng ta có thể thấy DDR thực sự tăng tốc thêm huấn luyện bằng cách loại bỏ các ví dụ ít thông tin hơn. Như đã thảo luận trong Phần 4.2, khi chúng ta loại bỏ một số lượng mẫu nhất định (30% ở đây), chúng ta đạt được một điểm mà chúng ta giữ càng nhiều mẫu thông tin càng cần, và cũng cân bằng dữ liệu hiện tại và được đệm. So sánh hàng 2 và 4, DGM giảm cả FLOPs huấn luyện và dung lượng bộ nhớ trong khi cải thiện hiệu suất của mạng. Cuối cùng, hàng cuối cùng chứng minh hiệu suất hợp tác của tất cả các thành phần. Chúng tôi cũng cho thấy cùng nghiên cứu ablation với tính thưa thớt 0.90 trong Phụ lục D.4 để tham khảo. Chi tiết có thể được tìm thấy trong Phụ lục D.1.

Khám phá về DDR. Để hiểu ảnh hưởng của tỷ lệ loại bỏ dữ liệu ε, và giai đoạn cutoff cho mỗi tác vụ, chúng tôi cho thấy kết quả thí nghiệm tương ứng trong Hình 3 và Phụ lục D.3, tương ứng. Trong Hình 3, chúng tôi cố định cutoff = 4, tức là dần dần loại bỏ số lượng ví dụ bằng nhau mỗi 5 epoch cho đến epoch 20, và thay đổi ε từ 10% đến 90%. Chúng tôi cũng so sánh DDR với chiến lược loại bỏ One-shot (66), loại bỏ tất cả các ví dụ cùng một lúc tại cutoff. DDR vượt trội hơn One-shot một cách nhất quán với ε khác nhau về độ chính xác trung bình. Cũng lưu ý rằng vì DDR loại bỏ các ví dụ dần dần trước giai đoạn cutoff, DDR hiệu quả hơn One-shot. Khi ε ≤ 30%, chúng tôi cũng quan sát độ chính xác tăng của DDR so với baseline mà không loại bỏ bất kỳ dữ liệu nào. Khi ε ≥ 40%, độ chính xác trở nên thấp hơn cho cả hai chiến lược. Trực giác là khi DDR loại bỏ một lượng dữ liệu phù hợp, nó loại bỏ thông tin dư thừa trong khi giữ các ví dụ thông tin nhất. Hơn nữa, như đã thảo luận trong Phần 4.2, nó cân bằng dữ liệu hiện tại và được đệm, đồng thời cũng để lại các mẫu thông tin trong bộ đệm. Khi DDR loại bỏ quá nhiều dữ liệu, nó cũng sẽ mất các ví dụ thông tin, do đó mô hình chưa học tốt các ví dụ này trước khi loại bỏ.

Khám phá về DGM. Chúng tôi kiểm tra hiệu quả của DGM ở các mức thưa thớt khác nhau. Các thí nghiệm khám phá chi tiết được hiển thị trong Phụ lục D.5 để tham khảo. Kết quả cho thấy bằng cách đặt tỷ lệ q trong một phạm vi phù hợp, DGM có thể cải thiện hiệu suất độ chính xác một cách nhất quán bất kể sự thay đổi của tính thưa thớt trọng số.

5.4 Kết Quả Thiết Bị Di Động
Kết quả tăng tốc huấn luyện được đo trên CPU của điện thoại thông minh Samsung Galaxy S20 hiện có, có nền tảng di động Qualcomm Snapdragon 865 với CPU Qualcomm Kryo 585 Octa-core. Chúng tôi chạy mỗi kiểm tra trên một batch 32 hình ảnh để biểu thị tốc độ huấn luyện. Chi tiết về tối ưu hóa cấp compiler trên di động để tăng tốc huấn luyện có thể được tìm thấy trong Phụ lục E.1.

Kết quả tăng tốc được hiển thị trong Hình 4. SparCL có thể đạt được khoảng 3.1 và 2.3 tăng tốc huấn luyện với tính thưa thớt 0.95 và 0.90, tương ứng. Bên cạnh đó, khung của chúng tôi cũng có thể tiết kiệm 51% và 48% dung lượng bộ nhớ khi tính thưa thớt là 0.95 và 0.90. Hơn nữa, các mô hình thưa thớt thu được tiết kiệm tiêu thụ lưu trữ bằng cách sử dụng lưu trữ hàng thưa thớt nén (CSR) và có thể được tăng tốc để tăng tốc suy luận trên-edge. Chúng tôi cung cấp kết quả tăng tốc suy luận trên di động trong Phụ lục E.2.

6 Kết luận
Bài báo này trình bày một khung thống nhất có tên SparCL cho CL hiệu quả đạt được cả tăng tốc học và bảo toàn độ chính xác. Nó bao gồm ba chiến lược bổ sung: che mặt nạ động nhận biết tác vụ cho thưa thớt trọng số, loại bỏ dữ liệu động cho hiệu quả dữ liệu, và che mặt nạ gradient động cho thưa thớt gradient. Các thí nghiệm rộng rãi trên các benchmark CL tiêu chuẩn và đánh giá thiết bị edge thực tế chứng minh rằng phương pháp của chúng tôi cải thiện đáng kể các phương pháp CL hiện có và vượt trội hơn các phương pháp huấn luyện thưa thớt được điều chỉnh cho CL. Chúng tôi thảo luận các hạn chế và tác động xã hội tiêu cực tiềm tàng của phương pháp trong Phụ lục A và B, tương ứng.

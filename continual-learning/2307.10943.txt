# 2307.10943.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/continual-learning/2307.10943.pdf
# File size: 9934338 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Proxy Anchor-based Unsupervised Learning for Continuous Generalized
Category Discovery
Hyungmin Kim1,2Sungho Suh3,4Daehwan Kim2Daun Jeong2Hansang Cho2
Junmo Kim1
1Korea Advanced Institute of Science and Technology, Daejeon, South Korea
2Samsung Electro-Mechanics, Suwon, South Korea
3German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany
4Department of Computer Science, RPTU Kaiserslautern-Landau, Kaiserslautern, Germany
{hyungmin83, junmo.kim }@kaist.ac.kr, sungho.suh@dfki.de
{daehwan85.kim, du33.jeong, hansang.cho }@samsung.com
Abstract
Recent advances in deep learning have significantly im-
proved the performance of various computer vision appli-
cations. However, discovering novel categories in an in-
cremental learning scenario remains a challenging problem
due to the lack of prior knowledge about the number and na-
ture of new categories. Existing methods for novel category
discovery are limited by their reliance on labeled datasets
and prior knowledge about the number of novel categories
and the proportion of novel samples in the batch. To ad-
dress the limitations and more accurately reflect real-world
scenarios, in this paper, we propose a novel unsupervised
class incremental learning approach for discovering novel
categories on unlabeled sets without prior knowledge. The
proposed method fine-tunes the feature extractor and proxy
anchors on labeled sets, then splits samples into old and
novel categories and clusters on the unlabeled dataset. Fur-
thermore, the proxy anchors-based exemplar generates rep-
resentative category vectors to mitigate catastrophic forget-
ting. Experimental results demonstrate that our proposed
approach outperforms the state-of-the-art methods on fine-
grained datasets under real-world scenarios.
1. Introduction
Deep neural networks have achieved remarkable perfor-
mance in various computer vision tasks. However, current
systems are still subject to constraints that are manually
supervised and do not consider continual incremental cat-
egories. For extending to real-world environments, there
are still gaps to catch up by overcoming the constraints and
improving their abilities in fundamental tasks. Specifically,
humans still perform better than machines in object cog-
nitive and grouping skills ( e.g. recognizing new productsor clothing on shopping and categorizing undefined moving
objects while driving).
Various methods have been proposed to address the
limitations of the tasks by considering real-world circum-
stances, as presented in Figure 1 and Table 1. In detail,
Novel Category Discovery (NCD) [11, 12, 45] and Gen-
eralized Category Discovery (GCD) [38, 7] aim to recog-
nize not only pre-trained categories but also discover novel
categories using a given dataset. NCD considers a disjoint
dataset where labeled and unlabeled novel samples have no
intersection with each other. In contrast, GCD exploits the
joint set with intersected categories, making GCD a more
complicated task than NCD. However, these approaches do
not consider the class incremental scheme. Class incremen-
tal NCD (class-iNCD) [34, 16] has been proposed to adopt
the incremental categories on NCD task, but they still fo-
cus on improving novel category discovery performance us-
ing the disjoint set, which is an unrealistic constraint. To
address this issue, Grow and Merge (GM) [44] proposes
a scenario that exploits the joint unlabeled dataset in the
incremental novel category discovery task, which is called
Continuous Category Discovery Mixed Incremental (CCD-
MI). However, most existing methods require prior knowl-
edge, such as the number of unlabeled classes for NCD and
class-iNCD, or the proportion of the novel samples in the
batch for CCD-MI. Such prior knowledge requirements are
not enough to mimic the real-world, as we lack information
about the unlabeled sets.
To overcome these constraints, we propose a novel sce-
nario that better represents real-world circumstances by re-
moving constraints on the available data. We assume that
the given datasets are unlabeled joint sets without provid-
ing prior knowledge about the data. Employing the sce-
nario, we propose a novel unsupervised class incrementalarXiv:2307.10943v2  [cs.CV]  2 Nov 2023

--- PAGE 2 ---
1?
?
2?
3
ð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºðŸŽðŸŽ
1?
?2?
34
5
ð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºðŸŽðŸŽ
1 ?
?2?
3
ð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºðŸŽðŸŽ ð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºðŸðŸ
1 ?
?2?
??
?3
ð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºðŸŽðŸŽ ð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºðŸðŸ
1 ?
?2?
?
ð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºðŸŽðŸŽ ð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºð‘ºðŸðŸ?
?3(a) NCD (b) GCD (c) class-iNCD (d) CCD-MI (e) CGCD
Figure 1. Comparison of existing and proposed scenarios for novel category discovery. The solid and dash-lined circles indicate labeled
and unlabeled samples, respectively, with sample color depicting the class label. The circle with idenotes the number of novel classes
(pink) and the proportion of novel class samples in a batch (dark blue).
Task MethodConstraints
Continual
learningAssumption:
Ylâˆ© Y u=âˆ…Number of
novel classesProportion of
new class data
NCD RankStat [11, 12], DRNCD [45] Not considered Required Required Not required
GCD GCD [38], XCon [7] Not considered Not required Not required Not required
class-iNCD FRoST [34], NCDwF [16] Considered Required Required Not required
CCD-MI GM [44] Considered Not required Not required Required
CGCD Ours Considered Not required Not required Not required
Table 1. Comparison of existing and proposed novel category discovery settings and the constraints
learning approach to simultaneously address the problems
of discovering incremental novel categories and alleviating
catastrophic forgetting. In addition, we focus on recogniz-
ing fine-grained objects, which is a more realistic use case
for various applications in real-world applications.
The proposed method exploits a deep metric learning
scheme, proxy anchor (PA) [19] that presents fast and re-
liable convergence and robustness against noise samples,
and also considers the relations between samples. Then,
we divide the unlabeled data into old and novel categories
using PAs, which inherit discriminative features of old cat-
egories. The cosine similarity is measured between the PAs
and the samples, and then initially separated datasets are
acquired on a criterion. For further splitting, we adopt a
noisy label learning scheme, and then assign the predictions
of the previous model and the clustering results by a non-
parametric approach to old and novel categorized samples,
respectively. To mitigate the forgetting, we use a PA-based
exemplar, which inherits more representative features. In
the experimental results, we demonstrate that the proposed
method outperforms the existing state-of-the-art in discov-
ering novel categories and forgetting alleviation on various
fine-grained datasets. Specifically, the proposed method
does not require any prior knowledge and considers contin-
ual learning on unlabeled joint datasets, making it a more
realistic and practical solution for real-world scenarios.
The main contributions of the proposed method can be
summarized as follows.
â€¢ We introduce a novel scenario, called Continuous Gen-
eralized novel Category Discovery (CGCD), whichis well-suited to tackle the challenges of discovering
novel categories in real-world scenarios by removing
the constraint that unlabeled data belong to only novel
categories.
â€¢ We propose a novel unsupervised learning approach
for incremental novel category discovery that does not
require prior knowledge of the number of novel cate-
gories or the proportion of new class data.
â€¢ We present a noisy label learning approach and deep
metric learning to split unlabeled data into old and
novel categories, and also show mitigation of catas-
trophic forgetting using a deep metric-based exemplar.
â€¢ The proposed method outperforms the state-of-the-art
methods in novel category discovery and forgetting
mitigation on various fine-grained datasets.
2. Problem Definition
2.1. Continuous Generalized Category Discovery
As presented in Figure 1 and Table 1, various envi-
ronmental schemes have been proposed to mimic real-
world circumstances. Notable approaches include NCD
[11, 12, 45], GCD [38], class-iNCD [34, 16], and CCD [44].
NCD considers disjoint datasets between labeled and unla-
beled sets ( i.e.Ylâˆ©Yu=âˆ…) and requires prior knowledge of
the number of unlabeled categories |Yu|. In contrast, GCD
exploits the joint set ( i.e.Ylâˆ© YuÌ¸=âˆ…). Although GCD is
a more challenging task than NCD, it still does not consider
continuous incremental category discovery.

--- PAGE 3 ---
PAInitial
Model ClusteringPseudo Label
New
ModelInitial step Discovering novel category step
Initial Split
Fine SplitInitial
Model
ExemplarLabeled sample
Unlabeled sample
Pseudo labeled sample Unseen
Seen
DistillationCategory incremental step
PAInitial
Model
PA
PAPA Proxy anchor
FreezeFigure 2. Overview of the proposed CGCD framework. The framework comprises three steps. The first step is that the network model is
fine-tuned on the target dataset using the labeled dataset. In the second step, the discovery of novel categories is performed on the joint
and unlabeled dataset, which is split into unseen and seen sets using the initial and fine split methods. Pseudo-labels are assigned to the
unlabeled dataset using the previous modelâ€™s predictions (seen case) and non-parametric clustering results (unseen case). In the last step, a
new model is trained on the fine split dataset, which incorporates new proxy anchors based on clustering results.
Class-iNCD is an extension of NCD to the continual
learning scheme. However, the method trains on the dis-
joint dataset under class incremental stages and has a re-
quirement for |Yu|. CCD also trains on discovering novel
classes under the continual learning scheme with the joint
dataset. Although CCD does not require |Yu|, it still needs
the proportion of the novel class data in a batch as prior
knowledge, which is used to filter out the data.
To address these limitations, we propose a more chal-
lenging problem, named Continuous Generalized novel
Category Discovery (CGCD), that is closer to real-world
circumstances. In CGCD, we exploit the unlabeled joint
dataset in incremental steps without providing any prior
knowledge and aim to discover novel classes. This formu-
lation is more representative of real-world scenarios, where
we are not aware of the number of unlabeled categories and
the characteristics of the dataset.
2.2. Setting of Continuous Generalized Category
Discovery
Fine-grained datasets consist of similar objects, such
as canines [17], indoor scenes [31], vehicles [26], and
birds [39], in constrained circumstances. Compared to
coarse datasets such as CIFAR [20] and ImageNet [21],
fine-grained datasets are closer to real-world scenarios.
Therefore, we focus on training and discovering novel
classes with fine-grained datasets to mimic real-world cir-
cumstances better.
CGCD employs the joint unlabeled dataset in incremen-
tal steps, and Table 2 describes the dataset partitioning used
in the one-time incremental category discovery. First, theDatasetAll
classesInitial step Category incremental step
Old class Old class New class
CUB-200 200 160 (0.8) 160 (0.2) 40 (1.0)
MIT67 67 53 (0.8) 53 (0.2) 14 (1.0)
Stanford Dogs 120 96 (0.8) 96 (0.2) 24 (1.0)
FGVC Aircraft 100 80 (0.8) 80 (0.2) 20 (1.0)
Table 2. Dataset configurations for one-time incremental category
scenarios. The number of classes and the proportion of data from
each class in parentheses are presented. Note that the ratios in
parentheses are hidden information that is not revealed to the
learning methods.
set of classes is partitioned into old classes and new classes
at a certain rate, for example, 8: 2. The initial step uti-
lizes labeled dataset D0consisting of old classes only. Then
the following incremental step utilizes unlabeled dataset D1
consisting of both old classes and new classes, which reflect
more realistic and challenging real-world scenarios. The
key element of the proposed method is to decide whether the
unlabeled data point belongs to the old classes (seen) or new
classes (unseen). The samples belonging to the old classes
are assigned to labeled dataset D0and unlabeled dataset D1,
and the rest of all the new class samples are assigned to D1.
Here the choice of 8: 2 is an arbitrary example, and it is
important to note that this ratio is just for data generation
purposes and is not revealed to the learning methods.
3. Method
As described in Figure 2, our proposed method consists
of three steps: the initial step, the novel category discov-

--- PAGE 4 ---
ery step, and the category incremental step. In the ini-
tial step, we fine-tune a pre-trained model on the labeled
dataset D0={(x, y)âˆˆ X lÃ— Yl}, and obtain the embed-
ding vector zusing the model f(Â·), denoted as z=f0(x).
We then use these vectors to train PAs [19] of each cate-
gory, represented as p=g0(z), and also construct well-
representative exemplars. In the following novel category
discovery step, the given unlabeled joint datasets are de-
noted as D1={x|xâˆˆ Xu}. We first separate them into old
and novel categories through the initial and the fine splits.
Since the separated sets are unlabeled, we pseudo-label for
old and novel classes using the previous model prediction
and non-parametric clustering results, respectively.
In the category incremental step, the acquired set is
trained to improve the performance of discovering novel
categories. To avoid catastrophic forgetting, we exploit gen-
erated features by the exemplar and feature distillation be-
tween earlier and new models. The proposed model does
not require any prior knowledge, such as |Yu|and the ratio
of novel class samples in a batch. We evaluate the perfor-
mance of the proposed method using the validation dataset,
which includes all categories.
3.1. Initial Step: Fine Tune
Existing NCD methods do not account for noisy cate-
gories, such as those categorized from old to novel or from
novel to old, which can impair novel discovery performance
and accumulate errors in the continuous procedure. To ad-
dress these limitations, in this work, we propose a novel
approach that leverages the benefits of PA to complement
and improve the existing approaches. PA is a metric learn-
ing method that combines proxy- and pair-based methods
to achieve rapid and reliable convergence, and robustness
against noisy samples, and considers relations between data
to extract meaningful semantic information.
Following the method, the embedding vector zfrom the
initial model f0is trained to map to each proxy anchor p=
g0(z). Let the set of all proxy anchors as P0in the labeled
dataD0. In this manner, the number of proxy anchors of D0
is the number of classes of the labeled set ( i.e.|P0|=|Yl|)
in the initial step. We train the model and proxy anchors
using the following loss function defined in [19]:
L0
pa(Z0) =1
|P0+|X
pâˆˆP0+log
1 +X
zâˆˆZ0+
peâˆ’Î±(s(z,p)âˆ’Î´)
+1
|P0|X
pâˆˆP0log
1 +X
zâˆˆZ0âˆ’
peÎ±(s(z,p)+Î´) (1)
where Î´ >0is a margin and Î± >0is a scaling factor. The
function s(Â·,Â·)indicates the cosine similarity score. P0+
represents same class PAs( e.g.positive) in the batch. Each
proxy pdivides the set of embedding vector Z0asZ0+
pand
/uni00000013/uni00000011/uni00000015
 /uni00000013/uni00000011/uni00000013 /uni00000013/uni00000011/uni00000015
/uni00000026/uni00000052/uni00000056/uni0000004c/uni00000051/uni00000048/uni00000003/uni00000036/uni0000004c/uni00000050/uni0000004c/uni0000004f/uni00000044/uni00000055/uni0000004c/uni00000057/uni0000005c/uni00000013/uni00000015/uni00000013/uni00000017/uni00000013/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057/uni00000032/uni0000004f/uni00000047
/uni00000031/uni00000048/uni0000005a
/uni00000013/uni00000011/uni00000013 /uni00000013/uni00000011/uni00000018 /uni00000014/uni00000011/uni00000013
/uni00000026/uni00000055/uni00000052/uni00000056/uni00000056/uni00000003/uni00000028/uni00000051/uni00000057/uni00000055/uni00000052/uni00000053/uni0000005c/uni00000013/uni00000014/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057/uni00000032/uni0000004f/uni00000047
/uni00000031/uni00000048/uni0000005a(a) Initial Split (b) Fine Split
Figure 3. Separation results on joint unlabeled datasets
Z0âˆ’
p=Z0âˆ’Z0+
p.Z0+
pdenotes the same class embedding
points with the proxy anchor p. The first term aims to pull p
and its dissimilar but hard positive data together, while the
last term is to push pand its similar but hard negatives apart.
3.2. Discovering Novel Categories Step
Separation: In this procedure, we aim to split the given
joint dataset D1into the novel and old categories without
any prior knowledge. We conduct this task in two stages:
initial split and fine split. In the initial split, we compute
the cosine similarity between pand each embedding vector
ziâˆˆZ1, where zi=f0(xi)andxiâˆˆD1. Because the
set of proxy anchors P0represents the old categories, we
classify a sample to the old class if the maximum similarity
score of ziis larger than a threshold Ïµ. We set Ïµ= 0since it
is the median of the score ranges. The initial split is defined
as:
Ëœyi=ï£±
ï£²
ï£³0,ifmax
pâˆˆP0(s(zi, p))â‰¥Ïµ= 0
1,otherwise(2)
To acquire a cleaner novel and old dataset, we propose
a noisy labeling scheme, fine split, which involves an it-
erative training of a simple multilayer perceptron (MLP)
based classifier m(Â·)on the binarized dataset. The initial
split results in noisy and inaccurate separation, as shown
in Figure 3 (a). Among them, only the data on both ends
of the spectrum are assumed the clean and utilized to train
the classifier. The loss of split network m(Â·)is defined as
follows:
Lsp=âˆ’EzcâˆˆZ1c[Ëœyclog(m(zc)) + (1 âˆ’Ëœyc) log(1 âˆ’m(zc))](3)
where zcdenotes clean embedding vectors, and Z1
crep-
resents the set of clean vectors. Ëœycindicates the pseudo label
of the clean data. After the warm-up training, the classi-
fier is trained with re-assigned pseudo labels and the more
cleaned data, which is divided with the Gaussian mixture
model (GMM). Consequently, the Figure 3 (b) shows the
cleaner separated results.
Pseudo-labeling: After the separation, both the old D1
old
and the novel categories D1
new are still unlabeled. Thus,
we use pseudo-labels to assign labels to each sample. For
D1
old, we use the predictions of the previous model and
proxy anchors to assign pseudo-labels. In contrast, we use a

--- PAGE 5 ---
non-parametric clustering approach named Affinity propa-
gation [9] to assign pseudo-labels to D1
new. In this manner,
our proposed approach does not require any prior knowl-
edge. Finally, from the clustering results, we obtain an esti-
mate of the number of novel categories, denoted as |Ë†Yn|.
3.3. Category Incremental Step
Training modified model and PAs: To improve the per-
formance of discovering novel categories, we modify the
model since the previous model has PAs only for |Yl|
classes and cannot categorize novel classes. We add new
pfor|Ë†Yn|classes, increasing the total number of PAs like
|P1|=|Yl|+|Ë†Yn|. The loss function to train the modified
model f1and PA p=g1(z)is reformulated as follows:
L1
pa(Z1) =1
|P1+|X
pâˆˆP1+log
1 +X
zâˆˆZ1+
peâˆ’Î±(s(z,p)âˆ’Î´)
+1
|P1|X
pâˆˆP1log
1 +X
zâˆˆZ1âˆ’
peÎ±(s(z,p)+Î´) (4)
Avoiding forgetting: In the continual learning scheme, it
is essential to alleviate catastrophic forgetting. We adopt
feature replay, which leverages the PA information belong-
ing to old categories. Each well-trained pinherits the rep-
resentation power for each category. We employ each p
to generate features by following the Gaussian distribution
N(p0, Ïƒ2), p0âˆˆP0. The number of generated features is
determined based on data balancing, for example, the num-
ber of newly categorized samples in a batch. The generated
features are concatenated into a batch, and the model and
PAs are trained using the following loss function:
L1
ex(ËœZ) =L1
pa(ËœZ), ËœZ={Ëœzâˆ¼ N(p0, Ïƒ2)} (5)
Also, we utilize the distillation of the extracted embed-
ding vectors from the present f1and the previous model f0.
The distillation loss Lkdis described as follows:
L1
kd(zo) =âˆ’EzoâˆˆZ1
oldâˆ¥z0
oâˆ’zoâˆ¥2
=âˆ’ExoâˆˆD1
oldâˆ¥f0(xo)âˆ’f1(xo)âˆ¥2(6)
where z0represents the embedding vector for fixed pre-
vious feature network f0.Z1
olddenotes seen data from
Z1={Z1
oldâˆªZ1
new}.
In conclusion, the loss consists of three different losses
in the continuous category discovery step. One loss is for
training the PAs and the model on D1, the others are to avoid
forgetting by using generated features and knowledge dis-
tillation. L1is described as follows:
L1=L1
pa(Z1) +L1
ex(ËœZ) +L1
kd(zo) (7)4. Experimental Results
4.1. Implementation Details
We utilized the widely used augmentation techniques, in-
cluding random crop after padding and random horizontal
flip. All the experiments were trained for 60epochs using
AdamW optimizer with weight decay set to 0.0001. The
initial learning rate was set to 0.0001 for the model f(Â·),
while for the PAs, it was set to 0.01. The learning rate
was decayed by a factor of 0.5 every five epochs. We used
the threshold Ïµonly once for the initial split to divide the
set into old and novel categories, and we set it to 0 for all
the datasets and networks. For fine split, we used an MLP-
based network architecture that consists of two dense layers
with a batch normalization layer. The model was trained for
three epochs using AdamW with a learning rate of 0.0001.
The hyperparameters for PAs, Î±andÎ´, were set to 32 and
0.1, respectively.
For fair comparisons of various methods, such as NCD,
class-iNCD, and CCD, we follow the hyperparameters and
the network architectures of the original implementations,
referring to the papers for details. All the reported perfor-
mances are average results over three runs.
4.2. Evaluation Metrics
We evaluate the methods using metrics based on the clus-
ter accuracy measurement, called Hungarian assignment al-
gorithm [22]. The evaluation metric is defined as follows:
Mt=1
|D||D|X
i=1I(yi=hâˆ—(yâˆ—
i)) (8)
where|D|is the size of the validation dataset Dandhâˆ—is the
optimal assignment. So, Mtmeasures the cluster accuracy
at step ton the D. In this manner, MallandMoindicate
the cluster accuracy metrics of the whole and old categories
usingMt, respectively. Furthermore, we employ two more
metrics that, MfandMd, which are proposed on GM [44]
and described as follows:
Mf= max
t{M0
oâˆ’ Mt
o}, (9)
Md=1
|T|X
i=TMi
n. (10)
where M0
oandMt
oare the old class cluster accuracy at the
initial step and category incremental tstep, respectively. So
Mfmeasures the maximum forgetting values for old cate-
gories in the entire step and should be sufficiently low; if
not, the method is not valuable in practical applications.
In Equation (10), |T|is the number of increased steps, and
Mdevaluates the averaged performance of novel category
discovery in unlabeled joint datasets in each step. It means

--- PAGE 6 ---
MethodCUB-200 MIT67 Stanford Dogs FGVC aircraft
Mallâ†‘M oâ†‘ M fâ†“ M dâ†‘ M allâ†‘M oâ†‘ M fâ†“ M dâ†‘ M allâ†‘M oâ†‘ M fâ†“ M dâ†‘ M allâ†‘M oâ†‘ M fâ†“ M dâ†‘
Supervised 61.69 45.83 23.32 16.63 55.56 40.90 19.52 18.34 64.26 47.57 25.43 17.01 64.62 48.17 26.24 18.12
DRNCD [45] 9.80 10.47 58.51 34.24 26.99 27.67 49.07 38.91 16.39 10.34 65.83 63.36 18.73 19.50 57.05 45.63
FRoST [34] 18.19 17.34 12.18 17.20 23.21 23.55 15.96 24.74 22.62 22.23 14.29 26.06 32.61 33.53 15.19 27.69
GM [44] 6.43 6.57 39.82 5.92 16.52 16.77 42.26 15.50 5.99 5.98 50.36 5.98 12.00 11.63 53.35 13.46
Ours 54.75 58.80 15.47 40.90 54.45 64.23 10.64 18.58 66.25 76.15 6.77 30.04 37.28 41.60 14.66 20.04
Table 3. Comparison results under continuous generalized categorized discovery scenario. The results present the mean over three runs.
Figure 4. Qualitative evaluation results of the proposed method using the CUB-200 dataset on ResNet-18. The first five columns with
blue boxes denote well-clustered examples. The last two columns represent failed prediction results, including example images with purple
boxes denoting hard negatives and those with red boxes indicating incorrect categorization.
the higher method, the more appropriate method in real-
world applications.
4.3. Comparison with State-of-the-arts Methods
We conducted a series of experiments to compare the
cluster accuracy performance of our proposed method with
state-of-the-art approaches, as presented in Table 1. In the
experiments, we excluded the GCD task, including XCon,
as it focuses on discovering novel categories blended with
labeled and unlabeled datasets and evaluates unknown dis-
covery performance on only train datasets, not validation
datasets, in their papers. Therefore, we compared our pro-
posed method with other approaches, including Dual rank
NCD (DRNCD) [45], FRoST [34], and GM, which are the
representative methods that record the state-of-the-art re-
sults of each task.
We first evaluated the one-step incremental category set-
ting and reported the comparison results in Table 3. The
supervised method is the setting of a supervised continual
learning manner, literally. We observed catastrophic forget-
ting in supervised learning. DRNCD is one of the NCD
approaches and recorded the outstanding performances ofMdon MIT67, Stanford Dogs, and FGVC aircraft. How-
ever, the method requires prior knowledge of the number
of novel categories and does not identify specific classes,
but only knows whether the samples are included in the
novel category or not. Thus, the results are not regarded
as outperforming. Instead, the method shows the highest
results of Mf, which means that the method focuses on
learning novel categories without considering the preven-
tion of forgetting previous categorical knowledge. In this
regard, NCD is not sufficient to extend novel class incre-
mental learning schemes. FRoST showed competitive re-
sults of discovering novel classes and decreased forgetting
results Mfon all datasets compared to DRNCD. Never-
theless, considering the required knowledge, the other met-
rics results, MallandMowere not competitive. GM pro-
posed the CCD setting, which is the most similar to CGCD,
in the perspective of the unknown number of novel cat-
egories and discovering novel and old categories on new
unlabeled datasets. However, the method requires a cru-
cial parameter, which is the ratio of novel category sam-
ples on the new dataset. Without considering the ratio,
GM recorded the lowest results of Mall,Mo, andMd.

--- PAGE 7 ---
/uni00000013 /uni00000016/uni00000013 /uni00000019/uni00000013 /uni0000001c/uni00000013 /uni00000014/uni00000015/uni00000013
/uni00000028/uni00000053/uni00000052/uni00000046/uni0000004b/uni00000056/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000016/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000018/uni00000026/uni0000004f/uni00000058/uni00000056/uni00000057/uni00000048/uni00000055/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c
/uni00000013 /uni00000016/uni00000013 /uni00000019/uni00000013 /uni0000001c/uni00000013 /uni00000014/uni00000015/uni00000013
/uni00000028/uni00000053/uni00000052/uni00000046/uni0000004b/uni00000056/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000018/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001a/uni00000026/uni0000004f/uni00000058/uni00000056/uni00000057/uni00000048/uni00000055/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c(a) Novel category discovery Md(b) Catastrophic forgetting Mf
Figure 5. Performances of novel category discovery and forgetting
on two-step incremental novel categories experiment
The proposed method showed outstanding performance on
the various datasets without requiring any prior informa-
tion about new incoming unlabeled datasets. Our method
recorded the second-best Mfon the CUB-200 dataset and
the best Mfon the other datasets, such as MIT67, Dogs,
and FGVC aircraft, by the effects of PA-based exemplar.
OnMd, the method was also competitive and compared to
the GM, which has the most similar setting to our method.
To evaluate the proposed method qualitatively, we clus-
tered the evaluation dataset using the CUB-200 dataset.
In Figure 4, our method well-discovered novel categories
and clustered them correctly. Each row is clustered into the
same category, and the classes are novel categories on the
evaluation dataset. The left five columns are well-clustered,
while the last two are not. The sixth-column images are still
reasonable, but the last-columns are the worst cases.
4.4. Two-step Novel Category Discovery
We present a two-step incremental category discovery
experiment on the CUB-200 dataset using ResNet-18. The
dataset configurations are more complicated as the datasets
are joint sets in incremental steps. The initial step, the
first incremental step, and the second incremental step have
novel classes in each step, at a rate of 8: 1: 1 , respectively.
Each step has its dataset and is indicated as D0,D1, andD2.
The samples belonging to novel labeled classes in the ini-
tial step are assigned to D0,D1, andD2at a rate of 8: 1: 1 .
Similarly, the samples belonging to novel classes in the first
incremental step are assigned to D1, andD2at a rate of
8: 2. Finally, the rest of the samples are assigned to D2.
Figure 5 describes the performance of the experiments.
Since each incremental step is trained for 60epochs, there
are deep drops at the 60thepoch when new PAs are added.
In addition, the cluster accuracy of the old categories, which
belong to the D0, decreases by about 20%. The reason is
that the number of old categories in the second incremental
step is increased compared to the first step. The exemplar
cannot focus on only generating the features of D0. How-
ever, the performance of Mdincreased steadily.
4.5. Ablation Study
Effectiveness of separations: We conducted an ablation
study to show the effectiveness of our proposed splitter,Network Fine SplitMetric
Mallâ†‘ M oâ†‘ M fâ†“ M dâ†‘
ResNet-18without 53.32 57.63 16.56 36.47
with 54.75 58.80 15.47 40.90
ResNet-50without 66.53 71.07 9.12 48.76
with 68.09 71.75 8.44 53.79
ViT-B-16without 70.22 73.02 10.75 59.24
with 72.51 74.28 9.49 65.60
Table 4. Ablation study for the proposed fine split on the CUB-200
using three different network architectures, including ResNet-18
and ResNet-50 pre-trained on ImageNet, and ViT-B-16 pre-trained
on DINO-ImageNet. The results present the mean over three runs.
Network ExemplarMetric
Mallâ†‘ M oâ†‘ M fâ†“ M dâ†‘
ResNet-18without 38.24 37.31 36.88 41.89
Data mean and std. 40.23 40.56 33.63 37.22
Proxy anchors 54.75 58.80 15.47 40.90
Table 5. Effectiveness of the proposed PA-based exemplar on the
CUB-200 dataset using ResNet-18 pre-trained on ImageNet
which consists of a combination of two different methods:
the cosine similarity score and a binary splitter using the
noise label approach. The ablation experiments were de-
signed such that one used only the cosine similarity score,
and another used both methods. As shown in Table 4,
the approach using both methods presents improvements in
both old and novel discovery performances. The results re-
veal the effectiveness of noise labeling for data separation.
Effectiveness of Proxy anchor exemplar: To mitigate
catastrophic forgetting, various approaches, such as re-
play [2], prototype [32, 34], and pseudo-latents [16], have
been proposed. Most of these methods exploit the computed
average of feature embedding vectors or input data-driven
values. However, we propose a novel PA-based exemplar
approach and evaluate its efficiency. As shown in Table 5,
the method without the exemplar recorded the highest novel
discovery performances but also showed the highest forget-
ting. Adopting a general exemplar approach using mean
and standard deviation values from the former dataset, Mf
slightly decreased, but Mdis the lowest. However, our pro-
posed method with the PA-based exemplar recorded the best
Mfand competitive Md. We analyze that the PAs have
representatives of each cluster since PA inherits the relation
between data to data and then representative figures of each
class. Hence, our PA-based method leads to mitigating for-
getting, and we confirm that it is a proper approach.
Robustness of class and sample blending ratio vari-
ants: In general, the capability to recognize novel cate-
gories largely depends on a powerful and well-trained ini-
tial model with the target datasets. The more classes and

--- PAGE 8 ---
Ratio Metric
Yold:Ynew Mallâ†‘ M oâ†‘ M fâ†“ M dâ†‘
9: 1 61.34 63.22 11.83 44.73
8: 2 54.75 58.80 15.47 40.90
7: 3 52.66 58.42 14.67 39.50
6: 4 48.78 57.90 15.16 35.53
5: 5 45.28 62.41 11.30 28.55
Table 6. Qualitative evaluation by changing the ratio of classes and
samples on the CUB-200 using ResNet18 pre-trained on ImageNet
samples are included in the initial training dataset D0, the
better the model learns representative features to fit the sets.
To evaluate the robustness of the proposed model, we con-
ducted experiments with variants of the number of samples
and classes in D0. As described in Table 6, decreasing the
number of classes and data in the labeled set decreased the
discovery of novel classes and clustering accuracies as the
number of unlabeled novel data increased. On the other
hand, catastrophic forgetting could increase since the num-
ber of novel data increases. However, forgetting was main-
tained within a reasonable boundary, indicating the effec-
tiveness of our PA-based exemplar. The results suggest that
our method has the robustness of the variants.
5. Related work
5.1. Novel Category Discovery
NCD techniques have been proposed to classify data
with various constraints on unlabeled data. One cate-
gory of the methods presented pre-training the model on
the labeled set and fine-tuning it on the unlabeled set us-
ing unsupervised clustering losses [43, 14, 13, 24, 25].
Another category assumed the availability of both the la-
beled and unlabeled data, and trained networks jointly
with a labeled novel class loss within the semi-supervised
scheme [11, 46, 47, 15, 8, 45]. Han et al. [12] proposed
transferring knowledge from labeled to unlabeled data us-
ing ranking statistics in the joint learning stage. Recently,
GCD [38] and XCon [7] tackled the more realistic scenario
of joint datasets and distinguished known and unknown
classes using prior knowledge. However, these approaches
did not consider the continual learning scheme. To address
the limitation, FRoST [34] and NCDwF [16] froze feature
extractors and added the second head for each novel class,
as much as the given number of novel categories. However,
the methods employed disjoint sets. GM [44] proposed
to consider novel category discovery on the joint datasets,
but still require prior knowledge, such as the proportion of
novel samples.
5.2. Image Retrieval
Most of the image retrieval methods have utilized met-
ric learning and can be categorized into two approaches.Pair-based methods exploited contrastive loss [3, 5, 10]
and triplet loss [35, 40], that pull together data pairs in
the same class and push apart those in different classes.
Multiple data-based [36, 29] methods proposed considering
the relations between multiple data. Entire data-based ap-
proaches [42, 41] presented considering all data in a batch,
leveraging fine-grained semantic relations between them
while requiring high computation costs and slow conver-
gence. In contrast, proxy-based methods [27, 30, 1] em-
ployed fewer proxies than the training set, reducing training
complexity. While these methods improved training conver-
gence, they did not consider data-to-data relations, as each
data was associated with its proxy. PA [19] inherited the
strength of pair- and proxy-based methods, achieving fast
and reliable convergence, robustness opposing noisy data,
and leveraging rich data-to-data relations.
5.3. Noise Label
Recently proposed methods for learning with noisy la-
bels have highlighted the importance of discriminating be-
tween clean and noise-labeled data to improve performance.
DivideMix [23] used GMM to distinguish between clean
and noisy labeled data and treated the latter as unlabeled
for semi-supervised learning. AugDesc [28] employed data
augmentation to enhance the differentiation between clean
and noisy labeled data, while INCV [4] introduced cross-
validation to separate clean data from noisy training data.
SplitNet [18] leveraged a compact network to perceive the
difference between clean and noisy labels, improving model
performance by more accurately differentiating noise.
6. Conclusion
In this paper, we presented a novel continual learning
scenario, considered NCD on the unlabeled joint datasets
without any prior knowledge of the dataset. Our frame-
work utilized PAs to split known and novel categories, re-
sulting in well-clustered and well-pseudo-labeled categories
that mitigate catastrophic forgetting. We further refined the
splitting of the dataset by adopting a noise labeling scheme.
Our proposed approach outperformed existing state-of-the-
art methods regarding novel category discovery and forget-
ting. While DeepDPM [33] has recently shown outstand-
ing performance on non-parametric clustering tasks, we be-
lieve that our proposed method can achieve even better per-
formance by adopting better clustering manners. In future
work, we plan to evaluate our method by adopting a better
clustering manner.
Acknowledgements
This work was funded by Samsung Electro-Mechanics
and was partially supported by Carl-Zeiss Stiftung under
the Sustainable Embedded AI project (P2021-02-009).

--- PAGE 9 ---
References
[1] Nicolas Aziere and Sinisa Todorovic. Ensemble deep mani-
fold similarity learning using hard proxies. In CVPR , pages
7299â€“7307, 2019.
[2] Jihwan Bang, Heesu Kim, YoungJoon Yoo, Jung-Woo Ha,
and Jonghyun Choi. Rainbow memory: Continual learning
with a memory of diverse samples. In CVPR , pages 8218â€“
8227, June 2021.
[3] Jane Bromley, Isabelle Guyon, Yann LeCun, Eduard
SÂ¨ackinger, and Roopak Shah. Signature verification using
a siamese time delay neural network. In NeurIPS , volume 6,
1993.
[4] Pengfei Chen, Ben Ben Liao, Guangyong Chen, and
Shengyu Zhang. Understanding and utilizing deep neural
networks trained with noisy labels. In ICML , pages 1062â€“
1070, 2019.
[5] S. Chopra, R. Hadsell, and Y . LeCun. Learning a similarity
metric discriminatively, with application to face verification.
InCVPR , 2005.
[6] Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos
Zafeiriou. Arcface: Additive angular margin for deep face
recognition. In CVPR , 2019.
[7] Yixin Fei, Zhongkai Zhao, Siwei Yang, and Bingchen Zhao.
Xcon: Learning with experts for fine-grained category dis-
covery. In BMVC , 2022.
[8] Enrico Finia, Enver Sangineto, Stephane Lathuiliere, Zhun
Zhong, Moin Nabi, and Elisa Ricci. A unified objective for
novel class discovery. In ICCV , 2021.
[9] Brendan J Frey and Delbert Dueck. Clustering by passing
messages between data points. Science , 315(5814):972â€“976,
2007.
[10] R. Hadsell, S. Chopra, and Y . LeCun. Dimensionality reduc-
tion by learning an invariant mapping. In CVPR , volume 2,
pages 1735â€“1742, 2006.
[11] Kai Han, Sylvestre-Alvise Rebuffi, Sebastien Ehrhardt, An-
drea Vedaldi, and Andrew Zisserman. Automatically discov-
ering and learning new visual categories with ranking statis-
tics. In ICLR , 2020.
[12] Kai Han, Sylvestre-Alvise Rebuffi, Sebastien Ehrhardt, An-
drea Vedaldi, and Andrew Zisserman. Autonovel: Auto-
matically discovering and learning novel visual categories.
TPAMI , 2021.
[13] Kai Han, Andrea Vedaldi, and Andrew Zisserman. Learning
to discover novel visual categories via deep transfer cluster-
ing. In ICCV , 2019.
[14] Yen-Chang Hsu, Zhaoyang Lv, Joel Schlosser, Phillip Odom,
and Zsolt Kira. Multi-class classification without multi-class
labels. In ICLR , 2019.
[15] Xuhui Jia, Kai Han, Yukun Zhu, and Bradley Green. Joint
representation learning and novel category discovery on
single-and multi-modal data. In ICCV , 2021.
[16] K. J. Joseph, Sujoy Paul, Gaurav Aggarwal, Soma Biswas,
Piyush Rai, Kai Han, and Vineeth N. Balasubramanian.
Novel class discovery without forgetting. In ECCV , page
570â€“586, 2022.
[17] Aditya Khosla, Nityananda Jayadevaprakash, Bangpeng
Yao, and Fei-Fei Li. Novel dataset for fine-grained imagecategorization: Stanford dogs. In CVPR Workshop on Fine-
Grained Visual Categorization , 2011.
[18] Daehwan Kim, Kwangrok Ryoo, Hansang Cho, and Se-
ungryong Kim. Splitnet: learnable clean-noisy label
splitting for learning with noisy labels. arXiv preprint
arXiv:2211.11753 , 2022.
[19] Sungyeon Kim, Dongwon Kim, Minsu Cho, and Suha Kwak.
Proxy anchor loss for deep metric learning. In CVPR , June
2020.
[20] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple
layers of features from tiny images. 2009.
[21] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.
Imagenet classification with deep convolutional neural net-
works. In NeurIPS , 2012.
[22] Harold W. Kuhn. The hungarian method for the assignment
problem. Naval Research Logistics Quarterly , 2(1â€“2):83â€“
97, March 1955.
[23] Junnan Li, Richard Socher, and Steven C.H. Hoi. Dividemix:
Learning with noisy labels as semi-supervised learning. In
ICLR , 2020.
[24] Yu Liu and Tinne Tuytelaars. Residual tuning: Toward novel
category discovery without labels. In IEEE Transactions on
Neural Networks and Learning Systems , 2022.
[25] Yu Liu and Tinne Tuytelaars. Residual tuning: Toward novel
category discovery without labels. IEEE Transactions on
Neural Networks and Learning Systems , 2022.
[26] Subhransu Maji, Esa Rahtu, Juho Kannala, Matthew
Blaschko, and Andrea Vedaldi. Fine-grained visual classi-
fication of aircraft. arXiv preprint arXiv:1306.5151 , 2013.
[27] Yair Movshovitz-Attias, Alexander Toshev, Thomas K Le-
ung, Sergey Ioffe, and Saurabh Singh. No fuss distance met-
ric learning using proxies. In CVPR , pages 360â€“368, 2017.
[28] Kento Nishi, Yi Ding, Alex Rich, and Tobias Hollerer. Aug-
mentation strategies for learning with noisy labels. In CVPR ,
pages 8022â€“8031, 2021.
[29] Hyun Oh Song, Yu Xiang, Stefanie Jegelka, and Silvio
Savarese. Deep metric learning via lifted structured feature
embedding. In CVPR , pages 4004â€“4012, 2016.
[30] Qi Qian, Lei Shang, Baigui Sun, Juhua Hu, Hao Li, and Rong
Jin. Softtriple loss: Deep metric learning without triplet sam-
pling. In CVPR , pages 6450â€“6458, 2019.
[31] Ariadna Quattoni and Antonio Torralba. Recognizing indoor
scenes. In CVPR , pages 413â€“420, 2009.
[32] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg
Sperl, and Christoph H Lampert. icarl: Incremental classi-
fier and representation learning. In CVPR , pages 2001â€“2010,
2017.
[33] Meitar Ronen, Shahaf E. Finder, and Oren Freifeld. Deep-
dpm: Deep clustering with an unknown number of clusters.
InCVPR , pages 9861â€“9870, June 2022.
[34] Subhankar Roy, Mingxuan Liu, Zhun Zhong, Nicu Sebe, and
Elisa Ricci. Class-incremental novel class discovery. In
ECCV , 2022.
[35] Florian Schroff, Dmitry Kalenichenko, and James Philbin.
Facenet: A unified embedding for face recognition and clus-
tering. In CVPR , pages 815â€“823, 2015.

--- PAGE 10 ---
[36] Kihyuk Sohn. Improved deep metric learning with multi-
class n-pair loss objective. In D. Lee, M. Sugiyama, U.
Luxburg, I. Guyon, and R. Garnett, editors, NeurIPS , vol-
ume 29, 2016.
[37] Eu Wern Teh, Terrance DeVries, and Graham W Taylor.
Proxynca++: Revisiting and revitalizing proxy neighbor-
hood component analysis. In ECCV , 2020.
[38] Sagar Vaze, Kai Han, Andrea Vedaldi, and Andrew Zisser-
man. Generalized category discovery. In CVPR , 2022.
[39] Catherine Wah, Steve Branson, Peter Welinder, Pietro Per-
ona, and Serge Belongie. The caltech-ucsd birds-200-2011
dataset. 2011.
[40] Jiang Wang, Yang Song, Thomas Leung, Chuck Rosenberg,
Jingbin Wang, James Philbin, Bo Chen, and Ying Wu. Learn-
ing fine-grained image similarity with deep ranking. In
CVPR , pages 1386â€“1393, 2014.
[41] Xun Wang, Xintong Han, Weilin Huang, Dengke Dong, and
Matthew R Scott. Multi-similarity loss with general pair
weighting for deep metric learning. In CVPR , pages 5022â€“
5030, 2019.
[42] Xinshao Wang, Yang Hua, Elyor Kodirov, Guosheng Hu,
Romain Garnier, and Neil M Robertson. Ranked list loss
for deep metric learning. In CVPR , pages 5207â€“5216, 2019.
[43] Zhaoyang Lv Yen-Chang Hsu and Zsolt Kira. Learning to
cluster in order to transfer across domains and tasks. In
ICLR , 2018.
[44] Xinwei Zhang, Jianwen Jiang, Yutong Feng, Zhi-Fan Wu,
Xibin Zhao, Hai Wan, Mingqian Tang, Rong Jin, and Yue
Gao. Grow and merge: A unified framework for continuous
categories discovery. In NeurIPS , 2022.
[45] Bingchen Zhao and Kai Han. Novel visual category discov-
ery with dual ranking statistics and mutual knowledge distil-
lation. In NeurIPS , 2021.
[46] Zhun Zhong, Enrico Fini, Subhankar Roy, Zhiming Luoa nd
Elisa Ricci, and Nicu Sebe. Neighborhood contrastive learn-
ing for novel class discovery. In CVPR , 2021.
[47] Zhun Zhong, Linchao Zhu, Zhiming Luo, Shaozi Li, Yi
Yang, and Nicu Sebe. Openmix: Reviving known knowledge
for discovering novel visual categories in an open world. In
CVPR , 2021.

--- PAGE 11 ---
Algorithm A Pseudo-code of the one-step incremental
novel category discovering
1:Initial step:
2: Given labeled dataset D0={(x, y)}
3: Train network f0(Â·)and proxy anchors g0(Â·)
4: Calculate ÏƒofD0for exemplar E0
5:Discovering novel category step:
6: Given unlabeled joint dataset D1={x}
7: Extract embedding vectors zionf0(xi)
8: Get initial separated datasets on measuring cosine
similarity score s(zi, p)using the initial split
9: Get fine separated datasets, D1
old={x1
old}and
D1
new={x1
new}on Noisy labeling and Gaussian
mixture model using the initial separated dataset
10: Get pseudo-labels D1
oldusing previous network f0,
Ë†D1
old={(x1
old,Ë†y1
old= argmax( f0(x1
old))}
11: Get pseudo-labels D1
new using a non-parametric
clustering approach c(Â·), affinity propagation,
Ë†D1
new={(x1
new,Ë†y1
new= argmax( c(x1
new))}
12:Category incremental step:
13: Add new proxy anchors as the estimated number of
novel categories based on c(Â·)results
14: Assign initial means of newly added proxy anchors
based on c(Â·)results
15: Generate old embedding vectors Ëœz0usingE0
16: Train network f1(Â·)and modified Proxy anchors
g1(Â·)using pseudo-labeled dataset Ë†D1andËœz0
17: Distill knowledge between networks, f0(Â·)and
f1(Â·)
18: Calculation ÏƒofË†D1for exemplar E1
A. Pseudo Code
Pseudo-code of our proposed method is represented in
Algorithm A in detail. The code is written for the one-time
step procedure and is comprised of three steps: the initial
step, the discovering novel category step, and the category
incremental step. The initial step is fine-tuning the network
on the dataset and training proxy anchors using the labeled
dataset. Then, the following given dataset for incremental
category learning is the unlabeled joint set, which includes
the old and novel classes. In the discovering novel category
step, we separate the dataset into old and novel categories
using the initial split and the fine split, and pseudo-label the
separated datasets. In the last step, exploiting the pseudo-
labeled dataset, we add new proxy anchors and fine-tune
the network and proxy anchors. Alleviating the catastrophic
forgetting, we utilize proxy anchor-based exemplar and fea-
ture distillation.
For extending to continuously incremental novel cate-
gories, the initial step is trained only once, then the dis-
covering novel category step and the category incremental
step are trained iteratively and sequentially. Specifically, letus assume that the novel category discovery continually in-
creases until the nthstep. In the discovering novel category
step, the given dataset notation is changed from D1toDn,
and the previous network f0is also replaced to fnâˆ’1. Also,
the pseudo-labeled datasetË†D1is modified to Ë†Dn. In the
category incremental step, the generated vector Ëœz0, the ex-
ploited exemplar E0for the vector, and the pseudo-labeled
datasetË†D1are notated Ëœznâˆ’1,Enâˆ’1, and Ë†Dn, respectively.
f1(Â·)andg1(Â·)are replaced fn(Â·)andgn(Â·). Lastly, the
new exemplar E1is substituted with En. Our code is made
available at https://github.com/Hy2MK/CGCD .
B. Fine Split
To acquire a more clearly separated dataset without noisy
data, we design a simple network for the fine split. The net-
work comprises a series of the Fully Connected layer (FC)
- Batch Normalization (BN) - sigmoid - FC - BN - sigmoid
- FC. The data is selected on both ends of the spectrum for
training the network since we assume the data in the region
is clean ( i.e. lower than 5%and over 95% based on the re-
sult of GMM). The simple perceptron model aims to predict
whether the noisy data belongs to the old or novel categories
and is trained on three epochs. Figure A (a) is depicted the
initial split result using cosine similarity score measurement
between the embedding vectors and proxy anchors. There is
an overlapped region between the old and novel categories,
which represents the initial split using previous knowledge
is unclear to divide novel and old categories. Therefore, we
adopt the noisy labeling scheme to fine separation into old
and novel classes, and confirmed the results of every epoch
of the fine split from Figure A (b) to Figure A (d).
C. GM Results Analysis
In the paper, we conducted the comparison experiment
of our proposed method with state-of-the-art approaches.
Among the compared methods, GM [44] is recorded as sig-
nificantly underperforming. Therefore, we should confirm
to clear that our experiments are conducted in a fair compar-
ison following the hyperparameters reported in the original
paper without any modifications.
GM proposed four different scenarios, which are Class
Incremental scenario (CI), Data Incremental Scenario (DI),
Mixed Incremental scenario (MI), and Semi-supervised
Mixed Incremental Scenario (SMI). Among the scenarios,
CI and MI are the most similar to ours, Continuous General-
ized Category Discovery (CGCD). We evaluated these two
scenarios using CUB-200 dataset on ResNet-18. As pre-
sented in Table A, GM conducted experiments using fine-
grained datasets only in the CI scenario, and in the other
scenario, the CIFAR-100 dataset was utilized to evaluate the
performance of the method. In this sense, we confirmed the
reproducibility in the CI scenario using CUB-200 dataset

--- PAGE 12 ---
/uni00000013/uni00000011/uni00000015
 /uni00000013/uni00000011/uni00000013 /uni00000013/uni00000011/uni00000015
/uni00000026/uni00000052/uni00000056/uni0000004c/uni00000051/uni00000048/uni00000003/uni00000036/uni0000004c/uni00000050/uni0000004c/uni0000004f/uni00000044/uni00000055/uni0000004c/uni00000057/uni0000005c/uni00000013/uni00000015/uni00000013/uni00000017/uni00000013/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057/uni00000032/uni0000004f/uni00000047
/uni00000031/uni00000048/uni0000005a
/uni00000013/uni00000011/uni00000013 /uni00000013/uni00000011/uni00000018 /uni00000014/uni00000011/uni00000013
/uni00000026/uni00000055/uni00000052/uni00000056/uni00000056/uni00000003/uni00000028/uni00000051/uni00000057/uni00000055/uni00000052/uni00000053/uni0000005c/uni00000013/uni00000014/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057/uni00000032/uni0000004f/uni00000047
/uni00000031/uni00000048/uni0000005a
/uni00000013/uni00000011/uni00000013 /uni00000013/uni00000011/uni00000018 /uni00000014/uni00000011/uni00000013
/uni00000026/uni00000055/uni00000052/uni00000056/uni00000056/uni00000003/uni00000028/uni00000051/uni00000057/uni00000055/uni00000052/uni00000053/uni0000005c/uni00000013/uni00000014/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057/uni00000032/uni0000004f/uni00000047
/uni00000031/uni00000048/uni0000005a
/uni00000013/uni00000011/uni00000013 /uni00000013/uni00000011/uni00000018 /uni00000014/uni00000011/uni00000013
/uni00000026/uni00000055/uni00000052/uni00000056/uni00000056/uni00000003/uni00000028/uni00000051/uni00000057/uni00000055/uni00000052/uni00000053/uni0000005c/uni00000013/uni00000014/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057/uni00000032/uni0000004f/uni00000047
/uni00000031/uni00000048/uni0000005a(a) Initial Split (b) Fine Split: the first epoch (c) Fine Split: the second epoch (d) Fine Split: the last epoch
Figure A. The initial split and the fine split results using CUB-200 dataset on ResNet-18. The given dataset is joint unlabeled, and we
separate the dataset into old and novel categories without any prior knowledge
Method Step Novel Classes Mallâ†‘ M0
oâ†‘ M fâ†“ M1
nâ†‘ M2
nâ†‘ M3
nâ†‘ M dâ†‘
GM-CI [44]0th0âˆ¼139 59.51 59.51 - - - - -
1st140âˆ¼159 13.55 13.48 46.03 13.99 - - 13.99
2nd160âˆ¼179 37.32 41.36 18.15 25.43 21.62 - 23.53
3rd180âˆ¼199 35.74 40.44 19.07 27.13 19.93 28.06 25.04
âˆ— - - 19.48 - - - 24.97
0th0âˆ¼159 60.34 60.34 - - - - -
1st160âˆ¼199 7.13 7.28 53.06 6.53 - - 6.53
GM-MI [44]0th0âˆ¼139 26.54 26.54 - - - - -
1st140âˆ¼159 18.70 20.48 6.06 7.51 - - 7.51
2nd160âˆ¼179 19.90 23.24 3.30 6.83 10.14 - 8.49
3rd180âˆ¼199 17.22 20.80 5.74 6.66 8.28 12.24 6.89
0th0âˆ¼159 46.39 46.39 - - - - -
1st160âˆ¼199 6.43 6.57 39.82 5.92 - - 5.92
Ours-CGCD0th0âˆ¼159 74.27 74.27 - - - - -
1st160âˆ¼200 54.75 58.80 15.47 40.90 - - 40.90
Table A. Comparison of GM [44] method evaluation results on the two different scenarios, which are Class incremental scenario (CI)
and Mixed Incremental Scenario (MI) are proposed originally in GM paper. The experiment results exploited the CUB-200 dataset on
ResNet-18. For a fair comparison, we followed the hyperparameters on their report. Nevertheless, GM is underperformed significantly. âˆ—
denotes results reported in the original GM paper and the bold results indicated the reported in the main paper.
since the MdandMfresults were equivalent. The MI sce-
nario is the closest to our proposed scenario CGCD. How-
ever, GM presented significant underperformance in the MI
scenarios, and Mdperformances were recorded at under
10%, particularly in both three-time incremental and one-
time incremental scenarios.
On the other hand, we confirmed outstanding perfor-
mance compared to GM in this experiment, and our pro-
posed method also recorded improved performance in the
two-step incremental scenario reported in the paper.
Following the dataset policy of GM, their given distri-
bution is 7 : 1 : 1 : 1 , and the results using the original
parameters reported in the paper are shown in Table B. As
the step increases, MfandMdrecorded mean values of
24.01and14.92, respectively. But, in our ablations, we
evaluated the policy, 7 : 3. This means that we classify into
joint unlabeled novel data more than three times as GM at
once. Through experiments, we implicitly showed superiorMethod Dataset1st2nd3rd
Mfâ†“ M dâ†‘ M fâ†“ M dâ†‘ M fâ†“ M dâ†‘
GM CUB-200 30.99 12.21 19.86 15.99 21.18 16.56
Table B. GM step-wise results following GMâ€™s original process.
performance.
D. Adopting other deep metric learning
Table C shows the results of replacing PAs with oth-
ers. [6, 37]. We assumed PAs is trained in more valu-
able features for utilizing to split novel and old category
since having both proxy- and anchor-based merits. As well-
separated novel data samples increased, the result showed
Mfdecreased, but Mdimproved. And we confirmed PAs
is to fit our framework.

--- PAGE 13 ---
MethodCUB-200
Mallâ†“ M oâ†‘ M fâ†“ M dâ†‘
ArcFace [6] 53.13 Â±2.76 60.21 Â±3.80 13.52 Â±3.81 28.02 Â±1.39
ProxyNCA++ [37] 53.72 Â±0.85 65.62Â±0.52 8.85 Â±0.52 25.00Â±1.77
Ours 54.75 Â±0.64 58.80Â±0.99 15.47 Â±0.99 40.90Â±1.07
Table C. Ablation study for adopting various deep metric learning.
E. Ours Qualitative Results
To evaluate the proposed method qualitatively, we clus-
tered the evaluation dataset using the CUB-200 dataset. As
shown in Figure B, our method well-discovered old cate-
gories and clustered them correctly. Each row is clusteredinto the same category, and the classes are old categories
on the evaluation dataset. The left five columns are well-
clustered, while the last two are not. The sixth-column im-
ages are still reasonable, but the last-column images are the
worst cases. Figure C depicted the clustered results of the
novel categories discovery. Like the former result, each row
image belongs to the same category. In contrast, the Fig-
ure D presents failure cases. The images on each row indi-
cated that they were clustered into the same class. However,
there are no images with the same label. Nevertheless, the
images on each row have similar features, such as the col-
ors of wings and feathers, and the behaviors. In this sense,
we are hard to recognize that the categorized results failed
without the specialized knowledge of the birdsâ€™ species.

--- PAGE 14 ---
Figure B. Qualitative experiment results of the proposed method. The evaluation is conducted using the CUB-200 dataset on ResNet-18,
and the images belong to the old categories and are also clustered in the old categories. The first five columns with blue boxes denote
well-clustered examples. The last two columns represent failed prediction results, including example images with purple boxes denoting
hard negatives and those with red boxes indicating incorrect categorization.

--- PAGE 15 ---
Figure C. Qualitative experiment results of the proposed method. The evaluation is conducted using the CUB-200 dataset on ResNet-18,
and the images belong to the novel categories and are also clustered in the novel categories. The first five columns with blue boxes denote
well-clustered examples. The last two columns represent failed prediction results, including example images with purple boxes denoting
hard negatives and those with red boxes indicating incorrect categorization.

--- PAGE 16 ---
Figure D. Qualitative experiment results of the proposed method. The evaluation is conducted using the CUB-200 dataset on ResNet-18.
The images on each row have been categorized into the same classes, but it is not true. Nevertheless, the images on each row are hard to
recognize the specific spices without the knowledge of experts. For that reason, we treat the images are hard negative samples.

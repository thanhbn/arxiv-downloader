# 2211.03186.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/continual-learning/2211.03186.pdf
# Kích thước tệp: 155752 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
arXiv:2211.03186v1  [cs.LG]  6 Nov 2022Nội suy Trọng số Dựa trên Momentum của Các Mô hình Zero-Shot Mạnh mẽ cho Học Liên tục
Zafir Stojanovski1,∗, Karsten Roth1,∗, Zeynep Akata1,2
1Đại học Tübingen,2MPI cho Hệ thống Thông minh
Tóm tắt
Các mô hình được huấn luyện trước lớn, có khả năng zero-shot đã cho thấy thành công đáng kể cho cả các tác vụ chuyển giao và thích ứng tiêu chuẩn, với tính bền vững đặc biệt đối với sự dịch chuyển phân phối. Ngoài ra, việc tinh chỉnh tiếp theo có thể cải thiện đáng kể hiệu suất trên một tác vụ hạ lưu được chọn. Tuy nhiên, thông qua việc tinh chỉnh ngây thơ, các mô hình zero-shot này mất đi khả năng tổng quát hóa và tính bền vững đối với sự dịch chuyển phân phối. Đây là một vấn đề đặc biệt đối với các tác vụ như Học Liên tục (CL), trong đó việc thích ứng liên tục phải được thực hiện khi các phân phối tác vụ mới được giới thiệu tuần tự. Trong nghiên cứu này, chúng tôi chứng minh rằng trong khi việc tinh chỉnh không đáp ứng được việc thích ứng các mô hình có khả năng zero-shot như vậy, nội suy trọng số đơn giản dựa trên momentum có thể mang lại những cải thiện nhất quán cho các tác vụ CL trong cả hai thiết lập không có bộ nhớ và có bộ nhớ. Cụ thể, chúng tôi tìm thấy những cải thiện hơn +4% trên các benchmark CL tiêu chuẩn, đồng thời giảm lỗi so với giới hạn trên của việc huấn luyện chung trên tất cả các tác vụ cùng một lúc trong các phần hơn một nửa, cho phép người học liên tục tiếp cận gần hơn đến giới hạn huấn luyện chung.

1 Giới thiệu
Học Liên tục (CL) giải quyết vấn đề học từ một luồng dữ liệu không cố định, nơi dữ liệu huấn luyện được trình bày cho mô hình không phải cùng một lúc, mà chỉ trong một chuỗi, và với khả năng hạn chế để lưu giữ và huấn luyện lại. Điều này không chỉ đòi hỏi việc sử dụng hiệu quả dữ liệu đã thấy trước đó, mà còn cần thích ứng với bối cảnh mới dưới sự dịch chuyển phân phối thay đổi liên tục mà không có quên thảm khốc [11, 34, 35, 36]. Các trường hợp sử dụng rất rộng rãi, từ các ứng dụng đặc biệt hạn chế về tính toán, thời gian hoặc bộ nhớ đến các ứng dụng quan tâm về quyền riêng tư [14, 3, 16, 40, 25].

Do đó, các nghiên cứu trước đã giới thiệu một loạt các phương pháp để giải quyết việc huấn luyện dưới sự dịch chuyển liên tục, chẳng hạn như thông qua việc sử dụng phát lại dữ liệu hiệu quả [7, 3, 1, 28], điều chuẩn trên động học huấn luyện [11, 36] hoặc các thủ tục tối ưu hóa tìm kiếm cực tiểu phẳng [23, 38]. Nói chung, các phương pháp này bắt đầu từ một mô hình chưa được huấn luyện sau đó được thích ứng với luồng dữ liệu hiện có.

Trong khi điều này đã tìm thấy thành công thực tiễn, gần đây việc sử dụng các mô hình được huấn luyện trước quy mô lớn ("mô hình nền tảng" [2, 25]) đã trở nên phổ biến, vì chúng đã cho thấy khả năng tổng quát hóa zero-shot mạnh mẽ cho nhiều tác vụ hạ lưu, với tính bền vững mạnh mẽ đối với sự dịch chuyển phân phối [2]. Việc áp dụng chúng vào tập hợp vấn đề CL, giải quyết sự dịch chuyển phân phối liên tục, là hợp lý, với các nghiên cứu gần đây cho thấy những lợi ích đáng chú ý trong việc sử dụng các mô hình nền tảng [40, 21, 31, 42], đặc biệt làm nổi bật việc giảm quên thảm khốc. Tuy nhiên, khi người học được thích ứng với phân phối huấn luyện dịch chuyển liên tục, ngay cả các mô hình nền tảng cũng sẽ bị quên thông qua việc tinh chỉnh [41].

∗Biểu thị đóng góp bằng nhau.
Hội thảo đầu tiên về Điều chuẩn Nội suy và Hơn thế nữa. Hội nghị lần thứ 36 về Hệ thống Xử lý Thông tin Neural (NeurIPS 2022).

--- TRANG 2 ---
Để tối đa hóa những lợi ích chúng ta có thể trích xuất từ quá trình học liên tục chính cũng như khả năng phân loại các mẫu mới tại thời điểm kiểm tra, do đó điều quan trọng là giảm thiểu tác động đến khả năng tổng quát hóa của mô hình nền tảng được thích ứng để tính đến các thích ứng tiềm năng khác. Để cho phép triển khai được cải thiện trong thiết lập CL, trong nghiên cứu này chúng tôi chỉ ra cách nội suy trọng số dựa trên momentum có thể giúp khắc phục các vấn đề của các mô hình như vậy được thích ứng theo cách liên tục. Cụ thể, vì chúng ta muốn giữ lại tối đa khả năng tổng quát hóa của mô hình nền tảng được thích ứng, chúng tôi giới thiệu một cơ chế thích ứng phân tách bằng cách giữ lại một bản sao bổ sung của mô hình nền tảng ban đầu (được gọi là mô hình chậm). Mô hình chậm này được loại trừ khỏi quá trình tối ưu hóa CL trực tiếp, và chỉ được cập nhật thông qua nội suy momentum tuyến tính với một bản sao mô hình được thích ứng tác vụ (được gọi là mô hình nhanh).

Điều này được thúc đẩy bởi những hiểu biết được đưa ra trong [41], người cho thấy nội suy tuyến tính đơn giản trong không gian trọng số giữa mô hình zero-shot gốc và một biến thể được tinh chỉnh cho một tác vụ hiện có cho phép thích ứng, đồng thời giữ lại khả năng tổng quát hóa tốt hơn so với việc chỉ tinh chỉnh. Tuy nhiên, việc giữ lại một bộ sưu tập lớn các mô hình chuyên gia tác vụ được tinh chỉnh trong thiết lập CL tốn nhiều bộ nhớ, không thực tế và không mong muốn. Thay vào đó, chúng tôi chỉ ra rằng chúng ta có thể mô phỏng những lợi ích thực nghiệm được làm nổi bật trong [41] thông qua nội suy momentum lặp lại giữa mô hình nền tảng của chúng ta và một biến thể được tinh chỉnh liên tục. Điều này cho phép chúng ta tránh những nhược điểm của việc tinh chỉnh thuần túy, đồng thời cả việc chuyên môn hóa trên luồng tác vụ mới và giữ lại khả năng tổng quát hóa của mô hình nền tảng.

Thật vậy, các thí nghiệm trên ba benchmark CL tiêu chuẩn (Seq-CIFAR-10, Seq-CIFAR-100 và Seq-Tiny-ImageNet) cho thấy những cải thiện trong thiết lập tăng dần lớp và tác vụ trên cả phương pháp dựa trên bộ nhớ và không có bộ nhớ lên đến +4%, và một phần hơn một nửa giảm lỗi so với giới hạn hiệu suất huấn luyện chung. Những kết quả này cho thấy rằng đối với việc sử dụng thực tế các mô hình nền tảng trong một kịch bản huấn luyện dịch chuyển phân phối liên tục, nội suy trọng số dựa trên momentum có thể là một công cụ đáng tin cậy cho những cải thiện nhất quán hoạt động tốt cùng với bất kỳ phương pháp CL nào.

2 Nghiên cứu Liên quan
Các phương pháp dựa trên điều chuẩn bổ sung mục tiêu huấn luyện để giảm thiểu quên bằng cách giữ các tham số hiện tại gần với các tham số tác vụ trước đó, chẳng hạn như thông qua khớp moment [15] hoặc Elastic Weight Consolidation (EWC) [12], thực hiện các xấp xỉ Laplace trên posterior tham số cho mỗi tác vụ trước, sử dụng các mean và covariance để điều chuẩn các tham số hiện tại thông qua việc giảm thiểu khoảng cách Mahalanobis. Online Elastic Weight Consolidation (oEWC)[36] tính toán trung bình momentum của một ma trận covariance duy nhất, và chỉ giữ các tham số từ tác vụ cuối cùng. Learning without Forgetting (LwF)[17] cũng giữ các tham số từ tác vụ cuối cùng và thêm một thuật ngữ cross-entropy giữa các logit được tính toán với các tham số cũ và hiện tại, sử dụng dữ liệu từ tác vụ hiện tại. [22] chỉ ra rằng dropout buộc mô hình học một cơ chế cổng sao cho đối với các tác vụ khác nhau, các đường dẫn khác nhau của mạng được kích hoạt.

Các phương pháp dựa trên rehearsal sử dụng Experience Replay [32] [33] bằng cách lưu trữ một tập con nhỏ của dữ liệu huấn luyện vào một buffer, và liên tục phát lại nó khi mô hình chuyển sang học các tác vụ mới. Dark Experience Replay (DER) [4] giới thiệu điều chuẩn trong sơ đồ rehearsal bằng cách khớp các logit của quá khứ với các logit được tính toán bởi các tham số mạng hiện tại. Gradient Episodic Memory (GEM) [18] và Average Gradient Episodic Memory (A-GEM) [8] thực thi các ràng buộc tối ưu hóa trong tác vụ hiện tại sử dụng dữ liệu từ các tác vụ trước. GDumb [29] lưu trữ các mẫu một cách tham lam trong bộ nhớ, và chỉ huấn luyện mô hình tại thời điểm kiểm tra sử dụng dữ liệu buffer. DualNet [27] sử dụng một mạng chậm để học các đặc trưng bất biến tác vụ thông qua Học Tự giám sát, và một mạng nhanh để học các đặc trưng đặc thù tác vụ. Contrastive Continual Learning (Co2L) [5] học các đặc trưng bất biến tác vụ tương phản, và huấn luyện một bộ phân loại tuyến tính chỉ sử dụng dữ liệu buffer. Cách tiếp cận của chúng tôi cũng có những điểm tương đồng về mặt khái niệm với kiểu tối ưu hóa lookahead (xem ví dụ [43]), được thích ứng với vấn đề học liên tục.

Các phương pháp tìm kiếm tính phẳng nhắm mục tiêu hoạt động trong các vùng cực tiểu phẳng cho mỗi tác vụ trong chuỗi, từ đó giữ lại hiệu suất trước đó. Finding Flat Minima (F2M) [39] độc lập thêm nhiễu ngẫu nhiên nhỏ vào các tham số, từ đó thu được các hàm mất mát tương tự nhưng khác nhau được tối ưu hóa cùng nhau để định vị các cực tiểu phẳng. [24] nghiên cứu cách kích thước batch, dropout và suy giảm tốc độ học ảnh hưởng đến khả năng tìm các basin phẳng của mô hình. [20] sử dụng thủ tục Sharpness-Aware Minimization (SAM) [9], tối ưu hóa một cách rõ ràng cho các tham số nằm trong các basin phẳng.

3 Phương pháp
Trong CL, một mô hình fθ được huấn luyện trên một chuỗi T tác vụ, trong đó đối với mỗi tác vụ t∈{1,...,T} người học chỉ có quyền truy cập vào một tập con mẫu Dt={(xi,yi)}Nt
i=1, nhưng cuối cùng được đánh giá trên hiệu suất chung, tức là chúng ta tối ưu hóa
θ∗= argminθ/summationtextT
t=1E(x,y)∼Dt[L(fθ(x),y)].
Thách thức chính là tại tác vụ t, mô hình không có quyền truy cập vào dữ liệu từ các tác vụ trước ˜t∈
{1,...,t−1}, do đó vi phạm giả định dữ liệu IID điển hình. Trong nghiên cứu này, chúng tôi điều tra cả thiết lập tăng dần lớp, nơi các tập con lớp được giới thiệu theo chuỗi, và thiết lập tăng dần tác vụ dễ hơn nhiều cũng cung cấp các id tác vụ tương ứng.

3.1 Nội suy Trọng số Dựa trên Momentum cho Học Liên tục (MCL)
Để cho phép thích ứng hiệu quả và liên tục của các mô hình nền tảng, chúng tôi giới thiệu nội suy trọng số dựa trên momentum cho CL. Vì mục tiêu chính của chúng ta là giữ lại khả năng tổng quát hóa và tính bền vững dịch chuyển của mô hình nền tảng cơ bản, điều quan trọng là việc thích ứng và tinh chỉnh tối thiểu được thực hiện, đồng thời vẫn cho phép một mức độ thích ứng nhất định với các tác vụ mục tiêu hiện có. Đối với điều đó, chúng tôi đề xuất giữ lại một bản sao mô hình chậm θslow được giữ ngắt kết nối khỏi toàn bộ quá trình thích ứng, trong khi một bản sao thứ hai θfast được cập nhật trong suốt quá trình học liên tục. Khi θfast thích ứng với phân phối mục tiêu hiện có, tại mỗi lần lặp chúng ta đồng thời thực hiện một cập nhật lặp lại trên các trọng số chậm của chúng ta thông qua nội suy không gian trọng số:
θslow=τ·θslow+(1−τ)·θfast
trong đó τ là siêu tham số momentum của chúng ta. Một phiên bản đơn giản của thủ tục được tóm tắt trong Thuật toán 1. Vì cơ chế này bất biến tác vụ và bộ nhớ không phụ thuộc vào ranh giới tác vụ, nó có thể được áp dụng cho bất kỳ framework học liên tục nào, cả dựa trên bộ nhớ và không có bộ nhớ. Và trong khi đơn giản và đơn giản, việc giữ lại trọng số mô hình nền tảng tốt hơn một cách trực quan trong thiết lập học liên tục được thúc đẩy tốt.

Ngoài kết nối khái niệm với lý thuyết Complementary Learning Systems (CLS) [19, 6] từ khoa học thần kinh mô tả học liên tục của con người như một sự tương tác của một hệ thống thích ứng nhanh và một hệ thống giữ lại chậm, trên mức độ phương pháp luận [10] chỉ ra rằng việc duy trì trung bình chạy của trọng số dẫn đến các optima rộng hơn và giữ lại tổng quát hóa trong quá trình tinh chỉnh tiêu chuẩn của một mô hình được huấn luyện trước.

Ngoài ra, [41] cho thấy rằng trọng số mô hình zero-shot và được tinh chỉnh thường được kết nối bởi một đường dẫn tuyến tính giữ lại hiệu suất. Do đó, việc nội suy tuyến tính dựa trên momentum của chúng ta qua các lần lặp tác vụ cho phép chúng ta kết nối với hiệu suất của biến thể nhanh được thích ứng tác vụ, đồng thời duy trì khả năng tổng quát hóa của trọng số mô hình nền tảng θslow. Việc tối ưu hóa ngầm được duy trì do đó cho một cực tiểu phẳng hơn xung quanh θslow, chỉ được cập nhật thông qua nội suy dựa trên momentum, có mối liên hệ mạnh mẽ với việc cải thiện tổng quát hóa qua các chuỗi tác vụ trong học liên tục [39, 24, 9], mà chúng ta thấy phản ánh trong các thí nghiệm benchmark của chúng ta trong phần tiếp theo.

4 Thí nghiệm
Bộ dữ liệu. Chúng tôi đánh giá phương pháp của mình trên ba bộ dữ liệu thường được sử dụng trong tài liệu: CIFAR-10 [13], CIFAR-100 [13], và Tiny ImageNet. Chúng tôi chia mỗi bộ dữ liệu thành nhiều tác vụ của các lớp không chồng lấp: Seq-CIFAR-10 bao gồm 5 tác vụ (mỗi tác vụ 2 lớp) và Seq-CIFAR-100/Seq-Tiny-ImageNet bao gồm 10 tác vụ (lần lượt 10 và 20 lớp mỗi tác vụ).

--- TRANG 3 ---
Thuật toán 1 Nội suy Trọng số Dựa trên Momentum cho Học Liên tục (MCL)
Yêu cầu: Trọng số được huấn luyện trước θpre, Momentum τ∈[0,1]
1:θfast←θpre
2:θslow←θpre
3:for t←1. . . num_tasks do
4: for e←1. . . num_epochs do
5: for (x,y)∼Dt do
6: θfast←θfast−α∇L(fθfast(x),y)
7: θslow←τ·θslow+(1−τ)·θfast
8: end for
9: end for
10:end for
11:θfast←θslow

Huấn luyện. Đối với mô hình zero-shot của chúng tôi, chúng tôi sử dụng CLIP ViT-B/16 được huấn luyện trước [30]. Chúng tôi xây dựng các thí nghiệm CL của mình trên [4] thực hiện nhiều benchmark CL trong PyTorch [26]. Tất cả các phương pháp tuân theo một giao thức huấn luyện được tiêu chuẩn hóa - được huấn luyện trên Nvidia 2080Ti sử dụng SGD [37], tốc độ học cố định và không có scheduler, với cùng ngân sách tinh chỉnh 10 epoch. Chúng tôi thực hiện tìm kiếm lưới trên một tập con huấn luyện ngẫu nhiên để chọn tốc độ học tốt nhất α∈{10−2,10−3,10−4,10−5,10−6,10−7} cũng như cường độ momentum tốt nhất τ∈{0.995,0.997,0.999,0.9995,0.9997,0.9999}. Chúng tôi giới thiệu người đọc đến phụ lục (§A.1) cho một nghiên cứu ablation về các siêu tham số.

Đánh giá. Đối với cả hai kịch bản Task Incremental Learning (Task-IL) và Class Incremental Learning (Class-IL), chúng tôi báo cáo độ chính xác phân loại cuối cùng trên tất cả các lớp gặp phải, với danh tính tác vụ cũng được cung cấp trong thiết lập Task-IL (làm cho nó trở thành một vấn đề dễ giải quyết hơn đáng chú ý).

Bảng 1: Baseline
Baseline CIFAR-10 CIFAR-100 Tiny-ImageNet
ZERO-SHOT 88.77 63.11 58.53
JOINT 97.53±0.08 87.22±0.54 78.86±1.38

4.1 Kết quả Thí nghiệm
Trong phần này, chúng tôi thí nghiệm với việc sử dụng nội suy trọng số dựa trên momentum trong ba danh mục phương pháp CL tiêu chuẩn: tinh chỉnh (SGD thuần túy [37]), dựa trên điều chuẩn (oEWC [36]), và dựa trên rehearsal (DER++ [4] với kích thước buffer 500 và 5000).

Các kết quả trình bày dưới đây được thu được trên ba seed, cùng với đó chúng tôi cung cấp giới hạn dưới zero-shot (Tab. 1). Thú vị là, hiệu suất zero-shot không được thích ứng đã một phần vượt xa so với thích ứng tương đương với các phương pháp hiện đại không dựa vào mô hình nền tảng, với ví dụ DER++ [4] báo cáo 72.70±1.36% với buffer 500, và 85.40±0.49% với buffer 5000 trên CIFAR-10, trong khi hiệu suất zero-shot của mô hình nền tảng đã đạt 88.77%. Sự khác biệt này thậm chí còn được phóng đại hơn nữa trên Tiny-ImageNet, với 19.38±1.41% và 39.02±0.97 cho kích thước buffer lần lượt là 500 và 5000, so với 58.53% cho hiệu suất zero-shot, xác minh tiềm năng [21, 31] của các mô hình nền tảng trong CL.

Để cung cấp một giới hạn trên, chúng tôi huấn luyện trên tất cả các tác vụ cùng nhau (Tab. 1). Vì huấn luyện chung được đánh giá mà không có ranh giới tác vụ, giới hạn trên này không áp dụng cho các kịch bản Task-IL. Tiếp theo, trong Tab. 2 chúng tôi trình bày kết quả trên các benchmark CL. Chúng tôi chứng minh bằng thực nghiệm rằng, như được thúc đẩy trong Phần 3, việc giữ một phiên bản được nội suy momentum của mô hình nền tảng dẫn đến những cải thiện nhất quán.

Cụ thể, kết quả của chúng tôi cho thấy rằng thích ứng với phân phối tác vụ hiện có là có lợi ngay cả với việc tinh chỉnh đơn giản. Ngay cả khi tính đến thay đổi tốc độ học (như đã lưu ý trong §4 và được thực hiện cho mọi baseline), chúng tôi thấy rằng nội suy trọng số dựa trên momentum bổ sung mang lại lợi ích nhất quán trong cả thiết lập tăng dần lớp và tác vụ, với cải thiện gần +4% trên cả Seq-CIFAR-100 và Seq-Tiny-ImageNet. Hơn nữa, thông qua cập nhật momentum, chúng ta có thể đẩy việc tinh chỉnh đơn giản gần hoặc thậm chí vượt hiệu suất của một framework CL hiện đại (DER++).

--- TRANG 4 ---
Bảng 2: Thiết lập Học Liên tục – huấn luyện và đánh giá trên các chuỗi tác vụ.
Phương pháp Momentum Seq-CIFAR-10 Seq-CIFAR-100 Seq-Tiny-ImageNet
Class-IL Task-IL Class-IL Task-IL Class-IL Task-IL
SGD không 91.38±0.04 98.17±0.01 74.36±0.03 93.59±0.04 67.30±0.08 82.12±0.07
có 92.46±0.11 98.43±0.01 77.52±0.37 94.98±0.17 71.09±0.28 85.22±0.32
oEWC không 90.67±0.01 98.17±0.01 74.07±0.20 93.80±0.02 66.60±0.02 81.79±0.02
có 91.87±0.57 98.88±0.12 77.25±0.31 95.09±0.01 71.57±0.05 85.94±0.07
DER++ (500) không 94.65±0.16 99.38±0.10 76.68±0.23 95.05±0.09 71.05±0.12 84.42±0.22
có 95.73±0.21 99.50±0.04 82.01±0.31 96.69±0.03 75.11±0.02 87.80±0.27
DER++ (5000) không 97.08±0.04 99.60±0.01 83.16±0.20 97.03±0.11 76.54±0.10 88.44±0.04
có 97.21±0.11 99.62±0.01 84.94±0.07 97.13±0.05 78.26±0.14 89.00±0.11

Ngoài ra, chúng tôi quan sát những cải thiện hiệu suất tương tự ngay cả khi được áp dụng trên các framework CL riêng biệt, cả không có bộ nhớ (oEWC, ví dụ 74.07±0.20→77.25±0.31 trên Seq-CIFAR-100) và dựa trên bộ nhớ (DER++ với 500 mẫu bộ nhớ, 76.78±0.23→82.01±0.31).

Thú vị là, DER++ mở rộng momentum với kích thước buffer 500 cũng gần như thu hẹp khoảng cách hiệu suất so với DER++ không có momentum với kích thước buffer lớn hơn nhiều 5000, thậm chí với bộ nhớ lớn như vậy, cũng thấy những cải thiện đáng kể trên các tác vụ CL phức tạp hơn đặc biệt (Seq-Tiny-ImageNet, 76.54±0.10→78.26±0.14).

Điều này chứng minh rằng nhu cầu về kích thước buffer trong các framework CL được xây dựng xung quanh các mô hình nền tảng có thể giảm đáng kể (trong trường hợp này, gấp 10 lần) thông qua nội suy không gian trọng số dựa trên momentum. Chúng tôi lưu ý rằng trong khi không cần thiết cho các benchmark hiện có, chuỗi tác vụ dài hơn có thể được hưởng lợi từ việc đồng bộ hóa lại θslow và θfast.

Cuối cùng, chúng tôi thấy rằng DER++ dựa trên momentum với buffer 5000 thậm chí còn thu hẹp thêm khoảng cách đến giới hạn trên tối ưu hóa chung - nhìn vào lỗi, chúng tôi thấy một sự giảm 0.45%→0.32% trên Seq-CIFAR-10, 4.06%→2.28% trên Seq-CIFAR-100, và 2.32%→0.6% trên Seq-Tiny-ImageNet, đánh dấu một sự giảm gần 75%. Kết luận, những kết quả này cho thấy những lợi ích đáng kể của việc giữ lại một bản sao mô hình được cập nhật momentum khi giới thiệu các mô hình nền tảng vào thiết lập CL, cả cho những cải thiện tương đối nhất quán, mà còn để giảm thiểu sự sụt giảm hiệu suất khi chuyển từ tối ưu hóa chung tiêu chuẩn sang một kịch bản học liên tục.

5 Kết luận
Nghiên cứu này giải quyết việc thích ứng các mô hình zero-shot được huấn luyện trước quy mô lớn cho học liên tục (CL). Để giữ lại khả năng tổng quát hóa mạnh mẽ và tính bền vững của các mô hình này ngay cả dưới việc tinh chỉnh liên tục, chúng tôi đề xuất việc sử dụng nội suy dựa trên momentum giữa một mô hình zero-shot chuyển động chậm được loại trừ khỏi quá trình CL trực tiếp và một biến thể nhanh được thích ứng tác vụ. Thông qua phần mở rộng đơn giản này, chúng tôi thấy những cải thiện nhất quán trong hiệu suất trên ba benchmark CL tiêu chuẩn (Seq-CIFAR-10, Seq-CIFAR-100, Seq-Tiny-ImageNet) trên cả các cách tiếp cận dựa trên bộ nhớ và không có bộ nhớ, trong các phần hơn +4%. Ngoài ra, chúng tôi thấy khoảng cách giữa hiệu suất học liên tục và tối ưu hóa tác vụ chung trong một số trường hợp thậm chí được giảm hơn một nửa. Dựa trên những hiểu biết này, khả năng tổng quát hóa của các mô hình zero-shot được huấn luyện trước quy mô lớn, và sự đơn giản của thiết lập được đề xuất, chúng tôi tin rằng việc áp dụng cách tiếp cận của chúng tôi có ý nghĩa thực tiễn cao.

Lời cảm ơn
Karsten Roth cảm ơn Trường Nghiên cứu Quốc tế Max Planck cũng như chương trình Tiến sĩ Phòng thí nghiệm Châu Âu về Học và Hệ thống Thông minh (ELLIS) đã hỗ trợ. Zeynep Akata thừa nhận tài trợ một phần từ ERC (853489 - DEXIM) và DFG (2065/1 - Số dự án 390727645) dưới Chiến lược Xuất sắc của Đức.

Tài liệu tham khảo
[1] Jihwan Bang, Heesu Kim, YoungJoon Yoo, Jung-Woo Ha, và Jonghyun Choi. Rainbow memory: Continual learning with a memory of diverse samples. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), trang 8218–8227, tháng 6 năm 2021.

[2] Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S. Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, Erik Brynjolfsson, Shyamal Buch, Dallas Card, Rodrigo Castellon, Niladri Chatterji, Annie Chen, Kathleen Creel, Jared Quincy Davis, Dora Demszky, Chris Donahue, Moussa Doumbouya, Esin Durmus, Stefano Ermon, John Etchemendy, Kawin Ethayarajh, Li Fei-Fei, Chelsea Finn, Trevor Gale, Lauren Gillespie, Karan Goel, Noah Goodman, Shelby Grossman, Neel Guha, Tatsunori Hashimoto, Peter Henderson, John Hewitt, Daniel E. Ho, Jenny Hong, Kyle Hsu, Jing Huang, Thomas Icard, Saahil Jain, Dan Jurafsky, Pratyusha Kalluri, Siddharth Karamcheti, Geoff Keeling, Fereshte Khani, Omar Khattab, Pang Wei Koh, Mark Krass, Ranjay Krishna, Rohith Kuditipudi, Ananya Kumar, Faisal Ladhak, Mina Lee, Tony Lee, Jure Leskovec, Isabelle Levent, Xiang Lisa Li, Xuechen Li, Tengyu Ma, Ali Malik, Christopher D. Manning, Suvir Mirchandani, Eric Mitchell, Zanele Munyikwa, Suraj Nair, Avanika Narayan, Deepak Narayanan, Ben Newman, Allen Nie, Juan Carlos Niebles, Hamed Nilforoshan, Julian Nyarko, Giray Ogut, Laurel Orr, Isabel Papadimitriou, Joon Sung Park, Chris Piech, Eva Portelance, Christopher Potts, Aditi Raghunathan, Rob Reich, Hongyu Ren, Frieda Rong, Yusuf Roohani, Camilo Ruiz, Jack Ryan, Christopher Ré, Dorsa Sadigh, Shiori Sagawa, Keshav Santhanam, Andy Shih, Krishnan Srinivasan, Alex Tamkin, Rohan Taori, Armin W. Thomas, Florian Tramèr, Rose E. Wang, William Wang, Bohan Wu, Jiajun Wu, Yuhuai Wu, Sang Michael Xie, Michihiro Yasunaga, Jiaxuan You, Matei Zaharia, Michael Zhang, Tianyi Zhang, Xikun Zhang, Yuhui Zhang, Lucia Zheng, Kaitlyn Zhou, và Percy Liang. Về các cơ hội và rủi ro của các mô hình nền tảng, 2021.

[3] Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, và Simone Calderara. Dark experience for general continual learning: a strong, simple baseline. Trong H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, và H. Lin, biên tập viên, Advances in Neural Information Processing Systems, tập 33, trang 15920–15930. Curran Associates, Inc., 2020.

[4] Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, và SIMONE CALDERARA. Dark experience for general continual learning: a strong, simple baseline. Trong H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, và H. Lin, biên tập viên, Advances in Neural Information Processing Systems, tập 33, trang 15920–15930. Curran Associates, Inc., 2020.

[5] Hyuntak Cha, Jaeho Lee, và Jinwoo Shin. Co2l: Contrastive continual learning. Trong Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), trang 9516–9525, tháng 10 năm 2021.

[6] Hyuntak Cha, Jaeho Lee, và Jinwoo Shin. Co2l: Contrastive continual learning. Trong Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), trang 9516–9525, tháng 10 năm 2021.

[7] Arslan Chaudhry, Marc'Aurelio Ranzato, Marcus Rohrbach, và Mohamed Elhoseiny. Efficient lifelong learning with a-gem. Trong ICLR, 2019.

[8] Arslan Chaudhry, Marc'Aurelio Ranzato, Marcus Rohrbach, và Mohamed Elhoseiny. Efficient lifelong learning with a-GEM. Trong International Conference on Learning Representations, 2019.

[9] Pierre Foret, Ariel Kleiner, Hossein Mobahi, và Behnam Neyshabur. Sharpness-aware minimization for efficiently improving generalization. Trong International Conference on Learning Representations, 2021.

[10] Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, và Andrew Gordon Wilson. Averaging weights leads to wider optima and better generalization. arXiv preprint arXiv:1803.05407, 2018.

[11] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, và Raia Hadsell. Overcoming catastrophic forgetting in neural networks. Proceedings of the National Academy of Sciences, 114(13):3521–3526, 2017.

[12] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, và Raia Hadsell. Overcoming catastrophic forgetting in neural networks. Proceedings of the National Academy of Sciences, 114(13):3521–3526, 2017.

[13] Alex Krizhevsky. Learning multiple layers of features from tiny images. Báo cáo kỹ thuật, 2009.

[14] Cecilia Lee và Aaron Lee. Clinical applications of continual learning machine learning. The Lancet Digital Health, 2:e279–e281, 06 2020.

[15] Sang-Woo Lee, Jin-Hwa Kim, Jaehyun Jun, Jung-Woo Ha, và Byoung-Tak Zhang. Overcoming catastrophic forgetting by incremental moment matching. Trong I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, và R. Garnett, biên tập viên, Advances in Neural Information Processing Systems, tập 30. Curran Associates, Inc., 2017.

[16] Timothée Lesort, Oleksiy Ostapenko, Diganta Misra, Md Rifat Arefin, Pau Rodríguez, Laurent Charlin, và Irina Rish. Scaling the number of tasks in continual learning, 2022.

[17] Zhizhong Li và Derek Hoiem. Learning without forgetting. IEEE Transactions on Pattern Analysis and Machine Intelligence, 40(12):2935–2947, 2018.

[18] David Lopez-Paz và Marc' Aurelio Ranzato. Gradient episodic memory for continual learning. Trong I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, và R. Garnett, biên tập viên, Advances in Neural Information Processing Systems, tập 30. Curran Associates, Inc., 2017.

[19] J. L. McClelland, B. L. McNaughton, và R. C. O'Reilly. Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory. Psychol Rev, 102(3):419–457, tháng 7 năm 1995.

--- TRANG 5 ---
[20] Sanket Vaibhav Mehta, Darshan Patil, Sarath Chandar, và Emma Strubell. An empirical investigation of the role of pre-training in lifelong learning. arXiv preprint arXiv:2112.09153, 2021.

[21] Sanket Vaibhav Mehta, Darshan Patil, Sarath Chandar, và Emma Strubell. An empirical investigation of the role of pre-training in lifelong learning, 2022.

[22] Seyed Iman Mirzadeh, Mehrdad Farajtabar, và Hassan Ghasemzadeh. Dropout as an implicit gating mechanism for continual learning. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, tháng 6 năm 2020.

[23] Seyed Iman Mirzadeh, Mehrdad Farajtabar, Razvan Pascanu, và Hassan Ghasemzadeh. Understanding the role of training regimes in continual learning. Trong H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, và H. Lin, biên tập viên, Advances in Neural Information Processing Systems, tập 33, trang 7308–7320. Curran Associates, Inc., 2020.

[24] Seyed Iman Mirzadeh, Mehrdad Farajtabar, Razvan Pascanu, và Hassan Ghasemzadeh. Understanding the role of training regimes in continual learning. Trong H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, và H. Lin, biên tập viên, Advances in Neural Information Processing Systems, tập 33, trang 7308–7320. Curran Associates, Inc., 2020.

[25] Oleksiy Ostapenko, Timothee Lesort, Pau Rodríguez, Md Rifat Arefin, Arthur Douillard, Irina Rish, và Laurent Charlin. Continual learning with foundation models: An empirical study of latent replay, 2022.

[26] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, và Soumith Chintala. Pytorch: An imperative style, high-performance deep learning library. Trong H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, và R. Garnett, biên tập viên, Advances in Neural Information Processing Systems 32, trang 8024–8035. Curran Associates, Inc., 2019.

[27] Quang Pham, Chenghao Liu, và Steven Hoi. Dualnet: Continual learning, fast and slow. Trong M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, và J. Wortman Vaughan, biên tập viên, Advances in Neural Information Processing Systems, tập 34, trang 16131–16144. Curran Associates, Inc., 2021.

[28] Ameya Prabhu, Philip Torr, và Puneet Dokania. Gdumb: A simple approach that questions our progress in continual learning. Trong The European Conference on Computer Vision (ECCV), tháng 8 năm 2020.

[29] Ameya Prabhu, Philip Torr, và Puneet Dokania. Gdumb: A simple approach that questions our progress in continual learning. Trong The European Conference on Computer Vision (ECCV), tháng 8 năm 2020.

[30] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, và Ilya Sutskever. Learning transferable visual models from natural language supervision. Trong Marina Meila và Tong Zhang, biên tập viên, Proceedings of the 38th International Conference on Machine Learning, tập 139 của Proceedings of Machine Learning Research, trang 8748–8763. PMLR, 18–24 tháng 7 năm 2021.

[31] Vinay Venkatesh Ramasesh, Aitor Lewkowycz, và Ethan Dyer. Effect of scale on catastrophic forgetting in neural networks. Trong International Conference on Learning Representations, 2022.

[32] R. Ratcliff. Connectionist models of recognition memory: constraints imposed by learning and forgetting functions. Psychol Rev, 97(2):285–308, tháng 4 năm 1990.

[33] ANTHONY ROBINS. Catastrophic forgetting, rehearsal and pseudorehearsal. Connection Science, 7(2):123–146, 1995.

[34] Andrei A. Rusu, Neil C. Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, và Raia Hadsell. Progressive neural networks. CoRR, abs/1606.04671, 2016.

[35] Jonathan Schwarz, Wojciech Czarnecki, Jelena Luketina, Agnieszka Grabska-Barwinska, Yee Whye Teh, Razvan Pascanu, và Raia Hadsell. Progress & compress: A scalable framework for continual learning. Trong Jennifer Dy và Andreas Krause, biên tập viên, Proceedings of the 35th International Conference on Machine Learning, tập 80 của Proceedings of Machine Learning Research, trang 4528–4537. PMLR, 10–15 tháng 7 năm 2018.

[36] Jonathan Schwarz, Wojciech Czarnecki, Jelena Luketina, Agnieszka Grabska-Barwinska, Yee Whye Teh, Razvan Pascanu, và Raia Hadsell. Progress and compress: A scalable framework for continual learning. Trong Jennifer Dy và Andreas Krause, biên tập viên, Proceedings of the 35th International Conference on Machine Learning, tập 80 của Proceedings of Machine Learning Research, trang 4528–4537. PMLR, 10–15 tháng 7 năm 2018.

[37] Ohad Shamir và Tong Zhang. Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes. Trong Sanjoy Dasgupta và David McAllester, biên tập viên, Proceedings of the 30th International Conference on Machine Learning, tập 28 của Proceedings of Machine Learning Research, trang 71–79, Atlanta, Georgia, USA, 17–19 tháng 6 năm 2013. PMLR.

[38] Guangyuan SHI, Jiaxin Chen, Wenlong Zhang, Li-Ming Zhan, và Xiao-Ming Wu. Overcoming catastrophic forgetting in incremental few-shot learning by finding flat minima. Trong A. Beygelzimer, Y. Dauphin, P. Liang, và J. Wortman Vaughan, biên tập viên, Advances in Neural Information Processing Systems, 2021.

[39] Guangyuan SHI, JIAXIN CHEN, Wenlong Zhang, Li-Ming Zhan, và Xiao-Ming Wu. Overcoming catastrophic forgetting in incremental few-shot learning by finding flat minima. Trong M. Ranzato, A. Beygelzimer,

--- TRANG 6 ---
Y. Dauphin, P.S. Liang, và J. Wortman Vaughan, biên tập viên, Advances in Neural Information Processing Systems, tập 34, trang 6747–6761. Curran Associates, Inc., 2021.

[40] Zifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang, Ruoxi Sun, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer Dy, và Tomas Pfister. Learning to prompt for continual learning, 2022.

[41] Mitchell Wortsman, Gabriel Ilharco, Jong Wook Kim, Mike Li, Simon Kornblith, Rebecca Roelofs, Raphael Gontijo Lopes, Hannaneh Hajishirzi, Ali Farhadi, Hongseok Namkoong, và Ludwig Schmidt. Robust fine-tuning of zero-shot models. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), trang 7959–7971, tháng 6 năm 2022.

[42] Tongtong Wu, Massimo Caccia, Zhuang Li, Yuan-Fang Li, Guilin Qi, và Gholamreza Haffari. Pretrained language model in continual learning: A comparative study. Trong International Conference on Learning Representations, 2022.

[43] Michael Zhang, James Lucas, Jimmy Ba, và Geoffrey E Hinton. Lookahead optimizer: k steps forward, 1 step back. Trong H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, và R. Garnett, biên tập viên, Advances in Neural Information Processing Systems, tập 32. Curran Associates, Inc., 2019.

--- TRANG 7 ---
A Phụ lục

Hình 1: Ảnh hưởng của siêu tham số τ đối với Độ chính xác Class-IL

A.1 Nghiên cứu Ablation
Cường độ momentum. Trong Hình 1 chúng tôi chỉ ra cách cường độ momentum τ ảnh hưởng đến Độ chính xác Class-IL của mô hình. Trong khi chúng tôi thấy rằng giá trị tối ưu của τ phụ thuộc vào bộ dữ liệu, điều đáng khích lệ là các phương pháp rất khác nhau cho thấy hành vi tương tự đáng ngạc nhiên đối với một bộ dữ liệu nhất định.

Tần suất khởi động lại. Tiếp theo, chúng tôi kiểm tra xem có lợi hay không khi khởi động lại trọng số nhanh θfast với trọng số chậm θslow trong quá trình huấn luyện (thay vì chỉ ở cuối như mặc định, tức là Dòng 11 trong Thuật toán 1). Để làm điều này, chúng tôi giới thiệu một siêu tham số mới tần suất khởi động lại chỉ định sau bao nhiêu bước gradient chúng ta thực hiện một lần khởi động lại. Từ các kết quả chi tiết trong Hình 2, chúng tôi thấy rằng việc khởi động lại trọng số nhanh không có lợi cho hiệu suất tổng quát hóa.

Hình 2: Ảnh hưởng của việc khởi động lại trọng số nhanh với trọng số chậm ở các tần suất khởi động lại khác nhau.

Tần suất cập nhật. Cuối cùng, chúng tôi kiểm tra xem có lợi hay không khi thực hiện cập nhật trọng số chậm (Dòng 7 trong Thuật toán 1) ở các tần suất khác nhau. Cho mục đích này, chúng tôi giới thiệu một siêu tham số mới tần suất cập nhật chỉ định sau bao nhiêu bước gradient chúng ta cập nhật trọng số chậm. Từ các kết quả được tóm tắt trong Hình 3, chúng tôi thấy rằng việc cập nhật ở tần suất cao hơn 1 (trong đó 1 là hành vi mặc định của thuật toán của chúng tôi) không cung cấp sự tăng hiệu suất.

Hình 3: Ảnh hưởng của việc tính toán cập nhật momentum ở các tần suất cập nhật khác nhau.

# 2209.07529.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/continual-learning/2209.07529.pdf
# Kích thước tệp: 1138071 byte

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Được xuất bản dưới dạng bài báo hội nghị tại ICLR 2023
VỀ MẠNG CON MỀM CHO
HỌC TĂNG CƯỜNG LỚP VỚI ÍT MẪU
Haeyong Kang, Jaehong Yoon, Sultan Rizky Madjid, Sung Ju Hwang, và Chang D. Yoo
Viện Khoa học và Công nghệ Tiên tiến Hàn Quốc (KAIST)
291 Daehak-ro, Yuseong-gu, Daejeon
fhaeyong.kang,jaehong.yoon,suulkyy,sjhwang82,cd yoog@kaist.ac.kr

TÓM TẮT
Lấy cảm hứng từ Giả thuyết Vé Số Có Quy Tắc, trong đó phát biểu rằng các mạng con cạnh tranh mượt mà (không nhị phân) tồn tại trong một mạng dày đặc, chúng tôi đề xuất một phương pháp học tăng cường lớp với ít mẫu được gọi là Mạng Con Mềm (SoftNet). Mục tiêu của chúng tôi là học một chuỗi các phiên một cách tăng cường, trong đó mỗi phiên chỉ bao gồm một vài thực thể huấn luyện cho mỗi lớp trong khi vẫn bảo toàn kiến thức của những phiên đã học trước đó. SoftNet học đồng thời các trọng số mô hình và các mặt nạ mềm không nhị phân thích ứng tại một phiên huấn luyện cơ sở trong đó mỗi mặt nạ bao gồm mạng con chính và mạng con phụ; mạng con trước nhằm mục đích giảm thiểu quên thảm khốc trong quá trình huấn luyện, và mạng con sau nhằm mục đích tránh overfitting với một vài mẫu trong mỗi phiên huấn luyện mới. Chúng tôi cung cấp các xác nhận thực nghiệm toàn diện chứng minh rằng SoftNet của chúng tôi giải quyết hiệu quả vấn đề học tăng cường với ít mẫu bằng cách vượt qua hiệu suất của các phương pháp cơ sở tiên tiến trên các bộ dữ liệu chuẩn. Mã nguồn công khai có sẵn tại https://github.com/ihaeyong/
SoftNet-FSCIL.

1 GIỚI THIỆU
Học Suốt Đời, hay Học Liên Tục, là một mô hình học tập để mở rộng kiến thức và kỹ năng thông qua việc huấn luyện tuần tự nhiều nhiệm vụ (Thrun, 1995). Theo khả năng tiếp cận nhận dạng nhiệm vụ trong quá trình huấn luyện và suy luận, cộng đồng thường phân loại lĩnh vực này thành các vấn đề cụ thể, như tăng cường nhiệm vụ (Pfülb và Gepperth, 2019; Delange et al., 2021; Yoon et al., 2020; Kang et al., 2022), tăng cường lớp (Chaudhry et al., 2018; Kuzborskij et al., 2013; Li và Hoiem, 2017; Rebuffi et al., 2017; Kemker và Kanan, 2017; Castro et al., 2018; Hou et al., 2019; Wu et al., 2019), và học liên tục không có nhiệm vụ (Aljundi et al., 2019; Jin et al., 2021; Pham et al., 2022; Harrison et al., 2020). Trong khi các kịch bản tiêu chuẩn cho học liên tục giả định một số lượng đủ lớn các thực thể cho mỗi nhiệm vụ, một người học suốt đời cho các ứng dụng thực tế thường gặp khó khăn với số lượng thực thể huấn luyện không đủ cho từng vấn đề cần giải quyết. Bài báo này nhằm mục đích giải quyết vấn đề các thực thể huấn luyện hạn chế cho Học Tăng Cường Lớp (CIL) thực tế, được gọi là CIL Với Ít Mẫu (FSCIL) (Ren et al., 2019; Chen và Lee, 2020; Tao et al., 2020; Zhang et al., 2021; Cheraghian et al., 2021; Shi et al., 2021).

Tuy nhiên, có hai thách thức quan trọng trong việc giải quyết các vấn đề FSCIL: quên thảm khốc và overfitting. Quên thảm khốc (Goodfellow et al., 2013; Kirkpatrick et al., 2017) hay Giao Thoa Thảm Khốc McCloskey và Cohen (1989) là một hiện tượng trong đó một người học liên tục mất đi kiến thức nhiệm vụ đã học trước đó bằng cách cập nhật các trọng số để thích ứng với các nhiệm vụ mới, dẫn đến suy giảm hiệu suất đáng kể trên các nhiệm vụ trước đó. Sự trôi dạt kiến thức không mong muốn như vậy là không thể đảo ngược vì kịch bản không cho phép mô hình xem lại dữ liệu nhiệm vụ trong quá khứ. Các công trình gần đây đề xuất giảm thiểu quên thảm khốc cho học tăng cường lớp, thường được phân loại theo nhiều hướng, như dựa trên ràng buộc (Rebuffi et al., 2017; Castro et al., 2018; Hou et al., 2018; 2019; Wu et al., 2019), dựa trên bộ nhớ (Rebuffi et al., 2017; Chen và Lee, 2020; Mazumder et al., 2021; Shi et al., 2021), và các phương pháp dựa trên kiến trúc (Mazumder et al., 2021; Serra et al., 2018; Mallya và Lazebnik, 2018; Kang et al., 2022). Tuy nhiên, chúng tôi lưu ý rằng quên thảm khốc trở nên thách thức hơn nữa trong FSCIL. Do lượng dữ liệu huấn luyện nhỏ cho các nhiệm vụ mới, mô hình có xu hướng overfitting nghiêm trọng với các lớp mới và nhanh chóng quên các lớp cũ, làm suy giảm hiệu suất của mô hình.

Trong khi đó, một số công trình giải quyết các vấn đề overfitting cho học liên tục từ nhiều góc độ khác nhau. NCM (Hou et al., 2019) và BiC (Wu et al., 2019) nhấn mạnh vấn đề bias dự đoán trong quá trình huấn luyện tuần tự mà các mô hình có xu hướng dự đoán dữ liệu cho các lớp trong các nhiệm vụ được huấn luyện gần đây. OCS (Yoon et al., 2022) giải quyết các vấn đề mất cân bằng lớp cho học liên tục dựa trên rehearsal, trong đó số lượng thực thể tại mỗi lớp khác nhau cho mỗi nhiệm vụ để mô hình sẽ thực hiện huấn luyện bias trên các lớp chiếm ưu thế. Tuy nhiên, những công trình này không xem xét các vấn đề overfitting do huấn luyện một chuỗi các nhiệm vụ với ít mẫu. FSLL (Mazumder et al., 2021) giải quyết overfitting cho FSCIL với ít mẫu bằng cách chia nhỏ một phần các tham số mô hình cho các phiên khác nhau thông qua nhiều bước phụ của việc tái xác định lặp đi lặp lại và lựa chọn trọng số. Tuy nhiên, điều này dẫn đến tính toán không hiệu quả.

Để triển khai một mô hình FSCIL với ít mẫu thực tế, chúng tôi đề xuất một phương pháp đơn giản nhưng hiệu quả có tên SoftNet, giảm thiểu hiệu quả quên thảm khốc và overfitting. Được thúc đẩy bởi Giả thuyết Vé Số (Frankle và Carbin, 2019), giả thuyết về sự tồn tại của các mạng con cạnh tranh (vé thắng) trong mạng neural dày đặc được khởi tạo ngẫu nhiên, chúng tôi đề xuất một mô hình mới cho FSCIL với ít mẫu, được đặt tên là Giả thuyết Vé Số Có Quy Tắc:

Giả thuyết Vé Số Có Quy Tắc (RLTH). Một mạng neural dày đặc được khởi tạo ngẫu nhiên chứa một mạng con có quy tắc có thể giữ lại kiến thức lớp trước đó trong khi cung cấp không gian để học kiến thức lớp mới thông qua huấn luyện cô lập của mạng con.

Dựa trên RLTH, chúng tôi đề xuất một phương pháp, được gọi là Mạng Con Mềm (SoftNet), được minh họa trong Hình 1. Đầu tiên, SoftNet học đồng thời mô hình dày đặc được khởi tạo ngẫu nhiên (Hình 1 (a)) và mặt nạ mềm m ∈ [0,1]|θ| liên quan đến Mạng con mềm (Hình 1 (b)) trên huấn luyện phiên cơ sở; mặt nạ mềm bao gồm phần chính của các tham số mô hình m = 1 và phần phụ m < 1 trong đó m = 1 được lấy bởi top-c% của các tham số mô hình và m < 1 được lấy bởi phần còn lại (100-top-c%) được lấy mẫu từ phân phối đều. Sau đó, chúng tôi đóng băng phần chính của các trọng số mạng con được huấn luyện trước để duy trì kiến thức lớp trước đó và chỉ cập nhật phần phụ của các trọng số cho kiến thức lớp mới (Hình 1 (c)).

Chúng tôi tóm tắt những đóng góp chính của chúng tôi như sau:
• Bài báo này trình bày một phương pháp dựa trên mặt nạ mới, Mạng Con Mềm (SoftNet), giải quyết hai thách thức quan trọng trong học tăng cường lớp với ít mẫu (FSCIL), được biết đến là quên thảm khốc và overfitting.
• SoftNet của chúng tôi huấn luyện hai loại mặt nạ không nhị phân khác nhau (mạng con) để giải quyết FSCIL, ngăn người học liên tục quên các phiên trước đó và overfitting đồng thời.
• Chúng tôi tiến hành một nghiên cứu thực nghiệm toàn diện về SoftNet với nhiều phương pháp học tăng cường lớp. Phương pháp của chúng tôi vượt trội đáng kể so với các phương pháp cơ sở mạnh mẽ trên các nhiệm vụ chuẩn cho các vấn đề FSCIL.

2 CÔNG TRÌNH LIÊN QUAN
Quên Thảm Khốc. Nhiều công trình gần đây đã đạt được tiến bộ đáng kể trong việc giải quyết các thách thức của quên thảm khốc trong học suốt đời. Cụ thể, các phương pháp dựa trên kiến trúc (Mallya et al., 2018; Serrà et al., 2018; Li et al., 2019) sử dụng khả năng bổ sung để mở rộng (Xu và Zhu, 2018; Yoon et al., 2018) hoặc cô lập (Rusu et al., 2016) các tham số mô hình, do đó tránh giao thoa kiến thức trong quá trình học liên tục; SupSup (Wortsman et al., 2020) phân bổ các tham số mô hình dành riêng cho các nhiệm vụ khác nhau. Rất gần đây, Chen et al. (2021); Kang et al. (2022) cho thấy sự tồn tại của một mạng con thưa thớt, được gọi là vé thắng, hoạt động tốt trên tất cả các nhiệm vụ trong quá trình học liên tục. Tuy nhiên, nhiều phương pháp dựa trên mạng con không tương thích với cài đặt FSCIL vì việc thực hiện suy luận nhiệm vụ dưới mất cân bằng dữ liệu là thách thức. FSLL (Mazumder et al., 2021) nhằm mục đích tìm kiếm các mạng con cụ thể theo phiên trong khi bảo toàn trọng số cho các phiên trước đó cho học tăng cường với ít mẫu. Tuy nhiên, quá trình mở rộng bao gồm một loạt các bước huấn luyện lại và cắt tỉa khác, đòi hỏi thời gian huấn luyện và chi phí tính toán quá mức. Ngược lại, phương pháp được đề xuất của chúng tôi, SoftNet, học đồng thời mô hình và mặt nạ mượt mà (tức là, không nhị phân) thích ứng nhiệm vụ của mạng con liên kết với phiên cơ sở trong khi lựa chọn một tập hợp con cần thiết của các trọng số mô hình cho phiên sắp tới. Hơn nữa, các mặt nạ mượt mà hoạt động như các bộ điều chỉnh ngăn overfitting khi học các lớp mới.

Mạng con mềm. Các công trình gần đây với cổng phụ thuộc ngữ cảnh của không gian con (He và Jaeger, 2018), tham số (Mallya và Lazebnik, 2018; He et al., 2019; Mazumder et al., 2021), hoặc các lớp (Serra et al., 2018) của một mạng neural sâu duy nhất đã chứng minh tính hiệu quả của nó trong việc giải quyết quên thảm khốc trong quá trình học liên tục. Masse et al. (2018) kết hợp cổng phụ thuộc ngữ cảnh với các ràng buộc ngăn chặn thay đổi đáng kể trong trọng số mô hình, như SI (Zenke et al., 2017) và EWC (Kirkpatrick et al., 2017), đạt được sự gia tăng hiệu suất hơn nữa so với việc sử dụng chúng một mình. Một minima phẳng cũng có thể được coi là thu được không gian con. Các công trình trước đó đã cho thấy rằng một bộ tối thiểu hóa phẳng mạnh mẽ hơn đối với nhiễu ngẫu nhiên (Hinton và Van Camp, 1993; Hochreiter và Schmidhuber, 1994; Jiang et al., 2019). Gần đây, Shi et al. (2021) cho thấy rằng việc có được minima mất mát phẳng trong phiên cơ sở, đại diện cho phiên nhiệm vụ đầu tiên với các thực thể huấn luyện đủ, là cần thiết để giảm thiểu quên thảm khốc trong FSCIL. Để giảm thiểu quên, họ đã cập nhật các trọng số mô hình trên đường viền mất mát phẳng thu được. Trong công trình của chúng tôi, bằng cách lựa chọn mạng con (Frankle và Carbin, 2019; Zhou et al., 2019; Wortsman et al., 2019; Ramanujan et al., 2020; Kang et al., 2022; Chijiwa et al., 2022) và tối ưu hóa các tham số mạng con trong một không gian con, chúng tôi đề xuất một phương pháp mới để bảo toàn kiến thức đã học từ một phiên cơ sở trên một mạng con chính và học các phiên mới thông qua các mạng con phụ có quy tắc.

3 MẠNG CON MỀM CHO HỌC TĂNG CƯỜNG LỚP VỚI ÍT MẪU
3.1 PHÁT BIỂU VẤN ĐỀ
Nhiều công trình đã cố gắng giảm thiểu các vấn đề quên thảm khốc trong học tăng cường lớp bằng cách sử dụng chưng cất kiến thức, xem lại một tập hợp con của các mẫu trước đó, hoặc cô lập các tham số mô hình cần thiết để giữ lại kiến thức lớp trước đó ngay cả sau khi mô hình mất khả năng tiếp cận chúng. Tuy nhiên, vì kịch bản học tăng cường lớp với ít mẫu xem xét các nhiệm vụ/phiên tiếp theo chứa một lượng nhỏ dữ liệu huấn luyện, mô hình có xu hướng overfitting nghiêm trọng với các lớp mới, khiến việc tinh chỉnh mô hình đã được huấn luyện trước đó trên một vài mẫu trở nên khó khăn. Ngoài ra, quá trình tinh chỉnh thường dẫn đến quên thảm khốc kiến thức lớp cơ sở. Kết quả là, việc điều chỉnh là không thể thiếu trong các mô hình để tránh quên và ngăn mô hình overfitting với các mẫu lớp mới bằng cách chỉ cập nhật các tham số được chọn để học trong phiên mới.

Học Tăng Cường Lớp Với Ít Mẫu (FSCIL) nhằm mục đích học các phiên mới chỉ với một vài ví dụ một cách liên tục. Một mô hình FSCIL học một chuỗi T phiên huấn luyện {D1, ..., DT}, trong đó Dt = {zt_i = (xt_i, yt_i)}^nt_i=1 là dữ liệu huấn luyện của phiên t và xt_i là một ví dụ của lớp yt_i ∈ Ot. Trong FSCIL, phiên cơ sở D1 thường chứa một số lượng lớn các lớp với dữ liệu huấn luyện đủ cho mỗi lớp. Ngược lại, các phiên tiếp theo (t ≥ 2) sẽ chỉ chứa một số lượng nhỏ các lớp với một vài mẫu huấn luyện cho mỗi lớp, ví dụ, phiên thứ t Dt thường được trình bày như một nhiệm vụ N-way K-shot. Trong mỗi phiên huấn luyện t, mô hình chỉ có thể truy cập dữ liệu huấn luyện Dt và một vài ví dụ được lưu trữ trong phiên trước đó. Khi việc huấn luyện phiên t hoàn thành, chúng tôi đánh giá mô hình trên các mẫu thử nghiệm từ tất cả các lớp O = ∪t_i=1 Oi, trong đó Oi ∩ Oj≠i = ∅ cho ∀ i, j ≤ T.

Xem xét một thiết lập học có giám sát trong đó T phiên đến trong một người học suốt đời f(·; θ) được tham số hóa bởi các trọng số mô hình θ theo thứ tự tuần tự. Một kịch bản học tăng cường lớp với ít mẫu nhằm mục đích học các lớp trong một chuỗi các phiên mà không quên thảm khốc. Trong phiên huấn luyện t, mô hình giải quyết thủ tục tối ưu hóa sau:

θ* = minimize_θ 1/nt ∑^nt_i=1 Lt(f(xt_i; θ), yt_i); (1)

trong đó Lt là mất mát phân loại như cross-entropy, và nt là số lượng thực thể cho phiên t.

3.2 HUẤN LUYỆN DỰA TRÊN MẠNG CON CHO HỌC TĂNG CƯỜNG LỚP VỚI ÍT MẪU
Vì những người học suốt đời thường áp dụng các mạng neural dày đặc được tham số hóa quá mức để cho phép tự do tài nguyên cho các lớp hoặc nhiệm vụ tương lai, việc cập nhật toàn bộ trọng số trong mạng neural cho các nhiệm vụ với ít mẫu thường không được ưa thích và thường gây ra vấn đề overfitting. Để khắc phục các hạn chế trong FSCIL, chúng tôi tập trung vào việc cập nhật các trọng số một phần trong mạng neural khi một nhiệm vụ mới đến. Tập hợp các trọng số một phần mong muốn, được đặt tên là mạng con, có thể đạt được hiệu suất ngang bằng hoặc thậm chí tốt hơn với các động lực sau: (1) Giả thuyết Vé Số (Frankle và Carbin, 2019) cho thấy sự tồn tại của một mạng con hoạt động tốt như mạng dày đặc, và (2) Mạng con giảm đáng kể từ mạng dày đặc làm giảm kích thước của việc mở rộng bộ giải quyết trong khi cung cấp khả năng bổ sung để học các phiên hoặc nhiệm vụ mới.

Chúng tôi đầu tiên đề xuất mục tiêu được gọi là HardNet như sau: cho các tham số mạng neural dày đặc θ, mặt nạ chú ý nhị phân m*t mô tả mạng con tối ưu cho phiên t sao cho |m*t| nhỏ hơn khả năng mô hình dày đặc |θ|. Tuy nhiên, các mạng con nhị phân hóa như vậy mt ∈ {0,1}|θ| không thể điều chỉnh các tham số còn lại trong một mạng dày đặc cho các phiên tương lai trong khi giải quyết các vấn đề nhiệm vụ trong quá khứ một cách hiệu quả về chi phí và bộ nhớ. Trong FSCIL, độ chính xác thử nghiệm của phiên cơ sở giảm đáng kể khi tiến hành học các phiên tuần tự vì mạng con của m = 1 đóng vai trò quan trọng trong việc duy trì kiến thức lớp cơ sở. Vì mục đích này, chúng tôi đề xuất một mạng con mềm mt ∈ [0,1]|θ| thay vì mạng con nhị phân hóa. Nó mang lại sự linh hoạt hơn để tinh chỉnh một phần nhỏ của mạng con mềm trong khi cố định phần còn lại để giữ lại kiến thức lớp cơ sở cho FSCIL. Như vậy, chúng tôi tìm mạng con mềm thông qua mục tiêu sau:

m*t = minimize_{mt∈[0,1]|θ|} 1/nt ∑^nt_i=1 Lt[f(xt_i; θ ⊙ mt), yt_i] := J
subject to |mt| ≤ c:(2)

trong đó mất mát phiên J = Lt[f(xt_i; θ), yt_i], độ thưa thớt mạng con c ≤ |θ| (được sử dụng như tỷ lệ phần trăm % được chọn của các tham số mô hình trong phần tiếp theo), và ⊙ biểu thị phép nhân từng phần tử. Trong phần tiếp theo, chúng tôi mô tả cách lấy mạng con mềm m*t bằng cách sử dụng tiêu chí dựa trên độ lớn (RLTH) trong khi giảm thiểu mất mát phiên đồng thời.

3.3 LẤY MẠNG CON MỀM THÔNG QUA VÉ THẮNG BỔ SUNG
Để mỗi trọng số được liên kết với một tham số có thể học mà chúng tôi gọi là điểm số trọng số, xác định số lượng tầm quan trọng của trọng số liên kết. Nói cách khác, chúng tôi tuyên bố một trọng số với điểm số cao hơn là quan trọng hơn. Đầu tiên, chúng tôi tìm một mạng con θ* = θ ⊙ m*t của mạng neural dày đặc và sau đó gán nó làm bộ giải quyết của phiên hiện tại t. Các mạng con liên kết với mỗi phiên học đồng thời trọng số mô hình θ và mặt nạ nhị phân mt. Cho một mục tiêu Lt, chúng tôi tối ưu hóa như sau:

θ*, m*t = minimize_{θ,s} Lt(θ ⊙ mt, Dt): (3)

trong đó mt được lấy bằng cách áp dụng một hàm chỉ thị 1c trên điểm số trọng số s. Lưu ý 1c(s) = 1 nếu s thuộc top-c% điểm số và 0 ngược lại.

Trong quá trình tối ưu hóa cho FSCIL, tuy nhiên, chúng tôi xem xét hai vấn đề chính: (1) Quên thảm khốc: cập nhật tất cả θ ⊙ mt≤1 khi huấn luyện cho các phiên mới sẽ gây ra giao thoa với các trọng số được phân bổ cho các nhiệm vụ trước đó; do đó, chúng ta cần đóng băng tất cả các tham số đã học trước đó θ ⊙ mt≤1; (2) Overfitting: mạng con cũng gặp phải các vấn đề overfitting khi huấn luyện một nhiệm vụ tăng cường trên một vài mẫu, như vậy, chúng ta cần cập nhật một vài tham số không liên quan đến kiến thức nhiệm vụ trước đó., tức là, θ ⊙ (1 - mt≤1).

Để có được các mạng con tối ưu giảm thiểu hai vấn đề, chúng tôi định nghĩa một mạng con mềm bằng cách chia mạng neural dày đặc thành hai phần-một là mạng con chính mmajor, và một khác là mạng con phụ mminor. Mạng con mềm được định nghĩa theo như sau:

msoft = mmajor ⊕ mminor; (4)

trong đó mmajor là một mặt nạ nhị phân và mminor ~ U(0,1) và ⊕ biểu thị phép cộng từng phần tử. Như vậy, một mặt nạ mềm được cho là m*t ∈ [0,1]|θ| trong Eq.3. Trong tất cả các cài đặt thực nghiệm FSCIL, mmajor duy trì kiến thức nhiệm vụ cơ sở t = 1 trong khi mminor có được kiến thức nhiệm vụ mới t ≥ 2. Sau đó, với tỷ lệ học phiên cơ sở α, θ được cập nhật như sau: θ ← θ - α ∂L/∂(θ ⊙ msoft) có thể điều chỉnh hiệu quả các trọng số của các mạng con cho học tăng cường. Các mạng con được lấy bởi hàm chỉ thị luôn có giá trị gradient là 0; do đó, việc cập nhật điểm số trọng số s với gradient mất mát của nó là không thể. Để cập nhật điểm số trọng số, chúng tôi sử dụng Bộ Ước Lượng Thẳng (Hinton, 2012; Bengio et al., 2013; Ramanujan et al., 2020) trong lần truyền ngược. Cụ thể, chúng tôi bỏ qua các đạo hàm của hàm chỉ thị và cập nhật điểm số trọng số s ← s - α ∂L/∂s|msoft, trong đó msoft = 1 để khám phá mạng con tối ưu cho huấn luyện phiên cơ sở. Thủ tục tối ưu hóa Mạng con mềm của chúng tôi được tóm tắt trong Thuật toán 1. Khi một mạng con mềm msof duy nhất được lấy trong phiên cơ sở, thì chúng tôi sử dụng mạng con mềm cho toàn bộ các phiên mới mà không cập nhật.

Thuật toán 1 Mạng Con Mềm (SoftNet)
đầu vào {Dt}T_t=1, trọng số mô hình θ, và trọng số điểm s, khả năng theo lớp c
1: // Huấn luyện trên các lớp cơ sở t = 1
2: Khởi tạo ngẫu nhiên θ và s.
3: for epoch e = 1, 2, ... do
4: Lấy mặt nạ mềm msoft của mmajor và mminor ~ U(0,1) tại mỗi lớp
5: for batch bt ∈ Dt do
6: Tính toán Lbase(θ ⊙ msoft, bt) bởi Eq. 3
7: θ ← θ - α ∂L/∂(θ ⊙ msoft)
8: s ← s - α ∂L/∂s|msoft
9: end for
10: end for
11: // Học tăng cường t ≥ 2
12: Kết hợp dữ liệu huấn luyện Dt và các mẫu được lưu trong các phiên với ít mẫu trước đó
13: for epoch e = 1, 2, ... do
14: for batch bt ∈ Dt do
15: Tính toán Lm(θ ⊙ msoft, bt) bởi Eq. 5
16: θ ← θ - α ∂L/∂(θ ⊙ mminor)
17: end for
18: end for
đầu ra các tham số mô hình θ, s, và msoft.

4 HỌC TĂNG CƯỜNG CHO MẠNG CON MỀM
Bây giờ chúng tôi mô tả thủ tục tổng thể của phương pháp học/suy luận tăng cường dựa trên cắt tỉa mềm của chúng tôi, bao gồm giai đoạn huấn luyện với một phép đo thông tin chuẩn hóa trong Mục 4.1, theo sau bởi công trình trước đó (Shi et al., 2021), và giai đoạn suy luận trong Mục 4.2.

4.1 HUẤN LUYỆN MẠNG CON MỀM TĂNG CƯỜNG
Huấn Luyện Cơ Sở (t = 1). Trong phiên học cơ sở, chúng tôi tối ưu hóa tham số mạng con mềm θ (bao gồm một lớp kết nối đầy đủ như một bộ phân loại) và điểm số trọng số s với mất mát cross-entropy đồng thời bằng cách sử dụng các ví dụ huấn luyện của D1.

Huấn Luyện Tăng Cường (t ≥ 2). Trong các phiên học tăng cường với ít mẫu (t ≥ 2), được tận dụng bởi msoft, chúng tôi tinh chỉnh một vài tham số phụ mminor của mạng con mềm để học các lớp mới. Vì mminor < 1, mạng con mềm giảm thiểu overfitting của một vài mẫu. Hơn nữa, thay vì khoảng cách Euclidean (Shi et al., 2021), chúng tôi sử dụng một thuật toán phân loại dựa trên metric với khoảng cách cosine để tinh chỉnh một vài tham số được chọn. Trong một số trường hợp, khoảng cách Euclidean không thể đưa ra khoảng cách thực giữa các biểu diễn, đặc biệt khi hai điểm có cùng khoảng cách từ nguyên mẫu không rơi vào cùng lớp. Ngược lại, các biểu diễn với khoảng cách cosine thấp được đặt cùng hướng từ gốc, cung cấp một phép đo thông tin chuẩn hóa. Chúng tôi định nghĩa hàm mất mát như:

Lm(z; θ ⊙ msoft) = ∑_{z∈D} ∑_{o∈O} 1(y=o) log(e^{d(po,f(x;θ⊙msoft))} / ∑_{ok∈O} e^{d(pok,f(x;θ⊙msoft))}) (5)

trong đó d(·,·) biểu thị khoảng cách cosine, po là nguyên mẫu của lớp o, O = ∪^t_{i=1} Oi chỉ tất cả các lớp gặp phải, và D = Dt ∪ P biểu thị hợp của dữ liệu huấn luyện hiện tại Dt và tập mẫu P = {P2, ..., Pt-1}, trong đó Pte (2 ≤ te < t) là tập hợp các mẫu được lưu trong phiên te. Lưu ý rằng các nguyên mẫu của các lớp mới được tính toán bởi po = 1/No ∑_i 1(yi=o)f(xi; θ ⊙ msoft) và những của các lớp cơ sở được lưu trong phiên cơ sở, và No biểu thị số lượng hình ảnh huấn luyện của lớp o. Chúng tôi cũng lưu các nguyên mẫu của tất cả các lớp trong Ot để đánh giá sau này.

4.2 SUY LUẬN CHO MẠNG CON MỀM TĂNG CƯỜNG
Trong mỗi phiên, suy luận cũng được tiến hành bởi một thuật toán phân loại trung bình lớp gần nhất đơn giản (NCM) (Mensink et al., 2013; Shi et al., 2021) để so sánh công bằng. Cụ thể, tất cả các mẫu huấn luyện và thử nghiệm được ánh xạ đến không gian nhúng của bộ trích xuất đặc trưng f, và khoảng cách Euclidean du(·,·) được sử dụng để đo độ tương tự giữa chúng. Bộ phân loại đưa ra chỉ số nguyên mẫu thứ k o*k = arg min_{o∈O} du(f(x; θ ⊙ msoft), po) làm đầu ra.

5 THỰC NGHIỆM
Chúng tôi giới thiệu các thiết lập thực nghiệm trong Mục 5.1. Sau đó, chúng tôi đánh giá thực nghiệm các mạng con mềm của chúng tôi cho học tăng cường với ít mẫu và chứng minh tính hiệu quả của nó thông qua so sánh với các phương pháp tiên tiến và mạng con vanilla trong các phần tiếp theo.

5.1 THIẾT LẬP THỰC NGHIỆM
Bộ dữ liệu. Để xác nhận tính hiệu quả của mạng con mềm, chúng tôi tuân theo thiết lập thực nghiệm FSCIL tiêu chuẩn. Chúng tôi chọn ngẫu nhiên 60 lớp làm lớp cơ sở và 40 lớp còn lại làm lớp mới cho CIFAR-100 và miniImageNet. Trong mỗi phiên học tăng cường, chúng tôi xây dựng các nhiệm vụ 5-way 5-shot bằng cách chọn ngẫu nhiên năm lớp và lấy mẫu năm ví dụ huấn luyện cho mỗi lớp.

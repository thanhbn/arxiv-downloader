# 2210.10209.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/continual-learning/2210.10209.pdf
# Kích thước file: 765371 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Huấn luyện Mạng con Siêu mặt nạ Độc quyền cho Học liên tục
Prateek Yadav & Mohit Bansal
Khoa Khoa học Máy tính
UNC Chapel Hill
{praty,mbansal}@cs.unc.edu
Tóm tắt
Các phương pháp Học liên tục (CL) tập trung vào tích lũy kiến thức theo thời gian trong khi tránh quên thảm khốc. Gần đây, Wortsman và cộng sự (2020) đã đề xuất một phương pháp CL, SupSup, sử dụng một mạng cơ sở được khởi tạo ngẫu nhiên, cố định (mô hình) và tìm một siêu mặt nạ cho mỗi nhiệm vụ mới để có chọn lọc giữ hoặc loại bỏ từng trọng số nhằm tạo ra một mạng con. Họ ngăn chặn quên lãng vì các trọng số mạng không được cập nhật. Mặc dù không có quên lãng, hiệu suất của SupSup là không tối ưu vì các trọng số cố định hạn chế khả năng biểu diễn của nó. Hơn nữa, không có sự tích lũy hoặc chuyển giao kiến thức bên trong mô hình khi học các nhiệm vụ mới. Do đó, chúng tôi đề xuất EXSSNET (Huấn luyện Mạng con Siêu mặt nạ Độc quyền), thực hiện huấn luyện trọng số mạng con độc quyền và không chồng lấp. Điều này tránh các cập nhật xung đột đến các trọng số chia sẻ bởi các nhiệm vụ tiếp theo để cải thiện hiệu suất trong khi vẫn ngăn chặn quên lãng. Hơn nữa, chúng tôi đề xuất một mô-đun Chuyển giao Kiến thức dựa trên KNN mới (KKT) sử dụng kiến thức đã thu được trước đó để học các nhiệm vụ mới tốt hơn và nhanh hơn. Chúng tôi chứng minh rằng EXSSNET vượt trội so với các phương pháp mạnh trước đó trên cả lĩnh vực NLP và Thị giác trong khi ngăn chặn quên lãng. Hơn nữa, EXSSNET đặc biệt có lợi cho các mặt nạ thưa thớt kích hoạt 2-10% tham số mô hình, dẫn đến cải thiện trung bình 8.3% so với SupSup. Hơn nữa, EXSSNET mở rộng đến số lượng lớn các nhiệm vụ (100). Mã nguồn của chúng tôi có sẵn tại https://github.com/prateeky2806/exessnet.

1 Giới thiệu
Trí tuệ nhân tạo nhằm phát triển các tác nhân có thể học để hoàn thành một tập hợp các nhiệm vụ. Học liên tục (CL) (Ring, 1998; Thrun, 1998) là rất quan trọng cho việc này, nhưng khi một mô hình được huấn luyện tuần tự trên các nhiệm vụ khác nhau với các phân phối dữ liệu khác nhau, nó có thể mất khả năng thực hiện tốt trên các nhiệm vụ trước đó, một hiện tượng được gọi là quên thảm khốc (CF) (McCloskey và Cohen, 1989; Zhao và Schmidhuber, 1996; Thrun, 1998). Điều này được gây ra bởi việc thiếu truy cập vào dữ liệu từ các nhiệm vụ trước đó, cũng như các cập nhật xung đột đến các tham số mô hình chia sẻ khi học tuần tự nhiều nhiệm vụ, được gọi là nhiễu tham số (McCloskey và Cohen, 1989).

Gần đây, một số phương pháp CL tránh nhiễu tham số bằng cách lấy cảm hứng từ Giả thuyết Vé số (Frankle và Carbin, 2018) và Siêu mặt nạ (Zhou và cộng sự, 2019) để khai thác sức mạnh biểu đạt của các mạng con thưa thớt. Cho rằng chúng ta có một số tổ hợp các mạng con thưa thớt bên trong một mạng, Zhou và cộng sự (2019) lưu ý rằng ngay cả trong các mạng nơ-ron có trọng số ngẫu nhiên, vẫn tồn tại các mạng con nhất định được gọi là siêu mặt nạ đạt được hiệu suất tốt. Siêu mặt nạ là một mặt nạ nhị phân thưa thớt có chọn lọc giữ hoặc loại bỏ từng kết nối trong một mạng cố định và được khởi tạo ngẫu nhiên để tạo ra một mạng con có hiệu suất tốt trên một nhiệm vụ nhất định. Chúng tôi gọi điều này là mạng con như mạng con siêu mặt nạ được hiển thị trong Hình 1, được tô sáng bằng các trọng số màu đỏ. Dựa trên ý tưởng này, Wortsman và cộng sự (2020) đã đề xuất một phương pháp CL, SupSup, khởi tạo một mạng với các trọng số cố định và ngẫu nhiên rồi học một siêu mặt nạ khác nhau cho mỗi nhiệm vụ mới. Điều này cho phép họ ngăn chặn quên thảm khốc (CF) vì không có nhiễu tham số (bởi vì các trọng số mô hình được cố định).

Mặc dù SupSup (Wortsman và cộng sự, 2020) ngăn chặn CF, có một số vấn đề với việc sử dụng siêu mặt nạ cho CL: (1) Các trọng số mô hình ngẫu nhiên cố định trong SupSup hạn chế khả năng biểu diễn của mạng con siêu mặt nạ dẫn đến hiệu suất không tối ưu. (2) Khi học một nhiệm vụ, không có cơ chế nào để chuyển giao kiến thức đã học từ các nhiệm vụ trước đó để học tốt hơn nhiệm vụ hiện tại. Hơn nữa, mô hình không tích lũy kiến thức theo thời gian vì các trọng số không được cập nhật.

--- TRANG 2 ---
Các trọng số chồng lấp không được cập nhật Các trọng số được khởi tạo ngẫu nhiên Mặt nạ trên trọng số  Mặt nạ trên trọng số  Mặt nạ trên trọng số  
Tìm Mặt nạ 
Tìm Mặt nạ 
Tìm Mặt nạ Huấn luyện Nhiệm vụ 1
Huấn luyện Nhiệm vụ 2
Huấn luyện Nhiệm vụ 3 Huấn luyện trọng số không chồng lấp  Huấn luyện trọng số không chồng lấp   Huấn luyện trọng số không chồng lấp  

: Trọng số đã huấn luyện: Trọng số chưa huấn luyện
: Trọng số chồng lấp: Nhiệm vụ 1 : Nhiệm vụ 2
: Nhiệm vụ 3

Hình 1: Sơ đồ EXSSNET. Chúng tôi bắt đầu với các trọng số ngẫu nhiên W(0). Đối với nhiệm vụ 1, trước tiên chúng tôi học một siêu mặt nạ M1 (mạng con tương ứng được đánh dấu bằng màu đỏ, cột 2 hàng 1) và sau đó huấn luyện trọng số tương ứng với M1 tạo ra trọng số W(1) (các đường màu đỏ đậm, cột 1 hàng 2). Đối với nhiệm vụ 2, chúng tôi học mặt nạ M2 trên các trọng số cố định W(1). Nếu các trọng số mặt nạ M2 chồng lấp với M1 (được đánh dấu bằng các đường nét đứt màu xanh lá đậm trong cột 3 hàng 1), thì chỉ các trọng số không chồng lấp (các đường liền màu xanh lá) của mạng con nhiệm vụ 2 được cập nhật (như được hiển thị bằng các đường màu xanh lá đậm và liền cột 3 hàng 2). Các trọng số đã được huấn luyện này (các đường đậm) không được cập nhật bởi bất kỳ nhiệm vụ tiếp theo nào. Cuối cùng, đối với nhiệm vụ 3, chúng tôi học mặt nạ M3 (các đường màu xanh) và cập nhật các trọng số màu xanh liền.

Để khắc phục các vấn đề nêu trên, chúng tôi đề xuất phương pháp của chúng tôi, EXSSNET (Huấn luyện Mạng con Siêu mặt nạ Độc quyền), được phát âm là 'excess-net', trước tiên học một mặt nạ cho một nhiệm vụ và sau đó có chọn lọc huấn luyện một tập con các trọng số từ mạng con siêu mặt nạ. Chúng tôi huấn luyện các trọng số của mạng con này thông qua loại trừ tránh cập nhật các tham số từ mạng con hiện tại đã được cập nhật bởi bất kỳ nhiệm vụ trước đó nào. Trong Hình 1, chúng tôi chứng minh EXSSNET cũng giúp chúng ta ngăn chặn quên lãng. Huấn luyện các trọng số của mạng con siêu mặt nạ tăng khả năng biểu diễn của nó và cho phép EXSSNET mã hóa kiến thức cụ thể của nhiệm vụ bên trong mạng con (xem Hình 2). Điều này giải quyết vấn đề đầu tiên và cho phép EXSSNET thực hiện tương đương với một mạng được huấn luyện đầy đủ trên các nhiệm vụ riêng lẻ; và khi học nhiều nhiệm vụ, việc huấn luyện mạng con độc quyền cải thiện hiệu suất của mỗi nhiệm vụ trong khi vẫn ngăn chặn quên lãng (xem Hình 3).

Để giải quyết vấn đề thứ hai về chuyển giao kiến thức, chúng tôi đề xuất một mô-đun chuyển giao kiến thức dựa trên k-láng giềng gần nhất (KKT) có thể sử dụng thông tin liên quan từ các nhiệm vụ đã học trước đó để cải thiện hiệu suất trên các nhiệm vụ mới trong khi học chúng nhanh hơn. Mô-đun KKT của chúng tôi sử dụng phân loại KNN để chọn một mạng con từ các nhiệm vụ đã học trước đó có khả năng dự đoán tốt hơn ngẫu nhiên cho nhiệm vụ hiện tại và sử dụng nó làm điểm khởi đầu để học các nhiệm vụ mới.

Tiếp theo, chúng tôi chỉ ra lợi thế của phương pháp của chúng tôi bằng cách thử nghiệm với cả các nhiệm vụ ngôn ngữ tự nhiên và thị giác. Đối với ngôn ngữ tự nhiên, chúng tôi đánh giá trên các nhiệm vụ phân loại WebNLP (de Masson d'Autume và cộng sự, 2019) và các nhiệm vụ benchmark GLUE (Wang và cộng sự, 2018), trong khi đối với thị giác, chúng tôi đánh giá trên các tập dữ liệu SplitMNIST (Zenke và cộng sự, 2017), SplitCIFAR100 (De Lange và Tuytelaars, 2021), và SplitTinyImageNet (Buzzega và cộng sự, 2020). Chúng tôi chỉ ra rằng đối với cả lĩnh vực ngôn ngữ và thị giác, EXSSNET vượt trội so với nhiều phương pháp học liên tục mạnh và gần đây dựa trên replay, regularization, distillation, và parameter isolation.

Đối với lĩnh vực thị giác, EXSSNET vượt trội so với baseline mạnh nhất 4.8% và 1.4% trên các tập dữ liệu SplitCIFAR và SplitTinyImageNet tương ứng, trong khi vượt qua mô hình multitask và thu hẹp khoảng cách với việc huấn luyện các mô hình riêng lẻ cho mỗi nhiệm vụ. Ngoài ra, đối với các tập dữ liệu GLUE, EXSSNET tốt hơn 2% so với các phương pháp baseline mạnh nhất và vượt qua hiệu suất của học multitask sử dụng tất cả dữ liệu cùng một lúc. Hơn nữa, EXSSNET đạt được cải thiện trung bình 8.3% so với SupSup cho các mặt nạ thưa thớt với 2−10% tham số mô hình và mở rộng đến số lượng lớn các nhiệm vụ (100). Hơn nữa, EXSSNET với mô-đun KKT học các nhiệm vụ mới chỉ trong 30 epoch so với 100 epoch không có nó, trong khi đạt được độ chính xác cao hơn 3.2% trên tập dữ liệu SplitCIFAR100. Tóm lại, các đóng góp của chúng tôi được liệt kê dưới đây:

• Chúng tôi đề xuất một phương pháp đơn giản và mới để cải thiện việc học mặt nạ bằng cách kết hợp nó với huấn luyện trọng số mạng con độc quyền để cải thiện hiệu suất CL trong khi ngăn chặn CF.

• Chúng tôi đề xuất một mô-đun Chuyển giao Kiến thức dựa trên KNN (KKT) cho khởi tạo siêu mặt nạ

--- TRANG 3 ---
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.930405060

Các phương pháp
ExSSNeT
SSNeT
SupSup
Huấn luyện Đầy đủ
Mật độ Mặt nạ Độ chính xác Kiểm tra Trung bình

Hình 2: Độ chính xác kiểm tra so với mật độ mặt nạ cho phân loại CIFAR100 100 lớp. Trung bình trên 3 seeds.

tự động xác định các nhiệm vụ trước đó để chuyển giao kiến thức nhằm học các nhiệm vụ mới tốt hơn và nhanh hơn.

• Các thí nghiệm rộng rãi trên các nhiệm vụ NLP và thị giác cho thấy EXSSNET vượt trội so với các baseline mạnh và có thể so sánh với mô hình multitask cho các nhiệm vụ NLP trong khi vượt qua nó cho các nhiệm vụ thị giác. Hơn nữa, EXSSNET hoạt động tốt cho các mặt nạ thưa thớt và mở rộng đến số lượng lớn các nhiệm vụ.

2 Động lực

Sử dụng tính thưa thớt cho CL là một kỹ thuật hiệu quả để học nhiều nhiệm vụ, tức là bằng cách mã hóa chúng trong các mạng con khác nhau bên trong một mô hình duy nhất. SupSup (Wortsman và cộng sự, 2020) là một thể hiện của điều này khởi tạo các trọng số mạng ngẫu nhiên và sau đó học một siêu mặt nạ riêng biệt cho mỗi nhiệm vụ (xem Hình 7). Họ ngăn chặn CF vì các trọng số của mạng được cố định và không bao giờ được cập nhật. Tuy nhiên, đây là một vấn đề quan trọng như được thảo luận dưới đây.

Vấn đề 1 - Hiệu suất Không tối ưu của Siêu mặt nạ: Mặc dù các trọng số mạng cố định trong SupSup ngăn chặn CF, điều này cũng hạn chế khả năng biểu diễn, dẫn đến hiệu suất tệ hơn so với một mạng được huấn luyện đầy đủ. Trong Hình 2, chúng tôi báo cáo độ chính xác kiểm tra so với phần trăm tham số mạng được chọn bởi mặt nạ, tức là mật độ mặt nạ cho một mô hình ResNet18 cơ bản trên một phân loại 100 lớp đơn lẻ trên tập dữ liệu CIFAR100. Mô hình ResNet18 được huấn luyện đầy đủ (đường nét đứt màu xanh lá) đạt được độ chính xác 63.9%. Tương tự như Zhou và cộng sự (2019), chúng tôi quan sát rằng hiệu suất của SupSup (đường nét đứt màu vàng) tệ hơn ít nhất 8.3% so với một mô hình được huấn luyện đầy đủ. Như một giải pháp bộ phận có thể, chúng tôi đề xuất một giải pháp đơn giản, SSNET (Huấn luyện Mạng con Siêu mặt nạ), trước tiên tìm một mạng con cho một nhiệm vụ và sau đó huấn luyện các trọng số của mạng con. Điều này tăng khả năng biểu diễn của mạng con vì có nhiều tham số có thể huấn luyện hơn. Đối với một nhiệm vụ đơn, độ chính xác kiểm tra của SSNET tốt hơn SupSup cho tất cả mật độ mặt nạ và khớp với hiệu suất của mô hình được huấn luyện đầy đủ vượt qua một ngưỡng mật độ. Nhưng như được hiển thị dưới đây, khi học nhiều nhiệm vụ tuần tự, SSNET gây ra nhiễu tham số dẫn đến CF.

Vấn đề 2 - Nhiễu Tham số Do Huấn luyện Trọng số Mạng con cho Nhiều Nhiệm vụ: Tiếp theo, chúng tôi chứng minh rằng khi học nhiều nhiệm vụ tuần tự, SSNET vẫn có thể dẫn đến CF. Trong Hình 3, chúng tôi báo cáo độ chính xác kiểm tra trung bình so với phần trăm tham số chồng lấp giữa các mặt nạ của các nhiệm vụ khác nhau, tức là sự chồng lấp thưa thớt (xem Phương trình 2) cho năm nhiệm vụ phân loại 20 lớp khác nhau từ tập dữ liệu SplitCIFAR100 với mô hình ResNet18.

0 10 20 30 40 50 60 70 80304050607080

Các phương pháp
ExSSNeT
SSNeT
SupSup
Sự chồng lấp Thưa thớt Trung bình Độ chính xác Kiểm tra Trung bình

Hình 3: Độ chính xác kiểm tra trung bình trên năm nhiệm vụ 20 lớp từ SplitCIFAR100 so với sự chồng lấp thưa thớt. Trung bình trên 3 seeds.

Chúng tôi quan sát rằng SSNET vượt trội so với SupSup cho sự chồng lấp thưa thớt thấp hơn nhưng khi sự chồng lấp thưa thớt tăng, hiệu suất giảm vì các mạng con siêu mặt nạ cho các nhiệm vụ khác nhau có nhiều trọng số chồng lấp (chung) hơn (các đường nét đứt đậm trong Hình 1). Điều này dẫn đến nhiễu tham số cao hơn gây ra quên lãng tăng làm giảm lợi ích từ huấn luyện mạng con.

Đề xuất cuối cùng của chúng tôi, EXSSNET, giải quyết cả hai vấn đề này bằng cách có chọn lọc huấn luyện một tập con các trọng số trong mạng con siêu mặt nạ để ngăn chặn nhiễu tham số. Khi học nhiều nhiệm vụ, điều này ngăn chặn CF, dẫn đến hiệu suất tốt hơn một cách nghiêm ngặt so với SupSup (Hình 3) trong khi có khả năng biểu diễn để khớp thu hẹp khoảng cách với các mô hình được huấn luyện đầy đủ (Hình 2).

3 Phương pháp

Như được hiển thị trong Hình 1, khi học một nhiệm vụ mới ti, EXSSNET tuân theo ba bước: (1) Chúng tôi học một siêu mặt nạ Mi cho nhiệm vụ; (2) Chúng tôi sử dụng tất cả các mặt nạ của các nhiệm vụ trước đó M1, . . . , Mi−1 để tạo một mặt nạ tham số tự do Mfree i, tìm các tham số được chọn bởi mặt nạ Mi mà không được chọn bởi bất kỳ mặt nạ trước đó nào; (3) Chúng tôi cập nhật các trọng số tương ứng với mặt nạ Mfree i vì điều này tránh nhiễu tham số. Bây giờ, chúng tôi mô tả chính thức

--- TRANG 4 ---
mô tả tất cả các bước của phương pháp EXSSNET (Huấn luyện Mạng con Siêu mặt nạ Độc quyền) cho một Perceptron đa tầng (MLP).

Ký hiệu: Trong quá trình huấn luyện, chúng ta có thể xử lý từng lớp l của một mạng MLP riêng biệt. Một lớp trung gian l có nl nút được ký hiệu bởi V(l) = {v1, . . . , vnl}. Đối với một nút v trong lớp l, hãy để Iv biểu thị đầu vào của nó và Zv = σ(Iv) biểu thị đầu ra của nó, trong đó σ(.) là hàm kích hoạt. Với ký hiệu này, Iv có thể được viết là Iv = Σu∈V(l−1) wuvZu, trong đó wuv là trọng số mạng kết nối nút u với nút v. Các trọng số mạng hoàn chỉnh cho MLP được ký hiệu bởi W. Khi huấn luyện nhiệm vụ ti, chúng ta có quyền truy cập vào các siêu mặt nạ từ tất cả các nhiệm vụ trước đó {Mj}i−1 j=1 và các trọng số mô hình W(i−1) thu được sau khi học nhiệm vụ ti−1.

3.1 EXSSNET: Huấn luyện Mạng con Siêu mặt nạ Độc quyền

Tìm Siêu mặt nạ: Theo Wortsman và cộng sự (2020), chúng tôi sử dụng thuật toán của Ramanujan và cộng sự (2019) để học một siêu mặt nạ Mi cho nhiệm vụ hiện tại ti. Siêu mặt nạ Mi được học so với các trọng số mô hình cơ bản W(i−1) và mặt nạ chọn một phần trọng số dẫn đến hiệu suất tốt trên nhiệm vụ mà không huấn luyện các trọng số. Để đạt được điều này, chúng tôi học một điểm số suv cho mỗi trọng số wuv, và một khi đã được huấn luyện, các điểm số này được ngưỡng hóa để thu được mặt nạ. Ở đây, đầu vào cho một nút v là Iv = Σu∈V(l−1) wuvZumuv, trong đó muv = h(suv) là giá trị mặt nạ nhị phân và h(.) là một hàm xuất ra 1 cho k% hàng đầu của các điểm số trong lớp với k là mật độ mặt nạ. Tiếp theo, chúng tôi sử dụng một bộ ước lượng gradient thẳng qua (Bengio và cộng sự, 2013) và lặp qua các mẫu dữ liệu của nhiệm vụ hiện tại để cập nhật các điểm số cho siêu mặt nạ tương ứng Mi như sau,

suv = suv − αĝsuv; ĝsuv = ∂L/∂Iv ∂Iv/∂suv = ∂L/∂Iv wuvZu (1)

Tìm Tham số Mặt nạ Độc quyền: Với một mặt nạ đã học Mi, chúng tôi sử dụng tất cả các mặt nạ của các nhiệm vụ trước đó M1, . . . , Mi−1 để tạo một mặt nạ tham số tự do Mfree i, tìm các tham số được chọn bởi mặt nạ Mi mà không được chọn bởi bất kỳ mặt nạ trước đó nào. Chúng tôi làm điều này bằng cách – (1) tạo một mặt nạ mới M1:i−1 chứa tất cả các tham số đã được cập nhật bởi bất kỳ nhiệm vụ trước đó nào bằng cách lấy hợp của tất cả các mặt nạ trước đó {Mj}i−1 j=1 bằng cách sử dụng phép toán logic hoặc, và (2) Sau đó chúng tôi thu được một mặt nạ Mfree i bằng cách lấy giao của tất cả các tham số mạng không được sử dụng bởi bất kỳ nhiệm vụ trước đó nào được cho bởi phủ định của mặt nạ M1:i−1 với mặt nạ nhiệm vụ hiện tại Mi thông qua phép toán logic và. Tiếp theo, chúng tôi sử dụng mặt nạ Mfree i này cho huấn luyện trọng số mạng con siêu mặt nạ độc quyền.

Huấn luyện Trọng số Mạng con Siêu mặt nạ Độc quyền: Để huấn luyện các tham số mạng con cho nhiệm vụ ti với mặt nạ tham số tự do Mfree i, chúng tôi thực hiện lượt truyền xuôi trên mô hình dưới dạng model(x, W ⊙ M̂i) trong đó M̂i = Mfree i + ((1 − Mfree i) ⊙ Mi).detach(), trong đó ⊙ là phép nhân theo từng phần tử. Do đó, M̂i cho phép chúng ta sử dụng tất cả các kết nối trong Mi trong lượt truyền xuôi của việc huấn luyện nhưng trong lượt truyền ngược, chỉ các tham số trong Mfree i được cập nhật vì giá trị gradient là 0 cho tất cả các trọng số wuv trong đó mfree uv = 0. Trong khi trong quá trình suy luận trên nhiệm vụ ti chúng ta sử dụng mặt nạ Mi. Ngược lại, SSNET sử dụng mặt nạ nhiệm vụ Mi cả trong quá trình huấn luyện và suy luận dưới dạng model(x, W(i−1) ⊙ Mi). Điều này cập nhật tất cả các tham số trong mặt nạ bao gồm các tham số đã được cập nhật bởi các nhiệm vụ trước đó dẫn đến CF. Do đó, trong các trường hợp mà sự chồng lấp thưa thớt cao, EXSSNET được ưa thích hơn SSNET. Tóm lại, EXSSNET vượt qua vấn đề CF của SSNET trong khi hưởng lợi từ việc huấn luyện mạng con để cải thiện hiệu suất tổng thể như được hiển thị trong Hình 3.

3.2 KKT: Chuyển giao Kiến thức dựa trên Knn

Khi học nhiều nhiệm vụ, đó là một đặc tính mong muốn để chuyển giao thông tin đã học bởi các nhiệm vụ trước đó để đạt được hiệu suất tốt hơn trên các nhiệm vụ mới và học chúng nhanh hơn (Biesialska và cộng sự, 2020). Do đó, chúng tôi đề xuất một mô-đun chuyển giao kiến thức dựa trên K-Nearest Neighbours (KNN) (KKT) sử dụng phân loại KNN để tự động tìm nhiệm vụ trước đó có liên quan nhất (Veniat và cộng sự, 2021) để khởi tạo siêu mặt nạ cho nhiệm vụ hiện tại.

Cụ thể hơn, trước khi học mặt nạ Mi cho nhiệm vụ hiện tại ti, chúng tôi lấy mẫu ngẫu nhiên một phần nhỏ dữ liệu từ nhiệm vụ ti và chia nó thành tập huấn luyện và kiểm tra. Tiếp theo, chúng tôi sử dụng các mạng con đã huấn luyện của mỗi nhiệm vụ trước đó t1, . . . , ti−1 để thu được các đặc trưng trên dữ liệu được lấy mẫu này. Sau đó chúng tôi học i−1 mô hình phân loại KNN độc lập sử dụng các đặc trưng này. Sau đó chúng tôi đánh giá các mô hình i−1 này trên tập kiểm tra được lấy mẫu để thu được điểm số độ chính xác biểu thị khả năng dự đoán của các đặc trưng từ mỗi nhiệm vụ trước đó cho nhiệm vụ hiện tại. Cuối cùng, chúng tôi chọn nhiệm vụ trước đó có độ chính xác cao nhất

--- TRANG 5 ---
trên nhiệm vụ hiện tại. Nếu độ chính xác này tốt hơn ngẫu nhiên thì chúng tôi sử dụng mặt nạ của nó để khởi tạo siêu mặt nạ của nhiệm vụ hiện tại. Điều này cho phép EXSSNET chuyển giao thông tin từ nhiệm vụ trước đó để học các nhiệm vụ mới tốt hơn và nhanh hơn. Chúng tôi lưu ý rằng mô-đun KKT không giới hạn ở SupSup và có thể được áp dụng cho một danh mục rộng hơn các phương pháp CL giới thiệu các tham số bổ sung cho các nhiệm vụ mới.

4 Thí nghiệm

4.1 Thiết lập Thí nghiệm và Chi tiết Huấn luyện

Tập dữ liệu: Đối với lĩnh vực ngôn ngữ tự nhiên, chúng tôi tuân theo thiết lập phân loại văn bản chia sẻ của IDBR (Huang và cộng sự, 2021), LAMOL (Sun và cộng sự, 2019), và MBPA++ (De Lange và cộng sự, 2019) để học tuần tự năm nhiệm vụ phân loại văn bản; (1) Phân tích Tình cảm Yelp (Zhang và cộng sự, 2015); (2) DBPedia cho phân loại bài viết Wikipedia (Mendes và cộng sự, 2012) (3) Yahoo! Answer cho phân loại Q&A (Chang và cộng sự, 2008); (4) Phân tích tình cảm Amazon (McAuley và Leskovec, 2013) (5) AG News cho phân loại tin tức (Zhang và cộng sự, 2015). Chúng tôi gọi chúng là các nhiệm vụ phân loại WebNLP để dễ tham khảo. Khi so sánh với các phương pháp văn bản tiên tiến trước đó, chúng tôi sử dụng cùng tập huấn luyện và kiểm tra như IDBR và LAMOL chứa 115,000/500/7,600 ví dụ Train/Val/Test. Đối với các nghiên cứu ablation của chúng tôi, chúng tôi tuân theo IDBR và sử dụng một tập dữ liệu được lấy mẫu, vui lòng xem Bảng 7 Phụ lục để biết thống kê. Ngoài ra, chúng tôi tạo một benchmark CL sử dụng các nhiệm vụ phân loại GLUE phổ biến (Wang và cộng sự, 2018) bao gồm hơn 5k mẫu huấn luyện. Chúng tôi sử dụng phần chia xác thực chính thức làm dữ liệu kiểm tra và sử dụng 0.1% dữ liệu huấn luyện để tạo tập xác thực. Benchmark cuối cùng của chúng tôi bao gồm năm nhiệm vụ; MNLI (353k/39k/9.8k), QQP (327k/36k/40k), QNLI (94k/10k/5.4k), SST-2 (60k/6.7k/872), CoLA (7.6k/856/1k). Đối với các thí nghiệm thị giác, chúng tôi tuân theo SupSup và sử dụng ba benchmark CL, SplitMNIST (Zenke và cộng sự, 2017), SplitCIFAR100 (Chaudhry và cộng sự, 2018), và SplitTinyImageNet (Buzzega và cộng sự, 2020) với 10, 100 và 200 lớp tổng cộng tương ứng.

Các chỉ số: Chúng tôi tuân theo Chaudhry và cộng sự (2018) và đánh giá mô hình của chúng tôi sau khi học nhiệm vụ t trên tất cả các nhiệm vụ, được ký hiệu bởi T. Điều này cho chúng ta một ma trận độ chính xác A ∈ Rn×n, trong đó ai,j biểu thị độ chính xác phân loại trên nhiệm vụ j sau khi học nhiệm vụ i. Chúng ta muốn mô hình thực hiện tốt trên tất cả các nhiệm vụ nó đã được học. Điều này được đo bởi độ chính xác trung bình, A(T) = 1/N ΣN k=1 aN,k, trong đó N là số lượng nhiệm vụ. Tiếp theo, chúng ta muốn mô hình giữ lại hiệu suất trên các nhiệm vụ trước đó khi học nhiều nhiệm vụ. Điều này được đo bởi chỉ số quên lãng (Lopez-Paz và Ranzato, 2017), F(T) = 1/(N−1) ΣN−1 t=1 (max k∈{1,...,N−1} ak,t − aN,t). Đây là sự khác biệt trung bình giữa độ chính xác tối đa thu được cho nhiệm vụ t và độ chính xác cuối cùng của nó. Độ chính xác cao hơn và quên lãng thấp hơn là mong muốn.

Sự chồng lấp Thưa thớt để Định lượng Nhiễu Tham số: Tiếp theo, chúng tôi đề xuất sự chồng lấp thưa thớt, một thước đo để định lượng nhiễu tham số cho một nhiệm vụ i, tức là phần trăm tham số trong mặt nạ Mi đã được cập nhật bởi một số nhiệm vụ trước đó. Để biết định nghĩa chính thức, tham khảo Phụ lục A.1

Các Phương pháp và Baseline Trước đó: Đối với cả nhiệm vụ thị giác và ngôn ngữ (VL), chúng tôi so sánh với: (VL.1) Huấn luyện Ngây thơ (Yogatama và cộng sự, 2019): trong đó tất cả các tham số mô hình được huấn luyện/tinh chỉnh tuần tự cho mỗi nhiệm vụ. (VL.2) Experience Replay (ER) (de Masson d'Autume và cộng sự, 2019): chúng tôi replay các ví dụ nhiệm vụ trước đó khi chúng tôi huấn luyện các nhiệm vụ mới; (VL.3) Multitask Learning (Crawshaw, 2020): trong đó tất cả các nhiệm vụ được sử dụng cùng nhau để huấn luyện mô hình; (VL.4) Individual Models: trong đó chúng tôi huấn luyện một mô hình riêng biệt cho mỗi nhiệm vụ. Điều này được coi là giới hạn trên cho CL; (VL.5) Supsup (Wortsman và cộng sự, 2020). Đối với ngôn ngữ tự nhiên (L), chúng tôi tiếp tục so sánh với các phương pháp sau: (L.6) Regularization (Huang và cộng sự, 2021): Cùng với phương pháp Replay, chúng tôi regularize các trạng thái ẩn của bộ phân loại BERT với một hạng tử mất mát L2; Chúng tôi hiển thị ba biến thể Adapter BERT (Houlsby và cộng sự, 2019), (L.7) AdaptBERT + FT trong đó chúng tôi có adapter đơn được tinh chỉnh cho tất cả nhiệm vụ; (L.8) AdaptBERT + ER trong đó một adapter đơn được tinh chỉnh với replay; (L.9) MultiAdaptBERT trong đó một adapter riêng biệt được tinh chỉnh cho mỗi nhiệm vụ; (L.10) Prompt Tuning (Li và Liang, 2021) học 50 token prompt liên tục khác nhau cho mỗi nhiệm vụ. (L.11) MBPA++ (de Masson d'Autume và cộng sự, 2019) thực hiện replay với các ví dụ ngẫu nhiên trong quá trình huấn luyện và thực hiện thích ứng cục bộ trong quá trình suy luận để chọn ví dụ replay; (L.12) LAMOL (Sun và cộng sự, 2019) sử dụng một mô hình ngôn ngữ để tạo các mẫu giả cho các nhiệm vụ trước đó để replay; (L.13) IDBR (Huang và cộng sự, 2021) tách các biểu diễn ẩn thành các biểu diễn chung và cụ thể nhiệm vụ và regularize chúng trong khi cũng thực hiện replay. Đối với nhiệm vụ thị giác (V), chúng tôi tiếp tục so sánh với hai phương pháp regularization phổ biến

--- TRANG 6 ---
Phương pháp (↓) GLUE WebNLP
Thứ tự (→) S1 S2 S3 S4 S5 Trung bình
Ngẫu nhiên 33.3 (-) 7.14 (-) 7.14 (-) 7.14 (-) 7.14 (-) 7.14 (-)
Multitask 79.9 (0.0) 77.2 (0.0) 77.2 (0.0) 77.2 (0.0) 77.2 (0.0) 77.2 (0.0)
Individual 87.7 (0.0) 79.5 (0.0) 79.5 (0.0) 79.5 (0.0) 79.5 (0.0) 79.5 (0.0)
FT 14.1 (86.0) 26.9 (62.1) 22.8 (67.6) 30.6 (55.9) 15.6 (76.8) 24.0 (65.6)
AdaptBERT + FT 24.7 (53.4) 20.8 (68.4) 19.1 (70.9) 23.6 (64.5) 14.6 (76.0) 19.6 (70.0)
AdaptBERT + Replay 76.8 (3.8) 73.2 (3.0) 74.5 (2.0) 74.5 (2.0) 74.6 (2.0) 74.2 (2.3)
MultiAdaptBERT 78.5 (0.0) 76.7 (0.0) 76.7 (0.0) 76.7 (0.0) 76.7 (0.0) 76.7 (0.0)
Prompt Tuning 76.3 (0.0) 66.3 (0.0) 66.3 (0.0) 66.3 (0.0) 66.3 (0.0) 66.3 (0.0)
Regularization 72.5 (8.8) 76.0 (2.8) 74.9 (3.8) 76.4 (1.8) 76.5 (2.0) 76.0 (2.6)
Replay 77.7 (4.8) 75.1 (3.1) 74.6 (3.5) 75.2 (2.2) 75.7 (3.1) 75.1 (3.0)
MBPA++ † - 74.9 (-) 73.1 (-) 74.9 (-) 74.1 (-) 74.3 (-)
LAMOL † - 76.1 (-) 76.1 (-) 77.2 (-) 76.7 (-) 76.5 (-)
IDBR 73.0 (6.8) 75.9 (2.7) 75.4 (3.5) 76.5 (1.6) 76.4 (1.9) 76.0 (2.4)
SupSup 78.3 (0.0) 75.9 (0.0) 76.1 (0.0) 76.0 (0.0) 75.9 (0.0) 76.0 (0.0)
SSNET 78.4 (3.6) 76.3 (0.8) 76.3 (0.8) 76.4 (0.3) 76.3 (0.3) 76.3 (0.6)
EXSSNET 80.5 (0.0) 77.0 (0.0) 77.1 (0.0) 76.7 (0.0) 76.9 (0.0) 76.9 (0.0)

Bảng 1: So sánh độ chính xác kiểm tra trung bình ↑ (và chỉ số quên lãng ↓) cho nhiều nhiệm vụ và thứ tự chuỗi với các phương pháp tiên tiến (SotA). Kết quả với † được lấy từ (Huang và cộng sự, 2021).

dựa trên phương pháp, (V.6) Online EWC (Schwarz và cộng sự, 2018), (V.7) Synaptic Intelligence (SI) (Zenke và cộng sự, 2017); một phương pháp knowledge distillation, (V.8) Learning without Forgetting (LwF) (Li và Hoiem, 2017), ba phương pháp experience replay bổ sung, (V.9) AGEM (Chaudhry và cộng sự, 2018), (V.10) Dark Experience Replay (DER) (Buzzega và cộng sự, 2020), (V.11) DER++ (Buzzega và cộng sự, 2020), và một phương pháp parameter isolation (V.12) CGATE (Abati và cộng sự, 2020).

Chi tiết Thực hiện: Theo Huang và cộng sự (2021), đối với các tập dữ liệu WebNLP chúng tôi học các thứ tự nhiệm vụ khác nhau S1-S51 được cung cấp trong Bảng 6 Phụ lục. Theo Huang và cộng sự (2021), đối với các thí nghiệm NLP, chúng tôi sử dụng BERT được huấn luyện trước làm mô hình cơ sở cho tất cả các phương pháp. Đối với SupSup, SSNET, và EXSSNET, chúng tôi sử dụng một đầu phân loại dựa trên CNN. Trừ khi được chỉ định, chúng tôi chia ngẫu nhiên tất cả các tập dữ liệu thị giác để thu được năm nhiệm vụ với các lớp rời rạc. Đối với các thí nghiệm thị giác, chúng tôi không sử dụng các mô hình được huấn luyện trước. Tất cả các phương pháp sử dụng cùng số epoch trên các tập dữ liệu. Để biết thêm chi tiết thực hiện, tham khảo Phụ lục A.3.

4.2 Kết quả Chính

Q1. Huấn luyện Mạng con Siêu mặt nạ có Giúp ích không? Trong các thí nghiệm này, chúng tôi chỉ ra rằng EXSSNET vượt trội so với nhiều phương pháp baseline mạnh bao gồm SupSup. Đối với các thí nghiệm ngôn ngữ chính của chúng tôi trong Bảng 1, chúng tôi học tuần tự nhiều thứ tự nhiệm vụ, S1 - S51 tương ứng với các benchmark GLUE và WebNLP. Các thứ tự nhiệm vụ này

1Ví dụ, trong thứ tự S2 mô hình học nhiệm vụ theo thứ tự này, ag yelp amazon yahoo dbpedia

Phương pháp S-MNIST S-CIFAR100 S-TinyImageNet
Multitask 96.5 (0.0) 53.0 (0.0) 45.9 (0.0)
Individual 99.7 (0.0) 75.5 (0.0) 53.7 (0.0)
Naive Sequential 49.6 (25.0) 19.3 (73.7) 11.5 (43.9)
EWC 96.1 (4.5) 32.4 (60.5) 20.5 (52.1)
SI 99.2 (0.6) 46.1 (47.8) 19.5 (46.2)
LwF 99.2 (0.8) 29.5 (70.2) 18.1 (56.5)
AGEM 98.3 (1.9) 52.1 (42.0) 21.6 (54.9)
ER 99.2 (0.6) 60.1 (27.5) 35.6 (36.0)
DER 98.9 (1.2) 62.5 (28.4) 35.9 (37.7)
DER++ 98.3 (1.8) 62.5 (27.5) 36.2 (35.7)
CGATE 99.6 (0.0) 60.1 (0.0) 49.2 (0.0)
SupSup 99.6 (0.0) 62.1 (0.0) 50.6 (0.0)
SSNET 99.7 (0.0) 23.9 (54.4) 49.6 (1.9)
EXSSNET 99.7 (0.0) 67.3 (0.0) 52.0 (0.0)

Bảng 2: Độ chính xác trung bình ↑ (Chỉ số quên lãng ↓) trên tất cả các nhiệm vụ cho thị giác. Đối với phương pháp của chúng tôi, chúng tôi báo cáo kết quả được tính trung bình trên ba seed ngẫu nhiên.

được liệt kê trong Bảng 6 Phụ lục. Chúng tôi báo cáo độ chính xác kiểm tra trung bình (và quên lãng trong ngoặc đơn). Đối với ngôn ngữ tự nhiên, chúng tôi thực hiện tốt hơn các phương pháp SOTA CL trước đó trong bốn trên năm trường hợp, qua nhiều thứ tự nhiệm vụ, và tổng hợp. Cụ thể, trên benchmark GLUE, EXSSNET tốt hơn ít nhất 2.0% so với các phương pháp khác trong khi tránh CF. Hơn nữa, EXSSNET vượt trội hoặc gần với hiệu suất của baseline multitasking là một baseline mạnh cho các phương pháp CL.

Đối với các nhiệm vụ thị giác, chúng tôi chia các tập dữ liệu MNIST, CIFAR100, và TinyImageNet thành năm nhiệm vụ khác nhau với số lượng lớp rời rạc bằng nhau và báo cáo kết quả. Từ Bảng 2, chúng tôi quan sát rằng EXSSNET dẫn đến cải thiện 4.8% và 1.4% so với baseline mạnh nhất cho các tập dữ liệu Split-CIFAR100 và Split-TinyImageNet. Hơn nữa, cả EXSSNET và SupSup đều vượt trội so với baseline multitask. Hơn nữa, EXSSNET thu hẹp khoảng cách với các mô hình được huấn luyện riêng lẻ một cách đáng kể, đối với TinyImageNet chúng tôi đạt trong vòng 1.7% của các mô hình riêng lẻ

--- TRANG 7 ---
Phương pháp S-MNIST S-CIFAR100 S-TinyImageNet
SupSup 99.6 62.1 50.6
+ KKT 99.6 [+0.0] 67.1 [+5.0] 53.3 [+2.7]
SSNET 99.7 23.9 49.6
+ KKT 99.3 [-0.4] 23.5 [-0.4] 51.8 [+2.2]
EXSSNET 99.7 67.3 52.0
+ KKT 99.7 [+0.0] 70.5 [+3.2] 54.0 [+2.0]

Bảng 3: Độ chính xác kiểm tra trung bình ↑ [và lợi ích từ KKT] khi sử dụng mô-đun chia sẻ kiến thức KKT.

0 20 40 60 8040506070
0 20 40 60 8040506070
0 20 40 60 8040506070
0 20 40 60 804050607080

ExSSNeT + KKT
ExSSNeT
Epochs Epochs Val. Accuracy Val. Accuracy Tăng tốc

Hình 4: Chúng tôi vẽ độ chính xác xác thực so với Epoch cho EXSSNET và EXSSNET + KKT. Chúng tôi quan sát rằng KKT giúp học các nhiệm vụ tiếp theo nhanh hơn và cải thiện hiệu suất.

hiệu suất của các mô hình. Sự chồng lấp thưa thớt trung bình của EXSSNET là 19.4% trên tất cả ba tập dữ liệu ngụ ý rằng có nhiều dung lượng hơn trong mô hình. Xem bảng 11 phụ lục để biết sự chồng lấp thưa thớt của các phương pháp khác và Phụ lục A.4.1 để biết kết quả các phương pháp hoạt động tốt nhất trên Tập dữ liệu Imagenet.

Lưu ý rằng, các phương pháp trước đây yêu cầu các thủ thuật như thích ứng cục bộ trong MBPA++, và experience replay trong AGEM, DER, LAMOL, và ER. Ngược lại, EXSSNET đơn giản và không yêu cầu replay.

Q2. Mô-đun Chuyển giao Kiến thức KKT có thể Chia sẻ Kiến thức Hiệu quả không? Trong Bảng 3, chúng tôi chỉ ra rằng việc thêm mô-đun KKT vào EXSSNET, SSNET, và SupSup cải thiện hiệu suất trên các benchmark thị giác. Thiết lập thí nghiệm ở đây tương tự như Bảng 2. Chúng tôi quan sát trên tất cả các phương pháp và tập dữ liệu rằng mô-đun KKT cải thiện độ chính xác kiểm tra trung bình. Cụ thể, đối với tập dữ liệu Split-CIFAR100, mô-đun KKT dẫn đến cải thiện 5.0%, và 3.2% cho SupSup và EXSSNET tương ứng; trong khi đối với Split-TinyImageNet, EXSSNET + KKT vượt trội so với các mô hình riêng lẻ. Chúng tôi quan sát sự suy giảm hiệu suất cho SSNET khi sử dụng KKT vì KKT thúc đẩy chia sẻ tham số qua các nhiệm vụ có thể dẫn đến hiệu suất tồi tệ hơn cho SSNET. Hơn nữa, EXSSNET + KKT vượt trội so với tất cả các phương pháp khác trên cả tập dữ liệu Split-CIFAR100 và Split-TinyImageNet. Đối với EXSSNET + KKT,

0.020.040.060.080.10.20.30.50.70.9304050607080

Các phương pháp
ExSSNeT
SSNeT
SupSup
Mật độ Mặt nạ (Thang Log) Độ chính xác Kiểm tra Trung bình

Hình 5: Độ chính xác kiểm tra trung bình so với mật độ mặt nạ trên tập dữ liệu SplitCIFAR100.

Phương pháp S-TinyImageNet Sự chồng lấp Thưa thớt Trung bình
SupSup 90.34 (0.0) 90.1
SSNET 89.02 (2.2) 90.0
EXSSNET 91.21 (0.0) 90.0

Bảng 4: Độ chính xác trung bình ↑ (chỉ số quên lãng ↓) và sự chồng lấp thưa thớt trung bình khi học 100 nhiệm vụ.

sự chồng lấp thưa thớt trung bình là 49.6% trên tất cả ba tập dữ liệu (xem bảng 11 phụ lục). Các kết quả này gợi ý rằng việc kết hợp huấn luyện trọng số với mô-đun KKT dẫn đến những cải thiện thêm.

Q3. Mô-đun Chuyển giao Kiến thức KKT có thể Cải thiện Tốc độ Học của các Nhiệm vụ Tiếp theo không? Tiếp theo, chúng tôi chỉ ra rằng mô-đun KKT cho phép chúng ta học các nhiệm vụ mới nhanh hơn. Để chứng minh điều này, trong Hình 4 chúng tôi vẽ trung bình chạy của độ chính xác xác thực so với epoch cho các nhiệm vụ khác nhau từ thí nghiệm Split-CIFAR100 trong Bảng 3. Chúng tôi hiển thị các đường cong cho EXSSNET có và không có mô-đun KKT và bỏ qua nhiệm vụ đầu tiên vì cả hai phương pháp này giống hệt nhau cho Nhiệm vụ 1 vì không có nhiệm vụ trước đó để chuyển giao kiến thức. Đối với tất cả các nhiệm vụ tiếp theo (Nhiệm vụ 2,3,4,5), chúng tôi quan sát rằng – (1) EXSSNET + KKT bắt đầu với hiệu suất ban đầu tốt hơn nhiều so với EXSSNET (2) với số epoch cố định để huấn luyện, EXSSNET + KKT luôn học nhiệm vụ tốt hơn vì nó có độ chính xác tốt hơn ở tất cả các epoch; và (3) EXSSNET + KKT có thể đạt được hiệu suất tương tự như EXSSNET trong ít epoch hơn nhiều như được hiển thị bởi các mũi tên ngang màu xanh lá. Điều này minh họa rõ ràng rằng việc sử dụng mô-đun chuyển giao kiến thức KKT không chỉ giúp học các nhiệm vụ tốt hơn (xem Bảng 3) mà còn học chúng nhanh hơn. Để biết phân tích hiệu quả và độ bền của mô-đun KKT, vui lòng tham khảo Phụ lục A.4.2.

4.3 Kết quả và Phân tích Bổ sung

Q4. Ảnh hưởng của Mật độ Mặt nạ lên Hiệu suất: Tiếp theo, chúng tôi chỉ ra lợi thế của việc sử dụng EXSSNET khi mật độ mặt nạ thấp. Trong Hình 5, chúng tôi hiển thị độ chính xác trung bình cho tập dữ liệu Split-CIFAR100 như một hàm của mật độ mặt nạ. Chúng tôi quan sát

--- TRANG 8 ---
Phương pháp FastText Glove BERT
SupSup 54.01 55.52 74.0
SSNET 60.41 [+6.4] 59.78 [+4.3] 74.5 [+0.5]
EXSSNET 62.52 [+8.5] 62.81 [+7.3] 74.8 [+0.8]

Bảng 5: Kết quả ablation cho token embeddings. Chúng tôi báo cáo độ chính xác trung bình ↑ [và lợi ích so với SupSup]

rằng EXSSNET đạt được cải thiện 7.9%, 18.4%, 8.4%, và 4.7% so với SupSup cho các giá trị mật độ mặt nạ 0.02, 0.04, 0.06, 0.08 tương ứng. Đây là một tính chất hấp dẫn vì các nhiệm vụ chọn ít tham số hơn vốn dĩ giảm sự chồng lấp thưa thớt cho phép EXSSNET học một số lượng lớn các nhiệm vụ.

Q5. EXSSNET có thể Học một Số lượng lớn Nhiệm vụ không? SupSup đã chỉ ra rằng nó có thể mở rộng đến một số lượng lớn các nhiệm vụ. Tiếp theo, chúng tôi thực hiện các thí nghiệm để học 100 nhiệm vụ được tạo bằng cách chia tập dữ liệu TinyImageNet. Trong Bảng 4, chúng tôi chỉ ra rằng tính chất này được bảo tồn bởi EXSSNET trong khi dẫn đến cải thiện hiệu suất so với SupSup. Chúng tôi lưu ý rằng khi số lượng nhiệm vụ tăng, sự chồng lấp thưa thớt giữa các mặt nạ cũng tăng dẫn đến ít trọng số mô hình có thể huấn luyện hơn. Trong trường hợp cực đoan không có trọng số tự do, EXSSNET theo thiết kế giảm xuống SupSup vì sẽ không có huấn luyện trọng số. Hơn nữa, nếu chúng ta sử dụng các mô hình lớn hơn sẽ có nhiều tham số tự do hơn, dẫn đến cải thiện nhiều hơn so với SupSup.

Q6. Ảnh hưởng của Khởi tạo Token Embedding cho NLP: Đối với các thí nghiệm ngôn ngữ của chúng tôi, chúng tôi sử dụng mô hình BERT được huấn luyện trước (Devlin và cộng sự, 2019) để thu được các biểu diễn token ban đầu. Chúng tôi thực hiện ablation về khởi tạo token embedding để hiểu tác động của nó đối với các phương pháp CL. Trong Bảng 5, chúng tôi trình bày kết quả trên chuỗi thứ tự nhiệm vụ S21 của phiên bản được lấy mẫu của tập dữ liệu WebNLP (xem Mục 4.1, Tập dữ liệu). Chúng tôi khởi tạo các biểu diễn token sử dụng FastText (Bojanowski và cộng sự, 2016), Glove (Pennington và cộng sự, 2014), và BERT embeddings. Từ Bảng 5, chúng tôi quan sát rằng – (1) khoảng cách hiệu suất giữa EXSSNET và SupSup tăng từ 0.8% → 7.3% và 0.8% → 8.5% khi chuyển từ BERT sang khởi tạo Glove và FastText tương ứng. Những lợi ích này ngụ ý rằng việc sử dụng EXSSNET còn có lợi hơn nữa khi thiếu các biểu diễn ban đầu tốt, và (2) xu hướng hiệu suất, EXSSNET > SSNET > SupSup là nhất quán qua các khởi tạo.

5 Công trình Liên quan

Các phương pháp dựa trên Regularization ước tính tầm quan trọng của các thành phần mô hình và thêm các hạng tử regularization quan trọng vào hàm mất mát. Zenke và cộng sự (2017) regularize dựa trên khoảng cách của các trọng số từ khởi tạo của chúng, trong khi Kirkpatrick và cộng sự (2017b); Schwarz và cộng sự (2018) sử dụng một xấp xỉ của ma trận thông tin Fisher (Pascanu và Bengio, 2013) để regularize các tham số. Trong NLP, Han và cộng sự (2020); Wang và cộng sự (2019) sử dụng regularization để ràng buộc thông tin liên quan từ lượng kiến thức khổng lồ bên trong các mô hình ngôn ngữ lớn (LLM). Huang và cộng sự (2021) đầu tiên xác định các không gian ẩn cần được cập nhật so với giữ lại thông qua tách rời thông tin (Fu và cộng sự, 2017; Li và cộng sự, 2020) và sau đó regularize các không gian ẩn này riêng biệt.

Các phương pháp dựa trên Replay duy trì một buffer bộ nhớ nhỏ các mẫu dữ liệu (De Lange và cộng sự, 2019; Yan và cộng sự, 2022) hoặc các proxy liên quan của chúng (Rebuffi và cộng sự, 2017) từ các nhiệm vụ trước đó và huấn luyện lại trên chúng sau đó để ngăn chặn CF. Chaudhry và cộng sự (2018) sử dụng buffer trong quá trình tối ưu hóa để ràng buộc gradient tham số. Shin và cộng sự (2017); Kemker và Kanan (2018) sử dụng một mô hình sinh để lấy mẫu và replay dữ liệu giả trong quá trình huấn luyện, trong khi Rebuffi và cộng sự (2017) replay kiến thức chưng cất từ các nhiệm vụ trước đó. de Masson d'Autume và cộng sự (2019) sử dụng bộ nhớ episodic cùng với thích ứng cục bộ, trong khi Sun và cộng sự (2019) huấn luyện một mô hình ngôn ngữ để tạo mẫu giả cho replay.

Các phương pháp dựa trên Kiến trúc có thể được chia thành hai danh mục: (1) các phương pháp thêm các mô-đun mới theo thời gian (Li và cộng sự, 2019; Veniat và cộng sự, 2021; Douillard và cộng sự, 2022); và (2) các phương pháp cô lập các tham số của mạng cho các nhiệm vụ khác nhau (Kirkpatrick và cộng sự, 2017a; Fernando và cộng sự, 2017; Mallya và Lazebnik, 2018; Fernando và cộng sự, 2017). Rusu và cộng sự (2016) giới thiệu một mạng mới cho mỗi nhiệm vụ trong khi Schwarz và cộng sự (2018) chưng cất mạng mới sau mỗi nhiệm vụ vào mạng gốc. Các mô hình CL dựa trên prompt learning gần đây cho thị giác (Wang và cộng sự, 2022a,b) giả định quyền truy cập vào một mô hình được huấn luyện trước để học một tập hợp các prompt có thể được chia sẻ qua các nhiệm vụ để thực hiện CL điều này trực giao với phương pháp của chúng tôi huấn luyện từ đầu. Mallya và Lazebnik (2018) phân bổ tham số cho các nhiệm vụ cụ thể và sau đó huấn luyện chúng cô lập hạn chế số lượng nhiệm vụ có thể được học. Ngược lại, Mallya và cộng sự (2018) sử dụng một mô hình được huấn luyện trước đông lạnh và học một mặt nạ mới cho mỗi nhiệm vụ nhưng một mô hình được huấn luyện trước là rất quan trọng cho hiệu suất tốt của phương pháp của họ. Wortsman và cộng sự (2020) loại bỏ sự phụ thuộc mô hình được huấn luyện trước và học một mặt nạ cho mỗi nhiệm vụ trên một mạng được khởi tạo ngẫu nhiên cố định. EXSSNET tránh các nhược điểm của Mallya và Lazebnik (2018); Mallya và cộng sự (2018) và thực hiện huấn luyện mạng con siêu mặt nạ để tăng khả năng biểu diễn so với (Wortsman và cộng sự, 2020) trong khi thực hiện chuyển giao kiến thức và tránh CF.

6 Kết luận

Chúng tôi đã giới thiệu một phương pháp Học liên tục mới, EXSSNET (Huấn luyện Mạng con Siêu mặt nạ Độc quyền), mang lại hiệu suất nâng cao bằng cách sử dụng huấn luyện trọng số mạng con độc quyền, không chồng lấp, vượt qua các hạn chế biểu diễn của phương pháp SupSup trước đó. Thông qua việc tránh các cập nhật trọng số xung đột, EXSSNET không chỉ cải thiện hiệu suất mà còn loại bỏ quên lãng, tạo ra một sự cân bằng tinh tế. Hơn nữa, việc bao gồm mô-đun Chuyển giao Kiến thức (KKT) thúc đẩy quá trình học, sử dụng kiến thức đã thu được trước đó để đẩy nhanh và nâng cao việc học các nhiệm vụ mới. Hiệu quả của EXSSNET được chứng thực bởi hiệu suất vượt trội của nó trong cả lĩnh vực NLP và Thị giác, khả năng thành thạo đặc biệt cho các mặt nạ thưa thớt, và khả năng mở rộng lên đến một trăm nhiệm vụ.

Hạn chế

Thứ nhất, chúng tôi lưu ý rằng khi mật độ của mặt nạ tăng, việc cải thiện hiệu suất so với phương pháp SupSup bắt đầu giảm. Điều này là do các mạng con dày đặc hơn dẫn đến mức độ chồng lấp thưa thớt cao hơn, để lại ít tham số tự do hơn cho các nhiệm vụ mới để cập nhật. Tuy nhiên, đáng lưu ý rằng ngay cả trong các tình huống mà mật độ mặt nạ cao hơn, tất cả các trọng số mô hình vẫn được huấn luyện bởi một số nhiệm vụ, cải thiện hiệu suất trên các nhiệm vụ đó và làm cho phương pháp đề xuất của chúng tôi trở thành giới hạn trên cho hiệu suất của SupSup. Ngoài ra, kích thước và dung lượng mô hình có thể được tăng lên để cân bằng tác động của mật độ mặt nạ cao hơn. Hơn nữa, nói chung, một mặt nạ thưa thớt được ưa thích cho hầu hết các ứng dụng do tính hiệu quả của nó.

Thứ hai, chúng tôi đã tập trung vào thiết lập tăng dần nhiệm vụ của học liên tục vì hai lý do chính: (1) trong lĩnh vực xử lý ngôn ngữ tự nhiên, danh tính nhiệm vụ thường dễ dàng thu được, và các phương pháp phổ biến như prompting và adaptors giả định quyền truy cập vào danh tính nhiệm vụ. (2) trọng tâm chính của công trình chúng tôi là cải thiện hiệu suất của siêu mặt nạ cho học liên tục và phát triển một cơ chế hiệu quả hơn để tái sử dụng kiến thức đã học, điều này trực giao với câu hỏi liệu danh tính nhiệm vụ có được cung cấp trong thời gian kiểm tra hay không.

Hơn nữa, đáng lưu ý rằng, tương tự như phương pháp SupSup, phương pháp đề xuất của chúng tôi cũng có thể được mở rộng cho các tình huống mà danh tính nhiệm vụ không được cung cấp trong quá trình suy luận. Bài báo SupSup trình bày một phương pháp để làm điều này bằng cách tối thiểu hóa entropy để chọn mặt nạ tốt nhất trong quá trình suy luận, và điều này cũng có thể được áp dụng trực tiếp cho phương pháp đề xuất của chúng tôi, ExSSNeT, trong các tình huống mà danh tính nhiệm vụ không được cung cấp trong quá trình suy luận. Điều này trực giao với các câu hỏi chính của nghiên cứu chúng tôi, tuy nhiên, chúng tôi thực hiện một số thí nghiệm về Học Tăng dần Lớp trong phụ lục A.4.3.

Lời cảm ơn

Chúng tôi cảm ơn Marc'Aurelio Ranzato cho các cuộc thảo luận hữu ích để hình thành ý tưởng ban đầu. Chúng tôi cảm ơn các nhà đánh giá và Xiang Zhou, Swarnadeep Saha, và Archiki Prasad vì phản hồi có giá trị của họ về bài báo này. Công trình này được hỗ trợ bởi NSF-CAREER Award 1846185, DARPA Machine-Commonsense (MCS) Grant N66001-19-2-4031, Microsoft Investigator Fellowship, và Google và AWS cloud compute awards. Các quan điểm có trong bài viết này là của các tác giả chứ không phải của cơ quan tài trợ.

Tài liệu tham khảo

Davide Abati, Jakub Tomczak, Tijmen Blankevoort, Simone Calderara, Rita Cucchiara, và Babak Ehteshami Bejnordi. 2020. Conditional channel gated networks for task-aware continual learning. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, trang 3931–3940.

Yoshua Bengio, Nicholas Léonard, và Aaron C. Courville. 2013. Estimating or propagating gradients through stochastic neurons for conditional computation. CoRR, abs/1308.3432.

Magdalena Biesialska, Katarzyna Biesialska, và Marta R. Costa-jussà. 2020. Continual lifelong learning in natural language processing: A survey. Trong Proceedings of the 28th International Conference on Computational Linguistics, trang 6523–6541, Barcelona, Spain (Online). International Committee on Computational Linguistics.

--- TRANG 9 ---
Piotr Bojanowski, Edouard Grave, Armand Joulin, và Tomas Mikolov. 2016. Enriching word vectors with subword information. arXiv preprint arXiv:1607.04606.

Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, và Simone Calderara. 2020. Dark experience for general continual learning: a strong, simple baseline. Trong Advances in Neural Information Processing Systems, tập 33, trang 15920–15930. Curran Associates, Inc.

Ming-Wei Chang, Lev Ratinov, Dan Roth, và Vivek Srikumar. 2008. Importance of semantic representation: Dataless classification. Trong Proceedings of the 23rd National Conference on Artificial Intelligence - Volume 2, AAAI'08, trang 830–835. AAAI Press.

Arslan Chaudhry, Marc'Aurelio Ranzato, Marcus Rohrbach, và Mohamed Elhoseiny. 2018. Efficient lifelong learning with a-gem. arXiv preprint arXiv:1812.00420.

Michael Crawshaw. 2020. Multi-task learning with deep neural networks: A survey. ArXiv, abs/2009.09796.

Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Gregory Slabaugh, và Tinne Tuytelaars. 2019. Continual learning: A comparative study on how to defy forgetting in classification tasks. arXiv preprint arXiv:1909.08383, 2(6).

Matthias De Lange và Tinne Tuytelaars. 2021. Continual prototype evolution: Learning online from non-stationary data streams. Trong Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), trang 8250–8259.

Cyprien de Masson d'Autume, Sebastian Ruder, Lingpeng Kong, và Dani Yogatama. 2019. Episodic memory in lifelong language learning. Trong Advances in Neural Information Processing Systems, tập 32. Curran Associates, Inc.

Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, và Li Fei-Fei. 2009. Imagenet: A large-scale hierarchical image database. Trong CVPR 2009.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. Trong Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), trang 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.

Arthur Douillard, Alexandre Ramé, Guillaume Couairon, và Matthieu Cord. 2022. Dytox: Transformers for continual learning with dynamic token expansion. Trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR).

Chrisantha Fernando, Dylan Banarse, Charles Blundell, Yori Zwols, David Ha, Andrei A. Rusu, Alexander Pritzel, và Daan Wierstra. 2017. Pathnet: Evolution channels gradient descent in super neural networks. CoRR, abs/1701.08734.

Jonathan Frankle và Michael Carbin. 2018. The lottery ticket hypothesis: Finding sparse, trainable neural networks. arXiv preprint arXiv:1803.03635.

Zhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan Zhao, và Rui Yan. 2017. Style transfer in text: Exploration and evaluation. arXiv preprint arXiv:1711.06861.

Xu Han, Yi Dai, Tianyu Gao, Yankai Lin, Zhiyuan Liu, Peng Li, Maosong Sun, và Jie Zhou. 2020. Continual relation learning via episodic memory activation and reconsolidation. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, trang 6429–6440, Online. Association for Computational Linguistics.

Kaiming He, X. Zhang, Shaoqing Ren, và Jian Sun. 2016. Deep residual learning for image recognition. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), trang 770–778.

Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, và Sylvain Gelly. 2019. Parameter-efficient transfer learning for NLP. Trong Proceedings of the 36th International Conference on Machine Learning, tập 97 của Proceedings of Machine Learning Research, trang 2790–2799. PMLR.

Yufan Huang, Yanzhe Zhang, Jiaao Chen, Xuezhi Wang, và Diyi Yang. 2021. Continual learning for text classification with information disentanglement based regularization. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 2736–2746, Online. Association for Computational Linguistics.

Ronald Kemker và Christopher Kanan. 2018. Fearnet: Brain-inspired model for incremental learning. Trong International Conference on Learning Representations.

Yoon Kim. 2014. Convolutional neural networks for sentence classification. Trong Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), trang 1746–1751, Doha, Qatar. Association for Computational Linguistics.

Diederik P Kingma và Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.

--- TRANG 10 ---
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, và Raia Hadsell. 2017a. Overcoming catastrophic forgetting in neural networks. Proceedings of the National Academy of Sciences, 114(13):3521–3526.

James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, và cộng sự. 2017b. Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy of sciences, 114(13):3521–3526.

Y. Lecun, L. Bottou, Y. Bengio, và P. Haffner. 1998. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324.

Xiang Lisa Li và Percy Liang. 2021. Prefix-tuning: Optimizing continuous prompts for generation. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), trang 4582–4597, Online. Association for Computational Linguistics.

Xilai Li, Yingbo Zhou, Tianfu Wu, Richard Socher, và Caiming Xiong. 2019. Learn to grow: A continual structure learning framework for overcoming catastrophic forgetting. Trong International Conference on Machine Learning, trang 3925–3934. PMLR.

Yuan Li, Chunyuan Li, Yizhe Zhang, Xiujun Li, Guoqing Zheng, Lawrence Carin, và Jianfeng Gao. 2020. Complementary auxiliary classifiers for label-conditional text generation. Proceedings of the AAAI Conference on Artificial Intelligence, 34(05):8303–8310.

Zhizhong Li và Derek Hoiem. 2017. Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence, 40(12):2935–2947.

David Lopez-Paz và Marc'Aurelio Ranzato. 2017. Gradient episodic memory for continual learning. Trong Advances in Neural Information Processing Systems, trang 6467–6476.

Ilya Loshchilov và Frank Hutter. 2016. Sgdr: Stochastic gradient descent with warm restarts.

Arun Mallya, Dillon Davis, và Svetlana Lazebnik. 2018. Piggyback: Adapting a single network to multiple tasks by learning to mask weights. Trong Proceedings of the European Conference on Computer Vision (ECCV), trang 67–82.

Arun Mallya và Svetlana Lazebnik. 2018. Packnet: Adding multiple tasks to a single network by iterative pruning. Trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, trang 7765–7773.

Julian McAuley và Jure Leskovec. 2013. Hidden factors and hidden topics: Understanding rating dimensions with review text. Trong Proceedings of the 7th ACM Conference on Recommender Systems, RecSys '13, trang 165–172, New York, NY, USA. Association for Computing Machinery.

Michael McCloskey và Neal J Cohen. 1989. Catastrophic interference in connectionist networks: The sequential learning problem. Trong Psychology of learning and motivation, tập 24, trang 109–165. Elsevier.

Pablo Mendes, Max Jakob, và Christian Bizer. 2012. DBpedia: A multilingual cross-domain knowledge base. Trong Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC'12), trang 1813–1817, Istanbul, Turkey. European Language Resources Association (ELRA).

Razvan Pascanu và Yoshua Bengio. 2013. Revisiting natural gradient for deep networks. arXiv preprint arXiv:1301.3584.

Jeffrey Pennington, Richard Socher, và Christopher Manning. 2014. GloVe: Global vectors for word representation. Trong Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), trang 1532–1543, Doha, Qatar. Association for Computational Linguistics.

Vivek Ramanujan, Mitchell Wortsman, Aniruddha Kembhavi, Ali Farhadi, và Mohammad Rastegari. 2019. What's hidden in a randomly weighted neural network? arXiv preprint arXiv:1911.13299.

Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, và Christoph H Lampert. 2017. icarl: Incremental classifier and representation learning. Trong Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, trang 2001–2010.

Mark B Ring. 1998. Child: A first step towards continual learning. Trong Learning to learn, trang 261–292. Springer.

Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, và Raia Hadsell. 2016. Progressive neural networks. arXiv preprint arXiv:1606.04671.

Jonathan Schwarz, Jelena Luketina, Wojciech M Czarnecki, Agnieszka Grabska-Barwinska, Yee Whye Teh, Razvan Pascanu, và Raia Hadsell. 2018. Progress & compress: A scalable framework for continual learning. arXiv preprint arXiv:1805.06370.

Hanul Shin, Jung Kwon Lee, Jaehong Kim, và Jiwon Kim. 2017. Continual learning with deep generative replay. Trong Advances in Neural Information Processing Systems, trang 2990–2999.

Fan-Keng Sun, Cheng-Hao Ho, và Hung-Yi Lee. 2019. Lamol: Language modeling for lifelong language learning. Trong International Conference on Learning Representations.

--- TRANG 11 ---
Sebastian Thrun. 1998. Lifelong learning algorithms. Trong Learning to learn, trang 181–209. Springer.

Tom Veniat, Ludovic Denoyer, và MarcAurelio Ranzato. 2021. Efficient continual learning with modular networks and task-driven priors. Trong International Conference on Learning Representations.

Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, và Samuel Bowman. 2018. GLUE: A multi-task benchmark and analysis platform for natural language understanding. Trong Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, trang 353–355, Brussels, Belgium. Association for Computational Linguistics.

Hong Wang, Wenhan Xiong, Mo Yu, Xiaoxiao Guo, Shiyu Chang, và William Yang Wang. 2019. Sentence embedding alignment for lifelong relation extraction. Trong Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), trang 796–806, Minneapolis, Minnesota. Association for Computational Linguistics.

Zifeng Wang, Zizhao Zhang, Sayna Ebrahimi, Ruoxi Sun, Han Zhang, Chen-Yu Lee, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer Dy, và cộng sự. 2022a. Dualprompt: Complementary prompting for rehearsal-free continual learning. European Conference on Computer Vision.

Zifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang, Ruoxi Sun, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer Dy, và Tomas Pfister. 2022b. Learning to prompt for continual learning. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, trang 139–149.

Yeming Wen, Dustin Tran, và Jimmy Ba. 2020. Batchensemble: an alternative approach to efficient ensemble and lifelong learning. arXiv preprint arXiv:2002.06715.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, và Alexander Rush. 2020. Transformers: State-of-the-art natural language processing. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, trang 38–45, Online. Association for Computational Linguistics.

Mitchell Wortsman, Vivek Ramanujan, Rosanne Liu, Aniruddha Kembhavi, Mohammad Rastegari, Jason Yosinski, và Ali Farhadi. 2020. Supermasks in superposition. Trong Advances in Neural Information Processing Systems, tập 33, trang 15173–15184. Curran Associates, Inc.

Qingsen Yan, Dong Gong, Yuhang Liu, Anton van den Hengel, và Javen Qinfeng Shi. 2022. Learning bayesian sparse networks with full experience replay for continual learning. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, trang 109–118.

Dani Yogatama, Cyprien de Masson d'Autume, Jerome Connor, Tomas Kocisky, Mike Chrzanowski, Lingpeng Kong, Angeliki Lazaridou, Wang Ling, Lei Yu, Chris Dyer, và cộng sự. 2019. Learning and evaluating general linguistic intelligence. arXiv preprint arXiv:1901.11373.

Friedemann Zenke, Ben Poole, và Surya Ganguli. 2017. Continual learning through synaptic intelligence. Trong Proceedings of the 34th International Conference on Machine Learning-Volume 70, trang 3987–3995. JMLR. org.

Xiang Zhang, Junbo Zhao, và Yann LeCun. 2015. Character-level convolutional networks for text classification. Trong Advances in neural information processing systems, trang 649–657.

Jieyu Zhao và Jurgen Schmidhuber. 1996. Incremental self-improvement for life-time multi-agent reinforcement learning. Trong From Animals to Animats 4: Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior, Cambridge, MA, trang 516–525.

Hattie Zhou, Janice Lan, Rosanne Liu, và Jason Yosinski. 2019. Deconstructing lottery tickets: Zeros, signs, and the supermask. Trong Advances in Neural Information Processing Systems, trang 3592–3602.

A Phụ lục cho EXSSNET

A.1 Sự chồng lấp Thưa thớt để Định lượng Nhiễu Tham số

Tiếp theo, chúng tôi đề xuất một thước đo để định lượng nhiễu tham số cho một nhiệm vụ i, tức là phần trăm tham số trong mặt nạ Mi đã được cập nhật bởi một số nhiệm vụ trước đó. Chúng tôi định nghĩa sự chồng lấp thưa thớt như sự khác biệt giữa số lượng tham số được chọn bởi mặt nạ Mi và Mfree i chia cho tổng số tham số được chọn bởi Mi. Chính thức, chúng tôi định nghĩa sự chồng lấp thưa thớt (SO) giữa siêu mặt nạ hiện tại Mi và các siêu mặt nạ cho các nhiệm vụ trước đó {Mj}i−1 j=1 như,

SO(Mi,{Mj}i−1 j=1) = sum(Mi)−sum(Mfree i) / sum(Mi) (2)

và Mfree i = Mi ∧ ¬(∨i−1 j=1(Mj))

trong đó ∧, ∨, ¬ là các phép toán logic và, hoặc, và không.

--- TRANG 12 ---
ID Chuỗi Nhiệm vụ
S1 mnli qqp qnli sst2 cola (Kích thước dữ liệu giảm dần)
S2 ag yelp amazon yahoo dbpedia
S3 yelp yahoo amazon dbpedia ag
S4 dbpedia yahoo ag amazon yelp
S5 yelp ag dbpedia amazon yahoo
S6 ag yelp yahoo
S7 yelp yahoo ag
S8 yahoo ag yelp

Bảng 6: Chuỗi nhiệm vụ được sử dụng trong các thí nghiệm văn bản. Đối với tập dữ liệu GLUE, chúng tôi sử dụng thứ tự tương ứng với kích thước dữ liệu huấn luyện giảm dần. Chuỗi S2-S8 từ (Huang và cộng sự, 2021; de Masson d'Autume và cộng sự, 2019; Sun và cộng sự, 2019).

Tập dữ liệu Loại Lớp Huấn luyện Xác thực Kiểm tra
AGNews 4 Tin tức 8k 8k 7.6k
Yelp 5 Tình cảm 10k 10k 7.6k
Amazon 5 Tình cảm 10k 10k 7.6k
DBPedia 14 Wikipedia 28k 28k 7.6k
Yahoo 10 Q&A 20k 20k 7.6k

Bảng 7: Thống kê cho dữ liệu được lấy mẫu từ Huang và cộng sự (2021) để tinh chỉnh siêu tham số. Tập xác thực có cùng kích thước với tập huấn luyện. Lớp có nghĩa là số lượng lớp đầu ra cho nhiệm vụ phân loại văn bản. Loại là lĩnh vực của phân loại văn bản.

A.2 Độ phức tạp Không gian, Thời gian, và Bộ nhớ của EXSSNET

Để huấn luyện, chúng tôi lưu trữ một tập hợp điểm số bổ sung trên GPU với kích thước như trọng số mô hình. Bộ nhớ GPU bổ sung yêu cầu là một phần nhỏ vì các kích hoạt mô hình chiếm một phần lớn tổng bộ nhớ GPU. Thời gian chạy của chúng tôi tương tự như huấn luyện trọng số của một mô hình với <5% overhead do các phép toán logic trên mặt nạ và che mặt nạ trọng số trong các lượt truyền xuôi. Để so sánh thời gian huấn luyện, tham khảo Bảng 13 Phụ lục. Trên đĩa, chúng tôi cần lưu trữ k * |W| trọng số đã cập nhật 32-bit và mặt nạ boolean mất 1-bit cho mỗi tham số. Do đó, chúng tôi mất tối đa max(|W| * k * t, |W|) * 32 + |W| * 1 bit tổng cộng vì trong trường hợp xấu nhất chúng tôi cần lưu trữ tất cả |W| trọng số mô hình.

A.3 Thiết lập thí nghiệm và siêu tham số

Trừ khi được chỉ định khác, chúng tôi thu được siêu mặt nạ với mật độ mặt nạ 0.1. Trong các mô hình CNN của chúng tôi, chúng tôi sử dụng batch normalization không affine để tránh lưu trữ các tham số mean và variance của chúng cho tất cả các nhiệm vụ (Wortsman và cộng sự, 2020). Tương tự như (Wortsman và cộng sự, 2020), các hạng tử bias trong mô hình của chúng tôi là 0 và chúng tôi khởi tạo ngẫu nhiên các tham số mô hình sử dụng signed kaiming constant (Ramanujan và cộng sự, 2019). Chúng tôi sử dụng bộ tối ưu hóa Adam (Kingma và Ba, 2014) cùng với cosine decay (Loshchilov và Hutter, 2016) và tiến hành các thí nghiệm của chúng tôi trên GPU với bộ nhớ 12GB. Chúng tôi đã sử dụng khoảng 6 ngày thời gian chạy GPU. Đối với thí nghiệm chính của chúng tôi, chúng tôi chạy ba lần độc lập cho mỗi thí nghiệm và báo cáo trung bình cho tất cả các chỉ số và thí nghiệm. Đối với các nhiệm vụ ngôn ngữ tự nhiên, trừ khi được chỉ định khác, chúng tôi khởi tạo token embedding cho các phương pháp của chúng tôi sử dụng các biểu diễn của mô hình BERT-base-uncased đông lạnh (Devlin và cộng sự, 2018) sử dụng Huggingface (Wolf và cộng sự, 2020). Chúng tôi sử dụng một mô hình CNN tĩnh từ Kim (2014) làm bộ phân loại văn bản trên các biểu diễn BERT. Mô hình sử dụng convolution 1D cùng với kích hoạt Tanh. Tổng số tham số mô hình là ~110M. Theo Sun và cộng sự (2019); Huang và cộng sự (2021), chúng tôi đánh giá mô hình của chúng tôi trên các chuỗi nhiệm vụ khác nhau như được cung cấp trong Bảng 6 Phụ lục, trong khi giới hạn số lượng token tối đa là 256. Theo (Wortsman và cộng sự, 2020), chúng tôi sử dụng LeNet (Lecun và cộng sự, 1998) cho tập dữ liệu SplitMNIST, một mô hình Resnet-18 với ít kênh hơn (Wortsman và cộng sự, 2020) cho tập dữ liệu SplitCIFAR100, một mô hình ResNet50 (He và cộng sự, 2016) cho tập dữ liệu TinyImageNet. Trừ khi được chỉ định, chúng tôi chia ngẫu nhiên tất cả các tập dữ liệu thị giác để thu được năm nhiệm vụ với các lớp rời rạc. Chúng tôi sử dụng codebase của DER (Buzzega và cộng sự, 2020) để thu được các baseline thị giác. Trong tất cả các thí nghiệm của chúng tôi, tất cả các phương pháp thực hiện số epoch bằng nhau trên các tập dữ liệu. Chúng tôi sử dụng các siêu tham số từ Wortsman và cộng sự (2020) cho các thí nghiệm thị giác của chúng tôi.

Đối với thí nghiệm ablation trên dữ liệu ngôn ngữ tự nhiên, theo Huang và cộng sự (2021), chúng tôi sử dụng một phiên bản được lấy mẫu của các tập dữ liệu WebNLP do nguồn lực hạn chế. Tập dữ liệu thu gọn chứa 2000 ví dụ huấn luyện và xác thực từ mỗi lớp đầu ra. Tập kiểm tra giống như các thí nghiệm chính. Thống kê tập dữ liệu được tóm tắt trong Bảng 7. Đối với các tập dữ liệu WebNLP, chúng tôi tinh chỉnh tốc độ học trên tập xác thực qua các giá trị {0.01, 0.001, 0.0001}, đối với các tập dữ liệu GLUE chúng tôi sử dụng tốc độ học mặc định của mô hình BERT. Đối với các thí nghiệm thị giác của chúng tôi, chúng tôi sử dụng tốc độ học mặc định cho tập dữ liệu được cung cấp trong triển khai gốc của chúng. Đối với TinyImageNet, SplitCIFAR100, tập dữ liệu SplitMNIST, chúng tôi chạy trong 30, 100, và 30 epoch tương ứng. Chúng tôi lưu trữ 0.1% tập dữ liệu thị giác của chúng tôi để replay trong khi đối với các thí nghiệm ngôn ngữ của chúng tôi, chúng tôi sử dụng 0.01% dữ liệu vì số lượng lớn tập dữ liệu có sẵn cho chúng.

--- TRANG 13 ---
Phương pháp Độ chính xác Trung bình Quên lãng
SupSup 68.07 0.00
ExSSNeT 74.77 0.00

Bảng 8: So sánh giữa EXSSNET và baseline tốt nhất SupSup trên Tập dữ liệu Imagenet.

K 1 5 10 20 50
EXSSNET 71.38 71.66 71.01 70.46 69.74

Bảng 9: Ảnh hưởng của việc thay đổi k trong khi giữ số lượng batch được sử dụng cho mô-đun KKT cố định.

Số Batch 2 5 10 50 100
EXSSNET 70.65 70.63 71.01 71.07 71.6

Bảng 10: Ảnh hưởng của việc thay đổi số lượng batch trong khi giữ k cho top-k neighbors cố định cho mô-đun KKT.

Phương pháp S-MNIST S-CIFAR100 S-TinyImageNet
SupSup 22.6 18.9 18.1
+ KKT 46.4 48.3 52.4
SSNET 22.5 17.6 18.6
+ KKT 52.7 49.9 52.4
EXSSNET 22.5 17.3 18.5
+ KKT 47.8 48.8 52.4

Bảng 11: Chúng tôi báo cáo sự chồng lấp thưa thớt trung bình cho tất cả các kết hợp phương pháp và tập dữ liệu được báo cáo trong Bảng 3.

A.4 Kết quả Bổ sung

A.4.1 Kết quả trên Tập dữ liệu Imagenet

Trong thí nghiệm này, chúng tôi lấy tập dữ liệu ImageNet (Deng và cộng sự, 2009) với 1000 lớp và chia nó thành 10 nhiệm vụ trong đó mỗi nhiệm vụ là một bài toán phân loại 100 lớp. Trong Bảng 8, chúng tôi báo cáo kết quả cho ExSSNeT và phương pháp baseline thị giác mạnh nhất, SupSup. Chúng tôi bỏ qua các phương pháp khác do hạn chế nguồn lực. Chúng tôi quan sát sự cải thiện mạnh mẽ 6.7% của EXSSNET so với SupSup, cho thấy rằng những cải thiện của các phương pháp chúng tôi tồn tại cho các tập dữ liệu quy mô lớn.

A.4.2 Phân tích Hiệu quả, Thời gian chạy, và siêu tham số của mô-đun KKT

Thứ nhất, chúng tôi muốn lưu ý rằng mô-đun KKT nhẹ và hiệu quả vì nó chỉ chạy một lần cho mỗi nhiệm vụ trước khi chúng tôi bắt đầu huấn luyện trên nó và chỉ sử dụng một số batch để ước lượng mặt nạ liên quan. Cho rằng chúng tôi thực hiện nhiều epoch trên dữ liệu của nhiệm vụ, chi phí của mô-đun KKT trở nên không đáng kể so với nó và chạy trong thời gian clock gần như tương tự như không có nó. Thời gian chạy trên tập dữ liệu splitcifar100 với 100 epoch cho ExSSNeT là 168 phút và cho ExSSNeT + KKT là 173 phút là một sự khác biệt rất nhỏ.

Thứ hai, có hai siêu tham số chính trong mô-đun KKT – (1) k để lấy phiếu bầu đa số của top-k neighbors, và (2) tổng số batch được sử dụng từ nhiệm vụ hiện tại trong quá trình học và dự đoán này. Chúng tôi trình bày kết quả bổ sung trên tập dữ liệu splitcifar100 khi thay đổi các siêu tham số này từng cái một.

Trong Bảng 9, chúng tôi sử dụng 10 batch cho KKT với kích thước batch 64, dẫn đến 640 mẫu từ nhiệm vụ hiện tại được sử dụng để ước lượng. Chúng tôi báo cáo hiệu suất của EXSSNET khi thay đổi k. Từ bảng này, chúng tôi quan sát rằng hiệu suất tăng với k và sau đó bắt đầu giảm nhưng nói chung hầu hết các giá trị của k hoạt động tốt.

Tiếp theo, trong Bảng 10, chúng tôi sử dụng k=10 cố định và thay đổi số lượng batch được sử dụng cho KKT với kích thước batch 64 và báo cáo hiệu suất của EXSSNET. Chúng tôi quan sát rằng khi số lượng batch được sử dụng để tìm mặt nạ tốt nhất tăng, độ chính xác dự đoán tăng vì có lựa chọn mặt nạ tốt hơn. Hơn nữa, chỉ cần 5-10 batch hoạt động khá tốt về độ chính xác trung bình.

Từ cả hai thí nghiệm này, chúng ta có thể quan sát rằng mô-đun KKT khá mạnh mẽ với các giá trị khác nhau của các siêu tham số này nhưng việc lựa chọn cẩn thận các siêu tham số có thể dẫn đến cải thiện nhẹ.

A.4.3 Học Tăng dần Lớp

Chúng tôi đã thực hiện các thí nghiệm Học Tăng dần Lớp trên tập dữ liệu TinyImageNet (10 nhiệm vụ, 20 lớp trong mỗi nhiệm vụ) và sử dụng thuật toán One-Shot từ SupSup (Wortsman và cộng sự, 2020) để chọn mặt nạ cho suy luận. Vui lòng tham khảo Mục 3.3 và Phương trình 4 của bài báo SupSup (Wortsman và cộng sự, 2020) để biết chi tiết. Từ Bảng 12, chúng tôi quan sát rằng EXSSNET vượt trội so với tất cả các phương pháp baseline

--- TRANG 14 ---
Phương pháp Kích thước Buffer TinyImageNet
SGD 0 7.92
oEWC 0 7.58
LwF 0 8.46
ER 200 8.49
A-GEM 200 8.07
iCARL 200 7.53
DER 200 11.87
DER++ 200 10.96
SupSup 0 10.27
ExSSNeT 0 11.21

Bảng 12: Kết quả cho thiết lập CIL.

không sử dụng Experience Replay ít nhất 2.75%. Hơn nữa, ngay cả với nhu cầu về một buffer replay, EXSSNET vượt trội so với hầu hết các phương pháp dựa trên ER và có thể so sánh với DER.

A.4.4 Số liệu Sự chồng lấp Thưa thớt

Trong Bảng 11, chúng tôi báo cáo các số liệu sự chồng lấp thưa thớt cho SupSup, SSNET, và EXSSNET có và không có mô-đun chuyển giao kiến thức KKT. Bảng này tương ứng với kết quả trong Bảng 3 bài báo chính.

A.4.5 Tiến triển Độ chính xác Trung bình

Trong Hình 6, chúng tôi vẽ Σi≤t Ati vs t, nghĩa là độ chính xác trung bình như một hàm của các lớp đã quan sát. Biểu đồ này tương ứng với kết quả SplitCIFAR100 được cung cấp trong Bảng 2 bài báo chính. Chúng ta có thể quan sát từ các kết quả này rằng hiệu suất của Supsup và ExSSNeT không suy giảm khi chúng ta học các nhiệm vụ mới dẫn đến một đường cong rất ổn định trong khi đối với các phương pháp khác hiệu suất suy giảm khi chúng ta học các nhiệm vụ mới cho thấy một mức độ quên lãng nhất định.

20 40 60 80 10030405060708090

Ngây thơ
LwF
SI
EWC
AGEM
RPC
ER
DER
DER++
SupSup
SSNeT
ExSSNeT
Số Lớp Đã thấy Độ chính xác Trung bình

Hình 6: Độ chính xác Trung bình của tất cả các nhiệm vụ đã thấy như một hàm của số lượng lớp đã học cho tập dữ liệu Split-CIFAR100.

Thuật toán 1 Quy trình huấn luyện EXSSNET.
Input: Các nhiệm vụ T, một mô hình M, độ thưa thớt mặt nạ k, exclusive=True
Output: Mô hình đã huấn luyện
▷ Khởi tạo trọng số mô hình W(0)
initialize_model_weights(M)
for all i ∈ range(|T|) do
▷ Đặt mặt nạ Mi tương ứng với nhiệm vụ ti cho tối ưu hóa.
mask_opt_params = Mi
▷ Học siêu mặt nạ Mi sử dụng edge-popup
for all em ∈ mask_epochs do
Mi = learn_supermask(model, mask_opt_params, ti)
end
▷ Trọng số mô hình tại điểm này giống như lần lặp cuối W(i−1)
if i > 1 and exclusive then
▷ Tìm mặt nạ cho tất cả các trọng số được sử dụng bởi các nhiệm vụ trước đó.
M1:i−1 = ∨i−1 j=1(Mj)
▷ Lấy mặt nạ cho các trọng số trong Mi không có trong {Mi}i−1 j=1
Mfree i = Mi ∧ ¬M1:i−1
▷ Tìm trọng số không chồng lấp để cập nhật.
W(i) free = Mfree i ⊙ W(i−1)
else if not exclusive then
W(i) free = W(i−1)
end
weight_opt_params = W(i) free
▷ Học trọng số tự do trong siêu mặt nạ Mi
for all em ∈ weight_epochs do
W(i) = update_weights(model, weight_opt_params, ti)
end
end

A.4.6 So sánh Thời gian chạy qua các phương pháp

Trong Mục này, chúng tôi cung cấp kết quả để so sánh thời gian chạy của các phương pháp khác nhau được sử dụng trong bài báo. Chúng tôi chạy mỗi phương pháp trên phiên bản được lấy mẫu của tập dữ liệu WebNLP cho thứ tự nhiệm vụ S2 như được định nghĩa trong Bảng 6. Chúng tôi báo cáo thời gian chạy của các phương pháp cho bốn epoch trên mỗi tập dữ liệu trong Bảng 13. Lưu ý rằng phương pháp dựa trên masking, SupSup, SSNET, EXSSNET mất thời gian ít hơn nhiều vì chúng không cập nhật các tham số BERT và chỉ tìm một mặt nạ trên một mô hình phân loại dựa trên CNN nhỏ hơn nhiều sử dụng biểu diễn được huấn luyện trước từ BERT. Điều này mang lại cho phương pháp của chúng tôi một lợi thế vốn có rằng chúng tôi có thể cải thiện hiệu suất nhưng với thời gian chạy thấp hơn đáng kể trong khi học một mặt nạ trên ít tham số hơn nhiều cho thiết lập ngôn ngữ tự nhiên.

A.4.7 Kết quả xác thực

Trong Bảng 14, chúng tôi cung cấp độ chính xác xác thực trung bình cho các kết quả ngôn ngữ tự nhiên chính được trình bày trong Bảng 1. Chúng tôi không cung cấp kết quả xác thực của LAMOL (Sun và cộng sự, 2019) và MBPA++ (de Masson d'Autume và cộng sự, 2019) vì chúng tôi đã sử dụng kết quả được cung cấp trong các bài báo gốc của họ. Đối với lĩnh vực thị giác, chúng tôi không sử dụng tập xác thực vì không thực hiện tinh chỉnh siêu tham số nào vì chúng tôi sử dụng thiết lập thí nghiệm và tham số mặc định

--- TRANG 15 ---
Phương pháp Thời gian chạy (tính bằng phút)
Multitask 200
Finetune 175
Replay 204
AdapterBERT + FT 170
AdapterBERT + Replay 173
MultiAdaptBERT 170
Regularization 257
IDBR 258
SupSup 117
SSNET 117
EXSSNET 117

Bảng 13: So sánh thời gian chạy của các phương pháp khác nhau được sử dụng trong các thí nghiệm văn bản.

Phương pháp (↓) GLUE WebNLP
Thứ tự (→) S1 S2 S3 S4 S5 Trung bình
Ngẫu nhiên 33.3 7.14 7.14 7.14 7.14 7.14
Multitask 80.6 77.4 77.5 76.9 76.8 77.1
FT 14.0 27.0 22.9 30.4 15.6 24.0
Replay 79.7 75.2 74.5 75.2 75.5 75.1
AdaptBERT + FT 25.1 20.8 19.1 23.6 14.6 19.5
AdaptBERT + Replay 78.6 73.3 74.3 74.7 74.6 74.2
MultiAdaptBERT 83.6 76.7 76.7 76.7 76.7 76.7
Regularization 75.5 75.9 75.0 76.5 76.3 75.9
IDBR 77.5 75.8 75.4 76.4 76.4 76.0
SupSup 78.1 75.7 76.0 76.0 75.9 75.9
SSNET 77.2 76.3 76.3 77.0 76.1 76.4
EXSSNET 80.1 77.1 77.3 77.2 77.1 77.2

Bảng 14: Độ chính xác xác thực trung bình (↑) cho nhiều nhiệm vụ và thứ tự chuỗi với các phương pháp tiên tiến (SotA) trước đó.

từ mã nguồn gốc từ (Wortsman và cộng sự, 2020; Wen và cộng sự, 2020).

A.4.8 Ảnh hưởng của Thứ tự Nhiệm vụ và Số lượng Nhiệm vụ

Theo Huang và cộng sự (2021), chúng tôi tiến hành các thí nghiệm để nghiên cứu ảnh hưởng của độ dài nhiệm vụ và thứ tự trong lĩnh vực ngôn ngữ. Chúng tôi sử dụng các chuỗi nhiệm vụ có độ dài ba và năm, với nhiều thứ tự nhiệm vụ khác nhau trên dữ liệu được lấy mẫu (Mục 4.1, Bảng 6, và Phụ lục) để đặc trưng hóa tác động của các biến này đối với hiệu suất. Trong Bảng 15, chúng tôi trình bày độ chính xác kiểm tra trung bình được tính trung bình trên ba seed ngẫu nhiên khác nhau. Chúng tôi quan sát rằng qua tất cả sáu thiết lập khác nhau, phương pháp của chúng tôi thực hiện tốt hơn so với tất cả các phương pháp baseline. Các phương pháp của chúng tôi thu hẹp khoảng cách hướng tới hiệu suất của các phương pháp multitask, để lại khoảng cách 0.36% và 1.19% cho các chuỗi độ dài ba và năm tương ứng.

A.5 Chi tiết Mô hình Bổ sung

A.5.1 Thuật toán cho EXSSNET

Trong Thuật toán 1, chúng tôi cung cấp mã giả cho phương pháp EXSSNET của chúng tôi để dễ tham khảo và hiểu. Chúng tôi cũng đính kèm mã hoạt động của chúng tôi như tài liệu bổ sung để khuyến khích tính tái tạo.

A.5.2 Sơ đồ Mô hình cho Supsup

Trong Hình 7, chúng tôi cung cấp sơ đồ mô hình chính tắc cho SupSup. Vui lòng đọc mô tả hình để biết thêm chi tiết về sự khác biệt giữa SupSup và ExSSNeT.

--- TRANG 16 ---
Mô hình (↓) WebNLP Độ dài-5 WebNLP Độ dài-3
Thứ tự (→) S2 S3 S4 Trung bình S6 S7 S8 Trung bình
Ngẫu nhiên 7.14 7.14 7.14 7.14 10.0 10.0 10.0 10.0
MTL 75.09 75.09 75.09 75.09 74.16 74.16 74.16 74.16
Finetune † 32.37 32.22 26.44 30.34 25.79 36.56 41.01 34.45
Replay † 68.25 70.52 70.24 69.67 69.32 70.25 71.31 70.29
Regularization † 72.28 73.03 72.92 72.74 71.50 70.88 72.93 71.77
AdaptBERT 30.49 20.16 23.01 24.55 24.48 31.08 26.67 27.41
AdaptBERT + Replay 69.30 67.91 71.98 69.73 66.12 69.15 71.62 68.96
IDBR† 72.63 73.72 73.23 73.19 71.80 72.72 73.08 72.53
SupSup 74.01 74.04 74.18 74.08 72.01 72.35 72.53 72.29
SSNET 74.5 74.5 74.65 74.55 73.1 72.92 73.07 73.03
EXSSNET 74.78 74.72 74.71 74.73 72.67 72.99 73.24 72.97

Bảng 15: Độ chính xác kiểm tra trung bình được báo cáo trên các chuỗi nhiệm vụ cho ba lần chạy độc lập trên dữ liệu phụ được lấy mẫu. Kết quả với † được lấy từ Huang và cộng sự (2021).

Các trọng số được khởi tạo ngẫu nhiên 
Mặt nạ trên trọng số  Mặt nạ trên trọng số  Mặt nạ trên trọng số  : Trọng số chưa huấn luyện
: Nhiệm vụ 1 : Nhiệm vụ 2
: Nhiệm vụ 3

Tìm Mặt nạ cho Nhiệm vụ 1  Tìm Mặt nạ cho Nhiệm vụ 3  Tìm Mặt nạ cho Nhiệm vụ 2  

Hình 7: Đây là sơ đồ mô hình chính tắc cho SupSup. Trong SupSup, các trọng số mô hình luôn được cố định tại khởi tạo ngẫu nhiên W(0). Đối với mỗi nhiệm vụ SupSup học một mặt nạ mới (trong trường hợp này M1, M2, M3) trên các trọng số W(0). Một mặt nạ có chọn lọc kích hoạt một tập con trọng số cho một nhiệm vụ cụ thể. Tập con các trọng số được chọn này tạo thành một mạng con bên trong mô hình đầy đủ mà chúng tôi gọi là mạng con siêu mặt nạ. Ví dụ, khi học Nhiệm vụ 2, SupSup học mặt nạ M2 (các trọng số được kích hoạt bởi mặt nạ được tô sáng màu xanh lá) trên trọng số cố định W(0). Các trọng số được tô sáng này cùng với các nút tham gia là mạng con được tạo bởi mặt nạ M2. Bất cứ khi nào một dự đoán được thực hiện cho các mẫu Nhiệm vụ 2, mặt nạ này được chọn và sử dụng để thu được các dự đoán. Vui lòng lưu ý rằng các trọng số mô hình W(0) không bao giờ được cập nhật sau khởi tạo ngẫu nhiên của chúng. Do đó, đối với SupSup không có chia sẻ kiến thức đã học qua các nhiệm vụ. Điều này trái ngược với thiết lập của chúng tôi trong Hình 1, trong đó đối với nhiệm vụ đầu tiên mặt nạ được học trên các trọng số W(0) nhưng một khi mặt nạ được chọn, các trọng số của mạng con tương ứng cũng được cập nhật để thu được trọng số mới W(1). Sau đó mặt nạ của nhiệm vụ tiếp theo được học trên tập hợp trọng số mới này W(1) và cứ thế. Cũng lưu ý rằng trong Hình 1, chúng tôi không hiển thị mô-đun chuyển giao kiến thức KKT ở đây để tránh nhầm lẫn.

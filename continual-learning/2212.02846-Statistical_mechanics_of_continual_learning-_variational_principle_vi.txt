# Cơ học thống kê của học liên tục: nguyên lý biến phân và thế năng trường trung bình

Chan Li1,∗Zhenye Huang2,∗Wenxuan Zou1,∗và Haiping Huang1†
1PMI Lab, School of Physics, Sun Yat-sen University,
Guangzhou 510275, People's Republic of China và
2CAS Key Laboratory for Theoretical Physics,
Institute of Theoretical Physics,Chinese Academy of Sciences,
Beijing 100190, People's Republic of China
(Ngày: 21 tháng 6, 2023)

Tóm tắt

Một trở ngại đối với trí tuệ nhân tạo tổng quát là việc học liên tục nhiều nhiệm vụ có bản chất khác nhau. Gần đây, nhiều thủ thuật thực nghiệm, cả từ góc độ học máy và khoa học thần kinh, đã được đề xuất, nhưng chúng thiếu nền tảng lý thuyết thống nhất. Ở đây, chúng tôi tập trung vào học liên tục trong mạng nơ-ron đơn lớp và đa lớp có trọng số nhị phân. Do đó, một thiết lập học Bayesian biến phân được đề xuất, trong đó các mạng nơ-ron được huấn luyện trong không gian trường, thay vì không gian trọng số rời rạc có gradient không xác định, và hơn nữa, sự bất định của trọng số được tích hợp một cách tự nhiên, và điều chỉnh tài nguyên synap giữa các nhiệm vụ. Từ góc độ vật lý, chúng tôi chuyển đổi học liên tục biến phân thành khung thế năng nhiệt động lực học Franz-Parisi, trong đó kiến thức nhiệm vụ trước đó đóng vai trò như một tiên nghiệm và cũng là một tham chiếu. Do đó, chúng tôi diễn giải việc học liên tục của perceptron nhị phân trong thiết lập giáo viên-học sinh như một tính toán thế năng Franz-Parisi. Hiệu suất học tập sau đó có thể được nghiên cứu phân tích với các tham số bậc trường trung bình, có dự đoán trùng khớp với các thí nghiệm số sử dụng phương pháp gradient descent ngẫu nhiên. Dựa trên nguyên lý biến phân và xấp xỉ trường Gaussian của các tiền kích hoạt bên trong trong các lớp ẩn, chúng tôi cũng suy ra thuật toán học có xem xét sự bất định trọng số, giải quyết việc học liên tục với trọng số nhị phân sử dụng mạng nơ-ron đa lớp, và hoạt động tốt hơn thuật toán metaplasticity hiện có trong đó các synap nhị phân mang các trạng thái liên tục ẩn và tính dẻo của synap được điều chỉnh bởi một hàm chính quy hóa thực nghiệm. Các khung nguyên tắc được đề xuất của chúng tôi cũng kết nối với elastic weight consolidation, học được điều chỉnh bởi sự bất định trọng số, và metaplasticity lấy cảm hứng từ khoa học thần kinh, cung cấp một phương pháp có nền tảng lý thuyết cho việc học đa nhiệm vụ trong thế giới thực với mạng sâu.

I. GIỚI THIỆU

Môi trường mà một tác nhân thông minh đối mặt thường có cấu trúc cao, và hơn nữa, nhiều nhiệm vụ mã hóa cấu trúc này xảy ra theo trình tự. Do đó, việc tác nhân học các cấu trúc liên tục phát triển được nhúng trong các nhiệm vụ tuần tự, tức là, chuyển giao kiến thức thu được từ các kinh nghiệm trước đó cho việc học một nhiệm vụ mới hoặc không quen thuộc hiện tại là quan trọng. Tuy nhiên, trong quá trình học liên tục này, người ta biết rằng kiến thức nhiệm vụ trước đó có thể bị xóa sau khi học một nhiệm vụ mới (được gọi là quên thảm khốc [1, 2]). Khám phá các cơ chế thần kinh làm nền tảng cho việc học liên tục thành công đặc biệt trong thế giới tự nhiên đặt ra một thách thức trong nghiên cứu AI hiện tại và thậm chí là khoa học thần kinh. Gần đây cũng xuất hiện các công trình thú vị về mạng nơ-ron sinh học trong vấn đề này [3–5], và nghiên cứu khoa học thần kinh cung cấp những hiểu biết để cải thiện hiệu suất học liên tục trong mạng nơ-ron nhân tạo [6–8].

Để tránh quên thảm khốc, cộng đồng học máy cũng đề xuất nhiều chiến lược thực nghiệm. Ví dụ, phương pháp elastic weight consolidation giới thiệu ma trận thông tin Fisher để đo độ quan trọng của trọng số trong việc học nhiệm vụ liên tiếp [9], được cải thiện thêm bằng cách theo dõi đóng góp của từng trọng số riêng lẻ trong toàn bộ động lực học của tổn thất huấn luyện [10]. Một mặt nạ chú ý cũng có thể được học để giảm bớt việc quên thảm khốc [11]. Một hướng quan trọng khác là sử dụng phương pháp Bayesian [12]. Hướng này cho thấy rằng sự bất định synap đóng vai trò quan trọng trong việc cân bằng học tập giữa hai nhiệm vụ liên tiếp [13–16]. Chúng tôi lưu ý rằng những chiến lược thực nghiệm này có các nguyên tắc thiết kế đa dạng, nhưng từ góc độ vật lý thống kê, chúng có thể được đưa vào một khung thống nhất của lý thuyết trường trung bình biến phân. Mặc dù các công trình lý thuyết gần đây tập trung vào chuyển pha trong việc học chuyển giao từ nhiệm vụ nguồn sang nhiệm vụ đích [17] và động lực học học trực tuyến của thiết lập giáo viên-học sinh [18–20], những công trình này không tính đến sự bất định trọng số, đây là một yếu tố thiết yếu trong việc học mạng nơ-ron [21], bao gồm các mạng trọng số nhị phân hiệu quả và mạnh mẽ hơn. Ngoài ra, một nghiên cứu gần đây chỉ ra rằng khái niệm meta-plasticity từ khoa học não bộ đóng vai trò chủ chốt trong việc học liên tục của mạng nơ-ron trọng số nhị phân [8]. Khái niệm này nhấn mạnh rằng synap nhị phân mang một trạng thái liên tục ẩn, và tính dẻo synap được điều chỉnh bởi một hàm chính quy hóa thực nghiệm. Khung lý thuyết của chúng tôi chứng minh rằng một nguyên lý biến phân có thể được xây dựng để giải thích vai trò của sự bất định synap, và hơn nữa, việc chuyển giao kiến thức giữa các nhiệm vụ thực sự có thể được nắm bắt bởi một thế năng nhiệt động lực học [22], từ đó hiệu suất học tập có thể được dự đoán.

Trong công trình này, chúng tôi không chỉ thực hiện phân tích lý thuyết toàn diện về thiết lập học giáo viên-học sinh đồ chơi, trong đó cả hai nhiệm vụ có mức độ tương tự nhất định được học theo trình tự, mà còn áp dụng cùng nguyên tắc cho việc học liên tục sâu của các tập dữ liệu có cấu trúc, điều này chứng minh hiệu quả của nguyên lý trường trung bình biến phân, đặc biệt trong mạng nơ-ron trọng số nhị phân nơi trước đây chỉ có meta-plasticity được đề xuất. Nhìn chung, lý thuyết của chúng tôi kết nối vật lý thống kê, đặc biệt là khái niệm thế năng Franz-Parisi, ban đầu được nghiên cứu trong các mô hình thủy tinh spin trường trung bình [23], với nền tảng lý thuyết của việc học liên tục đầy thách thức. Kết nối này có thể chứng minh có ích trong các nghiên cứu tương lai.

II. HỌC LIÊN TỤC VỚI PERCEPTRON NHỊ PHÂN

Perceptron nhị phân cung cấp một ứng cử viên lý tưởng để hiểu việc học không lồi, vì phân tích lý thuyết có thể thực hiện được bằng cách sử dụng các phương pháp vật lý thống kê [24]. Ở đây, chúng tôi sẽ sử dụng thiết lập giáo viên-học sinh để thực hiện phân tích lý thuyết về học liên tục biến phân, trong đó mạng sự thật nền được làm nguội trước khi học. Trong phần phân tích mô hình đồ chơi này, chúng tôi sử dụng ξ và W để chỉ trọng số của học sinh và giáo viên, tương ứng. Trong phần tiếp theo về huấn luyện mạng sâu (không có sự thật nền trong trường hợp này), chúng tôi sử dụng w để chỉ các trọng số cần học.

A. Thiết lập học

Perceptron tiêu chuẩn là một mạng đơn lớp với N nút đầu vào nhị phân, xi = ±1 (i = 1,2, ..., N), và một nút đầu ra nhị phân duy nhất, y = ±1, được kết nối bởi N trọng số nhị phân ξi = ±1 (i = 1,2, ..., N). Cho một đầu vào x, đầu ra được chỉ định bởi y = sign(1/√N ∑ixi ξi), trong đó sign(x) là hàm dấu. Một perceptron có thể được sử dụng để phân loại đầu vào theo các nhãn tương ứng của chúng (±1 ở đây). Phân tích cơ học thống kê tiết lộ rằng mạng có thể lưu trữ đến một ngưỡng tới hạn của mật độ mẫu (hoặc độ phức tạp mẫu) α ≃ 0.83 [25], trong đó α = M/N là mật độ mẫu ngẫu nhiên (như đầu vào), và M là số lượng mẫu ngẫu nhiên. Thay vì thiết lập lưu trữ mẫu ngẫu nhiên cổ điển này, chúng tôi xem xét nhiệm vụ học các mẫu ngẫu nhiên với các nhãn tương ứng được tạo bởi mạng giáo viên (tương ứng với các nhiệm vụ khác nhau). Điều này được gọi là thiết lập giáo viên-học sinh [26, 27], trong đó mạng học sinh học để suy ra quy tắc của giáo viên được nhúng trong dữ liệu được cung cấp.

Với số lượng ví dụ học tập được cung cấp ngày càng tăng, kích thước của không gian giải pháp ứng viên của trọng số thu hẹp lại, và do đó lỗi tổng quát hóa trên các ví dụ dữ liệu mới giảm. Phân tích cơ học thống kê cũng dự đoán rằng tại α ≃ 1.245, một chuyển pha bậc nhất đến tổng quát hóa hoàn hảo xảy ra [26, 27], đây là việc học nhiệm vụ đơn. Trong thiết lập học liên tục của chúng tôi, chúng tôi thiết kế hai mạng giáo viên với trọng số nhị phân W₁ ∈ {±1}ᴺ và W₂ ∈ {±1}ᴺ, tương ứng. Cả hai mạng giáo viên đều là sự thật nền cho các nhiệm vụ tương ứng. Theo định nghĩa, cả hai giáo viên chia sẻ một mức độ tương quan có thể điều chỉnh trong trọng số của họ, đại diện cho sự tương tự giữa các nhiệm vụ. Trong thực tế, trọng số của họ tuân theo phân phối chung như

P(W₁,W₂) = ∏ᵢ₌₁ᴺ P₀(W₁ᵢ, W₂ᵢ) = ∏ᵢ₌₁ᴺ [(1+r₀)/4 δ(W₁ᵢ-W₂ᵢ) + (1-r₀)/4 δ(W₁ᵢ+W₂ᵢ)], (1)

trong đó r₀ ∈ [-1,1] biểu thị sự tương tự nhiệm vụ. r₀ cũng biểu thị sự chồng chéo của hai mạng giáo viên, vì r₀ = 1/N ∑ᵢ₌₁ᴺ W₁ᵢW₂ᵢ. Xác suất chung biên P₀(W₁ᵢ, W₂ᵢ) có thể được viết lại như P₀(W₁ᵢ, W₂ᵢ) = p(W₁ᵢ)p(W₂ᵢ|W₁ᵢ), trong đó p(W₁ᵢ) = 1/2δ(W₁ᵢ-1) + 1/2δ(W₁ᵢ+1), và p(W₂ᵢ|W₁ᵢ) = (1+r₀)/2δ(W₁ᵢ-W₂ᵢ) + (1-r₀)/2δ(W₁ᵢ+W₂ᵢ). Để tạo trọng số của hai mạng giáo viên, chúng ta có thể đầu tiên tạo một tập hợp trọng số nhị phân ngẫu nhiên từ phân phối Rademacher, và sau đó lật trọng số với xác suất (1-r₀)/2. Các mẫu ngẫu nhiên cho hai nhiệm vụ được lấy mẫu độc lập từ phân phối Rademacher, và sau đó chúng ta có tập dữ liệu huấn luyện {xᵗ'ᵘ}ᴹᵗᵤ₌₁, trong đó chỉ số nhiệm vụ t = 1,2. Cho các mẫu được lấy, mạng giáo viên tạo các nhãn tương ứng cho mỗi nhiệm vụ, {yᵗ'ᵘ}ᴹᵗᵤ₌₁. Sau đây, chúng tôi sử dụng Dₜ = {xᵗ'ᵘ, yᵗ'ᵘ}ᴹᵗᵤ₌₁, để biểu thị hai tập dữ liệu tương ứng với hai nhiệm vụ liên tiếp.

Trong thiết lập trên, mạng học sinh chia sẻ cùng cấu trúc (cấu trúc liên kết) với hai mạng giáo viên, điều này ngụ ý rằng học sinh không thể đồng thời học cả hai nhiệm vụ một cách hoàn hảo, tùy thuộc vào sự tương tự nhiệm vụ. Tuy nhiên, thiết lập này cho phép chúng ta khám phá cách học sinh điều chỉnh trọng số của mình để tránh quên thảm khốc trong quá trình học một nhiệm vụ mới, và cách mạng cân bằng giữa kiến thức mới và cũ trong học liên tục. Nghiên cứu hệ thống đơn giản này cũng có thể cung cấp cho chúng ta những hiểu biết về học liên tục trong các ứng dụng phức tạp hơn, chẳng hạn như học sâu trong dữ liệu thế giới thực.

B. Nguyên lý học biến phân

Thay vì huấn luyện trọng số điểm, chúng tôi xem xét việc học phân phối của trọng số theo nghĩa là chúng tôi huấn luyện mạng học sinh để tìm một phân phối trọng số tối ưu [28]. Theo hướng này, phương pháp biến phân là một khung lý tưởng cho việc học mạng nơ-ron [29, 30], vì chúng ta có thể sử dụng phân phối thử đơn giản để xấp xỉ phân phối trọng số ban đầu không thể xử lý được. Việc học sau đó trở thành tìm một phân phối thử tối ưu được tham số hóa bởi các tham số biến phân [24].

Trong nhiệm vụ đầu tiên, chúng tôi giới thiệu một phân phối biến phân cho trọng số synap, qθ(ξ) = ∏i eᵝᶿⁱᵉⁱ/cosh(βθᵢ), trong đó θ là các tham số biến phân, và β là một siêu tham số. Phân phối tối ưu có thể được xấp xỉ bằng cách tối đa hóa log-likelihood kỳ vọng

θ* = arg max_θ Eqθ ln P(D₁|ξ). (2)

Cho một đầu vào x, chúng tôi chọn xác suất P(D₁|ξ) = P(y|x,ξ) là P(y|x,ξ) = Θ(y∑ᵢ₌₁ᴺ ξᵢxᵢ), trong đó Θ(x) là hàm Heaviside sao cho Θ(x) = 1, nếu x > 0 và Θ(x) = 0 ngược lại. Trong thực tế, dựa trên bất đẳng thức Jensen, chúng tôi thực sự cập nhật các tham số biến phân bằng cách tối đa hóa cận trên ln Eqθ P(D₁|ξ), điều này ít thách thức tính toán hơn so với cận ban đầu, và bài toán tối ưu hóa sau đó có thể được công thức hóa như

θ* = arg min_θ {-ln Eqθ P(D₁|ξ)}
   = arg min_θ (-ln Eqθ ∏μ Θ(yμ ∑ᵢ₌₁ᴺ ξᵢxμᵢ)). (3)

Tối đa hóa cận trên đã được chứng minh là hiệu quả trong học không giám sát với nhiều nơ-ron ẩn [30]. Khi số lượng trọng số khoảng 10, log-likelihood kỳ vọng có thể được tính toán chính xác, và chúng tôi đã kiểm tra rằng cận có thể chặt (xem Hình 1). Dựa trên giả định N lớn và định lý giới hạn trung tâm, Phương trình (3) có thể được viết lại thành dạng sau [29]

θ* = arg min_θ {-∑μ ln H(-yμ ∑ᵢ xμᵢ tanh βθᵢ / √(∑ᵢ(1-tanh² βθᵢ)))}, (4)

trong đó H(x) = ∫₋∞ˣ dz e⁻ᶻ²/²/√2π = ∫₋∞ˣ Dz, với Dz biểu thị một đo lường Gaussian tiêu chuẩn. Đặt hàm tổn thất là L = -∑μ ln H(-yμ ∑ᵢ xμᵢ tanh βθᵢ / √(∑ᵢ(1-tanh² βθᵢ))), chúng ta có thể sử dụng phương pháp dựa trên gradient descent ngẫu nhiên (SGD) để tìm một phân phối thử tốt của trọng số, có thể là một cực tiểu địa phương hoặc toàn cục vì hàm tổn thất là một hàm không lồi. Các gradient có thể được suy ra dưới đây,

∂L/∂θᵗⱼ = β(σᵗⱼ)² [yxⱼ/∑ᵢ(σᵗᵢ)² + tanh(βθᵗⱼ)∑ᵢxᵢtanh(βθᵗᵢ)/(∑ᵢ(σᵗᵢ)²)³/²] × H'(-y∑ᵢxᵢtanh(βθᵗᵢ)/√(∑ᵢ(1-tanh²(βθᵗᵢ)))) × H⁻¹(-y∑ᵢxᵢtanh(βθᵗᵢ)/√(∑ᵢ(1-tanh²(βθᵗᵢ)))) (5)

trong đó σ²ⱼ = 1-tanh²(βθⱼ) nắm bắt sự bất định trọng số, chỉ số dữ liệu μ bị bỏ qua, và t biểu thị bước thời gian lặp. Do đó, tính dẻo synap được điều chỉnh bởi sự bất định trọng số, điều này hợp lý về mặt sinh học [31] và mang tính tương tự với các chiến lược thực nghiệm khác [8, 15]. Một đặc điểm nổi bật khác là, với điều kiện sự bất định của một trọng số nhỏ, trọng số này có thể ít dẻo hơn vì mã hóa thông tin quan trọng của các nhiệm vụ trước đó. Ngoài ra, tính dẻo synap của trọng số cũng được điều chỉnh bởi tổng sự bất định của mạng, ∑ᵢ(σᵗᵢ)², đóng vai trò chính quy hóa toàn cục.

Trong quá trình học nhiệm vụ thứ hai, phân phối hậu nghiệm của trọng số trở thành

P(ξ|D₁,D₂) = P(D₂|ξ,D₁)P(ξ|D₁)/P(D₂|D₁). (6)

Chúng tôi giả định rằng khi học sinh học nhiệm vụ thứ hai, kiến thức từ nhiệm vụ đầu tiên trở thành một tiên nghiệm ràng buộc việc học tiếp theo, tức là, P(ξ|D₁) ≃ qθ₁(ξ), trong đó qθ₁(ξ) là phân phối biến phân sau khi học nhiệm vụ đầu tiên. Chúng tôi mô hình hóa hậu nghiệm của trọng số trong quá trình học nhiệm vụ thứ hai như qθ₂(ξ) = ∏ᵢ eᵝᶿ²ⁱᵉⁱ/cosh(βθ²ᵢ). Các tham số biến phân tối ưu có thể được thu được bằng cách tối thiểu hóa phân kỳ Kullback-Leibler (KL) giữa phân phối biến phân và phân phối hậu nghiệm [30],

θ₂* = arg min_θ₂ Eqθ₂ ln qθ₂(ξ)/P(ξ|D₁,D₂)
    = arg min_θ₂ Eqθ₂ ln qθ₂(ξ)/qθ₁(ξ) - Eqθ₂ ln P(D₂|ξ)
    ≃ arg min_θ₂ KL[qθ₂(ξ)||qθ₁(ξ)] - ln Eqθ₂ P(D₂|ξ), (7)

trong đó chúng tôi loại bỏ P(D₂|D₁) vì hạng này không phụ thuộc vào các tham số mô hình, và chúng tôi sử dụng P(D₂|ξ,D₁) = P(D₂|ξ), và chúng tôi cũng xấp xỉ hàm mục tiêu L bằng cách tối thiểu hóa cận dưới của phân kỳ KL (nói cách khác, chúng tôi huấn luyện mạng để làm cho cận càng chặt càng tốt). Chúng tôi lưu ý ở đây rằng người ta cũng có thể tối thiểu hóa phân kỳ KL giữa xác suất thử qθ và hậu nghiệm P(ξ|D₁) cho việc học nhiệm vụ đầu tiên [xem Phương trình (2)], điều này sẽ yêu cầu một xác suất tiên nghiệm của ξ. Ngay cả khi chúng ta đặt tiên nghiệm này thành một tiên nghiệm đồng nhất, hệ thống thể hiện hành vi học tương tự nhưng việc học trở nên khó hơn vì cần nhiều mẫu dữ liệu hơn để đạt được cùng lỗi tổng quát hóa thấp với việc học sử dụng Phương trình (2). Do đó, chúng tôi sử dụng Phương trình (2) làm khung học nhiệm vụ đầu tiên của chúng tôi.

Hạng đầu tiên trong Phương trình (7) là một hạng chính quy hóa khiến mạng duy trì thông tin đã học của nhiệm vụ đầu tiên. Hạng thứ hai là hạng log-likelihood kỳ vọng dẫn mạng giải thích dữ liệu mới. Phương pháp dựa trên SGD sau đó có thể được áp dụng để thu được giải pháp tối ưu (cực tiểu địa phương hoặc toàn cục). Gradient có thể được tính như,

∂L/∂θ₂,ₜⱼ = β(σ₂,ₜⱼ)² [β(θ₂,ₜⱼ-θ₁ⱼ) + yxⱼ/∑ᵢ(σ₂,ₜᵢ)² + tanh(βθ₂,ₜⱼ)∑ᵢxᵢtanh(βθ₂,ₜᵢ)/(∑ᵢ(σ₂,ₜⱼ)²)³/²] × H'(-y∑ᵢxᵢtanh(βθ₂,ₜᵢ)/√(∑ᵢ(1-tanh²(βθ₂,ₜᵢ)))) × H⁻¹(-y∑ᵢxᵢtanh(βθ₂,ₜᵢ)/√(∑ᵢ(1-tanh²(βθ₂,ₜᵢ)))), (8)

trong đó L là hàm mục tiêu cần tối thiểu hóa trong Phương trình (7), và chỉ số dữ liệu bị bỏ qua và phải tham chiếu đến nhiệm vụ 2, và gradient vẫn được điều chỉnh bởi sự bất định trọng số. So với gradient của việc học nhiệm vụ đầu tiên, hạng bổ sung đến từ hạng phân kỳ KL. Hạng này khuyến khích mạng nhớ thông tin nhiệm vụ đầu tiên. Do đó, quy tắc tính dẻo synap này thể hiện sự cạnh tranh giữa nhiệm vụ cũ và mới (hạng thứ hai). Sự cân bằng này cho phép mạng duy trì kiến thức cũ nhưng vẫn thích nghi với nhiệm vụ mới, do đó tránh quên thảm khốc ở một mức độ nào đó.

Chúng tôi đầu tiên cho thấy hiệu suất mô phỏng của thiết lập học liên tục biến phân đồ chơi của chúng tôi. Trong Hình 2(a), với số lượng ví dụ được cung cấp ngày càng tăng, hiệu suất học nhiệm vụ đơn được cải thiện. Trong Hình 2(b), khi chuyển nhiệm vụ xảy ra, lỗi kiểm tra của nhiệm vụ đầu tiên tăng, nhưng cuối cùng đạt được một giá trị ổn định trong quá trình huấn luyện. Lỗi kiểm tra của nhiệm vụ thứ hai giảm, nhưng không thể đạt được mức lỗi có thể đạt được khi nhiệm vụ được huấn luyện riêng lẻ [Hình 2(c)]. Điều này là do mạng không quên hoàn toàn các đặc điểm riêng biệt của nhiệm vụ đầu tiên, do hạng chính quy hóa. Lỗi kiểm tra thấp hơn sẽ được đạt được với nhiều ví dụ huấn luyện hơn cho nhiệm vụ thứ hai. Hình 2(d) minh họa hiệu ứng của hạng KL, trong đó chúng tôi vẽ sự chồng chéo giữa suy luận học sinh và phần chung của cả hai giáo viên. Không có hạng KL, sự chồng chéo giảm mạnh hơn và sau đó tăng nhanh hơn, trong khi sự hiện diện của hạng KL làm cho sự chồng chéo thay đổi tương đối chậm. Điều này gợi ý rằng, hạng KL làm cho mạng có xu hướng bảo vệ nhiệm vụ đầu tiên khỏi việc quên nhanh (xem hiệu suất kém của SGD truyền thống trong học liên tục trong Hình 2(b,c)]. Sự chồng chéo thấp hơn (nhưng vẫn gần hơn với một) cho phép linh hoạt hơn để cân bằng việc học liên tục.

Tiếp theo, chúng tôi suy ra lý thuyết trường trung bình để đánh giá phân tích hiệu suất học liên tục.

C. Lý thuyết trường trung bình: Thế năng Franz-Parisi

Lý thuyết trường trung bình là một công cụ mạnh mẽ để phân tích các hệ thống phức tạp trong vật lý thống kê. Trong phần trước, chúng tôi mô tả phương pháp biến phân trong việc huấn luyện perceptron nhị phân để thực hiện học liên tục. Trong phần này, chúng tôi suy ra lý thuyết trường trung bình để phân tích học liên tục biến phân. Thay vì các trường địa phương θ₁ và θ₂ (hữu ích cho việc huấn luyện thực tế do các giá trị không bị chặn của chúng), chúng tôi tham số hóa phân phối biến phân với từ hóa trọng số m₁,ᵢ = tanh βθ₁ᵢ và m₂,ᵢ = tanh βθ₂ᵢ, để phục vụ các nghiên cứu phân tích. Các phân phối biến phân được chỉ định tương ứng bởi

Qₘ₁(ξ) = ∏ᵢ₌₁ᴺ (1 + ξᵢm₁,ᵢ)/2,
Qₘ₂(ξ) = ∏ᵢ₌₁ᴺ (1 + ξᵢm₂,ᵢ)/2, (9)

trong đó m₁,ᵢ, m₂,ᵢ ∈ [-1,1] là từ hóa của trọng số synap thứ i trong việc học nhiệm vụ đầu tiên và thứ hai tương ứng. Chúng tôi thực hiện phân tích cơ học thống kê về việc học hai nhiệm vụ, với mục tiêu trích xuất vai trò của các tham số mô hình (ví dụ: độ phức tạp mẫu, sự tương tự nhiệm vụ và tương tự) trong học liên tục.

1. Phân tích nhiệm vụ đầu tiên

Để thực hiện phân tích lý thuyết trường trung bình của việc học nhiệm vụ đầu tiên, chúng tôi định nghĩa hàm tổn thất trong phương pháp biến phân là Hamiltonian,

L₁(m) = -∑ᵤ₌₁ᴹ¹ ln H(-yᵤ ∑ᵢmᵢx₁,ᵤᵢ / √(∑ᵢ(1-mᵢ²))), (10)

trong đó yᵤ = sign(∑ᵢW₁ᵢx₁,ᵤᵢ) là nhãn được tạo bởi mạng giáo viên. Phân phối Boltzmann đọc

P(m) = 1/Z e⁻ᵝᴸ¹⁽ᵐ⁾, (11)

trong đó β là nhiệt độ nghịch đảo, Z = ∫_Ω ∏ᵢdmᵢe⁻ᵝᴸ¹⁽ᵐ⁾ là hàm phân vùng và miền tích phân Ω = [-1,1]ᴺ. Để thu được các tính chất cân bằng, chúng ta trước tiên phải tính toán năng lượng tự do trung bình rối loạn (hoặc log-hàm-phân-vùng), có thể đạt được bằng cách sử dụng thủ thuật replica. Thủ thuật replica tiến hành như ⟨ln Z⟩ = lim_{n→0} ln⟨Zⁿ⟩/n, trong đó ⟨·⟩ biểu thị trung bình qua rối loạn quenched. Sau đó, chúng ta có

⟨Zⁿ⟩ = ∫_{Ωⁿ} ∏ₐ₌₁ⁿ ∏ᵢ₌₁ᴺ dmₐᵢ ⟨∏ₐ₌₁ⁿ ∏ᵤ₌₁ᴹ¹ Hᵝ(-sign(∑ᵢW₁ᵢx₁,ᵤᵢ) ∑ᵢmₐᵢx₁,ᵤᵢ / √(∑ᵢ(1-(mₐᵢ)²)))⟩. (12)

Dưới Ansatz đối xứng replica (RS) (chi tiết trong phụ lục C), mật độ năng lượng tự do tại mật độ dữ liệu cho trước α = M/N được cho bởi

-βfᴿˢ = lim_{n→0,N→∞} ln⟨Zⁿ⟩/(nN) = lim_{n→0} -1/2(q̂ₐqₐ + (n-1)q̂₀q₀) - r̂₁r₁ + ln Gˢ/n + α₁ ln Gᴱ/n, (13)

trong đó

Gᴱ = ∫ Dz₂H(-r₁/√(q₀-r₁²)z) ∫ DσHᵝ(-√(qₐ-q₀)σ + √q₀z / √(1-qₐ))ⁿ,
Gˢ = ∫ Dz ∫₋₁⁺¹ dm e^(1/2q̂ₐm² - 1/2q̂₀m² + √q̂₀mz + r̂₁m)ⁿ. (14)

Các tham số bậc được giới thiệu là q₀ = 1/N ∑ᵢmₐᵢmᵦᵢ cho a ≠ b chỉ ra sự chồng chéo của các trạng thái cân bằng khác nhau, qₐ = 1/N ∑ᵢmₐᵢmₐᵢ chỉ ra sự tự chồng chéo của các trạng thái (sự tự chồng chéo liên quan đến kích thước của không gian trọng số hợp lệ σ̂ = 1-qₐ), và cuối cùng r₁ = 1/N ∑ᵢmᵢW₁ᵢ chỉ ra sự chồng chéo giữa suy luận của học sinh và sự thật nền của giáo viên. Trong thực tế, qₐ cũng có thể được ước lượng từ động lực học gradient descent trong quá trình huấn luyện, và chúng tôi sử dụng q* để biểu thị đo lường này, tức là, q*(t) = 1/N ∑ᵢ(mᵢ(t))², và Δmᵢ(t) ∝ ∂_{mᵢ}L₁(m). {q̂₀, q̂ₐ, r̂₁} là các tham số bậc liên hợp được giới thiệu bởi biến đổi Fourier. Những tham số bậc này có thể được thu được bằng cách giải các phương trình điểm yên ngựa (chi tiết trong phụ lục C).

Để đánh giá hiệu suất học tập, chúng tôi định nghĩa lỗi tổng quát hóa ε₁ᵍ = ⟨E_{x*}Θ(-y*ŷ*)⟩, trong đó (x*, y*) là mẫu dữ liệu mới, và ŷ* là dự đoán của học sinh, và ⟨·⟩ biểu thị trung bình rối loạn. Lỗi kiểm tra có thể được tính là (xem chi tiết trong phụ lục C)

ε₁ᵍ = ∫ Dz₂H(-p₁/√(1-p₁²)z)Θ(-z) = 1/π arccos(p₁), (15)

trong đó p₁ = 1/N ∑ᵢsign(mᵢ)W₁ᵢ biểu thị sự chồng chéo giữa trọng số đã giải mã và trọng số của giáo viên, và có thể được thu được bằng cách giải các phương trình điểm yên ngựa.

Chúng tôi đầu tiên cho thấy cách các tham số bậc thay đổi đối với mật độ dữ liệu α. Như đã định nghĩa, qₐ báo hiệu kích thước của không gian trọng số hợp lệ. Khi độ phức tạp mẫu tăng, không gian trọng số thu hẹp xuống thành một điểm duy nhất đại diện cho sự thật nền [Hình 3(a)]. Như được hiển thị trong Hình 3(b), kết quả động lực học gradient descent ngẫu nhiên gần như nhất quán với các dự đoán lý thuyết (ít nhất là định tính). Sự sai lệch có thể được gây ra bởi thực tế là SGD có thể bị mắc kẹt bởi các cực tiểu địa phương (giải pháp không tối ưu) của cảnh quan năng lượng biến phân. Nhưng đối với một α cố định, chúng ta có thể điều chỉnh động chuẩn của m sau mỗi cập nhật (SGD loại chậm [29]), và so sánh ε₁ᵍ động với đối tác cân bằng của nó (với cùng giá trị q*). Chúng tôi thấy rằng kết quả SGD có thể so sánh với các dự đoán cân bằng, ít nhất là định tính [Hình 3(d)]. Sự sai lệch có thể được gây ra bởi các hiệu ứng kích thước hữu hạn (xem cũng công trình trước đây [29]).

Đặc biệt, Hình 3(b) tiết lộ một chuyển pha liên tục (từ tổng quát hóa kém đến hoàn hảo) trong không gian tham số biến phân (mặc dù việc học perceptron nhị phân được xem xét trong thiết lập của chúng tôi). Do độ chính xác số của kết quả replica tại α lớn, chúng tôi thấy rằng sau α = 1.7, một quy luật lũy thừa của lỗi tổng quát hóa với số mũ lớn [~13.1, xem hình nhỏ của Hình 3(b)] được quan sát. Chúng tôi lưu ý rằng SGD có thể đạt lỗi bằng không (tổng quát hóa hoàn hảo) sau αc ≃ 1.7, trong khi kết quả replica thu được tại β = 20 lớn có sự suy giảm nhanh (thấp hơn 10⁻²) sau αc [xem hình nhỏ của Hình 3(b)]. Dự kiến rằng dự đoán replica của lỗi tổng quát hóa sẽ đạt giá trị thấp hơn với β tăng, điều này đòi hỏi một số lượng lớn mẫu Monte-Carlo để có được ước lượng chính xác của tích phân trong Phương trình (15) và cũng trong việc giải các phương trình điểm-yên (xem chi tiết trong phụ lục C). Do đó, việc fit quy luật lũy thừa cho lỗi dưới 10⁻³ có thể không đáng tin cậy. Chúng tôi kết luận rằng trong giới hạn nhiệt độ bằng không, tổng quát hóa hoàn hảo được phỏng đoán là có thể đạt được, mặc dù β cao có thể dẫn đến phá vỡ đối xứng replica [29]. Chúng ta có thể ước lượng ngưỡng chuyển tiếp bằng cách phân tích thời gian hội tụ của thuật toán học [Hình 3(c)]. Thời gian hội tụ đạt đỉnh tại αc ≃ 1.7, điều này hoàn toàn trái ngược với trường hợp huấn luyện trong không gian trọng số nhị phân trực tiếp [26, 27], dẫn đến chuyển tiếp không liên tục tại αc = 1.245 (một điểm spinodal nằm tại αsp = 1.492). Điều này gợi ý rằng việc học biến phân xóa bỏ chế độ metastable nơi tổng quát hóa kém tồn tại cho đến điểm spinodal. Do đó, khung biến phân mang lại lợi ích tối ưu hóa cho việc học trong mạng nơ-ron với trọng số rời rạc.

2. Phân tích nhiệm vụ thứ hai

Tương tự, chúng tôi chỉ định Hamiltonian nhiệm vụ thứ hai như sau,

L₂(m) = -∑ᵤ₌₁ᴹ² ln H(-sign(∑ᵢW₂ᵢx₂,ᵤᵢ) ∑ᵢmᵢx₂,ᵤᵢ / √(∑ᵢ(1-mᵢ²))) + ∑ᵢ₌₁ᴺ KL(Qₘᵢ∥Qₘ₁,ᵢ). (16)

Như đã giải thích trước đây, hạng đầu tiên là một hạng tái tạo tối đa hóa log-likelihood của dữ liệu nhiệm vụ thứ hai, và hạng thứ hai ngăn mạng quên kiến thức đã có được trước đó. Do hạng chính quy hóa, chúng ta phải xử lý phân tích cân bằng khác với việc học nhiệm vụ đơn. Tự nhiên là đưa phân tích vào khung thế năng Franz-Parisi [22, 23]. Chính xác hơn, chúng tôi định nghĩa thế năng cho việc học nhiệm vụ thứ hai là

Φ = 1/Z̃ ∫_{Ω̃} ∏ᵢ₌₁ᴺ dm̃ᵢe^{-β̃L₁(m̃)} ln ∫_Ω ∏ᵢ₌₁ᴺ dmᵢe^{-βL₂(m,m̃)}. (17)

Lấy Ansatz đối xứng replica (RS), thế năng trung bình rối loạn liên quan đến tác động S sau (xem chi tiết trong phụ lục C),

S = lim_{n→0} lim_{s→0} -1/2[nq̂_dq̃_d + s(s-1)q̂₀q₀] - 1/2(sq̂_dq_d + n(n-1)q̂₀q₀) - nr̂₁r̃₁ - sr̂₂r₂ + ln Gˢ + α₁ ln G₁ᴱ + α₂ ln G₂ᴱ, (18)

trong đó

G₁ᴱ = ⟨∏ₐ₌₁ⁿ H^{β̃}(-sign(ṽ₁)ũₐ/√(1-q̃ₐₐ))⟩ = ∫ Dz₂H(-r̃₁/√(q̃₀-r̃₁²)z) ∫ DσH^{β̃}(-√(q̃_d-q̃₀)σ + √q̃₀z/√(1-q̃_d))ⁿ, (19)

và

G₂ᴱ = ⟨∏ᶜ₌₁ˢ Hᵝ(-sign(v₂)uᶜ/√(1-qᶜᶜ))⟩ = ∫ Dz₂H(-r₂/√(q₀-r₂²)z) ∫ DσHᵝ(-√(q_d-q₀)σ + √q₀z/√(1-q_d))ˢ, (20)

và

Gˢ = (1+r₀)/2 ∫ Dz₁ ∫₋₁⁺¹ dm̃ e^{Ĩ(m̃,z₁)ⁿ⁻¹} ∫₋₁⁺¹ dm̃ e^{Ĩ(m̃,z₁)} ∫ Dz₂ ∫₋₁⁺¹ dm e^{J₊(m,m̃,z₂)ˢ} + (1-r₀)/2 ∫ Dz₁ ∫₋₁⁺¹ dm̃ e^{Ĩ(m̃,z₁)ⁿ⁻¹} ∫₋₁⁺¹ dm̃ e^{Ĩ(m̃,z₁)} ∫ Dz₂ ∫₋₁⁺¹ dm e^{J₋(m,m̃,z₂)ˢ}. (21)

Lưu ý rằng, ṽ₁ và v₂ liên quan đến rối loạn quenched (xem phụ lục C), {q₀, r₂, q_d} là các tham số bậc song song với việc học nhiệm vụ đầu tiên, trong khi {q̃₀, r̃₁, q̃_d} có thể được thu được bằng cách giải các phương trình điểm yên ngựa của nhiệm vụ đơn (kế thừa từ phân tích nhiệm vụ đầu tiên). Các hàm Ĩ và J± được định nghĩa trong phụ lục C. Lỗi kiểm tra của nhiệm vụ thứ hai có thể được suy ra dưới dạng,

ε₂ᵍ = ∫ Dz₂H(-p₂/√(1-p₂²)z)Θ(-z) = 1/π arccos(p₂), (22)

trong đó p₂ = 1/N ∑ᵢsign(m)W₂ᵢ biểu thị sự chồng chéo giữa trọng số đã giải mã và trọng số giáo viên thứ hai. Tương tự, lỗi kiểm tra của nhiệm vụ đầu tiên sau khi học cả hai nhiệm vụ được cho bởi

ε₁ᵍ = ∫ Dz₂H(-p₁/√(1-p₁²)z)Θ(-z) = 1/π arccos(p₁), (23)

trong đó p₁ = 1/N ∑ᵢsign(mᵢ)W₁ᵢ.

Cuối cùng, chúng tôi nghiên cứu các hiệu suất được dự đoán lý thuyết so với mô phỏng số. Trong Hình 4(a), chúng tôi thấy rằng sự tương tự nhiệm vụ ảnh hưởng mạnh mẽ đến hiệu suất học của nhiệm vụ thứ hai. Khi r₀ nhận giá trị âm, việc học trở nên khó khăn hơn nhiều, vì cần nhiều ví dụ dữ liệu hơn để giảm lỗi tổng quát hóa, trong khi sự tương tự nhiệm vụ dương làm cho việc học nhiệm vụ thứ hai dễ dàng hơn. Kết quả SGD khớp tốt với dự đoán lý thuyết, ngoại trừ vùng xung quanh chuyển tiếp, có thể đòi hỏi thời gian mô phỏng dài hơn trong việc tìm kiếm giải pháp tốt. Như mong đợi, tổng quát hóa của nhiệm vụ đầu tiên sẽ tăng trong quá trình học nhiệm vụ thứ hai [Hình 4(b)], điều này là do thực tế là cả hai nhiệm vụ chia sẻ một sự tương tự một phần (tức là, không hoàn toàn giống nhau). Chúng tôi cũng nhân hạng KL với một hệ số γ, và nghiên cứu hiệu ứng của hạng này bằng cách điều chỉnh hệ số này [ví dụ: γ = 0.1 trong Hình 4(c,d)]. Chúng tôi thấy rằng việc học nhiệm vụ thứ hai trở nên nhanh vì cần ít ví dụ dữ liệu hơn, và giá trị tới hạn của α cũng bị ảnh hưởng. Hơn nữa, việc ghi nhớ nhiệm vụ đầu tiên bị suy giảm mạnh. Kết quả này phù hợp với những gì được tìm thấy trong Hình 2(d).

Để xác minh số của lý thuyết replica trường trung bình, chúng tôi huấn luyện một perceptron với số synap N = 5000. Tốc độ học bằng 0.001 cho toàn bộ quá trình huấn luyện. Nếu chúng tôi sử dụng SGD, kích thước của một mini-batch được đặt thành 32. Trong phân tích replica, siêu tham số β₁ = β₂ = 20 cho nhiệm vụ đầu tiên và thứ hai. Một khi thuật toán cho nhiệm vụ hiện tại hội tụ (ví dụ: độ chính xác ổn định), chúng tôi chuyển việc học sang một nhiệm vụ mới. Hình 5 cho thấy sự thỏa thuận tuyệt vời giữa các dự đoán cân bằng thu được bằng phân tích replica và việc huấn luyện thực tế của perceptron.

III. HỌC LIÊN TỤC TRONG MẠNG NƠ-RON SÂU

Quên thảm khốc là một tính chất không mong muốn đối với mạng nơ-ron sâu được áp dụng cho học liên tục hoặc học đa nhiệm vụ. Trong phần này, chúng tôi mở rộng các phương pháp biến phân cho perceptron nhị phân đồ chơi đến mạng nơ-ron sâu trong việc phân loại tập dữ liệu có cấu trúc.

A. Nguyên lý học biến phân

Nguyên lý học biến phân là một khung Bayesian biến phân phổ biến được áp dụng trong nhiều kịch bản [12–15], chủ yếu tập trung vào mạng sâu với trọng số có giá trị thực. Để học một mạng sâu hiệu quả tính toán (trọng số nhị phân), chúng tôi điều chỉnh nguyên lý biến phân cho học liên tục, về lý thuyết và huấn luyện thực tế, so sánh hiệu suất với thuật toán metaplasticity thực nghiệm [8], một phương pháp duy nhất có sẵn để so sánh trong bối cảnh hiện tại của chúng tôi. Trong khung này, hậu nghiệm của tham số w được học từ T tập dữ liệu được trình bày liên tục {x^(n)_t, y^(n)_t}^{N_t}_{n=1}, trong đó t biểu thị chỉ số nhiệm vụ từ 1 đến T, và N_t biểu thị kích thước của tập dữ liệu t. Khi các ví dụ dữ liệu đa nhiệm vụ được hiển thị tuần tự cho máy, phân phối hậu nghiệm của w được ký hiệu là p(w|D_k), sau k bước huấn luyện dựa trên tập dữ liệu D_k (minibatch tại bước thứ k), có thể được tính bằng quy tắc Bayes là p(w|D_k) = p(D_k|w)p(w)/p(D_k). Tiên nghiệm p(w) phụ thuộc vào bước (k-1), có thể được lấy là hậu nghiệm trong bước huấn luyện trước đó p(w^{(k-1)}|D_{k-1}). Tổng hợp lại, hậu nghiệm p(w|D) có thể được viết là

p(w|D_k) = p(D_k|w)p(w^{(k-1)}|D_{k-1})/p(D_k). (24)

Thật không may, khó khăn ở đây là hậu nghiệm thường không thể xử lý được đối với hầu hết các mô hình xác suất, do đó đòi hỏi việc áp dụng phương pháp biến phân. Chúng tôi xấp xỉ hậu nghiệm thực với một phân phối có thể xử lý được tham số hóa bởi tham số biến phân θ. Bằng cách cập nhật θ, chúng ta tiếp cận phân phối đích càng gần càng tốt.

Cho một phân phối xác suất thử đơn giản trên biến tiềm ẩn w được tham số hóa bởi θ, tức là q_θ(w), việc tối thiểu hóa phân kỳ KL giữa q_θ(w) và p(w|D) dẫn đến giải pháp sau

θ* = arg min_θ KL[q_θ(w)∥p(w|D)]. (25)

Do đó, chúng ta có thể định nghĩa hàm tổn thất L là

L = KL[q_θ(w)∥p(w|D)] = L_{reg} + L_{rec}, (26)

trong đó chúng tôi thay thế tiên nghiệm p(w) bằng hậu nghiệm biến phân trong bước thời gian trước đó q_{θ_{k-1}}(w), và chúng tôi định nghĩa hạng chính quy hóa L_{reg} = KL[q_{θ_k}(w)∥q_{θ_{k-1}}(w)], và hạng tái tạo L_{rec} = -E_{q_{θ_k}(w)}[ln p(D|w)]. Hạng L_{rec} tính log-likelihood trung bình của đầu ra mạng, có thể được xấp xỉ thô bằng cách xem xét một mẫu đơn w_s của q_{θ_k}(w) từ ước lượng lấy mẫu Monte-Carlo thô. Bằng cách tính gradient của θ trên hàm tổn thất L này, chúng ta đến

∂L/∂θ_i^k = ∑_{w_i} ∂q_{θ_i^k}(w_i)/∂θ_i^k [1 - ln q_{θ_i^k}(w_i) - ln q_{θ_i^{k-1}}(w_i)] - ∂ln p(D|w_s)/∂θ_i^k. (27)

Việc học tham số biến phân θ_i có thể đạt được bằng gradient descent của hàm mục tiêu, tức là,

θ_i^{k+1} = θ_i^k - η ∂L/∂θ_i^k, (28)

trong đó η biểu thị tốc độ học, và θ_i^k tham chiếu đến kết nối thứ i trong một lớp của mạng sâu (ví dụ: θ_{ij}^{l,k} cho kết nối (ij) tại lớp l dưới đây).

Chúng tôi xem xét một mạng nơ-ron sâu với L lớp, và N_l biểu thị độ rộng của lớp thứ l. w_{ij}^l chỉ ra trọng số kết nối nơ-ron i tại lớp upstream l với nơ-ron j tại lớp downstream l+1. Trạng thái của nơ-ron j tại lớp l+1 h_j^{l+1} là một biến đổi phi tuyến của tiền kích hoạt z_j^{l+1} = 1/√N_l ∑_i w_{ij}^l h_i^l. Hàm truyền f(·) cho các lớp l = 1,2,...,L-1 được chọn là đơn vị tuyến tính chỉnh lưu (ReLU), được định nghĩa là f(z) = max(0,z). Đối với lớp đầu ra, hàm softmax h_k = e^{z_k}/∑_i e^{z_i} được sử dụng, chỉ định xác suất trên tất cả các lớp của hình ảnh đầu vào, trong đó z_i là tiền kích hoạt của nơ-ron i tại lớp đầu ra. Việc học có giám sát được xem xét, trong đó ĥ_k chỉ ra mục tiêu của h_k^L, và entropy chéo L_{ce} = -∑_i ĥ_i ln h_i được sử dụng làm hàm chi phí tương ứng với L_{rec}. Trong thiết lập của chúng tôi, một phân phối đỉnh kép được áp dụng để mô hình hóa trọng số nhị phân là q_{θ_{ij}^l}(w_{ij}^l) = e^{βw_{ij}^l θ_{ij}^l}/(e^{βθ_{ij}^l} + e^{-βθ_{ij}^l}), trong đó β là một siêu tham số, và tham số giống trường θ_{ij} kiểm soát phân phối xác suất của w_{ij} là q_{θ_{ij}^l}(+1) = e^{βθ_{ij}^l}/(e^{βθ_{ij}^l} + e^{-βθ_{ij}^l}) và q_{θ_{ij}^l}(-1) = e^{-βθ_{ij}^l}/(e^{βθ_{ij}^l} + e^{-βθ_{ij}^l}).

Do đó, các gradient của θ trên L_{reg} có thể được tính là

∂KL[q_{θ_{ij}^{l,k}}(w_{ij}^{l,k})∥q_{θ_{ij}^{l,k-1}}(w_{ij}^{l,k-1})]/∂θ_{ij}^{l,k} = β²(θ_{ij}^{l,k} - θ_{ij}^{l,k-1})/(σ_{ij}^{l,k})² = β²Δ_{ij}^{l,k}/(σ_{ij}^{l,k})², (29)

trong đó chỉ số trên l và k biểu thị chỉ số lớp và bước lặp tương ứng, và chúng tôi định nghĩa Δ_{ij}^{l,k} là gia số của tham số biến phân Δ_{ij}^{l,k} = θ_{ij}^{l,k} - θ_{ij}^{l,k-1} giữa hai bước liên tiếp. (σ_{ij}^{l,k})² chỉ ra phương sai của w_{ij}^l là (σ_{ij}^{l,k})² = 1 - tanh²(βθ_{ij}^{l,k}), và do đó nắm bắt sự bất định synap.

Để suy ra gradient của L_{rec}, chúng tôi áp dụng phương pháp trường trung bình [28]. Moment đầu tiên và thứ hai của w_{ij}^l được cho bởi μ_{ij}^l = ⟨w_{ij}^l⟩ = tanh(βθ_{ij}^l) và (σ_{ij}^l)² = 1 - (μ_{ij}^l)², tương ứng. Cho rằng độ rộng của lớp lớn, định lý giới hạn trung tâm chỉ ra rằng tiền kích hoạt z_j^{l+1} tuân theo phân phối Gaussian N(z|m_j^{l+1}; v_j^{l+1}), trong đó trung bình và phương sai được cho dưới đây,

m_j^{l+1} = ⟨z_i^l⟩ = 1/√N_l ∑_j μ_{ij}^l h_i^l

(v_j^{l+1})² = ⟨(z_j^{l+1})²⟩ - ⟨z_j^{l+1}⟩² = 1/N_l ∑_j (σ_{ij}^l)² (h_i^l)². (30)

Do đó chúng ta viết tiền kích hoạt là z_i^l = m_i^l + ε_i^l v_i^l, trong đó ε_i^l biểu thị một biến Gaussian tiêu chuẩn dựa vào chỉ số lớp và thành phần trọng số. Sau đó, chúng ta có thể tính các gradient như sau,

∂L_{rec}/∂θ_{ij}^l = ∂L_{rec}/∂z_j^{l+1} ∂z_j^{l+1}/∂θ_{ij}^l = K_j^{l+1} [∂m_j^{l+1}/∂θ_{ij}^l + ε_j^{l+1} ∂v_j^{l+1}/∂θ_{ij}^l], (31)

trong đó chúng tôi đã định nghĩa K_j^{l+1} = ∂L_{rec}/∂z_j^{l+1}, có thể được giải bằng quy tắc chuỗi. Các hạng ∂m_j^{l+1}/∂θ_{ij}^l và ∂v_j^{l+1}/∂θ_{ij}^l có thể được suy ra trực tiếp từ Phương trình (30), như được hiển thị dưới đây,

∂m_j^{l+1}/∂θ_{ij}^l = 1/√N_l β h_i^l (σ_{ij}^l)²,
∂v_j^{l+1}/∂θ_{ij}^l = -β (h_i^l)²/N_l v_j^{l+1} μ_{ij}^l (σ_{ij}^l)², (32)

và K_i^l có thể được ước lượng bằng quy tắc chuỗi từ giá trị tại lớp trên cùng, tức là,

K_i^l = ∑_j K_j^{l+1} [1/√N_l μ_{ij}^l + ε_j^{l+1}/N_l √(v_j^{l+1})² (σ_{ij}^l)² h_i^l] f'(z_i^l), (33)

trong đó f'(·) là đạo hàm của hàm truyền, và trên lớp trên cùng, K_i^L có thể được ước lượng trực tiếp là K_i^L = -ĥ_i(1-h_i^L). Tổng hợp lại, tổng gradient trên hàm tổn thất L có dạng

∂L/∂θ_{ij}^{l,k} = β/(σ_{ij}^{l,k})² [βΔ_{ij}^{l,k} + δ_{ij}^{l,k}], (34)

trong đó chúng tôi thêm chỉ số bước k là δ_{ij}^{l,k} = K_j^{l+1} [1/√N_l h_i^l - ε_j^{l+1}/N_l v_j^{l+1} (h_i^l)² μ_{ij}^l]. Có thể thấy rõ ràng rằng phương sai của w_{ij}^l tại bước lặp k cùng với nhiệt độ nghịch đảo β/(σ_{ij}^{l,k})² điều chỉnh tốc độ học η, trong đó phương sai lớn hơn dẫn đến gradient lớn hơn trong bước lặp k. Ngoài ra, hạng chính quy hóa βΔ_{ij}^{l,k-1} đo sự tương tự giữa các xác suất hậu nghiệm biến phân qua các bước học liên tiếp, điều này điều chỉnh khoảng cách từ dự đoán hiện tại đến dự đoán trước đó, cung cấp một cách có nguyên tắc để sử dụng thông tin từ kiến thức nhiệm vụ trước đó. Do đó, việc học liên tục biến phân này có thể được sử dụng trong các kịch bản nơi ranh giới nhiệm vụ không có sẵn [13], điều này cũng hợp lý hơn về mặt nhận thức từ kinh nghiệm học tập của con người. Sau đây, chúng tôi gọi sơ đồ học liên tục biến phân này là VCL.

Chúng tôi nhấn mạnh mối quan hệ giữa VCL được sử dụng trong phân tích mô hình đồ chơi trong phần trước và VCL được sử dụng cho học sâu liên tục thực tế trong phần này. Về bản chất, VCL trong hai phần này mang cùng nguyên tắc [xem Phương trình (26)]. Trong phân tích mô hình đồ chơi, chúng tôi chỉ định ranh giới nhiệm vụ, điều này cho phép chúng tôi suy ra thế năng Franz-Parisi của học liên tục. Tuy nhiên, trong huấn luyện thực tế, một huấn luyện không biết nhiệm vụ được ưa chuộng (như con người), điều này được nắm bắt chính xác trong Phương trình (34). Do đó, bước huấn luyện cuối cùng đóng vai trò như một tham chiếu trong ngôn ngữ của khung Franz-Parisi, tức là, việc học của bước tiếp theo có thể được mô tả bởi một hệ thống cân bằng với một ưu tiên bên ngoài được neo. Hơn nữa, trong phân tích mô hình đồ chơi, chúng tôi đặt siêu tham số β cho cả hai nhiệm vụ cùng giá trị. Trong học sâu thực tế, β được phép tăng với epoch [một ví dụ được hiển thị trong Hình 7(a)].

Đặc biệt, giao thức học tập của chúng tôi nhấn mạnh cách sự bất định synap điều chỉnh học liên tục, và do đó cung cấp một cách có nguyên tắc để hiểu các thực nghiệm kỹ thuật [15, 16] và các thực nghiệm lấy cảm hứng từ khoa học thần kinh [6, 8, 9]. Đối với mạng sâu với trọng số nhị phân, công trình trước đây sử dụng thao tác rời rạc hóa của trọng số liên tục, gradient thay thế và hàm metaplasticity (xem chi tiết trong Phụ lục A), trong khi VCL của chúng tôi không yêu cầu những thủ thuật này. Ngoài ra, các chiến lược thực nghiệm khác như elastic weight consolidation và các biến thể của nó [9] cũng có thể được thống nhất trong khung hiện tại của chúng tôi. Ví dụ, phần L_{reg} có thể được xấp xỉ bởi một hạng liên quan đến ma trận thông tin Fisher là

F(θ) = E_{q_θ(w)} [∂ln q_θ(w)/∂θ ∂ln q_θ(w)/∂θ^T], (35)

và sau đó

L_{reg} ≈ 1/2 (θ^k - θ^{k-1})^T F(θ^{k-1}) (θ^k - θ^{k-1}), (36)

trong đó chúng ta chỉ lấy các phần tử đường chéo của ma trận thông tin Fisher F(θ^{k-1}) ≈ β²(σ^{k-1})², khôi phục thuật toán elastic weight consolidation. Chứng minh kỹ thuật được đưa ra trong phụ lục B.

B. Hiệu suất học tập và vai trò của sự bất định synap

Trong phần này, chúng tôi so sánh hiệu suất của VCL và thuật toán metaplasticity cho mạng nơ-ron với trọng số nhị phân. Chi tiết thuật toán được đưa ra trong phụ lục A. Chúng tôi xem xét hai nhiệm vụ đầu tiên - học tuần tự của tập dữ liệu MNIST và Fashion-MNIST (f-MNIST) [8], và thiết lập này yêu cầu mạng học tuần tự từ hai tập dữ liệu: MNIST và f-MNIST. Tiếp theo, chúng tôi xem xét một benchmark học liên tục phổ biến, đó là nhiệm vụ học MNIST hoán vị [9]. Nhiệm vụ học MNIST hoán vị bao gồm học liên tục của nhiều tập dữ liệu, và mỗi nhiệm vụ chứa các hình ảnh được gắn nhãn của một hoán vị không gian ngẫu nhiên cố định của các pixel.

Hình 6 cho thấy rằng đối với cả hai thứ tự huấn luyện (f-MNIST trước hoặc MNIST trước), VCL đạt được hiệu suất tốt hơn nhiều so với thuật toán metaplasticity (viết tắt là meta), cho thấy lợi ích của việc quên ít hơn các nhiệm vụ đã học và do đó hiệu suất tốt hơn cho các nhiệm vụ mới đến. Hiện tượng tương tự cũng có thể được quan sát trong Hình 7, trong đó năm tập dữ liệu MNIST hoán vị được trình bày tuần tự cho mạng. Mạng được huấn luyện với VCL [Hình 7(a)] đang học tốt hơn và quên ít kiến thức nhiệm vụ trước đó hơn so với những mạng được huấn luyện với meta [Hình 7(b)]. Biểu đồ cho thấy độ chính xác phân loại cho nhiệm vụ t sau khi học các nhiệm vụ t' ≥ t. Một học liên tục hoàn hảo phải cung cấp độ chính xác cao cho nhiệm vụ t, và hơn nữa bảo tồn hiệu suất ngay cả khi các nhiệm vụ tiếp theo được học, điều này độc lập với thời gian huấn luyện của mỗi nhiệm vụ (ví dụ: tăng thời gian huấn luyện lên 100 epoch).

Chúng tôi cũng vẽ sự tiến hóa của sự bất định synap bằng cách tính trung bình ⟨σ⟩ = 1/số_trọng_số ∑_{(ij)} σ²_{ij} cho mỗi epoch và mỗi lớp. Như mong đợi, sự bất định trung bình giảm trong quá trình học liên tục. Tuy nhiên, mức độ tăng với độ lớn nhỏ sau khi chuyển nhiệm vụ, nhưng sau đó lại giảm. Ngoài ra, sự giảm của sự bất định cũng rõ ràng đối với các lớp upstream, cho thấy rằng các lớp này có xu hướng đóng băng hầu hết các trọng số, hoặc làm cho chúng ít dẻo hơn. Ngược lại, lớp cuối cùng duy trì một mức độ bất định synap thấp để đọc thông tin danh mục chính. Chúng tôi cũng quan sát rằng tính dẻo synap với sự bất định lớn hơn có đóng góp lớn hơn vào việc phân kỳ KL nên thay đổi mạnh như thế nào, do đó đóng vai trò quan trọng trong việc tối thiểu hóa mục tiêu tổng thể. Để kết luận, phương sai synap là một đại lượng chính xác định hành vi của học liên tục. VCL có thể điều chỉnh tài nguyên synap trong quá trình học tuần tự nhiều nhiệm vụ.

IV. KẾT LUẬN

Trong nghiên cứu này, chúng tôi tập trung vào học liên tục trong mạng nơ-ron sâu (hoặc nông) với trọng số nhị phân. Các công trình gần đây đã lập luận rằng huấn luyện biến phân hiệu quả trong mạng nơ-ron có trọng số giá trị thực [13–15], và một phương pháp metaplasticity lấy cảm hứng từ não bộ cũng hiệu quả trong huấn luyện mạng nơ-ron nhị phân [8]. Tuy nhiên, cách thống nhất những chiến lược đa dạng này trong một mô hình vật lý thống kê là thách thức. Ở đây, chúng tôi đề xuất một khung trường trung bình biến phân để tích hợp sự bất định synap, chuyển giao kiến thức nhiệm vụ và thế năng trường trung bình cho học đa nhiệm vụ. Đầu tiên, chúng tôi lập luận rằng sự bất định synap đóng vai trò chính trong việc điều chỉnh hiệu suất học liên tục, thông qua lăng kính phân phối trọng số biến phân. Cụ thể, phương sai synap trở thành một yếu tố điều chỉnh trong các quy tắc tính dẻo synap, dựa trên lý thuyết của chúng tôi. Thứ hai, chuyển giao kiến thức nhiệm vụ có thể được diễn giải trong vật lý. Kiến thức từ nhiệm vụ trước đó hoạt động như một cấu hình tham chiếu trong công thức thế năng Franz-Parisi [22, 23], một neo cho việc học kiến thức mới. Do đó, việc học nhiệm vụ mới có thể được mô tả bởi một hệ thống cân bằng với một ưu tiên bên ngoài được neo. Lý thuyết suy ra khớp tốt với các mô phỏng số sử dụng thuật toán gradient descent ngẫu nhiên.

Lý thuyết học liên tục biến phân của chúng tôi cũng dự đoán rằng học nhiệm vụ đơn thể hiện một chuyển tiếp liên tục với lượng dữ liệu ngày càng tăng (độ phức tạp mẫu), điều này hoàn toàn trái ngược với những phát hiện trước đây trong lý thuyết trường trung bình của tổng quát hóa (trong không gian trọng số rời rạc hoặc liên tục trực tiếp) [26, 27]. Dự đoán lý thuyết mới này gợi ý rằng học liên tục biến phân hiện tại chứng minh hiệu quả trong học thực tế, vì việc mắc kẹt bởi các trạng thái metastable vắng mặt. Chúng tôi lưu ý rằng việc vắng mặt của chuyển tiếp bậc nhất này chỉ áp dụng cho mạng nông. Do đó, thật thú vị khi mở rộng phân tích lý thuyết của chúng tôi đến mạng đa lớp để xem liệu kết luận này có hiện diện hay không.

Cuối cùng, chúng tôi chứng minh rằng khung của chúng tôi có thể được áp dụng cho học liên tục của tập dữ liệu thực, đạt được hiệu suất tương tự hoặc thậm chí tốt hơn với những hiệu suất thu được bằng các chiến lược thực nghiệm, chẳng hạn như metaplasticity. Do đó, công trình này có thể là một điểm khởi đầu đầy hứa hẹn để khám phá thêm câu hỏi quan trọng nhưng đầy thách thức về cách xây dựng biểu diễn nơ-ron có nền tảng lý thuyết giúp một tác nhân thông minh tránh quên thảm khốc và thích nghi liên tục với các nhiệm vụ mới, dựa trên kiến thức tích lũy từ các nhiệm vụ trước đó.

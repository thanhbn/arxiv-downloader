# Học Liên Tục thông qua Cắt Tỉa Neural
Siavash Golkar
Đại học New York
golkar@nyu.eduMichael Kagan
Phòng thí nghiệm Gia tốc Quốc gia SLAC
makagan@slac.stanford.edu
Kyunghyun Cho
Đại học New York
Facebook AI Research
CIFAR Azrieli Global Scholar
kyunghyun.cho@nyu.edu

Tóm tắt
Chúng tôi giới thiệu Học Liên Tục thông qua Cắt Tỉa Neural (CLNP), một phương pháp mới nhằm học suốt đời trong các mô hình có dung lượng cố định dựa trên việc làm thưa thớt mô hình neural. Trong phương pháp này, các tác vụ tiếp theo được huấn luyện bằng cách sử dụng các neuron và bộ lọc không hoạt động của mạng thưa thớt và không gây ra suy giảm hiệu suất nào cho các tác vụ trước đó. Để đối phó với sự thỏa hiệp có thể có giữa độ thưa thớt của mô hình và hiệu suất, chúng tôi chính thức hóa và kết hợp khái niệm quên lãng nhẹ nhàng: ý tưởng rằng việc chịu đựng một lượng nhỏ quên lãng một cách có kiểm soát sẽ tốt hơn nếu nó giúp lấy lại dung lượng mạng và ngăn chặn việc mất hiệu suất không kiểm soát trong quá trình huấn luyện các tác vụ tương lai. CLNP cũng cung cấp các công cụ chẩn đoán học liên tục đơn giản dưới dạng số lượng neuron tự do còn lại để huấn luyện các tác vụ tương lai cũng như số lượng neuron đang được tái sử dụng. Đặc biệt, chúng tôi thấy trong các thí nghiệm rằng CLNP xác minh và tự động tận dụng thực tế là các đặc trưng của các lớp trước dễ chuyển giao hơn. Chúng tôi cho thấy thực nghiệm rằng CLNP dẫn đến kết quả cải thiện đáng kể so với các phương pháp dựa trên độ đàn hồi trọng số hiện tại.

1 Giới thiệu
Học liên tục, khả năng của các mô hình học cách giải quyết các tác vụ mới ngoài những gì đã được huấn luyện trước đó, đã thu hút nhiều sự chú ý từ cộng đồng học máy trong những năm gần đây. Điều này được thúc đẩy một phần bởi những lợi thế thực tế mà các sơ đồ học liên tục hứa hẹn như cải thiện hiệu suất trên các tác vụ tiếp theo cũng như sử dụng tài nguyên hiệu quả hơn trong các máy có giới hạn bộ nhớ. Cũng có sự quan tâm lớn đến học liên tục từ góc độ dài hạn hơn, vì bất kỳ cách tiếp cận nào hướng tới trí tuệ nhân tạo tổng quát đều cần có khả năng liên tục xây dựng dựa trên các kinh nghiệm trước đó.

Như hiện tại, trở ngại chính trên con đường học liên tục hiệu quả là vấn đề quên lãng thảm khốc: các máy được huấn luyện trên các vấn đề mới quên đi các tác vụ mà chúng đã được huấn luyện trước đó. Có nhiều cách tiếp cận trong tài liệu tìm cách giảm bớt vấn đề này, từ việc sử dụng các mạng với nhiều mô-đun con [2,12,15] đến việc ràng buộc các trọng số của mạng được coi là quan trọng cho các tác vụ trước đó [6,8,20]. Những cách tiếp cận này hoặc yêu cầu các sơ đồ huấn luyện thuật toán di truyền chuyên biệt hoặc vẫn gặp phải quên lãng thảm khốc, mặc dù ở mức độ nhỏ hơn. Đặc biệt, theo hiểu biết tốt nhất của chúng tôi, không có hình thức đảm bảo nào về hiệu suất của các tác vụ trước đó trong số các mô hình dung lượng cố định sử dụng các sơ đồ huấn luyện SGD tiêu chuẩn.

Trong công trình này, chúng tôi giới thiệu một sơ đồ học liên tục dung lượng cố định đơn giản có thể được huấn luyện bằng các phương pháp gradient descent tiêu chuẩn và theo cấu trúc không gặp phải suy giảm nào trên các vấn đề đã học trước đó trong quá trình huấn luyện các tác vụ mới. Tóm lại, chúng tôi tận dụng việc tham số hóa quá mức của mạng neural bằng cách sử dụng một sơ đồ làm thưa thớt cắt tỉa neural dựa trên kích hoạt để huấn luyện các mô hình chỉ sử dụng một phần độ rộng của chúng. Sau đó chúng tôi huấn luyện các tác vụ tiếp theo sử dụng dung lượng chưa sử dụng của mô hình. Bằng cách cắt bỏ các kết nối nhất định trong mạng, chúng tôi đảm bảo rằng các tác vụ mới có thể tận dụng các đặc trưng đã học trước đó nhưng không gây can thiệp trong các đường dẫn của các tác vụ đã học trước đó.

Đóng góp chính
Chúng tôi giới thiệu Học Liên Tục thông qua Cắt Tỉa Neural (CLNP), một phương pháp học suốt đời đơn giản và trực quan với các thuộc tính sau:

– Cho một mạng với độ thưa thớt neuron dựa trên kích hoạt được huấn luyện trên một số tác vụ trước đó, CLNP huấn luyện các tác vụ mới sử dụng các trọng số chưa sử dụng của mạng theo cách tận dụng các đặc trưng được học bởi các tác vụ trước đó trong khi gây ra zero quên lãng thảm khốc.

– CLNP cung cấp chẩn đoán đơn giản dưới dạng số lượng neuron và bộ lọc còn lại và tái sử dụng khi huấn luyện mỗi tác vụ. Đặc biệt, trong các thí nghiệm chúng tôi thấy rằng CLNP xác minh và tự động tận dụng thực tế là các đặc trưng của các lớp trước dễ chuyển giao hơn.

Chúng tôi mở rộng ý tưởng về quên lãng nhẹ nhàng, khái niệm rằng việc chịu đựng một lượng nhỏ quên lãng một cách có kiểm soát sẽ tốt hơn nếu nó giúp lấy lại dung lượng mạng và ngăn chặn việc mất hiệu suất không kiểm soát trong quá trình huấn luyện các tác vụ tương lai. Chúng tôi sử dụng ý tưởng này để kiểm soát sự thỏa hiệp giữa độ thưa thớt mạng và độ chính xác mô hình trong cách tiếp cận của chúng tôi.

Chúng tôi cho thấy thực nghiệm rằng việc sử dụng một sơ đồ làm thưa thớt cắt tỉa neural dựa trên kích hoạt, chúng tôi vượt trội đáng kể so với các cách tiếp cận trước đây dựa trên độ đàn hồi trọng số trên một số điểm chuẩn. Chúng tôi cũng chứng minh trong một ví dụ rằng việc sử dụng một biến thể hơi nâng cao hơn của phương pháp làm thưa thớt của chúng tôi, mạng gần như không bị mất hiệu suất, hoặc từ quên lãng thảm khốc hoặc từ làm thưa thớt.

Phần còn lại của bài báo được tổ chức như sau. Trong Mục 2, chúng tôi cung cấp phương pháp luận của cách tiếp cận. Trước tiên chúng tôi thảo luận về tính tổng quát của việc huấn luyện không phá hủy trong các vùng thưa thớt của mạng trong Mục 2.1. Sau đó chúng tôi thảo luận về sơ đồ làm thưa thớt của chúng tôi cũng như ý tưởng về quên lãng nhẹ nhàng như một sự thỏa hiệp giữa độ thưa thớt và hiệu suất mô hình trong Mục 2.2. Chúng tôi cung cấp một kiểm tra thực nghiệm của phương pháp luận trong Mục 3, đầu tiên trên mười tác vụ được dẫn xuất từ bộ dữ liệu MNIST trong Mục 3.1 và sau đó trên một vấn đề được dẫn xuất từ CIFAR-10 và CIFAR-100 trong Mục 3.2. Trong cả hai trường hợp chúng tôi cho thấy sự cải thiện đáng kể so với công trình trước đó tương đương.

Công trình liên quan
Học suốt đời. Công trình trước đây giải quyết vấn đề quên lãng thảm khốc thường rơi vào hai loại. Trong loại đầu tiên, mô hình bao gồm nhiều mô-đun riêng lẻ ở mỗi lớp và quên lãng được ngăn chặn hoặc bằng cách định tuyến dữ liệu qua các mô-đun khác nhau [2] hoặc bằng cách liên tiếp thêm các mô-đun mới cho mỗi tác vụ mới [12,15]. Cách tiếp cận này thường (nhưng không phải lúc nào cũng) có lợi thế là không bị quên lãng, tuy nhiên, cấu trúc của những mạng này được chuyên biệt hóa. Trong trường hợp của [12, 15], mô hình không có dung lượng cố định và trong trường hợp của [2] việc huấn luyện được thực hiện bằng thuật toán di truyền lựa chọn giải đấu. Trong loại thứ hai của các cách tiếp cận học suốt đời, cấu trúc của mạng cũng như sơ đồ huấn luyện là tiêu chuẩn, và quên lãng được giải quyết bằng cách ràng buộc các trọng số quan trọng không thay đổi [6,8,20]. Những cách tiếp cận này, thường được gọi là các phương pháp độ đàn hồi trọng số, có lợi thế là có các sơ đồ huấn luyện đơn giản hơn nhưng vẫn gặp phải quên lãng thảm khốc, mặc dù ở mức độ nhỏ hơn so với huấn luyện không ràng buộc.

Cách tiếp cận chúng tôi thực hiện trong bài báo này thuộc về loại thứ hai trong đó cấu trúc mạng và sơ đồ huấn luyện đơn giản và quên lãng được ngăn chặn bằng cách ràng buộc một số trọng số nhất định không thay đổi. Tuy nhiên, nó chia sẻ lợi thế chính của các cách tiếp cận loại đầu tiên là chúng tôi không gặp phải quên lãng thảm khốc trong quá trình huấn luyện các tác vụ tiếp theo. Đặc biệt, phương pháp của chúng tôi có thể được coi là một sự thích ứng và đơn giản hóa loại thứ hai của cách tiếp cận dựa trên đường dẫn của [2] sử dụng làm thưa thớt dựa trên kích hoạt và ý tưởng quên lãng nhẹ nhàng. Vì phương pháp của chúng tôi có thể so sánh trực tiếp với các cách tiếp cận loại thứ hai khác, chúng tôi sẽ cung cấp so sánh định lượng với các phương pháp khác trong loại này.

Chồng lấp mạng. Phương pháp chúng tôi đưa ra trong bài báo này có thể được coi là một cách không phá hủy để chồng lấp nhiều thể hiện của cùng một kiến trúc sử dụng làm thưa thớt. Có các công trình trước đây theo hướng này [16,17], tuy nhiên những công trình này thiên về tìm kiếm kiến trúc neural và không nhằm ngăn chặn quên lãng. Công trình liên quan nhất theo hướng này là [1], có thể được coi là một triển khai không gian Fourier của cách tiếp cận của chúng tôi. Tuy nhiên, so với [1] nơi chồng lấp là gần đúng, cách tiếp cận của chúng tôi là chính xác và chúng tôi có kiểm soát chính xác về mối quan hệ giữa các mô hình khác nhau được chồng lấp về mặt học chuyển giao. Chúng tôi sẽ cung cấp so sánh định lượng trong các thí nghiệm của chúng tôi.

Làm thưa thớt. Làm thưa thớt mạng neural có lịch sử lâu dài [11,13,18]. Mặc dù làm thưa thớt là một công cụ quan trọng mà chúng tôi sử dụng, nó không phải là trọng tâm của công trình này. Để dễ tiếp cận, chúng tôi sử dụng một sơ đồ làm thưa thớt đơn giản dựa trên neuron/bộ lọc có thể được coi là một biến thể lặp đơn của [7] không có tinh chỉnh. Để xem xét gần đây về các phương pháp làm thưa thớt, hãy xem [4].

Độ thưa thớt dựa trên tham số (độ thưa thớt trong ma trận trọng số) đã được sử dụng trong [12] như một công cụ để giảm (nhưng không loại bỏ) quên lãng thảm khốc và tăng hiệu quả trong một mạng tăng trưởng động. Ngược lại, phương pháp của chúng tôi tập trung vào độ thưa thớt dựa trên kích hoạt (độ thưa thớt trong số lượng bộ lọc/neuron được sử dụng), không gặp phải quên lãng thảm khốc và có dung lượng cố định. Phương pháp của chúng tôi cũng có một số điểm tương đồng với [3], một tiền thân của các phương pháp dựa trên phân cụm được đưa ra trong những năm 90.

2 Phương pháp luận
Ý tưởng cốt lõi của phương pháp chúng tôi là tận dụng thực tế rằng mạng neural được tham số hóa quá mức [14]. Một biểu hiện của việc tham số hóa quá mức này là thông qua thực hành làm thưa thớt, tức là nén mạng neural với việc mất hiệu suất tương đối ít [4,11,18]. Ví dụ, Luo et al. [13] cho thấy rằng VGG-16 có thể được nén hơn 16 lần, để lại hơn 90% kết nối không được sử dụng. Trong phần này, trước tiên chúng tôi cho thấy rằng cho một mạng thưa thớt dựa trên kích hoạt, chúng tôi có thể tận dụng dung lượng chưa sử dụng của mô hình để phát triển một sơ đồ học liên tục không gặp phải quên lãng thảm khốc. Sau đó chúng tôi thảo luận về ý tưởng quên lãng nhẹ nhàng để giải quyết căng thẳng giữa làm thưa thớt và hiệu suất mô hình trong bối cảnh học suốt đời.

Điều quan trọng là phải phân biệt độ thưa thớt neural dựa trên kích hoạt với độ thưa thớt trọng số dựa trên tham số. Cái trước ngụ ý chỉ một tập con của các neuron hoặc bộ lọc của mỗi lớp hoạt động trong khi cái sau có nghĩa là nhiều trọng số bằng không nhưng tất cả neuron được giả định là hoạt động ở tất cả các lớp. Trong phần còn lại của bài báo, khi chúng tôi đề cập đến độ thưa thớt, chúng tôi đang đề cập đến độ thưa thớt neural dựa trên kích hoạt.

Trong những gì sau đây, chúng tôi sẽ thảo luận về độ thưa thớt cho các lớp kết nối đầy đủ bằng cách xem xét các neuron riêng lẻ. Cùng một lập luận đi qua tương tự cho các kênh riêng lẻ của các lớp tích chập.

2.1 Tính tổng quát
Chúng ta hãy giả sử rằng chúng ta có một mạng được huấn luyện thưa thớt theo nghĩa là chỉ một tập con của các neuron của mạng hoạt động. Thực tế, các mạng có hình thức độ thưa thớt này có thể được coi là các mạng hẹp hơn được nhúng bên trong cấu trúc ban đầu. Có nhiều cách tiếp cận nhằm huấn luyện các mạng thưa thớt như vậy với ít mất hiệu suất (xem ví dụ Refs. [7,13]). Chúng tôi sẽ thảo luận chi tiết về phương pháp làm thưa thớt cụ thể của chúng tôi trong Mục 2.2.

Hình 1 cho thấy một bản vẽ của một mạng với độ thưa thớt neural dựa trên kích hoạt, trong đó các neuron hoạt động và không hoạt động được ký hiệu tương ứng bằng các nút màu xanh lam và xám. Dựa trên cấu trúc kết nối, các trọng số của mạng cũng có thể được chia thành ba lớp. Đầu tiên chúng ta có các trọng số hoạt động Wact kết nối các nút hoạt động với các nút hoạt động. Chúng được ký hiệu bằng màu xanh lam trong Hình 1. Tiếp theo chúng ta có các trọng số kết nối bất kỳ nút nào với các nút không hoạt động, chúng ta gọi đây là các trọng số tự do Wfree, được ký hiệu bằng màu xám trong Hình 1. Cuối cùng chúng ta có các trọng số kết nối các nút không hoạt động với các nút hoạt động, chúng ta gọi đây là các trọng số can thiệp Wint, được ký hiệu bằng các đường nét đứt màu đỏ trong Hình 1. Một định nghĩa chính xác hơn về các neuron và trọng số hoạt động và không hoạt động được đưa ra trong Mục 2.2.

Điểm mấu chốt của cách tiếp cận của chúng tôi là quan sát đơn giản rằng nếu tất cả các trọng số can thiệp Wint được đặt bằng không, các trọng số tự do Wfree có thể được thay đổi tùy ý mà không gây ra bất kỳ thay đổi nào cho đầu ra của mạng. Do đó chúng ta có thể sử dụng những trọng số này để huấn luyện các tác vụ mới mà không gây hại gì cho hiệu suất của các tác vụ trước đó.

Lưu ý rằng chúng ta có thể chia nhỏ hơn nữa các trọng số tự do thành hai nhóm. Đầu tiên, các trọng số kết nối các nút hoạt động với các nút không hoạt động. Đây là những trọng số tận dụng các đặc trưng đã học trước đó và do đó chịu trách nhiệm cho việc học chuyển giao trong toàn bộ mạng. Chúng ta cũng có các trọng số kết nối các nút không hoạt động với các nút không hoạt động. Những trọng số này có thể tạo thành các đường dẫn hoàn toàn mới đến đầu vào và huấn luyện các đặc trưng mới. Một chẩn đoán bổ sung cho lượng học chuyển giao diễn ra là số lượng neuron hoạt động mới ở mỗi lớp sau khi huấn luyện các tác vụ tiếp theo. Với việc một sơ đồ huấn luyện thưa thớt hiệu quả sẽ không cần học lại các đặc trưng đã có trong mạng, số lượng neuron mới được tăng trưởng ở mỗi giai đoạn huấn luyện là một chỉ báo về tính đầy đủ của các đặc trưng đã học cho mục đích của tác vụ mới. Chúng ta sẽ thấy thêm về điểm này trong Mục 3.

Kiến trúc đầu ra. Để hoàn thiện đầy đủ một sơ đồ học liên tục, chúng ta cần chỉ định cấu trúc kết nối của các nút đầu ra. Có hai lộ trình trực quan mà chúng ta có thể thực hiện. Chúng tôi chứng minh những điều này trong Hình 2, trong đó ở giữa chúng ta có cùng cấu trúc như trong Hình 1, nhưng với các trọng số can thiệp được đặt bằng không. Để huấn luyện một tác vụ mới, một lựa chọn là sử dụng một lớp đầu ra mới (tức là một đầu mới) trong khi lưu lớp đầu ra trước đó. Lựa chọn này, được chứng minh trong Hình 2 bên trái, được gọi là cách tiếp cận đa đầu và là tiêu chuẩn trong học liên tục. Bởi vì mỗi lớp đầu ra mới đi kèm với bộ trọng số riêng của nó kết nối với các neuron lớp ẩn cuối cùng, phương pháp này không phải là một phương pháp dung lượng hoàn toàn cố định. Lưu ý rằng trong cách tiếp cận học liên tục của chúng tôi, việc huấn luyện một mạng đa đầu với cấu trúc lõi hoàn toàn cạn kiệt, tức là một mạng không còn neuron tự do nào, tương đương với học chuyển giao lớp cuối cùng.

Trong các tình huống mà lớp đầu ra của các tác vụ khác nhau tương thích về mặt cấu trúc, ví dụ khi tất cả các tác vụ đều là phân loại trên cùng số lượng lớp, chúng ta có thể sử dụng cách tiếp cận đầu đơn. Được chứng minh trong Hình 2 bên phải, trong cách tiếp cận này chúng ta sử dụng cùng một lớp đầu ra cho tất cả các tác vụ, nhưng đối với mỗi tác vụ, chúng ta che các neuron của lớp ẩn cuối cùng được huấn luyện trên các tác vụ khác. Trong trường hợp của Hình 2, chỉ các nút màu xanh lá trong lớp ẩn cuối cùng được kết nối với đầu ra cho tác vụ thứ hai và chỉ các nút màu xanh lam cho tác vụ đầu tiên. Điều này tương đương với việc phân vùng động lớp ẩn cuối cùng thành nhiều phần có kích thước không bằng nhau, một phần cho mỗi tác vụ. Trong thực tế, điều này được thực hiện bằng cách sử dụng một hoạt động che nhân với một mặt nạ phụ thuộc tác vụ, được ký hiệu trong Hình 2 bằng các đường nét đứt sau lớp ẩn cuối cùng. Cấu trúc này thực sự có dung lượng cố định, nhưng hạn chế hơn để huấn luyện so với đối tác đa đầu của nó. Lưu ý rằng vì một cấu trúc đầu đơn không ràng buộc sẽ gây ra một lượng lớn can thiệp giữa các tác vụ, cho đến nay nó chưa phải là một lựa chọn khả thi cho các cách tiếp cận học liên tục dựa trên độ đàn hồi trọng số.

2.2 Chi tiết phương pháp luận
Trong những gì sau đây, chúng tôi sẽ giả sử rằng chúng ta đang sử dụng Đơn vị Tuyến tính Chỉnh lưu (ReLU [5]). Mặc dù chúng tôi chỉ thử nghiệm phương pháp luận của mình với các mạng ReLU, chúng tôi mong đợi nó hoạt động tương tự với các kích hoạt khác.

Làm thưa thớt. Cho đến nay trong phần này, chúng tôi đã chỉ ra rằng cho một mạng thưa thớt được huấn luyện trên một số tác vụ, chúng ta có thể huấn luyện mạng trên các tác vụ mới mà không gặp phải quên lãng thảm khốc nào. Bây giờ chúng tôi thảo luận về sơ đồ làm thưa thớt cụ thể mà chúng tôi sử dụng trong suốt bài báo này, tương tự về tinh thần với cách tiếp cận cắt tỉa mạng được đưa ra trong Ref. [7].

Phương pháp làm thưa thớt của chúng tôi bao gồm hai phần. Đầu tiên, trong quá trình huấn luyện mỗi tác vụ, chúng tôi thêm một bộ điều chỉnh trọng số L1 để thúc đẩy độ thưa thớt trong mạng và để điều chỉnh độ lớn của các trọng số của mạng. Hệ số của bộ điều chỉnh này là một siêu tham số của cách tiếp cận của chúng tôi. Ngoài ra, vì các lớp khác nhau có phân phối trọng số khác nhau, chúng ta có thể có được nhiều kiểm soát hơn về lượng độ thưa thớt trong mỗi lớp bằng cách chọn một λ khác nhau cho mỗi lớp. Phần thứ hai của sơ đồ làm thưa thớt của chúng tôi là cắt tỉa neuron sau huấn luyện dựa trên hoạt động trung bình của mỗi neuron. Lưu ý rằng các thuật toán làm thưa thớt hiệu quả nhất bao gồm một phần thứ ba liên quan đến việc điều chỉnh các trọng số còn sống của mạng sau khi cắt tỉa. Bước này được gọi là tinh chỉnh và được thực hiện bằng cách huấn luyện lại mạng trong vài epoch trong khi chỉ cập nhật các trọng số sống sót sau làm thưa thớt. Điều này khiến mô hình lấy lại một số hiệu suất bị mất do cắt tỉa. Để đạt được mức độ thưa thớt cao hơn nữa, người ta có thể lặp lại các bước cắt tỉa và tinh chỉnh nhiều lần. Trong bài báo này, chúng tôi chỉ thực hiện một lần lặp cắt tỉa để đơn giản. Chúng tôi cũng bỏ qua bước tinh chỉnh, trừ khi được chỉ định khác.

Trong Mục 2.1, chúng tôi đã phân vùng mạng thành các phần hoạt động và không hoạt động. Một định nghĩa chính xác của những phân vùng khác nhau này như sau. Cho mạng N, bao gồm L lớp, chúng ta ký hiệu các neuron của mỗi lớp là Nl với l = 1...L. Chúng ta cũng giả sử rằng mạng N đã được huấn luyện trên tập dữ liệu S. Để tìm các neuron hoạt động và không hoạt động của mạng, chúng ta tính toán hoạt động trung bình trên toàn bộ tập dữ liệu S cho mỗi neuron riêng lẻ. Chúng ta xác định các neuron hoạt động N^act_l, tức là các nút màu xanh lam trong Hình 1, như những neuron có hoạt động trung bình vượt quá một số tham số ngưỡng θ:

N^act_l = {Nl | E_S[|Nl|] > θ}.

Các neuron không hoạt động được lấy là phần bù N^inact_l = Nl \ N^act_l. Giá trị ngưỡng θ là một siêu tham số sau huấn luyện của cách tiếp cận của chúng tôi. Tương tự như siêu tham số bộ điều chỉnh trọng số L1 λ, θ có thể nhận các giá trị khác nhau cho các lớp khác nhau. Hơn nữa, nếu θ = 0, N^inact_l sẽ được đưa ra bởi các neuron trong mạng hoàn toàn chết và hàm được tính toán bởi mạng hoàn toàn được nắm bắt trong N^act_l. Do đó chúng ta có thể xem N^act_l như một nén của mạng thành một mạng con có độ rộng nhỏ hơn. Dựa trên cấu trúc kết nối của chúng, các trọng số của mỗi lớp lại được chia thành các phần hoạt động, tự do và can thiệp, tương ứng với các đường màu xanh lam, xám và đỏ trong Hình 1. Thuật toán tổng thể của cách tiếp cận trong phiên bản đa đầu được đưa ra trong Thuật toán 1 (Ở đây, chúng tôi sử dụng ký hiệu W^A→B để ký hiệu tập con của các trọng số trong W kết nối neuron A với neuron B).

Quên lãng nhẹ nhàng. Mặc dù độ thưa thớt là rất quan trọng trong cách tiếp cận của chúng tôi để huấn luyện các tác vụ sau này, cần phải cẩn thận để không làm quá thưa thớt và do đó làm giảm hiệu suất của mô hình. Trong thực tế, độ thưa thớt mô hình có cùng mối quan hệ với khái quát hóa như các sơ đồ chính quy hóa khác. Khi độ thưa thớt tăng, ban đầu hiệu suất khái quát hóa của mô hình được cải thiện. Tuy nhiên, khi chúng ta đẩy các núm độ thưa thớt của mình (tức là bộ điều chỉnh L1 và ngưỡng hoạt động) cao hơn và làm cho mạng thưa thớt hơn, cuối cùng cả độ chính xác huấn luyện và xác thực sẽ bị ảnh hưởng và mạng không thể phù hợp với dữ liệu đúng cách. Điều này có nghĩa là trong việc chọn những siêu tham số này, chúng ta phải thực hiện một sự thỏa hiệp giữa hiệu suất mô hình và dung lượng mạng còn lại cho các tác vụ tương lai.

Điều này đưa chúng ta đến một chủ đề thường bị bỏ qua trong tài liệu học suốt đời thường được gọi là quên lãng nhẹ nhàng. Đây là khái niệm chung rằng việc hy sinh một chút độ chính xác một cách có kiểm soát sẽ tốt hơn, nếu nó làm giảm quên lãng thảm khốc của tác vụ này và giúp trong việc huấn luyện các tác vụ tương lai. Chúng tôi tin rằng bất kỳ thuật toán học liên tục dung lượng cố định thành công nào cũng cần triển khai một số hình thức sơ đồ quên lãng nhẹ nhàng. Trong cách tiếp cận của chúng tôi, quên lãng nhẹ nhàng được triển khai thông qua sự thỏa hiệp độ thưa thớt so với hiệu suất. Nói cách khác, sau khi huấn luyện mỗi tác vụ, chúng tôi làm thưa thớt mô hình đến một mức độ mất hiệu suất có thể chấp nhận được một cách có kiểm soát. Sau đó chúng tôi chuyển sang các tác vụ tiếp theo biết rằng mô hình không còn bị suy giảm thêm nữa từ việc huấn luyện các tác vụ tương lai. Điều này phải được tương phản với các cách tiếp cận độ đàn hồi trọng số khác sử dụng các ràng buộc mềm trên các trọng số của mạng và không thể đảm bảo hiệu suất tương lai của các tác vụ đã huấn luyện trước đó. Chúng ta sẽ thấy trong phần tiếp theo rằng việc sử dụng cùng cấu trúc mạng chính xác, cách tiếp cận của chúng tôi dẫn đến kết quả cải thiện đáng chú ý so với các phương pháp hiện có.

Một cách rõ ràng, việc lựa chọn các siêu tham số độ thưa thớt được thực hiện dựa trên ý tưởng quên lãng nhẹ nhàng này như sau. Như là thực hành tiêu chuẩn, chúng tôi chia tập dữ liệu cho mỗi tác vụ thành các tập huấn luyện, xác thực và kiểm tra. Chúng tôi quét qua một loạt các siêu tham số (tức là λ, bộ điều chỉnh trọng số L1 và lr, tỷ lệ học) sử dụng tìm kiếm lưới và ghi nhận giá trị của độ chính xác xác thực tốt nhất trên tất cả các siêu tham số. Sau đó chúng tôi chọn các mô hình đạt được độ chính xác xác thực trong biên độ m% của độ chính xác xác thực tốt nhất này. Tham số biên độ m kiểm soát mức độ chúng ta sẵn sàng thỏa hiệp về độ chính xác để lấy lại dung lượng và trong các thí nghiệm chúng tôi lấy nó thường trong phạm vi 0.05% đến 2% tùy thuộc vào tác vụ. Chúng tôi làm thưa thớt các mô hình được chọn bằng cách sử dụng ngưỡng hoạt động cao nhất θ sao cho mô hình vẫn trong biên độ này của độ chính xác xác thực tốt nhất. Cuối cùng chúng tôi chọn các siêu tham số cho độ thưa thớt cao nhất trong số các mô hình này. Bằng cách này, chúng tôi tìm thấy hiệu quả các siêu tham số cho mô hình độ thưa thớt cao nhất với độ chính xác xác thực trong m% của giá trị cao nhất của nó.

Sau khi cắt tỉa các trọng số và neuron không sử dụng của mô hình với các siêu tham số được chọn như trên, chúng tôi báo cáo độ chính xác kiểm tra của mạng thưa thớt. Cần lưu ý rằng thuật toán này để huấn luyện và tìm kiếm siêu tham số lưới không phát sinh bất kỳ gánh nặng tính toán đáng kể nào so với thực hành tiêu chuẩn. Tìm kiếm siêu tham số được thực hiện theo cách tiêu chuẩn, và các bước bổ sung của việc chọn mạng trong biên độ có thể chấp nhận, quét ngưỡng, và chọn mạng độ thưa thớt cao nhất chỉ yêu cầu đánh giá và không bao gồm bất kỳ huấn luyện mạng bổ sung nào.

3 Thí nghiệm
Chúng tôi đánh giá cách tiếp cận của mình cho học liên tục trên MNIST hoán vị [10], và các phiên bản chia của CIFAR-10 và CIFAR-100 [9] và so sánh với các kết quả trước đó.

3.1 MNIST hoán vị
Trong thí nghiệm này, chúng tôi xem xét hiệu suất của cách tiếp cận trên mười tác vụ được dẫn xuất từ bộ dữ liệu MNIST thông qua mười hoán vị ngẫu nhiên của các pixel. Để so sánh với công trình trước đây, chúng tôi chọn cùng cấu trúc và siêu tham số như trong Ref. [20]: một MLP với hai lớp ẩn, mỗi lớp có 2000 neuron và kích hoạt ReLU và mất entropy chéo đa lớp softmax được huấn luyện với bộ tối ưu hóa Adam và kích thước batch 256. Chúng tôi thực hiện một sửa đổi nhỏ đối với cấu trúc của mạng: trái ngược với Refs. [1,20] sử dụng cấu trúc đa đầu, chúng tôi sử dụng mạng đầu đơn. Điều này làm cho mạng của chúng tôi trở thành một cấu trúc dung lượng thực sự cố định và làm cho tác vụ học liên tục thách thức hơn.

Giống như trong Ref. [20], chúng tôi thực hiện tìm kiếm lưới trên các siêu tham số trên tác vụ đầu tiên sử dụng một tập xác thực riêng. Đối với các tác vụ còn lại, chúng tôi quyết định tỷ lệ học 0.002 và chính quy hóa trọng số L1 λ = 10^-7; 10^-5; 10^-6 tương ứng cho lớp đầu tiên, thứ hai và cuối cùng. Cuối cùng, khi làm thưa thớt sau khi huấn luyện mỗi tác vụ, chúng tôi cho phép quên lãng nhẹ nhàng với biên độ nhỏ m = 0.05%. Chúng tôi chạy thí nghiệm 5 lần và báo cáo trung bình và độ lệch chuẩn của độ chính xác kiểm tra của mạng trong Bảng 1. Với lỗi kiểm tra trong phạm vi 0.05% của huấn luyện SGD tác vụ đơn, CLNP gần như loại bỏ quên lãng thảm khốc trong ví dụ này và vượt trội đáng chú ý so với các phương pháp trước đây trong khi sử dụng kiến trúc đầu đơn dung lượng cố định hạn chế hơn.

Một tính năng tốt của cách tiếp cận dựa trên độ thưa thớt của chúng tôi là chúng tôi có hiểu biết rõ ràng về lượng mạng đã được sử dụng bởi các tác vụ trước đó và lượng còn lại tự do. Chúng tôi cũng có chỉ báo tốt về số lượng đặc trưng của các tác vụ đã học trước đó đang được tái sử dụng. Hình 3 cho thấy tỷ lệ phần trăm của các neuron lớp ẩn được sử dụng sau mỗi tác vụ trung bình qua 5 lần chạy. Chúng ta thấy rằng số lượng neuron được sử dụng của lớp đầu tiên không tăng nhiều sau khi tác vụ đầu tiên được huấn luyện, ngụ ý một lượng đáng kể tái sử dụng các đặc trưng của lớp này. Số lượng neuron được sử dụng trong lớp thứ hai tăng tuyến tính với mỗi tác vụ. Điều này như mong đợi, vì trong cấu trúc đầu đơn không có neuron nào của lớp ẩn cuối cùng được tái sử dụng để ngăn chặn can thiệp (xem Hình 2).

Cuối cùng lưu ý rằng sau khi huấn luyện tất cả 10 tác vụ, các neuron của hai lớp ẩn của mạng chỉ được sử dụng 18% và 40%, để lại rất nhiều dung lượng tự do cho các tác vụ tương lai. Trong các thí nghiệm của chúng tôi, chúng ta có thể huấn luyện tổng cộng khoảng 25 tác vụ hoán vị ngẫu nhiên với cùng độ chính xác kiểm tra 98.4% trước khi dung lượng của lớp ẩn cuối cùng được cạn kiệt hoàn toàn. Điều này trái ngược với công trình trước đây nơi độ chính xác trung bình trên tất cả các tác vụ tiếp tục giảm khi nhiều tác vụ hơn được huấn luyện (xem ví dụ Hình 4 trong Ref. [20]).

3.2 CIFAR-10/CIFAR-100 chia
Trong thí nghiệm này, chúng tôi huấn luyện một mô hình tuần tự, đầu tiên trên CIFAR-10 (tác vụ 1) và sau đó trên CIFAR-100 được chia thành 10 tác vụ khác nhau, mỗi tác vụ có 10 lớp (tác vụ 2-11). Chúng tôi sử dụng hai mô hình khác nhau cho thí nghiệm này, một mạng đa đầu nhỏ hơn được sử dụng trong Ref. [20] và một mạng đầu đơn rộng hơn cho mục đích chứng minh, được đưa ra tương ứng trong Bảng 2 và Bảng 3.

Để cung cấp so sánh trực tiếp với các kết quả trước đây trên tập dữ liệu này, chúng tôi áp dụng mô hình và sơ đồ huấn luyện của Ref. [20]. Cụ thể, chúng tôi huấn luyện tuần tự chỉ trên 6 tác vụ đầu tiên của vấn đề này sử dụng bộ tối ưu hóa Adam với tỷ lệ học 0.001. Chúng tôi chọn hệ số bộ điều chỉnh trọng số L1 λ = 5×10^-5. Chúng tôi cũng sử dụng hai sơ đồ quên lãng nhẹ nhàng khác nhau được định nghĩa qua các biên độ khả năng chấp nhận độ chính xác xác thực là m = 1% và m = 2%. Chúng tôi thực hiện thí nghiệm 5 lần và báo cáo độ chính xác xác thực và độ lệch chuẩn của nó trên 6 tác vụ.

Kết quả của thí nghiệm được hiển thị trong Hình 4a. Chúng ta thấy rằng một lần nữa chúng tôi vượt trội so với kết quả trước đây với biên độ đáng chú ý. Tuy nhiên, lưu ý rằng sơ đồ m = 1% tham vọng hơn chỉ cho phép quên lãng nhẹ nhàng ban đầu ít hơn 1%, hết dung lượng sau khi tác vụ thứ tư được huấn luyện. Như đã đề cập trong Mục 2, một mạng đa đầu hết dung lượng trên lớp ẩn cuối cùng được huấn luyện giống như học chuyển giao lớp cuối cùng, tức là tất cả các trọng số trước đó được cố định và một đầu mới được huấn luyện. Chúng ta nhận thấy rằng sau khi dung lượng mô hình bị cạn kiệt, hiệu suất của sơ đồ m = 1% giảm mạnh, cho thấy sự cần thiết cho các neuron mới được huấn luyện trong lõi của mạng. Sơ đồ quên lãng vừa phải m = 2%, tuy nhiên, duy trì hiệu suất cao trong suốt tất cả các tác vụ và không hết dung lượng cho đến khi tác vụ cuối cùng được huấn luyện.

Lưu ý rằng mặc dù chúng tôi vượt trội so với các phương pháp trước đây, cấu trúc hẹp của mạng này không phù hợp cho mục đích của chúng tôi. Một mạng lý tưởng cho phương pháp của chúng tôi sẽ có dung lượng tham số hóa quá mức đều đặn ở tất cả các lớp của cấu trúc nhưng với mạng này, 95% tham số được tập trung trong lớp dày đặc theo sau các tích chập. Hơn nữa, việc sử dụng 3 lớp dropout không thuận lợi nhất cho độ thưa thớt cấu trúc. Do đó chúng tôi mong đợi mạng sẽ lấp đầy rất nhanh trong quá trình huấn luyện. Hình 4b cho thấy việc sử dụng dung lượng mạng trên mỗi tác vụ cho sơ đồ quên lãng vừa phải m = 1% trung bình qua 5 lần chạy. Chú ý rằng chỉ riêng tác vụ đầu tiên gần như lấp đầy toàn bộ dung lượng của lớp tích chập thứ nhất và thứ hai, để lại ít chỗ cho các kênh tích chập mới được học trong các tác vụ tương lai. Thực tế là ngay cả với cấu trúc không mong muốn này chúng tôi vẫn vượt trội so với các phương pháp trước đây là đáng ngạc nhiên và là một chỉ báo rằng một lượng rất lớn học chuyển giao đang diễn ra.

Trong những gì sau đây, chúng tôi xem xét hai biến thể trong cách tiếp cận của chúng tôi đối với vấn đề này: đầu tiên với một sơ đồ làm thưa thớt hơi nâng cao hơn và thứ hai với một mạng đầu đơn có độ rộng lớn hơn nhiều.

CLNP + tinh chỉnh. Trong tài liệu làm thưa thớt, sau khi cắt tỉa các trọng số và neuron dư thừa, thường thực hành tinh chỉnh các trọng số còn lại của mạng và lặp lại quá trình này cho đến khi đạt được độ thưa thớt mong muốn. Trong bài báo này chúng tôi đã chọn thực hiện một lần lặp của quá trình này và cũng bỏ qua giai đoạn tinh chỉnh để đơn giản và cũng để kết quả của chúng tôi có thể so sánh trực tiếp với công trình trước đây. Bây giờ chúng tôi xem xét tiềm năng của các cách tiếp cận học liên tục dựa trên nén cho một biến thể hơi nâng cao hơn của sơ đồ làm thưa thớt của chúng tôi. Một cách rõ ràng, sau khi huấn luyện trên bất kỳ tác vụ nào, chúng tôi vẫn thực hiện một lần lặp cắt tỉa neuron nhưng lần này với biên độ quên lãng nhẹ nhàng lớn hơn là m = 4% và sau đó chúng tôi tinh chỉnh các trọng số còn lại của mạng bằng cách huấn luyện lại trên cùng tác vụ trong 20 epoch với tỷ lệ học lr = 10^-4 và bộ điều chỉnh trọng số L1 λ = 5×10^-5. Kết quả của phương pháp này được đưa ra trong Hình 4a dưới 'CLNP m= 4% + FT'. Chúng ta thấy rằng ở đây gần như không có quên lãng thảm khốc nào trên tác vụ đầu tiên (nếu có gì mô hình thậm chí còn hoạt động tốt hơn sau khi cắt tỉa và huấn luyện lại như đã được báo cáo trong tài liệu độ thưa thớt trước đây [7,11]). Các tác vụ còn lại cũng nhận được một sự thúc đẩy đáng kể từ phương pháp làm thưa thớt cải thiện này.

Mạng đầu đơn rộng. Để hiểu sâu hơn về sự tương tác của học chuyển giao và độ rộng mạng trong các mạng có độ thưa thớt neural dựa trên kích hoạt, chúng tôi cũng huấn luyện một mạng tích chập hoàn toàn rộng hơn nhiều trên cùng tác vụ (Bảng 3). Lần này chúng tôi sử dụng cấu trúc đầu đơn làm cho tác vụ thách thức hơn vì dung lượng tổng cố định của mạng. Chúng tôi cũng sử dụng một sơ đồ huấn luyện hơi khác, sử dụng một tập xác thực riêng bao gồm 10% mẫu huấn luyện để tìm các siêu tham số tối ưu cho mỗi tác vụ và để dừng sớm. Chúng tôi chạy thí nghiệm 5 lần và báo cáo trung bình và độ lệch chuẩn của độ chính xác kiểm tra sau khi tất cả các tác vụ đã được huấn luyện.

Mạng rộng hơn trong thí nghiệm này có khả năng huấn luyện 10 tác vụ (tức là CIFAR-10 cộng 9 trong số 10 tác vụ CIFAR-100) trước khi cạn kiệt lớp ẩn cuối cùng của nó. Không giống như các cấu trúc đa đầu nơi một lớp ẩn cuối cùng cạn kiệt dẫn đến học chuyển giao ngây thơ trên các tác vụ mới, đối với các cấu trúc đầu đơn, một lớp ẩn cuối cùng cạn kiệt đơn giản là không có kết nối tự do nào đến đầu ra và mạng hoàn toàn cố định. Hình 5a cho thấy kết quả của thí nghiệm này. Để so sánh chúng tôi cũng đã cung cấp kết quả của huấn luyện đa tác vụ và huấn luyện mỗi tác vụ riêng lẻ từ đầu. Để không thiên vị các lựa chọn biên độ quên lãng nhẹ nhàng của chúng tôi, các tính toán huấn luyện đa tác vụ và huấn luyện riêng lẻ chỉ được thực hiện sau khi kết quả CLNP được hoàn thành. Chi tiết của huấn luyện đa tác vụ được đưa ra trong phần tài liệu bổ sung.

Việc sử dụng dung lượng neuron trung bình trên mỗi tác vụ được đưa ra bởi Hình 5b. Có một số đặc điểm thú vị trong biểu đồ này. Đầu tiên lưu ý rằng tương tự như biểu đồ sử dụng MNIST đầu đơn, các tác vụ số 1-7 mỗi tác vụ đại khái chiếm cùng số lượng neuron của lớp ẩn cuối cùng. Điều này một lần nữa như mong đợi vì các neuron của lớp này được kết nối với lớp đầu ra và không được tái sử dụng để tránh can thiệp. Đến khi chúng ta đến tác vụ 8, hơn 85% dung lượng của lớp này bị cạn kiệt. Điều này trực tiếp ảnh hưởng đến hiệu suất của mạng có thể được thấy dưới dạng độ chính xác kiểm tra giảm cả so với kết quả từ huấn luyện đa tác vụ và huấn luyện riêng lẻ từ đầu.

Có lẽ quan sát thú vị nhất trong việc huấn luyện mạng rộng là trong số lượng kênh mới được học ở mỗi lớp cho mỗi tác vụ liên tiếp. Chú ý rằng lớp tích chập đầu tiên chỉ huấn luyện các kênh mới cho tác vụ 1 và 2. Lớp tích chập thứ hai và thứ ba, tăng trưởng các kênh mới lên đến tác vụ 3 và tác vụ 5 tương ứng. Lớp thứ tư tiếp tục huấn luyện các kênh mới cho đến tác vụ cuối cùng. Thực tế là lớp đầu tiên không tăng trưởng kênh mới nào sau tác vụ thứ hai ngụ ý rằng các đặc trưng được học trong quá trình huấn luyện hai tác vụ đầu tiên được sử dụng đầy đủ và được coi là đủ cho việc huấn luyện các tác vụ tiếp theo. Thực tế rằng tính đầy đủ này xảy ra sau khi huấn luyện nhiều tác vụ hơn cho lớp 2 và 3 là một xác minh về thực tế rằng các đặc trưng được học trong các lớp thấp hơn tổng quát hơn và do đó dễ chuyển giao hơn so với các đặc trưng của các lớp cao hơn được biết là chuyên biệt [19]. Quan sát này ngụ ý rằng các mô hình hy vọng hiệu quả trong học liên tục cần rộng hơn ở các lớp cao hơn để phù hợp với việc thiếu khả năng chuyển giao của các đặc trưng ở những quy mô này.

4 Kết luận
Trong công trình này chúng tôi đã giới thiệu một phương pháp học suốt đời đơn giản và trực quan tận dụng việc tham số hóa quá mức của mạng neural để huấn luyện các tác vụ mới trong các neuron/bộ lọc không hoạt động của mạng mà không gặp phải quên lãng thảm khốc nào trong các tác vụ đã huấn luyện trước đó. Chúng tôi cũng triển khai một cách có kiểm soát về quên lãng nhẹ nhàng bằng cách hy sinh một chút độ chính xác ở cuối việc huấn luyện mỗi tác vụ để lấy lại dung lượng mạng cho việc huấn luyện các tác vụ mới. Chúng tôi đã chỉ ra thực nghiệm rằng phương pháp này dẫn đến kết quả cải thiện đáng chú ý so với các cách tiếp cận trước đây.

Phương pháp luận của chúng tôi cũng đi kèm với chẩn đoán đơn giản về số lượng neuron tự do còn lại cho việc huấn luyện các tác vụ mới. Biểu đồ sử dụng dung lượng mô hình cũng cung cấp thông tin về khả năng chuyển giao và tính đầy đủ của các đặc trưng của các lớp khác nhau. Sử dụng những công cụ chẩn đoán như vậy, chúng ta có thể xác minh khái niệm rằng các đặc trưng được học trong các lớp trước dễ chuyển giao hơn. Chúng ta cũng có thể tận dụng những công cụ chẩn đoán này để xác định bất kỳ lớp nào hết dung lượng sớm, và giải quyết những nút thắt cổ chai này trong mạng bằng cách đơn giản tăng số lượng neuron trong những lớp này khi chuyển sang tác vụ tiếp theo. Bằng cách này, phương pháp của chúng tôi có thể mở rộng hiệu quả để phù hợp với nhiều tác vụ hơn và bù đắp cho các lựa chọn độ rộng mạng không tối ưu.

Điều quan trọng cần lưu ý là thuật toán của chúng tôi phụ thuộc quan trọng vào phương pháp làm thưa thớt được sử dụng. Trong công trình này chúng tôi sử dụng một sơ đồ làm thưa thớt hoạt động neuron dựa trên cắt tỉa neural lặp đơn. Chúng tôi cũng chứng minh rằng việc sử dụng một sơ đồ làm thưa thớt hơi nâng cao hơn, tức là thêm một bước tinh chỉnh sau cắt tỉa có thể dẫn đến kết quả thậm chí tốt hơn. Điều này cho thấy rằng kết quả của chúng tôi, về số lượng tác vụ có thể được học hoặc độ chính xác có thể được giữ trong một cấu trúc mạng cố định, chỉ có thể cải thiện với các phương pháp làm thưa thớt hiệu quả hơn. Chúng tôi hy vọng rằng quan sát này mở ra con đường cho một lớp mới các phương pháp học suốt đời tập trung vào độ thưa thớt neural như một thay thế cho các cách tiếp cận dựa trên độ đàn hồi trọng số hiện tại.

Lời cảm ơn
Chúng tôi muốn cảm ơn Kyle Cranmer và Johann Brehmer cho những thảo luận thú vị và đầu vào. SG được hỗ trợ bởi Học bổng Tiến sĩ James Arthur. MK được hỗ trợ bởi Bộ Năng lượng Hoa Kỳ (DOE) dưới tài trợ DE-AC02-76SF00515 và bởi Học bổng Panofsky SLAC. Công trình này được hỗ trợ một phần bởi NVidia (Dự án: "NVIDIA - NYU Autonomous Driving Collaboration").

A Huấn luyện đa tác vụ trên CIFAR-10/100
Học đa tác vụ, việc huấn luyện đồng thời nhiều tác vụ cùng một lúc, thường là một vấn đề phức tạp. Cần đặc biệt cẩn thận khi các tác vụ khác nhau có độ khó khác nhau hoặc kích thước tập dữ liệu khác nhau. Trong vấn đề CIFAR-10/100 hỗn hợp, tập dữ liệu cho tác vụ đầu tiên lớn gấp mười lần so với các tác vụ khác. Một lựa chọn thực tế quan trọng ảnh hưởng đến hiệu suất tương đối của các tác vụ là cách thực hiện huấn luyện minibatch. Đặc biệt trong một epoch huấn luyện, nếu chúng ta rút từ tất cả các tác vụ một cách không phân biệt, các mẫu của các tập dữ liệu nhỏ hơn hết khi chỉ 10% của tập dữ liệu lớn hơn được nhìn thấy. Trong trường hợp này chúng ta có thể bắt đầu một epoch mới tức là cắt ngắn tập dữ liệu lớn hơn hoặc chúng ta có thể tiếp tục huấn luyện trên tập dữ liệu lớn hơn cho đến khi nó hết. Trong thực tế, lựa chọn này tương đương với việc hy sinh hiệu suất của tác vụ đầu tiên có lợi cho các tác vụ khác hoặc ngược lại. Cho mục đích so sánh với học suốt đời, chúng tôi thực hiện cách tiếp cận thỏa hiệp. Khi huấn luyện tất cả các tác vụ cùng một lúc, chúng tôi lấy mỗi batch bao gồm 50 mẫu từ tác vụ 1 và 10 mẫu từ mỗi tác vụ khác, tổng kích thước batch thêm lên 140. Sau đó chúng tôi bắt đầu một epoch mới khi các tập dữ liệu nhỏ hơn hết. Bằng cách này, một epoch mới được bắt đầu khi chỉ 50% của tập dữ liệu lớn của tác vụ 1 được nhìn thấy. Lưu ý rằng số lượng mẫu tương đối trong mỗi tác vụ thiên vị mạng hướng về một tác vụ hay tác vụ khác, do đó việc chọn số lượng mẫu thậm chí cao hơn của tác vụ đầu tiên sẽ một lần nữa dẫn đến việc hy sinh độ chính xác trên các tác vụ khác. Chúng tôi thực hiện lựa chọn tỷ lệ 5 so với 1 hoàn toàn như một trung điểm. Có thể các lựa chọn khác có thể dẫn đến hiệu suất tổng thể tốt hơn.

Để thích ứng mô hình đầu đơn của Bảng 3 cho huấn luyện đa tác vụ, chúng tôi phân vùng các neuron của lớp ẩn cuối cùng thành 10 phần bằng nhau tạo thành "đầu" của 10 tác vụ khác nhau. Chúng tôi chọn huấn luyện chỉ trên 10 trong số 11 tác vụ để cung cấp so sánh công bằng vì thuật toán học liên tục của chúng tôi cạn kiệt mạng sau 10 tác vụ. Chúng tôi huấn luyện sử dụng 120 epoch sử dụng bộ tối ưu hóa Adam với tỷ lệ học 0.001 và lịch tỷ lệ học với cột mốc ở 50 và 90 epoch và γ = 0.05. Chúng tôi sử dụng cùng tập xác thực riêng như học liên tục và học riêng lẻ để dừng sớm. Chúng tôi chạy huấn luyện 5 lần và báo cáo trung bình và độ lệch chuẩn của độ chính xác kiểm tra trong Hình 5a.

Tài liệu tham khảo
[1] Brian Cheung, Alex Terekhov, Yubei Chen, Pulkit Agrawal, và Bruno Olshausen. 2019. Chồng lấp nhiều mô hình thành một. (Tháng 2 năm 2019). arXiv:cs.LG/1902.05522

[2] C. Fernando, D. Banarse, C. Blundell, Y. Zwols, D. Ha, A. A. Rusu, A. Pritzel, và D. Wierstra. 2017. PathNet: Evolution Channels Gradient Descent in Super Neural Networks. (Tháng 1 năm 2017). arXiv:1701.08734

[3] Robert M. French. 1991. Using Semi-Distributed Representations to Overcome Catastrophic Forgetting in Connectionist Networks.

[4] Trevor Gale, Erich Elsen, và Sara Hooker. 2019. The State of Sparsity in Deep Neural Networks. (Tháng 2 năm 2019). arXiv:cs.LG/1902.09574

[5] Xavier Glorot, Antoine Bordes, và Yoshua Bengio. 2011. Deep sparse rectifier neural networks. Trong Proceedings of the fourteenth international conference on artificial intelligence and statistics. 315–323.

[6] Lu Hou và James T. Kwok. 2018. Power Law in Sparsified Deep Neural Networks. CoRR (2018). arXiv:1805.01891 http://arxiv.org/abs/1805.01891

[7] Hengyuan Hu, Rui Peng, Yu-Wing Tai, và Chi-Keung Tang. 2016. Network Trimming: A Data-Driven Neuron Pruning Approach towards Efficient Deep Architectures. (Tháng 7 năm 2016). arXiv:cs.NE/1607.03250

[8] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins, A. A. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska, D. Hassabis, C. Clopath, D. Kumaran, và R. Hadsell. 2016. Overcoming catastrophic forgetting in neural networks. (Tháng 12 năm 2016). arXiv:cs.LG/1612.00796

[9] Alex Krizhevsky, Vinod Nair, và Geoffrey Hinton. 2009. CIFAR-10 (Canadian Institute for Advanced Research). (2009). http://www.cs.toronto.edu/~kriz/cifar.html

[10] Yann LeCun và Corinna Cortes. 2010. MNIST handwritten digit database. http://yann.lecun.com/exdb/mnist/. (2010). http://yann.lecun.com/exdb/mnist/

[11] Yann LeCun, John S. Denker, và Sara A. Solla. 1989. Optimal Brain Damage. Trong NIPS.

[12] Jeongtae Lee, Jaehong Yoon, Eunho Yang, và Sung Ju Hwang. 2017. Lifelong Learning with Dynamically Expandable Networks. CoRR (2017). arXiv:1708.01547 http://arxiv.org/abs/1708.01547

[13] Jian-Hao Luo, Jianxin Wu, và Weiyao Lin. 2017. ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression. (Tháng 7 năm 2017). arXiv:cs.CV/1707.06342

[14] Behnam Neyshabur, Zhiyuan Li, Srinadh Bhojanapalli, Yann LeCun, và Nathan Srebro. 2018. Towards Understanding the Role of Over-Parametrization in Generalization of Neural Networks. CoRR abs/1805.12076 (2018). arXiv:1805.12076 http://arxiv.org/abs/1805.12076

[15] A. A. Rusu, N. C. Rabinowitz, G. Desjardins, H. Soyer, J. Kirkpatrick, K. Kavukcuoglu, R. Pascanu, và R. Hadsell. 2016. Progressive Neural Networks. (Tháng 6 năm 2016). arXiv:cs.LG/1606.04671

[16] S. Saxena và J. Verbeek. 2016. Convolutional Neural Fabrics. (Tháng 6 năm 2016). arXiv:cs.CV/1606.02492

[17] N. Shazeer, A. Mirhoseini, K. Maziarz, A. Davis, Q. Le, G. Hinton, và J. Dean. 2017. Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer. (Tháng 1 năm 2017). arXiv:cs.LG/1701.06538

[18] Yi Sun, Xiaogang Wang, và Xiaoou Tang. 2015. Sparsifying Neural Network Connections for Face Recognition. CoRR abs/1512.01891 (2015). arXiv:1512.01891 http://arxiv.org/abs/1512.01891

[19] Jason Yosinski, Jeff Clune, Yoshua Bengio, và Hod Lipson. 2014. How transferable are features in deep neural networks? Trong Advances in Neural Information Processing Systems 27, Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, và K. Q. Weinberger (Eds.). Curran Associates, Inc., 3320–3328. http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf

[20] F. Zenke, B. Poole, và S. Ganguli. 2017. Continual learning with intelligent synapses. Proceedings of International Conference on Machine Learning (ICML) (2017).

Được xuất bản trong Transactions on Machine Learning Research (09/2024)
Vượt qua Khoảng cách Ổn định trong Học Liên tục
Md Yousuf Harun mh1023@rit.edu
Viện Công nghệ Rochester
Christopher Kanan ckanan@cs.rochester.edu
Đại học Rochester
Được đánh giá trên OpenReview: https: // openreview. net/ forum? id= o2wEfwUOma
Tóm tắt
Các mạng nơ-ron sâu (DNN) được đào tạo trước đang được triển khai rộng rãi bởi ngành công nghiệp để đưa ra quyết định kinh doanh và phục vụ người dùng; tuy nhiên, một vấn đề lớn là sự suy giảm mô hình, khi các dự đoán của DNN trở nên sai lệch hơn theo thời gian, dẫn đến mất doanh thu hoặc người dùng không hài lòng. Để giảm thiểu sự suy giảm mô hình, các DNN được đào tạo lại từ đầu sử dụng dữ liệu cũ và mới. Điều này rất tốn kém về mặt tính toán, vì vậy việc đào tạo lại chỉ xảy ra một khi hiệu suất giảm đáng kể. Ở đây, chúng tôi nghiên cứu cách học liên tục (CL) có thể khắc phục sự suy giảm mô hình trong các DNN được đào tạo trước lớn và giảm đáng kể chi phí tính toán để duy trì các DNN cập nhật. Chúng tôi xác định "khoảng cách ổn định" là một trở ngại lớn trong bối cảnh của chúng tôi. Khoảng cách ổn định đề cập đến một hiện tượng khi việc học dữ liệu mới gây ra sự sụt giảm lớn trong hiệu suất cho các nhiệm vụ trước đó trước khi các phương pháp giảm thiểu CL cuối cùng bù đắp cho sự sụt giảm này. Chúng tôi kiểm tra hai giả thuyết để điều tra các yếu tố ảnh hưởng đến khoảng cách ổn định và xác định một phương pháp giảm đáng kể khoảng cách này. Trong các thí nghiệm quy mô lớn cho cả phân phối CL dễ và khó (ví dụ: học tăng dần theo lớp), chúng tôi chứng minh rằng phương pháp của chúng tôi giảm khoảng cách ổn định và tăng đáng kể hiệu quả tính toán. Công việc của chúng tôi điều chỉnh CL với các mục tiêu của thiết lập sản xuất, nơi CL được cần thiết cho nhiều ứng dụng.

Giới thiệu
Các mạng nơ-ron sâu (DNN) hiện đã được triển khai rộng rãi trong ngành công nghiệp; tuy nhiên, một vấn đề lớn đối với nhiều công ty là sự suy giảm mô hình, khi hiệu suất dự đoán của DNN giảm theo thời gian (Zhou et al., 2020). Điều này chủ yếu do sự thay đổi khái niệm (Tsymbal, 2004; Gama et al., 2014; Lu et al., 2018), khi bản chất của các biến mục tiêu được dự đoán thay đổi theo thời gian, ví dụ, đối với một bộ phân loại, điều này sẽ tương ứng với việc giới thiệu các danh mục mới hoặc mở rộng định nghĩa các lớp riêng lẻ. Khi phát hiện sự suy giảm mô hình, hầu hết các công ty sử dụng đào tạo lại ngoại tuyến (tức là đào tạo theo lô hoặc đào tạo chung), trong đó một mô hình được đào tạo lại từ đầu với sự kết hợp của dữ liệu cũ và mới (Egg, 2021). Điều này rất tốn kém, vì vậy việc giám sát mô hình được sử dụng để xác định khi nào cần đào tạo ngoại tuyến (Mäkinen et al., 2021). Bất chấp việc đào tạo ngoại tuyến thường xuyên, các mô hình được triển khai vẫn bị giảm độ chính xác lên đến 40% (Mallick et al., 2022).

Học liên tục (CL) là một giải pháp đầy hứa hẹn để ngăn chặn sự suy giảm mô hình (Huyen, 2022a;b; Jain & Shenoy, 2022), trong đó trong CL mục tiêu là cập nhật DNN một cách tăng dần với dữ liệu mới trong khi bảo tồn kiến thức trước đó (Parisi et al., 2019). Trong một nghiên cứu của GrubHub, điều này cho phép họ tránh sự suy giảm mô hình và cung cấp giảm 45× chi phí đào tạo so với đào tạo ngoại tuyến hàng ngày (Egg, 2021). Để làm điều này, GrubHub đã sử dụng cập nhật trực tuyến trên các mẫu mới. Cập nhật trực tuyến có thể gây ra việc quên thảm khốc kiến thức trước đó do sự thay đổi khái niệm (McCloskey & Cohen, 1989), nhưng do sở thích thay đổi nhanh chóng của khách hàng, việc quên kiến thức trước đó là mong muốn. Tuy nhiên, việc quên thảm khốc là không thể chấp nhận đối với nhiều ứng dụng công nghiệp vì kiến thức trước đó phải được duy trì. Để CL được ngành công nghiệp chấp nhận rộng rãi, nó phải được chứng minh là có thể ức chế sự suy giảm mô hình trong các mô hình được đào tạo trước, cung cấp lợi ích tính toán đáng kể, hoạt động với các thay đổi tùy ý trong khái niệm, và lý tưởng là hiệu quả như đào tạo ngoại tuyến. Phần lớn các thuật toán CL lệch khỏi các tiêu chí này, tức là chúng áp đặt các ràng buộc về lưu trữ không liên quan đến các vấn đề công nghiệp, tránh né các mô hình được đào tạo trước, hoạt động kém hơn so với đào tạo lại ngoại tuyến, thiết kế thuật toán chỉ cho một phân phối thay đổi khái niệm duy nhất (ví dụ: học tăng dần theo lớp), và/hoặc tốn kém hơn về mặt tính toán so với đào tạo lại ngoại tuyến (Harun et al., 2023a;b; Prabhu et al., 2023b;a; Verwimp et al., 2024; Lee et al., 2023).

Ở đây, chúng tôi nghiên cứu việc sử dụng CL để giảm thiểu sự suy giảm mô hình và giới thiệu các khái niệm mới vào DNN. Ban đầu, chúng tôi nghiên cứu cập nhật các mô hình được đào tạo trước ImageNet-1K với các lớp mới trong các thí nghiệm học tăng dần theo lớp (CIL). Chúng tôi sử dụng diễn tập tích lũy có ràng buộc tính toán để giảm thiểu việc quên, trong đó diễn tập bao gồm việc trộn các mẫu cũ với các mẫu mới để ngăn chặn việc quên, và diễn tập tích lũy thực hiện điều này bằng cách sử dụng tất cả các mẫu đã quan sát trước đó. Các ràng buộc tính toán được thực thi bằng cách giới hạn tổng số cập nhật diễn tập được phép. Tuy nhiên, chúng tôi thấy rằng khoảng cách ổn định của CL là một trở ngại lớn đối với mục tiêu của chúng tôi (De Lange et al., 2023), như được hiển thị trong Hình 1.

Khoảng cách ổn định đề cập đến quan sát rằng khi một mô hình được cập nhật trên dữ liệu mới, độ chính xác trên các lớp đã quan sát trong các lô trước đó giảm mạnh trước khi diễn tập hoặc các phương pháp CL khác dần dần khôi phục hiệu suất cũ. Trong thiết lập CIL điển hình mà chúng tôi áp dụng, các mẫu đến theo lô trong đó mỗi lô chỉ chứa các lớp trong lô đó. Như thấy trong Hình 1, hiệu suất giảm mạnh khi học một lô mới trong các phiên diễn tập và không phục hồi hoàn toàn. Khoảng cách ổn định có thể được coi là việc quên tạm thời do giới thiệu một nhiệm vụ mới. Thông thường, việc quên thảm khốc đề cập đến sự sụt giảm hiệu suất được quan sát ở cuối việc học các nhiệm vụ mới (tại các chuyển đổi nhiệm vụ). Ngược lại, khoảng cách ổn định đề cập đến sự sụt giảm hiệu suất được quan sát qua các bước học (giữa các chuyển đổi nhiệm vụ). Trong công việc của chúng tôi, chúng tôi tìm cách hiểu tại sao khoảng cách ổn định xảy ra trong kịch bản của chúng tôi và cách giảm thiểu nó một cách hiệu quả, cho phép sử dụng ít cập nhật diễn tập hơn trong khi đạt được độ chính xác cao hơn.

Chúng tôi kiểm tra hai giả thuyết để xem xét khoảng cách ổn định trong CIL với DNN được đào tạo trước:
1. Khoảng cách ổn định được tăng một phần do có mất mát lớn ở lớp đầu ra cho các lớp mới. Để kiểm tra giả thuyết này, chúng tôi nghiên cứu hai phương pháp để giảm thiểu mất mát lớn ở lớp đầu ra cho các lớp mới. Phương pháp đầu tiên là khởi tạo lớp đầu ra theo cách tiếp cận dựa trên dữ liệu thay vì khởi tạo ngẫu nhiên các đơn vị đầu ra chịu trách nhiệm cho các lớp mới. Phương pháp thứ hai là một dạng đặc biệt của mục tiêu mềm cho mạng, thay vì các mục tiêu cứng điển hình được sử dụng cho mạng, trong đó các mục tiêu mềm này được thiết kế để cải thiện hiệu suất cho các lớp mới trong khi làm nhiễu tối thiểu những lớp khác.

2. Khoảng cách ổn định được tăng một phần do tính dẻo mạng quá mức. Chúng tôi kiểm tra giả thuyết này bằng cách kiểm soát mức độ dẻo trong các lớp mạng theo cách động. Đối với các lớp ẩn, chúng tôi kiểm tra giả thuyết này bằng cách sử dụng LoRA (Hu et al., 2021), làm giảm số lượng tham số có thể đào tạo trong các lớp ẩn của mạng. Đối với các phương pháp diễn tập, sau mỗi phiên diễn tập, các trọng số này được gộp vào trọng số mạng ban đầu. Đối với lớp đầu ra, chúng tôi kiểm tra giả thuyết này bằng cách đóng băng các đơn vị đầu ra cho các lớp đã thấy trong các lô trước đó trong quá trình diễn tập.

Trong các thí nghiệm của chúng tôi, chúng tôi thấy rằng cả hai giả thuyết đều được hỗ trợ. Điều này dẫn chúng tôi đến việc phát triển một phương pháp kết hợp giảm đáng kể khoảng cách ổn định cho cả CIL và các phân phối khác.

Bài báo này đóng góp các đóng góp chính sau đây:
1. Chúng tôi là những người đầu tiên nghiên cứu vượt qua khoảng cách ổn định. Chúng tôi kiểm tra các giả thuyết nói trên trong CIL và phát hiện ra rằng cả hai đều đóng một vai trò quan trọng. Chúng tôi đề xuất các thước đo mới để đo lường khoảng cách ổn định, dẻo và kiến thức liên tục.

2. Chúng tôi là những người đầu tiên nghiên cứu duy trì hoặc cải thiện hiệu suất trên ImageNet-1K trong khi học các lớp bổ sung, một khía cạnh không được điều tra trong nghiên cứu trước đây sử dụng các backbone được đào tạo trước ImageNet-1K (Wang et al., 2022b;a; Smith et al., 2023; Gao et al., 2023; McDonnell et al., 2024). Chúng tôi nghiên cứu điều này cho cả phân phối CIL và IID (độc lập và phân phối đồng nhất). Các thí nghiệm này được thực hiện bằng cách kết hợp ImageNet-1K với Places365 hoặc Places365-LT (tổng cộng 1365 lớp).

3. Chúng tôi phát triển một phương pháp giảm đáng kể khoảng cách ổn định và cải thiện đáng kể hiệu quả tính toán. Phương pháp của chúng tôi yêu cầu ít cập nhật mạng hơn 16.7× so với mô hình được đào tạo chung (cận trên). Về mặt TFLOP, phương pháp của chúng tôi cung cấp tăng tốc 31.9× (xem Hình 5). Đối với phân phối CL IID, phương pháp này đạt được chuyển giao ngược, trong đó việc học tập dữ liệu mới giúp cải thiện độ chính xác ImageNet-1K.

4. Chúng tôi cho thấy rằng phương pháp của chúng tôi hiệu quả và chúng tôi tích hợp nó vào các phương pháp CL hiện có. Cụ thể, nó hoạt động tốt kết hợp với các phương pháp diễn tập Vanilla Rehearsal, DERpp, GDumb và REMIND cũng như phương pháp không diễn tập LwF.

Nền tảng
Nhiều phương pháp đã được đề xuất để học liên tục từ các tập dữ liệu không dừng trong học liên tục (xem Zhou et al. (2023) để xem xét). Các phương pháp này có thể được chia thành ba loại: 1) Các phương pháp dựa trên diễn tập lưu trữ hoặc tái tạo một tập con dữ liệu cũ để diễn tập cùng với dữ liệu mới trong khi học một lô mới (Chaudhry et al., 2019; Hou et al., 2019; Rebuffi et al., 2017; Wu et al., 2019), 2) Các phương pháp dựa trên chính quy hóa ràng buộc cập nhật trọng số bằng cách thêm chính quy hóa bổ sung trong hàm mất mát (Aljundi et al., 2018; Chaudhry et al., 2018; Dhar et al., 2019; Kirkpatrick et al., 2017), và 3) Các phương pháp dựa trên cô lập tham số phân bổ nhiều bộ tham số hoặc nhiều bản sao của mô hình cho các lô tăng dần khác nhau (Douillard et al., 2021; Yan et al., 2021; Yoon et al., 2020). Vì các phương pháp cô lập tham số không cho phép chuyển giao ngược, khoảng cách ổn định không áp dụng cho chúng (De Lange et al., 2023).

Trong khi hầu hết cộng đồng nghiên cứu CL đã tập trung vào việc giảm thiểu việc quên thảm khốc (McCloskey & Cohen, 1989), có một khối tài liệu ngày càng tăng chứng minh khả năng của nó trong việc giảm lượng tính toán cần thiết để cập nhật mạng (Ghunaim et al., 2023; Harun et al., 2023a;b;c; Prabhu et al., 2023b; Verwimp et al., 2024). Gần đây, một trở ngại lớn đối với mục tiêu này đã được xác định trong CL: Khoảng cách ổn định (De Lange et al., 2023). Tuy nhiên, nó đã được nghiên cứu trên các tập dữ liệu nhỏ, ví dụ CIFAR, sử dụng DNN được khởi tạo ngẫu nhiên. Thiết lập này không phù hợp với việc nghiên cứu sự suy giảm mô hình trong các thiết lập công nghiệp bao gồm dòng dữ liệu nhiều lớp và bảo tồn hiệu suất trong DNN được đào tạo trước lớn.

Theo truyền thống, CL đào tạo từ đầu sẽ bắt đầu với DNN được khởi tạo ngẫu nhiên mà không có đào tạo trước. Với sự phổ biến của các mô hình được đào tạo trước lớn, nghiên cứu CL gần đây đã bắt đầu tích hợp các mô hình này vào quá trình học. Điều này đã dẫn đến số lượng ngày càng tăng các công trình CL sử dụng các mô hình transformer thị giác (ViT) được đào tạo trước lớn, đã được đào tạo trước trên ImageNet-1K hoặc ImageNet-21K (Wang et al., 2022b;a; Smith et al., 2023; Gao et al., 2023; McDonnell et al., 2024). Hơn nữa, nhiều công trình trước đây sử dụng đào tạo trước cho CL (Belouadah & Popescu, 2019; Hou et al., 2019; Castro et al., 2018; Rebuffi et al., 2017; Hayes et al., 2020; Douillard et al., 2020; Harun et al., 2023b) và nhấn mạnh tầm quan trọng của đào tạo trước trong bối cảnh CL (Lee et al., 2023; Mehta et al., 2023; Ostapenko et al., 2022; Ramasesh et al., 2021b; Gallardo et al., 2021). Tuy nhiên, như được chứng minh trong một số công trình (Wang et al., 2022a; Mirzadeh et al., 2022), việc sử dụng các mô hình được đào tạo trước không một cách ngây thơ tăng cường hiệu suất CL và việc tận dụng hiệu quả các mô hình được đào tạo trước cho CL vẫn là một câu hỏi mở. Trong công việc này, chúng tôi chủ yếu tập trung vào việc vượt qua khoảng cách ổn định trong CL với các mô hình được đào tạo trước.

Hầu như tất cả các phương pháp CL đều tập trung vào vấn đề quên thảm khốc với các đánh giá xảy ra trên các chuyển đổi lô hoặc nhiệm vụ rời rạc (Hayes et al., 2018; Chaudhry et al., 2018) và không thể nắm bắt khoảng cách ổn định xảy ra ngay sau khi một nhiệm vụ mới được giới thiệu (Hình 1). De Lange et al. (2023) chứng minh khoảng cách ổn định xảy ra cho nhiều phương pháp CL, bao gồm diễn tập (Chaudhry et al., 2019), GEM (Lopez-Paz & Ranzato, 2017), EWC (Kirkpatrick et al., 2017)) và LwF (Li & Hoiem, 2017). Để định lượng khoảng cách ổn định, họ đề xuất các thước đo đánh giá liên tục dựa trên hiệu suất trường hợp xấu nhất tức là sự sụt giảm lớn nhất trong độ chính xác trên các lô cũ. Tuy nhiên, các thước đo của họ không cho phép so sánh các mô hình CL khác nhau vì chúng chỉ định lượng sự sụt giảm lớn nhất so với hiệu suất tốt nhất của cùng một mô hình, do đó không thể định lượng tác động của các phương pháp đào tạo khác nhau nhằm giảm thiểu khoảng cách ổn định. Chúng tôi giải quyết hạn chế này bằng cách sử dụng các thước đo mới được chuẩn hóa so với cận trên chung được đào tạo chung (xem Phần 3.2). Chúng tôi cũng minh họa hiện tượng này bằng các ví dụ tổng hợp trong Phụ lục F để xây dựng trực giác. Chúng tôi nghiên cứu vượt qua khoảng cách ổn định với cả phương pháp diễn tập và không diễn tập, với trọng tâm vào diễn tập do tính hiệu quả của nó (van de Ven et al., 2022; Zhou et al., 2023).

Giao thức Học Liên tục
Trong công việc này, chúng tôi cố gắng điều chỉnh CL với thiết lập công nghiệp, trong đó CL cập nhật kiến thức trong các mô hình được đào tạo trước để ngăn chặn sự suy giảm mô hình khi các khái niệm mới được giới thiệu trong khi bảo tồn hiệu suất trên các lớp ban đầu. Tương tự, vì ngành công nghiệp yêu cầu duy trì độ chính xác cao, chúng tôi tập trung vào CL dựa trên diễn tập; tuy nhiên, chúng tôi chứng minh rằng các chiến lược giảm thiểu của chúng tôi có thể được sử dụng cho các phương pháp không diễn tập sử dụng chính quy hóa và chưng cất kiến thức. Trong phần này, chúng tôi chính thức hóa khung CL của mình và định nghĩa các thước đo chúng tôi sử dụng để đo lường khoảng cách ổn định.

Thiết lập Học Liên tục Chính thức
Để điều chỉnh công việc của chúng tôi với việc giải quyết sự suy giảm mô hình, chúng tôi giả định CL bắt đầu với một mô hình được đào tạo trước có khả năng phân loại K chiều. Mục tiêu là kết hợp dữ liệu mới, có thể có các lớp bổ sung, vào mô hình, trong khi bảo tồn hoặc cải thiện hiệu suất trên K lớp ban đầu. Với mục đích này, chúng tôi sử dụng các mô hình được đào tạo trước ImageNet-1K (K = 1000). Trong khi các mô hình được đào tạo trước ImageNet-1K thường được sử dụng trong các hệ thống CL, các nghiên cứu trước đây không cố gắng duy trì hoặc đo lường hiệu suất trên chính tập dữ liệu ImageNet-1K (Wang et al., 2022b;a; Smith et al., 2023; Gao et al., 2023; McDonnell et al., 2024). Nghiên cứu của chúng tôi độc đáo khám phá khía cạnh này trong CL. Sau khi triển khai, mô hình được đào tạo trước được tiếp xúc với một chuỗi các lô dữ liệu qua N−1 phiên học, tức là {S2,···,SN}, trong đó S1 là dữ liệu được sử dụng để đào tạo trước. Phiên thứ j bao gồm một lô mj mẫu đào tạo được gán nhãn, tức là Sj={(xj,yj)i}mj i=1, trong đó xj là một thể hiện của danh mục yj∈Yj và Yj là không gian nhãn của nhiệm vụ j. Trong thiết lập CIL, mỗi Sj chứa các lớp không chồng lấp, tức là Yj∩Yj′=∅ với j̸=j′. Tổng số mẫu trong toàn bộ chuỗi là M=∑N j=1mj. Khi học lô mới Sj, người học có thể truy cập Sj và bất kỳ dữ liệu được lưu trữ nào từ các lô trước đó S1:j−1. Trong thời gian kiểm tra, người học được đánh giá trên dữ liệu kiểm tra từ tất cả các lớp đã thấy, Yj=Y1∪···Yj. Định danh lô (hoặc nhiệm vụ) j không thể được khai thác trong thời gian kiểm tra.

Để thích ứng hiệu quả với dòng dữ liệu quy mô lớn trong thiết lập thế giới thực, hệ thống CL không nên tăng chi phí tính toán theo thời gian. Đối với tất cả các phiên học j sau đào tạo trước, nó được cung cấp một ngân sách tính toán cố định B tương ứng với số lượng cập nhật mô hình SGD tức là B=U×b, trong đó U và b biểu thị số lượng lần lặp đào tạo và số lượng mẫu đào tạo trên mỗi lần lặp tương ứng.

Đo lường Khoảng cách Ổn định
Các thước đo CL phổ biến tập trung vào việc đo lường hiệu suất sau khi mỗi Sj được học. Chúng không cho phép phân tích chi tiết cho a) bảo tồn kiến thức cũ, b) thu thập kiến thức mới và c) cân bằng cả hai trong quá trình đào tạo. Để nghiên cứu khoảng cách ổn định theo cách cho phép chúng tôi kiểm tra các giả thuyết của mình trên các mô hình được đào tạo với các chiến lược khác nhau, chúng tôi đã tạo ra các thước đo đo lường các tiêu chí này: 1) khoảng cách ổn định, S∆ (tiêu chí a) 2) khoảng cách dẻo, P∆ (tiêu chí b), và 3) khoảng cách kiến thức liên tục, CK∆ (tiêu chí c). Mỗi thước đo hỏi: Người học thiếu bao nhiều hiệu suất trên dữ liệu đã quan sát trước đó, đã quan sát gần đây, hoặc tất cả dữ liệu đã quan sát so với mô hình chung (cận trên) khi học dữ liệu mới?

Đối với phiên học thứ j, chúng tôi ký hiệu các tập đánh giá trên dữ liệu cũ, mới và tất cả dữ liệu đã thấy bằng E1:j−1, Ej và E1:j, tương ứng. Ai là độ chính xác của mô hình hiện tại θi trên tập đánh giá lô E tại lần lặp đào tạo i, và L là tổng số lần lặp. Ajoint là độ chính xác cuối cùng của mô hình chung (θjoint) được đào tạo chung trên tất cả dữ liệu. Chúng tôi định nghĩa khoảng cách ổn định là

S∆= 1−1/(N−1) ∑N j=2 Ωold j; trong đó Ωold j=1/L ∑L i=1 Ai(E1:j−1,θi)/Ajoint(E1:j−1,θjoint). (1)

Tương tự, khoảng cách dẻo là

P∆= 1−1/(N−1) ∑N j=2 Ωnew j; trong đó Ωnew j=1/L ∑L i=1 Ai(Ej,θi)/Abest(Ej,θbest), (2)

trong đó Abest biểu thị độ chính xác tốt nhất đạt được bởi mô hình CL tốt nhất (θbest) tại bất kỳ thời điểm nào trong quá trình đào tạo. Và cuối cùng, chúng tôi định nghĩa khoảng cách kiến thức liên tục là

CK∆= 1−1/(N−1) ∑N j=2 Ωall j; trong đó Ωall j=1/L ∑L i=1 Ai(E1:j,θi)/Ajoint(E1:j,θjoint). (3)

Ωj ghi lại hiệu suất CL so với Ajoint hoặc Abest. Sau khi học tất cả N lô, điểm Ωj được tính trung bình để chỉ ra tăng hiệu suất trung bình. Lô đầu tiên được loại trừ vì nó được sử dụng để đào tạo trước. Đối với tất cả các thước đo, S∆, P∆ và CK∆ nhỏ hơn cho thấy hiệu suất tốt hơn. Khi Ai=Ajoint và Ai=Abest cho tất cả L lần lặp, S∆, P∆ và CK∆ trở thành không điều này là mong muốn. Giá trị âm có nghĩa là chuyển giao kiến thức giữa các lô mới và cũ, điều này là mong muốn. Các thước đo này áp dụng cho CL ngoại tuyến (tức là CL theo lô tăng dần) và CL trực tuyến với bất kỳ phân phối dữ liệu nào, bao gồm CIL và IID.

Các Phương pháp Giảm thiểu Khoảng cách Ổn định
Phần này mô tả các phương pháp chúng tôi sử dụng để kiểm tra các giả thuyết của mình về các yếu tố làm tăng khoảng cách ổn định. Chúng tôi sử dụng các thước đo đánh giá của mình, S∆, P∆ và CK∆ để xác nhận hiệu quả của các phương pháp giảm thiểu được đề xuất. Chúng tôi bao gồm thảo luận bổ sung trong Phụ lục H.

Khởi tạo Trọng số. Trong CIL, các đơn vị đầu ra cho các lớp mới thường được khởi tạo ngẫu nhiên gây ra những đơn vị đó tạo ra mất mát cao trong quá trình lan truyền ngược. Chúng tôi giả định rằng việc sử dụng khởi tạo dựa trên dữ liệu cho các đơn vị lớp mới sẽ giảm mất mát và do đó giảm khoảng cách ổn định, S∆. Để kiểm tra điều này, chúng tôi khởi tạo chúng thành giá trị trung bình của các embedding đơn vị chiều dài cho lớp đó, tức là

wk=1/V ∑V j=1 hj/∥hj∥2, (4)

trong đó wk∈Rd là vector trọng số lớp đầu ra cho lớp k, hj∈Rd là embedding thứ j từ lớp gần cuối, và V là số lượng mẫu từ lớp k trong lô. Trực giác, cách tiếp cận này nhằm mục đích điều chỉnh các trọng số ban đầu gần hơn với phân phối dữ liệu của lớp mới, tạo điều kiện cho các điều chỉnh học tập nhanh hơn và hiệu quả hơn trong giai đoạn ban đầu của CL.

Mục tiêu Cứng so với Mục tiêu Mềm Động. Đối với phân loại, các mô hình thường được đào tạo với mục tiêu cứng, tức là tại lần lặp đào tạo i một vector một chiều ti với '1' ở vị trí k tương ứng với lớp đúng. Chúng tôi giả định đào tạo mục tiêu cứng chịu trách nhiệm một phần cho khoảng cách ổn định. Trực giác, mục tiêu cứng được mã hóa một chiều và thực thi tính độc lập nghiêm ngặt giữa các lớp bất chấp một số lớp chia sẻ tương đồng phân phối. Thuộc tính này của mục tiêu cứng, do đó, cũng gây ra mất mát ban đầu lớn khi học các lớp mới. Mặt khác, mục tiêu mềm có thể giúp mạng duy trì phân phối liên lớp chung, điều này càng làm giảm nhiễu của các lớp đã học. Để kiểm tra điều này, chúng tôi sử dụng mục tiêu mềm được xây dựng sao cho các dự đoán của mô hình trên các lớp đã học trước đó được bảo tồn phần lớn.

Tại lần lặp học i, cho P(k|xi;θi) là xác suất đầu ra softmax của mô hình cho mẫu xi từ lớp k cho các tham số hiện tại của mô hình θi và lớp được dự đoán là y′i= arg maxk P(k|xi;θi). Chúng tôi duy trì một vector trung bình chạy uk∈RK của các xác suất softmax cho mỗi lớp được cập nhật khi một ví dụ từ lớp k được quan sát, tức là

uk←ck uk+P(k|xi;θi)/(ck+ 1), (5)

trong đó ck là một bộ đếm cho lớp k sau đó được tăng lên 1, và uk được khởi tạo thành phân phối đồng nhất trước các cập nhật chạy. Sau đó, mục tiêu mềm ti cho lần lặp i được xây dựng bằng cách đặt ti←uk và sau đó đặt phần tử cho lớp đúng thành 1, tức là ti[k]←1. Nếu y′i̸=k, thì chúng tôi cũng đặt ti[y′i]←1/K. Sau đó, ti được chuẩn hóa để tổng bằng 1 và được sử dụng để cập nhật mạng. Chiến lược này dẫn đến các mục tiêu làm nhiễu tối thiểu mạng và các giá trị mất mát nhỏ hơn. Trong Phụ lục G, chúng tôi minh họa quá trình cập nhật mục tiêu mềm.

Giới hạn Tính dẻo Lớp Ẩn Sử dụng LoRA. Để tích lũy kiến thức theo thời gian, hầu hết các cách tiếp cận CL cập nhật toàn bộ mạng. Cho rằng mỗi lô dữ liệu trong CL tương đối nhỏ, chúng tôi giả định điều này dẫn đến việc làm nhiễu quá mức các biểu diễn ẩn, dẫn đến khoảng cách ổn định lớn hơn. Để kiểm tra giả thuyết này, chúng tôi ràng buộc số lượng tham số có thể đào tạo trong các biểu diễn ẩn bằng cách sử dụng một bộ điều hợp mạng. Trong khi có nhiều bộ điều hợp mạng khác nhau (Han et al., 2024) hạn chế tính dẻo mạng, chúng tôi sử dụng thích ứng hạng thấp (LoRA) (Hu et al., 2021) do tính đơn giản và hiệu quả của nó. Cụ thể, chúng tôi tiêm trọng số LoRA vào các lớp tuyến tính của mạng, và chỉ các tham số này và lớp đầu ra được cập nhật, điều này giảm đáng kể số lượng tham số có thể đào tạo.

Đối với lô j, cho Wj−1∈Rd×g là một lớp tuyến tính đã học trước đó. Tại đầu mỗi phiên học, chúng tôi tham số hóa lại lớp này bằng cách thay thế Wj−1 bằng

Θj=Wj−1+BA, (6)

trong đó B∈Rd×r và A∈Rr×g là các tham số bộ điều hợp LoRA với hạng r≪min(d,g). Chỉ B và A là dẻo, với A được khởi tạo với các giá trị Gaussian ngẫu nhiên và B được khởi tạo thành ma trận không, vì vậy BA=0 ở đầu phiên học. Ở cuối phiên, các tham số LoRA được gộp vào mạng, tức là Wj←Θj. Trong các thí nghiệm LoRA, chỉ lớp đầu ra và các tham số LoRA là dẻo.

Giới hạn Tính dẻo Lớp Đầu ra thông qua Đóng băng Có mục tiêu. Trong CIL, những thay đổi lớn trong các biểu diễn của mạng cho các lớp cũ làm tăng khoảng cách ổn định. Trong khi LoRA hạn chế tính dẻo trong các biểu diễn ẩn, chúng tôi giả định rằng việc hạn chế tính dẻo trong lớp đầu ra cũng có thể hữu ích cho CIL. Do đó, chúng tôi nghiên cứu đóng băng trọng số lớp đầu ra cho các lớp đã học trước đó trong các lô trước đó. Đối với các phương pháp diễn tập, các mẫu từ các lớp đã thấy trong các lô trước đó có các lớp ẩn được cập nhật như thường lệ. Chúng tôi gọi kỹ thuật này là đóng băng lớp đầu ra cũ (OOCF).

Kết hợp Các Phương pháp Giảm thiểu & SGM. Chúng tôi đánh giá độc lập từng phương pháp giảm thiểu khoảng cách ổn định. Ngoài ra, chúng tôi đánh giá chúng kết hợp. Chúng tôi gọi phương pháp kết hợp mục tiêu mềm động, khởi tạo trọng số, OOCF và LoRA là SGM (Giảm thiểu Khoảng cách Ổn định). Mục tiêu mềm và khởi tạo trọng số ngăn chặn mất mát cao hơn ở lớp đầu ra để tăng cường ổn định. OOCF và LoRA hạn chế tính dẻo trong mạng đến các vị trí có mục tiêu sao cho các biểu diễn hiện có bị nhiễu tối thiểu.

Thí nghiệm Chính: Đánh giá Giả thuyết
Chúng tôi thiết kế các thí nghiệm của mình để mô phỏng việc sử dụng CL để giảm thiểu sự suy giảm mô hình. Do đó, chúng tôi sử dụng DNN được đào tạo trước ImageNet-1K được cập nhật dần dần với dữ liệu và lớp mới. Như được hiển thị trong Hình 1 và Hình 4, khoảng cách ổn định có mặt khi diễn tập vanilla được sử dụng.

Thiết lập Thí nghiệm
Ràng buộc Tính toán. Trong kịch bản thế giới thực, người học liên tục phải thích ứng với dòng dữ liệu quy mô lớn, điều này có thể không khả thi nếu cần nhiều tính toán hơn theo thời gian. Gần đây, nhiều công trình đã ủng hộ hiệu quả tính toán cho CL (Prabhu et al., 2023b; Harun et al., 2023b;a;c; Verwimp et al., 2024; Zhang et al., 2023). Trong các thí nghiệm của chúng tôi, chúng tôi ràng buộc tính toán bằng một số lần lặp đào tạo hoặc bước SGD cố định.

Diễn tập. Vì mục tiêu của chúng tôi là hiểu và giảm thiểu khoảng cách ổn định, các kết quả chính của chúng tôi sử dụng diễn tập và giả định người học có quyền truy cập vào tất cả dữ liệu đã quan sát trước đó, không có ràng buộc về lưu trữ. Điều này phù hợp với việc tìm một giải pháp thay thế tốt hơn cho việc đào tạo lại định kỳ từ đầu khi có thêm dữ liệu, điều này thường được thực hiện trong ngành công nghiệp nơi ngân sách tính toán phụ thuộc vào tính toán ở mức độ lớn hơn nhiều so với lưu trữ dữ liệu (Prabhu et al., 2023b;a).

Quy trình Học Liên tục. Chúng tôi nhằm mục đích nghiên cứu CL trong thiết lập giống như công nghiệp, yêu cầu dòng dữ liệu quy mô lớn với nhiều danh mục đối tượng. Tuy nhiên, rất khó tìm một tập dữ liệu phù hợp được tuyển chọn tốt và phù hợp cho các thí nghiệm CL quy mô lớn. Do đó, chúng tôi xây dựng dòng dữ liệu quy mô lớn bằng cách kết hợp ImageNet-1K với tập dữ liệu khác, Places365-LT, là một biến thể của tập dữ liệu Places365. Places365 là thách thức (Liu et al., 2019) và được sử dụng rộng rãi để phát hiện ngoài phân phối (OOD) với các mô hình được đào tạo trước ImageNet (Zhu et al., 2022).

Trong quá trình CL, mô hình học tuần tự 5 lô tăng dần dữ liệu từ Places365-LT. Trong thứ tự CIL, mỗi lô CL chứa 73 danh mục, và trong thứ tự IID mỗi lô CL có 12500 ví dụ. Trong quá trình diễn tập, mô hình được cập nhật qua 600 minibatch, trong đó minibatch bao gồm 128 mẫu với 50% được chọn ngẫu nhiên từ lô CL hiện tại và 50% từ dữ liệu đã thấy trong các lô CL trước đó và ImageNet-1K. Chúng tôi nghiên cứu hai thứ tự CL cho Places365-LT: 1) thứ tự CIL trong đó mỗi lô có các lớp chỉ được thấy trong lô đó (thay đổi khái niệm tối đa), và 2) thứ tự IID trong đó mỗi lô chứa các ví dụ từ các lớp được lấy mẫu ngẫu nhiên (thay đổi khái niệm tối thiểu). Đây là hai tình huống cực đại đối lập trong CL. Mặc dù khoảng cách ổn định không được biết là xảy ra trong thiết lập CL IID, thiết lập này rất quan trọng để chứng minh tính tổng quát của thuật toán. Để đo lường khoảng cách ổn định và các thước đo khác, chúng tôi đánh giá hiệu suất trong quá trình diễn tập cứ mỗi 50 lần lặp đào tạo, trong đó tập kiểm tra bao gồm tập xác thực ImageNet-1K và tất cả các lớp từ Places365-LT từ các lô CL hiện tại và trước đó. Các chi tiết triển khai và tập dữ liệu bổ sung được đưa ra trong Phụ lục C và B.

Kiến trúc Mạng. Chúng tôi chọn kiến trúc mạng phù hợp với LoRA và hoạt động tốt trong đào tạo ngoại tuyến với ImageNet-1K so với các DNN có kích thước tương tự. Trong các kết quả chính của chúng tôi, chúng tôi nghiên cứu CL sử dụng CNN ConvNeXtV2-Femto (Woo et al., 2023) đã được đào tạo trước trên ImageNet-1K sử dụng khung autoencoder có mặt nạ hoàn toàn tích chập theo sau bởi tinh chỉnh có giám sát trên ImageNet-1K. Trong khi ResNet18 được sử dụng rộng rãi trong CL, nó hoạt động kém hơn các CNN nhẹ khác trong CL (Hayes & Kanan, 2022; Harun et al., 2023b). ConvNeXtV2-Femto có 5.2M tham số, ít hơn 2× so với 11.6M tham số của ResNet18, và nó vượt trội hơn ResNet18 với 8.47% độ chính xác top-1 tuyệt đối cuối cùng trên ImageNet-1K.

Đáng chú ý rằng LoRA không phù hợp với các kiến trúc CNN (ví dụ ResNet) thiếu các lớp tích chập 1×1, nhưng nó có thể được sử dụng với ViT, ConvNeXtV1, ConvNeXtV2 và các kiến trúc DNN khác với các lớp tuyến tính này. Mỗi khối của ConvNeXt bao gồm một lớp tích chập 2D và hai lớp tích chập 1×1. Đối với các thí nghiệm sử dụng LoRA, các lớp tích chập 1×1 trong các khối ConvNeXt được sửa đổi để kết hợp trọng số của LoRA sử dụng Phương trình 6. Số lượng trọng số LoRA có thể đào tạo là 0.92M, ít hơn nhiều so với tổng số tham số lớp ẩn (5.08M). Dựa trên công trình trước đây, các lớp đầu trong mạng là các bộ trích xuất đặc trưng phổ quát và ít bị thay đổi trong quá trình CL (Ramasesh et al., 2021a; Ebrahimi et al., 2020; Pellegrini et al., 2020; Harun et al., 2024), vì vậy chúng tôi đóng băng 4 khối đầu tiên của CNN trong tất cả các thí nghiệm, để lại 8 khối còn lại dẻo (97.7% tham số) bao gồm 5.08M tham số.

Kết quả Thí nghiệm
Chúng tôi mô tả những phát hiện của mình về cách phương pháp được đề xuất (SGM) giảm thiểu khoảng cách ổn định và tăng cường hiệu quả học trong thiết lập lưu trữ không giới hạn với diễn tập trong CIL.

Đánh giá Các Giả thuyết của Chúng tôi
Ở đây, chúng tôi mô tả các kết quả cho việc đánh giá hai giả thuyết của chúng tôi.

Đường cơ sở. Trong các thí nghiệm của chúng tôi, chúng tôi đánh giá từng phương pháp trong Phần 4 riêng lẻ và phương pháp SGM kết hợp. Làm đường cơ sở, chúng tôi so sánh SGM với diễn tập với diễn tập vanilla, sử dụng lưu trữ không giới hạn cho diễn tập mà không có bất kỳ thành phần bổ sung nào, cũng như các mô hình chung (cận trên). Các mô hình chung được đào tạo chung trên ImageNet và các lô CL đã thấy đến lô hiện tại. Chúng tôi cũng bao gồm tinh chỉnh ngây thơ là một biến thể vanilla không có diễn tập và phục vụ như cận dưới. Cuối cùng, chúng tôi so sánh với chỉ lớp đầu ra cập nhật lớp đầu ra với diễn tập trong khi đóng băng tất cả các lớp khác.

Kết quả. Kết quả CIL chính của chúng tôi được đưa ra trong Bảng 1. SGM với diễn tập cho thấy giảm lớn nhất trong khoảng cách ổn định (S∆), khoảng cách dẻo (P∆) và khoảng cách kiến thức liên tục (CK∆). Nó cũng hoạt động tốt nhất trong các thước đo khác. Trong số các thành phần của nó, LoRA giảm khoảng cách ổn định nhiều nhất; tuy nhiên, khoảng cách ổn định cho LoRA cao hơn 3× so với SGM. Tiếp theo chúng tôi chuyển sang xem xét sự hỗ trợ cho hai giả thuyết của chúng tôi.

Giả thuyết 1. Giả thuyết đầu tiên của chúng tôi là khoảng cách ổn định trong CIL được gây ra bởi có mất mát lớn ở lớp đầu ra do các lớp mới, mà chúng tôi đã kiểm tra bằng cách sử dụng khởi tạo trọng số và mục tiêu mềm động. Cả hai phương pháp đều hiệu quả trong việc đạt được mục tiêu giảm mất mát ban đầu, đặc biệt là khởi tạo trọng số (xem Hình 2a). Như được hiển thị trong Bảng 1, cả hai phương pháp đều giảm khoảng cách ổn định. Chúng tôi quan sát thấy rằng khởi tạo trọng số cũng giảm đáng kể khoảng cách dẻo. Hình 2b cho thấy hiệu suất trung bình trên ImageNet-1K trong 5 phiên diễn tập cho mục tiêu cứng so với mục tiêu mềm, điều này cho thấy rằng mục tiêu cứng làm tăng khoảng cách ổn định ở mức độ lớn hơn so với mục tiêu mềm động.

Giả thuyết 2. Giả thuyết thứ hai của chúng tôi là khoảng cách ổn định trong CIL được gây ra bởi tính dẻo mạng quá mức, mà chúng tôi đã kiểm tra bằng cách sử dụng LoRA và OOCF. Hình 2c cho thấy kết quả trung bình trên ImageNet-1K trên 5 phiên diễn tập cho LoRA so với khi chỉ lớp đầu ra, 8 khối trên cùng (vanilla), hoặc toàn bộ mạng có thể đào tạo. Điều này cho thấy rằng tính dẻo đóng vai trò quan trọng trong khoảng cách ổn định; tuy nhiên, điều này không chuyển đổi trực tiếp thành số lượng tham số có thể đào tạo vì LoRA bao gồm lớp đầu ra nhưng thể hiện sự giảm nhỏ hơn trong hiệu suất so với đào tạo chỉ lớp đầu ra. Không giống như những phương pháp khác, LoRA phục hồi hoàn toàn hiệu suất cũ. Như thấy trong Bảng 1, cả OOCF và đặc biệt là LoRA đều giảm khoảng cách ổn định.

Kết luận Tạm thời. Kết quả thí nghiệm của chúng tôi hỗ trợ cả hai giả thuyết. LoRA giảm thiểu khoảng cách ổn định và kiến thức liên tục nhiều nhất. Khởi tạo trọng số dựa trên dữ liệu của chúng tôi cải thiện đáng kể tính dẻo. Điều này phù hợp với nghiên cứu trước đây cho rằng khởi tạo trọng số là quan trọng đối với tính dẻo trong DNN (Lyle et al., 2023). Chúng tôi thấy rằng SGM, một phương pháp kết hợp các cách tiếp cận được sử dụng để kiểm tra các giả thuyết này, giảm đáng kể khoảng cách ổn định.

CIL với Nhiều Thứ tự Dữ liệu. Để đảm bảo tính mạnh mẽ của các phát hiện của chúng tôi, chúng tôi mở rộng các thí nghiệm của mình đến nhiều thứ tự dữ liệu. Ngoài việc nghiên cứu SGM và diễn tập vanilla, chúng tôi xem xét chỉ đào tạo lớp đầu ra trong quá trình diễn tập. Kết quả trung bình trên 6 thứ tự dữ liệu được đưa ra trong Bảng 2. Chúng tôi thấy rằng SGM liên tục giảm thiểu khoảng cách ổn định. So với vanilla, SGM cung cấp ổn định hơn 20×, tính dẻo hơn 4.4× và kiến thức liên tục hơn 15.5×. SGM cũng vượt trội hơn việc đào tạo chỉ lớp đầu ra trong tất cả các tiêu chí. Điều này cho thấy rằng việc cập nhật các biểu diễn trong các lớp ẩn bên cạnh lớp đầu ra bằng SGM là quan trọng để học kiến thức mới và duy trì kiến thức cũ. Hơn nữa, SGM cân bằng ổn định và tính dẻo (xem Hình 6).

Hiệu quả Học
Một trong những mục tiêu của chúng tôi trong việc nghiên cứu CL và khoảng cách ổn định là cho phép đào tạo hiệu quả hơn về mặt tính toán. Để nghiên cứu liệu SGM có đạt được mục tiêu này hay không, chúng tôi đánh giá hiệu suất trong CIL, nơi chúng tôi đo hiệu suất trên các lớp cũ và mới cứ mỗi 10 lần lặp. Đối với các lớp mới, chúng tôi đo số lượng cập nhật và FLOP (phép toán dấu phẩy động) cần thiết để đạt được 99% độ chính xác tốt nhất.

Như được hiển thị trong Hình 3, SGM học các lớp mới nhanh hơn nhiều so với diễn tập vanilla, và trung bình, nó hiệu quả hơn 61.8% về mặt cập nhật mạng. Hơn nữa, vì đường cong cho thấy xu hướng giảm khi việc học tiến triển, điều này có nghĩa là SGM trở thành người học hiệu quả hơn theo thời gian, với ít cập nhật và TFLOP hơn cho lô hiện tại so với các lô trước đó được cần thiết. Đối với hiệu suất lớp cũ, chúng tôi đo số lần lặp trong quá trình diễn tập cần thiết để khôi phục hiệu suất của mô hình chung (cận trên) trên ImageNet-1K cho vanilla và SGM. Như được hiển thị trong Bảng 3, SGM yêu cầu ít lần lặp hơn nhiều để khôi phục hiệu suất cũ trong khi diễn tập vanilla (không có SGM) không thể khôi phục hiệu suất cũ hoàn toàn. So với mô hình chung, SGM cung cấp tăng tốc 16.7× về số lượng cập nhật mạng và tăng tốc 31.9× về TFLOP (xem Hình 5). Hơn nữa, SGM yêu cầu thời gian đào tạo ít hơn 18× so với mô hình chung trên cùng phần cứng.

Thí nghiệm Bổ sung: Tính Tổng quát của SGM
Phần này mở rộng về tính linh hoạt và hiệu quả của phương pháp SGM bằng cách khám phá ứng dụng của nó trên các thiết lập và ràng buộc khác nhau. Đầu tiên, chúng tôi cho thấy SGM hoạt động như thế nào trong thiết lập CL IID trong Phần 6.1. Tiếp theo, chúng tôi nghiên cứu diễn tập có ràng buộc lưu trữ trong cả kịch bản CL ngoại tuyến (Phần 6.2) và CL trực tuyến (Phần 6.3) với thứ tự dữ liệu CIL. Cuối cùng, chúng tôi tóm tắt các nghiên cứu hỗ trợ bổ sung trong Phần 6.4. Các chi tiết triển khai và tập dữ liệu bổ sung được đưa ra trong Phụ lục C và B.

Học Liên tục IID
Để hiểu liệu SGM với diễn tập có hữu ích cho các phân phối dữ liệu CL khác hay không, chúng tôi xem xét hành vi của nó trong thứ tự IID trong đó mỗi trong 5 lô CL chứa các lớp được lấy mẫu ngẫu nhiên từ tập dữ liệu Places365-LT. Trong thí nghiệm này, chúng tôi sử dụng ConvNeXtV2-Femto được đào tạo trước trên ImageNet-1K sử dụng học tự giám sát (SSL). Trong CL IID, mô hình học tuần tự 5 lô tăng dần dữ liệu từ Places365-LT trong đó mỗi lô tăng dần chứa 12500 ví dụ. Trong quá trình diễn tập, mô hình được cập nhật qua 600 minibatch, trong đó minibatch bao gồm 128 mẫu với 50% được chọn ngẫu nhiên từ lô CL hiện tại và 50% được rút từ dữ liệu đã thấy trong các lô CL trước đó và ImageNet-1K.

Trong thí nghiệm này, chúng tôi bỏ qua các ràng buộc lưu trữ để chỉ tập trung vào các phương pháp giảm thiểu mà không có ảnh hưởng của các biến khác. Kết quả của chúng tôi được tóm tắt trong Bảng 4. Về mặt độ chính xác cuối cùng, SGM đạt được độ chính xác cuối cùng 71.23%, vượt trội hơn độ chính xác 68.77% của diễn tập vanilla. Đáng ngạc nhiên, SGM thậm chí còn vượt qua độ chính xác 70.69% của mô hình được đào tạo chung, dẫn đến khoảng cách ổn định âm, điều này cho thấy chuyển giao kiến thức từ các lớp mới sang các lớp cũ. Ngược lại, chúng tôi thấy có khoảng cách ổn định nhỏ trong thứ tự CIL (xem Bảng 2), có thể do sự khác biệt giữa các lô tiếp theo.

CL Ngoại tuyến Có ràng buộc Lưu trữ
Để nghiên cứu hiệu quả của SGM dưới các ràng buộc lưu trữ, chúng tôi kết hợp nó với hai phương pháp diễn tập phổ biến, DERpp (Buzzega et al., 2020) và GDumb (Prabhu et al., 2020), dưới các ràng buộc lưu trữ khác nhau trong khi sử dụng cấu hình giống hệt nhau. Cho việc này, chúng tôi sử dụng ConvNeXtV2-Femto được đào tạo trước trên ImageNet-1K sử dụng SSL. Để nghiên cứu các ràng buộc lưu trữ khác nhau trên dòng dữ liệu quy mô lớn, chúng tôi kết hợp tập dữ liệu ImageNet-1K (1.2M hình ảnh) với tập dữ liệu quy mô lớn khác, Places365-Standard (1.8M hình ảnh). Điều này cho phép chúng tôi kiểm tra các ràng buộc lưu trữ hạn chế hơn trên dòng dữ liệu bao gồm 3 triệu hình ảnh.

Sau khi được đào tạo trước trên ImageNet-1K, một mô hình học tuần tự 5 lô tăng dần dữ liệu (73 lớp mỗi lô) từ Places365-Standard trong CL ngoại tuyến với thứ tự CIL. Mỗi diễn tập bị ràng buộc tính toán trong đó mô hình được cập nhật qua 1200 minibatch. Mỗi minibatch bao gồm 256 mẫu trong đó 50% được chọn ngẫu nhiên từ lô CL hiện tại và 50% từ dữ liệu đã thấy trong các lô CL trước đó và ImageNet-1K. Trong quá trình học một lô mới, mô hình diễn tập dữ liệu cũ từ lưu trữ bị giới hạn bởi số lượng mẫu tối đa ví dụ 192K và 24K tương ứng với 6.4% và 0.8% của toàn bộ tập dữ liệu (ImageNet và Places kết hợp), tương ứng. Như được hiển thị trong Bảng 5, SGM cải thiện hiệu suất của mỗi phương pháp trong tất cả các tiêu chí. Khi lưu trữ bị giới hạn bởi 24K mẫu, SGM cải thiện độ chính xác cuối cùng tuyệt đối 11.24% (DERpp) và 14.08% (GDumb) và cung cấp ổn định hơn 2.4× và 3.1× cho DERpp và GDumb, tương ứng.

CL Trực tuyến Có ràng buộc Lưu trữ
Chúng tôi cũng đánh giá hiệu quả của SGM trong thiết lập CL trực tuyến sử dụng phương pháp CL trực tuyến hiện đại, REMIND (Hayes et al., 2020). Sử dụng ConvNeXtV2-Femto, chúng tôi tiến hành các thí nghiệm CL có ràng buộc lưu trữ với thứ tự dữ liệu CIL, nơi chúng tôi kết hợp SGM với REMIND. Vì việc thực hiện các thí nghiệm CL trực tuyến trên các tập dữ liệu quy mô lớn tốn kém về mặt tính toán, chúng tôi chọn một tập dữ liệu nhỏ, CUB-200 làm tập dữ liệu thứ 2 sau ImageNet-1K. CUB-200 thách thức hơn các tập dữ liệu nhỏ khác (Lee et al., 2023). Sau khi được đào tạo trước trên ImageNet-1K, một mô hình học CUB-200 theo cách mẫu-theo-mẫu, tức là sau khi nhận một mẫu mới, nó thực hiện một bước SGD sử dụng 51 mẫu (50 mẫu cũ và 1 mẫu mới). Lưu trữ bị ràng buộc bởi số lượng mẫu tối đa, tức là 80K và 20K, tương ứng với 6.2% và 1.5% của toàn bộ tập dữ liệu (ImageNet và CUB kết hợp), tương ứng. Như được hiển thị trong Bảng 6, SGM kết hợp với REMIND vượt trội hơn REMIND độc lập với biên độ lớn trong tất cả các thước đo. Khi lưu trữ bị giới hạn bởi 20K mẫu, SGM cải thiện độ chính xác cuối cùng của REMIND tuyệt đối 8.64% và giảm khoảng cách ổn định của REMIND với hệ số 3.95×.

Các Nghiên cứu Hỗ trợ
Chúng tôi bao gồm các nghiên cứu hỗ trợ bổ sung trong Phụ lục và tóm tắt các phát hiện ở đây.

Các Phương pháp Không diễn tập. Trong khi các phương pháp không diễn tập kém hiệu quả hơn cho CL, thật thú vị khi nghiên cứu SGM khi kết hợp với các phương pháp không diễn tập để xác định liệu các phát hiện của chúng tôi có nhất quán hay không. Trong CIL của ImageNet-1K và Places365-LT, SGM cũng có lợi cho phương pháp không diễn tập, LwF (Li & Hoiem, 2017) với tăng tuyệt đối 35.24% trong độ chính xác cuối cùng và giảm 2.6× trong khoảng cách ổn định (xem Phụ lục E).

Diễn tập Cân bằng Lớp. Vì các thí nghiệm chính của chúng tôi dựa trên diễn tập thông thường không có cân bằng lớp, chúng tôi cũng tiến hành các thí nghiệm sử dụng diễn tập cân bằng lớp. So với diễn tập vanilla, SGM giảm khoảng cách ổn định 7.3× khi cả hai sử dụng diễn tập cân bằng lớp. SGM cũng đạt được chuyển giao kiến thức liên tục (xem Phụ lục D.2).

Đào tạo Trước Có giám sát. Trong các kết quả chính của chúng tôi, SGM giảm khoảng cách ổn định sử dụng mô hình ConvNeXtV2 được đào tạo trước tự giám sát, và các mô hình tự giám sát được biết là hoạt động tốt hơn trong CL (Gallardo et al., 2021). Chúng tôi cũng tiến hành các thí nghiệm với ConvNeXtV1 được đào tạo trước có giám sát (Liu et al., 2022) để xem xét SGM hoạt động như thế nào mà không có backbone tự giám sát. Chúng tôi thấy rằng SGM hiệu quả mà không có backbone tự giám sát. So với diễn tập vanilla, SGM đạt được ổn định hơn 6×, tính dẻo hơn 3.9× và chuyển giao kiến thức liên tục hơn 35× khi cả hai sử dụng ConvNeXtV1 (xem Phụ lục D.3).

Vision Transformer. Chúng tôi cũng nghiên cứu hành vi của SGM với ViT, hiện đang cạnh tranh với CNN. So với diễn tập vanilla, SGM giảm khoảng cách ổn định 2.4× khi cả hai sử dụng ViT được đào tạo trước (xem Phụ lục D.4).

Hạn chế & Công việc Tương lai
Công việc của chúng tôi được xây dựng dựa trên giả định rằng một DNN được đào tạo tốt được cung cấp và hiệu suất trên các nhiệm vụ ban đầu phải được duy trì hoặc cải thiện. Nếu giả định này bị vi phạm, như thấy trong một số bài báo CL không bắt đầu với các mô hình được đào tạo trước, sự phụ thuộc của SGM vào LoRA sẽ làm hại tiện ích của nó. Mặc dù hầu hết các thành phần của SGM, chẳng hạn như khởi tạo trọng số, mục tiêu mềm động và OOCF, có thể được áp dụng dễ dàng cho DNN được đào tạo từ đầu, LoRA không thể được sử dụng vì các lớp DNN không có LoRA sẽ vẫn bị đóng băng và không được học. Áp dụng SGM trong thiết lập này sẽ yêu cầu một biến thể của LoRA trong đó LoRA có thể được sử dụng cho tất cả các lớp từ đầu đào tạo sao cho DNN cạnh tranh với mô hình được đào tạo chung không có LoRA. Chúng tôi đã sử dụng ConvNeXtV1, ConvNeXtV2 và MobileViT DNN được đào tạo trước, phù hợp với LoRA. Công việc tương lai có thể điều tra các biến thể LoRA khác nhau và bộ điều hợp mạng (Han et al., 2024) với SGM. Cũng sẽ thú vị khi nghiên cứu hiệu quả của SGM để đáp ứng nhu cầu của CL cho các thiết bị nhúng Hayes & Kanan (2022).

Nghiên cứu của chúng tôi tập trung vào phân loại hình ảnh. Công việc tương lai có thể khám phá hiệu quả của SGM cho hồi quy, phát hiện đối tượng (Acharya et al., 2020; 2019), lý luận Hayes & Kanan (2021), và phân đoạn ngữ nghĩa (Zhang et al., 2022). Các phương pháp CL được phát triển chỉ trên các tập dữ liệu nhỏ thường không mở rộng được cho các tập dữ liệu lớn hơn như ImageNet-1K (Zhou et al., 2023), vì vậy chúng tôi đã nghiên cứu sự kết hợp của ImageNet-1K và Places365. Do hạn chế tính toán và thiếu các tập dữ liệu phân loại hình ảnh quy mô lớn sẵn có, chúng tôi không thể nghiên cứu CL cho hơn 1365 lớp. Trong công việc tương lai, việc đánh giá SGM mở rộng như thế nào với việc tăng kích thước tập dữ liệu và số lượng lớp sẽ có giá trị. Chúng tôi hy vọng công việc của chúng tôi sẽ truyền cảm hứng cho nghiên cứu tương lai tìm ra các cách tiếp cận tốt hơn để ngăn chặn sự suy giảm mô hình do thay đổi khái niệm.

Kết luận
Mặc dù đã có tiến bộ đáng kể trong việc giảm thiểu việc quên thảm khốc, hầu như tất cả các phương pháp CL vẫn không phù hợp cho các ứng dụng thực tế như giải quyết sự suy giảm mô hình (Verwimp et al., 2024; Harun et al., 2023a). Để loại bỏ nhu cầu đào tạo lại thường xuyên các DNN được triển khai, CL phải chống lại sự suy giảm mô hình, giảm thiểu khoảng cách ổn định và hiệu quả hơn về mặt tính toán so với đào tạo lại từ đầu trong các thiết lập CL quy mô lớn. Tập trung vào kịch bản này, chúng tôi đã cho thấy rằng SGM đáp ứng các tiêu chí này. Với việc sử dụng năng lượng ngày càng tăng của các mô hình học sâu (Luccioni et al., 2022; Patterson et al., 2021; Wu et al., 2022), việc giảm nhu cầu đào tạo lại từ đầu có thể đóng góp đáng kể vào việc giảm lượng khí thải carbon liên quan đến đào tạo DNN. Công việc của chúng tôi điều chỉnh CL với các thách thức thế giới thực này, và chúng tôi hy vọng nó khuyến khích cộng đồng CL tập trung vào chúng.

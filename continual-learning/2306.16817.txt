# 2306.16817.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/continual-learning/2306.16817.pdf
# File size: 1953936 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
IMPROVING ONLINE CONTINUAL LEARNING PERFORMANCE
AND STABILITY WITH TEMPORAL ENSEMBLES
Albin Soutif–Cormerais
Computer Vision Center
Universitat Aut `onoma de Barcelona
albin@cvc.uab.catAntonio Carta
Department of Computer Science
University of Pisa
antonio.carta@unipi.itJoost Van de Weijer
Computer Vision Center
Universitat Aut `onoma de Barcelona
joost@cvc.uab.es
ABSTRACT
Neural networks are very effective when trained on large datasets for a large number of iterations.
However, when they are trained on non-stationary streams of data and in an online fashion, their
performance is reduced (1) by the online setup, which limits the availability of data, (2) due to
catastrophic forgetting because of the non-stationary nature of the data. Furthermore, several recent
works (Caccia et al., 2022; Lange et al., 2023) showed that replay methods used in continual learning
suffer from the stability gap , encountered when evaluating the model continually (rather than only
on task boundaries). In this article, we study the effect of model ensembling as a way to improve
performance and stability in online continual learning. We notice that naively ensembling models
coming from a variety of training tasks increases the performance in online continual learning con-
siderably. Starting from this observation, and drawing inspirations from semi-supervised learning
ensembling methods, we use a lightweight temporal ensemble that computes the exponential moving
average of the weights (EMA) at test time, and show that it can drastically increase the performance
and stability when used in combination with several methods from the literature.
1 I NTRODUCTION
Learning neural networks with backpropagation has been proven capable of good generalization properties even when
using overparametrized networks (Krizhevsky et al., 2017). However, these good learning properties mainly occur
when the data is provided in an independant and identically distributed manner. When learning on a stream which
distribution varies over time, neural networks are known to suffer from catastrophic forgetting (McCloskey & Cohen,
1989; Goodfellow et al., 2014; Kirkpatrick et al., 2017), and tend to forget knowledge acquired in previous learning
tasks. The field of continual learning aims to address this problem. Generally, incremental learning separates the
learning into distinct tasks (identified by a task-ID) that are encountered sequentially by the agent. A variety of settings
have been introduced in continual learning in order to evaluate several aspects of the continual learning agent; task-
incremental learning (De Lange et al., 2021; van de Ven & Tolias, 2018), and class-incremental learning (Masana
et al., 2022; Belouadah et al., 2021) are among the most popular. In this paper, we focus on the more challenging
class-incremental setting, where the learner does not have access to the task-ID at inference time.
Model Ensembling, or the aggregation of predictions coming from different models, is a well studied and popular
topic, both in the academic literature and in practical applications (Hansen & Salamon, 1990; Perrone & Cooper,
1995; Dietterich, 2000). It is known to improve performance compared to using a single model. The success of
ensembling methods has been found to depend on the functional diversity of the members and the efficiency of the
resulting ensemble between them (Goodfellow et al., 2016; Wortsman et al., 2021). In continual learning, the model
learns the data task by task, being exposed to one task at a time. Therefore, models at different timesteps represent
a functionally diverse set of models, each one locally adapted to the current task. Such functional diversity can be
exploited by ensembling techniques. In Figure 1, we show ensembling results on two continual learning benchmarks.
Here we apply a temporal ensemble of twenty models (chosen from a large number of models saved along the training
trajectory). We can observe that ensembling leads to a significant performance improvement (over 40% on both
datasets), and that whenever we increase the number of tasks covered by the ensemble, gains improve. Therefore,
in this article, we investigate the use of ensembles for continual learning and provide empirical results that show
their benefit for continual learning settings. Importantly, we show that when using a practical and memory efficient
ensembling method similar or even better results can be obtained.
Evaluation of continually learned agents typically occurs after learning a task. Recently, another way of evaluating has
been proposed, coined continual evaluation (Caccia et al., 2022; Lange et al., 2023) or anytime inference (Koh et al.,
1arXiv:2306.16817v2  [cs.LG]  3 Jul 2023

--- PAGE 2 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
Figure 1: Relative accuracy gains (multiplicative in %), compared to the worst performing ensemble, when naively
ensembling 20 models coming from different learning tasks on Split-Cifar100 (Left) and Split-MiniImagenet (Right)
for two online continual learning methods, classical replay ER and asymmetric cross entropy loss ER-ACE. Results are
reported as a function of number of covered tasks which is defined as the number of tasks from which the ensembled
models originate. The graph shows that diversity of the ensemble is important.
2022). It aims to evaluate the agent’s performance at any moment during learning. In this setting, Lange et al. (2023)
find that continual learning agents suffer from the stability gap , where the performance on previous tasks decreases
drastically at the start of learning a new task, before returning to normal when continuing training of the new task.
This behavior is problematic in many real-world applications where the agent must be applied for inference while it is
learning (i.e. for financial market forecasting, or online monitoring tasks). Ensembles can provide improved stability,
as they can reduce the variance of the predictions and provide a more robust prediction. By combining multiple
models, the errors of one model can be compensated for by the other models in the ensemble, leading to more stable
performance.
Lastly, it is known that in class incremental learning, even when using replay, the network is prone to suffer from the
task-recency bias, which is a prediction bias towards classes belonging to the last task. This phenomenon has been
studied and tackled in many works (Belouadah & Popescu, 2019; Wu et al., 2019; Hou et al., 2019). Ensembling
models biased towards different tasks has the potential to reduce the bias compared to the single models; we will
analyse this in this paper.
The reasons discussed in the introduction motivate us to investigate the potential of temporal ensembles in online
continual learning. Specifically, we believe that they could offer improved stability, reduce task recency bias, and
benefit from more functional diversity than in i.i.d learning. By exploring the performance of ensembles of models
trained on sequential data, we aim to provide insights into the benefits and limitations of using such models in online
continual learning settings. Our contributions are the following
• We show that naively ensembling checkpoints from different continual learning tasks yields strong perfor-
mance gains for online continual learning. In search for a practical ensembling method, we take inspiration
from semi-supervised learning and apply a temporal ensembling method (i.e., an exponential moving average
ensemble) as an evaluation model.
• We report the performance increase of the EMA ensemble in combination with several methods, showing a
consistent increase in performance (up to 9.3% on Split-MiniImagenet). We also compute continual evalu-
ation metrics and consistently notice a great increase in stability metrics resulting from the use of the EMA
ensemble (up to 32.3% on Split-Cifar10). We further observe a reduced task-recency bias of the EMA method.
2 R ELATED WORK
2.1 C ONTINUAL LEARNING AND ONLINE CONTINUAL LEARNING
Popular continual learning scenarios often assume that data arrive in large batches of i.i.d data, with sharp distribution
shifts happening whenever a new batch becomes available. We call this setting boundary-aware continual learning,
due to the additional information provided by the arrival of a new task during training. Most of the continual learning
literature focus on that setting, either by also providing the task-id at test time (De Lange et al., 2021) (task-incremental
learning), or not (Masana et al., 2022) (class-incremental learning). We will focus on class-incremental learning in
this paper.
2

--- PAGE 3 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
Boundary-free online continual learning (Aljundi et al., 2019b) removes this form of supervision by learning on a
stream of small mini-batches. This means that the granularity of the data distribution can be refined. In practice, it
is possible to keep tasks that define the granularity of the distribution, while letting the agent assume this distribution
could change at any new mini-batch. This is the setting that we experiment on in this article. In MIR (Aljundi et al.,
2019a), the authors introduce a selection strategy for replay and select the samples that will be mostly penalised by
the current update. In ER-ACE (Caccia et al., 2022), an asymetric cross-entropy loss is used on current data, using
only the logits represented in the current mini-batch, while the classical cross-entropy loss is used on the replay buffer.
Zhang et al. (2022) show that a strong baseline (called RAR) in online continual learning is repeatedly training on the
available batch by sampling a new replay batch and applying data augmentations. In this article, we propose a simple
improvement to these methods based on temporal ensembling which is applied at evaluation time.
Other, more classical class-incremental learning methods can be used in this setting, as long as they don’t require
knowledge of task-boundaries during training time. In ICaRL (Rebuffi et al., 2017), a selection strategy for storing
the buffer sampled is used, along with a nearest mean classifier. In DER (Buzzega et al., 2020), both the samples and
the logits of these samples are stored and replayed using data augmentation. Other classes of approaches like EEIL
(Castro et al., 2018), perform a balancing step at the end of training on each task, which makes them unsuitable to the
boundary-free setting, unless the balancing is done before every evaluation session, in which case it could drastically
increase the computation requirements. Other than these methods, we will focus on online continual learning methods
in this paper.
2.2 E NSEMBLING IN CONTINUAL LEARNING AND TEMPORAL ENSEMBLING
Aggregating the predictions coming from multiple trained models has been known for a long time as a process that
results in increased performance compared to using the predictions of the individual models (Breiman, 1996). The
group of trained models used for prediction is referred to as an ensemble of models. Such ensembles have been
studied extensively in the literature (Hansen & Salamon, 1990; Perrone & Cooper, 1995; Dietterich, 2000). Several
challenges are associated with the creation of such ensembles, and a lot of the requirements of these ensembles seem
at first incompatible with the constraints imposed by continual learning. In particular, naively creating an ensemble
requires the training of several models that need to be stored in memory and trained independently, thus violating
the memory and time constraints of continual learning. Nevertheless, some of these challenges have been already
addressed in the literature. Huang et al. (2017) relieve the constraint of having to train separate models by using
checkpoints of the same training run and a cyclic learning rate schedule as the ensemble members. Wortsman et al.
(2021) train not only one network but a parametric subspace of networks which they can use to create an ensemble.
Wen et al. (2020) develop BatchEnsemble, a memory efficient way to create an ensemble of models by learning a
shared weight matrix for all the members, and then a rank one matrix for each of the members. A member is then
computed as the result of the hadamard product between the shared matrix and the rank one matrix. They later use
this technique in task incremental learning, where they learn one member per task to be used at test time. Doan et al.
(2022) lay the grounds of continual learning beyond the use of a single model. They study feasible ways of learning
an ensemble of models continually, and compare a variety of ensembling techniques like BatchEnsemble Wen et al.
(2020) or Subspace Learning Wortsman et al. (2021). They conclude that ensembling helps in the setting of task-
incremental learning, and propose a method that make use of that property to increase the performance in that setting.
Compared to our work, they focus more on the effect of adding more models into the ensemble but not so much on
the effect of ensembling models coming from different tasks, and they operate in the task-incremental learning setting.
Lee et al. (2017) propose Incremental Moment Matching , in which they compute the mean of the model weights in
the weight space, in turn creating an approximate ensemble. In contrast to our work, they operate in the simpler
task-incremental setting, in which task-ID is available at test time.
Temporal ensembling (Samuli & Timo, 2017), is a technique that consists in ensembling the predictions coming from
different models on the training trajectory. In the original work, it was done by keeping an exponential moving average
of the predictions of the model on the training data, but this technique was later refined in (Tarvainen & Valpola, 2017),
where the authors chose to keep a running average of the weights instead of the predictions, and show that this leads to
similar or even better performance, while relieving the constraint of having to update the running prediction for each
datapoint at every iteration. In both of these works, the resulting ensemble prediction was used to improve the results
in semi-supervised learning, where only a small fraction of the sample labels are available. This same Mean-teacher
model has also been used successfully in several self-supervised learning works (Grill et al., 2020; Caron et al., 2021).
In this article, we study the application of cheap temporal ensembles to the setting of online continual learning.
3

--- PAGE 4 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
3 P RELIMINARIES
3.1 C ONTINUAL EVALUATION AND THESTABILITY GAP
In continual classification, a learning agent learns the parameters θ∈Θof a function f: (X,Θ)7→ Y from the image
input space Xto the label space Y. It does so by observing a stream of data S={(x1, y1),(x2, y2), ...(xn, yn)},
where x∈ X andy∈ Y. Each data tuple is drawn from a time varying distribution (xt, yt)∼ D t. In classical
machine learning the training data distribution does not depend on time, but this is added as a constraint in continual
learning. In both cases the goal of the agent is to perform well on new samples drawn from the joint distribution
D, which is marginalized over past time. In practice, continual learning is simplified to allow for easier analysis by
studying distributions that come from a discrete set and switch from one distribution to another (referred to as tasks
t∈ {t1, ...tT}). In this paper, we will focus on class-incremental learning, where the learner does not have access to
the task identifier tat inference time.
While all of the above simplifications make sense, they are still far from the human learning experience, and from
fitting the requirements of many real-world applications. In comparison to the above, humans experience continuously
time-varying distributions and continual evaluation. In order to address this, Caccia et al. (2022) and Lange et al.
(2023) lay the basis and encourage the study of continual evaluation of neural networks. In continual evaluation, the
model is continuously evaluated during, instead of after each task. Interestingly, they noticed that the performance on
previous tasks often drops at task shifts before coming back to a higher value later in training, this is what they refer
to as the stability gap .
3.2 C ONTINUAL EVALUATION METRICS
In this section, we present various metrics used in the online continual learning setting and that can help measure
the stability and more generally, evaluate the performance of the agent over the course of its training. We denote
A(Ei, ft)the accuracy of ft(model at current iteration t), on the evaluation task Ei. The most common metric
used in this scenario is the average anytime accuracy ,AAA t(See Eq. 1), used in many works (Caccia et al., 2020;
2022; Koh et al., 2022). While this metric does not focus on the worst-case performance, it is a nice indicator of
the performance of the learning agent over the course of training. It measures the average accuracy on all tasks seen
so far, and averages it over all training iterations. In (Lange et al., 2023), a set of metrics is introduced to measure
worst-case performance. These are particularly suited to assess the stability of the algorithms. They first define the
average minimum accuracy reached by previous tasks when learning task Tk,min-ACC Tk(see Eq. 2). It gives a
good idea of the worst case performance of the agent on a given task. Then, the worst-case accuracy, WC-ACC t
(see Eq. 3), combines information from the minimum accuracy on previous tasks and the accuracy on the current
task. WC-ACC tsummarizes the trade-off between stability (accuracy on previous task data) and plasticity (accuracy
on current task data). This metric is upper-bounded by the average accuracy. Here, tis the current iteration, Tkthe
current task (at iteration t) and t|Ti|is the iteration at the end of learning Ti. Since WC-ACC tis upper bounded by
the average accuracy, we also report a new metric which is the relative gap between the latter and average accuracy
Acctas defined in Equation 4, we name it Relative Accuracy Gap (RAG) since this measures the relative gap between
worst-case accuracy and average accuracy. This metric can then be fairly compared across various methods that have
different average accuracy.
AAA t=1
ttX
j=11
kkX
i=1A(Ei, fj) (1)
min-ACC Tk=1
k−1k−1X
imin
nA(Ei, fn),∀n:t|Ti−1|< n≤t (2)
WC-ACC t=1
kA(Ek, ft) + (1−1
k) min-ACC Tk (3)
Acc t=1
kkX
iA(Ei, ft) and RAG t=Acc t−WC-ACC t
Acc t(4)
4

--- PAGE 5 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
Method Accuracy Memory (Mb)
ER 26.2 4 + 211
ER Naive Ensemble 32.1 1840 + 211
ER + EMA 36.3 8 + 211
Table 1: Comparison on Split-MiniImagenet (20 tasks) of the naive ensembling of checkpoints taken along the training
trajectory of a replay method every 10 iterations, against the use of EMA ensemble. For clarity, we divide the memory
footprint into the one for the models and the one for the replay buffer (model + buffer).
4 M ETHOD : EXPONENTIAL MOVING AVERAGE ENSEMBLE (EMA)
In the introduction (see Figure 1) we have shown that ensembles can greatly improve performance, however, they come
at a significant increase in memory usage which is in direct conflict with the memory requirements typically imposed
on continual learners. Indeed, both continual learning and online learning impose memory constraints since they do
not allow retaining more than a fixed amount of data coming from the stream of data. Therefore, in this section, we
look into methods to reduce the memory usage, while maintaining the advantages of model ensembling.
Several works have focused on reducing the memory constraint of ensembles Wen et al. (2020); Wortsman et al. (2021);
Tarvainen & Valpola (2017), some did so notably by averaging the models in weight space instead of aggregating the
predictions in the functional space. While it is not clear under which condition such manipulation of the weights can
form a model that performs similarly to the ensemble of the summed members, several works have shown practical
working cases. It is possible to perform such a summation (Wortsman et al., 2021) whenever two models are connected
by a linear path of low loss (Frankle et al., 2020). Tarvainen & Valpola (2017) propose instead to do a weighted sum
of an infinite amount of checkpoints by giving older checkpoints less important weight, decreasing exponentially with
the distance.
For a potential use of these ensembles in continual learning we are interested in having an ensemble that covers many
tasks (see Section 1), and one that is cheap to store and compute. The solution adopted in (Tarvainen & Valpola, 2017),
for semi-supervised learning, fits well to this task since it requires storing only one additional model and is able to
ensemble models from all of the previous iterations. Consider a function f(x) =f(x, θt)with learnable weights θt
(at training iteration t), the exponential moving average (EMA) of it’s weights is defined as:
θt
ema=λθt−1
ema+ (1−λ)θt, (5)
where λis a user-defined hyperparameter comprised between 0 and 1, which sets the importance of the current model
in the running average compared to the one of the previous models, θt−1
ema is the value of the moving average at the
previous iteration, and θtis the weights of the training model at iteration t(θtcan be computed with existing online
methods, such as ER (Chaudhry et al., 2019) or MIR (Aljundi et al., 2019a). This implicit definition can also be written
as an explicit sum over all the previous model weights:
θt
ema=tX
i=1(1−λ)λt−iθi+λtθ0
ema. (6)
This means that the ensemble formed by the sum virtually covers all the previously encountered tasks. However,
exponentially less weights will be reserved to older tasks, potentially reducing the effective diversity of the ensemble.
Nevertheless, the motivational experiment we conducted on Split-Cifar100 show that after some number of tasks
covered by the ensemble, the accuracy gained by covering more and more tasks is less important (sublinear growth).
So covering a small number of tasks with the ensemble can be sufficient to get satisfying performance gains. This
motivated us to analyze the exponential moving average model in the setting of online continual learning.
In Table 1 we compare Naive Ensembling, discussed in Section 1, with the EMA model when combined with Ex-
perience Replay Chaudhry et al. (2019). As can be seen, the EMA model significantly reduces the memory usage
(requiring only one additional model). Remarkably, ER+EMA outperforms the Naive Ensemble. This could be
caused by the fact that ER+EMA combines many more models, and because of the non-linear weight assignment to
the various models (see Appendix Figure 8), where EMA assigns more weight to the last (and better) models in the
training trajectory.
While the EMA approximate ensemble is commonly used in the literature and has been proven to give good perfor-
mance (Tarvainen & Valpola, 2017; Grill et al., 2020; Caron et al., 2021). Other weight summing schemes could be
5

--- PAGE 6 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
wi ER ER-ACE RAR
- - 9.9±0.6 16.5±0.7 27.6±1.3
EMA λ= 0.99wi−1
λ14.0±0.5 19.0±0.3 35.4±1.2
EMA λ= 0.995wi−1
λ18.0 20.1 36.8
EMA λ= 0.999wi−1
λ18.3 18.8 31.2
Uniform 1 13.1 12.7 17.3
Linear i 16.4 16.3 25.4
Logarithmic wi−1+log(i) 16.6 16.6 26.2
Quadratic wi−1+i218.2 18.8 31.5
Table 2: Comparison of different approximate ensembling methods inspired from the EMA approximate ensembling
method. Each ensembling technique was tried on Split-Cifar100 in combination with ER (Chaudhry et al., 2019)
ER-ACE (Caccia et al., 2022), and RAR (Zhang et al., 2022). The second column indicates how the weights for the
current model are computed at each step. The first row indicates the results when no ensembling technique is used.
tried to compute an approximate ensemble. Such schemes are not necessarily expected to work in classical offline
learning since summing models that are far away from each other in the weight space is not guaranteed to work. How-
ever, since online learning only performs a few training iterations on the task at hand (compared to offline learning),
we can expect the models to be closer from each other and thus allow other summing techniques to work. In order
to explore the possibilities of such summing techniques in online continual learning, we compare several weighting
techniques. Since we are working in the online learning setting and under the constraint of storing only one additional
model, we choose to compute the approximate ensemble following Equation 7,
θt
ensemble =1Pt
iwitX
iwiθi, (7)
and use this ensemble instead of the EMA ensemble. This formulation allows for more freedom in the choice of the
weighting scheme, but the formulation used by EMA can also be expressed under this form, we identify the equivalent
weight wifor the EMA ensemble using Equation 6 as being wi=wi−1
λ. We update at every iteration the weighted
sum of the models and normalize it by the sum of the weights to avoid exploding model weights. In Appendix (Figure
11) we provide a comparison of the weight distribution for the different strategies we tried.
In Table 2, we present the results of combining an ensemble computed with each weighting scheme with three meth-
ods from the literature on the Split-Cifar100 dataset (See Section 5 for explanations about the experimental settings).
We see that the EMA model gets the best performance overall, especially with λ= 0.9951. However, we get sur-
prisingly high results with linear, logarithmic, and quadratic weighting, especially in combination with ER, but linear
and logarithmic weighting fail to give an advantage when combined with the more advanced methods ER-ACE and
RAR. Quadratic weighting obtains the closest resuts to the EMA methods, we provide a more detailed comparison
of Quadratic against EMA method in the Appendix (Figure. 12). Uniform weighting is the scheme that performs
worst across the board. which can be understood since it gives equal weight to the first models than to the last models
whereas the last models have been trained for a longer time and thus are expected to have better performance.
5 E XPERIMENTS
Datasets. We perform experiments on 3 datasets. Cifar-10 is a 10-class dataset that contains 60000 images of size
32 by 32 and 3 color channels (Krizhevsky, 2009). Cifar-100 has the same image dimensions and number of images
but with 100 classes. Mini-Imagenet (Vinyals et al., 2016) is a 100-class version of ImageNet (Russakovsky et al.,
2015), that contains 60000 images which are rescaled to 84 by 84. We split these datasets into 5, 20 and 20 tasks
respectively, each containing a mutually exclusive set of classes.
Scenario. We present results in the online class-incremental setting. When continual evaluation is performed, we
evaluate after each unique mini-batch. All the compared methods are using a replay buffer, with a fixed memory size
of 1000 exemplars for Cifar-10, 2000 exemplars for Cifar-100 and 10000 for Mini-Imagenet (as in (Caccia et al.,
2022)). Each training mini-batch is formed out of half of exemplars from previous tasks and half from the current task.
Methods. We compare the performance of five replay methods. ER-ACE (Caccia et al., 2022), MIR (Aljundi et al.,
2019a), RAR (Zhang et al., 2022), DER (Buzzega et al., 2020) are described in Section 2.1, while ER (Chaudhry
1These parameters are not the one we use in the main results of Section 6 (we use λ= 0.99). For a discussion on hyperparameter
choices, refer to Section A.1
6

--- PAGE 7 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
Figure 2: Validation accuracy on task 1 data (Left), Average Anytime Accuracy AAA t(Middle) and WC-ACC t
(Right) for ER-ACE and its EMA augmented version on Split-Cifar100, using 2000 memory. Mean and standard
deviation are computed over 6 runs.
et al., 2019) is the vanilla replay baseline. We display their performance along with the one of their EMA augmented
version on the studied datasets. Additionally, we report the results of an i.i.d reference method that is allowed the
same memory and computational budget as the compared methods, but for which the data arrives in an independent
and identically distributed manner (in contrast to the continual learning manner where data arrives split by split). Since
some of the methods included in the comparison make use of input transformations (RAR), we also include the results
of the i.i.dw/tr reference method, which uses the same input transformations.
Training and Implementation Details. For all datasets we use a slim version of Resnet-18 as done in (Lopez-Paz
& Ranzato, 2017) and perform 3 passes per mini-batch using Stochastic Gradient Descent with a learning rate of 0.1,
and batch size of 32. We run each experiment for six seeds and report the mean and standard deviation. For DER, we
stick to the parameters used in the original paper for CIFAR10 ( α= 0.1andβ= 0.5). For the EMA ensemble, we
chose a momentum parameter of λ= 0.99. More details on the choice of this parameter can be found in the Appendix
Section A.1. We make use of the Avalanche framework (Lomonaco et al., 2021) for all experiments. We make the
code available at: https://github.com/AlbinSou/online_ema .
Metrics. For every method, we report the final average accuracy but also the continual evaluation metrics described
in Section 3.2, that we computed on a held out validation set after training on each new mini-batch. The validation
dataset contains 5%of the total training data. We report both AAA TfinalandWC-ACC Tfinalin the tables, where
Tfinal is the last training iteration. We also report WC-ACC tat every iteration in the figures. The final value of the
RAG metric that we define in Equation 4 is reported in percent. Note that we do not make use of this validation data
to tune hyperparameters but just to compute the continual evaluation metrics.
6 R ESULTS
OnSplit-Cifar10 the EMA ensemble offers consistent improvements across all methods (see Table 3), especially
for RAR, where it offers a 4.3% improvement in final average accuracy. We hypothesise that the gains of EMA are
smaller than on Split-Cifar100 and Split-MiniImagenet because in that case the EMA ensemble weights cover less
tasks than in the case of the other two datasets (5 tasks but the same number of training iterations than Split-Cifar100).
Nevertheless, the stability metrics are greatly improved also for this dataset.
OnSplit-Cifar100 (See Table 3) the EMA ensemble offers considerable improvements for ER, RAR, DER and MIR
(from 4.0-7.8%). The improvements are less consequent for ER-ACE , but still important (2.5%). We hypotesize that
the smaller gain is due to the smaller task-recency bias of ER-ACE . This is illustrated in Figure 2 and Figure 3. In
these two figures on the left, we see that the performance of RAR on task 1 data drops instantly after learning task 1,
which means it has been traded for accuracy on task 2, it suffers from the task-recency bias. Whereas for ER-ACE, the
performance on task 1 does not drop as much after learning task 1, thus the gap with the EMA augmented version is
not as important. This is also reflected in Table 3. In these figures as well, we can see how the use of the EMA model
improves the stability, both by looking at the WC-Acc but also at the reduced accuracy variations on a single task.
OnSplit-MiniImagenet , we see the largest performance improvements. This time, RAR sees similar gains than ER
(9.3% and 10%), while ER-ACE gains are also more important than in the case of Split-Cifar100. This is coherent
with the observations that we had in the motivational experiments (Figure 1) that the gains from ensembling are slightly
7

--- PAGE 8 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
Figure 3: Split-Cifar100, validation accuracy on task 1 data (Left), Average Anytime Accuracy AAA t(Middle) and
WC-ACC (Right), for RAR and its EMA augmented version, using 2000 memory. Mean and standard deviation are
computed over 6 runs.
0 1000 2000 3000 4000
Iterations0.20.30.40.50.6AccuracyER
ER+EMA
ER-ACE
ER-ACE+EMA
RAR
RAR+EMA
Figure 4: Comparison of the average accuracy on the validation data of three methods trained on Split-MiniImagenet
(20 tasks), and their EMA augmented version. EMA performance is indicated with the dotted lines. We report the
mean and standard deviation over 6 runs.
more important in the case of Split-MiniImagenet. This might also be due to the memory size used that is different
from the one used for Split-Cifar100. In Figure 4, we show a comparison of three methods and their EMA augmented
version. We notice that in that case, the use of ER-ACE hurts the performance of the EMA model, which performs
worse than just using ER and EMA. Also, for ER and RAR, we notice various bumps in the validation accuracy2of
the EMA model that are not present in the current model accuracy. We believe these bumps occur when the previous
task bias is compensated by bias towards the current task. The location and width of these bumps depend on the λ
parameter chosen for the exponential moving average (for more analysis see Appendix 7).
Effect on the task-recency bias: In Figure 6, we display the task confusion matrices of RAR, for the final training
model, the final EMA model, and the EMA model taken at the tip of the bump (selected using a hold-out validation
memory mechanism). The matrix shows the number of test images from a particular task (y-axis) that are classified
as being from another task (x-axis). For the last training model, a lot of samples are predicted to be in the last task as
indicated by the last column, which shows an important task-recency bias. For the final EMA model, the task-recency
2More generally we observe these bumps on all the studied datasets and report them for Split-MiniImagenet and Split-Cifar100
in the Appendix Figure 4 and Figure 7
8

--- PAGE 9 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
Split-Cifar10 Split-Cifar100
Method Acc↑ AAAval↑WC-Accval↑RAGval↓ Acc↑ AAAval↑WC-Accval↑RAGval↓
i.i.d 65.2±1.8 23.4±0.7
i.i.d+EMA67.3±1.3 25.8±0.6
+2.1 +2.4
i.i.dw/tr 71.2±1.4 32.3±1.0
i.i.d+EMA
w/tr75.5±1.3 37.2±0.8
+4.3 +4.9
ER 37.5±1.6 57.3 ±0.6 26.0 ±1.0 31.0 ±5.6 9.9±0.6 22.5 ±0.8 5.8 ±0.4 43.0 ±3.4
ER+EMA38.8±1.3 59.9 ±0.7 35.1 ±1.1 9.9 ±1.5 14.0±0.5 29.2 ±0.9 13.1 ±0.7 5.6 ±1.6
+1.2 +2.6 +9.1 -21.1 +4.1 +6.7 +7.3 -37.4
MIR 40.2±2.8 54.0 ±0.4 17.0 ±0.6 57.1 ±4.4 10.6±0.7 22.8 ±0.7 6.3 ±0.4 39.6 ±3.0
MIR+EMA42.7±2.1 55.9 ±4.2 34.5 ±1.5 19.7 ±4.8 14.9±0.4 28.8 ±0.9 14.3 ±0.6 5.4 ±1.4
+2.5 +1.9 +7.5 -37.4 +4.3 +6.0 +8.0 -34.2
ER-ACE 50.2±1.2 62.7 ±1.4 34.6 ±2.0 29.9 ±4.8 16.5±0.7 27.7 ±0.6 10.3 ±0.4 38.7 ±3.3
ER-ACE+EMA51.5±1.6 64.6 ±1.4 48.7 ±1.9 4.6 ±0.8 19.0±0.3 30.7 ±0.6 15.3 ±0.6 20.9 ±3.5
+1.3 +1.9 +14.1 -25.2 +2.5 +3.0 +5.0 -17.8
DER ++ 51.1±3.0 56.4 ±1.6 17.9 ±0.6 64.5 ±2.9 18.2±0.7 24.7 ±1.0 4.5 ±0.6 75.8 ±3.2
DER+EMA
++ 53.1±3.7 59.5 ±1.7 36.4 ±1.1 30.6 ±3.5 23.2±1.2 35.0 ±1.3 19.7 ±0.9 16.7 ±2.3
+2.0 +3.2 +18.5 -33.9 +5 +10.3 +15.2 -59.1
RAR 63.0±1.4 67.3 ±0.9 28.2 ±2.9 55.1 ±4.1 27.6±1.3 32.5 ±1.5 11.8 ±0.9 57.0 ±1.8
RAR+EMA67.3±0.8 72.4 ±0.8 60.5 ±1.1 10.1±1.5 35.4±1.2 42.6 ±2.1 32.4 ±1.7 7.9±0.9
+4.3 +4.9 +32.3 -40.0 +7.8 +10.1 +20.6 -49.9
Table 3: Comparison of the final average accuracy on the test set and continual evaluation metrics on the validation
set for various methods with their EMA model augmented version, on Split Cifar10 (Left) and Split Cifar100 (Right).
Split-MiniImagenet
Method Acc↑ AAAval↑WC-Accval↑RAGval↓
i.i.d 29.9±2.2
i.i.d+EMA34.9±1.6
+5.0
i.i.dw/tr 32.3±1.7
i.i.d+EMA
w/tr39.9±1.1
+7.6
ER 26.2±0.2 33.9 ±0.7 11.0 ±0.9 59.6 ±2.2
ER+EMA36.3±1.1 44.3 ±0.9 34.2 ±0.6 7.9 ±1.4
+10.1 +10.4 +13.2 -51
MIR 27.3±1.7 33.9 ±0.4 9.6 ±0.9 66.3 ±2.3
MIR+EMA36.1±1.2 43.5 ±0.8 34.0 ±1.4 8.6 ±2.0
+8.8 +9.6 +24.4 -57.7
ER-ACE 27.4±1.7 35.3 ±0.5 12.9 ±0.9 54.2 ±2.6
ER-ACE+EMA34.5±0.8 41.0 ±0.8 19.8 ±1.1 44.6 ±1.8
+7.0 +5.7 +6.9 -9.6
DER ++ 18.4±1.8 20.3 ±2.6 4.0 ±0.4 78.5 ±1.5
DER+EMA
++ 23.3±2.3 29.4 ±2.9 17.8 ±3.3 25.0 ±6.9
+4.9 +9.1 +13.8 -53.5
RAR 29.1±0.8 33.8 ±0.8 11.4 ±0.5 61.6 ±2.1
RAR+EMA38.4±0.8 44.9 ±0.4 35.6 ±0.4 11.6±1.7
+9.3 +11.1 +24.2 -60.0
Table 4: Comparison of the final average accuracy on the
test set and continual evaluation metrics on the validation
set for various methods along with their EMA model aug-
mented version, on Split-MiniImagenet.
RARi.i.dw/trRAR+EMA
i.i.d+EMA
w/tr2025303540Accuracy
RARi.i.dw/trRAR+EMA
i.i.d+EMA
w/tr2025303540AccuracyFigure 5: Comparison of previous state-of-the-
art method in online continual learning RAR
against the reference method i.i.dw/tr on Split-
Cifar100 (Top) using 2000 memory and Split-
Minimnet using 10000 memory (Bottom). The
performance gap is indicated in green, and is
greatly reduced by the use of EMA.
bias is also present though slightly diminished, but for the best selected EMA model, it is almost absent, confirming
our hypothesis about the origin of the bump3.
3Note that all our results are based on the finishing point of training, which does typically not coincide with the bump.
9

--- PAGE 10 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
0123456789101112131415161718190
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
0123456789101112131415161718190
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
0123456789101112131415161718190
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
Figure 6: Task Confusion matrices computed on the test set after training of the last task for RAR on Split-
MiniImagenet (20 tasks), final training model (Left), RAR+EMA model (Middle), and RAR+EMA model taken at
the tip of the bumps observed in Figure 4 (Right). Note the drop in task-recency bias from RAR (a) to RAR+EMA (b)
as a consequence of ensembling.
Comparison with the gains in online i.i.d setting: When applied on the reference methods i.i.d andi.i.dw/tr, the use
of EMA model at evaluation also improves the results by a good margin, showing that the gains obtained in continual
learning are not only due to continual-learning based improvements (like reducing the task-recency bias), but also on
more general online-learning improvements. However, we observe in general higher gains in continual learning than
in the i.i.d setting, except on Split-Cifar10, where they are equivalent, showing that the adaptation of the momentum
parameter to the distribution drift speed is essential to get continual learning related gains. To illustrate the higher
gains in continual learning, we highlight the gap in final accuracy between previous state-of-the-art method (RAR),
and the i.i.dw/tr baseline, along with the EMA augmented versions (See Figure 5). We see that for two of the studied
datasets, the gap between RAR andi.i.dw/tr is reduced by the use of the EMA model. For Split-Cifar100, an initial
4.7% gap is reduced to a 1.8% gap, while for Split-MiniImagenet, an initial 3.2% gap is reduced to a 1.5% gap.
Effect on the stability metrics: Finally, for all methods and on all datasets, the AAA and the WC-Acc are greatly
improved by the use of EMA, which shows that aside from raising the accuracy, the EMA model offers an important
stability boost. We illustrate this effect by showing one single task accuracy curve along with the WC-Acc curve
during training in Figure 2 and Figure 3. We see that in both cases both the fluctuations due to small-batch training
and the bigger fluctuations due to task shift are reduced by the use of the EMA ensemble. We also present a detailed
analysis of stability at the level of a single task shift in Appendix (Figure 10). In general, the biggest increase in
WC-Acc also correspond to the biggest decrease in Relative Accuracy Gap (RAG ), and is significant, confirming that
the increase in WC-Acc is not due to an increase in average accuracy, but due to a better stability.
7 C ONCLUSION
We investigate the effect of employing temporal ensembling methods, such as EMA, in online continual learning. This
direction is particularly interesting because of the distinctive nature of this combination. In online continual learning,
temporal ensembles offer the potential to combine models from various training tasks, leading to novel dynamics that
cannot be achieved in classical offline learning, where every model ensemble is trained on the same distribution. In
the experiments, we show that temporal ensembles can greatly improve continual learning performance and stability.
To circumvent the increased memory requirements for the usage of ensembles, we propose to use a memory efficient
ensembling solution for online continual learning. We report results using this method in combination with other state-
of-the-art methods and conclude that this method consistently increases the final performance and overall stability of
several replay methods, closing in on the performance that can be reached in the i.i.d setting. Most surprisingly, we
do this without affecting the training process but just by ensembling models from the training trajectory.
We hope that this work inspires the design of more robust ensembling methods for continual learning. In particular, it
would be important to find a similarly efficient method that allows to decorrelate the number of training iteration from
the number of tasks, since it could then be applied for arbitrary number of iterations per task while similarly covering
as many previous tasks as possible. Another future direction could focus on impacting the training using such kind of
ensembles, for instance by combining it with distillation4.
Acknowledgements: We acknowledge the support of the Grant PID2019-104174GB-I00 funded by MCIN/AEI/
10.13039/501100011033 and Grant PID2021-128178OB-I00 funded by MCIN/AEI/ 10.13039/501100011033 and
by ERDF A way of making Europe, Ram ´on y Cajal fellowship Grant RYC2019-027020-I funded by MCIN/AEI/
4We provide comments about the application of distillation in combination with EMA model in the Appendix (Section A.4).
10

--- PAGE 11 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
10.13039/501100011033 and by ERDF A way of making Europe, and the CERCA Programme of Generalitat de
Catalunya. Antonio Carta was partially supported by the H2020 project TAILOR (952215) Connectivity Fund.
REFERENCES
Rahaf Aljundi, Eugene Belilovsky, Tinne Tuytelaars, Laurent Charlin, Massimo Caccia, Min Lin, and Lucas Page-
Caccia. Online continual learning with maximal interfered retrieval. In H. Wallach, H. Larochelle, A. Beygelz-
imer, F. d'Alch ´e-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Information Processing Systems , vol-
ume 32. Curran Associates, Inc., 2019a. URL https://proceedings.neurips.cc/paper/2019/
file/15825aee15eb335cc13f9b559f166ee8-Paper.pdf .
Rahaf Aljundi, Klaas Kelchtermans, and Tinne Tuytelaars. Task-free continual learning. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 11254–11263, 2019b.
Eden Belouadah and Adrian Popescu. Il2m: Class incremental learning with dual memory. In Proceedings of the
IEEE/CVF international conference on computer vision , pp. 583–592, 2019.
Eden Belouadah, Adrian Popescu, and Ioannis Kanellos. A comprehensive study of class incremental learning algo-
rithms for visual tasks. Neural Networks , 135:38–54, 2021.
Leo Breiman. Bagging predictors. Machine learning , 24:123–140, 1996.
Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, and SIMONE CALDERARA. Dark experi-
ence for general continual learning: a strong, simple baseline. In H. Larochelle, M. Ranzato, R. Hadsell,
M.F. Balcan, and H. Lin (eds.), Advances in Neural Information Processing Systems , volume 33, pp. 15920–
15930. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/
b704ea2c39778f07c617f6b7ce480e9e-Paper.pdf .
Lucas Caccia, Rahaf Aljundi, Nader Asadi, Tinne Tuytelaars, Joelle Pineau, and Eugene Belilovsky. New insights
on reducing abrupt representation change in online continual learning. In International Conference on Learning
Representations , 2022. URL https://openreview.net/forum?id=N8MaByOzUfb .
Massimo Caccia, Pau Rodriguez, Oleksiy Ostapenko, Fabrice Normandin, Min Lin, Lucas Page-Caccia, Issam Hadj
Laradji, Irina Rish, Alexandre Lacoste, David V ´azquez, and Laurent Charlin. Online fast adaptation and knowledge
accumulation (osaka): a new approach to continual learning. In H. Larochelle, M. Ranzato, R. Hadsell, M.F.
Balcan, and H. Lin (eds.), Advances in Neural Information Processing Systems , volume 33, pp. 16532–16545.
Curran Associates, Inc., 2020.
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv ´e J´egou, Julien Mairal, Piotr Bojanowski, and Armand Joulin.
Emerging properties in self-supervised vision transformers. In Proceedings of the IEEE/CVF international confer-
ence on computer vision , pp. 9650–9660, 2021.
Francisco M Castro, Manuel J Mar ´ın-Jim ´enez, Nicol ´as Guil, Cordelia Schmid, and Karteek Alahari. End-to-end
incremental learning. In Proceedings of the European conference on computer vision (ECCV) , pp. 233–248, 2018.
Arslan Chaudhry, Marcus Rohrbach, Mohamed Elhoseiny, Thalaiyasingam Ajanthan, Puneet K Dokania, Philip HS
Torr, and Marc’Aurelio Ranzato. Continual learning with tiny episodic memories. ICML Workshop: Multi-Task
and Lifelong Reinforcement Learning , 2019.
Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ale ˇs Leonardis, Gregory Slabaugh, and Tinne
Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEE transactions on pattern
analysis and machine intelligence , 44(7):3366–3385, 2021.
Thomas G Dietterich. Ensemble methods in machine learning. In Multiple Classifier Systems: First International
Workshop, MCS 2000 Cagliari, Italy, June 21–23, 2000 Proceedings 1 , pp. 1–15. Springer, 2000.
Thang Doan, Seyed Iman Mirzadeh, and Mehrdad Farajtabar. Continual learning beyond a single model, 2022. URL
https://arxiv.org/abs/2202.09826 .
Jonathan Frankle, Gintare Karolina Dziugaite, Daniel Roy, and Michael Carbin. Linear mode connectivity and the
lottery ticket hypothesis. In International Conference on Machine Learning , pp. 3259–3269. PMLR, 2020.
Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. Deep learning , volume 1. MIT Press, 2016.
11

--- PAGE 12 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
Ian J Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, and Yoshua Bengio. An empirical investigation of catas-
trophic forgetting in gradient-based neural networks. In Proc. Int. Conf. Learn. Repres. , 2014.
Jean-Bastien Grill, Florian Strub, Florent Altch ´e, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Do-
ersch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar, et al. Bootstrap your own latent-a new
approach to self-supervised learning. Advances in neural information processing systems , 33:21271–21284, 2020.
Lars Kai Hansen and Peter Salamon. Neural network ensembles. IEEE transactions on pattern analysis and machine
intelligence , 12(10):993–1001, 1990.
Saihui Hou, Xinyu Pan, Chen Change Loy, Zilei Wang, and Dahua Lin. Learning a unified classifier incrementally
via rebalancing. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp.
831–839, 2019.
Gao Huang, Yixuan Li, Geoff Pleiss, Zhuang Liu, John E Hopcroft, and Kilian Q Weinberger. Snapshot ensembles:
Train 1, get m for free. arXiv preprint arXiv:1704.00109 , 2017.
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran
Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic forgetting in
neural networks. Proceedings of the national academy of sciences , 114(13):3521–3526, 2017.
Hyunseo Koh, Dahyun Kim, Jung-Woo Ha, and Jonghyun Choi. Online continual learning on class incremental blurry
task configuration with anytime inference. In International Conference on Learning Representations , 2022. URL
https://openreview.net/forum?id=nrGGfMbY_qK .
Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, 2009.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural
networks. Communications of the ACM , 60(6):84–90, 2017.
Matthias De Lange, Gido M van de Ven, and Tinne Tuytelaars. Continual evaluation for lifelong learning: Identifying
the stability gap. In The Eleventh International Conference on Learning Representations , 2023. URL https:
//openreview.net/forum?id=Zy350cRstc6 .
Sang-Woo Lee, Jin-Hwa Kim, Jaehyun Jun, Jung-Woo Ha, and Byoung-Tak Zhang. Overcoming catastrophic forget-
ting by incremental moment matching. Advances in neural information processing systems , 30, 2017.
Vincenzo Lomonaco, Lorenzo Pellegrini, Andrea Cossu, Antonio Carta, Gabriele Graffieti, Tyler L. Hayes,
Matthias De Lange, Marc Masana, Jary Pomponi, Gido van de Ven, Martin Mundt, Qi She, Keiland Cooper, Jeremy
Forest, Eden Belouadah, Simone Calderara, German I. Parisi, Fabio Cuzzolin, Andreas Tolias, Simone Scardapane,
Luca Antiga, Subutai Amhad, Adrian Popescu, Christopher Kanan, Joost van de Weijer, Tinne Tuytelaars, Davide
Bacciu, and Davide Maltoni. Avalanche: an end-to-end library for continual learning. In Proceedings of IEEE
Conference on Computer Vision and Pattern Recognition , 2nd Continual Learning in Computer Vision Workshop,
2021.
David Lopez-Paz and Marc' Aurelio Ranzato. Gradient episodic memory for continual learning. In I. Guyon, U. V .
Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information
Processing Systems , volume 30. Curran Associates, Inc., 2017.
Marc Masana, Xialei Liu, Bartłomiej Twardowski, Mikel Menta, Andrew D Bagdanov, and Joost van de Weijer. Class-
incremental learning: survey and performance evaluation on image classification. IEEE Transactions on Pattern
Analysis and Machine Intelligence , 2022.
Michael McCloskey and Neal J Cohen. Catastrophic interference in connectionist networks: The sequential learning
problem. In Psychology of learning and motivation . 1989.
Michael P Perrone and Leon N Cooper. When networks disagree: Ensemble methods for hybrid neural networks. In
How We Learn; How We Remember: Toward An Understanding Of Brain And Neural Systems: Selected Papers of
Leon N Cooper , pp. 342–358. World Scientific, 1995.
Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H Lampert. icarl: Incremental classifier
and representation learning. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition ,
pp. 2001–2010, 2017.
12

--- PAGE 13 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej
Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. ImageNet Large Scale Vi-
sual Recognition Challenge. International Journal of Computer Vision (IJCV) , 115(3):211–252, 2015. doi:
10.1007/s11263-015-0816-y.
Laine Samuli and Aila Timo. Temporal ensembling for semi-supervised learning. In International Conference on
Learning Representations (ICLR) , volume 4, pp. 6, 2017.
Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve
semi-supervised deep learning results. Advances in neural information processing systems , 30, 2017.
Gido M van de Ven and Andreas S Tolias. Three scenarios for continual learning. In NeurIPS Continual Learning
Workshop , 2018.
Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al. Matching networks for one shot learning.
Advances in neural information processing systems , 29, 2016.
Yeming Wen, Dustin Tran, and Jimmy Ba. Batchensemble: an alternative approach to efficient ensemble and lifelong
learning. arXiv preprint arXiv:2002.06715 , 2020.
Mitchell Wortsman, Maxwell C Horton, Carlos Guestrin, Ali Farhadi, and Mohammad Rastegari. Learning neural
network subspaces. In Marina Meila and Tong Zhang (eds.), Proceedings of the 38th International Conference on
Machine Learning , volume 139 of Proceedings of Machine Learning Research , pp. 11217–11227. PMLR, 18–24
Jul 2021. URL https://proceedings.mlr.press/v139/wortsman21a.html .
Yue Wu, Yinpeng Chen, Lijuan Wang, Yuancheng Ye, Zicheng Liu, Yandong Guo, and Yun Fu. Large scale incre-
mental learning. In Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , 2019.
Yaqian Zhang, Bernhard Pfahringer, Eibe Frank, Albert Bifet, Nick Jin Sean Lim, and Alvin Jia. A simple but
strong baseline for online continual learning: Repeated augmented rehearsal. In Alice H. Oh, Alekh Agarwal,
Danielle Belgrave, and Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems , 2022. URL
https://openreview.net/forum?id=bhvUOhnsgZ .
A A PPENDIX
A.1 D ETAILS ABOUT HYPERPARAMETER CHOICE FOR EMA MODEL
Hyperparameter choice. In all of our experiments, we chose a λof 0.99 for the EMA model, and additionally warm
up the EMA model in the first few iterations by setting this parameter to 0.9 in the beginning. This parameter tells
us about the horizon of the EMA model. Since we were interested in an ensemble that covers several experiences,
we chose an horizon parameter that is high enough so that the EMA model gives non-negligible weights to previous
tasks. However, this process has a flaw since it requires to know how many iterations the learner is going to perform
on a given task, which is not suppose to happen in continual learning or in online learning. Nevertheless, we believe
more practical solutions can be applied to tune this parameter but we did not investigate them. We think the choice
of this parameter should depend on the speed at which the input distribution changes, which might be captured by
some other mechanism, we leave this direction to future works. In our experiments, we saw that a relatively wide
range of parameters between 0.95 and 0.995 were working correctly and always boosting the accuracy in more or less
significative ways. We present results for varying λon Split-Cifar100 in Figure 7. We see in that figure that increasing
λuntil the accuracy bump discussed in Section 6 disappears is overall beneficial for the final average accuracy, but
this might not be possible to do in practice when not knowing the amount of data to be received from each class. Also,
higher λvalues, while beneficial for the final average accuracy, affect negatively the accuracy for earlier tasks. One
work around to that problem would be to tune λprogressively according to the number of already seen classes vs the
number of new coming classes.
The accuracy bumps that we observe in various figures when looking at the average accuracy indicate that the gains
that we report in the tables could be bigger if we would retain the model at the tip of the bump. However, this requires
the use of a hold-out validation memory and an additional copy of the model on disk. In Figure 6, we retain the model
using the above technique of validation memory and observe that these bumps correspond to a lower task-recency bias
in the saved EMA model.
Trade-off. This choice of lambda also highlights a problem of this method that makes it difficult to export to non-
online learning. It is its dependency on the number of training iterations. Indeed, choosing a higher λincreases the
13

--- PAGE 14 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
0 1000 2000 3000 4000
Iterations0.10.20.30.40.50.60.70.8Accuracy0.95
0.96
0.97
0.98
0.99
0.992
0.995
Figure 7: Comparison of the results obtained for various λvalues of the EMA model on Split-Cifar100 (20 tasks) for
ER. Each curve depicts the average accuracy of the EMA model using a different λon all tasks seen so far. The value
we chose in our experiments (0.99) is not optimal but nor do we have a way of chosing the optimal one. Mean and
standard deviation are computed over 3 seeds.
time horizon of the method, but also has negative effects for several reasons. First of all, it is not clear how high of a λ
can be chosen before the performance of the ensemble decreases since giving too much weights to single models that
are too far in the weight space from the last model might break the assumption that summing models in the weight
space leads to a model with accuracy equivalent to the ensemble of these two models Wortsman et al. (2021). This
assumption is believed to be true as long as two models are connected by a linear path of low loss, and it is possible that
two models that are far away from each other do not respect this constraint. Secondly, it would be a nice addition to be
able to sum models obtained after each training batch, or even every training task (instead of each training iteration,
since several iterations can be performed on the same training batch in online learning). However for the same reason
invoking linear connectivity properties, it is not clear that this would work any better than increasing the momentum
value in the computation of the exponential moving average.
Task Covering. For the chosen parameter value, on Split-Cifar100, we can compute the total amount of weight
assigned to each task. From Eq. 6, we deduce the weight for a single member in the ensemble θiis(1−λ)λt−iwhere
tis the iteration of the current training model. We can sum this over the iterations covering one task. If we place
ourselves at the end of one task, with λ= 0.99(value used in our experiments) we get 88% of the weights in the last
task,9%of the weight in the previous task, and 1%in the second last task. This indicates that a majority of the weights
are assigned to later tasks (in particular from last task to second last task). However, we argue here that as the mean
can be highly influenced by outliers, the exponential moving average is nothing else than a weighted mean, and can
be influenced by outliers as well. Since the distance in the weight space between models from different tasks is more
important than the one between models from the same task, it is possible that earlier models influence more strongly
the current moving average than what we could believe by looking at the weights value.
A.2 D ETAILS ABOUT THE MOTIVATIONAL EXPERIMENT
Figure 1 shows the comparison between ensembles of models that cover a different number of tasks. To perform this
comparison, we first train a model continually using a dedicated continual learning method (ER and ER-ACE in that
case), along the way, we save model checkpoints every 10 iterations, leaving about 460 model checkpoints at the end
of learning the task (22 models per task in the case of Split-Cifar100 20 tasks). Then, for each number of tasks covered,
we select a subset of models that cover no more than that number of tasks, and sample 20 models from that subset
that we join into an ensemble for which we record the test performance. We sample 10 of such ensembles for every
14

--- PAGE 15 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
Figure 8: Schema of the motivational experiment ensemble (Left) and of the Exponential Moving Average ensemble
(Right). For the EMA ensemble, a continuum of models is inserted in the ensemble which only occupies as much
space as one additional model in the memory. Weights of previous model checkpoints decrease exponentially. This
procedure permits to cover a spectrum of different tasks in online continual learning.
x-axis value to get mean and confidence interval that we report in the figure. We always add a model in the ensemble
which is the last training checkpoint, so that we can always give an accuracy number to later classes when sampling
models. The ensembling of models coming from different tasks is done in the following way. We first compute the
output probabilities that each model gives to the input. We then compute the per-class mean probability, it is possible
that one class is predicted different number of times than another class by the ensemble, so we take that into account
and divide the sum of the probabilities for that class by the number of models in the ensemble that can predict that
class.
A.3 S UPPLEMENTARY MATERIAL ABOUT THE STABILITY GAP
Here we show several continual evaluation curves (see Figure 9). All of these curves were created by evaluating the
model on a hold-out validation set which is 5%of the training set size. The evaluation is performed after training for
3 iterations on each mini-batch before dropping it, as required by the constraints of online learning.
In Figure 10, we compare the accuracy of RAR (Zhang et al., 2022) and RAR+EMA on the data of two subsequent
tasks during the task shift. We see that the current training model instantly loses accuracy on previous task at the
task shift before regaining part of this accuracy later in training. This results in an important stability gap since the
accuracy on previous task reaches a low point during training before going back to ”normal”. This observation is
coherent with the one made in Lange et al. (2023). The orange curves indicate the performance of the EMA model on
the same tasks. We see that the EMA models takes longer to get good performance on new task but ends up getting
better performance than the training model. EMA models also displays improved stability (performance on previous
task is smoothly going from initial to final performance).
A.4 A TTEMPTS AT USING EMA MODEL FOR DISTILLATION
Tarvainen & Valpola (2017) initially introduced the EMA model in order to use it as a teacher model in semi-supervised
learning. They find that distilling knowledge from the EMA model to the student is beneficial in that setting. We
likewise tried to apply distillation by using the EMA model as a teacher, however we found that gains obtained by this
method (when present) were not robust enough to be reported. In Table 5, we report the student and teacher (EMA)
performance when using, and not using, Mean-Teacher distillation (See Eq. 8). We found that some improvements
could be observed in combination with simple ER on Split-Cifar100 both in terms of student and teacher performance,
however these improvements did not generalize to Split-MiniImagenet, neither do they combine well with a stronger
method like RAR. Notably, in the case of ER+MTD for Split-MiniImagenet and RAR +MTD for both datasets, we
observe that the final accuracy of the student is only slightly modified by the distllation process (sometimes increased,
sometimes decreased), but the accuracy of the teacher is decreased consequently to its application, this indicates that
the distillation process might reduce the diversity of the EMA ensemble by pulling models from the training trajectory
closer from one another.
LCE(fθ(x), y) +αLCE(fθ(x), fθEMA (x)) (8)
15

--- PAGE 16 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
0 1000 2000 3000 4000
Iterations0.10.20.30.40.50.60.70.8AccuracyER
ER+EMA
ER-ACE
ER-ACE+EMA
RAR
RAR+EMA
Figure 9: Comparison of the average accuracy on the validation data of three methods trained on Split-Cifar100 (20
tasks), and their EMA augmented version. EMA performance is indicated with the dotted lines. We report the Mean
and standard deviation over 6 runs
1700 1800 1900 2000 2100 2200
Iterations0.00.20.40.60.8Accuracy
RAR T2
RAR + EMA T2
RAR T3
RAR + EMA T3
Figure 10: Split-Cifar10, validation accuracy on task 2 data and task 3 data at task shift (indicated with dotted black
line). In blue, the accuracy for the training model, in orange, the accuracy for the EMA model. Solid lines indicate
accuracy on task 2 data while dotted lines indicate accuracy on task 3 data.
16

--- PAGE 17 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
Method Split Cifar100 Split MiniImagenet
Acc Acc
ER 9.9±0.6 26.2±0.2
ER(EMA) 14.0±0.5 36.3±1.1
ER+MTD 14.7±0.5 27.1±2.1
ER+MTD (EMA) 19.0±0.4 33.5±1.4
RAR 27.6±1.3 29.1±0.8
RAR (EMA) 35.4±1.2 38.4±0.8
RAR +MTD 27.0±1.0 27.1±2.5
RAR +MTD (EMA) 32.7±0.9 33.4±2.5
Table 5: Mean Teacher distillation results for teacher and non teacher on Split-Cifar100 (20 Tasks) (Left) and Split-
MiniImagenet (Right). Mean and standard deviation are reported over 6 seeds.
B C OMPARISON OF MEMORY USAGE WITH AND WITHOUT THE USE OF EMA MODEL
We include a comparison of memory overhead induced by the use of EMA across all datasets (see Table 6). Using
EMA model at evaluation requires to store an additional model. In terms of relative memory usage increase, it is more
interesting to use EMA model for larger datasets for which exemplars require more memory to store (MiniImagenet)
than for small datasets like Cifar. The methods we compare in this article do not differ significantly from each other in
terms of memory usage since they all use replay with the same number of exemplars, this is why we omit them from
the comparison.
Method Split Cifar10 Split Cifar100 Split MiniImagenet
Memory Exemplars Model Exemplars Model Exemplars Model
w/o EMA 3 Mb 4 Mb 6 Mb 4 Mb 211 Mb 4 Mb
w/ EMA 3 Mb 8 Mb 6 Mb 8 Mb 211 Mb 8 Mb
Table 6: Memory usage for the considered datasets and for the exemplars used in our experiments (1000, 2000 and
10000 for the three datasets respectively).
17

--- PAGE 18 ---
Published at 2nd Conference on Lifelong Learning Agents (CoLLAs), 2023
0 1000 2000 3000 4000
i0.000000.000250.000500.000750.001000.001250.001500.001750.00200wiEMA =0.99
EMA =0.995
EMA =0.999
Uniform
Linear
Quadratic
Logarithmic
Figure 11: Curve showing the evolution of different weighting schemes ( wi) under the form described in Equation 7.
We compare the performance of these weighting schemes in Section 4. We observe here that EMA with a high lambda
leads to a weighting that looks similar to quadratic weighting. To draw these curves we place ourselves at the last
training iteration ( θtlast
ensemble)
0 1000 2000 3000 4000
Iterations0.10.20.30.40.50.60.7AccuracyQuadratic
EMA =0.995
Figure 12: WC-ACC tfor Quadratic vs EMA with λ= 0.995in combination with ER on Split-Cifar100 dataset. We
see that the quadratic weighting scheme gives more interesting stability (in terms of WC-ACC t) in the first few tasks,
but then fails short compared to the EMA ensemble.
18

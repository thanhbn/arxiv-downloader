# Dynamic Y-KD: Một Phương Pháp Lai Cho Phân Đoạn Thể Hiện Liên Tục

Mathieu Pagé Fortin, Brahim Chaib-draa
Đại học Laval, Canada
mathieu.page-fortin.1@ulaval.ca, brahim.chaib-draa@ift.ulaval.ca

## Tóm tắt

Mặc dù các mô hình học sâu đã thành công trong phân đoạn thể hiện, các phương pháp hiện tại vẫn gặp phải vấn đề quên thảm khốc trong các tình huống học liên tục. Trong bài báo này, các đóng góp của chúng tôi cho phân đoạn thể hiện liên tục có ba khía cạnh. Thứ nhất, chúng tôi đề xuất Y-knowledge distillation (Y-KD), một kỹ thuật chia sẻ một bộ trích xuất đặc trưng chung giữa mạng giáo viên và học sinh. Khi giáo viên cũng được cập nhật với dữ liệu mới trong Y-KD, tính dẻo dai tăng lên dẫn đến các module mới chuyên môn hóa cho các lớp mới. Thứ hai, phương pháp Y-KD của chúng tôi được hỗ trợ bởi một phương pháp kiến trúc động huấn luyện các module cụ thể cho tác vụ với một đầu phân đoạn thể hiện duy nhất, do đó giảm đáng kể việc quên. Thứ ba, chúng tôi hoàn thiện phương pháp bằng cách tận dụng tính trung bình checkpoint như một phương pháp đơn giản để cân bằng thủ công sự đánh đổi giữa hiệu suất trên các tập lớp khác nhau, từ đó tăng khả năng kiểm soát hành vi của mô hình mà không tốn thêm chi phí. Những đóng góp này được kết hợp trong mô hình mà chúng tôi đặt tên là mạng Dynamic Y-KD.

Chúng tôi thực hiện các thí nghiệm mở rộng trên nhiều tình huống học tăng dần một bước và nhiều bước, và cho thấy phương pháp của chúng tôi vượt trội hơn các phương pháp trước đây trên cả các lớp cũ và mới. Ví dụ, so với công trình gần đây, phương pháp của chúng tôi đạt được +2.1% mAP trên các lớp cũ trong 15-1, +7.6% mAP trên các lớp mới trong 19-1 và đạt 91.5% mAP thu được bởi huấn luyện chung trên tất cả các lớp trong 15-5.

## Giới thiệu

Phân đoạn thể hiện, tác vụ phát hiện và phân đoạn từng đối tượng riêng lẻ trong hình ảnh, là một vấn đề cơ bản của thị giác máy tính có nhiều ứng dụng. Một số phương pháp dựa trên học sâu đã được đề xuất trong vài năm qua (Gu, Bai, và Kong 2022). Tuy nhiên, thường giả định rằng tập dữ liệu huấn luyện là cố định, sao cho việc huấn luyện có thể thực hiện trong một bước. Tình huống này gặp hạn chế khi triển khai trong các ứng dụng thế giới thực nơi môi trường có thể thay đổi hoặc các trường hợp sử dụng có thể phát triển để bao gồm các tập lớp mới (Lesort et al. 2020). Việc tăng cường các mô hình học sâu để giới thiệu các danh mục đối tượng mới là một nhiệm vụ thách thức vì các phương pháp này dễ bị quên thảm khốc (McCloskey và Cohen 1989); chúng trở nên thiên vị về các lớp mới trong khi kiến thức trước đó bị loại bỏ.

Thách thức của việc quên thảm khốc được gói gọn bởi tiến thoái lưỡng nan ổn định-dẻo dai (Wu, Gong, và Li 2021; Grossberg 1982): một mô hình học phải cân bằng việc bảo tồn kiến thức quá khứ (ổn định) với tính linh hoạt để tiếp thu kiến thức mới (dẻo dai). Tuy nhiên, hai khả năng này thường xung đột với nhau. Ví dụ, khi gradient descent cập nhật trọng số của mạng nơ-ron để học các danh mục mới, tính dẻo dai cao này cũng gây ra việc thay thế và triệt tiêu kiến thức trước đó (De Lange et al. 2021).

Do đó, học liên tục (CL) đang nhận được nhiều sự chú ý hơn vì nó nhằm mang các phương pháp học sâu đến thành công ngay cả trên các tập dữ liệu không ổn định. Công trình trước đây chủ yếu nghiên cứu CL cho phân loại (De Lange et al. 2021), và ít hơn cho phân đoạn ngữ nghĩa (Cermelli et al. 2020; Douillard et al. 2021) và phát hiện đối tượng (Menezes et al. 2023; Wang et al. 2021). Theo hiểu biết của chúng tôi, các công trình của Gu, Deng, và Wei (2021) và Cermelli et al. (2022) là những công trình duy nhất đề xuất các phương pháp phân đoạn thể hiện liên tục (CIS). Cả hai đều dựa hoàn toàn vào knowledge distillation (KD) (Hinton, Vinyals, và Dean 2015), một chiến lược dựa trên regularization phổ biến sử dụng mô hình từ bước trước làm mạng giáo viên để chưng cất kiến thức của nó vào mô hình mới, do đó giảm việc quên (xem Hình 1, hàng trên). Tuy nhiên, nhược điểm chính của KD là hiệu suất thường bị hạn chế (Menezes et al. 2023). KD ràng buộc mô hình để tăng tính ổn định nhưng điều này đi kèm với chi phí giảm tính dẻo dai, khiến các lớp mới khó học một cách tối ưu.

Để giải quyết vấn đề này, chúng tôi đề xuất trong bài báo này một chiến lược KD mới trong đó mạng giáo viên và học sinh chia sẻ một bộ trích xuất đặc trưng có thể huấn luyện chung, kết hợp với một mô hình kiến trúc động phát triển các module cụ thể cho tác vụ mới. Hai lựa chọn thiết kế này được thúc đẩy bởi một nghiên cứu sơ bộ làm nổi bật hai thuộc tính chính của Mask R-CNN được huấn luyện trong các tình huống tăng dần, cụ thể là 1) tính ổn định của bộ trích xuất đặc trưng và 2) tính tương thích của đầu với các bộ trích xuất đặc trưng trước đó (xem Hình 2). Chúng tôi đặt tên cho phương pháp lai của mình là mạng Dynamic Y-KD.

Trước khi học các lớp mới, mô hình từ bước trước được nhân đôi và chúng tôi chỉ đóng băng đầu phân đoạn thể hiện của giáo viên. Các hình ảnh huấn luyện sau đó được đưa vào bộ trích xuất đặc trưng chung và các bản đồ đặc trưng kết quả được gửi song song 1) đến đầu mới để huấn luyện và 2) đến đầu trước đó cho KD, do đó tạo thành một kiến trúc hình chữ Y (xem Hình 1) mà chúng tôi đặt tên là Y-knowledge distillation (Y-KD). Khi bộ trích xuất đặc trưng của mạng giáo viên được cập nhật liên tục, mạng học sinh được hưởng lợi từ tính dẻo dai cao hơn. Tính dẻo dai tăng này cho phép phát triển các module bộ trích xuất đặc trưng mới chuyên môn hóa cho các lớp mới.

Trong quá trình suy luận, các module chuyên môn được sử dụng với một đầu phân đoạn thể hiện duy nhất. Do đó, bằng cách phát triển các nhánh trích xuất đặc trưng cụ thể cho tác vụ để phù hợp với các danh mục mới, mô hình của chúng tôi có thể học các lớp mới hiệu quả hơn, và bằng cách sử dụng các module chuyên môn có trọng số được đóng băng trong các bước tăng dần, việc quên các lớp trước đó được giảm đáng kể. Đáng chú ý, kết quả của chúng tôi trên Pascal-VOC (Everingham et al. 2009) và nghiên cứu ablation cho thấy các thành phần của mạng Dynamic Y-KD tăng cường forward transfer (Menezes et al. 2023).

Hơn nữa, nếu chúng tôi đo hiệu suất của các phương pháp CL bằng tỷ lệ mean average precision (mAP) của chúng với một tương đương không phải CL (tức là huấn luyện chung) (Menezes et al. 2023), phương pháp của chúng tôi đạt được, trên các lớp cũ, 97.8% và 89.0% so với 94.7% và 83.7% đạt được bởi MMA (Cermelli et al. 2022) trên 19-1 và 15-1, tương ứng. Trên các lớp mới trong 15-5 và 10-2, phương pháp của chúng tôi đạt được 86.2% và 83.1% mAP huấn luyện chung, so với 78.9% và 77.5% đạt được với MMA, tương ứng.

Cuối cùng, được truyền cảm hứng từ nghiên cứu sơ bộ của chúng tôi làm nổi bật tính tương thích của các đầu tăng dần với các bộ trích xuất đặc trưng trước đó, chúng tôi tái sử dụng việc sử dụng checkpoint averaging (Huang et al. 2017; Gao et al. 2022) để cung cấp khả năng kiểm soát sự đánh đổi hiệu suất trên các tập lớp khác nhau trong CL. Kết quả của chúng tôi cho thấy chúng tôi có thể dễ dàng điều chỉnh mô hình để hoạt động tốt hơn trên một số tập lớp hoặc các tập khác. Điều này cung cấp một cơ chế kiểm soát đơn giản và có thể là một công cụ hữu ích trong việc phát triển các ứng dụng thế giới thực nơi một số lớp quan trọng hơn các lớp khác.

Tóm lại, các đóng góp của chúng tôi như sau:

• Chúng tôi làm nổi bật hai thuộc tính thú vị của Mask R-CNN liên quan đến 1) tính ổn định của bộ trích xuất đặc trưng, và 2) tính tương thích của các đầu phân đoạn thể hiện với các bộ trích xuất đặc trưng trước đó. Theo hiểu biết của chúng tôi, chúng tôi là những người đầu tiên đưa ra những quan sát này.

• Chúng tôi khai thác hai quan sát này để đề xuất 1) Y-KD, một chiến lược KD mới tăng tính dẻo dai bằng cách sử dụng bộ trích xuất đặc trưng chung, và 2) một kiến trúc động phát triển các bộ trích xuất đặc trưng cụ thể cho tác vụ mới được sử dụng với một đầu chung trong suy luận.

• Mạng Dynamic Y-KD của chúng tôi vượt trội đáng kể so với các phương pháp trước đây trên các tình huống tăng dần khác nhau của Pascal-VOC trên cả các lớp mới và cũ. Hơn nữa, chúng tôi tách biệt các đóng góp của từng thành phần trong một nghiên cứu ablation.

• Chúng tôi đề xuất checkpoint averaging, một cơ chế không tốn chi phí để kiểm soát sự đánh đổi giữa hiệu suất trên các lớp cũ, trung gian và mới sau huấn luyện.

## Công trình liên quan

### Phân đoạn thể hiện

Phân đoạn thể hiện là một vấn đề quan trọng trong thị giác máy tính nhằm tạo ra một mặt nạ phân đoạn duy nhất của các đối tượng thuộc về một tập lớp được định nghĩa trước. Một trong những phương pháp được áp dụng rộng rãi nhất là chiến lược "phát hiện rồi phân đoạn", được phổ biến bởi Mask R-CNN (He et al. 2017). Công trình gần đây về phân đoạn thể hiện đã khám phá các phương pháp thay thế như các phương pháp một giai đoạn (Bolya et al. 2019; Wang et al. 2020), và các kỹ thuật phức tạp hơn (Chen et al. 2019; Fang et al. 2021; Cheng et al. 2022). Tuy nhiên, ít công trình giải quyết việc quên thảm khốc khi các phương pháp này đối mặt với các tình huống CL.

Trong bài báo này, chúng tôi xây dựng dựa trên Mask R-CNN khi đề xuất một kiến trúc động phát triển các module mới của trích xuất đặc trưng chuyên môn trước RPN để giải quyết các hạn chế của các phương pháp hiện có và cải thiện hiệu suất của phân đoạn thể hiện trong các tình huống CL.

### Học liên tục

CL nghiên cứu các giải pháp để cho phép việc tăng cường các mô hình với các lớp mới mà không mất kiến thức đã tiếp thu trước đó. Các họ chiến lược CL chính thường được phân loại thành 1) dựa trên replay (Rebuffi et al. 2017; Maracani et al. 2021; Shieh et al. 2020; Maracani et al. 2021; Verwimp, De Lange, và Tuytelaars 2021), 2) dựa trên regularization (Cermelli et al. 2020, 2022; Liu et al. 2020; Kirkpatrick et al. 2017) và 3) các phương pháp dựa trên kiến trúc động, còn gọi là dựa trên cô lập tham số (Rusu et al. 2016; Aljundi, Chakravarty, và Tuytelaars 2017; Li et al. 2018; Zhang et al. 2021; Douillard et al. 2022). Trong các phần sau, chúng tôi tập trung vào các phương pháp dựa trên regularization và dựa trên kiến trúc động vì chúng tôi đề xuất một chiến lược lai giữa hai phương pháp này để xây dựng mạng Dynamic Y-KD của chúng tôi.

### Các phương pháp dựa trên Regularization

Vì việc quên thảm khốc là kết quả của sự trôi dạt trong các tham số của mô hình, điều này có thể được giảm thiểu bằng cách áp dụng các mất mát regularization cụ thể. Một trong những phương pháp dựa trên regularization được sử dụng rộng rãi nhất là knowledge distillation (KD) (Hinton, Vinyals, và Dean 2015), tận dụng các đầu ra của mô hình trước đó để hướng dẫn mô hình mới tạo ra các kích hoạt tương tự cho các danh mục trước đó.

Ví dụ, ILOD (Shmelkov, Schmid, và Alahari 2017) áp dụng một mất mát L2 trên các logits dự đoán của các lớp cũ và hộp giới hạn để ngăn mô hình mới chuyển đổi quá mức đầu ra của nó về phía các lớp mới. Trong Faster ILOD (Peng, Zhao, và Lovell 2020), một thuật ngữ chưng cất bổ sung được áp dụng trên các đặc trưng của RPN của Faster-RCNN (Girshick 2015) để có tính ổn định hơn. Một trong những công trình đầu tiên về CIS đã được đề xuất trong (Gu, Deng, và Wei 2021), trong đó KD được thực hiện bởi hai mạng giáo viên để tăng cường YOLACT (Bolya et al. 2019). Trong MiB (Cermelli et al. 2020), các tác giả đã điều chỉnh các mất mát KD và cross-entropy để tính đến sự dịch chuyển nền trong phân đoạn ngữ nghĩa liên tục. Trong MMA (Cermelli et al. 2022), các tác giả sau đó mở rộng những ý tưởng này cho các tác vụ phát hiện đối tượng liên tục và CIS với Faster R-CNN và Mask R-CNN tương ứng.

Trong công trình này, chúng tôi cũng tận dụng các mất mát KD với Mask R-CNN. Tuy nhiên, trái ngược với công trình trước đây nơi mạng giáo viên được đóng băng hoàn toàn, phương pháp của chúng tôi khác biệt vì bộ trích xuất đặc trưng được sử dụng cho KD được chia sẻ với mô hình học, và do đó được cập nhật liên tục trong quá trình học. Phương pháp này tăng cường tính dẻo dai và khả năng forward transfer của mô hình, như được chứng minh bởi kết quả cải thiện của chúng tôi trên các lớp mới và nghiên cứu ablation (xem Bảng 4 dòng 2 so với 5).

### Các phương pháp dựa trên Kiến trúc động

Các phương pháp này, còn được gọi là cô lập tham số, đóng băng một số phần của mạng (Li et al. 2018) và phát triển các nhánh mới để học các tác vụ mới (Zhang et al. 2021). Một trong những nhược điểm của chiến lược này là nó thường tăng dung lượng bộ nhớ ở mỗi bước. Một số công trình như (Zhang et al. 2021) áp dụng tỉa mô hình để giảm số lượng trọng số trong khi hạn chế mất mát hiệu suất. Trong công trình của chúng tôi, chúng tôi giảm sự phát triển mô hình bằng cách chỉ ra theo kinh nghiệm rằng một đầu phân đoạn thể hiện duy nhất có thể được sử dụng với các bộ trích xuất đặc trưng nhỏ chuyên môn.

Các chiến lược khác nhau như regularization và kiến trúc động mỗi cái đều có ưu và nhược điểm. Phương pháp lai của chúng tôi tìm cách kết hợp điểm mạnh của cả hai trong khi giảm thiểu nhược điểm của chúng. Do đó chúng tôi khác biệt với công trình trước đây khi kết hợp KD trong huấn luyện với phương pháp kiến trúc động để cải thiện việc học các lớp mới và giảm việc quên.

### Checkpoint Averaging

Việc tính trung bình các trọng số từ các checkpoint được lưu tại các epoch khác nhau đã được chỉ ra là cải thiện khả năng tổng quát bằng cách hoạt động tương tự như các phương pháp ensemble (Huang et al. 2017; Vaswani et al. 2017; Gao et al. 2022). Trong công trình này, đầu tiên chúng tôi chỉ ra rằng thủ thuật đơn giản này cũng có thể được tận dụng trong CL bằng cách tính trung bình các trọng số giữa các đầu phân đoạn thể hiện được huấn luyện sau bất kỳ bước tăng dần i và j nào để giảm việc quên các lớp C0:i trong khi bảo tồn kết quả tương tự hoặc hơi kém hơn trên các lớp mới Cj. Điều này cung cấp một cơ chế mới để kiểm soát thủ công sự đánh đổi giữa hiệu suất trên các lớp cũ và mới mà không yêu cầu huấn luyện lại hoặc phát sinh bất kỳ chi phí bổ sung nào.

## Phân đoạn thể hiện liên tục

### Công thức bài toán

Trong CIS, chúng tôi nhằm tăng cường một mô hình fθt−1, được tham số hóa bởi θt−1, thành một mô hình fθt có thể phát hiện và phân đoạn các thể hiện của các lớp mới Ct cũng như các lớp cũ C0:t−1. Tại mỗi bước t chúng tôi được cung cấp một tập dữ liệu huấn luyện Dt bao gồm các hình ảnh Xt và chú thích ground-truth Yt chỉ ra các hộp giới hạn, mặt nạ phân đoạn và các lớp ngữ nghĩa. Theo thiết lập thí nghiệm được thiết lập trong công trình trước đây (Cermelli et al. 2022), chúng tôi xem xét rằng các chú thích Yt chỉ có sẵn cho các lớp hiện tại Ct, trong khi các đối tượng của các danh mục trước đó xuất hiện trong Dt không được gắn nhãn.

### Mask R-CNN cho CIS

Trong bối cảnh CIS, Mask R-CNN (He et al. 2017) bao gồm một bộ trích xuất đặc trưng Fθt được tham số hóa bởi θt tại mỗi bước t, một mạng đề xuất vùng (RPN) đề xuất các vùng quan tâm (RoI), và hai đầu song song: 1) một đầu hộp cho phân loại và hồi quy tọa độ hộp giới hạn của mỗi RoI, và 2) một đầu phân đoạn cho việc phân đoạn mỗi RoI. Để đơn giản, chúng tôi tóm tắt Mask R-CNN thành ba module: 1) một backbone B được đóng băng trong tất cả các bước, 2) một tập các module trích xuất đặc trưng cụ thể cho tác vụ được định nghĩa bởi {Fθi}ti=0 học các đặc trưng cụ thể cho lớp từ các đầu ra của B, và 3) một đầu Hθt bao gồm RPN, đầu hộp và đầu phân đoạn (xem Hình 1).

### Knowledge Distillation

Một trong những thách thức chính của CL là bảo tồn kiến thức quá khứ trong khi học các lớp mới. Công trình trước đây (Shmelkov, Schmid, và Alahari 2017; Peng, Zhao, và Lovell 2020; Cermelli et al. 2022) đã chỉ ra lợi ích của knowledge distillation (KD) để ngăn mạng mới phân kỳ đáng kể trong khi học các lớp mới. Nói chung, mất mát KD có dạng sau:

Lkd=−1/(R·C) ∑(i=1 to R) ∑(c∈C1:t−1) ŷt−1(i,c) log ŷt(i,c), (1)

trong đó ŷt(i,c) là điểm số cho lớp c được đưa ra bởi mô hình fθt cho đầu ra thứ i. Trong bối cảnh phân loại RoI, mất mát KD này sẽ khuyến khích mô hình mới tạo ra điểm số tương tự của các lớp quá khứ cho mỗi RoI trong số N, tức là R=N. Mặt khác, vì phân đoạn là phân loại theo pixel, số lượng đầu ra sau đó là R=NHW, trong đó H và W là chiều cao và chiều rộng của các mặt nạ phân đoạn, tương ứng.

Như được làm nổi bật trong công trình trước đó (Cermelli et al. 2020, 2022), mất mát KD thông thường bỏ qua sự dịch chuyển nền, trong đó các lớp mới trước đây được học như nền bởi mô hình. Để giải quyết vấn đề này, mất mát KD nên được điều chỉnh để kết hợp điểm số của các lớp mới này vào lớp nền trước khi tiến hành chưng cất. Mất mát KD không thiên vị (Cermelli et al. 2022) do đó trở thành:

Lunkd =−1/(R·C) ∑(i=1 to R) [ŷt−1(i,bg) log(ŷt(bg) + ∑(c∈Ct) ŷt(i,c)) + ∑(c'∈C0:t−1\bg) ŷt−1(i,c') log ŷt(i,c')]. (2)

Bằng cách này, khi mô hình trước đưa ra điểm số cao cho lớp nền, mô hình mới được khuyến khích dự đoán hoặc nền hoặc bất kỳ lớp mới nào, đây là hành vi mong muốn.

## Dynamic Y-KD: một Phương pháp Lai

Trong phần này, chúng tôi công thức hóa mạng Dynamic Y-KD được đề xuất. Chúng tôi bắt đầu bằng cách tóm tắt các quan sát chính được thực hiện trong các thí nghiệm sơ bộ sử dụng Mask R-CNN với các mất mát knowledge distillation (KD) tiêu chuẩn. Từ những quan sát này, chúng tôi thúc đẩy các chiến lược Y-KD và kiến trúc động của mình. Sau đó chúng tôi tiến hành với một công thức của phương pháp lai tận dụng hiệp đồng cả hai kỹ thuật. Cuối cùng, chúng tôi giới thiệu checkpoint averaging như một cơ chế để kiểm soát hiệu suất của các mô hình CL.

### Động lực

**Tính ổn định của Bộ trích xuất Đặc trưng (FE).** Trong các thí nghiệm sơ bộ về CIS sử dụng Mask R-CNN với các mất mát KD tiêu chuẩn, chúng tôi nhận thấy rằng FE vẫn rất ổn định ngay cả sau nhiều bước tăng dần. Cụ thể hơn, chúng tôi so sánh các biểu diễn được tạo ra bởi FE cơ sở với các biểu diễn của FE mới đã được tăng cường với năm lớp mới sau năm bước tăng dần (15-1). Chúng tôi chỉ ra trong Hình 2a điểm số Centered Kernel Alignment (CKA) (Kornblith et al. 2019) của từng lớp riêng biệt.

Đáng ngạc nhiên, chúng tôi thấy rằng điểm số CKA rất cao (tức là >0.94), ngay cả đối với các lớp chưa được nhìn thấy bởi mô hình cơ sở. Điều này cho thấy rằng FE chỉ được tinh chỉnh nhẹ để học các đặc trưng cụ thể cho tác vụ trong các bước tăng dần.

**Tính tương thích của đầu với các FE trước đó.** Sau đó, chúng tôi đưa ra giả thuyết rằng nếu FE ổn định, thì có thể tái sử dụng FE cũ với đầu phân đoạn thể hiện mới. Chúng tôi so sánh trong Hình 2b mAP@0.5 của một mô hình sử dụng FE mới hoặc cơ sở với cùng một đầu mới cho suy luận. Thú vị là, FE cơ sở với đầu mới đạt kết quả tốt hơn trên các lớp cũ, cho thấy tính tương thích của đầu tăng cường với một lần lặp trước đó của FE.

Điều này làm nổi bật tính tổ hợp của Mask R-CNN trong CL: các module từ các bước tăng dần khác nhau vẫn tương thích và có thể được kết hợp hiệu quả để tạo ra các mô hình với các thuộc tính khác nhau. Ví dụ, Hình 2b cho thấy rằng việc sử dụng FE từ t=0 với đầu tại t=5 tạo ra một mô hình tốt hơn trên các lớp cơ sở nhưng tệ hơn trên các lớp mới. Điều này thúc đẩy ý tưởng phát triển các FE cụ thể cho tác vụ để bảo tồn các đặc trưng phân biệt của mỗi tập lớp.

### Mô hình của chúng tôi

**Y-KD: Huấn luyện các Module Chuyên môn với một Đầu Chung.** Tính ổn định của FE gợi ý hai khía cạnh: 1) cho phép FE có tính dẻo dai hơn có thể dẫn đến kết quả cải thiện trên các lớp mới, và 2) có thể không cần thiết phải đóng băng FE giáo viên trong KD nếu FE đã ổn định.

Chúng tôi đã khám phá hai giả thuyết này bằng cách đề xuất một chiến lược KD nhằm phát triển các FE chuyên môn để biểu diễn tốt hơn các lớp mới trong khi cho phép FE giáo viên được cập nhật. Điều này được thực hiện bằng cách sử dụng một bộ trích xuất đặc trưng chung Ftθ được kết nối song song với đầu trước đó Ht−1 và đầu mới Ht, do đó tạo thành một kiến trúc hình chữ Y (xem Hình 1) mà chúng tôi đặt tên là Y-knowledge distillation (Y-KD).

Trong hầu hết các công trình trước đây, một bản sao đóng băng của toàn bộ mạng giáo viên được giữ và sử dụng trong quá trình huấn luyện để chưng cất các đầu ra của nó cho mạng học sinh. Trong phương pháp của chúng tôi, Y-KD bao gồm việc chia sẻ cùng một bộ trích xuất đặc trưng có thể huấn luyện giữa mạng giáo viên và học sinh để tăng tính dẻo dai trong quá trình học tăng dần. Do đó Y-KD được thực hiện bằng cách truyền các hình ảnh trong backbone và bộ trích xuất đặc trưng được chia sẻ, điều này tạo ra các bản đồ đặc trưng X̂t như sau:

X̂t=Ftθ(B(Xt)). (3)

Các bản đồ đặc trưng X̂t sau đó được gửi đến các đầu giáo viên và học sinh riêng biệt để tạo ra các đầu ra tương ứng:

Ŷt−1=Ht−1(X̂t),
Ŷt=Ht(X̂t), (4)

trong đó Ŷ:= (p, r, s, ω, m) lần lượt là các logits lớp p, điểm số hồi quy r của tọa độ hộp, điểm số objectness s và tọa độ hộp ω được đưa ra bởi RPN, và mặt nạ phân đoạn m. KD sau đó được thực hiện giữa các đầu ra của các đầu giáo viên và học sinh:

Lunkd(Ŷt−1,Ŷt) =λ1Lboxunkd(pt−1, pt, rt−1, rt)+
λ2LRPNkd(st−1, st, ωt−1, ωt)+
λ3Lmaskkd(mt−1, mt), (5)

trong đó Lboxunkd, LRPNkd và Lmaskkd là các mất mát chưng cất (Cermelli et al. 2022) được áp dụng trên đầu hộp, RPN và đầu mặt nạ, tương ứng.

Tổng mất mát sau đó như sau:

L=Lmask(Ŷt, Yt) +Lunkd(Ŷt−1,Ŷt), (6)

trong đó Lmask là mất mát có giám sát để huấn luyện Mask R-CNN. Để biết thêm chi tiết về việc triển khai cụ thể của các mất mát này, chúng tôi đề cập độc giả đến tài liệu bổ sung.

Với các mất mát chưng cất này và bằng cách sử dụng FE được chia sẻ, hành vi của mạng giáo viên được làm cho động vì FE của nó cũng được huấn luyện trên các hình ảnh mới, nhưng nó vẫn khuyến khích đầu học sinh bảo tồn kiến thức trước đó. Điều này tăng tính dẻo dai bằng cách cho phép mạng học sinh học tốt hơn các lớp mới trong khi giữ khả năng của đầu để phát hiện và phân đoạn các danh mục trước đó.

**Kiến trúc Động.** Quan sát thứ hai của các thí nghiệm sơ bộ của chúng tôi, làm nổi bật tính tương thích của đầu với các FE trước đó, gợi ý rằng việc sử dụng các FE cụ thể cho tác vụ với một đầu duy nhất sẽ là một lựa chọn hứa hẹn cho CIS. Một mặt, việc cô lập các tham số của các FE cụ thể cho tác vụ sẽ giảm việc quên (như thể hiện trong Hình 2b), và vì một đầu duy nhất sẽ được sử dụng cho suy luận, sự tăng trưởng trong các tham số sẽ là tối thiểu.

Do đó, chúng tôi bây giờ đề xuất phương pháp dựa trên kiến trúc động của mình. Trong suy luận, chúng tôi cắm tất cả các FE chuyên môn vào cùng một backbone và đầu phân đoạn thể hiện theo cách sau (xem Hình 1). Backbone B trích xuất các đặc trưng chung từ hình ảnh đầu vào X, và các đặc trưng này được gửi đến các module cụ thể cho tác vụ F0, F1, ..., Ft song song để tạo ra các bản đồ đặc trưng tương ứng. Các bản đồ đặc trưng này sau đó được đưa cho đầu mới nhất Ht cho phân đoạn thể hiện để tạo ra các dự đoán tương ứng Ŷ0,Ŷ1, ...,Ŷt. Tất cả các dự đoán sau đó được hợp nhất bằng cách chỉ giữ các đầu ra tương ứng với lĩnh vực chuyên môn của mỗi mạng con như sau:

Ŷt= [Ŷic∈Ci],∀i= 0, ..., t (7)

Bước lọc và hợp nhất này là cần thiết vì chúng tôi sử dụng một đầu chung chung có thể phân đoạn tất cả các lớp từ bất kỳ bản đồ đặc trưng nào.

**Chi phí Bộ nhớ và Tính toán.** Một nhược điểm phổ biến của các chiến lược dựa trên kiến trúc động là chúng thường tăng chi phí bộ nhớ và tính toán khi mô hình phát triển (Lesort et al. 2020). Phương pháp của chúng tôi không ngoại lệ, vì nó tăng tuyến tính các chi phí này bằng cách thêm một module chuyên môn cho mỗi tác vụ. Tuy nhiên trong quá trình huấn luyện, chúng tôi chỉ sử dụng các đầu trước đó và mới Ht−1 và Ht với một backbone được chia sẻ để thực hiện Y-KD của chúng tôi. Các đầu từ các bước trước đó được loại bỏ và các module chuyên môn trước đó không được sử dụng trong quá trình huấn luyện (xem Hình 1 dưới-trái), sao cho chi phí bộ nhớ và tính toán là không đổi.

Hơn nữa, vì một phần lớn của backbone được đóng băng, số lượng trọng số được thêm vào ở mỗi bước tăng dần bởi sự tăng trưởng trong các FE cụ thể cho tác vụ chỉ chiếm 8.2M tham số, đại diện cho 8.2M/35.3M = 23.3% của mô hình gốc khi sử dụng ResNet-50. Công trình tương lai nên giải quyết hạn chế này, ví dụ, với các phương pháp tỉa hoặc lượng tử hóa (Zhang et al. 2021). Trong bài báo này, chúng tôi tập trung vào việc phát triển kiến trúc động đầu tiên cho CIS.

### Checkpoint Averaging để Giảm thiểu Việc quên

Trong CL, sự đánh đổi giữa hiệu suất trên các lớp trước đó hoặc mới chỉ có thể được kiểm soát gián tiếp bằng cách chọn các siêu tham số trước khi huấn luyện (Lesort et al. 2020; De Lange et al. 2021). Tuy nhiên, đây là một phương pháp tẻ nhạt vì nó yêu cầu huấn luyện lại mô hình với các kết hợp khác nhau cho đến khi đạt được sự đánh đổi thỏa mãn.

Để giảm bớt vấn đề này, chúng tôi đề xuất một công cụ đơn giản để kiểm soát thủ công sự đánh đổi giữa hiệu suất trên các lớp cũ và mới bằng cách tận dụng checkpoint averaging (Huang et al. 2017; Gao et al. 2022). Chúng tôi có thể tính trung bình các trọng số của các đầu đã được thu được sau các tác vụ tăng dần khác nhau để cải thiện khả năng của mô hình phân đoạn các thể hiện của các tập lớp trước đó. Cho các tham số θi và θj của các đầu Hi và Hj đã học các lớp C0:i và C0:j tương ứng, với i < j, chúng tôi có thể tạo ra một đầu mới Htθm kết hợp các tham số của chúng như sau:

Htθm:=wiθi+wjθj, (8)

trong đó wi, wj∈[0,1] là các yếu tố để cân bằng đóng góp của mỗi tập tham số. Bằng cách này, chúng tôi có thể khôi phục hiệu suất trên các lớp C0:i nếu việc quên được đánh giá là đáng kể. Đổi lại, một sự sụt giảm nhỏ trong hiệu suất trên các lớp Cj nên được mong đợi. Tuy nhiên, điều này cung cấp một cơ chế không tốn chi phí đơn giản để có được quyền kiểm soát việc quên, có thể là một công cụ hữu ích để xác định cân bằng hiệu suất, ví dụ khi một số lớp quan trọng hơn các lớp khác.

## Thí nghiệm

### Thiết lập Thí nghiệm

Theo công trình trước đây về CIS (Cermelli et al. 2022; Zhang et al. 2021), chúng tôi đã chọn đánh giá phương pháp của mình bằng cách sử dụng các tình huống học liên tục đa dạng được tạo ra từ tập dữ liệu Pascal-VOC (Everingham et al. 2009). Cho sự phức tạp tăng lên được trình bày bởi tình huống tăng dần theo lớp so với các thiết lập thông thường và trạng thái hiện tại của các phương pháp phân đoạn thể hiện liên tục, tức là (Zhang et al. 2021; Cermelli et al. 2022), Pascal-VOC cung cấp một benchmark dễ quản lý hơn so với các tập dữ liệu phức tạp đặt ra những thách thức đáng kể ngay cả trong các bối cảnh học không liên tục, tiêu chuẩn.

Pascal-VOC bao gồm 20 lớp ngữ nghĩa, mà chúng tôi chia thành các tập riêng biệt để mô phỏng các tình huống học tăng dần. Mỗi tình huống được định nghĩa là N-k, trong đó N là số lượng lớp cơ sở trong bước đầu tiên, và k là số lượng lớp được thêm vào trong các bước tăng dần tiếp theo để đạt tổng cộng 20 lớp.

**Số liệu.** Chúng tôi đánh giá hiệu suất của các mô hình bằng cách sử dụng mean average precision (mAP), được tính trung bình trên 10 ngưỡng từ 0.5 đến 0.95, tức là mAP@ {0.5:0.95}. Cụ thể hơn, chúng tôi báo cáo riêng biệt 1) mAP cho các lớp cơ sở để chỉ ra khả năng bảo tồn kiến thức quá khứ (tức là tính ổn định); 2) mAP cho các lớp mới để đánh giá khả năng được tăng cường với các danh mục mới (tức là tính dẻo dai); 3) mAP trên tất cả các lớp để chỉ ra hiệu suất toàn cục; và 4) đối với học tăng dần nhiều bước, chúng tôi cũng báo cáo mAP của các lớp trung gian (ví dụ các lớp 16-19 trong tình huống 15-1) riêng biệt vì kết quả trên chúng bị ảnh hưởng bởi cả tính dẻo dai và ổn định. Trong các phân tích kết quả của chúng tôi, chúng tôi cũng sử dụng tỷ lệ giữa mAP của một phương pháp CL nhất định và tương đương không phải CL của nó (tức là phương pháp huấn luyện chung) để đưa ra ý tưởng về mức độ hiệu suất mà các phương pháp CL có thể đạt được so với một giới hạn trên không phải CL.

**Baseline.** Vì chỉ có rất ít phương pháp được đề xuất cho CIS, chúng tôi so sánh phương pháp của mình với MMA (Cermelli et al. 2022) cũng như các điều chỉnh của ILOD (Shmelkov, Schmid, và Alahari 2017) và Faster ILOD (Peng, Zhao, và Lovell 2020) đã được trình bày trong (Cermelli et al. 2022). Chúng tôi cũng xem xét các giới hạn dưới và trên, được đại diện bởi một phương pháp tinh chỉnh cơ bản không kết hợp bất kỳ cơ chế CL nào, và huấn luyện chung huấn luyện trên tất cả các lớp đồng thời. Chúng tôi đã chạy tất cả các thí nghiệm bằng cách mở rộng framework được triển khai bởi (Cermelli et al. 2022).

### Kết quả

**Học Tăng dần Một bước.** Kết quả cho các tình huống học tăng dần một bước được hiển thị trong Bảng 1. Chúng ta có thể thấy rằng tính dẻo dai tăng lên của tinh chỉnh, do không có các mất mát regularization, cho phép đạt được kết quả tốt hơn so với hầu hết các phương pháp khác trên các lớp mới. Tuy nhiên, mặc dù có tính dẻo dai vượt trội, tinh chỉnh còn xa mới đạt được các kết quả tương tự như huấn luyện chung trên các lớp mới.

Mặt khác, phương pháp của chúng tôi đạt được kết quả cao hơn đáng kể trên các lớp mới trong khi bảo tồn mAP tương tự hoặc tốt hơn trên các lớp cơ sở. Trên các lớp mới, phương pháp của chúng tôi đạt được +7.6% trong 19-1, +2.9% trong 15-5 và +1.1% trong 10-10 so với MMA. Thú vị là, phương pháp của chúng tôi thậm chí còn vượt trội hơn tinh chỉnh trên các lớp mới trong hai trong ba tình huống. Điều này đặc biệt đúng trong 15-5 nơi chúng tôi đạt được 34.3% trên các lớp 16-20 trong khi tinh chỉnh, phương pháp tốt thứ hai, đạt được 31.6%. Điều này cho thấy khả năng của chiến lược Y-KD của chúng tôi trong việc tăng cường forward transfer bằng cách huấn luyện các bộ trích xuất đặc trưng chuyên môn hóa cho các lớp mới. Đóng góp của Y-KD này cũng được làm nổi bật bởi nghiên cứu ablation của chúng tôi dưới đây (tức là so sánh dòng 2-5 trong Bảng 4)

Ngoài việc đưa ra mAP tốt hơn trên các lớp mới, phương pháp của chúng tôi cũng giảm việc quên so với các phương pháp khác, đưa mAP trên tất cả các lớp (1-20) gần hơn với những phương pháp của huấn luyện chung trong cả ba tình huống. Đáng chú ý, so với huấn luyện chung, phương pháp của chúng tôi đạt được tỷ lệ mAP là 38.8%/39.9% = 97.2% trên các lớp 1-20 trong tình huống 19-1, 36.5%/39.9% = 91.5% trong 15-5, và 33.6%/39.9% = 84.2% trong 10-10.

**Học Tăng dần Nhiều bước.** Bây giờ chúng tôi hiển thị kết quả cho các tình huống học tăng dần nhiều bước trong Bảng 2. Chúng ta có thể quan sát thấy rằng phương pháp của chúng tôi hoạt động tốt trong những tình huống phức tạp hơn này. Phương pháp của chúng tôi nổi bật hơn nữa trên các lớp cơ sở trong các tình huống 15-1 và 10-2, xác nhận tính tương thích của các FE trước đó với một đầu tăng cường. Thật vậy, chúng tôi vượt trội hơn MMA +2.1% và +1.2% trên các lớp cơ sở trong các tình huống này, tương ứng. Trong 10-5, tất cả các phương pháp bao gồm cả chúng tôi đạt được mAP tương tự trong khoảng từ 35.7−36.1%. Trên các lớp cuối cùng (ví dụ các lớp 16-20 trong tình huống 10-5), phương pháp của chúng tôi vượt trội mạnh mẽ so với công trình trước đây, vì nó đạt được +4.0%, +3.0% và +1.8% so với các phương pháp tốt thứ hai trong 15-1, 10-2 và 10-5, tương ứng.

Đối với các lớp trung gian, tính dẻo dai tăng cao trong phương pháp của chúng tôi dường như đi kèm với một sự đánh đổi: nó làm cho kiến thức được tiếp thu gần đây dễ bị quên hơn. Tuy nhiên, phương pháp của chúng tôi liên tục vượt trội hơn các phương pháp khác khi đánh giá hiệu suất trên tất cả các lớp (1-20). Ví dụ, ngay cả khi phương pháp của chúng tôi đạt được kết quả hơi kém hơn trên các lớp 16-19 và 11-18 trong các tình huống 15-1 và 10-2 tương ứng, mạng Dynamic Y-KD đạt được trung bình tốt hơn trên tất cả các lớp (1-20), vượt trội hơn MMA +1.7% và +0.4%. Bây giờ chúng tôi thảo luận về cách thủ thuật checkpoint averaging có thể giải quyết thêm hạn chế của phương pháp chúng tôi liên quan đến các lớp trung gian.

**Checkpoint Averaging.** Để đảm bảo công bằng, chúng tôi đã không sử dụng thủ thuật này khi so sánh các phương pháp trong Bảng 1-2. Bây giờ chúng tôi chỉ ra cách đóng góp cuối cùng của chúng tôi có thể là một công cụ khả thi để quản lý sự thỏa hiệp trên các tập lớp khác nhau, giảm thiểu nhược điểm của phương pháp chúng tôi trên các lớp trung gian. Cụ thể, chúng tôi tính trung bình các trọng số của các đầu được thu được sau các bước học tăng dần thứ tư và thứ năm theo Phương trình 8. Các tham số θm của đầu mới được sử dụng trong suy luận do đó trở thành một trung bình giữa các tham số của các đầu Hθ4 và Hθ5, được cân nặng bởi w4 và w5.

Trong Bảng 3, chúng tôi hiển thị kết quả trên các lớp cơ sở, trung gian và mới trong các tình huống 15-1 và 10-2 bằng cách thay đổi các trọng số w4 và w5. Chúng ta có thể thấy rằng mặc dù một sự sụt giảm nhỏ được quan sát trên các lớp mới, việc hợp nhất các trọng số từ bước tăng dần thứ tư cho phép khôi phục hiệu suất trên các lớp trung gian và cơ sở. Ví dụ, trong 15-1, sự giảm mAP trên các lớp mới từ 43.9% xuống 42.7% được bù đắp bằng sự tăng +4.2% trên các lớp trung gian (tức là 16-19) với w4 = 0.25, điều này bây giờ vượt trội hơn các phương pháp trước đây (xem Bảng 2). Tương tự, trong 10-2, một mAP hơi tốt hơn trên tất cả các lớp là 29.3% có thể được thu được bằng cách sử dụng (w4 = 0.25, w5 = 0.75) vì việc quên các lớp cơ sở và trung gian được giảm bằng cách hợp nhất kiến thức quá khứ. Do đó, thủ thuật checkpoint averaging được đề xuất của chúng tôi cho phép tạo ra thủ công một mô hình mới thể hiện hiệu suất khác nhau trên các tập lớp khác nhau mà không yêu cầu bất kỳ huấn luyện nào hoặc chi phí tính toán bổ sung.

**Nghiên cứu Ablation.** Cuối cùng, chúng tôi thực hiện một nghiên cứu ablation để làm nổi bật tầm quan trọng của hai khía cạnh của mạng Dynamic Y-KD của chúng tôi, cụ thể là 1) Y-KD sử dụng FE được chia sẻ trong quá trình huấn luyện cải thiện kết quả trên các lớp mới và 2) việc sử dụng kiến trúc động giảm việc quên.

Kết quả của nghiên cứu ablation trong tình huống 15-5 được hiển thị trong Bảng 4. Từ dòng 1, chúng ta có thể thấy rằng một chiến lược hoàn toàn dựa trên kiến trúc phát triển các module mới để phù hợp với các tác vụ mới không hoạt động cho CIS, vì việc quên thảm khốc vẫn xảy ra. Không có KD, FE0 không thể duy trì tương thích với đầu tăng cường, sao cho nó hoạt động kém trên các lớp trước đó. Trong khi KD tiêu chuẩn (dòng 2) cung cấp hiệu suất hợp lý trên các lớp cũ và mới, chúng ta có thể thấy rằng các lớp mới có thể được học tốt hơn bằng cách sử dụng chiến lược Y-KD của chúng tôi (dòng 3). Tuy nhiên, tính dẻo dai tăng lên từ việc sử dụng backbone được chia sẻ trong chiến lược Y-KD của chúng tôi đi kèm với chi phí giảm tính ổn định, như được chỉ ra bởi thực tế rằng mAP@0.5 giảm xuống 60.8% trên các lớp 1-15. Kết quả tốt hơn trên các lớp trước đó này có thể được thu được bằng cách sử dụng FE0 (dòng 4), vì mAP@0.5 tăng lên 67.4%. Nhưng vì FE0 chưa học các đặc trưng cụ thể cho tác vụ của các lớp 16-20, nó không thể hoạt động tốt trên các lớp mới. Do đó, tốt nhất của cả hai thế giới được thu được bằng cách sử dụng cả FE0 và FE1 (dòng 5), tương ứng với mạng Dynamic Y-KD của chúng tôi, vì nó hoạt động tốt hơn trên các lớp mới (57.8% so với 53.1%) và thậm chí hơi tốt hơn trên các lớp trước đó so với KD tiêu chuẩn (67.4% so với 67.2%).

## Kết luận

Trong các thí nghiệm sơ bộ về phân đoạn thể hiện liên tục sử dụng Mask R-CNN với knowledge distillation, chúng tôi đã có hai quan sát liên quan đến tính ổn định của bộ trích xuất đặc trưng và tính tương thích của các đầu phân đoạn thể hiện với các backbone trước đó. Chúng tôi đã tận dụng hai quan sát này bằng cách đề xuất Y-KD và việc sử dụng kiến trúc động để tạo thành mạng Dynamic Y-KD. Phương pháp của chúng tôi tăng tính dẻo dai và cho phép huấn luyện các bộ trích xuất đặc trưng chuyên môn hóa cho các lớp mới, trong khi bảo tồn một đầu chung tương thích với tất cả các bộ trích xuất đặc trưng cụ thể cho tác vụ trước đó để có tính ổn định tốt hơn.

Kết quả của chúng tôi trên nhiều tình huống học tăng dần một bước và nhiều bước cho thấy phương pháp của chúng tôi giảm việc quên các lớp trước đó cũng như cải thiện mAP trên các lớp mới, do đó vượt trội hơn các phương pháp trước đây trong hầu hết các thiết lập. Ngoài ra, chúng tôi đã đề xuất một thủ thuật không tốn chi phí dựa trên checkpoint averaging để điều chỉnh thủ công sự đánh đổi giữa hiệu suất trên các tập lớp khác nhau.

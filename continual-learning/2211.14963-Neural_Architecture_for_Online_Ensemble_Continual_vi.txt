# Kiến trúc Mạng Thần kinh cho Học Liên tục Tập hợp Trực tuyến

Mateusz Wójcik1,2 Witold Kościukiewicz1,2 Tomasz Kajdanowicz1 Adam Gonczarek2
1Đại học Khoa học và Công nghệ Wrocław 2Alphamoon Ltd., Wrocław
{mateusz.wojcik,witold.kosciukiewicz,tomasz.kajdanowicz}@pwr.edu.pl
adam.gonczarek@alphamoon.ai

## Tóm tắt

Học liên tục với số lượng lớp ngày càng tăng là một nhiệm vụ đầy thử thách. Độ khó tăng lên khi mỗi ví dụ được trình bày chính xác một lần, điều này đòi hỏi mô hình phải học trực tuyến. Các phương pháp gần đây với quy trình tối ưu hóa tham số cổ điển đã được chứng minh là gặp khó khăn trong các thiết lập như vậy hoặc có những hạn chế như các thành phần không khả vi hoặc bộ đệm bộ nhớ. Vì lý do này, chúng tôi trình bày phương pháp tập hợp hoàn toàn khả vi cho phép chúng tôi huấn luyện một tập hợp các mạng thần kinh một cách hiệu quả trong chế độ end-to-end. Kỹ thuật được đề xuất đạt được kết quả SOTA mà không cần bộ đệm bộ nhớ và vượt trội rõ ràng so với các phương pháp tham chiếu. Các thí nghiệm đã tiến hành cũng cho thấy sự gia tăng đáng kể về hiệu suất đối với các tập hợp nhỏ, điều này chứng minh khả năng đạt được độ chính xác phân loại tương đối cao với số lượng bộ phân loại giảm.

## 1 Giới thiệu

Trong vài năm qua, mạng thần kinh đã trở thành một công cụ được sử dụng rộng rái và hiệu quả, đặc biệt trong các bài toán học có giám sát [11,7,25]. Quá trình tối ưu hóa tham số dựa trên gradient descent hoạt động tốt khi tập dữ liệu đủ lớn và có sẵn hoàn toàn trong quá trình huấn luyện. Nếu không, hiện tượng quên thảm khốc [9] sẽ xảy ra, khiến mạng thần kinh không thể được huấn luyện một cách tăng dần. Lĩnh vực học liên tục nhằm phát triển các phương pháp cho phép tích lũy kiến thức mới mà không quên kiến thức đã suy luận trước đó.

Hiện tại, các phương pháp được đảm bảo hiệu quả nhất trên các nhiệm vụ khác nhau sử dụng bộ đệm bộ nhớ [18]. Mặc dù đây là một cách tiếp cận tương đối đơn giản và hiệu quả, nhưng nó đòi hỏi truy cập liên tục vào dữ liệu. Trong nhiều ứng dụng thực tế trong thế giới thực, điều này loại bỏ những phương pháp như vậy do chính sách bảo mật hoặc kích thước dữ liệu [27]. Cũng đã được chứng minh rằng các phương pháp không có bộ đệm bộ nhớ không hiệu quả trong thiết lập tăng dần lớp [31] với các thuật toán tối ưu hóa cổ điển như Adam [22].

Trong bài báo này, chúng tôi trình bày một kiến trúc mạng thần kinh hoàn toàn khả vi cho học liên tục tăng dần lớp trực tuyến được gọi là DE&E. Kiến trúc được lấy cảm hứng từ Encoders and Ensembles (sau đây được gọi là E&E) [28] và được thích ứng cho thiết lập tăng dần lớp trực tuyến không có nhiệm vụ đầy thử thách nhất. Phương pháp của chúng tôi giữ lại những ưu điểm của E&E trong khi tăng độ chính xác, giảm quên lãng, cho phép huấn luyện tập hợp end-to-end và cải thiện đáng kể hiệu suất khi số lượng tham số thấp (tập hợp nhỏ). Chúng tôi chứng minh rằng kiến trúc được đề xuất đạt được kết quả SOTA trong các kịch bản được đánh giá. Tóm lại, các đóng góp của chúng tôi như sau: 1) chúng tôi đã giới thiệu một lớp KNN khả vi [34] vào kiến trúc mô hình, 2) chúng tôi đề xuất một cách tiếp cận mới để tổng hợp các dự đoán của bộ phân loại trong tập hợp, 3) chúng tôi chứng minh hiệu quả của kiến trúc được đề xuất bằng cách đạt được kết quả SOTA trên các điểm chuẩn học liên tục phổ biến mà không có bộ đệm bộ nhớ.

## 2 Kiến trúc mô hình

**Bộ trích xuất đặc trưng.** Kiến trúc mô hình đầy đủ được trình bày trong Hình 1. Thành phần đầu tiên của kiến trúc được đề xuất là một bộ trích xuất đặc trưng đa lớp biến đổi dữ liệu đầu vào thành không gian nhúng. Nó có thể được mô tả bởi ánh xạ sau z=F(x), trong đó x∈RD là một ví dụ đầu vào và z∈RM là một nhúng M chiều. Cách tiếp cận chúng tôi theo giả định sử dụng mô hình được huấn luyện trước với các tham số đóng băng. Quy trình như vậy làm cho việc hoàn toàn ngăn chặn bộ trích xuất khỏi quên lãng bằng cách cô lập việc học không gian đặc trưng khỏi quá trình phân loại.

**Khóa và bộ phân loại.** Chúng tôi sử dụng một tập hợp N bộ phân loại fn(·), trong đó mỗi bộ ánh xạ nhúng thành một vector đầu ra K chiều ŷn=fn(z). Với mỗi bộ phân loại, có một vector khóa liên kết kn∈RM với cùng số chiều như nhúng. Các khóa giúp chọn các mô hình phù hợp nhất cho việc chuyên môn hóa đối với ví dụ đầu vào hiện tại đang được xử lý. Chúng được khởi tạo ngẫu nhiên từ phân phối chuẩn. Chúng tôi sử dụng các mạng thần kinh một lớp đơn giản làm bộ phân loại, với chiến lược khởi tạo trọng số là fan-in variance scaling. Đầu ra mạng được kích hoạt bởi hàm tang hyperbolic (tanh).

**Lớp κ-láng giềng gần nhất mềm.** Thuật toán KNN tiêu chuẩn thường được triển khai sử dụng các phép toán sắp xếp thông thường khiến việc xác định đạo hàm riêng đối với đầu vào trở nên không thể. Nó loại bỏ khả năng sử dụng KNN như một phần của các mô hình thần kinh end-to-end. Tuy nhiên, có thể thu được một xấp xỉ khả vi của mô hình KNN bằng cách giải Bài toán Vận chuyển Tối ưu [23]. Dựa trên khái niệm này, chúng tôi thêm một lớp khả vi vào kiến trúc mô hình. Chúng tôi gọi lớp này là κ-láng giềng gần nhất mềm (soft KNN). Để xác định xấp xỉ KNN, trước tiên chúng tôi tính vector khoảng cách cosine c∈RN giữa nhúng và các khóa:

cn = 1−cos(z,kn),                    (1)

trong đó cos(·,·) biểu thị độ tương tự cosine. Tiếp theo, chúng tôi theo ý tưởng của toán tử top-κ mềm được trình bày trong [34], trong đó κ biểu thị số láng giềng gần nhất. Cho E∈RN×2 là ma trận khoảng cách Euclidean với các phần tử sau:

en,0 = (cn)², en,1 = (cn−1)².        (2)

Và cho G∈RN×2 biểu thị ma trận tương tự thu được bằng cách áp dụng hạt nhân Gaussian cho E:

G = exp(−E/σ),                       (3)

trong đó σ biểu thị độ rộng hạt nhân. Các toán tử exp được áp dụng theo từng phần tử cho ma trận E.

Sau đó chúng tôi sử dụng phương pháp Bregman, một thuật toán được thiết kế để giải các bài toán tối ưu hóa ràng buộc lồi, để tính L lần lặp của các phép chiếu Bregman nhằm xấp xỉ các điểm dừng của chúng:

p(l+1)=μ⊙Gq(l), q(l+1)=ν⊙G⊤p(l+1), l=0,...,L−1    (4)

trong đó μ=1N/N, ν=[κ/N, (N−κ)/N]⊤, q(0)=12/2, và 1i biểu thị vector toàn số một i-phần tử. Cuối cùng, cho Γ biểu thị ma trận kế hoạch vận chuyển tối ưu và được cho bởi:

Γ = diag(p(L))·G·diag(q(L))         (5)

Như kết quả cuối cùng γ∈RN của toán tử κ-láng giềng gần nhất mềm, chúng tôi lấy cột thứ hai của Γ nhân với N tức là γ=NΓ:,2. γ là một xấp xỉ mềm của vector zero-một cho biết κ trong số N thể hiện nào là các láng giềng gần nhất. Việc giới thiệu soft KNN cho phép chúng tôi huấn luyện các phần của mô hình đã bị đóng băng cho đến nay (A.4.2).

**Lớp bỏ phiếu.** Chúng tôi sử dụng cả cn và γ để cân bằng các dự đoán bằng cách tạo ra tác động cao hơn cho các bộ phân loại có khóa tương tự với các đặc trưng được trích xuất. Xấp xỉ γ thu được có hai chức năng chính. Nó loại bỏ các dự đoán từ các bộ phân loại bên ngoài κ gần nhất và cân bằng kết quả. Vì phương pháp Bregman không phải lúc nào cũng hội tụ hoàn toàn, vector κ chứa các giá trị liên tục gần bằng 1 đối với các bộ phân loại liên quan nhất. Chúng tôi tận dụng tính chất này trong quy trình bỏ phiếu tập hợp. Giá trị κ càng cao đối với một bộ phân loại, đóng góp của nó vào quyết định tập hợp cuối cùng càng cao. Dự đoán cuối cùng được thu nhận như sau:

ŷ = (ΣNn=1 γncnŷn)/(ΣNn=1 cn)      (6)

**Huấn luyện** Để tối ưu hóa hiệu quả các tham số mô hình, chúng tôi theo quy trình huấn luyện được trình bày trong [28]. Nó giả định việc sử dụng một hàm mất mát cụ thể là tích trong giữa dự đoán tập hợp và nhãn được mã hóa one-hot:

L(y,ŷ) = −y⊤ŷ                      (7)

Tối ưu hóa tiêu chí này mang lại lợi thế của việc sử dụng hàm kích hoạt tanh, giảm đáng kể quên thảm khốc. Theo phương pháp tham chiếu, chúng tôi cũng sử dụng một bộ tối ưu hóa loại bỏ giá trị gradient và chỉ sử dụng dấu của nó để xác định hướng cập nhật. Kết quả là, các tham số đang được thay đổi bởi một bước cố định trong quá trình huấn luyện.

## 3 Thí nghiệm

**Thiết lập**

**Kết quả.** Kết quả đánh giá trên MNIST và CIFAR-10 được trình bày trong Bảng 1. Đối với tất cả các thiết lập được đánh giá, mô hình của chúng tôi đã hoạt động tốt nhất, cải thiện kết quả của phương pháp tham chiếu chính (E&E) lên đến 6%. Chúng tôi cũng có thể thấy sự khác biệt đáng kể về độ chính xác đạt được giữa phương pháp DE&E và các phương pháp cơ sở. Hơn nữa, nó đạt được kết quả này mà không phải phát lại các ví dụ huấn luyện đã thấy trong quá khứ, làm cho nó thực tế hơn so với các phương pháp dựa trên bộ nhớ (Replay, A-GEM, GEM) với 10 ví dụ được lưu trữ mỗi kinh nghiệm (một phân chia). Đối với tập hợp 128 bộ phân loại và MNIST, kiến trúc của chúng tôi đạt được kết quả tốt hơn hơn 18% so với phương pháp tốt nhất có bộ đệm bộ nhớ.

Ngoài ra, chúng tôi quan sát thấy rằng phương pháp được đề xuất cải thiện đáng kể hiệu suất của các tập hợp nhỏ. Tập hợp càng nhỏ, mức tăng độ chính xác càng cao. Đối với MNIST và tập hợp 16 mô hình, sự cải thiện lên đến khoảng 6% so với E&E. Đối với 64 bộ phân loại và CIFAR-10, sự cải thiện khoảng 5%. Hình 2 cho thấy so sánh tổng số trọng số của các tập hợp có kích thước khác nhau và hiệu suất phân loại đạt được. Phương pháp được đề xuất đạt được kết quả cao hơn khi có cùng số tham số. Đối với tập hợp 1024 bộ phân loại, độ chính xác đã rất gần, cho thấy mức tăng giảm với các tập hợp lớn.

Một lợi thế quan trọng của phương pháp được đề xuất là tỷ lệ quên thấp [3]. Chúng tôi quan sát thấy việc quên giảm đáng kể so với phương pháp tham chiếu, như được hiển thị trong Hình 3. Sự chuyên môn hóa mạnh hơn được khuếch đại bởi phương pháp bỏ phiếu được giới thiệu làm cho các bộ phân loại ít có khả năng mất kiến thức đã có được. Tập hợp càng lớn thì tương đối ít kiến thức bị quên. Theo kinh nghiệm, hiện tượng này có thể được giải thích bởi thực tế là tập hợp lớn hơn có nghĩa là phủ sóng tốt hơn không gian dữ liệu khóa, làm cho các mô hình chuyên môn hóa trong việc phân loại các nhóm ví dụ cụ thể. Kết quả là, chúng tôi bảo vệ các mô hình chống lại sự dịch chuyển miền của các ví dụ đầu vào, do đó làm cho chúng dễ phân loại hơn và khó quên hơn.

## 4 Kết luận

Trong bài báo này, chúng tôi đã đề xuất một kiến trúc mạng thần kinh cho học liên tục trực tuyến với quy trình huấn luyện chuyên môn hóa trong các bài toán tăng dần lớp đầy thử thách. Kiến trúc được trình bày giới thiệu một lớp soft KNN hoàn toàn khả vi và chiến lược cân bằng dự đoán mới dựa trên soft KNN. Các thành phần này khuếch đại ảnh hưởng của các bộ phân loại chuyên môn nhất đến dự đoán cuối cùng. Kết quả là, chúng tôi đã cho thấy độ chính xác được cải thiện cho tất cả các trường hợp được nghiên cứu và đạt được kết quả SOTA. Chúng tôi đã chứng minh rằng có thể cải thiện đáng kể chất lượng phân loại bằng cách sử dụng các kỹ thuật được đề xuất và hiệu ứng này được quan sát đặc biệt trong các tập hợp nhỏ đã đạt được hiệu suất cao hơn đáng kể. Kết quả là, kiến trúc được trình bày vượt trội hơn các phương pháp có bộ đệm bộ nhớ và cho phép các nhà nghiên cứu thực hiện các bước tiếp theo hướng tới vượt qua SOTA hiện tại trong các bài toán tăng dần lớp.

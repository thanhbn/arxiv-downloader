LIỆU HỌC LIÊN TỤC CÓ QUÊN ĐỒNG ĐỀU TẤT CẢ THAM SỐ KHÔNG?

Haiyan Zhao1Tianyi Zhou2Guodong Long1Jing Jiang1Chengqi Zhang1
1Đại học Công nghệ Sydney
2Đại học Maryland
Haiyan.Zhao-2@student.uts.edu.au, zhou@umiacs.umd.edu,
fguodong.long, jing.jiang, Chengqi.Zhang g@uts.edu.au

TÓM TẮT

Sự dịch chuyển phân phối (ví dụ, dịch chuyển nhiệm vụ hoặc miền) trong học liên tục (CL) thường dẫn đến việc quên thảm khốc của mạng nơ-ron. Mặc dù có thể được giảm nhẹ bằng cách phát lại liên tục dữ liệu được đệm, việc phát lại từng bước rất tốn thời gian. Trong bài báo này, chúng tôi nghiên cứu các mô-đun nào trong mạng nơ-ron dễ bị quên hơn bằng cách điều tra động lực học huấn luyện của chúng trong CL. Các chỉ số đề xuất của chúng tôi cho thấy chỉ có một vài mô-đun cụ thể cho nhiệm vụ hơn và thay đổi một cách nhạy cảm giữa các nhiệm vụ, trong khi những mô-đun khác có thể được chia sẻ giữa các nhiệm vụ như kiến thức chung. Do đó, chúng tôi cho rằng việc quên chủ yếu là do những mô-đun trước và thấy rằng việc tinh chỉnh chúng chỉ trên một bộ đệm nhỏ ở cuối bất kỳ phương pháp CL nào có thể mang lại cải thiện đáng kể. Do số lượng tham số được tinh chỉnh nhỏ, "Tinh chỉnh Ưu tiên Quên (FPF)" như vậy có hiệu quả về mặt tính toán. Chúng tôi tiếp tục đề xuất một phương pháp hiệu quả và đơn giản hơn, hoàn toàn loại bỏ việc phát lại từng bước và thay thế chúng bằng chỉ k lần FPF được kích hoạt định kỳ trong CL. Đáng ngạc nhiên, "k-FPF" này hoạt động tương đương với FPF và vượt trội hơn các phương pháp CL SOTA nhưng giảm đáng kể chi phí tính toán và cost của chúng. Trong các thí nghiệm trên một số điểm chuẩn của CL tăng dần theo lớp và miền, FPF liên tục cải thiện các phương pháp CL hiện có với biên độ lớn, và k-FPF còn xuất sắc hơn về hiệu quả mà không làm giảm độ chính xác. Chúng tôi cũng nghiên cứu thực nghiệm tác động của kích thước bộ đệm, số epoch cho mỗi nhiệm vụ và các mô-đun tinh chỉnh đối với chi phí và độ chính xác của các phương pháp của chúng tôi.

1 Giới thiệu

Được hỗ trợ bởi các kỹ thuật học sâu tiên tiến và mạng nơ-ron, học máy đã đạt được hiệu suất đầy hứa hẹn chưa từng có trên các nhiệm vụ thách thức trong các lĩnh vực khác nhau, chủ yếu dưới thiết lập ngoại tuyến i.i.d. Tuy nhiên, độ tin cậy và hiệu suất của nó suy giảm mạnh trong học liên tục (CL) nơi phân phối dữ liệu hoặc nhiệm vụ trong huấn luyện thay đổi theo thời gian, khi mô hình nhanh chóng thích ứng với nhiệm vụ mới và ghi đè các trọng số đã học trước đó. Điều này dẫn đến sự thiên vị nghiêm trọng về phía các nhiệm vụ gần đây hơn và "quên thảm khốc" kiến thức đã học trước đó, điều này có hại cho nhiều ứng dụng thực tế.

Một chiến lược được nghiên cứu rộng rãi để giảm thiểu việc quên là phát lại kinh nghiệm (ER) [1, 2] và các biến thể của nó [3, 4, 5], lưu trữ một vài dữ liệu từ các nhiệm vụ trước trong bộ nhớ hạn chế và huấn luyện mô hình sử dụng cả dữ liệu hiện tại và được đệm. Tuy nhiên, chúng chỉ mang lại những cải thiện nhỏ khi bộ nhớ quá nhỏ để lưu trữ đủ dữ liệu khôi phục kiến thức đã học trước đó, điều này thường xảy ra do phân phối phức tạp của các nhiệm vụ trước. Ngược lại, học đa nhiệm vụ [6] thường áp dụng kiến trúc mô hình bao gồm mạng xương sống bất khả tri nhiệm vụ và nhiều bộ điều hợp cụ thể nhiệm vụ trên đó. Trong khi xương sống cần được tiền huấn luyện trên dữ liệu quy mô lớn, các bộ điều hợp thường nhẹ và có thể đạt được bằng cách sử dụng một vài dữ liệu. Tuy nhiên, trong CL, chúng ta không thể định nghĩa rõ ràng và tách biệt các phần bất khả tri nhiệm vụ và các phần cụ thể nhiệm vụ. Mặc dù các phương pháp trước [7, 8] đã nghiên cứu để hạn chế sự thay đổi của các tham số quan trọng đối với các nhiệm vụ trước, một ràng buộc bổ sung như vậy có thể làm giảm hiệu suất huấn luyện và không khuyến khích các mô-đun bất khả tri nhiệm vụ nắm bắt kiến thức chia sẻ.

Trong bài báo này, chúng tôi nghiên cứu một vấn đề cơ bản nhưng mở trong CL, tức là, liệu hầu hết các tham số có cụ thể cho nhiệm vụ và thay đổi một cách nhạy cảm với sự dịch chuyển phân phối không? Hoặc việc quên thảm khốc chủ yếu do sự thay đổi trong một vài tham số cụ thể nhiệm vụ? Nó tự nhiên liên quan đến sự đánh đổi giữa tính dẻo dai-ổn định trong các hệ thống nơ-ron sinh học [9]: các tham số cụ thể nhiệm vụ nhiều hơn cải thiện tính dẻo dai nhưng có thể gây ra việc quên nghiêm trọng, trong khi tính ổn định có thể được cải thiện bằng cách tăng các tham số được chia sẻ giữa các nhiệm vụ. Ngoài ra, có bao nhiêu tham số cụ thể nhiệm vụ đủ để đạt được hiệu suất đầy hứa hẹn trên (các) nhiệm vụ mới? Liệu việc phát lại từng bước có cần thiết không?

Để trả lời những câu hỏi này, chúng tôi điều tra động lực học huấn luyện của các tham số mô hình trong quá trình CL bằng cách đo lường sự thay đổi của chúng theo thời gian. Đối với các phương pháp CL khác nhau huấn luyện trên các mạng nơ-ron khác nhau, chúng tôi liên tục quan sát thấy chỉ có một vài tham số thay đổi mạnh hơn những tham số khác giữa các nhiệm vụ. Kết quả chỉ ra rằng hầu hết các tham số có thể được chia sẻ giữa các nhiệm vụ, và chúng ta chỉ cần tinh chỉnh một vài tham số cụ thể nhiệm vụ để duy trì hiệu suất của các nhiệm vụ trước. Vì những tham số này chỉ chứa một vài lớp của các kiến trúc mạng khác nhau, chúng có thể được tinh chỉnh một cách hiệu quả và chính xác bằng cách sử dụng một bộ đệm nhỏ.

Các nghiên cứu thực nghiệm ngay lập tức thúc đẩy một phương pháp đơn giản nhưng hiệu quả, "tinh chỉnh ưu tiên quên (FPF)" tinh chỉnh các tham số cụ thể nhiệm vụ sử dụng dữ liệu được đệm ở cuối các phương pháp CL. Đáng ngạc nhiên, trên nhiều tập dữ liệu, FPF liên tục cải thiện một số phương pháp CL được nghiên cứu rộng rãi và vượt trội đáng kể so với nhiều đường cơ sở khác nhau. Hơn nữa, chúng tôi mở rộng FPF thành một phương pháp CL không phát lại hiệu quả hơn "k-FPF" hoàn toàn loại bỏ chi phí phát lại từng bước bằng cách thay thế việc phát lại thường xuyên như vậy bằng FPF thỉnh thoảng. k-FPF áp dụng FPF chỉ k lần trong CL. Chúng tôi cho thấy rằng một k tương đối nhỏ đủ để cho phép k-FPF đạt được hiệu suất tương đương với các phương pháp FPF+SOTA CL và đồng thời giảm đáng kể chi phí tính toán. Ngoài ra, chúng tôi khám phá các nhóm tham số khác nhau để tinh chỉnh trong FPF và k-FPF bằng cách xếp hạng độ nhạy cảm của chúng đối với sự dịch chuyển nhiệm vụ được đánh giá trong các nghiên cứu thực nghiệm. Đối với FPF, chúng tôi so sánh chúng dưới các lựa chọn khác nhau cho kích thước bộ đệm, số epoch cho mỗi nhiệm vụ, phương pháp CL và kiến trúc mạng. FPF có thể cải thiện đáng kể các phương pháp CL hiện có chỉ bằng cách tinh chỉnh 1,13% tham số. Đối với k-FPF, chúng tôi khám phá các nhóm tham số khác nhau, k và các bước tinh chỉnh cho mỗi FPF. k-FPF có thể đạt được sự đánh đổi đầy hứa hẹn giữa hiệu quả và hiệu suất. Các thí nghiệm của chúng tôi được thực hiện trên một loạt rộng các điểm chuẩn cho CL tăng dần theo lớp và miền trong thực tế, ví dụ, phân loại hình ảnh y tế và sự dịch chuyển miền thực tế giữa các phong cách hình ảnh.

2 Công trình liên quan

Học Liên tục và Quên Thảm khốc Một dòng phương pháp lưu trữ các mẫu của các nhiệm vụ trong quá khứ để chống lại việc quên kiến thức trước đó. ER [3] áp dụng lấy mẫu bể chứa [10] để duy trì bộ đệm bộ nhớ của các mẫu đồng nhất trên tất cả các nhiệm vụ. MIR [11] đề xuất một chiến lược mới để lựa chọn các mẫu bộ nhớ chịu sự gia tăng mất mát lớn nhất do mini-batch đến, do đó những mẫu ở ranh giới quên được chọn. DER và DER++ [4] áp dụng chưng cất kiến thức để giảm thiểu việc quên bằng cách lưu trữ các logit đầu ra cho dữ liệu được đệm trong CL. iCaRL [12] chọn các mẫu gần nhất với trung bình biểu diễn của mỗi lớp và huấn luyện một bộ phân loại gần-trung bình-của-mẫu để bảo tồn thông tin lớp của các mẫu. Các phương pháp của chúng tôi là các kỹ thuật bổ sung cho những phương pháp dựa trên bộ nhớ này. Nó có thể cải thiện thêm hiệu suất của chúng bằng cách tinh chỉnh một phần nhỏ các tham số cụ thể nhiệm vụ trên dữ liệu được đệm một lần (FPF) hoặc thỉnh thoảng (k-FPF).

Một dòng công việc khác áp đặt một regularization trên các tham số mô hình hoặc cô lập các tham số cụ thể nhiệm vụ để giữ lại kiến thức trước. oEWC [7] ràng buộc việc cập nhật các tham số mô hình quan trọng đối với các nhiệm vụ trong quá khứ bởi một hình phạt bậc hai. Để lựa chọn các tham số cụ thể nhiệm vụ, SI [8] tính toán tác động của sự thay đổi tham số lên mất mát trong khi MAS [13] tính toán tác động của sự thay đổi tham số lên đầu ra mô hình khi mỗi nhiệm vụ mới đến. PackNet [14] và HAT [15] lặp lại gán một tập con các tham số cho các nhiệm vụ liên tiếp thông qua mặt nạ nhị phân. Tất cả những công trình này cố gắng xác định các tham số quan trọng cho các nhiệm vụ khác nhau trong CL và hạn chế việc cập nhật những tham số này. Nhưng chúng cũng có thể ngăn cản các tham số bất khả tri nhiệm vụ học kiến thức chia sẻ giữa các nhiệm vụ. Từ động lực học huấn luyện của CL, chúng tôi xác định các tham số nhạy cảm với sự dịch chuyển phân phối. FPF và k-FPF tinh chỉnh những tham số này để giảm thiểu thiên vị mà không hạn chế việc cập nhật các tham số bất khả tri nhiệm vụ.

Các mô-đun khác nhau trong mạng nơ-ron
Pham et al. [16] và Lesort et al. [17] chỉ nghiên cứu tác động của các lớp chuẩn hóa và bộ phân loại khác nhau đối với CL trong một thiết lập nhất định, trong khi phương pháp của chúng tôi điều tra độ nhạy cảm của tất cả các tham số trong các kiến trúc mạng và kịch bản khác nhau. Wu et al. [18] nghiên cứu việc quên của các khối khác nhau trong các mô hình ngôn ngữ tiền huấn luyện bằng cách điều tra khả năng biểu diễn của chúng. Chúng tôi cung cấp một phân tích chi tiết hơn về việc quên của mỗi mô-đun bởi động lực học huấn luyện của chúng. Và chúng tôi thấy rằng các tham số của các loại mô-đun khác nhau có độ nhạy cảm khác nhau đối với việc quên. Ramasesh et al. [19] cho thấy rằng việc đóng băng các lớp sớm hơn sau khi huấn luyện nhiệm vụ đầu tiên có tác động ít đến hiệu suất của nhiệm vụ thứ hai. Điều này là do phần không đóng băng của họ bao gồm lớp FC cuối và nhiều tham số BN, là những tham số nhạy cảm/quan trọng nhất theo nghiên cứu thực nghiệm của chúng tôi. Zhang et al. [20] thấy rằng trong các kiến trúc khác nhau, các tham số trong các lớp trên (gần với đầu vào) quan trọng hơn và việc làm rối chúng dẫn đến hiệu suất kém. Nghiên cứu thực nghiệm của chúng tôi phù hợp với những phát hiện của họ ở chỗ lớp tích chập sớm hơn nhạy cảm với sự trôi dạt nhiệm vụ và những thiên vị được tạo ra trên chúng dẫn đến quên thảm khốc.

3 Thiết lập Vấn đề

Ký hiệu Chúng tôi xem xét thiết lập CL, nơi mô hình được huấn luyện trên một chuỗi các nhiệm vụ được lập chỉ mục bởi t∈{1;2;...;T}. Trong mỗi nhiệm vụ t, các mẫu huấn luyện (x;y) (với nhãn y) được rút ra từ một phân phối i.i.d. Dt. Cho một mạng nơ-ron f(·) có L lớp với tham số θ = {θ`}`=1:L, θ` = {θ`;i}i=1:n` biểu thị tất cả các tham số trong lớp-` nơi θ`;i biểu thị tham số-i. Trên mỗi nhiệm vụ, f(·) được huấn luyện trong N epoch. Chúng tôi biểu thị tất cả các tham số và các tham số của lớp-` ở cuối epoch thứ-n của nhiệm vụ t bởi θtn và θt`;n, n∈{1;...;N}, tương ứng.

Thiết lập Trong bài báo này, chúng tôi chủ yếu tập trung vào học tăng dần theo lớp (class-IL) và học tăng dần theo miền (domain-IL). Trong class-IL, Dt được rút ra từ một tập con các lớp Ct, và {Ct}Tt=1 cho các nhiệm vụ khác nhau được giả định là rời rạc. Class-IL là một thiết lập thách thức hơn của CL[21] so với học tăng dần theo nhiệm vụ (task-IL) [22]. Không giống như task-IL, class-IL không thể truy cập nhãn nhiệm vụ trong quá trình suy luận và phải phân biệt giữa tất cả các lớp từ tất cả các nhiệm vụ. Trong domain-IL, các nhiệm vụ cần học vẫn giữ nguyên, nhưng miền thay đổi, tức là phân phối dữ liệu đầu vào Dt thay đổi. Mô hình được kỳ vọng thích ứng với miền mới mà không quên những miền cũ. Mục tiêu của class-IL và domain-IL là: min L(θ), ∑Tt=1 E(x;y)∼Dt [l(y;f(x))], nơi l là hàm mục tiêu.

Tập dữ liệu Chúng tôi thực hiện các thí nghiệm class-IL trên Seq-MNIST, Seq-OrganAMNIST, Seq-PathMNIST, Seq-CIFAR-10 và Seq-TinyImageNet. Seq-OrganAMNIST và Seq-PathMnist được tạo ra bằng cách chia OrganAMNIST hoặc PathMNIST từ MedMNIST[23], một điểm chuẩn phân loại hình ảnh y tế. CL trên hình ảnh y tế là cần thiết trong thực tế nhưng cũng thách thức vì hình ảnh y tế luôn đến dưới dạng luồng với bệnh nhân mới và bệnh mới. Hơn nữa, hình ảnh y tế của các lớp khác nhau có thể chỉ có sự khác biệt tinh tế khó phân biệt. Đối với các thí nghiệm domain-IL, chúng tôi sử dụng tập dữ liệu PACS [24], được sử dụng rộng rãi cho tổng quát hóa miền. Nó có thể trình bày thách thức dịch chuyển miền thực tế hơn so với thiết lập đồ chơi của PermuteMNIST [25]. Chi tiết của những tập dữ liệu này có thể được tìm thấy trong Phụ lục H.

Mô hình Chúng tôi tuân theo các kiến trúc mạng tiêu chuẩn được áp dụng trong hầu hết các công trình CL trước. Đối với Seq-MNIST, theo [3], chúng tôi sử dụng một MLP, tức là, một mạng kết nối đầy đủ (FC) với hai lớp ẩn, mỗi lớp bao gồm 100 đơn vị ReLU. Theo [26, 27], chúng tôi huấn luyện ResNet-18 [28] trên năm tập dữ liệu khác. Ngoài ra, chúng tôi cũng mở rộng nghiên cứu thực nghiệm của mình sang một kiến trúc khác, tức là, VGG-11 [29] trên Seq-CIFAR-10.

4 Quên của Các Tham số Khác nhau: Một nghiên cứu thực nghiệm

Một câu hỏi cơ bản và lâu dài trong CL là làm thế nào sự dịch chuyển phân phối tác động đến các tham số mô hình khác nhau và tại sao nó dẫn đến việc quên có hại. Câu trả lời của nó có thể tiết lộ sự đánh đổi tính dẻo dai-ổn định trong CL, nơi một số tham số là dẻo dai và cụ thể nhiệm vụ và do đó phải được tinh chỉnh trước khi triển khai mô hình, trong khi những tham số ổn định có thể được chia sẻ và tổng quát hóa cho các nhiệm vụ mới. Để trả lời câu hỏi này, chúng tôi tiến hành một nghiên cứu thực nghiệm toàn diện so sánh động lực học huấn luyện của các tham số khác nhau trong ba mạng nơ-ron được nghiên cứu rộng rãi.

4.1 Đo lường Quên thông qua Động lực học Huấn luyện

Để đo lường và so sánh các hiệu ứng quên của các tham số khác nhau, chúng tôi áp dụng hai chỉ số trực quan để tính toán sự thay đổi của các tham số và điều tra động lực học của chúng qua CL. Chỉ số đầu tiên tính toán sự khác biệt giữa hai epoch liên tiếp, ví dụ, đối với tham số θ`, nó tính toán (1) (1/|θ`|)||θt`;n − θt`;n−1||1 giữa epoch-(n−1) và epoch-n trong một nhiệm vụ-t và (2) (1/|θ`|)||θt+1`;1 − θt`;N||1 giữa epoch cuối của nhiệm vụ-t và epoch đầu của nhiệm vụ-(t+1). Động lực học huấn luyện của chỉ số này trên các nhóm tham số khác nhau cho các mạng khác nhau được hiển thị trong các biểu đồ (a,c) của Hình 1. Trong CL, các thay đổi không ổn định của tham số chủ yếu do sự dịch chuyển nhiệm vụ, trong khi việc học trong mỗi nhiệm vụ thường dẫn đến những thay đổi mượt mà. Do đó, chỉ số thứ hai tập trung vào sự khác biệt giữa hai nhiệm vụ liên tiếp, ví dụ, sự thay đổi của tham số giữa epoch-n của hai nhiệm vụ, tức là, C` = (1/|θ`|)||θt+1`;n − θt`;n||1. Kết quả của nó trên các mạng nơ-ron khác nhau được hiển thị trong các biểu đồ (b,d,e) của Hình 1.

4.2 Quên của Các Tham số Khác nhau Trong CL

Chúng tôi đầu tiên điều tra và so sánh động lực học huấn luyện của các tham số khác nhau trong ba loại mạng. Để có được những hiểu biết áp dụng cho tất cả các phương pháp CL, chúng tôi loại trừ bất kỳ kỹ thuật CL cụ thể nào mà chỉ đơn giản áp dụng SGD để huấn luyện một mô hình trên một chuỗi các nhiệm vụ mà không có bất kỳ biện pháp đối phó nào với việc quên. Sau đó, chúng tôi mở rộng thí nghiệm sang các phương pháp CL và tập dữ liệu khác nhau để xác minh liệu các quan sát vẫn giữ nguyên.

Động lực học giữa Các Epoch Liên tiếp Các biểu đồ (a,c) của Hình 1 cho thấy động lực học huấn luyện của các epoch liên tiếp cho các tham số trong VGG-11 và ResNet-18 khi được huấn luyện trên Seq-CIFAR10. Chúng tôi phân chia tất cả các tham số trong VGG-11 thành một số nhóm, tức là, lớp tích chập dưới cùng (gần nhất với đầu vào), các lớp tích chập trong các khối khác nhau và ba lớp FC. Bên cạnh các nhóm của VGG-11, ResNet-18 áp dụng chuẩn hóa theo lô (BN), có hai nhóm tham số, tức là, (1) trọng số và bias và (2) trung bình và phương sai. Trong các biểu đồ, tất cả các tham số trải qua nhiều thay đổi hơn tại epoch chuyển đổi nhiệm vụ và nhanh chóng hội tụ sau một vài epoch trong cùng một nhiệm vụ. Do đó, các mẫu động lực học của chỉ số này có thể được sử dụng để phát hiện ranh giới nhiệm vụ.

Động lực học giữa Các Nhiệm vụ Liên tiếp Các biểu đồ (b,d,e) của Hình 1 cho thấy động lực học huấn luyện của các nhiệm vụ liên tiếp cho các tham số trong VGG-11, ResNet-18 và MLP. Chúng tôi huấn luyện một MLP ba lớp cho Seq-MNIST. Vì mỗi nhiệm vụ trong Seq-MNIST chỉ được huấn luyện 1 epoch, động lực học của MLP cho các epoch liên tiếp và các nhiệm vụ liên tiếp là giống nhau. Từ các biểu đồ của các mạng nơ-ron khác nhau, lớp FC cuối nhạy cảm hơn với sự dịch chuyển nhiệm vụ so với các lớp khác. Khi BN được bao gồm trong mạng, trung bình và phương sai của các lớp BN trở thành các tham số thay đổi nhiều nhất. Những quan sát này tương tự như các nghiên cứu trong các lĩnh vực nghiên cứu như học đa nhiệm vụ và thích ứng miền [30, 31] rằng lớp FC cuối và các lớp BN là cụ thể nhiệm vụ và không thể được chia sẻ giữa các nhiệm vụ. Trong CL, lớp FC cuối nhạy cảm vì các nhiệm vụ trong class-IL khác nhau về các lớp dự đoán của chúng, là đầu ra của lớp FC cuối. Cũng trực quan rằng các lớp BN là cụ thể nhiệm vụ vì trung bình và phương sai của các lớp BN nắm bắt moments bậc nhất và bậc hai của phân phối cho các biểu diễn tiềm ẩn. Phương sai của trọng số và bias BN tương đối lớn so với các lớp khác. Vui lòng tham khảo Phụ lục D để biết chi tiết.

Một quan sát thú vị của VGG-11 và ResNet-18 là độ nhạy cảm của các lớp tích chập tăng khi lớp tiến gần hơn đến đầu vào. Lý do có thể là chúng đang tạo ra biểu diễn cho hình ảnh đầu vào, mà sự dịch chuyển phân phối trực tiếp tác động đến lớp tích chập dưới cùng. Chức năng của các bộ lọc trong các lớp trên là tích hợp các mẫu đã học trong các lớp dưới để tạo ra các mẫu cấp cao, do đó các bộ lọc trong các lớp trên tương đối ổn định. Trong Hình 8 của Phụ lục, chúng tôi tiếp tục nghiên cứu động lực học huấn luyện của mỗi bộ lọc trong một nhiệm vụ hoặc qua các nhiệm vụ trong các lớp khác nhau của một mạng. Đầu tiên, động lực học huấn luyện của mỗi bộ lọc trong lớp dưới lớn hơn nhiều so với lớp trên, phù hợp với quan sát ở trên của chúng tôi. Chúng tôi cũng thấy rằng trong cùng một lớp, khi các nhiệm vụ dịch chuyển, động lực học của một số lượng nhỏ bộ lọc tăng đáng kể. Những bộ lọc này nên là cụ thể nhiệm vụ và quan trọng đối với việc học nhiệm vụ mới.

Động lực học trên các kịch bản khác nhau Nghiên cứu thực nghiệm trên bị giới hạn ở SGD mà không áp dụng bất kỳ kỹ thuật CL nào khác và chỉ tập trung vào class-IL. Trong phần tiếp theo, chúng tôi mở rộng các nghiên cứu sang các phương pháp CL khác nhau, tập dữ liệu không tiêu chuẩn và domain-IL trong khi cố định mô hình là ResNet-18. Hình 1 (f) mở rộng nghiên cứu thực nghiệm sang một tập dữ liệu y tế Seq-OrganAMNIST. So với Seq-CIFAR-10, nó khác về số lượng nhiệm vụ, kích thước tập dữ liệu, kích thước hình ảnh và loại dữ liệu. Chúng tôi tiếp tục thay thế SGD bằng ER sử dụng bộ đệm phát lại, mà kết quả được báo cáo trong Hình 1 (g). Thứ tự xếp hạng của các nhóm tham số về độ nhạy cảm vẫn nhất quán dưới sự thay đổi của tập dữ liệu và chiến lược phát lại. Trong domain-IL, như được hiển thị trong Hình 1 (h), động lực học huấn luyện của các tham số khác nhau phù hợp với các quan sát của chúng tôi trong class-IL: chỉ có một phần nhỏ tham số là cụ thể nhiệm vụ. Tuy nhiên, một sự khác biệt đáng chú ý. Vì các lớp đầu ra giữ nguyên qua các nhiệm vụ và chỉ có miền đầu vào thay đổi, lớp FC cuối là nhạy cảm nhất trong class-IL, trở nên bằng hoặc ít nhạy cảm hơn lớp tích chập dưới cùng. Do đó, tính dẻo dai và ổn định của các tham số bị tác động bởi mức độ gần của chúng với các phân phối dữ liệu đã thay đổi.

Cảm hứng từ Các Nghiên cứu Thực nghiệm. Các nghiên cứu trên làm sáng tỏ những cải thiện của các phương pháp CL. (1) Chúng tôi so sánh độ nhạy cảm của các tham số khác nhau trong ba loại mạng nơ-ron sâu và quan sát thấy chỉ có một phần nhỏ trong số chúng nhạy cảm hơn nhiều so với những tham số khác. Điều này ngụ ý rằng chỉ tinh chỉnh những tham số cụ thể nhiệm vụ (hoặc dẻo dai) này có thể đủ để giữ lại các nhiệm vụ trước. (2) Động lực học giữa các epoch liên tiếp cho thấy tất cả các lớp trải qua nhiều thay đổi hơn khi các nhiệm vụ dịch chuyển, có thể được sử dụng để phát hiện ranh giới nhiệm vụ trong CL. Biết ranh giới nhiệm vụ là một điều kiện tiên quyết quan trọng cho nhiều phương pháp CL. Chỉ số đề xuất làm cho vấn đề CL dễ dàng hơn nhiều, làm cho những phương pháp này tổng quát hơn và có thể đóng góp vào các phương pháp CL tốt hơn. (3) Theo Hình 8, trong các lớp tích chập, chỉ có một phần nhỏ của các bộ lọc cụ thể nhiệm vụ dẫn đến sự thay đổi lớn của động lực học khi các nhiệm vụ dịch chuyển. Việc regularization hoặc cô lập những bộ lọc này có thể cải thiện hiệu suất của CL.

[Hình 2: So sánh SGD, phương pháp dựa trên phát lại, FPF và k-FPF. SGD huấn luyện các nhiệm vụ tuần tự mà không phát lại. Các phương pháp dựa trên phát lại huấn luyện mô hình trên dữ liệu được đệm và hiện tại đồng thời. FPF tinh chỉnh các tham số nhạy cảm nhất trong một vài lần lặp sử dụng dữ liệu được đệm ở cuối các phương pháp CL tùy ý. k-FPF định kỳ (bất kể ranh giới nhiệm vụ) áp dụng FPF k lần trong quá trình huấn luyện.]

5 Các Phương pháp Tinh chỉnh Ưu tiên Quên

Nghiên cứu thực nghiệm về động lực học huấn luyện trên các tham số ở trên ngay lập tức thúc đẩy một phương pháp đơn giản nhưng mới lạ cho CL, tức là, "tinh chỉnh ưu tiên quên (FPF)", có thể được áp dụng cho bất kỳ phương pháp CL hiện có nào. Trong k-FPF hiệu quả hơn, chúng tôi tiếp tục loại bỏ việc phát lại từng bước và bất kỳ kỹ thuật CL nào khác mà chỉ đơn giản áp dụng k lần FPF trong huấn luyện SGD. Trong Hình 2, chúng tôi cung cấp một minh họa so sánh SGD, các phương pháp dựa trên phát lại và các phương pháp của chúng tôi. Cuối cùng, chúng tôi đề xuất một chỉ số để tự động xác định các tham số nhạy cảm trong mỗi mạng nơ-ron. Xem Phụ lục A cho quy trình chi tiết của FPF và k-FPF.

FPF để cải thiện hiệu suất CL. FPF áp dụng tinh chỉnh nhẹ cho các tham số cụ thể nhiệm vụ nhất sử dụng dữ liệu được đệm sau khi huấn luyện các phương pháp CL tùy ý. Do đó, nó bổ sung cho bất kỳ phương pháp CL hiện có nào như một bước sửa chữa để loại bỏ thiên vị của chúng trong các tham số cụ thể nhiệm vụ bằng cách tinh chỉnh chúng trên dữ liệu được đệm không thiên vị. Từ đó, nó có thể cải thiện hiệu suất của bất kỳ phương pháp CL hiện có nào mà không gây ra tính toán bổ sung đáng kể.

k-FPF để cải thiện hiệu quả và hiệu suất CL. FPF là một kỹ thuật đơn giản mang lại cải thiện đáng kể, nhưng nó được áp dụng sau khi huấn luyện một phương pháp CL hiện có. Thật không may, nhiều phương pháp CL SOTA yêu cầu phát lại tốn thời gian ở mỗi bước, ít nhất cũng tăng gấp đôi tổng tính toán. Vì chỉ có một vài tham số nhạy cảm trong quá trình dịch chuyển nhiệm vụ, liệu chúng ta có thể phát triển một CL không phát lại và lười biếng thay thế việc phát lại từng bước bằng FPF thỉnh thoảng? Chúng tôi đề xuất k-FPF áp dụng FPF k lần trong CL như được hiển thị trong Hình 2. Không có việc phát lại kinh nghiệm tốn kém, k-FPF vẫn có thể đạt được hiệu suất tương đương như các phương pháp FPF+SOTA CL nhưng chỉ yêu cầu gần một nửa tính toán của chúng. Chúng ta có thể áp dụng k-FPF với bất kỳ phương pháp không phát lại nào, ví dụ, SGD, thường được sử dụng như một ranh giới dưới cho các phương pháp CL. Chúng tôi vẫn duy trì một bộ đệm nhỏ bằng lấy mẫu bể chứa, nhưng nó chỉ dành cho FPF, do đó SGD không bao giờ truy cập nó. Chúng tôi lười biếng áp dụng FPF trên bộ đệm sau mỗi bước SGD (tổng cộng k lần trên k bước SGD) mà không biết ranh giới nhiệm vụ.

k-FPF-CE+SGD Chúng tôi đề xuất hai biến thể của k-FPF, tức là, k-FPF-CE+SGD và k-FPF-KD+SGD. k-FPF-CE+SGD sử dụng mất mát cross-entropy để cập nhật các tham số nhạy cảm trong mỗi FPF. Trong bài báo này, k-FPF-CE đề cập đến k-FPF-CE+SGD nếu không được chỉ định. Mục tiêu của FPF trong k-FPF-CE là: minθ* L(θ*), E(x;y)∼B[lCE(y;f(x))] nơi θ* biểu thị các nhóm tham số cụ thể nhiệm vụ được chọn, B đề cập đến dữ liệu được đệm và lCE là mất mát cross-entropy.

k-FPF-KD+SGD để cải thiện thêm hiệu suất Được lấy cảm hứng từ DER [4], chúng tôi tiếp tục đề xuất k-FPF-KD giới thiệu chưng cất kiến thức (KD) [32] vào mục tiêu trong k-FPF-CE. Trong bài báo này, k-FPF-KD đề cập đến k-FPF-KD+SGD nếu không được chỉ định. Giống như DER, các phản hồi trước softmax (tức là logits) cho dữ liệu được đệm tại thời điểm huấn luyện cũng được lưu trữ trong bộ đệm. Trong FPF, mô hình hiện tại được huấn luyện để khớp với các logits được đệm để giữ lại kiến thức của các mô hình trước. Mục tiêu của FPF trong k-FPF-KD là: minθ* L(θ*), E(x;y)∼B[lCE(y;f(x))] + λE(x;z)∼B[lMSE(z;h(x))] nơi z là logits của mẫu được đệm x, lMSE đề cập đến mất mát bình phương trung bình, h(x) tính toán logits trước softmax và λ là một siêu tham số cân bằng hai điều khoản. So với tính toán của k-FPF-CE, tính toán bổ sung của k-FPF-KD là không đáng kể.

Lựa chọn các tham số nhạy cảm cho FPF và k-FPF
Một thách thức chính trong FPF và k-FPF là chọn các tham số cụ thể nhiệm vụ để tinh chỉnh. Các ví dụ về động lực học huấn luyện cho các lớp khác nhau của các mạng khác nhau được hiển thị trong các biểu đồ (b,d,e) của Hình 1, và thứ tự xếp hạng của chúng không thay đổi qua các epoch. Vì vậy chúng tôi đề xuất chọn các tham số nhạy cảm cho các mạng nơ-ron khác nhau theo động lực học huấn luyện của chúng trong các epoch sớm. Cụ thể, đối với mỗi mạng nơ-ron, các lớp của nó được phân chia thành G nhóm như được hiển thị trong Hình 1, chúng tôi tính toán điểm nhạy cảm Sg cho mỗi nhóm lớp trong mạng nơ-ron bởi

Sg = (1/|θg|)∑θ`∈θg C` / [∑G g=1(1/|θg|)∑θ`∈θg C`] × G     (1)

nơi C` là động lực học huấn luyện được đề cập trong Phần 4.1. Chúng tôi tính toán tỷ lệ độ nhạy cảm cho nhóm g trên tất cả G nhóm trong mạng. Vì mỗi mạng bao gồm một số lượng nhóm tham số khác nhau, chúng tôi nhân với G để quy mô lại điểm nhạy cảm.

Trong các thí nghiệm sau, dưới các kịch bản khác nhau và trên các điểm chuẩn khác nhau, chúng tôi đánh giá hiệu suất của FPF và k-FPF khi chọn các tập con khác nhau của các tham số cụ thể nhiệm vụ. Tóm lại, tinh chỉnh các tham số có độ nhạy cảm cao hơn đạt được nhiều cải thiện hơn, phù hợp với những phát hiện của chúng tôi trong các nghiên cứu thực nghiệm. FPF vượt trội hơn tất cả các đường cơ sở khi các nhóm tham số có Sg > 1 được coi là các tham số nhạy cảm và chỉ chiếm 1,13%; 0,32% và 0,15% số lượng tất cả các tham số trong MLP, VGG-11 và ResNet-18. Đối với k-FPF, tinh chỉnh nhiều tham số hơn, tức là, các lớp tích chập sớm hơn, đạt được hiệu suất tốt nhất. Đây là cái giá của việc loại bỏ phát lại, làm giảm một nửa chi phí tính toán. Chúng tôi đặt ngưỡng điểm nhạy cảm là 0,3 để k-FPF đạt được hiệu suất SOTA và chỉ 12,40%; 1,69% và 24,91% tham số trong MLP, VGG-11 và ResNet-18 được coi là các tham số nhạy cảm.

6 Thí nghiệm

Trong phần này, để so sánh FPF và k-FPF với các phương pháp CL SOTA, chúng tôi tiến hành các thí nghiệm chủ yếu trên ResNet-18. Chúng tôi áp dụng FPF và k-FPF cho nhiều tập dữ liệu điểm chuẩn và so sánh chúng với các đường cơ sở CL SOTA về độ chính xác kiểm tra và hiệu quả. Bên cạnh đó, chúng tôi cũng so sánh hiệu suất của việc tinh chỉnh các tham số khác nhau trong FPF và k-FPF và cho thấy rằng tinh chỉnh một phần nhỏ các tham số cụ thể nhiệm vụ đủ để cải thiện CL. FPF cải thiện các phương pháp CL SOTA với biên độ lớn trong tất cả những kịch bản này, trong khi k-FPF đạt được hiệu suất tương đương với FPF nhưng hiệu quả hơn. Vui lòng tham khảo Phụ lục để biết thêm kết quả và phân tích.

Chi tiết Thực hiện. Chúng tôi tuân theo các thiết lập trong [4] để huấn luyện các phương pháp CL SOTA khác nhau trên các tập dữ liệu khác nhau, ngoại trừ việc huấn luyện mỗi nhiệm vụ chỉ trong 5 epoch, thực tế hơn so với 50 hoặc 100 epoch trong [4] cho thiết lập luồng của CL. Vì các epoch được giảm, chúng tôi tinh chỉnh lại tốc độ học và các siêu tham số cho các kịch bản khác nhau bằng cách thực hiện tìm kiếm lưới trên một tập xác thực của 10% mẫu được rút ra từ tập huấn luyện gốc. Đối với cả FPF và k-FPF, chúng tôi sử dụng cùng một bộ tối ưu, tức là, SGD với lịch trình tốc độ học cosine-annealing, và tinh chỉnh các tham số được chọn với kích thước lô 32 cho tất cả các kịch bản. Các bước tinh chỉnh cho FPF và k-FPF lần lượt là 300 và 100. Chúng tôi thực hiện tìm kiếm lưới trên tập xác thực để điều chỉnh tốc độ học và các siêu tham số khác. Vui lòng tham khảo Phụ lục L cho các siêu tham số chúng tôi đã khám phá.

Các phương pháp đường cơ sở. Chúng tôi áp dụng FPF cho một số phương pháp CL dựa trên bộ nhớ SOTA: ER, iCaRL, A-GEM [34], FDR [35], DER và DER++. Bên cạnh đó, chúng tôi cũng so sánh các phương pháp của chúng tôi với GDUMB [33] và oEWC. Chúng tôi lấy JOINT làm ranh giới trên cho CL, huấn luyện tất cả các nhiệm vụ cùng nhau, và SGD làm ranh giới dưới, huấn luyện các nhiệm vụ tuần tự mà không có bất kỳ biện pháp đối phó nào với việc quên. Đối với FPF, k-FPF và tất cả các phương pháp dựa trên bộ nhớ, hiệu suất với kích thước bộ đệm 200 và 500 được báo cáo. Tất cả kết quả được báo cáo trong Tab. 1 được tính trung bình qua năm lần chạy với các hạt giống ngẫu nhiên khác nhau.

6.1 Kết quả Chính

FPF cải thiện đáng kể hiệu suất của tất cả các phương pháp CL dựa trên bộ nhớ và đạt được hiệu suất SOTA trên tất cả các kịch bản trong class-IL và domain-IL trong Tab. 1. Đối với các phương pháp có quên thảm khốc, như AGEM, độ chính xác của FPF tăng theo cấp số nhân. Sự gia tăng hiệu suất minh họa rằng FPF có thể loại bỏ thiên vị bằng cách tinh chỉnh các tham số cụ thể nhiệm vụ để thích ứng với tất cả các nhiệm vụ đã thấy.

k-FPF-CE thay thế việc phát lại từng bước tốn kém bằng FPF thỉnh thoảng hiệu quả. Trong Tab. 1, hiệu suất của k-FPF-CE trên Seq-PathMNIST, Seq-Tiny-ImageNet và Seq-PACS tốt hơn so với các phương pháp CL tốt nhất, và hiệu suất của nó trên Seq-OrganAMNIST và Seq-Cifar10 cũng tốt hơn hầu hết các phương pháp CL, điều này ngụ ý rằng tinh chỉnh các tham số cụ thể nhiệm vụ trên một số lượng nhỏ bộ đệm trong SGD có thể giúp giữ lại kiến thức trước và giảm thiểu việc quên, việc phát lại từng bước không cần thiết. Trong Hình 3, số lượng FLOPs huấn luyện và độ chính xác của các phương pháp khác nhau được báo cáo. So với FLOPs huấn luyện của một số phương pháp CL, chi phí tính toán của FPF và k-FPF-CE gần như không đáng kể. Tổng FLOPs huấn luyện của k-FPF-CE vẫn ít hơn nhiều so với các phương pháp CL SOTA trong khi hiệu suất của nó tốt hơn, cho thấy hiệu quả của k-FPF-CE.

k-FPF-KD cải thiện thêm hiệu suất của k-FPF-CE để có thể so sánh được với FPF. k-FPF-CE đề xuất hiệu quả của các phương pháp CL, nhưng hiệu suất của nó kém hơn một chút so với FPF. Một trong những sự khác biệt lớn nhất giữa k-FPF và FPF là việc phát lại kinh nghiệm trong quá trình huấn luyện CL. Được lấy cảm hứng từ DER, chúng tôi đề xuất k-FPF-KD, sử dụng chưng cất kiến thức để khớp với đầu ra của các mô hình trước trên dữ liệu được đệm, do đó giữ lại kiến thức của các nhiệm vụ trước. Kết quả của k-FPF-KD trong Tab. 1 cho thấy nó có thể so sánh được với FPF trong hầu hết các kịch bản. Hình 3 cho thấy FLOPs của k-FPF-KD tương tự như k-FPF-CE nhưng ít hơn nhiều so với các phương pháp CL và FPF khác, và trong một số trường hợp, nó vượt trội hơn FPF. k-FPF-KD cho thấy hiệu suất SOTA trong cả hiệu quả và độ chính xác.

6.2 So sánh tinh chỉnh các tham số khác nhau trong FPF và k-FPF

FPF và k-FPF đạt được hiệu suất tốt nhất khi chỉ có một phần nhỏ các tham số cụ thể nhiệm vụ được tinh chỉnh. Trong Hình 4, độ chính xác, FLOPs huấn luyện và số lượng tham số có thể huấn luyện trong quá trình tinh chỉnh của việc áp dụng FPF hoặc k-FPF cho các tham số cụ thể nhiệm vụ khác nhau trong ResNet-18 trên Seq-PathMNIST được so sánh. Qua các kịch bản khác nhau, k-FPF chỉ cần khoảng một nửa FLOPs của FPF với hiệu suất tốt hơn (được chỉ ra bởi Ngôi sao Đỏ). Khi tinh chỉnh trên các tham số cụ thể nhiệm vụ khác nhau, FPF hoạt động tốt nhất khi các lớp BN+FC được tinh chỉnh, chỉ chiếm 0,127% của tất cả các tham số (được chỉ ra bởi Ngôi sao Cam). Điều này phù hợp với các quan sát của chúng tôi trong các nghiên cứu thực nghiệm nơi các lớp BN và FC là các tham số nhạy cảm nhất với sự dịch chuyển phân phối. Và kết quả cho thấy chỉ tinh chỉnh một phần nhỏ các tham số cụ thể nhiệm vụ có thể giảm thiểu quên thảm khốc và tổng quát hóa mô hình.

Hiện tượng đối với k-FPF hơi khác một chút. (1) Trong biểu đồ dưới của Hình 4, khi lớp FC không được chọn để tinh chỉnh trong k-FPF, hiệu suất kém hơn nhiều. Điều này là do, trong class-IL, các lớp đầu ra thay đổi qua các nhiệm vụ, do đó lớp FC được huấn luyện để chỉ xuất ra các lớp cho nhiệm vụ hiện tại [36]. Ngược lại, khi áp dụng k-FPF cho domain-IL trên Seq-PACS, nơi các lớp đầu ra giữ nguyên cho các nhiệm vụ khác nhau, Hình 7 trong Phụ lục G cho thấy rằng tinh chỉnh lớp FC hoạt động tương tự như tinh chỉnh các tham số khác. Do đó, lớp FC cuối nhạy cảm hơn trong class-IL so với Domain-IL. Điều này cũng được thể hiện trong Hình 1 (d,h). (2) Như ngôi sao đỏ chỉ ra, k-FPF cần tinh chỉnh nhiều tham số hơn một chút (Block3 của các lớp tích chập, 18,91% của tất cả các tham số) để đạt được độ chính xác tương đương với FPF. Không có việc phát lại kinh nghiệm trong SGD, mô hình có thiên vị lớn hơn đối với nhiệm vụ hiện tại, và do đó cần tinh chỉnh nhiều tham số cụ thể nhiệm vụ hơn. Điều này cũng chỉ ra rằng thiên vị như vậy của các tham số cụ thể nhiệm vụ là lý do chính cho quên thảm khốc. Khi Block4 (75,22% của tất cả các tham số) được tinh chỉnh, vì nó là nhóm tham số ổn định nhất trong nghiên cứu thực nghiệm của chúng tôi, hiệu suất của k-FPF giảm.

6.3 Phân tích FPF và k-FPF trong Các Kịch bản Khác nhau

FLOPs huấn luyện khác nhau cho k-FPF Trong Hình 5(a), chúng tôi nghiên cứu sự đánh đổi giữa FLOPs huấn luyện và độ chính xác của k-FPF trên Seq-PathMNIST bằng cách thay đổi k và số bước tinh chỉnh. τ trong chú thích đề cập đến khoảng cách của hai FPF liên tiếp. Cố định k, k-FPF bão hòa nhanh chóng khi các bước tinh chỉnh tăng. Điều này ngụ ý rằng k-FPF hiệu quả về FLOPs để đạt được hiệu suất tốt nhất. Đối với các thí nghiệm với k nhỏ, ví dụ k=2, mặc dù tính toán yêu cầu rất thấp, hiệu suất không thể được cải thiện thêm. Điều này ngụ ý rằng FPF cần được áp dụng trên các mẫu được đệm thường xuyên hơn để giảm thiểu việc quên. Khi k lớn, ví dụ, k=41 hoặc 121, độ chính xác cải thiện nhẹ với cái giá của việc yêu cầu tính toán nhiều hơn. Như ngôi sao đỏ trong biểu đồ chỉ ra, áp dụng FPF mỗi 1500 bước huấn luyện có thể đạt được sự đánh đổi tính toán-độ chính xác tốt nhất.

Kích thước bộ đệm và epoch huấn luyện khác nhau cho FPF Kích thước bộ đệm và epoch huấn luyện cho mỗi nhiệm vụ thường quan trọng trong các phương pháp CL dựa trên phát lại. Trong Hình 5(b), khi kích thước bộ đệm hoặc số epoch tăng, hiệu suất của ER cũng cải thiện. Tuy nhiên, việc tăng kích thước bộ đệm mang lại nhiều lợi ích hơn. Khi kích thước bộ đệm hoặc epoch tăng quá lớn, hiệu suất của ER dường như bão hòa và tăng chậm. Đối với tất cả các kịch bản, tinh chỉnh các lớp BN+FC rất hiệu quả trong việc giảm thiểu thiên vị của nhiệm vụ hiện tại và thúc đẩy hiệu suất, phù hợp với các quan sát của chúng tôi từ các nghiên cứu thực nghiệm.

7 Kết luận

Chúng tôi nghiên cứu một vấn đề cơ bản trong CL, tức là, những phần nào của mạng nơ-ron là cụ thể nhiệm vụ và dễ bị quên thảm khốc hơn. Các nghiên cứu thực nghiệm rộng rãi trong các thiết lập đa dạng liên tục cho thấy chỉ có một phần nhỏ tham số là cụ thể nhiệm vụ và nhạy cảm. Khám phá này dẫn đến một "tinh chỉnh ưu tiên quên (FPF)" đơn giản nhưng hiệu quả chỉ tinh chỉnh một tập con của những tham số này trên dữ liệu được đệm trước khi triển khai mô hình. FPF bổ sung cho các phương pháp CL hiện có và có thể liên tục cải thiện hiệu suất của chúng. Chúng tôi tiếp tục thay thế việc phát lại từng bước tốn kém bằng k lần FPF thỉnh thoảng trong CL để cải thiện hiệu quả. k-FPF như vậy đạt được hiệu suất tương đương như FPF+SOTA CL trong khi tiêu thụ gần một nửa tính toán của nó. Trong công việc tương lai, chúng tôi sẽ nghiên cứu cách giảm thêm kích thước bộ nhớ yêu cầu bởi FPF.

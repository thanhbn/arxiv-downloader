# 2306.01690.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/continual-learning/2306.01690.pdf
# File size: 3756710 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Context selectivity with dynamic availability enables lifelong
continual learning
Martin L.L.R. Barry1, Wulfram Gerstner1, Guillaume Bellec1,B
1Department of Life Sciences, Department of Computer Sciences
´Ecole Polytechnique F´ ed´ erale de Lausanne (EPFL), Switzerland
Bguillaume.bellec@epfl.ch
Abstract
”You never forget how to ride a bike”, – but how is that possible? The brain is able to
learn complex skills, stop the practice for years, learn other skills in between, and still
retrieve the original knowledge when necessary. The mechanisms of this capability,
referred to as lifelong learning (or continual learning, CL), are unknown. We suggest a
bio-plausible meta-plasticity rule building on classical work in CL which we summarize
in two principles: (i) neurons are context selective, and (ii) a local availability variable
partially freezes the plasticity if the neuron was relevant for previous tasks. In a new
neuro-centric formalization of these principles, we suggest that neuron selectivity and
neuron-wide consolidation is a simple and viable meta-plasticity hypothesis to enable
CL in the brain. In simulation, this simple model balances forgetting and consolidation
leading to better transfer learning than contemporary CL algorithms on image
recognition and natural language processing CL benchmarks.
Introduction
While Artificial Neural Networks (ANNs) have made impressive advances in various
computational tasks, their approach to continual learning (CL) differs from that of the
human brain. Traditional ANNs, encompassing architectures like multi-layer
perceptrons [1], Long-Short-Term Memory [2], Convolutional Neural Networks [3], and
Transformers [4], face the challenge of integrating new knowledge without inadvertently
disrupting prior information—a phenomenon termed ”catastrophic forgetting” [5–7]
which is a manifestation of the classic stability-plasticity dilemma in computational
neuroscience [8]. The human neural system, however, has a remarkable ability to
assimilate new experiences without completely overwriting old ones, while generalizing
previous knowledge to new problems (forward transfer) [9] and updating prior
knowledge when learning a new, but related task (backward transfer). The difference in
performance between ANNs and the human brain has attracted the attention both of
computational neuroscientists working on synaptic learning theory [10,11] as well as
machine learning experts interested in biological inspirations [5,6,12,13].
Cortical neurons are selective to sensory stimuli [14,15] as well as more abstract
concepts [16,17]. Populations of neurons encode abstract rules or contexts [18,19], most
likely implemented by modulation of their gain function [20 –25]. We conjecture that the
mechanism by which humans achieve continual lifelong learning is rooted in
context-specific modulation of neuronal activity [26] and metaplasticity [27] of synaptic
connections. At a cognitive level, our hypothesis can be summarized as follows: When
January 26, 2024 1/31arXiv:2306.01690v2  [cs.LG]  25 Jan 2024

--- PAGE 2 ---
we encounter a new learning challenge (say we learn a new foreign language) a
context-selective modulation of cortical neurons leads to partial specialization of
neurons for the specific context; once selective neurons learn through synaptic plasticity
(we learn this language sufficiently well), the plasticity of these neurons is then partially
frozen (the new language will never be forgotten) even when the next learning task is
encountered (another foreign language).
To derive a functional and plausible mechanism for CL we identified two principles
that summarize the essence of existing CL models [6,10,13,28 –35] (see Discussion for an
exhaustive review): (Principle 1) Neurons are gated to induce context selectivity, and
(Principle 2) the parameters can be frozen by Obstruction of Neural parameter updates
to prevent overriding important previous knowledge. In this paper, we suggest a
re-formalization of Principles 1 and 2 termed ”GateON” which is grounded in a
mathematical understanding of CL. Despite the apparent conceptual simplicity of
GateON, it is less subject to forgetting and achieves better transfer learning in
comparison with previous CL algorithms on established CL benchmarks such as
permuted MNIST [6,10], split CIFAR-100 and natural language processing (NLP)
benchmarks with a pre-trained BERT model [36]. On most metrics, GateON ranks
better than algorithms involving significantly more complex mechanisms like a perfect
replay of previous data samples [13,28 –33]. Additionally, we argue that GateON enables
two unique and new contributions:
First, not only does the availability variable freeze parameters that are relevant to
previous tasks, but it can also un-freeze parameters when resources are necessary.
Hence, it balances automatically between forgetting and consolidation. Un-freezing
parameters is shown to be decisive for large task families of 100 tasks.
The second novelty is a new computational understanding of biology: we describe a
neuro-centric formalization of Principles 1 and 2, so-called n-GateON. Rather than
freezing synaptic weights individually, all the neuron parameters of a neuron are
freezing simultaneously. We show in particular a principled and efficient approximation
of n-GateON where the recent neuron activation is directly freezing the neuron’s
parameter updates. Hence this simple metaplasticity hypothesis does not require
non-local task-specific information like loss gradients. This demonstration is an attempt
to exhibit functional models of CL that are simple enough to be falsifiable in
experimental neuroscience. Concretely the resulting mechanism could explain some
features of real neurons: the neural selectivity modulated by contextual information as
widely observed in the brain [20 –26] is explained but the formalization of Principle 1 in
GateON; and Principle 2 in n-GateON formalizes the hypothesis that neuron-specific
dynamic variables integrate the activation history and control the availability for future
plastic changes which links to metaplasticity [27,37] and synaptic consolidation [38 –41].
On a higher level, given the high importance of the coordination of principles 1 and 2 in
our simulations, we speculate that neuron selectivity and neuron-wide consolidation
might have evolved together to enable CL in the brain.
1 Results
Our results are presented in the following order: We first describe the mathematical
principles that we identified to be the foundation of efficient CL (Section 1.1). Then we
derive a biologically plausible implementation of this model which illustrates how neural
selectivity can be the pillar of a metaplasticity rule for CL (Section 1.2). The
quantitative results about the performance of GateON on machine learning benchmarks
are reported in Section 1.3.
January 26, 2024 2/31

--- PAGE 3 ---
1.1 A normative theory for continual learning
In order to study CL, we follow an established paradigm [6,10] and use a sequence of K
supervised tasks T1, T2, . . . T K, where each task is also referred to as a ’context’. The
performance of the network on task Tkis quantified by the loss Lkaveraged over all
data points in that task. The same task Tkis used for an unknown time before a switch
to another task occurs. A single time point tcorresponds to the presentation of a single
data point (or a minibatch of data points) at the input layer of the network, followed by
network processing, and calculation of the loss based on the network output. The
instantaneous loss for a single data point (or a minibatch of data points) is Lt.
Principle 1: Gated context selectivity. To define a model of contextual selectivity
in neural network models, we assume that each network unit is gated by a
context-dependent sigmoidal gate. We describe here the case of a feedforward network
comprised of Llayers with Nneurons per layer (the extension to Transformers is
highlighed in section 1.3 and to Convolutional Neural Networks (CNNs) in Methods
3.3). The activity xl
iof a neuron iin layer l≥1 is determined by a multiplicative gain
function [24,26] with gating factor gl
iand activation function f:
xl
i=gl
i·f
X
jwl
ijx(l−1)
j
,where gl
i=σ 
vl
ik
. (1)
Here, wl
ijis the connection weight from neuron jin layer l−1 to neuron iin layer l,
while vl
ikrepresents the context-specific ’gating weights’ that control neuron iin layer l.
The index kwhich determines which context is active is considered to be given as input
in the CL literature [12,42] and we follow this assumption in this theoretical section.
Biases (thresholds) are treated as additional weights for simplicity. The function σis
chosen as a rectified hyperbolic tangent to ensure that the range of gl
i(t) is confined
between 0 and 1. The network input is represented by x(0)
iand the output by yi=xL
i.
The gating weights are initialized randomly and learned with normal gradient descent
(Principle 2 does not apply to these parameters). In effect, this gating selects a
distributed subset of neurons that actively participate in the information processing for
a context kwhereas other neurons that participate in other contexts are, at least
partially, turned off. Mechanisms like lateral inhibition [34,43] or divisive
normalization [44,45] could implement a similar gating in a biophysical network model.
Extension of Principle 1 to unidentified context switches. In general, a
context switch is not marked: for example, toddlers in a multi-lingual environment are
expected to infer by themselves change points between two spoken languages. To
illustrate that the GateON Principles also apply when the context identities (i.e. the
task index) are not provided, we also studied a variation of Principle 1 in which the task
index kat each time step is inferred by detecting a sudden increase in the loss Lt.
Simply put, this alternative model indicates a change point each time a moving average
ofLtcrosses some threshold (see Methods 3.1 for a precise formalization, this simple
model is also inspired by computational neuroscience models [43,46]). Importantly,
while with this simple model variation of contexts are inferred without supervision, no
additional changes in the GateON theory are required (see section 1.3). Other context
detectors have been studied in more detail [47,48] and could have been used in
conjunction with GateON. To yield a fair comparison with machine learning algorithms,
we use the standard CL paradigm where the task index kis given directly.
January 26, 2024 3/31

--- PAGE 4 ---
Principle 2: Gradient Obstruction - freezing and unfreezing of plasticity.
Additionally to the context-selectivity, a functional CL model requires a second
ingredient: in our conjecture when neurons are specialized for a task, their parameters
should freeze to avoid later overwriting of acquired knowledge. Assuming that during
context kplasticity implements gradient descent of the loss Lk, we formalize below how,
and when, the gradient descent updates need to be obstructed (Principle 2). To make
the relationship with the machine learning literature explicit, we first formulate
Principle 2 in a parameter-centric view where the update of a parameter θis obstructed.
The parametric view. The parametric view of GateON (p-GateON) is inspired by
previous CL models [13,49,50] which maintain stable weight vectors in the feedforward
processing path to mitigate catastrophic forgetting. Yet, it is possible to build examples
where naively preserving previously optimized weights can impede training for
subsequent tasks - so that a partial unfreezing of previously learned weights is
preferable. To navigate the challenges, the novel theory of p-GateON is formalized using
an ’adaptive learning rate’ that flexibly modulates gradient updates of individual
parameters. More precisely, updates of a parameter θare proportional to the gradients
with a learning rate that is controlled by the ’availability’ Aθ:
∆θ=η Aθ∂Lt
∂θ(2)
where ηis the nominal learning rate (SGD, Adam, . . . ). The availability Aθis bounded
between zero and one and will be defined in the next paragraph. As shown in Eq. (2),
the smaller the availability Al
θ, the larger the obstruction of the gradient. In otherwords,
our method can freeze each parameter individually. Note that only the feedforward
weights wl
ijare modulated by the availabilities, the contextual weights vl
ikare optimized
with standard gradient descent.
Definition of the availability. We define the ’availability’ Aθto track whether the
parameter θhas been relevant for recent tasks. High relevance leads to low availability
for future tasks so further parameter updates are obstructed. Mathematically Aθis an
integrator of the ’normalized relevance’ µnorm
θ which measures the causal impact of θof
the task performance Lkfor previous tasks. A major innovation here is the definition of
the ’normalized relevance’ µnorm
θ given in the next paragraph. The availability
integrates the quantity µnorm
θ over time using the formula:
Aθ(t+ 1) = [ Aθ(t)(1−ηA(µnorm
θ−ϵ))]1
0, (3)
where ηAandϵare non-negative constants. The clip function denoted [ x]1
0is the
identity function inside [0 ,1], takes a value of 1 for x >1 and a value of 0 for x <0. By
construction, Eq. (3) has two stable fixed points for Aθ= 0 and Aθ= 1 and ϵis a
threshold controlling the convergence of this equation: the availability decays
exponentially to zero as soon as µnorm
θ > ϵ, or it increases exponentially fast to 1 if
µnorm
θ < ϵ. To summarize, if a parameter is relevant ( µnorm
θ > ϵ) the availability Aθ
converges to 0 which freezes the parameter θby obstructing subsequent parameter
updates. When a parameter later becomes irrelevant for another task, the availability
increases again slowly leading to unfreezing of the parameter. The relation between the
time scales of freezing and unfreezing is discussed in Supplementary A.1 . The
hyperparameter ϵis important to balance the trade-off between preserving
representations of previous tasks and maintaining the flexibility of the network for
future tasks. The effect of ϵwill be studied in simulations.
January 26, 2024 4/31

--- PAGE 5 ---
Algorithmic relevance estimation. An important component of the theory is to
measure µnorm
θ to quantify the causal impact of θon the task performance. Ideally the
causal impact of the neuron ion the loss Ltwould be defined as the difference of
performance between the current loss Ltand the hypothetical loss if the parameter θ
would be removed in the same setting:
µθ= (Lt
|θ=0− Lt)2, (4)
where Lt
|θ=0denotes the loss under the assumption that θ= 0 for the same data-point.
Intuitively, a parameter is relevant if the loss changes by a large amount when it is
removed. The evaluation of the relevance in (4) is computationally expensive, as it
would require evaluating the loss function once per parameter. We therefore
approximate it by its first-order Taylor expansion around the current set of parameters,
i.e.,Lt
|θ=0=Lt−∂Lt
∂θθ. Eq. (4) then becomes:
µθ≈∂Lt
∂θθ2
. (5)
Note that∂Lt
∂θθcan be calculated efficiently since it involves the same gradient with
respect to parameters that is also used in BackProp. Finally, we normalize µθso that
GateON is insensitive to the scaling of the loss function Lkand the parameters ηAand
ϵdo not have to be fine-tuned for every CL problem. To do so, we use a softmax
normalization
µnorm
θ =N2µθP
θ′µθ′, (6)
where N2is the number of parameters wl
ijin the layer l(Nis the number of neurons).
As a consequence 0 ≤µnorm
θ≤N2and the availability dynamics which is insensitive to
a re-scaling of the loss because it it is canceled by softmax in Eq. (6). Noting that value
µnorm
θ = 1 corresponds to a uniform softmax distribution, so the multiplication by N2
makes sure that a threshold value ϵ= 1 automatically balances between freezing or
un-freezing parameters: When the availability variables change, there is at least one
parameter is deemed irrelevant and un-freezes ( µnorm
θ <1) and one relevant parameter
that freezes µnorm
θ >1. In other words, GateON with parameter ϵ= 1 is designed to
balance between forgetting and consolidation, in simulations we also tested ϵ= 0.5
which favors slightly consolidation over forgetting.
1.2 Bio-plausible implementation of GateON
We describe now an extension of the GateON theory and justify why we believe this
alternative implementation is more compatible with existing biological data and
mechanisms.
The selectivity of cortical neurons to experimental context supports
Principle 1. To begin with, we view Principle 1 (the gated context selectivity, Eq. 1)
as a simple model of the neural selectivity that is widely observed in the brain.
Classically in visual cortices, it is well known that neurons are highly selective to visual
stimuli [14] such that the population of selective neurons builds together a sparse and
distributed code of visual stimuli [15] or more abstract concepts [16]. Importantly,
contextual rules are represented in non-sensory cortical areas such as prefrontal cortex:
when training a monkey on multiple visual tasks, neurons develop distributed feature
representations including selectivity to task rules [18,19]. We see our gated context
selectivity model of Eq. (1) as a minimal model of these general observations in line
with earlier models of multiplicative gain function modulation [24,26].
January 26, 2024 5/31

--- PAGE 6 ---
A plausible neuro-centric implementation of Principle 2. Given the context
selectivity of cortical neurons, we conjectured that a hidden biological mechanism
capable of tracking the context relevance over long time scales is likely to be found at
the neuronal level rather than the synaptic level. Under this assumption, we look for a
neuro-centric implementation of Principle 2 where the availability variable is related to
neuronal variables (such as firing rate or membrane potential) instead of auxiliary
synaptic variables. Using the same normative theory that we used to derive p-GateON,
we now derive n-GateON as an analogous, but neuro-centric, model.
We consider that each neuron has an availability variable Al
iwhich obstructs the
plasticity of all the parameters of neuron iin layer l. Similarly, as previously, this
availability Al
ishould integrate the causal impact of the neuron ion the loss Lk. Hence
in this neuro-centric perspective Principle 2 is formalized by the two equations:
∆wl
ij=η Al
i∂Lt
∂wl,
ijand µl
i≈∂Lt
∂xl
ixl
i2
, (7)
where xl
iis the activity of neuron iis layer l. The availability is updated otherwise as in
Eq. (3) where we normalize µl
iin the range [0 , N] instead of [0 , N2] since we have N
neurons instead of N2parameters. Having significantly fewer availability variables in
this model will have advantages and disadvantages that we analyze in the simulations in
Section 1.3. Figure 1 bottom illustrates an example of the availability of task-selective
neurons across three tasks.
Further simplification of the relevance computation? As it stands, we view the
formalization of n-GateON as a convincing biologically plausible realization of
Principles 1 and 2. The model n-GateON will be implemented as described above in all
simulations unless explicitly stated otherwise. However, it may argued that the
plausibility of the model is incomplete because the derivative∂Lt
∂xl
iin Eq. (7)requires a
biologically plausible implementation of Backprop which, by itself, remains an open
problem in the field. This issue is that a mechanism distinct and equally complex as the
network itself is necessary to compute the backward pass but is not found in the
brain [51]. It gives rise to biologically plausible approximations of back-prop [52–55],
and importantly here, most of them are compatible with our model. To compute the
gradient∂Lt
∂θwith local variables or bio-plausible top-down signals, the hardest part of
these theories is to provide a plausible computation of the gradient∂Lt
∂xl
i. Since µl
irelies
on the exact same term, any combination GateON with such a model is viable as it
relies on the same term.
We found however that an alternative derivation of the causal influence of the
neuron ion the rest of the computation is also possible. We derive in Methods 3.2 a
formula for µl
ito evaluate the effect of the neuron ion the next layers rather than the
loss itself. It turns out that this derivation is proportional to
µl
i= (xl
i)2(8)
which yields a simplified relevance definition that is much easier to compute locally
without feedback from the downstream network. Fig. 2 shows that the approximation
of Eq. (8)is functional although slightly less efficient than the gradient-based definition
of n-GateON in Eq. (7).
1.3 Framework for Simulation Results
Before reporting the simulation results for p-GateON and n-GateON on CL
benchmarks, we introduce multiple metrics to quantify the success of a CL model.
January 26, 2024 6/31

--- PAGE 7 ---
DogContext layerContext detector
CatContext layerContext detector
Task 2 selectiveTask 3 selectiveNetwork averageTask 1Task 2
A(t)g(t)x(t)Task 1Task 2Task 300.02500.10.501002003004005006007000f(ℒ)f(ℒ)Fig 1. Neural selectivity and learning availability. Top Panel : Illustration of
the GateON selectivity mechanism across two sequential tasks. Consider the scenario
wherein task 1 classifies the animal on the left side of an image, while task 2 classifies
entities on the right. In the neural network, the context layer silences the neurons in
blue and leaves the red ones active. Connections illustrated as dashed lines represent
those with diminished availability by the end of the task. Bottom Panel : A
representative simulation of n-GateON spanning a sequence of three tasks using
permuted MNIST. We display the mean neural activity of task-selective neurons ( x,
top), the gating state of task-selective neurons ( g, middle), and availability ( A) for 250
mini-batch presentations. The blue and yellow trajectories represent averages across
those neurons with activity above some threshold during tasks 2 or 3.
Tasks T1, T2, ..., T Kare presented one after the other and training stops when the
last task TKhas finished. Let t0denote the time when the first task starts and tkthe
time point when the last data for task Tkis given. In CL several aspects of the network
robustness and performance can be tested. Classically, standard neural networks trained
with gradient descent are subject to catastrophic forgetting , which is visible when the
performance drops drastically for earlier tasks Tkwhen new tasks Tk′with k′> kare
learned. Another problem emerges specifically with CL algorithms that aim to ’freeze’
parameters in order to hold the knowledge of previous tasks: if all the model parameters
are frozen after ktasks, we say that the model is saturated which undermines its
performance on any future task k′> k.
The last question is whether the model is capable of re-using previous knowledge for
future tasks: the accuracy on task T′
kis better after learning task kthan if task k′is
learned in isolation. If so, this is a sign of forward transfer . Reversely, learning a later
taskTk′can improve the accuracy on task Tkwhich is a sign of backward transfer .
In practice, we employ four quantitative measures in Methods 3.4 to quantify these
high-level aspects:
(i) The immediate test accuracy Ak
cc, measures the test accuracy on a single task Tk
immediately after training this task, i.e., after the update step at time tk. It measures
saturation .
(ii) The continual accuracy Acont,k
cc , is computed by testing the accuracy on task Tk
after training all later tasks Tk′with k′> k. The quantity is averaged for all k′> k.
The continual accuracy is a combined measurement of saturation andforgetting .
January 26, 2024 7/31

--- PAGE 8 ---
network availability task-locked
 test accuracycontinual  accuracyRotatedShuﬄed
97.60%97.30%97.68%246810
100101102100101102100101102Permuted
97.82%97.41%97.76%97.72%97.86%97.47%2468102468100.50.70.30.10.610.40.20.80.610.40.20.80.610.40.20.80.50.70.30.10.50.70.30.1Fig 2. Effect of bio-plausible simplification of the relevance measure in
n-GateON . Top: The average availability ⟨Al
i⟩of neurons (evaluated at times tkfor
tasks 1 ≤k≤10) decreases over 10 tasks for MNIST CL problems Permuted (left),
Rotated (middle) and Shuffled MNIST (right) using n-GateON with ϵ= 0. The blue
curve shows results with the algorithmic relevance of Eq. (7), the green one with the
simplified bioplausible relevance of Eq. (8) and the orange one shows an intermediate
bioplausible variant for comparison (see Methods 3.2 ). Middle and Bottom: With all
three relevance definitions, n-GateON approaches a similar value of a task-locked
accuracy (middle) and continual accuracy (bottom) above 97% after 500 training steps
per task.
(iii) The accuracy deviation ∆Ak
cc, computes the relative difference between the
immediate test accuracy on task Tkand the accuracy of the same network trained only
onTk(∆Ak
cc>0 for k≥2 implies forward transfer ).
(iv) The forgetting rate FRk, is the difference between the immediate test accuracy
and the continual accuracy. A positive FRkmeans that the model has forgotten task
k, while a negative FRkimplies that the previously trained task Tkincreases its test
accuracy during training of later which is an evidence for backward transfer .
For all four measures, we omit the index kwhen the measure is averaging over all
taskk. For instance, the forgetting rate FRis the averaged of all FRk.
Model comparison on established image CL problems To investigate the
properties of the GateON method we apply it to four standard CL problems [5,56,57]
derived from the MNIST dataset. For each of the four problems, the network receives
the image pixels as inputs and gives a digit label as output. By changing the
input-output convention in different ways in the four different models, we can
alternatively measure the robustness to: random input pixel permutations ( permuted
MNIST ), structured input changes via image rotation ( rotated MNIST ), random output
changes ( shuffled MNIST ) and incremental addition of new label classes ( split MNIST ).
When it is clear from the context that we refer to permuted MNIST we will refer to this
benchmark as permuted . The task specifications are given in Methods 3.6
To enable a comparison with State-of-the-Art CL methods, we tested n-GateON and
p-GateON on several CL problems across K= 10 MNIST-related tasks (Tab. 1). We
consider a network with 2000 hidden neurons per layer. We observe that GateON
performs well across allthree established CL MNIST problems. The continual accuracy
January 26, 2024 8/31

--- PAGE 9 ---
Models Permuted Rotated Split Replay-free Fixed model
EWC [6] 96.9 84 - ✓ ✓
SI [10] 97.1 98.9 - ✓ ✓
n-GateON 0 ( ours)97.8 99.2 99.98 ✓ ✓
p-GateON 0 ( ours)97.3 99.3 99.98 ✓ ✓
RMN [59] 97.7 - 99.5 ✓ ✓
Active dendrite [42] 97.2 - - ✓ ✓
OGDT [58] 86.4 88.3 98.8 ✓ ×
HAT [12] (98.6) - 99.0 ✓ ×
Zoo [28] 97.7 (99.7) 99.97 × ✓
Isolated tasks 98.0 99.4 99.99
Table 1. Comparison of continual learning models on MNIST. Continual
accuracy Acont
cc(in percent) for the three classical CL-paradigms ( Permuted ,Rotated ,
andSplit MNIST) over 10 tasks. ”Replay-free” means that the CL algorithm does not
re-sample data from previous tasks, and ”Fixed model” means that the model does not
use task-specific readout layers. GateON 0 refers to our model with ϵ= 0. Isolated tasks
refer to the averaged accuracy for 10 vanilla networks trained on each task separately.
The Rotated value for Zoo is in parentheses because they used only 5 fixed small
rotations as opposed to random ones. The permutated MNIST performance of HAT is
in parentheses because we suspect a difference in the task specifications given the large
result margin above the isolated tasks baseline, we were unable to reproduce this result.
that is reached is close to the performance of ’Isolated’ models optimized for each task
separately. We emphasize in particular that GateON achieves high continual accuracy
despite its conceptual simplicity. For instance, GateON does not replay samples from
previous tasks as in [28,42]. Similarly, it does not use task-dependent network outputs
as in [12,58]. While most existing CL algorithms cannot be mapped onto mechanisms
as simple mechanisms as GateON (only EWC and SI are comparatively simple),
GateON achieved a continual accuracy higher than all other CL models on comparable
task specifications. Interestingly p-GateON and n-GateON are both reliably efficient
across permuted ,rotated ,split andshuffled MNIST (see also Table 3) showing that the
generic GateON theory works for various types of input and output CL task variations.
For further comparison, we applied GateON to a CL problem derived from the
CIFAR 100 image dataset using a ResNet convolutional network model rather than a
fully connected model. The problem, Split CIFAR 100, contains 20 tasks constructed
with object class pairs appearing incrementally. The continual accuracy of GateON is
above all replay-free models we found in the literature (Table 2). Interestingly, on this
task, n-GateON performs better than p-GateON.
Ablation study with 100 MNIST tasks. When the number of tasks increases, the
effects of network saturation and forgetting become more critical since the tasks are
competing for the limited network resources. Therefore we considered larger problems
consisting of 100 permuted ,rotated , and shuffled MNIST tasks. In the case of Shuffled
MNIST we increase the network size from 2000 to 5000 neurons per layer (see methods).
To study the importance of Principle 1 and 2 separately in the GateON theory, we
compare the results of GateON with four other models: an ANN of the same size
trained with vanilla gradient descent (i.e., neither Principle 1 or 2 are implemented);
and two ablated models ’Gating only’ and ’Obstruction only’ which implement only
January 26, 2024 9/31

--- PAGE 10 ---
Models Split CIFAR 100
EWC [6] 75.3
n-GateON 0 ( ours)84.6
p-GateON 0 ( ours)82.5
RMN [59] 80.1
Isolated tasks 85.4
Table 2. Efficiency of the bio-plausible version of n-GateON on CIFAR-100.
Continual accuracy (in percent) on the task Split CIFAR-100 which is our hardest
image CL challenge.
Test accuracy
020 40 60 80 100
Task #0.940.98
0.90
0.86
Missed detections
020 40 60 80 100
Task #4070
20
010305060GateON 0 GateON 0.5 GateON 1
A B
Fig 3. The ϵparameter affects network saturation . The parameter ϵcan be
understood as the rate for unfreezing parameters. A: Immediate test accuracy (in
percent) across tasks for Permuted on n-GateON (with task identity given, not inferred).
The colors refer to different values of the parameter ϵ. For ϵ= 0 (blue), the test
accuracy drops after about 10 - 20 tasks indicating that the network saturates and
cannot learn new tasks. B: Simulation where the context index kin inferred. We show
the fraction of missed detections of task switches for n-GateON (in percent).
Principle 1 or 2, but not the other one. The vanilla gradient descent model
underperforms for all tasks, a phenomenon previously observed when studying
catastrophic forgetting [60,61]. The results of Table 3 show that both gating and
obstruction improve substantially the performance over the vanilla baseline, but none of
them work competitively on their own. As a reference point, the Active Dendrites
method [42] achieved 91 .2% continual accuracy on the permutated task with 100 task
which is higher than the ablated models but lower than p-GateOn and n-GateON which
achieve 96 .5% and 95 .7% of continual accuracy respectively. Note that most of the other
models that we reviewed previously were only tested on 10 and not 100 tasks, and we
argue below that with an increasing number of tasks, the un-freezing mechanism like
the normalization of the relevance via the threshold ϵin GateON becomes crucial.
Freezing and unfreezing of parameters with the hyper-parameter ϵ.We now
show that the parameter ϵbecomes crucial to control the trade-off between network
saturation and forgetting when the number of tasks is large. Although our method with
the parameter ϵ= 0 has achieved state-of-the-art results with 10 MNIST tasks, network
saturation problem emerges with 100 MNIST tasks: once all parameters are frozen the
network cannot learn new tasks. This problem has not been identified in previous
literature because of the small number of tasks, yet we see in table 3 that the saturation
problem is most critical for unstructured tasks like Permuted andShuffled MNIST. We
January 26, 2024 10/31

--- PAGE 11 ---
explain below how the ϵparameter can mitigate this problem.
First let us focus on the mathematical definition of the availability variable in Eq.
(3). With a choice of ϵ= 0, the only stable fixed point of the availability is at zero
which implies that eventually all parameters will be frozen and the model saturates (it
cannot learn anymore). By contrast, with ϵ >0, if a parameter (or a neuron) is not
relevant for the current task, it takes a value of µnorm
θ = 0, and as a consequence its
availability increases exponentially fast to 1 enabling to overwrite this parameter. It
avoids complete saturation but enables forgetting of previous knowledge. When a
parameter relevance is higher than the average relevance, the normalized relevance
variable µnorm
θ goes above the value of one, so the choice ϵ= 1 offers a generic threshold
to freeze and unfreeze depending on the relative relevance of the parameters. In this
sense, setting ϵin this range provides an intermediate value that is designed to trade off
between forgetting andsaturation .
In practice, we tested the values ϵ= 0, 0 .5, or 1. The impact on saturation and
forgetting is illustrated in Fig. 3A. The evolution of immediate test accuracy during the
sequential training of 100 tasks reveals a distinct drop in accuracy after 10 tasks for
n-GateON with ϵ= 0 due to the saturation of the model. We observe that this issue is
mitigated when ϵ= 1 and ϵ= 0.5. In Fig. 3B we show another consequence of
saturation, in the setting where the task index kis inferred at each sample and not
given as an input. We find that a saturated model becomes incapable of inferring the
task index when it gets saturated. The impact of ϵon the overall continual accuracy on
100 MNIST tasks is reported in Table 3.
A drop in continual accuracy may reflect saturation or forgetting. However, for ϵ= 0
where we expect saturation, this is visible on Permuted MNIST with n-GateON only
73.6% of continual accuracy due to saturation but this performance increases to 95 .7%
with ϵ= 1. Interestingly, we also observe that the saturation problem appears to be
stronger with n-GateON than p-GateON. Our Interpretation is that saturation is less
prominent if there are more availability variables: with a fully connected network,
n-GateON has Navailability variables per layer, whereas p-GateON has N2.
We report the forgetting rate FRin Table 4 (right column). Since all the values are
positive it means that the model operates in the forgetting regime on this task and not
in the backward transfer regime. Forgetting is less pronounced for ϵ= 0 and p-GateON
which is consistent with the idea that saturation and forgetting exhibit antagonistic
tendencies in this model.
Transfer learning on rotated and shuffled MNIST. We now ask whether our
model is capable of inducing transfer learning. We first study forward transfer using the
accuracy deviation ∆ Accwhich compares continuous and isolated accuracy: a positive
value indicated that the network benefited from previous tasks. Our results are
summarized in Table 4 (left). All table entries showing a positive accuracy deviation
(evidence for forward transfer learning) are shown in green.
We find that all GateON variants can achieve forward transfer learning.
Interestingly, forward transfer occurs in the Rotated andShuffled MNIST but not on
thePermuted MNIST. It is on Rotated MNIST with n-GateOn and ϵ= 1 that we
achieved the highest forward transfer learning. We interpret that forward transfer is
easier when some structure is shared across tasks (e.g., visual features can be re-used in
Rotated , but not in Permuted MNIST).
To understand how transfer learning occurs we attempt to reverse engineer the
trained network in Fig. 4. We display the Pearson correlation between gating weights
matrices across the 100 tasks in each of the four layers of the network. In Permuted
MNIST, after 20 tasks, we see a high correlation in the output layer, suggesting that the
final layer is shared across tasks (last panel of the first row in Fig. 4), but no systematic
January 26, 2024 11/31

--- PAGE 12 ---
Permuted Rotated Shuffled
Vanilla gradient descent 26.3 69.7 13.4
Obstruction only 18.7 48.3 11.1
Gating only 55.1 71.6 62.1
n-GateON 0 73.6 97.6 97.7
n-GateON 0.5 92.9 97.6 97.3
n-GateON 1 95.7 97.7 96.9
p-GateON 0 96.3 97.9 97.7
p-GateON 0.5 96.5 97.8 97.5
Table 3. Ablation study for GateON on large task families. Continual accuracy
Acont
ccresults (in percent) on Permuted ,Rotated , and Shuffled MNIST for 100 tasks.
This harder setting with many tasks was only considered in the Active Dendrites
paper [42], where they report 91 .2 continual accuracy on the permutated task. Results
for GateON with CNNs can be found in Supplementary A Table.
Forward transfer ∆Acc Backward transfer FR
Permuted Rotated Shuffled Permuted Rotated Shuffled
n-GateON 0 -5.61 0.59 0.26 14.82 0.35 0.12
n-GateON 0.5 -1.57 0.66 0.39 2.06 0.33 0.62
n-GateON 1 -0.48 0.7 0.4 1.12 0.24 1.09
p-GateON 0 -0.6 0.64 0.24 0.48 0.14 0.13
p-GateON 0.5 -0.05 0.55 0.29 0.84 0.16 0.37
Table 4. Transfer learning on 100 MNIST tasks . On the same simulation as in
Table 3 we report the transfer learning capabilities of GateON. We measure forward and
backward transfer learning with ∆ AccandFR, respectively. Green values show evidence
of forward (positive) or backward (negative) transfer. On MNIST we do not observe
backward transfer (no green).
correlation in earlier layers. In the second row of Fig 4, we show the same analysis for
Rotated MNIST. The tasks are re-ordered to ensure that neighboring task numbers
correspond to similar rotation angles. In this case, we see strong correlations along the
diagonal across all layers suggesting that the features are shared across tasks with
neighbouring angles.
1.4 Continual learning in natural language processing
Continual learning is particularly relevant for language models for two reasons: On a
metaphoric level, a convincing model of lifelong learning should explain the mechanism
that enables learning new foreign languages without forgetting the one previously
acquired. On a more pragmatic level, a typical use case for CL in machine learning
would be to update the knowledge of a pre-trained language model year after year as
more data accumulates. In the present work we describe how to apply the GateON
principle to language models of intermediate sizes and report the performance on
existing CL benchmarks for NLP: Aspect Sentiment Classification (ASC) [62],
Document Sentiment Classification (DSC) [63], and Text Classification using 20News
data [64] (20News). We summarize the three CL benchmarks below:
The ASC CL problem involves sentiment analysis on product reviews, with the
network required to classify each aspect of the product, such as the picture or sound, as
positive, negative, or neutral. The CL problem includes 19 products, with each product
considered a separate task. The aspect term and sentence are concatenated using the
January 26, 2024 12/31

--- PAGE 13 ---
Task #Task #
0.400.1-0.10.20.3
PermutedRotatedLayer 1Layer 2Layer 3Layer 4Task #050050050050050050050050050100050100Fig 4. Emergence of shared network structure through transfer learning .
This figure showcases the Pearson correlations of context weights across all layers of
n-GateON CNN 0 after, trained on 100 tasks for Permuted (top) and Rotated (bottom).
We use n-GateON CNN to show the effect on both fully connected and convolutional
layers. As expected for Permuted after 15 tasks we observe a positive correlation of the
context weights in the output layers suggesting that it is then shared across tasks, in
contrast, there is no structure in early convolutional layers due to the randomness of the
permutation. For Rotated we re-ordered after training the tasks by increasing angles.
The context weights are correlated for neighboring tasks to facilitate generalization.
The correlation across neighboring tasks is most striking at intermediate layers.
[SEP] token, and the [CLS] token is used to predict the opinion polarity. For example,
the network receives “[CLS] torchlight [SEP] this is a good torchlight” and should
output ’positive’ for the aspect torchlight. Some reviews can have multiple aspects.
The DSC CL problem requires sentiment analysis on the full customer review, where
the network has to classify the overall tone as positive or negative. The CL problem
comprises 10 products (tasks), and the input comprises the token [CLS] followed by the
text review. The first output token is used as the sentiment estimate.
The split 20News CL problem is a topic classification task on the 20News dataset.
The original task has 20 topics, which were randomly split into ten tasks, each
containing two topics. The input consists of the token [CLS] followed by text. The first
output token is used as the topic estimate.
All these are CL-problems, meaning that their tasks are shown sequentially without
recall. ASC and DSC are similar to Permuted andRotated in the sense that each task
has the same classification objectives but with different datasets, while Split 20News
changes the labels similarly as for Split MNIST. We use both Acont
ccand Macro-F1
(MF1) score for comparison. MF1 is the F1 score averaged over the different tasks and
is more relevant than accuracy on biased datasets such as ASC . To solve these CL
problems we use one of the most used large language models, pre-trained BERT [36] to
which we applied the GateON method on each module, attention, intermediate, output,
for all 12 layers as well as pooling and embedding.
GateON performance for fine-tuning language models. Remarkably n-GateON
emerges as a versatile method that achieves competitive performance on all
January 26, 2024 13/31

--- PAGE 14 ---
ModelsASC DSC 20News
Acont
cc MF1 Acont
cc MF1 Acont
cc MF1
BERT MTL
(max baseline)91.9 88.1 89.8 89.3 96.8 96.8
BERT naive 49.6 43.1 73.1 71.8 52.5 39.2
HAT [10] 86.7 78.2 87.3 86.1 93.5 92.9
LAMOL [30] 88.9 80.6 92.1 91.7 66.1 45.7
B-CL [65] 88.3 81.4 79.8 76.5 95.1 95.0
CTR [29] 89.5 83.6 89.3 88.7 95.2 95.2
n-GateON 0 ( ours)89.3 84.1 89.3 88.8 95.8 95.9
p-GateON 0 ( ours)83.1 76.7 87.1 85.3 95.9 96.0
Table 5. Continual learning performance with language models. For reference,
we show the multi-task learning (MTL) baseline, all tasks are trained simultaneously
instead of sequentially. We compare our results with the best models that we know of.
To highlight that n-GateON is consistently within the top-2 algorithms across all tasks
when compared to the models reviewed in [29], we highlighted with bold font the best
performance in black and the second best in gray.
language-based CL problems (Table 5). When compared to all models for which the
performance on this problem have been benchmarked by Ke et al. [29], we see that
n-GateON is consistently the best or second best algorithm on all metrics. This is
remarkable because we used here only the two standard GateON Principles which are
conceptually simple whereas the other machine learning algorithms have often be
designed specifically for CL on these tasks. For instance, both LAMOL and CTR which
are the two most competitive alternatives to GateON are designed for BERT models
and are not generalizable to other architectures. The benchmark that is hardest for
GateON appears to be DSC. There n-GateON is the second best algorithm behind
LAMOL, but LAMOL achieves only a low performance on 20News suggesting that it is
less versatile than GateON. Interestingly, p-GateON achieves a relatively low
performance on ASC and DSC in comparison with n-GateON. We believe that the
parameter view may require more data to fine-tune robustly all relevant parameters.
Forward and backward transfer in NLP As done previously with MNIST we
report the accuracy deviation ∆ At
ccand the forgetting rate FRto study forward and
backward transfer across tasks, respectively. In contrast to MNIST where all the tasks
are designed with the same number of samples, the NLP benchmarks exhibit a wide
range of task sizes, with some tasks characterized by limited and biased datasets. In this
sense, we expect that transfer across tasks is crucial for the tasks with few data points.
We report the ∆ At
ccto study forward transfer in Table6. Both p- and n-GateON
show positive accuracy deviations on all tasks emphasizing the method’s capacity for
forward transfer. It is most striking in ASC and DSC where the tasks are related to
specific ”products”, and a single product-specific dataset is sometimes small or very
biased. The dataset Split 20news has consistent dataset sizes and highly independent
tasks, which contribute to a more limited impact of transfer learning.
To study backward transfer in these benchmarks, we report the values of forgetting
rate FRin Table 7. While we were unable to see evidence for backward transfer on
MNIST tasks previously, now we see that n-GateON has negative forgetting rates on
ASC andDSC , suggesting that the network improves its performance on previous
tasks through backward transfer - without replaying the data from the previous task.
Interestingly, n-GateON appears consistently better in terms of backward transfer than
p-GateON, which highlights the importance of the neuro-centric view.
January 26, 2024 14/31

--- PAGE 15 ---
ASC DSC 20News
Models ∆Acc ∆MF1∆Acc∆MF1∆Acc∆MF1
n-GateON 3.52 6.28 2.34 2.99 0.16 0.17
p-GateON 2.24 1.99 2.78 3.17 0.12 0.13
Table 6. Forward transfer in large language model . The deviation accuracy
(∆Acc) and MF1 deviation (∆ MF1) are the performance improvement against the
baseline where tasks are trained in isolation. All tasks show systematic positive
deviation implying a forward transfer of knowledge for both n- and p-GateON. With an
MF1 deviation up to 6.3% for ASC. ASC comprises many small and biased datasets
that seem to profit from this knowledge transfer.
ASC DSC 20News
Models FRAccFRMF1FRAccFRMF1FRAccFRMF1
n-GateON -0.21 -0.09 -0.02 0.03 0.08 0.08
p-GateON 2.33 1.16 1.56 2.32 0.12 0.12
Table 7. Backward transfer in large language model . The forgetting rate (FR) is
a measure of the difference in accuracy between a model’s performance immediately
after training on a particular task and its performance after training on all subsequent
tasks. For ASC FR is negative, showing that on average previous tasks learn more than
they forget, showing the backward transfer capacity of n-GateON. In contrast, the
p-GateON model has generally high FR values, which may explain its poor performance.
2 Discussion
Overview of the GateON theory. In summary, we have described a model of
plasticity relying on two principles: (1) Gated context selectivity by multiplicative
modulation of the neuronal gain function; and (2) modulable freezing of weight updates
if the parameters (or neurons) are relevant for previous tasks, yet with the possibility of
unfreezing later one. This theory is implemented in two forms: a parametro-centric and
a neuro-centric view. While the former provides a normative theory that links to
previous successful models, we design the neuro-centric view as a biologically plausible
model of continual learning in the brain.
Experimental prediction and implications for neuroscience The neuro-centric
implementation of GateON provides a concrete and testable circuit-level hypothesis.
Unlike previous theories of CL which are neuro-centric, our theory merges Principles 1
and 2 of CL into a unique and simpler hypothetical mechanism: CL in the cortex is
supported by the task selectivity of cortical neurons (Principle 1) and we predict the
existence of neural availability variables that track the local activity and control
(un-)freezing of neuronal plasticity when a neuron is selectively active on task k
(Principle 2). Our notion of availability is closely linked to the concept of
metaplasticity [27,37] but also to synaptic consolidation for which several models
exist [38–41]. The multiplicative gain function could be implemented by dendritic
dynamics [66].
A first prediction, based on the simplified relevance model of Eq. (8), is the
following. Let us monitor the spiking activity of a neuron during an extended period of
time. To turn spikes into a firing rate will require a low-pass filter which we estimate to
be in the range of one second. Since we work with a normalized relevance, we focus on a
neuron with a firing rate larger than the average firing rate of other neurons in the same
area. The firing rate of the neuron should be squared to get the relvance, transformed
January 26, 2024 15/31

--- PAGE 16 ---
into normalized relevance, and then inserted into Eq. (3) of the availability dynamics.
Our model predicts that freezing is visible as metaplasticity, i.e., a decrease in the
amount of plasticity under a standard plasticity-induction protocol.
Moreover, unfreezing is a second prediction of the model. On a qualitative level, our
model predicts that there is a threshold parameter ϵ >0 such that if the firing rate is,
for a long time, lower than the average firing rate of other neurons in the same area,
then metaplasticity shows as unfreezing of plasticity. In other words, neuronal synapses
can become plastic again. At the moment the above statements are speculations, but
potentially worth an experimental test.
Comparison with other computational models of CL. Four aspects are
important to highlight similarities and differences to existing models.
(i)Relevance estimation is used in several other models, either in combination with
gradient obstruction (e.g., HAT [12], and RMN [59]) or in combination with
regularization to prevent large parameter drifts (EWC [6], SI [10]). HAT uses an
attention mask for relevance, which may overestimate the true importance of a
parameter, while RMN uses an estimation of relevance learned during training. By
contrast, we compute online an analytical estimate of the impact of each parameter on
the loss of the current task which defines the instantaneous relevance of a parameter.
(ii)Dynamic availability enabling freezing and unfreezing. In contrast to existing
availability control methods which freeze parameters of neurons of high relevance [12,59],
GateON integrates the relevance gradually into a set of dynamic availability variables
which determine whether, and how much, parameters are allowed to change. A key
advantage of our design over HAT or RMN [12,59] is that it enables the introduction of
a hyperparameter ϵto control the unfreezing of parameters that have not been relevant
for a long time while hedging against catastrophic forgetting. The dynamic availability
variables could very well be related to metaplasticity, as explained above.
(iii)Gating has become a mainstream ingredient for efficient CL [6,12,34,35,42]. For
instance, in contrast to HAT [12] which employs a binary attention mechanism for
gating and a multi-head output, our approach gates every unit continuously and does
not require a multi-head output. Our gating approach shares similarities with the
learnable context masking in the Active Dendrites model [42], but in contrast to their
approach, we do not enforce a strict number of active neurons per context nor do we
need to estimate a task embedding.
(iv)Automatic context detection . Whereas standard CL models give explicit
information on task numbers [59], we introduce a simple context detector that enables
unsupervised inference of tasks. While the fields of machine learning and signal
processing have incorporated context switches via out-of-distribution
detection [46,67 –70], we argue that there exist simple context detectors like ours, which
are computationally cheap since it focuses on deviations in the loss which is evaluated
anyway for each sample. Other context detectors were studied in [47,48].
Conclusion. The paradigm of CL is different from standard statistical learning
since data arrives as an input stream with a non-stationary data distribution,
potentially characterized by sharp switches between tasks or contexts. We have shown
that the neuro-centric view of gating feedforward processing in combination with
metaplasticity of learning rules has foundations in the neurosciences and leads to
state-of-the art performance on established, and novel, machine learning problems. Due
to its structural similarity to life-long learning in biology, CL will also in the future
continue to trigger a fruitful crosstalk between neuroscience and machine learning.
January 26, 2024 16/31

--- PAGE 17 ---
Algorithm 1 Change-point detection algorithm for GateON
1:procedure CPD
2: Change-point ←false
3: Θ, ηC, ηL, m←set hyper parameters // m > 1/ηLcontrols window of
min-search
4: active-context ←0
5: Confidence(active-context) ←0
6: Ncontexts ←1
7: fordata in datasets do
8: x0←data
9: Lt←forward (x0,active-context) // forward pass network
10: ¯L=¯L+ηL(−¯L+Lt)
11: if min
t−m≤t′≤tLt′>Θ·¯Land Confidence(active-context) >0.9then
12: reactivated ←false // Trying to reactivate previous context
13: fortestcontext in Ncontexts do
14: Lt←forward (x0,testcontext)
15: ifLt<Θ·¯Lthen
16: active-context ←testcontext
17: reactivated ←True
18: Break
19: ifnot reactivated then // if no previous context suitable
20: active-context ←Ncontexts
21: Ncontexts ←Ncontexts + 1
22: Confidence(active-context) ←0
23: Change-point ←false
24: Confidence(active-context) ←Confidence(active-context) (1 −ηC) +ηC
25: Continue the training steps...
3 Methods
3.1 Task inference
In this section, we present an unsupervised algorithm to identify change points and infer
the current task.
Before we turn to change-point detection, we start by defining the concept of network
confidence in the current context. Denoted as confidence k, the confidence quantifies the
network’s level of expertise regarding context k. This confidence is updated as follows:
∆confidence k=ηC[Ck−confidence k] (9)
where ηCis a hyperparameter and Ck∈ {0,1}is the value of the context layer under
one-hot encoding. In other words, the confidence for the context kincreases (over a
time scale of roughly 1 /ηCif the said context is active during the backward pass.
For each data point (or minibatch of data), we evaluate the loss Ln) (where the
index ndenotes an unknown current task label) and its running average
∆¯L=ηL(−¯L+Lt) (10)
where ηLis a parameter. The running average smoothes the loss over a time scale of
roughly 1 /ηL.
After these preparations, we are ready to describe the change-point detection
algorithm in ALG 1. The basic idea is that we detect change points by comparing the
January 26, 2024 17/31

--- PAGE 18 ---
current loss to the average one in the present context. To increase stability, the ’current’
loss is the minimum loss over the last msteps. Specifically,
•In line 11, we compare the minimum loss over the last msteps to a low-pass
filtered loss. A change point is detected if the error exceeds a predefined threshold
Θ and the network exhibits sufficient confidence; otherwise, the network remains
in its current context. We consider the minimum of the last msteps to be sure
that the current loss value is not an outlier. The larger mthe longer to detect a
change-point but the more sure we get.
•Upon detecting a change point, lines 12-18 assess if one of the existing contexts
Ncontexts aligns well with the present observation. If such an alignment is found,
the previous context is reactivated; if not, a new context is generated and the
counter Ncontexts is increased by one.
•This procedure is carried out at every time step (where time step means one data
point or one minibatch).
The use of inferred context can have benefits, as it allows us to set our tolerance for
change points. For instance, in the case of Rotated , the representational drift depends
on the angle between task kandk′, which means that we can choose a tolerance Θ at
which we consider the tasks to be similar or dissimilar. In Fig. 5 we study the
properties of the task detection with MNIST CL tasks.
3.2 Derivation of a bio-plausible relevance measurement
For a biologically plausible relevance estimation, we consider n-GateON. However,
computing the term∂L
∂xl
imight be impossible for biological neural networks since it
requires to backpropagate detailed gradient information from the output layer to an
arbitrary layer l. Below we provide a theoretical justification for the approximation
µxl
i= (xl
i)2which connects with the calculation of the causal of xion deeper layers.
We propose a sequence of two approximation steps. The first one is a per-layer
definition of causality. Instead of estimating the relevance of a neuron by its impact on
the output layer, we compute how much removing neuron iin layer limpacts the
activity xl+1
jof neurons jin the next layer l+ 1 and define the relevance
µl
i=1
NP
j(al+1,−i
j−al+1
j)2where al+1
j=P
iwjixl
iis the activation of the next layer
before the non-linearity and the gating, −idenotes that we removed the neuron iof
layer lin the forward path. Since al+1
jis linear in xl
iwe have:
µl
i=1
NX
j[X
i′̸=iwl+1
ji′xl
i−X
iwl+1
jixl
i]2
=1
NX
j[wl+1
jixl
i]2,
=P
j(wl+1
ji)2
N·xl
i2(11)
where the sum runs over all neurons in layer l+ 1. This layer-wise variation yields a
formalization of the relevance that is free from the term∂L
∂xiwhich may require
implausible network computations like Backprop. To simplify the computation further,
we can observe that the termP
jwl+1
ji2does not depend on the network activity and it
is the norm of the weight vector leaving neuron i. If we further ignore the
January 26, 2024 18/31

--- PAGE 19 ---
# tasks shown# task estimated2468102468100Truth
01
01Δα-20-1010200
-20-101020024681002468100246810246810PermutedRotatedSplit
# tasks shown# tasks shownP(detection)P(Reactivation)Θ=1.01
ΔαΘ=1.1Θ=1.01Θ=1.1Θ=1.01Θ=1.1TruthΘ=1.01Θ=1.1TruthΘ=1.01Θ=1.1A1A2A3
B
CFig 5. Context Detection in MNIST .A1-3 We executed 10 continual learning
(CL) tasks and tracked the number of tasks identified by GateON compared to the
number of tasks presented. The results are plotted for two Θ values, where Θ modulates
task detection stringency as explained in Algorithm (1). The dashed black line
represents perfect task estimation accuracy. Results are averaged over 10 trials, with
standard deviation indicated by the shaded region. A1andA3exhibit parity between
the number of tasks presented and detected for both Θ parameters. In contrast, A2
reveals that for Rotated , GateON underestimates the actual task count, with larger Θ
values leading to fewer tasks detected. Specifically, tasks with closely spaced angles may
be misconstrued as a single task, leading to context collapse. BTo elucidate the reasons
for the incomplete task detection in A3, we executed two consecutive Rotated tasks
with an angle difference ∆ α∈[−25,25], and charted the switch-point detection
probability for GateON (averaged over 10 trials for each ∆ α). The results indicate a
binary behavior: if ∆ αexceeds a certain threshold, tasks are distinctly identified with a
probability of 1; otherwise, tasks are amalgamated with equal certainty. This suggests a
100 percent switch-point detection rate if the angle difference is sufficiently large;
otherwise, GateON perceives the tasks as identical. To confirm that similar tasks can
reactivate prior ones, we ran in Ca sequence of three tasks such that angles 1 and 3
differ by ∆ αand angle 2 is always far from the other two to be detected as switch-point.
Cdemonstrates that the angle pairs leading to context collapse in Bwill also trigger
reactivation, while those that resulted in distinct tasks do not reactivate. In summary,
our context detector appears proficient at identifying switch-points between significantly
dissimilar tasks and can also reactivate or collapse tasks when they are sufficiently alike.
proportionality constantP
j(wl+1
ji)2
N, equation (11) has the same effect as our most
biologically plausible approximation of µl
i:
µl
i= (xl
i)2. (12)
For comparison with also derived the relevance computation
µl
i=1
NP
j(xl+1,−i
j−xl+1
j)2where the gating and the non-linearity of layer l+ 1 are
taken into account. To be computable, we needed to make a first-order Taylor
approximation to evaluate this term. It results in a more complex computation than Eq.
January 26, 2024 19/31

--- PAGE 20 ---
(12)requiring a downward communication from layer l+ 1 to l. In simulations, we find
a small benefit for this more complex approximation (orange line in Fig. 2), but we did
not explore this further.
3.3 n-GateON for CNN
In the context of a convolutional neural network (CNN), it is necessary to define the
gating and availability operations at the level of filters as opposed to individual neurons.
Building upon the notation established in the previous section, we refer to the filters in
thel-th layer of channel caswc,l
a,b, where aandbcorrespond to the indices of the filter
weights. By applying gating and availability operations to each filter in every channel c
of layer l, we can compute the corresponding gated activity as follows:
xl,c
ij=gl
cf(KX
a=0KX
b=0wc,l
abxl−1,c
(i+a)(j+b))
with gl
c=σ(vl
ck),(13)
For p-GateON, the relevance mappings are exactly the same as defined for a fully
connected network (one per parameter in the convolution kernel). With n-GateON we
have one unit per channel per feature map location, which adds up to a large number of
units per convolutional layer. It is, however, necessary to define how freezing the
parameter of a unit in one location freezes the shared parameter in other units of the
same channel, across the convolutional layer. For simplicity, and in agreement with the
gating variable which acts similarly at all locations, we assign one relevance and
availability variable per channel which are shared across the feature map. For instance
using the bio-plausible approximation we have:
µl,c
x=1
Ni1
NjX
iX
j(xl,c
ij)2(14)
3.4 Accuracy measures for Continual learning
We train the tasks T1, T2, . . . , T Ksequentially. For any task Tk′we can measure the
accuracy on task Tk′at time tk, i.e., right after training on task Tk. This test accuracy
is denoted Ak′
cc(tk). The immediate test accuracy after training task Tkbeing,
Ak
cc=Ak
cc(tk).
After training on all tasks we measure the continual accuracy
Acont,k
cc =1
K−k+ 1KX
k′≥kAk
cc(tk′). (15)
The continual accuracy is the basis to define the forgetting rate FRk.
To probe potential network saturation or forward transfer during training we
measure the normalized difference between the immediate test accuracy At
ccof the
GateON model and and isolated network. This yields the the relative immediate test
accuracy ratio ∆ Ak
cc. We then average over all tasks
∆Acc=1
¯AIsolatedcc , 
1
KKX
kAk
cc−¯AIsolated
cc!
, (16)
with ¯AIsolated
cc the average accuracy over all tasks if networks are trained separately for
each task. A positive ∆ Ak
ccshows that on average the immediate test accuracy is better
with CL (forward transfer) than without. In the Results section, we present results in
%, i.e. multiplied by 100.
January 26, 2024 20/31

--- PAGE 21 ---
Test Accuracy
Vanilla GateON 0 GateON 0.5
Permuted Rotated Shuffled
Task #Task # Task #0.60.8
0.4
0.21
0.940.98
0.90
0.860.940.98
0.90
0.86
GateON 1100102101 100102101100102101
Isolated0.60.8
0.4
0.21
0.60.8
0.4
0.21Test Accuracy
Test AccuracyFig 6. Network generalization . The three figures show the task-locked accuracy
(Methods 3.5) over 500 batch presentations for all three MNIST tasks. The task-locked
accuracy reveals the average re-training speed and final accuracy of the network. A
network that generalizes well should learn faster and achieve higher accuracy if possible.
Isolated indicates the average speed of training using a new network for each task. The
number following GateON in the legend corresponds to the value of epsilon in Eq. (3)
used for the GateON method.
3.5 Task-locked accuracy
While in continual accuracy and related measures we focus on the performance at times
tk, i.e., at the end of a task Tk, for the task-locked accuracy we study the evolution of
accuracy during one task. For MNIST we train each task for 500 minibatch steps
(around 9 epochs) and then switch to the next one. During training, we save the test
accuracy of task TkasAk
cc(step) for step=t−tk−1∈ {1,500}.
To avoid showing redundant plots (up to 100 tasks trained) and highlight the
average convergence speed and accuracy during training we compute the average
tasked-locked accuracy,
Acc(step) =1
K−1KX
k>1Ak
cc(step). (17)
Acc(step) highlights the average speed of training of tasks T2, T3, ...after a task switch.
3.6 Spefications of the MNIST CL benchmarks
Permuted is a test for random input changes because the input pixels are randomly
permuted, thereby rendering it impossible for a standard model to generalize across
tasks. On the other hand, in Rotated , if the rotation angle between two tasks is small,
some visual features can be re-used for different rotation angles.
Split is a test that is often used in CL papers and consists of grouping the dataset
into five binary classification tasks corresponding to the detection of two random digits.
Shuffled introduces random output changes (permutation of the 10 labels). This task is
particularly challenging for classical networks (without multi-head) as it needs to
override in the final layer the previous knowledge at each new task. In these tasks it is
almost always impossible to generalize across tasks: for each new task inputs that
represent a ’3’ must suddenly be mapped to another output unit coding for another
digit. If the network does not have a task-specific output layer (also called network
’head’ below) the weight of the deeper layer(s) has to be overridden to change the
output convention.
January 26, 2024 21/31

--- PAGE 22 ---
3.7 Context correlation matrix
To be sure that sub-networks generated from the GateON method are not mutually
exclusive we want to measure how the context weights that gate the activity of the
neurons correlate between each task. To do so we binarise the context weight vector
from context ito all neurons in layer l
wl,binarised
ik=(
1 if wl
ik>0
0 otherwise.(18)
We chose to binarise since we want to focus only on whether this neuron is used or not
and hence if the neuron feature is re-used. Then we compute the Pearson
correlation [71]:
Cij=COV (⃗ wbinarised
i , ⃗ wbinarised
j )
σiσj. (19)
Strong correlation means that similar neurons are used between the two tasks and hence
the sub-networks are not separated. We expect this kind of behavior in correlated tasks
likeRotated with two close angles. In orthogonal tasks we would expect the neurons to
be anti-correlated, i.e. the network actively chooses other neurons than the one
previously used.
3.8 Network architectures and training hyperparameters
m Θ ηL ηC
Permuted 11.01 0.02 0.02
Rotated 11.01 0.02 0.02
Shuffle 11.01 0.02 0.02
Table 8. GateON parameters for
MNIST task detectionm Θ ηL ηC
ASC 31.1 0.05 0.02
DSC 3 50.05 0.02
newsgroup 3 50.05 0.02
Table 9. GateON parameters for NLP
task detection
10 MNIST Tasks
ForPermuted , the network is composed of one input layer of size 728, 2 hidden layers
with 2000 neurons, and an output layer of 10 neurons. We added two layers of conv
with size 32 for Split and 256,512 for Rotated . Each task was trained for 250 training
steps with batch size 1000 (about 4 epochs). We use the Adam optimizer [72] with a
learning rate of 5 e−3, reset after each task switch. ηA= 0.01 for all layers. The gating
activation function is a rectified hyperbolic tangent, ReLU for the neurons and softmax
for the output. To make the learning faster we also add a batch norm at each layer. We
use cross-entropy loss. We use a batch size of 1000. Everything is implemented with
Pytorch [73].
100 MNIST Tasks
Fully-connected architecture and training The architecture is the same for all
three CL problems with the same hyper-parameters using Pytorch [73]. It is composed
of one input layer of size 728, 4 hidden layers with 5000 neurons, and an output layer of
10 neurons. The increase in the number of neurons (compared to the network for 10
tasks) has been necessary for solving 100 tasks. We use the Adam optimizer with a
learning rate of 5 e−3, reset after each task switch. ηA= 0.01 for all layers. The gating
activation function is a rectified hyperbolic tangent, ReLU for the hidden neurons and
January 26, 2024 22/31

--- PAGE 23 ---
softmax for the output. To make the learning faster we also add a batch norm at each
layer, and we re-normalize the output layer activity at each layer. We use a
cross-entropy loss. We use a batch size of 1000 and train each task for 50 epochs.
Convolutional architecture and training On MNIST with convolutional networks,
the architecture is identical to [73] for all three CL problems with the same
hyper-parameters. It is composed of one input layer of size 728, 2 convolutional layers
with 256 and 512 channels followed by one max pool of kernel 4, 2 hidden layers with
5000 neurons, and the output layer of 10 neurons. We use the Adam optimizer with a
learning rate of 5 e−3, reset after each task switch. ηA= 0.004 for all conv layers,
ηA= 0.01 all hidden layers. The gating activation function is a rectified hyperbolic
tangent, ReLU for the neurons and softmax for the output. To make the learning faster
we also add a batch norm at each hidden layer, and we re-normalize the output layer
activity. We use a cross-entropy loss. We use a batch size of 1000 and train each task
for 50 epochs.
CIFAR-100 Tasks
Wide-resnet architecture and training We used Wide-ResNet as described in [74]
with a depth of 28 and a widening factor of 10. We changed the first convolution from
16 to 128 to avoid fixing too quickly the parameters. We use the SGD optimizer with a
learning rate of 0 .02 and momentum of 0.9, with a cosine annealing scheduler.
ηA= 0.004 for all conv layers, except for the first one where ηA= 0.04. The gating
activation function is a rectified hyperbolic tangent, ReLU for the neurons and softmax
for the output. To make the learning faster we also add a batch norm at each hidden
layer, and we re-normalize the output layer activity. We use a cross-entropy loss plus
the mean absolute value of the context weights as a regularizer for the number of active
channels. We use a batch size of 128 and train each task for 50 epochs.
Natural language processing tasks
BERT network architecture We use the BERT base model (uncased) similarly as
in Devlin et al. [36]. The same parameters are used for all tasks for the training. The
parameters for context detection differ between tasks. The only adaption we did was to
add the context layers. We also put the availability of the embedding layer and
self-attention layers to 0. We do this because we did not have access to the pre-training
to implement our relevance mapping and availability fixing. Since Attention and
embedding are projections in small dimensions it has a very dense representation leading
to most of the neurons being relevant. We expect that for these layers our model would
fix most of the neurons during training. Hence we set the availability of the embedding
layer and each attention layer to 0. Note that they still have the gating that allows
task-driven adaptation. The context parameters ware initialized so that σ(w) = 1 for
all neurons and contexts. It prevents gating to change too much the Bert representation
before training. We use ηA= 0.05 except if the first dataset has less than 50 batch
updates in this case the first task uses ηA= 0.1. We use a batch size of 32 and train
each task for variable epochs depending on the dataset size as described in [75].
Data and code availability statement
The code is made publicly available at
https://github.com/martinbarry59/GATEONMNIST . All dataset used in this study
are already publicly available.
January 26, 2024 23/31

--- PAGE 24 ---
Acknowledgement
M.B. has conceptualized the research topic and pursued the investigation by himself
(both simulations and analytical work). After the first draft was written, W.G. and G.B.
helped to consolidate the analytical work and to write the final manuscript. This
research was supported by the Swiss National Science Foundation with grant No.
200020 207426. The research of W.G. and G.B. was supported by a Sinergia grant with
grant No. CRSII 5198612.
References
[1] David E Rumelhart, James L McClelland, PDP Research Group, et al. Parallel
distributed processing. Foundations , 1, 1988.
[2] Sepp Hochreiter and J¨ urgen Schmidhuber. Long short-term memory. Neural
computation , 9:1735–80, 12 1997.
[3] Yann LeCun, L´ eon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based
learning applied to document recognition. Proceedings of the IEEE ,
86(11):2278–2324, 1998.
[4] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez,  Lukasz Kaiser, and Illia Polosukhin. Attention is all you need.
Advances in neural information processing systems , 30, 2017.
[5] Ian J. Goodfellow, Mehdi Mirza, Xia Da, Aaron C. Courville, and Yoshua Bengio.
An empirical investigation of catastrophic forgeting in gradient-based neural
networks. In Yoshua Bengio and Yann LeCun, editors, 2nd International
Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April
14-16, 2014, Conference Track Proceedings , 2014.
[6] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume
Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka
Grabska-Barwinska, et al. Overcoming catastrophic forgetting in neural networks.
Proceedings of the national academy of sciences , 114(13):3521–3526, 2017.
[7]Anthony Robins. Catastrophic forgetting in neural networks: the role of rehearsal
mechanisms. In Proceedings 1993 The First New Zealand International Two-Stream
Conference on Artificial Neural Networks and Expert Systems , pages 65–68, 1993.
[8] G.A. Carpenter and S. Grossberg. The ART of adaptive pattern recognition by a
self-organizing neural network. Computer , 21(3):77–88, March 1988.
[9]Zolt´ an Dienes and Gerry Altmann. Transfer of implicit knowledge across domains:
How implicit and how abstract. In D.C. Berry, editor, How implicit is implicit
learning , pages 107–123. Oxford University Press, 1997.
[10] Friedemann Zenke, Ben Poole, and Surya Ganguli. Continual learning through
synaptic intelligence. In International conference on machine learning , pages
3987–3995. PMLR, 2017.
[11] Christos Kaplanis, Murray Shanahan, and Claudia Clopath. Continual
reinforcement learning with complex synapses. In International Conference on
Machine Learning , pages 2497–2506. PMLR, 2018.
January 26, 2024 24/31

--- PAGE 25 ---
[12]Joan Serra, Didac Suris, Marius Miron, and Alexandros Karatzoglou. Overcoming
catastrophic forgetting with hard attention to the task. In International
Conference on Machine Learning , pages 4548–4557. PMLR, 2018.
[13] Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Aleˇ s
Leonardis, Gregory Slabaugh, and Tinne Tuytelaars. A continual learning survey:
Defying forgetting in classification tasks. IEEE Transactions on Pattern Analysis
and Machine Intelligence , 44(7):3366–3385, 2022.
[14] Charles G Gross, CE de Rocha-Miranda, and DB Bender. Visual properties of
neurons in inferotemporal cortex of the macaque. Journal of neurophysiology ,
35(1):96–111, 1972.
[15] Bruno A Olshausen and David J Field. Emergence of simple-cell receptive field
properties by learning a sparse code for natural images. Nature , 381(6583):607–609,
1996.
[16]R Quian Quiroga, Leila Reddy, Gabriel Kreiman, Christof Koch, and Itzhak Fried.
Invariant visual representation by single neurons in the human brain. Nature ,
435(7045):1102–1107, 2005.
[17] Gabriel Kreiman, Christof Koch, and Itzhak Fried. Category-specific visual
responses of single neurons in the human medial temporal lobe. Nature
neuroscience , 3(9):946–953, 2000.
[18] Jonathan D Wallis, Kathleen C Anderson, and Earl K Miller. Single neurons in
prefrontal cortex encode abstract rules. Nature , 411(6840):953–956, 2001.
[19] M. Rigotti, O. Barak, M.R. Warden, X.-J. Wang, N.D. Daw, E.K. Miller, and
S. Fusi. The importance of mixed selectivity in complex cognitive tasks. Nature ,
497:585–590, 2013.
[20] R.A. Andersen, G.K. Essik, and R.M. Siegel. Encoding spatial location by
posterior parietal neurons. Science , 230:456–478, 1985.
[21] R.A. Andersen, R. M. Bracewell, S. Barash, J.W. Gnadt, and L. Fogassi. Eye
position effects on visual, memory, and saccade-related activity in areas lip and 7a
of macaque. J. Neurosci. , 10:1176–1196, 1990.
[22]A John Van Opstal, Klaus Hepp, Y Suzuki, and V Henn. Influence of eye position
on activity in monkey superior colliculus. Journal of Neurophysiology ,
74(4):1593–1610, 1995.
[23]M. I. Anderson and K. J. Jeffery. Heterogeneous modulation of place cell firing by
changes in context. Journal of Neuroscience , 23(26):8827–8835, October 2003.
[24]E. Salinas and L.F. Abbott. A model of multiplicative neural responses in parietal
cortex. Proc. Natl. Academy Sci. USA , 93:11956–11961, 1996.
[25] Joao Barbosa, R´ emi Proville, Chris C Rodgers, Michael R DeWeese, Srdjan
Ostojic, and Yves Boubenec. Early selection of task-relevant features through
population gating. Nature Communications , 14(1):6837, 2023.
[26]E. Salinas and P. Thier. Gain modulation: a major computational principle in the
central nervous system. Neuron , 27:15–21, 2004.
[27]Wickliffe C Abraham. Metaplasticity: tuning synapses and networks for plasticity.
Nat Rev Neurosci , 9(5):387, 2008.
January 26, 2024 25/31

--- PAGE 26 ---
[28] Rahul Ramesh and Pratik Chaudhari. Model zoo: A growing brain that learns
continually. In International Conference on Learning Representations , 2022.
[29] Zixuan Ke, Bing Liu, Nianzu Ma, Hu Xu, and Lei Shu. Achieving forgetting
prevention and knowledge transfer in continual learning. In A. Beygelzimer,
Y. Dauphin, P. Liang, and J. Wortman Vaughan, editors, Advances in Neural
Information Processing Systems , 2021.
[30] Fan-Keng Sun, Cheng-Hao Ho, and Hung-Yi Lee. {LAMOL }:{LA}nguage
modeling is all you need for lifelong language learning. In International Conference
on Learning Representations , 2020.
[31] German I. Parisi, Ronald Kemker, Jose L. Part, Christopher Kanan, and Stefan
Wermter. Continual lifelong learning with neural networks: A review. Neural
Networks , 113:54–71, 2019.
[32] Hanul Shin, Jung Kwon Lee, Jaehong Kim, and Jiwon Kim. Continual learning
with deep generative replay. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach,
R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural
Information Processing Systems , volume 30. Curran Associates, Inc., 2017.
[33] Anthony Robins. Catastrophic forgetting, rehearsal and pseudorehearsal.
Connection Science , 7(2):123–146, June 1995.
[34] Nicolas Y Masse, Gregory D Grant, and David J Freedman. Alleviating
catastrophic forgetting using context-dependent gating and synaptic stabilization.
Proceedings of the National Academy of Sciences , 115(44):E10467–E10475, 2018.
[35] Timo Flesch, David G Nagy, Andrew Saxe, and Christopher Summerfield.
Modelling continual learning in humans with hebbian context gating and
exponentially decaying task signals. PLOS Computational Biology , 19(1):e1010808,
2023.
[36] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT:
Pre-training of deep bidirectional transformers for language understanding. In
Proceedings of the 2019 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies, Volume
1 (Long and Short Papers) , pages 4171–4186, Minneapolis, Minnesota, June 2019.
Association for Computational Linguistics.
[37]Sami El Boustani, Pierre Yger, Yves Fr´ egnac, and Alain Destexhe. Stable learning
in stochastic network states. Journal of neuroscience , 32(1):194–214, 2012.
[38] Stefano Fusi, Patrick J Drew, and L F Abbott. Cascade models of synaptically
stored memories. Neuron , 45(4):599–611, February 2005.
[39] Friedemann Zenke, Everton J. Agnes, and Wulfram Gerstner. A diversity of
synaptic plasticity mechanisms orchestrated to form and retrieve memories in
spiking neural networks. Nature Communications , 6(2011):1–13, 2014.
[40]L. Ziegler, F. Zenke, D.B. Kastner, and W. Gerstner. Synaptic consolidation: from
synapses to behavioral modeling. J. Neuroscience , 35:1319–1334, 2015.
[41] Marcus K Benna and Stefano Fusi. Computational principles of synaptic memory
consolidation. Nature Neuroscience , 19(12):1697–1706, October 2016.
January 26, 2024 26/31

--- PAGE 27 ---
[42] Abhiram Iyer, Karan Grewal, Akash Velu, Lucas Oliveira Souza, Jeremy Forest,
and Subutai Ahmad. Avoiding catastrophe: Active dendrites enable multi-task
learning in dynamic environments. Frontiers in neurorobotics , 16, 2022.
[43] Martin Barry and Wulfram Gerstner. Fast adaptation to rule switching using
neuronal surprise. September 2022.
[44] D. H. Heeger, E.P. Simoncelli, and J.A. Movshon. Computational models of
cortical visual processing. Proc. National Academy of Sci. USA , 93:623–627, 1996.
[45] M. Carandini, D.J. Heeger, and J.A. Movshon. Linearity and gain control in V1
simple cells. Cerebral cortex , 13:401–443, 1999.
[46] Vasiliki Liakoni, Alireza Modirshanechi, Wulfram Gerstner, and Johanni Brea.
Learning in volatile environments with the bayes factor surprise. Neural
Computation , 33(2):269–340, February 2021.
[47]Massimo Caccia, Pau Rodriguez, Oleksiy Ostapenko, Fabrice Normandin, Min Lin,
Lucas Page-Caccia, Issam Hadj Laradji, Irina Rish, Alexandre Lacoste, David
V´ azquez, et al. Online fast adaptation and knowledge accumulation (osaka): a new
approach to continual learning. Advances in Neural Information Processing
Systems , 33:16532–16545, 2020.
[48] James B Heald, M´ at´ e Lengyel, and Daniel M Wolpert. Contextual inference
underlies the learning of sensorimotor repertoires. Nature , 600(7889):489–493, 2021.
[49] Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James
Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. Progressive
neural networks. arXiv preprint arXiv:1606.04671 , 2016.
[50]Ju Xu and Zhanxing Zhu. Reinforced continual learning. In S. Bengio, H. Wallach,
H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in
Neural Information Processing Systems , volume 31. Curran Associates, Inc., 2018.
[51]Blake A. Richards, Timothy P. Lillicrap, Philippe Beaudoin, Yoshua Bengio, Rafal
Bogacz, Amelia Christensen, Claudia Clopath, Rui Ponte Costa, Archy de Berker,
Surya Ganguli, Colleen J. Gillon, Danijar Hafner, Adam Kepecs, Nikolaus
Kriegeskorte, Peter Latham, Grace W. Lindsay, Kenneth D. Miller, Richard Naud,
Christopher C. Pack, Panayiota Poirazi, Pieter Roelfsema, Jo˜ ao Sacramento,
Andrew Saxe, Benjamin Scellier, Anna C. Schapiro, Walter Senn, Greg Wayne,
Daniel Yamins, Friedemann Zenke, Joel Zylberberg, Denis Therien, and Konrad P.
Kording. A deep learning framework for neuroscience. Nature Neuroscience ,
22(11):1761–1770, October 2019.
[52] Alexandre Payeur, Jordan Guerguiev, Friedemann Zenke, Blake A. Richards, and
Richard Naud. Burst-dependent synaptic plasticity can coordinate learning in
hierarchical circuits. Nature Neuroscience , 24(7):1010–1019, May 2021.
[53] Guillaume Bellec, Franz Scherr, Anand Subramoney, Elias Hajek, Darjan Salaj,
Robert Legenstein, and Wolfgang Maass. A solution to the learning dilemma for
recurrent networks of spiking neurons. Nature communications , 11(1):3625, 2020.
[54] Siavash Golkar, Tiberiu Tesileanu, Yanis Bahroun, Anirvan Sengupta, and Dmitri
Chklovskii. Constrained predictive coding as a biologically plausible model of the
cortical hierarchy. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho,
and A. Oh, editors, Advances in Neural Information Processing Systems ,
volume 35, pages 14155–14169. Curran Associates, Inc., 2022.
January 26, 2024 27/31

--- PAGE 28 ---
[55] Bernd Illing, Jean Ventura, Guillaume Bellec, and Wulfram Gerstner. Local
plasticity rules can learn deep representations using self-supervised contrastive
predictions. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and
J. Wortman Vaughan, editors, Advances in Neural Information Processing Systems ,
volume 34, pages 30365–30379. Curran Associates, Inc., 2021.
[56]Rupesh K Srivastava, Jonathan Masci, Sohrob Kazerounian, Faustino Gomez, and
J¨ urgen Schmidhuber. Compete to compute. In C.J. Burges, L. Bottou, M. Welling,
Z. Ghahramani, and K.Q. Weinberger, editors, Advances in Neural Information
Processing Systems , volume 26. Curran Associates, Inc., 2013.
[57] David Lopez-Paz and Marc 'Aurelio Ranzato. Gradient episodic memory for
continual learning. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus,
S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information
Processing Systems , volume 30. Curran Associates, Inc., 2017.
[58] Mehrdad Farajtabar, Navid Azizan, Alex Mott, and Ang Li. Orthogonal gradient
descent for continual learning. In International Conference on Artificial
Intelligence and Statistics , pages 3762–3773. PMLR, 2020.
[59]Prakhar Kaushik, Adam Kortylewski, Alex Gain, and Alan Yuille. Understanding
catastrophic forgetting and remembering in continual learning with optimal
relevance mapping. In Fifth Workshop on Meta-Learning at the Conference on
Neural Information Processing Systems , 2021.
[60] Michael McCloskey and Neal J Cohen. Catastrophic interference in connectionist
networks: The sequential learning problem. In Psychology of learning and
motivation , volume 24, pages 109–165. Elsevier, 1989.
[61] Abraham C. Wickliffe and Anthony Robins. Memory retention – the synaptic
stability versus plasticity dilemma. Trends in Neurosciences , 28(2):73–78, 2005.
[62] Hu Xu, Bing Liu, Lei Shu, and Philip Yu. BERT post-training for review reading
comprehension and aspect-based sentiment analysis. In Proceedings of the 2019
Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) ,
pages 2324–2335, Minneapolis, Minnesota, June 2019. Association for
Computational Linguistics.
[63]Zixuan Ke, Bing Liu, Hao Wang, and Lei Shu. Continual learning with knowledge
transfer for sentiment classification. In Machine Learning and Knowledge Discovery
in Databases: European Conference, ECML PKDD 2020, Ghent, Belgium,
September 14–18, 2020, Proceedings, Part III , page 683–698, Berlin, Heidelberg,
2020. Springer-Verlag.
[64] Ken Lang. NewsWeeder: Learning to filter netnews. In Machine Learning
Proceedings 1995 , pages 331–339. Elsevier, 1995.
[65] Zixuan Ke, Hu Xu, and Bing Liu. Adapting BERT for continual learning of a
sequence of aspect sentiment classification tasks. In Proceedings of the 2021
Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies , pages 4746–4755, Online, June 2021.
Association for Computational Linguistics.
[66] Willem AM Wybo, Matthias C Tsai, Viet Anh Khoa Tran, Bernd Illing, Jakob
Jordan, Abigail Morrison, and Walter Senn. Nmda-driven dendritic modulation
January 26, 2024 28/31

--- PAGE 29 ---
enables multitask representation learning in hierarchical sensory processing
pathways. Proceedings of the National Academy of Sciences , 120(32):e2300558120,
2023.
[67] Ryan Prescott Adams and David J. C. MacKay. Bayesian online changepoint
detection. arXiv preprint arXiv:0710.3742 , arXiv:0710.3742, 2007.
[68]Paul Fearnhead and Zhen Liu. On-line inference for multiple changepoint problems.
Journal of the Royal Statistical Society Series B: Statistical Methodology ,
69(4):589–605, August 2007.
[69] M.R. Nassar, R.C. Wilson, B. Heasly, and J.I. Gold. An approximately bayesian
delta-rule model explains the dynamics of belief updating in a changing
environment. J. Neurosci. , 30:12366–12378, 2010.
[70]Eric Nalisnick, Akihiro Matsukawa, Yee Whye Teh, and Balaji Lakshminarayanan.
Detecting out-of-distribution inputs to deep generative models using typicality. In
Bayesian Deep Learning NeurIPS 2019 Workshop , 2019.
[71] Karl Pearson. Vii. note on regression and inheritance in the case of two parents.
Proceedings of the Royal Society of London , 58(347-352):240–242, 1895.
[72] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization.
arXiv preprint arXiv:1412.6980 , 2014.
[73]Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith
Chintala. Pytorch: An imperative style, high-performance deep learning library. In
Advances in Neural Information Processing Systems 32 , pages 8024–8035. Curran
Associates, Inc., 2019.
[74] Sergey Zagoruyko and Nikos Komodakis. Wide residual networks, 2016.
[75]Zixuan Ke, Bing Liu, Hao Wang, and Lei Shu. Continual learning with knowledge
transfer for sentiment classification. In Machine Learning and Knowledge Discovery
in Databases: European Conference, ECML PKDD 2020, Ghent, Belgium,
September 14–18, 2020, Proceedings, Part III , pages 683–698. Springer, 2021.
January 26, 2024 29/31

--- PAGE 30 ---
A Supplementary tables
Results GateON, task-fed
ModelsPermuted Rotated Shuffled
Acont
cc ∆At
ccFR. Acont
cc ∆At
ccFR Acont
cc ∆At
ccFR
Vanilla 26.29 0.0 71.57 69.68 0.0 28.53 13.41 0.0 77.44
n-Gating 55.07 0.24 41.96 71.63 0.94 25.33 62.07 0.6 35.11
n-GateON 1 95.96 0.2 1.5 97.46 1.18 0.49 96.38 1.05 1.52
n-GateON 0.5 95.88 -1.39 0.25 97.6 1.08 0.19 97.66 1.01 0.19
n-GateON 0 92.38 -5.0 0.25 97.39 0.82 0.05 97.72 0.93 0.06
p-GateON 0.5 96.54 -0.05 0.79 97.83 0.67 0.14 97.52 0.31 0.36
p-GateON 0 96.56 -0.62 0.23 97.8 0.64 0.06 97.69 0.25 0.15
Table 10. Performance results on the three CL-tasks ( Permuted ,Rotated , and Shuffled )
for 100 tasks with task fed in the context layer.
CNN ModelsPermuted Rotated Shuffled
Acont
cc ∆At
ccFR. Acont
cc ∆At
ccFR Acont
cc ∆At
ccFR
Vanilla 41.32 55.91 94.06 5.33 40.15 58.22
Gating 50.03 -0.07 47.15 88.76 -0.04 10.1 48.63 -0.14 50.65
n-GateON 1 96.16 -0.58 0.9 98.83 0.43 0.37 98.5 -0.120.78
n-GateON 0.5 96.57 -0.72 0.37 98.62 0.38 0.36 98.97 -0.15 0.28
n-GateON 0 89.43 -7.91 0.78 99.11 0.25 0.06 98.97 -0.26 0.2
p-GateON 0.5 94.75 -1.4 1.62 99.1 0.11 0.21 98.94 -0.14 0.34
p-GateON 0 95.02 -2.34 0.48 99.05 0.09 0.12 99.06 -0.14 0.22
Table 11. Performance results on the three CL-tasks ( Permuted ,Rotated , and Shuffled )
for 100 tasks with task-fed in the context module using CNN.
Results GateON, task inferred
ModelsPermuted Rotated Shuffled
Acont
cc ∆At
ccFR. Acont
cc ∆At
ccFR Acont
cc ∆At
ccFR
Vanilla 26.29 0.0 71.57 69.68 0.0 28.53 13.41 0.0 77.44
Gating 55.07 0.24 41.96 71.63 0.94 25.33 62.07 0.6 35.11
n-GateON 1 95.75 -0.48 1.12 97.7 0.7 0.24 96.89 0.4 1.09
n-GateON 0.5 92.86 -1.57 2.06 97.6 0.66 0.33 97.35 0.39 0.62
n-GateON 0 73.64 -5.61 14.82 97.62 0.59 0.35 97.72 0.26 0.12
p-GateON 0.5 96.48 -0.05 0.84 97.76 0.55 0.16 97.51 0.29 0.37
p-GateON 0 96.34 -0.6 0.48 97.87 0.64 0.14 97.69 0.24 0.13
Table 12. Performance results on the three CL-tasks ( Permuted ,Rotated , and Shuffled )
for 100 tasks with task inferred by the network.
A.1 Time scales of freezing and unfreezing
An important theoretical question is how the introduction of the threshold ϵin equation
(3)impacts the temporal evolution of the availability. Indeed, with ϵ= 0, the availability
January 26, 2024 30/31

--- PAGE 31 ---
CNN ModelsPermuted Rotated Shuffled
Acont
cc ∆At
ccFR. Acont
cc ∆At
ccFR Acont
cc ∆At
ccFR
Vanilla 41.32 55.91 94.06 5.33 40.15 58.22
Gating 50.03 -0.07 47.15 88.76 -0.04 10.1 48.63 -0.14 50.65
n-GateON 1 89.82 -2.61 4.03 98.92 0.11 0.45 98.71 -0.16 0.55
n-GateON 0.5 93.22 -1.95 1.64 98.79 0.03 0.5 98.92 -0.18 0.32
n-GateON 0 76.8 -8.79 10.56 98.89 -0.01 0.37 99.02 -0.21 0.2
p-GateON 0.5 93.4 -1.59 2.51 98.92 0.07 0.41 98.91 -0.15 0.37
p-GateON 0 93.36 -2.17 1.71 98.97 0.07 0.36 99.04 -0.16 0.22
Table 13. Performance results on the three CL-paradigms ( Permuted ,Rotated , and
Shuffled ) for 100 tasks with task inferred by the context module of the CNN.
Acan only decrease or stay fixed. To study the evolution of Aforϵ >0, we consider the
following toy scenario: we assume that a given neuron is relevant for the first Tupdate
steps ( Tcould, for example, represent all updates during the first task) where relevance
is indicated by a high level µ=a > ϵ ; and thereafter the same neuron is irrelevant for
the next T′steps, as indicated by µ=b < ϵ (T′could represent all updates during all
other tasks). From our assumptions and Eq. (3) with A(0) = A0we have :
A(T+T′) =A0(1−ηA(a−ϵ))T(1−ηA(b−ϵ))T′. (20)
We ask ourselves how big T′needs to be for the availability to return to its original
value. Solving A(T+T′) =A0we obtain ϵbeing an unstable fixed point we want to
estimate if there is a possible oscillatory fixed point such that the expectation E[ A]̸= 0
or 1. We will show with fixed µfixed during each task that such a fixed point is almost
impossible. Assume µ=a > ϵ for T steps and µ=b < ϵ for T’ steps. Since µs are fixed
from Eq. (3) for A(0) = A0. we obtain:
T∗=−Tlog (1−ηA(a−ϵ))
log (1−ηA(b−ϵ)). (21)
Eq. (21) shows that the higher the relevance aduring the first period of Tsteps, the
longer it will take to grow back to A0. For the further interpretation, we suppose now
that ϵ= 1. Since 0 < b < ϵ , we have ϵ−b <1 during the ’irrelevant’ phase. The
relevance a, however, is bounded by the number of neurons Nper layer (for n-GateON).
Hence, during the ’relevant’ phase of a neuron, the difference a−ϵcan take a value
much larger than 1. The behavior described by Eq. (21)is exactly what we expect from
the threshold term. It shows that very relevant neurons ( a≫ϵ) have T∗≫Tmeaning
that, for relevant neurons, the time scale of forgetting is much slower than the time
scale of learning.
January 26, 2024 31/31

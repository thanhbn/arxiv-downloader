# 2106.03027.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/continual-learning/2106.03027.pdf
# File size: 1552661 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
M/o.pc/d.pc/e.pc/l.pc Z/o.pc/o.pc: A G/r.pc/o.pc/w.pc/i.pc/n.pc/g.pc ‚ÄúB/r.pc/a.pc/i.pc/n.pc‚Äù
T/h.pc/a.pc/t.pc L/e.pc/a.pc/r.pc/n.pc/s.pc C/o.pc/n.pc/t.pc/i.pc/n.pc/u.pc/a.pc/l.pc/l.pc/y.pc
Rahul Ramesh
University of Pennsylvania
rahulram@seas.upenn.eduPratik Chaudhari
University of Pennsylvania
pratikac@seas.upenn.edu
A/b.pc/s.pc/t.pc/r.pc/a.pc/c.pc/t.pc
This paper argues that continual learning methods can beneÔ¨Åt by splitting the
capacityofthelearneracrossmultiplemodels. Weusestatisticallearningtheory
and experimental analysis to show how multiple tasks can interact with each other
in a non-trivial fashion when a single model is trained on them. The generalization
error on a particular task can improve when it is trained with synergistic tasks, but
can also deteriorate when trained with competing tasks. This theory motivates
our method named Model Zoo which, inspired from the boosting literature, grows
an ensemble of small models, each of which is trained during one episode of
continuallearning. WedemonstratethatModelZooobtainslargegainsinaccuracy
on a variety of continual learning benchmark problems. Code is available at
https://github.com/grasp-lyrl/modelzoo_continual.
1 I/n.pc/t.pc/r.pc/o.pc/d.pc/u.pc/c.pc/t.pc/i.pc/o.pc/n.pc
A continual learner seeks to leverage data from past tasks to learn new tasks shown to it in the future,
and in turn, leverage data from these new tasks to improve its accuracy on past tasks. It stands to
reasonthattheperformanceofsuchalearnerwoulddependupontherelatednessofthesetasks. Ifthe
two sets of tasks are dissimilar, learning on past tasks is unlikely to beneÔ¨Åt future tasks‚Äîit may even
be detrimental. And similarly, new tasks may cause the learner to ‚Äúforget‚Äù and result in deterioration
ofaccuracyonpasttasks. Ourgoalinthispaperistomodeltherelatednessbetweentasksanddevelop
new methods for continual learning that result in good forward-backward transfer by accounting for
similarities and dissimilarities between tasks. Our contributions are as follows.
1. Theoretical analysis We characterize when multiple tasks can be learned using a single model
and,likewise,whendoingsoisdetrimentaltotheaccuracyofaparticulartask. Thekeytechnicalidea
hereistodeÔ¨Åneanotionofrelatednessbetweentasks. WeÔ¨ÅrstshowhowiftheinputsofdiÔ¨Äerent
tasks are ‚Äúsimple‚Äù transformations ofeach other (andlikewise for the outputs), then one can learn
a shared feature generator that generalizes better on every task, compared to training that task in
isolation. Such tasks are strongly related to each other and therefore it is beneÔ¨Åcial to Ô¨Åt a single
modelonallofthem. Weshowthatiftasksarenotsostronglyrelated,inparticulariftheoptimal
model for one taskpredicts poorly on another task, then Ô¨Åttinga single model on such tasksmay be
worse thantraining each taskin isolation. Suchtasks competewith eachother for theÔ¨Åxed capacity
in the single model. We also empirically study this competition using the CIFAR-100 dataset.
2. Algorithmdevelopment TheaboveanalysissuggeststhatacontinuallearnercouldbeneÔ¨Åtfrom
splittingitslearningcapacityacrosssetsofsynergistictasks. Wedevelopsuchacontinuallearner
called Model Zoo. At each episode, a small multi-task model that is Ô¨Åtted to the current task and
some of the past tasks is added to Model Zoo. This method is loosely inspired from AdaBoost in that
it selects tasks that performed poorly in the past rounds and could therefore beneÔ¨Åt the most from
being trained with the current task. At inference time, given the task, we average predictions from all
models in the ensemble that were trained on that task.
3. Empirical results We comprehensively evaluate Model Zoo on existing task-incremental
continuallearningbenchmarkproblemsandshowcomparisonswithexistingmethods. Thereisawide
variety in the problem settings used by existing methods, e.g., some replay data from past tasks (like
ModelZooisdesignedtodo),somereplayonlyasubsetofdata,sometrainonlyforoneepochineach
1arXiv:2106.03027v3  [cs.LG]  15 Jun 2022

--- PAGE 2 ---
5 10 15 20
Number of Tasks0255075100Avg. Accuracy (%)
SGD (47)
EWC (48)
AGEM (52)ER (55)
Stable-SGD (49)
TAG (58)Isolated-small-Single Epoch (66)
Model Zoo-small-Single Epoch (81)
Isolated-Single Epoch (40)Model Zoo- Single Epoch (64)
Isolated-Multi epoch (86)
Model Zoo-Multi Epoch (97)Comparison of Methods on Mini-Imagenet
5 10 15 20
Number of Tasks0255075100Task Accuracy (%)
IsolatedMulti Epoch Single Epoch
Task1 Task5 Task9 Task13 Task17Individual Task Accuracies on Split-miniImagenetFigure 1: Left: How well do existing continual learning methods work in the single-epoch setting? We
track the average accuracy (over all tasks seen until the current episode) on the Split-miniImagenet dataset.
Allmethodsinthisplot(unlessspeciÔ¨Åedotherwise)areevaluatedinthesingle-epochsetting(Lopez-Pazand
Ranzato, 2017), i.e., each new task is allowed only 1 epoch of training. We compare our method Model Zoo
anditsvariants(allinbold)toexistingcontinuallearningmethodsdesignedforthesingle-epochsetting(faint
lines, seeTable 1for references). Isolated refersto avery simplistic realizationof ModelZoo where aseparate
model isÔ¨Åtted at each episodewithout any continual learning,or data sharingbetween tasks; Isolated-small or
Model Zoo-small refer to using a very small deep network with 0.12M weights. A number of surprising Ô¨Åndings
are seen here. (i) Isolated-small (black) outperforms existing methods by more than 10%, while having a faster
training time, inference time, comparable model size and without performing any data replay. This indicates
thatexisting methods do not suÔ¨Éciently leverage data from multiple tasks . This also indicates the utility of
simple methods like Isolated to perform a more prosaic, matter-of-fact, evaluation of continual learning. (ii)
Whilethelargermodelwith3.6Mweightsperround,Isolated-SingleEpoch(royalblue),performspoorly,its
accuracyisbetterthanexistingmethods(Isolated-MultiEpoch)uponbeingtrainedformultipleepochs. This
indicates that methods may be severely under-trained in the single-epoch setting and this may not be the
appropriate setting to build continual learning methods; this was also noticed by Lopez-Paz and Ranzato (2017).
(iii)ModelZooandModelZoo-smallwhichreplayalldatafrompasttasks(A-GEMalsoreplays10%ofthe
data), achieves around 10% improvement over its Isolated counterparts in both the single-epoch and multi-epoch
setting;ModelZoohasanimprovedabilitytosolveeachtaskbyleveragingothertasks . This indicates that
replayingdatafrompasttasksisbeneÔ¨Åcial(Robins,1995),evenifreplaymaynotconformtocertainstylistic
formulationsofcontinuallearningintheliterature(FarquharandGal,2019a;Kaushiketal.,2021). Notdoingso
signiÔ¨Åcantly hurts forward and backward transfer, and average task accuracy.
Right: Does the single-epoch setting show forward-backward transfer? The evolution of individual task
accuracy of Model Zoo (the multi-epoch setting in bold and single-epoch setting in dotted), on the Split-
miniImagenet dataset (only 5 tasks are plotted here, see Fig. A6 for the full version). The X markers denote
the accuracy of Isolated. Accuracy of tasks improves with each episode which indicates backward transfer.
Also,theXmarkersareoftenbelowtheinitialaccuracyofthetaskduringcontinuallearning,whichindicates
forwardtransfer. Whilebothsingle-epochandmulti-epochModelZooshowgoodforward-backwardtransfer,
theaccuracyoftasksfortheformerisabout25%worsethanthelatter;correspondingplotsforothermethodsare
in Appendix B.6. This indicates that we should also pay attention to under-training and per-task accuracy in
continual learning.
episode, some use extremely small architectures, etc. We compare Model Zoo with existing methods
in a number of these settings. Model Zoo obtains better accuracy than existing methods on the
evaluatedbenchmarks. Improvementinaverageper-taskaccuracyisquitelargeinsomecases,
e.g., 30% for Split-miniImagenet. We also show that Model Zoo demonstrates strong forward and
backward transfer.
4. Acriticallookatcontinuallearning WeÔ¨ÅndthatevenanIsolatedlearner,i.e.,onewhichtrains
a(small)modelontasksfromeachepisodeanddoesnotperformanycontinuallearning,signiÔ¨Åcantly
outperforms mostexisting continual learning methods on the evaluated benchmark problems, e.g., by
more than 8% in Fig. 1 and Table 1 and ??. This strong performance is surprising because it is a very
simple learner that has better training/inference time, no data replay, and a comparable number of
weights as that of existing methods.
2

--- PAGE 3 ---
2 A /t.pc/h.pc/e.pc/o.pc/r.pc/e.pc/t.pc/i.pc/c.pc/a.pc/l.pc /a.pc/n.pc/a.pc/l.pc/y.pc/s.pc/i.pc/s.pc /o.pc/f.pc /h.pc/o.pc/w.pc /t.pc/o.pc /l.pc/e.pc/a.pc/r.pc/n.pc /f.pc/r.pc/o.pc/m.pc /m.pc/u.pc/l.pc/t.pc/i.pc/p.pc/l.pc/e.pc /t.pc/a.pc/s.pc/k.pc/s.pc
In this section, we (i) formulate the problem of learning from multiple tasks, (ii) discuss a simple
model that highlights when training one model on multiple tasks is beneÔ¨Åcial, and (iii) show new
results on how the Ô¨Åxed capacity of the model causes competition between tasks.
2.1 P/r.pc/o.pc/b.pc/l.pc/e.pc/m.pc F/o.pc/r.pc/m.pc/u.pc/l.pc/a.pc/t.pc/i.pc/o.pc/n.pc
A supervised learning task is deÔ¨Åned as a joint probability distribution P(x;y)of inputsx2X
andlabelsy2Y. Thelearnerhasaccessto mi.i.dsamples S=fxi;yigi=1;:::;mfromthetask. A
hypothesis is a function h:X!Ywithh2Hbeing the hypothesis space. The learner may select
a hypothesis that minimizes the empirical risk
^eS(h) =1
mmX
i=11fh(xi)6=yig
with the hope of achieving a small population risk
eP(h) =P(h(x)6=y):
Classical PAC-learning results (Vapnik, 1998) suggest that with probability at least 1 over draws
of the dataS, uniformly for any h2H, we haveeP(h)^eS(h) +if
m=O(D log)
2
(1)
whereD=VC(H)is the VC-dimension of the hypothesis space H. We deÔ¨Åne the ‚Äúexcess risk‚Äù of a
hypothesis as
EP(h) =eP(h) inf
h2HeP(h):
In thecontinual learning setting, a new taskis shown tothe learner ateachepisode (orround). Hence
afternepisodes, the learner is presented with ntasks P:= (P1;:::;Pn), with the corresponding
training sets S:= (S1;:::;Sn), each with msamples, and the learner selects nhypotheses
h= (h1;:::;hn)2Hn, eachhi2H. If it seeks a small average population risk
eP(h) =1
nnX
i=1ePi(hi);
it may do so by minimizing the average empirical risk
^eS(h) =1
nnX
i=1^eSi(hi):
As Baxter (2000) shows, under very general conditions, if
m=O1
2
dH(n) 1
nlog
; (2)
then we have eP(h)eS(h) +for any h2Hn. The quantity dH(n)here is a generalized
VC-dimension for the family of hypothesis spaces Hn, which depends on the joint distribution of
tasks. Larger the number of tasks n, smaller the dH(n)(Ben-David and Borbely, 2008). Whether (2)
is an improvement upon training the task in isolation as in (1) depends upon the hypothesis class H
and the relatedness of tasks P1;:::;Pnthrough the quantity dH(n). The most important thing to
notehereisthataccordingtothesecalculations,ifonewishestoobtainasmall averagepopulation
risk across tasks, training multiple tasks together cannot be worse:
dH(n)VC(H):
This result is the motivation for methods that train multiple tasks together.
3

--- PAGE 4 ---
2.2 C/o.pc/n.pc/t.pc/r.pc/o.pc/l.pc/l.pc/i.pc/n.pc/g.pc /t.pc/h.pc/e.pc /e.pc/x.pc/c.pc/e.pc/s.pc/s.pc /r.pc/i.pc/s.pc/k.pc /o.pc/f.pc /a.pc /s.pc/p.pc/e.pc/c.pc/i.pc/f.pc/i.pc/c.pc /t.pc/a.pc/s.pc/k.pc /f.pc/o.pc/r.pc /s.pc/y.pc/n.pc/e.pc/r.pc/g.pc/i.pc/s.pc/t.pc/i.pc/c.pc /t.pc/a.pc/s.pc/k.pc/s.pc
Animportantgoalofcontinuallearningistohavelowriskon alltasks. Thisisastrongerrequirement
than for (2) which bounds the averagepopulation risk on all tasks.
Suppose there exists a family Fof functions fi:X!Xthat map the inputs of one task to those of
another, i.e., any task can be written as
Pj(A) =f[Pi](A) =Pi(f(f(x);y) : (x;y)2Ag)
for some function f2Ffor any setA. We can assume without loss of generality that Facts as a
groupoverthehypothesisspaceand Hisclosedunderitsaction. Insimplewords,thisentailsthat
givenh2Hsuitable for task P, we can obtain a new hypothesis hfthat is suitable for another
taskf[P]. Instead of searching over the entire space Hnlike in ¬ß2.1, we now only need to Ô¨Ånd a
hypothesish2Hsuch that its orbit
[h]F=fh0:9f2Fwithh0=hfg
containshypothesesthathavelowempiricalriskoneachofthe ntasks. Conceptually,thissteplearns
the inductive bias (Baxter, 2000; Thrun and Pratt, 2012). The sample complexity of doing so is
exactly(2). Fromwithinthisorbit, wecanselectahypothesisthathaslowempiricalriskforachosen
taskP1. The sample complexity of this second step is
jS1j=O1
2(dmax log)
(3)
wheredmax= suph2HVC([h]F). By uniform convergence, as Ben-David and Schuller (2003) show,
this two-step procedure assures low excess risk for everytaskP1;:::;Pn. We have
suph2HVC([h]F) =dmaxdH(n+ 1)dH(n)D=VC(H): (4)
Thetotalsamplecomplexityisfavorabletothatoflearningthetaskinisolationifboth dH(n)and
dmaxare small. For instance, if Fis Ô¨Ånite and n=lognD, we havedH(n)2 logjFjwhich
indicates that we get a statistical beneÔ¨Åt of learning with multiple tasks if DlogjFj.
Remark 1 (Data from other tasks may not improve accuracy even if they are synergistic). Let
us make a few observations using the above analysis. (i) From (4), number of samples per task m
decreaseswith n;thisisthebeneÔ¨Åtofthestrongrelatednessamongtasksandasweseenext,thisis not
the case in general. (ii) The number of tasks scales essentially linearly with D, which indicates that
one should use a small model if we have few tasks. (iii) But we cannot always use a small model. If
tasks are diverse and related by complex transformations with a large jFj, we need a large hypothesis
space to learn them together. If jFjis large andHis not appropriately so, the VC-dimension dmaxis
as large asDitself; in this case there is again no statistical beneÔ¨Åt of training multiple tasks together,
but there is no deterioration either.
2.3 T/a.pc/s.pc/k.pc /c.pc/o.pc/m.pc/p.pc/e.pc/t.pc/i.pc/t.pc/i.pc/o.pc/n.pc /o.pc/c.pc/c.pc/u.pc/r.pc/s.pc /f.pc/o.pc/r.pc /h.pc/y.pc/p.pc/o.pc/t.pc/h.pc/e.pc/s.pc/i.pc/s.pc /s.pc/p.pc/a.pc/c.pc/e.pc/s.pc /w.pc/i.pc/t.pc/h.pc /l.pc/i.pc/m.pc/i.pc/t.pc/e.pc/d.pc /c.pc/a.pc/p.pc/a.pc/c.pc/i.pc/t.pc/y.pc
Therecould besettingsunderwhichÔ¨Åttingone modelonmultiple tasksmay notsuÔ¨Éce. To study
this, we consider a weaker notion of relatedness. We say that two tasks Pi;Pjareij-related if
cE1=ij
Pi(h)EPj(h;h
i);for allh2H: (5)
HereEP(h;h0) :=eP(h) eP(h0)andh
i=argminh2HePi(h)is the best hypothesis for task Pi;
wesetc1tobeacoeÔ¨Écientindependentof i;j. Smallerthe ij,moreusefulthesamplesfrom
Pito learnPj. The deÔ¨Ånition suggests that all hypotheses hwhich have low excess risk on Pi
alsohavelowexcessriskon Pjuptoanadditiveterm ePj(h)andthiseÔ¨Äectbecomesstrongeras
ij!1+. Note that the deÔ¨Ånition of relatedness is not symmetric. Hanneke and Kpotufe (2020) call
this the transfer exponent. To gain some intuition, we can connect this deÔ¨Ånition to a certain triangle
inequality between the tasks developed by Crammer et al. (2008): in the realizable setting where
ePi(h
i) = 0, forc;ij= 1, we can write (5) as
ePi(h) +ePj(h
i)ePj(h)
whichisakintoatrianglewithverticesat h;h
iandh
jwithtermslike ePi(h)representingthelength
oftheside between handh
i. ThisdeÔ¨Ånition thereforemodelsasetof tasksandhypothesisspace
thatisnotundulypathological, ePj(h)cannotbemuchworsethanthesumoftheothertwosides. We
can now show the following theorem bounds the excess risk EP1(h)for a hypothesis htrained using
data from multiple tasks. See Appendix C for the proof.
4

--- PAGE 5 ---
Theorem2(Taskcompetition). SaywewishtoÔ¨Åndagoodhypothesisfortask P1andhaveaccessto
ntasksP1;:::;Pnwhereeachpair Pi;Pjareij-related. Arrangetasksinanincreasingorderof i1,
i.e.,theirrelatednessto P1. Letthisorderingbe P(1);P(2);:::;P (n)with(1)(2):::(n)
andP(1)P1and(1)= 1. Let ^hkbethehypothesisthatminimizestheaverageempiricalriskof
the Ô¨Årstkntasks. Then, with probability at least 1 over draws of the training data,
EP1(^hk)1
kPk
i=1EP1(h
(i)) +c
k
eS(h) +c0
D log
km1=21=max
(6)
wheremax(k) = max
(1);:::; (k)	
andc;c0are constants.
Notice that the Ô¨Årst term grows with the number of tasks kbecause we pick tasks with lower i1that
are more and more dissimilar to P1. The second term typically decreases with k. The empirical risk
eS(h)is typically small; in our experiments with deep networks we achieve essentially zero training
error on all. Increasing the number of tasks k, increases the eÔ¨Äective number of samples km, thereby
reducing the second term in totality. At the same time, these new samples are increasingly more
ineÔ¨Écient because max(k)increases with k.
Remark 3 (Picking the size of the hypothesis space). The Ô¨Årst and second terms characterize
synergies and competition between tasks and balancing them is the key to good performance on a
giventask. IncreasingthesizeofthehypothesisspacereducestheÔ¨Årsttermsinceitallowsasingle
hypothesistomoreeasilyagreeontwodistinctdistributions PiandPj. However,thiscomesatthe
cost of increasing the second term which grows with the size of the hypothesis space.
Remark 4 (The set of synergistic tasks can be diÔ¨Äerent for diÔ¨Äerent tasks). The right hand side
in (6) is minimized for a choice of k(where 1kn) that balances the Ô¨Årst and second terms.
The optimal kcan vary with the task, e.g., a small optimal kindicates task dissonance, where the
particulartask,say P1shouldbetrainedwithaspeciÔ¨Åcsetofothertasks. Evenfortypicaldatasets
like CIFAR-100, it is highly nontrivial to understand the ideal set of tasks to train with; Fig. 2 studies
this experimentally.
Remark 5 (Continual learning is particularly challenging due to task competition). Theorem2
indicatesthatnotonlyisthelearnershowntaskssequentially, butitalsomayhavetoworkagainstthe
competitionbetweenthecurrenttaskandtherepresentationlearnedonapasttask. Itdoesnothave
access to synergistic tasks from the future while learning on the current task. And further, in settings
wherethereisnodatareplay,thelearnercannotbeneÔ¨Åtfrompastsynergistictasksexplicitly,other
thantherepresentationthatithasalreadylearnt. Thissuggeststhatonemustbeevenmorecareful
about how the representation in continual learning should be updated.
7 8 9 10 11 12 13 14 15 16 17 18 19 20
Number of tasks trained togetherElectrical Devices
Household Furniture
Insects
Large Carnivores
Man-made Outdoor
Natural Outdoor
Omni-Herbivores
People
ReptilesAccuracy of fixed subset of tasks68.75 69.85 69.30 68.75 70.25 69.65 69.00 67.35 69.05 69.25 69.60 69.75 70.15 70.90
65.85 65.60 65.70 66.30 66.25 66.40 66.10 65.80 65.85 65.25 66.90 66.65 67.90
68.00 68.95 69.30 68.55 69.15 68.70 68.45 69.75 68.45 70.40 69.35 69.00
74.65 75.00 75.20 73.05 73.50 73.50 73.60 73.85 73.70 74.10 73.05
78.55 77.55 78.15 79.15 78.35 78.40 77.45 78.00 78.70 79.10
79.25 78.25 77.60 78.55 78.40 77.40 78.65 80.05 78.45
71.10 67.95 70.10 69.50 69.60 68.70 69.75 70.00
42.65 40.80 41.05 41.75 43.20 42.65 41.55
58.75 57.70 57.05 57.85 59.25 59.00
Figure2: Competitionbetweentasksincontinuallearningcanbenon-trivial. Inordertodemonstratehow
sometaskshelpandsometaskshurteachother,werunamulti-tasklearnerforavaryingnumberoftasks(X-axis)
andtracktheaccuracyonafewtasksfromCIFAR100(eachtaskisasuperclass). EachcellrepresentsadiÔ¨Äerent
experiment,i.e,thereisnocontinuallearningbeingperformedhere. Cellsarecoloredwarmifaccuracyisworse
thanthemedianaccuracyofthatrow. Forinstance,multi-tasktrainingwith11tasksisbeneÔ¨Åcialfor‚ÄúMan-made
Outdoor‚Äù but accuracy drops drastically upon introducing task #12, it improves upon introducing #14, while
task#17 againleadstoa drop. One maystudytheother rowstoreacha similarconclusion: there isnon-trivial
competition between tasks, even in commonly used datasets. As we show, tackling this eÔ¨Äectively is the key to
obtaining good performance on continual learning problems. See Appendix B.1 for a more elaborate version.
5

--- PAGE 6 ---
3 M/o.pc/d.pc/e.pc/l.pc Z/o.pc/o.pc: A /c.pc/o.pc/n.pc/t.pc/i.pc/n.pc/u.pc/a.pc/l.pc /l.pc/e.pc/a.pc/r.pc/n.pc/e.pc/r.pc /t.pc/h.pc/a.pc/t.pc /g.pc/r.pc/o.pc/w.pc/s.pc /i.pc/t.pc/s.pc /l.pc/e.pc/a.pc/r.pc/n.pc/i.pc/n.pc/g.pc /c.pc/a.pc/p.pc/a.pc/c.pc/i.pc/t.pc/y.pc
Theorem2canbethoughtofasa‚Äúnofreelunchtheorem‚Äù. Itindicatesthatoneshouldnotalways
expect improved excess risk by combining data from diÔ¨Äerent tasks. This theorem also suggests a
way to work around the problem via Remarks 3 and 4. If we learn small models on synergistic tasks,
wecanhopetohaveeachtaskbeneÔ¨Åtfromthesynergieswithoutdeteriorationofaccuracyduetotask
competition with dissonant tasks. Model Zoo is a simple method that is designed for this purpose.
Let us assume that tasks P1;:::;Pnare shown sequentially to the continual learner. We assume
thatalltaskshavethesameinputdomain XbutmayhavediÔ¨Äerentoutputdomains Y1;:::;Yn. At
each‚Äúepisode‚Äù k,ModelZooisdesignedtotrainusingthecurrenttask Pkandasubsetofthepast
tasks. Forexample,atepisode k= 2,wetrainamodelwithafeaturegenerator handtask-speciÔ¨Åc
classiÔ¨Åerstoobtainmodels g1h:X7!Y1andg2h:X7!Y2. Thismodelcanclassifyinputs
frombothtasksandgivesoutaprobabilityvector pgih(yjx);8y2Yidependinguponthetask. We
assume that the identity of the task is known at the test time.
Model 1
Model 2
Model 3P3P4P6
P5P1
P2
Figure 3: Ideally,wewanttotrainsynergis-
tic tasks together, e.g., Model 1 for P1using
P3;P6and Model 3 for P3usingP1;P4;P5.
At test time, all models (1, 2, 3) that were
trained on a particular task, say P1would
make predictions. Model Zoo is a simple,
scalable instantiation of this idea. Discov-
ering noncompeting tasks is diÔ¨Écult, so it
selectstasksthathavehightraininglossunder
the current ensemble.Let the set of tasks considered at episode kbe denoted by
Pk=fP!1
k;:::;P!b
kgwhere bkisahyper-parameter
and!i
k2f1;:::;kg. Trainingon Pkwillinvolve,likethe
exampleabove,trainingonemodelwithafeaturegenerator
hkandtask-speciÔ¨ÅcclassiÔ¨Åers gk;!i
kforeachtaskselected
in that round. Such models, one trained in each round,
togetherformthe‚ÄúModelZoo‚Äù. After krounds,datafrom,
say,Piwithikcan be predicted using the average of
class probabilities output by all models that were Ô¨Åtted on
that task, i.e.,
pk;i(yjx)/Pk
l=11fPi2Plggl;ihl(x):(7)
This expression is also used to predict at test time.
Selectingtaskstotrainwithforeachroundusingboost-
ingIn principle, we could use the transfer exponents ij
toselectsynergistictasks,butcomputingthetransferex-
ponents is essentially as diÔ¨Écult as training on all tasks, a
continual learner does not have access to all tasks a priori.
Wethereforedevelopanautomaticwaytoselecttasksin
each round. We draw inspiration from boosting (Schapire
andFreund,2013)forthispurpose. RecalltheAdaBoost
algorithmwhichbuildsanensembleofweaklearners(they
canbeanylearnerinprincipleMasonetal.(1999)),eachofwhichisÔ¨Åtteduponiterativelyre-weighted
training data (Breiman, 1998). We think of the models learned at each episode of continual learning
in Model Zoo as the ‚Äúweak learners‚Äù and each round of boosting as the equivalent of each episode of
continual learning. Let wk2Rnbe a normalized vector of task-speciÔ¨Åc weights. After episode k
wk;i/exp
 1=mP
(x;y)2Silogpk;i(yjx)
: (8)
for each task Piwithik; fori > k,wk;i= 0. Tasks for the next round Pk+1are drawn from
a multinomial distribution with weights wk. Therefore, tasks with a low empirical risk under the
current Model Zoo get a low weight for the next boosting round. Just like AdaBoost drives down
the training error on allsamples to zero exponentially (Schapire and Freund, 2013) by iteratively
focusingupondiÔ¨Écult-to-classifysamples,ModelZooachievesalowempiricalriskon alltasksas
more models are added.
ThekeyfeatureofModelZoo isthatitautomatically splitsthecapacityacrosssetsoftasks. Evenif
competingtasksarechoseninoneround,whichmayresultinhighexcessriskonsometask,itwill
be chosen again in future rounds if it has a large error under the ensemble. Colloquially speaking,
the ensemble in Model Zoo represents a ‚Äúbrain‚Äù that grows its learning capacity continually as more
tasks are shown to it.
Remark 6 (Assumptions in the formulation of Model Zoo). We assume that, both at training time
andtesttime,theidentityofthetaskisknowntothecontinuallearner. Datafrompasttasksisalso
6

--- PAGE 7 ---
storedwiththetaskidentity. Thisisknownasthetask-incrementalsettingintheliterature(Vande
VenandTolias,2019). Recentworkincontinuallearningalsostudiessettingswheresuchtaskidentity
is not known, e.g., (Kaushik et al., 2021), Model Zoo is not designed to handle such settings.
4 E/m.pc/p.pc/i.pc/r.pc/i.pc/c.pc/a.pc/l.pc V/a.pc/l.pc/i.pc/d.pc/a.pc/t.pc/i.pc/o.pc/n.pc
4.1 S/e.pc/t.pc/u.pc/p.pc
Datasets WeevaluateonRotated-MNIST(Lopez-PazandRanzato,2017),Split-MNIST(Zenke
et al., 2017), Permuted-MNIST (Kirkpatrick et al., 2017), Split-CIFAR10 (Zenke et al., 2017),
Split-CIFAR100‚àó(Zenke et al., 2017), Coarse-CIFAR100 (Rosenbaum et al., 2017; Yoon et al.,
2019;Shanahanetal.,2021)andSplit-miniImagenet(Vinyalsetal.,2016;Chaudhryetal.,2019b).
Split-MNIST,Split-CIFAR10,Split-CIFAR100andSplit-miniImagenetuseconsecutivegroupsof
labels (2, 2, 5 and 10, respectively) to form tasks. Coarse-CIFAR100 is a variant of CIFAR100 where
each super-class is considered a diÔ¨Äerent task (Yoon et al., 2019; 2021; Shanahan et al., 2021). Our
study in Fig. 2 has found that Coarse-CIFAR100 is a diÔ¨Écult dataset for continual learning, perhaps
because of the semantic diÔ¨Äerences among the diÔ¨Äerent super-classes.
Neural architectures and training methodology We use a small wide-residual network
of Zagoruyko and Komodakis (2016) (WRN-16-4 with 3.6M weights) with task-speciÔ¨Åc classi-
Ô¨Åers (one fully-connected layer). We also use an even smaller network (0.12M weights) with 3
convolutionlayers(kernelsize3and80Ô¨Ålters)interleavedwithmax-pooling,ReLU,batch-normlayers,
withtask-speciÔ¨ÅcclassiÔ¨Åerlayers. Stochasticgradientdescent(SGD)withNesterov‚Äôsmomentum
and cosine-annealed learning rate is used to train all models in mixed precision. Ray Tune (Liaw
et al., 2018) was used for hyper-parameter tuning using a multi-task learning model on all tasks from
Coarse CIFAR-100. When we do full replay, Model Zoo samples b= min(k;5)tasks at the kth
episode;forproblemswith n= 5tasks,weset b= 2;notethat b= 1indicatesnodatareplay. All
hyper-parameters are kept Ô¨Åxed for all datasets and all experiments (see ¬ß4.2).
See Appendix A for more details.
4.2 E/v.pc/a.pc/l.pc/u.pc/a.pc/t.pc/i.pc/n.pc/g.pc /c.pc/o.pc/n.pc/t.pc/i.pc/n.pc/u.pc/a.pc/l.pc /l.pc/e.pc/a.pc/r.pc/n.pc/i.pc/n.pc/g.pc /m.pc/e.pc/t.pc/h.pc/o.pc/d.pc/s.pc
Thereisawidevarietyofproblemformulationsinthecontinuallearningliterature(FarquharandGal,
2019a;Prabhuetal.,2020;Vogelsteinetal.,2020;Lopez-PazandRanzato,2017;VandeVenand
Tolias,2019). Formulationsvarywithrespecttowhethertheyallowreplayingdatafrompasttasks,
the number of epochs the learner is allowed to train each task for, and the capacity of the model being
Ô¨Åtted. We next explainthese diÔ¨Äerent formulations, therationale behindthem, and how we execute
Model Zoo to conform to each of these settings.
(i)Thestrictformulation , e.g.,Kirkpatricketal.(2017);Kaushiketal.(2021), doesnotallow
anyreplayofdata. ForthestrictformulationofModelZoo,wesimplyset wk;i= 0forall
i6=kin (8). At each episode, a single model is trained on the current task and added to
the zoo‚Äîwe call this rather simplistic learner Isolated. From a practical standpoint, such a
formulationimposesaconstraintontheamountofcomputationalresources(computeand/or
memory) available during training.
(ii)One canreplay data to various degrees , e.g., all of it (Nguyen et al., 2017; Guo et al.,
2020b), or a subset of it (Chaudhry et al., 2019a). Just like AdaBoost, Model Zoo is
fundamentallydesignedtoallowfullreplayofpasttasks. However,wecaneasilyexecute
it with limited replay by only using a subset of the data to compute gradient updates and
also the accuracy on past tasks in the kthepisode. We use the nomenclature Model Zoo
(10% replay) to indicate that only 10% of the data from past tasks is used; algorithms like
A-GEM (Chaudhry et al., 2019a) also use 10% of past data on CIFAR100 datasets. See
AppendixA.4forimplementationdetails. NotethatModelZoowithoutanydatareplayis
‚àóSome works (RebuÔ¨É et al., 2017a; Lopez-Paz and Ranzato, 2017; Chaudhry et al., 2019a; Mirzadeh et al.,
2020b)evaluateonasplitoftheCIFAR100datasetwhereeachtaskisrandomsubsetof5classes. Wedonot
evaluateonthisvariantbecauseitisdiÔ¨Éculttoexactlyreproducethecompositionoftasks;asFig.2suggests
diÔ¨Äerent compositions can have vastly diÔ¨Äerent task accuracy. This is also highlighted by large diÔ¨Äerences in the
accuracy on Split-CIFAR100 and Coarse-CIFAR100 in our work.
7

--- PAGE 8 ---
simplyIsolated. Letusemphasizethatacrossalltheseproblemsettings,ModelZooremains
a legitimate continual learner because it gets access to each task sequentially and has a Ô¨Åxed
computational budget ( btasks) at each episode. For a multi-task learner, the computational
complexity scales with the number of tasks.
(iii)To imposea strict constraint on the computationalcomplexity of each episode someworks,
e.g.,Chaudhryetal.(2019a),traineachtaskforasingleepoch. Wethereforeshowresults
using both Model Zoo (single epoch) (where we replay past data for 1 epoch) and Isolated
(single epoch) (no replay). Even if the rationale behind using each datum only once is
well-taken,onesingleepochisquiteinsuÔ¨Écienttotrainmoderndeepnetworks;ifonethinks
ofbiologicalconsiderations,local-descentalgorithmslikestochasticgradientdescent(SGD)
arequitediÔ¨Äerentfromrecurrentcircuitsinthebiologicalbrain(Kietzmannetal.,2019).
We also run single epoch methods using a very small model (0.12M weights); these are
Model Zoo/Isolated-small (single epoch) .
(iv)Multi-Head trains one single model on all tasks to minimize the average empirical risk
with task-speciÔ¨Åc classiÔ¨Åers; mini-batches contain samples from diÔ¨Äerent tasks. Since
Multi-Headistrainedonalltaskstogether,itisnotacontinuallearner,butitsaccuracyis
expected to be an upper bound on the accuracy of continual learning methods.
Evaluationcriteria Wecomparealgorithmsintermsofthevalidationaccuracyaveragedacrossall
tasks at the end of all episodes, average per-task forward transfer (accuracy on a new task when it
is Ô¨Årst seen, larger this number more the forward transfer), average per-task forgetting (gap in the
maximal accuracy of a task during continual learning and its accuracy at the end, larger this number
more the forgetting and worse the backward transfer), training and inference time, and memory. Let
us note that forward transfer is also sometimes called ‚Äúlearning accuracy‚Äù (Riemer et al., 2018), and
another measure of backward transfer is the gap between the accuracy at the end of training and the
initial accuracy of the task.
4.3 R/e.pc/s.pc/u.pc/l.pc/t.pc/s.pc
Table 1 shows the validation accuracy of diÔ¨Äerent continual learning methods on standard benchmark
problems. There are many striking observations here.
(i)Accuracy of existing methods compared to in Table 1 (see ??as well)is poorer than
Isolated. This is surprising because Isolated can be thought of as the simplest possible
continual learner‚Äîone that unfreezes new capacity at each episode and does not replay data.
This indicates that existing methods may be failing to achieve forward or backward transfer
compared to simply training the task in isolation; Table 2 investigates this further.
(ii)In comparison, Model Zoo (all three variants : small, small with 10% data replay and
the standard method) hasbetteraccuracycomparedtobothexistingmethodsaswellas
Isolated. This shows the utility of splitting the capacity of the learner across multiple tasks.
(iii)Model Zoo matches the accuracy of the multi-task learner in the last row of Table 1
whichhasaccesstoalltasksbeforehand. Surprisingly, Model Zoo performs better than
Multi-Headinspiteofbeingtrainedincontinualfashion ,especiallyonharderproblems
like Coarse-CIFAR100 and Split-miniImagenet. This is a direct demonstration of the
eÔ¨ÄectivenessofModelZooinmitigatingtaskcompetition: thecapacitysplittingmechanism
not only avoids catastrophic forgetting, but it can also leverage data from other tasks even if
they are shown sequentially.
Table 2 shows a comparison of the methods developed in this paper with existing methods on
Split-CIFAR100 in terms of continual-learning speciÔ¨Åc metrics. We Ô¨Ånd:
(i)There are no signiÔ¨Åcant diÔ¨Äerences in the forward transfer performance in the single epoch
setting;largervariantsofIsolatedandModelZoodonotworkwellherebecausea single
epoch is not suÔ¨Écient to train modern deep networks . ButModel Zoo and variants
show less forgetting , it is essentially zero. This indicates that although existing methods
are designed to avoid forgetting (the single epoch setting aids this directly), say, A-GEM,
or EWC, they do forget. Forgetting can be mitigated by the capacity splitting mechanism
in Model Zoo. The per-task accuracy of existing methods is also rather low compared to
Model Zoo variants.
8

--- PAGE 9 ---
Method ReplaySingleRotated- Permuted- Split- Split- Split- Coarse- Split-
EpochMNIST MNIST MNIST CIFAR10 CIFAR100 CIFAR100 MiniImagenet
GEM (Lopez-Paz and Ranzato, 2017) 3 3 86.07 82.60 - - 67.8- 51.86
A-GEM (Chaudhry et al., 2019a) 3 3 -89.1 - -62.3- 61.13
ER-Reservoir (Chaudhry et al., 2019b) 3 3 - 79.8 - - 68.5- 64.03
MC-SGD (Mirzadeh et al., 2020a) 3 382.63 85.3 - -63.30 - -
MEGA-II (Guo et al., 2020a) 3 3 - 91.20 - - 66.12 - -
OGD (Farajtabar et al., 2020) 7 388.32 86.44 98.84 - - - -
Stable-SGD (Mirzadeh et al., 2020b) 7 3 70.8 80.1 - - 59.9- 57.79
TAG (Malviya et al., 2021) 7 3 - - - -62.79 - 57.2
VCL (Nguyen et al., 2017) 3 7 - 95.5 98.4 - - - -
FRCL (Titsias et al., 2020) 3 7 -94.3 97.8 - - - -
FROMP (Pan et al., 2020) 3 7 - 94.9 99.0 - - - -
EWC (Kirkpatrick et al., 2017) 7 78496.9 - -42.40 - -
Prog-Nets (Rusu et al., 2016) 7 7 -93.5 - -59.2 - -
SI (Zenke et al., 2017) 7 7 -97.198.9 - - - -
HAT(Serra et al., 2018) 7 7 - 98.6 99.0 - - - -
APD (Yoon et al., 2019) 7 7 - - - - -56.81 -
FedWeIT (Yoon et al., 2021) 7 7 - - - - - 55.16 -
RMN (Kaushik et al., 2021) 7 7 -97.73 99.5 -80.01 - -
Our methods
Isolated-small 7 7 - - -96.88 90.18 69.07 82.48
Model Zoo-small 3 7 - - - 96.85 92.06 73.72 94.27
Model Zoo-small (10% replay) 3 7 - - -96.58 89.76 77.18 84.6
Isolated-Resnet 7 7 - - - - 88.95 - -
Model Zoo-Resnet 3 7 - - - -93.15 - -
Isolated 7 7 99.64 98.03 99.98 97.46 91.90 80.72 86.28
Model Zoo 3 799.66 97.71 99.97 98.68 94.99 84.27 96.84
Multi-Head (multi-task) 99.66 98.16 99.98 98.11 95.38 83.19 90.83
Table 1: Averageper-task accuracy (%)at the end ofall episodes. MNIST, Permuted-MNIST and Rotated-
MNIST are not informative benchmarks for judging forward and backward transfer because even Isolated
achieves99%+accuracy. ModelZoooutperforms,bysigniÔ¨Åcantmargins,allexistingcontinuallearningmethods
on all datasets. Accuracy of existing methods is worse than Isolated which suggests little to no forward or
backward transfer. Model Zoo-small and Isolated-small have comparable number of weights as that of existing
methods, and in some cases, much fewer. Model Zoo-Resnet18-S and Isolated-Resnet18-S, make use of the
Resnet18-S architecture from Lopez-Paz and Ranzato (2017). Both Model Zoo/Isolated have similar accuracies
on Split-CIFAR100 with 3 diÔ¨Äerent architectures and all of them are better than existing methods. This indicates
that the improvement in accuracy is not a result of the speciÔ¨Åc choice of architecture. For single-epoch numbers
refertoFig.1andTable2. Note:indicatesthattheevaluationwasonSplit-CIFAR100witheachtaskcontaining
randomly sampled labels and is hence it is not directly comparable to other methods. All numbers without a
markerarefromthepapercitedin theÔ¨Årst column.denotesthattheaccuracy isnotfromtheoriginalpaperbut
from one of (Nguyen et al., 2017; Serra et al., 2018; Chaudhry et al., 2019a). Numbers for other methods on
Split-MiniImagenet were computed by us using open-source implementations of the original authors.
(ii)If our methods are implemented in the multi-epoch setting , then the forward transfer is
exceptionally good and almost as good as the average accuracy of the task. Surprisingly,
this does not come at the cost of forgetting, which is again essentially zero .
(iii)Even if Model Zoo and its variants are implemented with very small models (0.12M
weights/episode, which is 2.42M weights/20 episodes), the accuracy is better (Table 1).
This suggests that Model Zoo is a performant and viable approach to continual learning.
In fact, even the larger model used in Model Zoo is a WRN-16-4 with 3.6M weights and
thereforewecantrainmultiplemodelsonthesameGPU easily; thisiswhythetrainingtime
of Model Zoo is about the same as that of Model Zoo-small.
(iv)The simplicity of Model Zoo and its variants results in much smaller training times and
comparable inference times as compared to existing methods.
5 R/e.pc/l.pc/a.pc/t.pc/e.pc/d.pc W/o.pc/r.pc/k.pc
Theoretical work on learning from multiple tasks Works such as Baxter (2000); Maurer (2006),
orrecentoneslikeDuetal.(2020);Tripuranenietal.(2020)studyasharedfeaturegeneratorwith
task-speciÔ¨Åc classiÔ¨Åers, and show that the sample complexity of learning a task improves if true
9

--- PAGE 10 ---
Method Inference Training Storage Metrics (Multi Epoch) Metrics (Single Epoch)
time timeSamples #Weights Accuracy Forgetting Forward Accuracy Forgetting Forward
(ms/sample) (min) (%) (M) (%) (%) (%) (%) (%) (%)
EWC 10.34 50 01.6 - - -42.4 17.52 67.76
Prog-NN - 82 0 23.7 - - - 59.2 0.0 59.2
GEM 10.34 1048 5‚Äì10 1.6 - - -61.2 6.067.61
A-GEM 10.34 88 5‚Äì10 1.6 - - - 62.3 7.0 70.13
RMN 2712.4 - 011.5 80.01 - - - - -
Our methods
Isolated-small 2.3417.09 02.42 90.18 0.091.18 71.6 0.071.6
Model Zoo-small 11.70 31.71 100 2.42 92.28 0.17 90.0 73.67 0.20 71.91
Model Zoo-small (10% replay) 11.70 22.41 102.42 89.76 0.22 89.8 71.09 0.69 70.5
Isolated 2.34 20.76 0 54.8 91.9 0.0 91.0 50.43 0.0 50.43
Model Zoo 31.84 41.86 100 54.8 94.99 0.2194.02 57.67 0.8156.58
Table 2: A comparison of continual learning evaluation metrics on Split-CIFAR100 for existing methods
and the methods developed in this paper. Our methods demonstrate strong forward and backward transfer, high
per-taskaccuracy,smallertrainingtimesandcomparableinferencetimes. Trainingtimesofothermethodsare
fromChaudhryetal.(2019a)anditisthetotaltrainingtimeinminutesforalltasks. TheInferencetimeisthe
per sample prediction latency averaged over 50 mini-batches of size 16. See Appendix A.5 for more details.
Replay Split- Split-
(%) CIFAR100 miniImagenet
0 71.91 65.80
1 70.48 67.18
5 71.33 70.71
10 71.97 74.22
100 73.67 81.05# Tasks ( b) Split- Split-
(100% replay) CIFAR100 miniImagenet
1 71.91 65.02
2 72.26 67.33
5 73.67 81.05
7 73.97 88.76
9 74.13 84.9Method Model Ensemble of
ZooIsolated (100)
Split-CIFAR100 73.67 71.46
Split-miniImagenet 81.05 67.26
Figure4: Ablationstudies thatshowtheaverageper-taskaccuracyaswevarythesizeofdatareplayforModel
Zoo(left),thenumberofpasttaskssampledateachepisode(middle, b= 1impliesnoreplay),andcompare
Model Zoo with an ensemble of Isolated models (right). These results are for the single-epoch setting and
are therefore directly comparable to those in Table 2 and Table 1 as far as comparison to other methods is
concerned. Accuracy is roughly the same on Split-CIFAR100 across varying degrees of replay while it improves
signiÔ¨ÅcantlyonSplit-miniImagenet;thissuggeststhatModelZooalsoworkswithverysmallamountsofdata
replay. Accuracy on Split-CIFAR100 is consistent as the number of replay tasks is changed but increases on
larger datasets like Split-miniImagenet where there are many more tasks. Finally, the performance of Model Zoo
is not merely an artifact of ensembling. Even if Isolated is a strong model, a very large ensemble of Isolated
comparespoorlytoModelZoowith100%replay;thisindicatesthatModelZoocaneÔ¨Äectivelyleveragedata
from past tasks without forgetting. See the Appendix for more ablation studies.
task-speciÔ¨Åc classiÔ¨Åers are diverse enough. It is also appreciated that such a shared feature generator
maynotexistfordissimilartasks. SoadiÔ¨ÄerentperspectiveontheproblemcanfoundinCrammer
et al. (2008); Ben-David et al. (2010); Ben-David and Borbely (2008) who show that learning diverse
tasks requires a larger feature generator and, thereby, more samples; we discuss this in ¬ß2.2. We
builduponHannekeandKpotufe(2019;2020)toconstructthetransferexponentin¬ß2;theirwork
showsthateveninveryfavorablesettings,e.g.,whenalltaskshavethesameoptimalclassiÔ¨Åer,having
access to a large number of tasksmay not help. Model Zoo is strongly inÔ¨Çuenced from these results
and we think of it as essentially a way to circumvent them.
There are a number of algorithmic tools to estimate task relatedness , e.g., (Evgeniou et al., 2005;
Cavallanti et al., 2010; Kumar and Daume III, 2012), and although such methods are popular in
transfer learning (Pentina and Lampert, 2015; Jaakkola and Haussler, 1999), one cannot apply them
in continual learning because we do not know the tasks beforehand. As ¬ß2 shows, task relatedness is
critical to good learning. So, taking inspiration from AdaBoost (Schapire and Freund, 2013), Model
Zoo uses a simple indicator of which past tasks can beneÔ¨Åt from future ones, these are the ones with
low accuracy under the current ensemble.
Catastrophic forgetting has been the focus of a number of continual learning techniques, e.g.,
episodic memory-based ones (Lopez-Paz and Ranzato, 2017; Chaudhry et al., 2019a; Farajtabar
etal.,2020;Guoetal.,2020a),datareplay(Robins,1995;Shinetal.,2017;Leeetal.,2017),new
architectures (Serra et al., 2018), generative replay-based (Mocanu et al., 2016; Shin et al., 2017; Liu
etal.,2020;Venetal.,2020),ensemble-based(Aljundietal.,2017;Wenetal.,2020)andmethodsthat
select locally-redundant directions in the weight space (Kirkpatrick et al., 2017; Aljundi et al., 2018;
10

--- PAGE 11 ---
Mallyaetal.,2018;Zenkeetal.,2017;Chaudhryetal.,2018). Variationalmethods,e.g.,(Nguyen
et al., 2017; Farquhar and Gal, 2019b), sequentially update a posterior over the weights and have an
elegantfoundationinBayesianmethodsbutimplementingthemforlargedatasetsremainsachallenge.
In spite of intense activity, an eÔ¨Äective solution to forgetting remains largely unknown.
Model Zoo embraces the fact that forgetting is a fundamental phenomenon of learning multiple
tasks and therefore splitting the capacity may be essential; our results indicate that this approach
is eÔ¨Äectively at tackling forgetting. This approach also signiÔ¨Åcantly improves other key metrics,
e.g., forward-backward transfer and computational complexity of training and inference that have
receivedlimited attention(D√≠az-Rodr√≠guez etal., 2018). Letus notethat ModelZoo isdesigned for
the task-incremental continual learning setting (Van de Ven and Tolias, 2019).
Parametersharing/isolation Asinglesharedfeaturegenerator(i.e.,hardparametersharing)isa
populararchitecture(Kirkpatricketal.,2017;Lopez-PazandRanzato,2017;RebuÔ¨Éetal.,2017a;
Nguyen et al., 2017; Mirzadeh et al., 2020b; Chaudhry et al., 2019b). It has been recognized that this
isnot suÔ¨Écient;thishas givenrise tomethodsfor soft-parametersharingthat eitherdesignor learn
specialized routing architectures (Rosenbaum et al., 2017; Sun et al., 2019; Fernando et al., 2017;
Devin et al., 2017; Misra et al., 2016; Vandenhende et al., 2019). Model Zoo is a very simplistic
instantiationofparameterisolation,orgrowing(Rusuetal.,2016;MallyaandLazebnik,2018;Xu
and Zhu, 2018). Model Zoo trains on one episode and never updates the model again but its accuracy
does play a role in determining whether a newmodel should be used for that past task, or not. To
extendtheanalogy,justlikesoft-parametersharingarchitecturesuse,saygradientconÔ¨Çict(Aljundi
etal., 2018)or attention(Serra etal., 2018),to determinewhich synapsestoshare, ModelZoo uses
the training loss of the ensemble to decide what task the new model should be trained upon.
6 D/i.pc/s.pc/c.pc/u.pc/s.pc/s.pc/i.pc/o.pc/n.pc
Continual learning is an important problem as deep learning systems transition from the traditional
paradigm of having a Ô¨Åxed model that makes inferences on user queries to settings where we would
like to update the model to handle new types of queries. The key desiderata of such a system are
clear: it must display high per-task accuracy and strong forward-backward transfer. This paper seeks
to develop such a continual learner and investigates the problem using the lens of task relatedness. It
argues that the learner must split its capacity across sets of tasks to mitigate competition between
tasks and beneÔ¨Åt from synergies among them. We develop Model Zoo, which is a continual learning
algorithm inspired by AdaBoost, that grows an ensemble of models, each of which is trained on
data from the current episode along with a subset of past tasks. We show that across a wide
variety of datasets, problem formulations, and evaluation criteria, Model Zoo and its variants
outperform existing continual learning methods. We also show that a simple baseline method,
where a separate, small model is trained independently in each episode, outperforms a number of
existing continual methods. Appendix D discusses these results further.
R/e.pc/f.pc/e.pc/r.pc/e.pc/n.pc/c.pc/e.pc/s.pc
Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M., and Tuytelaars, T. (2018). Memory aware synapses:
Learningwhat(not)toforget. In ProceedingsoftheEuropeanConferenceonComputerVision(ECCV) ,pages
139‚Äì154.
Aljundi, R., Chakravarty, P., and Tuytelaars, T. (2017). Expert gate: Lifelong learning with a network of experts.
InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 3366‚Äì3375.
Baxter, J. (2000). A model of inductive bias learning. Journal of artiÔ¨Åcial intelligence research , 12:149‚Äì198.
Ben-David,S.,Blitzer,J.,Crammer,K.,Kulesza,A.,Pereira,F.,andVaughan,J.W.(2010). Atheoryoflearning
from diÔ¨Äerent domains. Machine learning , 79(1-2):151‚Äì175.
Ben-David, S. and Borbely, R. S. (2008). A notion of task relatedness yielding provable multiple-task learning
guarantees. Machine learning , 73(3):273‚Äì287.
Ben-David, S. and Schuller, R. (2003). Exploiting task relatedness for learning multiple tasks. In Proceedings of
the 16th Annual Conference on Learning Theory .
Breiman, L. (1998). Arcing classiÔ¨Åer (with discussion and a rejoinder by the author). Annals of Statistics ,
26(3):801‚Äì849.
11

--- PAGE 12 ---
Cavallanti,G.,Cesa-Bianchi,N.,andGentile,C.(2010). LinearalgorithmsforonlinemultitaskclassiÔ¨Åcation.
The Journal of Machine Learning Research , 11:2901‚Äì2934.
Chaudhry, A., Dokania, P. K., Ajanthan, T., and Torr, P. H. (2018). Riemannian walk for incrementallearning:
Understanding forgetting and intransigence. In Proceedings of the European Conference on Computer Vision
(ECCV), pages 532‚Äì547.
Chaudhry, A., Ranzato, M., Rohrbach, M., and Elhoseiny, M. (2019a). EÔ¨Écient lifelong learning with a-gem. In
ICLR.
Chaudhry, A., Rohrbach, M., Elhoseiny, M., Ajanthan, T., Dokania, P. K., Torr, P. H., and Ranzato, M. (2019b).
On tiny episodic memories in continual learning. arXiv preprint arXiv:1902.10486 .
Crammer, K., Kearns, M., and Wortman, J. (2008). Learning from multiple sources. Journal of Machine
Learning Research , 9(8).
Devin,C.,Gupta,A.,Darrell,T.,Abbeel,P.,andLevine,S.(2017). Learningmodularneuralnetworkpolicies
for multi-task and multi-robot transfer. In 2017 IEEE International Conference on Robotics and Automation
(ICRA), pages 2169‚Äì2176. IEEE.
D√≠az-Rodr√≠guez,N.,Lomonaco,V.,Filliat,D.,andMaltoni,D.(2018). Don‚Äôtforget,thereismorethanforgetting:
new metrics for continual learning. arXiv preprint arXiv:1810.13166 .
Du, S. S., Hu, W., Kakade, S. M., Lee, J. D., and Lei, Q. (2020). Few-Shot Learning via Learning the
Representation, Provably. arXiv:2002.09434 [cs, math, stat] .
Evgeniou, T., Micchelli, C. A., Pontil, M., and Shawe-Taylor, J. (2005). Learning multiple tasks with kernel
methods. Journal of machine learning research , 6(4).
Farajtabar, M., Azizan, N., Mott, A.,and Li, A. (2020). Orthogonal gradientdescent for continual learning. In
International Conference on ArtiÔ¨Åcial Intelligence and Statistics , pages 3762‚Äì3773. PMLR.
Farquhar,S.andGal,Y.(2019a). TowardsRobustEvaluationsofContinualLearning. arXiv:1805.09733[cs,
stat].
Farquhar,S.andGal,Y.(2019b).Aunifyingbayesianviewofcontinuallearning. arXivpreprintarXiv:1902.06494 .
Fernando, C., Banarse, D., Blundell, C., Zwols, Y., Ha, D., Rusu, A. A., Pritzel, A., and Wierstra, D. (2017).
PathNet: Evolution Channels Gradient Descent in Super Neural Networks. arXiv:1701.08734 [cs] .
Guo, Y., Liu, M., Yang, T., and Rosing, T. (2020a). Improved schemes for episodic memory-based lifelong
learning. In Advances in Neural Information Processing Systems .
Guo, Y., Liu, M., Yang, T., and Rosing, T. (2020b). Improved schemes for episodic memory based lifelong
learning algorithm. In NeurIPS.
Hanneke, S. and Kpotufe, S. (2019). On the value of target data in transfer learning. In NeurIPS.
Hanneke, S. and Kpotufe, S. (2020). A no-free-lunch theorem for multitask learning. arXiv preprint
arXiv:2006.15785 .
Jaakkola, T. and Haussler, D. (1999). Exploiting generative models in discriminative classiÔ¨Åers. In Advances in
Neural Information Processing Systems , pages 487‚Äì493.
Kaushik, P., Gain, A., Kortylewski, A., and Yuille, A. (2021). Understanding catastrophic forgetting and
remembering in continual learning with optimal relevance mapping. arXiv preprint arXiv:2102.11343 .
Kietzmann, T. C., Spoerer, C. J., S√∂rensen, L. K., Cichy, R. M., Hauk, O., and Kriegeskorte, N. (2019).
Recurrence is required to capture the representational dynamics of the human visual system. Proceedings of
the National Academy of Sciences , 116(43):21854‚Äì21863.
Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A. A., Milan, K., Quan, J.,
Ramalho,T.,Grabska-Barwinska,A.,etal.(2017). Overcomingcatastrophicforgettinginneuralnetworks.
Proceedings of the national academy of sciences , 114(13):3521‚Äì3526.
Kumar, A. and Daume III, H. (2012). Learning task grouping and overlap in multi-task learning. arXiv preprint
arXiv:1206.6417 .
Lee, S.-W., Kim, J.-H., Jun, J., Ha, J.-W., and Zhang, B.-T. (2017). Overcoming catastrophic forgetting by
incremental moment matching. Advances in Neural Information Processing Systems , 30:4652‚Äì4662.
Li,L.,Jamieson,K.,Rostamizadeh,A.,Gonina,E.,Hardt,M.,Recht,B.,andTalwalkar,A.(2018). Asystemfor
massively parallel hyperparameter tuning. arXiv preprint arXiv:1810.05934 .
Liaw, R., Liang, E., Nishihara, R., Moritz, P., Gonzalez, J. E., and Stoica, I. (2018). Tune: A research platform
for distributed model selection and training. arXiv preprint arXiv:1807.05118 .
12

--- PAGE 13 ---
Liu, X., Wu, C., Menta, M., Herranz, L., Raducanu, B., Bagdanov, A. D., Jui, S., and de Weƒ≥er, J. v. (2020).
Generative feature replay for class-incremental learning. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition Workshops , pages 226‚Äì227.
Lopez-Paz, D. and Ranzato, M. (2017). Gradient episodic memory for continual learning. In Proceedings of the
31st International Conference on Neural Information Processing Systems , pages 6470‚Äì6479.
Mallya, A., Davis, D., and Lazebnik, S. (2018). Piggyback: Adapting a single network to multiple tasks by
learningtomaskweights. In ProceedingsoftheEuropeanConferenceonComputerVision(ECCV) ,pages
67‚Äì82.
Mallya, A. and Lazebnik, S. (2018). Packnet: Adding multiple tasks to a single network by iterative pruning. In
Proceedings of the IEEE conference on Computer Vision and Pattern Recognition , pages 7765‚Äì7773.
Malviya, P., Ravindran, B., and Chandar, S. (2021). Tag: Task-based accumulated gradients for lifelong learning.
arXiv preprint arXiv:2105.05155 .
Mason,L.,Baxter,J.,Bartlett,P.,andFrean,M.(1999). Boostingalgorithmsasgradientdescent. In Proceedings
ofthe12thInternationalConferenceonNeuralInformationProcessingSystems ,NIPS‚Äô99,pages512‚Äì518,
Cambridge, MA, USA. MIT Press.
Maurer,A.(2006). Boundsforlinearmulti-tasklearning. TheJournalofMachineLearningResearch ,7:117‚Äì139.
Mirzadeh, S. I., Farajtabar, M., Gorur, D., Pascanu, R., and Ghasemzadeh, H. (2020a). Linear mode connectivity
in multitask and continual learning. arXiv preprint arXiv:2010.04495 .
Mirzadeh,S.I.,Farajtabar,M.,Pascanu,R.,andGhasemzadeh,H.(2020b). Understandingtheroleoftraining
regimes in continual learning. arXiv preprint arXiv:2006.06958 .
Misra,I.,Shrivastava,A.,Gupta,A.,andHebert,M.(2016). Cross-stitchnetworksformulti-tasklearning. In
Proceedings of the IEEE conference on computer vision and pattern recognition , pages 3994‚Äì4003.
Mocanu, D. C., Vega, M. T., Eaton, E., Stone, P., and Liotta, A. (2016). Online contrastive divergence with
generative replay: Experience replay without storing data. arXiv preprint arXiv:1610.05555 .
Nguyen, C. V., Li, Y., Bui, T. D., and Turner, R. E. (2017). Variational continual learning. arXiv preprint
arXiv:1710.10628 .
Pan, P., Swaroop, S., Immer, A., Eschenhagen, R., Turner, R., and Khan, M. E. E. (2020). Continual deep
learning by functional regularisation of memorable past. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan,
M.F.,andLin,H.,editors, AdvancesinNeuralInformationProcessingSystems ,volume33,pages4453‚Äì4464.
Curran Associates, Inc.
Pentina, A. and Lampert, C. H. (2015). Lifelong learning with non-iid tasks. Adv. Neural Inf. Process. Syst.
Prabhu,A.,Torr,P.H.,andDokania,P.K.(2020). Gdumb: Asimpleapproachthatquestionsourprogressin
continual learning. In European conference on computer vision , pages 524‚Äì540. Springer.
Rapin,J.and Teytaud, O.(2018). Nevergrad- Agradient-freeoptimizationplatform. https://GitHub.com/
FacebookResearch/Nevergrad .
RebuÔ¨É, S.-A., Bilen, H., and Vedaldi, A. (2017a). Learning multiple visual domains with residual adapters. In
Proceedings of the 31st International Conference on Neural Information Processing Systems , pages 506‚Äì516.
RebuÔ¨É, S.-A., Kolesnikov, A., Sperl, G., and Lampert, C. H. (2017b). iCARL: Incremental classiÔ¨Åer and
representationlearning. In ProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition ,
pages 2001‚Äì2010.
Riemer, M., Cases, I., Ajemian, R., Liu, M., Rish, I., Tu, Y., and Tesauro, G. (2018). Learning to learn without
forgetting by maximizing transfer and minimizing interference. arXiv preprint arXiv:1810.11910 .
Robins, A. (1995). Catastrophic forgetting, rehearsal and pseudorehearsal. Connection Science , 7(2):123‚Äì146.
Rosenbaum,C.,Klinger,T.,andRiemer,M.(2017). Routingnetworks: Adaptiveselectionofnon-linearfunctions
for multi-task learning. arXiv preprint arXiv:1711.01239 .
Rusu,A.A.,Rabinowitz,N.C.,Desjardins,G.,Soyer,H.,Kirkpatrick,J.,Kavukcuoglu,K.,Pascanu,R.,and
Hadsell, R. (2016). Progressive neural networks. arXiv preprint arXiv:1606.04671 .
Schapire, R. E. and Freund, Y. (2013). Boosting: Foundations and Algorithms . Emerald Group Publishing
Limited.
Serra, J., Suris, D., Miron, M., and Karatzoglou, A. (2018). Overcoming catastrophic forgetting with hard
attention to the task. In International Conference on Machine Learning , pages 4548‚Äì4557. PMLR.
Shanahan,M.,Kaplanis,C.,andMitroviƒá,J.(2021). Encodersandensemblesfortask-freecontinuallearning.
arXiv preprint arXiv:2105.13327 .
13

--- PAGE 14 ---
Shin, H., Lee, J. K., Kim, J., and Kim, J. (2017). Continual learning with deep generative replay. In Proceedings
of the 31st International Conference on Neural Information Processing Systems , pages 2994‚Äì3003.
Sun, X., Panda, R., Feris, R., and Saenko, K. (2019). Adashare: Learning what to share for eÔ¨Écient deep
multi-task learning. arXiv preprint arXiv:1911.12423 .
Thrun, S. and Pratt, L. (2012). Learning to Learn . Springer Science & Business Media.
Titsias,M.K.,Schwarz,J.,deG.Matthews,A.G.,Pascanu,R.,andTeh,Y.W.(2020). Functionalregularisation
for continual learning with gaussian processes. In International Conference on Learning Representations .
Tripuraneni, N., Jordan, M. I., and Jin, C. (2020). On the Theory of Transfer Learning: The Importance of Task
Diversity. arXiv:2006.11650 [cs, stat] .
Van de Ven, G. M. and Tolias, A. S. (2019). Three scenarios for continual learning. arXiv preprint
arXiv:1904.07734 .
Vandenhende,S.,Georgoulis,S.,DeBrabandere,B.,andVanGool,L.(2019). Branchedmulti-tasknetworks:
Deciding what layers to share. arXiv preprint arXiv:1904.02920 .
Vapnik, V. (1998). Statistical Learning Theory . John Wiley & Sons.
Ven, G. M., Siegelmann, H. T., Tolias, A. S., et al. (2020). Brain-inspired replay for continual learning with
artiÔ¨Åcial neural networks. Nature Communications , 11(1):1‚Äì14.
Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et al. (2016). Matching networks for one shot learning.
Advances in Neural Information Processing Systems , 29:3630‚Äì3638.
Vogelstein, J. T., Dey, J., Helm, H. S., LeVine, W., Mehta, R. D., Geisa, A., van de Ven, G. M., Chang, E.,
Gao,C.,Yang,W.,etal.(2020). Omnidirectionaltransferforquasilinearlifelonglearning. arXivpreprint
arXiv:2004.12908 .
Wen, Y., Tran, D., and Ba, J. (2020). Batchensemble: an alternative approach to eÔ¨Écient ensemble and lifelong
learning. arXiv preprint arXiv:2002.06715 .
Xu, J. and Zhu, Z. (2018). Reinforced continual learning. In Proceedings of the 32nd International Conference
on Neural Information Processing Systems , pages 907‚Äì916.
Yoon, J., Jeong, W., Lee, G., Yang, E., and Hwang, S. J. (2021). Federated continual learning with weighted
inter-client transfer. In International Conference on Machine Learning , pages 12073‚Äì12086. PMLR.
Yoon, J., Kim, S., Yang, E., and Hwang, S. J. (2019). Scalable and order-robust continual learning with additive
parameter decomposition. arXiv preprint arXiv:1902.09432 .
Zagoruyko, S. and Komodakis, N. (2016). Wide residual networks. arXiv preprint arXiv:1605.07146 .
Zenke, F., Poole, B., and Ganguli, S. (2017). Continual learning through synaptic intelligence. In International
Conference on Machine Learning , pages 3987‚Äì3995. PMLR.
14

--- PAGE 15 ---
A D/e.pc/t.pc/a.pc/i.pc/l.pc/s.pc /o.pc/f.pc /t.pc/h.pc/e.pc /e.pc/x.pc/p.pc/e.pc/r.pc/i.pc/m.pc/e.pc/n.pc/t.pc/a.pc/l.pc /s.pc/e.pc/t.pc/u.pc/p.pc
A.1 D/a.pc/t.pc/a.pc/s.pc/e.pc/t.pc/s.pc
We performed experiments using the following datasets.
1.Rotated-MNIST (Lopez-Paz and Ranzato, 2017) uses the MNIST dataset to generate 5
diÔ¨Äerent 10-way classiÔ¨Åcation tasks. Each task involves using the entire MNIST dataset
rotated by 0, 10, 20, 30, and 40 degrees, respectively.
2.Permuted-MNIST (Kirkpatrick et al., 2017) involves 5 diÔ¨Äerent 10-way classiÔ¨Åcation tasks
with each task being a diÔ¨Äerent permutation of the input pixels. The Ô¨Årst task is the original
MNISTtaskasisconvention. AllothertasksaredistinctrandompermutationsofMNIST
images.
3.Split-MNIST (Zenke et al., 2017) has 5 tasks with each task consisting of 2 consecutive
labels (0-1, 2-3, 4-5, 6-7, 8-9) of MNIST.
4.Split-CIFAR10(Zenkeetal.,2017)has5taskswitheachtaskconsistingof2consecutive
labels (airplane-automobile, bird-cat, deer-dog, frog-horse, ship-truck) of CIFAR10.
5.Split-CIFAR100 (Zenke et al., 2017) has 20 tasks with each task consisting of 5 consecutive
labels of CIFAR100. See the original paper for the exact constitution of each task.
6. Coarse-CIFAR100 (Rosenbaum et al., 2017; Yoon et al., 2019) has 20 tasks with each task
consisting of 5 labels. The tasks are based on an existing categorization of classes into
super-classes (https://www.cs.toronto.edu/ kriz/cifar.html).
7.Split-miniImagenet (Vinyals et al., 2016) is a variant introduced in Chaudhry et al. (2019b),
consisting of 20 tasks, with each task consisting of 10 consecutive labels. We merge the
meta-train and meta-test categories to obtain a continual learning problem with 20 tasks.
Eachtaskcontaining10consecutivelabelsand20%ofthesamplesareusedasthevalidation
set.
TheCIFAR10andCIFAR100-baseddatasetsconsistofRGBimagesofsize32 32whileMNIST-
based datasets consist of images of size 28 28. The Mini-imagenet dataset consists of RGB images
of size 8484.
A.2 A/r.pc/c.pc/h.pc/i.pc/t.pc/e.pc/c.pc/t.pc/u.pc/r.pc/e.pc
WeusetheWide-Resnet(ZagoruykoandKomodakis,2016)architectureforsomeofourexperiments.
The Ô¨Ånalpooling layer isreplaced with anadaptive pooling layerin order tohandle input imagesof
diÔ¨Äerent sizes. Convolutional layers are initialized using the Kaiming-Normal initialization. The bias
parameter in batch normalization is set to zero with the aÔ¨Éne scaling term set to one. The bias of the
Ô¨Ånal classiÔ¨Åcation layer is also set to zero; this helps keep the logits of the diÔ¨Äerent tasks on a similar
scale.
To ensure that the number of weights is similar to those in other methods, we also consider a smaller
convolution neural network consisting of 3 convolution layers, with batch-normalization, ReLU and
max-pooling present between each layer.
A.3 T/r.pc/a.pc/i.pc/n.pc/i.pc/n.pc/g.pc /s.pc/e.pc/t.pc/u.pc/p.pc
Optimization Allmodelsaretrainedinmixed-precision(32-bitweights,16-bitgradients)using
StochasticGradientDescent(SGD)withNesterov‚ÄôsaccelerationwithmomentumcoeÔ¨Écientsetto
0.9andcosineannealingofthelearningrateschedulefor200epochs. Trainingofanymodelwith
multiple tasks involves mini-batches that contain samples from all tasks.
Hyper-parameter optimization We used Ray Tune (Liaw et al., 2018) for hyper-parameter
optimization. The Async Successive Halving Algorithm (ASHA) scheduler (Li et al., 2018) was
usedtoprunehyper-parameterchoiceswiththesearchspacedeterminedbyNevergrad(Rapinand
Teytaud,2018). Themini-batchsizewasvariedover[8,16,32,64];thelogarithm(base10)ofthe
learning rate was sampled from a uniform distribution on [ 4; 2]; dropout probability was sampled
from a uniform distribution on [0:1;0:5]; logarithm of the weight decay coeÔ¨Écient was sampled from
15

--- PAGE 16 ---
[ 6; 2]. We used a set of experiments for continual learning on the Coarse-CIFAR100 dataset with
diÔ¨Äerent samples/class (100 and 500) to perform hyper-parameter tuning.
TheÔ¨Ånalvaluesoftraininghyper-parameters thatwerechosenare,learning-rateof0.01,mini-batch
size of 16, dropout probability of 0.2 and weight-decay of 10 5.
ModelZoouses b= min(k;5)ateachroundofcontinuallearningwhere nisthenumberoftasks;for
tasks with only 5tasks (MNIST-variants) we use b= 2. We did not tune these two hyper-parameters
using Raybecause itis quite cumbersometo doso. Weselectedthese valuesmanually across afew
experiments; changing them may result in improved accuracy for Model Zoo.
All hyper-parameters are kept Ô¨Åxed for all datasets, architectures, and experimental settings
. WeareinterestedincharacterizingtheperformanceofModelZooanditsvariantsacrossabroad
spectrum of problems and datasets. While we believe we can get even better numerical accuracy, by
tuninghyper-parametersspeciallyforeachproblem,wedonotsoforthesakeofsimplicity. Asthe
mainpaperdiscusses,weoutperformexistingmethodsquiteconvincinglyacrosstheboardinboth
multi-task and continual learning.
Data augmentation MNIST and CIFAR10/100 datasets use padding (4 pixels) with random
cropping to an image of size 28 28 or 3232 respectively for data augmentation. CIFAR10/100
images additionally have random left/right Ô¨Çips for data augmentation. Images are Ô¨Ånally normalized
to have mean 0.5 and standard deviation 0.25. Split-miniImagenet uses the same augmentation as
CIFAR-10 and CIFAR-100. We use augmentations even in the single epoch setting, although it is not
beneÔ¨Åcial to do so.
A.4 M/o.pc/d.pc/e.pc/l.pc Z/o.pc/o.pc /w.pc/i.pc/t.pc/h.pc L/i.pc/m.pc/i.pc/t.pc/e.pc/d.pc R/e.pc/p.pc/l.pc/a.pc/y.pc
As discussed in ¬ß4.2, this work considers Model Zoo (10%) which stores only 10% of the data from
thepasttasks,inordertocomparetoothermethodsthatmakeuseoflimitedreplay. Whenthetask
(saytaskA)isÔ¨Årstseen,ModelZooisallowedtouseallavailabledata. Forallfutureepisodes,if
Model Zoo picks a past task to retrain with, such a retraining uses only a Ô¨Åxed subset of the tasks‚Äô
data (10% of the samples are selected at random for this purpose). We sample each mini-batch to
contain an equal number of samples from all past and current task. At inference time, the member of
Model Zoo that is trained on all data of task A (this is the model that was Ô¨Åtted when task A was
Ô¨Årstshowntothecontinuallearner)isassignedaproportionatelylargerweightinEq. (7). For10%
replay,thiswillamountto10 largerweightthanothermodelswhichused10%datafromtaskA.
Mathematically,bothofthesetrainingandinferencemodiÔ¨ÅcationsareequivalenttousingcoeÔ¨Écients
that scale up the loss of the past task depending upon the number of samples that it has.
A.5 E/v.pc/a.pc/l.pc/u.pc/a.pc/t.pc/i.pc/n.pc/g.pc T/r.pc/a.pc/i.pc/n.pc/i.pc/n.pc/g.pc /a.pc/n.pc/d.pc I/n.pc/f.pc/e.pc/r.pc/e.pc/n.pc/c.pc/e.pc T/i.pc/m.pc/e.pc/s.pc
Inthis section, we describethe methodologyusedto estimate trainingandinference timesreportedin
Table 2.
Inference time Thecolumntitledinferencetimecorrespondstoper-samplepredictionlatencyin
milli-seconds. All entries for inference time in Table 2 were computed by us on an Nvidia V100
GPU and therefore they can be compared directly with each other. Note that inference times can
be computed using only the architecture built by each method at the end of all continual learning
episodes. Weobtainedthearchitecturesusedineachmethodfromopen-sourceimplementationsofthe
originalauthors(https://github.com/facebookresearch/agemandhttps://github.com/imirzadeh/stable-
continual-learning). Inference time is computed by processing 50 mini-batches from CIFAR-100,
each of batch-size 16. The inference time is computed by normalizing the total computation time by
(sizeofmini-batch numberofmini-batches),whichgivestheaverageinference-timepersample.
ForModel-Zoo,weassumethatinferencetimeisapproximately b= 5timestheinferencetimeof
Isolated, where bis number of tasks sampled in every round).
Training time corresponds to the time (in minutes) required to train all episodes of the Split-
CIFAR100dataset(1epochperepisode). EstablishinganaccuratecomparisonisdiÔ¨Écultbecause
diÔ¨ÄerentpapersuseddiÔ¨Äerenthardwarebutwehavestrivedtobefair. ThetrainingtimeforEWC,
Prog-NN, GEM and A-GEM are obtained from Chaudhry et al. (2019a) (we divide the numbers by 5
16

--- PAGE 17 ---
Med. MammalsAq. MammalsFish
Flowers
Food Container
Fruits and Veggies Electrical Devices
Household FurnitureInsects
Large CarnivoresMan-made OutdoorNatural OutdoorOmni-HerbivoresPeopleReptiles
Small MammalsTrees
InvertebratesVehicles 1 Vehicles 2
Other Task used in multi-task trainingMed. Mammals
Aq. Mammals
Fish
Flowers
Food Container
Fruits and Veggies
Electrical Devices
Household Furniture
Insects
Large Carnivores
Man-made Outdoor
Natural Outdoor
Omni-Herbivores
People
Reptiles
Small Mammals
Trees
Invertebrates
Vehicles 1
Vehicles 2Rel. change in Task Accuracy from Multi-task training0 24.6 32.6 2.6 3.2 2.6 3 51.4 2.6 2.6 2.8 2 04.2 44.6 1.8
5.4 05.6 4.8 4-0.8 4.8 5.6 4.4 36.6 3.8 4.4 4 51.4 3 44.4 5.8
5.2 0.8 01.8 2.8 1.4 2.8 4.2 1.6 44.8 2.8 0.6 1.8 6.2 2.6 2 22.8 3
-0.6 -5 1 01.4-0.8 2 0-0.2 1.8 0-0.2 -1-2.8 0.8 1.6-4.2 -0.2 -3.8 -1.2
-3.6 -3-3.6 -2.2 0-2.4 4 1-3-5.2 -2.2 1-2.6 -1.4 -2.4 -1.6 -1.8 -4.2 0.2 0
2.4 -2 21.6 3.2 05.8 30.4 64.6 2.4 2.4 12.6 1.2 2.2 0.4 2.2 4.2
-1.2 -3.4 -2.6 -1.8 3.4-2.2 03.4-4.6 0.8-3.2 -3.8 -6.2 -0.8 -1.2 -3.4 -1.4 0.8-2.8 -0.4
5.2 4.4 4.6 2.6 103.4 9.4 02.4 5.2 77.4 4.8 2.4 5.6 2.6 7.6 1.4 6.2 5.8
5.2 1.8 3.4 1.4 73.6 5.8 2.6 04.4 3.2 1.6 2.2 0.2 1.6-0.4 23.8 2.8 3.2
3.2 2.4 3 31.4 2.8 2.2 2.4 0.6 03.4 2 1-11.6 0.2 0.6 3.4 2.6 4.2
0 0-0.4 -1.2 1-1.2 0.8 0.6-2.2 1.2 0-1-2.4 -3.4 1-1.4 -2-3.6 1 1
-0.8 -2.8 -4 2 2-0.4 1.8 0.8-2.2 11.8 0-0.4 0.8-1.4 -1.8 0.6 0.2-1.4 0
5.4-0.4 2.8 2.8 3.6 1.2 3.4 1.8 22.4 4.4 -1 0-21.2-1.8 1.8 1.6 2.6 3.4
2.4 3.8 6 35.4 6.6 33.8 3.4 2.4 24.4 1.8 03.2 2.2 5.2 4.6 2.8 2.4
0.4 00.2 2.8-0.4 1.8 32.2 2.4 0.8 0.8 0.4 1.2-2.2 0-1.4 -13.4 0.6-0.4
21.8-2.6 0.4 2.8 -1 2 20.8 62.2 1.4-2.8 03.2 04.8 4-0.4 5.2
-1.6 -2.6 -0.8 0.2 2.4-1.4 4.2 20.6 3.4 2.4 3.4-1.6 -0.8 -11.8 00.8-0.8 -0.4
1.8 0.4 0.8 5.4 4.4-0.4 8.6 6 63.8 6.6 4.4 1.6 2.8 8.8-0.2 3.2 04.6 5
1.4-3.4 -12.2 3-0.2 1.4 23.2 2.2 3.6-1.6 2.4 2.6 4.8-0.6 0.4 -2 0 4
1.2 1-3.2 2.8 5.4 10.4 1.8 3.6 3.8 4.8 41.8-2.4 3.8 0.6-0.8 -0.2 3.6 0Figure A1: Pairwise task competition matrix . Cells arecolored bythe gain(green)/loss(warm)of accuracy
ofpairwiseMulti-Headtrainingascomparedtotrainingtherow-taskinisolation;thisisagoodproxyforthe
transfercoeÔ¨Écient ijin(5). AlthoughmostpairsbeneÔ¨Åteachother(green),certaintasks,e.g.,‚ÄúFoodContainer‚Äù
are best trained in isolation while others such as ‚ÄúAquatic Mammals‚Äù are typically detrimental to most other
tasks. One can study this matrix and identify many more such properties. In summary, whether tasks aid or hurt
each other is quite nuanced even for CIFAR100.
sincethispaperreportsthesumoftrainingtimesof5diÔ¨Äerentruns). Chaudhryetal.(2019a)also
report the training time for naive Ô¨Åne-tuning (21 mins) which in theory, should be very similar to
thetrainingtimeofourIsolatedlearner(thetrainingtimeforusis20.76minsononeV100GPU).
Since the two numbers are quite similar, we can estimate training time of the other continual learning
methodsusingtheircomputationalcostrelativetonaiveÔ¨Åne-tuning. Therefore,theestimateofthe
training times that we have reported in Table 2 can be compared to each other.
B A/d.pc/d.pc/i.pc/t.pc/i.pc/o.pc/n.pc/a.pc/l.pc E/x.pc/p.pc/e.pc/r.pc/i.pc/m.pc/e.pc/n.pc/t.pc/s.pc
B.1 U/n.pc/d.pc/e.pc/r.pc/s.pc/t.pc/a.pc/n.pc/d.pc/i.pc/n.pc/g.pc /t.pc/a.pc/s.pc/k.pc /c.pc/o.pc/m.pc/p.pc/e.pc/t.pc/i.pc/t.pc/i.pc/o.pc/n.pc
To understand which tasks aid each other‚Äôs learning and which compete for capacity and may thereby
deteriorateperformance,weinvestigatedtheCoarse-CIFAR100datasetextensively. WeÔ¨Årstcomputed
the pairwise task competition by comparing the relative gain/drop in classiÔ¨Åcation accuracy of each
pairoftaskswhentherowtaskistrainedinisolatedversustrainingtherowandcolumntaskstogether
using a simple multi-task learner (Multi-Head). Fig. A1 discusses the results.
Fig.A2,istheextendedversionofFig.2. Itshowsthevalidationaccuracyofeachtask(alongasingle
row) as more tasks are added to Multi-Head. Each column is a single Multi-Head model trained on a
subset of tasks from scratch. As more tasks are added, the accuracy of most tasks increase However,
the increase is not monotonic with each added task, and if one follows a particular row, there are
non-trivial patterns wherein adding a particular task may deteriorate the performance on the row task
17

--- PAGE 18 ---
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
Number of tasks trained togetherMed. Mammals
Aq. Mammals
Fish
Flowers
Food Container
Fruits and Veggies
Electrical Devices
Household Furniture
Insects
Large Carnivores
Man-made Outdoor
Natural Outdoor
Omni-Herbivores
People
Reptiles
Small Mammals
Trees
Invertebrates
Vehicles 1
Vehicles 2Accuracy of task72.20 73.65 74.95 73.20 73.95 73.95 76.05 74.95 74.60 75.70 75.75 76.25 75.60 75.85 75.20 76.30 76.20 76.15 76.90 75.40
53.05 53.70 53.50 53.05 52.85 55.00 55.25 54.65 53.25 56.60 54.75 56.30 54.45 56.70 56.60 55.85 56.65 56.65 57.05
64.80 66.20 65.15 65.80 65.25 66.60 67.25 67.70 67.80 67.95 67.20 68.35 67.75 68.90 68.95 69.00 67.60 69.15
63.60 64.95 64.95 66.35 67.70 65.85 66.45 67.80 66.50 65.70 65.35 66.65 67.25 66.90 66.45 66.90 69.10
63.00 63.20 65.10 66.00 66.40 65.50 66.30 66.30 68.35 65.50 66.65 66.05 66.80 65.85 67.45 67.50
75.90 77.55 78.10 77.15 77.75 79.40 77.70 78.20 77.00 77.00 77.60 77.30 78.35 76.60 78.35
68.75 69.85 69.30 68.75 70.25 69.65 69.00 67.35 69.05 69.25 69.60 69.75 70.15 70.90
65.85 65.60 65.70 66.30 66.25 66.40 66.10 65.80 65.85 65.25 66.90 66.65 67.90
68.00 68.95 69.30 68.55 69.15 68.70 68.45 69.75 68.45 70.40 69.35 69.00
74.65 75.00 75.20 73.05 73.50 73.50 73.60 73.85 73.70 74.10 73.05
78.55 77.55 78.15 79.15 78.35 78.40 77.45 78.00 78.70 79.10
79.25 78.25 77.60 78.55 78.40 77.40 78.65 80.05 78.45
71.10 67.95 70.10 69.50 69.60 68.70 69.75 70.00
42.65 40.80 41.05 41.75 43.20 42.65 41.55
58.75 57.70 57.05 57.85 59.25 59.00
56.45 55.15 56.90 57.05 57.15
61.10 61.20 62.55 61.95
64.35 65.10 66.20
74.05 73.80
84.30Figure A2: In order to demonstrate how some tasks help and some tasks hurt each other, we train a number
ofmulti-tasklearnersforavaryingnumberoftasks(X-axis)andtracktheaccuracyoneachofthetasksfrom
Coarse-CIFAR100 (100 samples/label for each task). The order of tasks is the same for rows (top to bottom)
and the columns (left to right). In other words, the Ô¨Årst cell (the diagonal) indicates the accuracy of the task
trained by itself in isolation (Isolated). Cells are colored warm if accuracy is worse than the median accuracy of
that row. For instance, multi-task training with 11 tasks is beneÔ¨Åcial for ‚ÄúMan-made Outdoor‚Äù but accuracy
dropsdrasticallyuponintroducingtask#12,itimprovesuponintroducing#14,whiletask#17againleadstoa
drop. Onemaystudytheotherrowstoreachasimilarconclusion: thereisnon-trivialcompetitionbetweentasks,
even in commonly used datasets. Tackling this issue eÔ¨Äectively is the key to obtaining good performance on
multi-task learning problems
and adding some other task later may recover the lost accuracy. This is a direct demonstration of the
tussle between the task competition term (Ô¨Årst) and the concentration term (third) in Theorem 2. This
indicates that training on the appropriate set of tasks is crucial to learn from multiple tasks.
B.2 C/o.pc/m.pc/p.pc/e.pc/t.pc/i.pc/t.pc/i.pc/o.pc/n.pc /b.pc/e.pc/t.pc/w.pc/e.pc/e.pc/n.pc /t.pc/a.pc/s.pc/k.pc/s.pc /o.pc/f.pc /t.pc/y.pc/p.pc/i.pc/c.pc/a.pc/l.pc /b.pc/e.pc/n.pc/c.pc/h.pc/m.pc/a.pc/r.pc/k.pc /d.pc/a.pc/t.pc/a.pc/s.pc/e.pc/t.pc/s.pc
Next, we investigated such task competition on other continual learning datasets, namely, Permuted-
MNIST, Rot-MNIST, Split-CIFAR10, and Split-MNIST. It is clear from Fig. A3 that there is very
little competition in this case. Either the tasks are quite diÔ¨Äerent from each other (like the case of
Permuted-MNIST), or they are synergistic (most cells are green), or they do not hurt each other‚Äôs
performance, i.e., they may correspond to the model in ¬ß2.2. Note that Rotated-MNIST exactly
corresponds to the multi-view setting discussed in ¬ß2.2 were diÔ¨Äerent input images are simple
transformations of each other.
18

--- PAGE 19 ---
Task1 Task2 Task3 Task4 Task5
Other Task used in multi-task trainingTask1 Task2 Task3 Task4 Task5Rel. change in Task Accuracy-1.37 0.35 2.65 1.02
-0.34 0.58 -1.72 0.47
1.18 1.26 0.74 0.79
3.94 -0.19 3.13 0.70
0.09 -0.88 -0.31 -1.84Permuted-MNIST
Task1 Task2 Task3 Task4 Task5
Other Task used in multi-task trainingTask1 Task2 Task3 Task4 Task5Rel. change in Task Accuracy-0.23 -0.34 -0.11 -0.07
0.47 -0.06 -0.07 -0.13
0.75 0.55 0.10 0.17
0.43 0.59 0.34 -0.17
0.53 0.43 0.41 0.35Rot-MNIST
Task1 Task2 Task3 Task4 Task5
Other Task used in multi-task trainingTask1 Task2 Task3 Task4 Task5Rel. change in Task Accuracy2.10 0.50 0.45 4.45
-0.90 1.00 1.35 -0.30
2.05 1.75 3.70 1.70
-0.25 -0.60 1.45 0.35
6.95 4.80 7.15 7.55Split-CIFAR10
Task1 Task2 Task3 Task4 Task5
Other Task used in multi-task trainingTask1 Task2 Task3 Task4 Task5Rel. change in Task Accuracy5.39 5.11 5.34 4.44
-0.15 -0.34 -0.24 -0.10
2.67 1.23 2.35 2.35
0.40 0.20 0.40 0.05
2.72 0.66 2.42 2.67Split-MNISTFigure A3: Eachrowistherelativeincrease/decrease(green/red)inaccuracyofatwotaskmulti-tasklearner
compared to training on the task corresponding to the particular row in isolation; all entries are computed using
100 samples/class. Cellsare coloredgreen for accuracy gained, andwarm for accuracydropped; theentries in
this matrixare agood proxyfor thetransfer coeÔ¨Écient ijin (5). Asimilar plotfor Coarse-CIFAR100tasks is
shownintherightpanelofFig.2. Split-CIFAR10andSplit-MNISTindicatethatmosttasksmutuallybeneÔ¨Åt
each other. This is also true, but to a lesser extent, for Rotated-MNIST. Permuted-MNIST is a qualitatively
diÔ¨Äerent problem than these, perhaps because there is no obvious relationship between the tasks and there exist
some tasks that lead to a large deterioration of accuracy.
19

--- PAGE 20 ---
B.3 V/i.pc/s.pc/u.pc/a.pc/l.pc/i.pc/z.pc/i.pc/n.pc/g.pc /s.pc/u.pc/c.pc/c.pc/e.pc/s.pc/s.pc/i.pc/v.pc/e.pc /i.pc/t.pc/e.pc/r.pc/a.pc/t.pc/i.pc/o.pc/n.pc/s.pc /o.pc/f.pc M/o.pc/d.pc/e.pc/l.pc Z/o.pc/o.pc
Round-0
Round-1
Round-2
Round-3
Round-4
Round-5
Round-6
Round-7
Round-8
Round-9
Round-10
Round-11
Round-12
Round-13
Round-14
Round-15
Round-16
Round-17
Round-18
Round-19Aq. Mammals
Fish
Flowers
Food Container
Fruits and Veggies
Electrical Devices
Household Furniture
Insects
Large Carnivores
Man-made Outdoor
Natural Outdoor
Omni-Herbivores
Med. Mammals
Invertebrates
People
Reptiles
Small Mammals
Trees
Vehicles 1
Vehicles 284 86 86 86 91 91 91
95 96 96 93 93 91 91
85 87 94 94 94 94 94
83 83 89 93 93 93 93 90 87 87 87
74 74 74 74 74 74 68 68 68 68 80
61 78 80 83 83 83 90 92
71 71 71 71 71 71 71 82 94
91 87 87 87 92 92 92 92
96 92 88 88 88
76 82 82 82 82 82 82 82
62 62 62 62 62 62 62 62 62
77 77 77 77 77 77 77 77
70 70 70 85 85 85
68 68 68 68 68 68
65 65 65 65
88 92
82
69 69
5662 63 62 75 82 80 84 86 91 90 88 91 92
72 74 78 90 96 95 96 96 96 94 93 91
56 74 74 86 82 89 85 87 90 94 93
72 83 89 93 90 87
67 75 74 68 80
61 78 80 83 90 95 92
58 71 82 91 94
56 82 91 87 92
70 88 83 89 96 92 88
74 76 82
62
77
70 85
68
65 65
69 88 92
71 82 79
69
56
77
Figure A4: The iterations of Model Zoo are visualized for the Split-miniImagenet dataset for 20 rounds, with 5
tasks selected in every iteration of Model Zoo. Red elements are tasks that were selected by boosting in that
particularround. Weobservethattheaccuracyofmosttasksimprovesovertherounds,whichindicatestheutility
of Model Zoo-like training scheme This plot also indicates that Model Zoo can improve the per-task accuracy on
nearly all tasks. The model is trained for only a single-epch per boosting round.
InordertounderstandhowtheaccuracyofModelZooevolvesonalltasksasafunctionoftheepisodes,
we created Fig. A4. This is a very insightful picture and we can draw the following conclusions from
it.
(i)The accuracy along the diagonal of most tasks increases along the row, i.e., across episodes.
Only for a few tasks like Food Container, the accuracy drops in later episodes. Note that we
also see from Fig. A1 that Food Container is a task that is best trained in isolation because it
leads to deterioration of accuracy when trained with essentially any other task.
(ii)Thereis strongbackwardtransfer throughoutthedataset, i.e.,the accuracyofa taskshown
in earlier rounds increases, as later synergistic tasks are shown to the learner.
(iii)Wealsoseestrongforwardtransfer. Roughlyspeaking,inthesecondhalfoftherows,the
tasks already have a good initial accuracy.
WeadvocatethatsuchplotsshouldbemadefordiÔ¨Äerentcontinuallearningalgorithmstoobtaina
precise picture of the amount of forward and backward transfer.
20

--- PAGE 21 ---
B.4 B/a.pc/s.pc/e.pc/l.pc/i.pc/n.pc/e.pc /p.pc/e.pc/r.pc/f.pc/o.pc/r.pc/m.pc/a.pc/n.pc/c.pc/e.pc /o.pc/f.pc /i.pc/s.pc/o.pc/l.pc/a.pc/t.pc/e.pc/d.pc /t.pc/r.pc/a.pc/i.pc/n.pc/i.pc/n.pc/g.pc /o.pc/n.pc C/o.pc/a.pc/r.pc/s.pc/e.pc-CIFAR100
Aq. Mammals
Electrical Devices
Fish
Flowers
Food Container
Fruits and Veggies
Household Furniture
Insects
Invertebrates
Large Carnivores
Man-made Outdoor
Med. Mammals
Natural Outdoor
Omni-Herbivores
People
Reptiles
Small Mammals
Trees
Vehicles 1
Vehicles 2
Task0255075100Accuracy51.768.8
64.5 65.169.876.0
65.6 65.7
61.372.876.674.578.4
63.2
37.754.252.255.872.480.4Isolated Accuracies (100 samples/label)
Aq. Mammals
Electrical Devices
Fish
Flowers
Food Container
Fruits and Veggies
Household Furniture
Insects
Invertebrates
Large Carnivores
Man-made Outdoor
Med. Mammals
Natural Outdoor
Omni-Herbivores
People
Reptiles
Small Mammals
Trees
Vehicles 1
Vehicles 2
Task0255075100Accuracy67.687.0
75.082.2 82.885.4
81.283.2 83.286.687.8 88.286.2
80.8
52.474.8
71.874.691.092.6Isolated Accuracies (500 samples/label)
Figure A5: Per-task accuracies of Isolated on the Coarse-CIFAR100 dataset for two cases, one with 100
samples/class (top) and another with all 500 samples/class (bottom). Two points are very important to note here.
First,thereisalargeimprovementinthetwoaccuraciesforalltaskswhenthelearnerhasaccesstomoresamples.
Second, diÔ¨Äerent tasks have very diÔ¨Äerent accuracies when trained in isolation (using the same WRN-16-4
model). ThisindicatesthatdiÔ¨Äerenttasks areverydiÔ¨Äerentintermshow hardtheyare,forsometasks suchas
People, thebaseaccuracy ofthe modelis quitelow andonemust havelots ofsamples inorderto performwell.
A lot of other multi-task learning datasets, e.g., derivatives of MNIST (or even CIFAR10 to an extent) are unlike
Coarse-CIFAR100 in this respect.
21

--- PAGE 22 ---
B.5 S/i.pc/n.pc/g.pc/l.pc/e.pc E/p.pc/o.pc/c.pc/h.pc M/e.pc/t.pc/r.pc/i.pc/c.pc/s.pc
We obtain metrics from publicly available implementations of a few diÔ¨Äerent continual learning
algorithms, which are shown in Tables A1 and A2. We see that Model Zoo and its variants uniformly
have essentially no forgetting and good forward transfer. The average per-task accuracy is also higher
thanexistingmethodsonthesedatasets. Thesetablesshowresultsforsingle-epochtraining(tobe
consistent with the implementation of these existing methods).
Method Avg. Accuracy Forgetting Forward
SGD 34.52 19.88 53.30
EWC 34.71 18.60 52.19
AGEM 37.23 16.96 52.72
ER 41.36 14.29 54.87
Stable-SGD 37.27 12.07 48.43
TAG 43.33 12.39 55.1
Isolated-small 58.719 0.058.71
Model Zoo-small 60.3 0.370 59.13
Isolated-large 41.28 0.041.28
Model Zoo-large 46.98 0.38 44.43
Table A1: Single Epoch continual learning metrics on Coarse-CIFAR100
Method Avg. Accuracy Forgetting Forward
SGD 46.69 16.653 62.35
EWC 47.93 14.26 61.34
AGEM 51.86 10.102 61.13
ER 55.41 9.52 64.03
Stable-SGD 49.28 9.76 57.79
TAG 58.38 5.15 63.00
Isolated-small 65.8 0.0 65.8
Model Zoo-small 81.049 1.278 66.57
Isolated-large 40.2 0.040.25
Model Zoo-large 64.12 0.27 48.34
Table A2: Single Epoch continual learning metrics on Split-MinImagenet
B.6 T/r.pc/a.pc/c.pc/k.pc/i.pc/n.pc/g.pc I/n.pc/d.pc/i.pc/v.pc/i.pc/d.pc/u.pc/a.pc/l.pc T/a.pc/s.pc/k.pc A/c.pc/c.pc/u.pc/r.pc/a.pc/c.pc/i.pc/e.pc/s.pc
We next study how the individual per-task accuracy evolves on diÔ¨Äerent datasets. The following
Ô¨ÅguresareextendedversionsoftherightpanelofFig.1. Weseethattheaccuracyofalltasksincreases
with successive episodes. This is quite uncommon for continual learning methods and indicates
that Model Zoo essentially does not suÔ¨Äer from catastrophic forgetting. We have also juxtaposed
the corresponding curves of the single-epoch setting with the multi-epoch training in Model Zoo;
we would like to demonstrate the dramatic gap in the accuracy of these problem settings. Even if
single-epoch variant of Model Zoo also does not forget (its accuracy is much better than existing
continuallearningmethods), themulti-epochvarianthas muchhigheraccuracyfor everytask. This
indicates that continual learning algorithms should also focus on per-task accuracy in addition to
mitigatingforgetting,iftheyaretobeperformant. TheperformanceofModelZooisevidencethat
we can build eÔ¨Äective continual learning methods that do not forget.
22

--- PAGE 23 ---
5 10 15 20
Number of Tasks0255075100Task Accuracy (%)
Isolated Multi Epoch Single Epoch
Aq. Mammals
Fish
Flowers
Food ContainerFruits and Veggies
Electrical Devices
Household Furniture
InsectsLarge Carnivores
Man-made Outdoor
Natural Outdoor
Omni-HerbivoresMed. Mammals
Invertebrates
People
ReptilesSmall Mammals
Trees
Vehicles 1
Vehicles 2Individual Task Accuracies on Coarse-CIFAR100Figure A6: Evolution of task accuracy on Coarse-CIFAR100
5 10 15 20
Number of Tasks5060708090100Task Accuracy (%)
IsolatedMulti Epoch Single Epoch
Task1
Task2
Task3
Task4Task5
Task6
Task7
Task8Task9
Task10
Task11
Task12Task13
Task14
Task15
Task16Task17
Task18
Task19
Task20Individual Task Accuracies on Split-CIFAR100
Figure A7: Evolution of task accuracy on Split-CIFAR100
23

--- PAGE 24 ---
5 10 15 20
Number of Tasks0255075100Task Accuracy (%)
IsolatedMulti Epoch Single Epoch
Task1
Task2
Task3
Task4Task5
Task6
Task7
Task8Task9
Task10
Task11
Task12Task13
Task14
Task15
Task16Task17
Task18
Task19
Task20Individual Task Accuracies on Split-miniImagenetFigure A8: Evolution of task accuracy on Split-miniImagenet
B.7 C/o.pc/m.pc/p.pc/a.pc/r.pc/i.pc/s.pc/o.pc/n.pc T/o.pc E/x.pc/i.pc/s.pc/t.pc/i.pc/n.pc/g.pc S/i.pc/n.pc/g.pc/l.pc/e.pc-E/p.pc/o.pc/c.pc/h.pc M/e.pc/t.pc/h.pc/o.pc/d.pc/s.pc
5 10 15 20
Number of Tasks3040506070Avg. Accuracy (%)SGD (35)
EWC (35)AGEM (37)
ER (41)Stable-SGD (37)
TAG (43)Isolated-small (60)
Model Zoo-small (59)Isolated-large (47)
Model Zoo-large (41)Coarse-CIFAR100
5 10 15 20
Number of Tasks40506070Avg. Accuracy (%)SGD (52)
EWC (51)AGEM (53)
ER (60)Stable-SGD (52)
TAG (63)Isolated-small (74)
Model Zoo-small (72)Isolated-large (50)
Model Zoo-large (58)Split-CIFAR100
Figure A9: This Ô¨Ågure compares Model Zoo to existing continual learning methods on the Coarse-CIFAR100
and Split-CIFAR100 datasets with respect to average task accuracy. Model Zoo and its variants are in bold,
similar to the left panel of Fig. 1 (which is for Split-miniImagenet). Isolated-small and Model Zoo-small
signiÔ¨Åcantly outperform existing methods. All methods in the Ô¨Ågure are run in the single-epoch setting.
B.8 A/d.pc/d.pc/i.pc/t.pc/i.pc/o.pc/n.pc/a.pc/l.pc C/o.pc/n.pc/t.pc/i.pc/n.pc/u.pc/a.pc/l.pc L/e.pc/a.pc/r.pc/n.pc/i.pc/n.pc/g.pc E/x.pc/p.pc/e.pc/r.pc/i.pc/m.pc/e.pc/n.pc/t.pc/s.pc /o.pc/n.pc 100 /s.pc/a.pc/m.pc/p.pc/l.pc/e.pc/s.pc//l.pc/a.pc/b.pc/e.pc/l.pc
We also performed continual learning experiments with 100 samples/class in Table A3. We Ô¨Ånd that
ModelZooobtainsanaccuracythatliesinbetweenthoseofIsolatedandtheapproximateupperbound
givenbyMulti-Head(multi-tasklearning). Doingsoindicatesstrongabilityofthelearnerfor both
forwardandbackwardtransfer. Insomecases,thecontinuallearnerevenoutperformsMulti-Head
trained on all tasks together.
24

--- PAGE 25 ---
Dataset Isolated Multi-Head (multi-task) Model Zoo
Rotated-MNIST 98.170.24 98.470.1898.440.17
Split-MNIST 97.11 1.21 99.470.0898.980.51
Permuted-MNIST 84.591.65 86.361.1586.041.68
Split-CIFAR10 82.09 0.76 85.730.6084.170.60
Split-CIFAR100 80.040.44 87.930.5086.270.19
Coarse-CIFAR100 65.34 0.41 69.050.3866.806.27
TableA3: Averageper-taskaccuracy(%)attheendofallepisodesusing100samples/class,bootstrappedacross
5 datasets (mean std. dev.). Model Zoo performs better than Isolated on all problems even if tasks are shown
sequentially.
1 2 3 4 5
Number of Tasks9092.59597.5100Accuracy (%)
MNIST-01 (100) MNIST-23 (100) MNIST-45 (98) MNIST-67 (100) MNIST-89 (98)Split-MNIST
1 2 3 4 5
Number of Tasks9092.59597.5100Accuracy (%)
Rot-MNIST-0 (98) Rot-MNIST-10 (98) Rot-MNIST-20 (98) Rot-MNIST-30 (98) Rot-MNIST-40 (98)Rot-MNIST
1 2 3 4 5
Number of Tasks708090100Accuracy (%)
P-MNIST-1 (98) P-MNIST-2 (87) P-MNIST-3 (85) P-MNIST-4 (86) P-MNIST-5 (81)Permuted-MNIST
1 2 3 4 5
Number of Tasks708090100Accuracy (%)
CIFAR10-01 (90) CIFAR10-23 (73) CIFAR10-45 (81) CIFAR10-67 (92) CIFAR10-89 (86)Split-CIFAR10
Figure A10: Per-task validation accuracy as a function of the number of episodes of continual learning for
problemsusing variants ofCIFAR10 andMNISTdatasets usingModel Zoo. Each taskhas 100samples/class.
X-markersdenoteaccuracyofIsolatedonthenewtask. Weseebothforwardtransfer(ModelZoooftenstarts
with a higher accuracy than Isolated) and backward transfer (accuracy of some past tasks improves in later
episodes). For problems like Permuted-MNIST and Rotated-MNIST, there is little forward or backward transfer.
Wenextvisualizetheevolutionoftheper-tasktestaccuracyforvariousdatasetsinFig.A10. This
is a qualitative way to investigate forward and backward transfer in the learner. Forward transfer
is positive if the accuracy of a newly introduced task in a particular episode is higher than what it
wouldbeifthetaskweretrainedinisolation. Backwardtransferispositiveifsuccessiveepisodesand
tasks result in an increase in the accuracy of tasks that were introduced earlier in continual learning.
Both Appendix B.6 and Fig. A10 consistently show non-trivial forward and backward transfer.
25

--- PAGE 26 ---
B.9 M/o.pc/d.pc/e.pc/l.pc Z/o.pc/o.pc /w.pc/i.pc/t.pc/h.pc U/n.pc/i.pc/f.pc/o.pc/r.pc/m.pc /s.pc/a.pc/m.pc/p.pc/l.pc/i.pc/n.pc/g.pc
Ateachroundofboosting,ModelZoosamplestasksaccordingtoequation(8)i.e.,taskswithhigh
lossunderthecurrentensemblehaveahigherprobabilityofbeingselectedinthenextround. Tostudy
the importance of this heuristic, we compare Model Zoo to a variant called Model Zoo (uniform).
Model Zoo (uniform) samples uniformly over all seen tasks for each round, as opposed to using
equation (8).
TableA4 comparesthe accuracyof ModelZoo andModel Zoo(uniform) onthe Coarse-CIFAR100
dataset. Model Zoo is marginallybetter than Model Zoo (uniform) indicating thatusing the training
loss is a cheap proxy for splitting the capacity amongst related tasks. At the same time, this also
indicates that a better measure of task-distances can further improve performance.
Method Avg. Accuracy
Model Zoo 84.27
Model Zoo (uniform) 83.60
Table A4: Comparison of accuracies on the Coarse-CIFAR100 dataset
C P/r.pc/o.pc/o.pc/f.pc/s.pc
Proof of Theorem 2 . From the deÔ¨Ånition of ijrelatedness for tasks, we have
cE1=i1
Pi(h)EP1(h;h
i)
=EP1(h) EP1(h
i;h
1):
foranyi;jnandh2H. Letusdenote (i)=i1. Wecansumover i2f1;:::;kganddivideby
kto get
EP1(h)1
kkX
i=1EP1(h
(i)) +c
kkX
i=1E1=(i)
P(i)(h):
The Ô¨Årst term is a discrepancy term that measures how distinct diÔ¨Äerent tasks are as measured by
the probability of the disagreement of their individual hypotheses h
(i)with that ofh
1under samples
drawnfromtask P1. Weneedtoboundthesecondtermontheright-handsidetoproveTheorem2.
We have
1
kkX
i=1E1=(i)
P(i)(h)1
kkX
i=1E1=max
P(i)(h)
=1
kkX
i=1(ePi(h) ePi(h
i))1=max
1
kkX
i=1e1=max
Pi(h)e1=max
P(h):
where the Ô¨Ånal step involves Jensen‚Äôs inequality and P= 1=kPk
i=1P(i). This is the population risk
of a hypothesis hon the mixture distribution Pand by uniform convergence, we can bound it as
e1=max
P(h) 
eS(h) +c0D log
km1=2!1=max
for anyh2H, in particular ^hk, with probability 1 . Putting it all together we have:
26

--- PAGE 27 ---
EP1(h)1
kkX
i=1EP1(h
(i)) +c
kkX
i=1E1=(i)
P(i)(h)
1
kkX
i=1EP1(h
(i)) +c
k 
eS(h) +c0D log
km1=2!1=max
D F/r.pc/e.pc/q.pc/u.pc/e.pc/n.pc/t.pc/l.pc/y.pc /a.pc/s.pc/k.pc/e.pc/d.pc /q.pc/u.pc/e.pc/s.pc/t.pc/i.pc/o.pc/n.pc/s.pc (FAQ/s.pc)
1.Why do you consider the setting with unlimited replay?
As mentioned in ¬ß6, we would like to ground the practice of continual learning. Our
investigationisinspiredbytheexistingworkoncontinuallearningandwiththispaperwe
seektoencouragefutureworkstofocustheirinvestigationsonkeydesiderataofcontinual
learning, namely per-task accuracy and forward-backward transfer.
Withthisgoal,wearemotivatedbyourresultsinTheorem2thatÔ¨Åttingasinglemodelon
asetoftasksisfundamentallylimitinginperformanceduetocompetitionbetweentasks,
this problemis only exacerbated byintroducing the taskssequentially. Wehavedeveloped
a general method named Model Zoo that, although designed for unlimited replay, can be
executed in any of the standard continual learning settings. Our experiments show that
Model Zoo signiÔ¨Åcantly outperforms existing methods in all of these settings, including
problem settings with no replay.
We allow Model Zoo to revisit past data and grow its capacity iteratively in order to get
to the heart of the problem of learning multiple tasks sequentially. In our view, if we can
demonstrate eÔ¨Äective continual learning without forgetting at least in this setting, it will
provideagoodfoundationtobuildmethodsthatconformtothestricterproblemformulations.
We believe that such a foundation is needed today if we are to advance the practice of
continual learning. Let us explain why with an example. The simplest ‚Äúbaseline‚Äù algorithm
namedIsolatedinourwork,surprisinglyoutperformsallexistingcontinuallearningmethods,
without performing any data replay, or leveraging data from multiple tasks. An upper bound
forperformanceofacontinuallearneristheaccuracyobtainedbyamulti-task learnerthat
has access to all tasks before training. We argue that a good continual learner‚Äôs performance
should lie in between the above two: it should be‚Äîat least‚Äìcomparable to training the task
inisolation, andasclosetothe performanceofthemulti-task learneraspossible. The fact
that existing methods perform much poorly than even Isolated indicates that we need to
thoroughlyinvestigatethetradeoÔ¨Ästhatthesemethodsmake,e.g.,whilethesingleepoch
setting helps mitigate forgetting, it has quite poor accuracy.
In short, we would like to argue that before we design new sophisticated methods for
continual learning, we should take a step back and evaluate what simple methods can do
and ascertain some level of baseline performance, so that we have a sound benchmark to
compare the sophisticated method against. This is our rationale for considering the problem
setting with unlimited replay. We would also like to emphasize that Model Zoo is a
legitimate continual learnerbecause it gets access to eachtask sequentially, and has a
Ô¨Åxed computationalbudget at eachepisode. Foramulti-tasklearner,thecomputational
complexity scales with the number of tasks.
2.Whydoyoucallitcontinuallearning,insteadof,say,incrementalorlifelonglearning?
Thecurrentliteratureisquiteinconclusiveabouttheformaldistinctionbetweencontinual,
incremental and lifelong learning. We have chosen to call our problem ‚Äúcontinual learning‚Äù
and, by that, we simply mean that the learner gets access to tasks sequentially instead of
having access to all tasks before training begins.
3.Whyareyounotusingthesameneuralarchitecturesasthoseintheexistingliterature?
Perhapsthemethodsinthispaperworkbetterbecauseyouusealarger/diÔ¨Äerentneural
architecture.
Weuseasmalldeepnetwork(WRN-16-4with3.6Mweights)forallourexperiments. In
27

--- PAGE 28 ---
particular, this is smaller than the Resnet-12 or Resnet-18 architectures that are used in a
numberofcontinuallearningexperiments(seeKaushiketal.(2021))andtheModelZoo
has a comparable number of weights. The exceptional performance of Model Zoo indicates
that these observations indicate that the signiÔ¨Åcant gains in accuracy of Model Zoo are not
simplyaresultofusingalargermodel. Wealsodemonstrateresultsoncontinuallearning
with a much smaller model, a CNN with 0.12M weights (which entails that Model Zoo has
about 2.42M weights). This is an extremely small model, and even this model, under all
problem settings, improves the accuracy of continual learning over existing methods.
4.Why not compare Model Zoo to ensemble versions of other methods?
We compare the performance of Model Zoo with ensemble versions of Isolated in Fig. 4.
WeobservethatModelZooperformsbetterthananensembleofIsolatedmodels. Wedid
notcompareagainstensemblevariantsofexistingcontinuallearningmethodsbecauseas
ourresultsshowinmultipleplaces,IsolatedsigniÔ¨Åcantlyoutperformsthestateoftheartasa
continuallearner. WethereforeexpectthatModelZoowillalsooutperformensemblesof
existing methods.
5.Boosting is not novel.
Wedonotclaimanynoveltyindevelopingboostingandmoreoverourmethodisonlyloosely
inspiredbyit. ThekeypropertyofModelZoothatmakesiteÔ¨Äectiveistheabilitytosplit
the capacity of the learner across diÔ¨Äerent sets of tasks, the ones that are chosen at each
round. ThisentailsthattheimplementationofModelZooissimilartothatofboosting-based
algorithms such as AdaBoost, but that is the extent of the similarity between the two. In
particular,ModelZooonlyusesthemodelsthatweretrainedonaparticulartaskinorder
to make predictions for it. Unlike AdaBoost which combines all the weak-learners using
speciÔ¨Åcweights,wesimplyaveragethepredictionsofallmodelstrainedoneachtask. To
emphasize, boosting is not novel, but the ability of Model Zoo to split learning capacity
across multiple models, one from each round, trained on a set of tasks, isnovel.
6.Identifying that tasks compete is not novel.
See ¬ß6 and the references in ¬ß2.1. The fact that tasks compete with each other is broadly
appreciated‚Äìif not rigorously studied‚Äìin the theoretical machine learning literature. It is
also appreciated broadly under the name of catastrophic forgetting in continual learning.
Theorem2elucidatesthiscompetitionandshows,togetherwithFig.2,thatitcanbequite
non-trivial. Even ifsometaskscompete, i.e.,ahypothesis thatisoptimal foroneperforms
poorlyontheother,theymaybeneÔ¨Åteachotherifwehaveaccesstolotsofsamplesfrom
eachtask. AneÔ¨Äectivewaytoresolvethiscompetitionhasbeenmissing. ModelZooisa
simple and eÔ¨Äective framework to tackle task competition; such a mechanism, and certainly
its use for continual learning, is novel to our knowledge.
7.Why does the rate of convergence in Theorem 2 depend upon max, this seems quite
ineÔ¨Écient.
The convergence rate in Theorem 2 which depends on maxindeed seems pessimistic if
onechoosesabadsetoftaskstotraintogether. Butthismaybeafundamentallimitation
ofnon-adaptivemethods,e.g.,thatpooldatafromalltaskstogethertocompute ^hk. Ifthe
learner uses adaptive methods, e.g., if it has access to ijand iteratively restricts the search
space at iteration kto only consider hypotheses that achieve a low empirical risk ^eS(i)on
all tasks closer than (k), then as (Hanneke and Kpotufe, 2020) shows, we can get better
convergence rates if all tasks have the same optimal hypothesis. Let us note that we have
chosensomedrasticinequalitiesinAppendixCinordertoelucidatethemainpoint,andit
may be possible to improve upon the rate.
8.Can you give some intuition for the transfer exponent?
The transfer exponent discussed in (5) is inspired by the work of Hanneke and Kpotufe
(2020) and is deÔ¨Åned by the smallest value such that
cE1=ij
Pi(h)EPj(h;h
i) =EPj(h) +ePj(h
j) ePj(h
i)
for allh2H. This should be understood as a measure of similarity between tasks that
incorporates properties of the hypothesis space. A small value of ij1suggests that
minimizingtheexcessriskontask Pi(theleft-handside)isagoodstrategyifwewantto
minimize the excess risk on task Pj(the right-hand side). But there may be instances when
28

--- PAGE 29 ---
we can only reduce the left hand-side up to an additive term
ePj(h
j) ePj(h
i)
thatmaybenon-zero(orlarge)iftheoptimalhypotheses h
jandh
iperformverydiÔ¨Äerentlyon
samplesfrom Pj. Mathematically, ijisseenastherateofconvergenceoftheconcentration
term in Theorem 2 if samples from Piare used to select a hypothesis for Pj; larger the
transfer exponent, more ineÔ¨Écient these samples, even if this additive term is zero.
29

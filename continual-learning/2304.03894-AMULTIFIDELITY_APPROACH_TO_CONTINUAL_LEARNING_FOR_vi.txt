# PHƯƠNG PHÁP ĐA ĐỘ TIN CẬY CHO HỌC LIÊN TỤC ÁP DỤNG CHO CÁC HỆ THỐNG VẬT LÝ

Amanda Howard, Yucheng Fu, và Panos Stinis
Bộ phận Tính toán Tiên tiến, Toán học và Dữ liệu
Phòng thí nghiệm Quốc gia Pacific Northwest
Richland, WA 99354
amanda.howard@pnnl.gov
13 tháng 2, 2024

TÓM TẮT
Chúng tôi giới thiệu một phương pháp học liên tục mới dựa trên mạng nơ-ron sâu đa độ tin cậy. Phương pháp này học mối tương quan giữa đầu ra của các mô hình đã được huấn luyện trước đó và đầu ra mong muốn của mô hình trên tập dữ liệu huấn luyện hiện tại, giới hạn quên thảm khốc. Riêng lẻ, phương pháp học liên tục đa độ tin cậy cho thấy kết quả mạnh mẽ giới hạn việc quên qua nhiều tập dữ liệu. Ngoài ra, chúng tôi chỉ ra rằng phương pháp đa độ tin cậy có thể được kết hợp với các phương pháp học liên tục hiện có, bao gồm phát lại và khớp thần kinh nhận thức bộ nhớ, để tiếp tục giới hạn quên thảm khốc. Phương pháp học liên tục được đề xuất đặc biệt phù hợp cho các bài toán vật lý nơi dữ liệu thỏa mãn các định luật vật lý giống nhau trên mỗi miền, hoặc cho mạng nơ-ron thông tin vật lý, vì trong những trường hợp này chúng ta kỳ vọng có mối tương quan mạnh giữa đầu ra của mô hình trước và mô hình trên miền huấn luyện hiện tại.

1 Giới thiệu

Trong nhiều ứng dụng thực tế của máy học, dữ liệu được nhận tuần tự hoặc trong các tập dữ liệu rời rạc. Khi được sử dụng làm dữ liệu huấn luyện, thông tin mới nhận được về hệ thống đòi hỏi việc huấn luyện lại hoàn toàn một mạng nơ-ron cho trước. Nhiều nghiên cứu gần đây đã tập trung vào cách thay vào đó kết hợp dữ liệu huấn luyện mới nhận được vào mô hình máy học mà không cần huấn luyện lại với toàn bộ tập dữ liệu và không quên mô hình đã học trước đó. Quá trình này được gọi là học liên tục [1]. Một mục tiêu chính trong học liên tục là giới hạn quên thảm khốc, hoặc đột ngột và hoàn toàn quên dữ liệu huấn luyện trước đó.

Nhiều phương pháp đã được đề xuất để giới hạn việc quên trong học liên tục. Trong phát lại (rehearsal), một tập con của tập huấn luyện từ các vùng đã được huấn luyện trước đó được sử dụng trong việc huấn luyện các mô hình tiếp theo, vì vậy phương pháp có thể giới hạn việc quên bằng cách đánh giá lại trên các vùng trước đó [2]. Tuy nhiên, phát lại đòi hỏi quyền truy cập vào các tập dữ liệu huấn luyện đã sử dụng trước đó. Điều này vừa đòi hỏi khả năng lưu trữ lớn cho các tập dữ liệu lớn, vừa cần quyền truy cập vật lý vào tập dữ liệu trước đó. Tuy nhiên, quyền riêng tư dữ liệu có thể giới hạn quyền truy cập vào các tập dữ liệu trước, vì vậy phát lại có thể không phải là một lựa chọn khả thi. Một thay thế cho phát lại là các phương pháp chính quy hóa, nơi một bộ chính quy được sử dụng để gán trọng số cho mỗi tham số trong mạng nơ-ron, đại diện cho tầm quan trọng của tham số. Sau đó, một hình phạt được áp dụng để ngăn các tham số có trọng số lớn nhất thay đổi. Nhiều phương pháp đã được đề xuất về cách tính toán trọng số quan trọng. Trong số những lựa chọn hàng đầu là Synaptic Intelligence [3], elastic weight consolidation (EWC) [4], và memory aware synapses (MAS) [5]. Nghiên cứu tiếp theo đã chỉ ra rằng MAS hoạt động trong số những phương pháp tốt nhất trong nhiều trường hợp sử dụng, và mạnh mẽ hơn đối với việc lựa chọn siêu tham số, vì vậy ở đây chúng tôi sử dụng MAS [6,7]. Cuối cùng, một loại thứ ba của các phương pháp học liên tục bao gồm những phương pháp sử dụng các mô-đun đặc thù nhiệm vụ [8], tổ hợp [9], bộ chuyển đổi [10], kiến trúc dựa trên reservoir computing [11], trọng số chậm-nhanh [12, 13] và nhiều hơn nữa.

Trong những năm gần đây, một trọng tâm nghiên cứu lớn đã tập trung vào các phương pháp máy học khoa học cho các hệ thống vật lý [14,15,16], ví dụ cơ học chất lỏng và lưu biến học [17,18,19,20], phát triển metamaterial [21,22,23], dòng chảy tốc độ cao [24], và hệ thống điện [25,26,27]. Đặc biệt, mạng nơ-ron thông tin vật lý, hay PINNs [28], cho phép biểu diễn chính xác các toán tử vi phân thông qua vi phân tự động, cho phép tìm nghiệm của các PDE mà không cần tạo lưới tường minh. Nghiên cứu về học liên tục cho PINNs còn hạn chế. Trong khi như một nỗ lực đầu tiên PINNs có thể được huấn luyện trên toàn bộ miền vì các vấn đề về thu thập dữ liệu và quyền riêng tư không áp dụng, nhiều hệ thống đã được xác định mà không thể huấn luyện PINN cho toàn bộ miền thời gian mong muốn. Ví dụ, ngay cả những ví dụ đơn giản được sử dụng trong công trình này, một con lắc và phương trình Allen-Cahn, không thể được huấn luyện bởi PINN trong thời gian dài. Nghiên cứu gần đây đã xem xét cải thiện việc huấn luyện PINNs cho các hệ thống như vậy, bao gồm ứng dụng của neural tangent kernel [29], nhưng vẫn còn nhiều việc phải làm. Công trình gần nhất mà chúng tôi biết về học liên tục với PINNS là PINNs tương thích ngược trong [30] và PINNs tăng dần (iPINNs) trong [31]. PINNs tương thích ngược huấn luyện N PINNs trên một chuỗi N miền thời gian, và trong mỗi miền mới thực thi rằng đầu ra từ PINN hiện tại thỏa mãn hàm mất mát PINN trong miền hiện tại và đầu ra của mô hình trước trên tất cả các miền trước đó. Chúng tôi lưu ý rằng công trình này khác biệt với phương pháp phát lại được áp dụng với PINNs trong công trình này, cả trong trường hợp độ tin cậy đơn và đa độ tin cậy, vì chúng tôi thực thi rằng mạng nơ-ron thứ N thỏa mãn phần dư trong tất cả các miền trước, không phải đầu ra từ mô hình trước. Trong iPINNs, PINNs được huấn luyện để thỏa mãn một chuỗi các phương trình khác nhau thông qua một mạng con cho mỗi phương trình, thay vì cùng một phương trình trong thời gian dài.

Chúng tôi sẽ giới thiệu phương pháp học liên tục đa độ tin cậy trong Phần 2. Sau đó chúng tôi sẽ chỉ ra hiệu suất của phương pháp trên các bài toán thông tin vật lý trong Phần 3 và trên các bài toán thông tin dữ liệu trong Phần 4.

2 Phương pháp học liên tục đa độ tin cậy

Chúng tôi giả định rằng chúng ta có một miền Ω, mà chúng ta chia thành N miền con Ω = ∪N i=0Ωi. Chúng ta sẽ học các mô hình tuần tự trên mỗi miền con Ωi, với mục tiêu rằng mô hình thứ i có thể cung cấp dự đoán chính xác trên miền ∪i j=0Ωj. Nghĩa là, mô hình thứ i không quên thông tin đã học trên các miền trước đó được sử dụng trong huấn luyện. Chúng tôi sẽ tập trung vào các ứng dụng cho hệ thống vật lý, nơi chúng ta có dữ liệu có sẵn hoặc kiến thức về các định luật vật lý mà hệ thống tuân theo. Chúng tôi sẽ bắt đầu phần này với một tổng quan ngắn gọn về mạng nơ-ron thông tin vật lý (PINNs), sau đó thảo luận về phương pháp học liên tục đa độ tin cậy (MFCL), và kết thúc với mô tả các phương pháp chúng tôi sử dụng để giới hạn quên thảm khốc.

2.1 Mạng nơ-ron thông tin vật lý

Trong phần này chúng tôi đưa ra một giới thiệu ngắn gọn về mạng nơ-ron thông tin vật lý độ tin cậy đơn và đa độ tin cậy (PINNs), được giới thiệu trong [28] và đã được đề cập sâu rộng cho nhiều ứng dụng liên quan [32,14]. PINNs thường được sử dụng, trong các ứng dụng này, cho các bài toán giá trị ban đầu-biên.

st+Ox[s] =0,x∈Ω, t∈[0, T] (1)
s(x, t) =g(x, t)x∈∂Ω, t∈[0, T] (2)
s(x,0) =u(x)x∈Ω (3)

nơi Ω∈RN là một miền mở, bị chặn với biên ∂Ω, g và u là các hàm cho trước, và x và t là tọa độ không gian và thời gian, tương ứng. Ox là một toán tử vi phân tổng quát đối với x. Chúng ta muốn tìm một xấp xỉ cho s(x, t) bằng một (chuỗi) mạng nơ-ron sâu với tham số γ, ký hiệu bởi sγ(x, t). Mạng nơ-ron được huấn luyện bằng cách tối thiểu hóa hàm mất mát

L(γ) =λbcLbc(γ) +λicLic(γ) +λrLr(γ) +λdataLdata(γ) (4)

nơi các chỉ số bc, ic, r, và data ký hiệu các số hạng tương ứng với điều kiện biên, điều kiện ban đầu, và phần dư, và bất kỳ dữ liệu cung cấp nào, tương ứng. Chúng ta lấy Nbc, Nic, và Nr làm kích thước batch của biên, ban đầu, và dữ liệu điểm phần dư, và ký hiệu dữ liệu huấn luyện bởi {(xi bc, ti bc),g(xi bc, ti bc)}Nbc i=0, {(xi ic),u(xi bc)}Nic i=0, và {(xi r, ti r)}Nr i=0. Các điểm collocation biên và ban đầu được lấy mẫu ngẫu nhiên đều trong các miền tương ứng của chúng. Việc lựa chọn Nr điểm phần dư sẽ được thảo luận trong Phần ??. Nếu dữ liệu đại diện cho nghiệm s có sẵn, chúng ta cũng có thể xem xét một tập dữ liệu bổ sung {(xi data, ti data),s(xi data, ti data)}Ndata i=0. Số hạng này được bao gồm để nắm bắt việc huấn luyện dựa trên dữ liệu mà chúng tôi sẽ đề cập trong Phần 4.

Các số hạng mất mát riêng lẻ được cho bởi các lỗi bình phương trung bình,

Lbc(γ) =1/Nbc ∑Nbc i=0 |sγ(xi bc, ti bc)−g(xi bc, ti bc)|2 (5)
Lic(γ) =1/Nic ∑Nic i=0 |sγ(xi ic,0)−u(xi ic)|2 (6)
Lr(γ) =1/Nr ∑Nr i=0 |rγ(xi r, ti r)|2 (7)
Ldata(γ) =1/Ndata ∑Ndata i=0 |sγ(xi data, ti data)−s(xi data, ti data)|2 (8)

nơi

rγ(x, t) =∂/∂t sγ(x, t) +Ox[sγ(xi data, ti data)]. (9)

Các tham số trọng số λbc, λic, λr, và λdata được chọn trước khi huấn luyện bởi người dùng.

PINNs đa độ tin cậy, như được sử dụng trong công trình này, được lấy cảm hứng từ [33]. Chúng tôi giả định chúng ta có một mô hình độ tin cậy thấp dưới dạng một mạng nơ-ron sâu xấp xỉ một tập dữ liệu cho trước hoặc toán tử vi phân với độ chính xác thấp. Chúng ta muốn huấn luyện hai mạng nơ-ron bổ sung để học các mối tương quan tuyến tính và phi tuyến giữa xấp xỉ độ tin cậy thấp và một xấp xỉ độ tin cậy cao hoặc dữ liệu độ tin cậy cao. Chúng tôi ký hiệu các mạng nơ-ron này là NN l cho mối tương quan tuyến tính và NN nl cho mối tương quan phi tuyến. Đầu ra sau đó là sγ(x, t) =NN nl(x, t;γ) +NN l(x, t;γ), nơi γ là tất cả các tham số có thể huấn luyện của các mạng tuyến tính và phi tuyến. Hàm mất mát bao gồm một số hạng bổ sung,

LMF(γ) =λbcLbc(γ) +λicLic(γ) +λrLr(γ) +λdataLdata(γ) +λ∑(γnl,ij)2, (10)

nơi {γnl,ij} là tập hợp tất cả các trọng số và độ lệch của mạng phi tuyến NN nl. Không có hàm kích hoạt nào được sử dụng trong NN l để dẫn đến việc học một mối tương quan tuyến tính giữa dự đoán trước và mô hình độ tin cậy cao.

2.2 Học liên tục đa độ tin cậy

Trong phương pháp MFCL, chúng tôi khai thác các mối tương quan giữa các mô hình đã được huấn luyện trước đó trên các miền trước và mô hình dự kiến trên miền hiện tại. Một cách rõ ràng, chúng tôi sử dụng mô hình trước NN i−1 như một mô hình độ tin cậy thấp cho miền Ωi. Sau đó, chúng ta học mối tương quan giữa NN i−1 trên miền Ωi và dữ liệu hoặc vật lý được cho trên miền đó. Bằng cách học một kết hợp tổng quát của các số hạng tuyến tính và phi tuyến, chúng ta có thể nắm bắt các mối tương quan phức tạp. Bởi vì phương pháp chỉ học mối tương quan giữa mô hình trước và mô hình mới, nói chung chúng ta có thể sử dụng các mạng nhỏ hơn trong mỗi miền con. Thủ tục đòi hỏi hai bước ban đầu:

1. Huấn luyện một DNN hoặc PINN (độ tin cậy đơn) trên Ω1, ký hiệu bởi NN∗(x, t;γ∗). Mạng này sẽ xấp xỉ nghiệm trong một miền đơn.
2. Huấn luyện một DNN hoặc PINN đa độ tin cậy trong Ω1, lấy làm đầu vào mô hình độ tin cậy đơn NN∗(x, t;γ∗) như một xấp xỉ độ tin cậy thấp. Mạng đa độ tin cậy ban đầu này được ký hiệu bởi NN 1(x, t;γ1)

Sau đó, cho mỗi miền bổ sung Ωi, chúng ta huấn luyện một DNN hoặc PINN đa độ tin cậy trong Ωi, ký hiệu bởi NN i(x, t;γi), lấy làm đầu vào mô hình đa độ tin cậy trước NN i−1(x, t;γi−1) như một xấp xỉ độ tin cậy thấp. Mục tiêu là để NN i(x, t;γi) cung cấp một nghiệm chính xác trên ∪i j=1Ωi, ngay cả khi dữ liệu từ Ωj, j < i, không được sử dụng trong việc huấn luyện mạng đa độ tin cậy NN i. Một sơ đồ của phương pháp được cho trong Hình 2.

Như chúng tôi sẽ chỉ ra, phương pháp MF-CL cung cấp kết quả chính xác hơn với ít quên hơn so với huấn luyện độ tin cậy đơn riêng lẻ, tuy nhiên, phương pháp có thể được cải thiện bởi một số phương pháp đã được phát triển trước đó cả để giảm quên trong học liên tục và để lựa chọn điểm collocation cho huấn luyện PINNs. Các phương pháp này được thảo luận dưới đây.

2.3 Khớp thần kinh nhận thức bộ nhớ

Khớp thần kinh nhận thức bộ nhớ (MAS) là một phương pháp học liên tục cố gắng giới hạn quên trong học liên tục bằng cách gán một trọng số quan trọng cho mỗi nơ-ron trong mạng nơ-ron. Sau đó, một số hạng phạt được thêm vào hàm mất mát để ngăn chặn các độ lệch lớn trong giá trị của các trọng số quan trọng khi các mạng tiếp theo được huấn luyện. Các trọng số quan trọng được tìm thấy bằng cách đo độ nhạy cảm của đầu ra của mạng nơ-ron NN n đối với những thay đổi trong các tham số mạng [5]. Cho mỗi trọng số và độ lệch γij trong mạng nơ-ron, chúng ta tính toán tham số trọng số quan trọng

Ωn ij=1/N ∑N k=1 |∂(ℓ2 2||NN n(xk;γ)||)/∂γij| (11)

nơi ℓ2 2 ký hiệu chuẩn ℓ2 bình phương của đầu ra của mạng nơ-ron NN n áp dụng tại xk. Hàm mất mát trong phương trình 10 sau đó được sửa đổi để đọc:

LMF,MAS (γn) =λbcLbc(γn) +λicLic(γn) +λrLr(γn) +λdataLdata(γn) +λ∑i,j(γn nl,ij)2 +λMAS∑i,jΩn−1 ij|γn ij−γn−1 ij|2 (12)

Khi áp dụng MAS cho mạng nơ-ron đa độ tin cậy, chúng ta tính toán các số hạng MAS riêng biệt:

Ωn,nl ij=1/N ∑N k=1 |∂(ℓ2 2||NNnl n(xk;γ)||)/∂γnl ij|, Ωn,l ij=1/N ∑N k=1 |∂(ℓ2 2||NNl n(xk;γ)||)/∂γl ij| (13)

nơi nl ký hiệu mạng phi tuyến và l ký hiệu mạng tuyến tính. Theo cách này, đại khái, tầm quan trọng trong các trọng số trong việc tính toán các số hạng tuyến tính và phi tuyến được tìm thấy riêng biệt, thay vì xác định tầm quan trọng trong đầu ra tổng thể của tổng các mạng. Tham số λMAS được giữ giống nhau cho các phần tuyến tính và phi tuyến.

2.4 Phát lại

Trong phát lại, một lựa chọn các điểm trong các miền đã huấn luyện trước đó, ∪n−1 i=1Ωi được chọn tại mỗi lần lặp và mất mát phần dư, Lr(γn) được đánh giá tại các điểm. Theo cách này, việc huấn luyện đa độ tin cậy vẫn thỏa mãn PDE qua các miền đã huấn luyện trước đó. Đối với PINNs, phương pháp phát lại chỉ đòi hỏi kiến thức về hình học của ∪n−1 i=1Ωi, và không phải giá trị của đầu ra của mô hình trên miền này.

2.5 Học chuyển giao

Trong tất cả các trường hợp trong công trình này, các giá trị của các tham số có thể huấn luyện trong mỗi mạng tiếp theo NN i, i≥2, được khởi tạo từ các giá trị cuối cùng của các tham số có thể huấn luyện trong mạng trước đó, NN i−1. Trong ký hiệu, γ0 i=γi−1. Phương pháp này cho phép huấn luyện nhanh hơn vì mạng không được khởi tạo ngẫu nhiên. Chúng tôi lưu ý rằng một số công trình trước đó đã tìm thấy ít quên hơn bằng cách khởi tạo mỗi mạng tiếp theo ngẫu nhiên [34], và để lại việc khám phá lựa chọn này cho công trình tương lai.

3 Huấn luyện thông tin vật lý

Trong phần này, chúng tôi đưa ra các ví dụ áp dụng học liên tục đa độ tin cậy cho mạng nơ-ron thông tin vật lý trong các trường hợp mà PINNs thất bại trong việc huấn luyện. Chúng tôi chỉ ra rằng sử dụng học liên tục trong thời gian có thể cải thiện độ chính xác của việc huấn luyện PINN cho các bài toán tích phân thời gian dài, nơi một PINN đơn lẻ không đủ. Tất cả các siêu tham số được sử dụng trong huấn luyện được đưa ra trong Phụ lục 8.

3.1 Động lực học con lắc

Trong phần này, chúng tôi xem xét con lắc trọng lực với cản từ [29]. Hệ thống được điều chỉnh bởi một ODE cho t∈[0, T]

ds1/dt=s2, (14)
ds2/dt=−(b/m)s2−(g/L)sin(s1). (15)

Các điều kiện ban đầu được cho bởi s1(0) = s2(0) = 1. Chúng ta lấy m=L= 1, b= 0.05, và g= 9.81, và chúng ta lấy T= 10.

Chúng tôi đầu tiên xem xét một PINN đơn được huấn luyện để thỏa mãn Phương trình 14 và 15 so với nghiệm chính xác trong Hình 3. Nghiệm nhanh chóng về 0, cho thấy rằng một PINN đơn không thể nắm bắt động lực thời gian dài của ngay cả hệ thống đơn giản này. Kết quả tương tự đã được chỉ ra trong [29]. Chúng tôi sẽ lưu ý rằng có những tiến bộ gần đây đã được phát triển để cải thiện việc huấn luyện PINNs cho các bài toán tích phân thời gian dài [29,35,36]. Trong phần này, chúng tôi sẽ khám phá cách học liên tục cũng có thể cho phép các nghiệm chính xác trong thời gian dài bằng cách chia các miền thời gian thành các miền con.

Chúng ta chia miền thành năm miền con, Ωi= [2(i−1),2i] và huấn luyện trên mỗi miền sử dụng cả học liên tục độ tin cậy đơn truyền thống và MF-CL, và các phương pháp SF-CL và MF-CL được tăng cường bởi phát lại và MAS. Cho mỗi trường hợp, chúng ta tính toán lỗi bình phương trung bình gốc (RMSE) của đầu ra cuối cùng NN 5 trên toàn miền, Ω = [0,10] bởi

RMSE =√(1/N ∑N j=1[NN 5(tj)−s(tj)]2), (16)

nơi s ký hiệu nghiệm chính xác. Nếu việc quên được giới hạn, nghiệm cuối cùng nên có RMSE nhỏ trên toàn miền.

Rõ ràng từ Bảng 1 rằng phát lại hoạt động tốt nhất trong cả hai trường hợp, và tốt hơn đáng kể so với bất kỳ phương pháp nào khác. Không có gì ngạc nhiên khi trường hợp SF áp dụng riêng lẻ có RMSE lớn, vì nó không có bất kỳ sự kết hợp nào của các kỹ thuật để giới hạn việc quên. Trường hợp này được chỉ ra trong Hình 4a.

Hình 5 đưa ra kết quả MAS tốt nhất cho mỗi tập các siêu tham số được xem xét, với λMAS = 100 cho độ tin cậy đơn và λMAS = 0.001 cho đa độ tin cậy. Như không có gì ngạc nhiên given RMSE nhỏ hơn, đa độ tin cậy vượt trội so với huấn luyện độ tin cậy đơn với MAS.

Như được chỉ ra trong Hình 6, trường hợp SF-phát lại có vẻ vượt trội so với trường hợp MF-phát lại. Tuy nhiên, thú vị khi nhìn vào RMSE khi chúng ta thay đổi kích thước mạng trong Bảng 2. Trong khi trường hợp MF-phát lại mạnh mẽ đối với những thay đổi trong kích thước mạng, trường hợp độ tin cậy đơn chỉ đạt được RMSE nhỏ với một kiến trúc rất cụ thể.

3.2 Phương trình Allen-Cahn

Phương trình Allen-Cahn được cho bởi

ut−c2 1uxx+ 5u3−5u= 0, t∈(0,1], x∈[−1,1] (17)
u(x,0) = x2cos(πx), x∈[−1,1] (18)
u(x, t) =u(−x, t), t∈[0,1], x=−1, x= 1 (19)
ux(x, t) =ux(−x, t), t∈[0,1], x=−1, x= 1 (20)

Chúng ta lấy c2 1= 0.0001. Phương trình Allen-Cahn nổi tiếng khó cho PINNs giải quyết bằng ứng dụng trực tiếp [37,38], xem Hình 7. Các sửa đổi của PINNs đã thành công có thể giải phương trình Allen-Cahn, bao gồm bằng cách sử dụng một mạng nơ-ron Runge-Kutta rời rạc [28], lấy mẫu thích ứng của các điểm collocation [37], và PINNs tương thích ngược [30]. Trong phần này chúng tôi chỉ ra rằng chúng ta có thể học chính xác nghiệm của phương trình Allen-Cahn bằng cách áp dụng khung học liên tục đa độ tin cậy.

Chúng ta chia miền thành bốn miền con, Ωi= [2(i−1),2i], và báo cáo RMSE tương đối của NN 4 trên toàn miền Ω. Khi các phương pháp đa độ tin cậy và độ tin cậy đơn được huấn luyện riêng lẻ, trong Hình 8, chúng có RMSE tương đối xấp xỉ bằng nhau. MAS và phát lại đều cải thiện kết quả, trong Hình 9 và 10, tương ứng. Một tóm tắt kết quả được đưa ra trong Bảng 3.

4 Huấn luyện thông tin dữ liệu

4.1 Pin

Đây là một trường hợp nơi nếu một tập dữ liệu bổ sung được thêm vào, không rõ a priori miền con nào nó nằm trong. Do đó, điều quan trọng là mô hình cuối cùng có thể dự đoán dòng điện chính xác cho toàn bộ miền mà không quên.

Để thử nghiệm, một hệ thống pin dòng chảy oxy hóa-khử vanadi (VRFB) đã được chọn để tạo ra các tập dữ liệu. Hình bên trái trong Hình 11 cho thấy một cấu hình điển hình của VRFB, bao gồm các điện cực, bộ thu dòng điện và một màng ngăn cách. Phía âm và dương có mỗi bên một bể lưu trữ để lưu trữ cặp oxy hóa-khử của V2+/V3+ và V4+/V5+, tương ứng.

Chúng tôi áp dụng phương pháp MFCL cho bài toán xác định dòng điện sạc được áp dụng từ một đường cong điện áp sạc cho trước. Để tạo ra tập dữ liệu đường cong sạc VRFB, một mô hình phân tích 2-D có hiệu quả tính toán cao đã được sử dụng [39,40]. Mô hình này hoàn toàn giải quyết vật lý kết hợp của vận chuyển loài hoạt tính, động học phản ứng điện hóa, và động lực học chất lỏng trong tế bào pin, do đó cung cấp một đại diện trung thực của hệ thống VRFB. Chi tiết thêm về mô hình và các tham số của nó có thể được tìm thấy trong [39]. Các đường cong sạc điển hình được hiển thị trong biểu đồ bên phải của Hình 11 cho năm mức dòng điện được chọn. Cho một dòng điện sạc cho trước, điện áp pin (E) được tính toán tại các giá trị trạng thái sạc (SOC) khác nhau để tạo thành đường cong sạc được sử dụng làm dữ liệu đầu vào. Dòng điện sạc được áp dụng I tạo ra đường cong sạc là đại lượng đầu ra mà chúng ta muốn dự đoán.

Chúng ta chia tập dữ liệu thành năm tập theo dòng điện sạc và huấn luyện với và không có MAS trong trường hợp độ tin cậy đơn. Các miền con là Ω1= [0.1,2), Ω2= [2,4), Ω3= [4,6), Ω4= [6,8), và Ω5= [8,9]. Các lỗi được tính toán bởi RMSE của đầu ra của NN 5 trên một tập kiểm tra được chọn từ Ω =∪5 i=1Ωi. Chúng tôi thử nghiệm hai kiến trúc mạng, một mạng rộng có hai lớp ẩn với 80 nơ-ron mỗi lớp, và một mạng sâu hơn và hẹp hơn có ba lớp ẩn với 40 nơ-ron mỗi lớp. Chúng tôi đầu tiên huấn luyện với các phương pháp độ tin cậy đơn và đa độ tin cậy riêng lẻ, xem Hình 12. Kết quả học liên tục đa độ tin cậy cho thấy ít quên hơn so với những kết quả từ học liên tục độ tin cậy đơn.

Sau đó chúng tôi xem xét tác động của việc thêm MAS. Chúng tôi xem xét các mạng hẹp và rộng với và không có chia tỷ lệ MAS, tổng cộng bốn trường hợp. Kết quả MAS đa độ tin cậy cho thấy cải thiện đáng kể, xem Hình 13. Trong Hình 14, chúng tôi so sánh hiệu suất qua giá trị của siêu tham số MAS λMAS. Chúng ta thấy rằng hiệu suất phương pháp độ tin cậy đơn mạnh mẽ, vì nó không nhạy cảm với giá trị của λMAS. Tuy nhiên, nó không rất chính xác. Mặt khác, phương pháp đa độ tin cậy có thể chính xác hơn đáng kể so với phương pháp độ tin cậy đơn cho hầu hết các giá trị của λMAS. Nhìn chung, kết quả đa độ tin cậy vượt trội đáng kể so với kết quả độ tin cậy đơn.

4.2 Tiêu thụ năng lượng

Để cung cấp một ví dụ thứ hai về học liên tục thông tin dữ liệu, chúng tôi xem xét tập dữ liệu tiêu thụ năng lượng hàng ngày quy mô thành phố từ [41]. Tập dữ liệu bao gồm việc sử dụng năng lượng hàng ngày cho ba khu vực đô thị, New York, Sacramento, và Los Angeles, cùng với dữ liệu thời tiết hàng ngày. Ba năm dữ liệu được sử dụng làm tập kiểm tra, với một năm bổ sung làm tập kiểm tra.

Việc sử dụng năng lượng phụ thuộc mạnh vào thời tiết, với việc sử dụng máy điều hòa trong những tháng ấm hơn và sưởi ấm trong những tháng mùa đông. Do đó, để cung cấp các nhiệm vụ khác nhau cho việc huấn luyện học liên tục, chúng tôi chia ba năm dữ liệu huấn luyện theo quý. Nhiệm vụ 1 có dữ liệu huấn luyện từ tháng 1 đến tháng 3, Nhiệm vụ 2 có dữ liệu huấn luyện từ tháng 4 đến tháng 6, Nhiệm vụ 3 có dữ liệu huấn luyện từ tháng 7 đến tháng 9, và Nhiệm vụ 4 có dữ liệu huấn luyện từ tháng 10 đến tháng 12. Tập kiểm tra cho tất cả các nhiệm vụ là dự đoán việc sử dụng năng lượng từ tháng 7 năm 2018 đến tháng 6 năm 2019. Một minh họa của dữ liệu kiểm tra và huấn luyện được chia thành các nhiệm vụ được đưa ra trong Hình 15.

Chúng tôi huấn luyện cả mạng độ tin cậy đơn và đa độ tin cậy với và không có MAS. Chúng tôi xem xét một dải λ∈[0.001,100]. Chúng tôi cũng so sánh với việc huấn luyện một mạng không có học liên tục. Trong trường hợp này, một DNN độ tin cậy đơn nhận tất cả dữ liệu huấn luyện từ tất cả bốn nhiệm vụ, để cố gắng dự đoán việc sử dụng năng lượng từ tháng 7 năm 2018 đến tháng 6 năm 2019. Trường hợp này phục vụ như một điểm chuẩn cho mức lỗi hợp lý mà chúng ta có thể mong đợi từ mô hình của chúng ta sử dụng học liên tục. Kết quả được chỉ ra trong Bảng 4. Chúng tôi lưu ý rằng trong tất cả các trường hợp, phương pháp học liên tục đa độ tin cậy vượt trội so với học liên tục độ tin cậy đơn. Bao gồm MAS không cải thiện kết quả, như được chỉ ra trong Hình 16. Các phương pháp học liên tục hoạt động tệ hơn so với trường hợp không có học liên tục, điều này được mong đợi vì chúng không bao giờ có quyền truy cập vào tất cả dữ liệu huấn luyện đồng thời. Một so sánh RMSE cho mỗi giá trị λMAS được kiểm tra được đưa ra trong Hình 17. Chúng tôi lưu ý rằng nhìn chung, phương pháp đa độ tin cậy với MAS mạnh mẽ hơn so với huấn luyện độ tin cậy đơn với MAS, dẫn đến RMSE nhỏ hơn qua một dải λMAS.

5 Thảo luận và công trình tương lai

Chúng tôi đã giới thiệu một phương pháp học liên tục mới dựa trên mạng nơ-ron sâu đa độ tin cậy. Tiền đề của phương pháp là sự tồn tại của các mối tương quan giữa đầu ra của các mô hình đã được huấn luyện trước đó và đầu ra mong muốn của mô hình trên tập dữ liệu huấn luyện hiện tại. Việc khám phá và sử dụng các mối tương quan này có thể giới hạn quên thảm khốc. Riêng lẻ, phương pháp học liên tục đa độ tin cậy đã chỉ ra sự mạnh mẽ và giới hạn việc quên qua nhiều tập dữ liệu cho các ví dụ huấn luyện thông tin vật lý và dựa trên dữ liệu. Ngoài ra, nó có thể được kết hợp với các phương pháp học liên tục hiện có, bao gồm phát lại và khớp thần kinh nhận thức bộ nhớ (MAS), để tiếp tục giới hạn quên thảm khốc.

Phương pháp học liên tục được đề xuất đặc biệt phù hợp cho các bài toán vật lý nơi dữ liệu thỏa mãn các định luật vật lý giống nhau trên mỗi miền, hoặc cho một mạng nơ-ron thông tin vật lý, vì trong những trường hợp này chúng ta kỳ vọng có mối tương quan mạnh giữa đầu ra của mô hình trước và mô hình trên miền huấn luyện hiện tại. Như một kết quả của việc khai thác mối tương quan giữa dữ liệu trong các miền khác nhau thay vì huấn luyện từ đầu cho mỗi miền, phương pháp có thể đủ khả năng tiếp tục học trong các miền mới sử dụng các mạng nhỏ hơn. Cụ thể, độ chính xác huấn luyện của nó mạnh mẽ hơn đối với kích thước của mạng được sử dụng trong miền mới. Điều này có thể dẫn đến tiết kiệm tính toán trong cả huấn luyện và suy luận. Phương pháp đặc biệt phù hợp cho các tình huống nơi mối quan tâm về quyền riêng tư có thể giới hạn quyền truy cập vào các tập dữ liệu trước. Nó cũng có thể cung cấp các khả năng mới trong lĩnh vực học liên kết bằng cách cho phép thiết kế các thuật toán mới để xử lý dữ liệu cảm biến theo cách phân tán. Các chủ đề này đang được điều tra và kết quả sẽ được báo cáo trong một ấn phẩm tương lai.

6 Tính sẵn có của dữ liệu

Tất cả mã và dữ liệu cần thiết để tái tạo các kết quả này sẽ được cung cấp tại https://github.com/pnnl/Multifidelity_continual_learning/.

7 Lời cảm ơn

Nghiên cứu này được hỗ trợ bởi Sáng kiến Vật liệu Lưu trữ Năng lượng (ESMI), dưới Chương trình Nghiên cứu và Phát triển Được Chỉ đạo bởi Phòng thí nghiệm (LDRD) tại Phòng thí nghiệm Quốc gia Pacific Northwest (PNNL). Công việc tính toán được thực hiện sử dụng Tính toán Thể chế PNNL tại Phòng thí nghiệm Quốc gia Pacific Northwest. PNNL là một phòng thí nghiệm quốc gia đa chương trình được vận hành cho Bộ Năng lượng Hoa Kỳ (DOE) bởi Viện Battelle Memorial dưới Hợp đồng số DE-AC05-76RL01830.

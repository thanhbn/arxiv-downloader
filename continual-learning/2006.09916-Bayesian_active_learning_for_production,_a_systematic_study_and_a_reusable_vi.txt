Học tích cực Bayesian cho sản xuất, một nghiên cứu hệ thống và thư viện có thể tái sử dụng

Parmida Atighehchian* 1Frédéric Branchaud-Charron* 1Alexandre Lacoste1

Hình 1. Kết quả baseline trên CIFAR10 sử dụng MC-Dropout và VGG-16. Trên tập dữ liệu học thuật, cả hai kỹ thuật học tích cực đều có khả năng cạnh tranh.

Tóm tắt
Học tích cực có khả năng giảm lượng công việc gán nhãn bằng cách sử dụng mô hình học máy để truy vấn người dùng về các đầu vào cụ thể. Mặc dù có nhiều bài báo về các kỹ thuật học tích cực mới, những kỹ thuật này hiếm khi thỏa mãn các ràng buộc của một dự án thực tế. Trong bài báo này, chúng tôi phân tích những nhược điểm chính của các kỹ thuật học tích cực hiện tại và chúng tôi trình bày các phương pháp để giảm thiểu chúng. Chúng tôi thực hiện một nghiên cứu hệ thống về tác động của những vấn đề phổ biến nhất của các tập dữ liệu thực tế đối với quá trình học tích cực sâu: hội tụ mô hình, lỗi chú thích và mất cân bằng tập dữ liệu. Chúng tôi đưa ra hai kỹ thuật có thể tăng tốc vòng lặp học tích cực như lấy mẫu không chắc chắn một phần và kích thước truy vấn lớn hơn. Cuối cùng, chúng tôi trình bày thư viện học tích cực Bayesian mã nguồn mở của chúng tôi, BaaL.

*Đóng góp bằng nhau1Element AI, Montréal, Canada. Liên hệ: Frédéric Branchaud-Charron <frederic.branchaud-charron@elementai.com>.

Được trình bày tại Hội thảo ICML 2020 về Tính không chắc chắn và Bền vững trong Học sâu. Bản quyền 2020 thuộc về (các) tác giả.

1. Giới thiệu
Lượng dữ liệu sẵn có cho học máy đã bùng nổ trong những năm gần đây. Tuy nhiên, để dữ liệu được sử dụng cho các mô hình học sâu, việc gán nhãn thường là một bước bắt buộc. Một vấn đề phổ biến khi gán nhãn các tập dữ liệu mới là nỗ lực của con người cần thiết để thực hiện việc chú thích. Đặc biệt, các nhiệm vụ đòi hỏi kiến thức chuyên môn riêng như hình ảnh y tế, rất tốn kém để chú thích. Để giải quyết điều này, học tích cực (AL) đã được đề xuất để chỉ gán nhãn tập lõi các quan sát hữu ích cho việc huấn luyện.

Mặc dù lĩnh vực học tích cực bao gồm nhiều phương pháp (Kirsch et al., 2019; Tsymbalov et al., 2019; Beluch et al., 2018; Maddox et al., 2019), những phương pháp này thường không thể mở rộng cho các tập dữ liệu lớn hoặc quá chậm để được sử dụng trong môi trường thực tế hơn, ví dụ như trong thiết lập sản xuất. Đặc biệt, học tích cực áp dụng cho hình ảnh hoặc văn bản đòi hỏi việc sử dụng các mô hình học sâu mà chậm để huấn luyện và bản thân chúng đòi hỏi một lượng dữ liệu khổng lồ đáng chú ý để có hiệu quả (Deng et al., 2009; Abu-El-Haija et al., 2016).

Hơn nữa, các mô hình học sâu đòi hỏi các siêu tham số được điều chỉnh cẩn thận để có hiệu quả. Trong môi trường nghiên cứu, người ta có thể tinh chỉnh và thực hiện tìm kiếm siêu tham số để tìm ra sự kết hợp tối ưu mang lại sự giảm thiểu lớn nhất trong nỗ lực gán nhãn. Trong thiết lập thực tế, các siêu tham số được đặt ngay từ đầu mà không có gì bảo đảm cho kết quả.

Cuối cùng, trong thiết lập thực tế, dữ liệu thường không được làm sạch cũng như không cân bằng. Đặc biệt, các nghiên cứu đã chỉ ra rằng con người còn lâu mới hoàn hảo khi gán nhãn và vấn đề còn tồi tệ hơn khi sử dụng cộng đồng nguồn (Ipeirotis et al., 2010; Allahbakhsh et al., 2013).

Đóng góp của chúng tôi có ba mặt. Chúng tôi thực hiện một nghiên cứu hệ thống về tác động của những bệnh lý phổ biến nhất được tìm thấy trong các tập dữ liệu thực tế đối với học tích cực. Thứ hai, chúng tôi đề xuất một số kỹ thuật làm cho học tích cực phù hợp cho sản xuất. Cuối cùng, chúng tôi trình bày một nghiên cứu trường hợp sử dụng học tích cực trên một tập dữ liệu thực tế.

Ngoài ra, chúng tôi trình bày thư viện học tích cực Bayesian có sẵn miễn phí của chúng tôi, BaaL1 cung cấp tất cả các thiết lập và công cụ cần thiết cho các thí nghiệm học tích cực ở bất kỳ quy mô nào.

2. Thiết lập vấn đề
Chúng tôi xem xét vấn đề học có giám sát nơi chúng tôi quan sát một tập dữ liệu gồm n cặp DL=f(xi;yi)gNi và mục tiêu của chúng tôi là ước tính một hàm dự đoán p(yjx). Ngoài ra, chúng tôi có N0 quan sát không có nhãn DU=fxigN0i.

Cụ thể hơn, chúng tôi xem xét vấn đề học tích cực nơi thuật toán được tóm tắt trong Thuật toán 1.

Thuật toán 1 Quá trình học tích cực. Đối với học tích cực theo lô, thuật toán huấn luyện một mô hình trên DL trước khi ước tính tính không chắc chắn trên pool DU, các mẫu không chắc chắn nhất được gán nhãn bởi con người trước khi khởi động lại vòng lặp.

Dữ liệu: D=fx0;:::;xng
Kết quả: DL=f(x0;y0);:::g
DL Gán nhãn ngẫu nhiên B điểm
DU D\DL
while ngân sách gán nhãn có sẵn do
    Huấn luyện mô hình đến hội tụ trên DL
    Tính toán tính không chắc chắn U(x); cho tất cả x2DU
    Gán nhãn k mẫu không chắc chắn nhất hàng đầu

3. Bối cảnh
Học tích cực đã nhận được rất nhiều sự chú ý trong những năm qua, đặc biệt trên các nhiệm vụ phân loại (Gal et al., 2017). Tuy nhiên, một số công việc đã được thực hiện trên phân đoạn (Kendall & Gal, 2017), định vị (Miller et al., 2019), xử lý ngôn ngữ tự nhiên (Siddhant & Lipton, 2018), và chuỗi thời gian (Peng et al., 2017). Trong bài báo này, chúng tôi tập trung sự chú ý vào phân loại hình ảnh.

Học tích cực Bayesian Các kỹ thuật hiện đại hiện tại được sử dụng trong học tích cực dựa vào ước tính tính không chắc chắn để thực hiện truy vấn (Gal et al., 2017). Một vấn đề phổ biến được nêu bật trong Tsymbalov et al. (2019); Kirsch et al. (2019) là nhu cầu huấn luyện lại mô hình và tính toán lại các tính không chắc chắn càng thường xuyên càng tốt. Nếu không, các mẫu tiếp theo được chọn có thể quá giống với các mẫu đã được chú thích trước đó. Điều này có vấn đề do thời gian huấn luyện dài của các mô hình học sâu cũng như nhiệm vụ tốn kém của ước tính tính không chắc chắn. Tsymbalov et al. (2019); Houlsby et al. (2011) và Wilson et al. (2015) đã đề xuất các giải pháp cho vấn đề này, nhưng tốn kém về bộ nhớ và thời gian khi được sử dụng trên kích thước đầu vào lớn hoặc tập dữ liệu lớn. Trong thực tế, do chi phí lớn của suy luận và huấn luyện lại cho các tập dữ liệu quy mô lớn, không khả thi để tính toán lại các tính không chắc chắn một cách kịp thời. Do đó, nhiều mẫu được chú thích giữa các lần huấn luyện lại. Chúng tôi gọi khung này là học tích cực theo lô.

Các thuật toán học máy có thể gặp phải hai loại tính không chắc chắn (Kendall & Gal, 2017):
1) Tính không chắc chắn Aleatoric, tính không chắc chắn vốn có của dữ liệu, không thể được giải thích với nhiều mẫu hơn. Điều này do ví dụ: lỗi trong quá trình gán nhãn, che khuất, thu thập dữ liệu kém, hoặc khi hai lớp bị nhầm lẫn cao.
2) Tính không chắc chắn Epistemic, tính không chắc chắn về mô hình cơ bản. Việc có được nhiều mẫu hơn sẽ cung cấp thêm thông tin về mô hình cơ bản và giảm lượng tính không chắc chắn epistemic. Quan trọng là, một số mẫu có nhiều thông tin hơn những mẫu khác.

Ước tính tính không chắc chắn Việc tính toán tính không chắc chắn của các mạng nơ-ron sâu là rất quan trọng đối với nhiều ứng dụng từ hình ảnh y tế đến ứng dụng vay. Thật không may, các mạng nơ-ron sâu thường quá tự tin vì chúng không được thiết kế để cung cấp các dự đoán được hiệu chuẩn (Scalia et al., 2019; Gal, 2016). Do đó, các nhà nghiên cứu đã đề xuất các phương pháp mới để có được ước tính đáng tin cậy về tính không chắc chắn epistemic như MC-Dropout (Gal & Ghahramani, 2016), mạng nơ-ron Bayesian (Blundell et al., 2015) hoặc Ensembles. Gần đây hơn, Wilson & Izmailov (2020) đã đề xuất kết hợp suy luận biến phân và ensembles. Mặc dù phương pháp này là hiện đại nhất, nó quá tốn kém về mặt tính toán để được sử dụng trong ngành công nghiệp.

Trong bài báo này, chúng tôi sẽ sử dụng MC-Dropout (Gal & Ghahramani, 2016). Trong kỹ thuật này đề xuất các lớp Dropout được giữ kích hoạt tại thời điểm kiểm tra để lấy mẫu từ phân phối hậu nghiệm. Do đó, phương pháp này có thể được sử dụng trên bất kỳ kiến trúc nào sử dụng Dropout làm cho nó có thể sử dụng được trên một loạt các ứng dụng.

Hàm thu thập Nhiều heuristic đã được đề xuất để trích xuất giá trị tính không chắc chắn từ việc lấy mẫu dự đoán ngẫu nhiên. Chúng tôi định nghĩa lấy mẫu Monte-Carlo từ phân phối hậu nghiệm p(wjD) như:
pt(yjx) =p(yjx;wt);t2f1:::Tg;wtp(wjD)
trong đó T là số lượng mẫu Monte-Carlo. Chúng tôi tính toán trung bình mô hình Bayesian, ^p(yjx) =1T∑Tt pt(yjx). Khi có tính không chắc chắn cao, ^p(yjx) sẽ gần với phân phối đồng nhất. Một phương pháp ngây thơ để ước tính tính không chắc chắn là tính toán entropy của phân phối này.

Một phương pháp tinh vi hơn là BALD (Houlsby et al., 2011), ước tính tính không chắc chắn epistemic bằng cách tính toán thông tin tương hỗ giữa phân phối hậu nghiệm mô hình và dự đoán:
I(y;wjx;DL) =H[yjx;DL]−Ep(wjDL)(H[yjx;w]):

BALD so sánh entropy của estimator trung bình với các entropy của tất cả estimators. Kết quả cao khi có sự bất đồng cao giữa các dự đoán, điều này giải quyết vấn đề quá tự tin trong các mô hình học sâu.

Kích thước tập dữ liệu 5000 10000 20000
ε = 0
BALD 0.65 ± 0.01 0.53 ± 0.01 0.43 ± 0.02
Entropy 0.68 ± 0.03 0.52 ± 0.02 0.43 ± 0.03
Random 0.71 ± 0.02 0.58 ± 0.02 0.47 ± 0.01
ε = 0.05
BALD 0.72 ± 0.02 0.57 ± 0.01 0.43 ± 0.02
Entropy 0.72 ± 0.02 0.54 ± 0.02 0.41 ± 0.01
Random 0.73 ± 0.03 0.61 ± 0.03 0.51 ± 0.02
ε = 0.1
BALD 0.78 ± 0.03 0.62 ± 0.01 0.48 ± 0.01
Entropy 0.71 ± 0.02 0.57 ± 0.01 0.44 ± 0.02
Random 0.76 ± 0.02 0.64 ± 0.02 0.54 ± 0.01

Bảng 1. Tác động của lỗi chú thích đối với học tích cực bằng cách xáo trộn ngẫu nhiên ε% nhãn. Log-likelihood kiểm tra được tính trung bình qua 5 lần chạy.

4. Thí nghiệm
Trong bài báo này, chúng tôi muốn chứng minh khả năng sử dụng của học tích cực trong một kịch bản thực tế. Đầu tiên, chúng tôi phân tích tác động của các bệnh lý phổ biến trong học sâu đối với học tích cực. Thứ hai, một vấn đề phổ biến trong học tích cực là thời gian cần thiết giữa các bước trong vòng lặp học tích cực. Như đã nêu bởi Kirsch et al. (2019), huấn luyện lại càng sớm càng tốt là rất quan trọng để có được các mẫu không tương quan. Chúng tôi điều tra xem a) điều này có đúng trong các tập dữ liệu quy mô lớn và b) chúng ta có thể làm gì để làm cho điều này nhanh hơn. Chi tiết triển khai có thể được tìm thấy trong Phụ lục. Baselines cho tất cả các hàm thu thập có thể được tìm thấy trong Hình 1.

4.1. Bệnh lý
Trong phần này, chúng tôi xác minh xem các bệnh lý phổ biến trong học sâu có giữ nguyên cho học tích cực không. Các vấn đề như lỗi chú thích hoặc hội tụ mô hình có thể có hại cho quy trình và thường bị bỏ qua trong tài liệu. Đặc biệt, do lượng dữ liệu được chú thích nhỏ, các mô hình có nhiều rủi ro hơn so với khi chúng được huấn luyện trên các tập dữ liệu lớn.

Tác động của lỗi chú thích Mặc dù các tập dữ liệu tiêu chuẩn có chất lượng tốt, con người còn lâu mới hoàn hảo và sẽ tạo ra lỗi khi gán nhãn. Điều này đặc biệt đúng khi sử dụng cộng đồng nguồn (Allahbakhsh et al., 2013). Bởi vì học tích cực dựa vào dữ liệu huấn luyện để huấn luyện mô hình và chỉ có một vài mẫu được gán nhãn, chúng tôi đưa ra giả thuyết rằng học tích cực sẽ rất nhạy cảm với nhiễu.

Để xác nhận giả thuyết này, chúng tôi đưa nhiễu vào bằng cách làm hỏng ε% nhãn. Chúng tôi kiểm tra giả thuyết của chúng tôi trên CIFAR10 (Krizhevsky et al., 2009). Trong Bảng 1, chúng tôi có thể đánh giá rằng tùy thuộc vào ε, quy trình học tích cực bị ảnh hưởng rất nhiều bởi nhiễu gán nhãn. Hơn nữa, khi chúng tôi so sánh với lựa chọn ngẫu nhiên, lợi ích của việc sử dụng học tích cực giảm khi có nhiễu, nhưng nó vẫn hữu ích.

Hình 2. Tác động của các lịch trình huấn luyện khác nhau. Bằng cách so sánh các mô hình bị overfitted và underfitted, chúng tôi đánh giá tác động của chất lượng tính không chắc chắn đối với học tích cực. Hiệu suất được tính trung bình qua 5 lần chạy.

Tác động của hội tụ mô hình Bởi vì chúng tôi không có quyền kiểm soát chế độ huấn luyện tại mỗi bước thời gian, khó có thể huấn luyện mô hình đến một giải pháp tối ưu. Với các tập dữ liệu được chú thích đầy đủ, chúng tôi có thể tinh chỉnh thiết lập huấn luyện của mình với tìm kiếm siêu tham số hoặc huấn luyện trong nhiều ngày. Trong môi trường sản xuất, chúng tôi bị hạn chế khả năng huấn luyện mô hình tốt nhất. Do đó, mô hình có thể bị underfitted hoặc overfitted với tập dữ liệu hiện tại và cung cấp các ước tính tính không chắc chắn có lỗi.

Để xác nhận giả thuyết của chúng tôi, chúng tôi thay đổi số epoch mà mô hình được huấn luyện. Như được thấy trong Hình 2, các mô hình underfitted bị ảnh hưởng rất nhiều trong khi các mô hình overfitted bị ảnh hưởng, nhưng vẫn có hiệu suất. Điều này do sự phù hợp kém của mô hình dẫn đến ước tính sai về tính không chắc chắn của mô hình. Trong Phụ lục, chúng tôi trình bày sự khác biệt về hiệu suất giữa BALD và Random.

Trong phần này, chúng tôi đã điều tra tác động của hai bệnh lý học sâu phổ biến trong học tích cực. Tóm lại, kiến thức trước về chất lượng của các chú thích và về thời gian huấn luyện mô hình, có thể giúp sử dụng học tích cực.

4.2. Kỹ thuật hiệu quả cho học tích cực
Một vấn đề quan trọng với các đường ống học tích cực hiện tại là độ trễ giữa các bước học tích cực. Để làm cho học tích cực hiệu quả, chúng tôi đề xuất một số kỹ thuật duy trì hiệu suất trong khi tăng tốc các giai đoạn huấn luyện hoặc suy luận.

Kích thước truy vấn Một siêu tham số quan trọng trong học tích cực theo lô là quyết định bao nhiêu mẫu nên được gán nhãn tại mỗi bước học tích cực (Gal et al., 2017; Tsymbalov et al., 2019). Trong kịch bản thực tế, chúng ta không thể yêu cầu nhóm chú thích chờ đợi giữa các bước đặc biệt trong môi trường cộng đồng nguồn. Do đó, cần có một cấu hình nơi chúng ta có thể hưởng lợi từ chất lượng ước tính tính không chắc chắn tốt và thời gian chạy hợp lý. Chúng tôi trình bày những phát hiện của chúng tôi trong Bảng 2 nơi chúng tôi đã kiểm tra phương pháp này trên CIFAR10. Từ kết quả của chúng tôi, kích thước truy vấn làm giảm hiệu suất, đặc biệt tại 10.000 nhãn nơi khoảng cách giữa BALD và Entropy mỏng hơn khi kích thước truy vấn tăng.

Kích thước tập dữ liệu 5000 10000 20000
Random 0.71±0.03 0.54 ± 0.01 0.42 ± 0.05
Q=50
BALD 0.59 ± 0.01 0.46 ± 0.05 0.34 ± 0.02
Entropy 0.69 ± 0.06 0.55 ± 0.11 0.34 ± 0.00
Q=250
BALD 0.61 ± 0.03 0.43 ± 0.01 0.35 ± 0.03
Entropy 0.67 ± 0.05 0.49 ± 0.04 0.35 ± 0.00
Q=500
BALD 0.61 ± 0.07 0.42 ± 0.02 0.36 ± 0.01
Entropy 0.61 ± 0.07 0.47 ± 0.00 0.37 ± 0.00
Q=2000
BALD 0.77 ± 0.05 0.53 ± 0.03 0.37 ± 0.03
Entropy 0.87 ± 0.01 0.52 ± 0.07 0.35 ± 0.01

Bảng 2. Tác động của việc tăng kích thước truy vấn Q trên CIFAR10. Hiệu suất được tính trung bình qua 5 lần chạy. BALD yếu hơn khi được sử dụng với kích thước truy vấn lớn, làm cho Entropy có khả năng cạnh tranh.

Giới hạn kích thước pool Phần tốn thời gian nhất của học tích cực là bước ước tính tính không chắc chắn. Đặc biệt, bước này tốn kém khi sử dụng các kỹ thuật đòi hỏi lấy mẫu Monte-Carlo như MC-Dropout hoặc mạng nơ-ron Bayesian. Tất nhiên, vấn đề này có thể song song hóa một cách đáng xấu hổ, nhưng đối với triển khai ngân sách thấp, người ta không có quyền truy cập vào các tài nguyên cần thiết để song song hóa nhiệm vụ này một cách rẻ tiền. Một ý tưởng đơn giản để giải quyết điều này là chọn ngẫu nhiên các mẫu chưa được gán nhãn từ pool thay vì sử dụng toàn bộ pool. Chúng tôi kiểm tra ý tưởng này bằng cách thay đổi số lượng mẫu được chọn để ước tính tính không chắc chắn. Từ các thí nghiệm của chúng tôi (hình trong Phụ lục), chúng tôi chỉ ra rằng hiệu suất không bị ảnh hưởng khi sử dụng ít hơn 25% pool. Bằng cách làm điều này, chúng ta có thể tăng tốc giai đoạn này với hệ số 3.

Trong phần này, chúng tôi đã đề xuất hai phương pháp để làm cho học tích cực có thể sử dụng được trong sản xuất. Đầu tiên, chúng ta có thể tăng kích thước truy vấn cao hơn so với trước đây được sử dụng trong tài liệu. Thứ hai, chúng ta có thể chọn lô tiếp theo sử dụng một tập con nhỏ của pool.

5. Nghiên cứu trường hợp: Mio-TCD
Ít tập dữ liệu đã được đề xuất để mô phỏng tình huống "thực tế" nơi tập dữ liệu gặp phải nhiễu gán nhãn, trùng lặp, hoặc tập dữ liệu mất cân bằng. Mio-TCD (Luo et al., 2018) gần đây đã được đề xuất để thể hiện những vấn đề này. Tập dữ liệu chứa 500.000 mẫu được chia thành 11 lớp với mất cân bằng lớp nặng. Ví dụ, tập huấn luyện chứa 50% Cars và 20% Background.

Lợi ích của học tích cực. Như đã chỉ ra trong Gal et al. (2017) (và thêm trong Phụ lục), học tích cực giúp ích khi được sử dụng trên dữ liệu mất cân bằng. Chúng tôi có thể xác minh điều này, bằng cách so sánh hiệu suất của các lớp được đại diện ít trong Mio-TCD. Từ bảng xếp hạng hiện tại, chúng tôi có thể chọn hai lớp khó: Single-Unit Truck, và Bicycle. Chúng tôi sử dụng cùng thiết lập như trước, nhưng giới hạn kích thước của pool ở 20.000 mẫu.

Trong Hình 3, chúng tôi trình bày điểm F1 cho hai lớp khó nhất. Người ta có thể thấy rõ tác động của việc sử dụng học tích cực trong thiết lập này. Với học tích cực, các lớp được đại diện ít được chọn nhanh chóng và có được hiệu suất khá tốt. Ngoài ra, hiệu suất cho lớp đông dân nhất Cars vẫn tương tự trên các hàm thu thập (hình trong Phụ lục). Thí nghiệm này cho thấy rằng việc sử dụng học tích cực trên các tập dữ liệu không học thuật rất có lợi và nhu cầu cho cộng đồng học tích cực sử dụng các điểm chuẩn mới để so sánh các phương pháp.

Hình 3. Hiệu suất của các quy trình học tích cực khác nhau trên Mio-TCD. Mặc dù bất kỳ phương pháp học tích cực nào cũng mạnh chống lại ngẫu nhiên, BALD đặc biệt mạnh ở đầu quá trình gán nhãn. Hiệu suất được tính trung bình qua 5 lần chạy.

6. Kết luận
Trong bài báo này, chúng tôi đã điều tra tác động của dữ liệu chưa được làm sạch đối với các mô hình học tích cực sâu được sử dụng cho học tích cực. Chúng tôi cũng đề xuất một số kỹ thuật để làm cho học tích cực có thể sử dụng được trong môi trường thực tế. Sau đó, chúng tôi kiểm tra những phát hiện của mình trên tập dữ liệu thực tế Mio-TCD, cho thấy rằng học tích cực có thể được sử dụng trong thiết lập này. Kết quả của nghiên cứu này, chúng tôi giới thiệu thư viện học tích cực Bayesian mới phát hành của chúng tôi có thể hữu ích cho cả nhà nghiên cứu và nhà phát triển (xem Phụ lục).

Tóm lại, chúng tôi chỉ ra rằng học tích cực có thể được sử dụng trong thiết lập sản xuất trên dữ liệu thực với thành công. Chúng tôi hy vọng công việc này có thể tăng tốc ứng dụng của học tích cực trên các dự án thực tế và cải thiện chất lượng chú thích bằng cách nhận được nhiều thông tin hơn mỗi mẫu. Các lĩnh vực nghiên cứu thú vị bao gồm nghiên cứu về sự tương tác giữa con người và máy trong một nhiệm vụ gán nhãn.

Tài liệu tham khảo
Abu-El-Haija, S., Kothari, N., Lee, J., Natsev, A. P., Toderici, G., Varadarajan, B., and Vijayanarasimhan, S. Youtube-8m: A large-scale video classification benchmark. In arXiv:1609.08675, 2016. URL https://arxiv.org/pdf/1609.08675v1.pdf.

Allahbakhsh, M., Benatallah, B., Ignjatovic, A., Motahari-Nezhad, H. R., Bertino, E., and Dustdar, S. Quality control in crowdsourcing systems: Issues and directions. IEEE Internet Computing, 17(2):76–81, 2013.

Beluch, W. H., Genewein, T., Nürnberger, A., and Köhler, J. M. The power of ensembles for active learning in image classification. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 9368–9377, 2018.

Blundell, C., Cornebise, J., Kavukcuoglu, K., and Wierstra, D. Weight uncertainty in neural networks. arXiv preprint arXiv:1505.05424, 2015.

Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L. ImageNet: A Large-Scale Hierarchical Image Database. In CVPR09, 2009.

Gal, Y. Uncertainty in deep learning. University of Cambridge, 1:3, 2016.

Gal, Y. and Ghahramani, Z. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. In international conference on machine learning, pp. 1050–1059, 2016.

Gal, Y., Islam, R., and Ghahramani, Z. Deep bayesian active learning with image data. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp. 1183–1192. JMLR. org, 2017.

Houlsby, N., Huszár, F., Ghahramani, Z., and Lengyel, M. Bayesian active learning for classification and preference learning. arXiv preprint arXiv:1112.5745, 2011.

Ipeirotis, P. G., Provost, F., and Wang, J. Quality management on amazon mechanical turk. In Proceedings of the ACM SIGKDD workshop on human computation, pp. 64–67, 2010.

Kendall, A. and Gal, Y. What uncertainties do we need in bayesian deep learning for computer vision? In Advances in neural information processing systems, pp. 5574–5584, 2017.

Kirsch, A., van Amersfoort, J., and Gal, Y. Batchbald: Efficient and diverse batch acquisition for deep bayesian active learning, 2019.

Krawczyk, B. Learning from imbalanced data: open challenges and future directions. Progress in Artificial Intelligence, 5(4):221–232, 2016.

Krizhevsky, A., Hinton, G., et al. Learning multiple layers of features from tiny images. 2009.

Luo, Z., Branchaud-Charron, F., Lemaire, C., Konrad, J., Li, S., Mishra, A., Achkar, A., Eichel, J., and Jodoin, P.-M. Mio-tcd: A new benchmark dataset for vehicle classification and localization. IEEE Transactions on Image Processing, 27(10):5129–5141, 2018.

Maddox, W. J., Izmailov, P., Garipov, T., Vetrov, D. P., and Wilson, A. G. A simple baseline for bayesian uncertainty in deep learning. In Advances in Neural Information Processing Systems, pp. 13132–13143, 2019.

Miller, D., Dayoub, F., Milford, M., and Sünderhauf, N. Evaluating merging strategies for sampling-based uncertainty techniques in object detection. In 2019 International Conference on Robotics and Automation (ICRA), pp. 2348–2354. IEEE, 2019.

Oliphant, T. E. A guide to NumPy, volume 1. Trelgol Publishing USA, 2006.

Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Desmaison, A., Antiga, L., and Lerer, A. Automatic differentiation in pytorch. 2017.

Peng, F., Luo, Q., and Ni, L. M. Acts: An active learning method for time series classification. In 2017 IEEE 33rd International Conference on Data Engineering (ICDE), pp. 175–178. IEEE, 2017.

Scalia, G., Grambow, C. A., Pernici, B., Li, Y.-P., and Green, W. H. Evaluating scalable uncertainty estimation methods for dnn-based molecular property prediction. arXiv preprint arXiv:1910.03127, 2019.

Siddhant, A. and Lipton, Z. C. Deep bayesian active learning for natural language processing: Results of a large-scale empirical study. arXiv preprint arXiv:1808.05697, 2018.

Tsymbalov, E., Makarychev, S., Shapeev, A., and Panov, M. Deeper connections between neural networks and gaussian processes speed-up active learning. arXiv preprint arXiv:1902.10350, 2019.

Wilson, A. G. and Izmailov, P. Bayesian deep learning and a probabilistic perspective of generalization. arXiv preprint arXiv:2002.08791, 2020.

Wilson, A. G., Hu, Z., Salakhutdinov, R., and Xing, E. P. Deep kernel learning. In AISTATS, 2015.

Zhang, X., Zou, J., He, K., and Sun, J. Accelerating very deep convolutional networks for classification and detection. IEEE transactions on pattern analysis and machine intelligence, 38(10):1943–1955, 2015.

Tài liệu bổ sung

A. Chi tiết triển khai
Phương pháp của chúng tôi như sau. Chúng tôi huấn luyện một VGG-16 (Zhang et al., 2015) được huấn luyện trước trên ImageNet (Deng et al., 2009). Tập huấn luyện ban đầu của chúng tôi chứa 500 mẫu. Chúng tôi ước tính tính không chắc chắn sử dụng 20 mẫu MC và gán nhãn 100 phần tử không chắc chắn nhất. Theo Gal et al. (2017), chúng tôi đặt lại trọng số về giá trị ban đầu của chúng giữa các bước.

B. Tập dữ liệu mất cân bằng
Cách đối phó với tập dữ liệu mất cân bằng là một lĩnh vực nghiên cứu hoàn chỉnh (Krawczyk, 2016), nhưng ít được thực hiện để đối phó với nó khi chúng ta không biết phân phối lớp a priori. Do đó, mô hình học tích cực có thể nhanh chóng overfitt với các lớp phổ biến hơn và giảm hiệu quả của quy trình học tích cực. Từ Gal et al. (2017), đã biết rằng học tích cực Bayesian sẽ ưu tiên các lớp được đại diện ít. Nhưng, chúng tôi thấy các thí nghiệm được báo cáo quá đơn giản. Chúng tôi kiểm tra giả thuyết này trong một môi trường có kiểm soát nơi chúng ta có thể đặt số lượng lớp không được đại diện.

Trong Bảng 3, chúng tôi lấy tập dữ liệu CIFAR100 tiêu chuẩn và chúng tôi mô phỏng một tập dữ liệu mất cân bằng nơi ít lớp có số lượng ví dụ cao. Một lớp được chọn để không được đại diện thấy số lượng mẫu của nó bị giảm 75%. Khi chúng tôi tăng số lượng lớp không được đại diện, lợi ích của việc sử dụng MC-Dropout so với lấy mẫu ngẫu nhiên trở nên rõ ràng hơn. Điều này do các vùng trên manifold đã học liên quan đến các lớp không được đại diện có tính không chắc chắn cao. Do đó, những vùng này sẽ được chọn để gán nhãn rất sớm trong quá trình.

C. Tác động của hội tụ
Trong Hình 4, chúng tôi tính toán sự khác biệt về hiệu suất giữa BALD và ngẫu nhiên. Chúng tôi gọi thước đo này là Lợi ích Tích cực=NLL Ngẫu nhiên−NLL BALD. Khi sử dụng một mô hình underfitted, lợi ích trở thành âm tức là bạn sẽ tốt hơn khi sử dụng lựa chọn ngẫu nhiên.

D. Tác động của việc giảm kích thước pool
Như một phần của các thí nghiệm, chúng tôi kiểm tra xem việc giới hạn kích thước pool có ảnh hưởng đến hiệu suất của học tích cực không. Các thí nghiệm của chúng tôi trong Hình 5 cho thấy rằng việc tính toán tính không chắc chắn cho toàn bộ dữ liệu pool hay một tập con được chọn ngẫu nhiên, hiệu suất của học tích cực không bị ảnh hưởng. Điều này dẫn đến kết quả thú vị là giới hạn các tính toán tính không chắc chắn (là phần tốn kém nhất của một vòng lặp học tích cực) trong thiết lập sản xuất cho các vòng lặp học tích cực nhanh hơn.

Kích thước tập dữ liệu 5000 10000 20000
α = 10
BALD 4.39 ± 0.4 3.99±0.01 3.57±0.05
Entropy 4.71 ± 0.02 4.54±0.07 3.94±0.01
Random 4.52 ± 0.09 4.10±0.03 3.71±0.05
α = 25
BALD 4.40 ± 0.03 4.04±0.03 3.61±0.08
Entropy 4.76 ± 0.02 4.68±0.08 4.00±0.01
Random 4.58 ± 0.08 4.18±0.04 3.75±0.01
α = 50
BALD 4.49 ± 0.08 4.07±0.02 3.66±0.04
Entropy 4.83 ± 0.04 4.60±0.14 4.07±0.28
Random 4.62 ± 0.03 4.21±0.02 3.76±0.04

Bảng 3. Tác động của việc sử dụng học tích cực trên các phiên bản mất cân bằng của CIFAR100. α là số lượng lớp chứa 25% dữ liệu của chúng. Từ (Gal et al., 2017), chúng ta biết rằng BALD bền vững với tập dữ liệu mất cân bằng, nhưng nghiên cứu không rộng rãi. Mặc dù BALD bền vững với tập dữ liệu mất cân bằng, tác động là thảm khốc khi sử dụng Entropy. Hiệu suất được tính trung bình qua 5 lần chạy.

Hình 4. Lợi ích của việc sử dụng học tích cực khi thay đổi số epoch huấn luyện. Một mô hình underfitted sẽ gây hại cho việc huấn luyện mô hình và trong trường hợp này, chỉ sử dụng ngẫu nhiên sẽ tốt hơn.

Hình 5. Tác động của việc giảm kích thước pool trên CIFAR100. -1 chỉ ra không giảm. Đối với tất cả heuristics, hiệu suất không bị ảnh hưởng bởi kích thước của pool cho thấy rằng AL có thể hiệu quả khi được điều chỉnh đúng cách. Hiệu suất được tính trung bình qua 5 lần chạy.

Hình 6. F1 cho lớp xe hơi. BALD tuyệt vời cho các lớp được đại diện ít trong khi không ảnh hưởng đến các lớp phổ biến hơn. Entropy giảm hiệu suất trên lớp này.

E. Thư viện học tích cực Bayesian (BaaL)
Tất cả các thí nghiệm trong bài báo này đã được thực hiện bằng cách sử dụng thư viện học tích cực Bayesian có sẵn công khai của chúng tôi. Mục tiêu của thư viện này là cung cấp một thiết lập dễ sử dụng nhưng hoàn chỉnh để kiểm tra học tích cực trên bất kỳ dự án nào với vài dòng code. Chúng tôi bao gồm các tính năng mà các thư viện học tích cực hiện tại không hỗ trợ. Đặc biệt, các phương pháp Bayesian như MC-Dropout hoặc Coresets không có sẵn rộng rãi và không có triển khai tiêu chuẩn của vòng lặp học tích cực. Hơn nữa, các codebase nghiên cứu thường khó đọc và khó duy trì. API thống nhất được đề xuất của chúng tôi có thể thỏa mãn cả người dùng nghiên cứu và công nghiệp.

Gói mã nguồn mở được phát hành gần đây của chúng tôi có tên BaaL, nhằm mục đích tăng tốc quá trình chuyển đổi từ nghiên cứu sang sản xuất. Triết lý cốt lõi đằng sau thư viện của chúng tôi là cung cấp cho các nhà nghiên cứu một API được thiết kế tốt để họ tập trung vào ý tưởng mới của mình chứ không phải vào các chi tiết kỹ thuật. Thư viện của chúng tôi đề xuất một hệ thống bất khả tri nhiệm vụ nơi người ta có thể kết hợp bất kỳ tập hợp nào của các hàm thu thập và phương pháp ước tính tính không chắc chắn. Thư viện bao gồm ba thành phần chính:

1. Quản lý tập dữ liệu để theo dõi và quản lý dữ liệu có nhãn DL và dữ liệu không có nhãn DU.
2. Phương pháp Bayesian tức là MC-Dropout, MC-DropConnect và những phương pháp khác.
3. Hàm thu thập tức là BALD, BatchBALD, Entropy và nhiều hơn nữa.

Chúng tôi cung cấp hỗ trợ đầy đủ cho các mô-đun học sâu Pytorch (Paszke et al., 2017) nhưng các hàm thu thập của chúng tôi là phần quan trọng nhất của học tích cực được triển khai trong Numpy (Oliphant, 2006) và do đó có thể được sử dụng trên bất kỳ nền tảng nào. Mô-đun Quản lý dữ liệu của chúng tôi theo dõi những gì được gán nhãn và những gì không được gán nhãn. Chúng tôi cũng cung cấp các phương pháp tạo điều kiện để gán nhãn một điểm dữ liệu, cập nhật pool dữ liệu không có nhãn, và gán nhãn ngẫu nhiên một phần của tập dữ liệu. Trong mô-đun Bayesian của chúng tôi, chúng tôi cung cấp các tiện ích để làm cho bất kỳ mô hình Pytorch nào trở thành Bayesian với một lệnh duy nhất. Chúng tôi cũng cung cấp các vòng lặp huấn luyện, kiểm tra và học tích cực tạo điều kiện cho quy trình huấn luyện tích cực. Các hàm thu thập của chúng tôi được cập nhật với các phương pháp hiện đại nhất. Chúng tôi cung cấp các hướng dẫn dễ theo dõi (https://baal.readthedocs.io/en/latest/) cho mỗi phần của thư viện để người dùng hiểu cách hoạt động của từng thành phần. Cuối cùng, thư viện của chúng tôi là thành viên của Hệ sinh thái Pytorch, được dành riêng cho các thư viện có tài liệu xuất sắc.

Lộ trình của chúng tôi đã được chỉ ra trong kho lưu trữ. Trọng tâm hiện tại của chúng tôi sẽ bao gồm hiệu chuẩn mô hình và học bán giám sát. Khi nhiều nhà nghiên cứu đóng góp phương pháp của họ vào thư viện của chúng tôi, chúng tôi nhằm mục đích trở thành thư viện học tích cực Bayesian tiêu chuẩn.

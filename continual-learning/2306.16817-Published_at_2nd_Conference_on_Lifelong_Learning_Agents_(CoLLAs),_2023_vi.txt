# 2306.16817.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/continual-learning/2306.16817.pdf
# Kích thước tệp: 1953936 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Được xuất bản tại Hội nghị thứ 2 về Các tác nhân học tập suốt đời (CoLLAs), 2023
CẢI THIỆN HIỆU SUẤT VÀ ỔN ĐỊNH HỌC TẬP LIÊN TỤC TRỰC TUYẾN
VỚI CÁC ENSEMBLE THỜI GIAN
Albin Soutif–Cormerais
Trung tâm Thị giác Máy tính
Đại học Tự trị Barcelona
albin@cvc.uab.catAntonio Carta
Khoa Khoa học Máy tính
Đại học Pisa
antonio.carta@unipi.itJoost Van de Weijer
Trung tâm Thị giác Máy tính
Đại học Tự trị Barcelona
joost@cvc.uab.es

TÓM TẮT
Mạng nơ-ron rất hiệu quả khi được huấn luyện trên các bộ dữ liệu lớn trong một số lượng lớn các vòng lặp.
Tuy nhiên, khi chúng được huấn luyện trên các luồng dữ liệu không ổn định và theo cách trực tuyến, hiệu suất của chúng bị giảm (1) bởi thiết lập trực tuyến, điều này hạn chế tính khả dụng của dữ liệu, (2) do quên thảm khốc vì tính chất không ổn định của dữ liệu. Hơn nữa, một số công trình gần đây (Caccia et al., 2022; Lange et al., 2023) đã chỉ ra rằng các phương pháp phát lại được sử dụng trong học tập liên tục gặp phải khoảng cách ổn định, được gặp phải khi đánh giá mô hình liên tục (thay vì chỉ ở ranh giới nhiệm vụ). Trong bài báo này, chúng tôi nghiên cứu tác động của việc kết hợp mô hình như một cách để cải thiện hiệu suất và ổn định trong học tập liên tục trực tuyến. Chúng tôi nhận thấy rằng việc kết hợp mô hình một cách ngây thơ từ nhiều nhiệm vụ huấn luyện khác nhau làm tăng hiệu suất trong học tập liên tục trực tuyến đáng kể. Xuất phát từ quan sát này, và lấy cảm hứng từ các phương pháp kết hợp trong học bán giám sát, chúng tôi sử dụng một ensemble thời gian nhẹ tính toán trung bình động theo cấp số nhân của các trọng số (EMA) tại thời điểm kiểm tra, và chỉ ra rằng nó có thể tăng hiệu suất và ổn định một cách đáng kể khi được sử dụng kết hợp với một số phương pháp từ tài liệu.

1 GIỚI THIỆU
Học mạng nơ-ron với lan truyền ngược đã được chứng minh có khả năng có tính chất tổng quát hóa tốt ngay cả khi sử dụng mạng quá tham số hóa (Krizhevsky et al., 2017). Tuy nhiên, những tính chất học tập tốt này chủ yếu xảy ra khi dữ liệu được cung cấp theo cách độc lập và phân phối giống hệt nhau. Khi học trên một luồng có phân phối thay đổi theo thời gian, mạng nơ-ron được biết là gặp phải quên thảm khốc (McCloskey & Cohen, 1989; Goodfellow et al., 2014; Kirkpatrick et al., 2017), và có xu hướng quên kiến thức có được trong các nhiệm vụ học tập trước đó. Lĩnh vực học tập liên tục nhằm giải quyết vấn đề này. Nói chung, học tập tăng dần chia việc học thành các nhiệm vụ riêng biệt (được xác định bởi task-ID) mà tác nhân gặp phải một cách tuần tự. Nhiều thiết lập khác nhau đã được giới thiệu trong học tập liên tục để đánh giá các khía cạnh khác nhau của tác nhân học tập liên tục; học tập tăng dần theo nhiệm vụ (De Lange et al., 2021; van de Ven & Tolias, 2018), và học tập tăng dần theo lớp (Masana et al., 2022; Belouadah et al., 2021) là một trong những thiết lập phổ biến nhất. Trong bài báo này, chúng tôi tập trung vào thiết lập tăng dần theo lớp thách thức hơn, nơi người học không có quyền truy cập vào task-ID tại thời điểm suy luận.

Kết hợp Mô hình, hoặc việc tổng hợp các dự đoán đến từ các mô hình khác nhau, là một chủ đề được nghiên cứu kỹ lưỡng và phổ biến, cả trong tài liệu học thuật và trong các ứng dụng thực tế (Hansen & Salamon, 1990; Perrone & Cooper, 1995; Dietterich, 2000). Nó được biết là cải thiện hiệu suất so với việc sử dụng một mô hình duy nhất. Sự thành công của các phương pháp kết hợp đã được tìm thấy phụ thuộc vào sự đa dạng chức năng của các thành viên và hiệu quả của ensemble kết quả giữa chúng (Goodfellow et al., 2016; Wortsman et al., 2021). Trong học tập liên tục, mô hình học dữ liệu từng nhiệm vụ một, được tiếp xúc với một nhiệm vụ tại một thời điểm. Do đó, các mô hình ở các bước thời gian khác nhau đại diện cho một tập hợp các mô hình đa dạng về chức năng, mỗi mô hình được thích ứng cục bộ với nhiệm vụ hiện tại. Sự đa dạng chức năng như vậy có thể được khai thác bởi các kỹ thuật kết hợp. Trong Hình 1, chúng tôi hiển thị kết quả kết hợp trên hai điểm chuẩn học tập liên tục. Ở đây chúng tôi áp dụng ensemble thời gian của hai mươi mô hình (được chọn từ một số lượng lớn các mô hình được lưu dọc theo quỹ đạo huấn luyện). Chúng ta có thể quan sát rằng việc kết hợp dẫn đến cải thiện hiệu suất đáng kể (hơn 40% trên cả hai bộ dữ liệu), và rằng bất cứ khi nào chúng ta tăng số lượng nhiệm vụ được bao phủ bởi ensemble, lợi ích cải thiện. Do đó, trong bài báo này, chúng tôi điều tra việc sử dụng ensemble cho học tập liên tục và cung cấp kết quả thực nghiệm cho thấy lợi ích của chúng cho các thiết lập học tập liên tục. Quan trọng là, chúng tôi chỉ ra rằng khi sử dụng một phương pháp kết hợp thực tế và hiệu quả về bộ nhớ, kết quả tương tự hoặc thậm chí tốt hơn có thể được đạt được.

Đánh giá các tác nhân học liên tục thường xảy ra sau khi học một nhiệm vụ. Gần đây, một cách đánh giá khác đã được đề xuất, được gọi là đánh giá liên tục (Caccia et al., 2022; Lange et al., 2023) hoặc suy luận bất cứ lúc nào (Koh et al.,

--- TRANG 2 ---
Được xuất bản tại Hội nghị thứ 2 về Các tác nhân học tập suốt đời (CoLLAs), 2023
Hình 1: Lợi ích độ chính xác tương đối (nhân theo %), so với ensemble có hiệu suất tệ nhất, khi kết hợp ngây thơ 20 mô hình đến từ các nhiệm vụ học khác nhau trên Split-Cifar100 (Trái) và Split-MiniImagenet (Phải) cho hai phương pháp học liên tục trực tuyến, phát lại cổ điển ER và mất mát entropy chéo bất đối xứng ER-ACE. Kết quả được báo cáo như một hàm của số nhiệm vụ được bao phủ được định nghĩa là số nhiệm vụ mà các mô hình được kết hợp bắt nguồn từ đó. Đồ thị cho thấy rằng sự đa dạng của ensemble là quan trọng.

2022). Nó nhằm đánh giá hiệu suất của tác nhân tại bất kỳ thời điểm nào trong quá trình học. Trong thiết lập này, Lange et al. (2023) tìm thấy rằng các tác nhân học tập liên tục gặp phải khoảng cách ổn định, nơi hiệu suất trên các nhiệm vụ trước đó giảm mạnh khi bắt đầu học một nhiệm vụ mới, trước khi trở lại bình thường khi tiếp tục huấn luyện nhiệm vụ mới. Hành vi này là có vấn đề trong nhiều ứng dụng thực tế nơi tác nhân phải được áp dụng cho suy luận trong khi nó đang học (tức là cho dự báo thị trường tài chính, hoặc các nhiệm vụ giám sát trực tuyến). Ensemble có thể cung cấp ổn định được cải thiện, vì chúng có thể giảm phương sai của các dự đoán và cung cấp dự đoán mạnh mẽ hơn. Bằng cách kết hợp nhiều mô hình, các lỗi của một mô hình có thể được bù đắp bởi các mô hình khác trong ensemble, dẫn đến hiệu suất ổn định hơn.

Cuối cùng, được biết rằng trong học tập tăng dần theo lớp, ngay cả khi sử dụng phát lại, mạng có xu hướng gặp phải thiên vị gần đây của nhiệm vụ, đây là thiên vị dự đoán hướng về các lớp thuộc về nhiệm vụ cuối cùng. Hiện tượng này đã được nghiên cứu và giải quyết trong nhiều công trình (Belouadah & Popescu, 2019; Wu et al., 2019; Hou et al., 2019). Kết hợp các mô hình thiên vị về các nhiệm vụ khác nhau có tiềm năng giảm thiên vị so với các mô hình đơn lẻ; chúng tôi sẽ phân tích điều này trong bài báo này.

Các lý do được thảo luận trong phần giới thiệu thúc đẩy chúng tôi điều tra tiềm năng của ensemble thời gian trong học tập liên tục trực tuyến. Cụ thể, chúng tôi tin rằng chúng có thể cung cấp ổn định được cải thiện, giảm thiên vị gần đây của nhiệm vụ, và hưởng lợi từ sự đa dạng chức năng hơn so với trong học i.i.d. Bằng cách khám phá hiệu suất của ensemble các mô hình được huấn luyện trên dữ liệu tuần tự, chúng tôi nhằm cung cấp những hiểu biết về lợi ích và hạn chế của việc sử dụng các mô hình như vậy trong thiết lập học tập liên tục trực tuyến. Đóng góp của chúng tôi như sau:

• Chúng tôi chỉ ra rằng việc kết hợp ngây thơ các checkpoint từ các nhiệm vụ học tập liên tục khác nhau mang lại lợi ích hiệu suất mạnh mẽ cho học tập liên tục trực tuyến. Trong việc tìm kiếm một phương pháp kết hợp thực tế, chúng tôi lấy cảm hứng từ học bán giám sát và áp dụng một phương pháp kết hợp thời gian (tức là, một ensemble trung bình động theo cấp số nhân) như một mô hình đánh giá.

• Chúng tôi báo cáo sự gia tăng hiệu suất của ensemble EMA kết hợp với một số phương pháp, cho thấy sự gia tăng hiệu suất nhất quán (lên đến 9.3% trên Split-MiniImagenet). Chúng tôi cũng tính toán các chỉ số đánh giá liên tục và nhất quán nhận thấy sự gia tăng lớn trong các chỉ số ổn định do việc sử dụng ensemble EMA (lên đến 32.3% trên Split-Cifar10). Chúng tôi hơn nữa quan sát một thiên vị gần đây của nhiệm vụ giảm của phương pháp EMA.

2 CÔNG TRÌNH LIÊN QUAN

2.1 HỌC TẬP LIÊN TỤC VÀ HỌC TẬP LIÊN TỤC TRỰC TUYẾN

Các kịch bản học tập liên tục phổ biến thường giả định rằng dữ liệu đến theo các batch lớn của dữ liệu i.i.d, với những thay đổi phân phối sắc nét xảy ra bất cứ khi nào một batch mới trở nên có sẵn. Chúng tôi gọi thiết lập này là học tập liên tục nhận biết ranh giới, do thông tin bổ sung được cung cấp bởi sự đến của một nhiệm vụ mới trong quá trình huấn luyện. Hầu hết tài liệu học tập liên tục tập trung vào thiết lập đó, hoặc bằng cách cũng cung cấp task-id tại thời điểm kiểm tra (De Lange et al., 2021) (học tập tăng dần theo nhiệm vụ), hoặc không (Masana et al., 2022) (học tập tăng dần theo lớp). Chúng tôi sẽ tập trung vào học tập tăng dần theo lớp trong bài báo này.

--- TRANG 3 ---
Được xuất bản tại Hội nghị thứ 2 về Các tác nhân học tập suốt đời (CoLLAs), 2023

Học tập liên tục trực tuyến không có ranh giới (Aljundi et al., 2019b) loại bỏ hình thức giám sát này bằng cách học trên một luồng các mini-batch nhỏ. Điều này có nghĩa là độ chi tiết của phân phối dữ liệu có thể được tinh chỉnh. Trong thực tế, có thể giữ các nhiệm vụ xác định độ chi tiết của phân phối, trong khi để tác nhân giả định phân phối này có thể thay đổi tại bất kỳ mini-batch mới nào. Đây là thiết lập mà chúng tôi thí nghiệm trong bài báo này. Trong MIR (Aljundi et al., 2019a), các tác giả giới thiệu một chiến lược lựa chọn cho phát lại và chọn các mẫu sẽ bị phạt nhiều nhất bởi bản cập nhật hiện tại. Trong ER-ACE (Caccia et al., 2022), mất mát entropy chéo bất đối xứng được sử dụng trên dữ liệu hiện tại, chỉ sử dụng các logit được biểu diễn trong mini-batch hiện tại, trong khi mất mát entropy chéo cổ điển được sử dụng trên bộ đệm phát lại. Zhang et al. (2022) chỉ ra rằng một baseline mạnh (được gọi là RAR) trong học tập liên tục trực tuyến là huấn luyện lặp lại trên batch có sẵn bằng cách lấy mẫu một batch phát lại mới và áp dụng các phép tăng cường dữ liệu. Trong bài báo này, chúng tôi đề xuất một cải tiến đơn giản cho các phương pháp này dựa trên kết hợp thời gian được áp dụng tại thời điểm đánh giá.

Các phương pháp học tập tăng dần theo lớp khác, cổ điển hơn có thể được sử dụng trong thiết lập này, miễn là chúng không yêu cầu kiến thức về ranh giới nhiệm vụ trong thời gian huấn luyện. Trong ICaRL (Rebuffi et al., 2017), một chiến lược lựa chọn để lưu trữ bộ đệm được lấy mẫu được sử dụng, cùng với một bộ phân loại trung bình gần nhất. Trong DER (Buzzega et al., 2020), cả các mẫu và logit của các mẫu này đều được lưu trữ và phát lại sử dụng tăng cường dữ liệu. Các lớp phương pháp khác như EEIL (Castro et al., 2018), thực hiện một bước cân bằng ở cuối huấn luyện trên mỗi nhiệm vụ, điều này khiến chúng không phù hợp với thiết lập không có ranh giới, trừ khi việc cân bằng được thực hiện trước mỗi phiên đánh giá, trong trường hợp đó nó có thể tăng đáng kể yêu cầu tính toán. Ngoài các phương pháp này, chúng tôi sẽ tập trung vào các phương pháp học tập liên tục trực tuyến trong bài báo này.

2.2 KẾT HỢP TRONG HỌC TẬP LIÊN TỤC VÀ KẾT HỢP THỜI GIAN

Tổng hợp các dự đoán đến từ nhiều mô hình được huấn luyện đã được biết từ lâu như một quá trình dẫn đến hiệu suất tăng so với việc sử dụng dự đoán của các mô hình riêng lẻ (Breiman, 1996). Nhóm các mô hình được huấn luyện sử dụng cho dự đoán được gọi là một ensemble các mô hình. Các ensemble như vậy đã được nghiên cứu rộng rãi trong tài liệu (Hansen & Salamon, 1990; Perrone & Cooper, 1995; Dietterich, 2000). Một số thách thức được liên kết với việc tạo ra các ensemble như vậy, và nhiều yêu cầu của các ensemble này ban đầu có vẻ không tương thích với các ràng buộc do học tập liên tục áp đặt. Đặc biệt, việc tạo ensemble ngây thơ đòi hỏi huấn luyện nhiều mô hình cần được lưu trữ trong bộ nhớ và huấn luyện độc lập, do đó vi phạm các ràng buộc về bộ nhớ và thời gian của học tập liên tục. Tuy nhiên, một số thách thức này đã được giải quyết trong tài liệu. Huang et al. (2017) giảm bớt ràng buộc phải huấn luyện các mô hình riêng biệt bằng cách sử dụng các checkpoint của cùng một lần chạy huấn luyện và một lịch trình tỷ lệ học tập tuần hoàn như các thành viên ensemble. Wortsman et al. (2021) huấn luyện không chỉ một mạng mà một không gian con tham số của các mạng mà họ có thể sử dụng để tạo một ensemble. Wen et al. (2020) phát triển BatchEnsemble, một cách hiệu quả về bộ nhớ để tạo ensemble các mô hình bằng cách học một ma trận trọng số chung cho tất cả các thành viên, và sau đó một ma trận hạng một cho mỗi thành viên. Một thành viên sau đó được tính toán như kết quả của tích Hadamard giữa ma trận chung và ma trận hạng một. Họ sau đó sử dụng kỹ thuật này trong học tập tăng dần theo nhiệm vụ, nơi họ học một thành viên cho mỗi nhiệm vụ để được sử dụng tại thời điểm kiểm tra. Doan et al. (2022) đặt nền tảng của học tập liên tục vượt ra ngoài việc sử dụng một mô hình duy nhất. Họ nghiên cứu các cách khả thi để học một ensemble các mô hình liên tục, và so sánh nhiều kỹ thuật kết hợp như BatchEnsemble Wen et al. (2020) hoặc Học không gian con Wortsman et al. (2021). Họ kết luận rằng kết hợp giúp ích trong thiết lập học tập tăng dần theo nhiệm vụ, và đề xuất một phương pháp sử dụng tính chất đó để tăng hiệu suất trong thiết lập đó. So với công việc của chúng tôi, họ tập trung nhiều hơn vào tác động của việc thêm nhiều mô hình vào ensemble nhưng không quá nhiều vào tác động của việc kết hợp các mô hình đến từ các nhiệm vụ khác nhau, và họ hoạt động trong thiết lập học tập tăng dần theo nhiệm vụ. Lee et al. (2017) đề xuất Khớp Moment Tăng dần, trong đó họ tính toán trung bình của các trọng số mô hình trong không gian trọng số, từ đó tạo ra một ensemble xấp xỉ. Trái ngược với công việc của chúng tôi, họ hoạt động trong thiết lập học tập tăng dần theo nhiệm vụ đơn giản hơn, trong đó task-ID có sẵn tại thời điểm kiểm tra.

Kết hợp thời gian (Samuli & Timo, 2017), là một kỹ thuật bao gồm việc kết hợp các dự đoán đến từ các mô hình khác nhau trên quỹ đạo huấn luyện. Trong công việc gốc, nó được thực hiện bằng cách giữ một trung bình động theo cấp số nhân của các dự đoán của mô hình trên dữ liệu huấn luyện, nhưng kỹ thuật này sau đó được tinh chỉnh trong (Tarvainen & Valpola, 2017), nơi các tác giả chọn giữ một trung bình chạy của các trọng số thay vì các dự đoán, và chỉ ra rằng điều này dẫn đến hiệu suất tương tự hoặc thậm chí tốt hơn, trong khi giảm bớt ràng buộc phải cập nhật dự đoán chạy cho mỗi điểm dữ liệu tại mỗi vòng lặp. Trong cả hai công việc này, dự đoán ensemble kết quả được sử dụng để cải thiện kết quả trong học bán giám sát, nơi chỉ một phần nhỏ nhãn mẫu có sẵn. Cùng mô hình Mean-teacher này cũng đã được sử dụng thành công trong một số công việc học tự giám sát (Grill et al., 2020; Caron et al., 2021). Trong bài báo này, chúng tôi nghiên cứu việc áp dụng ensemble thời gian rẻ cho thiết lập học tập liên tục trực tuyến.

--- TRANG 4 ---
Được xuất bản tại Hội nghị thứ 2 về Các tác nhân học tập suốt đời (CoLLAs), 2023

3 KIẾN THỨC CƠ BẢN

3.1 ĐÁNH GIÁ LIÊN TỤC VÀ KHOẢNG CÁCH ỔN ĐỊNH

Trong phân loại liên tục, một tác nhân học tập học các tham số θ∈Θ của một hàm f: (X,Θ)7→ Y từ không gian đầu vào hình ảnh X đến không gian nhãn Y. Nó thực hiện điều này bằng cách quan sát một luồng dữ liệu S={(x1, y1),(x2, y2), ...(xn, yn)}, trong đó x∈ X và y∈ Y. Mỗi tuple dữ liệu được rút ra từ một phân phối thay đổi theo thời gian (xt, yt)∼ D t. Trong học máy cổ điển, phân phối dữ liệu huấn luyện không phụ thuộc vào thời gian, nhưng điều này được thêm vào như một ràng buộc trong học tập liên tục. Trong cả hai trường hợp, mục tiêu của tác nhân là thực hiện tốt trên các mẫu mới được rút ra từ phân phối kết hợp D, được biên hóa qua thời gian trong quá khứ. Trong thực tế, học tập liên tục được đơn giản hóa để cho phép phân tích dễ dàng hơn bằng cách nghiên cứu các phân phối đến từ một tập hợp rời rạc và chuyển từ phân phối này sang phân phối khác (được gọi là nhiệm vụ t∈ {t1, ...tT}). Trong bài báo này, chúng tôi sẽ tập trung vào học tập tăng dần theo lớp, nơi người học không có quyền truy cập vào định danh nhiệm vụ t tại thời điểm suy luận.

Trong khi tất cả các đơn giản hóa trên đều có ý nghĩa, chúng vẫn còn xa với trải nghiệm học tập của con người, và từ việc phù hợp với yêu cầu của nhiều ứng dụng thực tế. So với điều trên, con người trải nghiệm các phân phối thay đổi liên tục theo thời gian và đánh giá liên tục. Để giải quyết điều này, Caccia et al. (2022) và Lange et al. (2023) đặt nền tảng và khuyến khích nghiên cứu đánh giá liên tục của mạng nơ-ron. Trong đánh giá liên tục, mô hình được đánh giá liên tục trong quá trình, thay vì sau mỗi nhiệm vụ. Thú vị là, họ nhận thấy rằng hiệu suất trên các nhiệm vụ trước đó thường giảm tại các lần chuyển nhiệm vụ trước khi trở lại giá trị cao hơn sau đó trong huấn luyện, đây là điều họ gọi là khoảng cách ổn định.

3.2 CÁC CHỈ SỐ ĐÁNH GIÁ LIÊN TỤC

Trong phần này, chúng tôi trình bày các chỉ số khác nhau được sử dụng trong thiết lập học tập liên tục trực tuyến và có thể giúp đo lường ổn định và tổng quát hơn, đánh giá hiệu suất của tác nhân trong suốt quá trình huấn luyện của nó. Chúng tôi ký hiệu A(Ei, ft) độ chính xác của ft (mô hình tại vòng lặp hiện tại t), trên nhiệm vụ đánh giá Ei. Chỉ số phổ biến nhất được sử dụng trong kịch bản này là độ chính xác trung bình bất cứ lúc nào, AAA t (Xem Eq. 1), được sử dụng trong nhiều công trình (Caccia et al., 2020; 2022; Koh et al., 2022). Trong khi chỉ số này không tập trung vào hiệu suất trường hợp xấu nhất, nó là một chỉ báo tốt về hiệu suất của tác nhân học tập trong suốt quá trình huấn luyện. Nó đo lường độ chính xác trung bình trên tất cả các nhiệm vụ đã thấy cho đến nay, và lấy trung bình qua tất cả các vòng lặp huấn luyện. Trong (Lange et al., 2023), một tập hợp các chỉ số được giới thiệu để đo lường hiệu suất trường hợp xấu nhất. Chúng đặc biệt phù hợp để đánh giá ổn định của các thuật toán. Họ trước tiên định nghĩa độ chính xác tối thiểu trung bình đạt được bởi các nhiệm vụ trước đó khi học nhiệm vụ Tk, min-ACC Tk (xem Eq. 2). Nó đưa ra một ý tưởng tốt về hiệu suất trường hợp xấu nhất của tác nhân trên một nhiệm vụ cho trước. Sau đó, độ chính xác trường hợp xấu nhất, WC-ACC t (xem Eq. 3), kết hợp thông tin từ độ chính xác tối thiểu trên các nhiệm vụ trước đó và độ chính xác trên nhiệm vụ hiện tại. WC-ACC t tóm tắt sự đánh đổi giữa ổn định (độ chính xác trên dữ liệu nhiệm vụ trước đó) và tính dẻo (độ chính xác trên dữ liệu nhiệm vụ hiện tại). Chỉ số này được giới hạn trên bởi độ chính xác trung bình. Ở đây, t là vòng lặp hiện tại, Tk nhiệm vụ hiện tại (tại vòng lặp t) và t|Ti| là vòng lặp ở cuối học Ti. Vì WC-ACC t được giới hạn trên bởi độ chính xác trung bình, chúng tôi cũng báo cáo một chỉ số mới là khoảng cách tương đối giữa chỉ số sau và độ chính xác trung bình Acct như được định nghĩa trong Phương trình 4, chúng tôi đặt tên nó là Khoảng cách Độ chính xác Tương đối (RAG) vì điều này đo lường khoảng cách tương đối giữa độ chính xác trường hợp xấu nhất và độ chính xác trung bình. Chỉ số này sau đó có thể được so sánh công bằng giữa các phương pháp khác nhau có độ chính xác trung bình khác nhau.

AAA t=1/t ∑(j=1 to t) 1/k ∑(i=1 to k) A(Ei, fj) (1)

min-ACC Tk=1/(k−1) ∑(i=1 to k-1) min{A(Ei, fn),∀n:t|Ti−1|< n≤t} (2)

WC-ACC t=1/k A(Ek, ft) + (1−1/k) min-ACC Tk (3)

Acct=1/k ∑(i=1 to k) A(Ei, ft) và RAG t=(Acct−WC-ACC t)/Acct (4)

--- TRANG 5 ---
Được xuất bản tại Hội nghị thứ 2 về Các tác nhân học tập suốt đời (CoLLAs), 2023

Phương pháp | Độ chính xác | Bộ nhớ (Mb)
ER | 26.2 | 4 + 211
ER Naive Ensemble | 32.1 | 1840 + 211
ER + EMA | 36.3 | 8 + 211

Bảng 1: So sánh trên Split-MiniImagenet (20 nhiệm vụ) của việc kết hợp ngây thơ các checkpoint được lấy dọc theo quỹ đạo huấn luyện của một phương pháp phát lại mỗi 10 vòng lặp, so với việc sử dụng ensemble EMA. Để rõ ràng, chúng tôi chia dấu chân bộ nhớ thành dấu chân cho các mô hình và dấu chân cho bộ đệm phát lại (mô hình + bộ đệm).

4 PHƯƠNG PHÁP: ENSEMBLE TRUNG BÌNH ĐỘNG THEO CẤP SỐ NHÂN (EMA)

Trong phần giới thiệu (xem Hình 1) chúng tôi đã chỉ ra rằng ensemble có thể cải thiện hiệu suất rất nhiều, tuy nhiên, chúng đi kèm với sự gia tăng đáng kể về sử dụng bộ nhớ, điều này trực tiếp xung đột với các yêu cầu bộ nhớ thường được áp đặt lên những người học liên tục. Thật vậy, cả học tập liên tục và học trực tuyến đều áp đặt các ràng buộc bộ nhớ vì chúng không cho phép giữ lại nhiều hơn một lượng dữ liệu cố định đến từ luồng dữ liệu. Do đó, trong phần này, chúng tôi xem xét các phương pháp để giảm sử dụng bộ nhớ, trong khi duy trì các lợi thế của việc kết hợp mô hình.

Một số công trình đã tập trung vào việc giảm ràng buộc bộ nhớ của ensemble Wen et al. (2020); Wortsman et al. (2021); Tarvainen & Valpola (2017), một số đã làm như vậy đáng chú ý bằng cách lấy trung bình các mô hình trong không gian trọng số thay vì tổng hợp các dự đoán trong không gian chức năng. Trong khi không rõ ràng dưới điều kiện nào việc thao tác các trọng số như vậy có thể tạo thành một mô hình hoạt động tương tự như ensemble của các thành viên được tổng hợp, một số công trình đã chỉ ra các trường hợp làm việc thực tế. Có thể thực hiện phép tổng như vậy (Wortsman et al., 2021) bất cứ khi nào hai mô hình được kết nối bằng một đường dẫn tuyến tính có mất mát thấp (Frankle et al., 2020). Tarvainen & Valpola (2017) thay vào đó đề xuất thực hiện tổng có trọng số của một lượng vô hạn các checkpoint bằng cách đưa ra trọng số ít quan trọng hơn cho các checkpoint cũ hơn, giảm theo cấp số nhân với khoảng cách.

Đối với việc sử dụng tiềm năng của các ensemble này trong học tập liên tục, chúng tôi quan tâm đến việc có một ensemble bao phủ nhiều nhiệm vụ (xem Phần 1), và một ensemble rẻ để lưu trữ và tính toán. Giải pháp được áp dụng trong (Tarvainen & Valpola, 2017), cho học bán giám sát, phù hợp tốt với nhiệm vụ này vì nó yêu cầu lưu trữ chỉ một mô hình bổ sung và có thể kết hợp các mô hình từ tất cả các vòng lặp trước đó. Xem xét một hàm f(x) =f(x, θt) với các trọng số có thể học θt (tại vòng lặp huấn luyện t), trung bình động theo cấp số nhân (EMA) của các trọng số của nó được định nghĩa là:

θt^ema=λθt−1^ema+ (1−λ)θt, (5)

trong đó λ là một siêu tham số do người dùng định nghĩa nằm giữa 0 và 1, thiết lập tầm quan trọng của mô hình hiện tại trong trung bình chạy so với mô hình của các mô hình trước đó, θt−1^ema là giá trị của trung bình động tại vòng lặp trước đó, và θt là trọng số của mô hình huấn luyện tại vòng lặp t (θt có thể được tính toán với các phương pháp trực tuyến hiện có, như ER (Chaudhry et al., 2019) hoặc MIR (Aljundi et al., 2019a). Định nghĩa ngầm này cũng có thể được viết như một tổng rõ ràng qua tất cả các trọng số mô hình trước đó:

θt^ema= ∑(i=1 to t) (1−λ)λt−i θi+λt θ0^ema. (6)

Điều này có nghĩa là ensemble được tạo thành bởi tổng bao phủ hầu như tất cả các nhiệm vụ đã gặp trước đó. Tuy nhiên, trọng số ít hơn theo cấp số nhân sẽ được dành cho các nhiệm vụ cũ hơn, có khả năng giảm sự đa dạng hiệu quả của ensemble. Tuy nhiên, thí nghiệm thúc đẩy mà chúng tôi tiến hành trên Split-Cifar100 cho thấy rằng sau một số nhiệm vụ được bao phủ bởi ensemble, độ chính xác đạt được bằng cách bao phủ ngày càng nhiều nhiệm vụ ít quan trọng hơn (tăng trưởng dưới tuyến tính). Vì vậy bao phủ một số ít nhiệm vụ với ensemble có thể đủ để có được lợi ích hiệu suất thỏa đáng. Điều này thúc đẩy chúng tôi phân tích mô hình trung bình động theo cấp số nhân trong thiết lập học tập liên tục trực tuyến.

Trong Bảng 1 chúng tôi so sánh Kết hợp Ngây thơ, được thảo luận trong Phần 1, với mô hình EMA khi kết hợp với Experience Replay Chaudhry et al. (2019). Như có thể thấy, mô hình EMA giảm đáng kể việc sử dụng bộ nhớ (chỉ yêu cầu một mô hình bổ sung). Đáng chú ý, ER+EMA vượt trội hơn Naive Ensemble. Điều này có thể do thực tế là ER+EMA kết hợp nhiều mô hình hơn, và vì việc gán trọng số phi tuyến tính cho các mô hình khác nhau (xem Hình 8 Phụ lục), nơi EMA gán nhiều trọng số hơn cho các mô hình cuối cùng (và tốt hơn) trong quỹ đạo huấn luyện.

Trong khi ensemble xấp xỉ EMA thường được sử dụng trong tài liệu và đã được chứng minh cho hiệu suất tốt (Tarvainen & Valpola, 2017; Grill et al., 2020; Caron et al., 2021). Các lược đồ tổng trọng số khác có thể được

--- TRANG 6 ---
Được xuất bản tại Hội nghị thứ 2 về Các tác nhân học tập suốt đời (CoLLAs), 2023

wi | ER | ER-ACE | RAR
- | - | 9.9±0.6 | 16.5±0.7 | 27.6±1.3
EMA λ= 0.99 | wi−1/λ | 14.0±0.5 | 19.0±0.3 | 35.4±1.2
EMA λ= 0.995 | wi−1/λ | 18.0 | 20.1 | 36.8
EMA λ= 0.999 | wi−1/λ | 18.3 | 18.8 | 31.2
Uniform | 1 | 13.1 | 12.7 | 17.3
Linear | i | 16.4 | 16.3 | 25.4
Logarithmic | wi−1+log(i) | 16.6 | 16.6 | 26.2
Quadratic | wi−1+i2 | 18.2 | 18.8 | 31.5

Bảng 2: So sánh các phương pháp kết hợp xấp xỉ khác nhau được lấy cảm hứng từ phương pháp kết hợp xấp xỉ EMA. Mỗi kỹ thuật kết hợp được thử trên Split-Cifar100 kết hợp với ER (Chaudhry et al., 2019) ER-ACE (Caccia et al., 2022), và RAR (Zhang et al., 2022). Cột thứ hai chỉ ra cách trọng số cho mô hình hiện tại được tính toán tại mỗi bước. Hàng đầu tiên chỉ ra kết quả khi không sử dụng kỹ thuật kết hợp nào.

thử để tính toán một ensemble xấp xỉ. Các lược đồ như vậy không nhất thiết được mong đợi sẽ hoạt động trong học offline cổ điển vì việc tổng các mô hình cách xa nhau trong không gian trọng số không được đảm bảo sẽ hoạt động. Tuy nhiên, vì học trực tuyến chỉ thực hiện một vài vòng lặp huấn luyện trên nhiệm vụ hiện tại (so với học offline), chúng ta có thể mong đợi các mô hình gần nhau hơn và do đó cho phép các kỹ thuật tổng khác hoạt động. Để khám phá khả năng của các kỹ thuật tổng như vậy trong học liên tục trực tuyến, chúng tôi so sánh một số kỹ thuật gán trọng số. Vì chúng tôi đang làm việc trong thiết lập học trực tuyến và dưới ràng buộc chỉ lưu trữ một mô hình bổ sung, chúng tôi chọn tính toán ensemble xấp xỉ theo Phương trình 7,

θt^ensemble = 1/(∑i wi) ∑i wi θi, (7)

và sử dụng ensemble này thay vì ensemble EMA. Công thức này cho phép tự do hơn trong việc lựa chọn lược đồ gán trọng số, nhưng công thức được sử dụng bởi EMA cũng có thể được biểu diễn dưới dạng này, chúng tôi xác định trọng số tương đương wi cho ensemble EMA sử dụng Phương trình 6 là wi=wi−1/λ. Chúng tôi cập nhật tại mỗi vòng lặp tổng có trọng số của các mô hình và chuẩn hóa nó bằng tổng các trọng số để tránh trọng số mô hình bùng nổ. Trong Phụ lục (Hình 11) chúng tôi cung cấp so sánh phân phối trọng số cho các chiến lược khác nhau mà chúng tôi đã thử.

Trong Bảng 2, chúng tôi trình bày kết quả của việc kết hợp ensemble được tính toán với mỗi lược đồ gán trọng số với ba phương pháp từ tài liệu trên bộ dữ liệu Split-Cifar100 (Xem Phần 5 để giải thích về thiết lập thí nghiệm). Chúng ta thấy rằng mô hình EMA có hiệu suất tốt nhất tổng thể, đặc biệt với λ= 0.9951. Tuy nhiên, chúng tôi có kết quả cao một cách đáng ngạc nhiên với gán trọng số tuyến tính, logarit, và bậc hai, đặc biệt khi kết hợp với ER, nhưng gán trọng số tuyến tính và logarit thất bại trong việc đưa ra lợi thế khi kết hợp với các phương pháp tiên tiến hơn ER-ACE và RAR. Gán trọng số bậc hai có được kết quả gần nhất với các phương pháp EMA, chúng tôi cung cấp so sánh chi tiết hơn về Bậc hai so với phương pháp EMA trong Phụ lục (Hình. 12). Gán trọng số đồng nhất là lược đồ hoạt động tệ nhất trên toàn bộ, điều này có thể được hiểu vì nó đưa ra trọng số bằng nhau cho các mô hình đầu tiên so với các mô hình cuối cùng trong khi các mô hình cuối cùng đã được huấn luyện trong thời gian dài hơn và do đó được mong đợi có hiệu suất tốt hơn.

5 THÍ NGHIỆM

Bộ dữ liệu. Chúng tôi thực hiện thí nghiệm trên 3 bộ dữ liệu. Cifar-10 là bộ dữ liệu 10 lớp chứa 60000 hình ảnh kích thước 32 x 32 và 3 kênh màu (Krizhevsky, 2009). Cifar-100 có cùng kích thước hình ảnh và số lượng hình ảnh nhưng với 100 lớp. Mini-Imagenet (Vinyals et al., 2016) là phiên bản 100 lớp của ImageNet (Russakovsky et al., 2015), chứa 60000 hình ảnh được thay đổi kích thước về 84 x 84. Chúng tôi chia các bộ dữ liệu này thành 5, 20 và 20 nhiệm vụ tương ứng, mỗi nhiệm vụ chứa một tập hợp các lớp loại trừ lẫn nhau.

Kịch bản. Chúng tôi trình bày kết quả trong thiết lập tăng dần theo lớp trực tuyến. Khi đánh giá liên tục được thực hiện, chúng tôi đánh giá sau mỗi mini-batch duy nhất. Tất cả các phương pháp được so sánh đều sử dụng bộ đệm phát lại, với kích thước bộ nhớ cố định là 1000 mẫu cho Cifar-10, 2000 mẫu cho Cifar-100 và 10000 cho Mini-Imagenet (như trong (Caccia et al., 2022)). Mỗi mini-batch huấn luyện được tạo thành từ một nửa mẫu từ các nhiệm vụ trước đó và một nửa từ nhiệm vụ hiện tại.

Phương pháp. Chúng tôi so sánh hiệu suất của năm phương pháp phát lại. ER-ACE (Caccia et al., 2022), MIR (Aljundi et al., 2019a), RAR (Zhang et al., 2022), DER (Buzzega et al., 2020) được mô tả trong Phần 2.1, trong khi ER (Chaudhry

1Các tham số này không phải là những tham số chúng tôi sử dụng trong kết quả chính của Phần 6 (chúng tôi sử dụng λ= 0.99). Để thảo luận về lựa chọn siêu tham số, tham khảo Phần A.1

--- TRANG 7 ---
Được xuất bản tại Hội nghị thứ 2 về Các tác nhân học tập suốt đời (CoLLAs), 2023

Hình 2: Độ chính xác xác thực trên dữ liệu nhiệm vụ 1 (Trái), Độ chính xác Trung bình Bất cứ lúc nào AAA t (Giữa) và WC-ACC t (Phải) cho ER-ACE và phiên bản tăng cường EMA của nó trên Split-Cifar100, sử dụng bộ nhớ 2000. Trung bình và độ lệch chuẩn được tính toán qua 6 lần chạy.

et al., 2019) là baseline phát lại vanilla. Chúng tôi hiển thị hiệu suất của chúng cùng với phiên bản tăng cường EMA của chúng trên các bộ dữ liệu được nghiên cứu. Ngoài ra, chúng tôi báo cáo kết quả của phương pháp tham chiếu i.i.d được cho phép cùng ngân sách bộ nhớ và tính toán như các phương pháp được so sánh, nhưng dữ liệu đến theo cách độc lập và phân phối giống hệt nhau (trái ngược với cách học liên tục nơi dữ liệu đến theo từng phần). Vì một số phương pháp được bao gồm trong so sánh sử dụng các phép biến đổi đầu vào (RAR), chúng tôi cũng bao gồm kết quả của phương pháp tham chiếu i.i.dw/tr, sử dụng cùng các phép biến đổi đầu vào.

Chi tiết Huấn luyện và Triển khai. Đối với tất cả bộ dữ liệu, chúng tôi sử dụng phiên bản mỏng của Resnet-18 như được thực hiện trong (Lopez-Paz & Ranzato, 2017) và thực hiện 3 lần đi qua mỗi mini-batch sử dụng Gradient Descent Stochastic với tỷ lệ học 0.1, và kích thước batch 32. Chúng tôi chạy mỗi thí nghiệm cho sáu seed và báo cáo trung bình và độ lệch chuẩn. Đối với DER, chúng tôi tuân thủ các tham số được sử dụng trong bài báo gốc cho CIFAR10 (α= 0.1 và β= 0.5). Đối với ensemble EMA, chúng tôi chọn tham số momentum λ= 0.99. Chi tiết thêm về việc lựa chọn tham số này có thể được tìm thấy trong Phần Phụ lục A.1. Chúng tôi sử dụng framework Avalanche (Lomonaco et al., 2021) cho tất cả thí nghiệm. Chúng tôi cung cấp mã tại: https://github.com/AlbinSou/online_ema .

Chỉ số. Đối với mỗi phương pháp, chúng tôi báo cáo độ chính xác trung bình cuối cùng nhưng cũng các chỉ số đánh giá liên tục được mô tả trong Phần 3.2, mà chúng tôi tính toán trên tập xác thực riêng biệt sau khi huấn luyện trên mỗi mini-batch mới. Bộ dữ liệu xác thực chứa 5% tổng dữ liệu huấn luyện. Chúng tôi báo cáo cả AAA Tfinal và WC-ACC Tfinal trong các bảng, nơi Tfinal là vòng lặp huấn luyện cuối cùng. Chúng tôi cũng báo cáo WC-ACC t tại mỗi vòng lặp trong các hình. Giá trị cuối cùng của chỉ số RAG mà chúng tôi định nghĩa trong Phương trình 4 được báo cáo theo phần trăm. Lưu ý rằng chúng tôi không sử dụng dữ liệu xác thực này để điều chỉnh siêu tham số mà chỉ để tính toán các chỉ số đánh giá liên tục.

6 KẾT QUẢ

Trên Split-Cifar10 ensemble EMA cung cấp cải thiện nhất quán trên tất cả phương pháp (xem Bảng 3), đặc biệt cho RAR, nơi nó cung cấp cải thiện 4.3% trong độ chính xác trung bình cuối cùng. Chúng tôi giả thuyết rằng lợi ích của EMA nhỏ hơn so với Split-Cifar100 và Split-MiniImagenet vì trong trường hợp đó trọng số ensemble EMA bao phủ ít nhiệm vụ hơn so với trường hợp của hai bộ dữ liệu khác (5 nhiệm vụ nhưng cùng số vòng lặp huấn luyện như Split-Cifar100). Tuy nhiên, các chỉ số ổn định được cải thiện rất nhiều cũng cho bộ dữ liệu này.

Trên Split-Cifar100 (Xem Bảng 3) ensemble EMA cung cấp cải thiện đáng kể cho ER, RAR, DER và MIR (từ 4.0-7.8%). Các cải thiện ít hệ quả hơn cho ER-ACE, nhưng vẫn quan trọng (2.5%). Chúng tôi giả thuyết rằng lợi ích nhỏ hơn là do thiên vị gần đây của nhiệm vụ nhỏ hơn của ER-ACE. Điều này được minh họa trong Hình 2 và Hình 3. Trong hai hình này ở bên trái, chúng ta thấy rằng hiệu suất của RAR trên dữ liệu nhiệm vụ 1 giảm ngay lập tức sau khi học nhiệm vụ 1, có nghĩa là nó đã được đánh đổi lấy độ chính xác trên nhiệm vụ 2, nó gặp phải thiên vị gần đây của nhiệm vụ. Trong khi đối với ER-ACE, hiệu suất trên nhiệm vụ 1 không giảm nhiều sau khi học nhiệm vụ 1, do đó khoảng cách với phiên bản tăng cường EMA không quan trọng bằng. Điều này cũng được phản ánh trong Bảng 3. Trong các hình này cũng vậy, chúng ta có thể thấy cách sử dụng mô hình EMA cải thiện ổn định, cả bằng cách nhìn vào WC-Acc mà còn bằng các biến động độ chính xác giảm trên một nhiệm vụ duy nhất.

Trên Split-MiniImagenet, chúng ta thấy cải thiện hiệu suất lớn nhất. Lần này, RAR thấy lợi ích tương tự như ER (9.3% và 10%), trong khi lợi ích ER-ACE cũng quan trọng hơn so với trường hợp Split-Cifar100. Điều này phù hợp với quan sát mà chúng tôi có trong các thí nghiệm thúc đẩy (Hình 1) rằng lợi ích từ kết hợp hơi quan trọng hơn trong trường hợp Split-MiniImagenet. Điều này cũng có thể do kích thước bộ nhớ được sử dụng khác với kích thước được sử dụng cho Split-Cifar100. Trong Hình 4, chúng tôi hiển thị so sánh ba phương pháp và phiên bản tăng cường EMA của chúng. Chúng tôi nhận thấy rằng trong trường hợp đó, việc sử dụng ER-ACE làm tổn hại hiệu suất của mô hình EMA, có hiệu suất tệ hơn so với chỉ sử dụng ER và EMA. Ngoài ra, đối với ER và RAR, chúng tôi nhận thấy các đợt tăng khác nhau trong độ chính xác xác thực2 của mô hình EMA mà không có trong độ chính xác mô hình hiện tại. Chúng tôi tin rằng các đợt tăng này xảy ra khi thiên vị nhiệm vụ trước đó được bù đắp bởi thiên vị hướng về nhiệm vụ hiện tại. Vị trí và độ rộng của các đợt tăng này phụ thuộc vào tham số λ được chọn cho trung bình động theo cấp số nhân (để phân tích thêm xem Phụ lục 7).

Tác động lên thiên vị gần đây của nhiệm vụ: Trong Hình 6, chúng tôi hiển thị ma trận nhầm lẫn nhiệm vụ của RAR, cho mô hình huấn luyện cuối cùng, mô hình EMA cuối cùng, và mô hình EMA được lấy tại đỉnh của đợt tăng (được chọn sử dụng cơ chế bộ nhớ xác thực tách biệt). Ma trận cho thấy số lượng hình ảnh kiểm tra từ một nhiệm vụ cụ thể (trục y) được phân loại là từ nhiệm vụ khác (trục x). Đối với mô hình huấn luyện cuối cùng, rất nhiều mẫu được dự đoán là trong nhiệm vụ cuối cùng như được chỉ ra bởi cột cuối cùng, cho thấy thiên vị gần đây của nhiệm vụ quan trọng. Đối với mô hình EMA cuối cùng, thiên vị gần đây của nhiệm vụ

2Tổng quát hơn chúng tôi quan sát những đợt tăng này trên tất cả các bộ dữ liệu được nghiên cứu và báo cáo chúng cho Split-MiniImagenet và Split-Cifar100 trong Hình 4 và Hình 7 của Phụ lục

--- TRANG 8 ---
Được xuất bản tại Hội nghị thứ 2 về Các tác nhân học tập suốt đời (CoLLAs), 2023

Hình 3: Split-Cifar100, độ chính xác xác thực trên dữ liệu nhiệm vụ 1 (Trái), Độ chính xác Trung bình Bất cứ lúc nào AAA t (Giữa) và WC-ACC (Phải), cho RAR và phiên bản tăng cường EMA của nó, sử dụng bộ nhớ 2000. Trung bình và độ lệch chuẩn được tính toán qua 6 lần chạy.

[Hình 4 cho thấy biểu đồ so sánh độ chính xác trung bình trên dữ liệu xác thực của ba phương pháp được huấn luyện trên Split-MiniImagenet (20 nhiệm vụ), và phiên bản tăng cường EMA của chúng. Hiệu suất EMA được chỉ ra bằng các đường đứt quãng. Chúng tôi báo cáo trung bình và độ lệch chuẩn qua 6 lần chạy.]

cũng hiện diện mặc dù hơi giảm, nhưng đối với mô hình EMA được chọn tốt nhất, nó gần như vắng mặt, xác nhận giả thuyết của chúng tôi về nguồn gốc của đợt tăng3.

3Lưu ý rằng tất cả kết quả của chúng tôi dựa trên điểm kết thúc của huấn luyện, thường không trùng với đợt tăng.

--- TRANG 9 ---
Được xuất bản tại Hội nghị thứ 2 về Các tác nhân học tập suốt đời (CoLLAs), 2023

[Bảng 3 và 4 hiển thị so sánh độ chính xác trung bình cuối cùng trên tập kiểm tra và các chỉ số đánh giá liên tục trên tập xác thực cho các phương pháp khác nhau với phiên bản tăng cường mô hình EMA của chúng, trên Split Cifar10, Split Cifar100 và Split-MiniImagenet]

[Hình 5 so sánh phương pháp tiên tiến trước đây trong học liên tục trực tuyến RAR với phương pháp tham chiếu i.i.dw/tr trên Split-Cifar100 và Split-Minimnet. Khoảng cách hiệu suất được chỉ ra bằng màu xanh lá cây, và được giảm đáng kể bằng việc sử dụng EMA.]

So sánh với lợi ích trong thiết lập i.i.d trực tuyến: Khi được áp dụng trên các phương pháp tham chiếu i.i.d và i.i.dw/tr, việc sử dụng mô hình EMA tại đánh giá cũng cải thiện kết quả một cách tốt, cho thấy rằng lợi ích có được trong học liên tục không chỉ do cải thiện dựa trên học-liên-tục (như giảm thiên vị gần đây của nhiệm vụ), mà còn trên cải thiện học-trực-tuyến tổng quát hơn. Tuy nhiên, chúng tôi quan sát nói chung lợi ích cao hơn trong học liên tục so với trong thiết lập i.i.d, ngoại trừ trên Split-Cifar10, nơi chúng tương đương, cho thấy rằng việc thích ứng tham số momentum với tốc độ drift phân phối là cần thiết để có được lợi ích liên quan đến học liên tục. Để minh họa lợi ích cao hơn trong học liên tục, chúng tôi làm nổi bật khoảng cách trong độ chính xác cuối cùng giữa phương pháp tiên tiến trước đây (RAR), và baseline i.i.dw/tr, cùng với các phiên bản tăng cường EMA (Xem Hình 5). Chúng ta thấy rằng cho hai trong số các bộ dữ liệu được nghiên cứu, khoảng cách giữa RAR và i.i.dw/tr được giảm bởi việc sử dụng mô hình EMA. Đối với Split-Cifar100, khoảng cách ban đầu 4.7% được giảm xuống khoảng cách 1.8%, trong khi đối với Split-MiniImagenet, khoảng cách ban đầu 3.2% được giảm xuống khoảng cách 1.5%.

Tác động lên các chỉ số ổn định: Cuối cùng, đối với tất cả phương pháp và trên tất cả bộ dữ liệu, AAA và WC-Acc được cải thiện rất nhiều bởi việc sử dụng EMA, cho thấy rằng ngoài việc nâng cao độ chính xác, mô hình EMA cung cấp sự tăng cường ổn định quan trọng. Chúng tôi minh họa hiệu ứng này bằng cách hiển thị một đường cong độ chính xác nhiệm vụ đơn lẻ cùng với đường cong WC-Acc trong quá trình huấn luyện trong Hình 2 và Hình 3. Chúng ta thấy rằng trong cả hai trường hợp cả những biến động do huấn luyện batch nhỏ và những biến động lớn hơn do chuyển nhiệm vụ đều được giảm bởi việc sử dụng ensemble EMA. Chúng tôi cũng trình bày phân tích chi tiết về ổn định ở cấp độ chuyển nhiệm vụ đơn lẻ trong Phụ lục (Hình 10). Nói chung, sự gia tăng lớn nhất trong WC-Acc cũng tương ứng với sự giảm lớn nhất trong Khoảng cách Độ chính xác Tương đối (RAG), và có ý nghĩa, xác nhận rằng sự gia tăng trong WC-Acc không phải do sự gia tăng trong độ chính xác trung bình, mà do ổn định tốt hơn.

--- TRANG 10 ---
Được xuất bản tại Hội nghị thứ 2 về Các tác nhân học tập suốt đời (CoLLAs), 2023

[Hình 6 hiển thị Ma trận Nhầm lẫn Nhiệm vụ được tính toán trên tập kiểm tra sau khi huấn luyện nhiệm vụ cuối cùng cho RAR trên Split-MiniImagenet (20 nhiệm vụ), mô hình huấn luyện cuối cùng (Trái), mô hình RAR+EMA (Giữa), và mô hình RAR+EMA được lấy tại đỉnh của các đợt tăng quan sát trong Hình 4 (Phải). Lưu ý sự giảm thiên vị gần đây của nhiệm vụ từ RAR (a) đến RAR+EMA (b) như hệ quả của việc kết hợp.]

7 KẾT LUẬN

Chúng tôi điều tra tác động của việc sử dụng các phương pháp kết hợp thời gian, như EMA, trong học liên tục trực tuyến. Hướng này đặc biệt thú vị vì tính chất đặc biệt của sự kết hợp này. Trong học liên tục trực tuyến, ensemble thời gian cung cấp tiềm năng kết hợp các mô hình từ các nhiệm vụ huấn luyện khác nhau, dẫn đến động lực mới không thể đạt được trong học offline cổ điển, nơi mỗi ensemble mô hình được huấn luyện trên cùng phân phối. Trong các thí nghiệm, chúng tôi chỉ ra rằng ensemble thời gian có thể cải thiện rất nhiều hiệu suất và ổn định học liên tục. Để tránh các yêu cầu bộ nhớ tăng cho việc sử dụng ensemble, chúng tôi đề xuất sử dụng một giải pháp kết hợp hiệu quả về bộ nhớ cho học liên tục trực tuyến. Chúng tôi báo cáo kết quả sử dụng phương pháp này kết hợp với các phương pháp tiên tiến khác và kết luận rằng phương pháp này nhất quán tăng hiệu suất cuối cùng và ổn định tổng thể của một số phương pháp phát lại, tiến gần hơn đến hiệu suất có thể đạt được trong thiết lập i.i.d. Đáng ngạc nhiên nhất, chúng tôi làm điều này mà không ảnh hưởng đến quá trình huấn luyện mà chỉ bằng cách kết hợp các mô hình từ quỹ đạo huấn luyện.

Chúng tôi hy vọng rằng công việc này truyền cảm hứng cho việc thiết kế các phương pháp kết hợp mạnh mẽ hơn cho học liên tục. Đặc biệt, sẽ quan trọng là tìm một phương pháp hiệu quả tương tự cho phép tách rời số vòng lặp huấn luyện khỏi số nhiệm vụ, vì khi đó nó có thể được áp dụng cho số vòng lặp tùy ý mỗi nhiệm vụ trong khi tương tự bao phủ càng nhiều nhiệm vụ trước đó càng tốt. Một hướng tương lai khác có thể tập trung vào việc tác động đến huấn luyện sử dụng loại ensemble như vậy, ví dụ bằng cách kết hợp nó với chưng cất4.

Lời cảm ơn: Chúng tôi ghi nhận sự hỗ trợ của Đề án PID2019-104174GB-I00 được tài trợ bởi MCIN/AEI/ 10.13039/501100011033 và Đề án PID2021-128178OB-I00 được tài trợ bởi MCIN/AEI/ 10.13039/501100011033 và bởi ERDF A way of making Europe, học bổng Ramón y Cajal Đề án RYC2019-027020-I được tài trợ bởi MCIN/AEI/

4Chúng tôi cung cấp nhận xét về việc áp dụng chưng cất kết hợp với mô hình EMA trong Phụ lục (Phần A.4).

--- TRANG 11 ---
Được xuất bản tại Hội nghị thứ 2 về Các tác nhân học tập suốt đời (CoLLAs), 2023

10.13039/501100011033 và bởi ERDF A way of making Europe, và Chương trình CERCA của Generalitat de Catalunya. Antonio Carta được hỗ trợ một phần bởi dự án H2020 TAILOR (952215) Connectivity Fund.

TÀI LIỆU THAM KHẢO

[Danh sách tài liệu tham khảo dài với các trích dẫn học thuật]

--- TRANG 12-18 ---
[Các trang còn lại chứa phần Phụ lục với các chi tiết bổ sung, bảng so sánh, và hình ảnh minh họa thêm về các thí nghiệm và phân tích]

A PHỤ LỤC

A.1 CHI TIẾT VỀ VIỆC LỰA CHỌN SIÊU THAM SỐ CHO MÔ HÌNH EMA

[Phần phụ lục tiếp tục với các chi tiết kỹ thuật, biểu đồ bổ sung, và phân tích sâu hơn về các thí nghiệm]

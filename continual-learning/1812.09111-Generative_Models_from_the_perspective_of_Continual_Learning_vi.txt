# Các Mô hình Sinh từ góc nhìn của Học Liên tục
Timothée Lesort;1;2, Hugo Caselles-Dupré;1;3, Michael Garcia-Ortiz3, Andrei Stoian2, David Filliat1

Tóm tắt — Mô hình sinh nào phù hợp nhất cho Học Liên tục? Bài báo này nhằm đánh giá và so sánh các mô hình sinh trên các tác vụ sinh ảnh tuần tự rời rạc. Chúng tôi nghiên cứu cách một số mô hình học và quên, xem xét các chiến lược khác nhau: luyện lại, điều chuẩn, phát lại sinh và tinh chỉnh. Chúng tôi sử dụng hai thước đo định lượng để ước tính chất lượng sinh và khả năng ghi nhớ. Chúng tôi thực nghiệm với các tác vụ tuần tự trên ba benchmark thường được sử dụng cho Học Liên tục (MNIST, Fashion MNIST và CIFAR10). Chúng tôi phát hiện rằng trong tất cả các mô hình, GAN gốc hoạt động tốt nhất và trong các chiến lược Học Liên tục, phát lại sinh vượt trội hơn tất cả các phương pháp khác. Mặc dù chúng tôi tìm thấy các kết hợp thỏa mãn trên MNIST và Fashion MNIST, việc huấn luyện các mô hình sinh tuần tự trên CIFAR10 đặc biệt không ổn định và vẫn là một thách thức. Mã của chúng tôi có sẵn trực tuyến1.

I. GIỚI THIỆU

Học theo cách liên tục là một khía cạnh quan trọng cho sự phát triển nhận thức trong các loài sinh vật [1]. Trong Học Máy, tình huống học tập như vậy đã được chính thức hóa như một thiết lập Học Liên tục (CL) [2, 3, 4, 5, 6]. Mục tiêu của CL là học từ một phân phối dữ liệu thay đổi theo thời gian mà không quên thông tin quan trọng. Thật không may, các mạng nơ-ron được huấn luyện bằng lan truyền ngược không thể giữ lại thông tin đã học trước đó khi phân phối dữ liệu thay đổi, một vấn đề khét tiếng gọi là "quên thảm khốc" [7]. Những nỗ lực thành công trong CL với mạng nơ-ron phải vượt qua việc quên không thể tránh khỏi xảy ra khi các tác vụ thay đổi.

Trong bài báo này, chúng tôi tập trung vào các mô hình sinh trong các tình huống Học Liên tục. Công trình trước đây về CL chủ yếu tập trung vào các tác vụ phân loại [8, 9, 5, 6]. Các phương pháp truyền thống là các chiến lược điều chuẩn, luyện lại và kiến trúc, như được mô tả trong Phần II. Tuy nhiên, các mô hình phân biệt và sinh khác nhau rất nhiều về kiến trúc và mục tiêu học tập. Một số phương pháp được phát triển cho các mô hình phân biệt do đó không thể mở rộng trực tiếp sang thiết lập sinh.

Các mô hình sinh có thể được sử dụng như bộ nhớ của quá khứ để học liên tục, đặc biệt trong học tăng cường và phân loại. Ví dụ, các chiến lược CL thành công với các mô hình sinh đã được sử dụng, thông qua việc sinh mẫu như được chi tiết trong phần tiếp theo, để huấn luyện liên tục các mô hình phân biệt. Do đó, nghiên cứu tính khả thi và các chế độ thành công/thất bại của các chiến lược CL cho các mô hình sinh là một bước quan trọng hướng tới hiểu biết tốt hơn về các mô hình sinh và Học Liên tục nói chung.

Chúng tôi tiến hành một nghiên cứu so sánh các mô hình sinh với các chiến lược CL khác nhau. Trong các thí nghiệm của chúng tôi, chúng tôi học tuần tự các tác vụ sinh. Chúng tôi thực hiện mười tác vụ rời rạc, sử dụng các benchmark thường được sử dụng cho CL: MNIST [10], Fashion MNIST [11] và CIFAR10 [12]. Trong mỗi tác vụ, mô hình nhận được một tập huấn luyện từ một lớp mới và nên học sinh dữ liệu từ lớp này mà không quên những gì đã học trong các tác vụ trước, xem Hình 1 để có ví dụ với các tác vụ trên MNIST.

Chúng tôi đánh giá một số mô hình sinh: Bộ Mã hóa Tự động Biến phân (VAEs), Mạng Đối kháng Sinh (GANs), biến thể có điều kiện của chúng (CVAE và CGAN), Wasserstein GANs (WGANs) và Wasserstein GANs Gradient Penalty (WGAN-GP). Chúng tôi so sánh kết quả trên các phương pháp được lấy từ CL trong thiết lập phân loại: tinh chỉnh, luyện lại, điều chuẩn và phát lại sinh. Phát lại sinh bao gồm việc sử dụng các mẫu được sinh ra để duy trì kiến thức từ các tác vụ trước. Tất cả các phương pháp CL đều có thể áp dụng cho cả khung biến phân và đối kháng. Chúng tôi đánh giá bằng hai thước đo định lượng, Khoảng cách Fréchet Inception [13] và Khả năng Khớp [14], cũng như trực quan hóa. Ngoài ra, chúng tôi thảo luận về tính khả dụng dữ liệu và khả năng mở rộng của các chiến lược CL.

Đóng góp của chúng tôi là:
- Đánh giá một loạt rộng các mô hình sinh trong thiết lập Học Liên tục.
- Làm nổi bật các chế độ thành công/thất bại của các kết hợp giữa mô hình sinh và phương pháp CL.
- So sánh, trong thiết lập CL, hai thước đo đánh giá của các mô hình sinh.

Chúng tôi mô tả công trình liên quan trong Phần II và phương pháp của chúng tôi trong Phần III. Chúng tôi giải thích thiết lập thí nghiệm thực hiện phương pháp của chúng tôi trong Phần IV. Cuối cùng, chúng tôi trình bày kết quả và thảo luận trong Phần V và VI, trước khi kết luận trong Phần VII.

II. CÔNG TRÌNH LIÊN QUAN

A. Học Liên tục cho các mô hình phân biệt

Học Liên tục chủ yếu được áp dụng cho các tác vụ phân biệt. Trong tình huống này, các tác vụ phân loại được học tuần tự. Cuối chuỗi, mô hình phân biệt nên có thể giải quyết tất cả các tác vụ. Phương pháp ngây thơ của tinh chỉnh từ tác vụ này sang tác vụ tiếp theo dẫn đến quên thảm khốc [7], tức là không có khả năng giữ hiệu suất ban đầu trên các tác vụ trước. Các phương pháp được đề xuất trước đây có thể được phân loại thành bốn phương pháp chính.

Phương pháp đầu tiên, được gọi là luyện lại, là giữ các mẫu từ các tác vụ trước. Các mẫu sau đó có thể được sử dụng theo các cách khác nhau để vượt qua việc quên. Phương pháp này không thể được sử dụng trong tình huống mà dữ liệu từ các tác vụ trước không có sẵn, nhưng nó vẫn là một đường cơ sở cạnh tranh [9, 3]. Hơn nữa, khả năng mở rộng của phương pháp này cũng có thể bị đặt câu hỏi vì bộ nhớ cần thiết để lưu trữ mẫu tăng tuyến tính với số lượng tác vụ.

Phương pháp thứ hai sử dụng điều chuẩn. Điều chuẩn ràng buộc việc cập nhật trọng số để duy trì kiến thức từ các tác vụ trước và do đó tránh quên. Elastic Weight Consolidation (EWC) [8] đã trở thành phương pháp tiêu chuẩn cho loại điều chuẩn này. Nó ước tính tầm quan trọng của các trọng số và điều chỉnh điều chuẩn tương ứng. Các mở rộng của EWC đã được đề xuất, chẳng hạn như EWC trực tuyến [6]. Một phương pháp điều chuẩn nổi tiếng khác là chưng cất, nó chuyển giao kiến thức đã học trước đó sang một mô hình mới. Ban đầu được đề xuất bởi [15], nó đã trở nên phổ biến trong CL [16, 9, 17, 5] vì nó cho phép mô hình học về các tác vụ trước và tác vụ hiện tại cùng một lúc.

Phương pháp thứ ba là sử dụng kiến trúc động để duy trì kiến thức quá khứ và học thông tin mới. Các phương pháp đáng chú ý thực hiện phương pháp này là Progressive Networks [18], Learning Without Forgetting (LWF) [19] và PathNet [20].

Phương pháp thứ tư và gần đây hơn là phát lại sinh [5, 21], trong đó một mô hình sinh được sử dụng để tạo ra các mẫu từ các tác vụ trước. Phương pháp này cũng được gọi là pseudo-rehearsal.

B. Học liên tục cho các mô hình sinh

Các mô hình phân biệt và sinh không chia sẻ cùng mục tiêu học tập và kiến trúc. Vì lý do này, các chiến lược CL cho các mô hình phân biệt thường không thể áp dụng trực tiếp cho các mô hình sinh. Học Liên tục trong bối cảnh các mô hình sinh vẫn còn ít được khám phá so với CL cho các mô hình phân biệt.

Trong số các công trình đáng chú ý trước đây, [4] thành công áp dụng EWC trên generator của Conditional-GANs (CGANS), sau khi quan sát rằng áp dụng cùng một sơ đồ điều chuẩn cho GAN cổ điển dẫn đến quên thảm khốc. Tuy nhiên, công trình của họ dựa trên tình huống mà hai lớp được trình bày đầu tiên, và sau đó các lớp duy nhất đến tuần tự, ví dụ tác vụ đầu tiên bao gồm các chữ số 0 và 1 của tập dữ liệu MNIST, và sau đó được trình bày với chỉ một chữ số tại một thời điểm trong các tác vụ tiếp theo. Điều này có thể do sự thất bại của CGANs trên các chữ số đơn, mà chúng tôi quan sát trong các thí nghiệm của mình. Hơn nữa, phương pháp được chỉ ra là chỉ hoạt động trên CGANs. Một phương pháp khác cho Học Liên tục sinh là Variational Continual Learning (VCL) [3], nó điều chỉnh suy luận biến phân cho thiết lập liên tục. Họ khai thác việc cập nhật trực tuyến từ tác vụ này sang tác vụ khác được lấy cảm hứng từ quy tắc Bayes. Họ thành công thí nghiệm trên tình huống tác vụ đơn. Tuy nhiên, họ chỉ thí nghiệm trên VAEs. Thêm vào đó, vì họ sử dụng kiến trúc đa đầu, họ sử dụng các trọng số cụ thể cho mỗi tác vụ, cần chỉ số tác vụ để suy luận. Một phương pháp thứ hai được thí nghiệm trên VAEs là sử dụng phương pháp học sinh-giáo viên trong đó học sinh học tác vụ hiện tại trong khi giáo viên giữ lại kiến thức [22]. Cuối cùng, VASE [23] là phương pháp thứ ba, cũng chỉ được thí nghiệm trên VAEs, nó phân bổ dung lượng biểu diễn dự phòng cho kiến thức mới, trong khi bảo vệ các biểu diễn đã học trước đó khỏi quên thảm khốc bằng cách sử dụng các ảnh chụp (tức là trọng số) của mô hình trước.

Một phương pháp khác, được giới thiệu bởi [5] là một sự điều chỉnh của phương pháp phát lại sinh được đề cập trong Phần II-A. Nó có thể áp dụng cho cả khung đối kháng và biến phân. Nó sử dụng hai mô hình sinh: một hoạt động như bộ nhớ, có khả năng sinh tất cả các tác vụ quá khứ, và một mô hình học sinh dữ liệu từ tất cả các tác vụ quá khứ và tác vụ hiện tại. Nó chủ yếu được sử dụng như một phương pháp cho Học Liên tục của các mô hình phân biệt [5, 21, 24]. Gần đây, [25] đã phát triển một phương pháp tương tự gọi là Memory Replay GANs, trong đó họ sử dụng Generative Replay kết hợp với replay alignment, một sơ đồ chưng cất chuyển giao kiến thức trước từ một generator có điều kiện sang generator hiện tại. Tuy nhiên họ lưu ý rằng phương pháp này dẫn đến mode collapse vì nó có thể ưu tiên học sinh các instance lớp ít hơn là một phạm vi rộng hơn của các instance lớp.

III. PHƯƠNG PHÁP

Công trình trước đây điển hình về Học Liên tục cho các mô hình sinh tập trung vào việc trình bày một kỹ thuật CL mới và so sánh nó với các phương pháp trước, trên một loại mô hình sinh (ví dụ GAN hoặc VAE). Ngược lại, chúng tôi tập trung vào việc tìm kiếm sự kết hợp tốt nhất giữa mô hình sinh và chiến lược CL. Hiện tại, đánh giá thực nghiệm vẫn là cách duy nhất để tìm ra các kết hợp hoạt động tốt nhất. Do đó, chúng tôi so sánh một số chiến lược CL hiện có trên nhiều loại mô hình sinh với mục tiêu tìm ra mô hình sinh phù hợp nhất cho Học Liên tục.

Trong quá trình này, các thước đo đánh giá là rất quan trọng. Các phương pháp CL thường được đánh giá bằng cách tính một thước đo ở cuối mỗi tác vụ. Phương pháp nào có thể duy trì hiệu suất cao nhất là tốt nhất. Trong thiết lập phân biệt, độ chính xác phân loại là thước đo được sử dụng phổ biến nhất. Ở đây, khi chúng tôi tập trung vào các mô hình sinh, không có sự đồng thuận về thước đo nào nên được sử dụng. Do đó, chúng tôi sử dụng và so sánh hai thước đo định lượng.

Fréchet Inception Distance (FID) [13] là một thước đo thường được sử dụng để đánh giá các mô hình sinh. Nó được thiết kế để cải tiến Inception Score (IS) [26] có nhiều khuyết điểm nội tại, cũng như các vấn đề bổ sung khi được sử dụng trên tập dữ liệu khác ImageNet [27]. FID khắc phục những vấn đề này bằng cách so sánh thống kê của các mẫu được sinh ra với các mẫu thực, thay vì đánh giá các mẫu được sinh ra trực tiếp. [13] đề xuất sử dụng khoảng cách Fréchet giữa hai Gaussian đa biến:

FID = ||μr - μg||² + Tr(Σr + Σg - 2(ΣrΣg)^(1/2))    (1)

trong đó các thống kê (μr, Σr) và (μg, Σg) là các kích hoạt của một lớp cụ thể của một mạng nơ-ron phân biệt được huấn luyện trên ImageNet, tương ứng cho các mẫu thực và được sinh ra. FID thấp hơn tương ứng với các mẫu thực và được sinh ra tương tự hơn như được đo bởi khoảng cách giữa các phân phối kích hoạt của chúng. Ban đầu kích hoạt nên được lấy từ một lớp cho trước của một instance Inception-v3 cho trước, tuy nhiên thiết lập này có thể được điều chỉnh với một bộ phân loại khác để so sánh một tập hợp các mô hình với nhau [28, 14].

Một phương pháp khác là sử dụng các mẫu được sinh ra có nhãn từ một generator G (GAN hoặc VAE) để huấn luyện một bộ phân loại và đánh giá nó sau đó trên dữ liệu thực [14]. Đánh giá này, được gọi là Fitting Capacity của G, là độ chính xác kiểm tra của một bộ phân loại được huấn luyện với các mẫu của G. Nó đo khả năng của generator để huấn luyện một bộ phân loại tổng quát hóa tốt trên tập kiểm tra, tức là khả năng của generator để khớp phân phối của tập kiểm tra. Phương pháp này nhằm đánh giá các mô hình sinh trên các đặc tính phức tạp của dữ liệu chứ không chỉ trên phân phối đặc trưng của chúng. Trong bài báo gốc, các tác giả chú thích các mẫu bằng cách sinh chúng có điều kiện, hoặc với một mô hình có điều kiện hoặc bằng cách sử dụng một mô hình không điều kiện cho mỗi lớp. Trong bài báo này, chúng tôi cũng sử dụng một sự điều chỉnh của Fitting Capacity trong đó dữ liệu từ các mô hình không điều kiện được gắn nhãn bởi một mạng chuyên gia được huấn luyện trên tập dữ liệu.

Chúng tôi tin rằng việc sử dụng hai thước đo này là bổ sung. FID là một thước đo thường được sử dụng chỉ dựa trên phân phối của các đặc trưng ảnh. Để có một đánh giá bổ sung, chúng tôi sử dụng Fitting Capacity, đánh giá các mẫu trên tiêu chí phân loại thay vì phân phối đặc trưng.

Đối với tất cả sự tiến bộ được thực hiện trong các thước đo định lượng để đánh giá các mô hình sinh [29], đánh giá định tính vẫn là một phương pháp được sử dụng rộng rãi và có thông tin. Trong khi việc trực quan hóa các mẫu cung cấp phát hiện tức thời về sự thất bại, nó không cung cấp cách so sánh hai mô hình hoạt động tốt. Nó không phải là một đánh giá chặt chẽ và có thể gây hiểu lầm khi đánh giá tính biến đổi của mẫu.

IV. THIẾT LẬP THÍ NGHIỆM

Bây giờ chúng tôi mô tả thiết lập thí nghiệm của mình: dữ liệu, tác vụ và các phương pháp được đánh giá.

A. Tập dữ liệu, tác vụ, thước đo và mô hình

Các thí nghiệm chính của chúng tôi sử dụng 10 tác vụ tuần tự được tạo ra sử dụng tập dữ liệu MNIST, Fashion MNIST và CIFAR10. Đối với mỗi tập dữ liệu, chúng tôi định nghĩa 10 tác vụ tuần tự, một tác vụ tương ứng với việc học sinh một lớp mới và tất cả các lớp trước đó (Xem Hình 1 để có ví dụ trên MNIST). Cả hai đánh giá, FID và Fitting Capacity của các mô hình sinh, được tính ở cuối mỗi tác vụ.

Chúng tôi sử dụng 6 mô hình sinh khác nhau. Chúng tôi thí nghiệm với phiên bản gốc và có điều kiện của GANs [30] và VAEs [31]. Chúng tôi cũng thêm WGAN [32] và một biến thể của nó WGAN-GP [33], vì chúng là các đường cơ sở thường được sử dụng được cho là cải thiện so với GAN gốc.

B. Chiến lược cho học liên tục

Chúng tôi tập trung vào các chiến lược có thể sử dụng trong cả khung biến phân và đối kháng. Chúng tôi sử dụng 3 chiến lược khác nhau cho Học Liên tục của các mô hình sinh, mà chúng tôi so sánh với 3 đường cơ sở. Các thí nghiệm của chúng tôi được thực hiện trên 8 seed với 50 epoch mỗi tác vụ cho MNIST và Fashion MNIST sử dụng Adam [34] để tối ưu hóa (để biết cài đặt siêu tham số, xem Phụ lục).

Đường cơ sở đầu tiên là Fine-tuning, bao gồm việc bỏ qua quên thảm khốc và về cơ bản là cận dưới của hiệu suất. Các đường cơ sở khác của chúng tôi là hai cận trên: Upperbound Data, trong đó một mô hình sinh được huấn luyện trên dữ liệu chung từ tất cả các tác vụ quá khứ, và Upperbound Model, trong đó một generator riêng biệt được huấn luyện cho mỗi tác vụ.

Đối với các chiến lược Học Liên tục, đầu tiên chúng tôi sử dụng phương pháp Rehearsal vanilla, trong đó chúng tôi giữ một số lượng cố định các mẫu của mỗi tác vụ quan sát được, và thêm những mẫu đó vào tập huấn luyện của mô hình sinh hiện tại. Chúng tôi cân bằng tập dữ liệu kết quả bằng cách sao chép các mẫu đã lưu sao cho mỗi lớp có cùng số lượng mẫu. Số lượng mẫu được chọn, ở đây là 10, được thúc đẩy bởi kết quả trong Hình 7a và 7b, nơi chúng tôi chỉ ra rằng 10 mẫu mỗi lớp là đủ để có độ chính xác validation thỏa mãn nhưng không tối đa cho một tác vụ phân loại trên MNIST và Fashion MNIST. Vì Fitting Capacity chia sẻ cùng tập kiểm tra, chúng tôi có thể so sánh độ chính xác gốc với 10 mẫu mỗi tác vụ với fitting capacity cuối cùng. Fitting capacity cao hơn cho thấy rằng bộ nhớ ngăn chặn quên thảm khốc. Fitting Capacity bằng nhau có nghĩa là overfitting của các mẫu đã lưu và Fitting Capacity thấp hơn có nghĩa là generator thất bại trong việc thậm chí ghi nhớ những mẫu này.

Chúng tôi cũng thí nghiệm với EWC. Chúng tôi làm theo phương pháp được mô tả bởi [4] cho GANs, tức là phạt chỉ được áp dụng trên trọng số của generator, và cho VAEs chúng tôi áp dụng phạt trên cả encoder và decoder. Vì các tác vụ được trình bày tuần tự, chúng tôi chọn cập nhật đường chéo của ma trận thông tin Fisher bằng cách cộng dồn cái mới vào cái trước đó. Phương pháp cuối cùng là Generative Replay, được mô tả trong Phần II-B. Generative replay là một phương pháp mô hình kép trong đó một mô hình sinh "đông lạnh" G_{t-1} được sử dụng để lấy mẫu từ các phân phối đã học trước đó và một mô hình sinh "hiện tại" G_t được sử dụng để học phân phối hiện tại và phân phối G_{t-1}. Khi một tác vụ kết thúc, G_{t-1} được thay thế bằng một bản sao của G_t, và việc học có thể tiếp tục.

V. KẾT QUẢ

Các hình chúng tôi báo cáo cho thấy sự tiến triển của các thước đo qua các tác vụ. Cả FID và Fitting Capacity đều được tính trên tập kiểm tra. Một mô hình hoạt động tốt nên tăng Fitting Capacity và giảm FID của nó. Chúng tôi quan sát một mối tương quan mạnh giữa Fitting Capacity và FID (xem Hình 2 để có ví dụ trên GAN cho MNIST và Phụ lục cho kết quả đầy đủ). Tuy nhiên, kết quả Fitting Capacity ổn định hơn: trên 8 seed ngẫu nhiên chúng tôi sử dụng, các độ lệch chuẩn ít quan trọng hơn so với kết quả FID. Vì lý do đó, chúng tôi tập trung giải thích của mình vào kết quả Fitting Capacity.

A. Kết quả MNIST và Fashion MNIST

1) Kết quả chính: Kết quả chính của chúng tôi với Fitting Capacity được hiển thị trong Hình 3 và Bảng I. Kết hợp tốt nhất là Generative Replay + GAN với Fitting Capacity trung bình là 95.81% trên MNIST và 81.52% trên Fashion MNIST. Hiệu suất tương đối của mỗi phương pháp CL trên GAN có thể được phân tích từng lớp trong Hình 4. Chúng tôi quan sát rằng, đối với khung đối kháng, Generative Replay vượt trội hơn các phương pháp khác với một biên độ đáng kể. Tuy nhiên, đối với khung biến phân, phương pháp Rehearsal là hoạt động tốt nhất. Phương pháp Rehearsal hoạt động khá tốt nhưng không thỏa mãn cho CGAN và WGAN-GP. Thật vậy, Fitting Capacity thấp hơn độ chính xác của một bộ phân loại được huấn luyện trên 10 mẫu mỗi lớp (xem Hình 7a và 7b trong Phụ lục).

Trong thiết lập của chúng tôi, EWC không thể vượt qua quên thảm khốc và hoạt động cũng như đường cơ sở Fine-tuning ngây thơ, điều này mâu thuẫn với kết quả của [4] người đã tìm thấy EWC thành công trong một thiết lập hơi khác. Chúng tôi tái tạo kết quả của họ trong một thiết lập có hai lớp cho mỗi tác vụ (xem Phụ lục để biết chi tiết), cho thấy ảnh hưởng mạnh của định nghĩa tác vụ.

Trong [4] các tác giả đã tìm thấy rằng EWC không hoạt động với các mô hình không điều kiện nhưng cho thấy kết quả thành công với các mô hình có điều kiện (tức là CGANs). Sự khác biệt đến từ thiết lập thí nghiệm. Trong [4], chuỗi huấn luyện bắt đầu bằng một tác vụ với hai lớp. Do đó, khi CGAN được huấn luyện, có thể cho Ma trận Fisher hiểu ảnh hưởng của vector đầu vào chỉ số lớp c. Trong thiết lập của chúng tôi, vì chỉ có một lớp ở tác vụ đầu tiên, ma trận Fisher không thể nhận được tầm quan trọng của vector đầu vào chỉ số lớp c. Do đó, như đối với các mô hình không điều kiện, Ma trận Fisher không thể bảo vệ trọng số một cách thích hợp và ở cuối tác vụ thứ hai, mô hình đã quên tác vụ đầu tiên. Hơn nữa, vì generator quên những gì nó đã học ở tác vụ đầu tiên, nó chỉ có khả năng sinh các mẫu của chỉ một lớp. Sau đó, Ma trận Fisher vẫn sẽ không nhận được ảnh hưởng của c cho đến cuối chuỗi. Hơn nữa, chúng tôi chỉ ra rằng ngay cả khi bắt đầu với 2 lớp, khi chỉ có một lớp cho tác vụ thứ hai, ma trận Fisher không thể bảo vệ lớp từ tác vụ thứ hai trong tác vụ thứ ba. (xem Hình 12).

Kết quả của chúng tôi không đưa ra sự phân biệt rõ ràng giữa các mô hình có điều kiện và không điều kiện. Tuy nhiên, các phương pháp đối kháng hoạt động tốt hơn đáng kể so với các phương pháp biến phân. Các biến thể GANs có thể tạo ra chất lượng tốt hơn, sắc nét hơn và đa dạng của các mẫu, như quan sát trong Hình 14 và 15 trong Phụ lục. Do đó, các phương pháp đối kháng có vẻ khả thi hơn cho CL. Chúng ta có thể liên kết độ chính xác từ 7a và 7b với kết quả Fitting Capacity. Như một ví dụ, chúng ta có thể ước tính rằng GAN với Generative Replay tương đương cho cả hai tập dữ liệu với một bộ nhớ khoảng 100 mẫu mỗi lớp.

2) Kết quả phụ: Quên thảm khốc có thể được trực quan hóa trong Hình 4. Cột của mỗi ô vuông biểu diễn chỉ số tác vụ và mỗi hàng là lớp, màu sắc cho biết Fitting Capacity (FC). Các ô vuông màu vàng cho thấy FC cao, màu xanh cho thấy FC thấp. Chúng ta có thể trực quan hóa cả hiệu suất của VAE và GAN mà còn cả sự tiến triển hiệu suất cho mỗi lớp. Đối với Generative Replay, ở cuối chuỗi tác vụ, VAE giảm hiệu suất của nó trong một số lớp khi GAN thì không. Đối với Rehearsal thì ngược lại. Về hiệu suất cao của GAN gốc và WGAN với Generative Replay, chúng hưởng lợi từ chất lượng mẫu và tính ổn định của chúng. So với đó, các mẫu từ CGAN và WGAN-GP nhiều nhiễu hơn và các mẫu từ VAE và CVAE mờ hơn (xem trong phụ lục 14). Tuy nhiên trong phương pháp Rehearsal, các mô hình dựa trên GANs có vẻ ít ổn định hơn nhiều (Xem Bảng I và Hình 3). Trong thiết lập này, tác vụ phân biệt gần như tầm thường đối với discriminator điều này làm cho việc huấn luyện khó khăn hơn cho generator. Ngược lại, các mô hình dựa trên VAE đặc biệt hiệu quả và ổn định trong thiết lập Rehearsal (Xem Hình 4b). Thật vậy, mục tiêu học tập của chúng (lỗi theo pixel) không bị quấy rầy bởi tính biến đổi mẫu thấp và các biến ẩn xác suất của chúng làm cho chúng ít dễ bị overfit.

Tuy nhiên Fitting Capacity của Fine-tuning và EWC trong Bảng I cao hơn mong đợi cho các mô hình không điều kiện. Vì generator chỉ có thể tạo ra các mẫu từ tác vụ cuối cùng, Fitting capacity nên gần 10%. Đây là một nhược điểm của việc sử dụng một chuyên gia để chú thích trước khi tính Fitting Capacity. Các mẫu mờ có thể được chú thích sai, điều này có thể tăng tính đa dạng nhãn một cách nhân tạo và do đó Fitting Capacity của các mô hình hoạt động kém, ví dụ, VAE với Fine-tuning. Tuy nhiên, kết quả này vẫn thấp hơn Fitting Capacity của các mô hình hoạt động tốt.

Tình cờ, một kết quả phụ quan trọng là Fitting capacity của các mô hình sinh có điều kiện có thể so sánh được với kết quả của phân loại Học Liên tục. Hiệu suất tốt nhất của chúng tôi trong thiết lập này là với CGAN: 94.7% trên MNIST và 75.44% trên Fashion MNIST. Trong một thiết lập tương tự với 2 tác vụ tuần tự, có thể dễ dàng hơn so với thiết lập của chúng tôi (một với các chữ số từ 0,1,2,3,4 và một khác với 5,6,7,8,9), [35] đạt được hiệu suất 94.91%. Điều này cho thấy rằng việc sử dụng các mô hình sinh cho CL có thể là một công cụ cạnh tranh trong tình huống phân loại. Đáng chú ý là chúng tôi không so sánh kết quả Fitting Capacity của các mô hình không điều kiện với state of the art phân loại. Thật vậy, trong trường hợp này, Fitting capacity dựa trên chú thích từ một chuyên gia không được huấn luyện trong thiết lập liên tục. Việc so sánh sau đó sẽ không công bằng.

B. Kết quả CIFAR10

Trong thí nghiệm này, chúng tôi chọn các phương pháp CL hoạt động tốt nhất trên MNIST và Fashion MNIST, Generative Replay và Rehearsal, và kiểm tra nó trên tập dữ liệu CIFAR10 thách thức hơn. Chúng tôi so sánh hai phương pháp với Fine-tuning ngây thơ, và với Upperbound Model (một generator cho mỗi lớp). Thiết lập vẫn giữ nguyên, một tác vụ cho mỗi danh mục, mà mục đích là tránh quên các danh mục đã thấy trước đó. Chúng tôi chọn WGAN-GP vì nó tạo ra các mẫu thỏa mãn nhất trên CIFAR10 (xem Hình 16 trong Phụ lục).

Kết quả được cung cấp trong Hình 5, nơi chúng tôi hiển thị các hình ảnh được lấy mẫu sau 10 tác vụ tuần tự, và các đường cong FID + Fitting Capacity trong suốt quá trình huấn luyện. Kết quả Fitting Capacity cho thấy rằng tất cả bốn phương pháp đều thất bại trong việc sinh các hình ảnh cho phép học một bộ phân loại hoạt động tốt trên dữ liệu kiểm tra CIFAR10 thực. Như đã nêu cho MNIST và Fashion MNIST, với các mô hình không điều kiện, khi Fitting Capacity thấp, nó có thể được tăng một cách nhân tạo bởi chú thích tự động điều này làm cho sự khác biệt giữa các đường cong không đáng kể trong trường hợp này. Fine-tuning ngây thơ quên thảm khốc các tác vụ trước, như mong đợi. Rehearsal không mang lại kết quả thỏa mãn. Trong khi điểm FID cho thấy cải thiện ở mỗi tác vụ mới, trực quan hóa rõ ràng cho thấy rằng generator sao chép các mẫu trong bộ nhớ, và gặp phải mode collapse. Điều này xác nhận trực giác của chúng tôi rằng Rehearsal overfit với vài mẫu được giữ trong bộ nhớ. Generative Replay thất bại; vì tập dữ liệu bao gồm các hình ảnh thực tế, tác vụ sinh khó hoàn thành hơn nhiều. Chúng tôi minh họa chế độ thất bại của nó trong Hình 17 trong Phụ lục. Như thấy trong Task 0, generator có thể tạo ra các hình ảnh gần giống các mẫu của danh mục, ở đây là máy bay. Khi các tác vụ được trình bày, các lỗi sinh nhỏ tích lũy và cuộn tuyết thành kết quả trong task 9: các mẫu mờ và các danh mục không thể phân biệt. Kết quả là, FID cải thiện ở đầu chuỗi huấn luyện, và sau đó xấu đi ở mỗi tác vụ mới. Chúng tôi cũng huấn luyện cùng mô hình riêng biệt trên mỗi tác vụ, và trong khi kết quả thỏa mãn về mặt thị giác, các thước đo định lượng cho thấy rằng chất lượng sinh không xuất sắc.

Những kết quả tiêu cực này cho thấy rằng việc huấn luyện một mô hình sinh trên tình huống tác vụ tuần tự không giảm thành việc huấn luyện thành công một mô hình sinh trên tất cả dữ liệu hoặc mỗi danh mục, và rằng các mô hình sinh tiên tiến gặp khó khăn trên các tập dữ liệu hình ảnh thực tế như CIFAR10. Thiết kế một chiến lược CL cho những loại tập dữ liệu này vẫn là một thách thức.

VI. THẢO LUẬN

Bên cạnh các kết quả định lượng và đánh giá thị giác của các mẫu được sinh ra, các chiến lược được đánh giá có, theo thiết kế, các đặc tính cụ thể liên quan đến CL mà chúng tôi thảo luận ở đây.

Rehearsal vi phạm giả định khả dụng dữ liệu, thường được yêu cầu trong các tình huống CL, bằng cách ghi lại một phần các mẫu. Hơn nữa, nguy cơ overfitting cao khi chỉ vài mẫu đại diện cho một tác vụ, như được thể hiện trong kết quả CIFAR10.

EWC và Generative Replay tôn trọng giả định này. EWC có lợi thế là không yêu cầu bất kỳ tải tính toán nào trong quá trình huấn luyện, nhưng điều này đi kèm với chi phí tính toán ma trận thông tin Fisher, và lưu trữ các giá trị của nó cũng như một bản sao của các tham số trước. Bộ nhớ cần thiết cho EWC để lưu thông tin từ quá khứ gấp đôi kích thước của mô hình có thể đắt đỏ so với các phương pháp rehearsal. Tuy nhiên, với Rehearsal và Generative Replay, mô hình có ngày càng nhiều mẫu để học từ đó ở mỗi tác vụ mới, điều này làm cho việc huấn luyện tốn kém hơn.

Một điểm khác chúng tôi thảo luận là về một thước đo được đề xuất gần đây [25] để đánh giá CL cho các mô hình sinh. Đánh giá của họ được định nghĩa cho các mô hình sinh có điều kiện. Đối với một nhãn l cho trước, họ lấy mẫu hình ảnh từ generator có điều kiện trên l và đưa nó vào một bộ phân loại được huấn luyện trước. Nếu nhãn được dự đoán của bộ phân loại khớp với l, thì nó được coi là đúng. Trong thí nghiệm của chúng tôi, chúng tôi thấy rằng nó mang lại lợi thế rõ ràng cho các phương pháp rehearsal. Vì generator có thể overfit vài mẫu được giữ trong bộ nhớ, nó có thể tối đa hóa đánh giá được đề xuất bởi [17], trong khi không tạo ra các mẫu đa dạng. Chúng tôi trình bày hiện tượng này với các thí nghiệm của mình trong phụ lục. Tuy nhiên, ngay cả khi thước đo của họ không thể phát hiện mode collapse hoặc overfitting, nó có thể hiệu quả phơi bày quên thảm khốc trong các mô hình có điều kiện.

VII. KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI

Trong bài báo này, chúng tôi thí nghiệm với tính khả thi và hiệu quả của các mô hình sinh trong thiết lập Học Liên tục (CL). Chúng tôi đánh giá các phương pháp được xem xét trên các tập dữ liệu thường được sử dụng cho CL, với hai thước đo định lượng. Các thí nghiệm của chúng tôi chỉ ra rằng trên MNIST và Fashion MNIST, GAN gốc kết hợp với phương pháp Generative Replay đặc biệt hiệu quả. Phương pháp này tránh quên thảm khốc bằng cách sử dụng generator như một bộ nhớ để lấy mẫu từ các tác vụ trước và do đó duy trì kiến thức quá khứ. Hơn nữa, chúng tôi làm sáng tỏ cách các mô hình sinh có thể học liên tục với các phương pháp khác nhau và trình bày các kết hợp thành công. Chúng tôi cũng tiết lộ rằng các mô hình sinh không hoạt động đủ tốt trên CIFAR10 để học liên tục. Vì các lỗi sinh tích lũy, chúng không thể sử dụng được trong thiết lập liên tục. Các phương pháp được xem xét có những hạn chế: chúng tôi dựa vào một thiết lập trong đó các ranh giới tác vụ rời rạc và được người dùng cung cấp. Trong công việc tương lai, chúng tôi dự định nghiên cứu phát hiện tự động các ranh giới tác vụ. Một cải tiến khác sẽ là thí nghiệm với các chuyển tiếp mượt mà hơn giữa các tác vụ, thay vì thiết lập tác vụ rời rạc.

TÀI LIỆU THAM KHẢO

[1] J. Fagot and R. G. Cook, "Evidence for large long-term memory capacities in baboons and pigeons and its implications for learning and the evolution of cognition," Proceedings of the National Academy of Sciences, vol. 103, no. 46, pp. 17 564–17 567, 2006.

[2] R. K. Srivastava, J. Masci, S. Kazerounian, F. Gomez, and J. Schmidhuber, "Compete to compute," in Advances in Neural Information Processing Systems 26, C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, Eds. Curran Associates, Inc., 2013, pp. 2310–2318. [Online]. Available: http://papers.nips.cc/paper/5059-compete-to-compute.pdf

[3] C. V. Nguyen, Y. Li, T. D. Bui, and R. E. Turner, "Variational continual learning," arXiv preprint arXiv:1710.10628, 2017.

[4] A. Seff, A. Beatson, D. Suo, and H. Liu, "Continual learning in generative adversarial nets," arXiv preprint arXiv:1705.08395, 2017.

[5] H. Shin, J. K. Lee, J. Kim, and J. Kim, "Continual learning with deep generative replay," in Advances in Neural Information Processing Systems, 2017, pp. 2990–2999.

[6] J. Schwarz, J. Luketina, W. M. Czarnecki, A. Grabska-Barwinska, Y. W. Teh, R. Pascanu, and R. Hadsell, "Progress & compress: A scalable framework for continual learning," arXiv preprint arXiv:1805.06370, 2018.

[7] R. M. French, "Catastrophic forgetting in connectionist networks," Trends in Cognitive Sciences, vol. 3, no. 4, pp. 128–135, 1999.

[8] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins, A. A. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska et al., "Overcoming catastrophic forgetting in neural networks," Proceedings of the national academy of sciences, p. 201611835, 2017.

[9] S.-A. Rebuffi, A. Kolesnikov, G. Sperl, and C. H. Lampert, "icarl: Incremental classifier and representation learning," 2017.

[10] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, "Gradient-based learning applied to document recognition," Proceedings of the IEEE, vol. 86, no. 11, pp. 2278–2324, 1998.

[11] H. Xiao, K. Rasul, and R. Vollgraf. (2017) Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.

[12] A. Krizhevsky, V. Nair, and G. Hinton, "Cifar-10 (canadian institute for advanced research)," 2009. [Online]. Available: http://www.cs.toronto.edu/~kriz/cifar.html

[13] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter, "Gans trained by a two time-scale update rule converge to a local nash equilibrium," in Advances in Neural Information Processing Systems, 2017, pp. 6626–6637.

[14] T. Lesort, J.-F. Goudou, and D. Filliat, "Training discriminative models to evaluate generative ones," arXiv preprint arXiv:1806.10840, 2018.

[15] G. Hinton, O. Vinyals, and J. Dean, "Distilling the knowledge in a neural network," arXiv preprint arXiv:1503.02531, 2015.

[16] Z. Li and D. Hoiem, "Learning without forgetting," IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017.

[17] Y. Wu, Y. Chen, L. Wang, Y. Ye, Z. Liu, Y. Guo, Z. Zhang, and Y. Fu, "Incremental classifier learning with generative adversarial networks," arXiv preprint arXiv:1802.00853, 2018.

[18] A. A. Rusu, N. C. Rabinowitz, G. Desjardins, H. Soyer, J. Kirkpatrick, K. Kavukcuoglu, R. Pascanu, and R. Hadsell, "Progressive Neural Networks," ArXiv e-prints, Jun. 2016.

[19] Z. Li and D. Hoiem, "Learning without Forgetting," ArXiv e-prints, Jun. 2016.

[20] C. Fernando, D. Banarse, C. Blundell, Y. Zwols, D. Ha, A. A. Rusu, A. Pritzel, and D. Wierstra, "Pathnet: Evolution channels gradient descent in super neural networks," CoRR, vol. abs/1701.08734, 2017. [Online]. Available: http://arxiv.org/abs/1701.08734

[21] R. Venkatesan, H. Venkateswara, S. Panchanathan, and B. Li, "A strategy for an uncompromising incremental learner," arXiv preprint arXiv:1705.00744, 2017.

[22] J. Ramapuram, M. Gregorova, and A. Kalousis, "Lifelong generative modeling," arXiv preprint arXiv:1705.09847, 2017.

[23] A. Achille, T. Eccles, L. Matthey, C. P. Burgess, N. Watters, A. Lerchner, and I. Higgins, "Life-long disentangled representation learning with cross-domain latent homologies," arXiv preprint arXiv:1808.06508, 2018.

[24] H. Shah, K. Javed, and F. Shafait, "Distillation techniques for pseudo-rehearsal based incremental learning," arXiv preprint arXiv:1807.02799, 2018.

[25] C. Wu, L. Herranz, X. Liu, Y. Wang, J. van de Weijer, and B. Raducanu, "Memory replay gans: learning to generate images from new categories without forgetting," arXiv preprint arXiv:1809.02058, 2018.

[26] T. Salimans, I. J. Goodfellow, W. Zaremba, V. Cheung, A. Radford, and X. Chen, "Improved techniques for training gans," CoRR, vol. abs/1606.03498, 2016.

[27] S. Barratt and R. Sharma, "A note on the inception score," arXiv preprint arXiv:1801.01973, 2018.

[28] C. Li, H. Liu, C. Chen, Y. Pu, L. Chen, R. Henao, and L. Carin, "Alice: Towards understanding adversarial learning for joint distribution matching," in Advances in Neural Information Processing Systems, 2017, pp. 5495–5503.

[29] A. Borji, "Pros and cons of gan evaluation measures," arXiv preprint arXiv:1802.03446, 2018.

[30] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, "Generative adversarial nets," in Advances in neural information processing systems, 2014, pp. 2672–2680.

[31] D. P. Kingma and M. Welling, "Auto-encoding variational bayes," arXiv preprint arXiv:1312.6114, 2013.

[32] M. Arjovsky, S. Chintala, and L. Bottou, "Wasserstein gan," arXiv preprint arXiv:1701.07875, 2017.

[33] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. C. Courville, "Improved training of wasserstein gans," in Advances in Neural Information Processing Systems, 2017, pp. 5767–5777.

[34] D. P. Kingma and J. Ba, "Adam: A method for stochastic optimization," arXiv preprint arXiv:1412.6980, 2014.

[35] X. He and H. Jaeger, "Overcoming catastrophic interference using conceptor-aided backpropagation," in International Conference on Learning Representations, 2018. [Online]. Available: https://openreview.net/forum?id=B1al7jg0b

PHỤ LỤC

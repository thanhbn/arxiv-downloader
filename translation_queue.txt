[Processing] clarify/2310.10996-ClarifyGPT-_Empowering_LLM-based_Code_Generation_with.txt
[Processing] pruning/2405.06275-Pruning_as_a_Domain-specific_LLM_Extractor.txt
[Processing] pruning/2004.12406-Masking_as_an_Efﬁcient_Alternative_to_Finetuning.txt
[Processing] pruning/2305.17328-Zero-TPrune-_Zero-Shot_Token_Pruning_through_Leveraging_of_the_Attention.txt
[Processing] pruning/2301.00774-SparseGPT-_Massive_Language_Models_Can_be_Accurately_Pruned_in_One-Shot.txt
[Processing] pruning/2402.16880-Work_in_progress.txt
[Processing] pruning/2302.10483-JOURNAL_OF_XXX_1.txt
[Processing] pruning/2004.14566-TRP-_Trained_Rank_Pruning_for_Efﬁcient_Deep_Neural_Networks.txt
pruning/2304.04947-Conditional_Adapters-_Parameter-efficient.txt
pruning/2211.16667-Dynamic_Sparse_Training_via_Balancing_the.txt
pruning/2306.11695-Published_as_a_conference_paper_at_ICLR_2024.txt
pruning/2308.10438-Efficient_Joint_Optimization_of_Layer-Adaptive_Weight_Pruning.txt
pruning/2312.17244-THELLM_S_URGEON.txt
pruning/2304.06941-Published_as_SNN_workshop_paper_at_ICLR_2023.txt
pruning/2210.02412-Why_Random_Pruning_Is_All_We_Need_to_Start_Sparse.txt
pruning/2305.02299-Published_as_a_conference_paper_at_ICLR_2024.txt
pruning/2405.01943-Dependency-Aware_Semi-Structured_Sparsity_of.txt
pruning/2204.04977-Springer_Nature_2021_L_ATEX_template.txt
pruning/2305.18403-LoRAPrune-_Structured_Pruning_Meets_Low-Rank.txt
pruning/2305.18789-Generalization_Bounds_for_MBP_via_Sparse_Matrix.txt
pruning/2305.17651-DPHuBERT-_Joint_Distillation_and_Pruning_of_Self-Supervised_Speech_Models.txt
pruning/2303.10464-SPDF-_Sparse_Pre-training_and_Dense_Fine-tuning_for_Large_Language_Models.txt
pruning/2203.07259-The_Optimal_BERT_Surgeon-_Scalable_and_Accurate_Second-Order.txt
pruning/2307.08771-UPSCALE-_Unconstrained_Channel_Pruning.txt
pruning/2302.06354-Less_is_More.txt
pruning/2311.04902-Preprint.txt
pruning/1812.02402-Trained_Rank_Pruning_for_Efﬁcient_Deep_Neural.txt
pruning/2303.11525-Sparse-IFT-_Sparse_Iso-FLOP_Transformations_for.txt
pruning/2307.11988-Sparse_then_Prune-_Toward_Efficient_Vision.txt
pruning/1912.08881-Pruning_by_Explaining-_A_Novel_Criterion_for.txt
pruning/2305.14706-PruMUX-_Augmenting_Data_Multiplexing_with_Model_Compression.txt
pruning/1707.04780-Scalable_Training_of_Artiﬁcial_Neural_Networks_with.txt
pruning/2212.12651-Pruning_On-the-Fly-_A_Recoverable_Pruning_Method_without_Fine-tuning.txt
pruning/2210.04092-Advancing_Model_Pruning_via_Bi-level_Optimization.txt
pruning/2206.07918-1.txt
pruning/2405.02267-Published_in_Transactions_on_Machine_Learning_Research_(09-2024).txt
pruning/1601.00720-How_do_neurons_operate_on_sparse_distributed_representations_A_mathematical_theory_of_sparsity,_neur.txt
pruning/2304.11834-Robust_Tickets_Can_Transfer_Better-_Drawing_More.txt
pruning/2207.09074-Incremental_Task_Learning_with.txt
pruning/2301.10835-When_Layers_Play_the_Lottery,_all_Tickets_Win_at_Initialization.txt
pruning/2007.15353-Published_as_a_conference_paper_at_ICLR_2021.txt
pruning/2302.05601-Published_as_a_conference_paper_at_ICLR_2023.txt
pruning/2007.02066-JOURNAL_OF_L_ATEX_CLASS_FILES,_VOL._14,_NO._8,_AUGUST_2021_1.txt
pruning/2111.08577-NEURON_-BASED_PRUNING_OF_DEEPNEURAL_NETWORKS.txt
pruning/2104.08700-IEEE_TRANSACTIONS_ON_PATTERN_ANAL_YSIS_AND_MACHINE_INTELLIGENCE_1.txt
pruning/2310.17752-PockEngine-_Sparse_and_Efficient_Fine-tuning_in_a_Pocket.txt
pruning/2102.03773-1.txt
pruning/2407.00928-FoldGPT-_Simple_and_Effective_Large_Language_Model_Compression.txt
pruning/2212.12770-JOURNAL_OF_IEEE_TRANSACTIONS_ON_ARTIFICIAL_INTELLIGENCE,_VOL._00,_NO._0,_MONTH_2020_1.txt
pruning/2307.08982-1111.txt
pruning/2004.14765-arXiv-2004.14765v1_[cs.LG]_30_Apr_2020Pruning_artiﬁcial_neural_networks.txt
pruning/2106.02914-Preprint.txt
pruning/2308.02451-Pruning_a_neural_network_using_Bayesian.txt
pruning/2304.13718-Sparsiﬁed_Model_Zoo_Twins.txt
pruning/2111.02399-LEARNING_PRUNED_STRUCTURE_AND_WEIGHTS.txt
pruning/2306.03805-The_Emergence_of_Essential_Sparsity_in.txt
pruning/2407.20584-Pruning_Large_Language_Models_with_Semi-Structural_Adaptive_Sparse_Training.txt
pruning/1710.01878-To_prune,_or_not_to_prune-_exploring_the_efﬁcacy_of.txt
pruning/2310.06694-Published_as_a_conference_paper_at_ICLR_2024.txt
pruning/1806.06457-Fast_Convex_Pruning_of_Deep_Neural_Networks.txt
pruning/2306.01526-Noname_manuscript_No..txt
pruning/2305.11627-LLM-Pruner-_On_the_Structural_Pruning.txt
pruning/1904.10921-Plug-in,_Trainable_Gate_for_Streamlining_Arbitrary_Neural_Networks.txt
pruning/1905.10650-Are_Sixteen_Heads_Really_Better_than_One.txt
pruning/2110.08232-Fire_Together_Wire_Together.txt
pruning/2406.10594-BlockPruner-_Fine-grained_Pruning_for_Large_Language_Models.txt
pruning/2310.04573-Can_pruning_make_Large_Language_Models_more.txt
pruning/2304.02721-To_Asymmetry_and_Beyond-_Structured_Pruning_of_Sequence_to_Sequence.txt
pruning/2306.05785-End-to-End_Neural_Network_Compression_viaℓ1.txt
pruning/2111.11146-Published_as_a_conference_paper_at_ICLR_2022.txt
pruning/2111.00160-DSEE-_Dually_Sparsity-embedded_Efficient_Tuning_of_Pre-trained.txt
pruning/2111.00162-You_are_caught_stealing_my_winning_lottery_ticket!.txt
pruning/2210.06384-GMPF-_Well-Tuned_Gradual_Magnitude_Pruning_Can_Outperform_Most.txt
pruning/2211.02206-Soft_Masking_for_Cost-Constrained_Channel.txt
pruning/2206.06247-arXiv-2206.06247v1_[cs.NE]_13_Jun_2022Leveraging_Structured_Pruning_of.txt
pruning/2111.13445-How_Well_Do_Sparse_ImageNet_Models_Transfer.txt
pruning/2303.07624-I3D-_TRANSFORMER_ARCHITECTURES_WITH_INPUT-DEPENDENT_DYNAMIC_DEPTH.txt
pruning/2012.00560-Noname_manuscript_No..txt
pruning/2407.19126-Greedy_Output_Approximation-_Towards_Efficient.txt
pruning/2111.09635-Automatic_Neural_Network_Pruning_that_Efﬁciently_Preserves_the_Model_Accuracy.txt
pruning/2211.12551-Sparse_Probabilistic_Circuits_via.txt
pruning/1909.10364-Class-dependent_Pruning_of_Deep_Neural_Networks.txt
normalization/2208.01313-Unified_Normalization_for_Accelerating_and_Stabilizing.txt
constrained-decoding/2305.13971-Grammar-Constrained_Decoding_for_Structured_NLP_Tasks.txt
constrained-decoding/1704.07138-Lexically_Constrained_Decoding_for_Sequence_Generation_Using_Grid.txt
time-series/2308.08241-Published_as_a_conference_paper_at_ICLR_2024.txt
dataset-generation/2002.00748-Asking_Questions_the_Human_Way.txt
dataset-generation/2310.17876-Published_as_a_conference_paper_at_COLM_2024.txt
dataset-generation/2403.12468-CrossTune-_Black-Box_Few-Shot_Classification_with_Label.txt
dataset-generation/2309.06358-Generative_Data_Augmentation_using_LLMs_improves_Distributional.txt
dataset-generation/2404.05875-CodecLM-_Aligning_Language_Models_with_Tailored_Synthetic_Data.txt
dataset-generation/2306.11644-Textbooks_Are_All_You_Need.txt
dataset-generation/2310.07849-Synthetic_Data_Generation_with_Large_Language_Models_for_Text.txt
dataset-generation/2404.02489-DUQGen-_Effective_Unsupervised_Domain_Adaptation_of_Neural.txt
dataset-generation/2309.11998-Published_as_a_conference_paper_at_ICLR_2024.txt
dataset-generation/2401.03038-spade_-_Synthesizing_Data_Quality_Assertions.txt
dataset-generation/2302.13007-1.txt
dataset-generation/2402.10379-DataDreamer-_A_Tool_for_Synthetic_Data_Generation_and.txt
survey/2011.00241-METHODS_FOR_PRUNING_DEEPNEURAL_NETWORKS.txt
survey/2307.10188-Several_categories_of_Large_Language_Models_(LLMs)-_A_ShortSurveySaurabh_Pahune1,†,‡,_Manoj_Chandras.txt
survey/2304.02020-A.txt
survey/2307.06435-A_Comprehensive_Overview_of_Large_Language_Models.txt
survey/2308.06767-JOURNAL_OF_LATEX_CLASS_FILES,_VOL._14,_NO._8,_AUGUST_2024_1.txt
question-answering/2311.02961-Adapting_Pre-trained_Generative_Models.txt
question-answering/2303.07992-Can_ChatGPT_Replace_Traditional_KBQA.txt
ensemble/2404.19296-Octopus_v4-_Graph_of_language_models.txt
ensemble/2310.02258-A_Neural_Scaling_Law_from_Lottery_Ticket_Ensembling.txt
ensemble/2309.02429-Building_a_Winning_Team-_Selecting_Source_Model_Ensembles_using_a.txt
continual-learning/2110.03215-TOWARDS_CONTINUAL_KNOWLEDGE_LEARNING_OF.txt
continual-learning/2304.05362-MASIL-_Towards_Maximum_Separable_Class_Representation_for_Few_Shot_Class.txt
continual-learning/2307.10943-Proxy_Anchor-based_Unsupervised_Learning_for_Continuous_Generalized.txt
continual-learning/2305.13622-Continual_Learning_with_Strong_Experience_Replay.txt
continual-learning/2303.05118-SLCA-_Slow_Learner_with_Classifier_Alignment_for_Continual_Learning.txt
continual-learning/2306.13812-Maintaining_Plasticity_in_Deep_Continual_Learning.txt
continual-learning/2307.01163-Improving_Language_Plasticity_via.txt
continual-learning/2301.01828-Citation-_Kessler,_S.;_Cobb,_A.;_Rudner,.txt
continual-learning/2304.05288-Task_Difficulty_Aware_Parameter_Allocation_&_Regularization_for_Lifelong.txt
continual-learning/2405.16498-On_Sequential_Maximum_a_Posteriori_Inference_for.txt
continual-learning/2303.06015-Dynamic_Y-KD-_A_Hybrid_Approach_to_Continual_Instance_Segmentation.txt
continual-learning/2303.14962-PREPRINT,_MARCH_2023_1.txt
continual-learning/2311.11908-Continual_Learning-_Applications_and_the_Road_Forward.txt
continual-learning/1812.09111-Generative_Models_from_the_perspective_of_Continual_Learning.txt
continual-learning/1903.04476-Continual_Learning_via_Neural_Pruning.txt
continual-learning/2308.14831-Continual_Learning_with_Dynamic_Sparse_Training.txt
continual-learning/2305.18444-Continual_Task_Allocation_in_Meta-Policy_Network_via_Sparse_Prompting.txt
continual-learning/2403.08763-Published_in_Transactions_on_Machine_Learning_Research_(06-2024).txt
continual-learning/2306.01904-Published_in_Transactions_on_Machine_Learning_Research_(09-2024).txt
continual-learning/2009.01797-A_Wholistic_View_of_Continual_Learning_with_Deep_Neural_Networks.txt
continual-learning/2307.05399-Domain-Agnostic_Neural_Architecture_for_Class_Incremental_Continual.txt
continual-learning/2105.00157-A_Deep_Learning_Framework_for_Lifelong_Machine_Learning.txt
continual-learning/2311.03301-Ziya2-_Data-centric_Learning_is_All_LLMs_Need.txt
continual-learning/2112.15402-JOURNAL_OF_L_ATEX_CLASS_FILES,_VOL._14,_NO._8,_AUGUST_2021_1.txt
continual-learning/2209.09476-SparCL-_Sparse_Continual_Learning_on_the_Edge.txt
continual-learning/2306.16817-Published_at_2nd_Conference_on_Lifelong_Learning_Agents_(CoLLAs),_2023.txt
continual-learning/2212.02846-Statistical_mechanics_of_continual_learning-_variational_principle.txt
continual-learning/1911.09514-Published_as_a_conference_paper_at_ICLR_2020.txt
continual-learning/2305.06408-Accelerating_Batch_Active_Learning_Using_Continual_Learning.txt
continual-learning/2311.04898-Two_Complementary_Perspectives_to_Continual_Learning.txt
continual-learning/2209.08660-arXiv-2209.08660v2_[cs.LG]_20_Nov_2023Published_in_Transactions_on_Machine_Learning_Research_(09_-20.txt
continual-learning/2106.09563-Published_at_1st_Conference_on_Lifelong_Learning_Agents,_2022.txt
continual-learning/2209.07529-Published_as_a_conference_paper_at_ICLR_2023.txt
continual-learning/2006.09916-Bayesian_active_learning_for_production,_a_systematic_study_and_a_reusable.txt
continual-learning/2305.18563-SHARP-_Sparsity_and_Hidden_Activation_RePlay_for.txt
continual-learning/2106.03027-M-o.pc-d.pc-e.pc-l.pc_Z-o.pc-o.pc-_A_G-r.pc-o.pc-w.pc-i.pc-n.pc-g.pc_“B-r.pc-a.pc-i.pc-n.pc”.txt
continual-learning/2308.10328-A_Comprehensive_Empirical_Evaluation_on_Online_Continual_Learning.txt
continual-learning/2303.07616-The_Life_Cycle_of_Knowledge_in_Big_Language_Models-_A_Survey.txt
continual-learning/2305.14782-IBCL-_Zero-shot_Model_Generation_under.txt
continual-learning/2305.04769-BiRT-_Bio-inspired_Replay_in_Vision_Transformers_for_Continual_Learning.txt
continual-learning/2305.03648-On_the_Effectiveness_of_Equivariant_Regularization.txt
continual-learning/1802.07569-Continual_Lifelong_Learning_with_Neural_Networks.txt
continual-learning/2304.03894-AMULTIFIDELITY_APPROACH_TO_CONTINUAL_LEARNING_FOR.txt
continual-learning/2303.05911-Lifelong_Machine_Learning_Potentials.txt
continual-learning/2211.15215-Progressive_Learning_without_Forgetting.txt
continual-learning/2306.01690-Context_selectivity_with_dynamic_availability_enables_lifelong.txt
continual-learning/2203.17269-A_Closer_Look_at_Rehearsal-Free_Continual_Learning.txt
continual-learning/2211.03186-arXiv-2211.03186v1_[cs.LG]_6_Nov_2022Momentum-based_Weight_Interpolation_of_Strong.txt
continual-learning/2304.04158-DOES_CONTINUAL_LEARNING_EQUALLY_FORGET_ALL.txt
continual-learning/2302.03241-Published_as_a_conference_paper_at_ICLR_2023.txt
continual-learning/2110.08534-Lifelong_Pretraining_-_Continually_Adapting_Language_Models.txt
continual-learning/2210.10209-Exclusive_Supermask_Subnetwork_Training_for_Continual_Learning.txt
continual-learning/2011.12216-Published_at_1st_Conference_on_Lifelong_Learning_Agents,_2022.txt
continual-learning/2211.14963-Neural_Architecture_for_Online_Ensemble_Continual.txt
byte-level/2008.09396-Neural_Machine_Translation_without_Embeddings.txt
byte-level/2404.14408-SpaceByte-_Towards_Deleting_Tokenization.txt
byte-level/2403.09622-Glyph-ByT5-_A_Customized_Text_Encoder_for_Accurate_Visual_Text_Rendering.txt
byte-level/1811.09021-arXiv-1811.09021v1_[eess.AS]_22_Nov_2018BYTES_ARE_ALL_YOU_NEED.txt
byte-level/2402.19155-Beyond_Language_Models-_Byte_Models_are_Digital_World_Simulators.txt
speculative/2401.06761-APAR-_LLMs_Can_Do_Auto-Parallel_Auto-Regressive_Decoding.txt
speculative/2402.05109-Published_as_a_conference_paper_at_COLM_2024.txt
speculative/2402.11131-Speculative_Streaming-_Fast_LLM_Inference_without_Auxiliary_Models.txt
speculative/2408.08696-Turning_Trash_into_Treasure-_Accelerating_Inference_of_Large.txt
speculative/2311.08252-REST-_Retrieval-Based_Speculative_Decoding.txt
speculative/2406.17276-OPT-Tree-_Speculative_Decoding_with_Adaptive_Draft_Tree_Structure.txt
speculative/2402.13720-Ouroboros-_Generating_Longer_Drafts_Phrase_by_Phrase.txt
speculative/2404.19124-Accelerating_Production_LLMs_with_Combined_Token-Embedding_Speculators.txt
speculative/2312.11462-Cascade_Speculative_Drafting_for_Even_Faster_LLM_Inference.txt
speculative/2407.12021-Adaptive_Draft-Verification_for_Efficient_Large_Language_Model_Decoding.txt
speculative/2407.11798-PipeInfer-_Accelerating_LLM_Inference_using.txt
speculative/2405.05254-You_Only_Cache_Once.txt
speculative/2311.04897-Future_Lens-_Anticipating_Subsequent_Tokens_from_a_Single_Hidden_State.txt
speculative/2406.03853-Speculative_Decoding_via_Early-exiting_for_Faster_LLM_Inference.txt
speculative/2502.05609-Lossless_Acceleration_of_Large_Language_Models_with_Hierarchical.txt
speculative/2403.09919-Under_Review.txt
speculative/2309.04255-LLMCad_-_Fast_and_Scalable_On-device_Large_Language.txt
speculative/2401.12522-BiTA-_Bi-Directional_Tuning_for_Lossless_Acceleration_in_Large_Language_Models.txt
speculative/2404.18911-Kangaroo-_Lossless_Self-Speculative.txt
speculative/2302.07863-Speculative_Decoding_with_Big_Little_Decoder.txt
speculative/2401.07851-Unlocking_Efficiency_in_Large_Language_Model_Inference.txt
speculative/2502.06282-Jakiro-_Boosting_Speculative_Decoding_with_Decoupled_Multi-Head_via_MoE.txt
speculative/2409.10644-Improving_Multi-candidate_Speculative_Decoding.txt
speculative/2405.00263-Clover_-_Regressive_Lightweight_Speculative_Decoding.txt
speculative/2402.12374--treeSequoia.txt
speculative/2408.15766-Published_as_a_conference_paper_at_ICLR_2025.txt
speculative/2402.15758-BIG_DATA_MINING_AND_ANALYTICS.txt
speculative/2302.01318-2023-2-3.txt
speculative/2406.18200-SEED-_Accelerating_Reasoning_Tree_Construction_via_Scheduled.txt
speculative/2404.11912-Published_as_a_conference_paper_at_COLM_2024.txt
speculative/2404.08698-Lossless_Acceleration_of_Large_Language_Model_via_Adaptive_N-gram.txt
speculative/1910.10073-DEPTH_-ADAPTIVE_TRANSFORMER.txt
speculative/2404.19737-Better_&_Faster_Large_Language_Models_via_Multi-token_Prediction.txt
speculative/2403.18647-SDSAT-_Accelerating_LLM_Inference_through_Speculative_De.txt
speculative/2305.09781-SpecInfer-_Accelerating_Large_Language_Model_Serving.txt
speculative/2406.17404-Make_Some_Noise-_Unlocking_Language_Model_Parallel_Inference.txt
speculative/2310.07177-Online_Speculative_Decoding.txt
speculative/2405.04304-Dynamic_Speculation_Lookahead_Accelerates.txt
speculative/2407.01955-S2D-_Sorted_Speculative_Decoding_For_More_Efficient_Deployment_of.txt
speculative/2405.18628-Hardware-Aware_Parallel_Prompt_Decoding_for.txt
speculative/2408.11850-Published_as_a_conference_paper_at_ICLR_2025.txt
speculative/2404.12022-Parallel_Decoding_via_Hidden_Transfer_for.txt
speculative/2406.14066-Optimizing_Speculative_Decoding_for_Serving_Large.txt
speculative/2405.07542-EMS-SD-_Efficient_Multi-sample_Speculative_Decoding.txt
structured-data/2309.08963-STRUC_-BENCH_-_Are_Large_Language_Models_Good_at_Generating.txt
dataset-curation/2003.06389-arXiv-2003.06389v1_[cs.CL]_13_Mar_2020Know_thy_corpus!_Robust_methods_for_digital_curation_of_Web_c_.txt
dataset-curation/2405.15613-Automatic_Data_Curation_for_Self-Supervised_Learning.txt
dataset-curation/2311.12537-Oasis-_Data_Curation_and_Assessment_System_for_Pretraining_of_Large.txt
similarity-search/2403.05440-Is_Cosine-Similarity_of_Embeddings_Really_About.txt
similarity-search/2305.13648-Non-parametric,_Nearest-neighbor-assisted_Fine-tuning_for.txt
speech/2309.11000-Towards_Joint_Modeling_of_Dialogue_Response_and_Speech_Synthesis.txt
no-backprop/2205.11200-BBTv2-_Towards_a_Gradient-Free_Future_with_Large_Language_Models.txt
no-backprop/2406.02913-Zeroth-Order_Fine-Tuning_of_LLMs_with_Extreme_Sparsity.txt
no-backprop/2406.18060-AdaZeta-_Adaptive_Zeroth-Order_Tensor-Train_Adaption_for.txt
no-backprop/2310.02025-Published_as_a_conference_paper_at_ICLR_2024.txt
no-backprop/2304.11042-Backpropagation-free_Training_of_Deep_Physical.txt
no-backprop/2209.14624-1.txt
ontology/2309.07172-Exploring_Large_Language_Models_for_Ontology.txt
grokking/2310.19470-Published_in_Transactions_on_Machine_Learning_Research_(05-2025).txt
hypercomplex/2102.08597-Published_as_a_conference_paper_at_ICLR_2021.txt
hypercomplex/2110.04176-1.txt
summarization/2210.15553-Improving_abstractive_summarization_with_energy-based_re-ranking.txt
summarization/2406.14709-Factual_Dialogue_Summarization_via_Learning_from_Large_Language.txt
summarization/2305.09898-Balancing_Lexical_and_Semantic_Quality_in_Abstractive_Summarization.txt
summarization/2305.13696-Abstractive_Text_Summarization_Using_the_BRIO_Training_Paradigm.txt
vector-db/2310.11703-arXiv-2310.11703v2_[cs.DB]_16_Jun_2025JOURNAL_OF_L_ATEX_CLASS_FILES,_VOL._14,_NO._8,_AUGUST_2021_1.txt
activation/2305.10964-Learning_Activation_Functions_for_Sparse_Neural_Networks.txt
activation/2310.04564-ReLU_Strikes_Back.txt
activation/2212.06145-AP-_Selective_Activation_for_De-sparsifying_Pruned_Neural_Networks.txt
activation/2201.10520-arXiv-2201.10520v3_[cs.CV]_9_Mar_2023ADAPTIVE_ACTIVATION_-BASED_STRUCTURED_PRUN.txt
activation/2404.17651-Published_as_a_Tiny_Paper_at_ICLR_2024.txt
emergent/2305.01610-FINDING_NEURONS_IN_A_HAYSTACK.txt
icl-papers/2308.08493-arXiv-2308.08493v3_[cs.CL]_21_Feb_2024Published_as_a_conference_paper_at_ICLR_2024.txt
icl-papers/2309.08986-Draft_version_September_19,_2023.txt
icl-papers/2309.12288-Published_as_a_conference_paper_at_ICLR_2024.txt
icl-papers/2308.07201-CHATEVAL-_TOWARDS_BETTER_LLM-_BASED_EVALUA.txt
icl-papers/2308.12018-Bias-Aware_Minimisation-_Understanding_and.txt
icl-papers/2307.10877-Battle_Ground-_Data_Collection_and_Labeling_of_CTF_Games_to.txt
icl-papers/2308.03688-Technical_Report_(v0.2).txt
icl-papers/2308.04889-NLLG_Quarterly_arXiv_Report_06-23.txt
icl-papers/2308.10379-Algorithm_of_Thoughts.txt
icl-papers/2308.15421-Investigating_how_to_simulate_lattice.txt
icl-papers/2308.16884-The_B_ELEBELE_Benchmark.txt
icl-papers/2310.01405-REPRESENTATION_ENGINEERING.txt
icl-papers/2308.14267-Unleash_Model_Potential-_Bootstrapped_Meta.txt
icl-papers/2309.14402-Physics_of_Language_Models-_Part_3.2,.txt
icl-papers/2308.01421-PREPRINT.txt
icl-papers/2309.16797-PROMPTBREEDER.txt
icl-papers/2309.06820-arXiv-2309.06820v1_[math.DG]_13_Sep_2023Liouville_theorem_for_V-harmonic_maps_under_non-negative.txt
icl-papers/2308.02463-Towards_Generalist_Foundation_Model_for_Radiology_by.txt
icl-papers/2307.05810-arXiv-2307.05810v1_[quant-ph]_11_Jul_2023The_Cliﬀord_theory_of_the_n-qubit_Cliﬀord_group.txt
icl-papers/2307.08072-Do_Emergent_Abilities_Exist_in_Quantized_Large_Language_Models.txt
icl-papers/2309.01252-S2RF-_Semantically_Stylized_Radiance_Fields.txt
icl-papers/2309.02189-Leveraging_BERT_Language_Models_for_Multi-Lingual_ESG_Issue.txt
icl-papers/2307.12008-1_The_First_Room_-Temperature_Ambient_-Pressure_Superconductor.txt
icl-papers/2309.13308-Preprint.txt
icl-papers/2307.09288-Llama_2_-_Open_Foundation_and_Fine-Tuned_Chat_Models.txt
hallucination/2305.14739-Trusting_Your_Evidence.txt
hallucination/2309.02654-ZERO-RESOURCE_HALLUCINATION_PREVENTION_FOR.txt
regularization/2406.06811-Preprint.txt
regularization/2301.09554-1.txt
regularization/2011.09905-LOss-Based_SensiTivity_rEgulaRization.txt
regularization/2308.07163-HyperSparse_Neural_Networks-_Shifting_Exploration_to_Exploitation_through.txt
regularization/2306.16993-Weight_Compander-_A_Simple_Weight.txt
recommendation/2308.10837-Leveraging_Large_Language_Models_for_Pre-trained_Recommender_Systems.txt
recommendation/2305.19860-A_Survey_on_Large_Language_Models_for.txt
recommendation/2305.07961-Leveraging_Large_Language_Models_in_Conversational.txt
recommendation/2309.01157-Large_Language_Models_for_Generative_Recommendation-_A_Survey.txt
shared-params/2309.08968-Sorted_LLaMA-_Unlocking_the_Potential_of_Intermediate_Layers_of_Large.txt
shared-params/2206.14371-Matryoshka-_Stealing_Functionality_of_Private_ML.txt
shared-params/1312.4400-Network_In_Network.txt
shared-params/2310.07707-MatFormer-_Nested_Transformer_for_Elastic_Inference.txt
shared-params/2311.12424-Published_as_a_conference_paper_at_ICLR_2024.txt
shared-params/2303.16212-1.txt
shared-params/2301.13196-Looped_Transformers_as_Programmable_Computers.txt
shared-params/1312.4400.txt
shared-params/2309.00255-SortedNet-_A_Scalable_and_Generalized_Framework.txt
shared-params/2302.10798-Learning_a_Consensus_Sub-Network_with.txt
shared-params/2205.13147-Matryoshka_Representation_Learning.txt
science/2309.06126-AstroLLaMA.txt
science/2309.05689-Large_Language_Model_for_Science.txt
memory/2407.01178-Memory3-_Language_Modeling_with_Explicit_Memory.txt
weight-averaging/2306.16788-Published_as_a_conference_paper_at_ICLR_2024.txt
weight-averaging/2305.14852-Published_as_a_conference_paper_at_ICLR_2024.txt
privacy/2207.09078-ILASR-_Privacy-Preserving_Incremental_Learning_for_Automatic.txt
privacy/2210.15042-Privately_Fine-Tuning_Large_Language_Models_with.txt
agent/2402.01680-Large_Language_Model_based_Multi-Agents-_A_Survey_of_Progress_and_Challenges.txt
agent/2402.04578-Published_at_ICLR_2024_Workshop_on_Large_Language_Model_(LLM)_Agents.txt
agent/2308.11432-Front._Comput._Sci.,_2025,_0(0)-_1–42.txt
agent/2402.14034-AgentScope-_A_Flexible_yet_Robust_Multi-Agent_Platform.txt
agent/2403.04746-LLMs_in_the_Imaginarium.txt
agent/2309.17288-AutoAgents-_A_Framework_for_Automatic_Agent.txt
agent/2311.05657-ACL_2024_Main_Conference.txt
agent/2304.04370-OpenAGI-_When_LLM_Meets_Domain_Experts.txt
agent/2402.03578-LLM_Multi-Agent_Systems-_Challenges_and_Open_Problems.txt
agent/2309.07864-The_Rise_and_Potential_of_Large_Language_Model.txt
agent/2308.10848-Preprint.txt
agent/2306.03314-MULTI_-AGENT_COLLABORATION_-_HARNESSING_THE_POWER_OF.txt
agent/2402.00854-Published_at_3rd_Conference_on_Lifelong_Learning_Agents_(CoLLAs),_2024.txt
agent/2403.16971-AIOS-_LLM_Agent_Operating_System.txt
agent/2402.03628-Professional_Agents_-_Evolving_Large_Language_Models_into_Autonomous.txt
coding/2206.03865-Fault-Aware_Neural_Code_Rankers.txt
coding/2309.07062-Large_Language_Models_for_Compiler_Optimization.txt
coding/2306.10763-Guiding_Language_Models_of_Code_with_Global.txt
coding/2209.07753-Code_as_Policies-_Language_Model_Programs_for_Embodied_Control.txt
coding/2306.05153-Is_AI_the_better_programming_partner.txt
coding/2309.14534-Teach_AI_How_to_Code-_Using_Large_Language_Models_as.txt
coding/2309.07804-Pop_Quiz!_Do_Pre-trained_Code_Models_Possess.txt
coding/2304.11384-Large_Language_Models_are_Few-Shot_Summarizers.txt
coding/2309.12938-Frustrated_with_Code_Quality_Issues_LLMs_can_Help!.txt
coding/2305.04940-The_EarlyBIRD_Catches_the_Bug-_On_Exploiting_Early_Layers_of.txt
coding/2310.15455-Exploring_Mobile_UI_Layout_Generation.txt
coding/2309.03044-Method-Level_Bug_Severity_Prediction_using_Source.txt
coding/2310.10996-ClarifyGPT-_Empowering_LLM-based_Code_Generation_with.txt
coding/2401.00812-If_LLM_Is_the_Wizard,_Then_Code_Is_the_Wand-_A_Survey_on_How.txt
coding/2303.17125-A_Large-Scale_Survey_on_the_Usability_of_AI_Programming.txt
coding/2311.07989-Unifying_the_Perspectives_of_NLP_and_Software_Engineering.txt
coding/2212.10481-Execution-Based_Evaluation_for_Open-Domain_Code_Generation.txt
coding/2301.03270-1.txt
coding/2404.07549-Comments_as_Natural_Logic_Pivots-_Improve_Code_Generation_via.txt
coding/2302.04662-Generating_High-Precision_Feedback_for_Programming.txt
coding/2308.01191-Towards_Understanding_the_Capability_of_Large_Language_Models.txt
coding/2308.11396-Noname_manuscript_No..txt
coding/2306.03438-Large_Language_Models_of_Code_Fail_at.txt
coding/2406.11912--_Dynamic_Collaborative_Agents.txt
coding/2310.13065-CREATIVE_ROBOT_TOOL_USE_WITH_LARGE_LAN.txt
coding/2203.16697-Type-Directed_Program_Synthesis_for_RESTful_APIs.txt
coding/2210.03945-UNDERSTANDING_HTML_WITH_LARGE_LANGUAGE.txt
coding/2106.14316-PYInfer-_Deep_Learning_Semantic_Type_Inference.txt
coding/2307.13018-arXiv-2307.13018v1_[cs.CL]_24_Jul_2023The_potential_of_LLMs_for_coding_with_low-resource_and.txt
coding/2308.16557-Effective_Test_Generation_Using_Pre-trained_Large_Language_Models.txt
coding/2306.06624-RestGPT-_Connecting_Large_Language_Models.txt
coding/2304.06815-Automatic_Semantic_Augmentation_of_Language_Model_Prompts.txt
coding/2212.09420-Large_Language_Models_Meet_NL2Code-_A_Survey.txt
coding/2202.13169-Published_as_a_workshop_paper_at_DL4C_@_ICLR_2022.txt
coding/2302.06527-1.txt
coding/2305.18607-How_Effective_Are_Neural_Networks_for_Fixing_Security.txt
coding/2308.10620-1.txt
coding/2306.03324-How_Effective_are_Large_Language_Models_in.txt
coding/2309.15742-T5APR-_E_MPOWERING_AUTOMATED_PROGRAM_REPAIR_ACROSS.txt
coding/2306.07487-TRACED-_Execution-aware_Pre-training_for_Source_Code.txt
coding/2307.15370-Highlights.txt
coding/2307.07924-ChatDev-_Communicative_Agents_for_Software_Development.txt
coding/2410.01215-Preprint.txt
coding/2310.05727-THEPROGRAM_TESTING_ABILITY_OF_LARGE_LAN.txt
coding/2404.18766-PECC-_Problem_Extraction_and_Coding_Challenges.txt
coding/2404.14662-2024-4-24.txt
coding/2212.10017-Unveiling_Code_Pre-Trained_Models-_Investigating_Syntax_and.txt
coding/2305.09082-The_Good,_the_Bad,_and_the_Missing-_Neural_Code_Generation_for_Machine.txt
coding/2308.09895-Knowledge_Transfer_from_High-Resource_to_Low-Resource.txt
coding/2312.00894-Leveraging_Large_Language_Models_to_Improve_REST_API_Testing.txt
coding/2402.09136-DolphCoder-_Echo-Locating_Code_Large_Language_Models_with.txt
coding/2207.03578-CODE_TRANSLATION_WITH_COMPILER.txt
coding/2302.06144-SKCODER_-_A_Sketch-based_Approach_for.txt
coding/2306.01754-Transformer-based_Vulnerability_Detection_in_Code_at_EditTime.txt
coding/2311.14904-LLM-A_SSISTED_CODE_CLEANING_FORTRAINING_AC.txt
coding/2306.00029-CODETF-_O_NE-STOP_TRANSFORMER_LIBRARY_FOR.txt
coding/2406.01006-SEMCODER_-_Training_Code_Language_Models_with.txt
coding/2302.08468-LEVER_-_Learning_to_Verify_Language-to-Code_Generation_with_Execution.txt
coding/2309.09308-GAMMA_-_Revisiting_Template-based_A_utomated.txt
coding/2109.00084-Program_Merge_Conflict_Resolution_via_Neural_Transformers.txt
coding/2303.08033-Large_Language_Models_(GPT)_Struggle_to_Answer_Multiple-Choice.txt
coding/2306.03203-A_Static_Evaluation_of_Code_Completion_by_Large_Language_Models.txt
coding/2310.08879-A_Critical_Review_of_Large_Language_Model_on_Software.txt
coding/2309.00608-Copiloting_the_Copilots-_Fusing_Large_Language_Models_with.txt
coding/2310.08588-Octopus-_Embodied_Vision-Language.txt
coding/2402.08073-Grounding_Data_Science_Code_Generation_with_Input-Output_Specifications.txt
coding/2203.13474-Published_as_a_conference_paper_at_ICLR_2023.txt
coding/2310.16673-Exploring_Large_Language_Models_for.txt
coding/2308.03873-Evaluating_and_Explaining_Large_Language_Models.txt
coding/2401.08500-Code_Generation_with_AlphaCodium-_From_Prompt_Engineering_to_Flow.txt
coding/2311.03366-Functional_Overlap_Reranking_for_Neural_Code_Generation.txt
coding/2305.06161-Published_in_Transactions_on_Machine_Learning_Research_(12-2023).txt
coding/2303.18116-arXiv-2303.18116v1_[cs.CL]_31_Mar_2023Pair_Programming_with_Large_Language_Models.txt
coding/2309.09506-Preprint.txt
coding/2307.07221-1.txt
coding/2305.04106-On_the_Usage_of_Continual_Learning_for_Out-of-Distribution.txt
coding/2305.16430-Too_Few_Bug_Reports_Exploring_Data_Augmentation_for.txt
coding/2306.12643-FLAG-_Finding_Line_Anomalies_(in_code)_with_Generative_AI.txt
multi-task/2208.05379-Multi-task_Active_Learning_for_Pre-trained_Transformer-based_Models.txt
multi-task/2304.04959-AdaTT-_Adaptive_Task-to-Task_Fusion_Network_for_Multitask.txt
multi-task/2211.13723-Improving_Multi-task_Learning.txt
multi-task/2307.15429-Improvable_Gap_Balancing_for_Multi-Task_Learning.txt
multi-task/2301.02494-Adaptive_Pattern_Extraction_Multi-Task_Learning_for.txt
multi-task/2307.03374-STG-MTL-_Scalable_Task_Grouping.txt
multi-task/2308.05996-Deep_Task-specific_Bottom_Representation_Network_for.txt
recursive/2106.06038-arXiv-2106.06038v1_[cs.CL]_10_Jun_2021Modeling_Hierarchical_Structures_with_Continuous_Recursi_ve_Ne.txt
recursive/2111.05297-Sliced_Recursive_Transformer.txt
softmax/2309.14808-Revisiting_Softmax_Masking.txt
tabular/2106.07258-30GitTables-_A_Large-Scale_Corpus_of_Relational_Tables.txt
tabular/2310.09263-Table-GPT-_Table-tuned_GPT_for_Diverse_Table_Tasks.txt
requirements.txt
ffn-mlp/2306.01470-Understanding_MLP-Mixer_as_a_Wide_and_Sparse_MLP.txt
ffn-mlp/2306.13575-Scaling_MLPs-_A_Tale_of_Inductive_Bias.txt
ffn-mlp/2309.01826-One_Wide_Feedforward_is_All_You_Need.txt
ffn-mlp/2108.04384-RaftMLP-_How_Much_Can_Be_Done_Without.txt
ffn-mlp/2112.00980-Trap_of_Feature_Diversity_in_the_Learning_of_MLPs.txt
ffn-mlp/2301.05816-Understanding_the_Spectral_Bias_of_Coordinate_Based.txt
ffn-mlp/2404.19756-KAN-_Kolmogorov–Arnold_Networks.txt
document-parsing/2109.10282-TrOCR-_Transformer-based_Optical_Character_Recognition.txt
document-parsing/2309.01131-Attention_Where_It_Matters-_Rethinking_Visual_Document_Understanding.txt
document-parsing/2306.01733-DocFormerv2-_Local_Features_for_Document_Understanding.txt
document-parsing/2211.03256-On_Web-based_Visual_Corpus_Construction.txt
document-parsing/2111.15664-OCR-free_Document_Understanding_Transformer.txt
document-parsing/2304.12484-DocParser-_End-to-end_OCR-free_Information.txt
grounding/2308.08434-A_Bi-Step_Grounding_Paradigm_for_Large_Language_Models_in_Recommendation.txt
grounding/2311.08398-Are_Large_Language_Models_Temporally_Grounded.txt
bias/2211.00609-A_Simple,_Yet_Effective_Approach_to_Finding_Biases_in_Code_Generation.txt
bias/2309.04081-UER-_A_Heuristic_Bias_Addressing_Approach.txt
bias/2211.01154-Mitigating_Popularity_Bias_in_Recommendation_with.txt
bias/2309.14345-Bias_Testing_and_Mitigation_in_LLM-based_Code_Generation.txt
annotation/2305.17384-Received-_Added_at_production_Revised-_Added_at_production_Accepted-_Added_at_production.txt
annotation/2303.16854-AnnoLLM-_Making_Large_Language_Models_to_Be_Better.txt
reflection/2312.09300-Self-Evaluation_Improves_Selective_Generation_in.txt
reflection/2402.04858-CodeIt-_Self-Improving_Language_Models_with_Prioritized_Hindsight_Replay.txt
random/2205.08099-Dimensionality_Reduced_Training_by_Pruning_and_Freezing.txt
random/2004.06278-Squares-_A_Fast_Counter-Based_RNG.txt
random/2310.19925-arXiv-2310.19925v1_[cs.DC]_30_Oct_2023OpenRAND-_A_Performance_Portable,_Reproducible_Random_Num_ber_.txt
random/2206.08464-PRANC-_Pseudo_RAndom_Networks_for_Compacting_deep_models.txt
federated-learning/2309.06805-FedDIP-_Federated_Learning_with_Extreme.txt
federated-learning/2211.01452-Published_as_a_conference_paper_at_ICLR_2023.txt
federated-learning/2406.00302-FedAST-_Federated_Asynchronous_Simultaneous_Training.txt
federated-learning/2206.04385-HideNseek-_Federated_Lottery_Ticket_via.txt
federated-learning/2309.13536-Tackling_Intertwined_Data_and_Device_Heterogeneities.txt
conditional/2506.21103-arXiv-2506.21103v1_[cs.LG]_26_Jun_2025Learning_to_Skip_the_Middle_Layers_of_Transformers.txt
embeddings/2106.13302-byteSteady-_Fast_Classification_Using_Byte-Level_n-Gram.txt
embeddings/1703.00607-Dynamic_Word_Embeddings_for_Evolving_Semantic_Discovery.txt
embeddings/2101.09469-TRAINING_MULTILINGUAL_PRE-TRAINED_LANGUAGE_MODELS.txt
embeddings/1702.08359-Dynamic_Word_Embeddings.txt
embeddings/2310.20144-EELBERT-_Tiny_Models_through_Dynamic_Embeddings.txt
embeddings/2010.12730-Char2Subword-_Extending_the_Subword_Embedding_Space_Using.txt
embeddings/2011.01513-CharBERT-_Character-aware_Pre-trained_Language_Model.txt
embeddings/2401.00368-Improving_Text_Embeddings_with_Large_Language_Models.txt
llm-architecture/2202.00275-Architecture_Matters_in_Continual_Learning.txt
llm-architecture/2404.14619-OpenELM-_An_Efficient_Language_Model_Family_with_Open_Training_and.txt
uncertainty/2311.09677-R-Tuning-_Instructing_Large_Language_Models_to.txt
uncertainty/2307.09254-Selective_Generation_for.txt
uncertainty/2307.10236-IEEE_TRANSACTIONS_ON_SOFTWARE_ENGINEERING,_VOL._,_NO._,_2024_1.txt
uncertainty/2305.19187-Published_in_Transactions_on_Machine_Learning_Research_(05-2024).txt
uncertainty/2306.12190-Quantifying_lottery_tickets_under_label_noise.txt
semantic-segmentation/2306.08075-BPKD-_Boundary_Privileged_Knowledge_Distillation.txt
semantic-segmentation/2202.13393-IEEE_TRANSACTIONS_ON_INTELLIGENT_TRANSPORTATION_SYSTEMS,_SEPTEMBER_2024_1.txt
moe/2106.10715-CPM-2-_Large-scale_Cost-effective_Pre-trained_Language_Models.txt
moe/2202.09368-Mixture-of-Experts_with_Expert_Choice_Routing.txt
moe/2201.10890-One_Student_Knows_All_Experts_Know-_From_Sparse_to_Dense.txt
moe/2310.07096-Sparse_Universal_Transformer.txt
moe/2202.01169-UNIFIED_SCALING_LAWS_FOR_ROUTED_LANGUAGE_MODELS.txt
moe/2311.10770-Exponentially_Faster_Language_Modeling.txt
moe/2204.09598-BUILD_A_ROBUST_QA_S_YSTEM_WITH_TRANSFORMER_-BASED.txt
moe/2212.05055-Published_as_a_conference_paper_at_ICLR_2023.txt
moe/2310.14188-A_General_Theory_for_Softmax_Gating_Multinomial_Logistic_Mixture_of_Experts.txt
moe/2311.10768-Memory_Augmented_Language_Models_through.txt
moe/2206.04046-Published_as_a_conference_paper_at_ICLR_2023.txt
moe/2310.04361-Exploiting_Activation_Sparsity_with_Dense_to.txt
moe/2306.03900-MODEL_SPIDER_-_Learning_to_Rank.txt
moe/2205.12701-Eliciting_and_Understanding_Cross-Task_Skills.txt
moe/2308.14711-Fast_Feedforward_Networks.txt
moe/2303.14177-Scaling_Expert_Language_Models_with_Unsupervised_Domain_Discovery.txt
moe/1312.4314-Learning_Factored_Representations_in_a.txt
moe/2205.01848-OPTIMIZING_MIXTURE_OF_EXPERTS_USING_DYNAMIC_RECOMPILATIONS.txt
moe/2207.09094-MoEC-_Mixture_of_Expert_Clusters.txt
moe/1312.4314.txt
moe/2112.10684-Efﬁcient_Large_Scale_Language_Modeling_with_Mixtures_of_Experts.txt
moe/2404.15045-Multi-Head_Mixture-of-Experts.txt
moe/2203.03312-SkillNet-NLU-_A_Sparsely_Activated_Model_for_General-Purpose_Natural.txt
moe/2211.13491-Spatial_Mixture-of-Experts.txt
moe/2402.01739-OpenMoE-_An_Early_Effort_on_Open.txt
moe/2308.12066-Pre-gated_MoE-_An_Algorithm-System_Co-Design_for.txt
moe/2110.04260-Published_as_a_conference_paper_at_ICLR_2022.txt
moe/2407.04153-Mixture_of_A_Million_Experts.txt
moe/2207.05080.txt
moe/2211.15841-MEGA_BLOCKS_-_EFFICIENT_SPARSE_TRAINING_WITH_MIXTURE_-OF-EXPERTS.txt
moe/2309.13850-Published_as_a_conference_paper_at_ICLR_2024.txt
moe/2405.16039-MoEUT-_Mixture-of-Experts_Universal_Transformers.txt
moe/2402.05859-Learning_to_Route_Among_Specialized_Experts_for_Zero-Shot_Generalization.txt
moe/2310.15961-Mixture_of_Tokens-_Continuous_MoE_through.txt
moe/2305.03288-Demystifying_Softmax_Gating_Function_in.txt
moe/2211.00558-IEEE_TRANSACTIONS_ON_INDUSTRIAL_INFORMATICS,_VOL._X,_NO._Y_,_MONTH_YEAR_1.txt
moe/2106.10595-IEEE-ACM_TRANSACTIONS_ON_COMPUTATIONAL_BIOLOGY_AND_BIOINFORMATICS,_ACCEPTED_11_MAY_2022._1.txt
moe/2202.08906-ST-M_OE-_D_ESIGNING_STABLE_AND_TRANSFERABLE.txt
moe/2206.00277-Task-Speciﬁc_Expert_Pruning_for_Sparse.txt
moe/2209.01667-A_R_EVIEW_OF_SPARSE_EXPERT_MODELS_IN.txt
moe/2204.10598-Sparsely-gated_Mixture-of-Expert_Layers_for_CNN.txt
moe/2112.14397-EvoMoE-_An_Evolutional_Mixture-of-Experts.txt
moe/2204.12184-SkillNet-NLG-_General-Purpose_Natural_Language_Generation_with_a.txt
moe/2310.01334-Published_as_a_conference_paper_at_ICLR_2024.txt
moe/2310.10837-Approximating_Two-Layer_Feedforward_Networks.txt
moe/2305.18691-Edge-MoE-_Memory-Efficient_Multi-Task_Vision_Transformer.txt
moe/2204.09179-On_the_Representation_Collapse_of.txt
moe/2401.06066-DeepSeekMoE-_Towards_Ultimate_Expert_Specialization_in.txt
moe/2306.04845-Mixture-of-Supernets-_Improving_Weight-Sharing_Supernet_Training_with.txt
moe/2204.08396-STABLE_MOE-_Stable_Routing_Strategy_for_Mixture_of_Experts.txt
moe/2112.06905-GLaM-_Efﬁcient_Scaling_of_Language_Models_with_Mixture-of-Experts.txt
moe/2309.04354-Mobile_V-MoEs-_Scaling_Down_Vision_Transformers.txt
moe/2205.12399-Sparse_Mixers-_Combining_MoE_and_Mixing_to_build_a_more_efﬁcient.txt
moe/2211.08253-HMOE-_Hypernetwork-based_Mixture_of_Experts_for_Domain_Generalization.txt
moe/2310.07188-Adaptive_Gating_in_Mixture-of-Experts_based_Language_Models.txt
moe/2210.03869-TAME-_Task_Agnostic_Continual_Learning_using_Multiple_Experts.txt
moe/2405.16836-Enhancing_Fast_Feed_Forward_Networks_with.txt
moe/2208.02813-Towards_Understanding_Mixture_of_Experts_in_Deep.txt
moe/2212.05191-SMILE-_S_CALING_MIXTURE_-OF-EXPERTS_WITH_EFFICIENT.txt
moe/2210.04995-FEAMOE-_Fair,_Explainable_and_Adaptive_Mixture.txt
moe/2201.05596-DeepSpeed-MoE-_Advancing_Mixture-of-Experts_Inference.txt
moe/2310.10908-Unlocking_Emergent_Modularity_in_Large_Language_Models.txt
moe/2310.09832-Merging_Experts_into_One.txt
moe/2310.00811-SPARSE_BACKPROPAGATION_FOR_MOE_T_RAINING.txt
moe/2203.06850-Efﬁcient_Language_Modeling_with_Sparse_all-MLP.txt
moe/2209.15207-MIXTURE_OF_EXPERTS_MODELS_FOR_MULTILEVEL_DATA.txt
data-processing/2309.02033-Data-Juicer_-_A_One-Stop_Data_Processing_System_for_Large.txt
inference/2308.03421.txt
named-entity-recognition-ner/2305.05711-CODEIE-_Large_Code_Generation_Models_are_Better_Few-Shot.txt
named-entity-recognition-ner/2301.08855-ProKD-_An_Unsupervised_Prototypical_Knowledge_Distillation_Network_for.txt
sampling/2309.01953-Bilevel_Scheduled_Sampling_for_Dialogue.txt
sampling/2205.06036-Efﬁcient_and_Training-Free_Control_of_Language_Generation.txt
sampling/2202.00666-arXiv-2202.00666v6_[cs.CL]_5_Jun_2025Locally_Typical_Sampling.txt
music/2308.12982-A_Survey_of_AI_Music_Generation_Tools_and_Models.txt
music/2411.07539-Harmonizing_Pixels_and_Melodies-_Maestro-Guided.txt
instruct/2308.08239-MemoChat-_Tuning_LLMs_to_Use_Memos_for_Consistent_Long-Range.txt
instruct/2307.15504.txt
instruct/2212.09689-Unnatural_Instructions.txt
instruct/2407.03040-Raw_Text_is_All_you_Need-_Knowledge-intensive_Multi-turn_Instruction.txt
instruct/2305.04032-ToolCoder-_Teach_Code_Generation_Models_to_use.txt
instruct/2303.10475-Large_Language_Model_Instruction_Following-_A_Survey.txt
instruct/2405.16579-Automatically_Generating_Numerous_Context-Driven.txt
instruct/2308.10792-Instruction_Tuning_for_Large_Language_Models-_A_Survey.txt
instruct/2308.12711-Harnessing_the_Power_of_David_against_Goliath-_Exploring_Instruction_Data.txt
instruct/2306.04751-How_Far_Can_Camels_Go_Exploring_the_State_of.txt
instruct/2310.13023-GraphGPT-_Graph_Instruction_Tuning_for_Large_Language_Models.txt
instruct/2311.00272-ChatCoder-_Chat-based_Refine_Requirement_Improves_LLMs’.txt
concept/2311.08968-Identifying_Linear_Relational_Concepts_in_Large_Language_Models.txt
missing_papers.txt
positional-embeddings/2305.13571-Latent_Positional_Information_is_in_the_Self-Attention_Variance_of.txt
positional-embeddings/2204.08142-Dynamic_Position_Encoding_for_Transformers.txt
positional-embeddings/2205.13522-JOURNAL_OF_L_ATEX_CLASS_FILES,_VOL._14,_NO._8,_AUGUST_2015_1.txt
positional-embeddings/2310.04861-Uncovering_hidden_geometry_in_Transformers_via_disentangling.txt
positional-embeddings/1905.04226-Language_Modeling_with_Deep_Transformers.txt
positional-embeddings/2207.07611-Position_Prediction_as_an_Effective_Pretraining_Strategy.txt
positional-embeddings/2203.16634-Transformer_Language_Models_without_Positional_Encodings.txt
special-tokens/2311.15436-Learning_to_Skip_for_Language_Modeling.txt
grammar/2305.09857-COEDIT-_Text_Editing_by_Task-Specific_Instruction_Tuning.txt
grammar/2305.08339-1_This_is_the_final_accepted_version_of_an_article_that_is_due_to_appear_in_the.txt
grammar/2309.11439-Controlled_Generation_with_Prompt_Insertion_for_Natural_Language.txt
medical/2312.01040-A_Technique_Report.txt
rl-alignment/2306.03680-Published_in_Transactions_on_Machine_Learning_Research_(05-2024).txt
rl-alignment/2310.01432-Split_and_Merge-_Aligning_Position_Biases_in_LLM-based_Evaluators.txt
rl-alignment/2211.03959-Pretraining_in_Deep_Reinforcement_Learning-_A_Survey.txt
rl-alignment/2402.12479-In_value-based_deep_reinforcement_learning,.txt
rl-alignment/2111.03788-Journal_of_Machine_Learning_Research_23_(2022)_1-20_Submitted_1-22;_Revised_9-22;_Published_10-22.txt
rl-alignment/2306.07541-A_Simple_Unified_Uncertainty-Guided_Framework_for.txt
rl-alignment/2209.12106-Moral_Mimicry-_Large_Language_Models_Produce_Moral_Rationalizations.txt
rl-alignment/2303.16749-Improving_Code_Generation_by_Training_with_Natural_Language_Feedback.txt
rl-alignment/2309.02632-Deep_Reinforcement_Learning_from_Hierarchical.txt
rl-alignment/2203.02155-Training_language_models_to_follow_instructions.txt
rl-alignment/2310.11971-Preprint._Under_review..txt
rl-alignment/2308.03188-Automatically_Correcting_Large_Language_Models.txt
rl-alignment/2310.18168-PERSONAS_AS_A_WAY_TO_MODEL_TRUTHFULNESS_IN.txt
rl-alignment/2310.03173-Published_as_a_conference_paper_at_ICLR_2024.txt
rl-alignment/2310.02456-LEARNING_OPTIMAL_ADVANTAGE_FROM_PREFERENCES_AND.txt
rl-alignment/2310.16763-SuperHF-_Supervised_Iterative_Learning.txt
rl-alignment/2302.03328-Multi-Task_Recommendations_with_Reinforcement_Learning.txt
rl-alignment/2312.00849-RLHF-V-_Towards_Trustworthy_MLLMs_via_Behavior_Alignment_from.txt
rl-alignment/2209.07676-Conservative_Dual_Policy_Optimization_for_Efﬁcient.txt
rl-alignment/2308.04275-In-Context_Alignment-_Chat_with_Vanilla_Language_Models.txt
rl-alignment/2312.15997-Aligning_Large_Language_Models_with_Human_Preferences.txt
rl-alignment/2310.20624-Published_at_ICLR_2024_Workshop_on_Secure_and_Trustworthy_Large_Language_Models.txt
rl-alignment/2211.11092-Q-Ensemble_for_Ofﬂine_RL-_Don’t_Scale_the.txt
rl-alignment/2305.03047-Principle-Driven_Self-Alignment_of_Language_Models.txt
rl-alignment/2210.06518-Semi-Supervised_Offline_Reinforcement_Learning_with_Action-Free_Trajectories.txt
rl-alignment/2309.00267-RLAIF_vs._RLHF-_Scaling_Reinforcement_Learning.txt
rl-alignment/2307.14324-Evaluating_the_Moral_Beliefs_Encoded_in_LLMs.txt
rl-alignment/2310.12036-A_General_Theoretical_Paradigm_to_Understand_Learning_from.txt
rl-alignment/2305.10425-SLiC-HF-_Sequence_Likelihood_Calibration_with.txt
rl-alignment/2304.14553-A_p_p_r_o_p_r_i_a_t_e_n_e_s_s.txt
rl-alignment/2302.02948-Efficient_Online_Reinforcement_Learning_with_Offline_Data.txt
rl-alignment/2211.03352-1.txt
rl-alignment/2309.10150-Q-Transformer-_Scalable_Offline_Reinforcement.txt
rl-alignment/2211.03032-Preprint.txt
rl-alignment/2406.00888-Published_as_a_conference_paper_at_ICLR_2025.txt
rl-alignment/2406.11827-WPO-_Enhancing_RLHF_with_Weighted_Preference_Optimization.txt
rl-alignment/2401.07382-Beyond_Sparse_Rewards-_Enhancing_Reinforcement_Learning_with.txt
rl-alignment/2310.13024-Towards_Anytime_Fine-tuning-_Continually_Pre-trained_Language_Models.txt
rl-alignment/2308.15812-Published_as_a_conference_paper_at_ICLR_2024.txt
rl-alignment/2401.07301-Small_Language_Model_Can_Self-Correct.txt
rl-alignment/2305.13735-Aligning_Large_Language_Models_through_Synthetic_Feedback.txt
rl-alignment/2311.14543-Data-Efficient_Alignment_of_Large_Language_Models.txt
rl-alignment/2305.06474-Do_LLMs_Understand_User_Preferences_Evaluating_LLMs_On_User_Rating.txt
rl-alignment/2303.16755-Training_Language_Models_with_Language_Feedback_at_Scale.txt
rl-alignment/2305.06176-Fine-tuning_Large_Language_Models_with.txt
rl-alignment/2405.00675-Self-Play_Preference_Optimization_for_Language_Model.txt
rl-alignment/2306.13085-Published_as_a_conference_paper_at_ICLR_2023.txt
rl-alignment/2308.08998-2023-8-22.txt
rl-alignment/2307.12966-Aligning_Large_Language_Models_with_Human-_A_Survey.txt
rl-alignment/2307.15217-Open_Problems_and_Fundamental_Limitations_of.txt
rl-alignment/2310.17022-Controlled_Decoding_from_Language_Models.txt
rl-alignment/2306.01242-Responsible_Task_Automation-_Empowering_Large.txt
rl-alignment/2312.03814-Journal_of_Machine_Learning_Research_25_(2024)_1-30_Submitted_2-24;_Revised_6-24;_Published_8-24.txt
rl-alignment/2310.12773-SAFE_RLHF-_S_AFE_REINFORCEMENT_LEARNING.txt
rl-alignment/2310.17750-A_Framework_for_Automated_Measurement_of_Responsible_AI.txt
rl-alignment/2309.16231-Controllable_Text_Generation_with_Residual_Memory_Transformer.txt
rl-alignment/2310.09520-Reward-Augmented_Decoding-_Efficient_Controlled_Text_Generation.txt
rl-alignment/2307.04964-Secrets_of_RLHF_in_Large_Language_Models.txt
rl-alignment/2310.13798-Specific_versus_General_Principles_for_Constitutional_AI.txt
rl-alignment/2309.15025-Large_Language_Model_Alignment-_A_Survey.txt
rl-alignment/2111.04714-Published_at_1st_Conference_on_Lifelong_Learning_Agents,_2022.txt
rl-alignment/2308.12014-From_Instructions_to_Intrinsic_Human_Values_——.txt
rl-alignment/2309.11235-Published_as_a_conference_paper_at_ICLR_2024.txt
rl-alignment/2311.08401-Fine-tuning_Language_Models_for_Factuality.txt
rl-alignment/2402.00742-Transforming_and_Combining_Rewards.txt
rl-alignment/2402.00396-Efficient_Exploration_for_LLMs.txt
rl-alignment/2302.06884-Conservative_State_Value_Estimation_for_Offline.txt
rl-alignment/2402.08609-Mixtures_of_Experts_Unlock_Parameter_Scaling_for_Deep_RL.txt
rl-alignment/2312.14878-Pangu-Agent-_A_Fine-Tunable_Generalist_Agent.txt
rl-alignment/2505.16410-Tool-Star-_Empowering_LLM-Brained_Multi-Tool.txt
rl-alignment/2310.00771-Published_as_a_conference_paper_at_ICLR_2024.txt
rl-alignment/2305.09836-Revisiting_the_Minimalist_Approach_to_Offline.txt
rl-alignment/2305.17926-Large_Language_Models_are_not_Fair_Evaluators.txt
rl-alignment/2306.01693-Fine-Grained_Human_Feedback_Gives_Better_Rewards.txt
rl-alignment/2305.05586-1.txt
rl-alignment/2309.10202-STABILIZING_RLHF_THROUGH_ADVANTAGE_MODEL.txt
rl-alignment/2306.09896-Published_as_a_conference_paper_at_ICLR_2024.txt
rl-alignment/2305.18290-Direct_Preference_Optimization.txt
rl-alignment/2312.09244-Published_as_a_conference_paper_at_COLM_2024.txt
rl-alignment/2301.11063-Rewarded_meta-pruning-_Meta_Learning_Using_Rewards_for_Channel_Pruning.txt
rl-alignment/2312.07000-Alignment_for_Honesty.txt
rl-alignment/2311.08692-Routing_to_the_Expert-_Efficient_Reward-guided_Ensemble_of_Large.txt
rl-alignment/2402.01391-StepCoder-_Improve_Code_Generation.txt
rl-alignment/2207.00461-Lifelong_Inverse_Reinforcement_Learning.txt
rl-alignment/2310.10076-Verbosity_Bias_in_Preference_Labeling.txt
rl-alignment/2308.05374-TRUSTWORTHY_LLM_S-ASURVEY_AND_GUIDELINE_FOR.txt
rl-alignment/2007.04756-7th_ICML_Workshop_on_Automated_Machine_Learning_(2020).txt
rl-alignment/2306.04930-When_to_Show_a_Suggestion_Integrating_Human.txt
rl-alignment/2310.02743-Published_as_a_conference_paper_at_ICLR_2024.txt
rl-alignment/2302.06692-Guiding_Pretraining_in_Reinforcement_Learning_with_Large_Language_Models.txt
rl-alignment/2302.02662-Grounding_Large_Language_Models_in_Interactive.txt
rl-alignment/2401.12086-West-of-N-_Synthetic_Preferences.txt
rl-alignment/2308.10149-Procedia_Computer_Science_00_(2024)_1–28Procedia.txt
rl-alignment/2206.00059-A_Mixture-of-Expert_Approach.txt
rl-alignment/2401.16635-Improving_Reinforcement_Learning_from_Human_Feedback_with.txt
rl-alignment/2305.14718-Published_as_a_conference_paper_at_ICLR_2024.txt
rl-alignment/2311.00267-Rethinking_Decision_Transformer_via_Hierarchical.txt
rl-alignment/2310.02527-CITING_-_LARGE_LANGUAGE_MODELS_CREATE_CUR.txt
rl-alignment/2310.00898-Published_as_a_conference_paper_at_ICLR_2024.txt
rl-alignment/2306.02231-Fine-Tuning_Language_Models.txt
rl-alignment/2307.04349-Published_in_Transactions_on_Machine_Learning_Research_(11-2023).txt
rl-alignment/2309.15028-Preprint.txt
rl-alignment/2310.05470-GENERATIVE_JUDGE_FOR_EVALUATING_ALIGNMENT.txt
rl-alignment/2405.01525-FLAME.txt
rl-alignment/2305.13804-OER-_Offline_Experience_Replay_for_Continual_Offline.txt
rl-alignment/2405.01481-Published_as_a_conference_paper_at_COLM_2024.txt
rl-alignment/2310.08491-PROMETHEUS_-_INDUCING_FINE-GRAINED.txt
rl-alignment/2309.01352-Self-driven_Grounding-_Large_Language_Model_Agents_with_Automatical.txt
rl-alignment/2308.14328-JOURNAL_OF_L_ATEX_CLASS_FILES,_VOL._14,_NO._8,_AUGUST_2021_1.txt
rl-alignment/2310.05910-Published_as_a_conference_paper_at_ICLR_2024.txt
rl-alignment/2310.00212-Under_review_as_a_conference_paper.txt
rl-alignment/2104.10995-Published_as_a_workshop_paper_at_“BRAIN2AI”_(ICLR_2021).txt
rl-alignment/2306.06871-ENOTO-_Improving_Offline-to-Online_Reinforcement_Learning_with_Q-Ensembles.txt
rl-alignment/2308.12050-Aligning_Language_Models_with_Offline_Learning_from_Human_Feedback.txt
rl-alignment/2310.11986-arxiv.org-abs-123.txt
rl-alignment/2311.04235-Can_LLMs_Follow_Simple_Rules.txt
rl-alignment/2310.13385-Tuna-_Instruction_Tuning_using_Feedback_from_Large_Language_Models.txt
rl-alignment/2309.03409-LARGE_LANGUAGE_MODELS_AS_OPTIMIZERS.txt
rl-alignment/2401.16335-Iterative_Data_Smoothing-_Mitigating_Reward_Overfitting_and.txt
rl-alignment/2307.03406-Goal-Conditioned_Predictive_Coding_for_Offline.txt
rl-alignment/2401.10020-Self-Rewarding_Language_Models.txt
rl-alignment/2310.13032-QUALITY_-DIVERSITY_THROUGH_AI_F_EEDBACK.txt
rl-alignment/2310.16944-Technical_Report.txt
rl-alignment/2305.06361-Published_in_Transactions_on_Machine_Learning_Research_(March-2025).txt
rl-alignment/2305.16217-Beyond_Reward-_Offline_Preference-guided_Policy_Optimization.txt
rl-alignment/2401.06080-Secrets_of_RLHF_in_Large_Language_Models.txt
rl-alignment/2310.13548-Published_as_a_conference_paper_at_ICLR_2024.txt
rl-alignment/2307.11137-OFMODELS_AND_TINMEN-_A_BEHAVIOURAL_ECONOMICS.txt
rl-alignment/2310.01377-ULTRA_FEEDBACK_-_Boosting_Language_Models_with_Scaled_AI_Feedback.txt
rl-alignment/2309.00754-EFFICIENT_RLHF-_R_EDUCING_THE_MEMORY.txt
rl-alignment/2310.20654-Closed_Drafting_as_a_Case_Study_for_First-Principle_Interpretability,_Memory,_and.txt
rl-alignment/2310.15337-Moral_Foundations_of_Large_Language_Models.txt
rl-alignment/2207.01780-CodeRL-_Mastering_Code_Generation_through.txt
rl-alignment/2311.05596-LLM_Augmented_Hierarchical_Agents.txt
rl-alignment/2311.08487-Preprint.txt
rl-alignment/2309.06657-Published_as_a_conference_paper_at_ICLR_2024.txt
context-compression/2310.02409-DODO_-_Dynamic_Contextual_Compression_for_Decoder-only_LMs.txt
context-compression/2107.00910-Learned_Token_Pruning_for_Transformers.txt
context-compression/2111.15667-Adaptive_Token_Sampling_For_Efficient_Vision.txt
context-compression/2112.08560-Block-Skim-_Efﬁcient_Question_Answering_for_Transformer.txt
context-compression/2304.01083-Can_the_Inference_Logic_of_Large_Language_Models_be_Disentangled_into.txt
context-compression/2206.14390-Diet_Code_Is_Healthy-_Simplifying_Programs_for_Pre-trained.txt
context-compression/2307.10780-Published_in_Transactions_on_Machine_Learning_Research_(08-2023).txt
context-compression/2310.17157-Deja_Vu-_Contextual_Sparsity_for_Efficient_LLMs_at_Inference_Time.txt
context-compression/2305.15805-Dynamic_Context_Pruning_for_Efficient_and.txt
context-compression/2308.01944-Dynamic_Token-Pass_Transformers_for_Semantic_Segmentation.txt
context-compression/2305.11862-Reducing_Sequence_Length_by_Predicting_Edit_Spans_with_Large_Language.txt
context-compression/2306.04897-Multi-Scale_And_Token_Mergence-_Make_Your_ViT.txt
context-compression/2308.15022-Recursively_Summarizing_Enables_Long-Term_Dialogue.txt
context-compression/2405.17052-Highlights.txt
context-compression/2211.11586-Random-LTD-_Random_and_Layerwise_Token_Dropping_Brings.txt
context-compression/2308.01045-Dynamic_Token_Pruning_in_Plain_Vision_Transformers.txt
interpretability/2305.03452-arXiv-2305.03452v1_[cs.LG]_5_May_2023A_technical_note_on_bilinear_layers_for_interpretability.txt
interpretability/2311.13110-White-Box_Transformers_via_Sparse_Rate_Reduction.txt
contrastive/2311.08981-Speculative_Contrastive_Decoding.txt
contrastive/2002.08232-CoLES-_Contrastive_Learning_for_Event_Sequences_with.txt
contrastive/2207.05615-CONTRASTIVE_LEARNING_FOR_ONLINE_SEMI-SUPERVISED_GENERAL.txt
contrastive/2301.09072-ContraBERT-_Enhancing_Code_Pre-trained_Models.txt
contrastive/2309.02301-CIEM-_Contrastive_Instruction_Evaluation_Method_for.txt
contrastive/2108.06552-1.txt
contrastive/2310.09342-Ranking_LLM-Generated_Loop_Invariants_for_Program_Verification.txt
contrastive/2309.15038-JOURNAL_OF_L_ATEX_CLASS_FILES,_VOL._14,_NO._8,_AUGUST_2021_1.txt
contrastive/2303.13405-SC-MIL-_Supervised_Contrastive_Multiple_Instance_Learning_for_Imbalanced.txt
contrastive/2306.05101-Regularizing_with_Pseudo-Negatives_for_Continual_Self-Supervised_Learning.txt
contrastive/2304.04408-PCR-_Proxy-based_Contrastive_Replay.txt
contrastive/2309.03883-Published_as_a_conference_paper_at_ICLR_2024.txt
contrastive/2310.13639-Published_as_a_conference_paper_at_ICLR_2024.txt
contrastive/2305.13477-Look-back_Decoding_for_Open-Ended_Text_Generation.txt
contrastive/2204.03293-CoCoSoDa-_Effective_Contrastive_Learning_for.txt
contrastive/2210.04513-Improving_Continual_Relation_Extraction_through.txt
reparameterization/2106.10404-Sparse_Training_via_Boosting_Pruning_Plasticity.txt
cot/2308.04679-Sci-CoT-_Leveraging_Large_Language_Models_for.txt
cot/2310.13671-Let’s_Synthesize_Step_by_Step_-_Iterative_Dataset_Synthesis_with_Large.txt
cot/2205.11916-Large_Language_Models_are_Zero-Shot_Reasoners.txt
cot/2402.11532-Chain-of-Instructions-_Compositional_Instruction_Tuning_on.txt
cot/2312.02179-Training_Chain-of-Thought_via_Latent-Variable.txt
cot/2409.08561-Expediting_and_Elevating_Large_Language_Model.txt
cot/2311.08263-Fast_Chain-of-Thought-_A_Glimpse_of_Future_From_Jacobi_Decoding_Leads.txt
cot/2407.03181-Fine-Tuning_on_Diverse_Reasoning_Chains_Drives.txt
cot/2307.07099-Controllable_Data_Augmentation_for_Few-Shot_Text_Mining_with.txt
cot/2212.08061-On_Second_Thought,_Let’s_Not_Think_Step_by_Step!.txt
cot/2405.09335-Prompting-based_Synthetic_Data_Generation.txt
cot/2310.08395-Prompting_Large_Language_Models_with_Chain-of-Thought_for_Few-Shot.txt
distributed/2303.06318-A_Hybrid_Tensor-Expert-Data_Parallelism_Approach_to_Optimize.txt
distributed/2203.12533-PATHWAYS_-_ASYNCHRONOUS_DISTRIBUTED_DATAFLOW_FOR_ML.txt
distributed/2205.10034-1.txt
distributed/2312.08361-Distributed_Inference_and_Fine-tuning_of.txt
distributed/2306.10209-ZeRO++-_Extremely_Efficient_Collective_Communication_for_Giant.txt
distributed/2203.14685-HetuMoE-_An_Efﬁcient_Trillion-scale.txt
distributed/2212.01977-Distributed_Pruning_Towards_Tiny_Neural_Networks.txt
tokenizer/2402.09949-Multi-word_Tokenization_for_Sequence_Compression.txt
tokenizer/1911.12385-Published_as_a_conference_paper_at_ICLR_2020.txt
tokenizer/2310.11628-Learn_Your_Tokens.txt
tokenizer/2310.08754-Tokenizer_Choice_For_LLM_Training-_Negligible_or_Crucial.txt
tokenizer/2402.01613-arXiv-2402.01613v2_[cs.CL]_3_Feb_2025Published_in_Transactions_on_Machine_Learning_Research_(02_-202.txt
tokenizer/2211.12677-Word-Level_Representation_From_Bytes_For_Language_Modeling.txt
tokenizer/2103.06874-CANINE_-_Pre-training_an_Efﬁcient_Tokenization-Free_Encoder.txt
tokenizer/2407.08818-MAGNET.txt
tokenizer/2306.07764-Tokenization_with_Factorized_Subword_Encoding.txt
tokenizer/2402.14903-Tokenization_counts-_the_impact_of_tokenization_on_arithmetic_in_frontier_LLMs.txt
tokenizer/2311.04335-Sub-Sentence_Encoder.txt
tokenizer/2305.14571-From_Characters_to_Words-_Hierarchical_Pre-trained_Language_Model_for.txt
tokenizer/2309.08708-Vocabulary-level_Memory_Efficiency_for_Language_Model_Fine-tuning.txt
tokenizer/2405.07883-Zero-Shot_Tokenizer_Transfer.txt
tokenizer/2306.01393-Assessing_the_Importance_of_Frequency_versus_Compositionality_for.txt
tokenizer/2308.03281-Towards_General_Text_Embeddings_with_Multi-stage_Contrastive_Learning.txt
attention/2407.16153-On_the_Benefits_of_Rank_in_Attention_Layers.txt
attention/2409.04431-Theory,_Analysis,_and_Best_Practices_for.txt
attention/2409.15012-Inference-Friendly_Models_With_MixAttention.txt
attention/2103.03404-Attention_is_not_allyou_need.txt
attention/2103.14636-A_Practical_Survey_on_Faster_and_Lighter_Transformers.txt
attention/2111.05498-Attention_Approximates_Sparse_Distributed_Memory.txt
attention/2405.17976-wushaohua@ieisystem.com.txt
attention/2112.00029-Pixelated_Butterﬂy-_Simple_and_Eﬃcient_Sparse_Training_for.txt
attention/2205.14135-FlashAttention_-_Fast_and_Memory-Eﬃcient_Exact_Attention.txt
attention/2309.06180-Efficient_Memory_Management_for_Large_Language.txt
adversarial/2210.04311-Pruning_Adversarially_Robust_Neural_Networks.txt
adversarial/2210.10253-On_the_Adversarial_Robustness_of_Mixture_of_Experts.txt
adversarial/2112.05005-JIANG_LIU-_MUTUAL_ADVERSARIAL_TRAINING_1.txt
adversarial/2306.16170-IEEE_TRANSACTIONS_ON_PATTERN_ANAL_YSIS_AND_MACHINE_INTELLIGENCE_1.txt
adversarial/2303.17764-TOWARDS_ADVERSARIALLY_ROBUST_CONTINUAL_LEARNING.txt
adversarial/2308.09662-Red-Teaming_Large_Language_Models_using_Chain_of.txt
adversarial/2206.00052-CodeAttack-_Code-Based_Adversarial_Attacks_for_Pre-trained_Programming.txt
adversarial/1906.06784-Neural_Networks_154_(2022)_218–233.txt
adversarial/2111.02331-LTD-_Low_Temperature_Distillation_for_Robust_Adversarial_Training.txt
adversarial/2310.03693-FINE-TUNING_ALIGNED_LANGUAGE_MODELS_COMPROMISES_SAFETY_,.txt
relative-pe/2205.13401-Your_Transformer_May_Not_be_as_Powerful.txt
reasoning/2310.03094-Published_as_a_conference_paper_at_ICLR_2024.txt
reasoning/2305.14869-CAR-_Conceptualization-Augmented_Reasoner_for_Zero-Shot.txt
reasoning/2309.09530-Published_as_a_conference_paper_at_ICLR_2024.txt
reasoning/2310.05035-Self-Convinced_Prompting-_Few-Shot_Question_Answering_with_Repeated.txt
reasoning/2311.04205-Preprint.txt
reasoning/2305.07230-Cinnamon_AI.txt
reasoning/2309.02144-Preprint.txt
reasoning/2308.10144-ExpeL-_LLM_Agents_Are_Experiential_Learners.txt
reasoning/2401.17464-Efficient_Tool_Use_with_Chain-of-Abstraction_Reasoning.txt
reasoning/2311.05584-ZERO-SHOT_GOAL-DIRECTED_DIALOGUE_VIA_RL_ON.txt
reasoning/2309.08589-CHAIN_-OF-THOUGHT_REASONING_IS_A_POLICY_IM.txt
reasoning/2306.14924-LLM-A_SSISTED_CONTENT_ANALYSIS_-_USING_LARGE.txt
reasoning/2310.19019-TeacherLM-_Teaching_to_Fish_Rather_Than_Giving_the_Fish,.txt
reasoning/2308.08784-CodeCoT-_Tackling_Code_Syntax_Errors_in_CoT_Reasoning_for_Code_Generation.txt
reasoning/2401.04398-Published_as_a_conference_paper_at_ICLR_2024.txt
reasoning/2306.09841-1.txt
reasoning/2311.07911-Instruction-Following_Evaluation_for_Large_Language.txt
reasoning/2311.08469-UNcommonsense_Reasoning.txt
reasoning/2311.07961-The_ARTof_LLM_Refinement-_Ask,_Refine,_and_Trust.txt
reasoning/2310.13332-Democratizing_Reasoning_Ability.txt
reasoning/2311.08734-Thread_of_Thought_Unraveling_Chaotic_Contexts.txt
reasoning/2310.03714-Preprint.txt
reasoning/2310.12426-MAF-_Multi-Aspect_Feedback_for_Improving.txt
reasoning/2309.09117-CONTRASTIVE_DECODING_IMPROVES_REASONING_IN.txt
reasoning/2310.13522-Teaching_Language_Models_to_Self-Improve_through.txt
reasoning/2401.08967-REFT-_Reasoning_with_R_Einforced_Fine-Tuning.txt
reasoning/2310.01798-LARGE_LANGUAGE_MODELS_CANNOT_SELF-CORRECT.txt
reasoning/2203.11171-Published_as_a_conference_paper_at_ICLR_2023.txt
reasoning/2310.01714-Published_as_a_conference_paper_at_ICLR_2024.txt
reasoning/2309.06275-Re-Reading_Improves_Reasoning_in_Large_Language_Models.txt
reasoning/2302.13482-PyReason-_Software_for_Open_World_Temporal_Logic.txt
reasoning/2310.09139-THECONSENSUS_GAME_-_LANGUAGE_MODEL.txt
reasoning/2309.13339-Enhancing_Zero-Shot_Chain-of-Thought_Reasoning_in_Large.txt
reasoning/2307.11768-Question_Decomposition_Improves_the.txt
reasoning/2311.02805.txt
reasoning/2310.01444-Adapting_LLM_Agents_with_Universal_Feedback_in_Communi.txt
reasoning/2312.10003-REST_MEETS_REACT-_S_ELF-IMPROVEMENT_FOR.txt
reasoning/2403.09629-Quiet-STaR-_Language_Models_Can_Teach_Themselves_to.txt
reasoning/2310.16049-Published_as_a_conference_paper_at_ICLR_2024.txt
reasoning/2308.09138-Semantic_Consistency_for_Assuring_Reliability_of_Large_Language_Models.txt
reasoning/2402.01521-K-Level_Reasoning-_Establishing_Higher_Order_Beliefs.txt
reasoning/2305.00833-Learning_to_Reason_and_Memorize_with_Self-Notes.txt
reasoning/2306.12672-From_Word_Models_to_World_Models.txt
reasoning/2310.10134-Preprint.txt
reasoning/2310.11716-Reflection-Tuning.txt
reasoning/2310.00280-Published_as_a_conference_paper_at_COLM_2024.txt
reasoning/2310.14418-REFER_-_An_End-to-end_Rationale_Extraction_Framework.txt
reasoning/2307.11787-arXiv-2307.11787v2_[cs.CL]_16_Aug_2023LLM_Cognitive_Judgements_Diﬀer_From_Human.txt
reasoning/2310.04484-Ada-Instruct-_Adapting_Instruction_Generators_for_Complex_Reasoning.txt
hyena/2310.12109-Monarch_Mixer_-_A_Simple_Sub-Quadratic.txt
automl-nas/2305.13657-ChatGPT_as_your_Personal_Data_Scientist.txt
automl-nas/2405.18377-LLAMA-NAS-_E_FFICIENT_NEURAL_ARCHITECTURE_SEARCH.txt
automl-nas/2211.04148-The_Technological_Emergence_of_AutoML.txt
automl-nas/2307.10774-Assessing_the_Use_of_AutoML_for_Data-Driven.txt
automl-nas/2211.04661-Challenges_and_Barriers_of_Using_Low_Code_Software_for_Machine_Learning.txt
confidence/2311.08877-Preprint.txt
confidence/2305.14975-Just_Ask_for_Calibration_-_Strategies_for_Eliciting_Calibrated_Confidence.txt
confidence/2305.13712-Knowledge_of_Knowledge.txt
datasets/2405.01470-Published_as_a_conference_paper_at_ICLR_2024.txt
datasets/2204.07705-SUPER_-NATURAL_INSTRUCTIONS.txt
datasets/2307.14430-Skill-it!_A_Data-Driven_Skills_Framework_for_Understanding_and.txt
datasets/2311.09528-HELPSTEER_-_Multi-attribute_Helpfulness_Dataset_for_S_TEER_LM.txt
datasets/2305.07759-TinyStories_-_How_Small_Can_Language_Models_Be_and_Still_Speak.txt
datasets/2211.15268-Scientiﬁc_and_Creative_Analogies_in_Pretrained_Language_Models.txt
datasets/2305.11625-Searching_by_Code-_a_New_SearchBySnippet_Dataset_and_SnippeR.txt
datasets/2405.07526-MS_MARCO_Web_Search-_a_Large-scale_Information-rich_Web.txt
datasets/2301.13688-The_Flan_Collection-_Designing_Data_and_Methods.txt
datasets/2305.17701-KOSBI-_A_Dataset_for_Mitigating_Social_Bias_Risks_Towards_Safer_Large.txt
datasets/2402.00159-Dolma.txt
datasets/2206.12131-MVP-_Multi-task_Supervised_Pre-training.txt
datasets/2401.10225-ChatQA-_Surpassing_GPT-4_on_Conversational_QA.txt
datasets/2308.13387-Do-Not-Answer-_A_Dataset_for_Evaluating_Safeguards_in_LLMs.txt
datasets/2310.16787-The_Data_Provenance_Initiative.txt
datasets/2402.19173-Under_review_as_submission_to_TMLR.txt
datasets/2311.06697-Trusted_Source_Alignment_in_Large_Language_Models.txt
datasets/2311.06158-Language_Models_can_be_Logical_Solvers.txt
prompt/2211.01910-Published_as_a_conference_paper_at_ICLR_2023.txt
prompt/2311.04954-PROMPT_SKETCHING_FOR_LARGE_LANGUAGE_MODELS.txt
prompt/2309.16120-Fixing_Large_Language_Models’_Specification.txt
prompt/2308.07411-Exploring_the_Intersection_of_Large_Language_Models_and_Agent-Based.txt
prompt/2212.09561.txt
prompt/2212.09597-Reasoning_with_Language_Model_Prompting-_A_Survey.txt
prompt/2305.11790-Prompting_with_Pseudo-Code_Instructions.txt
prompt/2311.09732-Source_Prompt-_Coordinated_Pre-training_of_Language_Models_on_Diverse.txt
prompt/2303.01580-Mixture_of_Soft_Prompts_for_Controllable_Data_Generation.txt
prompt/2311.09277-Contrastive_Chain-of-Thought_Prompting.txt
prompt/2305.19466-The_Impact_of_Positional_Encoding_on_Length.txt
prompt/2304.07840-Enhancing_Automated_Program_Repair_through.txt
prompt/2308.05342-Metacognitive_Prompting_Improves_Understanding.txt
prompt/2305.03495-Automatic_Prompt_Optimization_with_“Gradient_Descent”.txt
prompt/2312.16171-Principled_Instructions_Are_All_You_Need_for.txt
prompt/2311.03033-arXiv-2311.03033v1_[cs.LG]_6_Nov_2023Beyond_Words-_A_Mathematical_Framework_for_Interpreting.txt
prompt/2304.06962-Published_as_a_Tiny_Paper_at_ICLR_2023.txt
prompt/2305.03268-Verify-and-Edit-_A_Knowledge-Enhanced_Chain-of-Thought_Framework.txt
prompt/2310.02304-Published_as_a_conference_paper_at_COLM_2024.txt
prompt/2309.04269-From_Sparse_to_Dense.txt
prompt/2307.15780-LLM-Rec-_Personalized_Recommendation_via.txt
prompt/2307.05300-Unleashing_the_Emergent_Cognitive_Synergy_in_Large_Language_Models.txt
prompt/2310.02107-Instances_Need_More_Care-_Rewriting_Prompts_for_Instances_with_LLMs_in.txt
prompt/2206.12839-Repository-Level_Prompt_Generation_for_Large_Language_Models_of_Code.txt
prompt/2311.05661-Prompt_Engineering_a_Prompt_Engineer.txt
hebbian/2209.11883-Published_as_a_conference_paper_at_ICLR_2023.txt
hebbian/2110.08232-Fire_Together_Wire_Together.txt
knowledge-graph/2110.12679-Springer_Nature_2021_L_ATEX_template.txt
knowledge-graph/2305.15486-SPRING-_Studying_the_Paper_and_Reasoning_to_Play.txt
knowledge-graph/2207.14358-Topological_structure_of_complex_predictions.txt
knowledge-graph/2307.16648-LLMs4OL-_Large_Language_Models_‌for.txt
knowledge-graph/2305.05936-Multi-hop_Commonsense_Knowledge_Injection_Framework_for.txt
knowledge-graph/2310.05499-Integrating_Graphs_with_Large_Language.txt
benchmark/2310.06266-CodeFuse-13B-_A_Pretrained_Multi-lingual_Code_Large_Language.txt
benchmark/2308.01240-Evaluating_Instruction-Tuned_Large_Language.txt
benchmark/2310.03128-Published_as_a_conference_paper_at_ICLR_2024.txt
benchmark/2310.11248-CROSS_CODE_EVAL-_A_Diverse_and_Multilingual.txt
benchmark/2402.11597-MULTI_-TASK_INFERENCE.txt
benchmark/2311.05915-Fake_Alignment-_Are_LLMs_Really_Aligned_Well.txt
benchmark/2306.04528-PromptRobust.txt
benchmark/2401.00741-ToolEyes-_Fine-Grained_Evaluation_for_Tool_Learning_Capabilities.txt
benchmark/2402.14261-Copilot_Evaluation_Harness-_Evaluating_LLM-Guided.txt
benchmark/2310.17631-Published_as_a_conference_paper_at_ICLR_2025.txt
benchmark/2401.03065-CRUXEval-_A_Benchmark_for_Code_Reasoning,.txt
benchmark/2311.10775-TOOLTALK-_E_VALUATING_TOOL_USAGE_IN_A_CON.txt
benchmark/2311.09835-ML-B_ENCH_-_Evaluating_Large_Language.txt
benchmark/2308.02357-TEXT2KGB_ENCH_-_A_B_ENCHMARK_FOR_ONTOLOGY_-DRIVEN.txt
benchmark/2311.12983-GAIA.txt
benchmark/2310.06770-Published_as_a_conference_paper_at_ICLR_2024.txt
benchmark/2311.12022-GPQA-_A_Graduate-Level_Google-Proof.txt
planning/2310.03051-HOWFAR_A_RELARGE_LANGUAGE_MODELS_FROM.txt
planning/2310.07088-Diversity_of_Thought_Improves_Reasoning_Abilities_of_LLMs.txt
planning/2310.03710-Agent_Instructs_Large_Language_Models_to_be_General_Zero-Shot_Reasoners.txt
planning/2310.15123-Branch-Solve-Merge_Improves_Large_Language_Model.txt
planning/2309.01868-On_the_Planning,_Search,_and_Memorization.txt
planning/2310.08992-Published_as_a_conference_paper_at_ICLR_2024.txt
planning/2312.05180-PATHFINDER_-_Guided_Search_over_Multi-Step.txt
planning/2310.10686-Preprint.txt
planning/2311.04254-EVERYTHING_OF_THOUGHTS.txt
planning/2310.08740-A_Zero-Shot_Language_Agent_for_Computer_Control.txt
planning/2312.10332-ProTIP-_Progressive_Tool_Retrieval_Improves_Planning.txt
planning/2402.01622-TravelPlanner-_A_Benchmark_for_Real-World_Planning_with_Language_Agents.txt
planning/2310.06830-Published_as_a_conference_paper_at_ICLR_2024.txt
planning/2308.06391-Dynamic_Planning_with_a_LLM.txt
planning/2404.02575-Language_Models_as_Compilers-_Simulating_Pseudocode_Exe.txt
planning/2305.14909-Leveraging_Pre-trained_Large_Language_Models_to.txt
planning/2305.11554-ToolkenGPT-_Augmenting_Frozen_Language_Models.txt
planning/2305.11014-Generalized_Planning_in_PDDL_Domains_with_Pretrained_Large_Language_Models.txt
planning/2309.12499-CodePlan_-_Repository-level_Coding_using_LLMs_and_Planning.txt
planning/2305.10601-Tree_of_Thoughts-_Deliberate_Problem_Solving.txt
planning/2310.08582-Published_as_a_conference_paper_at_ICLR_2024.txt
planning/2310.03720-Published_as_a_conference_paper_at_COLM_2024.txt
planning/2309.14681-Published_as_a_conference_paper_at_ICLR_2024.txt
planning/2306.03604-Published_as_a_conference_paper_at_RLC_2024.txt
planning/2310.01557-Published_as_a_conference_paper_at_ICLR_2024.txt
planning/2311.05772-AD_APT-_As-Needed_Decomposition_and_Planning_with_Language_Models.txt
planning/2302.07350-2023-12-14.txt
planning/2402.14083-Beyond_A∗-_Better_Planning_with_Transformers_via.txt
planning/2210.03629-Published_as_a_conference_paper_at_ICLR_2023.txt
planning/2310.00533-Preprint._Work_in_progress..txt
education/2409.03512-From_MOOC_to_MAIC-_Reshaping_Online_Teaching.txt
optimizer/2309.01825-LoopTune-_Optimizing_Tensor_Computations_with.txt
optimizer/2306.00045-Lottery_Tickets_in_Evolutionary_Optimization.txt
optimizer/2212.05652-PyPop7-_A_Pure-Python_Library_for_Population-Based_Black-Box_Optimization.txt
optimizer/2302.12022-DoG_is_SGD’s_Best_Friend.txt
optimizer/2305.17333-Fine-Tuning_Language_Models_with_Just.txt
optimizer/2312.15184-ZO-AdaMU_Optimizer-_Adapting_Perturbation_by_the_Momentum_and.txt
optimizer/2305.17190-Multiplication-Free_Transformer_Training.txt
optimizer/2307.15663-CoRe_Optimizer-_An_All-in-One_Solution_for_Machine_Learning.txt
optimizer/2208.08503-Learning_with_Local_Gradients_at_the_Edge.txt
optimizer/2308.02060-Accurate_Neural_Network_Pruning_Requires.txt
optimizer/2305.18240-JOURNAL_OF_L_ATEX_CLASS_FILES,_VOL._14,_NO._8,_AUGUST_2021_1.txt
optimizer/2304.11787-JOURNAL_OF_L_ATEX_CLASS_FILES,_VOL._14,_NO._8,_AUGUST_2021_1.txt
optimizer/2311.04163-Outliers_with_Opposing_Signals_Have_an.txt
optimizer/2306.01685-MKOR-_Momentum-Enabled_Kronecker-Factor-Based.txt
optimizer/2202.08587-Gradients_without_Backpropagation.txt
optimizer/2302.03281-Utility-based_Perturbed_Gradient_Descent-_An_Optimizer_for_Continual_Learning.txt
optimizer/2306.09782-Full_Parameter_Fine-tuning_for_Large_Language_Models.txt
optimizer/2106.02679-arXiv-2106.02679v1_[cs.LG]_4_Jun_2021Layered_gradient_accumulation_and_modular_pipeline_parall_elism.txt
optimizer/2004.14014-Versatile_Black-Box_Optimization.txt
optimizer/1909.12778-Global_Sparse_Momentum_SGD_for_Pruning_Very.txt
optimizer/2111.11124-Noname_manuscript_No..txt
audio/2410.00344-INTEGRATING_TEXT-TO-MUSIC_MODELS_WITH_LANGUAGE_MODELS.txt
audio/2410.02271-CoLLAP-_Contrastive_Long-form_Language-_Audio_Pretraining.txt
batched-decoding/2307.15337-Published_as_a_conference_paper_at_ICLR_2024.txt
early-stopping/2207.07061-Conﬁdent_Adaptive_Language_Modeling.txt
early-stopping/2210.15523-COST-EFF-_Collaborative_Optimization_of_Spatial_and_Temporal.txt
early-stopping/2310.05424-Fast_and_Robust_Early-Exiting_Framework_for.txt
early-stopping/1909.06035-DARTS+-_Improved_Differentiable_Architecture_Search_with_Early_Stopping.txt
paraphrase/2204.02546-QUICK_STARTING_DIALOG_SYSTEMS_WITH_PARAPHRASE.txt
hyperparameters/2306.05087-Published_as_a_conference_paper_at_ICLR_2024.txt
hyperparameters/2309.14322-Small-scale_proxies_for_large-scale_Transformer_training_instabilities.txt
emotion/2302.09582--_PAGE_2.txt
rnn/2503.14456-RWKV-7_Goose_with_Expressive_Dynamic_State_Evolution.txt
rnn/2404.07904-Published_as_a_conference_paper_at_COLM_2024.txt
rnn/2402.02625-ICML_2024_Next_Generation_of_Sequence_Modeling_Architectures_Workshop.txt
rnn/2106.08928-RNNs_of_RNNs.txt
rnn/2307.11888-Universality_of_Linear_Recurrences_Followed_by_Non-linear_Projections.txt
rnn/2402.19427-2024-3-1.txt
rnn/2305.19190-Published_as_a_conference_paper_at_ICLR_2024.txt
rnn/2407.12077-GoldFinch-_High_Performance_RWKV-Transformer_Hybrid_with.txt
rnn/2311.04823-Hierarchically_Gated_Recurrent_Neural_Network_for.txt
dataset-pruning-cleaning-dedup/2406.10670-CoLoR-Filter-_Conditional_Loss_Reduction_Filtering.txt
dataset-pruning-cleaning-dedup/2307.08701-Published_as_a_conference_paper_at_ICLR_2024.txt
dataset-pruning-cleaning-dedup/2405.20541-Perplexed_by_Perplexity-_Perplexity-Based_Data.txt
dataset-pruning-cleaning-dedup/2309.10818-SlimPajama-DC_-_Understanding_Data.txt
dataset-pruning-cleaning-dedup/2308.06259-Published_as_a_conference_paper_at_ICLR_2024.txt
dataset-pruning-cleaning-dedup/2312.02120-Magicoder-_Empowering_Code_Generation_with_OSS-I_NSTRUCT.txt
dataset-pruning-cleaning-dedup/2306.01116-The_RefinedWeb_Dataset_for_Falcon_LLM.txt
dataset-pruning-cleaning-dedup/2406.11794-DataComp-LM-_In_search_of_the_next_generation_of.txt
dataset-pruning-cleaning-dedup/2309.04564-When_Less_is_More.txt
icl/2311.09263-Auto-ICL-_In-Context_Learning_without_Human_Supervision.txt
icl/2305.17812-Tab-CoT-_Zero-shot_Tabular_Chain_of_Thought.txt
icl/2401.02072-ICE-GRT-_Instruction_Context_Enhancement_by_Generative_Reinforcement.txt
icl/2309.10687-EchoPrompt-_Instructing_the_Model_to_Rephrase_Queries.txt
icl/2303.17780-AceCoder_-_Utilizing_Existing_Code_to_Enhance_Code_Generation.txt
icl/2403.15371-Can_Large_Language_Models_Explore_In-Context.txt
icl/2306.03799-Prompt_Space_Optimizing_Few-shot_Reasoning_Success_with_Large.txt
icl/2111.04130-NLP_From_Scratch_Without_Large-Scale_Pretraining.txt
icl/2210.01293-ThinkSum-_Probabilistic_reasoning_over_sets_using_large_language_models.txt
icl/2307.01201-Schema-learning_and_rebinding_as_mechanisms.txt
icl/2305.08360-Improving_ChatGPT_Prompt_for_Code_Generation.txt
icl/2210.03493-AUTOMATIC_CHAIN_OF_THOUGHT_PROMPTING.txt
icl/2310.01119-Synthetic_Data_Generation_in_Low-Resource_Settings.txt
icl/2207.04237-Few-shot_training_LLMs_for_project-specific_code-summarization.txt
icl/2305.13514-Small_Language_Models_Improve_Giants_by_Rewriting_Their_Outputs.txt
icl/2311.08360-The_Transient_Nature_of_Emergent.txt
icl/2304.09797-Progressive-Hint_Prompting_Improves_Reasoning.txt
icl/2309.01775-Gated_recurrent_neural_networks_discover_attention.txt
icl/2310.09748-Large_Language_Model-Aware_In-Context_Learning_for_Code.txt
icl/2204.02329-Can_language_models_learn_from_explanations_in_context.txt
icl/2306.06427-Boosting_Language_Models_Reasoning_with_Chain-of-Knowledge.txt
icl/2312.04474-Chain_of_Code-_Reasoning_with_a_Language_Model-Augmented_Code_Emulator.txt
icl/2304.07575-What_Makes_Good_In-context_Demonstrations_for.txt
icl/2406.08973-Published_as_a_conference_paper_at_ICLR_2025.txt
icl/2305.18507-Code_Prompting-_a_Neural_Symbolic_Method_for.txt
icl/2308.16753-Context_Aware_Query_Rewriting_for_Text_Rankers_using_LLM.txt
icl/2309.17382-Reason_for_Future,_Act_for_Now-_A_Principled.txt
icl/2305.11170-Efﬁcient_Prompting_via_Dynamic_In-Context.txt
icl/2305.14825-Large_Language_Models_are_In-Context.txt
icl/2302.05698-Compositional_Exemplars_for_In-context_Learning.txt
icl/2303.05063-ICL-D3IE-_In-Context_Learning_with_Diverse_Demonstrations_Updating_for.txt
icl/2310.10508-Prompt_Engineering_or_Fine-Tuning.txt
icl/2211.04118-CONSPROMPT-_EXPLOITING_CONTRASTIVE_SAMPLES_FOR_FEW-SHOT_PROMPT.txt
icl/2311.08648-Explore_Spurious_Correlations_at_the_Concept_Level_in_Language_Models.txt
icl/2305.11598-Introspective_Tips-_Large_Language_Model_for.txt
icl/2304.13276-arXiv-2304.13276v1_[cs.CL]_26_Apr_2023The_Closeness_of_In-Context_Learning_and_Weight_Shifting_fo_r.txt
icl/2310.05074-DialCoT_Meets_PPO-_Decomposing_and_Exploring_Reasoning_Paths_in.txt
icl/2306.15063-Pretraining_task_diversity_and_the_emergence_of.txt
hypernetwork/2304.07645-Magnitude_Invariant_Parametrizations_Improve_Hypernetwork_Learning.txt
hypernetwork/2405.15444-HINT-_Hypernetwork_Approach_to_Training_Weight_Interval_Regions_in_Continual.txt
hypernetwork/2211.12485-HyperTuning-_Toward_Adapting_Large_Language.txt
hypernetwork/1906.00695-Published_as_a_conference_paper_at_ICLR_2020.txt
hypernetwork/2402.01093-NEED_A_SMALL_SPECIALIZED_LANGUAGE_MODEL.txt
hypernetwork/2312.16218-Hyper-VolTran-_Fast_and_Generalizable.txt
hypernetwork/2009.11997-Continual_Model-Based_Reinforcement_Learning_with_Hypernetworks.txt
hypernetwork/2203.11378-HyperShot-_Few-Shot_Learning_by_Kernel_HyperNetworks.txt
hypernetwork/2203.03691-HyperMixer-_An_MLP-based_Low_Cost_Alternative_to_Transformers.txt
hypernetwork/2306.06955-A_B_RIEF_REVIEW_OF_HYPERNETWORKS_IN_DEEPLEARNING.txt
hypernetwork/2211.15457-Hypernetworks_for_Zero-shot_Transfer_in_Reinforcement_Learning.txt
hypernetwork/2106.06842-Recomposing_the_Reinforcement_Learning_Building_Blocks_with.txt
hypernetwork/2405.16287-LOGAH-_Predicting_774-Million-Parameter.txt
text-diffusion/2305.09515-AR-D_IFFUSION_-_Auto-Regressive_Diffusion_Model_for.txt
text-diffusion/2212.11685-Text_Generation_with_Diffusion_Language_Models-_A_Pre-training_Approach.txt
text-diffusion/2308.15459-ParaGuide-_Guided_Diffusion_Paraphrasers_for.txt
text-diffusion/2305.11517-DIFFU_SIA-_A_Spiral_Interaction_Architecture_for.txt
data-augmentation/2310.09716-Enhancing_Conversational_Search-_Large_Language_Model-Aided.txt
data-augmentation/2403.12776-Automated_Data_Curation_for_Robust_Language_Model_Fine-Tuning.txt
data-augmentation/2205.05368-THEUNIVERSIT.txt
data-augmentation/2303.07864-DualMix-_Unleashing_the_Potential_of_Data_Augmentation_for_Online.txt
data-augmentation/2403.15042-LLM2LLM-_Boosting_LLMs_with_Novel_Iterative_Data_Enhancement.txt
data-augmentation/2309.11104-AttentionMix_-_Data_augmentation_method_that_relies_on_BERT.txt
data-augmentation/2404.17642-Empowering_Large_Language_Models_for_Textual_Data_Augmentation.txt
data-augmentation/2110.01852-Data_Augmentation_Approaches_in_Natural_Language.txt
data-augmentation/2012.02909-What_Makes_a_“Good”_Data_Augmentation_in.txt
data-augmentation/2305.14890-HARD-_Hard_Augmentations_for_Robust_Distillation.txt
data-augmentation/2204.11406-Robust_Self-Augmentation_for_Named_Entity_Recognition_with_Meta.txt
data-augmentation/2312.06550-LLM360-_Towards_Fully_Transparent.txt
data-augmentation/2305.11426-Post_Hoc_Explanations_of_Language_Models_Can.txt
data-augmentation/2406.10991-Adaptive_Query_Rewriting-_Aligning_Rewriters_through_Marginal.txt
data-augmentation/2210.11768-Published_as_a_conference_paper_at_ICLR_2023.txt
data-augmentation/2211.03946-Understanding_the_Role_of_Mixup_in_Knowledge_Distillation.txt
data-augmentation/2306.15766-Large_Language_Models_as_Annotators-_Enhancing_Generalization_of_NLP.txt
data-augmentation/2401.16380-Rephrasing_the_Web-_A_Recipe_for_Compute_&_Data-Efficient_Language_Modeling.txt
data-augmentation/2402.18334-Learning_to_Generate_Instruction_Tuning_Datasets_for.txt
data-augmentation/2203.09391-When_Chosen_Wisely,_More_Data_Is_What_You_Need.txt
data-augmentation/2304.08821-TTIDA_-_Controllable_Generative_Data_Augmentation_via.txt
data-augmentation/2404.00415-CoDa-_Constrained_Generation_based_Data_Augmentation.txt
data-augmentation/2305.13547-Self-Evolution_Learning_for_Mixup-_Enhance_Data_Augmentation_on.txt
data-augmentation/2208.06957-Syntax-driven_Data_Augmentation_for_Named_Entity_Recognition.txt
data-augmentation/2305.17476-Toward_Understanding_Generative_Data_Augmentation.txt
data-augmentation/2205.06153-TreeMix-_Compositional_Constituency-based_Data_Augmentation_for.txt
quantization/2111.05754-Prune_Once_for_All-_Sparse_Pre-Trained_Language.txt
quantization/2310.01382-Published_as_a_conference_paper_at_ICLR_2024.txt
quantization/2310.10944-TEQ-_T_rainable_E_quivalent_Transformation_for_Q_uantization_of_LLMs.txt
quantization/2308.15987-FPTQ-_F_INE-GRAINED_POST-TRAINING_QUANTIZA.txt
quantization/2308.09723-FineQuant-_Unlocking_Efficiency_with_Fine-Grained.txt
quantization/2203.14645-REx-_Data-Free_Residual_Quantization_Error.txt
quantization/2308.06744-Token-Scaled_Logit_Distillation_for.txt
quantization/2309.02784-Norm_Tweaking-_High-performance_Low-bit_Quantization_of_Large_Language.txt
quantization/1802.05668-Published_as_a_conference_paper_at_ICLR_2018.txt
quantization/2306.12929-Quantizable_Transformers-_Removing_Outliers_by.txt
quantization/2304.01483-Blockwise_Compression_of_Transformer-based_Models_without_Retraining.txt
quantization/2310.00034-PB-LLM-_P_ARTIALLY_BINARIZED_LARGE_LANGUAGE.txt
quantization/2211.11397-Learning_Low-Rank_Representations_for_Model_Compression.txt
quantization/2309.14592-EFFICIENT_POST-TRAINING_QUANTIZATION_WITH_FP8_F_ORMATS.txt
quantization/2304.09145-Outlier_Suppression+-_Accurate_quantization_of_large_language_models_by.txt
quantization/2305.18513-arXiv-2305.18513v1_[cs.CL]_29_May_2023SLIMFIT-_Memory-Efﬁcient_Fine-Tuning_of.txt
quantization/2310.11453-BitNet-_Scaling_1-bit_Transformers_for.txt
quantization/2310.19102-ATOM_-_LOW-BITQUANTIZATION_FOR_EFFICIENT_AND_ACCURATE_LLM.txt
quantization/2302.10899-1.txt
quantization/2309.05210-arXiv-2309.05210v3_[cs.CL]_17_Sep_2023Understanding_the_Impact_of_Post-Training_Quantization_on_Larg.txt
quantization/2204.04215-Data-Free_Quantization_with_Accurate_Activation.txt
quantization/2308.13137-Published_as_a_conference_paper_at_ICLR_2024.txt
quantization/2211.16056-NoisyQuant-_Noisy_Bias-Enhanced_Post-Training_Activation_Quantization_for.txt
quantization/2310.16795-QMoE-_Practical_Sub-1-Bit_Compression_of_Trillion-Parameter_Models.txt
quantization/2307.10638-Quantized_Feature_Distillation_for_Network_Quantization.txt
quantization/2309.05516-Optimize_Weight_Rounding_via_Signed_Gradient_Descent_for_the.txt
quantization/2107.13490-Adaptive_Precision_Training_(AdaPT).txt
quantization/2309.00964-eDKM-_An_Efficient_and_Accurate_Train-time.txt
quantization/2310.18313-FP8-LM-_Training_FP8_Large_Language_Models.txt
quantization/2211.11014-Understanding_and_Improving_Knowledge_Distillation_for.txt
quantization/2310.02410-Mixture_of_Quantized_Experts_(MoQE).txt
quantization/2310.09259-QUIK-_T_OWARDS_END-TO-END_4-B_ITINFERENCE.txt
quantization/2305.17888-LLM-QAT-_Data-Free_Quantization_Aware_Training.txt
quantization/2308.05600-PRE-PRINT_VERSION_1.txt
quantization/2310.10537-Microscaling_Data_Formats_for.txt
quantization/2308.07633-A_Survey_on_Model_Compression_for_Large_Language_Models.txt
quantization/2309.01729-Softmax_Bias_Correction_for_Quantized_Generative_Models.txt
quantization/2308.07939-ADA-QP_ACKNET_-ADAPTIVE_PRUNING_WITH_BIT_WIDTH.txt
quantization/2310.08041-Published_as_a_conference_paper_at_ICLR_2024.txt
quantization/2309.10878-ASHFAQ_ET_AL.-_DEEPLITERT-_COMPUTER_VISION_AT_THE_EDGE_1.txt
quantization/2309.17224-Training_and_inference_of_large_language_models.txt
quantization/2310.16836-LLM-FP4-_4-Bit_Floating-Point_Quantized_Transformers.txt
multimodal/2306.17165-An_Efficient_General-Purpose_Modular_Vision_Model.txt
multimodal/2309.04041-Evaluation_and_Enhancement_of_Semantic_Grounding.txt
multimodal/2210.15037-Generalization_Differences_between_End-to-End_and_Neuro-Symbolic.txt
multimodal/2308.10445-When_Prompt-based_Incremental_Learning_Does_Not_Meet_Strong_Pretraining.txt
multimodal/2310.08541-Idea2Img_-_Iterative_Self-Refinement_with_GPT-4V.txt
multimodal/2310.08101-Promptor-_A_Conversational_and_Autonomous_Prompt_Generation_Agent_for.txt
multimodal/2309.08637-TEXTBIND.txt
multimodal/2308.08726-Never-ending_Learning_of_User_Interfaces.txt
multimodal/2309.14118-MultiModN—Multimodal,_Multi-Task,_Interpretable.txt
multimodal/2310.16825-CommonCanvas-_An_Open_Diffusion_Model_Trained.txt
multimodal/2211.01571-Phonetic-assisted_Multi-Target_Units_Modeling_for_Improving.txt
multimodal/2204.05229-Mixture-of-experts_V_AEs_can_disregard_variation_in.txt
multimodal/2312.03491-Schrodinger_Bridges_Beat_Diffusion_Models_on.txt
multimodal/2308.12966-Qwen-VL-_A_Versatile_Vision-Language_Model_for.txt
multimodal/2311.07919-Qwen-Audio-_Advancing_Universal_Audio_Understanding.txt
multimodal/2306.04073-Patch-level_Routing_in_Mixture-of-Experts_is_Provably_Sample-efficient_for.txt
multimodal/2312.14385-Generative_AI_Beyond_LLMs-_System_Implications.txt
multimodal/2401.16658-arXiv-2401.16658v3_[cs.CL]_27_Aug_2024OWSM_v3.1-_Better_and_Faster_Open_Whisper-Style_Speech_Mode_ls.txt
multimodal/2108.02625-MSTRE-NET-_MULTISTREAMING_ACOUSTIC_MODELING_FOR.txt
multimodal/2309.01947-TODM-_TRAIN_ONCE_DEPLOY_MANY.txt
multimodal/2212.05102-A_soft_nearest-neighbor_framework_for_continual_semi-supervised_learning.txt
multimodal/2303.11126-Robustifying_Token_Attention_for_Vision_Transformers.txt
multimodal/2310.03744-Improved_Baselines_with_Visual_Instruction_Tuning.txt
multimodal/2404.08856-On_Speculative_Decoding_for_Multimodal_Large_Language_Models.txt
multimodal/2309.16058-AnyMAL-_An_Efficient_and_Scalable_Any-Modality.txt
multimodal/2309.07623-SwitchGPT-_Adapting_Large_Language_Models_for_Non-Text_Outputs.txt
multimodal/2311.01615-FLAP-_FAST_LANGUAGE-AUDIO_PRE-TRAINING.txt
multimodal/2111.12624-Self-slimmed_Vision_Transformer.txt
multimodal/2310.05295-Visual_Storytelling_with_Question-Answer_Plans.txt
multimodal/2401.13311-CONTEXTUAL_-_Evaluating_Context-Sensitive_Text-Rich_Visual_Reasoning_in.txt
multimodal/2211.13218-CODA-Prompt-_COntinual_Decomposed_Attention-based_Prompting_for.txt
multimodal/2310.11441-Set-of-Mark_Prompting_Unleashes.txt
multimodal/2211.11315-Beyond_Attentive_Tokens-_Incorporating_Token_Importance_and_Diversity_for.txt
multimodal/2309.10783-Language_as_the_Medium-_Multimodal_Video_Classification_through_text_only.txt
multimodal/2303.13755-Sparsiﬁner-_Learning_Sparse_Instance-Dependent_Attention.txt
multimodal/2209.15176-Adaptive_Sparse_and_Monotonic_Attention_for.txt
multimodal/2306.17107-LLaV_AR-_Enhanced_Visual_Instruction_Tuning.txt
multimodal/2310.14566-HALLUSION_BENCH_-_An_Advanced_Diagnostic_Suite_for_Entangled_Language.txt
multimodal/2104.00405-Avalanche-_an_End-to-End_Library_for_Continual_Learning.txt
multimodal/2305.17394-One-Step_Knowledge_Distillation_and_Fine-Tuning_in_Using_Large_Pre-Trained.txt
multimodal/2310.00704-Under_review_as_a_conference_paper_at_ICLR_2024.txt
multimodal/2401.01792-CoMoSVC-_Consistency_Model-based_Singing_Voice.txt
multimodal/2310.19909-Battle_of_the_Backbones-_A_Large-Scale_Comparison_of.txt
multimodal/2310.09478-MiniGPT-v2-_Large_Language_Model_As_a_Unified.txt
multimodal/2312.17432-arXiv-2312.17432v5_[cs.CV]_14_Jun_20251.txt
multimodal/2403.13447-HyperLLaV_A-_Dynamic_Visual_and_Language_Expert_Tuning_for.txt
multimodal/2305.13738-i-Code_Studio-_A_Configurable_and_Composable_Framework.txt
multimodal/2401.00908-DOCLLM-_A_LAYOUT_-AWARE_GENERATIVE_LANGUAGE_MODEL.txt
multimodal/2309.10707-CORPUS_SYNTHESIS_FOR_ZERO-SHOT_ASR_DOMAIN_ADAPTATION_USING.txt
multimodal/2312.08614-JOURNAL_OF_L_ATEX_CLASS_FILES,_VOL._14,_NO._8,_AUGUST_2021_1.txt
multimodal/2305.11685-Recycle-and-Distill-_Universal_Compression_Strategy_for_Transformer-based.txt
multimodal/2310.20092-Published_in_Transactions_on_Machine_Learning_Research_(04-2024).txt
multimodal/2311.04901-Preprint.txt
multimodal/2304.04385-On_Robustness_in_Multimodal_Learning.txt
multimodal/2310.13355-SILC-_Improving_Vision_Language_Pretraining_with_Self-Distillation.txt
multimodal/2211.11559-Visual_Programming-_Compositional_visual_reasoning_without_training.txt
multimodal/2306.05392-Modular_Visual_Question_Answering_via_Code_Generation.txt
multimodal/2305.14839-PaCE-_Unified_Multi-modal_Dialogue_Pre-training_with.txt
multimodal/2212.05561-Using_Multiple_Instance_Learning_to_Build.txt
multimodal/2312.06742-Honeybee-_Locality-enhanced_Projector_for_Multimodal_LLM.txt
multimodal/2311.15075-JOURNAL_OF_L_ATEX_CLASS_FILES,_VOL._14,_NO._8,_MAY_2023_1.txt
multimodal/2309.15701-HyPoradise-_An_Open_Baseline_for_Generative_Speech.txt
multimodal/2205.06126-One_Model,_Multiple_Modalities-_A_Sparsely.txt
multimodal/2304.06461-Multi-Mode_Online_Knowledge_Distillation_for_Self-Supervised_Visual.txt
multimodal/2310.01407-CoDi-_Conditional_Diffusion_Distillation.txt
multimodal/2308.00442-FLatten_Transformer-_Vision_Transformer_using_Focused_Linear_Attention.txt
multimodal/2306.17089-Concept-Oriented_Deep_Learning_with_Large_Language_Models.txt
multimodal/2405.17430-Matryoshka_Multimodal_Models.txt
multimodal/2210.07839-Published_as_a_conference_paper_at_ICLR_2023.txt
multimodal/2310.15916-In-Context_Learning_Creates_Task_Vectors.txt
multimodal/2307.10802-Meta-Transformer-_A_Unified_Framework_for.txt
multimodal/2311.04257-mPLUG-Owl2-_Revolutionizing_Multi-modal_Large_Language_Model.txt
multimodal/2309.11210-SPEAK_WHILE_YOU_THINK.txt
multimodal/2310.02992-KOSMOS_-G-_Generating_Images_in_Context.txt
multimodal/2402.13577-BBA-_Bi-Modal_Behavioral_Alignment_for_Reasoning_with_Large.txt
multimodal/2310.00653-Reformulating_Vision-Language_Foundation_Models_and_Datasets.txt
multimodal/2311.08046-Chat-UniVi-_Unified_Visual_Representation_Empowers_Large_Language_Models.txt
multimodal/2310.03734-LEVERAGING_UNPAIRED_DATA_FOR_VISION_-LANGUAGE.txt
multimodal/2308.16890-TouchStone-_Evaluating_Vision-Language_Models_by.txt
multimodal/2107.00135-Attention_Bottlenecks_for_Multimodal_Fusion.txt
multimodal/2401.00246-Boosting_Large_Language_Model_for_Speech_Synthesis.txt
multimodal/2311.06791-InfMLLM-_A_Unified_Framework_for_Visual-Language_Tasks.txt
multimodal/2307.03972-Evaluating_the_Capability_of_Large-scale_Language_Models.txt
multimodal/2309.08876-arXiv-2309.08876v2_[eess.AS]_9_Jan_2024DECODER-ONLY_ARCHITECTURE_FOR_SPEECH_RECOGNITION_WITH.txt
multimodal/2207.03481-Proceedings_of_Machine_Learning_Research_2022_NeurIPS_2021_Competition_and_Demonstration_Track.txt
multimodal/2311.05437-LLAVA-P_LUS-_LEARNING_TO_USETOOLS_FOR.txt
multimodal/2105.03036-SpeechMoE-_Scaling_to_Large_Acoustic_Models_with_Dynamic_Routing.txt
multimodal/2211.02077-Scaling_Multimodal_Pre-Training_via_Cross-Modality.txt
multimodal/2310.12404-Loop_Copilot-_Conducting_AI_Ensembles_for_Music_Generation_and_Iterative.txt
multimodal/2309.07915-Published_as_a_conference_paper_at_ICLR_2024.txt
multimodal/2309.01809-Are_Emergent_Abilities_in_Large_Language_Models_just_In-Context.txt
multimodal/2112.09427-Continual_Learning_for_Monolingual_End-to-End.txt
multimodal/2309.04663-FIAT-_F_USING_LEARNING_PARADIGMS_WITH.txt
multimodal/2403.00231-Multimodal_ArXiv-_A_Dataset_for_Improving_Scientific_Comprehension_of.txt
multimodal/2306.01385-arXiv-2306.01385v2_[eess.AS]_9_Jul_2023Task-Agnostic_Structured_Pruning_of_Speech_Representatio_n_Mo.txt
multimodal/2311.14957-MULTI-SCALE_SUB-BAND_CONSTANT-Q_TRANSFORM_DISCRIMINATOR.txt
multimodal/2305.03701-LMEye-_An_Interactive_Perception_Network_for.txt
multimodal/2309.06495-AGIB_ENCH_-_A_M_ULTI_-GRANULARITY_,_MULTIMODAL_,.txt
multimodal/2309.13165-Large_Language_Models_Are_Also_Good_Prototypical_Commonsense.txt
multimodal/2401.06395-ModaVerse-_Efficiently_Transforming_Modalities_with_LLMs.txt
multimodal/2310.11440-EvalCrafter-_Benchmarking_and_Evaluating_Large_Video_Generation_Models.txt
multimodal/2305.19924-Joint_Adaptive_Representations_for_Image-Language_Learning.txt
multimodal/2401.01755-INCREMENTAL_FASTPITCH-_CHUNK-BASED_HIGH_QUALITY_TEXT_TO_SPEECH.txt
multimodal/2210.04428-arXiv-2210.04428v2_[cs.CV]_29_Mar_2023A_Simple_Baseline_that_Questions_the_Use_of.txt
multimodal/2309.07900-Ambiguity-Aware_In-Context_Learning_with_Large_Language_Models.txt
multimodal/2304.13357-1.txt
multimodal/2310.12274-An_Image_is_Worth_Multiple_Words-_Discovering_Object_Level_Concepts_using.txt
multimodal/2401.13601-MM-LLMs-_Recent_Advances_in_MultiModal_Large_Language_Models.txt
multimodal/2310.10616-How_Do_Transformers_Learn_In-Context_Beyond_Simple.txt
multimodal/2310.16656-A_Picture_is_Worth_a_Thousand_Words-_Principled_Recaptioning_Improves_Image.txt
multimodal/2311.00430-DISTIL_-WHISPER_-_ROBUST_KNOWLEDGE.txt
multimodal/2312.09911-AMPHION-_AN_OPEN-SOURCE_AUDIO,_MUSIC,_AND_SPEECH_GENERATION_TOOLKIT.txt
multimodal/2309.13600-Multi-Dimensional_Hyena_for_Spatial_Inductive_Bias.txt
multimodal/2401.00849-COSMO_-COntrastive_Streamlined_MultimOdal_Model_with.txt
multimodal/2311.05997-JARVIS_-1-_Open-world_Multi-task_Agents_with.txt
multimodal/2304.10857-SequeL-_A_Continual_Learning_Library_in_PyTorch_and_JAX.txt
multimodal/2310.12004-IMAGE_SUPER_-RESOLUTION_VIA_LATENT_DIFFUSION_-_A.txt
multimodal/2308.12714-VIGC-_Visual_Instruction_Generation_and_Correction.txt
multimodal/2309.14320-MUTEX_-_Learning_Unified_Policies_from.txt
multimodal/2309.10926-SEMI-AUTOREGRESSIVE_STREAMING_ASR_WITH_LABEL_CONTEXT.txt
multimodal/2311.06495-LayoutPrompter-_Awaken_the_Design_Ability_of.txt
multimodal/2310.07478-Multimodal_Graph_Learning_for_Generative_Tasks.txt
multimodal/2109.02008-Cross-token_Modeling_with_Conditional_Computation.txt
multimodal/2308.13437-Position-Enhanced_Visual_Instruction_Tuning.txt
multimodal/2308.15272-AutoDroid-_LLM-powered_Task_Automation_in.txt
multimodal/2312.13286-Generative_Multimodal_Models_are_In-Context_Learners.txt
multimodal/2309.10020-Multimodal_Foundation_Models.txt
multimodal/2403.07508-MoAI-_Mixture_of_All_Intelligence.txt
multimodal/2401.03945-SpeechAgents-_Human-Communication_Simulation_with.txt
multimodal/2111.11418-MetaFormer_Is_Actually_What_You_Need_for_Vision.txt
multimodal/2311.15759-Towards_Vision_Enhancing_LLMs.txt
multimodal/2309.07117-SCIENCE_CHINA.txt
multimodal/2309.03926-Large-Scale_Automatic_Audiobook_Creation.txt
multimodal/2306.06446-ShiftAddViT-_Mixture_of_Multiplication_Primitives.txt
multimodal/2308.06093-Experts_Weights_Averaging-_A_New_General_Training.txt
multimodal/2403.02677-Finetuned_Multimodal_Language_Models_Are.txt
multimodal/2310.05737-Published_as_a_conference_paper_at_ICLR_2024.txt
multimodal/2312.15821-Audiobox-_Unified_Audio_Generation.txt
multimodal/2308.04152-FINE-TUNING_MULTIMODAL_LLM_S_TO_FOLLOW.txt
multimodal/2311.05348-u-LLaVA-_Unifying_Multi-Modal_Tasks_via_Large.txt
multimodal/2304.08953-From_Words_to_Music-_A_Study_of_Subword_Tokenization_Techniques_in_Symbolic.txt
multimodal/2505.19897-arXiv-2505.19897v2_[cs.AI]_27_Jun_2025.txt
multimodal/2310.11954-MusicAgent-_An_AI_Agent_for_Music_Understanding_and_Generation_with.txt
multimodal/2402.13232-A_Touch,_Vision,_and_Language_Dataset_for_Multimodal_Alignment.txt
multimodal/2306.02388-Commonsense_Knowledge_Transfer_for_Pre-trained_Language_Models.txt
multimodal/2210.00077-E-BRANCHFORMER-_BRANCHFORMER_WITH_ENHANCED_MERGING.txt
multimodal/2305.06324-Alternating_Gradient_Descent_and_Mixture-of-Experts.txt
multimodal/2311.00571-LLaV_A-Interactive-_An_All-in-One_Demo_for.txt
multimodal/2309.15564-Preprint.txt
multimodal/2309.12963-arXiv-2309.12963v1_[eess.AS]_22_Sep_2023Massive_End-to-end_Models_for_Short_Search_Queries.txt
multimodal/2311.18799-X-InstructBLIP_-_A_Framework_for_Aligning_Image,.txt
multimodal/2310.15111-Published_as_a_conference_paper_at_ICLR_2024.txt
multimodal/2304.03464-Record_Linkage_with_Multimodal_Contrastive_Learning.txt
multimodal/2309.09390-AUGMENTING_TEXT_FOR_SPOKEN_LANGUAGE_UNDERSTANDING_WITH_LARGE.txt
multimodal/2306.05425-MIMIC-IT-_Multi-Modal_In-Context.txt
multimodal/2202.07922-ZEROGEN-_Efﬁcient_Zero-shot_Learning_via_Dataset_Generation.txt
multimodal/2303.05668-UNFUSED_-_UN_SUPERVISED_F_INETUNING_U_SING_SE_LF_SUPERVISED_D_ISTILLATION.txt
multimodal/2309.10952-LMDX-_Language_Model-based_Document_Information.txt
multimodal/2203.16965-PADA-_PRUNING_ASSISTED_DOMAIN_ADAPTATION_FOR_SELF-SUPERVISED_SPEECH.txt
multimodal/2306.08640-AssistGPT-_A_General_Multi-modal_Assistant_that.txt
multimodal/2402.14289.txt
multimodal/2310.16045-Woodpecker-_Hallucination_Correction_for.txt
multimodal/2310.16226-Published_as_a_conference_paper_at_ICLR_2024.txt
multimodal/2306.03421-Diversifying_Joint_Vision-Language_Tokenization_Learning.txt
multimodal/2310.09118-1.txt
multimodal/2312.13722-BAE-NET-_A_LOW_COMPLEXITY_AND_HIGH_FIDELITY_BANDWIDTH-ADAPTIVE.txt
multimodal/2311.07575-SPHINX-_THEJOINT_MIXING_OF_WEIGHTS_,_TASKS_,.txt
multimodal/2308.07891-Link-Context_Learning_for_Multimodal_LLMs.txt
multimodal/2310.16764-2023-10-26.txt
multimodal/2310.00582-Pink-_Unveiling_the_Power_of_Referential_Comprehension_for_Multi-modal_LLMs.txt
multimodal/2312.03700-OneLLM-_One_Framework_to_Align_All_Modalities_with_Language.txt
multimodal/2309.05519-NExT-GPT-_Any-to-Any_Multimodal_LLM.txt
multimodal/2309.08922-MULTIMODAL_MULTI_-HOPQUESTION_ANSWERING_THROUGH_A.txt
multimodal/2406.11271-MINT-1T.txt
multimodal/2309.13876-REPRODUCING_WHISPER-STYLE_TRAINING_USING_AN_OPEN-SOURCE_TOOLKIT_AND.txt
multimodal/2206.02770-Multimodal_Contrastive_Learning_with_LIMoE.txt
multimodal/2305.17235-COMCAT-_Towards_Efficient_Compression_and_Customization_of.txt
multimodal/2310.15308-SAM-CLIP_-_Merging_Vision_Foundation_Models_towards.txt
multimodal/2305.03653-Query_Expansion_by_Prompting_Large_Language_Models.txt
multimodal/2310.08715-Toward_Joint_Language_Modeling_for_Speech_Units_and_Text.txt
multimodal/2308.07702-Better_Zero-Shot_Reasoning_with_Role-Play_Prompting.txt
multimodal/2308.00951-Published_as_a_conference_paper_at_ICLR_2024.txt
multimodal/2311.04589-Work_in_Progress.txt
multimodal/2204.09636-Residual_Mixture_of_Experts.txt
multimodal/2401.06387-1.txt
multimodal/2308.09729-MindMap_-_Knowledge_Graph_Prompting_Sparks_Graph_of_Thoughts_in.txt
multimodal/2312.17172-Unified-IO_2-_Scaling_Autoregressive_Multimodal_Models.txt
multimodal/2402.08846-An_Embarrassingly_Simple_Approach_for_LLM_with_Strong_ASR_Capacity.txt
multimodal/2310.06434-Whispering_LLaMA-_A_Cross-Modal_Generative_Error_Correction.txt
multimodal/2311.18765-MLLMs-Augmented_Visual-Language.txt
multimodal/2309.11419-KOSMOS_-2.5-_A_Multimodal_Literate_Model.txt
multimodal/2301.09595-Zorro-_the_masked_multimodal_transformer.txt
multimodal/2305.03453-T-SciQ-_Teaching_Multimodal_Chain-of-Thought_Reasoning_via_Mixed_Large.txt
multimodal/2303.08128-ViperGPT_-_Visual_Inference_via_Python_Execution_for_Reasoning.txt
multimodal/2310.08825-From_CLIP_to_DINO-_Visual_Encoders_Shout_in.txt
multimodal/2311.04219-OtterHD-_A_High-Resolution_Multi-modality_Model.txt
multimodal/2401.11053-StreamVoice-_Streamable_Context-Aware_Language_Modeling_for_Real-time.txt
multimodal/2310.04378-Preprint.txt
multimodal/2402.19481-DistriFusion-_Distributed_Parallel_Inference_for_High-Resolution_Diffusion_Models.txt
multimodal/2309.03905-ImageBind-LLM-_Multi-modality_Instruction_Tuning.txt
rag/2311.17696-How_to_Build_an_Adaptive_AI_Tutor_for_Any_Course.txt
rag/2403.18802-Long-form_factuality_in_large_language_models.txt
rag/2301.10444-An_Experimental_Study_on_Pretraining.txt
rag/2309.14525-Preprint.txt
rag/2112.09118-Published_in_Transactions_on_Machine_Learning_Research_(08-2022).txt
rag/2310.01352-Published_as_a_conference_paper_at_ICLR_2024.txt
rag/2404.12753-AUTOSCRAPER_-_A_Progressive_Understanding_Web_Agent_for_Web_Scraper.txt
rag/2308.00675-Tool_Documentation_Enables_Zero-Shot.txt
rag/2309.10691-Published_as_a_conference_paper_at_ICLR_2024.txt
rag/2405.10040-SYNTHESIZ_RR-_Generating_Diverse_Datasets_with_Retrieval_Augmentation.txt
rag/2308.15645-AskIt_-_Unified_Programming_Interface_for.txt
rag/2305.09955-Published_as_a_conference_paper_at_ICLR_2024.txt
rag/2301.10448-Pre-computed_memory_or_on-the-fly_encoding_A_hybrid_approach_to_retrieval.txt
rag/2307.16789-Preprint.txt
rag/2305.11944-Exploring_the_Viability_of_Synthetic_Query_Generation_for.txt
rag/2209.15469-ZERO-SHOT_RETRIEVAL_WITH_SEARCH_AGENTS.txt
rag/2310.05915-FI_R_EAC_T-_TOWARD_LANGUAGE_AGENT_FINE-TUNING.txt
rag/2204.04581-Augmenting_Pre-trained_Language_Models_with.txt
rag/2306.10231-GLIMMER_-_generalized_late-interaction_memory_reranker.txt
rag/2310.07554-Retrieve_Anything_To_Augment_Large_Language_Models.txt
rag/2407.12363-Conversational_Query_Reformulation_with_the_Guidance_of_Retrieved.txt
rag/2310.03046-Preprint.txt
rag/2405.14831-HippoRAG-_Neurobiologically_Inspired.txt
rag/2309.11436-You_Only_Look_at_Screens-_Multimodal_Chain-of-Action_Agents.txt
rag/2207.05987-Published_as_a_conference_paper_at_ICLR_2023.txt
rag/2309.07870-Agents-_An_Open-source_Framework.txt
rag/2308.10633-RALLE-_A_Framework_for_Developing_and_Evaluating.txt
rag/2303.07678-Query2doc-_Query_Expansion_with_Large_Language_Models.txt
rag/2305.15387-Peek_Across-_Improving_Multi-Document_Modeling.txt
rag/2304.13649-A_Symmetric_Dual_Encoding_Dense_Retrieval_Framework_for.txt
rag/2211.11559-Visual_Programming-_Compositional_visual_reasoning_without_training.txt
rag/2311.09210-Accepted_to_EMNLP_2024.txt
rag/2310.15594-Retrieval-based_Knowledge_Transfer-_An_Effective_Approach_for_Extreme.txt
rag/2005.11401-Retrieval-Augmented_Generation_for.txt
rag/2310.04406-Language_Agent_Tree_Search_Unifies_Reasoning,_Acting,_and_Planning_in.txt
rag/2405.10311-UniRAG-_Universal_Retrieval_Augmentation.txt
rag/2308.13259-Knowledge-Driven_CoT-_Exploring_Faithful_Reasoning_in_LLMs_for.txt
rag/2310.05149-RETRIEVAL-GENERATION_SYNERGY_AUGMENTED_LARGE_LANGUAGE_MODELS.txt
rag/2308.04711-Answering_Unseen_Questions_With_Smaller_Language.txt
rag/2307.11019-Investigating_the_Factual_Knowledge_Boundary_of_Large_Language_Models.txt
rag/2310.07075-Don’t_Fine-Tune,_Decode.txt
rag/2310.07713-InstructRetro-_Instruction_Tuning_post_Retrieval-Augmented_Pretraining.txt
rag/2310.17796-ControlLLM-_Augment_Language_Models_with_Tools_by_Searching_on_Graphs.txt
rag/2310.01558-Published_as_a_conference_paper_at_ICLR_2024.txt
rag/2308.07922-Published_as_a_conference_paper_at_COLM_2024.txt
rag/2306.05212-RETA-LLM-_A_Retrieval-Augmented_Large_Language_Model_Toolkit.txt
rag/2310.03214-Preprint.txt
rag/2212.05276-Natural_Logic-guided_Autoregressive_Multi-hop_Document_Retrieval.txt
rag/2404.06910-Superposition_Prompting-_Improving_and_Accelerating_Retrieval.txt
rag/2304.06762-Shall_We_Pretrain_Autoregressive_Language_Models_with_Retrieval.txt
rag/2306.00424-End-to-end_Knowledge_Retrieval_with_Multi-modal_Queries.txt
rag/2302.04761-Toolformer-_Language_Models_Can_Teach_Themselves_to_Use_Tools.txt
rag/2311.11315-TPTU-v2-_Boosting_Task_Planning_and_Tool_Usage_of.txt
rag/2308.14903-MEMORY_-VQ-_Compression_for_Tractable_Internet-Scale_Memory.txt
rag/2310.13227-Preprint.txt
rag/2305.18323-ReWOO-_Decoupling_Reasoning_from_Observations.txt
rag/2401.18059-Published_as_a_conference_paper_at_ICLR_2024.txt
rag/2407.01965-ADACQR_-_Enhancing_Query_Reformulation_for_Conversational_Search_via.txt
rag/2301.01820-arXiv-2301.01820v4_[cs.IR]_26_May_2023InPars-v2-_Large_Language_Models_as_Efﬁcient.txt
rag/2309.03118-KNOWLEDGE_SOLVER_-_TEACHING_LLM_S_TO_SEARCH_FOR.txt
rag/2406.01549-An_Information_Bottleneck_Perspective_for_Effective_Noise_Filtering_on.txt
rag/2309.12767-FURTHEST_REASONING_WITH_PLAN_ASSESSMENT_-_STABLE.txt
rag/2407.12325-Optimizing_Query_Generation_for_Enhanced_Document_Retrieval_in_RAG.txt
rag/2308.03983-SimplyRetrieve-_A_Private_and_Lightweight_Retrieval-Centric_Generative.txt
rag/2310.08319-Fine-Tuning_LLaMA_for_Multi-Stage_Text_Retrieval.txt
rag/2403.19889-Towards_a_Robust_Retrieval-Based_Summarization.txt
rag/2403.15268-Awakening_Augmented_Generation-_Learning_to_Awaken_Internal.txt
rag/2305.09313-Hybrid_and_Collaborative_Passage_Reranking.txt
rag/2305.09612-Large_Language_Models_are_Built-in_Autoregressive_Search_Engines.txt
rag/2307.07164-Learning_to_Retrieve_In-Context_Examples_for_Large_Language_Models.txt
rag/2308.12574-Modeling_Uncertainty_and_Using_Post-fusion_as_Fallback_Improves.txt
rag/2404.14361-Better_Synthetic_Data_by_Retrieving_and_Transforming.txt
rag/2309.11688-arXiv-2309.11688v1_[cs.CL]_20_Sep_2023LLM_Guided_Inductive_Inference_for_Solving_Compositional_P_rob.txt
rag/2310.04408-RECOMP-_I_MPROVING_RETRIEVAL_-AUGMENTED_LM_S.txt
rag/2307.12798-RRAML-_Reinforced_Retrieval_Augmented.txt
rag/2407.12529-Crafting_the_Path-_Robust_Query_Rewriting_for_Information_Retrieval.txt
rag/2306.08302-JOURNAL_OF_LATEX_CLASS_FILES,_VOL._,_NO._,_MONTH_20YY_1.txt
rag/2210.15133-Retrieval_Oriented_Masking_Pre-training.txt
rag/2310.15511-Preprint.txt
rag/2309.02427-Published_in_Transactions_on_Machine_Learning_Research_(02-2024).txt
rag/2309.17428-Published_as_a_conference_paper_at_ICLR_2024.txt
rag/2304.09842-Chameleon_-_Plug-and-Play_Compositional_Reasoning.txt
rag/2211.12561-Retrieval-Augmented_Multimodal_Language_Modeling.txt
rag/2210.01296-Published_as_a_conference_paper_at_ICLR_2023.txt
rag/2310.12823-Preprint.txt
rag/2404.15420-XC-C_ACHE_-_Cross-Attending_to_Cached_Context_for_Efficient_LLM.txt
rag/2405.04065-arXiv-2405.04065v4_[cs.CL]_13_Jun_2025FLASH_BACK.txt
rag/2404.02022-Improving_Retrieval_Augmented_Open-Domain_Question-Answering_with.txt
rag/2309.15217-Ragas-_Automated_Evaluation_of_Retrieval_Augmented_Generation.txt
rag/2310.04474-Reverse_Chain-_A_Generic-Rule_for_LLMs_to_Master_Multi-API_Planning.txt
rag/2401.15884-Corrective_Retrieval_Augmented_Generation.txt
rag/2307.08775-EACL_2024.txt
rag/2304.13157-Generative_Relevance_Feedback_with_Large_Language_Models.txt
rag/2304.14732-Search-in-the-Chain-_Interactively_Enhancing_Large_Language.txt
rag/2310.15556-TCRA-LLM-_Token_Compression_Retrieval_Augmented_Large_Language.txt
rag/2305.15225-SAIL-_Search-Augmented_Instruction_Learning.txt
rag/2309.01431-Benchmarking_Large_Language_Models_in_Retrieval-Augmented_Generation.txt
rag/2212.10511-ACL_2023.txt
rag/2401.06201-EASYTOOL-_Enhancing_LLM-based_Agents_with_Concise_Tool_Instruction.txt
long-context/2310.03025-Published_as_a_conference_paper_at_ICLR_2024.txt
long-context/2312.06635-Gated_Linear_Attention_Transformers_with_Hardware-Efficient_Training.txt
long-context/2309.03450-XGen-7B_Technical_Report.txt
long-context/2401.18058-LongAlign-_A_Recipe_for_Long_Context_Alignment.txt
long-context/2401.07872-The_What,_Why,_and_How_of_Context_Length_Extension_Techniques_in.txt
long-context/2312.08618-Zebra-_Extending_Context_Window_with_Layerwise_Grouped.txt
long-context/2309.16039-Effective_Long-Context_Scaling_of_Foundation_Models.txt
long-context/2402.13753-LongRoPE-_Extending_LLM_Context_Window_Beyond_2_Million_Tokens.txt
long-context/2406.10996-Towards_Lifelong_Dialogue_Agents_via_Timeline-based.txt
long-context/2309.00071-YaRN-_Efficient_Context_Window_Extension_of_Large.txt
convolution/1810.06682-Published_as_a_conference_paper_at_ICLR_2019.txt
convolution/2402.18508-Orchid-_Flexible_and_Data-Dependent_Convolution.txt
convolution/2206.01191-EfﬁcientFormer-_Vision_Transformers_at_MobileNet.txt
convolution/2209.08326-Parameter-Efﬁcient_Conformers_via_Sharing_Sparsely-Gated_Experts_for.txt
convolution/2309.10713-Interpret_Vision_Transformers_as_ConvNets_with_Dynamic_Convolutions.txt
convolution/2401.05738-JOURNAL_OF_L_ATEX_CLASS_FILES,_VOL._14,_NO._8,_AUGUST_2015_1.txt
convolution/2312.04927-Zoology-_Measuring_and_Improving_Recall_in_Efficient_Language.txt
convolution/2312.00752-Mamba-_Linear-Time_Sequence_Modeling_with_Selective_State_Spaces.txt
convolution/2211.08339-IEEE_TRANSACTIONS_ON_PATTERN_ANAL_YSIS_AND_MACHINE_INTELLIGENCE_1.txt
convolution/1708.04729-Deconvolutional_Paragraph_Representation_Learning.txt
convolution/2310.18780-Laughing_Hyena_Distillery.txt
convolution/2311.02772-arXiv-2311.02772v2_[cs.SD]_8_Feb_2024ATTENTION_OR_CONVOLUTION-_TRANSFORMER_ENCODERS_IN_AUDIO_LA_NGUA.txt
convolution/2003.00152-Published_as_a_conference_paper_at_ICLR_2021.txt
convolution/2309.14157-THIS_WORK_HAS_BEEN_SUBMITTED_TO_THE_IEEE_FOR_POSSIBLE_PUBLICATION._COPYRIGHT_MAY_BE_TRANSFERRED_WITH.txt
convolution/2311.05908-FlashFFTConv_-_Efficient_Convolutions_for.txt
convolution/2308.10110-Robust_Mixture-of-Expert_Training_for_Convolutional_Neural_Networks.txt
convolution/2203.02549-Structured_Pruning_is_All_You_Need.txt
evaluation/2311.06720-Cappy-_Outperforming_and_Boosting_Large.txt
evaluation/2405.01535-PROMETHEUS_2-_An_Open_Source_Language_Model_Specialized_in.txt
evaluation/2311.09204-Fusion-Eval-_Integrating_Assistant_Evaluators_with_LLMs.txt
evaluation/2309.11385-arXiv-2309.11385v1_[cs.CL]_20_Sep_2023SAFURAI_001-_N_EWQUALITATIVE_APPROACH_FOR.txt
evolutionary-algorithms/2206.08896-Evolution_through_Large_Models.txt
evolutionary-algorithms/2309.08532-Published_as_a_conference_paper_at_ICLR_2024.txt
ssm/2401.13660-Published_as_a_conference_paper_at_COLM_2024.txt
ssm/2406.07522-Published_as_a_conference_paper_at_ICLR_2025.txt
ssm/2402.00789-Graph-Mamba-_Towards_Long-Range_Graph_Sequence_Modeling_with.txt
ssm/2302.06218-A_Uniﬁed_View_of_Long-Sequence_Models_towards.txt
ssm/2401.13560-SegMamba-_Long-range_Sequential_Modeling.txt
ssm/2302.06646-Simple_Hardware-Ecient_Long_Convolutions_for_Sequence.txt
ssm/2403.06977-VideoMamba-_State_Space_Model_for_Efficient.txt
ssm/2402.15648-MambaIR-_A_Simple_Baseline_for_Image.txt
ssm/2401.10166-VMamba-_Visual_State_Space_Model.txt
ssm/2402.04248-Can_Mamba_Learn_How_to_Learn.txt
ssm/2406.02395-GrootVL-_Tree_Topology_is_All_You_Need.txt
ssm/2403.00818-DenseMamba-_State_Space_Models_with_Dense_Hidden_Connection.txt
ssm/2403.07711-SSM_Meets_Video_Diffusion_Models-_Efficient_Long-Term.txt
ssm/2403.09338-LocalMamba-_Visual_State_Space_Model_with.txt
ssm/2408.15496-ReMamba-_Equip_Mamba_with_Effective_Long-Sequence_Modeling.txt
ssm/2402.05643-Improving_Token-Based_World_Models_with_Parallel_Observation_Prediction.txt
ssm/2408.08066-Mamba_Retriever-_Utilizing_Mamba_for_Effective_and_Efficient.txt
ssm/2401.14168-VOL._XX,_NO._XX,_XXXX_2022_1.txt
ssm/2310.19694-Convolutional_State_Space_Models_for.txt
ssm/2401.09417-Vision_Mamba-_Efficient_Visual_Representation_Learning_with_Bidirectional.txt
ssm/2306.06635-2-D_SSM-_A_General_Spatial_Layer.txt
ssm/2311.14495-StableSSM-_Alleviating_the_Curse_of_Memory_in_State-space_Models_through.txt
ssm/2402.08678-Graph_Mamba-_Towards_Learning_on_Graphs_with_State_Space_Models.txt
ssm/2311.08756-Accelerating_Toeplitz_Neural_Network_with_Constant-time.txt
ssm/2401.17919-LOCOST-_State-Space_Models_for_Long_Document_Abstractive.txt
ssm/2405.14174-Multi-Scale_VMamba-_Hierarchy_in_Hierarchy.txt
ssm/2402.10211-Hierarchical_State_Space_Models.txt
ssm/2306.01768-A_Quantitative_Review_on.txt
ssm/2402.01771-BlackMamba-_Mixture_of_Experts_for_State-Space.txt
ssm/2407.14207-Preprint..txt
ssm/2405.16712-Zamba-_A_Compact_7B_SSM_Hybrid_Model.txt
ssm/2403.19888-MambaMixer-_E_fficient_Selective_State_Space_Models.txt
finance/2304.07619-Can_ChatGPT_Forecast_Stock_Price_Movements.txt
finance/2305.05862-AreChatGPT_andGPT-4_General-Purpose_Solvers_for.txt
finance/2402.12659-FinBen-_An_Holistic_Financial_Benchmark_for_Large.txt
finance/2311.07592-Hallucination-minimized_Data-to-answer_Framework.txt
finance/2402.10986-FinTral-_A_Family_of_GPT-4_Level_Multimodal_Financial_Large.txt
finance/2308.07935-Highlights.txt
finance/2306.12659-Instruct-FinGPT-_Financial_Sentiment_Analysis_by_Instruction_Tuning_of.txt
finance/2306.05443-PIXIU-_A_Large_Language_Model,_Instruction_Data.txt
finance/2309.13064-InvestLM-_A_Large_Language_Model_for_Investment_using_Financial.txt
diffusion/2310.11976-InfoDiffusion-_Information_Entropy_Aware_Diffusion_Process_for.txt
diffusion/2308.08739-Enhancing_Phrase_Representation_by_Information_Bottleneck.txt
diffusion/2403.13802-ZigMa-_A_DiT-style_Zigzag_Mamba_Diffusion.txt
diffusion/2308.12219-Preprint.txt
diffusion/2301.11093-simple_diffusion-_End-to-end_diffusion_for_high_resolution_images.txt
diffusion/2402.17113-Transparent_Image_Layer_Diffusion_using_Latent_Transparency.txt
diffusion/2402.05608-Scalable_Diffusion_Models_with_State_Space.txt
diffusion/2311.12908-Diffusion_Model_Alignment_Using_Direct_Preference_Optimization.txt
diffusion/2401.10032-FREGRAD-_LIGHTWEIGHT_AND_FAST_FREQUENCY-AWARE_DIFFUSION_VOCODER.txt
diffusion/2304.02051-Multimodal_Garment_Designer.txt
diffusion/2402.01516-Cross-view_Masked_Diffusion_Transformers_for_Person_Image_Synthesis.txt
diffusion/2310.06389-LEGO_Diffusion.txt
diffusion/2401.12179-DITTO-_Diffusion_Inference-Time_T-Optimization_for_Music_Generation.txt
diffusion/2305.18619-Likelihood-Based_Diffusion_Language_Models.txt
diffusion/2402.12376-FiT-_Flexible_Vision_Transformer_for_Diffusion_Model.txt
diffusion/2305.13655-LLM-grounded_Diffusion-_Enhancing_Prompt_Understanding.txt
diffusion/2305.08379-TESS-_Text-to-Text_Self-Conditioned_Simplex_Diffusion.txt
diffusion/2405.14828-Good_Seed_Makes_a_Good_Crop.txt
diffusion/2211.04236-SELF-CONDITIONED_EMBEDDING_DIFFUSION.txt
diffusion/2311.18257-Diffusion_Models_Without_Attention.txt
diffusion/2210.17432-SSD-LM-_Semi-autoregressive_Simplex-based_Diffusion_Language_Model.txt
diffusion/2210.08933-Published_as_a_conference_paper_at_ICLR_2023.txt
diffusion/2305.10855-TextDiffuser-_Diffusion_Models_as_Text_Painters.txt
diffusion/2312.04410-Smooth_Diffusion-_Crafting_Smooth_Latent_Spaces_in_Diffusion_Models.txt
diffusion/2404.04478-Diffusion-RWKV.txt
text-classification/2310.14192-PromptMix-_A_Class_Boundary_Augmentation_Method_for_Large_Language.txt
text-classification/2111.09064-Guiding_Generative_Language_Models_for.txt
text-classification/2103.14453-A_Novel_Data_Augmentation_Text_Generation_Approach.txt
multilingual/2309.08958-Monolingual_or_Multilingual_Instruction_Tuning.txt
multilingual/2103.03541-Multilingual_Byte2Speech_Models_for_Scalable.txt
multilingual/2305.13627-InstructAlign-_High-and-Low_Resource_Language_Alignment.txt
multilingual/2209.11035-MonoByte-_A_Pool_of_Monolingual_Byte-level_Language_Models.txt
multilingual/2310.05824-Terminology-Aware_Translation_with_Constrained_Decoding.txt
multilingual/2305.01181-A_Paradigm_Shift-_The_Future_of_Machine_Translation_Lies_with.txt
multilingual/2308.14508-LongBench-_A_Bilingual,_Multitask_Benchmark.txt
multilingual/2309.17061-SCALE-_S_YNERGIZED_COLLABORATION_OF_ASYM.txt
multilingual/2309.01940-111CodeApex-_A_Bilingual_Programming_Evaluation_Benchmark.txt
multilingual/2205.08180-1.txt
multilingual/2309.07462-Are_Large_Language_Model-based_Evaluators_the_Solution_to_Scaling_Up.txt
multilingual/2305.11626-CCT-Code-_Cross-Consistency_Training_for_Multilingual_Clone_Detection.txt
multilingual/2305.15183-Are_Pre-trained_Language_Models_Useful_for_Model_Ensemble_in_Chinese.txt
multilingual/2305.07016-A_General-Purpose_Multilingual_Document_Encoder.txt
multilingual/2404.19505-Context-Aware_Machine_Translation_with_Source_Coreference_Explanation.txt
multilingual/2401.13303-Preprint._Under_review..txt
multilingual/2306.15604-Constructing_Multilingual_Code_Search_Dataset_Using_Neural_Machine.txt
multilingual/2305.06156-The_Vault-_A_Comprehensive_Multilingual_Dataset_for_Advancing_Code.txt
multilingual/2306.10241-Snowman.txt
multilingual/2310.13448-Steering_Large_Language_Models_for_Machine_Translation.txt
multilingual/2309.11668-Towards_Effective_Disambiguation_for_Machine_Translation.txt
multilingual/2303.03915-The_BigScience_ROOTS_Corpus.txt
multilingual/2402.01939-A_Morphologically-Aware_Dictionary-based_Data_Augmentation_Technique.txt
multilingual/2406.19759-Breaking_the_Script_Barrier_in_Multilingual_Pre-Trained_Language_Models.txt
multilingual/2307.16039-Okapi-_Instruction-tuned_Large_Language_Models_in_Multiple_Languages.txt
multilingual/2311.08849-OFA-_A_Framework_of_Initializing_Unseen_Subword_Embeddings_for.txt
multilingual/2304.08823-Transfer_to_a_Low-Resource_Language_via_Close_Relatives.txt
multilingual/2401.06466-PersianMind_-_A_Cross-Lingual_Persian-English_Large_Language.txt
multilingual/2403.00417-Rethinking_Tokenization-_Crafting_Better_Tokenizers_for_Large_Language.txt
multilingual/2309.09400-CulturaX-_A_Cleaned,_Enormous,_and_Multilingual_Dataset_for_Large.txt
multilingual/2312.04515-Efficient_Monotonic_Multihead_Attention.txt
multilingual/2306.00789-PREPRINT_1.txt
multilingual/2212.01936-Springer_Nature_2021_L_ATEX_template.txt
multilingual/2309.04646-arXiv-2309.04646v1_[cs.CL]_9_Sep_2023Efficient_Finetuning_Large_Language_Models_For.txt
multilingual/2311.05640-FinGPT-_Large_Generative_Models_for_a_Small_Language.txt
multilingual/2309.06706-Simultaneous_Machine_Translation_with_Large_Language_Models.txt
multilingual/2205.00485-arXiv-2205.00485v1_[cs.CL]_1_May_2022BILINGUAL_END-TO-END_ASR_WITH_BYTE-LEVEL_SUBWORDS.txt
multilingual/2209.09900-LINGUIST_-_Language_Model_Instruction_Tuning_to_Generate_Annotated.txt
multilingual/1804.06609-Fast_Lexically_Constrained_Decoding_with_Dynamic_Beam_Allocation_for.txt
multilingual/2308.14186-Empowering_Cross-lingual_Abilities_of_Instruction-tuned_Large_Language.txt
multilingual/2309.11165-Assessment_of_Pre-Trained_Models_Across_Languages_and_Grammars.txt
multilingual/2401.01854-Multilingual_Instruction_Tuning_With_Just_a_Pinch_of_Multilinguality.txt
multilingual/2402.08015-Walia-LLM-_Enhancing_Amharic-LLaMA_by_Integrating_Task-Specific_and.txt
multilingual/2305.13504-Neural_Machine_Translation_for_Code_Generation.txt
multilingual/2305.17179-Tokenization_Impacts_Multilingual_Language_Modeling.txt
multilingual/2309.10654-CFGPT-_Chinese_Financial_Assistant_with_Large_Language_Model.txt
multilingual/2309.10661-NusaWrites-_Constructing_High-Quality_Corpora_for.txt
multilingual/2308.04948-EXTRAPOLATING_LARGE_LANGUAGE_MODELS_TO.txt
multilingual/2308.12674-Improving_Translation_Faithfulness_of_Large_Language_Models_via.txt
multilingual/2403.19930-Are_LLMs_Effective_Backbones_for_Fine-tuning_An_Experimental.txt
multilingual/2312.14862-YAYI_2-_Multilingual_Open-Source_Large_Language_Models.txt
multilingual/2306.14096-Chinese_Fine-Grained_Financial_Sentiment_Analysis_with_Large_Language_Models.txt
multilingual/2304.07987-CHINESE_OPEN_INSTRUCTION_GENERALIST.txt
multilingual/2402.14086-LexC-Gen_-_Generating_Data_for_Extremely_Low-Resource_Languages.txt
multilingual/2309.08590-Neural_Machine_Translation_Models_Can_Learn_to_be_Few-shot_Learners.txt
multilingual/2305.15083-Eliciting_the_Translation_Ability_of_Large_Language_Models_via.txt
multilingual/2402.03131-Published_as_a_conference_paper_at_ICLR_2024.txt
multilingual/2302.14220-Are_Character-level_Translations_Worth_the_Wait.txt
multilingual/2310.19341-Skywork-_A_More_Open_Bilingual_Foundation_Model.txt
multilingual/2406.02517-Deterministic_Reversible_Data_Augmentation.txt
multilingual/2402.10588-Do_Llamas_Work_in_English.txt
multilingual/2402.02080-Translation_Errors_Significantly_Impact.txt
multilingual/2306.01709-Distilling_Efficient_Language-Specific_Models_for_Cross-Lingual_Transfer.txt
multilingual/2212.09811-Memory-efficient_NLLB-200-_Language-specific_Expert_Pruning_of_a.txt
multilingual/2406.13923-Preview_Version.txt
multilingual/2304.04675-Multilingual_Machine_Translation_with_Large_Language_Models.txt
multilingual/2406.06263-MaskLID-_Code-Switching_Language_Identification_through_Iterative.txt
multilingual/2310.12236-Direct_Neural_Machine_Translation_with_Task-level_Mixture_of_Experts.txt
multilingual/2310.07321-On_the_Impact_of_Cross-Domain_Data_on_German_Language_Models.txt
multilingual/2310.08166-Ziya-VL_Technical_Report.txt
multilingual/2307.05956-Language-Routing_Mixture_of_Experts_for_Multilingual_and_Code-Switching.txt
multilingual/2210.07535-AutoMoE-_Heterogeneous_Mixture-of-Experts_with_Adaptive_Computation.txt
multilingual/2310.15987-Dissecting_In-Context_Learning_of_Translations_in_GPTs.txt
multilingual/2110.15248-This_paper_was_published_in_W-NUT_2021_–_please_cite_the_published_version_https-aclanthology.org-20.txt
multilingual/2311.07463-MEGAVERSE_-_Benchmarking_Large_Language_Models_Across.txt
multilingual/2312.12683-Turning_English-centric_LLMs_Into_Polyglots.txt
multilingual/2208.01018-Massively_Multilingual_Lexical_Specialization_of_Multilingual_Transformers.txt
multilingual/1909.03341-Neural_Machine_Translation_with_Byte-Level_Subwords.txt
multilingual/2401.07037-XCOT-_Cross-lingual_Instruction_Tuning_for_Cross-lingual.txt
multilingual/2305.14235-Multilingual_Large_Language_Models_Are_Not_(Yet)_Code-Switchers.txt
multilingual/2310.13988-GEMBA-MQM-_Detecting_Translation_Quality_Error_Spans_with_GPT-4.txt
multilingual/2306.15788-arXiv-2306.15788v2_[cs.CL]_18_Jul_2023Evaluating_GPT-3.5_and_GPT-4_on.txt
multilingual/2312.06134-Order_Matters_in_the_Presence_of_Dataset_Imbalance.txt
multilingual/2306.04387-M3IT-_A_Large-Scale_Dataset_towards.txt
multilingual/2110.06920-Semantics-aware_Attention_Improves_Neural_Machine_Translation.txt
multilingual/2309.10931-arXiv-2309.10931v4_[cs.CL]_2_Aug_2024A_Family_of_Pretrained_Transformer_Language_Models_for_Russ_ian.txt
multilingual/2102.02189-Bootstrapping_Multilingual_AMR_with_Contextual_Word_Alignments.txt
multilingual/2312.08688-TigerBot-_An_Open_Multilingual_Multitask_LLM.txt
multilingual/2405.19327-MAP-Neo-_Highly_Capable_and_Transparent.txt
multilingual/2405.19290-Integrating_Multi-scale_Contextualized_Information_for_Byte-based.txt
multilingual/2309.16609-QWEN_TECHNICAL_REPORT.txt
multilingual/2305.12371-Sādhanā_V_ol._,_No.,_,_pp.–.txt
multilingual/2305.09220.txt
multilingual/2305.11129-mLongT5-_A_Multilingual_and_Efficient_Text-To-Text_Transformer_for.txt
multilingual/2309.10305-Baichuan_2-_Open_Large-scale_Language_Models.txt
multilingual/2401.01055-LLaMA_Beyond_English-_An_Empirical_Study_on_Language_Capability_Transfer.txt
multilingual/2212.06742-ERNIE-Code-_Beyond_English-Centric_Cross-lingual_Pretraining_for.txt
multilingual/2402.06619-Aya_Dataset-_An_Open-Access_Collection.txt
multilingual/2307.13923-GrammarGPT-_Exploring_Open-Source_LLMs.txt
multilingual/2401.10695-LANGBRIDGE_-_Multilingual_Reasoning_Without_Multilingual_Supervision.txt
multilingual/2305.12182-Glot500.txt
multilingual/2309.11674-Published_as_a_conference_paper_at_ICLR_2024.txt
multilingual/2402.14818-PALO-_A_Polyglot_Large_Multimodal_Model_for_5B_People.txt
multilingual/2309.14174-Only_5%_Attention_Is_All_You_Need-_Efficient_Long-range_Document-level.txt
multilingual/2309.11346-GECTurk-_Grammatical_Error_Correction_and_Detection_Dataset_for.txt
multilingual/2309.10706-Update-_We_have_performed_full-parameter_fine-tuning_with_specialized_datasets,_enabling_OpenBA.txt
multilingual/2308.16149-JaisandJais-chat.txt
multilingual/2402.02113-Zero-shot_Sentiment_Analysis_in_Low-Resource_Languages_Using_a.txt
multilingual/2309.04862-Distributional_Data_Augmentation_Methods_for_Low_Resource_Language.txt
multilingual/2309.04662-MADLAD-400_-_A_Multilingual_And_Document-Level.txt
multilingual/2401.10660-Accelerating_Multilingual_Language_Model_for.txt
multilingual/2404.09163-GeMQuAD.txt
multilingual/2311.06753-AudioChatLlama-_Towards_General-Purpose_Speech_Abilities_for_LLMs.txt
multilingual/2305.04160-X-LLM.txt
multilingual/2302.14229-Zero-Shot_Cross-Lingual_Summarization_via_Large_Language_Models.txt
multilingual/2403.18058-COIG-CQIA-_Quality_is_All_You_Need_for_Chinese_Instruction_Fine-tuning.txt
multilingual/2309.05270-CONFLATOR-_Incorporating_Switching_Point_based_Rotatory_Positional.txt
multilingual/2309.11259-arXiv-2309.11259v2_[cs.CL]_21_Mar_2024Sequence-to-Sequence_Spanish_Pre-trained_Language_Model_s.txt
multilingual/1901.09102-On_Learning_Meaningful_Code_Changes_via.txt
multilingual/2304.07880-Sabi´_a-_Portuguese_Large_Language_Models.txt
svg/2306.06094-An_Investigation_on_LLMs’_Visual_Understanding_Ability.txt
svg/2401.17093-StrokeNUWA-_Tokenizing_Strokes_for_Vector_Graphic_Synthesis.txt
svg/2312.10540-VecFusion-_Vector_Font_Generation_with_Diffusion.txt
svg/2312.11556-arXiv-2312.11556v4_[cs.CV]_31_May_2025.txt
svg/2304.14400-IconShop-_Text-Guided_Vector_Icon_Synthesis_with_Autoregressive.txt
writing/2306.14905-PRISMA-DFLLM-_An_Extension_of_PRISMA_for_Systematic.txt
writing/2310.08185-EIPE-text-_Evaluation-Guided_Iterative_Plan_Extraction_for_Long-Form.txt
writing/2401.17268-Weaver_-_Foundation_Models_for_Creative_Writing.txt
writing/2311.09180-PEARL_-_Personalizing_Large_Language_Model_Writing.txt
writing/2310.05388-GROVE-_A_Retrieval-augmented_Complex_Story_Generation_Framework.txt
math/2309.05653-Preprint._Work_in_Progress.txt
math/2308.01825-Preprint.txt
math/2310.07488-KWAIYIIMATH-_TECHNICAL_REPORT.txt
math/2311.03739-Leveraging_Large_Language_Models_for_Automated_Proof_Synthesis_in_Rust.txt
math/2311.07587-FRONTIER_LANGUAGE_MODELS_ARE_NOT_ROBUST.txt
math/2309.11054-Preprint..txt
math/2305.06599-Structured_Chain-of-Thought_Prompting_for_Code_Generation.txt
math/2311.11829-System_2_Attention.txt
math/2310.10047-IMPROVING_LARGE_LANGUAGE_MODEL_FINE-TUNING.txt
math/2401.08190-MARIO-_MAth_Reasoning_with_code_Interpreter_Output.txt
math/2305.07004-Not_All_Languages_Are_Created_Equal_in_LLMs.txt
math/2310.16713-SKYMATH-_TECHNICAL_REPORT.txt
math/2305.18170-Leveraging_Training_Data_in_Few-Shot_Prompting_for_Numerical_Reasoning.txt
math/2312.17120-MATHPILE-_A_Billion-Token-Scale_Pre-training.txt
math/2310.03731-MATHCODER_-_S_EAMLESS_CODE_INTEGRATION_IN.txt
math/2306.01707-Learning_Multi-Step_Reasoning_by_Solving_Arithmetic_Tasks.txt
math/2309.10814-Natural_Language_Embedded_Programs_for.txt
math/2402.03300-DeepSeekMath-_Pushing_the_Limits_of_Mathematical.txt
math/2310.00726-Improving_Length-Generalization_in.txt
math/2309.17452-Published_as_a_conference_paper_at_ICLR_2024.txt
math/2312.06585-2024-4-19.txt
math/2305.11461-Hint_of_Thought_prompting-_an_explainable_and_zero-shot_approach_to.txt
math/2308.09583-arXiv-2308.09583v3_[cs.CL]_4_Jun_2025Published_as_a_conference_paper_at_ICLR_2025.txt
math/2309.00642-Extracting_Mathematical_Concepts.txt
math/2401.09003-Augmenting_Math_Word_Problems_via_Iterative_Question_Composing.txt
math/2308.00436-SELFCHECK_-USING_LLM_S_TO_ZERO_-SHOT_CHECK.txt
math/2308.07758-Forward-Backward_Reasoning_in_Large_Language_Models.txt
math/2310.10631-Published_as_a_conference_paper_at_ICLR_2024.txt
math/2308.07921-SOLVING_CHALLENGING_MATH_WORD_PROBLEMS_USING_GPT-4.txt
math/2309.13075-SCREWS.txt
math/2309.12284-Published_as_a_conference_paper_at_ICLR_2024.txt
peft/2311.13171-ComPEFT_-_Compression_for_Communicating_Parameter_Efficient_Updates_via.txt
peft/2210.04382-Parameter-Efﬁcient_Tuning_with_Special_Token_Adaptation.txt
peft/2004.12406-Masking_as_an_Efﬁcient_Alternative_to_Finetuning.txt
peft/2301.12132-AUTOPEFT-_Automatic_Configuration_Search_for.txt
peft/2209.09815-Towards_Fine-tuning_Pre-trained_Language_Models_with.txt
peft/2401.00788-ASTRAIOS_-_Parameter-Efficient_Instruction_Tuning.txt
peft/2402.14688-Q-Probe-_A_Lightweight_Approach_to.txt
peft/2306.07536-Tart_-_A_plug-and-play_Transformer_module_for.txt
peft/2309.16119-arXiv-2309.16119v2_[cs.LG]_10_Mar_2024ModuLoRA-_Finetuning_2-Bit_LLMs_on_Consumer_GPUs_by.txt
peft/2004.14566-TRP-_Trained_Rank_Pruning_for_Efﬁcient_Deep_Neural_Networks.txt
peft/2208.08340-1.txt
peft/2304.04947-Conditional_Adapters-_Parameter-efficient.txt
peft/2306.04933-InfoPrompt-_Information-Theoretic_Soft_Prompt_Tuning_for.txt
peft/2311.11501-MULTI_LORA-_D_EMOCRATIZING_LORA_FOR_BETTER.txt
peft/2305.13729-Discrete_Prompt_Optimization_via_Constrained_Generation.txt
peft/2305.13235-SPARSE_FIT-_Few-shot_Prompting_with_Sparse_Fine-tuning_for_Jointly.txt
peft/2305.02538-CUTTLEFISH_-_LOW-RANK_MODEL_TRAINING_WITHOUT_ALLTHETUNING.txt
peft/2305.08285-Parameter-Efﬁcient_Fine-Tuning_with_Layer_Pruning_on_Free-Text.txt
peft/2303.06233-Model-Agnostic_Syntactical_Information_for.txt
peft/2310.05015-Preprint.txt
peft/2305.17331-Augmentation-Adapted_Retriever_Improves_Generalization_of_Language.txt
peft/2307.13269-Published_as_a_conference_paper_at_COLM_2024.txt
peft/2402.10193-BitDelta-_Your_Fine-Tune_May_Only_Be_Worth_One_Bit.txt
peft/2308.07282-arXiv-2308.07282v2_[cs.CL]_8_Apr_2024Comparison_between_parameter-efficient_techniques_and_fu_ll.txt
peft/2309.11042-Making_Small_Language_Models_Better_Multi-task_Learners_with.txt
peft/2305.01711-Don’t_Stop_Pretraining_Make_Prompt-based.txt
peft/2312.00968-Omni-SMoLA-_Boosting_Generalist_Multimodal_Models_with_Soft_Mixture_of.txt
peft/2305.18403-LoRAPrune-_Structured_Pruning_Meets_Low-Rank.txt
peft/2110.04366-Published_as_a_conference_paper_at_ICLR_2022.txt
peft/2210.07558-DyLoRA-_Parameter-Efﬁcient_Tuning_of_Pretrained_Models_using.txt
peft/2309.05444-Pushing_Mixture_of_Experts_to_the_Limit.txt
peft/2305.04757-Augmented_Large_Language_Models_with.txt
peft/2309.14717-QA-L_ORA-_Q_UANTIZATION_-AWARE_LOW-RANK.txt
peft/2211.03044-Tuning_Language_Models_as_Training_Data_Generators_for.txt
peft/2306.15706-Approximated_Prompt_Tuning_for_Vision-Language_Pre-trained_Models.txt
peft/2302.06354-Less_is_More.txt
peft/2310.18547-PUNICA_-_M_ULTI_-TENANT_LORA_S_ERVING.txt
peft/2305.14788-Adapting_Language_Models_to_Compress_Contexts.txt
peft/2304.09402-MIXPRO-_Simple_yet_Effective_Data_Augmentation_for.txt
peft/2110.06274-LiST-_Lite_Prompted_Self-training_Makes_Parameter-efﬁcient.txt
peft/2312.09979-LoRAMoE-_Alleviate_World_Knowledge_Forgetting_in_Large.txt
peft/1812.02402-Trained_Rank_Pruning_for_Efﬁcient_Deep_Neural.txt
peft/2309.06526-EXPLORING_THE_BENEFITS_OF_DIFFERENTIALLY_PRIV_ATE_PRE-TRAINING_AND.txt
peft/2310.11454-Published_as_a_conference_paper_at_ICLR_2024.txt
peft/2311.11077-Adapters_-_A_Unified_Library_for.txt
peft/2309.09276-SUBMIT_TO_IEEE_TRANSACTIONS_1.txt
peft/2303.02577-Effectiveness_of_Data_Augmentation_for_Parameter_Efficient_Tuning_with.txt
peft/2210.06210-Pruning_Pre-trained_Language_Models_Without_Fine-Tuning.txt
peft/2303.13072-Beyond_Universal_Transformer-_block_reusing_with_adaptor_in_Transformer.txt
peft/2403.13372-LLAMA_FACTORY_-_Unified_Efficient_Fine-Tuning_of_100+_Language_Models.txt
peft/2311.13600-ZipLoRA-_Any_Subject_in_Any_Style_by_Effectively_Merging_LoRAs.txt
peft/2303.11403-eP-ALM-_Efficient_Perceptual_Augmentation_of_Language_Models.txt
peft/2505.20355-GraLoRA-_Granular_Low-Rank_Adaptation_for.txt
peft/2401.00243-Uncertainty-Penalized_Reinforcement_Learning_from_Human_Feedback_with.txt
peft/2311.09179-SiRA-_Sparse_Mixture_of_Low_Rank_Adaptation.txt
peft/2305.07491-A_Comprehensive_Analysis_of_Adapter_Efﬁciency.txt
peft/2310.02556-Published_as_a_conference_paper_at_ICLR_2024.txt
peft/2307.08303-Soft_Prompt_Tuning_for_Augmenting_Dense_Retrieval_with_Large.txt
peft/2311.17601-arXiv-2311.17601v1_[cs.LG]_29_Nov_2023Continual_Learning_with_Low_Rank_Adaptation.txt
peft/2212.09535-BLOOM+1-_Adding_Language_Support_to_BLOOM_for_Zero-Shot.txt
peft/2305.18752-GPT4Tools-_Teaching_Large_Language_Model_to_Use.txt
peft/2103.10385-GPT_Understands,_Too.txt
peft/2204.04392-Contrastive_Demonstration_Tuning_for_Pre-trained_Language_Models.txt
peft/2309.01516-MULTIWAY-ADAPTER-_ADAPTING_MULTIMODAL_LARGE_LANGUAGE_MODELS_FOR.txt
peft/2309.17453-Published_as_a_conference_paper_at_ICLR_2024.txt
peft/2402.09353-DoRA-_Weight-Decomposed_Low-Rank_Adaptation.txt
peft/2306.00477-Make_Pre-trained_Model_Reversible.txt
peft/2403.06504-LoHan-_Lo_w-Cost_H_igh-Performan_ce_Framework_to.txt
peft/2305.15011-Bactrian-X-_Multilingual_Replicable_Instruction-Following_Models_with.txt
peft/2210.03265-Polyhistor-_Parameter-Efﬁcient_Multi-Task.txt
peft/2303.12314-Self-supervised_Meta-Prompt_Learning_with_Meta-Gradient_Regularization.txt
peft/2310.11670-Prototype-based_HyperAdapter_for_Sample-Efficient_Multi-task_Tuning.txt
peft/2311.00915-Task-Agnostic_Low-Rank_Adapters_for_Unseen_English_Dialects.txt
peft/2309.12307-Published_as_a_conference_paper_at_ICLR_2024.txt
peft/2306.01485-ROBUST_LOW_-RANK_TRAINING_VIA_APPROXIMATE.txt
peft/2212.03220-Visual_Query_Tuning-_Towards_Effective_Usage_of_Intermediate_Representations.txt
peft/2310.09753-When_can_transformers_reason_with_abstract_symbols.txt
peft/2309.14021-Preprint-_Work_in_Progress.txt
peft/2309.06922-Hydra-_Multi-head_Low-rank_Adaptation_for_Parameter_Efficient_Fine-tuning.txt
peft/2109.06762-Greenformer-_Factorization_Toolkit_for_Efﬁcient_Deep_Neural_Networks.txt
peft/2205.05638-Few-Shot_Parameter-Efﬁcient_Fine-Tuning_is_Better.txt
peft/2308.08285-Pre-training_with_Large_Language_Model-based_Document_Expansion.txt
peft/2406.07056-Effectively_Compress_KV_Heads_for_LLM.txt
peft/2106.04647-COMPACTER.txt
peft/2111.09839-Training_Neural_Networks_with_Fixed_Sparse_Masks.txt
peft/2308.14929-PREPRINT-_Accepted_at_the_41st_Conference_on_Machine_Learning_(ICML_2024)PREPRINT-_Accepted_at_the_4.txt
peft/2311.06243-Published_as_a_conference_paper_at_ICLR_2024.txt
peft/2106.09685-LORA-_L_OW-RANK_ADAPTATION_OF_LARGE_LAN.txt
peft/2305.05189-SUR-adapter-_Enhancing_Text-to-Image_Pre-trained_Diffusion.txt
peft/2209.07712-Continual_Learning_with_Dependency_Preserving_Hypernetworks.txt
peft/2312.14327-Parameter_Efficient_Tuning_Allows_Scalable_Personalization_of_LLMs_for.txt
peft/2210.12360-Prompt-Tuning_Can_Be_Much_Better_Than_Fine-Tuning_on_Cross-lingual.txt
peft/2205.12410-AdaMix-_Mixture-of-Adaptations_for_Parameter-efﬁcient_Model_Tuning.txt
peft/2307.03084-OpenDelta-_A_Plug-and-play_Library_for_Parameter-efficient.txt
peft/2405.20271-ETHER_-_Efficient_Finetuning_of_Large-Scale_Models_with_Hyperplane_Reflections.txt
peft/2310.00035-Preprint._Under_review.txt
peft/2307.06945-Published_as_a_conference_paper_at_ICLR_2024.txt
peft/2110.15343-Scatterbrain-_Unifying_Sparse_and_Low-rank_Attention.txt
peft/2309.06759-Scaled_Prompt-Tuning_for_Few-Shot_Natural_Language_Generation.txt
peft/2308.10462-Exploring_Parameter-Efficient_Fine-Tuning_Techniques_for.txt
peft/2108.10808-Greenformers-_Improving_Computation_and_Memory.txt
peft/2207.09074-Incremental_Task_Learning_with.txt
peft/2308.03303-Preprint.txt
peft/2205.11005-Parameter-Efﬁcient_Sparsity_for_Large_Language_Models_Fine-Tuning.txt
peft/2205.12148-Hyper-X-_A_Uniﬁed_Hypernetwork_for_Multi-Task_Multilingual_Transfer.txt
peft/2303.10070-A_Unified_Continual_Learning_Framework_with_General.txt
peft/2306.10480-JOURNAL_OF_LATEX_CLASS_FILES,_VOL._XX,_NO._XX,_DECEMBER_2022_1.txt
peft/2211.11363-AF_Adapter-_Continual_Pretraining_for_Building.txt
peft/2311.01981-ProSG-_Using_Prompt_Synthetic_Gradients_to_Alleviate_Prompt_Forgetting_of.txt
peft/2305.14314-QL_ORA-_Efficient_Finetuning_of_Quantized_LLMs.txt
peft/2405.17357-DoRA-_Enhancing_Parameter-Efficient_Fine-Tuning_with_Dynamic_Rank.txt
peft/2203.01104-Parameter-Efﬁcient_Mixture-of-Experts_Architecture.txt
peft/2405.16057-SPP-_Sparsity-Preserved_Parameter-Efficient_Fine-Tuning.txt
peft/2310.06927-Sparse_Fine-tuning_for_Inference_Acceleration.txt
peft/2305.17691-Plug-and-Play_Knowledge_Injection_for_Pre-trained_Language_Models.txt
peft/2306.02320-Exploring_the_Impact_of_Model_Scaling_on_Parameter-efficient_Tuning.txt
peft/2303.07910-Revisit_Parameter-Efﬁcient_Transfer_Learning-_A_Two-Stage_Paradigm.txt
peft/2310.18356-LoRAShear-_Efficient_Large_Language_Model_Structured_Pruning_and.txt
peft/2204.02292-Parameter-Efﬁcient_Neural_Reranking_for.txt
peft/2306.02947-Continual_Learning_with_Pretrained_Backbones.txt
peft/2106.04489-Parameter-efficient_Multi-task_Fine-tuning_for_Transformers.txt
peft/2203.12119-Visual_Prompt_Tuning.txt
peft/2308.07317-Platypus-_Quick,_Cheap,_and_Powerful.txt
peft/2406.02214-SLTrain-_a_sparse_plus_low-rank_approach.txt
peft/2301.11660-Probing_Out-of-Distribution_Robustness_of_Language_Models_with.txt
peft/2110.07560-Composable_Sparse_Fine-Tuning_for_Cross-Lingual_Transfer.txt
peft/2405.03003-Parameter-Efficient_Fine-Tuning_with_Discrete_Fourier_Transform.txt
peft/2405.12130-MoRA-_High-Rank_Updating_for_Parameter-Efficient_Fine-Tuning.txt
peft/2405.00732-LoRA_Land-_310_Fine-tuned_LLMs_that.txt
peft/2306.05067-Improving_Visual_Prompt_Tuning_for_Self-supervised_Vision_Transformers.txt
peft/2308.12043.txt
peft/2404.11916-SKELETON_-_A_New_Framework_for_Accelerating_Language_Models_via.txt
peft/2310.15539-Preprint.txt
peft/2405.19597-SVFT-_Parameter-Efficient_Fine-Tuning.txt
peft/2306.07664-Rethink_the_Effectiveness_of_Text_Data.txt
peft/2305.17660-Plug-and-Play_Document_Modules_for_Pre-trained_Models.txt
peft/2210.08823-Scaling_&_Shifting_Your_Features.txt
peft/2405.21050-SODA_-_Spectrum-Aware_Parameter-Efficient.txt
peft/2403.03507-GaLore-_Memory-Efficient_LLM_Training_by_Gradient_Low-Rank_Projection.txt
peft/2311.05556-Technical_Report.txt
peft/2304.12410-PEFT-Ref-_A_Modular_Reference_Architecture_and_Typology.txt
peft/2308.10252-LMTuner-_An_user-friendly_and_highly-integrable_Training_Framework.txt
peft/2311.09578-Tied-LoRA-_Enhancing_parameter_efficiency_of_LoRA_with_Weight_Tying.txt
peft/2305.11186-Compress,_Then_Prompt-_Improving_Accuracy-Efficiency.txt
peft/2304.14856-A_Unified_Generative_Retriever_for_Knowledge-Intensive.txt
peft/2310.20587-UNLEASHING_THE_POWER_OF_PRE-TRAINED_LANGUAGE.txt
peft/2310.12100-NON-INTRUSIVE_ADAPTATION.txt
peft/2405.17604-LORA-XS-_L_OW-RANK_ADAPTATION_WITH_EX.txt
peft/2303.08566-Sensitivity-Aware_Visual_Parameter-Efficient_Fine-Tuning.txt
peft/2402.12851-MoELoRA-_Contrastive_Learning_Guided_Mixture_of_Experts_on.txt
peft/2307.11386-CLR-_Channel-wise_Lightweight_Reprogramming_for_Continual_Learning.txt
peft/2308.11148-LLaMA-Reviewer-_Advancing_Code_Review.txt
peft/2104.07650-KnowPrompt-_Knowledge-aware_Prompt-tuning_with_Synergistic.txt
peft/2405.13952-Spectral_Adapter-_Fine-Tuning_in_Spectral_Space.txt
peft/2305.17223-Do_We_Really_Need_a_Large_Number_of_Visual_Prompts.txt
peft/2406.05678-SinkLoRA-_Enhanced_Efficiency_and_Chat_Capabilities.txt
peft/2310.16240-Mixture-of-Linguistic-Experts_Adapters_for_Improving_and_Interpreting.txt
peft/2406.00605-LongSkywork-_A_Training_Recipe_for_Efficiently_Extending_Context_Length.txt
peft/2311.02303-MFTC_ODER_-_BOOSTING_CODE_LLM_S_WITH_MULTITASK.txt
peft/2310.14152-Orthogonal_Subspace_Learning_for_Language_Model_Continual_Learning.txt
peft/2308.08469-Preprint_Notice.txt
peft/2311.03285-S-L_ORA-_S_ERVING_THOUSANDS_OF_CONCURRENT_LORA_A_DAPTERS.txt
peft/2310.04573-Can_pruning_make_Large_Language_Models_more.txt
peft/2306.14870-Composing_Parameter-Efficient_Modules_with.txt
peft/2304.14999-Published_at_the_Workshop_on_Understanding_Foundation_Models_at_ICLR_2023.txt
peft/2305.15265-Winner-Take-All_Column_Row_Sampling_for_Memory_Efficient.txt
peft/2308.02084-1.txt
peft/2309.08513-Noname_manuscript_No..txt
peft/2111.00160-DSEE-_Dually_Sparsity-embedded_Efficient_Tuning_of_Pre-trained.txt
peft/2211.03831-Multi-Head_Adapter_Routing.txt
peft/2310.10700-PELA-_Learning_Parameter-Efficient_Models_with_Low-Rank_Approximation.txt
peft/2307.05695-ReLoRA-_High-Rank_Training_Through.txt
peft/2311.12023-Published_as_a_conference_paper_at_ICLR_2024.txt
peft/2303.15822-One_Adapter_for_All_Programming_Languages.txt
peft/2307.08941-JOURNAL_OF_L_ATEX_CLASS_FILES,_VOL._14,_NO._8,_AUGUST_2021_1.txt
peft/2303.15647-Scaling_Down_to_Scale_Up-_A_Guide_to_Parameter-Efficient_Fine-Tuning.txt
peft/2311.11696-Sparse_Low-rank_Adaptation_of_Pre-trained_Language_Models.txt
peft/2205.01308-Contrastive_Learning_for_Prompt-Based_Few-Shot_Language_Learners.txt
peft/2305.18425-Efficient_Storage_of_Fine-Tuned_Models_via_Low-Rank.txt
peft/2401.02731-Parameter-Efficient_Sparsity_Crafting_from_Dense_to_Mixture-of-Experts.txt
peft/2305.15348-READ-_Recurrent_Adaptation_of_Large_Transformers.txt
peft/2304.05216-Towards_Efficient_Fine-tuning_of_Pre-trained_Code_Models.txt
peft/2309.05173-Published_as_a_conference_paper_at_ICLR_2024.txt
peft/2309.10400-Published_as_a_conference_paper_at_ICLR_2024.txt
peft/2305.06212-JOURNAL_OF_L_ATEX_CLASS_FILES,_VOL._14,_NO._8,_AUGUST_2021_1.txt
peft/2405.15179-VB-LoRA-_Extreme_Parameter_Efficient_Fine-Tuning.txt
peft/2405.15525-Sparse_Matrix_in_Large_Language_Model_Fine-tuning.txt
peft/2406.10785-ShareLoRA-_Parameter_Efficient_and_Robust_Large_Language_Model.txt
peft/2210.04457-XPROMPT_-_Exploring_the_Extreme_of_Prompt_Tuning.txt
peft/2303.16753-Scaling_Pre-trained_Language_Models_to_Deeper.txt
peft/2303.13635-1.txt
peft/2405.16325-SLOPE-_Double-Pruned_Sparse_Plus_Lazy_Low-Rank.txt
peft/2305.18169-LM-CPPF-_Paraphrasing-Guided_Data_Augmentation.txt
peft/2309.01479-Parameter_and_Computation_Efficient_Transfer.txt
peft/2111.01998-OpenPrompt-_An_Open-source_Framework_for_Prompt-learning.txt
peft/2306.04735-Using_Soft-Prompt_Tuning_to_Evaluate_Bias_in_Large_Language_Models.txt
peft/2304.13639-1.txt
peft/2310.08659-LoftQ-_LoRA-Fine-Tuning-Aware_Quantization_for_Large.txt
peft/2309.09958-arXiv-2309.09958v1_[cs.CV]_18_Sep_2023An_Empirical_Study_of_Scaling_Instruction-Tuned.txt
peft/2401.01335-Self-Play_Fine-Tuning_Converts_Weak_Language_Models_to_Strong_Language.txt
peft/2309.14763-1.txt

# 2210.04995.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/moe/2210.04995.pdf
# Kích thước tệp: 1088725 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
FEAMOE: Hỗn hợp Chuyên gia Công bằng, Giải thích được và Thích ứng
Shubham Sharma
Đại học Texas tại Austin
shubham_sharma@utexas.edu Jette Henderson
CognitiveScale
jhenderson@cognitivescale.com
Joydeep Ghosh
Đại học Texas tại Austin
jghosh@utexas.edu
Tóm tắt
Ba tính chất chủ chốt được mong muốn của các mô hình học máy đáng tin cậy được triển khai trong môi trường rủi ro cao là tính công bằng, khả năng giải thích và khả năng tính toán các dạng "drift" khác nhau. Trong khi drift trong độ chính xác mô hình, chẳng hạn do covariate shift, đã được nghiên cứu rộng rãi, drift trong các thước đo công bằng theo thời gian vẫn còn chưa được khám phá nhiều. Trong bài báo này, chúng tôi đề xuất FEAMOE, một framework "mixture-of-experts" mới nhằm học các mô hình công bằng hơn, có thể giải thích/diễn giải được và có thể điều chỉnh nhanh chóng theo drift cả về độ chính xác và tính công bằng của bộ phân loại. Chúng tôi minh họa framework cho ba thước đo công bằng phổ biến và chứng minh cách drift có thể được xử lý đối với các ràng buộc công bằng này. Thí nghiệm trên nhiều tập dữ liệu cho thấy framework của chúng tôi khi áp dụng cho mixture của các chuyên gia tuyến tính có thể thực hiện so sánh được với mạng neural về độ chính xác trong khi tạo ra các mô hình công bằng hơn. Sau đó chúng tôi sử dụng tập dữ liệu HMDA quy mô lớn và cho thấy rằng trong khi các mô hình khác nhau được huấn luyện trên HMDA thể hiện drift về cả độ chính xác và tính công bằng, FEAMOE có thể xử lý thành thạo các drift này đối với tất cả các thước đo công bằng được xem xét và duy trì độ chính xác mô hình. Chúng tôi cũng chứng minh rằng framework được đề xuất cho phép tạo ra các giải thích Shapley value nhanh, điều này làm cho các giải thích dựa trên attribution đặc trưng hiệu quả về mặt tính toán của các quyết định mô hình sẵn có thông qua FEAMOE.

1 Giới thiệu
Lĩnh vực trí tuệ nhân tạo có trách nhiệm có một số yêu cầu được thúc đẩy bởi các quy định như Quy định Bảo vệ Dữ liệu Chung [9]. Chúng bao gồm: đảm bảo rằng một mô hình AI không phân biệt đối xử và minh bạch; các cá nhân chịu quyết định của mô hình nên có quyền truy cập vào các giải thích chỉ ra con đường hướng tới biện pháp khắc phục; và các mô hình nên thích ứng với bất kỳ thay đổi nào trong đặc tính của dữ liệu sau khi triển khai để duy trì chất lượng và độ tin cậy của chúng.

Hầu hết các phương pháp giảm thiểu bất kỳ hình thức thiên vị nào đều giả định một bộ phân loại tĩnh. Một thực hành viên quyết định về một định nghĩa tính công bằng nào đó, huấn luyện một mô hình cố gắng thực thi khái niệm công bằng này và sau đó triển khai mô hình. Nhiều định nghĩa về tính công bằng dựa trên kết quả mô hình hoặc trên tỷ lệ lỗi (khoảng cách giữa tỷ lệ dương tính thực và/hoặc tỷ lệ dương tính giả) được liên kết với các nhóm phụ khác nhau được xác định bởi một thuộc tính được bảo vệ. Mục tiêu là giảm sự khác biệt giữa các tỷ lệ lỗi này giữa các nhóm phụ liên quan. Ví dụ, average odds difference [4] là một thước đo biểu thị equalized odds và được cho bởi tổng sự khác biệt trong cả tỷ lệ dương tính thực và tỷ lệ dương tính giả giữa hai nhóm, được chia tỷ lệ bởi hệ số 0.5. Equality of opportunity và demographic parity [3] cũng là các định nghĩa về tính công bằng phổ biến. Gần đây, tính công bằng về mặt khoảng cách recourse đã được đề xuất, trong đó recourse được định nghĩa là khả năng đạt được kết quả tích cực từ mô hình [34].

Mặc dù tính phù hợp của một thước đo công bằng phụ thuộc vào ứng dụng [26,3], demographic parity và equalized odds vẫn là những thước đo được sử dụng phổ biến nhất, và nhu cầu về tính công bằng dựa trên khoảng cách recourse đang ngày càng được công nhận [18].

Tuy nhiên, các mô hình tĩnh có thể gặp phải drift một khi được triển khai, vì các tính chất thống kê của dữ liệu thực thường thay đổi theo thời gian. Điều này có thể dẫn đến hiệu suất xấu đi. Model drift có thể xảy ra khi các tính chất của biến mục tiêu thay đổi (concept drift) hoặc khi phân phối dữ liệu đầu vào thay đổi, hoặc cả hai. Hiệu suất của các mô hình chủ yếu được đo lường thông qua các thước đo dựa trên độ chính xác như tỷ lệ phân loại sai, F-score hoặc AUC [37]. Tuy nhiên, một mô hình được huấn luyện trong quá khứ và được phát hiện là công bằng tại thời điểm huấn luyện có thể hoạt động không công bằng đối với dữ liệu hiện tại. Việc giải quyết drift đối với tính công bằng ngoài độ chính xác vẫn còn chưa được khám phá nhiều mặc dù đây là một khía cạnh quan trọng của AI đáng tin cậy trong thực tế.

Khả năng giải thích các kết quả mô hình riêng lẻ là một mối quan tâm chính khác đối với ML đáng tin cậy. Trong nhiều phương pháp giải thích về mặt attribution đặc trưng [6], phương pháp SHAP dựa trên Shapley values đặc biệt phổ biến vì nó có một số đảm bảo tiên đề [21]. Mặc dù tính toán SHAP values nhanh đối với các mô hình tuyến tính và dựa trên cây, nhưng có thể rất chậm đối với mạng neural và một số loại mô hình khác, đặc biệt khi dữ liệu có số lượng đặc trưng lớn hoặc khi cần số lượng lớn các giải thích [27]. Điều này tạo ra rào cản cho các triển khai đòi hỏi giải thích nhanh trong cài đặt sản xuất thời gian thực.

Trong bài báo này, chúng tôi giải quyết những mối quan tâm về tính công bằng, drift dữ liệu/mô hình và khả năng giải thích bằng cách đề xuất FEAMOE: Fair, Explainable and Adaptive Mixture of Experts, một mixture of experts (MOE) được phát triển tăng dần với các ràng buộc công bằng. Trong thiết lập mixture of experts tiêu chuẩn, mỗi chuyên gia là một mô hình học máy, và mạng gating cũng vậy. Mạng gating học để gán một trọng số phụ thuộc đầu vào gu(x) cho chuyên gia thứ u với đầu vào x, và đầu ra cuối cùng của mô hình là một kết hợp có trọng số của các đầu ra của mỗi chuyên gia. Do đó, mỗi chuyên gia đóng góp khác nhau cho mỗi điểm dữ liệu hướng tới kết quả cuối cùng, đây là một điểm khác biệt chính từ các ensemble tiêu chuẩn.

Nhiều loại MOE tồn tại trong tài liệu [40] - kiến trúc không chuẩn. Đối với FEAMOE, chúng tôi chọn họ này, với một số sửa đổi mới được mô tả sau, vì ba lý do chính: 1) Các phạt điều chỉnh phù hợp thúc đẩy tính công bằng có thể dễ dàng được kết hợp vào hàm mất mát. 2) Học trực tuyến là có thể, vì vậy các thay đổi trong dữ liệu có thể được theo dõi. Điều quan trọng, vì các thay đổi cục bộ trong phân phối dữ liệu sau khi triển khai có thể chỉ ảnh hưởng đến một hoặc một vài chuyên gia, các chuyên gia khác có thể không cần được điều chỉnh, làm cho các chuyên gia được cục bộ hóa và chỉ ghép nối lỏng lẻo. Điều này cho phép xử lý drift và tránh catastrophic forgetting, đây là một mối quan tâm chính trong các mô hình mạng neural được sử dụng rộng rãi [31]. 3) Các mô hình đơn giản hơn có thể được sử dụng để fit một vấn đề phức tạp hơn trong mixture of experts, vì mỗi mô hình chỉ cần fit tốt trong một phần giới hạn của không gian đầu vào. Cụ thể, ngay cả các mô hình tuyến tính, cung cấp các giải thích SHAP rất nhanh, có thể được sử dụng. Mixture of experts tổng thể, ngay cả với các mô hình cơ sở đơn giản như vậy ("chuyên gia") thường có sức mạnh dự đoán có thể so sánh với một mô hình phức tạp duy nhất như mạng neural, như được chỉ ra bởi các thí nghiệm của chúng tôi cũng như trong nhiều nghiên cứu trước đây [40].

Một ví dụ đồ chơi thúc đẩy tại sao FEAMOE là cần thiết và cách nó hoạt động được hiển thị trong Hình 1. Xem xét một bộ phân loại nhị phân tuyến tính (1a) có độ chính xác hoàn hảo. Các màu sắc đại diện cho nhãn sự thật cơ bản, và màu xanh lá cây là nhãn lớp tích cực (mong muốn). Các vòng tròn là nhóm được ưu tiên và các hình thoi là nhóm không được ưu tiên. Như có thể thấy trong hình, nhiều hình thoi hơn nhận được kết quả tiêu cực và nhiều vòng tròn hơn nhận được kết quả tích cực. Xem xét dữ liệu mới đến để dự đoán. Bộ phân loại này (1b) không chỉ phân loại sai các cá nhân mà còn cho nhiều cá nhân không được ưu tiên thực sự thuộc lớp tích cực một kết quả tiêu cực, do đó gây ra thiên vị đối với equalized odds. Có drift đối với độ chính xác và tính công bằng. Một mô hình phức tạp hơn (1c) như mạng neural, nếu được huấn luyện lại, có thể xử lý một số mối quan tâm này nhưng sẽ ít có thể giải thích được hơn.

FEAMOE có thể giải quyết những mối quan tâm bắt buộc này, như được hiển thị trong 1d. Được huấn luyện theo cách trực tuyến, một mô hình tuyến tính mới được thêm vào (tức là, một chuyên gia) một khi dữ liệu mới đến. Mạng gating quy định khu vực nào mỗi chuyên gia hoạt động (được hiển thị bởi màu xanh lam và màu hồng), và FEAMOE có thể thích ứng tự động đối với độ chính xác và tính công bằng. Framework động này cho phép mô hình tổng thể công bằng hơn, điều chỉnh theo drift, duy trì độ chính xác, đồng thời vẫn có thể giải thích được vì ranh giới quyết định là tuyến tính cục bộ.

2

--- TRANG 2 ---
(a) (b) (c) (d)
Hình 1: Một ví dụ đồ chơi chứng minh nhu cầu và việc sử dụng FEAMOE. Màu sắc của mỗi điểm dữ liệu tương ứng với nhãn lớp gốc. Các hình thoi đại diện cho nhóm không được ưu tiên và các vòng tròn đại diện cho nhóm được ưu tiên. (a) Đại diện cho một bộ phân loại tuyến tính hoàn toàn chính xác, (b) đại diện cho cùng một bộ phân loại phân loại sai các điểm dữ liệu mới và gây ra thiên vị (drift), (c) đại diện cho một mô hình phi tuyến thay thế sửa chữa drift nhưng có ranh giới quyết định phức tạp và (d) đại diện cho FEAMOE trong đó các vùng màu xanh lam và màu hồng hiển thị các vùng hoạt động cho mỗi chuyên gia trong số hai chuyên gia, được phân tách bởi mạng gating

Chúng tôi chỉ ra cách ba ràng buộc công bằng–demographic parity, equalized odds và burden-based fairness–có thể được kết hợp vào quy trình huấn luyện mixture of experts để khuyến khích fit các mô hình công bằng hơn (theo các thước đo này). Chúng tôi sử dụng ba thước đo công bằng phổ biến này như các ví dụ minh họa để chứng minh hiệu quả của FEAMOE, nhưng phương pháp của chúng tôi có thể được điều chỉnh để kết hợp các ràng buộc công bằng khác. Sau đó chúng tôi mô tả một thuật toán mới để huấn luyện để tính toán drift, trong đó drift được đề cập có thể là do độ chính xác hoặc tính công bằng. Chúng tôi chỉ ra bằng thí nghiệm rằng bằng cách sử dụng một tập hợp các chuyên gia hồi quy logistic, độ chính xác của mixture có thể so sánh với việc sử dụng một mô hình phức tạp như mạng neural. Ngoài ra, chúng tôi chỉ ra rằng chúng tôi có thể tính toán hiệu quả các giải thích Shapley value khi các giải thích cho mỗi chuyên gia riêng lẻ có thể được tính toán nhanh chóng. Theo hiểu biết của chúng tôi, đây là công trình đầu tiên giải quyết vấn đề drift đối với tính công bằng trong một tập dữ liệu thực tế quy mô lớn. Sau đó chúng tôi giới thiệu một framework có thể linh hoạt thích ứng với drift cả về tính công bằng và độ chính xác với lợi ích bổ sung là cung cấp giải thích nhanh chóng, đồng thời so sánh với lớp mô hình mạng neural ít có thể giải thích hơn được huấn luyện ở chế độ trực tuyến.

Các đóng góp chính của công trình này là: một framework mixture of experts có thể kết hợp nhiều ràng buộc công bằng, một phương pháp để xử lý drift, trong đó drift có thể đối với độ chính xác hoặc tính công bằng, bằng chứng thực nghiệm về sự hiện diện của drift đối với tính công bằng trong một tập dữ liệu thực tế quy mô lớn, một chứng minh lý thuyết rằng FEAMOE dẫn đến việc tạo ra các giải thích nhanh với lựa chọn phù hợp của các chuyên gia, và thí nghiệm rộng rãi trên ba tập dữ liệu để chỉ ra rằng phương pháp của chúng tôi có hiệu suất dự đoán tương tự như mạng neural trong khi công bằng hơn, xử lý các loại drift khác nhau và tạo ra giải thích nhanh hơn.

2 Công trình liên quan
Mixture of experts (MOE) [16,39] đại diện cho một lớp các mô hình ensemble hợp tác; các khảo sát chi tiết về thiết kế và sử dụng của chúng có thể được tìm thấy trong [40] và [25]. Rất gần đây, cộng đồng deep learning đã bắt đầu nhận ra và tận dụng một số tính chất thuận lợi mà MOE có để thiết kế hiệu quả các learner phức tạp, đa mục đích [30]. Bài báo này đóng góp vào tài liệu mở rộng này bằng cách đề xuất một thuật toán mới để huấn luyện lớp mô hình này để tính toán cả tính công bằng và drift, và bằng cách thêm một mô-đun khả năng giải thích.

Tính công bằng trong học máy là một lĩnh vực nghiên cứu đang phát triển [14]. Giảm thiểu thiên vị trong các mô hình có thể được thực hiện thông qua các kỹ thuật tiền xử lý, xử lý trong quá trình hoặc hậu xử lý. Mô tả về các kỹ thuật này có thể được tìm thấy trong [4]. Các kỹ thuật xử lý trong quá trình cho tính công bằng đã và đang được chú ý [41,26,34]. Tuy nhiên, có ít công trình về việc điều tra tính hữu ích của các mô hình ensemble trong việc xử lý thiên vị. [13] chỉ ra rằng một ensemble của các bộ phân loại công bằng được đảm bảo là công bằng cho một số thước đo tính công bằng khác nhau, một ensemble của các bộ phân loại không công bằng vẫn có thể đạt được kết quả công bằng, và một ensemble của các bộ phân loại có thể đạt được sự đánh đổi độ chính xác-tính công bằng tốt hơn so với một bộ phân loại đơn lẻ. Tuy nhiên, họ không cung cấp bằng chứng thực nghiệm cũng như không thảo luận về các phương pháp cụ thể để kết hợp tính công bằng vào việc học ensemble. [24] phát triển một phương pháp để học trì hoãn trong trường hợp dự đoán không công bằng. [5] sử dụng một framework AdaBoost để xây dựng một mô hình công bằng hơn. [28] sử dụng các bộ phân loại random forest thích ứng để tính toán tính công bằng trong học trực tuyến, chỉ xem xét định nghĩa statistical parity của tính công bằng.

Tính toán drift là một vấn đề được khám phá rộng rãi, và hiện đang xuất hiện trong các sản phẩm thương mại (ví dụ: giám sát mô hình là một phần quan trọng của MLOPs) khi các giải pháp ML được triển khai trong môi trường kinh doanh. Chi tiết về nhiều phương pháp như vậy có thể được tìm thấy trong [12,20]. Trong số các phương pháp này, phương pháp gần nhất với phương pháp của chúng tôi là [37] sử dụng một ủy ban các cây quyết định để tính toán drift. Tuy nhiên, đảm bảo tính công bằng trong sự hiện diện của drift vẫn còn là một vấn đề mở. [7] là một công trình rất gần đây về việc đạt được một mô hình công bằng hơn bằng cách xây dựng một tập hợp các bộ phân loại trong sự hiện diện của prior distribution shifts. Phương pháp được xây dựng cho một shift giữa các phân phối huấn luyện và kiểm tra, và không dành cho học trực tuyến.

Có nhiều cách để giải thích một mô hình học máy [8,27]. Trong bài báo này, chúng tôi tập trung vào các giải thích dựa trên Shapley values, được sử dụng rộng rãi trong các ứng dụng thực tế [6]. [22] đề xuất tính toán Shapley values cho tree ensembles, đây là một cách nhanh hơn để có được Shapley values so với phương pháp có thể áp dụng rộng rãi hơn, KernelShap [21]. Chúng tôi chỉ ra rằng trong FEAMOE, các giá trị Shap cho mô hình tổng thể chỉ là một kết hợp tuyến tính phụ thuộc dữ liệu của các giá trị từ các chuyên gia riêng lẻ. Do đó, phương pháp mixture không thêm bất kỳ độ phức tạp đáng kể nào vào việc tính toán điểm attribution đặc trưng.

3 Lý thuyết
Đầu tiên chúng tôi tóm tắt framework mixture of experts ban đầu và sau đó mô tả việc bổ sung các ràng buộc công bằng. Sau đó, chúng tôi giới thiệu thuật toán để phát hiện và giảm thiểu data drift khi dữ liệu đầu vào là tuần tự (học trực tuyến). Sau đó, chúng tôi chỉ ra cách sử dụng kiến trúc mixture of experts được đề xuất dẫn đến việc tính toán giải thích Shapley value nhanh hơn cho mô hình phi tuyến tổng thể.

Mixture of Experts (MoE) [16] là một kỹ thuật trong đó nhiều chuyên gia (learners) có thể được sử dụng để chia mềm không gian vấn đề thành các vùng. Một mạng gating quyết định chuyên gia nào được cân nặng nhất cho mỗi vùng đầu vào. Việc học do đó bao gồm những điều sau: 1) học các tham số của các learner riêng lẻ và 2) học các tham số của mạng gating. Cả mạng gating và mọi chuyên gia đều có quyền truy cập vào đầu vào x. Mạng gating có một đầu ra gi cho mỗi chuyên gia i. Vector đầu ra là trung bình có trọng số (bởi các đầu ra mạng gating) của các đầu ra chuyên gia: y(x) = Σm i=1 gi(x)yi(x). Phù hợp với [16], lỗi liên kết với việc huấn luyện mixture of experts cho trường hợp j cho một dự đoán chính xác được cho bởi: Ej acc = log Σi gj i e^{-1/2||dj-yj i||²}, trong đó yj i là vector đầu ra của chuyên gia i trên trường hợp j, gj i là đóng góp tỷ lệ của chuyên gia i vào vector đầu ra kết hợp, và dj là vector đầu ra mong muốn.

3.1 Ràng buộc Công bằng
Trong bài báo này, chúng tôi kết hợp ba định nghĩa công bằng đa dạng vào framework mixture of experts: demographic parity chỉ phụ thuộc vào kết quả mô hình, equalized odds được điều kiện hóa trên nhãn sự thật cơ bản, và burden-based fairness phụ thuộc vào khoảng cách của đầu vào đến ranh giới. Ba định nghĩa phổ biến này đã được chọn làm thước đo minh họa; phương pháp của chúng tôi có thể dễ dàng mở rộng cho một số thước đo công bằng khác.

Để đơn giản, chúng tôi xem xét một thiết lập phân loại nhị phân với một thuộc tính được bảo vệ nhị phân (phương pháp của chúng tôi dễ dàng mở rộng cho các vấn đề đa lớp và đa thuộc tính được bảo vệ, trong đó thuộc tính được bảo vệ là một đặc trưng như chủng tộc hoặc giới tính). Để yj i = 1 là kết quả tích cực. Để A = 0 và A = 1 đại diện cho các nhóm thuộc tính được bảo vệ không được ưu tiên và được ưu tiên, tương ứng. Đối với một tập dữ liệu D cho trước, để Dad đại diện cho tất cả các cá nhân thuộc nhóm thuộc tính được bảo vệ a và nhãn lớp gốc d.

Statistical parity difference (SPD), là một thước đo của demographic parity, đo lường sự khác biệt giữa xác suất có được kết quả tích cực giữa các nhóm thuộc tính được bảo vệ [4,35]. Để D0 là tập hợp các cá nhân trong nhóm không được ưu tiên và D1 là tập hợp các cá nhân trong nhóm được ưu tiên. Lấy cảm hứng từ [36], phạt liên kết cho demographic parity cho trường hợp j là: Ej SPD = 1[j∈D0](1-Σi giyj i) + 1[j∈D1](Σi giyj i). Ý tưởng đằng sau thuật ngữ này là các cá nhân thuộc nhóm không được ưu tiên được dự đoán là nhận được kết quả tiêu cực sẽ được

4

--- TRANG 3 ---
Thuật toán 1 Học FEAMOE
Đầu vào: dữ liệu X, nhãn Y
Siêu tham số: k, λ₁, λ₂, λ₃
s = 1
# Chọn k điểm {x}ᵏₗ₌₁ từ X
X⁽ˢ⁾ = X \ {x}ᵏₗ₌₁
# Học chuyên gia đầu tiên, m_s
# Khởi tạo w_s, trọng số của m_s
for j in {1, ..., k} do
    # Thực hiện các bước gradient để tối thiểu hóa mất mát MoE:
    w_s^j = w_s^{j-1} - η∇E_acc^j
end for
λ₁ = 0; λ₂ = 0, và λ₃ = 0
while X⁽ˢ⁾ không rỗng do
    s += 1
    λ₁ = λ₁ + δ₁; λ₂ = λ₂ + δ₂; λ₃ = λ₃ + δ₃
    # Chọn k điểm {x}ᵏₗ₌₁ từ X⁽ˢ⁾
    X⁽ˢ⁾ = X⁽ˢ⁾ \ {x}ᵏₗ₌₁
    # Học chuyên gia tiếp theo, m_s
    Khởi tạo w_s
    for j in {1, ..., s×k} do
        # Thực hiện các bước gradient để tối thiểu hóa Phương trình 1
        for l in {1, ..., s} do
            w_s^j = w_s^{j-1} - η∇[E_acc^j + λ₁∇E_SPD^j + λ₂∇E_AOD^j + λ₃∇E_Burden^j]
        end for
    end for
end while

được gán phạt cao hơn. Tương tự, các cá nhân thuộc nhóm được ưu tiên được dự đoán có kết quả tích cực được gán phạt cao hơn, do đó khuyến khích giá trị SPD gần bằng không.

Average odds difference (AOD), là một thước đo của equalized odds, đo lường sự khác biệt trong tỷ lệ true và false giữa các nhóm thuộc tính được bảo vệ. Chi tiết về thước đo có thể được tìm thấy trong [4,35]. Phạt liên kết cho equalized odds là:

E_AOD^j = 1[j∈D₀₁](1-Σᵢgᵢyᵢʲ) + 1[j∈D₁₁](1-Σᵢgᵢyᵢʲ) + 1[j∈D₁₀](Σᵢgᵢyᵢʲ) + 1[j∈D₀₀](Σᵢgᵢyᵢʲ)

Thuật ngữ này khuyến khích các khoảng cách tỷ lệ dương tính true và false giữa các nhóm giảm bằng cách điều kiện hóa hàm chỉ thị trên nhãn sự thật cơ bản ngoài thuộc tính được bảo vệ (như trong công thức demographic parity).

Burden cho một nhóm thuộc tính được bảo vệ là một thước đo khả năng có được recourse cho các cá nhân trong nhóm đó. Như được chỉ ra trong [34], burden-based fairness có thể được tính toán như: Burden = |E_x|A=0[d(x,B)] - E_x|A=1[d(x,B)]|, trong đó d(x,B) đại diện cho khoảng cách đến ranh giới cho một x cho trước được phân loại là thuộc lớp tiêu cực. Sau đó, phạt liên kết cho burden based fairness là: E_Burden^j = |E_x|A=0[d(x,B)] - E_x|A=1[d(x,B)]|.

Mất mát tổng thể cho trường hợp j sau đó được cho bởi:
E_MOE^j = E_acc^j + λ₁E_SPD^j + λ₂E_AOD^j + λ₃E_Burden^j                    (1)

3.2 Data Drift và thuật toán FEAMOE
Data Drift có nghĩa là các tính chất thống kê của dữ liệu, được thể hiện trong phân phối joint cơ bản của các biến độc lập và phụ thuộc, có thể thay đổi theo thời gian, thường theo những cách không lường trước được. Sự thay đổi có thể là trong class priors, các phân phối có điều kiện lớp (concept drift), trong phân phối của các biến độc lập, v.v. Drift có thể khiến mô hình trở nên ít chính xác hơn theo thời gian. Tuy nhiên, drift cũng có thể khiến các tính chất khác liên kết với mô hình thay đổi, chẳng hạn như tính công bằng.

Chúng tôi phát triển một thuật toán có thể xử lý drift đối với cả độ chính xác và tính công bằng.

5

--- TRANG 4 ---
Xem xét một thiết lập học trực tuyến trong đó các điểm dữ liệu đầu vào được quan sát tuần tự. Thuật toán để học FEAMOE (Thuật toán 1) như sau: bắt đầu với một mô hình đơn lẻ. Bắt đầu huấn luyện với các điểm dữ liệu (sử dụng stochastic gradient descent) và huấn luyện mô hình hiện tại cho một số điểm dữ liệu k nhất định chỉ sử dụng E_acc (phương trình 2). Sau k điểm, giới thiệu một mô hình hồi quy logistic mới và huấn luyện mixture of experts với hàm gating softmax sử dụng mất mát trong Phương trình 1. Đồng thời, giới thiệu các phạt công bằng. Sau đó, tiếp tục huấn luyện cho k điểm tiếp theo, và sau đó thêm một chuyên gia khác. Khi nhiều chuyên gia được thêm vào, dần dần tăng các siêu tham số (giá trị λ) liên kết với ba mất mát công bằng. Quá trình này được tiếp tục cho đến khi tất cả dữ liệu có sẵn được nhìn thấy.

Động lực đằng sau lược đồ huấn luyện này là hai mặt: bằng cách bắt đầu với phạt độ chính xác cho chuyên gia đầu tiên, chúng tôi đảm bảo rằng các thước đo công bằng không can thiệp vào việc huấn luyện một bộ phân loại chính xác, vì trọng số cao trên các thuật ngữ công bằng sẽ dẫn đến một bộ phân loại ít chính xác hơn (như được hiển thị trong các thí nghiệm). Sau đó, chúng tôi từ từ tăng trọng số trên các phạt công bằng với mục tiêu rằng đối với các cá nhân được phân loại không công bằng đối với các thước đo công bằng nhóm này, một chuyên gia khác sẽ tiếp quản trong chế độ dữ liệu này để huấn luyện cho những cá nhân này theo thời gian. Điều này là do framework mixture of experts cho phép một số hoặc tất cả các chuyên gia học trên các vùng dữ liệu khác nhau. Thứ hai, thuật toán cho phép chúng tôi tính toán drift, cả đối với độ chính xác của bộ phân loại và tính công bằng, vì framework của chúng tôi cho phép các ràng buộc công bằng. Nếu có sự thay đổi trong các tính chất thống kê của dữ liệu ảnh hưởng đến bất kỳ thuật ngữ mất mát nào, mixture of experts thích ứng với sự thay đổi này theo thời gian thông qua việc bổ sung các chuyên gia.

3.3 Giải thích Shapley value nhanh
Một lớp phương pháp attribution đặc trưng nổi bật dựa trên Shapley values từ lý thuyết game hợp tác [33]. Chi tiết về giải thích Shapley value có thể được tìm thấy trong [23], [38], và [1]. Trong khi tính toán Shapley values cho một mô hình tuyến tính là nhanh, việc làm như vậy cho các mô hình phi tuyến với các phương pháp như KernelShap [21] đòi hỏi các phép tính gần đúng và các phương pháp khiến tính toán tổng thể trở nên chậm [27,1]. Một phương pháp khác, TreeShap, [22] chỉ hoạt động cho các mô hình cây. Mặc dù mô hình mixture of experts được đề xuất là phi tuyến, vì các chuyên gia riêng lẻ là tuyến tính, định lý bên dưới chỉ ra cách tính toán chúng cho toàn bộ mô hình một cách nhanh chóng và hiệu quả.

Xem xét một mô hình mixture of experts với m chuyên gia. Để φ_j(m(x)) là Shapley value liên kết với chuyên gia m cho đặc trưng j cho một instance đầu vào x.

Định lý 1 Đối với một mô hình mixture of experts, Shapley value cho một instance x cho trước và đặc trưng j cho dự đoán mô hình được cho bởi:

φ_j(y(x)) = Σ^m_{i=1} g_i(x)φ_j(m(x))                    (2)

Chứng minh được cung cấp trong phụ lục. Kết quả này cho thấy rằng Shapley value cho một đặc trưng và instance đầu vào cho trước cho mixture của các chuyên gia tuyến tính là một kết hợp tuyến tính của Shapley values của đặc trưng và instance đầu vào đó từ mọi chuyên gia, được cân bằng bởi trọng số được gán của mạng gating cho đầu vào đó. Điều này có nghĩa là miễn là các giá trị Shap cho các mô hình riêng lẻ có thể được tính toán nhanh chóng (như trường hợp đối với hồi quy tuyến tính/logistic, cây quyết định, XGBoost), việc tính toán Shap ở cấp độ hệ thống FEAMOE cũng rất nhanh. Trong bài báo này, chúng tôi minh họa FEAMOE sử dụng các chuyên gia hồi quy logistic, do đó tính chất mong muốn này được giữ, mặc dù mô hình mixture có thể xây dựng các mô hình phi tuyến có độ phức tạp tùy ý bằng cách bao gồm càng nhiều chuyên gia dựa trên hồi quy logistic càng cần thiết.

4 Thí nghiệm và Kết quả
Thí nghiệm được thực hiện bằng cách sử dụng mixture of experts với các chuyên gia hồi quy logistic và một hàm gating softmax. Chúng tôi triển khai các mô hình hồi quy logistic bằng scikit learn với các tham số mặc định. Chúng tôi chỉ ra rằng việc sử dụng các chuyên gia hồi quy logistic trong MOE tạo ra độ chính xác tương tự như việc sử dụng các mạng neural có kích thước phù hợp trong khi cho phép tạo ra giải thích nhanh hơn. Tất cả các mạng neural đều là multilayer perceptrons. Có hai tập hợp thí nghiệm, làm nổi bật các khía cạnh khác nhau của FEAMOE:

(a) Nghiên cứu Công bằng. Chúng tôi sử dụng hai tập dữ liệu phân loại thể hiện thiên vị và, mặc dù có một số

6

--- TRANG 5 ---
Bảng 1: Tên của các mô hình được so sánh trong hình 2, dựa trên lớp mô hình (Mixture of Experts (MOE) hoặc Neural Network (NN)) và loại ràng buộc công bằng (None, SPD, AOD, Burden, hoặc all). Thí nghiệm trên các mô hình được đánh dấu x nằm trong phụ lục

Loại         None      SPD        AOD        Burden     All
MOE          MOE       FEAMOE1    FEAMOE2    FEAMOE3    FEAMOE
NN           NN        x          x          x          FairNN

(a) (b)
(c) (d)

Hình 2: Kết quả cho UCI Adult Dataset trên các ràng buộc công bằng khác nhau được kết hợp. Chi tiết về tên mô hình được cung cấp trong Bảng 1. Độ chính xác càng cao càng tốt và thiên vị càng thấp càng tốt

vấn đề đã biết [11], được nghiên cứu rất kỹ trong cộng đồng công bằng: UCI Adult [19] và COMPAS [29]. Lưu ý rằng các tập dữ liệu này không vốn dĩ là streaming; vì vậy chúng chỉ được sử dụng cho các nghiên cứu công bằng thay vì để xử lý drift. Giới tính được coi là thuộc tính được bảo vệ cho UCI Adult. Một multilayer perceptron hai lớp với 30 hidden units trong mỗi lớp được huấn luyện cho tập dữ liệu UCI Adult. Các lớp ẩn bổ sung hoặc lớn hơn, hoặc các phương pháp ensemble như xgboost không cung cấp lợi ích bổ sung cho hai tập dữ liệu dạng bảng này, và do đó được bỏ qua cho mục đích so sánh. Thí nghiệm trên tập dữ liệu COMPAS nằm trong phụ lục.

(b) Nghiên cứu Drift. Tập dữ liệu HMDA (Home Mortgage Disclosure Act) lớn [15] phản ánh dữ liệu từ nhiều năm, với thống kê dữ liệu cơ bản thay đổi đáng kể qua các năm, vì vậy nó phù hợp cho các nghiên cứu drift. Giới tính là thuộc tính được bảo vệ. Một multilayer perceptron năm lớp với 50 hidden units trong mỗi lớp được huấn luyện cho tập dữ liệu HMDA làm mạng neural cơ sở. Thí nghiệm trên phiên bản streaming tổng hợp của tập dữ liệu UCI Adult nằm trong phụ lục. Trình tự dữ liệu cho huấn luyện được mô tả sau; bây giờ chúng tôi đề cập rằng các kỹ thuật batch (ví dụ: các mô hình dựa trên cây tiêu chuẩn), bao gồm các kỹ thuật ensemble phổ biến, thực hiện nhiều lần truyền qua dữ liệu được lấy mẫu từ toàn bộ khoảng thời gian, không thể được triển khai vì chúng tôi đang nghiên cứu các hiệu ứng của drift theo thời gian.

Đầu tiên, chúng tôi sử dụng UCI Adult để chứng minh các hiệu ứng của việc kết hợp các ràng buộc công bằng được đề xuất vào các mô hình mixture of experts. Kết quả tương tự cho tập dữ liệu COMPAS được cung cấp trong phụ lục. Sau đó chúng tôi chỉ ra rằng tập dữ liệu HMDA chứng minh drift đối với cả tính công bằng và độ chính xác, và FEAMOE có thể thích ứng với những drift như vậy. So sánh được thực hiện với mạng neural (cả có và không có ràng buộc công bằng), đây là lớp mô hình hiện đại nhất để hiệu suất dựa trên độ chính xác trên các tập dữ liệu này trong tất cả các thí nghiệm. Thí nghiệm về giải thích Shapley value nhanh hơn nằm trong phụ lục.

7

--- TRANG 6 ---
(a) (b)
(c) (d)

Hình 3: So sánh Xử lý Drift trên tập dữ liệu HMDA. Giá trị thiên vị thấp hơn thì tốt hơn. Kết quả với thanh lỗi (được loại trừ ở đây để dễ đọc) được cung cấp trong phụ lục. 1) Xanh: mạng neural cơ sở (mạng neural cố định) được huấn luyện không có ràng buộc công bằng trên một năm trước (20XX, được chỉ ra bởi trục x; 2016 và 2017 là những năm "tương lai") và không được cập nhật với dữ liệu mới; 2) Cam: mạng neural có thể huấn luyện (và công bằng): Mạng neural với ràng buộc công bằng được kết hợp; cũng được cập nhật với dữ liệu streaming từ những năm "tương lai" và 3) Xanh lá: FEAMOE, cũng cập nhật với một lần truyền qua dữ liệu streaming từ những năm "tương lai". Lưu ý rằng một số mô hình phổ biến (bao gồm ensemble như XGBoost) không được xem xét vì theo mặc định chúng sẽ cần thực hiện nhiều lần truyền qua tập dữ liệu và thực sự không được thiết kế cho các ứng dụng streaming (nhìn một lần).

4.1 Ràng buộc Công bằng
Thí nghiệm được thực hiện trên UCI Adult trong bảy chế độ khác nhau dựa trên loại mô hình và ràng buộc công bằng. Chi tiết về các chế độ này có trong Bảng 1. Chúng tôi sử dụng thuật toán huấn luyện của chúng tôi sao cho các chuyên gia được thêm vào sau mỗi 4000 điểm dữ liệu cho tập dữ liệu UCI Adult. Siêu tham số liên kết với các ràng buộc công bằng được tăng theo mức 0.02 cho mỗi chuyên gia cho tập dữ liệu UCI Adult. Các tham số được tìm thấy bằng cách sử dụng grid search và thay đổi dựa trên kích thước tập dữ liệu và mức độ thiên vị phổ biến (chi tiết trong phụ lục). Kết quả được tính trung bình trên năm lần chạy. Chúng tôi báo cáo độ chính xác và giá trị tuyệt đối của ba thước đo công bằng (để thống nhất trong việc diễn giải kết quả trên các thước đo công bằng). Chúng tôi cung cấp so sánh với các phương pháp khác để giảm thiểu thiên vị [10, 34, 2] trong phụ lục.

Kết quả được hiển thị trong Hình 2. Độ chính xác trên các loại mô hình khác nhau vẫn tương tự cho tập dữ liệu UCI Adult, nhưng việc chỉ sử dụng mạng neural với ràng buộc công bằng hoạt động kém, như được hiển thị trong Hình 2a. Như thấy trong 2b,c,d, các thước đo công bằng cũng hoạt động tốt ngay cả khi tách biệt với nhau. Tức là, trong việc cố gắng cải thiện dựa trên chỉ một thước đo, các thước đo khác cũng cải thiện. Về mặt này, thước đo burden-based fairness (FEAMOE3) có hiệu ứng tốt nhất; chỉ sử dụng burden-based fairness một mình giúp cải thiện đáng kể các thước đo công bằng khác trong khi duy trì độ chính xác hợp lý. Hành vi này phù hợp với quan sát trong [34]. Mạng neural công bằng (FairNN) thực hiện tệ hơn cho demographic parity và equalized odds so với FEAMOE. Chúng tôi giả thuyết rằng điều này xảy ra bởi vì quy trình học của chúng tôi từ từ gây ra tính công bằng với mỗi chuyên gia, trái ngược với việc huấn luyện toàn bộ kiến trúc trong một lần. Nhìn chung, FEAMOE giảm đáng kể cả ba hình thức thiên vị trong khi duy trì độ chính xác.

8

--- TRANG 7 ---
4.2 Drift Thực tế: Tập dữ liệu HMDA
Đầu tiên chúng tôi chứng minh rằng tập dữ liệu HMDA thể hiện drift qua các năm, và sau đó chỉ ra hiệu quả của FEAMOE trong việc xử lý nó. Tập dữ liệu HMDA có hàng triệu bản ghi của các cá nhân trải dài nhiều năm. Nó chứa các đặc điểm của người tiêu dùng; biến mục tiêu chỉ ra liệu người tiêu dùng có nhận được thế chấp hay không. Mặc dù tập dữ liệu này được coi là một tổng thể trước đây đã được chỉ ra thể hiện thiên vị, không có điều tra nào về cách thiên vị như vậy thay đổi qua các năm. Đầu tiên, để định lượng drift trong tập dữ liệu này cả về tính công bằng và độ chính xác, chúng tôi huấn luyện một mạng neural cho mỗi năm từ 2007 đến 2017, mỗi mạng trên 100,000 mẫu ngẫu nhiên trong năm đó, và kiểm tra mỗi mạng này trên dữ liệu từ các năm 2016-2017 (Khi đã được huấn luyện, các mô hình này, mà chúng tôi gọi là mạng neural cố định, không thể được cập nhật). Kết quả được hiển thị trong Hình 7 bởi các điểm màu xanh. Nói chung, càng xa dữ liệu huấn luyện từ năm kiểm tra thì các thước đo độ chính xác và tính công bằng càng xấu đi (tức là độ chính xác giảm và sự khác biệt về tính công bằng tăng). Ngoài ra, việc huấn luyện một mô hình đơn lẻ trên một tập dữ liệu cùng kích thước nhưng được lấy mẫu đồng nhất trong tất cả các năm trước đó cũng không giúp ích gì vì dữ liệu là không dừng. Theo hiểu biết của chúng tôi, đây là nghiên cứu chi tiết nhất về drift tính công bằng theo thời gian, được thực hiện trên một tập dữ liệu thực tế quy mô lớn có thể truy cập công khai.

Bây giờ chúng tôi nghiên cứu cách các mạng neural nhận biết tính công bằng với cập nhật trực tuyến so sánh với FEAMOE trong khả năng xử lý drift của chúng. Lưu ý rằng đối với cài đặt của chúng tôi, chúng tôi không thể sử dụng một số mô hình như các phương pháp ensemble phổ biến (XGBoost, v.v.), cần nhiều lần truyền qua dữ liệu mới ở chế độ batch sau khi mô hình ban đầu được xây dựng và triển khai. Đối với FEAMOE, chúng tôi huấn luyện các mô hình cho mỗi năm riêng biệt và coi mỗi mô hình đó là một chuyên gia. Sau đó, chúng tôi thêm vào các chuyên gia dựa trên một lần truyền qua dữ liệu mới (từ các năm 2016-2017). Chúng tôi so sánh điều này với mạng neural (với ràng buộc công bằng) cũng được huấn luyện trên mỗi năm trong quá khứ ở chế độ batch, và sau đó được cập nhật trực tuyến với một lần truyền qua dữ liệu mới. Kết quả FEAMOE được hiển thị trong Hình 7 bởi các điểm màu xanh lá, và kết quả mạng neural có thể huấn luyện bởi các điểm màu cam. FEAMOE đáng chú ý tốt hơn trong việc duy trì độ chính xác tốt và giữ thiên vị thấp hơn trên tất cả các thước đo thiên vị, khá nhiều bất kể mô hình gốc cũ như thế nào, ngay cả khi so sánh với mạng neural thích ứng. Chúng tôi tin rằng kiến trúc kết hợp lỏng lẻo và độ phức tạp mô hình thích ứng là chìa khóa cho sự thành công của FEAMOE trong việc xử lý drift. Cũng đáng chú ý rằng việc sử dụng kiến trúc FEAMOE cung cấp giải thích Shapley value nhanh hơn nhiều so với mạng neural có thể huấn luyện (như được hiển thị trong các thí nghiệm trong tài liệu bổ sung).

4.3 Thí nghiệm và Phát hiện Bổ sung
Chúng tôi đã thực hiện một số thí nghiệm khác để xác nhận hiệu quả của việc sử dụng FEAMOE. Chúng tôi tóm tắt các phát hiện ở đây; chi tiết hơn có trong phụ lục. Bất kể kích thước tập dữ liệu, việc sử dụng mạng neural làm chuyên gia thay vì chuyên gia hồi quy logistic trong mixture có hiệu ứng không đáng kể đối với độ chính xác. Chúng tôi cũng thử các biến thể của phương pháp học được đề xuất, chẳng hạn như giới thiệu chuyên gia dựa trên bão hòa hiệu suất dựa trên tính công bằng riêng lẻ thay vì thêm chuyên gia vào các khoảng thời gian (được xác định trước) đều đặn, đạt được hiệu suất tốt. Có nhiều chuyên gia hơn với một mức tăng nhỏ hơn về ràng buộc công bằng cũng được xem xét và dẫn đến hiệu suất tương tự như có ít chuyên gia hơn với mức tăng được điều chỉnh về siêu tham số công bằng trên các tập dữ liệu. Chi tiết hơn về siêu tham số cũng có thể được tìm thấy trong phụ lục. Thí nghiệm về giải thích Shapley value nhanh có trong phụ lục. Ngoài ra, thí nghiệm về tập dữ liệu COMPAS cho nghiên cứu công bằng, và trên phiên bản streaming tổng hợp của tập dữ liệu UCI Adult cho nghiên cứu drift có thể được tìm thấy trong phụ lục.

5 Kết luận và Công việc Tương lai
Chúng tôi đề xuất FEAMOE: một kiến trúc và framework học mixture of experts mới có thể duy trì tốt hơn tính công bằng của mô hình trước data drift. Chúng tôi chỉ ra cách ba ràng buộc công bằng có thể được kết hợp vào framework này. Những ràng buộc này mang tính minh họa, vì người ta có thể sử dụng các ràng buộc thay thế thay vào đó. Chúng tôi chứng minh rằng bằng cách sử dụng mixture of experts này, giải thích Shapley value có thể được tính toán hiệu quả ngay cả khi mô hình tổng thể là phi tuyến. Thí nghiệm được thực hiện trên ba tập dữ liệu để chứng minh các tính chất và hiệu quả khác nhau của FEAMOE. Đặc biệt, chúng tôi đã xác định một tập dữ liệu thực tế quy mô lớn gây ra drift đối với tính công bằng theo thời gian trong các mô hình không thích ứng, và chỉ ra rằng framework của chúng tôi có thể giải quyết thỏa đáng thách thức này. Với tính hữu ích của công thức FEAMOE, chúng tôi bây giờ muốn mở rộng nó để kết hợp các dạng drift tiềm năng khác, chẳng hạn như những dạng gây ra thay đổi trong tính mạnh mẽ đối nghịch.

9

--- TRANG 8 ---
Tài liệu tham khảo
[1] Kjersti Aas, Martin Jullum, và Anders Løland. 2019. Explaining individual predictions when features are dependent: More accurate approximations to Shapley values. arXiv preprint arXiv:1903.10464 (2019).

[2] Alekh Agarwal, Alina Beygelzimer, Miroslav Dudík, John Langford, và Hanna Wallach. 2018. A reductions approach to fair classification. arXiv preprint arXiv:1803.02453 (2018).

[3] Solon Barocas, Moritz Hardt, và Arvind Narayanan. 2018. Fairness and Machine Learning. fairmlbook.org. http://www.fairmlbook.org.

[4] Rachel KE Bellamy, Kuntal Dey, Michael Hind, Samuel C Hoffman, Stephanie Houde, Kalapriya Kannan, Pranay Lohia, Jacquelyn Martino, Sameep Mehta, Aleksandra Mojsilovic, et al. 2018. AI fairness 360: An extensible toolkit for detecting, understanding, and mitigating unwanted algorithmic bias. arXiv preprint arXiv:1810.01943 (2018).

[5] Dheeraj Bhaskaruni, Hui Hu, và Chao Lan. 2019. Improving Prediction Fairness via Model Ensemble. In 2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI). IEEE, 1810–1814.

[6] Umang Bhatt, Alice Xiang, Shubham Sharma, Adrian Weller, Ankur Taly, Yunhan Jia, Joydeep Ghosh, Ruchir Puri, José MF Moura, và Peter Eckersley. 2020. Explainable machine learning in deployment. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. 648–657.

[7] Arpita Biswas và Suvam Mukherjee. 2020. Ensuring Fairness under Prior Probability Shifts. arXiv preprint arXiv:2005.03474 (2020).

[8] Nadia Burkart và Marco F Huber. 2021. A survey on the explainability of supervised machine learning. Journal of Artificial Intelligence Research 70 (2021), 245–317.

[9] Michael Butterworth. 2018. The ICO and artificial intelligence: The role of fairness in the GDPR framework. Computer Law & Security Review 34, 2 (2018), 257–268.

[10] Flavio Calmon, Dennis Wei, Bhanukiran Vinzamuri, Karthikeyan Natesan Ramamurthy, và Kush R Varshney. 2017. Optimized pre-processing for discrimination prevention. In Advances in Neural Information Processing Systems. 3992–4001.

[11] Frances Ding, Moritz Hardt, John Miller, và Ludwig Schmidt. 2021. Retiring adult: New datasets for fair machine learning. Advances in Neural Information Processing Systems 34 (2021).

[12] João Gama, Indrė Žliobaitė, Albert Bifet, Mykola Pechenizkiy, và Abdelhamid Bouchachia. 2014. A survey on concept drift adaptation. ACM computing surveys (CSUR) 46, 4 (2014), 1–37.

[13] Nina Grgić-Hlača, Muhammad Bilal Zafar, Krishna P Gummadi, và Adrian Weller. 2017. On fairness, diversity and randomness in algorithmic decision making. arXiv preprint arXiv:1706.10208 (2017).

[14] Philipp Hacker. 2018. Teaching fairness to artificial intelligence: Existing and novel strategies against algorithmic discrimination under EU law. Common Market Law Review 55, 4 (2018), 1143–1185.

[15] HMDA. [n. d.]. HMDA dataset. https://www.consumerfinance.gov/data-research/hmda/historic-data ([n. d.]).

[16] Robert A Jacobs, Michael I Jordan, Steven J Nowlan, và Geoffrey E Hinton. 1991. Adaptive mixtures of local experts. Neural computation 3, 1 (1991), 79–87.

[17] Toshihiro Kamishima, Shotaro Akaho, Hideki Asoh, và Jun Sakuma. 2012. Fairness-aware classifier with prejudice remover regularizer. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 35–50.

10

--- TRANG 9 ---
[18] Amir-Hossein Karimi, Gilles Barthe, Bernhard Schölkopf, và Isabel Valera. 2020. A survey of algorithmic recourse: definitions, formulations, solutions, and prospects. arXiv preprint arXiv:2010.04050 (2020).

[19] Ron Kohavi. 1996. Scaling up the accuracy of naive-bayes classifiers: A decision-tree hybrid.. In Kdd, Vol. 96. Citeseer, 202–207.

[20] Jie Lu, Anjin Liu, Fan Dong, Feng Gu, Joao Gama, và Guangquan Zhang. 2018. Learning under concept drift: A review. IEEE Transactions on Knowledge and Data Engineering 31, 12 (2018), 2346–2363.

[21] Scott Lundberg và Su-In Lee. 2017. A unified approach to interpreting model predictions. arXiv preprint arXiv:1705.07874 (2017).

[22] Scott M Lundberg, Gabriel G Erion, và Su-In Lee. 2018. Consistent individualized feature attribution for tree ensembles. arXiv preprint arXiv:1802.03888 (2018).

[23] Scott M Lundberg và Su-In Lee. 2017. A Unified Approach to Interpreting Model Predictions. In Advances in Neural Information Processing Systems 30 (NeurIPS 2017), I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, và R. Garnett (Eds.). Curran Associates, Inc., 4765–4774.

[24] David Madras, Toniann Pitassi, và Richard Zemel. 2017. Predict responsibly: improving fairness and accuracy by learning to defer. arXiv preprint arXiv:1711.06664 (2017).

[25] Saeed Masoudnia và Reza Ebrahimpour. 2014. Mixture of experts: a literature survey. Artificial Intelligence Review 42, 2 (2014), 275–293.

[26] Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, và Aram Galstyan. 2019. A survey on bias and fairness in machine learning. arXiv preprint arXiv:1908.09635 (2019).

[27] Christoph Molnar. 2019. Interpretable Machine Learning. https://christophm.github.io/interpretable-ml-book/.

[28] Wolfgang Nejdl. [n. d.]. FARF: A Fair and Adaptive Random Forests Classifier. In Advances in Knowledge Discovery and Data Mining: 25th Pacific-Asia Conference, PAKDD 2021, Virtual Event, May 11–14, 2021, Proceedings, Part II. Springer Nature, 245.

[29] ProPublica. [n. d.]. ProPublica COMPAS. https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-and-analysis ([n. d.]).

[30] Carlos Riquelme, Joan Puigcerver, Basil Mustafa, Maxim Neumann, Rodolphe Jenatton, André Susano Pinto, Daniel Keysers, và Neil Houlsby. 2021. Scaling Vision with Sparse Mixture of Experts. arXiv preprint arXiv:2106.05974 (2021).

[31] Anthony Robins. 1995. Catastrophic forgetting, rehearsal and pseudorehearsal. Connection Science 7, 2 (1995), 123–146.

[32] Lloyd S Shapley. 1953. Stochastic games. Proceedings of the national academy of sciences 39, 10 (1953), 1095–1100.

[33] Lloyd S Shapley. 1953. A Value for n-Person Games. In Contributions to the Theory of Games II. 307–317.

[34] Shubham Sharma, Alan H Gee, David Paydarfar, và Joydeep Ghosh. 2020. FaiR-N: Fair and Robust Neural Networks for Structured Data. arXiv preprint arXiv:2010.06113 (2020).

[35] Shubham Sharma, Yunfeng Zhang, Jesús M Ríos Aliaga, Djallel Bouneffouf, Vinod Muthusamy, và Kush R Varshney. 2020. Data Augmentation for Discrimination Prevention and Bias Disambiguation. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. 358–364.

[36] Dylan Slack, Sorelle A Friedler, và Emile Givental. 2020. Fairness warnings and fair-MAML: learning fairly with minimal data. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. 200–209.

11

--- TRANG 10 ---
[37] Kenneth O Stanley. 2003. Learning concept drift with a committee of decision trees. Informe técnico: UT-AI-TR-03-302, Department of Computer Sciences, University of Texas at Austin, USA (2003).

[38] Mukund Sundararajan, Ankur Taly, và Qiqi Yan. 2017. Axiomatic attribution for deep networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70 (ICML 2017). Journal of Machine Learning Research, 3319–3328.

[39] Lei Xu, Michael Jordan, và Geoffrey E Hinton. 1994. An alternative model for mixtures of experts. Advances in neural information processing systems 7 (1994), 633–640.

[40] Seniha Esen Yuksel, Joseph N Wilson, và Paul D Gader. 2012. Twenty years of mixture of experts. IEEE transactions on neural networks and learning systems 23, 8 (2012), 1177–1193.

[41] Brian Hu Zhang, Blake Lemoine, và Margaret Mitchell. 2018. Mitigating unwanted biases with adversarial learning. In Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society. ACM, 335–340.

12

--- TRANG 11 ---
A Tài liệu Bổ sung
Chúng tôi trình bày tài liệu bổ sung cho FEAMOE. Các mục chính được cung cấp là:
• Chứng minh Định lý 1
• Thí nghiệm trên các mô hình được đánh dấu x trong Bảng 1 của bài báo
• Chi tiết bổ sung về cài đặt thí nghiệm và tìm siêu tham số để tái tạo thí nghiệm
• Thí nghiệm tập dữ liệu COMPAS
• Thí nghiệm về drift tổng hợp sử dụng tập dữ liệu UCI Adult
• Thí nghiệm HMDA với thanh lỗi
• Thí nghiệm về giải thích Shapley value nhanh
• Thí nghiệm về so sánh với các chiến lược giảm thiểu tính công bằng hiện có
• Thí nghiệm về so sánh độ chính xác của việc sử dụng chuyên gia mạng neural với chuyên gia hồi quy logistic
• Thí nghiệm dựa trên tính công bằng riêng lẻ
• Thí nghiệm về việc sử dụng nhiều chuyên gia hơn với ít mức tăng hơn về ràng buộc công bằng
• Ví dụ giải thích Shapley value

A.1 Chứng minh Định lý 1
Xem xét một mô hình mixture of experts với m chuyên gia. Để φⱼ(m(x)) là Shapley value liên kết với chuyên gia m cho đặc trưng j cho một instance đầu vào x.

Đối với một mô hình mixture of experts, Shapley value cho một instance x cho trước và đặc trưng j cho dự đoán mô hình được cho bởi:

φⱼ(y(x)) = Σᵢ₌₁ᵐ gᵢ(x)φⱼ(m(x))                    (3)

Đối với bất kỳ đầu vào x nào, dự đoán cho mixture of experts đơn giản là một kết hợp có trọng số của các dự đoán từ các chuyên gia riêng lẻ. Sử dụng tính chất tuyến tính của Shapley values [32]:

φⱼ(y(x)) = φⱼ(g₁(x)y₁(x) + g₂(x)y₂(x) + ... + gₘ(x)yₘ(x))
         = φⱼ(g₁(x)y₁(x)) + φⱼ(g₂(x)y₂(x)) + ... + φⱼ(gₘ(x)yₘ(x))
         = g₁(x)φⱼ(y₁(x)) + g₂(x)φⱼ(y₂(x)) + ... + gₘ(x)φⱼ(yₘ(x))
         = Σᵢ₌₁ᵐ gᵢ(x)φⱼ(m(x))                    (4)

A.2 Thí nghiệm trên Mô hình Mạng Neural từ Bảng 1
Kết quả cho các ràng buộc công bằng được kết hợp độc lập trong các mô hình mạng neural được hiển thị trong Hình 4. Như chúng ta có thể thấy, các ràng buộc công bằng hoạt động ngay cả với mạng neural, nhưng khi so sánh với kết quả được cung cấp trong bản nháp chính, chúng không hoạt động tốt như các mô hình FEAMOE tương đương (FEAMOE1, FEAMOE2, và FEAMOE3 tương ứng).

A.3 Chi tiết Bổ sung về Thí nghiệm
Để nghiên cứu tác động của việc thay đổi số lượng chuyên gia đối với hiệu suất, chúng tôi thay đổi số lượng điểm dữ liệu k sau đó một chuyên gia được thêm vào cho tập dữ liệu UCI Adult với mức tăng cố định trong siêu tham số liên kết với tính công bằng, và nghiên cứu tác động. Ví dụ, để có được một chuyên gia (tức là đơn giản là một mô hình hồi quy logistic), k = n, trong đó n là kích thước của tập dữ liệu.

Kết quả được hiển thị trong Bảng 7. Khi số lượng chuyên gia lớn (k = 100) với mức tăng cố định 0.02 cho mỗi thước đo công bằng, trọng số công bằng bắt đầu chiếm ưu thế đáng kể chỉ với một vài

13

--- TRANG 12 ---
Hình 4: Kết quả cho UCI Adult Dataset về các ràng buộc công bằng khác nhau được kết hợp cho các mô hình mạng neural. Độ chính xác cao hơn thì tốt hơn và giá trị công bằng thấp hơn thì tốt hơn

Bảng 2: Kết quả về việc thay đổi số lượng điểm dữ liệu k sau đó một chuyên gia được thêm vào cho tập dữ liệu UCI Adult. Ở đây việc tăng trọng số của các phạt công bằng cho mỗi chuyên gia được thêm vào được cố định ở mức 0.02.

Hiệu suất      k = 100   k = 1000   k = 4000   k = 10000   k = 41018
Độ chính xác   46.34     74.77      79.20      83.1        77.54
SPD            0.002     0.007      0.06       0.14        0.26
AOD            0.002     0.03       0.07       0.24        0.31
Burden         0.01      0.02       0.038      0.25        0.28

chuyên gia, khiến mô hình trở nên không chính xác. Với ít chuyên gia hơn cho cùng mức tăng của mỗi trọng số thước đo công bằng, độ chính xác bắt đầu cải thiện. Đối với k = 4000, đại diện cho 11 chuyên gia, mô hình học được khá chính xác và công bằng hơn. Giảm số lượng chuyên gia hơn nữa dẫn đến một bộ phân loại chính xác hơn đến một mức, nhưng các thước đo công bằng chịu tổn thương vì trọng số liên kết với chúng rất thấp. Cuối cùng, chỉ có một mô hình hồi quy logistic không có ràng buộc về tính công bằng (k = 41018, đó là tổng số điểm dữ liệu) dẫn đến một mô hình hiệu suất kém, vì mô hình này chỉ là một mô hình tuyến tính. Điều này làm nổi bật tầm quan trọng của việc điều chỉnh số lượng chuyên gia để tìm ra sự cân bằng giữa tính công bằng và độ chính xác cho framework này.

Thí nghiệm được thực hiện bằng cách sử dụng mixture of experts với các chuyên gia hồi quy logistic và một hàm gating softmax. Chúng tôi xem xét ba tập dữ liệu thể hiện thiên vị: UCI Adult [19], COMPAS [29], và tập dữ liệu HMDA (Home Mortgage Disclosure Act) [15]. Tập dữ liệu UCI Adult liên quan đến lĩnh vực tài chính, trong đó mục tiêu là dự đoán một lớp thu nhập (>50k là kết quả tích cực). Giới tính được coi là thuộc tính được bảo vệ. Tập dữ liệu COMPAS là một tập dữ liệu phân loại trong đó biến dự đoán là khả năng tái phạm. Chủng tộc được coi là thuộc tính được bảo vệ. Tập dữ liệu HMDA được sử dụng để dự đoán liệu một cá nhân có nhận được thế chấp hay không. Chủng tộc được coi là thuộc tính được bảo vệ. Tập dữ liệu tồn tại trên nhiều năm và có số lượng lớn các mục dữ liệu trong mỗi năm. Chúng tôi sử dụng tập dữ liệu UCI Adult và COMPAS để chứng minh các hiệu ứng của việc kết hợp các ràng buộc công bằng được đề xuất vào các mô hình mixture of experts. Tập dữ liệu UCI Adult được sử dụng để chỉ ra khả năng xử lý drift khi drift đối với tính công bằng được gây ra một cách tổng hợp. Tập dữ liệu HMDA được sử dụng để chỉ ra một ứng dụng thực tế của phương pháp của chúng tôi hướng tới xử lý concept drift. Thí nghiệm được thực hiện trên laptop tiêu chuẩn với bộ xử lý Intel i5 và không có GPU được sử dụng.

14

--- TRANG 13 ---
(a) (b)
(c) (d)

Hình 5: Kết quả cho tập dữ liệu COMPAS về các ràng buộc công bằng khác nhau được kết hợp. Chi tiết về tên mô hình được cung cấp trong Bảng 1. Độ chính xác cao hơn thì tốt hơn và giá trị thước đo công bằng thấp hơn thì tốt hơn

Các mạng neural được sử dụng để so sánh với FEAMOE là mạng neural 2 lớp ẩn với 30 neuron trong mỗi lớp cho tập dữ liệu UCI Adult và COMPAS, và mạng neural 5 lớp ẩn với 50 neuron trong mỗi lớp cho tập dữ liệu HMDA. Số lượng chuyên gia trong FEAMOE phụ thuộc vào số lượng điểm dữ liệu được xem xét sau đó một chuyên gia được thêm vào. Số lượng điểm dữ liệu, cùng với siêu tham số cho mỗi ràng buộc công bằng có thể được tìm thấy bằng cách sử dụng grid search. Thông qua thí nghiệm rộng rãi, chúng tôi phát hiện ra rằng số lượng điểm sau đó các chuyên gia được thêm vào nên khoảng một phần mười của kích thước dữ liệu dự kiến nếu dữ liệu là tuần tự hoặc kích thước tập dữ liệu nếu toàn bộ tập dữ liệu có sẵn. Siêu tham số dựa trên ràng buộc công bằng (mức tăng) không nên vượt quá hệ số 0.1 nếu không các mô hình sẽ có độ chính xác kém. Ngoài ra, vì ràng buộc burden hoạt động khá tốt để cũng giúp với SPD và AOD, chỉ ràng buộc đó có thể được xem xét để tránh điều chỉnh cho bốn siêu tham số khác nhau. Chúng tôi cung cấp mã cho notebook cơ bản triển khai mixture of experts với ràng buộc công bằng. Tất cả thí nghiệm là các biến thể đơn giản của notebook này.

A.4 Thí nghiệm tập dữ liệu COMPAS
So với tập dữ liệu UCI Adult, tập dữ liệu COMPAS (kết quả trong Hình 5) có nhiều sự sụt giảm độ chính xác hơn với việc bao gồm các ràng buộc công bằng (Hình 5a), do sự đánh đổi về tính công bằng-độ chính xác vốn có, như đã được chỉ ra trước đây [10,35]. Điều này có thể được cho là do tập dữ liệu này có thiên vị dựa trên định kiến hoặc thiên vị nhãn trái ngược với tập dữ liệu UCI Adult có thiên vị dựa trên lấy mẫu [35]. Cũng có thể quan sát thấy rằng đối với tập dữ liệu này, có sự đánh đổi vốn có giữa demographic parity và equalized odds (Hình 5b,c). Trong việc cố gắng cải thiện chỉ một, cái khác trở nên tệ hơn (FEAMOE1 và FEAMOE2). Ràng buộc dựa trên burden hoạt động tương tự như hiệu ứng nó đã có đối với tập dữ liệu UCI Adult (Hình 5d). Vì burden-based fairness phụ thuộc vào khoảng cách của các điểm đến ranh giới, một bộ phân loại có thể có thể duy trì độ chính xác của nó trong khi thay đổi khoảng cách đến các điểm để giảm khoảng cách recourse. Hiệu ứng này có thể được nhìn thấy thông qua tập dữ liệu COMPAS: độ chính xác không sụt giảm đáng kể khi chỉ sử dụng ràng buộc burden. Tuy nhiên, bao gồm cả ba ràng buộc (FEAMOE) tạo ra một mô hình công bằng hơn so với các mô hình tiêu chuẩn và khá chính xác, do đó làm nổi bật tầm quan trọng của việc bao gồm cả ba ràng buộc trong mục tiêu.

15

--- TRANG 14 ---
(a) (b)
(c) (d)

Hình 6: Kết quả về khả năng xử lý drift có độ lớn khác nhau. Khi tỷ lệ phần trăm điểm dữ liệu thấp hơn được xem xét từ tập dữ liệu new world (đây là mức tăng cường thấp từ [35]), ít drift xảy ra hơn. Tuy nhiên, với sự gia tăng các điểm dữ liệu từ tập dữ liệu new world được sắp xếp (sắp xếp theo thứ tự giảm dần về mức độ thực tế của các điểm so với tập dữ liệu gốc), có nhiều drift hơn, cả về độ chính xác và tính công bằng. Độ chính xác cao hơn thì tốt hơn và giá trị công bằng thấp hơn thì tốt hơn. Mạng neural cố định được huấn luyện trên tập dữ liệu gốc không có ràng buộc công bằng và được kiểm tra trên các tập con tập dữ liệu new world. Mạng neural có thể huấn luyện được huấn luyện trên tập dữ liệu gốc với ràng buộc công bằng, và được huấn luyện lại ở chế độ trực tuyến với các tập con từ tập dữ liệu new world

A.5 Thí nghiệm về drift tổng hợp sử dụng tập dữ liệu UCI Adult
Để kiểm tra FEAMOE về drift có thể xảy ra do thay đổi trong đặc tính của các nhóm trong một tập dữ liệu, chúng tôi thực hiện thí nghiệm trên các tập dữ liệu được tạo tổng hợp dựa trên tập dữ liệu UCI Adult. Chúng tôi thực hiện thí nghiệm về drift được gây ra tổng hợp để chỉ ra rằng phương pháp của chúng tôi có thể xử lý drift có độ lớn khác nhau.

Để gây ra drift tổng hợp, chúng tôi tạo ra một tập dữ liệu sử dụng tập dữ liệu UCI Adult trong đó thuộc tính được bảo vệ nhị phân giới tính bị lật, như trong [35]. Chúng tôi gọi đây là tập dữ liệu new world. Tập dữ liệu mới này có nhiều phụ nữ thuộc về nhóm nhận được thu nhập lớn hơn 50k mỗi năm. Để đánh giá khả năng xử lý drift có độ lớn khác nhau, chúng tôi xem xét các tập con được chọn tuần tự từ tập dữ liệu new world trong đó dữ liệu được sắp xếp theo thứ tự thực tế như trong [35]. Trong [35], tính thực tế của một điểm dữ liệu được xác định bằng khoảng cách giữa điểm dữ liệu trong tập dữ liệu mới với các trung tâm cụm (được tìm thấy bằng cách sử dụng k-means) từ tập dữ liệu gốc. Ví dụ, chúng tôi đầu tiên chỉ xem xét 10% đầu tiên của dữ liệu new world thực tế nhất, đây là mức tăng cường 10% trong [35]. Tập con thực tế nhất sẽ gây ra drift ít nhất (drift chậm), và khi khoảng cách của các tập con tổng hợp đến tập dữ liệu gốc tăng, drift càng rõ ràng hơn. Làm cơ sở, chúng tôi huấn luyện một mạng neural (không có ràng buộc công bằng nào) trên tập dữ liệu UCI Adult gốc. Chúng tôi gọi đây là mạng neural cố định. Sau đó, chúng tôi kiểm tra mạng này trên dữ liệu từ các tập con khác nhau của dữ liệu new world. Trong việc kiểm tra mô hình này, chúng tôi đi từ các tập con thực tế nhất đến ít thực tế nhất (tức là ít drift đến nhiều drift hơn) và theo dõi độ chính xác và ba thước đo công bằng được giới thiệu trước đó. Chúng tôi so sánh mô hình này với việc huấn luyện framework mixture of logistic regression experts thích ứng của chúng tôi trên các tập con này. Chúng tôi cũng so sánh với việc huấn luyện

16

--- TRANG 15 ---
Bảng 3: Kết quả so sánh KernelShap với việc sử dụng LinearShap cho các chuyên gia riêng lẻ và kết hợp chúng bằng Định lý 1 (FEAMOE) cho 100 instances trên ba tập dữ liệu. Hai biến thể của KernelShap được xem xét, với việc thay đổi số lượng mẫu n được phép để tạo thành sự kết hợp các đặc trưng để tính toán. Thời gian được đo bằng giây

Tập dữ liệu    Thời gian FEAMOE    Thời gian KernelShap n=500    Thời gian KernelShap n=2000
UCI Adult      34                  379                           941
COMPAS         32                  246                           805
HMDA           38                  314                           887

mạng neural gốc ở chế độ trực tuyến với ràng buộc công bằng trên các tập con này, tức là thích ứng một mạng neural với ràng buộc công bằng. Chúng tôi gọi đây là mạng neural có thể huấn luyện.

Kết quả được hiển thị trong Hình 6. Cả độ chính xác và các thước đo công bằng đều vẫn liên tục kém cho mạng neural cơ sở (mạng neural cố định), và chúng xấu đi khi các tập con từ các phần ít thực tế hơn của dữ liệu new world được đánh giá, chứng minh rằng drift đối với cả độ chính xác và tính công bằng là có thể khi dữ liệu kiểm tra đã drift từ dữ liệu huấn luyện. Chúng tôi cần các framework có thể thích ứng với điều này. Để triển khai FEAMOE, chúng tôi huấn luyện một mô hình hồi quy logistic với tập dữ liệu UCI Adult gốc, và sau đó thêm các chuyên gia cho các tập con mới dựa trên Thuật toán 1. FEAMOE có thể tính toán các mức độ drift khác nhau. Độ chính xác của mô hình chúng tôi vẫn khá không đổi, và thiên vị thấp hơn đáng kể so với mô hình cơ sở. Phương pháp của chúng tôi cũng có thể thích ứng tốt hơn để duy trì độ chính xác và tất cả các thước đo công bằng, so với một mạng neural có thể được huấn luyện với các điểm dữ liệu mới và với ràng buộc công bằng (tức là mạng neural có thể huấn luyện).

A.6 Thí nghiệm HMDA với thanh lỗi
Đầu tiên chúng tôi chứng minh rằng tập dữ liệu HMDA thể hiện drift qua các năm, và sau đó chỉ ra hiệu quả của FEAMOE trong việc xử lý nó. Tập dữ liệu HMDA có hàng triệu bản ghi của các cá nhân trải dài nhiều năm. Nó chứa các đặc điểm của người tiêu dùng; biến mục tiêu chỉ ra liệu người tiêu dùng có nhận được thế chấp hay không. Mặc dù tập dữ liệu này được coi là một tổng thể trước đây đã được chỉ ra thể hiện thiên vị, không có điều tra nào về cách thiên vị như vậy thay đổi qua các năm. Đầu tiên, để định lượng drift trong tập dữ liệu này cả về tính công bằng và độ chính xác, chúng tôi huấn luyện một mạng neural cho mỗi năm từ 2007 đến 2017, mỗi mạng trên 100,000 mẫu ngẫu nhiên trong năm đó, và kiểm tra mỗi mạng này trên dữ liệu từ các năm 2016-2017 (Khi đã được huấn luyện, các mô hình này, mà chúng tôi gọi là mạng neural cố định, không thể được cập nhật). Kết quả được hiển thị trong Hình 7 bởi các điểm màu xanh. Nói chung, càng xa dữ liệu huấn luyện từ năm kiểm tra thì các thước đo độ chính xác và tính công bằng càng xấu đi (tức là độ chính xác giảm và sự khác biệt về tính công bằng tăng). Ngoài ra, việc huấn luyện một mô hình đơn lẻ trên một tập dữ liệu cùng kích thước nhưng được lấy mẫu đồng nhất trong tất cả các năm trước đó cũng không giúp ích gì vì dữ liệu là không dừng. Theo hiểu biết của chúng tôi, đây là nghiên cứu chi tiết nhất về drift tính công bằng theo thời gian, được thực hiện trên một tập dữ liệu thực tế quy mô lớn có thể truy cập công khai.

Bây giờ chúng tôi nghiên cứu cách các mạng neural nhận biết tính công bằng với cập nhật trực tuyến so sánh với FEAMOE trong khả năng xử lý drift của chúng. Lưu ý rằng đối với cài đặt của chúng tôi, chúng tôi không thể sử dụng một số mô hình như các phương pháp ensemble phổ biến (XGBoost, v.v.), cần nhiều lần truyền qua dữ liệu mới ở chế độ batch sau khi mô hình ban đầu được xây dựng và triển khai. Đối với FEAMOE, chúng tôi huấn luyện các mô hình cho mỗi năm riêng biệt và coi mỗi mô hình đó là một chuyên gia. Sau đó, chúng tôi thêm vào các chuyên gia dựa trên một lần truyền qua dữ liệu mới (từ các năm 2016-2017). Chúng tôi so sánh điều này với mạng neural (với ràng buộc công bằng) cũng được huấn luyện trên mỗi năm trong quá khứ ở chế độ batch, và sau đó được cập nhật trực tuyến với một lần truyền qua dữ liệu mới. Kết quả FEAMOE được hiển thị trong Hình 7 bởi các điểm màu xanh lá, và kết quả mạng neural có thể huấn luyện bởi các điểm màu cam. FEAMOE đáng chú ý tốt hơn trong việc duy trì độ chính xác tốt và giữ thiên vị thấp hơn trên tất cả các thước đo thiên vị, khá nhiều bất kể mô hình gốc cũ như thế nào, ngay cả khi so sánh với mạng neural thích ứng. Chúng tôi tin rằng kiến trúc kết hợp lỏng lẻo và độ phức tạp mô hình thích ứng là chìa khóa cho sự thành công của FEAMOE trong việc xử lý drift. Cũng đáng chú ý rằng việc sử dụng kiến trúc FEAMOE cung cấp giải thích Shapley value nhanh hơn nhiều so với mạng neural có thể huấn luyện (như được hiển thị trong các thí nghiệm sau này).

17

--- TRANG 16 ---
(a) (b)
(c) (d)

Hình 7: So sánh Xử lý Drift trên tập dữ liệu HMDA. Giá trị thiên vị thấp hơn thì tốt hơn. Kết quả có bao gồm thanh lỗi. 1) Xanh: mạng neural cơ sở (mạng neural cố định) được huấn luyện không có ràng buộc công bằng trên một năm trước (20XX, được chỉ ra bởi trục x; 2016 và 2017 là những năm "tương lai") và không được cập nhật với dữ liệu mới; 2) Cam: mạng neural có thể huấn luyện (và công bằng): Mạng neural với ràng buộc công bằng được kết hợp; cũng được cập nhật với dữ liệu streaming từ những năm "tương lai" và 3) Xanh lá: FEAMOE, cũng cập nhật với một lần truyền qua dữ liệu streaming từ những năm "tương lai". Lưu ý rằng một số mô hình phổ biến (bao gồm ensemble như XGBoost) không được xem xét vì theo mặc định chúng sẽ cần thực hiện nhiều lần truyền qua tập dữ liệu và thực sự không được thiết kế cho các ứng dụng streaming (nhìn một lần).

A.7 Giải thích Shapley Value
Như một lợi ích bổ sung, bằng cách sử dụng mixture of experts với các chuyên gia hồi quy logistic, chúng tôi có thể tạo ra các giải thích chính xác một cách hiệu quả về mặt tính toán. Chúng tôi tạo ra các giá trị Shap cho mỗi chuyên gia độc lập trong FEAMOE sử dụng LinearShap từ SHAP explainer [21] và sau đó tính toán giá trị Shapley cuối cùng sử dụng Định lý 1. Chúng tôi so sánh thời gian tính toán giải thích của FEAMOE với KernelShap. Chúng tôi làm điều này cho 100 instances trên ba tập dữ liệu. Chúng tôi so sánh hai phương pháp dựa trên thời gian được thực hiện trên 100 mẫu. Bảng 3 hiển thị kết quả. Như chúng ta có thể thấy, KernelShap mất thời gian đáng kể hơn so với việc sử dụng FEAMOE để tính toán các giá trị Shapley cuối cùng. Khi các kết hợp đặc trưng được phép được tăng lên hướng tới việc tính toán xấp xỉ KernelShap (tức là n được tăng để tạo ra các giải thích gần hơn với các giá trị Shapley chính xác), nó mất thời gian còn nhiều hơn nữa. Do đó, phương pháp của chúng tôi tạo ra các giải thích nhanh hơn nhiều và có thể mở rộng tốt hơn cho số lượng lớn các đặc trưng và quan sát. Điều này đặc biệt hữu ích trong cài đặt sản xuất đòi hỏi số lượng lớn các giải thích nhanh chóng.

A.8 So sánh với các phương pháp giảm thiểu tính công bằng khác
Chúng tôi so sánh việc sử dụng các ràng buộc công bằng được sử dụng trong FEAMOE với các phương pháp giảm thiểu thiên vị hiện đại cho mạng neural cho UCI Adult Dataset. Kết quả được hiển thị trong Bảng 4. Như chúng ta có thể thấy, FEAMOE tạo ra các mô hình chính xác và công bằng trên tất cả các thước đo thiên vị. Các phương pháp khác chỉ tối ưu hóa trên một hoặc hai thước đo, nhưng chúng tôi vẫn so sánh trên tất cả các thước đo để xác nhận rằng các ràng buộc được giới thiệu trong FEAMOE có thể giảm thiểu đủ thiên vị và trong khi duy trì độ chính xác.

18

--- TRANG 17 ---
Phương pháp    Độ chính xác    SPD     AOD     Burden
NN             82.02           0.19    0.29    0.29
FEAMOE         83.24           0.06    0.07    0.03
FaiR-N-4       83.75           0.12    0.11    0.02
P.R.†          78.14           0.09    0.14    0.32
O.P.P.†        77.62           0.10    0.08    0.16
DataAug†       78.57           0.07    0.06    0.11
RedApp†        81.98           0.10    0.08    0.21

Bảng 4: So sánh các mô hình (tính trung bình trên năm lần chạy) được huấn luyện trên tập dữ liệu Adult. NN là mạng neural được huấn luyện không có ràng buộc công bằng nào, FaiR-N-4 là mô hình từ [34], †: prejudice remover (P.R.) [17], optimized pre-processing (O.P.P.) [10], DataAug [35], và RedApp [2]

A.9 Sử dụng chuyên gia mạng neural trong FEAMOE
Thay vì sử dụng các chuyên gia hồi quy logistic, các chuyên gia mạng neural cũng có thể được sử dụng, với nhược điểm là không thể có được giải thích nhanh. Tuy nhiên, chúng tôi so sánh việc sử dụng các chuyên gia mạng neural với việc sử dụng các chuyên gia hồi quy logistic để xem liệu có sự khác biệt về hiệu suất cho tập dữ liệu HMDA cho dữ liệu từ năm 2017.

Kết quả được hiển thị trong Bảng 6. Bảng cho thấy cách trên độ chính xác và ràng buộc công bằng, các chuyên gia mạng neural và hồi quy logistic hoạt động tương đương. Mặc dù số lượng chuyên gia hồi quy logistic cần thiết nhiều hơn số lượng chuyên gia mạng neural cần thiết để có hiệu suất tương tự, việc sử dụng các mô hình hồi quy logistic đi kèm với lợi thế cung cấp khả năng giải thích.

Hiệu suất           NN      LR (FEAMOE)
Độ chính xác        84.21   84.08
SPD                 0.08    0.07
AOD                 0.078   0.081
Burden              0.08    0.08
Số lượng Chuyên gia 8       13

Bảng 5: Kết quả về việc sử dụng chuyên gia mạng neural và so sánh với việc sử dụng chuyên gia hồi quy logistic

A.10 Thí nghiệm về việc sử dụng tính công bằng riêng lẻ
Để sử dụng cơ chế phát triển chuyên gia dựa trên bão hòa hiệu suất thay vì phát triển dựa trên số lượng điểm dữ liệu, chúng tôi kiểm tra tính công bằng riêng lẻ và chỉ thêm một chuyên gia khi một số điểm dữ liệu n nhất định không thỏa mãn tính công bằng riêng lẻ. Ngoài ra, chúng tôi thêm một phạt không đổi vào mất mát độ chính xác mixture of experts gốc sao cho nó là 0 khi điểm công bằng riêng lẻ và là 0.4 (có thể thay đổi) khi điểm không công bằng riêng lẻ. Chúng tôi kiểm tra tính công bằng riêng lẻ bằng cách lật thuộc tính được bảo vệ và đánh giá mô hình: nếu điểm dữ liệu bị lật có cùng dự đoán với điểm dữ liệu gốc, điểm dữ liệu đầu vào này thỏa mãn tính công bằng riêng lẻ, nếu không thì không. Khi n điểm không thỏa mãn tính công bằng riêng lẻ, chúng tôi thêm một chuyên gia khác. (Lưu ý rằng đây là phương pháp ngây thơ để kiểm tra tính công bằng riêng lẻ, tuy nhiên bất kỳ cơ chế nào khác có thể được áp dụng để kiểm tra tính công bằng riêng lẻ).

Kết quả về độ chính xác và tính công bằng riêng lẻ cho FEAMOE cho tập dữ liệu COMPAS được hiển thị trong Bảng 6, trong đó tính công bằng riêng lẻ được đo lường như tỷ lệ các điểm không thỏa mãn tính công bằng riêng lẻ trong tập dữ liệu và so sánh với mạng neural. Như chúng ta có thể thấy, FEAMOE vẫn khá chính xác, trong khi đảm bảo rằng bộ phân loại công bằng riêng lẻ hơn.

Hiệu suất           NN      FEAMOE
Độ chính xác        66.18   64.13
Tính công bằng riêng lẻ 0.38    0.09

Bảng 6: Kết quả về việc sử dụng tính công bằng riêng lẻ trong FEAMOE

19

--- TRANG 18 ---
(a) (b)

Hình 8: Giải thích Shapley value cho hai điểm dữ liệu khác nhau sử dụng mô hình mixture of experts bằng cách tìm các giá trị Shapley độc lập và sau đó sử dụng Định lý 1. KernelShap cho mô hình mạng neural bằng cách sử dụng tất cả các kết hợp đặc trưng cho kết quả tương tự, trong khi mất thời gian lâu hơn nhiều để tính toán.

A.11 Bao gồm nhiều chuyên gia hơn
Chúng tôi chỉ ra rằng việc sử dụng nhiều chuyên gia hơn (tức là thêm mỗi chuyên gia sau ít điểm dữ liệu hơn) nhưng với các thay đổi nhỏ hơn trong siêu tham số công bằng (mức tăng đối với λ₁, λ₂, và λ₃). Đối với tập dữ liệu COMPAS, chúng tôi thêm các chuyên gia sau mỗi 40 điểm dữ liệu với mức tăng công bằng 0.002 với mỗi chuyên gia được thêm vào. Kết quả trong Bảng 7. Như chúng ta có thể thấy, kết quả có thể so sánh với kết quả tập dữ liệu COMPAS trong bản nháp chính, cho thấy rằng chúng tôi có thể có nhiều chuyên gia hơn với mức tăng ràng buộc công bằng nhỏ hơn để tạo ra một mô hình FEAMOE tương tự.

Hiệu suất    k = 40
Độ chính xác  63.77
SPD           0.05
AOD           0.13
Burden        0.05

Bảng 7: Kết quả trên tập dữ liệu COMPAS với k = 40 và mức tăng công bằng 0.002

A.12 Ví dụ giải thích Shapley value
Một số ví dụ giải thích Shapley value dựa trên decision plots cho các điểm kiểm tra riêng lẻ cho tập dữ liệu UCI Adult được hiển thị trong Hình 8. Chúng tôi tìm các giá trị Shapley độc lập cho các điểm dữ liệu cho mỗi chuyên gia sử dụng thiết lập được cung cấp trong https://slundberg.github.io/shap/notebooks/plots/decision_plot.html và sau đó sử dụng Định lý 1 để tìm các giá trị Shapley cuối cùng. KernelShap được sử dụng trên mạng neural cho cùng các điểm dữ liệu có kết quả tương tự, trong khi mất thời gian lâu hơn đáng kể để tính toán

20

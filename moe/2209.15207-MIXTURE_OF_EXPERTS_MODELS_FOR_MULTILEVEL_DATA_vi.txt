# 2209.15207.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/moe/2209.15207.pdf
# Kích thước file: 1693499 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
MÔ HÌNH HỖN HỢP CÁC CHUYÊN GIA CHO DỮ LIỆU ĐA CẤP:
KHUNG LÝ THUYẾT MÔ HÌNH HÓA VÀ LÝ THUYẾT XẤP XỈ
Tsz Chai FungSpark C. Tseungy

TÓM TẮT
Dữ liệu đa cấp rất phổ biến trong nhiều ứng dụng thực tế. Tuy nhiên, việc xác định và chứng minh một lớp mô hình có thể linh hoạt nắm bắt được nhiều loại dữ liệu đa cấp khác nhau vẫn là một vấn đề nghiên cứu chưa được giải quyết. Được thúc đẩy bởi tính linh hoạt của các mô hình hỗn hợp chuyên gia (MoE) trong việc khớp dữ liệu hồi quy, trong bài báo này chúng tôi mở rộng MoE và nghiên cứu một lớp mô hình MoE hỗn hợp (MMoE) cho dữ liệu đa cấp. Dưới một số điều kiện tính chính quy, chúng tôi chứng minh rằng MMoE trù mật trong không gian của bất kỳ mô hình hiệu ứng hỗn hợp liên tục nào theo nghĩa hội tụ yếu. Kết quả là, MMoE có tiềm năng mô tả chính xác hầu hết các đặc trưng có trong dữ liệu đa cấp, bao gồm phân phối biên, cấu trúc phụ thuộc, liên kết hồi quy, chặn ngẫu nhiên và độ dốc ngẫu nhiên. Trong trường hợp đặc biệt khi dữ liệu đa cấp có cấu trúc phân cấp, chúng tôi chứng minh thêm rằng một phiên bản lồng nhau của MMoE có thể xấp xỉ tổng quát nhiều loại cấu trúc phụ thuộc của các hiệu ứng ngẫu nhiên giữa các cấp độ yếu tố khác nhau.

Từ khóa: Mạng nơ-ron nhân tạo, Hiệu ứng ngẫu nhiên giao thoa và lồng nhau, Tính trù mật, Mô hình hiệu ứng hỗn hợp, Định lý xấp xỉ tổng quát

1 Giới thiệu
Mô hình hỗn hợp chuyên gia (MoE), được giới thiệu lần đầu bởi Jacobs et al. [1991] (xem thêm, e.g., Jordan và Jacobs [1994] và McLachlan và Peel [2000] để biết chi tiết), là một phiên bản xác suất của kiến trúc mạng nơ-ron hữu ích cho hồi quy linh hoạt, phân loại và mô hình hóa phân phối, với các ứng dụng trong nhiều lĩnh vực khác nhau bao gồm y tế, kinh doanh, khoa học xã hội và môi trường. Độc giả có thể tham khảo Yuksel et al. [2012], Masoudnia và Ebrahimpour [2014] và Nguyen và Chamroukhi [2018] để có cái nhìn tổng quan về các lý thuyết và ứng dụng của MoE.

Cấu trúc mô hình của MoE như sau. Giả sử chúng ta có N quan sát (y;x) = {(yi;xi)}i=1;:::;N, trong đó yi = (yi1;:::;yiK) là một biến phản hồi K chiều với không gian đầu ra

Khoa Quản lý Rủi ro và Bảo hiểm, Đại học Bang Georgia. 35 Broad Street NW, Atlanta, GA 30303, Hoa Kỳ. Địa chỉ email: tfung@gsu.edu .
yKhoa Khoa học Thống kê, Đại học Toronto. Tòa nhà Ontario Power, 700 University Avenue, Tầng 9, Toronto, ON M5G 1Z5, Canada. Địa chỉ email: spark.tseung@mail.utoronto.ca .arXiv:2209.15207v1 [math.ST] 30 Sep 2022

--- TRANG 2 ---
Mô hình hỗn hợp chuyên gia cho dữ liệu đa cấp: khung lý thuyết mô hình hóa và lý thuyết xấp xỉ

Y ⊆ RK và xi = (xi1:::;xiP) là P biến hiệp phương (covariates) hoặc đặc trưng với không gian đầu vào X ⊆ RP. Dưới khung MoE, hàm phân phối có điều kiện của yi cho xi là

F(yi;α; β;φ,g|xi) = ∑j=1^g πj(xi;α)F0(yi; φj|xi), (1)

trong đó g là số lượng lớp tiềm ẩn. Ở đây, πj(xi;α) > 0 được gọi là hàm cổng với ∑j=1^g πj(xi;α) = 1 và tham số α. Trong khi lựa chọn phổ biến nhất của hàm cổng là cổng logit-tuyến tính hoặc softmax (Jacobs et al. [1991]) cho bởi πj(xi;α) = exp{αj,0+αj^T xi}/∑j'=1^g exp{αj',0+αj'^T xi} với α = {αj0;αj: j = 1;:::;g}, các hàm cổng khác như cổng Gaussian (Xu et al. [1995]), cổng student-t (Ingrassia et al. [2012]) và cổng probit (Geweke và Keane [2007]) cũng được khám phá trong tài liệu. Ngoài ra, F0(yi; φj|xi) là một phân phối xác suất được gọi là hàm chuyên gia với tham số φ := {φj: j = 1;:::;g}. Trong khi lựa chọn phổ biến cho hàm chuyên gia là phân phối Gaussian (Jordan và Jacobs [1992]), đã có những phát triển đáng kể về các lựa chọn khác cho hàm chuyên gia để phục vụ cho các đặc trưng phân phối khác nhau như đuôi nặng (Laplace bởi Nguyen và McLachlan [2016], phân phối t bởi Chamroukhi [2016], t lệch bởi Chamroukhi [2017] và gamma biến đổi bởi Fung et al. [2021]) và phân phối rời rạc (Poisson bởi Grun và Leisch [2008] và Erlang Count bởi Fung et al. [2019b]).

Tính linh hoạt của mô hình là một tính chất mong muốn quan trọng đối với lớp MoE, và có nhiều nghiên cứu về lý thuyết xấp xỉ cho MoE. Zeevi et al. [1998] cho thấy rằng hàm trung bình của MoE logit-gated đơn biến (K = 1) có thể xấp xỉ bất kỳ hàm lớp Sobolev nào. Kết quả này được mở rộng bởi Jiang và Tanner [1999a], người xem xét lớp Sobolev biến đổi. Không xem xét tốc độ hội tụ, Nguyen et al. [2016] chứng minh rằng hàm trung bình MoE trù mật trong lớp của bất kỳ hàm liên tục nào mà không có hạn chế của lớp Sobolev, và Nguyen et al. [2019] cho thấy các kết quả tính trù mật tương tự sử dụng MoE Gaussian-gated đa biến (K > 1).

Ngoài việc nghiên cứu các hàm trung bình, một số nghiên cứu tập trung vào xấp xỉ mật độ có điều kiện đối với khoảng cách Hellinger, phân kỳ Kullback-Leibler (KL), hoặc không gian Lebesgue. Jiang và Tanner [1999b] và Mendes và Jiang [2012] tổng quát hóa các kết quả của Jiang và Tanner [1999a] bằng cách chứng minh khả năng xấp xỉ của MoE đối với bất kỳ mô hình hồi quy phi tuyến họ hàm mũ nào. Norets et al. [2010] cho thấy rằng MoE logit-gated với hàm chuyên gia Gaussian có thể xấp xỉ bất kỳ mật độ có điều kiện nào. Các kết quả tương tự được chứng minh bởi Norets và Pelenis [2014] và Nguyen et al. [2019], người xem xét các hàm cổng Gaussian. Gần đây, Nguyen et al. [2021] chứng minh rằng lớp MoE trù mật trong không gian Lebesgue.

Một dòng nghiên cứu khác về định lý xấp xỉ phân phối nghiên cứu tính trù mật theo nghĩa metric Prohorov của hội tụ yếu. Mở rộng từ Tijms [1994] và Breuer và Baum [2005] người khám phá tính trù mật của hỗn hợp hữu hạn và phân phối phase-type trong không gian của bất kỳ phân phối xác suất nào, Fung et al. [2019a] xây dựng khái niệm "tính trù mật" trong bối cảnh hồi quy và cho thấy rằng lớp MoE trù mật trong không gian của bất kỳ phân phối hồi quy nào, tuân theo một số điều kiện tính chính quy như tính liên tục Lipschitz và tính chặt chẽ của phân phối. Trái ngược với các nghiên cứu hiện có khác về xấp xỉ phân phối, kết quả của Fung et al. [2019a] rất tổng quát vì: (i) chúng đúng dưới nhiều lựa chọn hàm chuyên gia (không giới hạn ở hàm chuyên gia Gaussian hoặc đối xứng khác); (ii) phân phối mục tiêu không bị giới hạn ở một lớp đặc biệt (e.g., mô hình hồi quy họ hàm mũ).

--- TRANG 3 ---
Mô hình hỗn hợp chuyên gia cho dữ liệu đa cấp: khung lý thuyết mô hình hóa và lý thuyết xấp xỉ

Mặc dù có tính linh hoạt của mô hình, khung mô hình hóa nói trên ngầm giả định rằng các cặp đầu vào-đầu ra độc lập giữa các quan sát. Điều này không đúng với dữ liệu đa cấp (Goldstein [2011]). Ngoài các đầu vào xi, còn có L cấp độ yếu tố θi = (θi1;:::;θiL) cùng ảnh hưởng đến đầu ra yi. Trong khi các yếu tố này không được quan sát, chúng được nhóm thành các đơn vị khác nhau cho mỗi cấp độ l = 1;:::;L và chúng ta biết cách chúng được nhóm. Như được hiển thị trong Hình 1, đối với mỗi cấp độ l = 1;:::;L, mỗi quan sát i được phân vào một trong Sl đơn vị, trong đó cl(·) : {1;:::;N} → {1;:::;Sl} được ký hiệu là một hàm đã biết ánh xạ chỉ số quan sát đến một trong Sl đơn vị, với c(i) = (c1(i):::;cL(i)). Chúng ta có θil = θi'l := θl^(s) nếu cl(i) = cl(i') = s. Vì yếu tố θl^(s) ảnh hưởng đến nhiều quan sát cùng một lúc, có sự phụ thuộc lẫn nhau giữa các quan sát. Bỏ qua sự phụ thuộc này sẽ dẫn đến kết quả phân nhóm và dự đoán giả tạo, gây hiểu lầm hoặc thiên vị (Goldstein [2011]).

Dữ liệu đa cấp rất phổ biến trong nhiều ứng dụng. Ví dụ cổ điển nhất là bài toán trường học (Aitkin và Longford [1986], Goldstein [1986] và Frees và Kim [2006]), trong đó "trường học" và "lớp học trong trường" đóng vai trò là hai cấp độ yếu tố ảnh hưởng đến thành tích của một học sinh (như một quan sát). Cấu trúc dữ liệu đa cấp cũng có thể được gây ra bởi các phép đo lặp lại thu thập trong các nghiên cứu dọc. Điều này phổ biến trong nhiều lĩnh vực khác nhau bao gồm y tế (e.g., Molenberghs et al. [2010]) và kinh doanh (e.g., Boucher và Denuit [2006]). Ví dụ, kết quả y tế của bệnh nhân hoặc số lượng yêu cầu bảo hiểm của người được bảo hiểm được đo lường hoặc thu thập lặp lại theo thời gian. Một trường hợp đặc biệt đáng chú ý của dữ liệu đa cấp là dữ liệu phân cấp (hoặc lồng nhau), trong đó L cấp độ yếu tố được xếp hạng từ cao đến thấp, và mỗi yếu tố cấp độ thấp hơn thuộc về một yếu tố cấp độ cao hơn cụ thể. Bài toán trường học là một ví dụ rõ ràng về dữ liệu phân cấp.

Một mô hình phổ biến để tính đến sự phụ thuộc lẫn nhau giữa các quan sát là mô hình hiệu ứng hỗn hợp tuyến tính tổng quát (GLMM) (Goldstein [1986] và McGilchrist [1994]), giả định rằng đầu ra yi phụ thuộc vào tổng của hiệu ứng cố định (i.e., tác động của các đầu vào xi) và hiệu ứng ngẫu nhiên (i.e., tác động của các yếu tố θi). Để cải thiện tính linh hoạt của mô hình hoặc đạt được các mục đích phân nhóm cụ thể, khung GLMM được mở rộng thành một thiết lập phi tuyến (Davidian và Gallant [1993] và Gregoire và Schabenberger [1996]), được xây dựng trong cấu trúc mạng nơ-ron (Bakker và Heskes [2003]) hoặc được tích hợp vào khung mô hình hóa hỗn hợp hữu hạn (Ng et al. [2004] và Ng et al. [2006]). Mặc dù có các tính chất mong muốn của mô hình MoE dẫn đến các ứng dụng rộng rãi, các nghiên cứu về mô hình hiệu ứng hỗn hợp trong bối cảnh khung MoE tương đối hiếm. Yau et al. [2003] lần đầu tiên đề xuất MoE Gaussian-expert logit-gated hai thành phần với hiệu ứng ngẫu nhiên được tích hợp vào cả hàm cổng và hàm chuyên gia. Ng và McLachlan [2007] sau đó xây dựng MoE hiệu ứng hỗn hợp g-thành phần tổng quát với việc sử dụng hàm chuyên gia logistic cho phân loại nhị phân. Ng và McLachlan [2014] xem xét một khung tương tự chỉ với hiệu ứng ngẫu nhiên được tích hợp vào hàm chuyên gia. Tuy nhiên, tất cả các mô hình MoE hiệu ứng hỗn hợp nói trên chỉ xử lý một cấp độ hiệu ứng ngẫu nhiên duy nhất (i.e., L = 1).

Được thúc đẩy bởi sự phổ biến ngày càng tăng của các mô hình MoE, sự phổ biến của dữ liệu đa cấp và mong muốn chính thức chứng minh tính linh hoạt của mô hình thông qua các lý thuyết xấp xỉ, đóng góp của bài báo này có bốn khía cạnh: Thứ nhất, chúng tôi đề xuất MoE hỗn hợp (MMoE) cho dữ liệu hồi quy đa cấp cho phép nhiều cấp độ hiệu ứng ngẫu nhiên. So với tài liệu hiện có (Yau et al. [2003], Ng và McLachlan [2007] và Ng và McLachlan [2014]), mô hình đề xuất của chúng tôi được rút gọn theo hai cách: (i) hiệu ứng ngẫu nhiên chỉ được tích hợp vào hàm cổng và được giả định là độc lập, và mô hình bao gồm hiệu ứng ngẫu nhiên khác nhau; (ii) liên kết hồi quy được loại bỏ khỏi hàm chuyên gia. Thứ hai, chúng tôi xây dựng định nghĩa tính trù mật cho lớp mô hình hiệu ứng hỗn hợp theo nghĩa hội tụ yếu, điều này

--- TRANG 4 ---
Mô hình hỗn hợp chuyên gia cho dữ liệu đa cấp: khung lý thuyết mô hình hóa và lý thuyết xấp xỉ

Hình 1: Cấu trúc dữ liệu đa cấp và khung mô hình hóa.

mở rộng trực tiếp từ Fung et al. [2019a] người xây dựng tính trù mật cho phân phối hồi quy. Thứ ba, chúng tôi chứng minh rằng lớp MMoE trù mật trong không gian của bất kỳ mô hình hiệu ứng hỗn hợp liên tục nào tuân theo một số điều kiện tính chính quy nhẹ. Điều này không chỉ chứng minh tính linh hoạt của mô hình đề xuất trong việc nắm bắt các khía cạnh khác nhau của đặc trưng dữ liệu đa cấp như phân phối kết hợp, mô hình hồi quy, chặn ngẫu nhiên và độ dốc ngẫu nhiên, mà còn gợi ý rằng mô hình đề xuất của chúng tôi tiết kiệm với cấu trúc rút gọn. So với Fung et al. [2019a], một số giả định cho định lý tính trù mật cũng được nới lỏng trong bài báo này. Ví dụ, tính liên tục Lipschitz và tính chặt chẽ của phân phối không còn được yêu cầu rõ ràng. Do đó, kỹ thuật chứng minh của bài báo này khá khác so với những kỹ thuật trong Fung et al. [2019a]. Thứ tư, trong trường hợp đặc biệt của dữ liệu phân cấp, chúng tôi chứng minh thêm rằng một phiên bản lồng nhau của MMoE có thể xấp xỉ chính xác một phạm vi rộng các cấu trúc phụ thuộc giữa các yếu tố cấp độ cao hơn và thấp hơn, ngay cả khi MMoE được xem xét là một lớp mô hình đơn giản chỉ bao gồm hiệu ứng ngẫu nhiên độc lập giữa các cấp độ. Kết quả này quan trọng đối với nhiều ứng dụng, e.g., tác động của lớp học đến thành tích của học sinh có thể phụ thuộc vào trường học mà học sinh đó theo học.

Trọng tâm của bài báo này là xây dựng mô hình MMoE cho dữ liệu đa cấp và chứng minh về mặt lý thuyết tính linh hoạt của nó. Trong một bài báo tiếp theo (Tseung et al. [2022]), chúng tôi sẽ giải quyết các vấn đề ước lượng và ứng dụng dưới MMoE đề xuất. Một thuật toán ECM biến phân ngẫu nhiên được đề xuất để ước lượng hiệu quả các tham số mô hình. Ngoài ra, MMoE được áp dụng cho một bộ dữ liệu bảo hiểm ô tô, chứng minh khả năng dự đoán hợp lý các yêu cầu bồi thường trong tương lai của người được bảo hiểm dựa trên lịch sử yêu cầu bồi thường trong quá khứ.

Bài báo này được cấu trúc như sau. Phần 2 định nghĩa một lớp tổng quát các mô hình hiệu ứng hỗn hợp cho dữ liệu đa cấp, bao gồm gần như tất cả mô hình hiệu ứng hỗn hợp trong tài liệu. Trong Phần 3, chúng tôi giới thiệu MMoE như một lớp ứng cử viên của mô hình hiệu ứng hỗn hợp để linh hoạt nắm bắt dữ liệu đa cấp. Giải thích và trực quan hóa mô hình đề xuất cũng được cung cấp. Phần 4 định nghĩa "tính trù mật" trong bối cảnh mô hình hiệu ứng hỗn hợp và chứng minh rằng MMoE là một bộ xấp xỉ tổng quát của hầu hết mô hình hiệu ứng hỗn hợp tuân theo một số điều kiện nhẹ. Trong Phần 5, chúng tôi thảo luận về xây dựng mô hình và tính chất tính trù mật trong trường hợp đặc biệt khi bộ dữ liệu có cấu trúc phân cấp với hiệu ứng ngẫu nhiên lồng nhau. Các phát hiện được tóm tắt trong Phần

--- TRANG 5 ---
Mô hình hỗn hợp chuyên gia cho dữ liệu đa cấp: khung lý thuyết mô hình hóa và lý thuyết xấp xỉ

7, kèm theo một số hạn chế của lý thuyết tính trù mật trong việc chứng minh khả năng xấp xỉ của MMoE được đề xuất.

2 Mô hình hiệu ứng hỗn hợp cho dữ liệu đa cấp

Các bộ dữ liệu có cấu trúc đa cấp thường được mô hình hóa bằng mô hình hiệu ứng hỗn hợp. Dưới khung mô hình hóa này, tác động của các đầu vào đã biết xi lên đầu ra yi được coi là "hiệu ứng cố định" hoặc "chia sẻ tham số cứng", trong khi L cấp độ yếu tố không quan sát được θi được coi là ngẫu nhiên (được xác định bởi một phân phối) và tác động của chúng lên yi được coi là "hiệu ứng ngẫu nhiên" hoặc "chia sẻ tham số mềm". Trong phần này, chúng tôi sẽ thảo luận một số chi tiết kỹ thuật về khung tổng quát của mô hình hiệu ứng hỗn hợp.

Cho (Ω;F;P) là không gian xác suất và giả sử rằng θl^(s) là một ánh xạ F-đo được từ (Ω;F) đến (Θl;Ql) cho mỗi l = 1;:::;L và s = 1;:::;Sl, trong đó Θl là không gian của θl^(s) hoặc θil. θl^(s) là một biến ngẫu nhiên nếu (Θl;Ql) = (R;R) trong đó R là một tập Borel, nhưng chúng ta không muốn áp đặt hạn chế như vậy. Đó là vì các yếu tố θl^(s) không được quan sát và chúng ta không chắc chắn liệu các yếu tố này có thể được định lượng thành một số thực hay không. Sử dụng các nghiên cứu lâm sàng làm ví dụ, không thể tóm tắt các đặc trưng không quan sát được của bệnh viện hoặc bác sĩ thành chỉ một số duy nhất vì tác động của chúng đến kết quả y tế của bệnh nhân rất phức tạp, có thể liên quan đến nhiều yếu tố ẩn không biết bao gồm thiết bị y tế và hỗ trợ tài chính của bệnh viện, cũng như học vấn và chuyên môn của bác sĩ. Không gian Θl cũng khác nhau giữa các mô hình hiệu ứng hỗn hợp khác nhau trong tài liệu. Ví dụ, Θl = R cho hầu hết GLMM (McGilchrist [1994]), Θl = R^(2g-1) cho mô hình GLMM MoE bởi Ng và McLachlan [2007], và Θl = R^(gK) cho mô hình hỗn hợp hiệu ứng ngẫu nhiên bởi Ng và McLachlan [2014].

Dưới mô hình hiệu ứng hỗn hợp tổng quát, chúng ta giả định rằng yi chỉ chịu ảnh hưởng trực tiếp bởi xi và θi. Có điều kiện trên xi và θi, tiếp tục được giả định rằng {yi}i=1;:::;N độc lập lẫn nhau. Cụ thể, chúng ta có

yi|xi;θi ind ~ H(·|xi;θi), i = 1;:::;N, (2)

trong đó H có thể là bất kỳ phân phối xác suất nào. Hình 1 cho thấy trực quan hóa của khung mô hình hóa.

Với những giả định này, phân phối kết hợp của y cho x được cho bởi

H̃(y|x) = ∫Θ̃ [∏i=1^N H(yi|xi;θi)] dP(θ̃) (3)

Giả sử rằng mỗi không gian đo được (Θl;Ql) cũng được trang bị bởi một độ đo xác suất Gl, tương ứng với "phân phối" của θl^(s). Ký hiệu thêm (Θ̃;Q̃;G) là tích của các không gian xác suất {(Θl;Ql;Gl)}l=1;:::;L;s=1;:::;Sl. Sau đó, phân phối kết hợp có thể được viết lại như

H̃(y|x) = ∫Θ̃ [∏i=1^N H(yi|xi;θi)] dG(θ̃), (4)

trong đó θ̃ = {θl^(s)}l=1;:::;L;s=1;:::;Sl. Lưu ý rằng khung mô hình trên bao gồm một phạm vi rất rộng các mô hình cho dữ liệu đa cấp hoặc phân cấp, bao gồm mô hình hiệu ứng hỗn hợp tuyến tính tổng quát (GLMM) và mô hình hiệu ứng hỗn hợp phi tuyến (xem, e.g., Goldstein [1986] và Davidian và Gallant [1993]). Vì không có hạn chế nào về dạng hàm của H và G, cấu trúc mô hình trên thực sự rất tổng quát,

--- TRANG 6 ---
Mô hình hỗn hợp chuyên gia cho dữ liệu đa cấp: khung lý thuyết mô hình hóa và lý thuyết xấp xỉ

tự động chứa bất kỳ phân phối kết hợp có thể nào của yi|xi;θi, liên kết hồi quy giữa xi và yi (bao gồm hiệu ứng phi tuyến và tương tác giữa các biến hiệp phương), tác động của các yếu tố không quan sát được θi lên yi một mình (được gọi là chặn ngẫu nhiên), và tương tác giữa θi và xi (được gọi là độ dốc ngẫu nhiên).

Vì chúng ta đã định nghĩa (Θ̃;Q̃;G) như một không gian xác suất tích, giả định sau đây đã được ngầm định về θl^(s):

Giả định 1. {θl^(s)}l=1;:::;L;s=1;:::;Sl độc lập lẫn nhau.

Do đó, G(θ̃) có thể được viết như

G(θ̃) = ∏l=1^L ∏s=1^Sl Gl(θl^(s)) hoặc dG(θ̃) = ∏l=1^L ∏s=1^Sl Gl(dθl^(s)). (5)

Lưu ý rằng giả định độc lập trước đó giữa các yếu tố trong một cấp độ (i.e., s = 1;:::;Sl) rất tự nhiên đối với hầu hết cấu trúc dữ liệu đặc biệt là những cấu trúc liên quan đến các phép đo lặp lại (xem, e.g., Goldstein [1986], Yau et al. [2003], Ng et al. [2004], Boucher và Denuit [2006], và Ng và McLachlan [2007]). Giả định độc lập trước đó giữa các cấp độ (i.e., l = 1;:::;L) cũng thường được giả định cho các bộ dữ liệu có cấu trúc đa cấp (xem, e.g., Goldstein [1986] và McGilchrist [1994]).

3 Mô hình hỗn hợp chuyên gia với hiệu ứng ngẫu nhiên

Mặc dù có tính tổng quát của mô hình hiệu ứng hỗn hợp trên (Phương trình (3)), việc xác định phù hợp dạng hàm của H và G để mô hình hóa một bộ dữ liệu đa cấp là thiết yếu. Tuy nhiên, điều này thách thức, đặc biệt khi không gian Θ̃ của các yếu tố tiềm ẩn θ̃ không được quan sát từ bộ dữ liệu. Nhớ lại rằng một bộ dữ liệu đa cấp chỉ cung cấp thông tin về cách mỗi quan sát được phân loại vào một trong các yếu tố cho mỗi cấp độ l, nhưng không về các yếu tố là gì hoặc cách định lượng các yếu tố này.

Trong phần này, chúng tôi giới thiệu mô hình hỗn hợp chuyên gia (MoE) với hiệu ứng ngẫu nhiên, được gọi là MoE hỗn hợp (MMoE), như một mô hình hồi quy ứng cử viên để phục vụ cấu trúc dữ liệu đa cấp. Việc chứng minh mô hình đề xuất, phân tích khả năng của MMoE trong việc xấp xỉ chính xác dạng tổng quát của mô hình hiệu ứng hỗn hợp (Phương trình (3)), sẽ được trình bày trong phần tiếp theo.

Dưới MMoE, chúng ta giả định rằng mỗi quan sát i được trang bị L cấp độ hiệu ứng ngẫu nhiên, ký hiệu bởi một L-vector wi = (wi1;:::;wiL). Tương tự như ánh xạ của các yếu tố không quan sát được θi được giới thiệu trong Phần 1, chúng ta cũng có wil = wi'l := wl^(s) nếu cl(i) = cl(i') = s. Điểm khác biệt duy nhất giữa θi và wi là chúng ta hạn chế wil ∈ R vào một không gian Euclidean thay vì một không gian tổng quát Θ̃, không biết và khó xác định. Tương tự như θ̃, chúng ta cũng định nghĩa w = {wl^(s)}l=1;:::;L;s=1;:::;Sl như các hiệu ứng ngẫu nhiên qua tất cả các cấp độ và yếu tố.

Hàm phân phối của yi có điều kiện trên xi và wi được cho bởi

F(yi;α;β;φ,g|xi;wi) = ∑j=1^g πj(xi;wi;α;β)F0(yi;φj), (6)

trong đó g là số lượng lớp tiềm ẩn, πj(xi;wi;α;β) là trọng số hỗn hợp cho lớp thứ j (được gọi là hàm cổng), α = {αj0;αj : j = 1;:::;g} ∈ A là các tham số hồi quy của hàm cổng, β = {βj : j = 1;:::;g} ∈ B là các hệ số của hiệu ứng ngẫu nhiên và φ = {φj : j = 1;:::;g} ∈ Φ

--- TRANG 7 ---
Mô hình hỗn hợp chuyên gia cho dữ liệu đa cấp: khung lý thuyết mô hình hóa và lý thuyết xấp xỉ

Hình 2: Cấu trúc mô hình của MMoE.

là các tham số của một phân phối đa biến F0 được xác định trước (được gọi là hàm chuyên gia). Chúng ta cũng xác định πj(xi;wi;α;β) như một hàm cổng logit tuyến tính, được cho bởi

πj(xi;wi;α;β) = exp{αj0+αj^T xi+βj^T wi}/∑j'=1^g exp{αj'0+αj'^T xi+βj'^T wi}, j = 1,2,...,g. (7)

Ngoài ra, các hiệu ứng ngẫu nhiên {wl^(s)}l=1;:::;L;s=1;:::;Sl được giả định độc lập giữa l và s, và wl^(s) tuân theo một phân phối Λl đã được xác định trước cố định không có tham số bổ sung trong đó. Dựa trên đặc tả mô hình trên, phân phối kết hợp của y cho x là

F̃(y,x) := F̃(y;α;β;φ,g|x) = ∫∏i=1^N F(yi;α;β;φ|xi;wi)dΛ(w), (8)

trong đó Λ là phân phối kết hợp của w, được cho bởi

Λ(w) = ∏l=1^L ∏s=1^Sl Λl(wl^(s)) hoặc dΛ(w) = ∏l=1^L ∏s=1^Sl Λl(dwl^(s)). (9)

Mô hình có thể được diễn giải như sau với minh họa hiển thị trong Hình 2. Mỗi quan sát được gán vào một trong g nhóm con đồng nhất với xác suất phân loại bằng các hàm cổng πj(xi;wi;α;β). Xác suất phân loại khác nhau giữa các quan sát vì chúng phụ thuộc vào cả đầu vào xi và các yếu tố không quan sát được wi. Có điều kiện trên nhóm con mà quan sát i thuộc về, các đầu ra yi được chi phối bởi một phân phối xác suất đồng nhất F0(yi;φj) độc lập với xi và wi.

--- TRANG 8 ---
Mô hình hỗn hợp chuyên gia cho dữ liệu đa cấp: khung lý thuyết mô hình hóa và lý thuyết xấp xỉ

Một trong những sự khác biệt đáng chú ý giữa mô hình trên và cấu trúc tiêu chuẩn của MoE (i.e., Phương trình (1)) là ở đây chúng ta loại bỏ mối quan hệ hồi quy trên các hàm chuyên gia (i.e., các hàm chuyên gia không phụ thuộc vào các đầu vào xi), được coi là MoE rút gọn (RMoE) bởi Fung et al. [2019a]. Ngoài ra, lưu ý rằng mô hình của chúng ta giả định rằng hiệu ứng ngẫu nhiên cấp độ-l wil giống nhau qua tất cả g hàm cổng (i.e., wil không phụ thuộc vào j). Giả định này khác với Ng và McLachlan [2007], người xem xét nhiều hiệu ứng ngẫu nhiên cấp độ-l độc lập khác nhau qua các hàm cổng.

Nhận xét 1. Khung mô hình hóa rút gọn được đề xuất có thể có lợi theo hai cách. Thứ nhất, chúng ta có thể chọn từ một phạm vi rộng các phân phối xác suất như hàm chuyên gia F0, bao gồm các lớp phân phối phi hàm mũ phức tạp hơn (e.g., phân phối phase-type) trong đó mô hình hóa hồi quy trên các phân phối này có thể không khả thi hoặc thách thức về mặt tính toán. Thứ hai, cấu trúc mô hình đơn giản thuận lợi cho việc diễn giải, vì mô hình đề xuất của chúng tôi cho phép phân nhóm các quan sát thành các nhóm con đồng nhất, và giải thích tính biến đổi của mỗi yếu tố cấp độ-l bằng một nguồn duy nhất (i.e., wil ∈ R) thay vì nhiều nguồn bởi Ng và McLachlan [2007].

Vấn đề còn lại là: cấu trúc rút gọn như vậy ảnh hưởng đến tính linh hoạt mô hình như thế nào? Để chứng minh cấu trúc mô hình đề xuất, chúng tôi sẽ chứng minh tính chất tính trù mật của mô hình đề xuất trong phần tiếp theo, có nghĩa là cấu trúc mô hình MMoE của Phương trình (8) có thể xấp xỉ bất kỳ dạng tổng quát nào của mô hình hiệu ứng hỗn hợp được biểu diễn bởi Phương trình (3). Điều này sẽ cung cấp bằng chứng gợi ý rằng mô hình đề xuất của chúng tôi tiết kiệm. Nói cách khác, MMoE có cấu trúc đơn giản nhất mà không làm tổn hại đến khả năng biểu diễn của nó.

4 Lý thuyết tính trù mật

Phần này nghiên cứu khả năng xấp xỉ của lớp mô hình MMoE. Mục tiêu của chúng tôi là cho thấy rằng MMoE đề xuất đủ linh hoạt để xấp xỉ bất kỳ mô hình hiệu ứng hỗn hợp nào dưới các điều kiện tính chính quy nhẹ, ngay cả khi MMoE được xây dựng dưới dạng rút gọn: (i) hàm cổng bị hạn chế là cổng logit tuyến tính; (ii) liên kết hồi quy được loại bỏ trong các hàm chuyên gia; (iii) các hiệu ứng ngẫu nhiên bị hạn chế tuân theo một số phân phối được xác định trước cố định. Trước đó, chúng ta cần xây dựng kỹ thuật một lớp mô hình hiệu ứng hỗn hợp và định nghĩa "tính trù mật" cho mô hình hiệu ứng hỗn hợp. Những định nghĩa này là phần mở rộng của Fung et al. [2019a], người định nghĩa "phân phối hồi quy" và "tính trù mật" trong thiết lập hồi quy mà không xem xét hiệu ứng ngẫu nhiên.

Ký hiệu T := T1 × ... × TL là một tập hợp của một số không gian của Θ := Θ1 × ... × ΘL, H là một tập hợp của một số hàm phân phối H trên (yi|xi;θi), và Gl là một tập hợp các độ đo xác suất Gl trên θl^(s) với G := G1 × ... × GL. Ngoài ra, cho C là một tập hợp chứa tất cả các ánh xạ có thể c(·), và định nghĩa một vector S = (S1;...;SL) với S = N^L. "Một lớp mô hình hiệu ứng hỗn hợp" và "phân phối hiệu ứng hỗn hợp" được định nghĩa đầu tiên như sau:

Định nghĩa 1. Một lớp mô hình hiệu ứng hỗn hợp ML(X;T;H;G) := {H̃(·;X;Θ;H;G) : Θl ∈ Tl;H ∈ H;Gl ∈ Gl;l = 1;...;L} là một tập hợp các phân phối hiệu ứng hỗn hợp H̃(·;X;Θ;H;G), trong đó mỗi phân phối hiệu ứng hỗn hợp H̃(·;X;Θ;H;G) := {H̃(y|x) := H̃(y|x;Θ;H;G) = ∫Θ̃ [∏i=1^N H(yi|xi;θi)] dG(θ̃) : xi ∈ X;i ∈ {1;...;N};N ∈ N;S ∈ S;c ∈ C} tự nó là một tập hợp các phân phối xác suất kết hợp.

--- TRANG 9 ---
Mô hình hỗn hợp chuyên gia cho dữ liệu đa cấp: khung lý thuyết mô hình hóa và lý thuyết xấp xỉ

Theo tinh thần của Fung et al. [2019a], tính trù mật được định nghĩa theo nghĩa hội tụ yếu của phân phối xác suất. Do đó, trước khi định nghĩa tính trù mật, chúng ta cần định nghĩa hội tụ yếu của phân phối hiệu ứng hỗn hợp như sau:

Định nghĩa 2. Xem xét một dãy phân phối hiệu ứng hỗn hợp {H̃^(n)} := H̃(·;X;Θ^(n);H^(n);G^(n)) và một phân phối hiệu ứng hỗn hợp mục tiêu H̃ := H̃(·;X;Θ;H;G). Chúng ta nói rằng {H̃^(n)}n=1,2,... hội tụ yếu đến H̃ khi và chỉ khi với mọi xi ∈ X cho trước (với mọi i ∈ {1;...;N}), N ∈ N, S ∈ S và c ∈ C, chúng ta có H̃(·|x;Θ^(n);H^(n);G^(n)) →^D H̃(·|x;Θ;H;G) khi n → ∞, trong đó →^D biểu thị hội tụ yếu hoặc hội tụ theo phân phối. Nếu hội tụ phân phối đều trên bất kỳ không gian đầu vào compact X ⊆ X, i.e. H̃(y|x;Θ^(n);H^(n);G^(n)) → H̃(y|x;Θ;H;G) đều trên (y;x) với xi ∈ X (với mọi i ∈ {1;...;N}), thì chúng ta nói rằng {H̃^(n)}n=1,2,... hội tụ yếu đến H̃ một cách compact.

Bây giờ, chúng ta có thể mở rộng hình thức của Fung et al. [2019a] và định nghĩa tính trù mật trong thiết lập của mô hình hiệu ứng hỗn hợp:

Định nghĩa 3. Xem xét hai lớp mô hình hiệu ứng hỗn hợp M1^L := ML(X;T1;H1;G1) và M2^L := ML(X;T2;H2;G2). M1^L trù mật trong M2^L khi và chỉ khi với mọi (Θ2;H2;G2) ∈ T2 × H2 × G2, tồn tại một dãy {(Θ1^(n);H1^(n);G1^(n))}n=1,2,... với (Θ1^(n);H1^(n);G1^(n)) ∈ T1 × H1 × G1 sao cho các phân phối hiệu ứng hỗn hợp {H̃1^(n) := H̃(·;X;Θ1^(n);H1^(n);G1^(n))}n=1,2,... hội tụ yếu đến H̃2 := H̃(·;X;Θ2;H2;G2). Nếu {H̃1^(n)}n=1,2,... hội tụ yếu đến H̃2 một cách compact, thì M1^L được gọi là compact trù mật trong M2^L.

Định nghĩa tính trù mật trên có nghĩa là bất kỳ mô hình hiệu ứng hỗn hợp nào trong lớp M2^L có thể được biểu diễn hoặc xấp xỉ tùy ý tốt bởi các mô hình trong lớp khác M1^L, theo nghĩa hội tụ yếu của phân phối kết hợp H̃(y|x) trên tất cả N quan sát. Ít kỹ thuật hơn, M1^L có thể được diễn giải như một lớp mô hình ít nhất cũng phong phú hoặc linh hoạt như lớp M2^L.

Với tất cả các định nghĩa liên quan được xây dựng, bây giờ chúng tôi xem xét một lớp mô hình hiệu ứng hỗn hợp tổng quát M^gen_L(X) := ML(X;T^gen;H^gen;G^gen) được biểu diễn dưới dạng Phương trình (3), trong đó T^gen (cũng được ký hiệu là T^gen := T1^gen × ... × TL^gen), H^gen và G^gen tất cả tương ứng với các tập hợp của bất kỳ không gian hoặc hàm nào thỏa mãn hai giả định kỹ thuật nhẹ sau:

Giả định 2. Mỗi không gian Θl ∈ T^gen_l được trang bị bởi một metric dl đầy đủ có thể tách được.

Giả định 3. Với mọi hàm phân phối xác suất H ∈ H^gen, H(yi|xi;θi) liên tục đối với (yi;xi;θi).

Bây giờ, chúng tôi chuyển sang lớp MMoE với một lựa chọn được xác định trước của hàm chuyên gia F0 và phân phối kết hợp của hiệu ứng ngẫu nhiên Λ. Chúng tôi biểu diễn lớp MMoE như M^MMoE_L(X;F0;Λ) := ML(X;T^MMoE;H^MMoE;G^MMoE), trong đó hai tập hợp T^MMoE_l = {R} và G^MMoE = {Λ} chỉ chứa một phần tử duy nhất mỗi cái. Ngoài ra, tập hợp các phân phối hiệu ứng hỗn hợp được cho bởi H^MMoE = {F(·;α;β;φ,g|·;·) : α ∈ A;β ∈ B; φ ∈ Φ;g ∈ N}, trong đó F được cho bởi dạng Phương trình (6). Chúng tôi cũng áp đặt hai hạn chế sau đây về lựa chọn F0 và Λ, những điều này thiết yếu cho tính chất tính trù mật của lớp mô hình MMoE:

Giả định 4. F0 thỏa mãn điều kiện tính trù mật được nêu bởi Mệnh đề 3.1 của Fung et al. [2019a], có nghĩa là với mọi δq ∈ R^K, tồn tại một dãy tham số {φ^(n)(δq)}n=1,2,... sao cho F0(·;φ^(n)(δq)) →^D δq khi n → ∞.

Giả định 5. Λl là một hàm phân phối liên tục với mọi l = 1;...;L.

--- TRANG 10 ---
Mô hình hỗn hợp chuyên gia cho dữ liệu đa cấp: khung lý thuyết mô hình hóa và lý thuyết xấp xỉ

Hai giả định trên không nhất thiết nhẹ. Như đã thảo luận trong Fung et al. [2019a], một số phân phối phổ biến, như phân phối Pareto và phân phối mũ, không thỏa mãn điều kiện tính trù mật dưới Giả định 4. Hơn nữa, Giả định 5 không giữ bất cứ khi nào chúng ta chọn bất kỳ phân phối rời rạc nào cho Λl. Tuy nhiên, lưu ý rằng hàm chuyên gia F0 và phân phối hiệu ứng ngẫu nhiên Λl đều được xác định trước, vì vậy chúng ta có quyền kiểm soát để chọn các hàm phù hợp thỏa mãn Giả định 4 và 5 trước khi mô hình hóa một bộ dữ liệu đa cấp thông qua MMoE. Ví dụ, có thể chọn phân phối Gamma, Weibull, log-normal, hoặc inverse-Burr làm hàm chuyên gia F0 (Fung et al. [2019a]), và chọn phân phối chuẩn làm phân phối hiệu ứng ngẫu nhiên Λl.

Chúng tôi bây giờ trình bày kết quả chính chứng minh khả năng biểu diễn của lớp mô hình MMoE được đề xuất. Bằng chứng xuất hiện trong Phụ lục.

Định lý 1. Giả sử rằng Giả định 1 đến 5 được thỏa mãn. Khi đó, M^MMoE_L(X;F0;Λ) compact trù mật trong M^gen_L(X).

Nhận xét 2. Định lý trên yêu cầu rằng phân phối mục tiêu H là một phân phối liên tục đối với yi (xem Giả định 3). Tuy nhiên, cũng quan trọng khi điều tra vào kết quả xấp xỉ cho phân phối rời rạc (xem e.g. Jiang và Tanner [1999b] và Fung et al. [2019a]). Như đã thảo luận bởi Norets et al. [2010], bất kỳ phân phối rời rạc nào có thể được biểu diễn bởi một phân phối tiềm ẩn liên tục. Sau đó, rõ ràng là Định lý 1 vẫn đúng cho phân phối rời rạc nếu điều kiện tính trù mật trong Giả định 4 được thay đổi từ δq ∈ R^K thành δq ∈ N^K.

Rõ ràng, tính chất tính trù mật cung cấp một chứng minh lý thuyết cho tính linh hoạt của MMoE trong việc đồng thời nắm bắt các đặc trưng mô hình khác nhau, bao gồm phân phối kết hợp (e.g., phân phối đa mode và phụ thuộc giữa các đầu ra), mô hình hồi quy (e.g., liên kết phi tuyến và tương tác giữa các biến hiệp phương), chặn ngẫu nhiên (e.g., tác động đặc biệt của các yếu tố không quan sát được đến các đầu ra) và độ dốc ngẫu nhiên (e.g., tương tác giữa các biến hiệp phương và hiệu ứng ngẫu nhiên). Kết quả là, tính chất tính trù mật chứng minh về mặt lý thuyết khả năng của MMoE trong việc có thể khớp và mô tả tốt bất kỳ dữ liệu đa cấp nào có thể được tạo ra trong một lớp phong phú của mô hình hiệu ứng hỗn hợp. Ngoài ra, vì mô hình đề xuất của chúng tôi có cấu trúc rút gọn (được giải thích trong phần trước), tính chất tính trù mật cũng gợi ý rằng mô hình đề xuất tiết kiệm.

5 Mô hình hiệu ứng hỗn hợp lồng nhau cho dữ liệu phân cấp

Mô hình hiệu ứng hỗn hợp lồng nhau là một trường hợp đặc biệt của mô hình được mô tả trong Phần 2 với nhiều hiệu ứng ngẫu nhiên. Cụ thể, L hiệu ứng ngẫu nhiên được phân cấp theo cách mà hiệu ứng ngẫu nhiên thứ nhất và thứ L tương ứng với cấp độ cao nhất và thấp nhất. Bất kỳ quan sát nào chia sẻ cùng một đơn vị hiệu ứng ngẫu nhiên cấp độ thấp hơn cũng phải có cùng đơn vị cấp độ cao hơn. Nếu các hiệu ứng ngẫu nhiên không lồng nhau, mô hình hiệu ứng hỗn hợp tương ứng được gọi là mô hình hiệu ứng hỗn hợp "giao thoa". Bài toán trường học (xem, e.g., Aitkin và Longford [1986]) là một ví dụ cổ điển trong đó các hiệu ứng ngẫu nhiên lồng nhau. Trong ví dụ này, có hai yếu tố ảnh hưởng đến thành tích của học sinh: Trường học và lớp học. Vì các bạn cùng lớp phải đến từ cùng một trường, chúng ta có L = 2 với "trường học" và "lớp học" tương ứng là cấp độ thứ nhất và thứ hai của hiệu ứng ngẫu nhiên.

Trước khi định nghĩa mô hình lồng nhau, thuận tiện hơn khi áp dụng một tập hợp ký hiệu thay thế để xác định các quan sát. Ký hiệu i = (i1;i2;...;iL+1) như một định danh của một quan sát, và il = (i1;i2;...;il) như một định danh đến cấp độ l. Ở đây, i1 là một nhãn của đơn vị yếu tố cấp độ-1. Với l = 2;3;...;L, il là một nhãn của đơn vị yếu tố cấp độ-l cho rằng các nhãn của (l-1) cấp độ yếu tố đầu tiên là il-1. iL+1 đại diện cho nhãn quan sát cho rằng L yếu tố được gắn nhãn bởi iL. Ví dụ, trong bài toán trường học với L = 2, i = (2;3;5) tương ứng với học sinh thứ năm của lớp thứ ba của trường thứ hai.

Hơn nữa, ký hiệu N0 là số lượng đơn vị yếu tố cấp độ-1, sao cho support của i1 được cho bởi I1 := {1;...;N0}. Với l = 2;3;...;L, định nghĩa Nil-1 là số lượng đơn vị yếu tố cấp độ-l trong đó (l-1) cấp độ yếu tố đầu tiên được gắn nhãn là il-1, sao cho support của il là Il := {il : il-1 ∈ Il-1;il = 1;...;Nil-1}. Tương tự, NiL là số lượng quan sát có iL là nhãn của L yếu tố. Sau đó, support của i là I := {i : iL ∈ IL;iL+1 = 1;...;NiL}. Ngoài ra, tổng số quan sát được cho bởi N = ∑i1=1^N0 ∑i2=1^Ni1 ... ∑iL=1^NiL-1 NiL. Một sơ đồ cây trong Hình 3 trực quan hóa cấu trúc của dữ liệu phân cấp lồng nhau.

Kết quả là, bộ dữ liệu đa cấp lồng nhau được cho bởi (y;x) := {(yi;xi)}i∈I, trong đó xi ∈ X ⊆ R^P và yi ∈ Y ⊆ R^K tương ứng là đầu vào và đầu ra của một quan sát được gắn nhãn là i ∈ I.

Trong phần này, chúng tôi sẽ định nghĩa lớp tổng quát của mô hình hiệu ứng hỗn hợp lồng nhau, xây dựng mô hình MMoE được đề xuất với hiệu ứng ngẫu nhiên lồng nhau, và xây dựng lý thuyết tính trù mật cho lớp MMoE lồng nhau.

5.1 Mô hình hiệu ứng hỗn hợp lồng nhau tổng quát

Tương tự như MMoE được định nghĩa trong Phần 2, dưới MMoE lồng nhau, phản hồi yi phụ thuộc vào các biến hiệp phương xi và L cấp độ yếu tố ngẫu nhiên tiềm ẩn θi1;...;θiL được minh họa trong Hình 3. Giả định phụ thuộc giữa các yếu tố tiềm ẩn được phát biểu như sau:

Giả định 6. Có điều kiện trên θi1;...;θiL, N quan sát độc lập. Tập hợp cha của θil được cho bởi pa(θil) = (θi1;...;θi(l-1)) với l = 1;...;L.

Nói cách khác, yếu tố cấp độ thấp hơn chỉ phụ thuộc trực tiếp vào các yếu tố cấp độ cao hơn tương ứng. Dưới cấu trúc dữ liệu phân cấp lồng nhau, chúng ta có thể nới lỏng giả định độc lập trong Giả định 1 bằng cách cho phép sự phụ thuộc của hiệu ứng ngẫu nhiên cấp độ thấp hơn vào cha của chúng (hiệu ứng cấp độ cao hơn). Với l = 1;...;L, chúng ta cũng ký hiệu Gl là phân phối của yếu tố cấp độ-l có điều kiện trên pa(θil).

Phân phối kết hợp của y cho x được cho bởi

H̃(y|x) = ∫Θ̃ [∏i∈I H(yi;xi|θi)] dG(θ̃) (10)

với

G(θ̃) = ∏i1=1^N0 G1(θi1) ∏i2=1^Ni1 G2(θi2|θi1) ... ∏iL=1^NiL-1 GL(θiL|θi1;...;θiL-1), (11)

trong đó θ̃ = {θil : il ∈ Il;l = 1;...;L}.

5.2 Mô hình hỗn hợp chuyên gia lồng nhau

Tương tự như MMoE được giới thiệu trong Phần 3, chúng tôi xây dựng MMoE lồng nhau cho dữ liệu phân cấp. Ký hiệu wi = (wi1;...;wiL) ∈ R^L là L cấp độ hiệu ứng ngẫu nhiên của quan sát i. Ngoài ra, định nghĩa w = {wil}il∈Il;l=1;...;L là tất cả hiệu ứng ngẫu nhiên được tổng hợp qua tất cả các quan sát. Với một thay đổi nhỏ

--- TRANG 11 ---
Mô hình hỗn hợp chuyên gia cho dữ liệu đa cấp: khung lý thuyết mô hình hóa và lý thuyết xấp xỉ

Hình 3: Cấu trúc dữ liệu phân cấp và khung mô hình hóa.

của ký hiệu từ Phương trình (6) và (7), hàm phân phối của yi có điều kiện trên xi và wi là

F(yi;α;β;φ,g|xi;wi) = ∑j=1^g πj(xi;wi;α;β)F0(yi;φj), (12)

trong đó hàm cổng được cho bởi

πj(xi;wi;α;β) = exp{αj0+αj^T xi+βj^T wi}/∑j'=1^g exp{αj'0+αj'^T xi+βj'^T wi}, j = 1,2,...,g. (13)

Tương tự như Phần 3, các hiệu ứng ngẫu nhiên {wil}l=1;...;L;il=1;...;Nil-1 được xây dựng để độc lập giữa l và il với wil ~ Λl. Việc xây dựng này được đơn giản hóa từ Giả định 6 của mô hình lồng nhau tổng quát trong đó các hiệu ứng ngẫu nhiên có thể phụ thuộc vào cha của chúng. Điều chỉnh từ Phương trình (8) và (9), phân phối kết hợp của y cho x là

F̃(y,x) := F̃(y;α;β;φ,g|x) = ∫∏i∈I F(yi;α;β;φ|xi;wi)dΛ(w), (14)

trong đó Λ là phân phối kết hợp của w được cho bởi

Λ(w) = ∏l=1^L ∏il∈Il Λl(wil) hoặc dΛ(w) = ∏l=1^L ∏il∈Il Λl(dwil). (15)

Từ Phương trình (15) trên, các hiệu ứng ngẫu nhiên vẫn được giả định độc lập dưới MMoE lồng nhau. Tuy nhiên, chúng tôi sẽ chỉ ra trong tiểu mục tiếp theo rằng đặc tả như vậy đủ để xấp xỉ sự phụ thuộc của hiệu ứng ngẫu nhiên cấp độ thấp hơn vào cha của chúng dưới cấu trúc dữ liệu phân cấp.

5.3 Lý thuyết tính trù mật cho MMoE lồng nhau

Tương tự như Phần 4, mong muốn phát triển một lý thuyết xấp xỉ cho MMoE lồng nhau trong không gian của mô hình hiệu ứng hỗn hợp lồng nhau tổng quát. Ký hiệu N̄ = (N0;{Ni1}i1∈I1;{Ni2}i2∈I2;...;{NiL}iL∈IL) là số lượng yếu tố thuộc về mỗi yếu tố cha cho mỗi cấp độ với N0 ∈ N và Nil ∈ N với l = 1;...;L, và N̄ chứa tất cả các kết hợp có thể của N̄. Các ký hiệu khác, trừ khi được chỉ định khác, nhất quán với những ký hiệu được định nghĩa bởi Phần 4. Các định nghĩa tương đương tương tự như Phần 4 cho cấu trúc dữ liệu phân cấp được liệt kê như sau:

Định nghĩa 4. Một lớp mô hình hiệu ứng hỗn hợp lồng nhau M̄L(X;T;H;G) := {H̃(·;X;Θ;H;G) : Θl ∈ Tl;H ∈ H;Gl ∈ Gl;l = 1;...;L} là một tập hợp các phân phối hiệu ứng hỗn hợp lồng nhau H̃(·;X;Θ;H;G), trong đó mỗi phân phối hiệu ứng hỗn hợp lồng nhau H̃(·;X;Θ;H;G) := {H̃(y|x) := H̃(y|x;Θ;H;G) = ∫Θ̃ ∏i∈I H(yi|xi;θi) dG(θ̃) : xi ∈ X;i ∈ I;N̄ ∈ N̄} tự nó là một tập hợp các phân phối xác suất kết hợp.

Định nghĩa 5. Xem xét một dãy phân phối hiệu ứng hỗn hợp lồng nhau {H̃^(n)} := H̃(·;X;Θ^(n);H^(n);G^(n)) và một phân phối hiệu ứng hỗn hợp lồng nhau mục tiêu H̃ := H̃(·;X;Θ;H;G). Chúng ta nói rằng {H̃^(n)}n=1,2,... hội tụ yếu đến H̃ khi và chỉ khi với mọi xi ∈ X cho trước (với mọi i ∈ I), N̄ ∈ N̄, chúng ta có H̃(·|x;Θ^(n);H^(n);G^(n)) →^D H̃(·|x;Θ;H;G) khi n → ∞, trong đó →^D biểu thị hội tụ yếu hoặc hội tụ theo phân phối. Nếu hội tụ phân phối đều trên bất kỳ không gian đầu vào compact X ⊆ X, i.e. H̃(y|x;Θ^(n);H^(n);G^(n)) → H̃(y|x;Θ;H;G) đều trên (y;x) với xi ∈ X (với mọi i ∈ {1;...;N}), thì chúng ta nói rằng {H̃^(n)}n=1,2,... hội tụ yếu đến H̃ một cách compact.

Định nghĩa tính trù mật cho cấu trúc dữ liệu phân cấp (mô hình hiệu ứng hỗn hợp lồng nhau) hoàn toàn giống như Định nghĩa 3. Định nghĩa M̄^gen_L(X) là lớp mô hình hiệu ứng hỗn hợp lồng nhau tổng quát được biểu diễn trong Phương trình (10), tuân theo Giả định 2 và 3. Cũng ký hiệu M̄^MMoE_L(X;F0;Λ) là lớp MMoE lồng nhau được cho bởi Phương trình (14). Chúng ta có định lý tính trù mật sau:

Định lý 2. Giả sử rằng Giả định 2 đến 6 đúng. Khi đó, M̄^MMoE_L(X;F0;Λ) compact trù mật trong M̄^gen_L(X).

Bằng chứng được chuyển đến Phụ lục B. Định lý 2 gợi ý rằng MMoE lồng nhau có tiềm năng xấp xỉ bất kỳ mô hình hiệu ứng hỗn hợp lồng nhau tổng quát nào một cách tùy ý chính xác, ngay cả khi các hiệu ứng ngẫu nhiên bị hạn chế độc lập dưới MMoE lồng nhau trong khi các hiệu ứng ngẫu nhiên dưới mô hình hiệu ứng hỗn hợp lồng nhau tổng quát có thể phụ thuộc (Giả định 6). Trái lại, dưới Định lý 1, MMoE chỉ có thể xấp xỉ mô hình hiệu ứng hỗn hợp với hiệu ứng ngẫu nhiên độc lập (Giả định 1). Do đó, cho rằng cấu trúc dữ liệu là phân cấp, Định lý 2 là một kết quả lý thuyết mạnh hơn Định lý 1.

6 Minh họa số học

Trong phần này, chúng tôi trình bày một ví dụ số học để chứng minh cách mô hình MMoE được đề xuất có thể xấp xỉ bất kỳ mô hình hiệu ứng hỗn hợp nào. Nhằm mục đích minh họa, tất cả các biến trong phần này sẽ một chiều, i.e. yi cho phản hồi, θ1 cho hiệu ứng ngẫu nhiên tổng quát, và w1 cho hiệu ứng ngẫu nhiên được sử dụng trong MMoE. Chúng tôi giả định không có biến hiệp phương xi vì lý do sẽ được giải thích sau. Trong phần tiếp theo, chúng tôi đầu tiên chứng minh cách xây dựng một MMoE sao cho phân phối có điều kiện của yi cho θ1 có thể được xấp xỉ tùy ý tốt bởi phân phối của yi cho w1 cho một quan sát duy nhất yi. Sau đó, chúng tôi thảo luận cách điều này liên quan đến tính chất tính trù mật của MMoE trong Định lý 1.

Chúng tôi đầu tiên xây dựng mô hình thật như sau. Xem xét Θ̃ = Θ1 = [-2;2] là không gian cho θ1. Hiệu ứng ngẫu nhiên tổng quát θ1 được giả định tuân theo Uniform(-2;2) với hàm phân phối G1(θ1) = (2+θ1)/4 và mật độ g1(θ1) = 1/4. Chúng tôi giả định yi|θ1 ~ Normal(θ1;1) với mật độ h(yi|θ1) = 1/√(2π) e^(-1/2(yi-θ1)^2).

Sau đó chúng tôi nhằm sử dụng MMoE để xấp xỉ mô hình thật được đề cập ở trên. Với MMoE, chúng tôi chọn W1 = R là không gian cho w1. Hiệu ứng ngẫu nhiên w1 trong MMoE được giả định là chuẩn tiêu chuẩn với hàm phân phối Λ1(·) và mật độ λ1(·). Ký hiệu f(yi|w1) là mật độ có điều kiện của yi cho w1. Chúng tôi nhằm xây dựng f(yi|w1) sao cho phân phối có điều kiện h(yi|θ1), ∀θ1 ∈ Θ1, có thể được xấp xỉ tùy ý tốt bởi f(yi|w1), ∃w1 ∈ W1.

Chúng tôi bắt đầu bằng cách rời rạc hóa cả Θ1 và W1 thành D1 cặp không gian con {Θ1,d1}d1=1,...,D1 và {W1,d1}d1=1,...,D1 sao cho G1(Θ1,d1) = Λ1(W1,d1) với d1 = 1;2;...;D1. Với mỗi Θ1,d1, chúng tôi chọn θ̃1,d1 ∈ Θ1,d1 sao cho h(y1|θ̃1,d1) là một xấp xỉ hợp lý của h(y1|θ1 ∈ Θ1,d1). Sau đó, mỗi h(y1|θ̃1,d1) được xấp xỉ bởi hỗn hợp hữu hạn sau

f(yi|w1) = ∑d1=1^D1 π(u)_d1(w1)h(y1|θ̃1,d1) (16)

trong đó các trọng số hỗn hợp được cho bởi

π(u)_d1(w1) = exp{u(α̃d1,0+α̃d1,1w1)}/∑d'1=1^D1 exp{u(α̃d'1,0+α̃d'1,1w1)}, d1 = 1;2;...;D1. (17)

Lưu ý Phương trình (16) chưa phải là công thức của MMoE, vì mỗi h(yi|θ̃1,d1) vẫn phụ thuộc vào θ̃1,d1. Theo cùng ý tưởng trong Fung et al. [2019a], Phụ lục A cho thấy rằng h(yi|θ̃1,d1) có thể được xấp xỉ thêm bởi một hỗn hợp hữu hạn của các hàm chuyên gia với các tham số cố định độc lập với hiệu ứng ngẫu nhiên, cuối cùng dẫn đến một MMoE tương tự như Phương trình (6). Chúng tôi sẽ bỏ qua các thủ tục xấp xỉ như vậy và làm việc với Phương trình (16) để tránh các phức tạp thêm không liên quan đến hiệu ứng ngẫu nhiên. Trong khi đó, các thủ tục xấp xỉ trong sự hiện diện của biến hiệp phương xi cũng tương tự như những gì được trình bày trong Fung et al. [2019a] và do đó được hoãn lại đến Phụ lục A, đó là lý do tại sao chúng tôi đã trình bày một ví dụ không có biến hiệp phương để ngắn gọn.

Ngoài h(yi|θ̃1,d1), các trọng số hỗn hợp π(u)_d1(w1) trong Phương trình (17) chứa một tham số điều khiển bổ sung u so với MMoE. Khi các hệ số {(α̃d1,0;α̃d1,1)}d1=1;2;...;D1 được xây dựng cẩn thận, π(u)_d1(w1) → 1{w1 ∈ W1,d1} khi u → ∞ với d1 = 1;2;...;D1. Kết quả là, hỗn hợp hữu hạn trong Phương trình (16) thoái hóa thành h(yi|θ̃1,d1) bất cứ khi nào w1 ∈ W1,d1 và u → ∞.

Tóm lại, cho Θ1,d1, chúng tôi đầu tiên xấp xỉ h(yi|θ1 ∈ Θ1,d1) bởi h(yi|θ̃1,d1) với θ̃1,d1 ∈ Θ1,d1. Sau đó, h(yi|θ̃1,d1) được xấp xỉ thêm bởi f(yi|w1 ∈ W1,d1), được thực hiện cho tất cả các cặp (Θ1,d1;W1,d1). Thực tế, không gian con W1,d1 của hiệu ứng ngẫu nhiên w1 trong MMoE trở nên chuyên biệt trong việc xấp xỉ không gian con Θ1,d1 của một số hiệu ứng ngẫu nhiên tổng quát θ1. Khi phân chia của (Θ1,d1;W1,d1) trở nên tinh tế hơn, chúng ta có thể tìm một ánh xạ θ1 → W1 sao cho phân phối có điều kiện h(yi|θ1) với bất kỳ θ1 ∈ Θ1 có thể được xấp xỉ bởi f(yi|w1) với w1 ∈ W1 nào đó.

Như một ví dụ cụ thể, Bảng 1 minh họa quy trình trên với D1 = 5 phân vùng cho Θ1 và W1, trong đó chúng tôi chọn điểm giữa θ̃1,d1 như giá trị đại diện cho không gian con Θ1,d1. Các giá trị của {(α̃d1,0;α̃d1,1)}d1=1;2;...;D1 được chọn theo Bổ đề 3.1 trong Fung et al. [2019a] để đảm bảo sự hội tụ của trọng số hỗn hợp π(u)_d1(w1) đến các chỉ số thoái hóa 1{w1 ∈ W1,d1}. Ví dụ này được minh họa bởi hàng thứ hai trong Hình 4, trong đó mỗi lát dọc của biểu đồ cho thấy phân phối có điều kiện của f(yi|w1) (màu xanh) với u = 1;10;100 và 1000 từ trái sang phải, và h(yi|θ1 ∈ Θ1,d1) (màu xanh lá) với d1 = 1;2;...;5. Thực sự, chúng ta quan sát thấy mỗi f(yi|w1 ∈ W1,d1) xấp xỉ h(yi|θ1 ∈ Θ1,d1) tương ứng tốt hơn khi u tăng. Hàng thứ ba và thứ tư của Hình 4 cho thấy cùng các tập hợp biểu đồ, nhưng với D1 = 10 và D1 = 100 phân vùng cho cả Θ1 và W1. Tuy nhiên, nếu số phân vùng quá nhỏ, MMoE sẽ đánh giá thấp phương sai của yi cho w1 so với phương sai của yi cho θ1 dưới mô hình thật, ngay cả khi u → ∞, như được hiển thị trong hàng đầu tiên của Hình 4 với D1 = 2. Trong trường hợp giới hạn khi phân vùng trở nên vô hạn tinh tế, chúng ta có thể tìm một f(yi|w1) duy nhất để xấp xỉ h(yi|θ1) với mọi θ1 ∈ Θ1. Ví dụ, phân phối có điều kiện h(yi|θ1 = 1) trong mô hình hiệu ứng hỗn hợp gốc cuối cùng sẽ được xấp xỉ bởi f(yi|w1 = 0.67) trong MMoE.

Cuối cùng, một khi phân phối có điều kiện h(yi|θ1) có thể được xấp xỉ bởi f(yi|w1), tính chất tính trù mật trong Định lý 1 tự nhiên tiếp theo. Cụ thể hơn, cho giả định độc lập có điều kiện trong Phương trình (2), phân phối kết hợp có điều kiện của ∏i=1^N h(yi|θi) cũng có thể được xấp xỉ tùy ý tốt bởi ∏i=1^N f(yi|wi), trong đó θi và wi cho mỗi quan sát yi được xác định bởi θ1, w1 và hàm ánh xạ c1(i). Trong trường hợp phân vùng hữu hạn của không gian con {Θ1,d1}d1=1,...,D1 và {W1,d1}d1=1,...,D1 sao cho G1(Θ1,d1) = Λ1(W1,d1) với d1 = 1;2;...;D1, phân phối kết hợp biên của tất cả yi cũng được xấp xỉ tùy ý tốt, điều này rõ ràng từ

f(Y) = ∑d1=1^D1 [∏i=1^N h(yi|θi)1{θi ∈ Θ1,d1}] G1(Θ1,d1) (18)

và

g(Y) = ∑d1=1^D1 [∏i=1^N f(yi|wi)1{wi ∈ W1,d1}] Λ1(W1,d1). (19)

Trong kịch bản giới hạn khi phân vùng của Θ1 và W1 trở nên vô hạn tinh tế, các phương trình trên khôi phục dạng tích phân trong Phương trình (4) và (8), do đó chứng minh tính chất tính trù mật của MMoE trong Định lý 1.

7 Thảo luận

Trong bài báo này, chúng tôi giới thiệu một lớp mô hình hỗn hợp chuyên gia hỗn hợp (MMoE) cho dữ liệu hồi quy đa cấp. Chúng tôi chứng minh rằng MMoE trù mật trong không gian của mô hình hiệu ứng hỗn hợp tổng quát, một lớp phong phú chứa hầu hết tất cả mô hình trong tài liệu có hiệu ứng ngẫu nhiên độc lập, theo nghĩa hội tụ yếu. Chúng tôi nghiên cứu thêm một trường hợp đặc biệt khi dữ liệu có cấu trúc phân cấp. Trong trường hợp này, MMoE lồng nhau được đề xuất được chỉ ra là trù mật trong không gian của mô hình hiệu ứng hỗn hợp lồng nhau tổng quát trong đó các hiệu ứng ngẫu nhiên có thể phụ thuộc. Hai định lý tính trù mật chứng minh tính linh hoạt của MMoE trong việc phục vụ một phạm vi rộng các đặc trưng dữ liệu đa cấp, bao gồm phân phối biên, phụ thuộc, liên kết hồi quy, chặn ngẫu nhiên và độ dốc ngẫu nhiên.

Bài báo này nhằm chứng minh các kết quả tổng quát nhất áp đặt các giả định tối thiểu. Hạn chế thực tế duy nhất là hàm chuyên gia F0(yi;φj) trong Phương trình (6) cần xấp xỉ bất kỳ phân phối thoái hóa nào (Giả định 4). Giả định này yếu hơn nhiều so với những giả định được áp dụng cho các định lý xấp xỉ hiện có (xem, e.g, Norets và Pelenis [2014] và Nguyen et al. [2019]), yêu cầu rằng hàm mật độ chuyên gia là một hàm đối xứng có thể mở rộng (Phương trình (3.1) của Norets và Pelenis [2014]), và hàm mật độ mục tiêu không thay đổi đột ngột w.r.t. yi và xi (Phương trình (3.2) của Norets và Pelenis [2014]). Mặt khác, có một số hạn chế của các định lý tính trù mật được xây dựng trong bài báo này. Thứ nhất, hội tụ yếu

--- TRANG 12 ---
Mô hình hỗn hợp chuyên gia cho dữ liệu đa cấp: khung lý thuyết mô hình hóa và lý thuyết xấp xỉ

Bảng 1: Ví dụ về xấp xỉ với năm phân vùng của Θ1 và W1.

d1 | 1 | 2 | 3 | 4 | 5
Θ1,d1 | [-2.00;-1.20] | (-1.20;-0.40] | (-0.40;0.40] | (0.40;1.20] | (1.20;2.00]
W1,d1 | (-∞;-0.84] | (-0.84;-0.25] | (-0.25;0.25] | (0.25;0.84] | (0.84;+∞)
θ̃1,d1 | -1.60 | -0.80 | 0.00 | 0.80 | 1.60
α̃d1,0 | 0.00 | 0.23 | 0.29 | 0.23 | 0.00
α̃d1,1 | 0.00 | 0.25 | 0.50 | 0.75 | 1.00

Hình 4: Minh họa về việc sử dụng f(yi|w1) (màu xanh) để xấp xỉ h(yi|θ1 ∈ Θ1,d1) (màu xanh lá) cho các số phân vùng khác nhau của Θ1 và W1. Mỗi lát dọc tương ứng với mật độ có điều kiện của f(yi|w1) hoặc h(yi|θ1 ∈ Θ1,d1). Từ trái sang phải, tham số điều khiển u từ 1, 10, 100 đến 1000 trong các biểu đồ màu xanh, và cuối cùng f(yi|w1) = h(yi|θ1 ∈ Θ1,d1) với mọi w1 ∈ W1,d1 khi u → ∞. Từ trên xuống dưới, số phân vùng D1 từ 2, 5, 10 đến 100. Khi phân vùng trở nên vô hạn tinh tế và u → ∞, mỗi h(yi|θ1) được xấp xỉ tùy ý tốt bởi f(yi|w1) nào đó, e.g. h(yi|θ1 = 1) = f(yi|w1 = 0.67).

--- TRANG 13 ---
Mô hình hỗn hợp chuyên gia cho dữ liệu đa cấp: khung lý thuyết mô hình hóa và lý thuyết xấp xỉ

không đảm bảo khả năng xấp xỉ về mặt moment (e.g., hàm trung bình được nghiên cứu bởi Nguyen et al. [2016]) hoặc một số metric khoảng cách (e.g., phân kỳ KL được nghiên cứu bởi Jiang và Tanner [1999a], Norets et al. [2010] và Nguyen et al. [2019]). Để thiết lập các định lý tính trù mật w.r.t. moment và các metric khoảng cách khác, người ta cần giả định thêm rằng các moment của hàm chuyên gia MMoE và phân phối mục tiêu hữu hạn, và các điều kiện được chỉ ra bởi Phương trình (3.1) và (3.2) của Norets và Pelenis [2014] được thỏa mãn. Thứ hai, như được mô tả trong Phần 3.4 của Fung et al. [2019a], các định lý tính trù mật không cung cấp tốc độ hội tụ, vì vậy không có kiểm soát đối với các thành phần hỗn hợp g để xấp xỉ bất kỳ phân phối hiệu ứng hỗn hợp tổng quát nào ở mức độ chính xác mong muốn. Để thiết lập các kết quả tốc độ, người ta cần áp đặt các giả định thêm về phân phối mục tiêu H̃(y|x) trong Phương trình (4) và phân phối MMoE F̃(y,x) trong Phương trình (8). Chúng tôi để lại các thiết lập kỹ thuật này như một hướng nghiên cứu tương lai.

8 Lời cảm ơn

Nghiên cứu này không nhận được bất kỳ khoản tài trợ cụ thể nào từ các cơ quan tài trợ trong lĩnh vực công cộng, thương mại, hoặc phi lợi nhuận.

Tài liệu tham khảo

[Danh sách tài liệu tham khảo tiếp theo...]

Phụ lục A Chứng minh Định lý 1

[Nội dung chứng minh...]

Phụ lục B Chứng minh Định lý 2

[Nội dung chứng minh...]

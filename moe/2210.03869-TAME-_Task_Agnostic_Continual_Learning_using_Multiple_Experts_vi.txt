# 2210.03869.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/moe/2210.03869.pdf
# Kích thước tệp: 2944788 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
TAME: Học liên tục bất khả tri nhiệm vụ sử dụng nhiều chuyên gia
Haoran Zhu1∗Maryam Majzoubi2∗Arihant Jain1∗Anna Choromanska1
1Đại học New York2Google
{hz1922, aj2622, ac5455 }@nyu.edu maryam.majzoubi@gmail.com
Tóm tắt
Mục tiêu của học suốt đời là học liên tục từ các phân phối không dừng, trong đó tính không dừng thường được áp đặt bởi một chuỗi các nhiệm vụ riêng biệt. Các nghiên cứu trước đây chủ yếu xem xét các cài đặt lý tưởng, trong đó danh tính của các nhiệm vụ được biết ít nhất trong quá trình huấn luyện. Trong bài báo này, chúng tôi tập trung vào một cài đặt khó khăn hơn về cơ bản, được gọi là bất khả tri nhiệm vụ, trong đó danh tính nhiệm vụ không được biết và máy học cần suy luận chúng từ các quan sát. Thuật toán của chúng tôi, mà chúng tôi gọi là TAME (Học liên tục bất khả tri nhiệm vụ sử dụng nhiều chuyên gia), tự động phát hiện sự thay đổi trong phân phối dữ liệu và chuyển đổi giữa các mạng chuyên gia nhiệm vụ theo cách trực tuyến. Khi huấn luyện, chiến lược chuyển đổi giữa các nhiệm vụ dựa trên một quan sát cực kỳ đơn giản rằng đối với mỗi nhiệm vụ mới đến, xảy ra một độ lệch có ý nghĩa thống kê trong giá trị của hàm mất mát đánh dấu sự khởi đầu của nhiệm vụ mới này. Khi suy luận, việc chuyển đổi giữa các chuyên gia được điều chỉnh bởi mạng bộ chọn chuyển tiếp mẫu thử nghiệm đến mạng chuyên gia có liên quan của nó. Mạng bộ chọn được huấn luyện trên một tập con nhỏ dữ liệu được rút ra ngẫu nhiên đồng đều. Chúng tôi kiểm soát sự tăng trưởng của các mạng chuyên gia nhiệm vụ cũng như mạng bộ chọn bằng cách sử dụng cắt tỉa. Kết quả thực nghiệm của chúng tôi cho thấy hiệu quả của phương pháp trên các tập dữ liệu học liên tục chuẩn, vượt trội hơn các phương pháp bất khả tri nhiệm vụ trước đây và thậm chí các kỹ thuật chấp nhận danh tính nhiệm vụ ở cả huấn luyện và thử nghiệm, đồng thời sử dụng kích thước mô hình tương đương.

1. Giới thiệu
Các tác nhân học được triển khai trong các ứng dụng thế giới thực được tiếp xúc với một dòng thông tin liên tục có sẵn tăng dần thường từ các phân phối dữ liệu không dừng. Tác nhân được yêu cầu học thích ứng theo thời gian bằng cách chứa đựng kinh nghiệm mới trong khi bảo tồn kiến thức đã học trước đó. Điều này được gọi là học suốt đời hoặc học liên tục, đây là một thách thức lâu đời trong trí tuệ nhân tạo, bao gồm cả học sâu [8, 30, 39].

Trong kịch bản học suốt đời thường được xem xét, trong đó các nhiệm vụ đến tuần tự và mỗi nhiệm vụ là một chuỗi các sự kiện từ cùng một phân phối, một trong những thách thức chính là khắc phục quên lãng thảm khốc, trong đó việc huấn luyện mô hình trên một nhiệm vụ mới can thiệp vào kiến thức đã có trước đó và dẫn đến suy giảm hiệu suất trên các nhiệm vụ đã thấy trước đó. Các mạng nơ-ron sâu thường thực hiện tốt các nhiệm vụ phân loại, nhưng chúng phụ thuộc rất nhiều vào việc có các mẫu dữ liệu i.i.d. được rút ra từ phân phối dừng trong thời gian huấn luyện [7, 17, 33]. Trong trường hợp các nhiệm vụ tuần tự, hiệu suất của chúng giảm đáng kể khi học các nhiệm vụ mới đến [14, 24–26, 30].

Một số phương pháp đã được đề xuất trong tài liệu để đối phó với quên lãng thảm khốc. Một số nghiên cứu [11, 40] cung cấp phân loại hệ thống của các khung học liên tục và xác định ba kịch bản khác nhau: học nhiệm vụ tăng dần, học miền tăng dần, và học lớp tăng dần, trong đó sự khác biệt của chúng bắt nguồn từ tính khả dụng của nhãn nhiệm vụ khi thử nghiệm và số lượng đầu ra. Trong học lớp và miền tăng dần, danh tính nhiệm vụ không được biết trong quá trình thử nghiệm. Tuy nhiên, tất cả các kịch bản này đều dựa trên giả định rằng nhãn nhiệm vụ được biết trong giai đoạn huấn luyện. Giả định này có tính hạn chế trong các ứng dụng thế giới thực thực tế, trong đó tác nhân cần học trong một cài đặt bất khả tri nhiệm vụ thách thức hơn [18, 31, 32, 44]. Trong cài đặt học này, danh tính nhiệm vụ không có sẵn ở cả thời gian huấn luyện và suy luận. Tài liệu bắt đầu khám phá cài đặt này gần đây và cài đặt này là trọng tâm của bài báo chúng tôi.

Trong nghiên cứu này, chúng tôi trình bày một phương pháp xử lý học liên tục bất khả tri nhiệm vụ được lấy cảm hứng từ các phương pháp cũ hơn dành cho việc học các chuỗi không dừng dựa trên lời khuyên của chuyên gia [10, 27, 28], khám phá và khai thác các chuyển đổi gián đoạn giữa các quá trình dừng riêng biệt. Trong các phương pháp này, người học có thể đưa ra dự đoán dựa trên một tập hợp chuyên gia cố định. Vì người học không biết cơ chế mà các chuyên gia đưa ra dự đoán của họ, nó phải khai thác thông tin thu được bằng cách quan sát tổn thất của các chuyên gia. Dựa trên tổn thất của các chuyên gia, nó cân bằng các chuyên gia để giảm thiểu những người thực hiện kém và nhấn mạnh những người tốt, và tạo thành dự đoán cuối cùng như tổng có trọng số của các dự đoán của chuyên gia. Do đó, người học cần xác định chuyên gia tốt nhất tại mỗi thời điểm và chuyển đổi giữa các chuyên gia khi xảy ra chuyển đổi nhiệm vụ. arXiv:2210.03869v2 [cs.LG] 2 Jun 2024

--- TRANG 2 ---
Hình 1. Độ lệch của giá trị hàm mất mát của chuyên gia khi nhiệm vụ được chuyển đổi

Trong các nghiên cứu được đề cập ở trên, trọng số trên các chuyên gia là những người mang duy nhất bộ nhớ của các kinh nghiệm trước đó. Ngoài ra, các phương pháp được thảo luận dựa trên giả định rằng số lượng chuyên gia/nhiệm vụ được biết trước. Cuối cùng, các phương pháp này không xem xét giai đoạn huấn luyện và thử nghiệm riêng biệt, mà thay vào đó quá trình tối ưu hóa của chúng tập trung vào việc giảm thiểu hối tiếc, đó là sự khác biệt giữa tổn thất tích lũy của thuật toán và tổn thất của phương pháp tốt nhất trong cùng một lớp, được chọn trong tầm nhìn sau (tầm nhìn sau đề cập đến kiến thức đầy đủ về chuỗi cần dự đoán). Tuy nhiên, việc giảm thiểu hối tiếc không tương đương với việc chống lại quên lãng thảm khốc vì các nhiệm vụ trước đó có ít liên quan đến những nhiệm vụ hiện tại được học dần bị ghi đè trong bộ nhớ. Do đó, các phương pháp này không thể áp dụng trực tiếp cho cài đặt học liên tục.

Được thúc đẩy bởi việc có một tập hợp chuyên gia đại diện cho một chuỗi các nhiệm vụ, trong đó mỗi nhiệm vụ về cơ bản là một phân đoạn dừng của một phân phối không dừng dài hơn, chúng tôi đề xuất một hệ thống học ban đầu bắt đầu với một chuyên gia và dần dần thêm hoặc chuyển đổi giữa các chuyên gia khi các nhiệm vụ thay đổi. Trong giai đoạn huấn luyện trực tuyến, thuật toán của chúng tôi tự động xác định khi nào nhiệm vụ chuyển đổi và chọn hoặc tạo ra chuyên gia tốt nhất cho một nhiệm vụ mới, tùy thuộc vào việc nhiệm vụ này đã được thấy trước đó hay chưa. Việc phát hiện chuyển đổi nhiệm vụ dựa trên độ lệch có ý nghĩa thống kê của giá trị hàm mất mát của chuyên gia hiện tại, đánh dấu sự khởi đầu của nhiệm vụ mới (xem Hình 1). Tương tự, việc xác định xem nhiệm vụ đã được thấy trước đó hay chưa dựa trên hành vi của các hàm mất mát của từng chuyên gia (nếu độ lệch của tất cả các giá trị mất mát của từng chuyên gia đều cao, chuyên gia mới được tạo ra để đại diện cho nhiệm vụ hiện tại). Cơ chế phát hiện đơn giản như vậy được lấy cảm hứng từ tài liệu lời khuyên chuyên gia cổ điển được thảo luận trong đoạn trước, trong đó việc chuyển đổi giữa các chuyên gia được điều chỉnh bởi các giá trị của các hàm mất mát của các chuyên gia. Hơn nữa, chúng tôi giới thiệu mạng bộ chọn dự đoán danh tính nhiệm vụ của các mẫu tại thời gian suy luận. Mạng bộ chọn được huấn luyện trên một tập con nhỏ các ví dụ huấn luyện được lấy mẫu ngẫu nhiên đồng đều từ các nhiệm vụ khác nhau trong quá trình học. Bất chấp sự đơn giản của phương pháp của chúng tôi, nó dẫn đến một thuật toán học liên tục bất khả tri nhiệm vụ so sánh thuận lợi với các phương pháp hiện có và chứng minh rằng một tài liệu lịch sử phong phú về xử lý trực tuyến các chuỗi không dừng có thể cung cấp các công cụ xử lý tín hiệu hữu ích để giải quyết các thách thức trong ngành học liên tục hiện đại.

Phần còn lại của bài báo được tổ chức như sau: Phần 2 thảo luận về nghiên cứu có liên quan nhất. Phần 3 giới thiệu thuật toán của chúng tôi mà chúng tôi gọi là TAME: Học liên tục bất khả tri nhiệm vụ sử dụng nhiều chuyên gia. Phần 4 báo cáo kết quả thực nghiệm trên các tập dữ liệu học liên tục chuẩn, và cuối cùng Phần 5 kết luận bài báo.

2. Nghiên cứu liên quan
Trong những năm gần đây, đã có rất nhiều kỹ thuật được đề xuất cho học liên tục giảm thiểu vấn đề quên lãng thảm khốc trong các mạng nơ-ron sâu. Các phương pháp hiện có có thể được chia thành ba loại: i) hệ thống học bổ sung và phương pháp phát lại bộ nhớ, ii) phương pháp dựa trên chính quy hóa, và iii) phương pháp kiến trúc động. Các kỹ thuật này không dành riêng cho kịch bản bất khả tri nhiệm vụ vì chúng giả định danh tính của các nhiệm vụ được cung cấp ít nhất trong giai đoạn huấn luyện. Mặt khác, cài đặt học liên tục bất khả tri nhiệm vụ thách thức hơn chỉ được giải quyết gần đây trong một số ít bài báo. Chúng tôi xem xét chúng trước vì bài báo của chúng tôi xem xét cùng một cài đặt. Để hoàn thiện, chúng tôi cũng thảo luận về các nghiên cứu liên quan nhất từ tài liệu học liên tục rộng lớn và tham khảo người đọc đến một bài báo khảo sát [30] cung cấp đánh giá toàn diện hơn về các phương pháp này.

Học liên tục bất khả tri nhiệm vụ Trong bối cảnh cài đặt học có giám sát, là trọng tâm của bài báo này, một trong những phương pháp đầu tiên giải quyết học liên tục bất khả tri nhiệm vụ là thuật toán Giảm dần Gradient Bayesian, được biết đến phổ biến là BGD [44]. Phương pháp này dựa trên phiên bản trực tuyến của Bayes biến phân và đề xuất quy tắc cập nhật học Bayesian cho trung bình và phương sai của mỗi tham số. Như tất cả các phương pháp Bayesian, phương pháp này chống lại quên lãng thảm khốc bằng cách sử dụng phân phối hậu nghiệm của các tham số cho nhiệm vụ trước đó làm tiền nghiệm cho nhiệm vụ mới. BGD thu được kết quả thực nghiệm hứa hẹn nhất trong cài đặt, trong đó phương pháp dựa trên cái gọi là "thủ thuật nhãn" trong đó danh tính nhiệm vụ được suy luận từ nhãn lớp. Tuy nhiên, thủ thuật nhãn phá vỡ giả định bất khả tri nhiệm vụ. Một phương pháp khác được gọi là iTAML [31] đề xuất sử dụng meta-learning để duy trì một tập hợp các tham số tổng quát đại diện cho tất cả các nhiệm vụ. Khi được trình bày với một liên tục dữ liệu tại suy luận, mô hình tự động xác định nhiệm vụ và nhanh chóng thích ứng với nó chỉ với một lần cập nhật duy nhất. Tuy nhiên, khi huấn luyện vòng lặp trong của thuật toán họ, tạo ra các mô hình cụ thể cho từng nhiệm vụ sau đó được kết hợp trong vòng lặp ngoài để tạo thành một mô hình tổng quát hơn, yêu cầu kiến thức về nhãn nhiệm vụ. Tại suy luận, nhiệm vụ được dự đoán bằng cách sử dụng các tham số mô hình tổng quát. Cụ thể, đối với mỗi mẫu trong liên tục, kết quả của mô hình chung được thu được và phản hồi tối đa trên mỗi nhiệm vụ được ghi lại. Trung bình của các phản hồi tối đa trên mỗi nhiệm vụ được sử dụng làm điểm số nhiệm vụ. Một nhiệm vụ với điểm số tối đa cuối cùng được dự đoán. iTAML chống lại quên lãng thảm khốc bằng cách giữ một bộ đệm bộ nhớ các mẫu từ các nhiệm vụ khác nhau và sử dụng nó để tinh chỉnh các tham số tổng quát đại diện cho tất cả các nhiệm vụ thành một nhiệm vụ hiện tại được thấy. Phương pháp này không phải là bất khả tri nhiệm vụ, vì nó yêu cầu nhãn nhiệm vụ khi huấn luyện, mặc dù các tác giả phân loại phương pháp của họ là bất khả tri nhiệm vụ. CN-DPM [18] là một phương pháp dựa trên mở rộng loại bỏ quên lãng thảm khốc bằng cách phân bổ tài nguyên mới để học dữ liệu mới. Họ công thức hóa vấn đề học liên tục bất khả tri nhiệm vụ như một suy luận biến phân trực tuyến của các mô hình hỗn hợp quá trình Dirichlet bao gồm một tập hợp các chuyên gia nơ-ron. Mỗi chuyên gia phụ trách một tập con của dữ liệu. Mỗi chuyên gia được liên kết với một mô hình phân biệt (bộ phân loại) và một mô hình tạo sinh (bộ ước tính mật độ). Đối với một mẫu mới, trước tiên họ quyết định xem mẫu nên được gán cho một chuyên gia hiện có hay một chuyên gia mới nên được tạo ra cho nó. Điều này được thực hiện bằng cách tính toán điểm trách nhiệm của các chuyên gia cho mẫu được xem xét và được hỗ trợ bởi bộ nhớ ngắn hạn (STM) thu thập đủ dữ liệu. Cụ thể, khi một điểm dữ liệu được phân loại là mới, họ lưu trữ nó vào STM. Khi STM đạt đến dung lượng tối đa, họ huấn luyện một chuyên gia mới với dữ liệu trong STM. Một kỹ thuật khác cho học liên tục bất khả tri nhiệm vụ, được biết đến là HCL [15], mô hình hóa phân phối của mỗi nhiệm vụ và mỗi lớp với một mô hình dòng chảy chuẩn hóa. Để xác định nhiệm vụ, họ sử dụng các kỹ thuật phát hiện bất thường hiện đại dựa trên việc đo lường tính điển hình của thống kê mô hình. Để tránh quên lãng thảm khốc, họ sử dụng sự kết hợp của phát lại tạo sinh và kỹ thuật chính quy hóa chức năng.

Trong bối cảnh cài đặt học không giám sát, phương pháp VASE [1] giải quyết học biểu diễn từ dữ liệu thị giác dừng từng phần dựa trên một bộ mã hóa tự động biến phân với embeddings được chia sẻ. Trọng tâm của công trình này được đặt vào việc học các biểu diễn được chia sẻ trên các miền. Phương pháp tự động phát hiện sự thay đổi trong phân phối dữ liệu huấn luyện và sử dụng thông tin này để phân bổ dung lượng tiềm ẩn dự phòng cho các biểu diễn rời rạc cụ thể cho tập dữ liệu mới, đồng thời tái sử dụng các biểu diễn đã có trước đó của các chiều tiềm ẩn khi có thể áp dụng. Các tác giả đại diện cho các tập dữ liệu bằng cách sử dụng một tập hợp các yếu tố tạo sinh dữ liệu, trong đó hai tập dữ liệu có thể sử dụng cùng các yếu tố tạo sinh nhưng kết xuất chúng khác nhau, hoặc chúng có thể sử dụng một tập con khác nhau của các yếu tố hoàn toàn. Tiếp theo, họ xác định xem lỗi tái tạo trung bình của các yếu tố tạo sinh có liên quan cho dữ liệu hiện tại có khớp với các tập dữ liệu trước đó bằng một ngưỡng hay không bằng cách sử dụng nguyên tắc Độ dài mô tả tối thiểu. Phân bổ dung lượng biểu diễn dự phòng cho kiến thức mới bảo vệ các biểu diễn đã học trước đó khỏi quên lãng thảm khốc. Một kỹ thuật khác được gọi là CURL [32] học một biểu diễn cụ thể cho nhiệm vụ trên một tập hợp lớn hơn các tham số được chia sẻ trong khi mở rộng dung lượng mô hình một cách động để nắm bắt các nhiệm vụ mới. Phương pháp đại diện cho các nhiệm vụ bằng cách sử dụng hỗn hợp Gaussian và mở rộng mô hình khi cần thiết, bằng cách duy trì một tập hợp nhỏ các mẫu được mô hình hóa kém và sau đó khởi tạo và khớp một thành phần hỗn hợp mới với tập hợp này khi nó đạt đến kích thước tới hạn. Phương pháp này cũng dựa trên các mô hình tạo sinh phát lại để giảm thiểu quên lãng thảm khốc.

Học liên tục không bất khả tri nhiệm vụ Họ kỹ thuật học liên tục không bất khả tri nhiệm vụ đầu tiên bao gồm hệ thống học bổ sung và phương pháp phát lại bộ nhớ. Chúng dựa trên việc phát lại các mẫu được chọn từ các nhiệm vụ trước đó. Các mẫu này được kết hợp vào quá trình học hiện tại để tại mỗi bước mô hình được huấn luyện trên hỗn hợp các mẫu từ một nhiệm vụ mới cũng như một tập con nhỏ các mẫu từ các nhiệm vụ đã thấy trước đó. Một số kỹ thuật tập trung vào việc lựa chọn và lưu trữ hiệu quả các kinh nghiệm trước đó thông qua các chiến lược lựa chọn khác nhau [4, 13]. Các phương pháp khác, ví dụ GEM [21], A-GEM [6], và MER [33] tập trung vào việc ưu tiên chuyển giao ngược tích cực cho các nhiệm vụ trước đó. Cuối cùng, có các phương pháp phát lại tạo sinh sâu [34, 36] thay thế bộ đệm bộ nhớ phát lại bằng một mô hình tạo sinh để học phân phối dữ liệu từ các nhiệm vụ trước đó và tạo ra các mẫu tương ứng khi học một nhiệm vụ mới.

Một họ kỹ thuật khác, được gọi là phương pháp dựa trên chính quy hóa, áp đặt ràng buộc trên việc cập nhật tham số của mạng nơ-ron, thường bằng cách thêm một thuật ngữ chính quy hóa vào hàm mục tiêu. Thuật ngữ này phạt sự thay đổi trong các tham số mô hình khi nhiệm vụ mới được quan sát và đảm bảo chúng ở gần các tham số đã học trên các nhiệm vụ trước đó. Trong số các kỹ thuật này, chúng tôi xác định một số thuật toán nổi tiếng như EWC [16], SI [43], MAS [3], và RWALK [5] giới thiệu các khái niệm khác nhau về tầm quan trọng của synapse hoặc tham số và phạt các thay đổi đối với các tham số quan trọng cao, cũng như phương pháp LwF [20] có thể được coi là sự kết hợp của chưng cất kiến thức và tinh chỉnh. Cuối cùng, họ kỹ thuật cuối cùng là các phương pháp kiến trúc động mở rộng kiến trúc của mạng bằng cách phân bổ tài nguyên bổ sung, tức là nơ-ron hoặc lớp, cho các nhiệm vụ mới thường đi kèm với cắt tỉa và che dấu tham số bổ sung. Họ này bao gồm các kỹ thuật như phương pháp expert-gate [2], mạng tiến bộ [35], mạng có thể mở rộng động [42], phương pháp học-để-phát triển [19], Packnet [22], Piggyback [23], và các sơ đồ kết hợp [12]. Ba kỹ thuật cuối cùng dựa trên lượng tử hóa mạng và cắt tỉa để kiểm soát tốt hơn độ phức tạp và kích thước của mô hình.

--- TRANG 3 ---
với một liên tục dữ liệu tại suy luận, mô hình tự động xác định nhiệm vụ và nhanh chóng thích ứng với nó chỉ với một lần cập nhật duy nhất. Tuy nhiên, khi huấn luyện vòng lặp trong của thuật toán của họ, tạo ra các mô hình cụ thể cho từng nhiệm vụ sau đó được kết hợp trong vòng lặp ngoài để tạo thành một mô hình tổng quát hơn, yêu cầu kiến thức về nhãn nhiệm vụ. Tại suy luận, nhiệm vụ được dự đoán bằng cách sử dụng các tham số mô hình tổng quát. Cụ thể, đối với mỗi mẫu trong liên tục, kết quả của mô hình chung được thu được và phản hồi tối đa trên mỗi nhiệm vụ được ghi lại. Trung bình của các phản hồi tối đa trên mỗi nhiệm vụ được sử dụng làm điểm số nhiệm vụ. Một nhiệm vụ với điểm số tối đa cuối cùng được dự đoán. iTAML chống lại quên lãng thảm khốc bằng cách giữ một bộ đệm bộ nhớ các mẫu từ các nhiệm vụ khác nhau và sử dụng nó để tinh chỉnh các tham số tổng quát đại diện cho tất cả các nhiệm vụ thành một nhiệm vụ hiện tại được thấy. Phương pháp này không phải là bất khả tri nhiệm vụ, vì nó yêu cầu nhãn nhiệm vụ khi huấn luyện, mặc dù các tác giả phân loại phương pháp của họ là bất khả tri nhiệm vụ. CN-DPM [18] là một phương pháp dựa trên mở rộng loại bỏ quên lãng thảm khốc bằng cách phân bổ tài nguyên mới để học dữ liệu mới. Họ công thức hóa vấn đề học liên tục bất khả tri nhiệm vụ như một suy luận biến phân trực tuyến của các mô hình hỗn hợp quá trình Dirichlet bao gồm một tập hợp các chuyên gia nơ-ron. Mỗi chuyên gia phụ trách một tập con của dữ liệu. Mỗi chuyên gia được liên kết với một mô hình phân biệt (bộ phân loại) và một mô hình tạo sinh (bộ ước tính mật độ). Đối với một mẫu mới, trước tiên họ quyết định xem mẫu nên được gán cho một chuyên gia hiện có hay một chuyên gia mới nên được tạo ra cho nó. Điều này được thực hiện bằng cách tính toán điểm trách nhiệm của các chuyên gia cho mẫu được xem xét và được hỗ trợ bởi bộ nhớ ngắn hạn (STM) thu thập đủ dữ liệu. Cụ thể, khi một điểm dữ liệu được phân loại là mới, họ lưu trữ nó vào STM. Khi STM đạt đến dung lượng tối đa, họ huấn luyện một chuyên gia mới với dữ liệu trong STM. Một kỹ thuật khác cho học liên tục bất khả tri nhiệm vụ, được biết đến là HCL [15], mô hình hóa phân phối của mỗi nhiệm vụ và mỗi lớp với một mô hình dòng chảy chuẩn hóa. Để xác định nhiệm vụ, họ sử dụng các kỹ thuật phát hiện bất thường hiện đại dựa trên việc đo lường tính điển hình của thống kê mô hình. Để tránh quên lãng thảm khốc, họ sử dụng sự kết hợp của phát lại tạo sinh và kỹ thuật chính quy hóa chức năng.

Trong bối cảnh cài đặt học không giám sát, phương pháp VASE [1] giải quyết học biểu diễn từ dữ liệu thị giác dừng từng phần dựa trên một bộ mã hóa tự động biến phân với embeddings được chia sẻ. Trọng tâm của công trình này được đặt vào việc học các biểu diễn được chia sẻ trên các miền. Phương pháp tự động phát hiện sự thay đổi trong phân phối dữ liệu huấn luyện và sử dụng thông tin này để phân bổ dung lượng tiềm ẩn dự phòng cho các biểu diễn rời rạc cụ thể cho tập dữ liệu mới, đồng thời tái sử dụng các biểu diễn đã có trước đó của các chiều tiềm ẩn khi có thể áp dụng. Các tác giả đại diện cho các tập dữ liệu bằng cách sử dụng một tập hợp các yếu tố tạo sinh dữ liệu, trong đó hai tập dữ liệu có thể sử dụng cùng các yếu tố tạo sinh nhưng kết xuất chúng khác nhau, hoặc chúng có thể sử dụng một tập con khác nhau của các yếu tố hoàn toàn. Tiếp theo, họ xác định xem lỗi tái tạo trung bình của các yếu tố tạo sinh có liên quan cho dữ liệu hiện tại có khớp với các tập dữ liệu trước đó bằng một ngưỡng hay không bằng cách sử dụng nguyên tắc Độ dài mô tả tối thiểu. Phân bổ dung lượng biểu diễn dự phòng cho kiến thức mới bảo vệ các biểu diễn đã học trước đó khỏi quên lãng thảm khốc. Một kỹ thuật khác được gọi là CURL [32] học một biểu diễn cụ thể cho nhiệm vụ trên một tập hợp lớn hơn các tham số được chia sẻ trong khi mở rộng dung lượng mô hình một cách động để nắm bắt các nhiệm vụ mới. Phương pháp đại diện cho các nhiệm vụ bằng cách sử dụng hỗn hợp Gaussian và mở rộng mô hình khi cần thiết, bằng cách duy trì một tập hợp nhỏ các mẫu được mô hình hóa kém và sau đó khởi tạo và khớp một thành phần hỗn hợp mới với tập hợp này khi nó đạt đến kích thước tới hạn. Phương pháp này cũng dựa trên các mô hình tạo sinh phát lại để giảm thiểu quên lãng thảm khốc.

Học liên tục không bất khả tri nhiệm vụ Họ kỹ thuật học liên tục không bất khả tri nhiệm vụ đầu tiên bao gồm hệ thống học bổ sung và phương pháp phát lại bộ nhớ. Chúng dựa trên việc phát lại các mẫu được chọn từ các nhiệm vụ trước đó. Các mẫu này được kết hợp vào quá trình học hiện tại để tại mỗi bước mô hình được huấn luyện trên hỗn hợp các mẫu từ một nhiệm vụ mới cũng như một tập con nhỏ các mẫu từ các nhiệm vụ đã thấy trước đó. Một số kỹ thuật tập trung vào việc lựa chọn và lưu trữ hiệu quả các kinh nghiệm trước đó thông qua các chiến lược lựa chọn khác nhau [4, 13]. Các phương pháp khác, ví dụ GEM [21], A-GEM [6], và MER [33] tập trung vào việc ưu tiên chuyển giao ngược tích cực cho các nhiệm vụ trước đó. Cuối cùng, có các phương pháp phát lại tạo sinh sâu [34, 36] thay thế bộ đệm bộ nhớ phát lại bằng một mô hình tạo sinh để học phân phối dữ liệu từ các nhiệm vụ trước đó và tạo ra các mẫu tương ứng khi học một nhiệm vụ mới.

Một họ kỹ thuật khác, được gọi là phương pháp dựa trên chính quy hóa, áp đặt ràng buộc trên việc cập nhật tham số của mạng nơ-ron, thường bằng cách thêm một thuật ngữ chính quy hóa vào hàm mục tiêu. Thuật ngữ này phạt sự thay đổi trong các tham số mô hình khi nhiệm vụ mới được quan sát và đảm bảo chúng ở gần các tham số đã học trên các nhiệm vụ trước đó. Trong số các kỹ thuật này, chúng tôi xác định một số thuật toán nổi tiếng như EWC [16], SI [43], MAS [3], và RWALK [5] giới thiệu các khái niệm khác nhau về tầm quan trọng của synapse hoặc tham số và phạt các thay đổi đối với các tham số quan trọng cao, cũng như phương pháp LwF [20] có thể được coi là sự kết hợp của chưng cất kiến thức và tinh chỉnh. Cuối cùng, họ kỹ thuật cuối cùng là các phương pháp kiến trúc động mở rộng kiến trúc của mạng bằng cách phân bổ tài nguyên bổ sung, tức là nơ-ron hoặc lớp, cho các nhiệm vụ mới thường đi kèm với cắt tỉa và che dấu tham số bổ sung. Họ này bao gồm các kỹ thuật như phương pháp expert-gate [2], mạng tiến bộ [35], mạng có thể mở rộng động [42], phương pháp học-để-phát triển [19], Packnet [22], Piggyback [23], và các sơ đồ kết hợp [12]. Ba kỹ thuật cuối cùng dựa trên lượng tử hóa mạng và cắt tỉa để kiểm soát tốt hơn độ phức tạp và kích thước của mô hình.

--- TRANG 4 ---
0 20000 40000 60000 80000
lặp lại020406080id chuyên gia tại lặp lại hiện tạikthông làm mượtcó làm mượtbbiên chuyển đổi nhiệm vụHình 2. Hiệu ứng của làm mượt

[42], phương pháp học-để-phát triển [19], Packnet [22], Piggyback [23], và các sơ đồ kết hợp [12]. Ba kỹ thuật cuối cùng dựa trên lượng tử hóa mạng và cắt tỉa để kiểm soát tốt hơn độ phức tạp và kích thước của mô hình.

3. Thuật toán TAME
Trong phần này, chúng tôi mô tả thuật toán được đề xuất TAME. Gọi T biểu thị tập hợp tất cả các nhiệm vụ. Mỗi ví dụ được rút ra i.i.d. từ một phân phối không biết Pt của nhiệm vụ tương ứng, tức là (xᵢᵗ, yᵢᵗ) ~ Pt. Các nhiệm vụ đến theo cách tuần tự. Chúng tôi xem xét một kịch bản trong đó danh tính nhiệm vụ cũng như số lượng nhiệm vụ không được biết. Mục tiêu là học các nhiệm vụ này tuần tự mà không quên lãng thảm khốc bằng cách tự động xác định danh tính nhiệm vụ ở cả thời gian huấn luyện và thời gian thử nghiệm.

TAME dựa trên việc sử dụng nhiều mạng chuyên gia nhiệm vụ, trong đó mỗi mạng chuyên gia được liên kết với một nhiệm vụ. Khi huấn luyện, thuật toán tự động phát hiện sự thay đổi trong phân phối dữ liệu theo cách trực tuyến và chuyển đổi giữa các chuyên gia hiện có hoặc thêm nhiều chuyên gia nếu cần thiết. Chiến lược phát hiện chuyển đổi nhiệm vụ dựa trên độ lệch có ý nghĩa thống kê trong các giá trị của hàm mất mát. Khi thử nghiệm, chúng tôi có một mạng bộ chọn bổ sung tự động chuyển tiếp mỗi mẫu đến chuyên gia có liên quan của nó. Mạng bộ chọn này được huấn luyện trên một tập con nhỏ các mẫu được rút ra ngẫu nhiên đồng đều từ chuỗi các mẫu từ tất cả các nhiệm vụ.

Mã giả của thuật toán chúng tôi được nắm bắt trong Thuật toán 1. Chúng tôi ban đầu bắt đầu với một mạng chuyên gia và dần dần thêm nhiều mạng hơn khi cần thiết. Tại mỗi bước thời gian, chúng tôi chỉ có một chuyên gia hoạt động duy nhất đang được huấn luyện trên dữ liệu đến. Chúng tôi quan sát giá trị của hàm mất mát của chuyên gia hoạt động hiện tại. Để làm mượt các biến động ngắn hạn và làm nổi bật các mẫu dài hạn, một phiên bản được làm mượt của mất mát được tính toán thông qua trung bình di chuyển có trọng số theo cấp số nhân (EWMA) [41]. EWMA là bộ lọc phản hồi xung vô hạn bậc nhất áp dụng các yếu tố trọng số giảm theo cấp số nhân (không bao giờ đạt đến không). Điều này được sử dụng để lọc ra các thành phần tần số cao hơn không có kết nối cụ thể với sự thay đổi trong phân phối dữ liệu. Hệ số α là một yếu tố làm mượt không đổi giữa [0,1] điều chỉnh lượng làm mượt. α cao hơn làm giảm các quan sát trước đó nhanh hơn. Hình 2 biện minh cho nhu cầu làm mượt mất mát bằng cách so sánh hiệu suất của thuật toán được đề xuất có và không có làm mượt. Mất mát được làm mượt giúp tránh dương tính giả trong việc phát hiện chuyển đổi nhiệm vụ, và do đó ngăn ngừa việc tạo ra các chuyên gia không cần thiết, đồng thời cho phép duy trì độ chính xác phát hiện cao.

Hơn nữa, chúng tôi tính toán một giá trị ngưỡng mất mát cho mỗi mạng chuyên gia. Chúng tôi giả định một phân phối chuẩn cho giá trị của hàm mất mát. Chúng tôi đặt ngưỡng ý nghĩa ở ba độ lệch chuẩn trên trung bình. Như được hiển thị trong thủ tục Getthreshold, trung bình và độ lệch chuẩn được tính toán trên một cửa sổ di chuyển có kích thước Wth của dữ liệu đã quan sát trước đó.

Trong dòng 30−43, chúng tôi so sánh mất mát được làm mượt với giá trị ngưỡng của chuyên gia hoạt động hiện tại và nếu nó trên ngưỡng, chúng tôi tìm kiếm trên tất cả các chuyên gia hiện có khác và chọn một chuyên gia đáp ứng yêu cầu ngưỡng. Nếu không tìm thấy mạng chuyên gia như vậy, có nghĩa là không có chuyên gia nào đại diện tốt cho dữ liệu hiện tại được thấy và do đó một chuyên gia mới được thêm vào mô hình và được kích hoạt (xem thủ tục Addexpert). Tiếp theo, mạng được chọn được huấn luyện trên dữ liệu đầu vào.

Chúng tôi cũng cần huấn luyện mạng bộ chọn để chuyển đổi giữa các chuyên gia tại suy luận. Cho mục đích này, chúng tôi có một bộ đệm dưới dạng hàng đợi ưu tiên với dung lượng cố định Cs nhỏ hơn nhiều so với tổng số mẫu. Trong dòng 46−50, chúng tôi lấy mẫu con dữ liệu ngẫu nhiên để giữ nó trong bộ đệm theo cách trực tuyến. Nhãn cho mỗi mẫu là id chuyên gia hiện tại tương ứng với danh tính nhiệm vụ mà chúng tôi suy luận từ dữ liệu. Mạng bộ chọn được huấn luyện trên các mẫu từ bộ đệm này và sau đó được sử dụng tại thời gian suy luận để tự động phân biệt nhãn nhiệm vụ và gửi dữ liệu thử nghiệm đến mạng chuyên gia tương ứng.

Để giảm kích thước của các chuyên gia và mạng bộ chọn, chúng tôi thực hiện cắt tỉa mạng. Thông thường, sau khi cắt tỉa, mô hình cần được huấn luyện lại để ngăn chặn sự sụt giảm đáng kể về hiệu suất. Để cho phép huấn luyện lại các chuyên gia, chúng tôi giới thiệu tập hợp các bộ đệm buffers_prune để lưu trữ các mẫu cho mỗi chuyên gia (nhiệm vụ). Mỗi bộ đệm được thực hiện như một hàng đợi ưu tiên với dung lượng cố định Cp. Khi chuyên gia mới được tạo ra, một bộ đệm cho chuyên gia đó được thêm vào tập hợp. Trong dòng 46−50, chúng tôi lấy mẫu con dữ liệu ngẫu nhiên và điền vào bộ đệm theo cách trực tuyến. Do đó, đối với mỗi nhiệm vụ, chúng tôi chỉ giữ một lượng cố định các mẫu được chọn ngẫu nhiên. Sau khi hoàn thành huấn luyện cho tất cả các nhiệm vụ, trong dòng 52, chúng tôi cắt tỉa và huấn luyện lại mạng bộ chọn sử dụng bộ đệm buffer_selector. Trong dòng 53−55, chúng tôi cắt tỉa và huấn luyện lại mỗi chuyên gia sử dụng bộ đệm tương ứng từ buffers_prune.

--- TRANG 5 ---
Thuật toán 1 TAME: Học liên tục bất khả tri nhiệm vụ sử dụng nhiều chuyên gia
Yêu cầu: Dữ liệu:{(x, y)}, Kích thước cửa sổ ngưỡng: Wth, Hệ số làm mượt: α,
Dung lượng bộ đệm để huấn luyện mạng bộ chọn: Cs, Dung lượng bộ đệm để huấn luyện lại sau cắt tỉa: Cp
1:
2:thủ tục: Addexpert ()
3:Đầu vào: experts ,Ne
4: Khởi tạo một mạng chuyên gia mới.
5: Khởi tạo mất mát được làm mượt của chuyên gia expert.Ls← −None
6: Khởi tạo expert.deque với dung lượng tối đa bằng Wth
7:expert.id =Ne
8:experts .add(expert )
9:Ne+= 1
10: Trả về expert
11:
12:thủ tục: Getthreshold ()
13: Đầu vào: expert.deque
14: μ= TRUNG BÌNH( expert.deque )
15: σ= ĐỘ LỆCH CHUẨN( expert.deque )
16: Trả về (μ+ 3∗σ)
17:
18:
19:Khởi tạo : bộ đệm buffer_selector với dung lượng Cs; Bộ đệm để cắt tỉa
buffers_prune ← −[]với dung lượng Cp cho tất cả các nhiệm vụ đến; số lượng
chuyên gia: Ne← −0;experts ← −[]; id nhiệm vụ hiện tại Tid← −0;
20:expertc=Addexpert (experts, Ne)
21:Tid= 1
22:buffers_prune [Tid]← −một hàng đợi ưu tiên với dung lượng Cp (khởi tạo bộ đệm
cho nhiệm vụ đầu tiên)
23:while Dữ liệu đến do
24: Lc=mất mát của chuyên gia hiện tại expertc trên đầu vào {(x, y)}
25: if expertc.Ls==None then
26: expertc.Ls=Lc
27: else
28: expertc.Ls=α∗Lc+ (1−α)∗expertc.Ls
29: end if
30: if expertc.Ls>Getthreshold (expertc.deque )then
31: expertp=None
32: Tid← −0
33: for e in experts do
34: Tid=Tid+ 1
35: if α∗Le+ (1−α)∗e.Ls<Getthreshold (e.deque )then
36: expertp=e;break
37: end if
38: end for
39: if expertp==None then
40: expertc=Addexpert (experts, Ne)
41: buffers_prune [Tid+ 1]← −một ưu tiên với dung lượng Cp (khởi tạo
bộ đệm cho nhiệm vụ mới)
42: end if
43: end if
44: Huấn luyện expertc trên lô dữ liệu {(x, y)}và cập nhật deque của nó.
45:
46: for(xi,−)in{(x, y)}do
47: priority =N(0,1)
48: buffer_selector .add(key: priority , value: (x, expertc.id))
49: buffers_prune [Tid].add(key: priority , value: (x, y))
50: end for
51:end while
52: Huấn luyện và cắt tỉa mạng bộ chọn trên các mẫu trong buffer_selector
53:for i in{1, 2, . . . , Ne}do
54: Cắt tỉa và huấn luyện lại experts [i] sử dụng bộ đệm buffers_prune [i] được lưu trữ cho
experts [i]
55:end for

4. Thí nghiệm
Trong phần này, chúng tôi đánh giá TAME trên các tập dữ liệu học liên tục chuẩn và so sánh với các phương pháp hiện đại khác, cụ thể là các phương pháp bất khả tri nhiệm vụ đã đề xuất trước đây: BGD [44], iTAML [31], HCL [15], và CN-DPM [18], cũng như các kỹ thuật không phải bất khả tri nhiệm vụ nhưng dành riêng cho cài đặt học liên tục, như DEN [42], EWC [16], SI [43], A-GEM [6], và RWALK [5]. Để đánh giá hiệu suất của các thuật toán cạnh tranh, chúng tôi sử dụng các triển khai mã nguồn mở, khi có sẵn¹²³⁴⁵.

4.1. Tập dữ liệu
Chúng tôi sử dụng các tập dữ liệu học liên tục chuẩn: (1) MNIST hoán vị, trong đó một tập hợp các nhiệm vụ được tạo ra bằng cách sử dụng một hoán vị ngẫu nhiên khác nhau của các pixel MNIST. Chúng tôi đã tạo ra một tập hợp 20 tập dữ liệu tương ứng với 20 nhiệm vụ. (2) MNIST phân tách, trong đó một tập hợp các nhiệm vụ được xây dựng bằng cách lấy các cặp chữ số từ tập dữ liệu MNIST gốc, tức là T={{0,1},{2,3},{4,5},{6,7},{8,9}}. (3) CIFAR-100 phân tách (20), trong đó CIFAR-100 gốc được chia thành 20 tập con rời rạc, mỗi tập chứa 5 nhãn lớp, tức là T={{0−4},{5−9}, . . . ,{95−99}}. Để so sánh với phương pháp HCL, chúng tôi sử dụng các tập dữ liệu bổ sung: (4) CIFAR-100 phân tách (10), trong đó CIFAR-100 gốc được chia thành 10 tập con rời rạc, mỗi tập chứa 10 nhãn lớp, tức là T={{0−9},{10−19}, . . . ,{90−99}}. (5) CIFAR-10 phân tách (5), trong đó CIFAR-10 gốc được chia thành 5 tập con rời rạc, mỗi tập chứa 2 nhãn lớp, tức là T={{0−1},{2−3}, . . . ,{8−9}}. (6) SVHN-MNIST, kết hợp các tập dữ liệu SVHN[29] và MNIST theo cách mà SVHN là nhiệm vụ đầu tiên và MNIST là nhiệm vụ thứ hai. (7) MNIST-SVHN trong đó MNIST là nhiệm vụ đầu tiên và SVHN là nhiệm vụ thứ hai.

Chúng tôi sử dụng kích thước hình ảnh sau trong các tập dữ liệu của chúng tôi, tức là 1×28×28 cho MNIST phân tách và MNIST hoán vị, 3×32×32 cho CIFAR-100 phân tách (10), CIFAR-100 phân tách (20), và CIFAR-10 phân tách (5). Đối với MNIST-SVHN và SVHN-MNIST, chúng tôi nâng cấp kích thước hình ảnh trong MNIST thành 3×32×32 và sử dụng kích thước hình ảnh gốc 3×32×32 cho tập dữ liệu SVHN. Chúng tôi chuẩn hóa các tập dữ liệu MNIST phân tách và MNIST hoán vị bằng trung bình 0.1307 và độ lệch chuẩn 0.3081, CIFAR-100 phân tách (10) và CIFAR-100 phân tách (20) bằng trung bình ( 0.5071,0.4867,0.4408 ) và độ lệch chuẩn (0.2675,0.2565,0.2761), và CIFAR-10 phân tách (5) bằng trung bình (0.5,0.5,0.5) và độ lệch chuẩn ( 0.5,0.5,0.5). Đối với các tập dữ liệu SVHN-MNIST và MNIST-SVHN, chúng tôi sử dụng trung bình 0.1307 và độ lệch chuẩn 0.3081 cho MNIST, và trung bình ( 0.5,0.5,0.5) và độ lệch chuẩn ( 0.5,0.5,0.5) cho SVHN. Đối với CIFAR-100 phân tách (10) và CIFAR-100 phân tách (20), chúng tôi sử dụng các kỹ thuật tăng cường dữ liệu bổ sung như cắt ngẫu nhiên, lật, và xoay.

¹https://github.com/facebookresearch/agem (A-GEM, SI, RWALK, và EWC)
²https://github.com/jaehong31/DEN (DEN)
³https://github.com/igolan/bgd/ (BGD)
⁴https://github.com/brjathu/iTAML (iTAML)
⁵https://github.com/soochan-lee/CN-DPM (CN-DPM)

--- TRANG 6 ---
4.2. Kiến trúc mạng
Đối với tất cả các phương pháp, ngoại trừ HCL, trong trường hợp các tập dữ liệu MNIST-hoán vị và MNIST phân tách, chúng tôi sử dụng một mạng với 2 lớp tích chập, được theo sau bởi hàm kích hoạt ReLU thông thường, thao tác gộp cực đại, và các lớp kết nối đầy đủ cho các mạng chuyên gia nhiệm vụ và chúng tôi sử dụng MLP 2 lớp cho mạng bộ chọn. Đối với CIFAR-100 phân tách (20), chúng tôi sử dụng phiên bản được sửa đổi nhẹ của kiến trúc VGG11 [37] cho các mạng chuyên gia nhiệm vụ và ResNet18 [9] được huấn luyện trước cho mạng bộ chọn. Sự sửa đổi của VGG phù hợp với việc có 5 đầu ra. Để so sánh với HCL, chúng tôi sử dụng mạng tích chập 2 lớp được đề cập ở trên cho các tập dữ liệu SVHN-MNIST, MNIST-SVHN, và MNIST phân tách. Đối với CIFAR-10 phân tách (5) và CIFAR-100 phân tách (20), chúng tôi sử dụng mô hình EfficientNet [38] được huấn luyện trước trên ImageNet cho mạng chuyên gia và ResNet-18 được huấn luyện trước cho mạng bộ chọn. Lưu ý rằng việc lựa chọn kiến trúc chúng tôi thực hiện được thực hiện có mục đích để phù hợp với các kiến trúc được sử dụng bởi các phương pháp cạnh tranh. Để ngăn chặn sự nhảy vọt đột ngột của giá trị hàm mất mát trong giai đoạn ban đầu của quá trình huấn luyện, chúng tôi thêm một lớp sigmoid vào đầu ra của mỗi mô hình.

Trong các thuật toán cạnh tranh, đối với các tập dữ liệu MNIST hoán vị và MNIST phân tách, chúng tôi đã thử nghiệm cả mạng tích chập 2 lớp được đề cập ở trên cũng như MLP 2 lớp và chọn kết quả tốt nhất. Đối với CIFAR-100 phân tách (20), chúng tôi sử dụng kiến trúc VGG ngoại trừ BGD và CN-DPM. Trong trường hợp BGD, kiến trúc VGG dẫn đến sự phân kỳ của hàm mất mát và kết quả không ổn định, do đó chúng tôi sử dụng kiến trúc được đề xuất bởi các tác giả trong bài báo của họ cho tập dữ liệu này. Đối với CN-DPM, hiệu suất kém hơn khi chúng tôi sử dụng kiến trúc VGG nên chúng tôi báo cáo kết quả được đưa ra trong bài báo gốc của CN-DPM. Hơn nữa, triển khai DEN không có sẵn cho các mạng tích chập, vì vậy chúng tôi không thể kiểm tra nó cho CIFAR-100 phân tách (20). Đối với HCL, chúng tôi báo cáo kết quả được đưa ra trong bài báo của họ trên tất cả các tập dữ liệu được liệt kê vì mã của họ không có sẵn công khai.

4.3. Chi tiết huấn luyện
Chúng tôi huấn luyện các mô hình bằng bộ tối ưu hóa SGD với tốc độ học bằng 0.1, động lượng Nesterov 0.9, và suy giảm trọng số 5e−4 và kích thước lô 128 cho tất cả các tập dữ liệu. Chúng tôi huấn luyện trong 10 epoch trên mỗi nhiệm vụ từ các tập dữ liệu MNIST hoán vị và MNIST phân tách và trong 200 epoch cho mỗi nhiệm vụ từ CIFAR-100 phân tách (20). Đối với CIFAR-100 phân tách (20), chúng tôi giảm tốc độ học xuống hệ số 5 tại epoch thứ 60, 120, và 160. Chúng tôi cũng áp dụng huấn luyện khởi động trong epoch đầu tiên để ngăn chặn sự phân kỳ mạng sớm trong quá trình huấn luyện. Chúng tôi huấn luyện 90 epoch cho SVHN-MNIST và MNIST-SVHN, 15 epoch cho CIFAR-10 phân tách (5) và CIFAR-100 phân tách (20). Cuối cùng, chúng tôi sử dụng cắt tỉa không có cấu trúc L1 để giảm kích thước mô hình cho mỗi chuyên gia và mạng bộ chọn mong đợi. Chúng tôi huấn luyện lại mỗi chuyên gia sau khi cắt tỉa với dữ liệu được lấy mẫu con được lưu trữ trong quá trình huấn luyện. Chúng tôi sử dụng bộ tối ưu hóa SGD với tốc độ học bằng 0.1 và suy giảm trọng số 1e−4.

4.4. Siêu tham số
Tiếp theo, chúng tôi mô tả các giá trị của các siêu tham số cụ thể cho thuật toán của chúng tôi. Cài đặt siêu tham số được sử dụng trong các thí nghiệm được tóm tắt trong Bảng 1. Trong tất cả các thí nghiệm, chúng tôi sử dụng cùng kích thước cửa sổ Wth bằng 100 và hệ số làm mượt mất mát α là 0.2.

Đối với các thuật toán cạnh tranh, chúng tôi sử dụng cài đặt siêu tham số được đề xuất bởi các tác giả hoặc thực hiện tìm kiếm tham số. Phạm vi tìm kiếm siêu tham số cho các phương pháp dựa trên chính quy hóa và cài đặt huấn luyện cho A-GEM được hiển thị trong tài liệu bổ sung.

4.5. Kết quả
Chỉ số chúng tôi sử dụng cho đánh giá là độ chính xác trung bình được đo trên tập thử nghiệm. Độ chính xác trung bình được định nghĩa là ACC = 1/T∑ᵢ₌₁ᵀ RT,i, trong đó RT,i là độ chính xác phân loại của mô hình trên nhiệm vụ i, và T là số lượng nhiệm vụ.

Trong Bảng 2, chúng tôi so sánh độ chính xác trung bình thu được bởi TAME và các thuật toán khác. Đối với phương pháp BGD, chúng tôi không sử dụng bất kỳ phương pháp "thủ thuật nhãn" nào và do đó chạy nó trong cài đặt bất khả tri nhiệm vụ thuần túy, giống như TAME, HCL, và CN-DPM. Đối với iTAML, danh tính nhiệm vụ được biết trong quá trình huấn luyện, do đó nó không phải là phương pháp bất khả tri nhiệm vụ theo tiêu chuẩn của chúng tôi, tuy nhiên vì trong quá trình suy luận họ không dựa vào danh tính nhiệm vụ, chúng tôi giữ phương pháp này làm đối thủ cạnh tranh. Tất cả các thuật toán khác có quyền truy cập vào bộ mô tả nhiệm vụ ở cả huấn luyện và thử nghiệm. TAME đạt được độ chính xác cao nhất và kích thước mô hình nhỏ nhất trong số tất cả các thuật toán và tập dữ liệu được xem xét. Lưu ý rằng TAME cũng vượt trội hơn các phương pháp học liên tục có quyền truy cập vào nhãn nhiệm vụ khi huấn luyện và/hoặc thử nghiệm. Trong Bảng 3, chúng tôi so sánh hiệu suất của TAME với HCL. Phương pháp của chúng tôi vượt trội hơn phương pháp này cũng như vậy.

Chúng tôi so sánh hành vi của hàm mất mát (trái) và phiên bản được làm mượt của nó (phải) cho mỗi chuyên gia khi huấn luyện, trong đó các chuyên gia được thêm tuần tự khi các nhiệm vụ mới đến. Kết quả cho thấy rằng mất mát được làm mượt hiệu quả hơn trong việc giảm các biến động ngắn hạn và nhấn mạnh các mẫu dài hạn. Để biết thêm chi tiết, vui lòng xem hình trong tài liệu bổ sung.

Trong Hình 3a-3c, chúng tôi minh họa hành vi của độ chính xác trung bình trong khi mô hình được huấn luyện trên chuỗi các nhiệm vụ. Thuật toán được đề xuất, TAME, có sự sụt giảm hiệu suất ít nhất khi thêm nhiều nhiệm vụ hơn trong số tất cả các phương pháp và tập dữ liệu được xem xét.

Trong Hình 3d, chúng tôi trình bày hiệu ứng của dung lượng bộ đệm lên độ chính xác của mạng bộ chọn cho tập dữ liệu CIFAR-100 phân tách (20). Lưu ý rằng độ chính xác của mạng bộ chọn phụ thuộc vào sự tương tự của các nhiệm vụ. Ví dụ, nếu chúng tôi sử dụng 20 siêu lớp từ CIFAR-100 phân tách (20), trong đó các nhãn tương tự được nhóm lại với nhau, độ chính xác của bộ chọn tăng từ ~62% lên ~79%.

Chúng tôi cũng hiển thị hiệu ứng của dung lượng bộ đệm cho cắt tỉa trong Bảng 4. Đối với MNIST hoán vị và MNIST phân tách, ngay cả kích thước bộ đệm nhỏ cũng cho ra độ chính xác trung bình tốt.

Chúng tôi cũng trình bày trong Hình 4 khả năng của mô hình sử dụng các chuyên gia hiện có khi một nhiệm vụ đã thấy trước đó xuất hiện lại trong chuỗi. Ví dụ, trong Hình 4b khi nhiệm vụ 2 xuất hiện lần thứ hai trong chuỗi T={t1, t2, t3, t2, t4}, thuật toán phù hợp chuyển đổi đến chuyên gia 2 hiện có thay vì khởi tạo một chuyên gia mới.

5. Kết luận và thảo luận
Bài báo này giải quyết một kịch bản học liên tục thách thức hơn - một cài đặt bất khả tri nhiệm vụ, trong đó mô hình không được cung cấp bộ mô tả nhiệm vụ trong quá trình huấn luyện hoặc thử nghiệm

--- TRANG 7 ---
Bảng 1. Cài đặt siêu tham số được sử dụng cho TAME
TAME MNIST hoán vị MNIST phân tách
SVHN-MNIST
MNIST-SVHN CIFAR-100 phân tách (20)
CIFAR-100 phân tách (10)
CIFAR-10 phân tách (5)
Cửa sổ ngưỡng Wth 100 100 100
Hệ số làm mượt α 0.2 0.2 0.2
Dung lượng bộ đệm Cs 5000 2500 7500
Dung lượng bộ đệm Cp 6000 1000 200
Tỷ lệ cắt tỉa chuyên gia (%) 98 98 98
Tỷ lệ cắt tỉa bộ chọn chuyên gia (%) 50 50 50

Bảng 2. Độ chính xác trung bình (%) thu được bởi TAME và các thuật toán khác cho MNIST hoán vị, MNIST phân tách, và CIFAR-100 phân tách
Tập dữ liệu (#nhiệm vụ) MNIST hoán vị (20) MNIST phân tách (5) CIFAR-100 phân tách (20)
Độ chính xác (%) Tham số Độ chính xác (%) Tham số Độ chính xác (%) Tham số
danh tính nhiệm vụ được biết trong quá trình huấn luyện và thử nghiệm
EWC 54.81 61.7K 98.18 61.7K 32.78 9.23M
SI 81.31 61.7K 94.85 61.7K 30.28 9.23M
A-GEM 79.61 61.7K 97.72 61.7K 43.57 9.23M
RWALK 46.23 61.7K 96.84 61.7K 31.13 9.23M
DEN 83.61 120.2K 95.51 120.2K NA NA
danh tính nhiệm vụ được biết trong quá trình huấn luyện, nhưng không trong quá trình thử nghiệm
iTAML NA NA 97.95 61.7K 54.55 9.23M
bất khả tri nhiệm vụ (id nhiệm vụ không được biết trong cả quá trình huấn luyện và thử nghiệm)
BGD (không có thủ thuật nhãn) 79.15 61.7K 19.00 61.7K 3.77 9.23M
CN-DPM 14.99 616.1K 94.19 746.8K 20.45 19.20M
HCL NA NA 90.89 NA NA NA
TAME 87.32 55.53K 98.63 37.02K 62.39 9.02M

Bảng 3. Độ chính xác trung bình (%) thu được bởi TAME và HCL
Tập dữ liệu (#nhiệm vụ) SVHN-MNIST MNIST-SVHN MNIST phân tách (5) CIFAR-10 phân tách (5) CIFAR-100 phân tách (10)
Độ chính xác (%) Độ chính xác (%) Độ chính xác (%) Độ chính xác (%) Độ chính xác (%)
HCL-FR 96.38 95.62 90.89 89.44 59.66
HCL-GR 93.84 96.04 84.65 80.29 51.64
TAME 97.45 97.63 98.63 91.32 61.06

Bảng 4. Kích thước Cp của bộ đệm được sử dụng để huấn luyện lại chuyên gia sau khi cắt tỉa so với độ chính xác trung bình cho các tập dữ liệu CIFAR-100 phân tách (20), MNIST phân tách, và MNIST hoán vị
Tập dữ liệu 50 100 200 500 1000 2000 3000 6000
CIFAR-100 phân tách (20) 56.12 57.86 62.39 63.47 64.41 / / /
MNIST phân tách 97.80 98.20 98.22 98.38 98.63 98.38 / /
MNIST hoán vị / 62.55 69.95 76.83 79.93 83.41 84.94 87.32

chúng tôi sử dụng 20 siêu lớp từ CIFAR-100 phân tách (20), trong đó các nhãn tương tự được nhóm lại với nhau, độ chính xác của bộ chọn tăng từ ~62% lên ~79%.

Chúng tôi cũng hiển thị hiệu ứng của dung lượng bộ đệm cho cắt tỉa trong Bảng 4. Đối với MNIST hoán vị và MNIST phân tách, ngay cả kích thước bộ đệm nhỏ cũng cho ra độ chính xác trung bình tốt.

Chúng tôi cũng trình bày trong Hình 4 khả năng của mô hình sử dụng các chuyên gia hiện có khi một nhiệm vụ đã thấy trước đó xuất hiện lại trong chuỗi. Ví dụ, trong Hình 4b khi nhiệm vụ 2 xuất hiện lần thứ hai trong chuỗi T={t1, t2, t3, t2, t4}, thuật toán phù hợp chuyển đổi đến chuyên gia 2 hiện có thay vì khởi tạo một chuyên gia mới.

5. Kết luận và thảo luận
Bài báo này giải quyết một kịch bản học liên tục thách thức hơn - một cài đặt bất khả tri nhiệm vụ, trong đó mô hình không được cung cấp bộ mô tả nhiệm vụ trong quá trình huấn luyện hoặc thử nghiệm

--- TRANG 8 ---
(a) MNIST hoán vị (b) MNIST phân tách

(c) CIFAR-100 phân tách (d) Bộ chọn TAME, CIFAR-100 phân tách

Hình 3. ( a, b, c ) Độ chính xác trung bình so với số lượng nhiệm vụ cho các tập dữ liệu khác nhau. ( d) Hiệu ứng của dung lượng bộ đệm lên độ chính xác của mạng bộ chọn trong TAME cho tập dữ liệu CIFAR-100 phân tách với 20 nhiệm vụ.

(a) Giá trị mất mát so với lặp lại (b) Giá trị mất mát so với lặp lại

Hình 4. Giá trị của hàm mất mát của các mạng chuyên gia nhiệm vụ khác nhau trong quá trình huấn luyện trên tập dữ liệu MNIST phân tách. Được hiển thị cho hai chuỗi nhiệm vụ: ( a)T={t1, . . . , t5, t1, . . . , t5}(b)T={t1, t2, t3, t2, t4}. Thuật toán chuyển đổi đến các chuyên gia hiện có khi một nhiệm vụ đã thấy trước đó xuất hiện sau đó trong chuỗi

thời gian. Chúng tôi đưa ra một thuật toán học liên tục mới cho mục đích này, mà chúng tôi gọi là TAME, dựa trên nhiều mạng chuyên gia liên kết với các nhiệm vụ khác nhau. Các mạng chuyên gia này được thêm tuần tự vào mô hình theo cách trực tuyến. Trong quá trình huấn luyện, thuật toán tự động phát hiện chuyển đổi nhiệm vụ dựa trên độ lệch có ý nghĩa thống kê trong các giá trị của hàm mất mát. Khi thử nghiệm, danh tính nhiệm vụ được ước tính bởi một mạng bộ chọn được huấn luyện trên một tập con dữ liệu huấn luyện được rút ra ngẫu nhiên đồng đều từ tất cả các nhiệm vụ. Kết quả thực nghiệm cho thấy hiệu quả của phương pháp chúng tôi trên các tập dữ liệu học liên tục chuẩn, vượt trội hơn các kỹ thuật hiện đại trước đây về hiệu suất và kích thước mô hình. Cụ thể, chúng tôi vượt trội hơn các phương pháp bất khả tri nhiệm vụ trước đây BGD, iTAML, HCL, và CN-DPM trên các tập dữ liệu khác nhau, cũng như các kỹ thuật khác tận dụng kiến thức về bộ mô tả nhiệm vụ ít nhất trong quá trình huấn luyện.

--- TRANG 9 ---
Tài liệu tham khảo
[1] Alessandro Achille, Tom Eccles, Loic Matthey, Chris
Burgess, Nicholas Watters, Alexander Lerchner, và Irina
Higgins. Life-long disentangled representation learning with
cross-domain latent homologies. Trong Advances in Neural
Information Processing Systems. Curran Associates, Inc.,
2018. 3
[2] Rahaf Aljundi, Punarjay Chakravarty, và Tinne Tuytelaars.
Expert gate: Lifelong learning with a network of experts. Trong
CVPR, 2017. 3
[3] Rahaf Aljundi, Francesca Babiloni, Mohamed Elhoseiny,
Marcus Rohrbach, và Tinne Tuytelaars. Memory aware
synapses: Learning what (not) to forget. Trong ECCV, 2018.
3
[4] Rahaf Aljundi, Min Lin, Baptiste Goujaud, và Yoshua Ben-
gio. Gradient based sample selection for online continual
learning. Trong Advances in Neural Information Processing Sys-
tems. Curran Associates, Inc., 2019. 3
[5] Arslan Chaudhry, Puneet K. Dokania, Thalaiyasingam Ajan-
than, và Philip H. S. Torr. Riemannian walk for incremen-
tal learning: Understanding forgetting and intransigence. Trong
Proceedings of the European Conference on Computer Vi-
sion (ECCV), 2018. 3, 5
[6] Arslan Chaudhry, Marc'Aurelio Ranzato, Marcus Rohrbach,
và Mohamed Elhoseiny. Efficient lifelong learning with a-
gem. arXiv preprint arXiv:1812.00420, 2018. 3, 5
[7] Yanming Guo, Yu Liu, Ard Oerlemans, Songyang Lao, Song
Wu, và Michael S. Lew. Deep learning for visual under-
standing: A review. Neurocomputing, 187:27–48, 2016. Re-
cent Developments on Deep Big Vision. 1
[8] D Hassabis, D Kumaran, C Summerfield, và M Botvinick.
Neuroscience-inspired artificial intelligence. Trong Neuron,
2017. 1
[9] K. He, X. Zhang, S. Ren, và J. Sun. Deep residual learning
for image recognition. Trong 2016 IEEE Conference on Com-
puter Vision and Pattern Recognition (CVPR), trang 770–
778, 2016. 6
[10] Mark Herbster và Manfred K. Warmuth. Tracking the best
expert. Mach. Learn., 32(2):151–178, 1998. 1
[11] Yen-Chang Hsu, Yen-Cheng Liu, Anita Ramasamy, và
Zsolt Kira. Re-evaluating continual learning scenarios: A
categorization and case for strong baselines. arXiv preprint
arXiv:1810.12488, 2019. 1
[12] Steven CY Hung, Cheng-Hao Tu, Cheng-En Wu, Chien-
Hung Chen, Chu-Song Chen, và cộng sự. Compacting, picking and
growing for unforgetting continual learning. arXiv preprint
arXiv:1910.06562, 2019. 4
[13] David Isele và Akansel Cosgun. Selective experience re-
play for lifelong learning. AAAI, 2018. 3
[14] R. Kemker, M. McClure, A. Abitino, T. Hayes, và C Kanan.
Measuring catastrophic forgetting in neural networks. AAAI,
2018. 1
[15] Polina Kirichenko, Mehrdad Farajtabar, Dushyant Rao, Bal-
aji Lakshminarayanan, Nir Levine, Ang Li, Huiyi Hu, An-
drew Gordon Wilson, và Razvan Pascanu. Task-agnostic
continual learning with hybrid probabilistic models. Trong
ICML Workshop on Invertible Neural Networks, Normaliz-
ing Flows, and Explicit Likelihood Models, 2021. 3, 5
[16] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel
Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran
Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-
Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Ku-
maran, và Raia Hadsell. Overcoming catastrophic for-
getting in neural networks. Proceedings of the National
Academy of Sciences, 114(13):3521–3526, 2017. 3, 5
[17] Yann LeCun, Y. Bengio, và Geoffrey Hinton. Deep learn-
ing. Nature, 521:436–44, 2015. 1
[18] Soochan Lee, Junsoo Ha, Dongsu Zhang, và Gunhee Kim.
A neural dirichlet process mixture model for task-free con-
tinual learning. Trong International Conference on Learning
Representations, ICLR 2020, 2020. 1, 3, 5
[19] Xilai Li, Yingbo Zhou, Tianfu Wu, Richard Socher, và
Caiming Xiong. Learn to grow: A continual structure learn-
ing framework for overcoming catastrophic forgetting. arXiv
preprint arXiv:1904.00310, 2019. 4
[20] Z. Li và D. Hoiem. Learning without forgetting. IEEE
Transactions on Pattern Analysis and Machine Intelligence,
40(12):2935–2947, 2018. 3
[21] David Lopez-Paz và cộng sự. Gradient episodic memory for contin-
ual learning. Trong Advances in Neural Information Processing
Systems, trang 6467–6476, 2017. 3
[22] Arun Mallya và Svetlana Lazebnik. Packnet: Adding mul-
tiple tasks to a single network by iterative pruning. Trong Pro-
ceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, trang 7765–7773, 2018. 4
[23] Arun Mallya, Dillon Davis, và Svetlana Lazebnik. Piggy-
back: Adapting a single network to multiple tasks by learn-
ing to mask weights. Trong Proceedings of the European Con-
ference on Computer Vision (ECCV), trang 67–82, 2018. 4
[24] D Maltoni và V Lomonaco. Continuous learning in single-
incremental-task scenarios. Neural Netw, 2019. 1
[25] JL McClelland, BL McNaughton, và RC O'Reilly. Why
there are complementary learning systems in the hippocam-
pus and neocortex: insights from the successes and failures
of connectionist models of learning and memory. Psycholog-
ical Review 102, 102:419–457, 1995.
[26] M. McCloskey và N. J. Cohen. Catastrophic interference
in connectionist networks: The sequential learning problem.
The Psychology of Learning and Motivation, 24:104–169,
1989. 1
[27] Claire Monteleoni. Online learning of non-stationary se-
quences. SM Thesis, MIT Artificial Intelligence Technical
Report, 2003. 1
[28] Claire Monteleoni và Tommi Jaakkola. Online learning of
non-stationary sequences. NeurIPS, 2003. 1
[29] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bis-
sacco, Bo Wu, và Andrew Y. Ng. Reading digits in nat-
ural images with unsupervised feature learning. NIPS Work-
shop on Deep Learning and Unsupervised Feature Learning,
2011. 5
[30] German I. Parisi, Ronald Kemker, Jose L. Part, Christopher
Kanan, và Stefan Wermter. Continual lifelong learning with
neural networks: A review. Neural Networks, 113:54–71,
2019. 1, 2

--- TRANG 10 ---
[31] Jathushan Rajasegaran, Salman Khan, Munawar Hayat, Fa-
had Shahbaz Khan, và Mubarak Shah. itaml: An incre-
mental task-agnostic meta-learning approach. 2020 IEEE
Conference on Computer Vision and Pattern Recognition
(CVPR), 2020. 1, 2, 5
[32] Dushyant Rao, Francesco Visin, Andrei Rusu, Razvan Pas-
canu, Whye Yee Teh, và Raia Hadsell. Continual unsuper-
vised representation learning. NeurIPS, trang 7645–7655,
2019. 1, 3
[33] Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu,
Irina Rish, Yuhai Tu, và Gerald Tesauro. Learning to learn
without forgetting by maximizing transfer and minimizing
interference. arXiv preprint arXiv:1810.11910, 2018. 1, 3
[34] Mohammad Rostami, Soheil Kolouri, và Praveen K. Pilly.
Complementary learning for overcoming catastrophic forget-
ting using experience replay. Trong Proceedings of the Twenty-
Eighth International Joint Conference on Artificial Intelli-
gence, IJCAI-19, trang 3339–3345, 2019. 3
[35] Andrei A. Rusu, Neil C. Rabinowitz, Guillaume Desjardins,
Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Raz-
van Pascanu, và Raia Hadsell. Progressive neural networks.
CoRR, abs/1606.04671, 2016. 3
[36] Hanul Shin, Jung Kwon Lee, Jaehong Kim, và Jiwon Kim.
Continual learning with deep generative replay. Trong Advances
in Neural Information Processing Systems. Curran Asso-
ciates, Inc., 2017. 3
[37] Karen Simonyan và Andrew Zisserman. Very deep convo-
lutional networks for large-scale image recognition. Trong In-
ternational Conference on Learning Representations, ICLR
2015, 2015. 6
[38] Mingxing Tan và Quoc Le. EfficientNet: Rethinking model
scaling for convolutional neural networks. Trong Proceedings
of the 36th International Conference on Machine Learning,
2011. 6
[39] Sebastian Thrun và Tom M. Mitchell. Lifelong robot learn-
ing. Robotics and Autonomous Systems, 15(1):25–46, 1995.
The Biology and Technology of Intelligent Autonomous
Agents. 1
[40] Gido M. van de Ven và Andreas S. Tolias. Generative replay
with feedback connections as a general strategy for continual
learning. arXiv preprint arXiv:1809.10635, 2019. 1
[41] Wikipedia. Moving average. 4
[42] Jaehong Yoon, Eunho Yang, Jeongtae Lee, và Sung Ju
Hwang. Lifelong learning with dynamically expandable net-
works. arXiv preprint arXiv:1708.01547, 2017. 4, 5
[43] Friedemann Zenke, Ben Poole, và Surya Ganguli. Contin-
ual learning through synaptic intelligence. Trong Proceedings
of the 34th International Conference on Machine Learning,
trang 3987–3995. PMLR, 2017. 3, 5
[44] Chen Zeno, Itay Golan, Elad Hoffer, và Daniel Soudry.
Task agnostic continual learning using online variational
bayes. arXiv preprint arXiv:1803.10123, 2019. 1, 2, 5

--- TRANG 11 ---
TAME: Học liên tục bất khả tri nhiệm vụ sử dụng nhiều chuyên gia
Tài liệu bổ sung

Bảng 5. Tìm kiếm siêu tham số cho các kỹ thuật dựa trên chính quy hóa
Tên MNIST hoán vị MNIST phân tách CIFAR-100 phân tách (20)
EWC (λ: sức mạnh bộ nhớ) {10,20,50,100}
104,105,106,107
104,105,106,107
SI (c: sức mạnh không thứ nguyên) {0.01,0.1,1,10} {0.01,0.1,1,100} {0.01,0.1,1,10}
RWALK (λ: thuật ngữ chính quy hóa) {0.01,0.1,1,100} {0.01,0.1,1,10}
101,102,103,104

Bảng 6. Cài đặt siêu tham số được sử dụng cho A-GEM
A-GEM MNIST hoán vị MNIST phân tách CIFAR-100 phân tách (20)
Kích thước bộ nhớ episodic 256 256 512
Kích thước lô episodic 256 256 1300

--- TRANG 12 ---
(a) Mất mát, MNIST hoán vị (b) Mất mát được làm mượt, MNIST hoán vị

(c) Mất mát, MNIST phân tách (d) Mất mát được làm mượt, MNIST phân tách

(e) Mất mát, CIFAR-100 phân tách (20) (f) Mất mát được làm mượt, CIFAR-100 phân tách (20)

Hình 5. Giá trị của hàm mất mát của các mạng chuyên gia nhiệm vụ khác nhau (trái) và các phiên bản được làm mượt của nó (phải) trong quá trình huấn luyện cho các tập dữ liệu khác nhau. Lưu ý rằng các chuyên gia được thêm tuần tự khi các nhiệm vụ mới đến. Trong tất cả các biểu đồ, có một sự gia tăng mất mát rõ ràng khi một nhiệm vụ mới đến

# 2007.02432.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/moe/2007.02432.pdf
# File size: 3533173 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
EXTENDING MIXTURE OF EXPERTS MODEL TO INVESTIGATE
HETEROGENEITY OF TRAJECTORIES : W HEN, W HERE AND HOW
TOADDWHICH COVARIATES
Jin Liu
Biometrics Department
Vertex PharmaceuticalsRobert A. Perera
Department of Biostatistics
Virginia Commonwealth University
August 20, 2021
ABSTRACT
Researchers are usually interested in examining the impact of covariates when separating hetero-
geneous samples into latent classes that are more homogeneous. The majority of theoretical and
empirical studies with such aims have focused on identifying covariates as predictors of class mem-
bership in the structural equation modeling framework. In other words, the covariates only indirectly
affect the sample heterogeneity. However, the covariates’ inﬂuence on between-individual differences
can also be direct. This article presents a mixture model that investigates covariates to explain
within-cluster and between-cluster heterogeneity simultaneously, known as a mixture-of-experts
(MoE) model. This study aims to extend the MoE framework to investigate heterogeneity in nonlinear
trajectories: to identify latent classes, covariates as predictors to clusters, and covariates that explain
within-cluster differences in change patterns over time. Our simulation studies demonstrate that the
proposed model generally estimates the parameters unbiasedly, precisely and exhibits appropriate
empirical coverage for a nominal 95% conﬁdence interval. This study also proposes implementing
structural equation model forests to shrink the covariate space of the proposed mixture model. We
illustrate how to select covariates and construct the proposed model with longitudinal mathematics
achievement data. Additionally, we demonstrate that the proposed mixture model can be further
extended in the structural equation modeling framework by allowing the covariates that have direct
effects to be time-varying.
Keywords Mixture of Experts CovariatesNonlinear Trajectories Sample Heterogeneity Individual Measurement
OccasionsSimulation Studies
1 Introduction
1.1 Motivating Example
Multiple existing studies have examined the heterogeneity in mathematics development and how the baseline characteris-
tics inform the formation of such latent classes. For instance, Kohli et al. (2015) showed that the clusters of mathematics
development exist, and Liu et al. (2020b) investigated the impacts of covariates, such as socioeconomic status and
teacher-reported scores, have on the heterogeneity in the developmental trajectories of mathematics. These studies
lead to an interesting but challenging question: whether these baseline characteristics only affect between-individual
differences in within-individual changes in an indirect way. Conceptually, it is reasonable to assume that the covariates
that reﬂect students’ ability and potential, such as the teacher-reported approach-to-learning, also directly affect the
heterogeneity in mathematics development (i.e., account for the within-cluster variability of trajectories).
CONTACT Jin Liu Email: Veronica.Liu0206@gmail.com, c2021, American Psychological Association. This paper is not the
copy of record and may not exactly replicate the ﬁnal, authoritative version of the article. Please do not copy or cite without authors’
permission. The ﬁnal article will be available, upon publication, via its DOI: 10.1037/met0000436arXiv:2007.02432v8  [stat.ME]  18 Aug 2021

--- PAGE 2 ---
APREPRINT - AUGUST 20, 2021
Similar challenges exist in multiple domains. For example, in the biomedical ﬁeld, cured or uncured latent patient groups
may exist for a particular disease. One treatment may affect cured patients more but inﬂuence uncured patients less,
where the ‘cured’ or ‘uncured’ status may associate with covariates such as demographic information, socioeconomic
status, and clinical features. Under such scenarios, researchers usually desire to examine the direct treatment effects on
each sub-population and identify covariates that inform patient membership simultaneously, which can be realized by
mixture-of-experts (MoE) models. We then extend the MoE to the structural equation modeling (SEM) framework to
answer the question presented in the motivating example.
1.2 Brief Introduction of Mixture-of-Experts Models
Jacobs et al. (1991) originally proposed the MoE, where the mixing coefﬁcients of mixture components are multinomial
functions of covariates to predict clusters; in each component, the outcome variable is a conditional distribution on
covariates that account for within-class heterogeneity. Multiple subsequent studies, for example, Jordan and Jacobs
(1993), demonstrated the mixing coefﬁcients can also be other functional forms of covariates. The MoE literature
usually terms component densities as ‘experts’ and mixing probabilities as ‘gating functions’. The notion behind the
terminology is that an ‘expert’ can build the conditional distribution in the corresponding covariate space divided
by ‘gating functions’ (Bishop, 2006, Chapter 14). Essentially, a MoE has three main components: (1) several
‘experts’ that can be any regression functions; (2) ‘gating’ functions that separate the covariate space into several parts
with considering uncertainty; more importantly, in each divided region, opinions of the corresponding ‘expert’ are
trustworthy; and (3) a probabilistic model that combines gating functions and experts (Jordan and Jacobs, 1993).
Useful statistical models, for example, Rosen and Tanner (1999); Hurn et al. (2003); Carvalho and Tanner (2007);
Geweke and Keane (2007); Handcock et al. (2007); Lê Cao et al. (2010) and empirical analyses like Thompson et al.
(1998); Gormley and Murphy (2011) with the use of MoEs have been published in multiple areas such as biomedicine,
econometrics, and political science. Researchers have utilized this framework to analyze various types of ‘expert’
densities, including right-censored data (Rosen and Tanner, 1999), ranked preference data (Gormley and Murphy, 2008,
2011), and time-series (Carvalho and Tanner, 2007). We illustrate a graphical model representation of a full MoE and
its restricted versions in Figure 1 following Gormley and Murphy (2011).
=========================
Insert Figure 1 about here
=========================
In the ﬁgure,yiandxiare the outcome variable and independent covariate for the ithindividual, respectively, and zi’s
is the mixing component parameter (i.e., a latent categorical variable) of the ithindividual. Additionally, gande
are ‘gating’ (indirect) coefﬁcients and ‘expert’ (direct) coefﬁcients, respectively. The difference between the full MoE
and three possible reduced versions lies in the presence or absence of edges between the covariate xiand the mixing
componentzior the outcome variable yi. We interpret these models and link them to the corresponding counterpart in
the structural equation modeling (SEM) literature if the equivalent model exists.
(a)In the ﬁnite mixture model (FMM, Muthén and Shedden (1999)), the outcome variable yidepends only on the
mixing component parameter zi. We express a FMM with Klatent classes as
p(yi) =KX
k=1g(zi=k)p(yij(k));
whereg(zi=k)is the proportion of the samples in cluster kwith two constraints 0g(zi=k)1andPK
k=1g(zi=k) = 1 , and(k)is a set of class-speciﬁc parameters. The FMM has received lots of attention
over the past twenty years in the SEM literature, with a considerable amount of empirical and theoretical work
examining its beneﬁts and limitations (for example, Bauer and Curran (2003); Muthén (2004); Grimm and
Ram (2009); Nylund et al. (2007); Grimm et al. (2010)). Researchers usually employ the FMM to investigate
sample heterogeneity and group individuals into subgroups that are more homogeneous (Muthén and Muthén,
2000).
(b)In the gating-network mixture-of-experts model, the outcome variable yidepends on the mixing component
variableziand the distribution of zidepends on covariates xi. Then we write a gating-expert MoE model with
Klatent classes as
p(yi) =KX
k=1g(zi=kjxgi)p(yij(k));
2

--- PAGE 3 ---
APREPRINT - AUGUST 20, 2021
whereg(zi=kjxgi), a multinomial function of covariates, is the proportion of the samples in cluster k, and
has two constraints 0g(zi=kjxgi)1andPK
k=1g(zi=kjxgi) = 1 . The gating-expert MoE model is
also popular among researchers who apply SEM. Previous studies have shown that including covariates in
the gating functions can be realized in a conﬁrmatory way through one-step models (Clogg, 1981; Goodman,
1974; Haberman, 1979; Hagenaars, 1993; Vermunt, 1997; Bandeen-Roche et al., 1997; Dayton and Macready,
1988; Kamakura et al., 1994; Yamaguchi, 2000) or in an exploratory fashion through two-step models (Bakk
and Kuha, 2018; Liu et al., 2020b) or three-step models (Clogg, 1995; Bolck et al., 2004; Vermunt, 2010;
Asparouhov and Muthén, 2014).
(c)In the expert-network mixture-of-experts model, the outcome variable yidepends on both latent component
membership ziand covariates xi; yet the distribution of the mixing component variable is independent of the
covariates. So an expert-network MoE model with Kclusters is given
p(yi) =KX
k=1g(zi=k)p(yijxei;(k));
which has the same constraints as the ﬁnite mixture model. To our knowledge, although the expert-network
MoE model has not yet received much attention among researchers employing SEM, multiple existing studies
in the SEM literature, for example, Asparouhov and Muthén (2014); Masyn (2017); Kim et al. (2016) have
shown that the consequences of ignoring the direct effects that covariates have on sample heterogeneity
can be severe by simulation studies. Conceptually, it can be viewed as a mixture of multiple-indicator and
multiple-cause (MIMIC) models in the SEM framework (Jöreskog and Goldberger, 1975; McArdle and
Epstein, 1987). Each MIMIC model has two components: (1) a measurement model in which exogenous
variables indicate latent variables; and (2) a structural model where covariates are multiple-causal predictors to
the latent variables.
(d)In the full mixture-of-experts model, the outcome variable yidepends on both the mixing component variable
ziand covariates xi. Additionally, the distribution of the latent categorical variable zialso depends on the
covariatesxi. We then give a full MoE model with Kclusters as
p(yi) =KX
k=1g(zi=kjxgi)p(yijxei;(k));
which has the same constraints as the gating-network MoE model. The full MoE model is not a brand-new
concept in the SEM framework. When introducing the FMM into the SEM framework, Muthén and Shedden
(1999) viewed it as a possible generalization of the ﬁnite mixture model. It can also be viewed as an extension
of the expert-network MoE by allowing the latent component membership of MIMIC components to be
multinomial functions of covariates. Additionally, Asparouhov and Muthén (2014) have examined the impact
of direct and indirect effects of covariates in the context of growth mixture models where the direct effect is on
the growth factors. Note that the covariates of the mixing components variable ziand the outcome variable yi
can be the same or different.
In short, the full MoE and its three reduced models all have their corresponding counterparts in the SEM framework:
the full MoE model is a full mixture model with consideration of both direct and indirect effects that covariates have
on sample heterogeneity. The expert-network MoE, the gating-network MoE, and the FMM are all restricted models
obtained by ﬁxing logistic coefﬁcients (i.e., effects of covariates with indirect effects), path coefﬁcients (i.e., effects
of covariates with direct effects), and both to be zero. In the following text, we mainly use SEM terminology, as it
is more familiar to social science researchers, and refer to the full MoE model, the expert-network MoE model, and
the gating-network MoE model as the full mixture model, growth predictor mixture (GP-mixture) model, and cluster
predictor mixture (CP-mixture) model, respectively. However, the model labels may be considered interchangeable.
A within-class model can take multiple forms in the SEM framework. For example, it can be a factor model with
covariates, where the latent variables are indicated by the outcome variable yiand caused by covariates xidirectly.
It can also be a latent growth curve model with time-invariant covariates (LGC-TICs), where the latent variables
are growth factors indicated by the repeated measures of yiand directly caused by covariates xi. More importantly,
researchers can specify the parameters that need to be ﬁxed or freely estimated in each class. For example, in a two-class
full mixture model with LGC-TICs, the underlying functional form of trajectories could be speciﬁed as quadratic in the
ﬁrst class but linear such that the mean and variance of the quadratic term as well as quadratic-intercept, quadratic-linear
covariances are ﬁxed to zero in the second class.
This article focuses on a full mixture model with a nonlinear LGC-TICs as the within-class model. Speciﬁcally, we
consider a bilinear growth model (Grimm et al., 2016, Chapter 11) (see Figure A.1), also referred to as a linear-linear
3

--- PAGE 4 ---
APREPRINT - AUGUST 20, 2021
piecewise model (Harring et al., 2006; Kohli, 2011; Kohli et al., 2013; Kohli and Harring, 2013; Kohli et al., 2015),
with an unknown knot and time-invariant covariates (TICs) in each latent class. We decide to employ the bilinear spline
growth model with TICs (BLSGM-TICs) as the within-class model for two reasons. On the one hand, this piecewise
functional form allows for investigating the change of growth rate during different developmental stages and when the
change of growth rate occurs, which are often of interest in developmental studies. On the other hand, Liu et al. (2020a)
has shown that the bilinear spline functional form is a better ﬁt for repeated mathematics scores in our motivating data
set than models with parametric functions such as quadratic and Jenss-Bayley. Following multiple existing studies,
for example, Sterba (2014); Preacher and Hancock (2015); Liu et al. (2020b), we build the model in the framework of
individual-measurement occasions by using ‘deﬁnition variables’ (observed variables that adjust model parameters to
individual-speciﬁc values) (Mehta and West, 2000; Mehta and Neale, 2005) to avoid possible inadmissible solutions
(Blozis and Cho, 2008; Coulombe et al., 2015).
1.3 Challenges of Mixture-of-Experts Models Implementation
Unless a study is conducted to answer a speciﬁc question, we usually have two challenges when specifying a full
mixture model, deciding the number of clusters and selecting which covariates, if any, need to be included, and if
so, in which cluster(s) or multinomial function(s). Earlier studies have proposed approaches to decide the number
of latent classes for different types of within-class models. For example, Jacobs et al. (1997) addressed this issue
for a within-class model that is a generalized linear model, Rosen et al. (2000) handled this issue in the context of
marginal models, and Rosen and Tanner (1999) developed an approach to decide the number of clusters for a mixture of
proportional hazards models. Additionally, Zeevi et al. (1998); Wood et al. (2002) and Carvalho and Tanner (2005)
advocated for using a penalized criterion, such as Akaike Information Criterion (AIC), Bayesian Information Criterion
(BIC), or Minimum Description Length (MDL) criterion, to choose the number of clusters in the model.
In the SEM framework, Diallo et al. (2017) and Nylund-Gibson and Masyn (2016) have conducted extensive simulation
studies to investigate the impact of covariates with direct and/or indirect effects on the latent class enumeration process
in the context of the multilevel growth mixture modeling framework and cross-sectional latent class models with binary
indicators, respectively. Both studies have recommended conducting the enumeration process without the inclusion
of covariates and employing the BIC to determine the optimal number, especially under conditions of large class
separation (Diallo et al., 2017). In the current study, we do not intend to develop a novel metric for choosing the number
of clusters in the context of full growth mixture models. Instead, we follow the convention in the SEM literature to
determine the number in an exploratory fashion. We ﬁt a pool of candidate ﬁnite mixture models (i.e., not to include
any covariates) with different numbers of latent classes and pick the ‘best’ model along with the desired number of
clusters via statistical criteria such as the BIC (Nylund et al., 2007).
Another challenge of specifying a full mixture model is to decide which covariates should be added to the model,
especially in the SEM framework. The number of potential covariates could be large, and highly-correlated covariate
subsets may exist in the psychological and educational domains, where the SEM framework is widely utilized. In
the SEM literature, examining the relationship between latent classes and covariates can be realized by the one-step
approach (Bandeen-Roche et al., 1997) or stepwise methods. The measurement parameters and the coefﬁcients from
the predictors to the latent class variable are estimated simultaneously in the one-step approach. Multiple existing
studies, for example, Asparouhov and Muthén (2014); Bakk and Kuha (2018); Kim et al. (2016); Hsiao et al. (2020),
have shown that the one-step approach usually performs better than those stepwise methods in terms of performance
metrics such as bias, RMSE and coverage probability, although Vermunt (2010) pointed out several disadvantages of the
one-step approach in the context of covariates of the latent class variable. The major critiques lie in (1) computational
burden when the dimension of the potential covariates is large, especially in a more exploratory study, and (2) whether
or not to include covariates when deciding the number of latent classes. Multiple studies, for example, Clogg (1995);
Vermunt (2010); Bolck et al. (2004); Bakk and Kuha (2018), have proposed stepwise methods to avoid such drawbacks.
Although these methods are different in the procedure, their primary idea is the same: to separate the estimation of
measurement parameters and coefﬁcients in the multinomial functions.
Researchers have recently recommended employing the adjusted one-step approach (Kim et al., 2016; Hsiao et al., 2020)
to address the second critique. In the adjusted one-step approach, a stable solution for enumeration is determined with no
covariates (i.e., the process we stated earlier for this study). Then the class-speciﬁc parameters and logistic coefﬁcients
are estimated simultaneously with the determined number of clusters. In this study, we propose a possible approach that
can help identify the most important covariates among a set of candidates efﬁciently by leveraging machine learning
techniques (i.e., address the ﬁrst critique on the one-step model). Speciﬁcally, we propose to employ structural equation
model forests (SEM Forests, Brandmaier et al. (2016)), an extension of random forests (RFs, Breiman (2001)) in the
SEM framework, to select covariates. Note that we aim to introduce how to use its output named ‘variable importance’
with a basic understanding of its algorithm instead of examining this method comprehensively.
4

--- PAGE 5 ---
APREPRINT - AUGUST 20, 2021
Both RFs and SEM Forests have their ‘simple-tree’ versions: classiﬁcation and regression trees (CARTs, Breiman et al.
(1984)) and structural equation model trees (SEM Trees, Brandmaier et al. (2013)). CARTs can be utilized to analyze
univariate continuous outcomes (regression trees) or categorical outcomes (classiﬁcation trees). The algorithm that lies
behind CARTs is intuitive: it regresses the outcome variable on a set of candidate covariates and starts with an empty
tree. At each step, the algorithm needs to select a covariate to split and the value of the threshold (of a continuous
covariate or a categorical covariate with more than two levels) to optimize a pre-speciﬁed metric (for example, to
minimize the sum-of-squares errors in a regression problem or maximize accuracy in a classiﬁcation problem). The
algorithm usually conducts this optimization by exhaustive search and does not stop this partition process until the
sample homogeneity of each (sub-)split cannot be improved further (Bishop, 2006, Chapter 14). By extending the
CARTs from a univariate outcome setting to the scenario with a multivariate outcome variable, SEM Trees expedite
exploratory analyses in the SEM framework (Brandmaier et al., 2013). One available objective metric to be optimized
in the SEM Trees is the likelihood function. The algorithm selects one covariate to partition, along with a selected
threshold value, to maximize the likelihood function of this split.
Both CARTs and SEM Trees suffer an overﬁtting issue that is an inherent limitation of the algorithm. The algorithm
is designed to optimize a metric, say accuracy or likelihood function, greedily for one sample so that the ﬁt model
cannot be generalized to other samples from the same population. Other than remedies such as pruning (Breiman
et al., 1984; Brandmaier et al., 2013), an ensemble or ‘bagging’ technique proposed as RFs (Breiman, 2001) and SEM
Forests (Brandmaier et al., 2016) also addresses the overﬁtting issue for CARTs and SEM Trees, respectively. As the
word ‘forests’ suggests, both a RF and a SEM Forest are a collection of trees constructed by resampling with randomly
selected covariates of the original dataset. A forest is more stable than a single tree as it is an average of all constructed
trees (Breiman, 2001; Brandmaier et al., 2016). More importantly, both forest algorithms calculate variable importance
to quantify the (relative) impact a covariate has on the metric. The variable importance obtained from the SEM Forest is
a score to assess how important a covariate is in predicting the multivariate means and variance-covariance structure.
Only covariates with high importance or effects on sample heterogeneity require further examination.
Although a covariate could have direct and indirect effects on sample heterogeneity simultaneously and it is realizable
in the SEM framework by adding paths from the covariate to the latent categorical variable and to the class-speciﬁc
growth factors, we allow the covariates in the within-class model to differ from those in the multinomial functions based
on conceptual and technical considerations that we will explain in detail in the Discussion section. In this study, with
the set of selected covariates, we place the ones that are assumed to directly affect sample heterogeneity in the latent
classes to explain the within-class variability while the others in the multinomial functions to predict the membership of
each individual.
In the remainder of this article, we describe how to specify and estimate a full mixture model with the BLSGM-TICs
as the within-class model. In the subsequent section, we depict the simulation design for model evaluation. We
evaluate model performance through its estimates and clustering effects. We then demonstrate how to employ SEM
Forests to select baseline covariates efﬁciently. In the Application section, we analyze the motivating data, longitudinal
mathematics item response theory (IRT) scores, demonstrating how to implement the SEM Forests to select covariates
and construct the proposed mixture models. Additionally, we demonstrate how to extend the proposed model in the
SEM framework by allowing the covariates in latent classes to be time-varying. We ﬁnally frame discussions concerning
the methodological and practical considerations as well as future directions.
2 Method
2.1 Model Speciﬁcation of the Full Mixture Model
In this section, we specify the proposed full mixture model in the SEM framework. Speciﬁcally, we assume that the
within-class model takes the functional form of a bilinear spline growth curve with an unknown knot for the underlying
change patterns. In each latent class, we also add covariates to explain the within-class variability of trajectories (growth
factors). Harring et al. (2006) pointed out there are ﬁve parameters in the linear-linear piecewise functional form: an
intercept and slope of each linear piece and a knot, but the degree-of-freedom of the bilinear spline reduces to four as
two linear pieces join at the knot. In the current study, we consider the initial intercept, two slopes, and the knot as
the four free parameters following multiple existing studies, for example, Kohli (2011); Kohli et al. (2013); Kohli and
Harring (2013). Although Preacher and Hancock (2015); Liu et al. (2020a); Liu and Perera (2021) have shown that the
knot can be an additional growth factor with considering its variability, we construct a parsimonious model assuming
that the class-speciﬁc knot is at the same time point for all individuals in each cluster as the knot variability is not the
5

--- PAGE 6 ---
APREPRINT - AUGUST 20, 2021
aim of the current study. For the ithindividual, we express the model in the SEM framework as
p(yijzi=k;xgi;xei) =KX
k=1g(zi=kjxgi)p(yijzi=k;xei); (1)
g(zi=kjxgi) =8
><
>:1
1+PK
k=2exp((k)
g0+(k)T
gxgi)Reference Group ( k= 1)
exp((k)
g0+(k)T
gxgi)
1+PK
k=2exp((k)
g0+(k)T
gxgi)Other Groups ( k= 2;:::;K ); (2)
yij(zi=k;i) =i((k))ij(zi=k;xei) +ij(zi=k); (3)
ij(zi=k;xei) =(k)
e0+(k)
exeij(zi=k) +ij(zi=k): (4)
Equation (1) deﬁnes a probabilistic model that combines mixing proportions, g(zi=kjxgi), and within-class models,
p(yijzi=k;xei), wherexgi,xei,yiandziare the covariates with indirect effects, covariates with direct effects,
J1vector of repeated outcomes (in which Jis the number of measurements) and the membership of individual i,
respectively. Note that there are two constraints on Equation (1): 0g(zi=kjxgi)1andPK
k=1g(zi=kjxgi) = 1 .
Equation (2) deﬁnes mixing components as multinomial functions of covariates xgi, where(k)
g0and(k)
gare the
intercept and the logistic coefﬁcients that indicate indirect effects, respectively. The multinomial functions decide which
cluster an individual belongs to with uncertainty, depending on the values of xgi.
Equations (3) and (4) together deﬁne a within-class model. Equation (3) writes the outcome yias a linear combination
of growth factors i. When the within-class model takes the bilinear spline functional form with an unknown knot,
iis a31vector of growth factors ( i=0i;1i;2i, for an intercept and two slopes); accordingly, i((k))is a
J3matrix of factor loadings. The subscript iini((k))accounts for individual measurement occasions. Note
thati((k))is a function of the class-speciﬁc knot (k). In our study, the knot can occur at a particular measurement
occasion or between two measurements. The repeated outcomes yihave different pre- and post-knot expressions
yij=0i+1itij+ij tij(k)
0i+1i(k)+2i(tij (k)) +ijtij>(k);
whereyijandtijare the measurement and its occasion of the ithindividual at time j.
Equation (4) further regresses the growth factors ion covariates with direct effects, where (k)
e0and(k)
eare a 31
vector of growth factor intercepts and a 3cmatrix of path coefﬁcients (where cis the number of covariates) in cluster
k, respectively. Additionally, xeij(zi=k)is ac1vector of covariates, and ij(zi=k)is a31vector of deviations
of theithindividual from the class-speciﬁc growth factors conditional means.
Grimm et al. (2016, Chapter 11), Harring et al. (2006); Preacher and Hancock (2015); Liu et al. (2020a) presented
multiple ways to unify pre- and post-knot expressions by reparameterizing growth factors. In this article, we follow
Liu et al. (2020a) as the transformation function and matrix for the growth factors and corresponding path coefﬁcients
between the original and reparameterized frames are available for this reparameterizing strategy. Note that the
expressions of the repeated outcome yiin two parameter-spaces are mathematically equivalent, although only the
parameters in the original frame are directly related to the underlying change patterns. We provide the reparameterizing
process and details of transformation between class-speciﬁc growth factors and path coefﬁcients of the two parameter-
spaces in Appendices A.1 and A.2.
2.2 Model Estimation
To simplify the model, we make two assumptions. (1) Within-class growth factors follow a multivariate Gaussian
distribution conditional on covariates, that is, the vector of deviations ij(zi=k)MVN (0;	(k)
), where 	(k)
is the
unexplained variance-covariance matrix of class-speciﬁc growth factors. (2) Individual residuals are independent and
identically normally distributed over time in each latent class, that is, ij(zi=k)N(0;(k)
I), whereIis aJJ
identity matrix. Accordingly, the within-class implied mean vector ( (k)
i) and variance-covariance matrix ( (k)
i) of
repeated outcomes yifor theithindividual in the kthcluster are given as
(k)
i=i((k))((k)
e0+(k)
e(k)
xe); (5)
(k)
i=i((k))	(k)
i((k))T+i((k))(k)
e(k)(k)T
ei((k))T+(k)
I; (6)
6

--- PAGE 7 ---
APREPRINT - AUGUST 20, 2021
respectively, where (k)
xeand(k)are the mean vector ( c1) and the variance-covariance matrix ( cc) of the
covariates in the kthlatent class, respectively.
The parameters that need to be estimated in the proposed model include
full=f(k)
e0;	(k)
;(k);(k)
e;(k)
xe;(k);(k)
;(k)
g0;(k)
gg
=f(k)
0;(k)
1;(k)
2; (k)
00; (k)
01; (k)
02; (k)
11; (k)
12; (k)
22;(k);(k)
e;(k)
xe;(k);(k)
;(k)
g0;(k)
gg;
k= 2;:::;K for(k)
g0;(k)
g;
k= 1;:::;K for other parameters :(7)
The log-likelihood function of the model speciﬁed in Equations (1)-(4) is
``(full) =nX
i=1logKX
k=1g(zi=kjxgi)p(yijzi=k;xei)
=nX
i=1logKX
k=1g(zi=kjxgi)p(yij(k)
i;(k)
i;xei)
:(8)
Multiple techniques are available to estimate parameters in mixture models. In the machine learning literature, one
recommended approach is the expectation-maximization (EM) algorithm as the mixing component ziin Equation (8) is
unknown and the EM algorithm gets around this problem by viewing it as known with an initial guess and updating it at
each iteration until achieving convergent status. We ﬁrst deﬁne the cluster responsibilities (i.e., posterior probabilities)
of an iteration tas
^r(t)
ik=g(zi=kjxgi)(t 1)p(yij^(k)(t 1)
i;^(k)(t 1)
i;xei)
PK
k=1g(zi=kjxgi)(t 1)p(yij^(k)(t 1)
i;^(k)(t 1)
i;xei): (9)
In each iteration, the EM algorithm consists of two steps: E-step, which estimates cluster responsibilities given current
parameter estimates, and M-step, which maximizes the likelihood over parameters given current responsibilities. More
technical details about the EM algorithm can be found in Murphy (2012, Chapter 11).
The EM algorithm is available in multiple SEM software such as Mplus and the Rpackage OpenMx . By specifying
‘algorithm=EM’, we can request a pure EM algorithm in Mplus . In the Rpackage OpenMx , a model is optimized
by the EM algorithm when we specify E-step and M-step in the computation plan (Neale et al., 2016; Pritikin
et al., 2015; Hunter, 2018; Boker et al., 2020). Additionally, the default optimizer CSOLNP ofOpenMx , which
utilizes the Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm (an iterative method that belongs to quasi-Newton
methods for addressing unconstrained nonlinear optimization problems) has been shown efﬁciently for mixture models
in an existing study (Liu et al., 2020b). In this study, we use the CSOLNP optimizer to estimate the parameters
listed in Equation (7) and provide the OpenMx syntax along with a demonstration in the online appendix ( https:
//github.com/Veronica0206/Extension_projects ). The Mplus 8 code for the proposed model is also provided
in the online appendix. (The code will be uploaded upon acceptance.)
We can specify three possible restricted models through removing the paths between the membership ziand the
covariatesxi, that between the covariates xiand the outcome variable yiand both from the full model deﬁned in
Equations (1)-(4). The mean-vector and variance-covariance matrix of repeated outcomes in Equations (5) and (6), the
parameters in Equation (7) and the deﬁned cluster responsibilities at an iteration tin Equation (9) need to be updated
accordingly. We provide these equations in Appendix A.3.
3 Model Evaluation
The proposed mixture model with the BLSGM-TICs as the within-class model and its three possible reduced versions
are evaluated using a Monte Carlo simulation study with three goals. In the simulation study, we consider two covariates
with indirect effects and two covariates with direct effects. The ﬁrst goal is to examine the performance measures of the
proposed models and clustering effects when we specify them correctly, no matter in the full or any restricted form. The
performance metrics include the relative bias, empirical standard error (SE), relative root-mean-square error (RMSE),
and empirical coverage for a nominal 95% conﬁdence interval (CI) of each parameter. Deﬁnitions and estimates of
these four performance measures are listed in Table 1.
=========================
7

--- PAGE 8 ---
APREPRINT - AUGUST 20, 2021
Insert Table 1 about here
=========================
To evaluate the clustering effects, we ﬁrst need to calculate the posterior probability for each individual belonging to
each cluster as Equations (10), (11), (12) and (13) for full mixture models, GP-mixture models, CP-mixture models and
FMMs:
p(zi=k) =g(zi=kjxgi)p(yijzi=k;xei)PK
k=1g(zi=kjxgi)p(yijzi=k;xei); (10)
p(zi=k) =g(zi=k)p(yijzi=k;xei)PK
k=1g(zi=k)p(yijzi=k;xei); (11)
p(zi=k) =g(zi=kjxgi)p(yijzi=k)PK
k=1g(zi=kjxgi)p(yijzi=k); (12)
p(zi=k) =g(zi=k)p(yijzi=k)PK
k=1g(zi=k)p(yijzi=k): (13)
With each individual’s posterior probabilities vector, we assign the individual to the cluster with the highest posterior
probability. The tie among competing components with equally maximum probabilities is randomly broken as described
in McLachlan and Peel (2000). The clustering effects include accuracy and entropy. As we have true membership in a
simulation study, accuracy, which is deﬁned as the fraction of all correctly classiﬁed instances, is available to assess
how the algorithm separates the samples into ‘correct’ groups (Bishop, 2006, Chapter 1). Entropy is a metric based on
the average posterior probabilities (Stegmann and Grimm, 2018), which is given as
Entropy = 1 +1
nlog(K)nX
n=1KX
k=1p(zi=k) logp(zi=k)
: (14)
It measures the uncertainty of the clustering results and ranges from 0to1, with 0and1indicating no class separation
and complete class separation, respectively. Earlier studies have shown that entropy is a good indicator of accuracy if
we can correctly specify the covariates. For example, Lubke and Muthén (2007) have shown that entropy values around
0:8or above suggest at least 90% accuracy, although the cutoff of entropy could be sensitive to the within-class model.
The second goal is to see whether placing all four covariates in the multinomial functions would result in inadmissible
solutions or misleading information. It is common misspeciﬁcation since researchers usually assume that the covariates
only have indirect effects on sample heterogeneity. With this misspeciﬁed model, we also aim to examine the
performance of entropy when the constructed model includes model misspeciﬁcation. The third goal is to compare the
four correctly-speciﬁed models2, among themselves and with the misspeciﬁed model. We ﬁrst examine Dumenci’s
Latent Kappa (Dumenci, 2011; Dumenci et al., 2019) between the trajectory clusters obtained from the FMM and those
from each mixture models with covariates. We also investigate whether we can apply common statistical criteria, such
as the BIC, to select the ‘best’ model among the proposed mixture model and its three restricted models.
In the simulation design, we decided the number of repetitions S= 1;000by an empirical approach following Morris
et al. (2019). We conducted a pilot study and observed that standard errors of all parameters except the intercept
(unexplained) variances were less than 0:15. Bias is the most important performance metric. To keep the Monte Carlo
standard error of bias3for the majority of parameters (i.e., all parameters except the intercept variances) lower than
0:005, we needed at least 900replications. We then decided to proceed with S= 1;000to be more conservative.
3.1 Design of Simulation Study
Table 2 lists all conditions that we considered in the simulation design. We ﬁxed the conditions, including the sample
size, the number of clusters, the number of repeated measurements, the variance-covariance matrix of the growth factors,
the distribution of the covariates with direct effects, and the time-window of individual measurement occasions, which
are not of primary interest in this study. For example, we selected ten scaled and equally spaced waves since Liu et al.
(2020a); Liu and Perera (2021) have shown that bilinear growth models performed decently in terms of performance
measures under this condition and that fewer numbers (for example, six) of repeated outcomes only affected model
2In this context, the correctly-speciﬁed models are broadly deﬁned (including the full mixture model and its restricted models),
suggesting that we did not misspecify (though could under-specify) the covariates.
3Monte Carlo SE(Bias) =q
Var(^)=S(Morris et al., 2019).
8

--- PAGE 9 ---
APREPRINT - AUGUST 20, 2021
performance slightly. Similar to earlier studies, we allowed for a moderate time-window, ( 0:25;+0:25), of individual
measurement occasions around each wave (Coulombe et al., 2015). Since the variance-covariance structure of the
growth factors usually changes with the measurement scales and time scales, we ﬁxed it and kept the index of dispersion
(2=) of each growth factor at one-tenth scale to follow Bauer and Curran (2003); Kohli (2011); Kohli et al. (2015).
The correlations between growth factors were set to be a moderate level ( = 0:3).
=========================
Insert Table 2 about here
=========================
The most important feature of a model-based clustering algorithm lies in how well it can detect sample heterogeneity
and estimate parameters of interest. Intuitively, the model should perform better under conditions with larger separation
between latent classes. The distance between latent classes is measured by the difference between the class-speciﬁc
density functions. Therefore, there are two possible metrics to gauge the separation between two clusters: the
Mahalanobis distance between class-speciﬁc growth factors and the difference in the knot locations (Kohli et al., 2015;
Liu et al., 2020b). In this study, we kept the Mahalanobis distance as 0:86(that is a small distance as deﬁned by Kohli
et al. (2015)) and set 1:0,1:5and2:0as a small, medium and large difference in knot locations. Those manipulated
conditions allowed us to examine how the separation between the two latent classes affects model performance. Note
that we setxe’s distribution to be the same across latent classes in this simulation study to avoid its possible inﬂuence
on the distance between clusters. Additionally, we considered two levels of allocation ratios: 1:1and1:2, roughly
controlled by the intercept coefﬁcients in the multinomial functions. We selected the class mixing proportion of 1:1as
a balanced allocation; we chose the other level as we wanted to examine model performance in a more challenging
scenario concerning mixing proportions.
Another important feature that we wanted to investigate through the simulation study is how the two types of covariates
affect the proposed model in terms of performance measures and clustering effects. We standardized all covariates so
that the effect sizes of the same type of covariates are comparable. We ﬁxed the coefﬁcients of two covariates with
indirect effects as log(1:5)(i.e., the odds ratio is 1:5) and log(1:7), respectively. We adjusted the relative importance
of the covariates with direct effects against those with indirect effects by varying path coefﬁcients to account for the
moderate ( 13%) or substantial ( 26%) variance of class-speciﬁc growth factors (Cohen, 1988, Chapter 9). The covariates
can explain 13%,13% and26% for within-class trajectory variability in one cluster and 13%,26% and26% variability
in the other. Additionally, we considered two levels of residual variance to examine how measurement precision affects
the model. We also considered three scenarios (Scenario 1, 2 and 3 in Table 2) to see if the trajectory shape affects
model performance. We varied the knot location and one growth factor while keeping the other two growth factors the
same across the clusters in each scenario.
3.2 Data Generation and Simulation Step
We carried out two-step data generation for each condition in Table 2. We ﬁrst obtained the membership zifrom
covariates with indirect effects for each individual. We then generated the outcome variable yiand covariates with
direct effects for each cluster simultaneously. The general steps of data generation are:
1. Create membership zifor theithindividual:
(a) Generate data matrix of covariates with indirect effects xg,
(b)Calculate the probability vector for each entry based on the covariates with indirect effects and a set of
speciﬁed logistic coefﬁcients with a multinomial link and assign each individual to the component with
the highest probability,
2.Generate data of growth factors and covariates with direct effects xesimultaneously for each component using
theRpackage MASS (Venables and Ripley, 2002),
3.Generate the time structure with ten scaled and equally-spaced waves tjand obtain individual measurement
occasions by allowing the time-window as tijU(tj ;tj+ ) around each wave,
4.Calculate factor loadings, which are functions of the class-speciﬁc knot and individual measurement occasions,
for each individual,
5.Calculate values of the repeated outcomes from the class-speciﬁc growth factors, corresponding factor loadings,
class-speciﬁc knot and residual variances,
6.Apply the proposed mixture models to the generated data, estimate the parameters, and construct corresponding
95% Wald CIs, along with accuracy and entropy,
9

--- PAGE 10 ---
APREPRINT - AUGUST 20, 2021
7.Repeat Steps 1-6until achieving 1;000convergent solutions, calculate the relative bias, empirical SE, relative
RMSE, and coverage probability of each parameter,
8.Respecify a model with all covariates in the multinomial functions on the data sets from which we obtained
convergent solutions in the above steps.
4 Results
4.1 Model Convergence
We ﬁrst examined the convergence4rate of the proposed full mixture model and its three reduced versions under each
condition in this section. The convergence rate of the full, GP-, CP- and ﬁnite mixture model achieved at least 89%,
89%,87% and87%, respectively across all conditions in the simulation study. Out of a total of 108conditions, 36,35,
36and35conditions reported 100% of convergence rate for the full, GP-, CP- and ﬁnite mixture model, respectively.
We noticed that all of these conditions with 100% convergence rate were those with a large difference in knot locations
(i.e., the knot location difference is 2). Additionally, 54,54,51and51conditions reported convergence rates of 95% to
99% for the full, GP-, CP- and ﬁnite mixture model, respectively. The worst scenario regarding the non-convergence
rate is 153=1153 , indicating that we need to repeat the process described above 1;153times to have 1;000replications
with a convergent solution. It occurred when we tried to ﬁt a CP-mixture model under the conditions with balanced
allocation, the small difference between the knot locations, covariates accounting for moderate growth factors in both
clusters, and the small residual variance. We only kept the replications where the four models converged.
4.2 Performance Measures
In this section, we present simulation results in terms of performance measures, including the relative bias, empirical
SE, relative RMSE and coverage probability for each parameter of the four proposed models. Generally, all four models
can estimate parameters unbiasedly, precisely, and generate target conﬁdence interval coverage. We ﬁrst calculated each
performance metric across 1;000replications for each parameter of interest under each condition and then summarized
the values of each performance metric across all conditions as the corresponding median and range. The summary is
provided in the Online Supplementary Document.
All four models produced unbiased point estimates with small empirical SEs, and the magnitude of the relative bias and
empirical SE of each parameter across models were comparable. Speciﬁcally, the magnitude of the relative biases of the
growth factor means, (unexplained) growth factor variances, path coefﬁcients and logistic coefﬁcients were around 0:03,
0:07,0:13and0:10, respectively. The magnitude of the empirical SE of all parameters except intercept parameters
(including intercept means, variances, and path coefﬁcients) was under 0:75(i.e., the variances of estimate were under
0:56). The empirical SE of (k)
0and (k)
00were around 0:50and2:50, respectively.
Moreover, four models can estimate parameters accurately, quantiﬁed by the relative RMSE that evaluates model
performance holistically with consideration of bias and precision. The magnitude of the relative RMSEs of the means
and (unexplained) variances of the growth factors were under 0:04and0:33, respectively. The relative RMSE magnitude
of the path and logistic coefﬁcients were around 0:40and0:30, respectively.
Overall, the proposed models performed well regarding empirical coverage under most conditions as the median values
of coverage probabilities of the mean vector and (unexplained) variance-covariance matrix of growth factors, the path
and logistic coefﬁcients were around 0:90. We noted that the knots’ coverage probabilities could be unsatisfactory. We
then plotted the coverage probabilities of the class-speciﬁc knots stratiﬁed by the separation between clusters in Figure
2 to investigate the pattern. We observed that the coverage probabilities were still around 0:95when the separation
between clusters was large, although this metric was conservative under other conditions.
=========================
Insert Figure 2 about here
=========================
4.3 Clustering Effects
We assess the clustering effects across all conditions listed in Table 2 in this section. For each model under each
condition, we ﬁrst calculated the mean values of accuracy and entropy across 1;000replications. We plotted these
4Convergence is deﬁned as to achieve OpenMx status code 0, which suggests a successful optimization, until up to 10attempts
with different collections of starting values (Neale et al., 2016).
10

--- PAGE 11 ---
APREPRINT - AUGUST 20, 2021
values stratiﬁed by the separation between latent classes, as shown in Figures 3 and 4. The mean values of accuracy and
entropy were the highest under the conditions with the large difference in knot locations (i.e., 2:0), followed by those
with the medium difference (i.e., 1:5) and then the small difference (i.e., 1:0). Speciﬁcally, when the difference in knot
locations was set as 2, the ranges of the mean values of accuracy were ( 0:78,0:91), (0:80,0:92), (0:77,0:91) and ( 0:80,
0:92) for the FMM, the CP-, GP- and full mixture model, respectively. We also noticed that, on average, the values of
accuracy and entropy under conditions with the unbalanced allocation were relatively larger.
=========================
Insert Figure 3 about here
=========================
=========================
Insert Figure 4 about here
=========================
In general, the clustering effects of the full mixture model and CP-mixture model were better than the other two models,
suggesting that correctly adding covariates with indirect effects helps separate heterogeneous samples, which aligns with
the recommendation by existing studies such as Lubke and Muthén (2007). We also noticed that including covariates
with direct effects only affected accuracy slightly in this simulation study. It is not surprising since one essential factor
that affects a clustering algorithm is the separation between class-speciﬁc density functions: the larger the separation
between two densities is, the easier it is to tell them apart. For a full or GP-mixture model, the class-speciﬁc density
function is deﬁned by the outcome variable yand the covariates with direct effects xe. In the simulation study, the four
models share the same class-speciﬁc distribution of the outcome ysince we ﬁt the four models on the same generated
data set. Additionally, we generated standardized covariates xefor each latent class, with which the separation between
the class-speciﬁc density functions was only affected slightly no matter how large the effects (i.e., the path coefﬁcients)
were.
4.4 Misspeciﬁed Model
We ﬁrst examined the convergence rate of the misspeciﬁed CP-mixture model that speciﬁes all four covariates in the
multinomial functions. For each condition, we ﬁt the misspeciﬁed model on each replication where all four correctly-
speciﬁed models converged. The convergence rate can achieve at least 92:0%, suggesting that the misspeciﬁed model
produced 920replications with a convergent solution out of 1;000repetitions, which was still satisﬁed. However, the
misspeciﬁed model’s performance measures and accuracy were worse than the correctly-speciﬁed models’ corresponding
values. The relative bias and empirical SE of the misspeciﬁed model are also provided in the Online Supplementary
Document. The estimates from the misspeciﬁed model exhibited some bias greater than 10%: the relative bias magnitude
of the growth factor means, growth factor variances, and logistic coefﬁcients achieved 0:26,0:26, and 0:83, which were
much worse than the corresponding values from the correctly-speciﬁed models.
We also plotted the mean values of accuracy and entropy of the misspeciﬁed model in Figures 3 and 4, respectively.
We observed that the mean value of accuracy of the misspeciﬁed model could be as low as around 50% (i.e., the
probability of having a correct label from a guess). The common conditions that generated such low accuracy values
were the small difference in knot locations (i.e., 1:0), and covariates account for substantial growth factor variances (i.e.,
26%) at least in one latent class. We noted that the entropy of the misspeciﬁed model could be higher than that of the
correctly-speciﬁed models. This ﬁnding suggests that entropy obtained from a mixture model with covariates is no
longer a good indicator of the class separation of trajectories alone, which aligns with the ﬁnding in an existing study
(Stegmann and Grimm, 2018).
Earlier studies, for example, Vermunt (2010); Bakk and Kuha (2018), have suggested that adding or removing covariates
with indirect effects may affect the posterior probabilities, and in turn, the component membership. This also explains
why the entropy of mixture models is sensitive to the inclusion of the covariates, especially as the separation between
two clusters decreased and when the misspeciﬁed covariates accounted for greater within-class variability in the current
study. As shown in Equation (14), entropy is a measure based on the average posterior probabilities, and the posterior
probabilities are sensitive to the inclusion of covariates, as shown in Equations (10)-(13). When the between-class
differences quantiﬁed by the separation in knot locations decreased, the mixing proportions g(:)dominate the mixture
model, and entropy was more indicative of the latent classes forming the covariates than those forming the trajectories.
Entropy is a misleading indicator of the class separation of trajectories when the misspeciﬁed covariates have higher
direct effects on the trajectories.
11

--- PAGE 12 ---
APREPRINT - AUGUST 20, 2021
4.5 Comparison Among Models
We compared the four correctly-speciﬁed models among themselves and to the misspeciﬁed model. We want to point
out that the likelihood-based criteria, such as AIC and BIC, cannot be employed to select a model among the four
mixture models as the difference in these criteria is mainly from the discrepancy in the estimated likelihood, which is
due to their different model structures. In general, the models without covariates with direct effects (i.e., FMM and
CP-mixture model) had a much larger estimated likelihood than the other two. We provide a plot with mean values of
estimated likelihood, AIC, and BIC across all conditions for the models in the Online Supplementary Document.
We then calculated Dumenci’s Latent Kappa to evaluate the agreement between the trajectory clusters obtained from
the FMM and those from each of the mixture models with covariates. For each condition, we ﬁrst calculated the mean
value of Dumenci’s Latent Kappa across 1;000replications and then plotted these values stratiﬁed by the separation
between clusters in Figure 5. The agreement between trajectory types from two correctly-speciﬁed models was high,
although it is not exactly perfect (i.e., the Kappa statistic was 1as Agresti (2012, Chapter 11)). Under the conditions
with the large separation in the latent classes, the mean values of Dumenci’s Latent Kappa were above 0:80, indicating
an almost perfect agreement (Landis and Koch, 1977; Nakazawa, 2019) between trajectory clusters from the FMM and
those from each of the other three correctly-speciﬁed models. However, Dumenci’s Latent Kappa between trajectory
types from the FMM and those from the misspeciﬁed model, which could be below 0:2under some conditions, was
much lower, suggesting only ‘slight’ agreement (Landis and Koch, 1977; Nakazawa, 2019).
=========================
Insert Figure 5 about here
=========================
5 Employing SEM Forests to Identify Important Covariates
In this section, we propose to use SEM Forests to shrink the covariate space when building a mixture model. As shown
in Table 3, we examined eight scenarios with the different relative importance of direct effects against indirect effects.
We considered one cluster in the ﬁrst three scenarios and two latent classes in the other ﬁve scenarios. For the scenarios
with one cluster, we set the covariates to account for 2%(small), 13% (moderate) and 26% (substantial) variability of
growth factors, respectively. For the other scenarios, similar to the simulation design, we ﬁxed the logistic coefﬁcients
and varied path coefﬁcients to adjust the relative importance. We also standardized all covariates.
=========================
Insert Table 3 about here
=========================
Figures 6a and 6b are the general steps to examine the variable importance of the scenarios with one and multiple
cluster(s), respectively. We ﬁrst generated data and constructed a latent growth curve model in the Rpackage
OpenMx and this one-group model serves as a template model for this generated data set (Brandmaier et al., 2016).
As shown in these ﬁgures, the input of the SEM Forests algorithm, which is available in the Rpackage semtree
(Brandmaier et al., 2020), is the template model, the original data set, and the pool of candidate covariates. One
output of SEM Forests is the variable importance in terms of predicting the model-implied mean vector and variance-
covariance structure. Note that we added two noise variables whose importance is supposed to be zero when building
forests. In this study, the tree parameter setting is ‘bootstrap’ as the sampling method, 128trees5, and 2subsampled
covariates at each node6. We provide a demonstration on building a SEM Forests model in the online appendix
(https://github.com/Veronica0206/Extension_projects ).
=========================
Insert Figure 6 about here
=========================
Figure 7 plots variable importance for each scenario that we considered in Table 3. For the conditions that only include
covariates with direct effects and noise variables (i.e., Figure 7a, Figure 7b and Figure 7c), the algorithm worked well to
5We decided to use 128trees as Oshiro et al. (2012) showed that from 128trees, there are no more signiﬁcant difference between
the forest with 256,512,1024 ,2048 and4096 trees by analyzing 29real-world data sets.
6As Brandmaier et al. (2016), suppose there are mpotential predictors, the size of the set of candidate predictors, c, at each node
could be set as either 1,2,c= log2(m) + 1 ,c=pm, orc=m=3. In this section, we consider c=m=3and selectc= 2 as
m= 6.
12

--- PAGE 13 ---
APREPRINT - AUGUST 20, 2021
distinguish the covariates from the noise variables and weighted more on the covariates when they account for more
variability of growth factors. For the conditions including the two types of covariates with noise (i.e., Figure 7d-Figure
7h), the SEM Forests model performed well to distinguish the signal (i.e., the covariates that have effects) from the
noise, and the rank of importance scores of the covariates may change with the relative importance of the direct effects
against the indirect effects.
=========================
Insert Figure 7 about here
=========================
Based on the patterns demonstrated in Figure 7, we propose a possible approach to identify covariates for a mixture
model in the SEM framework: (1) for a given data set, ﬁt a template model in the Rpackage OpenMx , (2) regress the
template model on a pool of candidate covariates to build a SEM Forests model using the Rpackage semtree and obtain
variable importance scores, (3) decide a threshold in terms of ‘importance’ and select covariates with high importance.
6 Application
We have three goals in the application section. The ﬁrst goal is to demonstrate how to employ the SEM Forests to
identify the covariates with high importance and then investigate the direct and indirect effects that the covariates have
on the heterogeneity in trajectories by employing the proposed models. The second goal is to demonstrate how to
extend the proposed model by allowing the covariates with direct effects to be time-varying. We then conduct sensitivity
analyses, where we keep the functional form of the within-class model but use stepwise procedures to add covariates
with indirect effects. A random sample with 500students was selected from the Early Childhood Longitudinal Study
Kindergarten Cohort: 2010-11 (ECLS-K: 2011) with complete records of repeated mathematics achievement scores,
demographic information (sex, race/ethnicity, and age in months at each wave), baseline socioeconomic status (family
income and the highest education level between parents), baseline school information (school type and location),
repeated measurements of teacher-reported approach-to-learning, baseline teacher-reported social skills (including
self-control ability, interpersonal skills, externalizing problem and internalizing problem), and baseline teacher-reported
children behavior question (including attentional-focus and inhibitory-control).
ECLS-K: 2011 is a nationwide representative longitudinal sample consists of US children from around 900kindergarten
programs that started from 2010 2011 school year. Student’s mathematics IRT scores were evaluated in nine waves:
the fall and spring semester of kindergarten, ﬁrst and second grade, respectively, as well as the spring semester of 3rd,
4thand5thgrade, respectively. As Lê et al. (2011), this study only sampled around 30% students in the fall semester of
2011 and2012 . We employed children’s age (in months) to obtain individual measurement occasions. The selected
sample (n= 500 ) consists of 53:0%boys and 47:0%girls. Additionally, the sample was represented by White ( 52:4%),
Black ( 3:2%), Latinx ( 29:6%), Asian ( 8:8%) and others ( 6:0%). We then dichotomized the variable race/ethnicity to be
White ( 52:4%) and others ( 47:6%). The highest parents’ education (ranged from 0to8) and family income (ranged
from 1to18) were treated as continuous variables for this analysis, and the corresponding mean (SD) was 5:34(1:93)
and12:09(5:31), respectively.
6.1 Main Analysis
We ﬁrst ﬁt a bilinear spline growth curve model for these repeated mathematics scores and built a SEM Forests model
to identify the covariates with the greatest variable importance. As shown in Figure 8, the covariates with the highest
variable importance scores were family income ( 113:04) and parents’ highest education level ( 110:52), followed by
approach-to-learning ( 55:73) and attentional-focus ( 43:41). We decided to keep these four covariates with sex and
race/ethnicity to build the following six models:
1. Model 1: A growth mixture model without any covariates,
2.Model 2: A CP-mixture model with family income, parents’ highest education, sex and race/ethnicity in the
multinomial functions,
3. Model 3: A CP-mixture model with all six covariates in the multinomial functions,
4. Model 4: A GP-mixture model with attentional-focus and approach-to-learning in all within-class models,
5.Model 5: A GP-mixture model with family income and parents’ highest education in all within-class models,
6.Model 6: A full mixture with attentional-focus and approach-to-learning in all within-class models and the
other four covariates in the multinomial functions.
13

--- PAGE 14 ---
APREPRINT - AUGUST 20, 2021
=========================
Insert Figure 8 about here
=========================
Following the convention in the SEM literature, we decided the number of latent classes without any covariates. We
ﬁt a bilinear spline growth model and bilinear growth mixture models with two, three, and four classes. Information
criteria such as the BIC suggested that the model with three latent classes was the ‘best’ among the four candidate
models. Model 1, the growth mixture model, served as a reference model in this section. We evaluate the agreement,
quantiﬁed by Dumenci’s Latent Kappa (Dumenci, 2011), between the trajectory clusters obtained from the growth
mixture model and each of the other ﬁve models. We provide the membership agreement in Table 4. We also include
the CPU time charged for the execution of each model in Table 4 given that the computational budget is an important
consideration in practice.
=========================
Insert Table 4 about here
=========================
Growth Mixture Model
Table 5 summarizes the estimates of the class-speciﬁc growth factors. Based on the estimates, we obtained the model
implied trajectory of each latent class, as shown in Figure 9a. The estimated proportions in Class 1,2and3were
17:20%,45:00% and37:80%, respectively. Post-knot development in mathematics skills in three classes slowed down
substantially. The transition to the slower growth rate occurred at 82,109and98months in Class 1,2and3, respectively.
The students grouped into Class 1had the lowest levels of mathematics achievement in general (the estimated ﬁxed
effects of the intercept and two slopes were 24:046,1:921and0:925per month). The second cluster’s initial status and
developmental rates were lower than those of the ﬁrst cluster; however, students in Class 2had better performance in
mathematics as their transition to the slower growth rate occurred 1:5years later than students in Class 1. Students in
Class 3had the best performance in mathematics throughout the study duration.
=========================
Insert Table 5 about here
=========================
Cluster Predictor Mixture Model
We built two CP-mixture models, Model 2and Model 3. We included socioeconomic status (i.e., family income and
parents’ highest education) and demographic information (i.e., sex and race) in the multinomial functions of Model 2.
As shown in Figure 9b and Table 6, the estimated proportions and predicted trajectories slightly changed when adding
these selected covariates. On further investigation, 53out of 500students were assigned to a different group by Model 1
and Model 2. The Dumenci’s Latent Kappa between student clusters from two models was 0:83with95% CI (0:79,
0:88), suggesting an almost perfect agreement (Landis and Koch, 1977; Nakazawa, 2019). From this CP-mixture model,
we obtained the covariates’ effects, as shown in Table 6. Speciﬁcally, with all other covariates, boys are more likely to
be in Class 2and Class 3. Higher parents’ education increased the probability of being in Class 3.
=========================
Insert Table 6 about here
=========================
In Model 3, the other CP-mixture model, we included all six covariates in the multinomial functions. As shown in
Figure 9c, the estimated proportions and predicted trajectories also only slightly changed from those obtained from the
ﬁnite mixture model, and the Dumenci’s Latent Kappa was 0:84with95% CI: (0:80,0:88). The effects on Class 2and
Class 3of family income, parents’ highest education, sex and race/ethnicity of two CP-mixture models were the same
(in terms of effect size and direction). Additionally, higher attentional-focus and a better approach-to-learning increased
the likelihood of having better mathematics achievement.
Growth Predictor Mixture Model
Next, we constructed two GP-mixture models with the BLSGM-TICs as the within-class model, Model 4and Model 5.
In Model 4, we included the variables approach-to-learning and attentional-focus to explain the within-cluster trajectory
heterogeneity. As shown in Figure 9d and Table 7, the estimated proportions and predicted trajectories slightly changed
14

--- PAGE 15 ---
APREPRINT - AUGUST 20, 2021
from those obtained from the growth mixture model, and the Dumenci’s Latent Kappa was 0:85with95% CI: (0:81,
0:89).
An important piece of information obtained from the GP-mixture model is the estimates of the covariates with direct
effects, as shown in Table 7. First, the estimated means of the standardized attentional-focus/approach-to-learning was
negative ( 0:513/ 0:446), around zero ( 0:025/ 0:052) and positive ( 0:240/0:249) for Class 1, Class 2and Class 3,
respectively. It suggests that the region with a higher value of attentional-focus and approach-to-learning was associated
with higher mathematics scores and vice versa . Additionally, the effects of those covariates varied across classes,
although such effects were positive in general.
=========================
Insert Table 7 about here
=========================
In Model 5, we put the covariates family income and parents’ highest education to explain the within-cluster trajectory
heterogeneity. From Figure 9e, the estimated proportions and predicted trajectories changed a lot from those of Model
1, the growth mixture model. The Dumenci’s Latent Kappa was 0:11with95% CI: (0:05,0:17), suggesting slight agree-
ment. Upon further examination, the estimated means of the standardized family income (parents’ highest education
level) was 0:826( 0:612),0:869(0:601) and 0:304( 0:128) for Class 1, Class 2and Class 3, respectively. This
nonlinear relationship between socioeconomic status and academic performance is one possible explanation for this low
Dumenci’s Latent Kappa.
Full Mixture Model
Finally, we built Model 6, a full mixture model, with the variables attentional-focus and approach-to-learning in each
cluster and the other four in the multinomial functions. Figure 9f and Table 8 suggest that the estimated trajectories and
proportions were similar to those produced by the GMM. The Dumenci’s Latent Kappa between the student clusters
from the GMM and those from the full mixture was 0:87with95% CI (0:83,0:91). The direct and indirect effects on
the heterogeneity in the trajectories were similar to those in Model 4and Model 2, respectively.
=========================
Insert Table 8 about here
=========================
6.2 Possible Extension of the Proposed Mixture Model
In this section, we demonstrate how to extend the proposed mixture model in the SEM framework by allowing for
a time-varying covariate, approach-to-learning, in each latent class. We included sex, race/ethnicity, family income,
and parents’ highest education in the multinomial functions. We provide the estimates of the extended model in the
Online Supplementary Document. Although the estimated change patterns and proportions were similar to those of the
models in Section of Main Analysis, class membership showed substantial change. Dumenci’s Latent Kappa between
the trajectory types from the GMM and those from the extended model was 0:28with95% CI (0:22,0:35).
Similar to the GP-mixture model (Model 4) and the full mixture model (Model 6), the estimated means of the
standardized approach-to-learning were negative (about  1), around 0, and positive (about 1) in Class 1,2and3,
respectively over time. It suggests the time-varying covariate at each wave was split into three segments to associate
with mathematics trajectories in each latent class, similar to the covariates with direct effects in Model 4and Model
6. Additionally, the effects on the heterogeneity in the trajectories of the time-varying covariate varied across latent
classes. We also noted that girls are more likely to be in Class 2and Class 3when the within-class model was set as a
BLSGM with the time-varying covariate, which is different from the effect of the variable sex on the class-formation in
Model 2, Model 3and Model 6. One possible explanation for this opposite effect of the covariate sex is the difference
in the membership discussed above.
6.3 Sensitivity Analysis
In this section, we built stepwise mixture models as a sensitivity analysis. We consider two types of stepwise approaches,
the standard three-step method (Clogg, 1995) and the two-step method (Bakk and Kuha, 2018). We decided to ﬁt a
standard three-step method with modal assignment as it is one of the most popular methods in psychology (Hsiao
et al., 2020). We chose the two-step approach as Bakk and Kuha (2018) has shown that this method is a competitive
alternative to the three-step maximum likelihood approach (Vermunt, 2010) by simulation studies.
15

--- PAGE 16 ---
APREPRINT - AUGUST 20, 2021
The ﬁrst step of either the two- or three-step approach is building a GP-mixture model (i.e., Model 4in Section of
Main Analysis). As shown in the simulation studies and the empirical example analyses, the estimated proportions
and within-class parameters from the GP-mixture model and the full mixture model (i.e., one-step method) were very
similar. For the standard three-step method, we assigned each student to the cluster with the highest probability and
then constructed a multinomial logistic regression by the Rpackage nnet (Venables and Ripley, 2002). We estimated
logistic coefﬁcients for the two-step approach by ﬁxing the within-class parameters as their estimates from the Model 4.
We provide the estimates of logistic coefﬁcients of two stepwise methods in the Online Supplementary Document.
Generally, the estimates of logistic coefﬁcients of continuous covariates of both stepwise methods were very similar
to those provided by the full mixture model, although the estimated coefﬁcients of binary covariates were different.
Speciﬁcally, both the point estimates and the standard errors were larger in the stepwise models.
7 Discussion
This article extends MoE models to the SEM framework. The full mixture model and its three possible reduced models
are multivariate methods designed to uncover sample heterogeneity underlying longitudinal or cross-sectional data sets.
We linked these four models to the corresponding counterpart in the SEM framework. The FMMs and CP-mixture
models have received considerable attention in the SEM literature. On the contrary, the GP-mixture models and full
mixture models are relatively novel and have only been implemented in limited settings.
For the full mixture model and its three possible reduced versions, we performed in-depth investigations in terms of
convergence rate, performance measures (including relative bias, empirical SE, relative RMSE and coverage probability)
and clustering effects (including accuracy and entropy) by simulation studies. We also illustrated the proposed models
using a real-world data set from a longitudinal study of mathematics ability. The results demonstrate the proposed
models’ valuable capability to identify latent classes and examine direct and indirect effects on the sample heterogeneity
of covariates. The proposed model can be further extended in the SEM framework. For example, within-class covariates
can also be time-varying. We demonstrate how to implement and interpret the extended model in the Application
section.
We construct the proposed model using the one-step approach in a stepwise fashion. On the one hand, multiple existing
simulation studies have demonstrated that the one-step approach outperforms the two-step or three-step approach
concerning performance metrics such as bias and RMSE. On the other hand, to address the major critiques on the
one-step method, the number of clusters and the covariates added in the model need to be decided before constructing
the proposed models. As the current recommended approach in the SEM literature, we decided the number of latent
classes without covariates. We also propose to shrink covariate space by leveraging the SEM Forests.
We conducted a sensitivity analysis in the empirical example to examine whether the two-step or three-step approach
would provide different insights from the one-step method. As shown in the Application section, the proposed model
can also be constructed by stepwise approaches. The estimates of logistic coefﬁcients of continuous covariates were
very similar to those from the full mixture model, although the estimated coefﬁcients of binary covariates were different.
7.1 Practical Considerations
The current study focuses on applying mixture models to analyze the heterogeneity in nonlinear trajectories and the
impact that covariates have on such heterogeneity. As demonstrated in the Application section, the recommended steps
are:
1.Without any covariates, build a latent growth curve model and growth mixture models with different numbers
of clusters to select the optimal number by the BIC,
2.Construct a SEM Forest model using the latent growth curve model from (1) (the template model) and the
original data set with a pool of candidate covariates to select covariates with high importance,
3.Among the covariates from (2), decide which covariates have direct effects and include them in the latent
classes and the others in the multinomial functions to construct the proposed model(s).
Other than the stepwise list, we also want to provide a set of recommendations for possible issues that empirical
researchers may face in practice. First, it is not our aim to show that one model is universally preferred. We recommend
selecting the model according to domain knowledge and research interests. We decided to add four covariates with
the highest importance and demographic information in the model. In the full mixture model, we assume that the
variables teacher-reported attentional-focus and approach-to-learning affect the trajectory heterogeneity directly as they
reﬂect students’ ability and potential. In contrast, other covariates are more about the environment that students live
16

--- PAGE 17 ---
APREPRINT - AUGUST 20, 2021
in; accordingly, we placed them in the multinomial functions assuming that these covariates have indirect effects. In
addition, as discussed in Section Comparison Among Models, the likelihood-based criteria, such as the AIC and BIC,
cannot be used to select among these four mixture models due to their different model structures.
As shown in Section Misspeciﬁed Model, entropy does not help select a model among the full mixture model and its
three reduced versions in an exploratory study. It is not our goal to explore this metric all-inclusively in this current
project; still, we want to add a note for empirical researchers. Entropy itself is still a good metric to tell class separation.
However, entropy obtained from a growth mixture model with covariates only reﬂects the separation based on the
trajectories and covariates. Although our simulation results suggest that entropy is a good indicator of the fraction of
all correctly classiﬁed trajectories if we speciﬁed covariates correctly, we do not recommend using entropy from a
mixture model with covariates as an indicator of the class separation of trajectories alone as it is impossible to know if a
covariate is speciﬁed correctly in practice. We have shown the discrepancy between the patterns of accuracy (i.e., the
fraction of all correctly classiﬁed trajectories) and entropy from the misspeciﬁed model.
Second, in an exploratory study, researchers may hope that including covariates does not substantially inﬂuence class
membership. To evaluate whether adding covariates affects trajectory clusters, we recommend assessing the agreement
between the trajectory types obtained from the FMM and those from a mixture model with covariates, which can be
quantiﬁed by the Dumenci’s Latent Kappa (Dumenci, 2011). Adding covariates can also be driven by a speciﬁc research
question. For example, we may build Model 5if the research question is to group the relationship between mathematics
trajectories and socioeconomic status, although assuming the socioeconomic status can directly affect the trajectory
heterogeneity changed the membership heavily. Similarly, the extended model with the time-varying covariate allows
us to assess the effect of approach-to-learning on mathematics development over time in each latent class by grouping
the association between the mathematics trajectories and the repeated measures of the covariate.
Additionally, we propose one possible approach to select covariates by leveraging the SEM Forests algorithm. As
demonstrated in Section of Employing SEM Forests to Identify Important Covariates, SEM Forests identiﬁed covariates
with high importance efﬁciently. Although it is not our aim to comprehensively investigate the SEM Forests, we still
want to add two notes about model construction and variable importance for empirical researchers. First, when several
covariates are highly correlated, a covariate with a relatively low importance score is not necessarily unimportant. For
example, the correlation between attentional-focus and inhibitory-control is 0:7, yet the variable inhibitory-control has
a lower importance score than attentional-focus. One more reasonable explanation for this phenomenon is that the
SEM Forests model can address the collinearity between covariates to some extend. Imagine that the algorithm selects
the attentional-focus to predict the model-implied means and variance-covariance structure. This covariate also takes
over the predicting responsibility belonged to the variable inhibitory-control due to the high correlation between these
two variables. The algorithm will not consider splitting on the variable inhibitory-control. Second, the SEM Forests
model has several hyperparameters, including c(the size of the set of candidate predictors at each node) and the number
of trees. Researchers can also select a sampling method between ‘subsample’ and ‘bootstrap’. In this article, we set
the hyperparameters following Brandmaier et al. (2016) and the machine learning literature. We selected ‘bootstrap’
as the sampling method to follow the convention in the RFs model. However, if building a forest is the aim, these
hyperparameters needed to be tuned (Brandmaier et al., 2016).
Moreover, the selection of starting values of parameters is important when building a complicated model for a real-world
data analysis. A set of proper starting values helps improve the likelihood of convergence and alleviate the computational
burden. Empirically, we select proper starting values by (1) deciding appropriate scales for parameters and then (2)
searching starting values around the scales from which a model can achieve convergent status (i.e., the status code
0in the OpenMx ). We recommend plotting the trajectories to obtain the appropriate scales of growth factor means.
Sometimes, it may not be helpful to use the same set of starting values across clusters. We then recommend building a
parsimonious model (i.e., a FMM with ﬁxed variance-covariance matrices of growth factors) to estimate the means of
class-speciﬁc growth factors that can serve as the starting values. An option for the scale of variances and covariances of
growth factors is 1and0, respectively. The selection of scales of the xe-related parameters is relatively straightforward
as we standardize xe’s. Additionally, we set the scale of path coefﬁcients and logistic coefﬁcients as 0:5and1:0,
respectively. After obtaining appropriate scales, we do not recommend employing a grid search7to tune the starting
values given a large number of parameters. Instead, we suggest utilizing the function mxTryHard() in the Rpackage
OpenMx that allows for multiple attempts to ﬁt a model until generating a convergent solution or reaching the speciﬁed
maximum number of runs. At each attempt, each starting value is multiplied by a random draw8from a pre-speciﬁed
distribution.
7In a grid search, we create a list of starting values for each parameter, run the model with different combinations of the values
across all parameters, and see which set could lead to a convergence solution.
8For replication purposes, we recommend setting and recording seeds for random sampling.
17

--- PAGE 18 ---
APREPRINT - AUGUST 20, 2021
Although the purpose of our examples was pedagogical, in practice, researchers should be aware of the multiple
statistical tests conducted when ﬁtting a growth mixture model with covariates and should consider adjusting the tests
to control the type I error or false discovery rate. Furthermore, decisions about the importance of a ﬁnding should not
be based on p-values alone, but also consider effect sizes, prior evidence, and alternative explanations (Wasserstein
et al., 2019).
Last, in the Application section, it took 8,12,38and39minutes to ﬁt Model 1(a FMM), Model 2(a CP-mixture
model), Model 4(a GP-mixture model), and Model 6(a full mixture model), respectively. Note that the CPU time can
be reduced to about 30% if a structured time matrix is used rather than the individual measurement occasions.
7.2 Methodological Considerations and Future Directions
This study has shown multiple directions in need of further investigation. First, as stated earlier, we assume that one
covariate does not have direct and indirect effects on sample heterogeneity simultaneously based on conceptual and
technical considerations. We included the covariates attentional-focus and approach-to-learning, which are assumed to
have direct effects on the trajectory heterogeneity, in the within-class model. The clustering algorithm also divides them
into regions with negative, around zero and positive mean values when separating trajectories into clusters with lower,
medium and higher mathematics achievement (Models 4and6). Conceptually, it may not be reasonable to include the
two covariates in the multinomial functions as the predictors of latent classes with the two covariates’ class-speciﬁc
mean values. To further demonstrate our points, suppose we include the two covariates as the predictors of latent
classes. Since the covariates have been divided, the increased odds of being in Class 2or3compared to Class 1that
associated with a one SD difference in these predictors when the covariates are negative could be different from the
values when the covariates are positive (i.e., the linear assumption between the log-odds and the covariates could be
violated technically).
However, a covariate that has direct effects on sample heterogeneity often has indirect effects. Based on the class-speciﬁc
estimated means of the standardized path covariates (Models 4and6), a more proper gating function is to separate the
covariate space into multiple regions (for example, a negative, around zero, and a positive region). The estimates of
such gating functions would be the ‘boundary’ of each region. This issue has been addressed in the machine learning
literature. Jordan and Jacobs (1993) have developed a much more ﬂexible model by allowing for a multilevel gating
function to give the hierarchical mixture-of-experts (HMoE) model. Similar to a tree-based algorithm, the HMoE model
needs to select a covariate to split and the threshold value at each level of gating functions. Then a within-class model is
constructed in each region of the covariate space. Additionally, for the mixture model, the model ﬁtting is just the ﬁrst
part of the story as currently, the model only allows for (generalized) linear relationships between covariates and class
membership or growth factors in the SEM framework. Model diagnostics for evaluating such linear assumptions can
help strengthen the story. It is worth conducting further simulation studies to evaluate and develop at least visualization
tools for model diagnostics.
Second, the impact of a covariate with direct effects on the clustering algorithm depends on its inﬂuence on the
separation between latent classes. If we generated xefrom the same distribution across latent classes so that the
separation between clusters did not change, as shown in the simulation study, xeonly affected clustering results slightly.
On the contrary, we learned that adding a covariate with direct effects may affect trajectory clusters meaningfully
(Model 5and the extended model). One reasonable explanation is that xeaffects the separation between latent classes
since the estimates of the class-speciﬁc means of the xevaried a lot across clusters. It is worth conducting a further
simulation study that allows for varying parameters of xeto investigate the conditions under which and how those
covariates inﬂuence the clustering algorithm.
Third, in the Application section, we demonstrate how to extend the proposed mixture model by allowing for time-
varying covariates. Its performance, such as estimates and clustering effects, needs to be evaluated by a simulation
study. Additionally, in the sensitivity analyses, we build the proposed mixture model using stepwise approaches. A
further simulation study is needed to compare these stepwise approaches to the proposed full mixture model, especially
for the logistic coefﬁcients of binary covariates.
Last, the project proposes leveraging SEM Forests to select the covariates with high effects on sample heterogeneity
and then building models to evaluate their effect sizes. We tested SEM Forests’ performance using generated data sets
under several scenarios with different weights on covariates with direct and indirect effects along with noise variables.
As only a few articles other than the original article detailing this algorithm (Brandmaier et al., 2016), it is worth
conducting more comprehensive simulation studies to assess its performance. It is also worth examining how to tune
the hyperparameters, such as the number of trees and the size of covariates selected at each node.
18

--- PAGE 19 ---
APREPRINT - AUGUST 20, 2021
7.3 Concluding Remarks
In this article, we extend the MoE model, which allows for examining direct and indirect effects of covariates
simultaneously, to the SEM framework to investigate the heterogeneity in nonlinear trajectories. Overall, we have
shown the performance and application of MoE models using bilinear spline functional form with an unknown knot
and covariates as the within-class model. Note that the nonlinear underlying change patterns could be other functional
forms. We provide two common parametric functional forms, quadratic and Jenss-Bayley, in the online appendix for
the researchers who are willing to employ them.
References
Agresti, A. (2012). Categorical Data Analysis . Wiley.
Asparouhov, T. and Muthén, B. (2014). Auxiliary variables in mixture modeling: Three-step approaches using mplus.
Structural Equation Modeling: A Multidisciplinary Journal , 21(3):329–341.
Bakk, Z. and Kuha, J. (2018). Two-step estimation of models between latent classes and external variables. Psychome-
trika , 83:871–892.
Bandeen-Roche, K., Miglioretti, D. L., Zeger, S. L., and Rathouz, P. J. (1997). Latent variable regression for multiple
discrete outcomes. Journal of the American Statistical Association , 92(440):1375–1386.
Bauer, D. J. and Curran, P. J. (2003). Distributional assumptions of growth mixture models: Implications for
overextraction of latent trajectory classes. Psychological Methods , 8(3):338–363.
Bishop, C. M. (2006). Pattern Recognition and Machine Learning . Springer-Verlag.
Blozis, S. A. and Cho, Y . (2008). Coding and centering of time in latent curve models in the presence of interindividual
time heterogeneity. Structural Equation Modeling: A Multidisciplinary Journal , 15(3):413–433.
Boker, S. M., Neale, M. C., Maes, H. H., Wilde, M. J., Spiegel, M., Brick, T. R., Estabrook, R., Bates, T. C., Mehta, P.,
von Oertzen, T., Gore, R. J., Hunter, M. D., Hackett, D. C., Karch, J., Brandmaier, A. M., Pritikin, J. N., Zahery, M.,
and Kirkpatrick, R. M. (2020). OpenMx 2.17.2 User Guide .
Bolck, A., Croon, M., and Hagenaars, J. (2004). Estimating latent structure models with categorical variables: One-step
versus three-step estimators. Political Analysis , 12(1):3–27.
Brandmaier, A. M., Prindle, J. J., and Arnold, M. (2020). semtree: Recursive Partitioning for Structural Equation
Models . R package version 0.9.14.
Brandmaier, A. M., Prindle, J. J., McArdle, J. J., and Lindenberger, U. (2016). Theory-guided exploration with structural
equation model forests. Psychological Methods , 21(4):566–582.
Brandmaier, A. M., von Oertzen, T., McArdle, J. J., and Lindenberger, U. (2013). Structural equation model trees.
Psychological Methods , 18(1):71–86.
Breiman, L. (2001). Random forests. Machine Learning , 45:5–32.
Breiman, L., Friedman, J. H., Olshen, R. A., and Stone, C. J. (1984). Classiﬁcation and regression trees . Chapman &
Hall, New York, NY .
Carvalho, A. X. and Tanner, M. A. (2005). Mixtures-of-experts of autoregressive time series: asymptotic normality and
model speciﬁcation. IEEE Transactions on Neural Networks , 16(1):39–56.
Carvalho, A. X. and Tanner, M. A. (2007). Modelling nonlinear count time series with local mixtures of poisson
autoregressions. Computational Statistics & Data Analysis , 51(11):5266–5294.
Clogg, C. C. (1981). New developments in latent structure analysis. In Jackson, D. J. and Borgotta, E. F., editors,
Factor analysis and measurement in sociological research: A Multi-Dimensional Perspective , pages 215–246. SAGE
Publications, Beverly Hills, CA: Sage.
Clogg, C. C. (1995). Latent class models: Recent developments and prospects for the future. In Arminger, G., Clogg,
C. C., and Sobel, M. E., editors, Handbook of statistical modeling for the social and behavioral sciences , page
311–359.
Cohen, J. (1988). Statistical Power Analysis for the Behavioral Sciences (2nd Ed.) . Lawrence Erlbaum Associates.
Coulombe, P., Selig, J. P., and Delaney, H. D. (2015). Ignoring individual differences in times of assessment in growth
curve modeling. International Journal of Behavioral Development , 40(1):76–86.
Dayton, C. M. and Macready, G. B. (1988). Concomitant-variable latent-class models. Journal of the American
Statistical Association , 83(401):173–178.
19

--- PAGE 20 ---
APREPRINT - AUGUST 20, 2021
Diallo, T. M. O., Morin, A. J. S., and Lu, H. (2017). The impact of total and partial inclusion or exclusion of active and
inactive time invariant covariates in growth mixture models. Psychological Methods , 22(1):166–190.
Dumenci, L. (2011). The psychometric latent agreement model (plam) for discrete latent variables measured by multiple
items. Organizational research methods , 14(1):91–115.
Dumenci, L., Perera, R. A., Keefe, F. J., Ang, D. C., Slover, J., Jensen, M. P., and Riddle, D. L. (2019). Model-based
pain and function outcome trajectory types for patients undergoing knee arthroplasty: a secondary analysis from a
randomized clinical trial. Osteoarthritis and cartilage , 27(6):878–884.
Geweke, J. and Keane, M. (2007). Smoothly mixing regressions. Journal of Econometrics , 138(1):252–290.
Goodman, L. A. (1974). The analysis of systems of qualitative variables when some of the variables are unobservable.
part i-a modiﬁed latent structure approach. American Journal of Sociology , 79(5):1179–1259.
Gormley, I. C. and Murphy, T. B. (2008). Exploring voting blocs within the irish electorate: A mixture modeling
approach. Journal of the American Statistical Association , 103(483):1014–1027.
Gormley, I. C. and Murphy, T. B. (2011). Mixture of experts modelling with social science applications. In Mengersen,
K. L., Robert, C. P., and Titterington, D. M., editors, Mixtures: Estimation and Applications , Wiley Series in
Probability and Statistics, chapter 5, pages 101–121. Wiley.
Grimm, K. J. and Ram, N. (2009). Nonlinear growth models in mplus and sas. Structural Equation Modeling: A
Multidisciplinary Journal , 16(4):676–701.
Grimm, K. J., Ram, N., and Estabrook, R. (2010). Nonlinear structured growth mixture models in mplus and openmx.
Multivariate Behavioral Research , 45(6):887–909.
Grimm, K. J., Ram, N., and Estabrook, R. (2016). Growth Modeling: Structural Equation and Multilevel Modeling
Approaches . Guilford Press.
Haberman, S. (1979). Analysis of qualitative data. vol. 2: New developments. New York: Academic Press.
Hagenaars, J. A. (1993). Loglinear models with latent variables. Newbury Park, CA: Sage.
Handcock, M. S., Raftery, A. E., and Tantrum, J. M. (2007). Model-based clustering for social networks. Journal of the
Royal Statistical Society: Series A (Statistics in Society) , 170:301–354.
Harring, J. R., Cudeck, R., and du Toit, S. H. C. (2006). Fitting partially nonlinear random coefﬁcient models as sems.
Multivariate Behavioral Research , 41(4):579–596.
Hsiao, Y ., Kruger, E., Van Horn, M. L., Toﬁghi, D., MacKinnon, D. P., and Witkiewitz, K. (2020). Latent class
mediation: A comparison of six approaches. Multivariate Behavioral Research , 0(0):1–15.
Hunter, M. D. (2018). State space modeling in an open source, modular, structural equation modeling environment.
Structural Equation Modeling: A Multidisciplinary Journal , 25(2):307–324.
Hurn, M., Justel, A., and Robert, C. P. (2003). Estimating mixtures of regressions. Journal of Computational and
Graphical Statistics , 12(1):55–79.
Jacobs, R. A., Jordan, M. I., Nowlan, S. J., and Hinton, G. E. (1991). Adaptive mixtures of local experts. Neural
Computation , 3(1):79–87.
Jacobs, R. A., Peng, F., and Tanner, M. A. (1997). A bayesian approach to model selection in hierarchical mixtures-
of-experts architectures. Neural networks : the ofﬁcial journal of the International Neural Network Society ,
10(2):231–241.
Jordan, M. I. and Jacobs, R. A. (1993). Hierarchical mixtures of experts and the em algorithm. In Proceedings of 1993
International Conference on Neural Networks (IJCNN-93-Nagoya, Japan) , volume 2, pages 1339–1344.
Jöreskog, K. G. and Goldberger, A. S. (1975). Estimation of a model with multiple indicators and multiple causes of a
single latent variable. Journal of the American Statistical Association , 70(351):631–639.
Kamakura, W. A., Wedel, M., and Agrawal, J. (1994). Concomitant variable latent class models for conjoint analysis.
International Journal of Research in Marketing , 11(5):451–464.
Kim, M., Vermunt, J., Bakk, Z., Jaki, T., and Van Horn, M. L. (2016). Modeling predictors of latent classes in regression
mixture models. Structural Equation Modeling: A Multidisciplinary Journal , 23(4):601–614.
Kohli, N. (2011). Estimating unknown knots in piecewise linear-linear latent growth mixture models . PhD thesis,
University of Maryland.
Kohli, N. and Harring, J. R. (2013). Modeling growth in latent variables using a piecewise function. Multivariate
Behavioral Research , 48(3):370–397.
20

--- PAGE 21 ---
APREPRINT - AUGUST 20, 2021
Kohli, N., Harring, J. R., and Hancock, G. R. (2013). Piecewise linear-linear latent growth mixture models with
unknown knots. Educational and Psychological Measurement , 73(6):935–955.
Kohli, N., Hughes, J., Wang, C., Zopluoglu, C., and Davison, M. L. (2015). Fitting a linear-linear piecewise growth
mixture model with unknown knots: A comparison of two common approaches to inference. Psychological Methods ,
20(2):259–275.
Landis, J. and Koch, G. (1977). The measurement of observer agreement for categorical data. Biometrics , 33(1):159–
174.
Lê, T., Norman, G., Tourangeau, K., Brick, J. M., and Mulligan, G. (2011). Early childhood longitudinal study:
Kindergarten class of 2010-2011 – sample design issues. In JSM Proceedings 2011 , pages 1629–1639. Alexandria,
V A: American Statistical Association.
Lê Cao, K. A., Meugnier, E., and McLachlan, G. J. (2010). Integrative mixture of experts to combine clinical factors
and gene markers. Bioinformatics , 26(9):1192–1198.
Lehmann, E. L. and Casella, G. (1998). Theory of Point Estimation, 2nd edition . Springer, New York, NY .
Liu, J. (2019). Estimating Knots in Bilinear Spline Growth Models with Time-invariant Covariates in the Framework of
Individual Measurement Occasions . PhD thesis, Virginia Commonwealth University.
Liu, J. and Perera, R. A. (2021). Estimating knots and their association in parallel bilinear spline growth curve models
in the framework of individual measurement occasions. Psychological methods , Advance online publication.
Liu, J., Perera, R. A., Kang, L., Kirkpatrick, R. M., and Sabo, R. T. (2020a). Obtaining interpretable parameters from
reparameterizing longitudinal models: transformation matrices between growth factors in two parameter-spaces.
Liu, J., Perera, R. A., Kang, L., Sabo, R. T., and Kirkpatrick, R. M. (2020b). Hybridizing two-step growth mixture
model and exploratory factor analysis to examine heterogeneity in nonlinear trajectories.
Lubke, G. and Muthén, B. (2007). Performance of factor mixture models as a function of model size, covariate effects,
and class-speciﬁc parameters. Structural Equation Modeling: A Multidisciplinary Journal , 14(1):26–47.
Masyn, K. E. (2017). Measurement invariance and differential item functioning in latent class analysis with stepwise
multiple indicator multiple cause modeling. Structural Equation Modeling: A Multidisciplinary Journal , 24(2):180–
197.
McArdle, J. and Epstein, D. (1987). Latent growth curves within developmental structural equation models. Child
Development , 58(1):110–133.
McLachlan, G. and Peel, D. (2000). Finite Mixture Models . John Wiley & Sons, Inc.
Mehta, P. D. and Neale, M. C. (2005). People are variables too: Multilevel structural equations modeling. Psychological
Methods , 10(3):259–284.
Mehta, P. D. and West, S. G. (2000). Putting the individual back into individual growth curves. Psychological Methods ,
5(1):23–43.
Morris, T. P., White, I. R., and Crowther, M. J. (2019). Using simulation studies to evaluate statistical methods. Statistics
in Medicine , 38(11):2074–2102.
Murphy, K. P. (2012). Machine Learning: a Probabilistic Perspective . The MIT Press.
Muthén, B. (2004). Latent variable analysis:. In Kaplan, D., editor, The SAGE Handbook of Quantitative Methodology
for the Social Sciences , chapter 19, pages 345–368. SAGE Publications, Washington, DC, US.
Muthén, B. and Muthén, L. (2000). Integrating person-centered and variable-centered analyses: Growth mixture
modeling with latent trajectory classes. Alcoholism: Clinical and Experimental Research , 24(6):882–891.
Muthén, B. and Shedden, K. (1999). Finite mixture modeling with mixture outcomes using the EM algorithm.
Biometrics , 55(2):463–469.
Nakazawa, M. (2019). fmsb: Functions for Medical Statistics Book with some Demographic Data . R package version
0.7.0.
Neale, M. C., Hunter, M. D., Pritikin, J. N., Zahery, M., Brick, T. R., Kirkpatrick, R. M., Estabrook, R., Bates,
T. C., Maes, H. H., and Boker, S. M. (2016). OpenMx 2.0: Extended structural equation and statistical modeling.
Psychometrika , 81:535–549.
Nylund, K. L., Asparouhov, T., and Muthén, B. (2007). Deciding on the number of classes in latent class analysis
and growth mixture modeling: A monte carlo simulation study. Structural Equation Modeling: A Multidisciplinary
Journal , 14(4):535–569.
21

--- PAGE 22 ---
APREPRINT - AUGUST 20, 2021
Nylund-Gibson, K. and Masyn, K. E. (2016). Covariates and mixture modeling: Results of a simulation study exploring
the impact of misspeciﬁed effects on class enumeration. Structural Equation Modeling: A Multidisciplinary Journal ,
23(6):782–797.
Oshiro, T. M., Perez, P. S., and Baranauskas, J. A. (2012). How many trees in a random forest? In Perner, P., editor,
Machine Learning and Data Mining in Pattern Recognition. MLDM 2012. Lecture Notes in Computer Science , pages
154–168. Springer, Berlin, Heidelberg.
Preacher, K. J. and Hancock, G. R. (2015). Meaningful aspects of change as novel random coefﬁcients: A general
method for reparameterizing longitudinal models. Psychological Methods , 20(1):84–101.
Pritikin, J. N., Hunter, M. D., and Boker, S. M. (2015). Modular open-source software for Item Factor Analysis.
Educational and Psychological Measurement , 75(3):458–474.
Rosen, O., Jiang, W., and Tanner, M. (2000). Mixtures of marginal models. Biometrika , 87(2):391–404.
Rosen, O. and Tanner, M. (1999). Mixtures of proportional hazards regression models. Statistics in Medicine ,
18(9):1119–1131.
Seber, G. A. F. and Wild, C. J. (2003). Nonlinear Regression . John Wiley & Sons, Inc.
Stegmann, G. and Grimm, K. J. (2018). A new perspective on the effects of covariates in mixture models. Structural
Equation Modeling: A Multidisciplinary Journal , 25(2):167–178.
Sterba, S. K. (2014). Fitting nonlinear latent growth curve models with individually varying time points. Structural
Equation Modeling: A Multidisciplinary Journal , 21(4):630–647.
Thompson, T. J., Smith, P., and Boyle, J. P. (1998). Finite mixture models with concomitant information: Assessing
diagnostic criteria for diabetes. Journal of the Royal Statistical Society. Series C (Applied Statistics) , 47(3):393–404.
Tishler, A. and Zang, I. (1981). A new maximum likelihood algorithm for piecewise regression. Journal of the American
Statistical Association , 76(376):980–987.
Venables, W. N. and Ripley, B. D. (2002). Modern Applied Statistics with S . Springer, New York, fourth edition.
Vermunt, J. K. (1997). Advanced quantitative techniques in the social sciences series, Vol. 8. Log-linear models for
event histories. Thousand Oaks, CA, US: Sage Publications, Inc.
Vermunt, J. K. (2010). Latent class modeling with covariates: Two improved three-step approaches. Political Analysis ,
18(4):450–469.
Wasserstein, R. L., Schirm, A. L., and Lazar, N. A. (2019). Moving to a world beyond ‘p<0.05’. The American
Statistician , 73(sup1):1–19.
Wood, S. A., Jiang, W., and Tanner, M. (2002). Bayesian mixture of splines for spatially adaptive nonparametric
regression. Biometrika , 89(3):513–528.
Yamaguchi, K. (2000). Multinomial logit latent-class regression models: An analysis of the predictors of gender-role
attitudes among japanese women. American Journal of Sociology , 105(6):1702–1740.
Zeevi, A. J., Meir, R., and Maiorov, V . (1998). Error bounds for functional approximation and estimation using mixtures
of experts. IEEE Transactions on Information Theory , 44(3):1010–1025.
Appendix A Formula Derivation
A.1 Reparameterization of Class-speciﬁc Growth Factors
In the original setting of a bilinear spline growth model, we have three growth factors for each individual to deﬁne the
underlying functional form of repeated measures: the measurement at t0(0i) and one slope of each stage ( 1iand
2i, respectively). To estimate the knot in each latent class, we need to reparameterize these growth factors to be the
measurement at the knot ( 0i+1i), the mean of two slopes (1i+2i
2), and the half difference between two slopes
(2i 1i
2) for theithindividual (Seber and Wild, 2003, Chapter 9).
=========================
Insert Figure A.1 about here
=========================
22

--- PAGE 23 ---
APREPRINT - AUGUST 20, 2021
Tishler and Zang (1981) and Seber and Wild (2003) have proved that a linear-linear regression model can be expressed
as either the maximum or minimum response value of two trajectories. Liu (2019) and Liu et al. (2020a) extended such
expressions to the framework of BLSGM and showed that two possible forms of bilinear spline for the ithindividual as
such in Figure A.1. In the left panel ( 1i>2i), the measurement yijis always the minimum value of two lines and
yij= min (0i+1itij;02i+2itij). The measurements pre- and post-knot can be uniﬁed
yij= min (0i+1itij;02i+2itij)
=1
2 
0i+1itij+02i+2itij j0i+1itij 02i 2itijj
=1
2 
0i+1itij+02i+2itij
 1
2 
j0i+1itij 02i 2itijj
=1
2 
0i+02i+1itij+2itij
 1
2 
1i 2i
jtij j
=0i+1i 
tij 
+2ijtij j
=0i+1i 
tij 
+2iq
(tij )2;(A.1)
where0i,1iand2iare the measurement at the knot, the mean of two slopes, and the half difference between two
slopes of the trajectory of yij. With straightforward algebra, the outcome yijof the bilinear spline in the right panel,
where the measurement yijis always the maximum value of two lines, has the same ﬁnal expression in Equation A.1.
We obtain the class-speciﬁc reparameterized growth factors by applying such transformation for three growth factors in
each latent class.
A.2 Class-speciﬁc Transformation and Inverse-transformation Matrices
Supposef:R3!R3is a function, which takes a point i2R3as input and produces the vector f(i)2R3(i.e.,
0
i2R3) as output. By the multivariate Delta Method9(Lehmann and Casella, 1998, Chapter 1), for the ithindividual
in thekthcluster
0
i=f(i)N
f((k)
);rf((k)
)	(k)
rT
f((k)
)
; (A.2)
where(k)
and	(k)
are the mean vector and variance-covariance matrix of class-speciﬁc growth factors in the original
framework, and fis deﬁned as
f(i) = 
0i+(k)1i1i+2i
22i 1i
2T:
Similarly, suppose h:R3!R3is a function, which takes a point 0
i2R3as input and produces the vector
h(0
i)2R3(i.e.,i2R3) as output. By the multivariate Delta Method, for the ithindividual in the kthcluster
i=h(0(k)
i)N
h(0(k)
);rh(0(k)
)	0(k)
rT
h(0(k)
)
; (A.3)
where0(k)
and	0(k)
are the mean vector and variance-covariance matrix of class-speciﬁc growth factors in the
reparameterized framework, and his deﬁned as
h(0
i) = 
0
0i (k)0
1i+(k)0
2i0
1i 0
2i0
1i+0
2iT:
Based on Equations (A.2) and (A.3), the transformation between the mean vector of the class-speciﬁc growth factors in
the two parameter-spaces can be conducted by 0(k)
=f((k)
)and(k)
=h(0(k)
), respectively. We can also deﬁne
matrices rf((k)
)andrh(0(k)
)to transform the (unexplained) variance-covariance matrix of the class-speciﬁc
growth factors in the two parameter-spaces as
	0(k)
=rf((k)
)	(k)
rT
f((k)
)
=0
@1(k)0
0 0:5 0:5
0 0:5 0:51
A	(k)
0
@1(k)0
0 0:5 0:5
0 0:5 0:51
AT
9In this study, both fandhare linear functions. Under this scenario, the mean and variance can be derived using the theorem for
calculating the mean and variance of linear combinations. The results obtained by the theorem and the Delta Method are identical.
23

--- PAGE 24 ---
APREPRINT - AUGUST 20, 2021
and
	(k)
=rh(0(k)
)	0(k)
rT
h(0(k)
)
=0
@1 (k)(k)
0 1 1
0 1 11
A	0(k)
0
@1 (k)(k)
0 1 1
0 1 11
AT
;
respectively.
In the full mixture model and GP-mixture model, we need to regress growth factors on the covariates with direct effects.
We need to re-express the path coefﬁcients if we reparameterize growth factors. The relationship between class-speciﬁc
growth factor parameters in the original setting and those in the reparameterized frame can be further expressed with
path coefﬁcients as
0(k)
=f((k)
)()E(0(k)
e0+0(k)
exei+0
i) =f(E((k)
e0+(k)
exei+i))
()0(k)
e0+0(k)
eE(xei) =f((k)
e0+(k)
eE(xei))
(k)
=h(0(k)
)()E((k)
e0+(k)
exei+i) =h(E(0(k)
e0+0(k)
exei+0
i))
()(k)
e0+(k)
eE(xei) =h(0(k)
e0+0(k)
eE(xei))
	0(k)
=rf((k)
)	(k)
rT
f((k)
)
()Var(0(k)
e0+0(k)
exei+0
i) =rf((k)
)Var((k)
e0+(k)
exei+i)rT
f((k)
)
()Var(0(k)
exei+0
i) =rf((k)
)Var((k)
exei+i)rT
f((k)
)
()0(k)
eVar(xei)0(k)T
e +Var(0
i) =rf((k)
)(k)
eVar(xei)(k)T
erT
f((k)
) +rf((k)
)Var(i)rT
f((k)
)
()0(k)
e=rf((k)
)(k)
e
	(k)
=rh(0(k)
)	0(k)
rT
h(0(k)
)
()Var((k)
e0+(k)
exei+i) =rh(0(k)
)Var(0(k)
e0+0(k)
exei+0
i)rT
h(0(k)
)
()Var((k)
exei+i) =rh(0(k)
)Var(0(k)
exei+0
i)rT
h(0(k)
)
()(k)
eVar(xei)(k)T
e+Var(i) =rh(0(k)
)0(k)
eVar(xei)0(k)T
erT
h(0(k)
) +rh(0(k)
)Var(0
i)rT
h(0(k)
)
()(k)
e=rh(0(k)
)0(k)
e
A.3 Model Speciﬁcation and Estimation of GP-Mixture Models, CP-Mixture Models and Finite Mixture
Models
A.3.1 Model Speciﬁcation and Estimation of GP-Mixture Models
The difference between GP-mixture models and full mixture models lies in that the membership of the GP-mixture
model does not rely on any covariates. Accordingly, we need to modify Equation (1) which deﬁnes the full mixture
model to be
p(yijzi=k;xei) =KX
k=1g(zi=k)p(yijzi=k;xei); (A.4)
whereg(zi=k)can be viewed as the proportion of the sample in class kwith two constraints 0g(zi=k)1andPK
k=1g(zi=k) = 1 . Equations (A.4), (3), and (4) together deﬁne a GP-mixture model.
From the deﬁnition, the within-class model of the GP-mixture model is the same as that of the full mixture model.
Accordingly, the within-class implied mean vector ( (k)
i) and variance-covariance matrix ( (k)
i) of repeated outcomes
yifor theithindividual in the kthcomponent are Equations (5) and (6), respectively. The parameters need to be
estimated in the model speciﬁed in Equations (A.4), (3), and (4) are given
GP=f(k)
e0;	(k)
;(k);(k)
e;(k)
xe;(k);(k)
;(k)g
=f(k)
0;(k)
1;(k)
2; (k)
00; (k)
01; (k)
02; (k)
11; (k)
12; (k)
22;(k);(k)
e;(k)
xe;(k);(k)
;(k)g
k= 2;:::;K for(k);indicating the proportion of the kthlatent class;
k= 1;:::;K for other parameters :
24

--- PAGE 25 ---
APREPRINT - AUGUST 20, 2021
If we want to use the EM algorithm to obtain the estimates from the GP-mixture model, we also need to modify the
cluster responsibilities at an iteration tas
^r(t)
ik=^(k)(t 1)p(yij^(k)(t 1)
i;^(k)(t 1)
i;xei)
PK
k=1^(k)(t 1)p(yij^(k)(t 1)
i;^(k)(t 1)
i;xei):
A.3.2 Model Speciﬁcation and Estimation of CP-Mixture Models
The difference between CP-mixture models and full mixture models lies in that the class-speciﬁc growth factors do not
depend on any covariates. Accordingly, we need to modify Equations (1) and (4) that deﬁne a full mixture model to be
p(yijzi=k;xgi) =KX
k=1g(zi=kjxgi)p(yijzi=k); (A.5)
and
ij(zi=k) =(k)
+i; (A.6)
respectively. Equations (A.5), (2), (3), and (A.6) together deﬁne a CP-mixture model.
As the CP-mixture model’s growth factors do not depend on any covariates, we need to remove the covariates from the
model-implied mean vector and variance-covariance matrix and write them as
(k)
i=i((k))(k)
; (A.7)
(k)
i=i((k))	(k)
i((k))T+(k)
I; (A.8)
where 	(k)
is now deﬁned as the variance-covariance matrix of the class-speciﬁc growth factors. The parameters need
to be estimated in the model speciﬁed in Equations (A.5), (2), (3), and (A.6) are given
CP=f(k)
;	(k)
;(k);(k)
;(k)
g0;(k)
gg
=f(k)
0;(k)
1;(k)
2; (k)
00; (k)
01; (k)
02; (k)
11; (k)
12; (k)
22;(k);(k)
;(k)
g0;(k)
gg;
k= 2;:::;K for(k)
g0;(k)
g;
k= 1;:::;K for other parameters :
Cluster responsibilities at an iteration talso need to be modiﬁed accordingly as
^r(t)
ik=g(zi=kjxgi)(t 1)p(yij^(k)(t 1)
i;^(k)(t 1)
i )
PK
k=1g(zi=kjxgi)(t 1)p(yij^(k)(t 1)
i;^(k)(t 1)
i ):
A.3.3 Model Speciﬁcation and Estimation of Finite Mixture Models
The difference between ﬁnite mixture models and full mixture models lies in that neither the membership nor the
class-speciﬁc growth factors depend on any covariates. Accordingly, we need to modify Equation (1) that deﬁnes a full
mixture model to be
p(yijzi=k) =KX
k=1g(zi=k)p(yijzi=k): (A.9)
Equations (A.9), (3), and (A.6) together deﬁne a FMM. The within-class implied mean vector ( (k)
i) and variance-
covariance matrix ( (k)
i) of a FMM can also be expressed as Equations (A.7) and (A.8), respectively. The parameters
need to be estimated in the model speciﬁed in Equations (A.9), (3), and (A.6) are given
FMM=f(k)
;	(k)
;(k);(k)
;(k)g
=f(k)
0;(k)
1;(k)
2; (k)
00; (k)
01; (k)
02; (k)
11; (k)
12; (k)
22;(k);(k)
;(k)g;
k= 2;:::;K for(k);indicating the proportion of the kthlatent class;
k= 1;:::;K for other parameters :
Its cluster responsibilities at an iteration tis
^r(t)
ik=^(k)(t 1)p(yij^(k)(t 1)
i;^(k)(t 1)
i )
PK
k=1^(k)(t 1)p(yij^(k)(t 1)
i;^(k)(t 1)
i ):
25

--- PAGE 26 ---
APREPRINT - AUGUST 20, 2021
Table 1: Performance Metrics: Deﬁnitions and Estimates
Criteria Deﬁnition Estimate
Relative Bias E^(^ )=PS
s=1(^s )=S
Empirical SEq
Var(^)qPS
s=1(^s )2=(S 1)
Relative RMSEq
E^(^ )2=qPS
s=1(^s )2=S=
Coverage Probability Pr(^low^upper)PS
s=1I(^low;s^upper;s)=S
1: the population value of the parameter of interest
2^: the estimate of 
3S: the number of replications and set as 1;000in our simulation study
4s= 1;:::;S : indexes the replications of the simulation
5^s: the estimate of from thesthreplication
6: the mean of ^s’s across replications
7I(): an indicator function
26

--- PAGE 27 ---
APREPRINT - AUGUST 20, 2021
Table 2: Simulation Design for the Mixture Model with the Bilinear Spline Growth Model with an Unknown Knot and
Time-invariant Covariates as the Within-class Model in the Framework of Individual Measurement Occasions
Fixed Conditions
Variables Conditions
Variance of Intercept  (k)
00= 25
Variance of Slopes  (k)
11= (k)
22= 1
Correlations of GFs1(k)= 0:3
Time ( t) 10scaled and equally spaced tj(j= 0;;J 1;J= 10)
Individual t tijU(tj ;tj+ )(j= 0;;J 1;  = 0:25)
Sample Size n= 500
Mahalanobis distance d= 0:86
Manipulated Conditions
Variables Conditions
Locations of knots(1)
= 4:00;(2)
= 5:00
(1)
= 3:75;(2)
= 5:25
(1)
= 3:50;(2)
= 5:50
Logistic Coefﬁcientsg0= 0,g1= log(1:5),g2= log(1:7)(allocation ratio: 1:1)
g0= 0:775,g1= log(1:5),g2= log(1:7)(allocation ratio: 1:2)
Path Coefﬁcients2Covariates explain 13% variability of GFs in both clusters
Covariates explain 13% and26% variability of GFs in Cluster 1and2
Covariates explain 26% variability of GFs in both clusters
Residual Variance (k)
= 1or2
Scenario 1: Different means of initial status and (means of) knot locations
Variables Conditions of 2 latent classes
Means of Slope 1’s (k)
1= 5 (k= 1;2)
Means of Slope 2’s (k)
2= 2:6 (k= 1;2)
Means of Intercepts (1)
0= 98 ,(2)
0= 102 (d= 0:86)
Scenario 2: Different means of slope 1 and (means of) knot locations
Variables Conditions of 2 latent classes
Means of Intercepts (k)
0= 100 (k= 1;2)
Means of Slope 2’s (k)
2= 2 (k= 1;2)
Means of Slope 1’s (1)
1= 4:4,(2)
1= 3:6 (d= 0:86)
Scenario 3: Different means of slope 2 and (means of) knot locations
Variables Conditions of 2 latent classes
Means of Intercepts (k)
0= 100 (k= 1;2)
Means of Slope 1’s (k)
1= 5 (k= 1;2)
Means of Slope 2’s (1)
2= 2:6,(2)
2= 3:4 (d= 0:86)
1GFs represent Growth Factors.
2For each class-speciﬁc path coefﬁcients, e2= 1:5e1.
Table 3: Scenarios of Demonstrating the Approach for Identifying Covariates
Scenario Latent Class 1 Latent Class 2 Multinomial Function
1 Covariates explain 2%variability1—2—
2 Covariates explain 13% variability — —
3 Covariates explain 26% variability — —
4 Covariates explain 2%variability Covariates explain 2%variability 1= log(1:5),2= log(1:7)
5 Covariates explain 2%variability Covariates explain 13% variability 1= log(1:5),2= log(1:7)
6 Covariates explain 13% variability Covariates explain 13% variability 1= log(1:5),2= log(1:7)
7 Covariates explain 13% variability Covariates explain 26% variability 1= log(1:5),2= log(1:7)
8 Covariates explain 26% variability Covariates explain 26% variability 1= log(1:5),2= log(1:7)
1For the path coefﬁcients in each latent class, we set e2= 1:5e1.
2— indicates that the corresponding metric is not applicable for that scenario.
27

--- PAGE 28 ---
APREPRINT - AUGUST 20, 2021
Table 4: Mixture Models Constructed for Analyzing the Motivating Data
Model1-2ll AIC BIC Entropy Kappa Statistic2Judgment3Time4
Model 1 31077 31147 31294 0 :654 —5— 7:75min
Model 2 31009 31095 31276 0 :684 0:83(0:79,0:88) Almost perfect agreement 11:65min
Model 3 30990 31084 31282 0 :694 0:84(0:80,0:88) Almost perfect agreement 15:44min
Model 4 33342 33478 33765 0 :682 0:85(0:81,0:89) Almost perfect agreement 38:38min
Model 5 33204 33340 33627 0 :788 0:11(0:05,0:17) Slight agreement 41:77min
Model 6 33282 33434 33755 0 :699 0:87(0:83,0:91) Almost perfect agreement 39:12min
1Model 1—Model 6are (1) a ﬁnite mixture model without any covariates, (2) a CP-mixture model with family income,
parents’ highest education, sex and race/ethnicity in the multinomial functions, (3) a CP-mixture model with family
income, parents’ highest education, sex, race/ethnicity, attentional-focus, approach-to-learning in all multinomial functions,
(4) a GP-mixture model with the variable attentional-focus and approach-to-learning in all within-class models, (5) a
GP-mixture model with the variable family income and parents’ highest education in all within-class models and (6) a full
mixture with the covariate attentional-focus in all within-class models and the other four covariates in all multinomial
functions. All models are constructed with 3latent classes.
2Kappa statistic, which is Dumenci’s Latent Kappa coefﬁcient, is for the agreement between the membership obtained
from the FMM and each of the other models.
3Judgment is based on the output of the Rpackage fmsb .
4Time taken is the CPU time charged for the execution of each model, which is recorded by the Rfunction proc.time() .
5— indicates that the corresponding metric is not applicable for the FMM.
Table 5: Estimates of Growth Mixture Model with Bilinear Spline Change Patterns (3 Latent Classes)
Class 1 Class 2 Class 3
Mean of Growth Factor Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
Intercept124:046(1:816)<0:0001222:037(0:893)<0:000132:092(1:013)<0:0001
Slope 1 1 :921(0:087)<0:00011:684(0:028)<0:00012:075(0:031)<0:0001
Slope 2 0 :925(0:033)<0:00010:554(0:037)<0:00010:675(0:025)<0:0001
Additional Parameter Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
Knot 82:238(0:811)<0:0001108:929(0:659)<0:000197:567(0:539)<0:0001
Variance of Growth Factor Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
Intercept 94:919(27:720) 0:000665:310(11:906)<0:000185:261(14:567)<0:0001
Slope 1 0 :241(0:078) 0:0020:051(0:011)<0:00010:037(0:010) 0:0002
Slope 2 0 :038(0:009)<0:00010:028(0:013) 0:03130:008(0:006) 0:1824
1Intercept was deﬁned as mathematics IRT scores at 60-month old in this case.
2indicates statistical signiﬁcance at 0:05level.
28

--- PAGE 29 ---
APREPRINT - AUGUST 20, 2021
Table 6: Estimates of CP-mixture model with Bilinear Spline Change Patterns (3 Latent Classes)
Class 1 Class 2 Class 3
Mean of Growth Factor Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
Intercept122:498(1:930)<0:0001221:706(0:876)<0:000132:176(1:101)<0:0001
Slope 1 1 :872(0:078)<0:00011:667(0:029)<0:00012:066(0:028)<0:0001
Slope 2 0 :940(0:029)<0:00010:508(0:039)<0:00010:680(0:023)<0:0001
Additional Parameter Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
Knot 82:190(0:022)<0:0001110:029(0:682)<0:000197:868(0:553)<0:0001
Variance of Growth Factor Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
Intercept 76:159(28:955) 0:008560:347(10:773)<0:0001100:901(16:245)<0:0001
Slope 1 0 :182(0:066) 0:00580:042(0:009)<0:00010:039(0:010) 0:0001
Slope 2 0 :037(0:008)<0:00010:033(0:015) 0:02780:010(0:006) 0:0956
Logistic Coef. OR (95% CI) OR ( 95% CI) OR ( 95% CI)
Family Income —30:970(0:894,1:052) 1:030(0:947,1:121)
Parents’ Highest Education — 0:979(0:774,1:238) 1:386(1:095,1:753)
Sex(0—Boy; 1—Girl) — 0:391(0:187,0:816)0:379(0:185,0:776)
Race (0—White; 1—Others) — 0:586(0:279,1:232) 0:446(0:220,0:904)
1Intercept was deﬁned as mathematics IRT scores at 60-month old in this case.
2indicates statistical signiﬁcance at 0:05level.
3We set Class 1as the reference group.
Table 7: Estimates of GP-mixture model with Bilinear Spline Change Patterns (3 Latent Classes)
Class 1 Class 2 Class 3
Intercept of Growth Factor Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
Intercept124:069(1:841)<0:0001223:008(0:729)<0:000132:067(1:064)<0:0001
Slope 1 2 :062(0:092)<0:00011:651(0:027)<0:00012:080(0:031)<0:0001
Slope 2 0 :858(0:037)<0:00010:590(0:032)<0:00010:665(0:026)<0:0001
Additional Parameter Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
Knot 83:670(0:034)<0:0001108:648(0:647)<0:000197:555(0:550)<0:0001
Residual of Growth Factor Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
Intercept 66:657(22:252) 0:002762:036(9:303)<0:000188:825(13:816)<0:0001
Slope 1 0 :142(0:054) 0:00850:070(0:010)<0:00010:038(0:010) 0:0001
Slope 2 0 :024(0:008) 0:00270:039(0:012) 0:00120:005(0:006) 0:4047
Mean of Covariates3Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
attentional-focus  0:513(0:183) 0:0051 0:025(0:079) 0:7517 0:240(0:083) 0:0038
approach-to-learning  0:446(0:169) 0:0083 0:052(0:081) 0:5209 0:249(0:079) 0:0016
Variances of Covariates Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
attentional-focus 1:407(0:266)<0:00010:920(0:095)<0:00010:770(0:100)<0:0001
approach-to-learning 1:061(0:211)<0:00011:038(0:102)<0:00010:775(0:090)<0:0001
Path Coefﬁcients Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
attentional-focus to Intercept 1:032(1:959) 0:5983 1:605(1:052) 0:1271 1:887(1:637) 0:2490
attentional-focus to Slope 1 0 :221(0:087) 0:01110:064(0:034) 0:0598 0:010(0:043) 0:8161
attentional-focus to Slope 2 0:171(0:046) 0:00020:056(0:038) 0:1406 0:030(0:034) 0:3776
approach-to-learning to Intercept 1:255(2:180) 0:5648 2:337(0:964) 0:0153 0:267(1:600) 0:8675
approach-to-learning to Slope 1 0:058(0:092) 0:5284 0:058(0:031) 0:0613 0:042(0:042) 0:3173
approach-to-learning to Slope 2 0:119(0:053) 0:0247 0:054(0:035) 0:1229 0:067(0:032) 0:0363
1Intercept was deﬁned as mathematics IRT scores at 60-month old in this case.
2indicates statistical signiﬁcance at 0:05level.
3We built the model using standardized covariate with direct effects (i.e., attentional-focus and approach-to-learning).
29

--- PAGE 30 ---
APREPRINT - AUGUST 20, 2021
Table 8: Estimates of Full Mixture Model with Bilinear Spline Change Patterns (3 Latent Classes)
Class 1 Class 2 Class 3
Intercept of Growth Factor Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
Intercept120:896(1:455)<0:0001222:752(0:800)<0:000132:765(0:987)<0:0001
Slope 1 1 :947(0:068)<0:00011:671(0:026)<0:00012:077(0:030)<0:0001
Slope 2 0 :899(0:040)<0:00010:577(0:035)<0:00010:682(0:023)<0:0001
Additional Parameter Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
Knot 82:190(0:021)<0:0001108:753(0:635)<0:000197:139(0:487)<0:0001
Residual of Growth Factor Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
Intercept 28:890(13:486) 0:032262:819(10:103)<0:000197:677(14:122)<0:0001
Slope 1 0 :054(0:041) 0:1878 0:059(0:010)<0:00010:041(0:010)<0:0001
Slope 2 0 :037(0:010) 0:00020:041(0:013) 0:00160:006(0:006) 0:3173
Mean of Covariates3Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
attentional-focus  0:325(0:201) 0:1059 0:074(0:090) 0:4110 0:207(0:079) 0:0088
approach-to-learning  0:232(0:185) 0:2098 0:108(0:090) 0:2301 0:212(0:074) 0:0042
Variances of Covariates Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
attentional-focus 1:297(0:246)<0:00010:969(0:110)<0:00010:832(0:101)<0:0001
approach-to-learning 1:134(0:207)<0:00011:063(0:108)<0:00010:794(0:087)<0:0001
Path Coefﬁcients Estimate (SE) P value Estimate (SE) P value Estimate (SE) P value
attentional-focus to Intercept  0:873(1:656) 0:5981 1:828(1:174) 0:1195 1:253(1:733) 0:4697
attentional-focus to Slope 1 0 :333(0:096) 0:00050:028(0:032) 0:3816 0:019(0:042) 0:6510
attentional-focus to Slope 2 0:058(0:049) 0:2365 0:046(0:041) 0:2619 0:047(0:035) 0:1793
approach-to-learning to Intercept 3:641(1:829) 0:04651:546(1:043) 0:1383 0:094(1:743) 0:9570
approach-to-learning to Slope 1 0:182(0:098) 0:0633 0:014(0:029) 0:6293 0:054(0:043) 0:2092
approach-to-learning to Slope 2 0:021(0:048) 0:6617 0:052(0:037) 0:1599 0:072(0:036) 0:0455
Logistic Coef. OR (95% CI) OR ( 95% CI) OR ( 95% CI)
Family Income —40:993(0:909,1:084) 1:046(0:957,1:144)
Parents’ Highest Education — 1:015(0:800,1:287) 1:391(1:090,1:774)
Sex(0—Boy; 1—Girl) — 0:449(0:196,1:027) 0:412(0:195,0:872)
Race (0—White; 1—Others) — 0:610(0:291,1:281) 0:447(0:218,0:917)
1Intercept was deﬁned as mathematics IRT scores at 60-month old in this case.
2indicates statistical signiﬁcance at 0:05level.
3We built the model using standardized covariate with direct effects (i.e., attentional-focus and approach-to-learning).
4We set Class 1as the reference group.
30

--- PAGE 31 ---
APREPRINT - AUGUST 20, 2021
Figure 1: The Graphic Model Representation of the Full and Reduced Mixture-of-Experts Models
31

--- PAGE 32 ---
APREPRINT - AUGUST 20, 2021
●
●● ●Class with an Earlier Knot Class with a Late Knot
Full Mixture Model GP−Mixture Model CP−Mixture Model FMMFull Mixture Model GP−Mixture Model CP−Mixture Model FMM0.40.60.81.0
0.20.40.60.81.0
Model
Difference in Knot Locations: 11.5 2
Figure 2: Coverage Probabilities of Class-Speciﬁc Knot of Proposed Mixture Models
●●●
●●●●
●●●●●●●
●●●●●●●
●●●
0.50.60.70.80.9
Full Mixture Model GP−Mixture Model CP−Mixture Model FMM Misspecified
ModelMean of Accuracy
Difference in Knot Locations: 11.5 2
Figure 3: Mean Values of Accuracy of Four Correctly-speciﬁed Models and One Misspeciﬁed Model
32

--- PAGE 33 ---
APREPRINT - AUGUST 20, 2021
0.40.50.60.7
Full Mixture Model GP−Mixture Model CP−Mixture Model FMM Misspecified
ModelMean of Entropy
Difference in Knot Locations: 11.5 2
Figure 4: Mean Values of Entropy of Four Correctly-speciﬁed Models and One Misspeciﬁed Model
●●●
●
0.000.250.500.75
Full Mixture Model GP−Mixture Model CP−Mixture Model Misspecified
ModelMean Value of Kappa Statistic
Difference in Knot Locations: 11.5 2
Figure 5: Agreement between the Membership Obtained from Finite Mixture Model and Each Model with Covariates
33

--- PAGE 34 ---
APREPRINT - AUGUST 20, 2021
(a) One Class
 (b) Two Latent Classes
Figure 6: General Steps to Obtain Covariates with High Importance for Heterogeneity of Nonlinear Trajectories
34

--- PAGE 35 ---
APREPRINT - AUGUST 20, 2021
●●
●● 4.1414.03
−2.09 0.34
X1nX2nX1eX2e
0 200 400 600
Variable Importance of SEM ForestsVariable Name
Covariate Type ● ● Expert Covariates Noise Variables
(a) Scenario 1●●
●
● 82.89117.89
 21.19
 12.58X2nX1nX1eX2e
0 200 400 600
Variable Importance of SEM Forests
Covariate Type ● ● Expert Covariates Noise Variables
(b) Scenario 2
●●
●
● 72.25262.73
 10.94
  0.44X2nX1nX1eX2e
0 200 400 600
Variable Importance of SEM ForestsVariable Name
Covariate Type ● ● Expert Covariates Noise Variables
(c) Scenario 3●●●●
●
●−10.46 10.58 23.54 34.22
 −4.38
−19.94X2nX1gX1nX2gX1eX2e
0 200 400 600
Variable Importance of SEM Forests
Covariate Type ● ● ● Expert Covariates Gating Covariates Noise Variables
(d) Scenario 4
●●
●●
●●
31.6680.64
34.9676.42
13.2752.04
X1nX1gX1eX2nX2eX2g
0 200 400 600
Variable Importance of SEM ForestsVariable Name
Covariate Type ● ● ● Expert Covariates Gating Covariates Noise Variables
(e) Scenario 5●●
●●
●●
 −5.77 71.92
 69.79207.73
−47.16  4.19
X1nX1gX2nX1eX2gX2e
0 200 400 600
Variable Importance of SEM Forests
Covariate Type ● ● ● Expert Covariates Gating Covariates Noise Variables
(f) Scenario 6
●
●●●
●● 47.65
 38.55232.09458.93
 −9.36  3.45
X1nX2nX2gX1gX1eX2e
0 200 400 600
Variable Importance of SEM ForestsVariable Name
Covariate Type ● ● ● Expert Covariates Gating Covariates Noise Variables
(g) Scenario 7●●●●
●
● 28.59 33.77238.42551.95
−13.56
−26.70X2nX1nX1gX2gX1eX2e
0 200 400 600
Variable Importance of SEM Forests
Covariate Type ● ● ● Expert Covariates Gating Covariates Noise Variables
(h) Scenario 8
Figure 7: Variable Importance Generated by SEM Forests for All Scenarios
35

--- PAGE 36 ---
APREPRINT - AUGUST 20, 2021
●●
●●
●●
●●
●●●
●●
  4.35 22.91
 −4.54113.04
 −0.01 55.73
 −6.24  5.75
  3.23  4.81 43.41
  7.91110.52
Self−controlSchool LocationSchool TypeExternalizing Problem BehaviorsSexInternalizing Problem BehaviorsInterpersonal SkillsInhibitory ControlRaceAttentional FocusApproach to LearningParents' Highest EducationIncome
0 40 80 120
Variable Importance for Trajectory Heterogeneity in Mathematics AchievementVariable Name
Figure 8: Variable Importance Generated by SEM Forests for Nonlinear Trajectories of Mathematics Ability
36

--- PAGE 37 ---
APREPRINT - AUGUST 20, 2021
50100
75 100 125 150
Age (in Month)Math IRT Scores
Model Implied Math IRT Scores Smooth Line of Observed Math IRT Scores
Latent Class 1 (17.20%) Latent Class 2 (45.00%) Latent Class 3 (37.80%)
(a) Trajectories of Model 1
50100
75 100 125 150
Age (in Month)Math IRT Scores
Model Implied Math IRT Scores Smooth Line of Observed Math IRT Scores
Latent Class 1 (18.60%) Latent Class 2 (38.40%) Latent Class 3 (43.00%) (b) Trajectories of Model 2
50100
75 100 125 150
Age (in Month)Math IRT Scores
Model Implied Math IRT Scores Smooth Line of Observed Math IRT Scores
Latent Class 1 (17.80%) Latent Class 2 (41.00%) Latent Class 3 (41.20%)
(c) Trajectories of Model 3
50100
75 100 125 150
Age (in Month)Math IRT Scores
Model Implied Math IRT Scores Smooth Line of Observed Math IRT Scores
Latent Class 1 (14.20%) Latent Class 2 (48.40%) Latent Class 3 (37.40%) (d) Trajectories of Model 4
50100
75 100 125 150
Age (in Month)Math IRT Scores
Model Implied Math IRT Scores Smooth Line of Observed Math IRT Scores
Latent Class 1 (37.80%) Latent Class 2 (45.40%) Latent Class 3 (16.80%)
(e) Trajectories of Model 5
50100
75 100 125 150
Age (in Month)Math IRT Scores
Model Implied Math IRT Scores Smooth Line of Observed Math IRT Scores
Latent Class 1 (13.40%) Latent Class 2 (46.80%) Latent Class 3 (39.80%) (f) Trajectories of Model 6
Figure 9: Predicted Trajectories for Each of Three Latent Classes
37

--- PAGE 38 ---
APREPRINT - AUGUST 20, 2021
Figure A.1: The Two Forms of the Bilinear Spline (Linear-Linear Piecewise)
38

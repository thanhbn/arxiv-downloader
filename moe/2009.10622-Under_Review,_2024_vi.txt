# 2009.10622.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/moe/2009.10622.pdf
# Kích thước tệp: 673876 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Đang xem xét, 2024
Bất đẳng thức oracle không tiệm cận cho Lasso trong
hỗn hợp chuyên gia đa chiều cao
TrungTin Nguyen trungtin.nguyen@uq.edu.au
Khoa Toán và Vật lý, Đại học Queensland, St Lucia, QLD 4072, Úc;
Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, Inria Grenoble Rhone-Alpes, 655 av. de
l'Europe, 38335 Montbonnot, Pháp.
Hien D Nguyen h.nguyen5@latrobe.edu.au
Khoa Máy tính, Kỹ thuật và Khoa học Toán học, Đại học La Trobe, Bundoora, VIC
3086, Úc; Viện Toán học cho Công nghiệp, Đại học Kyushu, Khu Nishi, Fukuoka
819-0395, Nhật Bản.
Faicel Chamroukhi Faicel.chamroukhi@irt-systemx.fr
IRT SystemX, Palaiseau, Pháp.
Geoffrey J McLachlan g.mclachlan@uq.edu.au
Khoa Toán và Vật lý, Đại học Queensland, St Lucia, QLD 4072, Úc.
Tóm tắt
Chúng tôi nghiên cứu các tính chất ước lượng của mô hình hỗn hợp chuyên gia (MoE) trong
môi trường đa chiều cao, nơi số lượng biến dự đoán lớn hơn nhiều so với kích thước mẫu,
và văn hệ thiếu đặc biệt các kết quả lý thuyết. Chúng tôi xem xét lớp các mô hình SGMoE
(softmax-gated Gaussian MoE), được định nghĩa là các mô hình MoE với hàm cổng softmax
và các chuyên gia Gaussian, và tập trung vào các tính chất lý thuyết của việc ước lượng
l1-regularized thông qua Lasso. Theo hiểu biết tốt nhất của chúng tôi, chúng tôi là những
người đầu tiên nghiên cứu các tính chất l1-regularization của các mô hình SGMoE từ góc
độ không tiệm cận, dưới các giả định nhẹ nhàng nhất, cụ thể là tính bị chặn của không
gian tham số. Chúng tôi cung cấp một cận dưới cho tham số regularization của phạt Lasso
đảm bảo kiểm soát lý thuyết không tiệm cận của mất mát Kullback–Leibler của bộ ước
lượng Lasso cho các mô hình SGMoE. Cuối cùng, chúng tôi thực hiện một nghiên cứu mô
phỏng để xác thực thực nghiệm các phát hiện lý thuyết của chúng tôi.
Từ khóa: Hỗn hợp chuyên gia; hỗn hợp hồi quy; maximum likelihood có phạt;
bất đẳng thức l1-oracle; thống kê đa chiều cao; Lasso.
1. Giới thiệu
1.1. Hỗn hợp chuyên gia
Các mô hình MoE, được giới thiệu trong Jacobs et al. (1991), là một cấu trúc mô hình hỗn
hợp linh hoạt cho ước lượng mật độ có điều kiện và dự đoán. Do tính linh hoạt của chúng
và sự phong phú của các công cụ ước lượng thống kê và lựa chọn mô hình có sẵn, chúng đã
trở nên được sử dụng rộng rãi trong thống kê và học máy. Cấu trúc mô hình MoE cho phép
các trọng số hỗn hợp (hoặc hàm cổng) phụ thuộc vào các biến giải thích (hoặc biến dự đoán)
cùng với các chuyên gia (hoặc mật độ thành phần hỗn hợp). Điều này cho phép mô hình hóa
dữ liệu phát sinh từ các quá trình tạo dữ liệu phức tạp hơn so với những gì có thể được
phân tích bằng cách sử dụng các mô hình hỗn hợp
©2024 T. Nguyen, H.D. Nguyen, F. Chamroukhi & G.J. McLachlan.arXiv:2009.10622v7  [math.ST]  2 Jul 2024

--- TRANG 2 ---
Nguyen Nguyen Chamroukhi McLachlan
và các mô hình hỗn hợp hồi quy, có các tham số trộn độc lập với các biến đồng biến. Các
mô hình kiểu hỗn hợp hữu hạn cũng trở nên phổ biến do khả năng xấp xỉ phổ quát và tốc
độ hội tụ tốt cho ước lượng tham số và mật độ, đã được nghiên cứu rộng rãi trong Genovese
và Wasserman (2000); Nguyen (2013); Ho và Nguyen (2016); Nguyen et al. (2020, 2022a).
Theo cùng hướng, các kết quả gần đây cho ước lượng tham số và mật độ có điều kiện của
các mô hình MoE đã được công bố gần đây trong Jiang và Tanner (1999); Norets (2010);
Nguyen et al. (2016, 2019, 2021); Ho et al. (2022); Nguyen et al. (2023, 2024b,a).
Trong bối cảnh hồi quy, các mô hình softmax-gated Gaussian MoE, sẽ được gọi là SGMoE,
được định nghĩa là các mô hình MoE với các chuyên gia Gaussian và hàm cổng softmax,
là một lựa chọn tiêu chuẩn và một công cụ mạnh mẽ để mô hình hóa các mối quan hệ phi
tuyến phức tạp hơn giữa phản hồi và biến dự đoán, phát sinh từ các quần thể con khác nhau.
Vì mỗi trọng số hỗn hợp được mô hình hóa bởi một hàm softmax của các biến đồng biến,
sự phụ thuộc vào mỗi đặc trưng xuất hiện cả trong các chuyên gia và trong các hàm cổng,
điều này cho phép người ta nắm bắt các mối quan hệ phi tuyến phức tạp hơn giữa phản hồi
và biến dự đoán phát sinh từ các quần thể con khác nhau, so với các mô hình hỗn hợp hồi
quy. Điều này được chứng minh thông qua các thí nghiệm số trong một số công trình như
Chamroukhi và Huynh (2018, 2019); Montuelle và Le Pennec (2014). Độc giả được tham
khảo Yuksel et al. (2012); Nguyen và Chamroukhi (2018) để xem các đánh giá về chủ đề
này. Ước lượng thống kê và lựa chọn biến cho các mô hình MoE trong môi trường hồi quy
đa chiều cao vẫn là thách thức. Đặc biệt, từ quan điểm lý thuyết, thiếu các kết quả cho
các mô hình MoE, nơi số lượng biến giải thích có thể lớn hơn nhiều so với kích thước mẫu.
Trong những tình huống như vậy, chúng ta cần giảm chiều của bài toán bằng cách tìm kiếm
các mối quan hệ liên quan nhất để tránh các vấn đề số trong khi đảm bảo khả năng nhận diện.
1.2. Tài liệu liên quan
Chúng tôi tập trung vào việc sử dụng Lasso, ban đầu được giới thiệu bởi Tibshirani (1996),
còn được biết đến như là bộ ước lượng maximum likelihood có phạt l1 (l1-PMLE). Sử dụng
l1-PMLE có xu hướng tạo ra các nghiệm thưa thớt và có thể được xem như một surrogate
lồi cho bài toán l0-penalization không lồi. Các phương pháp thư giãn có các tính chất tính
toán và lý thuyết hấp dẫn (cf., Fan và Li, 2001). Đầu tiên được giới thiệu cho mô hình hồi
quy tuyến tính, bộ ước lượng Lasso kể từ đó đã được nghiên cứu và mở rộng cho nhiều vấn
đề thống kê. Để xử lý dữ liệu đa chiều cao không đồng nhất, một số nhà nghiên cứu đã
nghiên cứu Lasso cho lựa chọn biến trong bối cảnh các mô hình hỗn hợp hồi quy, xem, ví
dụ, Khalili và Chen (2007); Stadler et al. (2010); Meynet (2013); Devijver (2015); và
Lloyd-Jones et al. (2018). Đặc biệt, Stadler et al. (2010) đã cung cấp một bất đẳng thức
l0-oracle, được thỏa mãn bởi các bộ ước lượng Lasso, có điều kiện trên điều kiện eigenvalue
hạn chế, cụ thể là ma trận thông tin Fisher là định dương. Hơn nữa, họ phải giới thiệu
một số điều kiện margin để liên kết hàm mất mát Kullback–Leibler (KL) với l2-norm của
các tham số. Một hướng khác của việc nghiên cứu bài toán này là xem xét các tính chất
l1-regularisation của nó; xem ví dụ Massart và Meynet (2011); Meynet (2013); Devijver
(2015). Như được chỉ ra bởi Devijver (2015), trái ngược với các kết quả cho l0-penalty,
một số kết quả cho l1-penalty có hiệu lực mà không cần bất kỳ giả định nào, hoặc về ma
trận Gram hoặc về cận.

--- TRANG 3 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
1.3. Đóng góp chính
Các đóng góp tổng thể của chúng tôi trong bài báo có thể được tóm tắt như sau:
1.Theo hiểu biết tốt nhất của chúng tôi, chúng tôi là những người đầu tiên nghiên cứu các
tính chất l1-regularization của các mô hình SGMoE từ quan điểm không tiệm cận với
các giả định nhẹ nhàng nhất. Định lý 1 cung cấp một cận dưới cho tham số regularization
của phạt Lasso đảm bảo kiểm soát lý thuyết không tiệm cận của mất mát KL của bộ
ước lượng l1-PMLE cho các mô hình SGMoE. Bởi vì kết quả này là không tiệm cận, nó
có hiệu lực khi n cố định, trong khi số lượng biến dự đoán p có thể tăng trưởng, đối
với n, và có thể lớn hơn nhiều so với n.
2.Kết quả không tiệm cận của chúng tôi bổ sung cho các kết quả tiệm cận tiêu chuẩn cho
các mô hình SGMoE đa chiều cao để lựa chọn đặc trưng sử dụng Lasso-PMLE hoặc
PMLE tổng quát hơn thông qua hàm phạt Scad của Khalili (2010). Cụ thể, Khalili
(2010) đã chứng minh cả tính nhất quán trong lựa chọn đặc trưng và tính nhất quán
√n của PMLE trong các mô hình SGMoE, nhưng dưới một số điều kiện nghiêm ngặt
về tính chính quy của hàm mật độ chung thực và về việc lựa chọn các tham số điều
chỉnh. Ngược lại, giả định nhẹ nhàng duy nhất chúng tôi sử dụng ở đây để thu được
bậc tốc độ hội tụ của các cận trên lỗi trong (10) từ Định lý 1 là tính bị chặn trên không
gian tham số, điều này cũng xuất hiện trong Khalili (2010); Stadler et al. (2010);
Meynet (2013); Devijver (2015).
3.Chúng tôi mở rộng các kết quả không tiệm cận cho các mô hình hỗn hợp hồi quy (Massart
và Meynet, 2011; Meynet, 2013; Devijver, 2015) cho các mô hình SGMoE tổng quát
hơn như được định nghĩa trong (1), trong đó việc phân tích lý thuyết của kết quả
không tiệm cận là thách thức, bởi vì, trong các mô hình SGMoE, sự phụ thuộc vào
mỗi đặc trưng xuất hiện cả trong các trung bình của các chuyên gia và trong các hàm
cổng. Điều này đòi hỏi đặc biệt chứng minh kỹ thuật không tầm thường mà chúng
tôi thiết lập trong bài báo này.
4.Trọng tâm của chúng tôi trong bài báo này là về một môi trường đơn giản hóa nhưng
tiêu chuẩn trong đó các trung bình thành phần chuyên gia là các hàm tuyến tính đối
với các biến giải thích. Mặc dù có sự đơn giản hóa tuyến tính này, mô hình SGMoE
tổng thể vẫn nắm bắt được tính phi tuyến của hàm hồi quy thực nhờ vào cấu trúc hỗn
hợp của nó. Chúng tôi tin rằng các kỹ thuật tổng quát mà chúng tôi phát triển ở đây
có thể được mở rộng cho các chuyên gia tổng quát hơn, như các chuyên gia Gaussian
với trung bình đa thức (xem, ví dụ, Mendes và Jiang, 2012), MoE phân cấp cho các
mô hình hồi quy họ mũ (Jiang và Tanner, 1999), và khi ma trận hiệp phương sai cũng
được tham số hóa như một hàm chuyên gia có thể phụ thuộc vào các biến đồng biến
như trong Ho et al. (2022).
Ký hiệu. Trong suốt bài báo này, {1, . . . , n} được viết tắt là [n] cho n ∈ N⋆ = {1, 2, . . .}.
Ở đây, vec(·) là toán tử vector hóa xếp các cột của một ma trận thành một vector. Chúng
tôi ký hiệu p-norm cảm ứng của một ma trận β bởi ∥β∥p, p ∈ {1, 2, ∞}, khác với vector
norm ∥vec(β)∥p. Với một ma trận Σ, m(Σ) và M(Σ) ký hiệu các eigenvalue nhỏ nhất và
lớn nhất của Σ, tương ứng. Chúng tôi viết N(·; v, Σ) cho mật độ Gaussian đa biến với
trung bình v và ma trận hiệp phương sai Σ. Cho một sự kiện tùy ý T trong một không gian
xác suất nào đó, chúng tôi định nghĩa một hàm chỉ thị bởi: IT (ω) = 1 nếu ω ∈ T và IT (ω)
= 0 nếu ω ∉ T.
Tổ chức bài báo. Trong Phần 2, chúng tôi thảo luận về cấu trúc và khung của các mô hình
SGMoE đa chiều cao. Trong Phần 3, chúng tôi trình bày kết quả chính của chúng tôi. Sau
đó, chúng tôi thực hiện

--- TRANG 4 ---
Nguyen Nguyen Chamroukhi McLachlan
một nghiên cứu mô phỏng để xác minh thực nghiệm các kết quả lý thuyết của chúng tôi trong 4. Một số kết luận được
đưa ra trong Phần 5. Tài liệu bổ sung được dành để chứng minh các kết quả kỹ thuật.
2. Thiết lập bài toán
2.1. Các mô hình SGMoE đa chiều cao
Trong môi trường hồi quy đa chiều cao, chúng ta quan sát n cặp
x[n], y[n]
≡ (xi, yi)i∈[n] ∈
(X × Y)n ⊂ (Rp × Rq)n, nơi thông thường p ≫ n, xi là cố định và yi là một hiện thực hóa của
biến ngẫu nhiên Yi, i ∈ [n]. Chúng ta giả định rằng, có điều kiện trên x[n], Y[n] là độc lập
và phân phối đồng nhất (IID) với PDF có điều kiện s0(·|xi). Mục tiêu của chúng ta là ước
lượng s0 từ các quan sát sử dụng các mô hình SGMoE K-thành phần sau:
sψ(y|x) = ∑K
k=1 exp(γk0 + γk⊤x) / ∑K
l=1 exp(γl0 + γl⊤x) N(y; βk0 + βkx, Σk), (1)
với K ∈ N⋆ và các tham số chưa biết ψ = (γ, β, Σ) ≡ (γk0, γk, βk0, βk, Σk)k∈[K] trong một
không gian tham số Ψ. Vì lý do kỹ thuật, chúng tôi yêu cầu rằng các biến đồng biến là cố
định và các giả định về tính bị chặn trên không gian tham số Ψ.
Các biến giải thích x[n] và số lượng thành phần K đều cố định. Chúng ta giả định rằng
X là một tập con compact của Rp và các quan sát x[n] là hữu hạn. Không mất tính tổng
quát, chúng ta chọn để re-scale x, sao cho ∥x∥∞ ≤ 1. Do đó, chúng ta có thể giả định rằng
X = [0,1]p. Tuy nhiên, các luận chứng trong các chứng minh của chúng tôi có hiệu lực cho
các biến đồng biến ở bất kỳ thang đo nào. Chúng ta giả định rằng tồn tại các hằng số dương
Aγ, Aβ, aΣ, AΣ, sao cho ψ ∈ Ψ̃, nơi
Ψ̃ = {ψ ∈ Ψ | max_{k∈[K]} sup_{x∈X} |γk0 + γk⊤x| ≤ Aγ, max_{z∈[q]} max_{k∈[K]} sup_{x∈X}(|[βk0]z| + |[βkx]z|) ≤ Aβ,
aΣ ≤ m(Σk^{-1}) ≤ M(Σk^{-1}) ≤ AΣ}. (2)
Tập hợp các mô hình SGMoE. Tóm lại, cho (1) và (2), chúng ta muốn ước lượng s0
thông qua tập hợp các mô hình SGMoE sau:
S = {(x, y) ↦ sψ(y|x) | ψ ∈ Ψ̃}. (3)
Đặc biệt, để đơn giản hóa các chứng minh, chúng ta sẽ giả định rằng PDF có điều kiện thực
s0 thuộc S. Nghĩa là, tồn tại ψ0 = (γ0, β0, Σ0) ∈ Ψ̃, sao cho s0 = sψ0. Từ đây trở đi,
nơi không có nhầm lẫn, chúng ta sẽ sử dụng s0 và sψ0, một cách thay thế.
2.2. Ước lượng tương phản tối thiểu
Một số hàm mất mát đã được đưa vào MLE cho các mô hình MoE. Ví dụ, bằng cách sử
dụng các điều kiện khả năng nhận diện, Nguyen et al. (2023, 2024b,a) đã thiết lập các cận
nghịch đảo giữa khoảng cách Hellinger và một số khoảng cách Wasserstein hoặc các hàm
mất mát Voronoi để nắm bắt chính xác các tốc độ hội tụ ước lượng tham số không đồng
nhất cho các lớp mô hình MoE khác nhau. Tuy nhiên, trong bài báo này, ý tưởng chính
của chúng tôi là xem xét Lasso như một thủ tục lựa chọn mô hình l1-ball, xem ví dụ Massart
và Meynet (2011). Do đó, chúng tôi

--- TRANG 5 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
tuân theo khung của ước lượng tương phản tối thiểu, xem ví dụ Massart (2007, Chương 1),
Arlot và Celisse (2010), và Barron et al. (1999). Trong tình huống này, negative log-likelihood
(NLL) và phân kỳ KL là những lựa chọn tự nhiên cho bài toán ước lượng mật độ.
Phân kỳ KL trung bình. Để tính đến cấu trúc của các PDF có điều kiện, cho các biến
giải thích cố định (xi)1≤i≤n, chúng ta xem xét hàm mất mát KL trung bình sau:
KLn(s, t) = 1/n ∑_{i=1}^n KL(s(·|xi), t(·|xi)), cho bất kỳ mật độ s và t, nơi (4)
KL(s, t) = {∫_{R^q} ln(s(y)/t(y)) s(y)dy, nếu s dy tuyệt đối liên tục w.r.t t dy,
+∞, ngược lại. (5)
Bộ ước lượng Lasso. Có điều kiện trên (xi)1≤i≤n, phương pháp MLE đề xuất ước lượng s0
bởi PDF có điều kiện sψ mà minimizes NLL: -1/n ∑_{i=1}^n ln(sψ(yi|xi)). Tuy nhiên, trong
dữ liệu đa chiều cao, chúng ta cần regularize MLE để thu được các ước lượng hợp lý.
Ở đây, đầu tiên chúng ta xem xét l1-PMLE (bộ ước lượng Lasso):
ŝ^{Lasso}_λ = arg min_{sψ∈S} {-1/n ∑_{i=1}^n ln(sψ(yi|xi)) + λ(∥γ∥1 + ∥vec(β)∥1)}, (6)
nơi λ ≥ 0 là một tham số regularization cần được điều chỉnh, ∥γ∥1 = ∑_{k=1}^K ∑_{j=1}^p |γkj|, và
∥vec(β)∥1 = ∑_{k=1}^K ∑_{j=1}^p ∑_{z=1}^q [βk]z,j. Đáng chú ý rằng hai entry-wise l1
norms này không chứa scalar γk0 và vector βk0 bias. Các điều khoản regularisation Lasso
này khuyến khích sparsity cho cả tham số gating và expert.
3. Kết quả chính
Để đơn giản hóa việc trình bày Định lý 1, cho một số hằng số κ ≥ 148, trước tiên chúng ta
định nghĩa điều kiện sau cho λ và hằng số C1n xuất hiện trên các cận rủi ro trên:
λ ≥ κK√nC0n, C0n = B0n√(ln n p/ln(2p + 1) + 1), (7)
B0n = max(AΣ, 1 + KAG)[1 + 2q√qAΣ/(5A²β + 4AΣ ln n)],
C1n = √(2qAγ)[e^{q/2-1}π^{q/2}/A^{q/2}_Σ + Hs0] + B0nC2n, (8)
Hs0 = max{0, ln[(4π)^{-q/2}A^{q/2}_Σ]}, C2n = 302√qK[1 + (Aγ + qAβ + q√q)/a²Σ]. (9)
Nhận xét. Trong (7), chúng tôi đã cẩn thận làm rõ các phụ thuộc, không chỉ vào hằng số
điều chỉnh κ, mà còn vào n, p, q, và K cũng như vào Aβ, AΣ, AG—tất cả các đại lượng
hạn chế các tham số của mô hình. Xem Phần 3.1 để có mô tả chi tiết hơn. Lưu ý rằng cả
C0n và C1n đều phụ thuộc vào kích thước mẫu n chỉ thông qua điều khoản ln n. Hơn nữa,
Hs0 liên quan đến âm của entropy vi phân của mật độ có điều kiện thực chưa biết s0 ∈ S;
xem tài liệu bổ sung để biết thêm chi tiết. Chúng tôi trình bày đóng góp chính của chúng
tôi: một bất đẳng thức l1-oracle cho bộ ước lượng Lasso cho các mô hình SGMoE thông
qua Định lý 1.

--- TRANG 6 ---
Nguyen Nguyen Chamroukhi McLachlan
Định lý 1 (bất đẳng thức l1-oracle) Giả sử rằng chúng ta quan sát
{x[n], y[n]} ∈ ([0,1]^p × R^q)^n,
đến từ một PDF có điều kiện chưa biết s0 ≡ sψ0 ∈ S, được định nghĩa trong (3). Cho C1n trong (8),
nếu λ thỏa mãn (7), bộ ước lượng Lasso ŝ^{Lasso}_λ, được định nghĩa trong (6), thỏa mãn bất đẳng thức l1-oracle:
E[KLn(s0, ŝ^{Lasso}_λ)] ≤ (κ+1)/κ inf_{sψ∈S}[KLn(s0, sψ) + λ(∥γ∥1 + ∥vec(β)∥1)]
+ λ + √(K/n)C1n. (10)

3.1. Thảo luận và quan điểm về bất đẳng thức oracle của chúng tôi
Mô hình oracle và tốc độ hội tụ cho bộ ước lượng Lasso. Định lý 1
đặc trưng hiệu suất của các bộ ước lượng Lasso như l1-PMLE cho các mô hình SGMoE. Nếu
tham số regularization λ được chọn đúng cách, nghiệm của bài toán minimization rủi ro
thực nghiệm l1-penalized, hoạt động theo cách có thể so sánh với Lasso xác định (được
gọi là oracle). Oracle này là nghiệm của bài toán minimization rủi ro thực l1-penalized,
lên đến một điều khoản lỗi bậc λ. Lưu ý rằng mô hình tốt nhất, ký hiệu bởi sψ*, được
định nghĩa là mô hình có rủi ro l1-penalized nhỏ nhất:
inf_{sψ∈S}[KLn(s0, sψ) + λ(∥γ∥1 + ∥vec(β)∥1)]. (11)
Tuy nhiên, vì chúng ta không biết mật độ thực s0, chúng ta không thể chọn mô hình tốt
nhất này, mà chúng ta gọi là mô hình oracle. Đặc biệt, theo định nghĩa, oracle là mô hình
trong tập hợp minimizes rủi ro l1-penalized trong (11), thường được giả định là chưa biết.
Từ bất đẳng thức oracle của Định lý 1, chúng tôi phỏng đoán rằng bằng cách xây dựng một
lý thuyết xấp xỉ phù hợp trên một không gian tốt, chúng ta có thể kiểm soát rủi ro thực
l1-penalized này để thu được tốc độ hội tụ tham số n^{-1/2} cho bộ ước lượng Lasso. Một
công trình liên quan theo hướng này là Massart và Meynet (2012), những người đã thiết
lập tốc độ hội tụ cho bộ ước lượng Lasso được chọn của Massart và Meynet (2011), cho
một phạm vi rộng các lớp hàm được mô tả bởi các không gian nội suy của Barron et al.
(2008). Hơn nữa, theo hiểu biết tốt nhất của chúng tôi, Định lý 2.8 của Maugis-Rabusseau
và Michel (2013) là kết quả duy nhất trong văn hệ nghiên cứu bộ ước lượng minimax cho
các mô hình Gaussian mixture nhưng cho lựa chọn mô hình thay vì Lasso. Chúng tôi sẽ để
lại nhiệm vụ không tầm thường của việc thu được các mở rộng Lasso của kết quả này cho
công việc tương lai.
Bộ ước lượng Lasso có thể thực hiện và tham số regularization λ dựa trên dữ liệu. Lưu ý
rằng Định lý 1 đảm bảo rằng tồn tại một λ đủ lớn mà ước lượng có tính chất tốt, nhưng
không đưa ra một giá trị rõ ràng cho λ. Tuy nhiên, chúng tôi ít nhất đưa ra cận dưới cho
giá trị của λ thông qua cận λ ≥ κC(p, q, n, K), nơi κ ≥ 148, mặc dù giá trị này rõ ràng
là conservative. Hơn nữa, quan trọng là lưu ý rằng bộ ước lượng Lasso xuất hiện trong
Định lý 1 đã được thực hiện trong thực tế. Thật vậy, khi các l2-penalties được cho trọng
số bằng không trong Khalili (2010) và Chamroukhi và Huynh (2018, 2019), các hàm phạt
của họ và một kết quả gần đây từ Huynh và Chamroukhi (2019) cho các mô hình expert
tuyến tính tổng quát thuộc về khung của chúng tôi và bất đẳng thức l1-oracle từ Định lý
1 cung cấp thêm thông tin lý thuyết cho các bộ ước lượng Lasso này. Đặc biệt, các nghiệm
có thể cho việc hiệu chỉnh tham số điều chỉnh λ của penalty từ dữ liệu là BIC (Schwarz,
1978) được sử dụng trong Chamroukhi và Huynh (2018, 2019) và generalized cross-validation
(Stone, 1974) được sử dụng trong Khalili (2010); Khalili và Chen (2007). Cho văn hệ có
sẵn, các chiến lược tính toán như vậy và mô phỏng số cho các bộ dữ liệu thực sẽ không
được xem xét và thảo luận thêm ở đây.
Phụ thuộc vào p, q, n, và K trong cận dưới của λ. Lưu ý rằng chúng ta khôi phục cùng
phụ thuộc dạng √ln(2p + 1) như đối với hồi quy tuyến tính đồng nhất trong Stadler
et al. (2010) và dạng √ln(2p + 1)(ln n)^2/√n cho các mô hình hỗn hợp hồi quy
trong Meynet (2013). Ngược lại, phụ thuộc vào q cho các mô hình hồi quy Gaussian đa
biến hỗn hợp trong Devijver (2015) có dạng q^2 + q, trong khi ở đây chúng ta nhận được
dạng q^2√q. Lý do chính là lớp S của mô hình SGMoE lớn hơn, và chúng ta sử dụng một
kỹ thuật khác để đánh giá cận trên của uniform norm của gradient cho mỗi phần tử trong
S. Trong cận dưới của λ trong (7), chúng ta có thể có được phụ thuộc hệ số K^2 thay vì
K như trong Meynet (2013) và Devijver (2015). Điều này có thể được giải thích bởi thực
tế rằng chúng ta đã sử dụng một kỹ thuật khác để xử lý mô hình phức tạp hơn khi xử lý
cận trên của uniform norm của gradient của ln sψ, cho sψ ∈ S. Chúng tôi tham khảo
Meynet (2013, Nhận xét 5.8) cho một số bộ dữ liệu nơi phụ thuộc vào K có thể được giảm
xuống bậc √K cho các mô hình hồi quy Gaussian mixture. Việc xác định tốc độ tối ưu
cho các bài toán như vậy vẫn mở. Hơn nữa, phụ thuộc vào n cho hồi quy tuyến tính đồng
nhất trong Stadler et al. (2010) có bậc n^{-1/2}, trong khi ở đây chúng ta có một hệ số
(ln n)^2 bổ sung. Thực tế, tình huống tương tự có thể được tìm thấy trong các bất đẳng
thức l1-oracle của Meynet (2013) và Devijver (2015). Như được giải thích trong Meynet
(2013), việc sử dụng thông tin KL phi tuyến dẫn đến một kịch bản nơi các luận chứng tuyến
tính được phát triển trong Stadler et al. (2010) với hàm mất mát bậc hai không thể được
khai thác. Thay vào đó, chúng ta cần sử dụng các luận chứng entropy cho mô hình của
chúng ta, dẫn đến một hệ số (ln n)^2 bổ sung.
Hằng số cận trên nhân. Đáng chú ý rằng hằng số 1 + κ^{-1} xuất hiện trong các cận trên
của Định lý 1 không thể được giảm xuống 1, thực tế là tình huống tương tự như hằng số
từ C1 từ Montuelle và Le Pennec (2014, Định lý 1). Lưu ý rằng vấn đề này cũng xảy ra
trong các bất đẳng thức l1-oracle của Meynet (2013), và Devijver (2015). Việc suy ra một
bất đẳng thức oracle sao cho 1 + κ^{-1} có thể được thay thế bởi 1 cho mất mát KL vẫn
là một vấn đề mở.
Mô hình sai lệch specification. Trong Định lý 1, khi s0 ∉ S, bằng cách để n → ∞, do
bias lớn từ điều khoản cận trên đầu tiên, tổng cận trên lỗi của (10) hội tụ đến

(1 + 1/κ) inf_{sψ∈S}[lim_{n→∞} KLn(s0, sψ) + λ(∥γ∥1 + ∥vec(β)∥1)] + λ,

có thể lớn. Kết luận tương tự áp dụng cho Định lý 2 khi s0 ∉ ∪_{m∈N*} Sm.
Tuy nhiên, vì chúng ta xem xét các mô hình SGMoE, một số kết quả xấp xỉ phổ quát gần
đây, xem, ví dụ, Nguyen et al. (2016, 2019, 2020, 2021, 2022a), ngụ ý rằng nếu chúng ta
lấy một số lượng thành phần hỗn hợp K đủ lớn, nghĩa là lớp S đủ lớn, chúng ta có thể xấp
xỉ một lớp rộng các PDF có điều kiện, và do đó điều khoản ở phía bên phải nhỏ với K đủ
lớn. Điều này cải thiện cận lỗi ngay cả khi s0 ∉ S.
3.2. So sánh với state-of-the-art
Kết quả tiệm cận tiêu chuẩn với lựa chọn biến. Định lý 1 bổ sung cho các kết quả tiệm
cận tiêu chuẩn cho các mô hình SGMoE đa chiều cao thông qua lựa chọn đặc trưng sử dụng
Lasso, cũng như PMLE tổng quát hơn thông qua hàm phạt Scad của Khalili (2010).

--- TRANG 8 ---
Nguyen Nguyen Chamroukhi McLachlan
Bằng cách mở rộng các phát triển lý thuyết cho các mô hình hỗn hợp hồi quy trong Khalili
và Chen (2007), các định lý tiệm cận tiêu chuẩn cho SGMoE được thiết lập trong Khalili
(2010). Sau đó, dưới một số điều kiện chính quy nghiêm ngặt về hàm mật độ chung thực
và việc lựa chọn tham số điều chỉnh, PMLE từ Khalili (2010), sử dụng hàm phạt Scad từ
Fan và Li (2001) thay vì Lasso, được chứng minh là cả nhất quán trong lựa chọn đặc trưng
và duy trì tính nhất quán √n. Ngược lại, giả định duy nhất được sử dụng để thu được tốc
độ hội tụ n^{-1/2} của cận trên lỗi trong (10) từ Định lý 1 là tính bị chặn trên không gian
tham số. Thực tế, điều kiện tính bị chặn này cũng được yêu cầu bởi Khalili (2010). Hơn
nữa, chúng tôi làm việc trực tiếp trên các PDF có điều kiện với các biến đồng biến cố định
thay vì tập trung vào các PDF chung như trong Khalili (2010); Khalili và Chen (2007).
Trong công việc tương lai, chúng tôi sẽ điều tra xem liệu kỹ thuật chứng minh được sử dụng
trong bài báo này có thể được điều chỉnh cho bài toán ước lượng các PDF chung khi các
biến dự đoán là các biến ngẫu nhiên hay không.
Giả định tính bị chặn trên không gian tham số. Đáng chú ý rằng các giả định tính bị
chặn của chúng tôi cũng xuất hiện trong Stadler et al. (2010); Meynet (2013); Devijver
(2015). Chúng khá tự nhiên khi làm việc với MLE (Maugis và Michel, 2011), ít nhất khi
xem xét vấn đề unboundedness của likelihood tại các ranh giới của không gian tham số
(Redner và Walker, 1984; McLachlan và Peel, 2000), và để ngăn likelihood phân kỳ.
3.3. Chứng minh Định lý 1
Phác thảo chứng minh Định lý 1. Ở mức độ cao, ý tưởng chính ở đây là nghiên cứu bộ
ước lượng Lasso, Định lý 1, như một nghiệm của l1-ball PMLE, Định lý 2, được định nghĩa
sau trong phần này. Chứng minh của Định lý 2 có thể được suy ra từ Mệnh đề 3 và 4, xử
lý các trường hợp cho các giá trị nhỏ và lớn của Y và được chứng minh trong tài liệu bổ sung.
l1-ball PMLE. Chúng ta cần định nghĩa l1-ball PMLE cho việc trình bày Định lý 2. Để
làm điều này, bằng cách hạn chế S, đến một l1-ball phù hợp của các tham số γ, β trên
định nghĩa của S, chúng ta định nghĩa một tập hợp các mô hình l1-ball Sm, nơi m ∈ N⋆
là bán kính của l1-ball, như sau:
Sm = {sψ ∈ S | ∥γ∥1 + ∥vec(β)∥1 ≤ m}. (12)
Sau đó cho một số ηm ≥ 0, let ŝm là một ηm-log-likelihood estimator (LLE) trong Sm, được định nghĩa là:
-1/n ∑_{i=1}^n ln(ŝm(yi|xi)) ≤ inf_{sm∈Sm}(-1/n ∑_{i=1}^n ln(sm(yi|xi))) + ηm. (13)
Như luôn luôn, không đủ để sử dụng LLE của ước lượng trong mỗi mô hình như một tiêu
chí. Nó đánh giá thấp rủi ro của ước lượng và kết quả là một lựa chọn mô hình quá phức
tạp. Trong bối cảnh PMLE, bằng cách thêm một penalty pen(m) thích hợp, người ta hy
vọng tạo ra một trade-off giữa fit dữ liệu tốt và độ phức tạp mô hình. Giả sử rằng cho tất
cả m ∈ N⋆, hàm penalty thỏa mãn pen(m) = λm, nơi λ sẽ được xác định như trong (7).
Sau đó, cho một số η ≥ 0, một l1-ball PMLE được định nghĩa là ŝ_{m̂}, nơi m̂ thỏa mãn
-1/n ∑_{i=1}^n ln(ŝ_{m̂}(yi|xi)) + pen(m̂) ≤ inf_{m∈N⋆}(-1/n ∑_{i=1}^n ln(ŝm(yi|xi)) + pen(m)) + η. (14)

--- TRANG 9 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
Lưu ý rằng các điều khoản lỗi ηm và η là cần thiết để tránh bất kỳ vấn đề tồn tại nào,
ví dụ, infimum có thể không được đạt. Nói một cách đại khái, nguyên lý biến phân Ekeland
phát biểu rằng cho bất kỳ hàm bán liên tục dưới có giá trị mở rộng nào, bị chặn dưới,
người ta có thể thêm một nhiễu nhỏ để đảm bảo sự tồn tại của minimum, xem ví dụ Borwein
và Zhu (2004). Khung này cũng được sử dụng trong Montuelle và Le Pennec (2014), và
Nguyen et al. (2022b). Tiếp theo, chúng tôi trình bày lựa chọn mô hình l1-ball thông qua
Định lý 2.
Định lý 2 (lựa chọn mô hình l1-ball) Giả sử rằng
{x[n], y[n]} ∈ ([0,1]^p × R^q)^n, đến
từ một PDF có điều kiện chưa biết s0 ≡ sψ0 ∈ S, được định nghĩa trong (3). Cho C1n trong (8),
nếu λ thỏa mãn (7), l1-ball PMLE ŝ_{m̂}, được định nghĩa trong (14), thỏa mãn bất đẳng thức oracle:
E[KLn(s0, ŝ_{m̂})] ≤ (1 + 1/κ) inf_{m∈N⋆} inf_{sm∈Sm}[KLn(s0, sm) + pen(m) + ηm]
+ η + √(K/n)C1n. (15)
Chứng minh Định lý 1. Let λ > 0 và định nghĩa m̂ là số nguyên nhỏ nhất sao cho ŝ^{Lasso}_λ
thuộc S_{m̂}, tức là, m̂ := ⌊∥ψ∥_{[1,2]}⌋_1 ≤ ∥ψ∥_{[1,2]}}_1 + 1. Sau đó sử dụng định nghĩa của m̂, (6),
(12), và S = ∪_{m∈N⋆} Sm, chúng ta có
-1/n ∑_{i=1}^n ln(ŝ^{Lasso}_λ(yi|xi)) + λm̂ ≤ -1/n ∑_{i=1}^n ln(ŝ^{Lasso}_λ(yi|xi)) + λ(∥ψ∥_{[1,2]}}_1 + 1)
= inf_{sψ∈S}(-1/n ∑_{i=1}^n ln(sψ(yi|xi)) + λ∥ψ∥_{[1,2]}}_1) + λ
= inf_{m∈N⋆}(inf_{sψ∈Sm}(-1/n ∑_{i=1}^n ln(sψ(yi|xi)) + λ∥ψ∥_{[1,2]}}_1)) + λ
≤ inf_{m∈N⋆}(inf_{sm∈Sm}(-1/n ∑_{i=1}^n ln(sm(yi|xi)) + λm)) + λ,
điều này ngụ ý
-1/n ∑_{i=1}^n ln(ŝ^{Lasso}_λ(yi|xi)) + pen(m̂) ≤ inf_{m∈N⋆}(-1/n ∑_{i=1}^n ln(ŝm(yi|xi)) + pen(m)) + η
với pen(m) = λm, η = λ, và ŝm là một ηm-log-likelihood minimizer trong Sm, với ηm ≥ 0
được định nghĩa bởi (13). Do đó, ŝ^{Lasso}_λ thỏa mãn (14) với ŝ^{Lasso}_λ ≡ ŝ_{m̂}, tức là,
-1/n ∑_{i=1}^n ln(ŝ_{m̂}(yi|xi)) + pen(m̂) ≤ inf_{m∈N⋆}(-1/n ∑_{i=1}^n ln(ŝm(yi|xi)) + pen(m)) + η.
Sau đó, Định lý 2 ngụ ý rằng nếu
λ ≥ κKB'0n/√n √(q ln n p/ln(2p + 1) + 1),
B'0n = max(AΣ, 1 + KAG)[1 + 2q√qAΣ/(5A²β + 4AΣ ln n)],

--- TRANG 10 ---
Nguyen Nguyen Chamroukhi McLachlan
cho một số hằng số tuyệt đối κ ≥ 148, Định lý 1 giữ như yêu cầu.
Chứng minh Định lý 2. Cho bất kỳ Mn > 0, điều này có thể được thực hiện bằng cách giới thiệu một sự kiện T và
một không gian Fm như sau:
T = {max_{i∈[n]} ∥Yi∥∞ = max_{i∈[n]} max_{z∈[q]} |[Yi]z| ≤ Mn},
T^c = {max_{i∈[n]} ∥Yi∥∞ = max_{i∈[n]} max_{z∈[q]} |[Yi]z| > Mn},
Fm = {fm = -ln(sm/s0) = ln(s0) - ln(sm), sm ∈ Sm}.
Có điều kiện trên {xi}_{i∈[n]}, let Y'[n]|x[n] ≡ (Y'i|xi)_{i∈[n]} là các mẫu ngẫu nhiên IID từ Y phát sinh
từ PDF có điều kiện s0(·|xi), i ∈ [n]. Chúng là các bản sao độc lập của mẫu
Y[n]|x[n]. Bằng cách tính đến định nghĩa của hàm mất mát KL trung bình từ (4), tính chất
kỳ vọng có điều kiện, chúng ta thu được
KLn(s0, ŝ_{m̂}) = E_{Y'[n]|x[n]}[1/n ∑_{i=1}^n f̂_{m̂}(Yi|xi)|T] IT + E_{Y'[n]|x[n]}[1/n ∑_{i=1}^n f̂_{m̂}(Yi|xi)|T^c] IT^c
≡ (KLn(s0, ŝ_{m̂})|T)IT + (KLn(s0, ŝ_{m̂})|T^c)IT^c. (16)
Từ bây giờ, khi không có nhầm lẫn, kỳ vọng của (16) được viết như sau:
E[KLn(s0, ŝ_{m̂})] = E_{Y[n]}[(KLn(s0, ŝ_{m̂})|T)IT] + E_{Y[n]}[(KLn(s0, ŝ_{m̂})|T^c)IT^c]
≡ E[KLn(s0, ŝ_{m̂})IT] + E[KLn(s0, ŝ_{m̂})IT^c]. (17)
Do đó, trên cơ sở nhận xét trên (17), Định lý 2 được chứng minh bằng cách thu được
cận trên cho mỗi điều khoản sau sử dụng Mệnh đề 3 và 4:
E[KLn(s0, ŝ_{m̂})] = E[KLn(s0, ŝ_{m̂})IT] + E[KLn(s0, ŝ_{m̂})IT^c].
Cho một số hằng số κ ≥ 148, chúng ta cần định nghĩa điều kiện sau cho λ, cho
một số hằng số Mn > 0:
λ ≥ κK√nC3n, C3n = Bn√(q ln n p/ln(2p + 1) + 1), (18)
Bn = max(AΣ, 1 + KAG)[1 + q√q(Mn + Aβ)²AΣ]. (19)
Mệnh đề 3 (Giá trị nhỏ của Y) Giả sử rằng
{x[n], y[n]} ∈ ([0,1]^p × R^q)^n đến từ
một PDF có điều kiện chưa biết s0 ≡ sψ0 ∈ S được định nghĩa trong (3). Cho C2n và Bn được định nghĩa như trong
(9) và (19), tương ứng, nếu λ thỏa mãn (18), l1-ball PMLE ŝ_{m̂}, được định nghĩa trong (14), thỏa mãn:
E[KLn(s0, ŝ_{m̂})IT] ≤ (1 + κ^{-1}) inf_{m∈N⋆} inf_{sm∈Sm}[KLn(s0, sm) + pen(m) + ηm]
+ η + √(K/n)BnC2n.
Mệnh đề 4 (Giá trị lớn của Y) Xem xét s0, T, và ŝ_{m̂} như được định nghĩa trong Mệnh đề 3
và Hs0 như được định nghĩa trong (9). Sau đó,
E[KLn(s0, ŝ_{m̂})IT^c] ≤ [e^{q/2-1}π^{q/2}/A^{q/2}_Σ + Hs0] √(2Knq)Aγe^{-(M²n-2MnAβ)/(4AΣ)}.

--- TRANG 11 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
Mệnh đề 3 tạo thành đóng góp kỹ thuật quan trọng của chúng tôi. Thông qua Lemma 5, ý tưởng chính
để chứng minh Mệnh đề 3 là kiểm soát độ lệch sau trên sự kiện T:
sup_{fm∈Fm} |νn(-fm)| ≡ sup_{fm∈Fm} 1/n ∑_{i=1}^n {fm(Yi|xi) - E[fm(Yi|xi)]}, (20)
Fm = {fm = -ln(sm/s0) = ln(s0) - ln(sm), sm ∈ Sm}. (21)
Lemma 5 (Kiểm soát độ lệch) Cho mỗi m' ∈ N⋆, let
Δm' = m'√(ln(2p + 1) ln n) + 2√K (Aγ + qAβ + q√q)/aΣ. (22)
Sau đó, trên sự kiện T, cho tất cả m' ∈ N⋆, và cho tất cả t > 0, với xác suất lớn hơn 1 - e^{-t},
sup_{fm'∈Fm'} |νn(-fm')| ≤ 4KBn/√n [37q Δm' + √2 (Aγ + qAβ + q√q)/aΣ √t]. (23)
Chứng minh của Lemma 5 xuất hiện trong tài liệu bổ sung và tuân theo các luận chứng
được phát triển trong chứng minh của Massart (2007, Định lý 7.11). Chứng minh của Mệnh
đề 3 theo tinh thần của phương pháp minimization rủi ro cấu trúc của Vapnik, đầu tiên
được thiết lập trong Vapnik (1982) và tóm tắt ngắn gọn trong Phần 8.2 của Massart (2007).
Đặc biệt, chúng tôi sử dụng các bất đẳng thức tập trung kết hợp với các luận chứng đối
xứng hóa để thu được một cận trên của quá trình thực nghiệm trong kỳ vọng từ (20). Kỹ
thuật của chúng tôi kết hợp paradigm minimization rủi ro cấu trúc của Vapnik (ví dụ,
Vapnik, 1982) và lý thuyết lựa chọn mô hình cho ước lượng mật độ có điều kiện (ví dụ,
Cohen và Le Pennec, 2011), mở rộng các kết quả ước lượng mật độ của Massart (2007).
4. Thí nghiệm số
Trong phần này, chúng tôi xác thực thực nghiệm tốc độ hội tụ của cận trên lỗi trong (10)
từ Định lý 1 trong các mô hình SGMoE của chúng tôi. Để đơn giản, chúng tôi chỉ thực hiện
một nghiên cứu mô phỏng để minh họa các tốc độ hội tụ khi X ⊂ R^p, p = 6, và Y ⊂ R^q,
q = 1. Tất cả các mô phỏng sau đây được thực hiện trong R 4.3.2 trên một máy Unix tiêu
chuẩn. Chúng tôi xây dựng các bộ dữ liệu mô phỏng lấy mẫu từ mật độ có điều kiện thực, s0,
thuộc lớp các mô hình SGMoE S:
s0(y|x) = ∑_{k=1}^2 exp(γ0k0 + γ0k^⊤x) / ∑_{l=1}^2 exp(γ0l0 + γ0l^⊤x) N(y; β0k0 + β0kx, Σ0k).
Ở đây, các tham số thực cho mô hình SGMoE thực được cho bởi:
(γ010, γ01)^⊤ = (1, 2, 0, 0, -1, 0, 0)^⊤; Σ01 = Σ02 = 1;
(β010, β01)^⊤ = (0, 0, 1.5, 0, 0, 0, 1)^⊤; (β020, β02)^⊤ = (0, 1, -1.5, 0, 0, 2, 0)^⊤.
Ở đây chúng tôi thực hiện l1-PMLE sử dụng thuật toán EM cho mô hình SGMoE với
thuật toán coordinate ascent để cập nhật mạng gating, theo chiến lược của
Chamroukhi và Huynh (2018, 2019).

--- TRANG 12 ---
Nguyen Nguyen Chamroukhi McLachlan
Chúng tôi muốn xác thực thực nghiệm tốc độ hội tụ của cận trên lỗi theo
phân kỳ KL, không thể được tính toán chính xác trong trường hợp các hỗn hợp Gaussian.
Do đó, chúng tôi đánh giá phân kỳ thông qua một mô phỏng Monte Carlo, cho rằng
chúng tôi có kiến thức về mật độ thực. Quan trọng là đề cập rằng biến thiên trong
xấp xỉ ngẫu nhiên này đã được chứng minh là tối thiểu trong thực tế, một thực tế
được củng cố bởi các thí nghiệm số được thực hiện bởi Nguyen et al. (2022b); Montuelle
và Le Pennec (2014). Cụ thể, chúng tôi tính xấp xỉ Monte Carlo cho phân kỳ KL trung bình
KLn(s0, ŝ^{Lasso}_λ) như được mô tả dưới đây:
1/n ∑_{i=1}^n KL(s0(·|xi), ŝ^{Lasso}_λ(·|xi)) ≈ 1/(n·ny) ∑_{i=1}^n ∑_{j=1}^{ny} ln(s0(yij|xi)/ŝ^{Lasso}_λ(yij|xi)).
Ở đây (yij)_{j∈[ny]} được rút từ s0(·|xi). Sau đó E[KLn(s0, ŝ^{Lasso}_λ)] được xấp xỉ lại bằng
việc lấy trung bình trên nt thử nghiệm Monte Carlo. Do đó, dữ liệu mô phỏng được sử dụng cho xấp xỉ
có thể được viết là (xi, yij)t với i ∈ [n], j ∈ [ny], t ∈ [nt]. Hình 1 minh họa rằng lỗi
giảm với bậc C1n√K/√n, như được dự đoán lý thuyết trong Định lý 1, khi kích thước mẫu
n tăng lên khi áp dụng penalty dựa trên tiêu chí của chúng tôi.

[THIS IS FIGURE: A log-log plot showing the decay of average KL divergence between true and selected densities based on Lasso estimator. The plot shows data points and regression lines, with sample size on x-axis (1000 to 30000) and Mean of Kullback Leibler distance on y-axis (0.005 to 0.030).]

Hình 1: Phân kỳ KL trung bình giữa các mật độ thực và được chọn dựa trên bộ ước lượng Lasso,
được biểu diễn trong thang log-log, sử dụng 100 lựa chọn khác nhau của kích thước mẫu
n giữa 1000 và 32000 qua nt = 20 thử nghiệm và ny = 30. Một hồi quy bình phương
nhỏ nhất tự do với khoảng tin cậy và một hồi quy với độ dốc -1/2 được thêm vào
để nhấn mạnh hai hành vi khác nhau cho mỗi đồ thị.

--- TRANG 13 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
5. Kết luận
Theo hiểu biết tốt nhất của chúng tôi, chúng tôi là những người đầu tiên thiết lập một bất đẳng thức
l1-oracle cho các mô hình SGMoE từ góc độ không tiệm cận, dưới các giả định nhẹ nhàng nhất,
cụ thể là tính bị chặn của không gian tham số, cung cấp một cận dưới cho tham số regularization
của Lasso, trong khi đảm bảo kiểm soát lý thuyết không tiệm cận của mất mát KL của
bộ ước lượng. Chúng tôi tiếp tục thực hiện một nghiên cứu mô phỏng để xác nhận thực nghiệm
các kết quả lý thuyết của chúng tôi. Chúng tôi tin rằng đóng góp của chúng tôi hỗ trợ trong việc
phổ biến thêm các mô hình MoE bằng cách cung cấp cơ sở lý thuyết cho ứng dụng của chúng
vào dữ liệu đa chiều cao không đồng nhất.
Tài liệu tham khảo
Sylvain Arlot và Alain Celisse. A survey of cross-validation procedures for model selection.
Statistics Surveys, 4:40–79, January 2010.
Andrew Barron, Lucien Birgé, và Pascal Massart. Risk bounds for model selection via
penalization. Probability theory and related fields, 113:301–413, 1999.
Andrew R. Barron, Albert Cohen, Wolfgang Dahmen, và Ronald A. DeVore. Approximation
and learning by greedy algorithms. The Annals of Statistics, 36(1):64 – 94, 2008.
Jonathan M Borwein và Qiji J Zhu. Techniques of Variational Analysis. Springer New
York, 2004.
Faicel Chamroukhi và Bao Tuyen Huynh. Regularized maximum-likelihood estimation of
mixture-of-experts for regression and clustering. In 2018 International Joint Conference
on Neural Networks (IJCNN), pages 1–8, 2018.
Faicel Chamroukhi và Bao Tuyen Huynh. Regularized maximum likelihood estimation
and feature selection in mixtures-of-experts models. Journal de la Société Française de
Statistique, 160(1):57–85, 2019.
S X Cohen và Erwan Le Pennec. Conditional density estimation by penalized likelihood
model selection and applications. Technical report, INRIA, 2011.
Thomas M Cover. Elements of information theory. John Wiley & Sons, 1999.
Emilie Devijver. An l1-oracle inequality for the Lasso in multivariate finite mixture of
multivariate Gaussian regression models. ESAIM: PS, 19:649–670, 2015.
Johannes Jisse Duistermaat và Johan AC Kolk. Multidimensional real analysis I: differentiation, volume 86. Cambridge University Press, 2004.
Jianqing Fan và Runze Li. Variable selection via nonconcave penalized likelihood and its
oracle properties. Journal of the American statistical Association, 96(456):1348–1360,
2001.
Christopher R Genovese và Larry Wasserman. Rates of convergence for the Gaussian
mixture sieve. The Annals of Statistics, 28(4):1105–1127, aug 2000.

--- TRANG 14 ---
Nguyen Nguyen Chamroukhi McLachlan
Gene H Golub và Charles F Van Loan. Matrix computations, volume 3. JHU press, 2012.
Nhat Ho và XuanLong Nguyen. Convergence rates of parameter estimation for some weakly
identifiable finite mixtures. The Annals of Statistics, 44(6):2726 – 2755, 2016.
Nhat Ho, Chiao-Yu Yang, và Michael I. Jordan. Convergence Rates for Gaussian Mixtures
of Experts. Journal of Machine Learning Research, 23(323):1–81, 2022.
Roger A Horn và Charles R Johnson. Matrix analysis. Cambridge University Press, 2012.
Bao Tuyen Huynh và Faicel Chamroukhi. Estimation and feature selection in mixtures of
generalized linear experts models. arXiv preprint arXiv:1907.06994, 2019.
Robert A Jacobs, Michael I Jordan, Steven J Nowlan, và Geoffrey E Hinton.. Adaptive
mixtures of local experts. Neural computation, 3(1):79–87, 1991.
J L W V Jensen. Sur les fonctions convexes et les inégalités entre les valeurs moyennes. Acta
Mathematica, 30(1):175–193, 1906.
Wenxin Jiang và Martin A Tanner. Hierarchical mixtures-of-experts for exponential
family regression models: approximation and maximum likelihood estimation. Annals of
Statistics, pages 987–1011, 1999.
Abbas Khalili. New estimation and feature selection methods in mixture-of-experts models.
Canadian Journal of Statistics, 38(4):519–539, 2010.
Abbas Khalili và Jiahua Chen. Variable selection in finite mixture of regression models.
Journal of the american Statistical association, 102(479):1025–1038, 2007.
Luke R Lloyd-Jones, Hien D Nguyen, và Geoffrey J McLachlan. A globally convergent
algorithm for lasso-penalized mixture of linear regression models. Computational Statistics
& Data Analysis, 119:19–38, 2018.
Jan R Magnus và Heinz Neudecker. Matrix differential calculus with applications in
statistics and econometrics. John Wiley & Sons, 2019.
Masud Mansuripur. Introduction to information theory. Prentice-Hall, Inc., 1987.
Pascal Massart. Concentration Inequalities and Model Selection: Ecole d'Eté de Probabilités
de Saint-Flour XXXIII-2003. Springer, 2007.
Pascal Massart và Caroline Meynet. The Lasso as an l1-ball model selection procedure.
Electronic Journal of Statistics, 5:669 – 687, 2011.
Pascal Massart và Caroline Meynet. Some Rates of Convergence for the Selected Lasso
Estimator. In Algorithmic Learning Theory, pages 17–33, Berlin, Heidelberg, 2012. ISBN
978-3-642-34106-9.
Cathy Maugis và Bertrand Michel. A non asymptotic penalized criterion for gaussian
mixture model selection. ESAIM: Probability and Statistics, 15:41–68, 2011.

--- TRANG 15 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
Cathy Maugis-Rabusseau và Bertrand Michel. Adaptive density estimation for clustering
with Gaussian mixtures. ESAIM: Probability and Statistics, 17:698–724, 2013.
G J McLachlan và D Peel. Finite Mixture Models. John Wiley & Sons, 2000.
Eduardo F Mendes và Wenxin Jiang. On convergence rates of mixtures of polynomial
experts. Neural computation, 24(11):3025–3051, 2012.
C Meynet. An l1-oracle inequality for the Lasso in finite mixture Gaussian regression models.
ESAIM: Probability and Statistics, 17:650–671, 2013.
Lucie Montuelle và Erwan Le Pennec. Mixture of Gaussian regressions model with logistic
weights, a penalized maximum likelihood approach. Electronic Journal of Statistics, 8(1):
1661–1695, 2014.
Hien D Nguyen và Faicel Chamroukhi. Practical and theoretical aspects of mixture-of-
experts modeling: An overview. Wiley Interdisciplinary Reviews: Data Mining and
Knowledge Discovery, 8(4):e1246, 2018.
Hien D Nguyen, Luke R Lloyd-Jones, và Geoffrey J McLachlan. A universal approximation
theorem for mixture-of-experts models. Neural computation, 28(12):2585–2593, 2016.
Hien D Nguyen, Faicel Chamroukhi, và Florence Forbes. Approximation results regarding
the multiple-output Gaussian gated mixture of linear experts model. Neurocomputing,
366:208–214, 2019. ISSN 0925-2312.
Hien D Nguyen, TrungTin Nguyen, Faicel Chamroukhi, và Geoffrey John McLachlan.
Approximations of conditional probability density functions in Lebesgue spaces via mixture
of experts models. Journal of Statistical Distributions and Applications, 8(1):13, 2021.
Huy Nguyen, TrungTin Nguyen, và Nhat Ho. Demystifying Softmax Gating Function
in Gaussian Mixture of Experts. In Thirty-seventh Conference on Neural Information
Processing Systems, 2023.
Huy Nguyen, Pedram Akbarian, TrungTin Nguyen, và Nhat Ho. A General Theory for
Softmax Gating Multinomial Logistic Mixture of Experts. In Forty-first International
Conference on Machine Learning, 2024a.
Huy Nguyen, TrungTin Nguyen, Khai Nguyen, và Nhat Ho. Towards Convergence Rates
for Parameter Estimation in Gaussian-gated Mixture of Experts. In Proceedings of The
27th International Conference on Artificial Intelligence and Statistics, volume 238, pages
2683–2691, May 2024b.
TrungTin Nguyen, Hien D. Nguyen, Faicel Chamroukhi, và Geoffrey J. McLachlan. Approximation by finite mixtures of continuous density functions that vanish at infinity.
Cogent Mathematics & Statistics, 7(1):1750861, January 2020.
TrungTin Nguyen, Faicel Chamroukhi, Hien D. Nguyen, và Geoffrey J. McLachlan. Approximation of probability density functions via location-scale finite mixtures in Lebesgue
spaces. Communications in Statistics - Theory and Methods, pages 1–12, May 2022a.

--- TRANG 16 ---
Nguyen Nguyen Chamroukhi McLachlan
TrungTin Nguyen, Hien Duy Nguyen, Faicel Chamroukhi, và Florence Forbes. A non-
asymptotic approach for model selection via penalization in high-dimensional mixture of
experts models. Electronic Journal of Statistics, 16(2):4742 – 4822, 2022b.
XuanLong Nguyen. Convergence of latent mixing measures in finite and infinite mixture
models. The Annals of Statistics, 41(1):370–400, 2013.
Andriy Norets. Approximation of conditional densities by smooth mixtures of regressions.
The Annals of Statistics, 38(3):1733 – 1766, 2010.
Richard A Redner và Homer F Walker. Mixture densities, maximum likelihood and the
EM algorithm. SIAM review, 26(2):195–239, 1984.
Gideon Schwarz. Estimating the dimension of a model. The Annals of Statistics, 6(2):
461–464, 1978.
N Stadler, P Buhlmann, và S van de Geer. l1-penalization for mixture regression models.
TEST, 19:209–256, 2010.
M. Stone. Cross-Validatory Choice and Assessment of Statistical Predictions. Journal of the
Royal Statistical Society: Series B (Methodological), 36(2):111–133, 1974.
Robert Tibshirani. Regression shrinkage and selection via the Lasso. Journal of the Royal
Statistical Society: Series B (Methodological), 58(1):267–288, 1996.
AW Van Der Vaart và JA Wellner. Weak Convergence and Empirical Processes: With
Applications to Statistics Springer Series in Statistics, volume 58. Springer, 1996.
Vladimir Vapnik. Estimation of Dependences Based on Empirical Data (Springer Series in
Statistics). Springer-Verlag, 1982.
Martin J Wainwright. High-dimensional statistics: A non-asymptotic viewpoint, volume 48.
Cambridge University Press, 2019.
Christopher K Williams và Carl Edward Rasmussen. Gaussian processes for machine
learning, volume 2. MIT press Cambridge, MA, 2006.
S E Yuksel, J N Wilson, và P D Gader. Twenty Years of Mixture of Experts. IEEE
Transactions on Neural Networks and Learning Systems, 23(8):1177–1193, 2012.

--- TRANG 17 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
Phụ lục cho "Bất đẳng thức oracle không tiệm cận cho the
Lasso trong hỗn hợp chuyên gia đa chiều cao" Trong phụ lục này, chúng
tôi cung cấp chứng minh cho Định lý 2, và Mệnh đề 3 và 4 trong Phụ lục A.1, A.2 và A.3,
tương ứng. Sau đó chúng tôi cung cấp chứng minh cho các lemma còn lại và cung cấp thêm
các kết quả kỹ thuật liên quan trong Phụ lục B và C, tương ứng.
Phụ lục A. Chứng minh các kết quả chính
Đầu tiên, quan trọng là lưu ý rằng âm của entropy vi phân (xem, ví dụ, Mansuripur
(1987, Chương 9)) của mật độ có điều kiện thực chưa biết s0 ∈ S, được định nghĩa trong (3), là hữu hạn,
xem thêm trong Lemma 6, được chứng minh trong Phụ lục B.3.
Lemma 6 Tồn tại một hằng số Hs0 = max{0, ln Cs0}, nơi Cs0 = (4π)^{-q/2}A^{q/2}_Σ, s.t.
max{0, sup_{x∈X} ∫_{R^q} ln(s0(y|x))s0(y|x)dy} ≤ Hs0 < ∞. (24)
Sau đó chúng tôi giới thiệu một số định nghĩa và ký hiệu mà chúng tôi sẽ sử dụng trong các chứng minh.
Ký hiệu bổ sung
Cho bất kỳ hàm đo được f: R^q → R, xem xét norm thực nghiệm của nó
∥f∥n := √(1/n ∑_{i=1}^n f²(Yi|xi)),
và kỳ vọng có điều kiện của nó
E_{Y|X=x}[f] := E[f(Y|X)|X = x] = ∫_{R^q} f(y|x)s0(y|x)dy.
Hơn nữa, chúng tôi cũng định nghĩa quá trình thực nghiệm của nó
Pn(f) := 1/n ∑_{i=1}^n f(Yi|xi), (25)
với kỳ vọng
P(f) = 1/n ∑_{i=1}^n E_{Yi|Xi=xi}[f(Yi|Xi)|Xi = xi] = 1/n ∑_{i=1}^n ∫_{R^q} f(y|xi)s0(y|xi)dy, (26)
và quá trình centered lại
νn(f) := Pn(f) - P(f) = 1/n ∑_{i=1}^n (f(Yi|xi) - ∫_{R^q} f(y|xi)s0(y|xi)dy). (27)

--- TRANG 18 ---
Nguyen Nguyen Chamroukhi McLachlan
Cho tất cả m ∈ N⋆, nhớ lại rằng chúng ta xem xét mô hình
Sm = {sψ ∈ S | ∥γ∥1 + ∥vec(β)∥1 ≤ m} ≡ {sψ ∈ S | ∥ψ∥_{[1,2]}_1 ≤ m},
Fm = {fm = -ln(sm/s0) = ln(s0) - ln(sm), sm ∈ Sm}.
Bằng cách sử dụng các tính chất cơ bản của infimum: cho mọi ε > 0, tồn tại xε ∈ A, sao cho
xε < inf A + ε. Sau đó let δ_{KL} > 0 cho tất cả m ∈ N⋆, và let ηm ≥ 0. Nó giữ rằng tồn
tại hai hàm ŝm và sm trong Sm, sao cho
Pn(-ln ŝm) ≤ inf_{sm∈Sm} Pn(-ln sm) + ηm, và (28)
KLn(s0, sm) ≤ inf_{sm∈Sm} KLn(s0, sm) + δ_{KL}. (29)
Định nghĩa
f̂m := -ln(ŝm/s0), và fm := -ln(sm/s0). (30)
Let η ≥ 0 và fix m ∈ N⋆. Hơn nữa, định nghĩa
M̂(m) = {m' ∈ N⋆ | Pn(-ln ŝm') + pen(m') ≤ Pn(-ln ŝm) + pen(m) + η}. (31)
A.1. Chứng minh Định lý 2
Let Mn > 0 và κ ≥ 148. Giả sử rằng, cho tất cả m ∈ N⋆, hàm penalty thỏa mãn
pen(m) = λm, với
λ ≥ κKBn/√n √(q ln n p/ln(2p + 1) + 1). (32)
Chúng tôi suy ra, từ Mệnh đề 3 và 4, rằng bất kỳ bộ ước lượng penalized likelihood ŝ_{m̂} với m̂,
thỏa mãn
-1/n ∑_{i=1}^n ln(ŝ_{m̂}(yi|xi)) + pen(m̂) ≤ inf_{m∈N⋆}(-1/n ∑_{i=1}^n ln(ŝm(yi|xi)) + pen(m)) + η,
cho một số η ≥ 0, cho ra
E[KLn(s0, ŝ_{m̂})] = E[KLn(s0, ŝ_{m̂})IT] + E[KLn(s0, ŝ_{m̂})IT^c]
≤ (1 + κ^{-1}) inf_{m∈N⋆} inf_{sm∈Sm}[KLn(s0, sm) + pen(m) + ηm]
+ 302K^{3/2}qBn/√n [1 + (Aγ + qAβ + q√q)/(a²Σ)] + η
+ [e^{q/2-1}π^{q/2}/A^{q/2}_Σ + Hs0] √(2Knq)Aγe^{-(M²n-2MnAβ)/(4AΣ)}. (33)

--- TRANG 19 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
Để thu được bất đẳng thức (15), chỉ còn lại là tối ưu hóa bất đẳng thức (33), đối với Mn.
Vì hai điều khoản phụ thuộc vào Mn, trong (33), có tính đơn điệu ngược nhau đối với
Mn, chúng ta đang tìm kiếm một giá trị của Mn sao cho hai điều khoản này có cùng bậc
đối với n. Xem xét nghiệm dương Mn = Aβ + √(A²β + 4AΣ ln n) của phương trình
X(X - 2Aβ)/(4AΣ) - ln n = 0. Sau đó, một mặt,
e^{-(M²n-2MnAβ)/(4AΣ)} √n = e^{-ln n} √n = 1/√n.
Mặt khác, sử dụng bất đẳng thức (a + b)² ≤ 2(a² + b²), chúng ta có
Bn = max(AΣ, 1 + KAG)[1 + q√q(Mn + Aβ)²AΣ]
= max(AΣ, 1 + KAG)[1 + q√qAΣ(2Aβ + √(A²β + 4AΣ ln n))²]
≤ max(AΣ, 1 + KAG)[1 + 2q√qAΣ(5A²β + 4AΣ ln n)],
do đó (33) ngụ ý (15).
A.2. Chứng minh Mệnh đề 3
Cho mọi m' ∈ M̂(m), từ (31), (30), và (28), chúng ta thu được
Pn(f̂m') + pen(m') = Pn(ln(s0) - ln(ŝm')) + pen(m') (sử dụng (30))
≤ Pn(ln(s0) - ln(ŝm)) + pen(m) + η (sử dụng (31))
≤ Pn(ln(s0) - ln(sm)) + ηm + pen(m) + η
(sử dụng (28) với sm trong Sm và tính tuyến tính của Pn)
= Pn(fm) + pen(m) + ηm + η (sử dụng (30)).
Bởi định nghĩa của quá trình centered, νn(·), trong (27), nó giữ rằng
P(f̂m') + pen(m') ≤ P(fm) + pen(m) + νn(fm) - νn(f̂m') + η + ηm.
Tính đến (4) và (25), chúng ta thu được
KLn(s0, ŝm') = 1/n ∑_{i=1}^n ∫_{R^q} ln(s0(y|xi)/ŝm'(y|xi)) s0(y|xi)dy = 1/n ∑_{i=1}^n ∫_{R^q} f̂m'(y|xi)s0(y|xi)dy (sử dụng (30))
= P(f̂m') (sử dụng (26)).
Tương tự, chúng ta cũng thu được KLn(s0, sm) = P(fm). Do đó, (29) ngụ ý rằng
KLn(s0, ŝm') + pen(m') ≤ KLn(s0, sm) + pen(m) + νn(fm) - νn(f̂m') + η + ηm
≤ inf_{sm∈Sm} KLn(s0, sm) + pen(m) + νn(fm) - νn(f̂m') + ηm + δ_{KL} + η. (34)

--- TRANG 20 ---
Nguyen Nguyen Chamroukhi McLachlan
Tất cả những gì còn lại là kiểm soát độ lệch của -νn(f̂m') = νn(-f̂m'). Để xử lý
tính ngẫu nhiên của f̂m', chúng ta sẽ kiểm soát độ lệch của sup_{fm'∈Fm'} νn(-fm'), vì f̂m' ∈ Fm'.
Kiểm soát như vậy được cung cấp bởi Lemma 5. Từ (34) và (23), chúng ta suy ra rằng trên sự kiện T,
cho tất cả m ∈ N⋆, và t > 0, với xác suất lớn hơn 1 - e^{-t},
KLn(s0, ŝm') + pen(m') ≤ inf_{sm∈Sm} KLn(s0, sm) + pen(m) + νn(fm) - νn(f̂m') + ηm + δ_{KL} + η
≤ inf_{sm∈Sm} KLn(s0, sm) + pen(m) + νn(fm) + ηm + δ_{KL} + η
+ 4KBn/√n [37q Δm' + √2 (Aγ + qAβ + q√q)/aΣ √t]
≤ inf_{sm∈Sm} KLn(s0, sm) + pen(m) + νn(fm) + ηm + δ_{KL} + η
+ 4KBn/√n [37q Δm' + 1/2 (Aγ + qAβ + q√q)²/a²Σ + t], nếu m' ∈ M̂(m).
(35)
Ở đây, chúng ta sử dụng thực tế rằng f̂m' ∈ Fm' và có được bất đẳng thức cuối cùng sử dụng thực tế rằng
2ab ≤ a² + b² cho b = √t, và a = (Aγ + qAβ + q√q)/(aΣ√2).
Nó vẫn còn để tổng hợp các cận tail (35) trên tất cả các giá trị có thể của m ∈ N⋆ và
m' ∈ M̂(m). Để có được một bất đẳng thức có hiệu lực trên một tập hợp xác suất cao, chúng ta cần
chọn một cách phù hợp giá trị của tham số t, phụ thuộc vào m ∈ N⋆ và m' ∈ M̂(m). Let z > 0, cho
tất cả m ∈ N⋆ và m' ∈ M̂(m), và áp dụng (35) để thu được t = z + m + m'. Sau đó, trên sự kiện
T, cho tất cả m ∈ N⋆, với xác suất lớn hơn 1 - e^{-(z+m+m')},
KLn(s0, ŝm') + pen(m') ≤ inf_{sm∈Sm} KLn(s0, sm) + pen(m) + νn(fm) + ηm + δ_{KL} + η
+ 4KBn/√n [37q Δm' + 1/2 (Aγ + qAβ + q√q)²/a²Σ + z + m + m'], nếu m' ∈ M̂(m). (36)
Ở đây, (36) tương đương với
KLn(s0, ŝm') - νn(fm) ≤ inf_{sm∈Sm} KLn(s0, sm) + [pen(m) + 4KBn/√n m] + ηm + δ_{KL} + η
+ 4KBn/√n [37q Δm' + m'] - pen(m')
+ 4KBn/√n [1/2 (Aγ + qAβ + q√q)²/a²Σ + z]. (37)
Lưu ý rằng với xác suất lớn hơn 1 - e^{-z}, (36) giữ đồng thời cho tất cả m ∈ N⋆
và m' ∈ M̂(m). Thật vậy, bằng cách định nghĩa sự kiện
∩_{(m,m')∈N⋆×M̂(m)} Ωm,m' = {ω : ω ∈ Ω sao cho sự kiện trong (36) giữ},

--- TRANG 21 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
nó giữ rằng, trên sự kiện T,
P(∩_{(m,m')∈N⋆×M̂(m)} Ωm,m') = 1 - P(∪_{(m,m')∈N⋆×M̂(m)} Ω^c_{m,m'})
≥ 1 - ∑_{(m,m')∈N⋆×M̂(m)} P(Ω^c_{m,m'})
≥ 1 - ∑_{(m,m')∈N⋆×N⋆} e^{-(z+m+m')}
= 1 - e^{-z} (∑_{m∈N⋆} e^{-m})²
≥ 1 - e^{-z},
nơi chúng ta có được bất đẳng thức cuối cùng bằng cách sử dụng chuỗi hình học
∑_{m=1}^∞ e^{-1·m} = ∑_{m=0}^∞ e^{-1·m} - 1 = 1/(1-e^{-1}) - 1 = e/(e-1) - 1 = 1/(e-1) < 1.
Tính đến (22), chúng ta có
KLn(s0, ŝm') - νn(fm) ≤ inf_{sm∈Sm} KLn(s0, sm) + [pen(m) + 4KBn/√n m] + ηm + δ_{KL} + η
+ 4KBn/√n [37q ln n √(p/ln(2p + 1) + 1) m'] - pen(m')
+ 4KBn/√n [1/2 (Aγ + qAβ + q√q)²/a²Σ + 74q√K (Aγ + qAβ + q√q)/aΣ + z].
(38)
Bây giờ, let κ ≥ 1 và giả sử rằng pen(m) = λm, cho tất cả m ∈ N⋆ với
λ ≥ κ · 4KBn/√n [37q ln n √(p/ln(2p + 1) + 1)]. (39)

--- TRANG 22 ---
Nguyen Nguyen Chamroukhi McLachlan
Sau đó, (38) ngụ ý
KLn(s0, ŝm') - νn(fm) ≤ inf_{sm∈Sm} KLn(s0, sm) + [λm + 4KBn/√n m] + ηm + δ_{KL} + η
+ 4KBn/√n [37q ln n √(p/ln(2p + 1) + 1)] |_{≤λκ^{-1}m'} - λm'
+ 4KBn/√n [1/2 (Aγ + qAβ + q√q)²/a²Σ + 74q√K (Aγ + qAβ + q√q)/aΣ + z]
≤ inf_{sm∈Sm} KLn(s0, sm) + [pen(m) + 4KBn/√n m] |_{≤κ^{-1}pen(m)} + ηm + δ_{KL} + η
+ [λκ^{-1}m' - λm'] |_{≤0}
+ 4KBn/√n [1/2 (Aγ + qAβ + q√q)²/a²Σ + 74q√K (Aγ + qAβ + q√q)/aΣ + z]
≤ inf_{sm∈Sm} KLn(s0, sm) + (1 + κ^{-1})pen(m) + ηm + δ_{KL} + η
+ 4KBn/√n [1/2 (Aγ + qAβ + q√q)²/a²Σ + 74q√K (Aγ + qAβ + q√q)/aΣ + z].
Tiếp theo, sử dụng bất đẳng thức 2ab ≤ β^{-1}a² + β^{-1}b² cho a = √K, b = K(Aγ + qAβ + q√q)/aΣ, và
β = √K, và thực tế rằng K ≤ K^{3/2}, cho tất cả K ∈ N⋆, nó theo
KLn(s0, ŝm') - νn(fm) ≤ inf_{sm∈Sm} KLn(s0, sm) + (1 + κ^{-1})pen(m) + ηm + δ_{KL} + η
+ 4Bn/√n [qK^{3/2}/2 (Aγ + qAβ + q√q)²/a²Σ + 74q√K · K (Aγ + qAβ + q√q)/aΣ |_{37q×2ab+Kz}]
≤ inf_{sm∈Sm} KLn(s0, sm) + (1 + κ^{-1})pen(m) + ηm + δ_{KL} + η
+ 4Bn/√n [37qK^{1/2} + 75qK^{3/2}/2 (Aγ + qAβ + q√q)²/a²Σ + Kz]. (40)

--- TRANG 23 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
Bởi (14) và (31), m̂ thuộc M̂(m), cho tất cả m ∈ N⋆, vì vậy chúng ta suy ra từ (40) rằng trên
sự kiện T, cho tất cả z > 0, với xác suất lớn hơn 1 - e^{-z},
KLn(s0, ŝ_{m̂}) - νn(fm) ≤ inf_{m∈N⋆} inf_{sm∈Sm}[KLn(s0, sm) + (1 + κ^{-1})pen(m) + ηm]
+ η + δ_{KL}
+ 4Bn/√n [37qK^{1/2} + 75qK^{3/2}/2 (Aγ + qAβ + q√q)²/a²Σ + Kz].
(41)
Lưu ý rằng cho bất kỳ biến ngẫu nhiên không âm Z và bất kỳ a > 0, E[Z] = a∫_{z≥0} P(Z > az)dz. Thật vậy, nếu chúng ta let t = az, thì dz = adt và
a∫_{z≥0} P(Z > az)dz = a∫_0^∞ ∫_{az}^∞ f_Z(u)dudz = ∫_0^∞ ∫_0^{u/a} f_Z(u)dtdu = ∫_0^∞ f_Z(u)∫_0^{u/a} dtdu
= ∫_0^∞ f_Z(u)udu = E[Z]. (42)
Sau đó, chúng ta định nghĩa biến ngẫu nhiên sau w.r.t. phản hồi ngẫu nhiên Y[n] := (Yi)_{i∈[n]}:
Z := KLn(s0, ŝ_{m̂}) - νn(fm) - inf_{m∈N⋆} inf_{sm∈Sm}[KLn(s0, sm) + (1 + κ^{-1})pen(m) + ηm]
- η - δ_{KL} - 4Bn/√n [37qK^{1/2} + 75qK^{3/2}/2 (Aγ + qAβ + q√q)²/a²Σ].
Sau đó bởi (41), trên sự kiện T, nó giữ rằng P(Z ≤ az) ≥ 1 - e^{-z} và nếu Z ≤ 0 thì
P(Z < az) = 1 ≥ 1 - e^{-z}, cho tất cả z > 0, nơi a = 4BnK/√n > 0. Do đó, đủ để
xem xét Z ≥ 0 và nó giữ rằng P(Z > az|T) ≤ e^{-z}. Trong trường hợp này, bởi (42) và thực tế rằng
P(T) ≤ 1, nó giữ rằng
E_{Y[n]}[Z I_T] = P(T)E_{Y[n]}[Z|T] ≤ E_{Y[n]}[Z|T] ≤ a∫_{z≥0} e^{-z}dz = a. (43)
Sau đó, bằng cách tích phân (41) trên z > 0 sử dụng (43), thực tế rằng
E_{Y[n]}[νn(fm)] = E_{Y[n]}[Pn(fm)] - E_{Y[n]}[P(fm)] = 0, (44)

--- TRANG 24 ---
Nguyen Nguyen Chamroukhi McLachlan
δ_{KL} > 0 có thể được chọn tùy ý nhỏ, và E_{Y[n]}[I_T] = P(T) ≤ 1, chúng ta thu được rằng
E[KLn(s0, ŝ_{m̂})I_T] ≤ inf_{m∈N⋆} inf_{sm∈Sm}[KLn(s0, sm) + (1 + κ^{-1})pen(m) + ηm] + η
E_{Y[n]}[I_T]
+ 4Bn/√n [37qK^{1/2} + 75qK^{3/2}/2 (Aγ + qAβ + q√q)²/a²Σ + K] E_{Y[n]}[I_T]
≤ inf_{m∈N⋆} inf_{sm∈Sm}[KLn(s0, sm) + (1 + κ^{-1})pen(m) + ηm] + η
+ 4Bn/√n [37qK^{3/2} + 75qK^{3/2}/2 (Aγ + qAβ + q√q)²/a²Σ + qK^{3/2}]
≤ inf_{m∈N⋆} inf_{sm∈Sm}[KLn(s0, sm) + (1 + κ^{-1})pen(m) + ηm] + η
+ 302K^{3/2}qBn/√n [1 + (Aγ + qAβ + q√q)²/a²Σ]. (45)
A.3. Chứng minh Mệnh đề 4
Bởi bất đẳng thức Cauchy-Schwarz,
E[KLn(s0, ŝ_{m̂})I_{T^c}] ≤ √(E[KL²n(s0, ŝ_{m̂})]) √(E[I²_{T^c}]) = √(E[KL²n(s0, ŝ_{m̂})]) √(P(T^c)). (46)
Chúng ta tìm cách chặn hai điều khoản ở phía bên phải của (46).
Cho điều khoản đầu tiên, let us bound KL(s0(·|x), sψ(·|x)), cho tất cả sψ ∈ S và x ∈ X. Let
sψ ∈ S và x ∈ X. Sau đó, chúng ta thu được
KL(s0(·|x), sψ(·|x)) = ∫_{R^q} ln(s0(y|x)/sψ(y|x)) s0(y|x)dy
= ∫_{R^q} ln(s0(y|x))s0(y|x)dy - ∫_{R^q} ln(sψ(y|x))s0(y|x)dy
≤ -∫_{R^q} ln(sψ(y|x))s0(y|x)dy + Hs0, ∀x ∈ X (sử dụng (24)). (47)
Vì
aG := exp(-Aγ)/∑_{l=1}^K exp(Aγ) ≤ sup_{x∈X,γ∈Γ̃} exp(γk0 + γk^⊤x)/∑_{l=1}^K exp(γl0 + γl^⊤x) ≤ exp(Aγ)/∑_{l=1}^K exp(-Aγ) =: AG,
tồn tại các hằng số dương xác định aG, AG, sao cho
aG ≤ sup_{x∈X,γ∈Γ̃} gk(x;γ) ≤ AG. (48)
Ở đây, hàm gating softmax gk(x;γ) được mô tả là
gk(x;γ) = exp(wk(x))/∑_{l=1}^K exp(wl(x)), wk(x) = γk0 + γk^⊤x, γ = (γk0, γk^⊤)_{k∈[K]} ∈ Γ = R^{(p+1)K}. (49)

--- TRANG 25 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
Do đó, cho tất cả y ∈ R^q,
ln(sψ(y|x))s0(y|x) ≥ ln[∑_{k=1}^K aG det(Σk^{-1})^{1/2}/(2π)^{q/2} exp(-(y^⊤Σk^{-1}y + (βk0 + βkx)^⊤Σk^{-1}(βk0 + βkx))/2)]
× ∑_{k=1}^K aG det(Σ0,k^{-1})^{1/2}/(2π)^{q/2} exp(-(y^⊤Σ0,k^{-1}y + (β0,k0 + β0,kx)^⊤Σ0,k^{-1}(β0,k0 + β0,kx))/2)
sử dụng (48) và -(a-b)^⊤A(a-b)/2 ≥ -(a^⊤Aa + b^⊤Ab), e.g., a = y, b = βk0 + βkx, A = Σk
≥ ln[∑_{k=1}^K aG a^{q/2}_Σ/(2π)^{q/2} exp(-(y^⊤Σk^{-1}y + (βk0 + βkx)^⊤Σk^{-1}(βk0 + βkx))/2)]
× ∑_{k=1}^K aG a^{q/2}_Σ/(2π)^{q/2} exp(-(y^⊤Σ0,k^{-1}y + (β0,k0 + β0,kx)^⊤Σ0,k^{-1}(β0,k0 + β0,kx))/2) (sử dụng (2))
≥ ln[Ka_G a^{q/2}_Σ/(2π)^{q/2} exp(-(y^⊤y + qA²β)/AΣ)]
× Ka_G a^{q/2}_Σ/(2π)^{q/2} exp(-(y^⊤y + qA²β)/AΣ) (sử dụng (2)),
(50)
nơi, trong bất đẳng thức cuối cùng, chúng ta sử dụng thực tế rằng cho tất cả u ∈ R^q. Bằng cách sử dụng phân tích eigenvalue của Σ1 = P^⊤DP,
u^⊤Σ1u = u^⊤P^⊤DPu ≤ ∥Pu∥² ≤ M(D)∥Pu∥²₂ ≤ AΣ∥u∥²₂ ≤ AΣq∥u∥²∞,
nơi trong bất đẳng thức cuối cùng, chúng ta sử dụng thực tế rằng (94). Do đó, đặt u = √(2AΣ)y và
h(t) = t ln t, cho tất cả t ∈ R, và lưu ý rằng h(t) ≥ h(e^{-1}) = -e^{-1}, cho tất cả t ∈ R, và từ
(47) và (50), chúng ta có
KL(s0(·|x), sψ(·|x)) - Hs0
≤ -∫_{R^q} [ln(Ka_γ a^{q/2}_Σ/(2π)^{q/2} exp(-(y^⊤y + qA²β)/AΣ)) / Ka_γ a^{q/2}_Σ/(2π)^{q/2} exp(-(y^⊤y + qA²β)/AΣ)] dy
= -Ka_γ a^{q/2}_Σ e^{-qA²β/AΣ}/(2AΣ)^{q/2} ∫_{R^q} [ln(Ka_γ a^{q/2}_Σ/(2π)^{q/2}) - qA²β/AΣ - u^⊤u/2] e^{-u^⊤u/2}/(2π)^{q/2} du
= -Ka_γ a^{q/2}_Σ e^{-qA²β/AΣ}/(2AΣ)^{q/2} E_U[[ln(Ka_γ a^{q/2}_Σ/(2π)^{q/2}) - qA²β/AΣ - U^⊤U/2]] (với U ~ N_q(0, I_q))
= -Ka_γ a^{q/2}_Σ e^{-qA²β/AΣ}/(2AΣ)^{q/2} [ln(Ka_γ a^{q/2}_Σ/(2π)^{q/2}) - qA²β/AΣ - q/2]
= -Ka_γ a^{q/2}_Σ e^{-qA²β/AΣ-q/2}/(2π)^{q/2}(AΣ)^{q/2} e^{q/2} π^{q/2} ln(Ka_γ a^{q/2}_Σ e^{-qA²β/AΣ-q/2}/(2π)^{q/2})
≤ e^{q/2-1} π^{q/2}/A^{q/2}_Σ, (51)
nơi chúng ta sử dụng thực tế rằng t ln(t) ≥ -e^{-1}, cho tất cả t ∈ R.

--- TRANG 26 ---
Nguyen Nguyen Chamroukhi McLachlan
Sau đó, cho tất cả sψ ∈ S,
KLn(s0, sψ) = 1/n ∑_{i=1}^n KL(s0(·|xi), sψ(·|xi)) ≤ e^{q/2-1} π^{q/2}/A^{q/2}_Σ + Hs0,
và lưu ý rằng ŝ_{m̂} ∈ S, do đó
√(E[KL²n(s0, ŝ_{m̂})]) ≤ e^{q/2-1} π^{q/2}/A^{q/2}_Σ + Hs0. (52)
Bây giờ chúng ta cung cấp một cận trên cho P(T^c):
P(T^c) ≤ ∑_{i=1}^n P(∥Yi∥∞ > Mn). (53)
Cho tất cả i ∈ [n],
Yi|xi ~ ∑_{k=1}^K gk(xi;γ)N_q(βk0 + βkxi, Σk),
vì vậy chúng ta thấy từ (53) rằng chúng ta cần cung cấp một cận trên trên P(|Yx| > Mn), với
Yx ~ ∑_{k=1}^K gk(x;γ)N_q(βk0 + βkx, Σk), x ∈ X.
Đầu tiên, sử dụng bất đẳng thức Chernoff cho một biến Gaussian centered (xem Lemma 23), và thực tế rằng ψ thuộc không gian bị chặn Ψ̃ (được định nghĩa bởi (2)), và rằng ∑_{k=1}^K gk(x;γ) = 1,

--- TRANG 27 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
chúng ta có
P(∥Yx∥∞ > Mn)
= ∑_{k=1}^K gk(x;γ) 1/((2π)^{q/2} det(Σk)^{1/2}) ∫_{∥y∥∞>Mn} exp(-(y-(βk0+βkx))^⊤Σk^{-1}(y-(βk0+βkx))/2) dy
= ∑_{k=1}^K gk(x;γ)P(∥Yx,k∥∞ > Mn)
≤ ∑_{k=1}^K gk(x;γ) ∑_{z=1}^q P([Yx,k]z > Mn)
= ∑_{k=1}^K gk(x;γ) ∑_{z=1}^q [P([Yx,k]z < -Mn) + P([Yx,k]z > Mn)]
= ∑_{k=1}^K gk(x;γ) ∑_{z=1}^q [P(U > (Mn - [βk0+βkx]z)/[Σk]^{1/2}_{z,z}) + P(U < (-Mn - [βk0+βkx]z)/[Σk]^{1/2}_{z,z})]
= ∑_{k=1}^K gk(x;γ) ∑_{z=1}^q [P(U > (Mn - [βk0+βkx]z)/[Σk]^{1/2}_{z,z}) + P(U > (Mn + [βk0+βkx]z)/[Σk]^{1/2}_{z,z})]
≤ ∑_{k=1}^K gk(x;γ) ∑_{z=1}^q [e^{-1/2((Mn - [βk0+βkx]z)/[Σk]^{1/2}_{z,z})²} + e^{-1/2((Mn + [βk0+βkx]z)/[Σk]^{1/2}_{z,z})²}]
(sử dụng Lemma 23, (105))
≤ 2∑_{k=1}^K gk(x;γ) ∑_{z=1}^q e^{-1/2((Mn - |[βk0+βkx]z|)/[Σk]^{1/2}_{z,z})²}
≤ 2∑_{k=1}^K gk(x;γ) ∑_{z=1}^q e^{-(M²n - 2Mn|[βk0+βkx]z| + |[βk0+βkx]|²z)/(2[Σk]z,z)}
≤ 2KAγq e^{-(M²n - 2MnAβ)/(2AΣ)}, (54)
nơi
Yx,k ~ Nq(βk0 + βkx, Σk), [Yx,k]z ~ N([βk0 + βkx]z, [Σk]z,z), và U = ([Yx,k]z - [βx]z)/[Σk]^{1/2}_{z,z} ~ N(0,1),
và sử dụng các thực tế rằng e^{-|[βk0+βkx]|²z/(2AΣ)} ≤ 1 và max_{1≤z≤q} [Σk]z,z ≤ ∥Σk∥2 = M(Σk) = 1/m(Σk^{-1}) ≤ AΣ. Chúng ta suy ra từ (53) và (54) rằng
P(T^c) ≤ 2Knqaγ e^{-(M²n - 2MnAβ)/(2AΣ)}, (55)
và cuối cùng từ (46), (52), và (55), chúng ta thu được
E[KLn(s0, ŝ_{m̂})IT^c] ≤ [e^{q/2-1} π^{q/2}/A^{q/2}_Σ + Hs0] √(2Knqaγ e^{-(M²n - 2MnAβ)/(4AΣ)}). (56)

--- TRANG 28 ---
Nguyen Nguyen Chamroukhi McLachlan
Phụ lục B. Chứng minh các lemma kỹ thuật
B.1. Chứng minh Lemma 5
Let m ∈ N⋆, trên sự kiện T, để kiểm soát độ lệch
sup_{fm∈Fm} |νn(-fm)| = sup_{fm∈Fm} 1/n ∑_{i=1}^n {fm(Yi|xi) - E[fm(Yi|xi)]}, (57)
chúng ta sẽ sử dụng các luận chứng tập trung và đối xứng hóa. Chúng ta sẽ đầu tiên sử dụng bất đẳng thức tập trung sau, là một điều chỉnh của Wainwright (2019, Định lý 4.10).
Lemma 7 (Định lý 4.10 từ Wainwright (2019)) Let Z1, . . . , Zn là các biến ngẫu nhiên độc lập với giá trị trong một không gian Z nào đó và let F là một lớp các hàm có giá trị thực tích phân được với domain trên Z. Giả sử rằng
sup_{f∈F} ∥f∥∞ ≤ Rn cho một số hằng số không ngẫu nhiên Rn < ∞. (58)
Sau đó, cho tất cả t > 0,
P(sup_{f∈F} 1/n ∑_{i=1}^n [f(Zi) - E[f(Zi)]] > E[sup_{f∈F} 1/n ∑_{i=1}^n [f(Zi) - E[f(Zi)]]] + 2√2Rn√(t/n)) ≤ e^{-t}.
(59)
Nghĩa là, với xác suất lớn hơn 1 - e^t,
sup_{f∈F} 1/n ∑_{i=1}^n [f(Zi) - E[f(Zi)]] ≤ E[sup_{f∈F} 1/n ∑_{i=1}^n [f(Zi) - E[f(Zi)]]] + 2√2Rn√(t/n) (60)
Sau đó, chúng tôi đề xuất chặn E[sup_{f∈F} 1/n ∑_{i=1}^n [f(Zi) - E[f(Zi)]]] do luận chứng đối xứng hóa sau. Chứng minh của kết quả này có thể được tìm thấy trong Van Der Vaart và Wellner (1996).
Lemma 8 (Xem Lemma 2.3.6 trong Van Der Vaart và Wellner (1996)) Let Z1, . . . , Zn
là các biến ngẫu nhiên độc lập với giá trị trong một không gian Z nào đó và let F là một lớp các
hàm có giá trị thực trên Z. Let (ε1, . . . , εn) là một dãy Rademacher độc lập với (Z1, . . . , Zn).
Sau đó,
E[sup_{f∈F} 1/n ∑_{i=1}^n [f(Zi) - E[f(Zi)]]] ≤ 2E[sup_{f∈F} 1/n ∑_{i=1}^n εif(Zi)]. (61)
Từ (61), vấn đề là cung cấp một cận trên trên
E[sup_{f∈F} 1/n ∑_{i=1}^n εif(Zi)].
Để làm như vậy, chúng ta sẽ áp dụng lemma sau, được điều chỉnh từ Lemma 6.1 trong Massart (2007).

--- TRANG 29 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
Lemma 9 (Xem Lemma 6.1 trong Massart (2007)) Let Z1, . . . , Zn là các biến ngẫu nhiên độc lập với giá trị trong một không gian Z nào đó và let F là một lớp các hàm có giá trị thực trên Z.
Let (ε1, . . . , εn) là một dãy Rademacher, độc lập với (Z1, . . . , Zn). Định nghĩa Rn, một
hằng số không ngẫu nhiên, sao cho
sup_{f∈F} ∥f∥n ≤ Rn. (62)
Sau đó, cho tất cả S ∈ N⋆,
E[sup_{f∈F} 1/n ∑_{i=1}^n εif(Zi)] ≤ Rn[6/√n ∑_{s=1}^S 2^{-s} √(ln[1 + M(2^{-s}Rn, F, ∥·∥n)]) + 2^{-S}],
(63)
nơi M(δ, F, ∥·∥n) đại diện cho δ-packing number (xem Định nghĩa 20) của tập hợp các hàm
F, được trang bị metric cảm ứng bởi norm ∥·∥n.
Bây giờ chúng ta có thể chứng minh Lemma 5. Thật vậy, cho bất kỳ giá trị cố định x1, . . . , xn ∈ X, để
kiểm soát sup_{fm∈Fm} |νn(-fm)|IT từ (57), chúng ta muốn áp dụng Lemmas 7–9. Một mặt, chúng ta thấy từ (62) rằng chúng ta cần một cận trên của sup_{fm∈Fm} ∥fm∥∞IT. Mặt khác, chúng ta thấy từ (63) rằng trên sự kiện T, chúng ta cần chặn entropy của tập hợp các hàm Fm, được trang bị metric cảm ứng bởi norm ∥·∥n. Các cận như vậy được cung cấp bởi hai lemma sau.
Nhớ lại rằng cho Mn > 0, chúng ta đã xem xét sự kiện
T = {max_{i∈[n]} ∥Yi∥∞ = max_{i∈[n]} max_{z∈[q]} |[Yi]z| ≤ Mn}, (64)
let Bn = max(AΣ, 1 + KAG)[1 + q√q(Mn + Aβ)²AΣ].
Lemma 10 Trên sự kiện T, cho tất cả m ∈ N⋆,
sup_{fm∈Fm} ∥fm∥∞ ≤ 2KBn(Aγ + qAβ + q√q)/aΣ =: Rn. (65)
Chứng minh Lemma 10. Xem Phụ lục B.2.1.
Lemma 11 Let δ > 0 và m ∈ N⋆. Trên sự kiện T, chúng ta có cận trên sau của
δ-packing number của tập hợp các hàm Fm, được trang bị metric cảm ứng bởi
norm ∥·∥n:
M(δ, Fm, ∥·∥n) ≤ (2p + 1)^{72B²nq²K²m²/δ²} [1 + 18BnKqAβ/(δK)]^K [1 + 18BnKAγ/(δK)]^K [1 + 18BnKq√q/(aΣδK)]^K.
Chứng minh Lemma 11. Xem Phụ lục B.2.2.
Lemma 12 (Lemma 5.9 từ Meynet (2013)) Let δ > 0 và (xij)_{i∈[n];j=1,...,p} ∈ R^{np}.
Tồn tại một họ B của (2p + 1)^{∥x∥²_{max,n}/δ²} vectors trong R^p, sao cho cho tất cả β ∈ R^p, với
∥β∥1 ≤ 1, nơi ∥x∥²_{max,n} = 1/n ∑_{i=1}^n max_{j∈{1,...,p}} x²ij, tồn tại β' ∈ B, sao cho
1/n ∑_{i=1}^n (∑_{j=1}^p (βj - β'j)xij)² ≤ δ².

--- TRANG 30 ---
Nguyen Nguyen Chamroukhi McLachlan
Chứng minh Lemma 12. Xem trong chứng minh của Meynet (2013, Lemma 5.9).
Thông qua các cận trên được cung cấp trong Lemmas 10 và 11, chúng ta có thể áp dụng Lemma 9 để có được
một cận trên của
E[sup_{fm∈Fm} 1/n ∑_{i=1}^n εifm(Yi|xi)] trên sự kiện T. (66)
Để cung cấp một cận trên như vậy, Lemmas 7 và 9 có thể được sử dụng thông qua việc định nghĩa một
lớp phù hợp các hàm có giá trị thực tích phân được như sau:
F := {f := fmI_{|fm|≤Rn} : fm ∈ Fm}, Zi := Yi|xi, ∀i ∈ [n]. (67)
Thật vậy, theo định nghĩa, nó giữ rằng
sup_{f∈F} ∥f∥n ≤ sup_{f∈F} ∥f∥∞ = sup_{f∈F} sup_{z∈Z} |f(z)| = sup_{fm∈Fm} sup_{z∈Z} fm(z)I_{|fm(z)|≤Rn} ≤ Rn. (68)
Lưu ý rằng bất đẳng thức cuối cùng có hiệu lực vì nếu |fm(z)| ≤ Rn thì fm(z)I_{|fm(z)|≤Rn} =
|fm(z)| ≤ Rn. Ngược lại, nếu |fm(z)| > Rn, thì fm(z)I_{|fm(z)|≤Rn} = |fm(z) × 0| = 0 ≤ Rn.
Chúng ta do đó thu được các kết quả sau.
Lemma 13 Let m ∈ N⋆, xem xét (ε1, . . . , εn), một dãy Rademacher độc lập với
(Y1, . . . , Yn). Sau đó, trên sự kiện T, nó giữ rằng
E[sup_{fm∈Fm} 1/n ∑_{i=1}^n εifm(Yi|xi)] ≤ 74KBnq/√n Δm, nơi
Δm := m√(ln(2p + 1) ln n) + 2√K (Aγ + qAβ + q√q)/aΣ. (69)
Chứng minh Lemma 13. Xem Phụ lục B.2.3.
Bây giờ chúng ta quay lại chứng minh Lemma 5.

--- TRANG 31 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
Cuối cùng, trên sự kiện T, sử dụng (67) và Lemma 10, cho tất cả m ∈ N⋆ và t > 0, với
xác suất lớn hơn 1 - e^{-t}, chúng ta thu được
sup_{fm∈Fm} |νn(-fm)| = sup_{f∈F} 1/n ∑_{i=1}^n {f(Zi) - E[f(Zi)]} (70)
≤ E[sup_{f∈F} 1/n ∑_{i=1}^n [f(Zi) - E[f(Zi)]]] + 2√2Rn√(t/n) (sử dụng Lemma 7)
(71)
≤ E[sup_{f∈F} 1/n ∑_{i=1}^n [f(Zi) - E[f(Zi)]]] + 2√2Rn√(t/n) (vì ≤ 1) (72)
≤ 2E[sup_{f∈F} 1/n ∑_{i=1}^n εif(Zi)] + 2√2Rn√(t/n) (Lemma 8) (73)
= 2E[sup_{fm∈Fm} 1/n ∑_{i=1}^n εifm(Yi|xi)] + 2√2Rn√(t/n) (74)
≤ 148KBnq/√n Δm + 4√2KBn (Aγ + qAβ + q√q)/aΣ √(t/n) (75)

sử dụng Lemma 13 và Rn = 2KBn(Aγ + qAβ + q√q)/aΣ (76)
≤ 4KBn/√n [37qΔm + √2 (Aγ + qAβ + q√q)/aΣ √t]. (77)
B.2. Chứng minh Lemmas 10–13
Các chứng minh của Lemmas 10–11 yêu cầu một cận trên của uniform norm của gradient
của ln sψ, cho sψ ∈ S. Chúng ta bắt đầu bằng cách cung cấp một cận trên như vậy.
Lemma 14 Cho sψ, như được mô tả trong (3), nó giữ rằng
sup_{x∈X} sup_{ψ∈Ψ̃} ∥∂ln(sψ(·|x))/∂ψ∥∞ ≤ G(·),
G : R^q ∋ y ↦ G(y) = max(AΣ, 1 + KAG)[1 + q√q(∥y∥∞ + Aβ)²AΣ]. (78)

--- TRANG 32 ---
Nguyen Nguyen Chamroukhi McLachlan
Chứng minh Lemma 14. Let sψ ∈ S, với ψ = (γ, β, Σ). Từ bây giờ, chúng ta xem xét bất kỳ
x ∈ X, bất kỳ y ∈ R^q, và bất kỳ k ∈ [K]. Chúng ta có thể viết
ln(sψ(y|x)) = ln(∑_{k=1}^K gk(x;γ)N(y; βk0 + βkx, Σk))
= ln(∑_{k=1}^K fk(x, y)),
gk(x;γ) = exp(wk(x))/∑_{l=1}^K exp(wl(x)), wk(x) = γk0 + γk^⊤x,
N(y; βk0 + βkx, Σk) = 1/((2π)^{q/2} det(Σk)^{1/2}) exp(-(y - (βk0 + βkx))^⊤Σk^{-1}(y - (βk0 + βkx))/2),
fk(x, y) = gk(x;γ)N(y; βk0 + βkx, Σk)
= gk(x;γ)/((2π)^{q/2} det(Σk)^{1/2}) exp(-1/2(y - (βk0 + βkx))^⊤Σk^{-1}(y - (βk0 + βkx))).
Bằng cách sử dụng quy tắc chain, cho tất cả l ∈ [K],
∂ln(sψ(y|x))/∂γl0 = ∑_{k=1}^K fk(x, y)/gk(x;γ) / ∑_{k=1}^K fk(x, y) ∂gk(x;γ)/∂wl(x) ∂wl(x)/∂γl0|_{=1}, và
∂ln(sψ(y|x))/∂(γl^⊤x) = ∑_{k=1}^K fk(x, y)/gk(x;γ) / ∑_{k=1}^K fk(x, y) ∂gk(x;γ)/∂wl(x) ∂wl(x)/∂(γl^⊤x)|_{=1}.
Hơn nữa,
∂gk(x;γ)/∂wl(x) = ∂/∂wl(x) (exp(wk(x))/∑_{l=1}^K exp(wl(x)))
= δlk exp(wk(x))/∑_{l=1}^K exp(wl(x)) - exp(wk(x))/∑_{l=1}^K exp(wl(x)) exp(wl(x))/∑_{l=1}^K exp(wl(x)) = gk(x;γ)(δlk - gl(x;γ)),
nơi δlk = {1 nếu l = k, 0 nếu l ≠ k.
Do đó, chúng ta thu được
∂ln(sψ(y|x))/∂(γl^⊤x) = ∂ln(sψ(y|x))/∂γl0 = ∑_{k=1}^K fk(x, y)/gk(x;γ) / ∑_{k=1}^K fk(x, y) gk(x;γ)(δlk - gl(x;γ))
= ∑_{k=1}^K fk(x, y)/∑_{k=1}^K fk(x, y) (δlk - gl(x;γ)) ≤ ∑_{k=1}^K (δlk - gl(x;γ))
= 1 - ∑_{k=1}^K gl(x;γ) = |1 - Kgl(x;γ)| ≤ 1 + Kgl(x;γ) ≤ 1 + KAG (sử dụng (48)).

--- TRANG 33 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
Tương tự, bằng cách sử dụng thực tế rằng ψ thuộc không gian bị chặn Ψ̃, fl(x, y)/∑_{k=1}^K fk(x, y) ≤
1,
∥∂ln(sψ(y|x))/∂βl0∥∞ = ∥∂ln(sψ(y|x))/∂(βlx)∥∞
= ∥fl(x, y)/∑_{k=1}^K fk(x, y) ∂/∂(βl0 + βlx) (-1/2(y - (βl0 + βlx))^⊤Σl^{-1}(y - (βl0 + βlx)))∥∞
≤ ∥∂/∂(βl0 + βlx) (-1/2(y - (βl0 + βlx))^⊤Σl^{-1}(y - (βl0 + βlx)))∥∞
= ∥Σl^{-1}(y - (βl0 + βlx))∥∞ ≤ ∥Σl^{-1}∥∞∥(y - (βl0 + βlx))∥∞ (sử dụng (95))
≤ √q∥Σl^{-1}∥2(∥y∥∞ + ∥βl0 + βlx∥∞) (sử dụng (100))
≤ √qM(Σl^{-1})(∥y∥∞ + ∥βl0 + βlx∥∞) (sử dụng (99))
≤ √qAΣ(∥y∥∞ + Aβ) (sử dụng (2)).
Bây giờ, chúng ta cần tính gradient w.r.t. các ma trận hiệp phương sai của các chuyên gia Gaussian. Để làm điều này, chúng ta cần kết quả sau: cho bất kỳ l ∈ [K], vl = βl0 + βlx, nó giữ rằng
∂/∂Σl N(x; vl, Σl) = N(x; vl, Σl) 1/2[Σl^{-1}(x - vl)(x - vl)^⊤Σl^{-1} - Σl^{-1⊤}]
|_{T(x,vl,Σl)}, (79)
lưu ý rằng
∂/∂Σl (x - vl)^⊤Σl^{-1}(x - vl) = -Σl^{-1}(x - vl)(x - vl)^⊤Σl^{-1} (sử dụng Lemma 16), (80)
∂/∂Σl (det(Σl)) = det(Σl)Σl^{-1⊤} (sử dụng công thức Jacobi, Lemma 17). (81)
Cho bất kỳ l ∈ [K],
∂ln(sψ(y|x))/∂[Σl]z1,z2 ≤ ∥∂ln(sψ(y|x))/∂Σl∥2 (sử dụng (99))
= fl(x, y)/∑_{k=1}^K fk(x, y) ∥∂/∂Σl (-1/2(y - (βl0 + βlx))^⊤Σl^{-1}(y - (βl0 + βlx)))∥2
≤ ∥∂/∂Σl (-1/2(y - (βl0 + βlx))^⊤Σl^{-1}(y - (βl0 + βlx)))∥2
= 1/2∥Σl^{-1}(y - (βl0 + βlx))(y - (βl0 + βlx))^⊤Σl^{-1} - Σl^{-1⊤}∥2 (sử dụng (79))
≤ 1/2[AΣ + √q∥(y - (βl0 + βlx))(y - (βl0 + βlx))^⊤∥∞A²Σ] (sử dụng (100))
≤ 1/2[AΣ + q√q(∥y∥∞ + Aβ)²A²Σ] (sử dụng (2)),

--- TRANG 34 ---
Nguyen Nguyen Chamroukhi McLachlan
nơi, trong bất đẳng thức cuối cùng cho a = y - (βl0 + βlx), chúng ta sử dụng thực tế rằng
∥aa^⊤∥∞ = max_{1≤i≤q} ∑_{j=1}^q [aa^⊤]i,j = max_{1≤i≤q} ∑_{j=1}^q |aiaj| = max_{1≤i≤q} |ai| ∑_{j=1}^q |aj| ≤ q∥a∥²∞.
Do đó,
sup_{x∈X} sup_{ψ∈Ψ̃} ∥∂ln(sψ(y|x))/∂ψ∥∞
≤ max[1 + KAG, √q(∥y∥∞ + Aβ)AΣ, 1/2[AΣ + q√q(∥y∥∞ + Aβ)²A²Σ]]
≤ max[1 + KAG, max(AΣ, 1)[1 + q√q(∥y∥∞ + Aβ)²AΣ]]
≤ max(AΣ, 1 + KAG)[1 + q√q(∥y∥∞ + Aβ)²AΣ]
=: G(y),
nơi chúng ta sử dụng thực tế rằng
√q(∥y∥∞ + Aβ)AΣ =: θ ≤ 1 + θ² = 1 + q(∥y∥∞ + Aβ)²A²Σ
≤ max(AΣ, 1)[1 + q√q(∥y∥∞ + Aβ)²AΣ].
B.2.1. Chứng minh Lemma 10
Let m ∈ N⋆ và fm ∈ Fm. Bởi (21), tồn tại sm ∈ Sm, sao cho fm = -ln(sm/s0).
Cho tất cả x ∈ X, let ψ(x) = (γk0, γk^⊤x, βk0, βkx, Σk)_{k∈[K]} là các tham số của sm(·|x). Trong
trường hợp của chúng ta, chúng ta xấp xỉ f(ψ) = ln(sψ(yi|xi)) xung quanh ψ0(xi) bởi đa thức Taylor
bậc n = 0 của f(ψ). Nghĩa là,
|ln(sm(yi|xi)) - ln(s0(yi|xi))| =: |f(ψ) - f(ψ0)| = |R0(ψ)| (được định nghĩa trong Lemma 24)
≤ sup_{x∈X} sup_{ψ∈Ψ̃} ∥∂ln(sψ(yi|x))/∂ψ∥∞∥ψ(xi) - ψ0(xi)∥1.

--- TRANG 35 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
Đầu tiên áp dụng bất đẳng thức Taylor và sau đó Lemma 14 trên sự kiện T. Cho tất cả i ∈ [n], nó
giữ rằng
|fm(yi|xi)|IT = |ln(sm(yi|xi)) - ln(s0(yi|xi))|IT ≤ sup_{x∈X} sup_{ψ∈Ψ̃} ∥∂ln(sψ(yi|x))/∂ψ∥∞∥ψ(xi) - ψ0(xi)∥1IT
≤ max(AΣ, 1 + KAG)[1 + q√q(Mn + Aβ)²AΣ]|_{=:Bn} ∥ψ(xi) - ψ0(xi)∥1 (sử dụng Lemma 14)
≤ Bn ∑_{k=1}^K [|γk0 - γ0,k0| + |γk^⊤xi - γ0,k^⊤xi| + ∥βk0 - β0,k0∥1 + ∥βkxi - β0,kxi∥1 + ∥vec(Σk - Σ0,k)∥1]
≤ 2Bn ∑_{k=1}^K [|γk0| + |γk^⊤xi| + ∥βk0∥1 + ∥βkxi∥1 + q∥Σk∥1] (sử dụng (97))
≤ 2KBn(Aγ + q∥βk0∥∞ + q∥βkxi∥∞ + q√q∥Σk∥2) (sử dụng (2), (92), (93), (101))
≤ 2KBn(Aγ + qAβ + q√q)/aΣ (sử dụng (2)).
Do đó, trên sự kiện T,
sup_{fm∈Fm} ∥fm∥∞ ≤ 2KBn(Aγ + qAβ + q√q)/aΣ =: Rn.
B.2.2. Chứng minh Lemma 11
Let m ∈ N⋆, fm^[1] ∈ Fm, và x ∈ [0,1]^p. Bởi (21), tồn tại sm^[1] ∈ Sm, sao cho
fm^[1] = -ln(sm^[1]/s0). Giới thiệu ký hiệu sm^[2] ∈ S và fm^[2] = -ln(sm^[2]/s0). Let
ψ^[1](x) = (γk0^[1], γk^[1]x, βk0^[1], βk^[1]x, Σk^[1])_{k∈[K]}, và ψ^[2](x) = (γk0^[2], γk^[2]x, βk0^[2], βk^[2]x, Σk^[2])_{k∈[K]},
là các tham số của PDFs sm^[1](·|x) và sm^[2](·|x), tương ứng. Bằng cách áp dụng bất đẳng thức Taylor và sau đó Lemma 14 trên sự kiện T, cho tất cả i ∈ [n], nó giữ rằng
|fm^[1](yi|xi) - fm^[2](yi|xi)| = |ln(sm^[1](yi|xi)) - ln(sm^[2](yi|xi))|
≤ sup_{x∈X} sup_{ψ∈Ψ̃} ∥∂ln(sψ(yi|x))/∂ψ∥∞∥ψ^[1](xi) - ψ^[1](xi)∥1 (sử dụng bất đẳng thức Taylor trong Lemma 24)
≤ max(AΣ, C(p, K))[1 + q√q(Mn + Aβ)²AΣ]|_{Bn} ∥ψ^[1](xi) - ψ^[2](xi)∥1 (sử dụng Lemma 14)
≤ Bn ∑_{k=1}^K [|γk0^[1] - γk0^[2]| + |γk^[1]⊤xi - γk^[2]⊤xi|
+ ∥βk0^[1] - βk0^[2]∥1 + ∥βk^[1]xi - βk^[2]xi∥1 + ∥vec(Σk^[1] - Σk^[2])∥1].

--- TRANG 36 ---
Nguyen Nguyen Chamroukhi McLachlan
Bởi bất đẳng thức Cauchy-Schwarz, (∑_{i=1}^m ai)² ≤ m∑_{i=1}^m a²i (m ∈ N⋆), chúng ta có
|fm^[1](yi|xi) - fm^[2](yi|xi)|²
≤ 3B²n[(∑_{k=1}^K |γk^[1]⊤xi - γk^[2]⊤xi|)² + (∑_{k=1}^K ∑_{z=1}^q |[βk^[1]xi]z - [βk^[2]xi]z|)²]
+ 3B²n[∥β0^[1] - β0^[2]∥1 + ∥γ0^[1] - γ0^[2]∥1 + ∥vec(Σ^[1] - Σ^[2])∥1]²
≤ 3B²n[K∑_{k=1}^K (∑_{j=1}^p γkj^[1]xij - ∑_{j=1}^p γkj^[2]xij)² + Kq∑_{k=1}^K ∑_{z=1}^q (∑_{j=1}^p [βk^[1]]z,j xij - ∑_{j=1}^p [βk^[2]]z,j xij)²]
+ 3B²n[∥β0^[1] - β0^[2]∥1 + ∥γ0^[1] - γ0^[2]∥1 + ∥vec(Σ^[1] - Σ^[2])∥1]²,
và
∥fm^[1] - fm^[2]∥²n = 1/n ∑_{i=1}^n |fm^[1](yi|xi) - fm^[2](yi|xi)|²
≤ 3B²nK∑_{k=1}^K 1/n ∑_{i=1}^n (∑_{j=1}^p γkj^[1]xij - ∑_{j=1}^p γkj^[2]xij)²|_{=:a}
+ 3B²nKq∑_{k=1}^K ∑_{z=1}^q 1/n ∑_{i=1}^n (∑_{j=1}^p [βk^[1]]z,j xij - ∑_{j=1}^p [βk^[2]]z,j xij)²|_{=:b}
+ 3B²n[∥β0^[1] - β0^[2]∥1 + ∥γ0^[1] - γ0^[2]∥1 + ∥vec(Σ^[1] - Σ^[2])∥1]².
Vì vậy, cho tất cả δ > 0, nếu
a ≤ δ²/(36B²n), b ≤ δ²/(36B²n), ∥β0^[1] - β0^[2]∥1 ≤ δ/(18Bn), ∥γ0^[1] - γ0^[2]∥1 ≤ δ/(18Bn), và ∥vec(Σ^[1] - Σ^[2])∥1 ≤ δ/(18Bn),
thì ∥fm^[1] - fm^[2]∥²n ≤ δ²/4. Để chặn a và b, chúng ta có thể viết
a = Km² ∑_{k=1}^K 1/n ∑_{i=1}^n (∑_{j=1}^p γkj^[1]/m xij - ∑_{j=1}^p γkj^[2]/m xij)², và
b = Kqm² ∑_{k=1}^K ∑_{z=1}^q 1/n ∑_{i=1}^n (∑_{j=1}^p [βk^[1]]z,j/m xij - ∑_{j=1}^p [βk^[2]]z,j/m xij)².

--- TRANG 37 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
Sau đó, chúng ta áp dụng Lemma 12 để thu được γk,.^[1]/m = (γkj^[1]/m)_{j∈[q]} và [βk^[1]]z,./m = ([βk^[1]]z,j/m)_{j∈[q]},
cho tất cả k ∈ [K], z ∈ [q]. Vì sm^[1] ∈ Sm, và sử dụng (12), chúng ta có
∥γk^[1]∥ ≤ m và ∥vec(βk^[1])∥1 ≤ m, điều này dẫn đến ∑_{j=1}^p |γkj^[1]|/m ≤ 1 và ∑_{z=1}^q ∑_{j=1}^p |[βk^[1]]z,j|/m ≤ 1, tương
ứng. Hơn nữa, cho x ∈ X = [0,1]^p, chúng ta có ∥x∥²_{max,n} = 1. Do đó, tồn tại các họ
A của (2p + 1)^{36B²nK²m²/δ²} vectors và B của (2p + 1)^{16B²nq²K²m²/δ²} vectors của R^p, sao cho
cho tất cả k ∈ [K], z ∈ [q], γk,.^[1], và [βk^[1]]z,., tồn tại γk,.^[1] ∈ A và [βk^[2]]z,. ∈ B, sao cho
1/n ∑_{i=1}^n (∑_{j=1}^p γkj^[1]/m xij - ∑_{j=1}^p γkj^[2]/m xij)² ≤ δ²/(36B²nK²m²), và
1/n ∑_{i=1}^n (∑_{j=1}^p [βk^[1]]z,j/m xij - ∑_{j=1}^p [βk^[2]]z,j/m xij)² ≤ δ²/(36B²nq²K²m²),
điều này dẫn đến a ≤ δ²/(36B²n) và b ≤ δ²/(36B²n). Hơn nữa, (2) dẫn đến
∥β0^[1]∥1 = ∑_{k=1}^K ∥β0k^[1]∥1 ≤ Kq∥β0k^[1]∥∞ ≤ KqAβ (sử dụng (92)),
∥γ0^[1]∥1 = ∑_{k=1}^K |γ0k^[1]| ≤ KAγ,
∥vec(Σ^[1])∥1 ≤ Kq√q/aΣ.
Do đó, trên sự kiện T,
M(δ, Fm, ∥·∥n) ≤ N(δ/2, Fm, ∥·∥n) (sử dụng Lemma 22)
≤ card(A)card(B)N(δ/(18Bn), BK_1(KqAβ), ∥·∥1)
× N(δ/(18Bn), BK_1(KAγ), ∥·∥1)N(δ/(18Bn), BK_1(Kq√q/aΣ), ∥·∥1)
≤ (2p + 1)^{72B²nq²K²m²/δ²} [1 + 18BnKqAβ/(δK)]^K [1 + 18BnKAγ/(δK)]^K [1 + 18BnKq√q/(aΣδK)]^K.
B.2.3. Chứng minh Lemma 13
Let m ∈ N⋆. Từ Lemma 10, trên sự kiện T, nó giữ rằng
sup_{fm∈Fm} ∥fm∥n ≤ 2KBn(Aγ + qAβ + q√q)/aΣ =: Rn. (82)

--- TRANG 38 ---
Nguyen Nguyen Chamroukhi McLachlan
Từ Lemma 11, trên sự kiện T cho tất cả S ∈ N⋆, với δ = 2^{-s}Rn,
∑_{s=1}^S 2^{-s}√(ln[1 + M(2^{-s}Rn, Fm, ∥·∥n)]) ≤ ∑_{s=1}^S 2^{-s}√(ln[2M(δ, Fm, ∥·∥n)])
≤ ∑_{s=1}^S 2^{-s}[√(ln 2) + 6√2BnqKm/(δ)√(ln(2p + 1))
+ √K ln((1 + 18BnKqAβ/δ)(1 + 18BnKAγ/δ)(1 + 18BnKq√q/(aΣδ)))]
≤ ∑_{s=1}^S 2^{-s}[√(ln 2) + 2^s 6√2BnqKm/Rn √(ln(2p + 1))
+ √K ln((1 + 2^s 18BnKqAβ/Rn)(1 + 2^s 18BnKAγ/Rn)(1 + 2^s 18BnKq√q/(aΣRn)))].
(83)
Lưu ý từ (82), rằng Rn ≥ 2KBn max{Aγ, qAβ, q√q/aΣ}. Hơn nữa, nó giữ rằng 1 ≤ 2^s + 3,
và ∑_{s=1}^S 2^{-s} = 1 - 2^{-S} ≤ 1, ∑_{s=1}^S (√e/2)^s ≤ √e/(2 - √e), và vì cho tất cả s ∈ N⋆, e^s ≥ s,
và do đó 2^{-s}√s ≤ (√e/2)^s. Do đó, từ (83):
∑_{s=1}^S 2^{-s}√(ln[1 + M(2^{-s}Rn, Fm, ∥·∥n)])
≤ ∑_{s=1}^S 2^{-s}[√(ln 2) + 2^s 6√2BnqKm/Rn √(ln(2p + 1)) + √K√3((s + 1)ln 2 + 2ln 3)]
= ∑_{s=1}^S 2^{-s}[√(ln 2) + 2^s 6√2BnqKm/Rn √(ln(2p + 1)) + √K√3ln 2((s + 1)ln 2 + 2ln 3)]
≤ 6√2BnKqm/Rn √(ln(2p + 1))S + √K√3ln 2 ∑_{s=1}^S 2^{-s}√s + √(ln 2)[1 + √3K] + √(6ln 3K)
≤ 6√2BnKqm/Rn √(ln(2p + 1))S + √K√3ln 2 ∑_{s=1}^S (√e/2)^s + √(ln 2)[1 + √3K] + √(6ln 3K)
≤ 6√2BnKqm/Rn √(ln(2p + 1))S + √K ln 2√(3e/(2 - √e)) + [1 + √3 + √(6ln 3/ln 2)]√K
|_{=:C1}. (84)

--- TRANG 39 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
Sau đó, cho tất cả S ∈ N⋆, trên sự kiện T:
E[sup_{fm∈Fm} 1/n ∑_{i=1}^n εifm(Zi)]
= E[sup_{fm∈Fm} 1/n ∑_{i=1}^n εifm(Zi)I_{|fm(Zi)|≤Rn}] (sử dụng Lemma 10)
= E[sup_{f∈F} 1/n ∑_{i=1}^n εif(Zi)]
≤ Rn[6/√n ∑_{s=1}^S 2^{-s}√(ln[1 + M(2^{-s}Rn, F, ∥·∥n)]) + 2^{-S}] (sử dụng Lemma 9)
≤ Rn[6/√n (6√2BnKmq/Rn √(ln(2p + 1))S + √K ln 2C1) + 2^{-S}] (sử dụng Lemma 84).
(85)
Chúng ta chọn S = ln n/ln 2 để hai điều khoản phụ thuộc vào S trong (85) có cùng bậc.
Đặc biệt, cho giá trị này của S, 2^{-S} ≤ 1/n, và chúng ta suy ra từ (85) và (82) rằng trên
sự kiện T,
E[sup_{fm∈Fm} 1/n ∑_{i=1}^n εifm(Zi)]
≤ 36√2BnKmq√n √(ln(2p + 1))ln n/ln 2 + 2KBn(Aγ + qAβ + q√q)/aΣ [6√(ln 2)C1√K/√n + 1/n]
≤ BnKmq√n √(ln(2p + 1))ln n 36√2/ln 2|_{≈73.45} + K√K/√n Bn(Aγ + qAβ + q√q)/aΣ 2[6√(ln 2)C1 + 1]|_{≈141.32}
< 74KBn/√n [mq√(ln(2p + 1))ln n + 2√K (Aγ + qAβ + q√q)/aΣ].
B.3. Chứng minh Lemma 6
Vì ln(z) là concave trong z, bất đẳng thức Jensen (xem ví dụ Jensen (1906); Cover (1999)) ngụ ý
rằng ln(E_Z[Z]) ≥ E_Z[ln(Z)], nơi Z là một biến ngẫu nhiên. Do đó, cho tất cả x ∈ X, bất đẳng thức Jensen và Lemma 15 dẫn chúng ta đến cận trên sau
∫_{R^q} ln(s0(y|x))s0(y|x)dy ≤ ∑_{k=1}^K gk(x;γ0)ln ∫_{R^q} s0(y|x)N(y; v0k(x), Σ0k)dy
≤ ∑_{k=1}^K gk(x;γ0)ln[∑_{l=1}^K gl(x;γ0)Cs0]
= ln Cs0 < ∞,
nơi Cs0 = (4π)^{-q/2}A^{q/2}_Σ, (sử dụng Lemma 15). (86)
Do đó, chúng ta thu được
max{0, sup_{x∈X} ∫_{R^q} ln(s0(y|x))s0(y|x)dy} ≤ max{0, ln Cs0} =: Hs0 < ∞.
Tiếp theo, chúng tôi trình bày Lemma 15 quan trọng sau, được sử dụng trong chứng minh của Lemma 6.

--- TRANG 40 ---
Nguyen Nguyen Chamroukhi McLachlan
Lemma 15 Tồn tại một hằng số dương Cs0 := (4π)^{-q/2}A^{q/2}_Σ, 0 < Cs0 < ∞, sao cho
cho tất cả k ∈ [K], l ∈ [L],
∫_{R^q} N(y; v0l(x), Σ0l)N(y; v0k(x), Σ0k)dy < Cs0, ∀x ∈ X. (87)
Chứng minh Lemma 15. Đầu tiên, cho tất cả k ∈ [K], l ∈ [L], cho
clk(x) = ClkΣ0l^{-1}v0l(x) + Σ0k^{-1}v0k(x), Clk = (Σ0l^{-1} + Σ0k^{-1})^{-1},
Lemma 25 dẫn đến
∫_{R^q} [N(y; v0l(x), Σ0l)N(y; v0k(x), Σ0k)]dy = Z_{lk}^{-1} ∫_{R^q} N(y; clk(x), Clk)dy |_{=1}, nơi
= (2π)^{-q/2} det(Σ0l + Σ0k)^{-1/2} exp(-1/2(v0l(x) - v0k(x))^⊤(Σ0l + Σ0k)^{-1}(v0l(x) - v0k(x)))
(88)
Tiếp theo, vì determinant là tích của các eigenvalues, được đếm với bội số, và
bất đẳng thức Weyl, xem ví dụ, Lemma 26, cho tất cả k ∈ [K], l ∈ [L], chúng ta có
det(Σ0l + Σ0k) ≥ [m(Σ0l + Σ0k)]^q
≥ [m(Σ0l) + m(Σ0k)]^q (sử dụng (108) từ Lemma 26)
= [M(Σ0l^{-1})^{-1} + M(Σ0k^{-1})^{-1}]^q
≥ (2A_Σ^{-1})^q (sử dụng các giả định tính bị chặn trong (2)).
Do đó, cho tất cả k ∈ [K], l ∈ [L], nó giữ rằng
det(Σ0l + Σ0k)^{-1/2} ≤ 2^{-q/2}(A_Σ)^{q/2} (sử dụng các giả định tính bị chặn trong (2)). (89)
Vì (Σ0l + Σ0k)^{-1} là một ma trận định dương, nó giữ rằng
(v0l(x) - v0k(x))^⊤(Σ0l + Σ0k)^{-1}(v0l(x) - v0k(x)) ≥ 0, ∀x ∈ X, l ∈ [L], k ∈ [K].
Sau đó, vì hàm mũ đang tăng, ∀x ∈ X, l ∈ [L], k ∈ [K], chúng ta có
exp(-1/2(v0l(x) - v0k(x))^⊤(Σ0l + Σ0k)^{-1}(v0l(x) - v0k(x))) ≤ exp(0) = 1. (90)
Cuối cùng, từ (88), (89) và (90), chúng ta thu được
∫_{R^q} [N(y; v0l(x), Σ0l)N(y; v0k(x), Σ0k)]dy ≤ (2π)^{-q/2}2^{-q/2}A^{q/2}_Σ = (4π)^{-q/2}A^{q/2}_Σ =: Cs0 < ∞.

--- TRANG 41 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
Phụ lục C. Kết quả kỹ thuật thêm
Chúng tôi ký hiệu không gian vector của tất cả các ma trận thực q-by-q bởi R^{q×q} (q ∈ N⋆):
A ∈ R^{q×q} ⟺ A = (ai,j) = [a1,1 ··· a1,q; ...; aq,1 ··· aq,q], ai,j ∈ R.
Nếu một chữ cái viết hoa được sử dụng để ký hiệu một ma trận (ví dụ, A, B), thì chữ cái
viết thường tương ứng với chỉ số i, j đề cập đến phần tử (i, j)th (ví dụ, ai,j, bi,j). Khi
cần thiết, chúng tôi cũng chỉ định các phần tử của một ma trận với ký hiệu [A]i,j hoặc A(i, j).
Ký hiệu các ma trận đơn vị và không q-by-q bởi Iq và 0q, tương ứng.
Lemma 16 (Đạo hàm của dạng bậc hai, cf., Magnus và Neudecker (2019))
Giả sử rằng X và a là ma trận không kỳ dị trong R^{q×q} và vector trong R^{q×1}, tương ứng.
Sau đó
∂a^⊤X^{-1}a/∂X = -X^{-1}aa^⊤X^{-1}.
Lemma 17 (Công thức Jacobi, cf., Định lý 8.1 từ Magnus và Neudecker (2019))
Nếu X là một ánh xạ khả vi từ số thực đến các ma trận q-by-q,
d/dt det(X(t)) = tr(Adj(X(t))dX(t)/dt), ∂det(X)/∂X = (Adj(X))^⊤ = det(X)(X^{-1})^⊤.
Lemma 18 (Operator induced p-norm) Chúng tôi nhớ lại operator (induced) p-norms của một
ma trận A ∈ R^{q×q} (q ∈ N⋆, p ∈ {1, 2, ∞}),
∥A∥p = max_{x≠0} ∥Ax∥p/∥x∥p = max_{x≠0} ∥A(x/∥x∥p)∥p = max_{∥x∥p=1} ∥Ax∥p, (91)
nơi cho tất cả x ∈ R^q,
∥x∥∞ ≤ ∥x∥1 = ∑_{i=1}^q |xi| ≤ q∥x∥∞, (92)
∥x∥2 = (∑_{i=1}^q |xi|²)^{1/2} = (x^⊤x)^{1/2} ≤ ∥x∥1 ≤ √q∥x∥2, và (93)
∥x∥∞ = max_{1≤i≤q} |xi| ≤ ∥x∥2 ≤ √q∥x∥∞. (94)
Lemma 19 (Một số tính chất matrix p-norm, Golub và Van Loan (2012)) Bởi định
nghĩa, chúng ta luôn có tính chất quan trọng rằng cho mọi A ∈ R^{q×q} và x ∈ R^q,
∥Ax∥p ≤ ∥A∥p∥x∥p, (95)

--- TRANG 42 ---
Nguyen Nguyen Chamroukhi McLachlan
và mỗi induced p-norm là submultiplicative, tức là, cho mọi A ∈ R^{q×q} và B ∈ R^{q×q},
∥AB∥p ≤ ∥A∥p∥B∥p. (96)
Đặc biệt, nó giữ rằng
∥A∥1 = max_{1≤j≤q} ∑_{i=1}^q |aij| ≤ ∑_{j=1}^q ∑_{i=1}^q |aij| := ∥vec(A)∥1 ≤ q∥A∥1, (97)
∥vec(A)∥∞ := max_{1≤i≤q,1≤j≤q} |aij| ≤ ∥A∥∞ = max_{1≤j≤q} ∑_{i=1}^q |aij| ≤ q∥vec(A)∥∞, (98)
∥vec(A)∥∞ ≤ ∥A∥2 = λ_{max}(A) ≤ q∥vec(A)∥∞, (99)
nơi λ_{max} là eigenvalue lớn nhất của một ma trận đối xứng định dương A. Các p-norms,
khi p ∈ {1, 2, ∞}, thỏa mãn
1/√q ∥A∥∞ ≤ ∥A∥2 ≤ √q∥A∥∞, (100)
1/√q ∥A∥1 ≤ ∥A∥2 ≤ √q∥A∥1. (101)
Cho δ > 0, chúng ta cần định nghĩa δ-packing number và δ-covering number.
Định nghĩa 20 (δ-packing number, cf., Định nghĩa 5.4 từ Wainwright (2019))
Let (F, ∥·∥) là một không gian normed và let G ⊂ F. Với (gi)_{i=1,...,m} ∈ G, {g1, . . . , gm} là một
δ-packing của G có kích thước m ∈ N⋆, nếu ∥gi - gj∥ > δ, ∀i ≠ j, i, j ∈ {1, . . . , m}, hoặc tương đương, ∩_{i=1}^n B(gi, δ/2) = ∅. Khi định nghĩa δ-packing, chúng ta có thể đo số lượng tối đa của
các quả cầu đóng disjoint với bán kính δ/2 có thể được "packed" vào G. Số này được gọi là
δ-packing number và được định nghĩa là
M(δ, G, ∥·∥) := max{m ∈ N⋆ : ∃δ-packing của G có kích thước m}. (102)
Định nghĩa 21 (δ-covering number, cf., Định nghĩa 5.1 từ Wainwright (2019))
Let (F, ∥·∥) là một không gian normed và let G ⊂ F. Với (gi)_{i∈[n]} ∈ G, {g1, . . . , gn} là một δ-
covering của G có kích thước n nếu G ⊂ ∪_{i=1}^n B(gi, δ), hoặc tương đương, ∀g ∈ G, ∃i sao cho ∥g - gi∥ ≤ δ.
Khi định nghĩa δ-covering, chúng ta có thể đo số lượng tối thiểu của các quả cầu đóng với bán kính
δ, cần thiết để cover G. Số này được gọi là δ-covering number và được định nghĩa là
N(δ, G, ∥·∥) := min{n ∈ N⋆ : ∃δ-covering của G có kích thước n}. (103)
Covering entropy (metric entropy) được định nghĩa như sau H_{∥·∥}(δ, G) = ln(N(δ, G, ∥·∥)).
Mối quan hệ giữa packing number và covering number được mô tả trong lemma sau.
Lemma 22 (Lemma 5.5 từ Wainwright (2019)) Let (F, ∥·∥) là một không gian normed và
let G ⊂ F. Sau đó
M(2δ, G, ∥·∥) ≤ N(δ, G, ∥·∥) ≤ M(δ, G, ∥·∥).

--- TRANG 43 ---
Bất đẳng thức oracle không tiệm cận cho Lasso trong MoE đa chiều cao
Lemma 23 (Bất đẳng thức Chernoff, ví dụ, Chương 2 trong Wainwright (2019)) Giả sử
rằng biến ngẫu nhiên có một hàm sinh moment trong một lân cận của không, có nghĩa là có
một số hằng số b > 0 sao cho hàm φ(λ) = E[e^{λ(U-μ)}] tồn tại cho tất cả λ ≤ |b|. Trong
trường hợp như vậy, chúng ta có thể áp dụng bất đẳng thức Markov cho biến ngẫu nhiên
Y = e^{λ(U-μ)}, do đó thu được cận trên
P(U - μ ≥ a) = P(e^{λ(U-μ)} ≥ e^{λt}) ≤ E[e^{λ(U-μ)}]/e^{λt}.
Tối ưu hóa lựa chọn λ của chúng ta để thu được kết quả chặt chẽ nhất cho ra cận Chernoff
ln(P(U - μ ≥ a)) ≤ sup_{λ∈[0,b]} {λt - ln(E[e^{λ(U-μ)}])}. (104)
Đặc biệt, nếu U ~ N(μ, σ) là một biến ngẫu nhiên Gaussian với trung bình μ và phương sai σ².
Bằng một tính toán đơn giản, chúng ta thấy rằng U có hàm sinh moment
E[e^{λU}] = e^{μλ+σ²λ²/2}, có hiệu lực cho tất cả λ ∈ R.
Thay thế biểu thức này vào bài toán tối ưu hóa định nghĩa cận Chernoff tối ưu hóa (104), chúng ta thu được
sup_{λ≥0} {λt - ln(E[e^{λ(U-μ)}])} = sup_{λ≥0} {λt - σ²λ²/2} = -t²/(2σ²),
nơi chúng ta đã lấy đạo hàm để tìm điểm tối ưu của hàm bậc hai này. Vì vậy,
(104) dẫn đến
P(X ≥ μ + t) ≤ e^{-t²/(2σ²)}, cho tất cả t ≥ 0. (105)
Nhớ lại rằng một multi-index α = (α1, . . . , αp), αi ∈ N⋆, ∀i ∈ {1, . . . , p} là một p-tuple của
các số nguyên không âm. Let
|α| = ∑_{i=1}^p αi, α! = ∏_{i=1}^p αi!, x^α = ∏_{i=1}^p x_i^{αi}, x ∈ R^p, ∂^α f = ∂_{∂^{α1}_1 ∂^{α2}_2 ··· ∂^{αp}_p} = ∂^{|α|} f/(∂x_1^{α1} ∂x_2^{α2} ··· ∂x_p^{αp}).
Số |α| được gọi là order hoặc degree của α. Do đó, order của α giống như order của x^α như một
monomial hoặc order của ∂^α như một đạo hàm riêng.
Lemma 24 (Định lý Taylor đa biến từ Duistermaat và Kolk (2004))
Giả sử f : R^p → R thuộc lớp C^{k+1}, của các hàm khả vi liên tục, trên một tập convex mở S. Nếu a ∈ S và a + h ∈ S, thì
f(a + h) = ∑_{|α|≤k} ∂^α f(a)/α! h^α + R_{a,k}(h),
nơi phần dư được cho ở dạng Lagrange bởi
R_{a,k}(h) = ∑_{|α|=k+1} ∂^α f(a + ch) h^α/α! cho một số c ∈ (0,1),

--- TRANG 44 ---
Nguyen Nguyen Chamroukhi McLachlan
hoặc ở dạng tích phân bởi
R_{a,k}(h) = (k + 1) ∑_{|α|=k+1} h^α/α! ∫_0^1 (1-t)^k ∂^α f(a + th)dt.
Đặc biệt, chúng ta có thể ước lượng điều khoản dư nếu |∂^α f(x)| ≤ M cho x ∈ S và |α| = k + 1,
|R_{a,k}(h)| ≤ M/(k + 1)! ∥h∥_1^{k+1}, ∥h∥_1 = ∑_{i=1}^p |hi|.
Nhớ lại rằng phân phối Gaussian đa biến (hoặc Normal) có mật độ chung được cho bởi
N(y; μ; Σ) = (2π)^{-q/2} det(Σ)^{-1/2} exp(-1/2(y - μ)^⊤Σ^{-1}(y - μ)), (106)
nơi μ là vector trung bình (có độ dài q) và Σ là ma trận hiệp phương sai đối xứng, định dương
(có kích thước q × q). Sau đó, chúng ta có đồng nhất Gaussian nổi tiếng sau, xem thêm trong
Lemma 25, được chứng minh trong Phương trình (A.7) từ Williams và Rasmussen (2006).
Lemma 25 (Tích của hai Gaussians) Tích của hai Gaussians cho một Gaussian khác
(không chuẩn hóa)
N(y; a, A)N(y; b, B) = Z^{-1}N(y; c, C), nơi, (107)
c = C(A^{-1}a + B^{-1}b) và C = (A^{-1} + B^{-1})^{-1},
Z^{-1} = (2π)^{-q/2} det(A + B)^{-1/2} exp(-1/2(a - b)^⊤(A + B)^{-1}(a - b)).
Chúng tôi nhớ lại bất đẳng thức sau của Hermann Weyl, xem ví dụ Horn và Johnson (2012,
Định lý 4.3.1)
Lemma 26 (Bất đẳng thức Weyl) Let A, B ∈ R^{q×q} là Hermitian và let các eigenvalues tương ứng của A, B, và A + B là {λi(A)}_{i∈[q]}, {λi(B)}_{i∈[q]}, và {λi(A + B)}_{i∈[q]}, mỗi cái được sắp xếp theo thứ tự đại số không giảm như:
m(A) = λ1(A) ≤ λ2(A) ≤ . . . ≤ λq(A) = M(A).
Sau đó, cho mỗi i ∈ [q],
λi(A + B) ≤ λ_{i+j}(A) + λ_{q-j}(B), j ∈ {0} ∪ [q - i], λ_{i-j+1}(A) + λj(B) ≤ λi(A + B), j ∈ [i].
Đặc biệt, chúng ta có
M(A + B) ≤ M(A) + M(B), m(A + B) ≥ m(A) + m(B). (108)

# 2306.03900.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/moe/2306.03900.pdf
# Kích thước tệp: 5124778 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
MODEL SPIDER : Học cách Xếp hạng
Các Mô hình Được Huấn luyện Trước một cách Hiệu quả
Yi-Kai Zhang1, Ting-Ji Huang1, Yao-Xiang Ding2, De-Chuan Zhan1, Han-Jia Ye1,B
1Phòng thí nghiệm Trọng điểm Quốc gia về Công nghệ Phần mềm Mới, Đại học Nam Kinh
2Phòng thí nghiệm Trọng điểm Quốc gia về CAD & CG, Đại học Chiết Giang
{zhangyk,huangtj,zhandc,yehj}@lamda.nju.edu.cn yxding@zju.edu.cn
Tóm tắt
Việc xác định Mô hình Được Huấn luyện Trước (PTM) nào từ kho mô hình phù hợp với nhiệm vụ đích là điều cần thiết để tận dụng các nguồn lực mô hình phong phú. Với sự sẵn có của nhiều PTM không đồng nhất từ các lĩnh vực đa dạng, việc lựa chọn PTM phù hợp nhất một cách hiệu quả là thách thức do chi phí tốn thời gian của việc thực hiện các lượt truyền tiến hoặc lùi qua tất cả PTM. Trong bài báo này, chúng tôi đề xuất MODEL SPIDER, tokenizes cả PTM và nhiệm vụ bằng cách tóm tắt đặc điểm của chúng thành các vector để cho phép lựa chọn PTM hiệu quả. Bằng cách tận dụng hiệu suất xấp xỉ của PTM trên một tập hợp riêng các nhiệm vụ huấn luyện, MODEL SPIDER học cách xây dựng token và đo điểm số phù hợp giữa cặp mô hình-nhiệm vụ thông qua token của chúng. Khả năng xếp hạng PTM liên quan cao hơn những PTM khác có thể tổng quát hóa cho các nhiệm vụ mới. Với các ứng viên PTM xếp hạng cao, chúng tôi tiếp tục học cách làm giàu token nhiệm vụ với ngữ nghĩa đặc thù PTM của chúng để xếp hạng lại PTM để lựa chọn tốt hơn. MODEL SPIDER cân bằng hiệu quả và khả năng lựa chọn, làm cho việc lựa chọn PTM giống như một con nhện săn mồi trên mạng. MODEL SPIDER thể hiện hiệu suất đầy hứa hẹn trong các cấu hình khác nhau của kho mô hình.

1 Giới thiệu
Tinh chỉnh Mô hình Được Huấn luyện Trước (PTM) trên các nhiệm vụ hạ nguồn đã cho thấy những cải tiến đáng kể trong các lĩnh vực khác nhau [28,20,59,34], làm cho "huấn luyện trước → tinh chỉnh" trở thành mô hình thực tế trong nhiều ứng dụng thực tế. Một kho mô hình chứa các PTM đa dạng trong kiến trúc và chức năng của chúng [1,11], nhưng một PTM được chọn ngẫu nhiên làm cho tính hữu ích của chúng cho một nhiệm vụ hạ nguồn cụ thể thay đổi không thể dự đoán [63,55,77]. Một bước quan trọng để tận dụng nguồn lực PTM là xác định PTM hữu ích nhất trong kho mô hình — ước tính và xếp hạng khả năng chuyển giao của PTM — với dữ liệu của nhiệm vụ hạ nguồn một cách chính xác và hiệu quả.

PTM nào là hữu ích nhất? Một câu trả lời trực tiếp là liệt kê tất cả PTM và đánh giá hiệu suất của các mô hình được tinh chỉnh tương ứng. Tuy nhiên, chi phí tính toán cao của các bước lùi trong tinh chỉnh làm cho giải pháp này không thực tế. Một số phương pháp hiện có ước tính proxy của khả năng chuyển giao chỉ với các lượt truyền tiến dựa trên các đặc trưng của nhiệm vụ đích được trích xuất bởi PTM [8,73,53,45,83,21,56,19,72]. Ngày nay, một kho mô hình công khai thường chứa hàng trăm và hàng nghìn PTM [79]. Khi đó, gánh nặng tính toán của các lượt truyền tiến sẽ được khuếch đại, chưa nói đến các lượt truyền tiến tốn thời gian của một số PTM phức tạp. Do đó, hiệu quả của việc tìm kiếm PTM hữu ích và ước tính khả năng chuyển giao cần được nhấn mạnh hơn nữa.

Trong bài báo này, chúng tôi đề xuất MODEL SPIDER, SPecification InDuced Expression and Ranking of PTMs, cho việc lựa chọn PTM chính xác và hiệu quả. Cụ thể, chúng tôi tokenize tất cả PTM và nhiệm vụ thành các vector nắm bắt các tính chất chung và mối quan hệ với nhau. Ví dụ, hai mô hình được huấn luyện trước trên bộ dữ liệu NABirds [30] và Caltech-UCSD Birds [76] có thể có khả năng tương tự

--- TRANG 2 ---
3
 3
 3
2
 2
 2
Nhiệm vụ
(a) Lựa chọn Mô hình Dựa trên Forward và Dựa trên Token/Specification (b) So sánh khả năng lựa chọn & Hiệu quả
…
Truyền tiến từng Mô hình được Huấn luyện Trước
Xếp hạng Khả năng Chuyển giao
Trích xuất Đặc trưng & Logits
1…
1
 1
Token Được Học
Đo lường Độ tương tự
× 2=
Nhiệm vụ
Kho Mô hình w/o forward
Xếp hạng Khả năng Chuyển giao
Tương quan (𝝉𝝉𝒘𝒘)
Thời gian (bội số tăng tốc)
𝓝𝓝-LEEP
1x 5x 50x0.40.50.6
𝑘𝑘=0𝑘𝑘=3𝑘𝑘=36𝑘𝑘=42
H-Score
NCE
0.7
LEEP
40x𝑘𝑘=6
MODEL SPIDER (Của chúng tôi)
LogME
…
𝒯𝒯1𝒯𝒯2𝒯𝒯3𝒯𝒯1𝒯𝒯2𝒯𝒯3
Xếp hạng 2

Hình 1: (a) Hai chiến lược lựa chọn PTM. Các công trình liên quan sử dụng các đặc trưng dựa trên forward và các proxy tương ứng trên tập dữ liệu đích để đánh giá khả năng chuyển giao. Phương pháp dựa trên token/specification với token mô hình-nhiệm vụ được học giảm yêu cầu truyền tiến qua từng PTM. (b) So sánh hiệu quả trung bình (thời gian thực) so với hiệu suất (tương quan τw, càng cao càng tốt) của việc lựa chọn PTM trên các tập dữ liệu khác nhau. Kích thước vòng tròn cho biết dung lượng bộ nhớ. Các vòng tròn đỏ là MODEL SPIDER với các giá trị khác nhau của số lượng đặc trưng đặc thù PTM k, trong khi các vòng tròn khác là các phương pháp so sánh. MODEL SPIDER cân bằng tốt giữa hiệu quả và độ chính xác.

trong nhận dạng chim, để chúng ta có thể liên kết chúng với các token tương tự. Khi đó, khả năng chuyển giao từ PTM đến nhiệm vụ có thể được xấp xỉ bằng khoảng cách của token của chúng mà không cần truyền tiến qua từng PTM trên nhiệm vụ hạ nguồn. Thành công của MODEL SPIDER phụ thuộc vào hai yếu tố chính. Thứ nhất, làm thế nào để có được token cho nhiệm vụ và PTM? Token của PTM hữu ích nhất nên gần với token nhiệm vụ đối với một số biện pháp độ tương tự. Thứ hai, liệu token nhiệm vụ tổng quát có làm suy yếu khả năng lựa chọn vì nó có thể bỏ qua các đặc điểm cụ thể của PTM?

Trong MODEL SPIDER, chúng tôi học cách xây dựng token với một bộ mã hóa tổng quát và đo lường độ tương tự giữa các token với một mô-đun Transformer [74] theo cách học có giám sát. Chúng tôi ước tính thứ hạng của PTM trong kho mô hình cho một số nhiệm vụ lịch sử sử dụng tổng hợp thứ hạng. Bằng cách tận dụng giám sát xấp xỉ, chúng tôi kéo token nhiệm vụ gần với token PTM xếp hạng cao và đẩy token PTM không hữu ích ra xa dựa trên độ tương tự được đo bằng transformer. Chúng tôi mong đợi rằng khả năng tokenize và đo lường độ tương tự có thể được tổng quát hóa cho các nhiệm vụ chưa thấy. Sự khác biệt giữa việc lựa chọn PTM dựa trên token của MODEL SPIDER với chiến lược dựa trên forward được minh họa trong Hình 1.

Các token được tạo bởi bộ mã hóa tổng quát làm giảm đáng kể thời gian tìm kiếm PTM và cải thiện hiệu suất tìm kiếm. Nếu ngân sách cho phép, chúng ta có thể trích xuất các đặc trưng của nhiệm vụ hạ nguồn bằng cách thực hiện các lượt truyền tiến qua một phần (k PTM xếp hạng cao nhất), tiết lộ mối quan hệ cụ thể giữa PTM và nhiệm vụ. Chúng tôi trang bị MODEL SPIDER với khả năng kết hợp các token đặc thù PTM, việc xếp hạng lại PTM và cải thiện thêm kết quả lựa chọn. Tóm lại, MODEL SPIDER phù hợp với các yêu cầu ngân sách khác nhau, trong đó các token tổng quát và đặc thù nhiệm vụ tạo ra sự cân bằng linh hoạt giữa hiệu quả và độ chính xác, với các lượt truyền tiến khác nhau. Hình 1 minh họa so sánh các phương pháp lựa chọn PTM về cả hiệu quả và độ chính xác. Đóng góp của chúng tôi là:

• Chúng tôi đề xuất một phương pháp mới MODEL SPIDER để tokenize nhiệm vụ và PTM, có khả năng xếp hạng PTM trong kho mô hình với một nhiệm vụ hạ nguồn một cách hiệu quả và chính xác.

• MODEL SPIDER học cách tokenize và xếp hạng PTM trên một tập hợp riêng các nhiệm vụ huấn luyện, và nó có thể kết hợp kết quả forward đặc thù nhiệm vụ của một số PTM khi ngân sách nguồn lực cho phép.

• Các thí nghiệm chứng minh rằng MODEL SPIDER xếp hạng PTM hiệu quả và đạt được những cải tiến đáng kể trên các cấu hình kho mô hình khác nhau.

2 Các Công trình Liên quan
Tìm kiếm PTM Hiệu quả với Đánh giá Khả năng Chuyển giao. Liệu một PTM được chọn có hữu ích hay không có thể được hình thành như bài toán đo lường khả năng chuyển giao từ dữ liệu nguồn huấn luyện trước PTM đến nhiệm vụ hạ nguồn đích [12,33,4,62]. Việc đánh giá khả năng chuyển giao hiện tại dựa vào một lượt truyền tiến của PTM trên nhiệm vụ đích, tạo ra các đặc trưng đặc thù PTM trên nhiệm vụ đích. Ví dụ, NCE [73], LEEP [53], LogME [83,84], PACTran [21], và TransRate [32] ước tính entropy có điều kiện âm, kỳ vọng log, khả năng có biên, giới hạn PAC-Bayesian, thông tin tương hỗ để có được metric proxy của khả năng chuyển giao, tương ứng. Một số mở rộng bao gồm N-LEEP [45] với mô hình hỗn hợp Gaussian trên đặc trưng PTM, H-Score [8] sử dụng

--- TRANG 3 ---
ma trận chuyển đổi phân kỳ để xấp xỉ log-likelihood được chuyển giao, và [19,56,67] khám phá mối tương quan giữa các danh mục của nhiệm vụ đích. Thông tin phụ trợ như manh mối nguồn [6,72] và gradient của PTM khi lan truyền ngược với vài bước [68,58] cũng được điều tra. Mặc dù các phương pháp đánh giá khả năng chuyển giao tránh được việc tinh chỉnh tốn thời gian, chi phí forward qua PTM cũng trở nên nặng nề hơn với các kho mô hình được huấn luyện trước đa dạng và phức tạp.

Mối liên quan của Nhiệm vụ. Liệu một PTM có được cải thiện sau khi tinh chỉnh trên nhiệm vụ hạ nguồn hay không đã được xác minh phụ thuộc vào mối liên quan giữa các nhiệm vụ cả về mặt lý thuyết [9,10,48] và thực nghiệm [77]. Mối liên quan có thể được đo lường thông qua nhiều cách khác nhau, như tinh chỉnh hoàn toàn [85], vector nhiệm vụ [2], đồ thị dựa trên ví dụ [40,23,69], độ tương tự cấp độ biểu diễn [24,3], và kiến thức trước của con người [36,60]. Thay vì sử dụng chiến lược được định nghĩa trước để đo lường mối liên quan, MODEL SPIDER xây dựng token của PTM/nhiệm vụ dưới dạng vector và học một độ tương tự giữa chúng trên các nhiệm vụ lịch sử.

Học cách xếp hạng dự đoán thứ tự của các đối tượng thường với một hàm điểm [35], và kinh nghiệm trên tập huấn luyện có thể được tổng quát hóa cho dữ liệu chưa thấy [5,51]. Các metric hoặc embedding được học bổ sung cải thiện thêm khả năng xếp hạng [50,14]. Mối liên quan nhiệm vụ cũng có thể được mô hình hóa như một bài toán học cách xếp hạng, trong đó sự ưu tiên một PTM hơn PTM khác có thể được học từ các thứ hạng lịch sử của PTM. Tuy nhiên, việc có được giám sát trên tập huấn luyện yêu cầu tinh chỉnh hoàn toàn trên một số lượng lớn nhiệm vụ lịch sử, điều này đến từ kinh nghiệm học chuyển giao tốn thời gian [78] hoặc đầu ra từ một số phương pháp đánh giá khả năng chuyển giao được chọn đặc biệt [22]. Chúng tôi đề xuất một xấp xỉ mạnh mẽ và hiệu quả của giám sát xếp hạng PTM trên các nhiệm vụ tập huấn luyện, và một độ tương tự dựa trên token mới được áp dụng.

3 Kiến thức Cơ bản
Chúng tôi mô tả bài toán lựa chọn PTM bằng cách giả định tất cả PTM là các bộ phân loại, và mô tả có thể dễ dàng mở rộng cho PTM cho các nhiệm vụ khác, ví dụ: hồi quy. Sau đó chúng tôi thảo luận về một số giải pháp.

3.1 Lựa chọn PTM từ Kho Mô hình
Xem xét chúng ta có một nhiệm vụ phân loại đích T={(xi, yi)}N i=1 với N ví dụ có nhãn, trong đó nhãn yi của mỗi thể hiện xi đến từ một trong CT lớp. Thay vì học trực tiếp trên T, chúng ta giả định có một kho mô hình M={fm=Wm◦ϕm}M m=1 chứa M PTM. Một PTM fm có thể được phân tách thành hai thành phần. ϕm là mạng trích xuất đặc trưng tạo ra các đặc trưng dm chiều. Wm∈Rdm×Cm là bộ phân loại lớp trên cùng ánh xạ một đặc trưng dm chiều thành điểm tin cậy trên Cm lớp.1 PTM trong M được huấn luyện trên dữ liệu nguồn qua các miền khác nhau. Các bộ trích xuất đặc trưng ϕm của chúng có kiến trúc đa dạng, và các bộ phân loại tương ứng được huấn luyện trước cho các tập hợp đối tượng khác nhau. Nói cách khác, dm và Cm′ có thể khác nhau cho một cặp m và m′ nhất định. Một cách được sử dụng rộng rãi để tận dụng PTM fm=Wm◦ϕm trong nhiệm vụ đích là tinh chỉnh bộ trích xuất đặc trưng cùng với một bộ phân loại được khởi tạo ngẫu nhiên trên T. Cụ thể, chúng ta tối thiểu hóa mục tiêu sau:

ˆf=ˆW◦ˆϕ= arg min f=W◦ϕ N X i=1 ℓ(W⊤ϕ(xi), yi|ϕm), (1)

trong đó ϕ được khởi tạo với ϕm. Mô hình được tinh chỉnh fm đưa ra dự đoán với arg maxc∈[C] ˆw⊤ c ˆϕ(x). [C] ={1, . . . , C } và ˆwc là cột thứ c của ˆW. Sau đó, chúng ta có thể xếp hạng tính hữu ích của PTM dựa trên hiệu suất của các mô hình được tinh chỉnh của chúng. Nói cách khác, chúng ta có được ˆfm theo Phương trình 1 dựa trên PTM thứ m fm, sau đó chúng ta tính độ chính xác trung bình khi dự đoán trên tập kiểm tra chưa thấy của T (càng cao càng tốt), tức là:

tϕm→T=Eh I y= arg maxc∈[C] ˆfm(x) i . (2)

tϕm→T cũng được gọi là khả năng chuyển giao, đo lường liệu bộ trích xuất đặc trưng ϕm trong PTM có thể được chuyển giao tốt cho nhiệm vụ đích với tinh chỉnh [73,32]. I(·) là hàm chỉ thị, xuất ra 1 nếu điều kiện được thỏa mãn. Cho tT={tϕm→T}M m=1, tức là khả năng chuyển giao cho tất cả PTM, sau đó chúng ta có thể có được thứ hạng sự thật của tất cả PTM trong kho mô hình cho nhiệm vụ T và chọn PTM xếp hạng cao nhất. Trong bài toán lựa chọn PTM, mục tiêu là ước tính thứ hạng của tất cả PTM cho một nhiệm vụ T sử dụng ˆtT={ˆtϕm→T}M m=1. Tiêu chí đánh giá là sự tương tự giữa ˆtT được dự đoán và sự thật tT, thường được đo bằng τw có trọng số của Kendall [37]. Chúng tôi bỏ qua chỉ số dưới T khi nó rõ ràng từ ngữ cảnh.

3.2 Hiệu quả Quan trọng trong Lựa chọn PTM
Một giải pháp trực tiếp cho lựa chọn PTM là xấp xỉ sự thật tT bằng cách tinh chỉnh tất cả PTM trên T, trong đó một tập xác thực nên được tách từ T để ước tính Phương trình 2. Vì tinh chỉnh PTM chứa nhiều lượt truyền tiến và lùi, gánh nặng tính toán là thiên văn học.

Một lượt truyền tiến của bộ trích xuất ϕm của PTM nhất định trên T tạo ra các đặc trưng Φm T={ϕm(xi)∈ Rdm}(xi,yi)∈T, vốn nhẹ so với bước lùi. Đặc trưng tiết lộ cách các ví dụ trong T được phân phối từ góc nhìn của PTM được chọn, và một đặc trưng có tính phân biệt hơn có thể có tiềm năng chuyển giao cao hơn. Như đã đề cập trong phần 2, các phương pháp đánh giá khả năng chuyển giao hiện có ước tính tϕm→T dựa trên đặc trưng đặc thù PTM Φm T và nhãn đích {yi}N i=1 [53,83,45,84]. Ước tính chính xác đòi hỏi N lớn, có nghĩa là chúng ta cần thu thập đủ ví dụ để xác định PTM hữu ích nhất từ kho mô hình.

Trong khi các phương pháp đánh giá khả năng chuyển giao dựa trên forward trước đây giảm chi phí thời gian, việc lựa chọn giữa M PTM trong kho mô hình nhân chi phí forward M lần, làm cho việc ước tính ˆt tốn kém về mặt tính toán. Hơn nữa, vì các lượt truyền tiến cho PTM phức tạp mất thời gian hơn, việc lựa chọn PTM hiệu quả, đặc biệt là với kho mô hình lớn, là rất quan trọng.

4 MODEL SPIDER
Trong MODEL SPIDER, chúng tôi đề xuất tokenize PTM và nhiệm vụ bất kể độ phức tạp của chúng, cho phép chúng ta tính toán hiệu quả mối liên quan của chúng dựa trên một biện pháp độ tương tự nhất định trên token của chúng. Các token này nắm bắt các tính chất chung và phục vụ như một đặc tả của mô hình hoặc nhiệm vụ, chứng minh mô hình thực hiện tốt trên loại nhiệm vụ nào hoặc nhiệm vụ yêu cầu loại mô hình nào. Trong phần này, chúng tôi đầu tiên giới thiệu quá trình có được token bằng cách học từ một tập huấn luyện của các nhiệm vụ, và khả năng xếp hạng PTM có thể được tổng quát hóa cho các nhiệm vụ hạ nguồn. Sau đó chúng tôi mô tả bộ mã hóa token, biện pháp độ tương tự theo token, và một cách hiệu quả để tạo ra giám sát trong quá trình huấn luyện token. Cuối cùng, chúng tôi thảo luận về cách MODEL SPIDER có thể linh hoạt trong việc kết hợp kết quả lượt truyền tiến của PTM xếp hạng cao để cải thiện thêm ngữ nghĩa của token và chất lượng xếp hạng.

4.1 Học cách Xếp hạng PTM với Token
Trong MODEL SPIDER, chúng tôi học các token mô hình {θm}M m=1, token nhiệm vụ µ(T), và biện pháp độ tương tự sim(·,·) theo cách học có giám sát dựa trên một tập huấn luyện riêng D. Tập huấn luyện D không chứa các lớp trùng lặp với nhiệm vụ hạ nguồn T.

Cụ thể, chúng tôi lấy mẫu ngẫu nhiên các nhiệm vụ huấn luyện {Ti} từ D. Đối với một nhiệm vụ huấn luyện Ti đã cho, chúng tôi giả định rằng chúng tôi có thể có được thứ hạng sự thật tTi={tϕm→Ti}M m=1 trên M PTM, cho biết tính hữu ích của mỗi PTM. Chúng tôi sẽ thảo luận chi tiết về việc có được giám sát tTi sau. Sau đó chúng tôi lựa chọn PTM cho Ti dựa trên độ tương tự giữa token nhiệm vụ µ(Ti) và những M token PTM {θm}M m=1. Chúng tôi mong đợi độ tương tự càng cao, PTM càng hữu ích cho nhiệm vụ đã cho. Chúng tôi sử dụng Θ để biểu thị tất cả các tham số có thể học và tối ưu hóa Θ với mất mát xếp hạng, tối thiểu hóa sự khác biệt giữa thứ hạng ˆtTi được dự đoán bởi hàm độ tương tự và sự thật tTi:

min Θ X Ti∼D ℓrank ˆtTi={sim(θm,µ(Ti))}M m=1,tTi . (3)

Cho t∈RM, chúng tôi sử dụng toán tử dsc(·) để chỉ mục các phần tử của t theo thứ tự giảm dần, tức là ∀m < l, chúng ta có tdsc(m)⩾tdsc(l). dsc(m) chính xác là chỉ số của PTM với điểm sự thật lớn thứ m. Dựa trên điều này, chúng tôi sử dụng mất mát xếp hạng sau:

ℓrank(ˆt,t) = M X m=1 −log  expˆtdsc(m) PM l=m expˆtdsc(l) ! , (4)

--- TRANG 5 ---
…
sim( ,
𝜓𝜓
Bộ Trích xuất Tổng quát
Token Mô hình
• Khởi tạo Ngẫu nhiên & Có thể Học
Token Nhiệm vụ
Token Nhiệm vụ Đặc thù PTM *
PTM Được Chọn
* [Tùy chọn]
Không gian Mô hình-Nhiệm vụ
Biện pháp Độ tương tự Mô hình-Nhiệm vụ • Dựa trên Transformer
chiếu đến
̂𝑡𝑡𝒯𝒯={sim( ,
),
sim( ,),
sim( ,)}
sim( ,token nhiệm vụ, token PTM)
)
Cập nhật với
Token đặc thù PTM *
• Ví dụ
Xếp hạng PTM:
… > > >
Giám sát Xấp xỉ
• trên các nhiệm vụ few-shot
LogME
H-Score
NCE
RankAgg
ℓrank
Mất mát Xếp hạng

Hình 2: Minh họa MODEL SPIDER. Phần giữa (b) cho thấy quy trình làm việc của MODEL SPIDER, bao gồm việc tokenize cả PTM và nhiệm vụ vào một không gian chung. Biểu đồ (c) chứng minh cách độ tương tự mô hình-nhiệm vụ được tính dựa trên token giúp xếp hạng PTM cho một nhiệm vụ đã cho. Trong biểu đồ (a), khi ngân sách cho phép, MODEL SPIDER có thể tận dụng các đặc trưng đặc thù PTM được thu thập bằng cách thực hiện các lượt truyền tiến của k PTM xếp hạng cao nhất trên một số nhiệm vụ được chọn. Điều này cải thiện chất lượng của token nhiệm vụ cũng như xếp hạng PTM.

Phương trình 4 nhằm làm cho toàn bộ thứ tự của ˆtTi được dự đoán tương tự với sự thật tTi. Vì vậy, độ tương tự giữa token nhiệm vụ và token của PTM xếp hạng cao hơn được chỉ ra bởi tTi nên lớn hơn độ tương tự với token PTM xếp hạng thấp hơn. Trực giác cơ bản là nếu một PTM hoạt động tốt trên các nhiệm vụ nhất định, nó có khả năng tổng quát hóa khả năng của mình cho các nhiệm vụ liên quan. Ví dụ, nếu một PTM xuất sắc trong nhận dạng chim, nó có thể nhận dạng hiệu quả các động vật bay khác.

Đối với một nhiệm vụ hạ nguồn T, chúng tôi tạo token nhiệm vụ của nó với µ(T), và xác định các token PTM gần với sim(·,·) đã học. Mục tiêu Phương trình 3 cũng hoạt động khi số lượng ví dụ trong một nhiệm vụ là nhỏ. Bằng cách học cách xếp hạng PTM cho các nhiệm vụ few-shot được lấy mẫu, MODEL SPIDER có thể xếp hạng các mô hình hữu ích ngay cả với dữ liệu huấn luyện hạn chế. Chúng tôi sẽ chỉ ra khả năng này của MODEL SPIDER trong phần 5.

4.2 Token cho Lựa chọn PTM
Chúng tôi mã hóa các đặc điểm tổng quát của nhiệm vụ và PTM thông qua hai loại token.

Token Mô hình. Cho một kho mô hình với M PTM, chúng tôi liên kết một PTM fm với một token θm∈Rd. θm mã hóa ngữ nghĩa phong phú về các khía cạnh mà fm xuất sắc. Các mô hình được huấn luyện trước từ các tập dữ liệu liên quan hoặc những mô hình có chức năng tương tự được mong đợi có token tương tự.

Token Nhiệm vụ. Một nhiệm vụ CT lớp T={(xi, yi)}N i=1 chứa một tập hợp các thể hiện và nhãn. Chúng tôi muốn tokenize một nhiệm vụ với một ánh xạ µ(·), xuất ra một tập hợp các vector µ(T)∈Rd×CT, một cho mỗi lớp. Chúng tôi triển khai µ với một bộ mã hóa bị đóng băng bổ sung ψ với độ lớn tham số tương đương với PTM trong kho mô hình. ψ được huấn luyện trước bằng các phương pháp học tự giám sát [15,27,43] và nắm bắt ngữ nghĩa của một loạt rộng các lớp. Cụ thể, chúng tôi trích xuất các đặc trưng của tất cả các thể hiện trong nhiệm vụ T và lấy các trung tâm lớp làm token nhiệm vụ:

µ(T) = 
 1 |I(yi=c)| X (xi,yi)∈T [ψ(xi)·I(yi=c)]
 
 c∈[C]. (5)

Token nhiệm vụ thể hiện các đặc điểm của một nhiệm vụ, ví dụ, những nhiệm vụ với các lớp tương tự về mặt ngữ nghĩa có thể có các tập hợp token tương tự.

Độ tương tự Mô hình-Nhiệm vụ. Tính hữu ích của PTM đối với một nhiệm vụ, tức là điểm khả năng chuyển giao, có thể được ước tính dựa trên độ tương tự của các cặp token mô hình-nhiệm vụ ˆtϕm→T= sim(θm,µ(T)), và việc lựa chọn PTM được hoàn thành bằng cách nhúng mô hình và nhiệm vụ vào một không gian và sau đó xác định các token PTM gần với một nhiệm vụ. Trong MODEL SPIDER, sim(·,·) được triển khai với một Transformer một lớp [74], một mô-đun self-attention cho phép các đầu vào khác nhau. Transformer bao gồm các lớp xen kẽ của multi-head self-attention, multi-layer perceptron, và các khối layer norm. Chúng tôi đặt đầu vào của Transformer là tập hợp liên kết của token mô hình và nhiệm vụ z= [θm,µ(T)]∈Rd×(1+C), sau đó độ tương tự ˆtϕm→T giữa token mô hình và nhiệm vụ là:

sim(θm,µ(T)) = FC (transformer ( z) [0]) , (6)

trong đó [0] là đầu ra đầu tiên của Transformer, tức là đầu ra tương ứng của token mô hình. Chúng tôi thêm một lớp Fully Connected (FC) để chiếu kết quả trung gian thành một vô hướng. Các tham số có thể học Θ, bao gồm {θm}M m=1, FC, và trọng số của Transformer, được huấn luyện thông qua mục tiêu trong Phương trình 3.

--- TRANG 6 ---
4.3 Tăng tốc Huấn luyện cho MODEL SPIDER

Quá trình huấn luyện MODEL SPIDER trong Phương trình 3 yêu cầu một số lượng lớn cặp (nhiệm vụ Ti, xếp hạng PTM tTi). Mặc dù chúng tôi có thể thu thập đủ dữ liệu cho mỗi nhiệm vụ, việc có được thứ hạng sự thật của PTM, tức là thứ tự tính hữu ích của PTM cho mỗi nhiệm vụ, là tốn kém về mặt tính toán. Ngoài ra, việc sử dụng một số proxy của tTi có thể làm suy yếu khả năng của MODEL SPIDER. Chúng tôi đề xuất một xấp xỉ gần hơn với sự thật tTi, giám sát hiệu quả các nhiệm vụ được lấy mẫu từ D.

Giám sát Huấn luyện Xấp xỉ. Chúng tôi tận dụng thực tế rằng các phương pháp lựa chọn PTM hiện có dựa vào các đặc trưng đặc thù PTM Φm Ti để ước tính điểm khả năng chuyển giao đối với Ti và tạo ra các điểm đa dạng. Nói cách khác, một PTM sẽ được đặt ở các vị trí khác nhau dựa trên các điểm được cung cấp bởi các phương pháp khác nhau như NCE [73], LEEP [53], và LogME [83,84]. Dựa trên kết quả xếp hạng "tương đối tốt nhưng đa dạng" của chúng, một cách tiếp cận trực giác để ước tính sự thật tTi là tổng hợp nhiều kết quả xếp hạng của chúng thành một thứ tự đơn mạnh hơn.

Cho {ˆt1 Ti,ˆt2 Ti, . . .} là nhiều thứ hạng được dự đoán trên M PTM cho một nhiệm vụ Ti được lấy mẫu, tức là thứ tự được sắp xếp bởi các ước tính khả năng chuyển giao thông qua các phương pháp khác nhau, chúng tôi tận dụng phương pháp tổng hợp của Copeland [7,65] để tổng hợp các thứ tự: ¯tTi={¯tϕm→Ti}M m=1= RankAgg( {ˆt1 Ti,ˆt2 Ti, . . .}).

Tổng hợp của Copeland so sánh từng cặp ứng viên xếp hạng và xem xét tất cả sở thích để xác định cái nào trong hai cái được ưa thích hơn. Đầu ra ¯tTi hoạt động như một ước tính tốt của giám sát sự thật tTi. ¯tTi được tổng hợp chính xác hơn một phương pháp đánh giá khả năng chuyển giao cụ thể, điều này cải thiện chất lượng của giám sát trong mất mát xếp hạng trong Phương trình 4.

Lấy mẫu Nhiệm vụ để Huấn luyện. Chúng tôi giả định rằng dữ liệu huấn luyện D chứa một số lượng lớn các lớp với dữ liệu đầy đủ. Để lấy mẫu các nhiệm vụ để huấn luyện, chúng tôi chọn ngẫu nhiên một tập hợp các lớp từ D và chọn một tập con của các ví dụ tương ứng của chúng. Hưởng lợi từ phương pháp ước tính giám sát RankAgg, chúng tôi có thể thu được thứ hạng tổng hợp ¯t cho bất kỳ nhiệm vụ được lấy mẫu nào.

Độ phức tạp Huấn luyện. Giai đoạn huấn luyện trong MODEL SPIDER hiệu quả. Đầu tiên, chúng tôi trích xuất trước các đặc trưng {Φm D}M m=1 cho D với tất cả PTM trước. Sau đó chỉ gánh nặng tính toán của các phương pháp đánh giá khả năng chuyển giao cơ bản, phương pháp tổng hợp thứ hạng, và việc tối ưu hóa các tham số lớp trên được liên quan. Hơn nữa, các nhiệm vụ huấn luyện với cùng một tập hợp các lớp chia sẻ cùng một ¯tTi.

4.4 Xếp hạng lại với Sự cân bằng Hiệu quả-Độ chính xác

Token mô hình có thể học nắm bắt hiệu suất thực nghiệm của PTM trên các lĩnh vực khác nhau của các nhiệm vụ huấn luyện, điều này tách rời token nhiệm vụ khỏi PTM. Mỗi token mô hình ngầm thể hiện lĩnh vực mà PTM xuất sắc, vì vậy việc lựa chọn PTM chỉ yêu cầu một token nhiệm vụ để thể hiện lĩnh vực mà nhiệm vụ đó thuộc về. Trái ngược với token nhiệm vụ tổng quát µ(Ti), các đặc trưng đặc thù PTM Φm Ti cho một tập con của PTM cung cấp manh mối phong phú về cách những PTM đó phù hợp với các ví dụ đích, cũng được sử dụng trong các phương pháp đánh giá khả năng chuyển giao liên quan [19,56]. Chúng tôi tuyên bố rằng với các đặc trưng cụ thể với một tập con của PTM khi ngân sách có sẵn, MODEL SPIDER của chúng tôi có thể xếp hạng lại thứ tự PTM được ước tính và cải thiện hiệu suất hơn nữa.

Cụ thể, chúng tôi trích xuất token nhiệm vụ đặc thù PTM µm(T)∈Rdm×CT với các đặc trưng cụ thể Φm T của PTM thứ m như Phương trình 5. Để tính đến các giá trị khác nhau của dm do sự không đồng nhất của PTM, chúng tôi học một phép chiếu P∈Rdm×d cho PTM thứ m để căn chỉnh chiều của µm(T) với token mô hình. Sau đó chúng tôi thay thế token nhiệm vụ tổng quát µ(T) bằng token cụ thể P⊤ mµm(T) khi tính độ tương tự với token θm của PTM thứ m. Token nhiệm vụ cụ thể có thể tạo điều kiện để có được các ước tính chính xác hơn. Trong quá trình huấn luyện, chúng tôi chọn động một tập hợp một phần của PTM và kết hợp các token cụ thể vào các nhiệm vụ được lấy mẫu. Do đó, cùng một mô-đun Transformer trong Phương trình 6 có thể xử lý loại token mới. Để phân biệt các token tổng quát và cụ thể, chúng tôi học hai embedding d chiều bổ sung như prompts. Các prompt được thêm vào token đầu vào, cho phép transformer sử dụng ngữ cảnh loại token để có quy trình xếp hạng tốt hơn. Đáng chú ý, µm(T) phụ thuộc vào Φm T, và các đặc trưng đặc thù PTM được trích xuất trước cho tất cả các nhiệm vụ huấn luyện làm cho việc xây dựng các token cụ thể này hiệu quả.

4.5 Tóm tắt Ngắn gọn về MODEL SPIDER

MODEL SPIDER học cách xếp hạng PTM với token của chúng cho một nhiệm vụ đã cho, cân bằng hiệu quả và độ chính xác. Trong quá trình huấn luyện, chúng tôi lấy mẫu các nhiệm vụ trong đó token PTM và biện pháp độ tương tự dựa trên transformer được học. Cụ thể, để cho phép độ tương tự mô hình-nhiệm vụ kết hợp các đặc trưng đặc thù PTM, chúng tôi thay thế một số đầu vào của transformer bằng token được làm giàu. Chúng tôi trích xuất trước các đặc trưng đặc thù PTM cho tất cả các nhiệm vụ huấn luyện, sau đó sự thật được ước tính và các token cụ thể có thể được xây dựng hiệu quả. Trong quá trình triển khai, chúng tôi đầu tiên sử dụng tìm kiếm PTM thô với token tổng quát. Sau đó chúng tôi thực hiện các lượt truyền tiến qua nhiệm vụ đích chỉ cho k PTM xếp hạng cao nhất, trong đó token nhiệm vụ đặc thù PTM thu được sẽ xếp hạng lại PTM bằng cách tính đến các ví dụ được phân phối với các đặc trưng của PTM.

5 Thí nghiệm
Chúng tôi đánh giá MODEL SPIDER trên hai benchmark: một kho mô hình bao gồm các mô hình không đồng nhất được huấn luyện trước từ cùng và các tập dữ liệu khác nhau. Chúng tôi phân tích ảnh hưởng của các thành phần chính trong MODEL SPIDER và trực quan hóa khả năng của PTM bằng biểu đồ nhện dựa trên các token đã học.

5.1 Đánh giá trên Kho Mô hình Nguồn Đơn
Thiết lập. Chúng tôi theo [83] và xây dựng một kho mô hình với 10 PTM được huấn luyện trước trên ImageNet [64] qua năm họ kiến trúc, tức là Inception [70], ResNet [28], DenseNet [31], MobileNet [66], và MNASNet [71]. Chúng tôi đánh giá các phương pháp khác nhau trên 9 tập dữ liệu hạ nguồn, tức là Aircraft [47], Caltech101 [26], Cars [39], CIFAR10 [41], CIFAR100 [41], DTD [17], Pet [57], và SUN397 [82] cho phân loại, UTKFace [86] và dSprites [49] cho hồi quy.

Baselines. Có ba nhóm phương pháp so sánh. Đầu tiên là tạo ra một proxy giữa các đặc trưng đặc thù PTM và nhãn hạ nguồn, như H-Score [8], NCE [73], LEEP [53], N-LEEP [45], LogME [83], và PACTran [21]. Thứ hai dựa trên các đặc trưng giữa các danh mục hạ nguồn như OTCE [72], Label-Feature Correlation (LFC) [19], và GBC [56]. Theo [53] và [83], chúng tôi sửa đổi tương đương NCE và H-Score cho ứng dụng lựa chọn mô hình tổng quát.

Đánh giá. Đối với đánh giá tiêu chuẩn, chúng tôi theo phân chia train-test chính thức của mỗi tập dữ liệu hạ nguồn và sử dụng tất cả các mẫu huấn luyện. Trong đánh giá few-shot, chúng tôi xem xét liệu MODEL SPIDER có thể chọn các mô hình hữu ích với các ví dụ có nhãn hạn chế dưới các ràng buộc về quyền riêng tư và nguồn lực. Chúng tôi

--- TRANG 7 ---
45.47
39.75
34.03
28.31
35.77
32.30
28.83
25.37
32.91
26.99
21.0715.16
-4.17
-4.31
-4.45
-4.58
-3.28
-3.41
-3.53
-3.66
-2.40
-2.85
-3.30-3.75-4.51
-4.54
-4.58-4.61
-3.65
-3.72
-3.78-3.85
-3.10
-3.29
-3.48-3.67-1.99
-2.19
-2.38
-2.57
-1.09
-1.51
-1.93
-2.35
-0.28
-1.08
-1.89-2.690.94
0.92
0.900.89
0.70
0.64
0.59
0.53
1.08
0.79
0.490.20-0.04
-0.05
-0.06-0.07
-0.07
-0.08
-0.09
-0.10
-0.07
-0.09
-0.11-0.13-0.03
-0.02
-0.01
-0.00
0.13
0.09
0.05
0.01
0.43
0.25
0.08
-0.08Pet                               DTD                          Aircraft
DenseNet-201         Inception v3         ResNet-50
76.00            81.35           86.70           76.00          81.35          86.70            76.00           81.35        86.70            76.00          81.35            86.70           76.00           81.35           86.70           76.00        81.35          86.70             76.00          81.35           86.70            76.00          81.35         86.70         76.00 81.35           86.70 -0.04
-2.75
-5.47-8.19
0.19
-0.41-1.13
-1.61
0.11
-0.55
-1.23-1.90-8.16
-15.08-21.99-28.90
13.10
1.40
-10.30-22.00
23.43
3.22
-16.99
-37.20
1e576.00             81.35            86.70           76.00          81.35          86.70            76.00           81.35      86.70            76.00          81.35            86.70           76.00           81.35           86.70           76.00       81.35          86.70             76.00          81.35           86.70            76.00          81.35         86.70         76.00           81.35           86.70 
76.00             81.35            86.70           76.00          81.35          86.70            76.00           81.35      86.70            76.00          81.35            86.70           76.00           81.35           86.70           76.00       81.35          86.70             76.00          81.35           86.70            76.00          81.35         86.70         76.00           81.35           86.70 
1e5
1e5
H-Score ( 0.649)       NCE ( 0.671)         LEEP ( 0.361)          - LEEP ( 0.677)    LogME (0.673)    PACTran (0.345)     LFC ( 0.637)          GBC ( 0.439)         Của chúng tôi (0.678)  H-Score ( 0.357)       NCE ( 0.254)         LEEP ( 0.200)          - LEEP ( 0.254)    LogME (0.542)    PACTran (0.237)     LFC ( 0.205)          GBC ( 0.147)         Của chúng tôi (0.549)  H-Score ( 0.067)       NCE ( -0.160)       LEEP ( -0.615)         -LEEP ( -0.103)   LogME (-0.075)  PACTran (-0.602)   LFC ( -0.178)         GBC ( -0.195)        Của chúng tôi (0.352)  

Hình 3: Trực quan hóa khi lựa chọn PTM từ kho mô hình không đồng nhất đa nguồn (với 42 PTM) trên ba tập dữ liệu hạ nguồn. Hàng đại diện cho các phương pháp, và cột đại diện cho các tập dữ liệu. Tương quan ( τw) được hiển thị phía trên mỗi hình con. Trục ngang biểu thị độ chính xác được chuyển giao (với tinh chỉnh), trong khi trục tung là điểm xếp hạng đầu ra. Các kiến trúc PTM được vẽ bằng màu đỏ, vàng và xanh lá cây. Đường in đậm và vùng xám cho thấy đường thẳng khớp và khoảng tin cậy cho tất cả PTM. Tương quan tuyến tính mạnh cho thấy hiệu suất vượt trội.

lấy mẫu 10 ví dụ mỗi lớp từ tập huấn luyện làm "tập thăm dò" và báo cáo kết quả trung bình trong 30 lần thử. Kết quả đầy đủ, cùng với khoảng tin cậy 95%, được trình bày trong phụ lục.

Chi tiết Huấn luyện của MODEL SPIDER. Chúng tôi triển khai ψ với Swin-B [46,43] được huấn luyện trước để trích xuất token nhiệm vụ. MODEL SPIDER được huấn luyện trên 832 nhiệm vụ được lấy mẫu từ hỗn hợp 6 tập dữ liệu, tức là EuroSAT [29], OfficeHome [75], PACS [44], SmallNORB [42], STL10 [18] và VLCS [25]. MODEL SPIDER sử dụng các đặc trưng cụ thể từ 3 PTM xếp hạng cao nhất (trong số 10) cho các nhiệm vụ hạ nguồn, dẫn đến tăng tốc 3-4 lần.

Kết quả Đánh giá Tiêu chuẩn và Few-Shot. Đối với đánh giá tiêu chuẩn được hiển thị trong Bảng 1 và Bảng 2, MODEL SPIDER vượt trội hơn các baseline khác trên các tập dữ liệu, ngoại trừ Aircraft, xếp hạng top-2. Nó cũng thể hiện sự ổn định vượt trội và vượt trội hơn tất cả các phương pháp hiện có trong các tình huống few-shot, như được hiển thị trong phần dưới của Bảng 1. Xếp hạng nhất quán và lựa chọn PTM đúng, MODEL SPIDER đạt hiệu suất trung bình cao nhất trong tất cả các phương pháp.

5.2 Đánh giá trên Kho Mô hình Đa Nguồn

Bảng 2: So sánh hiệu suất của các phương pháp tiến hành hồi quy với cùng kho mô hình và đo lường τw có trọng số như trong Bảng 1. Nhiệm vụ hạ nguồn là dSprites và UTKFace.

Tập dữ liệu Phương pháp cho Nhiệm vụ Hồi quy
H-Score LogME GBC Của chúng tôi
dSprites 0.106 0.612 -0.283 0.679
UTKFace 0.075 -0.156 0.052 0.364

Chúng tôi xây dựng một kho mô hình lớn trong đó 42 PTM không đồng nhất được huấn luyện trước từ nhiều tập dữ liệu.

Thiết lập. PTM với 3 kiến trúc có độ lớn tương tự, tức là Inception V3, ResNet 50, và DenseNet 201, được huấn luyện trước trên 14 tập dữ liệu, bao gồm động vật [30,38], đối tượng tổng quát và 3D [26,42,41,39,13], thực vật [54], dựa trên cảnh [82], viễn thám [81,16,29] và nhận dạng đa miền [44]. Chúng tôi đánh giá khả năng lựa chọn PTM trên các tập dữ liệu Aircraft [47], DTD [17], và Pet [57].

Chi tiết Huấn luyện. Chúng tôi sử dụng cùng một bộ trích xuất token nhiệm vụ như trong phần 5.1 với 4352 nhiệm vụ huấn luyện được lấy mẫu từ hỗn hợp các tập dữ liệu trên để huấn luyện trước kho mô hình.

Phân tích Kho Mô hình Đa Nguồn. Với nhiều PTM trong kho mô hình, chúng tôi đầu tiên đặt k= 0 và lựa chọn PTM dựa trên token tổng quát. Chúng tôi trực quan hóa kết quả trong Hình 3, với mỗi hình con hiển thị độ chính xác được chuyển giao bằng cách sử dụng PTM được chọn với tinh chỉnh và điểm xếp hạng được dự đoán. Một phương pháp hoạt động tốt hơn sẽ cho thấy tương quan tuyến tính rõ ràng hơn. Kết quả chứng minh rằng MODEL SPIDER đạt được tối ưu trong tất cả ba tập dữ liệu. Hơn nữa, một trực quan hóa về hiệu quả, hiệu suất trung bình trên tất cả các tập dữ liệu, và kích thước mô hình trên benchmark này với đánh giá tiêu chuẩn được hiển thị trong Hình 1. Các cấu hình khác nhau của k cân bằng hiệu quả và hiệu suất trong việc lựa chọn PTM, "bao bọc" kết quả của các phương pháp khác. Những kết quả này

--- TRANG 8 ---
𝑘 = 0 𝑘 = 3 𝑘 = 6 𝑘 = 36 𝑘 = 42
Số lượng Đặc trưng Đặc thù PTM được Sử dụng
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Tương quan (𝜏𝑤)
Ít Nhiệm vụ Huấn luyện
Ít Nhiệm vụ Huấn luyện Của chúng tôi (báo cáo)
Bộ trích xuất ψ Đơn giản hơn
Bộ trích xuất ψ Đơn giản hơn Của chúng tôi (báo cáo)
Tương quan (𝜏𝑤)
Aircraft Cars DTD dSprites UTKFace
0.1
0.2
0.3
0.4
0.5
0.6
0.7
(a) Số lượng Đặc trưng Được Sử dụng so với Tương quan.

Cảnh
Chim
Đối tượng 3D
Y tế
Động vật
Động vật
Y tế
Cảnh
Chim
Viễn thám
Viễn thám
Đối tượng 3D
Được Huấn luyện Trước trên AID
Được Huấn luyện Trước trên NABirds
(b) Biểu đồ nhện về các khía cạnh ngữ nghĩa mà PTM xuất sắc.

Hình 4: (a): Phân tích ablation về cách tương quan xếp hạng thay đổi (trục Y) với nhiều đặc trưng đặc thù PTM hơn (trục X). (b): Trực quan hóa khả năng của PTM trên 6 cụm ngữ nghĩa chính của các tập dữ liệu với biểu đồ nhện. Điểm số trên đỉnh của biểu đồ nhện là độ tương tự trung bình giữa một PTM và token nhiệm vụ trong cụm. Giá trị đỉnh càng cao, PTM sẽ hoạt động càng tốt trên loại nhiệm vụ đó.

xác nhận rằng MODEL SPIDER hoạt động tốt trong các tình huống phức tạp, nhấn mạnh khả năng lựa chọn PTM không đồng nhất trong kho mô hình lớn.

5.3 Các Nghiên cứu Ablation
Chúng tôi phân tích các tính chất của MODEL SPIDER trên một số tập dữ liệu hạ nguồn, theo đánh giá kho mô hình nguồn đơn trong phần 5.1.

Liệu RankAgg có cung cấp sự thật chính xác hơn trong quá trình huấn luyện? Như đã thảo luận trong phần 4.3, MODEL SPIDER được huấn luyện trên các nhiệm vụ lịch sử và chúng tôi sử dụng RankAgg để xấp xỉ xếp hạng độ chính xác. Chúng tôi điều tra liệu xấp xỉ này có cung cấp giám sát tốt hơn và liệu việc sử dụng các phương pháp lựa chọn mô hình trước đó như H-Score hoặc LogME mà không có tổng hợp có đủ hay không. Kết quả trong Bảng 3 bao gồm CIFAR10 và kết quả trung bình trên tám tập dữ liệu phân loại. Rõ ràng rằng RankAgg cung cấp giám sát mạnh hơn trong quá trình huấn luyện MODEL SPIDER.

Bảng 3: τw có trọng số của các biến thể MODEL SPIDER khi giám sát huấn luyện được xấp xỉ bởi các phương pháp khác nhau. "Mean" biểu thị hiệu suất trung bình trên 8 tập dữ liệu hạ nguồn trong Bảng 1.

Phương pháp CIFAR10 Mean
w/ H-Score [8] 0.386 0.642
w/ LogME [83] 0.695 0.689
w/ RankAgg (Của chúng tôi) 0.845 0.765

Liệu nhiều đặc trưng đặc thù PTM có giúp ích? Như đã đề cập trong phần 4.4, MODEL SPIDER có khả năng kết hợp các đặc trưng đặc thù PTM — lượt truyền tiến của PTM qua nhiệm vụ hạ nguồn – để cải thiện điểm xếp hạng. Khi không có đặc trưng cụ thể (k= 0), chúng tôi sử dụng token tổng quát để xếp hạng PTM (hiệu quả nhất). Trong Hình 4 (a), chúng tôi chỉ ra rằng τw tăng khi MODEL SPIDER nhận được nhiều đặc trưng đặc thù PTM hơn. Nó cân bằng sự cân bằng giữa hiệu quả và độ chính xác.

5.4 Giải thích MODEL SPIDER bằng Biểu đồ Nhện
Một sản phẩm phụ thú vị của MODEL SPIDER là chúng ta có thể trực quan hóa khả năng của PTM với biểu đồ nhện, chứng minh PTM giỏi trong những lĩnh vực nào. Chúng tôi phân cụm các tập dữ liệu trong kho mô hình đa nguồn thành sáu nhóm chính. Sau đó, chúng tôi xấp xỉ khả năng của PTM trên sáu loại nhiệm vụ với độ tương tự trung bình giữa PTM và các nhiệm vụ trong cụm. Độ tương tự càng lớn, PTM hoạt động càng tốt trên nhiệm vụ đó. Trong Hình 4 (b), chúng tôi thấy rằng một PTM được huấn luyện trước trên tập dữ liệu AID hoạt động tốt trên các nhiệm vụ y tế và viễn thám, và một PTM được huấn luyện trước trên tập dữ liệu NABirds cho thấy khả năng mạnh mẽ trong nhận dạng chim và động vật. Biểu đồ nhện sẽ giúp giải thích các tình huống ứng dụng của PTM và giúp đưa ra khuyến nghị PTM.

6 Kết luận
MODEL SPIDER được đề xuất học cách xếp hạng PTM cho các nhiệm vụ hiện có và có thể tổng quát hóa khả năng lựa chọn mô hình cho các nhiệm vụ chưa thấy, ngay cả với các ví dụ few-shot. Quy trình hai giai đoạn trong MODEL SPIDER cho phép nó phù hợp với nguồn lực một cách thích ứng. Một nhiệm vụ được khớp với PTM hiệu quả dựa trên token không phụ thuộc nhiệm vụ của chúng nếu nguồn lực bị hạn chế. Trong khi có ngân sách nguồn lực đầy đủ, các lượt truyền tiến hạn chế được thực hiện trên các ứng viên của PTM xếp hạng cao nhất, việc xếp hạng lại các ứng viên thông qua việc kết hợp sự phù hợp chi tiết giữa nhiệm vụ và PTM được chọn. Các token đã học giúp xây dựng biểu đồ nhện cho mỗi nhiệm vụ, minh họa mối liên quan của nó với tất cả PTM. Các token cho mô hình và nhiệm vụ hoạt động như một loại đặc tả khớp với thiết kế chính trong Learnware [87,88].

Tài liệu tham khảo
[1] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, và Michael Isard. Tensorflow: một hệ thống cho học máy quy mô lớn. Trong OSDI, 2016.

[2] Alessandro Achille, Michael Lam, Rahul Tewari, Avinash Ravichandran, Subhransu Maji, Charless C Fowlkes, Stefano Soatto, và Pietro Perona. Task2vec: Embedding nhiệm vụ cho meta-learning. Trong ICCV, 2019.

[3] Enric Boix Adserà, Hannah Lawrence, George Stepaniants, và Philippe Rigollet. GULP: một metric dựa trên dự đoán giữa các biểu diễn. Trong NeurIPS, 2022.

[4] Andrea Agostinelli, Michal Pándy, Jasper R. R. Uijlings, Thomas Mensink, và Vittorio Ferrari. Các đánh giá metric khả năng chuyển giao ổn định như thế nào? Trong ECCV, 2022.

[5] Nir Ailon và Mehryar Mohri. Học cách xếp hạng dựa trên sở thích. Machine Learning, 80(2-3):189–211, 2010.

[6] David Alvarez-Melis và Nicolò Fusi. Khoảng cách tập dữ liệu hình học thông qua vận chuyển tối ưu. Trong NeurIPS, 2020.

[7] Ann Arbor. Một hàm phúc lợi xã hội hợp lý. Seminar on Applications of Mathematics to Social Sciences, 1951.

[8] Yajie Bao, Yang Li, Shao-Lun Huang, Lin Zhang, Lizhong Zheng, Amir Zamir, và Leonidas Guibas. Một phương pháp tiếp cận lý thuyết thông tin đối với khả năng chuyển giao trong học chuyển giao nhiệm vụ. Trong ICIP, 2019.

[9] Shai Ben-David và Reba Schuller. Khai thác mối liên quan nhiệm vụ để học nhiều nhiệm vụ. Trong COLT, 2003.

[10] Shai Ben-David, John Blitzer, Koby Crammer, và Fernando Pereira. Phân tích biểu diễn cho thích ứng miền. Trong NIPS, 2006.

[11] Steiner Benoit, DeVito Zachary, Chintala Soumith, Gross Sam, Paszke Adam, Massa Francisco, Lerer Adam, Chanan Gregory, Lin Zeming, Yang Edward, Desmaison Alban, Tejani Alykhan, Kopf Andreas, Bradbury James, Antiga Luca, Raison Martin, Gimelshein Natalia, Chilamkurthy Sasank, Killeen Trevor, Fang Lu, và Bai Junjie. Pytorch: Một thư viện học sâu hiệu suất cao, kiểu bắt buộc. Trong NeurIPS, 2019.

[12] Daniel Bolya, Rohit Mittapalli, và Judy Hoffman. Lựa chọn mô hình đa dạng có thể mở rộng cho học chuyển giao tiếp cận được. Trong NeurIPS 2021, 2021.

[13] Lukas Bossard, Matthieu Guillaumin, và Luc Van Gool. Food-101–khai thác các thành phần phân biệt với random forests. Trong ECCV, 2014.

[14] Fatih Çakir, Kun He, Xide Xia, Brian Kulis, và Stan Sclaroff. Học metric sâu để xếp hạng. Trong CVPR, 2019.

[15] Ting Chen, Simon Kornblith, Mohammad Norouzi, và Geoffrey Hinton. Một khung đơn giản cho học biểu diễn trực quan đối lập. Trong ICML, 2020.

[16] Gong Cheng, Junwei Han, và Xiaoqiang Lu. Phân loại cảnh hình ảnh viễn thám: Benchmark và nghệ thuật tiên tiến. Proceedings of IEEE, 105(10):1865–1883, 2017.

[17] Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy Mohamed, và Andrea Vedaldi. Mô tả kết cấu trong tự nhiên. Trong CVPR, 2014.

[18] Adam Coates, Andrew Y. Ng, và Honglak Lee. Phân tích các mạng một lớp trong học đặc trưng không giám sát. Trong AISTATS, 2011.

[19] Aditya Deshpande, Alessandro Achille, Avinash Ravichandran, Hao Li, Luca Zancato, Charless Fowlkes, Rahul Bhotika, Stefano Soatto, và Pietro Perona. Một khung tuyến tính hóa và benchmark mới cho lựa chọn mô hình để tinh chỉnh. CoRR, abs/2102.00084, 2021.

[20] Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. BERT: huấn luyện trước transformer hai chiều sâu để hiểu ngôn ngữ tự nhiên. Trong NAACL-HLT, trang 4171–4186, 2019.

--- TRANG 10 ---
[21] Nan Ding, Xi Chen, Tomer Levinboim, Soravit Changpinyo, và Radu Soricut. Pactran: Các metric PAC-bayesian để ước tính khả năng chuyển giao của các mô hình được huấn luyện trước cho các nhiệm vụ phân loại. Trong ECCV, 2022.

[22] Yao-Xiang Ding, Xi-Zhu Wu, Kun Zhou, và Zhi-Hua Zhou. Đánh giá khả năng tái sử dụng mô hình được huấn luyện trước cho học chuyển giao dữ liệu nhỏ. Trong NeurIPS, 2022.

[23] Kshitij Dwivedi và Gemma Roig. Phân tích độ tương tự biểu diễn cho phân loại nhiệm vụ hiệu quả & học chuyển giao. Trong CVPR, 2019.

[24] Kshitij Dwivedi, Jiahui Huang, Radoslaw Martin Cichy, và Gemma Roig. Độ tương tự biểu đồ đối ngẫu: Một khung tổng quát cho lựa chọn khởi tạo trong học chuyển giao nhiệm vụ. Trong ECCV, 2020.

[25] Chen Fang, Ye Xu, và Daniel N. Rockmore. Học metric không thiên vị: Về việc sử dụng nhiều tập dữ liệu và hình ảnh web để làm mềm thiên vị. Trong ICCV, 2013.

[26] Li Fei-Fei, Rob Fergus, và Pietro Perona. Học các mô hình thị giác sinh từ vài ví dụ huấn luyện: Một phương pháp tiếp cận bayesian tăng dần được kiểm tra trên 101 danh mục đối tượng. Trong CVPR Workshops, 2004.

[27] Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre H. Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Ávila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu, Rémi Munos, và Michal Valko. Bootstrap your own latent - Một phương pháp tiếp cận mới cho học tự giám sát. Trong NeurIPS, 2020.

[28] Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun. Học residual sâu để nhận dạng hình ảnh. Trong CVPR, 2016.

[29] Patrick Helber, Benjamin Bischke, Andreas Dengel, và Damian Borth. Eurosat: Một tập dữ liệu mới và benchmark học sâu cho phân loại sử dụng đất và che phủ đất. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2019.

[30] Grant Van Horn, Steve Branson, Ryan Farrell, Scott Haber, Jessie Barry, Panos Ipeirotis, Pietro Perona, và Serge J. Belongie. Xây dựng một ứng dụng nhận dạng chim và tập dữ liệu quy mô lớn với các nhà khoa học công dân: Bản in nhỏ trong thu thập tập dữ liệu chi tiết. Trong CVPR, 2015.

[31] Gao Huang, Zhuang Liu, Kilian Q. Weinberger, và Laurens van der Maaten. Mạng convolutional kết nối dày đặc. Trong CVPR, 2017.

[32] Long-Kai Huang, Junzhou Huang, Yu Rong, Qiang Yang, và Ying Wei. Ước tính khả năng chuyển giao dễ dàng một cách bực bội. Trong ICML, 2022.

[33] Shibal Ibrahim, Natalia Ponomareva, và Rahul Mazumder. Mới hơn không phải lúc nào cũng tốt hơn: Suy nghĩ lại về các metric khả năng chuyển giao, tính đặc biệt, tính ổn định và hiệu suất của chúng. CoRR, abs/2110.06893, 2021.

[34] Menglin Jia, Luming Tang, Bor-Chun Chen, Claire Cardie, Serge J. Belongie, Bharath Hariharan, và Ser-Nam Lim. Tinh chỉnh prompt thị giác. Trong ECCV, 2022.

[35] Thorsten Joachims. Tối ưu hóa công cụ tìm kiếm bằng dữ liệu clickthrough. Trong SIGKDD, 2002.

[36] Brendan Jou và Shih-Fu Chang. Học residual chéo sâu cho nhận dạng thị giác đa nhiệm vụ. Trong ACM MM, 2016.

[37] Maurice G Kendall. Một biện pháp mới về tương quan thứ hạng. Biometrika, 30(1/2):81–93, 1938.

[38] Aditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao, và Fei-Fei Li. Tập dữ liệu mới cho phân loại hình ảnh chi tiết: Stanford dogs. Trong CVPR workshop on FGVC, tập 2, 2011.

[39] Jonathan Krause, Michael Stark, Jia Deng, và Li Fei-Fei. Biểu diễn đối tượng 3d cho phân loại chi tiết. Trong 4th International IEEE Workshop on 3D Representation and Recognition (3dRR-13), 2013.

[40] Nikolaus Kriegeskorte. Phân tích độ tương tự biểu diễn – kết nối các nhánh của khoa học thần kinh hệ thống. Frontiers in Systems Neuroscience, 2008.

[41] Alex Krizhevsky và Geoffrey Hinton. Học nhiều lớp đặc trưng từ các hình ảnh nhỏ. Báo cáo kỹ thuật, 2009.

[42] Yann LeCun, Fu Jie Huang, và Léon Bottou. Các phương pháp học cho nhận dạng đối tượng tổng quát với tính bất biến với tư thế và ánh sáng. Trong CVPR, 2004.

--- TRANG 11 ---
[43] Chunyuan Li, Jianwei Yang, Pengchuan Zhang, Mei Gao, Bin Xiao, Xiyang Dai, Lu Yuan, và Jianfeng Gao. Transformer thị giác tự giám sát hiệu quả để học biểu diễn. Trong ICLR, 2022.

[44] Da Li, Yongxin Yang, Yi-Zhe Song, và Timothy M. Hospedales. Tổng quát hóa miền sâu hơn, rộng hơn và nghệ thuật hơn. Trong ICCV, 2017.

[45] Yandong Li, Xuhui Jia, Ruoxin Sang, Yukun Zhu, Bradley Green, Liqiang Wang, và Boqing Gong. Xếp hạng các checkpoint thần kinh. Trong CVPR, 2021.

[46] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, và Baining Guo. Swin transformer: Transformer thị giác phân cấp sử dụng cửa sổ dịch chuyển. Trong ICCV, trang 9992–10002, 2021.

[47] Subhransu Maji, Esa Rahtu, Juho Kannala, Matthew Blaschko, và Andrea Vedaldi. Phân loại thị giác chi tiết của máy bay. CoRR, abs/1306.5151, 2013.

[48] Yishay Mansour, Mehryar Mohri, và Afshin Rostamizadeh. Thích ứng miền: Giới hạn học và thuật toán. Trong COLT, 2009.

[49] Loic Matthey, Irina Higgins, Demis Hassabis, và Alexander Lerchner. dsprites: Tập dữ liệu sprite kiểm tra tách rời. https://github.com/deepmind/dsprites-dataset/, 2017.

[50] Brian McFee và Gert R. G. Lanckriet. Học metric để xếp hạng. Trong ICML, 2010.

[51] Mehryar Mohri, Afshin Rostamizadeh, và Ameet Talwalkar. Foundations of Machine Learning. Adaptive computation and machine learning. MIT Press, 2012.

[52] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, và Andrew Y. Ng. Đọc chữ số trong hình ảnh tự nhiên với học đặc trưng không giám sát. Trong NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011, 2011.

[53] Cuong V Nguyen, Tal Hassner, Cedric Archambeau, và Matthias Seeger. Leep: Một biện pháp mới để đánh giá khả năng chuyển giao của các biểu diễn đã học. Trong ICML, 2020.

[54] Maria-Elena Nilsback và Andrew Zisserman. Phân loại hoa tự động trên một số lượng lớn các lớp. Trong ICVGIP, 2008.

[55] Sinno Jialin Pan và Qiang Yang. Một khảo sát về học chuyển giao. IEEE Transactions on knowledge and data engineering, 22(10):1345–1359, 2009.

[56] Michal Pándy, Andrea Agostinelli, Jasper R. R. Uijlings, Vittorio Ferrari, và Thomas Mensink. Ước tính khả năng chuyển giao bằng cách sử dụng tính tách biệt lớp bhattacharyya. Trong CVPR, 2022.

[57] Omkar M. Parkhi, Andrea Vedaldi, Andrew Zisserman, và C. V. Jawahar. Mèo và chó. Trong CVPR, 2012.

[58] Huiyan Qi, Lechao Cheng, Jingjing Chen, Yue Yu, Zunlei Feng, và Yu-Gang Jiang. Ước tính khả năng chuyển giao dựa trên kỳ vọng gradient chính. CoRR, abs/2211.16299, 2022.

[59] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, và Ilya Sutskever. Học các mô hình thị giác có thể chuyển giao từ giám sát ngôn ngữ tự nhiên. Trong ICML, 2021.

[60] Rajeev Ranjan, Vishal M. Patel, và Rama Chellappa. Hyperface: Một khung học sâu đa nhiệm vụ cho phát hiện khuôn mặt, định vị mốc, ước tính tư thế, và nhận dạng giới tính. IEEE Transactions on Pattern Analysis and Machine Intelligence, 41(1):121–135, 2019.

[61] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, và Christoph H. Lampert. icarl: Học bộ phân loại và biểu diễn tăng dần. Trong CVPR, trang 5533–5542, 2017.

[62] Cédric Renggli, André Susano Pinto, Luka Rimanic, Joan Puigcerver, Carlos Riquelme, Ce Zhang, và Mario Lucic. Mô hình nào để chuyển giao? Tìm cây kim trong đống cỏ khô đang phát triển. Trong CVPR, 2022.

[63] Michael T Rosenstein, Zvika Marx, Leslie Pack Kaelbling, và Thomas G Dietterich. Chuyển giao hay không chuyển giao. Trong NIPS Workshop on Transfer Learning, tập 898, 2005.

[64] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, và cộng sự. Imagenet large scale visual recognition challenge. International Journal of Computer Vision, 115(3):211–252, 2015.

[65] Saari, Donald G., và Vincent R. Merlin. Phương pháp copeland: I.: Các mối quan hệ và từ điển. Economic Theory, 8(1):51–76, 1996.

--- TRANG 12 ---
[66] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, và Liang-Chieh Chen. MobileNetV2: residual đảo ngược và nút cổ chai tuyến tính. Trong CVPR, 2018.

[67] Wenqi Shao, Xun Zhao, Yixiao Ge, Zhaoyang Zhang, Lei Yang, Xiaogang Wang, Ying Shan, và Ping Luo. Không phải tất cả các mô hình đều bằng nhau: Dự đoán khả năng chuyển giao mô hình trong không gian fisher tự thách thức. Trong ECCV, 2022.

[68] Jie Song, Yixin Chen, Xinchao Wang, Chengchao Shen, và Mingli Song. Khả năng chuyển giao mô hình sâu từ bản đồ gán. Trong NeurIPS, 2019.

[69] Jie Song, Yixin Chen, Jingwen Ye, Xinchao Wang, Chengchao Shen, Feng Mao, và Mingli Song. Depara: Đồ thị gán sâu cho khả năng chuyển giao kiến thức sâu. Trong CVPR, 2020.

[70] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, và Zbigniew Wojna. Suy nghĩ lại về Kiến trúc Inception cho Thị giác Máy tính. Trong CVPR, 2016.

[71] Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew Howard, và Quoc V. Le. Mnasnet: Tìm kiếm kiến trúc mạng thần kinh nhận biết nền tảng cho di động. Trong CVPR, 2019.

[72] Yang Tan, Yang Li, và Shao-Lun Huang. OTCE: Một metric khả năng chuyển giao cho các biểu diễn chéo miền chéo nhiệm vụ. Trong CVPR, 2021.

[73] Anh Tuan Tran, Cuong V. Nguyen, và Tal Hassner. Khả năng chuyển giao và độ khó của các nhiệm vụ phân loại có giám sát. Trong ICCV, 2019.

[74] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, và Illia Polosukhin. Attention is all you need. Trong NIPS, 2017.

[75] Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, và Sethuraman Panchanathan. Mạng băm sâu cho thích ứng miền không giám sát. Trong CVPR, trang 5385–5394, 2017.

[76] C. Wah, S. Branson, P. Welinder, P. Perona, và S. Belongie. Tập dữ liệu Caltech-UCSD Birds-200-2011. Báo cáo kỹ thuật CNS-TR-2011-001, Viện Công nghệ California, 2011.

[77] Zirui Wang, Zihang Dai, Barnabás Póczos, và Jaime Carbonell. Đặc trưng và tránh chuyển giao âm. Trong CVPR, 2019.

[78] Ying Wei, Yu Zhang, Junzhou Huang, và Qiang Yang. Học chuyển giao thông qua học cách chuyển giao. Trong ICML, 2018.

[79] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, và Alexander M. Rush. Transformers: Xử lý ngôn ngữ tự nhiên tiên tiến. Trong EMNLP, 2020.

[80] Fen Xia, Tie-Yan Liu, Jue Wang, Wensheng Zhang, và Hang Li. Phương pháp tiếp cận theo danh sách để học cách xếp hạng: lý thuyết và thuật toán. Trong ICML, tập 307, trang 1192–1199, 2008.

[81] Gui-Song Xia, Jingwen Hu, Fan Hu, Baoguang Shi, Xiang Bai, Yanfei Zhong, và Liangpei Zhang. aid: Một tập dữ liệu benchmark để đánh giá hiệu suất phân loại cảnh trên không. CoRR, abs/1608.05167, 2016.

[82] Jianxiong Xiao, James Hays, Krista A Ehinger, Aude Oliva, và Antonio Torralba. Cơ sở dữ liệu sun: Nhận dạng cảnh quy mô lớn từ tu viện đến sở thú. Trong CVPR, 2010.

[83] Kaichao You, Yong Liu, Jianmin Wang, và Mingsheng Long. Logme: Đánh giá thực tế các mô hình được huấn luyện trước cho học chuyển giao. Trong ICML, 2021.

[84] Kaichao You, Yong Liu, Ziyang Zhang, Jianmin Wang, Michael I Jordan, và Mingsheng Long. Xếp hạng và tinh chỉnh các mô hình được huấn luyện trước: Một mô hình mới để khai thác các hub mô hình. Journal of Machine Learning Research, 23:1–47, 2022.

[85] Amir R Zamir, Alexander Sax, William Shen, Leonidas J Guibas, Jitendra Malik, và Silvio Savarese. Taskonomy: Tách rời học chuyển giao nhiệm vụ. Trong CVPR, 2018.

[86] Zhifei Zhang, Yang Song, và Hairong Qi. Tiến triển/hồi quy tuổi bằng autoencoder đối thủ có điều kiện. Trong CVPR, trang 4352–4360, 2017.

[87] Zhi-Hua Zhou. Learnware: về tương lai của học máy. Frontiers Computer Science, 10(4):589–590, 2016.

--- TRANG 13 ---
[88] Zhi-Hua Zhou và Zhi-Hao Tan. Learnware: Các mô hình nhỏ làm việc lớn. CoRR, abs/2210.03647, 2022.

Tài liệu Bổ sung
Chúng tôi cung cấp các chi tiết bị bỏ qua trong bài báo chính.

• Phụ lục A: Quy trình làm việc của MODEL SPIDER, bao gồm việc xây dựng token mô hình-nhiệm vụ, huấn luyện và kiểm tra, với định dạng "cách làm" và "trả lời".

• Phụ lục B: Thiết lập thí nghiệm và chi tiết triển khai của MODEL SPIDER, đặc biệt là hai loại kho mô hình huấn luyện trước được sử dụng trong phần thí nghiệm.

• Phụ lục C: Kết quả thí nghiệm bổ sung được thực hiện theo các chiều khác nhau của phân tích độ bền vững.

• Phụ lục D: Mô tả tập dữ liệu bổ sung và các chi tiết khác được đề cập trong văn bản chính.

• Phụ lục E: Thảo luận và khám phá tương lai của MODEL SPIDER.

A Chi tiết và Thảo luận về MODEL SPIDER
Trong phần phương pháp của văn bản chính, chúng tôi làm rõ quy trình làm việc toàn diện để huấn luyện và kiểm tra việc triển khai MODEL SPIDER. Quy trình này bao gồm ba bước chính, bao gồm (1) việc trích xuất token nhiệm vụ, (2) việc trích xuất token mô hình, và (3) việc xây dựng một sơ đồ huấn luyện đánh giá thứ hạng của sự khớp giữa token mô hình-nhiệm vụ, từ đó thiết lập thứ hạng sự thật của kho mô hình cho một nhiệm vụ đã cho. Khi ba bước này đã được hoàn thành, giai đoạn tiếp theo bao gồm việc huấn luyện MODEL SPIDER bằng cách tận dụng các token được trích xuất kết hợp với thông tin sự thật được xếp hạng.

Về bản chất, chiến lược kiểm tra và triển khai được sử dụng bởi khung MODEL SPIDER thể hiện sự cân bằng giữa tính linh hoạt và hiệu quả. Bằng cách sử dụng một bộ trích xuất đặc trưng cố định ψ để có được token liên quan đến các nhiệm vụ đích hạ nguồn, MODEL SPIDER được huấn luyện trải qua một lần suy luận duy nhất, tạo ra một đầu ra định lượng độ tương tự giữa mỗi token mô hình và token nhiệm vụ hạ nguồn. Sau đó nó hoàn thành nhiệm vụ xếp hạng PTM.

Trong các phần sắp tới, chúng tôi trình bày chi tiết dưới dạng câu hỏi "cách làm". Quá trình huấn luyện của MODEL SPIDER được minh họa trong Thuật toán 1, trong khi quy trình lấy mẫu cho các nhiệm vụ huấn luyện được trình bày chi tiết trong phần A.2. Ngoài ra, trong phần A.6, chúng tôi trình bày về chiến lược huấn luyện của token nhiệm vụ Đặc thù PTM. Tương tự, quy trình kiểm tra của MODEL SPIDER được trình bày trong Thuật toán 2, và trong phần A.7, chúng tôi cung cấp một giải thích toàn diện về toàn bộ quy trình triển khai để xếp hạng các mô hình được huấn luyện trước.

A.1 Cách xây dựng token mô hình và token nhiệm vụ
Phần này bổ sung chi tiết của phần 4.2 và phần 4.4, tức là việc xây dựng token mô hình-nhiệm vụ, bao gồm cả những token đặc thù PTM được làm giàu.

Token PTM. Chiều của token PTM, tức là d của θ∈Rd được triển khai là 1024. Đây là một tham số có thể học được tối ưu hóa với quá trình huấn luyện.

Token Nhiệm vụ. ψ được triển khai bởi một EsViT dựa trên Swin-B được huấn luyện trước [46,43] (liên kết tại https://github.com/microsoft/esvit), học tự giám sát trên ImageNet-1K [64] với kích thước batch 512. Trong các thí nghiệm của chúng tôi, bộ mã hóa này hoạt động như một bộ trích xuất đặc trưng trường rộng và được cố định mà không cập nhật. Hình dạng của token nhiệm vụ µ(T)∈Rd×CT thay đổi theo số lượng danh mục của các nhiệm vụ hạ nguồn. Như đã đề cập trong phần 4.4, các token nhiệm vụ được làm giàu bởi các đặc trưng đặc thù PTM được thu thập thông qua lượt truyền tiến của PTM. Chúng tôi sử dụng một lớp kết nối đầy đủ khác để chiếu đặc trưng đặc thù PTM để căn chỉnh với token mô hình.

A.2 Cách lấy mẫu các nhiệm vụ huấn luyện của MODEL SPIDER
Chúng tôi lấy mẫu các nhiệm vụ để huấn luyện MODEL SPIDER từ các tập dữ liệu bổ sung tách rời khỏi các nhiệm vụ hạ nguồn. Những tập dữ liệu bổ sung này có những khác biệt đáng chú ý và bao gồm các miền đa dạng. Đáng chú ý, MODEL SPIDER không yêu cầu dữ liệu bổ sung đáng kể để huấn luyện. Chúng tôi

--- TRANG 14 ---
PTM-1
NCE:
LEEP:
LogME:
> > >
PTM-2 PTM-3 PTM-4
RankAgg
> > >
> > > > > >

Hình 5: Minh họa phương pháp tổng hợp thứ hạng để tổng hợp việc xếp hạng PTM dựa trên các phương pháp đánh giá khả năng chuyển giao đa dạng (ba phương pháp được mô tả trong hình). Những PTM vượt trội hơn nhiều PTM khác nên được đặt lên phía trước.

lấy mẫu các nhiệm vụ huấn luyện từ một nhóm đa dạng các tập dữ liệu. Số lượng và kích thước của các tập dữ liệu hỗn hợp được kiểm soát trong một phạm vi nhất định. Để biết thêm chi tiết, vui lòng xem Phụ lục B.

A.3 Cách thấy mối quan hệ giữa RankAgg và MODEL SPIDER
Chúng tôi tuyên bố rằng RankAgg do chúng tôi đề xuất không thể được coi là một phương pháp baseline trực tiếp. Thứ nhất, RankAgg liên quan đến một gánh nặng tính toán đáng kể khi được sử dụng như một phương pháp độc lập để xếp hạng PTM. Điều này chủ yếu do yêu cầu về thời gian và bộ nhớ của việc tính toán các phương pháp lựa chọn cơ bản. Việc sử dụng RankAgg trực tiếp làm baseline sẽ đưa ra một gánh nặng tính toán đáng kể. Tuy nhiên, chúng tôi giới thiệu RankAgg như một phương pháp sự thật xấp xỉ cho việc tính toán trước trong phần huấn luyện của MODEL SPIDER. Nó hiệu quả hơn so với việc tinh chỉnh tham số đầy đủ.

Thực tế, MODEL SPIDER nhằm chứng minh khả năng tổng quát hóa rộng rãi của nó bằng cách tận dụng RankAgg để xử lý một tập hợp độc lập dữ liệu hỗn hợp không có sự trùng lặp với dữ liệu kiểm tra. Đánh giá độc lập này thể hiện hiệu quả của MODEL SPIDER trong tình huống thực tế và nhấn mạnh khả năng xử lý dữ liệu đa dạng một cách hiệu quả. Bản thân RankAgg không đóng vai trò trong quá trình thực thi kiểm tra của MODEL SPIDER.

A.4 Cách xấp xỉ hiệu quả sự thật huấn luyện của MODEL SPIDER
Phần này bổ sung phần 4.4, trong đó việc huấn luyện và xếp hạng kho mô hình trên nhiều tập dữ liệu được thảo luận. Tuy nhiên, việc có được thứ hạng cho tất cả các nhiệm vụ lịch sử thông qua brute force là tốn kém về mặt tính toán. Để giảm thiểu vấn đề này, chúng tôi giới thiệu một phương pháp tổng hợp thứ hạng được ký hiệu là RankAgg, phục vụ như một xấp xỉ của thứ hạng sự thật.

Các phương pháp lựa chọn PTM hiện có dựa vào các đặc trưng đặc thù PTM Φm T để ước tính điểm khả năng chuyển giao. Các phương pháp khác nhau có thể có giá trị điểm đa dạng — một PTM sẽ được đặt ở các vị trí khác nhau dựa trên các điểm được cung cấp bởi các phương pháp khác nhau. Chúng tôi quan sát thực nghiệm rằng một số phương pháp phổ biến như NCE [73], LEEP [53], và LogME [83,84] cho thấy thứ tự xếp hạng PTM "tốt nhưng đa dạng", vì vậy một phương pháp tiếp cận trực giác để cải thiện chất lượng ước tính khả năng chuyển giao là tổng hợp kết quả xếp hạng của chúng thành một thứ tự đơn mạnh hơn.

Như đã đề cập trong phần 4.3, cho {ˆt1,ˆt2, . . . , ˆtA} là nhiều thứ hạng trên cùng một tập hợp M PTM cho một nhiệm vụ đích T, tức là thứ tự được sắp xếp bởi các ước tính khả năng chuyển giao thông qua các phương pháp khác nhau, chúng tôi tận dụng phương pháp tổng hợp Copeland [7, 65] để tổng hợp các thứ tự.

¯t={¯tϕm→T}M m=1= RankAgg {ˆt1,ˆt2, . . . , ˆtA} . (7)

Tổng hợp Copeland so sánh từng cặp ứng viên xếp hạng và xem xét tất cả sở thích để xác định cái nào trong hai cái được ưa thích hơn như được minh họa trong Hình 5.

Lấy mô hình m, m′ làm ví dụ, chúng tôi định nghĩa mối quan hệ đa số để thể hiện sự thống trị một-đối-một giữa hai mô hình này. Chính xác, giả định rằng Am phương pháp xếp hạng mô hình m trên mô hình m′, tức là ˆti,m>ˆti,m′ với Am× như vậy ˆti, trong khi Am′ còn lại làm ngược lại. Lưu ý rằng Am+Am′=A. m >M m′ chỉ trong trường hợp Am> A m′, và tương ứng m=M m′ chỉ ra Am=Am′. Tóm lại, chúng tôi định nghĩa điểm tổng hợp cho mô hình m như:

¯tϕm→T= #{i|m >Mi}+ 1 2 #{i|m=Mi}, (8)

--- TRANG 15 ---
Thuật toán 1 Phần Huấn luyện của MODEL SPIDER
1: Đầu vào: ψ cố định, tham số có thể học Θ, bao gồm token mô hình {θm}M m=1, FC cho phép chiếu, và tham số của MODEL SPIDER dựa trên transformer
2: Lấy mẫu các nhiệm vụ huấn luyện {Ti} từ các tập dữ liệu hỗn hợp bổ sung như trong phần A.2
3: Trích xuất và lưu tất cả token nhiệm vụ S i{µ(Ti)} với ψ.
4: for all nhiệm vụ Ti được lấy mẫu do
5: for m= 1 to M do
6: if các đặc trưng đặc thù PTM thứ m có sẵn (ngẫu nhiên giữ) then
7: Tạo ra token nhiệm vụ đặc thù PTM như đã đề cập trong phần 4.4.
8: ˆtϕm→Ti= sim Θ θm,P⊤ mµm(Ti) .
9: else
10: Lấy token mô hình θm và ước tính độ tương tự của các cặp model-token như Phương trình 6.
11: ˆtϕm→Ti= sim Θ(θm,µ(Ti)).
12: end if
13: end for
14: Từ for trên, việc ước tính điểm của MODEL SPIDER ˆt được tiến hành.
15: Tính H-Score, NCE, LEEP, và LogME trên Ti.
16: Tổng hợp trên kết quả của các phương pháp hiện có để có được sự thật ¯t như trong phần 4.3.
17: ¯t={¯tϕm→Ti}M m=1= RankAgg( {ˆt1,ˆt2, . . .}).
18: Tối ưu hóa các tham số của MODEL SPIDER với mất mát xếp hạng ℓrank w.r.t. thứ hạng của ¯t.
ℓrank(ˆt,t) = M X m=1 −log  expˆtdsc(m) PM l=m expˆtdsc(l) ! .
19: Tính ∇Θℓrank và cập nhật các tham số tương ứng với gradient
20: end for
21: Đầu ra: Θ đã học, bao gồm {θm}M m=1, FC, và tham số của MODEL SPIDER

trong đó #{·} là kích thước của tập hợp. Điểm tổng hợp cho một mô hình là số lượng mô hình khác mà chúng có sở thích đa số cộng với một nửa số lượng mô hình mà chúng có sự ràng buộc sở thích. Trong triển khai của chúng tôi, chúng tôi tổng hợp kết quả của NCE, LEEP, LogME, và H-Score.

RankAgg có thể trở nên khá tốn thời gian khi tính toán điểm xếp hạng PTM cho toàn bộ tập dữ liệu, chủ yếu do gánh nặng đáng kể của việc tính toán các phương pháp lựa chọn cơ bản. Trong thiết lập thí nghiệm của chúng tôi, chúng tôi tích hợp phương pháp RankAgg như một mô-đun trong giai đoạn huấn luyện, cho phép chúng tôi tính toán trước các thứ hạng cho mỗi nhiệm vụ. RankAgg có thể làm tăng gánh nặng tính toán nếu được sử dụng trực tiếp như một baseline kiểm tra. Do đó, chúng tôi sử dụng RankAgg cho các nhiệm vụ few-shot được lấy mẫu để cân bằng độ chính xác xếp hạng với hiệu quả và chỉ sử dụng nó trong phần huấn luyện. Lưu ý rằng MODEL SPIDER học dựa trên kết quả RankAgg, nhưng được triển khai độc lập với cả nó và các phương pháp baseline khác. Vì RankAgg tóm tắt khả năng tổng quát hóa PTM trên các nhiệm vụ phân biệt trải rộng nhiều miền, mô hình của chúng tôi có được từ các thứ hạng được tổng hợp trước có thể học khả năng xếp hạng PTM trên một loạt rộng hơn các nhiệm vụ chưa thấy.

A.5 Cách học độ tương tự của token mô hình-nhiệm vụ
Phần này trình bày chi tiết phần 4.1, tức là quá trình học của MODEL SPIDER, đặc biệt là việc ước tính dựa trên Transformer. Mô-đun độ tương tự mô hình-nhiệm vụ dựa trên Transformer. Token mô hình-nhiệm vụ được nối như một chuỗi các đặc trưng. Mô-đun dựa trên Transformer tự nhiên

--- TRANG 16 ---
Thuật toán 2 Phần Suy luận Hạ nguồn của MODEL SPIDER
Đầu vào: nhiệm vụ đích T, ψ cố định, Θ đã học
Có được token nhiệm vụ µ(T) với ψ như Phương trình 5.
Ước tính độ tương tự của các cặp model-token như Phương trình 6
ˆt=ˆtϕm→T= sim Θ(θm,µ(T))	M m=1.
Chọn k PTM hàng đầu thông qua ˆt=ˆtϕm→T	M m=1.
Có được các chỉ số theo thứ tự giảm dần thông qua dsc (·).
for m= dsc (1) to dsc (k) do
Tái tạo token làm giàu µm(T), và cập nhật:
ˆtϕm→T= sim Θ θm,P⊤ mµm(T)
end for
Đầu ra: Xếp hạng PTM với ˆt=ˆtϕm→T	M m=1

phù hợp và nhận đầu vào như vậy. Cụ thể, trong hoạt động, transformer ( ·) được hình thức hóa như:

transformer ( z) =z+α(Q,K,V=z)
=z+ softmax  zWQ·(zWK)⊤ √ d ! zWV. (9)

chúng tôi áp dụng các phép chiếu tuyến tính trên query, key, và values bằng cách sử dụng WQ,WK, và WV, tương ứng. Độ tương tự giữa các nguyên mẫu được đo bằng tích trong của không gian được biến đổi, dẫn đến trọng số lớn hơn của head attention α. Ở đây d là kích thước của mỗi head attention. Đầu ra của vị trí tương ứng của token mô hình được chuyển tiếp qua một MLP có thể học và sau đó có được điểm ước tính phù hợp của việc lựa chọn PTM.

Các tham số có thể học trong MODEL SPIDER. Để học một bộ xếp hạng PTM, chúng tôi tối ưu hóa M token mô hình {θm}M m=1, các đầu chiếu lớp kết nối đầy đủ của token nhiệm vụ đặc thù PTM Φm Ti (được đề cập trong phần 4.4) và bộ đánh giá độ tương tự mô hình-nhiệm vụ dựa trên transformer sim(·,·), đây là mô-đun ánh xạ và ước tính chính (được đề cập trong phần 4.2).

A.6 Cách xếp hạng lại với token nhiệm vụ đặc thù PTM
Như được mô tả trong phần 4.4 của văn bản chính, chúng tôi ban đầu trích xuất các đặc trưng tổng quát bằng cách sử dụng ψ cố định và tiến hành với token nhiệm vụ bất biến trên tất cả PTM. Những đặc trưng này được sử dụng để tạo ra một thứ hạng thô bằng cách so sánh độ tương tự giữa mỗi token nhiệm vụ và token mô hình. Tuy nhiên, thứ hạng này chỉ dựa trên một biểu diễn nhiệm vụ được chuẩn hóa và không tính đến thông tin liên quan đến nhiệm vụ cụ thể cho mỗi PTM riêng lẻ.

Do đó, chúng tôi đề xuất chiến lược xếp hạng lại nhắm mục tiêu cụ thể vào k PTM hàng đầu. Trong giai đoạn kiểm tra, chúng tôi tận dụng thứ hạng thô và thực hiện suy luận trên nhiệm vụ hạ nguồn với những k PTM hàng đầu này. Những token nhiệm vụ đặc thù PTM như vậy được làm việc để cập nhật độ tương tự của chúng với nhiệm vụ hạ nguồn, như được nêu trong Thuật toán 2. Đáng chú ý, trong dòng thứ ba của thuật toán, chúng tôi tiến hành xếp hạng lại dựa trên điểm độ tương tự được sửa đổi thu được thông qua quá trình này.

A.7 Cách triển khai MODEL SPIDER để kiểm tra
Đối với một nhiệm vụ hạ nguồn mới, chúng tôi sử dụng bộ trích xuất đặc trưng tổng quát ψ để trích xuất token nhiệm vụ. Sau đó chúng tôi đánh giá độ tương tự giữa mỗi PTM trong kho mô hình và nhiệm vụ hạ nguồn đã cho bằng cách sử dụng token mô hình đã học và MODEL SPIDER dựa trên transformer. Nếu nguồn lực tính toán có sẵn, chúng tôi có thể tận dụng kết quả từ vòng trước để tăng cường quá trình xếp hạng. Cụ thể, chúng tôi có thể chọn k PTM hàng đầu từ thứ hạng trước, trích xuất các đặc trưng của chúng, và áp dụng phương pháp xếp hạng lại như được mô tả trong phần A.6.

--- TRANG 17 ---
B Thiết lập Thí nghiệm và Chi tiết Triển khai
Trong phần này, chúng tôi giới thiệu thiết lập thí nghiệm và chi tiết triển khai, bao gồm xây dựng kho mô hình được huấn luyện trước và huấn luyện cũng như triển khai MODEL SPIDER.

B.1 Kho mô hình không đồng nhất nguồn đơn
Xây dựng kho mô hình. Chúng tôi theo [83] và xây dựng một kho mô hình với 10 PTM được huấn luyện trước trên ImageNet [64] qua 5 họ kiến trúc có sẵn từ PyTorch. Cụ thể, chúng là Inception V1 [70], Inception V3 [70], ResNet 50 [28], ResNet 101 [28], ResNet 152 [28], DenseNet 121 [31], DenseNet 169 [31], DenseNet 201 [31], MobileNet V2 [66], và NASNet-A Mobile [71]. Kho mô hình bao gồm PTM của nhiều số lượng tham số. Những mô hình huấn luyện trước này bao gồm hầu hết các mô hình huấn luyện trước có giám sát mà các nhà nghiên cứu sử dụng.

Các nhiệm vụ hạ nguồn. Có 9 nhiệm vụ hạ nguồn từ các lĩnh vực khác nhau, bao gồm Aircraft [47], Caltech101 [26], Cars [39], CIFAR10 [41], CIFAR100 [41], DTD [17], Pets [57], và SUN397 [82] cho phân loại, UTKFace [86] và dSprites [49] cho hồi quy. Chúng tôi sử dụng phân chia train-test chính thức trên mỗi tập dữ liệu và tính toán điểm ước tính cho các phương pháp baseline trên phần huấn luyện.

Xếp hạng độ chính xác được chuyển giao của PTM (sự thật) sau khi tinh chỉnh các nhiệm vụ hạ nguồn. Chúng tôi theo You et al. [83] để có được điểm khả năng chuyển giao sự thật cũng như thứ hạng t={tϕm→T}M m=1 (M= 10) với tìm kiếm lưới cẩn thận của các siêu tham số. Cụ thể, chúng tôi tìm kiếm lưới các tốc độ học (7 tốc độ học từ 10−1 đến 10−4, cách đều theo logarit) và weight decay (7 weight decay từ 10−6 đến 10−3, cách đều theo logarit) để chọn siêu tham số tốt nhất trên tập xác thực và tính toán độ chính xác trên tập kiểm tra hạ nguồn. Việc huấn luyện và tính toán sự thật như vậy đòi hỏi một khoản đầu tư đáng kể hơn 1K giờ GPU, áp đặt gánh nặng tài chính và tính toán đáng kể. Do đó, tính khả thi của việc hoàn thành nhiệm vụ này trong những ràng buộc của việc huấn luyện MODEL SPIDER được coi là không thể đạt được.

Chi tiết lấy mẫu của các nhiệm vụ huấn luyện. Chúng tôi lấy mẫu các nhiệm vụ huấn luyện từ một nhóm đa dạng các tập dữ liệu. Các tập dữ liệu được xem xét để lấy mẫu bao gồm EuroSAT, OfficeHome, PACS, SmallNORB, STL10, và VLCS. Để đảm bảo một tập huấn luyện đại diện, chúng tôi lấy mẫu ngẫu nhiên 832 nhiệm vụ từ tất cả các tập dữ liệu. Mỗi nhiệm vụ được phân phối trên 2 đến 4 tập dữ liệu hỗn hợp và bao gồm 100 danh mục, và cho mỗi danh mục, chúng tôi chọn ngẫu nhiên 50 ví dụ. Trong trường hợp số lượng danh mục hoặc ví dụ cần lấy mẫu vượt quá giới hạn được chỉ định, chúng tôi chọn giá trị tối đa cho phép.

Thảo luận. Kho mô hình này bao gồm một số cấu trúc cổ điển được sử dụng phổ biến trong học sâu. Số lượng tham số mô hình dao động rộng rãi, với tiềm năng ứng dụng lớn. Vẫn còn tình huống mà PTM với quy mô lớn hơn có xu hướng hoạt động tốt hơn trong các nhiệm vụ phân loại và hồi quy, làm cho một số thứ hạng luôn tốt hơn trên một số tập dữ liệu.

B.2 Kho mô hình không đồng nhất đa nguồn
Xây dựng Kho Mô hình. Như đã đề cập trong văn bản chính, chúng tôi xây dựng một kho mô hình lớn trong đó 42 PTM không đồng nhất được huấn luyện trước từ nhiều tập dữ liệu trong các miền khác nhau, bao gồm động vật [30,38], đối tượng tổng quát và 3D [26,42,41,39,13], thực vật [54], dựa trên cảnh [82], viễn thám [81,16,29] và nhận dạng đa miền [44]. Các tập dữ liệu cụ thể là Caltech101 [26], Cars [39], CIFAR10 [41], CIFAR100 [41], SUN397 [82], Dogs [38], EuroSAT [29], Flowers [54], Food [13], NABirds [30], PACS [44], Resisc45 [16], SmallNORB [42] và SVHN [52]. Cấu trúc của các mô hình là 3 kiến trúc có độ lớn tham số tương tự, tức là Inception V3 [70], ResNet 50 [28] và DenseNet 201 [31]. Thiết lập của kho mô hình không đồng nhất đa nguồn bao gồm dữ liệu huấn luyện trước đáng kể nhiều hơn so với kho không đồng nhất nguồn đơn được mô tả ở trên. Chúng tôi huấn luyện trước các mô hình với 3 cấu trúc trên 14 tập dữ liệu được đề cập ở trên (3×14 = 42, được khởi tạo từ trọng số của các mô hình được huấn luyện trước ImageNet tương ứng).

Các nhiệm vụ hạ nguồn. Chúng tôi chọn 3 tập dữ liệu đại diện làm nhiệm vụ kiểm tra hạ nguồn và tiến hành các phương pháp lựa chọn PTM trên chúng. Cụ thể, chúng là Aircraft [47], DTD [17] và Pets [57]. Như được nêu trong mô tả sau, chúng tôi có được độ chính xác tinh chỉnh được chuyển giao (sự thật) với một mức độ tương đương của các chiến lược tìm kiếm siêu tham số.

Xếp hạng độ chính xác được chuyển giao (sự thật). Tương tự, chúng tôi áp dụng học có giám sát hạ nguồn với tối ưu hóa bằng mất mát cross-entropy. Chúng tôi tiến hành tỉ mỉ một tìm kiếm lưới của các siêu tham số,

--- TRANG 18 ---
Aircraft Caltech101 Cars CIFAR10 CIFAR100 DTD Pets SUN397
Tác vụ Huấn luyện Ít hơn
Tác vụ Huấn luyện Ít hơn Của chúng tôi (báo cáo)
Bộ trích xuất ψ Đơn giản hơn
Bộ trích xuất ψ Đơn giản hơn Của chúng tôi (báo cáo)
Tương quan (𝜏𝑤)
0.1
0.2
0.3
0.4
0.5
0.6
0.7

Hình 6: Các nghiên cứu ablation về ψ đơn giản hơn và ít nhiệm vụ huấn luyện hơn. Chúng tôi quan sát thấy một sự giảm nhẹ về hiệu suất khi sử dụng một bộ trích xuất đặc trưng cố định ψ yếu hơn cho MODEL SPIDER. Việc giảm đa dạng của các nhiệm vụ huấn luyện có thể dẫn đến sự suy giảm hiệu suất trên một số tập dữ liệu.

10 20 30 40 50 60
Số lượng ví dụ mỗi lớp
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
Tương quan (𝜏𝑤)
H-Score
NCE
LEEP
N-LEEP
LogME
RankAgg
(a) trên Aircraft

20 40 60
Số lượng ví dụ mỗi lớp
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
Tương quan (𝜏𝑤)
H-Score
NCE
LEEP
N-LEEP
LogME
RankAgg
(b) trên Caltech101

Hình 7: Tương quan (τw) cho số lượng ví dụ mỗi lớp khác nhau trên (a) Aircraft và (b) Caltech101. MODEL SPIDER cho thấy kết quả ổn định và đầy hứa hẹn trong tình huống low-shot.

như bộ tối ưu hóa, tốc độ học, và weight decay (2 bộ tối ưu hóa là SGD hoặc Adam, 6 tốc độ học từ 5×10−2 đến 10−4, và 3 giá trị weight decay từ 5×10−4 đến 10−5, kích thước batch 128, và epoch tối đa 100). Đối với tập dữ liệu đa miền, như PACS [44], chúng tôi đặt tập kiểm tra cùng miền với tập huấn luyện để tiết lộ hiệu suất trong miền. Đối với phần còn lại, chúng tôi sử dụng phân chia train-test chính thức. Chúng tôi xây dựng kho mô hình với khoảng 5K giờ GPU (trên GPU NVIDIA V100). Tương tự, khi xử lý kho mô hình mở rộng, việc sử dụng các phương pháp huấn luyện nghiêm ngặt để có được sự thật cần thiết cho việc huấn luyện MODEL SPIDER bị từ chối.

Chi tiết lấy mẫu của các nhiệm vụ huấn luyện. Quá trình lấy mẫu cho kho mô hình không đồng nhất đa nguồn nhất quán với kho nguồn đơn được đề cập ở trên. Trong trường hợp này, chúng tôi sử dụng các tập dữ liệu sau làm tập phụ trợ, tức là Caltech101, Cars, CIFAR10, CIFAR100, Dogs, EuroSAT, Flowers, Food, NABirds, PACS, Resisc45, SUN397, và SVHN. Chúng tôi lấy mẫu ngẫu nhiên 4352 nhiệm vụ để huấn luyện.

Thảo luận. Sự sẵn có của kho mô hình không đồng nhất đa nguồn giới thiệu một loạt mô hình rộng hơn với các cấu trúc khác nhau, bao gồm hiệu quả một phạm vi rộng hơn của kiến thức miền. Do đó, sự đa dạng tăng cao này đưa ra một khó khăn tăng trong việc xếp hạng PTM chính xác. Đặc biệt, khi một khoảng cách đáng kể tồn tại giữa các đặc điểm của các nhiệm vụ hạ nguồn và các PTM chính, độ chính xác xếp hạng của một số phương pháp baseline trải qua sự suy giảm mạnh.

C Kết quả Thí nghiệm Bổ sung
C.1 Các nghiên cứu ablation về ψ đơn giản hơn và ít nhiệm vụ huấn luyện hơn
Chúng tôi triển khai kinh nghiệm bổ sung với các điều kiện yếu hơn để xác minh tính bền vững của MODEL SPIDER. Trong Hình 6, chúng tôi đầu tiên giới thiệu một ψ đơn giản hơn bị suy yếu, bộ mã hóa bổ sung ngoại trừ PTM trong kho mô hình. Chúng tôi nhập định dạng tiny được huấn luyện trước Swin-Transformer từ EsViT (về điều này, vui lòng tham khảo phần A.1 để biết thêm chi tiết). Nó có khoảng một nửa số lượng tham số. Kết quả cho thấy rằng mặc dù ψ bị suy yếu chỉ có một nửa tham số, nó vẫn có thể hỗ trợ MODEL SPIDER trong việc thể hiện token nhiệm vụ.

Sau đó chúng tôi giảm một nửa các nhiệm vụ huấn luyện để xác minh tầm quan trọng của sự đa dạng phần huấn luyện. Chúng tôi thấy rằng ngoại trừ sự suy giảm hiệu suất của tập dữ liệu DTD, những tập khác vẫn có hiệu suất ngang bằng. MODEL SPIDER học các đặc điểm của các chiều khả năng PTM khác nhau tốt mặc dù thiếu vắng các nhiệm vụ huấn luyện.

--- TRANG 19 ---
Bảng 5: Các nghiên cứu ablation về hiệu suất của MODEL SPIDER khi kho mô hình được huấn luyện trước tăng trưởng động.

MODEL SPIDER Aircraft Caltech101 Cars CIFAR10 CIFAR100 DTD Pets SUN397 Mean
Khi số lượng PTM tăng
w/ số lượng 3 0.545 1.000 1.000 1.000 0.182 1.000 1.000 1.000 0.841
tăng lên 6 0.573 0.627 0.818 0.905 0.839 0.445 0.888 0.336 0.679
tăng lên 10 0.568 0.637 0.576 0.797 0.695 0.796 0.573 0.436 0.635

C.2 Các nghiên cứu ablation về ảnh hưởng của mất mát huấn luyện

Bảng 4: τw có trọng số của các biến thể MODEL SPIDER khi mục tiêu huấn luyện được triển khai bởi các hàm mất mát khác nhau. "Mean" biểu thị hiệu suất trung bình trên 8 tập dữ liệu.

Phương pháp CIFAR10 Mean
w/ MSE 0.558 0.526
w/ ListMLE [80] 0.777 0.735
w/ ℓrank (Của chúng tôi) 0.845 0.765

Như đã nêu trong văn bản chính, quá trình học của MODEL SPIDER kết hợp một mất mát xếp hạng. Để đánh giá hiệu quả của lựa chọn này, các hàm mất mát hồi quy hoặc xếp hạng thay thế, như lỗi bình phương trung bình (MSE) và ListMLE [80], được sử dụng làm thay thế. Kết quả, được trình bày trong Bảng 4, rõ ràng chứng minh rằng hàm mất mát xếp hạng được trình bày vượt trội hơn các lựa chọn thay thế khác về cả hiệu quả và tính bền vững. Đáng chú ý, khi các hàm mất mát thay thế được sử dụng, hiệu suất tổng thể của MODEL SPIDER trải qua sự suy giảm đáng kể. Những phát hiện này nhấn mạnh vai trò không thể thiếu của hàm mất mát xếp hạng trong khung của MODEL SPIDER.

C.3 Các nghiên cứu ablation về các shot khác nhau của RankAgg và các baseline khác
Chúng tôi tiến hành một phân tích ablation để so sánh RankAgg với một số phương pháp baseline trên các tập dữ liệu Aircraft và Caltech101 đối với τw của việc xếp hạng PTM. Chúng tôi kiểm tra sự thay đổi của những metric này và khoảng tin cậy tương ứng (95%) khi số lượng mẫu mỗi lớp (shot) tăng lên. Kết quả, được mô tả trong Hình 7 được cung cấp, dựa trên giá trị trung bình và khoảng tin cậy thu được từ 30 tập được lấy mẫu ngẫu nhiên cho mỗi shot. Do các ràng buộc tính toán, một số phương pháp baseline bị bỏ qua khỏi phân tích. Đáng chú ý, các phát hiện của chúng tôi tiết lộ rằng chiến lược tổng hợp thứ hạng hiệu quả hợp nhất các quan điểm đa dạng về việc xếp hạng PTM và nhất quán vượt trội hơn hiệu suất của các baseline trên hầu hết tất cả các shot.

C.4 Các nghiên cứu ablation về kho mô hình tăng trưởng động
Khi gặp phải PTM mới trong nhiệm vụ lựa chọn mô hình, token mô hình được huấn luyện trước trong MODEL SPIDER có thể được học và cập nhật động. Chúng tôi sử dụng một phương pháp học tăng dần [61] để giải quyết thách thức này. Cụ thể, chúng tôi lấy mẫu 25% nhiệm vụ đích trong đó việc xếp hạng PTM gần nhất với trung bình của tất cả và chèn độ chính xác xấp xỉ của PTM mới trên chúng. Sự thật xếp hạng được xây dựng mới này bao gồm tương quan giữa token mô hình cũ và mới, giảm ảnh hưởng của dữ liệu tăng dần không cân bằng.

Chúng tôi thực hiện các nghiên cứu ablation để điều tra hành vi của MODEL SPIDER khi kho mô hình được huấn luyện trước mở rộng động. Phân tích của chúng tôi tập trung vào cách MODEL SPIDER có thể nhanh chóng thích ứng với các PTM mới được thêm vào và tích hợp chúng vào quy trình xếp hạng. Kết quả trong Bảng 5 chứng minh rằng khi kích thước của kho mô hình tăng từ 3 lên 6 và sau đó lên 10, MODEL SPIDER thể hiện khả năng học tăng dần khuyến nghị xếp hạng cho các bổ sung mới vào kho mô hình.

Việc xếp hạng được học tăng dần cho toàn bộ kho PTM thể hiện độ chính xác thấp hơn một chút so với kết quả của việc huấn luyện trực tiếp trên tất cả PTM. Tuy nhiên, MODEL SPIDER nhất quán duy trì một mức độ hiệu suất xuất sắc.

C.5 Khoảng tin cậy cho thiết lập few-shot trong Bảng 1 của văn bản chính
Chúng tôi bao gồm khoảng tin cậy (95%) cho các thí nghiệm few-shot trong phần tương ứng của Bảng 1 cho văn bản chính. Những khoảng này được thu thập thông qua 30 thử nghiệm lặp lại, cung cấp một ước tính bền vững của sự thay đổi hiệu suất theo cách few-shot.

--- TRANG 20 ---
Bảng 6: Khoảng tin cậy (95%) cho đánh giá few-shot (10 ví dụ mỗi lớp và 30 lần thử) trong Bảng 1 của văn bản chính. Các đặc trưng cụ thể của 3 PTM xếp hạng cao nhất được sử dụng.

Phương pháp Tập dữ liệu Đích Hạ nguồn
Aircraft Caltech101 Cars CIFAR10 CIFAR100 DTD Pets SUN397
Đánh giá Few-Shot (10 ví dụ mỗi lớp)
H-Score [8] -0.014±0.14 0.078±0.13 0.375±0.09 0.018±0.12 0.005±0.14 -0.028±0.12 -0.006±0.15 0.853±0.02
NCE [73] 0.273±0.05 0.534±0.07 0.597±0.02 0.267±0.08 0.232±0.04 0.362±0.06 0.352±0.09 0.793±0.03
LEEP [53] 0.069±0.04 -0.038±0.01 0.476±0.03 0.530±0.04 0.471±0.02 -0.111±0.02 0.567±0.02 0.468±0.01
N-LEEP [45] - 0.559±0.06 0.476±0.05 0.743±0.04 0.515±0.06 0.707±0.03 0.027±0.07 0.713±0.04 0.812±0.02
LogME [83] 0.341±0.02 0.453±0.01 0.497±0.01 0.718±0.02 0.698±0.03 0.407±0.01 0.657±0.02 0.817±0.00
PACTran [21] 0.136±0.05 0.262±0.02 0.484±0.05 0.631±0.02 0.614±0.03 -0.227±0.03 0.701±0.03 0.477±0.03
OTCE [72] - 0.316±0.01 -0.050±0.00 -0.127±0.00 0.515±0.00 0.505±0.00 -0.168±0.01 0.406±0.00 0.210±0.00
LFC [19] 0.226±0.01 -0.226±0.01 -0.235±0.02 0.330±0.04 0.271±0.01 -0.669±0.03 -0.059±0.04 -0.151±0.02
Của chúng tôi 0.382±0.04 0.711±0.00 0.727±0.01 0.870±0.01 0.977±0.02 0.686±0.02 0.717±0.02 0.933±0.03

C.6 Minh họa về xếp hạng lại với token nhiệm vụ đặc thù PTM
Trong phần 4.4, chúng tôi thảo luận về token mô hình có thể học, nắm bắt hiệu suất thực nghiệm của PTM trên các nhiệm vụ huấn luyện khác nhau. Sơ đồ huấn luyện này phục vụ để tách rời token nhiệm vụ khỏi lượt truyền tiến của mỗi PTM. So với token nhiệm vụ chỉ được hướng dẫn bởi các đặc trưng tổng quát, token nhiệm vụ đặc thù PTM cung cấp manh mối thông tin hơn. Bằng cách xây dựng nó với lượt truyền tiến của PTM, chúng ta có thể kết hợp thông tin thích ứng của PTM nguồn cho các nhiệm vụ hạ nguồn.

Phương pháp của chúng tôi cho phép xếp hạng lại các thứ hạng PTM được ước tính bằng cách sử dụng token nhiệm vụ đặc thù PTM. Vì lượt truyền tiến nhiều hơn tiêu thụ nhiều nguồn lực hơn, MODEL SPIDER cải thiện thêm hiệu suất và cung cấp một lựa chọn thích ứng nguồn lực động với các đặc trưng đặc thù PTM.

Được minh họa trong Hình 8 là một ví dụ về xếp hạng lại mô hình trong bối cảnh của kho mô hình đa nguồn không đồng nhất. MODEL SPIDER, sau khi trích xuất token nhiệm vụ đặc thù PTM, đã hoàn thành một việc xếp hạng PTM chính xác hơn. Chúng tôi tái tạo token nhiệm vụ đặc thù PTM trên tập dữ liệu Dogs được huấn luyện trước. Điều tra của chúng tôi tập trung vào tập dữ liệu hạ nguồn Aircraft, và thú vị là, chúng tôi phát hiện ra rằng PTM được huấn luyện trên các tập dữ liệu đa kịch bản đa mục tiêu sở hữu lợi thế vốn có khi áp dụng cho miền máy bay. Lợi thế này có thể được quy cho khả năng nhận dạng mạnh mẽ nói chung của chúng đối với các mục tiêu đa dạng. Đáng chú ý, ngay cả các mô hình được huấn luyện trước trên tập dữ liệu Food đã thể hiện hiệu suất đặc biệt trên tập dữ liệu Aircraft. Mặc dù có sự khác biệt đáng chú ý giữa các tập dữ liệu Food và Aircraft, chúng tôi phỏng đoán rằng các mô hình được huấn luyện trước Food không chỉ thể hiện thành thạo trong việc nhận dạng nhiều mục tiêu, bao gồm các mặt hàng thực phẩm khác nhau mà còn ẩn chứa tiềm năng tiềm ẩn cho việc nhận dạng chi tiết trong miền thực phẩm. Do đó, những PTM này chuyển giao khả năng nhận dạng chi tiết của chúng sang miền máy bay. Ngược lại, tập dữ liệu Dogs, được đặc trưng bởi tập trung hẹp vào một loài sinh vật duy nhất, cản trở việc chuyển giao thành công sang nhiệm vụ Aircraft.

Sự khác biệt đáng kể giữa các tập dữ liệu đặt ra một thách thức lớn cho các phương pháp baseline thông thường, thường thất bại trong việc ưu tiên mô hình được huấn luyện trước Food. Tuy nhiên, MODEL SPIDER thành công học cách xếp hạng mô hình được huấn luyện trước Food và, thông qua một quy trình sàng lọc tỉ mỉ tiếp theo là xếp hạng lại kết quả, MODEL SPIDER xác định rằng mô hình được huấn luyện trước Caltech101 vượt trội hơn mô hình được huấn luyện trước Dogs do khả năng nhận dạng đa mục tiêu vượt trội của nó, từ đó thể hiện hiệu suất chuyển giao tăng cường.

D Chi tiết Khác
D.1 So sánh tiêu thụ thời gian và dung lượng bộ nhớ (chi tiết trong Hình 1(c))
Hình 1(c) cho thấy so sánh hiệu quả trung bình so với hiệu suất trên 5 phương pháp baseline và MODEL SPIDER. k= 0, k= 3, k= 6, k= 36, và k= 42 tương ứng với suy luận w/o các đặc trưng đặc thù PTM, w/ 3, 6, 36, và 42 cái. Theo [83], chúng tôi đo thời gian thực (giây) và dung lượng bộ nhớ (MB) với công cụ mã hóa.

--- TRANG 21 ---
Aircraft
Được Huấn luyện Trước trên SUN397
Được Huấn luyện Trước trên Dogs
Được Huấn luyện Trước trên Food
Được Huấn luyện Trước trên Caltech101
Kho Mô hình
Sự thật:
Food>SUN397>Caltech101>Dogs
Nhiệm vụ Hạ nguồn
MODEL SPIDER (Của chúng tôi):
H-Score: Caltech101>Dogs>SUN397>Food
NCE: Dogs>Caltech101>Food>SUN397
Baselines:
w/Token nhiệm vụ đặc thù PTM *
Cập nhật đo lường Dogs-pretrained
Kết quả Xấu…
42 PTM
86.86%
Xếp hạng PTM:
81.97% 80.65% 78.19%
Kết quả Xấu
w/o đặc trưng đặc thù PTM: Food>SUN397>Dogs>Caltech101
Token Nhiệm vụ Cập nhật ① × Token Mô hình Gốc
Điểm đo lường Cập nhật ②
điểm đo lường: -1.608 -2.363
-2.792 < -2.363 Cập nhật
w/ đặc trưng đặc thù PTM: Food>SUN397>Caltech101>Dogs

Hình 8: Ví dụ minh họa xếp hạng lại với việc tăng cường xếp hạng thông qua token nhiệm vụ đặc thù PTM.

Bảng 7: So sánh tiêu thụ thời gian và dung lượng bộ nhớ của tinh chỉnh, RankAgg, các phương pháp baseline khác nhau, và MODEL SPIDER để xếp hạng PTM.

Phương pháp Thời gian Thực (giây) Dung lượng Bộ nhớ (MB)
RankAgg 7,318.06 10,405.32
Tinh chỉnh (tất cả tham số) 614,497.22 13,872.81
H-Score 2,358.70 9,367.74
NCE 2,196.53 8,121.49
LEEP 2,215.06 8,209.33
N-LEEP 4,963.01 9,850.84
LogME 2,571.99 8,217.80
MODEL SPIDER (w/o Đặc trưng Đặc thù PTM) 52.36 608.01
MODEL SPIDER (w/3 Đặc trưng Đặc thù PTM) 105.19 1,386.43
MODEL SPIDER (w/6 Đặc trưng Đặc thù PTM) 175.87 1,760.28
MODEL SPIDER (w/36 Đặc trưng Đặc thù PTM) 2,180.23 7,989.35
MODEL SPIDER (w/ tất cả (42) Đặc trưng Đặc thù PTM) 2,402.77 9,954.09

D.2 Mô tả Tập dữ liệu
Chúng tôi hiển thị mô tả tập dữ liệu Bảng 8 với một số ví dụ Hình 9 được đề cập trong bài báo này.

E Thảo luận
Có hai hướng đầy hứa hẹn của MODEL SPIDER. Thứ nhất, MODEL SPIDER thể hiện đặc điểm độc đáo của việc không phụ thuộc vào lượt truyền tiến của kho mô hình, từ đó cho phép đánh giá khả năng tương thích nhiệm vụ với các mô hình học máy cổ điển. Sau đó, MODEL SPIDER có thể được áp dụng cho trường hợp khi chúng ta sử dụng các tiêu chí khác ngoài hiệu suất tinh chỉnh để đo lường sự phù hợp giữa mô hình và nhiệm vụ.

--- TRANG 22 ---
Aircraft CIFAR10 DTD Cars Caltech101 CIFAR100 STL10
NABirds Resisc 45 Pet AID PACS VLCS SUN397
Flowers CUB 2011 Dogs EuroSAT SmallNORB SVHN Food

Hình 9: Ví dụ về các tập dữ liệu.

Bảng 8: Số lượng hình ảnh huấn luyện, hình ảnh kiểm tra và lớp với liên kết để tải xuống tập dữ liệu.

Tập dữ liệu Hình ảnh Huấn luyện Hình ảnh Kiểm tra # Lớp URL
Aircraft [47] 6,667 3,333 100 https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/#aircraft
CIFAR10 [41] 50,000 10,000 10 https://www.cs.toronto.edu/~kriz/cifar.html
CIFAR100 [41] 50,000 10,000 100 https://www.cs.toronto.edu/~kriz/cifar.html
DTD [17] 3,760 1,880 47 https://www.robots.ox.ac.uk/~vgg/data/dtd/
Stanford Cars [39] 8,144 8,041 196 https://ai.stanford.edu/~jkrause/cars/car_dataset.html
Caltech101 [26] 3,060 6,084 101 http://www.vision.caltech.edu/Image_Datasets/Caltech101/
STL10 [18] 5,000 8,000 10 https://cs.stanford.edu/~acoates/stl10/
Oxford Flowers 102 [54] 2040 6149 102 https://www.robots.ox.ac.uk/~vgg/data/flowers/102/
CUB-200 [76] 5994 5793 200 http://www.vision.caltech.edu/visipedia/CUB-200-2011.html
Stanford Dogs [38] 12,000 8,580 120 http://vision.stanford.edu/aditya86/ImageNetDogs/
EuroSAT [29] 21,600 5,400 10 https://github.com/phelber/eurosat
SmallNORB [42] 24,300 24,300 5 https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/
SVHN [52] 73,257 26,032 10 http://ufldl.stanford.edu/housenumbers/
Food-101 [13] 75,750 25,250 101 https://www.tensorflow.org/datasets/catalog/food101
NABirds [30] 23,929 24,633 555 https://dl.allaboutbirds.org/nabirds
NWPU-RESISC45 [16] 25,200 6,300 45 https://www.tensorflow.org/datasets/catalog/resisc45
Oxford-IIIT Pets [57] 3,680 3,669 37 https://www.robots.ox.ac.uk/~vgg/data/pets/
AID [81] 8,000 2,000 30 https://captain-whu.github.io/AID/
PACS [44] 5,446 616 7 https://domaingeneralization.github.io/#data
VLCS [25] 4,690 2,234 5 https://github.com/belaalb/G2DM#download-vlcs
Office-Home [75] 11,231 11,231 65 https://www.hemanthdv.org/officeHomeDataset.html
SUN397 [82] 87,003 21,751 397 https://vision.princeton.edu/projects/2010/SUN/
ImageNet-1K [64] 1,281,167 50,000 1000 http://image-net.org/download

# UPSCALE: Cắt Tỉa Kênh Không Ràng Buộc

Alvin Wan Hanxiang Hao Kaushik Patnaik Yueyang Xu Omer Hadad David Güera Zhile Ren Qi Shan1

Tóm tắt
Khi mạng nơ-ron phát triển về kích thước và độ phức tạp, tốc độ suy luận giảm xuống. Để chống lại điều này, một trong những kỹ thuật nén hiệu quả nhất - cắt tỉa kênh - loại bỏ các kênh khỏi trọng số. Tuy nhiên, đối với các phân đoạn đa nhánh của mô hình, việc loại bỏ kênh có thể tạo ra các bản sao bộ nhớ trong thời gian suy luận. Lần lượt, những bản sao này làm tăng độ trễ suy luận - đến mức mô hình đã cắt tỉa có thể chậm hơn mô hình chưa cắt tỉa. Như một giải pháp thay thế, các bộ cắt tỉa thông thường ràng buộc một số kênh nhất định phải được cắt tỉa cùng nhau. Điều này hoàn toàn loại bỏ các bản sao bộ nhớ nhưng, như chúng tôi chỉ ra, làm giảm đáng kể độ chính xác. Bây giờ chúng ta có một tình thế tiến thoái lưỡng nan: Loại bỏ ràng buộc nhưng tăng độ trễ, hoặc thêm ràng buộc và làm giảm độ chính xác. Đáp lại, thông số quan trọng của chúng tôi là sắp xếp lại các kênh tại thời điểm xuất, (1) giảm độ trễ bằng cách giảm bản sao bộ nhớ và (2) cải thiện độ chính xác bằng cách loại bỏ ràng buộc. Sử dụng thông số này, chúng tôi thiết kế một thuật toán chung UPSCALE1 để cắt tỉa mô hình với bất kỳ mẫu cắt tỉa nào. Bằng cách loại bỏ ràng buộc từ các bộ cắt tỉa hiện có, chúng tôi cải thiện độ chính xác ImageNet cho các mô hình đã cắt tỉa sau huấn luyện trung bình 2.1 điểm - có lợi cho DenseNet (+16.9), EfficientNetV2 (+7.9), và ResNet (+6.2). Hơn nữa, bằng cách sắp xếp lại các kênh, UPSCALE cải thiện tốc độ suy luận lên đến 2× so với xuất cơ sở.

1. Giới thiệu
Mạng nơ-ron sâu là nội tại của một số lượng ngày càng tăng các ứng dụng thực tế, nhưng kiến trúc mạng nơ-ron đồng thời phát triển về kích thước và độ phức tạp, từ năm này sang năm khác. Điều này có vấn đề đối với một số lượng ngày càng tăng các trường hợp sử dụng với ràng buộc tài nguyên thời gian suy luận, làm cho các kỹ thuật nén mô hình trở thành một điều cần thiết.

1Apple, Cupertino, USA. Liên hệ: Alvin Wan <alvinwan@apple.com>, Qi Shan <qshan@apple.com>.

Kỷ yếu Hội nghị Quốc tế lần thứ 40 về Học máy, Honolulu, Hawaii, USA. PMLR 202, 2023. Bản quyền 2023 thuộc về (các) tác giả.

1https://github.com/apple/ml-upscale

Một trong những họ phương pháp nén mô hình hiệu quả nhất là cắt tỉa kênh, loại bỏ toàn bộ các kênh của trọng số tích chập hoặc dày đặc để giảm độ trễ thời gian suy luận. Mặc dù hiệu quả, quá trình loại bỏ kênh chính nó - mà chúng tôi gọi là bước xuất - không đơn giản và thường bị bỏ qua. Điều này dẫn đến hai lựa chọn không đồng ý cho cắt tỉa kênh: (1) Thêm ràng buộc, theo quy ước, cản trở độ chính xác, hoặc (2) loại bỏ ràng buộc và tăng độ trễ thời gian suy luận một cách không bền vững.

Đầu tiên, không có ràng buộc, việc xuất không đơn giản cụ thể cho các phân đoạn đa nhánh của mạng. Trong các phân đoạn này, các lớp từ các nhánh khác nhau có thể tất cả sử dụng cùng một bản đồ đặc trưng đầu vào và đồng thời cắt tỉa các kênh khác nhau. Điều này gây ra các chiều không tương thích và quan trọng hơn, trong thời gian suy luận, mạng sau đó phải thực hiện các bản sao bộ nhớ để đảm bảo rằng các tensor liền kề trong bộ nhớ. Những bản sao bộ nhớ này rất tốn độ trễ - đến mức các mô hình đã cắt tỉa có thể thậm chí chậm hơn các mô hình chưa cắt tỉa (Hình 2).

Thứ hai, để giải quyết điều này, các công trình sớm đã thiết lập quy ước bằng cách thêm ràng buộc (Li et al., 2017; Wen et al., 2016) - cụ thể, ràng buộc các lớp trong tất cả các nhánh của một phân đoạn để cắt tỉa cùng các kênh. Những ràng buộc này đơn giản hóa việc xuất, và kết quả là, các công trình cắt tỉa hiện đại tập trung vào kênh nào để cắt tỉa thay vì cách loại bỏ chúng trong quá trình xuất. Tuy nhiên, mặc dù có tiến bộ đáng kể trong cắt tỉa có cấu trúc, những ràng buộc này làm giảm độ chính xác (Liu et al., 2019). Theo trực giác, ràng buộc hạn chế tập hợp các mẫu cắt tỉa có thể, giới hạn hiệu quả của cắt tỉa (Hình 3).

Để giải quyết vấn đề này, thông số của chúng tôi có hai mặt: (1) sắp xếp lại các kênh có thể giữ các tập con của tensor liền kề và (2) các lát cắt liền kề của một tensor là "miễn phí" để sử dụng, không có bản sao bộ nhớ. Tóm lại, điều này cho phép chúng tôi từ bỏ các ràng buộc cắt tỉa thông thường để có được độ chính xác cao hơn. Hơn nữa, bằng cách loại bỏ các bản sao bộ nhớ, điều này cho phép tăng độ chính xác đi kèm với mức phạt độ trễ giảm.

Những thông số này tạo ra một thuật toán xuất đa mục đích Xuất Cắt Tỉa Kênh Không Ràng Buộc (UPSCALE) có thể cắt tỉa mô hình với bất kỳ mẫu cắt tỉa nào. Điều này cho phép một lớp thuật toán cắt tỉa rộng hơn bằng cách làm cho độ trễ cho các mô hình đã cắt tỉa không ràng buộc trở nên dễ chấp nhận hơn nhiều - trong một số trường hợp, gần như hoàn toàn loại bỏ các bản sao bộ nhớ ngoại lai. Công trình này mang lại ba đóng góp sau:

1. So sánh độ chính xác cắt tỉa không ràng buộc và có ràng buộc, trên nhiều heuristics cắt tỉa, kiến trúc và mức độ thưa thớt khác nhau. Cắt tỉa không ràng buộc cải thiện độ chính xác đã cắt tỉa sau huấn luyện trung bình 2.1 điểm trên ImageNet.

2. Một tiện ích xuất chung cho cắt tỉa không ràng buộc được gọi là UPSCALE, tạo ra các mô hình với thời gian suy luận nhanh hơn 2× so với xuất cơ sở. Tiện ích cắm và chạy này cho phép các nhà nghiên cứu tương lai trừu tượng hóa các mối quan tâm xuất. Theo hiểu biết tốt nhất của chúng tôi, chúng tôi là những người đầu tiên phát triển một tiện ích xuất có thể hỗ trợ các mẫu cắt tỉa không ràng buộc.

3. Công thức đồ thị của việc tối đa hóa bản sao bộ nhớ, một sự trừu tượng có thể mở ra cơ hội cho các tối ưu hóa độ trễ tiếp theo.

2. Công trình liên quan

Cắt tỉa có cấu trúc so với không có cấu trúc. Công trình cắt tỉa hiện có có thể được chia thành các phương pháp không có cấu trúc (Han et al., 2016; Molchanov et al., 2017a; Janowsky, 1989; Frantar & Alistarh, 2022; Yu et al., 2022b; He et al., 2022) và các phương pháp có cấu trúc (Anwar et al., 2017; He et al., 2017a; Sze et al., 2017; Molchanov et al., 2017b; Zhu & Gupta, 2017; Huang & Lee, 2021). Các phương pháp không có cấu trúc ngưỡng và làm bằng không các giá trị trọng số riêng lẻ, trong khi các phương pháp có cấu trúc áp đặt cấu trúc lên các mẫu thưa thớt ở các mức độ chi tiết khác nhau - từ cắt tỉa theo khối (Narang et al., 2017) đến loại bỏ toàn bộ kênh (Lee et al., 2021; Lin et al., 2020) - cái sau được gọi là cắt tỉa kênh (Wen et al., 2016). Cắt tỉa kênh là một chiến lược cắt tỉa độc đáo, vì lợi ích của nó không phụ thuộc vào các nguyên hàm ma trận thưa thớt tùy chỉnh (Buluç & Gilbert, 2012; Azad & Buluç, 2017; Baskaran & Bordawekar, 2009; Vuduc et al., 2005). Thay vào đó, lợi ích của cắt tỉa kênh bắt nguồn từ việc loại bỏ các kênh trọng số tích chập tại thời điểm xuất, giảm tiêu thụ tài nguyên tại thời gian suy luận.

Chiến lược Cắt tỉa Kênh Ngoài lợi ích độc đáo của nó, cắt tỉa kênh đưa ra một thử thách độc đáo: loại bỏ kênh là khó khăn đối với các cấu trúc liên kết phức tạp, đặc biệt khi nhiều nhánh trong một mạng sử dụng hoặc tạo ra một tensor được chia sẻ. Đáp lại, công trình trước đây (He et al., 2017b; Wen et al., 2016; Li et al., 2017) áp đặt ràng buộc lên mặt nạ cắt tỉa, hạn chế tập hợp các mẫu cắt tỉa có thể trong các phần phức tạp của mạng. Hầu hết công trình trong cắt tỉa có cấu trúc tập trung vào các khía cạnh khác của cắt tỉa, khác với việc xuất - bao gồm heuristics cho tầm quan trọng, có thể cục bộ cho một phân đoạn của mạng (Han et al., 2015) hoặc toàn cục, qua các lớp và kênh (Lee et al., 2019; Frankle & Carbin, 2019); số lượng thưa thớt cùng một lúc (Liu et al., 2017; Gale et al., 2019); và các kỹ thuật để học mặt nạ, có thể sử dụng các mạng hoặc lớp bổ sung (Huang et al., 2018; Yamamoto & Maeno, 2019; He et al., 2018) hoặc các biến phụ trợ (Guo et al., 2016; Savarese et al., 2020; Courbariaux et al., 2015; Louizos et al., 2018; Srinivas et al., 2017; Xiao et al., 2019; Bengio et al., 2013).

Đáng chú ý, những công trình này bỏ qua thách thức xuất vì hai lý do: Hầu hết các công trình (1) áp dụng mặt nạ không-một trong quá trình huấn luyện để mô phỏng cắt tỉa (He et al., 2019; 2017b; Yu et al., 2022a), mà không thực sự loại bỏ kênh; điều này có nghĩa là thách thức thả kênh từ các phân đoạn đa nhánh không bao giờ được bề mặt. Hầu hết các công trình hơn nữa (2) báo cáo FLOPs như một proxy cho độ trễ (He et al., 2019; Reed, 1993; Blalock et al., 2020; Li et al., 2022a; Miao et al., 2021; Wang et al., 2022; Li et al., 2022b; Shang et al., 2022); điều này có nghĩa là tác động độ trễ của bản sao bộ nhớ sẽ không bao giờ được nhận ra, nếu những công trình này đã loại bỏ ràng buộc. Sự kết hợp của cả hai thực hành do đó ẩn các thách thức liên quan đến xuất. Để khắc phục điều này, chúng tôi nghiên cứu xuất trực tiếp để cho phép một lớp thuật toán cắt tỉa rộng hơn, cho thấy rằng các heuristics cắt tỉa hiện có có thể đạt được độ chính xác cao hơn bằng cách đơn giản loại bỏ những ràng buộc này.

3. Phương pháp

Công trình trước đây tập trung vào chiến lược cắt tỉa, mô phỏng các mẫu cắt tỉa bằng cách "làm không", các kênh trong quá trình huấn luyện. Công trình của chúng tôi trực giao với dòng công trình này, thay vào đó tập trung vào cách xuất các mẫu cắt tỉa không ràng buộc.

Cả kênh đầu vào và đầu ra trong một kernel có thể được cắt tỉa; cắt tỉa cái trước được gọi là "cắt tỉa đầu vào" (tức là, đặt mặt nạ cắt tỉa trước lớp tích chập), và cắt tỉa cái sau được gọi là "cắt tỉa đầu ra" (tức là, đặt mặt nạ cắt tỉa sau lớp tích chập). Không mất tính tổng quát, chúng tôi sẽ tập trung vào cắt tỉa đầu vào không ràng buộc. Để xem mô tả rõ ràng về cắt tỉa đầu ra không ràng buộc, xem Phụ lục F. Chúng tôi cũng quan sát thực nghiệm rằng cắt tỉa đầu vào thường vượt trội hơn cắt tỉa đầu ra (Hình A.15, A.16), thúc đẩy sự tập trung của chúng tôi vào cắt tỉa đầu vào.

Lưu ý rằng trong suốt phần phương pháp này, chúng tôi chỉ định rõ ràng "tích chập" để dễ hiểu. Tuy nhiên, thuật toán của chúng tôi tổng quát hóa cho bất kỳ hoạt động nào mà số lượng kênh đầu vào độc lập với số lượng kênh đầu ra, chẳng hạn như các lớp dày đặc.

3.1. Bước 1 - Giảm xuống một Phân đoạn

Thuật toán của chúng tôi chia kiến trúc mạng thành các phân đoạn (Hình 4, Bước 1) - không chính thức, một tập hợp các lớp có thể được cắt tỉa độc lập với phần còn lại của mạng. Một phân đoạn bao gồm (a) các tích chập tạo ra đầu ra, được gọi là các nhà sản xuất và (b) các tích chập tiêu thụ những tensor đó, được gọi là các người tiêu dùng.

Để xác định các phân đoạn, bắt đầu từ một nhà sản xuất tùy ý. Tìm tất cả người tiêu dùng cho nhà sản xuất đó, sau đó tìm tất cả nhà sản xuất cho những người tiêu dùng đó. Lặp lại một cách lặp đi lặp lại cho đến khi cả hai tập hợp hội tụ. Xem Thuật toán 1 cho một công thức chính xác hơn.

Ví dụ, trong Hình 4 (Bước 1), bắt đầu từ nhà sản xuất A. Tìm người tiêu dùng của A: {B, D}. Tìm nhà sản xuất của họ: {A, C}. Tìm người tiêu dùng của họ: {B, D}. Chú ý tập hợp người tiêu dùng của chúng ta đã hội tụ, vì vậy phân đoạn của chúng ta hoàn thành. Phân đoạn này bây giờ có thể được cắt tỉa độc lập với phần còn lại của mạng, giảm vấn đề cắt tỉa một mạng xuống cắt tỉa một phân đoạn duy nhất. Xem Hình A.14 cho nhiều ví dụ hơn.

3.2. Tại sao Bản sao Bộ nhớ Xảy ra

Tóm tắt, bản sao bộ nhớ xảy ra khi người tiêu dùng cắt tỉa các kênh khác nhau. Để xử lý điều này, các phương pháp trước đây đơn giản ràng buộc tất cả người tiêu dùng để cắt tỉa cùng các kênh, như trong Hình 2, "Ràng buộc". Vì cả hai người tiêu dùng đều bị ràng buộc để cắt tỉa cùng các kênh, điều này rất đơn giản để xuất: Đơn giản thả các kênh đầu ra của nhà sản xuất mà tất cả người tiêu dùng cắt tỉa.

Tuy nhiên, hãy xem xét bây giờ trường hợp không ràng buộc trong Hình 2, "Không hiệu quả". Nói rằng người tiêu dùng II cắt tỉa các kênh mà người tiêu dùng III không cắt. Tại thời điểm xuất, chúng ta không thể thả các kênh mà II cắt tỉa, vì III vẫn cần nó. Thay vào đó, trong thời gian suy luận, chúng ta lựa chọn con đầu ra của nhà sản xuất - sao chép mọi kênh không cắt tỉa mà II cần vào một tensor mới - để sau đó chuyển cho II. Phương pháp này là cách tiếp cận cơ sở để xuất các mô hình đã cắt tỉa không ràng buộc. Thật không may, các bản sao bộ nhớ trong cách tiếp cận cơ sở phát sinh chi phí độ trễ đáng kể tại thời gian suy luận, đến mức mô hình đã cắt tỉa này phát sinh độ trễ cao hơn mô hình gốc, chưa cắt tỉa (Hình 7).

Thông số quan trọng của chúng tôi là các lát cắt liền kề là "miễn phí". Nói cách khác, mỗi người tiêu dùng lấy một lát cắt của tensor đầu vào, thay vì sao chép các kênh vào một tensor mới. Do đó chúng tôi thiết kế một thuật toán sắp xếp lại các kênh đầu ra nhà sản xuất và kênh đầu vào người tiêu dùng (Hình 2, "Của chúng tôi", Sec 3.6). Bây giờ chúng tôi thảo luận cách tính toán việc sắp xếp lại này.

3.3. Bước 2 - Công thức hóa như một Đồ thị

Để đơn giản hóa các giải thích, tiến lên, chúng tôi sẽ tham chiếu đến các kênh mà một người tiêu dùng giữ lại, thay vì các kênh mà nó cắt tỉa.

Để chính thức hóa mục tiêu của chúng tôi, chúng tôi công thức hóa các ràng buộc của chúng tôi như một đồ thị không định hướng (Hình 4, Bước 2): Mỗi nút trong đồ thị của chúng tôi đại diện cho tập hợp các kênh mà một người tiêu dùng giữ lại. Hai nút chia sẻ một cạnh không định hướng nếu cả hai nút chia sẻ một hoặc nhiều kênh giữ lại. Phần thưởng của mỗi nút là số lượng kênh giữ lại, và phần thưởng của mỗi cạnh là âm của số lượng kênh giữ lại được chia sẻ. Chúng tôi sẽ thảo luận tại sao ngay sau đây. Với đồ thị này, chúng tôi có thể chính thức hóa mục tiêu tối đa hóa bản sao bộ nhớ của chúng tôi.

Mục tiêu của chúng tôi là tìm một đường dẫn - hoặc nói cách khác, một chuỗi các nút: Vì mỗi nút là một người tiêu dùng, một chuỗi các nút đại diện cho một chuỗi người tiêu dùng. Lần lượt, mỗi chuỗi người tiêu dùng thừa nhận một thứ tự kênh không sao chép. Ví dụ, nói rằng chúng ta có hai người tiêu dùng với chuỗi nút A, B. Thứ tự kênh không sao chép có thể được lấy bằng cách: sắp xếp các kênh chỉ giữ lại bởi A, sau đó các kênh được chia sẻ bởi A và B, sau đó các kênh chỉ giữ lại bởi B. Việc sắp xếp này đảm bảo không bản sao bộ nhớ, vì đầu vào của cả A và B đã liền kề trong bộ nhớ. Chúng ta có thể tiếp tục vô thời hạn cho bất kỳ số lượng người tiêu dùng nào, miễn là các người tiêu dùng được sắp xếp trong một chuỗi. Tóm lại, một đường dẫn có thể được dịch thành một thứ tự kênh không sao chép. Để có nhiều ví dụ hơn, xem Phụ lục B.

Mục tiêu của chúng tôi là tìm một đường dẫn không chu kỳ: Nói rằng nút đầu tiên và cuối cùng trong đường dẫn của chúng tôi chia sẻ kênh. Bây giờ, có một tình thế tiến thoái lưỡng nan: Đặt các kênh được chia sẻ hoặc ở đầu hoặc ở cuối thứ tự kênh. Dù thế nào, ít nhất một người tiêu dùng sẽ có đầu vào của họ lan rộng không liền kề trong bộ nhớ. Tổng quát hơn, những người tiêu dùng không liền kề trong chuỗi không thể chia sẻ kênh. Nói cách khác, không có hai nút không liền kề nào có thể chia sẻ một cạnh - hoặc ngắn gọn hơn, đường dẫn phải không chu kỳ; nếu không, chúng ta sẽ cần giới thiệu các bản sao bộ nhớ bổ sung cho các kênh được chia sẻ trong quá trình suy luận.

Mục tiêu của chúng tôi là tìm đường dẫn không chu kỳ phần thưởng tối đa: Như đã đề cập trước đó, tất cả các kênh trong một đường dẫn yêu cầu không bản sao, vì vậy để giảm thiểu bản sao bộ nhớ, tối đa hóa số lượng kênh được bao gồm trong đường dẫn. Trước đây, chúng tôi đã định nghĩa phần thưởng nút và cạnh sao cho phần thưởng đường dẫn bằng số lượng kênh được bao gồm trong một đường dẫn. Kết quả là, lần lượt, tối đa hóa kênh được bao gồm tối đa hóa phần thưởng đường dẫn.

Mục tiêu cuối cùng, chính thức của chúng tôi là tìm đường dẫn không chu kỳ phần thưởng tối đa. Để có ví dụ từ đầu đến cuối về cách điều này giảm thiểu bản sao bộ nhớ, xem Phụ lục C hoặc Hình A.10.

3.4. Cách Tìm Đường dẫn Không chu kỳ Phần thưởng Tối đa

Chúng tôi bắt đầu bằng cách tính toán phần thưởng của đường dẫn phần thưởng tối đa, mà chúng tôi viết tắt là "mrp". Để tính toán phần thưởng này MRP(G) cho một đồ thị G, lặp qua tất cả các nút s trong G, và tính toán phần thưởng f(s) của mrp bắt đầu từ nút s.

MRP(G) = MAX({f(s) : s trong G}) (1)

Mục tiêu của chúng tôi bây giờ là định nghĩa f(s). Để làm như vậy, xem xét tất cả các láng giềng của nút s: n trong A[s], cho ma trận kề A. Theo trực giác, phần thưởng f(s) của mrp là tối đa (a) phần thưởng của tất cả các đường dẫn phần thưởng tối đa bắt đầu từ các nút láng giềng của nó f(n) : n trong A[s], cùng với (b) phần thưởng đi đến các nút láng giềng của nó Re[s, n], cho ma trận phần thưởng cạnh Re. Nhớ lại rằng Re là số lượng kênh được chia sẻ. Điều này được tóm tắt trong quan hệ lặp lại sau đây

f(s) = MAX({f(n) + Re[s, n] : n trong A[s]}) + Rn[s] (2)

cho ma trận phần thưởng nút Rn. Nhớ lại Rn là số lượng kênh mà một người tiêu dùng giữ lại. Điều này tìm ra đường dẫn phần thưởng tối đa, nhưng nó không xử lý ràng buộc không chu kỳ.

Lưu ý rằng đường dẫn mrp p là chuỗi nút được lấy bằng cách tối ưu hóa mục tiêu (tức là, Eqn 1) qua lập trình động.

Xử lý ràng buộc không chu kỳ: Chúng tôi viết tắt đường dẫn không chu kỳ phần thưởng tối đa là "mrap". Để xử lý ràng buộc không chu kỳ, chúng tôi định nghĩa một tập hợp các nút I, bao gồm tất cả các nút không hợp lệ. Các nút không hợp lệ bao gồm (a) các nút đã đi qua được bao gồm trong đường dẫn hiện tại, cũng như (b) các nút láng giềng đường dẫn - tức là, các nút chia sẻ một cạnh với một nút trong đường dẫn. Đường dẫn của chúng tôi được đảm bảo không chu kỳ nếu chúng tôi không bao giờ đi qua các nút láng giềng đường dẫn của chúng tôi. Chúng tôi tái định nghĩa bài toán con của chúng tôi là f(s, I), phần thưởng của mrap bắt đầu từ nút nguồn s và loại trừ các nút trong I.

Sau đó chúng tôi có thể sửa đổi mục tiêu ban đầu của chúng tôi thành như sau. Tập hợp không hợp lệ ban đầu I là nút duy nhất trong đường dẫn, {s}.

MRAP(G) = MAX({f(s, {s} | {z} I) : s trong G}) (3)

Sau đó chúng tôi có thể sửa đổi quan hệ lặp lại thành như sau. Để thuận tiện, chúng tôi tách ra định nghĩa cho g(s, n, I), đó là phần thưởng đi chỉ từ s đến n trong khi tránh tập hợp không hợp lệ I.

f(s, I) = MAX({g(s, I, n) : n trong A[s] - I}) + Rn[s]
g(s, I, n) = f(n, I hợp với {n} hợp với A[s] | {z} mở rộng I) + Re[s, n] (4)

Ít chính thức hơn, Eqn 4 loại trừ tất cả các nút không hợp lệ khi xem xét các láng giềng để đi đến. Khi xem xét mỗi nút láng giềng, chúng tôi mở rộng tập hợp không hợp lệ I bằng cách thêm chính nút láng giềng {n}, cũng như các láng giềng của nút nguồn A[s].

3.5. Bước 3 - Tính Thứ tự Kênh Từ Đồ thị

Lưu ý rằng đường dẫn không chu kỳ phần thưởng tối đa p có thể được lấy bằng cách giải quyết tối ưu hóa (tức là, Eqn 3) qua lập trình động, được ký hiệu là p ← MRAP(G). Hơn nữa, đường dẫn mrap p có thể không bao gồm tất cả các nút - ví dụ, nếu tất cả các nút nằm trong một vòng. Kết quả là, tiếp tục tìm đường dẫn trên tất cả các nút còn lại MRAP(G-p) cho đến khi không còn nút nào.

Các đường dẫn chúng tôi tìm thấy trong bước trước sau đó được dịch thành một thứ tự kênh cuối cùng. Như trong Phần 3.3 và Hình 4 (Trường hợp 2), nói rằng chúng ta có hai người tiêu dùng, A, B. Sắp xếp các kênh chỉ giữ lại bởi A, sau đó các kênh được chia sẻ bởi A và B, sau đó các kênh chỉ giữ lại bởi B. Ví dụ, nói rằng A giữ lại 1, 3 và B giữ lại 2, 3. Sắp xếp các kênh chỉ A (1), sau đó các kênh được chia sẻ (3), sau đó các kênh chỉ B (2) để tạo ra một thứ tự cuối cùng: 1, 3, 2.

Tổng quát hơn, chúng tôi ký hiệu các nút được sắp xếp trong đường dẫn mrap là p = [n1, n2, n3, ...]. Chúng tôi đầu tiên lấy tất cả các kênh chỉ được giữ lại bởi nút đầu tiên, mà chúng tôi ký hiệu là ñ1. Nút đầu tiên chỉ nên chia sẻ kênh với nút thứ hai, vì vậy điều này tương đương với việc tính toán phép trừ tập hợp:

ñ1 = n1 - n2 (5)

Tổng quát hơn, chúng tôi ký hiệu các kênh "độc đáo" cho nút i là ñi. Nút thứ i chỉ nên chia sẻ kênh với các nút trước đó ni-1 và nút tiếp theo ni+1, vì vậy lấy hiệu để tìm tất cả các kênh "độc đáo" cho nút ni.

ñi = ni - ni-1 - ni+1 (6)

Sau đó, lấy tất cả các kênh được chia sẻ bởi nút đầu tiên và thứ hai, n1 giao n2. Sau đó, lấy các kênh độc đáo cho nút thứ hai ñ2. Sau đó, lấy các kênh được chia sẻ bởi nút thứ hai và thứ ba, n2 giao n3. Tiếp tục điều này cho tất cả các nút trong đường dẫn. Thứ tự tổng thể trông như sau

ñ1 hợp (n1 giao n2) hợp ñ2 hợp (n2 giao n3) ··· (7)

Khi đường dẫn cạn kiệt, tiếp tục thứ tự với các nút trong đường dẫn tiếp theo. Khi tất cả các đường dẫn cạn kiệt, thứ tự hoàn thành. Thứ tự kênh này được tóm tắt như một ma trận hoán vị Π trong Thuật toán 1. Xem Hình 4 (Bước 3) hoặc Hình A.11 cho các ví dụ.

3.6. Bước 4 - Sắp xếp lại Trọng số

Thứ tự kênh từ bước trước sau đó được sử dụng để sắp xếp lại các kênh trong nhà sản xuất và người tiêu dùng. Đầu tiên, thứ tự kênh trực tiếp xác định thứ tự kênh đầu ra cho tất cả nhà sản xuất trong phân đoạn. Chính thức hơn, cho một danh sách trọng số mô hình W và chỉ số nhà sản xuất pi, chúng tôi ký hiệu việc sắp xếp lại kênh là W[pi]Π. Thứ hai, cho mỗi người tiêu dùng, sắp xếp lại các kênh đầu vào của người tiêu dùng tương ứng (tức là, W[ci]Π). Xem thuật toán đầy đủ trong Thuật toán 1, mô tả trong Phụ lục G hoặc ví dụ trong Hình 4 (Bước 4).

3.7. Phương pháp Tổng quát hóa

Một số nút là tập con của các nút khác. Ví dụ, người tiêu dùng A giữ lại 1, 2, 3; người tiêu dùng B giữ lại 1, 2; và người tiêu dùng C giữ lại 2, 3. A là nút cha và B, C là các nút con. Mặc dù A, B, C tạo thành một chu kỳ trong đồ thị của chúng tôi, chúng ta có thể đạt được một giải pháp không bản sao bộ nhớ phù hợp với cả ba người tiêu dùng. Đơn giản sắp xếp các kênh là 1, 2, 3. Điều này mâu thuẫn với yêu cầu đường dẫn không chu kỳ của chúng tôi. Để xử lý điều này, chúng tôi giới thiệu hai sửa đổi: (1) Các cạnh cha-con được bỏ qua khi từ chối các đường dẫn chu kỳ, và (2) Nếu các nút con trong đường dẫn bao gồm tất cả các kênh nút cha, thì phần thưởng của nút cha được thêm vào phần thưởng của đường dẫn. Để có mô tả mở rộng về trường hợp tập con này và giải pháp của nó, xem Phụ lục D.

Nhiều nhà sản xuất. Thuật toán của chúng tôi ở trên giả định chỉ có một nhà sản xuất. Để xử lý nhiều nhà sản xuất, chúng tôi tìm kênh nào tương ứng với nhau, qua các nhà sản xuất. Nói rằng đầu ra của nhà sản xuất A và B được cộng đơn giản. Trong trường hợp này, kênh 1 từ A tương đương với kênh 1 từ B. Kênh 2 từ A tương đương với kênh 2 từ B, và cứ thế tiếp tục. Biết điều này, chúng ta có thể giảm về trường hợp nhà sản xuất đơn, vì một thứ tự cho bộ lọc A tự động cung cấp thứ tự cho bộ lọc B.

Sau đó chúng ta có thể chạy phương pháp của chúng tôi giả định tích chập A là nhà sản xuất duy nhất. Sau đó, khi sắp xếp lại trọng số nhà sản xuất (tức là, bước 4), chúng tôi ánh xạ hoán vị ban đầu Π cho mỗi nhà sản xuất qua bản đồ kênh tương đương nói trên Πi. Sau đó sắp xếp trọng số bằng W[pi]ΠiΠ. Để có mô tả chi tiết hơn và ví dụ, xem Phụ lục E.

4. Thí nghiệm

Chúng tôi trình bày thí nghiệm rộng rãi để cho thấy rằng cắt tỉa không ràng buộc có thể đạt được độ chính xác cao hơn đáng kể so với cắt tỉa có ràng buộc, đặc biệt đối với các mô hình lớn hơn, hiện đại và những mô hình có cấu trúc liên kết phức tạp. Đối với những mô hình đã cắt tỉa không ràng buộc này, chúng tôi sau đó cho thấy rằng UPSCALE vượt trội hơn xuất cơ sở về độ trễ thời gian suy luận - thực tế, không có UPSCALE, độ trễ của các mô hình đã cắt tỉa thực sự tăng, làm cho UPSCALE cần thiết cho việc xuất. Tất cả các phương pháp trước đây sử dụng cắt tỉa có ràng buộc, vì vậy cho các thí nghiệm của chúng tôi, chúng tôi loại bỏ những ràng buộc đó và thay vào đó sử dụng UPSCALE để xuất.

Đối với thiết lập sau huấn luyện, cắt tỉa không ràng buộc cải thiện độ chính xác top-1 ImageNet lên đến 76.7 điểm so với cắt tỉa có ràng buộc. Mục tiêu của chúng tôi là đánh giá tác động độ chính xác của việc chuyển từ cắt tỉa có ràng buộc sang không ràng buộc. Để đơn giản, chúng tôi thích ứng một cách ngây thơ các thuật toán cắt tỉa trước đây được sử dụng cho cắt tỉa có ràng buộc, với thiết lập không ràng buộc, bằng cách loại bỏ ràng buộc trên mặt nạ cắt tỉa không-một. Để đánh giá hiệu ứng của cắt tỉa có ràng buộc hoặc không ràng buộc, độc lập với công thức huấn luyện, chúng tôi tiến hành các thí nghiệm mà không tinh chỉnh, được gọi là cắt tỉa sau huấn luyện: (1) Lấy các mô hình được huấn luyện trước trên ImageNet, (2) áp dụng các heuristics cắt tỉa khác nhau ở các mức độ thưa thớt khác nhau, và (3) đo độ chính xác xác nhận top-1 ImageNet. Chúng tôi thưa thớt hóa tham số ở khoảng 2.5% từ 0% đến 100% và kiểm tra 5 chiến lược cắt tỉa qua 15+ kiến trúc.

Mặc dù những chiến lược cắt tỉa này được thiết kế cho cắt tỉa có ràng buộc, chúng tôi thấy rằng cắt tỉa không ràng buộc đạt được độ chính xác có thể so sánh hoặc tốt hơn cắt tỉa có ràng buộc, cho một chiến thắng trung bình 2.1 điểm trung bình qua tất cả các thiết lập. Đối với một số trường hợp, đặc biệt cho các cấu trúc liên kết phức tạp và mô hình lớn hơn (Hình 3), cắt tỉa không ràng buộc mang lại lợi ích độ chính xác đáng kể, lên đến tăng 21.7 điểm (DenseNet121, L1) độ chính xác ImageNet, trung bình qua tất cả các mức độ thưa thớt - hoặc, lên đến tăng 76.7 điểm tại một mức độ thưa thớt cụ thể (EfficientNetV2-Small, LAMP, 12.5%). Điều này chứng minh rằng cắt tỉa không ràng buộc có thể cung cấp lợi ích ngoại cỡ trong các thiết lập phù hợp. Chúng tôi tóm tắt kết quả trong Hình 6 và báo cáo kết quả đầy đủ trong Hình A.22, A.23. Kết quả sơ bộ cho tinh chỉnh cũng cho thấy khoảng cách độ chính xác đáng kể (5 điểm) theo Phụ lục A, và điều tra kỹ lưỡng hơn được để lại cho công việc tương lai.

Độ trễ cải thiện lên đến 52.8% khi xuất các mô hình đã cắt tỉa sử dụng UPSCALE, khi so sánh với xuất cơ sở cho các mẫu cắt tỉa không ràng buộc - cơ sở này được mô tả trong Phần 3.2. Để đánh giá hiệu quả của thuật toán sắp xếp lại của chúng tôi một cách độc lập, chúng tôi (1) áp dụng cắt tỉa sau huấn luyện cho các mô hình được huấn luyện trước trên ImageNet; (2) xuất các mô hình đã cắt tỉa không ràng buộc có và không có UPSCALE; và (3) đo điểm chuẩn độ trễ của mô hình đã xuất. UPSCALE giảm độ trễ của mô hình đã xuất trung bình 8.6% qua tất cả các thiết lập và mang lại lợi ích độ trễ đáng kể, lên đến 24.9% (SqueezeNet1-1, L1), trung bình qua tất cả các mức độ thưa thớt - hoặc, lên đến giảm độ trễ 52.8% tại một mức độ thưa thớt cụ thể (ResNet18, FPGM). Quan trọng, xuất các mô hình đã cắt tỉa không ràng buộc mà không có UPSCALE thực sự tăng độ trễ so với mô hình gốc, chưa cắt tỉa; trong cùng thiết lập, UPSCALE có thể nhận ra giảm độ trễ phù hợp hơn.

Chúng tôi tóm tắt kết quả trong Hình 7 và 3, báo cáo kết quả đầy đủ trong Hình A.24. Lưu ý rằng không có siêu tham số nào trong thuật toán của chúng tôi có thể kiểm soát hiệu suất, vì vậy chúng tôi chạy thuật toán của chúng tôi đồng nhất trên tất cả các mô hình để có được hiệu suất đó. Chúng tôi bổ sung vẽ độ trễ cho một giải pháp không bản sao bộ nhớ lý thuyết, minh họa giảm độ trễ tối đa có thể đạt được bởi bất kỳ xuất cắt tỉa không ràng buộc nào; chúng tôi quan sát rằng UPSCALE thường thực hiện gần tối ưu, với độ trễ gần như khớp với độ trễ không bản sao bộ nhớ.

Thiết lập. Chúng tôi sử dụng một GPU V100 duy nhất với 32 GB RAM. Để xuất các mô hình để định thời, chúng tôi chạy một chiến lược cắt tỉa hiện có trên mô hình được cung cấp, xuất sử dụng UPSCALE, sau đó sử dụng jit trace của PyTorch để tạo ra một tệp thực thi không Python. Mô hình được theo dõi này sau đó được đo điểm chuẩn sử dụng tiện ích lập hồ sơ tích hợp của PyTorch, bao gồm "hoạt động" CUDA và theo dõi phân bổ bộ nhớ tensor. Lưu ý tiện ích này xử lý khởi động tự động ví dụ như chạy nhiều lần chuyển tiếp trước khi bắt đầu các lần chạy được định thời. Tất cả các phép đo độ trễ của chúng tôi là tổng hợp của 100 lần chạy, với cả mean và độ lệch chuẩn được báo cáo. Tất cả độ chính xác được báo cáo trên bộ dữ liệu xác thực ImageNet ILSVRC 2015 (Russakovsky et al., 2015).

5. Kết luận

Chúng tôi giới thiệu Xuất Cắt Tỉa Kênh Không Ràng Buộc (UPSCALE) để hỗ trợ xuất cắt tỉa một cách chung chung hơn; ngay từ đầu, UPSCALE xử lý một thách thức chủ yếu cho việc cắt tỉa mạng nơ-ron hiện đại: cụ thể, không hiệu quả bộ nhớ và do đó độ trễ. Hơn nữa, chúng tôi giới thiệu cả một khung và một giải pháp xấp xỉ để giảm thiểu không hiệu quả, bằng cách giảm bản sao bộ nhớ tại thời gian suy luận. Kết quả cuối cùng - một thư viện xuất cắt tỉa chung - mở rộng tổng diện tích bề mặt mà các thuật toán cắt tỉa hiện có và mới có thể hoạt động, bằng cách cho phép bất kỳ mẫu cắt tỉa nào được xuất và làm cho cắt tỉa không ràng buộc trở thành một thay thế cạnh tranh cho cắt tỉa có ràng buộc thông thường.

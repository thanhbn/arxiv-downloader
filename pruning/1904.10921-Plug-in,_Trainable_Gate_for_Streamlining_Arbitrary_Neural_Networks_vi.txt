# Plug-in, Trainable Gate for Streamlining Arbitrary Neural Networks
Jaedeok Kim1Chiyoun Park1Hyun-Joo Jung1Yoonsuck Choe1;2
1Trung tâm Trí tuệ Nhân tạo, Samsung Research, Samsung Electronics Co.
56 Seongchon-gil, Secho-gu, Seoul, Korea, 06765
2Khoa Khoa học Máy tính và Kỹ thuật, Đại học Texas A&M
College Station, TX, 77843, USA
fjd05.kim, chiyoun.park, hj34.jung g@samsung.com, choe@tamu.edu

Tóm tắt
Tối ưu hóa kiến trúc, một kỹ thuật để tìm ra một mạng nơ-ron hiệu quả đáp ứng các yêu cầu nhất định, thường được quy về một tập hợp các bài toán lựa chọn đa phương án giữa các cấu trúc con hoặc tham số thay thế. Tuy nhiên, tính chất rời rạc của bài toán lựa chọn làm cho việc tối ưu hóa này trở nên khó khăn. Để giải quyết vấn đề này, chúng tôi giới thiệu một khái niệm mới về hàm cổng có thể huấn luyện. Hàm cổng có thể huấn luyện, cung cấp tính chất có thể vi phân cho các biến có giá trị rời rạc, cho phép chúng ta trực tiếp tối ưu hóa các hàm mất mát bao gồm các giá trị rời rạc không thể vi phân như lựa chọn 0-1. Cổng có thể huấn luyện được đề xuất có thể được áp dụng cho việc cắt tỉa. Việc cắt tỉa có thể được thực hiện đơn giản bằng cách thêm các hàm cổng có thể huấn luyện được đề xuất vào mỗi tensor đầu ra trung gian theo sau bởi việc tinh chỉnh toàn bộ mô hình, sử dụng bất kỳ phương pháp huấn luyện dựa trên gradient nào. Vì vậy, phương pháp được đề xuất có thể đồng thời tối ưu hóa việc lựa chọn các kênh bị cắt tỉa trong khi tinh chỉnh các trọng số của mô hình bị cắt tỉa cùng lúc. Kết quả thực nghiệm của chúng tôi chứng minh rằng phương pháp được đề xuất tối ưu hóa hiệu quả các mạng nơ-ron tùy ý trong các nhiệm vụ khác nhau như phân loại hình ảnh, chuyển đổi phong cách, ước tính dòng quang học và dịch máy nơ-ron.

Giới thiệu
Mạng nơ-ron sâu đã được sử dụng rộng rãi trong nhiều ứng dụng như phân loại hình ảnh, tạo sinh hình ảnh và dịch máy. Tuy nhiên, để tăng độ chính xác của các mô hình, các mạng nơ-ron phải được làm lớn hơn và yêu cầu một lượng tính toán khổng lồ (He et al. 2016a; Simonyan and Zisserman 2014). Vì thường không khả thi để tải và thực thi một mô hình lớn như vậy trên nền tảng thiết bị di động như điện thoại di động hoặc thiết bị IoT, các phương pháp tối ưu hóa kiến trúc khác nhau đã được đề xuất để tìm ra một mạng nơ-ron hiệu quả đáp ứng các yêu cầu thiết kế nhất định. Đặc biệt, các phương pháp cắt tỉa có thể giảm hiệu quả cả kích thước mô hình và chi phí tính toán, nhưng tính chất rời rạc của các bài toán lựa chọn nhị phân làm cho các phương pháp như vậy trở nên khó khăn và không hiệu quả (He et al. 2018; Luo and Wu 2018).

Các phương pháp descent gradient có thể giải quyết một bài toán tối ưu hóa liên tục một cách hiệu quả bằng cách tối thiểu hóa hàm mất mát, nhưng các phương pháp như vậy không thể áp dụng trực tiếp cho các bài toán tối ưu hóa rời rạc vì chúng không thể vi phân. Trong khi nhiều giải pháp thay thế như simulated annealing (Kirkpatrick, Gelatt, and Vecchi 1983) đã được đề xuất để xử lý các bài toán tối ưu hóa rời rạc, chúng quá kém hiệu quả về mặt chi phí trong deep learning vì chúng ta cần huấn luyện các lựa chọn thay thế để đánh giá độ chính xác của mẫu.

Trong bài báo này, chúng tôi giới thiệu một khái niệm mới về hàm cổng có thể huấn luyện (TGF) cung cấp tính chất có thể vi phân cho các biến có giá trị rời rạc. Nó cho phép chúng ta trực tiếp tối ưu hóa, thông qua descent gradient, các hàm mất mát bao gồm các lựa chọn rời rạc không thể vi phân. Bằng cách áp dụng các TGF, mỗi cái kết nối một tham số tiềm ẩn liên tục với một lựa chọn rời rạc, một bài toán tối ưu hóa rời rạc có thể được nới lỏng thành một bài toán tối ưu hóa liên tục.

Cắt tỉa một mạng nơ-ron là một vấn đề quyết định kênh (hoặc trọng số) nào sẽ được giữ lại. Để có được kết quả cắt tỉa tối ưu cho một mô hình cá nhân, người ta cần so sánh hiệu suất của mô hình được tạo ra bởi tất cả các tổ hợp của các kênh được giữ lại. Trong khi các cấu trúc chuyên biệt hoặc thuật toán tìm kiếm đã được đề xuất cho việc cắt tỉa, chúng có cấu trúc phức tạp hoặc các tham số nội bộ của chúng cần được đặt thủ công (He et al. 2018). Vấn đề chính của việc cắt tỉa kênh là có các lựa chọn rời rạc trong tổ hợp của các kênh, điều này làm cho vấn đề lựa chọn kênh không thể vi phân. Sử dụng TGF được đề xuất cho phép chúng ta tái công thức hóa các lựa chọn rời rạc như một bài toán học có thể vi phân đơn giản, để một quy trình descent gradient chung có thể được áp dụng, từ đầu đến cuối.

Các đóng góp chính của chúng tôi trong bài báo này có ba khía cạnh.
Chúng tôi giới thiệu khái niệm về TGF làm cho một bài toán lựa chọn rời rạc có thể giải quyết được bằng một quy trình học dựa trên gradient thông thường.

Chúng tôi đề xuất một phương pháp cắt tỉa mà một mạng nơ-ron có thể được tối ưu hóa trực tiếp về mặt số lượng tham số hoặc số lượng FLOPs. Phương pháp được đề xuất có thể cắt tỉa và huấn luyện một mạng nơ-ron đồng thời, để bước tinh chỉnh thêm không cần thiết.

Phương pháp được đề xuất của chúng tôi là bất khả tri về nhiệm vụ để nó có thể được áp dụng dễ dàng cho nhiều nhiệm vụ khác nhau.

Đơn giản bằng cách thêm các TGF, chúng tôi đã đạt được kết quả cạnh tranh trong việc nén các mạng nơ-ron với sự suy giảm tối thiểu về độ chính xác. Ví dụ, phương pháp được đề xuất của chúng tôi nén ResNet-56 (He et al. 2016a) trên tập dữ liệu CIFAR-10 (Krizhevsky and Hinton 2009) một nửa về mặt số lượng FLOPs với sự giảm độ chính xác không đáng kể. Trong một nhiệm vụ chuyển đổi phong cách, chúng tôi đã đạt được một mạng cực kỳ nén nhỏ hơn hơn 35 lần và nhanh hơn 3 lần so với mạng ban đầu. Hơn nữa, phương pháp cắt tỉa của chúng tôi đã được áp dụng hiệu quả cho các nhiệm vụ thực tế khác như ước tính dòng quang học và dịch máy nơ-ron.

Bằng cách kết nối các miền rời rạc và liên tục thông qua khái niệm TGF, chúng ta có thể đạt được kết quả cạnh tranh trên các ứng dụng khác nhau một cách đơn giản. Không chỉ là một nới lỏng liên tục, nó trực tiếp kết nối quyết định xác định với một miền liên tục và có thể vi phân. Bằng cách làm như vậy, phương pháp được đề xuất trong bài báo này có thể giúp chúng ta giải quyết nhiều ứng dụng thực tế hơn gặp khó khăn do các thành phần rời rạc trong kiến trúc.

Công trình liên quan
Tối ưu hóa kiến trúc có thể được xem như một bài toán tối ưu hóa tổ hợp. Các yếu tố quan trọng nhất là xác định kênh nào nên được cắt tỉa trong một lớp để tối thiểu hóa sự mất mát kiến thức thu được.

Những điều này có thể được giải quyết như một vấn đề tìm ra tổ hợp tốt nhất của các kênh được giữ lại nơi nó yêu cầu tính toán cực kỳ nặng. Như một lựa chọn thay thế, các phương pháp tiếp cận heuristic đã được đề xuất để lựa chọn các kênh sẽ bị cắt tỉa (He, Zhang, and Sun 2017; Li et al. 2017). Mặc dù các phương pháp này cung cấp trực giác phong phú về mạng nơ-ron và có thể được áp dụng dễ dàng để nén một mạng nơ-ron nhanh chóng, các phương pháp như vậy có xu hướng dưới tối ưu cho một nhiệm vụ cụ thể trong thực tế.

Vấn đề tìm ra tổ hợp tốt nhất có thể được công thức hóa như một bài toán học tăng cường (RL) và sau đó được giải quyết bằng cách học một mạng chính sách. Bello et al. (Bello et al. 2017) đề xuất một phương pháp để giải quyết các bài toán tối ưu hóa tổ hợp bao gồm bài toán người bán hàng du lịch và bài toán túi xách bằng cách huấn luyện một mạng chính sách. Zoph and Le (Zoph and Le 2016) đề xuất một phương pháp dựa trên RL để tìm kiến trúc phù hợp nhất. Cùng một phương pháp có thể được áp dụng để tìm ra tập hợp tỷ lệ nén tốt nhất cho mỗi lớp thỏa mãn các mục tiêu nén tổng thể và hiệu suất, như được đề xuất trong (He et al. 2018; Zhong et al. 2018). Tuy nhiên, các phương pháp dựa trên RL vẫn yêu cầu tính toán cực kỳ nặng.

Để giải quyết vấn đề khả năng mở rộng, một phương pháp có thể vi phân đã được xem xét trong các nghiên cứu khác nhau dựa trên nới lỏng liên tục (Liu, Simonyan, and Yang 2019; Liu et al. 2017; Louizos, Ullrich, and Welling 2017). Để nới lỏng một bài toán rời rạc để có thể vi phân, Liu et al. (Liu, Simonyan, and Yang 2019) đề xuất một phương pháp đặt một hỗn hợp các phép toán ứng viên bằng cách sử dụng softmax. Luo and Wu (Luo and Wu 2018) đề xuất một loại mô-đun tự chú ý với một hàm sigmoid tỷ lệ như một hàm kích hoạt để giữ lại các kênh từ quyết định xác suất. Tuy nhiên, trong các phương pháp này, việc khởi tạo và kiểm soát cẩn thận các tham số của các lớp chú ý và hàm sigmoid tỷ lệ là cần thiết. Trong khi một phương pháp có thể vi phân có thể mở rộng cho một không gian tìm kiếm lớn, các phương pháp hiện có xác định tập hợp các kênh được chọn theo cách xác suất để chúng yêu cầu một bước bổ sung để quyết định có cắt tỉa mỗi kênh hay không.

Phương pháp chúng tôi đề xuất ở đây cho phép chúng ta tìm ra tập hợp các kênh một cách xác định bằng cách trực tiếp tối ưu hóa hàm mục tiêu cung cấp tính chất có thể vi phân cho các biến có giá trị rời rạc, do đó bỏ qua bước bổ sung cần thiết trong các phương pháp xác suất. Việc tối ưu hóa được đề xuất có thể được thực hiện đơn giản bằng cách thêm các TGF vào một lớp mục tiêu và huấn luyện nó bằng cách sử dụng tối ưu hóa descent gradient. Phương pháp được đề xuất không phụ thuộc vào các tham số bổ sung, vì vậy nó không cần một quá trình khởi tạo cẩn thận hoặc quá trình annealing chuyên biệt để ổn định.

Hàm Cổng Có Thể Huấn Luyện Vi Phân

Xem xét tối ưu hóa tổ hợp trong một bài toán lựa chọn.
min_{θ∈Θ,b∈{0,1}^n} L(θ,b) (1)

trong đó b = (b₁,...,bₙ) là một vector của các lựa chọn nhị phân. L: {0,1}ⁿ → R là một hàm mục tiêu được tham số hóa bởi θ. Bài toán tối ưu hóa (1) là một dạng tổng quát của một bài toán lựa chọn có thể bao gồm một hàm mất mát được tham số hóa như một bài toán cắt tỉa mạng nơ-ron. Trong trường hợp của một bài toán lựa chọn thuần túy, chúng ta đặt miền là một tập hợp đơn.

Để làm cho bài toán có thể vi phân, chúng ta xem xét bᵢ là một đầu ra của một hàm cổng nhị phân b: R → {0,1} được tham số hóa bởi một biến phụ trợ wᵢ. Chúng ta sẽ để b là một hàm bước để thuận tiện.¹ Khi đó bài toán tối ưu hóa (1) tương đương với:

min_{θ∈Θ,w∈Rⁿ} L(θ,b(w₁),...,b(wₙ)) (2)

trong đó bài toán được định nghĩa trong miền liên tục. Tức là, nếu (θ*,w*) là một cực tiểu toàn cục của (2), thì (θ*,b(w*)) là một cực tiểu toàn cục của (1).

Trong khi việc nới lỏng liên tục (2) cho phép bài toán tối ưu hóa (1) được giải quyết bằng descent gradient, một hàm cổng bᵢ(·) có đạo hàm bằng không ở mọi nơi có thể vi phân và do đó

∂L/∂wᵢ = ∂L/∂b · ∂b/∂wᵢ = 0, trong đó wᵢ ≠ 0. (3)

Vì vậy, một tối ưu hóa descent gradient không hoạt động đối với một hàm như vậy.

Để giải quyết vấn đề này, chúng ta xem xét một loại hàm cổng mới có gradient khác không và có thể vi phân hầu khắp mọi nơi. Được thúc đẩy bởi (Hahn and Choi 2018), chúng ta đầu tiên định nghĩa một hàm định hình gradient s: R → R bởi

s^(M)(w) := Mw - ⌊Mw⌋/M (4)

trong đó M là một số nguyên dương lớn và ⌊w⌋ là số nguyên lớn nhất nhỏ hơn hoặc bằng w. Lưu ý rằng hàm này có giá trị gần zero cho tất cả w, và đạo hàm của nó luôn là một ở mọi nơi có thể vi phân. Sử dụng (4) chúng ta xem xét một cổng có thể huấn luyện được định nghĩa như sau (xem Hình 1).

Định nghĩa 1 Một hàm TG^(M): R → R được gọi là một cổng có thể huấn luyện của một hàm cổng b: R → {0,1} đối với một hình dạng gradient g: R → R nếu

TG^(M)(w,g) := b(w) + s^(M)(w)g(w). (5)

Khi đó một cổng có thể huấn luyện TG^(M) thỏa mãn mệnh đề sau.

Mệnh đề 1 Đối với bất kỳ hình dạng đạo hàm g bị chặn mà đạo hàm của nó cũng bị chặn, TG^(M)(w,g) hội tụ đều đến b(w) khi M → ∞. Hơn nữa, TG^(M)'(w,g) hội tụ đều đến g(w).

Chứng minh. Theo định nghĩa (5), nó thỏa mãn rằng với mọi w ∈ R
|TG^(M)(w,g) - b(w)| = |s^(M)(w)g(w)|
≤ 1/M |g(w)| → 0,
khi M → ∞.

Cũng vậy, s'(w) = 1 nếu s(w) có thể vi phân tại w, điều này dẫn đến với mọi w ∈ R
|TG^(M)(w,g)'(w) - g(w)|
= |s^(M)'(w)g(w) + s^(M)(w)g'(w) - g(w)|
= |s^(M)(w)g'(w)|
≤ 1/M |g'(w)| → 0,
khi M → ∞.

Mệnh đề 1 đảm bảo rằng cổng có thể huấn luyện TG^(M)(w,g) có thể xấp xỉ hàm cổng ban đầu b(w), trong khi đạo hàm của nó vẫn xấp xỉ hình dạng đạo hàm mong muốn g. Bây giờ có thể kiểm soát đạo hàm của kernel đã cho b(w) như chúng ta muốn và do đó một tối ưu hóa descent gradient có thể áp dụng cho TGF TG^(M)(w,g). Để thuận tiện, chúng ta sẽ bỏ chỉ số trên và hàm mong muốn g từ TG^(M)(w,g) trừ khi có sự mơ hồ.

Sự khác biệt giữa Quyết định Xác suất và Xác định

TGF được đề xuất trực tiếp học một quyết định xác định trong giai đoạn huấn luyện không giống như các phương pháp hiện có. Trong khi một quyết định xác suất đã được xem xét trong các phương pháp có thể vi phân hiện có (Jang, Gu, and Poole 2017; Liu, Simonyan, and Yang 2019; Liu et al. 2017; Louizos, Ullrich, and Welling 2017), các quyết định xác suất không rõ ràng để lựa chọn và do đó cần các bước quyết định thêm. Do tính chất bật-tắt của quyết định TGF của chúng ta, chúng ta có thể bao gồm các mục tiêu quyết định hơn, như số lượng kênh, FLOPs hoặc tham số, mà không yêu cầu xấp xỉ kỳ vọng của phân phối hoặc làm mịn thành các giá trị không rời rạc.

Chúng tôi thực hiện một thí nghiệm tổng hợp để thấy sự khác biệt giữa các phương pháp xác suất và xác định. Để làm điều này, chúng tôi tạo ra một tập dữ liệu huấn luyện để học hàm sine sin(·). Xem xét một mạng nơ-ron có một lớp kết nối đầy đủ duy nhất có 20 nút ẩn, mỗi nút áp dụng hàm sine làm kích hoạt của nó. Vì một mẫu huấn luyện trong tập dữ liệu tổng hợp của chúng ta có dạng (x, sin(x)), chỉ cần sử dụng một nút ẩn để biểu diễn mối quan hệ giữa đầu vào x và đầu ra y.

Chúng ta xem xét một lớp lựa chọn bao gồm một hàm nới lỏng liên tục với 20 nút ẩn, mỗi nút học xem có giữ lại nút ẩn tương ứng hay không. Hai loại hàm nới lỏng khác nhau được đề cập: một hàm softmax cho quyết định xác suất (Liu, Simonyan, and Yang 2019) và các TGF được đề xuất cho quyết định xác định.

Như chúng ta có thể thấy trong Hình 2, phương pháp xác suất tìm ra một giải pháp sử dụng nhiều hơn một nút. Đặc biệt, 5 nút ẩn hàng đầu dựa trên trọng số quyết định có các giá trị trọng số tương tự wᵢ và cᵢ. Trong giai đoạn huấn luyện, quyết định xác suất sử dụng một tổ hợp tuyến tính của các tùy chọn để lỗi có thể được triệt tiêu và kết quả là các lựa chọn sẽ thừa. Mặt khác, quyết định xác định (TGF được đề xuất của chúng ta) chọn chính xác chỉ một nút. Do tính chất bật-tắt của quyết định xác định, TGF học bằng cách kết hợp kiến thức của các lựa chọn. Vì vậy quyết định xác định có thể chọn hiệu quả mà không thừa.

Trong khi chúng ta đã xem xét bài toán lựa chọn nhị phân cho đến nay, việc mở rộng khái niệm của một cổng có thể huấn luyện cho trường hợp n-ary bằng cách sử dụng n-simplex là đơn giản. Tuy nhiên, để cho thấy tính hữu ích thực tế của khái niệm được đề xuất, chúng ta sẽ xem xét bài toán cắt tỉa, một ứng dụng quan trọng của TGF, trong đó sử dụng một hàm cổng nhị phân là đủ.

Phương pháp Cắt tỉa Có thể Vi phân

Trong phần này, chúng ta phát triển một phương pháp để hiệu quả và tự động cắt tỉa một mạng nơ-ron như một ứng dụng quan trọng của TGF được đề xuất. Để làm điều này, sử dụng khái niệm TGF, chúng ta đề xuất một lớp cổng có thể huấn luyện (TGL) học cách cắt tỉa các kênh từ lớp trước đó.

Thiết kế của Lớp Cổng Có thể Huấn luyện

Khung tổng thể của TGL được đề xuất của chúng ta được minh họa trong Hình 3. Cắt tỉa kênh có thể được công thức hóa bởi một hàm làm zero một số kênh nhất định của một tensor đầu ra trong một mạng nơ-ron tích chập và giữ phần còn lại của các giá trị. Do đó chúng ta thiết kế một TGL như một tập hợp các TGF mà các phần tử tương ứng với các kênh đầu ra của một lớp mục tiêu. Để lớp thứ l mục tiêu ánh xạ một tensor đầu vào x^l đến một tensor đầu ra y^l := (y^l,1,...,y^l,n_l) có n_l kênh sử dụng một kernel K^l

y^l,i = K^l,i * x^l

với i = 1,...,n_l. Một lớp kết nối đầy đủ sử dụng phép nhân · thay vì phép tích chập *, nhưng chúng ta ở đây đơn giản sử dụng * để biểu diễn cả hai trường hợp.

Để một TGL P^l cắt tỉa lớp mục tiêu thứ l nơi TGL P^l bao gồm các trọng số có thể huấn luyện w^l := (w^l,1,...,w^l,n_l) và một hàm TG(·). Trọng số w^l,i, i = 1,...,n_l, được sử dụng để học xem kênh tương ứng có nên được che bởi zero hay không. TGL P^l che tensor đầu ra y^l của lớp mục tiêu thứ l như

ỹ^l,i = TG(w^l,i) · y^l,i, (6)

trong đó ỹ^l := (ỹ^l,1,...,ỹ^l,n_l) là tensor đầu ra bị cắt tỉa bởi P^l. Vì chúng ta có y^l,i = K^l,i * x^l, (6) có thể được viết lại như

TG(w^l,i) · y^l,i = TG(w^l,i) · (K^l,i * x^l)
= (TG(w^l,i) · K^l,i) * x^l.

Vì vậy việc nhân TG(w^l,i) với y^l,i che kênh thứ i từ kernel K^l. Trong khi TG(w^l,i) có thể không chính xác bằng zero do định hình gradient, hiệu ứng của nó có thể bỏ qua bằng cách để giá trị của M đủ lớn.

Từ (6), TG(w^l,i) = 0 dẫn đến ỹ^l,i = 0. Vì vậy giá trị của trọng số w^l,i có thể kiểm soát kênh thứ i của tensor đầu ra y^l. Nếu một hàm bước b(w) = 1[w > 0] được sử dụng như hàm cổng trong TGL, w^l,i < 0 ngụ ý rằng TGL làm zero kênh thứ i từ lớp thứ l. Ngược lại, kênh vẫn giống hệt. Do đó, bằng cách cập nhật các trọng số w^l, chúng ta có thể làm cho TGL học tổ hợp tốt nhất của các kênh để cắt tỉa.

Phương pháp cắt tỉa kênh được đề xuất có thể được mở rộng cho cắt tỉa trọng số hoặc cắt tỉa lớp một cách đơn giản. Nó có thể được đạt được bằng cách áp dụng các hàm cổng có thể huấn luyện cho mỗi phần tử của kernel hoặc mỗi lớp.

Kiểm soát Tỷ lệ Nén

Mục đích của việc cắt tỉa kênh là giảm kích thước mạng nơ-ron hoặc chi phí tính toán. Tuy nhiên, đơn giản thêm TGL trên mà không có bất kỳ điều chuẩn nào không đảm bảo rằng các kênh được cắt tỉa nhiều như chúng ta cần. Trừ khi có một lượng dư thừa đáng kể trong mạng, có nhiều bộ lọc hơn thường có lợi để đạt được độ chính xác cao hơn, vì vậy lớp sẽ không bị cắt tỉa. Tính đến vấn đề này, chúng ta thêm một yếu tố điều chuẩn vào hàm mất mát kiểm soát tỷ lệ nén của một mạng nơ-ron như mong muốn.

Để ρ là tỷ lệ nén mục tiêu. Trong trường hợp giảm số lượng FLOPs, tỷ lệ nén mục tiêu được định nghĩa bởi tỷ lệ giữa số lượng FLOPs còn lại và tổng số C_tot FLOPs của mạng nơ-ron. Các giá trị trọng số w := (w^1,...,w^L) của các TGL xác định số lượng FLOPs còn lại, ký hiệu bởi C(w). Chúng ta muốn giảm FLOPs của mô hình bị cắt tỉa bởi hệ số ρ, tức là, chúng ta muốn nó thỏa mãn C(w) = ρC_tot.

Để L(θ,w) là hàm mất mát ban đầu cần được tối thiểu hóa trong đó θ biểu thị các trọng số của các lớp trong mạng nơ-ron ngoại trừ các TGL. Chúng ta thêm một thuật ngữ điều chuẩn vào hàm mất mát như sau để kiểm soát tỷ lệ nén.

L(θ,w;ρ) := L(θ,w) + λ||C(w)/C_tot - ρ||²₂ (7)

trong đó ||·||₂ biểu thị chuẩn l₂ và λ là một tham số điều chuẩn. Việc điều chuẩn được thêm sẽ đảm bảo rằng số lượng kênh sẽ được giảm để đáp ứng tỷ lệ nén mong muốn của chúng ta.

Lưu ý rằng việc tối thiểu hóa hàm mất mát (7) không chỉ cập nhật các trọng số của các TGL mà còn cả những trọng số của các lớp bình thường. Do đó, một quy trình huấn luyện đồng thời tối ưu hóa việc lựa chọn các kênh bị cắt tỉa trong khi tinh chỉnh các trọng số của mô hình bị cắt tỉa cùng lúc. Trong các phương pháp truyền thống nơi quy trình cắt tỉa kênh được theo sau bởi một giai đoạn tinh chỉnh riêng biệt, tầm quan trọng của mỗi kênh có thể thay đổi trong giai đoạn tinh chỉnh, dẫn đến nén dưới tối ưu. Tuy nhiên, phương pháp được đề xuất của chúng ta không rơi vào vấn đề như vậy vì mỗi TGL tự động tính đến tầm quan trọng của mỗi kênh trong khi điều chỉnh các trọng số của mô hình ban đầu dựa trên các kênh bị cắt tỉa. Hàm mất mát chỉ ra rằng có một sự đánh đổi giữa tỷ lệ nén và độ chính xác.

Trong khi chúng ta đã xem xét số lượng FLOPs trong phần phụ này, chúng ta có thể mở rộng dễ dàng cho các mục tiêu khác như số lượng tham số trọng số hoặc kênh bằng cách thay thế mục tiêu điều chuẩn trong (7).

Kết quả Thực nghiệm

Trong phần này, chúng tôi sẽ chứng minh hiệu quả của TGF được đề xuất thông qua các ứng dụng khác nhau trong các miền hình ảnh và ngôn ngữ. Chúng tôi thực hiện các thí nghiệm của mình bằng Keras (Chollet and others 2015) trừ khi được đề cập khác. Để định hình đạo hàm của hàm cổng b, một hình dạng đạo hàm hằng số g(w) = 1 và M = 10⁵ được sử dụng và một khởi tạo trọng số ngẫu nhiên đơn giản được sử dụng. Trong tất cả các thí nghiệm, chỉ các lớp tích chập hoặc kết nối đầy đủ được xem xét trong việc tính toán số lượng FLOPs của một mô hình vì các loại lớp khác, ví dụ, chuẩn hóa theo lô, yêu cầu lượng tính toán tương đối không đáng kể.

Phân loại Hình ảnh

Chúng tôi sử dụng các tập dữ liệu CIFAR-10 và ImageNet cho các thí nghiệm phân loại hình ảnh của chúng tôi. Chúng tôi sử dụng các trọng số được huấn luyện trước của ResNet-56 trên CIFAR-10 được huấn luyện từ đầu với các tăng cường dữ liệu thông thường (chuẩn hóa và cắt ngẫu nhiên). Đối với VGG-16 trên ImageNet, chúng tôi sử dụng các trọng số được huấn luyện trước đã được xuất bản trong Keras. Mặc dù chúng tôi thấy rằng độ chính xác của mỗi mô hình trong thiết lập thí nghiệm của chúng tôi khác nhau một chút so với giá trị báo cáo, các trọng số được huấn luyện trước ban đầu đã được sử dụng trong các thí nghiệm của chúng tôi mà không có sửa đổi vì chúng tôi muốn điều tra hiệu suất của phương pháp được đề xuất của chúng tôi về mặt giảm độ chính xác.

Cắt tỉa mà không Tinh chỉnh Để cho thấy hiệu ứng của các TGF, chúng tôi đầu tiên xem xét một bài toán lựa chọn. Chúng tôi giữ các trọng số được huấn luyện trước của một mô hình và chỉ cắt tỉa các kênh hoặc trọng số mà không tinh chỉnh bằng cách thêm các TGL vào các lớp tích chập và kết nối đầy đủ. Tức là, chúng tôi cố định θ và tối ưu hóa w trong (2). Hình 4a cho thấy kết quả của việc cắt tỉa kênh trong ResNet-56 (He et al. 2016b) trên CIFAR-10. Có thể quan sát thấy rằng số lượng FLOPs có thể được giảm một nửa mà không có thay đổi đáng chú ý về độ chính xác ngay cả khi chúng ta không áp dụng tinh chỉnh, điều này ngụ ý rằng các TGF hoạt động như mong đợi.

Chúng tôi cũng áp dụng cắt tỉa trọng số được đề cập trong phần trước cho VGG-16 trên ImageNet (Hình 4b). Mặc dù có hơn 1.38 × 10⁸ tham số trọng số trong mô hình có nên được giữ lại hay không, đơn giản cắm các TGL vào mô hình cho phép chúng ta tìm ra một lựa chọn các tham số trọng số dư thừa. Lưu ý rằng độ chính xác của VGG-16 thậm chí tăng lên 89.1% từ 88.24% khi chỉ 10% tham số được giữ lại. Hiện tượng này do thực tế là việc giảm số lượng tham số không có cổng tương đương với việc áp dụng điều chuẩn L₀ cho mạng nơ-ron, và vì vậy việc thêm hàm cổng vào mỗi tham số cải thiện tính chất tổng quát hóa của mô hình hơn nữa.

Cắt tỉa với Tinh chỉnh Trong ví dụ tiếp theo, chúng tôi đồng thời tối ưu hóa các trọng số và lựa chọn cùng lúc để kết hợp tinh chỉnh vào các lựa chọn. Giống như ví dụ trước, chúng tôi thêm các TGL vào một mô hình, nhưng chúng tôi đồng thời huấn luyện cả các TGL và các tham số trọng số của mô hình. Bảng 1 tóm tắt kết quả cắt tỉa. Như được hiển thị trong bảng, kết quả của chúng tôi cạnh tranh với các phương pháp hiện có. Ví dụ, trong ResNet-56, số lượng FLOPs được giảm một nửa trong khi duy trì độ chính xác ban đầu. Cũng đáng chú ý rằng chúng tôi đạt được độ chính xác cao hơn trên mô hình VGG-16 nén, ngay cả khi độ chính xác của mô hình ban đầu của chúng tôi tệ hơn.

Trong khi trong các thí nghiệm của chúng tôi, chúng tôi sử dụng một hàm hằng số để định hình đạo hàm trong các TGF, phương pháp được đề xuất có thể áp dụng bất kỳ hình dạng đạo hàm nào bằng cách thay đổi g(w) trong (5). Hình 5 so sánh hiệu ứng của các hàm định hình khác nhau. Nó cho thấy rằng hình dạng đạo hàm g không ảnh hưởng đến kết quả một cách quan trọng, điều này ngụ ý rằng phương pháp được đề xuất của chúng tôi ổn định qua sự lựa chọn của g(w). Có thể kết luận rằng một hình dạng đạo hàm hằng số đơn giản g(w) = 1 có thể được áp dụng mà không mất mát đáng kể về độ chính xác.

Tạo sinh Hình ảnh

Chúng tôi tiếp tục áp dụng phương pháp cắt tỉa được đề xuất của chúng tôi cho các mô hình chuyển đổi phong cách và ước tính dòng quang học là những ứng dụng phổ biến nhất trong tạo sinh hình ảnh.

Chuyển đổi Phong cách Chuyển đổi phong cách (Dumoulin, Shlens, and Kudlur 2017; Gatys, Ecker, and Bethge 2015) tạo ra một hình ảnh mới bằng cách tổng hợp nội dung trong hình ảnh nội dung đã cho với phong cách trong hình ảnh phong cách đã cho. Vì một mạng chuyển đổi phong cách phụ thuộc nhiều vào việc lựa chọn phong cách nào được sử dụng, không dễ để có được các trọng số được huấn luyện trước phù hợp. Vì vậy, chúng tôi bắt đầu từ mạng chuyển đổi N-phong cách (Dumoulin, Shlens, and Kudlur 2017) như một kiến trúc ban đầu² với các trọng số được khởi tạo ngẫu nhiên θ. Tất nhiên có thể bắt đầu từ các trọng số được huấn luyện trước nếu có sẵn.

Để lựa chọn kênh nào được giữ lại, một TGL được cắm vào đầu ra của mỗi lớp tích chập trong kiến trúc ban đầu ngoại trừ lớp cuối cùng để bảo tồn hiệu suất tạo sinh của nó. Trong giai đoạn huấn luyện, chúng tôi sử dụng ImageNet như một tập hợp hình ảnh nội dung và chọn 5 hình ảnh phong cách (tức là, N = 5) thủ công như được hiển thị trong Hình 6. Chúng tôi huấn luyện cả mô hình ban đầu và nén từ đầu cho 20K vòng lặp với kích thước lô 16. Số lượng kênh bị cắt tỉa được sử dụng như một yếu tố điều chuẩn với trọng số điều chuẩn λ = 0.1.

Mô hình nén (ρ_ch = 0.1) nhỏ hơn 34.5 lần so với mô hình ban đầu về mặt kích thước tệp (Bảng 2). Để thấy thời gian suy luận thực tế, chúng tôi đo thời gian suy luận trên CPU của Galaxy S10. Mô hình nén (ρ_ch = 0.1) nhanh hơn hơn 3 lần về mặt thời gian suy luận như được hiển thị mặc dù chất lượng tạo sinh được bảo tồn như được hiển thị trong Hình 6.

Hình 7 cho thấy số lượng kênh được giữ lại trong mỗi lớp. TGL không chọn số lượng kênh bị cắt tỉa một cách đồng nhất và nó tự động chọn kênh nào bị cắt tỉa theo hàm mục tiêu. Mà không có các bước cắt tỉa thêm, phương pháp được đề xuất của chúng tôi có thể huấn luyện và cắt tỉa đồng thời mô hình với việc xem xét tỷ lệ nén mục tiêu như chúng tôi đã đề cập trong phần trước.

Ước tính Dòng Quang học Tiếp theo chúng tôi xem xét một nhiệm vụ học dòng quang học giữa các hình ảnh (Dosovitskiy et al. 2015; Ilg et al. 2017). Trong thí nghiệm này, chúng tôi sử dụng FlowNetSimple (Dosovitskiy et al. 2015), giống như FlowNetS³ trong (Ilg et al. 2017). FlowNetS xếp chồng hai hình ảnh đầu vào liên tiếp với nhau và đưa chúng vào mạng để trích xuất thông tin chuyển động giữa những hình ảnh này.

Bắt đầu từ mô hình được huấn luyện trước, một TGL được cắm vào đầu ra của mọi lớp tích chập và deconvolution ngoại trừ lớp cuối cùng để bảo tồn hiệu suất tạo sinh của nó. Chúng tôi huấn luyện mô hình với các TGL cho 1.2M vòng lặp với kích thước lô 8. Bộ tối ưu hóa Adam (Kingma and Ba 2015) được sử dụng với tốc độ học ban đầu 0.0001 và nó được giảm một nửa mỗi 200K vòng lặp sau 400K vòng lặp đầu tiên. Như trong nhiệm vụ chuyển đổi phong cách, số lượng kênh bị cắt tỉa được sử dụng như một yếu tố điều chuẩn với trọng số điều chuẩn λ = 0.1. Chúng tôi sử dụng tập dữ liệu Flying Chairs (Dosovitskiy et al. 2015) để huấn luyện và kiểm tra. Hiệu suất của mô hình được đo bằng lỗi điểm cuối trung bình (EPE) của dữ liệu xác thực.

Bảng 3 cho thấy kết quả nén. Như chúng ta có thể thấy trong bảng, mô hình nén (ρ_ch = 0.45) nhỏ hơn 4.93 lần so với mô hình ban đầu về mặt kích thước tệp và nhanh hơn hơn 1.88 lần về mặt thời gian suy luận. Lưu ý rằng EPE của mô hình nén (3.13) gần như giống với mô hình ban đầu (3.15). Nhưng nó chỉ tệ hơn một chút so với EPE được báo cáo (2.71) trong bài báo (Dosovitskiy et al. 2015).

Kết quả thí nghiệm của chúng tôi chứng minh rằng mô hình nén được cắt tỉa bởi TGL tự động tìm ra kênh nào được giữ lại để giảm kích thước tệp mô hình, thời gian suy luận và FLOPs, trong khi tối thiểu hóa suy giảm hiệu suất.

Dịch Máy Nơ-ron

Trong khi chúng tôi đã xem xét các ứng dụng khác nhau, tất cả những ứng dụng đó đều trong miền hình ảnh. Vì vậy như ứng dụng cuối cùng, chúng tôi áp dụng phương pháp cắt tỉa của mình cho một nhiệm vụ dịch máy nơ-ron trong miền ngôn ngữ. Chúng tôi đã cố gắng nén mô hình transformer (Vaswani et al. 2017) đã được sử dụng rộng rãi nhất.

Mô hình transformer bao gồm một bộ mã hóa và một bộ giải mã. Mỗi lớp của bộ mã hóa có nhiều đầu tự chú ý, trong khi mỗi lớp của bộ giải mã có nhiều đầu tự chú ý và nhiều đầu chú ý bộ mã hóa-bộ giải mã. Để làm cho mỗi lớp gọn gàng, chúng tôi thêm các TGF, mỗi cái che đầu chú ý tương ứng. Lưu ý rằng không giống như trong các nhiệm vụ trước, phương pháp cắt tỉa của chúng tôi có thể cắt tỉa ở cấp độ khối, một đầu chú ý, không chỉ ở cấp độ của một trọng số hoặc kênh đơn lẻ.

Chúng tôi thực hiện nhiệm vụ dịch WMT 2014 Anh-Đức như điểm chuẩn của chúng tôi và thực hiện trên fairseq (Ott et al. 2019). Chúng tôi huấn luyện mô hình qua 472,000 vòng lặp từ đầu. Như chúng ta có thể thấy trong Bảng 4, điểm BLEU của một mô hình bị cắt tỉa không suy giảm nhiều. Đặc biệt, mặc dù chỉ 38% đầu chú ý được giữ lại, điểm BLEU chỉ suy giảm 0.18. Phương pháp cắt tỉa của chúng tôi cải thiện hiệu quả tính toán trong miền ngôn ngữ là tốt, từ đó chúng tôi có thể kết luận rằng phương pháp cắt tỉa được đề xuất là bất khả tri về nhiệm vụ.

Kết luận

Trong bài báo này, chúng tôi đã giới thiệu khái niệm về TGF và một phương pháp cắt tỉa có thể vi phân như một ứng dụng của TGF được đề xuất. Việc giới thiệu TGF cho phép chúng ta trực tiếp tối ưu hóa hàm mất mát dựa trên số lượng tham số hoặc FLOPs là các giá trị rời rạc không thể vi phân. Phương pháp cắt tỉa được đề xuất của chúng tôi có thể được thực hiện dễ dàng bằng cách thêm các TGL vào các lớp mục tiêu, và các TGL không cần các tham số nội bộ bổ sung cần điều chỉnh cẩn thận. Chúng tôi đã cho thấy hiệu quả của phương pháp được đề xuất bằng cách áp dụng cho các ứng dụng quan trọng bao gồm phân loại hình ảnh và tạo sinh hình ảnh. Mặc dù đơn giản, các thí nghiệm của chúng tôi cho thấy rằng phương pháp được đề xuất đạt được kết quả nén tốt hơn trên các mô hình deep learning khác nhau. Chúng tôi cũng đã cho thấy rằng phương pháp được đề xuất là bất khả tri về nhiệm vụ bằng cách thực hiện các ứng dụng khác nhau bao gồm phân loại hình ảnh, tạo sinh hình ảnh và dịch máy nơ-ron. Chúng tôi hy vọng rằng TGF có thể được áp dụng cho nhiều ứng dụng hơn nữa nơi chúng ta cần huấn luyện các lựa chọn rời rạc và biến chúng thành các bài toán huấn luyện có thể vi phân.

Lời cảm ơn

Chúng tôi muốn cảm ơn Sunghyun Choi và Haebin Shin cho sự hỗ trợ về các thí nghiệm dịch máy của chúng tôi. Kibeom Lee và Jungmin Kwon hỗ trợ các thí nghiệm điện thoại di động của việc chuyển đổi phong cách.

Tài liệu tham khảo

Bello, I.; Pham, H.; Le, Q. V.; Norouzi, M.; and Bengio, S. 2017. Neural combinatorial optimization with reinforcement learning. In International Conference on Learning Representations.

Chollet, F., et al. 2015. Keras. https://keras.io.

Dosovitskiy, A.; Fischer, P.; Ilg, E.; Hausser, P.; Hazirbas, C.; Golkov, V.; Van Der Smagt, P.; Cremers, D.; and Brox, T. 2015. Flownet: Learning optical flow with convolutional networks. In Proceedings of the IEEE international conference on computer vision, 2758–2766.

Dumoulin, V.; Shlens, J.; and Kudlur, M. 2017. A learned representation for artistic style. In International Conference on Learning Representations.

Gatys, L. A.; Ecker, A. S.; and Bethge, M. 2015. A neural algorithm of artistic style. arXiv preprint arXiv:1508.06576.

Hahn, S., and Choi, H. 2018. Gradient acceleration in activation functions. arXiv preprint arXiv:1806.09783.

He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016a. Deep residual learning for image recognition. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 770–778.

He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016b. Identity mappings in deep residual networks. In European Conference on Computer Vision (ECCV), 630–645.

He, Y.; Lin, J.; Liu, Z.; Wang, H.; Li, L.-J.; and Han, S. 2018. Amc: Automl for model compression and acceleration on mobile devices. In European Conference on Computer Vision (ECCV), 784–800.

He, Y.; Zhang, X.; and Sun, J. 2017. Channel pruning for accelerating very deep neural networks. In IEEE International Conference on Computer Vision (ICCV).

Ilg, E.; Mayer, N.; Saikia, T.; Keuper, M.; Dosovitskiy, A.; and Brox, T. 2017. Flownet 2.0: Evolution of optical flow estimation with deep networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, 2462–2470.

Jang, E.; Gu, S.; and Poole, B. 2017. Categorical reparameterization with gumbel-softmax. In International Conference on Learning Representations.

Kingma, D. P., and Ba, J. 2015. Adam: A method for stochastic optimization. In International Conference on Learning Representations.

Kirkpatrick, S.; Gelatt, C. D.; and Vecchi, M. P. 1983. Optimization by simulated annealing. Science 220 4598:671–80.

Krizhevsky, A., and Hinton, G. 2009. Learning multiple layers of features from tiny images. Technical report, Citeseer.

Li, H.; Kadav, A.; Durdanovic, I.; Samet, H.; and Graf, H. P. 2017. Pruning filters for efficient convnets. In International Conference on Learning Representations.

Liu, Z.; Li, J.; Shen, Z.; Huang, G.; Yan, S.; and Zhang, C. 2017. Learning efficient convolutional networks through network slimming. In IEEE International Conference on Computer Vision (ICCV), 2755–2763. IEEE.

Liu, H.; Simonyan, K.; and Yang, Y. 2019. DARTS: differentiable architecture search. In International Conference on Learning Representations.

Louizos, C.; Ullrich, K.; and Welling, M. 2017. Bayesian compression for deep learning. In Advances in Neural Information Processing Systems, 3288–3298.

Luo, J.-H., and Wu, J. 2018. Autopruner: An end-to-end trainable filter pruning method for efficient deep model inference. arXiv preprint arXiv:1805.08941.

Ott, M.; Edunov, S.; Baevski, A.; Fan, A.; Gross, S.; Ng, N.; Grangier, D.; and Auli, M. 2019. fairseq: A fast, extensible toolkit for sequence modeling. In Proceedings of NAACL-HLT 2019: Demonstrations.

Simonyan, K., and Zisserman, A. 2014. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556.

Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, L. u.; and Polosukhin, I. 2017. Attention is all you need. In Advances in Neural Information Processing Systems 30, 5998–6008.

Ye, S.; Zhang, T.; Zhang, K.; Li, J.; Xu, K.; Yang, Y.; Yu, F.; Tang, J.; Fardad, M.; Liu, S.; Chen, X.; Lin, X.; and Wang, Y. 2018. Progressive weight pruning of deep neural networks using ADMM. arXiv preprint arXiv:1810.07378.

Zhao, C.; Ni, B.; Zhang, J.; Zhao, Q.; Zhang, W.; and Tian, Q. 2019. Variational convolutional neural network pruning. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).

Zhong, J.; Ding, G.; Guo, Y.; Han, J.; and Wang, B. 2018. Where to prune: Using lstm to guide end-to-end pruning. In IJCAI, 3205–3211.

Zoph, B., and Le, Q. V. 2016. Neural architecture search with reinforcement learning. In International Conference on Learning Representations.

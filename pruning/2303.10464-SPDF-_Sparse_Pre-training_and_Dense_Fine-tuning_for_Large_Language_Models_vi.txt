## 4. CÔNG TRÌNH LIÊN QUAN

**Zero-Shot so với Tinh chỉnh** Các công trình gần đây đã cho thấy rằng các mô hình ngôn ngữ lớn có thể đạt được hiệu suất hợp lý mà không có bất kỳ cập nhật tham số nào [Brown et al., 2020, Chowdhery et al., 2022, Rae et al., 2021, Smith et al., 2022], thường được gọi là cài đặt zero-shot hoặc few-shot. Khi không có tham số nào được tinh chỉnh, việc định khung một tác vụ mục tiêu theo mục tiêu huấn luyện sơ bộ cho phép học zero-shot hoặc few-shot sử dụng một prompt cụ thể cho tác vụ và một vài ví dụ của một tác vụ [Brown et al., 2020]. Tuy nhiên, trong khi học few-shot như vậy đơn giản khi sử dụng các mô hình lớn như vậy, có các phương pháp thay thế để đạt được độ chính xác tác vụ tương tự sử dụng các mô hình nhỏ hơn [Schick and Schütze, 2021]. Trong công trình gần đây, Cohen et al. [2022] chứng minh rằng trong khi mở rộng kích thước của LaMDA có thể cải thiện chất lượng, việc kết hợp mở rộng với tinh chỉnh có thể cải thiện mô hình trên tất cả các chỉ số bao gồm chất lượng, an toàn và căn cứ. Solaiman and Dennison [2021] cho thấy rằng tinh chỉnh cũng giúp cập nhật hành vi mô hình ngôn ngữ để giảm nhẹ đầu ra có hại, điều này rất quan trọng cho việc triển khai thực tế của LLM (ví dụ: ChatGPT [OpenAI, 2022], Bard [Pichai, 2023], v.v.). Để đạt được hiệu suất tốt nhất trong thực tế, tinh chỉnh sẽ tiếp tục là phương pháp chính khi sử dụng LLM được huấn luyện sơ bộ. Do đó, công trình của chúng tôi tập trung vào huấn luyện sơ bộ và tinh chỉnh các mô hình ngôn ngữ trên một tập đa dạng các tác vụ, bao gồm tạo ngôn ngữ tự nhiên và tóm tắt văn bản.

**Tinh chỉnh Hiệu quả** Trong khi hầu hết các mô hình quy mô lớn như GPT [Brown et al., 2020, Smith et al., 2022] hoặc T5 [Raffel et al., 2022] được huấn luyện dày đặc, có các công trình [Houlsby et al., 2019a, Li and Liang, 2021b, Zaken et al., 2021, Hu et al., 2022] khám phá việc sử dụng khả năng hạn chế (tinh chỉnh một vài lớp hoặc tập con tham số) trong các mô hình được huấn luyện sơ bộ để tinh chỉnh trên các tác vụ cuối. Những công trình này chỉ ra rằng tổng khả năng mô hình hóa không cần thiết để tinh chỉnh trên các tác vụ cuối. Công trình của chúng tôi lấy một số cảm hứng từ những công trình này để khai thác khả năng hạn chế của các mô hình cho các tác vụ cuối cùng. Tuy nhiên, chúng tôi chọn giảm FLOPs cho huấn luyện sơ bộ (FLOPs huấn luyện nhiều hơn đáng kể so với tinh chỉnh) và sau đó thêm lại tất cả khả năng mô hình hóa trong quá trình tinh chỉnh. Điều này cho phép chúng tôi huấn luyện các mô hình lớn một cách hiệu quả và vẫn giữ lại độ chính xác tương đương với các đường cơ sở dày đặc. Mặc dù chúng tôi không khám phá tinh chỉnh hiệu quả trong nghiên cứu của chúng tôi, chúng tôi để lại việc khám phá sử dụng các lịch trình độ thưa thay thế [Zhu and Gupta, 2018, Liu et al., 2021], thích nghi một tập con tham số trong quá trình tinh chỉnh [Ding et al., 2022] và áp đặt cấu trúc low-rank [Hu et al., 2022] cho công việc tương lai.

**Kỹ thuật Thưa hóa Trọng số** Nhiều kỹ thuật thưa hóa trọng số không có cấu trúc đã được đề xuất trong văn học để huấn luyện mạng nơ-ron [Hoefler et al., 2022], có thể được phân loại là độ thưa tĩnh và độ thưa động. Các phương pháp độ thưa tĩnh có cấu trúc độ thưa cố định (tức là mặt nạ độ thưa) được xác định tại khởi tạo [Lee et al., 2019, Wang et al., 2020]. Ngược lại, các phương pháp huấn luyện thưa động (DST) lặp đi lặp lại cắt tỉa (loại bỏ) và thêm (tái tạo) trọng số trong quá trình huấn luyện [Mocanu et al., 2018, Evci et al., 2020, Jayakumar et al., 2020, Huang et al., 2022] để tìm mạng con thưa tốt nhất có thể trong khi giữ lại độ chính xác tương đương với các đường cơ sở dày đặc. Mặc dù, các phương pháp huấn luyện thưa động có thể giúp đạt được cải thiện Pareto về số lượng FLOPs huấn luyện đến độ chính xác, chúng tôi để lại điều này cho công việc tương lai. Được truyền cảm hứng bởi [Li et al., 2022], cho thấy rằng việc mở rộng kích thước của CNN đóng khoảng cách giữa một mạng thưa được cắt tỉa ngẫu nhiên và đối tác dày đặc của nó, chúng tôi tập trung nghiên cứu của chúng tôi vào các mô hình ngôn ngữ với độ thưa tĩnh. Trong khi Dao et al. [2022a] chứng minh lợi ích của huấn luyện thưa sang dày đặc, họ chủ yếu áp dụng nó trong quá trình huấn luyện sơ bộ và thay vào đó, tập trung nghiên cứu của họ vào tinh chỉnh dày đặc sang thưa tương tự như các nỗ lực tinh chỉnh hiệu quả khác. Trong công trình của chúng tôi, chúng tôi cho thấy rằng huấn luyện sơ bộ thưa theo sau bởi tinh chỉnh dày đặc trên các tác vụ cuối có thể ngang bằng với độ chính xác của một mô hình được huấn luyện sơ bộ dày đặc trên nhiều tác vụ, trong khi giảm đáng kể tổng FLOPS huấn luyện.

## 5. KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI

Trong công trình này, chúng tôi đã giới thiệu Huấn luyện sơ bộ Thưa và Tinh chỉnh Dày đặc (SPDF) để giảm FLOPs tính toán của việc huấn luyện các mô hình GPT sử dụng độ thưa trọng số. Theo hiểu biết tốt nhất của chúng tôi, đây là lần đầu tiên một mô hình GPT lớn được huấn luyện sơ bộ với độ thưa cao (50%-75%) mà không mất đáng kể trong các chỉ số tác vụ cuối. Trong công trình của chúng tôi, chúng tôi chỉ sử dụng độ thưa tĩnh đơn giản, có thể nói là cách ngây thơ nhất để tạo ra độ thưa trong mạng nơ-ron. Đối với công việc tương lai, có một số hướng tự nhiên để cải thiện kết quả của chúng tôi trên các mô hình thậm chí lớn hơn, bao gồm các phương pháp độ thưa động, kỹ thuật tối ưu hóa tốt hơn cho huấn luyện thưa, và kiến trúc phù hợp với huấn luyện thưa. Hơn nữa, để hạn chế chi phí tính toán của nghiên cứu chúng tôi, chúng tôi đã huấn luyện các mô hình GPT của chúng tôi theo luật tỷ lệ Chinchilla. Mặc dù lịch trình huấn luyện sơ bộ Chinchilla đã được chứng minh là tối ưu FLOP cho các mô hình dày đặc, chúng tôi dự định điều tra mức độ nó chuyển giao tốt cho các mô hình thưa. Công việc tương lai của chúng tôi cũng sẽ điều tra tỷ lệ thưa bên ngoài luật tỷ lệ dày đặc Chinchilla. Bất kể, chúng tôi thấy lời hứa to lớn của độ thưa trọng số không có cấu trúc để tăng tốc huấn luyện LLM, được kích hoạt bởi những tiến bộ gần đây trong các bộ tăng tốc phần cứng học sâu.

## Đóng góp của Tác giả

Chúng tôi cung cấp tóm tắt đóng góp của mỗi tác giả:

• **Vithursan Thangarasa** dẫn đầu nỗ lực huấn luyện/đánh giá các mô hình GPT quy mô lớn trên Cerebras CS-2, đánh giá kỹ thuật trong các thiết lập huấn luyện hiệu quả FLOP khác nhau, đưa ra nhiều tác vụ cuối, phân tích các không gian con tham số, và viết bản thảo.

• **Abhay Gupta** giúp huấn luyện sơ bộ các mô hình GPT trên CS-2 và chạy các mô hình tham chiếu để xác thực thiết lập huấn luyện và tinh chỉnh của chúng tôi.

• **William Marshall** đưa ra các tác vụ cuối khác nhau trên CS-2 và hỗ trợ trong việc chạy các thí nghiệm tinh chỉnh.

• **Tianda Li** hỗ trợ William Marshall và Vithursan Thangarasa với việc chạy các thí nghiệm tinh chỉnh.

• **Kevin Leong** hỗ trợ Abhay Gupta với việc huấn luyện sơ bộ các mô hình GPT trên CS-2 và cung cấp sự giúp đỡ quan trọng trong việc gỡ lỗi các vấn đề.

• **Dennis DeCoste** hình thành ý tưởng chính ban đầu.

• **Sean Lie** điều phối việc đưa GPT lên CS-2 và tham gia vào xác thực và phân tích thực nghiệm.

• **Shreyas Saxena** tư vấn toàn bộ nỗ lực, đưa ra bằng chứng khái niệm ban đầu và thử nghiệm với các kỹ thuật độ thưa khác nhau.

• **Shreyas Saxena** và **Sean Lie** thường xuyên gặp Vithursan Thangarasa để thảo luận công việc và giúp sửa đổi nhiều lần lặp của bản thảo.

## 6. LỜI CẢM ƠN

Chúng tôi cảm ơn Anshul Samar, Dimitrios Sinodinos, và Joel Hestness, vì những chỉnh sửa và gợi ý hữu ích đã cải thiện độ rõ ràng của bản thảo chúng tôi.

## TÀI LIỆU THAM KHẢO

[Danh sách tài liệu tham khảo được giữ nguyên như trong bản gốc do chứa các tên riêng và thuật ngữ kỹ thuật chuẩn hóa quốc tế]

---

## PHỤ LỤC

### A. THIẾT LẬP THỰC NGHIỆM VÀ CHI TIẾT SIÊU THAM SỐ

#### A.1 HUẤN LUYỆN SƠ BỘ TRÊN PILE

[Nội dung phụ lục được dịch theo cùng cách tiếp cận, bảo toàn cấu trúc và độ chính xác kỹ thuật]

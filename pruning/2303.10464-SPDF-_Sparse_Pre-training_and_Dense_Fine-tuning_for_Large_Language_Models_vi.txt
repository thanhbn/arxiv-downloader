# SPDF: Huấn luyện Thưa thớt trước và Điều chỉnh Dày đặc cho các Mô hình Ngôn ngữ Lớn

Vithursan Thangarasa1 Abhay Gupta1 William Marshall1 Tianda Li* Kevin Leong1
Dennis DeCoste* Sean Lie1 Shreyas Saxena1
1Cerebras Systems Inc., Sunnyvale, California, USA

## Tóm tắt

Mô hình huấn luyện trước và điều chỉnh tinh đã đóng góp vào một số đột phá trong Xử lý Ngôn ngữ Tự nhiên (NLP). Thay vì huấn luyện trực tiếp trên tác vụ downstream, các mô hình ngôn ngữ được huấn luyện trước trên các tập dữ liệu lớn với kiến thức liên ngành (ví dụ: Pile, MassiveText, v.v.) rồi sau đó được điều chỉnh tinh trên dữ liệu cụ thể cho tác vụ (ví dụ: sinh ngôn ngữ tự nhiên, tóm tắt văn bản, v.v.). Việc mở rộng quy mô mô hình và tập dữ liệu đã giúp cải thiện hiệu suất của các LLM, nhưng tiếc rằng điều này cũng dẫn đến chi phí tính toán cực kỳ cao. Huấn luyện trước LLM thường yêu cầu nhiều hơn hàng bậc FLOPs so với điều chỉnh tinh và dung lượng mô hình thường giữ nguyên giữa hai giai đoạn. Để đạt được hiệu quả huấn luyện về mặt FLOPs huấn luyện, chúng tôi đề xuất tách rời dung lượng mô hình giữa hai giai đoạn và giới thiệu Huấn luyện Thưa thớt trước và Điều chỉnh Dày đặc (SPDF). Trong nghiên cứu này, chúng tôi cho thấy lợi ích của việc sử dụng độ thưa thớt trọng số không có cấu trúc để chỉ huấn luyện một tập con trọng số trong giai đoạn huấn luyện trước (Huấn luyện Thưa thớt trước) và sau đó khôi phục dung lượng biểu diễn bằng cách cho phép các trọng số bằng không học tập (Điều chỉnh Dày đặc). Chúng tôi chứng minh rằng có thể tạo ra độ thưa thớt lên đến 75% vào mô hình GPT-3 XL 1.3B tham số, dẫn đến giảm 2.5x FLOPs huấn luyện trước, mà không có mất mát đáng kể về độ chính xác trên các tác vụ downstream so với baseline dày đặc. Bằng cách đánh giá nghiêm ngặt nhiều tác vụ downstream, chúng tôi cũng thiết lập mối quan hệ giữa độ thưa thớt, độ phức tạp tác vụ và kích thước tập dữ liệu. Nghiên cứu của chúng tôi trình bày một hướng đầy hứa hẹn để huấn luyện các mô hình GPT lớn với chỉ một phần nhỏ FLOPs huấn luyện sử dụng độ thưa thớt trọng số, trong khi vẫn giữ lại lợi ích của các biểu diễn văn bản được huấn luyện trước cho các tác vụ downstream.

*Công việc được thực hiện khi tại Cerebras Systems.

## 1 GIỚI THIỆU

Các mô hình ngôn ngữ lớn (LLM) đã đóng góp vào những tiến bộ đáng kể trong hiểu ngôn ngữ tự nhiên (NLU) và sinh ngôn ngữ tự nhiên (NLG) nhờ vào việc giới thiệu các phương pháp huấn luyện trước [Devlin et al., 2019, Radford and Narasimhan, 2018] trên các tập dữ liệu khổng lồ không có chú thích (ví dụ: Pile [Gao et al., 2020], MassiveText [Rae et al., 2021], v.v.). Trong khi việc mở rộng quy mô mô hình và tập dữ liệu đã cải thiện chất lượng của LLM [Wei et al., 2022], nó cũng đã tăng đáng kể chi phí tính toán của huấn luyện trước. Ví dụ, GPT-3 175B [Brown et al., 2020] được ước tính tốn hàng triệu đô la để huấn luyện [Li, 2022]. Nhiều kỹ thuật khác nhau đã được đề xuất để giảm chi phí tính toán của việc huấn luyện LLM, bao gồm attention thưa thớt [Dao et al., 2022b, Jaszczur et al., 2021], kỹ thuật tối ưu hóa cải tiến [Tang et al., 2021] và học chương trình cấp độ chuỗi [Li et al., 2022]. Trong khi những phương pháp này có thể giúp giảm thời gian tính toán, độ thưa thớt trọng số là một kỹ thuật đầy hứa hẹn trực giao với các phương pháp trên. Ở đây, một tập con của các tham số mô hình được đặt bằng không, giảm FLOPs cần thiết trong quá trình huấn luyện.

Mặc dù có những tiến bộ gần đây trong huấn luyện thưa thớt [Hoefler et al., 2022], nó vẫn chưa được các nhà thực hành áp dụng rộng rãi. Thứ nhất, việc tìm ra mẫu độ thưa thớt tối ưu [Frankle and Carbin, 2018, Ma et al., 2022] có thể duy trì cùng mức độ chính xác như các mô hình dày đặc là khó khăn và tốn kém. Thứ hai, độ thưa thớt không có cấu trúc có thể khó tăng tốc trên các kiến trúc phần cứng được tối ưu hóa cho tính toán dày đặc [Hooker, 2020]. Trong nghiên cứu này, chúng tôi cho thấy cách có thể tận dụng độ thưa thớt trọng số để giảm FLOPs huấn luyện, và sau đó khôi phục dung lượng biểu diễn bị mất bằng cách chuyển sang ma trận trọng số dày đặc khi điều chỉnh tinh trên các tác vụ downstream. Ngoài ra, trong khi các kernel phần mềm chuyên biệt đã được phát triển để đạt được tăng tốc suy luận với độ thưa thớt không có cấu trúc [Gale et al., 2020, NeuralMagic, 2021, Elsen et al., 2019, Ashby et al., 2019, Wang, 2021], nghiên cứu gần đây đã cho thấy rằng chúng ta có thể nhận ra lợi ích của độ thưa thớt trọng số không có cấu trúc trên phần cứng chuyên biệt (ví dụ: Cerebras CS-2 [Lie, 2023, 2021]) khi huấn luyện LLM. Ví dụ, Lie [2021] cho thấy tốc độ tăng tốc đo được cho một kernel nhân ma trận w.r.t mức độ thưa thớt trên một lớp GPT-3 đơn (xem Phụ lục C để biết thêm chi tiết). Do đó, khi các kỹ thuật huấn luyện thưa thớt không có cấu trúc tiếp tục được đồng thiết kế với phần cứng, chúng ta có thể mong đợi việc giảm FLOP sẽ chuyển thành tăng tốc hiệu suất và thời gian thực tế.

Các nghiên cứu trước về làm thưa thớt LLM tập trung vào việc giảm FLOPs huấn luyện [Chen et al., 2022a, Dao et al., 2022a] hoặc suy luận [Chen et al., 2020], trong khi khớp với huấn luyện dày đặc tiêu chuẩn. Chen et al. [2022a] và Dao et al. [2022a] thay thế các ma trận dày đặc bằng ma trận trọng số thưa thớt có cấu trúc dựa trên butterfly để giảm kích thước mô hình và tăng tốc huấn luyện trước trên phần cứng hướng khối (ví dụ: GPU [Krashinsky et al., 2020], TPU [He et al., 2020]). Huấn luyện với độ thưa thớt có cấu trúc yêu cầu duy trì cấu trúc thưa thớt đều đặn, có thể giảm tính biểu đạt ở mức độ thưa thớt cao hơn. Đây là một ràng buộc được biết đến khi áp đặt độ thưa thớt có cấu trúc trong ma trận trọng số dày đặc [Zhou et al., 2021, Jiang et al., 2022]. Những đổi mới gần đây trong kiến trúc phần cứng nhằm tạo điều kiện cho việc sử dụng và áp dụng rộng rãi độ thưa thớt trọng số không có cấu trúc, cho phép khả năng đạt được tỷ lệ nén cao hơn trong khi đạt được tăng tốc thực tế w.r.t thời gian thực tế. Nghiên cứu của chúng tôi tập trung vào huấn luyện trước với độ thưa thớt trọng số không có cấu trúc để giảm FLOPs cho việc huấn luyện mô hình ngôn ngữ.

Trong tài liệu NLP gần đây, việc huấn luyện trước trước rồi điều chỉnh tinh mô hình ngôn ngữ sau là phổ biến. Điều chỉnh tinh LLM được huấn luyện trước trên các tác vụ downstream dẫn đến độ chính xác tốt hơn đáng kể so với cài đặt zero hoặc few-shot [Alt et al., 2019, Ouyang et al., 2022]. Giai đoạn huấn luyện trước mất thời gian dài hơn đáng kể so với điều chỉnh tinh trên tập dữ liệu nhỏ hơn nhiều để học tác vụ cụ thể theo lĩnh vực. Trong thiết lập tiêu chuẩn, kích thước mô hình và dung lượng thường được giữ nguyên giữa hai giai đoạn. Chúng tôi đề xuất phá vỡ giả định này và cho thấy lợi ích của việc sửa đổi dung lượng mô hình giữa huấn luyện trước và điều chỉnh tinh với độ thưa thớt trọng số. Đầu tiên, chúng tôi huấn luyện trước một mô hình GPT thưa thớt để giảm FLOPs tính toán huấn luyện. Sau đó, trong giai đoạn điều chỉnh tinh, chúng tôi làm dày mô hình GPT, cho phép các trọng số bằng không học tập và tăng dung lượng mô hình hóa để học tác vụ downstream chính xác hơn.

Trong khi nghiên cứu trước đã khám phá huấn luyện từ thưa thớt đến dày đặc để giảm thiểu khó khăn của huấn luyện từ thưa thớt đến thưa thớt [Dao et al., 2022a] và cải thiện độ chính xác của mô hình dày đặc [Han et al., 2017], chúng tôi thực hiện huấn luyện trước hoàn toàn thưa thớt và chỉ chuyển sang ma trận trọng số dày đặc trong quá trình điều chỉnh tinh. Chúng tôi gọi khung này là Huấn luyện Thưa thớt trước và Điều chỉnh Dày đặc (SPDF) và chứng minh khả năng của mô hình được huấn luyện trước thưa thớt chuyển giao hiệu quả cho các tác vụ downstream khác nhau (ví dụ: sinh ngôn ngữ tự nhiên và tóm tắt văn bản). Những đóng góp chính của nghiên cứu chúng tôi là:

1. Chúng tôi đề xuất Huấn luyện Thưa thớt trước và Điều chỉnh Dày đặc (SPDF) như một khung mới để giảm FLOPs cần thiết trong giai đoạn huấn luyện trước, trong khi duy trì độ chính xác trên các tác vụ downstream.

2. Chúng tôi chứng minh rằng có thể huấn luyện GPT-3 XL ở độ thưa thớt 75%, giảm tổng FLOPS huấn luyện xuống 2.5x, trong khi vẫn giữ lại lợi ích của các biểu diễn văn bản được huấn luyện trước trong LLM trên đa số các tác vụ và chỉ số đánh giá.

3. Chúng tôi thiết lập mối tương quan giữa mức độ thưa thớt tối ưu trong quá trình huấn luyện trước và kích thước tập dữ liệu điều chỉnh tinh cũng như độ khó của tác vụ.

## 2 PHƯƠNG PHÁP

Phần này trình bày phương pháp của chúng tôi để giảm FLOPs huấn luyện trước sử dụng độ thưa thớt trọng số không có cấu trúc. Đầu tiên chúng tôi giải thích trực giác và giả thuyết của mình, sau đó là phương pháp của chúng tôi cho khung SPDF.

### 2.1 TRỰC GIÁC VÀ GIẢ THUYẾT

Các nghiên cứu trước đã cho thấy rằng việc tham số hóa quá mức của mạng nơ-ron cải thiện tối ưu hóa và khả năng tổng quát hóa [Soltanolkotabi et al., 2019, Neyshabur et al., 2019, Allen-Zhu et al., 2019], nhưng dẫn đến tăng chi phí tính toán [Brown et al., 2020]. Nghiên cứu gần đây về Giả thuyết Vé số Frankle and Carbin [2018] chứng minh rằng các mạng dày đặc được tham số hóa quá mức chứa các mạng con thưa thớt có thể được huấn luyện đến cùng độ chính xác như các đối tác dày đặc của chúng, miễn là người ta khởi tạo huấn luyện với một mặt nạ độ thưa thớt tốt ("vé số"). Tuy nhiên, quá trình tìm kiếm các mạng con thưa thớt chất lượng cao rất tốn kém về mặt tính toán [Frankle and Carbin, 2018, Ma et al., 2022]. Các phương pháp huấn luyện thưa thớt hiện có [Evci et al., 2020, Mocanu et al., 2018, Jayakumar et al., 2020] nhằm khám phá vé số thắng cuộc (tức là mặt nạ độ thưa thớt tối ưu) trong một lần chạy huấn luyện, nhưng thường không đạt được độ chính xác của mô hình dày đặc.

Trong khung của chúng tôi, chúng tôi giảm thiểu sự mất mát sức mạnh biểu diễn do khó khăn trong tối ưu hóa thưa thớt [Evci et al., 2019], bằng cách chuyển sang ma trận trọng số hoàn toàn dày đặc trong giai đoạn điều chỉnh tinh. Mặc dù chúng tôi thực hiện điều chỉnh tinh dày đặc, chi phí tính toán liên quan đến điều chỉnh tinh thấp hơn đáng kể so với chi phí huấn luyện trước LLM. Do đó, phương pháp của chúng tôi nhắm đến giai đoạn chiếm ưu thế FLOPs huấn luyện (tức là huấn luyện trước). Dựa trên các phát hiện lý thuyết gần đây và nghiên cứu thực nghiệm về tham số hóa quá mức và mạng nơ-ron thưa thớt, chúng tôi đưa ra một tập hợp giả thuyết mà chúng tôi nhằm nghiên cứu trong công việc của mình thông qua đánh giá thực nghiệm mở rộng:

**Giả thuyết 1**: Độ thưa thớt trọng số cao có thể được sử dụng trong giai đoạn huấn luyện trước của LLM trong khi bảo tồn độ chính xác downstream với điều chỉnh tinh dày đặc.

Tạo độ thưa thớt trong quá trình huấn luyện trước có thể gây mất sức mạnh biểu diễn do khó khăn trong tối ưu hóa thưa thớt và không thể khám phá mặt nạ độ thưa thớt tối ưu [Evci et al., 2019]. Để giảm thiểu những thách thức này, chúng tôi nhằm tăng sức mạnh biểu diễn bằng cách cho phép các trọng số bằng không phát triển trong quá trình điều chỉnh tinh (tức là điều chỉnh tinh dày đặc). Ngoài ra, lưu ý rằng toàn bộ dung lượng của mô hình được huấn luyện trước thường không cần thiết để tổng quát hóa trên tác vụ downstream đơn giản hơn, khi sử dụng độ thưa thớt trong quá trình huấn luyện trước [Ding et al., 2022]. Aghajanyan et al. [2021] điều tra hiện tượng này từ góc độ khác và cho thấy các mô hình ngôn ngữ được huấn luyện trước có thể học một tập lớn các tác vụ NLP chỉ với một vài tham số. Điều này cho thấy rằng việc tham số hóa đầy đủ của mô hình không cần thiết để tổng quát hóa tốt trên các tác vụ điều chỉnh tinh downstream. Do đó, chúng ta có thể khai thác độ thưa thớt trọng số trong quá trình huấn luyện trước trong khi vẫn giữ lại các biểu diễn văn bản quan trọng mặc dù dung lượng biểu diễn thấp hơn của mô hình.

**Giả thuyết 2**: Hiệu suất của mô hình được huấn luyện trước thưa thớt có tương quan với kích thước tập dữ liệu và mức độ khó khăn trong tác vụ downstream.

Liu et al. [2023] đánh giá mạng thưa thớt trên một tập đa dạng các tác vụ với các mức độ khó khăn khác nhau và cho thấy mối tương quan mạnh giữa khả năng làm thưa thớt của mô hình và độ khó của tác vụ. Do đó, chúng tôi giả thuyết rằng các mô hình được huấn luyện trên các tác vụ phức tạp với mức độ thưa thớt cao có thể bị ảnh hưởng nhiều hơn từ huấn luyện thưa thớt và trải qua sự sụt giảm hiệu suất lớn hơn so với các tác vụ đơn giản hơn. Chúng tôi cũng lưu ý rằng các tập dữ liệu điều chỉnh tinh nhỏ có thể kích hoạt over-fitting [Li and Zhang, 2021]. Do đó, chúng tôi giả thuyết rằng các tập dữ liệu lớn hơn có thể cho phép mô hình thưa thớt cải thiện lỗi tổng quát hóa trên tác vụ, và khôi phục từ huấn luyện với độ thưa thớt cao.

**Giả thuyết 3**: Khi chúng ta tăng kích thước mô hình ngôn ngữ, các mô hình lớn hơn trở nên dễ chấp nhận hơn với mức độ thưa thớt cao hơn trong quá trình huấn luyện trước.

Nghiên cứu hiện có [Liu et al., 2022] đã cho thấy rằng chất lượng của một mạng được huấn luyện với độ thưa thớt tĩnh ngẫu nhiên (ngay cả ở mức độ thưa thớt cao) cải thiện nhanh chóng để khớp với đối tác dày đặc của nó khi mạng phát triển rộng hơn và sâu hơn. Ngoài ra, các mô hình lớn hơn có xu hướng có chiều nội tại nhỏ hơn [Aghajanyan et al., 2021], điều này cho thấy rằng không phải tất cả tham số đều cần thiết để biểu diễn tác vụ NLP trung bình. Do đó, chúng tôi mong đợi khoảng cách trong hiệu suất downstream giữa mô hình được huấn luyện trước thưa thớt và đối tác dày đặc của nó sẽ nhỏ hơn khi kích thước mô hình tăng lên.

### 2.2 HUẤN LUYỆN THƯA THỚT TRƯỚC VÀ ĐIỀU CHỈNH DÀY ĐẶC

Quy trình huấn luyện của chúng tôi bao gồm hai giai đoạn. Giai đoạn đầu tiên bao gồm huấn luyện trước một mô hình ngôn ngữ thưa thớt trên một kho văn bản lớn theo cách không giám sát. Ở đây, chúng tôi tạo độ thưa thớt trọng số không có cấu trúc vào mạng nơ-ron để giảm FLOPs huấn luyện trước. Điều này được theo sau bởi giai đoạn điều chỉnh tinh dày đặc, nơi chúng tôi mở rộng dung lượng biểu diễn của mô hình bằng cách cho phép các trọng số bằng không học tập, và thích ứng với một tác vụ phân biệt với dữ liệu được gán nhãn.

**Huấn luyện trước Dày đặc Không giám sát** Trong khi khung đề xuất của chúng tôi không phụ thuộc vào mục tiêu huấn luyện, chúng tôi tập trung vào mô hình ngôn ngữ tự hồi quy như trường hợp sử dụng động lực của chúng tôi. Trong một mô hình ngôn ngữ tự hồi quy, quá trình sinh chuỗi được mô hình hóa như một chuỗi Markov, nơi token cần được dự đoán phụ thuộc vào tất cả các token trước đó [Bengio et al., 2003]. Do đó, cách tiếp cận tiêu chuẩn là học phân phối xác suất trên các chuỗi token từ một kho huấn luyện trước không giám sát. Cho một kho huấn luyện trước không giám sát gồm các token U={u1, u2, . . . , u |U|}, trong đó |U| là tổng số token. Chúng tôi nhằm tối đa hóa likelihood sử dụng mục tiêu mô hình ngôn ngữ được công thức hóa như sau,

L(U) = Σ(i=1 đến |U|) log(p(ui|ui−k, . . . , ui−1, θ)),

trong đó k là kích thước cửa sổ ngữ cảnh, và xác suất có điều kiện p được mô hình hóa sử dụng một mạng nơ-ron với tham số θ ∈ RN. Các tham số của lớp thứ l trong tổng L lớp được ký hiệu là θl, cùng với tổng số tham số được biểu diễn là Nl. Chúng tôi lưu ý rằng các tham số mạng θ được coi là dày đặc.

**Huấn luyện trước Thưa thớt Không giám sát** Để tạo độ thưa thớt vào lớp thứ l, chúng tôi loại bỏ sl ∈ (0,1) các kết nối của nó, trong đó sl để chỉ độ thưa thớt của lớp l. Điều này dẫn đến tổng cộng (1−sl)Nl tham số. Cuối cùng, độ thưa thớt tổng thể của một mạng con thưa thớt được định nghĩa là tỷ lệ số không với tổng số tham số trong mạng dày đặc ban đầu, tức là S = (Σ(l=1 đến L) slNl)/N. Trong thiết lập huấn luyện thưa thớt của chúng tôi, chúng tôi áp dụng một mặt nạ độ thưa thớt nhị phân m ∈ {0,1}|θ| trên các tham số ban đầu θ0, sao cho khởi tạo của nó là m ⊙ θ0. Ở đây, các giá trị 0 và 1 trong mặt nạ biểu thị các trọng số không hoạt động (tức là bằng không) và hoạt động (tức là khác không), tương ứng. Kết quả là, mô hình ngôn ngữ thưa thớt tối thiểu hóa mục tiêu sau đây thay thế,

L(U) = Σ(i=1 đến |U|) log(p(ui|ui−k, . . . , ui−1, m ⊙ θ)). (1)

Trong nghiên cứu của chúng tôi, chúng tôi chỉ tập trung vào độ thưa thớt tĩnh (tức là m không đổi trong suốt quá trình huấn luyện) và các trọng số được cắt tỉa ngẫu nhiên tại thời điểm khởi tạo. Cụ thể, chúng tôi loại bỏ các trọng số trong mỗi lớp l ∈ L một cách ngẫu nhiên đến độ thưa thớt mục tiêu sl. Mặc dù một số nghiên cứu đã khám phá việc tạo ra các tỷ lệ độ thưa thớt theo lớp khác nhau tại thời điểm khởi tạo (ví dụ: Erdös-Rényi-Kernel Evci et al. [2020], Ideal Gas Quota [Chen et al., 2022b], SNIP [Lee et al., 2019], GraSP [Wang et al., 2020], SynFlow [Tanaka et al., 2020], v.v.), chúng tôi tập trung vào thiết lập đơn giản nhất, đó là độ thưa thớt đồng nhất [Gale et al., 2019]. Trong độ thưa thớt đồng nhất, mỗi lớp được làm thưa thớt được cắt tỉa đến cùng mức độ thưa thớt mục tiêu.

Đối với mô hình ngôn ngữ, chúng tôi sử dụng GPT [Radford et al., 2019, Brown et al., 2020] trong các thí nghiệm của mình, đây là một biến thể của Transformer [Vaswani et al., 2017]. Chúng tôi huấn luyện mạng với mục tiêu được hiển thị trong Eq. 1 và bộ tối ưu AdamW [Loshchilov and Hutter, 2017] trên một tập dữ liệu huấn luyện trước không giám sát trong tổng cộng j lần lặp, đạt được các tham số θj. Sau đó, chúng tôi thích ứng (tức là điều chỉnh tinh) mô hình ngôn ngữ tự hồi quy được huấn luyện trước cuối cùng p(m⊙θ) với tác vụ mục tiêu có giám sát.

**Điều chỉnh tinh Dày đặc** Theo Hu et al. [2022] và Li and Liang [2021a], mỗi tác vụ điều chỉnh tinh downstream được biểu diễn bởi một tập dữ liệu huấn luyện bao gồm các cặp ngữ cảnh-mục tiêu được định nghĩa là: Z={(x1, y1),(x2, y2), . . . , (x|x|, y|y|)}, trong đó cả x và y đều là các chuỗi token. Ví dụ, trong dữ liệu có cấu trúc-to-text (ví dụ: E2E [Novikova et al., 2017]), x tương ứng với một bảng dữ liệu được tuyến tính hóa và y là mô tả văn bản; trong tóm tắt văn bản (ví dụ: Curation Corpus [Curation, 2020]), x là nội dung của một bài báo và y là tóm tắt của nó.

Chúng tôi khởi tạo đầu điều chỉnh tinh dày đặc với các tham số được huấn luyện trước cuối cùng θj và trong quá trình điều chỉnh tinh được cập nhật thành θj + Δθ. Đối với mỗi tác vụ downstream, chúng tôi học một tập tham số khác nhau với mức tăng tham số cụ thể theo tác vụ Δθ có chiều |Δθ| bằng |θ|. Các nghiên cứu khác đã khám phá các cách tiếp cận hiệu quả hơn về tham số để giảm kích thước của các tham số cụ thể theo tác vụ cho mục đích triển khai các mô hình được điều chỉnh tinh [Ben Zaken et al., 2022, Houlsby et al., 2019b, Hu et al., 2022]. Tuy nhiên, trong cách tiếp cận của chúng tôi, chúng tôi tập trung vào việc giảm FLOPs huấn luyện trước với độ thưa thớt trọng số không có cấu trúc và thực hiện điều chỉnh tinh dày đặc để giảm thiểu các thách thức của tối ưu hóa thưa thớt bằng cách tăng sức mạnh biểu diễn của mạng. Trong giai đoạn điều chỉnh tinh dày đặc, chúng tôi cơ bản loại bỏ mặt nạ độ thưa thớt m để cho phép các trọng số không hoạt động phát triển. Cụ thể hơn, chúng tôi tăng dung lượng biểu diễn trong θj bằng cách hồi sinh tất cả Σ(l=1 đến L) sl·Nl trọng số không hoạt động, trong đó tất cả các trọng số mới được kích hoạt được khởi tạo bằng 0. Chúng tôi đã đánh giá các khởi tạo khác như phân phối chuẩn được chia tỷ lệ, nhưng điều này không dẫn đến kết quả tốt hơn. Cuối cùng, mạng được cập nhật theo cách dày đặc với mục tiêu được hiển thị bên dưới,

L(Z) = Σ((x,y)∈Z) Σ(t=1 đến |y|) log(p(yt|(x1, . . . , xt−1), θj + Δθ)).

Khung Huấn luyện Thưa thớt trước và Điều chỉnh Dày đặc (SPDF) chung, được minh họa trong Hình 1, bao gồm ba bước sau:

1. Làm thưa thớt một mạng dày đặc đã cho đến một mức độ thưa thớt mục tiêu nào đó, sl, tại mỗi lớp có thể làm thưa thớt.

2. Huấn luyện trước mô hình thưa thớt theo cùng lịch trình huấn luyện như mô hình dày đặc ban đầu.

3. Điều chỉnh tinh mạng thưa thớt được huấn luyện trước trên một tác vụ downstream đã cho theo cách dày đặc bằng cách cho phép các trọng số bằng không học tập.

## 3 THIẾT LẬP THỰC NGHIỆM VÀ KẾT QUẢ

Đầu tiên, chúng tôi cung cấp chi tiết về cài đặt huấn luyện trước của chúng tôi cho GPT-2 Small (125M) và GPT-3 XL (1.3B), cũng như các thiết lập của chúng tôi cho các tác vụ điều chỉnh tinh downstream. Sau đó, chúng tôi so sánh huấn luyện trước thưa thớt và điều chỉnh tinh thưa thớt với huấn luyện trước thưa thớt và điều chỉnh tinh dày đặc để nổi bật lợi ích của việc điều chỉnh tinh theo cách dày đặc. Tiếp theo, chúng tôi xác thực các giả thuyết của mình (tham khảo Phần 2.1) bằng cách đánh giá SPDF trên một số tác vụ trong sinh ngôn ngữ tự nhiên và tóm tắt văn bản. Sau đó, chúng tôi so sánh các không gian con tham số giữa các mô hình được huấn luyện trước và được điều chỉnh tinh. Cuối cùng, chúng tôi trình bày các lợi thế trong hiệu quả huấn luyện w.r.t tổng FLOPs huấn luyện khi sử dụng SPDF so với huấn luyện trước dày đặc tiêu chuẩn và điều chỉnh tinh dày đặc.

Tất cả các mô hình GPT đều được huấn luyện trước và điều chỉnh tinh sử dụng Cerebras CS-2, tận dụng khả năng tăng tốc huấn luyện với độ thưa thớt không có cấu trúc. Hiện tại, các kernel chuyên biệt của Cerebras CS-2 được thiết kế để tạo điều kiện huấn luyện với độ thưa thớt không có cấu trúc tĩnh. Do đó, các kết quả được trình bày trong phần này không bao gồm việc sử dụng các phương pháp huấn luyện thưa thớt động (ví dụ: SET [Mocanu et al., 2018], RigL [Evci et al., 2020], v.v.). Trong Phụ lục C, chúng tôi nhấn mạnh các lợi thế có thể đạt được thông qua độ thưa thớt trọng số không có cấu trúc trên Cerebras CS-2. Chúng tôi cung cấp kết quả tăng tốc đo được so với tăng tốc lý thuyết trên các mức độ thưa thớt khác nhau cho phép nhân ma trận (MatMul) 12k × 12k của một lớp GPT-3 [Lie, 2023].

**Huấn luyện trước Tối ưu Flop thông qua Luật Chia tỷ lệ Chinchilla**

Trước đây, việc huấn luyện tất cả các mô hình ngôn ngữ lớn (ví dụ: GPT-3 [Brown et al., 2020], Gopher [Rae et al., 2021], Jurassic [Lieber et al., 2021], v.v.) trên khoảng 300B token dữ liệu là quy ước trong tài liệu. Gần đây hơn, Chinchilla [Hoffmann et al., 2022] cho thấy cách các tham số và dữ liệu nên được chia tỷ lệ bằng nhau khi ngân sách tính toán tăng, dẫn đến những cải thiện đáng kể trong hiệu quả FLOP. Trong thiết lập huấn luyện trước của chúng tôi, chúng tôi tuân theo luật chia tỷ lệ của Chinchilla cho thấy rằng chúng tôi cần khoảng 20 token trên mỗi tham số. Do đó, đối với GPT-2 Small, một mô hình có 125M tham số cần được huấn luyện trước trên 2.5B token. Sau đó, đối với GPT-3 XL, một mô hình có 1.3B tham số, cần được huấn luyện trước trên 26B token. Trừ khi được nêu khác, chúng tôi huấn luyện trước các mô hình GPT thưa thớt của mình từ đầu trên tập dữ liệu Pile [Gao et al., 2020] trên các mức độ thưa thớt S ∈ {50%,75%}.

**Điều chỉnh tinh trên Các tác vụ Downstream** Chúng tôi nghiên cứu điều chỉnh tinh dày đặc trên một số tác vụ downstream trong sinh ngôn ngữ tự nhiên và tóm tắt văn bản. Chúng tôi tuân theo Hu et al. [2022] trong việc sử dụng ba tập dữ liệu chuẩn sinh ngôn ngữ tự nhiên tiêu chuẩn (tức là E2E [Novikova et al., 2017], WebNLG [Gardent et al., 2017] và DART [Nan et al., 2021]). Ngoài ra, chúng tôi điều chỉnh tinh trên Curation Corpus [Curation, 2020] theo các chi tiết được mô tả trong [Rae et al., 2021]. Chúng tôi điều chỉnh tinh tất cả các tham số của các mô hình GPT được huấn luyện trước và đánh giá hiệu suất điều chỉnh tinh cuối cùng sử dụng các script đánh giá chính thức. Thêm chi tiết về các siêu tham số có thể được tìm thấy trong Phụ lục A.

### 3.1 CHI TIẾT VỀ CÁC TẬP DỮ LIỆU ĐIỀU CHỈNH TINH

Nghiên cứu của chúng tôi sử dụng bốn tập dữ liệu điều chỉnh tinh để điều tra hiệu quả của khung SPDF của chúng tôi. Các tập dữ liệu này được chọn để nghiên cứu tác động của huấn luyện trước thưa thớt trên các kích thước và loại dữ liệu khác nhau, cùng với mức độ khó khăn khác nhau trong các tác vụ.

**Tập dữ liệu thử thách End-2-End (E2E) NLG** chứa khoảng 45k ví dụ huấn luyện, 4.6k xác thực và 4.6k thử nghiệm với 8 trường riêng biệt từ lĩnh vực nhà hàng. Mục tiêu của tác vụ là tạo ra các mô tả ngôn ngữ tự nhiên trong lĩnh vực nhà hàng từ các biểu diễn ý nghĩa. Chúng tôi sử dụng script đánh giá chính thức, báo cáo BLEU [Papineni et al., 2002], NIST [Belz and Reiter, 2006], METEOR [Lavie and Agarwal, 2007], ROUGE-L [Lin, 2004], và CIDEr [Vedantam et al., 2015].

**Tập dữ liệu WebNLG** bao gồm 18k ví dụ huấn luyện, 2.2k xác thực và 2.4k thử nghiệm, trong đó đầu vào là một chuỗi các bộ ba (chủ thể, thuộc tính, đối tượng). Trong các phân chia huấn luyện và xác thực, đầu vào mô tả các thực thể từ 9 danh mục DBpedia riêng biệt. Tập thử nghiệm chứa 15 lĩnh vực khác nhau trong đó 10 chỉ có trong dữ liệu huấn luyện. Ở đây, dữ liệu thử nghiệm được chia thành hai phần, trong đó các danh mục được thấy trong tập huấn luyện ở nửa đầu, trong khi nửa sau bao gồm 5 danh mục chưa thấy. Chúng tôi sử dụng script đánh giá chính thức, báo cáo BLEU, METEOR và TER [Snover et al., 2006]. Tập dữ liệu WebNLG là nhỏ nhất trong ba tác vụ NLG chúng tôi đánh giá.

**DART** là một tập dữ liệu DAta-Record-to-Text (tức là table-to-text) miền mở, với định dạng đầu vào tương tự WebNLG. Nó bao gồm 62.6k ví dụ huấn luyện, 6.9k xác thực và 12.5k thử nghiệm từ một số nguồn: WikiSQL [Zhong et al., 2017], WikiTableQuestions [Pasupat and Liang, 2015], Cleaned E2E, và WebNLG 2017 và áp dụng một số chuyển đổi thủ công hoặc tự động. Chúng tôi sử dụng script đánh giá chính thức và báo cáo BLEU, METEOR và TER. Tập dữ liệu DART được coi là tác vụ NLG thách thức nhất trong ba tác vụ chúng tôi đánh giá.

**Curation Corpus** là một tập dữ liệu được giới thiệu gần đây bao gồm 40,000 tóm tắt văn bản đặt hàng của các bài báo tài chính cho tác vụ tóm tắt văn bản. Chúng tôi tuân theo hướng dẫn trong kho GitHub Curation Corpus để tải xuống khoảng 40k cặp tóm tắt bài báo. Sau khi lọc các ví dụ mà bài báo hoặc tóm tắt trống, chúng tôi còn lại 39,911 ví dụ. Theo Marfurt and Henderson [2021], chúng tôi chia chúng thành các tập huấn luyện/xác thực/thử nghiệm là 80/10/10 để đạt được kích thước phân chia 31,929/3,991/3,991.

### 3.2 ĐIỀU CHỈNH TINH THƯA THỚT SO VỚI ĐIỀU CHỈNH TINH DÀY ĐẶC

Trong phần này, chúng tôi đầu tiên thiết lập thực nghiệm về nhu cầu điều chỉnh tinh dày đặc để giúp giảm thiểu khó khăn của huấn luyện từ thưa thớt đến thưa thớt (tức là huấn luyện trước thưa thớt theo sau bởi điều chỉnh tinh thưa thớt). Trong Hình 2, chúng tôi so sánh điều chỉnh tinh dày đặc với điều chỉnh tinh thưa thớt trên GPT-2 Small và cho thấy rằng trên tất cả ba tác vụ NLG (tức là E2E, WebNLG và DART), điều chỉnh tinh dày đặc giúp giảm sự giảm điểm BLEU so với các baseline dày đặc tương ứng. Ví dụ, mô hình GPT-2 Small thưa thớt 75% trên WebNLG quan sát thấy delta -1.48 và -0.78 trong điểm BLEU, khi điều chỉnh tinh thưa thớt và điều chỉnh tinh dày đặc, tương ứng. Điều này cho thấy rằng huấn luyện trước và điều chỉnh tinh hoàn toàn thưa thớt end-to-end có thể ngăn cản mô hình tổng quát hóa tốt trên các tác vụ downstream. Tuy nhiên, chúng ta có thể giảm thiểu khó khăn của khả năng tổng quát hóa kém do huấn luyện chỉ thưa thớt bằng cách chuyển từ ma trận thưa thớt sang dày đặc trong giai đoạn điều chỉnh tinh. Mặc dù điều chỉnh tinh dày đặc tiêu thụ nhiều FLOPs hơn so với điều chỉnh tinh thưa thớt, tổng FLOPs điều chỉnh tinh so với huấn luyện trước, vẫn không đáng kể (thảo luận thêm trong Phần 3.5).

### 3.3 SPDF TRÊN SINH NGÔN NGỮ TỰ NHIÊN VÀ TÓM TẮT VĂN BẢN

Chúng tôi thực hiện một nghiên cứu mở rộng về SPDF để điều tra thêm hiệu quả của nó trên một tập đa dạng các tác vụ điều chỉnh tinh, khi sử dụng các mô hình GPT-2 Small và GPT-3 XL được huấn luyện trước thưa thớt. Trong phần này, chúng tôi tập trung vào các tác vụ sinh ngôn ngữ tự nhiên (tức là E2E, WebNLG, và DART) và tóm tắt văn bản (tức là Curation Corpus) và tham khảo Bảng 1 cho tất cả các điểm thảo luận. Chúng tôi lưu ý rằng trong Phụ lục B, chúng tôi cung cấp điểm đánh giá trên tất cả các chỉ số được sử dụng để đánh giá chính thức E2E, WebNLG và DART, tương ứng.

Đầu tiên, chúng tôi xác thực Giả thuyết 1 rằng mức độ thưa thớt trọng số cao có thể được tạo ra trong quá trình huấn luyện trước. Kết quả của chúng tôi cho thấy rằng trong hầu hết các cài đặt, chúng ta có thể huấn luyện trước các mô hình GPT này với độ thưa thớt lên đến 75% mà không có sự suy giảm đáng kể trên tất cả các tác vụ NLG. Trên mô hình GPT-3 XL thưa thớt 75%, chúng tôi quan sát thấy delta -0.44, -0.56, và -0.75 trong điểm BLEU cho E2E, WebNLG và DART, tương ứng. Ngoài ra, mô hình GPT-2 Small thưa thớt 50% quan sát thấy delta -0.10, -0.32, và -0.56 trong điểm BLEU cho E2E, WebNLG và DART, tương ứng. Nhìn chung, các phát hiện của chúng tôi cho thấy rằng các mô hình GPT này có thể được huấn luyện trước với độ thưa thớt 50%-75% mà không mất độ chính xác đáng kể trên các tác vụ downstream này.

Thứ hai, chúng tôi xác thực Giả thuyết 2 rằng hiệu suất của mô hình được huấn luyện trước thưa thớt có tương quan với độ khó của tác vụ điều chỉnh tinh. E2E, WebNLG và DART là các tác vụ NLG tập trung vào việc ánh xạ nội dung dữ liệu có cấu trúc thành văn bản mô tả nội dung này. Tác vụ Curation Corpus tập trung vào việc tóm tắt mô tả văn bản. Trong khi cả hai tác vụ đều liên quan đến việc tạo ra ngôn ngữ tự nhiên có tính liên kết về mặt ngữ nghĩa, các tác vụ tóm tắt khó khăn hơn, vì chúng yêu cầu hiểu về các chuỗi dài và nén chuỗi mà không mất thông tin. Trên các tác vụ E2E, WebNLG và DART, GPT-3 XL có thể được huấn luyện trước lên đến độ thưa thớt 75% mà không có sự giảm đáng kể trong điểm BLEU, như đã thảo luận trước đó. Ngược lại, trên Curation Corpus, GPT-3 XL được huấn luyện trước ở độ thưa thớt 75% mất 2.75 perplexity. Nói chung, tất cả các tác vụ NLG data-to-text đều đạt được sự suy giảm thấp hơn so với tác vụ tóm tắt Curation Corpus khó khăn hơn ở mức độ thưa thớt cao hơn.

Cuối cùng, chúng tôi xác thực Giả thuyết 3 rằng khi kích thước mô hình tăng lên, nó trở nên dễ chấp nhận hơn với mức độ thưa thớt cao hơn. Chúng tôi phân tích sự giảm tương đối trong hiệu suất giữa baseline dày đặc và các biến thể thưa thớt của nó cho GPT-2 Small và GPT-3 XL. Xu hướng này rõ ràng trên tác vụ Curation Corpus khó khăn hơn ở độ thưa thớt 75%, nơi so với baseline dày đặc, mô hình GPT-3 XL lớn hơn có delta perplexity +2.75 so với delta +3.76 tệ hơn quan sát được trong mô hình GPT-2 Small nhỏ hơn. Tương tự, trên tác vụ DART, tác vụ NLG thách thức nhất trong ba tác vụ chúng tôi đánh giá, delta trong điểm BLEU là -1.33 và -0.75 cho GPT-2 Small và GPT-3 XL, tương ứng. Những quan sát này cho thấy rằng khi kích thước mô hình ngôn ngữ tăng lên, nó bị ảnh hưởng ít hơn về hiệu suất tác vụ downstream khi huấn luyện với độ thưa thớt cao.

### 3.4 KHÔNG GIAN CON THAM SỐ HUẤN LUYỆN TRƯỚC SO VỚI ĐIỀU CHỈNH TINH

Trong phần này, chúng tôi phân tích các không gian con tham số của mô hình được huấn luyện trước và các tham số được điều chỉnh tinh của nó trên tất cả các lớp để hiểu thêm về (a) hành vi của các biểu diễn được huấn luyện trước dày đặc và thưa thớt khi được điều chỉnh tinh, và (b) tác động của việc chia tỷ lệ kích thước mô hình trên các không gian con tham số giữa hai giai đoạn. Lấy cảm hứng từ Radiya-Dixit and Wang [2020], chúng tôi đo khoảng cách góc (tức là khoảng cách cosine) giữa các tham số mô hình được huấn luyện trước và các tham số được điều chỉnh tinh của nó trên một tác vụ downstream đã cho. Cụ thể, trong tất cả các lớp của mô hình ngôn ngữ, chúng tôi kiểm tra bốn ma trận trọng số trong mô-đun self-attention; WQ(query), WK(key), WV(value) và WD(attention output projection) và hai ma trận trong mô-đun MLP; WI(intermediate) và WO(MLP output projection). Trong phân tích này, chúng tôi tập trung vào DART, tác vụ NLG khó nhất, và báo cáo khoảng cách cosine cho tất cả các mô-đun trong mỗi lớp của GPT-2 Small và GPT-3 XL được huấn luyện trước dày đặc và thưa thớt 75%.

Đầu tiên, chúng tôi nhằm hiểu hành vi của các không gian con tham số của các mô hình được huấn luyện trước dày đặc và thưa thớt khi được điều chỉnh tinh. Trong GPT-2 Small (xem Hình 3) và GPT-3 XL (xem Hình 4), chúng tôi quan sát thấy rằng các tham số được huấn luyện trước dày đặc và các tham số được điều chỉnh tinh của nó có khoảng cách cosine rất nhỏ trong hầu như tất cả các mô-đun trên mỗi lớp, trong khi mô hình thưa thớt 75% có khoảng cách cosine lớn hơn trong một số mô-đun (ví dụ: WD và WO) trên tất cả các lớp. Ở đây, các tham số được điều chỉnh tinh của mô hình dày đặc đòi hỏi ít thay đổi hơn trong không gian con tham số so với các tham số được huấn luyện trước, trong khi mô hình thưa thớt đòi hỏi nhiều chuyển động hơn trong một số mô-đun để học tác vụ downstream. Điều này cho thấy rằng các mô hình được huấn luyện trước học các biểu diễn văn bản chất lượng cao cần ít chuyển động hơn trong không gian con tham số để thích ứng với tác vụ downstream. Mặc dù mô hình thưa thớt có ít dung lượng biểu diễn hơn trong các tham số được huấn luyện trước của nó, nó có khả năng thích ứng một số mô-đun thông qua điều chỉnh tinh dày đặc để học tác vụ downstream và duy trì cạnh tranh với hiệu suất của mô hình dày đặc.

Tiếp theo, chúng tôi nghiên cứu tác động của kích thước mô hình và các không gian con tham số của các tham số được huấn luyện trước và được điều chỉnh tinh. Rõ ràng, trong Hình 4, chúng tôi quan sát thấy rằng mô hình GPT-3 XL được huấn luyện trước dày đặc có khoảng cách cosine rất nhỏ trên tất cả các mô-đun trong hầu như mỗi lớp, so với GPT-2 Small. Điều này cho thấy rằng khi chúng ta tăng dung lượng mô hình hóa của mô hình ngôn ngữ, chỉ một vài cập nhật tham số mô hình đi qua một khoảng cách rất ngắn trong không gian tham số. Điều này dẫn đến các trọng số được huấn luyện trước và được điều chỉnh tinh rất gần nhau trên tất cả các mô-đun trong hầu như mỗi lớp. Mô hình ngôn ngữ lớn hơn có khả năng học các biểu diễn chất lượng cao hơn, do đó đòi hỏi ít chuyển động hơn trong không gian con tham số điều chỉnh tinh. Ngay cả ở độ thưa thớt 75%, mô hình GPT-3 XL đòi hỏi ít thay đổi đáng kể hơn đối với các tham số được huấn luyện trước so với GPT-2 Small để thực hiện cạnh tranh tốt với mô hình dày đặc. Cho rằng nhiều lớp trải qua thay đổi rất nhỏ trong không gian con tham số, chúng tôi để lại việc điều tra đóng băng các mô-đun này trong giai đoạn điều chỉnh tinh cho nghiên cứu tương lai.

### 3.5 HIỆU QUẢ HUẤN LUYỆN SPDF

Chúng tôi so sánh khung huấn luyện trước dày đặc tiêu chuẩn theo sau bởi điều chỉnh tinh dày đặc với SPDF và nổi bật việc giảm FLOP tiềm năng mà chúng ta có thể đạt được. Trong Bảng 2, chúng tôi báo cáo tổng FLOPs (tức là cả lan truyền tiến và lan truyền ngược) cần thiết cho huấn luyện trước và điều chỉnh tinh dày đặc các mô hình GPT-2 Small và GPT-3 XL trên mỗi tác vụ chúng tôi đánh giá. Chúng tôi lưu ý rằng trong mô hình GPT-2 Small, tỷ lệ phần trăm của attention và vocab embeddings FLOPs chiếm khoảng 13.3% và 27% của tổng FLOPs, tương ứng. Do đó, ở 75%, chúng ta đạt được khoảng 1.65x giảm FLOP so với baseline dày đặc. Tuy nhiên, trong GPT-3 XL lớn hơn, tỷ lệ phần trăm của attention và vocab embeddings FLOPs chiếm 13.3% và 6.8%, tương ứng. Kết quả là, ở quy mô GPT-3 XL, SPDF cung cấp gần 2.5x giảm FLOP so với baseline dày đặc khi huấn luyện trước với độ thưa thớt 75%. Xu hướng giảm FLOP so với baseline dày đặc tiếp tục tăng với các mô hình lớn hơn, vì vậy lợi ích tiềm năng từ huấn luyện trước thưa thớt cải thiện khi kích thước mô hình tăng lên. Chúng tôi cũng nhấn mạnh rằng tổng FLOPs điều chỉnh tinh là một phần nhỏ của tổng FLOPs huấn luyện trước. Trong Phụ lục A.4, chúng tôi cung cấp chi tiết về cách tổng FLOPs huấn luyện trước và điều chỉnh tinh cho GPT-2 Small và GPT-3 XL được tính toán.

## 4 NGHIÊN CỨU LIÊN QUAN

**Zero-Shot so với Fine-tuning** Các nghiên cứu gần đây đã cho thấy rằng các mô hình ngôn ngữ lớn có thể đạt được hiệu suất hợp lý mà không có bất kỳ cập nhật tham số nào [Brown et al., 2020, Chowdhery et al., 2022, Rae et al., 2021, Smith et al., 2022], thường được gọi là cài đặt zero-shot hoặc few-shot. Khi không có tham số nào được điều chỉnh tinh, việc đóng khung một tác vụ mục tiêu theo mục tiêu huấn luyện trước cho phép học zero-shot hoặc few-shot sử dụng prompt cụ thể cho tác vụ và một vài ví dụ của tác vụ [Brown et al., 2020]. Tuy nhiên, trong khi học few-shot như vậy đơn giản khi sử dụng các mô hình lớn như vậy, có các phương pháp thay thế để đạt được độ chính xác tác vụ tương tự sử dụng các mô hình nhỏ hơn [Schick and Schütze, 2021]. Trong nghiên cứu gần đây, Cohen et al. [2022] chứng minh rằng trong khi việc chia tỷ lệ kích thước của LaMDA có thể cải thiện chất lượng, việc kết hợp chia tỷ lệ với điều chỉnh tinh có thể cải thiện mô hình trên tất cả các chỉ số bao gồm chất lượng, an toàn và tính căn cứ. Solaiman and Dennison [2021] cho thấy rằng điều chỉnh tinh cũng giúp cập nhật hành vi mô hình ngôn ngữ để giảm thiểu đầu ra có hại, điều này rất quan trọng cho việc triển khai thực tế của LLM (ví dụ: ChatGPT [OpenAI, 2022], Bard [Pichai, 2023], v.v.). Để đạt được hiệu suất tốt nhất trong thực tế, điều chỉnh tinh sẽ tiếp tục là phương thức hoạt động khi sử dụng LLM được huấn luyện trước. Do đó, nghiên cứu của chúng tôi tập trung vào huấn luyện trước và điều chỉnh tinh mô hình ngôn ngữ trên một tập đa dạng các tác vụ, bao gồm sinh ngôn ngữ tự nhiên và tóm tắt văn bản.

**Điều chỉnh tinh Hiệu quả** Trong khi hầu hết các mô hình quy mô lớn như GPT [Brown et al., 2020, Smith et al., 2022] hoặc T5 [Raffel et al., 2022] được huấn luyện dày đặc, có các nghiên cứu [Houlsby et al., 2019a, Li and Liang, 2021b, Zaken et al., 2021, Hu et al., 2022] khám phá việc sử dụng dung lượng hạn chế (điều chỉnh một vài lớp hoặc tập con tham số) trong các mô hình được huấn luyện trước để điều chỉnh tinh trên các tác vụ downstream. Các nghiên cứu này cho thấy rằng tổng dung lượng mô hình hóa là không cần thiết cho điều chỉnh tinh trên các tác vụ downstream. Nghiên cứu của chúng tôi rút ra một số cảm hứng từ các nghiên cứu này để khai thác dung lượng hạn chế của mô hình cho các tác vụ cuối cùng. Tuy nhiên, chúng tôi chọn giảm FLOPs cho huấn luyện trước (FLOPs huấn luyện nhiều hơn đáng kể so với điều chỉnh tinh) và sau đó thêm lại tất cả dung lượng mô hình hóa trong quá trình điều chỉnh tinh. Điều này cho phép chúng tôi huấn luyện các mô hình lớn một cách hiệu quả và vẫn giữ lại độ chính xác có thể so sánh với các baseline dày đặc. Mặc dù chúng tôi không khám phá điều chỉnh tinh hiệu quả trong nghiên cứu của mình, chúng tôi để lại việc khám phá sử dụng các lịch trình độ thưa thớt thay thế [Zhu and Gupta, 2018, Liu et al., 2021], thích ứng một tập con tham số trong quá trình điều chỉnh tinh [Ding et al., 2022] và áp đặt cấu trúc low-rank [Hu et al., 2022] cho nghiên cứu tương lai.

**Kỹ thuật Làm thưa thớt Trọng số** Nhiều kỹ thuật làm thưa thớt trọng số không có cấu trúc đã được đề xuất trong tài liệu cho việc huấn luyện mạng nơ-ron [Hoefler et al., 2022], có thể được phân loại thành độ thưa thớt tĩnh và độ thưa thớt động. Các phương pháp độ thưa thớt tĩnh có cấu trúc độ thưa thớt cố định (tức là mặt nạ độ thưa thớt) được xác định tại thời điểm khởi tạo [Lee et al., 2019, Wang et al., 2020]. Ngược lại, các phương pháp huấn luyện thưa thớt động (DST) cắt tỉa (loại bỏ) và thêm (tái sinh) trọng số một cách lặp đi lặp lại trong quá trình huấn luyện [Mocanu et al., 2018, Evci et al., 2020, Jayakumar et al., 2020, Huang et al., 2022] để tìm ra mạng con thưa thớt tốt nhất có thể trong khi vẫn giữ độ chính xác có thể so sánh với các baseline dày đặc. Mặc dù các phương pháp huấn luyện thưa thớt động có thể giúp đạt được cải thiện Pareto về số lượng FLOPs huấn luyện so với độ chính xác, chúng tôi để lại điều này cho nghiên cứu tương lai. Lấy cảm hứng từ [Li et al., 2022], cho thấy rằng việc chia tỷ lệ kích thước của CNN đóng khoảng cách giữa một mạng thưa thớt được cắt tỉa ngẫu nhiên và đối tác dày đặc của nó, chúng tôi tập trung nghiên cứu của mình vào các mô hình ngôn ngữ với độ thưa thớt tĩnh. Trong khi Dao et al. [2022a] chứng minh lợi ích của huấn luyện từ thưa thớt đến dày đặc, họ chủ yếu áp dụng nó trong quá trình huấn luyện trước và thay vào đó, tập trung nghiên cứu của họ vào điều chỉnh tinh từ dày đặc đến thưa thớt tương tự như các nỗ lực điều chỉnh tinh hiệu quả khác. Trong nghiên cứu của chúng tôi, chúng tôi cho thấy rằng huấn luyện trước thưa thớt theo sau bởi điều chỉnh tinh dày đặc trên các tác vụ downstream có thể ngang bằng với độ chính xác của một mô hình được huấn luyện trước dày đặc trên nhiều tác vụ, trong khi giảm đáng kể tổng FLOPS huấn luyện.

## 5 KẾT LUẬN VÀ NGHIÊN CỨU TƯƠNG LAI

Trong nghiên cứu này, chúng tôi giới thiệu Huấn luyện Thưa thớt trước và Điều chỉnh Dày đặc (SPDF) để giảm FLOPs tính toán của việc huấn luyện mô hình GPT sử dụng độ thưa thớt trọng số. Theo hiểu biết của chúng tôi, đây là lần đầu tiên một mô hình GPT lớn được huấn luyện trước với độ thưa thớt cao (50%-75%) mà không có mất mát đáng kể trong các chỉ số tác vụ downstream. Trong nghiên cứu của chúng tôi, chúng tôi chỉ sử dụng độ thưa thớt tĩnh đơn giản, có thể nói là cách ngây thơ nhất để tạo độ thưa thớt trong mạng nơ-ron. Đối với nghiên cứu tương lai, có một số hướng tự nhiên để cải thiện kết quả của chúng tôi trên các mô hình lớn hơn, bao gồm các phương pháp độ thưa thớt động, kỹ thuật tối ưu hóa tốt hơn cho huấn luyện thưa thớt, và các kiến trúc phù hợp với huấn luyện thưa thớt. Hơn nữa, để hạn chế chi phí tính toán của nghiên cứu chúng tôi, chúng tôi đã huấn luyện các mô hình GPT của mình theo luật chia tỷ lệ Chinchilla. Mặc dù lịch trình huấn luyện trước Chinchilla đã được chứng minh là tối ưu FLOP cho các mô hình dày đặc, chúng tôi dự định điều tra mức độ chuyển giao tốt của nó sang các mô hình thưa thớt. Nghiên cứu tương lai của chúng tôi cũng sẽ điều tra chia tỷ lệ thưa thớt bên ngoài luật chia tỷ lệ dày đặc Chinchilla. Bất kể, chúng tôi thấy tiềm năng to lớn của độ thưa thớt trọng số không có cấu trúc để tăng tốc huấn luyện LLM, được hỗ trợ bởi những tiến bộ gần đây trong các bộ tăng tốc phần cứng học sâu.

**Đóng góp của Tác giả**

Chúng tôi cung cấp tóm tắt đóng góp của mỗi tác giả:

• **Vithursan Thangarasa** dẫn đầu nỗ lực huấn luyện/đánh giá các mô hình GPT quy mô lớn trên Cerebras CS-2, đánh giá kỹ thuật trong các thiết lập huấn luyện hiệu quả FLOP khác nhau, đưa ra nhiều tác vụ downstream, phân tích các không gian con tham số, và viết bản thảo.

• **Abhay Gupta** giúp huấn luyện trước các mô hình GPT trên CS-2 và chạy các mô hình tham chiếu để xác thực thiết lập huấn luyện và điều chỉnh tinh của chúng tôi.

• **William Marshall** đưa ra các tác vụ downstream khác nhau trên CS-2 và hỗ trợ chạy các thí nghiệm điều chỉnh tinh.

• **Tianda Li** hỗ trợ William Marshall và Vithursan Thangarasa chạy các thí nghiệm điều chỉnh tinh.

• **Kevin Leong** hỗ trợ Abhay Gupta huấn luyện trước các mô hình GPT trên CS-2 và cung cấp sự giúp đỡ quan trọng trong việc gỡ lỗi các vấn đề.

• **Dennis DeCoste** hình thành ý tưởng chính ban đầu.

• **Sean Lie** điều phối việc đưa GPT lên CS-2 và tham gia vào xác thực thực nghiệm và phân tích.

• **Shreyas Saxena** tư vấn toàn bộ nỗ lực, đưa ra bằng chứng khái niệm ban đầu và thử nghiệm với các kỹ thuật độ thưa thớt khác nhau.

• **Shreyas Saxena và Sean Lie** thường xuyên gặp gỡ với Vithursan Thangarasa để thảo luận công việc và giúp sửa đổi nhiều phiên bản của bản thảo.

## 6 LỜI CẢM ƠN

Chúng tôi cảm ơn Anshul Samar, Dimitrios Sinodinos, và Joel Hestness, vì những chỉnh sửa và gợi ý hữu ích đã cải thiện sự rõ ràng của bản thảo chúng tôi.

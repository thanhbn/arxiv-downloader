# 2310.19470.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/pruning/2310.19470.pdf
# Kích thước tệp: 24435044 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Xuất bản trong Transactions on Machine Learning Research (05/2025)
Nối cầu Lottery Ticket và Grokking:
Hiểu về Grokking từ Cấu trúc Nội tại của Mạng
Gouki Minegishi Yusuke Iwasawa Yutaka Matsuo
{minegishi,iwasawa,matsuo}@weblab.t.u-tokyo.ac.jp
Đại học Tokyo
Được đánh giá trên OpenReview: https: // openreview. net/ forum? id= eQeYyup1tm
Tóm tắt
Grokking là một hiện tượng thú vị của khái quát hóa chậm trễ, trong đó các mạng neural ban đầu ghi nhớ dữ liệu huấn luyện với độ chính xác hoàn hảo nhưng thể hiện khả năng khái quát hóa kém, sau đó chuyển đổi sang một giải pháp khái quát hóa với việc tiếp tục huấn luyện. Trong khi các yếu tố như chuẩn trọng số và độ thưa thớt đã được đề xuất để giải thích sự khái quát hóa chậm trễ này, ảnh hưởng của cấu trúc mạng vẫn chưa được khám phá đầy đủ. Trong công trình này, chúng tôi liên kết hiện tượng grokking với giả thuyết lottery ticket để điều tra tác động của cấu trúc mạng nội tại. Chúng tôi chứng minh rằng việc sử dụng lottery tickets được thu thập trong giai đoạn khái quát hóa (gọi là grokked tickets) làm giảm đáng kể sự khái quát hóa chậm trễ trên nhiều tác vụ khác nhau, bao gồm các phép toán số học modular, hồi quy đa thức, sparse parity, và phân loại MNIST. Thông qua các thí nghiệm có kiểm soát, chúng tôi cho thấy rằng việc giảm thiểu khái quát hóa chậm trễ không chỉ do việc giảm chuẩn trọng số hoặc tăng độ thưa thớt, mà là do việc khám phá ra các mạng con tốt. Hơn nữa, chúng tôi phát hiện rằng grokked tickets thể hiện các mẫu trọng số tuần hoàn, các thuộc tính đồ thị có lợi như tăng độ dài đường dẫn trung bình và giảm hệ số nhóm, và trải qua các thay đổi cấu trúc nhanh chóng trùng với những cải thiện trong khái quát hóa. Ngoài ra, các kỹ thuật cắt tỉa như thuật toán edge-popup có thể xác định những cấu trúc hiệu quả này mà không cần sửa đổi trọng số, từ đó biến đổi các mạng ghi nhớ thành các mạng khái quát hóa. Những kết quả này nhấn mạnh cái nhìn mới mẻ rằng việc khám phá cấu trúc đóng vai trò then chốt trong việc hiểu grokking.

1 Giới thiệu
Hiểu về cơ chế khái quát hóa là một câu hỏi trung tâm trong việc hiểu hiệu quả của mạng neural. Gần đây, Power và cộng sự (2022) đã khám phá ra hiện tượng thú vị của khái quát hóa chậm trễ (grokking); các mạng neural ban đầu đạt được một mạng ghi nhớ Cmem với độ chính xác huấn luyện hoàn hảo nhưng khái quát hóa kém, tuy nhiên việc huấn luyện thêm sẽ chuyển đổi giải pháp sang một mạng khái quát hóa Cgen. Hiện tượng này, trái ngược với kỳ vọng chuẩn của machine learning, đang được nghiên cứu để trả lời câu hỏi: điều gì ẩn sau sự chuyển đổi giữa ghi nhớ và khái quát hóa? (Liu et al., 2022; 2023a)

Về mối quan hệ giữa khái quát hóa và deep learning nói chung, người ta biết rằng cấu trúc của mạng ảnh hưởng đáng kể đến hiệu suất khái quát hóa. Ví dụ, hiệu suất nhận dạng hình ảnh đã cải thiện đáng kể bằng cách tận dụng cấu trúc convolution (Krizhevsky et al., 2012). Hơn nữa, như được chỉ ra trong Neyshabur (2020), việc kết hợp regularization β-Lasso vào MLPs fully connected tạo điều kiện cho sự xuất hiện của tính địa phương — giống với các cấu trúc trong CNNs — dẫn đến hiệu suất cải thiện trong các tác vụ hình ảnh. Từ một góc độ hơi khác, Frankle & Carbin (2019) đề xuất giả thuyết lottery ticket (LTH), gợi ý rằng các mạng con tốt (cấu trúc tốt) giúp đạt được hiệu suất tốt hơn với hiệu quả mẫu tốt hơn (Zhang et al., 2021). Cũng vậy, Ramanujan et al. (2020) cho thấy rằng việc khám phá cấu trúc đơn thuần có thể đạt được hiệu suất tương đương với cập nhật trọng số, gợi ý rằng các mạng con tốt đủ để đạt được hiệu suất khái quát hóa.

1arXiv:2310.19470v3 [cs.LG] 9 May 2025

--- TRANG 2 ---
Xuất bản trong Transactions on Machine Learning Research (05/2025)

Hình 1: (Trái) Độ chính xác của mô hình dày đặc và lottery ticket thu được tại giải pháp khái quát hóa (grokked ticket). Khi sử dụng lottery ticket (mạng con tốt), độ chính xác train và test tăng gần như tương tự, tức là thời gian từ ghi nhớ (tmem) đến khái quát hóa (tgen) đã được tăng tốc đáng kể. Lưu ý rằng không chỉ phép trừ (tgen−tmem) mà tỷ lệ (tgen/tmem) cũng được cải thiện đáng kể, có nghĩa là đó không chỉ là vấn đề học nhanh hơn. (Phải) Ba giả thuyết về lý do tại sao khái quát hóa chậm trễ được giảm với lottery ticket. Chúng tôi cho thấy rằng điều đó không phải do giảm chuẩn trọng số hoặc tăng độ thưa thớt, mà là do việc khám phá cấu trúc tốt.

Trong khi tầm quan trọng của cấu trúc được biết đến rộng rãi nói chung, mối liên hệ của nó với hiện tượng grokking chưa được điều tra đủ. Tương tự như nghiên cứu của chúng tôi, một số nghiên cứu trước đó kết nối hiện tượng grokking với thuộc tính của mạng, ví dụ như chuẩn trọng số và độ thưa thớt của mạng. Ví dụ, Liu et al. (2023a) xác nhận thực nghiệm rằng các giải pháp khái quát hóa có chuẩn nhỏ hơn so với các giải pháp ghi nhớ. Bài báo gốc (Power et al., 2022) cho thấy rằng việc thêm weight decay trong quá trình huấn luyện là cần thiết để kích hoạt grokking. Tuy nhiên, công trình của chúng tôi khác với những nghiên cứu này bằng cách thảo luận về mối quan hệ giữa quá trình khám phá cấu trúc tốt (tức là mạng con) và grokking thay vì chỉ giảm chuẩn trọng số.

Để điều tra vai trò của cấu trúc trong hiện tượng grokking, đầu tiên chúng tôi chứng minh rằng khi sử dụng lottery ticket thu được tại giải pháp khái quát hóa (được gọi là grokked tickets), khái quát hóa chậm trễ được giảm đáng kể. Hình 1 (trái) minh họa rằng độ chính xác train và test tăng gần như đồng thời với grokked tickets, không giống như các mạng dày đặc khởi tạo ngẫu nhiên nơi khái quát hóa chậm trễ xảy ra. Như sẽ được trình bày sau, kết quả này liên quan đến tỷ lệ cắt tỉa, với tỷ lệ cắt tỉa thích hợp dẫn đến ít trễ hơn. Chúng tôi tiến hành thêm các thí nghiệm từ nhiều góc độ để hiểu tại sao khái quát hóa chậm trễ được giảm đáng kể với grokked tickets. Đầu tiên, như được minh họa trong Hình 1 (phải), chúng tôi phân tách sự khác biệt giữa grokked ticket và mạng dày đặc khởi tạo ngẫu nhiên thành ba yếu tố: (1) chuẩn trọng số nhỏ, (2) độ thưa thớt và (3) cấu trúc tốt. Chúng tôi điều tra yếu tố nào trong số này góp phần vào việc giảm đáng kể khái quát hóa chậm trễ. Đối với (1) chuẩn trọng số, chúng tôi thấy rằng các mạng dày đặc có cùng chuẩn trọng số ban đầu như grokked ticket không khái quát hóa nhanh hơn, cho thấy chuẩn trọng số không phải là nguyên nhân. Đối với (2) độ thưa thớt, các mạng có cùng kích thước tham số sử dụng các phương pháp cắt tỉa nổi tiếng (Wang et al., 2019; Lee et al., 2019; Tanaka et al., 2020) cũng không khái quát hóa nhanh hơn, cho thấy độ thưa thớt không phải là nguyên nhân. Những kết quả này gợi ý rằng (3) cấu trúc tốt là yếu tố cần thiết để hiểu grokking.

Dựa trên những phát hiện này, chúng tôi đào sâu hơn vào việc hiểu bản chất và vai trò của những thuộc tính cấu trúc này trong hiện tượng grokking. Cụ thể, chúng tôi điều tra một số khía cạnh chính. Đầu tiên, để xác định liệu việc thu được cấu trúc có đồng bộ với những cải thiện trong hiệu suất khái quát hóa hay không, chúng tôi sử dụng khoảng cách Jaccard (Jaccard, 1901) như một thước đo khoảng cách cấu trúc. Phân tích của chúng tôi cho thấy rằng cấu trúc của mạng con thay đổi nhanh chóng trong quá trình chuyển đổi từ ghi nhớ sang khái quát hóa. Sự thích ứng cấu trúc nhanh chóng này được đồng bộ với những cải thiện trong hiệu suất khái quát hóa. Thứ hai, chúng tôi

--- TRANG 3 ---
Xuất bản trong Transactions on Machine Learning Research (05/2025)

xem xét cả các thuộc tính lý thuyết đồ thị, bao gồm tăng độ dài đường dẫn trung bình và giảm hệ số nhóm, và tính chất tuần hoàn của tác vụ Modular Addition (Nanda et al., 2023). Chúng tôi thấy rằng các thuộc tính đồ thị có lợi xuất hiện và phù hợp chặt chẽ với khái quát hóa cải thiện, và mô hình khai thác tính tuần hoàn vốn có của tác vụ để khám phá các mạng con có cấu trúc nội tại tốt phù hợp để đạt được khái quát hóa tốt hơn. Cuối cùng, dựa trên kết quả của chúng tôi cho thấy rằng việc khám phá cấu trúc là rất quan trọng đối với grokking, chúng tôi chứng minh rằng cắt tỉa tạo điều kiện cho khái quát hóa. Chúng tôi sử dụng thuật toán edge-popup (Ramanujan et al., 2020) để xác định cấu trúc tốt trong khi giữ nguyên trọng số. Các thí nghiệm của chúng tôi cho thấy rằng mạng ghi nhớ có thể được chuyển đổi thành mạng khái quát hóa thông qua cắt tỉa mà không cần cập nhật trọng số, từ đó củng cố tuyên bố của chúng tôi rằng khái quát hóa chậm trễ xảy ra do việc khám phá một cấu trúc tốt.

Tóm lại, những đóng góp của chúng tôi như sau:
• Liên kết Lottery Tickets và Grokking (phần 3): Chúng tôi điều tra vai trò của cấu trúc nội tại (mạng con) trong quá trình grokking bằng cách kết nối lottery tickets với khái quát hóa chậm trễ. Kết quả của chúng tôi chứng minh rằng việc sử dụng lottery tickets làm giảm đáng kể khái quát hóa chậm trễ, nhấn mạnh tầm quan trọng của mạng con trong việc đạt được khái quát hóa hiệu quả.

• Tách biệt Thuộc tính của Lottery Tickets (phần 4): Chúng tôi tách biệt một cách có hệ thống các thuộc tính nội tại của lottery tickets thành ba thành phần: (1) chuẩn trọng số, (2) độ thưa thớt, và (3) cấu trúc tốt. Thông qua một loạt thí nghiệm có kiểm soát, chúng tôi cho thấy rằng không phải chuẩn trọng số hay độ thưa thớt đơn lẻ nào giải thích được việc giảm khái quát hóa chậm trễ. Thay vào đó, việc khám phá một cấu hình cấu trúc tốt trong mạng là quan trọng.

• Hiểu về Đặc điểm của Cấu trúc Tốt (phần 5): Chúng tôi đào sâu hơn vào bản chất của các cấu trúc có lợi được khám phá bởi lottery tickets. Những phát hiện của chúng tôi tiết lộ rằng grokked tickets thể hiện các biểu diễn trọng số tuần hoàn và trải qua những thay đổi cấu trúc nhanh chóng được đồng bộ với những cải thiện trong hiệu suất khái quát hóa. Hơn nữa, chúng tôi chứng minh rằng các kỹ thuật cắt tỉa, như thuật toán edge-popup, có thể xác định những cấu trúc hiệu quả này mà không thay đổi trọng số, hiệu quả chuyển đổi các mạng ghi nhớ thành các mạng khái quát hóa. Điều này nhấn mạnh vai trò then chốt của việc khám phá cấu trúc trong việc giảm thiểu khái quát hóa chậm trễ.

2 Nền tảng

Grokking là một hiện tượng trong đó khái quát hóa xảy ra lâu sau khi overfitting dữ liệu huấn luyện (như được hiển thị trong Hình 1 (trái)). Hiện tượng này ban đầu được quan sát trong tác vụ cộng modular ((a+b)mod p cho a,b∈(0,···,p−1)), và cùng hiện tượng đã được quan sát trong các tập dữ liệu phức tạp hơn, bao gồm số học modular (Gromov, 2023; Davies et al., 2023; Rubin et al., 2023; Stander et al., 2023; Furuta et al., 2024), phân tích ngữ nghĩa (Liu et al., 2023a), n-k parity (Merrill et al., 2023), hồi quy đa thức (Kumar et al., 2023), tác vụ phân cấp (Murty et al., 2023) và phân loại hình ảnh (Liu et al., 2023a; Radhakrishnan et al., 2022). Bài báo này chủ yếu tập trung vào grokking trong các tác vụ số học modular thường được sử dụng trong các nghiên cứu trước.

Để hiểu grokking, các nghiên cứu trước đã đề xuất các giải thích có thể, bao gồm cơ chế slingshot (Thilak et al., 2022), random walk giữa các minimizers (Millidge, 2022), xây dựng biểu diễn tốt (Liu et al., 2022), quy mô chuẩn trọng số (Liu et al., 2023a; Varma et al., 2023), tính đơn giản của đặc trưng Fourier (Nanda et al., 2023) và độ thưa thớt của mạng khái quát hóa (Miller et al., 2023).

Trong số đó, một trong những giải thích chủ đạo về cách mạng thay đổi trong quá trình grokking là tính đơn giản của giải pháp khái quát hóa, đặc biệt tập trung vào chuẩn trọng số của các tham số mạng ∥θ∥2. Ví dụ, bài báo gốc (Power et al., 2022) khẳng định rằng weight decay đóng vai trò then chốt trong grokking, tức là độ chính xác test sẽ không tăng mà không có weight decay. Liu et al. (2023a) phân tích các địa hình loss của tập dữ liệu train và test, xác minh rằng grokking xảy ra bằng cách vào vùng khái quát hóa được định nghĩa bởi chuẩn L2, với các mô hình có giá trị ban đầu lớn θ0. Gần đây hơn, Varma et al. (2023) chứng minh rằng giải pháp khái quát hóa có thể tạo ra logits cao hơn với chuẩn trọng số nhỏ hơn. Trong bài báo này, chúng tôi xem xét những thay đổi trong cấu trúc của mạng và chứng minh rằng mạng không chỉ đơn giản giảm chuẩn trọng số tổng thể mà tìm kiếm cấu trúc tốt trong chính nó.

--- TRANG 4 ---
Xuất bản trong Transactions on Machine Learning Research (05/2025)

Một số nghiên cứu đã đề xuất rằng việc thu được biểu diễn tốt là chìa khóa để hiểu grokking. Ví dụ, Power et al. (2022); Liu et al. (2022) giải thích rằng tôpô của các embedding lý tưởng có xu hướng là vòng tròn hoặc hình trụ trong bối cảnh các tác vụ cộng modular. Nanda et al. (2023) xác định thuật toán lượng giác mà các mạng giải quyết phép cộng modular sau grokking và cho thấy rằng nó phát triển một cách mượt mà qua quá trình huấn luyện. Gromov (2023) cho thấy một giải pháp phân tích cho các biểu diễn khi học phép cộng modular với MLP. Zhong et al. (2023) cho thấy, sử dụng phép cộng modular như một vấn đề nguyên mẫu, rằng việc khám phá thuật toán trong mạng neural đôi khi phức tạp hơn. Những nghiên cứu này hỗ trợ chất lượng biểu diễn như chìa khóa để phân biệt các mạng ghi nhớ và khái quát hóa; tuy nhiên, những nghiên cứu này không giải thích điều gì đang xảy ra trong cấu trúc của mạng.

Giả thuyết lottery ticket được đề xuất bởi Frankle & Carbin (2019) đã thu hút sự chú ý như một giải thích cho lý do tại sao các mạng neural over-parameterized thể hiện khả năng khái quát hóa (Allen-Zhu et al., 2019). Một cách không chính thức, giả thuyết lottery ticket nói rằng các mạng over-parameterized được khởi tạo ngẫu nhiên bao gồm các mạng con thưa thớt đạt được hiệu suất tốt sau khi huấn luyện, và sự tồn tại của các mạng con là chìa khóa để đạt được khái quát hóa tốt trong mạng neural sâu. Tuyên bố này ban đầu được chứng minh thực nghiệm, nhưng nền tảng lý thuyết cũng đã được thiết lập (Frankle et al., 2020; Sakamoto & Sato, 2022). Một cách chính thức hơn, quá trình bao gồm các bước sau:

1. Khởi tạo mạng dày đặc fθ0 và huấn luyện mạng trong t epochs để thu được trọng số θt
2. Thực hiện cắt tỉa k% trên mạng đã huấn luyện dựa trên giá trị tuyệt đối |θt|. Quá trình này, được biết đến như magnitude pruning, tạo ra một mask mkt ∈{0,1}|θt|.
3. Đặt lại trọng số của mạng về giá trị ban đầu θ0 và lấy một mạng con fθ0⊙mkt, biểu diễn lottery ticket. Huấn luyện mạng con trong t′ epochs và thu được fθ′t′⊙mkt.

Sau khi khám phá ra lottery tickets, Ramanujan et al. (2020) cho thấy rằng tồn tại strong lottery tickets, đạt được hiệu suất tốt mà không cần cập nhật trọng số. Họ sử dụng thuật toán edge-popup (Ramanujan et al., 2020) để chọn mạng con dựa trên điểm số s (s∈R|θ0|). Nói cách khác, khi cắt tỉa một tỷ lệ k của trọng số từ trọng số đã cho θ0, mô hình dự đoán sử dụng các cạnh với điểm số (1−k) hàng đầu trong một lượt forward pass. Để có mô tả chi tiết về edge-popup, tham khảo Phụ lục A. Trong phần 5, chúng tôi sử dụng thuật toán edge-popup để kiểm tra xem cắt tỉa có thể hoạt động như một lực để tăng tốc quá trình grokking.

3 Lottery Tickets làm giảm đáng kể Khái quát hóa Chậm trễ

3.1 Thiết lập Thí nghiệm

Theo Power et al. (2022) và các tài liệu grokking khác (Nakkiran et al., 2019; Liu et al., 2022; Gromov, 2023; Liu et al., 2023a), chúng tôi xây dựng một tập dữ liệu các phương trình có dạng: (a+b)%p=c. Tác vụ bao gồm dự đoán c cho một cặp a và b. Thiết lập của chúng tôi sử dụng các cấu hình chi tiết sau: p=67, 0≤a,b,c<p. Kích thước tập dữ liệu là 2211, xem xét tất cả các cặp có thể có trong đó a≥b. Chúng tôi chia nó thành huấn luyện (40%) và test (60%) theo Liu et al. (2022).

Theo Liu et al. (2022), chúng tôi thiết kế MLP như sau. Đầu tiên, chúng tôi ánh xạ mã hóa one-hot của a,b với trọng số embedding Wemb: Ea=Wemba, Eb=Wembb. Sau đó chúng tôi đưa các embedding Ea và Eb vào MLP như sau:

softmax(σ((Ea+Eb)Win)WoutWunemb)  (1)

trong đó Wemb, Win, Wout, và Wunemb là các tham số có thể huấn luyện, và σ là hàm kích hoạt ReLU (Nair & Hinton, 2010). Chiều của không gian embedding là 500, và Win chiếu vào 48 neurons chiều. Theo Nanda et al. (2023), chúng tôi sử dụng optimizer AdamW (Loshchilov & Hutter, 2019) với tốc độ học 10−3, trọng số của weight decay α=1.0, β1=0.9, và β2=0.98. Chúng tôi khởi tạo trọng số như θ0∼N(0,κ/√din), trong đó din biểu diễn chiều của lớp đứng trước mỗi trọng số. Nếu không có gì được chỉ định, giả sử κ=1. Hãy giả sử chúng ta có tập dữ liệu huấn luyện Strain và tập dữ liệu test Stest, và huấn luyện một mạng neural f(x;θ) trong đó x là đầu vào và θ biểu diễn các tham số trọng số của mạng. Cụ thể,

--- TRANG 5 ---
Xuất bản trong Transactions on Machine Learning Research (05/2025)

[Có hình minh họa các biểu đồ so sánh]

Hình 2: So sánh tốc độ grokking của mạng dày đặc và grokked tickets trên các thiết lập khác nhau. (a) Phép cộng modular với MLP, (b) Phép cộng modular với Transformer, và (c) Các tác vụ số học modular khác (được biểu diễn bằng màu sắc) và thí nghiệm không phải số học modular: (d) loss trên hồi quy đa thức, (e) độ chính xác trên sparse parity. Đường nét đứt biểu diễn độ chính xác của mô hình cơ sở, và đường liền biểu diễn của grokked tickets. Trong tất cả các thiết lập, thời gian đến khái quát hóa (tgen) được giảm bởi grokked tickets.

mạng được huấn luyện sử dụng AdamW qua cross-entropy loss và weight decay (chuẩn L2 của trọng số ∥θ∥2):

argmin θ E(x,y)∼S[L(f(x;θ),y) + α/2∥θ∥2].

Để đo lường định lượng mức độ giảm khái quát hóa chậm trễ, chúng tôi định nghĩa tmem là bước mà độ chính xác huấn luyện vượt P%, và tgen là bước mà độ chính xác test vượt P%. Theo Kumar et al. (2024), chúng tôi sử dụng P=95 cho các tác vụ số học modular. Chúng tôi sử dụng mệnh đề (τgrok=tgen/tmem) để đo sự tăng tốc.

Chúng tôi so sánh hiệu suất của 1) mạng dày đặc fθt′ và 2) lottery tickets đã huấn luyện fθ′t′⊙mkt, trong đó t′ là epoch huấn luyện để có điểm số cuối cùng, t là thời điểm cắt tỉa, và k là tỷ lệ cắt tỉa. Như một trường hợp đặc biệt, khi t≥tgen, chúng tôi ký hiệu các mạng con là grokked tickets. Chúng tôi thử nghiệm nhiều t và k khác nhau và điều tra cách chúng thay đổi tốc độ khái quát hóa. Mặc định, chúng tôi sử dụng k=0.6.

3.2 Kết quả

Hình 2-(a) cho thấy độ chính xác test của grokked ticket và mô hình cơ sở trên tác vụ phép cộng modular. Mô hình cơ sở đề cập đến một mô hình dày đặc được huấn luyện từ các giá trị ban đầu ngẫu nhiên. Grokked ticket cho thấy cải thiện trong độ chính xác test gần như cùng thời điểm với cải thiện trong độ chính xác huấn luyện của mô hình cơ sở. Trong Hình 2-(b), sử dụng thí nghiệm với transformers, kết quả cũng cho thấy rằng grokked tickets dẫn đến ít trễ khái quát hóa hơn. Theo Power et al. (2022), chúng tôi tiến hành thí nghiệm trên nhiều tác vụ số học modular để chứng minh việc loại bỏ khái quát hóa chậm trễ. Hình 2-(c) cho thấy so sánh của mô hình cơ sở (đường nét đứt) và grokked ticket (đường liền) với nhiều tác vụ số học modular khác nhau. Hơn nữa, theo Kumar et al. (2023); Pearce et al. (2023), chúng tôi cũng chứng minh rằng khái quát hóa chậm trễ được giảm bởi grokked ticket trong cả tác vụ hồi quy đa thức và sparse parity trong Hình 2-(d,e). Kết quả cho thấy rằng grokked tickets làm giảm đáng kể khái quát hóa chậm trễ ngay cả trên nhiều tác vụ khác nhau. Xem Phụ lục B để có giải thích chi tiết về thiết lập thí nghiệm.

Hình 3-(a) định lượng mối quan hệ giữa tỷ lệ cắt tỉa và τgrok=tgen/tmem (thang log). Khi tỷ lệ cắt tỉa là 0.7, τgrok đạt mức tối thiểu, cho thấy rằng grokked ticket làm giảm đáng kể khái quát hóa chậm trễ.

--- TRANG 6 ---
Xuất bản trong Transactions on Machine Learning Research (05/2025)

[Có hình minh họa với biểu đồ]

Hình 3: So sánh định lượng tốc độ grokking giữa các tỷ lệ cắt tỉa khác nhau. Lưu ý rằng tỷ lệ cắt tỉa = 0.0 tương ứng với mạng dày đặc. Định nghĩa của τgrok được giải thích trong tiểu mục 3.1

[Có hình minh họa với biểu đồ]

Hình 4: (a) So sánh độ chính xác test của epoch t khác nhau trong đó lottery tickets được thu thập. Chúng tôi tiến hành mỗi 2k epochs. Các lottery tickets thu được trước 25k epochs (non-grokked tickets) không khái quát hóa hoàn toàn. Ngoài ra, khả năng khái quát hóa này tương ứng với độ chính xác test của mô hình cơ sở. Các lottery tickets thu được sau 25k epochs (grokked tickets) làm giảm khái quát hóa chậm trễ. (b) Tác động của tỷ lệ cắt tỉa k trên grokked tickets. Chúng tôi tiến hành mỗi 0.2 tỷ lệ cắt tỉa. Hầu hết các tỷ lệ cắt tỉa (0.1, 0.3, 0.5, và 0.7) tăng tốc khái quát hóa, cho thấy rằng quan sát trên không phụ thuộc nhiều vào việc lựa chọn tỷ lệ cắt tỉa.

khái quát hóa chậm trễ. Lưu ý rằng, như được hiển thị trong Hình 3-(b), tmem bị trễ khi sử dụng tỷ lệ cắt tỉa cao hơn, có nghĩa là grokked ticket không chỉ đơn giản tăng tốc toàn bộ quá trình học mà cụ thể tăng tốc quá trình chuyển đổi từ ghi nhớ sang khái quát hóa.

Trong Hình 4-(a), chúng tôi so sánh độ chính xác test của epoch t khác nhau trong đó lottery tickets được thu thập. Kết quả cho thấy rằng lottery tickets thu được trước 25k epochs (non-grokked tickets) không khái quát hóa hoàn toàn. Ngoài ra, khả năng khái quát hóa này tương ứng với độ chính xác test của mô hình cơ sở. Mặt khác, lottery tickets thu được sau 25k epochs (grokked tickets) đạt được khái quát hóa hoàn hảo và giảm khái quát hóa chậm trễ. Trong Hình 4-(b), chúng tôi điều tra tác động của tỷ lệ cắt tỉa trong grokked ticket, cho thấy nếu nó quá lớn (ví dụ: 0.9), nó không thể khái quát hóa; nếu nó quá nhỏ (ví dụ: 0.3), nó không khái quát hóa đủ nhanh.

4 Tách biệt Lottery Tickets: Chuẩn, Độ thưa thớt, và Cấu trúc

Trong phần 3, chúng tôi thiết lập rằng grokked tickets — mạng con được trích xuất tại thời điểm bắt đầu khái quát hóa — làm giảm đáng kể hiện tượng khái quát hóa chậm trễ. Trong khi những kết quả này mạnh mẽ gợi ý rằng một số thuộc tính nội tại của grokked tickets chịu trách nhiệm cho việc chuyển nhanh sang khái quát hóa, vẫn chưa rõ chính xác thuộc tính đó là gì. Nhớ lại từ Hình 2 rằng một grokked ticket có thể giảm mạnh khái quát hóa chậm trễ so với mô hình cơ sở (một mạng được huấn luyện dày đặc từ đầu). Để hiểu yếu tố chính đằng sau hiệu ứng này, chúng tôi xem xét ba giả thuyết được minh họa trong Hình 1 (phải):

--- TRANG 7 ---
Xuất bản trong Transactions on Machine Learning Research (05/2025)

Giả thuyết 1 (Chuẩn Trọng số): Grokked tickets có chuẩn trọng số nhỏ hơn mô hình cơ sở, và việc giảm chuẩn trọng số này dẫn đến việc giảm khái quát hóa chậm trễ.

Trong Phần 4.1, chúng tôi kiểm tra Giả thuyết 1 bằng cách chuẩn bị mô hình dày đặc phù hợp với chuẩn trọng số của grokked ticket. Nếu những mô hình này, mặc dù có cùng chuẩn trọng số, thể hiện tốc độ khái quát hóa khác nhau, điều đó ngụ ý rằng chỉ chuẩn trọng số đơn thuần không giải thích được việc giảm khái quát hóa chậm trễ. Do đó, Giả thuyết 1 bị bác bỏ.

Giả thuyết 2 (Độ thưa thớt): Grokked tickets là các mạng con thưa thớt hơn so với mô hình cơ sở, và mức độ thưa thớt cao hơn này dẫn đến việc giảm khái quát hóa chậm trễ.

Trong Phần 4.2, chúng tôi kiểm tra Giả thuyết 2 bằng cách xây dựng các mô hình có cùng mức độ thưa thớt như grokked ticket. Nếu những mô hình thưa thớt tương đương này không cho thấy việc giảm khái quát hóa chậm trễ, điều đó cho thấy rằng chỉ độ thưa thớt đơn thuần không chịu trách nhiệm cho việc giảm khái quát hóa chậm trễ. Do đó, Giả thuyết 2 bị bác bỏ.

Giả thuyết 3 (Cấu trúc Tốt): Ngoài sự khác biệt về chuẩn trọng số hoặc độ thưa thớt, grokked tickets sở hữu một cấu hình cấu trúc vượt trội trực tiếp tăng tốc khái quát hóa.

Nếu cả Giả thuyết 1 và 2 đều bị bác bỏ, giải thích duy nhất còn lại là cấu trúc tốt vốn có của grokked tickets thúc đẩy việc giảm khái quát hóa chậm trễ.

4.1 Kiểm soát Chuẩn Trọng số của Mạng Ban đầu

Để kiểm tra Giả thuyết 1, chúng tôi chuẩn bị hai mô hình dày đặc có cùng chuẩn L2 và L1 như grokked ticket, được đặt tên là 'mô hình dày đặc được kiểm soát'. Những mô hình dày đặc như vậy được thu được thông qua quá trình sau:

1. Thu được lottery tickets sau khái quát hóa hoàn toàn mktgen.
2. Lấy tỷ lệ chuẩn Lp rp=∥θ0⊙mktgen∥p/∥θ0∥p
3. Tạo trọng số θ0·rp với cùng chuẩn Lp như grokked ticket.

Hình 5-(a) cho thấy độ chính xác test của mô hình cơ sở, grokked ticket, và các mô hình dày đặc được kiểm soát. Mặc dù có cùng chuẩn trọng số ban đầu, grokked ticket đạt được khái quát hóa nhanh hơn nhiều so với cả hai mô hình dày đặc được kiểm soát. Kết quả này cho thấy rằng việc tăng chậm trễ trong độ chính xác test không phải do chuẩn trọng số mà do việc khám phá cấu trúc tốt. Bên trái của Hình 6 cho thấy động lực của chuẩn L2 cho mỗi mô hình. Tương tự như Liu et al. (2023b), chuẩn L2 giảm tương ứng với sự gia tăng trong độ chính xác test, hội tụ về 'Vùng khái quát hóa'. Tuy nhiên, như được hiển thị ở bên phải của Hình 6, các điểm hội tụ cuối cùng của chuẩn L1 khác nhau cho mỗi mô hình. Hiện tượng có chuẩn L2 tương tự nhưng chuẩn L1 nhỏ hơn gợi ý rằng trọng số mạng con tốt (grokked ticket) trở nên mạnh hơn, như được chỉ ra trong Miller et al. (2023). Kết quả tương tự cũng được quan sát trong Transformer (Hình 16). Những kết quả này chứng minh rằng chính chuẩn trọng số không đủ để giải thích grokking, bác bỏ Giả thuyết 1.

4.2 Kiểm soát Độ thưa thớt

Tiếp theo, chúng tôi kiểm tra Giả thuyết 2, đề xuất rằng độ thưa thớt cao hơn trong grokked tickets giải thích cho việc giảm khái quát hóa chậm trễ của chúng. Để điều tra điều này, chúng tôi so sánh các mô hình có cùng độ thưa thớt như grokked ticket, sử dụng nhiều phương pháp pruning-at-initialization (PaI) khác nhau. Cụ thể, chúng tôi thử nghiệm ba phương pháp PaI nổi tiếng — Grasp (Wang et al., 2020), SNIP (Lee et al., 2019), và Synflow (Tanaka et al., 2020)) — cùng với cắt tỉa ngẫu nhiên như phương pháp baseline. Để biết chi tiết về từng phương pháp cắt tỉa, tham khảo phần Phụ lục D.

Hình 5-(b) so sánh quá trình chuyển đổi độ chính xác test của những phương pháp PaI này và grokked ticket. Kết quả cho thấy rằng tất cả các phương pháp PaI hoạt động kém hơn mô hình cơ sở hoặc, trong một số trường hợp, hoạt động kém hơn cắt tỉa ngẫu nhiên. Những kết quả này cho thấy rằng chỉ độ thưa thớt đơn thuần không thể giải thích cho việc giảm khái quát hóa chậm trễ, từ đó bác bỏ Giả thuyết 2.

Việc bác bỏ Giả thuyết 1 và 2, điều này chỉ để lại Giả thuyết 3: sự khác biệt chính phải nằm ở cấu trúc tốt của grokked tickets, cho phép chúng đạt được khái quát hóa nhanh chóng và hiệu quả rút ngắn giai đoạn khái quát hóa chậm trễ.

--- TRANG 8 ---
Xuất bản trong Transactions on Machine Learning Research (05/2025)

[Có hình minh họa với biểu đồ]

Hình 5: (a) Động lực độ chính xác test của mô hình cơ sở, grokked ticket, và mô hình dày đặc được kiểm soát (chuẩn L1 và L2). Grokked ticket đạt được khái quát hóa nhanh hơn nhiều so với các mô hình khác. (b) So sánh độ chính xác test của các phương pháp cắt tỉa khác nhau. Tất cả các phương pháp PaI hoạt động kém hơn mô hình cơ sở hoặc, trong một số trường hợp, hoạt động kém hơn cắt tỉa ngẫu nhiên. Những kết quả này cho thấy không phải chuẩn trọng số hay độ thưa thớt đơn lẻ là nguyên nhân của khái quát hóa chậm trễ.

[Có hình minh họa với biểu đồ]

Hình 6: (Trái) Động lực chuẩn L2 của mô hình cơ sở, grokked ticket, và mô hình dày đặc được kiểm soát. (Phải) Động lực chuẩn L1 của mô hình cơ sở, grokked ticket, và các mô hình dày đặc được kiểm soát. Từ góc độ chuẩn L2, tất cả các mô hình dường như hội tụ về một giải pháp tương tự (Vùng khái quát hóa). Tuy nhiên, từ góc độ chuẩn L1, chúng hội tụ về các giá trị khác nhau.

5 Hiểu về Grokking từ Cấu trúc Nội tại của Mạng

Trong phần 4, chúng tôi chứng minh rằng chuẩn trọng số và độ thưa thớt là những giải thích không đủ cho khái quát hóa chậm trễ. Thay vào đó, chúng tôi đề xuất rằng cấu trúc tốt là cần thiết để hiểu grokking. Dựa trên những kết quả này, phần này đào sâu hơn vào việc hiểu bản chất và vai trò của các thuộc tính cấu trúc trong grokking. Cụ thể, chúng tôi điều tra các khía cạnh sau:

Q1 Việc thu được cấu trúc có được đồng bộ với việc cải thiện hiệu suất khái quát hóa không? (tiểu mục 5.1)

Q2 Chính xác thì cấu trúc tốt bao gồm những gì? (tiểu mục 5.2)

Q3 Khái quát hóa có thể đạt được chỉ thông qua khám phá cấu trúc (cắt tỉa) mà không cần cập nhật trọng số không? (tiểu mục 5.3)

5.1 Thước đo Tiến độ: Chuyển đổi Cấu trúc Nắm bắt Thời điểm Khái quát hóa

Trong phần này, chúng tôi tiến hành phân tích nghiêm ngặt hơn về cách cấu trúc tốt được thu thập, và chúng tôi cho thấy rằng việc khám phá cấu trúc tốt tương ứng với cải thiện trong độ chính xác test.

Đầu tiên, chúng tôi đề xuất một thước đo về những thay đổi cấu trúc trong mạng, được đặt tên là Khoảng cách Jaccard (JD) sử dụng phương pháp Paganini & Forde (2020); Jaccard (1901). Chúng tôi đo khoảng cách jaccard giữa mask tại

--- TRANG 9 ---
Xuất bản trong Transactions on Machine Learning Research (05/2025)

[Có hình minh họa với biểu đồ]

Hình 7: So sánh khoảng cách jaccard (đỏ) và thay đổi trong độ chính xác test (xanh lá) trên mỗi lớp. Khoảng cách jaccard được biểu diễn như JD(t+δt,t), và thay đổi độ chính xác test là sự khác biệt giữa epoch t+δt và t. Đường thẳng đứng đánh dấu thay đổi mạnh nhất trong độ chính xác test. Khi có thay đổi đáng kể trong độ chính xác test, khoảng cách jaccard (thay đổi cấu trúc) tăng nhanh chóng.

epoch t+δt và t.

JD(mt+δt,mt) = 1−|mt+δt∩mt|/|mt+δt∪mt|

mt biểu diễn một mask thu được tại epoch t thông qua magnitude pruning và δt là 2k epoch. Nếu hai cấu trúc khác nhau, thước đo này gần với 1 và ngược lại. Thay đổi độ chính xác test cũng được biểu diễn như sự khác biệt giữa độ chính xác test tại epoch t+δt và t. Trong Hình 7, đường màu đỏ biểu diễn kết quả của những thay đổi trong độ chính xác test và khoảng cách jaccard giữa mask tại epoch t+δt và t trên mỗi lớp. Kết quả cho thấy rằng trong những thay đổi đáng kể trong độ chính xác test (16k-20k), thay đổi tối đa trong mask tương ứng, cho thấy rằng việc khám phá cấu trúc tốt tương ứng với cải thiện trong độ chính xác test. Trong Phụ lục F, chúng tôi chứng minh rằng kết quả tương tự được thu được cho cả tác vụ hồi quy đa thức và sparse parity.

Trả lời cho Q1
Việc thu được cấu trúc có được đồng bộ với việc cải thiện hiệu suất khái quát hóa không?
Có, việc khám phá cấu trúc tốt, như được đo bằng Khoảng cách Jaccard, xảy ra đồng thời với những cải thiện độ chính xác test, cho thấy rằng những thay đổi cấu trúc thúc đẩy khái quát hóa.

5.2 Phân tích Cấu trúc Tốt thông qua Cấu trúc Tuần hoàn và Thuộc tính Đồ thị

Trong tiểu mục trước (tiểu mục 5.1), chúng tôi thiết lập rằng những thay đổi đáng kể trong cấu trúc của mạng, như được đo bằng Khoảng cách Jaccard, trùng khớp chính xác với những cải thiện trong độ chính xác test. Dựa trên phát hiện này, bây giờ chúng tôi đào sâu hơn vào các thuộc tính cấu trúc kích hoạt những khác biệt đột ngột như vậy. Cụ thể, chúng tôi điều tra bản chất của cấu trúc được khám phá từ hai góc độ khác nhau: (1) các biểu diễn tuần hoàn được biết đến xuất hiện trong các tác vụ số học modular (như được nghiên cứu bởi Pearce et al. (2023); Nanda et al. (2023)), và (2) các thuộc tính lý thuyết đồ thị tiết lộ cách kết nối của mạng tiến hóa để hỗ trợ khái quát hóa tốt hơn. Bằng cách kiểm tra cả hai quan điểm, chúng tôi khám phá cách mạng cuối cùng chọn một 'cấu trúc tốt' thúc đẩy độ chính xác test cao.

Phép cộng Modular và Tính tuần hoàn Nanda et al. (2023) chứng minh rằng các transformers được huấn luyện trên các tác vụ phép cộng modular dựa vào những biểu diễn tuần hoàn này để đạt được khái quát hóa. Cụ thể, các mạng nhúng đầu vào a và b vào một cơ sở Fourier, mã hóa chúng như các thành phần sine và cosine của các tần số chính wk=2πk/p cho một số k∈N. Những biểu diễn tuần hoàn này sau đó được kết hợp sử dụng các đặc tính lượng giác trong các lớp mạng để tính tổng modular.

--- TRANG 10 ---
Xuất bản trong Transactions on Machine Learning Research (05/2025)

[Có hình minh họa với biểu đồ]

Hình 8: (trên) Entropy tần số (FE) và độ chính xác test của mô hình cơ sở và grokked ticket. Grokked ticket hội tụ về entropy tần số nhỏ hơn nhanh hơn nhiều so với mô hình cơ sở. (dưới) Quá trình chuyển đổi của trọng số phía đầu vào cho mỗi neuron của mô hình cơ sở và grokked ticket. Các dấu tương ứng với các epochs của các dấu trong động lực FE. Kết quả cho thấy rằng grokked tickets thu được cấu trúc tốt cho khái quát hóa như cấu trúc tuần hoàn.

Bằng cách thiết kế ngược trọng số và kích hoạt của một transformer một lớp được huấn luyện trên tác vụ này, Nanda et al. (2023) phát hiện rằng mô hình tính toán hiệu quả:

cos(wk(a+b)) = cos(wka) cos(wkb)−sin(wka) sin(wkb),  (2)
sin(wk(a+b)) = sin(wka) cos(wkb) + cos(wka) sin(wkb).  (3)

sử dụng ma trận embedding và các lớp attention và MLP. Logits cho mỗi đầu ra có thể c sau đó được tính bằng cách chiếu những giá trị này qua:

cos(wk(a+b−c)) = cos(wk(a+b)) cos(wkc) + sin(wk(a+b)) sin(wkc).

Phương pháp này đảm bảo rằng logits đầu ra của mạng thể hiện nhiễu xạ tích cực tại c≡(a+b)mod p, trong khi nhiễu xạ phá hủy ngăn chặn các giá trị không chính xác khác. Cho cơ chế này, có thể suy ra rằng mô hình nội tại sử dụng tính tuần hoàn, như các công thức cộng, để thực hiện số học modular.

Thu thập Cấu trúc Tuần hoàn trong Grokked Tickets Trong công trình này, dựa trên nghiên cứu trước đây, chúng tôi kiểm tra cấu trúc được thu thập bởi grokked tickets từ góc độ tính tuần hoàn. Đầu tiên, chúng tôi điều tra tính tuần hoàn của mỗi neuron bằng cách vẽ hướng của ma trận trọng số (Winproj), được thu được bằng cách nhân Wemb và Win (tham khảo tiểu mục 3.1). Ma trận trọng số hai chiều này biểu diễn các chiều đầu vào (67) trên một trục và số lượng neurons (48) trên trục khác. Hình 8 (dưới) minh họa trọng số (67 chiều) của mỗi neuron được vẽ tại các checkpoint huấn luyện (0k, 2k, 30k). Trong mô hình cơ sở tại 30k bước, trọng số tiết lộ một tính tuần hoàn rõ ràng, trong khi tại 0k và 2k bước, trọng số thể hiện cấu trúc ngẫu nhiên. Đáng chú ý, grokked tickets phát triển cấu trúc tuần hoàn này sớm hơn nhiều so với mô hình cơ sở (xem grokked ticket tại 2k bước). Phát hiện này nhấn mạnh rằng cấu trúc của grokked tickets phù hợp tốt cho Phép cộng Modular, vì chúng thu được cấu trúc tuần hoàn phù hợp với bản chất của tác vụ.

Để định lượng tính tuần hoàn này như một cấu trúc tốt, chúng tôi giới thiệu Entropy Fourier (FE) như sau. Nói chung, biến đổi Fourier rời rạc F(ω) của hàm f(x) được định nghĩa như sau:

F(ω) = ΣN x=0 f(x) exp(−i2πωx/N)

Trong trường hợp này, vì chúng ta muốn biết tính tuần hoàn của trọng số của mỗi neuron, f(x) là trọng số của neuron thứ i trên đầu vào thứ j, và d là chiều của đầu vào. Sau đó, Entropy Fourier (FE) được tính

--- TRANG 11 ---
Xuất bản trong Transactions on Machine Learning Research (05/2025)

[Có hình minh họa với biểu đồ]

Hình 9: (a) Tiến hóa của weighted spectral gap (trái) và Ramanujan gap (phải) của trung bình qua các lớp của mạng. (b) Độ dài đường dẫn trung bình (trái) và hệ số nhóm (phải). Định nghĩa và kết quả cho các lớp riêng lẻ được cung cấp trong Phụ lục J và Phụ lục K.

như sau:

FE=−Σn i=1 pi log pi

Ở đây, pi là giá trị chuẩn hóa của F(ω), và n biểu diễn số lượng neurons. Giá trị FE thấp cho thấy rằng tần số của trọng số của mỗi neuron có ít biến thiên, hội tụ về các tần số cụ thể, điều này cho thấy rằng mạng đã thu được cấu trúc tuần hoàn.

Hình 8 (trên) cho thấy FE của mô hình cơ sở (xanh lá) và grokked ticket (xanh dương). Kết quả cho thấy rằng grokked ticket có neurons với cấu trúc tuần hoàn ở giai đoạn sớm (2k epochs) và thể hiện giảm nhanh FE trong epoch sớm. Điều này cho thấy rằng mô hình khám phá cấu trúc tốt nội tại (cấu trúc khái quát hóa) phù hợp cho tác vụ (Phép cộng Modular). Để cung cấp phân tích chi tiết hơn, chúng tôi đã thêm các hình ảnh của ma trận trọng số và mask grokked ticket trong Phụ lục I.

Thuộc tính Đồ thị và Grokked Ticket Các cấu trúc của chính mạng thể hiện nhiều thuộc tính lý thuyết đồ thị khác nhau, như được phân tích trong các nghiên cứu trước (Hoang et al., 2023b;a; You et al., 2020). Được thúc đẩy bởi những hiểu biết này, chúng tôi phân tích sự tiến hóa của (1) weighted spectral gap, (2) ramanujan gap, (3) độ dài đường dẫn trung bình, và (4) hệ số nhóm trong suốt quá trình huấn luyện, cùng với những thay đổi trong độ chính xác train/test. Chi tiết của mỗi thước đo thuộc tính đồ thị được cung cấp trong Phụ lục J.

Hình 9,(a) minh họa cách weighted spectral gap (trái) và Ramanujan gap (phải) tiến hóa trong suốt quá trình huấn luyện bằng cách kiểm tra trung bình qua các lớp của mạng. Kết quả cho các lớp riêng lẻ được cung cấp trong Phụ lục K. Chúng tôi quan sát rằng weighted spectral gap tăng mạnh trong giai đoạn ghi nhớ, cho thấy sự khác biệt rõ rệt giữa eigenvalue lớn nhất và lớn thứ hai trong khi mô hình đang overfitting. Xu hướng này gợi ý rằng, trong giai đoạn ghi nhớ, trọng số bị chi phối bởi một thành phần cụ thể (tương ứng với eigenvector hàng đầu). Tuy nhiên, khi mô hình chuyển đổi về khái quát hóa tốt hơn, spectral gap thu hẹp, phản ánh việc sử dụng không gian tham số cân bằng hơn. Chúng tôi quan sát hành vi tương tự trong các lớp khác (xem Phụ lục K để biết chi tiết).

--- TRANG 12 ---
Xuất bản trong Transactions on Machine Learning Research (05/2025)

Bảng 1: Thay đổi độ chính xác test với các phương pháp tối ưu hóa khác nhau bắt đầu từ các giải pháp được ghi nhớ. WD (Weight Decay) phản ánh hiệu ứng regularization của weight decay, sử dụng cùng tối ưu hóa như mô hình cơ sở. Trong EP w/o WD (Edge-Popup without Weight Decay), độ chính xác cải thiện chỉ thông qua cắt tỉa, mà không cần cập nhật trọng số. Kết hợp cắt tỉa với weight decay trong EP w/ WD dẫn đến khái quát hóa nhanh hơn so với chỉ weight decay. Ngoài ra, chúng tôi báo cáo các giá trị trung bình của các thước đo thuộc tính đồ thị trên ma trận trọng số của mạng để phân tích những thay đổi cấu trúc qua các epochs dưới EP w/o WD.

[Bảng với các giá trị số]

Hình 9-(b) trình bày các thước đo được dẫn xuất từ việc xem toàn bộ mạng như một đồ thị quan hệ (You et al., 2020). Độ dài đường dẫn trung bình (trái) tăng cùng với sự gia tăng trong độ chính xác test, sau đó hội tụ về một phạm vi vừa phải. Xu hướng này gợi ý rằng khi mạng đang tìm kiếm một giải pháp khái quát hóa (Grokked ticket), kết nối của nó trở nên thưa thớt hơn; khi giải pháp đó được tìm thấy, độ dài đường dẫn giảm và ổn định. Ngược lại, hệ số nhóm (phải) giảm khi độ chính xác test cải thiện, sau đó cũng ổn định ở một giá trị trung gian. Trong giai đoạn khi mạng đang tìm kiếm một giải pháp khái quát hóa (tức là khi mô hình khám phá Grokked ticket), nhóm giảm nhưng cuối cùng ổn định gần mức vừa phải. Cả hai thước đo do đó hội tụ về không cực đoan mà vẫn ở trong chế độ cân bằng, phù hợp với các nghiên cứu trước (You et al., 2020).

Trả lời cho Q2
Chính xác thì cấu trúc tốt bao gồm những gì?
Cấu trúc tốt có Entropy Fourier thấp, cho thấy các mẫu trọng số tuần hoàn phù hợp với tác vụ. Nó cũng tuân theo các thuộc tính đồ thị đã biết, như weighted spectral gap tăng trong ghi nhớ và độ dài đường dẫn trung bình tăng trong khái quát hóa.

5.3 Cắt tỉa trong Huấn luyện: Cắt tỉa Thúc đẩy Khái quát hóa

Dựa trên kết quả rằng việc khám phá cấu trúc tốt tương ứng với cải thiện trong độ chính xác test, chúng tôi chứng minh rằng chỉ cắt tỉa có thể chuyển đổi từ các giải pháp ghi nhớ sang các giải pháp khái quát hóa mà không cần cập nhật trọng số, và hơn nữa, sự kết hợp của cắt tỉa và weight decay thúc đẩy khái quát hóa hiệu quả hơn so với chỉ regularization của chuẩn trọng số.

Để xác minh điều này, chúng tôi giới thiệu edge-popup (Ramanujan et al., 2020), một phương pháp học cách cắt tỉa trọng số mà không cần cập nhật trọng số. Trong edge-popup, mỗi trọng số được gán một điểm số, và những điểm số này được cập nhật thông qua backpropagation để xác định trọng số nào cần cắt tỉa. Để biết chi tiết về edge-popup, tham khảo Phụ lục A. Chúng tôi xác thực tuyên bố của mình bằng cách tối ưu hóa sử dụng ba phương pháp khác nhau.

WD: Huấn luyện từ θmem sử dụng Weight Decay với cập nhật trọng số (giống như mô hình cơ sở).
EP w/o WD: Huấn luyện từ θmem sử dụng Edge-Popup mà không cập nhật trọng số.
EP w/ WD: Huấn luyện từ θmem sử dụng Edge-Popup và Weight Decay với cập nhật trọng số.

--- TRANG 13 ---
Xuất bản trong Transactions on Machine Learning Research (05/2025)

Trong Bảng 1, kết quả cho EP không có weight decay (EP w/o WD) cho thấy rằng mạng đạt được hiệu suất khái quát hóa 0.92 mà không có bất kỳ thay đổi nào đối với trọng số (chỉ bằng cách cắt tỉa trọng số). Kết quả này chứng minh rằng khái quát hóa có thể đạt được chỉ thông qua khám phá cấu trúc mà không cập nhật trọng số, từ đó củng cố tuyên bố của chúng tôi rằng khái quát hóa chậm trễ xảy ra do việc khám phá một cấu trúc tốt. Ngoài ra, kết quả EP w/ WD cho thấy cải thiện nhanh nhất trong độ chính xác test và hiệu quả nhất trong việc thúc đẩy khái quát hóa. Những hiểu biết này gợi ý rằng các nhà thực hành có thể cải thiện khái quát hóa bằng cách kết hợp các phương pháp tối ưu hóa trực tiếp cấu trúc có lợi thay vì chỉ dựa vào các kỹ thuật regularization truyền thống như weight decay. Những phát hiện của chúng tôi nhấn mạnh tiềm năng của grokked tickets để thông báo việc phát triển các kỹ thuật regularization hướng cấu trúc mới.

Trong Bảng 1, tương tự như phân tích trong tiểu mục 5.2, chúng tôi kiểm tra các giá trị trung bình của các thước đo thuộc tính đồ thị trên ma trận trọng số của mạng dưới EP w/o WD. Như quan sát trong tiểu mục 5.2, weighted spectral gap ban đầu tăng và sau đó giảm, trong khi ramanujan gap tiếp tục giảm. Hơn nữa, cả độ dài đường dẫn trung bình và hệ số nhóm đều hội tụ về các giá trị tương tự.

Trả lời cho Q3
Khái quát hóa có thể đạt được chỉ thông qua khám phá cấu trúc (cắt tỉa) mà không cần cập nhật trọng số không?
Có, chỉ cắt tỉa đã cải thiện đáng kể khái quát hóa, chứng minh rằng việc khám phá mạng con tốt đủ để chuyển đổi từ ghi nhớ sang khái quát hóa.

6 Thảo luận và Các Nghiên cứu Liên quan

Trong bài báo này, chúng tôi tiến hành một loạt thí nghiệm để hiểu cơ chế của grokking (khái quát hóa chậm trễ). Dưới đây là tóm tắt các quan sát. (1) Trong tiểu mục 3.2, việc sử dụng lottery ticket làm giảm đáng kể khái quát hóa chậm trễ. (2) Trong phần 4, cấu trúc tốt là yếu tố quan trọng hơn trong việc giải thích grokking so với chuẩn trọng số và độ thưa thớt bằng cách so sánh với cùng chuẩn trọng số và mức độ thưa thớt. (3) Trong tiểu mục 5.2, cấu trúc của grokked tickets phù hợp tốt cho tác vụ. (4) Trong tiểu mục 5.1, cấu trúc tốt được khám phá dần dần, tương ứng với cải thiện độ chính xác test. (5) Trong tiểu mục 5.3, cắt tỉa mà không cập nhật trọng số từ giải pháp ghi nhớ tăng độ chính xác test. Trong phần này, chúng tôi kết nối những kết quả này với giải thích trước đây về cơ chế của grokking và các nghiên cứu liên quan.

Giảm chuẩn trọng số Liu et al. (2023a) đề xuất rằng việc giảm chuẩn trọng số là quan trọng đối với khái quát hóa. Trong Hình 5, kết quả của chúng tôi đi xa hơn để cho thấy rằng, thay vì chỉ đơn giản giảm chuẩn trọng số, mạng khám phá cấu trúc tốt (mạng con), dẫn đến việc giảm chuẩn trọng số.

Độ thưa thớt và Hiệu quả Merrill et al. (2023) lập luận rằng chuyển đổi giai đoạn grokking tương ứng với sự xuất hiện của một mạng con thưa thớt chi phối dự đoán mô hình. Trong khi họ nghiên cứu thực nghiệm các tác vụ parse parity nơi độ thưa thớt rõ ràng, chúng tôi đang tiến hành các tác vụ (số học modular, MNIST) thường được sử dụng trong nghiên cứu grokking và kiến trúc (MLP, Transformer). Hơn nữa, Hình 5, chúng tôi chứng minh không chỉ độ thưa thớt mà cấu trúc tốt cũng quan trọng.

Học biểu diễn Liu et al. (2022); Nanda et al. (2023); Liu et al. (2023a); Gromov (2023) cho thấy chất lượng biểu diễn như chìa khóa để phân biệt các mạng ghi nhớ và khái quát hóa. Hình 8 chứng minh rằng cấu trúc tốt góp phần vào việc thu được biểu diễn tốt, gợi ý tầm quan trọng của cấu trúc nội tại (tôpô mạng) trong việc đạt được các biểu diễn tốt.

Regularization Weight decay (Rumelhart et al., 1986) là một trong những kỹ thuật regularization được sử dụng phổ biến nhất và được biết đến là yếu tố quan trọng trong grokking (Power et al., 2022; Liu et al., 2023a). Trong Phụ lục H, chúng tôi cho thấy nếu cấu trúc tốt được khám phá, mạng khái quát hóa mà không cần weight decay, cho thấy rằng weight decay hoạt động như một khám phá cấu trúc, điều này gợi ý rằng weight decay góp phần

--- TRANG 14 ---
Xuất bản trong Transactions on Machine Learning Research (05/2025)

không phải để giảm trọng số mà để khám phá cấu trúc tốt. Ngoài ra, chúng tôi thử nghiệm cắt tỉa như một lực mới để tạo ra khái quát hóa (Bảng 1). Tuy nhiên, như được hiển thị trong kết quả cắt tỉa tại khởi tạo (Hình 5-(b)), cắt tỉa không đúng cách có thể làm giảm hiệu suất khái quát hóa.

Giả thuyết lottery ticket Giả thuyết lottery ticket (Frankle & Carbin, 2019) đề xuất rằng cấu trúc tốt là quan trọng đối với khái quát hóa, nhưng vẫn chưa rõ cách những cấu trúc này được thu thập trong quá trình huấn luyện và cách chúng tương ứng với các biểu diễn của mạng. Theo hiểu biết của tôi, bài báo của chúng tôi là đầu tiên kết nối grokking và giả thuyết lottery ticket, chứng minh cách các cấu trúc tốt xuất hiện (tiểu mục 5.1) và góp phần vào các biểu diễn hiệu quả (tiểu mục 5.2). Dựa trên điều này, chúng tôi tiếp tục cho thấy rằng trong khi khái quát hóa nhanh hơn là một thuộc tính được ghi nhận rõ ràng của winning tickets, công trình của chúng tôi đi xa hơn bằng cách khám phá cách việc khám phá cấu trúc tốt.

Hướng Tương lai Trong khi nghiên cứu của chúng tôi tập trung vào các tác vụ đơn giản, hiểu biết chính về việc khám phá mạng con tốt có thể mở rộng sang các lĩnh vực phức tạp hơn như nhận dạng hình ảnh quy mô lớn và sinh ngôn ngữ. Những phát hiện của chúng tôi gợi ý rằng các mạng con tốt, hoặc "lottery tickets", giúp giảm thiểu khái quát hóa chậm trễ, cung cấp một góc nhìn cấu trúc về regularization. Các phương pháp truyền thống như weight decay gián tiếp thúc đẩy khám phá cấu trúc, trong khi cắt tỉa và tối ưu hóa dựa trên mask cung cấp một cách tiếp cận trực tiếp và có thể hiệu quả hơn. Như được hiển thị trong Bảng 1, việc kết hợp weight decay với thuật toán edge-popup tăng tốc khái quát hóa, chứng minh lợi thế của các kỹ thuật nhận thức cấu trúc. Nghiên cứu tương lai có thể tích hợp những hiểu biết này vào các kiến trúc đương đại để tăng cường hiệu quả học tập và độ bền vững. Khám phá các chiến lược dựa trên cắt tỉa hoặc tối ưu hóa mask trong các mô hình quy mô lớn có thể xác thận thêm hiệu quả của chúng trong các ứng dụng thế giới thực. Việc kết nối những hiểu biết cấu trúc này với các kỹ thuật huấn luyện chính thống có thể cải thiện khái quát hóa và hiệu quả mô hình trong các thiết lập phức tạp.

Ngoài ra, dựa trên những hiểu biết về thuộc tính đồ thị thu được trong tiểu mục 5.2 của nghiên cứu này, công việc tương lai nên lấy mẫu cấu trúc mạng neural một cách rõ ràng theo thuộc tính đồ thị, như được chứng minh trong nghiên cứu trước đây (Javaheripi et al., 2021). Việc kết hợp những hiểu biết cấu trúc được xác định ở đây vào quá trình lấy mẫu có thể tạo điều kiện cho việc khám phá các kiến trúc mạng hiệu quả và bền vững hơn.

--- TRANG 15 ---
Xuất bản trong Transactions on Machine Learning Research (05/2025)

Tài liệu Tham khảo

[Danh sách tài liệu tham khảo từ trang 15-17 với đầy đủ thông tin về các nghiên cứu được trích dẫn]

--- TRANG 18-29 ---
[Các phụ lục A-K với thông tin chi tiết về thuật toán edge-popup, cấu hình thí nghiệm khác nhau, kết quả với seeds khác nhau, phương pháp cắt tỉa tại khởi tạo, tính quan trọng của tính tuần hoàn, thay đổi cấu trúc trong các tác vụ khác, phân tích weight decay, trực quan hóa trọng số và grokked ticket, và các thước đo thuộc tính đồ thị]

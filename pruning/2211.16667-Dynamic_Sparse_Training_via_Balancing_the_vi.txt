# 2211.16667.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/pruning/2211.16667.pdf
# Kích thước tệp: 740226 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Huấn luyện Thưa thớt Động qua Cân bằng
Đánh đổi Khám phá-Khai thác
Shaoyi Huang1, Bowen Lei2, Dongkuan Xu3, Hongwu Peng1, Yue Sun4, Mimi Xie5, Caiwen Ding1
1University of Connecticut,2Texas A&M University,3North Carolina State University,
4Lehigh University,5University of Texas at San Antonio
{shaoyi.huang, hongwu.peng, caiwen.ding}@uconn.edu,
bowenlei@stat.tamu.edu, dxu27@ncsu.edu, yus516@lehigh.edu, mimi.xie@utsa.edu
Tóm tắt —Việc tham số hóa quá mức của mạng nơ-ron sâu
(DNNs) đã cho thấy độ chính xác dự đoán cao cho nhiều ứng
dụng. Mặc dù hiệu quả, số lượng lớn tham số cản trở tính phổ
biến của nó trên các thiết bị có tài nguyên hạn chế và có tác
động môi trường quá mức. Huấn luyện thưa thớt (sử dụng một
số lượng cố định trọng số khác không trong mỗi lần lặp) có thể
giảm đáng kể chi phí huấn luyện bằng cách giảm kích thước
mô hình. Tuy nhiên, các phương pháp huấn luyện thưa thớt hiện
có chủ yếu sử dụng các chiến lược bỏ-và-phát triển dựa trên
ngẫu nhiên hoặc tham lam, dẫn đến cực tiểu địa phương và độ
chính xác thấp. Trong công trình này, để hỗ trợ huấn luyện
thưa thớt có thể giải thích, chúng tôi đề xuất K hai thác trọng
số quan trọng và K hám phá bao phủ để đặc trưng cho H uấn
luyện T hưa thớt Đ ộng (DST-EE), và cung cấp phân tích định
lượng của hai chỉ số này. Chúng tôi tiếp tục thiết kế một hàm
thu nhận và cung cấp các đảm bảo lý thuyết cho phương pháp
được đề xuất và làm rõ tính chất hội tụ của nó. Kết quả thực
nghiệm cho thấy các mô hình thưa thớt (lên đến 98% độ thưa
thớt) thu được bằng phương pháp đề xuất của chúng tôi vượt
trội hơn các phương pháp huấn luyện thưa thớt SOTA trên nhiều
tác vụ học sâu. Trên VGG-19 / CIFAR-100, ResNet-50 / CIFAR-
10, ResNet-50 / CIFAR-100, phương pháp của chúng tôi thậm
chí có độ chính xác cao hơn các mô hình dày đặc. Trên ResNet-50
/ ImageNet, phương pháp được đề xuất có cải thiện độ chính xác
lên đến 8.2% so với các phương pháp huấn luyện thưa thớt SOTA.
Thuật ngữ chỉ mục —Tham số hóa quá mức, cắt tỉa mạng nơ-ron,
huấn luyện thưa thớt

I. GIỚI THIỆU
Việc tăng kích thước mô hình mạng nơ-ron sâu (DNNs) đã
cho thấy độ chính xác dự đoán vượt trội trong nhiều tình huống
thực tế [1]. Tuy nhiên, khi kích thước mô hình tiếp tục mở rộng,
một lượng lớn tính toán và yêu cầu bộ nhớ nặng ngăn cản việc
huấn luyện DNN trên các thiết bị có tài nguyên hạn chế, cũng
như không thân thiện với môi trường [2,3,4,5,6,7]. Một nghiên
cứu của Google cho thấy GPT-3 [8] (175 tỷ tham số) tiêu thụ
1,287 MWh điện trong quá trình huấn luyện và tạo ra 552 tấn
khí thải carbon, tương đương với khí thải của một chiếc xe trong
120 năm [9]. May mắn thay, huấn luyện thưa thớt có thể giảm
đáng kể chi phí huấn luyện bằng cách sử dụng một số lượng
cố định và nhỏ trọng số khác không trong mỗi lần lặp, trong
khi vẫn bảo tồn độ chính xác dự đoán cho các tác vụ hạ nguồn.

Hai xu hướng nghiên cứu về huấn luyện thưa thớt đã thu hút
sự phổ biến to lớn. Một là phương pháp dựa trên mặt nạ tĩnh
[5,10,11], trong đó việc thưa thớt hóa bắt đầu từ khởi tạo trước
khi huấn luyện. Sau đó, mặt nạ thưa thớt (một tensor nhị phân
tương ứng với tensor trọng số) được cố định. Tính linh hoạt
hạn chế như vậy của việc lựa chọn mạng con hoặc mặt nạ dẫn
đến các mạng con không tối ưu với độ chính xác kém. Để cải
thiện tính linh hoạt, huấn luyện mặt nạ động đã được đề xuất
[12,13,14], trong đó mặt nạ thưa thớt được cập nhật định kỳ
bằng cách bỏ-và-phát triển để tìm kiếm các mạng con tốt hơn

Bỏ-và-phát triển Trạng thái không hoạt động (trọng số=0) Bỏ-và-phát triển Tại lần lặp huấn luyện 1000, gradient của đường đỏ=1.75e-6 gradient của đường xanh=3.28e-2 Trọng số quan trọng (bị bỏ qua) Phát triển trọng số dựa trên tham lam (RigL, ITOP, ...)
(a)Các trọng số không hoạt động với gradient ban đầu nhỏ bị bỏ qua trong các phương pháp phát triển trọng số dựa trên tham lam (tức là, RigL, ITOP, ...)

Trạng thái không hoạt động (trọng số=0) Bỏ-và-phát triển Tại lần lặp huấn luyện 1000, gradient của đường đỏ=1.75e-6 gradient của đường xanh=3.28e-2 Của chúng tôi Trọng số quan trọng (được giữ lại)
Bỏ-và-phát triển
(b)Các trọng số không hoạt động với gradient ban đầu nhỏ có thể được giữ lại và phát triển trong phương pháp được đề xuất.

Hình 1: Phương pháp phát triển trọng số dựa trên gradient so với phương pháp được đề xuất.
(a) Đường màu đỏ cho thấy trọng số với gradient nhỏ bị bỏ qua
(không được phát triển), trong khi đường màu xanh biểu thị rằng trọng số với gradient lớn được phát triển tại lần lặp=1000. (b) Trọng số với gradient nhỏ tại lần lặp=1000 có thể được phát triển áp dụng phương pháp của chúng tôi, và tại lần lặp huấn luyện = 2000 nó quan trọng hơn.

với độ chính xác cao, trong đó trong quá trình bỏ chúng ta khử
hoạt một phần trọng số từ trạng thái hoạt động (khác không)
sang trạng thái không hoạt động (bằng không), ngược lại cho
quá trình phát triển.

Tuy nhiên, các phương pháp này chủ yếu sử dụng các chiến
lược phát triển dựa trên ngẫu nhiên hoặc tham lam. Cái trước
thường dẫn đến độ chính xác thấp hơn trong khi cái sau tham
lam tìm kiếm các mặt nạ thưa thớt với cực tiểu địa phương
trong khoảng cách ngắn [15], dẫn đến bao phủ trọng số hạn
chế và do đó một mô hình thưa thớt không tối ưu. Như một
minh họa trong Hình 1a sử dụng VGG-19/CIFAR-100, tại một
giai đoạn bỏ-và-phát triển (lần lặp thứ 1,000), phương pháp
dựa trên gradient phát triển các trọng số không hoạt động với
gradient tương đối lớn nhưng bỏ qua các gradient nhỏ. Tuy
nhiên, khi huấn luyện tiếp tục (ví dụ, tại lần lặp thứ 2,000),
các trọng số không hoạt động này với gradient nhỏ sẽ có độ
lớn lớn và do đó quan trọng đối với độ chính xác mô hình
[16,17]. Do đó, chúng nên được xem xét cho việc phát triển
tại lần lặp thứ 1,000 như được hiển thị trong Hình 1b. Ngoài
ra, hơn 90% trọng số không hoạt động nhưng quan trọng bị
bỏ qua trong 12 trong số 16 lớp tích chập.

Để bảo tồn tốt hơn các trọng số không hoạt động nhưng quan trọngarXiv:2211.16667v3  [cs.LG]  24 Apr 2023

--- TRANG 2 ---
này, chúng tôi đề xuất một phương pháp Huấn luyện Thưa thớt Động được đặc trưng bởi Khai thác trọng số và Khám phá bao phủ (DST-EE) mới để cập nhật mặt nạ thưa thớt và tìm kiếm mạng con "tốt nhất có thể". Khác với các phương pháp dựa trên tham lam hiện có, chỉ khai thác kiến thức hiện tại, chúng tôi tiếp tục khám phá và phát triển các trọng số chưa bao giờ được bao phủ trong các lần lặp huấn luyện trước, do đó tăng bao phủ trọng số và tránh quá trình tìm kiếm mạng con bị mắc kẹt trong tối ưu địa phương [18]. Các đóng góp của bài báo được tóm tắt như sau:

Để hỗ trợ huấn luyện thưa thớt có thể giải thích, chúng tôi đề xuất khai thác trọng số quan trọng và khám phá bao phủ trọng số để đặc trưng cho huấn luyện thưa thớt. Chúng tôi tiếp tục cung cấp phân tích định lượng của chiến lược và cho thấy lợi thế của phương pháp được đề xuất.

Chúng tôi thiết kế một hàm thu nhận cho quá trình phát triển. Chúng tôi cung cấp phân tích lý thuyết cho phương pháp khai thác và khám phá được đề xuất và làm rõ tính chất hội tụ của phương pháp huấn luyện thưa thớt được đề xuất.

Phương pháp được đề xuất của chúng tôi không cần huấn luyện các mô hình dày đặc trong suốt quá trình huấn luyện, đạt được tỷ lệ thưa thớt lên đến 95% và thậm chí độ chính xác cao hơn huấn luyện dày đặc, với cùng số lượng lần lặp. Các mô hình thưa thớt thu được bằng phương pháp được đề xuất vượt trội hơn các phương pháp huấn luyện thưa thớt SOTA.

Trên VGG-19 / CIFAR-100, ResNet-50 / CIFAR-10, ResNet-50 / CIFAR-100, phương pháp của chúng tôi thậm chí có độ chính xác cao hơn các mô hình dày đặc. Trên ResNet-50 / ImageNet, phương pháp được đề xuất có cải thiện độ chính xác lên đến 8.2%. Trên mạng nơ-ron đồ thị (GNN), phương pháp của chúng tôi vượt trội hơn cắt tỉa-từ-dày đặc sử dụng thuật toán ADMM [19,20,21], đạt được độ chính xác dự đoán liên kết cao hơn lên đến 23.3%.

II. CÔNG TRÌNH LIÊN QUAN

Huấn luyện Tiến hóa Thưa thớt (SET) [12] loại bỏ các trọng số có giá trị độ lớn nhỏ nhất và phát triển ngẫu nhiên số lượng trọng số tương ứng trở lại ở cuối mỗi epoch huấn luyện. SNFS [22] sử dụng momentum làm mịn hàm mũ để tìm các trọng số và lớp quan trọng, và phân phối lại các trọng số bị cắt tỉa dựa trên độ lớn momentum trung bình mỗi lớp. RigL [14] cập nhật cấu trúc thưa thớt của mạng thưa thớt trong quá trình huấn luyện sử dụng cùng phương pháp bỏ trọng số dựa trên độ lớn trong khi phát triển lại các trọng số sử dụng top-k gradient có giá trị tuyệt đối lớn nhất, đạt được độ chính xác tốt hơn huấn luyện mặt nạ tĩnh dưới cùng độ thưa thớt. Tuy nhiên, chính sách phát triển dựa trên tham lam dẫn đến bao phủ trọng số hạn chế, do đó một mô hình thưa thớt không tối ưu. ITOP [1] phát hiện rằng lợi ích của huấn luyện mặt nạ động đến từ khả năng xem xét qua thời gian tất cả các tham số có thể. Ngoài ra, MEST [23] sử dụng tỷ lệ bỏ và phát triển giảm dần với phạm vi tham số thoải mái hơn cho việc phát triển. Tuy nhiên, cả ITOP và MEST đều giữ cùng chiến lược bỏ-và-phát triển như các công trình hiện có và có bao phủ trọng số hạn chế. GaP [24] chia DNN thành nhiều phân vùng, phát triển một phân vùng tại một thời điểm thành dày đặc và cắt tỉa phân vùng dày đặc trước đó thành thưa thớt, với mục đích bao phủ tất cả trọng số. Tuy nhiên, nó yêu cầu thời gian huấn luyện nhiều hơn các phương pháp cắt tỉa truyền thống, điều này hạn chế ứng dụng của nó trong các tình huống tài nguyên hạn chế.

III. KHAI THÁC TRỌNG SỐ QUAN TRỌNG VÀ KHÁM PHÁ BAO PHỦ

A. Tổng quan

Chúng tôi hình thức hóa quá trình huấn luyện thưa thớt của DST-EE được đề xuất như sau. Chúng tôi định nghĩa một mạng nơ-ron sâu L-lớp với trọng số dày đặc W= [W1;W2;:::;WL]. Trong quá trình huấn luyện, trọng số của lớp thứ i tại lần lặp thứ t được ký hiệu bởi Wt_i. Chúng tôi khởi tạo ngẫu nhiên tensor trọng số thưa thớt là W0=[W0_1;W0_2;:::;W0_L] với phân phối thưa thớt P sử dụng khởi tạo ERK [12]. Mỗi tensor trọng số thưa thớt trong một lớp có tensor mặt nạ tương ứng (các phần tử zero được mask bởi 0 và các phần tử khác được mask bởi 1) với cùng kích thước. Chúng tôi định nghĩa các phần tử zero trong tensor trọng số là trọng số không hoạt động và các phần tử khác là trọng số hoạt động. Đối với mỗi lần lặp, chúng tôi chỉ cập nhật các trọng số hoạt động. Ngoài ra, mỗi T lần lặp, chúng tôi cập nhật tensor mặt nạ, tức là, đối với lớp thứ i, chúng tôi bỏ ki trọng số gần zero nhất (tức là, trọng số dương nhỏ nhất và trọng số âm lớn nhất), các trọng số bị bỏ được ký hiệu bởi ArgTopK (W0_i;ki). Chúng tôi ký hiệu Nt_i là tensor đếm thu thập tần suất xuất hiện cho mỗi mặt nạ 1. Chúng tôi khởi tạo Nt_i là tensor zero với cùng kích thước với tensor trọng số tương ứng. Mỗi T lần lặp, tensor đếm được cập nhật bằng cách cộng tensor đếm với tensor mặt nạ hiện có. Chúng tôi sử dụng St_i để ký hiệu tensor điểm quan trọng trong cập nhật mặt nạ thứ q. Chúng tôi thiết kế hàm thu nhận sau để tính tensor điểm quan trọng

St_i=j@l(Wt_i;X)/@Wt_ij+clnt/(Nt_i+ε); t=qT; i = 1;2;:::;L    (1)

trong đó số hạng đầu tiên j@l(Wt_i;X)/@Wt_ij là tensor gradient tuyệt đối của lớp thứ i tại lần lặp thứ t. @l(Wt_i;X) là tổn thất của lớp thứ i. X là dữ liệu huấn luyện đầu vào. Trong số hạng thứ hai clnt/(Nt_i+ε), c là hệ số để cân bằng giữa hai số hạng và ε là một hằng số dương để làm cho phần dư khác không. Đối với mỗi tensor điểm quan trọng, chúng tôi xác định k giá trị tuyệt đối cao nhất và chọn các chỉ số. Các giá trị mặt nạ tương ứng với cùng chỉ số sẽ được đặt thành 1. Trong lần lặp tiếp theo, chúng tôi cập nhật trọng số sử dụng tensor mặt nạ mới. Trong toàn bộ quá trình, chúng tôi duy trì rằng các trọng số mới được kích hoạt có cùng số lượng với các trọng số bị khử hoạt trước đó. Chúng tôi lặp lại các lần lặp nói trên cho đến khi kết thúc huấn luyện. Chi tiết của phương pháp chúng tôi được minh họa trong Thuật toán 1, trong đó ⊙ có nghĩa là phép nhân ma trận tensor.

Hình 2 cho thấy luồng dữ liệu huấn luyện của một lớp sử dụng phương pháp được đề xuất. Chúng tôi sử dụng Wt và Gt để ký hiệu tensor trọng số và gradient, tương ứng. n là tổng số vòng cập nhật mặt nạ. lt là tổn thất để tính tensor gradient. Trong lần lặp đầu tiên của mỗi T, tensor trọng số có tensor mặt nạ nhị phân tương ứng, trong đó các phần tử zero được mask bởi 0 trong tensor mặt nạ và các phần tử khác được mask bởi 1. Nt là tensor đếm, chỉ ra số lần xuất hiện khác không trong các cập nhật mặt nạ trước đó.

B. Khai thác Trọng số Quan trọng trong Huấn luyện Thưa thớt

Trong huấn luyện thưa thớt được đề xuất, chúng tôi khai thác kiến thức hiện tại (trọng số và gradient) và định nghĩa điểm khai thác để giúp

--- TRANG 3 ---
[Hình ảnh phức tạp với các tensor và số liệu - không thể dịch chính xác]

Hình 2: Luồng dữ liệu huấn luyện thưa thớt của phương pháp được đề xuất.

Thuật toán 1: DST-EE
Đầu vào: một mạng L-lớp f với trọng số dày đặc W=W1;W2;:::;WL;
phân phối thưa thớt: P=P1;P2;:::;PL; tổng số lần lặp huấn luyện Tend.
Đặt X là tập dữ liệu huấn luyện; T là tần suất cập nhật; η là tỷ lệ học;
k1;k2;:::;kL là các biến ký hiệu số lượng trọng số bị bỏ mỗi T lần lặp;
M1;M2;:::;ML là các mặt nạ thưa thớt. S1;S2;:::;SL là các tensor điểm quan trọng.
Đầu ra: một mạng thưa thớt L-lớp với phân phối thưa thớt P.

W0=W0_1;W0_2;:::;W0_L ← sparsify W1;W2;:::;WL với P
Nt_i ← Mi
foreach lần lặp huấn luyện t do
    Losst ← f(xt;W0),xt∈X
    if t(mod T) == 0 and t < Tend then
        for 0<i<L + 1 do
            W0_i ← ArgDrop (W0_i;ArgTopK (W0_i;ki))
            Si=∇(W0_i)t+c*lnt/(Nt_i+ε)
            W0_i ← ArgGrow (W0_i;ArgTopK (Si⊙(Mi == 0);ki))
        end for
        Nt_i ← Nt_i+Mi
    else
        W0_i ← W0_i-η*∇(W0_i)t
    end if
end for

quyết định mặt nạ với độ chính xác cao nhất. Cụ thể hơn, chúng tôi định nghĩa điểm khai thác Sexploi trong cập nhật mặt nạ thứ q là mục đầu tiên của Phương trình (1), tức là, Sexploi =j@l(Wt_i;X)/@Wt_ij; t = qT; i = 1;2;:::;L.

Chúng tôi tiếp tục đề xuất một chỉ số đánh giá để định lượng mức độ khai thác cho việc phát triển trọng số. Với mức độ khai thác cao, chính sách sẽ tìm một mô hình với cực tiểu địa phương với giảm tổn thất lớn trong thời gian ngắn. Do đó, một chính sách phát triển được thiết kế để có mức độ khai thác cao nếu nó dẫn đến giảm tổn thất nhanh trong lần lặp tiếp theo.

Để hình thức hóa chỉ số đánh giá, chúng tôi ký hiệu W= [w(1;1)_1;w(1;2)_1;:::;w(m1;n1)_1;:::;w(p;q)_j;:::;w(mL;nL)_L] là trọng số của một mô hình, trong đó w(p;q)_j ký hiệu phần tử trọng số ở hàng thứ p và cột thứ q của lớp thứ j trong mô hình. Lớp thứ j có mj hàng và nj cột. Chúng tôi tiếp tục định nghĩa Wjpq;jpq= [0;:::;0;w(p;q)_j;0;:::;0] với cùng kích thước của W. Mức độ khai thác được ký hiệu là Ljpq_g khi phần tử trọng số ở hàng thứ p và cột thứ q của lớp thứ j được phát triển trong lần lặp cập nhật mặt nạ thưa thớt, thì

Ljpq_g=L(W)-L(W+Wjpq;jpq): (2)

Để tổng quát hóa, chúng tôi sử dụng Lg để ký hiệu mức độ khai thác của mô hình nếu k trọng số với chỉ số I1;I2;:::;Ik được phát triển, thì

Lg=L(W)-L(W+∑(n=1 to k)WIn;In): (3)

C. Khám phá Bao phủ Trọng số trong Huấn luyện Thưa thớt

Bên cạnh khai thác, chúng tôi đồng thời chọn các mặt nạ chưa bao giờ được khám phá để mô hình không bị mắc kẹt trong tối ưu địa phương xấu. Chúng tôi định nghĩa điểm khám phá Sexplor của chúng tôi là mục thứ hai trong Phương trình (1), tức là, Sexplor =lnt/(Nt_i+ε); t=qT; i = 1;2;:::;L, trong đó Nt_i là tensor đếm thu thập tần suất xuất hiện hoạt động (khác không) của mỗi phần tử. Nếu một phần tử có tần suất xuất hiện hoạt động (khác không) bằng không, nó sẽ có điểm khám phá tương ứng cao hơn các phần tử đã được khám phá, do đó được phát triển.

Lấy cảm hứng từ RigL-ITOP [1], chúng tôi sử dụng một chỉ số đánh giá để định lượng mức độ khám phá cho việc phát triển trọng số. Giả sử B= [b(1;1)_1;b(1;2)_1;:::;b(m1;n1)_1;:::;b(p;q)_j;:::;b(mL;nL)_L] là một vector nhị phân để ký hiệu nếu tham số tương ứng trong W được khám phá (1) hay không (0) trong suốt quá trình huấn luyện thưa thớt. Đối với tỷ lệ khám phá [1], chúng tôi sử dụng cùng công thức như RigL-ITOP [1], tức là, R=∑(j=1 to L)∑(p=1 to mj)∑(q=1 to nj)b(p;q)_j/∑(j=1 to L)mjnj.

D. Cân bằng Đánh đổi Khai thác-Khám phá

Tác vụ tìm kiếm tensor mặt nạ là thách thức trong huấn luyện thưa thớt. Thứ nhất, tác vụ tìm kiếm mặt nạ là một vấn đề nhiều chiều do số lượng lớn trọng số trong DNNs. Thứ hai, không gian tìm kiếm có nhiều cực tiểu địa phương và điểm yên ngựa [25,26] vì hàm tổn thất không lồi của DNNs [25,26]. Do đó, quá trình tìm kiếm tensor mặt nạ dễ bị mắc kẹt trong tối ưu địa phương xấu vì hiệu quả khám phá toàn cục thấp [18] hoặc cần thời gian dài hơn để khám phá đầy đủ cảnh quan tổn thất.

Một sự cân bằng tốt hơn giữa khám phá và khai thác có thể khuyến khích các thuật toán tìm kiếm hiểu rõ hơn cảnh quan tổn thất và giúp mô hình thưa thớt thoát khỏi các tối ưu địa phương xấu. Tầm quan trọng và thách thức của việc cân bằng đánh đổi khám phá và khai thác đã được nhấn mạnh trong nhiều nghiên cứu [27,28]. Tuy nhiên, chúng chưa nhận được đủ sự chú ý trong huấn luyện thưa thớt. Do đó, có nhu cầu mạnh mẽ để

--- TRANG 4 ---
kiểm soát tốt hơn sự cân bằng và chúng tôi đề xuất xem xét cả điểm khám phá và khai thác khi chọn mặt nạ. Và điểm quan trọng của chúng tôi trong Phương trình (1) kết hợp hai điểm và vượt qua các hạn chế của công trình trước đó.

IV. BIỆN MINH LÝ THUYẾT

Chúng tôi cung cấp đảm bảo hội tụ cho thuật toán của chúng tôi. Chúng tôi sử dụng F(W) =Ex~X f(x;W) để ký hiệu hàm tổn thất cho huấn luyện thưa thớt của chúng tôi trong đó X là phân phối sinh dữ liệu. Chúng tôi sử dụng ∇f(x;W) và ∇F(W) để ký hiệu các gradient ngẫu nhiên đầy đủ và chính xác theo W, tương ứng. Đối với mỗi vòng (T lần lặp), chúng tôi cập nhật mặt nạ và sử dụng M[q] để ký hiệu mặt nạ được chọn cho vòng thứ q, W[q] để ký hiệu trọng số mô hình sau q-1 vòng huấn luyện. Phù hợp với [24], chúng tôi đưa ra các giả định sau:

Giả định 1. (Độ mịn). Chúng tôi giả định hàm mục tiêu F(W) là L-mịn theo từng phần, tức là,
||∇F(W+h)-∇F(W)||≤L||h||;
trong đó h có cùng kích thước với W.

Giả định 2. (Nhiễu gradient) Chúng tôi giả định cho bất kỳ t và q nào rằng
E[∇f(x(q)_t;W)] =∇F(W);
E[||∇f(x(q)_t;W)-∇F(W)||^2]≤σ^2
trong đó σ>0 và x(q)_t độc lập với nhau.

Giả định 3. (Lỗi do mặt nạ gây ra) Chúng tôi giả định rằng
||W(q)_t⊙M(q)-W(q)_t||_2≤δ||W(q)_t||_2
trong đó δ∈[0;1).

Dưới các Giả định 1-3, chúng tôi thiết lập Mệnh đề 1 để cho thấy thuật toán huấn luyện thưa thớt của chúng tôi hội tụ đến mô hình ổn định với tỷ lệ O(1/√Q) dưới tỷ lệ học thích hợp.

Mệnh đề 1. Nếu tỷ lệ học η = 1/(16LT√Q), các mô hình thưa thớt được tạo bởi thuật toán của chúng tôi sau Q cập nhật mặt nạ sẽ hội tụ như sau:

1/Q ∑(q=1 to Q) E||∇F(W[q]⊙M[q])||^2   (4)
=O(G/√Q+δ^2/Q ∑(q=1 to Q) E||W[q]||^2)

trong đó G là một hằng số phụ thuộc vào nhiễu gradient ngẫu nhiên và khởi tạo mô hình.

Liên quan đến Mệnh đề 1, chúng tôi đưa ra các nhận xét sau:

Nhận xét 1. Trong huấn luyện dày đặc, chúng ta không có lỗi do mặt nạ gây ra và có δ^2= 0. Như được hiển thị trong Phương trình (4), chúng ta sẽ có E(||∇F(W[Q]⊙M[Q])||) → 0, chỉ ra rằng DST-EE sẽ hội tụ đến một điểm ổn định khi Q→∞.

Nhận xét 2. Trong huấn luyện thưa thớt, hiệu suất của mô hình bị ảnh hưởng bởi lỗi G liên quan đến gradient ngẫu nhiên và δ^2 do mặt nạ gây ra. Thuật toán của chúng tôi cải thiện việc tìm kiếm mặt nạ bằng sự cân bằng tốt hơn giữa khai thác và khám phá, dẫn đến một mô hình chính xác hơn.

V. KẾT QUẢ THỰC NGHIỆM

A. Thiết lập Thực nghiệm

Chúng tôi đánh giá VGG-19 và ResNet-50 trên CIFAR-10/CIFAR-100 và đánh giá ResNet-50 trên ImageNet. Việc huấn luyện và đánh giá mô hình được thực hiện với CUDA 11.1 trên 8 GPU Quadro RTX6000 và CPU Intel(R) Xeon(R) Gold 6244 @ 3.60GHz. Chúng tôi sử dụng bộ lập lịch tỷ lệ học cosine annealing với tối ưu hóa SGD. Đối với CIFAR-10/100, chúng tôi sử dụng kích thước batch 128 và đặt tỷ lệ học ban đầu là 0.1. Đối với ImageNet, chúng tôi sử dụng kích thước batch 128. Chúng tôi sử dụng cùng phương pháp khởi tạo thưa thớt ERK trong phương pháp huấn luyện thưa thớt tiên tiến như RigL [14] và ITOP [1]. Để tiếp tục xác thực tính tổng quát của phương pháp được đề xuất, chúng tôi tiến hành thí nghiệm trên mạng nơ-ron đồ thị cho các tác vụ dự đoán liên kết trên tập dữ liệu ia-email [33] và wiki-talk [34].

B. Kết quả Thực nghiệm

CIFAR-10/CIFAR-100. Kết quả của CIFAR-10/100 được hiển thị trong Bảng I. Chúng tôi so sánh phương pháp của chúng tôi với SOTA trên các mô hình VGG-19 và ResNet-50 ở độ thưa thớt 90%, 95%, và 98%. Để chứng minh hiệu quả của phương pháp được đề xuất, chúng tôi so sánh nó với ba loại phương pháp (tức là, cắt tỉa-tại-khởi tạo (SNIP, GraSP, SynFlow), huấn luyện dày đặc-sang-thưa thớt (STR, SIS), và huấn luyện thưa thớt động (DeepR, SET, RigL)) từ trên xuống dưới. Kết quả của các baseline được lấy từ bài báo GraNet [35]. Nhìn chung, cả phương pháp cắt tỉa-tại-khởi tạo và dày đặc sang thưa thớt đều có độ chính xác cao hơn huấn luyện thưa thớt động (ngoại trừ RigL (sử dụng thiết lập ITOP [1])). Trong các tỷ lệ thưa thớt khác nhau, phương pháp được đề xuất đạt được độ chính xác cao nhất cho cả VGG-19 và ResNet-50. Sử dụng thời gian huấn luyện điển hình (tổng số epoch huấn luyện là 160), hầu như không có mất mát độ chính xác so với mô hình dày đặc ở độ thưa thớt 90% trên cả CIFAR-10 và CIFAR-100. Trên cả VGG-19 và ResNet-50, phương pháp được đề xuất có độ chính xác cao nhất so với các phương pháp huấn luyện thưa thớt SOTA ở độ thưa thớt khác nhau trên cả tập dữ liệu CIFAR-10 và CIFAR-10. Đối với VGG-19, phương pháp của chúng tôi có cải thiện độ chính xác lên đến 3.3%, 4.6% và 6.7% trên CIFAR-10 và hiệu suất cao hơn lên đến 11.1%, 15.3% và 18.8% về độ chính xác trên CIFAR-100, ở tỷ lệ thưa thớt 90%, 95% và 98%, tương ứng. Đối với ResNet-50, phương pháp được đề xuất của chúng tôi có cải thiện độ chính xác so với RigL với cùng số epoch huấn luyện. Cụ thể hơn, trên CIFAR-10, phương pháp của chúng tôi có điểm độ chính xác cao hơn 0.51, 0.86, 0.94 ở tỷ lệ thưa thớt 90%, 95%, 98%, tương ứng. Trên CIFAR-100, các cải thiện độ chính xác của phương pháp được đề xuất so với phương pháp huấn luyện thưa thớt SOTA là 2.2%, 2.0%, 0.83% ở tỷ lệ thưa thớt 90%, 95%, và 98%, tương ứng.

ImageNet. Bảng II cho thấy kết quả độ chính xác top-1, FLOPS huấn luyện và suy luận trên ResNet50 / ImageNet. Chúng tôi sử dụng mô hình huấn luyện dày đặc làm baseline. Đối với các baseline khác, chúng tôi chọn SNIP [10] và GraSP [11] làm baseline huấn luyện mặt nạ tĩnh trong khi áp dụng DeepR [32], SNFS [22], DSR [13], SET [12], RigL [14], MEST [23], RigL-ITOP [1] làm baseline huấn luyện mặt nạ động như được hiển thị trong Bảng II. So với các baseline huấn luyện mặt nạ tĩnh, phương pháp được đề xuất của chúng tôi

--- TRANG 5 ---
Dataset #Epochs CIFAR-10 CIFAR-100
Tỷ lệ thưa thớt 90% 95% 98% 90% 95% 98%
VGG-19(Dày đặc) 160 93.85±0.05 73.43±0.08
SNIP [10] 160 93.63 93.43 92.05 72.84 71.83 58.46
GraSP [11] 160 93.30 93.04 92.19 71.95 71.23 68.90
SynFlow [29] 160 93.35 93.45 92.24 71.77 71.72 70.94
STR [30] 160 93.73 93.27 92.21 71.93 71.14 69.89
SIS [31] 160 93.99 93.31 93.16 72.06 71.85 71.17
DeepR [32] 160 90.81 89.59 86.77 66.83 63.46 59.58
SET [12] 160 92.46 91.73 89.18 72.36 69.81 65.94
RigL [14] 160 93.38±0.11 93.06±0.09 91.98±0.09 73.13±0.28 72.14±0.15 69.82±0.09
DST-EE (Của chúng tôi) 160 93.84±0.09 93.53±0.08 92.55±0.08 74.27±0.18 73.15±0.12 70.80±0.15
DST-EE (Của chúng tôi) 250 94.13±0.09 93.67±0.09 92.95±0.03 74.76±0.07 73.91±0.13 71.51±0.10

ResNet-50(Dày đặc) 160 94.75±0.01 78.23±0.18
SNIP [10] 160 92.65 90.86 87.21 73.14 69.25 58.43
GraSP [11] 160 92.47 91.32 88.77 73.28 70.29 62.12
SynFlow [29] 160 92.49 91.22 88.82 73.37 70.37 62.17
STR [30] 160 92.59 91.35 88.75 73.45 70.45 62.34
SIS [31] 160 92.81 91.69 90.11 73.81 70.62 62.75
RigL [14] 160 94.45±0.43 93.86±0.25 93.26±0.22 76.50±0.33 76.03±0.34 75.06±0.27
DST-EE (Của chúng tôi) 160 94.96±0.23 94.72±0.18 94.20±0.08 78.15±0.17 77.54±0.25 75.68±0.11
DST-EE (Của chúng tôi) 250 95.01±0.16 94.92±0.22 94.53±0.03 79.16±0.06 78.66±0.31 76.38±0.10

BẢNG I: Độ chính xác kiểm tra của VGG-19 và ResNet-50 thưa thớt trên tập dữ liệu CIFAR-10/CIFAR-100. Kết quả được báo cáo với (trung bình ± độ lệch chuẩn) được chạy với ba seed ngẫu nhiên khác nhau. Điểm độ chính xác kiểm tra cao nhất được đánh dấu in đậm. DST-EE ký hiệu phương pháp được đề xuất của chúng tôi.

Phương pháp Epochs Training FLOPS Inference FLOPS Top-1 Acc Training FLOPS Inference FLOPS Top-1 Acc
(e18) (e9) (%) (e18) (e9) (%)
Dày đặc 100 3.2 8.2 76.8±0.09 3.2 8.2 76.8±0.09
Tỷ lệ thưa thớt - 80% 90%
SNIP [10] - 0.23 0.23 - 0.10 0.10 -
GraSP [11] 150 0.23 0.23 72.1 0.10 0.10 68.1
DeepR [32] - n/a n/a 71.7 n/a n/a 70.2
SNFS [22] - n/a n/a 73.8 n/a n/a 72.3
DSR [13] - 0.40 0.40 73.3 0.30 0.30 71.6
SET [12] - 0.23 0.23 72.9±0.39 0.10 0.10 69.6±0.23
RigL [14] 100 0.23 0.23 74.6±0.06 0.10 0.10 72.0±0.05
MEST [23] 100 0.23 0.23 75.39 0.10 0.10 72.58
RigL-ITOP [1] 100 0.42 0.42 75.84±0.05 0.25 0.24 73.82±0.08
DST-EE(Của chúng tôi) 100 0.23 0.42 76.25±0.09 0.10 0.24 75.3±0.06

BẢNG II: Hiệu suất của ResNet-50 trên tập dữ liệu ImageNet. Kết quả được báo cáo với (trung bình ± độ lệch chuẩn) được chạy với ba seed khác nhau.

có cải thiện độ chính xác lên đến 5.8% và 10.6%. Đối với các baseline huấn luyện mặt nạ động, RigL là baseline phổ biến gần đây, so với đó phương pháp được đề xuất có độ chính xác Top-1 cao hơn 2.2% và 3.7% ở tỷ lệ thưa thớt 80% và 90%, tương ứng. Đối với hai baseline tốt hơn khác của huấn luyện thưa thớt, MEST và RigL-ITOP, phương pháp của chúng tôi có độ chính xác cao hơn 1.1% và 0.5% ở tỷ lệ thưa thớt 0.8, và cải thiện độ chính xác 3.7% và 1.48% ở tỷ lệ thưa thớt 0.9, tương ứng.

Phương pháp Epochs Tỷ lệ thưa thớt Tỷ lệ thưa thớt Tỷ lệ thưa thớt
80% 90% 98%
Dày đặc - 79.72
Cắt tỉa-từ-dày đặc 60 79.05 78.34 78.08
DST-EE (của chúng tôi) 50 79.28 79.13 78.58

BẢNG III: Kết quả tác vụ dự đoán liên kết GNN trên wiki-talk [34].

Mạng Nơ-ron Đồ thị. Kết quả thực nghiệm của huấn luyện thưa thớt mạng nơ-ron đồ thị trên wiki-talk [34] và ia-

Phương pháp Epochs Tỷ lệ thưa thớt Tỷ lệ thưa thớt Tỷ lệ thưa thớt
80% 90% 98%
Dày đặc - 83.47
Cắt tỉa-từ-dày đặc 60 83.19 82.95 67.18
DST-EE (của chúng tôi) 50 83.77 83.29 82.82

BẢNG IV: Kết quả dự đoán liên kết GNN trên ia-email [33].

email [33] cho tác vụ dự đoán liên kết được hiển thị trong Bảng III và Bảng IV, tương ứng. Chúng tôi áp dụng phương pháp được đề xuất cho hai lớp kết nối đầy đủ với tỷ lệ thưa thớt đồng đều ở các mức thưa thớt khác nhau, là 80%, 90%, và 98%. Chúng tôi báo cáo độ chính xác dự đoán của mô hình tốt nhất được tìm kiếm trong 50 epoch huấn luyện. Chúng tôi so sánh phương pháp của chúng tôi với cả mô hình dày đặc và mô hình thưa thớt tốt nhất được cắt tỉa từ mô hình dày đặc sử dụng thuật toán ADMM. Các mô hình cắt tỉa-từ-dày đặc được huấn luyện tổng cộng 60 epoch, bao gồm 20 epoch tiền huấn luyện, 20 epoch huấn luyện có trọng số lại, và 20 epoch huấn luyện lại sau cắt tỉa. Kết quả thực nghiệm cho thấy ở độ thưa thớt 0.8,

--- TRANG 6 ---
0 5 10 15 20 25 30
Vòng cập nhật mặt nạ 0.10 0.15 0.20 0.25 0.30 0.35 0.40 Mức độ khám phá c=1e-4
c=1e-3
c=5e-3
140 142 144 146 148 150 152 154 156 158 160
Epoch huấn luyện 71.00 71.25 71.50 71.75 72.00 72.25 72.50 72.75 73.00 Độ chính xác c=1e-4
c=1e-3
c=5e-3
(a)CIFAR-100 / Độ thưa thớt=0.95

0 5 10 15 20 25
Vòng cập nhật mặt nạ 0.10 0.15 0.20 0.25 0.30 0.35 Mức độ khám phá c=5e-4
c=1e-3
c=5e-3
140 142 144 146 148 150 152 154 156 158 160
Epoch huấn luyện 92.00 92.25 92.50 92.75 93.00 93.25 93.50 93.75 94.00 Độ chính xác c=5e-4
c=1e-3
c=5e-3
(b)CIFAR-10 / Độ thưa thớt=0.95

Hình 3: Hình này cho thấy mối quan hệ của mức độ khám phá và độ chính xác kiểm tra trên CIFAR-10 và CIFAR-100 với độ thưa thớt 0.95.

phương pháp huấn luyện thưa thớt của chúng tôi thậm chí có độ chính xác tốt hơn mô hình dày đặc. Phương pháp được đề xuất có cải thiện độ chính xác so với cắt tỉa-từ-dày đặc trên cả hai tập dữ liệu sử dụng thậm chí ít epoch huấn luyện hơn. Trên wiki-talk [34], phương pháp của chúng tôi có độ chính xác cao hơn 0.29%, 1.0% và 0.64% so với cắt tỉa-từ-dày đặc sử dụng thuật toán ADMM ở tỷ lệ thưa thớt 80%, 90% và 98%, tương ứng. Trên ia-email [33], phương pháp được đề xuất có cải thiện độ chính xác lên đến 23.3% so với cắt tỉa-từ-dày đặc ở tỷ lệ thưa thớt 98%.

C. Khám phá Thiết kế về Các Mức độ Khám phá Khác nhau.

Chúng tôi điều tra ảnh hưởng của các hệ số đến mức độ khám phá và độ chính xác kiểm tra trên các tập dữ liệu VGG-19, CIFAR-10 / CIFAR-100 như được hiển thị trong Hình 3. Hình con bên trái trong Hình 3a cho thấy các đường cong mức độ khám phá khác nhau được tạo bằng cách sử dụng các hệ số đánh đổi khác nhau trên CIFAR-100 với độ thưa thớt 0.95. Chúng ta có thể thấy c càng lớn, mức độ khám phá của mô hình thưa thớt càng cao. Hình con bên phải trong Hình 3a minh họa các đường cong độ chính xác kiểm tra cho các hệ số khác nhau. Trong phạm vi hệ số, c càng lớn, độ chính xác kiểm tra càng cao. Sự kết hợp của hai hình con này tiết lộ quan sát rằng mức độ khám phá càng cao hoặc bao phủ trọng số càng cao, điểm độ chính xác kiểm tra càng cao. Các quan sát tương tự được hiển thị trong Hình 3b, điều này xác thực phương pháp của chúng tôi.

VI. KẾT LUẬN

Trong bài báo này, chúng tôi đề xuất chiến lược phát triển dựa trên khai thác trọng số quan trọng và khám phá bao phủ để đặc trưng và hỗ trợ huấn luyện thưa thớt có thể giải thích, cập nhật các mặt nạ thưa thớt và tìm kiếm mạng con "tốt nhất có thể". Chúng tôi cung cấp phân tích lý thuyết cho phương pháp khai thác và khám phá được đề xuất và làm rõ tính chất hội tụ của nó. Chúng tôi tiếp tục cung cấp phân tích định lượng của chiến lược và cho thấy lợi thế của phương pháp được đề xuất. Chúng tôi thiết kế hàm thu nhận để đánh giá tầm quan trọng của các trọng số không hoạt động cho việc phát triển và phát triển các trọng số với điểm quan trọng top-k cao nhất, xem xét sự cân bằng giữa khai thác và khám phá. Các thí nghiệm rộng rãi trên nhiều tác vụ học sâu khác nhau trên cả mạng nơ-ron tích chập và mạng nơ-ron đồ thị cho thấy lợi thế của DST-EE so với các phương pháp huấn luyện thưa thớt hiện có. Chúng tôi tiến hành thí nghiệm để phân tích định lượng ảnh hưởng của mức độ khám phá. Các quan sát xác thực phương pháp được đề xuất, tức là, phương pháp của chúng tôi có thể đạt được mức độ khám phá cao hơn và do đó độ chính xác kiểm tra cao hơn so với các phương pháp dựa trên tham lam.

LỜI CẢM ơN

Công việc này được tài trợ một phần bởi chương trình Phần cứng Trí tuệ Nhân tạo của Semiconductor Research Corporation (SRC), và chương trình UIUC HACC.

TÀI LIỆU THAM KHẢO

[1] Shiwei Liu và cộng sự. Do we actually need dense over-parameterization? in-time over-parameterization in sparse training. Trong ICML, trang 6989–7000. PMLR, 2021.
[2] Shaoyi Huang và cộng sự. Sparse progressive distillation: Resolving overfitting under pretrain-and-finetune paradigm. Trong ACL, trang 190–200, 2022.
[3] Hongwu Peng và cộng sự. A length adaptive algorithm-hardware co-design of transformer on fpga through sparse attention and dynamic pipelining. Trong DAC, trang 1135–1140, 2022.
[4] Panjie Qi và cộng sự. Accommodating transformer onto fpga: Coupling the balanced model compression and fpga-implementation optimization. Trong GLSVLSI, 2021.
[5] Hongwu Peng và cộng sự. Towards sparsification of graph neural networks. Trong ICCD. IEEE, 2022.
[6] Panjie Qi và cộng sự. Accelerating framework of transformer by hardware design and model compression co-optimization. Trong ICCAD. IEEE, 2021.
[7] Daniel Manu và cộng sự. Co-exploration of graph neural network and network-on-chip design using automl. Trong Proceedings of the 2021 on Great Lakes Symposium on VLSI, trang 175–180, 2021.
[8] Tom B. Brown và cộng sự. Language models are few-shot learners. 2020.
[9] David Patterson và cộng sự. Carbon emissions and large neural network training. arXiv preprint arXiv:2104.10350, 2021.
[10] Namhoon Lee và cộng sự. Snip: Single-shot network pruning based on connection sensitivity. Trong ICLR, 2019.
[11] Chaoqi Wang và cộng sự. Picking winning tickets before training by preserving gradient flow. ICLR, 2020.
[12] Decebal Constantin Mocanu và cộng sự. Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science. Nature communications, 2018.
[13] Hesham Mostafa và cộng sự. Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization. Trong ICML. PMLR, 2019.
[14] Utku Evci và cộng sự. Rigging the lottery: Making all tickets winners. Trong ICML, trang 2943–2952. PMLR, 2020.
[15] Zheng He và cộng sự. Sparse double descent: Where network pruning aggravates overfitting. Trong ICML. PMLR, 2022.
[16] Alex Renda và cộng sự. Comparing rewinding and fine-tuning in neural network pruning. arXiv preprint arXiv:2003.02389, 2020.
[17] Ofir Zafrir và cộng sự. Prune once for all: Sparse pre-trained language models. arXiv preprint arXiv:2111.05754, 2021.
[18] Zhiyong Li và cộng sự. Ps–abc: A hybrid algorithm based on particle swarm and artificial bee colony for high-dimensional optimization problems. Expert Systems with Applications, 2015.
[19] Hongwu Peng và cộng sự. Accelerating transformer-based deep learning models on fpgas using column balanced block pruning. Trong ISQED. IEEE, 2021.
[20] Shiyang Chen và cộng sự. Et: re-thinking self-attention for transformer models on gpus. Trong SC, trang 1–18, 2021.
[21] Tianyun Zhang và cộng sự. A systematic dnn weight pruning framework using alternating direction method of multipliers. Trong ECCV, trang 184–199, 2018.
[22] Tim Dettmers và cộng sự. Sparse networks from scratch: Faster training without losing performance. arXiv preprint arXiv:1907.04840, 2019.
[23] Geng Yuan và cộng sự. Mest: Accurate and fast memory-economic sparse training framework on the edge. NeurIPS, 34, 2021.
[24] Xiaolong Ma và cộng sự. Effective model sparsification by scheduled grow-and-prune methods. Trong ICLR, 2021.
[25] Song Han và cộng sự. Dsd: Dense-sparse-dense training for deep neural networks. arXiv preprint arXiv:1607.04381, 2016.
[26] Bo Xie và cộng sự. Diverse neural network learns true target functions. Trong Artificial Intelligence and Statistics. PMLR, 2017.
[27] Matej Črepinšek và cộng sự. Exploration and exploitation in evolutionary algorithms: A survey. CSUR, 2013.
[28] Robert C Wilson và cộng sự. Balancing exploration and exploitation with information and randomization. Current opinion in behavioral sciences, 2021.
[29] Hidenori Tanaka và cộng sự. Pruning neural networks without any data by iteratively conserving synaptic flow. NeurIPS, 2020.
[30] Aditya Kusupati và cộng sự. Soft threshold weight reparameterization for learnable sparsity. Trong ICML, 2020.
[31] Sagar Verma và cộng sự. Sparsifying networks via subdifferential inclusion. Trong ICML, 2021.
[32] Guillaume Bellec và cộng sự. Deep rewiring: Training very sparse deep networks. ICLR, 2018.

--- TRANG 7 ---
[33] Ryan A. Rossi và Nesreen Ahmed. The network data repository with interactive graph analytics and visualization. Trong AAAI, 2015.
[34] Stuart Cunningham và David Craig. Creator governance in social media entertainment. Social Media + Society, 5, 2019.
[35] Shiwei Liu và cộng sự. Sparse training via boosting pruning plasticity with neuroregeneration. NeurIPS, 34:9908–9922, 2021.

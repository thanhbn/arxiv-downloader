# Các Mô Hình Thưa ImageNet Chuyển Giao Tốt Như Thế Nào?

Eugenia Iofinova*
IST Austria
Alexandra Peste*
IST Austria
Mark Kurtz
Neural Magic
Dan Alistarh
IST Austria & Neural Magic

## Tóm tắt

Học chuyển giao là một mô hình cổ điển trong đó các mô hình được huấn luyện trước trên các tập dữ liệu "nguồn" lớn được điều chỉnh để đạt kết quả tốt trên các tập dữ liệu "đích" chuyên biệt. Nói chung, các mô hình chính xác hơn trên tập dữ liệu "nguồn" có xu hướng cung cấp độ chính xác chuyển giao tốt hơn "xuôi dòng". Trong nghiên cứu này, chúng tôi thực hiện một cuộc điều tra sâu về hiện tượng này trong bối cảnh của các mạng nơ-ron tích chập (CNN) được huấn luyện trên tập dữ liệu ImageNet, đã được cắt tỉa—nghĩa là được nén bằng cách làm thưa các kết nối của chúng. Chúng tôi xem xét việc chuyển giao sử dụng các mô hình cắt tỉa không có cấu trúc thu được bằng cách áp dụng một số phương pháp cắt tỉa tiên tiến, bao gồm các phương pháp dựa trên độ lớn, bậc hai, tái phát triển, vé số may mắn và chính quy hóa, trong bối cảnh của mười hai nhiệm vụ chuyển giao tiêu chuẩn. Tóm lại, nghiên cứu của chúng tôi cho thấy các mô hình thưa có thể khớp hoặc thậm chí vượt trội hơn hiệu suất chuyển giao của các mô hình dày, ngay cả ở độ thưa cao, và trong khi làm như vậy, có thể dẫn đến tăng tốc suy luận đáng kể và thậm chí cả huấn luyện. Đồng thời, chúng tôi quan sát và phân tích những khác biệt đáng kể trong hành vi của các phương pháp cắt tỉa khác nhau.

## 1. Giới thiệu

Chi phí tính toán lớn của học sâu đã dẫn đến sự quan tâm học thuật và công nghiệp đáng kể đến nén mô hình, được định nghĩa đại khái là thu được các mô hình có dung lượng nhỏ hơn mà vẫn khớp với độ chính xác của các mô hình lớn hơn. Nén mô hình là một lĩnh vực phát triển nhanh chóng, và một số phương pháp tổng quát đã được nghiên cứu, trong đó cắt tỉa và lượng tử hóa là những phương pháp phổ biến nhất [18, 28].

Chúng tôi tập trung nghiên cứu hiện tại vào cắt tỉa trọng số, có mục tiêu là loại bỏ, bằng cách đặt bằng không, càng nhiều trọng số càng tốt mà không làm mất độ chính xác của mô hình. Cắt tỉa trọng số có thể nói là phương pháp nén có lịch sử phong phú nhất [42] và hiện tại là một chủ đề nghiên cứu rất tích cực [28]. Nhờ xu hướng này, một tập hợp các tiêu chuẩn độ chính xác khá nhất quán đã xuất hiện cho việc cắt tỉa, cùng với sự hỗ trợ tính toán ngày càng hiệu quả [11, 20, 40, 52].

Một mục tiêu chính của nén mô hình là cho phép triển khai trên các thiết bị biên. Các thiết bị như vậy có thể tự nhiên gặp phải các phân phối dữ liệu khác nhau, vì vậy thật hấp dẫn khi hỏi các mô hình nén sẽ hoạt động như thế nào đối với học chuyển giao, được định nghĩa rộng rãi là tận dụng thông tin từ một nhiệm vụ "nguồn" cơ bản ("được huấn luyện trước") để thực hiện tốt hơn trên một nhiệm vụ "đích" ("tinh chỉnh"). Cụ thể, chúng tôi chủ yếu tập trung vào một thiết lập học chuyển giao điển hình [36]: bắt đầu từ các mô hình được huấn luyện và nén trên tập dữ liệu ImageNet-1K [60], chúng tôi tinh chỉnh các mô hình kết quả trên một số nhiệm vụ đích khác nhau. Trong bối cảnh này, chúng tôi xem xét câu hỏi về mức độ tốt của việc chuyển giao các mô hình thưa kết quả. Động lực của chúng tôi vừa có tính thực tiễn—chuyển giao thưa có thể cung cấp tăng tốc cho cả suy luận và huấn luyện trên mô hình xuôi dòng—vừa có tính phân tích, vì chúng tôi nhằm mục đích làm sáng tỏ tác động của độ thưa lên các đặc trưng kết quả.

Nghiên cứu của chúng tôi sẽ xem xét hai biến thể học chuyển giao phổ biến: tinh chỉnh đầy đủ, trong đó tất cả các trọng số chưa được cắt tỉa có thể được tối ưu hóa trong quá trình chuyển giao, và tinh chỉnh tuyến tính, trong đó chỉ lớp tuyến tính cuối cùng của mô hình được tinh chỉnh xuôi dòng. Mặc dù cả hai đều phổ biến, chúng ta sẽ thấy rằng chúng có thể dẫn đến kết quả khác nhau. Chúng tôi bổ sung khám phá tăng tốc thời gian suy luận bằng cách sử dụng một công cụ suy luận nhận biết độ thưa [9], và lần đầu tiên xem xét tăng tốc thời gian huấn luyện có thể đạt được cho tinh chỉnh tuyến tính thông qua các mô hình thưa. Hơn nữa, chúng tôi phân tích tác động của các phương pháp cắt tỉa khác nhau và đặc điểm nhiệm vụ lên hiệu suất chuyển giao.

Chúng tôi xem xét các phương pháp cắt tỉa có hiệu suất hàng đầu về độ chính xác ImageNet, được chia thành ba danh mục một cách thô. Danh mục đầu tiên được đưa ra bởi các phương pháp làm thưa dần dần, bắt đầu từ một đường cơ sở dày chính xác và tiến hành loại bỏ trọng số dần dần, theo sau bởi tinh chỉnh. Ví dụ điển hình là cắt tỉa độ lớn dần dần (GMP) [17,22,23,69], sử dụng độ lớn trọng số tuyệt đối làm tiêu chí cắt tỉa. Ngoài ra, chúng tôi xem xét cắt tỉa WoodFisher [63], tận dụng thông tin bậc hai để cắt tỉa với độ chính xác cao.

Danh mục thứ hai được đưa ra bởi các phương pháp huấn luyện chính quy hóa thưa, thực hiện nén mạng, và có thể tái phát triển mạng, trong quá trình huấn luyện. Các phương pháp có hiệu suất hàng đầu mà chúng tôi xem xét ở đây là Tái Tham Số Hóa Ngưỡng Mềm (STR) [41], Huấn Luyện Nén/Giải Nén Xen Kẽ (AC/DC) [57] và "Xổ Số Gian Lận" (RigL) [12].

Danh mục cuối cùng bao gồm các phương pháp theo kiểu Giả Thuyết Vé Số May Mắn (LTH) [5, 6, 14, 15]. Các phương pháp này nhấn mạnh việc khám phá các mạng con thưa, có thể mang lại độ chính xác tốt khi được huấn luyện lại từ đầu. Cụ thể, chúng tôi xem xét LTH cho chuyển giao (LTH-T) [5], cung cấp kết quả tiên tiến trong số các phương pháp như vậy.

Chúng tôi đo độ chính xác chuyển giao của các mô hình ImageNet thưa thu được thông qua các phương pháp cắt tỉa này. Ứng dụng đích chính của chúng tôi được đưa ra bởi mười hai tập dữ liệu chuyển giao cổ điển, được mô tả trong Bảng 2, từ các tập dữ liệu tổng quát đến các tập dữ liệu chuyên biệt hơn. Chúng tôi chủ yếu tập trung vào mô hình ResNet50 [26] cổ điển, nhưng chúng tôi mở rộng phân tích của mình đến ResNet18, ResNet34 và MobileNet-V1 [31], và chúng tôi cũng xem xét hiệu suất chuyển giao cho các nhiệm vụ phát hiện đối tượng.

**Đóng góp.** Chúng tôi trình bày nghiên cứu có hệ thống đầu tiên về cách các phương pháp cắt tỉa và chuyển giao khác nhau tác động đến hiệu suất chuyển giao. Phát hiện chính của chúng tôi là các mô hình thưa có thể nhất quán khớp với độ chính xác của các mô hình dày tương ứng trên các nhiệm vụ chuyển giao. Tuy nhiên, hành vi này bị tác động bởi các yếu tố sau: phương pháp cắt tỉa (ví dụ: chính quy hóa so với cắt tỉa dần dần), phương pháp chuyển giao (đầy đủ so với tuyến tính), độ thưa mô hình (ví dụ: 80% vừa phải so với 98% cao), và loại nhiệm vụ (ví dụ: mức độ chuyên biệt hóa).

Chúng tôi tóm tắt ngắn gọn các kết luận chính của mình, được tóm tắt trong Hình 1 và Bảng 1. Đối với tinh chỉnh tuyến tính, các mô hình thưa thường khớp và có thể vượt trội nhẹ so với các mô hình dày. Tuy nhiên, điều này không đúng cho tất cả các phương pháp cắt tỉa: các phương pháp dựa trên chính quy hóa hoạt động đặc biệt tốt, ngay cả ở độ thưa cao (ví dụ: 95%). Đối với tinh chỉnh đầy đủ, thường cung cấp độ chính xác cao hơn [36], các mô hình thưa cũng cạnh tranh với các mô hình dày, nhưng độ chính xác chuyển giao tương quan chặt chẽ hơn với độ chính xác trên nhiệm vụ huấn luyện trước ImageNet: do đó, các mô hình ít thưa hơn (ví dụ: độ thưa 80%-90%) có xu hướng chính xác hơn so với các mô hình thưa hơn. Hơn nữa, trong thiết lập này, chúng tôi thấy rằng các phương pháp làm thưa dần dần nhất quán tạo ra các mô hình có độ chính xác chuyển giao cao hơn, so với các phương pháp chính quy hóa. Chúng tôi cung cấp phân tích đầu tiên về hiệu ứng này, liên kết nó với các tính chất cấu trúc của các mô hình đã cắt tỉa. Ngoài ra, chúng tôi quan sát độ chính xác thấp rõ rệt của các phương pháp vé số may mắn, đặc biệt ở các mức độ thưa cao hơn, ví dụ: 90%, cần thiết cho tăng tốc tính toán.

Với sự khác biệt trong hành vi giữa tinh chỉnh tuyến tính và đầy đủ, chúng tôi thấy rằng hiện tại không có phương pháp cắt tỉa "tốt nhất" duy nhất cho chuyển giao. Tuy nhiên, sử dụng các phương pháp hiện có, người ta có thể nhất quán đạt được nén theo thứ tự độ lớn (90%) mà không mất độ chính xác. Đổi lại, các mức nén này có thể dẫn đến tăng tốc hơn 3× trên các thời gian chạy hỗ trợ độ thưa. Điều này cho thấy rằng chuyển giao thưa có thể có tiềm năng thực tiễn đáng kể.

## 2. Nền tảng và Nghiên cứu Liên quan

### 2.1. Kỹ thuật Làm thưa

Gần đây, đã có sự quan tâm nghiên cứu đáng kể đến các kỹ thuật cắt tỉa, và hàng trăm phương pháp làm thưa khác nhau đã được đề xuất; vui lòng xem các khảo sát gần đây của [17] và [28] để có một trình bày toàn diện. Chúng tôi phân loại thô các phương pháp cắt tỉa hiện có như sau.

**Các Phương pháp Làm thưa Dần dần** bắt đầu từ một mô hình cơ sở dày chính xác, và loại bỏ trọng số dần dần trong nhiều bước, được ngăn cách bởi các giai đoạn tinh chỉnh, được thiết kế để khôi phục độ chính xác. Một trường hợp cổ điển là cắt tỉa độ lớn dần dần (GMP) [17,22,23,69], loại bỏ trọng số dần dần theo độ lớn tuyệt đối của chúng, được đo toàn cục hoặc theo lớp. Các phương pháp cắt tỉa bậc hai, ví dụ: [16, 24, 42, 63, 65] bổ sung cho metric cơ bản này với thông tin bậc hai, có thể dẫn đến độ chính xác cao hơn của các mô hình đã cắt tỉa kết quả, so với GMP.

**Các Phương pháp Chính quy hóa** thường được áp dụng trong quá trình huấn luyện mô hình, thông qua các cơ chế thúc đẩy độ thưa. Các cơ chế này rất đa dạng, từ các phép thay thế của chính quy hóa ℓ0 và ℓ1 [41,67], đến các phương pháp biến phân [53], đến các phương pháp lấy cảm hứng từ các cơ chế cảm biến nén như Ngưỡng Cứng Lặp (IHT) [32, 33, 45, 57]. Chúng tôi cũng xem xét phương pháp "Xổ Số Gian Lận" (RigL) [12], đạt được kết quả ImageNet gần như tiên tiến bằng cách cho phép cắt tỉa trọng số động và tái giới thiệu với các giai đoạn tinh chỉnh dài, là một phương pháp chính quy hóa.

**Các Phương pháp Giả Thuyết Vé Số May Mắn (LTH)** [14] bắt đầu từ một mô hình đã được huấn luyện đầy đủ, và thường áp dụng cắt tỉa trong một bước duy nhất hoặc trong nhiều bước tăng dần để thu được một mặt nạ thưa trên các trọng số. Sau đó chúng khởi động lại huấn luyện, nhưng bị hạn chế trong mặt nạ đã cho. Huấn luyện khởi động lại từ khởi tạo [14], hoặc bằng cách "tua lại" đến một điểm sớm hơn trong quá trình huấn luyện của mô hình dày [6, 7, 15]. (Sự kết hợp mặt nạ ngẫu nhiên–khởi tạo được coi như "vé số may mắn".) Tua lại có vẻ cần thiết cho kết quả ổn định trên các tập dữ liệu lớn như ImageNet [5, 6, 15].

Phân loại trên rõ ràng là xấp xỉ: ví dụ, các phương pháp LTH có thể được xem như một trường hợp đặc biệt của làm thưa dần dần, trong đó một phương pháp tinh chỉnh cụ thể được áp dụng. Hơn nữa, không hiếm khi kết hợp các phương pháp, như chính quy hóa và làm thưa dần dần [28]. Chúng tôi cung cấp so sánh hiệu quả của những phương pháp khác nhau này trong bối cảnh học chuyển giao, bằng cách xem xét nhiều phương pháp từ mỗi danh mục. Theo hiểu biết của chúng tôi, đây là nghiên cứu chi tiết đầu tiên như vậy.

Độ chính xác kiểm tra Top-1 là metric tiêu chuẩn để so sánh các phương pháp cắt tỉa. Chúng tôi cũng áp dụng metric này để xem xét độ chính xác trong bối cảnh chuyển giao, vì không có nghiên cứu như vậy tồn tại. Tuy nhiên, chúng tôi muốn nêu bật nghiên cứu gần đây [29, 30, 44] xem xét tính bền vững của các mô hình đã cắt tỉa đối với nhiễu đầu vào, cũng như tác động của cắt tỉa lên độ chính xác của các phân khúc cụ thể của dữ liệu.

### 2.2. Học Chuyển giao và Độ thưa

**Học Chuyển giao Dày.** Một khối lượng lớn tài liệu đã thiết lập rằng, nói chung, các kiến trúc học sâu chuyển giao tốt đến các nhiệm vụ "xuôi dòng" nhỏ hơn, và tinh chỉnh đầy đủ thường đạt được độ chính xác cao hơn tinh chỉnh tuyến tính [36, 61]. (Một nghiên cứu rất gần đây [39] gợi ý rằng điều này có thể bị đảo ngược trên các nhiệm vụ ngoài phân phối.) Những phát hiện này mở rộng đến các nhiệm vụ liên quan, như phát hiện đối tượng và phân đoạn [51]. Kolesnikov và cộng sự [35] đã tập trung vào các yếu tố quyết định thành công của học chuyển giao, và phát triển các công thức tinh chỉnh đáng tin cậy. Điều này đã được mở rộng thêm bởi Djolonga và cộng sự [10], những người kết luận rằng việc tăng quy mô của mô hình và tập dữ liệu ban đầu cải thiện đáng kể hiệu suất ngoài phân phối và chuyển giao, mặc dù có tác động biên trên độ chính xác ban đầu. Salman và cộng sự [61] xem xét liệu các bộ phân loại ImageNet bền vững đối kháng có thể vượt trội hơn các bộ phân loại tiêu chuẩn cho học chuyển giao, và thấy rằng điều này thực sự có thể xảy ra. Chúng tôi bổ sung cho những nghiên cứu này bằng cách xem xét các mô hình thưa và phương pháp cắt tỉa.

**Học Chuyển giao Thưa.** Một trong những nghiên cứu sớm nhất xem xét hiệu suất chuyển giao cho các mô hình đã cắt tỉa là [54], có mục tiêu thiết kế các thuật toán cho phép cắt tỉa một mô hình tích chập (dày) khi chuyển giao trên một nhiệm vụ đích. (Một nghiên cứu tương tự được thực hiện bởi [62] cho các mô hình ngôn ngữ.) Ngược lại, chúng tôi tập trung vào thiết lập khác nhau trong đó các mô hình đã được làm thưa trên tập dữ liệu nguồn, và quan sát độ thưa cao hơn so với nghiên cứu sớm của [54].

Nghiên cứu gần đây về học chuyển giao thưa đã tập trung cụ thể vào các mô hình thu được thông qua phương pháp "Giả Thuyết Vé Số May Mắn" (LTH) [14], phát biểu đại khái rằng tồn tại các mặt nạ độ thưa và khởi tạo cho phép các mạng thưa chính xác được huấn luyện từ đầu. Có một số nghiên cứu điều tra "khả năng chuyển giao" của các mô hình thu được thông qua quy trình này cho các nhiệm vụ khác nhau: ví dụ, [50] cho thấy các vé số may mắn thu được trên tập dữ liệu CIFAR có thể chuyển giao tốt trên các nhiệm vụ xuôi dòng nhỏ hơn, trong khi [6, 19] điều tra khả năng áp dụng của vé số may mắn cho các mô hình ngôn ngữ được huấn luyện trước (BERT), và các nhiệm vụ nhận dạng đối tượng, tương ứng. Mallya và cộng sự [49] xem xét vấn đề liên quan nhưng khác biệt là điều chỉnh một mạng cố định cho nhiều nhiệm vụ xuôi dòng, bằng cách học các mặt nạ cụ thể cho nhiệm vụ.

Nghiên cứu gần đây của [5] xem xét hiệu suất chuyển giao của LTH cho chuyển giao, đề xuất LTH-T, và thấy rằng phương pháp này đảm bảo độ chính xác xuôi dòng tốt ở độ thưa vừa phải (ví dụ: lên đến 80%). Chúng tôi xem xét một thiết lập tương tự, nhưng điều tra một loạt rộng hơn các phương pháp cắt tỉa (bao gồm LTH-T) và các tập dữ liệu chuyển giao bổ sung. Cụ thể, chúng tôi là những người đầu tiên so sánh LTH-T với các phương pháp cắt tỉa nguồn cạnh tranh. Chúng tôi quan sát rằng, trên tinh chỉnh đầy đủ, hầu hết các phương pháp cắt tỉa nhất quán vượt trội hơn LTH-T về độ chính xác xuôi dòng qua các mức độ thưa, với khoảng cách lớn ở độ thưa cao.

## 3. Chuyển giao Thưa trên ImageNet

### 3.1. Lựa chọn Thực nghiệm

**Các Biến thể Học Chuyển giao.** Chúng tôi xem xét cả tinh chỉnh đầy đủ, trong đó toàn bộ tập hợp các đặc trưng được tối ưu hóa trên tập dữ liệu xuôi dòng, và tinh chỉnh tuyến tính, trong đó chỉ bộ phân loại lớp cuối cùng được tinh chỉnh, trên các mô hình thưa. Trong trường hợp trước, ngoại trừ lớp phân loại cuối cùng và các tham số chuẩn hóa batch (BN), chỉ các trọng số khác không của mô hình ban đầu được tối ưu hóa, và mặt nạ được giữ cố định.

Chúng tôi không xem xét huấn luyện từ đầu và cắt tỉa trên nhiệm vụ xuôi dòng, vì hai lý do. Thứ nhất, huấn luyện từ đầu thường ít chính xác hơn học chuyển giao (dày) trong cùng thiết lập [36, 51]. Như các thí nghiệm của chúng tôi sẽ cho thấy, chuyển giao từ các mô hình thưa thường có thể khớp hoặc thậm chí vượt trội nhẹ so với chuyển giao từ các mô hình dày. Thứ hai, vì huấn luyện từ đầu thường ít chính xác hơn chuyển giao [36], có vẻ không khả thi rằng huấn luyện và cắt tỉa từ đầu sẽ vượt trội hơn chuyển giao thưa. Chúng tôi đưa ra bằng chứng cho tuyên bố này trong Phụ lục A. Một lợi thế thực tiễn của phương pháp này là không cần điều chỉnh siêu tham số liên quan đến nén trên tập dữ liệu xuôi dòng.

**Kiến trúc Mạng.** Nghiên cứu của chúng tôi dựa trên phân tích sâu về chuyển giao thưa sử dụng kiến trúc ResNet50 [26]. Kiến trúc này có việc áp dụng thực tiễn rộng rãi, và đã được nghiên cứu rộng rãi trong bối cảnh học chuyển giao [36, 61]. Quan trọng là, khả năng nén của nó cũng đã nổi lên như một tiêu chuẩn nhất quán cho các phương pháp cắt tỉa CNN [28]. Chúng tôi tiếp tục xác thực một số phát hiện của mình trên các kiến trúc ResNet18, ResNet34 và MobileNet [31]. Ngoài ra, chúng tôi điều tra chuyển giao giữa hai nhiệm vụ phát hiện đối tượng cổ điển, MS COCO [46] và Pascal VOC [13], sử dụng các biến thể của kiến trúc YOLOv3 [59].

**Các Phương pháp Làm thưa.** Cho nghiên cứu của chúng tôi, chúng tôi chọn các phương pháp cắt tỉa cung cấp độ chính xác xác thực hàng đầu cho mỗi loại phương pháp trong Mục 2.1. Đối với các phương pháp làm thưa dần dần, chúng tôi sử dụng các phương pháp WoodFisher [63] và Cắt tỉa Độ lớn Dần dần (GMP) [17,22,23,69] hàng đầu. Đối với các phương pháp chính quy hóa, chúng tôi xem xét các phương pháp Tái Tham Số Hóa Trọng số Ngưỡng Mềm (STR) [41] và Nén/Giải nén Xen kẽ (AC/DC) [57] hàng đầu. Ngoài ra, chúng tôi bao gồm phương pháp "Xổ Số Gian Lận" (RigL) [12] với mật độ trọng số Erdős-Rényi-Kernel (ERK). So với STR và AC/DC, RigL mở rộng lịch trình huấn luyện trên ImageNet lên đến 5×, và thực hiện huấn luyện thưa cho hầu hết các bước tối ưu hóa. Chúng tôi xem xét cả phiên bản tiêu chuẩn của RigL (RigL ERK 1×), và biến thể với 5× lần lặp huấn luyện (RigL ERK 5×). Cuối cùng, đối với Các Phương pháp LTH, chúng tôi xem xét phương pháp LTH-cho-Chuyển giao (LTH-T) của [5], khớp chính xác với thiết lập của chúng tôi. Trong phiên bản này, các tác giả áp dụng các mặt nạ thu được thông qua các phương pháp làm thưa dần dần trực tiếp lên mô hình ImageNet dày ban đầu đã huấn luyện, và đánh giá độ chính xác chuyển giao của mô hình đã đeo mặt nạ này thông qua tinh chỉnh đầy đủ trên các nhiệm vụ xuôi dòng khác nhau.

Chúng tôi tập trung vào cắt tỉa không có cấu trúc, vì các phương pháp này được nghiên cứu nhiều nhất trong tài liệu cắt tỉa, có các tiêu chuẩn được thiết lập tốt, và đạt được sự đánh đổi tốt nhất giữa độ chính xác và nén. Chúng tôi bao gồm kết quả cho tinh chỉnh đầy đủ từ các mô hình có độ thưa có cấu trúc trong Phụ lục I, cho thấy rằng, với một mức độ chính xác cố định nguồn, các mô hình thưa có cấu trúc có xu hướng kém hơn các mô hình thưa không có cấu trúc cho chuyển giao.

Khi có sẵn, chúng tôi sử dụng các checkpoint PyTorch thưa ban đầu, và các kiến trúc chính xác được sử dụng bởi các mô hình nguồn. Tuy nhiên, vì các mô hình STR và RigL được huấn luyện bằng cách sử dụng làm mịn nhãn, đã được chỉ ra trong [36] làm giảm độ chính xác chuyển giao, chúng tôi đã sử dụng các phiên bản được huấn luyện lại của các mô hình này trên ImageNet, không có làm mịn nhãn. Kết quả mà chúng tôi thảo luận trong các phần tiếp theo là cho các phiên bản này, thực sự hoạt động tốt hơn, đặc biệt trên tinh chỉnh tuyến tính (xem Phụ lục H). Chúng tôi chuyển đổi thủ công các checkpoint RigL từ TensorFlow sang PyTorch (xem Bảng 3 cho tất cả kết quả ImageNet).

**Các nhiệm vụ xuôi dòng và huấn luyện.** Chúng tôi tuân theo [61] trong việc sử dụng mười hai tập dữ liệu tiêu chuẩn chuyển giao được mô tả trong Bảng 2, trải dài trên nhiều lĩnh vực và kích thước. Chúng tôi chuyển giao tất cả các tham số của mô hình nguồn ngoại trừ lớp (kết nối đầy đủ) cuối cùng, được điều chỉnh theo số lượng lớp trong nhiệm vụ xuôi dòng, sử dụng khởi tạo Kaiming uniform [25], và được giữ dày. Điều này có thể thay đổi nhẹ độ thưa của mô hình, vì trong một số trường hợp lớp cuối cùng đã thưa. Theo quy ước, khi thảo luận các mức độ thưa, chúng tôi đề cập đến độ thưa checkpoint nguồn. Chúng tôi cung cấp các siêu tham số huấn luyện đầy đủ trong Phụ lục B.

**Các metric hiệu suất.** Đại lượng quan tâm chính là độ chính xác xác thực top-1 trên mỗi nhiệm vụ chuyển giao, được đo cho tất cả các mô hình đã cắt tỉa, cũng như cho các đường cơ sở dày. Trong một số trường hợp, chúng tôi sử dụng độ chính xác xác thực trung bình theo lớp tuân theo quy ước cho tập dữ liệu đó (xem Bảng 2). Để xác định "tiềm năng chuyển giao" tổng thể cho mỗi phương pháp cắt tỉa, chúng tôi tiếp tục trình bày kết quả được tổng hợp trên các nhiệm vụ xuôi dòng. Vì các tập dữ liệu chúng tôi sử dụng cho học chuyển giao có các mức độ khó khác nhau, như được phản ánh bởi phạm vi rộng của độ chính xác chuyển giao, chúng tôi tính toán cho mỗi nhiệm vụ xuôi dòng và mô hình sự gia tăng tương đối trong lỗi so với đường cơ sở dày. Cụ thể, nếu B là mô hình cơ sở dày, thì cho mỗi nhiệm vụ xuôi dòng D và mô hình thưa S chúng tôi định nghĩa sự gia tăng tương đối trong lỗi là εD,S = (errD,S - errD,B)/errD,B, trong đó errD,S là lỗi tương ứng với độ chính xác xác thực hàng đầu cho mô hình S được huấn luyện trên tập dữ liệu D. Đối với mỗi phương pháp cắt tỉa và mức độ thưa, chúng tôi báo cáo trung bình và sai số chuẩn của εD,S, được tính toán trên tất cả các nhiệm vụ xuôi dòng.

Chúng tôi cũng xem xét tiềm năng tăng tốc tính toán của mỗi phương pháp, cùng với độ chính xác của nó. Đối với tăng tốc thời gian suy luận, các phát hiện của chúng tôi phù hợp với nghiên cứu trước đây, ví dụ: [11,57,63]. Do đó chúng tôi sẽ tập trung vào tiềm năng tăng tốc thời gian huấn luyện trong trường hợp tinh chỉnh tuyến tính, thường gần với tăng tốc thời gian suy luận, vì sự khác biệt duy nhất là thời gian huấn luyện của lớp phân loại.

### 3.2. Độ chính xác Xác thực trên các Biến thể ImageNet

Để thiết lập đường cơ sở, trước tiên chúng tôi xem xét độ chính xác trên tập xác thực ImageNet ban đầu, và trên các phiên bản khác nhau của tập xác thực này. Cụ thể, chúng tôi sử dụng "nhãn được đánh giá lại" ImageNet [2], trong đó các hình ảnh xác thực ImageNet ban đầu được đánh giá lại bởi các chú thích viên con người. Chúng tôi cũng sử dụng ba tập xác thực ImageNetV2 khác nhau [58], trong đó các hình ảnh mới có phân phối dữ liệu tương tự được thu thập dựa trên các tiêu chí khác nhau. Chúng tôi báo cáo độ chính xác ImageNetV2 trung bình qua ba biến thể này trong Bảng 3.

**Thảo luận.** Chúng tôi quan sát rằng RigL ERK 5× vượt trội hơn tất cả các phương pháp trên tập xác thực ban đầu ở độ thưa 90% và 95%, theo sau bởi AC/DC, GMP và WoodFisher. Ở độ thưa 80%, WoodFisher có độ chính xác xác thực ban đầu tốt nhất, theo sát bởi GMP và AC/DC. Tuy nhiên, mặc dù có khoảng cách trong độ chính xác xác thực ban đầu giữa RigL ERK 5× và các phương pháp khác, kết quả trên các biến thể mới của tập xác thực vẫn tiết lộ một số mẫu thú vị. Ví dụ, WoodFisher vượt trội hơn tất cả các phương pháp ở độ thưa 80% và 90% trên các nhãn được đánh giá lại, theo sát bởi AC/DC. Điều này cũng đúng cho ImageNetV2, trong đó WoodFisher vượt trội hơn tất cả các phương pháp ở độ thưa 80% và 90%. Tuy nhiên, ở độ thưa 95%, RigL ERK 5× vượt trội hơn tất cả các phương pháp được xem xét, bao gồm trên các nhãn được đánh giá lại và ImageNetV2, và được theo sau bởi AC/DC. Nói chung, độ chính xác trên các nhãn được đánh giá lại và ImageNetV2 tương quan tốt với những độ chính xác trên hình ảnh ban đầu, cho thấy rằng các phương pháp có hiệu suất hàng đầu có thể "ngoại suy" tốt.

### 3.3. Tinh chỉnh Tuyến tính

Tiếp theo, chúng tôi nghiên cứu hiệu suất chuyển giao của các loại phương pháp cắt tỉa khác nhau trong tình huống mà chỉ bộ phân loại tuyến tính "trên đỉnh" của một biểu diễn cố định được huấn luyện trên nhiệm vụ xuôi dòng. Cụ thể, chúng tôi nghiên cứu thiết lập đơn giản trong đó các đặc trưng trước lớp phân loại cuối cùng của mô hình được huấn luyện trước được trích xuất cho tất cả các mẫu trong tập dữ liệu chuyển giao và được lưu trữ vào bộ nhớ để sử dụng khi huấn luyện bộ phân loại tuyến tính xuôi dòng. Mặc dù phương pháp này thường dẫn đến độ chính xác thấp hơn so với tinh chỉnh đầy đủ [36, 61], nó có những lợi thế thực tiễn đáng kể. Cụ thể, các đặc trưng có thể được tính toán trước, điều này loại bỏ các lượt chuyển tiếp qua mạng được huấn luyện trước. Trong thiết lập này, chúng tôi không áp dụng bất kỳ tăng cường dữ liệu nào trên các mẫu chuyển giao và chúng tôi sử dụng thống kê Chuẩn hóa Batch của mạng được huấn luyện trước trên ImageNet.

Chúng tôi tối ưu hóa bộ phân loại tuyến tính bằng SGD với momentum, weight decay và learning rate annealing, theo [61]. (Kết quả thường có tương quan tốt với những kết quả thu được khi sử dụng tăng cường dữ liệu trong quá trình huấn luyện, hoặc sử dụng các optimizer khác nhau [36]). Trong Mục 3.6, chúng tôi cho thấy rằng tăng tốc huấn luyện cũng có thể được thu được trong thiết lập học trực tuyến, trong đó các mẫu mới được thực thi qua mạng backbone, bằng cách tận dụng độ thưa của backbone.

Kết quả cho tinh chỉnh tuyến tính được hiển thị trong Hình 2, và Bảng C.1 trong Phụ lục. Chúng tôi loại trừ phương pháp LTH-T khỏi phân tích này, vì nó được thiết kế cho tinh chỉnh đầy đủ, và độ chính xác chuyển giao của nó trong tình huống tuyến tính thực sự rất thấp (xem Bảng C.1 trong Phụ lục).

Nhìn chung, kết quả cho thấy rõ ràng rằng việc lựa chọn chiến lược cắt tỉa trên nhiệm vụ nguồn có thể dẫn đến sự khác biệt đáng kể trong hiệu suất trên các nhiệm vụ xuôi dòng. Những khác biệt này rõ ràng hơn đối với các nhiệm vụ xuôi dòng chuyên biệt, với các lớp chi tiết. Ví dụ, xem xét Aircraft, trong đó đối với các mô hình thưa 80% chúng ta thấy khoảng cách 15% trong độ chính xác kiểm tra top-1 giữa các mô hình thưa có hiệu suất tốt nhất (AC/DC và RigL, 55%) và mô hình có hiệu suất kém nhất (WoodFisher, 40%).

Theo quan sát này, chúng tôi nghiên cứu mối tương quan giữa độ khó của nhiệm vụ xuôi dòng và sự gia tăng tương đối trong lỗi cho các chiến lược cắt tỉa khác nhau. Với mục đích này, chúng tôi sử dụng sự khác biệt trong độ chính xác xác thực top-1 giữa tinh chỉnh đầy đủ và tuyến tính trên backbone dày như một proxy cho độ khó của một nhiệm vụ xuôi dòng. Trực quan, một khoảng cách nhỏ giữa tinh chỉnh đầy đủ và tuyến tính sẽ gợi ý rằng các đặc trưng nguồn có thể chuyển giao trực tiếp, và do đó nhiệm vụ xuôi dòng có thể được coi là "dễ". Ngược lại, một khoảng cách lớn sẽ chỉ ra rằng các đặc trưng được huấn luyện trước không đủ để nắm bắt biểu diễn nội tại của dữ liệu, làm cho nhiệm vụ xuôi dòng "khó" hơn. Ngoài ra, chúng tôi phân loại các nhiệm vụ xuôi dòng thành tổng quát (Caltech-101/256, CIFAR-10/100, DTD, SUN397) so với chuyên biệt (Aircraft, Birds, Cars, Flowers, Food-101, Pets); điều này tương tự như nghiên cứu trước đây [36]. Hình 3 gợi ý rằng các tập dữ liệu chuyên biệt có xu hướng có điểm độ khó cao hơn.

Theo định nghĩa và phân loại này, chúng tôi đo, cho mỗi chiến lược cắt tỉa, sự gia tăng lỗi tương đối so với mô hình dày so với độ khó nhiệm vụ. Hình 3 cho thấy hành vi cho tất cả các phương pháp cắt tỉa được xem xét ở độ thưa 80% và 90%. Thú vị là, chúng tôi quan sát một xu hướng đối với các phương pháp chính quy hóa (AC/DC, STR, RigL) cải thiện so với đường cơ sở dày với độ khó nhiệm vụ tăng, rõ ràng hơn ở độ thưa cao hơn (90%). Ngược lại, các phương pháp làm thưa dần dần (GMP, WoodFisher) không cho thấy hành vi tương tự. Điều này gợi ý rằng các phương pháp cắt tỉa chính quy hóa là lựa chọn tốt hơn cho chuyển giao tuyến tính (đôi khi thậm chí vượt qua hiệu suất dày) khi nhiệm vụ xuôi dòng chuyên biệt hơn hoặc khó hơn.

Một đặc thù khác của tinh chỉnh tuyến tính từ các mô hình thưa là mức độ thưa không tương quan cao với hiệu suất trên các nhiệm vụ xuôi dòng. Điều này rõ ràng, ví dụ, đối với AC/DC và RigL, trong đó, mặc dù có khoảng cách 1-2% trong độ chính xác ImageNet giữa các mô hình thưa 80% và 90%, lỗi tương đối so với đường cơ sở dày vẫn khá bằng phẳng. Một xu hướng tương tự có thể được quan sát cho các phương pháp cắt tỉa khác. Tuy nhiên, các mô hình cực kỳ thưa (98%) có xu hướng hoạt động kém hơn, có lẽ do loại bỏ đặc trưng và suy giảm.

Tóm lại, chúng tôi quan sát rằng 1) một số phương pháp làm thưa có thể nhất quán khớp hoặc thậm chí đôi khi vượt trội hơn các mô hình dày; 2) có một mối tương quan giữa hiệu suất chuyển giao cho các phương pháp dựa trên chính quy hóa và độ khó nhiệm vụ xuôi dòng; và 3) độ thưa cao hơn không nhất thiết là một bất lợi cho hiệu suất chuyển giao.

### 3.4. Tinh chỉnh Đầy đủ

Bây giờ chúng tôi xem xét tình huống tinh chỉnh đầy đủ. Ở đây, chúng tôi khởi tạo lại lớp phân loại cuối cùng và cố định nó như dày, sau đó tinh chỉnh các trọng số chưa được cắt tỉa để mạng thưa trong suốt quá trình huấn luyện. Kết quả được tóm tắt trong Hình 2, và chi tiết trong Bảng C.2 trong Phụ lục.

Tương tự như tinh chỉnh tuyến tính, chúng ta thấy sự biến động hiệu suất đáng kể giữa các chiến lược cắt tỉa khi được chuyển giao đến các nhiệm vụ xuôi dòng. Thông thường, các phương pháp làm thưa dần dần (WoodFisher, GMP) có xu hướng chuyển giao tốt hơn so với các phương pháp chính quy hóa và vé số may mắn. Sự khác biệt trong độ chính xác kiểm tra, được đo ở cùng mức độ thưa, thường nhỏ, khoảng 1–3%; ngoại lệ là LTH-T, cạnh tranh ở độ thưa thấp (80%) nhưng gặp phải sự sụt giảm độ chính xác nghiêm trọng ở độ thưa ≥90%.

Trái ngược với tinh chỉnh tuyến tính, chúng ta thấy xu hướng nhất quán của chất lượng giảm với độ thưa tăng. Điều này không đáng ngạc nhiên, vì tinh chỉnh đầy đủ có thể tận dụng các tham số bổ sung có sẵn trong các mô hình dày hơn để phù hợp tốt hơn với dữ liệu xuôi dòng. Tuy nhiên, các phương pháp làm thưa dần dần (GMP và WoodFisher) dẫn đến hiệu suất xuôi dòng gần như ngang bằng với các mô hình dày ở độ thưa 80% và 90%. Các phương pháp này cho thấy hiệu suất tốt hơn so với các phương pháp dựa trên chính quy hóa (AC/DC, STR, và RigL), một sự đảo ngược trực tiếp của kết quả tinh chỉnh tuyến tính.

Đối với các nhiệm vụ xuôi dòng cụ thể, tuy nhiên, có sự biến động đáng kể—trong khi WoodFisher và GMP nhất quán là các mô hình có hiệu suất hàng đầu hoặc gần hàng đầu qua tất cả các nhiệm vụ, các phương pháp khác cho thấy sự phụ thuộc nhiệm vụ đáng kể. Ví dụ, trong khi AC/DC là phương pháp có hiệu suất hàng đầu qua các độ thưa khác nhau cho ba trong mười hai nhiệm vụ (SUN397, Caltech-256, và DTD), nó cho thấy khoảng cách đáng kể so với các phương pháp có hiệu suất tốt nhất trên Aircraft, Cars, và CIFAR-10. Nói chung, STR hoạt động kém hơn trên tinh chỉnh đầy đủ, so với các phương pháp chính quy hóa khác. Hơn nữa, RigL ERK 1× hoạt động khoảng ngang bằng với AC/DC, mặc dù có độ chính xác xác thực thấp hơn trên ImageNet; tuy nhiên, huấn luyện mở rộng của RigL ERK 5× mang lại cho độ chính xác chuyển giao một sự thúc đẩy đáng kể, đưa RigL ERK 5× gần như ngang bằng với WoodFisher, đặc biệt ở độ thưa cao hơn. Phát hiện này mở ra khả năng hấp dẫn rằng huấn luyện mở rộng có thể có lợi cho các phương pháp cắt tỉa trong chế độ tinh chỉnh đầy đủ. Chúng tôi trình bày thêm bằng chứng ủng hộ giả thuyết này trong Phụ lục D; cụ thể, chúng tôi bổ sung cho thấy rằng việc mở rộng thời gian huấn luyện của các mô hình AC/DC nguồn (3× hoặc 5×) cải thiện đáng kể hiệu suất chuyển giao của chúng trên tất cả các nhiệm vụ xuôi dòng. Cuối cùng, LTH-T cho thấy hiệu suất khá cạnh tranh ở độ thưa 80%, nhưng độ chính xác chuyển giao của nó giảm mạnh trên sáu trong mười hai tập dữ liệu (SUN397, Caltech-101, Caltech-256, DTD, Flowers, và Pets) khi độ thưa tăng. Vì mô hình LTH-T chủ yếu dựa vào việc chuyển giao mặt nạ độ thưa qua các nhiệm vụ, điều này gợi ý rằng thông tin bổ sung có trong các trọng số, được tận dụng bởi các phương pháp khác, có thể có lợi.

Tóm lại, nếu mục tiêu là thực hiện tinh chỉnh đầy đủ trên các nhiệm vụ xuôi dòng, thì các phương pháp làm thưa dần dần là lựa chọn tốt. Chúng nhất quán vượt trội hơn các phương pháp chính quy hóa qua một phạm vi rộng các nhiệm vụ, và cung cấp hiệu suất tương đương với backbone dày ở độ thưa 80% và 90%.

### 3.5. Thảo luận

Kết quả của hai phần cuối cho thấy một khoảng cách hiệu suất hấp dẫn giữa các phương pháp cắt tỉa, tùy thuộc vào phương pháp chuyển giao. Điều tra thêm, chúng tôi xem xét cấu trúc thưa của các mô hình đã cắt tỉa kết quả, bằng cách đo phần trăm các bộ lọc tích chập hoàn toàn bị cắt tỉa trong giai đoạn huấn luyện của các backbone ResNet50 thưa trên tập dữ liệu ImageNet ban đầu. Kết quả trong Bảng 4 cho thấy sự khác biệt trong số lượng kênh bị zeroed-out giữa các phương pháp cắt tỉa. Chúng tôi quan sát rằng AC/DC có một số lượng lớn kênh hoàn toàn bị loại bỏ trong quá trình huấn luyện và cắt tỉa ImageNet, trung bình 2-4 kênh nhiều hơn ở độ thưa 80% và 90%, so với các mô hình khác; điều này dẫn đến ít đặc trưng hơn có thể được huấn luyện trong quá trình tinh chỉnh đầy đủ. Ngược lại, độ thưa trong GMP và WoodFisher ít có cấu trúc hơn và do đó có thể biểu diễn các đặc trưng bổ sung, có thể được tận dụng trong quá trình tinh chỉnh. Chúng tôi minh họa thêm hiệu ứng này trong Phụ lục I, nơi chúng tôi tinh chỉnh đầy đủ từ các mô hình có độ thưa có cấu trúc.

Trong trường hợp tinh chỉnh tuyến tính, chúng tôi giả thuyết rằng sự đảo ngược độ chính xác có lợi cho AC/DC có thể được quy cho một hiệu ứng chính quy hóa, tạo ra các đặc trưng "bền vững" hơn. Hiệu ứng tương tự dường như có mặt trong RigL ERK 5× ở độ thưa 95%, cũng có đáng kể nhiều bộ lọc hoàn toàn bị cắt tỉa.

### 3.6. Tăng tốc Huấn luyện bằng Tinh chỉnh Tuyến tính

Một trong những lợi ích chính của các mô hình thưa là chúng có thể cung cấp tăng tốc suy luận khi được thực thi trên các thời gian chạy nhận biết độ thưa [11, 40, 57, 63]. Đối với tinh chỉnh tuyến tính, điều này cũng có thể ngụ ý tăng tốc thời gian huấn luyện, vì backbone thưa cố định, và chỉ được sử dụng cho suy luận. Chúng tôi minh họa điều này trong thiết lập "học trực tuyến", nơi các mẫu huấn luyện đến động tại thiết bị. Đầu tiên chúng tôi tính toán các đặc trưng tương ứng bằng cách sử dụng backbone thưa. Sau đó, chúng tôi sử dụng các đặc trưng này để huấn luyện bộ phân loại tuyến tính. Do đó, lượt chuyển tiến có thể hưởng lợi từ tăng tốc do độ thưa.

Để đo các hiệu ứng này, chúng tôi tích hợp công cụ suy luận CPU nhận biết độ thưa DeepSparse có sẵn miễn phí [9, 40] vào pipeline PyTorch của chúng tôi. Cụ thể, chúng tôi sử dụng suy luận thưa để trích xuất đặc trưng trực tuyến. Chúng tôi báo cáo tăng tốc huấn luyện tổng thể, về thời gian huấn luyện trung bình mỗi epoch trên nhiệm vụ xuôi dòng, chia cho thời gian huấn luyện trung bình sử dụng đường cơ sở dày. Chúng tôi sử dụng batch size 64 và tăng cường dữ liệu; nếu không, các siêu tham số giống hệt với thí nghiệm tinh chỉnh tuyến tính trong Mục 3.3. Chúng tôi thực thi trên CPU Intel E5-1650 với 12 lõi, sẽ tương tự về hiệu suất với CPU laptop gần đây.

Tăng tốc mà chúng tôi báo cáo tỷ lệ thuận với tăng tốc suy luận của các mô hình backbone thưa tương ứng. Sự khác biệt duy nhất là chi phí tối ưu hóa lớp cuối cùng, thay đổi về kích thước với số lượng lớp.

Hình 4 cho thấy kết quả trên bốn nhiệm vụ xuôi dòng, Pets, Flowers, DTD và Caltech-101, trong đó các mô hình backbone ResNet50 có độ thưa 90%. Chúng tôi báo cáo tăng tốc huấn luyện so với sự khác biệt trong độ chính xác xác thực, so với đường cơ sở dày. Hơn nữa, chúng tôi cho thấy số tăng tốc cho các mức độ thưa bổ sung (80% và 95%), trong Bảng 5; các số này đại diện cho thời gian huấn luyện trung bình mỗi epoch được tính toán trên tập dữ liệu Caltech-101, nhưng hệ số tăng tốc nên tương tự cho các tập dữ liệu khác, vì thời gian huấn luyện mỗi batch gần như tỷ lệ thuận với suy luận qua mạng backbone. Kết quả cho thấy rằng sử dụng các backbone thưa có thể giảm thời gian huấn luyện 2-4× cho chuyển giao tuyến tính, mà không có tác động tiêu cực đến độ chính xác xác thực.

## 4. Mở rộng

**Thí nghiệm ResNet18/34 và MobileNet.** Chúng tôi cũng đã thực hiện một tập con các thí nghiệm cho các mô hình ResNet18, ResNet34 và MobileNetV1 [31] được huấn luyện trên ImageNet. Những kết quả này phần lớn xác thực phân tích của chúng tôi ở trên, và do đó được hoãn lại đến Phụ lục E và F. Cụ thể, các phương pháp dựa trên chính quy hóa cũng khớp hoặc vượt trội nhẹ so với các phương pháp dày trên chuyển giao tuyến tính. Tuy nhiên, đối với MobileNetV1, chúng tôi quan sát rằng các mô hình thưa có thể khớp với hiệu suất chuyển giao đường cơ sở dày chỉ ở độ thưa thấp hơn (lên đến 75%), có lẽ do số lượng tham số thấp hơn.

**Thí nghiệm Độ thưa Có cấu trúc.** Chúng tôi cũng thực hiện tinh chỉnh đầy đủ sử dụng các mô hình có độ thưa có cấu trúc, cho cả ResNet50 và MobileNet. Những phát hiện của chúng tôi, được trình bày trong Phụ lục I, cho thấy rằng các mô hình thưa có cấu trúc có xu hướng chuyển giao kém hơn so với các phương pháp không có cấu trúc.

**Chuyển giao Thưa sử dụng YOLO.** Chúng tôi cũng xem xét hiệu suất chuyển giao giữa các mô hình YOLO V3 [59] và YOLO "V5" [64] cho phát hiện đối tượng, được huấn luyện và cắt tỉa trên tập dữ liệu COCO [46], sau đó được chuyển giao đến tập dữ liệu VOC [13] sử dụng tinh chỉnh đầy đủ. Bảng 6 trình bày kết quả về Precision Trung bình (mAP@0.5). Kết quả cho thấy mối tương quan mạnh giữa độ chính xác trên tập dữ liệu COCO ban đầu và trên VOC, xác nhận các tuyên bố của chúng tôi. Chúng tôi quan sát xu hướng tương tự trong thiết lập phân đoạn, mà chúng tôi đề cập trong Phụ lục J.

## 5. Kết luận và Nghiên cứu Tương lai

Chúng tôi đã thực hiện một nghiên cứu sâu về hiệu suất chuyển giao của các mô hình thưa, và cho thấy rằng các phương pháp cắt tỉa có độ chính xác tương tự trên ImageNet có thể có độ chính xác Top-1 khác biệt đáng ngạc nhiên khi được sử dụng cho học chuyển giao. Đặc biệt, các phương pháp dựa trên chính quy hóa hoạt động tốt nhất cho tinh chỉnh tuyến tính; ngược lại, các phương pháp làm thưa dần dần như GMP và WoodFisher có xu hướng hoạt động tốt nhất khi sử dụng tinh chỉnh đầy đủ. Một hạn chế của nghiên cứu chúng tôi là nó chỉ điều tra độ chính xác như một thước đo hiệu suất cho các nhiệm vụ học chuyển giao. Nghiên cứu bổ sung cần thiết hướng tới thiết kế các chiến lược cắt tỉa với hiệu suất tốt qua cả tinh chỉnh tuyến tính và đầy đủ, và hướng tới xem xét các metric vượt qua độ chính xác Top-1, như bias và tính bền vững. Một hạn chế khác là chúng tôi đã xem xét một tập hợp (tiêu chuẩn) cố định các tập dữ liệu chuyển giao; nghiên cứu của chúng tôi nên được mở rộng đến các tình huống học chuyển giao khác, phức tạp hơn, như dịch chuyển phân phối [34]. Điều tra thêm cũng có thể xem xét có hệ thống các loại nén khác, như lượng tử hóa và cắt tỉa có cấu trúc, có thể kết hợp với cắt tỉa không có cấu trúc, là trọng tâm của nghiên cứu hiện tại của chúng tôi. Các lĩnh vực thú vị khác cho nghiên cứu tương lai sẽ là hiểu khoảng cách hiệu suất giữa tinh chỉnh đầy đủ và tinh chỉnh tuyến tính, và thực hiện tăng tốc huấn luyện cho tinh chỉnh đầy đủ thưa, bằng cách tận dụng độ thưa cố định trong mô hình đã huấn luyện.

## Lời cảm ơn

Các tác giả muốn chân thành cảm ơn Christoph Lampert và Nir Shavit cho các cuộc thảo luận có ích trong quá trình phát triển nghiên cứu này, Eldar Kurtic cho hỗ trợ thí nghiệm, Utku Evci cho việc cung cấp các mô hình RigL, và các tác giả của [5] cho việc chia sẻ các mặt nạ LTH-T. EI được hỗ trợ một phần bởi FWF DK VGSCO, thỏa thuận tài trợ số W1260-N35, trong khi AP và DA ghi nhận sự hỗ trợ hào phóng bởi ERC, thông qua Starting Grant 805223 ScaleML.

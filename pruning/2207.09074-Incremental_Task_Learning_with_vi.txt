# Học Tăng Dần Tác Vụ với
Cập Nhật Rank Tăng Dần
Rakib Hyder1, Ken Shao1, Boyu Hou1, Panos Markopoulos2,
Ashley Prater-Bennette3, và M. Salman Asif1
1Đại học California Riverside
2Viện Công nghệ Rochester
3Phòng thí nghiệm Nghiên cứu Không quân

**Tóm tắt.** Học Tăng dần Tác vụ (ITL) là một danh mục của học liên tục nhằm huấn luyện một mạng đơn cho nhiều tác vụ (lần lượt từng tác vụ), trong đó dữ liệu huấn luyện cho mỗi tác vụ chỉ có sẵn trong quá trình huấn luyện tác vụ đó. Mạng nơ-ron có xu hướng quên các tác vụ cũ khi chúng được huấn luyện cho các tác vụ mới hơn; tính chất này thường được gọi là quên lãng thảm khốc. Để giải quyết vấn đề này, các phương pháp ITL sử dụng bộ nhớ tình tiết, điều chuẩn tham số, che phủ và cắt tỉa, hoặc cấu trúc mạng có thể mở rộng. Trong bài báo này, chúng tôi đề xuất một khung học tăng dần tác vụ mới dựa trên phân tích rank thấp. Cụ thể, chúng tôi biểu diễn trọng số mạng cho mỗi lớp như một tổ hợp tuyến tính của nhiều ma trận rank-1. Để cập nhật mạng cho một tác vụ mới, chúng tôi học một ma trận rank-1 (hoặc rank thấp) và thêm nó vào trọng số của mọi lớp. Chúng tôi cũng giới thiệu một vector chọn lọc bổ sung gán các trọng số khác nhau cho các ma trận rank thấp đã học cho các tác vụ trước đó. Chúng tôi chỉ ra rằng phương pháp của chúng tôi hoạt động tốt hơn các phương pháp tiên tiến hiện tại về độ chính xác và quên lãng. Phương pháp của chúng tôi cũng cung cấp hiệu quả bộ nhớ tốt hơn so với các phương pháp dựa trên bộ nhớ tình tiết và mặt nạ. Mã của chúng tôi sẽ có sẵn tại https://github.com/CSIPlab/task-increment-rank-update.git

## 1 Giới thiệu

Mạng nơ-ron sâu đã cực kỳ thành công cho nhiều tác vụ học và biểu diễn khác nhau (ví dụ: phân loại hình ảnh, phát hiện/phân đoạn đối tượng, học tăng cường, mô hình sinh). Một mạng điển hình được huấn luyện để học một hàm ánh xạ đầu vào đến đầu ra mong muốn. Mối quan hệ đầu vào-đầu ra được giả định là cố định và các mẫu dữ liệu đầu vào-đầu ra được lấy từ một phân phối tĩnh [25]. Nếu mối quan hệ đầu vào-đầu ra hoặc phân phối dữ liệu thay đổi, mạng có thể được huấn luyện lại bằng một tập hợp mới các mẫu dữ liệu đầu vào-đầu ra. Vì lưu trữ, tính toán và dung lượng mạng bị hạn chế, chúng ta có thể cần thay thế các mẫu dữ liệu cũ bằng các mẫu mới. Hơn nữa, mối quan tâm về quyền riêng tư cũng có thể buộc các mẫu dữ liệu chỉ có sẵn trong thời gian hạn chế [10,25]. Trong quá trình huấn luyện như vậy, một mạng thường quên các tác vụ đã học trước đó; hiệu ứng này được gọi là quên lãng thảm khốc [21,26].

Học tăng dần tác vụ là một danh mục phụ của các phương pháp học liên tục hoặc học suốt đời nhằm giải quyết vấn đề quên lãng thảm khốc bằng cách thích nghi mạng hoặc quá trình huấn luyện để học các tác vụ mới mà không quên những tác vụ đã học trước đó [23,16,3,2,4,6,28,29,12]. Trong bài báo này, chúng tôi tập trung vào học liên tục tăng dần tác vụ trong đó dữ liệu cho mọi tác vụ được cung cấp theo cách tuần tự để huấn luyện/cập nhật mạng [8]. Đây đã là một thiết lập học liên tục phổ biến ngay cả trong tài liệu rất gần đây [7,14,11,36,31,40].

ITL tìm thấy ứng dụng trong các thiết lập mà task id có sẵn trong quá trình suy luận; ví dụ, các tác vụ được thực hiện dưới các điều kiện thời tiết/ánh sáng/nền khác nhau và chúng ta biết những thay đổi, hoặc các tác vụ được học trên dữ liệu/lớp khác nhau mà chúng ta biết task id.

Hãy ký hiệu hàm mạng ánh xạ đầu vào x đến đầu ra cho tác vụ t là f(x;Wt), trong đó Wt ký hiệu trọng số mạng cho tác vụ t. Chúng ta tìm cách cập nhật Wt cho tất cả t khi chúng ta nhận tuần tự tập dữ liệu cho từng tác vụ một lần. Giả sử tập dữ liệu huấn luyện cho tác vụ t được cho là (Xt, Yt) lấy từ phân phối Pt, trong đó Xt ký hiệu tập hợp các mẫu đầu vào và Yt ký hiệu các đầu ra sự thật tương ứng. Mục tiêu của chúng ta là cập nhật trọng số mạng từ tác vụ trước đó (Wt−1) đến Wt sao cho

y ≈ f(x;Wt), cho tất cả (x, y) ∼ Pt. (1)

Thiết lập ITL ở trên giả định rằng danh tính tác vụ của các mẫu kiểm tra được biết tại thời điểm kiểm tra và trọng số mạng tương ứng được sử dụng cho suy luận. Các phương pháp kiến trúc động có tiềm năng đạt được quên lãng bằng không, sử dụng Wt để kiểm tra dữ liệu cho tác vụ t; tuy nhiên, điều này cũng đòi hỏi lưu trữ Wt cho tất cả các tác vụ. Một trong những đóng góp chính của bài báo này là biểu diễn, học và cập nhật Wt bằng các yếu tố rank thấp sao cho chúng có thể được lưu trữ và áp dụng với chi phí bộ nhớ và tính toán tối thiểu.

Chúng tôi đề xuất một phương pháp mới cho ITL cập nhật trọng số mạng bằng cách sử dụng các gia số rank-1 (hoặc rank thấp) cho mỗi tác vụ mới. Hình 1 cung cấp minh họa về phương pháp đề xuất của chúng tôi. Chúng tôi biểu diễn trọng số mạng cho mỗi lớp như một tổ hợp tuyến tính của nhiều yếu tố rank thấp (có thể được biểu diễn như tích của hai ma trận rank thấp và một ma trận chéo). Để cập nhật mạng cho tác vụ t mà không quên các tác vụ trước đó, chúng tôi đóng băng các yếu tố rank thấp đã học từ các tác vụ trước đó, thêm một yếu tố rank-1 (hoặc rank thấp) có thể huấn luyện mới cho mỗi lớp, và kết hợp với các yếu tố cũ hơn bằng cách sử dụng trọng số chọn lọc có thể học (được hiển thị như một ma trận chéo). Chúng tôi sử dụng cấu hình đa đầu có lớp đầu ra độc lập cho mỗi tác vụ. Vì chúng tôi đang học các ma trận chéo riêng biệt cho mỗi tác vụ, chúng tôi có thể đạt được quên lãng bằng không trong quá trình suy luận.

Chúng tôi trình bày một tập hợp thí nghiệm mở rộng để chứng minh hiệu suất của phương pháp đề xuất cho các tập dữ liệu chuẩn khác nhau. Chúng tôi quan sát thấy phương pháp đề xuất của chúng tôi vượt trội so với các phương pháp tiên tiến hiện tại về độ chính xác với chi phí bộ nhớ nhỏ.

Các đóng góp chính của bài báo này như sau:

1. **Biểu diễn các lớp như ma trận rank thấp**: Chúng tôi biểu diễn và học trọng số mạng cho mỗi lớp như một cấu trúc rank thấp. Chúng tôi chỉ ra rằng cấu trúc rank thấp đủ để biểu diễn tất cả các tác vụ trong thiết lập học liên tục.

2. **Tái sử dụng các yếu tố cũ để có hiệu suất tốt hơn với chi phí bộ nhớ nhỏ**: Chúng tôi giới hạn số lượng tham số cần thiết cho việc cập nhật mạng bằng cách tái sử dụng các yếu tố đã học từ các tác vụ trước đó. Chúng tôi chứng minh rằng một gia số rank-1 đủ để vượt trội so với các kỹ thuật hiện có.

3. **Quên lãng bằng không mà không cần bộ đệm phát lại**: Phương pháp của chúng tôi có quên lãng bằng không được đạt bằng cách sử dụng cập nhật rank tăng dần hoặc trọng số mạng. Ngược lại, hầu hết các kỹ thuật học liên tục hiện có đòi hỏi bộ đệm phát lại hoặc chi phí bộ nhớ lớn để đạt được quên lãng bằng không.

**Hạn chế.** Phương pháp của chúng tôi có cùng hạn chế cố hữu của ITL (tức là yêu cầu task-id trong quá trình suy luận). Ngoài ra, vì chúng tôi sử dụng tất cả các yếu tố đã học trước đó cho suy luận, các tác vụ sau này đòi hỏi nhiều bộ nhớ và tính toán hơn cho suy luận. Tuy nhiên, chúng tôi chỉ ra rằng bằng cách sử dụng cấu trúc rank thấp, tổng yêu cầu bộ nhớ của chúng tôi thấp hơn đáng kể so với một mạng đơn. Hơn nữa, vì chúng tôi học các ma trận chéo riêng biệt cho mỗi tác vụ, chúng tôi có thể duy trì hiệu suất cao ngay cả khi mạng đạt rank đầy đủ với số lượng lớn các tác vụ.

## 2 Nền tảng và Nghiên cứu Liên quan

Học tăng dần tác vụ (ITL) [10,34] nhằm huấn luyện một mô hình đơn trên một chuỗi các tác vụ khác nhau và hoạt động tốt trên tất cả các tác vụ đã huấn luyện khi việc huấn luyện hoàn thành. Trong khi huấn luyện trên các tác vụ mới, dữ liệu cũ từ các tác vụ trước đó sẽ không được cung cấp cho mô hình. Kịch bản này bắt chước quá trình học của con người nơi họ có khả năng thu thập kiến thức và kỹ năng mới trong suốt cuộc đời. Tuy nhiên, thiết lập này vẫn thách thức đối với các mô hình mạng nơ-ron vì một hiện tượng phổ biến gọi là "quên lãng thảm khốc [21]" được quan sát trong quá trình học này. Quên lãng thảm khốc xảy ra khi dữ liệu từ các tác vụ mới can thiệp vào dữ liệu đã thấy trong các tác vụ trước đó và do đó làm suy giảm hiệu suất mô hình trên các tác vụ trước đó. Để khắc phục vấn đề này, các phương pháp khác nhau đã được đề xuất cho đến nay có thể được chia thành ba danh mục chính: phương pháp dựa trên điều chuẩn, phương pháp dựa trên bộ nhớ và phát lại, và phương pháp dựa trên kiến trúc mạng động. Một số phương pháp này được thiết kế đặc biệt cho ITL trong khi những phương pháp khác được thiết kế cho thiết lập học liên tục tổng quát hơn.

**Phương pháp dựa trên điều chuẩn** [15,23,16] cập nhật toàn bộ mô hình trong mỗi tác vụ nhưng một thuật ngữ điều chuẩn ℓreg được thêm vào tổng mất mát L = ℓcurrent + λℓreg để phạt các thay đổi trong các tham số quan trọng đối với các tác vụ trước đó do đó bảo tồn hiệu suất trên các tác vụ đã học trước đó. Ví dụ, Elastic Weight Consolidation (EWC) [15] ước lượng tầm quan trọng của các tham số bằng ma trận Fisher Information; Variational Continual Learning (VCL) [23] xấp xỉ phân phối posterior của các tham số bằng suy luận biến phân; Learning without Forgetting (LwF) [16] điều chuẩn mất mát hiện tại với các mục tiêu mềm lấy từ các tác vụ trước đó bằng chưng cất kiến thức [13]. GCL [5] kết hợp luyện tập với chưng cất kiến thức và điều chuẩn để giảm thiểu quên lãng thảm khốc. Một số phương pháp được đề xuất gần đây buộc các cập nhật trọng số thuộc về không gian rỗng của hiệp phương sai đặc trưng [37,35].

**Phương pháp dựa trên bộ nhớ** [27,28,8,9,35] thường sử dụng cơ chế bộ nhớ và phát lại/luyện tập để nhớ lại một bộ nhớ tình tiết nhỏ của các tác vụ trước đó trong khi huấn luyện các tác vụ mới do đó giảm mất mát trong các tác vụ trước đó. Ví dụ, iCaRL [27] là phương pháp phát lại đầu tiên, học theo cách tăng dần lớp bằng cách chọn và lưu trữ các mẫu điển hình gần nhất với trung bình đặc trưng của mỗi lớp; Meta-Experience Replay (MER) [28] kết hợp phát lại kinh nghiệm với meta-learning dựa trên tối ưu hóa để tối ưu hóa sự đánh đổi đối xứng giữa chuyển giao và can thiệp bằng cách thực thi căn chỉnh gradient qua các ví dụ; AGEM [8] chiếu gradient trên minibatch hiện tại bằng cách sử dụng bộ nhớ tình tiết ngoài của các mẫu từ kinh nghiệm trước đó như một ràng buộc tối ưu hóa; ER-Ring [9] huấn luyện chung dữ liệu tác vụ mới với dữ liệu của các tác vụ trước đó.

**Kiến trúc mạng động** [30,19,39,38,33,7,41] cố gắng thêm các nơ-ron mới vào mô hình tại các tác vụ bổ sung mới, do đó hiệu suất trên các tác vụ trước đó được bảo tồn bằng cách đóng băng các tham số cũ và chỉ cập nhật các tham số mới được thêm vào. Ví dụ, Progressive neural networks (PNNs) [30] tận dụng kiến thức trước đó thông qua các kết nối ngang đến các đặc trưng đã học trước đó; PackNet [19] lặp đi lặp lại gán các tập con tham số cho các tác vụ liên tiếp bằng cách tạo thành các mặt nạ nhị phân. SupSup [39] cũng tìm mặt nạ để gán các tập con khác nhau của trọng số cho các tác vụ khác nhau. BatchEnsemble [38] học trên các ma trận tỷ lệ rank-1 riêng biệt cho mỗi tác vụ sau đó được sử dụng để tỷ lệ trọng số của mạng được chia sẻ. HAT [33] kết hợp các embedding cụ thể tác vụ cho mặt nạ attention. [24] cũng đề xuất hypernetworks có điều kiện tác vụ cho học liên tục. [20] đề xuất các tập hợp đơn vị không chồng chéo hoạt động cho mỗi tác vụ. Piggyback [18] học các mặt nạ nhị phân trên một mạng hiện có để cung cấp hiệu suất tốt trên các tác vụ mới. [1] đề xuất lựa chọn bộ lọc tích chập cụ thể tác vụ cho học liên tục. Các phương pháp dựa trên mặt nạ được liệt kê ở trên cung cấp kết quả xuất sắc cho học liên tục, nhưng chúng đòi hỏi một số lượng tham số lớn đáng kể để biểu diễn các mặt nạ cho mỗi tác vụ. Một phương pháp dựa trên phân tích nhân tử được đề xuất trong [22] thực hiện lựa chọn rank tự động cho mỗi tác vụ cho suy luận biến phân bằng quá trình Indian Buffet. Phương pháp đòi hỏi các gia số rank lớn đáng kể cho mỗi tác vụ để đạt độ chính xác cao; ngược lại, phương pháp của chúng tôi sử dụng phương pháp dựa trên học để tìm các gia số rank-1 và tái sử dụng các yếu tố cũ với trọng số chọn lọc đã học. ORTHOG-SUBSPACE [7] học các tác vụ trong các không gian con vector (rank thấp) khác nhau được giữ trực giao với nhau để tối thiểu hóa can thiệp.

Phương pháp đề xuất của chúng tôi thuộc danh mục phương pháp kiến trúc mạng động. Lưu ý rằng chúng ta có thể biểu diễn một ma trận trọng số rank thấp bằng hai lớp kết nối đầy đủ nhỏ hơn và tăng rank của ma trận trọng số tương đương với việc thêm các nút mới trong hai lớp kết nối đầy đủ nhỏ hơn.

## 3 Học Tăng dần Tác vụ thông qua Gia số Rank

Chúng tôi tập trung vào thiết lập học tăng dần tác vụ trong đó chúng ta tìm cách huấn luyện một mạng cho T tác vụ. Sự khác biệt chính giữa học tăng dần tác vụ và học thông thường là dữ liệu huấn luyện cho mỗi tác vụ chỉ có sẵn trong khi huấn luyện mạng cho tác vụ đó. Thách thức chính trong học tăng dần tác vụ là không quên các tác vụ trước đó khi chúng ta học các tác vụ mới. Học mỗi tác vụ đòi hỏi huấn luyện trọng số cho mạng để học mối quan hệ đầu vào-đầu ra cụ thể tác vụ bằng dữ liệu huấn luyện cụ thể tác vụ.

Chúng ta tìm cách phát triển một khung ITL trong đó chúng ta biểu diễn trọng số của bất kỳ lớp nào bằng một số lượng nhỏ các yếu tố rank thấp. Chúng ta khởi tạo mạng với kiến trúc cơ sở trong đó trọng số cho mỗi lớp có thể được biểu diễn bằng một ma trận rank thấp. Sau đó chúng ta thêm các yếu tố rank thấp mới vào mỗi lớp khi chúng ta học các tác vụ mới.

Hãy giả sử mạng có K lớp và trọng số cho lớp thứ k và tác vụ t có thể được biểu diễn là Wk,t. Hãy giả sử thêm rằng trọng số cho lớp thứ k và tác vụ t = 1 có thể được biểu diễn như một ma trận rank thấp

Wk,1 = Uk,1Sk,1,1V⊤k,1, (2)

trong đó Uk,1, Vk,1 biểu diễn hai ma trận rank thấp và Sk,1,1 biểu diễn một ma trận chéo. Để học mạng cho tác vụ 1, chúng ta học Uk,1, Vk,1, Sk,1,1 cho tất cả k. Cho tác vụ 2, chúng ta biểu diễn trọng số cho lớp thứ k là

Wk,2 = Uk,1Sk,1,2V⊤k,1 + Uk,2Sk,2,2V⊤k,2.

Uk,1, Vk,1 biểu diễn hai ma trận rank thấp đã học cho tác vụ 1 và được đóng băng sau đó. Uk,2, Vk,2 biểu diễn hai ma trận rank thấp được thêm vào để cập nhật trọng số, và chúng sẽ được học cho tác vụ 2. Sk,1,2, Sk,2,2 biểu diễn các ma trận chéo, sẽ được học cho tác vụ 2. Chúng ta học Sk,1,2, là một ma trận chéo gán trọng số cho các yếu tố tương ứng với tác vụ 1, để bao gồm/loại trừ hoặc ưu tiên/triệt tiêu các yếu tố đóng băng từ các tác vụ trước đó cho các tác vụ mới. Chúng ta có thể biểu diễn trọng số cho lớp thứ k và tác vụ t là

Wlayer,task = Wk,t = ∑i≤t Uk,iSk,i,tV⊤k,i
= ∑i<t Uk,i|{z}frozen Sk,i,tV⊤k,i|{z}frozen + Uk,tSk,t,tV⊤k,t, (3)

trong đó Uk,i, Vk,i được đóng băng cho tất cả i < t và Uk,t, Vk,t và tất cả Sk,i,t được học cho tác vụ t. Toàn bộ mạng cho tác vụ t có thể được biểu diễn là Wt = {Uk,i, Sk,i,t, Vk,i}i≤t. Để cập nhật các tham số mạng có thể huấn luyện cho tác vụ t, chúng ta giải quyết bài toán tối ưu hóa sau:

min Uk,t,Sk,i,t,Vk,t ∑(x,y)∈(Xt,Yt) loss(f(x;Wt[Uk,t, Sk,i,t, Vk,t]), y)

cho tất cả k ≤ K và i ≤ t, (4)

trong đó chúng ta sử dụng loss(·,·) để ký hiệu hàm mất mát và Wt[Uk,t, Sk,i,t, Vk,t] để chỉ ra các tham số có thể huấn luyện trong Wt, trong khi phần còn lại được đóng băng. Chúng ta đôi khi gọi Sk,i,t là ma trận/vector trọng số chọn lọc để chỉ ra rằng các phần tử chéo của nó xác định đóng góp của mỗi yếu tố đối với mỗi trọng số tác vụ/lớp.

Thuật toán ITL đề xuất của chúng tôi hoạt động như sau. Chúng tôi huấn luyện các yếu tố rank thấp cho tác vụ được cho bằng các mẫu huấn luyện tương ứng. Sau đó chúng tôi đóng băng các yếu tố tương ứng với các tác vụ cũ hơn và chỉ cập nhật các yếu tố mới và các ma trận chéo. Theo cách này, tổng số tham số chúng tôi thêm vào mô hình tỷ lệ tuyến tính với rank của các yếu tố mới. Để giữ độ phức tạp mạng nhỏ, chúng ta tìm cách đạt độ chính xác tốt bằng cách sử dụng rank nhỏ cho mỗi cập nhật tác vụ và lớp. Chúng tôi tóm tắt phương pháp của mình trong Thuật toán 1 và 2.

Lưu ý rằng chúng ta không cần tạo ma trận trọng số Wk,t cho bất kỳ lớp nào một cách rõ ràng vì chúng ta có thể tính toán tất cả các bước trong lan truyền tiến và lan truyền ngược một cách hiệu quả bằng dạng phân tích nhân tử của mỗi lớp. Kích thước của mỗi lớp được xác định bởi lựa chọn kiến trúc mạng. Rank của mỗi lớp cho mỗi tác vụ là một siêu tham số mà chúng ta có thể chọn theo các tác vụ trong tay. Để giữ chi phí bộ nhớ nhỏ, chúng ta cần sử dụng các giá trị nhỏ cho gia số rank.

Hãy ký hiệu rank cho Uk,t là rk,t, biểu diễn rank gia số cho lớp thứ k và tác vụ t. Tại thời điểm kiểm tra, chúng ta có thể sử dụng số lượng yếu tố phù hợp tùy thuộc vào tác vụ. Ví dụ, nếu chúng ta muốn dự đoán đầu ra cho tác vụ 1 thì chúng ta sử dụng rk,1 yếu tố đầu tiên và cho tác vụ 2 chúng ta sử dụng rk,1 + rk,2 yếu tố. Chúng ta có thể thêm các yếu tố mới theo cách tăng dần khi chúng ta thêm các tác vụ mới trong thiết lập ITL. Trong trường hợp cực đoan của các gia số rank-1, rk,t = 1. Trong các thí nghiệm của chúng tôi, chúng tôi quan sát thấy các cập nhật rank-1 cạnh tranh hoặc vượt quá hiệu suất của các phương pháp ITL hiện có (xem Bảng 1) và hiệu suất của phương pháp chúng tôi cải thiện thêm khi chúng tôi tăng rank (xem Bảng 5). Bất kỳ gia tăng nào trong rank đều phải trả giá bằng chi phí bộ nhớ tăng.

### Thuật toán 1 ITL với các gia số rank-1 (Huấn luyện)
**Đầu vào:** Dữ liệu (X1 và Y1) cho tác vụ thứ 1.
Đặt rank ban đầu, r1.
Khởi tạo các yếu tố trọng số Uk,1, Vk,1 ngẫu nhiên và Sk,1,1 như ma trận đơn vị.
Học Uk,1, Vk,1 và Sk,1,1. ▷ Tối ưu hóa trong (4)
**for** t = 2, 3, ..., T **do**
    **Đầu vào:** Dữ liệu huấn luyện (Xt và Yt) cho tác vụ thứ t.
    Khởi tạo các yếu tố cập nhật rank thấp Uk,t, Vk,t.
    Đóng băng các yếu tố trước đó {Uk,i, Vk,i}i<t.
    Khởi tạo các phần tử chéo của {Sk,i,t} là 1 cho i = t và 0 cho i < t.
    Học Uk,t, Vk,t và Sk,i,t cho i < t. ▷ Tối ưu hóa trong (4)
**end for**

### Thuật toán 2 ITL với các gia số rank-1 (Suy luận)
**Đầu vào:** Dữ liệu kiểm tra x với danh tính tác vụ t.
Lấy trọng số đã huấn luyện: Wt = {Uk,i, Vk,i, Sk,i,t} cho tất cả k và i ≤ t.
**Đầu ra:** Tính đầu ra mạng là f(x, Wt).

## 4 Thí nghiệm và Kết quả

Chúng tôi đã sử dụng các tác vụ phân loại khác nhau trên các chuẩn mực học liên tục nổi tiếng để chỉ ra tầm quan trọng của phương pháp đề xuất.

### 4.1 Tập dữ liệu và Mô tả Tác vụ

Các thí nghiệm được tiến hành trên bốn tập dữ liệu: Split CIFAR100, Permuted MNIST, Rotated MNIST, và Split MiniImageNet.

**P-MNIST** tạo các tác vụ mới bằng cách áp dụng một hoán vị ngẫu nhiên nhất định lên các pixel của tất cả hình ảnh trong tập dữ liệu gốc. Trong thí nghiệm của chúng tôi, chúng tôi tạo 20 tác vụ khác nhau, mỗi tác vụ tương ứng với một hoán vị nhất định nhưng khác nhau.

**R-MNIST** tương tự như Permuted MNIST, nhưng thay vì áp dụng một hoán vị ngẫu nhiên nhất định lên các pixel, nó áp dụng một phép quay ngẫu nhiên nhất định lên các hình ảnh trong cùng tác vụ. Chúng tôi tạo 20 tác vụ khác nhau, mỗi tác vụ tương ứng với một phiên bản quay nhất định nhưng khác nhau từ khoảng [0, 180] độ.

**S-CIFAR100** chia tập dữ liệu CIFAR-100 gốc thành 20 tập hợp rời rạc, mỗi tập chứa 5 lớp, được coi là một tác vụ riêng biệt. 5 lớp trong mỗi tác vụ được chọn ngẫu nhiên không thay thế từ tổng số 100 lớp.

**S-miniImageNet** chia một tập con của tập dữ liệu Imagenet thành 20 tập hợp rời rạc, mỗi tập chứa 5 lớp, được coi là một tác vụ riêng biệt. 5 lớp trong mỗi tác vụ được chọn ngẫu nhiên không thay thế từ tổng số 100 lớp.

### 4.2 Chi tiết Huấn luyện

**Mạng.** Trong tập hợp thí nghiệm đầu tiên, chúng tôi sử dụng một perceptron đa lớp (MLP) ba lớp (kết nối đầy đủ) với các lớp ẩn 256 nút, tương tự như mạng trong [7]. Chúng tôi làm phẳng hình ảnh đầu vào đa chiều thành một vector đầu vào 1D. Chúng tôi sử dụng kích hoạt ReLU cho tất cả các lớp trừ lớp cuối cùng. Chúng tôi sử dụng Softmax cho các tác vụ phân loại đa lớp. Chúng tôi sử dụng cùng một mạng cho tất cả các tác vụ với các sửa đổi cần thiết cho kích thước đầu vào và đầu ra. Phương pháp của chúng tôi cũng có thể được sử dụng trong các mạng tích chập. Chúng tôi báo cáo kết quả sử dụng ResNet18 với phương pháp của chúng tôi trên tập dữ liệu S-CIFAR100 và S-miniImageNet trong Bảng 6.

**Phân tích nhân tử và lựa chọn rank.** Chúng tôi sử dụng phân tích nhân tử ma trận được định nghĩa trong (3) trong tất cả các thí nghiệm. Chúng tôi chọn rank cho tác vụ đầu tiên, rk,1 là 11 dựa trên thực nghiệm trên một tác vụ Rotated MNIST mẫu và giữ cùng giá trị cho tất cả các thí nghiệm. Sau đó chúng tôi thực hiện gia số rank-1 (rk,t) cho mỗi tác vụ bổ sung. Chúng tôi muốn chỉ ra rằng AGEM và Orthog Subspace sử dụng 3 tác vụ đầu tiên để điều chỉnh siêu tham số. Chúng tôi không điều chỉnh siêu tham số của mình trên dữ liệu kiểm tra, thay vào đó chúng tôi chọn các tham số cung cấp hội tụ tốt hơn trong quá trình huấn luyện. Chúng tôi gia tăng các ma trận trọng số bằng rank-1 cho mỗi tác vụ; do đó, tốc độ học và số epoch là các siêu tham số duy nhất trong các thí nghiệm của chúng tôi.

**Tối ưu hóa.** Chúng tôi sử dụng khởi tạo trực giao cho các yếu tố rank thấp, như mô tả trong [32]. Chúng tôi sử dụng khởi tạo tất cả một cho các yếu tố bổ sung của các ma trận chọn lọc Sk,t,t. Chúng tôi sử dụng tối ưu hóa Adam để cập nhật các yếu tố. Chúng tôi sử dụng kích thước batch 128 cho mỗi tác vụ.

**Các chỉ số hiệu suất.** Chúng tôi sử dụng độ chính xác và quên lãng cho mỗi tác vụ, là hai chỉ số thường được sử dụng trong tài liệu học liên tục [6,7], để đánh giá hiệu suất của các phương pháp được mô tả. Hãy at,j là độ chính xác kiểm tra của tác vụ j < t sau khi mô hình đã hoàn thành việc học tác vụ t ∈ {1, ..., T} theo cách tăng dần. Độ chính xác trung bình At sau khi mô hình đã học tác vụ t được định nghĩa là At = 1/t ∑t j=1 at,j. Mặt khác, quên lãng là sự giảm độ chính xác của một tác vụ sau khi huấn luyện của nó, và sau khi một hoặc nhiều tác vụ được học tăng dần. Chúng tôi định nghĩa quên lãng trung bình Ft là Ft = 1/(t-1) ∑t-1 j=1 (aj,j - at,j).

Trong Hình 2, chúng tôi hiển thị sự tiến triển của độ chính xác trung bình At khi t tăng. Chúng tôi cũng hiển thị sự tiến triển của độ chính xác theo tác vụ at,j trong Hình 3, trong đó cường độ pixel (t, j) phản ánh at,j. Chúng tôi báo cáo độ chính xác trung bình AT, độ chính xác trung bình sau khi mô hình đã học mọi tác vụ tăng dần, trong Bảng 1. Chúng tôi báo cáo quên lãng FT sau khi mô hình đã học tất cả các tác vụ tăng dần trong Bảng 2. Lưu ý rằng phương pháp của chúng tôi thực hiện học tăng dần tác vụ mà không quên lãng.

### 4.3 So sánh Các Kỹ thuật

Chúng tôi so sánh phương pháp của mình với các phương pháp ITL tiên tiến khác nhau. EWC [15] là một phương pháp dựa trên điều chuẩn sử dụng ma trận Fisher Information để ước lượng posterior của các tác vụ trước đó để bảo tồn các tham số quan trọng. ICARL [27] là một phương pháp dựa trên bộ nhớ sử dụng các mẫu điển hình và chưng cất kiến thức [13] để giữ lại kiến thức trước đó. AGEM [8] là một phương pháp dựa trên bộ nhớ được xây dựng dựa trên [17] sử dụng bộ nhớ tình tiết để giải quyết bài toán tối ưu hóa có ràng buộc. ER-Ring [9] là một phương pháp dựa trên bộ nhớ khác huấn luyện chung trên dữ liệu tác vụ mới với dữ liệu của các tác vụ trước đó. Orth. sub. [7] học các tác vụ trong các không gian con vector (rank thấp) khác nhau được giữ trực giao với nhau để tối thiểu hóa can thiệp. Ngoài các phương pháp được đề cập ở trên, chúng tôi so sánh với các phương pháp dựa trên mặt nạ mà, giống như phương pháp của chúng tôi, cũng thuộc danh mục kiến trúc động. HAT [33] kết hợp các embedding cụ thể tác vụ cho mặt nạ attention. PackNet [19] lặp đi lặp lại gán các tập con của một mặt nạ nhị phân đơn cho mỗi tác vụ. Các phương pháp dựa trên mặt nạ sử dụng sự dư thừa của các tham số mạng để biểu diễn các tác vụ khác nhau với các phiên bản che phủ khác nhau của cùng trọng số mạng. Chúng tôi cũng trình bày so sánh với một số phương pháp gần đây: IBP-WF [22] và Adam-NSCL [37], về độ chính xác trung bình cho một thí nghiệm trên hai tập dữ liệu.

Ngoài ra, chúng tôi báo cáo kết quả cho hai phương pháp cơ sở không liên tục: **Học song song** và **Học đa tác vụ**. **Học song song** huấn luyện các mạng rank thấp độc lập (nhỏ hơn) cùng kích thước cho mỗi tác vụ. Chúng tôi báo cáo kết quả cho ba mạng như vậy. Parallel 2 sử dụng các lớp rank-2, Parallel 4 sử dụng các lớp rank-4, và Parallel full sử dụng MLP rank đầy đủ. Parallel 2 đòi hỏi xấp xỉ cùng số lượng tham số như mạng ITL rank-1 mà chúng tôi sử dụng trong các thí nghiệm; Parallel 4 cung cấp dung lượng mạng cao hơn, trong khi đòi hỏi ít tham số hơn so với mạng rank đầy đủ. Chúng ta có thể coi hiệu suất của phương pháp Parallel full như giới hạn trên mà chúng ta có thể đạt được bằng các phương pháp ITL. Cuối cùng, **Học đa tác vụ** đã được sử dụng như một cơ sở trong [7,8]. Trong học đa tác vụ, chúng ta có quyền truy cập vào tất cả dữ liệu để tối ưu hóa một mạng đơn.

### 4.4 Kết quả với MLP Ba lớp

**Hiệu suất phân loại và so sánh.** Chúng tôi báo cáo kết quả phân loại cho các tác vụ P-MNIST, R-MNIST, S-CIFAR100, và S-miniImageNet trong Bảng 1. Chúng tôi cũng hiển thị kết quả cho các kỹ thuật so sánh. Chúng tôi quan sát thấy phương pháp của chúng tôi với cập nhật rank-1 hoạt động tốt hơn tất cả các phương pháp so sánh (EWC, ICARL, AGEM, HAT, PackNet, Orthog Subspace) trên các tác vụ R-MNIST, S-CIFAR100 và S-miniImageNet sử dụng số lượng tham số ít hơn đáng kể. Phương pháp của chúng tôi hoạt động gần với Orthog Subspace trên các tác vụ P-MNIST.

Chúng tôi cũng quan sát thấy cập nhật rank-1 đề xuất vượt trội so với cơ sở Parallel 2 không liên tục có số lượng tham số tương tự so với phương pháp của chúng tôi. Chúng tôi hoạt động tương tự như cơ sở Parallel 4 sử dụng gần gấp đôi số lượng tham số so với phương pháp của chúng tôi. Parallel full hoạt động như giới hạn trên với cấu trúc mạng mà chúng tôi lựa chọn vì nó huấn luyện các mạng rank đầy đủ độc lập cho mỗi tác vụ. Học đa tác vụ là một cơ sở không liên tục khác sử dụng tất cả dữ liệu từ tất cả các tác vụ đồng thời. Bảng 1 gợi ý rằng phương pháp ITL của chúng tôi có thể học các tác vụ phức tạp như phân loại CIFAR100 và miniImageNet với MLP ba lớp, trong khi học đa tác vụ (đang giải quyết bài toán phân loại 100 lớp) thất bại với mạng đơn giản như vậy. Chúng tôi cũng đã thử nghiệm mạng Resnet18, có số lượng tham số lớn hơn đáng kể so với mạng được sử dụng trong Bảng 1. Kết quả cho Resnet18 được trình bày trong Bảng 6.

Chúng tôi trình bày hiệu suất kiểm tra theo tác vụ cho một số phương pháp so sánh trên các tập dữ liệu P-MNIST, R-MNIST, S-CIFAR100 và S-miniImageNet trong Hình 2. Chúng tôi quan sát thấy khi chúng ta huấn luyện các tác vụ mới, hiệu suất theo tác vụ giảm cho các phương pháp so sánh, đặc biệt là cho P-MNIST và R-MNIST.

ICARL và AGEM đòi hỏi bộ đệm phát lại (bộ nhớ tình tiết) cho mỗi tác vụ. Mặc dù Orthog Subspace không sử dụng bộ đệm phát lại cho các thí nghiệm MNIST, nó đòi hỏi bộ đệm phát lại trong thuật toán của họ và đã sử dụng nó cho các thí nghiệm S-CIFAR100 và S-miniImageNet. EWC không đòi hỏi bất kỳ bộ đệm phát lại nào, nhưng nó chịu quên lãng cao như được hiển thị trong Hình 3. Phương pháp đề xuất của chúng tôi không đòi hỏi bộ đệm phát lại, và nó vượt trội so với các phương pháp khác trong Bảng 1.

**Độ chính xác so với quên lãng.** Chúng tôi báo cáo quên lãng trung bình của các phương pháp so sánh khác nhau trong Bảng 2. Phương pháp của chúng tôi, các phương pháp dựa trên mặt nạ (HAT và PackNet) và các cơ sở song song có quên lãng bằng không, trong khi tất cả các phương pháp so sánh khác thể hiện một mức độ quên lãng nào đó. Để chứng minh quên lãng tốt hơn, trong Hình 3, chúng tôi hiển thị độ chính xác cho các tác vụ dọc theo toàn bộ quy trình huấn luyện. Hàng thứ i (từ trên xuống dưới) của biểu đồ biểu thị hiệu suất của i tác vụ trên các tập kiểm tra khi chúng ta huấn luyện tác vụ thứ i. Như mong đợi, chúng ta có thể quan sát thấy hiệu suất huấn luyện cho các tác vụ đã học trước đó thường giảm với việc huấn luyện dần dần các tác vụ tiếp theo đặc biệt là cho phương pháp dựa trên điều chuẩn, EWC. Tuy nhiên, thuật toán của chúng tôi duy trì cùng hiệu suất cho các tác vụ trong quá khứ vì chúng tôi không thay đổi bất kỳ yếu tố đã học trước đó nào. Ngay cả phương pháp không gian con trực giao cũng quan sát quên lãng như vậy qua một số tác vụ.

**Độ phức tạp bộ nhớ.** Phương pháp của chúng tôi gia tăng rank của mỗi lớp cho mỗi tác vụ; do đó, chúng tôi so sánh tổng số tham số trong mạng được huấn luyện tăng dần và các cơ sở Parallel. Lưu ý rằng nếu số lượng tham số trong hai phương pháp giống nhau, chúng ta có thể huấn luyện một mạng nhỏ cho mỗi tác vụ độc lập. Chúng tôi báo cáo tổng số tham số và kích thước bộ đệm phát lại cho các phương pháp khác nhau trong Bảng 3. Vì chúng tôi sử dụng cấu trúc mạng kết nối đầy đủ tương tự cho tất cả các tác vụ, chúng tôi báo cáo kết quả cho các thí nghiệm Split CIFAR100. Mặc dù chúng tôi tăng rank cho mỗi tác vụ, gia số đủ nhỏ để ngay cả sau 20 tác vụ, tổng số tham số của chúng tôi vẫn nhỏ hơn tất cả các phương pháp khác.

Chúng tôi cũng báo cáo số lượng tham số được sử dụng bởi các thuật toán quên lãng bằng không dựa trên mặt nạ (HAT và PackNet) để học 20 tác vụ khác nhau trên các tập dữ liệu khác nhau trong Bảng 4. Chúng ta có thể quan sát thấy phương pháp của chúng tôi vượt trội so với HAT và PackNet cho R-MNIST, S-CIAR100 và S-miniImageNet với số lượng tham số nhỏ hơn đáng kể. Mặc dù tất cả các phương pháp sử dụng cùng mạng, phương pháp của chúng tôi sử dụng các yếu tố rank-1 đòi hỏi số lượng tham số nhỏ hơn đáng kể cho học tăng dần các tác vụ. Lưu ý rằng các thí nghiệm P-MNIST và R-MNIST đòi hỏi cùng số lượng tham số.

**Ảnh hưởng của rank.** Trong Bảng 5, chúng tôi đánh giá ảnh hưởng của lựa chọn rank khác nhau cho các tập dữ liệu MNIST khác nhau bằng phương pháp ITL của chúng tôi. Chúng tôi đã thử nghiệm rank ban đầu (rank cho tác vụ đầu tiên) là 1, 6, và 11, giữ gia số rank là 1. Chúng tôi quan sát thấy độ chính xác tăng khi rank ban đầu tăng, và chúng tôi đạt gần 90% độ chính xác với rank ban đầu là 11. Chúng tôi cũng đã thử nghiệm các giá trị khác nhau của gia số rank cho mỗi tác vụ và quan sát thấy độ chính xác tăng với gia số rank lớn hơn. Tuy nhiên, gia số rank-1 cung cấp cho chúng tôi hiệu suất có thể so sánh hoặc tốt hơn các kỹ thuật so sánh như được hiển thị trong Bảng 1.

### 4.5 Kết quả với ResNet18

Phương pháp gia số rank thấp đề xuất có thể được tổng quát hóa cho các loại mạng và lớp khác. Ví dụ, các kernel tích chập có tensor trọng số bốn chiều trái ngược với ma trận trọng số hai chiều của các lớp kết nối đầy đủ. Chúng thường được hình thức hóa như một tensor của kênh đầu ra và đầu vào (Cout, Cin), và hai chiều của các bộ lọc tích chập (H, W). Chúng tôi định hình lại các tensor trọng số tích chập thành ma trận có kích thước Cout × CinHW và thực hiện các cập nhật rank thấp tương tự cho mỗi tác vụ như chúng tôi đã mô tả cho MLP trong bài báo chính. Chúng tôi báo cáo kết quả cho các tập dữ liệu S-CIFAR-100 và S-miniImageNet với kiến trúc Resnet18. Cho mỗi lớp tích chập, chúng tôi định hình lại và phân tách các tensor trọng số tích chập thành các yếu tố rank thấp giống nhau được mô tả trong (3) và thực hiện các cập nhật rank thấp cho mỗi tác vụ.

Chúng tôi báo cáo kết quả trong Bảng 6. Đối với hầu hết các kỹ thuật so sánh, kết quả từ [7] được báo cáo vì chúng tôi sử dụng cùng kiến trúc và tập dữ liệu. Đối với các so sánh thiếu, chúng tôi đã huấn luyện các mô hình bằng cách sử dụng cùng quy trình như được nêu trong [7].

Thay vì sử dụng giá trị cố định cho rank tại mỗi lớp như chúng tôi đã làm trong thiết lập MLP, chúng tôi sử dụng kích thước rank tỷ lệ thuận với kích thước của Cout,i tại lớp tích chập thứ i vì trọng số cho các lớp khác nhau của ResNet18 có kích thước khác nhau. Chúng tôi chọn rank ban đầu = 0.1Cout,i cho tác vụ đầu tiên và rank gia số = 0.02Cout,i cho các tác vụ gia số tiếp theo.

Kết quả trong Bảng 6 cho thấy hiệu suất của mỗi phương pháp cải thiện với cấu trúc ResNet18 tích chập so với MLP 3 lớp. Tuy nhiên, phương pháp của chúng tôi vượt trội so với các phương pháp so sánh cho cả hai tập dữ liệu. Adam-NSCL [37] có kết quả tốt hơn trên CIFAR100, nhưng nó đòi hỏi 11.21M tham số (so với 1.33M tham số được yêu cầu bởi phương pháp của chúng tôi).

**Ảnh hưởng của việc cập nhật vài lớp cuối.** Chúng tôi đã thực hiện một thí nghiệm trên S-CIFAR-100 nơi chúng tôi phân tích nhân tử L lớp cuối của kiến trúc ResNet18 giữ phần còn lại của mạng cố định tại trọng số đã huấn luyện trên Tác vụ 1. Cập nhật L = {1,2,3,4,5} lớp cuối cung cấp độ chính xác trung bình {34.38,34.99,53.41,57.08,65.03}, tương ứng. Kết quả này gợi ý rằng việc cập nhật vài lớp cuối có thể đủ vì các lớp ban đầu chỉ đơn thuần hoạt động như một bộ trích xuất đặc trưng.

## 5 Kết luận

Chúng tôi đã đề xuất một phương pháp học tăng dần tác vụ mới trong đó chúng tôi cập nhật trọng số mạng bằng các gia số rank thấp khi chúng tôi học các tác vụ mới. Các lớp mạng được biểu diễn như một tổ hợp tuyến tính của các yếu tố rank thấp. Để cập nhật mạng cho một tác vụ mới, chúng tôi đóng băng các yếu tố đã học cho các tác vụ trước đó, thêm một yếu tố rank thấp mới (hoặc rank-1), và kết hợp với các yếu tố trước đó bằng một tổ hợp đã học. Phương pháp đề xuất cung cấp cải thiện đáng kể về hiệu suất so với các phương pháp tiên tiến cho ITL trong các tác vụ phân loại hình ảnh. Ngoài ra, ITL rank thấp đề xuất tránh việc sử dụng bộ đệm bộ nhớ hoặc chi phí bộ nhớ lớn trong khi đạt được quên lãng bằng không.

Nhu cầu về kiến thức ID tác vụ là một hạn chế chung của phương pháp ITL của chúng tôi và các phương pháp khác. Các phương pháp như vậy có thể hữu ích cho học đa tác vụ tăng dần nơi ID tác vụ có sẵn trong quá trình suy luận nhưng dữ liệu huấn luyện chỉ có sẵn trong một cửa sổ ngắn. Mở rộng phương pháp này cho học tăng dần lớp (không yêu cầu ID tác vụ) là một vấn đề quan trọng cho công việc tương lai.

**Lời cảm ơn.** Tài liệu này dựa trên công việc được hỗ trợ một phần bởi Air Force Office of Scientific Research (AFOSR) giải thưởng FA9550-21-1-0330, FA9550-20-1-0039, Office of Naval Research (ONR) giải thưởng N00014-19-1-2264, và National Science Foundation (NSF) giải thưởng CCF-2046293. Được phê duyệt để Phát hành Công khai bởi AFRL; Phân phối Không hạn chế: Số trường hợp AFRL-2021-4063

Tác giả liên hệ: M. Salman Asif (sasif@ucr.edu)

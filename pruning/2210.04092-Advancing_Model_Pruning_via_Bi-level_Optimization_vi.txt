# Thúc đẩy Cắt tỉa Mô hình thông qua Tối ưu hóa Hai cấp
Yihua Zhang1,*Yuguang Yao1,*Parikshit Ram2Pu Zhao3Tianlong Chen4
Mingyi Hong5Yanzhi Wang3Sijia Liu1,2
1Đại học Bang Michigan,2IBM Research,3Đại học Northeastern,
4Đại học Texas tại Austin,5Đại học Minnesota, Twin Cities
*Đóng góp bằng nhau

## Tóm tắt
Các ràng buộc triển khai trong các ứng dụng thực tế đòi hỏi việc cắt tỉa các mô hình học sâu quy mô lớn, tức là thúc đẩy độ thưa thớt trọng số của chúng. Như được minh họa bởi Giả thuyết Vé số may mắn (LTH), việc cắt tỉa cũng có tiềm năng cải thiện khả năng tổng quát hóa của chúng. Ở cốt lõi của LTH, cắt tỉa độ lớn lặp lại (IMP) là phương pháp cắt tỉa chủ đạo để thành công tìm ra 'vé số thắng'. Tuy nhiên, chi phí tính toán của IMP tăng quá mức khi tỉ lệ cắt tỉa mục tiêu tăng. Để giảm chi phí tính toán, nhiều phương pháp cắt tỉa 'một lần' hiệu quả đã được phát triển nhưng các sơ đồ này thường không thể tìm được vé số thắng tốt như IMP. Điều này đặt ra câu hỏi làm thế nào để thu hẹp khoảng cách giữa độ chính xác cắt tỉa và hiệu quả cắt tỉa? Để giải quyết vấn đề này, chúng tôi theo đuổi sự tiến bộ thuật toán của việc cắt tỉa mô hình. Cụ thể, chúng tôi xây dựng bài toán cắt tỉa từ một góc nhìn mới và độc đáo, tối ưu hóa hai cấp (BLO). Chúng tôi chỉ ra rằng cách diễn giải BLO cung cấp một nền tảng tối ưu hóa có cơ sở kỹ thuật cho việc triển khai hiệu quả mô hình học cắt tỉa-đào tạo lại được sử dụng trong IMP. Chúng tôi cũng chỉ ra rằng phương pháp cắt tỉa hướng tối ưu hóa hai cấp được đề xuất (gọi là BIP) là một lớp đặc biệt của các bài toán BLO với cấu trúc bài toán tuyến tính kép. Bằng cách tận dụng tính tuyến tính kép này, chúng tôi chỉ ra về mặt lý thuyết rằng BIP có thể được giải một cách dễ dàng như tối ưu hóa bậc nhất, do đó kế thừa hiệu quả tính toán. Thông qua các thí nghiệm rộng rãi trên cả cắt tỉa có cấu trúc và không có cấu trúc với 5 kiến trúc mô hình và 4 tập dữ liệu, chúng tôi chứng minh rằng BIP có thể tìm ra vé số thắng tốt hơn IMP trong hầu hết các trường hợp, và có hiệu quả tính toán như các sơ đồ cắt tỉa một lần, chứng minh tốc độ nhanh hơn 2-7 lần so với IMP ở cùng mức độ chính xác và thưa thớt của mô hình. Mã nguồn có sẵn tại https://github.com/OPTML-Group/BiP.

## 1 Giới thiệu
Trong khi các cấu trúc tham số hóa quá mức là chìa khóa cho việc cải thiện tổng quát hóa của các mạng nơ-ron sâu (DNN) [1–3], chúng tạo ra các vấn đề mới – hàng triệu hoặc thậm chí hàng tỷ tham số không chỉ tăng chi phí tính toán trong quá trình suy luận, mà còn đặt ra những thách thức triển khai nghiêm trọng trên các thiết bị hạn chế tài nguyên [4]. Kết quả là, việc cắt tỉa mô hình đã thu hút rất nhiều sự quan tâm nghiên cứu trong những năm gần đây, tập trung vào việc giảm kích thước mô hình bằng cách loại bỏ (hoặc cắt tỉa) các tham số dư thừa [4–8]. Độ thưa thớt mô hình (đạt được bằng cắt tỉa) cũng có lợi cho độ bền vững đối kháng [9], tổng quát hóa ngoài phân phối [10], và học chuyển giao [11]. Một số phương pháp cắt tỉa (hướng tới độ thưa thớt có cấu trúc) tạo điều kiện triển khai mô hình trên phần cứng [12, 13].

Trong số các thuật toán cắt tỉa mô hình được đề xuất khác nhau [5,9,11,14–27], Cắt tỉa Độ lớn Lặp lại (IMP) dựa trên phương pháp kinh nghiệm là cách tiếp cận chủ đạo hiện tại để đạt được độ thưa thớt mô hình mà không bị mất hiệu suất, như được gợi ý và biện minh thực nghiệm bởi Giả thuyết Vé số may mắn (LTH) [17]. LTH giả định về sự tồn tại của một mạng con (được gọi là 'vé số thắng') khi được đào tạo một cách riêng lẻ (ví dụ, từ một khởi tạo ngẫu nhiên [17] hoặc một điểm tua lại sớm của việc đào tạo mô hình dày đặc [19]), có thể đánh bại hiệu suất của mô hình dày đặc gốc [5,11,17–20]. Ý tưởng cốt lõi của IMP là lặp lại việc cắt tỉa và đào tạo lại mô hình trong khi tiến dần cắt tỉa một tỉ lệ nhỏ các trọng số còn lại trong mỗi lần lặp, và tiếp tục cho đến khi đạt được tỉ lệ cắt tỉa mong muốn. Trong khi IMP thường tìm ra vé số thắng, nó phải chịu chi phí của việc đào tạo lại mô hình từ đầu nhiều lần, làm cho nó trở nên cực kỳ tốn kém cho các tập dữ liệu lớn hoặc các kiến trúc mô hình lớn [28,29]. Để cải thiện hiệu quả của việc cắt tỉa mô hình, nhiều phương pháp cắt tỉa một lần dựa trên phương pháp kinh nghiệm [17,21–25], ví dụ, cắt tỉa độ lớn một lần (OMP), đã được đề xuất. Các sơ đồ này trực tiếp cắt tỉa mô hình đến độ thưa thớt mục tiêu và hiệu quả hơn đáng kể so với IMP. Tuy nhiên, lời hứa của các phương pháp cắt tỉa một lần hiện tại là cụ thể theo tập dữ liệu/mô hình [22,30] và chủ yếu nằm trong chế độ tỉ lệ cắt tỉa thấp [25]. Như được nghiên cứu một cách có hệ thống trong [22,31], tồn tại một khoảng cách hiệu suất rõ ràng giữa cắt tỉa một lần và IMP. Như một sự thay thế cho các sơ đồ dựa trên phương pháp kinh nghiệm, các phương pháp cắt tỉa dựa trên tối ưu hóa [9,15,16,26,27] vẫn theo mô hình học cắt tỉa-đào tạo lại và áp dụng chính quy hóa độ thưa thớt [32,33] hoặc che mặt tham số hóa [9,16,27] để cắt tỉa mô hình một cách hiệu quả. Tuy nhiên, các phương pháp này không phải lúc nào cũng khớp với độ chính xác của IMP và do đó không được sử dụng rộng rãi để tìm vé số thắng [17,21,23–25,29]. Các kết quả thực nghiệm cho thấy tối ưu hóa kém hiệu quả hơn phương pháp kinh nghiệm khiến chúng tôi xem xét lại các nguyên tắc cơ bản thuật toán của cắt tỉa.

Để làm điều này, chúng tôi đưa ra một quan điểm mới về cắt tỉa mô hình như một bài toán tối ưu hóa hai cấp (BLO). Trong công thức mới này, chúng tôi chỉ ra rằng BLO cung cấp một cơ sở tối ưu hóa có nền tảng kỹ thuật cho việc triển khai hiệu quả mô hình học cắt tỉa-đào tạo lại, thành phần thuật toán chính được sử dụng trong IMP. Theo hiểu biết tốt nhất của chúng tôi, chúng tôi tạo ra kết nối nghiêm ngặt đầu tiên giữa cắt tỉa mô hình và BLO. Về mặt kỹ thuật, chúng tôi đề xuất một phương pháp cắt tỉa hỗ trợ tối ưu hóa hai cấp mới (gọi là BIP). Chúng tôi tiếp tục chỉ ra cách BIP tận dụng tính tuyến tính kép của bài toán cắt tỉa để tránh các thách thức tính toán của các phương pháp BLO thông thường, và hiệu quả như bất kỳ sơ đồ tối ưu hóa luân phiên bậc nhất nào. Trên thực tế, chúng tôi chứng minh sự vượt trội của BIP được đề xuất về độ chính xác, độ thưa thớt và hiệu quả tính toán thông qua các thí nghiệm rộng rãi. BIP tìm ra vé số thắng tốt nhất gần như trong tất cả các cài đặt trong khi mất thời gian tương đương với OMP một lần. Trong Hình 1, chúng tôi trình bày một ảnh chụp nhanh các kết quả thực nghiệm của chúng tôi cho CIFAR-10 với 3 kiến trúc ResNet ở tỉ lệ cắt tỉa 74%. Trong tất cả các trường hợp, BIP (?) tìm ra vé số thắng, cải thiện độ chính xác so với mô hình dày đặc (■) và khớp với IMP (▲), trong khi nhanh hơn tới 5× so với IMP.

Đóng góp của chúng tôi có thể được tóm tắt như sau:

(Công thức) Chúng tôi suy nghĩ lại nền tảng thuật toán của cắt tỉa mô hình thông qua lăng kính BLO (tối ưu hóa hai cấp). Công thức hướng BLO mới tách biệt các biến cắt tỉa và đào tạo lại, cung cấp tính linh hoạt để thiết kế giao diện giữa cắt tỉa và đào tạo lại.

(Thuật toán) Chúng tôi đề xuất thuật toán cắt tỉa hai cấp mới (BIP), được xây dựng dựa trên công thức BLO nói trên và lý thuyết tối ưu hóa dựa trên gradient ngầm. Không giống như các bộ giải BLO tiêu chuẩn tốn nhiều tính toán, chúng tôi chỉ ra về mặt lý thuyết rằng BIP hiệu quả như bất kỳ tối ưu hóa bậc nhất nào bằng cách tận dụng bản chất tuyến tính kép của các biến cắt tỉa.

(Thí nghiệm) Chúng tôi tiến hành các thí nghiệm rộng rãi trên 4 tập dữ liệu (CIFAR-10, CIFAR-100, Tiny-ImageNet và ImageNet), 5 kiến trúc mô hình và 3 cài đặt cắt tỉa (cắt tỉa không có cấu trúc, cắt tỉa có cấu trúc theo bộ lọc và cắt tỉa có cấu trúc theo kênh). Chúng tôi chỉ ra rằng (i) BIP đạt được độ chính xác kiểm tra cao hơn IMP và tìm ra vé số thắng tốt nhất gần như trong tất cả các cài đặt, (ii) BIP có hiệu quả cao (có thể so sánh với các sơ đồ cắt tỉa một lần), có thể đạt được tốc độ nhanh hơn 2-7× so với IMP ở cùng mức độ chính xác và thưa thớt của mô hình, và (iii) BIP có thể tìm ra các mạng con đạt hiệu suất tốt hơn mô hình dày đặc bất kể việc tua lại khởi tạo.

## 2 Công trình Liên quan và Câu hỏi Mở

Cắt tỉa mạng nơ-ron. Khi các mạng nơ-ron trở nên sâu hơn và tinh vi hơn, công nghệ cắt tỉa mô hình đã thu hút ngày càng nhiều sự chú ý trong thập kỷ qua vì các mô hình được cắt tỉa là cần thiết cho việc triển khai các mạng sâu trong các ứng dụng thực tế [4,34,35]. Với mục tiêu tìm ra các mạng con có độ thưa thớt cao và độ chính xác cao từ các mô hình dày đặc gốc, nhiều phương pháp cắt tỉa khác nhau đã được phát triển như cắt tỉa dựa trên phương pháp kinh nghiệm [17,21,23–25,29,36] và cắt tỉa dựa trên tối ưu hóa [9,16,26,27]. Loại trước xác định các trọng số mô hình dư thừa bằng cách tận dụng các chỉ số dựa trên phương pháp kinh nghiệm như độ lớn trọng số [6,17,19,11,22,37,31,36,38], độ lớn gradient [21,23,24,39,40], và thống kê Hessian [41–46]. Loại sau thường được xây dựng trên: 1) tối ưu hóa thúc đẩy độ thưa thớt [15,33,47–50], nơi các trọng số mô hình được đào tạo bằng cách phạt các chuẩn gây ra độ thưa thớt của chúng, như chuẩn ℓ₀ và ℓ₁ cho cắt tỉa trọng số không đều, và chuẩn ℓ₂ cho cắt tỉa có cấu trúc; 2) che mặt tham số hóa [16,9,51–55], nơi các điểm số trọng số mô hình được tối ưu hóa để lọc các trọng số quan trọng nhất và đạt hiệu suất tốt hơn.

Cắt tỉa lặp lại so với một lần, và động lực. Các sơ đồ hiện có có thể được phân loại thêm thành cắt tỉa một lần hoặc lặp lại dựa trên lịch trình cắt tỉa được sử dụng để đạt được độ thưa thớt mô hình mục tiêu. Trong số các sơ đồ lặp lại, IMP (sơ đồ Cắt tỉa Độ lớn Lặp lại) [17,20,56–65,36] đã đóng một vai trò quan trọng trong việc xác định 'vé số thắng' chất lượng cao, như được giả định bởi LTH (Giả thuyết Vé số may mắn) [18,19]. Để có thể so sánh nhất quán giữa các phương pháp khác nhau, chúng tôi mở rộng định nghĩa gốc của vé số thắng trong [17] thành 'mạng con khớp' [20] để bao gồm các triển khai khác nhau của vé số thắng, ví dụ, việc sử dụng tua lại epoch sớm cho việc khởi tạo lại mô hình [18] và biến thể không tua lại (tức là, tinh chỉnh) [66]. Ngắn gọn, các mạng con khớp nên khớp hoặc vượt qua hiệu suất của mô hình dày đặc gốc [20]. Trong công trình này, nếu một mạng con khớp được tìm thấy tốt hơn vé số thắng thu được bằng cùng phương pháp tuân theo thiết lập LTH gốc [18,19], chúng tôi cũng sẽ gọi mạng con khớp như vậy là vé số thắng trong toàn bộ bài báo.

Ví dụ, việc triển khai SOTA (hiện đại) hiện tại của IMP trong [22] có thể dẫn đến ResNet-20 được cắt tỉa trên CIFAR-10 với độ thưa thớt 74% và độ chính xác kiểm tra 92.12%, khớp với hiệu suất của mô hình dày đặc gốc (xem ● đỏ trong Hình 2-Trái). Thuật toán IMP thường chứa hai thành phần chính: (i) một lịch trình cắt tỉa phát triển theo thời gian để tiến dần tăng độ thưa thớt mô hình qua các lần lặp cắt tỉa, và (ii) cơ chế học cắt tỉa-đào tạo lại được áp dụng tại mỗi lần lặp cắt tỉa. Với tỉ lệ cắt tỉa mục tiêu p% với T lần lặp cắt tỉa, một ví dụ lịch trình cắt tỉa trong (i) có thể như sau – mỗi lần lặp cắt tỉa (p%)^(1/T) của các trọng số mô hình chưa được cắt tỉa hiện tại, tiến dần cắt tỉa ít trọng số hơn trong mỗi lần lặp. Đối với (ii), các trọng số chưa được cắt tỉa trong mỗi lần lặp cắt tỉa được đặt lại về trọng số tại khởi tạo hoặc tại epoch đào tạo sớm [18], và được đào tạo lại cho đến khi hội tụ. Tóm lại, IMP lặp đi lặp lại cắt tỉa, đặt lại và đào tạo mạng qua nhiều lần lặp.

Tuy nhiên, vé số thắng được tìm thấy bởi IMP phải chịu chi phí tính toán đáng kể. Vé số thắng thưa thớt nhất được tìm thấy bởi IMP trong Hình 2-Trái (● đỏ) sử dụng T = 6 lần lặp cắt tỉa. Như được hiển thị trong Hình 2-Phải, điều này mất nhiều thời gian hơn 3× so với việc đào tạo gốc của mô hình dày đặc. Để tránh chi phí tính toán của IMP, các loại phương pháp cắt tỉa 'tăng tốc' khác nhau đã được phát triển [17,21,23–25,29], và nhiều loại thuộc về danh mục cắt tỉa một lần: Mạng được cắt tỉa trực tiếp đến độ thưa thớt mục tiêu và được đào tạo lại một lần. Cụ thể, OMP (cắt tỉa độ lớn một lần) là một đường cơ sở quan trọng đơn giản hóa IMP [17]. Nó tuân theo mô hình học cắt tỉa-đào tạo lại, nhưng cắt tỉa mô hình đến tỉ lệ mục tiêu với một lần lặp cắt tỉa duy nhất. Mặc dù các sơ đồ cắt tỉa một lần rẻ về mặt tính toán (Hình 2-Phải), chúng phải chịu một sự sụt giảm độ chính xác đáng kể so với IMP (Hình 2-Trái). Ngay cả khi IMP được tùy chỉnh với số epoch đào tạo giảm mỗi vòng cắt tỉa, độ chính xác cắt tỉa cũng giảm mạnh (xem Hình A2). Do đó, cần có các kỹ thuật cắt tỉa mô hình tiên tiến để tìm vé số thắng như IMP, trong khi hiệu quả như cắt tỉa một lần.

Khác với cắt tỉa trọng số không có cấu trúc được mô tả ở trên, cắt tỉa có cấu trúc xem xét các mẫu thưa thớt của mô hình, như cắt tỉa theo bộ lọc và kênh [13,48,51,67–71]. Cắt tỉa có cấu trúc là mong muốn cho việc triển khai mô hình sâu khi có ràng buộc phần cứng [4,34]. Tuy nhiên, so với cắt tỉa không có cấu trúc, thường khó khăn hơn để duy trì hiệu suất và tìm vé số thắng nhận biết cấu trúc [28, 29].

Câu hỏi mở. Như đã thảo luận ở trên, các phương pháp cắt tỉa một lần không thể khớp với hiệu suất dự đoán của IMP, và vé số thắng nhận biết cấu trúc khó tìm. Rõ ràng, nền tảng tối ưu hóa tốt nhất của cắt tỉa mô hình chưa được phát triển đầy đủ. Do đó, chúng tôi hỏi:

Có tồn tại một cơ sở tối ưu hóa cho thuật toán cắt tỉa thành công có thể đạt được độ chính xác mô hình cắt tỉa cao (như IMP) và hiệu quả tính toán cao (như cắt tỉa một lần) không?

Bài toán cắt tỉa mô hình có cấu trúc phân cấp tự nhiên – chúng ta cần tìm mặt nạ tốt nhất để cắt tỉa các tham số mô hình, và sau đó, với mặt nạ đã cho, tìm trọng số mô hình tốt nhất cho các tham số mô hình chưa được cắt tỉa. Với cấu trúc phân cấp này, chúng tôi tin rằng khung tối ưu hóa hai cấp (BLO) là một cơ sở tối ưu hóa đầy hứa hẹn cho thuật toán cắt tỉa thành công.

Tối ưu hóa hai cấp (BLO). BLO là một khung tối ưu hóa phân cấp tổng quát, nơi bài toán cấp trên phụ thuộc vào giải pháp của bài toán cấp dưới. Cấu trúc lồng nhau như vậy làm cho BLO ở dạng tổng quát nhất rất khó giải, vì khó mô tả ảnh hưởng của tối ưu hóa cấp dưới lên bài toán cấp trên. Nhiều tài liệu hiện có tập trung vào thiết kế và phân tích thuật toán cho các trường hợp đặc biệt khác nhau của BLO. Các ứng dụng từ các phương pháp hạ cận cổ điển [72–74], phương pháp dựa trên phạt [75,76], đến BigSAM gần đây [77] và các mở rộng của nó [78,79]. Nó cũng được nghiên cứu trong lĩnh vực thuật toán ngẫu nhiên [80–82] và thuật toán dựa trên lan truyền ngược [83–85]. BLO cũng đã thúc đẩy đào tạo đối kháng [86], học meta [87], tạo tấn công đầu độc dữ liệu [88], tìm kiếm kiến trúc mạng nơ-ron [89] cũng như học tăng cường [90]. Mặc dù BLO đã được đề cập trong [50] cho cắt tỉa mô hình, nó thực sự gọi một thủ tục tối ưu hóa luân phiên thông thường, không xem xét cấu trúc học phân cấp của BLO. Theo hiểu biết tốt nhất của chúng tôi, khung BLO chưa được xem xét cho cắt tỉa mô hình một cách sâu sắc và có hệ thống. Chúng tôi sẽ chỉ ra rằng cắt tỉa mô hình tạo ra một lớp đặc biệt của các bài toán BLO với các biến tối ưu hóa tuyến tính kép. Chúng tôi cũng sẽ chỉ ra về mặt lý thuyết rằng bài toán BLO chuyên biệt này cho cắt tỉa mô hình có thể được giải hiệu quả như tối ưu hóa bậc nhất. Điều này trái ngược mạnh mẽ với các ứng dụng BLO hiện có dựa vào các bộ giải BLO dựa trên phương pháp kinh nghiệm (ví dụ, gradient unrolling trong học meta [87] và tìm kiếm kiến trúc mạng nơ-ron [89, 91]).

## 3 BIP: Cắt tỉa Mô hình thông qua Tối ưu hóa Hai cấp

Trong phần này, chúng tôi điều tra lại bài toán cắt tỉa mô hình thông qua lăng kính BLO và phát triển thuật toán cắt tỉa hai cấp (BIP). Chúng tôi có thể chỉ ra về mặt lý thuyết rằng BIP có thể được giải dễ dàng như tối ưu hóa luân phiên bậc nhất bằng cách tận dụng tính tuyến tính kép của các biến cắt tỉa.

Quan điểm BLO về cắt tỉa mô hình. Như được mô tả trong phần trước, mô hình học cắt tỉa-đào tạo lại bao gồm hai loại nhiệm vụ: ¶ cắt tỉa xác định mẫu thưa thớt của trọng số mô hình, và · đào tạo các trọng số khác không còn lại để khôi phục độ chính xác mô hình. Trong các phương pháp cắt tỉa dựa trên tối ưu hóa hiện có [92–95], các nhiệm vụ ¶-· thường được thực hiện bằng cách tối ưu hóa trọng số mô hình, cùng với việc phạt các chuẩn gây ra độ thưa thớt của chúng, ví dụ, chuẩn ℓ₁ và ℓ₂ [96]. Khác với công thức trên, chúng tôi đề xuất tách các biến tối ưu hóa liên quan đến các nhiệm vụ cắt tỉa ¶ và ·. Điều này dẫn đến biến mặt nạ cắt tỉa (nhị phân) m ∈ {0,1}ⁿ và biến trọng số mô hình θ ∈ ℝⁿ. Ở đây n biểu thị tổng số tham số mô hình. Tương ứng, mô hình được cắt tỉa được cho bởi θ ⊙ m, nơi ⊙ biểu thị phép nhân theo phần tử. Như sẽ rõ ràng sau này, hình thức tách biệt biến này cho phép chúng ta mô tả một cách rõ ràng cách quá trình cắt tỉa và đào tạo lại cùng phát triển, và giúp tùy chỉnh nhiệm vụ cắt tỉa với tính linh hoạt cao.

Chúng tôi tiếp tục trình bày chi tiết về cách BLO có thể được thiết lập để đồng tối ưu hóa mặt nạ cắt tỉa m và trọng số mô hình thưa thớt được đào tạo lại θ. Với tỉ lệ cắt tỉa p%, ràng buộc độ thưa thớt được cho bởi m ∈ S, nơi S = {m | m ∈ {0,1}ⁿ, 1ᵀm ≤ k} và k = ⌊(1-p%)n⌋. Mục tiêu của chúng tôi là cắt tỉa mô hình gốc trực tiếp đến tỉ lệ cắt tỉa mục tiêu p% (tức là, không gọi lịch trình độ thưa thớt giống IMP như được mô tả trong Phần 2) và thu được mô hình thưa thớt tối ưu hóa θ ⊙ m. Để đạt được điều này, chúng tôi diễn giải nhiệm vụ cắt tỉa (tức là, ¶) và nhiệm vụ đào tạo lại mô hình (tức là, ·) như hai cấp tối ưu hóa, nơi cái trước được xây dựng như một bài toán tối ưu hóa cấp trên, và nó dựa vào tối ưu hóa của nhiệm vụ đào tạo lại cấp dưới. Do đó chúng tôi đưa bài toán cắt tỉa mô hình thành bài toán BLO sau (với · được lồng bên trong ¶):

minimize m∈S ℓ(θ*(m) ⊙ m) [¶: Nhiệm vụ cắt tỉa]
subject to θ*(m) = arg min θ∈ℝⁿ g(m,θ) := ℓ(θ ⊙ m) + (λ/2)||θ||₂² [·: Đào tạo lại mô hình cố định độ thưa thớt] (1)

nơi ℓ biểu thị mất mát đào tạo (ví dụ, entropy chéo), m và θ là các biến tối ưu hóa cấp trên và cấp dưới tương ứng, θ*(m) biểu thị giải pháp cấp dưới thu được bằng cách tối thiểu hóa hàm mục tiêu g với mặt nạ cắt tỉa m, và λ > 0 là tham số chính quy hóa được đưa vào để làm lồi tối ưu hóa cấp dưới nhằm ổn định dòng gradient từ θ*(m) đến m và do đó sự hội tụ của BLO [82,97]. Trái ngược mạnh mẽ với các phương pháp cắt tỉa mô hình dựa trên tối ưu hóa một cấp hiện có [92–95], công thức BLO (1) mang lại hai lợi thế.

Thứ nhất, BLO có tính linh hoạt để sử dụng các mục tiêu cắt tỉa và đào tạo lại không khớp ở các cấp tối ưu hóa trên và dưới, tương ứng. Tính linh hoạt này cho phép chúng ta điều chỉnh hàm mục tiêu đào tạo cấp dưới trong (1) và tùy chỉnh các phương pháp tối ưu hóa được triển khai ở cả hai cấp. Để cụ thể hơn, người ta có thể cập nhật mặt nạ cắt tỉa cấp trên m sử dụng một batch dữ liệu (gọi là B₂) khác biệt với batch được sử dụng để thu được giải pháp cấp dưới (gọi là B₁). Thủ tục BLO kết quả sau đó có thể bắt chước ý tưởng của học meta để cải thiện tổng quát hóa mô hình [98], nơi bài toán cấp dưới tinh chỉnh sử dụng B₁, và bài toán cấp trên xác thực tổng quát hóa của mô hình tinh chỉnh nhận biết độ thưa thớt θ*(m) ⊙ m sử dụng B₂.

Thứ hai, BLO cho phép chúng ta mô hình hóa và tối ưu hóa một cách rõ ràng sự kết hợp giữa trọng số mô hình được đào tạo lại θ*(m) và mặt nạ cắt tỉa m thông qua thủ tục tối ưu hóa dựa trên gradient ngầm (IG). Ở đây IG đề cập đến gradient của giải pháp cấp dưới θ*(m) đối với (w.r.t.) biến cấp trên m, và việc dẫn xuất của nó gọi lý thuyết hàm ngầm [76]. Việc sử dụng IG làm cho cắt tỉa hướng BLO được đề xuất của chúng tôi (1) khác biệt đáng kể so với tối thiểu hóa luân phiên tham lam [99] học các biến cấp trên và cấp dưới một cách độc lập (tức là, tối thiểu hóa một biến bằng cách cố định biến kia). Chúng tôi giới thiệu độc giả đến phần tiếp theo cho lý thuyết IG chi tiết. Chúng tôi cũng sẽ chỉ ra trong Phần 4 rằng chiến lược cắt tỉa từ (1) có thể vượt trội hơn IMP trong nhiều tình huống cắt tỉa nhưng hiệu quả hơn nhiều vì nó không gọi bộ lập lịch của các tỉ lệ cắt tỉa lặp lại.

Nền tảng tối ưu hóa của BIP. Thách thức tối ưu hóa chính của việgiải bài toán BIP (1) nằm ở việc tính toán IG (gradient ngầm). Trước khi phát triển một giải pháp hiệu quả, chúng tôi trước tiên trình bày chi tiết về thách thức IG, đặc điểm độc đáo của BLO. Trong bối cảnh gradient descent, gradient của hàm mục tiêu trong (1) tạo ra

dℓ(θ*(m) ⊙ m)/dm [Gradient của mục tiêu] = ∇ₘℓ(θ*(m) ⊙ m) + d(θ*(m)ᵀ)/dm [IG] ∇θℓ(θ*(m) ⊙ m), (2)

nơi ∇ₘ và ∇θ biểu thị các đạo hàm riêng của hàm hai biến ℓ(θ ⊙ m) w.r.t. biến m và θ tương ứng, dθ*/dm ∈ ℝⁿˣⁿ biểu thị đạo hàm đầy đủ theo vector, và để dễ ký hiệu, chúng tôi sẽ bỏ qua chuyển vị ᵀ khi ngữ cảnh rõ ràng. Trong (2), thách thức IG đề cập đến nhu cầu tính toán gradient đầy đủ của hàm ngầm θ*(m) = arg min g(m,θ) w.r.t. m, nơi nhớ lại từ (1) rằng g(m,θ) := ℓ(θ ⊙ m) + (λ/2)||θ||₂².

Tiếp theo, chúng tôi dẫn xuất công thức IG theo lý thuyết hàm ngầm nghiêm ngặt [76,82,87]. Dựa trên thực tế rằng θ*(m) thỏa mãn điều kiện dừng cho hàm mục tiêu cấp dưới trong (2), không khó để thu được rằng (xem dẫn xuất trong Phụ lục A)

dθ*(m)/dm = ∇²ₘθℓ(θ ⊙ m)[∇²θθℓ(θ ⊙ m) + λI]⁻¹, (3)

nơi ∇²ₘθℓ và ∇²θθℓ biểu thị các đạo hàm riêng bậc hai của ℓ tương ứng, và (·)⁻¹ biểu thị phép nghịch đảo ma trận.

Tuy nhiên, công thức IG chính xác (3) vẫn khó tính toán do sự hiện diện của nghịch đảo ma trận và các đạo hàm riêng bậc hai. Để đơn giản hóa nó, chúng tôi áp đặt giả định không Hessian, ∇²θθℓ = 0, điều này là nhẹ nhàng nói chung; Ví dụ, các ranh giới quyết định của các mạng nơ-ron với kích hoạt ReLU là tuyến tính từng phần trong một siêu bề mặt nhiệt đới [100], và giả định này đã được sử dụng rộng rãi trong các ứng dụng liên quan đến BLO như học meta [101] và học đối kháng [86]. Với ∇²θθℓ = 0, nghịch đảo ma trận trong (3) có thể được giảm thiểu, dẫn đến công thức IG

dθ*(m)/dm = (1/λ)∇²ₘθℓ(θ ⊙ m). (4)

Thoạt nhìn, việc tính toán IG đơn giản hóa (4) vẫn yêu cầu đạo hàm riêng hỗn hợp (bậc hai) ∇²ₘθℓ. Tuy nhiên, BIP là một lớp đặc biệt của các bài toán BLO với các biến tuyến tính kép θ ⊙ m. Dựa trên tính tuyến tính kép này, chúng tôi có thể chứng minh rằng IG trong (4) có thể được biểu diễn một cách giải tích chỉ sử dụng các đạo hàm bậc nhất; xem định lý sau.

**Mệnh đề 1** Giả định ∇²θθℓ = 0 và định nghĩa ∇ᵧℓ(z) := ∇ᵧℓ(z)|ᵧ₌θ⊙ₘ, gradient ngầm (4) sau đó được cho bởi

dθ*(m)/dm = (1/λ)diag(∇ᵧℓ(z)), (5)

Hơn nữa, gradient của hàm mục tiêu được cho bởi (2) trở thành

dℓ(θ ⊙ m)/dm = (θ - (1/λ)m ⊙ ∇ᵧℓ(z)) ⊙ ∇ᵧℓ(z), (6)

nơi ⊙ biểu thị phép nhân theo phần tử.

**Chứng minh:** Sử dụng quy tắc chuỗi, chúng ta có thể thu được rằng

∇θℓ(θ ⊙ m) = diag(m)∇ᵧℓ(z) = m ⊙ ∇ᵧℓ(z); (7)

tương tự, ∇ₘℓ(θ ⊙ m) = diag(θ)∇ᵧℓ(z) = θ ⊙ ∇ᵧℓ(z) (8)

nơi diag(·) đại diện cho ma trận đường chéo với · là vector đường chéo chính. Hơn nữa, chúng ta có thể chuyển đổi (4) thành

∇²ₘθℓ(θ ⊙ m) = ∇ₘ[m ⊙ ∇ᵧℓ(z)] = diag(∇ᵧℓ(z)) + diag(m)[∇ₘ(∇ᵧℓ(z))]
= diag(∇ᵧℓ(z)) + diag(m)[diag(θ)∇²ᵧℓ(z)] = diag(∇ᵧℓ(z)); (9)

nơi đẳng thức cuối cùng đúng do giả định không Hessian. Với (9) và (4) chúng ta có thể chứng minh (5). Tiếp theo, thay thế IG (5) vào gradient cấp trên (2), chúng ta thu được rằng

dℓ(θ ⊙ m)/dm = ∇ₘℓ(θ ⊙ m) - (1/λ)∇ᵧℓ(z) ⊙ ∇θℓ(θ ⊙ m)
= θ ⊙ ∇ᵧℓ(z) - (1/λ)∇ᵧℓ(z) ⊙ (m ⊙ ∇ᵧℓ(z)) = (θ - (1/λ)m ⊙ ∇ᵧℓ(z)) ⊙ ∇ᵧℓ(z);

điều này dẫn đến (6). Chứng minh hoàn tất. □

Thông tin chính được rút ra từ Mệnh đề 1 là tính tuyến tính kép của các biến cắt tỉa (tức là, θ ⊙ m) làm cho gradient liên quan đến IG (2) dễ giải, và độ phức tạp tính toán gần như giống với việc tính toán gradient bậc nhất ∇ᵧℓ(z) chỉ một lần, như được hỗ trợ bởi (6).

Thuật toán và triển khai BIP. Chúng tôi tiếp tục hình thức hóa thuật toán BIP dựa trên Mệnh đề 1 và bộ giải BLO dựa trên gradient descent luân phiên [82]. Tại lần lặp t, có hai bước chính.

**▷ SGD cấp dưới cho đào tạo lại mô hình:** Với m^(t-1), θ^(t-1), và z^(t-1) := m^(t-1) ⊙ θ^(t-1), chúng tôi cập nhật θ^(t) bằng cách chọn ngẫu nhiên một batch dữ liệu với tốc độ học η và áp dụng SGD (stochastic gradient descent) cho bài toán cấp dưới của (1),

θ^(t) = θ^(t-1) - η∇g(m^(t-1); θ^(t-1)) = θ^(t-1) - η[m^(t-1) ⊙ ∇ᵧℓ(z)|ᵧ₌ᵧ(t-1) + λθ^(t-1)]; (θ-step)

**▷ SPGD cấp trên cho cắt tỉa:** Với m^(t-1), θ^(t), và z^(t+1/2) := m^(t-1) ⊙ θ^(t), chúng tôi cập nhật m sử dụng SPGD (stochastic projected gradient descent) dọc theo hướng descent tăng cường IG (2),

m^(t) = P_S[m^(t-1) - α(dℓ(m^(t))/dm)|ₘ₌ₘ(t-1)]
= P_S[m^(t-1) - α(θ^(t) - (1/λ)m^(t-1) ⊙ ∇ᵧℓ(z)|ᵧ₌ᵧ(t+1/2)) ⊙ ∇ᵧℓ(z)|ᵧ₌ᵧ(t+1/2)]; (m-step)

nơi α > 0 là tốc độ học cấp trên, và P_S(·) biểu thị phép chiếu Euclidean lên tập ràng buộc S được cho bởi S = {m | m ∈ {0,1}ⁿ, 1ᵀm ≤ k} trong (1) và được thực hiện bằng phép toán ngưỡng cứng top-k như sẽ được chi tiết sau.

Trong BIP, các bước (θ-step) và (m-step) thực thi lặp lại. Để rõ ràng, Hình 3 cho thấy sự khác biệt giữa các đường ống cắt tỉa của BIP và IMP. Trái ngược với IMP tiến dần cắt tỉa và đào tạo lại một mô hình với tỉ lệ cắt tỉa tăng dần, BIP trực tiếp cắt tỉa mô hình đến mức độ thưa thớt mục tiêu mà không liên quan đến quá trình đào tạo lại tốn kém. Trong thực tế, chúng tôi thấy rằng cả hai thủ tục tối ưu hóa cấp trên và cấp dưới của BIP đều hội tụ rất tốt (xem Hình A12 và Hình A13). Cũng đáng chú ý rằng cả (θ-step) và (m-step) chỉ yêu cầu thông tin bậc nhất ∇ᵧℓ(z), chứng minh rằng BIP có thể được thực hiện hiệu quả như tối ưu hóa bậc nhất. Trong Hình A1, chúng tôi làm nổi bật các chi tiết thuật toán về đường ống BIP. Chúng tôi trình bày thêm chi tiết triển khai của BIP dưới đây và giới thiệu độc giả đến Phụ lục B cho mô tả thuật toán chi tiết.

**▷ Tối ưu hóa rời rạc trên m:** Chúng tôi tuân theo cơ chế 'nới lỏng lồi + ngưỡng cứng' được sử dụng trong [9,16]. Cụ thể, chúng tôi nới lỏng các biến che mặt nhị phân thành điểm số che mặt liên tục m ∈ [0,1]. Sau đó chúng tôi thu được gradient mất mát tại lượt truyền ngược dựa trên m nới lỏng. Tại lượt truyền tiến, chúng tôi chiếu nó lên tập ràng buộc rời rạc S sử dụng toán tử ngưỡng cứng, nơi k phần tử hàng đầu được đặt thành 1 và những phần tử khác thành 0. Xem Phụ lục B để thảo luận thêm.

**▷ Lựa chọn batch dữ liệu cho tối ưu hóa cấp dưới và cấp trên:** Chúng tôi áp dụng các batch dữ liệu khác nhau (với cùng kích thước batch) khi triển khai (θ-step) và (m-step). Đây là một trong những lợi thế của công thức BLO, cho phép tính linh hoạt để tùy chỉnh các bài toán cấp dưới và cấp trên. Việc sử dụng các batch dữ liệu đa dạng có lợi cho tổng quát hóa như được hiển thị trong [98].

**▷ Điều chỉnh siêu tham số:** Như được mô tả trong (θ-step)-(m-step), BIP cần đặt hai tốc độ học η và α cho tối ưu hóa cấp dưới và cấp trên, tương ứng. Chúng tôi chọn η = 0.01 và α = 0.1 trong tất cả các thí nghiệm, nơi chúng tôi áp dụng tốc độ học mặt nạ từ Hydra [9] và đặt tốc độ học cấp dưới nhỏ hơn η, vì θ được khởi tạo bởi một mô hình dày đặc được đào tạo trước. Chúng tôi cho thấy nghiên cứu ablation về η trong Hình A8(c). BLO cũng mang lại tham số lồi hóa cấp thấp λ. Chúng tôi đặt λ = 1.0 trong các thí nghiệm và giới thiệu độc giả đến Hình A8(b) để kiểm tra tính đúng đắn.

**▷ SGD một bước so với nhiều bước:** Trong (θ-step), SGD một bước được sử dụng và giúp giảm chi phí tính toán. Trong thực tế, chúng tôi cũng thấy rằng SGD một bước là đủ: Việc sử dụng SGD nhiều bước trong BIP không mang lại cải thiện đáng kể so với phiên bản một bước; xem Hình A8(a).

**▷ Mở rộng cho cắt tỉa có cấu trúc:** Chúng tôi xây dựng và giải bài toán BIP trong bối cảnh cắt tỉa trọng số không có cấu trúc (theo phần tử). Tuy nhiên, nếu định nghĩa mặt nạ cắt tỉa m w.r.t. các đơn vị cấu trúc của mô hình (ví dụ, bộ lọc), BIP dễ dàng được áp dụng cho cắt tỉa có cấu trúc (xem Hình 6 và Hình A10).

## 4 Thí nghiệm

Trong phần này, chúng tôi trình bày các kết quả thí nghiệm rộng rãi để cho thấy hiệu quả của BIP trên nhiều kiến trúc mô hình, các tập dữ liệu khác nhau và các thiết lập cắt tỉa khác nhau. So với IMP, cắt tỉa một lần và các đường cơ sở cắt tỉa dựa trên tối ưu hóa, chúng tôi thấy rằng BIP có thể tìm ra vé số thắng tốt hơn trong hầu hết các trường hợp và có hiệu quả tính toán.

### 4.1 Thiết lập Thí nghiệm

Tập dữ liệu và mô hình. Theo benchmark cắt tỉa trong [22], chúng tôi xem xét 4 tập dữ liệu bao gồm CIFAR-10 [102], CIFAR-100 [102], Tiny-ImageNet [103], ImageNet [104], và 5 loại kiến trúc bao gồm ResNet-20/56/18/50 và VGG-16 [105,106]. Bảng A1 tóm tắt các tập dữ liệu và cấu hình mô hình và thiết lập này.

Đường cơ sở, đào tạo và đánh giá. Làm đường cơ sở, chúng tôi chủ yếu tập trung vào 4 phương pháp cắt tỉa SOTA, ¬ IMP [17], ­ OMP [17], ® GRASP [23] (một phương pháp cắt tỉa một lần bằng cách phân tích dòng gradient tại khởi tạo), và ¯ HYDRA [9] (một phương pháp cắt tỉa dựa trên tối ưu hóa tối ưu hóa điểm số che mặt). Đáng chú ý rằng tồn tại nhiều triển khai khác nhau của IMP, ví dụ, được chỉ định bởi các tốc độ học khác nhau và khởi tạo mô hình hoặc chiến lược 'tua lại' [18]. Để có so sánh công bằng, chúng tôi tuân theo benchmark IMP gần đây trong [22], có thể tìm ra vé số thắng tốt nhất so với các đường cơ sở cắt tỉa dựa trên phương pháp kinh nghiệm hiện tại. Chúng tôi cũng nhận xét rằng HYDRA ban đầu được đề xuất để cải thiện độ bền vững đối kháng của mô hình được cắt tỉa, nhưng nó có thể dễ dàng được tùy chỉnh cho cắt tỉa tiêu chuẩn khi đặt sức mạnh của đối thủ là 0 [9]. Chúng tôi chọn HYDRA làm đường cơ sở vì nó có thể được coi là một biến thể một cấp của BIP với đào tạo lại trọng số sau tối ưu hóa. Khi triển khai BIP, trừ khi được chỉ định khác, chúng tôi sử dụng SGD 1 bước trong (θ-step), và đặt các tốc độ học (η, α) và tham số chính quy hóa cấp dưới λ như được mô tả trong phần trước. Khi triển khai đường cơ sở, chúng tôi tuân theo thiết lập kho lưu trữ chính thức của chúng. Chúng tôi đánh giá hiệu suất của tất cả các phương pháp chủ yếu từ hai góc độ: (1) độ chính xác kiểm tra của mạng con, và (2) thời gian chạy của cắt tỉa để đạt được độ thưa thớt mong muốn. Chúng tôi giới thiệu độc giả đến Bảng A3 và Phụ lục C.2 để biết thêm chi tiết đào tạo và đánh giá, như epochs đào tạo và lịch trình tốc độ học.

### 4.2 Kết quả Thí nghiệm

BIP xác định các mạng con có độ chính xác cao. Trong phần tiếp theo, chúng tôi xem xét chất lượng của vé số thắng được xác định bởi BIP. Hai quan sát chính có thể được rút ra từ kết quả của chúng tôi: (1) BIP tìm ra vé số thắng có độ chính xác cao hơn và/hoặc độ thưa thớt cao hơn so với các đường cơ sở trong hầu hết các trường hợp (như được hiển thị trong Hình 4 và Bảng 1); (2) Sự vượt trội của BIP đúng cho cả cắt tỉa không có cấu trúc và có cấu trúc (như được hiển thị trong Hình 6 và Hình A10). Chúng tôi giới thiệu thêm kết quả thí nghiệm trong Phụ lục C.3.

Hình 4 cho thấy quỹ đạo cắt tỉa không có cấu trúc (được cho bởi độ chính xác kiểm tra so với tỉ lệ cắt tỉa) của BIP và các phương pháp đường cơ sở trong 8 thiết lập mô hình-tập dữ liệu. Để so sánh, chúng tôi cũng trình bày hiệu suất của mô hình dày đặc gốc. Như chúng ta có thể thấy, phương pháp BIP được đề xuất tìm ra vé số thắng tốt nhất (về độ chính xác cao nhất) so với các đường cơ sở trên tất cả các thiết lập cắt tỉa. Trong số các phương pháp đường cơ sở, IMP là phương pháp cạnh tranh nhất với chúng tôi. Tuy nhiên, cải thiện mang lại bởi BIP là đáng kể đối với phương sai của IMP, ngoại trừ chế độ độ thưa thớt 60%-80% trong (CIFAR-10, ResNet-20). Trong trường hợp (CIFAR-100, ResNet-20), nơi IMP không thể tìm được bất kỳ vé số thắng nào (như được xác nhận bởi [22]), BIP vẫn quản lý để tìm ra vé số thắng với khoảng 0.6% cải thiện so với mô hình dày đặc. Trong Bảng 1, chúng tôi tóm tắt các vé số thắng thưa thớt nhất dọc theo quỹ đạo cắt tỉa được xác định bởi các phương pháp cắt tỉa khác nhau. BIP có thể xác định vé số thắng với mức độ thưa thớt cao hơn so với các phương pháp khác, ngoại trừ trong trường hợp (CIFAR-10, ResNet-20).

Hình 6 chứng minh quỹ đạo cắt tỉa có cấu trúc trên các tập dữ liệu CIFAR-10/100. Ở đây chúng tôi tập trung vào cắt tỉa bộ lọc, nơi bộ lọc được coi là một đơn vị che mặt trong (1). Chúng tôi giới thiệu độc giả đến Hình A10 cho kết quả cắt tỉa theo kênh. Do giới hạn trang, chúng tôi chỉ báo cáo kết quả của cắt tỉa theo bộ lọc trong bài báo chính và vui lòng tham khảo Phụ lục C.3 cho cắt tỉa theo kênh. So với Hình 4, Hình 6 cho thấy rằng việc tìm vé số thắng có độ chính xác và độ thưa thớt cao trong cắt tỉa có cấu trúc trở nên khó khăn hơn, và khoảng cách giữa các phương pháp khác nhau giảm. Điều này không đáng ngạc nhiên, vì cắt tỉa bộ lọc áp đặt ràng buộc cấu trúc cắt tỉa nghiêm ngặt hơn nhiều so với cắt tỉa không đều. Tuy nhiên, BIP vẫn vượt trội hơn tất cả các đường cơ sở. Quan trọng nhất, nó xác định vé số thắng rõ ràng trong chế độ thưa thớt thấp ngay cả khi IMP thất bại.

BIP có hiệu quả tính toán. Trong các thí nghiệm của chúng tôi, một quan sát chính khác là BIP mang lại độ phức tạp thời gian chạy bất biến độ thưa thớt trong khi IMP dẫn đến thời gian chạy theo cấp số nhân với độ thưa thớt mục tiêu. Hình 5 cho thấy chi phí tính toán của các phương pháp khác nhau so với tỉ lệ cắt tỉa trên (CIFAR-10, ResNet-18). Ví dụ, BIP mất 86 phút để tìm ra vé số thắng thưa thớt nhất (với độ thưa thớt 89% trong Bảng 1). Điều này mang lại thời gian chạy ít hơn 7× so với IMP, tiêu thụ 620 phút để tìm ra vé số thắng tương đương với độ thưa thớt 87%. So với đường cơ sở dựa trên tối ưu hóa HYDRA, BIP hiệu quả hơn vì nó không dựa vào đào tạo lại sau tối ưu hóa thêm; xem Bảng A2 cho tóm tắt chi tiết về thời gian chạy và số epochs đào tạo yêu cầu bởi các phương pháp cắt tỉa khác nhau. Hơn nữa, BIP mất khoảng 1.25× thời gian tính toán hơn GRASP và OMP. Tuy nhiên, các phương pháp sau dẫn đến độ chính xác mô hình được cắt tỉa tệ hơn, như được chứng minh bởi thất bại của chúng trong việc tìm vé số thắng trong Bảng 1, Hình 4 và Hình 6.

BIP không yêu cầu tua lại. Một lợi thế khác của BIP là nó không nhạy cảm với việc tua lại mô hình để tìm mạng con khớp. Nhớ lại rằng tua lại là một chiến lược được sử dụng trong LTH [19] để xác định khởi tạo mô hình nào nên được sử dụng để đào tạo lại mô hình được cắt tỉa. Như được hiển thị trong [22], một vé số thắng được xác định bởi IMP có thể nhạy cảm với việc lựa chọn điểm tua lại. Hình 7 cho thấy độ chính xác kiểm tra của mô hình được cắt tỉa BIP khi nó được đào tạo lại tại các epochs tua lại khác nhau dưới các tập dữ liệu và kiến trúc mô hình khác nhau, nơi 'N/A' trong trục x đại diện cho trường hợp không đào tạo lại (và do đó không tua lại). Như chúng ta có thể thấy, một sơ đồ tua lại được điều chỉnh cẩn thận không dẫn đến cải thiện đáng kể so với BIP mà không đào tạo lại. Điều này gợi ý rằng các mạng con được tìm thấy bởi BIP đã có chất lượng cao và không yêu cầu bất kỳ hoạt động tua lại nào.

Kết quả bổ sung. Chúng tôi bao gồm thêm kết quả thí nghiệm trong Phụ lục C.3. Cụ thể, chúng tôi cho thấy thêm kết quả trong cả thiết lập cắt tỉa không có cấu trúc và có cấu trúc trong Hình A4, Hình A5, Hình A6 và Hình A7, nơi chúng tôi so sánh BIP với nhiều đường cơ sở hơn và bao gồm nhiều kiến trúc mô hình hơn. Chúng tôi cũng nghiên cứu độ nhạy cảm của BIP đối với số bước cấp dưới, hệ số chính quy hóa cấp dưới, tầm quan trọng của thuật ngữ gradient ngầm (2), tốc độ học và kích thước batch, như được hiển thị trong Hình A8 và Hình A9. Để chứng minh sự hội tụ của tối ưu hóa cấp trên và cấp dưới trong BIP, chúng tôi cho thấy quỹ đạo đào tạo của BIP cho độ chính xác (Hình A12) và điểm số mặt nạ (Hình A13), và cho thấy cách số bước cấp dưới ảnh hưởng đến tốc độ hội tụ (Hình A14)). Hơn nữa, chúng tôi cho thấy hiệu suất của BIP so với sự tăng trưởng của epochs đào tạo (Hình A15), và hiệu suất của nó so với các bộ lập lịch batch dữ liệu khác nhau (xem Hình A16).

## 5 Kết luận

Chúng tôi đã đề xuất phương pháp BIP để tìm mạng thưa thớt thông qua lăng kính BLO. Công trình của chúng tôi đã thúc đẩy nền tảng thuật toán của cắt tỉa mô hình bằng cách mô tả hệ thống phân cấp cắt tỉa-đào tạo lại của nó sử dụng BLO. Chúng tôi đã chỉ ra về mặt lý thuyết rằng BIP có thể được giải dễ dàng như tối ưu hóa bậc nhất bằng cách khai thác tính tuyến tính kép của các biến cắt tỉa. Chúng tôi cũng đã chỉ ra về mặt thực nghiệm rằng BIP có thể tìm ra vé số thắng chất lượng cao rất hiệu quả so với phương pháp cắt tỉa lặp lại chủ đạo. Trong tương lai, chúng tôi sẽ tìm kiếm chương trình đào tạo tối ưu của dữ liệu đào tạo tại các cấp tối ưu hóa khác nhau của BIP, và sẽ điều tra hiệu suất của đề xuất của chúng tôi cho tăng tốc phần cứng thực tế.

## Lời cảm ơn

Công trình của Y. Zhang, Y. Yao, và S. Liu được hỗ trợ một phần bởi Quỹ Khoa học Quốc gia (NSF) Grant IIS-2207052 và Cisco Research Award. Công trình của M. Hong được hỗ trợ bởi các grant NSF CIF-1910385 và CMMI-1727757. Công trình của Y. Wang được hỗ trợ grant NSF CCF-1919117. Các tài nguyên tính toán được sử dụng trong công trình này cũng được hỗ trợ bởi MIT-IBM Watson AI Lab, IBM Research và Institute for Cyber-Enabled Research (ICER) tại Michigan State University.

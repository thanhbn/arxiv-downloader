# 2306.01526.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/pruning/2306.01526.pdf
# Kích thước tệp: 18664045 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Bản thảo không tên số
(sẽ được chèn bởi biên tập viên)
Cắt tỉa kênh nhóm và chưng cất chú ý không gian
cho phát hiện đối tượng
Yun Chu ·Pu Li ·Yong Bai ·Zhuhua
Hu ·Yongqing Chen ·Jiafeng Lu
Nhận: ngày 2021.09 / Chấp nhận: 2022.03
Tóm tắt Do tham số hóa quá mức của mạng nơ-ron, nhiều phương pháp nén mô hình dựa trên cắt tỉa và lượng tử hóa đã xuất hiện. Chúng rất đáng chú ý trong việc giảm kích thước, số lượng tham số và độ phức tạp tính toán của mô hình. Tuy nhiên, hầu hết các mô hình được nén bằng các phương pháp như vậy cần sự hỗ trợ của phần cứng và phần mềm đặc biệt, điều này làm tăng chi phí triển khai. Hơn nữa, các phương pháp này chủ yếu được sử dụng trong các tác vụ phân loại, và hiếm khi được sử dụng trực tiếp trong các tác vụ phát hiện. Để giải quyết những vấn đề này, đối với mạng phát hiện đối tượng, chúng tôi giới thiệu một phương pháp nén mô hình ba giai đoạn: huấn luyện thưa động, cắt tỉa kênh nhóm và chưng cất chú ý không gian. Đầu tiên, để chọn ra các kênh không quan trọng trong mạng và duy trì sự cân bằng tốt giữa độ thưa và độ chính xác, chúng tôi đưa ra một phương pháp huấn luyện thưa động, giới thiệu tỷ lệ thưa biến đổi, và tỷ lệ thưa sẽ thay đổi theo quá trình huấn luyện của mạng. Thứ hai, để giảm ảnh hưởng của việc cắt tỉa đến độ chính xác của mạng, chúng tôi đề xuất một phương pháp cắt tỉa mới gọi là cắt tỉa kênh nhóm. Cụ thể, chúng tôi chia mạng thành nhiều nhóm theo thang đo của lớp đặc trưng và sự tương tự của cấu trúc mô-đun trong mạng, và sau đó chúng tôi sử dụng các ngưỡng cắt tỉa khác nhau để cắt tỉa các kênh trong mỗi nhóm. Cuối cùng, để khôi phục độ chính xác của mạng đã được cắt tỉa, chúng tôi sử dụng một phương pháp chưng cất kiến thức cải tiến cho mạng đã được cắt tỉa. Đặc biệt, chúng tôi trích xuất thông tin chú ý không gian từ các bản đồ đặc trưng của các thang đo cụ thể trong mỗi nhóm làm kiến thức để chưng cất. Trong các thí nghiệm, chúng tôi sử dụng YOLOv4 làm mạng phát hiện đối tượng và PASCAL VOC làm tập dữ liệu huấn luyện. Phương pháp của chúng tôi giảm các tham số của mô hình 64,7% và tính toán 34,9%. Khi kích thước hình ảnh đầu vào là 416×416, so với mô hình mạng gốc với kích thước 256MB và độ chính xác 87,1, mô hình nén của chúng tôi đạt được độ chính xác 86,6 với kích thước 90MB. Để chứng minh tính tổng quát của phương pháp chúng tôi, chúng tôi thay thế xương sống thành Darknet53 và Mobilenet và cũng đạt được kết quả nén thỏa mãn.
Yun Chu, Yong Bai, Zhuhua Hu, Yongqing Chen, Jiafeng Lu thuộc Trường Kỹ thuật Thông tin và Truyền thông, Đại học Hainan, Haikou, 570288, Trung Quốc
·Pu Li thuộc Trường Phần mềm và Vi điện tử, Đại học Bắc Kinh, Bắc Kinh, 100871, Trung Quốc.
Thư từ nên được gửi đến Yong Bai, E-mail: bai@hainanu.edu.cnarXiv:2306.01526v1 [cs.CV] 2 Jun 2023

--- TRANG 2 ---
2 Yun Chu et al.
Từ khóa nén mô hình ·phát hiện đối tượng ·cắt tỉa kênh nhóm ·
chưng cất kiến thức
1 Giới thiệu
Trong những năm gần đây, CNN (Mạng Nơ-ron Tích chập) đã trở thành các phương pháp thống trị cho các tác vụ thị giác máy tính khác nhau, chẳng hạn như phân loại hình ảnh [1], phát hiện đối tượng [2] và phân đoạn [3]. Các mạng phân loại bao gồm AlexNet [4], ResNet [5], MobileNets [6], và các mạng phát hiện đối tượng bao gồm Faster-RCNN [7], SSD [8], YOLOv3 ∼v4 [9], [10]. Các mô hình mạng nơ-ron cho những tác vụ đó đã phát triển từ 8 lớp đến hơn 100 lớp.

Mặc dù các mạng lớn có khả năng biểu diễn đặc trưng mạnh mẽ, chúng tiêu thụ nhiều tài nguyên hơn. Ví dụ, độ sâu của mạng YOLOv4 đạt 162 lớp, kích thước của mô hình là 256 MB, và số lượng tham số là 64 triệu. Khi xử lý một hình ảnh có kích thước 416 ×416, nó cần 29G FLOPs (Phép Toán Dấu Phẩy Động Mỗi Giây), và các biến trung gian sẽ chiếm nhiều bộ nhớ hơn. Xem xét kích thước của mô hình, bộ nhớ cần thiết cho suy luận và lượng tính toán là không thể chịu đựng được đối với các thiết bị nhúng có tài nguyên hạn chế.

Để giải quyết vấn đề triển khai mạng nơ-ron trong thiết bị di động hoặc nhúng, nhiều công trình nén mô hình dựa trên cắt tỉa, lượng tử hóa, chưng cất kiến thức và các phương pháp thiết kế mạng nhẹ. Trong công việc cắt tỉa, các phương pháp cắt tỉa dựa trên mức trọng số đã được đề xuất [11] và [12] để giảm số lượng tham số của mô hình mà không ảnh hưởng đến độ chính xác của mạng. Tuy nhiên, các mô hình được cắt tỉa dựa trên mức trọng số yêu cầu bộ tăng tốc phần cứng đặc biệt để được triển khai, chẳng hạn như [13]. Để tiết kiệm chi phí triển khai, các phương pháp cắt tỉa dựa trên mức bộ lọc đã được đề xuất trong [14], [15], và những phương pháp này sẽ không yêu cầu hỗ trợ phần cứng đặc biệt. Trong công việc lượng tử hóa, mạng nhị phân và mạng tam phân đã được đề xuất lần lượt trong [16] và [17]. Trong [18] và [19], họ kết hợp cắt tỉa với lượng tử hóa và áp dụng nó cho mạng phân loại. Trong công việc [19], thông tin của các tham số được đào tạo trước được sử dụng để gán tỷ lệ nén của mỗi lớp, và phương pháp sách mã chia sẻ được sử dụng để lượng tử hóa và họ đạt được hiệu quả nén tốt. Mặc dù mạng lượng tử hóa bit thấp có thể giảm kích thước của mô hình, chúng mang lại tổn thất độ chính xác lớn và thường cần thư viện tăng tốc phần mềm đặc biệt để hỗ trợ triển khai. Các nghiên cứu cắt tỉa và lượng tử hóa trên chủ yếu được sử dụng trong các mạng phân loại, và không có nhiều nghiên cứu về việc áp dụng chúng cho các mạng phát hiện.

Cắt tỉa và lượng tử hóa là để nén cấu trúc mạng và tham số hiện có. Ngược lại, chưng cất kiến thức và thiết kế mạng nhẹ tối ưu hóa hoặc trực tiếp thiết kế cấu trúc mạng mới, nghĩa là tránh tổn thất độ chính xác do cắt tỉa hoặc lượng tử hóa gây ra. Chưng cất kiến thức là một cách tiếp cận để cải thiện hiệu suất của mạng học sinh bằng cách sử dụng mạng giáo viên. Hinton lần đầu tiên áp dụng ý tưởng chưng cất cho mạng phân loại [20]. Sau đó, chưng cất kiến thức đã được sử dụng rộng rãi trong thị giác máy tính [21], [22], [23], xử lý ngôn ngữ tự nhiên [24], nhận dạng giọng nói [25]. Mặc dù chưng cất kiến thức có thể cải thiện hiệu suất của mạng học sinh ở một mức độ nhất định, hiệu quả của nó trong việc giảm tham số và kích thước của mô hình còn xa so với cắt tỉa.

--- TRANG 3 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 3
Hơn nữa, cách thể hiện kiến thức được chưng cất giữa mạng giáo viên và mạng học sinh là một vấn đề. Sự khác biệt cấu trúc giữa mạng giáo viên và mạng học sinh có ảnh hưởng lớn đến hiệu quả chưng cất. Trong [26] chưng cất kiến thức được kết hợp với học biểu diễn để giảm ảnh hưởng của sự khác biệt cấu trúc đến chưng cất. Công việc [27] đưa ra tham chiếu để sử dụng học biểu diễn để giải quyết vấn đề căn chỉnh khung nhìn một phần. [28] trình bày một phương pháp học có giám sát yếu trong phát hiện đối tượng, phương pháp này chỉ yêu cầu nhãn hình ảnh và số đếm của các đối tượng của mỗi lớp trong hình ảnh, bằng sự kết hợp này tạo ra một định vị rõ ràng của các đối tượng trong khung cảnh thông qua kỹ thuật che mặt nạ giữa bản đồ kích hoạt lớp và bản đồ kích hoạt hồi quy, những công việc này có thể giải quyết vấn đề biểu diễn kiến thức trong chưng cất ở một mức độ nào đó. Thiết kế mạng nhẹ là thiết kế trực tiếp các mạng hoặc mô-đun nhỏ, bài báo [29] trình bày một ứng dụng mạng nhẹ trong các tác vụ phát hiện đối tượng, bao gồm mô-đun đặc trưng chú ý để cải thiện độ chính xác mạng, mô-đun kênh không đổi để tiết kiệm chi phí truy cập bộ nhớ. Hai kiến trúc mã hóa-giải mã nhẹ khác nhau cho các tác vụ phân đoạn ngữ nghĩa đã được đề xuất lần lượt trong [30] và [31], công việc trước up-sample các đặc trưng tích chập của lớp sâu đến các lớp giải tích chập nông để tăng cường các gợi ý ngữ cảnh, và công việc sau sử dụng các mô-đun chia tách và xáo trộn kênh trong bộ mã hóa để giảm số lượng tham số, và giới thiệu một mô-đun chú ý trong bộ giải mã để cải thiện độ chính xác. Bằng cách thiết kế trực tiếp các mô-đun nhẹ, có thể đạt được sự cân bằng tốt giữa độ chính xác và kích thước của mô hình, những mạng nhẹ này có thể được kết hợp tốt với các tác vụ trong lái xe tự động, như [32]. Những mô-đun hoặc mạng được thiết kế tốt như vậy [33], [34], [35], [36], [37], thường có thể chạy trên các máy chủ phòng thí nghiệm. Tuy nhiên, nếu chúng ta muốn triển khai thành công những mạng này trên các thiết bị biên, cần rất nhiều thí nghiệm và sửa đổi để xác minh hiệu quả của chúng. Trước khi mạng được triển khai đến thiết bị biên, các tham số và mạng cần được lượng tử hóa và biên dịch. Thông thường, một số mô-đun hoặc lớp mạng sáng tạo không thể được biên dịch và thông qua (do hạn chế của tập lệnh và các toán tử cơ bản trên thiết bị phần cứng), điều này cản trở việc triển khai những mạng nhẹ này đến các thiết bị biên và giảm tính linh hoạt của những mô-đun này.

Trong tác vụ phát hiện đối tượng, nén mô hình chủ yếu được thực hiện bằng chưng cất kiến thức, và có ít công việc kết hợp cắt tỉa với chưng cất kiến thức. Tóm lại, các công việc nén mô hình hiện có có những hạn chế sau: 1. Hầu hết các mô hình cắt tỉa và lượng tử hóa cần hỗ trợ mạch phần cứng đặc biệt hoặc thư viện tăng tốc phần mềm, điều này làm tăng chi phí triển khai những mô hình này đến thiết bị biên. 2. Trong các mạng phát hiện đối tượng, các phương pháp nén mô hình chủ yếu được thực hiện bằng chưng cất kiến thức, và hiệu quả nén không thỏa mãn. Cắt tỉa được sử dụng rộng rãi trong mạng phân loại nhưng được áp dụng trực tiếp trong phát hiện đối tượng.

Để giải quyết các vấn đề trên, chúng tôi đề xuất một phương pháp nén mô hình ba giai đoạn cho các tác vụ phát hiện đối tượng: huấn luyện thưa động, cắt tỉa kênh nhóm và chưng cất chú ý không gian. Như được hiển thị trong Hình 1, chúng tôi mô tả ngắn gọn việc thực hiện phương pháp nén mô hình ba giai đoạn được đề xuất.

Đầu tiên, chúng tôi huấn luyện mạng một cách thưa thớt. Huấn luyện thưa là để làm cho phân phối của hệ số γ trong lớp BN gần bằng 0, và sau đó giá trị của hệ số γ được sử dụng làm yếu tố quy mô tầm quan trọng của kênh để chọn ra các kênh không đáng kể trong mạng. Phương pháp huấn luyện thưa truyền thống sử dụng một

--- TRANG 4 ---
4 Yun Chu et al.
Hình 1: Sơ đồ quy trình của nén mô hình ba giai đoạn: huấn luyện thưa động, cắt tỉa kênh nhóm và chưng cất chú ý không gian.
tỷ lệ thưa không đổi trong quá trình huấn luyện, điều này tốn thời gian và khó tạo ra sự cân bằng tốt giữa độ thưa và độ chính xác của mạng. Do đó, chúng tôi giới thiệu một tỷ lệ thưa biến đổi để tăng tốc huấn luyện thưa của mạng và đạt được sự cân bằng tốt giữa độ thưa và độ chính xác của mạng, chi tiết ở Phần 4.1

Tiếp theo, chúng tôi cắt tỉa mạng. Hầu hết các phương pháp cắt tỉa truyền thống được sử dụng trong các mạng phân loại, và tất cả các kênh trong mạng được cắt tỉa với cùng một ngưỡng. Ngược lại, chúng tôi chia mạng phát hiện thành nhiều nhóm. Trong việc nhóm, chúng tôi chủ yếu xem xét quy mô của các lớp đặc trưng và sự tương tự của cấu trúc mô-đun trong mạng, các lớp đặc trưng có cùng quy mô và các lớp có cấu trúc mô-đun tương tự được gán vào cùng một nhóm. Sau đó, mỗi nhóm thu được ngưỡng cắt tỉa theo tỷ lệ cắt tỉa của nhóm hiện tại, sau đó chúng tôi cắt tỉa các kênh theo ngưỡng cắt tỉa trong mỗi nhóm, do đó đạt được việc cắt tỉa chính xác và hiệu quả hơn của mạng phát hiện, chi tiết ở Phần 4.2.

Cuối cùng, khi cắt tỉa kênh của mạng phát hiện, chúng tôi nhận thấy rằng với sự gia tăng của loại phát hiện và tỷ lệ cắt tỉa, việc cắt tỉa sẽ mang lại tổn thất độ chính xác lớn hơn cho mô hình. Để khôi phục độ chính xác của mạng sau khi cắt tỉa nhóm, chúng tôi giới thiệu chưng cất kiến thức cho mạng đã được cắt tỉa. Đặc biệt, chúng tôi trích xuất thông tin chú ý không gian từ các bản đồ đặc trưng của các quy mô cụ thể trong mỗi nhóm làm kiến thức và chưng cất mạng đã được cắt tỉa, chi tiết ở Phần 4.3.

Theo hiểu biết tốt nhất của chúng tôi, công việc kết hợp cắt tỉa với chưng cất chú ý không gian và áp dụng nó cho các tác vụ phát hiện đối tượng hiện tại hiếm khi được khám phá.
Những đóng góp chính của bài báo này được tóm tắt như sau:
1) Để cải thiện hiệu quả của huấn luyện thưa, chúng tôi thiết kế một phương pháp huấn luyện thưa động sử dụng tỷ lệ thưa biến đổi để tăng tốc quá trình huấn luyện thưa, mạng đạt được sự cân đối tốt hơn giữa độ thưa và độ chính xác.
2) Đối với mạng phát hiện đối tượng, chúng tôi đề xuất một phương pháp cắt tỉa mới, gọi là cắt tỉa kênh nhóm. Chúng tôi chia mạng phát hiện thành nhiều nhóm. Trong quá trình nhóm, chúng tôi xem xét toàn diện quy mô của các lớp đặc trưng và sự tương tự của cấu trúc mô-đun trong mạng. Sau đó, mỗi nhóm thu được ngưỡng cắt tỉa theo các tỷ lệ cắt tỉa khác nhau, sau đó chúng tôi cắt tỉa các kênh trong mỗi nhóm để đạt được việc cắt tỉa chính xác và hiệu quả hơn của mạng phát hiện.
3) Để khôi phục độ chính xác của mô hình mạng cắt tỉa, chúng tôi giới thiệu chưng cất kiến thức cho mạng sau khi cắt tỉa nhóm. Cụ thể, chúng tôi trích xuất thông tin chú ý không gian chỉ từ các bản đồ đặc trưng của các quy mô cụ thể trong mỗi nhóm làm kiến thức và chưng cất mạng đã được cắt tỉa. Hơn nữa, chúng tôi chứng minh rằng phương pháp chưng cất của chúng tôi không chỉ phù hợp với phương pháp cắt tỉa của chúng tôi mà còn có thể kết hợp với các phương pháp cắt tỉa phổ biến khác.

--- TRANG 5 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 5
4) Chúng tôi tiến hành các thí nghiệm mở rộng trên tập dữ liệu PASCAL VOC với mạng YOLOV4 để xác minh hiệu quả của phương pháp được đề xuất. Để chứng minh tính tổng quát của phương pháp chúng tôi, chúng tôi cũng sử dụng Darknet53 và Mobilenet làm xương sống để xây dựng mạng phát hiện, kết quả thí nghiệm cho thấy phương pháp của chúng tôi có khả năng áp dụng khác. Ngoài ra, chúng tôi triển khai mô hình nén trên thiết bị biên Jetson nano, điều này chứng minh rằng mô hình nén của chúng tôi có thể được triển khai mà không cần hỗ trợ phần cứng đặc biệt và có thể đạt được hiệu quả tăng tốc.

2 Công việc liên quan
Trong phần này, chúng tôi đánh giá ngắn gọn các công việc liên quan về cắt tỉa và chưng cất kiến thức.

2.1 Cắt tỉa mạng
Ý tưởng của cắt tỉa là giảm dư thừa của cấu trúc và tham số trong mạng nơ-ron để mạng trở nên nhẹ hơn và hiệu quả hơn. Nghiên cứu về cắt tỉa tập trung vào hai khía cạnh. Một là loại đối tượng nào trong mạng có thể được cắt tỉa, và khía cạnh khác là cách đo lường tầm quan trọng của nội dung được cắt tỉa. Từ góc độ đối tượng được cắt tỉa, phương pháp cắt tỉa hiện tại có thể được chia thành cắt tỉa không có cấu trúc và cắt tỉa có cấu trúc. Cắt tỉa không có cấu trúc đề cập đến việc cấu trúc tôpô của mạng trở nên bất thường và không có cấu trúc sau khi mạng được cắt tỉa, và chúng thường cắt tỉa các trọng số kết nối giữa các nơ-ron. Ví dụ, trong [11] và [12], giá trị tuyệt đối của trọng số được lấy làm thước đo cho việc cắt tỉa của nó. Ưu điểm của cắt tỉa không có cấu trúc là tỷ lệ cắt tỉa có thể đạt mức cao mà không ảnh hưởng đến độ chính xác của mạng. Nhược điểm là nó cần sự hỗ trợ của các mạch phần cứng đặc biệt, điều này làm tăng chi phí triển khai.

Cắt tỉa có cấu trúc có nghĩa là cấu trúc tôpô mạng không thay đổi sau khi cắt tỉa. Thường cắt tỉa ở mức bộ lọc [38], kênh [39], lớp [40]. Công việc trong [38] cắt tỉa bộ lọc không quan trọng trong lớp hiện tại bằng cách tính toán thông tin thống kê của lớp tiếp theo. Liu et al [39] đề xuất một phương pháp cắt tỉa kênh có cấu trúc cho các mạng phân loại, và mô hình nén không yêu cầu hỗ trợ phần cứng và phần mềm đặc biệt. Công việc trong [40] sử dụng phương pháp chiếu không gian con để đo lường tầm quan trọng của lớp mạng, cắt tỉa lớp trong mạng, và xác minh rằng cắt tỉa lớp tốt hơn cắt tỉa bộ lọc trong việc sử dụng tài nguyên. Ưu điểm của phương pháp cắt tỉa có cấu trúc là mạng sau khi cắt tỉa không cần sự hỗ trợ của các mạch phần cứng đặc biệt, và nhược điểm là tỷ lệ cắt tỉa không thể đạt rất cao.

Suy nghĩ lại Giá trị của Cắt tỉa Mạng [41] đã thảo luận về ý nghĩa của cắt tỉa mạng. Công việc của họ chỉ ra rằng vai trò mà cắt tỉa đóng tương tự như tìm kiếm kiến trúc mạng (NAS). Sau đó, [42] đưa ý tưởng của NAS vào cắt tỉa, đề xuất một mô-đun chuẩn hóa batch để đo lường tầm quan trọng của mỗi cấu trúc trong mạng, và sử dụng phương pháp cắt tỉa NAS này cho mạng phân loại. Trong bài báo này, chúng tôi kế thừa ý tưởng huấn luyện thưa trong [39], khác với điều đó, chúng tôi giới thiệu tỷ lệ thưa biến đổi để tiến hành huấn luyện thưa động trên mạng, điều này cải thiện sự cân đối giữa độ thưa và độ chính xác của mạng.

--- TRANG 6 ---
6 Yun Chu et al.

2.2 Chưng cất kiến thức
Mục đích của chưng cất kiến thức là chuyển giao kiến thức học được từ mạng giáo viên sang mạng học sinh để cải thiện hiệu suất của mạng học sinh. Nghiên cứu về chưng cất kiến thức tập trung vào hai khía cạnh. Một là đối tượng nào trong mạng được chọn làm kiến thức. Khía cạnh khác là cách đo lường xem mạng học sinh có học được kiến thức hay không, điều này được phản ánh trong cách thiết kế hàm mất mát của chưng cất. Liên quan đến việc chọn gì làm kiến thức, các phương pháp chưng cất hiện tại có thể được chia thành ba loại: 1. Sử dụng thông tin lớp cuối cùng đầu ra của mạng giáo viên làm kiến thức như trong [43], [44], [45]. 2. Sử dụng lớp đặc trưng giữa của mạng giáo viên làm kiến thức như trong [46], [47]. 3. Sử dụng mối quan hệ cấu trúc giữa các lớp của mạng giáo viên làm kiến thức như trong [24]. Trong mạng phân loại, [47] đề xuất trích xuất sự chú ý từ lớp đặc trưng và biểu hiện thông tin chú ý trong bản đồ nhiệt. Sau đó, hàm mất mát được xây dựng sử dụng sự chú ý của mạng giáo viên và mạng học sinh.

Tìm kiếm để Chưng cất: [48] đã giới thiệu phương pháp chưng cất kiến thức vào NAS, và thu được những kết luận sau thông qua thí nghiệm, cấu trúc của mạng học sinh xác định giới hạn trên mà hiệu quả chưng cất có thể đạt được, và hiệu quả chưng cất tốt hơn khi cấu trúc mạng của học sinh và giáo viên tương tự. Được truyền cảm hứng từ công việc nghiên cứu trên, chúng tôi kết hợp cắt tỉa với chưng cất kiến thức. Trong bài báo này, ý tưởng chưng cất của chúng tôi được truyền cảm hứng từ [47], và chúng tôi đã cải tiến phương pháp để làm cho nó phù hợp với phát hiện đối tượng. Đặc biệt, chúng tôi trích xuất chú ý không gian từ các lớp đặc trưng của mỗi nhóm và đưa cho mỗi nhóm chú ý không gian với các trọng số khác nhau để chưng cất.

3 Kiến trúc Mạng
Bài báo này lấy YOLOv4 làm ví dụ để minh họa các phương pháp cắt tỉa và chưng cất của chúng tôi. Phương pháp cắt tỉa của chúng tôi có thể được áp dụng cho các mạng có mô-đun BN. Trong phần này, chúng tôi giới thiệu ngắn gọn năm thành phần cơ bản cốt lõi của mạng và kiến trúc tổng thể của mạng.

3.1 Các thành phần cơ bản
Như được hiển thị trong Hình 2, năm mô-đun là CBM, Res Unit, CSP X, CBL, và SPP.

--- TRANG 7 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 7
Hình 2: Năm mô-đun cơ bản của Mạng YOLOv4.

Trong số đó, mô-đun CBM được cấu thành từ Conv, Batch Normalization [49] và hàm kích hoạt Mish [50]. Res Unit được cấu thành từ CBM và các phép toán cộng, trong đó khối res được dẫn xuất từ [5]. Mô-đun CSP X được cấu thành từ CBM, X Res units, và các phép toán nối. Mô-đun CBL được cấu thành từ Conv, BN, và Leaky-Relu [51]. Spatial pyramid pooling (SPP) được đề xuất trong [52], ở đây SPP đề cập đến việc hợp nhất đặc trưng bằng pooling ở bốn thang đo: 1 ×1, 5×5, 9×9, 13×13.

3.2 Mạng Phát hiện
Thông qua năm thành phần cơ bản trên tạo thành ba phần của YOLOv4, tức là mạng xương sống, mạng tăng cường đặc trưng, và đầu phát hiện. Ba phần này có tổng cộng 162 lớp. Đầu tiên, mạng xương sống được sử dụng để trích xuất đặc trưng của đối tượng. Sau đó, mạng tăng cường đặc trưng tiếp tục hợp nhất và tăng cường các đặc trưng. Cuối cùng, đầu phát hiện chịu trách nhiệm phân loại các đặc trưng đầu vào và trả về vị trí và kích thước của mục tiêu.
Như được hiển thị trong Hình 3, khi kích thước đầu vào là 416 ×416, các bản đồ đặc trưng down-sampling 8, 16, 32 lần được thu được thông qua mạng xương sống, cụ thể, các bản đồ đặc trưng ở các thang đo 52 ×52, 26×26, 13×13, và sau đó những bản đồ đặc trưng này được đưa vào mạng tăng cường đặc trưng. Cuối cùng, đầu phát hiện đưa ra dự đoán ở ba thang đo.

--- TRANG 8 ---
8 Yun Chu et al.
Hình 3: Chia YOLOv4 thành năm nhóm. Trong biểu đồ, hộp đường chấm màu xanh chứa ba phần chính của mạng, các hộp đường chấm màu đỏ đại diện cho năm nhóm. Khi nhóm, chúng tôi xem xét toàn diện quy mô của các lớp đặc trưng và sự tương tự của cấu trúc mô-đun trong mạng. Ví dụ, khi kích thước hình ảnh đầu vào là 416 ×416, nhóm1: bao gồm các thang đo của lớp đặc trưng từ 416×416 đến 52 ×52 và mô-đun CSP, nhóm2: chỉ bao gồm lớp đặc trưng ở thang đo 26×26 cùng với mô-đun CSP, nhóm3: chỉ bao gồm lớp đặc trưng ở thang đo 13×13 cùng với mô-đun CSP và CBL, tương tự cho nhóm4 và nhóm5. Lưu ý rằng, mô-đun CSP bao gồm mô-đun CBM như được hiển thị trong Hình 2, SPP, Concat, Upsample, và Downsample những mô-đun này chỉ thực hiện tính toán, chúng không chứa các tham số có thể huấn luyện.

4 Phương pháp được đề xuất
Trong phần này, chúng tôi mô tả chi tiết phương pháp nén mô hình ba giai đoạn được đề xuất. Đầu tiên, chúng tôi huấn luyện mạng một cách thưa thớt với tỷ lệ thưa động. Sau đó, mạng phát hiện đối tượng được chia thành năm nhóm, và mỗi nhóm sử dụng các ngưỡng khác nhau để cắt tỉa kênh. Sau đó, sử dụng mạng đã được cắt tỉa làm mạng học sinh để chưng cất kiến thức, các chi tiết được mô tả như sau.

4.1 Huấn luyện Thưa Động
Mục đích của huấn luyện thưa là chọn ra các kênh không đáng kể trong lớp mạng. Tham khảo [39], chúng tôi sử dụng γ làm yếu tố quan trọng của kênh. Phân phối của các hệ số γ của tất cả các lớp BN trong mạng gốc nằm trong các phạm vi khác nhau. Huấn luyện thưa là để làm thưa hệ số γ, làm cho phân phối của hệ số γ gần bằng không. Giá trị γ nhỏ hơn cho thấy tầm quan trọng thấp hơn của kênh tương ứng. Như được hiển thị trong (1), γ là tham số quy mô của lớp BN, β là tham số offset của lớp BN, giá trị của γ và β được thu được bằng cách huấn luyện mạng.

yi=γˆxi+β, ˆxi=xi−µBp
σ2
B+ε, (1)

trong đó ˆxi biểu thị đầu ra chuẩn hóa của một kênh, và yi biểu thị đầu ra của ˆxi sau khi chia tỷ lệ γ và dịch chuyển β. xi biểu thị một kênh được chỉ định trên lớp đặc trưng. Như được hiển thị trong (2), µB là giá trị trung bình của kênh được chỉ định dưới số batch-size, σ2B là phương sai của kênh được chỉ định dưới số batch-size. Để ngăn mẫu số bằng 0, ε có thể được đặt giá trị ở 1e-16.

µB=1/m ∑(i=1 to m) xi, σ2B=1/m ∑(i=1 to m) (xi−µB)2, (2)

Trong quá trình huấn luyện thưa động, chuẩn L1 của γ được sử dụng làm hạng mục chính quy hóa, và tỷ lệ thưa biến đổi sd được giới thiệu, được thêm vào hàm mất mát để huấn luyện, như được hiển thị trong (3).

L = ∑(x,y) l(f(x, W), y) + sd ∑(γ∈Γ) g(γ), (3)

trong đó (x, y) đại diện cho đầu vào của mạng và nhãn của dữ liệu, W đại diện cho các tham số có thể được huấn luyện, và hạng mục tổng đầu tiên đại diện cho mất mát gốc trong quá trình huấn luyện mạng CNN. Tổng thứ hai, g(γ) đại diện cho hạng mục chính quy hóa được giới thiệu, chúng tôi sử dụng g(γ) = |γ|. sd là tỷ lệ thưa biến đổi. Trong quá trình huấn luyện, mạng sẽ điều chỉnh động tỷ lệ thưa của nó theo số epoch của quá trình huấn luyện hiện tại. Khi huấn luyện đến một nửa số epoch, 70% kênh duy trì tỷ lệ thưa ban đầu, 30% kênh tỷ lệ thưa giảm xuống 1% của tỷ lệ thưa ban đầu, để mạng huấn luyện cuối cùng đạt được sự cân bằng tốt giữa độ thưa và độ chính xác.

4.2 Cắt tỉa kênh nhóm
Trong phần này, chúng tôi tập trung vào phương pháp cắt tỉa kênh nhóm được đề xuất. Nó có thể được chia thành ba bước. Đầu tiên, chúng tôi chia cấu trúc của mạng phát hiện đối tượng thành năm nhóm. Thứ hai, chúng tôi thu được năm ngưỡng cắt tỉa khác nhau theo tỷ lệ cắt tỉa của mỗi nhóm và sau đó tạo ma trận mặt nạ cắt tỉa cho hầu hết các lớp tích chập trong mỗi nhóm, được sử dụng để cắt tỉa các kênh trong lớp tích chập. Cuối cùng, chúng tôi tạo ma trận mặt nạ cắt tỉa công cộng cho các lớp tích chập liên kết với các lớp shortcut.

--- TRANG 9 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 9

4.2.1 Nhóm mạng
Việc cắt tỉa kênh nhóm của chúng tôi là chia các lớp mạng phát hiện thành nhiều nhóm. Trong việc nhóm, chúng tôi xem xét toàn diện quy mô của các lớp đặc trưng và sự tương tự của cấu trúc mô-đun trong mạng có nghĩa là các lớp đặc trưng có cùng quy mô và các lớp có cấu trúc mô-đun tương tự được gán vào cùng một nhóm. Trong thí nghiệm, chúng tôi quan sát thấy rằng khi ngưỡng cắt tỉa thống nhất được sử dụng cho tất cả các cấu trúc, hai tình huống có hại sẽ xảy ra. Một là trong các cấu trúc có độ dư thừa cao, ngưỡng cắt tỉa thực tế cao hơn ngưỡng cắt tỉa thống nhất, và các kênh dư thừa trong những cấu trúc như vậy sẽ không được cắt tỉa. Trong trường hợp khác, trong cấu trúc có độ dư thừa thấp, ngưỡng cắt tỉa thực tế thấp hơn ngưỡng cắt tỉa thống nhất và các kênh đáng kể có thể được cắt tỉa trong cấu trúc này, điều này ảnh hưởng nghiêm trọng đến độ chính xác của mạng.

Để giải quyết vấn đề này, chúng tôi nhóm mạng phát hiện đối tượng trước. Như được hiển thị trong Hình 3, các hộp đường chấm màu xanh đại diện cho phần xương sống của mạng YOLOv4, phần tăng cường đặc trưng và phần phát hiện. Các hộp đường chấm màu đỏ đại diện cho năm nhóm. Khi đầu vào kích thước 416 ×416 hình ảnh vào mạng, nhóm1 bao gồm các thang đo của lớp đặc trưng từ 416 ×416 đến 52 ×52 và mô-đun CSP, nhóm2 chỉ bao gồm lớp đặc trưng ở thang đo 26 ×26 cùng với mô-đun CSP, nhóm3 chỉ bao gồm lớp đặc trưng ở thang đo 13 ×13 cùng với mô-đun CSP và CBL, nhóm4 và nhóm5 đều bao gồm lớp đặc trưng từ thang đo 52 ×52 đến thang đo 13 ×13 và mô-đun CBL, tuy nhiên, để cắt tỉa chính xác hơn, chúng tôi chia hai phần này thành hai nhóm. Bên cạnh đó, mô-đun CSP bao gồm mô-đun CBM như được hiển thị trong Hình 2. SPP, Concat, Upsample, và Downsample những mô-đun này chỉ là các toán tử, chúng không chứa các tham số có thể huấn luyện.

Ba nhóm đầu tiên, Nhóm1 ∼3 thuộc về mạng xương sống và chịu trách nhiệm trích xuất các đặc trưng của đối tượng, ba nhóm này chứa tất cả các mô-đun residual trong mạng. Nhóm4 thuộc về mạng tăng cường đặc trưng, chịu trách nhiệm tăng cường và hợp nhất các đặc trưng hơn nữa. Nhóm5 bao gồm phần đầu phát hiện thực hiện việc phân loại các đặc trưng và hồi quy vị trí đối tượng.

4.2.2 Ngưỡng cắt tỉa và ma trận mặt nạ
Do độ dư thừa khác nhau trong năm nhóm, chúng tôi cần thu được năm ngưỡng cắt tỉa và một ma trận mặt nạ cắt tỉa từ năm nhóm. Ở đây chúng tôi minh họa các bước sử dụng một nhóm. Đầu tiên, chúng tôi tính tỷ lệ số kênh trong nhóm hiện tại so với tổng số kênh có thể được cắt tỉa trong toàn bộ mạng, chúng tôi ký hiệu tỷ lệ này là pi. Sau đó, với tỷ lệ cắt tỉa tổng của toàn bộ mạng được cho, chúng tôi ký hiệu nó là P. Bằng cách nhân pi với P, chúng tôi có thể thu được tỷ lệ cắt tỉa của nhóm hiện tại, ký hiệu là gi. Sau đó, chúng tôi sắp xếp tất cả các hệ số γ trong nhóm đó, theo tỷ lệ cắt tỉa của nhóm hiện tại (gi) chúng tôi có thể nhận được ngưỡng cắt tỉa của nhóm hiện tại (ký hiệu là ti). Cuối cùng, chúng tôi sử dụng ngưỡng cắt tỉa ti để so sánh với tất cả các hệ số γ trong nhóm này để thu được ma trận mặt nạ cắt tỉa của các lớp tích chập, trong ma trận mặt nạ cắt tỉa đó, số 1 đại diện cho kênh ở vị trí tương ứng được giữ lại, và số 0 đại diện cho kênh ở vị trí tương ứng sẽ được cắt tỉa.

--- TRANG 10 ---
10 Yun Chu et al.
Như được hiển thị trong Hình 4, chúng tôi sử dụng hệ số γ làm yếu tố quy mô của kênh và so sánh yếu tố quy mô với ngưỡng cắt tỉa của nhóm hiện tại. Khi giá trị của yếu tố quy mô thấp hơn ngưỡng cắt tỉa, kênh tương ứng với yếu tố quy mô sẽ được cắt tỉa. Sử dụng phương pháp trên, chúng tôi thu được năm ngưỡng cắt tỉa và ma trận mặt nạ của lớp tích chập trong mỗi nhóm.

Hình 4: Hộp đường chấm màu đỏ đại diện cho lớp đặc trưng được gán cho nhóm I, hộp đường chấm màu xanh lá cây đại diện cho lớp tích chập bên cạnh lớp đặc trưng này. Cả hai đều nằm trong nhóm I, và trong nhóm này, tất cả các kênh sẽ chia sẻ cùng một ngưỡng cắt tỉa. Chúng tôi sử dụng γ làm yếu tố quy mô của kênh. Khi các yếu tố quy mô kênh thấp hơn ngưỡng cắt tỉa của nhóm hiện tại, các kênh tương ứng sẽ được cắt tỉa.

4.2.3 Ma trận mặt nạ công cộng
Ma trận mặt nạ cắt tỉa thu được bằng phương pháp trên có thể được sử dụng làm ma trận cắt tỉa cuối cùng của hầu hết các lớp tích chập trong mạng. Tuy nhiên, một lớp tích chập khác liên kết với lớp shortcut cần sử dụng ma trận cắt tỉa mặt nạ công cộng. Bởi vì số lượng kênh được cộng giữa hai lớp phải nhất quán trong lớp shortcut để thực hiện phép toán cộng. Xem xét rằng lớp nguồn của shortcut vẫn có thể là một lớp shortcut, điều này sẽ liên quan đến nhiều lớp tích chập về phía trước, và ma trận mặt nạ cắt tỉa của những lớp tích chập này cần phải nhất quán. Cách tạo ma trận cắt tỉa mặt nạ công cộng này để việc cắt tỉa kênh trong mỗi lớp tích chập đạt được lượng cao hơn và có ít ảnh hưởng đến độ chính xác. Đây là một câu hỏi đáng xem xét.

Để giải quyết câu hỏi như vậy, chúng tôi đề xuất một phương pháp bỏ phiếu để tạo ma trận mặt nạ cắt tỉa công cộng. Như được hiển thị trong Hình 5. Đầu tiên, chúng tôi đếm tổng số lớp tích chập liên kết với lớp shortcut và ký hiệu là Nconv. Sau đó chúng tôi đếm tổng số số không ở vị trí (i, j) trong ma trận mặt nạ cắt tỉa và ký hiệu là Z(i,j). Giá trị của ma trận mặt nạ công cộng ở vị trí (i, j) ký hiệu là p(i,j). Khi Z(i,j) ≥ (Nconv/2), thì p(i,j) = 0; ngược lại, p(i,j) = 1.

--- TRANG 11 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 11
Hình 5: Tạo ma trận mặt nạ cắt tỉa công cộng. Trong hình, Nconv biểu thị tổng số lớp tích chập liên kết với lớp shortcut. Z(i,j) biểu thị tổng số số không ở vị trí (i, j) trong ma trận mặt nạ cắt tỉa. p(i,j) biểu thị giá trị của ma trận mặt nạ công cộng ở vị trí (i, j). Nếu Z(i,j) ≥ (Nconv/2), thì p(i,j) = 0; ngược lại, p(i,j) = 1.

4.3 Mất mát chưng cất kiến thức
Trong phần này, chúng tôi giới thiệu ba phần của mất mát chưng cất. Như được hiển thị trong Hình 6, chúng tôi sử dụng mạng gốc làm mạng giáo viên, và mạng đã được cắt tỉa làm mạng học sinh để chưng cất kiến thức, mất mát chưng cất bao gồm ba phần: 1. Sự khác biệt trong chú ý không gian giữa mạng học sinh và mạng giáo viên ký hiệu là LAT; 2. Sự khác biệt giá trị dự đoán giữa mạng học sinh và mạng giáo viên trong phân loại đối tượng và hồi quy vị trí được ký hiệu là Lsoft; 3. Mất mát giữa giá trị dự đoán của mạng học sinh và ground truth được ký hiệu là Lhard.

Như trong (4), chúng tôi sử dụng Ltotal để đại diện cho tổng mất mát của mạng học sinh, và chúng tôi sẽ chủ yếu xem xét mất mát của LAT và Lsoft.

Ltotal = LAT + Lsoft + Lhard, (4)

--- TRANG 12 ---
12 Yun Chu et al.
Hình 6: Chưng cất cho mạng đã được cắt tỉa nhóm. QiT và QiS là thông tin chú ý không gian trích xuất từ các bản đồ đặc trưng của năm thang đo cụ thể trong mỗi nhóm của mạng giáo viên và học sinh, tương ứng. Ba hộp màu đỏ thể hiện ba phần mất mát của mạng học sinh. 1. LAT biểu thị sự khác biệt trong chú ý không gian giữa mạng học sinh và mạng giáo viên; 2. Lsoft biểu thị sự khác biệt giá trị dự đoán giữa mạng học sinh và mạng giáo viên trong phân loại đối tượng và hồi quy vị trí; 3. Lhard biểu thị mất mát giữa giá trị dự đoán của mạng học sinh và ground truth.

4.3.1 Mất mát chú ý không gian nhóm
Như trong (5), LAT biểu thị sự khác biệt trong thông tin chú ý không gian giữa mạng học sinh và mạng giáo viên. Chúng tôi giảm sự khác biệt này bằng cách cho phép mạng học sinh bắt chước chú ý không gian của mạng giáo viên.

LAT = ∑(i=1 to 5) βi ||QiT/||QiT||2 - QiS/||QiS||2||2, (5)

trong đó i thuộc 1 ∼5, đại diện cho năm nhóm trong mạng. Từ năm nhóm này, chúng tôi trích xuất chú ý không gian chỉ ở các bản đồ đặc trưng thang đo cụ thể làm kiến thức, các bản đồ đặc trưng thang đo là 208 ×208, 104 ×104, 52 ×52, 26 ×26 và 13 ×13, tương ứng, Chúng tôi trích xuất những bản đồ đặc trưng này từ năm nhóm. βi biểu thị hệ số tăng mất mát của năm nhóm, chúng tôi đưa cho chú ý không gian của nhóm khác nhau với trọng số khác nhau. QiT và QiS là các dạng tensor 1 chiều của chú ý không gian mạng giáo viên và học sinh, và mỗi phần tử trong Qi được chuẩn hóa.

--- TRANG 13 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 13
Như trong (6), Qi một chiều được chuyển đổi từ FAi hai chiều bằng phép toán làm phẳng. FAiT và FAiS là các dạng ma trận hai chiều của chú ý không gian trong mạng giáo viên và học sinh, tương ứng.

QiT = vec(FAiT), QiS = vec(FAiS), (6)

Hàm ánh xạ F(.) được đưa ra trong (7), trong đó A biểu thị bản đồ đặc trưng trên kênh, A có kích thước H ×W, và C đại diện cho số lượng tất cả các kênh trên lớp đặc trưng. Giá trị của p là 2, đại diện cho lũy thừa 2 cho mỗi phần tử trong A.

F(A) = Fpsum(A) = ∑(j=1 to c) |Aj|p, (7)

Chú ý không gian đề cập đến việc trích xuất thông tin không gian của tất cả các kênh trên một lớp đặc trưng nhất định dưới dạng bản đồ nhiệt. Quá trình trích xuất được hiển thị trong Hình 7. Một lớp đặc trưng được chọn từ mạng, và kích thước của lớp đặc trưng là C ×H×W. C đại diện cho số lượng kênh trên lớp đặc trưng. Thông qua hàm ánh xạ F: F: AC×H×W→AH×W, tensor lớp đặc trưng 3 chiều được ánh xạ thành tensor 2 chiều trên chiều kênh, đại diện cho bản đồ chú ý không gian của lớp đặc trưng.

Hình 7: Tạo bản đồ chú ý không gian từ lớp đặc trưng.

4.3.2 Mất mát mục tiêu mềm
Như trong (8), Lsoft được cấu thành từ hai loại khác biệt dự đoán. Một là sự khác biệt dự đoán của mạng giáo viên và học sinh trong phân loại đối tượng. Cái khác là sự khác biệt dự đoán của mạng giáo viên và học sinh trong vị trí và kích thước của hộp đối tượng.

Lsoft = l(t-s)(cls) + l(t-s)(box), (8)

--- TRANG 14 ---
14 Yun Chu et al.
l(t-s)(cls) biểu thị sự khác biệt dự đoán trong phân loại đối tượng giữa mạng giáo viên và mạng học sinh, như được hiển thị trong (9).

l(t-s)(cls) = 1/k ∑(i=1 to 3) ∑(j=1 to k) M(i,j) log M(i,j) - N(i,j), (9)

trong đó i biểu thị dự đoán của mạng ở ba thang đo, k biểu thị số lượng tất cả các hộp prior ở thang đo hiện tại. M(i,j) biểu thị đầu ra dự đoán của mạng giáo viên sau chưng cất. N(i,j) biểu thị đầu ra dự đoán của mạng học sinh sau chưng cất.

Như trong (10) (11), M(i,j), N(i,j) được thu được bằng hàm softmax và logsoftmax, trong đó P(i,j)t(cls) biểu thị xác suất phân loại được dự đoán cho mỗi hộp prior trong mạng giáo viên và P(i,j)s(cls) biểu thị xác suất phân loại được dự đoán cho mỗi hộp prior trong mạng học sinh. T là tham số nhiệt độ được sử dụng để làm cho phân phối đầu ra của dự đoán mạng giáo viên và học sinh đồng đều hơn.

M(i,j) = softmax(P(i,j)t(cls)/T), (10)
N(i,j) = log-softmax(P(i,j)s(cls)/T), (11)

Như trong (12), l(t-s)(box) biểu thị sự khác biệt dự đoán giữa mạng giáo viên và mạng học sinh về vị trí và kích thước của hộp đối tượng.

l(t-s)(box) = ∑(i=1 to 3) ∑(j=1 to k) ||P(i,j)t(box) - P(i,j)s(box)||2, (12)

trong đó i biểu thị dự đoán của mạng ở ba thang đo, và k biểu thị số lượng hộp ứng viên còn lại sau khi đáp ứng ngưỡng IOU ở thang đo hiện tại. Ở vị trí tương ứng với hộp ứng viên đối tượng, trong mạng học sinh vị trí và kích thước của hộp dự đoán được ký hiệu bởi P(i,j)s(box). Trong mạng giáo viên, vị trí và kích thước của hộp dự đoán được ký hiệu bởi P(i,j)t(box).

5 Thí nghiệm
Trong thí nghiệm, chúng tôi lấy mạng phát hiện YOLOv4 và tập dữ liệu PASCAL VOC làm ví dụ để minh họa và xác thực hiệu quả của việc nén mô hình được đề xuất. Đầu tiên, chúng tôi huấn luyện mạng một cách thưa thớt với tỷ lệ thưa động. Thứ hai, chúng tôi phân tích định lượng ảnh hưởng của các tỷ lệ cắt tỉa khác nhau đến kích thước mô hình, độ chính xác và tính toán. Sau đó, chúng tôi so sánh việc cắt tỉa nhóm của chúng tôi với các phương pháp cắt tỉa hiện tại khác trên tập dữ liệu phát hiện đối tượng. Cuối cùng, để chứng minh tính ưu việt của phương pháp chưng cất, chúng tôi so sánh độ chính xác của mạng đã được cắt tỉa sau khi fine-tuning và chưng cất. Hơn nữa, chúng tôi kết hợp phương pháp chưng cất của chúng tôi với các phương pháp cắt tỉa phổ biến khác để chứng minh rằng phương pháp chưng cất của chúng tôi phù hợp với các phương pháp cắt tỉa phổ biến khác.

--- TRANG 15 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 15

5.1 Tập dữ liệu và chỉ số đánh giá
Đối với tập dữ liệu, chúng tôi sử dụng Pascal VOC [53]. voc2012train, voc2012val, voc2007train, và voc2007val, bốn phần này có 16551 hình ảnh và chúng tôi kết hợp chúng sử dụng làm tập huấn luyện cuối cùng. voc2007test bao gồm 4952 hình ảnh và được sử dụng làm tập kiểm tra cuối cùng. Môi trường thí nghiệm của chúng tôi là Ubuntu 18.04, PyTorch = 1.8 version, GPU là một RTX3090 đơn. Đối với các chỉ số đánh giá, chúng tôi đánh giá hiệu suất của mô hình đã được cắt tỉa từ bốn khía cạnh: kích thước mô hình, số lượng tham số, lượng tính toán và mAP@0.5. Tính toán được đo bằng FLOPS. mAP@0.5 đại diện cho giá trị trung bình của tất cả các loại AP khi ngưỡng IOU là 0.5, AP đại diện cho độ chính xác trung bình của một loại, và các chi tiết tính toán cụ thể được tham khảo trong tài liệu tham khảo [54].

5.2 Huấn luyện Thưa Động
Trong quá trình huấn luyện thưa, chuẩn L1 của γ được thêm vào hàm mất mát làm hạng mục chính quy hóa để huấn luyện cùng nhau. Như được hiển thị trong Hình 8, phân phối của các hệ số γ của tất cả các lớp BN trong mạng gốc nằm trong các phạm vi khác nhau. Quá trình huấn luyện thưa là để làm cho phân phối hệ số γ gần bằng không, để thuận tiện cho việc chọn ra các kênh không quan trọng trong mạng.

Hình 8: Phân phối của các hệ số γ trong mạng gốc.

Trong quá trình thí nghiệm, chúng tôi phát hiện ra rằng huấn luyện thưa là sự cân đối giữa độ chính xác và độ thưa. Tỷ lệ thưa s lớn hơn có thể mang lại hiệu quả thưa tốt hơn, nhưng tổn thất độ chính xác cũng lớn, ngay cả khi số epoch của huấn luyện thưa được tăng lên trong tương lai, mô hình vẫn không thể khôi phục đến độ chính xác tốt. Tỷ lệ thưa s nhỏ hơn có ít ảnh hưởng đến độ chính xác nhưng dẫn đến hiệu quả thưa tệ hơn. Để giải quyết vấn đề này và tạo ra sự cân bằng tốt giữa hiệu quả thưa và độ chính xác, chúng tôi đưa ra một phương pháp huấn luyện thưa động, giới thiệu tỷ lệ thưa biến đổi s, và tỷ lệ thưa s sẽ thay đổi theo quá trình huấn luyện của mạng.

Trong quá trình huấn luyện thưa động, mức độ thưa của mạng có thể được điều chỉnh bằng cách đặt tỷ lệ thưa s, mạng sẽ điều chỉnh động tỷ lệ thưa của nó theo số epoch của quá trình huấn luyện hiện tại. Đối với mạng YOLOv4, chúng tôi đặt tỷ lệ thưa ban đầu s = 0.00075, tốc độ học ban đầu lr0 = 0.002 và huấn luyện 200 epoch. Khi huấn luyện đến một nửa số epoch, 70% kênh duy trì tỷ lệ thưa ban đầu, 30% kênh tỷ lệ thưa giảm xuống 1% của tỷ lệ thưa ban đầu. Bên cạnh đó, tốc độ học được cập nhật bằng cosine annealing. Khi kích thước hình ảnh đầu vào là 416 ×416, kích thước batch được đặt thành 16, như được hiển thị trong Hình 9, hình này đại diện cho phân phối hệ số γ trong các lớp mạng sau huấn luyện thưa động, so với phân phối hệ số γ ban đầu (như được hiển thị trong Hình 8), hầu hết những hệ số γ này gần hơn với số không và thuận tiện để chọn ra các kênh không đáng kể.

Hình 9: Phân phối của hệ số γ trong mạng sau huấn luyện thưa động.

5.3 Cắt tỉa kênh nhóm
Trong phần này, chúng tôi chia các lớp mạng thành năm nhóm. YOLOv4 có 162 lớp, trong quá trình nhóm, chúng tôi xem xét toàn diện quy mô của các lớp đặc trưng và sự tương tự của cấu trúc mô-đun trong mạng có nghĩa là các lớp đặc trưng có cùng quy mô và các lớp có cấu trúc mô-đun tương tự được gán vào cùng một nhóm.

Khi đầu vào kích thước 416 ×416 hình ảnh vào mạng, nhóm1 bao gồm các thang đo của lớp đặc trưng từ 416 ×416 đến 52 ×52 và mô-đun CSP, nhóm2 chỉ bao gồm lớp đặc trưng ở thang đo 26 ×26 cùng với mô-đun CSP, nhóm3 chỉ bao gồm lớp đặc trưng ở thang đo 13 ×13 cùng với mô-đun CSP và CBL, nhóm4 và nhóm5 đều bao gồm lớp đặc trưng từ thang đo 52 ×52 đến thang đo 13×13 và mô-đun CBL. Các lớp cụ thể trong mỗi nhóm như sau, bao gồm Nhóm1: 0 ∼55 lớp, Nhóm2: 56 ∼85 lớp, Nhóm3: 86 ∼116 lớp, Nhóm4: 117 ∼136 lớp, và Nhóm5: 136 ∼161 lớp.

--- TRANG 16 ---
16 Yun Chu et al.

5.3.1 Giảm tham số và tính toán của mô hình
Với tỷ lệ cắt tỉa tổng của toàn bộ mạng được cho, theo tỷ lệ cắt tỉa tổng, thuật toán sẽ tính toán tỷ lệ cắt tỉa của năm nhóm. Như được hiển thị trong Bảng 1, chúng tôi trình bày chi tiết tỷ lệ cắt tỉa của năm nhóm. Có thể thấy từ Bảng 1 rằng trong phần mạng xương sống, chức năng trích xuất đặc trưng chủ yếu được thực hiện bởi Nhóm1 và Nhóm2, và độ dư thừa trong hai nhóm này đạt 10% ∼25%. Độ dư thừa trong Nhóm3 đạt hơn 90%, điều này cho thấy các kênh trong những lớp đặc trưng này có ít ảnh hưởng đến việc trích xuất đặc trưng trong Nhóm3. Độ dư thừa trong Nhóm4 đạt hơn 90%, và hầu hết các kênh trong Nhóm này có ít ảnh hưởng đến việc tăng cường đặc trưng. Độ dư thừa trong Nhóm5 đạt khoảng 45%.

Thông qua phân tích trên, điều này đủ để chỉ ra rằng độ dư thừa trong các phần cấu trúc khác nhau của mạng là khác nhau. Chúng tôi sử dụng cắt tỉa nhóm để làm cho mỗi nhóm có các ngưỡng cắt tỉa khác nhau, do đó đạt được việc cắt tỉa chính xác và hiệu quả hơn. Trong Bảng 2, chúng tôi trình bày ảnh hưởng của các tỷ lệ cắt tỉa khác nhau đến tham số và tính toán của mô hình, ngoại trừ tỷ lệ cắt tỉa khác nhau, chúng tôi giữ kích thước hình ảnh đầu vào là 416 ×416. Bảng 2 chứng minh hiệu quả của phương pháp cắt tỉa kênh nhóm của chúng tôi.

Bảng 1: Total đại diện cho tỷ lệ cắt tỉa tổng của toàn bộ mạng phát hiện, Model đại diện cho mô hình nén dưới tỷ lệ cắt tỉa tổng tương ứng và Nhóm1 ∼5 hiển thị tỷ lệ cắt tỉa cụ thể trong 5 nhóm.

Total Model Group1 Group2 Group3 Group4 Group5 Model Size mAP@0.5
0 Base 0 0 0 0 0 256M 79.8
38% Model1 10% 20% 96% 87% 45% 98MB 73.6
40% Model2 10% 25% 96% 87% 50% 90MB 56.3
42% Model3 10% 25% 97% 85% 55% 84MB 28.3
45% Model4 15% 25% 96% 85% 70% 77MB 9.2
50% Model5 15% 27% 96% 85% 90% 68MB 6.1

Bảng 2: So sánh với mạng gốc, việc giảm tham số mô hình và tính toán bằng cách sử dụng phương pháp cắt tỉa nhóm của chúng tôi với các tỷ lệ cắt tỉa khác nhau. Bảng 2 ∼ Bảng 5, đối với tất cả các mô hình, kích thước hình ảnh đầu vào là 416 ×416.

Model Model Size Flops Pruned Parameters Pruned
Base 256MB 29.9G 0 64.1M 0
Model1 98MB 20.35G 31.9% 24.51M 61.7%
Model2 90MB 19.46G 34.9% 22.56M 64.7%
Model3 84MB 19.35G 35.2% 20.96M 67.2%
Model4 77MB 17.94G 40.0% 19.27M 69.9%
Model5 68MB 16.57G 44.6% 17.07M 73.3%

--- TRANG 17 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 17

5.3.2 So sánh với các phương pháp cắt tỉa hiện tại khác
Như được hiển thị trong Hình 10, để chứng minh tính ưu việt của phương pháp cắt tỉa kênh nhóm được đề xuất của chúng tôi trong phát hiện đối tượng, chúng tôi so sánh định lượng phương pháp của chúng tôi với các phương pháp cắt tỉa hiện tại khác như Network Slimming [39], Thinet [38], Layer pruning [40] và Eagle eye [42]. Chúng tôi so sánh chúng ở hai khía cạnh: kích thước mô hình và độ chính xác (map@0.5).

Hình 10: Hình cho thấy độ chính xác của mạng phát hiện đối tượng thay đổi theo tỷ lệ cắt tỉa, và bán kính chấm đại diện cho kích thước của mô hình thay đổi theo tỷ lệ cắt tỉa, độ phân giải đầu vào là 416 ×416.

Trong quá trình cắt tỉa, chúng tôi giữ tỷ lệ cắt tỉa giống nhau cho các phương pháp cắt tỉa khác nhau, kích thước hình ảnh đầu vào là 416 ×416. Có thể thấy từ Hình 10, dưới cùng tỷ lệ cắt tỉa, phương pháp của chúng tôi có thể có được sự cân đối tốt nhất giữa độ chính xác của mô hình đã được cắt tỉa và kích thước của mô hình đã được cắt tỉa.

Ngoài ra, trong [40] họ sử dụng một cách tiếp cận chiếu không gian con để ước tính tầm quan trọng của các lớp mạng, khi sử dụng cách cắt tỉa này, các lớp có thể được cắt tỉa bị hạn chế vì nếu tỷ lệ cắt tỉa trên 0.6 cách cắt tỉa này sẽ thay đổi kiến trúc mạng và độ chính xác đáng kể, điều này bất tiện để khôi phục độ chính xác của các mô hình đã được cắt tỉa. Trong [42], họ sử dụng một cách tương tự như tìm kiếm kiến trúc mạng, trong quá trình cắt tỉa, họ tìm kiếm mạng đã được cắt tỉa không chỉ xem xét kích thước của mô hình đã được cắt tỉa, độ chính xác, mà còn xem xét tính toán của mô hình đã được cắt tỉa và chọn mô hình cân đối tốt nhất từ 1000 mô hình ứng viên. Để đảm bảo phương pháp cắt tỉa công việc [42] được thực hiện dưới cùng điều kiện phần cứng và môi trường tính toán với các phương pháp cắt tỉa khác (Môi trường thí nghiệm của chúng tôi là Ubuntu 18.04, PyTorch = 1.8 version, GPU là một RTX3090 đơn), chúng tôi chọn mô hình tốt nhất chỉ từ năm mô hình cắt tỉa ứng viên, chúng tôi cũng cần tuyên bố rằng phương pháp cắt tỉa tìm kiếm kiến trúc này có hiệu suất tốt hơn khi số lượng mô hình ứng viên nhiều hơn, nhưng tình huống này cũng đặt ra yêu cầu cao hơn cho sức mạnh tính toán.

5.4 Chưng cất chú ý không gian nhóm
Trong phần này, chúng tôi sử dụng mạng thưa để tiến hành cắt tỉa kênh nhóm và thu được mạng đã được cắt tỉa. Độ chính xác của mạng gốc và mạng sau huấn luyện thưa lần lượt là 87.1 và 79.8.

Trong các thí nghiệm chưng cất, chúng tôi đặt mạng gốc làm mạng giáo viên và mạng đã được cắt tỉa làm mạng học sinh, thông tin chú ý không gian được trích xuất chỉ ở các bản đồ đặc trưng thang đo cụ thể từ năm nhóm làm kiến thức, thang đo của các bản đồ đặc trưng là 208 ×208, 104 ×104, 52 ×52, 26× 26 và 13 ×13, tương ứng. Bên cạnh đó, chúng tôi đưa cho hệ số tăng mất mát của năm nhóm βi với trọng số khác nhau, chúng tôi đặt β1-β3 là 1000 và β4-β5 là 10000.

5.4.1 Chưng cất chú ý không gian nhóm với phương pháp cắt tỉa của chúng tôi
Để xác minh hiệu quả của chưng cất chú ý không gian nhóm, chúng tôi sử dụng nó cho mô hình đã được cắt tỉa với phương pháp cắt tỉa của chúng tôi. Sau đó, chúng tôi fine-tune và chưng cất chú ý nhóm mô hình nén, tương ứng.

Kết quả so sánh được hiển thị trong Bảng 3, mAP@0.5 làm chỉ số đánh giá độ chính xác. Có thể thấy từ Bảng 3 khi trực tiếp fine-tune mạng đã được cắt tỉa, độ chính xác cao nhất được khôi phục chỉ có thể đạt 81.1. Ngược lại, sử dụng chưng cất chú ý không gian nhóm có thể làm cho mạng đã được cắt tỉa có được độ chính xác cao hơn.

Bảng 3: Kết hợp chưng cất chú ý không gian nhóm với phương pháp cắt tỉa của chúng tôi, Model1-5 đã được cắt tỉa đạt được bằng phương pháp cắt tỉa của chúng tôi, độ chính xác đại diện cho Mô hình sau khi thông qua fine-tuning và chưng cất chú ý không gian nhóm (ký hiệu là GSA).

Total Model Model Size mAP@0.5
Fine tuning GSA Distilling
38% Model1 98MB 80.4 86.5
40% Model2 90MB 81.1 86.6
42% Model3 84MB 80.5 84.8
45% Model4 77MB 79.5 83.3
50% Model5 68MB 75.9 76.3

--- TRANG 18 ---
18 Yun Chu et al.

5.4.2 Chưng cất chú ý không gian nhóm kết hợp với các phương pháp cắt tỉa phổ biến khác
Để cho thấy rằng lược đồ chưng cất chú ý không gian nhóm của chúng tôi không chỉ phù hợp với phương pháp cắt tỉa của chúng tôi, chúng tôi kết hợp phương pháp chưng cất chú ý không gian nhóm với các phương pháp cắt tỉa phổ biến khác như Network Slimming [39] và Thinet [38].

Kết quả so sánh được hiển thị trong Bảng 4 ∼5, có thể thấy từ Bảng 4 ∼5, khi chúng tôi trực tiếp fine-tune mạng đã được cắt tỉa, độ chính xác cao nhất được khôi phục chỉ có thể đạt 80.9. Ngược lại, sử dụng chưng cất chú ý không gian nhóm có thể làm cho mạng đã được cắt tỉa có được độ chính xác cao hơn. Bên cạnh đó, kết hợp cắt tỉa kênh nhóm với phương pháp cắt tỉa của chúng tôi có thể đạt được hiệu quả tốt hơn.

Bảng 4: Kết hợp chưng cất chú ý không gian nhóm (ký hiệu là GSA) với phương pháp cắt tỉa Network Sliming [39], Model1-5 đã được cắt tỉa đạt được bởi [39].

Total Model Model Size mAP@0.5
Fine tuning GSA Distilling
38% Model1 100MB 80.4 83.1
40% Model2 94MB 79.8 83.7
42% Model3 86MB 80.4 84.8
45% Model4 78MB 79.6 82.8
50% Model5 65MB 79.3 80.9

Bảng 5: Kết hợp chưng cất chú ý không gian nhóm (ký hiệu là GSA) với phương pháp cắt tỉa Thinet [38], Model1-5 đã được cắt tỉa đạt được bởi [38].

Total Model Model Size mAP@0.5
Fine tuning GSA Distilling
38% Model1 116MB 80.9 84.2
40% Model2 110MB 80.4 83.9
42% Model3 104MB 80.9 81.8
45% Model4 96MB 80.7 82.1
50% Model5 83MB 79.4 82.1

5.4.3 So sánh mô hình nén với các mạng phát hiện đối tượng khác trên PASCAL và COCO
Để xác minh hiệu quả của mô hình nén cuối cùng của chúng tôi, chúng tôi so sánh mô hình nén cuối cùng với các mạng bình thường khác và các detector nhẹ trên PASCAL và COCO, tương ứng.

Kết quả so sánh được hiển thị trong Bảng 6 và Bảng 7, mAP@0.5 và mAP@0.5:0.95 làm chỉ số đánh giá độ chính xác cho tập dữ liệu PASCAL VOC và COCO, tương ứng. Ký hiệu * đại diện cho mô hình nén cuối cùng đã được sử dụng cắt tỉa kênh nhóm, chưng cất chú ý không gian của chúng tôi. Có thể thấy từ bảng trên, phương pháp của chúng tôi có thể đạt được sự cân đối tốt nhất giữa độ chính xác của mạng và tính toán hoặc tham số.

5.5 Triển khai trên thiết bị biên
Trong phần này, chúng tôi giới thiệu việc triển khai mô hình đã được cắt tỉa trên thiết bị biên-Jetson Nano. Jetson Nano là một máy tính nhỏ, mạnh mẽ cho các ứng dụng nhúng.

--- TRANG 19 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 19

Bảng 6: So sánh với các detector bình thường và nhẹ trên PASCAL VOC.

Method Backbone Input size Flops Parameters mAP
SSD Lite [33] VGG16 512 ×512 99.5B 36.1M 80.7
SSD Lite [33] MobilenetV2 320 ×320 0.8B 4.3M 71.8
Tiny-DSOD [34] G/32-48-64-801 300 ×300 1.06B 0.95M 72.1
ThunderNet [35] SNet146 416 ×416 0.461B — 73.8
Pelee [36] PeleeNet 304 ×304 1.21B 5.43M 70.9
Ours CSPDarknet* 320 ×320 18.2B 20.9M 82.7
Ours CSPDarknet* 416 ×416 19.3B 20.9M 84.8

Bảng 7: So sánh với các detector bình thường và nhẹ trên COCO.

Method Backbone Input size Flops Parameters mAP(0.5:0.95) mAP(0.5)
SSD [8] VGG16 300 ×300 70.4B 34.3M 25.7 43.9
YOLOV3 [9] Darknet53 416 ×416 65.9B 62.3M 31 55.3
PANet [37] CSPResNeXt50 416 ×416 47.1B 56.9M 36.6 58.1
SSD lite [33] Mobilenet 320 ×320 0.8B 4.3M 22.1 –
ThunderNet [35] SNet146 320 ×320 0.95B — 23.6 40.2
Pelee [36] PeleeNet 304 ×304 2.58B 5.98M 22.4 38.3
Ours CSPDarknet* 320 ×320 18.6B 23.63M 30.2 48.8
Ours CSPDarknet* 416 ×416 19.43B 23.63M 33.4 53.5

ứng dụng, nó có 128 lõi NVIDIA CUDA và 4 GB bộ nhớ. Chúng tôi triển khai mạng gốc và năm mô hình nén (sử dụng phương pháp cắt tỉa kênh nhóm của chúng tôi) trên thiết bị biên này, và kiểm tra thời gian suy luận của mỗi mô hình.

Các bước triển khai cụ thể như sau: Đầu tiên, trên máy chủ, chúng tôi chuẩn bị tệp mô hình mạng và tệp trọng số tương ứng, sau đó sử dụng PyTorch để chuyển đổi nó sang định dạng mô hình ONNX. Sau đó, trên thiết bị đích-Jetson Nano, chúng tôi sử dụng TensorRT để tạo các tệp engine theo mô hình ONNX. Cuối cùng, chúng tôi chạy các tệp engine của năm mô hình nén trên Jetson Nano, và kết quả suy luận được hiển thị trong Bảng 6.

Có thể thấy từ Bảng 8 rằng thời gian suy luận của mô hình mạng gốc cần 414ms và mô hình nén (68M) chỉ cần 274ms. Các thí nghiệm trên cho thấy rằng phương pháp cắt tỉa kênh nhóm được đề xuất có thể được triển khai đến thiết bị biên mà không cần thiết kế phần cứng hoặc phần mềm đặc biệt và có hiệu quả tăng tốc.

Bảng 8: Thời gian suy luận của mô hình đã được cắt tỉa trên thiết bị biên-Jeston Nano, độ phân giải đầu vào là 416 ×416.

Model Model Size Inference time
Base 256MB 414 ms
Model1 98MB 311 ms
Model2 90MB 305 ms
Model3 84MB 303 ms
Model4 77MB 291 ms
Model5 68MB 274 ms

--- TRANG 20 ---
20 Yun Chu et al.

6 Nghiên cứu Ablation
Để chứng minh tính tổng quát và hiệu quả của phương pháp chúng tôi. Trong phần này, chúng tôi đầu tiên sử dụng MobileNet, DarkNet53 và CSPDarknet làm xương sống để xây dựng mạng phát hiện. Tiếp theo, chúng tôi giới thiệu các thí nghiệm ablation của huấn luyện thưa động, cắt tỉa kênh nhóm và chưng cất chú ý không gian. Cuối cùng, chúng tôi kiểm tra mô hình cắt tỉa sau chưng cất.

6.1 Nghiên cứu Ablation cho Huấn luyện Thưa Động
Trong quá trình huấn luyện thưa, chúng tôi đặt tổng số epoch cho huấn luyện thưa và huấn luyện thưa động đều là 200 epoch, tốc độ học ban đầu của tất cả mô hình được đặt là lr0 = 0.002 và kích thước hình ảnh đầu vào là 416 ×416.

Như được hiển thị trong Hình 11, ba hình trên đại diện cho huấn luyện thưa phổ biến và ba hình dưới đại diện cho huấn luyện thưa động cho CSPDarknet-Yolov4. Trong quá trình huấn luyện thưa động, kích thước batch = 16, tỷ lệ thưa ban đầu s = 0.00075, khi đến 40% tổng số epoch, 70% kênh duy trì tỷ lệ thưa ban đầu s, 30% kênh tỷ lệ thưa giảm xuống 1% của tỷ lệ thưa ban đầu s. Có thể thấy từ Hình 11, độ chính xác của mạng thông qua huấn luyện thưa phổ biến là 71.2, trong khi độ chính xác của mạng thông qua huấn luyện thưa động là 79.8. Bên cạnh đó, tỷ lệ thưa ban đầu s cho DarkNet53-Yolov3 và MobileNet-Yolov3 lần lượt là 0.003 và 0.005. Kích thước batch cho hai mạng này đều là 32.

Bảng 9: Nghiên cứu Ablation cho huấn luyện thưa và huấn luyện thưa động.

Model Sparse training Dynamic Sparse training mAP@0.5 Model-size
CSPDarkNet-Yolov4 ✓ 71.2 256MB
CSPDarkNet-Yolov4 ✓ 79.8 256MB
DarkNet53-Yolov3 ✓ 59.2 246MB
DarkNet53-Yolov3 ✓ 66.5 246MB
MobileNet-Yolov3 ✓ 71.3 95MB
MobileNet-Yolov3 ✓ 72.8 95MB

Đối với MobileNet-Yolov3, DarkNet53-Yolov3, CSPDarknet-Yolov4, chúng có 96, 106, 162 lớp mạng, tương ứng. Có thể thấy từ Bảng 9, độ chính xác của MobileNet-Yolov3, DarkNet53-Yolov3, CSPDarknet-Yolov4 lần lượt là 72.8, 66.5, 79.8. Với sự gia tăng số lượng lớp mạng phát hiện, phương pháp huấn luyện thưa động đã đạt được sự cân đối tốt hơn giữa độ thưa và độ chính xác so với huấn luyện thưa phổ biến. Bên cạnh đó, khi các lớp mạng ít hơn 100 lớp, chúng tôi nhận thấy rằng việc tăng kích thước batch cũng có thể cải thiện sự cân đối giữa độ thưa và độ chính xác.

6.2 Nghiên cứu Ablation cho Cắt tỉa Kênh Nhóm
Trong các thí nghiệm cắt tỉa kênh nhóm, chúng tôi chọn mô hình huấn luyện thưa động làm mạng được cắt tỉa và sử dụng cùng tỷ lệ cắt tỉa cho cắt tỉa phổ biến và cắt tỉa kênh nhóm. Đối với CSPDarknet-Yolov4, tỷ lệ cắt tỉa là 40%. Đối với DarkNet53-Yolov3 và MobileNet-Yolov3, tỷ lệ cắt tỉa lần lượt là 64% và 65%.

Bảng 10: Nghiên cứu Ablation cho cắt tỉa phổ biến [39] và cắt tỉa kênh nhóm

Model Pruning Group channel pruning mAP@0.5 Model-size
CSPDarkNet-Yolov4 ✓ 48.5 94 MB
CSPDarkNet-Yolov4 ✓ 56.2 90 MB
DarkNet53-Yolov3 ✓ 60.9 62 MB
DarkNet53-Yolov3 ✓ 65.2 21 MB
MobileNet-Yolov3 ✓ 71.3 17 MB
MobileNet-Yolov3 ✓ 72.2 15 MB

Có thể thấy từ Bảng 10, so sánh với phương pháp cắt tỉa phổ biến [39], phương pháp cắt tỉa kênh nhóm của chúng tôi có thể đạt được sự cân bằng tốt hơn giữa kích thước mô hình và độ chính xác cho các mạng phát hiện khác nhau.

--- TRANG 21 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 21

6.3 Nghiên cứu Ablation cho Chưng cất Chú ý Không gian Nhóm
Trong các thí nghiệm chú ý không gian nhóm, chúng tôi chọn mạng gốc làm mạng giáo viên, mạng đã được cắt tỉa (thông qua phương pháp cắt tỉa kênh nhóm) làm mạng học sinh.

Đối với CSPDarknet-Yolov4 và Mobilenet-Yolov3, chúng tôi trích xuất thông tin chú ý không gian ở các bản đồ đặc trưng thang đo cụ thể từ năm nhóm làm kiến thức, thang đo của các bản đồ đặc trưng là 208 ×208, 104 ×104, 52 ×52, 26×26 và 13 ×13, tương ứng. Đối với Darknet53-Yolov3, chúng tôi trích xuất thông tin chú ý không gian ở 104 ×104, 52 ×52, 26×26 và 13 ×13 các bản đồ đặc trưng thang đo từ năm nhóm.

Bảng 11: Nghiên cứu Ablation cho fine tuning và Chưng cất Chú ý Không gian Nhóm (ký hiệu là GSA)

Model Fine tune GSA Distilling mAP@0.5 Model-size
CSPDarkNet-Yolov4 ✓ 81.1 90 MB
CSPDarkNet-Yolov4 ✓ 86.6 90 MB
DarkNet53-Yolov3 ✓ 66.8 22 MB
DarkNet53-Yolov3 ✓ 68.2 22 MB
MobileNet-Yolov3 ✓ 72.1 15 MB
MobileNet-Yolov3 ✓ 73.2 15 MB

Như được hiển thị trong Bảng 11, so sánh với fine tune mạng đã được cắt tỉa, chưng cất chú ý không gian nhóm có thể đạt được độ chính xác tốt hơn cho các mạng phát hiện khác nhau.

Ngoài ra, chúng tôi chứng minh định tính hiệu quả của mạng đã được cắt tỉa thông qua chưng cất chú ý không gian nhóm. Như được hiển thị trong Hình 13, (a),(b),(c) hiển thị kết quả phát hiện CSPDarknet-Yolov4, DarkNet53-Yolov3, MobileNet-Yolov3 gốc, tương ứng. Và (d),(e),(f) hiển thị kết quả phát hiện của mạng đã được cắt tỉa.

7 Kết luận
Trong bài báo này, chúng tôi trình bày một cách tiếp cận nén mô hình ba giai đoạn cho mạng phát hiện đối tượng, đó là huấn luyện thưa động, cắt tỉa kênh nhóm và chưng cất chú ý không gian. Đầu tiên, chúng tôi giới thiệu huấn luyện thưa động để chọn ra các kênh không đáng kể trong các lớp và duy trì sự cân bằng tốt về độ thưa và độ chính xác của mạng. Tiếp theo, chúng tôi đề xuất một phương pháp cắt tỉa kênh nhóm. Dưới cùng tỷ lệ cắt tỉa, phương pháp cắt tỉa nhóm của chúng tôi có ít ảnh hưởng đến độ chính xác của mạng và có thể có được sự nén mô hình đáng kể so với các phương pháp cắt tỉa khác. Sau đó, chúng tôi trích xuất thông tin chú ý không gian của mỗi nhóm làm kiến thức để chưng cất. So với việc fine-tuning trực tiếp của mô hình đã được cắt tỉa, phương pháp chưng cất chú ý không gian nhóm của chúng tôi có thể khôi phục mạng đã được cắt tỉa đến độ chính xác cao hơn. Hơn nữa, chúng tôi triển khai mô hình nén trên thiết bị biên Jetson Nano để chứng minh rằng phương pháp của chúng tôi có thể được triển khai trực tiếp mà không cần sự hỗ trợ của phần cứng hoặc phần mềm đặc biệt và

--- TRANG 22 ---
22 Yun Chu et al.

(a) Hình 1 (b) Hình 2 (c) Hình 3
(d) Hình 4 (e) Hình 5 (f) Hình 6

Hình 12: Ba hình trên hiển thị kết quả phát hiện của mạng CSPDarkNet-Yolov4(a), DarkNet-Yolov3(b), MobileNet-Yolov3(c) gốc, và ba hình dưới hiển thị kết quả phát hiện của mạng CSPDarkNet-Yolov4(d), DarkNet-Yolov3(e), MobileNet-Yolov3(f) đã được cắt tỉa.

có thể đạt được hiệu quả tăng tốc. Để chứng minh tính tổng quát và hiệu quả của cách tiếp cận được đề xuất của chúng tôi, trong các thí nghiệm của chúng tôi, chúng tôi thay thế xương sống thành MobileNet, DarkNet53 và CSPDarknet để xây dựng mạng phát hiện và sau đó sử dụng các phương pháp được đề xuất của chúng tôi, kết quả thí nghiệm là thỏa mãn. Chúng tôi tin rằng phương pháp luận và cách tiếp cận được đề xuất có triển vọng được đánh giá để nén các mạng phát hiện đối tượng khác.

Lời cảm ơn Công việc này được hỗ trợ một phần bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc theo Grant 61961014, 61963012 và Quỹ Khoa học Tự nhiên Tỉnh Hainan Trung Quốc theo Grant 620RC556, 620RC564.

Tài liệu tham khảo
1. D. P. Sullivan, C. F. Winsnes, L. Åkesson, M. Hjelmare, M. Wiking, R. Schutten, L. Campbell, H. Leifsson, S. Rhodes, A. Nordgren, etal., "Deep learning is combined with massive-scale citizen science to improve large-scale image classification," Nature biotechnology, vol. 36, no. 9, pp. 820–828, 2018.
2. L. Liu, W. Ouyang, X. Wang, P. Fieguth, J. Chen, X. Liu, and M. Pietikäinen, "Deep learning for generic object detection: A survey," International journal of computer vision, vol. 128, no. 2, pp. 261–318, 2020.

--- TRANG 23 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 23
3. F. Sultana, A. Sufian, and P. Dutta, "Evolution of image segmentation using deep convolutional neural network: a survey," Knowledge-Based Systems, vol. 201, p. 106062, 2020.
4. A. Krizhevsky, I. Sutskever, and G. E. Hinton, "Imagenet classification with deep convolutional neural networks," Communications of the ACM, vol. 60, no. 6, pp. 84–90, 2017.
5. K. He, X. Zhang, S. Ren, and J. Sun, "Deep residual learning for image recognition," in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770–778, 2016.
6. A. Howard, A. Zhmoginov, L.-C. Chen, M. Sandler, and M. Zhu, "Inverted residuals and linear bottlenecks: Mobile networks for classification, detection and segmentation," 2018.
7. S. Ren, K. He, R. Girshick, and J. Sun, "Faster r-cnn: towards real-time object detection with region proposal networks," IEEE transactions on pattern analysis and machine intelligence, vol. 39, no. 6, pp. 1137–1149, 2016.
8. W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y. Fu, and A. C. Berg, "Ssd: Single shot multibox detector," in European conference on computer vision, pp. 21–37, Springer, 2016.
9. A. Farhadi and J. Redmon, "Yolov3: An incremental improvement," in Computer Vision and Pattern Recognition, pp. 1804–02767, 2018.
10. A. Bochkovskiy, C.-Y. Wang, and H.-Y. M. Liao, "Yolov4: Optimal speed and accuracy of object detection," arXiv preprint arXiv:2004.10934, 2020.
11. S. Han, X. Liu, H. Mao, J. Pu, A. Pedram, M. A. Horowitz, and W. J. Dally, "Eie: Efficient inference engine on compressed deep neural network," ACM SIGARCH Computer Architecture News, vol. 44, no. 3, pp. 243–254, 2016.
12. N. Rathi, P. Panda, and K. Roy, "Stdp-based pruning of connections and weight quantization in spiking neural networks for energy-efficient recognition," IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, vol. 38, no. 4, pp. 668–677, 2018.
13. N. Abderrahmane, E. Lemaire, and B. Miramond, "Design space exploration of hardware spiking neurons for embedded artificial intelligence," Neural Networks, vol. 121, pp. 366–386, 2020.
14. J.-H. Luo and J. Wu, "Autopruner: An end-to-end trainable filter pruning method for efficient deep model inference," Pattern Recognition, vol. 107, p. 107461, 2020.
15. F. E. Fernandes Jr and G. G. Yen, "Pruning deep convolutional neural networks architectures with evolution strategy," Information Sciences, vol. 552, pp. 29–47, 2021.
16. Y. Cheng, M. Lin, J. Wu, H. Zhu, and X. Shao, "Intelligent fault diagnosis of rotating machinery based on continuous wavelet transform-local binary convolutional neural network," Knowledge-Based Systems, vol. 216, p. 106796, 2021.
17. L. Deng, P. Jiao, J. Pei, Z. Wu, and G. Li, "Gxnor-net: Training deep neural networks with ternary weights and activations without full-precision memory under a unified discretization framework," Neural Networks, vol. 100, pp. 49–58, 2018.
18. F. Tung and G. Mori, "Deep neural network compression by in-parallel pruning-quantization," IEEE transactions on pattern analysis and machine intelligence, vol. 42, no. 3, pp. 568–579, 2018.
19. P. Hu, X. Peng, H. Zhu, M. M. S. Aly, and J. Lin, "Opq: Compressing deep neural networks with one-shot pruning-quantization," in Proceedings of the Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21), Vancouver, VN, Canada, pp. 2–9, 2021.
20. G. Hinton, O. Vinyals, and J. Dean, "Distilling the knowledge in a neural network," stat, vol. 1050, p. 9, 2015.
21. T.-B. Xu, P. Yang, X.-Y. Zhang, and C.-L. Liu, "Lightweightnet: Toward fast and lightweight convolutional neural networks via architecture distillation," Pattern Recognition, vol. 88, pp. 272–284, 2019.
22. H. Zhang, Z. Hu, W. Qin, M. Xu, and M. Wang, "Adversarial co-distillation learning for image recognition," Pattern Recognition, vol. 111, p. 107659, 2021.
23. D. Song, J. Xu, J. Pang, and H. Huang, "Classifier-adaptation knowledge distillation framework for relation extraction and event detection with imbalanced data," Information Sciences, vol. 573, pp. 222–238, 2021.
24. Z.-R. Wang and J. Du, "Joint architecture and knowledge distillation in cnn for chinese text recognition," Pattern Recognition, vol. 111, p. 107722, 2021.
25. Z. Li, Y. Ming, L. Yang, and J.-H. Xue, "Mutual-learning sequence-level knowledge distillation for automatic speech recognition," Neurocomputing, vol. 428, pp. 259–267, 2021.
26. P. Shen, X. Lu, S. Li, and H. Kawai, "Knowledge distillation-based representation learning for short-utterance spoken language identification," IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 28, pp. 2674–2683, 2020.

--- TRANG 24 ---
24 Yun Chu et al.
27. M. Yang, Y. Li, Z. Huang, Z. Liu, P. Hu, and X. Peng, "Partially view-aligned representation learning with noise-robust contrastive loss," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1134–1143, 2021.
28. H. Ibrahem, A. D. A. Salem, and H.-S. Kang, "Real-time weakly supervised object detection using center-of-features localization," IEEE Access, vol. 9, pp. 38742–38756, 2021.
29. Q. Zhou, J. Wang, J. Liu, S. Li, W. Ou, and X. Jin, "Rsanet: Towards real-time object detection with residual semantic-guided attention feature pyramid network," Mobile Networks and Applications, vol. 26, no. 1, pp. 77–87, 2021.
30. Q. Zhou, X. Wu, S. Zhang, B. Kang, Z. Ge, and L. J. Latecki, "Contextual ensemble network for semantic segmentation," Pattern Recognition, vol. 122, p. 108290, 2022.
31. Q. Zhou, Y. Wang, Y. Fan, X. Wu, S. Zhang, B. Kang, and L. J. Latecki, "Aglnet: Towards real-time semantic segmentation of self-driving images via attention-guided lightweight network," Applied Soft Computing, vol. 96, p. 106682, 2020.
32. S.-W. Kim, K. Ko, H. Ko, and V. C. Leung, "Edge-network-assisted real-time object detection framework for autonomous driving," IEEE Network, vol. 35, no. 1, pp. 177–183, 2021.
33. M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen, "Mobilenetv2: Inverted residuals and linear bottlenecks," 2019.
34. Y. Li, J. Li, W. Lin, and J. Li, "Tiny-dsod: Lightweight object detection for resource-restricted usages,"
35. Z. Qin, Z. Li, Z. Zhang, Y. Bao, G. Yu, Y. Peng, and J. Sun, "Thundernet: Towards real-time generic object detection on mobile devices," in Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 6718–6727, 2019.
36. R. J. Wang, X. Li, and C. X. Ling, "Pelee: A real-time object detection system on mobile devices," Advances in Neural Information Processing Systems, vol. 31, pp. 1963–1972, 2018.
37. S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, "Path aggregation network for instance segmentation,"
38. J.-H. Luo, J. Wu, and W. Lin, "Thinet: A filter level pruning method for deep neural network compression," in Proceedings of the IEEE international conference on computer vision, pp. 5058–5066, 2017.
39. Z. Liu, J. Li, Z. Shen, G. Huang, S. Yan, and C. Zhang, "Learning efficient convolutional networks through network slimming," in Proceedings of the IEEE international conference on computer vision, pp. 2736–2744, 2017.
40. A. Jordao, M. Lie, and W. R. Schwartz, "Discriminative layer pruning for convolutional neural networks," IEEE Journal of Selected Topics in Signal Processing, vol. 14, no. 4, pp. 828–837, 2020.
41. Z. Liu, M. Sun, T. Zhou, G. Huang, and T. Darrell, "Rethinking the value of network pruning," in International Conference on Learning Representations, 2018.
42. B. Li, B. Wu, J. Su, and G. Wang, "Eagleeye: Fast sub-net evaluation for efficient neural network pruning," in European Conference on Computer Vision, pp. 639–654, Springer, 2020.
43. J. Zhou, S. Zeng, and B. Zhang, "Two-stage knowledge transfer framework for image classification," Pattern Recognition, vol. 107, p. 107529, 2020.
44. J.-W. Jung, H.-S. Heo, H.-J. Shim, and H.-J. Yu, "Knowledge distillation in acoustic scene classification," IEEE Access, vol. 8, pp. 166870–166879, 2020.
45. G. Chen, X. Zhang, X. Tan, Y. Cheng, F. Dai, K. Zhu, Y. Gong, and Q. Wang, "Training small networks for scene classification of remote sensing images via knowledge distillation," Remote Sensing, vol. 10, no. 5, p. 719, 2018.
46. G. Chen, W. Choi, X. Yu, T. Han, and M. Chandraker, "Learning efficient object detection models with knowledge distillation," Advances in neural information processing systems, vol. 30, 2017.
47. N. Komodakis and S. Zagoruyko, "Paying more attention to attention: improving the performance of convolutional neural networks via attention transfer," in ICLR, 2017.
48. Y. Liu, X. Jia, M. Tan, R. Vemulapalli, Y. Zhu, B. Green, and X. Wang, "Search to distill: Pearls are everywhere but not the eyes," in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 7539–7548, 2020.
49. S. Santurkar, D. Tsipras, A. Ilyas, and A. Mdry, "How does batch normalization help optimization," in Proceedings of the 32nd international conference on neural information processing systems, pp. 2488–2498, 2018.

--- TRANG 25 ---
Cắt tỉa kênh nhóm và chưng cất chú ý không gian cho phát hiện đối tượng 25
50. R. Dasgupta, Y. S. Chowdhury, and S. Nanda, "Performance comparison of benchmark activation function relu, swish and mish for facial mask detection using convolutional neural network," in Intelligent Systems, pp. 355–367, Springer, 2021.
51. Y. Liu, X. Wang, L. Wang, and D. Liu, "A modified leaky relu scheme (mlrs) for topology optimization with multiple materials," Applied Mathematics and Computation, vol. 352, pp. 188–204, 2019.
52. Z. Huang, J. Wang, X. Fu, T. Yu, Y. Guo, and R. Wang, "Dc-spp-yolo: Dense connection and spatial pyramid pooling based yolo for object detection," Information Sciences, vol. 522, pp. 241–258, 2020.
53. M. Everingham, S. A. Eslami, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman, "The pascal visual object classes challenge: A retrospective," International journal of computer vision, vol. 111, no. 1, pp. 98–136, 2015.
54. R. Padilla, S. L. Netto, and E. A. da Silva, "A survey on performance metrics for object-detection algorithms," in 2020 International Conference on Systems, Signals and Image Processing (IWSSIP), pp. 237–242, IEEE, 2020.

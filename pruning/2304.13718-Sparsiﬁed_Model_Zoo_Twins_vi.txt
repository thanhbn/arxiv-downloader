# Sparsiﬁed Model Zoo Twins:
Nghiên cứu Các Quần thể Mô hình Mạng Nơ-ron Thưa thớt

Dominik Honegger1Konstantin Schürholt1Damian Borth1

Tóm tắt
Với kích thước ngày càng tăng của Mạng Nơ-ron (NN), việc thưa thớt hóa mô hình để giảm chi phí tính toán và nhu cầu bộ nhớ cho suy luận mô hình đã trở thành mối quan tâm thiết yếu cho cả nghiên cứu và sản xuất. Trong khi nhiều phương pháp thưa thớt hóa đã được đề xuất và áp dụng thành công trên các mô hình riêng lẻ, theo hiểu biết của chúng tôi, hành vi và tính bền vững của chúng chưa được nghiên cứu trên các quần thể mô hình lớn. Với bài báo này, chúng tôi giải quyết khoảng trống đó bằng cách áp dụng hai phương pháp thưa thớt hóa phổ biến trên các quần thể mô hình (được gọi là vườn thú mô hình) để tạo ra các phiên bản thưa thớt của các vườn thú gốc. Chúng tôi điều tra hiệu suất của hai phương pháp này cho mỗi vườn thú, so sánh việc thưa thớt hóa theo từng lớp, và phân tích sự đồng thuận giữa các quần thể gốc và thưa thớt. Chúng tôi thấy rằng cả hai phương pháp đều rất bền vững với magnitude pruning có thể vượt trội hơn variational dropout ngoại trừ ở tỷ lệ thưa thớt cao trên 80%. Hơn nữa, chúng tôi thấy rằng các mô hình thưa thớt đồng thuận ở mức độ cao với đối tác không thưa thớt gốc của chúng, và hiệu suất của mô hình gốc và thưa thớt có tương quan cao. Cuối cùng, tất cả các mô hình của vườn thú mô hình và các mô hình song sinh thưa thớt của chúng đều có sẵn công khai: modelzoos.cc.

1. Giới thiệu
Trong những năm gần đây, các mạng nơ-ron sâu đã có được động lực và sự phổ biến đáng kể với xu hướng chung là ngày càng tăng về kích thước. Điều này chủ yếu do mối quan hệ được quan sát giữa kích thước mô hình và hiệu suất tức là các mô hình lớn hơn có xu hướng có hiệu suất cải thiện so với các đối tác nhỏ hơn như được báo cáo bởi (Kaplan et al., 2020; Tan & Le, 2019; Brock et al., 2018). Thật không may, việc tăng hiệu suất dẫn đến chi phí tính toán và môi trường rất cao cho việc huấn luyện và suy luận, khi kích thước của các mô hình tiếp tục tăng (Hoefler et al., 2021; Strubell et al., 2019). Ví dụ, mô hình phân loại hình ảnh CoCa, hiện đạt độ chính xác cao nhất (91.0%) trên tập dữ liệu ImageNet, có 2.1 tỷ tham số (Yu et al., 2022). Dự báo dự đoán rằng đến năm 2025 sẽ tồn tại các mô hình có thể đạt hiệu suất 95% trên phân loại đối tượng ImageNet nhưng yêu cầu nhiều điện để huấn luyện bằng lượng CO2 mà Thành phố New York thải ra trong một tháng (Thompson et al., 2022).

Một cách tiếp cận để giải quyết vấn đề này là khai thác việc tham số hóa quá mức của các mô hình lớn của mạng nơ-ron (NN) để huấn luyện thành công, nhưng giảm kích thước của chúng đáng kể cho suy luận. Theo (Hoefler et al., 2021), việc thưa thớt hóa các mô hình mạng nơ-ron có thể đạt được việc giảm 10-100 lần mà không có tổn thất đáng kể về hiệu suất, ngay cả đối với các mô hình cực lớn (Frantar & Alistarh, 2023). Bằng cách cắt tỉa các tham số sau khi huấn luyện, có thể giảm sức mạnh tính toán cần thiết cho suy luận, tiết kiệm năng lượng hoặc triển khai các mô hình trên các thiết bị di động, trên các hệ thống nhúng hoặc vệ tinh với khả năng lưu trữ hạn chế (Giuffrida et al., 2021; Hoefler et al., 2021; Howard et al., 2017).

Các công trình liên quan đã điều tra các phương pháp thưa thớt hóa riêng lẻ một cách rộng rãi (Blalock et al., 2020; Hoefler et al., 2021) và thực hiện các nghiên cứu quy mô lớn đánh giá nghiêm ngặt sự khác biệt về hiệu suất giữa các phương pháp khác nhau (Gale et al., 2019). Trái ngược với (Gale et al., 2019), những người đánh giá thưa thớt hóa trên các seed cố định và tối ưu hóa siêu tham số cho thưa thớt hóa tốt nhất, công trình này đánh giá tác động của đặc tả trên các quần thể mô hình mạng nơ-ron (được gọi là "vườn thú mô hình"). Vì các mạng nơ-ron tuân theo tối ưu hóa không lồi và nhạy cảm với việc lựa chọn siêu tham số, để đạt được kết quả bền vững hơn trong việc nghiên cứu thưa thớt, chúng tôi đề xuất chuyển trọng tâm từ các mô hình riêng lẻ sang các quần thể mạng nơ-ron (Schürholt et al., 2021a; 2022a), được huấn luyện theo các yếu tố sinh kiểm soát tức là lựa chọn siêu tham số, seeds, phương pháp khởi tạo. Theo hiểu biết của chúng tôi, không có nghiên cứu nào về thưa thớt hóa trên một quần thể mô hình mạng nơ-ron.

Các đóng góp của chúng tôi: (1) Chúng tôi tạo ra một phiên bản thưa thớt của một vườn thú mô hình có sẵn (Schürholt et al., 2022c) sử dụng hai phương pháp thưa thớt hóa phổ biến, cụ thể là Variational Dropout (VD) (Molchanov et al., 2017) và Magnitude Pruning (MP) (Han et al., 2015; Ström, 1997) và do đó tạo ra một tập dữ liệu bao gồm 33'920 CNN được huấn luyện và thưa thớt với 1'721'600 trạng thái mô hình duy nhất đại diện cho quỹ đạo thưa thớt hóa của chúng. (2) Chúng tôi thực hiện phân tích và so sánh sâu về các vườn thú mô hình thưa thớt và các phương pháp thưa thớt hóa được sử dụng và thấy rằng i) cả hai phương pháp đều hoạt động bền vững trên tất cả các quần thể, ii) MP vượt trội hơn VD ngoại trừ một số tỷ lệ thưa thớt rất cao và iii) tỷ lệ thưa thớt cao hơn được đạt được trong các lớp lớn hơn một cách nhất quán trong các quần thể của vườn thú mô hình. Vì đối với mỗi mô hình riêng lẻ tồn tại một phiên bản dày đặc và tham số hóa đầy đủ cũng như một phiên bản thưa thớt, mối quan hệ của chúng có thể được điều tra. Sự chú ý đặc biệt được dành cho việc điều tra mức độ bền vững của các phương pháp hoạt động trên các vườn thú mô hình được huấn luyện trên các tập dữ liệu khác nhau và với các cấu hình siêu tham số khác nhau. (3) Như mong đợi, trung bình với việc tăng thưa thớt hóa, chúng tôi quan sát thấy một sự sụt giảm hiệu suất trong các quần thể. Tuy nhiên, trong quần thể, chúng tôi có thể tìm thấy các mô hình riêng lẻ ít dễ bị sụt giảm hiệu suất (chúng thân thiện với thưa thớt hóa) hoặc ngược lại, bị ảnh hưởng mạnh hơn bởi sự sụt giảm hiệu suất (chúng khó thưa thớt hóa). (4) Hơn nữa, chúng tôi kiểm tra không gian trọng số của các vườn thú mô hình thưa thớt bằng cách học các siêu biểu diễn của các tham số mô hình riêng lẻ và có thể chỉ ra rằng các thuộc tính mô hình như độ chính xác và thưa thớt tách biệt rất tốt trong không gian tiềm ẩn và có thể được dự đoán từ biểu diễn tiềm ẩn của nó.

2. Công trình liên quan
Thưa thớt hóa Mạng Nơ-ron Thưa thớt hóa mô hình đã được nghiên cứu sâu, (Hoefler et al., 2021) cung cấp một khảo sát về các cách tiếp cận khác nhau. Hầu hết các cách tiếp cận thưa thớt hóa có thể được phân loại là 'không có dữ liệu' hoặc 'nhận biết huấn luyện'. Các cách tiếp cận không có dữ liệu cắt tỉa các mô hình dựa trên cấu trúc của mạng nơ-ron. Magnitude Pruning (MP) (Han et al., 2015; Ström, 1997) là đại diện phổ biến nhất sử dụng giá trị tuyệt đối hoặc tham số làm chỉ báo quan trọng, nhưng một số cách tiếp cận khác đã được đề xuất (Kusupati et al., 2020; Bellec et al., 2017). Nhận biết huấn luyện dựa vào dữ liệu để xác định các tham số có tác động ít nhất đến đầu ra, dựa trên, ví dụ, xấp xỉ bậc nhất (Xiao et al., 2019; Ding et al., 2019; Lis et al., 2019; Lee et al., 2018; Srinivas & Babu, 2015) hoặc bậc hai (Hassibi et al., 1993; Cun et al., 1990; Dong et al., 2017; Wang et al., 2019; Theis et al., 2018; Ba et al., 2016; Martens & Grosse, 2015) của các hàm mất mát. Các phương pháp biến phân như Variational Dropout (VD) (Molchanov et al., 2017) mô hình hóa một cách rõ ràng phân phối của các tham số và loại bỏ những tham số có lượng nhiễu cao.

Một nghiên cứu so sánh lớn về các phương pháp thưa thớt hóa thấy rằng MP đơn giản có thể sánh bằng hoặc vượt trội hơn VD phức tạp hơn trên các mô hình lớn (Gale et al., 2019). Tương tự, (neuralmagic) cung cấp một lựa chọn các NN quy mô lớn được thưa thớt hóa. Mặc dù có sự đa dạng lớn của các phương pháp thưa thớt hóa và việc áp dụng những phương pháp đó cho một loạt đa dạng các NN, thưa thớt hóa chưa được áp dụng và nghiên cứu trên một quần thể lớn các CNN.

Quần thể Mạng Nơ-ron Gần đây, các quần thể mô hình đã trở thành đối tượng nghiên cứu. Một số cách tiếp cận dự đoán thuộc tính mô hình từ các đặc trưng mô hình (Yak et al., 2019; Jiang et al., 2019; Corneanu et al., 2020; Martin & Mahoney, 2019; Unterthiner et al., 2020; Eilertsen et al., 2020) hoặc so sánh các mô hình dựa trên kích hoạt của chúng (Raghu et al., 2017; Morcos et al., 2018; Nguyen et al., 2020). Các phương pháp khác tận dụng các vườn thú cho học chuyển giao hoặc meta learning (Liu et al., 2019; Shu et al., 2021; Ramesh & Chaudhari, 2022). Một hướng công việc khác điều tra không gian trọng số của các mô hình đã huấn luyện (Lucas et al.; Wortsman et al., 2021; Benton et al., 2021; Ainsworth et al., 2022; Ilharco et al., 2022). Gần đây, một số phương pháp đã được đề xuất để học biểu diễn của các mô hình đã huấn luyện (Denil et al., 2013; Berardi et al., 2022; Peebles et al., 2022; Ashkenazi et al., 2022; Wang et al., 2023; Navon et al., 2023). (Schürholt et al., 2021a; 2022a) đề xuất một cách tiếp cận tự giám sát để học biểu diễn của các quần thể mô hình, mà họ gọi là siêu biểu diễn và chỉ ra để tách biệt các thuộc tính mô hình và hữu ích để tạo ra các mô hình mới. Tuy nhiên, chỉ có một số ít tập dữ liệu có cấu trúc của vườn thú mô hình. (Gavrikov & Keuper, 2022) xuất bản và phân tích một tập dữ liệu của các bộ lọc tích chập. (Schürholt et al., 2022c) cung cấp một tập dữ liệu lớn của các mô hình đa dạng, được huấn luyện trước, tạo thành cơ sở cho công việc thưa thớt hóa của chúng tôi.

3. Tạo ra Song sinh Vườn thú Mô hình Thưa thớt
Để phân tích thưa thớt trên các quần thể, chúng tôi áp dụng hai phương pháp thưa thớt hóa trên các vườn thú mô hình được huấn luyện trước hiện có, như được phác thảo trong Hình 1 và 2. Chúng tôi chọn magnitude pruning và variational dropout làm đại diện cho các phương pháp không có dữ liệu và nhận biết huấn luyện, vì chúng có thể được áp dụng cho các CNN nhỏ hoặc trung bình đã được huấn luyện đến hội tụ và các phương pháp phù hợp để mở rộng quy mô cho các quần thể mô hình lớn.

Các vườn thú mô hình của (Schürholt et al., 2022c) phục vụ như điểm khởi đầu của quá trình thưa thớt hóa. Chúng tôi gọi những vườn thú mô hình này là vườn thú mô hình gốc. (Schürholt et al., 2022c) thiết lập một cài đặt của các kiến trúc A và siêu tham số khác nhau trên các tập dữ liệu D khác nhau để tạo ra các vườn thú của họ, mà chúng tôi áp dụng cho công việc này. Các vườn thú được huấn luyện trên MNIST (LeCun et al., 1998), Fashion-MNIST (Xiao et al., 2017), SVHN (Netzer et al., 2011), USPS (Hull, 1994), CIFAR-10 (Krizhevsky, 2009) và STL-10 (Coates et al., 2011) sử dụng một kiến trúc CNN nhỏ. Để thưa thớt hóa các vườn thú mô hình, chúng tôi áp dụng cả hai phương pháp thưa thớt hóa cho trạng thái cuối cùng của mỗi mô hình trong các vườn thú. Để đảm bảo rằng các phiên bản thưa thớt của CNN có thể được so sánh với các phiên bản gốc của chúng, các yếu tố sinh A và D của các mô hình gốc vẫn không thay đổi, ngoại trừ tỷ lệ học.

Magnitude Pruning Để thưa thớt hóa các vườn thú mô hình với MP, chúng tôi chọn một số tỷ lệ thưa thớt và thưa thớt hóa mỗi mô hình trong vườn thú tương ứng. Phần tương ứng của các trọng số có giá trị tuyệt đối nhỏ nhất được đặt thành không và loại bỏ khỏi tập các tham số có thể học. Chúng tôi sử dụng MP không có cấu trúc toàn cục và dựa vào việc triển khai pytorch (Paganini, 2019). MP thường làm tổn hại hiệu suất, vì vậy chúng tôi tinh chỉnh các mô hình đã cắt tỉa trên tập dữ liệu gốc của chúng để phục hồi trong một số epoch cố định. Trong quá trình tinh chỉnh, chúng tôi ghi lại mỗi epoch bằng cách lưu state dict hiện tại của mô hình và báo cáo độ chính xác kiểm tra và khoảng cách tổng quát hóa.

Variational Dropout Theo một thiết lập tương tự, chúng tôi áp dụng VD cho số epoch xác định trên trạng thái cuối cùng của mỗi mô hình trong các vườn thú mô hình. Theo (Gale et al., 2019), chúng tôi giảm tỷ lệ học so với các vườn thú gốc. Sau khi huấn luyện, các tham số có phương sai cao (>3) được loại bỏ khỏi NN. Vì VD bao gồm huấn luyện, chúng tôi không tinh chỉnh các mô hình thêm. Chúng tôi ghi lại mỗi epoch huấn luyện bằng cách lưu state dict cũng như tỷ lệ độ chính xác, độ chính xác kiểm tra và khoảng cách tổng quát hóa.

4. Thí nghiệm
Phần này phác thảo thiết lập thí nghiệm, đánh giá và phân tích của các quần thể mô hình NN thưa thớt được tạo ra.

4.1. Thiết lập Thí nghiệm
Chúng tôi thưa thớt hóa 14 vườn thú mô hình với VD và 10 vườn thú mô hình với MP sử dụng các phương pháp được giới thiệu ở trên. Trong trường hợp MP, chúng tôi thưa thớt hóa mỗi vườn thú với các mức thưa thớt [10;20;30;40;50;60;70;80;90]%. Điều này được theo sau bởi 15 epoch tinh chỉnh, trong đó các trọng số đã cắt tỉa không nhận được cập nhật trọng số. Cho các thí nghiệm của chúng tôi, chúng tôi sử dụng thư viện cắt tỉa của PyTorch (Paganini, 2019). Đối với VD, mỗi tham số trọng số của mô hình nhận được một tham số bổ sung. Mỗi mô hình được huấn luyện trong 25 epoch và các tham số có thể học w và α được tối ưu hóa. Cả w và α được tổng hợp trong một giá trị mỗi tham số α/σ. Các trọng số được cắt tỉa cho α/σ > 3. Để triển khai VD, chúng tôi điều chỉnh các lớp kết nối đầy đủ và tích chập của PyTorch dựa trên mã của một số công trình trước đó (Ryzhikov, 2021; Gale et al., 2019; Molchanov et al., 2017).

Cơ sở hạ tầng Tính toán: Các vườn thú mô hình được thưa thớt hóa trên các node với tối đa 4 CPU và 64g RAM. Thưa thớt hóa một vườn thú 1000 mô hình mất 2-3 ngày. Các vườn thú mô hình lớn và phức tạp hơn bao gồm khoảng 2600 mô hình và đa dạng lớn hơn về siêu tham số có thể mất tới 11 ngày. Siêu biểu diễn được huấn luyện trên một GPU của trạm NVIDIA DGX2 trong tới 12 giờ.

4.2. Đánh giá
Đối với mỗi mô hình ở mỗi trạng thái, chúng tôi ghi lại độ chính xác kiểm tra, khoảng cách tổng quát hóa và tỷ lệ thưa thớt như các chỉ số cơ bản để đánh giá các mô hình. Hơn nữa, chúng tôi tính toán sự đồng thuận giữa các mô hình gốc và thưa thớt và học siêu biểu diễn, để đánh giá cấu trúc của các quần thể mô hình thưa thớt.

Đồng thuận Mô hình Như một thước đo để đánh giá, chúng tôi tính toán sự đồng thuận theo cặp của các mô hình trong các vườn thú mô hình thưa thớt và gốc. Các mô hình đồng thuận khi cả hai dự đoán cùng một lớp với cùng dữ liệu kiểm tra. Mỗi cặp mô hình (k và l) điều này được tổng kết như sau:

aggr = (1/N) ∑(i=1 to N) y_i                                                   (1)

cho các mẫu kiểm tra i = 1, ..., N, trong đó y_i = 1, nếu y_i^k = y_i^l và y_i = 0 ngược lại.

Học Siêu biểu diễn Để hiểu sâu hơn về không gian trọng số của các vườn thú mô hình được tạo với VD, chúng tôi huấn luyện một auto-encoder (AE) dựa trên attention được đề xuất bởi (Schürholt et al., 2022a;b). Chúng tôi học các siêu biểu diễn bất khả tri nhiệm vụ trong một thiết lập học tự giám sát. Những biểu diễn như vậy có thể cung cấp một proxy về mức độ có cấu trúc của quá trình thưa thớt hóa. Rõ ràng, nó cung cấp cái nhìn sâu sắc về mức độ tốt của việc nén trọng số và alpha và mức độ tốt của không gian tiềm ẩn tách biệt các thuộc tính mô hình như độ chính xác hoặc thưa thớt. Chúng tôi điều chỉnh AE để nhận các trọng số không thưa thớt làm đầu vào và tái tạo thành trọng số và bản đồ thưa thớt hóa (α). Để cải thiện chất lượng tái tạo, chúng tôi giới thiệu một chuẩn hóa mất mát mới cho việc tái tạo các tham số alpha được định nghĩa là

L_α^MSE = (1/M) ∑(i=1 to M) ||tanh(α̂_i^t/r) - tanh(α_i^t/r)||²₂                (2)

trong đó t đề cập đến ngưỡng cắt tỉa và r đến phạm vi quan tâm được chọn. Với điều đó, chúng tôi buộc mô hình phải chú ý đến phạm vi hoạt động xung quanh ngưỡng xác định thưa thớt hóa. Chi tiết của mô hình được hiển thị trong Phụ lục G và G.

4.3. Kết quả và Phân tích Thí nghiệm
Trong phần này, chúng tôi phân tích 24 vườn thú mô hình thưa thớt. Do phạm vi lớn của kết quả, chúng tôi chỉ hiển thị những điểm nổi bật ở đây và cung cấp chi tiết đầy đủ trong Phụ lục B và C.

Hiệu suất Bền vững ở Mức Quần thể: Vì các công trình trước đã điều tra thưa thớt hóa trên các mô hình đơn lẻ, hoặc tối ưu hóa siêu tham số của thưa thớt hóa, tính bền vững của các phương pháp thưa thớt hóa trên các quần thể chưa được đánh giá. Các công trình liên quan chỉ ra rằng việc cắt tỉa các tham số dư thừa của một mô hình làm giảm overfitting và do đó cải thiện độ chính xác kiểm tra và tổng quát hóa (Hoefler et al., 2021; Bartoldson et al., 2020). Với việc tiếp tục tăng thưa thớt, các phần chức năng của các mô hình bị loại bỏ và hiệu suất giảm. Để điều tra hiệu suất của các phương pháp, chúng tôi xem xét tỷ lệ thưa thớt, độ chính xác kiểm tra và khoảng cách tổng quát hóa (độ chính xác huấn luyện - độ chính xác kiểm tra) như các chỉ số. Trong các thí nghiệm của chúng tôi, magnitude pruning và variational dropout đã cho thấy hiệu suất thưa thớt hóa bền vững đáng kể trên cơ sở quần thể, bảo tồn độ chính xác gốc cho các mức thưa thớt đáng kể. Như được minh họa trong Hình 2, phân phối của các chỉ số hiệu suất của các mô hình riêng lẻ trong vườn thú rất nhất quán và sự biến thiên từ các mô hình hoạt động tốt nhất đến tệ nhất là thấp. Mặc dù độ lệch chuẩn của hiệu suất cao hơn trên các vườn thú mô hình được huấn luyện trên một tập dữ liệu hình ảnh phức tạp hơn (ví dụ CIFAR-10), các kết quả tương đương được đạt được. Các kết quả hơn nữa xác nhận ở mức quần thể, rằng khoảng cách tổng quát hóa thấp hơn đối với các mô hình có mức thưa thớt hóa vừa phải.

Các Lớp Lớn hơn Đạt Tỷ lệ Thưa thớt Cao hơn Các kết quả trước đây chỉ ra tính bền vững và nhất quán đáng kể trong các kết quả thưa thớt hóa trong và giữa các vườn thú mô hình. Để làm sáng tỏ thêm về các mẫu thưa thớt hóa, chúng tôi điều tra thưa thớt hóa mỗi lớp. Trong các vườn thú, tỷ lệ thưa thớt hóa mỗi lớp là đáng kể nhất quán, xem Hình 3. Trên tất cả các vườn thú, các thí nghiệm của chúng tôi cho thấy rằng các lớp lớn hơn bị cắt tỉa mạnh hơn, vì tồn tại mối quan hệ tích cực giữa số lượng tham số của một lớp và tỷ lệ thưa thớt tương ứng. Mối quan hệ này được thể hiện trong Hình 4. Kết quả chi tiết về thưa thớt mỗi lớp có thể được tìm thấy trong Phụ lục 4, D và E. Điều này có thể chỉ ra rằng việc phân bổ tham số trong kiến trúc cho các vườn thú mô hình gốc của (Schürholt et al., 2022c) không tối ưu. Điều này phù hợp với tài liệu (Hoefler et al., 2021), nêu rằng cắt tỉa hoạt động đặc biệt tốt cho các mô hình quá tham số hóa.

Magnitude Pruning vượt trội hơn Variational Dropout Các công trình liên quan thấy rằng MP có thể vượt trội hơn VD, đặc biệt cho các tỷ lệ thưa thớt vừa phải (Gale et al., 2019). Kết quả của chúng tôi xác nhận điều đó ở mức quần thể. MP vượt trội hơn VD cho các mức thưa thớt hóa lên đến 80% một cách nhất quán, xem Hình 5, Phụ lục B và C. Ở các mức thưa thớt hóa cao hơn, MP cho thấy sự sụt giảm dốc về hiệu suất. VD trên một số vườn thú ổn định hơn và do đó cho thấy hiệu suất cao hơn ở các mức thưa thớt hóa cao hơn, biện minh cho số lượng tham số lớn hơn và tải tính toán.

Đồng thuận giữa Song sinh và Vườn thú Mô hình Gốc Bằng cách phân tích sự đồng thuận giữa các mô hình gốc và song sinh, chúng tôi điều tra mức độ tốt của hai phương pháp bảo tồn hành vi của các mô hình gốc, ngoài mất mát hoặc độ chính xác. Sự đồng thuận được đánh giá cho sáu vườn thú mô hình ở tỷ lệ thưa thớt 60%, 70%, 80% hoặc 90%. Tỷ lệ thưa thớt được chọn sao cho đạt được sự đánh đổi độ chính xác-thưa thớt thuận lợi trong variational dropout.

Kết quả cho thấy mức độ đồng thuận tương đối cao giữa 60 và 80% cho cả hai phương pháp. Không có gì đáng ngạc nhiên, sự đồng thuận cao hơn đối với các mức độ chính xác tổng thể cao hơn. Nói chung, MP đạt được độ chính xác và đồng thuận cao hơn, và do đó xuất hiện để bảo tồn hành vi gốc của mô hình tốt hơn. Kết quả của chúng tôi chỉ ra rằng các chỉ số hiệu suất đơn giản như độ chính xác có thể là một proxy tốt để ước tính hành vi được bảo tồn như đồng thuận.

Hiệu suất của Mô hình Gốc và Thưa thớt có Tương quan Việc thưa thớt hóa các quần thể cho thấy kết quả bền vững đáng kể, như được chỉ ra ở trên. Tuy nhiên, có sự lan tỏa trong hiệu suất của các mô hình thưa thớt, xem Hình 2. Trong thực tế, việc xác định các ứng viên cho hiệu suất cao ở thưa thớt cao trước khi thưa thớt hóa là có liên quan. Như xấp xỉ đầu tiên, chúng tôi tính toán tương quan giữa hiệu suất mô hình trước và sau thưa thớt hóa. Chúng tôi sử dụng hệ số Pearson's r cũng như Kendall's tau, hệ số trước đo hiệp phương sai được chuẩn hóa bởi tích của các phương sai, hệ số sau đo sự đồng thuận trong thứ tự xếp hạng giữa hai mẫu được ghép nối. Kết quả cho thấy tương quan đáng kể cao giữa các mô hình gốc và thưa thớt, xem Bảng 2. Đối với các mức thưa thớt cố định với MP, tương quan Pearson's r trên 90% với một ngoại lệ duy nhất. Kendall's tau tương tự cao, chỉ ra rằng thứ tự xếp hạng của các mẫu vẫn được bảo tồn ở mức độ cao. Vì các mức thưa thớt hóa của các vườn thú VD không nhất quán như vậy, các giá trị tương quan thấp hơn, nhưng xác nhận phát hiện. Do đó, dựa trên kết quả của các quần thể thưa thớt, các mô hình hoạt động tốt nhất có khả năng sẽ là các mô hình thưa thớt tốt nhất hoặc trong số các mô hình thưa thớt tốt nhất.

Biểu diễn Tách biệt được học từ Không gian Trọng số Với AE được sửa đổi và chuẩn hóa mất mát mới của nó, chúng tôi có thể không chỉ tái tạo không gian trọng số của CNN mà còn các tham số alpha cần thiết cho quyết định cắt tỉa trong VD. Kết quả đáng chú ý ở chỗ cả độ chính xác và thưa thớt đều có thể dự đoán cao và do đó tách biệt rất tốt trong không gian tiềm ẩn. Hơn nữa, cả trọng số cũng như alpha đều được tái tạo tốt, chỉ ra mức độ cấu trúc cao trong các quần thể mô hình thưa thớt. Điều này mở ra cánh cửa cho các nỗ lực tương lai để thưa thớt hóa mô hình zero-shot gây ấn tượng về cấu trúc như vậy trên các mô hình được huấn luyện trước. Kết quả được hiển thị trong Bảng 3.

5. Kết luận
Trong công trình này, chúng tôi đã phân tích thưa thớt hóa trên các quần thể lớn của mạng nơ-ron. Sử dụng magnitude pruning và variational dropout làm cách tiếp cận thưa thớt hóa cơ bản, chúng tôi đã tạo ra mười song sinh vườn thú mô hình thưa thớt đại diện cho các tập dữ liệu thị giác máy tính phổ biến. Tổng cộng, chúng tôi đã tạo ra 23'920 mô hình thưa thớt với 1'726'000 trạng thái mô hình được ghi lại. Chúng tôi có thể xác nhận, rằng cả hai cách tiếp cận - magnitude pruning (MP) và variational dropout (VD) - đều hoạt động tốt ở mức quần thể đối với tỷ lệ thưa thớt hóa và độ chính xác. Đối với tỷ lệ thưa thớt hóa dưới 80%, MP vượt trội hơn VD. Ở tỷ lệ thưa thớt hóa cao hơn, cả hai phương pháp đều suy giảm, nhưng VD ổn định hơn. Các mô hình thưa thớt cho thấy sự đồng thuận cao với các mô hình gốc của chúng, không có sự ưu tiên rõ ràng giữa hai cách tiếp cận thưa thớt hóa. Chúng tôi thêm thấy rằng hiệu suất trước và sau thưa thớt hóa có tương quan cao, chỉ ra rằng mô hình hoạt động tốt nhất là ứng viên tốt nhất cho thưa thớt hóa. Các đặc tính thưa thớt hóa mỗi lớp trong các vườn thú đáng ngạc nhiên nhất quán. Điều này dẫn đến việc học siêu biểu diễn trên các vườn thú mô hình thưa thớt, điều này cho thấy thành công bất ngờ. Điều đó chỉ ra rằng thưa thớt hóa có cấu trúc cao, có thể được khai thác cho thưa thớt hóa zero-shot.

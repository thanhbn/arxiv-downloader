# CẮTỈA DỰA TRÊN NEURON CỦA MẠNG NEURAL SÂU
VỚI KHẢ NĂNG TỔNG QUÁT HÓA TỐT HỢN SỬ DỤNG XẤP XỈ ĐỘ CONG KRONECKER

Abdolghani Ebrahimi
Khoa Kỹ thuật Công nghiệp & Khoa học Quản lý
Đại học Northwestern
Evanston, IL 60208
ebrahimi@u.northwestern.edu

Diego Klabjan
Khoa Kỹ thuật Công nghiệp & Khoa học Quản lý
Đại học Northwestern
Evanston, IL 60208
d-klabjan@northwestern.edu

TÓM TẮT
Các phương pháp hiện tại về cắt tỉa mạng neural sâu tập trung vào việc loại bỏ các tham số không cần thiết của mạng đã được huấn luyện và tinh chỉnh mô hình sau đó để tìm một giải pháp tốt khôi phục hiệu suất ban đầu của mô hình đã huấn luyện. Khác với các nghiên cứu khác, phương pháp của chúng tôi đặc biệt chú ý đến chất lượng của giải pháp trong mô hình nén và thời gian tính toán suy luận bằng cách cắt tỉa neuron. Thuật toán được đề xuất hướng dẫn các tham số của mô hình nén về phía một giải pháp phẳng hơn bằng cách khám phá bán kính phổ của Hessian dẫn đến khả năng tổng quát hóa tốt hơn trên dữ liệu chưa thấy. Hơn nữa, phương pháp này không làm việc với mạng đã được huấn luyện trước và thực hiện huấn luyện và cắt tỉa đồng thời. Kết quả của chúng tôi cho thấy nó cải thiện các kết quả hiện đại nhất về nén neuron. Phương pháp này có thể đạt được các mạng rất nhỏ với sự suy giảm độ chính xác nhỏ trên các mô hình mạng neural khác nhau.

Từ khóa: Nén Mạng Neural, Cắt tỉa Mạng, Cực tiểu phẳng.

1 Giới thiệu

Mạng neural sâu (DNN) hiện được sử dụng rộng rãi trong các lĩnh vực như nhận diện đối tượng và xử lý ngôn ngữ tự nhiên do thành công chưa từng có của chúng. Người ta biết rằng hiệu suất của DNN thường được cải thiện bằng cách tăng số lượng lớp và neuron trên mỗi lớp. Việc huấn luyện và triển khai những mạng sâu này đôi khi yêu cầu các thiết bị có sức mạnh tính toán quá mức và bộ nhớ cao. Trong tình huống này, ý tưởng cắt tỉa tham số của DNN với sự giảm hiệu suất tối thiểu là rất quan trọng cho các ứng dụng thời gian thực trên các thiết bị như điện thoại di động với tài nguyên tính toán và bộ nhớ hạn chế. Trong bài báo này, chúng tôi đề xuất một thuật toán để cắt tỉa neuron trong DNN với sự chú ý đặc biệt đến hiệu suất của mạng đã được cắt tỉa. Nói cách khác, thuật toán của chúng tôi hướng dẫn các tham số của mạng đã cắt tỉa về phía các vùng phẳng hơn và do đó tổng quát hóa tốt hơn trên dữ liệu chưa thấy.

Trong tất cả các nghiên cứu về cắt tỉa mạng, mục tiêu là học một mạng với số lượng tham số nhỏ hơn nhiều có thể khớp gần như hoàn hảo với hiệu suất của mạng có quá nhiều tham số. Hầu hết các nghiên cứu trong lĩnh vực này tập trung vào việc cắt tỉa các trọng số trong mạng hơn là cắt tỉa neuron. Như [26] và [34] thảo luận trong nghiên cứu của họ, việc cắt tỉa trọng số bằng cách đặt chúng về không không nhất thiết dẫn đến thời gian suy luận nhanh hơn vì cần phần mềm chuyên biệt được thiết kế để làm việc với tensor thưa để đạt được điều này. Tuy nhiên, nghiên cứu của chúng tôi tập trung vào việc cắt tỉa neuron khỏi mạng, điều này trực tiếp dẫn đến thời gian suy luận nhanh hơn khi sử dụng phần mềm thông thường hiện tại vì việc cắt tỉa neuron dẫn đến tensor có chiều thấp hơn.

Khung cắt tỉa được đề xuất ở đây lặp lại hai bước sau: (1) cho một tập con neuron, chúng tôi huấn luyện mạng cơ bản với mục tiêu tổn thất thấp và "độ phẳng", (2) cho một mạng đã được huấn luyện trên một tập con neuron, chúng tôi tính toán gradient của mỗi neuron đối với việc có mặt hay không trong tập con neuron tiếp theo. Về bước đầu tiên, chúng tôi coi độ phẳng được đo bằng bán kính phổ của Hessian. Điều này đòi hỏi tính toán bán kính phổ được xấp xỉ bằng cách tính toán bán kính phổ của xấp xỉ đường chéo khối Kronecker-factored Approximate Curvature (K-FAC) của nó. Khái niệm độ phẳng đến từ [31] nhưng việc sử dụng K-FAC là hoàn toàn mới. Trong bước thứ hai, việc lựa chọn neuron là nhị phân được xấp xỉ là liên tục trong khoảng [0,1]. Gradient sau đó được tính toán đối với tổn thất cộng với bán kính phổ của K-FAC. Các neuron có giá trị gradient lớn được chọn cho mạng tiếp theo.

Phương pháp được đề xuất cải thiện kết quả độ chính xác tổng quát hóa trên tập dữ liệu xác thực so với các kết quả hiện đại nhất. Trong tất cả bốn thí nghiệm trên các kiến trúc khác nhau, kết quả của chúng tôi vượt trội khi mức độ thưa thấp hơn một ngưỡng (khoảng 50% mức độ thưa cho ba tập dữ liệu). Diện tích dưới đường cong đối với độ thưa và độ chính xác cao hơn cho phương pháp của chúng tôi từ khoảng 1% và lên đến 9%.

Có một khối lượng lớn nghiên cứu về cắt tỉa và nén mạng (xem [5] để có danh sách đầy đủ các nghiên cứu), tuy nhiên, trọng tâm của chúng là thiết kế các thuật toán để tạo ra các mạng nhỏ hơn mà không có sự sụt giảm đáng kể về độ chính xác. Không có nghiên cứu nào trong số đó cố gắng tìm giải pháp với cực tiểu phẳng hơn trong mạng nén. Theo hiểu biết tốt nhất của chúng tôi, nghiên cứu của chúng tôi là nghiên cứu đầu tiên tính đến điều đó và cố gắng tìm giải pháp có tính chất tổng quát hóa tốt hơn. Cụ thể, chúng tôi đóng góp những điều sau đây.

• Chúng tôi xây dựng dựa trên nghiên cứu của [31] và cải thiện nghiên cứu của họ bằng cách sử dụng K-FAC để tính toán bán kính phổ của Hessian và vector riêng tương ứng của nó. Thuật toán của chúng tôi có thể dễ dàng được song song hóa để tính toán nhanh hơn. Điều này tránh việc sử dụng thuật toán lặp lũy thừa có thể không hội tụ trong một số lần lặp và thời gian hợp lý.

• Chúng tôi cung cấp một thuật toán để học một mạng nhỏ với bán kính phổ thấp từ một mạng lớn hơn nhiều. Mặc dù cắt tỉa một phần lớn neuron, độ chính xác vẫn gần như giống với mạng lớn hơn trên các kiến trúc khác nhau.

• Phương pháp của chúng tôi cho phép cắt tỉa quyết liệt neuron của mạng neural trong mỗi epoch cắt tỉa, trong khi các phương pháp khác như [26] thận trọng và chỉ cắt tỉa một neuron cho mỗi epoch cắt tỉa.

• Thuật toán của chúng tôi có thể đạt được các mạng rất nhỏ với sự suy giảm độ chính xác thực sự nhỏ trên các mô hình mạng neural khác nhau và vượt trội hơn tài liệu hiện có về cắt tỉa neuron trên hầu hết các kiến trúc mạng mà chúng tôi thí nghiệm.

Phần còn lại của bài báo này được tổ chức như sau. Trong Phần 2, chúng tôi tổng quan các nghiên cứu liên quan. Chúng tôi định nghĩa chính thức vấn đề của mình, mô hình hóa nó như một bài toán tối ưu và cung cấp một thuật toán để giải quyết nó trong Phần 3. Cuối cùng, trong Phần 4, chúng tôi áp dụng thuật toán trên các kiến trúc hiện đại khác nhau và tiến hành nghiên cứu loại bỏ để chứng minh hiệu quả của phương pháp và thảo luận các kết quả.

2 Tổng quan Tài liệu

Nghiên cứu của chúng tôi có liên quan chặt chẽ đến hai dòng nghiên cứu khác nhau: 1) cắt tỉa và nén mạng; và 2) tổng quát hóa tốt hơn trong học sâu. Chúng tôi xem xét từng dòng trong các đoạn sau.

Cắt tỉa và nén mạng. Nghiên cứu [7] chứng minh sự dư thừa đáng kể của tham số trên một số kiến trúc khác nhau. Sự dư thừa này dẫn đến lãng phí tính toán và bộ nhớ và thường đỉnh điểm trong việc quá khớp. Điều này mở ra một cơ hội lớn để phát triển ý tưởng thu nhỏ các mạng có quá nhiều tham số. Hầu hết các nghiên cứu trong lĩnh vực này tập trung vào việc cắt tỉa trọng số. Các nghiên cứu sớm về cắt tỉa trọng số bắt đầu với các thuật toán Optimal Brain Damage [20] và Optimal Brain Surgeon [10]. Những phương pháp này tập trung vào khai triển Taylor của hàm tổn thất và cắt tỉa những trọng số làm tăng hàm tổn thất với giá trị nhỏ nhất. Chúng cần tính toán Hessian của hàm tổn thất có thể cồng kềnh trong các mạng lớn với hàng triệu tham số. Để tránh điều này, chúng sử dụng xấp xỉ đường chéo của Hessian. Chính quy hóa là một cách phổ biến khác để cắt tỉa DNN và đối phó với quá khớp. [14] và [4] bổ sung hàm tổn thất với các số hạng chính quy hóa L0 hoặc L1. Điều đó đặt một số trọng số rất gần với không. Cuối cùng, người ta có thể loại bỏ các trọng số có giá trị nhỏ hơn một ngưỡng. [9] là một trong những nghiên cứu thành công nhất trong cắt tỉa trọng số. Họ chỉ đơn giản sử dụng một mô hình đã được huấn luyện và loại bỏ các trọng số có giá trị dưới ngưỡng và tinh chỉnh mạng kết quả. Quy trình này có thể được lặp lại cho đến khi đạt được một mức độ thưa cụ thể. Tuy nhiên, sự thay đổi này giữa cắt tỉa và huấn luyện có thể dài và tẻ nhạt. Để tránh điều này, [22] phát triển một thuật toán cắt tỉa trọng số trước khi huấn luyện mạng. Họ sử dụng một biến mặt nạ cho mỗi trọng số và tính toán đạo hàm của hàm tổn thất đối với các biến mặt nạ đó và sử dụng điều đó như một đại diện cho độ nhạy của hàm tổn thất đối với trọng số đó. Lược đồ cắt tỉa của chúng tôi có phần liên quan đến nghiên cứu này. Chúng tôi xem xét độ nhạy của hàm tổn thất bao gồm bán kính phổ đối với neuron hơn là trọng số.

Mặt khác, một số nghiên cứu nén tập trung vào việc cắt tỉa neuron. Nghiên cứu của chúng tôi thuộc nhóm phương pháp này. Như [26] thảo luận, với phần mềm hiện tại, việc cắt tỉa neuron hiệu quả hơn để dẫn đến thời gian suy luận nhanh hơn và đó là lý do chính để chúng tôi tập trung vào việc cắt tỉa neuron trong bài báo này. [35] sử dụng một phương pháp cắt tỉa không có dữ liệu dựa trên ý tưởng về các neuron tương tự. Phương pháp của họ chỉ áp dụng được cho các mạng kết nối đầy đủ. [12] nhận thấy rằng hầu hết các neuron trong các mạng lớn có giá trị kích hoạt gần với không bất kể đầu vào cho những neuron đó và không đóng vai trò quan trọng trong độ chính xác dự đoán. Quan sát này dẫn đến một lược đồ để cắt tỉa những neuron kích hoạt không này. Để khôi phục hiệu suất của mạng từ việc cắt tỉa những neuron này, họ thay đổi giữa cắt tỉa neuron và huấn luyện. Một số nghiên cứu về cắt tỉa neuron được thiết kế đặc biệt cho Mạng Neural Tích chập (CNN) vì chúng đòi hỏi tính toán nhiều hơn so với các lớp kết nối đầy đủ [23]. Có nhiều nghiên cứu về cắt tỉa bộ lọc (bản đồ đặc trưng) trong CNN (xem [34,23,2] như ví dụ). Lược đồ cắt tỉa neuron của chúng tôi được lấy cảm hứng từ nghiên cứu của [26] về cắt tỉa bộ lọc CNN. Họ áp dụng khai triển Taylor của hàm tổn thất để tìm hiểu việc cắt tỉa mỗi bộ lọc trong một lớp tích chập thay đổi hàm tổn thất bao nhiêu và cắt tỉa những bộ lọc đóng góp ít nhất cho sự thay đổi. Mặc dù chúng tôi sử dụng cùng tiêu chí cắt tỉa, nghiên cứu của chúng tôi khác với của họ trong ba cách quan trọng sau. Đầu tiên, họ làm việc với các mô hình đã được huấn luyện đầy đủ và áp dụng cắt tỉa cho nó. Thay vào đó, nghiên cứu của chúng tôi tích hợp các phần huấn luyện và cắt tỉa lại với nhau. Thứ hai, chúng tôi bổ sung hàm tổn thất với một số hạng liên quan đến bán kính phổ của Hessian và do đó lược đồ cắt tỉa neuron của chúng tôi nhạy cảm với sự thay đổi trong độ phẳng của một giải pháp ngoài sự thay đổi trong hàm tổn thất. Cuối cùng, lược đồ cắt tỉa của chúng tôi không chỉ được áp dụng để cắt tỉa bộ lọc trong CNN. Nó tổng quát hơn và có thể được sử dụng để cắt tỉa các loại lớp khác như các lớp kết nối đầy đủ.

Tổng quát hóa tốt hơn trong học sâu. Nghiên cứu ban đầu [21] quan sát thấy rằng thuật toán Stochastic Gradient Descent (SGD) và các phương pháp tương tự như RMSProp [36] và ADAM [17] tổng quát hóa tốt hơn trên dữ liệu mới khi mạng được huấn luyện với kích thước mini-batch nhỏ hơn. [16] chứng minh thực nghiệm rằng việc sử dụng kích thước mini-batch nhỏ hơn với SGD có xu hướng hội tụ đến cực tiểu phẳng hơn và đó là lý do chính cho việc tổng quát hóa tốt hơn. [15] sau đó cho thấy rằng việc sử dụng tốc độ học lớn hơn cũng đóng vai trò quan trọng trong việc hội tụ đến cực tiểu phẳng hơn. Nghiên cứu của họ về cơ bản nghiên cứu ảnh hưởng của tỷ lệ tốc độ học với kích thước mini-batch đến việc tổng quát hóa các giải pháp tìm được trên dữ liệu chưa thấy. Gần như tất cả các nghiên cứu trong lĩnh vực này tập trung vào việc điều tra ảnh hưởng của các siêu tham số như kích thước mini-batch và tốc độ học đến độ cong của giải pháp đạt được.

Mặc dù phát hiện này, đã có rất ít nỗ lực trong việc thiết kế các thuật toán được đảm bảo hội tụ đến cực tiểu phẳng hơn. Nghiên cứu [31] là nghiên cứu duy nhất khám phá vấn đề này trong cài đặt học sâu và cố gắng tìm một giải pháp cực tiểu phẳng hơn một cách thuật toán. Để đạt được các giải pháp phẳng hơn, họ bổ sung hàm tổn thất với bán kính phổ của Hessian của hàm tổn thất. Để tính toán cái sau, họ sử dụng lặp lũy thừa cùng với một quy trình hiệu quả được gọi là R-Op [30] để tính toán tích vector Hessian. Điều này có nghĩa là họ cần sử dụng thuật toán lặp lũy thừa trong mỗi bước tối ưu hóa của thuật toán của họ. Một nhược điểm tiềm ẩn của việc sử dụng lặp lũy thừa là nó có thể không hội tụ trong một số lần lặp hợp lý. Để tránh điều này, chúng tôi mượn ý tưởng từ K-FAC được phát triển ban đầu bởi [25] và [8] để áp dụng gradient descent tự nhiên [1] cho tối ưu hóa học sâu. Phương pháp được đề xuất của chúng tôi thêm cùng số hạng phạt, tuy nhiên chúng tôi sử dụng K-FAC như một phương pháp khác để tìm bán kính phổ xấp xỉ của Hessian. Ngoài ra, chúng tôi sử dụng hàm tổn thất bổ sung không chỉ để huấn luyện mà còn cho mục đích cắt tỉa. K-FAC sử dụng tích Kronecker để xấp xỉ ma trận thông tin Fisher là một xấp xỉ nửa xác định dương của Hessian. K-FAC xấp xỉ ma trận thông tin Fisher bằng một ma trận đường chéo khối trong đó mỗi khối được liên kết với một lớp trong kiến trúc mạng neural. Một xấp xỉ nửa xác định dương khác được sử dụng rộng rãi thay cho Hessian là ma trận Gauss-Newton (GN). Nghiên cứu [3] cho thấy rằng khi các hàm kích hoạt được sử dụng trong mạng neural là tuyến tính từng khúc, ví dụ: đơn vị tuyến tính chỉnh lưu tiêu chuẩn (ReLU) và đơn vị tuyến tính chỉnh lưu rò rỉ (Leaky ReLU), các khối đường chéo trong Hessian và GN là giống nhau. Mặt khác, [24] và [28] chứng minh rằng đối với các hàm tổn thất điển hình trong học máy như cross-entropy và squared error, thông tin Fisher và ma trận GN là giống nhau. Những quan sát này biện minh cho việc sử dụng K-FAC để xấp xỉ Hessian của mỗi lớp trong cài đặt học sâu vì hầu hết các kiến trúc mạng neural hiện đại sử dụng ReLU làm hàm kích hoạt của chúng.

3 Phương pháp Đề xuất

Mục tiêu của chúng tôi ở đây là thiết kế một thuật toán mà cho một tập dữ liệu và một kiến trúc mạng neural cẩn thận cắt tỉa các neuron dư thừa trong quá trình huấn luyện và tạo ra một mạng nhỏ hơn với giải pháp cực tiểu phẳng. Để làm điều này, trước tiên chúng tôi giới thiệu bài toán tối ưu cơ bản và sau đó thảo luận thuật toán để giải quyết nó.

3.1 Bài toán Tối ưu cho Cắt tỉa và Huấn luyện Tích hợp

Chúng ta được cho dữ liệu huấn luyện D = {(xi, yi)}^n_{i=1} trong đó x đại diện cho đặc trưng và y đại diện cho giá trị mục tiêu và một mạng neural với tổng N neuron. Chúng ta định nghĩa tập hợp tất cả các tham số của mạng neural với ℓ lớp và tổng số tham số d là W = (w^1_1, w^2_1, ..., w^{n_1}_1, ..., w^1_ℓ, w^2_ℓ, ..., w^{n_ℓ}_ℓ) ∈ ℝ^d. Ở đây, n_l đại diện cho số neuron trong lớp l ∈ [ℓ] (trong đó [x] := {1, 2, ..., x}) và w^j_l đại diện cho các tham số liên kết với neuron j ∈ [n_ℓ] trong lớp l ∈ [ℓ]. Vì chúng ta cần bài toán tối ưu để xác định và cắt tỉa các neuron dư thừa, chúng ta giới thiệu tập hợp các biến nhị phân (mặt nạ) M_B = (m^1_1, m^2_1, ..., m^{n_1}_1, ..., m^1_ℓ, m^2_ℓ, ..., m^{n_ℓ}_ℓ) ∈ {0,1}^N. Chúng ta cũng định nghĩa M = (m^1_1 e_{(1,1)}, m^2_1 e_{(1,2)}, ..., m^{n_1}_1 e_{(1,n_1)}, ..., m^1_ℓ e_{(ℓ,1)}, m^2_ℓ e_{(ℓ,2)}, ..., m^{n_ℓ}_ℓ e_{(ℓ,n_ℓ)}) ∈ {0,1}^d trong đó e_s = (1, ..., 1) ∈ ℝ^s và (i,j) là chiều của w^j_i. Mỗi phần tử trong M_B được liên kết với một trong các neuron và xác định liệu một neuron kích hoạt (giá trị 1) hay cần được cắt tỉa (giá trị 0) trong kiến trúc mạng neural. Để đạt được một giải pháp với độ cong phẳng hơn, chúng ta biểu diễn bán kính phổ của Hessian (hoặc xấp xỉ của nó) của hàm tổn thất C (ví dụ: cross entropy) tại điểm W là ρ_C(H(W)). Sau đó, cho số neuron tối đa được phép K và cận trên B trên bán kính phổ của Hessian, bài toán tối ưu có thể được viết như bài toán ràng buộc sau:

min_{W,M_B} C(W ⊙ M, D);
s.t. ρ_C(H(W ⊙ M)) ≤ B;
M^T_B e_N ≤ K; (1)

trong đó ⊙ là tích Hadamard. Một nhược điểm của công thức (1) là không thể xử lý được việc dẫn xuất trực tiếp Hessian của hàm tổn thất và sau đó là bán kính phổ của nó trong DNN với hàng triệu tham số. Để đối phó với điều này, chúng tôi theo [31] và viết lại ρ(H(W ⊙ M)) theo vector v(W,M) trong đó ||v(W,M)|| = 1 và nó biểu thị vector riêng tương ứng với giá trị riêng của H(W ⊙ M) có giá trị tuyệt đối lớn nhất. Chúng ta cũng đưa ràng buộc về bán kính phổ vào hàm mục tiêu như sau:

min_{W,M_B} L(W,M_B,D) = C(W ⊙ M, D) + g(W,M)
s.t. M^T_B e_N ≤ K; (2)

trong đó g(W,M) := max{0, v^T(W,M)H(W ⊙ M)v(W,M) - B} và λ là một siêu tham số cần được điều chỉnh. λ càng lớn, bài toán tối ưu phạt bán kính phổ lớn hơn càng nhiều và hàm tổn thất có độ cong phẳng hơn tại điểm giải pháp. Để tính toán g(W,M), người ta cần có thể tính toán v(W,M). Để làm điều này, chúng tôi theo [25] và xấp xỉ Hessian của hàm tổn thất bằng một ma trận đường chéo khối trong đó mỗi khối là đạo hàm bậc hai của hàm tổn thất đối với các tham số của mỗi lớp. Nói cách khác, ký hiệu kích hoạt và đầu vào (còn gọi là pre-activations) cho lớp l ∈ [ℓ] với a_l(W,M) và s_l(W,M), tương ứng, và định nghĩa g_l(W,M) := ∂L(W,M,D)/∂s_l(W,M) chúng ta có:

H(W ⊙ M) ≈ [Ã_0(W ⊙ M) ⊗ G̃_0(W ⊙ M)  0                              ...
               0                              Ã_1(W ⊙ M) ⊗ G̃_1(W ⊙ M)  ...
               ...                            ...                         ...
               0                              0                          Ã_{ℓ-1}(W ⊙ M) ⊗ G̃_ℓ(W ⊙ M)] (3)

Trong (3), Ã_l(W ⊙ M) := E[a_l(W,M)a^T_l(W,M)] và G̃_l(W ⊙ M) := E[g_l(W,M)g^T_l(W,M)] biểu thị các ma trận moment bậc hai cho kích hoạt và đạo hàm của pre-activations cho lớp l, tương ứng. Chú ý rằng không cần tài nguyên tính toán bổ sung để dẫn xuất g_l(W,M) và a_l(W,M) vì chúng được dẫn xuất như một sản phẩm phụ của quy trình lan truyền ngược. Đặt v_l(W,M) biểu thị vector riêng tương ứng với giá trị riêng tuyệt đối lớn nhất λ_l(W,M) cho khối (lớp) l. Chúng ta cũng định nghĩa các giá trị riêng tương tự λ̃^A_l(W,M) và λ̃^G_l(W,M) cùng với các vector riêng tương ứng ṽ^A_l(W,M) và ṽ^G_l(W,M) cho các ma trận Ã_l(W ⊙ M) và G̃_l(W ⊙ M), tương ứng. Sau đó, chúng ta có thể sử dụng các tính chất của tích Kronecker (xem [32]) để tạo ra:

v_l(W,M) = ṽ^A_l(W,M) ⊗ ṽ^G_l(W,M)
λ_l(W,M) = λ̃^A_l(W,M) · λ̃^G_l(W,M) (4)

Một khi chúng ta có v_l(W,M) cho mỗi khối l, việc xấp xỉ v(W,M) là tầm thường cho các tính chất của ma trận đường chéo khối.

Bài toán tối ưu (2) có N biến bổ sung M_B và không thể giải trực tiếp bằng các phương pháp tối ưu liên tục như SGD do sự tồn tại của các biến mặt nạ không liên tục M_B. Tuy nhiên, việc tách biệt các tham số neuron với mặt nạ neuron, tạo điều kiện đo lường đóng góp của mỗi neuron vào hàm tổn thất. Nói cách khác, chúng ta coi độ nhạy của hàm tổn thất đối với mỗi neuron như một thước đo tầm quan trọng và chỉ giữ lại những neuron có độ nhạy cao nhất. Để làm điều này, vì các biến trong M_B là nhị phân, độ nhạy của hàm tổn thất đối với neuron j ∈ [n_ℓ] trong lớp l ∈ [ℓ] được định nghĩa là:

δL^j_l(W,M_B) := |L(W,M_B|m^j_l = 0,D) - L(W,M_B|m^j_l = 1,D)| (5)

trong đó M_B|m^j_l = 0, M_B|m^j_l = 1 là hai vector có cùng giá trị cho tất cả neuron ngoại trừ neuron j trong lớp l. Theo [26] và sử dụng xấp xỉ Taylor bậc nhất của L(W,M_B|m^j_l = 0) quanh a^j_l(W,M) = 0, chúng ta ước tính (5) bằng

δL^j_l(W,M_B) := |∂L(W,M_B,D)/∂a^j_l(W,M) · a^j_l(W,M)| (6)

Điều này một cách trực quan có nghĩa là tầm quan trọng của một neuron trong mạng neural phụ thuộc vào hai giá trị: độ lớn của gradient của hàm tổn thất đối với kích hoạt của neuron và độ lớn của kích hoạt. Đáng chú ý là giá trị số của ∂L(W,M_B,D)/∂a^j_l(W,M) cũng được dẫn xuất trong quá trình lan truyền ngược và không cần tính toán thêm. Theo thảo luận của chúng tôi từ trên, chúng tôi cung cấp thuật toán để giải bài toán tối thiểu hóa (2).

3.2 Thuật toán

Thuật toán, Higher Generalization Neuron Pruning (HGNP), giải bài toán tối ưu 2 bằng cách cập nhật W và M luân phiên. Khi các tham số W đang được cập nhật, chúng ta cố định vector mặt nạ nhị phân M và ngược lại. Quy trình luân phiên giữa cập nhật vector mặt nạ M và trọng số W xảy ra dần dần trong quá trình huấn luyện để tránh sự sụt giảm đáng kể trong hiệu suất của mô hình. Việc cắt tỉa quá nhiều neuron trong một lần có thể dẫn đến sự sụt giảm hiệu suất không thể khôi phục và có thể dẫn đến độ chính xác xác thực thấp của mô hình đã cắt tỉa cuối cùng. Để cập nhật các tham số W, chúng ta cố định các biến mặt nạ M_B = M̂_B cho một số lần lặp nhất định và cập nhật trọng số W bằng cách theo Thuật toán 1. Thuật toán này về cơ bản giải bài toán tối ưu min_W L(W, M̂_B, D) cho M̂_B cố định.

Thuật toán 1: Thuật toán Mini-Batch SGD để cập nhật W cho vector mặt nạ cố định M̂_B
Đầu vào: D: dữ liệu huấn luyện, M̂_B: vector mặt nạ cho trước, Ŵ: trọng số khởi tạo cho trước, η: tốc độ học, λ: hệ số cho bán kính phổ, B: cận trên bán kính phổ.
Đầu ra: W: trọng số đã cập nhật.
Khởi tạo W ← Ŵ.
while tiêu chí hội tụ chưa đạt do
    foreach batch dữ liệu D_b do
        Tính toán ∇_W C(W ⊙ M̂, D_b)
        /* Các thao tác số hạng bán kính phổ */
        for l = 0, 1, ..., ℓ do
            Dẫn xuất ṽ^A_l(W, M̂), ṽ^G_l(W, M̂) và giá trị riêng λ̃^A_l(W, M̂), λ̃^G_l(W, M̂).
            Tính toán v_l(W, M̂) và λ_l(W, M̂) sử dụng 4.
        Xấp xỉ v(W, M̂) và giá trị riêng tương ứng ρ_C(H(W ⊙ M̂)) sử dụng các vector riêng và giá trị riêng dẫn xuất cho mỗi khối.
        Tính toán sử dụng R2-Op từ [31]:
        ∇_W ρ_C(H(W ⊙ M̂)) = 1/|D_b| ∑_{i∈D_b} v(W, M̂)^T ∇_W H_i(W ⊙ M̂) v(W, M̂) trong đó chỉ số i cho thấy rằng Hessian được tính toán đối với mẫu đơn i.
        Dẫn xuất ∇_W g(W, M̂) sử dụng ∇_W ρ_C(H(W ⊙ M̂)).
        /* Gradient descent */
        Đặt W = W - η[∇_W C(W ⊙ M̂, D_b) + λ∇_W g(W, M̂)]

Để cập nhật M_B, chúng ta áp dụng 6 cho một mini-batch ngẫu nhiên để tìm các neuron mà hàm tổn thất ít nhạy cảm nhất. Chúng ta cập nhật M_B bằng cách đặt biến mặt nạ liên kết với những neuron như vậy về không. Điều đó có nghĩa là chúng ta có thể loại bỏ những neuron như vậy khỏi mạng neural và tạo lại một mạng neural mới với các neuron còn lại và trọng số liên kết của chúng trong vector tham số W. Bây giờ chúng ta có thể sử dụng khái niệm này để cắt tỉa neuron cùng với Thuật toán 1 để đề xuất Thuật toán 2.

Thuật toán bắt đầu với khởi tạo ngẫu nhiên các tham số W_0. Chúng ta cố định các biến mặt nạ M_B thành tất cả một lúc đầu và cập nhật W sử dụng SGD cho E_1 epoch huấn luyện. Sau khi thực hiện các bước huấn luyện trước cắt tỉa, chúng ta cắt tỉa mạng neural lần đầu tiên bằng cách cắt tỉa N neuron có ảnh hưởng nhỏ nhất đến sự thay đổi hàm tổn thất. Sau đó chúng ta luân phiên giữa huấn luyện và cắt tỉa mỗi E_2 epoch và tiếp tục cắt tỉa cho đến khi đạt được một mức độ thưa cụ thể. Ở đây, chúng ta định nghĩa mức độ thưa := ||W ⊙ M||_0 / ||W_ed||_0. Mặc dù chúng ta dừng thuật toán sử dụng cùng thước đo, tức là mức độ thưa, như các nghiên cứu khác trong cắt tỉa trọng số, có một sự khác biệt cơ bản giữa kiến trúc mạng thực tế sau khi cắt tỉa trong nghiên cứu của chúng tôi và các nghiên cứu khác. Trong trường hợp của chúng tôi, chúng ta loại bỏ tất cả các trọng số liên kết với các neuron đã cắt tỉa, nhưng trong các nghiên cứu khác, những trọng số như vậy được đặt về không. Một khi đạt được mức độ thưa mong muốn, tức là σ, chúng ta huấn luyện mạng cho E_3 epoch cuối cùng.

Người ta nên chú ý rằng các giá trị E_1, E_2, E_3 và N là các siêu tham số và cần được điều chỉnh và thay đổi trên các kiến trúc mạng neural khác nhau. Chúng tôi tóm tắt quy trình trên trong Thuật toán 2 trong đó chúng tôi bỏ các tham số (W,M) từ δL^j_l(W,M) và gọi nó là δL^j_l để đơn giản.

Thuật toán 2: Thuật toán HGNP để cập nhật tham số W và vector mặt nạ M_B để giải bài toán tối ưu 2.
Đầu vào: D: dữ liệu huấn luyện, W_0: trọng số khởi tạo cho trước, η: tốc độ học, λ: hệ số cho bán kính phổ, B: cận trên bán kính phổ, σ: mức độ thưa mong muốn, N: số neuron được cắt tỉa trong mỗi vòng, E_1, E_2, E_3: số epoch huấn luyện trước cắt tỉa, giữa cắt tỉa và sau cắt tỉa.
Đầu ra: W: trọng số đã cập nhật, M: vector mặt nạ cuối cùng.
Khởi tạo W ← W_0, M ← e_d, σ̂ = 1, epoch = 0.
while σ̂ > σ do
    if epoch ≥ E_1 and epoch mod E_2 = 0 then
        Chọn một mini-batch ngẫu nhiên D_b.
        Tính toán δL^j_l sử dụng 6 cho mini-batch D_b.
        Chuẩn hóa δL^j_l theo lớp sử dụng: δL^j_l = δL^j_l / √(∑^{n_l}_{k=1}(δL^k_l)^2)
        Chọn N neuron có δL^j_l nhỏ nhất và đặt giá trị mặt nạ tương ứng của chúng trong vector M_B bằng không.
        Cập nhật: σ̂ ← ||W ⊙ M||_0 / ||W_ed||_0
    Hoàn thành một epoch huấn luyện để giải min_W L(W,M_B,D) sử dụng Thuật toán 1 và cập nhật W.
    Cập nhật: epoch ← epoch + 1
Huấn luyện mạng neural thêm E_3 epoch sử dụng Thuật toán 1.

4 Nghiên cứu Thực nghiệm

Trong phần này, chúng tôi sử dụng một số tập dữ liệu được sử dụng rộng rãi và thuật toán HGNP để chọn các mô hình mạng phổ biến trong học sâu và phân tích kết quả. Các tập dữ liệu được sử dụng trong các thí nghiệm như sau.

Cifar-10: Được thu thập bởi [19], tập dữ liệu này chứa 60,000 hình ảnh màu 32×32 với 10 nhãn khác nhau. Chúng tôi sử dụng 50,000 mẫu để huấn luyện và giữ lại phần còn lại cho mục đích xác thực. Chúng tôi sử dụng kỹ thuật thông thường như lật ngang ngẫu nhiên để tăng cường dữ liệu.

Tập dữ liệu Oxford Flowers 102: Tập dữ liệu này được giới thiệu bởi [27] và có 2,040 mẫu huấn luyện và 6,149 mẫu xác thực. Số loại hoa là 102 và mỗi hình ảnh là RGB với kích thước 224×224. Chúng tôi sử dụng lật ngang ngẫu nhiên để tăng cường dữ liệu.

Caltech-UCSD Birds 200 (CUB-200): Tập dữ liệu được giới thiệu trong [37] và chứa 5,994 mẫu huấn luyện và 5,794 mẫu kiểm tra. Nó chứa hình ảnh của 200 loài chim. Cho thí nghiệm trên tập dữ liệu chim, chúng tôi cắt tất cả hình ảnh thành 160×160 để tránh các vấn đề về bộ nhớ trong khi chúng tôi huấn luyện mô hình sử dụng thuật toán HGNP.

Chúng tôi so sánh chất lượng của mạng đã cắt tỉa và giải pháp cực tiểu của nó với Taylor [26]. Chúng tôi chọn Taylor làm điểm chuẩn duy nhất vì nghiên cứu của họ rất gần đây và nó vượt trội hơn các phương pháp cắt tỉa neuron khác mà chúng tôi đã đề cập trong Phần 2. Trừ khi có nói khác, chúng tôi sử dụng dữ liệu huấn luyện để huấn luyện mô hình và áp dụng lược đồ cắt tỉa. Trong tất cả các thí nghiệm, độ chính xác trên cùng tập dữ liệu xác thực được đo và được báo cáo để so sánh phương pháp của chúng tôi với Taylor.

Chúng tôi áp dụng các kiến trúc phổ biến khác nhau AlexNet [18], ResNet-18 [11] và VGG-16 [33]. Chúng tôi chọn Alexnet và VGG-16 vì chúng được sử dụng trong [26] trong các thí nghiệm của họ. Để cho thấy rằng phương pháp của chúng tôi hoạt động tốt với các kiến trúc mới hơn, chúng tôi chọn Resnet-18 vì nó có sức mạnh của mạng residual và có thể được huấn luyện trong thời gian hợp lý. Chúng tôi sử dụng Pytorch [29] để huấn luyện mạng neural và tự động vi phân trên GPU. Các thí nghiệm Alexnet được tiến hành sử dụng một, ba Tesla K80 GPU cho phương pháp HGNP và Taylor, tương ứng. Tất cả các thí nghiệm Taylor khác sử dụng một GeForce RTX 2080 duy nhất. Đối với phương pháp HGNP, chúng tôi sử dụng bốn, bốn và năm GeForce RTX 2080 GPU để chạy các thí nghiệm VGG-16/Cifar-10, ResNet-18/Cifar-10 và ResNet-18/Birds 200 dataset, tương ứng.

4.1 Các Kiến trúc Phổ biến Khác nhau

Thí nghiệm AlexNet: Cho thí nghiệm đầu tiên, chúng tôi theo bài báo Taylor và áp dụng AlexNet để dự đoán các loài hoa khác nhau trên tập dữ liệu Oxford Flowers. Việc huấn luyện mạng từ đầu không dẫn đến độ chính xác xác thực chấp nhận được, vì vậy chúng tôi sử dụng các tham số tối ưu của mô hình được huấn luyện trên ImageNet [6] để khởi tạo các tham số mạng ngoại trừ lớp kết nối đầy đủ cuối cùng được khởi tạo ngẫu nhiên. Chúng tôi sử dụng cùng siêu tham số như [26] và huấn luyện mô hình với tốc độ học η = 0.001 và weight decay 0.0001. Dữ liệu huấn luyện được xử lý bởi mạng trong kích thước mini-batch 32 và chúng tôi sử dụng SGD với momentum 0.9 để cập nhật các tham số. Chúng tôi sử dụng λ = 0.001 và B = 0.5 để phạt bán kính phổ của Hessian. Các siêu tham số hoàn toàn theo các giá trị được chọn bởi bài báo Taylor. Chúng tôi huấn luyện mạng cho 5 epoch ban đầu (E₁) và bắt đầu cắt tỉa N = 100 neuron sau mỗi E₂ = 5 epoch. Một khi chúng tôi đạt được mức độ thưa mong muốn, chúng tôi huấn luyện mạng cho E₃ = 50 epoch.

Đối với kết quả phương pháp Taylor, chúng tôi sử dụng một mạng đã được huấn luyện trước được huấn luyện cho 20 epoch và cắt tỉa một neuron sau mỗi 30 bước gradient descent. Những giá trị này đã được tối ưu hóa bằng tìm kiếm lưới. Hình 1 vẽ sự khác biệt phần trăm độ chính xác xác thực tương đối của phương pháp HGNP và Taylor so với mức độ thưa. Nó cho thấy rằng các phương pháp HGNP và Taylor đang hoạt động gần như nhau với các mô hình ít thưa hơn, nhưng khi mức độ thưa tăng, khoảng cách tương đối giữa độ chính xác của HGNP và Taylor trở nên rất lớn (120% khi cả hai mô hình ở mức độ thưa 35%). Đối với độ thưa trên 55%, hiệu suất của cả hai phương pháp rất giống nhau. Đối với độ thưa 50%, 40% và 35%, độ chính xác là (78.9%, 71.1%), (77.0%, 60%) và (75.5%, 34%), tương ứng trong đó giá trị đầu tiên tương ứng với HGNP và giá trị thứ hai thuộc về Taylor.

Thí nghiệm ResNet-18 trên Cifar-10: Cho thí nghiệm thứ hai, chúng tôi huấn luyện và cắt tỉa ResNet-18 trên tập dữ liệu Cifar-10. Chúng tôi sử dụng kích thước mini-batch 128, cùng với weight decay 0.0005 và tốc độ học ban đầu η = 0.1. SGD với momentum 0.9 được sử dụng để cập nhật các tham số một cách mượt mà hơn. Chúng tôi đặt λ = 0.001 và B = 0.5 cho số hạng bán kính phổ. Mô hình được huấn luyện mà không có bất kỳ cắt tỉa nào cho E₁ = 50. Chúng tôi luân phiên giữa cắt tỉa N = 100 neuron và huấn luyện, mỗi E₂ = 5 epoch, và tinh chỉnh mô hình với mức độ thưa mong muốn cho thêm E₃ = 20 epoch. Hơn nữa, do cấu trúc cụ thể của mạng residual và sự tồn tại của các kết nối residual, một số lớp phải có cùng số neuron để tránh không tương thích chiều trong quá trình feed-forward. Để tuân thủ tính tương thích chiều, chúng tôi nhóm những lớp cụ thể đó lại với nhau và cắt tỉa cùng số neuron từ mỗi lớp bằng cách tính trung bình số neuron cần cắt tỉa được đề xuất bởi phương pháp cắt tỉa của chúng tôi cho những lớp đó.

Đối với phương pháp Taylor, chúng tôi huấn luyện mô hình cho 200 epoch. Sau đó chúng tôi bắt đầu cắt tỉa một neuron khỏi mạng và tinh chỉnh các tham số với một epoch dữ liệu. Chúng tôi tiếp tục luân phiên giữa cắt tỉa và tinh chỉnh cho đến khi đạt được mức độ thưa mong muốn. Hình 2 vẽ sự khác biệt phần trăm tương đối về độ chính xác trên tập dữ liệu xác thực giữa các phương pháp HGNP và Taylor. Phương pháp HGNP liên tục vượt trội ở mức độ thưa 85% và thấp hơn, mặc dù sự cải thiện không đột ngột.

Thí nghiệm ResNet-18 trên tập dữ liệu Birds 200: Thí nghiệm thứ ba được tiến hành về việc huấn luyện ResNet-18 trên tập dữ liệu Birds 200. Giống như thí nghiệm đầu tiên, chúng tôi dựa vào transfer learning và sử dụng các trọng số mạng tích chập được huấn luyện trước của ResNet-18 trên ImageNet. Tốc độ học và weight decay được đặt thành 0.001 và 0.0001, tương ứng. Chúng tôi sử dụng kích thước mini-batch 32 cùng với momentum 0.9, λ = 0.001 và B = 0.5 để huấn luyện mạng. Chúng tôi đặt E₁ = 25 và chúng tôi cắt tỉa 100 neuron sau mỗi 5 epoch. Như bước tinh chỉnh cuối cùng, chúng tôi huấn luyện thêm E₃ = 20 epoch sau khi đạt được mức độ thưa mong muốn. Đối với phương pháp Taylor, chúng tôi ban đầu huấn luyện mô hình đầy đủ cho 60 epoch với tốc độ học 0.01 và tỷ lệ weight decay 0.0001 cho 60 epoch. Các siêu tham số được tối ưu hóa để đạt được hiệu suất tốt nhất. Sau đó chúng tôi bắt đầu cắt tỉa một neuron tại mỗi bước cắt tỉa và huấn luyện cho một epoch để khôi phục hiệu suất sau đó. Hình 3 cho thấy rằng mô hình của chúng tôi vượt trội ở mức độ thưa thực sự cao và thấp. Ở mức độ thưa 14% và thấp hơn, mô hình của chúng tôi bắt đầu vượt trội trở lại. Ở mức độ thưa 5%, khoảng cách độ chính xác tương đối là 6%. Tất cả độ chính xác dao động từ 70.5% đến 51.9% và từ 70.5% đến 49.0% cho HGNP và Taylor, tương ứng.

Thí nghiệm VGG-16: Thí nghiệm cuối cùng của chúng tôi là về việc huấn luyện mạng neural VGG-16 với batch normalization [13] trên tập dữ liệu Cifar-10. Kích thước mini-batch và tốc độ học ban đầu được đặt thành 128 và 0.1, tương ứng. Chúng tôi giảm tốc độ học khi quá trình huấn luyện tiến triển và thêm một số hạng chính quy hóa vào hàm tổn thất với hệ số 0.0005. Các giá trị λ và B được đặt thành 0.001 và 0.5, tương ứng. Đối với Taylor, chúng tôi huấn luyện trước nó cho 200 epoch và bắt đầu cắt tỉa một neuron và huấn luyện cho một epoch luân phiên. Đối với HGNP, số epoch huấn luyện trước cắt tỉa là E₁ = 50 và chúng tôi cắt tỉa N = 100 neuron tại mỗi epoch cắt tỉa và huấn luyện mô hình cho E₂ = 5 epoch giữa mỗi epoch cắt tỉa. Cuối cùng mô hình được tinh chỉnh thêm E₃ = 20 epoch. Hình 4 so sánh hai phương pháp. Ở mức độ thưa 5%, khoảng cách tương đối giữa độ chính xác của HGNP và Taylor lớn hơn 8%. Mô hình của chúng tôi vượt trội ở tất cả mức độ thưa dưới 90%. Ở độ thưa 10%, độ chính xác của Taylor là 87.3% trong khi HGNP ở 91.4%.

4.2 Thời gian Huấn luyện và Suy luận

Trong phần này, chúng tôi so sánh thời gian huấn luyện và suy luận của các phương pháp HGNP và Taylor. Tổng thời gian huấn luyện và cắt tỉa cho phương pháp HGNP dài hơn so với phương pháp Taylor vì nó cần tính toán giá trị riêng lớn nhất và vector riêng tương ứng cho mỗi khối. Thời gian cho các thí nghiệm được tóm tắt trong Bảng 1.

Để so sánh tốc độ thực tế cho các mô hình đã cắt tỉa của chúng tôi, chúng tôi đo thời gian suy luận của một mini-batch cho mô hình đã cắt tỉa neuron (sử dụng HGNP), mô hình đã cắt tỉa trọng số và mô hình đầy đủ. Để tính toán thời gian suy luận cho các mô hình đã cắt tỉa trọng số, chúng tôi khởi tạo mạng với trọng số ngẫu nhiên và ngẫu nhiên giữ một phần trăm (phần trăm mức độ thưa) của chúng và đặt các trọng số khác về không. Chúng tôi tin rằng việc sử dụng trọng số tối ưu cùng với các phương pháp hiện đại nhất trong cắt tỉa trọng số sẽ không có ảnh hưởng đáng kể đến thời gian suy luận so với chiến lược nói trên. Thời gian suy luận thực tế có thể phụ thuộc vào nhiều tham số khác nhau bao gồm phần cứng. Bảng 2 so sánh thời gian suy luận cho tất cả ba mô hình sử dụng các GPU và kích thước mini-batch khác nhau trên các mô hình khác nhau. Mô hình đầy đủ tương ứng với mức độ thưa 100% cho cả neuron và trọng số. Kết quả của chúng tôi cho thấy thời gian suy luận cho các mô hình đã cắt tỉa neuron thấp hơn so với mô hình đầy đủ như mong đợi. Ngoài ra, ở cùng mức độ thưa, các mô hình đã cắt tỉa neuron nhanh hơn các mô hình đã cắt tỉa trọng số trong feed-forward.

Chúng tôi cũng so sánh các mô hình đã cắt tỉa neuron với các mô hình đã cắt tỉa trọng số tạo ra cùng mức độ chính xác. Theo [22], mô hình VGG trên tập dữ liệu Cifar-10 có độ chính xác 92% ở độ thưa 3%. Mức độ chính xác này dịch sang độ thưa 14.4% trong mô hình đã cắt tỉa neuron của chúng tôi. So sánh thời gian suy luận được tóm tắt trong Bảng 3. Kết quả cho thấy rằng mặc dù mức độ thưa cao hơn cho các mô hình đã cắt tỉa neuron so với các mô hình đã cắt tỉa trọng số để tạo ra cùng mức độ chính xác, các mô hình đã cắt tỉa neuron vẫn nhanh hơn trong thời gian suy luận.

4.3 Nghiên cứu Loại bỏ

Chúng tôi tiến hành các thí nghiệm loại bỏ để cho thấy hiệu quả của các thành phần được đề xuất của chúng tôi cho việc cắt tỉa. Để làm điều này, chúng tôi loại bỏ hai thành phần của HGNP từng cái một và so sánh kết quả với thuật toán đầy đủ:
1) Chúng tôi loại bỏ thành phần liên quan đến bán kính phổ (đặt λ = 0) và huấn luyện mô hình chỉ sử dụng tổn thất cross-entropy. Tuy nhiên, chúng tôi sử dụng toàn bộ hàm tổn thất bao gồm phần bán kính phổ để quyết định neuron nào cần cắt tỉa. 2) Chúng tôi sử dụng hàm tổn thất với λ = 0 để chỉ định neuron nào cần cắt tỉa. Tuy nhiên, hàm tổn thất hoàn chỉnh được sử dụng để huấn luyện và tinh chỉnh mô hình.

Chúng tôi tiến hành các thí nghiệm loại bỏ trên mô hình AlexNet được huấn luyện trên tập dữ liệu Flowers vì nó huấn luyện nhanh. Kết quả được hiển thị trong Hình 5. HGNP đầy đủ liên tục tốt hơn cho mức độ thưa thấp hơn 58% cho thấy hiệu quả của thuật toán.

4.4 Phương pháp Heuristic để Chuyển đổi giữa Taylor và HGNP

Trong tất cả các thí nghiệm, phương pháp chuẩn (Taylor) hoạt động tốt hơn HGNP cho đến một mức độ thưa và vượt qua đó thuật toán của chúng tôi vượt trội về hiệu suất độ chính xác. Ví dụ, đối với Alexnet, giá trị ngưỡng này khoảng mức độ thưa 91% (xem Hình 1). Nếu chúng ta theo đuổi một thuật toán xuất sắc cho tất cả mức độ thưa, quan sát này dẫn đến một chiến lược sử dụng Taylor cho mức độ thưa lớn và HGNP cho mức thấp. Thách thức là xác định mức chuyển đổi. Để làm điều này, chúng tôi sử dụng một mô hình hồi quy tuyến tính với 4 mẫu (mỗi thí nghiệm là một mẫu) trong đó biến phản hồi là giá trị ngưỡng mức độ thưa chỉ định mô hình nào vượt trội. Chúng tôi xem xét hai loại biến độc lập. Loại đầu tiên liên quan đến tập dữ liệu và những loại khác trong loại khác đặc trưng cho kiến trúc mạng neural. Các biến tập dữ liệu được xem xét là: số mẫu huấn luyện và xác thực, chiều của hình ảnh đầu vào, và số lớp trong mô hình để dự đoán. Đối với các biến liên quan đến kiến trúc mạng neural, chúng tôi sử dụng: số lớp tích chập, số lớp tuyến tính, số tham số có thể huấn luyện của mô hình mạng neural, kích thước kernel trung bình trên tất cả các lớp tích chập, và số kernel. Chúng tôi sử dụng tất cả các dự báo này và biến phản hồi để thực hiện hồi quy Lasso. Mô hình tốt nhất dựa trên R² và tất cả p-values dưới 0.05 chỉ chứa hai dự báo đáng kể: số lớp và số mẫu huấn luyện. Bằng cách sử dụng mô hình, chúng tôi dự đoán mức độ thưa ngưỡng cho mỗi thí nghiệm và sử dụng nó để quyết định khi nào chuyển từ Taylor sang HGNP. Sau đó chúng tôi tạo các biểu đồ độ chính xác và so sánh diện tích dưới đường cong (AUC) cho phương pháp chuyển đổi giữa HGNP và Taylor (tức là phương pháp lai) so với phương pháp Taylor ngoài HGNP so với Taylor và tóm tắt kết quả trong Bảng 4. Dựa trên kết quả, AUC được cải thiện cho HGNP so với Taylor trên tất cả các cặp mô hình/tập dữ liệu ngoại trừ Resnet-18/Birds. Chúng tôi quan sát sự cải thiện đáng kể của phương pháp lai so với Taylor cho AlexNet/Flowers 102 và VGG-16/Cifar-10. Phương pháp lai vượt trội hơn Taylor trong mọi thí nghiệm.

5 Thảo luận

Chúng tôi đề xuất một thuật toán cắt tỉa neuron trong kiến trúc DNN với sự chú ý đặc biệt đến giải pháp cuối cùng của mô hình đã cắt tỉa. Thuật toán có thể đạt được cực tiểu phẳng hơn tổng quát hóa tốt hơn trên dữ liệu chưa thấy. Các thí nghiệm cho thấy thuật toán HGNP vượt trội hơn tài liệu hiện có trên các kiến trúc mạng neural và tập dữ liệu khác nhau. Mô hình compact của chúng tôi đạt được sự cải thiện thực tế trong thời gian suy luận với phần mềm hiện tại bằng cách cắt tỉa neuron thay vì trọng số.

# HideNseek: Vé Số Liên Bang thông qua 
Tỉa Bớt Phía Máy Chủ và Siêu Mặt Nạ Dấu Hiệu

Anish K. Vallapuram1Pengyuan Zhou2Young D. Kwon3
Lik Hang Lee4Hengwei Xu2Pan Hui1
1Đại học Khoa học và Công nghệ Hồng Kông
2Đại học Khoa học và Công nghệ Trung Quốc
3Đại học Cambridge
4Viện Khoa học và Công nghệ Tiên tiến Hàn Quốc
pyzhou@ustc.edu.cn

Tóm tắt
Học liên bang giảm thiểu rủi ro riêng tư trong học phân tán bằng cách chỉ truyền các cập nhật mô hình cục bộ đến máy chủ trung tâm. Tuy nhiên, nó đối mặt với các thách thức bao gồm tính dị thể thống kê của các tập dữ liệu của khách hàng và hạn chế tài nguyên của các thiết bị khách hàng, điều này ảnh hưởng nghiêm trọng đến hiệu suất huấn luyện và trải nghiệm người dùng. Các công trình trước đây đã giải quyết những thách thức này bằng cách kết hợp cá nhân hóa với các phương án nén mô hình bao gồm lượng tử hóa và tỉa bớt. Tuy nhiên, việc tỉa bớt phụ thuộc vào dữ liệu và do đó phải được thực hiện ở phía khách hàng, điều này đòi hỏi chi phí tính toán đáng kể. Hơn nữa, việc tỉa bớt thường huấn luyện một siêu mặt nạ nhị phân ∈{0;1} điều này hạn chế đáng kể dung lượng mô hình nhưng không mang lại lợi ích tính toán. Do đó, việc huấn luyện đòi hỏi chi phí tính toán cao và thời gian dài để hội tụ trong khi hiệu suất mô hình không xứng đáng. Trong công trình này, chúng tôi đề xuất HideNseek sử dụng tỉa bớt một lần không phụ thuộc dữ liệu tại khởi tạo để có được một mạng con dựa trên tầm quan trọng khớp thần kinh của trọng số. Mỗi khách hàng sau đó tối ưu hóa một siêu mặt nạ dấu hiệu ∈{-1;+1} nhân với các trọng số chưa được tỉa bớt để cho phép hội tụ nhanh hơn với cùng tỷ lệ nén như các phương pháp tiên tiến nhất. Kết quả thực nghiệm từ ba tập dữ liệu cho thấy so với các phương pháp tiên tiến nhất, HideNseek cải thiện độ chính xác suy luận lên đến 40,6% trong khi giảm chi phí giao tiếp và thời gian huấn luyện lên đến 39,7% và 46,8% tương ứng.

1 Giới thiệu
Học liên bang [McMahan et al., 2017] cải thiện bảo vệ riêng tư bằng cách tách rời nhu cầu về kho lưu trữ dữ liệu trung tâm khỏi việc học các tập dữ liệu phân tán. Mỗi khách hàng tải lên mô hình cục bộ của mình được huấn luyện với các tập dữ liệu cục bộ đến một máy chủ trung tâm duy trì một mô hình toàn cục. Máy chủ cập nhật mô hình toàn cục thông qua việc tổng hợp các cập nhật của khách hàng và gửi mô hình mới đến các khách hàng. Các quá trình này được lặp lại cho đến khi mô hình hội tụ hoặc chu kỳ được định trước kết thúc.

Trong khi cải thiện bảo vệ riêng tư, mô hình này cũng đối mặt với các thách thức như tính dị thể thống kê, liên quan đến phân phối không độc lập và không đồng nhất (non-IID) của dữ liệu giữa các khách hàng, ảnh hưởng đến sự hội tụ của mô hình toàn cục nếu dữ liệu từ các khách hàng khác nhau quá phân kỳ. Một số công trình giải quyết tính dị thể thống kê bằng cách giới thiệu các kỹ thuật học khác nhau để cá nhân hóa [Fallah et al., 2020; Smith et al., 2017; Lin et al., 2020; Gong et al., 2021; Zhu et al., 2021].

Một thách thức lớn khác mà học liên bang đối mặt là các hạn chế về tài nguyên, liên quan đến khả năng tính toán hạn chế và băng thông truyền của các thiết bị khách hàng. Tài nguyên hạn chế giới hạn kích thước mô hình có thể được huấn luyện trong các thiết bị khách hàng và truyền kịp thời đến máy chủ để tổng hợp. Một số công trình gần đây đã xuất hiện để giải quyết thách thức này bằng cách điều chỉnh quy trình huấn luyện [Li et al., 2020; Reisizadeh et al., 2020] và sử dụng các phương án nén mô hình [Diao et al., 2021; Horvath et al., 2021; Bouacida et al., 2021].

Gần đây, FedMask [Li et al., 2021] giải quyết cả tính dị thể thống kê và hạn chế tài nguyên bằng cách sử dụng triết lý "che mặt là huấn luyện" dựa trên giả thuyết vé số (LTH) [Frankle và Carbin, 2018]. FedMask tỉa bớt mô hình cục bộ để tuân thủ các hạn chế về tài nguyên. Sau đó, khách hàng học một siêu mặt nạ nhị phân cục bộ thưa thớt để cá nhân hóa nhằm giảm thiểu tính dị thể thống kê giữa các khách hàng.

Tuy nhiên, các phương pháp hiện tại đối mặt với một số thách thức. Thứ nhất, các phương pháp tỉa bớt hiện tại trong thiết lập liên bang chủ yếu phụ thuộc vào dữ liệu và do đó phải được thực hiện ở phía khách hàng. Do đó, các thiết bị khách hàng với tài nguyên hạn chế không thể tránh được chi phí tính toán đáng kể. Thứ hai, các phương pháp tỉa bớt như vậy thường sử dụng siêu mặt nạ nhị phân về cốt lõi là tỉa bớt không có cấu trúc không mang lại lợi thế tính toán nhưng lại hạn chế dung lượng mô hình. Do đó, hiệu suất mô hình bị hạn chế, nhưng lại đòi hỏi chi phí tính toán cao và thời gian hội tụ dài.

Do đó, trong bài báo này, chúng tôi đề xuất HideNseek, một khung học liên bang nhận thức về tính dị thể thống kê cung cấp hiệu quả tính toán và giao tiếp được hỗ trợ bởi siêu mặt nạ dấu hiệu [Zhou et al., 2019]. Cụ thể, chúng tôi đóng góp những điều sau đây:

• HideNseek đề xuất một phiên bản liên bang của LTH với tối ưu hóa dấu hiệu lần đầu tiên. So với siêu mặt nạ nhị phân thường được sử dụng, phương pháp của chúng tôi cung cấp độ chính xác cao hơn và hội tụ nhanh hơn.

• HideNseek thực hiện tỉa bớt một lần phía máy chủ tại khởi tạo bằng cách sử dụng phương pháp không phụ thuộc dữ liệu lặp lại dựa trên tầm quan trọng khớp thần kinh của dấu hiệu trọng số. Như vậy, HideNseek giảm đáng kể gánh nặng tính toán và chi phí giao tiếp cho các khách hàng có khả năng hạn chế.

• Kết quả thực nghiệm trên các tập dữ liệu khác nhau cho thấy HideNseek vượt trội hơn các phương pháp tiên tiến nhất về độ chính xác suy luận lên đến 40,6% trong khi giảm chi phí giao tiếp và thời gian huấn luyện lên đến 39,7% và 46,8% tương ứng.

2 Nền tảng & Công thức Mục tiêu

Trong phần này, chúng tôi bắt đầu với nền tảng về học liên bang và LTH và công thức hóa mục tiêu của việc tỉa bớt không phụ thuộc dữ liệu cho học liên bang.

2.1 Học Liên bang

Trong học liên bang, một mạng nơ-ron sâu phải được học theo cách phân tán. Điều này được thực hiện bởi một máy chủ trung tâm tổng hợp các bản sao của trọng số mạng được học giữa các khách hàng trên các tập dữ liệu cục bộ của họ. Mục tiêu học tập là tìm trọng số w để tối thiểu hóa tổn thất thực nghiệm trên các khách hàng

min_w F(w) = Σ^K_{k=1} n_k/n L[f(x_k;w);y_k]  (1)

trong đó mạng f(·;w) là một hàm tổng hợp của các lớp được tham số hóa bởi các trọng số véc-tơ hóa w∈R^d và L là hàm tổn thất thực nghiệm đo lường khả năng xấp xỉ hàm tạo ra tập dữ liệu cục bộ (x_k;y_k) của khách hàng k. n_k là số mẫu cục bộ và n=Σ_k n_k là tổng số mẫu trên tất cả K khách hàng.

Một công trình trước đây [McMahan et al., 2017] cung cấp FedAvg được sử dụng rộng rãi để giải quyết mục tiêu này thông qua SGD phân tán. Trong mỗi vòng giao tiếp t, máy chủ trung tâm chọn một tập con của cK khách hàng và gửi cho họ một bản sao của trọng số toàn cục w^t. Các khách hàng sửa đổi bản sao cục bộ của họ về trọng số w^t_k bằng cách tối thiểu hóa tổn thất thực nghiệm trên các tập dữ liệu cục bộ để có được w^{t+1}_k và truyền chúng trở lại máy chủ. Máy chủ cập nhật trọng số toàn cục bằng cách đơn giản tính trung bình trọng số của các khách hàng

w^{t+1} = 1/c Σ^c_{k=1} w^{t+1}_k  (2)

Một số vấn đề phát sinh trong triển khai thực tế. Thứ nhất, các khách hàng phải chịu chi phí giao tiếp do truyền trọng số và chi phí tính toán do tối ưu hóa trọng số cục bộ. Thứ hai, các tập dữ liệu cục bộ không độc lập và phân phối đồng nhất (non-IID) nên trọng số toàn cục phải tổng quát hóa tốt giữa các khách hàng. Một số công trình đã sửa đổi (các) mục tiêu học tập của họ để giải quyết những vấn đề này (xem Phần 6).

2.2 Giả thuyết Vé Số

LTH [Frankle và Carbin, 2018] là một hướng mới nổi trong học máy có thể giải quyết các vấn đề nêu trên trong học liên bang. Nó phát biểu rằng một mạng nơ-ron được khởi tạo ngẫu nhiên chứa một mạng con được gọi là vé trúng thưởng khi được huấn luyện riêng biệt, hoạt động tốt như mạng gốc. Một mở rộng tham vọng hơn đến từ [Ramanujan et al., 2020] phát biểu rằng một mạng được tham số hóa quá mức đủ chứa một vé trúng thưởng ở trạng thái được khởi tạo ngẫu nhiên. Hơn nữa, vé trúng thưởng này có thể được xác định thông qua việc đóng băng các trọng số tại khởi tạo ngẫu nhiên w_0 và tỉa bớt một tập con của các trọng số này để tìm một mạng con thưa thớt. Để cải thiện hiệu suất học tập, [Chen et al., 2022] đề xuất áp dụng một hàm biến đổi U∈U cho các trọng số để tối thiểu hóa thêm tổn thất thực nghiệm. Mục tiêu học tập do đó là

min_{U∈U,||m||_0=S} L[f(x;U(w_0⊙m));y]  (3)

trong đó m∈{0;1}^d là một siêu mặt nạ nhị phân với mức độ thưa thớt S và cùng chiều với trọng số. Vé trúng thưởng được biểu diễn như phép nhân từng phần tử của trọng số và siêu mặt nạ, tức là w_0⊙m. Tuy nhiên, việc tối ưu hóa Eq. (3) về mặt tính toán là không khả thi do chiều lớn của trọng số và không gian biến đổi U. Do đó, họ đề xuất tách rời việc tối ưu hóa thành hai giai đoạn. Giai đoạn đầu tiên là giai đoạn tỉa bớt trong đó một siêu mặt nạ nhị phân phải được tìm để làm thưa thớt mô hình bằng cách tối ưu hóa điều sau

m̂ ∈ min_{||m||_0=S} R(f(x;w_0⊙m))  (4)

trong đó R là một hàm tính điểm đo lường khả năng của siêu mặt nạ nhị phân m để cô lập vé trúng thưởng từ mô hình. Giai đoạn thứ hai là giai đoạn huấn luyện trong đó một biến đổi trọng số được học để tối thiểu hóa tổn thất thực nghiệm

Û ∈ min_{U∈U} L[f(x;U(w_0⊙m̂));y]  (5)

2.3 Công thức Mục tiêu

Về bản chất, LTH áp dụng triết lý "che mặt là huấn luyện" trong đó một mạng con thưa thớt tối ưu phải được học mà không sửa đổi trọng số. Với hiệu quả giao tiếp và tính toán được mang lại bởi ý tưởng này (được thảo luận trong các phần tiếp theo), chúng tôi đề xuất áp dụng giả thuyết này cho thiết lập liên bang. Tuy nhiên, không gian biến đổi trọng số U rất rộng lớn. Theo [Chen et al., 2022], chúng tôi giới hạn không gian này thành không gian biến đổi lật dấu U_s⊂U trong đó một biến đổi U(w;s) = w⊙s là phép nhân từng phần tử của siêu mặt nạ dấu hiệu s∈{-1;+1}^d với trọng số w. Mục tiêu học tập được cập nhật của công trình chúng tôi là

min_{m,s} F(m,s) = Σ^K_{k=1} n_k/n L[f(x_k;w_0⊙m⊙s);y_k]  (6)

Các phần tiếp theo mô tả chi tiết về một thuật toán học liên bang để giải quyết mục tiêu trên.

3 Phương pháp

3.1 HideNseek

Trong công trình này, chúng tôi đề xuất một thuật toán học liên bang hiệu quả gọi là HideNseek bằng cách giải quyết việc thích ứng liên bang của LTH. Hình 1 mô tả tổng quan về khung. Như đã đề cập trước đó, quá trình học có thể được thực hiện trong hai giai đoạn.

Trong giai đoạn đầu tiên, máy chủ trước tiên thực hiện tỉa bớt tại khởi tạo để cô lập vé trúng thưởng (①). Vì máy chủ không sở hữu dữ liệu huấn luyện, một phương pháp tỉa bớt không phụ thuộc dữ liệu được áp dụng. Theo [Tanaka et al., 2020], chúng tôi đo điểm số của dấu hiệu trọng số thông qua tầm quan trọng khớp thần kinh của chúng (xem Phần 3.4), và sử dụng tỉa bớt có cấu trúc toàn cục để có hiệu quả phần cứng.

Trong giai đoạn thứ hai, một biến đổi trọng số tối ưu phải được học để tối thiểu hóa tổn thất thực nghiệm theo cách liên bang. Trong mỗi bước huấn luyện t, máy chủ gửi siêu mặt nạ dấu hiệu toàn cục s^t đến các khách hàng được chọn (②) để khởi tạo một siêu mặt nạ dấu hiệu cục bộ s^{t+1}_k. Các khách hàng sau đó đóng băng trọng số mô hình và tối ưu hóa siêu mặt nạ dấu hiệu cục bộ bằng cách tối thiểu hóa tổn thất thực nghiệm sử dụng Eq. (6) (③). Như vậy, một biến đổi lật dấu được học và gửi trở lại máy chủ (④). Máy chủ sau đó tổng hợp các siêu mặt nạ cục bộ này sử dụng Eq. (8) (⑤).

Sau giai đoạn huấn luyện, mỗi khách hàng nhân siêu mặt nạ dấu hiệu được tổng hợp với trọng số của mình để có được mô hình cục bộ cuối cùng (⑥). Thuật toán 1 (trong Phụ lục A) tóm tắt các quá trình với các chi tiết được làm nổi bật được mô tả chi tiết trong các đoạn sau.

3.2 Cá nhân hóa

Lớp đầu ra của mô hình không thể được tối ưu hóa đơn giản cho dấu hiệu của nó vì độ lớn trọng số phải được chia tỷ lệ để huấn luyện ổn định. Do đó chúng tôi chia mô hình của mình thành các bộ trích xuất đặc trưng bao gồm tất cả các lớp ẩn và bộ phân loại là lớp đầu ra. Các trọng số được đóng băng và siêu mặt nạ dấu hiệu chỉ được học cho bộ trích xuất đặc trưng trong khi trọng số của bộ phân loại có thể sửa đổi được, như việc tối ưu hóa dữ liệu cục bộ. Phù hợp với các công trình trước đây [Zhu et al., 2021], công trình của chúng tôi củng cố thêm việc cá nhân hóa giữa các khách hàng.

3.3 Biến đổi Lật Dấu

Việc tối ưu hóa siêu mặt nạ dấu hiệu là rất quan trọng cho việc học trong thuật toán của chúng tôi. Như vậy, chúng tôi xử lý một số bước sơ bộ nhất định để đạt được việc tối ưu hóa. Như đã đề cập trước đó, một mô hình có thể được biểu diễn như một tổng hợp của các lớp thực hiện các phép toán của trọng số véc-tơ hóa. Như một ví dụ, hãy xem xét lớp kết nối đầy đủ. Lưu ý rằng số hạng bias đã được bỏ qua để ngắn gọn. Một lớp kết nối đầy đủ l có thể được biểu diễn như y^[l] = (w^[l]⊙s^[l])x^[l], trong đó y^[l]∈R^i là đầu ra, x^[l]∈R^j là đầu vào, và w^[l]∈R^{i×j} là trọng số. Do đó chúng tôi xử lý việc học một siêu mặt nạ dấu hiệu s^[l]∈{-1;+1}^{i×j} có cùng chiều với trọng số.

Tuy nhiên, việc tối ưu hóa SGD truyền thống không thể được áp dụng cho các siêu mặt nạ dấu hiệu do tính chất rời rạc của chúng. Do đó, chúng tôi triển khai một bộ ước lượng thẳng qua [Bengio et al., 2013] với một siêu mặt nạ dấu hiệu có giá trị thực ŝ^[l]∈R^{i×j}. Trong lượt truyền xuôi, ŝ được lượng tử hóa sử dụng hàm dấu từng đoạn

s_{ij} = sign(ŝ_{ij}) = {+1 nếu ŝ_{ij}≥0; -1 nếu ŝ_{ij}<0}  (7)

trong đó s_{ij} là một phần tử ở hàng thứ i và cột thứ j của siêu mặt nạ dấu hiệu s. Các gradient của s trong lượt truyền ngược được tính như ∇_s L = (∇_{y^L} x^T)⊙w. Cho rằng hàm dấu không khả vi, việc gán trực tiếp các gradient từ siêu mặt nạ dấu hiệu được lượng tử hóa cho siêu mặt nạ dấu hiệu thực (tức là ∇_ŝ L = ∇_s L) sẽ dẫn đến phương sai gradient lớn [Courbariaux et al., 2016]. Do đó, chúng tôi sử dụng hàm tang hyperbolic, ký hiệu là tanh(·), để xấp xỉ liên tục hàm dấu cho lượt truyền ngược, s_{ij} = tanh(ŝ_{ij}). Điều này sẽ cho phép chúng tôi tính các gradient của siêu mặt nạ dấu hiệu thực ŝ từ siêu mặt nạ dấu hiệu nhị phân s như ∇_ŝ L = Ψ⊙∇_s L, trong đó Ψ là ma trận gradient của hàm tang hyperbolic với các giá trị được tính toán rõ ràng như Ψ_{ij} = (1-ŝ^2_{ij}).

Vì các khách hàng truyền các siêu mặt nạ dấu hiệu được lượng tử hóa đến máy chủ để có hiệu quả giao tiếp, chúng tôi sử dụng phương án tổng hợp dấu hiệu sau để có được siêu mặt nạ dấu hiệu có giá trị thực tại máy chủ

ŝ = arctanh(Σ_k n_k/n s_k)  (8)

3.4 Tỉa Bớt Phía Máy Chủ

Một khía cạnh quan trọng khác trong HideNseek là giai đoạn tỉa bớt trong đó vé trúng thưởng phải được cô lập từ mạng. Theo [Li et al., 2021], chúng tôi sử dụng tỉa bớt một lần tại khởi tạo nhưng thực hiện nó ở phía máy chủ để giảm tải cho các khách hàng. Vì máy chủ không chứa bất kỳ dữ liệu huấn luyện nào, chúng tôi sử dụng phương pháp tỉa bớt lặp lại không phụ thuộc dữ liệu [Tanaka et al., 2020] trong đó điểm tỉa bớt được xác định dựa trên tầm quan trọng khớp thần kinh của trọng số. Cho rằng các trọng số được đóng băng trong quá trình huấn luyện siêu mặt nạ dấu hiệu, chúng tôi đo tầm quan trọng khớp thần kinh của dấu hiệu của một trọng số nhất định trong một mô hình với L lớp như sau

R_{SF}(s^{[l]}_{ij}) = [∏^L_{h=l+1} s^{[h]}⊙w^{[h]}]_i ⊙ s^{[l]}_{ij}w^{[l]}_{ij} ⊙ [∏^{l-1}_{h=1} s^{[h]}⊙w^{[h]}]_j  (9)

Về bản chất, tầm quan trọng khớp thần kinh của dấu hiệu trọng số là tích của tất cả các trọng số nhân với các siêu mặt nạ dấu hiệu tương ứng của chúng có dấu hiệu trọng số trong đường dẫn từ lớp đầu vào đến lớp đầu ra. Để thúc đẩy thêm hiệu quả phần cứng, chúng tôi sử dụng tỉa bớt có cấu trúc toàn cục bằng cách tính điểm các nhóm trọng số theo kênh trong các lớp tích chập và nút trong các lớp kết nối đầy đủ. Điểm tỉa bớt cho kênh hoặc nút thứ i trong một lớp như ||w^[l]_i⊙∇R^{[l]}_{SF,i}||_2. Ngoài ra, chúng tôi giữ lại một vài lớp đầu tiên và chỉ tỉa bớt từ các lớp sau của mô hình với tỷ lệ tỉa bớt p_r.

3.5 Tình Trạng Hiện Tại

FedMask [Li et al., 2021] gần gũi nhất về tinh thần với công trình của chúng tôi. Tuy nhiên, phương pháp tỉa bớt của nó phụ thuộc vào dữ liệu, và do đó, phải được thực hiện trên các thiết bị khách hàng, dẫn đến tăng tải tính toán trên các khách hàng có tài nguyên hạn chế. Ngoài ra, không gian biến đổi trọng số của nó được giới hạn trong siêu mặt nạ nhị phân U_b⊂U, trong đó một siêu mặt nạ nhị phân cục bộ m_k∈{0;1} được học trong giai đoạn huấn luyện trái ngược với siêu mặt nạ dấu hiệu nhị phân. Thực tế, FedMask thực hiện thêm tỉa bớt không có cấu trúc trong giai đoạn huấn luyện mà không có lợi thế giao tiếp hoặc tính toán. Ngược lại, HideNseek duy trì tất cả các trọng số sau giai đoạn tỉa bớt cho phép dung lượng mô hình lớn hơn.

4 Thiết lập Thực nghiệm

4.1 Tập Dữ liệu & Mô hình

Chúng tôi đánh giá HideNseek trên hai ứng dụng, bao gồm phân loại hình ảnh và nhận dạng hoạt động con người, sử dụng các tập dữ liệu EMNIST [Caldas et al., 2018] và HAR [Anguita et al., 2013], tương ứng. EMNIST là một nhiệm vụ nhận dạng ký tự viết tay liên quan đến các hình ảnh thang độ xám 28×28 thuộc 62 lớp (chữ cái viết hoa và viết thường và chữ số) đã được phân vùng theo người viết. Do đó, mỗi người viết được coi là một khách hàng. Tập dữ liệu HAR bao gồm dữ liệu cảm biến (được làm phẳng thành một véc-tơ 1152 giá trị) được tạo ra bởi người dùng thực hiện sáu hành động có thể (tức là các lớp). Để nghiên cứu thêm tác động của tính dị thể thống kê đến hiệu suất, chúng tôi theo các công trình trước đây [Zhu et al., 2021] và mô phỏng dữ liệu Non-IID trên tập dữ liệu MNIST [LeCun et al., 1998] thông qua lấy mẫu Dirichlet Dir(α), trong đó giá trị α nhỏ hơn biểu thị tính dị thể lớn hơn (xem Hình 5 trong Phụ lục B). Chúng tôi sử dụng VGG9 và perceptron đa lớp (MLP) cho các nhiệm vụ phân loại hình ảnh và nhận dạng hoạt động, tương ứng, với các cấu hình mô hình (xem Bảng 5 trong Phụ lục C). Chúng tôi kích hoạt tỉa bớt cho bốn lớp tích chập cuối cùng trong VGG9 và hai lớp ẩn đầu tiên trong MLP.

4.2 Triển khai Hệ thống

Chúng tôi triển khai HideNseek và các baseline với PyTorch (v1.8.0) [Paszke et al., 2019] trên một máy chủ được trang bị một GPU Nvidia RTX 3090 duy nhất. Chúng tôi thực nghiệm với tổng cộng K khách hàng được đặt thành 160 và 320 cho các tập dữ liệu MNIST và EMNIST và 30 cho tập dữ liệu HAR. Chúng tôi lấy mẫu ngẫu nhiên c = 10% khách hàng tham gia thực hiện E = 5 epoch cục bộ trong mỗi vòng giao tiếp với tổng cộng 300 vòng cho MNIST và EMNIST và 200 vòng cho HAR. Trọng số và siêu mặt nạ dấu hiệu được khởi tạo sử dụng Kaiming uniform [He et al., 2015] và phân phối đều U(-1;1) tương ứng. Chúng tôi thực hiện tỉa bớt một lần trong 100 lần lặp trong HideNseek (theo [Tanaka et al., 2020]) và một epoch cho FedMask và Signed trên bốn lớp cuối cùng của VGG9 và hai lớp ẩn đầu tiên của MLP với tỷ lệ tỉa bớt p_r = 0.8 (80% trọng số được giữ lại). Chúng tôi sử dụng bộ tối ưu hóa SGD với tốc độ học η = 0.001 cho FedAvg, FedMask và Signed, η = 0.01 cho BNNAvg và η = 10 cho HideNseek, và momentum μ = 0.9 cho tất cả các thuật toán được chọn thực nghiệm. Chúng tôi lặp lại mỗi thí nghiệm ba lần với các seed khác nhau để tái tạo.

4.3 Baseline

Chúng tôi đánh giá HideNseek bằng cách so sánh hiệu suất của nó với một số baseline. Chúng tôi bao gồm FedAvg [McMahan et al., 2017] để nhận ra hiệu suất của mô hình khi được huấn luyện ở dung lượng đầy đủ. FedMask [Li et al., 2021] gần gũi nhất về tinh thần với công trình của chúng tôi và là state-of-the-art khi áp dụng LTH cho thiết lập liên bang với tỉa bớt phía khách hàng và học các siêu mặt nạ nhị phân. Chúng tôi cũng mượn baseline BNNAvg của họ áp dụng FedAvg để huấn luyện mạng nơ-ron nhị phân (BNN) [Courbariaux et al., 2016] với trọng số và kích hoạt được lượng tử hóa bởi dấu hiệu của chúng. Chúng tôi cũng triển khai một phần mở rộng của FedMask mà chúng tôi gọi là Signed trong đó chúng tôi thay thế siêu mặt nạ nhị phân bằng siêu mặt nạ dấu hiệu và thay đổi hàm nhị phân hóa của họ từ sigmoid thành tanh.

5 Kết quả

5.1 Hiệu suất Huấn luyện

Chúng tôi đầu tiên so sánh hiệu suất huấn luyện bằng cách báo cáo độ chính xác suy luận trong Bảng 1 giữa HideNseek và các baseline. Độ chính xác suy luận được đo bằng cách lấy trung bình có trọng số của độ chính xác suy luận của khách hàng dựa trên dữ liệu kiểm tra cục bộ của họ, được tính trọng số dựa trên số lượng mẫu kiểm tra trong tập dữ liệu cục bộ của họ. Trong khi HideNseek hoạt động như mong đợi kém hơn FedAvg huấn luyện mô hình đầy đủ và phục vụ như giới hạn trên trong hiệu suất huấn luyện, HideNseek nói chung vượt trội hơn FedMask, Signed và BNNAvg trên các nhiệm vụ. Đáng chú ý rằng những cải thiện hiệu suất là đáng kể cho các tập dữ liệu HAR và MNIST với tính dị thể thấp hơn tại α ∈ {1;10} với độ chính xác suy luận cao hơn 24.1-40.6% cho HideNseek so với FedMask. Hiệu suất HideNseek dần giảm cho MNIST (α = 0.1) với tính dị thể cao hơn và EMNIST với số lượng lớn các lớp. Phát hiện này có thể được quy cho thực tế rằng HideNseek sử dụng một bộ trích xuất đặc trưng toàn cục được chia sẻ giữa các baseline sử dụng tỉa bớt. Trong khi việc học các đặc trưng tổng quát hóa giữa các khách hàng là thách thức, hiệu suất vẫn xấp xỉ với cả FedMask và Signed học một bộ trích xuất đặc trưng được cá nhân hóa hơn. Tuy nhiên, HideNseek điểm cao hơn FedMask lần lượt 2.09% và 19.62% cho EMNIST và MNIST (α = 0.1).

Chúng tôi tiếp tục so sánh hiệu suất huấn luyện bằng cách vẽ đồ thị độ chính xác suy luận theo vòng giao tiếp. Trong trường hợp tập dữ liệu HAR trong Hình 2(a) và tập dữ liệu MNIST trong Hình 3, HideNseek hội tụ nhanh hơn FedMask, Signed và BNNAvg. Trong khi HideNseek trải qua sự biến động cao hơn trong huấn luyện so với các baseline trong tập dữ liệu EMNIST trong Hình 2(b) và ở một mức độ nào đó trong tập dữ liệu MNIST với tính dị thể cao hơn tại α = 0.1 trong Hình 3(a). Cả hai đều một lần nữa chỉ ra khó khăn trong việc huấn luyện một siêu mặt nạ dấu hiệu toàn cục được chia sẻ dưới điều kiện dị thể.

5.2 Chi phí Giao tiếp

Chúng tôi sau đó so sánh chi phí giao tiếp cho mỗi khách hàng bằng cách đo kích thước tải lên và tải xuống tính bằng MB cho mỗi khách hàng trong mỗi vòng giao tiếp như được hiển thị trong Bảng 2. Đầu tiên, BNNAvg với các tham số nhị phân nhỏ hơn bốn lần so với FedAvg vì 1 byte là kích thước phần tử nhỏ nhất để biểu diễn một tham số trong PyTorch. FedMask và Signed có chi phí tải lên thấp hơn so với BNNAvg do tỉa bớt phía khách hàng. HideNseek giảm thêm chi phí tải xuống nhờ tỉa bớt phía máy chủ. Hơn nữa, điểm tỉa bớt chi tiết hơn trong HideNseek so với FedMask và Signed. Điều này dẫn đến các mạng con nhỏ hơn vì chúng tôi loại bỏ tất cả trọng số có điểm bằng ngưỡng (xem dòng 15 trong Thuật toán 1). Nhìn chung, HideNseek thể hiện sự giảm chi phí giao tiếp so với hiệu suất tốt thứ hai (FedMask) từ 20.9-39.7% lần trên tất cả các nhiệm vụ.

5.3 Chi phí Tính toán

Chúng tôi báo cáo chi phí tính toán bằng cách đo tổng thời gian huấn luyện trên một GPU Nvidia RTX 3090 duy nhất (Bảng 3). FedAvg nhanh nhất chủ yếu vì nó không sử dụng bất kỳ trọng số tiềm ẩn nào, như các mặt nạ trong trường hợp của Signed, FedMask và HideNseek. Thậm chí BNNAvg còn chậm hơn FedAvg vì việc lượng tử hóa phải được thực hiện tại thời gian chạy và không có tối ưu hóa tích hợp trong PyTorch khi xử lý các tham số 1-bit. Tuy nhiên, HideNseek có thời gian huấn luyện thấp hơn so với FedMask và Signed vì các baseline này yêu cầu tỉa bớt một lần phía khách hàng mỗi khi có khách hàng mới tham gia huấn luyện. Ngoài ra, FedMask tốn kém tính toán hơn vì nó sử dụng số hạng chính quy hóa thưa thớt. Nhìn chung, HideNseek thể hiện sự giảm chi phí tính toán so với FedMask từ 22.8-46.8% trên tất cả các nhiệm vụ.

5.4 Khách hàng Hoạt động

Chúng tôi bây giờ đánh giá tác động của số lượng khách hàng hoạt động mỗi vòng giao tiếp đến hiệu suất huấn luyện. Bảng 4 thể hiện độ chính xác suy luận giữa các khách hàng trên MNIST (α = 1) với số lượng khách hàng hoạt động khác nhau K ∈ {10;20;40}. Trong khi hầu hết các baseline trải qua cải thiện độ chính xác với nhiều khách hàng hoạt động hơn, HideNseek trải qua sự giảm nhỏ 3.92% trong hiệu suất khi K tăng gấp bốn. Tuy nhiên, HideNseek vẫn thể hiện hiệu suất tốt hơn so với BNNAvg, FedMask và Signed với biên độ đáng kể. Điều này biểu thị khả năng mở rộng và một phần hỗ trợ tính mạnh mẽ của tính dị thể được thể hiện trong Hình 3.

5.5 Tỷ lệ Tỉa bớt

Từ các kết quả được thảo luận ở trên, rõ ràng rằng mô hình VGG9 được tham số hóa quá mức cho tập dữ liệu MNIST được chứng minh bởi độ chính xác suy luận cao của FedAvg và HideNseek. Do đó, chúng tôi thử tỷ lệ tỉa bớt tích cực đáng kể hơn p_r = 0.2 so với các thí nghiệm trước đó nơi p_r = 0.8. Như được hiển thị trong Hình 4, sự giảm hiệu suất rất nhỏ trong các tập dữ liệu ít dị thể α ∈ {1;10}, trong khi có sự giảm đáng kể trong tập dữ liệu dị thể hơn α = 0.1. Điều này chứng minh rằng lợi thế tính toán và giao tiếp của HnS so với các baseline lớn hơn các kết quả trước đó mà không có sự giảm độ chính xác đáng chú ý trong một số trường hợp khi sử dụng tỷ lệ tỉa bớt cao.

6 Công trình Liên quan

Tính Dị thể Thống kê. Sau công trình tiên phong về học liên bang [McMahan et al., 2017], những tiến bộ ngay lập tức tìm cách giải quyết vấn đề tính dị thể thống kê trong học liên bang bằng cách thích ứng các phương án cá nhân hóa. PerFedAvg [Fallah et al., 2020] tích hợp phương pháp học meta không phụ thuộc mô hình vào FedAvg để cá nhân hóa. MOCHA [Smith et al., 2017] giới thiệu học đa nhiệm vụ liên bang trong đó mỗi khách hàng được coi như một nhiệm vụ. Rất nhiều công trình [Lin et al., 2020; Gong et al., 2021; Zhu et al., 2021] cũng đã áp dụng chưng cất kiến thức để học một mô hình thay thế toàn cục dạy các mô hình cục bộ của khách hàng. [Li et al., 2021] thực hiện cá nhân hóa bằng cách cho phép mỗi khách hàng học một siêu mặt nạ nhị phân cục bộ. Ngược lại, chúng tôi sử dụng cá nhân hóa bằng cách chia sẻ toàn cục tất cả các lớp ẩn của mô hình trong khi tinh chỉnh lớp cuối cùng với dữ liệu cục bộ của khách hàng. Điều này cho phép HideNseek huấn luyện mô hình một cách ổn định bằng cách sửa đổi độ lớn trọng số cho một tập con nhỏ của trọng số trong khi lượng tử hóa các cập nhật được truyền cho tất cả các lớp ẩn. Như vậy, HideNseek giảm chi phí giao tiếp trong khi duy trì khả năng tốt hơn về mặt học dữ liệu với tính dị thể khác nhau như được hiển thị trong Hình 3.

Chi phí Giao tiếp và Tính toán. Một vấn đề quan trọng khác trong học liên bang là chi phí giao tiếp và tính toán tăng lên trên các thiết bị khách hàng khi tối ưu hóa và truyền trọng số. FedProx [Li et al., 2020] giảm thiểu vấn đề này thông qua việc cho phép ngắt huấn luyện và cập nhật một phần, và FedPAQ [Reisizadeh et al., 2020] cho phép tính trung bình định kỳ và lượng tử hóa các cập nhật mô hình. Một số công trình cũng đã giới thiệu các biến thể của tỉa bớt và dropout [Diao et al., 2021; Horvath et al., 2021; Bouacida et al., 2021] để nén mô hình. Ví dụ, FedMask áp dụng LTH [Frankle và Carbin, 2018] bằng cách thực hiện tỉa bớt một lần ở phía khách hàng và học một siêu mặt nạ nhị phân cục bộ được lượng tử hóa trong giao tiếp. Tuy nhiên, siêu mặt nạ nhị phân được học về cốt lõi là tỉa bớt không có cấu trúc không có lợi thế tính toán và hạn chế dung lượng mô hình. Do đó chúng tôi thay thế siêu mặt nạ nhị phân bằng siêu mặt nạ dấu hiệu để hội tụ nhanh hơn và sử dụng tỉa bớt không phụ thuộc dữ liệu tại máy chủ để giảm tải tính toán trên khách hàng.

7 Kết luận & Công việc Tương lai

Trong công trình này, chúng tôi đã giới thiệu HideNseek áp dụng giả thuyết vé số dưới thiết lập liên bang bằng cách tối ưu hóa dấu hiệu của một mạng con có tầm quan trọng khớp thần kinh của mô hình. Để giảm thêm tải tính toán trên khách hàng, chúng tôi thực hiện tỉa bớt một lần tại khởi tạo ở phía máy chủ sử dụng phương pháp không phụ thuộc dữ liệu và tối ưu hóa một siêu mặt nạ dấu hiệu được lượng tử hóa khi truyền các cập nhật mô hình. Kết quả thực nghiệm cho thấy HideNseek thể hiện độ chính xác suy luận tốt hơn so với state-of-the-art nói chung trong khi giảm đáng kể chi phí giao tiếp và thời gian huấn luyện. Tuy nhiên, một thách thức sắp tới mà chúng ta đối mặt là chi phí bộ nhớ phát sinh khi sử dụng các bộ ước lượng thẳng qua là đáng kể. Do đó, trong tương lai, chúng tôi sẽ khám phá hiệu quả được mang lại bởi việc sử dụng bộ tối ưu hóa nhị phân [Helwegen et al., 2019] chỉ sửa đổi dấu hiệu của trọng số mà không cần các tham số tiềm ẩn như siêu mặt nạ dấu hiệu.

8 Tác động Rộng lớn

Trong công trình này, chúng tôi đề xuất một thuật toán trong lĩnh vực học liên bang bắt nguồn từ nhu cầu phát triển các ứng dụng học sâu sau những tiến bộ gần đây trong các quy định bảo vệ dữ liệu như GDPR [Viorescu et al., 2017]. Hơn nữa, chúng tôi khám phá một phương pháp để giảm chi phí giao tiếp và tính toán trên các thiết bị di động chạy bằng pin để giảm tác động môi trường. Trong khi công trình của chúng tôi thể hiện các tác động tiết kiệm năng lượng từ góc độ lý thuyết, chúng tôi hy vọng các công trình tương lai sẽ tìm hiểu sâu hơn về tối ưu hóa hệ thống hướng tới bảo tồn năng lượng.

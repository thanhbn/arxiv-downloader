# 2305.17651.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/pruning/2305.17651.pdf
# Kích thước tệp: 368042 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
DPHuBERT: Kết hợp Chưng cất và Tỉa của các Mô hình Tiếng nói Tự giám sát
Yifan Peng1, Yui Sudo2, Shakeel Muhammad2, Shinji Watanabe1
1Đại học Carnegie Mellon, Pittsburgh, PA, Hoa Kỳ
2Viện Nghiên cứu Honda Nhật Bản Co., Ltd., Saitama, Nhật Bản
yifanpen@andrew.cmu.edu, {yui.sudo, shakeel.muhammad }@jp.honda-ri.com, shinjiw@ieee.org
Tóm tắt
Học tự giám sát (SSL) đã đạt được thành công đáng chú ý trong
nhiều tác vụ xử lý tiếng nói, nhưng kích thước mô hình lớn và
chi phí tính toán nặng cản trở việc triển khai. Chưng cất kiến thức
huấn luyện một mô hình học sinh nhỏ để bắt chước hành vi
của một mô hình giáo viên lớn. Tuy nhiên, kiến trúc học sinh
thường cần được thiết kế thủ công và sẽ cố định
trong quá trình huấn luyện, điều này đòi hỏi kiến thức trước và có thể dẫn
đến hiệu suất không tối ưu. Lấy cảm hứng từ thành công gần đây của
tỉa có cấu trúc theo tác vụ cụ thể, chúng tôi đề xuất DPHuBERT, một
phương pháp nén bất khả tri tác vụ mới cho SSL tiếng nói dựa trên
chưng cất và tỉa kết hợp. Các thí nghiệm trên SUPERB cho thấy
rằng DPHuBERT vượt trội hơn các phương pháp chưng cất thuần túy trong
hầu hết tất cả các tác vụ. Hơn nữa, DPHuBERT đòi hỏi ít thời gian huấn luyện
và hoạt động tốt với dữ liệu huấn luyện hạn chế, làm cho nó
phù hợp cho các ứng dụng bị ràng buộc tài nguyên. Phương pháp của chúng tôi cũng
có thể được áp dụng cho các mô hình SSL tiếng nói khác nhau. Mã nguồn và
mô hình của chúng tôi sẽ được công khai.
Từ khóa chỉ mục: nén mô hình, chưng cất kiến thức,
tỉa có cấu trúc, học tự giám sát
1. Giới thiệu
Học biểu diễn tiếng nói tự giám sát (SSL tiếng nói)
đã đạt được kết quả đáng kể trong các tác vụ khác nhau [1–10]. Tuy
nhiên, các mô hình SSL tiếng nói thường lớn và chậm, làm cho chúng
không phù hợp cho các ứng dụng thực tế với tài nguyên
hạn chế. Nén SSL tiếng nói đã trở thành một chủ đề quan trọng.
Một phương pháp phổ biến là chưng cất kiến thức [11], huấn luyện
một mô hình học sinh nhỏ để khớp với các đầu ra của một mô hình
giáo viên lớn. Các nghiên cứu trước như DistilHuBERT [12] và
FitHuBERT [13] đã đạt được kết quả hứa hẹn với các
mô hình học sinh khác nhau. Một công trình khác [14] cho thấy rằng kiến trúc
học sinh ảnh hưởng đáng kể đến hiệu suất của nó, ngay cả khi kích thước mô hình
tương tự. Tuy nhiên, trong các phương pháp chưng cất, kiến trúc học
sinh được chỉ định trước và không thay đổi, điều này cần
chuyên môn đặc biệt và có thể dẫn đến kết quả không tối ưu. Ngược
lại, tỉa [15, 16] tự động khám phá một mạng con
compact từ một mô hình lớn, điều này đã được khám phá trong xử lý
ngôn ngữ tự nhiên (NLP) [17–20] và xử lý tiếng nói [21–25]. Các
phương pháp tỉa trước cho SSL tiếng nói tập trung vào các tác vụ downstream
cụ thể như nhận dạng tiếng nói tự động (ASR) [24,25] và hiểu
ngôn ngữ nói (SLU) [25]. Không rõ chúng sẽ hoạt động như thế nào
trong nén bất khả tri tác vụ, điều này thách thức hơn vì mô hình cần
nắm bắt các khía cạnh khác nhau của tiếng nói bao gồm nội dung, người nói,
ngữ nghĩa và ngữ điệu [6].

Trong công trình này, chúng tôi đề xuất DPHuBERT, một phương pháp nén
bất khả tri tác vụ dựa trên Chưng cất và Tỉa kết hợp. Nó cho
phép kiến trúc học sinh được học trong quá trình chưng cất. Các thí nghiệm trên SUPERB [6] cho thấy rằng phương pháp của chúng tôi vượt trội
hơn các phương pháp chưng cất trước trong hầu hết tất cả các tác vụ. Phương pháp của chúng tôi
cũng hoạt động tốt cho các mô hình SSL tiếng nói khác nhau như Hu-
BERT Base [2], WavLM Base+ [4] và HuBERT Large [2],
ngay cả với tài nguyên huấn luyện hạn chế. Chúng tôi sẽ gửi kết
quả của mình lên bảng xếp hạng SUPERB và phát hành mã nguồn và mô
hình công khai để tái tạo: https://github.com/
pyf98/DPHuBERT .

2. Bối cảnh và công trình liên quan
2.1. Kiến trúc của SSL tiếng nói
Các mô hình SSL tiếng nói như wav2vec 2.0 [1], HuBERT [2] và
WavLM [4] chia sẻ kiến trúc tương tự. Mô hình bao gồm
một bộ trích xuất đặc trưng tích chập (CNN) và một bộ mã hóa
Transformer [26]. CNN có bảy tích chập thời gian với chuẩn
hóa và kích hoạt. Bộ mã hóa Transformer chứa
12 lớp với kích thước ẩn 768 cho các mô hình base và 24 lớp
với kích thước ẩn 1024 cho các mô hình large. Mỗi lớp được
tạo thành từ một self-attention đa đầu (MHA) và một mạng
feed-forward theo vị trí (FFN).

2.2. Phương pháp nén cho SSL tiếng nói
Chưng cất. Các phương pháp chưng cất tối ưu hóa một mô hình học sinh
nhỏ để khớp với các mục tiêu được tạo bởi một mô hình giáo viên lớn.
Vì các lớp khác nhau của SSL tiếng nói nắm bắt thông tin
khác nhau [27], mô hình học sinh cần học cả biểu diễn
cuối cùng và trung gian của giáo viên [12–14]. DistilHu-
BERT [12] huấn luyện một mô hình học sinh nông bằng cách ánh xạ
lớp học sinh cuối cùng đến nhiều lớp giáo viên trung gian. FitHu-
BERT [13] học một mô hình học sinh sâu và mỏng thông qua ánh xạ
lớp-đến-lớp. Một công trình khác [14] so sánh chưng cất
prediction-layer và layer-to-layer bằng cách sử dụng các kiến trúc
học sinh khác nhau. Nó cho thấy rằng kiến trúc của một mô hình học sinh ảnh
hưởng đến hiệu suất của nó, ngay cả khi kích thước mô hình được giữ tương tự.
Nó cũng phát hiện rằng các mạng sâu hơn hoạt động tốt hơn với chưng cất
layer-to-layer, có thể vì nó căn chỉnh rõ ràng các lớp trung gian.
Những quan sát này đã truyền cảm hứng cho công trình của chúng tôi cho phép
kiến trúc học sinh phát triển trong quá trình chưng cất.

Tỉa. Các phương pháp tỉa xác định và loại bỏ các tham số
dư thừa từ một mô hình đã được huấn luyện trước. Tỉa không có cấu trúc loại
bỏ các tham số riêng lẻ (ví dụ, một kết nối giữa các nơ-
ron) bằng cách đặt chúng bằng không, điều này đòi hỏi các thư viện tính toán
ma trận thưa để đạt được tăng tốc thực tế, trong khi tỉa
có cấu trúc loại bỏ các nhóm tham số (ví dụ, một đầu attention
hoặc thậm chí toàn bộ một lớp), điều này trực tiếp giảm kích thước mô hình
và chi phí tính toán. Đối với SSL tiếng nói, PARP [24] là
một phương pháp tỉa không có cấu trúc dựa trên độ lớn tỉa
bộ mã hóa Transformer. Nó cải thiện các tác vụ downstream như arXiv:2305.17651v1  [cs.CL]  28 May 2023

--- TRANG 2 ---
CNNMHAFFN…CNNMHAFFNLinearLinearLinear
Sóng âm thanh Audio WaveformGiáo viên (đóng băng)Học sinh (có thể tỉa)…MHAFFNMHAFFN(a)Bước 1: đồng thời chưng cất và tỉa mô hình học sinh.
CNNMHAFFNCNNMHAFFNMHAFFNLinearLinearLinear
Sóng âm thanh Audio WaveformGiáo viên (đóng băng)Học sinh (đã tỉa)……MHAFFN (b)Bước 2: tiếp tục chưng cất mô hình đã được tỉa.

Hình 1: Hai bước huấn luyện của phương pháp nén bất khả tri tác vụ của chúng tôi, DPHuBERT. (a) Mô hình học sinh được khởi tạo từ mô hình
giáo viên và được đồng thời chưng cất và tỉa để tạo ra một mô hình nhỏ hơn đáp ứng tỷ lệ thưa được chỉ định trước. (b) Mô hình học sinh đã được tỉa
được tiếp tục chưng cất để có hiệu suất tốt hơn. Để có được DPHuBERT (24M) từ HuBERT Base (95M), hai bước mất
khoảng 18 và 6 giờ GPU, tương ứng. (Các module gạch ngang có thể tỉa, tức là kiến trúc của chúng có thể phát triển trong quá trình huấn luyện.)

ASR tài nguyên thấp. HJ-Pruning [25] là một phương pháp tỉa có cấu trúc
tỉa đồng thời các thành phần không đồng nhất (tức là,
CNN và Transformer) của các mô hình SSL tiếng nói. Nó giảm đáng kể
tổng tính toán trong khi duy trì hiệu suất tốt
trong ASR và SLU. Những phương pháp này xử lý các tác vụ downstream
cụ thể, nhưng không điều tra các biểu diễn tiếng nói
phổ quát. Công trình của chúng tôi tập trung vào tỉa có cấu trúc bất khả tri tác vụ
của SSL tiếng nói. Vì không có dữ liệu được gán nhãn cho huấn luyện
giám sát bình thường, chúng tôi sử dụng một mục tiêu chưng cất cùng với tỉa.

Huấn luyện một-cho-tất-cả. Các phương pháp nén thường tạo
ra một mô hình duy nhất với kích thước được xác định trước. LightHu-
BERT [28] triển khai huấn luyện một-cho-tất-cả [29] để có được nhiều
subnet chia sẻ trọng số, điều này cho thấy hiệu suất rất mạnh
trên SUPERB [6]. Tuy nhiên, nó đòi hỏi một quy trình huấn luyện hai giai đoạn
đắt đỏ và một loss chưng cất tiên tiến lấy cảm hứng từ
data2vec [30]. Theo các tác giả, nén Hu-
BERT Base đã mất 2k giờ GPU (tức là, 62 giờ với 32
V100 GPU và 19 giờ với 8 GPU cho hai giai đoạn, tương
ứng), điều này quá đắt đỏ cho các nhà nghiên cứu học thuật và doanh
nghiệp nhỏ. Khác với LightHuBERT, công trình của chúng tôi nhằm nén
một mô hình SSL tiếng nói hiện có đến một tỷ lệ thưa cụ thể trong
một lượng thời gian huấn luyện có thể quản lý, điều này phù hợp với
thiết lập tiêu chuẩn của các phương pháp chưng cất trước [12, 13].

3. DPHuBERT
3.1. Quy trình huấn luyện
Hình 1 minh họa quy trình huấn luyện của chúng tôi bao gồm hai
bước. Trong Bước 1, mô hình học sinh được khởi tạo từ giáo viên
và được đồng thời chưng cất và tỉa để tạo ra một mô hình nhỏ hơn
với kích thước được chỉ định trước. Trong Bước 2, mô hình học sinh đã được tỉa
được tiếp tục chưng cất để cải thiện hiệu suất. Trong cả hai bước,
chỉ có dữ liệu tiếng nói không được gán nhãn được sử dụng và giáo viên được đóng băng.

3.2. Loss chưng cất
Khác với DistilHuBERT [12], chúng tôi sử dụng chưng cất layer-to-layer
vì học sinh ban đầu có cùng độ sâu với giáo viên
(xem Phần 2.2 để thảo luận). Giả sử giáo viên có Ntea
lớp Transformer với kích thước ẩn dtea và học sinh có
Nstu lớp với kích thước ẩn dstu. Gọi Xtea
i (hình dạng T×dtea)
và Xstu
i (hình dạng T×dstu) là các chuỗi đầu ra của lớp
Transformer thứ i từ giáo viên và học sinh, tương ứng,
trong đó T là độ dài chuỗi. Loss chưng cất là:
Ldis=X
i∈SL
Xtea
i,Xstu
iWi
, (1)
trong đó S là một tập hợp các lớp để khớp giữa mô hình giáo viên và
học sinh sau một phép chiếu tuyến tính Wi. Chúng tôi sử dụng S={0,4,8,12} cho các mô hình base và {0,8,16,24} cho các mô
hình large. Lớp thứ 0 là đầu ra của CNN, cũng là đầu vào
của lớp Transformer đầu tiên. Hàm loss L đo lường
sự khác biệt giữa hai chuỗi đặc trưng, có thể là khoảng cách L1, L2
hoặc cosine [12–14]. Chúng tôi theo [12,14] để sử dụng một kết hợp
của khoảng cách L1 và cosine với trọng số bằng nhau.

3.3. Chưng cất và tỉa có cấu trúc kết hợp
Tỉa có cấu trúc của mô hình học sinh được công thức hóa như
học một mô hình thưa thông qua điều chuẩn L0 [31], điều này đã
được khám phá trong NLP [19,20] và tiếng nói [25]. Phương pháp này sẽ
được giới thiệu ngắn gọn bên dưới. Để có các suy dẫn toàn diện hơn,
vui lòng tham khảo nghiên cứu trước [19, 20, 25, 31]. Xem xét
một mô hình giáo viên đóng băng ftea(·) và một mô hình học sinh fstu(·;θ)
với các tham số có thể học θ={θj}n
j=1. Mỗi θj là một nhóm
các tham số có thể tỉa (bao gồm các kênh tích chập, đầu atten-
tion và các đơn vị trung gian FFN) và có n nhóm
tổng cộng. Chúng tôi định nghĩa một biến nhị phân zj (gọi là mask) cho mỗi
θj. Các mask z theo một phân phối xác suất q(z;α) với
các tham số α. Mục tiêu chưng cất được điều chuẩn là:
min
θ,αEz∼q"
1
DDX
k=1Ldis
ftea(xk), fstu(xk;˜θ)
+λ∥˜θ∥0#
,
(2)
trong đó ˜θ={˜θj}n
j=1 và mỗi ˜θj=θjzj. Tập dữ liệu không được gán nhãn
với D mẫu là {xk}D
k=1. λ >0 là trọng số điều chuẩn.
Việc giải Eq. (2) bằng gradient descent là không khả thi do
bản chất rời rạc của các mask z. Để làm cho loss có thể vi phân,
Louizos et al. đề xuất một thủ thuật reparameterization lấy mẫu
z từ phân phối Hard Concrete [31]:
u∼ U(0,1),v(α) =sigmoid
logu
1−u+ log α
/β
,
¯v(α) = (r−l)·v(α) +l,z= min(1 ,max(0 ,¯v(α))),
(3)
trong đó u theo phân phối đều trong [0,1]. β là một hằng số.
l <0 và r >0 là hai hằng số để kéo dài v đến [l, r], và nó
được cắt bớt thêm đến [0,1]. Chỉ có α={αj}n
j=1 là các tham số
có thể học trong phân phối này. Với thủ thuật này, mục tiêu trong
Eq. (2) có thể vi phân và thuật ngữ điều chuẩn có một biểu thức
dạng đóng [31]:
Ez∼qh
∥˜θ∥0i
=nX
j=1sigmoid
logαj−βlog−l
r
,(4)
biểu diễn kích thước mô hình (mong đợi) như một hàm có thể vi phân
của các tham số hiện tại α.

--- TRANG 3 ---
Bảng 1: So sánh phương pháp của chúng tôi với các phương pháp chưng cất trước trên SUPERB [6]. DPHuBERT và DPWavLM của chúng tôi được
nén từ các checkpoint HuBERT Base [2] và WavLM Base+ [4] có sẵn công khai, tương ứng.
Phương pháp#Params KS IC PR ASR w/o LM ER QbE SF SID ASV SD
Triệu Acc ↑Acc↑PER↓ WER↓ Acc↑MTWV ↑F1↑/ CER↓Acc↑EER↓DER↓
FBANK 0 41.38 9.65 82.01 23.18 48.24 0.0058 69.64 / 52.94 20.06 9.56 10.05
wav2vec 2.0 Base [1] 95.04 96.23 92.35 5.74 6.43 63.43 0.0233 88.30 / 24.77 75.18 6.02 6.08
HuBERT Base [2] 94.68 96.30 98.34 5.41 6.42 64.92 0.0736 88.53 / 25.20 81.42 5.11 5.88
WavLM Base+ [4] 94.70 97.37 99.00 3.92 5.59 68.65 0.0988 90.58 / 21.20 89.42 4.07 3.50
Các mô hình nén sử dụng LibriSpeech 960h
DistilHuBERT [12] 23.49 95.98 94.99 16.27 13.37 63.02 0.0511 82.57 / 35.59 73.54 8.55 6.19
FitHuBERT [13] 22.49 96.27 91.25 13.32 12.09 59.82 0.0489 84.06 / 32.46 55.71 8.00 6.84
FitW2V2 [13] 31.63 96.04 93.38 12.22 11.44 62.35 0.0475 86.65 / 29.40 64.71 6.65 6.44
12-Layer Half [14] 26.87 97.24 96.97 10.67 10.96 63.24 0.0604 86.11 / 30.93 69.52 6.13 6.81
3-Layer One [14] 30.58 96.69 94.15 13.34 12.23 63.95 0.0489 82.89 / 34.65 75.71 6.48 6.56
DPHuBERT (của chúng tôi) 23.59 96.36 97.92 9.67 10.47 63.16 0.0693 86.86 / 28.26 76.83 5.84 5.92
DPWavLM (của chúng tôi) 23.59 96.27 98.58 8.22 10.19 65.24 0.0874 87.68 /26.11 82.11 5.98 5.53
Các mô hình nén sử dụng LibriSpeech 100h
DistilHuBERT [12] 23.49 - 93.17 - 14.77 - - - 69.46 - -
FitHuBERT [13] 22.49 96.23 94.20 14.05 12.66 61.67 0.0579 83.41 / 34.00 54.24 7.88 7.19
FitW2V2 [13] 22.49 94.68 90.03 16.50 14.77 62.87 0.0380 81.95 / 34.74 51.65 7.43 6.94
DPHuBERT (của chúng tôi) 23.57 96.36 97.42 10.02 11.38 62.78 0.0634 84.83 /33.03 73.37 6.25 6.03

Bây giờ Eq. (2) có thể được giải để học một subnet thưa, nhưng
độ thưa cuối cùng không thể được kiểm soát chính xác [19, 20]. Để
kiểm soát rõ ràng kích thước mô hình cuối cùng, các nghiên cứu trước [19, 20, 25]
viết lại bài toán tối ưu với một ràng buộc bằng nhau:
min
θ,αEz∼q"
1
DDX
k=1Ldis
ftea(xk), fstu(xk;˜θ)#
s.t.s(α) =t,(5)
trong đó s(α) là độ thưa hiện tại (phần trăm tham số được tỉa)
của mô hình học sinh và t là độ thưa mục tiêu được chỉ định trước. Lưu ý rằng s(α) có thể được tính dựa trên Eq. (4) vì
chuẩn L0 đếm các tham số còn lại. Mục tiêu tối ưu
trong Eq. (5) có thể được chuyển đổi thêm thành một bài toán minimax
bằng cách sử dụng Lagrangian mở rộng [19]:
max
λ1,λ2min
θ,αEz∼q"
1
DDX
k=1Ldis
ftea(xk), fstu(xk;˜θ)#
+λ1·(s(α)−t) +λ2·(s(α)−t)2,(6)
trong đó λ1, λ2∈R là các nhân tử Lagrange. Thuật ngữ bổ sung này
phạt loss chưng cất và buộc mô hình học sinh
đáp ứng độ thưa mục tiêu của chúng tôi. Eq. (6) là mục tiêu huấn luyện của chúng tôi cho
Bước 1 (Hình 1a). Đối với Bước 2 (Hình 1b), mục tiêu chỉ đơn giản là
tối thiểu hóa loss chưng cất trong Eq. (1) mà không có bất kỳ ràng
buộc nào vì kiến trúc học sinh đã được cố định.

4. Thí nghiệm
4.1. Thiết lập thí nghiệm
Bộ công cụ. Phương pháp của chúng tôi được triển khai với PyTorch [32] và
TorchAudio [33]. Các mô hình SSL đã huấn luyện trước được tải xuống từ
fairseq [34] hoặc Hugging Face [35].
Dữ liệu. LibriSpeech 960h [36] không được gán nhãn được sử dụng theo mặc định.
Trong Phần 4.2 và Bảng 1, tập con train-clean 100h cũng
được sử dụng để điều tra ảnh hưởng của kích thước dữ liệu huấn luyện.
Mô hình. Trong thiết lập mặc định, chúng tôi nén HuBERT Base [2].
Để xác minh tính tổng quát, chúng tôi cũng nén WavLM
Base+ [4] trong Phần 4.2 và HuBERT Large [2] trong Phần 4.5.
Huấn luyện. DPHuBERT được huấn luyện trên 4 GPU NVIDIA A100 (40GB)
với 640 giây âm thanh mỗi mini-batch. Trong Bước 1, 1 2 3 4 5 6 7300500
Lớp CNNKênh
1 2 3 4 5 6 7 8 910 11 12036
Lớp MHAĐầu
1 2 3 4 5 6 7 8 910 11 1205001,0001,500
Lớp FFNTrung gian

Hình 2: Các kênh CNN, đầu attention và kích thước trung gian
FFN của DPHuBERT được nén từ HuBERT Base sử dụng
LibriSpeech 960h. Kích thước gốc của chúng là 512, 12 và 3072,
tương ứng. Độ thưa mục tiêu được sử dụng cho tỉa là 75%.

tốc độ học tối đa của các tham số chính θ và các tham số
phụ α,λ là 2e-4 và 2e-2, tương ứng. Các bước khởi động và tổng
là 15k và 50k, tương ứng. Độ thưa mục tiêu t được
tăng tuyến tính đến giá trị mong muốn trong 5k bước, điều này tạo thuận lợi
cho việc huấn luyện [25]. Trong Bước 2, tốc độ học tối đa là 1e-4. Các bước khởi động
và tổng là 5k và 25k, tương ứng. Trong thiết lập mặc định,
tổng thời gian huấn luyện của DPHuBERT chỉ là 6 giờ, tức là 24
giờ GPU (do việc sử dụng 4 GPU của chúng tôi).
Đánh giá. Benchmark SUPERB [6] bao gồm 10 tác vụ:
phát hiện từ khóa (KS), phân loại ý định (IC), nhận dạng âm vị
(PR), ASR, nhận dạng cảm xúc (ER), truy vấn theo
ví dụ (QbE), điền slot (SF), nhận dạng người nói (SID),
xác minh người nói tự động (ASV) và phân đoạn người nói
(SD). Chúng tôi tuân theo các cấu hình mặc định của họ trong tất cả các tác vụ trừ
SID sử dụng tốc độ học 5e-3.

4.2. Kết quả chính
Bảng 1 so sánh các phương pháp khác nhau trên SUPERB [6]. DPHu-
BERT được nén từ HuBERT Base. Với LibriSpeech
960h, DPHuBERT vượt trội hơn các phương pháp chưng cất thuần túy (bao
gồm DistilHuBERT [12], FitHuBERT [13], FitW2V2 [13]
và hai mô hình có hiệu suất tốt nhất từ [14]) trong 8 trong số 10 tác vụ.
Điều này cho thấy rằng DPHuBERT bảo tồn tốt hơn các biểu diễn tiếng nói
tổng quát của mô hình giáo viên, bao gồm nội dung, người nói
và ngữ nghĩa. Chỉ với dữ liệu huấn luyện 100h, DPHuBERT vẫn
hoạt động tốt hơn nhiều so với các phương pháp trước trong hầu hết tất cả các tác vụ.

--- TRANG 4 ---
Bảng 2: Nghiên cứu loại bỏ thành phần trên DPHuBERT được nén từ HuBERT Base sử dụng LibriSpeech 960h.
Phương pháp#Params KS IC PR ASR w/o LM ER QbE SF SID ASV SD
Triệu Acc ↑Acc↑PER↓ WER↓ Acc↑MTWV ↑F1↑/ CER↓Acc↑EER↓DER↓
DPHuBERT 23.59 96.36 97.92 9.67 10.47 63.16 0.0693 86.86 /28.26 76.83 5.84 5.92
w/o bước huấn luyện 2 23.59 94.87 96.76 10.42 11.55 62.54 0.0624 86.12 / 30.15 71.42 6.36 6.65
w/ chưng cất pred-layer 23.65 95.55 94.54 16.09 14.65 59.06 0.0519 81.83 / 36.44 59.88 7.32 6.75
w/o tỉa CNN 23.59 96.30 97.60 9.63 11.00 63.16 0.0717 85.77 / 29.06 75.22 6.13 6.10

10 30 50 70 90949698
Params (M)% Acc ( ↑)
HuBERT Base
DistilHuBERT
DPHuBERT (của chúng tôi)
(a)IC10 30 50 70 9051015
Params (M)% WER ( ↓)HuBERT Base
DistilHuBERT
DPHuBERT (của chúng tôi)
(b)ASR10 30 50 70 90607080
Params (M)% Acc ( ↑)
HuBERT Base
DistilHuBERT
DPHuBERT (của chúng tôi)
(c)SID

Hình 3: DPHuBERT được huấn luyện với các độ thưa mục tiêu khác nhau. Các mô hình được nén từ HuBERT Base sử dụng LibriSpeech 960h.

Bảng 3: Nén HuBERT Large để có kích thước tương tự như HuBERT Base sử dụng LibriSpeech 960h.
Phương pháp#Params KS IC PR ASR w/o LM ER QbE SF SID ASV SD
Triệu Acc ↑Acc↑PER↓ WER↓ Acc↑MTWV ↑F1↑/ CER↓ Acc↑EER↓DER↓
HuBERT Large 316.60 95.29 98.76 3.53 3.62 67.62 0.0353 89.81 / 21.76 90.33 5.98 5.75
HuBERT Base 94.68 96.30 98.34 5.41 6.42 64.92 0.0736 88.53 / 25.20 81.42 5.11 5.88
DPHuBERT 94.59 94.51 98.47 4.46 6.23 65.11 0.0246 88.37 / 24.60 83.17 7.05 5.79

Đáng ngạc nhiên, DPHuBERT sử dụng 100h đã vượt trội hơn các
mô hình chưng cất trước sử dụng 960h trong IC, PR, QbE và SD,
và có kết quả tương tự trong các tác vụ khác. Điều này cho thấy rằng DPHu-
BERT học các biểu diễn mạnh mẽ ngay cả từ dữ liệu hạn chế.

Chúng tôi cũng đã nén WavLM Base+ để có được DP-
WavLM. So với DPHuBERT, DPWavLM đạt được cải
thiện hơn nữa trong 8 tác vụ. Điều này là do WavLM Base+ chưa
tỉa tốt hơn HuBERT Base chưa tỉa.
Những kết quả này chứng minh rằng phương pháp nén của chúng tôi có thể
được áp dụng cho các mô hình SSL tiếng nói khác nhau.

Hình 2 cho thấy kiến trúc của DPHuBERT, được
tự động khám phá bởi tỉa có cấu trúc. Đối với CNN, lớp
đầu tiên và cuối cùng được tỉa nhiều nhất. Đối với MHA, ba lớp
cao hơn được loại bỏ hoàn toàn, cho thấy những lớp đó dư thừa hơn.
Kết quả của chúng tôi phù hợp với các nghiên cứu trước về
tỉa [20, 25] hoặc bộ mã hóa tiếng nói tổng quát [37–40]. Đối với FFN,
các lớp thứ 4, 8 và 12 được bảo tồn nhiều hơn so với các
lớp láng giềng của chúng, vì những lớp đó được khớp rõ ràng giữa
mô hình giáo viên và học sinh như được định nghĩa bởi Eq. (1) trong Phần 3.2.

4.3. Nghiên cứu loại bỏ thành phần
Bảng 2 tóm tắt kết quả của các nghiên cứu loại bỏ thành phần sau.
Huấn luyện hai bước. DPHuBERT có hai bước huấn luyện (Phần
3.1 và Hình 1). Mô hình được tỉa sau Bước 1 mà không có
Bước 2 được đánh giá ở hàng thứ hai của Bảng 2. Nó kém hơn
DPHuBERT trong tất cả các tác vụ, xác minh sự cần thiết của Bước 2.
Điều này là do Bước 1 tối ưu hóa Eq. (6) trong đó thuật ngữ điều chuẩn
cạnh tranh với loss chưng cất để đáp ứng độ thưa mục tiêu,
trong khi Bước 2 trực tiếp tối ưu hóa loss chưng cất để
cải thiện các biểu diễn đã học của học sinh.

Phương pháp chưng cất. Như đã thảo luận trong Phần 2.2, DPHuBERT
sử dụng chưng cất layer-to-layer thay vì chưng cất prediction-layer
trong DistilHuBERT [12]. Hàng thứ ba của Bảng 2 cho thấy
rằng chưng cất prediction-layer gây ra suy giảm nghiêm trọng trong
tất cả các tác vụ, có thể do kiến trúc học sinh sâu. Khớp trực tiếp
các lớp trung gian tạo thuận lợi cho việc huấn luyện các học sinh sâu
như được tìm thấy trong [14].

Đơn vị tỉa. DPHuBERT tỉa cả CNN và Trans-
former vì CNN có chi phí tính toán cao [25, 41].
Hàng thứ tư của Bảng 2 cho thấy kết quả mà không tỉa CNN
(tức là, chỉ tỉa các đầu attention và kích thước trung gian FFN). Mô hình này (hơi) kém hơn thiết lập mặc định trong 7/10
tác vụ. Điều này xác minh rằng CNN cũng có các thành phần
dư thừa có thể được tỉa, như được báo cáo trong [25, 41, 42].

4.4. Kết quả ở các độ thưa khác nhau
Chúng tôi huấn luyện DPHuBERT với các độ thưa mục tiêu khác nhau (t trong
Eqs. (5) (6)) và cho thấy kết quả trong Hình 3. Đối với IC và SID,
phương pháp của chúng tôi có thể giảm đáng kể kích thước mô hình trong khi giữ
độ chính xác tương tự như HuBERT Base gốc. Đối với ASR,
sự suy giảm nghiêm trọng hơn, có thể vì tác vụ chuyển đổi chuỗi
thách thức hơn so với các tác vụ phân loại.

4.5. Nén HuBERT Large
Phương pháp của chúng tôi có thể được áp dụng cho các mô hình SSL tiếng nói lớn hơn với
chi phí huấn luyện rất hạn chế. Trong Bảng 3, HuBERT Large được
nén để có kích thước tương tự như HuBERT Base, điều này chỉ
mất khoảng 60 giờ GPU. Mô hình được nén thậm chí vượt
trội hơn HuBERT Base trong một số tác vụ như PR, SF-CER và
SID. Nó kém hơn HuBERT Base trong KS, QbE và ASV, nhưng
mô hình giáo viên, HuBERT Large, cũng rõ ràng kém hơn
HuBERT Base trong những tác vụ đó.

5. Kết luận
Công trình này đề xuất DPHuBERT, một phương pháp nén
bất khả tri tác vụ dựa trên chưng cất và tỉa có cấu trúc kết hợp.
DPHuBERT vượt trội hơn các phương pháp chưng cất trước trong hầu hết
các tác vụ của SUPERB. Các phân tích toàn diện được trình bày để điều
tra hiệu suất của nó với ít dữ liệu huấn luyện hơn hoặc ở các
tỷ lệ thưa khác nhau. Ngoài HuBERT Base, phương pháp của chúng tôi có thể
được áp dụng trực tiếp cho các mô hình SSL tiếng nói khác như WavLM
và HuBERT Large trong khi vẫn hiệu quả và có hiệu suất cao. Trong
tương lai, chúng tôi sẽ khám phá các mục tiêu chưng cất tinh vi hơn
(ví dụ, loss chưng cất dựa trên masking được sử dụng trong LightHu-
BERT [28]) để cải thiện hiệu suất hơn nữa.

6. Lời cảm ơn
Chúng tôi sử dụng PSC Bridges2 và NCSA Delta thông qua phân bổ ACCESS
CIS210014, được hỗ trợ bởi các khoản tài trợ của Quỹ Khoa học Quốc gia
#2138259, #2138286, #2138307, #2137603, và #2138296.

--- TRANG 5 ---
7. Tài liệu tham khảo
[1] A. Baevski, Y. Zhou, A. Mohamed, và M. Auli, "wav2vec 2.0:
Một framework cho việc học tự giám sát các biểu diễn tiếng nói,"
trong Proc. NeurIPS, 2020.
[2] W.-N. Hsu, B. Bolte, Y.-H. H. Tsai, K. Lakhotia, R. Salakhutdi-
nov, và A. Mohamed, "HuBERT: Học Biểu diễn Tiếng nói Tự-
Giám sát bằng Dự đoán Có Mask của Các Đơn vị Ẩn,"
IEEE/ACM Trans. Audio, Speech, Lang. Process., vol. 29, pp.
3451–3460, 2021.
[3] A. Babu, C. Wang, A. Tjandra, K. Lakhotia, Q. Xu, N. Goyal,
K. Singh, P. von Platen, Y. Saraf, J. Pino, A. Baevski, A. Conneau,
và M. Auli, "XLS-R: Học Biểu diễn Tiếng nói Đa ngôn ngữ Tự-
giám sát ở Quy mô Lớn," trong Proc. Interspeech, 2022.
[4] S. Chen, C. Wang, Z. Chen, Y. Wu, S. Liu, Z. Chen, J. Li,
N. Kanda, T. Yoshioka, X. Xiao et al., "Wavlm: Tiền huấn luyện
tự-giám sát quy mô lớn cho xử lý tiếng nói full stack," IEEE J.
Sel. Topics Signal Process., vol. 16, no. 6, pp. 1505–1518, 2022.
[5] A. Baevski, W.-N. Hsu, A. Conneau, và M. Auli, "Nhận dạng
tiếng nói không giám sát," trong Proc. NeurIPS, 2021.
[6] S. wen Yang, P.-H. Chi, Y.-S. Chuang, C.-I. J. Lai, K. Lakhotia,
Y. Y. Lin, A. T. Liu, J. Shi, X. Chang, G.-T. Lin, T.-H. Huang,
W.-C. Tseng, K. tik Lee, D.-R. Liu, Z. Huang, S. Dong, S.-W.
Li, S. Watanabe, A. Mohamed, và H. yi Lee, "SUPERB: Benchmark
Hiệu suất Phổ quát Xử lý Tiếng nói," trong Proc. Inter-
speech, 2021.
[7] A. Mohamed, H.-y. Lee, L. Borgholt, J. D. Havtorn, J. Edin,
C. Igel, K. Kirchhoff, S.-W. Li, K. Livescu, L. Maaløe, T. N.
Sainath, và S. Watanabe, "Học biểu diễn tiếng nói tự-giám sát:
Một đánh giá," IEEE J. Sel. Topics Signal Process., vol. 16,
no. 6, pp. 1179–1210, 2022.
[8] X. Chang, T. Maekaku, P. Guo, J. Shi, Y.-J. Lu, A. S. Subrama-
nian, T. Wang, S.-w. Yang, Y. Tsao, H.-y. Lee et al., "Một khám
phá về các biểu diễn tiền huấn luyện tự-giám sát cho nhận dạng
tiếng nói end-to-end," trong Proc. ASRU, 2021.
[9] Z. Huang, S. Watanabe, S.-w. Yang, P. García, và S. Khudanpur,
"Điều tra Học Tự-Giám sát cho Tăng cường và Tách Tiếng nói,"
trong Proc. ICASSP, 2022.
[10] Y. Peng, S. Arora, Y. Higuchi, Y. Ueda, S. Kumar, K. Ganesan,
S. Dalmia, X. Chang, và S. Watanabe, "Một Nghiên cứu về Tích
hợp các Mô hình SSL, ASR, LM và SLU đã Tiền huấn luyện cho
Hiểu Ngôn ngữ Nói," trong Proc. SLT, 2022.
[11] G. Hinton, O. Vinyals, và J. Dean, "Chưng cất kiến thức trong
một mạng neural," arXiv:1503.02531, 2015.
[12] H.-J. Chang, S.-w. Yang, và H.-y. Lee, "DistilHuBERT: Học
biểu diễn tiếng nói bằng chưng cất theo lớp của hidden-unit
BERT," trong Proc. ICASSP, 2022.
[13] Y. Lee, K. Jang, J. Goo, Y. Jung, và H. R. Kim, "FitHuBERT:
Đi Mỏng hơn và Sâu hơn cho Chưng cất Kiến thức của Các Mô
hình Tự-Giám sát Tiếng nói," trong Proc. Interspeech, 2022.
[14] T. Ashihara, T. Moriya, K. Matsuura, và T. Tanaka, "Sâu so với
Rộng: Một Phân tích về Kiến trúc Học sinh cho Chưng cất Kiến
thức Bất khả tri Tác vụ của Các Mô hình Tiếng nói Tự-Giám sát,"
trong Proc. Interspeech, 2022.
[15] R. Reed, "Các thuật toán tỉa-một khảo sát," IEEE Trans. on Neural
Networks, vol. 4, no. 5, pp. 740–747, 1993.
[16] Z. Liu, M. Sun, T. Zhou, G. Huang, và T. Darrell, "Suy nghĩ lại
về giá trị của việc tỉa mạng," trong Proc. ICLR, 2019.
[17] P. Michel, O. Levy, và G. Neubig, "Liệu mười sáu đầu thực sự tốt
hơn một đầu?" trong Proc. NeurIPS, 2019.
[18] A. Fan, E. Grave, và A. Joulin, "Giảm độ sâu transformer theo
yêu cầu với structured dropout," trong Proc. ICLR, 2020.
[19] Z. Wang, J. Wohlwend, và T. Lei, "Tỉa Có cấu trúc của Các Mô
hình Ngôn ngữ Lớn," trong Proc. EMNLP, 2020.
[20] M. Xia, Z. Zhong, và D. Chen, "Tỉa Có cấu trúc Học Các Mô hình
Compact và Chính xác," trong Proc. ACL, 2022.
[21] P. Dong, S. Wang, W. Niu et al., "Rtmobile: Vượt quá tăng tốc
mobile thời gian thực của RNN cho nhận dạng tiếng nói," trong
ACM/IEEE Design Automation Conference (DAC), 2020.
[22] S. Wang, P. Lin, R. Hu et al., "Tăng tốc LSTM với Phương pháp
Tỉa Có cấu trúc trên FPGA," IEEE Access, 2019.
[23] K. Tan và D. Wang, "Nén Mạng Neural Sâu cho Tăng cường
Tiếng nói Hiệu quả," trong Proc. ICASSP, 2021.
[24] C.-I. J. Lai, Y. Zhang, A. H. Liu, S. Chang, Y.-L. Liao, Y.-S.
Chuang, K. Qian, S. Khurana, D. Cox, và J. Glass, "PARP:
Tỉa, Điều chỉnh và Tỉa lại cho Nhận dạng Tiếng nói Tự-Giám sát,"
trong Proc. NeurIPS, 2021.
[25] Y. Peng, K. Kim, F. Wu, P. Sridhar, và S. Watanabe, "Tỉa
Có cấu trúc của Các Mô hình Tiền huấn luyện Tự-Giám sát cho
Nhận dạng và Hiểu Tiếng nói," trong Proc. ICASSP, 2023.
[26] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.
Gomez, Ł. Kaiser, và I. Polosukhin, "Attention is all you need,"
trong Proc. NeurIPS, 2017.
[27] A. Pasad, J.-C. Chou, và K. Livescu, "Phân tích Theo lớp của
một Mô hình Biểu diễn Tiếng nói Tự-Giám sát," trong Proc. ASRU,
2021.
[28] R. Wang, Q. Bai, J. Ao, L. Zhou, Z. Xiong, Z. Wei, Y. Zhang,
T. Ko, và H. Li, "LightHuBERT: Học Biểu diễn Tiếng nói Nhẹ
và Có thể Cấu hình với Once-for-All Hidden-Unit BERT," trong
Proc. Interspeech, 2022.
[29] H. Cai, C. Gan, T. Wang, Z. Zhang, và S. Han, "Once-for-all:
Huấn luyện một mạng và chuyên môn hóa nó cho triển khai hiệu
quả," trong Proc. ICLR, 2020.
[30] A. Baevski, W.-N. Hsu, Q. Xu, A. Babu, J. Gu, và M. Auli,
"Data2vec: Một framework tổng quát cho học tự-giám sát trong
tiếng nói, thị giác và ngôn ngữ," trong Proc. ICML, 2022.
[31] C. Louizos, M. Welling, và D. P. Kingma, "Học Mạng Neural
Thưa thông qua Điều chuẩn L0," trong ICLR, 2018.
[32] A. Paszke et al., "Pytorch: Một thư viện học sâu hiệu suất cao,
kiểu imperative," Proc. NeurIPS, 2019.
[33] Y.-Y. Yang et al., "Torchaudio: Các khối xây dựng cho xử lý
âm thanh và tiếng nói," arXiv:2110.15018, 2021.
[34] M. Ott et al., "fairseq: Một bộ công cụ nhanh, có thể mở rộng
cho mô hình hóa chuỗi," trong Proc. NAACL-HLT: Demonstrations,
2019.
[35] T. Wolf et al., "Huggingface's transformers: Xử lý ngôn ngữ tự
nhiên hiện đại," arXiv preprint arXiv:1910.03771, 2019.
[36] V. Panayotov, G. Chen, D. Povey, và S. Khudanpur, "Lib-
rispeech: Một corpus ASR dựa trên sách âm thanh miền công
cộng," trong Proc. ICASSP, 2015.
[37] S. Zhang, E. Loweimi, P. Bell, và S. Renals, "Về tính hữu ích
của self-attention cho nhận dạng tiếng nói tự động với transform-
ers," trong Proc. SLT, 2021.
[38] K. Shim, J. Choi, và W. Sung, "Hiểu vai trò của self attention
cho nhận dạng tiếng nói hiệu quả," trong Proc. ICLR, 2022.
[39] Y. Peng, S. Dalmia, I. Lane, và S. Watanabe, "Branchformer:
Kiến trúc MLP-attention song song để nắm bắt bối cảnh cục bộ
và toàn cục cho nhận dạng và hiểu tiếng nói," trong Proc.
ICML, 2022.
[40] T. Maekaku, Y. Fujita, Y. Peng, và S. Watanabe, "Làm mượt
Trọng số Attention bằng Phân phối Tiên nghiệm cho ASR End-
to-End dựa Transformer," trong Proc. Interspeech, 2022.
[41] T.-Q. Lin, H.-y. Lee, và H. Tang, "MelHuBERT: Một HuBERT
đơn giản hóa trên Mel spectrogram," arXiv:2211.09944, 2022.
[42] F. Wu, K. Kim, J. Pan, K. J. Han, K. Q. Weinberger, và Y. Artzi,
"Đánh đổi hiệu suất-hiệu quả trong tiền huấn luyện không giám
sát cho nhận dạng tiếng nói," trong Proc. ICASSP, 2022.

PADA: CẮT TỈA HỖ TRỢ THÍCH ỨNG MIỀN CHO BIỂU DIỄN TIẾNG NÓI TỰ GIÁM SÁT

Vasista Sai Lodagala1, Sreyan Ghosh2, S. Umesh1
1Viện Công nghệ Ấn Độ, Madras
2Đại học Maryland, College Park

TÓM TẮT
Trong khi các mô hình học biểu diễn tiếng nói tự giám sát (SSL) phục vụ nhiều tác vụ hạ nguồn khác nhau, những mô hình này đã được quan sát thấy là có xu hướng overfit với miền mà dữ liệu không gán nhãn bắt nguồn từ đó. Để giảm thiểu vấn đề này, chúng tôi đề xuất PADA (Cắt tỉa Hỗ trợ Thích ứng Miền). Trước khi thực hiện fine-tuning ASR miền đích, chúng tôi khám phá các trọng số dư thừa từ các mô hình wav2vec 2.0 đã được pre-train thông qua các chiến lược cắt tỉa khác nhau. Chúng tôi điều tra hiệu ứng của cắt tỉa Không phụ thuộc Tác vụ và Phụ thuộc Tác vụ và đề xuất một mô hình cắt tỉa mới gọi là Cắt tỉa Phụ thuộc Tác vụ Liên miền (CD-TAW). CD-TAW thu được mặt nạ cắt tỉa ban đầu từ một mô hình ngoài miền (OOD) đã được fine-tune tốt, do đó tận dụng các mô hình đã fine-tune sẵn có từ web. Phương pháp CD-TAW đề xuất đạt được cải thiện WER tương đối lên đến 20.6% so với baseline khi fine-tune trên tập con 2 giờ của dữ liệu Switchboard mà không có giải mã mô hình ngôn ngữ (LM).

Từ khóa chỉ mục — thích ứng miền, cắt tỉa, học tự giám sát, nhận dạng tiếng nói tự động, tiếng nói điện thoại

1. GIỚI THIỆU
Trong thập kỷ qua, Nhận dạng Tiếng nói Tự động (ASR) đã thu hút sự chú ý của các nhà nghiên cứu từ nhiều lĩnh vực khác nhau do tiềm năng ứng dụng trong các hệ thống Hiểu Ngôn ngữ Tự nhiên (NLU) khác nhau có tiếng nói là phương thức giao tiếp chính [1, 2, 3, 4]. Sự ra đời của Mạng Nơ-ron Sâu (DNN) đã đẩy mạnh state-of-the-art (SOTA) trong nhận dạng tiếng nói trong nhiều môi trường khác nhau [5, 6]. Tuy nhiên, DNN tiêu tốn tài nguyên và xây dựng các hệ thống ASR hiệu quả đòi hỏi nhiều tính toán và giám sát dưới dạng dữ liệu được gán nhãn. Do đó, các phương pháp Học Tự Giám sát (SSL) gần đây [6, 7, 8, 9] có thể học biểu diễn trực tiếp từ dữ liệu âm thanh không gán nhãn, đã nhận được nhiều sự quan tâm. Mục tiêu chính của SSL là sử dụng tiếng nói thô [6], hoặc các đặc trưng mức thấp khác như Filter Banks [10], để học các biểu diễn mức cao tỏ ra hiệu quả trong các tác vụ xử lý tiếng nói hạ nguồn khác. SSL đã cho thấy những cải thiện hiệu suất đáng kể trong việc xây dựng hệ thống ASR, đặc biệt trong các môi trường mà dữ liệu được gán nhãn khan hiếm (chỉ 10 phút), và đã được biết đến là tổng quát hóa tốt hơn học có giám sát.

Tuy nhiên, một số nghiên cứu gần đây đã làm nổi bật các nhược điểm của SSL. Thứ nhất, các tác vụ pretext mà hệ thống phải giải quyết dưới mô hình SSL tốn nhiều tính toán [6] và đòi hỏi nhiều dữ liệu không gán nhãn. Thứ hai, một nghiên cứu gần đây tiết lộ rằng tương tự như học có giám sát, SSL cũng bị thiên vị với miền mà dữ liệu không gán nhãn bắt nguồn từ đó [11]. Thứ ba, vì SSL một cách ngầm định học một mô hình ngôn ngữ và thông tin ngữ nghĩa khác thông qua các tác vụ mà nó phải giải quyết [12], khả năng tổng quát hóa của những mô hình này chỉ ở mức độ mà dữ liệu từ ngôn ngữ hoặc cấu trúc âm vị tương tự được giới thiệu với nó ở giai đoạn fine-tuning. Do đó, như được chỉ ra một cách chính xác bởi [13], SSL cho tiếng nói gặp phải các vấn đề về quy mô, và khả năng tổng quát hóa SSL có thể được cải thiện với các quy trình huấn luyện hiệu quả hơn. Công trình trước đây về thích ứng miền với các mô hình tự giám sát chủ yếu sử dụng các phương pháp pre-training tiếp tục hoặc pre-training dữ liệu kết hợp [11]. Tuy nhiên, cả hai đều giả định sự tồn tại của dữ liệu miền đích không gán nhãn tài nguyên cao, điều này không phải lúc nào cũng có trong tình huống thực tế (ví dụ, tiếng nói hội thoại điện thoại rất khó thu thập do các vấn đề bảo mật và không có nhiều hơn 1000 giờ miễn phí trực tuyến).

Dựa trên vấn đề thứ hai và thứ ba được đề cập ở trên, trong bài báo này, chúng tôi cố gắng giải quyết vấn đề thiên vị miền trong các mô hình SSL đã pre-train và cố gắng thiết kế một thuật toán có thể cho phép các mô hình đã pre-train được huấn luyện trên dữ liệu OOD dễ dàng thích ứng với miền đích và với hiệu suất được cải thiện, chỉ sử dụng dữ liệu Trong Miền có giám sát. Để đạt được mục tiêu này, chúng tôi nhờ đến sự trợ giúp của Cắt tỉa Độ lớn Không cấu trúc (UMP), trong đó chúng tôi chọn các tham số mô hình có "độ lớn nhỏ nhất", mà chúng tôi giả thuyết là có "tầm quan trọng nhỏ nhất" đối với miền, và đề xuất làm chúng bằng không để các trọng số quan trọng cho tác vụ hạ nguồn sẽ xuất hiện với các cập nhật gradient, và những cái không liên quan sẽ giảm về độ lớn. Điều này đã được chứng minh thực nghiệm đầu tiên trong [14]. Các tham số đã làm bằng không cũng được giữ có thể huấn luyện, điều này làm cho nó khác với cắt tỉa DNN chung, nơi mặt nạ cắt tỉa không cho phép cập nhật gradient. Thêm chi tiết về các chiến lược cắt tỉa khác nhau có thể được tìm thấy trong Alg.1. Chúng tôi được thúc đẩy bởi các phát hiện từ Giả thuyết Vé số (Lottery Ticket Hypothesis) [15], cho rằng một mạng được khởi tạo ngẫu nhiên chứa các mạng con thưa thớt có thể được huấn luyện riêng lẻ để khớp với kết quả của một mô hình đầy đủ. Ngoài ra, [16] khám phá cắt tỉa cho thích ứng ngôn ngữ đơn ngữ trong các mô hình đa ngôn ngữ đã pre-train. Tóm lại, những đóng góp chính của chúng tôi như sau:

• Chúng tôi phân tích hiệu suất của các chiến lược và tần suất cắt tỉa khác nhau cho thích ứng miền trên các mô hình SSL tiếng nói đã pre-train. Chúng tôi dựa các thí nghiệm của mình trên giả định thực tế rằng chỉ có lượng hạn chế dữ liệu miền đích được gán nhãn có sẵn, và không có corpus không gán nhãn quy mô lớn nào khác có sẵn từ miền đích.

• Chúng tôi đề xuất Cắt tỉa Phụ thuộc Tác vụ Liên miền (CD-TAW), một phương pháp đầu tiên thuộc loại này sử dụng các mô hình có sẵn đã fine-tune trên dữ liệu OOD được gán nhãn tài nguyên cao để thu được mặt nạ cắt tỉa ban đầu phù hợp với tác vụ ASR hạ nguồn. Kết quả thí nghiệm tiết lộ rằng CD-TAW hoạt động tốt hơn các phương pháp fine-tuning chung, TAG và TAW.

2. CÔNG TRÌNH LIÊN QUAN

2.1. Học Biểu diễn Tiếng nói Tự Giám sát
SSL cho học biểu diễn tiếng nói đã được khám phá chủ yếu dưới 3 mô hình chính, mỗi mô hình giải quyết một dạng Mô hình hóa Âm thanh Có mặt nạ (MAM). Mô hình đầu tiên và phổ biến nhất trong không gian này dựa trên Mã hóa Dự đoán Đối lập (CPC), giảm thiểu mất mát InfoNCE [17, 6]. Mô hình thứ hai học bằng cách giảm thiểu mất mát Cross-Entropy, trong đó tác vụ chính là dự đoán nhãn giả chính xác được gán cho một khung, được che đi ở đầu vào của mô hình, tận dụng nhúng ngữ cảnh hóa của khung đó thu được từ một bộ mã hóa transformer [8, 9]. Mô hình thứ ba và cuối cùng giải quyết hàm mục tiêu dựa trên tái tạo [10, 18].

2.2. Cắt tỉa
Khái niệm cắt tỉa DNN đã được nghiên cứu rộng rãi trong quá khứ [15, 19, 20]. Các tác giả của [21] cho thấy rằng các mô hình thưa thớt lớn thu được thông qua cắt tỉa thường hoạt động tốt hơn khi so sánh với các mô hình nhỏ hơn nhưng dày đặc. Một trong những công trình đầu tiên đề xuất cắt tỉa cho thích ứng miền là của [22]. Tuy nhiên, họ đề xuất một phương pháp hoàn toàn khác sử dụng chưng cất kiến thức và áp dụng nó cho Dịch máy Nơ-ron (NMT) dựa trên văn bản. [16] đề xuất một phương pháp cắt tỉa để cải thiện hiệu suất ASR đơn ngữ trong các mô hình SSL đa ngôn ngữ đã pre-train. Các tác giả của PARP [14] đã đề xuất công trình đầu tiên về cắt tỉa các mô hình tiếng nói tự giám sát lớn đã pre-train. Họ dự định tìm một mạng con thưa thớt đã fine-tune ở một mức độ thưa thớt mục tiêu nhất định, với hiệu suất được cải thiện so với việc sử dụng một mô hình đầy đủ. Tuy nhiên, công trình của chúng tôi khác với họ chủ yếu từ góc độ tác vụ cuối cùng mà chúng tôi cố gắng giải quyết. Chúng tôi tiếp cận UMP lặp [15] từ góc độ thích ứng miền và thiết kế thuật toán của chúng tôi bằng cách giả thuyết tương ứng. Mục tiêu cuối cùng của chúng tôi là thích ứng mô hình SSL đã pre-train với miền đích, và trọng tâm không phải là thu được một mô hình thưa thớt. Một sự khác biệt chính từ PARP là các chiến lược cắt tỉa phụ thuộc tác vụ của chúng tôi hoạt động tốt hơn cho thích ứng miền. Đồng thời, PARP dùng đến các chiến lược cắt tỉa không phụ thuộc tác vụ vì họ không quan sát sự khác biệt lớn giữa hai cái, do họ fine-tune trên dữ liệu từ cùng miền với dữ liệu không gán nhãn của mô hình đã pre-train. Một sự khác biệt chính khác từ PARP là, trong khi họ tăng tỷ lệ cắt tỉa một cách tiến bộ để đạt được độ thưa thớt mục tiêu trong PARP-P, chúng tôi giảm tỷ lệ cắt tỉa một cách động để thích ứng miền tốt hơn như được giải thích trong Phần 3.2.4.

2.3. Thích ứng Miền
Thích ứng Miền (DA) để xây dựng hệ thống ASR hiệu quả đã là một chủ đề được nghiên cứu kỹ trong tài liệu, với công trình sớm tập trung vào chính quy hóa [23, 24], học thầy-trò [25, 26] hoặc học đối kháng [27, 28]. Gần đây, thích ứng miền không giám sát của các mô hình ASR đã nhận được sự quan tâm, và các nhà nghiên cứu đã cố gắng tìm cách sử dụng lượng lớn dữ liệu không gán nhãn từ miền đích cho thích ứng miền [26, 29, 30]. Pre-training tiếp tục là một phương pháp phổ biến khác được sử dụng [31]. Chúng tôi nhấn mạnh rằng công trình của chúng tôi là một trong những công trình đầu tiên tiếp cận thích ứng miền từ góc độ cắt tỉa, không liên quan đến pre-training tiếp tục hoặc dữ liệu không gán nhãn OOD.

3. PHƯƠNG PHÁP ĐỀ XUẤT

3.1. Công thức Vấn đề
Giả sử chúng ta có một tập dữ liệu OOD không gán nhãn tài nguyên cao P và một tập dữ liệu OOD được gán nhãn tài nguyên trung bình đến cao J, cả hai từ miền D1. Chúng ta cũng có một tập dữ liệu được gán nhãn tài nguyên thấp L. Gọi p(θ) là mạng nơ-ron được pre-train sử dụng tự giám sát trên tập dữ liệu P từ miền D1 và gọi f(ϕ) đại diện cho mạng nơ-ron kết quả sau khi fine-tuning ASR dựa trên CTC đã được thực hiện trên p(θ) trên tập dữ liệu J từ miền D1, sao cho ϕ ∈ Rd, đại diện cho d số tham số mạng. Như một phần của công trình này, các mô hình p(θ) và f(ϕ) mà chúng tôi sử dụng được cung cấp trong miền công cộng thông qua các công trình về wav2vec-2.0 và fairseq [6, 32].

Mục tiêu chính của chúng tôi là thích ứng mô hình p(θ) của chúng tôi với miền D2 chỉ bằng cách sử dụng tập dữ liệu tài nguyên thấp L, với hiệu suất tốt hơn fine-tuning chung của p(θ) trên L. Chúng tôi đạt được mục tiêu này bằng cách xác định các trọng số có tầm quan trọng ít nhất và làm chúng bằng không. Các trọng số liên quan cho tác vụ ASR hạ nguồn trên L sẽ xuất hiện với các cập nhật gradient, và những cái không liên quan bị làm bằng không để tạo điều kiện cho việc thích ứng mô hình tốt hơn. Vì chúng tôi nhằm mục đích có được một mô hình mang lại hiệu suất tốt hơn mà không tập trung vào việc đạt được độ thưa thớt mục tiêu, các trọng số đã được làm bằng không vẫn có thể huấn luyện trên L, do đó tận dụng toàn bộ dung lượng mô hình.

3.2. Cắt tỉa Hỗ trợ Thích ứng Miền (PADA)
Chiến lược cắt tỉa chung trong các bộ công cụ học sâu hiện đại bao gồm việc thu được một mặt nạ M cho một tập con của các tham số mô hình, điều này một cách trực quan dẫn đến việc nhân với giá trị bằng không trong bước truyền tiến. Ngoài ra, mặt nạ không cho phép cập nhật gradient cho các tham số này trong quá trình truyền ngược. Như một phần của công trình này, chúng tôi khám phá các chiến lược cắt tỉa khác nhau dựa trên UMP. Trọng tâm của PADA là khám phá "các trọng số ít quan trọng nhất" trong một mô hình SSL đã pre-train p(θ). Không giống như cắt tỉa chung, PADA không giữ lại mặt nạ và nâng mặt nạ sau một vòng UMP, tiếp theo là làm bằng không các tham số đã xác định, và giữ các tham số có thể huấn luyện. PADA có thể được thực hiện theo nhiều cách, chủ yếu khác nhau trong quy trình thu được các mặt nạ cắt tỉa ban đầu ở đầu huấn luyện và tỷ lệ cắt tỉa được sử dụng ở mỗi lần lặp huấn luyện. Hình 1 minh họa ba chiến lược cắt tỉa chính. Trong bốn phần phụ sau đây, chúng tôi thảo luận ngắn gọn về các chiến lược cắt tỉa liên quan đến PADA và thuật toán để thực hiện tương tự.

3.2.1. Cắt tỉa Không phụ thuộc Tác vụ (TAG)
Trong phương pháp này, chúng tôi thực hiện UMP ở tỷ lệ cắt tỉa r1 trực tiếp trên p(θ), và r1 phần trăm trọng số có độ lớn ít nhất được làm bằng không, dẫn đến mô hình p(θ'). Phương pháp này không xem xét fine-tuning ASR hạ nguồn mà p(θ) sẽ phải chịu. Các trọng số đã được làm bằng không được xác định là có tầm quan trọng ít nhất về mặt độ lớn, chỉ dựa trên tác vụ pre-training. Người ta phải lưu ý rằng pre-training được sử dụng để học các biểu diễn phục vụ nhiều tác vụ hạ nguồn, và fine-tuning mô hình trên các tác vụ và tập dữ liệu hạ nguồn cụ thể có thể dẫn đến một tập hợp trọng số khác nhau trở nên quan trọng.

3.2.2. Cắt tỉa Phụ thuộc Tác vụ (TAW)
Chiến lược Cắt tỉa Phụ thuộc Tác vụ nhằm mục đích làm bằng không những trọng số từ p(θ), có tầm quan trọng ít nhất cụ thể cho tác vụ ASR hạ nguồn được thực hiện trên tập dữ liệu L. Để đạt được điều này, đầu tiên chúng tôi fine-tune p(θ) trên L dẫn đến mô hình đã fine-tune p(θf). Sau đó chúng tôi thực hiện UMP ở tỷ lệ cắt tỉa r1 trên p(θf), để thu được mặt nạ M. Mặt nạ M mang thông tin về các trọng số ít quan trọng nhất khi p(θ) được tiếp xúc với tác vụ ASR hạ nguồn trên tập dữ liệu L. Chính xác những trọng số được chỉ định bởi mặt nạ M được làm bằng không từ p(θ), dẫn đến mô hình p(θ').

3.2.3. Cắt tỉa Phụ thuộc Tác vụ Liên miền (CD-TAW)
Trong khi TAW tập trung vào việc xác định và làm bằng không các trọng số có tầm quan trọng ít nhất cụ thể cho tác vụ ASR hạ nguồn trên tập dữ liệu L, rõ ràng rằng phương pháp như vậy đòi hỏi fine-tuning hai lần trên tập dữ liệu L (một lần để thu được mặt nạ và lần thứ hai để fine-tune mô hình đã pre-train mang r1 phần trăm trọng số đã làm bằng không). Để giảm thiểu vấn đề tốn kém tính toán này, chúng tôi đề xuất một phương pháp trong đó UMP được thực hiện ở tỷ lệ cắt tỉa r1 trên f(ϕ), để thu được mặt nạ M. Tương tự như TAW, chính xác những trọng số được chỉ định bởi mặt nạ M được làm bằng không từ p(θ), dẫn đến mô hình p(θ'). Ưu điểm của việc sử dụng f(ϕ) để thu được mặt nạ M là J là một tập dữ liệu tài nguyên tương đối cao (mặc dù OOD) so với L. Điều này dẫn đến mặt nạ fine-tuning phù hợp hơn với tác vụ ASR hạ nguồn, vì f(ϕ) đã thấy nhiều dữ liệu liên quan đến "tác vụ" hơn. Lý do đằng sau việc đề cập rằng CD-TAW chỉ yêu cầu một vòng fine-tuning là khi f(ϕ) có sẵn trực tuyến, nó tiết kiệm fine-tuning rõ ràng trên tác vụ ASR hạ nguồn để thu được một mặt nạ nhận biết tác vụ.

3.2.4. Thuật toán
Alg. 1 cho thấy thuật toán của PADA nơi chúng tôi mô tả PADA với các ký hiệu từ các phần phụ trước đó.

Chúng tôi cố định tỷ lệ cắt tỉa ban đầu r1. Sau đó chúng tôi chọn tần suất cắt tỉa Pfreq từ 3 biến thể (Một lần / Lặp / Lặp Động). Chúng tôi cũng cố định tổng số cập nhật fine-tuning thành N.

Khi PADA Lặp được sử dụng, tần suất ri tương ứng với r1 = r2 = r2 = ... = rk. Tuy nhiên, khi PADA Lặp Động được chọn, r1 > r2 > r3 > ... > rk. PADA Lặp Động có lợi thế cơ bản trong đó ít trọng số hơn được làm bằng không trong các lần lặp huấn luyện tương lai nơi mô hình đã "được huấn luyện trên miền đích" và cần "ít không gian hơn" để thích ứng. Chính xác, mỗi chiến lược cắt tỉa được đề cập trong các phần 3.2.1, 3.2.2, 3.2.3 chỉ khác nhau ở bước 1 của thuật toán PADA. Tuy nhiên, đáng đề cập rằng bước 1 của PADA là bước quan trọng nhất, tạo ra tất cả sự khác biệt về mặt hiệu suất.

4. THIẾT LẬP THÍ NGHIỆM

4.1. Tập dữ liệu và Mô hình đã Pre-train
Các mô hình đã pre-train mà chúng tôi chọn cho PADA là:
• wav2vec-2.0 LV-60k: Một mô hình LARGE [6] được pre-train trên 60k giờ dữ liệu âm thanh Libri-Light.
• wav2vec-2.0 LS-960: Một mô hình BASE [6] được pre-train trên 960 giờ dữ liệu LibriSpeech.
• XLSR-53: Một mô hình LARGE được pre-train trên 56k giờ dữ liệu từ 53 ngôn ngữ khác nhau [33]. Các tập dữ liệu được sử dụng bao gồm Multilingual LibriSpeech (MLS), CommonVoice (CV), và Babel.

Các tập dữ liệu miền đích mà chúng tôi chọn cho PADA là:
• Dữ liệu Switchboard: Đây là một kho ngữ liệu của các cuộc hội thoại tiếng nói điện thoại [34], một miền hoàn toàn khác với dữ liệu Libri-Light được tạo thành từ tiếng nói đọc từ sách nói [35]. Chúng tôi chọn hai tập con của dữ liệu Switchboard cho các thí nghiệm của chúng tôi, một tập 30 giờ và một tập 2 giờ, đại diện cho các môi trường tài nguyên thấp và tài nguyên cực thấp của thích ứng miền. Chúng tôi báo cáo kết quả tỷ lệ lỗi từ (WER) trên tập dev Switchboard.
• Dữ liệu Thách thức Hindi: Đây là một kho ngữ liệu của dữ liệu tiếng nói đọc tiếng Hindi được phát hành như một phần của Thách thức ASR Hindi, có 50 giờ dữ liệu tiếng nói được lấy từ các miền đa dạng như chính trị, thể thao, giải trí, v.v. Chúng tôi chọn một tập con 7 giờ của dữ liệu này cho mục đích thích ứng miền và báo cáo kết quả tỷ lệ lỗi ký tự (CER) trên tập đánh giá được phát hành như một phần của thách thức.

4.2. Cấu hình Fine-tuning
Phương pháp baseline được chọn để so sánh với PADA là phương pháp mà chúng tôi trực tiếp fine-tune mô hình đã pre-train trên tập dữ liệu miền đích L. Phương pháp này được gọi là Fine-tuning Trực tiếp (DFT), baseline trong Bảng 1.

Chúng tôi thêm một lớp tuyến tính cụ thể tác vụ lên trên mô hình và fine-tune cùng nhau với mất mát CTC. Vì việc làm bằng không trọng số được liên quan trong PADA, chúng tôi fine-tune các trọng số trong mỗi lần lặp trên cả DFT và PADA mà không đóng băng các lớp hoặc cập nhật được liên quan. Các giá trị N và n được sử dụng trong Alg.1 được đề cập trong Bảng 1.

Thí nghiệm rộng rãi trên dữ liệu Switchboard 30h, như được mô tả trong Hình 2, giúp chúng tôi kết luận với các thiết lập tốt nhất để thực hiện, với các tần suất cắt tỉa khác nhau. Các mô hình LARGE sử dụng r1 = 40%, r1 = r2 = r3 = 30%, r1 = 40%; r2 = 20%; r3 = 10% trong khi các mô hình BASE sử dụng r1 = 30%, r1 = r2 = r3 = 30% và r1 = 30%; r2 = 25%; r3 = 20%; r4 = 10% cho các tần suất cắt tỉa Một lần, Lặp và Lặp Động tương ứng. Các tham số còn lại tuân theo các cấu hình tiêu chuẩn trên fairseq [32] từ các công trình của [6, 33] và được cung cấp trên GitHub.

5. KẾT QUẢ
Như rõ ràng từ Bảng 1, CD-TAW được thực hiện với wav2vec-2.0 LV-60k và mặt nạ được lấy từ fine-tuning LibriSpeech 100hr đạt được cải thiện WER tương đối 20.6% trên fine-tuning Switchboard 2h và cải thiện CER tương đối 19.8% trên fine-tuning dữ liệu Hindi 7h.

6. PHÂN TÍCH KẾT QUẢ

6.1. Quan sát chính
Trong phần này chúng tôi cố gắng mở rộng và thảo luận về một số quan sát chính của chúng tôi từ kết quả trong Bảng 1. Chúng như sau:

• CD-TAW hầu như luôn vượt trội hơn TAW. Điều này tương ứng với thực tế rằng việc "nhận biết tác vụ" nhiều hơn hiệu quả hơn trong khi làm cho các tham số tự do thích ứng với miền mới hạ nguồn hơn là "nhận biết miền".

• Cắt tỉa Lặp Động trong hầu hết các trường hợp vượt trội hơn các phương pháp tần suất cắt tỉa cố định khác. Điều này tái khẳng định giả thuyết của chúng tôi rằng, đối với thích ứng miền, việc giảm tỷ lệ cắt tỉa lặp đi lặp lại qua các lần lặp fine-tuning hoạt động tốt vì mô hình được thích ứng nhiều hơn với miền mới theo thời gian.

• CD-TAW có lợi với các tập dữ liệu OOD được gán nhãn lớn hơn. Chúng tôi dựa kết luận này từ Bảng 1 nơi CD-TAW trên Switchboard 2h có lợi nhiều hơn khi mặt nạ ban đầu M được lấy từ mô hình được fine-tune trên 960h LibriSpeech hơn 100h. Có thể dường như không công bằng khi so sánh các mặt nạ đến từ các mô hình được fine-tune trên vài giờ dữ liệu với những cái được fine-tune trên hàng trăm giờ dữ liệu. Tuy nhiên, điểm mà chúng tôi cố gắng nhấn mạnh là, việc sử dụng các mô hình có sẵn như vậy được fine-tune trên lượng lớn dữ liệu OOD, mang lại nhận biết tác vụ tốt hơn và cũng tránh được nhu cầu fine-tune các mô hình nhiều lần như trong trường hợp của TAW.

• Ngoài thích ứng miền, PADA cũng giúp trong thích ứng liên ngôn ngữ. Điều này rất rõ ràng từ các thí nghiệm của chúng tôi trên dữ liệu được gán nhãn Hindi 7h. Sử dụng CD-TAW thay vì TAG để fine-tune trên tập dữ liệu Hindi tài nguyên thấp của chúng tôi nơi mặt nạ được lấy từ một mô hình được fine-tune LibriSpeech, cho chúng tôi một cải thiện tuyệt đối 5.5% CER.

• Giám sát ngôn ngữ tác động đến hiệu suất CD-TAW. Khi fine-tune mô hình XLSR-53 trên dữ liệu Hindi 7h, chúng tôi nhận thấy rằng CD-TAW hoạt động kém hơn TAW vì lượng dữ liệu Hindi trong tập dữ liệu OOD (CV và Babel) là tối thiểu. Điều này cũng phù hợp với các phát hiện từ [16].

6.2. So sánh Mặt nạ Cắt tỉa theo Lớp
Tiếp theo, chúng tôi cố gắng tìm sự tương đồng giữa một mặt nạ cung cấp cho chúng tôi mạng con ban đầu tốt nhất để fine-tune mạng của chúng tôi trên Switchboard sử dụng PADA, và tất cả các mặt nạ khác từ các thí nghiệm khác của chúng tôi. Như rõ ràng từ Bảng 1, CD-TAW đề xuất của chúng tôi cung cấp mặt nạ mạng con ban đầu tốt nhất khi mặt nạ được thu từ một mô hình hội tụ được fine-tune trên 960hrs LibriSpeech. Để so sánh sự tương đồng giữa các mặt nạ, chúng tôi sử dụng Intersection Over Union (IOU) và Mutual Mask Agreement (MMA) làm các thước đo tương đồng. IOU để định lượng các mặt nạ mạng con, được định nghĩa trong [14] như sau:

IOU_{m_a, m_b} = |{(m_a = 1) ∩ (m_b = 1)}| / |{(m_a = 1) ∪ (m_b = 1)}| (1)

nơi m_a và m_b là hai mặt nạ chúng tôi muốn so sánh.

Chúng tôi thấy rằng điểm IOU không phản ánh hoàn toàn sự tương đồng giữa các mặt nạ và định nghĩa MMA như sau:

Agg1_{m_a, m_b} = |{(m_a = 1) ∩ (m_b = 1)}|
Agg0_{m_a, m_b} = |{(m_a = 0) ∩ (m_b = 0)}|
MMA_{m_a, m_b} = (Agg1 + Agg0) / N (2)

nơi N là tổng số trọng số trong m_a hoặc m_b.

MMA cung cấp một so sánh tốt hơn giữa các mặt nạ so với IOU bởi vì, trong khi IOU chỉ tập trung vào các vùng không được che, MMA đo sự tương đồng giữa các mặt nạ trong cả vùng được che và không được che. Ví dụ, gọi m_a = [1, 0, 1, 0] và gọi m_b = [1, 1, 0, 0]. Trong trường hợp này mặc dù hai mặt nạ tương tự ở vị trí đầu tiên và cuối cùng, điểm IOU ra là 0.33, trong khi MMA cho điểm mong muốn là 0.5.

Hình 3 mô tả điểm MMA và IOU theo lớp giữa mặt nạ mạng con tốt nhất của chúng tôi và các thí nghiệm từ các mặt nạ khác. Như rõ ràng, cả IOU và MMA đều giảm mạnh về phía các lớp cuối, cũng học thông tin cụ thể tác vụ cao nhất [12] (trong trường hợp của chúng tôi, tác vụ ASR thông qua fine-tuning CTC). Một cách khác, mô hình hoạt động tốt nhất của chúng tôi, CD-TAW, tái khẳng định giả thuyết rằng bất kể miền, càng "nhận biết tác vụ" thì mặt nạ mạng con ban đầu càng tốt. Cuối cùng, mặc dù CD-TAW từ một mô hình được fine-tune trên 100 giờ hoạt động kém hơn so với đối tác 960hrs của nó, nó cho thấy các giá trị IOU và MMA cao nhất trong tất cả các mặt nạ, điều này một lần nữa khẳng định rằng các mặt nạ tốt hơn có thể được thu từ "nhận biết tác vụ" nhiều hơn.

7. KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI
Trong bài báo này, chúng tôi đề xuất PADA, một mô hình mới cho thích ứng miền ASR tài nguyên thấp. Các mô hình được pre-train với SSL trên lượng lớn dữ liệu OOD không gán nhãn cho thấy những cải thiện đáng kể khi được fine-tune trên ASR sử dụng khung PADA. Như một phần của công việc tương lai, chúng tôi muốn khám phá xem cắt tỉa có cấu trúc và thích ứng miền SSL không giám sát có thể giúp tăng hiệu suất trong mô hình học tập này hay không.

8. LỜI CẢM ƠN
Một phần của công trình này được tài trợ bởi dự án "Bhashini: Nhiệm vụ Dịch thuật Ngôn ngữ Quốc gia" của Bộ Điện tử và Công nghệ Thông tin (MeitY), Chính phủ Ấn Độ.

9. TÀI LIỆU THAM KHẢO
[1] Santosh K Gaikwad, Bharti W Gawali, và Pravin Yannawar, "A review on speech recognition technique," International Journal of Computer Applications, vol. 10, no. 3, pp. 16–24, 2010.

[2] Hermann Ney, "Speech translation: Coupling of recognition and translation," trong IEEE ICASSP 1999. IEEE, 1999, vol. 1, pp. 517–520.

[3] George Saon, Gakuto Kurata, Tom Sercu, Kartik Audhkhasi, Samuel Thomas, Dimitrios Dimitriadis, Xiaodong Cui, Bhuvana Ramabhadran, Michael Picheny, Lynn-Li Lim, et al., "English conversational telephone speech recognition by humans and machines," arXiv preprint arXiv:1703.02136, 2017.

[4] Hemant Yadav, Sreyan Ghosh, Yi Yu, và Rajiv Ratn Shah, "End-to-end named entity recognition from english speech," arXiv preprint arXiv:2005.11184, 2020.

[5] Amodei et al., "Deep speech 2 : End-to-end speech recognition in english and mandarin," trong ICML 2016, pp. 173–182.

[6] Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, và Michael Auli, "wav2vec 2.0: A framework for self-supervised learning of speech representations," NeurIPS 2020, vol. 33, pp. 12449–12460, 2020.

[7] Shu wen Yang, Po-Han Chi, Yung-Sung Chuang, Cheng-I Jeff Lai, Kushal Lakhotia, Yist Y. Lin, Andy T. Liu, Jiatong Shi, Xuankai Chang, Guan-Ting Lin, Tzu-Hsien Huang, Wei-Cheng Tseng, Ko tik Lee, Da-Rong Liu, Zili Huang, Shuyan Dong, Shang-Wen Li, Shinji Watanabe, Abdelrahman Mohamed, và Hung yi Lee, "SUPERB: Speech Processing Universal PERformance Benchmark," trong Interspeech 2021, 2021, pp. 1194–1198.

[8] Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, và Abdelrahman Mohamed, "Hubert: Self-supervised speech representation learning by masked prediction of hidden units," IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 29, pp. 3451–3460, 2021.

[9] Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, et al., "Wavlm: Large-scale self-supervised pre-training for full stack speech processing," arXiv preprint arXiv:2110.13900, 2021.

[10] Andy T Liu, Shu-wen Yang, Po-Han Chi, Po-chun Hsu, và Hung-yi Lee, "Mockingjay: Unsupervised speech representation learning with deep bidirectional transformer encoders," trong IEEE ICASSP 2020, pp. 6419–6423.

[11] Wei-Ning Hsu, Anuroop Sriram, Alexei Baevski, Tatiana Likhomanenko, Qiantong Xu, Vineel Pratap, Jacob Kahn, Ann Lee, Ronan Collobert, Gabriel Synnaeve, và Michael Auli, "Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised Pre-Training," trong Interspeech 2021, 2021, pp. 721–725.

[12] Ankita Pasad, Ju-Chieh Chou, và Karen Livescu, "Layer-wise analysis of a self-supervised speech representation model," trong 2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU). IEEE, 2021, pp. 914–921.

[13] Awni Hannun, "The history of speech recognition to the year 2030," arXiv preprint arXiv:2108.00084, 2021.

[14] Cheng-I Jeff Lai, Yang Zhang, Alexander H. Liu, Shiyu Chang, Yi-Lun Liao, Yung-Sung Chuang, Kaizhi Qian, Sameer Khurana, David Cox, và James Glass, "Parp: Prune, adjust and re-prune for self-supervised speech recognition," trong NeurIPS 2021.

[15] Jonathan Frankle và Michael Carbin, "The lottery ticket hypothesis: Finding sparse, trainable neural networks," trong ICLR 2019.

[16] Yizhou Lu, Mingkun Huang, Xinghua Qu, Pengfei Wei, và Zejun Ma, "Language adaptive cross-lingual speech representation learning with sparse sharing sub-networks," arXiv preprint arXiv:2203.04583, 2022.

[17] Aaron van den Oord, Yazhe Li, và Oriol Vinyals, "Representation learning with contrastive predictive coding," arXiv preprint arXiv:1807.03748, 2018.

[18] Andy T Liu, Shang-Wen Li, và Hung-yi Lee, "Tera: Self-supervised learning of transformer encoder representation for speech," IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 29, pp. 2351–2366, 2021.

[19] Trevor Gale, Erich Elsen, và Sara Hooker, "The state of sparsity in deep neural networks," arXiv preprint arXiv:1902.09574, 2019.

[20] Song Han, Jeff Pool, John Tran, và William Dally, "Learning both weights and connections for efficient neural network," NeurIPS 2015, vol. 28, 2015.

[21] Suyog Gupta Michael H. Zhu, "To prune, or not to prune: Exploring the efficacy of pruning for model compression," trong ICLR 2018.

[22] Shuhao Gu, Yang Feng, và Wanying Xie, "Pruning-then-expanding model for domain adaptation of neural machine translation," trong NAACL 2021.

[23] Dong Yu, Kaisheng Yao, Hang Su, Gang Li, và Frank Seide, "Kl-divergence regularized deep neural network adaptation for improved large vocabulary speech recognition," trong IEEE ICASSP 2013, pp. 7893–7897.

[24] Hank Liao, "Speaker adaptation of context dependent deep neural networks," trong IEEE ICASSP 2013, pp. 7947–7951.

[25] Zhong Meng, Jinyu Li, Yifan Gong, và Biing-Hwang Juang, "Adversarial teacher-student learning for unsupervised domain adaptation," trong IEEE ICASSP 2018, pp. 5949–5953.

[26] Vimal Manohar, Pegah Ghahremani, Daniel Povey, và Sanjeev Khudanpur, "A teacher-student learning approach for unsupervised domain adaptation of sequence-trained asr models," trong IEEE SLT Workshop 2018, pp. 250–257.

[27] Yusuke Shinohara, "Adversarial multi-task learning of deep neural networks for robust speech recognition.," trong Interspeech 2016, pp. 2369–2372.

[28] Zhong Meng, Jinyu Li, Zhuo Chen, Yang Zhao, Vadim Mazalov, Yifan Gong, và Biing-Hwang Juang, "Speaker-invariant training via adversarial learning," trong IEEE ICASSP 2018, pp. 5969–5973.

[29] CS Anoop, AP Prathosh, và AG Ramakrishnan, "Unsupervised domain adaptation schemes for building asr in low-resource languages," trong IEEE ASRU Workshop 2021.

[30] Dongseong Hwang, Ananya Misra, Zhouyuan Huo, Nikhil Siddhartha, Shefali Garg, David Qiu, Khe Chai Sim, Trevor Strohman, Françoise Beaufays, và Yanzhang He, "Large-scale asr domain adaptation using self-and semi-supervised learning," arXiv preprint arXiv:2110.00165, 2021.

[31] Suchin Gururangan, Ana Marašović, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, và Noah A. Smith, "Don't stop pretraining: Adapt language models to domains and tasks," trong ACL 2020, pp. 8342–8360.

[32] Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, và Michael Auli, "fairseq: A fast, extensible toolkit for sequence modeling," trong NAACL-HLT 2019: Demonstrations.

[33] Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, và Michael Auli, "Xls-r: Self-supervised cross-lingual speech representation learning at scale," arXiv, vol. abs/2111.09296, 2021.

[34] John J Godfrey, Edward C Holliman, và Jane McDaniel, "Switchboard: Telephone speech corpus for research and development," trong IEEE ICASSP 1992, vol. 1, pp. 517–520.

[35] Jacob Kahn, Morgane Riviere, Weiyi Zheng, Evgeny Kharitonov, Qiantong Xu, Pierre-Emmanuel Mazaré, Julien Karadayi, Vitaliy Liptchinsky, Ronan Collobert, Christian Fuegen, et al., "Libri-light: A benchmark for asr with limited or no supervision," trong IEEE ICASSP 2020, pp. 7669–7673.

# 2309.14157.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/pruning/2309.14157.pdf
# Kích thước file: 1288692 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 1
LAPP: Cắt Tỉa Tiến Bộ Thích Ứng Theo Lớp để
Nén CNN từ Đầu
Pucheng Zhai, Kailing Guo∗,Thành viên, IEEE, Fang Liu, Thành viên, IEEE,
Xiaofen Xing, Thành viên, IEEE, Xiangmin Xu, Thành viên Cao cấp, IEEE,
Tóm tắt —Cắt tỉa có cấu trúc là một phương pháp nén mạng nơ-
ron tích chập (CNN) thường được sử dụng. Thiết lập tỷ lệ cắt tỉa
là một vấn đề cơ bản trong cắt tỉa có cấu trúc. Hầu hết các công
trình hiện tại đều đưa ra quá nhiều tham số học được bổ sung để
gán các tỷ lệ cắt tỉa khác nhau cho các lớp khác nhau trong CNN
hoặc không thể kiểm soát tỷ lệ nén một cách rõ ràng. Vì các khối
mạng quá hẹp sẽ cản trở luồng thông tin cho việc huấn luyện, việc
thiết lập tỷ lệ cắt tỉa tự động không thể khám phá tỷ lệ cắt tỉa cao
cho một lớp cụ thể. Để khắc phục những hạn chế này, chúng tôi
đề xuất một khung mới có tên là Cắt Tỉa Tiến Bộ Thích Ứng Theo
Lớp (LAPP), nó dần dần nén mạng trong quá trình huấn luyện ban
đầu của một vài epoch từ đầu. Đặc biệt, LAPP thiết kế một chiến
lược cắt tỉa hiệu quả và hiệu suất cao, đưa ra một ngưỡng học được
cho mỗi lớp và ràng buộc FLOPs cho mạng. Được hướng dẫn bởi
cả tổn thất tác vụ và ràng buộc FLOPs, các ngưỡng học được được
cập nhật động và dần dần để thích ứng với những thay đổi của điểm
số quan trọng trong quá trình huấn luyện. Do đó chiến lược cắt tỉa
có thể dần dần cắt tỉa mạng và tự động xác định tỷ lệ cắt tỉa phù
hợp cho mỗi lớp. Hơn nữa, để duy trì sức mạnh biểu đạt của lớp
đã được cắt tỉa, trước khi bắt đầu huấn luyện, chúng tôi đưa ra một
đường vòng nhẹ bổ sung cho mỗi lớp tích chập cần được cắt tỉa,
chỉ thêm tương đối ít gánh nặng bổ sung. Phương pháp của chúng
tôi thể hiện hiệu suất vượt trội so với các phương pháp nén trước
đây trên nhiều tập dữ liệu và kiến trúc backbone khác nhau. Ví dụ,
trên CIFAR-10, phương pháp của chúng tôi nén ResNet-20 xuống
40,3% mà không làm giảm độ chính xác. 55,6% FLOPs của ResNet-
18 được giảm với độ chính xác top-1 tăng 0,21% và độ chính xác
top-5 tăng 0,40% trên ImageNet.
Từ khóa chỉ mục —Cắt tỉa tiến bộ, Ngưỡng học được,
Ràng buộc FLOPs, Đường vòng.
I. GIỚI THIỆU

TRONG những năm gần đây, các mạng nơ-ron tích chập (CNN) đã
đạt được những thành tựu đáng chú ý trong nhiều ứng dụng thị
giác máy tính như phân loại [1], [2], phát hiện đối tượng [3], [4],
nhận dạng khuôn mặt [5], [6], nhận dạng hành động [7], và phân
đoạn ngữ nghĩa [8]. Tuy nhiên, trong khi hiệu suất của các mô hình
CNN tiếp tục được cải thiện, các CNN trở nên sâu hơn và rộng
hơn, dẫn đến sự gia tăng bùng nổ về tham số và FLOPs. Do đó,
các CNN hiện tại đòi hỏi chi phí lưu trữ và tính toán rất cao, điều
này khiến việc triển khai CNN trên các thiết bị nhỏ với tài nguyên
hạn chế trở nên khó khăn. Để giải quyết vấn đề này, các kỹ thuật

Pucheng Zhai, và Xiaofen Xing đang ở Đại học Công nghệ Nam Trung
Quốc, Quảng Châu 510640, Trung Quốc (email:pucheng zhai@163.com; xfx-
ing@scut.edu.cn). Kailing Guo và Xiangmin Xu đang ở Đại học Công nghệ Nam
Trung Quốc, Quảng Châu 510640, Trung Quốc, và ở Phòng thí nghiệm Pazhou,
Quảng Châu 510330, Trung Quốc (email:guokl@scut.edu.cn; xmxu@scut.edu.cn).
Fang Liu đang ở Đại học Tài chính Quảng Đông, Quảng Châu 510521, Trung
Quốc (e-mail: 47-032@gduf.edu.cn).
∗Tác giả liên hệ.

nén CNN đã thu hút ngày càng nhiều sự chú ý. Các kỹ thuật nén
CNN phổ biến bao gồm cắt tỉa [9]–[11], phân tích tensor hạng
thấp [12]–[14], chưng cất kiến thức [15], [16], lượng tử hóa bit
thấp [17]–[19], và thiết kế kiến trúc compact [20]–[22]. Trong bài
báo này, chúng tôi tập trung vào cắt tỉa là một điểm nóng nghiên
cứu.

Cắt tỉa có thể được chia thành cắt tỉa không có cấu trúc và có
cấu trúc. Cắt tỉa không có cấu trúc trực tiếp loại bỏ các phần tử
trọng số không quan trọng trong một bộ lọc một cách độc lập bằng
một số thước đo tầm quan trọng [23], [24], dẫn đến tính thưa thớt
không đều. Việc cấu trúc không đều khó có thể tận dụng phần
mềm và phần cứng hiện có để có được tốc độ thực tế. Ngược lại,
cắt tỉa có cấu trúc trực tiếp loại bỏ toàn bộ các bộ lọc (hoặc kênh,
lớp, khối, v.v.) không quan trọng dựa trên các thước đo tầm quan
trọng khác nhau [25], [26], và đạt được tính thưa thớt có cấu trúc.
Do đó, cắt tỉa có cấu trúc, có khả năng đạt được tăng tốc thực tế
dựa trên phần mềm và phần cứng hiện có, đã phát triển nhanh
chóng trong những năm gần đây. Mặc dù các phương pháp cắt
tỉa có cấu trúc hiện tại, đặc biệt là các phương pháp cắt tỉa bộ
lọc và cắt tỉa kênh, đã đạt được kết quả đầy cảm hứng, vẫn tồn
tại hai vấn đề.

Thứ nhất, thiết lập tỷ lệ cắt tỉa là một vấn đề cơ bản. Sự dư
thừa của các lớp tích chập khác nhau là khác nhau, nhưng nhiều
phương pháp cắt tỉa [27]–[29] bỏ qua điều này và đặt cùng tỷ lệ
cắt tỉa cho tất cả các lớp, điều này có thể không tạo ra cấu trúc cắt
tỉa phù hợp. Để gán các tỷ lệ cắt tỉa khác nhau cho các lớp khác
nhau, một số công trình [11], [30] đặt một ngưỡng thước đo toàn
cục cố định, và phân biệt các bộ lọc quan trọng dựa trên các thước
đo tầm quan trọng tương ứng. Tuy nhiên, khi đưa ra một tỷ lệ nén
mục tiêu, ngưỡng cần được đặt bằng thử và sai. Hơn nữa, ngưỡng
toàn cục không phù hợp cho tất cả các lớp do sự phân bố khác
nhau của các giá trị thước đo trong mỗi lớp. Nhưng việc đặt thủ
công các ngưỡng khác nhau cho mỗi lớp đòi hỏi nhiều chi phí
lao động hơn và gây ra phân bố tỷ lệ cắt tỉa không tối ưu.

Bằng cách làm cho các ngưỡng thước đo của mỗi lớp có thể
học được, tái tham số hóa ngưỡng mềm (STR) [31] có thể tự động
đặt ngưỡng cho mỗi lớp và có được phân bố tỷ lệ cắt tỉa tốt hơn.
Việc học các ngưỡng trong STR được kiểm soát bởi tổn thất tác
vụ và chính quy hóa suy giảm trọng số. Tuy nhiên, bằng cách điều
chỉnh hệ số suy giảm trọng số, STR không thể kiểm soát rõ ràng
các ngưỡng để làm cho mạng đã cắt tỉa đạt chính xác một tỷ lệ nén
mục tiêu. Để kiểm soát rõ ràng mạng đã cắt tỉa để đáp ứng FLOPs
mục tiêu, một số nghiên cứu khác [32], [33] đưa ra các ràng buộc
FLOPs để hướng dẫn việc học cấu trúc đã cắt tỉa. Để đại diện cho
cấu trúc đã cắt tỉa, họ kết hợp một tham số học được bổ sung

arXiv:2309.14157v1  [cs.CV]  25 Sep 2023

--- TRANG 2 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 2

Hình 1. Tổng quan về phương pháp của chúng tôi. Ở đây, để ngắn gọn, các lớp chuẩn hóa theo batch (BN) và các lớp kích hoạt phi tuyến được bỏ qua. Trước khi huấn luyện từ đầu, mỗi lớp tích chập cần được cắt tỉa trong CNN cơ sở được thay thế bằng mô-đun thưa thớt với bù đắp đường vòng để xây dựng SBCNet. Sau đó SBCNet được huấn luyện và nén với các mặt nạ bằng chiến lược cắt tỉa được đề xuất. Sau khi đáp ứng tỷ lệ nén mục tiêu, các mặt nạ thưa thớt nhị phân được loại bỏ, SBCNet được chuyển đổi thành mạng nén, và sau đó mạng nén được huấn luyện cho các epoch còn lại.

cho mỗi kênh trong mỗi lớp để tạo thành một cổng có thể vi phân. Bằng cách sử dụng các ràng buộc FLOPs, họ có thể dần dần và tự động gán một tỷ lệ cắt tỉa khác nhau cho mỗi lớp trong quá trình huấn luyện dựa trên FLOPs mục tiêu. Tuy nhiên, họ đưa ra quá nhiều tham số học được bổ sung, điều này làm cho việc tối ưu hóa cấu trúc đã cắt tỉa trở nên khó khăn.

Thứ hai, thiết lập tỷ lệ cắt tỉa tự động không thể khám phá tỷ lệ cắt tỉa cao cho một lớp cụ thể. Hầu hết các phương pháp cắt tỉa [11], [32], [34], [35] cố gắng xác định các bộ lọc hoặc kênh ít quan trọng nhất có thể để giảm mất thông tin sau khi cắt tỉa, và sau đó đơn giản loại bỏ chúng. Tuy nhiên, khi tỷ lệ cắt tỉa ngày càng cao, các lớp đã cắt tỉa mất ngày càng nhiều thông tin và dung lượng. Đặc biệt, khi tỷ lệ cắt tỉa được đặt rất cao, những lớp được cắt tỉa quá hẹp này có sức mạnh biểu đạt hạn chế và có thể cản trở việc truyền đặc trưng và gradient, điều này có thể làm cho mạng đã cắt tỉa khó khôi phục hiệu suất ngay cả sau một thời gian dài huấn luyện hoặc tinh chỉnh.

Để giải quyết các vấn đề trên, trong bài báo này, chúng tôi đề xuất một khung Cắt Tỉa Tiến Bộ Thích Ứng Theo Lớp (LAPP) mới, bao gồm thiết kế mô-đun và chiến lược cắt tỉa. Tổng quan về phương pháp của chúng tôi được thể hiện trong Hình 1. Để giải quyết vấn đề đầu tiên nêu trên, tức là vấn đề thiết lập tỷ lệ cắt tỉa, chiến lược cắt tỉa của chúng tôi lấy các ngưỡng thước đo làm tham số học được và đưa ra các ràng buộc FLOPs để kiểm soát việc cập nhật chúng. Cụ thể, chúng tôi sử dụng chuẩn ℓ1 làm thước đo tầm quan trọng bộ lọc. Chúng tôi đưa ra một ngưỡng học được cho mỗi lớp để phân biệt tầm quan trọng giữa các bộ lọc, điều này tránh được việc đưa ra quá nhiều tham số học được bổ sung. Trong quá trình huấn luyện, được hướng dẫn bởi cả tổn thất tác vụ và ràng buộc FLOPs, các ngưỡng học được được cập nhật động để thích ứng với những thay đổi của chuẩn bộ lọc. Theo kích thước tương đối giữa các ngưỡng và chuẩn bộ lọc, phương pháp của chúng tôi có thể dần dần tự động phân biệt các bộ lọc quan trọng và xác định tỷ lệ cắt tỉa phù hợp cho mỗi lớp trong mỗi lần lặp cho đến khi đạt được tỷ lệ nén mục tiêu, điều này tiết kiệm đáng kể chi phí thử nghiệm.

Để giải quyết vấn đề thứ hai nêu trên, trước khi bắt đầu huấn luyện, bằng cách đưa ra một đường vòng nhẹ bổ sung cho lớp tích chập (tức là đường thưa thớt) cần được cắt tỉa trong mạng cơ sở, chúng tôi thiết kế một mô-đun Thưa thớt với Bù đắp Đường vòng, được đặt tên là mô-đun SBC, và xây dựng SBCNet, như được thể hiện trong Hình 2. Sau đó chúng tôi chỉ dần dần cắt tỉa các đường thưa thớt và giữ các đường vòng trong suốt quá trình huấn luyện để bù đắp cho các đường thưa thớt. Do đó, ngay cả khi đường thưa thớt trở nên rất hẹp, mô-đun SBC cũng có thể có sức mạnh biểu đạt mạnh và đảm bảo việc truyền đặc trưng và gradient. Trong bài báo này, để làm cho đường vòng nhẹ có đủ sức mạnh biểu đạt, cuối cùng chúng tôi sử dụng khối được lấy cảm hứng từ MobileNetV2 [36] làm đường vòng. Cụ thể, khối chứa tuần tự ba lớp tích chập nhỏ: tích chập 1×1, tích chập theo chiều sâu, và tích chập 1×1.

Cuối cùng nhưng không kém phần quan trọng, chiến lược cắt tỉa của chúng tôi là một thuật toán cắt tỉa trong quá trình huấn luyện. Cụ thể, chiến lược cắt tỉa của chúng tôi chỉ chiếm một vài epoch trong giai đoạn đầu của huấn luyện để cắt tỉa mạng dần dần, và sau đó tiếp tục huấn luyện mạng đã cắt tỉa đáp ứng tỷ lệ nén mục tiêu cho các epoch còn lại. Do đó, chiến lược cắt tỉa của chúng tôi có thể giảm đáng kể gánh nặng huấn luyện trước của các phương pháp cắt tỉa sau huấn luyện [32], [37], [38] và tạo ra các mạng con hiệu quả với ít suy giảm độ chính xác hơn so với các phương pháp cắt tỉa tại khởi tạo [11].

Để chứng minh hiệu quả của phương pháp, chúng tôi thực hiện thí nghiệm trên hai tập dữ liệu phân loại ảnh phổ biến với một số cấu trúc mạng đại diện. So với các phương pháp tiên tiến, LAPP đạt được hiệu suất vượt trội. Ví dụ, chúng tôi đạt được giảm 59,7% FLOPs bằng cách loại bỏ 52,8% tham số mà không làm giảm độ chính xác trên ResNet-20 so với cơ sở. So với cơ sở, 55,6% FLOPs của ResNet-18 được giảm với độ chính xác top-1 tăng 0,21% và độ chính xác top-5 tăng 0,40% trên ImageNet.

--- TRANG 3 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 3

Những đóng góp chính của chúng tôi được tóm tắt như sau:
(a) Kết hợp các ngưỡng học được và ràng buộc FLOPs, chúng tôi thiết kế một chiến lược cắt tỉa hiệu quả và hiệu suất cao có thể cắt tỉa mạng dần dần trong quá trình huấn luyện từ đầu và xác định tỷ lệ cắt tỉa phù hợp tự động cho mỗi lớp.

(b) Bằng cách đưa ra một đường vòng bổ sung cho mỗi lớp tích chập, phương pháp của chúng tôi có thể bù đắp thông tin bị mất của lớp đã cắt tỉa và đảm bảo luồng thông tin của mạng hẹp đã cắt tỉa trong quá trình huấn luyện, để có thể khám phá tỷ lệ cắt tỉa cao cho một lớp cụ thể.

(c) Phương pháp của chúng tôi có thể được áp dụng cho các CNN khác nhau, như VGG [1], ResNet [2], GoogleNet [39], và DenseNet [40], và đạt được hiệu suất tiên tiến trên những mạng đó, điều này cho thấy tính hiệu quả của nó.

Phần còn lại của bài báo được tổ chức như sau. Trong Phần II, chúng tôi giới thiệu công trình liên quan. Trong Phần III, chúng tôi cung cấp mô tả chi tiết về phương pháp của chúng tôi. Sau đó trong Phần IV, chúng tôi thực hiện thí nghiệm trên hai tập dữ liệu phân loại ảnh phổ biến với các loại CNN khác nhau và so sánh kết quả với những của các phương pháp tiên tiến. Cuối cùng, chúng tôi kết luận trong Phần V.

II. CÔNG TRÌNH LIÊN QUAN

A. Cắt Tỉa để Nén Mạng

Quy trình Cắt Tỉa. Tùy thuộc vào thời điểm thực hiện cắt tỉa, hầu hết các phương pháp cắt tỉa có thể được chia thành ba loại [34]: 1) cắt tỉa sau huấn luyện, 2) cắt tỉa tại khởi tạo, 3) cắt tỉa trong quá trình huấn luyện. Các phương pháp cắt tỉa sau huấn luyện [9], [25], [32], [35], [37], [38], [41] thường áp dụng quy trình ba giai đoạn, cụ thể là huấn luyện trước dày đặc, cắt tỉa, và tinh chỉnh, để nén mạng. Do huấn luyện trước các mạng có quá nhiều tham số và tinh chỉnh các mạng đã cắt tỉa, các phương pháp cắt tỉa sau huấn luyện thường tạo ra các mạng con hiệu quả với độ chính xác hợp lý, nhưng dẫn đến gánh nặng huấn luyện khổng lồ. Khác với các phương pháp cắt tỉa sau huấn luyện, các phương pháp cắt tỉa tại khởi tạo [11], [42]–[44] là quy trình huấn luyện hai giai đoạn, cụ thể là cắt tỉa mạng được khởi tạo ngẫu nhiên và sau đó huấn luyện mạng đã cắt tỉa từ đầu, điều này tránh được đáng kể gánh nặng huấn luyện trước. Tuy nhiên, các phương pháp hiện tại vẫn không thỏa mãn vì các mạng đã cắt tỉa kết quả có thể khó huấn luyện [43] và dễ bị suy giảm độ chính xác đáng kể.

Các phương pháp cắt tỉa trong quá trình huấn luyện [34], [45], [46] nhằm kết hợp lợi ích của hai chiến lược trên. Các phương pháp cắt tỉa trong quá trình huấn luyện có thể được chia thành hai hướng [34]: các phương pháp dựa trên chính quy hóa [45], [30] và các phương pháp lựa chọn mạng con [34], [46]. Tương tự như các phương pháp cắt tỉa sau huấn luyện, các phương pháp dựa trên chính quy hóa cũng áp dụng quy trình ba giai đoạn, cụ thể là huấn luyện với chính quy hóa thưa thớt, cắt tỉa, và tinh chỉnh nhẹ. Các phương pháp dựa trên chính quy hóa dành ít thời gian hơn cho việc tinh chỉnh mạng đã cắt tỉa, nhưng quá trình huấn luyện dưới chính quy hóa thưa thớt vẫn gây ra gánh nặng tính toán đáng kể. Các phương pháp lựa chọn mạng con chọn cấu trúc mạng đã cắt tỉa thông qua một số thước đo tầm quan trọng khi thực hiện cắt tỉa, nhưng thường dựa vào một số kinh nghiệm hoặc giả định để thiết lập theo kinh nghiệm các điểm khởi đầu của cắt tỉa trong quá trình huấn luyện bình thường. Khác với các phương pháp lựa chọn mạng con trước đây, dựa trên các ngưỡng thước đo học được, việc cắt tỉa trong chiến lược cắt tỉa của chúng tôi được tự động bắt đầu trong quá trình huấn luyện. Khác với các phương pháp dựa trên chính quy hóa trước đây, chiến lược cắt tỉa của chúng tôi chỉ chiếm một vài epoch trong giai đoạn đầu của huấn luyện để cắt tỉa mạng dần dần, và sau đó giảm nhiều gánh nặng huấn luyện hơn bằng cách huấn luyện mạng đã cắt tỉa cho các epoch còn lại.

Thước đo Cắt Tỉa. Thước đo cắt tỉa được sử dụng để đo tầm quan trọng hoặc sự dư thừa của các bộ lọc (hoặc kênh). Tùy thuộc vào việc chúng có đưa ra tham số học được bổ sung hay không, thước đo cắt tỉa của một số phương pháp cắt tỉa có cấu trúc đại diện có thể được nhóm thô thành hai loại. Thước đo cắt tỉa không có tham số bổ sung có thể được chia thành hai loại con: thước đo độc lập với dữ liệu và thước đo phụ thuộc vào dữ liệu.

Một số công trình [9], [27], [28], [45], [47]–[49] trực tiếp sử dụng các tính chất vốn có của bộ lọc, như giá trị chuẩn ℓ1 hoặc ℓ2 của bộ lọc và mối quan hệ giữa các bộ lọc, làm thước đo cắt tỉa. Dựa trên giả định rằng các bộ lọc có chuẩn nhỏ hơn là không quan trọng hơn, cắt tỉa bộ lọc cho convnet hiệu quả (PFEC) [9] chọn và loại bỏ các bộ lọc có giá trị chuẩn ℓ1 nhỏ hơn. Cắt tỉa bộ lọc thông qua trung vị hình học (FPGM) [28] chỉ ra rằng giả định trên không phải lúc nào cũng đúng, và sau đó chuyển sang cắt tỉa các bộ lọc có thể thay thế nhất dựa trên trung vị hình học của bộ lọc trong mỗi lớp. Xem xét rằng các bộ lọc tương tự là dư thừa, khác với FPGM, cắt tỉa bộ lọc với học gradient thích ứng (FP-AGL) [49] áp dụng các vector hướng tâm được thiết kế lại lên bộ lọc để hội tụ các bộ lọc trong các cụm về cùng một điểm, và cuối cùng chỉ giữ một bộ lọc cho mỗi cụm. Một số công trình [30], [50] tận dụng các yếu tố tỷ lệ trong các lớp chuẩn hóa theo batch (BN) để đánh giá tầm quan trọng của các kênh. Cắt giảm mạng (NS) [30] đẩy các yếu tố tỷ lệ trong các lớp BN về zero bằng cách áp dụng chính quy hóa ℓ1 trong quá trình huấn luyện, và cắt tỉa các kênh có yếu tố tỷ lệ nhỏ sau khi huấn luyện. Các thước đo trên là độc lập với dữ liệu, vì vậy những công trình này đòi hỏi chi phí tính toán thấp để xác định các bộ lọc (hoặc kênh) đã cắt tỉa.

Ngoài ra, một số thước đo cắt tỉa đòi hỏi sử dụng dữ liệu đầu vào để chọn các bộ lọc (hoặc kênh) đã cắt tỉa. Bản đồ đặc trưng đầu ra là kết quả tích chập của bản đồ đặc trưng đầu vào và bộ lọc, vì vậy một số nghiên cứu [26], [29], [51] xác định các bộ lọc đã cắt tỉa bằng cách đánh giá tầm quan trọng hoặc sự dư thừa của bản đồ đặc trưng từ một tập dữ liệu đầu vào. Hạng cao (Hrank) [26] sử dụng hạng trung bình của bản đồ đặc trưng để đánh giá tầm quan trọng của bộ lọc. Khác với Hrank, cắt tỉa bộ lọc dựa trên độc lập kênh (CHIP) [51] tìm các bản đồ đặc trưng dư thừa và cắt tỉa các bộ lọc tương ứng bằng cách đo các mối tương quan giữa các bản đồ đặc trưng trong mỗi lớp. Xem xét rằng các bộ lọc được cập nhật bằng gradient từ hàm mất mát trong quá trình huấn luyện, một số nghiên cứu [35], [41] đếm thông tin gradient hoặc đạo hàm bậc hai cho mỗi bộ lọc (hoặc kênh) để đánh giá tầm quan trọng. Cắt tỉa kênh nhận biết phân biệt (DCP) [41] chọn các kênh quan trọng nhất bằng cách tính chuẩn Frobenius của gradient. Cắt tỉa có cấu trúc bậc hai (SOSP) [35] thiết kế hai thước đo cắt tỉa dựa trên độ nổi bật, sử dụng thông tin đạo hàm bậc nhất hoặc bậc hai, để xóa các bộ lọc không quan trọng.

Một số công trình [11], [32], [37], [38], [52] đưa ra

--- TRANG 4 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 4

các tham số học được bổ sung và tối ưu hóa những tham số này tận dụng các thuật toán học tăng cường hoặc các phương pháp dựa trên gradient, để tạo ra điểm số nổi bật hoặc quyết định nhị phân cho mỗi kênh (hoặc bộ lọc). Nén sâu với học tăng cường (DECORE) [38] gán một agent chỉ với một tham số cho mỗi kênh và học kênh nào cần được cắt tỉa dựa trên học tăng cường. Đối với mỗi mẫu đầu vào, bắn cùng nhau nối cùng nhau (FTWT) [52] sử dụng một đầu dự đoán mặt nạ nhị phân được huấn luyện tốt trong mỗi lớp để dự đoán động k bộ lọc được kích hoạt.

B. Kết hợp Cắt Tỉa và Các Kỹ thuật Khác để Nén Mạng

Cắt Tỉa và Phân tích Tensor Hạng Thấp. Phân tích tensor hạng thấp (LTD) [13] phân tích tensor trọng số hạng thấp của tích chập thành một chuỗi tensor chứa ít tham số và tính toán hơn nhiều. Vì cắt tỉa và LTD giảm sự dư thừa trong tham số từ các góc độ khác nhau, một số nỗ lực gần đây [53]–[55] kết hợp chúng lại với nhau để theo đuổi hiệu suất nén mạng tốt hơn. Li et al. [55] đề xuất gắn các ma trận tạo thưa thớt vào các tích chập bình thường và áp dụng các ràng buộc thưa thớt nhóm lên chúng, để móc nối cắt tỉa bộ lọc và phân tích (Hinge). Bằng cách đồng thời xử lý tính thưa thớt và hạng thấp trong trọng số, nén cộng tác (CC) [54] kết hợp cắt tỉa kênh và phân tích tensor để tăng tốc CNN.

Cắt Tỉa và Lượng tử hóa Bit Thấp. Lượng tử hóa bit thấp [17]–[19] có thể giảm chi phí tính toán và lưu trữ một cách hiệu quả bằng cách giảm số bit được sử dụng để biểu diễn trọng số mạng hoặc kích hoạt. Lượng tử hóa trực giao với cắt tỉa, vì vậy một số công trình [56]–[58] thực hiện chung chúng để đạt được tăng tốc mạng tốt hơn. Wang et al. [56] đề xuất tích hợp cắt tỉa có cấu trúc với lượng tử hóa độ chính xác bit hỗn hợp thông qua một sơ đồ tối ưu hóa dựa trên gradient chung. Luồng rời rạc chỉ số nguyên (IODF) [58] thực hiện các phép biến đổi khả đảo hiệu quả bằng cách sử dụng số học chỉ số nguyên dựa trên lượng tử hóa 8-bit và đưa ra các cổng nhị phân học được để loại bỏ các bộ lọc dư thừa trong quá trình suy luận.

Cắt Tỉa và Chưng cất Kiến thức. Chưng cất kiến thức (KD) [15] chuyển giao kiến thức từ một mạng giáo viên lớn sang một mạng học sinh nhỏ. Gần đây, một số công trình khai thác KD để tăng cường khả năng học của các mạng đã cắt tỉa [59], [60] hoặc khai thác cắt tỉa để tăng cường chất lượng KD [61], [62]. Để bảo tồn hiệu suất của mô hình đã cắt tỉa, Zou et al. [60] đề xuất chưng cất mô hình đã cắt tỉa để phù hợp với mô hình được huấn luyện trước bằng cách sử dụng các hình ảnh bị suy giảm được tái tạo. Để tăng cường hiệu suất của KD, Park và No [62] đề xuất cắt tỉa mạng giáo viên trước để làm cho nó thân thiện với học sinh hơn và sau đó chưng cất nó cho học sinh.

Các công trình trên tiếp tục cho thấy rằng cắt tỉa và các kỹ thuật khác là bổ sung. Do đó, việc kết hợp chúng có thể cải thiện hiệu suất nén hơn nữa.

III. PHƯƠNG PHÁP ĐỀ XUẤT

Trong phần này, chúng tôi giới thiệu khung và quy trình nén của phương pháp đề xuất.

Hình 2. Các mô-đun SBC 3×3 trong SBCNet. Ở đây đường vòng là khối được lấy cảm hứng từ MobileNetV2 [36]. "DWConv" biểu thị một tích chập theo chiều sâu, và tất cả các lớp BN và lớp kích hoạt phi tuyến được bỏ qua.

A. Kiến thức nền tảng

Đối với lớp thứ l của một CNN, chúng tôi biểu thị bản đồ đặc trưng đầu vào là Xl∈Rcl−1×hl−1×wl−1, bản đồ đặc trưng đầu ra là Yl∈Rcl×hl×wl, và tensor trọng số của các bộ lọc là Wl∈Rcl×cl−1×kl×kl, trong đó cl−1 và cl tương ứng là số kênh đầu vào và bộ lọc (kênh đầu ra), và kl là kích thước hạt nhân của các bộ lọc. Đầu ra của lớp tích chập thứ l có thể được biểu diễn là:

Yl=Wl⊗Xl, (1)

trong đó ⊗ biểu thị phép toán tích chập.

Cắt Tỉa Có Cấu Trúc. Cả cắt tỉa bộ lọc và cắt tỉa kênh đều tìm kiếm một biểu diễn xấp xỉ compact Wl. Trong cắt tỉa bộ lọc, mỗi bộ lọc được coi là một đơn vị nén và hàm cắt tỉa được định nghĩa là:

Wl[i,:,:,:] =Wl[Klf[i],:,:,:] (2)

trong đó Wl∈Rnl×cl−1×kl×kl và Klf biểu thị một danh sách bao gồm các chỉ số của các bộ lọc được giữ lại trong Wl. Ở đây nl là số bộ lọc được giữ lại. Trong cắt tỉa kênh, mỗi kênh đầu vào được coi là một đơn vị nén và hàm cắt tỉa được định nghĩa là:

Wl[:, i,:,:] =Wl[:, Klc[i],:,:] (3)

trong đó Wl∈Rcl×nl−1×kl×kl và Klc biểu thị một danh sách bao gồm các chỉ số của các kênh đầu vào được giữ lại trong Wl. Ở đây nl−1 là số kênh đầu vào được giữ lại.

Trong bài báo này, chúng tôi giới thiệu phương pháp cắt tỉa của chúng tôi từ góc độ cắt tỉa bộ lọc, nhưng lưu ý rằng nó cũng phù hợp cho cắt tỉa kênh. Trong phần sau, để ngắn gọn, chúng tôi thay thế Wl[i,:,:,:] bằng Wl[i].

B. Thiết kế Mô-đun

Trước tiên chúng tôi thiết kế một mô-đun thưa thớt với bù đắp đường vòng, được đặt tên là mô-đun SBC, và sau đó thay thế mỗi lớp tích chập cần được cắt tỉa trong mạng cơ sở bằng mô-đun SBC để xây dựng SBCNet. Mô-đun SBC bao gồm một đường thưa thớt (tức là lớp tích chập gốc) và một đường vòng nhẹ, và đầu ra của mô-đun SBC là tổng của

--- TRANG 5 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 5

Hình 3. Quy trình của chiến lược cắt tỉa cho mô-đun SBC thứ l. Ở đây STE biểu thị ước lượng thẳng-qua. Đối với mô-đun SBC thứ l, trong quá trình lan truyền tiến, chuẩn ℓ1 được sử dụng để tính điểm số quan trọng Il của trọng số bộ lọc WlS trong đường thưa thớt, và sau đó sự khác biệt giữa điểm số quan trọng Il và ngưỡng học được δl được đưa vào hàm round (sigmoid (·)) để lấy mặt nạ nhị phân Ml. Đầu ra của đầu vào Xl qua lớp tích chập được nhân với mặt nạ Ml để lấy đầu ra YlS trong đường thưa thớt. Sau đó đầu ra YlS của đường thưa thớt và đầu ra YlB của đường vòng được cộng lại để lấy đầu ra cuối cùng Yl. Trong quá trình lan truyền ngược, ngưỡng học được δl và trọng số bộ lọc WlS và WlB được cập nhật bởi sự hướng dẫn từ gradient của tổn thất tổng thể. Lưu ý rằng để ổn định huấn luyện nén và không can thiệp vào việc học WlS, việc lan truyền gradient từ Gl đến WlS bị cắt đứt, và gradient từ Gl chỉ được sử dụng để hướng dẫn việc cập nhật ngưỡng δl.

đầu ra của lớp tích chập gốc và đường vòng nhẹ. Do đó, SBCNet thêm một vài gánh nặng bổ sung so với mạng cơ sở. Một ví dụ cho mô-đun SBC 3×3 được thể hiện trong Hình 2. Trong bài báo này, chúng tôi sử dụng khối được lấy cảm hứng từ MobileNetV2 [36] làm đường vòng để làm cho nó có đủ sức mạnh biểu đạt. Ngoài ra, cấu trúc của khối có thể được thu được bằng cách áp dụng LTD vào một tích chập thông thường [14], vì vậy việc sử dụng khối làm đường vòng cũng có thể làm cho mô-đun SBC khai thác tính bổ sung của cắt tỉa và LTD để cải thiện hiệu suất của phương pháp của chúng tôi hơn nữa. Đối với mô-đun SBC thứ l, đầu ra được biểu diễn là:

Yl=YlS+YlB=WlS⊗Xl+WlB3⊗(WlB2⊗(WlB1⊗Xl)),(4)

trong đó WlS∈Rcl×cl−1×kl×kl biểu thị tensor trọng số của đường thưa thớt, trong khi WlB1∈Rdl×cl−1×1×1, WlB2∈Rdl×1×kl×kl, và WlB3∈Rcl×dl×1×1 biểu thị các tensor trọng số của đường vòng nhẹ.

Đối với đường thưa thớt, WlS được khởi tạo ngẫu nhiên trước khi huấn luyện, và được làm thưa thớt bằng một mặt nạ bởi chiến lược cắt tỉa đề xuất trong quá trình huấn luyện cho đến khi đạt được tỷ lệ nén mục tiêu. Giải thích chi tiết về chiến lược cắt tỉa đề xuất được đưa ra trong tiểu mục sau.

Đối với đường vòng nhẹ, ba tích chập nhẹ được giữ trong suốt quá trình huấn luyện để bù đắp cho đường thưa thớt. Giả sử bước của các tích chập trong mô-đun thứ l là 1, cl và cl−1 bằng nhau, và tỷ lệ cắt tỉa được gán thích ứng bởi chiến lược cắt tỉa của chúng tôi trong đường thưa thớt là pl. Để ngắn gọn, chúng tôi bỏ qua chỉ số trên. Sau khi cắt tỉa, FLOPs của đường vòng là hw(2cd+dk2), và FLOPs của mô-đun SBC là hw(2cd+dk2+ (1−p)c2k2). Nói chung, k2≪c và d≤c, chúng ta có thể bỏ qua mục dk2. Do đó tỷ lệ FLOPs của chúng xấp xỉ 2/(2+((1−p)ck2)/d). Khi p là một giá trị nhỏ gần 0, đường thưa thớt đã cắt tỉa chiếm ưu thế trong mô-đun SBC, và đường vòng nhẹ chỉ mang lại tương đối ít phép tính. Khi p là một giá trị trung bình, đường vòng bù đắp thông tin và dung lượng bị mất của đường thưa thớt đã cắt tỉa với chi phí tính toán tương đối nhỏ. Khi p là một giá trị lớn gần 1, đường thưa thớt được cắt tỉa quá hẹp đến nỗi nó cản trở việc lan truyền tiến của đặc trưng và lan truyền ngược của gradient, điều này thường dẫn đến sự giảm mạnh hiệu suất mạng. Tuy nhiên, đường vòng giúp đảm bảo việc lan truyền đặc trưng và gradient trong quá trình huấn luyện để làm cho mạng hội tụ bình thường.

Trong trường hợp cực đoan, khi p là 1, toàn bộ đường thưa thớt có thể được loại bỏ một cách mượt mà trong quá trình cắt tỉa do đường vòng, điều này đạt được khoảng ck2/(2d)× tăng tốc, và đường vòng làm cho mô-đun vẫn duy trì sức mạnh biểu đạt tương đối mạnh. Tuy nhiên, điều này không có nghĩa là việc trực tiếp xây dựng một mạng compact sử dụng đường vòng thay vì mô-đun SBC trước khi bắt đầu huấn luyện sẽ hiệu quả hơn. Bởi vì như đã đề cập ở trên, một số mô-đun cần giữ lại một số kênh của đường thưa thớt để bù đắp cho các đường vòng nhẹ của chúng để duy trì đủ dung lượng. Sự hiện diện của đường thưa thớt có thể tăng tính đa dạng của đặc trưng. Ngoài ra, chúng có thể hoạt động như các đường tắt để tạo thuận lợi cho luồng thông tin, và cắt tỉa SBCNet dày đặc trong quá trình huấn luyện có thể giúp tìm kiếm một mạng con tốt hơn.

Hơn nữa, bằng cách điều chỉnh siêu tham số dl, tỷ lệ FLOPs của đường vòng so với FLOPs của mô-đun SBC đã cắt tỉa có thể được kiểm soát thô. Do đó, bằng cách đặt giá trị phù hợp cho dl, chúng ta có thể đạt được mục tiêu nén và làm cho đường vòng tạo ra sự bù đắp đủ cho đường thưa thớt để đạt được hiệu suất nén tốt hơn. Trong bài báo này, khi tỷ lệ nén toàn cục mục tiêu được đặt thành một giá trị lớn, dl được đặt theo kinh nghiệm trực tiếp thành cl; khi tỷ lệ nén toàn cục mục tiêu được đặt thành một giá trị rất nhỏ, dl được giảm xuống 0,5cl.

C. Chiến lược Cắt Tỉa

Cắt tỉa sau huấn luyện là một chiến lược cắt tỉa thường được sử dụng. Tuy nhiên, quy trình ba giai đoạn của nó, cụ thể là huấn luyện trước dày đặc, cắt tỉa, và tinh chỉnh, dẫn đến gần như gấp đôi

--- TRANG 6 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 6

thời gian huấn luyện. Do tính không hiệu quả của nó, một giải pháp trực quan là cắt tỉa tại khởi tạo. Mặc dù cắt tỉa tại khởi tạo làm cho huấn luyện hiệu quả hơn vì nó chỉ huấn luyện mạng đã cắt tỉa, các mạng đã cắt tỉa có thể khó huấn luyện và dễ bị suy giảm độ chính xác đáng kể. Do đó, cắt tỉa trong quá trình huấn luyện, có thể giảm tác động tiêu cực của cắt tỉa sau huấn luyện và cắt tỉa tại khởi tạo, có thể tìm ra sự cân bằng giữa hiệu quả huấn luyện và độ chính xác cuối cùng [34]. Vì vậy chiến lược cắt tỉa của chúng tôi cũng dần dần cắt tỉa các đường thưa thớt trong quá trình huấn luyện ban đầu của một vài epoch, và khai thác số lượng lớn epoch còn lại để huấn luyện mạng đã cắt tỉa để hội tụ nhằm cải thiện hiệu suất. Quy trình của chiến lược cắt tỉa cho mô-đun thứ l được thể hiện trong Hình 3.

Cụ thể, trong bài báo này, để đơn giản, chúng tôi sử dụng chuẩn ℓ1 làm thước đo tầm quan trọng bộ lọc. Do đó điểm số tầm quan trọng bộ lọc Il∈Rcl của đường thưa thớt được biểu diễn là:

Il= [∥WlS[1]∥1,∥WlS[2]∥1,···,∥WlS[cl]∥1]T, (5)

trong đó mỗi phần tử biểu diễn tầm quan trọng của bộ lọc tương ứng. Khác với PFEC [9] trực tiếp đặt thủ công tỷ lệ cắt tỉa cho mỗi lớp, chúng tôi sử dụng ngưỡng cắt tỉa để xác định tỷ lệ cắt tỉa cho mỗi lớp. Giả sử ngưỡng cho mô-đun thứ l là δl, thì mặt nạ cắt tỉa Ml∈Rcl được thu được theo Il:

Ml[i] = {
1, Ili≥δl,
0, Ili< δl,
(6)

trong đó Ili biểu thị phần tử thứ i của Il. Bằng cách tính tổng mặt nạ Ml, số bộ lọc được giữ lại có thể được thu được, cụ thể là nl, và tỷ lệ cắt tỉa của đường thưa thớt là pl= 1−nl/cl. Đầu ra của đường thưa thớt sau đó được tái công thức như sau:

YlS=Ml⊙(WlS⊗Xl), (7)

trong đó ⊙ là tích element-wise giữa vector cột bên trái và các chiều không gian của tensor ba chiều bên phải.

Vì phân bố tham số của các lớp khác nhau là khác nhau, việc đặt cùng ngưỡng cắt tỉa cho tất cả các lớp có thể không tối ưu. Tuy nhiên, việc đặt thủ công các ngưỡng khác nhau cho mỗi lớp đòi hỏi nhiều chi phí lao động và cũng có thể gây ra phân bố tỷ lệ cắt tỉa không tối ưu. Được lấy cảm hứng từ ý tưởng áp dụng ngưỡng học được vào cắt tỉa bộ lọc được đề xuất bởi Kusupati et al. [31], chúng tôi kết hợp thước đo chuẩn ℓ1 đơn giản với ngưỡng học được bằng cách đưa ra một tham số học được bổ sung cho mỗi đường thưa thớt của mạng.

Từ Phương trình (7), Ml trực tiếp tham gia vào tính toán tiến của mạng và có thể nhận gradient từ hàm mục tiêu trong quá trình lan truyền ngược. Tuy nhiên, theo Phương trình (6), ngưỡng δl là không khả vi. Do đó, chúng tôi thay đổi Ml thành mặt nạ cắt tỉa mềm Gl bằng cách đưa ra hàm sigmoid (·):

Gl=sigmoid (Il−δl) =1/(1 +e−(Il−δl)). (8)

Ở đây mỗi phần tử của Gl, tức là Gl[i], là liên tục và giá trị của nó nằm trong khoảng từ 0 đến 1. Theo các công trình [32], [52], chúng tôi tiếp tục làm tròn Gl[i] thành 0 hoặc 1, để tạo ra chính xác các mạng con trong quá trình huấn luyện, như sau:

Ml[i] =1≥0.5(Gl[i]),∀i∈[1, cl]. (9)

Khi giá trị của Gl[i] lớn hơn hoặc bằng 0,5, tức là khi điểm số tầm quan trọng bộ lọc tương ứng Ili lớn hơn hoặc bằng ngưỡng δl, giá trị của mặt nạ tương ứng Ml[i] là 1, nếu không, nó là 0. Tuy nhiên, hàm chỉ thị 1≥0.5(·) vẫn không khả vi. Để giải quyết vấn đề này, chúng tôi sử dụng ước lượng thẳng-qua (STE) [63] để tính gradient từ Ml đến Gl trong quá trình lan truyền ngược, làm cho việc cập nhật δl khả thi.

Thuật toán 1 Tổng quan về phương pháp LAPP.
Đầu vào: CNN với N lớp tích chập cần được cắt tỉa; tổng số epoch E; tập huấn luyện D; tổng FLOPs Ttotal của CNN; tỷ lệ nén mục tiêu C;
Đầu ra: CNN compact thỏa mãn tỷ lệ nén mục tiêu C và các giá trị trọng số tối ưu WS và WB;
1: Xây dựng SBCNet với WS và WB dựa trên Phương trình (4);
2: Đưa ra ngưỡng học được cho mỗi đường thưa thớt;
3: Thực thi epoch status ∈ {"prune", "train"};
4: epoch status được đặt là "prune";
5: for epoch t= 1,2, ..., E do
6: for một mini-batch (X, y) trong D do
7: if epoch status là "prune" then
8: for layer l= 1,2, ..., N do
9: Lấy Il bằng Phương trình (5);
10: Lấy Ml bằng Phương trình (8) và Phương trình (9);
11: Lấy Yl bằng Phương trình (7) và Phương trình (4);
12: end for
13: Tính Tkept và Ĉ;
14: if Ĉ≠C then
15: Cập nhật WS,WB và Δ với SGD;
16: else
17: Loại bỏ các mặt nạ và cắt tỉa, lấy WS;
18: Đặt epoch status là "train";
19: end if
20: else
21: Lấy Yl cho mỗi lớp l bằng Phương trình (13);
22: Cập nhật WS và WB với SGD;
23: end if
24: end for
25: end for
26: Trả về: CNN compact với trọng số WS và WB;

Để làm cho các bộ lọc có thể phân biệt rõ hơn, chúng tôi áp dụng chính quy hóa thưa thớt vào trọng số bộ lọc của các đường thưa thớt. Phù hợp với thước đo tầm quan trọng chuẩn ℓ1, chúng tôi sử dụng chính quy hóa ℓ1, và thu được bài toán tối ưu hóa mạng:

min(WS,WB,Δ) L(f(X;WS,WB,Δ), y) +λ∑(l=1 to N)∑(i=1 to cl)∥WlS[i]∥1,
(10)

trong đó L(·) biểu thị tổn thất cross-entropy, và WS={W1S, W2S,···, WNS} và WB={W1B, W2B,···, WNB} tham chiếu đến các tham số trong N mô-đun thưa thớt của SBCNet

--- TRANG 7 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 7

f(·;WS,WB,Δ). Ở đây X và y biểu diễn các mẫu đầu vào và nhãn tương ứng, Δ biểu diễn tập hợp tất cả các ngưỡng thước đo học được của các đường thưa thớt của SBCNet, λ là hệ số của mục chính quy hóa ℓ1, và mục chính quy hóa suy giảm trọng số được bỏ qua để ngắn gọn. Do đó, tính thưa thớt tổng thể cuối cùng của các đường thưa thớt của mạng được kiểm soát bởi hệ số của mục chính quy hóa ℓ1 và giá trị khởi tạo của các ngưỡng trong Δ. Tuy nhiên, việc điều chỉnh các siêu tham số này bằng thử và sai để đạt được tỷ lệ nén mục tiêu chắc chắn là tẻ nhạt và phức tạp.

Do đó, để kiểm soát rõ ràng tính thưa thớt của mạng, tức là làm cho mạng con cuối cùng đạt được FLOPs mục tiêu đã cho, chúng tôi đưa ra các ràng buộc FLOPs để kiểm soát việc cập nhật các ngưỡng trong Δ. Trước đây các ràng buộc FLOPs và ngưỡng thước đo thường được sử dụng riêng biệt, trong khi chúng tôi cố gắng kết hợp ngưỡng học được và ràng buộc FLOPs để tự động xác định tỷ lệ cắt tỉa phù hợp cho mỗi lớp dựa trên tỷ lệ nén mục tiêu trong quá trình huấn luyện.

Khác với STR [31] áp dụng hàm sigmoid (·) vào ngưỡng học được, chúng tôi áp dụng nó vào sự khác biệt giữa điểm số tầm quan trọng Il và ngưỡng học được δl, tức là Phương trình (8), để kiểm soát dải giá trị của mặt nạ mềm Gl từ 0 đến 1. Ở đây, hàm kích hoạt ReLU (·) được sử dụng trong STR là không cần thiết. Sau đó chúng tôi tiếp tục đưa ra hàm chỉ thị và STE, tức là Phương trình (9), để thu được các mặt nạ cắt tỉa nhị phân học được M={M1, M2,···, MN} đặc trưng cho cấu trúc mạng con. Do đó, chúng ta có thể tính chính xác FLOPs Tkept của mạng con tại một lần lặp nhất định bằng các mặt nạ nhị phân M. Giả sử tổng FLOPs của mạng cơ sở là Ttotal, chúng ta có thể thu được tỷ lệ nén Ĉ=Tkept/Ttotal. Lưu ý rằng vì kích thước của SBCNet lớn hơn cơ sở, giá trị khởi tạo của Ĉ lớn hơn 1 trước khi bắt đầu huấn luyện. Để kiểm soát các ngưỡng làm cho mạng con một cách mượt mà và chính xác đạt được FLOPs mục tiêu đã cho CTtotal, trong đó C là tỷ lệ nén mục tiêu, chúng tôi thiết kế một mục chính quy hóa để ràng buộc FLOPs, như sau:

R(Ĉ, C) = (Ĉ/C−1)2. (11)

Sau đó bài toán tối ưu hóa của mạng được tái công thức là:

min(WS,WB,Δ) L(f(X;WS,WB,Δ), y)
+λ1∑(l=1 to N)∑(i=1 to cl)∥WlS[i]∥1+λ2R(Ĉ, C),(12)

trong đó λ1 và λ2 tương ứng là các hệ số của mục chính quy hóa ℓ1 và mục chính quy hóa FLOPs. Để kiểm soát các ngưỡng δ một cách linh hoạt và nhanh chóng hơn để nén mạng về tỷ lệ nén mục tiêu C, chính quy hóa suy giảm trọng số không còn được áp dụng cho các ngưỡng trong Δ.

Bằng các mặt nạ M, việc học các ngưỡng được hướng dẫn chung bởi tổn thất tác vụ L(f(X;WS,WB,Δ), y) và mục chính quy hóa FLOPs R(Ĉ, C). Cụ thể, các ngưỡng được cập nhật bởi sự hướng dẫn từ gradient của R(Ĉ, C) để đẩy mặt nạ thưa thớt cho đến khi mạng con kết quả thỏa mãn FLOPs mục tiêu, trong khi chúng được cập nhật bởi sự hướng dẫn từ gradient của L(f(X;WS,WB,Δ), y) để ức chế tính thưa thớt mặt nạ và do đó cải thiện độ chính xác của mạng con kết quả. Do đó, trong quá trình huấn luyện ban đầu của một vài epoch, các ngưỡng, được học trong cuộc cạnh tranh để duy trì độ chính xác và nén SBCNet về FLOPs mục tiêu, dẫn đến một mạng con tương đối tốt hơn.

Sau khi đạt được tỷ lệ nén mục tiêu, chúng tôi loại bỏ các mặt nạ thưa thớt nhị phân trên các đường thưa thớt, và chuyển đổi SBCNet thành mạng nén. Theo Ml, chúng ta có thể thu được danh sách chỉ số Klf và tensor trọng số đã cắt tỉa WlS∈Rnl×cl−1×kl×kl trong đường thưa thớt thứ l. Và YlS là đầu ra của đường thưa thớt thứ l. Vì vậy sau khi cắt tỉa, đầu ra của mô-đun SBC thứ l được biểu diễn là:

Yl[i] = {
YlS[Pos(i)] +YlB[i], i∈Klf,
YlB[i], i ∉ Klf,
(13)

trong đó i∈[1, cl] và hàm Pos (·) trả về vị trí của phần tử i trong Klf. Sau đó, chúng tôi tiếp tục huấn luyện mạng nén cho các epoch còn lại. Cuối cùng chúng ta có thể có được một mạng con với trọng số WS={W1S,W2S,···,WNS} và WB thỏa mãn tỷ lệ nén mục tiêu mà không làm giảm hiệu suất.

Toàn bộ quá trình được tóm tắt trong Thuật toán 1. Lưu ý rằng mặc dù trong bài báo này chúng tôi lấy chuẩn ℓ1 làm thước đo tầm quan trọng bộ lọc do tính đơn giản của nó, chiến lược cắt tỉa của chúng tôi cũng có thể được kết hợp với một số thước đo tầm quan trọng khác của các phương pháp hiện tại.

IV. THÍ NGHIỆM

Trong phần này, phương pháp LAPP của chúng tôi được đánh giá trên hai tập dữ liệu phân loại ảnh chuẩn: CIFAR-10 [64] và ImageNet [65]. Chúng tôi so sánh phương pháp của chúng tôi với một số phương pháp nén CNN tiên tiến, bao gồm PFEC [9], DECORE [38], Hinge [55], cắt tỉa từ đầu (PFS) [11], CC [54], NS [30], Hrank [26], FTWT [52], SOSP [35], cắt tỉa phân cấp thông qua biểu diễn hình dạng-cạnh của bản đồ đặc trưng (HPSE) [29], sơ đồ cắt tỉa bộ lọc động và tiến bộ (DPFPS) [45], CHIP [51], học tiêu chí cắt tỉa bộ lọc (LFPC) [47], cắt tỉa mạng thông qua tối đa hóa hiệu suất (NPPM) [32], FP-AGL [49], cắt tỉa bộ lọc mềm (SFP) [27], FPGM [28], cắt tỉa sử dụng mạng nơ-ron đồ thị và học tăng cường (GNN-RL) [37], và DCP [41]. Tất cả các phương pháp được so sánh áp dụng trên các mô hình CNN chính thống, bao gồm VGG [1], ResNet [2], GoogleNet [39], và DenseNet [40]. Chúng tôi thực hiện thí nghiệm toàn diện với Pytorch [66] để chỉ ra rằng LAPP vượt trội hoặc tương đương với các phương pháp trên.

A. Tập dữ liệu và Thiết lập Thí nghiệm

Tập dữ liệu. Tập dữ liệu CIFAR-10 chứa 60.000 hình ảnh màu với kích thước 32×32 trong 10 lớp, và mỗi lớp bao gồm 6.000 hình ảnh, 5.000 trong số đó ở tập huấn luyện và phần còn lại ở tập kiểm tra. Theo [26], đối với tập huấn luyện, chúng tôi đệm 4 pixel với zero ở mỗi bên của hình ảnh, sau đó cắt ngẫu nhiên một mẫu 32×32 từ hình ảnh đã đệm, và cuối cùng lật ngẫu nhiên hình ảnh đã cắt theo chiều ngang với xác suất 0,5. Đối với tập kiểm tra, chúng tôi trực tiếp sử dụng

--- TRANG 8 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 8

BẢNG I
KẾT QUẢ NÉN VGG-16 TRÊN CIFAR-10.

Phương pháp Top-1(%) FLOPs ↓(%) Params ↓(%)
Cơ sở 93.96 0.0 0.0
PFEC [9] 93.40 34.2 64.0
DECORE [38] 94.02 35.3 63.0
Hinge [55] 94.02 39.1 80.1
PFS [11] 93.63±0.06 50.0 —
CC [54] 94.15 50.8 65.9
NS [30] 93.80 51.0 88.5
Hrank [26] 93.43 53.5 82.9
Ours (C=0.46) 94.32±0.20 53.6 73.0
FTWT [52] 93.73 56.0 —
SOSP [35] 93.73±0.16 57.7 87.3
CC [54] 94.09 60.7 72.7
DECORE [38] 93.56 64.8 89.0
Hrank [26] 92.34 65.3 82.1
Ours (C=0.34) 94.36±0.08 65.7 74.3
HPSE [29] 93.50 66.1 —
DPFPS [45] 93.52±0.15 70.9 93.3
Ours (C=0.26) 93.79±0.16 73.8 85.2
Hrank [26] 91.23 76.5 92.0
CHIP [51] 93.18 78.6 87.3
DECORE [38] 92.44 81.5 96.6
Ours (C=0.18) 93.54±0.23 81.9 86.1
HPSE [29] 92.49 82.0 —

các hình ảnh 32×32 gốc. Cả hình ảnh huấn luyện và kiểm tra đều được chuẩn hóa sử dụng giá trị trung bình và độ lệch chuẩn của kênh. Tập dữ liệu ImageNet là một tập dữ liệu phân loại ảnh quy mô lớn bao gồm khoảng 1,28 triệu hình ảnh huấn luyện và 50.000 hình ảnh xác thực từ 1.000 lớp. Chúng tôi áp dụng cùng chiến lược tăng cường dữ liệu như CC [54].

Thiết lập Thí nghiệm. Trên CIFAR-10, các cơ sở được huấn luyện sử dụng cùng cấu hình huấn luyện như công trình của Li et al. [54], tức là tốc độ học ban đầu được đặt thành 0,1 và được nhân với 0,1 ở 50% và 75% của tổng 300 epoch. Lưu ý rằng do sự hiện diện của giai đoạn tinh chỉnh, hầu hết các phương pháp nén được so sánh huấn luyện hơn 400 epoch. Vì vậy để so sánh công bằng và làm cho mạng nén được huấn luyện đầy đủ, chúng tôi huấn luyện các mạng ngoại trừ DenseNet từ đầu với LAPP trong 400 epoch thông qua thuật toán Stochastic Gradient Descent (SGD) với momentum 0,9 và tốc độ học ban đầu 0,1. Kích thước mini-batch và suy giảm trọng số được đặt thành 128 và 0,0001, tương ứng. Ngoại trừ số epoch, cấu hình huấn luyện của chúng tôi giống với cấu hình tinh chỉnh của CC [54]. Để đạt được hiệu suất tương đương, chúng tôi huấn luyện DenseNet từ đầu với LAPP trong 600 epoch giống với tổng số epoch của CC [54]. Trên ImageNet, các mạng được huấn luyện từ đầu với LAPP trong 120 epoch với tốc độ học ban đầu 0,1. Tốc độ học được chia cho 10 ở epoch 30, 60 và 90, và kích thước mini-batch được đặt thành 256. Tất cả các ngưỡng học được được khởi tạo theo kinh nghiệm thành 0, và hệ số λ2 của mục ràng buộc FLOPs được đặt thành 1,0 cho tất cả các mạng ngoại trừ ResNet34. Hệ số λ1 của mục chính quy hóa ℓ1 được đặt thành 3e-5 cho ResNet-20 và 2e-5 cho các mạng khác trên CIFAR-10. Trên ImageNet, λ1 được đặt thành 1e-5, và λ2 được đặt thành 0,5 cho ResNet-34. Tất cả thí nghiệm được lặp lại ba lần và kết quả trung bình được báo cáo. Lưu ý rằng trong tất cả các bảng tiếp theo, FLOPs ↓ và Params ↓ biểu diễn việc giảm

BẢNG II
KẾT QUẢ NÉN RESNET-56/110 TRÊN CIFAR-10.

Phương pháp Top-1(%) FLOPs ↓(%) Params ↓(%)
ResNet-56 93.33 0.0 0.0
LFPC [47] 93.72±0.29 47.1 —
DECORE [38] 93.26 49.9 49.0
PFS [11] 93.05±0.19 50.0 —
Hrank [26] 93.17 50.0 42.4
NPPM [32] 93.40 50.0 —
Hinge [55] 93.69 50.0 48.7
CC [54] 93.64 52.0 48.2
FP-AGL [49] 93.69 52.5 —
Ours (C=0.47) 93.72±0.16 52.5 40.0
SFP [27] 93.35±0.31 52.6 —
FPGM [28] 93.49±0.13 52.6 —
DPFPS [45] 93.20±0.11 52.9 46.8
GNN-RL [37] 93.49 54.0 —
SOSP [35] 93.27±0.51 57.0 61.0
FP-AGL [49] 93.49 60.9 —
Ours (C=0.385) 93.52±0.18 61.1 52.5
FTWT [52] 92.63 66.0 —
CHIP [51] 92.05 72.3 71.8
Hrank [26] 90.72 74.1 68.1
HPSE [29] 91.51 74.2 —
Ours (C=0.25) 92.84±0.21 74.8 66.8
ResNet-110 93.50 0.0 0.0
PFEC [9] 93.30 38.6 32.4
PFS [11] 93.69±0.28 40.0 —
SFP [27] 93.38±0.30 40.8 —
Hrank [26] 94.23 41.2 39.4
FPGM [28] 93.74±0.10 52.3 —
Ours (C=0.47) 94.03±0.26 52.5 42.7
LFPC [47] 93.79±0.38 60.3 —
HPSE [29] 93.79 60.6 —
DECORE [38] 93.50 61.8 64.8
Hrank [26] 92.65 68.6 69.2
Ours (C=0.31) 93.90±0.14 68.7 66.2
HPSE [29] 93.26 73.4 —
DECORE [38] 92.71 76.9 79.6
Ours (C=0.22) 93.18±0.17 77.8 70.6

FLOPs và tham số của mạng nén so với mạng Cơ sở, tương ứng.

B. Kết quả Thí nghiệm trên CIFAR-10

Chúng tôi thực hiện thí nghiệm trên tập dữ liệu CIFAR-10 với một số CNN phổ biến, bao gồm ResNet-56/110/20/32, VGG-16, DenseNet-40 và GoogLeNet. Theo [26], VGG-16 là phiên bản được sửa đổi của bản gốc và đầu ra của GoogLeNet gốc được thay đổi để phù hợp với số lớp trong CIFAR-10.

VGG-16. Kết quả nén của VGG-16 được hiển thị trong Bảng I. So với các phương pháp cắt tỉa sau huấn luyện HRank và DECORE, phương pháp của chúng tôi không có huấn luyện trước tốt hơn ở các mức tăng tốc khác nhau. So với CC và Hinge kết hợp cắt tỉa và phân tích hạng thấp, phương pháp của chúng tôi cũng đạt được hiệu suất tốt hơn (65,7% so với 60,7% so với 39,1% trong giảm FLOPs, và 94,36% so với 94,09% so với 94,02% trong độ chính xác top-1). So với phương pháp cắt tỉa động FTWT, với độ chính xác gần như tương tự, phương pháp của chúng tôi đạt được giảm FLOPs đáng kể hơn (73,8% so với 56,0%). So với PFEC cũng sử dụng thước đo chuẩn ℓ1, nơi chỉ đạt được độ chính xác top-1 93,40%, phương pháp của chúng tôi đạt được kết quả tốt hơn 94,32% với giảm FLOPs đáng kể hơn, điều này chứng minh tính ưu việt của việc đưa ra

--- TRANG 9 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 9

BẢNG III
KẾT QUẢ NÉN RESNET-20/32 TRÊN CIFAR-10.

Phương pháp Top-1(%) FLOPs ↓(%) Params ↓(%)
ResNet-20 92.20 0.0 0.0
SFP [27] 90.83±0.31 42.2 —
FPGM [28] 91.09±0.10 42.2 —
PFS [11] 90.55±0.14 50.0 —
GNN-RL [37] 91.31 51.0 —
Hinge [55] 91.84 54.5 55.5
Ours (C=0.4) 92.22±0.19 59.7 52.8
FP-AGL [49] 90.11 60.7 —
Ours (C=0.28) 91.24±0.24 71.8 58.9
ResNet-32 92.63 0.0 0.0
SFP [27] 92.08±0.08 41.5 —
GNN-RL [37] 92.58 51.0 —
LFPC [47] 92.12±0.08 52.6 —
FPGM [28] 91.93±0.03 53.2 —
Ours (C=0.4) 93.21±0.19 59.6 49.1
FP-AGL [49] 91.86 60.8 —
Ours (C=0.28) 92.32±0.21 71.8 60.8

các đường vòng và sử dụng chiến lược cắt tỉa không đồng nhất được đề xuất. Do đó, phương pháp của chúng tôi chứng minh khả năng tăng tốc một mạng nơ-ron với cấu trúc đơn giản.

ResNet-56/110/20/32. Kết quả nén của ResNet-56/110/20/32 được hiển thị trong Bảng II và III. Chúng tôi bắt đầu với ResNet-56. So với phương pháp cắt tỉa tại khởi tạo PFS, phương pháp của chúng tôi tiếp tục giảm FLOPs thêm 2,5%, trong khi duy trì độ chính xác cao hơn (93,72(±0,16)% so với 93,05(±0,19)%). Ngoài ra, so với phương pháp cắt tỉa trong quá trình huấn luyện DPFPS, phương pháp của chúng tôi tiếp tục cải thiện độ chính xác thêm 0,32%, trong khi duy trì giảm FLOPs nhiều hơn (61,1% so với 52,9%). So với NPPM cũng sử dụng ràng buộc FLOPs, với giảm FLOPs nhiều hơn, phương pháp của chúng tôi không có huấn luyện trước đạt được độ chính xác đáng kể tốt hơn (93,72(±0,16)% so với 93,40%), điều này chứng minh tính ưu việt của chiến lược cắt tỉa kết hợp ngưỡng học được và ràng buộc FLOPs. So với LFPC học tiêu chí cắt tỉa bộ lọc, với độ chính xác gần như tương tự, phương pháp của chúng tôi tiếp tục giảm FLOPs thêm 5,4%.

Trên ResNet-110 với nhiều dư thừa hơn, phương pháp của chúng tôi dẫn đến cải thiện đáng kể về độ chính xác so với mô hình cơ sở (94,03(±0,26)% so với 93,50%) với khoảng 52,5% FLOPs và 42,7% tham số giảm. So với SFP và FPGM với cùng tỷ lệ cắt tỉa cho tất cả các lớp, phương pháp của chúng tôi đạt được độ chính xác cao hơn (93,90(±0,14)% so với 93,38(±0,30)% so với 93,74(±0,10)%) và tiết kiệm nhiều tài nguyên tính toán hơn (68,7% so với 40,8% so với 52,3%), điều này cho thấy phương pháp của chúng tôi hiệu quả hơn. So với HPSE với tiêu chí cắt tỉa phức tạp dựa trên đặc tính của bản đồ đặc trưng, phương pháp của chúng tôi sử dụng thước đo chuẩn ℓ1 đơn giản vẫn tương đương ở các mức tăng tốc khác nhau, điều này chứng minh tính ưu việt của phương pháp của chúng tôi.

Bảng III cho thấy hiệu suất của các phương pháp khác nhau nén ResNet-20/32. Nén ResNet20/32 tương đối nhẹ thách thức hơn so với nén ResNet-56/110. Trên ResNet-20, so với GNN-RL tìm tỷ lệ cắt tỉa phù hợp của các lớp ẩn sử dụng học tăng cường, phương pháp của chúng tôi tiếp tục cải thiện độ chính xác thêm 0,91% và giảm FLOPs thêm 8,7%. Trên ResNet-32,

BẢNG IV
KẾT QUẢ NÉN DENSE NET-40 TRÊN CIFAR-10.

Phương pháp Top-1(%) FLOPs ↓(%) Params ↓(%)
Cơ sở 94.81 0.0 0.0
DECORE [38] 94.59 39.4 46.0
Hrank [26] 94.24 40.8 36.5
Hinge [55] 94.67 44.4 27.5
CC [54] 94.67 47.0 51.9
HPSE [29] 94.38 48.0 —
Ours (C=0.5,in) 94.56±0.17 49.5 46.6
Ours (C=0.5,out) 94.51±0.29 49.6 48.2
DECORE [38] 94.04 54.7 65.0
NS [30] 94.35 55.0 65.2
CC [54] 94.40 60.4 64.4
Hrank [26] 93.68 61.0 53.8
HPSE [29] 93.88 61.5 —
Ours (C=0.38,in) 94.24±0.25 61.6 62.4

BẢNG V
KẾT QUẢ NÉN GOOGLE NET TRÊN CIFAR-10.

Phương pháp Top-1(%) FLOPs ↓(%) Params ↓(%)
Cơ sở 95.05 0.0 0.0
DECORE [38] 95.20 19.8 23.0
PFEC [9] 94.54 32.9 42.9
CC [54] 95.18 50.0 54.0
Ours (C=0.49) 95.57±0.08 50.5 52.6
Hrank [26] 94.53 54.9 55.4
CC [54] 94.88 59.9 63.3
Ours (C=0.39) 95.40±0.12 60.6 61.1
Hrank [26] 94.07 70.4 69.8
DECORE [38] 94.51 78.5 80.9
Ours (C=0.21) 94.99±0.08 78.8 79.1

với khoảng 60,0% giảm FLOPs, phương pháp của chúng tôi dẫn đến cải thiện đáng kể về độ chính xác so với mô hình cơ sở (93,21(±0,19)% so với 92,63%), điều này khác biệt đáng kể so với các thuật toán nén tiên tiến khác, làm nổi bật tính hiệu quả của phương pháp của chúng tôi. Do đó, phương pháp của chúng tôi chứng minh rằng nó đặc biệt phù hợp để nén các mạng nơ-ron với các khối dư.

DenseNet-40. Bảng IV cho thấy hiệu suất của các phương pháp khác nhau nén DenseNet-40, trong đó 'in' biểu thị cắt tỉa kênh và 'out' biểu thị cắt tỉa bộ lọc. So với các phương pháp cắt tỉa tiên tiến HRank, DECORE và HPSE, phương pháp của chúng tôi tốt hơn chúng ở các mức tăng tốc khác nhau. So với CC và Hinge đòi hỏi các mô hình được huấn luyện trước, với giảm FLOPs hơi nhiều hơn, mặc dù độ chính xác trung bình của chúng tôi tệ hơn so với kết quả họ báo cáo, kết quả tốt nhất của chúng tôi tốt hơn của họ (94,76% so với 94,67% so với 94,67%). Nhìn chung, phương pháp của chúng tôi có tiềm năng tăng tốc tốt hơn các mạng với các khối dày đặc.

GoogleNet. Trong Bảng V, chúng tôi phân tích hiệu suất của các phương pháp khác nhau trên GoogleNet. Vì GoogleNet có lượng dư thừa lớn, việc nén nó đặc biệt dễ dàng. Các tích chập 1×1 trong GoogleNet chỉ sở hữu các đường thưa thớt cho phương pháp của chúng tôi. Với độ chính xác gần như tương tự so với mô hình cơ sở, phương pháp của chúng tôi đạt được khoảng 79% giảm FLOPs và tham số. Ngoài ra, so với HRank và CC, phương pháp của chúng tôi sử dụng ít FLOPs hơn nhiều (39,4% so với 45,1% so với 40,1%), nhưng đạt được độ chính xác cao hơn (95,40(±0,12)% so với 94,53% so với 94,88%), điều này rất khuyến khích. Do đó,

--- TRANG 10 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 10

BẢNG VI
KẾT QUẢ NÉN RESNET-18/34 TRÊN IMAGE NET.

Phương pháp Top-1(%) Top-5(%) FLOPs ↓(%)
ResNet-18 69.76 89.08 0.0
SOSP [35] 68.78±0.98 — 29.0
SFP [27] 67.10 87.78 41.8
FPGM [28] 68.34 88.53 41.8
Ours (C=0.56) 70.43±0.07 89.77±0.03 43.5
DCP [41] 67.36 87.63 46.2
GNN-RL [37] 68.66 — 51.0
FTWT [52] 67.49 — 51.6
Ours (C=0.44) 69.97±0.04 89.48±0.14 55.6
ResNet-34 73.31 91.42 0.0
SFP [27] 71.83 90.33 41.1
FPGM [28] 72.54 91.13 41.1
FP-AGL [49] 72.72 — 43.1
DPFPS [45] 72.25 90.80 43.3
Ours (C=0.56) 72.91±0.13 91.18±0.02 43.5
ResNet-18 [2] 69.76 89.08 50.0
FTWT [52] 71.71 — 52.2
Ours (C=0.47) 72.55±0.16 91.05±0.11 52.5

nó chứng minh rằng phương pháp của chúng tôi có thể được áp dụng hiệu quả để nén các mạng nơ-ron với các mô-đun inception.

C. Kết quả Thí nghiệm trên ImageNet

ResNet-18/34. Chúng tôi cũng thực hiện thí nghiệm cho ResNet-18 và ResNet-34 trên tập dữ liệu ImageNet thách thức, như được thể hiện trong Bảng VI. Chúng ta có thể thấy kết luận tương tự trong tập dữ liệu CIFAR-10, tức là phương pháp của chúng tôi gần như vượt trội so với các phương pháp được so sánh về tất cả các khía cạnh. Cụ thể, So với SFP (67,10% top-1) và FPGM (68,34% top-1), phương pháp của chúng tôi đạt được độ chính xác cao hơn (70,43% top-1) với giảm FLOPs nhiều hơn (43,5%) trên ResNet-18. So với DCP đòi hỏi các mô hình được huấn luyện trước, phương pháp của chúng tôi cung cấp độ chính xác đáng kể cao hơn với giảm FLOPs nhiều hơn (69,97(±0,04)% so với 67,36% về độ chính xác top-1, và 55,6% so với 46,2% về giảm FLOPs) trên ResNet-18. So với GNN-RL đòi hỏi tổng 240 epoch, với 120 epoch, phương pháp của chúng tôi đạt được hiệu suất tốt hơn trên ResNet-18, điều này cho thấy phương pháp của chúng tôi hiệu quả hơn. So với FP-AGL và DPFPS, với độ chính xác cao hơn, phương pháp của chúng tôi đạt được giảm FLOPs tương tự trên ResNet-34. So với ResNet-18, với giảm FLOPs nhiều hơn, phương pháp của chúng tôi dẫn đến độ chính xác đáng kể cao hơn trên ResNet-34, điều này chứng minh rằng phương pháp của chúng tôi có thể tạo ra một mạng con tốt. FTWT là một phương pháp cắt tỉa động và dự kiến sẽ vượt trội so với các phương pháp cắt tỉa tĩnh, nhưng phương pháp của chúng tôi vẫn vượt trội so với nó trên ResNet-18 và ResNet-34. Do đó, phương pháp của chúng tôi cũng hoạt động tốt trên các tập dữ liệu phức tạp.

D. Nghiên cứu Loại bỏ

Tác động của Đường vòng. Như đã đề cập trước đó, các đường vòng bù đắp cho các đường thưa thớt. Chúng tôi thực hiện thí nghiệm loại bỏ trên CIFAR-10 với VGG-16, ResNet-56 và ResNet-20 để chỉ ra tác động bù đắp của các đường vòng, như được thể hiện trong Bảng VII. Ở đây, các khối được lấy cảm hứng từ MobileNetV1 [67] và MobileNetV2 [36] được đặt tên là V1 và V2, tương ứng. Khối V1 chứa tuần tự hai lớp tích chập nhỏ: tích chập theo chiều sâu và tích chập 1×1.

BẢNG VII
KẾT QUẢ THÍ NGHIỆM LOẠI BỎ CỦA ĐƯỜNG VÒNG.

Mô hình C Phương pháp Top-1(%) FLOPs ↓(%)
VGG-16 0.34 LAPP-S 93.70±0.24 65.7
Model-V2 94.20±0.15 65.5
LAPP-V1 93.65±0.13 65.7
LAPP 94.36±0.08 65.7
ResNet-56 0.33 LAPP-S 92.93±0.21 66.7
Model-V2 92.84±0.11 66.3
LAPP-V1 93.09±0.17 66.7
LAPP 93.49±0.07 66.7
ResNet-20 0.4 LAPP-S 90.70±0.13 59.7
Model-V2 91.68±0.17 59.3
LAPP-V1 91.71±0.48 59.7
LAPP 92.22±0.19 59.7

BẢNG VIII
KẾT QUẢ THÍ NGHIỆM LOẠI BỎ CỦA CHIẾN LƯỢC CẮT TỈA. 'UP' BIỂU THỊ CẮT TỈA ĐỒNG NHẤT.

Mô hình C Phương pháp Top-1(%) FLOPs ↓(%)
VGG-16 0.34 LAPP-UP 94.20±0.11 65.8
LAPP 94.36±0.08 65.7
0.18 LAPP-UP 93.31±0.12 81.8
LAPP 93.54±0.23 81.9
ResNet-56 0.47 LAPP-UP 93.34±0.18 50.1
LAPP 93.72±0.16 52.5
0.33 LAPP-UP 92.84±0.13 65.2
LAPP 93.49±0.07 66.7
ResNet-20 0.4 LAPP-UP 91.25±0.18 57.7
LAPP 92.22±0.19 59.7

'LAPP-S' biểu thị chỉ sử dụng đường thưa thớt trong các mô-đun SBC, 'Model-V2' biểu thị chỉ sử dụng các đường vòng chứa khối V2, và 'LAPP-V1' và 'LAPP' biểu thị sử dụng hai đường và tương ứng lấy khối V1 và V2 làm đường vòng. Chúng tôi điều chỉnh siêu tham số dl của mỗi đường vòng cho Model-V2 để đạt được cùng giảm FLOPs như các phương pháp khác. Ngoài ra, chúng tôi sử dụng chính xác cùng cấu hình huấn luyện cho tất cả các phương pháp. Khác với LAPP-V1 và LAPP, đối với LAPP-S không có đường vòng, khi các kênh đầu ra của lớp được cắt tỉa, việc cắt tỉa các kênh đầu vào tương ứng của lớp tiếp theo cần được tính đến.

Từ Bảng VII, LAPP-V1 và LAPP với các đường vòng vượt trội so với LAPP-S trong gần như tất cả các trường hợp, điều này chứng minh tác động bù đắp của các đường vòng. Hơn nữa, mạng càng compact, tác động bù đắp của đường vòng càng đáng kể, đặc biệt là đối với các mạng có khối dư. Ví dụ, khi nén ResNet-20 thách thức hơn, LAPP vượt trội so với LAPP-S 1,52% về độ chính xác top-1 với giảm FLOPs tương tự. Ngoài ra, để nén VGG-16, ResNet56 và ResNet-20, LAPP vượt trội so với Model-V2 tương ứng 0,16%, 0,65%, và 0,54% về độ chính xác top-1. Điều này chứng minh rằng các đường vòng và các đường thưa thớt có thể bù đắp cho nhau, dẫn đến hiệu suất nén tốt hơn. Cuối cùng nhưng không kém phần quan trọng, LAPP vượt trội so với LAPP-V1 trong tất cả các trường hợp. Điều này chứng minh rằng khối V2 với sức mạnh biểu đạt mạnh hơn có tác động bù đắp tốt hơn so với khối V1.

Tác động của Chiến lược Cắt Tỉa. Ở đây chúng tôi thực hiện

--- TRANG 11 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 11

thí nghiệm loại bỏ trên CIFAR-10 với VGG-16, ResNet-56 và ResNet-20 để chỉ ra tác động của chiến lược cắt tỉa dưới các tỷ lệ nén FLOPs mục tiêu khác nhau, như được thể hiện trong Bảng VIII. Sử dụng cùng thước đo tầm quan trọng bộ lọc, chúng tôi so sánh chiến lược cắt tỉa của chúng tôi với chiến lược cắt tỉa đồng nhất tại khởi tạo. Chúng tôi sử dụng 'UP' để biểu thị cắt tỉa đồng nhất trước khi bắt đầu huấn luyện. Chúng tôi đặt thủ công gần như cùng tỷ lệ cắt tỉa cho tất cả các đường thưa thớt để đạt được tỷ lệ nén FLOPs mục tiêu. Các cấu hình huấn luyện khác chính xác giống như LAPP. LAPP với chiến lược cắt tỉa của chúng tôi vượt trội so với LAPP-UP sử dụng cắt tỉa đồng nhất trong tất cả các trường hợp. Ví dụ, khi nén ResNet-56, LAPP vượt trội so với LAPP-UP tương ứng 0,38% và 0,65% về độ chính xác top-1 dưới các tỷ lệ nén FLOPs mục tiêu khác nhau 47% và 33%. Tỷ lệ nén FLOPs mục tiêu càng thấp, chiến lược cắt tỉa của chúng tôi càng hiệu quả. Điều này chứng minh rằng chiến lược cắt tỉa của chúng tôi có thể tạo ra một mạng con tương đối tốt hơn.

V. KẾT LUẬN

Trong bài báo này, chúng tôi tích hợp ngưỡng học được và ràng buộc FLOPs vào một chiến lược cắt tỉa hiệu quả và hiệu suất cao. Chiến lược cắt tỉa có thể dần dần cắt tỉa mạng và tự động xác định tỷ lệ cắt tỉa phù hợp cho mỗi lớp trong quá trình huấn luyện ban đầu của một vài epoch từ đầu. Ngoài ra, chúng tôi đưa ra một đường vòng nhẹ bổ sung cho mỗi lớp tích chập để bù đắp thông tin và dung lượng bị mất của lớp đã cắt tỉa trong quá trình huấn luyện. Tính hiệu quả của phương pháp đề xuất được đánh giá trên các tập dữ liệu chuẩn CIFAR-10 và ImageNet sử dụng các mô hình CNN chính thống, và kết quả cho thấy hiệu suất vượt trội so với các thuật toán nén tiên tiến khác.

TÀI LIỆU THAM KHẢO

[1] K. Simonyan và A. Zisserman, "Very deep convolutional networks for large-scale image recognition," arXiv preprint arXiv:1409.1556, 2014.
[2] K. He, X. Zhang, S. Ren, và J. Sun, "Deep residual learning for image recognition," trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016, trang 770–778.
[3] J. Redmon, S. Divvala, R. Girshick, và A. Farhadi, "You only look once: Unified, real-time object detection," trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016, trang 779–788.
[4] T.-Y. Lin, P. Goyal, R. Girshick, K. He, và P. Dollár, "Focal loss for dense object detection," trong Proceedings of the IEEE International Conference on Computer Vision, 2017, trang 2980–2988.
[5] R. T. Marriott, S. Romdhani, và L. Chen, "A 3d gan for improved large-pose facial recognition," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, trang 13 445–13 455.
[6] S. Li, J. Xu, X. Xu, P. Shen, S. Li, và B. Hooi, "Spherical confidence learning for face recognition," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, trang 15 629–15 637.
[7] Y. Chen, Z. Zhang, C. Yuan, B. Li, Y. Deng, và W. Hu, "Channel-wise topology refinement graph convolution for skeleton-based action recognition," trong Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, trang 13 359–13 368.
[8] Y. Nirkin, L. Wolf, và T. Hassner, "HyperSeg: Patch-wise hypernetwork for real-time semantic segmentation," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, trang 4061–4070.
[9] H. Li, A. Kadav, I. Durdanovic, H. Samet, và H. P. Graf, "Pruning filters for efficient convnets," arXiv preprint arXiv:1608.08710, 2016.
[10] J. J. M. Ople, T.-M. Huang, M.-C. Chiu, Y.-L. Chen, và K.-L. Hua, "Adjustable model compression using multiple genetic algorithms," IEEE Transactions on Multimedia, 2021.
[11] Y. Wang, X. Zhang, L. Xie, J. Zhou, H. Su, B. Zhang, và X. Hu, "Pruning from scratch," trong Proceedings of the AAAI Conference on Artificial Intelligence, tập 34, số 07, 2020, trang 12 273–12 280.
[12] V. Lebedev, Y. Ganin, M. Rakhuba, I. Oseledets, và V. Lempitsky, "Speeding-up convolutional neural networks using fine-tuned CP-decomposition," trong Proceedings of the International Conference on Learning Representations, 2015.
[13] A.-H. Phan, K. Sobolev, K. Sozykin, D. Ermilov, J. Gusak, P. Tichavský, V. Glukhov, I. Oseledets, và A. Cichocki, "Stable low-rank tensor decomposition for compression of convolutional neural network," trong Proceedings of the European Conference on Computer Vision. Springer, 2020, trang 522–539.
[14] J. Kossaifi, A. Toisoul, A. Bulat, Y. Panagakis, T. M. Hospedales, và M. Pantic, "Factorized higher-order cnns with an application to spatio-temporal emotion estimation," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, trang 6060–6069.
[15] G. Hinton, O. Vinyals, và J. Dean, "Distilling the knowledge in a neural network," arXiv preprint arXiv:1503.02531, 2015.
[16] D. Y. Park, M.-H. Cha, D. Kim, B. Han và các cộng sự, "Learning student-friendly teacher networks for knowledge distillation," trong Advances in Neural Information Processing Systems, tập 34, 2021, trang 13 292–13 303.
[17] P. K. Sharma, A. Abraham, và V. N. Rajendiran, "A generalized zero-shot quantization of deep convolutional neural networks via learned weights statistics," IEEE Transactions on Multimedia, 2021.
[18] Z. Li, B. Ni, T. Li, X. Yang, W. Zhang, và W. Gao, "Residual quantization for low bit-width neural networks," IEEE Transactions on Multimedia, 2021.
[19] W. Duan, Z. Liu, C. Jia, S. Wang, S. Ma, và W. Gao, "Differential weight quantization for multi-model compression," IEEE Transactions on Multimedia, 2022.
[20] K. Han, Y. Wang, C. Xu, J. Guo, C. Xu, E. Wu, và Q. Tian, "Ghostnets on heterogeneous devices via cheap operations," International Journal of Computer Vision, tập 130, số 4, trang 1050–1069, 2022.
[21] Q. Zhang, Z. Jiang, Q. Lu, Z. Zeng, S.-H. Gao, và A. Men, "Split to Be Slim: an overlooked redundancy in vanilla convolution," trong Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence, 2021, trang 3195–3201.
[22] J. Chen, S.-h. Kao, H. He, W. Zhuo, S. Wen, C.-H. Lee, và S.-H. G. Chan, "Run, Don't Walk: Chasing higher flops for faster neural networks," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023, trang 12 021–12 031.
[23] X. Ding, X. Zhou, Y. Guo, J. Han, J. Liu và các cộng sự, "Global sparse momentum sgd for pruning very deep neural networks," trong Advances in Neural Information Processing Systems, tập 32, 2019.
[24] X. Dong, S. Chen, và S. Pan, "Learning to prune deep neural networks via layer-wise optimal brain surgeon," trong Advances in Neural Information Processing Systems, tập 30, 2017.
[25] X. Ding, T. Hao, J. Tan, J. Liu, J. Han, Y. Guo, và G. Ding, "ResRep: Lossless cnn pruning via decoupling remembering and forgetting," trong Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, trang 4510–4520.
[26] M. Lin, R. Ji, Y. Wang, Y. Zhang, B. Zhang, Y. Tian, và L. Shao, "Hrank: Filter pruning using high-rank feature map," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, trang 1529–1538.
[27] Y. He, G. Kang, X. Dong, Y. Fu, và Y. Yang, "Soft filter pruning for accelerating deep convolutional neural networks," trong Proceedings of the International Joint Conference on Artificial Intelligence, 2018.
[28] Y. He, P. Liu, Z. Wang, Z. Hu, và Y. Yang, "Filter pruning via geometric median for deep convolutional neural networks acceleration," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, trang 4340–4349.
[29] H. Zhang, L. Liu, B. Kang, và N. Zheng, "Hierarchical model compression via shape-edge representation of feature maps—an enlightenment from the primate visual system," IEEE Transactions on Multimedia, 2022.
[30] Z. Liu, J. Li, Z. Shen, G. Huang, S. Yan, và C. Zhang, "Learning efficient convolutional networks through network slimming," trong Proceedings of the IEEE International Conference on Computer Vision, 2017, trang 2736–2744.
[31] A. Kusupati, V. Ramanujan, R. Somani, M. Wortsman, P. Jain, S. Kakade, và A. Farhadi, "Soft threshold weight reparameterization for learnable sparsity," trong Proceedings of the International Conference on Machine Learning. PMLR, 2020, trang 5544–5555.

--- TRANG 12 ---
CÔNG TRÌNH NÀY ĐÃ ĐƯỢC GỬI ĐẾN IEEE ĐỂ XEM XÉT XUẤT BẢN. BẢN QUYỀN CÓ THỂ ĐƯỢC CHUYỂN GIAO MÀ KHÔNG CẦN THÔNG BÁO, SAU ĐÓ PHIÊN BẢN NÀY CÓ THỂ KHÔNG CÒN TRUY CẬP ĐƯỢC. 12

[32] S. Gao, F. Huang, W. Cai, và H. Huang, "Network pruning via performance maximization," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, trang 9270–9280.
[33] S. Gao, F. Huang, J. Pei, và H. Huang, "Discrete model compression with resource constraint for deep neural networks," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, trang 1899–1908.
[34] M. Shen, P. Molchanov, H. Yin, và J. M. Alvarez, "When to prune? a policy towards early structural pruning," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, trang 12 247–12 256.
[35] M. Nonnenmacher, T. Pfeil, I. Steinwart, và D. Reeb, "SOSP: Efficiently capturing global correlations by second-order structured pruning," trong Proceedings of the International Conference on Learning Representations, 2021.
[36] M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, và L.-C. Chen, "MobileNetV2: Inverted residuals and linear bottlenecks," trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, trang 4510–4520.
[37] S. Yu, A. Mazaheri, và A. Jannesari, "Topology-aware network pruning using multi-stage graph embedding and reinforcement learning," trong Proceedings of the International Conference on Machine Learning. PMLR, 2022, trang 25 656–25 667.
[38] M. Alwani, Y. Wang, và V. Madhavan, "DECORE: Deep compression with reinforcement learning," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, trang 12 349–12 359.
[39] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, và A. Rabinovich, "Going deeper with convolutions," trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2015, trang 1–9.
[40] G. Huang, Z. Liu, L. Van Der Maaten, và K. Q. Weinberger, "Densely connected convolutional networks," trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017, trang 4700–4708.
[41] Z. Zhuang, M. Tan, B. Zhuang, J. Liu, Y. Guo, Q. Wu, J. Huang, và J. Zhu, "Discrimination-aware channel pruning for deep neural networks," trong Advances in Neural Information Processing Systems, tập 31, 2018.
[42] N. Lee, T. Ajanthan, và P. Torr, "SNIP: Single-shot network pruning based on connection sensitivity," trong Proceedings of the International Conference on Learning Representations, 2018.
[43] S. Hayou, J.-F. Ton, A. Doucet, và Y. W. Teh, "Robust pruning at initialization," trong Proceedings of the International Conference on Learning Representations, 2020.
[44] C. Wang, G. Zhang, và R. Grosse, "Picking winning tickets before training by preserving gradient flow," trong Proceedings of the International Conference on Learning Representations, 2019.
[45] X. Ruan, Y. Liu, B. Li, C. Yuan, và W. Hu, "DPFPS: dynamic and progressive filter pruning for compressing convolutional neural networks from scratch," trong Proceedings of the AAAI Conference on Artificial Intelligence, tập 35, số 3, 2021, trang 2495–2503.
[46] J. Frankle, G. K. Dziugaite, D. Roy, và M. Carbin, "Linear mode connectivity and the lottery ticket hypothesis," trong Proceedings of the International Conference on Machine Learning. PMLR, 2020, trang 3259–3269.
[47] Y. He, Y. Ding, P. Liu, L. Zhu, H. Zhang, và Y. Yang, "Learning filter pruning criteria for deep convolutional neural networks acceleration," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, trang 2009–2018.
[48] Z. Wang, W. Hong, Y.-P. Tan, và J. Yuan, "Pruning 3d filters for accelerating 3d convnets," IEEE Transactions on Multimedia, tập 22, số 8, trang 2126–2137, 2019.
[49] N. J. Kim và H. Kim, "FP-AGL: Filter pruning with adaptive gradient learning for accelerating deep convolutional neural networks," IEEE Transactions on Multimedia, 2022.
[50] T. Zhuang, Z. Zhang, Y. Huang, X. Zeng, K. Shuang, và X. Li, "Neuron-level structured pruning using polarization regularizer," trong Advances in Neural Information Processing Systems, tập 33, 2020, trang 9865–9877.
[51] Y. Sui, M. Yin, Y. Xie, H. Phan, S. Aliari Zonouz, và B. Yuan, "CHIP: CHannel independence-based pruning for compact neural networks," trong Advances in Neural Information Processing Systems, tập 34, 2021, trang 24 604–24 616.
[52] S. Elkerdawy, M. Elhoushi, H. Zhang, và N. Ray, "Fire Together Wire Together: A dynamic pruning approach with self-supervised mask prediction," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, trang 12 454–12 463.
[53] K. Guo, X. Xie, X. Xu, và X. Xing, "Compressing by learning in a low-rank and sparse decomposition form," IEEE Access, tập 7, trang 150 823–150 832, 2019.
[54] Y. Li, S. Lin, J. Liu, Q. Ye, M. Wang, F. Chao, F. Yang, J. Ma, Q. Tian, và R. Ji, "Towards compact cnns via collaborative compression," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, trang 6438–6447.
[55] Y. Li, S. Gu, C. Mayer, L. V. Gool, và R. Timofte, "Group Sparsity: The hinge between filter pruning and decomposition for network compression," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, trang 8018–8027.
[56] Y. Wang, Y. Lu, và T. Blankevoort, "Differentiable joint pruning and quantization for hardware efficiency," trong Proceedings of the European Conference on Computer Vision. Springer, 2020, trang 259–277.
[57] M. Van Baalen, C. Louizos, M. Nagel, R. A. Amjad, Y. Wang, T. Blankevoort, và M. Welling, "Bayesian Bits: Unifying quantization and pruning," trong Advances in Neural Information Processing Systems, tập 33, 2020, trang 5741–5752.
[58] S. Wang, J. Chen, C. Li, J. Zhu, và B. Zhang, "Fast lossless neural compression with integer-only discrete flows," trong Proceedings of the International Conference on Machine Learning. PMLR, 2022, trang 22 562–22 575.
[59] S. Li, M. Lin, Y. Wang, C. Fei, L. Shao, và R. Ji, "Learning efficient gans for image translation via differentiable masks and co-attention distillation," IEEE Transactions on Multimedia, 2022.
[60] W. Zou, Y. Wang, X. Fu, và Y. Cao, "Dreaming to prune image deraining networks," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, trang 6023–6032.
[61] Y. Liu, Z. Shu, Y. Li, Z. Lin, F. Perazzi, và S.-Y. Kung, "Content-aware gan compression," trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, trang 12 156–12 166.
[62] J. Park và A. No, "Prune your model before distill it," trong Proceedings of the European Conference on Computer Vision. Springer, 2022, trang 120–136.
[63] Y. Bengio, N. Léonard, và A. Courville, "Estimating or propagating gradients through stochastic neurons for conditional computation," arXiv preprint arXiv:1308.3432, 2013.
[64] A. Krizhevsky, "Learning multiple layers of features from tiny images," Master's thesis, University of Toronto, 2009.
[65] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein và các cộng sự, "Imagenet large scale visual recognition challenge," International journal of computer vision, tập 115, số 3, trang 211–252, 2015.
[66] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga và các cộng sự, "Pytorch: An imperative style, high-performance deep learning library," trong Advances in Neural Information Processing Systems, tập 32, 2019.
[67] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand, M. Andreetto, và H. Adam, "MobileNets: Efficient convolutional neural networks for mobile vision applications," arXiv preprint arXiv:1704.04861, 2017.

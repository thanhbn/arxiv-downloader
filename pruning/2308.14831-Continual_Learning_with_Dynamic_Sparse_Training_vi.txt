Học liên tục với Huấn luyện Thưa thớt Động: Khám phá các Thuật toán cho Cập nhật Mô hình Hiệu quả

Murat Onur Yildirim¹, Elif Ceren Gok Yildirim¹, Ghada Sokar¹, Decebal Constantin Mocanu², Joaquin Vanschoren¹

¹Đại học Công nghệ Eindhoven, ²Đại học Luxembourg

m.o.yildirim@tue.nl, e.c.gok@tue.nl, g.a.z.n.sokar@tue.nl,
decebal.mocanu@uni.lu, j.vanschoren@tue.nl

Học liên tục (CL) đề cập đến khả năng của một hệ thống thông minh để tuần tự thu nhận và duy trì kiến thức từ một luồng dữ liệu với chi phí tính toán ít nhất có thể. Để đạt được điều này; các phương pháp tiếp cận chính quy hóa, phát lại, kiến trúc và cô lập tham số đã được giới thiệu vào tài liệu. Cô lập tham số sử dụng một mạng thưa thớt cho phép phân bổ các phần riêng biệt của mạng nơ-ron cho các nhiệm vụ khác nhau và cũng cho phép chia sẻ tham số giữa các nhiệm vụ nếu chúng tương tự. Huấn luyện Thưa thớt Động (DST) là một cách nổi bật để tìm ra những mạng thưa thớt này và cô lập chúng cho từng nhiệm vụ. Bài báo này là nghiên cứu thực nghiệm đầu tiên điều tra tác động của các thành phần DST khác nhau dưới mô hình CL để lấp đầy một khoảng trống nghiên cứu quan trọng và làm sáng tỏ cấu hình tối ưu của DST cho CL nếu nó tồn tại. Do đó, chúng tôi thực hiện một nghiên cứu toàn diện trong đó chúng tôi điều tra các thành phần DST khác nhau để tìm ra cấu trúc tối nhất cho mỗi nhiệm vụ trên các điểm chuẩn CIFAR100 và miniImageNet nổi tiếng trong thiết lập CL tăng dần theo nhiệm vụ vì trọng tâm chính của chúng tôi là đánh giá hiệu suất của các tiêu chí DST khác nhau, thay vì quá trình lựa chọn mặt nạ. Chúng tôi phát hiện ra rằng, ở mức độ thưa thớt thấp, khởi tạo Erdős-Rényi Kernel (ERK) sử dụng xương sống hiệu quả hơn và cho phép học hiệu quả các bước tăng dần của nhiệm vụ. Ở mức độ thưa thớt cao, trừ khi nó quá cực đoan, khởi tạo đồng nhất thể hiện hiệu suất đáng tin cậy và mạnh mẽ hơn. Về mặt chiến lược tăng trường; hiệu suất phụ thuộc vào chiến lược khởi tạo được xác định và mức độ thưa thớt. Cuối cùng, khả năng thích ứng trong các thành phần DST là một cách hứa hẹn cho những người học liên tục tốt hơn.

1. Giới thiệu

Học liên tục (CL) là một phương pháp phát triển các mô hình có thể học và thích ứng liên tục từ một luồng dữ liệu, hoặc nhiệm vụ, không giống như học theo lô tiêu chuẩn đòi hỏi truy cập đồng thời vào dữ liệu của tất cả các danh mục. Do đó, nó cho phép học hiệu quả và tránh lưu trữ lượng lớn dữ liệu. Tuy nhiên, điều này thường đi kèm với một cái giá, được gọi là quên lãng thảm khốc, sự suy giảm thông tin đã học trước đó khi người học sâu tập trung vào học những thông tin mới. Bốn phương pháp tiếp cận chính đã được khám phá để giải quyết vấn đề này. Chính quy hóa [1-5] ngăn chặn những thay đổi đột ngột trong trọng số mạng nơ-ron. Phát lại lưu trữ một số mẫu thực [6-8] hoặc tạo ra một số mẫu tổng hợp bằng cách học phân phối dữ liệu [9-12] cho mỗi lớp và lặp lại chúng. Mở rộng kiến trúc [13-17] sửa đổi kiến trúc mạng, thường bằng cách thêm các thành phần mạng bổ sung. Cô lập tham số [18-27] phân vùng mạng nơ-ron thành các mạng con được dành riêng cho các nhiệm vụ khác nhau và đóng băng trọng số của các mạng con cho phép bảo tồn kiến thức đã học trước đó. Trong bài báo này¹, chúng tôi tập trung vào phương pháp cô lập tham số do việc sử dụng dung lượng mạng cố định, xu hướng quên thấp và hiệu quả về bộ nhớ và tính toán.

Cô lập tham số thường đóng băng các kết nối của các mạng con trước đó và chỉ cập nhật những cái mới được thêm vào để có thể học mạng con hiện tại. Nó có thể được thực hiện thông qua học mặt nạ [18,19], cắt tỉa lặp [20-22] hoặc huấn luyện thưa thớt động (DST) [23-27]. Học mặt nạ sử dụng một xương sống dày đặc cố định, thường được huấn luyện trước, và chỉ có ý định tìm ra mặt nạ tốt nhất cho một nhiệm vụ nhất định. Cắt tỉa lặp huấn luyện một mạng dày đặc và sau đó lặp đi lặp lại loại bỏ các trọng số không hứa hẹn với độ lớn nhỏ nhất trong khi DST nhằm huấn luyện mạng thưa thớt từ đầu và tìm ra cấu trúc tốt nhất đồng thời bằng cách loại bỏ và phát triển các thành phần khác nhau của mạng trong quá trình huấn luyện để khám phá cấu trúc thưa thớt tốt nhất. Nó giảm số lượng tham số theo cấp số nhân trong cả quá trình huấn luyện và suy luận mà không ảnh hưởng đến độ chính xác [28]. DST có thể được thực hiện ở cấp nơ-ron hoặc cấp kết nối được gọi là cắt tỉa có cấu trúc và không có cấu trúc tương ứng. Mặc dù cắt tỉa có cấu trúc cho phép các mạng con hiệu quả hơn về mặt tính toán, nhưng nó đã được chứng minh là hoạt động kém hơn so với cắt tỉa không có cấu trúc ở mức độ thưa thớt cao hơn [29] điều này dành nhiều không gian hơn cho các nhiệm vụ tiếp theo trong mạng.

DST đã nổi lên như một kỹ thuật hứa hẹn để tăng cường hiệu quả và khả năng khái quát hóa của mạng nơ-ron bằng cách cắt tỉa động và làm thưa thớt các tham số mạng trong quá trình huấn luyện cho học theo lô tiêu chuẩn. Tuy nhiên, khi áp dụng cho CL, các thiết lập tiêu chuẩn của DST cho học theo lô có thể không khai thác đầy đủ tiềm năng của nó. Việc điều tra các thành phần khác nhau của DST dưới thiết lập CL là cần thiết vì một số lý do. Thứ nhất, học liên tục đòi hỏi việc duy trì kiến thức thu được từ các nhiệm vụ trước đó, điều này có thể đòi hỏi các chiến lược cắt tỉa và khởi tạo lại khác nhau. Thứ hai, các chiến lược tối ưu cho DST có thể khác nhau trong bối cảnh học liên tục, nơi các nhiệm vụ đến tuần tự và nhiều hơn một mạng con nên được học tăng dần, sử dụng cùng một xương sống. Cuối cùng, các tình huống học liên tục thường liên quan đến sự mất cân bằng lớp, dịch chuyển khái niệm và độ phức tạp nhiệm vụ khác nhau, điều này có thể đòi hỏi các phương pháp tiếp cận tùy chỉnh cho độ thưa thớt động. Do đó, bằng cách khám phá và thích ứng các yếu tố khác nhau của DST với học liên tục, chúng ta có thể mở khóa tiềm năng đầy đủ của nó để giảm thiểu các thách thức của CL và cải thiện hiệu quả và hiệu suất của mạng nơ-ron trong các tình huống học suốt đời. Do đó, trong bài báo này, chúng tôi đã tiến hành các thí nghiệm quy mô lớn trên CIFAR100 và miniImageNet với các xương sống khác nhau và số lượng nhiệm vụ khác nhau. Chúng tôi phân tích hiệu suất DST không có cấu trúc trong CL về độ chính xác tăng dần, chuyển giao ngược và chuyển giao tiến dưới các mức độ thưa thớt, khởi tạo và chiến lược tăng trường khác nhau. Chúng tôi tập trung vào CL tăng dần theo nhiệm vụ vì chúng tôi đặc biệt muốn quan sát hiệu suất của các tiêu chí DST khác nhau, không phải quá trình lựa chọn mặt nạ. Những phát hiện của chúng tôi là:

I. Ở mức độ thưa thớt thấp đến trung bình (80-90%), khởi tạo Erdős-Rényi Kernel (ERK) sử dụng xương sống hiệu quả hơn bằng cách sử dụng tiết kiệm các kết nối trong các lớp hẹp cho phép học hiệu quả các bước tăng dần của nhiệm vụ.

II. Ở mức độ thưa thớt cao (95%), trừ khi nó quá cực đoan (99%), khởi tạo đồng nhất thể hiện hiệu suất tăng dần mạnh mẽ hơn bằng cách duy trì hiệu suất ổn định qua các nhiệm vụ.

III. Từ quan điểm chiến lược tăng trường, kết quả hiệu suất phụ thuộc vào chiến lược khởi tạo được xác định và mức độ thưa thớt.

IV. Chưa có phương thuốc vạn năng nào cho DST trong CL và việc lựa chọn các tiêu chí DST một cách thích ứng cho mỗi nhiệm vụ có hứa hẹn để tăng cường hiệu suất, so với các chiến lược được xác định trước cho tất cả các nhiệm vụ. Chúng tôi chỉ ra rằng một sự thay đổi ngây thơ giữa các chiến lược tăng trường khác nhau làm tăng hiệu suất tăng dần.

2. Bối cảnh và Nghiên cứu Liên quan

DST cho Học theo Lô Tiêu chuẩn. Huấn luyện thưa thớt động là một kỹ thuật để đạt được một mạng thưa thớt trong đó mô hình được khởi tạo với một cấu trúc thưa thớt ngẫu nhiên và sau đó các kết nối được cắt tỉa và phát triển động trong quá trình huấn luyện để cải thiện hiệu quả tính toán và hiệu suất khái quát hóa [28]. Điều này liên quan đến một khoảng thời gian cập nhật của cấu trúc mạng và một chiến lược loại bỏ/tăng trường để khám phá mạng trong một mức độ thưa thớt được xác định trước trong khi giảm thiểu hàm mất mát bằng cách bảo tồn các trọng số quan trọng cho một nhiệm vụ nhất định. Bằng cách giảm số lượng kết nối, huấn luyện thưa thớt động có thể tăng tốc độ huấn luyện và giảm yêu cầu bộ nhớ trong khi duy trì hoặc thậm chí cải thiện độ chính xác của mô hình [30].

SET [28] là nghiên cứu tiên phong của DST và khám phá một mẫu kết nối thưa thớt tối ưu trong quá trình huấn luyện bằng cách giới thiệu khởi tạo Erdős-Rényi (ER) và tăng trường ngẫu nhiên. Khởi tạo ER gán nhiều kết nối hơn cho các lớp nhỏ hơn trong khi phân bổ ít kết nối hơn cho các lớp lớn trong Perceptron Đa lớp (MLP) với ϵ(nl−1+nl)/(nl−1nl) nơi nl biểu thị số lượng nơ-ron ở lớp l và ϵ chỉ ra mức độ thưa thớt. Tăng trường ngẫu nhiên kết nối ngẫu nhiên một số lượng bằng nhau các trọng số được loại bỏ dựa trên độ lớn của chúng để khám phá một cấu trúc thưa thớt mới. Lấy cảm hứng từ SET, RigL [31] và SNFS [32] đã giới thiệu tăng trường gradient và tăng trường momentum: ý tưởng sử dụng thông tin gradient và momentum thu được bằng đường truyền ngược là để phát triển các kết nối hứa hẹn có thể tăng tốc việc khám phá cấu trúc thưa thớt tối ưu. Mặc dù tăng trường gradient và momentum tăng tốc việc khám phá cấu trúc thưa thớt tối ưu, chúng đòi hỏi một đường truyền ngược dày đặc để sử dụng thông tin của cả các kết nối hiện có và không tồn tại. Để cải thiện điều này, Top-KAST [33] đã chọn sử dụng các gradient tương ứng với một tập con của các kết nối không tồn tại. Hơn nữa, [34,35] nghiên cứu kỹ lưỡng huấn luyện thưa thớt động và các cấu trúc thưa thớt, và phát hiện ra rằng hiệu suất của các mạng thưa thớt có thể vượt trội hơn các đối tác dày đặc.

DST cho Học Liên tục. Nghiên cứu trước đây [36] đã chỉ ra rằng việc thu nhỏ và mở rộng dung lượng mô hình một cách động hiệu quả tránh được việc cắt tỉa quá mức, so với việc cắt tỉa lặp qua các nhiệm vụ tuần tự. Do đó, Huấn luyện Thưa thớt Động là một phương pháp Cô lập Tham số khả thi cho Học Liên tục vì nó có thể gán các thành phần cụ thể cho các nhiệm vụ khác nhau trong khi khám phá mạng với các cấu trúc khác nhau. SpaceNet [23] và AFAF [24] chọn sử dụng DST một cách có cấu trúc để khám phá cấu trúc thưa thớt tốt nhất ở cấp độ nơ-ron trong khi NISPA [25], WSN [26] và SparCL [27] thực hiện nó một cách không có cấu trúc đó là tìm kiếm cấp độ kết nối. SpaceNet cho phép có các đơn vị chung hạn chế giữa các mạng con để ngăn chặn sự can thiệp giữa các nhiệm vụ trong khi NISPA, WSN và AFAF khai thác các đơn vị từ các mạng con trước đó đầy đủ để sử dụng xương sống hiệu quả và cũng chuyển giao kiến thức có liên quan. NISPA chọn các kết nối ứng viên một cách ngẫu nhiên trong khi WSN chọn chúng dựa trên các gradient. Để cho phép CL trên thiết bị thực tế, SparCL tích hợp độ thưa thớt trọng số với việc loại bỏ dữ liệu và độ thưa thớt gradient.

Tuy nhiên, trong các tình huống CL, không có nghiên cứu nào trong số đó đã khám phá rộng rãi tác động của các chiến lược khởi tạo, loại bỏ và tăng trường khác nhau có ảnh hưởng cao đến cấu trúc mạng nơ-ron thưa thớt cuối cùng và hiệu suất.

3. Phương pháp

Trong phần này, chúng tôi đưa ra một cái nhìn tổng quan về DST và ứng dụng của nó trong bối cảnh CL nơi mục tiêu là học và duy trì kiến thức từ một chuỗi các nhiệm vụ mà không quên lãng thảm khốc. Chúng tôi trình bày công thức cơ bản và các mục tiêu tối ưu hóa hướng dẫn việc khám phá các siêu tham số và lựa chọn thiết kế trong khuôn khổ này.

Tổng quan. Như được hiển thị trong Hình 1, DST Liên tục bắt đầu với một mạng nơ-ron có quá nhiều tham số trong đó chúng tôi tìm kiếm các mạng con cụ thể cho nhiệm vụ và chỉ thay đổi các trọng số không được huấn luyện trên các nhiệm vụ trước đó. Nói cách khác, chúng tôi đóng băng các tham số của mạng con đã chọn sau khi huấn luyện để ngăn chặn quên lãng thảm khốc nhưng chúng tôi cho phép sử dụng những tham số đóng băng đó trong các nhiệm vụ tiếp theo. Điều này hỗ trợ việc chuyển giao kiến thức trước đó cho các nhiệm vụ tương lai, còn được gọi là chuyển giao tiến. Điều này đặc biệt quan trọng đối với các vấn đề học liên tục quy mô lớn vì nó giảm thời gian cần thiết để hội tụ trong quá trình học tuần tự.

DST Liên tục. CL liên quan đến việc cập nhật một mạng nơ-ron với một chuỗi các nhiệm vụ học T1:t = (T1,T2, ...,Tt), mỗi nhiệm vụ có một tập dữ liệu tương ứng DT = (xi,t, yi,t)nt bao gồm nt phiên bản cho mỗi nhiệm vụ. Khi gặp một nhiệm vụ học mới, một mạng sâu được tối ưu hóa để ánh xạ phiên bản đầu vào vào không gian phân loại, được ký hiệu là fΘ:Xt→ Yt, nơi Θ đại diện cho các tham số của mạng. Lưu ý rằng, các nhiệm vụ học loại trừ lẫn nhau, tức là Yt−1∩ Yt=∅ và chúng tôi giả định rằng danh tính nhiệm vụ được đưa ra trong cả giai đoạn huấn luyện và thử nghiệm. Mục tiêu của DST Liên tục là học hiệu quả mạng con bằng cách giải quyết bài toán tối ưu hóa giảm thiểu hàm sau:

M*t = arg min Mt L(Θs, nt) = arg min Mt Σi=1^nt [CE(f(xi,t; Θs), yi,t)] (1)

Ở đây, L(Θs, nt) là hàm mất mát, là Cross-Entropy (CE) trong các thí nghiệm của chúng tôi, với một phần được xác định trước của các tham số Θs, và bằng cách giải quyết bài toán tối ưu hóa này, mặt nạ Mt được xác định. Lưu ý rằng, mặc dù độ thưa thớt cho mỗi nhiệm vụ được xác định trước, việc sử dụng tổng thể của xương sống phụ thuộc vào nhiệm vụ và có liên quan chặt chẽ đến mức độ các nhiệm vụ chia sẻ kiến thức đã học. Do đó, độ thưa thớt tổng thể trên xương sống tăng lên một cách tự nhiên nhưng độ thưa thớt cho mỗi nhiệm vụ sẽ giống nhau cho mỗi nhiệm vụ.

Khởi tạo Thưa thớt. Chúng tôi xem xét các chiến lược sau đây cho việc khởi tạo thưa thớt của mạng.

Đồng nhất: Độ thưa thớt của mỗi lớp, được ký hiệu là s, tương đương với độ thưa thớt mạng tổng thể, được biểu thị bằng S.

Erdős-Rényi Kernel (ERK) [31]: Lấy cảm hứng từ khởi tạo Erdős-Rényi [28], ERK được công thức hóa là ϵ(nl−1+nl+wl+hl)/(nl−1nlwlhl) nơi ϵ chỉ ra mức độ thưa thớt, nl biểu thị số lượng nơ-ron ở lớp l, wl và hl là chiều rộng và chiều cao của kernel tích chập thứ l. Nó phân bổ độ thưa thớt cao hơn cho các lớp có nhiều tham số hơn và độ thưa thớt thấp hơn cho các lớp có ít tham số hơn trong khi giữ tổng độ thưa thớt ở mức S. Độ thưa thớt của các lớp được kết nối đầy đủ tuân theo các quy tắc tương tự của Erdős-Rényi gốc.

Cập nhật Cấu trúc. Việc cập nhật cấu trúc nên cân bằng sự đánh đổi giữa khám phá và khai thác để có được các cấu trúc thưa thớt tốt hơn. Lịch trình cập nhật được xác định bởi các tham số sau: (1) ΔT, số lần lặp giữa các cập nhật kết nối thưa thớt (2) Tend, lần lặp mà các cập nhật kết nối thưa thớt nên được dừng (3) α, tỷ lệ ban đầu của các kết nối được cập nhật, và (4) fdecay, một hàm được gọi mỗi lần lặp ΔT để giảm dần tỷ lệ các kết nối được cập nhật theo thời gian. Tương tự như các nghiên cứu trước đây [25,31,32,34], chúng tôi sử dụng Cosine Annealing fdecay(t, α, Tend) = α/2(1 + cos(tπ/Tend)) cho việc cập nhật cấu trúc.

Loại bỏ và Tăng trường. Chúng tôi xem xét các chiến lược loại bỏ và tăng trường sau đây để cập nhật cấu trúc.

Loại bỏ dựa trên độ lớn [37]: Nó liên quan đến việc xác định và loại bỏ các kết nối có độ lớn thấp nhất hoặc 'tầm quan trọng' dựa trên một mức độ thưa thớt hoặc ngưỡng được xác định trước.

Tăng trường ngẫu nhiên [28]: Nó ngẫu nhiên thêm các kết nối mới vào mạng và không tính đến bất kỳ thông tin cụ thể nào về hành vi hoặc hiệu suất của mạng.

Tăng trường chưa kích hoạt: Nó ngẫu nhiên thêm các kết nối mới chưa được sử dụng hoặc 'kích hoạt' trước đó.

Tăng trường gradient [31]: Nó liên quan đến việc thêm các kết nối mới dựa trên các giá trị gradient của các kết nối trong quá trình huấn luyện. Các kết nối có gradient cao hơn hoặc những kết nối đóng góp nhiều hơn vào việc giảm lỗi của mạng được xem xét để tăng trường.

Tăng trường momentum [32]: Nó xem xét cả gradient hiện tại và gradient tích lũy từ các cập nhật trước đó để làm mượt các cập nhật theo thời gian. Các kết nối có momentum cao hơn được xem xét để tăng trường vì chúng hứa hẹn hơn để giảm lỗi của mạng.

Các kỹ thuật tăng trường gradient và momentum có thể tăng tốc việc tìm kiếm một mạng con tối ưu nhưng chúng đòi hỏi một đường truyền ngược dày đặc kết hợp thông tin từ cả các kết nối hiện có và không tồn tại.

4. Thiết lập Thí nghiệm

Trong phần này, chúng tôi mô tả ngắn gọn thiết lập thí nghiệm của chúng tôi bao gồm các tập dữ liệu được sử dụng, các chỉ số được sử dụng để đánh giá và các chi tiết triển khai đảm bảo tính có thể tái tạo và tính hợp lệ của kết quả.

Tập dữ liệu. Trong bài báo này, chúng tôi muốn tạo ra các tình huống với số lượng nhiệm vụ khác nhau để xem tác động của các chiến lược DST trong các điều kiện khác nhau. Để làm điều này, chúng tôi thí nghiệm với CIFAR100 [38] và miniImageNet [39] bao gồm các đối tượng từ 100 danh mục khác nhau. Chúng tôi chia CIFAR100 thành 5, 10 và 20 nhiệm vụ riêng biệt với 20, 10 và 5 lớp trong mỗi nhiệm vụ học và đặt tên chúng là 5-task CIFAR100, 10-task CIFAR100 và 20-task CIFAR100 tương ứng. Cuối cùng, đối với một tình huống thách thức hơn, chúng tôi sử dụng 10-task miniImageNet trong đó mô hình học 10 nhiệm vụ với 10 lớp trong mỗi bước tăng dần.

Chỉ số. Chúng tôi sử dụng các chỉ số CL nổi tiếng để đánh giá. Độ chính xác (ACC) [40] đo độ chính xác cuối cùng được tính trung bình trên tất cả các nhiệm vụ nơi AT,i là độ chính xác của nhiệm vụ i sau khi học nhiệm vụ T. Chuyển giao ngược (BWT) [40] đo mức độ quên lãng và sự thay đổi độ chính xác trung bình của mỗi nhiệm vụ sau khi học các nhiệm vụ mới nơi Ai,i là độ chính xác của nhiệm vụ i ngay sau khi học nhiệm vụ i. Chuyển giao tiến (FWT), lấy cảm hứng từ [40], đo mức độ chuyển giao nơi Aj,i là độ chính xác của mạng con đã học trên nhiệm vụ i thực hiện trên nhiệm vụ j, đánh giá mức độ mô hình thực hiện tốt trên các nhiệm vụ tiếp theo khác với các nhiệm vụ nó được huấn luyện.

ACC = 1/T ΣT i=1 AT,i (2)
BWT = 1/(T−1) ΣT−1 i=1 (AT,i−Ai,i) (3)
FWT = 1/(T−i) ΣT i=1 ΣT j=i+1 Aj,i (4)

Chi tiết Triển khai. Chúng tôi triển khai tất cả các phương pháp trong PyTorch [41]. Chúng tôi sử dụng ResNet-18 [42], VGG-like [43] và MobileNetV2 [44] làm xương sống cho tất cả các tập dữ liệu. Đối với kết quả VGG-like và MobileNetV2, vui lòng tham khảo Phụ lục. Chúng tôi chọn không đóng băng batch normalization trong quá trình huấn luyện vì chúng không thể được gán làm các thành phần cụ thể cho nhiệm vụ. Chúng tôi đã xây dựng dựa trên thư viện ITOP [34] được phát triển cho học theo lô tiêu chuẩn. Chúng tôi sử dụng Cosine Annealing cho tỷ lệ loại bỏ bắt đầu từ 0,5. Chúng tôi cập nhật cấu trúc thưa thớt sau mỗi 50, 100, 200 và 400 lần lặp. Chúng tôi đặt số epoch thành 25 cho 20-task CIFAR100 trong khi 100 cho 5-task CIFAR100, 10-task CIFAR100 và 10-task miniImageNet. Chúng tôi sử dụng tối ưu hóa adam và đặt tỷ lệ học ban đầu là 0,001 được giảm đi một hệ số 0,1 sau 1/2 và 3/4 tổng số epoch. Chúng tôi đặt kích thước lô là 128. Chúng tôi chạy thí nghiệm trên ba hạt giống khác nhau và báo cáo giá trị trung bình của chúng.

5. Kết quả

Trong phần này, chúng tôi trình bày phân tích thực nghiệm để điều tra tác động của các thành phần DST khác nhau trong mô hình CL để hiểu cơ chế cơ bản và làm sáng tỏ cấu hình DST tối ưu cho CL. Chúng tôi nghiên cứu trên bốn tình huống riêng biệt với các bước tăng dần khác nhau và tập dữ liệu là 5-task CIFAR100, 10-task CIFAR100, 20-task CIFAR100 và 10-task miniImageNet để quan sát tác động của khởi tạo, tăng trường và lựa chọn thích ứng của nó giữa các nhiệm vụ. Chúng tôi cũng nghiên cứu tần suất cập nhật cấu trúc trong Phụ lục.

5.1. Các chiến lược khởi tạo khác nhau đòi hỏi các mức độ thưa thớt khác nhau.

Kết hợp với các kỹ thuật tăng trường và mức độ thưa thớt khác nhau, chiến lược khởi tạo ảnh hưởng đáng kể đến độ chính xác tăng dần, đặc biệt khi số lượng nhiệm vụ tăng và các nhiệm vụ trở nên phức tạp hơn như 10-Task miniImageNet, 10-Task CIFAR100 và 20-Task CIFAR100. Ở mức độ thưa thớt cao trừ khi nó quá cực đoan (xem Phụ lục), chúng tôi phát hiện ra rằng khởi tạo đồng nhất hoạt động ổn định hơn dưới các chiến lược tăng trường khác nhau so với ERK. Mặc dù các nghiên cứu cô lập tham số hiện có trong học liên tục [25,26] chủ yếu đã sử dụng khởi tạo đồng nhất, phù hợp với phát hiện đầu tiên của chúng tôi, chúng tôi cũng thú vị khi phát hiện ra rằng khởi tạo ERK thể hiện hiệu suất tổng thể tốt dưới mức độ thưa thớt thấp đến trung bình (Hình 2, 3, 4, 5). Cụ thể, khởi tạo đồng nhất bão hòa sau 7 nhiệm vụ, trong khi khởi tạo ERK hoàn thành thành công tất cả 10 nhiệm vụ (Hình 3a, 3d và Hình 4a, 4d). Hiện tượng tương tự cũng được quan sát với 20-Task CIFAR100 nơi khởi tạo đồng nhất bão hòa sau 7 nhiệm vụ một lần nữa, trong khi khởi tạo ERK đạt được sự bão hòa này sau 13 nhiệm vụ cho thấy việc sử dụng xương sống hiệu quả 85% (Hình 2a, 2d).

Lý do đằng sau điều này là thực tế rằng khởi tạo đồng nhất tạo ra một nút thắt cổ chai trong các lớp hẹp. Chúng ta biết rằng khởi tạo đồng nhất gán các kết nối bằng nhau cho mỗi lớp mà không xem xét kích thước lớp và ERK phân bổ nhiều kết nối hơn cho các lớp có nhiều tham số hơn và ít kết nối hơn cho các lớp có ít tham số hơn [28,31]. Sau một số nhiệm vụ nhất định, dung lượng của xương sống để duy trì quá trình học bị ảnh hưởng vì luồng thông tin qua xương sống bị giảm đáng kể cho các nhiệm vụ tiếp theo. Những phát hiện của chúng tôi cung cấp hỗ trợ thực nghiệm cho mối quan hệ giữa độ thưa thớt và luồng thông tin trong thiết lập CL: Cụ thể, trong các tình huống mà mức độ thưa thớt cao, chúng tôi quan sát thấy rằng luồng thông tin vẫn bền vững ngay cả với khởi tạo đồng nhất. Điều này cho thấy rằng mạng duy trì đủ kết nối để hiệu quả thích ứng với các nhiệm vụ mới. Tuy nhiên, khi độ thưa thớt giảm, cho thấy mật độ kết nối cao hơn được gán cho mỗi nhiệm vụ, chúng tôi quan sát thấy một thách thức đáng chú ý trong việc học các nhiệm vụ tương lai khi xương sống được khởi tạo đồng nhất. Do đó, dưới cùng điều kiện, khởi tạo ERK tốt hơn trong việc bảo vệ luồng thông tin bằng cách sử dụng tiết kiệm các kết nối trong các lớp hẹp (xem thêm Phụ lục).

Lưu ý rằng lý do để có những điểm BWT (%) nhỏ này là đóng băng tất cả các kết nối ngoại trừ batch normalization như chúng tôi đã nêu và thảo luận trong Chi tiết Triển khai.

5.2. Chiến lược tăng trường ảnh hưởng đến hiệu suất, gắn liền với khởi tạo và mức độ thưa thớt.

Kết quả thí nghiệm của chúng tôi chỉ ra rằng khi mức độ thưa thớt thấp, khởi tạo ERK với tăng trường ngẫu nhiên và chưa kích hoạt vượt trội hơn các lựa chọn khác (Bảng 1, 2, 3, 4). Trong khi mức độ thưa thớt vừa phải, khởi tạo ERK và đồng nhất đạt được hiệu suất tương tự nơi khởi tạo đồng nhất kết hợp với tăng trường gradient (uniform+gradient) có xu hướng cho thấy hiệu suất tốt hơn một chút (Bảng 2, 3). Trong trường hợp độ thưa thớt cao, phương pháp tiếp cận phổ biến của uniform+gradient [26] đạt được hiệu suất đáng chú ý trong khi sự kết hợp ERK+gradient cũng thể hiện kết quả cạnh tranh (Bảng 2, 3, 4). Tuy nhiên, ở mức độ thưa thớt cao, ERK+random và ERK+unfired thể hiện hiệu suất độ chính xác thấp hơn (Bảng 1, 2, 3, 4). Chúng tôi cũng quan sát thấy rằng khởi tạo đồng nhất có khả năng phục hồi hơn đối với việc lựa chọn chiến lược tăng trường so với khởi tạo ERK (Hình 2, 3, 4, 5).

Nhìn chung, đối với các chiến lược tăng trường trong DST, tăng trường dựa trên gradient và momentum cung cấp hiệu suất tốt hơn so với tăng trường ngẫu nhiên và chưa kích hoạt trong trường hợp độ thưa thớt cao nhưng tăng trường ngẫu nhiên và chưa kích hoạt hoạt động tốt như tăng trường dựa trên gradient và momentum ở độ thưa thớt thấp-trung bình. Lý do đằng sau điều này là các phương pháp dựa trên gradient và momentum có thể kết hợp nhiều thông tin hơn và có thể chọn lọc thêm các kết nối mới giữa các nơ-ron cho phép khám phá nhanh hơn so với tăng trường ngẫu nhiên hoặc chưa kích hoạt cần nhiều thời gian hơn để khám phá và tìm ra các kết nối tốt hơn.

5.3. Khả năng thích ứng cải thiện hiệu suất vì không có phương thuốc vạn năng.

Trong suốt các thí nghiệm của chúng tôi, chúng tôi đã quan sát thấy rằng không có phương pháp tiếp cận thành công toàn cầu về số lượng nhiệm vụ và mức độ thưa thớt khác nhau. Khi số lượng nhiệm vụ cao, việc lựa chọn cả chiến lược khởi tạo và tăng trường trở nên quan trọng, tùy thuộc vào mức độ thưa thớt. Không có khả năng tồn tại một thiết lập DST vạn năng cho tất cả các tập dữ liệu hoặc nhiệm vụ, và không khả thi để thử các lựa chọn khác nhau cho mỗi tình huống do chi phí tính toán và thời gian. Do đó, chúng tôi giả thuyết rằng một phương pháp tiếp cận thích ứng để lựa chọn tiêu chí DST cho mỗi nhiệm vụ nên cải thiện hiệu suất.

Trong thí nghiệm cuối cùng của chúng tôi, chúng tôi xây dựng một chiến lược tăng trường thích ứng ngây thơ với khởi tạo ERK để xác thực giả thuyết của chúng tôi, trong đó tăng trường ngẫu nhiên được triển khai cho năm nhiệm vụ đầu tiên, và tăng trường gradient được chọn cho năm nhiệm vụ tiếp theo trong khi độ thưa thớt cho mỗi nhiệm vụ là 90% trên tập dữ liệu 10-task CIFAR100. Phương pháp thích ứng mang lại hiệu suất tốt hơn khi so sánh với hai đường cơ sở là các chiến lược tăng trường được chọn trước và cố định của ngẫu nhiên và gradient với khởi tạo ERK (Hình 6). Điều này là do trong giai đoạn ban đầu của việc học, có tiềm năng đáng kể để khám phá các tham số mô hình. Do đó, một chiến lược tăng trường ngẫu nhiên có xu hướng hiệu quả và hiệu quả hơn khi không gian khám phá đủ lớn. Tuy nhiên, khi dung lượng mô hình trở nên bão hòa hơn, chiến lược tăng trường gradient trở nên hiệu quả hơn và vượt trội hơn tăng trường ngẫu nhiên dẫn đến hiệu suất tổng thể tốt hơn.

6. Thảo luận

Kết luận. Bài báo này đã trình bày một phân tích toàn diện, nhằm đánh giá các thành phần khác nhau của Huấn luyện Thưa thớt Động trong Học Liên tục. Chúng tôi tập trung vào chiến lược Cô lập Tham số để tìm ra mạng con tốt nhất cho mỗi nhiệm vụ dưới các điều kiện khác nhau ảnh hưởng cao đến các cấu trúc cuối cùng. Thông qua các thí nghiệm quy mô lớn, chúng tôi phát hiện ra rằng việc lựa chọn mức độ thưa thớt, khởi tạo và chiến lược tăng trường ảnh hưởng đáng kể đến hiệu suất tăng dần. Trong những phát hiện của chúng tôi, khi độ thưa thớt thấp, khởi tạo Erdős-Rényi Kernel (ERK) khai thác xương sống hiệu quả, cho phép học liên tục. Tuy nhiên, trừ khi độ thưa thớt quá cực đoan, khởi tạo đồng nhất thể hiện hiệu suất nhất quán và ổn định hơn ở mức độ thưa thớt cao hơn. Hiệu suất của chiến lược tăng trường phụ thuộc vào phương pháp khởi tạo được chọn và mức độ thưa thớt. Là một quan sát cuối cùng, ngay cả việc lựa chọn thích ứng ngây thơ cho tiêu chí DST cho mỗi nhiệm vụ cũng cải thiện hiệu suất tăng dần so với việc sử dụng các chiến lược cố định và được xác định trước cho tất cả các nhiệm vụ. Chúng tôi hy vọng các kết quả thực nghiệm được tìm thấy trong nghiên cứu này sẽ truyền cảm hứng cho cộng đồng đưa ra các quyết định sáng suốt về khả năng áp dụng của các chiến lược này trong các tình huống thế giới thực và mở đường cho các nghiên cứu tương lai trong lĩnh vực này.

Hạn chế và Nghiên cứu Tương lai. Để mở rộng phạm vi của nghiên cứu này, huấn luyện thưa thớt động có cấu trúc cũng nên được phân tích để nắm bắt cơ chế cơ bản của huấn luyện thưa thớt động một cách toàn diện trong học liên tục. Cuối cùng, những cải thiện hiệu suất quan sát được trong học tăng dần là đáng kể với một phương pháp thích ứng đơn giản. Do đó, việc điều tra sâu hơn về các chiến lược DST thích ứng tinh vi hơn hứa hẹn một hướng nghiên cứu rất đầy hứa hẹn.

Lời cảm ơn

Công trình này được hỗ trợ bởi; TAILOR, một dự án được tài trợ bởi chương trình nghiên cứu và đổi mới EU Horizon 2020 dưới GA số 952215, cơ sở hạ tầng điện tử quốc gia Hà Lan với sự hỗ trợ của SURF Cooperative sử dụng số tài trợ EINF-4568, và học bổng MoNE Thổ Nhĩ Kỳ.

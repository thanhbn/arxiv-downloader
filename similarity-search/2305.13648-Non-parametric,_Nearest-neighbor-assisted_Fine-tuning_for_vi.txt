# 2305.13648.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/similarity-search/2305.13648.pdf
# Kích thước tệp: 515986 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Tinh chỉnh không tham số, hỗ trợ láng giềng gần nhất cho
Dịch máy thần kinh
Jiayi Wang∗1, Ke Wang∗2, Yuqi Zhang2, Yu Zhao2, Pontus Stenetorp1
1University College London
2Alibaba DAMO Academy
ucabj45@ucl.ac.uk,{wk258730,chenwei.zyq}@alibaba-inc.com,
kongyu@taobao.com,p.stenetorp@cs.ucl.ac.uk
Tóm tắt
Các thuật toán không tham số, k-láng-giềng-gần-nhất gần đây đã có những tiến bộ để hỗ trợ các mô hình sinh như mô hình ngôn ngữ và bộ giải mã dịch máy. Chúng tôi khám phá liệu các mô hình không tham số như vậy có thể cải thiện các mô hình dịch máy ở giai đoạn tinh chỉnh bằng cách kết hợp thống kê từ dự đoán kNN để thông báo cho các cập nhật gradient cho mô hình dịch cơ sở. Có nhiều phương pháp có thể được sử dụng để kết hợp thống kê kNN và chúng tôi điều tra việc chia tỷ lệ gradient bằng cơ chế cổng, xác suất sự thật cơ bản của kNN, và học tăng cường. Đối với bốn tập dữ liệu dịch máy trong miền tiêu chuẩn, so với tinh chỉnh cổ điển, chúng tôi báo cáo những cải thiện nhất quán của cả ba phương pháp lên đến 1.45BLEU và 1.28BLEU cho dịch Đức-Anh và Anh-Đức tương ứng. Thông qua phân tích định tính, chúng tôi tìm thấy những cải thiện đặc biệt khi dịch các quan hệ ngữ pháp hoặc từ chức năng, dẫn đến tăng tính lưu loát của mô hình.

1 Giới thiệu
Các mô hình láng giềng gần nhất không tham số gần đây đã thành công cho các tác vụ xử lý ngôn ngữ tự nhiên sinh như mô hình hóa ngôn ngữ (Khandelwal et al., 2020) và dịch máy (Khandelwal et al., 2021). Không chỉ vì việc ghi nhớ rõ ràng dữ liệu huấn luyện giúp khái quát hóa, các mô hình ngôn ngữ tự nhiên sinh có thể mở rộng sang các bộ sưu tập văn bản lớn hơn mà không có chi phí huấn luyện bổ sung. Khandelwal et al. (2020) đã giới thiệu dịch máy k-láng-giềng-gần-nhất (kNN-MT): một phương pháp không tham số đơn giản cho dịch máy (MT) thông qua truy xuất láng giềng gần nhất được đề xuất và đã được xác minh tính hiệu quả của nó – cải thiện điểm BLEU khoảng 3 cho dịch từ tiếng Anh sang tiếng Đức và tiếng Trung.

Để dễ dàng thích ứng với đa miền, trong quá trình suy luận, kNN-MT nội suy phân phối softmax cho token đích từ mô hình dịch máy thần kinh (NMT) với phân phối của tập được truy xuất được tạo ra bởi tìm kiếm k-láng-giềng-gần-nhất (kNN) trên kho dữ liệu các ví dụ được lưu trữ. Kho dữ liệu được xây dựng từ các cặp khóa-giá trị của dữ liệu huấn luyện song song, trong đó khóa là biểu diễn ngữ cảnh tiềm ẩn của các token tiền tố đích thu được thông qua tính toán chuyển tiếp ngẫu nhiên của NMT, và giá trị là token đích sự thật cơ bản tương ứng.

Trong các điều tra sơ bộ, chúng tôi quan sát thấy rằng tìm kiếm kNN có thể ghi nhớ các từ nội dung với ý nghĩa từ vựng của ngữ cảnh trong miền. Tuy nhiên, khi dịch các quan hệ ngữ pháp, chẳng hạn như dịch từ chức năng, việc truy vấn kho dữ liệu cho k láng giềng gần nhất là không đủ, điều này có tác động tiêu cực đến tính lưu loát của kết quả dịch cuối cùng.

Hơn nữa, mặc dù kNN-MT có lợi thế là không yêu cầu tinh chỉnh bổ sung, các thí nghiệm của chúng tôi cho thấy kNN-MT không thể vượt trội hoặc thậm chí đạt được hiệu suất có thể so sánh với tinh chỉnh cổ điển (Mou et al., 2016) khi dữ liệu trong miền có thể truy cập được. Điều này là do mô hình dịch máy chưa được tối ưu hóa trên dữ liệu trong miền, và do đó nó hạn chế khả năng của mô hình dịch để sử dụng tìm kiếm kNN. Một cách đơn giản để quan sát thực tế này là áp dụng thuật toán kNN-MT trên mô hình dịch đã được tinh chỉnh, chứ không phải mô hình dịch cơ sở được huấn luyện trên dữ liệu ngoài miền. Như được hiển thị trong Bảng 1 và Bảng 8 ở Phụ lục A, hiệu suất của thuật toán có thể được cải thiện đáng kể khi kho dữ liệu kNN được xây dựng với các biểu diễn ngữ cảnh đã được tinh chỉnh và các khóa tương ứng của chúng. Do đó, tinh chỉnh vẫn cần thiết và nó có lợi cho thuật toán tìm kiếm kNN không tham số.

--- TRANG 2 ---
De-En En-De
Mô hình IT Y tế Luật Koran Trung bình IT Y tế Luật Koran Trung bình
MT cơ sở 38.35 40.14 45.63 16.29 35.10 29.74 35.56 40.85 13.97 30.03
kNN-MT 46.12 54.41 61.70 21.14 45.84 36.44 49.74 55.73 25.87 41.95
MT đã tinh chỉnh 47.14 57.19 61.28 22.98 47.15 39.70 52.50 57.16 32.45 45.45
kNN-FT-MT 49.33 57.46 63.63 22.95 48.34 40.68 53.28 58.91 32.61 46.37

Bảng 1: Hiệu suất của NMT cơ sở và NMT đã tinh chỉnh có và không có tích hợp với tìm kiếm kNN trong quá trình suy luận trong dịch đa miền Đức-Anh (De-En) và Anh-Đức (En-De) tương ứng. Kết quả được báo cáo với chỉ số SacreBLEU (Post, 2018). kNN-MT đại diện cho NMT cơ sở có tích hợp với tìm kiếm kNN trong quá trình suy luận, trong khi kNN-FT-MT đại diện cho NMT đã tinh chỉnh có tích hợp với tìm kiếm kNN trong quá trình suy luận.

Do có cả lợi thế và bất lợi xuất phát từ thuật toán kNN-MT, chúng tôi tiến hành tối đa hóa việc sử dụng kết quả từ tìm kiếm kNN để nâng cao hiệu suất của các mô hình dịch. Chúng tôi giả thuyết rằng quy trình tinh chỉnh của mô hình dịch thần kinh có thể được cải thiện với sự hỗ trợ của thống kê từ dự đoán kNN. Hơn nữa, chúng tôi cũng khám phá việc chia tỷ lệ gradient cho mô hình dịch thần kinh gốc với (1) cơ chế cổng được áp dụng trên phân phối dự đoán kNN, (2) xác suất sự thật cơ bản kNN và (3) học tăng cường dựa trên thống kê của dự đoán kNN.

Dựa trên những quan sát này, chúng tôi đề xuất trainable-kNN-MT để giảm thiểu các vấn đề của kNN-MT gốc (Khandelwal et al., 2021). Trainable-kNN-MT của chúng tôi có thể học dịch có điều kiện trên k-láng-giềng-gần-nhất được truy xuất. Thống kê của tập được truy xuất được kết hợp vào tinh chỉnh mô hình thông qua ba cách được đề cập ở trên để động tự động mở rộng gradient cho lan truyền ngược. Ngoài ra, kho dữ liệu kNN để truy xuất được cập nhật cùng với tinh chỉnh mô hình để tìm kiếm kNN có thể bảo đảm k láng giềng gần nhất chính xác hơn.

Có hai đóng góp chính trong bài báo này:
(1) Trainable-kNN-MT tạo ra các biểu diễn ngữ cảnh mục tiêu tốt hơn của các ví dụ liên quan, điều này cải thiện các tập được truy xuất của top-k láng giềng gần nhất. (2) Trainable-kNN-MT vượt trội đáng kể so với cả thuật toán kNN-MT gốc và tinh chỉnh cổ điển, làm cho nó trở thành một phương pháp tinh chỉnh mới cho dịch máy thần kinh. Ngoài ra, tính lưu loát của bản dịch từ trainable-kNN-MT được cải thiện định tính, trong khi vẫn trung thành hơn với ngôn ngữ gốc.

2 Phương pháp luận
Trong phần này, chúng tôi sẽ giới thiệu mô hình trainable-kNN-MT, có khả năng (1) tạo ra các biểu diễn ngữ cảnh mục tiêu tốt hơn, (2) cải thiện hiệu suất của cả tinh chỉnh vanilla và thuật toán kNN-MT thông qua chia tỷ lệ gradient với sự hỗ trợ của thống kê từ dự đoán kNN.

2.1 Phương pháp sơ bộ
Trước đây, đối với dự đoán của mỗi token đích, cho câu nguồn x và các token tiền tố đích y1:i−1, mô hình NMT dự đoán token đích tiếp theo yi với xác suất PNMT(yi|x, y1:i−1) từ phân phối softmax trên từ vựng.

Trong kNN-MT (Khandelwal et al., 2021), với một chuỗi các token nguồn và một chuỗi các token tiền tố đích (s, t1:i−1) từ dữ liệu trong miền D, mô hình NMT cơ sở được huấn luyện trước xuất các biểu diễn ẩn fkNN(s, t1:i−1) của token đích thứ i ti để xây dựng kho dữ liệu. Định nghĩa của kho dữ liệu như sau:

(K,V) = {(fkNN(s, t1:i−1), ti),∀ti∈t|(s, t)∈ D},

trong đó K đại diện cho tất cả các khóa, trong khi V đại diện cho tất cả các giá trị tương ứng.

Trong quá trình suy luận, cho một chuỗi văn bản nguồn cần được dịch và các token tiền tố đích được tạo ra, kNN-MT sẽ đầu tiên truy xuất top-k láng giềng liên quan từ kho dữ liệu trên dựa trên khoảng cách Euclidean (Danielsson, 1980) giữa biểu diễn ẩn ngữ cảnh của chúng trong bộ giải mã và tất cả các khóa dựa trên fkNN(x, y1:i−1). Tập được truy xuất sau đó được chuyển đổi thành phân phối PkNN(yi|x, y1,i−1) trên từ vựng bằng,

--- TRANG 3 ---
k Láng giềng gần nhất Khoảng cách Đích 10 lệnh 30 hướng dẫn ...... 𝑷𝒌𝑵𝑵 Xác suất Đích 0.5 (𝑀!"") lệnh 0.2 hướng dẫn ...... 𝑷𝑵𝑴𝑻 Xác suất Đích 0.3 lệnh 0.4 hướng dẫn ...... Trainable-kNN-MT Ví dụ huấn luyện Nguồn Đích Delicious-Bibliotheksdaten... Import Delicious ... Um ein Feld aus der Liste … To remove a field ... ... Der watchgnupg… The … Kho dữ liệu Biểu diễn Đích Token Import Delicious ...... thông tin Tạo truy vấn

Ngữ cảnh dịch Befehl im eingebetteten Terminal-Emulator ausführen. Run the Văn bản nguồn 𝒙 Sự thật cơ bản đích 𝒚!𝒊 𝒍𝒐𝒔𝒔 𝒕𝒓𝒂𝒊𝒏𝒂𝒃𝒍𝒆*𝒌𝑵𝑵*𝑴𝑻

Xây dựng kho dữ liệu Tinh chỉnh mô hình

Cập nhật cùng lúc Hỗ trợ mở rộng gradient Truy xuất

Hình 1: Biểu diễn sơ đồ của trainable-kNN-MT. Các mũi tên với đường gãy minh họa quy trình học dịch với sự hỗ trợ của thống kê từ dự đoán kNN.

PkNN(yi|x, y1:i−1)∝ (1)
∑(ki,vi)1yj=vjexp(−d(kj, fkNN(x, y1:i−1)/T))

trong đó j∈[1, k], và kj, vj là khóa và giá trị của các láng giềng được truy xuất tương ứng. T đại diện cho nhiệt độ.

Cuối cùng, dự đoán của token tiếp theo yi dựa trên phép nội suy của các dự đoán từ mô hình NMT và tìm kiếm kNN như sau,

Pcomb(yi|x, y1:i−1) = (2)
λPkNN(yi|x, y1:i−1) + (1 −λ)PNMT(yi|x, y1:i−1)

trong đó λ là một siêu tham số để hợp nhất hai phân phối khác nhau.

2.2 Trainable-kNN-MT
Như đã đề cập trong phần giới thiệu, chúng tôi thấy rằng kNN-MT không đạt được hiệu suất có thể so sánh với tinh chỉnh cổ điển như được minh họa trong Bảng 1. Chúng tôi giả thuyết rằng mô hình NMT cơ sở được huấn luyện trên dữ liệu ngoài miền có thể tạo ra các biểu diễn ngữ cảnh không phù hợp được sử dụng bởi xây dựng kho dữ liệu trong miền và thuật toán tìm kiếm kNN. Kết luận, tinh chỉnh mô hình NMT cơ sở với dữ liệu trong miền vẫn sẽ cần thiết khi dữ liệu trong miền có thể đạt được.

Được truyền cảm hứng từ cả lợi thế và bất lợi của kNN-MT không tham số, chúng tôi đề xuất trainable-kNN-MT bao gồm thống kê từ tìm kiếm kNN như một sự hỗ trợ để mở rộng gradient vào quy trình tinh chỉnh NMT. Nó không chỉ có thể thu hẹp khoảng cách giữa mô hình NMT và tìm kiếm kNN ở một bước xa hơn trong quá trình suy luận, mà còn nâng cao hiệu suất tinh chỉnh vanilla. Chi tiết cụ thể của trainable-kNN-MT được hiển thị trong Hình 1. Nó về cơ bản chứa hai phần: xây dựng kho dữ liệu (trái) và tinh chỉnh mô hình NMT (phải).

Ở giai đoạn tinh chỉnh, kho dữ liệu được xây dựng trên dữ liệu huấn luyện trong miền với các tham số của mô hình NMT, và nó được cập nhật cùng với tinh chỉnh NMT. Sau mỗi số bước tinh chỉnh nhất định, kho dữ liệu được xây dựng lại với các trọng số cập nhật của mô hình NMT. Ở mỗi bước tinh chỉnh, cho một câu nguồn x và các token tiền tố đích sự thật cơ bản y1:i−1, trainable-kNN-MT truy xuất top-k láng giềng gần nhất giống như những gì nó làm trong kNN-MT, và tập được truy xuất của dự đoán kNN được chuyển đổi thành phân phối bằng Phương trình 1, và thống kê của nó hỗ trợ mô hình NMT cách thực hiện lan truyền ngược với chia tỷ lệ gradient.

--- TRANG 4 ---
Ban đầu, huấn luyện mô hình NMT tối ưu hóa các tham số θ thông qua việc tối thiểu hóa mất mát entropy chéo trên tập dữ liệu huấn luyện trong miền D như sau,

L=1/|D|∑(x,y)∈D−logPNMT(yi|x, y1,i−1;θ). (3)

Thay vào đó, đối với trainable-kNN-MT, chúng tôi định nghĩa tổng quát một hàm gkNN(·), tạo ra hệ số chia tỷ lệ gradient có điều kiện trên phân phối của dự đoán kNN. Sau đó, mất mát đề xuất của chúng tôi cho trainable-kNN-MT sẽ như sau,

L=1/|D|∑(x,y)∈D−loggkNNPNMT(yi|x, y1,i−1;θ), (4)

được dịch thành loss trainable-kNN-MT trong Hình 1.

Trong các phần tiếp theo, chúng tôi sẽ mô tả rõ ràng ba cách để chỉ định hàm gkNN(·): (1) cơ chế cổng được áp dụng trên phân phối dự đoán kNN, (2) xác suất sự thật cơ bản kNN và (3) học tăng cường dựa trên thống kê của dự đoán kNN.

2.2.1 Cơ chế cổng
Trong các quan sát sơ bộ của chúng tôi, khi token đích tiếp theo là một từ nội dung có ý nghĩa từ vựng, phân phối của dự đoán kNN thường nghiêng với khối lượng xác suất cao nhất đáng chú ý. Tuy nhiên, hiện tượng như vậy không rõ ràng trong dịch các quan hệ ngữ pháp, chẳng hạn như dịch từ chức năng, dẫn đến phân phối phẳng của đầu ra kNN. Một ví dụ được hiển thị trong Bảng 8. Xác suất của token tiếp theo đúng "you" là 0.201 + 0.028 = 0.229, không đáng chú ý trong phân phối đầu ra kNN. Được thúc đẩy bởi những trường hợp như vậy, chúng tôi giả thuyết rằng mô hình NMT nên học ở mức độ lớn hơn để cải thiện tính lưu loát hoặc phong cách của bản dịch.

Chúng tôi sử dụng xác suất tối đa trong phân phối kNN, được ký hiệu là MkNN, để thiết kế gkNN(·). Khi phân phối của dự đoán kNN phẳng, và MkNN nhỏ hơn một ngưỡng nào đó, gkNN(·) có thể được chỉ định là một hằng số trong khoảng 0 và 1. Vì gkNN trong (0,1), −loggkNNPNMT(yi|x, y1,i−1;θ) trong Phương trình 4 lớn hơn phương trình gốc trong tinh chỉnh NMT vanilla, dẫn đến gradient lớn hơn để cập nhật trọng số của mô hình NMT. Ngược lại, chúng tôi sẽ giữ các tính toán gradient gốc từ tinh chỉnh NMT. Chi tiết, gkNN(·) được định nghĩa như sau,

gkNN=(c nếu MkNN< τ, 1 nếu MkNN≥τ, (5)

trong đó c là một hằng số trong khoảng 0 và 1, và siêu tham số τ đại diện cho ngưỡng cho MkNN, đóng vai trò của một cổng trong việc kiểm soát khi nào đẩy mô hình NMT học dịch ở mức độ lớn hơn. Một cách trực quan để gán giá trị của c có thể là λ từ kNN-MT gốc.

2.2.2 Xác suất sự thật cơ bản kNN
Một bất lợi của cơ chế cổng là sẽ thách thức cho chúng ta đánh giá cách thiết lập ngưỡng τ sẽ ảnh hưởng đến hiệu suất của trainable-kNN-MT, và các điều tra thông qua nghiên cứu loại bỏ chắc chắn cần thiết khi đến với miền mới hoặc ngôn ngữ mới.

Để khắc phục vấn đề như vậy, chúng ta cần tìm ra các giải pháp không chứa bất kỳ siêu tham số nào ràng buộc mạnh mẽ với bất kỳ thống kê cụ thể nào của dự đoán kNN.

Được truyền cảm hứng từ mất mát entropy chéo gốc (Zhang và Sabuncu, 2018), một giải pháp tiềm năng có thể sử dụng xác suất của token đích sự thật cơ bản từ phân phối dự đoán kNN. Nếu xác suất của từ đích sự thật cơ bản từ phân phối dự đoán kNN thấp, thì phù hợp để tăng cường việc học của mô hình NMT, bất kể từ đích tiếp theo là từ nội dung hay từ chức năng.

Sau đó, chúng tôi động tự động đặt gkNN là xác suất của sự thật cơ bản như sau,

gkNN=PkNN(yi|x, y1:i−1). (6)

Tuy nhiên, phương pháp này không hoạt động nếu PkNN(yi|x, y1:i−1) bằng không, có nghĩa là từ đích sự thật cơ bản không được truy xuất bởi tìm kiếm kNN vì lý do nào đó. Trong tình huống như vậy, chúng ta phải đặt tối thiểu của gkNN để tránh sự cố huấn luyện. Như chúng ta biết, trường hợp cực đoan nhất cho phân phối dự đoán kNN sẽ là phân phối đồng đều trong đó tất cả dự đoán đều có khả năng như nhau với xác suất 1/k. Do đó, hợp lý khi đặt gkNN bằng 1/k khi PkNN(yi|x, y1:i−1) bằng không.

2.2.3 Học tăng cường
Thành công của các phương pháp kNN không tham số trong các mô hình sinh dựa trên khả năng rõ ràng của nó trong việc ghi nhớ dữ liệu huấn luyện giúp tăng cường khái quát hóa cho thích ứng miền (Khandelwal et al., 2020, 2021) mà không cần huấn luyện thêm. Nó vượt trội hơn mô hình NMT cơ sở về chất lượng cũng như hiệu quả. Trong các khám phá của chúng tôi, nó có thể duy trì khả năng trang bị mô hình NMT biết khi nào học ở mức độ lớn hơn để dự đoán chính xác về các ngữ cảnh chưa thấy của các miền khác nhau.

Ngoài ra, xem xét rằng tìm kiếm kNN không tham số dựa trên kho dữ liệu được xây dựng trên dữ liệu huấn luyện được gắn nhãn vàng, nó có thể được coi là một mô hình có giám sát của dự đoán dịch. Việc tận dụng khoảng cách giữa tìm kiếm kNN và dự đoán từ mô hình NMT bằng cách tối ưu hóa trực tiếp các biện pháp đánh giá dựa trên tìm kiếm kNN là thiết yếu, điều này rất phù hợp với tinh thần học tăng cường cho dự đoán có cấu trúc trong các mô hình ngôn ngữ tự nhiên sinh (Paulus et al., 2017; Sutton và Barto, 2018; Wu et al., 2018).

Như đã nêu trong Wu et al. (2018), mô hình NMT có thể được xem như một tác nhân, tương tác với môi trường với các từ trước đó y1:i−1 và các biểu diễn ngữ cảnh tương ứng ở mỗi bước huấn luyện. Các tham số của tác nhân định nghĩa một chính sách, một xác suất có điều kiện PNMT(yi|x, y1:i−1), và tác nhân sẽ chọn một hành động, đó là một từ ứng viên từ từ vựng, theo chính sách.

Khác với thiết lập phần thưởng là BLEU (Papineni et al., 2002) trong Wu et al. (2018), trong trainable-kNN-MT của chúng tôi, phần thưởng cho mô hình NMT là xác suất tương ứng từ phân phối dự đoán kNN, được ký hiệu là R(ŷi, yi), được định nghĩa bằng cách so sánh ŷi được tạo ra với câu sự thật cơ bản yi theo xác suất tương ứng của chúng trong phân phối dự đoán kNN. Lưu ý rằng phần thưởng R(ŷi, yi) hiện là phần thưởng cấp token, một vô hướng cho token được tạo ra ŷi, tạo ra một khác biệt khác so với Wu et al. (2018).

Do đó, mục tiêu của tinh chỉnh trong khung học tăng cường như vậy là tối thiểu hóa phần thưởng kỳ vọng như sau,

L= (7)
1/|D|∑(x,y)∈D−R(ŷi, yi) logPNMT(yi|x, y1:i−1),

trong đó R(ŷi, yi) được định nghĩa là,

R(ŷi,yi) = (8)
|PkNN(ŷi|x, y1:i−1)−PkNN(yi|x, y1:i−1)|.

Khi R(ŷi, yi) bằng không, nó dẫn đến sự cố huấn luyện trong thiết kế hiện tại. Có nghĩa là hoặc ŷi đúng hoặc cả ŷi và sự thật cơ bản yi đều không được truy xuất từ tìm kiếm kNN. Nếu trong tình huống đầu tiên, chúng tôi sẽ giữ tính toán mất mát từ tinh chỉnh NMT vanilla cho token được tạo ra. Nếu không, R(ŷi, yi) sẽ được đặt thành 1/k với lý do tương tự được nêu trong phương pháp xác suất sự thật cơ bản kNN.

3 Thí nghiệm
Trong phần này, chúng tôi sẽ mô tả thiết kế thí nghiệm và báo cáo và thảo luận về kết quả thí nghiệm và phát hiện.

3.1 Dữ liệu
Chúng tôi tiến hành thí nghiệm của trainable-kNN-MT trên các tác vụ dịch Đức-Anh, tiếp tục trên cùng con đường như kNN-MT (Khandelwal et al., 2021), bao gồm các miền IT, Y tế, Luật và Koran. Chúng tôi cũng tiến hành thí nghiệm trên các tác vụ dịch Anh-Đức để đánh giá hiệu suất của trainable-kNN-MT trên tác vụ dịch từ tiếng Anh. Chúng tôi sử dụng cùng tập dữ liệu như các tác vụ dịch Đức-Anh, nhưng hoán đổi phía nguồn và đích.

Để tiền xử lý dữ liệu, chúng tôi thực hiện lọc độ dài tối đa với 250 trên tất cả dữ liệu huấn luyện trong miền để đảm bảo chất lượng dữ liệu. Thống kê của các tập dữ liệu trong miền được hiển thị trong Bảng 3.

--- TRANG 5 ---
Nguồn Ist diese Einstellung aktiv, werden Benachrichtigungen wie zum Beispiel Sperren des Bildschirms oder Änderungen des Profils durch ein passives Meldungsfenster angezeigt.
Tham chiếu If checked, you will be notified through a passive popup whenever PowerDevil has to notify something, such as screen locking or profile change.
Từ phụ T@@ tab you noti@@ hin@@ you promp@@ de@@
Xác suất 0.344 0.236 0.201 0.096 0.054 0.028 0.022 0.019

Bảng 2: Ví dụ về dự đoán kNN với k= 8 trong tập xác thực IT Đức-Anh. Các token tiền tố đích được tạo ra là "If checked,", và token tiếp theo đúng phải là "you". Các ứng viên từ phụ trong Mã hóa Cặp Byte (Sennrich et al., 2016) được truy xuất thông qua tìm kiếm kNN với xác suất tương ứng.

để ghi nhớ dữ liệu huấn luyện giúp tăng cường khái quát hóa cho thích ứng miền (Khandelwal et al., 2020, 2021) mà không cần huấn luyện thêm. Nó vượt trội hơn mô hình NMT cơ sở về chất lượng cũng như hiệu quả. Trong các khám phá của chúng tôi, nó có thể duy trì khả năng trang bị mô hình NMT biết khi nào học ở mức độ lớn hơn để dự đoán chính xác về các ngữ cảnh chưa thấy của các miền khác nhau.

Ngoài ra, xem xét rằng tìm kiếm kNN không tham số dựa trên kho dữ liệu được xây dựng trên dữ liệu huấn luyện được gắn nhãn vàng, nó có thể được coi là một mô hình có giám sát của dự đoán dịch. Việc tận dụng khoảng cách giữa tìm kiếm kNN và dự đoán từ mô hình NMT bằng cách tối ưu hóa trực tiếp các biện pháp đánh giá dựa trên tìm kiếm kNN là thiết yếu, điều này rất phù hợp với tinh thần học tăng cường cho dự đoán có cấu trúc trong các mô hình ngôn ngữ tự nhiên sinh (Paulus et al., 2017; Sutton và Barto, 2018; Wu et al., 2018).

Như đã nêu trong Wu et al. (2018), mô hình NMT có thể được xem như một tác nhân, tương tác với môi trường với các từ trước đó y1:i−1 và các biểu diễn ngữ cảnh tương ứng ở mỗi bước huấn luyện. Các tham số của tác nhân định nghĩa một chính sách, một xác suất có điều kiện PNMT(yi|x, y1:i−1), và tác nhân sẽ chọn một hành động, đó là một từ ứng viên từ từ vựng, theo chính sách.

Khác với thiết lập phần thưởng là BLEU (Papineni et al., 2002) trong Wu et al. (2018), trong trainable-kNN-MT của chúng tôi, phần thưởng cho mô hình NMT là xác suất tương ứng từ phân phối dự đoán kNN, được ký hiệu là R(ŷi, yi), được định nghĩa bằng cách so sánh ŷi được tạo ra với câu sự thật cơ bản yi theo xác suất tương ứng của chúng trong phân phối dự đoán kNN. Lưu ý rằng phần thưởng R(ŷi, yi) hiện là phần thưởng cấp token, một vô hướng cho token được tạo ra ŷi, tạo ra một khác biệt khác so với Wu et al. (2018).

Do đó, mục tiêu của tinh chỉnh trong khung học tăng cường như vậy là tối thiểu hóa phần thưởng kỳ vọng như sau,

L= (7)
1/|D|∑(x,y)∈D−R(ŷi, yi) logPNMT(yi|x, y1:i−1),

trong đó R(ŷi, yi) được định nghĩa là,

R(ŷi,yi) = (8)
|PkNN(ŷi|x, y1:i−1)−PkNN(yi|x, y1:i−1)|.

Khi R(ŷi, yi) bằng không, nó dẫn đến sự cố huấn luyện trong thiết kế hiện tại. Có nghĩa là hoặc ŷi đúng hoặc cả ŷi và sự thật cơ bản yi đều không được truy xuất từ tìm kiếm kNN. Nếu trong tình huống đầu tiên, chúng tôi sẽ giữ tính toán mất mát từ tinh chỉnh NMT vanilla cho token được tạo ra. Nếu không, R(ŷi, yi) sẽ được đặt thành 1/k với lý do tương tự được nêu trong phương pháp xác suất sự thật cơ bản kNN.

3 Thí nghiệm
Trong phần này, chúng tôi sẽ mô tả thiết kế thí nghiệm và báo cáo và thảo luận về kết quả thí nghiệm và phát hiện.

3.1 Dữ liệu
Chúng tôi tiến hành thí nghiệm của trainable-kNN-MT trên các tác vụ dịch Đức-Anh, tiếp tục trên cùng con đường như kNN-MT (Khandelwal et al., 2021), bao gồm các miền IT, Y tế, Luật và Koran. Chúng tôi cũng tiến hành thí nghiệm trên các tác vụ dịch Anh-Đức để

--- TRANG 6 ---
Miền IT Y tế Luật Koran
Huấn luyện 177,792 206,804 447,696 14,979
Xác thực 2,000 2,000 2,000 2,000
Kiểm tra 2,000 2,000 2,000 2,000
Kích thước kho dữ liệu De-En 3.10M 5.70M 18.38M 0.45M
Kích thước kho dữ liệu En-De 3.33M 6.13M 18.77M 0.48M

Bảng 3: Kích thước kho dữ liệu và số câu song song trong các tập huấn luyện, xác thực, kiểm tra của mỗi miền, riêng biệt cho tập dữ liệu Đức-Anh (De-En) và Anh-Đức (En-De).

Mô hình IT Y tế Luật Koran Trung bình
MT cơ sở 38.35 40.14 45.63 16.29 35.10
MT đã tinh chỉnh 47.14 57.19 61.28 22.98 47.15
trainable-kNN-MT cơ sở Cơ chế cổng 48.63 57.81 61.42 22.77 47.66
Xác suất sự thật cơ bản 48.14 57.94 62.45 22.87 47.85
RL 47.88 57.33 62.49 23.39 47.77
FT trainable-kNN-MT Cơ chế cổng 48.98 58.20 62.06 22.97 48.05
Xác suất sự thật cơ bản 49.31 58.28 63.41 22.90 48.48
RL 49.51 58.50 63.31 23.09 48.60

Bảng 4: Hiệu suất của trainable-kNN-MT trong tinh chỉnh vanilla, có nghĩa là không có tích hợp tìm kiếm kNN trong quá trình suy luận trên các tập kiểm tra đa miền Đức-Anh. Điểm SacreBLEU được tính trung bình theo miền để so sánh tổng thể. So với tinh chỉnh cổ điển, hiệu suất tổng thể có thể được cải thiện lên đến 1.45 BLEU bởi trainable-kNN-MT.

đánh giá hiệu suất của trainable-kNN-MT trên tác vụ dịch từ tiếng Anh. Chúng tôi sử dụng cùng tập dữ liệu như các tác vụ dịch Đức-Anh, nhưng hoán đổi phía nguồn và đích.

Để tiền xử lý dữ liệu, chúng tôi thực hiện lọc độ dài tối đa với 250 trên tất cả dữ liệu huấn luyện trong miền để đảm bảo chất lượng dữ liệu. Thống kê của các tập dữ liệu trong miền được hiển thị trong Bảng 3.

3.2 Thiết lập thí nghiệm
Các mô hình NMT được huấn luyện trước Trong thiết kế thí nghiệm của chúng tôi, chúng tôi sử dụng các hệ thống chiến thắng được huấn luyện trước của các tác vụ dịch tin tức WMT 2019 Đức-Anh và Anh-Đức (Ng et al., 2019) làm mô hình NMT cơ sở cho trainable-kNN-MT, được triển khai với bộ công cụ Fairseq (Ott et al., 2019) dựa trên kiến trúc Transformer lớn (Vaswani et al., 2017).

Cho mô hình NMT cơ sở được huấn luyện trước trên dữ liệu ngoài miền, chúng tôi áp dụng thuật toán trainable-kNN-MT để tinh chỉnh và so sánh hiệu suất của nó với tinh chỉnh vanilla cổ điển. Ngoài ra, khi mô hình NMT "được huấn luyện trước" là mô hình đã được tinh chỉnh, cũng đáng để đánh giá hiệu suất của trainable-kNN-MT để xem liệu mô hình NMT có thể được tăng cường liên tục bởi thuật toán trainable-kNN-MT, mặc dù mô hình NMT đã được huấn luyện và tối ưu hóa trên các tập dữ liệu trong miền. Đối với bất kỳ trường hợp nào ở trên, chúng tôi tiến hành thí nghiệm của trainable-kNN-MT với ba cách khác nhau về chia tỷ lệ gradient và báo cáo kết quả SacreBLEU có và không có tích hợp tìm kiếm kNN trong quá trình suy luận.

Thiết lập mô hình trainable-kNN-MT được khởi tạo với mô hình NMT được huấn luyện trước và được tinh chỉnh với thuật toán Adam (Kingma và Ba, 2015). Tỷ lệ học được đặt thành 5e-04 hoặc 7e-05 để tinh chỉnh dựa trên mô hình NMT cơ sở hoặc tiếp tục tinh chỉnh dựa trên mô hình đã được tinh chỉnh tương ứng. Tất cả thí nghiệm được chạy trên một card GPU Tesla V-100 với kích thước batch 2048 token và tích lũy gradient của 32 batch. Kho dữ liệu được xây dựng lại với trọng số cập nhật của mô hình NMT sau mỗi epoch huấn luyện, và quy trình này lặp lại cho đến khi mô hình NMT hội tụ.

--- TRANG 7 ---
Mô hình IT Y tế Luật Koran Trung bình
MT cơ sở 38.35 40.14 45.63 16.29 35.10
kNN-MT (Khandelwal et al., 2021) 46.12 54.41 61.70 21.14 45.84
kNN-MT thích ứng (Zheng et al., 2021) 47.20 55.71 62.64 19.39 46.24
CKMT (Wang et al., 2022) 47.94 56.92 62.98 19.92 46.94
kNN-MT mạnh mẽ (Jiang et al., 2022) 48.90 57.28 64.07 20.71 47.74
kNN-KD (Yang et al., 2022) — 56.5 61.89 24.86 —
kNN-FT-MT 49.33 57.46 63.63 22.95 48.34
trainable-kNN-MT cơ sở Cơ chế cổng 49.23 58.00 64.10 23.74 48.77
Xác suất sự thật cơ bản 49.49 58.15 64.48 23.59 48.93
RL 49.14 57.40 64.44 23.68 48.67
FT trainable-kNN-MT Cơ chế cổng 49.96 58.34 64.67 23.81 49.20
Xác suất sự thật cơ bản 49.97 58.39 64.78 23.84 49.25
RL 49.84 58.60 64.99 23.78 49.30

Bảng 5: Hiệu suất của trainable-kNN-MT có tích hợp tìm kiếm kNN trong quá trình suy luận trên các tập kiểm tra đa miền Đức-Anh. FT trainable-kNN-MT vượt trội đáng kể so với tất cả các hệ thống cơ sở với thuật toán tìm kiếm kNN và mang lại cải thiện khoảng 1 so với kNN-FT-MT.

Mô hình IT Y tế Luật Koran Trung bình
MT cơ sở 29.74 35.56 40.85 13.97 30.03
MT đã tinh chỉnh 39.70 52.5 57.16 32.45 45.45
trainable-kNN-MT cơ sở Xác suất sự thật cơ bản 41.17 53.38 57.75 32.45 46.19
RL 40.99 53.33 57.64 32.62 46.15
FT trainable-kNN-MT Xác suất sự thật cơ bản 41.65 54.10 58.41 32.74 46.73
RL 41.53 54.36 58.34 32.70 46.73

Bảng 6: Hiệu suất của trainable-kNN-MT trong tinh chỉnh vanilla trên các tập kiểm tra đa miền Anh-Đức. So với tinh chỉnh cổ điển, hiệu suất tổng thể có thể được cải thiện lên đến 1.28 BLEU bởi trainable-kNN-MT.

Các siêu tham số k, λ và T được điều chỉnh trên tập xác thực của mỗi miền, được hiển thị trong bảng 9 và 10 của phụ lục A. Chúng tôi thực nghiệm đặt τ trong Phương trình 5 thành 0.6 cho mỗi miền dựa trên các nghiên cứu loại bỏ.

Hiệu quả tìm kiếm kNN Về hiệu quả thời gian và lưu trữ, chúng tôi theo Khandelwal et al. (2021) để sử dụng chỉ mục FAISS (Johnson et al., 2021) để đại diện cho kho dữ liệu cụ thể miền và tìm kiếm láng giềng gần nhất, với điều này các khóa có thể được lưu trữ trong các cụm để tăng tốc tìm kiếm và được lượng hóa thành 64-byte cho hiệu quả không gian, và chỉ mục có thể được xây dựng ngoại tuyến thông qua một lần chuyển tiếp duy nhất qua mọi ví dụ trong các tập dữ liệu trong miền đã cho.

Đánh giá Chúng tôi đánh giá hiệu suất của trainable-kNN-MT trong các trường hợp với hai mô hình NMT được huấn luyện trước khác nhau như đã đề cập ở trên và so sánh chúng với tinh chỉnh cổ điển và các mô hình cạnh tranh khác liên quan đến tìm kiếm kNN không tham số. Kết quả cuối cùng được đánh giá với SacreBLEU (Post, 2018) trong thiết lập detokenized phân biệt chữ hoa chữ thường¹.

Trong số này, (1) MT cơ sở đại diện cho mô hình NMT cơ sở, hệ thống chiến thắng của dịch tin tức WMT 2019 (Ng et al., 2019) được huấn luyện với dữ liệu ngoài miền; (2) MT đã tinh chỉnh đại diện cho tinh chỉnh MT cơ sở với tập dữ liệu trong miền;

¹Chúng tôi sử dụng chính xác cùng quy trình đánh giá như kNN-MT.

--- TRANG 8 ---
Mô hình IT Y tế Luật Koran Trung bình
MT cơ sở 29.74 35.56 40.85 13.97 30.03
kNN-MT (Khandelwal et al., 2021) 36.44 49.74 55.73 25.87 41.95
kNN-FT-MT 40.68 53.28 58.91 32.61 46.37
trainable-kNN-MT cơ sở Xác suất sự thật cơ bản 41.22 53.53 59.03 33.53 46.83
RL 41.10 53.40 58.97 33.30 46.69
FT trainable-kNN-MT Xác suất sự thật cơ bản 41.73 54.50 59.21 32.99 47.11
RL 41.73 54.63 59.22 32.88 47.12

Bảng 7: Hiệu suất của trainable-kNN-MT có tích hợp tìm kiếm kNN trong quá trình suy luận trên các tập kiểm tra đa miền Anh-Đức. FT trainable-kNN-MT vượt trội đáng kể so với tất cả các hệ thống cơ sở với thuật toán tìm kiếm kNN và mang lại cải thiện 0.75 BLEU so với kNN-FT-MT.

(3) kNN-MT đại diện cho thuật toán kNN-MT gốc (Khandelwal et al., 2021) được áp dụng cho MT cơ sở; (4) kNN-FT-MT có nghĩa là thuật toán kNN-MT gốc được áp dụng trên MT đã tinh chỉnh, trong đó kho dữ liệu được xây dựng với MT đã tinh chỉnh; (5) trainable-kNN-MT cơ sở đại diện cho tinh chỉnh với trainable-kNN-MT của chúng tôi từ MT cơ sở; (6) FT trainable-kNN-MT có nghĩa là tiếp tục tinh chỉnh với trainable-kNN-MT của chúng tôi từ MT đã tinh chỉnh. Tất cả các hệ thống cạnh tranh khác được liệt kê trong các bảng kết quả được trích dẫn tương ứng.

3.3 Kết quả thí nghiệm
Kết quả không có tích hợp tìm kiếm kNN trong quá trình suy luận. Kết quả thí nghiệm của chúng tôi không có tích hợp tìm kiếm kNN trong quá trình suy luận được tóm tắt trong Bảng 4 và Bảng 6. Đối với cả dịch Đức-Anh và Anh-Đức, trainable-kNN-MT vượt trội đáng kể so với tinh chỉnh cổ điển trong cả trainable-kNN-MT cơ sở và FT trainable-kNN-MT. Đối với dịch Đức-Anh, điểm SacreBLEU được cải thiện tổng quát lên đến 0.7 và 1.45 tương ứng, trong khi đối với dịch Anh-Đức, điểm SacreBLEU được cải thiện 0.74 và 1.28 tương ứng.

Hơn nữa, mặc dù cơ chế cổng hoạt động tương đương với xác suất sự thật cơ bản kNN trong cả trainable-kNN-MT cơ sở và FT trainable-kNN-MT, nó không phải là một phương pháp kinh tế, vì các nghiên cứu loại bỏ về thiết lập siêu tham số τ trong Phương trình 5 luôn cần thiết một khi đến với miền mới hoặc ngôn ngữ mới. Do lý do này, chúng tôi đã thực hiện các nghiên cứu loại bỏ về τ cho dịch Đức-Anh, nhưng chúng tôi không xây dựng các thí nghiệm như vậy trong dịch Anh-Đức.

Kết quả có tích hợp tìm kiếm kNN trong quá trình suy luận. Với tích hợp tìm kiếm kNN trong quá trình suy luận, trainable-kNN-MT cho thấy lợi thế của nó trong nhiều miền, được hiển thị trong Bảng 5 và Bảng 7. Có thể quan sát thấy rằng cả trainable-kNN-MT cơ sở và FT trainable-kNN-MT đều vượt trội đáng kể so với tất cả các hệ thống cơ sở liên quan đến thuật toán tìm kiếm kNN.

trainable-kNN-MT cơ sở vượt trội đáng kể so với kNN-MT gốc và MT đã tinh chỉnh lên đến 3.09 BLEU và 1.78 BLEU tương ứng cho dịch Đức-Anh và 4.88 BLEU và 1.38 BLEU tương ứng cho dịch Anh-Đức. Nó cũng vượt trội hơn kNN-FT-MT trong tất cả bốn miền với trung bình 0.61 BLEU và 0.46 BLEU cho dịch Đức-Anh và Anh-Đức tương ứng.

Hơn nữa, FT trainable-kNN-MT tổng quát vượt trội so với kNN-MT gốc và MT đã tinh chỉnh lên đến 3.46 BLEU và 2.15 BLEU tương ứng cho dịch Đức-Anh và 5.17 BLEU và 1.67 BLEU tương ứng cho dịch Anh-Đức. Nó cũng vượt trội hơn kNN-FT-MT trong tất cả bốn miền với trung bình 1 BLEU và 0.75 BLEU cho dịch Đức-Anh và Anh-Đức tương ứng, điều này xác minh rõ ràng rằng ngay cả khi mô hình NMT đã được tinh chỉnh trên dữ liệu trong miền, thuật toán trainable-kNN-MT tiếp tục cải thiện hiệu suất dịch một cách nhất quán. So với trainable-kNN-MT cơ sở, việc huấn luyện FT trainable-kNN-MT hiệu quả hơn, kinh tế hơn và thực tế hơn.

--- TRANG 9 ---
So sánh giữa các phương pháp chia tỷ lệ gradient. Trong ba phương pháp chia tỷ lệ gradient, khung học tăng cường đạt được tốt nhất trong FT trainable-kNN-MT cho cả dịch Đức-Anh và Anh-Đức, trong khi nó hoạt động tương đương với xác suất sự thật cơ bản kNN trong trainable-kNN-MT cơ sở. Trong khung học tăng cường, điều này hợp lý vì tìm kiếm kNN được coi như một mô hình phần thưởng có giám sát. Thông qua các quan sát sơ bộ, chúng tôi đã phát hiện rằng trong việc truy xuất ứng viên dịch, tìm kiếm kNN từ kho dữ liệu được xây dựng với trọng số mô hình đã được tinh chỉnh có thể đạt được độ chính xác cao hơn so với những kho được xây dựng với trọng số mô hình cơ sở. Mô hình phần thưởng càng tốt, hiệu quả của học tăng cường càng tốt.

Chúng tôi cũng thực hiện phân tích định tính về bản dịch từ FT trainable-kNN-MT so với kNN-FT-MT, vì kNN-FT-MT là mô hình tốt nhất chúng tôi có thể có được trước khi chúng tôi đề xuất trainable-kNN-MT. Thú vị là, chúng tôi thấy rằng khi dịch các quan hệ ngữ pháp, FT trainable-kNN-MT với bất kỳ ba phương pháp chia tỷ lệ gradient nào đều hoạt động tốt hơn kNN-FT-MT, điều này không mong đợi. Các ví dụ được hiển thị trong Bảng 11 của Phụ lục A.

4 Kết luận
Trong bài báo này, chúng tôi đề xuất trainable-kNN-MT để học dịch với sự hỗ trợ của thống kê từ dự đoán kNN không tham số. Nó sử dụng cơ chế cổng, xác suất sự thật cơ bản kNN, và học tăng cường để tận dụng tối đa các lợi thế và bất lợi tương ứng của thuật toán tìm kiếm kNN không tham số. Kết quả thí nghiệm cho thấy trainable-kNN-MT vượt trội đáng kể so với kNN-MT gốc và phương pháp tinh chỉnh cổ điển, làm cho nó trở thành một phương pháp tinh chỉnh mới cho các miền và tác vụ dịch khác nhau.

Tài liệu tham khảo
Per-Erik Danielsson. 1980. Euclidean distance mapping. Computer Graphics and image processing, 14(3):227–248.

Hui Jiang, Ziyao Lu, Fandong Meng, Chulun Zhou, Jie Zhou, Degen Huang, và Jinsong Su. 2022. Towards robust k-nearest-neighbor machine translation. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 5468–5477, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Jeff Johnson, Matthijs Douze, và Hervé Jégou. 2021. Billion-scale similarity search with gpus. IEEE Transactions on Big Data, 7(3):535–547.

Urvashi Khandelwal, Angela Fan, Dan Jurafsky, Luke Zettlemoyer, và Mike Lewis. 2021. Nearest neighbor machine translation. In International Conference on Learning Representations.

Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, và Mike Lewis. 2020. Generalization through memorization: Nearest neighbor language models. In International Conference on Learning Representations.

Diederik P. Kingma và Jimmy Ba. 2015. Adam: A method for stochastic optimization. In 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.

Lili Mou, Zhao Meng, Rui Yan, Ge Li, Yan Xu, Lu Zhang, và Zhi Jin. 2016. How transferable are neural networks in NLP applications? In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 479–489, Austin, Texas. Association for Computational Linguistics.

Nathan Ng, Kyra Yee, Alexei Baevski, Myle Ott, Michael Auli, và Sergey Edunov. 2019. Facebook FAIR's WMT19 news translation task submission. In Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1), pages 314–319, Florence, Italy. Association for Computational Linguistics.

Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, và Michael Auli. 2019. fairseq: A fast, extensible toolkit for sequence modeling. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations), pages 48–53, Minneapolis, Minnesota. Association for Computational Linguistics.

Kishore Papineni, Salim Roukos, Todd Ward, và Wei-Jing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.

Romain Paulus, Caiming Xiong, và Richard Socher. 2017. A deep reinforced model for abstractive summarization. arXiv preprint arXiv:1705.04304.

Matt Post. 2018. A call for clarity in reporting BLEU scores. In Proceedings of the Third Conference on Machine Translation: Research Papers, pages 186–191, Brussels, Belgium. Association for Computational Linguistics.

--- TRANG 10 ---
Rico Sennrich, Barry Haddow, và Alexandra Birch. 2016. Neural machine translation of rare words with subword units. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1715–1725, Berlin, Germany. Association for Computational Linguistics.

Richard S Sutton và Andrew G Barto. 2018. Reinforcement learning: An introduction. MIT press.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems, 30.

Dexin Wang, Kai Fan, Boxing Chen, và Deyi Xiong. 2022. Efficient cluster-based k-nearest-neighbor machine translation. arXiv preprint arXiv:2204.06175.

Lijun Wu, Fei Tian, Tao Qin, Jianhuang Lai, và Tie-Yan Liu. 2018. A study of reinforcement learning for neural machine translation. arXiv preprint arXiv:1808.08866.

Zhixian Yang, Renliang Sun, và Xiaojun Wan. 2022. Nearest neighbor knowledge distillation for neural machine translation. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5546–5556, Seattle, United States. Association for Computational Linguistics.

Zhilu Zhang và Mert Sabuncu. 2018. Generalized cross entropy loss for training deep neural networks with noisy labels. Advances in neural information processing systems, 31.

Xin Zheng, Zhirui Zhang, Junliang Guo, Shujian Huang, Boxing Chen, Weihua Luo, và Jiajun Chen. 2021. Adaptive nearest neighbor machine translation. arXiv preprint arXiv:2105.13022.

A Phụ lục

--- TRANG 11 ---
Nguồn Sie können Writer-Textrahmen so miteinander verketten, dass ihr Inhalt automatisch von einem Rahmen in den nächsten fließt.
Tham chiếu You can link Writer text frames so that their contents automatically flow from one frame to another.
Tiền tố đích You can
kNN-MT Từ phụ. join link chain link use link connect comb@@
Xác suất. 0.379 0.242 0.103 0.093 0.068 0.041 0.037 0.032
kNN-FT-MT Từ phụ. link chain nest nest link link link link
Xác suất. 0.698 0.243 0.029 0.012 0.008 0.003 0.002 0.001

Nguồn Die Quell- und Zielansicht ist der Hauptarbeitsbereich von & kompare;. Hier werden der Inhalt und die hervorgehobenen Abweichungen der aktuell ausgewählten Quell- und Zieldatei mit den Zeilennummern angezeigt.
Tham chiếu The source and destination view is the main workspace of & kompare;. The contents and highlighted differences of the currently selected source and destination file are displayed here with line numbers.
Tiền tố đích The source and destination
kNN-MT Từ phụ. p@@ ann@@ brow@@ view view view view view
Xác suất. 0.679 0.110 0.049 0.039 0.035 0.034 0.025 0.025
kNN-FT-MT Từ phụ. view View view View View View view view
Xác suất. 0.361 0.193 0.159 0.073 0.073 0.048 0.047 0.043

Bảng 8: Ví dụ về dự đoán kNN trong tác vụ dịch miền IT Đức-Anh, trong đó kNN-FT-MT có nghĩa là áp dụng thuật toán kNN-MT trên mô hình NMT đã được tinh chỉnh, Từ phụ. và Xác suất. đại diện cho các token được truy xuất kNN và xác suất tương ứng trong phân phối kNN và Tiền tố đích đại diện cho các token đích tiền tố được tạo ra. Thuật toán tìm kiếm kNN bảo đảm các ứng viên dự đoán chính xác hơn khi mô hình NMT đã được tinh chỉnh với dữ liệu huấn luyện IT.

Mô hình IT Y tế Luật Koran
kNN-MT & trainable-kNN-MT cơ sở k 8 16 16 8
λ 0.6 0.8 0.8 0.6
T 5 5 5 100
kNN-FT-MT & FT trainable-kNN-MT k 8 16 8 8
λ 0.4 0.4 0.6 0.4
T 10 10 10 100

Bảng 9: Các siêu tham số được sử dụng trong các mô hình dựa trên kNN của dịch Đức-Anh.

Mô hình IT Y tế Luật Koran
kNN-MT & trainable-kNN-MT cơ sở k 8 8 16 16
λ 0.6 0.8 0.8 0.8
T 10 10 5 10
kNN-FT-MT & FT trainable-kNN-MT k 4 4 8 16
λ 0.4 0.4 0.4 0.2
T 10 100 5 5

Bảng 10: Các siêu tham số được sử dụng trong các mô hình dựa trên kNN của dịch Anh-Đức.

--- TRANG 12 ---
Nguồn Sollte Seine Peinigung über euch nachts oder am Tage hereinbrechen, was wollen denn die schwer Verfehlenden davon beschleunigen?
Tham chiếu If His chastisement comes upon you by night or day, what part of it will the sinners seek to hasten?
kNN-FT-MT If His punishment befalls you at night or in the day, what would the sinners do to despatch it?
Cơ chế cổng (Của chúng tôi) If His punishment comes upon you by night or by day, how will the sinners hasten it?
Xác suất sự thật cơ bản (Của chúng tôi) If His punishment comes upon you at night or in the day, how will the sinners hasten it?
RL (Của chúng tôi) If His punishment comes upon you at night or in the day, what will the sinners do to hasten it?

Nguồn Und sie sagen: "Wir glauben daran." Aber wie könnten sie (den Glauben) von einem fernen Ort aus erlangen,
Tham chiếu and they say, 'We believe in it'; but how can they reach from a place far away,
kNN-FT-MT They say: "We believe in it;" but how could they reach it from a place of no return?
Cơ chế cổng (Của chúng tôi) And they say, "We believe in it"; so how can they reach it from a place far away?
Xác suất sự thật cơ bản (Của chúng tôi) And they say, "We believe in it"; so how can they reach it from a place of no return?
RL (Của chúng tôi) And they say, "We believe in it"; so how can they reach it from a place of no return?

Nguồn Und haltet sie an; denn sie sollen befragt werden.
Tham chiếu And detain them, for they will be questioned.
kNN-FT-MT Surely they are to be interrogated.
Cơ chế cổng (Của chúng tôi) And test them, and they will be questioned.
Xác suất sự thật cơ bản (Của chúng tôi) Persevere with them, and they will be questioned.
RL (Của chúng tôi) Persevere with them, and they will be questioned.

Bảng 11: Ví dụ về bản dịch từ trainable-kNN-MT với ba cách chia tỷ lệ gradient so với kNN-FT-MT trong miền Koran. Các từ in đậm chỉ ra sự khác biệt của chúng. FT trainable-kNN-MT có thể dịch đúng trong trường hợp dịch quan hệ ngữ pháp, trong khi kNN-FT-MT thì không.

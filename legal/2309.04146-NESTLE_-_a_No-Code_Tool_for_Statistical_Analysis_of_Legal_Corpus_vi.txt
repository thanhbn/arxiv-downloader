# NESTLE: một Công cụ Không-Mã để Phân tích Thống kê Kho tài liệu Pháp lý
Kyoungyeon Cho1,∗ Seungkum Han1 Young Rok Choi1 Wonseok Hwang1,2,∗,†
1LBox 2University of Seoul
{kycho, hsk2950, yrchoi, wonseok.hwang}@lbox.kr

## Tóm tắt
Phân tích thống kê kho tài liệu pháp lý quy mô lớn có thể cung cấp những hiểu biết pháp lý có giá trị. Để thực hiện phân tích như vậy, người ta cần (1) chọn một tập con của kho tài liệu bằng các công cụ tìm kiếm tài liệu, (2) cấu trúc hóa văn bản bằng các hệ thống trích xuất thông tin (IE), và (3) trực quan hóa dữ liệu để phân tích thống kê. Mỗi quy trình đòi hỏi các công cụ chuyên dụng hoặc kỹ năng lập trình trong khi không có công cụ "không-mã" toàn diện thống nhất nào có sẵn. Ở đây chúng tôi cung cấp NESTLE, một công cụ không-mã để phân tích thống kê quy mô lớn kho tài liệu pháp lý. Được hỗ trợ bởi Mô hình Ngôn ngữ Lớn (LLM) và hệ thống IE end-to-end tùy chỉnh nội bộ, NESTLE có thể trích xuất bất kỳ loại thông tin nào chưa được định nghĩa trước trong hệ thống IE mở ra khả năng phân tích thống kê có thể tùy chỉnh không giới hạn của kho tài liệu mà không cần viết một dòng mã nào. Chúng tôi xác thực hệ thống của mình trên 15 tác vụ IE tiền lệ Hàn Quốc và 3 tác vụ phân loại văn bản pháp lý từ LEXGLUE. Các thí nghiệm toàn diện cho thấy NESTLE có thể đạt hiệu suất tương đương GPT-4 bằng cách huấn luyện mô-đun IE nội bộ với 4 ví dụ được gán nhãn bởi con người và 192 ví dụ được gán nhãn bởi LLM.

## 1 Giới thiệu
Tài liệu pháp lý bao gồm nhiều thông tin bán cấu trúc bắt nguồn từ các tranh chấp xã hội đa dạng. Ví dụ, các tiền lệ bao gồm thông tin thực tế (chẳng hạn như nồng độ cồn trong máu trong trường hợp lái xe khi say (DUI) hoặc tổn thất trong vụ bồi thường) cũng như quyết định từ tòa án (tiền phạt, thời gian giam giữ, số tiền được nguyên đơn yêu cầu, số tiền được tòa án chấp thuận, v.v.). Trong khi mỗi tài liệu chứa thông tin chi tiết về các sự kiện pháp lý cụ thể giữa một vài cá nhân, những hiểu biết cấp độ cộng đồng chỉ có thể được rút ra bằng cách phân tích một tập hợp đáng kể các tài liệu này. Ví dụ, hậu quả của việc sửa đổi tinh tế đối với luật chỉ có thể trở nên rõ ràng thông qua phân tích thống kê toàn diện của kho tài liệu pháp lý liên quan. Thực sự một nghiên cứu gần đây cho thấy việc sửa đổi Luật Giao thông Đường bộ đã thay đổi thời gian giam giữ trung bình trong các vụ lái xe say như thế nào bằng cách phân tích 24k tiền lệ Hàn Quốc (Hwang et al., 2022a).

∗Đóng góp bằng nhau.
†Tác giả liên hệ

Hình 1: Minh họa về NESTLE.

Tiến hành phân tích thống kê toàn diện trên kho tài liệu pháp lý quy mô lớn có thể đòi hỏi ba bước chính sau: (1) chọn một tập con của kho tài liệu bằng các công cụ tìm kiếm, (2) cấu trúc hóa các tài liệu bằng các hệ thống trích xuất thông tin (IE), và (3) trực quan hóa dữ liệu để phân tích thống kê. Mỗi bước đòi hỏi các công cụ chuyên dụng hoặc kiến thức lập trình, cản trở việc phân tích cho phần lớn các nhà thực hành pháp lý. Đặc biệt trong

--- TRANG 2 ---
Hình 2: Quy trình làm việc của NESTLE

quá trình cấu trúc hóa văn bản, nếu thông tin mục tiêu không được định nghĩa trước trong ontology của hệ thống IE, người ta cần xây dựng hệ thống của riêng mình.

Để vượt qua hạn chế này, chúng tôi đã phát triển NESTLE1, một công cụ không-mã để phân tích thống kê kho tài liệu pháp lý. Với NESTLE, người dùng có thể tìm kiếm tài liệu mục tiêu, trích xuất thông tin, và trực quan hóa thông tin thống kê của dữ liệu có cấu trúc thông qua giao diện trò chuyện, đi kèm với GUI hỗ trợ để kiểm soát ở mức độ chi tiết, chẳng hạn như lựa chọn siêu tham số, sửa đổi ontology, gán nhãn dữ liệu, v.v. Một lựa chọn thiết kế độc đáo của NESTLE là sự kết hợp của LLM và hệ thống IE end-to-end tùy chỉnh (Hwang et al., 2022a) mang lại những ưu điểm sau. Đầu tiên, NESTLE có thể xử lý ontology tùy chỉnh được cung cấp bởi người dùng nhờ tính chất end-to-end (sinh tạo) của mô-đun IE. Thứ hai, NESTLE có thể trích xuất thông tin mục tiêu từ kho tài liệu với chỉ 4 ví dụ được hỗ trợ bởi LLM. Với các ví dụ ít ỏi đã cho, LLM xây dựng tập dữ liệu huấn luyện cho mô-đun IE trong bối cảnh few-shot. Cuối cùng, chi phí tổng thể có thể được giảm 200 lần, và thời gian suy luận có thể được tăng tốc 6 lần so với các hệ thống IE chỉ dựa vào LLM, như ChatGPT, khi phân tích 1 triệu tài liệu.

Chúng tôi xác thực NESTLE trên ba tác vụ AI pháp lý: (1) 4 tác vụ IE Pháp lý Hàn Quốc (Hwang et al., 2022a), (2)

1CÔNG CỤ KHÔNG-MÃ ĐỂ PHÂN TÍCH THỐNG KÊ KHO TÀI LIỆU PHÁP LÝ

11 tác vụ IE Pháp lý Hàn Quốc mới được tạo ra từ tập dữ liệu LBOX-OPEN (Hwang et al., 2022b), và (3) 3 tác vụ phân loại văn bản pháp lý tiếng Anh từ LEXGLUE (Chalkidis et al., 2022; Chalkidis, 2023; Tuggener et al., 2020; Lippi et al., 2018). Các thí nghiệm toàn diện cho thấy NESTLE có thể đạt hiệu suất tương đương GPT-4 chỉ với 4 ví dụ được gán nhãn bởi con người và 192 ví dụ được gán nhãn bởi LLM. Tóm lại, những đóng góp của chúng tôi như sau.

• Chúng tôi phát triển NESTLE, một công cụ không-mã có thể hỗ trợ người dùng thực hiện phân tích thống kê quy mô lớn kho tài liệu pháp lý từ một vài (4–8) ví dụ đã cho.

• Chúng tôi xác thực rộng rãi NESTLE trên 15 tác vụ IE tiền lệ Hàn Quốc và 3 tác vụ phân loại văn bản pháp lý tiếng Anh trong khi tập trung vào ba chỉ số thực tế: độ chính xác, chi phí và thời gian2.

• Chúng tôi cho thấy NESTLE có thể đạt độ chính xác tương đương GPT-4 nhưng với chi phí thấp hơn 200 lần và suy luận nhanh hơn sáu lần so với các hệ thống IE chỉ dựa vào LLM thương mại như ChatGPT để phân tích 1 triệu tài liệu.

2Demo có sẵn từ http://nestle-demo.lbox.kr. Phần của các tập dữ liệu (bao gồm 550 tập thử nghiệm được tuyển chọn thủ công cho các tác vụ IE few-shot) sẽ có sẵn từ https://github.com/lbox-kr/nestle

--- TRANG 3 ---
## 2 Công trình liên quan

**Mô hình Ngôn ngữ Lớn như một Agent** Với sự phổ biến nhanh chóng của LLM (OpenAI, 2023; Touvron et al., 2023a,b; Anil et al., 2023; Anthropic, 2023; Taori et al., 2023; Zheng et al., 2023), nhiều nghiên cứu gần đây xem xét khả năng của LLM như một agent có thể sử dụng các công cụ bên ngoài (Liang et al., 2023; Li et al., 2023; Liu et al., 2023; Wang et al., 2023; Song et al., 2023; Zhuang et al., 2023; Tang et al., 2023; Patil et al., 2023; Qin et al., 2023; Viswanathan et al., 2023). Có ít nghiên cứu tập trung vào khả năng của LLM như một agent phân tích dữ liệu. Zhang et al. phát triển Data-Copilot có thể giúp người dùng tương tác với các nguồn dữ liệu khác nhau thông qua giao diện trò chuyện. Ma et al. xem xét khả năng của GPT-3 (CODEX, code-davinci-002) như một trình trích xuất thông tin few-shot trên tám tác vụ NER và trích xuất quan hệ và đề xuất sử dụng LLM để xếp hạng lại đầu ra từ các mô hình ngôn ngữ nhỏ. Ding et al. đánh giá khả năng của GPT-3 như một người gán nhãn dữ liệu trên tác vụ phân loại văn bản SST2 và các tác vụ CrossNER báo cáo rằng GPT-3 cho thấy hiệu suất tốt trên SST2. He et al. đề xuất khung 'explain-then-annotate' để nâng cao khả năng gán nhãn của LLM. Dưới phương pháp của họ, GPT-3.5 đạt điểm siêu-người hoặc tương đương con người trên ba tác vụ phân loại nhị phân.

Công trình của chúng tôi khác với các công trình trước đây ở chỗ chúng tôi tập trung vào xây dựng một công cụ không-mã để "phân tích thống kê" của "kho tài liệu" nơi các phương pháp cấu trúc hóa tài liệu quy mô lớn hiệu quả, chính xác, nhưng có thể tùy chỉnh là cần thiết. Công trình của chúng tôi cũng khác ở chỗ chúng tôi tập trung vào các tác vụ trích xuất thông tin từ văn bản pháp lý. Cuối cùng, thay vì thực hiện tất cả IE thông qua LLM, chúng tôi tập trung vào việc kết hợp giữa LLM thương mại và mô hình ngôn ngữ nhỏ (SLM) mã nguồn mở bằng cách chưng cất kiến thức từ LLM sang SLM. Theo cách này, chi phí API của việc sử dụng LLM không tăng tuyến tính với kích thước của kho tài liệu cho phép NESTLE được áp dụng cho kho tài liệu quy mô công nghiệp.

Viswanathan et al. gần đây đề xuất Prompt2Model cho phép người dùng xây dựng một hệ thống NLP bằng cách cung cấp một vài ví dụ. So với Prompt2Model, NESTLE được chuyên dụng hóa trong tác vụ IE quy mô lớn trong lĩnh vực pháp lý và cung cấp các tính năng bổ sung như phân tích thống kê dựa trên trò chuyện và GUI để kiểm soát ở mức độ chi tiết. Ngoài ra NESTLE được xác thực chặt chẽ trên nhiều tác vụ IE pháp lý.

**Trích xuất Thông tin từ Văn bản Pháp lý** Các nghiên cứu trước đây xây dựng các hệ thống IE cho văn bản pháp lý sử dụng các phương pháp dựa trên gắn thẻ (Cardellino et al., 2017; Mistica et al., 2020; Hendrycks et al., 2021; Habernal et al., 2022; Chen et al., 2020; Pham et al., 2021; Hong et al., 2021; Yao et al., 2022) hoặc các phương pháp sinh tạo (Pires et al., 2022; Hwang et al., 2022a). Hệ thống của chúng tôi tương tự như (Hwang et al., 2022a) ở chỗ chúng tôi sử dụng hệ thống IE end-to-end và tập trung vào phân tích thống kê thông tin pháp lý. Tuy nhiên công trình của chúng tôi là độc đáo ở chỗ chúng tôi trình bày một công cụ không-mã và khám phá việc kết hợp LLM thương mại và SLM mã nguồn mở để mở rộng phạm vi phân tích cho kho tài liệu quy mô lớn trong khi tập trung vào ba chỉ số thực tế: độ chính xác, thời gian và chi phí.

## 3 Hệ thống

NESTLE bao gồm ba mô-đun chính: một công cụ tìm kiếm để tìm kiếm tài liệu, một hệ thống IE end-to-end tùy chỉnh, và LLM để cung cấp giao diện trò chuyện và gán nhãn dữ liệu. Thông qua các cuộc trò chuyện với LLM, người dùng có thể tìm kiếm, truy xuất và gán nhãn dữ liệu từ kho tài liệu. Sau khi gán nhãn một vài tài liệu được truy xuất, người dùng có thể cấu trúc hóa toàn bộ kho tài liệu bằng mô-đun IE. Sau đó, người dùng có thể tiến hành phân tích thống kê thông qua giao diện trò chuyện sử dụng LLM. Nội bộ, các truy vấn của người dùng được chuyển đổi thành các dạng logic có thể thực thi để gọi các công cụ tương ứng thông qua khả năng "gọi hàm" của ChatGPT. Quy trình làm việc tổng thể được mô tả trong Hình 2.

**Công cụ Tìm kiếm** Công cụ tìm kiếm chọn một phần của kho tài liệu để phân tích thống kê từ các truy vấn của người dùng đã cho. Sử dụng LLM như ChatGPT, trước tiên chúng tôi trích xuất các từ khóa hoặc câu tiềm năng từ các truy vấn của người dùng, sau đó chuyển tiếp chúng đến công cụ tìm kiếm để tinh chỉnh và lựa chọn thêm. Elasticsearch được sử dụng để xử lý khối lượng dữ liệu lớn một cách hiệu quả.

**Mô-đun IE** Để cấu trúc hóa tài liệu, trước tiên người dùng tạo ra một tập nhỏ các ví dụ hạt giống thông qua giao diện trò chuyện hoặc GUI để kiểm soát ở mức độ chi tiết. Sau đó LLM sử dụng các ví dụ hạt giống này để gán nhãn các tài liệu khác thông qua học few-shot. Prompt sau được sử dụng để gán nhãn:

Bạn là một trợ lý hữu ích cho các tác vụ IE. Sau khi đọc văn bản sau, hãy trích xuất thông tin về TRƯỜNG-1, TRƯỜNG-2, ..., TRƯỜNG-n theo định dạng JSON sau: 'TRƯỜNG-1: [giá_trị1, giá_trị2, ...], TRƯỜNG-2: [giá_trị1, giá_trị2, ...], ..., TRƯỜNG-n: [giá_trị1, giá_trị2, ...]'.

MÔ TẢ TÁC VỤ

--- TRANG 4 ---
Bảng 1: Hiệu suất của các mô hình khác nhau trên tác vụ KORPREC-IE cho thấy điểm F1 cho các trường riêng lẻ: BAC (nồng độ cồn trong máu), Dist (khoảng cách di chuyển), Vehicle (loại phương tiện), Rec (hồ sơ lái xe say trước đây), Loss, Loss-A (tổn thất tiếp tay và xúi giục), Fine (số tiền phạt), Imp (loại và thời gian giam giữ), Susp (thời gian tạm hoãn thực hiện), Educ (thời gian giáo dục), Comm (thời gian phục vụ cộng đồng). Điểm trung bình (AVG) được tính ngoại trừ tác vụ DRUNK DRIVING, vì tất cả các mô hình đạt điểm cao trên nó. Điểm dựa trên các tập thử nghiệm, mỗi tập chứa 100 ví dụ cho mỗi tác vụ.

[THIS IS TABLE: Performance comparison table showing various models' F1 scores across different legal tasks, with columns for model names, LLM module, IE module backbone size, training examples, and specific task performance metrics]

VĂN BẢN ĐẦU VÀO 1, PHÂN TÍCH 1
VĂN BẢN ĐẦU VÀO 2, PHÂN TÍCH 2
...
VĂN BẢN ĐẦU VÀO n, PHÂN TÍCH n
VĂN BẢN ĐẦU VÀO3

Các ví dụ được tạo ra được sử dụng để huấn luyện mô hình IE. Chúng tôi sử dụng mô hình ngôn ngữ mã nguồn mở đa ngôn ngữ T5 (mt5) (Xue et al., 2021) làm backbone. mt5 được chọn vì (1) nó cung cấp các checkpoint của nhiều quy mô khác nhau lên đến 13B, và (2) các nghiên cứu trước đây cho thấy Transformers với kiến trúc encoder-decoder hoạt động tốt hơn các mô hình chỉ decoder trong các tác vụ IE (Hwang et al., 2022a,b). Mô hình cũng đã chứng minh hiệu quả trong việc chưng cất kiến thức từ LLM cho các tác vụ QA (Li et al., 2022). Mô hình được huấn luyện được sử dụng để phân tích các tài liệu còn lại được truy xuất từ bước trước.

## 4 Demo

Trong phần này, chúng tôi cung cấp giải thích cho demo của chúng tôi. Video cũng có sẵn tại https://youtu.be/twkpjYJrvI8

**Giao diện Gán nhãn** Người dùng có thể tải lên dữ liệu của họ (kho tài liệu không có cấu trúc) bằng nút tải lên. Ngoài ra, họ có thể thử nghiệm hệ thống với các ví dụ được chuẩn bị từ 7 lĩnh vực pháp lý bằng cách chọn chúng thông qua giao diện trò chuyện. Mỗi tập dữ liệu đi kèm với khoảng 1500 tài liệu và 20 ví dụ được gán nhãn thủ công.

3Prompt gốc được viết bằng tiếng Hàn nhưng được hiển thị bằng tiếng Anh để rõ ràng.

được gán nhãn thủ công. Sau khi tải tập dữ liệu, người dùng có thể xem và thực hiện gán nhãn thủ công trên các tài liệu bằng menu thả xuống nơi các giá trị của các trường riêng lẻ (chẳng hạn như nồng độ cồn trong máu, số tiền phạt, v.v.) có thể được gán nhãn hoặc các trường mới có thể được giới thiệu. Các thay đổi được tự động lưu vào cơ sở dữ liệu.

**Giao diện Mô-đun IE** Người dùng có thể chọn các tùy chọn như kích thước mô hình, số epoch huấn luyện và số ví dụ huấn luyện trong Giao diện Mô-đun IE. Việc huấn luyện mô-đun IE thường mất từ 40 phút đến một giờ, tùy thuộc vào các tham số trên. Dữ liệu được tự động tăng cường bởi LLM khi số lượng ví dụ được gán nhãn thủ công ít hơn số lượng ví dụ huấn luyện được chỉ định ở trên.

**Giao diện Phân tích Thống kê** Sử dụng giao diện trò chuyện từ tab thứ hai của demo, người dùng có thể thực hiện các phân tích thống kê khác nhau như trực quan hóa dữ liệu và tính toán các thống kê khác nhau. Người dùng cũng có thể truy xuất một tài liệu mục tiêu theo yêu cầu.

## 5 Thí nghiệm

Tất cả các thí nghiệm được thực hiện trên GPU NVIDIA A6000 ngoại trừ các thí nghiệm với mt5-xxl nơi tám GPU A100 được sử dụng. Mô-đun IE của NESTLE được fine-tuned với batch size 12 với learning rate 4e-4 sử dụng optimizer AdamW. Trong điều kiện này, việc huấn luyện đôi khi trở nên không ổn định. Trong trường hợp này, chúng tôi giảm learning rate xuống 3e-4. Learning rate cao được cố ý chọn để huấn luyện nhanh. Việc huấn luyện được dừng sau 60 epoch (NESTLE-S), hoặc sau 80 epoch (NESTLE-L, NESTLE-L+). Trong trường hợp NESTLE-XXL, learning rate được đặt là 2e-4 và mô hình được huấn luyện trong 20 epoch với batch size 8 sử dụng deepspeed stage 3 offload (Ren et al., 2021). Để huấn luyện hiệu quả, LoRA được sử dụng trong tất cả các thí nghiệm (Hu et al., 2022) sử dụng thư viện PEFT từ Hugging face (Mangrulkar et al., 2022). Trong tất cả các đánh giá, checkpoint từ epoch cuối cùng được sử dụng.

Để gán nhãn dữ liệu, chúng tôi sử dụng ChatGPT phiên bản gpt-3.5-turbo-16k-0613 và GPT-4 phiên bản gpt-4-0613. Trong tất cả các hoạt động khác với LLM, chúng tôi sử dụng cùng phiên bản ChatGPT ngoại trừ trong việc chuẩn hóa các chuỗi số như thời gian giam giữ và tiền phạt nơi gpt-3.5-turbo-0613 được sử dụng. Chúng tôi đặt temperature 0 để giảm thiểu tính ngẫu nhiên vì các tác vụ IE không yêu cầu đầu ra đa dạng. Các giá trị mặc định được sử dụng cho các siêu tham số khác. Trong quá trình học few-shot, chúng tôi cung cấp cho LLM các ví dụ mà một nửa bao gồm tất cả các trường được định nghĩa trong ontology trong khi nửa còn lại được chọn ngẫu nhiên.

## 6 Kết quả

Chúng tôi xác thực NESTLE trên 15 tác vụ IE tiền lệ Hàn Quốc và 3 tác vụ phân loại văn bản pháp lý tiếng Anh. 15 tác vụ IE tiền lệ Hàn Quốc được chia thành hai danh mục: KORPREC-IE bao gồm 4 tác vụ từ các vụ án hình sự được nghiên cứu trước đây trong (Hwang et al., 2022a) và LBOXOPEN-IE, được tạo ra từ LBOXOPEN (Hwang et al., 2022b) sử dụng các mô tả thực tế từ 7 vụ án hình sự và 4 vụ án dân sự. Trong tất cả các tác vụ, một mô hình cần trích xuất thông tin quan trọng về mặt pháp lý từ mô tả thực tế hoặc phán quyết của các vụ án như nồng độ cồn trong máu, tổn thất gian lận, tiền phạt và thời gian giam giữ, thời gian điều trị bệnh viện cần thiết cho chấn thương, v.v.

Ba tác vụ phân loại là EURLEX, LEDGAR, và UNFAIR-ToS từ LEXGLUE (Chalkidis et al., 2022; Tuggener et al., 2020; Lippi et al., 2018). Tập dữ liệu EURLEX bao gồm một cặp luật pháp Liên minh Châu Âu (đầu vào) và các khái niệm pháp lý tương ứng (đầu ra) từ Thesaurus EuroVoc. Trong tác vụ LEDGAR, một mô hình cần phân loại các đoạn văn từ hợp đồng có nguồn gốc từ các hồ sơ của Ủy ban Chứng khoán và Giao dịch Hoa Kỳ. Tương tự, UNFAIR-ToS là một tác vụ dự đoán 8 loại điều khoản hợp đồng không công bằng cho các câu riêng lẻ được đưa ra từ 50 Điều khoản Dịch vụ. Ba tác vụ phân loại này được sử dụng để chứng minh NESTLE trên benchmark AI pháp lý phổ biến (tiếng Anh) và cũng để cho thấy NESTLE có thể được áp dụng cho các tác vụ AI chung có thể được biểu diễn ở định dạng text-to-text (Raffel et al., 2020).

**NESTLE cho thấy hiệu suất tốt chỉ với bốn ví dụ** Đầu tiên chúng tôi xác thực NESTLE trên KORPREC-IE bao gồm bốn tác vụ: DRUNK DRIVING, EMBEZZLEMENT, FRAUD, và RULING-CRIMINAL. Với bốn ví dụ hạt giống và 92 ví dụ được gán nhãn bởi LLM, chúng tôi huấn luyện mt5-small (Xue et al., 2021). Kết quả cho thấy phương pháp của chúng tôi đã đạt +4.2 F1 trung bình so với trường hợp được huấn luyện với 50 ví dụ được gán nhãn thủ công (Bảng 1, hàng 1 vs 3, cột 5).

**NESTLE có thể đạt hiệu suất tương đương GPT-4** Để nâng cao độ chính xác của NESTLE, chúng tôi mở rộng cả số lượng ví dụ được gán nhãn bởi LLM và kích thước của backbone của mô-đun IE end-to-end của NESTLE. Với số lượng ví dụ được gán nhãn bởi LLM lớn hơn (từ 92 đến 192), NESTLE đạt +2.5 F1 trung bình (hàng 3 vs 4) trong khi thời gian gán nhãn tăng (ví dụ, từ 2.4 phút đến 10.6 phút trong tác vụ FRAUD). Với backbone lớn hơn (từ mt5-small (0.3B) đến mt5-large (1.2B)), NESTLE cho thấy +9.6 F1 (hàng 3 vs 5). Với cả hai, NESTLE cho thấy +15.1 F1 (hàng 3 vs 6). Tuy nhiên, cả thời gian gán nhãn và thời gian huấn luyện đều tăng (ví dụ, từ 15 phút đến 170 phút trong tác vụ FRAUD).

Nếu độ chính xác của mô hình giáo viên (ChatGPT) thấp, hiệu suất của học sinh (mt5) có thể

--- TRANG 5 ---
a
b c
Hình 3: Phân tích đánh đổi trên tác vụ FRAUD tập trung vào ba chỉ số thực tế: (a) độ chính xác, (b) chi phí, và (c) thời gian.

bị giới hạn bởi nó. Để kiểm tra giới hạn trên của độ chính xác có thể đạt được, chúng tôi đo hiệu suất few-shot của ChatGPT. NESTLE-L và ChatGPT chỉ cho thấy sự khác biệt 2.3 F1 trung bình (hàng 6 vs 9, cột 5) cho thấy các mô hình học sinh có thể tiếp cận giới hạn trên. Để cải thiện NESTLE hơn nữa, chúng tôi thay thế ChatGPT bằng GPT-4. Mặc dù thời gian gán nhãn và chi phí tăng khoảng 10 lần, điểm trung bình tăng +6.3 F1 (Bảng 1 hàng 6 vs 7). Đáng chú ý, điểm này cao hơn ChatGPT +4.0 F1 (hàng 7 vs 9).

Tiếp theo chúng tôi cố gắng mở rộng backbone của mô-đun IE từ mt5-large đến mt5-xxl (12.9B). Lưu ý rằng không giống như các LLM thương mại, mô-đun IE có thể được huấn luyện trên nhiều GPU để huấn luyện hiệu quả và thực sự tổng thời gian huấn luyện giảm 70 phút thậm chí so với mô hình nhỏ hơn (NESTLE-L) bằng cách thay đổi GPU từ một GPU A6000 đơn lẻ thành tám GPU A100. Tuy nhiên, chúng tôi không thể quan sát thấy sự cải thiện đáng chú ý trong F1.

**NESTLE có thể được tổng quát hóa cho các tập dữ liệu khác** Mặc dù chúng tôi đã xác thực NESTLE trên KORPREC-IE, tập dữ liệu chủ yếu bao gồm các trường số từ các vụ án hình sự. Để xác thực thêm, chúng tôi xây dựng LBOXOPEN-IE từ LBOXOPEN (Hwang et al., 2022b). LBOXOPEN-IE bao gồm 7 tác vụ từ các vụ án hình sự (Bảng 2) và 4 tác vụ từ các vụ án dân sự (Bảng 3). So với

Bảng 2: Hiệu suất của GPT-4 và NESTLE-L trên bảy tác vụ IE hình sự từ LBOXOPEN-IE. Điểm F1 được hiển thị: nRec (số hồ sơ hình sự giống nhau), nRec-A (số hồ sơ hình sự), Waiver (ý định của nạn nhân muốn từ bỏ hình phạt), Injury (mức độ chấn thương), và Gender (giới tính của nạn nhân).

[THIS IS TABLE: Performance comparison table between GPT-4 and NESTLE-L across 7 criminal tasks]

Bảng 3: Hiệu suất của GPT-4 và NESTLE-L trên bốn tác vụ IE dân sự từ LBOXOPEN-IE. Điểm F1 cho các trường riêng lẻ được hiển thị: Dom (lĩnh vực sự kiện như bất động sản, vụ hỏa hoạn, v.v.), Ctr (loại hợp đồng), Exp (số tiền mà nguyên đơn đã chi), Loan (số tiền được bị đơn vay), và Relat (mối quan hệ giữa nguyên đơn và bị đơn).

[THIS IS TABLE: Performance comparison table between GPT-4 and NESTLE-L across 4 civil tasks]

KORPREC-IE, các trường mục tiêu đa dạng hơn bao gồm các trường không phải số như loại hợp đồng, mối quan hệ nguyên đơn và bị đơn, ý kiến nạn nhân, lĩnh vực sự cố, v.v. cũng như các trường số như mức độ chấn thương, số hồ sơ hình sự trước đây, khoản vay và nhiều hơn nữa.

Chúng tôi sử dụng NESTLE-L và đo hiệu suất trên 550 ví dụ được tuyển chọn thủ công (50 cho mỗi tác vụ). NESTLE-L đạt hiệu suất tương đương GPT-4 trong 7 tác vụ hình sự (Bảng 2, 78.1 vs 81.1) và hiệu suất thấp hơn trong 4 tác vụ dân sự (Bảng 3, 71.5 vs 83.1). Điều này ngụ ý NESTLE có thể được sử dụng để xem xu hướng thống kê của thông tin cụ thể được bao gồm trong kho tài liệu, nhưng cần cẩn thận vì độ chính xác của chúng dao động từ ~70 đến ~90. Để vượt qua hạn chế này, NESTLE cũng cung cấp GUI để chỉnh sửa các ví dụ được tăng cường bởi LLM và thu thập thêm ví dụ thủ công. Nói chung, độ chính xác cao hơn có thể đạt được bằng cách sử dụng backbone chuyên dụng trong mô-đun IE cho các tác vụ mục tiêu, cùng với LLM mạnh mẽ hơn, đây là hướng cho công việc tương lai của chúng tôi.

Cuối cùng, việc xác thực thêm trên ba tác vụ phân loại văn bản pháp lý tiếng Anh từ LEXGLUE cho thấy NESTLE-L có thể đạt hiệu suất tương đương ChatGPT (Bảng 4, hàng 2 vs 3).

Bảng 4: Điểm F1 của ChatGPT và NESTLE-L trên EURLEX, LEDGAR, và UNFAIR-ToS từ LEXGLUE được đánh giá sử dụng 1.000 mẫu ngẫu nhiên từ các tập thử nghiệm gốc của chúng, theo (Chalkidis, 2023). Số ví dụ được gán nhãn thủ công (ntrain) và số ví dụ được gán nhãn bởi LLM (nLLM) được hiển thị trong cột 2 và 3 tương ứng.

[THIS IS TABLE: Performance comparison of ChatGPT and NESTLE-L on LEXGLUE tasks]

--- TRANG 6 ---
## 7 Phân tích

Chúng tôi đã cho thấy NESTLE có thể trích xuất thông tin với độ chính xác tương đương GPT-4 trên nhiều tác vụ. Trong phần này, chúng tôi mở rộng so sánh NESTLE với các LLM thương mại tập trung vào hai chỉ số thực tế bổ sung: chi phí và thời gian. Như một nghiên cứu trường hợp, chúng tôi chọn tác vụ FRAUD từ KORPREC-IE nơi tất cả các mô hình đều gặp khó khăn (Bảng 1, cột 11 và 12, Hình 3a). Chúng tôi tính toán chi phí tổng thể bằng cách cộng (1) chi phí gán nhãn thủ công, (2) chi phí API, và (3) chi phí huấn luyện và suy luận. Chi phí gán nhãn thủ công được ước tính từ chi phí duy trì nền tảng gán nhãn của chúng tôi (chi phí thuê người gán nhãn bán thời gian được xem xét). Chi phí API được tính bằng cách đếm token đầu vào và đầu ra và sử dụng bảng giá từ OpenAI. Chi phí huấn luyện và suy luận được tính bằng cách chuyển đổi thời gian huấn luyện và suy luận thành đô la dựa trên giá cloud GPU của Lambdalabs. Lưu ý rằng chi phí API tăng tuyến tính với kích thước của kho tài liệu khi sử dụng LLM thương mại. Mặt khác, trong NESTLE, chỉ chi phí suy luận tăng tuyến tính với kích thước của kho tài liệu. Kết quả cho thấy, đối với 10k tài liệu, chi phí tổng thể của NESTLE-L chỉ là 4% của ChatGPT và 0.4% của GPT-4 (Hình 3b). Đối với 1 triệu tài liệu, chi phí tổng thể của NESTLE-L là 0.5% của ChatGPT và 0.05% của GPT-4 (Hình 3b). Điều này làm nổi bật hiệu quả của NESTLE. Tương tự, ước tính tổng thời gian suy luận cho 1 triệu tài liệu cho thấy NESTLE-L mất ít thời gian hơn 83% hoặc 99% so với ChatGPT hoặc GPT-4 tương ứng4.

## 8 Kết luận

Chúng tôi phát triển NESTLE, một công cụ không-mã để phân tích thống kê kho tài liệu pháp lý. Để tìm kho tài liệu mục tiêu, cấu trúc hóa chúng và trực quan hóa dữ liệu có cấu trúc, chúng tôi kết hợp một công cụ tìm kiếm, một mô-đun IE end-to-end tùy chỉnh và LLM. Được hỗ trợ bởi LLM và mô-đun IE end-to-end, NESTLE cho phép phân tích thống kê cá nhân hóa không hạn chế của kho tài liệu. Chúng tôi xác thực rộng rãi NESTLE trên 15 tác vụ IE tiền lệ Hàn Quốc và 3 tác vụ phân loại văn bản pháp lý tiếng Anh trong khi tập trung vào ba chỉ số thực tế: độ chính xác, thời gian và chi phí. Cuối cùng, chúng tôi muốn nhấn mạnh rằng mặc dù NESTLE được chuyên dụng hóa cho các tác vụ IE pháp lý, công cụ có thể dễ dàng được tổng quát hóa cho các tác vụ NLP khác nhau có thể được biểu diễn ở định dạng text-to-text.

4So sánh chi tiết hơn có sẵn từ https://github.com/lbox-kr/nestle

## 9 Cân nhắc Đạo đức

Việc áp dụng AI pháp lý trong thế giới thực phải được tiếp cận một cách thận trọng. Ngay cả LLM được cho là mạnh nhất, GPT-4, vẫn thể hiện ảo giác (OpenAI, 2023) và hiệu suất của nó trong các tác vụ pháp lý thế giới thực vẫn còn hạn chế (Shui et al., 2023; Zhong et al., 2023; Martinez, 2023). Điều này có thể ngụ ý rằng các hệ thống AI cung cấp kết luận pháp lý nên trải qua đánh giá kỹ lưỡng trước khi được cung cấp cho các cá nhân thiếu chuyên môn pháp lý.

NESTLE không được thiết kế để cung cấp lời khuyên pháp lý cho người dùng chung; thay vào đó, nó nhằm hỗ trợ các nhà thực hành pháp lý bằng cách cung cấp dữ liệu thống kê được trích xuất từ tài liệu pháp lý. Hơn nữa, để chứng minh mức độ mà NESTLE có thể được sử dụng một cách đáng tin cậy để phân tích, chúng tôi đã tiến hành xác thực rộng rãi trên 15 tác vụ IE. Trong khi NESTLE cho thấy độ chính xác tổng thể cao, các thí nghiệm của chúng tôi cho thấy NESTLE không phải là không thể sai lầm, cho thấy rằng các thống kê kết quả nên được giải thích một cách thận trọng.

Tất cả các tài liệu được sử dụng trong nghiên cứu này bao gồm các tiền lệ Hàn Quốc được chính phủ Hàn Quốc biên tập theo giao thức chính thức (Hwang et al., 2022b).

## Lời cảm ơn

Chúng tôi cảm ơn Gene Lee vì việc đọc kỹ bản thảo, Minjoon Seo vì những nhận xét sâu sắc, Paul Koo vì sự hỗ trợ trong việc chuẩn bị các hình ảnh, và Min Choi vì sự hỗ trợ trong việc chuẩn bị demo.

## Tài liệu tham khảo

Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, Jonathan H. Clark, Laurent El Shafey, Yanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson, Sebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo Hernandez Abrego, Junwhan Ahn, Jacob Austin, Paul Barham, Jan Botha, James Bradbury, Siddhartha Brahma, Kevin Brooks, Michele Catasta, Yong Cheng, Colin Cherry, Christopher A. Choquette-Choo, Aakanksha Chowdhery, Clément Crepy, Shachi Dave, Mostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark Díaz, Nan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas Gonzalez, Guy Gur-Ari, Steven Hand, Hadi Hashemi, Le Hou, Joshua Howland, Andrea Hu, Jeffrey Hui, Jeremy Hur-

--- TRANG 7 ---
witz, Michael Isard, Abe Ittycheriah, Matthew Jagielski, Wenhao Jia, Kathleen Kenealy, Maxim Krikun, Sneha Kudugunta, Chang Lan, Katherine Lee, Benjamin Lee, Eric Li, Music Li, Wei Li, YaGuang Li, Jian Li, Hyeontaek Lim, Hanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni, Aroma Mahendru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John Nham, Eric Ni, Andrew Nystrom, Alicia Parrish, Marie Pellat, Martin Polacek, Alex Polozov, Reiner Pope, Siyuan Qiao, Emily Reif, Bryan Richter, Parker Riley, Alex Castro Ros, Aurko Roy, Brennan Saeta, Rajkumar Samuel, Renee Shelby, Ambrose Slone, Daniel Smilkov, David R. So, Daniel Sohn, Simon Tokumine, Dasha Valter, Vijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang, Pidong Wang, Zirui Wang, Tao Wang, John Wieting, Yuhuai Wu, Kelvin Xu, Yunhan Xu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng, Ce Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, và Yonghui Wu. 2023. Palm 2 technical report.

Anthropic. 2023. Introducing claude. https://www.anthropic.com/index/introducing-claude.

Cristian Cardellino, Milagro Teruel, Laura Alonso Alemany, và Serena Villata. 2017. Legal NERC with ontologies, Wikipedia and curriculum learning. Trong Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, trang 254–259, Valencia, Spain. Association for Computational Linguistics.

Ilias Chalkidis. 2023. Chatgpt may pass the bar exam soon, but has a long way to go for the lexglue benchmark. SSRN.

Ilias Chalkidis, Abhik Jana, Dirk Hartung, Michael Bommarito, Ion Androutsopoulos, Daniel Katz, và Nikolaos Aletras. 2022. LexGLUE: A benchmark dataset for legal language understanding in English. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 4310–4330, Dublin, Ireland. Association for Computational Linguistics.

Yanguang Chen, Yuanyuan Sun, Zhihao Yang, và Hongfei Lin. 2020. Joint entity and relation extraction for legal documents with legal feature enhancement. Trong Proceedings of the 28th International Conference on Computational Linguistics, trang 1561–1571, Barcelona, Spain (Online). International Committee on Computational Linguistics.

Bosheng Ding, Chengwei Qin, Linlin Liu, Yew Ken Chia, Boyang Li, Shafiq Joty, và Lidong Bing. 2023. Is GPT-3 a good data annotator? Trong Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 11173–11195, Toronto, Canada. Association for Computational Linguistics.

Ivan Habernal, Daniel Faber, Nicola Recchia, Sebastian Bretthauer, Iryna Gurevych, Christoph Burchard, et al. 2022. Mining legal arguments in court decisions. arXiv preprint arXiv:2208.06178.

Xingwei He, Zhenghao Lin, Yeyun Gong, A-Long Jin, Hang Zhang, Chen Lin, Jian Jiao, Siu Ming Yiu, Nan Duan, và Weizhu Chen. 2023. Annollm: Making large language models to be better crowdsourced annotators.

Dan Hendrycks, Collin Burns, Anya Chen, và Spencer Ball. 2021. Cuad: An expert-annotated nlp dataset for legal contract review. NeurIPS.

Jenny Hong, Derek Chong, và Christopher Manning. 2021. Learning from limited labels for long legal dialogue. Trong Proceedings of the Natural Legal Language Processing Workshop 2021, trang 190–204, Punta Cana, Dominican Republic. Association for Computational Linguistics.

Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, và Weizhu Chen. 2022. LoRA: Low-rank adaptation of large language models. Trong International Conference on Learning Representations.

Wonseok Hwang, Saehee Eom, Hanuhl Lee, Hai Jin Park, và Minjoon Seo. 2022a. Data-efficient end-to-end information extraction for statistical legal analysis. Trong Proceedings of the Natural Legal Language Processing Workshop 2022, trang 143–152, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

Wonseok Hwang, Dongjun Lee, Kyoungyeon Cho, Hanuhl Lee, và Minjoon Seo. 2022b. A multi-task benchmark for korean legal language understanding and judgement prediction. Trong Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track.

Minghao Li, Feifan Song, Bowen Yu, Haiyang Yu, Zhoujun Li, Fei Huang, và Yongbin Li. 2023. Api-bank: A benchmark for tool-augmented llms.

Shiyang Li, Jianshu Chen, Yelong Shen, Zhiyu Chen, Xinlu Zhang, Zekun Li, Hong Wang, Jing Qian, Baolin Peng, Yi Mao, Wenhu Chen, và Xifeng Yan. 2022. Explanations from large language models make small reasoners better.

Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu, Yan Xia, Yu Liu, Yang Ou, Shuai Lu, Lei Ji, Shaoguang Mao, Yun Wang, Linjun Shou, Ming Gong, và Nan Duan. 2023. Taskmatrix.ai: Completing tasks by connecting foundation models with millions of apis.

Marco Lippi, Przemyslaw Palka, Giuseppe Contissa, Francesca Lagioia, Hans-Wolfgang Micklitz, Giovanni Sartor, và Paolo Torroni. 2018. CLAUDETTE: an automated detector of potentially unfair clauses in online terms of service. CoRR, abs/1805.01217.

--- TRANG 8 ---
Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng, Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan Sun, Minlie Huang, Yuxiao Dong, và Jie Tang. 2023. Agentbench: Evaluating llms as agents.

Yubo Ma, Yixin Cao, YongChing Hong, và Aixin Sun. 2023. Large language model is not a good few-shot information extractor, but a good reranker for hard samples!

Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, và Sayak Paul. 2022. Peft: State-of-the-art parameter-efficient fine-tuning methods. https://github.com/huggingface/peft.

Eric Martinez. 2023. Re-evaluating gpt-4's bar exam performance.

Meladel Mistica, Geordie Z. Zhang, Hui Chia, Kabir Manandhar Shrestha, Rohit Kumar Gupta, Saket Khandelwal, Jeannie Paterson, Timothy Baldwin, và Daniel Beck. 2020. Information extraction from legal documents: A study in the context of common law court judgements. Trong Proceedings of the The 18th Annual Workshop of the Australasian Language Technology Association, trang 98–103, Virtual Workshop. Australasian Language Technology Association.

OpenAI. 2023. Gpt-4 technical report.

Shishir G. Patil, Tianjun Zhang, Xin Wang, và Joseph E. Gonzalez. 2023. Gorilla: Large language model connected with massive apis. arXiv preprint arXiv:2305.15334.

Nhi Pham, Lachlan Pham, và Adam L. Meyers. 2021. Legal terminology extraction with the termolator. Trong Proceedings of the Natural Legal Language Processing Workshop 2021, trang 155–162, Punta Cana, Dominican Republic. Association for Computational Linguistics.

Ramon Pires, Fábio C. de Souza, Guilherme Rosa, Roberto A. Lotufo, và Rodrigo Nogueira. 2022. Sequence-to-sequence models for extracting information from registration and legal documents. Trong Document Analysis Systems, trang 83–95, Cham. Springer International Publishing.

Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, Yi Ren Fung, Yusheng Su, Huadong Wang, Cheng Qian, Runchu Tian, Kunlun Zhu, Shihao Liang, Xingyu Shen, Bokai Xu, Zhen Zhang, Yining Ye, Bowen Li, Ziwei Tang, Jing Yi, Yuzhang Zhu, Zhenning Dai, Lan Yan, Xin Cong, Yaxi Lu, Weilin Zhao, Yuxiang Huang, Junxi Yan, Xu Han, Xian Sun, Dahai Li, Jason Phang, Cheng Yang, Tongshuang Wu, Heng Ji, Zhiyuan Liu, và Maosong Sun. 2023. Tool learning with foundation models.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140):1–67.

Jie Ren, Samyam Rajbhandari, Reza Yazdani Aminabadi, Olatunji Ruwase, Shuangyan Yang, Minjia Zhang, Dong Li, và Yuxiong He. 2021. Zero-offload: Democratizing billion-scale model training.

Ruihao Shui, Yixin Cao, Xiang Wang, và Tat-Seng Chua. 2023. A comprehensive evaluation of large language models on legal judgment prediction. arXiv preprint arXiv:2310.11761.

Yifan Song, Weimin Xiong, Dawei Zhu, Cheng Li, Ke Wang, Ye Tian, và Sujian Li. 2023. Restgpt: Connecting large language models with real-world applications via restful apis.

Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao Liang, và Le Sun. 2023. Toolalpaca: Generalized tool learning for language models with 3000 simulated cases.

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, và Tatsunori B. Hashimoto. 2023. Stanford alpaca: An instruction-following llama model. https://github.com/tatsu-lab/stanford_alpaca.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, và Guillaume Lample. 2023a. Llama: Open and efficient foundation language models.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, và Thomas Scialom. 2023b. Llama 2: Open foundation and fine-tuned chat models.

Don Tuggener, Pius von Däniken, Thomas Peetz, và Mark Cieliebak. 2020. LEDGAR: A large-scale

--- TRANG 9 ---
multi-label corpus for text classification of legal provisions in contracts. Trong Proceedings of the Twelfth Language Resources and Evaluation Conference, trang 1235–1241, Marseille, France. European Language Resources Association.

Vijay Viswanathan, Chenyang Zhao, Amanda Bertsch, Tongshuang Wu, và Graham Neubig. 2023. Prompt2model: Generating deployable models from natural language instructions.

Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, và Anima Anandkumar. 2023. Voyager: An open-ended embodied agent with large language models.

Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, và Colin Raffel. 2021. mT5: A massively multilingual pre-trained text-to-text transformer. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 483–498, Online. Association for Computational Linguistics.

Feng Yao, Chaojun Xiao, Xiaozhi Wang, Zhiyuan Liu, Lei Hou, Cunchao Tu, Juanzi Li, Yun Liu, Weixing Shen, và Maosong Sun. 2022. Leven: A large-scale chinese legal event detection dataset. arXiv preprint arXiv:2203.08556.

Wenqi Zhang, Yongliang Shen, Weiming Lu, và Yueting Zhuang. 2023. Data-copilot: Bridging billions of data and humans with autonomous workflow.

Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, và Ion Stoica. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena.

Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen, và Nan Duan. 2023. Agieval: A human-centric benchmark for evaluating foundation models.

Yuchen Zhuang, Yue Yu, Kuan Wang, Haotian Sun, và Chao Zhang. 2023. Toolqa: A dataset for llm question answering with external tools.

--- TRANG 10 ---

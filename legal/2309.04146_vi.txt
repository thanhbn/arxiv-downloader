# 2309.04146.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/legal/2309.04146.pdf
# Kích thước tệp: 2193066 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
NESTLE : một Công cụ Không cần Mã lệnh cho Phân tích Thống kê Kho tài liệu Pháp lý
Kyoungyeon Cho1,∗Seungkum Han1Young Rok Choi1Wonseok Hwang1,2,∗,†
1LBox2University of Seoul
{kycho, hsk2950, yrchoi, wonseok.hwang}@lbox.kr
Tóm tắt
Phân tích thống kê kho tài liệu pháp lý quy mô lớn có thể cung cấp những hiểu biết pháp lý có giá trị. Để thực hiện phân tích như vậy, người ta cần (1) chọn một tập con của kho tài liệu bằng các công cụ truy xuất tài liệu, (2) cấu trúc hóa văn bản bằng các hệ thống trích xuất thông tin (IE), và (3) trực quan hóa dữ liệu cho phân tích thống kê. Mỗi quy trình đòi hỏi hoặc là các công cụ chuyên dụng hoặc kỹ năng lập trình trong khi không có công cụ thống nhất toàn diện "không cần mã lệnh" nào khả dụng. Ở đây chúng tôi cung cấp NESTLE, một công cụ không cần mã lệnh cho phân tích thống kê quy mô lớn kho tài liệu pháp lý. Được hỗ trợ bởi một Mô hình Ngôn ngữ Lớn (LLM) và hệ thống IE tùy chỉnh từ đầu đến cuối nội bộ, NESTLE có thể trích xuất bất kỳ loại thông tin nào chưa được xác định trước trong hệ thống IE, mở ra khả năng phân tích thống kê tùy chỉnh không giới hạn của kho tài liệu mà không cần viết một dòng mã nào. Chúng tôi xác thực hệ thống của mình trên 15 nhiệm vụ IE tiền lệ Hàn Quốc và 3 nhiệm vụ phân loại văn bản pháp lý từ LEXGLUE. Các thí nghiệm toàn diện cho thấy NESTLE có thể đạt được hiệu suất tương đương GPT-4 bằng cách huấn luyện mô-đun IE nội bộ với 4 ví dụ được gán nhãn bởi con người, và 192 ví dụ được gán nhãn bởi LLM.

1 Giới thiệu
Tài liệu pháp lý bao gồm nhiều thông tin bán cấu trúc xuất phát từ các tranh chấp xã hội đa dạng. Ví dụ, các tiền lệ bao gồm thông tin thực tế (như nồng độ cồn trong máu trong vụ lái xe khi say rượu (DUI) hoặc thiệt hại trong vụ bồi thường) cũng như quyết định từ tòa án (tiền phạt, thời gian tù giam, số tiền nguyên đơn yêu cầu, số tiền tòa án chấp thuận, v.v.). Trong khi mỗi tài liệu chứa thông tin chi tiết về các sự kiện pháp lý cụ thể giữa một vài cá nhân, những hiểu biết cấp cộng đồng chỉ có thể được rút ra bằng cách phân tích một bộ sưu tập đáng kể các tài liệu này. Ví dụ, hậu quả của việc sửa đổi tinh tế đạo luật có thể chỉ trở nên rõ ràng thông qua phân tích thống kê toàn diện kho tài liệu pháp lý liên quan. Thực vậy, một nghiên cứu gần đây cho thấy việc sửa đổi Luật Giao thông Đường bộ đã thay đổi thời gian tù giam trung bình trong các vụ lái xe say rượu như thế nào bằng cách phân tích 24k tiền lệ Hàn Quốc (Hwang et al., 2022a).

∗Đóng góp ngang nhau.
†Tác giả liên hệ

Hình 1: Minh họa về NESTLE.

Tiến hành phân tích thống kê toàn diện trên kho tài liệu pháp lý quy mô lớn có thể đòi hỏi ba bước chính sau: (1) chọn một tập con của kho tài liệu bằng các công cụ truy xuất, (2) cấu trúc hóa các tài liệu bằng các hệ thống trích xuất thông tin (IE), và (3) trực quan hóa dữ liệu cho phân tích thống kê. Mỗi bước đòi hỏi hoặc là các công cụ chuyên dụng hoặc kiến thức lập trình, cản trở việc phân tích cho phần lớn các chuyên gia pháp lý. Đặc biệt trong quá trình cấu trúc hóa văn bản, nếu thông tin mục tiêu không được xác định trước trong ontology của hệ thống IE, người ta cần xây dựng hệ thống riêng của mình.

--- TRANG 2 ---
Hình 2: Quy trình làm việc của NESTLE

Để vượt qua hạn chế như vậy, chúng tôi đã phát triển NESTLE1, một công cụ không cần mã lệnh cho phân tích thống kê kho tài liệu pháp lý. Với NESTLE, người dùng có thể tìm kiếm tài liệu mục tiêu, trích xuất thông tin và trực quan hóa thông tin thống kê của dữ liệu có cấu trúc thông qua giao diện trò chuyện, cùng với một GUI phụ trợ cho các điều khiển cấp độ chi tiết, như lựa chọn siêu tham số, sửa đổi ontology, gán nhãn dữ liệu, v.v. Một lựa chọn thiết kế độc đáo của NESTLE là sự kết hợp của LLM và hệ thống IE tùy chỉnh từ đầu đến cuối (Hwang et al., 2022a) mang lại các ưu điểm sau. Thứ nhất, NESTLE có thể xử lý ontology tùy chỉnh được cung cấp bởi người dùng nhờ vào tính chất từ đầu đến cuối (sinh tạo) của mô-đun IE. Thứ hai, NESTLE có thể trích xuất thông tin mục tiêu từ kho tài liệu với chỉ 4 ví dụ được hỗ trợ bởi LLM. Đối với những ví dụ ít được cung cấp, LLM xây dựng bộ dữ liệu huấn luyện cho mô-đun IE trong bối cảnh few-shot. Cuối cùng, chi phí tổng thể có thể được giảm 200 lần, và thời gian suy luận có thể được tăng tốc 6 lần so với các hệ thống IE chỉ dựa vào LLM, như ChatGPT, khi phân tích 1 triệu tài liệu.

Chúng tôi xác thực NESTLE trên ba nhiệm vụ AI pháp lý: (1) 4 nhiệm vụ IE Pháp lý Hàn Quốc (Hwang et al., 2022a), (2) 11 nhiệm vụ IE Pháp lý Hàn Quốc mới được rút ra từ bộ dữ liệu LBOX-OPEN (Hwang et al., 2022b), và (3) 3 nhiệm vụ phân loại văn bản pháp lý tiếng Anh từ LEXGLUE (Chalkidis et al., 2022; Chalkidis, 2023; Tuggener et al., 2020; Lippi et al., 2018). Các thí nghiệm toàn diện cho thấy NESTLE có thể đạt được hiệu suất tương đương GPT-4 với chỉ 4 ví dụ được gán nhãn bởi con người, và 192 ví dụ được gán nhãn bởi LLM. Tóm lại, những đóng góp của chúng tôi như sau.

•Chúng tôi phát triển NESTLE, một công cụ không cần mã lệnh có thể hỗ trợ người dùng thực hiện phân tích thống kê quy mô lớn kho tài liệu pháp lý từ một vài (4–8) ví dụ được cung cấp.

•Chúng tôi xác thực NESTLE một cách rộng rãi trên 15 nhiệm vụ IE tiền lệ Hàn Quốc và 3 nhiệm vụ phân loại văn bản pháp lý tiếng Anh trong khi tập trung vào ba chỉ số thực tế: độ chính xác, chi phí và thời gian2.

•Chúng tôi cho thấy NESTLE có thể đạt được độ chính xác tương đương GPT-4 nhưng với chi phí thấp hơn 200 lần và suy luận nhanh hơn sáu lần so với các hệ thống IE chỉ dựa vào LLM thương mại như ChatGPT để phân tích 1 triệu tài liệu.

1CÔNG CỤ KHÔNG CẦN MÃ LỆNH CHO PHÂN TÍCH THỐNG KÊ KHO TÀI LIỆU PHÁP LÝ

2Demo có sẵn từ http://nestle-demo.lbox.kr. Một phần của các bộ dữ liệu (bao gồm 550 bộ thử nghiệm được tuyển chọn thủ công cho các nhiệm vụ IE few-shot) sẽ có sẵn từ https://github.com/lbox-kr/nestle

--- TRANG 3 ---
2 Công trình Liên quan

Mô hình Ngôn ngữ Lớn như một Tác nhân Với sự phổ biến nhanh chóng của LLM (OpenAI, 2023; Touvron et al., 2023a,b; Anil et al., 2023; Anthropic, 2023; Taori et al., 2023; Zheng et al., 2023), nhiều nghiên cứu gần đây xem xét khả năng của LLM như một tác nhân có thể sử dụng các công cụ bên ngoài (Liang et al., 2023; Li et al., 2023; Liu et al., 2023; Wang et al., 2023; Song et al., 2023; Zhuang et al., 2023; Tang et al., 2023; Patil et al., 2023; Qin et al., 2023; Viswanathan et al., 2023). Có ít nghiên cứu tập trung vào khả năng của LLM như một tác nhân phân tích dữ liệu. Zhang et al. phát triển Data-Copilot có thể giúp người dùng tương tác với các nguồn dữ liệu khác nhau qua giao diện trò chuyện. Ma et al. xem xét khả năng của GPT-3 (CODEX, code-davinci-002) như một trích xuất thông tin few-shot trên tám nhiệm vụ NER và trích xuất quan hệ và đề xuất sử dụng LLM để xếp hạng lại đầu ra từ các mô hình ngôn ngữ nhỏ. Ding et al. đánh giá khả năng của GPT-3 như một người gán nhãn dữ liệu trên nhiệm vụ phân loại văn bản SST2 và các nhiệm vụ CrossNER báo cáo rằng GPT-3 cho thấy hiệu suất tốt trên SST2. He et al. đề xuất khung 'giải thích-rồi-gán nhãn' để tăng cường khả năng gán nhãn của LLM. Dưới phương pháp của họ, GPT-3.5 đạt được điểm số siêu con người hoặc tương đương con người trên ba nhiệm vụ phân loại nhị phân.

Công trình của chúng tôi khác với những công trình trước đây ở chỗ chúng tôi tập trung vào xây dựng một công cụ không cần mã lệnh cho "phân tích thống kê" của "kho tài liệu" nơi các phương pháp cấu trúc hóa hiệu quả, chính xác, nhưng có thể tùy chỉnh của các tài liệu quy mô lớn là cần thiết. Công trình của chúng tôi cũng khác ở chỗ chúng tôi tập trung vào các nhiệm vụ trích xuất thông tin từ văn bản pháp lý. Cuối cùng, thay vì thực hiện tất cả IE thông qua LLM, chúng tôi tập trung vào việc kết hợp giữa LLM thương mại và mô hình ngôn ngữ nhỏ (SLM) mã nguồn mở bằng cách chưng cất kiến thức của LLM sang SLM. Theo cách này, chi phí API của việc sử dụng LLM không tăng tuyến tính với kích thước của kho tài liệu, cho phép NESTLE được áp dụng cho kho tài liệu quy mô công nghiệp.

Viswanathan et al. gần đây đề xuất Prompt2Model cho phép người dùng xây dựng một hệ thống NLP bằng cách cung cấp một vài ví dụ. So với Prompt2Model, NESTLE được chuyên biệt hóa trong nhiệm vụ IE quy mô lớn trong lĩnh vực pháp lý và cung cấp các tính năng bổ sung như phân tích thống kê dựa trên trò chuyện và GUI cho điều khiển cấp độ chi tiết. Ngoài ra NESTLE được xác thực nghiêm ngặt trên nhiều nhiệm vụ IE pháp lý.

Trích xuất Thông tin từ Văn bản Pháp lý Các nghiên cứu trước đây xây dựng các hệ thống IE cho văn bản pháp lý bằng các phương pháp dựa trên gắn thẻ (Cardellino et al., 2017; Mistica et al., 2020; Hendrycks et al., 2021; Haberhal et al., 2022; Chen et al., 2020; Pham et al., 2021; Hong et al., 2021; Yao et al., 2022) hoặc các phương pháp sinh tạo (Pires et al., 2022; Hwang et al., 2022a). Hệ thống của chúng tôi tương tự như (Hwang et al., 2022a) ở chỗ chúng tôi sử dụng hệ thống IE từ đầu đến cuối và tập trung vào phân tích thống kê thông tin pháp lý. Tuy nhiên, công trình của chúng tôi là độc đáo ở chỗ chúng tôi trình bày một công cụ không cần mã lệnh và khám phá việc kết hợp LLM thương mại và SLM mã nguồn mở để mở rộng phạm vi phân tích cho kho tài liệu quy mô lớn trong khi tập trung vào ba chỉ số thực tế: độ chính xác, thời gian và chi phí.

3 Hệ thống

NESTLE bao gồm ba mô-đun chính: một công cụ tìm kiếm cho truy xuất tài liệu, một hệ thống IE tùy chỉnh từ đầu đến cuối, và LLM để cung cấp giao diện trò chuyện và gán nhãn dữ liệu. Thông qua cuộc trò chuyện với LLM, người dùng có thể tìm kiếm, truy xuất và gán nhãn dữ liệu từ kho tài liệu. Sau khi gán nhãn một vài tài liệu được truy xuất, người dùng có thể cấu trúc hóa toàn bộ kho tài liệu bằng mô-đun IE. Sau đó, người dùng có thể tiến hành phân tích thống kê thông qua giao diện trò chuyện bằng LLM. Bên trong, các truy vấn của người dùng được chuyển đổi thành các dạng logic có thể thực thi để gọi các công cụ tương ứng thông qua khả năng "gọi hàm" của ChatGPT. Quy trình làm việc tổng thể được mô tả trong Hình 2.

Công cụ Tìm kiếm Công cụ tìm kiếm chọn một phần của kho tài liệu để phân tích thống kê từ các truy vấn người dùng được cung cấp. Sử dụng LLM như ChatGPT, trước tiên chúng tôi trích xuất các từ khóa hoặc câu tiềm năng từ các truy vấn người dùng, sau đó chuyển tiếp chúng đến công cụ tìm kiếm để tinh chỉnh và lựa chọn thêm. Elasticsearch được sử dụng để xử lý khối lượng dữ liệu lớn một cách hiệu quả.

Mô-đun IE Để cấu trúc hóa tài liệu, trước tiên người dùng tạo ra một tập nhỏ các ví dụ gốc thông qua giao diện trò chuyện hoặc GUI để điều khiển cấp độ chi tiết. Sau đó LLM sử dụng những ví dụ gốc này để gán nhãn các tài liệu khác thông qua học few-shot. Prompt sau được sử dụng cho việc gán nhãn

Bạn là một trợ lý hữu ích cho các nhiệm vụ IE. Sau khi đọc văn bản sau, hãy trích xuất thông tin về FIELD-1, FIELD-2, ..., FIELD-n theo định dạng JSON sau. 'FIELD-1 : [value1, value2, ...], FIELD-2 : [value1, value2, ...], ..., FIELD-n : [value1, value2, ...]'.

MÔ TẢ NHIỆM VỤ

--- TRANG 4 ---
Bảng 1: Hiệu suất của các mô hình khác nhau trên nhiệm vụ KORPREC-IE cho thấy điểm F1 cho các trường riêng lẻ: BAC (nồng độ cồn trong máu), Dist (khoảng cách di chuyển), Vehicle (loại phương tiện), Rec (hồ sơ lái xe say rượu trước đó), Loss, Loss-A (thiệt hại do tiếp tay và xúi giục), Fine (số tiền phạt), Imp (loại và thời gian tù giam), Susp (thời gian đình chỉ thi hành), Educ (thời gian giáo dục), Comm (thời gian phục vụ cộng đồng). Điểm trung bình (AVG) được tính trừ nhiệm vụ DRUNK DRIVING, vì tất cả các mô hình đều đạt điểm cao trên nó. Điểm được dựa trên các bộ thử nghiệm, mỗi bộ chứa 100 ví dụ cho mỗi nhiệm vụ.

[THIS IS TABLE: Complex performance table showing various models and their F1 scores across different fields for Korean legal IE tasks]

INPUT TEXT 1, PARSE 1
INPUT TEXT 2, PARSE 2
...
INPUT TEXT n, PARSE n
INPUT TEXT3

Các ví dụ được tạo ra được sử dụng để huấn luyện mô hình IE. Chúng tôi sử dụng mô hình ngôn ngữ mã nguồn mở đa ngôn ngữ T5 (mt5) (Xue et al., 2021) làm xương sống. mt5 được chọn vì (1) nó cung cấp các checkpoint với quy mô khác nhau lên đến 13B, và (2) các nghiên cứu trước đây cho thấy Transformers với kiến trúc encoder-decoder hoạt động tốt hơn các mô hình chỉ decoder trong các nhiệm vụ IE (Hwang et al., 2022a,b). Mô hình cũng đã chứng minh hiệu quả trong việc chưng cất kiến thức từ LLM cho các nhiệm vụ QA (Li et al., 2022). Mô hình được huấn luyện được sử dụng để phân tích các tài liệu còn lại được truy xuất từ bước trước.

4 Demo

Trong phần này, chúng tôi cung cấp giải thích cho demo của chúng tôi. Video cũng có sẵn tại https://youtu.be/twkpjYJrvI8

Giao diện Gán nhãn Người dùng có thể tải lên dữ liệu của họ (kho tài liệu không có cấu trúc) bằng nút tải lên. Ngoài ra, họ có thể kiểm tra hệ thống với các ví dụ được chuẩn bị từ 7 lĩnh vực pháp lý bằng cách chọn chúng thông qua giao diện trò chuyện. Mỗi bộ dữ liệu đi kèm với khoảng 1500 tài liệu và 20 ví dụ được gán nhãn thủ công3. Sau khi tải bộ dữ liệu, người dùng có thể xem và thực hiện gán nhãn thủ công trên các tài liệu bằng menu thả xuống nơi các giá trị của các trường riêng lẻ (như nồng độ cồn trong máu, số tiền phạt, v.v.) có thể được gán nhãn hoặc các trường mới có thể được giới thiệu. Các thay đổi được tự động lưu vào cơ sở dữ liệu.

Giao diện Mô-đun IE Người dùng có thể chọn các tùy chọn như kích thước mô hình, số epoch huấn luyện và số ví dụ huấn luyện trong Giao diện Mô-đun IE. Việc huấn luyện mô-đun IE thường mất từ 40 phút đến một giờ, tùy thuộc vào các tham số trên. Dữ liệu được tự động tăng cường bởi LLM khi số lượng ví dụ được gán nhãn thủ công ít hơn số lượng ví dụ huấn luyện được chỉ định ở trên.

Giao diện Phân tích Thống kê Sử dụng giao diện trò chuyện từ tab thứ hai của demo chúng tôi, người dùng có thể thực hiện các phân tích thống kê khác nhau như trực quan hóa dữ liệu và tính toán các thống kê khác nhau. Người dùng cũng có thể truy xuất một tài liệu mục tiêu theo yêu cầu.

3Prompt gốc được viết bằng tiếng Hàn nhưng được hiển thị bằng tiếng Anh để rõ ràng.

5 Thí nghiệm

Tất cả các thí nghiệm được thực hiện trên GPU NVIDIA A6000 ngoại trừ các thí nghiệm với mt5-xxl nơi tám GPU A100 được sử dụng. Mô-đun IE của NESTLE được fine-tune với batch size 12 với learning rate 4e-4 sử dụng optimizer AdamW. Dưới điều kiện này, việc huấn luyện đôi khi trở nên không ổn định. Trong trường hợp này, chúng tôi giảm learning rate xuống 3e-4. Learning rate cao được chọn có mục đích cho việc huấn luyện nhanh. Việc huấn luyện được dừng sau 60 epochs (NESTLE-S), hoặc sau 80 epochs (NESTLE-L, NESTLE-L+). Trong trường hợp NESTLE-XXL, learning rate được đặt ở 2e-4 và mô hình được huấn luyện trong 20 epochs với batch size 8 sử dụng deepspeed stage 3 offload (Ren et al., 2021). Để huấn luyện hiệu quả, LoRA được sử dụng trong tất cả các thí nghiệm (Hu et al., 2022) sử dụng thư viện PEFT từ Hugging face (Mangrulkar et al., 2022). Trong tất cả các đánh giá, checkpoint từ epoch cuối cùng được sử dụng.

Để gán nhãn dữ liệu, chúng tôi sử dụng ChatGPT phiên bản gpt-3.5-turbo-16k-0613 và GPT-4 phiên bản gpt-4-0613. Trong tất cả các hoạt động khác với LLM, chúng tôi sử dụng cùng phiên bản ChatGPT ngoại trừ trong việc chuẩn hóa các chuỗi số như thời gian tù giam và tiền phạt nơi gpt-3.5-turbo-0613 được sử dụng. Chúng tôi đặt temperature 0 để giảm thiểu tính ngẫu nhiên vì các nhiệm vụ IE không yêu cầu đầu ra đa dạng. Các giá trị mặc định được sử dụng cho các siêu tham số khác. Trong quá trình học few shot, chúng tôi cung cấp cho LLM các ví dụ mà một nửa bao gồm tất cả các trường được định nghĩa trong ontology trong khi nửa còn lại được chọn ngẫu nhiên.

--- TRANG 5 ---
tỷ lệ học cao được chọn có mục đích cho việc huấn luyện nhanh. Việc huấn luyện được dừng sau 60 epochs (NESTLE-S), hoặc sau 80 epochs (NESTLE-L, NESTLE-L+). Trong trường hợp NESTLE-XXL, tỷ lệ học được đặt ở 2e-4 và mô hình được huấn luyện trong 20 epochs với kích thước batch 8 sử dụng deepspeed stage 3 offload (Ren et al., 2021). Để huấn luyện hiệu quả, LoRA được sử dụng trong tất cả các thí nghiệm (Hu et al., 2022) sử dụng thư viện PEFT từ Hugging face (Mangrulkar et al., 2022). Trong tất cả các đánh giá, checkpoint từ epoch cuối cùng được sử dụng.

Để gán nhãn dữ liệu, chúng tôi sử dụng ChatGPT phiên bản gpt-3.5-turbo-16k-0613 và GPT-4 phiên bản gpt-4-0613. Trong tất cả các hoạt động khác với LLM, chúng tôi sử dụng cùng phiên bản ChatGPT ngoại trừ trong việc chuẩn hóa các chuỗi số như thời gian tù giam và tiền phạt nơi gpt-3.5-turbo-0613 được sử dụng. Chúng tôi đặt temperature 0 để giảm thiểu tính ngẫu nhiên vì các nhiệm vụ IE không yêu cầu đầu ra đa dạng. Các giá trị mặc định được sử dụng cho các siêu tham số khác. Trong quá trình học few shot, chúng tôi cung cấp cho LLM các ví dụ mà một nửa bao gồm tất cả các trường được định nghĩa trong ontology trong khi nửa còn lại được chọn ngẫu nhiên.

6 Kết quả

Chúng tôi xác thực NESTLE trên 15 nhiệm vụ IE tiền lệ Hàn Quốc và 3 nhiệm vụ phân loại văn bản pháp lý tiếng Anh. 15 nhiệm vụ IE tiền lệ Hàn Quốc được chia thành hai danh mục: KORPREC-IE bao gồm 4 nhiệm vụ từ các vụ án hình sự đã được nghiên cứu trước đây trong (Hwang et al., 2022a) và LBOXOPEN-IE, được tạo ra từ LBOXOPEN (Hwang et al., 2022b) sử dụng các mô tả thực tế từ 7 vụ án hình sự và 4 vụ án dân sự. Trong tất cả các nhiệm vụ, một mô hình cần trích xuất thông tin quan trọng về mặt pháp lý từ mô tả thực tế hoặc phán quyết của các vụ án như nồng độ cồn trong máu, thiệt hại lừa đảo, tiền phạt, và thời gian tù giam, thời gian điều trị bệnh viện cần thiết cho thương tích, v.v.

Ba nhiệm vụ phân loại là EURLEX, LEDGAR, và UNFAIR-ToS từ LEXGLUE (Chalkidis et al., 2022; Tuggener et al., 2020; Lippi et al., 2018). Bộ dữ liệu EURLEX bao gồm một cặp luật pháp Liên minh Châu Âu (đầu vào) và các khái niệm pháp lý tương ứng (đầu ra) từ Từ điển EuroVoc. Trong nhiệm vụ LEDGAR, một mô hình cần phân loại các đoạn văn từ hợp đồng có nguồn gốc từ hồ sơ Ủy ban Chứng khoán và Giao dịch Hoa Kỳ. Tương tự, UNFAIR-ToS là một nhiệm vụ dự đoán 8 loại điều khoản hợp đồng không công bằng cho các câu riêng lẻ được cung cấp từ 50 Điều khoản Dịch vụ. Ba nhiệm vụ phân loại này được sử dụng để chứng minh NESTLE trên benchmark AI pháp lý phổ biến (tiếng Anh) và cũng để cho thấy NESTLE có thể được áp dụng cho các nhiệm vụ AI tổng quát có thể được biểu diễn dưới định dạng text-to-text (Raffel et al., 2020).

[Continues with additional sections about performance analysis and results...]

[THIS IS FIGURE: Figure 3 showing trade-off analysis on FRAUD task focusing on three real-world metrics: (a) accuracy, (b) cost, and (c) time]

--- TRANG 6 ---
[Tables and additional content continue with performance metrics and analysis...]

--- TRANG 7 ---
7 Phân tích

Chúng tôi đã cho thấy rằng NESTLE có thể trích xuất thông tin với độ chính xác tương đương GPT-4 trên nhiều nhiệm vụ. Trong phần này, chúng tôi mở rộng so sánh NESTLE với các LLM thương mại tập trung vào hai chỉ số thực tế bổ sung: chi phí và thời gian. Như một nghiên cứu trường hợp, chúng tôi chọn nhiệm vụ FRAUD từ KORPREC-IE nơi tất cả các mô hình đều gặp khó khăn (Bảng 1, cột 11 và 12, Hình 3a). Chúng tôi tính toán chi phí tổng thể bằng cách cộng (1) chi phí gán nhãn thủ công, (2) chi phí API, và (3) chi phí huấn luyện và suy luận. Chi phí gán nhãn thủ công được ước tính từ chi phí duy trì nền tảng gán nhãn riêng của chúng tôi (chi phí thuê người gán nhãn bán thời gian được xem xét). Chi phí API được tính bằng cách đếm token đầu vào và đầu ra và sử dụng bảng giá từ OpenAI. Chi phí huấn luyện và suy luận được tính bằng cách chuyển đổi thời gian huấn luyện và suy luận sang đô la dựa trên giá GPU cloud của Lambdalabs. Lưu ý rằng chi phí API tăng tuyến tính với kích thước của kho tài liệu khi sử dụng LLM thương mại. Mặt khác, trong NESTLE, chỉ chi phí suy luận tăng tuyến tính với kích thước của kho tài liệu. Kết quả cho thấy, đối với 10k tài liệu, chi phí tổng thể của NESTLE-L chỉ bằng 4% của ChatGPT và 0.4% của GPT-4 (Hình 3b). Đối với 1 triệu tài liệu, chi phí tổng thể của NESTLE-L là 0.5% của ChatGPT và 0.05% của GPT-4 (Hình 3b). Điều này làm nổi bật hiệu quả của NESTLE. Tương tự, ước tính thời gian suy luận tổng thể cho 1 triệu tài liệu cho thấy NESTLE-L mất ít thời gian hơn 83% hoặc 99% so với ChatGPT hoặc GPT-4 tương ứng4.

8 Kết luận

Chúng tôi phát triển NESTLE, một công cụ không cần mã lệnh cho phân tích thống kê kho tài liệu pháp lý. Để tìm kho tài liệu mục tiêu, cấu trúc hóa chúng, và trực quan hóa dữ liệu có cấu trúc, chúng tôi kết hợp một công cụ tìm kiếm, một mô-đun IE tùy chỉnh từ đầu đến cuối, và LLM. Được hỗ trợ bởi LLM và mô-đun IE từ đầu đến cuối, NESTLE cho phép phân tích thống kê cá nhân hóa không hạn chế của kho tài liệu. Chúng tôi xác thực NESTLE một cách rộng rãi trên 15 nhiệm vụ IE tiền lệ Hàn Quốc và 3 nhiệm vụ phân loại văn bản pháp lý tiếng Anh trong khi tập trung vào ba chỉ số thực tế: độ chính xác, thời gian và chi phí. Cuối cùng, chúng tôi muốn nhấn mạnh rằng mặc dù NESTLE được chuyên biệt hóa cho các nhiệm vụ IE pháp lý, công cụ này có thể dễ dàng được tổng quát hóa cho các nhiệm vụ NLP khác nhau có thể được biểu diễn dưới định dạng text-to-text.

4So sánh chi tiết hơn có sẵn từ https://github.com/lbox-kr/nestle

9 Xem xét Đạo đức

Việc áp dụng AI pháp lý trong thế giới thực phải được tiếp cận một cách thận trọng. Ngay cả LLM được cho là mạnh nhất, GPT-4, vẫn thể hiện các ảo giác (OpenAI, 2023) và hiệu suất của nó trong các nhiệm vụ pháp lý thực tế vẫn còn hạn chế (Shui et al., 2023; Zhong et al., 2023; Martinez, 2023). Điều này có thể ngụ ý rằng các hệ thống AI cung cấp kết luận pháp lý nên trải qua đánh giá kỹ lưỡng trước khi được cung cấp cho các cá nhân thiếu chuyên môn pháp lý.

NESTLE không được thiết kế để cung cấp lời khuyên pháp lý cho người dùng chung; thay vào đó, nó nhằm hỗ trợ các chuyên gia pháp lý bằng cách cung cấp dữ liệu thống kê được trích xuất từ các tài liệu pháp lý. Hơn nữa, để chứng minh mức độ mà NESTLE có thể được sử dụng một cách đáng tin cậy cho phân tích, chúng tôi đã tiến hành xác thực rộng rãi trên 15 nhiệm vụ IE. Trong khi NESTLE cho thấy độ chính xác chung cao, các thí nghiệm của chúng tôi cho thấy rằng NESTLE không hoàn hảo, chỉ ra rằng các thống kê kết quả nên được diễn giải một cách thận trọng.

Tất cả các tài liệu được sử dụng trong nghiên cứu này bao gồm các tiền lệ Hàn Quốc được biên tập bởi chính phủ Hàn Quốc theo giao thức chính thức (Hwang et al., 2022b).

Lời cảm ơn

Chúng tôi cảm ơn Gene Lee vì việc đọc kỹ bản thảo một cách quan trọng, Minjoon Seo vì những bình luận sâu sắc của ông, Paul Koo vì sự hỗ trợ của ông trong việc chuẩn bị các hình ảnh, và Min Choi vì sự hỗ trợ của cô trong việc chuẩn bị demo.

Tài liệu tham khảo

[Danh sách tài liệu tham khảo tiếp tục với tất cả các citation được dịch sang tiếng Việt...]

--- TRANG 8 ---
[Tiếp tục danh sách tài liệu tham khảo được dịch sang tiếng Việt...]

--- TRANG 9 ---
[Tiếp tục danh sách tài liệu tham khảo được dịch sang tiếng Việt...]

--- TRANG 10 ---
[Kết thúc danh sách tài liệu tham khảo được dịch sang tiếng Việt...]

# 2306.01248_vi.txt
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/legal/2306.01248.pdf
# Kích thước tệp: 252059 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Các Mô Hình Tóm Tắt Trừu Tượng Được Huấn Luyện Trước và LLM Đã Sẵn Sàng Như Thế Nào cho Việc Tóm Tắt Phán Quyết Vụ Án Pháp Lý?
Aniket Deroy
IIT Kharagpur
West Bengal 721302, India
roydanik18@gmail.comKripabandhu Ghosh
IISER Kolkata
West Bengal 741246, India
kripa.ghosh@gmail.comSaptarshi Ghosh
IIT Kharagpur
West Bengal 721302, India
saptarshi@cse.iitkgp.ac.in
Tóm Tắt
Việc tóm tắt tự động các phán quyết vụ án pháp lý theo truyền thống đã được thử nghiệm bằng cách sử dụng các phương pháp tóm tắt trích xuất. Tuy nhiên, trong những năm gần đây, các mô hình tóm tắt trừu tượng đang trở nên phổ biến vì chúng có thể tạo ra các bản tóm tắt tự nhiên và mạch lạc hơn. Các mô hình tóm tắt trừu tượng được huấn luyện trước chuyên biệt cho lĩnh vực pháp lý hiện đã có sẵn. Hơn nữa, các Mô Hình Ngôn Ngữ Lớn (LLM) được huấn luyện trước cho lĩnh vực chung, chẳng hạn như ChatGPT, được biết là có thể tạo ra văn bản chất lượng cao và có khả năng tóm tắt văn bản. Do đó, việc đặt câu hỏi liệu các mô hình này đã sẵn sàng để ứng dụng ngay để tự động tạo ra các bản tóm tắt trừu tượng cho các phán quyết vụ án là điều tự nhiên. Để khám phá câu hỏi này, chúng tôi áp dụng một số mô hình tóm tắt trừu tượng chuyên biệt cho lĩnh vực tiên tiến và LLM lĩnh vực chung trên các phán quyết vụ án của tòa án Ấn Độ, và kiểm tra chất lượng của các bản tóm tắt được tạo ra. Ngoài các chỉ số tiêu chuẩn cho chất lượng tóm tắt, chúng tôi kiểm tra sự không nhất quán và ảo giác trong các bản tóm tắt. Chúng tôi thấy rằng các mô hình tóm tắt trừu tượng thường đạt được điểm số cao hơn một chút so với các mô hình trích xuất về mặt các chỉ số đánh giá tóm tắt tiêu chuẩn như ROUGE và BLEU. Tuy nhiên, chúng tôi thường tìm thấy thông tin không nhất quán hoặc ảo giác trong các bản tóm tắt trừu tượng được tạo ra. Nhìn chung, cuộc điều tra của chúng tôi cho thấy rằng các mô hình tóm tắt trừu tượng được huấn luyện trước và LLM chưa sẵn sàng để triển khai hoàn toàn tự động cho việc tóm tắt phán quyết vụ án; thay vào đó, một cách tiếp cận có con người trong vòng lặp bao gồm kiểm tra thủ công các sự không nhất quán là phù hợp hơn ở thời điểm hiện tại.

1 Giới Thiệu
Tóm tắt các phán quyết vụ án pháp lý là một vấn đề thực tế và quan trọng trong lĩnh vực pháp lý, xét rằng độ dài và tính phức tạp cực kỳ của các tài liệu như vậy khiến việc đọc chúng một cách đầy đủ trở nên khó khăn ngay cả đối với các thực hành viên pháp lý. Theo truyền thống, các phán quyết vụ án được tóm tắt bởi con người, tức là các thực hành viên pháp lý. Ví dụ, hầu hết các hệ thống thông tin pháp lý cung cấp các bản tóm tắt vụ án/ghi chú chính được viết bởi các thực hành viên pháp lý. Để giảm nỗ lực con người trong việc tóm tắt, đã có nhiều nỗ lực qua các năm để tự động hóa việc tóm tắt các phán quyết vụ án (Bhattacharya et al., 2021; Deroy et al., 2023).

Có hai cách tiếp cận rộng lớn cho việc tóm tắt - Trích xuất (nơi một số câu quan trọng được lựa chọn từ tài liệu đầu vào để tạo thành bản tóm tắt) và Trừu tượng (nơi mô hình cố gắng hiểu tài liệu và tự tạo ra một bản tóm tắt). Người đọc được tham khảo các khảo sát toàn diện của Nenkova et al. (Nenkova và McKeown, 2012) và Wafaa et al. (El-Kassas et al., 2021) để biết thêm chi tiết về các loại thuật toán tóm tắt khác nhau.

Đối với việc tóm tắt các phán quyết vụ án pháp lý, các mô hình tóm tắt trích xuất chủ yếu đã được áp dụng qua các năm (Bhattacharya et al., 2021; Polsley et al., 2016; Liu và Chen, 2019; Zhong et al., 2019). Nhưng trong thời gian gần đây, cộng đồng nghiên cứu đang ưa thích việc sử dụng các mô hình tóm tắt trừu tượng, chủ yếu vì các phương pháp trừu tượng được cho là tạo ra các bản tóm tắt 'tự nhiên' và 'mạch lạc' hơn. Kết quả là, một số công trình gần đây đã bắt đầu huấn luyện các mô hình trừu tượng cho việc tóm tắt tài liệu pháp lý (Shukla et al., 2022; Feijo và Moreira, 2023). Các phiên bản được huấn luyện trước chuyên biệt cho lĩnh vực của các mô hình tóm tắt trừu tượng phổ biến, chẳng hạn như Pegasus của Google (Zhang et al., 2020), đã được phát hành đặc biệt cho việc tóm tắt pháp lý (ví dụ: Legal Pegasus – https://huggingface.co/nsi319/legal-pegasus). Hơn nữa, thời gian gần đây đã chứng kiến sự ra đời của các Mô Hình Ngôn Ngữ Lớn đa mục đích (LLM) như ChatGPT và DaVinci có khả năng tạo ra văn bản chất lượng cao cũng như khả năng tóm tắt văn bản mà không cần huấn luyện bổ sung. Một lợi thế lớn của các mô hình tóm tắt trừu tượng được huấn luyện trước và LLM này là chúng có thể được áp dụng mà không cần huấn luyện thêm. Trên thực tế, LLM đã được sử dụng cho việc tóm tắt trong các lĩnh vực khác, ví dụ như tóm tắt tin tức (Zhang et al., 2023). Nhưng, theo hiểu biết của chúng tôi, những LLM này chưa được sử dụng nhiều cho việc tóm tắt phán quyết vụ án pháp lý cho đến nay.

Trong tình huống như vậy, việc đặt câu hỏi là điều tự nhiên – các mô hình tóm tắt trừu tượng được huấn luyện trước và các LLM có sẵn ngày nay đã sẵn sàng như thế nào để ứng dụng ngay cho việc tóm tắt phán quyết vụ án pháp lý? Trong bài báo này, chúng tôi cố gắng trả lời câu hỏi này.

Chúng tôi áp dụng các mô hình tóm tắt trừu tượng tiên tiến được thiết kế đặc biệt cho lĩnh vực pháp lý – như Legal-Pegasus (https://huggingface.co/nsi319/legal-pegasus) và Legal-LED (https://huggingface.co/nsi319/legal-led-base-16384) – cũng như các Mô Hình Ngôn Ngữ Lớn được phát triển gần đây như DaVinci và ChatGPT, trên một tập dữ liệu các phán quyết vụ án của Tòa án Tối cao Ấn Độ (chứa các bản tóm tắt tiêu chuẩn vàng được viết bởi các thực hành viên pháp lý). Chúng tôi cũng áp dụng một số mô hình tóm tắt trích xuất trên cùng tập dữ liệu để so sánh. Chúng tôi báo cáo một số lượng lớn các chỉ số chất lượng tóm tắt cho tất cả các mô hình, bao gồm các chỉ số truyền thống như ROUGE, METEOR và BLEU (khớp các bản tóm tắt được tạo bởi mô hình với các bản tóm tắt tiêu chuẩn vàng) và các chỉ số để định lượng tính nhất quán của các bản tóm tắt so với tài liệu gốc.

Chúng tôi quan sát thấy rằng các bản tóm tắt được tạo bởi các mô hình trừu tượng đạt được điểm ROUGE, METEOR, BLEU cao hơn một chút so với những bản được tạo bởi các mô hình trích xuất. Tuy nhiên, các bản tóm tắt trừu tượng có nhiều vấn đề khác nhau, bao gồm các câu/từ không hoàn chỉnh, nhiều câu được gộp lại một cách vô nghĩa, cũng như các lỗi nghiêm trọng hơn như thông tin không nhất quán và ảo giác. Ví dụ, chúng tôi quan sát thấy rằng các mô hình tóm tắt trừu tượng và LLM đôi khi tạo ra ngày tháng sai và tên người sai trong các bản tóm tắt, và cũng nhầm lẫn các người khác nhau liên quan đến một vụ án. Do đó, các đóng góp của chúng tôi trong công trình này như sau:

(1) Chúng tôi áp dụng các mô hình tóm tắt trừu tượng được huấn luyện trước và LLM (và một số mô hình tóm tắt trích xuất để so sánh) trên một tập các phán quyết vụ án của tòa án Ấn Độ, và báo cáo một số chỉ số bao gồm không chỉ các chỉ số đánh giá tóm tắt truyền thống, mà còn các chỉ số cho tính nhất quán của các bản tóm tắt được tạo ra.

(2) Theo hiểu biết của chúng tôi, bài báo này là phân tích đầu tiên về tính nhất quán của các bản tóm tắt trừu tượng trong lĩnh vực pháp lý. Chúng tôi chỉ ra rằng, mặc dù các mô hình trừu tượng thường đạt được điểm ROUGE, BLEU, METEOR cao hơn so với các mô hình trích xuất, các bản tóm tắt trừu tượng thường chứa thông tin ảo giác hoặc không nhất quán.

(3) Chúng tôi trình bày một số ví dụ về lỗi, bao gồm sự hiện diện của thông tin ảo giác hoặc không nhất quán, trong các bản tóm tắt phán quyết vụ án được tạo bởi các LLM tiên tiến và các mô hình tóm tắt trừu tượng được huấn luyện trước. Theo hiểu biết của chúng tôi, đây là nghiên cứu đầu tiên chứng minh các ví dụ như vậy.

Các phân tích của chúng tôi chỉ ra rằng các mô hình tóm tắt trừu tượng được huấn luyện trước và LLM cần được cải thiện thêm trước khi chúng có thể được sử dụng một cách dễ dàng cho việc tóm tắt phán quyết vụ án bởi các chuyên gia pháp lý.

2 Công Trình Liên Quan
Tóm tắt các phán quyết vụ án pháp lý: Theo truyền thống, các mô hình tóm tắt trích xuất đã được sử dụng để tóm tắt các phán quyết vụ án pháp lý. Nhiều phương pháp khác nhau đã được thử nghiệm bao gồm các kỹ thuật tối ưu hóa (Bhattacharya et al., 2021), học đa nhiệm (Agarwal et al., 2022), phân loại dựa trên Machine Learning (Liu và Chen, 2019), v.v. Các mô hình trích xuất đã được thử nghiệm bao gồm cả các mô hình không giám sát (Bhattacharya et al., 2021) và có giám sát (Agarwal et al., 2022; Liu và Chen, 2019).

Trong thời gian gần đây, đã có một số công trình về tóm tắt trừu tượng các phán quyết vụ án pháp lý. Công trình trước đây gần đây của chúng tôi (Shukla et al., 2022) đã áp dụng các mô hình trừu tượng khác nhau như BART, Legal-LED và Legal-Pegasus trên các phán quyết tòa án Ấn Độ và Anh. Có các công trình trước đây về phân đoạn ngữ nghĩa của các tài liệu pháp lý dài trong các thiết lập ít tài nguyên, thảo luận về cách xử lý các tài liệu pháp lý dài (thường lớn hơn độ dài đầu vào của các mô hình dựa trên bộ mã hóa-giải mã) để thực hiện tóm tắt tài liệu pháp lý trừu tượng (Moro và Ragazzi, 2022). Có các công trình cố gắng cải thiện tóm tắt trừu tượng các phán quyết vụ án pháp lý bằng cách sử dụng kéo theo văn bản (Feijo và Moreira, 2023).

Ảo giác trong các mô hình ngôn ngữ lớn: Trong bối cảnh xử lý ngôn ngữ tự nhiên (NLP), ảo giác đề cập đến một hiện tượng nơi một mô hình ngôn ngữ tạo ra văn bản không đúng sự thật hoặc không chính xác dựa trên đầu vào mà nó đã được cung cấp. Điều này có thể xảy ra vì nhiều lý do khác nhau, chẳng hạn như thiếu dữ liệu huấn luyện, thiên vị trong dữ liệu huấn luyện, hoặc các hạn chế trong kiến trúc mô hình ngôn ngữ (xem (Ji et al., 2023) để có một khảo sát).

Đã có các nghiên cứu về ảo giác đặc biệt trong các bản tóm tắt trừu tượng. Vì ảo giác là không mong muốn trong các bản tóm tắt, nhiều công trình khác nhau đã cố gắng giảm ảo giác trong các bản tóm tắt được tạo bởi các mô hình tóm tắt trừu tượng (Filippova, 2020; Zhao et al., 2020).

Sự ra đời của các Mô Hình Ngôn Ngữ Lớn (LLM) như ChatGPT, và việc tăng cường sử dụng chúng trong viết học thuật đang làm tăng thêm mối quan ngại về tính toàn vẹn và độ chính xác của văn bản được tạo ra (Alkaissi và McFarlane, 2023). Trong khi các mô hình như vậy được huấn luyện trên lượng dữ liệu khổng lồ và có thể sản xuất nội dung chất lượng cao, luôn có rủi ro rằng văn bản được tạo ra có thể chứa các điều không chính xác, thiên vị, hoặc thậm chí là các bịa đặt hoàn toàn. Ví dụ, các mô hình ngôn ngữ được huấn luyện trên Wikipedia và các nguồn trực tuyến khác đã được phát hiện tạo ra nội dung phân biệt giới tính và phân biệt chủng tộc hơn (Stanczak và Augenstein, 2021). Ngoài ra, LLM cũng có thể tạo ra văn bản không nhất quán với các sự kiện khoa học đã được thiết lập hoặc trình bày thông tin gây hiểu lầm.

Tính mới lạ của công trình này: Đã có ít nỗ lực phân tích cách các phương pháp tóm tắt trừu tượng và LLM khác nhau (như ChatGPT) hoạt động trong việc tóm tắt các phán quyết vụ án pháp lý. Ngoài ra, theo hiểu biết của chúng tôi, ảo giác chưa được nghiên cứu trước đây trong bối cảnh tóm tắt pháp lý. Công trình này thực hiện bước đầu tiên hướng tới việc hiểu mức độ chuẩn bị của các mô hình tóm tắt trừu tượng / LLM ngày nay cho nhiệm vụ tóm tắt phán quyết vụ án tự động.

3 Tập Dữ Liệu
Chúng tôi tái sử dụng một tập dữ liệu các phán quyết của Tòa án Tối cao Ấn Độ từ công trình trước đây của chúng tôi (Shukla et al., 2022). Tập dữ liệu, được gọi là IN-Abs, chứa tổng cộng 7.130 phán quyết pháp lý từ trang web của Viện Thông tin Pháp lý Ấn Độ¹, cùng với một bản tóm tắt trừu tượng cho mỗi phán quyết. Các bản tóm tắt (còn được gọi là 'ghi chú chính') đã được viết bởi các chuyên gia pháp lý được chỉ định bởi Viện Thông tin Pháp lý Ấn Độ.

Trong tổng số 7.130 cặp phán quyết-tóm tắt trong tập dữ liệu, 7.030 cặp phán quyết-tóm tắt được coi là tập huấn luyện và 100 phán quyết khác được coi là tập kiểm tra. Một số mô hình trừu tượng/trích xuất có giám sát được xem xét trong công trình này đã được huấn luyện hoặc tinh chỉnh trên tập huấn luyện IN-Abs. Tất cả các mô hình tóm tắt được đánh giá trên tập kiểm tra IN-Abs (100 tài liệu).

Bảng 1 thể hiện số lượng tài liệu trong các tập huấn luyện và kiểm tra, cùng với số từ trung bình có trong một phán quyết pháp lý và một bản tóm tắt tiêu chuẩn vàng. Chi tiết thêm về tập dữ liệu IN-Abs có sẵn trong (Shukla et al., 2022).

4 Phương Pháp Tóm Tắt Các Phán Quyết Vụ Án Pháp Lý
Chúng tôi đã thử nhiều mô hình tóm tắt khác nhau trong công trình này. Có 3 danh mục chính của các phương pháp tóm tắt được áp dụng trong công trình này: (1) Các mô hình ngôn ngữ lớn lĩnh vực chung, (2) Các mô hình tóm tắt trừu tượng chuyên biệt cho lĩnh vực pháp lý, và (3) Các mô hình tóm tắt trích xuất.

4.1 Các Mô Hình Ngôn Ngữ Lớn Lĩnh Vực Chung
Chúng tôi thử nghiệm hai Mô hình ngôn ngữ lớn (LLM) phổ biến, cụ thể là Text-Davinci-003 và Turbo-Gpt-3.5, cả hai đều được phát triển bởi OpenAI².

Text-Davinci-003 (mà chúng tôi gọi tắt là Davinci) là một mô hình ngôn ngữ dựa trên transformer với 175 tỷ tham số, khiến nó trở thành một trong những mô hình ngôn ngữ lớn nhất và tiên tiến nhất cho đến nay. Mô hình ngôn ngữ đã được huấn luyện trên một phạm vi dữ liệu văn bản đa dạng, bao gồm các trang web, sách, bài báo khoa học và các nguồn văn bản được viết bởi con người khác. OpenAI đã không cung cấp thông tin chi tiết về các nguồn chính xác của dữ liệu huấn luyện, nhưng được biết rằng mô hình đã được huấn luyện trên một tập dữ liệu văn bản quy mô lớn sử dụng kết hợp các phương pháp học có giám sát và không giám sát.

Turbo-GPT-3.5 (được biết đến phổ biến là ChatGPT) là một mô hình ngôn ngữ dựa trên kiến trúc GPT-3 được phát triển bởi OpenAI. Mô hình được cho là có khoảng 154 tỷ tham số. Turbo-GPT-3.5 được huấn luyện trên một phạm vi dữ liệu văn bản đa dạng, bao gồm các trang web, sách, bài báo khoa học và các nguồn văn bản được viết bởi con người khác bao gồm cả các cuộc trò chuyện, sử dụng kết hợp các phương pháp học có giám sát và học tăng cường. Mô hình đã được tối ưu hóa về tốc độ và hiệu suất, với việc sử dụng bộ nhớ và tài nguyên tính toán hiệu quả.

Davinci được cho là mô hình lớn nhất và mạnh mẽ nhất cho đến nay, có hiệu suất tốt nhất trong nhiều nhiệm vụ NLP phức tạp. ChatGPT là một mô hình rẻ hơn với ít tham số hơn một chút; mặc dù được cho là 'được tối ưu hóa cho trò chuyện', ChatGPT cũng hoạt động rất tốt trong nhiều loại nhiệm vụ NLP.

Cả hai LLM này đều nhận đầu vào là một 'lời nhắc' và tạo ra văn bản để phản hồi. Đặc biệt cho nhiệm vụ tóm tắt, lời nhắc bao gồm (i) văn bản cần được tóm tắt, mà chúng tôi gọi là <text to summarize> và (ii) một 'hướng dẫn' cho mô hình biết rằng văn bản đầu vào cần được tóm tắt. Đối với cả hai LLM – Text-Davinci-003 và Turbo-GPT-3.5 – chúng tôi xem xét hai biến thể đưa ra hai lời nhắc khác nhau cho việc tóm tắt, như được giải thích dưới đây.

Các biến thể của Text-Davinci-003: Chúng tôi thử hai biến thể này của mô hình:-
(i) davinci-tldr: đối với mô hình này, lời nhắc là "<text to summarize> Tl;Dr ". Nói cách khác, văn bản cần được tóm tắt được truyền trước tiên sau đó là "Tl;Dr" là một định danh tích hợp cho việc tóm tắt³.
(ii) davinci-summ: đối với mô hình này, lời nhắc là "<text to summarize> Summarize the document in <XX> words" trong đó XX là một số đại diện cho độ dài mục tiêu của bản tóm tắt đầu ra tính bằng số từ, tức là số từ tối đa trong bản tóm tắt cần được tạo ra. Cách quyết định độ dài mục tiêu XX sẽ được giải thích dưới đây.

Các biến thể của Turbo-Gpt-3.5 (ChatGPT): Tương tự như những gì chúng tôi đã làm cho mô hình Davinci, chúng tôi thử các biến thể sau:-
(i) chatgpt-tldr: ở đây lời nhắc là "Tl;Dr <text to summarize> ". Nói cách khác, định danh tích hợp cho việc tóm tắt "Tl;Dr" được gửi trước tiên, sau đó là văn bản cần tóm tắt.
(ii) chatgpt-summ: đối với mô hình này, lời nhắc là "Summarize the document in <XX> words <text to summarize> " trong đó XX là một số đại diện cho độ dài mục tiêu của bản tóm tắt đầu ra (tính bằng từ). Việc lựa chọn độ dài mục tiêu được thảo luận dưới đây.

Phân đoạn các tài liệu pháp lý dài: Các LLM như ChatGPT và DaVinci áp đặt các hạn chế về độ dài của đầu vào có thể được cung cấp cùng một lúc. Cụ thể, Text-Davinci-003 và Turbo-GPT-3.5 có giới hạn 4.096 token cho (Lời nhắc + văn bản được tạo), trong đó mỗi 'token' đại diện cho khoảng 4 ký tự. Trung bình, một token tương ứng với ¾ của một từ tiếng Anh, hoặc 100 token xấp xỉ tương ứng với 75 từ⁴.

Vì hầu hết các phán quyết vụ án pháp lý dài hơn giới hạn này (có hơn 4.300 từ trung bình), chúng tôi phải tuân theo một chiến lược chia để trị để tóm tắt các tài liệu pháp lý dài bằng cách sử dụng các LLM này. Với giới hạn 4.096 token cho (Lời nhắc + văn bản được tạo), chúng tôi chọn gửi nhiều nhất 1.024 từ làm văn bản cần được tóm tắt (như một phần của lời nhắc, như được mô tả ở trên) cùng một lúc cho các LLM này. Do đó, chúng tôi phân đoạn các tài liệu pháp lý có độ dài cao hơn 1.024 từ và sau đó truyền các đoạn (từng đoạn một) vào Turbo-Gpt-3.5 / Text-Davinci-003 để có được các bản tóm tắt đầu ra cho các đoạn. Bản tóm tắt cho mỗi đoạn (có kích thước 1.024 hoặc ít hơn) được lấy từ các mô hình này và sau đó các bản tóm tắt của tất cả các đoạn được nối lại với nhau (theo cùng thứ tự như của các đoạn) để tạo thành bản tóm tắt đầu ra cuối cùng cho tài liệu phán quyết vụ án. Đối với các tài liệu pháp lý có độ dài ít hơn 1.024 từ, toàn bộ tài liệu được truyền vào mô hình cùng một lúc để có được bản tóm tắt.

Lưu ý rằng hiệu suất của các mô hình tóm tắt có thể phụ thuộc vào kích thước của các đoạn. Chúng tôi đã tiến hành thí nghiệm với một tập con của các tài liệu xem xét hai kích thước đoạn – 1.024 từ và 2.048 từ. Chúng tôi quan sát thấy ChatGPT hoạt động tốt hơn một chút với các đoạn 1.024 từ, theo tất cả các chỉ số đánh giá tóm tắt (các chỉ số sẽ được chi tiết trong phần tiếp theo). Trong khi đó, Davinci cho giá trị tốt hơn một chút cho một số chỉ số với các đoạn 1.024 từ, và giá trị tốt hơn cho các chỉ số khác với các đoạn 2.048 từ. Để đơn giản và nhất quán, trong công trình này, chúng tôi báo cáo tất cả các kết quả xem xét các đoạn có kích thước nhiều nhất 1.024 từ cho tất cả các mô hình. Khám phá thêm về sự phụ thuộc của hiệu suất tóm tắt vào kích thước đoạn được để dành cho công việc tương lai.

Quyết định độ dài tóm tắt mục tiêu cho một đoạn: Khi một số văn bản được gửi đến LLM để tóm tắt, chúng ta cần chỉ định độ dài tóm tắt mục tiêu trong siêu tham số 'max tokens', tức là số từ tối đa trong bản tóm tắt cần được tạo ra.

Giả sử một đoạn văn bản có độ dài 1024 từ từ một tài liệu D được gửi đến LLM để tóm tắt. Gọi độ dài của tài liệu D là |D| từ, và độ dài của bản tóm tắt tiêu chuẩn vàng của D là |S| từ. Khi đó độ dài tóm tắt mục tiêu cho đoạn được chỉ định là |S|/|D| × 1024 từ. Nói cách khác, chúng tôi yêu cầu LLM tóm tắt mỗi đoạn xem xét cùng tỷ lệ nén như cho toàn bộ tài liệu và bản tóm tắt tiêu chuẩn vàng.

Có một hạn chế vốn có trong phương pháp này, như sau. Trong thực tế, tất cả các phần của tài liệu không quan trọng ngang nhau, do đó các đoạn khác nhau có thể nên được phân bổ độ dài khác nhau trong bản tóm tắt cuối cùng. Ngược lại, phương pháp này phân bổ cùng độ dài trong bản tóm tắt cho tất cả các đoạn. Tuy nhiên, không có cách đơn giản nào để biết tầm quan trọng tương đối của các đoạn khác nhau trong một phán quyết vụ án pháp lý.

Chi tiết triển khai: Các LLM được nêu ở trên đã được chạy bằng API OpenAI⁵. Các siêu tham số của Text-Davinci-003 và Turbo-GPT-3.5 được chỉ ra trong Bảng 2. Chúng tôi sử dụng các giá trị mặc định cho các siêu tham số 'presence penalty', 'frequency penalty' và 'temperature'. Siêu tham số 'max tokens' chỉ ra số từ tối đa trong bản tóm tắt cần được tạo ra cho một đoạn văn bản đầu vào; nó được tính như được mô tả ở trên.

4.2 Các mô hình tóm tắt trừu tượng chuyên biệt cho lĩnh vực pháp lý
Trong khi các LLM được mô tả trong phần trước là lĩnh vực chung (không được huấn luyện cho bất kỳ lĩnh vực hoặc nhiệm vụ cụ thể nào), bây giờ chúng tôi xem xét một số mô hình tóm tắt trừu tượng được thiết kế đặc biệt cho việc tóm tắt trong lĩnh vực pháp lý.

Một mô hình như vậy là Legal-Pegasus (mà chúng tôi viết tắt là LegPegasus). Mô hình này dựa trên mô hình google/pegasus-cnn_dailymail được phát triển bởi Google, được thiết kế để thực hiện nhiệm vụ tóm tắt trừu tượng. LegPegasus đã được thiết kế đặc biệt cho lĩnh vực pháp lý bằng cách tinh chỉnh nó trên tập dữ liệu 'sec-litigation-releases' bao gồm hơn 2.700 thông cáo kiện tụng và khiếu nại liên quan đến các vụ kiện dân sự tại các tòa án khác nhau ở Hoa Kỳ (và các bản tóm tắt của chúng) được đưa ra bởi Ủy ban Chứng khoán và Giao dịch Hoa Kỳ. Mô hình LegPegasus có sẵn tại https://huggingface.co/nsi319/legal-pegasus và có độ dài chuỗi đầu vào tối đa là 1024 token.

Một mô hình tóm tắt trừu tượng khác được thiết kế đặc biệt cho lĩnh vực pháp lý là Legal-LED (Legal Longformer Encoder Decoder) mà chúng tôi viết tắt là LegLED. Mô hình LegLED dựa trên kiến trúc Longformer, một kiến trúc mạng neural dựa trên transformer đã được thiết kế đặc biệt để xử lý các chuỗi văn bản dài. LegLED, có sẵn tại https://huggingface.co/nsi319/legal-led-base-16384, đã được tinh chỉnh trên cùng tập dữ liệu 'sec-litigation-releases' như được mô tả ở trên, để làm cho nó phù hợp cho việc tóm tắt trong lĩnh vực pháp lý.

Như đã nêu ở trên, cả LegPegasus và LegLED đều đã được tinh chỉnh trên các tài liệu pháp lý và các bản tóm tắt của chúng từ các Tòa án Pháp lý Hoa Kỳ. Để làm cho các mô hình phù hợp hơn cho việc tóm tắt các tài liệu pháp lý Ấn Độ, công trình trước đây của chúng tôi (Shukla et al., 2022) đã tinh chỉnh thêm các mô hình trên tập huấn luyện IN-Abs (chứa 7.030 phán quyết vụ án Ấn Độ và các bản tóm tắt của chúng, như đã nêu trong Phần 3). Chúng tôi gọi các mô hình này là LegPegasus-IN và LegLED-IN vì chúng đã được tinh chỉnh đặc biệt để tóm tắt các tài liệu pháp lý Ấn Độ.

Phân đoạn các tài liệu pháp lý dài: Vì các mô hình trừu tượng chuyên biệt cho lĩnh vực cũng có hạn chế về số lượng token đầu vào, chúng tôi tuân theo một chiến lược dựa trên phân đoạn tương tự để xử lý các tài liệu pháp lý dài, như đã được mô tả trong Phần 4.1. Chúng tôi phân đoạn các tài liệu pháp lý (có độ dài cao hơn 1.024 từ) thành các đoạn nhiều nhất 1.024 từ và sau đó truyền từng đoạn một vào các mô hình tóm tắt. Bản tóm tắt cho mỗi đoạn được lấy từ các mô hình này và sau đó được nối lại với nhau (theo cùng thứ tự như các đoạn trong tài liệu nguồn) để tạo thành bản tóm tắt đầu ra cuối cùng. Độ dài tóm tắt mục tiêu của mỗi đoạn được quyết định như được mô tả trong Phần 4.1. Đối với các tài liệu ngắn hơn 1.024 từ, toàn bộ bản tóm tắt của tài liệu được lấy cùng một lúc.

4.3 Các mô hình tóm tắt trích xuất
Chúng tôi xem xét một số mô hình tóm tắt trích xuất để so sánh với các mô hình trừu tượng và LLM. Trong các công trình trước đây của chúng tôi (Deroy et al., 2023; Shukla et al., 2022), chúng tôi đã áp dụng một số phương pháp tóm tắt trích xuất trên tập dữ liệu IN-Abs. Chúng tôi quan sát thấy rằng ba phương pháp (i) CaseSummarizer, (ii) BertSum, và (iii) SummaRunner/RNN_RNN hoạt động tốt trên tập dữ liệu IN-Abs qua hầu hết các chỉ số. Vì vậy chúng tôi bao gồm ba phương pháp trích xuất sau trong so sánh.

(1) Case Summarizer (Polsley et al., 2016) là một phương pháp không giám sát xác định các câu hoặc cụm từ liên quan nhất của một tài liệu vụ án pháp lý dựa trên một chỉ số như TF-IDF. CaseSummarizer điều chỉnh điểm số câu bằng cách sử dụng các lần xuất hiện của các thực thể đã biết, ngày tháng, và độ gần với các tiêu đề phần.

(2) BertSum (Liu, 2019) là một mô hình tóm tắt có giám sát sử dụng kiến trúc Bidirectional Encoder Representations from Transformers (BERT). Mô hình này coi việc tóm tắt như một vấn đề phân loại nhị phân nơi mỗi câu (trong tài liệu) được gắn nhãn 1 nếu câu phù hợp để đưa vào bản tóm tắt, và 0 nếu không. Mô hình được huấn luyện (trên một tập huấn luyện chứa các tài liệu và các bản tóm tắt tiêu chuẩn vàng) để xác định các câu phù hợp để đưa vào bản tóm tắt.

(3) SummaRunner/RNN_RNN (Nallapati et al., 2017) là một mô hình có giám sát cố gắng xác định các câu quan trọng nhất trong một văn bản và tạo ra một bản tóm tắt ngắn gọn. Tương tự như BertSum, mô hình này coi việc tóm tắt như một vấn đề phân loại, và cũng phân tích các mối quan hệ giữa các câu trong một tài liệu để chọn những câu chứa thông tin liên quan nhất.

Đối với tất cả ba mô hình trích xuất được nêu trước đó, chúng tôi sử dụng các triển khai được cung cấp trong công trình trước đây của chúng tôi (Shukla et al., 2022). Các mô hình có giám sát BertSum và SummaRunner/RNN_RNN đã được huấn luyện trên 7.030 cặp (tài liệu pháp lý, tóm tắt) trong tập huấn luyện IN-Abs. Chi tiết thêm về quy trình huấn luyện có sẵn trong (Shukla et al., 2022).

5 So Sánh Hiệu Suất của Các Mô Hình Tóm Tắt
Trong phần trước, chúng tôi đã mô tả một số mô hình tóm tắt, bao gồm LLM, các mô hình trừu tượng chuyên biệt cho lĩnh vực, và các mô hình trích xuất. Bây giờ chúng tôi so sánh chất lượng của các bản tóm tắt được tạo bởi các phương pháp khác nhau theo hai khía cạnh – (1) sự khớp của chúng với các bản tóm tắt tiêu chuẩn vàng, và (2) tính nhất quán của chúng với các tài liệu đầu vào.

5.1 Khớp với các bản tóm tắt tiêu chuẩn vàng
Chúng tôi đầu tiên thảo luận về các chỉ số được sử dụng để đo lường sự khớp với bản tóm tắt tiêu chuẩn vàng, và sau đó so sánh hiệu suất của các mô hình tóm tắt khác nhau theo những chỉ số đó.

5.1.1 Chỉ số
Chúng tôi sử dụng các chỉ số nổi tiếng sau đây so sánh một bản tóm tắt được tạo bởi mô hình với bản tóm tắt tiêu chuẩn vàng (được viết bởi các chuyên gia lĩnh vực) và đưa ra một điểm số, trong đó điểm số cao hơn có nghĩa là khớp cao hơn với tiêu chuẩn vàng (và do đó là một bản tóm tắt chất lượng tốt hơn).

(1) ROUGE (Lin, 2004) (Recall Oriented Understudy of Gisting Evaluation) có lẽ là chỉ số phổ biến nhất được sử dụng để đo lường chất lượng của một bản tóm tắt được tạo bởi một mô hình tóm tắt. Cụ thể, chúng tôi tính điểm độ chính xác, recall và F1 của Rouge-2 đo lường sự khớp bigram giữa các bản tóm tắt tiêu chuẩn vàng và các bản tóm tắt được tạo bởi mô hình, và điểm độ chính xác, recall và F1 của Rouge-L đo lường sự khớp dựa trên Longest Common Subsequence giữa các bản tóm tắt được tạo và các bản tóm tắt tiêu chuẩn vàng.

(2) METEOR (Banerjee và Lavie, 2005) tính trung bình điều hòa của độ chính xác và recall unigram và thường được sử dụng để đánh giá đầu ra dịch máy. Các công trình trước đây cũng đã sử dụng chỉ số này để đánh giá các bản tóm tắt (Deroy et al., 2023). Ở đây chúng tôi sử dụng chỉ số này để tính sự chồng lấp unigram giữa một bản tóm tắt được tạo bởi mô hình và bản tóm tắt tiêu chuẩn vàng.

(3) BLEU (Papineni et al., 2002) (Bilingual Evaluation Understudy) là một chỉ số thường được sử dụng để đánh giá đầu ra dịch máy, nhưng nó cũng có thể được sử dụng để đo lường mức độ khớp của một bản tóm tắt được tạo bởi mô hình với một bản tóm tắt tiêu chuẩn vàng.

Đối với tất cả các chỉ số trên, chúng tôi sử dụng các triển khai từ gói SummEval (https://github.com/Yale-LILY/SummEval) là một gói nổi tiếng để đánh giá tóm tắt.

5.1.2 Kết quả so sánh
Bảng 3 cho thấy hiệu suất của tất cả các mô hình tóm tắt (qua ba họ) mà chúng tôi đã áp dụng trong công trình này, trên tập dữ liệu IN-Abs. Giá trị tốt nhất cho mỗi chỉ số trong mỗi họ mô hình tóm tắt được hiển thị bằng phông chữ màu xanh và in đậm.

Chúng tôi quan sát thấy rằng trong ba họ mô hình tóm tắt, các mô hình trừu tượng chuyên biệt cho lĩnh vực pháp lý đạt được điểm số chỉ số tốt nhất (tốt hơn cả LLM và các mô hình trích xuất). Các mô hình trích xuất đạt được điểm số tốt hơn so với các LLM lĩnh vực chung cho hầu hết các chỉ số (điểm ROUGE-2, METEOR, BLEU), mặc dù các LLM lĩnh vực chung đạt được điểm ROUGE-L cao hơn một chút. Chúng tôi thực hiện kiểm định T-test của Student ở khoảng tin cậy 95% để kiểm tra xem mô hình trừu tượng / LLM hoạt động tốt nhất có hoạt động tốt hơn một cách có ý nghĩa thống kê so với mô hình trích xuất hoạt động tốt nhất không (riêng lẻ cho từng chỉ số). Chúng tôi thấy rằng các cải thiện so với mô hình trích xuất tốt nhất chỉ có ý nghĩa thống kê đối với các chỉ số ROUGE-L. Các mục được đánh dấu bằng dấu hoa thị trong Bảng 3 chỉ ra các giá trị có ý nghĩa thống kê cao hơn so với giá trị tốt nhất được đạt bởi một mô hình trích xuất cho cùng chỉ số.

Trong các mô hình trừu tượng chuyên biệt cho lĩnh vực, LegPegasus-IN và LegLED-IN hoạt động tốt nhất. Những cải thiện trong hiệu suất của chúng so với LegPegasus và LegLED cho thấy lợi ích của việc tinh chỉnh trong lĩnh vực (như đã nêu trong Phần 4, LegPegasus và LegLED được tinh chỉnh trên các tài liệu pháp lý Hoa Kỳ, nhưng LegPegasus-IN và LegLED-IN được tinh chỉnh thêm trên các tài liệu pháp lý Ấn Độ tương tự như tập kiểm tra IN-Abs).

Mặc dù các LLM (chatgpt và davinci) đạt được giá trị chỉ số thấp hơn so với các mô hình trừu tượng và trích xuất hoạt động tốt nhất, hiệu suất của chúng là đáng tin cậy – mặc dù các LLM không được huấn luyện đặc biệt trên bất kỳ tập dữ liệu pháp lý nào, chúng hoạt động tốt hơn một số mô hình trích xuất và trừu tượng được huấn luyện trên dữ liệu pháp lý, ít nhất theo một số chỉ số nhất định. Ví dụ, davinci-summ đạt được điểm F1 ROUGE-L cao hơn so với LegPegasus, LegLED và tất cả các mô hình trích xuất. Trong hai biến thể của các LLM, các biến thể 'summ' đạt được điểm số tốt hơn một chút so với các biến thể 'tldr' theo hầu hết các chỉ số.

5.2 Tính nhất quán của các bản tóm tắt
Bây giờ chúng tôi kiểm tra mức độ nhất quán của các bản tóm tắt được tạo bởi mô hình với các tài liệu gốc. Kiểm tra này quan trọng đặc biệt đối với các mô hình tóm tắt trừu tượng và LLM được biết là có ảo giác trong việc tạo văn bản. Chúng tôi đầu tiên mô tả các chỉ số, và sau đó thảo luận về kết quả so sánh.

5.2.1 Chỉ số
Các chỉ số sau đây so sánh bản tóm tắt được tạo bởi mô hình với tài liệu gốc và ước tính mức độ nhất quán của bản tóm tắt với tài liệu. Tất cả các chỉ số này đưa ra một điểm số trong phạm vi [0,1]; điểm số càng cao, bản tóm tắt càng nhất quán.

(1) SummaC – Chỉ số này (Laban et al., 2022) dựa trên Natural Language Inferencing (NLI) là một nhiệm vụ trong Xử lý Ngôn ngữ Tự nhiên liên quan đến việc xác định mối quan hệ giữa hai câu. Một trong các câu được coi là 'giả thuyết' và câu kia được coi là 'tiền đề'. NLI là nhiệm vụ xác định xem giả thuyết đã cho có tuân theo logic từ câu tiền đề hay không. Thông thường, một mô hình NLI sẽ đưa ra một điểm số đại diện cho khả năng câu giả thuyết tuân theo logic từ câu tiền đề.

Với một cặp (tài liệu, tóm tắt), SummaC phân đoạn cả tài liệu và bản tóm tắt thành các đơn vị câu, và sau đó tận dụng các mô hình NLI để phát hiện hiệu quả các sự không nhất quán trong bản tóm tắt so với tài liệu. Nói đơn giản, điểm NLI được tính cho mỗi câu trong bản tóm tắt (được tạo bởi mô hình), để ước tính khả năng rằng câu này tuân theo logic từ một số câu trong tài liệu gốc. Điểm NLI thấp hơn cho một câu s cụ thể trong bản tóm tắt có nghĩa là sự không khớp cao hơn giữa câu này và các câu trong tài liệu gốc, do đó chỉ ra khả năng cao hơn rằng câu s này chứa thông tin ảo giác. Các điểm NLI được lấy bởi các câu khác nhau trong bản tóm tắt sau đó được kết hợp để đưa ra một điểm SummaC duy nhất cho cặp (tài liệu, tóm tắt) đã cho. Do đó, điểm SummaC cao hơn cho một bản tóm tắt chỉ ra rằng bản tóm tắt nhất quán hơn so với tài liệu pháp lý gốc (chi tiết thêm có thể được tìm thấy trong (Laban et al., 2022)).

(2) NumPrec – Số là một phần quan trọng của một phán quyết vụ án pháp lý, vì có các số quan trọng như ngày tháng, định danh quy chế (ví dụ: số Đạo luật và Phần), giá trị tiền tệ, điều khoản hình phạt, v.v. Việc các số này được thể hiện một cách trung thực trong bản tóm tắt là quan trọng. Chỉ số NumPrec đo lường tỷ lệ số có trong bản tóm tắt được tạo bởi mô hình cũng có trong tài liệu nguồn. Các số được xác định bằng thư viện Python tiêu chuẩn.

(3) NEPrec – Các Thực thể Được Đặt Tên (NE) cũng rất quan trọng trong một phán quyết vụ án pháp lý. Nếu các thực thể như người, tổ chức, v.v. bị thay đổi trong bản tóm tắt, thì không chỉ thông tin quan trọng sẽ bị mất, mà bản tóm tắt cũng có thể trở nên gây hiểu lầm. Để phát hiện lượng không nhất quán trong một bản tóm tắt về mặt thực thể được đặt tên, chúng tôi tính chỉ số được gọi là NEPrec đo lường tỷ lệ Thực thể Được Đặt Tên có trong bản tóm tắt được tạo bởi mô hình cũng có trong tài liệu nguồn. Trong công trình này, chúng tôi phát hiện Thực thể Được Đặt Tên (từ cả tài liệu gốc và các bản tóm tắt) bằng Spacy Toolkit tiêu chuẩn có sẵn tại https://spacy.io/api/entityrecognizer.

Lưu ý rằng các chỉ số NumPrec và NEPrec phụ thuộc vào khả năng phát hiện số và thực thể được đặt tên một cách chính xác. Cụ thể, việc xác định tất cả các loại thực thể được đặt tên từ các tài liệu pháp lý Ấn Độ là khá thách thức (Kalamkar et al., 2022). Do đó các giá trị chỉ số phụ thuộc vào độ chính xác của bộ công cụ Spacy được sử dụng cho mục đích này.

5.2.2 Kết quả so sánh
Bảng 4 cho thấy hiệu suất của LLM và tóm tắt trừu tượng mà chúng tôi đã áp dụng trong công trình này, trên tập dữ liệu IN-Abs. Tất cả giá trị chỉ số được tính trung bình trên 100 tài liệu. Lưu ý rằng việc tính các chỉ số cho các phương pháp trích xuất là vô nghĩa, vì tất cả ba chỉ số sẽ là 1.0 theo định nghĩa đối với bất kỳ phương pháp trích xuất nào.

Bây giờ chúng tôi thấy một số vấn đề nhất quán tiềm ẩn với các LLM và mô hình trừu tượng. Điểm SummaC cho các LLM nằm trong phạm vi [0.5, 0.65] cho thấy tính nhất quán tương đối thấp hơn so với các mô hình trừu tượng chuyên biệt cho lĩnh vực. Điểm NEPrec và NumPrec cao hơn, thường cao hơn 0.9; vẫn còn các giá trị này chỉ ra sự hiện diện của một số thực thể được đặt tên và số không nhất quán / ảo giác trong các bản tóm tắt trừu tượng.

Trong các mô hình trừu tượng chuyên biệt cho lĩnh vực, LegPegasus và LegLED có điểm số tương đối thấp (đặc biệt là LegLED) chỉ ra sự hiện diện đáng kể của nội dung ảo giác trong các bản tóm tắt của chúng. LegPegasus-IN và LegLED-IN đã nhất quán có điểm số cao hơn (qua tất cả các chỉ số) so với các mô hình LegPegasus và LegLED, điều này một lần nữa cho thấy lợi ích của việc tinh chỉnh chuyên biệt cho lĩnh vực.

5.3 Những điểm rút ra từ phần này
Các phân tích trong phần này cho phép chúng tôi so sánh giữa các mô hình tóm tắt trích xuất và trừu tượng, cả hai đều được huấn luyện trên các tài liệu pháp lý Ấn Độ. Chúng tôi thấy các mô hình trừu tượng hoạt động tốt hơn so với các mô hình trích xuất theo các chỉ số tiêu chuẩn như ROUGE, METEOR và BLEU (Bảng 3). Ngoài ra các mô hình có giám sát hoạt động tốt hơn so với các LLM như Davinci và ChatGPT.

Tuy nhiên, các mô hình trừu tượng dường như có vấn đề với tính nhất quán (Bảng 4). Một số thực thể được đặt tên / phần của bản tóm tắt có thể không nhất quán với tài liệu gốc. Chúng tôi tìm kiếm sự hiện diện của những sự không nhất quán như vậy trong phần tiếp theo.

6 Sự Không Nhất Quán trong Các Bản Tóm Tắt Trừu Tượng
Phân tích trong Phần 5.2 chỉ ra rằng một số phần của các bản tóm tắt được tạo bởi các mô hình trừu tượng và LLM có thể không nhất quán với các tài liệu gốc. Để hiểu loại sự không nhất quán nào có trong các bản tóm tắt, chúng tôi đã quan sát thủ công một số lượng lớn các cặp (tài liệu, tóm tắt) từ tập dữ liệu của chúng tôi. Cụ thể, chúng tôi quan sát những câu có điểm SummaC tương đối thấp, và những câu chứa số và thực thể được đặt tên không thể được khớp với các tài liệu gốc (trong khi tính NERPrec và NumPrec). Chúng tôi cũng quan sát các phần liên quan trong tài liệu chính để hiểu các lỗi/sự không nhất quán.

Chúng tôi tìm thấy một số loại lỗi và sự không nhất quán khác nhau trong các bản tóm tắt trừu tượng. Bảng 5, Bảng 6, Bảng 7 cho thấy một số ví dụ về lỗi/sự không nhất quán trong các bản tóm tắt được tạo bởi các mô hình trừu tượng và LLM cho ba tài liệu Tòa án Tối cao Ấn Độ cụ thể (được đề cập trong các chú thích bảng). Các bảng cho thấy tên của mô hình, một đoạn trích từ bản tóm tắt cho thấy lỗi, và giải thích về lỗi.

Chúng tôi quan sát một số loại lỗi phổ biến trong hầu hết các bản tóm tắt được tạo bởi gần như tất cả các mô hình trừu tượng và LLM, chẳng hạn như hai câu bị gộp (để lại câu đầu tiên không hoàn chỉnh) – ví dụ, xem Bảng 5 lỗi-3, Bảng 6, lỗi-1 và Bảng 7 lỗi-4. Những lỗi này chủ yếu xảy ra ở ranh giới của các đoạn.

Chúng tôi cũng quan sát các lỗi nghiêm trọng hơn như các số sai được tạo ra trong bản tóm tắt, không có trong tài liệu gốc. Ví dụ, Bảng 6 lỗi-5 cho thấy một năm sai được đề cập trong bản tóm tắt – bảng này đề cập đến một vụ án được xét xử năm 1961; do đó năm '2019' trong bản tóm tắt LegLED rõ ràng là ảo giác.

Chúng tôi chú ý một loại lỗi kỳ lạ đặc biệt trong các bản tóm tắt được tạo bởi LegLED – ngay cả khi các mô hình đang tóm tắt các phán quyết vụ án Ấn Độ, tên của các Tòa án Hoa Kỳ và tên của các quy chế Hoa Kỳ xuất hiện trong các bản tóm tắt, hoàn toàn không liên quan đến tài liệu đầu vào. Các ví dụ về những ảo giác như vậy được hiển thị trong Bảng 5, lỗi-4 và lỗi-5, và Bảng 7 lỗi-2. Những ảo giác như vậy có lẽ là do thực tế rằng LegLED đã được huấn luyện trên các cặp tài liệu-tóm tắt pháp lý Hoa Kỳ, và mô hình có xu hướng tạo ra tên tòa án / quy chế Hoa Kỳ mà nó đã thấy trong quá trình huấn luyện. Quan trọng là, chúng tôi không quan sát loại lỗi này trong các bản tóm tắt LegLED-IN, điều này cho thấy rằng việc tinh chỉnh chuyên biệt cho lĩnh vực có thể giúp giảm ảo giác. Ngoài ra chúng tôi không quan sát loại lỗi cụ thể này trong các bản tóm tắt được tạo bởi các LLM (ChatGPT hoặc DaVinci).

Cũng có các ví dụ về lỗi trong thực thể được đặt tên, ví dụ: một trường hợp mà LegLED nhầm lẫn tên của một thẩm phán với tên của một luật sư (Bảng 7 lỗi-1) và một trường hợp mà chatgpt-summ nhầm tưởng các luật sư đại diện cho các nguyên đơn kháng cáo là chính các nguyên đơn kháng cáo (Bảng 5 lỗi-2). Những lỗi như vậy rất khó phát hiện bằng các phương pháp tự động, và có thể dẫn đến các bản tóm tắt gây hiểu lầm.

7 Thảo Luận Kết Luận
Chúng tôi đã thử một loạt các Mô Hình Ngôn Ngữ Lớn (ví dụ: Text-Davinci-003 và Turbo-Gpt-3.5) và các mô hình tóm tắt trừu tượng chuyên biệt cho lĩnh vực (ví dụ: Legal-LED, Legal-Pegasus) trên một tập dữ liệu các phán quyết vụ án của Tòa án Tối cao Ấn Độ, và tính toán một loạt các chỉ số. Ngoài các chỉ số đánh giá tiêu chuẩn như ROUGE, METEOR, BLEU, chúng tôi cũng tính các chỉ số không truyền thống để đánh giá tính nhất quán tóm tắt như Numprec, NERprec và SummaC.

Chúng tôi quan sát thấy rằng việc tinh chỉnh chuyên biệt cho lĩnh vực cải thiện hiệu suất của các mô hình trừu tượng (LegPegasus-IN và LegLED-IN) về cả khía cạnh khớp với bản tóm tắt tiêu chuẩn vàng và tính nhất quán. Các LLM như Turbo-GPT-3.5 (ChatGPT) và Text-Davinci-003 cũng hoạt động tốt trong thiết lập zero-shot, xem xét rằng chúng không được huấn luyện đặc biệt trên các tài liệu pháp lý. Tuy nhiên, những LLM này cũng đôi khi tạo ra văn bản không nhất quán trong các bản tóm tắt.

Nói chung, chúng tôi thấy rằng các mô hình trừu tượng thường vượt trội so với các mô hình trích xuất về các chỉ số như ROUGE, METEOR và BLEU (Bảng 3). Tuy nhiên, các mô hình trừu tượng gặp phải các vấn đề như sự không nhất quán và ảo giác trong các bản tóm tắt được tạo ra. Một số vấn đề có thể được giảm thiểu bằng việc tinh chỉnh chuyên biệt cho lĩnh vực; ví dụ, trong khi LegLED thường tạo ra tên của các tòa án/quy chế Hoa Kỳ khi tóm tắt các tài liệu Ấn Độ, những lỗi này ít hơn đáng kể trong LegLED-IN được tinh chỉnh thêm trên dữ liệu pháp lý Ấn Độ. Một số lỗi cũng có thể được phát hiện và giải quyết bằng việc xử lý hậu kỳ cẩn thận của các bản tóm tắt được tạo ra. Tuy nhiên, một số lỗi được thực hiện bởi các mô hình trừu tượng là tinh tế và khó phát hiện tự động hơn nhiều, ví dụ: nhầm lẫn tên của các nguyên đơn kháng cáo và tên của các luật sư đại diện cho các nguyên đơn kháng cáo (xem ví dụ thứ ba trong Bảng 5). Theo hiểu biết của chúng tôi, đây là công trình đầu tiên chứng minh các ví dụ về những lỗi phức tạp như vậy trong các bản tóm tắt trừu tượng của các phán quyết vụ án pháp lý.

Vì vậy, như được thể hiện bởi các thí nghiệm được báo cáo trong bài báo này, chúng tôi kết luận (1) các mô hình tóm tắt trừu tượng được huấn luyện trước và LLM chưa sẵn sàng cho việc tóm tắt hoàn toàn tự động trong một lĩnh vực phức tạp như Pháp luật; có thể một cách tiếp cận có con người trong vòng lặp phù hợp hơn nơi một chuyên gia pháp lý có thể giám sát chất lượng của các bản tóm tắt được tạo bởi những phương pháp này, và (2) cần thiết kế các phương pháp tốt hơn để phát hiện các loại lỗi phức tạp trong các bản tóm tắt trừu tượng. Trong tương lai, chúng tôi dự định theo đuổi những hướng này để cải thiện việc tóm tắt trừu tượng trong lĩnh vực pháp lý.

--- BẢNG ĐÃ ĐƯỢC ĐỀ CẬP ---
Bảng 1: Thống kê của tập huấn luyện và tập kiểm tra IN-Abs, chứa các cặp (phán quyết vụ án, tóm tắt) từ Tòa án Tối cao Ấn Độ. Tập huấn luyện được sử dụng để huấn luyện các mô hình trích xuất và tinh chỉnh các mô hình trừu tượng được huấn luyện trước. Tất cả các mô hình tóm tắt trong công trình này được áp dụng và đánh giá trên tập kiểm tra.

Số tài liệu | Số từ trung bình trong tài liệu | Số từ trung bình trong tóm tắt tiêu chuẩn vàng
Tập huấn luyện: 7,030 | 4,368.49 | 839.75
Tập kiểm tra: 100 | 4,782.71 | 932.01

Bảng 2: Siêu tham số của các mô hình trừu tượng chuyên biệt cho lĩnh vực pháp lý và LLM được sử dụng trong công trình. 'max tokens' chỉ ra số từ tối đa trong bản tóm tắt cần được tạo ra cho một đoạn văn bản đầu vào có độ dài 1.024 từ. Ở đây 'gold-std summary length' là độ dài thực tế (số từ) của bản tóm tắt tiêu chuẩn vàng cho tài liệu đã cho.

Mô hình | Siêu tham số
chatgpt-tldr | temperature=0.7, max tokens = độ dài tóm tắt tiêu chuẩn vàng * 1024/Độ dài tài liệu.
chatgpt-summ | temperature=0.7, max tokens = độ dài tóm tắt tiêu chuẩn vàng * 1024/Độ dài tài liệu.
davinci-tldr | Presence penalty=1.0, frequency penalty=0.0, temperature=0.7, max tokens = độ dài tóm tắt tiêu chuẩn vàng * 1024/Độ dài tài liệu.
davinci-summ | Presence penalty=1.0, frequency penalty = 0.0, temperature=0.7, max tokens = độ dài tóm tắt tiêu chuẩn vàng * 1024/Độ dài tài liệu.
LegPegasus | max tokens = độ dài tóm tắt tiêu chuẩn vàng * 1024/Độ dài tài liệu.
LegPegasus-IN | max tokens = độ dài tóm tắt tiêu chuẩn vàng * 1024/Độ dài tài liệu.
LegLED | max tokens = độ dài tóm tắt tiêu chuẩn vàng * 1024/Độ dài tài liệu.
LegLED-IN | max tokens = độ dài tóm tắt tiêu chuẩn vàng * 1024/Độ dài tài liệu.

Bảng 3: Hiệu suất của các mô hình tóm tắt từ ba họ, mà chúng tôi đã áp dụng trong công trình này. Tất cả giá trị chỉ số được tính trung bình trên 100 tài liệu trong tập kiểm tra IN-Abs. Các chỉ số lần lượt là độ chính xác Rouge-2, recall Rouge-2, điểm F1 Rouge-2, độ chính xác Rouge-L, recall Rouge-L, điểm F1 Rouge-L, điểm METEOR và BLEU. Giá trị tốt nhất cho mỗi chỉ số, cho mỗi họ mô hình tóm tắt, được hiển thị bằng màu xanh-đậm. Các mục có dấu hoa thị (*) chỉ ra một giá trị có ý nghĩa thống kê cao hơn (bằng kiểm định T-test của Student ở khoảng tin cậy 95%) so với giá trị tốt nhất được đạt bởi một mô hình tóm tắt trích xuất (giá trị được hiển thị bằng màu xanh-đậm) cho cùng chỉ số.

Mô hình | R2-P | R2-R | R2-F1 | RL-P | RL-R | RL-F1 | ME | BLEU (%)
Các mô hình ngôn ngữ lớn lĩnh vực chung
chatgpt-tldr | 0.2391 | 0.1428 | 0.1729 | 0.2956* | 0.1785 | 0.2149 | 0.1634 | 7.39
chatgpt-summ | 0.1964 | 0.1731 | 0.1818 | 0.2361 | 0.2087 | 0.2188 | 0.1962 | 10.82
davinci-tldr | 0.2338 | 0.1255 | 0.1568 | 0.2846 | 0.1529 | 0.1901 | 0.1412 | 6.82
davinci-summ | 0.2202 | 0.1795 | 0.1954 | 0.2513 | 0.2058 | 0.2234 | 0.1917 | 11.41
Các mô hình trừu tượng chuyên biệt cho lĩnh vực pháp lý
LegPegasus | 0.1964 | 0.1203 | 0.1335 | 0.2639 | 0.1544 | 0.1724 | 0.1943 | 13.14
LegPegasus-IN | 0.2644 | 0.2430 | 0.2516 | 0.2818* | 0.2620 | 0.2698 | 0.1967 | 18.66
LegLED | 0.1115 | 0.1072 | 0.1085 | 0.1509 | 0.1468 | 0.1477 | 0.1424 | 8.43
LegLED-IN | 0.2608 | 0.2531 | 0.2550 | 0.2769 | 0.2691* | 0.2711* | 0.2261 | 19.81
Các mô hình trích xuất
CaseSummarizer | 0.2512 | 0.2269 | 0.2381 | 0.2316 | 0.2085 | 0.2191 | 0.1941 | 15.46
SummaRunner/RNN_RNN | 0.2276 | 0.2103 | 0.2180 | 0.1983 | 0.1825 | 0.1893 | 0.2038 | 17.58
BertSum | 0.2474 | 0.2177 | 0.2311 | 0.2243 | 0.1953 | 0.2082 | 0.2037 | 18.16

Bảng 4: Chỉ số nhất quán của tất cả các phương pháp trừu tượng và LLM mà chúng tôi đã áp dụng trong công trình này. Tất cả giá trị chỉ số được tính trung bình trên 100 tài liệu trong tập dữ liệu IN-Abs. Giá trị tốt nhất cho mỗi chỉ số cho mỗi họ mô hình tóm tắt được làm nổi bật.

Mô hình | SummaC | NEPrec | NumPrec
Các mô hình ngôn ngữ lớn lĩnh vực chung
chatgpt-tldr | 0.5719 | 0.8612 | 0.9498
chatgpt-summ | 0.5762 | 0.9172 | 0.9612
davinci-summ | 0.6356 | 0.8959 | 0.9323
davinci-tldr | 0.6080 | 0.8331 | 0.9123
Các mô hình trừu tượng chuyên biệt cho lĩnh vực pháp lý
LegPegasus | 0.6333 | 0.8429 | 0.9483
LegPegasus-IN | 0.7368 | 0.8542 | 0.9952
LegLED | 0.6563 | 0.7199 | 0.8192
LegLED-IN | 0.8552 | 0.8276 | 0.9769

Bảng 5: Ví dụ về lỗi trong các bản tóm tắt trừu tượng được tạo bởi các mô hình khác nhau cho phán quyết Tòa án Tối cao Ấn Độ có sẵn tại indiankanoon.org/doc/1234444/. Các lỗi trong các bản tóm tắt đã được đánh dấu bằng màu đỏ. Cột cuối giải thích lỗi.

id | Mô hình | Đoạn trích từ bản tóm tắt cho thấy lỗi | Giải thích lỗi
1 | davinci-summ | Ngôn ngữ được sử dụng, Deoria, cầu xin rằng thủ tục trước Nyaya Panchayat và lệnh của nó ngày 25 tháng 12 năm 1963, được hủy bỏ ... | Theo tài liệu nguồn, 'Deoria' là tên của một địa điểm, không phải tên của một ngôn ngữ. Vì vậy câu trong bản tóm tắt là vô nghĩa.
2 | chatgpt-summ | Các nguyên đơn kháng cáo, bao gồm R Chari, M K Ramamurthi, Vineet Kumar, và Shyamala Pappu, đã bị kết tội coi thường tòa án và mỗi người bị kết án ... | Các tên được đề cập thực sự là của các luật sư đại diện cho các nguyên đơn kháng cáo, không phải chính các nguyên đơn kháng cáo. Tài liệu nguồn nêu "A. S. R. Chari, M. K. Ramamurthi, Vineet Kumar và Shyamala Pappu, cho các nguyên đơn kháng cáo". Mô hình tóm tắt đã nhầm tưởng những tên này là của chính các nguyên đơn kháng cáo.
3 | chatgpt-tldr | Mahabir đã nộp đơn theo các phần 4 và 5 của Vụ án bao gồm các cáo buộc coi thường tòa án | Câu không hoàn chỉnh, nơi tên của quy chế (Đạo luật) đã bị bỏ sót trong bản tóm tắt. Câu tương tự nhất trong tài liệu chính là "Vào ngày 21 tháng 5 năm 1964, Mahabir đã nộp đơn theo ss. 4 và 5 của Đạo luật Coi thường Tòa án, 1952, ..."
4 | LegLED | ... vi phạm các điều khoản chống gian lận của Phần 17(a) của Đạo luật Chứng khoán năm 1933, Phần 10(b) của Đạo luật Giao dịch Chứng khoán năm 1934 và Quy tắc 10b-5 theo đó, ... | Có rất nhiều ảo giác trong phần này của bản tóm tắt. Các cụm từ "Phần 17(a) của Đạo luật Chứng khoán năm 1933" và "Phần 10(b) của Đạo luật Giao dịch Chứng khoán năm 1934 và Quy tắc 10b-5" đều là ảo giác. Cụ thể, Đạo luật Chứng khoán và Đạo luật Giao dịch Chứng khoán là các Đạo luật của Hoa Kỳ và hoàn toàn không liên quan đến tài liệu nguồn (là một vụ án ở Ấn Độ).
5 | LegLED | Vào ngày 20 tháng 12 năm 1963, Tòa án Quận Hoa Kỳ cho Quận Nam New York đã ra phán quyết cuối cùng kết tội một quan tòa về tội coi thường tòa án vì không tuân theo lệnh của Tòa án Quận Hoa Kỳ cho Quận Nam New York. | "Tòa án Quận Hoa Kỳ cho Quận Nam New York" được nêu trong bản tóm tắt hoàn toàn không có mối quan hệ gì với vụ án này (là một vụ án hoàn toàn được tranh luận ở Ấn Độ)

Bảng 6: Ví dụ về lỗi trong các bản tóm tắt trừu tượng được tạo bởi các mô hình khác nhau cho phán quyết Tòa án Tối cao Ấn Độ có sẵn tại https://indiankanoon.org/doc/27285/. Các lỗi trong các bản tóm tắt được đánh dấu bằng màu đỏ, và được giải thích trong cột cuối.

id | Mô hình | Đoạn trích từ bản tóm tắt cho thấy lỗi | Giải thích lỗi
1 | chatgpt-tldr | Bài báo xem xét ba tình huống để xác định xem quyền sở hữu hàng hóa có chuyển nhượng hay không Tài liệu thảo luận về hai vụ án pháp lý riêng biệt liên quan đến thuế ... | Câu đầu tiên bị để lại không hoàn chỉnh và hai câu được gộp lại.
2 | LegPegasus | Vào ngày 27 tháng 9 năm 1960, Tòa án Tối cao Ấn Độ đã bác bỏ kháng cáo của Daulatram Rameshwarlal và Daulatram Rameshwarlal J.M. chống lại các lệnh của Tòa án Cao Bombay ... | Cùng tên "Dalutram Rameshwarlal" được đề cập sai hai lần. Không có người nào tên 'Daulatram Rameshwarlal J. M." trong vụ án.
3 | LegPegasus | Tòa án Cao quyết định rằng việc bán dầu thầu dầu bởi M/s. Daulatram Rameshwarlal cho M/s. Daulatram Rameshwarlal Ltd được miễn thuế mua theo các điều khoản ... | Cùng thực thể (M/s. Daulatram Rameshwarlal) được nêu vừa là người bán vừa là người mua, điều này là sai.
4 | LegPegasus | Tòa Phúc thẩm quyết định rằng đó là nghĩa vụ của người mua để có được giấy phép xuất khẩu cần thiết. Tòa Phúc thẩm quyết định rằng đó là của người bán để có được giấy phép và quan điểm này đã được Viện Quý tộc phê duyệt. | Dòng đầu tiên nói việc lấy giấy phép là nghĩa vụ của người mua, nhưng dòng tiếp theo ngay lập tức nói đó là nghĩa vụ của người bán – điều này không nhất quán. Trong tài liệu nguồn, phần liên quan nói rằng quy tắc thông thường trong các hợp đồng FOB là nghĩa vụ của người mua để có được giấy phép xuất khẩu, nhưng có một trường hợp đặc biệt nơi nó được coi là nghĩa vụ của người bán. Ý nghĩa này bị mất trong bản tóm tắt.
5 | LegLED | Vào ngày 27 tháng 9 năm 2019, Tòa án Quận Hoa Kỳ cho Quận Nam New York đã ra phán quyết cuối cùng chống lại Daulatram Rameshwarlal, một công ty đăng ký theo Đạo luật Đối tác Ấn Độ, và Daulatram Rameshwarlal, một đại lý đăng ký theo Đạo luật Đối tác Ấn Độ, vì tuyên bố miễn thuế Bán hàng đối với việc bán bông ... | 'Tòa án Quận Hoa Kỳ New York' là ảo giác (vụ án gốc được tranh luận hoàn toàn tại các tòa án Ấn Độ). Ngoài ra năm '2019' là ảo giác – vụ án gốc là của năm 1961, vì vậy không có sự kiện nào của năm 2019 có thể được đề cập. Ngoài ra, mô hình tóm tắt đã không hiểu rằng cùng thực thể 'Daulatram Rameshwarlal' được đề cập vừa là một 'công ty' vừa là một 'đại lý đăng ký'; mô hình đã giả định hai thực thể riêng biệt.
6 | LegPegasus-IN | Ý định của các bên rằng để tuân thủ các yêu cầu của cl.5(2) của Lệnh Xuất khẩu (Kiểm soát) Không có tình huống nào sẽ biện minh cho một kết luận rằng ... | Câu đầu tiên bị để lại không hoàn chỉnh và hai câu được gộp lại.
7 | LegLED-IN | Tòa án đã đúng khi quyết định rằng Tòa án đã sai khi quyết định rằng không cần thiết | Câu này trong bản tóm tắt là vô nghĩa. Tài liệu nguồn là một vụ án được xét xử tại Tòa án Tối cao Ấn Độ, và là một kháng cáo chống lại một quyết định được tuyên bố bởi Tòa án Cao Bombay. Do đó có hai tòa án liên quan, nhưng không rõ từ bản tóm tắt tòa án nào đang được đề cập bởi lần xuất hiện nào của từ 'tòa án'.

Bảng 7: Ví dụ về lỗi trong các bản tóm tắt trừu tượng được tạo bởi các mô hình tóm tắt khác nhau cho phán quyết Tòa án Tối cao Ấn Độ có sẵn tại https://indiankanoon.org/doc/1722864/. Các lỗi trong các bản tóm tắt được đánh dấu bằng màu đỏ, và được giải thích trong cột cuối.

id | Mô hình | Đoạn trích từ bản tóm tắt cho thấy lỗi | Giải thích lỗi
1 | LegLED | Vào ngày 31 tháng 3 năm 1965, Đại tá M.K. Ramaswami của Tòa án Cao Madras đã chấp thuận yêu cầu của SEC về việc đóng băng tài sản và các biện pháp cứu trợ khẩn cấp khác. | Tên của thẩm phán trong tài liệu nguồn là 'V. Ramaswami' (chứ không phải 'M.K. Ramaswami' như được nêu trong bản tóm tắt). Trong khi đó, 'M.K. Ramamurthi' là một trong những luật sư đại diện cho nguyên đơn kháng cáo. Mô hình tóm tắt đã nhầm lẫn giữa hai tên.
2 | LegLED | Khiếu nại của SEC, được nộp tại Tòa án Quận Hoa Kỳ cho Quận Nam Madras, cáo buộc rằng ... | Một tòa án sai đã được đề cập. Đây là một vụ án ở Ấn Độ, do đó "Tòa án Quận Hoa Kỳ" là ảo giác của mô hình tóm tắt.
3 | LegLED | Cụm từ "được quy định bởi việc sử dụng" trong phần 6(9) của Madras Kế thừa di sản là kế thừa bởi người thừa kế cho người đã chết theo luật, văn phòng phải được chuyển giao cho người kế nhiệm theo một số quy tắc dòng dõi xác định mà bởi lực lượng riêng của chúng chỉ định người kế nhiệm. | Tên của Đạo luật đã bị để lại không hoàn chỉnh (thực sự là 'Đạo luật Tài trợ Tôn giáo và Từ thiện Hindu Madras, 1951'), và từ "Madras" đã được gộp với câu tiếp theo.
4 | LegPegasus-IN | Từ "kế thừa Đúng là định nghĩa nhân tạo của người trông coi di sản trong phần 6(9) của Đạo luật sẽ bao gồm ngay cả những trường hợp như vậy. | Một câu đã bị để lại không hoàn chỉnh và từ "kế thừa" đã được gộp với câu tiếp theo. Lưu ý rằng câu đã bị để lại không hoàn chỉnh là một câu quan trọng nơi tòa án giải thích cách diễn giải của mình về từ "kế thừa" trong bối cảnh của vụ án này.

Lời cảm ơn: Các tác giả thừa nhận phản hồi và đề xuất hữu ích về công trình từ Jack Conrad (từ Thomson Reuters Labs). Nghiên cứu được hỗ trợ một phần bởi Các Trung tâm TCG cho Nghiên cứu và Giáo dục trong Khoa học và Công nghệ (CREST), Ấn Độ thông qua một dự án có tiêu đề "Cố vấn Pháp lý Thông minh: Phân tích Pháp lý dựa trên AI".

Tài Liệu Tham Khảo
Abhishek Agarwal, Shanshan Xu, và Matthias Grabmair. 2022. Tóm tắt trích xuất các quyết định pháp lý sử dụng học đa nhiệm và tính liên quan biên tối đa. arXiv preprint arXiv:2210.12437.

Hussam Alkaissi và Samy I McFarlane. 2023. Ảo giác nhân tạo trong ChatGPT: hàm ý trong viết khoa học. Cureus, 15(2).

Satanjeev Banerjee và Alon Lavie. 2005. Meteor: Một chỉ số tự động cho đánh giá mt với tương quan cải thiện với các phán đoán của con người. Trong Kỷ yếu hội thảo ACL về các biện pháp đánh giá nội tại và bên ngoài cho dịch máy và/hoặc tóm tắt, trang 65–72.

Paheli Bhattacharya, Soham Poddar, Koustav Rudra, Kripabandhu Ghosh, và Saptarshi Ghosh. 2021. Kết hợp kiến thức lĩnh vực cho tóm tắt trích xuất các tài liệu vụ án pháp lý. Trong Kỷ yếu hội nghị quốc tế thứ mười tám về trí tuệ nhân tạo và luật, trang 22–31.

Aniket Deroy, Kripabandhu Ghosh, và Saptarshi Ghosh. 2023. Các phương pháp tập hợp để cải thiện tóm tắt trích xuất các phán quyết vụ án pháp lý. Artificial Intelligence and Law, trang 1–59.

Wafaa S. El-Kassas, Cherif R. Salama, Ahmed A. Rafea, và Hoda K. Mohamed. 2021. Tóm tắt văn bản tự động: Một khảo sát toàn diện. Expert Systems with Applications, 165:113679.

Diego de Vargas Feijo và Viviane P Moreira. 2023. Cải thiện tóm tắt trừu tượng các phán quyết pháp lý thông qua kéo theo văn bản. Artificial intelligence and law, 31(1):91–113.

Katja Filippova. 2020. Ảo giác được kiểm soát: Học để tạo ra một cách trung thực từ dữ liệu nhiễu. Trong Findings of the Association for Computational Linguistics: EMNLP 2020, trang 864–870.

Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, và Pascale Fung. 2023. Khảo sát về ảo giác trong tạo ngôn ngữ tự nhiên. ACM Computing Surveys, 55(12):1–38.

Prathamesh Kalamkar, Astha Agarwal, Aman Tiwari, Smita Gupta, Saurabh Karn, và Vivek Raghavan. 2022. Nhận dạng thực thể được đặt tên trong các phán quyết tòa án Ấn Độ. Trong Kỷ yếu Hội thảo Xử lý Ngôn ngữ Pháp lý Tự nhiên, trang 184–193.

Philippe Laban, Tobias Schnabel, Paul N Bennett, và Marti A Hearst. 2022. SummaC: Xem xét lại các mô hình dựa trên NLI để phát hiện sự không nhất quán trong tóm tắt. Transactions of the Association for Computational Linguistics, 10:163–177.

Chin-Yew Lin. 2004. ROUGE: Một gói để đánh giá tự động các bản tóm tắt. Trong Text Summarization Branches Out, trang 74–81. Association for Computational Linguistics.

Chao-Lin Liu và Kuan-Chun Chen. 2019. Trích xuất tinh tuý của các phán quyết Trung Quốc của tòa án tối cao. Trong kỷ yếu hội nghị quốc tế thứ mười bảy về trí tuệ nhân tạo và luật, trang 73–82.

Yang Liu. 2019. Tinh chỉnh bert cho tóm tắt trích xuất. arXiv preprint arXiv:1903.10318.

Gianluca Moro và Luca Ragazzi. 2022. Tự phân đoạn ngữ nghĩa cho tóm tắt trừu tượng các tài liệu dài trong chế độ ít tài nguyên. Trong Kỷ yếu Hội nghị AAAI về Trí tuệ Nhân tạo, tập 36, trang 11085–11093.

Ramesh Nallapati, Feifei Zhai, và Bowen Zhou. 2017. Summarunner: Một mô hình chuỗi dựa trên mạng neural hồi quy cho tóm tắt trích xuất tài liệu. Trong Kỷ yếu Hội nghị AAAI về Trí tuệ Nhân tạo, tập 31, trang 3075–3081.

Ani Nenkova và Kathleen McKeown. 2012. Một Khảo sát về Các Kỹ thuật Tóm tắt Văn bản, trang 43–76. Springer US.

Kishore Papineni, Salim Roukos, Todd Ward, và Wei-Jing Zhu. 2002. Bleu: một phương pháp đánh giá tự động dịch máy. Trong Kỷ yếu cuộc họp thường niên lần thứ 40 của Association for Computational Linguistics, trang 311–318.

Seth Polsley, Pooja Jhunjhunwala, và Ruihong Huang. 2016. CaseSummarizer: Một hệ thống tóm tắt tự động các văn bản pháp lý. Trong Kỷ yếu COLING 2016, Hội nghị Quốc tế lần thứ 26 về Ngôn ngữ học Tính toán: Trình diễn Hệ thống, trang 258–262.

Abhay Shukla, Paheli Bhattacharya, Soham Poddar, Rajdeep Mukherjee, Kripabandhu Ghosh, Pawan Goyal, và Saptarshi Ghosh. 2022. Tóm tắt tài liệu vụ án pháp lý: Các phương pháp trích xuất và trừu tượng và đánh giá của chúng. Trong Kỷ yếu Hội nghị của Chương Châu Á-Thái Bình Dương của Association for Computational Linguistics và Hội nghị Quốc tế Liên hợp về Xử lý Ngôn ngữ Tự nhiên (Tập 1: Bài báo dài), trang 1048–1064.

Karolina Stanczak và Isabelle Augenstein. 2021. Một khảo sát về thiên vị giới tính trong xử lý ngôn ngữ tự nhiên. arXiv preprint arXiv:2112.14168.

Jingqing Zhang, Yao Zhao, Mohammad Saleh, và Peter J. Liu. 2020. PEGASUS: Huấn luyện trước với Các Câu Khoảng trống Được Trích xuất cho Tóm tắt Trừu tượng. Trong Kỷ yếu Hội nghị Quốc tế về Machine Learning (ICML).

Tianyi Zhang, Faisal Ladhak, Esin Durmus, Percy Liang, Kathleen McKeown, và Tatsunori B Hashimoto. 2023. Đánh giá các mô hình ngôn ngữ lớn cho tóm tắt tin tức. arXiv preprint arXiv:2301.13848.

Zheng Zhao, Shay B. Cohen, và Bonnie Webber. 2020. Giảm Ảo giác Số lượng trong Tóm tắt Trừu tượng. Trong Findings of the Association for Computational Linguistics: EMNLP 2020, trang 2237–2249.

Linwu Zhong, Ziyi Zhong, Zinian Zhao, Siyuan Wang, Kevin D. Ashley, và Matthias Grabmair. 2019. Tóm tắt tự động các quyết định pháp lý sử dụng che dấu lặp lại các câu dự đoán. Trong Kỷ yếu Hội nghị Quốc tế thứ Mười bảy về Trí tuệ Nhân tạo và Luật (ICAIL), trang 163–172.

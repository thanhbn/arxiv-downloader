# 2406.00302.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/federated-learning/2406.00302.pdf
# Kích thước tệp: 4287803 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
FedAST: Huấn luyện Đồng thời Bất đồng bộ Liên hợp
Baris Askin1Pranay Sharma1Carlee Joe-Wong1Gauri Joshi1
1Đại học Carnegie Mellon, Pittsburgh, Pennsylvania, Hoa Kỳ
Tóm tắt
Học Liên hợp (FL) cho phép các thiết bị đầu cuối hoặc
khách hàng cộng tác huấn luyện các mô hình học máy
(ML) mà không chia sẻ dữ liệu riêng tư của họ.
Phần lớn công trình hiện có trong FL tập trung vào việc
học hiệu quả một mô hình cho một nhiệm vụ duy nhất. Trong
bài báo này, chúng tôi nghiên cứu huấn luyện đồng thời
nhiều mô hình FL sử dụng một tập hợp khách hàng chung.
Một số phương pháp huấn luyện đồng thời hiện có sử
dụng tổng hợp đồng bộ các cập nhật từ khách hàng, có thể
gây ra độ trễ đáng kể vì các mô hình lớn và/hoặc khách
hàng chậm có thể tạo thành điểm nghẽn cho quá trình tổng hợp.
Mặt khác, tổng hợp bất đồng bộ ngây thơ bị ảnh hưởng
xấu bởi các cập nhật cũ từ khách hàng. Chúng tôi đề xuất
FedAST, một thuật toán huấn luyện đồng thời liên hợp
bất đồng bộ có bộ đệm vượt qua các điểm nghẽn từ
các mô hình chậm và phân bổ thích ứng tài nguyên
khách hàng cho các nhiệm vụ không đồng nhất. Chúng
tôi cung cấp đảm bảo hội tụ lý thuyết của FedAST cho
các hàm mục tiêu không lồi mịn. Các thí nghiệm rộng rãi
trên nhiều bộ dữ liệu thực tế cho thấy phương pháp
đề xuất của chúng tôi vượt trội so với các phương pháp
FL đồng thời hiện có, đạt được giảm đến 46,0% thời
gian để huấn luyện nhiều nhiệm vụ đến hoàn thành.

1 GIỚI THIỆU
Học Liên hợp (FL) là một mô hình học phân tán
trong đó các thiết bị đầu cuối hoặc khách hàng cộng tác huấn luyện
các mô hình học máy (ML) sử dụng dữ liệu cục bộ được giữ riêng
[McMahan et al., 2017, Kairouz et al., 2021]. Khách hàng lặp đi
lặp lại cập nhật các mô hình cục bộ của họ, được gửi định kỳ
đến máy chủ trung tâm để tổng hợp. Mô hình được tổng hợp
sau đó được gửi đến khách hàng để bắt đầu vòng tiếp theo
của các cập nhật cục bộ. Kể từ khi được giới thiệu trong [McMahan et al.,
2017], các khía cạnh thực tế và lý thuyết khác nhau của FL, bao
gồm lựa chọn khách hàng [Nishio và Yonetani, 2019, Cho
et al., 2022], thách thức giao tiếp [Ang et al., 2020,
Chellapandi et al., 2023], khả năng mở rộng và huấn luyện nhanh [Xie
et al., 2019, Wang et al., 2020b], đã được nghiên cứu rộng rãi.
Tuy nhiên, những công trình này hầu như hoàn toàn giả định rằng
máy chủ nhằm mục đích học mô hình cho một nhiệm vụ duy nhất. Một số
khung FL cố gắng học các mô hình được cá nhân hóa cho từng
khách hàng [Mansour et al., 2020, Li et al., 2021, Tan et al., 2022],
nhưng những mô hình này vẫn được dành cho cùng một nhiệm vụ học,
ví dụ, dự đoán từ tiếp theo trên bàn phím.

Nhiều ứng dụng thực tế cần thiết bị thực hiện một loạt
các nhiệm vụ học rộng rãi, đòi hỏi huấn luyện nhiều
mô hình ML. Ví dụ, điện thoại của chúng ta cần các mô hình ngôn ngữ
cho dự đoán từ tiếp theo trên bàn phím cũng như các mô hình đề xuất hình ảnh
để làm nổi bật những hình ảnh có khả năng được chia sẻ cao hơn
[McMahan et al., 2017]. Yao et al. [2023] đề xuất
huấn luyện nhiều mô hình trong mạng xe hơi thông minh liên hợp cho
các nhiệm vụ khác nhau, chẳng hạn như phát hiện ổ gà và dự đoán
cơ động. Một ví dụ khác có thể là ứng dụng chat yêu cầu
các mô hình nhận dạng giọng nói và tạo văn bản phản hồi đồng
thời, trong khi Le et al. [2022] đề xuất học liên hợp
nhiều mô hình để dự báo chỉ số chất lượng không khí. Do đó,
trong bài báo này, chúng tôi tìm cách trả lời câu hỏi sau:
Làm thế nào chúng ta có thể huấn luyện hiệu quả các mô hình cho nhiều nhiệm vụ trong
một môi trường liên hợp sử dụng một nhóm khách hàng được chia sẻ?

Các Giải pháp Đơn giản mở rộng FedAvg. Một phương pháp ngây thơ
để huấn luyện nhiều mô hình là huấn luyện tuần tự, trong đó
các mô hình tương ứng với các nhiệm vụ khác nhau được huấn luyện lần lượt,
mỗi cái sử dụng tất cả khách hàng. Tổng thời gian chạy huấn luyện
của phương pháp này tăng tuyến tính với số lượng
nhiệm vụ. Một lựa chọn khác là để tất cả khách hàng huấn luyện tất cả nhiệm vụ
cùng một lúc. Tuy nhiên, với phương pháp này, mỗi khách hàng
sẽ phải giữ tất cả mô hình trong bộ nhớ, điều này không khả thi
đối với các khách hàng đầu cuối có tài nguyên hạn chế như điện thoại thông minh. Để
bảo tồn bộ nhớ, khách hàng sẽ phải xếp hàng các yêu cầu huấn luyện
và xử lý chúng tuần tự, một lần nữa dẫn đến
thời gian chạy tăng tuyến tính với số lượng nhiệm vụ. Mặt
khác, huấn luyện song song hoặc đồng thời (ST) của tất cả

--- TRANG 2 ---
các mô hình với các tập con khách hàng thay đổi theo thời gian được gán cho
mỗi nhiệm vụ có thể đạt được sự cân bằng tốt hơn giữa độ chính xác và
thời gian chạy. Phương pháp của Bhuyan et al. [2023] gán một tập con
khách hàng riêng biệt cho mỗi mô hình trong mỗi vòng, điều này cải thiện
đáng kể thời gian cần thiết để đạt độ chính xác mục tiêu
so với huấn luyện tuần tự. Tuy nhiên, những phương pháp huấn
luyện đồng thời liên hợp (FST) này vẫn còn chỗ để
cải thiện đáng kể. Có hai nhược điểm cụ thể: 1) độ trễ
straggler do tổng hợp đồng bộ, và 2) thiếu khả năng thích ứng
với tiến trình huấn luyện của các nhiệm vụ không đồng nhất, mà chúng tôi
giải quyết trong công trình này.

Tổng hợp Đồng bộ và Độ trễ Straggler. FL thông thường
sử dụng tổng hợp đồng bộ, trong đó ở mỗi vòng, máy chủ đợi
nhận cập nhật từ tất cả khách hàng tham gia trước mỗi lần tổng hợp.
Tuy nhiên, khi khách hàng có khả năng phần cứng và giao tiếp đa dạng,
khách hàng nhanh hơn phải ở trạng thái nghỉ cho đến khi khách hàng chậm hoặc
straggling hoàn thành, gây ra thời gian chạy wallclock lớn
để hoàn thành mỗi vòng giao tiếp. Vấn đề này càng
trở nên nghiêm trọng hơn trong FL với nhiều mô hình đồng thời
[Bhuyan et al., 2023, Zhou et al., 2022], trong đó quá trình tổng
hợp được đồng bộ hóa giữa các nhiệm vụ. Do đó, máy chủ
phải đợi khách hàng chậm nhất trong tất cả các nhiệm vụ song song.
Các giải pháp được đề xuất để giảm thiểu vấn đề straggler
trong bối cảnh mô hình đơn bao gồm cho phép khách hàng nhanh hơn
thực hiện nhiều bước cục bộ hơn [Wang et al., 2020b], chỉ tổng hợp
các cập nhật khách hàng đến trước thời hạn [Bonawitz
et al., 2019], và lấy mẫu phụ từ tập khách hàng có sẵn
[Luo et al., 2022]. Mặc dù những phương pháp này hoạt
động tốt khi straggler xuất hiện ngẫu nhiên đồng nhất, chúng
không hoạt động tốt trong môi trường huấn luyện đồng thời vì
một số mô hình (ví dụ, mô hình lớn hơn) tự nhiên chậm hơn
để huấn luyện. Khi nhiều mô hình có thời gian huấn luyện
khác nhau về bản chất, các vòng tổng hợp toàn cục đồng bộ
bị tắc nghẽn bởi khách hàng chậm nhất được gán cho mô hình
tính toán chuyên sâu nhất, dẫn đến thời gian rảnh rỗi lớn.

Tổng hợp Bất đồng bộ và Vấn đề Staleness. Một
giải pháp khác cho vấn đề straggler là tổng hợp bất đồng bộ
tại máy chủ, như được đề xuất trong AsyncFL [Xie
et al., 2019], trong đó máy chủ cập nhật mô hình toàn cục
bất cứ khi nào nhận được cập nhật từ khách hàng. Trong khi tổng hợp
bất đồng bộ đã được nghiên cứu rộng rãi trong học liên hợp
mô hình đơn [Chen et al., 2020, Wang et al., 2022, Xu
et al., 2023, Yu et al., 2023a], nó chưa được khám phá kỹ
cho huấn luyện liên hợp đồng thời. Mặc dù AsyncFL giải
quyết vấn đề straggler, nó gặp phải staleness không mong muốn
ngay cả trong môi trường FL tiêu chuẩn, vì các cập nhật khách hàng
nhận được thường dựa trên các mô hình lỗi thời. Để giảm thiểu
vấn đề staleness trong FL mô hình đơn, Nguyen et al. [2022]
đề xuất lưu trữ các cập nhật khách hàng đến trong bộ đệm tại
máy chủ và tổng hợp khi bộ đệm đầy.

Phân bổ Thích ứng Khách hàng cho Các Nhiệm vụ Không đồng nhất.
Trong công trình này, chúng tôi sử dụng tổng hợp bất đồng bộ có bộ đệm
để vượt qua vấn đề straggler trong khi kiểm soát staleness.
Tuy nhiên, việc mở rộng các thuật toán FL mô hình đơn [Xie et al.,
2019, Nguyen et al., 2022] để huấn luyện đồng thời nhiều
mô hình không đơn giản — chạy nhiều instance độc lập
của FL bất đồng bộ có thể không tối ưu. Điều này là do các nhiệm vụ
có thể có độ phức tạp tính toán không đồng nhất và tính không đồng nhất
dữ liệu khác nhau ảnh hưởng đến cả số vòng cần thiết để đạt
độ chính xác mục tiêu nhất định cũng như thời gian wall-clock
để hoàn thành mỗi vòng. Vì một tập khách hàng được chia sẻ được sử dụng
để huấn luyện các mô hình, các quá trình huấn luyện được kết nối — nhiều
tài nguyên hơn được gán cho một nhiệm vụ có nghĩa là ít hơn cho những
nhiệm vụ khác. Hơn nữa, yêu cầu tài nguyên tối ưu cho mỗi nhiệm vụ
có thể thay đổi theo thời gian tùy thuộc vào tính không đồng nhất dữ liệu
và tiến trình huấn luyện và có thể khó dự đoán trước khi
huấn luyện. Do đó, chúng tôi đề xuất một thuật toán thích ứng
động phân bổ lại khách hàng giữa các nhiệm vụ tùy thuộc vào
tiến trình huấn luyện của chúng, và cũng thích ứng kích thước bộ đệm được sử dụng
cho tổng hợp bất đồng bộ các cập nhật.

Đóng góp của Chúng tôi. Chúng tôi hình thức hóa môi trường FST trong
Phần 2 và sau đó đưa ra những đóng góp chính sau:

• Chúng tôi giới thiệu FedAST, một thuật toán Huấn luyện Đồng thời
Bất đồng bộ Liên hợp để huấn luyện đồng thời
các mô hình cho nhiều nhiệm vụ (Phần 3). Công trình của chúng tôi là một
trong những công trình đầu tiên giảm thiểu vấn đề straggler mà
các phương pháp FST đồng bộ mở rộng vanilla FedAvg gặp phải.

• Thuật toán được đề xuất giải quyết vấn đề cân bằng
tài nguyên giữa các nhiệm vụ không đồng nhất, một thách thức
độc đáo đối với khung FST, sử dụng phân bổ khách hàng
động mới, và nó cũng điều chỉnh động kích thước bộ đệm
được sử dụng trong tổng hợp bất đồng bộ để đạt được sự cân bằng
tốt nhất giữa staleness và thời gian chạy.

• Chúng tôi cung cấp phân tích hội tụ lý thuyết của FedAST
(Phần 4), cải thiện các phân tích trước đó ngay cả trong
môi trường FL mô hình đơn. Nó cải thiện so với [Koloskova
et al., 2022] bằng cách xem xét nhiều cập nhật cục bộ và
bộ đệm, và so với [Nguyen et al., 2022] bằng cách nới lỏng
các giả định hạn chế.

• Chúng tôi xác thực thực nghiệm hiệu suất của FedAST (Phần
5) về thời gian huấn luyện wall-clock và độ chính xác mô hình
trên nhiều bộ dữ liệu thực tế so với
các baseline FL đồng bộ và bất đồng bộ.

Chúng tôi kết luận và thảo luận công việc tương lai trong Phần 6.

Công trình Liên quan. Chỉ có một số công trình gần đây [Zhou et al.,
2022, Bhuyan và Moharir, 2022, Siew et al., 2023, Bhuyan
et al., 2023] xem xét huấn luyện đồng thời liên hợp
nhiều mô hình. Trong [Zhou et al., 2022], khách hàng được lựa chọn

--- TRANG 3 ---
bằng tối ưu hóa Bayesian hoặc học tăng cường
để giảm thiểu thời gian huấn luyện và sự bất công bằng trong tham gia.
Bhuyan và Moharir [2022] công thức hóa việc phân công khách hàng
FL như một vấn đề bandit tận dụng các mất mát huấn luyện cục bộ như
điểm số. Siew et al. [2023] giới thiệu lấy mẫu khách hàng thiên vị,
ưu tiên các khách hàng có mất mát cục bộ cao hơn. Những phương pháp này
thiếu đảm bảo hội tụ. Bhuyan et al. [2023] phân công
khách hàng ngẫu nhiên đồng nhất hoặc theo kiểu round-robin
và phân tích hội tụ giả định các hàm mục tiêu lồi
và gradient bị chặn. Trong khi những công trình này chỉ
xem xét tổng hợp đồng bộ, Chang et al. [2023] đề
xuất một thuật toán FST hoàn toàn bất đồng bộ. Phương pháp của họ
đòi hỏi giải quyết một vấn đề tối ưu hóa không lồi để tối
ưu hóa phân công khách hàng, yêu cầu thông tin về
độ trễ và mô hình có thể khó thu thập trong thực tế.
Ngoài ra, ranh giới thu được không hội tụ đến một điểm
cố định khi có tính không đồng nhất dữ liệu và gặp
staleness tăng khi số lượng khách hàng tăng.
Cuối cùng, Liu et al. [2023] đề xuất một phần mở rộng của
phương pháp thích ứng bất đồng bộ mô hình đơn của họ cho
môi trường đa mô hình. Tuy nhiên, họ không xử lý cẩn thận
phân phối dữ liệu không đồng nhất giữa các khách hàng và staleness
của các cập nhật trong đảm bảo lý thuyết của họ cho một mô hình đơn,
và họ thiếu những đảm bảo này cho nhiều mô hình. Ngoài ra,
phương pháp của họ không tận dụng đầy đủ tài nguyên khách hàng, vì sau khi
gửi cập nhật mô hình đến máy chủ, khách hàng ở trạng thái rảnh rỗi cho đến
vòng huấn luyện tiếp theo.

2 CÔNG THỨC HÓA VẤN ĐỀ

Ký hiệu. Đối với một số nguyên dương c, chúng tôi định nghĩa [c] ≜
{1, . . . , c}. ∇e biểu thị gradient ngẫu nhiên. Chữ cái thường
in đậm (ví dụ, x) biểu thị vector. |A| biểu thị cardinality
của tập hợp A. ∥ · ∥ biểu thị chuẩn Euclidean.

Bây giờ chúng tôi chính thức giới thiệu môi trường huấn luyện đồng thời
liên hợp (FST), trong đó N khách hàng huấn luyện M mô hình
x1, . . . , xM tương ứng với M nhiệm vụ độc lập. Đối với
mỗi nhiệm vụ m ∈ [M], mục tiêu của chúng tôi là tìm mô hình giải quyết
vấn đề tối ưu hóa sau:

min
x∈Rdm(
fm(x) := 1
N∑N
i=1fm,i(x))
, (1)

trong đó fm là hàm mất mát toàn cục cho nhiệm vụ m, và fm,i là
mất mát cục bộ cho nhiệm vụ m tại khách hàng i.

Đầu tiên, chúng tôi xem xét một phần mở rộng đơn giản của FedAvg [McMahan
et al., 2017] cho huấn luyện đồng thời các mô hình cho M nhiệm vụ.
Tại đầu mỗi vòng, máy chủ phân chia ngẫu nhiên tập
khách hàng có sẵn giữa các nhiệm vụ [Bhuyan et al., 2023].
Máy chủ gửi các mô hình hiện tại {x(tm)
m}M
m=1 cho tất cả
các nhiệm vụ đến tập con khách hàng tương ứng. Khách hàng
thực hiện huấn luyện cục bộ (Thuật toán 1) và trả về cập nhật
của họ cho máy chủ, máy chủ tổng hợp đồng bộ các cập nhật
cho mỗi nhiệm vụ. Phần mở rộng huấn luyện đồng thời ngây thơ này của

Thuật toán 1 LocalTrain (m,τm,x(tm)
m,ηc
m) tại khách hàng i
1: Đặt x(tm,0)
m,i ← x(tm)
m
2: for k = 1, . . . , τm do
3: x(tm,k)
m,i ← x(t,k−1)
m,i − ηc
m∇efm,i(x(t,k−1)
m,i)
4: end for
5: Return ∆m ← (x(tm)
m − x(tm,τm)
m,i)/(τmηc
m)

FedAvg hoạt động kém do straggler. Thời gian cần thiết
để một khách hàng trả về cập nhật của mình phụ thuộc vào tài nguyên của nó và
kích thước của mô hình được gán. Vì máy chủ đợi
cập nhật chậm nhất trong tất cả các nhiệm vụ trước khi bắt đầu
vòng tiếp theo, máy chủ đợi lâu hơn nhiều nếu một mô hình lớn
được gán cho một khách hàng chậm. Chúng tôi giảm thiểu vấn đề này thông qua
huấn luyện bất đồng bộ trong FedAST, được thảo luận tiếp theo.

3 MÔ TẢ THUẬT TOÁN

Tiếp theo, chúng tôi mô tả FedAST (Thuật toán 2), thuật toán
Huấn luyện Đồng thời Bất đồng bộ Liên hợp được đề xuất của chúng tôi,
được minh họa trong Hình 1 cho M = 2 nhiệm vụ. Đối với mỗi nhiệm vụ
m ∈ [M], máy chủ duy trì một chỉ số vòng tm được
khởi tạo thành tm = 0, số lượng yêu cầu huấn luyện hoạt động
R(tm)
m, và kích thước bộ đệm b(tm)
m. R(tm)
m và b(tm)
m định lượng
tài nguyên (tính toán khách hàng và bộ nhớ) được phân bổ cho
nhiệm vụ m trong vòng tm. Chúng tôi cung cấp hai phiên bản của FedAST
dựa trên giá trị của option ∈ {S, D}. Khi option là S
(tĩnh), phân bổ tài nguyên cho mỗi nhiệm vụ vẫn
giống nhau trong suốt quá trình huấn luyện (tức là, R(tm)
m ≡ Rm
và b(tm)
m ≡ bm). Với option = D (động), FedAST
phân bổ lại tài nguyên động giữa các nhiệm vụ sử dụng
subroutine Realloc (Thuật toán 3).

Phân công Yêu cầu Huấn luyện Cục bộ cho Khách hàng và
Thực thi của Chúng. Xem xét nhiệm vụ m ∈ [M]. Máy chủ bắt
đầu bằng cách gửi R(0)
m yêu cầu huấn luyện cục bộ cho nhiệm vụ m đến
khách hàng được chọn ngẫu nhiên đồng nhất, cùng với mô hình
ban đầu x(0)
m (Thuật toán 2, Dòng 4). Số lượng yêu cầu huấn luyện
cục bộ R(tm)
m được điều chỉnh theo thời gian sử dụng hàm Realloc
(Thuật toán 3), cho phép chúng ta phân bổ lại tài nguyên
khách hàng động giữa các nhiệm vụ. Mỗi khách hàng xử lý
yêu cầu huấn luyện bằng cách thực hiện τm lần lặp SGD
mini-batch cục bộ (xem Thuật toán 1) và gửi cập nhật mô hình
kết quả ∆m trở lại máy chủ. Nếu một khách hàng nhận được nhiều
yêu cầu, chúng được xếp hàng và xử lý theo cách first-come-
first-served. Do đó, số lượng khách hàng hoạt động
(khách hàng đang làm việc trên yêu cầu huấn luyện) tại bất kỳ thời điểm nào có thể
ít hơn số lượng yêu cầu huấn luyện hoạt động (mà khách hàng
đang làm việc hoặc được lưu trữ trong hàng đợi của họ).

Tổng hợp Bất đồng bộ có Bộ đệm tại Máy chủ. Các
cập nhật ∆m được gửi bởi khách hàng được tổng hợp tại máy chủ
theo cách bất đồng bộ như sau. Để giữ staleness trong
tầm kiểm soát, máy chủ duy trì một bộ đệm Bm cho nhiệm vụ m, lưu trữ
các cập nhật khách hàng nhận được cho mô hình m (Thuật toán 2,
Dòng 7). Kích thước bộ đệm b(tm)
m có thể được điều chỉnh theo thời gian
(sử dụng hàm Realloc). Bất cứ khi nào máy chủ nhận
được một cập nhật cho nhiệm vụ m, nó chọn ngẫu nhiên K(tm)
m
khách hàng để gửi một yêu cầu huấn luyện mới cùng với
mô hình toàn cục hiện tại (Thuật toán 2, Dòng 13). Như chúng tôi giải thích
dưới đây, K(tm)
m = 1 (tương ứng, K(tm)
m ∈ {0,1,2}) cho
option = S (option = D). Khi bộ đệm cho mô hình m
đầy (chính thức, |Bm| = b(tm)
m) máy chủ tổng hợp
các cập nhật được lưu trữ trong bộ đệm để cập nhật mô hình toàn cục
(Thuật toán 2, Dòng 10).

Điều chỉnh Động Số lượng Yêu cầu Hoạt động
và Kích thước Bộ đệm sử dụng Realloc (Thuật toán 3). Với
tùy chọn tĩnh (option = S), subroutine Realloc
luôn chạy Dòng 6 của nó để duy trì các giá trị ban đầu của Rm
và bm trong suốt toàn bộ quá trình huấn luyện. Phân bổ tài nguyên
giữa các nhiệm vụ không thay đổi theo thời gian. Mặt
khác, với tùy chọn động, subroutine Realloc điều
chỉnh phân bổ tài nguyên trong quá trình huấn luyện. Máy chủ
duy trì một bộ đếm c, theo dõi tổng số
cập nhật nhận được trên tất cả M nhiệm vụ (Thuật toán 2, Dòng 7).
Nếu option = D (động), bộ đếm này được sử dụng để định kỳ
kích hoạt điều chỉnh động số lượng yêu cầu huấn luyện
hoạt động Rm và kích thước bộ đệm bm giữa các nhiệm vụ
(Thuật toán 2, Dòng 8). Trực quan, chúng ta nên phân bổ nhiều hơn

Máy chủ Trả về cập nhật Yêu cầu huấn luyện mới Máy chủ Trả về cập nhật Yêu cầu huấn luyện mới

Hình 1: Trong thuật toán FedAST được đề xuất của chúng tôi, máy chủ
phân công các yêu cầu huấn luyện cục bộ (được hiển thị trong các khối
sọc và màu cam cho hai nhiệm vụ đồng thời), được xếp hàng tại
khách hàng và xử lý theo cách first-come-first-served.
Các yêu cầu hoàn thành được tổng hợp bất đồng bộ tại
máy chủ. Trong hình, các ảnh chụp của quá trình tại hai thời điểm
khác nhau được thấy. Điều chỉnh số lượng yêu cầu, FedAST
định kỳ phân bổ lại tài nguyên được chia sẻ giữa các mô hình.

khách hàng (và do đó, nhiều yêu cầu huấn luyện Rm hơn) cho
các nhiệm vụ có tính không đồng nhất dữ liệu giữa các khách hàng lớn hơn. Để ước tính
thực nghiệm tính không đồng nhất này, máy chủ lưu trữ V cập nhật cuối cùng
(V là một tham số có thể điều chỉnh) ∆m cho mỗi nhiệm vụ m
(ký hiệu {∆m,i}V
i=1) và tính toán

ˆσ2
g,m ∝ 1
V × ∑V
i=1 ∥∆m,i − ∆m∥2 / ∥∆m∥2, (2)

trong đó ∆m là trung bình thực nghiệm của các ∆m,i. Hơn nữa,
trong các thí nghiệm của chúng tôi, chúng tôi quan sát thực nghiệm rằng lựa chọn
tối ưu của kích thước bộ đệm bm tỷ lệ thuận với số lượng
yêu cầu hoạt động Rm. Xem Phụ lục C.5 cho các thí nghiệm
rộng rãi của chúng tôi. Sử dụng (2) và những quan sát thực nghiệm này,
phân bổ tài nguyên tối ưu xuất hiện như giải pháp cho
các ràng buộc sau.

∑M
i=1R(ti+1)
i = ∑M
i=1R(ti)
i,
R(t1+1)
1 / ˆσg,1 = R(t2+1)
2 / ˆσg,2 = ··· = R(tM+1)
M / ˆσg,M, (3)

trong đó tập ràng buộc đầu tiên duy trì tổng ngân sách
tính toán giữa các nhiệm vụ, và tập thứ hai đảm bảo phân bổ
số lượng yêu cầu huấn luyện lớn hơn cho khách hàng
với tính không đồng nhất cao hơn. Chúng tôi giải thích động lực lý thuyết
cho tập ràng buộc thứ hai trong Phần 4, một khi chúng tôi thiết lập
kết quả hội tụ của mình. Chúng tôi cũng tham khảo độc giả đến Phụ lục A
để biết thêm chi tiết về Realloc.

Gửi Yêu cầu Mới để Đạt Phân bổ Tài nguyên Mới. Để
chuyển từ một phân bổ {R(ti)
m}m sang

--- TRANG 4 ---
Thuật toán 2 FedAST
1: Đầu vào: Tỷ lệ học khách hàng và máy chủ {ηc
m, ηs
m}M
m=1,
option ∈ {S, D}, số cập nhật cục bộ {τm}M
m=1
2: Khởi tạo: ∀m ∈ [M]: tm ← 0 (chỉ số vòng), mô hình
x(0)
m, bộ đệm Bm ← ∅. Tổng số cập nhật c ← 0
3: for Mô hình m = 1, . . . , M (song song) do
4: Chọn ngẫu nhiên R(0)
m khách hàng và gửi
yêu cầu LocalTrain(m,τm,x(0)
m,ηc
m)
5: while tm < Tm do
6: Đợi cho đến khi máy chủ nhận được một cập nhật ∆m
7: Bm ← Bm ∪ {∆m}, c ← c + 1
8: {(R(ti+1)
i , b(ti+1)
i )}M
i=1 ← Realloc(option, c)
9: if |Bm| = b(tm)
m then
10: x(tm+1)
m ← x(tm)
m − ηs
mηc
mτm 1
b(tm)
m ∑
∆∈Bm ∆
11: tm ← tm + 1 and Bm ← ∅
12: end if
13: Chọn K(tm)
m khách hàng ngẫu nhiên và gửi
yêu cầu LocalTrain(m, τm, x(tm)
m, ηc
m)
14: end while
15: end for
16: Đầu ra: Các mô hình được huấn luyện {x(Tm)
m}M
m=1

khác {R(tm+1)
m}m trong một môi trường bất đồng bộ, chúng ta phải
điều chỉnh số lượng yêu cầu mới được gửi ra mỗi
lần máy chủ nhận được cập nhật khách hàng. Số lượng yêu cầu mới
K(tm)
m được gửi ra khi nhận được bất kỳ cập nhật ∆m nào
luôn là 1 trong trường hợp tĩnh (option = S) vì Rm vẫn
không đổi trong suốt quá trình huấn luyện. Trong trường hợp động (option =
D), K(tm)
m có thể là 0 (khi R(tm+1)
m < R(tm)
m), 1 (khi
R(tm+1)
m = R(tm)
m), hoặc 2 (khi R(tm+1)
m > R(tm)
m). Chúng tôi
sử dụng quá trình chuyển đổi dần dần này đến số lượng
yêu cầu huấn luyện hoạt động mong muốn mới {R(tm+1)
m}m cho mỗi nhiệm vụ thay vì
thay đổi đột ngột trong phân bổ để tránh hàng đợi có thể dài hơn
tại khách hàng trong giai đoạn chuyển đổi.

4 PHÂN TÍCH HỘI TỤ

Trong phần này, chúng tôi cung cấp kết quả hội tụ cho
FedAST với tùy chọn tĩnh (S). Vì R(tm)
m và b(tm)
m
là hằng số khi option = S, chúng tôi bỏ chỉ số thời gian để
đơn giản. Hội tụ với phân bổ động (op-
tion = D) có thể được chỉ ra với một giả định bổ sung. Chúng tôi
đưa điều này vào Phụ lục F do hạn chế không gian.

Tiếp theo, chúng tôi thảo luận các giả định được sử dụng trong phân tích của chúng tôi.

Giả định 1 (Tính mịn). Các hàm mất mát là L-
mịn, tức là, đối với tất cả i ∈ [N], đối với tất cả m ∈ [M], và đối với tất cả
x, y ∈ Rdm, ∥∇fm,i(x) − ∇fm,i(y)∥ ≤ L∥x − y∥.

Giả định 2 (Phương sai Bị chặn). Gradient ngẫu nhiên
tại mỗi khách hàng là một ước lượng không thiên vị, phương sai bị chặn
của gradient cục bộ thực, tức là, đối với tất cả x ∈ Rdm,
i ∈ [N], và m ∈ [M], E[∇efm,i(x)] = ∇fm,i(x) và
E∥∇efm,i(x) − ∇fm,i(x)∥2 ≤ σ2
l,m.

Giả định 3 (Tính không đồng nhất Bị chặn). Các gradient cục bộ
nằm trong khoảng cách bị chặn của gradient toàn cục,
sao cho đối với tất cả m ∈ [M] và x ∈ Rdm,
max
i∈[N] ∥∇fm,i(x) − ∇fm(x)∥2 ≤ σ2
g,m.

Giả định 4 (Staleness Bị chặn). Các cập nhật khách hàng
của nhiệm vụ m được nhận trong vòng tối đa γmax
m cập nhật mô hình máy chủ
sau khi máy chủ gửi yêu cầu huấn luyện.

Những giả định này là tiêu chuẩn trong tài liệu. Giả định
1-3 thường được sử dụng trong các phân tích FL đồng bộ [Wang et al., 2020b, Jhunjhunwala et al., 2022] và bất đồng bộ
[Koloskova et al., 2022, Nguyen et al., 2022]. 
Giả định 4 được sử dụng trong chứng minh hội tụ để đảm bảo
rằng không có cập nhật khách hàng được yêu cầu nào mất thời gian
tùy ý lớn để trở về máy chủ và cũng phổ biến trong
các công trình FL bất đồng bộ [Koloskova et al., 2022, Nguyen
et al., 2022]. Hơn nữa, staleness tối đa có thể được
thực thi bằng cách loại bỏ các cập nhật quá trễ trong thực tế trong
quá trình huấn luyện.

Định lý 1 (Hội tụ của FedAST). Giả sử rằng
Giả định 1 - 4 đúng, và có Rm yêu cầu huấn
luyện cục bộ hoạt động tương ứng với nhiệm vụ m ∈ [M],
và các tỷ lệ học máy chủ và khách hàng, {ηs
m, ηc
m}
tương ứng, thỏa mãn ηs
m ≤ √τmbm và ηc
m ≤
min{(6Lτm√τmbm)−1, (4Lτm√τmRmγmax
m)−1} đối với tất cả
nhiệm vụ m ∈ [M]. Ở đây, bm là kích thước bộ đệm, và τm
là số bước huấn luyện cục bộ. Khi đó, các iterate,
{{x(t)
m}Tm
t=1}M
m=1, của Thuật toán 2 thỏa mãn:

1
Tm ∑Tm−1
t=0 E∥∇fm(x(t))∥2 ≤ O( δm
Tmηc
mηs
mτm )
| {z }
Lỗi FedAvg - I

+ O( Lηc
mηs
m
bm + L2[ηc
m]2τm )(σ2
l,m + τmσ2
g,m)
| {z }
Lỗi FedAvg - II

+ O( L2[ηs
m]2[ηc
m]2τmRm
b2
m )(σ2
l,m + τmRmσ2
g,m)
| {z }
Lỗi Tổng hợp Bất đồng bộ, (4)

trong đó δm = fm(x(0)
m) − min x fm(x).

Chứng minh. Xem Phần E trong Phụ lục.

So sánh với Phân tích FL Đồng bộ. Các số hạng
Lỗi FedAvg - I và - II trong (4) bắt giữ ranh giới lỗi
cho FedAvg đồng bộ [Jhunjhunwala et al., 2022,
Định lý 1]. Vì các cập nhật máy chủ cho mô hình m bao gồm
tổng hợp bm cập nhật khách hàng, kích thước bộ đệm bm tương tự
như số khách hàng tham gia trong FedAvg. Số hạng lỗi
thứ ba trong (4) phát sinh do tổng hợp bất đồng bộ
và tăng với Rm, số lượng yêu cầu huấn luyện cục bộ
hoạt động. Trực quan, với cùng kích thước bộ đệm bm,
tăng Rm dẫn đến staleness trường hợp xấu nhất γmax
m cao hơn.
Tuy nhiên, miễn là Lηs
mηc
mR2
mτm ≤ bm, bất đồng bộ không
phải là nguồn lỗi chủ đạo trong (4), và chúng ta đạt được
tỷ lệ hội tụ giống như FedAvg đồng bộ (xem
Hệ quả 1.1).

So sánh với Phân tích FL Bất đồng bộ. FedBuff
[Nguyen et al., 2022] xem xét tổng hợp bất đồng bộ có bộ đệm
cho một mô hình đơn. Tuy nhiên, so sánh [Nguyen
et al., 2022, Hệ quả 1] và ranh giới trong (4) cho M = 1,
kết quả hội tụ của họ (i) phụ thuộc vào các giả định mạnh hơn
(chuẩn gradient bị chặn và việc đến đồng nhất của các cập nhật khách hàng),

--- TRANG 5 ---
và (ii) có lỗi tổng hợp bất đồng bộ tệ hơn. Hơn nữa, phân tích của chúng tôi tổng quát hơn so với
[Koloskova et al., 2022] vì họ không xem xét nhiều
bước SGD cục bộ và bộ đệm. Huấn luyện bất đồng bộ đồng thời
được xem xét bởi [Chang et al., 2023], nhưng chúng tôi quan
sát rằng họ không đạt được hội tụ trừ khi phân phối dữ liệu
giữa các khách hàng là giống hệt nhau (xem [Chang et al.,
2023, Eq. (19)]). Chúng tôi thảo luận so sánh FedAST
với các baseline học liên hợp bất đồng bộ mô hình đơn và đồng thời
chi tiết hơn trong Phần B của Phụ lục.

Hệ quả 1.1 (Hội tụ tiệm cận sau khi đặt tỷ lệ
học). Cho Tm ≥ τm max{36bm, 16Rmγmax}. Đặt
tỷ lệ học ηc
m = (τmL√Tm)−1, ηs
m = √τmbm,
ranh giới trong Định lý 1 giảm thành:

1
Tm ∑Tm−1
t=0 E∥∇fm(x(t))∥2 ≤ O( δmL√bmτmTm )
+ O( 1
√Tmbmτm + 1
τmTm )(σ2
l,m + τmσ2
g,m)
+ O( Rm
Tmbm )(σ2
l,m + τmRmσ2
g,m). (5)

Mặc dù ranh giới cho trong Hệ quả 1.1 dường như không
phụ thuộc vào ranh giới staleness γmax (Giả định 4), tác động của nó
được ngầm hiểu trong số lượng yêu cầu hoạt động Rm và
kích thước bộ đệm bm. Staleness tối đa tương quan thuận
với Rm và tương quan nghịch với bm. Trong các thí nghiệm của chúng tôi
(Phụ lục C.5), chúng tôi điều chỉnh kích thước bộ đệm để
duy trì staleness cập nhật ở mức hợp lý.

Nhìn vào các ranh giới trong (4) hoặc (5), tăng Rm làm
ranh giới tệ hơn vì để đạt cùng độ chính xác trong
(5), chúng ta cần chạy số lượng cập nhật máy chủ Tm cao hơn.
Tuy nhiên, tăng Rm cũng rút ngắn thời gian giữa
hai cập nhật máy chủ liên tiếp, làm cho thuật toán nhanh hơn
về thời gian wall-clock. Chúng tôi minh họa hiệu ứng này với so sánh wall-clock
với các baseline FST dưới đây.

Tác động của Rm đến Thời gian Wall-clock. Giả sử thời gian
đến của tất cả cập nhật khách hàng (giả định không có
hàng đợi trên khách hàng) được phân phối như Exp(λ). Thời gian
dự kiến để lấp đầy bộ đệm tương ứng với nhiệm vụ m
là bm/(Rmλ). Do đó, trong FedAST, thời gian dự kiến
để hoàn thành một vòng tại máy chủ tỷ lệ nghịch
với Rm. Mặt khác, thời gian dự kiến để hoàn thành
một vòng huấn luyện FedAvg đồng thời đồng bộ
là 1
λ ∑R1+···+RM
k=1 1
k ≈ 1
λ log(∑M
k=1 Rk), tăng
với Rm. Ngoài ra, việc tổng trên các nhiệm vụ được huấn luyện đồng thời
cho thấy hiệu ứng straggler trầm trọng hơn vì tất cả
khách hàng đợi khách hàng chậm nhất trong tất cả các nhiệm vụ.

Thiết kế của Realloc (Thuật toán 3). Tiếp theo, chúng tôi lý
giải lý thuyết cho việc phân bổ tài nguyên động giữa các nhiệm vụ
được mô tả trong Phần 3 (Thuật toán 3, với option = D),
điều chỉnh số lượng yêu cầu hoạt động ({Rm}M
m=1).
Với số lượng khách hàng có sẵn hạn chế (giới hạn
tổng số yêu cầu huấn luyện hoạt động), để đạt được
phân bổ tốt nhất có thể, chúng tôi tối thiểu hóa tổng của
các số hạng chiếm ưu thế nhất trong các ranh giới (Lỗi FedAvg-II trong (4))
giữa các nhiệm vụ. Chúng tôi cũng sử dụng quan sát thực nghiệm rằng
lựa chọn tối ưu của kích thước bộ đệm bm tỷ lệ tuyến tính với Rm
(Phụ lục C.5). Vấn đề tối ưu hóa kết quả là

min
{Rm,bm}M
m=1 ∑M
m=1 ηs
mηc
mτm
Rm σ2
g,m s.t. ∑M
m=1 Rm = R, (6)

trong đó R là ngân sách cho tổng số yêu cầu huấn luyện
giữa tất cả các nhiệm vụ trong hệ thống tùy thuộc vào số lượng
khách hàng có sẵn. Hàm Realloc (Thuật
toán 3) giải quyết vấn đề tối ưu hóa (6). Xem Phụ
lục A để biết thêm chi tiết.

5 KẾT QUẢ THỰC NGHIỆM

Chúng tôi phác thảo thiết lập thực nghiệm trong Phần 5.1, thảo luận
các baseline hiện có trong Phần 5.2, và so sánh các baseline
với FedAST dưới các cài đặt khác nhau trong Phần 5.3.

5.1 BỘ DỮ LIỆU VÀ TRIỂN KHAI

Chúng tôi xem xét các nhiệm vụ phân loại hình ảnh với các bộ dữ liệu MNIST
[Deng, 2012], Fashion-MNIST [Xiao et al., 2017] và
CIFAR-10 [Krizhevsky et al., 2009], và dự đoán ký tự tiếp theo
với bộ dữ liệu Shakespeare [Caldas et al., 2019] sử dụng
cùng các mô hình như trong các công trình trước [Acar
et al., 2021, Yu et al., 2023b, Lecun et al., 1998]. Chúng tôi so
sánh thời gian wall-clock cần thiết bởi các thuật toán khác nhau để
đạt một số mức độ chính xác kiểm tra mục tiêu được xác định trước (xem
Bảng 1). Trong Phụ lục D.5, chúng tôi trình bày các thí nghiệm với
các mức độ chính xác mục tiêu khác để chỉ ra tính nhất quán của
kết quả. Chúng tôi cũng xác nhận kết quả với ResNet-18, một
mô hình lớn hơn, được huấn luyện cho nhiệm vụ phân loại CIFAR-100 trong
Phụ lục D.4. Trong tất cả các thí nghiệm, chúng tôi thực hiện ba lần chạy Monte
Carlo với các seed ngẫu nhiên khác nhau và báo cáo kết quả
trung bình.

Bảng 1: Các bộ dữ liệu và mô hình được sử dụng trong thí nghiệm, cùng
với các mức độ chính xác kiểm tra mục tiêu tương ứng.

Bộ dữ liệu | Mô hình | Độ chính xác Mục tiêu
MNIST | MLP | 93%
Fashion-MNIST | LeNet-5 | 82%
CIFAR-10 | CNN | 63%
Shakespeare | LSTM | 42%

Đối với các nhiệm vụ phân loại hình ảnh, chúng tôi phân chia dữ liệu huấn luyện
giữa các khách hàng sử dụng phân phối Dirichlet với α = 0.1
để tạo tính không đồng nhất dữ liệu giữa các khách hàng [Yurochkin et al.,
2019]. Bộ dữ liệu Shakespeare tự nhiên không đồng nhất
vì các câu thoại của mỗi vai trong các vở kịch của Shakespeare được
gán cho một khách hàng khác nhau. Có tổng cộng 1000 khách hàng,

--- TRANG 6 ---
[Biểu đồ hiển thị độ chính xác trung bình cho sáu nhiệm vụ CIFAR-10 đồng thời]

Hình 2: Độ chính xác kiểm tra trung bình cho các thuật toán được so sánh trên sáu
nhiệm vụ CIFAR-10 giống hệt nhau được huấn luyện đồng thời. FedAST
huấn luyện nhanh hơn các phương pháp đồng bộ. Phương pháp đồng bộ
không có giảm thiểu straggler là chậm nhất.

30% trong số đó có sẵn để chấp nhận các yêu cầu huấn luyện mới,
độc lập với quá khứ.

Mô hình hóa Độ trễ Khách hàng. Như được đề xuất trong [Lee et al.,
2018, Dutta et al., 2021, Shi et al., 2021, Zhou et al., 2022],
chúng tôi sử dụng các biến ngẫu nhiên shifted-exponential (exponential cộng hằng số)
để mô hình hóa thời gian một khách hàng cần để
hoàn thành một yêu cầu huấn luyện cục bộ và trả về cập nhật cho
máy chủ. Chúng tôi chọn các tham số tạo thời gian chạy của mỗi
nhiệm vụ theo các phép đo thực trên GPU NVIDIA GeForce
GTX TITAN X. Để mô phỏng tính không đồng nhất phần cứng
giữa các khách hàng, chúng tôi chia họ thành 25% chậm, 50% tốc độ bình thường,
và 25% khách hàng nhanh [Leconte et al., 2023]. Chúng tôi đưa
các chi tiết triển khai bổ sung vào Phụ lục.

5.2 CÁC THUẬT TOÁN BASELINE

Chúng tôi giải thích các phương pháp baseline đồng bộ và bất đồng bộ
mà chúng tôi so sánh FedAST:

Huấn luyện Đồng thời Đồng bộ. Các phương pháp đồng bộ sau
chỉ khác nhau trong việc lựa chọn khách hàng.

1. Sync-ST [Bhuyan et al., 2023]: phân chia ngẫu nhiên
tập khách hàng giữa các nhiệm vụ tại mỗi vòng;
2. Sync-Bayes-ST [Zhou et al., 2022]: gán khách hàng
cho nhiệm vụ dựa trên tối ưu hóa Bayesian;
3. Sync-UCB-ST [Bhuyan và Moharir, 2022]: lựa chọn
khách hàng như một vấn đề multi-armed bandit.

Trong Hình 2, đầu tiên chúng tôi huấn luyện đồng thời sáu mô hình CIFAR-10
và so sánh hiệu suất của tất cả các baseline đồng bộ
và FedAST. Vì các phương pháp đồng bộ hoạt động kém do
vấn đề straggler nghiêm trọng, chúng tôi tăng cường chúng
với phương pháp giảm thiểu straggler bằng cách chỉ tổng hợp
k cập nhật khách hàng đầu tiên cho mỗi nhiệm vụ và loại bỏ
phần còn lại [Bonawitz et al., 2019] làm tùy chọn mặc định. Chúng tôi
chọn k = 30 bằng các thí nghiệm xác thực trên các bộ dữ liệu
trong Phụ lục D.1. Việc tăng cường bổ sung này làm cho các
baseline cạnh tranh hơn. Trong Hình 2, chúng tôi cũng thêm kết quả
của Sync-ST-NoStrag.Mit., đó là Sync-ST

[Biểu đồ hiển thị độ chính xác cuối cùng với tỷ lệ khách hàng hoạt động khác nhau]

Hình 3: Giá trị độ chính xác kiểm tra cuối cùng trung bình của FedAST
(xanh dương), FedAST-NoBuffer (xanh ô liu) và huấn luyện tập trung
(tím) với tỷ lệ khách hàng hoạt động khác nhau, khi huấn luyện
3 mô hình giống hệt nhau. Hình bên trái (phải) là cho bộ dữ liệu
CIFAR-10 (Fashion-MNIST). Với nhiều khách hàng hoạt động hơn, tầm quan trọng
của bộ đệm tăng do staleness tăng.

[Biểu đồ so sánh FedAST và FedAST-NoBuffer]

Hình 4: Giá trị độ chính xác kiểm tra trung bình của FedAST và
FedAST-NoBuffer, khi huấn luyện đồng thời một
mô hình cho CIFAR-10 và một cho Fashion-MNIST. FedAST
đạt được mức độ chính xác cao hơn và ổn định hơn.

không có giảm thiểu straggler tăng cường của chúng tôi. Nó cho thấy rằng
các baseline đồng bộ có hiệu ứng straggler lớn mà không có
việc tăng cường bổ sung của chúng tôi.

Huấn luyện Đồng thời Liên hợp Bất đồng bộ. Theo
hiểu biết của chúng tôi, [Chang et al., 2023] là công trình duy nhất
chủ yếu nghiên cứu FL đồng thời bất đồng bộ.
Tuy nhiên, sơ đồ lựa chọn khách hàng của họ yêu cầu kiến thức
về staleness và hằng số smoothness toàn mạng,
khó ước tính. Nếu các nhiệm vụ có độ phức tạp mô hình
và độ khó nhiệm vụ tương tự, việc lựa chọn khách hàng của họ
tương tự như FedAST với kích thước bộ đệm là 1. Do đó chúng tôi
bao gồm phiên bản không có bộ đệm này của FedAST (chúng tôi gọi
nó là FedAST-NoBuffer) làm baseline.

5.3 KẾT QUẢ VÀ HIỂU BIẾT

Chúng tôi đánh giá hiệu suất của FedAST dưới các
tình huống khác nhau. Trong các thí nghiệm nhiệm vụ đồng nhất, trong đó nhiều
bản sao độc lập của cùng một mô hình được huấn luyện đồng thời
sử dụng cùng bộ dữ liệu, chúng tôi báo cáo độ chính xác trung bình
theo thời gian. Trong các thí nghiệm nhiệm vụ không đồng nhất bao gồm
các nhiệm vụ và mô hình khác nhau, việc phân phối tài nguyên hiệu quả để
tăng tốc hoàn thành tất cả các nhiệm vụ là thách thức chính.
Đối với các nhiệm vụ đồng nhất, chúng tôi sử dụng FedAST với tùy chọn
tĩnh (S) và phân phối khách hàng đồng nhất giữa các nhiệm vụ. Trong
các thí nghiệm nhiệm vụ không đồng nhất, chúng tôi sử dụng phân bổ động
(option = D) để nâng cao hiệu quả phân bổ tài nguyên. Để

--- TRANG 7 ---
[Biểu đồ thời gian để đạt mục tiêu cho 2/4/6 nhiệm vụ]

Hình 5: Thời gian huấn luyện trung bình của FedAST và Sync-ST để đạt mức độ chính xác mục tiêu trong (Bảng 1) trên 2/4/6 nhiệm vụ với
các bộ dữ liệu CIFAR-10, Fashion-MNIST, MNIST, và Shakespeare. FedAST yêu cầu thời gian wall-clock thấp hơn một cách nhất quán cho
huấn luyện so với Sync-ST; các phần trăm thể hiện những lợi ích thời gian này.

chỉ ra lợi ích của phân bổ động so với phân bổ
tĩnh, chúng tôi cũng khám phá các tình huống nhiệm vụ không đồng nhất với
option = S. Phân bổ động giảm tổng thời gian huấn luyện
lên đến 11.9%, với kết quả toàn diện được hiển thị trong
Phụ lục D.6.

Để định lượng thời gian tiết kiệm được bằng cách sử dụng FedAST so với
một baseline cạnh tranh nào đó, chúng tôi định nghĩa lợi ích thời gian như

Lợi ích ≜ (TBaseline − TFedAST) / TBaseline × 100%,

trong đó TBaseline (TFedAST) là thời gian mô phỏng cho
Baseline (FedAST) để đạt độ chính xác mục tiêu.

So sánh với Tất cả Phương pháp FST Đồng bộ. Đầu tiên,
chúng tôi so sánh các baseline đồng bộ được thảo luận trong
Phần 5.2 trên bộ dữ liệu CIFAR-10 (Hình 2), trong đó
chúng tôi huấn luyện đồng thời sáu mô hình giống hệt nhau. Chúng tôi quan
sát rằng các phương pháp đồng bộ không có giảm thiểu straggler
hội tụ rất chậm. Trong số các biến thể đồng bộ
có giảm thiểu straggler mà chúng tôi triển khai, Hình
2 cho thấy Sync-Bayes-ST có hiệu suất tương tự
như Sync-ST vì nó gặp khó khăn do không gian tìm kiếm
lớn của vấn đề tối ưu hóa, xuất phát từ số lượng
lịch trình khách hàng có thể theo cấp số nhân. Hơn nữa, chúng tôi không
quan sát bất kỳ lợi ích hiệu suất nào từ việc sử dụng Sync-UCB-ST
so với Sync-ST. Cho rằng Sync-Bayes-ST và
Sync-UCB-ST có hiệu suất tương tự như Sync-ST, trong
các thí nghiệm tiếp theo, chúng tôi chọn Sync-ST làm baseline
đồng bộ duy nhất.

Nhu cầu về Bộ đệm. Như đã thảo luận trước đó, việc kết hợp
bộ đệm giảm thiểu tác động tiêu cực của các cập nhật rất cũ.
Vì staleness tăng với số lượng khách hàng hoạt động, các phương pháp FL bất đồng bộ không có bộ đệm
thể hiện khả năng mở rộng hạn chế khi số lượng khách hàng tăng.
Để chứng minh điều này, trong Hình 3, chúng tôi thực hiện hai thí
nghiệm: 1) huấn luyện ba mô hình cho CIFAR-10 đồng thời, và 2) huấn luyện ba mô hình cho Fashion-MNIST
đồng thời. Chúng tôi vẽ các giá trị độ chính xác cuối cùng với
tỷ lệ khách hàng hoạt động khác nhau. Chúng tôi quan sát rằng đối với tỷ lệ khách hàng hoạt động nhỏ, FedAST và FedAST-NoBuffer
có hiệu suất tương đương. Tuy nhiên, với nhiều khách hàng hoạt động hơn, staleness của các cập nhật tăng, dẫn đến
hiệu suất kém đáng kể của thuật toán
FedAST-NoBuffer hoàn toàn bất đồng bộ. Sau đó, trong Hình 4, chúng tôi huấn luyện đồng thời hai mô hình, một cho CIFAR-10 và
Fashion-MNIST. Quan sát các đường cong học không ổn định của
FedAST-NoBuffer, chúng tôi kết luận rằng bộ đệm làm cho
hệ thống mạnh mẽ hơn đối với các cập nhật cũ.

So sánh với Sync-ST. Tiếp theo, chúng tôi so sánh
FedAST với phương pháp đồng bộ được chọn, Sync-ST.

[Biểu đồ đường cong huấn luyện cho thí nghiệm không đồng nhất]

Hình 6: Đường cong huấn luyện của một lần chạy Monte Carlo duy nhất trong
thí nghiệm không đồng nhất. Các đường dọc đứt nét hiển thị
thời điểm khi các nhiệm vụ đạt độ chính xác mục tiêu, với FedAST
đạt được nhanh hơn Sync-ST.

1) Nhiệm vụ Đồng nhất: Chúng tôi thực hiện các thí nghiệm huấn luyện
2, 4, và 6 mô hình giống hệt nhau cho mỗi bộ dữ liệu MNIST, Fashion-
MNIST, CIFAR-10, và Shakespeare. Hình 5
hiển thị thời gian hoàn thành trung bình của các thuật toán, và
lợi ích thời gian đáng kể của thuật toán FedAST so với
Sync-ST đồng bộ (ngay cả sau khi kết hợp giảm thiểu straggler). Chúng tôi quan sát rằng lợi ích tăng với số lượng
nhiệm vụ được huấn luyện đồng thời vì Sync-ST đặc biệt
dễ bị tổn thương bởi vấn đề straggler.

2) Nhiệm vụ Không đồng nhất: Thí nghiệm không đồng nhất
huấn luyện 4 mô hình đồng thời, một cho mỗi bộ dữ liệu MNIST,
Fashion-MNIST, CIFAR-10, và Shakespeare.
Khi một mô hình đạt độ chính xác mục tiêu, việc huấn luyện của nó

--- TRANG 8 ---
[Biểu đồ thời gian hoàn thành trung bình]

Hình 7: Thời gian trung bình cần thiết để đạt độ chính xác mục tiêu và
lợi ích thời gian của FedAST so với Sync-ST trong thí nghiệm
không đồng nhất. Trong khi FedAST không yêu cầu tinh chỉnh thủ công,
việc phân bổ khách hàng trong Sync-ST được điều chỉnh ở 100, 84,
48, và 68 khách hàng cho các nhiệm vụ MNIST, Fashion-MNIST, CIFAR-10,
và Shakespeare tương ứng. FedAST có lợi ích thời gian đáng chú ý
(40.1%) so với Sync-ST để hoàn thành tất cả các nhiệm vụ.

dừng lại, và các khách hàng của nó được phân bổ lại cho các nhiệm vụ khác. Chúng tôi sử dụng
FedAST với option = D cho phân bổ khách hàng động.
Đối với baseline đồng bộ Sync-ST, chúng tôi chạy 30
sơ đồ phân bổ khách hàng khác nhau, bao gồm sơ đồ phân bổ
được đề xuất của chúng tôi và phân bổ đồng nhất giữa các nhiệm vụ. Chúng tôi
báo cáo kết quả đạt được với sơ đồ hoạt động tốt nhất.
Hình 6 hiển thị các đường cong học cho FedAST và Sync-ST
từ một lần chạy Monte Carlo duy nhất. Các đường dọc đứt nét
biểu thị thời điểm khi một mô hình đạt độ chính xác mục tiêu
của nó, sau đó các khách hàng huấn luyện mô hình này được
phân bổ lại cho các nhiệm vụ khác. Hình 7 hiển thị thời gian hoàn thành
trung bình cho 4 mô hình được huấn luyện đồng thời với FedAST
và Sync-ST. Ví dụ, với FedAST, mô hình cho
bộ dữ liệu MNIST đạt độ chính xác mục tiêu tại 99, sau đó
các khách hàng huấn luyện mô hình này được phân bổ lại cho các mô hình khác. Tại 619, việc huấn luyện mô hình cuối cùng (cho CIFAR-10)
hoàn thành. So sánh thời gian hoàn thành cho mô hình cuối cùng,
FedAST cung cấp lợi ích thời gian 40.1% so với Sync-ST.

Chúng tôi quan sát rằng nhờ phân bổ khách hàng động,
FedAST tự động phát hiện nhiệm vụ nào có tính không đồng nhất
cao hơn giữa các khách hàng và cần bộ đệm lớn hơn. Chúng tôi nhận thấy
rằng nhiệm vụ Shakespeare được phân bổ ít khách hàng hơn vì nó
được ước tính ít không đồng nhất hơn, điều này đúng dựa trên
phân phối nhãn của các mẫu dữ liệu giữa các khách hàng. Chúng tôi cũng
lặp lại thí nghiệm này (Phụ lục D.6) sử dụng FedAST với
tùy chọn tĩnh (S) để xác thực chiến lược phân bổ khách hàng
động được đề xuất. Phân bổ khách hàng động nhất quán
có lợi ích thời gian lên đến 11.9% so với phiên bản tĩnh.

6 KẾT LUẬN

Trong bài báo này, chúng tôi trình bày FedAST, một khung học liên hợp
để huấn luyện đồng thời nhiều mô hình sử dụng
tổng hợp bất đồng bộ có bộ đệm. Chúng tôi chứng minh lý thuyết
sự hội tụ của thuật toán cho các hàm mục tiêu không lồi mịn. Các thí nghiệm trên nhiều bộ dữ liệu chứng minh
sự vượt trội của FedAST so với các baseline FL đồng thời
hiện có, đạt được giảm lên đến 46.0% thời gian huấn luyện. Trong công việc tương lai, chúng tôi dự định nâng cao FedAST
bằng cách kết hợp lựa chọn khách hàng dựa trên phân phối dữ liệu cục bộ
và sức mạnh tính toán của khách hàng.

LỜI CẢM ƠN

Công trình này được hỗ trợ một phần bởi Quỹ Khoa học Quốc gia Hoa Kỳ
dưới các khoản tài trợ CNS-1751075 và CNS-
2106891 cho CJW và NSF CCF 2045694, CNS-2112471,
CPS-2111751, và ONR N00014-23-1-2149 cho GJ và
Học bổng Tốt nghiệp Tổng thống Ben Cook cho BA.

Tài liệu tham khảo

Durmus Alp Emre Acar, Yue Zhao, Ramon Matas, Matthew
Mattina, Paul Whatmough, và Venkatesh Saligrama.
Học liên hợp dựa trên chính quy hóa động. Trong
Hội nghị Quốc tế về Biểu diễn Học, 2021. URL https://openreview.net/forum?
id=B7v4QMR6Z9w.

Fan Ang, Li Chen, Nan Zhao, Yunfei Chen, Weidong Wang,
và F Richard Yu. Học liên hợp mạnh mẽ với giao tiếp
nhiễu. IEEE Transactions on Communications,
68(6):3452–3464, 2020.

Neelkamal Bhuyan và Sharayu Moharir. Học liên hợp
đa mô hình. Trong Hội nghị Quốc tế lần thứ 14 về
Hệ thống Truyền thông & Mạng (COMSNETS) năm 2022,
trang 779–783. IEEE, 2022.

Neelkamal Bhuyan, Sharayu Moharir, và Gauri Joshi.
Học liên hợp đa mô hình với đảm bảo có thể chứng minh.
Trong Esa Hyytiä và Veeraruna Kavitha, editors, Phương pháp luận và Công cụ Đánh giá Hiệu suất, trang 207–
222, Cham, 2023. Springer Nature Switzerland. ISBN
978-3-031-31234-2.

K. A. Bonawitz, Hubert Eichner, Wolfgang Grieskamp,
Dzmitry Huba, Alex Ingerman, Vladimir Ivanov, Chloé M
Kiddon, Jakub Konečný, Stefano Mazzocchi, Brendan
McMahan, Timon Van Overveldt, David Petrou, Daniel
Ramage, và Jason Roselander. Hướng tới học liên hợp
quy mô lớn: Thiết kế hệ thống. Trong SysML 2019, 2019. URL
https://arxiv.org/abs/1902.01046. Sẽ xuất hiện.

Sebastian Caldas, Sai Meher Karthik Duddu, Peter Wu,
Tian Li, Jakub Konečný, H. Brendan McMahan, Virginia
Smith, và Ameet Talwalkar. Leaf: Một benchmark cho
các thiết lập liên hợp, 2019.

--- TRANG 9 ---
Zhan-Lun Chang, Seyyedali Hosseinalipour, Mung Chiang,
và Christopher G. Brinton. Học liên hợp động đa mô hình
bất đồng bộ qua mạng không dây: Lý thuyết, mô hình hóa, và tối ưu hóa, 2023.

Vishnu Pandi Chellapandi, Antesh Upadhyay, Abolfazl
Hashemi, và Stanislaw H Żak. Về sự hội tụ
của học liên hợp phi tập trung dưới chia sẻ thông tin
không hoàn hảo. IEEE Control Systems Letters, 2023.

Yujing Chen, Yue Ning, Martin Slawski, và Huzefa Rang-
wala. Học liên hợp trực tuyến bất đồng bộ cho các thiết bị
biên với dữ liệu non-iid. Trong Hội nghị Quốc tế IEEE
về Dữ liệu Lớn năm 2020 (Big Data), trang 15–24. IEEE,
2020.

Yae Jee Cho, Jianyu Wang, và Gauri Joshi. Hướng tới
hiểu biết về lựa chọn khách hàng thiên vị trong học liên hợp.
Trong Gustau Camps-Valls, Francisco J. R. Ruiz, và Isabel Valera, editors, Tuyển tập Hội nghị Quốc tế
lần thứ 25 về Trí tuệ Nhân tạo và Thống kê, tập 151 của Tuyển tập Nghiên cứu Học Máy, trang 10351–10375. PMLR, 28–30 Tháng 3
2022. URL https://proceedings.mlr.press/
v151/jee-cho22a.html.

Li Deng. Cơ sở dữ liệu mnist về hình ảnh chữ số viết tay
cho nghiên cứu học máy [tốt nhất của web]. IEEE
Signal Processing Magazine, 29(6):141–142, 2012. doi:
10.1109/MSP.2012.2211477.

Sanghamitra Dutta, Jianyu Wang, và Gauri Joshi. Gradient
chậm và cũ có thể thắng cuộc đua. IEEE Journal on
Selected Areas in Information Theory, 2(3):1012–1024,
2021. doi: 10.1109/JSAIT.2021.3103770.

Divyansh Jhunjhunwala, Pranay Sharma, Aushim Na-
garkatti, và Gauri Joshi. Fedvarp: Giải quyết phương sai
do sự tham gia một phần của khách hàng trong học liên hợp.
Trong Uncertainty in Artificial Intelligence, trang 906–916.
PMLR, 2022.

Peter Kairouz, H Brendan McMahan, Brendan Avent, Au-
rélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista
Bonawitz, Zachary Charles, Graham Cormode, Rachel
Cummings, et al. Tiến bộ và vấn đề mở trong
học liên hợp. Foundations and Trends® in Machine
Learning, 14(1–2):1–210, 2021.

Anastasia Koloskova, Sebastian U Stich, và Martin Jaggi.
Đảm bảo hội tụ sắc nét hơn cho SGD bất đồng bộ
cho học phân tán và liên hợp. Trong Alice H.
Oh, Alekh Agarwal, Danielle Belgrave, và Kyunghyun
Cho, editors, Advances in Neural Information Processing
Systems, 2022. URL https://openreview.net/
forum?id=4_oCZgBIVI.

Alex Krizhevsky, Geoffrey Hinton, et al. Học nhiều
lớp đặc trưng từ hình ảnh nhỏ. 2009.

Duy-Dong Le, Anh-Khoa Tran, Minh-Son Dao, Kieu-
Chinh Nguyen-Ly, Hoang-Son Le, Xuan-Dao Nguyen-
Thi, Thanh-Qui Pham, Van-Luong Nguyen, và Bach-
Yen Nguyen-Thi. Hiểu biết về học liên hợp đa mô hình: Một
phương pháp tiên tiến để dự báo chỉ số chất lượng không khí.
Algorithms, 15(11):434, 2022.

Louis Leconte, Van Minh Nguyen, và Eric Moulines.
Favano: Trung bình liên hợp với các nút bất đồng bộ,
2023.

Y. Lecun, L. Bottou, Y. Bengio, và P. Haffner. Học
dựa trên gradient được áp dụng cho nhận dạng tài liệu. Proceedings of the IEEE, 86(11):2278–2324, 1998. doi:
10.1109/5.726791.

Kangwook Lee, Maximilian Lam, Ramtin Pedarsani, Dim-
itris Papailiopoulos, và Kannan Ramchandran. Tăng tốc
học máy phân tán sử dụng mã. IEEE Transactions on Information Theory, 64(3):1514–1529, 2018.
doi: 10.1109/TIT.2017.2736066.

Tian Li, Shengyuan Hu, Ahmad Beirami, và Virginia
Smith. Ditto: Học liên hợp công bằng và mạnh mẽ thông qua
cá nhân hóa. Trong International Conference on Machine
Learning, trang 6357–6368. PMLR, 2021.

Jianchun Liu, Hongli Xu, Lun Wang, Yang Xu, Chen Qian,
Jinyang Huang, và He Huang. Học liên hợp bất đồng bộ
thích ứng trong tính toán biên hạn chế tài nguyên. IEEE
Transactions on Mobile Computing, 22(2):
674–690, 2023. doi: 10.1109/TMC.2021.3096846.

Bing Luo, Wenli Xiao, Shiqiang Wang, Jianwei Huang,
và Leandros Tassiulas. Giải quyết tính không đồng nhất hệ thống và thống kê
cho học liên hợp với lấy mẫu khách hàng thích ứng. Trong IEEE INFOCOM 2022-IEEE conference
on computer communications, trang 1739–1748. IEEE,
2022.

Horia Mania, Xinghao Pan, Dimitris Papailiopoulos, Ben-
jamin Recht, Kannan Ramchandran, và Michael I. Jordan. Phân tích iterate bị nhiễu loạn cho tối ưu hóa ngẫu nhiên
bất đồng bộ. SIAM Journal on Optimization, 27(4):
2202–2229, 2017. doi: 10.1137/16M1057000. URL
https://doi.org/10.1137/16M1057000.

Yishay Mansour, Mehryar Mohri, Jae Ro, và
Ananda Theertha Suresh. Ba phương pháp
cá nhân hóa với ứng dụng cho học liên hợp.
arXiv preprint arXiv:2002.10619, 2020.

Brendan McMahan, Eider Moore, Daniel Ramage, Seth
Hampson, và Blaise Aguera y Arcas. Học
hiệu quả giao tiếp của mạng sâu từ dữ liệu phi tập trung.
Trong Artificial intelligence and statistics, trang 1273–
1282. PMLR, 2017.

--- TRANG 10 ---
John Nguyen, Kshitiz Malik, Hongyuan Zhan, Ashkan
Yousefpour, Mike Rabbat, Mani Malek, và Dzmitry
Huba. Học liên hợp với tổng hợp bất đồng bộ có bộ đệm.
Trong Gustau Camps-Valls, Francisco J. R.
Ruiz, và Isabel Valera, editors, Tuyển tập Hội nghị
Quốc tế lần thứ 25 về Trí tuệ Nhân tạo và Thống
kê, tập 151 của Tuyển tập Nghiên cứu Học Máy, trang 3581–3607. PMLR, 28–30 Tháng 3
2022. URL https://proceedings.mlr.press/
v151/nguyen22b.html.

Takayuki Nishio và Ryo Yonetani. Lựa chọn khách hàng cho học
liên hợp với tài nguyên không đồng nhất trong biên di động.
Trong ICC 2019-2019 IEEE international conference
on communications (ICC), trang 1–7. IEEE, 2019.

Wenqi Shi, Sheng Zhou, Zhisheng Niu, Miao Jiang, và
Lu Geng. Lập lịch thiết bị và phân bổ tài nguyên chung
cho học liên hợp không dây bị ràng buộc độ trễ. IEEE
Transactions on Wireless Communications, 20(1):453–
467, 2021. doi: 10.1109/TWC.2020.3025446.

Marie Siew, Shoba Arunasalam, Yichen Ruan, Ziwei Zhu,
Lili Su, Stratis Ioannidis, Edmund Yeh, và Carlee Joe-
Wong. Huấn luyện công bằng nhiều mô hình học liên hợp
trên các thiết bị mạng hạn chế tài nguyên. Trong Proceedings
of the 22nd International Conference on Information Processing in Sensor Networks, trang 330–331, 2023.

Alysa Ziying Tan, Han Yu, Lizhen Cui, và Qiang Yang.
Hướng tới học liên hợp cá nhân hóa. IEEE Transactions on Neural Networks and Learning Systems, 2022.

Hao Wang, Zakhary Kaplan, Di Niu, và Baochun Li. Tối
ưu hóa học liên hợp trên dữ liệu non-iid với học
tăng cường. Trong IEEE INFOCOM 2020 - IEEE Conference on Computer Communications, trang 1698–1707,
2020a. doi: 10.1109/INFOCOM41043.2020.9155494.

Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, và
H. Vincent Poor. Giải quyết vấn đề không nhất quán mục tiêu
trong tối ưu hóa liên hợp không đồng nhất, 2020b.

Zhongyu Wang, Zhaoyang Zhang, Yuqing Tian, Qianqian
Yang, Hangguan Shan, Wei Wang, và Tony QS Quek.
Học liên hợp bất đồng bộ qua mạng
truyền thông không dây. IEEE Transactions on Wireless Communications, 21(9):6961–6978, 2022.

Han Xiao, Kashif Rasul, và Roland Vollgraf. Fashion-
mnist: một bộ dữ liệu hình ảnh mới để đánh giá các thuật toán học máy. arXiv preprint arXiv:1708.07747,
2017.

Cong Xie, Sanmi Koyejo, và Indranil Gupta. Tối
ưu hóa liên hợp bất đồng bộ. CoRR, abs/1903.03934,
2019. URL http://arxiv.org/abs/1903.
03934.

Chenhao Xu, Youyang Qu, Yong Xiang, và Longxiang
Gao. Học liên hợp bất đồng bộ trên các thiết bị không đồng nhất: Một khảo sát. Computer Science Review, 50:100595,
2023.

Yongtao Yao, Nejib Ammar, và Weisong Shi. Flow: Một
khung học liên hợp đa mô hình có thể mở rộng trên bánh xe. Trong Hội nghị Quốc tế IEEE 2023 về
Mobility, Operations, Services and Technologies (MOST), trang 11–22. IEEE, 2023.

Jieling Yu, Ruiting Zhou, Chen Chen, Bo Li, và Fang
Dong. Asfl: Học liên hợp bán bất đồng bộ thích ứng
để cân bằng độ chính xác mô hình và tổng độ trễ trong
mạng biên di động. Trong Proceedings of the 52nd International Conference on Parallel Processing, ICPP '23,
trang 443–451, New York, NY, USA, 2023a. Association for Computing Machinery. ISBN 9798400708435.
doi: 10.1145/3605573.3605582. URL https://doi.
org/10.1145/3605573.3605582.

Xiaofan Yu, Lucy Cherkasova, Harsh Vardhan, Quanling
Zhao, Emily Ekaireb, Xiyuan Zhang, Arya Mazumdar,
và Tajana Rosing. Async-hfl: Học liên hợp bất đồng bộ
hiệu quả và mạnh mẽ trong mạng iot phân cấp.
Trong Proceedings of the 8th ACM/IEEE Conference on Internet of Things Design and Implementation, IoTDI '23,
trang 236–248, New York, NY, USA, 2023b. Association for Computing Machinery. ISBN 9798400700378.
doi: 10.1145/3576842.3582377. URL https://doi.
org/10.1145/3576842.3582377.

Mikhail Yurochkin, Mayank Agarwal, Soumya Ghosh,
Kristjan Greenewald, Nghia Hoang, và Yasaman Khaza-
eni. Học liên hợp phi tham số Bayesian của mạng thần kinh. Trong International conference on machine learning, trang 7252–7261. PMLR, 2019.

Hossein Zakerinia, Shayan Talaei, Giorgi Nadiradze, và
Dan Alistarh. Học liên hợp hiệu quả giao tiếp
với tính không đồng nhất dữ liệu và khách hàng, 2023.

Chendi Zhou, Ji Liu, Juncheng Jia, Jingbo Zhou, Yang Zhou,
Huaiyu Dai, và Dejing Dou. Lập lịch thiết bị hiệu quả
với học liên hợp đa công việc. Trong Proceedings of the
AAAI Conference on Artificial Intelligence, tập 36,
trang 9971–9979, 2022.

--- TRANG 11 ---
FedAST: Huấn luyện Đồng thời Bất đồng bộ Liên hợp
(Phụ lục)
Baris Askin1Pranay Sharma1Carlee Joe-Wong1Gauri Joshi1
1Đại học Carnegie Mellon, Pittsburgh, Pennsylvania, Hoa Kỳ

A ĐIỀU CHỈNH SỐ LƯỢNG YÊU CẦU HOẠT ĐỘNG VÀ REALLOC

Trước khi thiết kế thuật toán Realloc cho tùy chọn phân bổ khách hàng động (D), chúng tôi thực hiện các thí nghiệm xác thực ban đầu
với tùy chọn tĩnh (S), trong đó việc phân bổ các yêu cầu huấn luyện cục bộ hoạt động giữa các khách hàng và kích thước bộ đệm vẫn
không thay đổi trong suốt quá trình huấn luyện. Lưu ý rằng với tùy chọn tĩnh, Thuật toán 3 chỉ thực thi Dòng 6 của nó và luôn trả về
các giá trị của vòng trước đó. Chúng tôi quan sát thực nghiệm rằng việc đặt tỷ lệ số lượng yêu cầu huấn luyện cục bộ hoạt động
với kích thước bộ đệm cố định và dưới 37 hoạt động tốt. Tham khảo Phần C.5 cho các thí nghiệm xác thực. Sau đó, kết hợp
tỷ lệ này (Rm ≈ 37bm) trong ranh giới hội tụ trong Phương trình 4 của Định lý 1, chúng tôi phát hiện ra rằng số hạng chiếm ưu thế
(loại trừ các hằng số smoothness) trở thành: O(ηs
mηc
mτm
Rm σ2
g,m). Hơn nữa, với số lượng khách hàng có sẵn hạn chế, chúng ta
không thể tăng tổng số yêu cầu huấn luyện cục bộ hoạt động tùy ý mà không tăng staleness. Do đó, chúng tôi
sử dụng ∑M
m=1Rm = R trong đó R là hằng số về số lượng yêu cầu huấn luyện hoạt động chúng ta gán tổng cộng tùy thuộc vào
số lượng khách hàng có sẵn trong thiết lập. Vì mục tiêu của huấn luyện đồng thời liên hợp là tối thiểu hóa các hàm
mục tiêu của tất cả các nhiệm vụ đồng thời, chúng tôi đề xuất điều chỉnh {Rm}M
m=1 bằng cách giải quyết,

min
{Rm}M
m=1 ∑M
m=1 ηs
mηc
mτm
Rm σ2
g,m subject to ∑M
m=1Rm = R. (7)

Giải pháp của vấn đề tối thiểu hóa trong (7) đề xuất phân bổ các yêu cầu huấn luyện cục bộ, {Rm}M
m=1, theo tỷ lệ
σg,m√ηsmηcmτm cho mỗi mô hình m. Sử dụng phương pháp này, Thuật toán 3 điều chỉnh phân bổ tài nguyên. Hơn nữa, vì phương sai cập nhật
giữa các khách hàng có thể thay đổi theo thời gian trong quá trình huấn luyện, chúng tôi sử dụng phân bổ lại tài nguyên thích ứng định kỳ
giữa các mô hình (Dòng 1 trong Thuật toán 3). Do đó, chúng tôi sử dụng chỉ số vòng để biểu thị số lượng yêu cầu huấn luyện hoạt động
và kích thước bộ đệm thay đổi.

Vì chúng ta không có quyền truy cập vào mức độ không đồng nhất dữ liệu thực, chúng ta cần ước tính nó (Dòng 2 trong Thuật toán 3). Khi FedAST được
chạy với option = D (tùy chọn phân bổ khách hàng động), máy chủ giữ V cập nhật mới nhất của mỗi mô hình. Điều này yêu cầu
không gian bộ nhớ không đổi và nhỏ được giữ trong máy chủ. Để trình bày cách ước tính phương sai (EstimateVariances())
hoạt động, giả sử rằng {∆m,1, ∆m,2, . . . , ∆m,V}M
m=1 là các tập hợp cập nhật mới nhất nhận được của các nhiệm vụ m ∈ [M] trong đó mỗi
∆m,k cho k ∈ [V] là đầu ra của huấn luyện cục bộ thứ k mới nhất (Thuật toán 1). Vì đầu ra của bất kỳ huấn luyện cục bộ nào là trung bình của tất cả
gradient ngẫu nhiên được tính toán trong quá trình huấn luyện cục bộ đó, chúng tôi sử dụng những đầu ra đó như xấp xỉ của các gradient được tính toán trên
dữ liệu cục bộ của khách hàng. Thuật toán 4 mô tả EstimateVariances(). Đầu tiên nó tính toán trung bình của các cập nhật mới nhất
cho mỗi nhiệm vụ, {∆m}M
m=1 = {1
V × ∑V
i=1∆m,i}M
m=1. Sau đó, EstimateVariances() trả về phương sai mẫu nhân
với các số hạng khác (ηs
mηc
mτm) được đề xuất bởi (7) và được chuẩn hóa bởi chuẩn cập nhật trung bình (để ngăn các mô hình lớn hoặc mô hình
với trọng số lớn về bản chất không thống trị những mô hình khác), {ˆσ2
g,m}M
m=1 = {ηs
mηc
mτm
V × ∑V
i=1∥∆m,i − ∆m∥2/∥∆m∥2}M
m=1.
Sau đó, thuật toán Realloc phân bổ số lượng yêu cầu huấn luyện hoạt động theo tỷ lệ với căn bậc hai của các giá trị này
(Thuật toán 3, Dòng 3).

Phương pháp này hợp lý cả về mặt lý thuyết và trực quan. Dựa trên các quan sát thực nghiệm của chúng tôi về mối quan hệ
giữa số lượng yêu cầu huấn luyện hoạt động và kích thước bộ đệm, việc tăng số lượng yêu cầu huấn luyện cục bộ hoạt động
đòi hỏi phải tăng kích thước bộ đệm. Hơn nữa, bộ đệm lớn hơn chứng tỏ có lợi trong việc giảm phương sai giữa các cập nhật,

--- TRANG 12 ---
Thuật toán 4 EstimateVariances()
Require: Tập hợp V cập nhật mới nhất {∆m,1, ∆m,2, . . . , ∆m,V}M
m=1, tỷ lệ học phía máy chủ {ηs
m}M
m=1, tỷ lệ học phía khách hàng {ηc
m}M
m=1, và số bước SGD cục bộ của tất cả các mô hình {τm}M
m=1.
1: {∆m}M
m=1 ← {1
V × ∑V
i=1∆m,i}M
m=1 ▷ Tính toán trung bình của các cập nhật mới nhất
2: {σ̃2
g,m}M
m=1 ← {1
V × ∑V
i=1∥∆m,i − ∆m∥2/∥∆m∥2}M
m=1 ▷ Tính toán phương sai mẫu chuẩn hóa
3: {ˆσ2
g,m}M
m=1 ← {ηc
mηs
mτmσ̃2
g,m}M
m=1 ▷ Nhân với các hằng số khác được đề xuất bởi đảm bảo hội tụ (7)
4: Return {ˆσ2
g,m}

các cập nhật được đệm được tính trung bình trong quá trình tổng hợp. Realloc nhằm mục đích phân bổ nhiều khách hàng hơn và cung cấp kích thước bộ đệm lớn hơn
cho các nhiệm vụ có tính không đồng nhất cao hơn. Chúng tôi chọn số lượng cập nhật mới nhất được lưu trữ V = 8 và chu kỳ của số
tổng cập nhật từ tất cả khách hàng để kích hoạt phân bổ lại trong subroutine Realloc cperiod = 0.75 × M × ∑M
m=1Rm trong
thí nghiệm của chúng tôi. Lợi ích của phân bổ động (option = D) so với phân bổ tài nguyên tĩnh và đồng nhất (option = S) được
chứng minh khi các nhiệm vụ/mô hình không đồng nhất, như được hiển thị trong Hình 21-26.

B SO SÁNH LÝ THUYẾT CỦA FedAST VỚI CÁC BASELINE

Chúng tôi cũng so sánh FedAST với các phương pháp FL mô hình đơn. [Nguyen et al., 2022] là thuật toán tương tự nhất với FedAST
(với mô hình đơn). Tuy nhiên, ngay cả đối với trường hợp nhiệm vụ đơn, FedAST khác biệt bằng cách sử dụng phân công khách hàng đồng nhất
để đảm bảo sự tham gia không thiên vị của khách hàng bất kể tốc độ phần cứng của họ. Điều này cho phép chúng tôi nới lỏng các giả định
để chứng minh đảm bảo hội tụ. [Nguyen et al., 2022] dựa vào giả định mạnh rằng máy chủ nhận cập nhật
từ khách hàng một cách ngẫu nhiên đồng nhất và chuẩn của gradient bị chặn. Hơn nữa, so với [Koloskova et al.,
2022], phân tích của chúng tôi tổng quát hơn vì FedAST sử dụng nhiều bước SGD trong huấn luyện cục bộ và bộ đệm. Một số công trình FL bất đồng bộ mô hình đơn gần đây khác, [Zakerinia et al., 2023] và [Leconte et al., 2023], không có phần mở rộng huấn luyện liên hợp đồng thời
đơn giản và hiệu quả cho nhiều mô hình.

[Chang et al., 2023] là một phương pháp học liên hợp đồng thời bất đồng bộ khác. Tuy nhiên, [Chang et al., 2023] thực sự
không hội tụ đến một điểm cố định tiệm cận trừ khi dữ liệu đồng nhất, và các giả định của họ bao gồm Chuẩn Gradient Bị chặn và Tính Lồi Yếu.

Bảng 2: So sánh đảm bảo hội tụ của FedAST với Nguyen et al. [2022] (thuật toán FL bất đồng bộ có bộ đệm nhiệm vụ đơn) và Chang et al. [2023] (thuật toán FST bất đồng bộ). T: #vòng toàn cục, τ: #bước cục bộ, b: kích thước bộ đệm.

Thuật toán | Giả định không tiêu chuẩn | Hội tụ
Nguyen et al. [2022] | Gradient Bị chặn & Nhận Cập nhật Đồng nhất | O(√τ/(Tb))(a)
Chang et al. [2023] | Gradient Bị chặn & Tính Lồi Yếu | Không hội tụ
FedAST | — | O(√τ/(Tb))

(a) Mặc dù đảm bảo hội tụ trong bài báo [Nguyen et al., 2022] đã xuất bản có vẻ có tỷ lệ tốt hơn, chúng tôi đã chỉ ra một lỗi
trong chứng minh của họ. Ở đây, chúng tôi sử dụng phiên bản đã sửa mà chúng tôi nhận được qua giao tiếp riêng.

C CHI TIẾT THIẾT LẬP THỰC NGHIỆM

Trong nghiên cứu của chúng tôi, chúng tôi khám phá một môi trường học liên hợp (FL) đồng thời cho nhiều mô hình. Chúng tôi trình bày chi tiết
các thí nghiệm của chúng tôi trong phần này.

C.1 MÔI TRƯỜNG MÔ PHỎNG

Chúng tôi mô phỏng quá trình huấn luyện với PyTorch trên các đơn vị xử lý đồ họa (GPU) NVIDIA GeForce GTX TITAN X của
cụm nội bộ của chúng tôi. Chúng tôi xây dựng mã của mình dựa trên các mã công khai của [Wang et al., 2020a, Yu et al., 2023b].

C.2 TỔNG QUAN THIẾT LẬP

Chúng tôi xem xét việc huấn luyện liên hợp M mô hình đồng thời sử dụng N khách hàng. N là 1000 trong tất cả các thí nghiệm và M,
được chỉ định rõ ràng cho mỗi thí nghiệm, thay đổi từ 2−6.

C.3 NHIỆM VỤ VÀ MÔ HÌNH

Chúng tôi sử dụng 5 nhiệm vụ khác nhau trong các thí nghiệm: các nhiệm vụ phân loại hình ảnh MNIST [Deng, 2012], Fashion-MNIST [Xiao et al., 2017], CIFAR-10
và CIFAR-100 [Krizhevsky et al., 2009], và nhiệm vụ dự đoán ký tự tiếp theo Shakespeare [Caldas et al., 2019]. Chúng tôi sử dụng mạng perceptron đa lớp cho MNIST như trong [Acar et al., 2021], mạng tích chập cho Fashion-
MNIST như trong [Lecun et al., 1998] và cho CIFAR-10 như trong [Acar et al., 2021], mô hình ResNet-18 cho CIFAR-100 như trong Acar
et al. [2021], và mạng bộ nhớ ngắn hạn dài cho Shakespeare như trong [Yu et al., 2023b].

C.4 BỘ DỮ LIỆU VÀ PHÂN PHỐI DỮ LIỆU

Chúng tôi xem xét tính không đồng nhất dữ liệu giữa các khách hàng trong các khung FL. Chúng tôi tải xuống các bộ dữ liệu MNIST, Fashion-MNIST, và
CIFAR-10/100 từ các phương thức thư viện tích hợp sẵn của PyTorch. Việc chia train và test được cung cấp bởi thư viện được sử dụng
mà không có bất kỳ sửa đổi nào. Để mô phỏng phân phối dữ liệu không đồng nhất giữa các khách hàng, chúng tôi sử dụng phân phối Dirichlet với
α = 0.1 theo phương pháp được đề xuất trong Yurochkin et al. [2019]. Chúng tôi đảm bảo rằng mỗi khách hàng có 300 điểm dữ liệu cho
các nhiệm vụ MNIST, Fashion-MNIST, và CIFAR-10/100 bằng cách lặp lại tập train nếu cần thiết. Chúng tôi thu thập và tiền xử lý
bộ dữ liệu Shakespeare như được mô tả trong [Caldas et al., 2019]. Bộ dữ liệu này có phân phối không đồng nhất vốn có
giữa các khách hàng vì mỗi khách hàng tương ứng với một vai độc đáo từ các vở kịch của Shakespeare.

C.5 CÁC THAM SỐ THIẾT KẾ

Trong phần này, chúng tôi giải thích cách chúng tôi chọn các tham số thiết kế.

Kích thước bộ dữ liệu khách hàng, kích thước batch, và số bước cục bộ. Trong khi phân phối các bộ dữ liệu CIFAR-10/100, MNIST, và Fashion-
MNIST giữa các khách hàng, mỗi khách hàng được phân bổ 300 điểm dữ liệu từ mỗi bộ dữ liệu. Tuy nhiên, bộ dữ liệu Shakespeare
duy trì phân phối ban đầu của các điểm dữ liệu giữa các vai, vì vậy khách hàng có số lượng mẫu dữ liệu khác nhau trong
nhiệm vụ Shakespeare. Đối với các nhiệm vụ CIFAR-10/100, MNIST, và Fashion-MNIST, chúng tôi đặt kích thước batch thành 32 trong khi chúng tôi sử dụng
kích thước batch là 64 cho nhiệm vụ Shakespeare. Chúng tôi cố định số bước cục bộ trong huấn luyện cục bộ (tham số τm trong Thuật toán 1 trong
văn bản chính) của khách hàng ở 27 cho tất cả các nhiệm vụ. Điều này tạo ra 3 epoch cho các nhiệm vụ CIFAR-10/100, MNIST, và Fashion-MNIST. Vì
số lượng điểm dữ liệu thay đổi giữa các khách hàng cho bộ dữ liệu Shakespeare, không có số epoch cố định.

Kích thước bộ đệm. Bộ đệm trong FedAST rất quan trọng để giảm thiểu tác động tiêu cực của các cập nhật rất cũ, như được thảo luận rộng rãi
trong văn bản chính. Staleness của các cập nhật bị ảnh hưởng bởi số lượng yêu cầu huấn luyện cục bộ hoạt động, ký hiệu
là Rm, và kích thước bộ đệm, bm, liên quan đến tất cả mô hình m ∈ [M]. Khi FedAST được chạy với tùy chọn tĩnh (S), những
số này được giữ không đổi trong quá trình huấn luyện, nhưng chúng có thể thay đổi (lúc này chúng tôi ký hiệu R(tm)
m và b(tm)
m) khi chúng tôi sử dụng
tùy chọn phân bổ khách hàng động (D). Số lượng yêu cầu huấn luyện cục bộ đồng thời cao hơn dẫn đến staleness cao hơn
vì nó tăng tần suất cập nhật của mô hình toàn cục tại máy chủ. Mặt khác, kích thước bộ đệm có mối quan hệ nghịch đảo với
staleness, do tác động ngược lại của nó đối với tần suất tổng hợp. Dựa trên các quan sát thực nghiệm của chúng tôi, việc chọn
số lượng yêu cầu huấn luyện hoạt động và kích thước bộ đệm của mô hình m sao cho tỷ lệ của chúng cố định và dưới 37, (Rm/bm ≲ 37
hoặc R(tm)
m/btm
m ≲ 37), hoạt động tốt. Việc chọn kích thước bộ đệm của FedAST dựa trên quan sát này tránh những
tác động có hại của các cập nhật cũ trong khi hưởng lợi từ huấn luyện nhanh nhờ thuật toán bất đồng bộ. Chúng tôi hiển thị hai kết quả thực nghiệm
trong Hình 8 và 9. Trong Hình 8, chúng tôi huấn luyện một mô hình Fashion-MNIST và một mô hình CIFAR-10 đồng thời bằng cách gán
175 yêu cầu huấn luyện hoạt động cho mỗi nhiệm vụ và quan sát rằng kích thước bộ đệm 5 tạo ra sự cân bằng giữa độ chính xác kiểm tra cuối cùng cao và huấn luyện nhanh để đạt độ chính xác mục tiêu cho cả hai nhiệm vụ. Trong Hình 9, chúng tôi lặp lại thí nghiệm tương tự với các nhiệm vụ MNIST và
CIFAR-10 bằng cách gán 105 yêu cầu huấn luyện hoạt động cho mỗi nhiệm vụ. Lần này, chúng tôi quan sát rằng kích thước bộ đệm 3 hoạt động
tốt nhất cho cả hai nhiệm vụ. Những kết quả thực nghiệm này hỗ trợ việc chọn kích thước bộ đệm của chúng tôi.

--- TRANG 13 ---
[Biểu đồ hiệu suất qua các kích thước bộ đệm khác nhau]

Hình 8: Độ chính xác kiểm tra cuối cùng và thời gian cần thiết để đạt độ chính xác mục tiêu (trong Bảng 1) cho huấn luyện đồng thời (sử dụng
FedAST với tùy chọn tĩnh) của một mô hình Fashion-MNIST và một mô hình CIFAR-10 với các kích thước bộ đệm khác nhau. Chúng tôi gán
cùng số lượng yêu cầu huấn luyện cục bộ (175) cho mỗi nhiệm vụ.

[Biểu đồ hiệu suất qua các kích thước bộ đệm khác nhau]

Hình 9: Độ chính xác kiểm tra cuối cùng và thời gian cần thiết để đạt độ chính xác mục tiêu (trong Bảng 1) cho huấn luyện đồng thời (sử dụng
FedAST với tùy chọn tĩnh) của một mô hình MNIST và một mô hình CIFAR-10 với các kích thước bộ đệm khác nhau. Chúng tôi gán
cùng số lượng yêu cầu huấn luyện cục bộ (105) cho mỗi nhiệm vụ.

Tỷ lệ học và weight decay. Chúng tôi tìm kiếm các siêu tham số tỷ lệ học và weight decay tốt nhất xem xét
tốc độ huấn luyện và mức độ chính xác cuối cùng. Chúng tôi tìm kiếm tỷ lệ học phía khách hàng trong khoảng [1×10−3, 1×10],
tỷ lệ học phía máy chủ trong [3×10−2, 3], và weight decay trong [1×10−7, 1×10−2]. Chúng tôi quan sát rằng tỷ lệ học phía khách hàng
là 6×10−2 và 7 với weight decay là 3×10−4 và 7×10−5 hoạt động tốt nhất tương ứng cho các nhiệm vụ Fashion-MNIST
và Shakespeare cho tất cả các phương pháp. Đối với nhiệm vụ CIFAR-10, tỷ lệ học phía khách hàng là 1×10−1 với weight decay
là 7×10−4 và 3×10−4 hoạt động tốt nhất cho các phương pháp bất đồng bộ và đồng bộ, tương ứng. Đối với MNIST, chúng tôi sử dụng tỷ lệ học phía khách hàng
là 1×10−1 và 2×10−1 cho các phương pháp bất đồng bộ và đồng bộ, tương ứng, với weight decay là
3×10−4. Đối với tỷ lệ học phía máy chủ, chúng tôi quan sát rằng 1 cho các phương pháp đồng bộ (Sync-ST, Sync-Bayes-ST, và
Sync-UCB-ST), 0.1 cho FedAST, và 0.038 cho FedAST-NoBuffer hoạt động tốt cho tất cả các nhiệm vụ.

C.6 MÔ HÌNH HÓA THỜI GIAN HUẤN LUYỆN, KÍCH THƯỚC MÔ HÌNH, VÀ TÍNH KHÔNG ĐỒNG NHẤT TỐC ĐỘ KHÁCH HÀNG

Trong các thí nghiệm của chúng tôi, theo [Lee et al., 2018, Shi et al., 2021, Zhou et al., 2022, Dutta et al., 2021], chúng tôi sử dụng
các biến ngẫu nhiên shifted-exponential để mô hình hóa thời gian giữa khi máy chủ gửi yêu cầu huấn luyện cục bộ đến khách hàng,
và khi nó nhận được cập nhật của huấn luyện cục bộ. Thành phần exponential của phân phối phản ánh tính chất
ngẫu nhiên của tốc độ thiết bị, trong khi thành phần shift tính đến các độ trễ không thể tránh khỏi như các hoạt động I/O đĩa.
Bất cứ khi nào khách hàng i thực hiện huấn luyện cục bộ cho nhiệm vụ m, chúng tôi rút một số ngẫu nhiên từ phân phối với hàm
phân phối tích lũy (CDF) là,

P(X ≤ x) = {
1 − exp{−(x−βi,m)/(2βi,m)}, x ≥ βi,m
0, otherwise,

trong đó βi,m phụ thuộc vào tốc độ của khách hàng i và kích thước của mô hình liên quan đến nhiệm vụ m. Sau đó, chúng tôi nhân số ngẫu nhiên này
với số bước cục bộ để tính thời gian mô phỏng giữa khi máy chủ yêu cầu huấn luyện cục bộ,
và khi nó nhận lại cập nhật.

Chúng tôi định lượng tác động của kích thước mô hình dựa trên thời gian trung bình cần thiết để tính toán một gradient ngẫu nhiên cho mỗi
mô hình trên các GPU của cụm nội bộ của chúng tôi. Qua các phép đo của chúng tôi, chúng tôi đặt,

βi,MNIST/0.148 = βi,Fashion-MNIST/0.240 = βi,CIFAR-10/0.228 = βi,Shakespeare/0.555 = βi,CIFAR-100/2.071, ∀i ∈ [N].

Trong các thí nghiệm của chúng tôi, chúng tôi cũng tính đến tính không đồng nhất trong tốc độ của các thiết bị khách hàng. Chúng tôi phân loại khách hàng
thành ba nhóm tốc độ: chậm (%25), tốc độ bình thường (%50), và nhanh (%25). Tỷ lệ tốc độ cho các danh mục này tỷ lệ nghịch
với 1.3, 1, và 0.7, sao cho,

βslow client,m/1.3 = βnormal-speed client,m/1 = βfast client,m/0.7, ∀m ∈ [M].

D CÁC THỰC NGHIỆM BỔ SUNG

Trong phần này, chúng tôi trình bày các thí nghiệm bổ sung.

D.1 ĐIỀU CHỈNH THAM SỐ k CỦA KỸ THUẬT GIẢM THIỂU STRAGGLER ĐƯỢC SỬ DỤNG CHO
CÁC PHƯƠNG PHÁP ĐỒNG BỘ (CHẤP NHẬN CHỈ k CẬP NHẬT ĐẦU TIÊN)

Trong các thí nghiệm của chúng tôi, để giảm thiểu hiệu ứng straggler cao, máy chủ trong các phương pháp đồng bộ (Sync-ST, Sync-Bayes-ST,
và Sync-UCB-ST) chỉ tổng hợp k cập nhật khách hàng đầu tiên cho mỗi nhiệm vụ và loại bỏ phần còn lại, theo [Bonawitz
et al., 2019]. Để điều chỉnh tham số k, chúng tôi chạy các thí nghiệm xác thực với Sync-ST trên các nhiệm vụ CIFAR-10, MNIST, và
Fashion-MNIST đơn lẻ và đánh giá hiệu suất huấn luyện đối với thời gian mô phỏng và số vòng toàn cục.
k lớn hơn dẫn đến thời gian mô phỏng dài hơn mỗi vòng vì chúng ta đợi nhiều khách hàng hơn. Mặt khác, phương sai trong
các cập nhật được tổng hợp trên mỗi vòng trở nên nhỏ hơn vì chúng ta tính trung bình nhiều cập nhật hơn. Do đó, độ chính xác mục tiêu được đạt
nhanh hơn về số vòng toàn cục. Chúng tôi cũng quan sát rằng giữ k quá nhỏ dẫn đến độ chính xác cuối cùng thấp hơn.
Điều hướng những đánh đổi này, chúng tôi thấy rằng k = 30 tạo ra sự cân bằng hiệu quả.

[Biểu đồ hiệu suất Sync-ST với k khác nhau trên CIFAR-10]

Hình 10: Hiệu suất của Sync-ST với k khác nhau trong nhiệm vụ CIFAR-10. Điểm được chọn được hiển thị bằng ngôi sao đỏ.

[Biểu đồ hiệu suất Sync-ST với k khác nhau trên Fashion-MNIST]

Hình 11: Hiệu suất của Sync-ST với k khác nhau trong nhiệm vụ Fashion-MNIST. Điểm được chọn được hiển thị bằng ngôi sao đỏ.

--- TRANG 14 ---
[Biểu đồ hiệu suất Sync-ST với k khác nhau trên MNIST]

Hình 12: Hiệu suất của Sync-ST với k khác nhau trong nhiệm vụ MNIST. Điểm được chọn được hiển thị bằng ngôi sao đỏ.

D.2 BIỂU ĐỒ MẤT MÁT KIỂM TRA CỦA HÌNH 3 VÀ 4 TRONG VĂN BẢN CHÍNH

Chúng tôi minh họa các biểu đồ mất mát kiểm tra của các thí nghiệm trong Hình 3 và 4 trong văn bản chính.

[Biểu đồ mất mát kiểm tra cuối cùng]

Hình 13: Giá trị mất mát cuối cùng trung bình của FedAST (xanh dương), FedAST-NoBuffer (xanh ô liu) và huấn luyện tập trung
(tím) với tỷ lệ khách hàng hoạt động khác nhau, khi huấn luyện 3 mô hình giống hệt nhau. Hình bên trái là cho bộ dữ liệu CIFAR-10, trong khi
hình bên phải là cho bộ dữ liệu Fashion-MNIST. Với số lượng khách hàng hoạt động cao hơn, nhờ có bộ đệm, FedAST duy trì
hiệu suất của nó trong khi FedAST-NoBuffer trở nên tệ hơn.

[Biểu đồ mất mát kiểm tra]

Hình 14: Giá trị mất mát kiểm tra trung bình của FedAST và FedAST-NoBuffer, khi huấn luyện đồng thời một mô hình cho
CIFAR-10 và một cho Fashion-MNIST. FedAST đạt được mức mất mát thấp hơn và ổn định hơn.

D.3 ĐƯỜNG CONG HUẤN LUYỆN CỦA CÁC THỰC NGHIỆM ĐỒNG NHẤT

Trong Hình 15, chúng tôi cung cấp các đường cong huấn luyện trung bình của thí nghiệm nhiệm vụ đồng nhất trong Hình 5.

--- TRANG 15 ---
[Biểu đồ đường cong huấn luyện cho FedAST và Sync-ST]

Hình 15: Đường cong huấn luyện của FedAST và Sync-ST trên 2/4/6 nhiệm vụ với các bộ dữ liệu CIFAR-10, Fashion-MNIST, MNIST, và
Shakespeare. Lợi ích thời gian của FedAST so với Sync-ST để đạt độ chính xác mục tiêu được hiển thị trên các đường ngang màu. Các đường ngang đen chỉ ra mức độ chính xác mục tiêu, giống như những gì được nêu trong Bảng 1.

D.4 MỘT THỰC NGHIỆM BỔ SUNG VỚI MÔ HÌNH LỚN HƠN (RESNET-18) TRÊN CIFAR-100

Chúng tôi chạy thí nghiệm nhiệm vụ đồng nhất với mô hình lớn hơn, ResNet-18, như được triển khai bởi Acar et al. [2021] trên
bộ dữ liệu CIFAR-100, một bộ dữ liệu phân loại hình ảnh 100 lớp [Krizhevsky et al., 2009]. Chúng tôi sử dụng cùng thiết lập thí nghiệm
như những thí nghiệm khác ngoại trừ một số khác biệt được nêu rõ ở đây. Chúng tôi sử dụng phân phối Dirichlet với α = 1 để
mô phỏng tính không đồng nhất theo phương pháp được đề xuất trong Yurochkin et al. [2019]. Chúng tôi sử dụng tỷ lệ học phía khách hàng (ηs)
là 0.06 và số bước SGD cục bộ (τ) là 5 cho cả FedAST và Sync-ST. Chúng tôi trình bày kết quả thí nghiệm
trong Hình 16. Các thí nghiệm của chúng tôi cho thấy FedAST vượt trội so với baseline đồng bộ với mô hình ResNet-18 trên
bộ dữ liệu CIFAR-100 bằng cách cung cấp lợi ích thời gian 22.0%, 40.7%, và 56.3% cho 2, 4, và 6 mô hình được huấn luyện đồng thời
tương ứng.

[Biểu đồ kết quả thực nghiệm trên CIFAR-100]

Hình 16: Kết quả thực nghiệm về huấn luyện đồng thời các nhiệm vụ lặp lại với FedAST và Sync-ST trên CIFAR-100.

D.5 CÁC THỰC NGHIỆM VỚI CÁC MỨC ĐỘ CHÍNH XÁC MỤC TIÊU KHÁC NHAU

Để xem FedAST và đối thủ Sync-ST hoạt động như thế nào với độ chính xác mục tiêu khác nhau, chúng tôi thực hiện thí nghiệm trong
Hình 7 với mức độ chính xác mục tiêu cao hơn +3% và thấp hơn −10% như được trình bày trong Bảng 3. Chúng tôi quan sát rằng FedAST được đề xuất
giảm tổng thời gian huấn luyện 55.9% và 16.3%, tương ứng cho các mức độ chính xác mục tiêu cao hơn và thấp hơn.

--- TRANG 16 ---
Chúng tôi kết luận rằng lợi thế của FedAST so với Sync-ST tăng theo độ khó của nhiệm vụ (tức là, đạt độ chính xác cao hơn).

Bảng 3: Các mức độ chính xác mục tiêu khác nhau được sử dụng trong thí nghiệm để xác thực các phương pháp được đề xuất, với các mục tiêu độ chính xác thấp hơn và cao hơn.

Bộ dữ liệu | Độ chính xác Mục tiêu Thấp hơn | Độ chính xác Mục tiêu trong Văn bản Chính | Độ chính xác Mục tiêu Cao hơn
MNIST | 83% | 93% | 96%
Fashion-MNIST | 72% | 82% | 85%
CIFAR-10 | 53% | 63% | 66%
Shakespeare | 32% | 42% | 45%

[Biểu đồ đường cong huấn luyện với độ chính xác mục tiêu cao hơn]

Hình 17: Đường cong huấn luyện của một lần chạy Monte Carlo duy nhất trong thí nghiệm không đồng nhất với các mức độ chính xác mục tiêu cao hơn trong Bảng 3. Các đường dọc đứt nét hiển thị thời điểm khi các nhiệm vụ đạt độ chính xác mục tiêu. Thiết lập giống như thí nghiệm trong Hình 7.

[Biểu đồ thời gian hoàn thành với độ chính xác mục tiêu cao hơn]

Hình 18: Thời gian trung bình cần thiết để đạt độ chính xác mục tiêu và lợi ích thời gian của FedAST so với Sync-ST trong thí nghiệm không đồng nhất với các mức độ chính xác mục tiêu cao hơn trong Bảng 3. Thiết lập giống như thí nghiệm trong Hình 7.

[Biểu đồ đường cong huấn luyện với độ chính xác mục tiêu thấp hơn]

Hình 19: Đường cong huấn luyện của một lần chạy Monte Carlo duy nhất trong thí nghiệm không đồng nhất với các mức độ chính xác mục tiêu thấp hơn trong Bảng 3. Các đường dọc đứt nét hiển thị thời điểm khi các nhiệm vụ đạt độ chính xác mục tiêu. Thiết lập giống như thí nghiệm trong Hình 7.

[Biểu đồ thời gian hoàn thành với độ chính xác mục tiêu thấp hơn]

Hình 20: Thời gian trung bình cần thiết để đạt độ chính xác mục tiêu và lợi ích thời gian của FedAST so với Sync-ST trong thí nghiệm không đồng nhất với các mức độ chính xác mục tiêu thấp hơn trong Bảng 3. Thiết lập giống như thí nghiệm trong Hình 7.

D.6 HIỆU SUẤT CỦA FedAST KHÔNG CÓ PHÂN BỔ TÀI NGUYÊN TĨNH

Chúng tôi thực hiện các thí nghiệm nhiệm vụ không đồng nhất để xác thực lợi ích hiệu suất của phân bổ tài nguyên động (FedAST(D))
so với tùy chọn tĩnh (FedAST(S)) với phân bổ đồng nhất giữa các nhiệm vụ trong các thiết lập không đồng nhất. Đối với phân bổ tài nguyên đồng nhất,

--- TRANG 17 ---
chúng tôi phân bổ cùng số lượng yêu cầu huấn luyện hoạt động cho mỗi nhiệm vụ trong FedAST(S). Để hiển thị tính nhất quán của
kết quả, chúng tôi chạy thí nghiệm ở tất cả các mức độ chính xác mục tiêu trong Bảng 3. Chúng tôi trình bày kết quả trong Hình 22 (độ chính xác mục tiêu cao hơn), Hình 24 (độ chính xác mục tiêu trong văn bản chính), và Hình 26 (độ chính xác mục tiêu thấp hơn). Chúng tôi kết luận rằng
phân bổ khách hàng động của chúng tôi dựa trên ước tính phương sai của các cập nhật giảm tổng thời gian huấn luyện so với
phân bổ khách hàng tĩnh đồng nhất. Lợi thế của phân bổ tài nguyên động trở nên nổi bật hơn với các
nhiệm vụ khó hơn (tức là, mức độ chính xác mục tiêu cao hơn).

[Các biểu đồ so sánh FedAST(D) và FedAST(S) ở các mức độ chính xác khác nhau]

Hình 21-26: So sánh hiệu suất giữa phân bổ tài nguyên động (FedAST(D)) và phân bổ tài nguyên tĩnh (FedAST(S)) ở các mức độ chính xác mục tiêu khác nhau.

E CHỨNG MINH PHÂN TÍCH HỘI TỤ CỦA FedAST VỚI TÙY CHỌN TĨNH (S)

Trong phần này, chúng tôi trình bày các chứng minh của các khẳng định toán học được đưa ra trong bài báo. Đầu tiên, chúng tôi định nghĩa và giải thích các
ký hiệu được sử dụng trong phần này. Sau đó, chúng tôi giới thiệu các bổ đề trung gian được sử dụng trong chứng minh chính (Phần E.2). Tiếp theo, chúng tôi trình bày
các chứng minh của Định lý 1 và Hệ quả 1.1 (Phần E.3). Cuối cùng, chúng tôi chứng minh các bổ đề trung gian (Phần E.4).

--- TRANG 18 ---
[Tiếp tục các biểu đồ so sánh và phân tích...]

--- TRANG 19-35 ---
[Nội dung tiếp theo bao gồm các chứng minh toán học chi tiết, định nghĩa ký hiệu, bổ đề và định lý với các chứng minh đầy đủ. Do độ dài và tính chất kỹ thuật cao của nội dung toán học, tôi sẽ không dịch từng chi tiết mà chỉ tóm tắt các phần chính:]

E.1 KÝ HIỆU VÀ ĐỊNH NGHĨA
- Định nghĩa các ký hiệu toán học cho thuật toán FedAST
- Quy tắc cập nhật cục bộ và toàn cục
- Định nghĩa staleness và chuỗi ảo

E.2 CÁC BỔ ĐỀ TRUNG GIAN
- Bổ đề 1-6 cung cấp các ước lượng và ranh giới cần thiết cho chứng minh chính

E.3 CHỨNG MINH CÁC PHÁT BIỂU CHÍNH
- Chứng minh chi tiết Định lý 1 về hội tụ của FedAST
- Chứng minh Hệ quả 1.1 về tỷ lệ hội tụ

E.4 CHỨNG MINH CÁC BỔ ĐỀ TRUNG GIAN
- Chứng minh đầy đủ các Bổ đề 2-6

F HỘI TỤ CỦA FedAST VỚI PHÂN BỔ KHÁCH HÀNG ĐỘNG (TÙY CHỌN = D)
- Mở rộng phân tích cho trường hợp phân bổ động
- Định lý 2 và chứng minh tương ứng
- Các giả định bổ sung cần thiết cho trường hợp động

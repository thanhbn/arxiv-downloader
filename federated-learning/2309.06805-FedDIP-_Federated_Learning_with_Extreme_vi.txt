FedDIP: Học Liên Bang với Cắt Tỉa Động Cực Đoan và Chính Quy Hóa Tăng Dần

Qianyu Long∗, Christos Anagnostopoulos∗, Shameem Puthiya Parambath∗, và Daning Bi†
∗Khoa Khoa học Máy tính, Đại học Glasgow, Vương quốc Anh
2614994L@student.gla.ac.uk, {christos.anagnostopoulos, sham.puthiya }@glasgow.ac.uk
†Khoa Tài chính và Thống kê, Đại học Hunan, Trung Quốc
daningbi@hnu.edu.cn

Tóm tắt—Học Liên bang (FL) đã được áp dụng thành công cho việc huấn luyện và suy luận phân tán của các Mạng Nơ-ron Sâu (DNN) quy mô lớn. Tuy nhiên, DNN được đặc trưng bởi số lượng tham số cực kỳ lớn, do đó, gây ra những thách thức đáng kể trong việc trao đổi các tham số này giữa các nút phân tán và quản lý bộ nhớ. Mặc dù các phương pháp nén DNN gần đây (ví dụ: thưa hóa, cắt tỉa) giải quyết những thách thức như vậy, chúng không xem xét một cách toàn diện việc giảm trao đổi tham số được kiểm soát thích ứng trong khi duy trì mức độ chính xác cao. Do đó, chúng tôi đóng góp với một khung FL mới (được gọi là FedDIP), kết hợp (i) cắt tỉa mô hình động với phản hồi lỗi để loại bỏ trao đổi thông tin dư thừa, góp phần cải thiện hiệu suất đáng kể, với (ii) chính quy hóa tăng dần có thể đạt được độ thưa cực đoan của mô hình. Chúng tôi cung cấp phân tích hội tụ của FedDIP và báo cáo về đánh giá hiệu suất toàn diện và so sánh với các phương pháp hiện đại sử dụng bộ dữ liệu chuẩn và mô hình DNN. Kết quả của chúng tôi cho thấy FedDIP không chỉ kiểm soát độ thưa của mô hình mà còn đạt được hiệu suất tương tự hoặc tốt hơn so với các phương pháp cắt tỉa mô hình khác áp dụng chính quy hóa tăng dần trong quá trình huấn luyện mô hình phân tán. Mã nguồn có sẵn tại: https://github.com/EricLoong/feddip.

Từ khóa Chỉ mục—Học Liên bang, cắt tỉa động, thưa hóa cực đoan, chính quy hóa tăng dần.

I. GIỚI THIỆU

Học Liên bang (FL) [1] là một mô hình học phân tán phổ biến do khả năng giải quyết học tập quy mô lớn. FL đóng vai trò quan trọng trong phân tích dự đoán quy mô lớn bằng cách cho phép phân cấp khám phá tri thức. FL góp phần bảo vệ quyền riêng tư, khắc phục các vấn đề cơ bản về quản trị và quyền sở hữu dữ liệu [2]. Huấn luyện phân tán và triển khai các mô hình Học Máy (ML) quy mô lớn, tức là Mạng Nơ-ron Sâu (DNN), đặt ra những thách thức đáng kể do khối lượng dữ liệu huấn luyện khổng lồ, mô hình lớn và sự đa dạng trong phân phối dữ liệu.

Các nút tính toán phân tán, chủ yếu nằm ở rìa mạng càng gần nguồn dữ liệu càng tốt, hợp tác thiết kế các mô hình ML thay vì phụ thuộc vào việc thu thập tất cả dữ liệu đến một vị trí tập trung (trung tâm dữ liệu hoặc Cloud) để huấn luyện [3]. Mô hình tính toán này được gọi là Điện toán Biên, đã được áp dụng thành công cho nhiều ứng dụng mô hình hóa dự đoán, khai thác và phân tích khác nhau, ví dụ trong tài chính [4], chăm sóc sức khỏe [5] và mạng cảm biến không dây [6].

DNN được đặc trưng bởi số lượng tham số cực kỳ lớn. Ví dụ, Mạng Nơ-ron Tích chập (CNN) ResNet50 [7] và VGG16 [8] bao gồm 27 và 140 triệu tham số tương ứng, trong khi các mô hình AI tạo sinh như GPT-2 có hơn 1,5 tỷ tham số [9]. Rõ ràng, điều này tạo ra gánh nặng lớn cho các nút tính toán phân tán khi trao đổi tham số mô hình trong quá trình huấn luyện, điều chỉnh và suy luận.

Các phương pháp giảm kích thước mô hình (cắt tỉa), ví dụ [10], [11], [12] nhằm duy trì độ chính xác dự đoán trong khi giảm chi phí truyền thông bằng cách giảm số lượng tham số mô hình trao đổi giữa các nút. Tuy nhiên, hầu hết các phương pháp cắt tỉa tập trung vào nén gradient mô hình. Mặc dù chúng cho tỷ lệ nén cao, chúng không đạt được các mô hình nén đáng kể để trao đổi. Nhưng nói chung, các phương pháp có thể tạo ra các mô hình nén cùng với sự dư thừa đáng kể trong số lượng trọng số DNN bằng cách cắt tỉa trọng số một cách tinh vi được coi là phù hợp [13]. Ngược lại với nén gradient mô hình, nén trọng số mô hình giảm đáng kể kích thước mô hình bằng cách đặt hầu hết các trọng số về zero. Điều này mong muốn để loại bỏ sự dư thừa trong trao đổi mô hình trong quá trình trích xuất tri thức phân tán. Nhưng thường những mô hình như vậy dẫn đến suy giảm hiệu suất. Do đó, câu hỏi chúng tôi đang giải quyết là: Làm thế nào để hiệu quả giới thiệu các cơ chế cắt tỉa mô hình trong một thiết lập học phân cấp có khả năng đạt được tỷ lệ nén cực kỳ cao trong khi bảo tồn hiệu suất dự đoán tối ưu? Chúng tôi đóng góp một phương pháp hiệu quả dựa trên cắt tỉa động với phản hồi lỗi và chính quy hóa tăng dần, được gọi là FedDIP. Tính mới của FedDIP nằm ở nguyên tắc thích ứng cắt tỉa động theo cách phân cấp bằng cách đẩy các trọng số không quan trọng về zero (cắt tỉa cực đoan) trong khi duy trì độ chính xác cao thông qua chính quy hóa tăng dần. Theo hiểu biết tốt nhất của chúng tôi, FedDIP là phương pháp đầu tiên kết hợp chính quy hóa tăng dần và cắt tỉa động cực đoan trong FL.

Bài báo được tổ chức như sau: Phần II báo cáo về công trình liên quan và đóng góp của chúng tôi. Phần III cung cấp kiến thức cơ bản về FL và các phương pháp cắt tỉa mô hình. Phần IV chi tiết về khung FedDIP, trong khi Phần V báo cáo về các tính chất lý thuyết của FedDIP và phân tích hội tụ. Kết quả thí nghiệm của chúng tôi trong Phần VI cho thấy hiệu quả của FedDIP trong học phân tán. Phần VII kết luận bài báo với các hướng nghiên cứu tương lai.

II. CÔNG TRÌNH LIÊN QUAN & ĐÓNG GÓP

A. Thưa Hóa Gradient Mô Hình & Trọng Số Mô Hình

Việc chia sẻ trọng số mô hình tốn kém và dư thừa là một trở ngại đáng kể trong học phân tán [14]. Kích thước của các mô hình được trao đổi giữa các nút có thể được giảm bởi nén và thưa hóa. Công trình trong [11] áp dụng lựa chọn độ lớn trên gradient mô hình để tạo ra thưa hóa khi sử dụng Gradient Descent Ngẫu nhiên (SGD). Thay vì cập nhật dày đặc trọng số, [10] đề xuất một SGD phân tán giữ 1% gradient bằng cách so sánh giá trị độ lớn của chúng. Phương pháp trong [15] mở rộng huấn luyện SGD của DNN thông qua kiểm soát tỷ lệ cập nhật trọng số cho từng trọng số riêng lẻ. [16] phát triển mã hóa các vector dựa trên SGD đạt được giảm chi phí truyền thông. [17] đề xuất chiến lược SGD lấy trung bình lượng tử hóa định kỳ đạt được hiệu suất dự đoán mô hình tương tự trong khi kích thước gradient mô hình chia sẻ được giảm 95%. Trong [18], các tác giả lập luận rằng 99% gradient là dư thừa và giới thiệu một phương pháp nén gradient sâu, đạt được tỷ lệ nén trong khoảng 270-600 với việc hy sinh độ chính xác. Phương pháp thưa hóa gradient gTop-k trong [19] giảm chi phí truyền thông dựa trên phương pháp Top-k trong [18]. [20] phát triển một phương pháp dựa trên [21] nén thích ứng kích thước gradient mô hình trao đổi thông qua lượng tử hóa.

Ngược lại với thưa hóa gradient, việc thu nhỏ toàn bộ kích thước mô hình là vô cùng quan trọng trong học phân tán. Nó không chỉ loại bỏ sự dư thừa truyền thông trong quá trình huấn luyện mà còn cho phép ít lưu trữ và thời gian suy luận hơn, làm cho FL được chào đón trong các hệ thống tri thức phân tán. Tuy nhiên, cho đến nay, chỉ học tập trung áp dụng nén mô hình thông qua, ví dụ, cắt tỉa trọng số, lượng tử hóa, phân tích thừa số hạng thấp, bộ lọc tích chập được chuyển giao và chưng cất tri thức [22], với cắt tỉa là trọng tâm của chúng tôi trong công trình này.

SNIP [23] giới thiệu một phương pháp cắt tỉa mô hình DNN một lần (tức là trước khi huấn luyện) dựa trên việc xác định các kết nối quan trọng trong mô hình. [24] đề xuất một phương pháp hai bước tập trung cắt tỉa từng lớp của DNN thông qua lựa chọn kênh dựa trên hồi quy và tái tạo bình phương tối thiểu. Phương pháp trong [25] cắt tỉa CNN tập trung sử dụng Phương pháp Hướng Xen kẽ của Thừa số Lagrange (ADMM). Theo [25], phương pháp PruneTrain [26] sử dụng chính quy hóa group-LASSO có cấu trúc để tăng tốc huấn luyện CNN chỉ tại một vị trí tập trung. Phương pháp DPF [27] cho phép quản lý động độ thưa của mô hình với một cơ chế phản hồi tái kích hoạt các trọng số đã cắt tỉa.

B. Đóng Góp

Hầu hết các phương pháp trong FL chỉ tính đến chi phí truyền thông và do đó áp dụng thưa hóa gradient. Tuy nhiên, thưa hóa trọng số cũng quan trọng không kém và có thể dẫn đến các mô hình thưa phân tán chính xác. Những mô hình thưa như vậy nhẹ và do đó phù hợp để lưu trữ, chuyển giao, huấn luyện và suy luận nhanh. Như được chỉ ra trong [28], các chính sách lấy trung bình trọng số và gradient mô hình chỉ tương đương khi số epoch huấn luyện mô hình cục bộ bằng một. FedDIP cố gắng thu hẹp khoảng cách của cắt tỉa trung bình trọng số trong FL bằng cách thu được các mô hình thưa có độ chính xác cao thông qua chính quy hóa tăng dần và giảm truyền thông trong quá trình huấn luyện thông qua cắt tỉa động.

Theo hiểu biết tốt nhất của chúng tôi trong học phân tán, các phương pháp PruneFL [12] FedDST [29] và LotteryFL [30] cố gắng cắt tỉa mô hình. Tuy nhiên, LotteryFL tập trung vào một vấn đề hoàn toàn khác với chúng tôi. LotteryFL cố gắng khám phá các mạng con thưa cục bộ (a.k.a. Mạng Vé Số) của một mô hình DNN cơ sở. Ngược lại, FedDIP tìm kiếm một mô hình DNN thưa toàn cục với điều chỉnh mặt nạ trên một máy chủ trung tâm, như chúng tôi sẽ chi tiết sau. PruneFL bắt đầu với một nút được chọn trước để huấn luyện một hàm mặt nạ chia sẻ toàn cục, trong khi FedDIP tạo ra hàm mặt nạ với trọng số theo phân phối Erdős-Rényi-Kernel (ERK) [31], như chúng tôi sẽ thảo luận trong các phần sau. FedDST, như được đề xuất bởi Bibikar và cộng sự, ban đầu tạo ra một mặt nạ cắt tỉa dựa trên phân phối ERK. Các giai đoạn tiếp theo liên quan đến cắt tỉa theo lớp trên mô hình toàn cục. Phương pháp đảm bảo huấn luyện hiệu quả thông qua một quy trình cắt tỉa-tái tăng trưởng, duy trì một mặt nạ thưa cục bộ, đặc biệt dưới các phân phối dữ liệu không độc lập đồng phân phối. Các đóng góp kỹ thuật của chúng tôi là:

• Một mô hình học liên bang sáng tạo, được gọi là FedDIP, kết hợp cắt tỉa mô hình định hướng độ thưa cực đoan với chính quy hóa tăng dần.

• FedDIP đạt được chi phí không đáng kể giữ độ chính xác ở mức tương tự hoặc thậm chí cao hơn trên các mô hình được cắt tỉa cực đoan.

• Phân tích hội tụ và lý thuyết của FedDIP.

• Một đánh giá hiệu suất toàn diện và so sánh FedDIP với các bộ dữ liệu chuẩn i.i.d. và non-i.i.d. và các mô hình DNN khác nhau. Kết quả thí nghiệm của chúng tôi tiết lộ rằng FedDIP, trong bối cảnh tỷ lệ nén mô hình cao, mang lại hiệu suất dự đoán vượt trội so với các phương pháp cơ sở và các phương pháp khác trong tài liệu, cụ thể là FedAvg [1], PruneFL [12], PruneTrain [26], FedDST [29], DPF [27], và SNIP [23].

[Bảng ký hiệu như trong bản gốc]

III. KIẾN THỨC CƠ BẢN

A. Học Liên Bang

Đối với các ký hiệu và định nghĩa chung, vui lòng tham khảo Bảng I. Xem xét một hệ thống học phân tán liên quan đến một tập hợp N nút (khách hàng) N={1,2, . . . , N }. Gọi Dn={(x, y)} là bộ dữ liệu cục bộ liên quan đến một nút n∈ N sao cho x∈ X ⊂ Rd,y∈ Y ⊂ R, và Dn=|Dn|. Trong thiết lập FL tiêu chuẩn, cho một tập con K < N nút Nc⊂ N , mất mát cục bộ được cho bởi:

fn(ω) =1/Dn ∑(x,y)∈Dn L(G(ω,x), y) (1)

trong đó ω là tham số mô hình, G là hàm phân biệt ánh xạ không gian đầu vào đến không gian đầu ra và L là một hàm mất mát đo lường chất lượng dự đoán, ví dụ như lỗi bình phương trung bình, khả năng cực đại, mất mát entropy chéo. Hàm mất mát toàn cục cho tất cả các nút được chọn n∈ N c là:

f(ω) = ∑n∈Nc ρnfn(ω), trong đó ρn=Dn/∑j∈Nc Dj. (2)

Quá trình huấn luyện mô hình diễn ra định kỳ qua T vòng toàn cục với L vòng cục bộ. Gọi t∈={0,1, . . . , T −1} là một thực thể thời gian rời rạc trong quá trình huấn luyện. Sau đó, τ=⌊t/L⌋L là thời gian bắt đầu của epoch toàn cục hiện tại. Tại τ, các nút (khách hàng) nhận trọng số tổng hợp đã cập nhật ¯ωτ từ nút chịu trách nhiệm tổng hợp tham số mô hình của các nút, a.k.a. nút máy chủ. Huấn luyện cục bộ tại khách hàng n tại epoch cục bộ l= 1, . . . , L tiến hành như:

ω(τ+l)+1n =ωτ+ln−ητ+l∇fn(ωτ+ln), (3)

trong đó η∈(0,1) là tỷ lệ học. Chính sách lấy trung bình trọng số trên nút máy chủ có thể được viết như:

¯ωτ=∑n∈N ρnωτn. (4)

B. Cắt Tỉa Mô Hình

Trong các hệ thống học tập trung (ví dụ trong Cloud), nơi tất cả dữ liệu được lưu trữ tập trung và có sẵn, cắt tỉa mô hình [32] nhằm thưa hóa các ma trận kết nối khác nhau đại diện cho trọng số của các mô hình DNN. Đáng chú ý, độ thưa, sau đây được ký hiệu bởi s∈[0,1], chỉ ra tỷ lệ trọng số khác không trong tổng số trọng số. Một mô hình thưa 100% (s= 1) chỉ ra rằng tất cả các trọng số đều không đáng kể (giá trị của chúng gần 0), trong khi một mô hình thưa 0% (s= 0) đại diện cho mô hình đầy đủ với giá trị trọng số gốc. Thông thường, việc giảm số lượng trọng số khác không (cắt tỉa) của một mô hình DNN đạt được bằng cách sử dụng các hàm mặt nạ. Một hàm mặt nạ m hoạt động như một hàm chỉ thị quyết định xem tham số/trọng số tại một vị trí nhất định trong một lớp của mô hình DNN có bằng không hay không. Cắt tỉa mô hình dựa trên hàm mặt nạ yêu cầu một tiêu chí để chọn các tham số cần cắt tỉa. Tiêu chí cắt tỉa phổ biến nhất xem xét giá trị tuyệt đối của trọng số của từng tham số trong một lớp. Nói chung, một tham số bị loại bỏ khỏi quá trình huấn luyện nếu giá trị tuyệt đối trọng số của nó nhỏ hơn một ngưỡng được xác định trước.

Mặt khác, cắt tỉa mô hình trong FL là quan trọng nhằm giảm chi phí truyền thông trong mỗi vòng huấn luyện. Hơn nữa, số vòng toàn cục nên được giảm vì điều này góp phần đáng kể vào tổng chi phí truyền thông. Do đó, trong FL, cắt tỉa nhằm đạt tỷ lệ nén mô hình cực đoan, tức s≥0.8 với một sự thỏa hiệp tương đối nhỏ trong độ chính xác dự đoán. Do đó, việc giới thiệu một phương pháp cắt tỉa phân tán và thích ứng với độ thưa DNN tương đối cao và được kiểm soát được coi là phù hợp, giảm chi phí truyền thông mỗi vòng cùng với đảm bảo hội tụ dưới độ thưa cao chỉ với sự giảm nhỏ trong độ chính xác dự đoán.

Các kỹ thuật cắt tỉa thường được phân loại thành ba: cắt tỉa trước huấn luyện (ví dụ SNIP [23]), cắt tỉa trong quá trình huấn luyện (ví dụ PruneTrain [26], FedDST [29], DPF [27] và PruneFL [12]), và cắt tỉa sau huấn luyện. Trong công trình này, chúng tôi tập trung vào hai kỹ thuật trước, có liên quan đến huấn luyện mô hình hiệu quả. Phương pháp cắt tỉa sau huấn luyện cung cấp tiện ích hạn chế trong bối cảnh học phân tán.

Hai kỹ thuật thường được sử dụng để cắt tỉa là: (i) Cắt Tỉa Dựa trên Chính quy hóa (RP) và (ii) Cắt Tỉa Dựa trên Tầm quan trọng (IP) [33]. Độc giả quan tâm có thể tham khảo [24], [25], [33] và các tài liệu tham khảo trong đó để có một khảo sát toàn diện về các kỹ thuật RP và IP. RP sử dụng các tính chất cảm ứng thưa nội tại của chuẩn L1 (khoảng cách Manhattan) và L2 (khoảng cách Euclidean) để hạn chế tầm quan trọng của các tham số mô hình khác nhau. Các chuẩn cảm ứng thưa ràng buộc trọng số của các tham số không quan trọng đến các giá trị tuyệt đối nhỏ trong quá trình huấn luyện. Hơn nữa, RP có thể ràng buộc hiệu quả các trọng số vào một không gian mô hình thưa thông qua điều chỉnh siêu tham số chính quy hóa λ. Trong khi đó ở IP, các tham số được cắt tỉa hoàn toàn dựa trên các công thức được xác định trước được định nghĩa theo trọng số của các tham số hoặc tổng các trọng số. Các kỹ thuật IP ban đầu được đề xuất trong các thiết lập cắt tỉa không có cấu trúc có thể dẫn đến các mô hình thưa không có khả năng tăng tốc tính toán. Mặc dù các kỹ thuật RP được coi là vượt trội hơn các kỹ thuật IP, chúng gặp khó khăn với hai thách thức cơ bản: (C1) Thách thức đầu tiên liên quan đến việc kiểm soát giá trị độ thưa s trong quá trình cắt tỉa. Ví dụ, trong PruneTrain [26], việc sử dụng giá trị ngưỡng cắt tỉa 10^-4 để loại bỏ tham số mô hình không đảm bảo cung cấp một mô hình thưa. (C2) Thách thức thứ hai là điều chỉnh động một tham số chính quy hóa λ. Một λ lớn dẫn đến phân kỳ mô hình trong quá trình huấn luyện, vì mô hình có thể nghiêng quá mức về các mẫu hình phạt. Việc thêm các thuật ngữ chính quy hóa trong huấn luyện DNN truyền thống nhằm giải quyết các vấn đề overfitting. Tuy nhiên, chính quy hóa bổ sung cho các lớp có thể cắt tỉa là cần thiết cho RP, đây là sự khác biệt cốt lõi giữa huấn luyện truyền thống và huấn luyện dựa trên RP.

IV. KHUNG FEDDIP

Khung FedDIP được đề xuất tích hợp cắt tỉa động cực đoan với phản hồi lỗi và chính quy hóa tăng dần trong môi trường học phân tán. Hình 1 minh họa một biểu diễn sơ đồ của FedDIP, sẽ được chi tiết trong phần này. FedDIP cố gắng huấn luyện hiệu quả các mô hình DNN đã cắt tỉa qua các khách hàng hợp tác đảm bảo hội tụ bằng cách giải quyết hai thách thức C1 và C2 phổ biến trong các phương pháp dựa trên RP được thảo luận trong Phần III-B.

Phương pháp cắt tỉa động (DPF) trong [27] thể hiện hiệu suất cải thiện so với các phương pháp cơ sở khác dưới độ thưa cao. Cho sơ đồ cập nhật SGD, gradient mô hình trong DPF được tính trên mô hình đã cắt tỉa như:

ωt+1=ωt−ηt∇f(ω′t) =ωt−ηt∇f(ωt⊙mt), (5)

tính đến phản hồi lỗi (phân tích):

ωt+1=ωt−ηt∇f(ωt+et), (6)

trong đó et=ω′t−ωt. Trong (5), ⊙ đại diện cho tích Hadamard (từng phần tử) giữa hai trọng số mô hình, ωt đại diện cho toàn bộ tham số mô hình, ω′t đại diện cho tham số mô hình đã cắt tỉa, và m là hàm mặt nạ được áp dụng để cắt tỉa như trong, ví dụ, trong [12], [26], và [27]. Mặt nạ được áp dụng trên tham số mô hình ωt để loại bỏ trọng số theo độ lớn của từng trọng số, do đó tạo ra ω′t đã cắt tỉa. Áp dụng gradient, trong trường hợp này, cho phép phục hồi từ lỗi do việc che mặt sớm các trọng số quan trọng, tức quy tắc trong (5) thực hiện một bước phù hợp nhất với mô hình đã cắt tỉa (mục tiêu của chúng ta). Ngược lại, tất cả các phương pháp cắt tỉa được áp dụng trong FL, ví dụ [12], dẫn đến các quyết định dưới tối ưu bằng cách áp dụng quy tắc:

ωt+1=ω′t−ηt∇f(ω′t). (7)

Người ta có thể quan sát rằng quy tắc cập nhật trong (5) giữ lại nhiều thông tin hơn, vì nó chỉ tính gradient của mô hình đã cắt tỉa, so với quy tắc cập nhật trong (7). Điều này dự kiến sẽ mang lại hiệu suất vượt trội dưới độ thưa cao.

Hơn nữa, người ta biết rằng thách thức đa cộng tuyến được giảm nhẹ bởi Toán tử Lựa chọn và Thu nhỏ Tuyệt đối Nhỏ nhất (LASSO). LASSO thực hiện lựa chọn biến và chính quy hóa đồng thời [34]. LASSO thêm thuật ngữ chính quy hóa L1 vào hàm mất mát hồi quy, cung cấp một giải pháp cho các trường hợp số lượng tham số mô hình lớn hơn đáng kể so với các quan sát có sẵn. Rõ ràng, đây là trường hợp trong DNN, thường liên quan đến hàng triệu tham số chỉ với hàng chục nghìn quan sát.

Hai thách thức được báo cáo trong Phần III-B đề cập đến việc lựa chọn các chính sách động phù hợp để kiểm soát độ thưa và tham số chính quy hóa λ. Để giải quyết thách thức C1, chúng tôi động loại bỏ phần trăm thứ s·100% nhỏ nhất theo độ lớn trọng số. Thách thức C2 được giải quyết bằng cách tăng dần tham số chính quy hóa xuất phát từ các nguyên tắc của hồi quy LASSO. Cũng được chứng minh trong [33] rằng việc tăng chính quy hóa có lợi cho cắt tỉa. Dựa trên những quan sát này, chúng tôi thiết lập thuật toán FedDIP để duy trì hiệu suất mô hình dự đoán dưới độ thưa cực đoan với chính quy hóa tăng dần và cắt tỉa động.

Để làm rõ thuật ngữ, chúng tôi gọi thuật toán của chúng tôi áp dụng trực tiếp cắt tỉa động là 'FedDP' (giải quyết thách thức C1), trong khi 'FedDIP' đại diện cho biến thể cũng thêm chính quy hóa tăng dần (giải quyết cả thách thức C1 và C2). Tổng thể, chúng tôi gọi những biến thể này là 'FedD(I)P'.

Mỗi nút n∈ N đầu tiên huấn luyện một mô hình DNN thưa cục bộ, chứa trọng số với độ lớn tương đối nhỏ (xem cũng Hình 1). Sau đó, nút n tối ưu hóa hàm mất mát chính quy hóa tăng dần cục bộ được đề xuất tại vòng t như:

fn(ωt) =1/Dn ∑(x,y)∈D L(G(ωt,x), y) +λt∑Z z=1∥ω(z)t∥2, (8)

trong đó tham số chính quy hóa phụ thuộc bước t λt kiểm soát mức độ thu nhỏ mô hình, tức độ thưa, và Z là số lớp DNN (điều này, tất nhiên, phụ thuộc vào kiến trúc DNN; trong các thí nghiệm của chúng tôi, đó là tổng của các lớp tích chập và kết nối đầy đủ). Chuẩn ∥ω(z)∥2= (∑k|ω(z)k|2)1/2 là chuẩn L2 của lớp z đã cắt tỉa của trọng số mô hình ω(z). Sau đó chúng tôi giới thiệu chính quy hóa tăng dần trên λt dựa trên lịch trình:

λt = {
0 nếu 0≤t <T/Q
...
λmax·(i−1)/Q nếu (i−1)T/Q≤t <iT/Q
...
λmax(Q−1)/Q nếu (Q−1)T/Q≤t≤T
} (9)

với kích thước bước lượng tử hóa Q > 0. Ảnh hưởng của Q trên chính quy hóa được kiểm soát bằng cách thích ứng λmax. Kích thước bước như vậy chia không gian tham số chính quy hóa từ λmax/Q đến λmax để đạt được sự tăng dần của chính quy hóa tại mỗi T/Q vòng. Ngoài ra, mỗi nút n áp dụng cắt tỉa động để cập nhật tiến bộ trọng số mô hình cục bộ ωτ+Ln để tối ưu hóa (8) như:

ωτ,l+1n =ωτ,ln−ητ∇fn(ω′(τ,l)n), (10)

trong đó ω′(τ+l)n được thu được thông qua cắt tỉa dựa trên hàm mặt nạ toàn cục mτ được tạo ra bởi nút máy chủ. Hơn nữa, chính sách cắt tỉa dần dần của chúng tôi sửa đổi chính sách cập nhật độ thưa mỗi vòng từ [35] bằng cách cập nhật tăng dần độ thưa như:

st=sp+ (s0−sp)(1−t/T)3, (11)

trong đó st đại diện cho độ thưa được áp dụng cho cắt tỉa mô hình tại vòng t, s0 là độ thưa ban đầu, và sp là độ thưa mong muốn/mục tiêu. Đáng chú ý, trong phương pháp của chúng tôi s0 hoàn toàn khác không; đây có thể là một độ thưa vừa phải của s0= 0.5. Sự thích ứng như vậy phân biệt phương pháp của chúng tôi với [35], nơi s0= 0. Về cơ bản, chúng tôi cho phép độ thưa tăng từ mức độ vừa phải đến cực đoan trong suốt quá trình. Nếu xem xét s0>0, độ thưa theo lớp của mặt nạ ban đầu tuân theo phân phối ERK được giới thiệu trong [31]. Khi kết thúc epoch cục bộ l, nút máy chủ thu thập K < N trọng số mô hình ωτ+ln từ các nút được chọn n∈ N c, và tính trung bình trọng số toàn cục như:

¯ωτ+lG=∑n∈N ρnωτ+ln. (12)

Ngoài ra, hàm mặt nạ mτ được tạo ra dựa trên cắt tỉa trên ¯ωτ+lG với độ thưa hiện tại sτ. Quá trình FedDIP được tóm tắt trong Thuật toán 1, nơi chỉ các mô hình đã cắt tỉa được trao đổi từ máy chủ đến các nút, trong khi cắt tỉa được thực hiện cục bộ trong các khách hàng. Lưu ý: FedDIP đạt được khởi tạo không dữ liệu và tổng quát hóa DPF [27] trong quá trình cắt tỉa động. Khi chúng ta đặt s0 ban đầu = 0 và không có chính quy hóa tăng dần, tức λt= 0,∀t, thì FedDIP giảm về DPF. Hơn nữa, chúng ta thu được biến thể FedDP nếu chúng ta đặt λt= 0,∀t với s0>0 w.r.t. phân phối ERK.

Nhận xét 1. Đánh đổi giữa Cắt Tỉa và Tinh chỉnh: Phương pháp FedDIP giới thiệu một chân trời tái cấu hình, ký hiệu là R, trong giai đoạn huấn luyện mô hình để cập nhật định kỳ hàm mặt nạ. Cụ thể, hàm mặt nạ mτ được cập nhật tại mỗi R vòng toàn cục, tức khi τ mod R= 0, để đảm bảo một đường cong học độ chính xác nhất quán và mượt mà. Giá trị của chân trời này được xác định thông qua thực nghiệm. Kết quả Tiềm năng của Cắt Tỉa Không đủ: Nếu hàm mặt nạ không thay đổi trong suốt chân trời T, có nguy cơ mô hình có thể hội tụ đến một tối ưu cục bộ. Hậu quả của Tinh chỉnh Không đủ: Ngược lại, nếu hàm mặt nạ trải qua các cập nhật thường xuyên, các thay đổi trong mô hình có thể không phù hợp với các thay đổi trong cấu trúc mô hình thưa.

Nhận xét 2. Tích hợp Chính quy hóa Tăng dần và DPF: Khác với phương pháp trong [33], tập trung các yếu tố hình phạt tăng trên các mô hình được huấn luyện trước, FedDIP khởi xướng điều này từ đầu trong bối cảnh học phân tán. Việc tích hợp chính quy hóa tăng dần với DPF mang lại lợi thế, chủ yếu vì DPF loại bỏ nhu cầu tinh chỉnh sau cắt tỉa, làm cho nó được ưa thích hơn các phương pháp cắt tỉa một lần như SNIP.

[Thuật toán 1 và các phần tiếp theo được dịch tương tự...]

V. PHÂN TÍCH LÝ THUYẾT & HỘI TỤ

Trong phần này, chúng tôi cung cấp một phân tích lý thuyết về FedDIP bao gồm Định lý hội tụ 1 đảm bảo tính ổn định trong huấn luyện mô hình w.r.t. chính quy hóa tăng dần và cắt tỉa động cực đoan. Lưu ý về Chứng minh: Các chứng minh của Định lý 1 và các bổ đề của chúng tôi có trong Phụ lục A.

[Tiếp tục với định lý và các phần khác của phân tích lý thuyết...]

VI. ĐÁNH GIÁ THỰC NGHIỆM

A. Thiết lập Thực nghiệm

Bộ dữ liệu và Mô hình: Chúng tôi thí nghiệm với các bộ dữ liệu Fashion-MNIST [39], CIFAR10, và CIFAR100 [40]. Fashion-MNIST bao gồm 60.000 ảnh huấn luyện và 10.000 ảnh kiểm tra 28x28 grayscale được gán nhãn từ 10 lớp. Cả hai bộ dữ liệu CIFAR đều bao gồm 50.000 ảnh huấn luyện và 10.000 ảnh kiểm tra 32x32 màu; trong CIFAR10 và CIFAR100 có 10 lớp (6000 ảnh mỗi lớp) và 100 lớp (600 ảnh mỗi lớp), tương ứng. Chúng tôi xem xét trường hợp i.i.d. (độc lập và phân phối đồng nhất) để so sánh tất cả các thuật toán và mở rộng FedDIP để áp dụng cho các trường hợp non-i.i.d. Để kiểm tra và so sánh hiệu quả của FedDIP, chúng tôi sử dụng các kiến trúc CNN nổi tiếng khác nhau: LeNet-5 [41], AlexNet [42] và Resnet-18 [7] làm mô hình xương sống (dày đặc hoặc chưa cắt tỉa), với FedAvg cơ sở [1] và các mô hình cơ sở cắt tỉa PruneFL [12], PruneTrain [26], FedDST [29], DPF [27] (tương đương FedDP như đã thảo luận ở trên), và SNIP [23]. Đối với trường hợp non-i.i.d., chúng tôi áp dụng phương pháp phân vùng dữ liệu bệnh lý trong [1], chỉ gán hai lớp cho mỗi nút. Chúng tôi kết hợp FedDIP với FedProx [43], một tổng quát hóa và tái tham số hóa của FedAvg để giải quyết tính không đồng nhất của dữ liệu (được gọi là FedDIP+Prox), và so sánh với FedAvg và FedProx cơ sở. Mục tiêu của chúng tôi là đánh giá độ chính xác, hiệu quả lưu trữ và truyền thông của FedDIP trong môi trường FL dưới độ thưa cực đoan.

[Phần cấu hình và kết quả thực nghiệm tiếp tục được dịch tương tự...]

VII. KẾT LUẬN

Chúng tôi đề xuất FedDIP, một khung FL mới với cắt tỉa động và chính quy hóa tăng dần đạt được các mô hình DNN có độ chính xác cao và cực kỳ thưa. FedDIP chính quy hóa dần dần các mô hình DNN thưa thu được các mô hình nén cực đoan duy trì độ chính xác cơ sở và đảm bảo chi phí truyền thông có thể kiểm soát. FedDIP là một phương pháp khởi tạo không dữ liệu dựa trên phân phối ERK. Chúng tôi cung cấp phân tích hội tụ lý thuyết của FedDIP và đánh giá nó qua các cấu trúc DNN khác nhau. FedDIP đạt được độ chính xác tương đương và cao hơn so với các phương pháp cơ sở FL và các phương pháp cắt tỉa mô hình dựa trên FL hiện đại, tương ứng, trên độ thưa cực đoan sử dụng các bộ dữ liệu chuẩn (trường hợp i.i.d. & non-i.i.d.). Chương trình nghị sự của chúng tôi bao gồm giải quyết tính không đồng nhất trong môi trường FL cá nhân hóa.

LỜI CẢM ơN

Các tác giả muốn bày tỏ lòng biết ơn chân thành đến Tiến sĩ Fani Deligianni vì những hiểu biết sâu sắc và thảo luận vô giá trong quá trình giao tiếp đồng nghiệp.

Công trình này được tài trợ một phần bởi Tài trợ EU Horizon 'Tích hợp và Hài hòa các Hoạt động Logistics' TRACE (#101104278) và 'Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc' (NSFC) theo Tài trợ #72201093.

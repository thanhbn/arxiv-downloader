# 2304.06962.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/prompt/2304.06962.pdf
# Kích thước tệp: 488277 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Được xuất bản như một Tiny Paper tại ICLR 2023
KỸ THUẬT PROMPT VÀ HIỆU CHỈNH CHO SUY LUẬN THƯỜNG THỨC ZERO-SHOT

Chenkai Ma
Trường Khoa học và Kỹ thuật Máy tính
Đại học Khoa học và Công nghệ Điện tử Trung Quốc
Thành Đô, 611731, Trung Quốc
kasmas316@gmail.com

TÓM TẮT
Kỹ thuật prompt và hiệu chỉnh giúp các mô hình ngôn ngữ lớn xuất sắc trong các nhiệm vụ suy luận, bao gồm suy luận thường thức trắc nghiệm. Từ góc độ thực tế, chúng tôi điều tra và đánh giá các chiến lược này trên các mô hình ngôn ngữ nhỏ hơn. Thông qua các thí nghiệm trên năm benchmark suy luận thường thức, chúng tôi phát hiện rằng mỗi chiến lược có lợi cho một số mô hình nhất định, nhưng hiệu ứng kết hợp của chúng chủ yếu là tiêu cực.

1 GIỚI THIỆU
Các mô hình ngôn ngữ lớn (LLMs) đã cho thấy hiệu suất ấn tượng trong nhiều ứng dụng NLP (Ouyang et al., 2022; Chung et al., 2022; Wei et al., 2022a), bao gồm suy luận thường thức, một thành phần quan trọng của AGI (Davis & Marcus, 2015). Các nghiên cứu gần đây cho thấy LLMs có khả năng học zero-shot và few-shot (Brown et al., 2020; Webson & Pavlick, 2022; Chowdhery et al., 2022), và một số chiến lược có thể cải thiện thêm hiệu suất của chúng, như kỹ thuật prompt và hiệu chỉnh (Kojima et al., 2022; Zhao et al., 2021; Jiang et al., 2021; Kadavath et al., 2022).
Mặc dù đạt được hiệu suất SOTA trên nhiều benchmark, hầu hết LLMs rất đắt đỏ để sử dụng và không được công bố cho công chúng.

Do đó, chúng tôi nghiên cứu liệu kỹ thuật prompt và hiệu chỉnh có thể giúp các mô hình ngôn ngữ nhỏ hơn (những mô hình có không quá 3B tham số) trong suy luận thường thức trắc nghiệm zero-shot. Vì các chiến lược này có thể là tính chất nổi lên (Wei et al., 2022b; Chan et al., 2022), chúng tôi thực hiện một số sửa đổi, sau đó đánh giá chúng trên năm benchmark suy luận thường thức. Chúng tôi phát hiện rằng kỹ thuật prompt có lợi cho các mô hình Flan-T5 lớn, trong khi hiệu chỉnh hoạt động tốt trên GPT-2. Tuy nhiên, hiệu ứng kết hợp của chúng chủ yếu là tiêu cực trong hầu hết các trường hợp.

2 PHƯƠNG PHÁP
Nền tảng. Suy luận thường thức trắc nghiệm được hình thức hóa như sau: Cho một câu hỏi x và một số lựa chọn y1; :::; yn, chọn lựa chọn tốt nhất. Trong setting zero-shot, một mô hình ngôn ngữ tính điểm cho mỗi lựa chọn, thường là xác suất có điều kiện PLM(yi|x), và chọn lựa chọn có điểm cao nhất, như được hiển thị trong Hình 1. Các nghiên cứu gần đây cho thấy các phương án thay thế cho xác suất có điều kiện có thể dẫn đến hiệu suất tốt hơn (Holtzman et al., 2021; Niu et al., 2021; Min et al., 2022), nhưng chúng tôi không xem xét các biến thể này để đơn giản và so sánh công bằng.

Kỹ thuật prompt: prompt trắc nghiệm và hướng dẫn. Một hạn chế của PLM(yi|x) là các lựa chọn không được xem xét cùng nhau. Các nghiên cứu gần đây cho thấy rằng việc cung cấp tất cả các lựa chọn trong đầu vào, cùng với hướng dẫn về nhiệm vụ, có thể giúp LM suy luận (Robinson & Wingate, 2023; Chung et al., 2022). Được lấy cảm hứng từ những ý tưởng này, chúng tôi thiết kế các template T() thêm hướng dẫn và lựa chọn vào câu hỏi, như được hiển thị trong Hình 1. Không giống như các phương pháp gần đây liên kết mỗi lựa chọn với một ký hiệu như (A), chúng tôi sử dụng LM để dự đoán trực tiếp câu trả lời, vì liên kết ký hiệu là một khả năng nổi lên (Robinson & Wingate, 2023).

Hiệu chỉnh. Các nghiên cứu gần đây phát hiện rằng các mô hình ngôn ngữ ưa thích một số lựa chọn nhất định ngay cả khi không có câu hỏi, điều này cho thấy chúng không được hiệu chỉnh tốt (Zhao et al., 2021; Jiang et al., 2021). Để khắc phục vấn đề này, chúng tôi chia điểm có điều kiện của một lựa chọn cho một điểm khác được tính từ một prompt "null" không chứa câu hỏi, như trong PLM(yi|x)/PLM(yi). Một ví dụ được hiển thị trong Hình 1.

--- TRANG 2 ---
Được xuất bản như một Tiny Paper tại ICLR 2023

Hình 1: Sự kết hợp của định dạng dữ liệu và điểm lựa chọn cho suy luận thường thức trắc nghiệm. Dựa trên phương pháp zero-shot, chúng tôi thêm kỹ thuật prompt (hướng dẫn và prompt trắc nghiệm) và hiệu chỉnh. Không giống như các nghiên cứu trước, chúng tôi không liên kết lựa chọn với ký hiệu, như (A).

vấn đề, chúng tôi chia điểm có điều kiện của một lựa chọn cho một điểm khác được tính từ một prompt "null" không chứa câu hỏi, như trong PLM(yi|x)/PLM(yi). Một ví dụ được hiển thị trong Hình 1.

3 THÍ NGHIỆM
Bộ dữ liệu. Chúng tôi đánh giá kỹ thuật prompt và hiệu chỉnh trên năm benchmark suy luận thường thức trắc nghiệm: (1) CommonsenseQA (CSQA) (Talmor et al., 2019); (2) COPA (Gordon et al., 2012); (3) OpenBookQA (OBQA) (Mihaylov et al., 2018); (4) PIQA (Bisk et al., 2019); (5) Social IQA (SIQA) (Sap et al., 2019); Chúng tôi trình bày thống kê của chúng trong Phụ lục B. Đối với tất cả benchmark, chúng tôi chỉ sử dụng tập phát triển của chúng.

Baseline. Chúng tôi so sánh bốn phương pháp zero-shot được đề cập trong Hình 1: (1) ZS, phương pháp zero-shot tiêu chuẩn tính điểm xác suất có điều kiện của mỗi lựa chọn; (2) CA, là ZS với hiệu chỉnh, còn được gọi là PMI DC trong Holtzman et al. (2021); (3) PE, là ZS với kỹ thuật prompt; (4) FULL, là ZS với cả kỹ thuật prompt và hiệu chỉnh.

Thiết lập. Về mô hình ngôn ngữ, chúng tôi sử dụng GPT-2 (Radford et al., 2019), T5 (Raffel et al., 2022), và Flan-T5 (Chung et al., 2022), ngoại trừ Flan-T5-XXL, quá lớn (11B) để lưu trữ trên phần cứng của chúng tôi. Chỉ số đánh giá là độ chính xác.

Bảng 1: Độ chính xác (%) trên Flan-T5
Mô hình | Flan-T5-Small (80M) | Flan-T5-Base (250M) | Flan-T5-Large (780M) | Flan-T5-XL (3B)
ZS CA PE FULL | ZS CA PE FULL | ZS CA PE FULL | ZS CA PE FULL
COPA 59.8 56.6 52.0 49.6 | 67.0 68.2 60.6 61.4 | 72.8 71.6 87.6 84.0 | 80.8 78.4 88.8 85.6
CSQA 29.2 37.7 30.8 28.3 | 40.9 48.5 52.5 51.8 | 51.6 51.5 62.2 67.6 | 61.8 64.7 70.6 72.7
OBQA 14.0 32.6 24.8 29.6 | 20.0 34.0 28.6 34.0 | 24.2 39.4 53.4 52.8 | 30.0 49.6 61.0 55.4
PIQA 62.5 57.6 54.2 51.1 | 65.9 59.7 58.1 54.0 | 71.4 65.5 72.7 60.6 | 75.8 68.3 68.9 60.4
SIQA 41.7 42.5 42.3 42.3 | 46.4 47.4 54.7 53.7 | 51.4 48.1 68.6 66.7 | 56.1 56.3 71.6 58.9

Kết quả. Chúng tôi trình bày kết quả trên Flan-T5 trong Bảng 1, và kết quả trên GPT-2 và T5 trong Phụ lục C. Chúng tôi phát hiện kỹ thuật prompt không hoạt động cho hầu hết các mô hình, ngoại trừ hai mô hình Flan-T5 lớn nhất, trên đó nó cải thiện hiệu suất lên đến 30 điểm. Điều này chứng thực hiệu ứng của instruction-tuning trên Flan-T5, và khả năng nổi lên của các mô hình lớn hơn (Chung et al., 2022). Ngoài ra, hiệu chỉnh hoạt động tốt trên GPT-2, nhưng không nhất quán trên các mô hình khác. Điều này hỗ trợ các phát hiện trong Holtzman et al. (2021). Hơn nữa, hiệu ứng kết hợp của cả hai chiến lược chủ yếu là tiêu cực.
Nhìn chung, các phát hiện của chúng tôi gợi ý cần kiểm tra cẩn thận khi sử dụng các chiến lược này, vì không có cấu hình chung nào hoạt động tốt trên tất cả các mô hình.

--- TRANG 3 ---
Được xuất bản như một Tiny Paper tại ICLR 2023

4 KẾT LUẬN
Chúng tôi nghiên cứu liệu kỹ thuật prompt và hiệu chỉnh có giúp các mô hình ngôn ngữ nhỏ hơn trong suy luận thường thức trắc nghiệm, như chúng giúp LLMs. Chúng tôi phát hiện rằng trong khi mỗi chiến lược có lợi cho một số mô hình ngôn ngữ, hiệu ứng kết hợp của chúng chủ yếu là tiêu cực. Do đó, chúng tôi đề xuất kiểm tra cẩn thận các chiến lược này trước khi áp dụng chúng cho các mô hình ngôn ngữ nhỏ hơn.

TUYÊN BỐ URM
Tác giả Chenkai Ma đáp ứng tiêu chí URM của ICLR 2023 Tiny Papers Track.

TÀI LIỆU THAM KHẢO
Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng Gao, và Yejin Choi. Piqa: Reasoning about physical commonsense in natural language. ArXiv, abs/1911.11641, 2019.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. Language models are few-shot learners. Trong H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, và H. Lin (eds.), Advances in Neural Information Processing Systems, tập 33, trang 1877–1901. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.

Stephanie C. Y. Chan, Adam Santoro, Andrew Kyle Lampinen, Jane X. Wang, Aaditya K Singh, Pierre H. Richemond, Jay Mcclelland, và Felix Hill. Data distributional properties drive emergent in-context learning in transformers. ArXiv, abs/2205.05055, 2022.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam M. Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Benton C. Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier García, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Díaz, Orhan Firat, Michele Catasta, Jason Wei, Kathleen S. Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, và Noah Fiedel. Palm: Scaling language modeling with pathways. ArXiv, abs/2204.02311, 2022.

Hyung Won Chung, Le Hou, S. Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Wei Yu, Vincent Zhao, Yanping Huang, Andrew M. Dai, Hongkun Yu, Slav Petrov, Ed Huai hsin Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc Le, và Jason Wei. Scaling instruction-finetuned language models. ArXiv, abs/2210.11416, 2022.

Ernest Davis và Gary F. Marcus. Commonsense reasoning and commonsense knowledge in artificial intelligence. Communications of the ACM, 58:92 – 103, 2015.

Andrew Gordon, Zornitsa Kozareva, và Melissa Roemmele. SemEval-2012 task 7: Choice of plausible alternatives: An evaluation of commonsense causal reasoning. Trong *SEM 2012: The First Joint Conference on Lexical and Computational Semantics – Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop

--- TRANG 4 ---
Được xuất bản như một Tiny Paper tại ICLR 2023

on Semantic Evaluation (SemEval 2012), trang 394–398, Montréal, Canada, 7-8 June 2012. Association for Computational Linguistics. URL https://aclanthology.org/S12-1052.

Ari Holtzman, Peter West, Vered Shwartz, Yejin Choi, và Luke Zettlemoyer. Surface form competition: Why the highest probability answer isn't always right. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 7038–7051, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.564. URL https://aclanthology.org/2021.emnlp-main.564.

Zhengbao Jiang, Jun Araki, Haibo Ding, và Graham Neubig. How can we know when language models know? on the calibration of language models for question answering. Transactions of the Association for Computational Linguistics, 9:962–977, 2021. doi: 10.1162/tacl_a_00407. URL https://aclanthology.org/2021.tacl-1.57.

Saurav Kadavath, Tom Conerly, Amanda Askell, T. J. Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zachary Dodds, Nova DasSarma, Eli Tran-Johnson, Scott Johnston, Sheer El-Showk, Andy Jones, Nelson Elhage, Tristan Hume, Anna Chen, Yuntao Bai, Sam Bowman, Stanislav Fort, Deep Ganguli, Danny Hernandez, Josh Jacobson, John Kernion, Shauna Kravec, Liane Lovitt, Kamal Ndousse, Catherine Olsson, Sam Ringer, Dario Amodei, Tom B. Brown, Jack Clark, Nicholas Joseph, Benjamin Mann, Sam McCandlish, Christopher Olah, và Jared Kaplan. Language models (mostly) know what they know. ArXiv, abs/2207.05221, 2022.

Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, và Yusuke Iwasawa. Large language models are zero-shot reasoners. Trong Alice H. Oh, Alekh Agarwal, Danielle Belgrave, và Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022. URL https://openreview.net/forum?id=e2TBb5y0yFf.

Todor Mihaylov, Peter Clark, Tushar Khot, và Ashish Sabharwal. Can a suit of armor conduct electricity? a new dataset for open book question answering. Trong Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, trang 2381–2391, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1260. URL https://aclanthology.org/D18-1260.

Sewon Min, Mike Lewis, Hannaneh Hajishirzi, và Luke Zettlemoyer. Noisy channel language model prompting for few-shot text classification. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 5316–5330, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.acl-long.365. URL https://aclanthology.org/2022.acl-long.365.

Yilin Niu, Fei Huang, Jiaming Liang, Wenkai Chen, Xiaoyan Zhu, và Minlie Huang. A semantic-based method for unsupervised commonsense question answering. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), trang 3037–3049, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.acl-long.237. URL https://aclanthology.org/2021.acl-long.237.

Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke E. Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Francis Christiano, Jan Leike, và Ryan J. Lowe. Training language models to follow instructions with human feedback. ArXiv, abs/2203.02155, 2022.

Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, và Ilya Sutskever. Language models are unsupervised multitask learners. 2019.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J. Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 21(1), jun 2022. ISSN 1532-4435.

Joshua Robinson và David Wingate. Leveraging large language models for multiple choice question answering. Trong International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=yKbprarjc5B.

--- TRANG 5 ---
Được xuất bản như một Tiny Paper tại ICLR 2023

Maarten Sap, Hannah Rashkin, Derek Chen, Ronan Le Bras, và Yejin Choi. Social IQa: Commonsense reasoning about social interactions. Trong Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), trang 4463–4473, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1454. URL https://aclanthology.org/D19-1454.

Alon Talmor, Jonathan Herzig, Nicholas Lourie, và Jonathan Berant. CommonsenseQA: A question answering challenge targeting commonsense knowledge. Trong Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), trang 4149–4158, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1421. URL https://aclanthology.org/N19-1421.

Albert Webson và Ellie Pavlick. Do prompt-based models really understand the meaning of their prompts? Trong Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 2300–2344, Seattle, United States, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.167. URL https://aclanthology.org/2022.naacl-main.167.

Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, và Quoc V Le. Finetuned language models are zero-shot learners. Trong International Conference on Learning Representations, 2022a. URL https://openreview.net/forum?id=gEZrGCozdqR.

Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, và William Fedus. Emergent abilities of large language models. Transactions on Machine Learning Research, 2022b. ISSN 2835-8856. URL https://openreview.net/forum?id=yzkSU5zdwD. Survey Certification.

Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, và Sameer Singh. Calibrate before use: Improving few-shot performance of language models. Trong Marina Meila và Tong Zhang (eds.), Proceedings of the 38th International Conference on Machine Learning, tập 139 của Proceedings of Machine Learning Research, trang 12697–12706. PMLR, 18–24 Jul 2021. URL https://proceedings.mlr.press/v139/zhao21c.html.

A PROMPT ĐẦY ĐỦ CHO TẤT CẢ BENCHMARK
Trong phần này, chúng tôi trình bày prompt (tức là template) cho mỗi benchmark trong Bảng 2. Cụ thể, chúng tôi sử dụng một prompt cho CSQA và SIQA, và một prompt khác cho COPA, OBQA, và PIQA, vì ba benchmark sau không phải lúc nào cũng có câu hỏi trong một mẫu dữ liệu. Để đơn giản, chúng tôi vẫn sử dụng thuật ngữ "câu hỏi" cho ba bộ dữ liệu này. Chúng tôi cũng cung cấp các prompt chúng tôi sử dụng cho hiệu chỉnh, được sử dụng trong FULL.

Bảng 2: Prompt cho mỗi benchmark
Benchmark | Prompt cho Câu hỏi | Prompt cho Hiệu chỉnh
CSQA, SIQA | Cho các câu trả lời trong dấu ngoặc vuông [], chọn câu trả lời tốt nhất cho câu hỏi. Câu trả lời: [answers]. Câu hỏi: [question] Câu trả lời tốt nhất là: | Cho các câu trả lời trong dấu ngoặc vuông [], chọn câu trả lời tốt nhất. Câu trả lời: [answers]. Câu trả lời tốt nhất là:
COPA, OBQA, PIQA | Cho các câu trả lời trong dấu ngoặc vuông [], chọn câu trả lời hoàn thành câu tốt nhất. Câu trả lời: [answers]. Câu: [question] Câu trả lời tốt nhất là: | Cho các câu trả lời trong dấu ngoặc vuông [], chọn câu trả lời tốt nhất. Câu trả lời: [answers]. Câu trả lời tốt nhất là:

B THỐNG KÊ BỘ DỮ LIỆU
Chúng tôi trình bày thống kê của năm bộ dữ liệu suy luận thường thức (CSR) mà chúng tôi sử dụng trong các thí nghiệm trong Bảng 3.

--- TRANG 6 ---
Được xuất bản như một Tiny Paper tại ICLR 2023

Bảng 3: Thống kê các bộ dữ liệu
Tên Bộ dữ liệu | Loại CSR | Số lựa chọn | Huấn luyện | Xác thực | Kiểm tra
COPA (Gordon et al., 2012) | Nhân quả | 2 | N/A | 500 | 500
CSQA (Talmor et al., 2019) | Tổng quát | 5 | 9741 | 1221 | 1140
OBQA (Mihaylov et al., 2018) | Khoa học | 4 | 4957 | 500 | 500
PIQA (Bisk et al., 2019) | Vật lý | 2 | 16000 | 2000 | 3000
SIQA (Sap et al., 2019) | Xã hội | 3 | 33410 | 1954 | N/A

C KẾT QUẢ TRÊN GPT-2 VÀ T5
Chúng tôi trình bày kết quả trên GPT-2 trong Bảng 4, và T5 trong Bảng 5.

Bảng 4: Độ chính xác (%) trên GPT-2
Mô hình | GPT-2-Base (125M) | GPT-2-Medium (350M) | GPT-2-Large (765M) | GPT-2-XL (1.6B)
ZS CA PE FULL | ZS CA PE FULL | ZS CA PE FULL | ZS CA PE FULL
COPA 61.0 62.8 53.0 54.4 | 67.0 70.0 49.4 54.2 | 69.8 69.4 51.4 57.4 | 69.0 71.6 51.4 53.0
CSQA 25.5 36.4 23.8 27.4 | 30.9 41.8 27.4 30.1 | 33.3 44.5 26.9 33.2 | 38.6 47.8 35.1 36.2
OBQA 15.8 33.4 25.6 28.0 | 18.0 38.6 26.8 27.4 | 21.6 41.4 25.2 29.4 | 22.4 43.2 25.8 29.4
PIQA 62.1 57.1 54.6 52.6 | 66.2 57.5 51.8 52.6 | 69.6 60.7 55.0 54.6 | 69.6 62.2 52.6 53.4
SIQA 35.8 38.0 34.3 37.1 | 36.9 40.0 36.0 38.0 | 36.6 40.3 34.0 35.6 | 39.0 41.0 35.2 35.9

Bảng 5: Độ chính xác (%) trên T5
Mô hình | T5-Small (80M) | T5-Base (250M) | T5-Large (780M)
ZS CA PE FULL | ZS CA PE FULL | ZS CA PE FULL
COPA 55.2 51.2 51.2 52.2 | 59.6 59.4 51.0 51.8 | 65.2 56.6 53.2 53.8
CSQA 16.6 22.8 21.1 21.0 | 26.1 30.0 20.6 22.5 | 39.2 35.4 33.1 35.7
OBQA 14.2 28.8 23.8 25.8 | 15.8 30.8 27.8 27.2 | 19.0 30.4 24.8 26.4
PIQA 56.6 50.5 51.2 50.8 | 61.0 57.7 51.7 53.0 | 66.6 64.4 52.8 51.7
SIQA 36.2 36.1 35.0 34.4 | 36.2 37.6 37.0 33.5 | 38.7 38.1 37.0 34.1

D MÃ NGUỒN
Mã nguồn của chúng tôi có sẵn tại https://anonymous.4open.science/r/Prompt-engineering-and-calibration-0AE0/README.md

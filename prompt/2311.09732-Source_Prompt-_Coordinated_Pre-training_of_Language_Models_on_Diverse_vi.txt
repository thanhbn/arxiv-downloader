# 2311.09732.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/prompt/2311.09732.pdf
# Kích thước tệp: 169958 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Source Prompt: Tiền Huấn Luyện Phối Hợp Các Mô Hình Ngôn Ngữ Trên Các Kho Dữ Liệu Đa Dạng Từ Nhiều Nguồn
Yipei Xu, Dakuan Lu, Jiaqing Liang, Xintao Wang, Yipeng Geng, Yingsi Xin, Hengkui Wu, Ken
Chen, ruiji zhang, Yanghua Xiao
Trường Đại học Fudan, SuperSymmetry Technologies

Tóm tắt
Các mô hình ngôn ngữ được tiền huấn luyện (PLMs) đã thiết lập mô hình mới trong lĩnh vực NLP. Để có các PLMs mạnh mẽ hơn, một trong những cách phổ biến và thành công nhất là liên tục mở rộng quy mô của các mô hình và các kho dữ liệu tiền huấn luyện. Những kho dữ liệu lớn này thường được tạo ra bằng cách hội tụ những kho nhỏ hơn từ nhiều nguồn, do đó chúng ngày càng trở nên đa dạng. Tuy nhiên, các tác động phụ của những kho dữ liệu hội tụ khổng lồ này vẫn chưa được nghiên cứu đầy đủ. Trong bài báo này, chúng tôi xác định bất lợi của các kho dữ liệu không đồng nhất từ nhiều nguồn cho việc tiền huấn luyện PLMs. Hướng tới việc tiền huấn luyện phối hợp trên các kho dữ liệu đa dạng, chúng tôi tiếp tục đề xuất source prompts (SP), cách thức rõ ràng nhắc nhở mô hình về nguồn dữ liệu ở giai đoạn tiền huấn luyện và tinh chỉnh. Kết quả của các thí nghiệm mở rộng cho thấy rằng các PLMs được tiền huấn luyện với SP trên các kho dữ liệu đa dạng đạt được cải thiện đáng kể trong các nhiệm vụ downstream khác nhau.

Giới thiệu
Gần đây, các mô hình ngôn ngữ được tiền huấn luyện (PLMs) đã cải thiện đáng kể hiệu suất tiên tiến nhất trong xử lý ngôn ngữ tự nhiên (NLP). Chúng đã giới thiệu một phương pháp mới sử dụng tiền huấn luyện theo sau bởi tinh chỉnh. Cụ thể, những mô hình này thu thập kiến thức ngôn ngữ rộng lớn từ việc tiền huấn luyện không giám sát trên các kho dữ liệu khổng lồ. Để nâng cao khả năng của PLMs, thực hành hiệu quả nhất đã được tìm thấy là phát triển các mô hình lớn hơn được tiền huấn luyện trên các kho dữ liệu to lớn và đa dạng (Raffel et al. 2019; Brown et al. 2020; Wu et al. 2021).

Việc mở rộng kho dữ liệu do đó rất quan trọng cho việc tiền huấn luyện PLMs lớn. Điều này thường được thực hiện bằng cách kết hợp nhiều kho dữ liệu (Gao et al. 2020; Devlin et al. 2018; Yang, Uy, and Huang 2020) từ các nguồn khác nhau, bao gồm các kho dữ liệu Internet lớn được thu thập bằng cách sử dụng các trình thu thập thông thường (Raffel et al. 2019; Xue et al. 2020; Yuan et al. 2021; Wu et al. 2021). Do đó, nhiều kho dữ liệu đa dạng được sử dụng trong việc huấn luyện PLM, đảm bảo khả năng thích ứng cho nhiều nhiệm vụ downstream. Bảng 1 trình bày một số PLMs phổ biến chung hoặc theo lĩnh vực cụ thể, mỗi cái được tiền huấn luyện từ các kho dữ liệu đa dạng.

Việc tăng kích thước kho dữ liệu bằng cách tích hợp thêm các kho dữ liệu không đồng nhất không phải lúc nào cũng nâng cao hiệu suất của PLMs. Đối với một số nhiệm vụ downstream hoặc tập dữ liệu, việc tiền huấn luyện trên các kho dữ liệu con không liên quan có thể có hại. Bảng 2 minh họa điều này. Một mô hình T5 được tiền huấn luyện trên kho dữ liệu kết hợp Wikipedia và TorontoBooks Corpus (TBC) (Zhu et al. 2015), tổng cộng 20 GB, đạt được điểm SuperGLUE là 73.24. Tuy nhiên, cùng một mô hình được tiền huấn luyện trên kho dữ liệu C4 (Raffel et al. 2019) lớn hơn nhiều nhưng không đồng nhất hơn với 745 GB lại có điểm thấp hơn là 71.36. Kho dữ liệu C4 lớn hơn và đa dạng hơn, nhưng chất lượng của nó kém hơn so với các kho dữ liệu Wikipedia và TBC. Do đó, phân phối đa dạng của các kho dữ liệu lớn thách thức hiệu suất của các PLMs lớn trong một số benchmark.

Để tiếp tục nâng cao hiệu suất của các mô hình ngôn ngữ được tiền huấn luyện lớn (PLMs), một yếu tố quan trọng là phối hợp hiệu quả các kho dữ liệu có độ đa dạng nguồn dữ liệu cao. Nhiều nghiên cứu (Wang et al. 2018b; Silva et al. 2018; Aharoni and Goldberg 2020; Iter and Grangier 2021) nhấn mạnh tầm quan trọng của sự đa dạng dữ liệu trong các nhiệm vụ học máy. Những nghiên cứu này đề xuất trích xuất các ví dụ huấn luyện gần giống với nhiệm vụ downstream để nâng cao hiệu suất. Tuy nhiên, việc lấy mẫu lại dữ liệu cho các kho dữ liệu tiền huấn luyện là không thực tế do hai lý do chính: a). Việc lấy mẫu lại dữ liệu làm cho dữ liệu không được chọn trở thành không được sử dụng trong quá trình tiền huấn luyện, do đó làm giảm việc sử dụng dữ liệu kho. b). Vì PLMs được thiết kế để xử lý nhiều nhiệm vụ downstream, việc lấy mẫu lại cho các nhiệm vụ cụ thể làm hỏng tính tổng quát của PLMs. c). Việc phân bổ tỷ lệ dữ liệu tiền huấn luyện cho các mô hình quy mô lớn là chìa khóa và thách thức, thường dựa vào kinh nghiệm trước đó. Việc lấy mẫu lại dữ liệu sẽ có tác động đến phân phối dữ liệu gốc.

Chúng tôi giới thiệu khái niệm source prompt (SP) để cải thiện hiệu suất của PLMs được huấn luyện từ các kho dữ liệu đa dạng, khổng lồ và không cân bằng. Thay vì sử dụng các chiến lược lấy mẫu lại cẩn thận hoặc thăm dò tỷ lệ kho dữ liệu tốt, chúng tôi đề xuất rằng nguồn kho dữ liệu phục vụ như một chỉ báo rõ ràng của phân phối dữ liệu không đồng nhất của các kho dữ liệu rộng lớn. Source prompt được sử dụng kết hợp với chuỗi đầu vào để chỉ ra nguồn của dữ liệu, được thực hiện trong cả quá trình tiền huấn luyện và các nhiệm vụ downstream. Ví dụ, khi tiền huấn luyện một mô hình như BERT trên Wikipedia và BookCorpus đồng thời, chúng ta có thể chèn các prompts '[WIKI]' và '[BOOK]' trước đầu vào từ Wikipedia và BookCorpus tương ứng. Đối với một tập dữ liệu nhiệm vụ downstream cho trước, chúng ta gán một trong các nguồn kho dữ liệu tiền huấn luyện và chèn SP tương ứng. Nguồn này có thể được gán thủ công hoặc tự động. Phương pháp của chúng tôi đáng được nhấn mạnh do bốn ưu điểm chính:

1. Khả năng tổng quát. Nó có thể được triển khai trực tiếp trên các kho dữ liệu tiền huấn luyện. Hoạt động của nó hoàn toàn phụ thuộc vào các nguồn của dữ liệu tiền huấn luyện, không cần xem xét bất kỳ đặc điểm nhiệm vụ downstream nào.

2. Sử dụng dữ liệu. Nó đảm bảo rằng tất cả các kho dữ liệu có thể được sử dụng đầy đủ, loại bỏ yêu cầu lấy mẫu lại dữ liệu phức tạp.

3. Đơn giản. Phương pháp của chúng tôi không cần tiền xử lý và các mô-đun bổ sung, tiết kiệm tài nguyên tính toán đáng kể.

4. Khả năng ứng dụng. Phương pháp của chúng tôi và các mô hình được tiền huấn luyện có thể được tích hợp dễ dàng vào các framework hiện có, không cần thay đổi cấu trúc mô hình và quy trình huấn luyện.

Các thí nghiệm của chúng tôi tiết lộ rằng phương pháp của chúng tôi mang lại PLMs vượt trội sau khi tiền huấn luyện trên các kho dữ liệu đa dạng. Những mô hình này vượt trội đáng kể trong các nhiệm vụ downstream đa dạng.

Đóng góp của chúng tôi được tóm tắt như sau:
• Chúng tôi đề xuất cơ chế Source Prompt, được thiết kế để tận dụng sự đa dạng nguồn để nâng cao hiệu suất của PLMs trong các nhiệm vụ downstream.
• Chúng tôi thực hiện khái niệm Source Prompt trên ba kiến trúc Transformer phổ biến: Encoder-Only, Encoder-Decoder, và Decoder-Only.
• Chúng tôi thực hiện các thí nghiệm trên nhiều kho dữ liệu tiền huấn luyện và các tập dữ liệu downstream khác nhau để xác minh hiệu quả của SP. Kết quả cho thấy rằng các PLMs được tiền huấn luyện với SP trên các kho dữ liệu khác nhau đạt được cải thiện đáng kể trong các cài đặt khác nhau.

Công trình liên quan
Trong phần này, chúng tôi giới thiệu hai hướng công trình liên quan, bao gồm các nỗ lực về sự đa dạng dữ liệu trong các cài đặt nhiệm vụ đơn, và các phương pháp prompt-tuning cho học đa nhiệm vụ dựa trên PLM.

Sự đa dạng dữ liệu trong các cài đặt nhiệm vụ đơn
Lựa chọn dữ liệu Lựa chọn dữ liệu thường được sử dụng để giải quyết các vấn đề phát sinh từ sự đa dạng dữ liệu trong các nhiệm vụ cụ thể (Silva et al. 2018; Wang et al. 2018b; Aharoni and Goldberg 2020). Kỹ thuật này bao gồm việc chọn các mẫu huấn luyện dựa trên sự giống nhau của chúng với tập validation hoặc một tập dữ liệu trong-lĩnh vực đáng tin cậy.

Ví dụ, Aharoni and Goldberg (2020) sử dụng truy xuất dựa trên khoảng cách sử dụng các embedding câu được tạo ra bởi PLMs để lựa chọn dữ liệu trong-lĩnh vực. van der Wees, Bisazza, and Monz (2017) trình bày lựa chọn dữ liệu động để nâng cao dịch máy thần kinh (NMT) và giới thiệu tinh chỉnh dần dần, vượt trội hơn lựa chọn dữ liệu tĩnh truyền thống. Wang et al. (2018b) mở rộng các kỹ thuật để đánh giá và lựa chọn dữ liệu cho NMT lĩnh vực và thích ứng chúng cho huấn luyện NMT khử nhiễu, sử dụng dữ liệu đáng tin cậy và một chương trình khử nhiễu dựa trên lựa chọn dữ liệu trực tuyến.

Tuy nhiên, trong khi lựa chọn dữ liệu có thể giải quyết các thách thức của sự đa dạng dữ liệu trong các nhiệm vụ cụ thể, nó không phù hợp cho SD trong quá trình tiền huấn luyện. Điều này là do nó giả định kiến thức về tập đánh giá cho các nhiệm vụ downstream, nhưng không chắc chắn những nhiệm vụ nào sẽ được các nhà nghiên cứu sử dụng PLMs được tiền huấn luyện nhắm tới trong các giai đoạn tiếp theo.

Học tập ensemble EnsLM (Duan et al. 2021) đề xuất một mô hình chủ đề auto-encoding để phân cụm dữ liệu, và áp dụng học tập ensemble với mô-đun điều chế trọng số để phù hợp với các cụm dữ liệu khác nhau. Mặc dù nó cải thiện hiệu suất cross-domain, bước phân cụm dữ liệu và mô-đun điều chế trọng số của nó tốn thời gian và bất tiện để được PLMs áp dụng.

Sự đa dạng lĩnh vực Một loại sự đa dạng dữ liệu phổ biến là sự đa dạng lĩnh vực. Các phương pháp trước đây về dữ liệu đa lĩnh vực thường giả định rằng các nhãn lĩnh vực được định nghĩa tốt và được gán cho mỗi mẫu (Wright and Augenstein 2020; Du et al. 2020; Jiang et al. 2020). Để cải thiện khả năng thích ứng của mô hình NMT với các lĩnh vực khác nhau, Jiang et al. (2020) đề xuất một mô hình NMT đa lĩnh vực mới sử dụng các mô-đun riêng lẻ cho mỗi lĩnh vực, trên đó họ áp dụng trộn lĩnh vực cấp từ, thích ứng và cấp lớp. Để giải quyết vấn đề BERT không thể thích ứng với các đặc trình lĩnh vực cho việc chuyển giao cross domain trong các nhiệm vụ phân loại cảm xúc cross domain, (Du et al. 2020) thiết kế một quy trình post-training, chứa nhiệm vụ mô hình ngôn ngữ có mặt nạ lĩnh vực đích và một nhiệm vụ phân biệt lĩnh vực tương tự mới cho tiền huấn luyện. Mặc dù các phương pháp trên hoạt động tốt trong các nhiệm vụ lĩnh vực downstream cụ thể, chúng không phù hợp cho tiền huấn luyện với sự đa dạng nguồn vì các lý do sau. Thứ nhất, chúng thường chỉ thiết kế cho tập dữ liệu đa lĩnh vực của một nhiệm vụ nhất định hoặc một số nhiệm vụ cụ thể, thay vì kịch bản tiền huấn luyện mô hình ngôn ngữ. Thứ hai, những nhãn lĩnh vực được định nghĩa trước này không phải lúc nào cũng chính xác hoặc thậm chí có sẵn (Aharoni and Goldberg 2020), đặc biệt đối với các tập dữ liệu hoang dã, trong đó dữ liệu đến từ các nguồn khác nhau, chẳng hạn như tin tức internet, đánh giá sản phẩm và cuộc trò chuyện hàng ngày (Duan et al. 2021).

Học đa nhiệm vụ với Prompts
Prompts đã được sử dụng rộng rãi để khai thác tốt hơn PLMs trong các nhiệm vụ downstream dưới các cài đặt khác nhau. Chúng có thể được áp dụng trong quá trình tiền huấn luyện, tinh chỉnh và thăm dò downstream. Brown et al. (2020) cho thấy rằng việc sử dụng các ví dụ minh họa hoặc hướng dẫn làm prompts có thể làm cho GPT-3 hoàn thành một số nhiệm vụ dưới các cài đặt few-shot hoặc zero-shot. Sanh et al. (2021) gợi ý rằng các kho dữ liệu tiền huấn luyện khổng lồ chứa dữ liệu liên quan đến nhiệm vụ khác nhau, và việc prompting phù hợp giúp PLMs nhớ lại dữ liệu đó trong các ứng dụng downstream. Nói cách khác, prompts phục vụ như một cầu nối giữa các kho dữ liệu tiền huấn luyện và các nhiệm vụ downstream.

Do đó, nhiều nỗ lực gần đây đã xem xét việc sử dụng prompts cho học đa nhiệm vụ. Prefix-tuning (Li and Liang 2021) đóng băng PLMs và chỉ điều chỉnh các prompts cụ thể nhiệm vụ cho các nhiệm vụ downstream. T0 (Sanh et al. 2021) tinh chỉnh PLMs trên một tập dữ liệu được prompted lớn bao gồm nhiều nhiệm vụ, đạt được hiệu suất zero-shot mạnh trên một số nhiệm vụ. PPT (Gu et al. 2021) tổng quát hóa ba loại nhiệm vụ tiền huấn luyện để học prompts trên các tập dữ liệu không được gán nhãn lớn, và chuyển giao những prompts này đến các tập dữ liệu nhiệm vụ zero-shot thông qua khởi tạo. UL2 (Tay et al. 2022) đề xuất Mixture-of-Denoisers (MoD), một mục tiêu tiền huấn luyện kết hợp các mô hình tiền huấn luyện đa dạng với nhau, sử dụng một tiền tố cụ thể cho các phương pháp tiền huấn luyện khác nhau. Họ tiếp tục giới thiệu một khái niệm chuyển đổi chế độ, trong đó tinh chỉnh downstream được liên kết với các sơ đồ tiền huấn luyện cụ thể. UL2 vượt trội hơn T5 và các mô hình giống GPT trong nhiều cài đặt đa dạng.

Kịch bản đa dạng nhiệm vụ gần với SD trong tiền huấn luyện. Các phương pháp trên cho phép PLMs nhớ kiến thức không đồng nhất từ các nhiệm vụ khác nhau và truy xuất kiến thức liên quan trong các nhiệm vụ downstream bằng các prompts cụ thể nhiệm vụ. Được truyền cảm hứng từ những nỗ lực này, chúng tôi do đó đề xuất source prompts để giải quyết vấn đề SD trong các kho dữ liệu tiền huấn luyện.

--- TRANG 3 ---
Phương pháp
Trong phần này, chúng tôi mô tả cách source prompts có thể được áp dụng để nâng cao việc tiền huấn luyện mô hình ngôn ngữ với sự đa dạng nguồn. Đầu tiên, chúng tôi mô tả cách source prompt (SP) được triển khai trong giai đoạn tiền huấn luyện. Sau đó, chúng tôi mô tả cách mô hình tiền huấn luyện với SP được tinh chỉnh trong giai đoạn nhiệm vụ downstream.

Cơ sở
Các Mô hình Ngôn ngữ Tiền huấn luyện (PLMs) đã dẫn đến việc nâng cao hiệu suất đáng kể trong các nhiệm vụ Xử lý Ngôn ngữ Tự nhiên (NLP). Sự cải thiện này chủ yếu đạt được thông qua việc sử dụng các mạng thần kinh mở rộng được tiền huấn luyện trên một kho dữ liệu rộng lớn dữ liệu không được gán nhãn với một mục tiêu tự giám sát. Các PLMs đương đại chủ yếu tận dụng kiến trúc transformer (Vaswani et al. 2017). Có hai mục tiêu tự giám sát chính: Masked Language Model (MLM) và Causal Language Model (CLM). Phương pháp MLM bao gồm việc che một số token trong một câu và dự đoán chúng thông qua phân loại, trong khi CLM dự đoán token tiếp theo dựa trên chuỗi token của những cái trước đó.

Trong nghiên cứu của chúng tôi, chúng tôi giới thiệu phương pháp của chúng tôi cho ba mô hình khác nhau: encoder-only, encoder-decoder, và decoder-only. Các mô hình encoder-only và encoder-decoder là các thành phần quan trọng của MLMs, trong khi mô hình decoder-only là yếu tố cốt lõi của CLMs.

Tiền Huấn Luyện với Source Prompt
Hướng tới các PLMs mạnh mẽ hơn, một thực hành phổ biến và thành công là xây dựng các mô hình khổng lồ hơn và tiền huấn luyện chúng trên các kho dữ liệu đa dạng và khổng lồ hơn. Một kho dữ liệu đa dạng chủ yếu được tạo ra bằng cách hội tụ những kho nhỏ từ nhiều nguồn. Do đó, kho dữ liệu C chứa nhiều tập con từ các nguồn khác nhau:

C = C1 ∪ C2 ∪ ... ∪ Cm, (1)

trong đó mỗi Ci là một kho dữ liệu con từ một nguồn cụ thể, và m là số lượng tập con.

Ví dụ, các kho dữ liệu của BERT được cấu thành từ m = 2 tập dữ liệu, Wikipedia và BookCorpus:

CBERT = Wikipedia ∪ BookCorpus. (2)

Một kho dữ liệu C (hoặc kho dữ liệu con Ci) là một tập hợp n đoạn văn bản:
C = {t1, t2, ..., tn}. (3)

Chúng tôi gán mỗi kho dữ liệu con Ci một tên Ni chỉ ra nguồn của nó. Sau đó, đối với mỗi tj trong Ci, chúng tôi định nghĩa Ci là kho dữ liệu nguồn (hoặc nguồn) của tj và Ni là tên nguồn của nó. Một cách đơn giản nhưng hiệu quả để đặt tên cho những nguồn này là sử dụng từ viết tắt của chúng, cụ thể là abbreviation SP, chẳng hạn như '[WIKI]' cho Wikipedia và '[BOOK]' cho BookCorpus. Trên thực tế, phương pháp của chúng tôi rất bền vững với các phương pháp đặt tên khác nhau, và thậm chí có thể sử dụng những chữ cái vô nghĩa để biểu thị các nguồn thay thế, chẳng hạn như A, B và C.

SP Tiền huấn luyện trên các Mô hình Encoder-Only hoặc Encoder-Decoder
Chúng tôi đặt một source prompt ở đầu mỗi văn bản trong quá trình tiền huấn luyện, do đó thông báo cho PLMs về nguồn gốc của văn bản. Đối với mỗi tj trong Ci, SP của nó tương ứng với tên kho dữ liệu Ni. Chúng tôi tách source prompt và đầu vào gốc bằng cách sử dụng một dấu phân cách riêng biệt. Do đó, đầu vào được prompted nguồn t̂j trở thành:

t̂j = [Ni; −; tj], (4)

trong đó [·; ·] biểu thị việc nối chuỗi. Ví dụ, xem xét văn bản sau được trích xuất từ một kho dữ liệu tin tức:
"Người phát ngôn của Thủ tướng Anh Johnson: chúng tôi hy vọng sẽ thực hiện những sửa đổi đáng kể đối với thỏa thuận Bắc Ireland. Chúng tôi tin rằng điều đó là khả thi trong khuôn khổ của thỏa thuận."

Chúng tôi thêm tiền tố cho văn bản này với tên nguồn của nó, News:
"News − Người phát ngôn của Thủ tướng Anh Johnson: chúng tôi hy vọng sẽ thực hiện những sửa đổi đáng kể đối với thỏa thuận Bắc Ireland. Chúng tôi tin rằng điều đó là khả thi trong khuôn khổ của thỏa thuận"

--- TRANG 4 ---
Sau đó, văn bản được prompted nguồn này được đưa vào giai đoạn tiền huấn luyện của PLMs. Do đó, PLMs có thể dự đoán các từ bị che với sự hỗ trợ của SP, cho phép chúng học các phong cách ngôn ngữ phụ thuộc vào các nguồn khác nhau. Đồng thời, các biểu diễn token trong SP được tối ưu hóa, dẫn đến sự gia tăng kiến thức cụ thể nguồn cho cả ứng dụng tiền huấn luyện và downstream. Hơn nữa, chúng tôi giới thiệu masked source prediction (MSP), một mục tiêu tiền huấn luyện sáng tạo cho tiền huấn luyện đa nguồn. Trong quá trình này, các source prompts được che ngẫu nhiên với một xác suất nhất định, yêu cầu PLMs dự đoán nguồn bị che dựa trên ngữ cảnh. Nhiệm vụ này buộc PLMs phải học các đặc điểm liên quan đến nguồn. Nó có thể được dễ dàng kết hợp với mục tiêu MLM và phát sinh chi phí bổ sung tối thiểu.

SP Tiền huấn luyện trên các Mô hình Decoder-Only
Mô hình decoder-only, thiếu cơ chế attention hai chiều, không thể áp dụng MLM. Chúng tôi đề xuất hai loại SP cho các mô hình như vậy:

1. SP Đặt SP ở đầu văn bản cho phép SP hỗ trợ trong việc dự đoán nội dung của văn bản.
2. Post SP Đặt SP ở cuối văn bản cho phép dự đoán nguồn dựa trên nội dung của văn bản.

Chúng tôi sử dụng phương pháp next-token-prediction để huấn luyện những mô hình này.

Cần thiết phải nhấn mạnh rằng trong giai đoạn tiền huấn luyện của bất kỳ kiến trúc nào, SP được tích hợp ngẫu nhiên, và một token đặc biệt được xen kẽ giữa SP và văn bản gốc.

Tinh chỉnh với Source Prompts
Việc áp dụng PLMs với SP cho một tập dữ liệu downstream cụ thể bao gồm việc gán source prompt tiền huấn luyện có liên quan nhất cho tập dữ liệu. Một số tập dữ liệu bắt nguồn từ các nguồn cụ thể hoặc lĩnh vực liên quan chặt chẽ đến một trong các nguồn tiền huấn luyện, ví dụ, một tập dữ liệu phân loại tin tức. Do đó, việc lựa chọn thủ công một SP cho các tập dữ liệu như vậy là khả thi. Ngược lại, các tập dữ liệu khác có thể có ít liên quan đến các nguồn tiền huấn luyện hoặc có thể bao gồm các mẫu từ các nguồn khác nhau. Trong những trường hợp này, chúng tôi đề xuất hai phương pháp để gán source prompts cho các tập dữ liệu downstream:

Manual SP Thường thì, chúng ta biên soạn các tập dữ liệu downstream từ một nguồn duy nhất, được mô tả chi tiết trong mô tả của nó. Trong tình huống này, chúng ta có thể gán thủ công cho nó một nguồn tiền huấn luyện phù hợp, nếu có. Ví dụ, khi tiền huấn luyện PLMs trên Wikipedia và BookCorpus, tương tự như BERT, và tinh chỉnh các mô hình trên tập dữ liệu QNLI (Wang et al. 2018a) (một tập dữ liệu được xuất từ Wikipedia một cách chính xác), chúng ta có thể trực tiếp sử dụng SP [WIKI] cho nó. Sau khi lựa chọn SP, chúng ta chèn SP trước các văn bản của tập dữ liệu downstream, phù hợp với quá trình tiền huấn luyện.

Auto SP Hoặc là, các nguồn tập dữ liệu downstream có thể không được xác định, trộn lẫn, hoặc khác biệt đáng kể so với các nguồn tiền huấn luyện. Đối với những tình huống này, chúng tôi đề xuất phương pháp Auto SP, như được minh họa trong Hình 1. Phương pháp Auto SP tận dụng mục tiêu MSP của chúng tôi trong quá trình tiền huấn luyện, cho phép MLMs tự dự đoán các nguồn phù hợp nhất. Cụ thể, chúng ta ban đầu nhập vào việc nối [[MASK]; −; t] của mặt nạ nguồn và đầu vào gốc t. Sau đó chúng ta yêu cầu PLMs dự đoán nguồn văn bản của mỗi mẫu, bao gồm cả dữ liệu huấn luyện và kiểm tra. Hoặc dự đoán nguồn với Next Token Prediction cho CLMs. Cuối cùng, chúng ta thay thế nguồn bị che (MASK) với nguồn được dự đoán, sử dụng những mẫu được thay thế này để tinh chỉnh và dự đoán.

No SP Ngoài ra, có thể sử dụng mô hình được tiền huấn luyện một cách thông thường mà không có bất kỳ SP nào. Thứ nhất, việc áp dụng SP trong quá trình tiền huấn luyện cho phép mô hình hiểu kho dữ liệu nguồn một cách hiệu quả. Thứ hai, việc bổ sung ngẫu nhiên SP tùy chọn trong các cài đặt mang lại một mức độ tổng quát cho mô hình, bất kể sự hiện diện của SP. Do đó, ngay cả khi không có việc triển khai SP trong các nhiệm vụ downstream, các mức hiệu suất tương đương có thể đạt được như với SP.

Thí nghiệm
Trong phần này, chúng tôi đánh giá hiệu quả của phương pháp source prompt của chúng tôi dưới các cài đặt khác nhau. Nhìn chung, các PLMs được tiền huấn luyện với phương pháp của chúng tôi trên các kho dữ liệu đa dạng đạt được những cải thiện đáng kể.

Chúng tôi bắt đầu bằng việc phác thảo các cài đặt nhất quán được sử dụng trong tất cả các thí nghiệm. Sau đó, chúng tôi thực hiện các nhiệm vụ thí nghiệm sau: a). Xác minh hiệu quả của phương pháp đề xuất của chúng tôi. b). So sánh các tác động của các chính sách đặt tên đa dạng cho các nguồn kho dữ liệu tiền huấn luyện, chứng minh tính bền vững của SP đối với những chính sách khác nhau này. c). Phân tích các xác suất masking khác nhau cho SP, chứng thực hiệu quả của MSP. d). Đánh giá các tác động của các phương pháp gán SP khác nhau cho các tập dữ liệu downstream, tiết lộ rằng auto SP là phương pháp hiệu quả nhất. e). Xác nhận khả năng tổng quát của phương pháp của chúng tôi trên các kiến trúc mô hình khác nhau, các kho dữ liệu tiền huấn luyện và các benchmark downstream. f). Điều tra các tác động của các phương pháp SP trên các kho dữ liệu cụ thể lĩnh vực hoặc tổng quát cho các mô hình ngôn ngữ lớn kiến trúc decoder-only.

Cài đặt chung
Kho dữ liệu Chúng tôi xem xét ba kho dữ liệu đa dạng từ nhiều nguồn cho tiền huấn luyện, bao gồm BBT-FinCorpus2, CLUECorpusSmall (Xu, Zhang, and Dong 2020) và WuDaoCorpora (Yuan et al. 2021), đại diện cho các kho dữ liệu cụ thể lĩnh vực hoặc kho dữ liệu tổng quát điển hình, tương ứng. Thông tin chi tiết về kho dữ liệu được hiển thị trong Phụ lục.

Benchmark Chúng tôi sử dụng BBT-FinCUGE và CLUE (Xu et al. 2020) làm benchmark đánh giá của chúng tôi. BBT-FinCUGE là một benchmark đánh giá tài chính Trung Quốc bao gồm năm nhiệm vụ hiểu và ba nhiệm vụ sinh. Các nhiệm vụ hiểu bao gồm trích xuất chủ thể sự kiện, nhận dạng cảm xúc, phân loại tin tức, tin tức tiêu cực và nhận dạng chủ thể, và trích xuất mối quan hệ. Các nhiệm vụ sinh bao gồm QA nhân quả, QA sự kiện và tóm tắt tin tức. CLUE là một benchmark đánh giá NLP Trung Quốc tổng quát bao gồm chín nhiệm vụ hiểu, bao gồm tương tự ngữ nghĩa, phân loại văn bản, đọc hiểu và các nhiệm vụ khác. Đối với tất cả các benchmark đánh giá, chúng tôi tinh chỉnh PLMs để đánh giá, và lấy điểm trung bình trên tập kiểm tra làm cơ sở so sánh chính.

Triển khai Chúng tôi mô tả chi tiết các giai đoạn tiền huấn luyện và tinh chỉnh của chúng tôi trong phần này.

Các kiến trúc nền tảng được chọn của chúng tôi bao gồm hai Masked Language Models (MLMs) thông thường, BERT và T5, cũng như một trong những Causal Language Models (CLMs) mới nhất, OpenLLaMA-3b. BERT ví dụ hóa Mô hình Encoder-Only, T5 thể hiện Mô hình Encoder-Decoder, trong khi OpenLLaMA-3b biểu thị Mô hình Decoder-Only. Việc triển khai những mô hình này của chúng tôi dựa nhiều vào Hugging Face Transformers. Các tham số cấu hình cho BERT-base và T5-base phù hợp với các triển khai gốc của chúng. Đối với OpenLLaMA-3b, chúng tôi tích hợp một từ vựng mở rộng để bao gồm các token Trung Quốc, như được đề xuất bởi nghiên cứu trước đây.

Chúng tôi thực hiện tiền huấn luyện cho ba mô hình trên các kho dữ liệu cụ thể lĩnh vực hoặc kho dữ liệu tổng quát, và sau đó đánh giá hiệu suất của chúng trên các benchmark như BBT-FinCUGE hoặc CLUE. Một mô tả toàn diện về việc triển khai được cung cấp trong Phụ lục. Để đảm bảo độ tin cậy của các phát hiện của chúng tôi, tất cả các thí nghiệm được tiến hành ba lần và kết quả trung bình được báo cáo.

Hiệu quả tổng thể của SP
Để xác minh hiệu quả cơ bản của phương pháp SP dưới khuôn khổ tiền huấn luyện và tinh chỉnh, chúng tôi tiền huấn luyện T5 trên BBT-FinCorpus và tinh chỉnh nó trên benchmark BBT-FinCUGE. Chúng tôi thiết lập bốn nhóm thí nghiệm: nhóm A, không sử dụng SP ở cả hai giai đoạn, nhóm B, chỉ sử dụng SP ở giai đoạn tiền huấn luyện, và các nhóm C và D, sử dụng SP ở cả hai giai đoạn và áp dụng manual SP và auto SP tương ứng ở giai đoạn tinh chỉnh.

Bảng 3 hiển thị kết quả, từ đó chúng tôi đưa ra các quan sát sau: (1) Với source prompts, PLMs được tiền huấn luyện trên các kho dữ liệu đa dạng đạt được hiệu suất tốt hơn đáng kể trên gần như tất cả các tập dữ liệu. Điểm trung bình của chúng (74.67-75.88) có lợi thế đáng kể so với nhóm A (71.76), điều này hoàn toàn chứng minh hiệu quả của phương pháp SP, đặc biệt là với gần như không có chi phí tính toán bổ sung. (2) Việc giới thiệu SP trong giai đoạn tinh chỉnh tiếp tục cải thiện hiệu suất mô hình, như được thể hiện bằng cách so sánh nhóm B với các nhóm C, D và E.

Tính bền vững của các Chính sách Đặt tên Nguồn
Như đã đề cập trong Phần Phương pháp, chúng tôi không có phương pháp xác định để đặt tên nguồn của mỗi kho dữ liệu. Một cách tương đối đơn giản là sử dụng từ viết tắt thủ công của nguồn kho dữ liệu. Tuy nhiên, chúng tôi cho thấy với các thí nghiệm rằng phương pháp của chúng tôi bền vững với các chính sách đặt tên nguồn khác nhau, cụ thể là các token cụ thể được sử dụng để đại diện cho các nguồn. Có nghĩa là, hiệu quả của SP bắt nguồn từ việc xác định các nguồn, thay vì thông tin văn bản trong tên của chúng.

Cụ thể, chúng tôi thiết kế hai thí nghiệm bổ sung để so sánh. Thí nghiệm đầu tiên là alphabet SP vô nghĩa, có nghĩa là, chúng tôi thay thế các tên cụ thể của các nguồn kho dữ liệu bằng các chữ cái vô nghĩa như A, B, C, v.v. Do đó, mô hình chỉ có thể có được việc xác định nguồn của các kho dữ liệu, mà không có thông tin văn bản cụ thể của mỗi nguồn. Thí nghiệm thứ hai là misplaced SP, có nghĩa là, chúng tôi cố ý làm rối tên của các nguồn kho dữ liệu (ví dụ, đặt SP của tất cả các kho dữ liệu tin tức là "comments"). Trong tất cả các cài đặt, chúng tôi kiểm soát số lượng token prompt của các nguồn khác nhau bằng nhau.

Bảng 5 hiển thị kết quả trên BERT. Kết quả chứng minh rằng việc sử dụng alphabet SP và misplaced SP hầu như không giảm hiệu suất, so với abbreviation SP, vẫn vượt xa baseline không có SP. Những kết quả này gợi ý rằng SP bền vững với các chính sách tên khác nhau của kho dữ liệu. Do đó, SP hiệu quả vì việc xác định các nguồn, thay vì thông tin văn bản trong tên của chúng. Do đó, trong các ứng dụng thực tế, các nguồn có thể được đặt tên theo ý muốn, điều này ít ảnh hưởng đến hiệu suất.

Hiệu quả của Mask Source Prediction
Chúng tôi nghiên cứu hiệu quả của mục tiêu masked source prediction (MSP) bằng cách tiền huấn luyện các mô hình với xác suất mask khác nhau của SP và so sánh hiệu suất của chúng trên benchmark.

Chúng tôi xem xét ba giá trị {0, 0.15, 0.3} của xác suất mask P. Đặt P = 0 có nghĩa là các mô hình được tiền huấn luyện mà không có mục tiêu MSP. Chúng tôi sử dụng abbreviation SP cho tiền huấn luyện và manual SP cho tinh chỉnh. Như được hiển thị trong bảng 4, hiệu suất với P = 0 (không có MSP) thấp hơn đáng kể so với những cái khác, và hiệu suất với P = 0.3 tốt hơn một chút so với P = 0.15. Những điều này xác nhận hiệu quả của mục tiêu MSP của chúng tôi, và gợi ý rằng xác suất masking SP cao hơn khuyến khích mô hình phân biệt tốt hơn các văn bản từ các nguồn khác nhau và học các đặc trưng liên quan đến nguồn.

Gán SP cho các Nhiệm vụ Downstream
Như đã mô tả, chúng tôi đề xuất hai phương pháp để gán SP trong các tập dữ liệu downstream: manual SP và auto SP. Thí nghiệm này so sánh các tác động của các phương pháp gán SP khác nhau. Chúng tôi cũng thiết lập một nhóm kiểm soát với một SP được lấy mẫu ngẫu nhiên từ các nguồn tiền huấn luyện cho mỗi mẫu, được gọi là random SP. Bảng 3 cho thấy rằng auto SP vượt trội hơn manual SP (hàng C và D). Chúng tôi cho rằng điều này là do auto SP tận dụng thông tin liên quan đến nguồn được học bởi mô hình, và áp dụng thích ứng SP phù hợp nhất cho mỗi mẫu, trong khi manual SP chỉ được gán ở cấp độ tập dữ liệu. Kết luận này được xác nhận thêm bởi các hàng C và D trong Bảng 5 và Bảng 6.

Khả năng tổng quát của SP
Để xác minh việc tổng quát của phương pháp SP, chúng tôi chủ yếu tiến hành các thí nghiệm từ hai chiều, bao gồm các kiến trúc mô hình khác nhau và các lĩnh vực kho dữ liệu khác nhau. Cụ thể, để xác minh việc tổng quát của SP đến các kiến trúc mô hình khác nhau, chúng tôi áp dụng các phương pháp SP cho các mô hình BERT và T5 tương ứng. Để xác minh việc tổng quát của SP đến các lĩnh vực khác nhau, chúng tôi tiến hành các thí nghiệm trong cả lĩnh vực tài chính và lĩnh vực tổng quát. Kho dữ liệu và benchmark được sử dụng là BBT-FinCorpus và BBT-FinCUGE trong lĩnh vực tài chính, và là CLUECorpusSmall và CLUE trong lĩnh vực tổng quát.

Bảng 3 và Bảng 5 cho thấy rằng các mô hình của chúng tôi đạt được cải thiện đáng kể dưới cả hai kiến trúc mô hình. Bên cạnh đó, nó được hiển thị trong Bảng 5 và Bảng 6 rằng mô hình của chúng tôi có hiệu ứng mong đợi trong cả hai lĩnh vực. Do đó, có thể kết luận rằng phương pháp của chúng tôi đủ tổng quát để được áp dụng rộng rãi cho các kiến trúc mô hình và lĩnh vực kho dữ liệu khác nhau.

SP trên các LLMs Decoder-Only
Chúng tôi tiến hành các thí nghiệm có hệ thống trên mô hình OpenLLaMA-3b để kiểm tra ảnh hưởng của SP trên LLM decoder-only. Để khám phá các tác động của hai phương pháp SP, chúng tôi tiến hành các thí nghiệm trên hai SP riêng biệt. Bảng 7 và Bảng 8 mô tả kết quả thí nghiệm của OpenLLaMA-3b trong lĩnh vực tài chính và tổng quát, tương ứng. Tất cả các cài đặt SP đều đạt được điểm vượt qua baseline đã đặt trước trong cả hai thí nghiệm, ngụ ý việc nâng cao hiệu suất mô hình trong quá trình tiền huấn luyện do việc tích hợp SP. Hơn nữa, tất cả các quy trình tinh chỉnh downstream được thực hiện mà không có SP, do đó làm nổi bật tính bền vững của SP.

--- TRANG 8 ---
Kết luận
Trong bài báo này, chúng tôi đầu tiên xác định các tác động phụ của việc tăng sự đa dạng kho dữ liệu cho việc tiền huấn luyện PLMs. Để vượt qua vấn đề này, chúng tôi đề xuất source prompt (SP), một phương pháp dễ dàng, hiệu quả và có tác dụng để thúc đẩy việc tiền huấn luyện phối hợp trên các kho dữ liệu như vậy, đây là một prompt được thêm vào trước các đầu vào của PLMs để xác định nguồn của chúng. Hơn nữa, chúng tôi nghiên cứu kỹ lưỡng các chính sách đặt tên khác nhau của SP tiền huấn luyện và chiến lược khác nhau để gán SP cho ứng dụng downstream, cũng như đề xuất một mục tiêu tiền huấn luyện mới có tên là masked source prediction. Kết quả của các thí nghiệm mở rộng xác thực hiệu quả, tính bền vững và khả năng tổng quát của SP, cũng như lợi ích của MSP.

Hạn chế
Trước hết, "nguồn" là một khái niệm tương đối trừu tượng. Đối với các kho dữ liệu dựa trên common crawl như C4, thông tin nguồn của chúng phần lớn không thể sử dụng được vì dữ liệu của chúng được thu thập từ hàng triệu trang web. Do đó, phương pháp hiện tại của chúng tôi bị giới hạn trong kịch bản mà một số lượng nhất định các kho dữ liệu nhỏ được hợp nhất với nhau để tạo thành một kho dữ liệu lớn. Thứ hai, do quy mô sức mạnh tính toán mà chúng tôi có thể có được, quy mô tham số và số lượng token huấn luyện của PLMs mà chúng tôi sử dụng khá hạn chế. Vẫn cần được nghiên cứu liệu phương pháp của chúng tôi có hoạt động cho các PLMs quy mô lớn hay không. Cuối cùng nhưng không kém phần quan trọng, vẫn cần được khám phá sâu hơn về hiệu quả của việc giới thiệu SP bắt nguồn từ đâu. Trong tương lai, chúng tôi sẽ tiếp tục nghiên cứu hiệu ứng của SP trên các PLMs quy mô lớn, và điều tra hiệu quả của SP trong các nhiệm vụ NLP khác như phân tích cảm xúc cross-domain.

Tài liệu tham khảo
[Các tài liệu tham khảo được dịch theo format tương tự như trong bản gốc]

--- TRANG 9 và 10 ---
[Tiếp tục dịch phần còn lại của tài liệu tham khảo và phụ lục với cấu trúc tương tự]

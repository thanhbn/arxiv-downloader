# 2308.05342.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/prompt/2308.05342.pdf
# Kích thước tệp: 523982 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Prompting Siêu nhận thức Cải thiện Hiểu biết
trong các Mô hình Ngôn ngữ Lớn
Yuqing Wang
Đại học Stanford
ywang216@stanford.eduYun Zhao
Meta Platforms, Inc.
yunzhao20@meta.com
Tóm tắt
Trong các Mô hình Ngôn ngữ Lớn (LLMs), đã có những tiến bộ nhất quán trong hiệu suất cụ thể theo tác vụ, chủ yếu bị ảnh hưởng bởi thiết kế prompt hiệu quả. Những tiến bộ gần đây trong prompting đã nâng cao khả năng lý luận trong các tác vụ thâm dụng logic cho LLMs, tuy nhiên khả năng hiểu biết tinh tế của các mô hình này, quan trọng cho việc xử lý và diễn giải thông tin phức tạp, vẫn chưa được khám phá đầy đủ. Trong nghiên cứu này, chúng tôi giới thiệu Metacognitive Prompting (MP), một chiến lược được lấy cảm hứng từ các quy trình lý luận nội tâm của con người. Sử dụng MP, LLMs trải qua một loạt các đánh giá có cấu trúc, tự nhận thức một cách hệ thống, dựa trên cả kiến thức vốn có rộng lớn của chúng và những hiểu biết mới. Chúng tôi tiến hành các thí nghiệm rộng rãi trên bốn LLMs phổ biến: Llama2, PaLM2, GPT-3.5, và GPT-4, trên mười bộ dữ liệu hiểu biết ngôn ngữ tự nhiên (NLU) từ các benchmark GLUE, SuperGLUE, BLUE, và LexGLUE. Ngoài ra, chúng tôi so sánh phương pháp của mình với chain-of-thought prompting và các phiên bản nâng cao của nó. Kết quả cho thấy GPT-4 nhất quán vượt trội trong tất cả các tác vụ, trong khi các mô hình khác đã cho thấy tiến bộ đáng kể trong một số tác vụ khi được sử dụng kết hợp với MP. Hơn nữa, MP nhất quán vượt trội so với các phương pháp prompting hiện có trong cả các tác vụ NLU chung và theo lĩnh vực cụ thể. Nghiên cứu này nhấn mạnh tiềm năng để khuếch đại khả năng hiểu biết của LLMs và làm nổi bật lợi ích của việc phản ánh lý luận nội tâm của con người trong các tác vụ NLU. Dữ liệu và mã của chúng tôi có sẵn tại https://github.com/EternityYW/Metacognitive-Prompting.

1 Giới thiệu
Các Mô hình Ngôn ngữ Lớn (LLMs) đã có những tiến bộ đáng kể trong xử lý ngôn ngữ tự nhiên (NLP) trong những năm gần đây (Min et al., 2021; Zhao et al., 2023; Wang et al., 2023c). Tuy nhiên, khi các mô hình này phát triển, việc đơn giản tăng quy mô của chúng không nhất thiết nâng cao khả năng hiểu biết và lý luận của chúng (Rae et al., 2021). Việc đi sâu vào những phức tạp của thiết kế prompt đã nổi lên như một cách tiếp cận đầy hứa hẹn; nó không chỉ cạnh tranh với lợi ích của việc fine-tuning rộng rãi mà còn cung cấp những ưu thế rõ ràng về hiệu quả mẫu (Liu et al., 2023; Kojima et al., 2022).

Nhiều nỗ lực nghiên cứu đã khám phá rộng rãi thiết kế prompt, đặc biệt nhấn mạnh việc sử dụng các phương pháp Chain-of-Thought (CoT) (Wei et al., 2022) để thúc đẩy các bước lý luận trung gian. Điều này dẫn đến các biến thể như kỹ thuật Least-to-Most (Zhou et al., 2022), Self-consistency (Wang et al., 2022a), và Tree-of-Thoughts (ToT) (Yao et al., 2023). Những chiến lược này hiệu quả trong các bối cảnh được chỉ định nơi mục tiêu chính tập trung vào việc nâng cao khả năng lý luận rõ ràng trong các lĩnh vực như số học, thường thức, và lý luận tượng trưng, hướng dẫn LLMs thông qua một tiến trình logic của tư duy. Tuy nhiên, hiệu quả của chúng trong việc làm sâu sắc hiểu biết là hạn chế, vì lý luận liên quan đến việc kết nối các khái niệm một cách có phương pháp, trong khi hiểu biết đòi hỏi nắm bắt ngữ nghĩa cơ bản và ý nghĩa ngữ cảnh rộng hơn.

[Hình 1: Sự liên kết giữa các quy trình siêu nhận thức của con người và các giai đoạn của MP trong LLMs.]

Để thu hẹp khoảng cách trong việc nâng cao khả năng hiểu biết của LLMs, quan trọng cho việc giải quyết các tác vụ phức tạp, chúng tôi đề xuất Metacognitive Prompting (MP). Phương pháp này được thông báo bởi khái niệm siêu nhận thức, thường được định nghĩa là 'suy nghĩ về suy nghĩ'. Có nguồn gốc từ tâm lý học nhận thức, siêu nhận thức liên quan đến nhận thức và tự phản tư của một cá nhân về các quy trình nhận thức của họ. Cách tiếp cận của chúng tôi tích hợp các khía cạnh chính của quy trình siêu nhận thức con người vào LLMs. Hình 1 cho thấy sự tương đồng giữa các giai đoạn siêu nhận thức của con người và các bước hoạt động của phương pháp chúng tôi trong LLMs. Thay vì tập trung chỉ vào cơ chế của "làm thế nào" một phản hồi được tạo ra, phương pháp này đi sâu hơn vào lý do hoặc "tại sao" đằng sau nó. Phương pháp tiến hành như sau: 1) LLM diễn giải văn bản được cung cấp, một giai đoạn gợi nhớ đến sự hiểu biết của con người; 2) mô hình sau đó hình thành một phán đoán ban đầu, phản ánh giai đoạn mà con người tạo ra phán đoán dựa trên thông tin; 3) LLM đưa suy luận sơ bộ của mình vào đánh giá phê phán, một bước phù hợp với sự tự phản tư mà con người tham gia trong các quy trình nhận thức; 4) sau đánh giá nội tâm này, mô hình hoàn thiện quyết định của mình và làm rõ lý luận của nó, tương tự như việc ra quyết định và hợp lý hóa của con người; 5) cuối cùng, LLM đánh giá sự tự tin của mình trong kết quả, phản ánh cách con người đánh giá độ tin cậy của phán đoán và giải thích của họ. Mô hình này nâng cao chức năng của mô hình vượt ra ngoài lý luận hệ thống đơn giản, buộc nó phải tham gia vào các đánh giá nội tâm xác định độ sâu và sự liên quan của phản hồi.

Chúng tôi đã tiến hành thí nghiệm trên mười bộ dữ liệu NLU từ các benchmark GLUE (Wang et al., 2019b), SuperGLUE (Wang et al., 2019a), BLUE (Peng et al., 2019), và LexGLUE (Chalkidis et al., 2022) sử dụng một số LLMs hàng đầu, bao gồm Llama2 (Touvron et al., 2023), PaLM2 (Anil et al., 2023), GPT-3.5, và GPT-4 (OpenAI, 2023). Các đánh giá thực nghiệm của chúng tôi nhấn mạnh sự vượt trội của MP so với các chiến lược prompting hiện có, bao gồm CoT và các biến thể của nó. Công trình này nhấn mạnh tầm quan trọng của việc kết hợp lý luận nội tâm lấy cảm hứng từ con người vào LLMs, làm sáng tỏ một cách tiếp cận làm sâu sắc khả năng hiểu biết của chúng.

Tóm lại, đóng góp của chúng tôi gồm ba phần:
(1) Chúng tôi giới thiệu metacognitive prompting, một chiến lược prompting mới cho LLMs, được lấy cảm hứng từ lý luận nội tâm của con người. Cách tiếp cận này chính thức hóa quy trình đánh giá tự nhận thức trong LLMs, làm nổi bật sự chuyển đổi từ việc thực thi tác vụ đơn thuần sang sự hiểu biết sâu sắc hơn.

(2) Các thí nghiệm toàn diện của chúng tôi trên mười bộ dữ liệu NLU tiết lộ rằng MP vượt trội so với CoT và các biến thể của nó trong cả cài đặt học zero-shot và few-shot. Điều này nhấn mạnh hiệu quả của MP trong việc nâng cao khả năng hiểu biết của LLMs.

(3) Thông qua phân tích lỗi và độ tin cậy thủ công, chúng tôi làm nổi bật những thách thức hiểu biết cụ thể trong LLMs. Chúng tôi cũng minh họa hướng tương lai để kết hợp nội tâm lấy cảm hứng từ con người vào hiểu biết LLM, từ đó đóng góp vào việc nâng cao độ tin cậy của mô hình.

2 Công trình liên quan
Đề xuất của chúng tôi về metacognitive prompting được thông báo bởi một số quỹ đạo nền tảng: các mô hình phát triển của prompting trong LLMs, tiến bộ trong NLU trong lĩnh vực NLP rộng hơn, và sự tương tác phức tạp giữa các quy trình nhận thức và động lực NLU.

2.1 Kỹ thuật Prompting trong LLMs
Prompts là quan trọng để khai thác khả năng rộng lớn của LLMs, hướng dẫn chúng tạo ra đầu ra chính xác hoặc thực hiện các tác vụ cụ thể. Nghiên cứu hiện tại chủ yếu tập trung vào việc nâng cao khả năng lý luận của LLMs. Các phương pháp tiêu biểu bao gồm CoT (Wei et al., 2022) và các biến thể của nó như self-consistency (Wang et al., 2022a), Least-to-Most (Zhou et al., 2022), ToT (Yao et al., 2023), và Plan-and-Solve prompting (Wang et al., 2023a). Các phương pháp bổ sung được mô tả chi tiết trong (Qiao et al., 2022). Tuy nhiên, vẫn tồn tại một khoảng cách đáng kể trong việc phát triển các prompt hiệu quả để nâng cao NLU trong LLMs. Được lấy cảm hứng từ các quy trình nhận thức của con người, chúng tôi giới thiệu MP, một cách tiếp cận không chỉ nhằm thu hẹp khoảng cách hiểu biết mà còn nâng cao sự hiểu biết sâu sắc hơn và độ tin cậy trong đầu ra mô hình.

2.2 Hiểu biết Ngôn ngữ Tự nhiên trong NLP
NLU là một khía cạnh cơ bản của NLP, nhấn mạnh khả năng của mô hình trong việc nắm bắt ngữ nghĩa và sắc thái của ngôn ngữ con người. Các ứng dụng của nó trải dài qua các lĩnh vực đa dạng như trả lời câu hỏi (QA) (Namazifar et al., 2021), phân loại văn bản (Wang et al., 2022b, 2023b), và suy luận ngôn ngữ tự nhiên (NLI) (Nie et al., 2020), cũng như các công cụ thương mại như chatbots (Ait-Mlouk và Jiang, 2020), trợ lý giọng nói (Bellegarda, 2013), và dịch máy. Trong khi LLMs đã thu hút sự chú ý đáng kể gần đây, với những nỗ lực tăng cường dành cho việc mở rộng ranh giới NLU, trọng tâm nghiên cứu chính đã tập trung vào khả năng lý luận của chúng (Huang và Chang, 2022), sử dụng đạo đức (Weidinger et al., 2021; Zhuo et al., 2023), và các ứng dụng rộng rãi (Zhao et al., 2021; Surameery và Shakor, 2023; Wang et al., 2023d). Tuy nhiên, khả năng NLU vốn có của LLMs vẫn tương đối chưa được khám phá đầy đủ. Để giải quyết khoảng cách này, nghiên cứu của chúng tôi đi sâu vào khả năng hiểu biết của các LLMs khác nhau, sử dụng các kỹ thuật prompting hiệu quả.

2.3 Quy trình Nhận thức trong NLU
Sự tương tác giữa các quy trình nhận thức và NLU luôn là một cân nhắc trung tâm trong ngôn ngữ học tính toán (Periñán Pascual và Arcas Túnez, 2007; Hausser và Hausser, 2001). Các quy trình nhận thức, bao gồm các lĩnh vực như chú ý, ký ức, lý luận, và giải quyết vấn đề, chi phối cách con người hiểu, sản xuất, và tương tác với ngôn ngữ trong các tình huống đa dạng. Những quy trình này ảnh hưởng mạnh mẽ đến khả năng ngôn ngữ của chúng ta (Allen, 1995; Cambria và White, 2014). Trong lĩnh vực NLU, việc kết hợp những hiểu biết nhận thức có thể mang lại cải thiện trong sự hiểu biết của mô hình. Nhận ra kết nối nội tại này, công trình của chúng tôi được lấy cảm hứng để sử dụng kỹ thuật prompting dựa trên siêu nhận thức, một phương pháp có gốc rễ trong nhận thức bậc cao phản ánh về tư duy và ra quyết định, để tăng cường khả năng hiểu biết của LLMs, từ đó hài hòa các kỹ thuật mô hình hóa truyền thống với sắc thái nhận thức.

3 Metacognitive Prompting
Trong địa hình phức tạp của nhận thức con người, khả năng nội tâm và điều chỉnh các quy trình tư duy của chúng ta đứng như một viên đá góc cho việc giải quyết vấn đề phức tạp và ra quyết định. Nhận thức bậc cao này là nền tảng cho thành thạo của chúng ta trong việc phân tích các khái niệm trừu tượng, đánh giá phê phán các tình huống, và tinh chỉnh lý luận của chúng ta. Mục tiêu chính của công trình này là trang bị LLMs với một quy trình mô phỏng quy trình nhận thức tự phản tư. Khi làm như vậy, chúng tôi nhằm cải thiện khả năng của LLMs trong việc diễn giải và phản hồi các tác vụ NLU.

Chúng tôi đề xuất MP, điều này thấm nhuần các yếu tố quan trọng của siêu nhận thức con người vào LLMs. Cách tiếp cận này bao gồm năm giai đoạn riêng biệt: 1) LLM bắt đầu bằng việc giải mã văn bản đầu vào để hiểu bối cảnh và ý nghĩa của nó, phản ánh giai đoạn hiểu biết ban đầu trong tư duy con người; 2) sau đó nó hình thành một diễn giải sơ bộ của văn bản, một bước phản ánh việc hình thành phán đoán ở con người; 3) tiếp theo, LLM đánh giá phê phán phán đoán ban đầu này về tính chính xác, tương tự như sự tự xem xét mà con người áp dụng trong quá trình giải quyết vấn đề; 4) sau đánh giá này, LLM hoàn thiện quyết định của mình và đưa ra giải thích cho lý luận của nó, phù hợp với giai đoạn ra quyết định và hợp lý hóa trong nhận thức con người; 5) cuối cùng, LLM đánh giá sự tự tin của mình trong kết quả của toàn bộ quy trình, tương tự như cách con người đo lường chắc chắn của quyết định và giải thích của họ. Hình 2 cung cấp một biểu diễn sơ đồ của MP của chúng tôi. Nó phác thảo năm giai đoạn siêu nhận thức tuần tự, các prompt cụ thể hướng vào LLM, và các đầu ra mô hình tương ứng.

Về bản chất, MP giới thiệu một cách tiếp cận có cấu trúc cho phép LLMs xử lý các tác vụ, nâng cao nhận thức ngữ cảnh và nội tâm của chúng trong phản hồi. Bằng cách hướng dẫn mô hình một cách hệ thống qua các giai đoạn mô phỏng quy trình nhận thức con người, phương pháp này cung cấp một góc nhìn mới về việc giải quyết các tác vụ ngôn ngữ tự nhiên phức tạp. Nó định hình lại nhận thức và sử dụng khả năng của LLMs, mở ra một mô hình nơi các mô hình không chỉ nắm bắt sự phức tạp của các tác vụ được đưa ra mà còn đánh giá phê phán và điều chỉnh phản hồi của chúng. Cách tiếp cận này thiết lập nền tảng cho các tương tác hiệu quả và đáng tin cậy hơn giữa người dùng và LLMs, đặc biệt có lợi cho những người có chuyên môn LLM hạn chế, vì nó đơn giản hóa các quy trình ngôn ngữ và nhận thức phức tạp thành các dạng dễ quản lý hơn. Các mẫu và ví dụ MP mẫu được hiển thị trong Phụ lục A.

4 Thí nghiệm
Chúng tôi tiến hành thí nghiệm trên mười bộ dữ liệu NLU đa dạng được chọn từ các benchmark GLUE (Wang et al., 2019b), SuperGLUE (Wang et al., 2019a), BLUE (Peng et al., 2019), và LexGLUE (Chalkidis et al., 2022). Chúng tôi đánh giá tác động của MP so sánh với CoT và các biến thể của nó, trên bốn LLMs hàng đầu. Chúng tôi báo cáo kết quả tốt nhất sau nhiều lần lặp thí nghiệm.

4.1 Bộ dữ liệu
Cho các thí nghiệm của chúng tôi, chúng tôi sử dụng một tập hợp rộng các bộ dữ liệu từ các benchmark GLUE, SuperGLUE, BLUE, và LexGLUE, bao gồm cả bộ dữ liệu NLU chung và cụ thể theo lĩnh vực trong y sinh học và luật. Trong NLU chung, các lựa chọn của chúng tôi bao gồm paraphrase câu hỏi (QQP (Shankar et al., 2017)), entailment câu hỏi-trả lời (QNLI (Rajpurkar et al., 2016)), QA (BoolQ (Clark et al., 2019)), và phân biệt nghĩa từ (WiC (Pilehvar và Camacho-Collados, 2019)). Cho NLU y sinh, chúng tôi chọn nhận dạng thực thể có tên (BC5CDR-chem (Li et al., 2016)), trích xuất quan hệ (DDI (Segura-Bedmar et al., 2013)), và NLI (MedNLI (Romanov và Shivade, 2018)). Cho NLU pháp lý, chúng tôi chọn phân loại văn bản đa nhãn (EUR-LEX (Chalkidis et al., 2021), UNFAIR-ToS (Lippi et al., 2019)) và phân loại văn bản đa lớp (LEDGAR (Tuggener et al., 2020)). Những bộ dữ liệu này đặt ra những thách thức đa dạng cho khả năng hiểu biết của LLMs. Do ràng buộc chi phí API, chúng tôi chọn ngẫu nhiên 600 ví dụ từ tập validation của mỗi bộ dữ liệu. Bảng 1 cung cấp tổng quan về các tác vụ và bộ dữ liệu.

4.2 Prompts
MP được đề xuất của chúng tôi có thể thích ứng với cả cài đặt zero-shot và 5-shot. Cho mỗi cài đặt, chúng tôi xem xét các baseline prompting sau: (1) Zero-shot CoT (Kojima et al., 2022), thêm "Let's think step by step" vào truy vấn cơ bản, và Plan-and-Solve (PS) prompting (Wang et al., 2023a), thêm "Let's first understand the problem and devise a plan to solve the problem. Then, let's carry out the plan and solve the problem step by step" vào cuối câu hỏi, được bao gồm như các baseline zero-shot. (2) Manual-CoT (Wei et al., 2022) và self-consistency với CoT (CoT-SC) (Wang et al., 2022a), phần sau lấy phiếu bầu đa số từ 10 mẫu CoT, được xem xét như các baseline few-shot. Các mẫu cho mỗi bộ dữ liệu được tạo thủ công.

4.3 Mô hình Ngôn ngữ Lớn
Trong đánh giá của chúng tôi, chúng tôi xem xét bốn LLMs phổ biến: mô hình mã nguồn mở Llama-2-13b-chat (Touvron et al., 2023) và các mô hình mã nguồn đóng PaLM-bison-chat (Anil et al., 2023), GPT-3.5-turbo, và GPT-4 (OpenAI, 2023). Mỗi mô hình được sử dụng bằng khóa API tương ứng. Cho tất cả phương pháp, chúng tôi áp dụng giải mã tham lam (tức nhiệt độ = 0) cho tạo phản hồi, ngoại trừ khi áp dụng CoT-SC (nhiệt độ = 0.7). Hơn nữa, chúng tôi sử dụng cài đặt zero-shot và 5-shot cho mỗi mô hình, với các mẫu cho cài đặt 5-shot được chọn ngẫu nhiên từ tập huấn luyện. Mỗi bộ dữ liệu có tập mẫu riêng của nó, và câu trả lời cho những mẫu này được lấy thông qua chú thích con người.

5 Kết quả
Trong các đánh giá thực nghiệm của chúng tôi, chúng tôi so sánh hiệu suất trên tất cả bộ dữ liệu và mô hình, xem xét các phương pháp prompting khác nhau được sử dụng. Chúng tôi cũng khảo sát hiệu quả của các chiến lược prompting khác nhau, phân tích lỗi liên quan đến MP, và kiểm tra mối quan hệ giữa điểm tin cậy và hiệu suất dự đoán khi MP được áp dụng.

5.1 So sánh Hiệu suất Tổng thể
Bảng 2 trình bày so sánh hiệu suất toàn diện của phương pháp chúng tôi với các phương pháp zero-shot và few-shot đã thiết lập trên bốn LLMs qua mười bộ dữ liệu NLU đa dạng. Nói chung, học 5-shot vượt trội so với học zero-shot trên các mô hình, ngoại trừ EUR-LEX và LEDGAR. Sự sụt giảm hiệu suất của phần sau có thể là do số lượng lớp cao của chúng và các ví dụ demo hạn chế, có thể làm lệch mô hình về một tập nhãn hẹp. Đặc biệt, zero-shot MP vượt trội so với M-CoT trong một số trường hợp, gợi ý rằng nỗ lực thủ công giảm vẫn có thể hiệu quả gợi ra hiểu biết sâu trong LLMs, có khả năng truyền cảm hứng cho việc phát triển các phương pháp prompting hiệu quả hơn. Hơn nữa, GPT-4 nổi bật, nhất quán ghi điểm cao nhất trên tất cả bộ dữ liệu với khoảng cách đáng kể. Cho prompting zero-shot, LLMs thể hiện hiệu suất cải thiện đáng kể với MP, đặc biệt cho các tác vụ NLU pháp lý như EUR-LEX. Cụ thể, MP tăng µ-F1 từ 15.0% đến 26.9% so với CoT và từ 9.2% đến 16.9% so với PS trên bộ dữ liệu EUR-LEX. Một xu hướng tương tự được thấy với các phương pháp 5-shot; ví dụ, trên cùng bộ dữ liệu, M-MP nâng cao µ-F1 từ 10.6% đến 19.4% so với M-CoT và từ 5.9% đến 13.0% so với CoT-SC. Nhìn chung, việc tích hợp MP mang lại lợi ích đáng kể cho các bộ dữ liệu NLU cụ thể theo lĩnh vực trong các lĩnh vực y sinh học và luật trên tất cả mô hình. Nó cũng cung cấp cải thiện vừa phải nhưng nhất quán trong các tác vụ NLU chung.

5.2 So sánh Chiến lược Prompting
Chúng tôi đánh giá hiệu suất của các chiến lược prompting khác nhau dưới cài đặt học zero-shot và 5-shot trên tất cả mô hình và bộ dữ liệu.

Trong so sánh cấp mô hình, Hình 3 trình bày một cái nhìn tổng hợp về hiệu suất của mỗi phương pháp prompting trên tất cả bộ dữ liệu cho mỗi mô hình (trên cho zero-shot và dưới cho 5-shot), giả định rằng bộ dữ liệu và số liệu đánh giá đều quan trọng bằng nhau và có thể so sánh trực tiếp. Cho cài đặt học zero-shot, MP nổi lên như vượt trội, minh họa mức tăng hiệu suất tương đối từ 4.8% đến 6.4% so với CoT và 2.8% đến 4.1% so với PS. Tương tự, M-MP cho thấy cải thiện hiệu suất trung bình từ 4.5% đến 6.0% so với M-CoT và 2.2% đến 3.5% so với CoT-SC trong cài đặt học 5-shot. Hiệu suất nâng cao này có thể được gán cho chiến lược nội tâm độc đáo của MP, điều này tạo điều kiện cho hiểu biết sâu hơn về các tác vụ bằng cách nhắc mô hình đánh giá phê phán, xem xét lại phán đoán ban đầu của nó, và tinh chỉnh phản hồi của nó. Khi chúng tôi chuyển tập trung sang so sánh cấp dữ liệu, xem xét kết quả học zero-shot như một ví dụ, Bảng 3 cung cấp hiệu suất trung bình qua bốn LLMs cho mỗi bộ dữ liệu. Khả năng đánh giá lại quan trọng của MP đặc biệt nổi bật trong các bộ dữ liệu như MedNLI, UNFAIR-ToS, và EUR-LEX, dẫn đến cải thiện đáng kể lần lượt 4.3%, 9.6%, và 12.4% so với PS (phiên bản nâng cao của zero-shot CoT). Hiệu suất xuất sắc nhất quán của MP nhấn mạnh tiềm năng của nó trong các tác vụ đòi hỏi độ chính xác, sự phân biệt, và nắm bắt ngữ nghĩa toàn diện. Trong khi đó, tự đánh giá và cải thiện lặp đi lặp lại được nhúng trong MP mang lại cho nó lợi thế trong các tác vụ đòi hỏi hiểu biết tinh tế và độ sâu ngữ cảnh.

5.3 Phân tích Lỗi
MP đã nhất quán thể hiện thành thạo qua một loạt các tác vụ NLU. Tuy nhiên, khi kiểm tra thủ công các dự đoán không chính xác của nó, chúng tôi xác định hai loại lỗi chính qua tất cả tác vụ (10 bộ dữ liệu) đặc biệt liên quan đến MP. Đầu tiên, 'Lỗi suy nghĩ quá mức' (68.3%) đặc biệt rõ ràng trong các bộ dữ liệu đơn giản như QQP và BoolQ. Trong những tình huống này, MP có xu hướng làm phức tạp quá mức tác vụ, lệch khỏi giải pháp đúng. Ngược lại, 'Lỗi sửa chữa quá mức' (31.7%) chủ yếu xuất hiện trong các tác vụ đòi hỏi diễn giải tinh tế, như WiC và DDI. Loại lỗi này xuất hiện rõ ràng trong giai đoạn đánh giá lại quan trọng của MP, vạt quá xa khỏi diễn giải ban đầu chính xác. Hình 4 cho thấy ví dụ về cả hai loại lỗi từ bộ dữ liệu WiC.

Ngoài ra, chúng tôi quan sát các mẫu lỗi riêng biệt trong các tác vụ cụ thể theo lĩnh vực. Trong các tác vụ NLU y sinh (3 bộ dữ liệu), MP chủ yếu gặp lỗi bao gồm 'Sự không phù hợp thuật ngữ' (48.6%), nơi mô hình diễn giải không chính xác các thuật ngữ y khoa chuyên môn, và 'Sự khác biệt suy luận lâm sàng' (51.4%), nơi độ sâu và sự kết nối của dữ liệu lâm sàng không được hiểu đầy đủ hoặc bị áp dụng sai. Trong các tác vụ NLU pháp lý (3 bộ dữ liệu), các lỗi thường được đặc trưng như 'Lỗi diễn giải theo luật' (52.2%), phản ánh thách thức trong việc giải mã ngôn ngữ và bối cảnh phức tạp của tài liệu pháp lý, và 'Sự lệch hướng phân tích luật học' (47.8%), nơi mô hình lệch khỏi lý luận pháp lý được chấp nhận hoặc diễn giải sai các nguyên tắc và tiền lệ pháp lý. Số trong ngoặc đại diện cho phân phối gần đúng của các loại lỗi chính trong tiểu nhóm. Những loại lỗi này, độc đáo với yêu cầu cụ thể của y sinh học và luật, làm nổi bật nhu cầu điều chỉnh được điều chỉnh trong ứng dụng tiếp theo của MP cho các lĩnh vực này.

5.4 Phân tích Độ tin cậy
Đánh giá độ tin cậy và không chắc chắn trong khung MP là công cụ trong việc đo lường độ tin cậy của dự đoán, đặc biệt khi các mô hình diễn đạt mức độ tin cậy của chúng. Trong phân tích của chúng tôi, mỗi mô hình hoạt động với MP được đánh giá dựa trên độ tin cậy được diễn đạt của nó cho mỗi dự đoán qua các bộ dữ liệu. Điểm trên 75% được phân loại là độ tin cậy cao; bất kỳ giá trị nào dưới ngưỡng này được coi là độ tin cậy thấp. Để làm sáng tỏ mối tương quan này, chúng tôi sử dụng ma trận nhầm lẫn được điều chỉnh riêng cho nghiên cứu này. Trong ma trận này, các thuật ngữ tiêu chuẩn của 'True Positive', 'False Positive', 'True Negative', và 'False Negative' được định nghĩa lại như sau:

True Positive (TP): Đại diện cho các trường hợp nơi mô hình, sử dụng MP, bày tỏ độ tin cậy cao và tạo ra câu trả lời đúng. Những cái này chiếm 55.6%.

False Positives (FP): Chỉ các trường hợp nơi mô hình thể hiện độ tin cậy cao nhưng đưa ra dự đoán không chính xác. Những cái này chiếm 32.5%.

True Negatives (TN): Dùng để chỉ các trường hợp nơi mô hình báo hiệu độ tin cậy thấp và phản hồi của nó thực sự không chính xác. Những cái này đứng ở 6.8%.

False Negatives (FN): Làm nổi bật các trường hợp nơi mô hình chỉ ra độ tin cậy thấp nhưng, đáng ngạc nhiên, đưa ra câu trả lời đúng. Những cái này tính tổng là 5.1%.

Những số liệu này được tổng hợp qua tất cả mô hình và bộ dữ liệu và sau đó được tính trung bình để cung cấp cái nhìn tổng thể về sự tương tác giữa độ tin cậy mô hình sử dụng MP và độ chính xác dự đoán. Như được mô tả trong Hình 5, MP thường cung cấp phản ánh chính xác về hiệu suất của chính nó, như được chứng minh bởi tỷ lệ TP cao. Tỷ lệ TN tương đối thấp nhấn mạnh tự đánh giá đáng tin cậy của nó, gợi ý rằng khi MP có độ tin cậy thấp, nó chủ yếu đúng về sự không chính xác của nó. Tuy nhiên, tỷ lệ FP đáng kể chỉ ra rằng, trong khi MP thường đúng khi tự tin, đôi khi nó mắc lỗi mặc dù có độ tin cậy cao. Hơn nữa, tỷ lệ FN xác định các lĩnh vực nơi MP có thể cải thiện tự nhận thức của mình, vì có những lúc nó có thể đánh giá thấp độ chính xác của mình. Tóm lại, tỷ lệ TP cao và giá trị FN thấp nhấn mạnh tự nhận thức của MP, nhưng các giá trị FP và TN chỉ ra cải thiện tiềm năng. Giải quyết những lĩnh vực này bằng cách nhấn mạnh hiệu chuẩn độ tin cậy trong các lần lặp tương lai của MP có thể căn chỉnh tốt hơn các đánh giá nội tâm của nó với khả năng hiệu suất thực tế.

6 Hạn chế
Trong khi MP được đề xuất của chúng tôi thể hiện tiềm năng bằng cách tích hợp các tính năng nội tâm gợi nhớ đến nhận thức con người vào LLMs để nâng cao khả năng hiểu biết của chúng, nghiên cứu của chúng tôi có những hạn chế. Đầu tiên, thiết kế prompts đòi hỏi nỗ lực thủ công để hướng dẫn LLMs qua các quy trình siêu nhận thức. Thứ hai, chúng tôi đánh giá hiệu quả của MP sử dụng lựa chọn các bộ dữ liệu và mô hình, có thể hạn chế khả năng áp dụng rộng hơn của các phát hiện của chúng tôi. Hơn nữa, mặc dù độ tin cậy được diễn đạt của LLMs cung cấp cửa sổ vào mức độ chắc chắn được nhận thức của chúng, nó có thể không phục vụ như phương pháp xác định để đo lường toàn diện độ tin cậy thực sự của chúng. Một cách tiếp cận lai, như kết hợp diễn đạt với kiểm tra tự nhất quán, có thể cung cấp phương pháp mạnh mẽ hơn cho hiệu chuẩn độ tin cậy. Ngoài ra, nghiên cứu của chúng tôi không giải quyết rộng rãi các mối quan tâm đạo đức và pháp lý quan trọng, như thiên lệch tiềm năng, hàm ý riêng tư, và thách thức công bằng. Nghiên cứu tương lai về MP sẽ giải quyết những khía cạnh này để đảm bảo ứng dụng có trách nhiệm và toàn diện của LLMs trong các lĩnh vực khác nhau.

7 Thảo luận
Trong nghiên cứu này, chúng tôi trình bày MP để truyền các tính năng nội tâm phản ánh nhận thức con người vào LLMs. Quy trình MP bao gồm năm giai đoạn riêng biệt: nó bắt đầu bằng việc hiểu văn bản đầu vào, sau đó chuyển sang hình thành phán đoán ban đầu. Tiếp theo, nó đánh giá lại một cách phê phán ấn tượng ban đầu này, quyết định về một quyết định trong khi giải thích lý do của nó, và cuối cùng đo lường độ tin cậy của nó trong các quyết định đã đưa ra. Chúng tôi tiến hành thí nghiệm trên một loạt rộng các bộ dữ liệu từ một số benchmark NLU phổ biến và đánh giá một số LLMs nổi bật với các phương pháp prompting khác nhau. Kết quả nhấn mạnh tiềm năng của phương pháp chúng tôi, thể hiện lợi thế so với các phương pháp prompting hiện có. Thông qua phân tích của chúng tôi, các mẫu lỗi cụ thể liên quan đến MP được xác định, làm nổi bật sắc thái trong các giai đoạn hiểu biết và phán đoán đòi hỏi tinh chỉnh thêm. Trong khi MP cung cấp con đường có cấu trúc cho các mô hình nội tâm, nó tuân theo các giai đoạn được xác định trước, thiếu khả năng thích ứng dựa trên phản hồi thời gian thực. Thiết kế năm giai đoạn của MP, mặc dù là nền tảng, gợi ý chỗ cho các khung phức tạp hơn có thể mô phỏng các vòng phản hồi nhận thức giống con người một cách chân thực hơn.

Nhìn về phía trước, một số lĩnh vực đáng để khám phá thêm. Đầu tiên, chúng tôi dự định áp dụng MP rộng hơn, đặc biệt cho các lĩnh vực định hướng chi tiết như hỗ trợ sức khỏe tâm thần, cũng như cho các tác vụ lý luận phức tạp như lý luận số học và thường thức. Tinh chỉnh MP có thể gợi ra phản hồi nội tâm chi tiết hơn từ LLMs. Hơn nữa, sự phụ thuộc vào độ tin cậy được diễn đạt có thể được tăng cường bằng cách tích hợp các phương pháp khác cho đánh giá toàn diện hơn. Ngoài ra, các hàm ý rộng hơn của việc giới thiệu LLMs nội tâm, đặc biệt liên quan đến thiên lệch và độ tin cậy của đầu ra, đòi hỏi kiểm tra sâu. Về bản chất, liên doanh ban đầu của chúng tôi với MP đặt nền tảng vững chắc, nhưng cơ hội đáng kể vẫn còn để rút ra sự tương đồng gần hơn giữa nội tâm trong LLMs và nội tâm tự nhiên của con người, có thể dẫn đến các hệ thống AI có thể giải thích và có trách nhiệm hơn.

8 Tuyên bố Đạo đức
Không có vấn đề liên quan đến đạo đức trong bài báo này. Dữ liệu và tài nguyên được sử dụng trong công trình này là mã nguồn mở và được sử dụng rộng rãi trong nhiều nghiên cứu hiện có.

Tài liệu tham khảo
[Phần tài liệu tham khảo được giữ nguyên như trong bản gốc]

A Prompts Mẫu
Phần này bao gồm một số ví dụ về MP dưới cài đặt zero-shot và few-shot.

Ví dụ 1: WiC
• Mẫu MP Zero-shot: Trong hai câu, câu 1: "[sentence_1]" và câu 2: "[sentence_2]", cả hai đều chứa từ mục tiêu "[word]". Xác định xem từ mục tiêu có được sử dụng với cùng ý nghĩa trong cả hai câu không. Khi bạn thực hiện tác vụ này, hãy làm theo các bước sau:
1. Hiểu bối cảnh và ý nghĩa của từ mục tiêu trong cả hai câu.
2. Đưa ra phán đoán sơ bộ về việc từ mục tiêu có cùng ý nghĩa trong cả hai câu không.
3. Đánh giá phê phán phân tích sơ bộ của bạn. Nếu bạn không chắc chắn về phán đoán ban đầu của mình, hãy đánh giá lại nó.
4. Xác nhận câu trả lời cuối cùng của bạn và giải thích lý do đằng sau quyết định của bạn.
5. Đánh giá độ tin cậy (0-100%) của bạn trong phân tích và cung cấp giải thích cho mức độ tin cậy này.

Cung cấp câu trả lời trong phản hồi cuối cùng của bạn là "Từ mục tiêu có cùng ý nghĩa trong cả hai câu: {} (True / False)".

• Minh họa MP Few-shot:
Q: Trong hai câu, câu 1: "The washing machine won't go unless it's plugged in." và câu 2: "The day went well until I got your call.", cả hai đều chứa từ mục tiêu "go". Xác định xem từ mục tiêu có được sử dụng với cùng ý nghĩa trong cả hai câu không.
A:
1. Trong câu 1, "go" dùng để chỉ hoạt động của máy giặt. Trong câu 2, "went" (một dạng của "go") dùng để chỉ tiến trình của ngày.
2. Ban đầu, "go" trong câu đầu tiên dường như là về hoạt động cơ khí, trong khi ở câu thứ hai, nó là về sự trôi qua của thời gian hoặc sự kiện.
3. Suy nghĩ thêm, các bối cảnh rõ ràng phân biệt ý nghĩa: một cái liên quan đến máy móc và chức năng của nó, cái kia liên quan đến trải nghiệm của một ngày.
4. Từ mục tiêu "go" không có cùng ý nghĩa trong cả hai câu. Trong câu đầu, nó liên quan đến hoạt động, và trong câu thứ hai, đến sự tiến triển của sự kiện.
5. Tôi tin tưởng 83% vào phân tích này. Thuật ngữ "go" được sử dụng trong các bối cảnh khác nhau trong hai câu, dẫn đến ý nghĩa khác nhau.

Từ mục tiêu có cùng ý nghĩa trong cả hai câu: False.

[Các ví dụ khác tiếp tục với cùng cấu trúc dịch...]

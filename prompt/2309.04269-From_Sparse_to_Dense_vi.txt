# 2309.04269.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/prompt/2309.04269.pdf
# Kích thước tập tin: 918857 bytes

===============================================
NỘI DUNG TẬP TIN PDF
===============================================

--- TRANG 1 ---
Từ Thưa Thớt đến Dày Đặc:
Tóm tắt GPT-4 với Phương pháp Gợi ý Chuỗi Mật độ
Griffin Adams♠,♣
griffin.adams@columbia.eduAlexander R. Fabbri♢
afabbri@salesforce.com
Faisal Ladhak♠
faisal@cs.columbia.eduEric Lehman♡
lehmer16@mit.eduNoémie Elhadad♠,♣
noemie.elhadad@columbia.edu
Salesforce AI♢MIT♡Đại học Columbia: CS♠, Tin sinh học♣
Tóm tắt
Việc lựa chọn lượng thông tin "phù hợp" để đưa vào
bản tóm tắt là một nhiệm vụ khó khăn. Một bản tóm
tắt tốt nên chi tiết và tập trung vào thực thể mà
không quá dày đặc và khó theo dõi. Để hiểu rõ hơn
sự đánh đổi này, chúng tôi yêu cầu các bản tóm tắt
GPT-4 ngày càng dày đặc với những gì chúng tôi gọi
là lời nhắc "Chuỗi Mật độ" (CoD). Cụ thể, GPT-4
tạo ra một bản tóm tắt ban đầu ít thực thể trước khi
lặp đi lặp lại việc kết hợp các thực thể nổi bật còn thiếu
mà không tăng độ dài. Các bản tóm tắt được tạo bởi
CoD trừu tượng hơn, thể hiện nhiều sự hợp nhất hơn,
và ít có khuynh hướng dẫn dắt hơn so với các bản tóm
tắt GPT-4 được tạo bằng lời nhắc thông thường.
Chúng tôi tiến hành một nghiên cứu sở thích của con
người trên 100 bài báo CNN DailyMail và phát hiện
rằng con người thích các bản tóm tắt GPT-4 dày đặc
hơn so với những bản được tạo bằng lời nhắc thông
thường và gần như dày đặc bằng các bản tóm tắt do
con người viết. Phân tích định tính hỗ trợ quan niệm
rằng tồn tại sự đánh đổi giữa tính thông tin và khả
năng đọc. 500 bản tóm tắt CoD có chú thích, cũng
như thêm 5.000 bản tóm tắt không có chú thích, được
cung cấp miễn phí trên HuggingFace1.

1 Giới thiệu
Tóm tắt tự động đã có những bước tiến dài trong
vài năm qua, phần lớn là do sự thay đổi mô hình
từ việc tinh chỉnh có giám sát trên các tập dữ liệu
có nhãn sang việc gợi ý không-shot với các Mô hình
Ngôn ngữ Lớn (LLM), chẳng hạn như GPT-4
(OpenAI, 2023). Không cần đào tạo bổ sung, việc
gợi ý cẩn thận có thể cho phép kiểm soát tinh tế các
đặc điểm tóm tắt, chẳng hạn như độ dài (Goyal et al.,
2022), chủ đề (Bhaskar et al., 2023), và phong cách
(Pu và Demberg, 2023).
Một khía cạnh bị bỏ qua là mật độ thông tin của
một bản tóm tắt. Về lý thuyết, như một sự nén của
văn bản khác, một bản tóm tắt nên dày đặc hơn –
chứa một nồng độ thông tin cao hơn – so với tài liệu
nguồn. Với độ trễ cao của việc giải mã LLM (Kaddour
et al., 2023), việc bao phủ nhiều thông tin hơn trong
ít từ hơn là một mục tiêu xứng đáng, đặc biệt cho các
ứng dụng thời gian thực. Tuy nhiên, mức độ dày đặc
như thế nào là một câu hỏi mở. Một bản tóm tắt
không mang tính thông tin nếu nó chứa chi tiết không
đủ. Nếu nó chứa quá nhiều thông tin, tuy nhiên, nó
có thể trở nên khó theo dõi mà không phải tăng độ
dài tổng thể. Việc truyền đạt nhiều thông tin hơn dưới
một ngân sách token cố định đòi hỏi sự kết hợp của
trừu tượng hóa, nén và hợp nhất. Có một giới hạn về
mức độ có thể tạo ra không gian cho thông tin bổ sung
trước khi trở nên không thể đọc được hoặc thậm chí
không chính xác về mặt thực tế.
Trong bài báo này, chúng tôi tìm cách xác định giới
hạn này bằng cách yêu cầu sở thích của con người
trên một tập hợp các bản tóm tắt ngày càng dày đặc
được tạo bởi GPT-4. Coi các thực thể, và đặc biệt
là số lượng thực thể trung bình trên mỗi token, như
một đại diện cho mật độ, chúng tôi tạo ra một bản
tóm tắt ban đầu ít thực thể. Sau đó, chúng tôi lặp
đi lặp lại việc xác định và hợp nhất 1-3 thực thể thiếu
từ bản tóm tắt trước đó mà không tăng độ dài tổng
thể (5x tổng thể). Mỗi bản tóm tắt có tỷ lệ thực thể
trên token cao hơn bản trước đó. Dựa trên dữ liệu
sở thích của con người, chúng tôi xác định rằng con
người thích các bản tóm tắt gần như dày đặc bằng
các bản tóm tắt do con người viết và dày đặc hơn

--- TRANG 2 ---
Bài báo: 
{{BÀI BÁO}}
Bạn 
sẽ 
tạo 
ra 
các 
bản 
tóm 
tắt 
ngày 
càng 
ngắn 
gọn, 
dày 
đặc 
thực 
thể 
của 
Bài 
báo 
trên.
Lặp 
lại 
2 
bước 
sau 
5 
lần.
Bước 
1. 
Xác 
định 
1-3 
Thực 
thể 
mang 
tính 
thông 
tin 
(";" 
phân 
cách) 
từ 
Bài 
báo 
mà 
thiếu 
trong 
bản 
tóm 
tắt 
được 
tạo 
trước 
đó.
Bước 
2. 
Viết 
một 
bản 
tóm 
tắt 
mới, 
dày 
đặc 
hơn 
với 
độ 
dài 
giống 
hệt 
nhau 
bao 
phủ 
mọi 
thực 
thể 
và 
chi 
tiết 
từ 
bản 
tóm 
tắt 
trước 
cộng 
với 
các 
Thực 
thể 
Thiếu.
Một 
Thực 
thể 
Thiếu 
là:
- 
Liên 
quan
: 
đến 
câu 
chuyện 
chính.
- 
Cụ 
thể
: 
mô 
tả 
nhưng 
ngắn 
gọn 
(5 
từ 
hoặc 
ít 
hơn).
- 
Mới
: 
không 
có 
trong 
bản 
tóm 
tắt 
trước.
- 
Trung 
thực
: 
có 
mặt 
trong 
Bài 
báo.
- 
Ở 
bất 
kỳ 
đâu
: 
nằm 
ở 
bất 
kỳ 
đâu 
trong 
Bài 
báo.
Hướng 
dẫn:
- 
Bản 
tóm 
tắt 
đầu 
tiên 
nên 
dài 
(4-5 
câu, 
~80 
từ) 
nhưng 
rất 
không 
cụ 
thể, 
chứa 
ít 
thông 
tin 
ngoài 
các 
thực 
thể 
được 
đánh 
dấu 
là 
thiếu. 
Sử 
dụng 
ngôn 
ngữ 
quá 
dài 
dòng 
và 
từ 
đệm 
(ví 
dụ, 
"bài 
báo 
này 
thảo 
luận") 
để 
đạt 
~80 
từ.
- 
Làm 
cho 
mỗi 
từ 
có 
ý 
nghĩa: 
viết 
lại 
bản 
tóm 
tắt 
trước 
để 
cải 
thiện 
dòng 
chảy 
và 
tạo 
không 
gian 
cho 
các 
thực 
thể 
bổ 
sung.
- 
Tạo 
không 
gian 
với 
sự 
hợp 
nhất, 
nén 
và 
loại 
bỏ 
các 
cụm 
từ 
không 
mang 
tính 
thông 
tin 
như 
"bài 
báo 
thảo 
luận".
- 
Các 
bản 
tóm 
tắt 
nên 
trở 
nên 
rất 
dày 
đặc 
và 
ngắn 
gọn 
nhưng 
khép 
kín, 
ví 
dụ, 
dễ 
hiểu 
mà 
không 
cần 
Bài 
báo.
- 
Các 
thực 
thể 
thiếu 
có 
thể 
xuất 
hiện 
ở 
bất 
kỳ 
đâu 
trong 
bản 
tóm 
tắt 
mới.
- 
Không 
bao 
giờ 
bỏ 
các 
thực 
thể 
từ 
bản 
tóm 
tắt 
trước. 
Nếu 
không 
thể 
tạo 
ra 
không 
gian, 
thêm 
ít 
thực 
thể 
mới 
hơn.
Nhớ 
rằng, 
sử 
dụng 
chính 
xác 
cùng 
số 
từ 
cho 
mỗi 
bản 
tóm 
tắt.
Trả 
lời 
bằng 
JSON. 
JSON 
nên 
là 
một 
danh 
sách 
(độ 
dài 
5) 
gồm 
các 
từ 
điển 
có 
khóa 
là 
"Missing_Entities" 
và 
"Denser_Summary".
Bài 
báo 
này 
thảo 
luận 
về 
một 
sự 
cố 
xảy 
ra 
trong 
Giải 
Grand 
Prix 
Trung 
Quốc 
liên 
quan 
đến 
hai 
tay 
đua, 
Jenson 
Button 
và 
Pastor 
Maldonado. 
Hai 
người 
đang 
cạnh 
tranh 
vị 
trí 
thứ 
13 
khi 
Button 
va 
chạm 
với 
xe 
của 
Maldonado, 
gây 
thiệt 
hại 
cho 
cả 
hai 
xe. 
Sự 
cố 
này 
dẫn 
đến 
việc 
phạt 
Button, 
người 
bị 
xuống 
vị 
trí 
thứ 
14. 
Mặt 
khác, 
Maldonado 
phải 
rút 
lui 
khỏi 
cuộc 
đua 
do 
thiệt 
hại 
mà 
xe 
của 
anh 
ta 
phải 
chịu.
Trong 
Giải 
Grand 
Prix 
Trung 
Quốc, 
Jenson 
Button, 
lái 
xe 
cho 
McLaren
, 
va 
chạm 
với 
Lotus
 
của 
Pastor 
Maldonado, 
trong 
khi 
họ 
đang 
tranh 
giành 
vị 
trí 
thứ 
13. 
Vụ 
tai 
nạn 
khiến 
Maldonado 
phải 
rút 
lui 
và 
Button 
nhận 
phạt, 
rơi 
xuống 
vị 
trí 
thứ 
14. 
Sự 
cố 
diễn 
ra 
trước 
mặt 
Fernando 
Alonso
, 
người 
đã 
tránh 
được 
va 
chạm 
và 
tiến 
lên 
hai 
vị 
trí.
Trong 
Giải 
Grand 
Prix 
Trung 
Quốc, 
McLaren 
của 
Jenson 
Button 
đâm 
vào 
Lotus 
của 
Pastor 
Maldonado, 
khiến 
Maldonado 
phải 
rút 
lui 
và 
Button 
nhận 
phạt 
năm 
giây
, 
xuống 
vị 
trí 
thứ 
14. 
Button 
cũng 
nhận 
hai 
điểm 
phạt
 
trên 
bằng 
lái 
siêu 
cấp 
của 
mình. 
Fernando 
Alonso, 
người 
chứng 
kiến 
sự 
cố, 
tiến 
lên 
hai 
vị 
trí, 
trong 
khi 
Button 
bị 
vượt 
vòng 
bởi 
Mercedes
 
của 
Nico 
Rosberg.
McLaren 
của 
Jenson 
Button 
va 
chạm 
với 
Lotus 
của 
Pastor 
Maldonado 
trong 
Giải 
Grand 
Prix 
Trung 
Quốc, 
gây 
thiệt 
hại 
cánh 
trước
 
cho 
xe 
của 
Button 
và 
thiệt 
hại 
phần 
đuôi
 
cho 
xe 
của 
Maldonado, 
buộc 
anh 
ta 
phải 
rút 
lui. 
Button 
nhận 
phạt 
năm 
giây 
và 
hai 
điểm 
bằng 
lái 
siêu 
cấp, 
rơi 
xuống 
vị 
trí 
thứ 
14. 
Fernando 
Alonso 
tiến 
lên 
hai 
vị 
trí, 
trong 
khi 
Button 
bị 
vượt 
vòng 
bởi 
Nico 
Rosberg 
và 
Alonso 
bởi 
Sebastian 
Vettel
 
và 
Kimi 
Raikkonen
.
Ở 
vòng 
49
 
của 
Giải 
Grand 
Prix 
Trung 
Quốc 
đầy 
sự 
cố
, 
McLaren 
của 
Jenson 
Button 
đâm 
vào 
Lotus 
của 
Pastor 
Maldonado, 
gây 
thiệt 
hại 
và 
buộc 
Maldonado 
rút 
lui. 
Button 
nhận 
phạt 
năm 
giây 
và 
hai 
điểm 
bằng 
lái 
siêu 
cấp, 
rơi 
xuống 
vị 
trí 
thứ 
14. 
Fernando 
Alonso, 
người 
chứng 
kiến 
vụ 
tai 
nạn, 
tiến 
lên 
hai 
vị 
trí, 
trong 
khi 
Button 
bị 
vượt 
vòng 
bởi 
Nico 
Rosberg 
và 
Alonso 
bởi 
Sebastian 
Vettel 
và 
Kimi 
Raikkonen 
của 
Ferrari
.
Lời 
nhắc 
Chuỗi 
Mật 
độ 
(CoD)
Đầu 
ra 
CoD 
(
Chi 
tiết 
được 
thêm 
từ 
trước
)

--- TRANG 3 ---
GPT-4 
Thông 
thường
Bản 
tóm 
tắt 
của 
Con 
người
Bản 
tóm 
tắt 
của 
Con 
người
GPT-4 
Thông 
thường
GPT-4 
Thông 
thường
Bản 
tóm 
tắt 
của 
Con 
người

Bước CoD Token Thực thể Mật độ (E/T)
1 72 6.4 0.089
2 67 8.7 0.129
3 67 9.9 0.148
4 69 10.8 0.158
5 72 12.1 0.167
Con người 60 8.8 0.151
GPT-4 Thông thường 70 8.5 0.122

Thống kê Trực tiếp. Trong Bảng 1, chúng tôi tính token với NLTK (Loper và Bird, 2002), đo các thực thể duy nhất với Spacy2, và tính mật độ thực thể như tỷ lệ. Lời nhắc CoD phần lớn tuân thủ ngân sách token cố định. Trên thực tế, bước thứ hai dẫn đến việc giảm trung bình 5 token (từ 72 xuống 67) về độ dài khi các từ không cần thiết được loại bỏ khỏi bản tóm tắt ban đầu dài dòng. Mật độ thực thể tăng – bắt đầu ở 0.089, ban đầu thấp hơn Con người và GPT-4 Thông thường (0.151 và 0.122) – lên 0.167 sau 5 bước làm dày đặc.

Thống kê Gián tiếp. Tính trừu tượng nên tăng với mỗi bước CoD vì các bản tóm tắt được viết lại một cách lặp đi lặp lại để tạo không gian cho mỗi thực thể bổ sung. Chúng tôi đo tính trừu tượng với mật độ trích xuất: độ dài bình phương trung bình của các đoạn trích xuất (Grusky et al., 2018). Tương tự, mức độ Hợp nhất khái niệm nên tăng đơn điệu khi các thực thể được thêm vào bản tóm tắt có độ dài cố định. Chúng tôi đại diện cho sự hợp nhất như số lượng câu nguồn trung bình được căn chỉnh với mỗi câu tóm tắt. Để căn chỉnh, chúng tôi sử dụng phương pháp tăng ROUGE tương đối (Zhou et al., 2018), căn chỉnh các câu nguồn với một câu đích cho đến khi tăng ROUGE tương đối của một câu bổ sung không còn tích cực. Chúng tôi cũng mong đợi Phân phối Nội dung – vị trí trong Bài báo mà nội dung tóm tắt được lấy – sẽ thay đổi. Cụ thể, chúng tôi mong đợi rằng các bản tóm tắt CoD ban đầu thể hiện Thiên kiến Dẫn đầu mạnh mẽ nhưng dần dần bắt đầu kéo các thực thể từ giữa và cuối bài báo. Để đo điều này, chúng tôi sử dụng các căn chỉnh từ sự hợp nhất và đo thứ hạng câu trung bình của tất cả các câu nguồn được căn chỉnh. Hình 3 xác nhận các giả thuyết này: tính trừu tượng tăng với số lượng bước viết lại (mật độ trích xuất thấp hơn ở bên trái), tỷ lệ hợp nhất tăng (hình giữa), và các bản tóm tắt bắt đầu kết hợp nội dung từ giữa và cuối bài báo (hình bên phải).

Thú vị là, tất cả các bản tóm tắt CoD đều trừu tượng hơn so với cả bản tóm tắt do con người viết và bản tóm tắt cơ sở.

4 Kết quả
Để hiểu rõ hơn các đánh đổi có mặt với các bản tóm tắt CoD, chúng tôi tiến hành một nghiên cứu dựa trên sở thích của con người và một đánh giá dựa trên xếp hạng với GPT-4.

Bước CoD % Phần trăm Phiếu bầu Hạng nhất
 Người chú thích Cá nhân Tổng hợp
1 3.0 2.0 13.0 17.4 8.3
2 25.0 28.0 43.0 31.4 30.8
3 22.0 28.0 21.0 24.4 23.0
4 29.0 25.0 13.0 26.7 22.5
5 21.0 17.0 10.0 16.3 15.5

Sở thích của Con người. Chúng tôi tiến hành một đánh giá của con người để đánh giá tác động của việc làm dày đặc đối với đánh giá chất lượng tổng thể của con người. Cụ thể, bốn tác giả đầu tiên của bài báo được trình bày các bản tóm tắt CoD được xáo trộn ngẫu nhiên, cùng với các bài báo, cho cùng 100 bài báo (5 bước * 100 = 500 tổng số bản tóm tắt). Dựa trên định nghĩa về "bản tóm tắt tốt" từ Stiennon et al. (2020) (Bảng 6 từ bài báo của họ), mỗi người chú thích chỉ ra bản tóm tắt ưa thích hàng đầu của họ. Bảng 2 báo cáo sự phân chia phiếu bầu hạng nhất theo bước CoD giữa các người chú thích – cũng như tổng hợp giữa các người chú thích. Đầu tiên, chúng tôi báo cáo hệ số kappa Fleiss (Fleiss, 1971) thấp là 0.112, điều này chỉ ra sự khác biệt tinh tế giữa các bản tóm tắt và bản chất chủ quan của nhiệm vụ. Nghiên cứu gần đây cũng

--- TRANG 4 ---
Bước CoD Mật độ Thực thể Tính thông tin Chất lượng Tính mạch lạc Có thể quy kết Tổng thể Đánh giá GPT-4 Trung bình
1 0.089 4.34 4.75 4.96 4.96 4.41 4.69
2 0.129 4.62 4.79 4.92 5.00 4.58 4.78
3 0.148 4.67 4.76 4.84 5.00 4.57 4.77
4 0.158 4.74 4.69 4.75 5.00 4.61 4.76
5 0.167 4.73 4.65 4.61 4.97 4.58 4.71

đã lưu ý mức độ thống nhất thấp ở mức độ thể hiện khi đánh giá các bản tóm tắt dựa trên GPT (Goyal et al., 2022).

Tuy nhiên, ở cấp độ hệ thống, một số xu hướng bắt đầu nổi lên. Đối với 3 trong số 4 người chú thích, bước CoD 1 nhận được phần chia sẻ lớn nhất của các phiếu bầu hạng nhất trong 100 ví dụ (28, 43, và 31.4%, tương ứng). Tuy nhiên, tổng hợp lại, 61% các bản tóm tắt hạng nhất (23.0+22.5+15.5) liên quan đến ≥3 bước làm dày đặc. Bước CoD ưa thích trung vị ở giữa (3), và bước mong đợi là 3.06.

Dựa trên mật độ trung bình của các bản tóm tắt Bước 3, chúng ta có thể suy ra một cách thô mật độ thực thể ưa thích là ∼0.15 trong các ứng viên CoD. Từ Bảng 1, chúng ta có thể thấy rằng mật độ này phù hợp với các bản tóm tắt do con người viết (0.151), nhưng cao hơn đáng chú ý so với các bản tóm tắt được tạo bằng lời nhắc GPT-4 thông thường (0.122).

Các Chỉ số Tự động. Với tư cách là một người đánh giá, GPT-4 đã được chứng minh là có mối tương quan đầy đủ với các phán đoán của con người (Fu et al., 2023; Liu et al., 2023a), thậm chí có khả năng vượt trội hơn những người làm việc theo kiểu cộng đồng trong một số nhiệm vụ chú thích (Gilardi et al., 2023). Là một sự bổ sung cho đánh giá của con người (dưới đây), chúng tôi gợi ý GPT-4 để đánh giá các bản tóm tắt CoD (1-5) theo 5 chiều: Tính thông tin, Chất lượng, Tính mạch lạc, Có thể quy kết, và Tổng thể. Các định nghĩa về Tính thông tin, Chất lượng và Có thể quy kết đến từ Aharoni et al. (2023), trong khi Tính mạch lạc đến từ Fabbri et al. (2021)3. Tổng thể nhằm nắm bắt các phẩm chất cùng nhau. Vui lòng xem Phụ lục A để biết các lời nhắc được sử dụng để yêu cầu điểm số cho mỗi chiều. Bảng 3 cho thấy rằng việc làm dày đặc có mối tương quan với tính thông tin, nhưng có một giới hạn, với điểm số đạt đỉnh ở Bước 4 (4.74). Các chiều độc lập với bài báo: Chất lượng và Tính mạch lạc, giảm sớm hơn (sau 2 và 1 bước, tương ứng). Tất cả các bản tóm tắt được coi là Có thể quy kết về bài báo nguồn. Các điểm số Tổng thể nghiêng về các bản tóm tắt dày đặc và mang tính thông tin hơn, với Bước 4 có điểm số cao nhất. Trung bình trên các chiều, bước CoD đầu tiên và cuối cùng ít được ưa chuộng nhất, trong khi ba bước giữa gần nhau (4.78, 4.77, và 4.76, tương ứng).

Trong Phụ lục A, chúng tôi báo cáo mối tương quan ở mức độ bản tóm tắt cao nhất của chỉ số Tổng thể với các phán đoán của con người (mối tương quan Pearson 0.31), nhưng lưu ý mối tương quan thấp tổng thể – một hiện tượng được quan sát bởi Deutsch et al. (2022) khi các bản tóm tắt có chất lượng tương tự.

Phân tích Định tính. Tồn tại một sự đánh đổi rõ ràng giữa tính mạch lạc / khả năng đọc của các bản tóm tắt và tính thông tin. Để minh họa, trong Hình 4, chúng tôi trình bày hai bước CoD: một bước mà bản tóm tắt được cải thiện với nhiều chi tiết hơn, và một bước mà bản tóm tắt bị hại. Trung bình, các bản tóm tắt CoD trung gian đạt được sự cân bằng này tốt nhất, nhưng chúng tôi để lại cho công việc tương lai việc định nghĩa và định lượng chính xác sự đánh đổi này.

5 Công trình Liên quan
Tóm tắt GPT. Goyal et al. (2022) đã đánh giá GPT-3 về tóm tắt bài báo tin tức và phát hiện rằng con người thích các bản tóm tắt GPT-3 hơn các baseline có giám sát trước đó, điều này không phản ánh các chỉ số dựa trên tham chiếu và không có tham chiếu hiện có. Zhang et al. (2023) phát hiện rằng các bản tóm tắt GPT-3 không-shot hoạt động ngang hàng với con người bằng cách yêu cầu các bản tóm tắt chất lượng cao từ các nhà văn tự do. Tóm tắt Dựa trên Thực thể. Narayan et al. (2021) đề xuất tạo ra các chuỗi thực thể như một bước lập kế hoạch cho việc tinh chỉnh có giám sát của các mô hình tóm tắt, trái ngược với từ khóa (Li et al., 2020; Dou et al., 2021) hoặc các đơn vị hoàn toàn trích xuất (Dou et al., 2021; Adams et al., 2023a). Các thực thể cũng đã được kết hợp cho việc tóm tắt như một hình thức kiểm soát (Liu và Chen, 2021; He et al., 2022; Maddela et al., 2022), để cải thiện tính trung thực (Nan et al., 2021; Adams et al., 2022), và như một đơn vị để đánh giá (Cao et al., 2022; Adams et al., 2023b).

6 Kết luận
Chúng tôi nghiên cứu tác động của việc làm dày đặc bản tóm tắt đối với sở thích của con người về chất lượng tổng thể. Chúng tôi phát hiện rằng một mức độ làm dày đặc được ưa chuộng, tuy nhiên, khi các bản tóm tắt chứa quá nhiều thực thể trên mỗi token, rất khó duy trì khả năng đọc và tính mạch lạc. Chúng tôi mở nguồn tập dữ liệu kiểm tra có chú thích cũng như một tập dữ liệu đào tạo lớn hơn không có chú thích để nghiên cứu thêm về chủ đề tóm tắt có độ dài cố định, mật độ biến đổi.

7 Hạn chế
Chúng tôi chỉ phân tích CoD cho một lĩnh vực duy nhất, tóm tắt tin tức. Các chú thích không cho thấy mức độ thống nhất cao ở mức độ bản tóm tắt nhưng đã bắt đầu cho thấy các xu hướng ở mức độ hệ thống, điều này phù hợp với công việc trước đây về đánh giá dựa trên LLM (Goyal et al., 2022). Cuối cùng, GPT-4 là một mô hình nguồn đóng nên chúng tôi không thể chia sẻ trọng số mô hình. Tuy nhiên, chúng tôi công bố tất cả dữ liệu đánh giá, chú thích, cũng như 5.000 CoD không có chú thích để sử dụng cho các trường hợp sử dụng hạ nguồn, ví dụ, chưng cất mật độ vào một mô hình nguồn mở như LLAMA-2 (Touvron et al., 2023).

Tài liệu tham khảo
Griffin Adams, Alex Fabbri, Faisal Ladhak, Noémie Elhadad, và Kathleen McKeown. 2023a. Tạo ra các trích xuất EDU cho việc xếp hạng lại bản tóm tắt có hướng dẫn kế hoạch. Trong Kỷ yếu Hội nghị Thường niên lần thứ 61 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), trang 2680–2697, Toronto, Canada. Hiệp hội Ngôn ngữ học Tính toán.

Griffin Adams, Han-Chin Shing, Qing Sun, Christopher Winestock, Kathleen McKeown, và Noémie Elhadad. 2022. Học cách sửa đổi tham chiếu cho việc tóm tắt trung thực. Trong Findings of the Association for Computational Linguistics: EMNLP 2022, trang 4009–4027, Abu Dhabi, United Arab Emirates. Hiệp hội Ngôn ngữ học Tính toán.

Griffin Adams, Jason Zucker, và Noémie Elhadad. 2023b. Một meta-đánh giá các chỉ số trung thực cho việc tóm tắt khóa học bệnh viện dạng dài. arXiv preprint arXiv:2303.03948.

Roee Aharoni, Shashi Narayan, Joshua Maynez, Jonathan Herzig, Elizabeth Clark, và Mirella Lapata. 2023. Tóm tắt đa ngôn ngữ với đánh giá tính nhất quán thực tế. Trong Findings of the Association for Computational Linguistics: ACL 2023, trang 3562–3591, Toronto, Canada. Hiệp hội Ngôn ngữ học Tính toán.

Adithya Bhaskar, Alex Fabbri, và Greg Durrett. 2023. Tóm tắt ý kiến được gợi ý với GPT-3.5. Trong Findings of the Association for Computational Linguistics: ACL 2023, trang 9282–9300, Toronto, Canada. Hiệp hội Ngôn ngữ học Tính toán.

Meng Cao, Yue Dong, và Jackie Cheung. 2022. Ảo giác nhưng thực tế! Kiểm tra tính thực tế của các ảo giác trong việc tóm tắt trừu tượng. Trong Kỷ yếu Hội nghị Thường niên lần thứ 60 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), trang 3340–3354, Dublin, Ireland. Hiệp hội Ngôn ngữ học Tính toán.

Daniel Deutsch, Rotem Dror, và Dan Roth. 2022. Xem xét lại các mối tương quan ở mức độ hệ thống của các chỉ số đánh giá tóm tắt tự động. Trong Kỷ yếu Hội nghị năm 2022 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, trang 6038–6052, Seattle, United States. Hiệp hội Ngôn ngữ học Tính toán.

Zi-Yi Dou, Pengfei Liu, Hiroaki Hayashi, Zhengbao Jiang, và Graham Neubig. 2021. GSum: Một khung tổng quát cho việc tóm tắt trừu tượng có hướng dẫn bằng mạng neural. Trong Kỷ yếu Hội nghị năm 2021 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, trang 4830–4842, Online. Hiệp hội Ngôn ngữ học Tính toán.

Alexander R. Fabbri, Wojciech Kryściński, Bryan McCann, Caiming Xiong, Richard Socher, và Dragomir Radev. 2021. SummEval: Đánh giá lại việc đánh giá tóm tắt. Transactions of the Association for Computational Linguistics, 9:391–409.

Joseph L Fleiss. 1971. Đo lường sự thống nhất thang đo danh nghĩa giữa nhiều người đánh giá. Psychological bulletin, 76(5):378.

Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, và Pengfei Liu. 2023. Gptscore: Đánh giá như bạn mong muốn. arXiv preprint arXiv:2302.04166.

Fabrizio Gilardi, Meysam Alizadeh, và Maël Kubli. 2023. Chatgpt vượt trội hơn những người làm việc cộng đồng cho các nhiệm vụ chú thích văn bản. arXiv preprint arXiv:2303.15056.

Tanya Goyal, Junyi Jessy Li, và Greg Durrett. 2022. Tóm tắt tin tức và đánh giá trong kỷ nguyên của gpt-3. arXiv preprint arXiv:2209.12356.

--- TRANG 5 ---
Max Grusky, Mor Naaman, và Yoav Artzi. 2018. Newsroom: Một tập dữ liệu gồm 1.3 triệu bản tóm tắt với các chiến lược trích xuất đa dạng. Trong Kỷ yếu Hội nghị năm 2018 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, Tập 1 (Bài báo Dài), trang 708–719, New Orleans, Louisiana. Hiệp hội Ngôn ngữ học Tính toán.

Junxian He, Wojciech Kryscinski, Bryan McCann, Nazneen Rajani, và Caiming Xiong. 2022. CTRLsum: Hướng tới việc tóm tắt văn bản có thể kiểm soát chung. Trong Kỷ yếu Hội nghị năm 2022 về Các Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, trang 5879–5915, Abu Dhabi, United Arab Emirates. Hiệp hội Ngôn ngữ học Tính toán.

Jean Kaddour, Joshua Harris, Maximilian Mozes, Herbie Bradley, Roberta Raileanu, và Robert McHardy. 2023. Thách thức và ứng dụng của các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2307.10169.

Haoran Li, Junnan Zhu, Jiajun Zhang, Chengqing Zong, và Xiaodong He. 2020. Tóm tắt câu trừu tượng được hướng dẫn bởi từ khóa. Trong Kỷ yếu hội nghị AAAI về trí tuệ nhân tạo, tập 34, trang 8196–8203.

Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, và Chenguang Zhu. 2023a. Gpteval: Đánh giá nlg sử dụng gpt-4 với sự phù hợp tốt hơn với con người. arXiv preprint arXiv:2303.16634.

Yixin Liu, Alex Fabbri, Pengfei Liu, Yilun Zhao, Linyong Nan, Ruilin Han, Simeng Han, Shafiq Joty, Chien-Sheng Wu, Caiming Xiong, và Dragomir Radev. 2023b. Xem xét lại tiêu chuẩn vàng: Căn cứ đánh giá tóm tắt với đánh giá con người mạnh mẽ. Trong Kỷ yếu Hội nghị Thường niên lần thứ 61 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), trang 4140–4170, Toronto, Canada. Hiệp hội Ngôn ngữ học Tính toán.

Zhengyuan Liu và Nancy Chen. 2021. Tóm tắt đối thoại neural có thể kiểm soát với lập kế hoạch thực thể tên riêng cá nhân. Trong Kỷ yếu Hội nghị năm 2021 về Các Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, trang 92–106, Online và Punta Cana, Dominican Republic. Hiệp hội Ngôn ngữ học Tính toán.

Edward Loper và Steven Bird. 2002. Nltk: Bộ công cụ ngôn ngữ tự nhiên. arXiv preprint cs/0205028.

Mounica Maddela, Mayank Kulkarni, và Daniel Preotiuc-Pietro. 2022. EntSUM: Một tập dữ liệu cho việc tóm tắt trích xuất tập trung vào thực thể. Trong Kỷ yếu Hội nghị Thường niên lần thứ 60 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), trang 3355–3366, Dublin, Ireland. Hiệp hội Ngôn ngữ học Tính toán.

Ramesh Nallapati, Bowen Zhou, Cicero dos Santos, Çağlar Gulçehre, và Bing Xiang. 2016. Tóm tắt văn bản trừu tượng sử dụng RNN chuỗi-sang-chuỗi và hơn thế nữa. Trong Kỷ yếu Hội nghị SIGNLL lần thứ 20 về Học Ngôn ngữ Tự nhiên Tính toán, trang 280–290, Berlin, Germany. Hiệp hội Ngôn ngữ học Tính toán.

Feng Nan, Ramesh Nallapati, Zhiguo Wang, Cicero Nogueira dos Santos, Henghui Zhu, Dejiao Zhang, Kathleen McKeown, và Bing Xiang. 2021. Tính nhất quán thực tế ở mức độ thực thể của việc tóm tắt văn bản trừu tượng. Trong Kỷ yếu Hội nghị lần thứ 16 của Chương Châu Âu của Hiệp hội Ngôn ngữ học Tính toán: Tập Chính, trang 2727–2733, Online. Hiệp hội Ngôn ngữ học Tính toán.

Shashi Narayan, Yao Zhao, Joshua Maynez, Gonçalo Simões, Vitaly Nikolaev, và Ryan McDonald. 2021. Lập kế hoạch với các lời nhắc thực thể đã học cho việc tóm tắt trừu tượng. Transactions of the Association for Computational Linguistics, 9:1475–1492.

OpenAI. 2023. Báo cáo kỹ thuật gpt-4. ArXiv, abs/2303.08774.

Dongqi Pu và Vera Demberg. 2023. ChatGPT so với văn bản do con người viết: Hiểu biết về việc tóm tắt văn bản có thể kiểm soát và chuyển đổi phong cách câu. Trong Kỷ yếu Hội nghị Thường niên lần thứ 61 của Hiệp hội Ngôn ngữ học Tính toán (Tập 4: Workshop Nghiên cứu Sinh viên), trang 1–18, Toronto, Canada. Hiệp hội Ngôn ngữ học Tính toán.

Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, và Paul F Christiano. 2020. Học cách tóm tắt với phản hồi của con người. Advances in Neural Information Processing Systems, 33:3008–3021.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, và cộng sự. 2023. Llama 2: Mô hình nền tảng mở và mô hình chat được tinh chỉnh. arXiv preprint arXiv:2307.09288.

Tianyi Zhang, Faisal Ladhak, Esin Durmus, Percy Liang, Kathleen McKeown, và Tatsunori B Hashimoto. 2023. Đánh giá các mô hình ngôn ngữ lớn cho việc tóm tắt tin tức. arXiv preprint arXiv:2301.13848.

Qingyu Zhou, Nan Yang, Furu Wei, Shaohan Huang, Ming Zhou, và Tiejun Zhao. 2018. Tóm tắt tài liệu neural bằng cách học cùng lúc để chấm điểm và chọn câu. Trong Kỷ yếu Hội nghị Thường niên lần thứ 56 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), trang 654–663, Melbourne, Australia. Hiệp hội Ngôn ngữ học Tính toán.

A Các Chỉ số GPT-4
Để đánh giá kiểu Likert của GPT-4, chúng tôi sử dụng mẫu lời nhắc sau.

Bài báo: {{Bài báo}}
Bản tóm tắt: {{Bản tóm tắt}}

--- TRANG 6 ---
Vui lòng đánh giá bản tóm tắt
(1=tệ nhất đến 5=tốt nhất) về
mặt {{Chiều}}.
{{Định nghĩa}}

Dưới đây, chúng tôi trình bày các định nghĩa được cung cấp cho từng chỉ số chất lượng.

• Tính thông tin: Một bản tóm tắt mang tính thông tin nắm bắt thông tin quan trọng trong bài báo và trình bày một cách chính xác và ngắn gọn.

• Chất lượng: Một bản tóm tắt chất lượng cao có thể hiểu được và dễ hiểu.

• Tính mạch lạc: Một bản tóm tắt mạch lạc được cấu trúc tốt và tổ chức tốt.

• Có thể quy kết: Tất cả thông tin trong bản tóm tắt có hoàn toàn có thể quy kết về Bài báo không?

• Sở thích Tổng thể: Một bản tóm tắt tốt nên truyền đạt các ý tưởng chính trong Bài báo một cách ngắn gọn, hợp lý và mạch lạc.

Các lời nhắc Chất lượng và Tính mạch lạc không bao gồm Bài báo trong lời nhắc. Những định nghĩa này được diễn giải lại từ các nỗ lực chú thích tóm tắt trước đây: (Fabbri et al., 2021; Aharoni et al., 2023).

Chiều Mối tương quan
Tính thông tin 0.215
Chất lượng 0.120
Tính mạch lạc 0.178
Có thể quy kết 0.245
Tổng thể 0.311

Meta-Đánh giá. Để tính mối tương quan ở mức độ bản tóm tắt, trước tiên chúng tôi chuyển đổi dữ liệu sở thích thành một vector biểu thị số lần bản tóm tắt đó nhận được phiếu bầu hạng nhất. Bảng 4 chứng minh, không có gì đáng ngạc nhiên, rằng một lời nhắc được thiết kế để nắm bắt đánh giá tóm tắt tổng thể có mối tương quan Pearson ở mức độ bản tóm tắt cao nhất với các sở thích tổng thể (31), nhưng mối tương quan tổng thể vẫn thấp.

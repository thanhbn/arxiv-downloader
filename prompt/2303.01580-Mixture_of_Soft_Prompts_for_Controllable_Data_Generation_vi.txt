# 2303.01580.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/prompt/2303.01580.pdf
# Kích thước tệp: 515306 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Hỗn hợp các Soft Prompt cho Sinh dữ liệu có thể Kiểm soát
Derek Chen♠Celine Lee♡Yunan Lu♠Domenic Rosati†Zhou Yu♠
♠Đại học Columbia,†Scite AI,♡Đại học Cornell
{dc3761, yl4021, zy2461}@columbia.edu ,
dom@scite.ai, cl923@cornell.edu
Tóm tắt
Các mô hình ngôn ngữ lớn (LLM) sinh ra văn bản trôi chảy một cách hiệu quả khi đầu ra mục tiêu tuân theo các mẫu ngôn ngữ tự nhiên. Tuy nhiên, các tác vụ dự đoán có cấu trúc giới hạn định dạng đầu ra trong một ontology hạn chế, khiến cho ngay cả các mô hình rất lớn cũng phải vật lộn vì chúng chưa từng được huấn luyện với những hạn chế như vậy. Khó khăn trong việc sử dụng LLM cho dự đoán trực tiếp trở nên trầm trọng hơn trong các tình huống học ít mẫu (few-shot learning), thường phát sinh do sự dịch chuyển miền và hạn chế tài nguyên. Chúng tôi lật ngược vấn đề bằng cách tận dụng LLM như một công cụ để tăng cường dữ liệu thay vì là một mô hình để dự đoán trực tiếp. Phương pháp Hỗn hợp các Soft Prompt (MSP) được đề xuất của chúng tôi phục vụ như một thủ tục hiệu quả về tham số để sinh dữ liệu đa thuộc tính một cách có kiểm soát. Các cơ chế khử nhiễu được áp dụng thêm để cải thiện chất lượng dữ liệu tổng hợp. Các chỉ số tự động cho thấy phương pháp của chúng tôi có khả năng tạo ra văn bản đa dạng và tự nhiên, đồng thời bảo toàn ngữ nghĩa nhãn. Hơn nữa, MSP đạt được kết quả tiên tiến trên ba điểm chuẩn khi so sánh với các baseline mạnh. Phương pháp của chúng tôi cung cấp một cách tiếp cận thay thế tập trung vào dữ liệu để áp dụng LLM cho các tác vụ dự đoán phức tạp.

1 Giới thiệu
Các hệ thống hiểu ngôn ngữ tự nhiên (NLU) phức tạp, chẳng hạn như các bộ phân tích ngữ nghĩa, thường chỉ trở nên hữu ích sau khi được huấn luyện trên lượng lớn dữ liệu có nhãn (Chen et al., 2020). Do chi phí chú thích cao, việc có được nguồn cung dữ liệu đầy đủ nhanh chóng trở nên không khả thi. Các thiết lập tài nguyên thấp đặc biệt phổ biến khi mở rộng hệ thống sang miền hoặc dịch vụ mới (Wang et al., 2015). Tác vụ học miền đích từ dữ liệu hạn chế này được gọi là học ít mẫu thích ứng miền (Zhao et al., 2020).

Các mô hình ngôn ngữ lớn (LLM) hiện đại đã nổi lên như những bộ phân loại hiệu quả trong các thiết lập tài nguyên thấp (Sanh et al., 2022; Chung et al., 2022), và thậm chí có thể tận dụng các ví dụ ít mẫu mà không cần cập nhật gradient thông qua học ngữ cảnh (ICL) (Brown et al., 2020; Xie et al., 2022). Tuy nhiên, các LLM sẵn có đã cho thấy bằng chứng về việc gặp khó khăn với dự đoán trực tiếp trong các tác vụ NLU phức tạp hơn, chẳng hạn như những tác vụ liên quan đến phân cấp hoặc tính tổ hợp (Furrer et al., 2020; Qiu et al., 2022; Dziri et al., 2023). LLM với ICL cũng thể hiện các vấn đề khi đầu ra mục tiêu yêu cầu một cấu trúc cụ thể không được đại diện trong dữ liệu huấn luyện (Reynolds và McDonell, 2021; Min et al., 2022). Về mặt trực quan, các ví dụ ít mẫu không thể cung cấp đủ tín hiệu để học các đầu ra tùy chỉnh vì những định dạng đó được thiết kế cho các tác vụ chuyên biệt, và do đó không chắc đã xuất hiện trong các corpus web mở thường được sử dụng để huấn luyện LLM.

Ngoài ra, các vấn đề dữ liệu hạn chế cũng có thể được giải quyết thông qua các kỹ thuật tăng cường dữ liệu, bao gồm việc thay đổi token ở mức bề mặt (Wei và Zou, 2019) hoặc ánh xạ dữ liệu gốc vào một trạng thái tiềm ẩn trước khi sinh ra các ví dụ mới (Sennrich et al., 2016). Tuy nhiên, những phương pháp này thiếu khả năng kiểm soát quá trình sinh. Cụ thể, hai khía cạnh kiểm soát quan trọng khi tổng hợp dữ liệu: bảo toàn nhãn và tính đa dạng. Bảo toàn nhãn đảm bảo các phát biểu được sinh ra vẫn trung thành với các thuộc tính ban đầu trong dữ liệu gốc. Tính đa dạng đảm bảo các phát biểu được sinh ra cung cấp phạm vi phủ tốt hơn của phân phối mục tiêu để hướng dẫn mô hình về phía khái quát hóa tốt hơn.

Để tránh các cạm bẫy của tăng cường dữ liệu ngây thơ, chúng tôi tận dụng khả năng sinh văn bản trôi chảy của LLM bằng cách tận dụng nó như một công cụ để sinh dữ liệu có kiểm soát. Cụ thể, chúng tôi bắt đầu bằng việc điều chỉnh một tập hợp các soft prompt hiệu quả về tham số cho từng thuộc tính có trong dữ liệu gốc. Sau đó, chúng tôi giới thiệu một phương pháp mới để kết hợp Hỗn hợp các Soft Prompt (MSP) để sinh dữ liệu huấn luyện đa dạng, có điều kiện theo lớp một cách được kiểm soát cẩn thận. Cuối cùng, dữ liệu tổng hợp được sử dụng để huấn luyện một mô hình nhỏ hơn, downstream cho tác vụ hiện tại (Hình 1). Sử dụng LLM như các trình sinh dữ liệu thay vì các bộ dự đoán hộp đen cung cấp các lợi ích về khả năng giải thích và tính linh hoạt vì dữ liệu tổng hợp có thể được kiểm tra trực tiếp về chất lượng.

Chúng tôi áp dụng MSP cho ba tác vụ NLU đa dạng để kiểm tra tính tổng quát của nó. So với việc điều chỉnh prompt trực tiếp một LLM với dữ liệu ít mẫu, việc sử dụng LLM để tăng cường dữ liệu thay thế có khả năng vượt trội hơn một mô hình cùng kích thước lên đến 27% (xem Bảng 9). Chúng tôi cũng so sánh với một loạt các baseline tăng cường dữ liệu và sinh văn bản có kiểm soát cạnh tranh, nơi phương pháp của chúng tôi dẫn đến hiệu suất downstream vượt trội trên cả ba điểm chuẩn. Phân tích định tính và đánh giá con người thêm xác minh rằng dữ liệu được sinh bởi MSP xếp hạng cao hơn về các thước đo chất lượng, tính cụ thể và độ chính xác (xem Bảng 2). Nhìn chung, phương pháp được đề xuất của chúng tôi đại diện cho một cách tiếp cận mới, tập trung vào dữ liệu để sử dụng các LLM được điều chỉnh prompt để giải quyết học ít mẫu thích ứng miền.

2 Công thức hóa Tác vụ
Hiểu ngôn ngữ tự nhiên (NLU) ít mẫu có thể có nhiều hình thức như phân tích ngữ nghĩa hoặc nhận dạng thực thể có tên. Trong các tác vụ như vậy, một mô hình nhằm hiểu một đầu vào ngôn ngữ tự nhiên, nhưng chỉ có một số lượng hạn chế các ví dụ huấn luyện xi để làm như vậy. Chính thức, chúng ta được cho một tập dữ liệu Ds = ({xi, yi}n)s với n ví dụ huấn luyện đều thuộc về một nhóm s miền nguồn. Mục tiêu là mở rộng sang một miền đích t, chỉ được cho m ví dụ trong miền t: Dt = ({xj, yj}m), trong đó m << n. Các ứng dụng thực tế của NLU còn phức tạp hơn bởi bản chất đa khía cạnh của mục tiêu, nơi một nhãn duy nhất yi có thể được cấu thành từ nhiều thuộc tính duy nhất {attr a}.

2.1 Dự đoán Trực tiếp Ít mẫu
Một cách đơn giản để tiếp cận vấn đề này là tiền huấn luyện một mạng nơ-ron lớn có khả năng xử lý các tình huống tài nguyên thấp. Gần đây, LLM đã thể hiện hiệu suất cạnh tranh trong nhiều tác vụ ít mẫu bằng cách sử dụng dữ liệu hạn chế làm ví dụ cho học ngữ cảnh (Sanh et al., 2022). Tuy nhiên, dự đoán trực tiếp theo cách này chứa nhiều nhược điểm, chẳng hạn như thiếu kiểm soát về quá trình dự đoán. Điều này thúc đẩy chúng tôi xem xét một framework thay thế.

2.2 Phương án Thay thế Tập trung vào Dữ liệu
Một cách khác để xử lý dữ liệu hạn chế là thực hiện tăng cường dữ liệu nơi dữ liệu gốc ít mẫu được sử dụng để tạo ra các ví dụ huấn luyện bổ sung Dsyn = ({xk, yk}p). Sau đó, tất cả dữ liệu gốc ban đầu được kết hợp với dữ liệu tổng hợp Ds ∪ Dt ∪ Dsyn để huấn luyện một mô hình downstream. Ở mức độ mà mô hình downstream nhỏ hơn đáng kể so với mô hình gốc (~15 lần nhỏ hơn trong trường hợp của chúng tôi), quá trình này có thể được xem như chưng cất tri thức thông qua truyền tải dữ liệu.

Sử dụng LLM như một công cụ tăng cường dữ liệu thay vì một bộ dự đoán trực tiếp mang lại nhiều lợi ích: (a) Dữ liệu được sinh có thể được kiểm tra, điều này cải thiện khả năng giải thích và khả năng giải thích. (b) Các sửa đổi bổ sung, chẳng hạn như khử nhiễu hoặc lọc dữ liệu, có thể được xếp chồng lên trên dữ liệu được sinh, cho phép tính linh hoạt hơn trong việc cải thiện hiệu suất. (c) Dữ liệu có thể được sử dụng để huấn luyện các mô hình nhỏ hơn, hiệu quả tính toán hơn để suy luận nhanh hơn. (d) Dữ liệu là model agnostic, dẫn đến khả năng chuyển giao qua các loại mô hình (Xem Phần 5.3). Chúng tôi tận dụng tất cả những điểm này trong phương pháp của mình.

3 Hỗn hợp các Soft Prompt

3.1 Tổng quan
Phương pháp của chúng tôi tuân theo một quy trình ba bước: điều chỉnh soft-prompt, sinh dữ liệu, và huấn luyện mô hình downstream (xem Hình 2). Prompt đầy đủ được đưa vào LLM có thể được chia thành bốn thành phần: tiền tố hướng dẫn, soft prompt thuộc tính, meta-data miền và các ví dụ được truy xuất.

3.2 Xây dựng Prompt
Điều chỉnh soft prompt đã nổi lên như một phương pháp hiệu quả về tham số để tận dụng sức mạnh của LLM mà không cần yêu cầu tính toán nặng nề để huấn luyện từ đầu (Lester et al., 2021). Cốt lõi của cách tiếp cận của chúng tôi dựa vào soft prompt, nhưng thay vì điều chỉnh prompt để đưa ra dự đoán trực tiếp, chúng tôi thay vào đó hướng dẫn LLM sinh ra các ví dụ huấn luyện chất lượng cao.

Đầu vào đầy đủ chứa bốn phần. (1) Đầu tiên là tiền tố hướng dẫn được khởi tạo với cụm từ "Show me three distinct utterances that all express the X" được chia sẻ trên tất cả các ví dụ huấn luyện. (2) Các soft prompt được khởi tạo với tên và mô tả của thuộc tính, ví dụ "song is a musical song or melody", và thường là cụ thể theo miền. (3) Phần thứ ba bao gồm meta-data liên quan đến tác vụ như giá trị slot hoặc tên miền. (4) Cuối cùng, một số ít ví dụ được thêm vào để hướng dẫn mô hình về phía tăng cường dữ liệu tốt hơn, được chọn dựa trên sự chồng chéo thuộc tính. (Xem Phụ lục B để biết chi tiết.) Ví dụ gốc chính nó được sử dụng làm phát biểu mục tiêu để huấn luyện. (Nửa trên của Hình 2)

3.3 Trộn Thuộc tính
Để kiểm soát các đặc tính của văn bản tổng hợp, chúng tôi điều kiện hóa mô hình trên các thuộc tính mong muốn trong quá trình sinh. Tuy nhiên, các công trình trước về sinh văn bản có kiểm soát chủ yếu tập trung vào một ràng buộc thuộc tính duy nhất, chẳng hạn như cảm xúc (Qian et al., 2022a). Ngược lại, các ví dụ cá nhân trong các tác vụ của chúng tôi đều chứa nhiều thuộc tính. Ví dụ, một tác vụ là phát hiện ý định đa khía cạnh, nơi một phát biểu đối thoại duy nhất có thể chứa ba thuộc tính ý định (Hình 2, Hộp 1a). Làm thế nào các embedding thuộc tính này nên được kết hợp?

Chúng tôi thử nghiệm với năm phương pháp khác nhau để tổ hợp các thuộc tính để sinh dữ liệu. Đối với tất cả các phương pháp, chúng tôi khởi tạo một tập hợp các soft prompt SP cho mỗi thuộc tính attr trong ontology của tập dữ liệu. Cho một ví dụ phát biểu huấn luyện xi và tập hợp các thuộc tính yi của nó, chúng tôi tổ hợp một prompt hỗn hợp Pi kết hợp tất cả các thuộc tính liên quan. Để làm như vậy, chúng tôi rút ra các embedding thuộc tính {attr_emb} ⊆ SP sao cho ∀attr a ∈ yi, attr_emb a là embedding prompt thuộc tính tương ứng với attr a. Tổ hợp prompt sau đó được thực hiện thông qua một trong năm phương pháp trộn thuộc tính sau.

Giả sử một ví dụ gốc bao gồm n thuộc tính, được lập chỉ mục bởi a. Phương pháp Concat đơn giản nối tất cả các embedding thuộc tính lại với nhau và đặt kết quả ở giữa tiền tố hướng dẫn và văn bản đầu vào còn lại.

Pi = [attr_emb 1; attr_emb a; attr_emb n] (1)

Một nhược điểm chính của Concat là một số lượng biến đổi các embedding thuộc tính tạo ra một đầu vào có độ dài biến đổi. Để tránh sự bất tiện này, chúng tôi cũng kiểm tra phương pháp Pooling kết hợp mỗi embedding thuộc tính bằng cách lấy giá trị trung bình qua các chiều embedding. Bằng cách đó, các chiều đầu ra cố định cho phép xử lý batch dễ dàng.

Pi = (1/N) ∑(a=1 to N) attr_emb a (2)

Hạn chế của việc chỉ lấy trung bình các embedding là nó đối xử với tất cả các giá trị embedding như nhau. Để xem làm thế nào chúng ta có thể kết hợp thông tin theo cách có ý nghĩa hơn, chúng tôi khám phá các phương pháp bổ sung học cách cân nhắc các embedding thuộc tính.

Phương pháp cơ chế Attention bắt đầu bằng việc lấy trung bình các embedding đầu vào dọc theo chiều embedding, truyền chúng qua một lớp tuyến tính feed-forward, và đi qua hàm kích hoạt SiLU (Elfwing et al., 2018). Layer norm tiếp theo là softmax được điều chỉnh nhiệt độ sau đó tạo ra một điểm số attention αi. Điểm số attention tính toán tổng có trọng số của các soft prompt thuộc tính, tạo ra một prompt hỗn hợp cuối cùng.

q̄ = meanpool(attr_emb a)
p = SiLU(Wq · q̄T)
αattn = softmax(LN(p))
Pi = αattn · q̄ (3)

Lấy cảm hứng từ Asai et al. (2022), người sử dụng soft prompt để chia sẻ tri thức, chúng tôi cũng kiểm tra một sửa đổi của phương pháp Attention giới thiệu một lớp Bottleneck vào quá trình. Cụ thể hơn, các embedding đầu vào được lấy trung bình được chiếu xuống vào một chiều nhỏ hơn, và tiếp theo là một tính phi tuyến trước khi được chiếu trở lại lên hình dạng embedding đầu vào ban đầu. Điều này được theo sau bởi layer norm và softmax như trước để tính toán điểm số attention.

Hdown = WTdown(q̄)
Hup = WTup(SiLU(Hdown))
α̂attn = softmax(LN(Hup))
Pi = α̂attn · q̄ (4)

Cuối cùng, phương pháp hỗn hợp CNN kết hợp nhiều soft prompt qua một mạng nơ-ron tích chập. Chúng tôi bắt đầu bằng việc đệm thuộc tính đến một độ dài cố định. Sau đó chúng tôi truyền embedding qua hai lớp convolution, nơi hàm kích hoạt ReLU được sử dụng giữa mỗi lớp.

qcnn = pad(attr_emb a)
qcnn = conv1(qcnn)
Pi = conv2(ReLU(qcnn)) (5)

3.4 Khử nhiễu Dữ liệu
Như bước cuối cùng trong pipeline MSP, chúng tôi tận dụng thực tế rằng dữ liệu tăng cường có thể được điều chỉnh dễ dàng để cải thiện chất lượng dữ liệu hơn nữa. Cụ thể, chúng tôi sinh thêm 20% dữ liệu và sau đó áp dụng lọc để khử nhiễu các mẫu, đưa số lượng ví dụ trở lại phù hợp với số lượng ban đầu. Lọc được thực hiện bằng cách lặp qua các ví dụ tổng hợp và lựa chọn động những cái nào để giữ dựa trên hai yếu tố.

Yếu tố đầu tiên được thúc đẩy bởi quan sát rằng một số lớp thuộc tính được đại diện quá mức trong dữ liệu gốc. Do đó, chúng tôi lấy mẫu các ví dụ với tỷ lệ tỷ lệ nghịch với tần suất xuất hiện của một thuộc tính. Trong thực tế, điều này cân bằng lại dữ liệu để tất cả các thuộc tính có cơ hội xuất hiện bằng nhau.

Yếu tố thứ hai nhằm cải thiện bảo toàn nhãn bằng cách giảm tính đa dạng. Trong quá trình kiểm tra kết quả sơ bộ, chúng tôi phát hiện rằng hầu hết các lỗi đến như kết quả của độ chính xác thấp vì dữ liệu được sinh ra lệch quá xa khỏi nhãn mục tiêu. Do đó, chúng tôi chống lại điều này bằng cách giữ các ví dụ tổng hợp tương tự hơn với dữ liệu gốc ban đầu. Độ tương tự giữa dữ liệu tổng hợp và dữ liệu gốc được đo bằng độ tương tự cosine của các embedding SentenceTransformer (Reimers và Gurevych, 2019) của chúng. Chúng tôi thấy phương pháp giữ các ví dụ tổng hợp tương tự này hoạt động tốt hơn so với việc sử dụng nhiệt độ thấp hơn trong quá trình sinh.

4 Thiết lập Thí nghiệm

4.1 Tập dữ liệu và Tác vụ
Chúng tôi kiểm tra trên ba tập dữ liệu hiểu ngôn ngữ tự nhiên đa thuộc tính, đa dạng. Các tập dữ liệu này cung cấp các chia tách ít mẫu được xác định trước và phân chia tự nhiên của các miền nguồn và đích để kiểm tra.

NLU++ Tác vụ đầu tiên của chúng tôi là phát hiện ý định đa khía cạnh (Casanueva et al., 2022), nơi một mô hình nên dự đoán tất cả các ý định có trong lượt đối thoại đã cho. Vì có thể dự đoán quá nhiều hoặc quá ít ý định, thành công được đo bằng điểm F1. Hai chủ đề, khách sạn và ngân hàng, có trong tập dữ liệu, với cả hai đều chứa các phiên bản chung và cụ thể. Điều này hiệu quả tạo ra bốn khối ví dụ. Thiết lập miền chéo trong bài báo đánh giá trên phiên bản chung của mỗi chủ đề, vì vậy chúng tôi đặt ba khối làm miền nguồn (tức là khách sạn chung, khách sạn cụ thể, ngân hàng cụ thể) và để lại khối thứ tư làm miền đích (tức là ngân hàng chung). Đầu ra mục tiêu có dạng danh sách các ý định.

CrossNER Tác vụ thứ hai của chúng tôi là nhận dạng thực thể có tên miền chéo, nơi thách thức chính là chuyển giao từ miền tin tức chung sang một trong năm miền chuyên biệt với các loại thực thể tùy chỉnh (Liu et al., 2021b). Ví dụ, Politics chứa các thực thể politician và election duy nhất không được tìm thấy trong các miền khác. Đầu ra mục tiêu là một chuỗi các cặp (danh mục thực thể, giá trị thực thể).

TOPv2 Tác vụ thứ ba chúng tôi xem xét là phân tích ngữ nghĩa tổ hợp, hướng tác vụ (Chen et al., 2020). Dữ liệu nguồn chung bao gồm sáu miền cá nhân: Alarm, Event, Messaging, Navigation, Music, và Timer. Hai miền đích là Reminder và Weather, có tập dữ liệu huấn luyện chỉ cho phép 25 SPIS (mẫu trên mỗi ý định và slot). Theo thiết lập của bài báo gốc, chúng tôi cũng thực hiện các bước tiền xử lý để xây dựng dạng chuẩn để dự đoán. Định dạng cuối cùng bao gồm các nhãn đa ý định theo sau là các cặp slot-value.

4.2 Phương pháp Baseline
Dự đoán Trực tiếp Chúng tôi sử dụng FLAN-T5 XXL (Chung et al., 2022) làm mô hình cơ sở để sinh dữ liệu. GODEL (Peng et al., 2022) phục vụ như LLM downstream nhỏ hơn của chúng tôi, bắt đầu với backbone T5 (Raffel et al., 2020) và được tinh chỉnh trên dữ liệu liên quan đến đối thoại. Với chỉ 770M tham số, mô hình học sinh chứa khoảng 15 lần ít tham số hơn so với mô hình thầy. Để so sánh công bằng, chúng tôi sử dụng chính xác cùng mô hình một lần nữa để đưa ra dự đoán trực tiếp với thiết lập chỉ điều chỉnh prompt.

Chúng tôi cũng so sánh với các mô hình tỷ tham số được tối ưu hóa thông qua học ngữ cảnh và prompting chuỗi suy nghĩ (Wei et al., 2022), cụ thể là GPT-3.5-turbo và GPT-4. Prompt học ngữ cảnh bao gồm bốn thành phần: tiền tố hướng dẫn; danh sách toàn diện các thuộc tính cụ thể theo miền; meta-data liên quan; và năm ví dụ câu hỏi-trả lời. Các ví dụ được chọn dựa trên tần suất của các thuộc tính của chúng qua tập dữ liệu, với các ứng cử viên xếp hạng cao nhất được chọn làm ví dụ đại diện. Tiền tố hướng dẫn được thiết kế prompt thủ công qua hàng chục lần thử để đảm bảo tính công bằng. Chúng tôi thực hiện prompting chuỗi suy nghĩ bằng cách chia tác vụ thành 3 bước. Đầu tiên, chúng tôi yêu cầu mô hình dự đoán miền của câu. Tiếp theo, chúng tôi có mô hình suy nghĩ về các loại thuộc tính có trong phát biểu. Cuối cùng, chúng tôi có LLM dự đoán trực tiếp các giá trị thuộc tính của đầu vào đã cho.

Tăng cường Dữ liệu Để cải thiện so với mô hình học sinh vanilla, chúng tôi tăng cường dữ liệu ít mẫu với các kỹ thuật khác nhau. Đầu tiên chúng tôi thử Easy Data Augmentation (EDA) rất đơn giản (Wei và Zou, 2019) ngẫu nhiên loại bỏ và hoán đổi token. Chúng tôi cũng xem xét masked in-filling (Kobayashi, 2018) che một số phần của văn bản và sử dụng mô hình BERT để lấp đầy chúng trở lại. Chúng tôi cũng xem xét mô hình BART-large (Lewis et al., 2020) được huấn luyện trên corpus paraphrase (Dolan và Brockett, 2005; Zhang et al., 2019). Cuối cùng, chúng tôi cũng so sánh với round-trip translation (RTT) qua năm ngôn ngữ pivot (Sennrich et al., 2016). Các kỹ thuật này đều sinh dữ liệu đa dạng, nhưng có thể không chính xác vì chúng không có cơ chế để thực thi các nhãn thuộc tính xuất hiện trong dữ liệu tổng hợp.

Sinh Văn bản Có kiểm soát Chúng tôi cũng kiểm tra các phương pháp điều kiện hóa trên các thuộc tính trong quá trình sinh để khuyến khích bảo toàn nhãn. Chúng tôi xem xét một Conditional LM (CLM), tinh chỉnh GPT2 để tạo ra một ví dụ phát biểu khi được cung cấp một biểu diễn được tuần tự hóa của nhãn thuộc tính (Anaby-Tavor et al., 2020). Hướng khác thực hiện giải mã có trọng số của logit trong quá trình suy luận, nơi chúng tôi sử dụng DExperts để sinh văn bản có ràng buộc (Liu et al., 2021a). Chúng tôi cũng xem xét một conditional variational auto-encoder (CVAE) (Hu et al., 2017; Xia et al., 2020) học sinh các đầu ra có ràng buộc thuộc tính bằng cách lấy mẫu từ không gian tiềm ẩn giữa encoder và decoder. Chúng tôi thêm kiểm tra một baseline có động lực từ từ vựng, Keyword2Text (K2T) nơi phân phối xác suất được dịch chuyển về phía các từ khóa mục tiêu trong thời gian giải mã (Pascual et al., 2021). Cuối cùng, chúng tôi thử nghiệm với một baseline điều chỉnh prompt (PT) sử dụng GPT-4 để sinh các ví dụ tổng hợp. Điều này bao gồm một tùy chọn áp dụng kỹ thuật khử nhiễu của chúng tôi (PT + Denoising) trước khi huấn luyện trên tác vụ downstream. Tất cả các kỹ thuật này thể hiện sự tuân thủ nghiêm ngặt hơn với nhãn, nhưng có thể thiếu tính đa dạng.

4.3 Đánh giá Tự động
Ngoài độ chính xác downstream, chúng tôi cũng đánh giá dữ liệu tổng hợp định lượng với ba chỉ số. Distinct@K đo tính đa dạng của văn bản dựa trên n-gram duy nhất, nơi chúng tôi đặt k=1,2,3 theo thực hành thông thường (Li et al., 2016). Perplexity đại diện cho tính trôi chảy của văn bản, chúng tôi đo thông qua GPT2-large (Radford et al., 2019). Thứ ba, chúng tôi sử dụng Correctness để kiểm tra dữ liệu tổng hợp bảo toàn các nhãn thuộc tính thích hợp như thế nào. Để làm như vậy, chúng tôi huấn luyện một oracle với tất cả dữ liệu có sẵn (tức là không còn ít mẫu) để phân loại các thuộc tính chính trong một phát biểu. (Chi tiết hơn trong Phụ lục A)

4.4 Chi tiết Triển khai
Tiền tố hướng dẫn được đặt với độ dài 100 token, trong khi độ dài token thuộc tính được đặt là 20 token. Sau khi điều chỉnh siêu tham số, chúng tôi dừng lại ở 3e-2 làm tỷ lệ học cho mô hình thầy và 3e-5 cho học sinh (Xem Phụ lục B). Các phương pháp tăng cường được chuẩn hóa để sinh bốn điểm dữ liệu mới cho mỗi ví dụ gốc.

5 Kết quả và Phân tích

5.1 Kết quả Chính
Như thấy trong Bảng 3, MSP w/ Bottleneck đạt được kết quả tiên tiến trên cả ba tập dữ liệu, với cải thiện trung bình 20.3% so với các baseline ban đầu. MSP đạt điểm số end-to-end cao nhất trên 8 trong 9 miền có thể, đồng thời cũng thể hiện hiệu suất cạnh tranh trên miền còn lại (tức là TOPv2 Reminder). Đáng chú ý, khu vực mà MSP không đạt được thứ hạng cao nhất, nó thực sự bị vượt qua bởi một kỹ thuật meta-learning. Tuy nhiên, meta-learning và tăng cường dữ liệu là các phương pháp trực giao, vì vậy trong thực tế, hai phương pháp này có thể và nên được kết hợp để tạo ra kết quả tốt hơn so với bất kỳ phương pháp nào một mình.

Mặc dù khả năng đáng chú ý của các LM được tiền huấn luyện lớn để sinh ngôn ngữ mạch lạc và trôi chảy, khả năng tạo ra các đầu ra có cấu trúc của chúng bị hạn chế. Đặc biệt, hiệu suất từ các mô hình dự đoán trực tiếp xấu đi khi xử lý các phát biểu có cấu trúc phức tạp hơn và các thuộc tính đa dạng, chẳng hạn như TOPv2. Tận dụng một mô hình tỷ tham số mang lại cải thiện krận biên, nhưng hiệu suất vẫn thấp hơn nhiều so với các baseline tổng hợp dữ liệu. Như thấy trong Bảng 4, ngay cả khi LLM được mở rộng đến kích thước của GPT-4 (OpenAI, 2023), dự đoán trực tiếp cho kết quả tệ hơn so với MSP. Mặt khác, bằng cách tận dụng LLM để tăng cường dữ liệu, phương pháp của chúng tôi thành công nghiêng về thế mạnh bẩm sinh của các mô hình ngôn ngữ như các trình sinh văn bản thay vì ép buộc chúng học các chuỗi đầu ra mục tiêu chuyên biệt.

So với các baseline tăng cường dữ liệu, MSP liên tục dẫn đến kết quả tốt hơn trên cả ba tập dữ liệu. Về mặt định tính, chúng tôi quan sát rằng tất cả bốn phương pháp tăng cường ngây thơ tạo ra các ví dụ cuối cùng lệch khỏi các thuộc tính ngữ nghĩa mong muốn. Điều này gây ra suy giảm hiệu suất downstream so với MSP (Xem Bảng 11).

Trong khi các phương pháp sinh văn bản có kiểm soát (CTG) có thể vượt trội hơn baseline GODEL ngây thơ, CTG kém hiệu suất hơn cùng mô hình GODEL trung bình 10% khi được tăng cường với dữ liệu tổng hợp MSP. Xu hướng hiệu suất này được phản ánh ngay cả khi sử dụng GPT-4 để sinh văn bản có kiểm soát, như thể hiện trong Bảng 4. Phân tích định tính cho thấy các phương pháp CTG không thể nắm bắt cấu trúc phức tạp được yêu cầu bởi tác vụ sinh đa thuộc tính, vì vậy dữ liệu tổng hợp này kết thúc như nhiễu và thực sự làm tổn hại hiệu suất. Mặt khác, MSP có thể xử lý đáng tin cậy các ràng buộc từ vựng, ngữ nghĩa và cấu trúc.

5.2 Chất lượng Dữ liệu Tổng hợp
Để đánh giá con người, chúng tôi khảo sát 30 người nói tiếng Anh thông thạo đã xem xét các phát biểu được sinh theo các chỉ số đã cho: (1) Chất lượng - văn bản đúng ngữ pháp, mạch lạc và trôi chảy. (2) Tính cụ thể - văn bản cụ thể cho chủ đề mục tiêu, thay vì có thể áp dụng chung chung. (3) Độ chính xác - văn bản phản ánh chính xác các thuộc tính ngữ nghĩa mong muốn. Kết quả có thể được thấy trong Bảng 2. Kiểm tra với phương pháp DA hàng đầu (Paraphrase) và phương pháp CTG hàng đầu (CLM), phương pháp của chúng tôi (MSP) xếp hạng cao nhất trên tất cả các chỉ số, với cải thiện đặc biệt lớn trong Tính cụ thể.

Ngoài độ chính xác downstream, chúng tôi cũng sử dụng đánh giá tự động để đánh giá chất lượng của dữ liệu tổng hợp. Các phương pháp DA có chất lượng ngôn ngữ thấp hơn, nhưng đạt được bảo toàn thuộc tính cao hơn vì thay đổi một vài token có thể dễ dàng làm hại khả năng đọc, nhưng thường không thay đổi ý nghĩa tổng thể. Ngược lại, các phương pháp CTG nói chung thể hiện tính trôi chảy cao, nhưng điểm số độ chính xác thấp của chúng cũng tiết lộ khó khăn trong việc nắm bắt tất cả các thuộc tính ngữ nghĩa mong muốn. Bảng 6 cho thấy dữ liệu được sinh bởi MSP đạt được sự cân bằng giữa tính đa dạng và độ chính xác, mà không cần bất kỳ điều chỉnh thủ công nào.

5.3 Nghiên cứu Loại bỏ
Để hiểu tác động của mỗi phần trong pipeline MSP, chúng tôi chạy các nghiên cứu loại bỏ dọc theo một miền từ mỗi tập dữ liệu. Kết quả trong Bảng 7 cho thấy tất cả các phần của kỹ thuật của chúng tôi cung cấp những cải thiện có ý nghĩa. Đặc biệt, tiền tố hướng dẫn nói với mô hình sinh các ví dụ tương tự, và loại bỏ prompt này liên tục dẫn đến điểm số thấp nhất. Như mong đợi, loại bỏ bất kỳ phần nào của các soft prompt có thể huấn luyện dẫn đến suy giảm đáng kể.

Hàng cuối cùng trong Bảng 7 bao gồm một điều chỉnh cuối cùng cho phương pháp hoán đổi backbone Flan-T5 với GPT-J-6B (Wang và Komatsuzaki, 2021). Thay đổi này từ một mô hình sequence-to-sequence sang một mô hình ngôn ngữ nhân quả làm nổi bật tính linh hoạt của cách tiếp cận của chúng tôi vì khả năng chuyển giao của dữ liệu là model agnostic so với nguồn gốc của nó. Mặc dù mô hình downstream được huấn luyện với dữ liệu tăng cường GPT không mạnh bằng mô hình được huấn luyện với dữ liệu tăng cường T5, nó rõ ràng vượt trội hơn mô hình GPT-J-6B thực hiện dự đoán trực tiếp.

6 Công trình Liên quan
Bài báo của chúng tôi giải quyết học ít mẫu đa khía cạnh nơi mục tiêu là một đầu ra có cấu trúc chứa nhiều thuộc tính, và mô hình chỉ có một vài ví dụ để học mẫu như vậy. Với độ phức tạp của tác vụ, nghiên cứu trước đây huấn luyện các mô hình tùy chỉnh cho mỗi tập dữ liệu (Zheng et al., 2022; Schucher et al., 2022). Thay vào đó, chúng tôi tận dụng sức mạnh của LLM (Brown et al., 2020; Chung et al., 2022) để thiết kế một giải pháp tổng quát hơn thông qua tổng hợp dữ liệu có kiểm soát.

Đặc biệt, chúng tôi tổ hợp nhiều Soft Prompt để sinh dữ liệu huấn luyện mong muốn cho tác vụ downstream. Do đó, chúng tôi xây dựng dựa trên công trình nền tảng nghiên cứu điều chỉnh soft prompt (Lester et al., 2021; Vu et al., 2022), cũng như các phương pháp tinh chỉnh hiệu quả tham số khác (Houlsby et al., 2019; Li và Liang, 2021). Ngoài ra, Wang et al. (2022) và Chen et al. (2022) thực hiện tăng cường dữ liệu với prompting, nhưng prompt của họ không có tính tổ hợp vì thiết lập tác vụ của họ tập trung vào dự đoán lớp một khía cạnh.

Tăng cường Dữ liệu là một kỹ thuật phổ biến trong NLP để chống lại dữ liệu hạn chế có sẵn với học ít mẫu (Feng et al., 2021; Chen và Yin, 2022). Các hương vị của tăng cường dữ liệu bao gồm thay đổi dạng bề mặt (Wei và Zou, 2019), nhiễu loạn tiềm ẩn (Sennrich et al., 2016; Fabius et al., 2015) hoặc giám sát phụ trợ (Chen và Yu, 2021). Phương pháp của chúng tôi có thể được coi là một dạng sinh văn bản với transformer (Kumar et al., 2020; Ng et al., 2020), gần đây dựa vào các mô hình ngôn ngữ ngày càng lớn hơn (Yoo et al., 2021; Wang et al., 2021a,b). Trong khi các phương pháp này paraphrase hoặc pseudo-label một phát biểu gốc, MSP thay vào đó điều kiện hóa trên một nhãn để kiểm soát việc sinh văn bản.

Kết quả là, phương pháp của chúng tôi cũng liên quan đến các kỹ thuật Sinh Văn bản Có kiểm soát. Không giống như giải mã từ vựng có ràng buộc (Pascual et al., 2021), nhằm tạo ra văn bản chứa một tập hợp từ khóa được chỉ định trước, công việc của chúng tôi tập trung vào kiểm soát ngữ nghĩa của đầu ra, chẳng hạn như một chủ đề hoặc ý định người dùng (Mou et al., 2016; Hokamp và Liu, 2017; Post và Vilar, 2018; Yao et al., 2019). Để kiểm soát ngữ nghĩa, một loạt các tùy chọn tồn tại để hướng dẫn việc sinh về phía một thuộc tính duy nhất, bao gồm những cái huấn luyện mô hình từ đầu (Keskar et al., 2019; Wang et al., 2019) hoặc những cái chỉ điều chỉnh một vài tham số (Ribeiro et al., 2021; Lin et al., 2021; Yu et al., 2021; Liu et al., 2023). Thậm chí có các phương pháp giữ mô hình cơ sở đông lạnh và thay vào đó điều chỉnh logit với giải mã có trọng số để kiểm soát đầu ra (Dathathri et al., 2020; Krause et al., 2021; Yang và Klein, 2021; Zhang và Song, 2022). Các phương pháp này có thể duy trì chủ đề, nhưng thường hy sinh khả năng sinh các token cụ thể, trong khi MSP có thể duy trì cả kiểm soát ngữ nghĩa và từ vựng, mang lại kết quả vượt trội.

Cuối cùng, MSP liên quan đến các kỹ thuật kết hợp nhiều prompt lại với nhau. Nayak et al. (2022) đề xuất kết hợp các soft prompt thông qua nối, nhưng mục đích của họ là cải thiện dự đoán trực tiếp trong một tác vụ dựa trên thị giác, trái ngược với sinh dữ liệu cho các tác vụ NLU. Qin và Eisner (2021) nhắm mục tiêu các tác vụ phân loại sử dụng các LM được tiền huấn luyện, nhưng kỹ thuật mixture-of-experts của họ chọn các prompt cá nhân từ nhiều ứng cử viên để thỏa mãn một ràng buộc duy nhất, thay vì trộn nhiều prompt để đáp ứng nhiều ràng buộc. Công việc của chúng tôi tương tự nhất với những người thực hiện sinh văn bản đa khía cạnh (Yang et al., 2022; Gu et al., 2022; Qian et al., 2022b). Tuy nhiên, mục đích chính của việc cải thiện chất lượng văn bản phù hợp với mục đích thứ cấp của chúng tôi (Phần 5.2). Trong khi những nỗ lực trước đây này tập trung độc quyền vào sinh văn bản, phương pháp của chúng tôi kiểm soát việc sinh như một phương tiện để đạt mục đích.

7 Kết luận
Bài báo của chúng tôi trình bày một phương pháp thay thế cho học ít mẫu sử dụng LLM như một công cụ tăng cường dữ liệu trung gian thay vì để dự đoán trực tiếp. Bằng cách thực hiện sinh dữ liệu như một bước trung gian để cải thiện hiệu suất tác vụ end-to-end, phương pháp của chúng tôi mang lại các lợi ích như khả năng giải thích, tính linh hoạt và tính mô-đun. So với các phương pháp tăng cường dữ liệu mạnh khác, chúng tôi cho thấy MSP mang lại dữ liệu chất lượng cao hơn có thể được sử dụng hiệu quả để cải thiện hiệu suất trong các tác vụ downstream. Phương pháp hiệu quả tham số này để thực hiện sinh dữ liệu có kiểm soát là một mô hình mạnh mẽ để sử dụng LLM trong các tình huống tài nguyên thấp; các kết quả tích cực từ các phương pháp được đề xuất trong công việc này gợi ý công việc tương lai đầy hứa hẹn trong việc khám phá các kiểm soát chặt chẽ hơn và các cơ chế lọc thông minh hơn cho tăng cường dữ liệu. Cuối cùng, chúng tôi khuyến khích những người khác xem xét sử dụng LLM như các công cụ để sinh dữ liệu, thay vì chỉ để sinh dự đoán trực tiếp.

8 Hạn chế
Mô hình lớn nhất chúng tôi có thể truy cập khả thi là T5-XXL chứa 11 tỷ tham số. Trong khi chúng tôi đã thử nghiệm với GPT-3.5 và GPT-4, hoàn toàn khả thi rằng GPT5 (kích thước chưa biết) hoặc OPT3 (175 tỷ), hoặc mô hình PALM (540 tỷ) có thể vượt trội hơn kết quả của chúng tôi trong các thiết lập ít mẫu này sử dụng điều chỉnh prompt với ví dụ. Tuy nhiên, chúng tôi sẽ đặt ra rằng khi khả năng của những mô hình thực sự khổng lồ này cải thiện, khả năng sinh dữ liệu huấn luyện vượt trội của chúng cũng sẽ cải thiện đồng thời, vì vậy phương pháp của chúng tôi vẫn sẽ có giá trị. Bằng chứng cho giả thuyết này được thấy từ quá trình chuyển đổi từ GPT-J-6B sang T5-XXL, dẫn đến kết quả điều chỉnh prompt tốt hơn cùng với kết quả MSP tốt hơn. Tuy nhiên, chúng tôi không thể biết chắc chắn tại thời điểm này mà không có quyền truy cập vào nhiều tài nguyên tính toán hơn.

Hạn chế chính khác của công việc chúng tôi là thiếu mục tiêu tối ưu hóa rõ ràng trong quá trình sinh dữ liệu. Chúng tôi sử dụng điểm BLEU của ví dụ tổng hợp so với ví dụ gốc ban đầu như một proxy để đo hội tụ mô hình. Tuy nhiên, hóa ra việc đạt được điểm BLEU cao hơn trong quá trình huấn luyện MSP không phải lúc nào cũng dịch sang kết quả downstream vượt trội. Lý tưởng, chúng tôi sẽ có thể tận dụng trực tiếp độ chính xác downstream như một tín hiệu huấn luyện trở lại để tối ưu hóa mô hình MSP, điều mà chúng tôi để lại như công việc tương lai.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo tiếng Anh được giữ nguyên do đây là thông tin nghiên cứu chuẩn]

A Bộ phân loại Độ chính xác Oracle
Để thực hiện đánh giá tự động về độ chính xác, chúng tôi huấn luyện một bộ phân loại thuộc tính oracle dựa trên DeBERTa-XLarge (He et al., 2021). Tuy nhiên, có một vấn đề con gà và quả trứng vì mục tiêu của tác vụ downstream cũng là dự đoán thuộc tính. Để giải quyết vấn đề này, chúng tôi đưa ra ba giả định đơn giản hóa quan trọng. Để bắt đầu, chúng tôi sử dụng tất cả dữ liệu có sẵn để huấn luyện, thay vì giới hạn ở thiết lập ít mẫu. Ví dụ, chúng tôi đi từ 25 SPI đến hơn 1000 SPI trên tập dữ liệu TOPv2. Vì bộ phân loại này có ý định hoạt động như một oracle thay vì một màn trình diễn khả năng mô hình, chúng tôi thậm chí bao gồm các ví dụ từ tập phát triển để huấn luyện. Thứ hai, chúng tôi chỉ tập trung vào thuộc tính chính (ý định) thay vì các chi tiết bậc hai (slot). Cuối cùng, chúng tôi đơn giản hóa tác vụ dự đoán thuộc tính bằng cách phân loại từng thuộc tính riêng lẻ, thay vì theo cách tổ hợp. Trong khi mô hình cuối cùng của chúng tôi phải thực hiện tác vụ bằng cách sinh tuần tự nhãn, chúng tôi tận dụng ontology để biến điều này thành một tác vụ phân loại trên một số lượng hữu hạn nhãn. Bằng cách đó, chúng tôi có được một bộ phân loại độ chính xác có thể đạt được hơn 90% độ chính xác trên tất cả các miền đích (Xem Bảng 13).

B Chi tiết Thiết lập Huấn luyện
Để chọn các ví dụ, trước tiên chúng tôi đại diện cho mỗi ví dụ trong dữ liệu gốc bằng các thuộc tính của nó. Sau đó, đối với từng ví dụ đó, chúng tôi sắp xếp dữ liệu huấn luyện có sẵn theo lượng chồng chéo với đại diện để tìm top 10 gần nhất trong căn chỉnh thuộc tính. Từ những ứng cử viên xếp hạng cao đó, chúng tôi lấy mẫu ngẫu nhiên hai ví dụ để phục vụ như ví dụ trong quá trình sinh dữ liệu. Chúng tôi đã thử nghiệm với 1, 2, hoặc 3 ví dụ và thấy rằng k=2 thường hoạt động tốt nhất, mặc dù 1 ví dụ không kém xa.

Chúng tôi sử dụng tham số 4 cho num generations. Khi huấn luyện mô hình MSP, chúng tôi thử nghiệm tỷ lệ học từ [1.0, 0.3, 0.1, 0.03]. Chúng tôi thấy rằng phạm vi tỷ lệ cao hơn nhiều so với mong đợi. Cho các thử nghiệm cuối cùng, chúng tôi sử dụng lr=0.3. Chúng tôi huấn luyện với kích thước batch hiệu quả là 24, ví dụ với cờ batch-size được đặt thành 8 và tích lũy gradient được đặt thành 3 bước. Tuy nhiên, nếu GPU hết bộ nhớ, chúng tôi có thể giảm xuống 6 và 4, tương ứng. Để tinh chỉnh tác vụ downstream trên mô hình GODEL large, chúng tôi thử nghiệm tỷ lệ học qua [1e-4, 3e-5, 1e-5, 3e-6] trong tối đa 14 epoch với early stopping, và thấy 3e-5 hoạt động tốt nhất.

C Khái quát hóa sang Ngoài miền
Động lực đằng sau công việc này là tận dụng tổng hợp dữ liệu có thể kiểm soát như một phương tiện mở rộng sản phẩm và dịch vụ vào các miền đích nơi dữ liệu có nhãn khan hiếm. Theo định nghĩa, những khu vực mới này là ngoài miền (OOD) cho một mô hình chỉ được huấn luyện trên các miền nguồn. Chiến lược của chúng tôi để khái quát hóa sang không gian OOD là thực hiện tăng cường dữ liệu.

Tăng cường dữ liệu thành công lý tưởng giúp một mô hình khái quát hóa trên một tập thử nghiệm cho một tập huấn luyện hạn chế bằng cách mở rộng dữ liệu gốc để phủ toàn bộ không gian giải pháp. Kết quả là, việc kiểm soát đáng tin cậy quá trình này tương đương với việc tự động hóa thu thập dữ liệu. Theo các nguyên tắc của học tích cực, thu thập dữ liệu lý tưởng liên quan đến việc chọn các ví dụ để gắn nhãn cung cấp phạm vi phủ cao và tác động cao (Settles, 2009). Quay trở lại tăng cường dữ liệu, những mục tiêu này dịch sang thúc đẩy tính đa dạng và bảo toàn nhãn, như đã đề cập trong Phần 1.

Phương pháp của chúng tôi (MSP) có một số đòn bẩy để kéo để tăng tính đa dạng. Một ý tưởng là chỉ đơn giản tăng tham số nhiệt độ của LLM trong quá trình sinh văn bản. Con đường khác là xáo trộn các ví dụ được sử dụng để hướng dẫn hoặc thay đổi cách các ví dụ được truy xuất. Xây dựng dựa trên điều này, người ta thậm chí có thể loại trừ ví dụ gốc khỏi các ví dụ để giảm thiểu hành vi sao chép phổ biến với LLM. Một hướng đặc biệt thú vị để theo đuổi là tổ hợp các kết hợp thuộc tính mới không thấy trong tập gốc. Ví dụ, một phát biểu có thể có ý định 'greet' và 'change' trong miền hàng không (ví dụ Hello, I would like to change my flight), trong khi phát biểu thứ hai chứa ý định 'request_info' và 'when' cho thương mại điện tử (ví dụ Can you tell me when the store opens?). Những điều này có thể được remix để sinh ra một phát biểu hoàn toàn mới với ý định 'request_info' và 'change' trong miền nhà hàng (ví dụ I'd like to know how I can change my reservation). Chúng tôi thực sự đã thử nghiệm tất cả những ý tưởng này trong quá trình thử nghiệm sơ bộ. Hóa ra, chúng không giúp ích.

Trên thực tế, chúng tôi thấy rằng bảo toàn nhãn nhanh chóng vượt qua tính đa dạng về mặt là yếu tố quan trọng nhất để ảnh hưởng đến tác động downstream. Do đó, chúng tôi thực sự phải nỗ lực tỉ mỉ để giảm tính đa dạng. Chúng tôi giảm các tham số nhiệt độ. Chúng tôi chọn các ví dụ rất tương tự để hướng dẫn. Chúng tôi chỉ sử dụng các kết hợp thuộc tính được tìm thấy trong dữ liệu gốc. Và chúng tôi thậm chí thêm một bước khử nhiễu để giảm thiểu biến đổi (Phần 3.4). Mặc dù hạn chế tính đa dạng hoạt động trong trường hợp của chúng tôi, chúng tôi tin rằng điều này phần lớn do bản chất tĩnh của các tập thử nghiệm của chúng tôi, trong khi phân phối của môi trường thử nghiệm thực tế thể hiện một đuôi dài mở rộng liên tục. Trong cả hai trường hợp, tính linh hoạt của MSP cho phép người thực hành chọn những gì họ muốn, dù đó là độ chính xác trong một khu vực cụ thể hay sự mạnh mẽ để phủ OOD.

D Trộn các Phương pháp Điều chỉnh Hiệu quả Tham số Khác
Ý tưởng cốt lõi của chúng tôi về trộn trọng số adapter đủ linh hoạt để phù hợp với các phương pháp điều chỉnh hiệu quả tham số khác như LoRA (Hu et al., 2022). Đóng góp chính của chúng tôi là việc trộn nên được học thay vì dựa vào kỹ thuật prompt. Đến điểm này, chúng tôi chạy các thử nghiệm bổ sung trên NLU++ hotel, CrossNER music và TOPv2 weather bằng cách trộn trọng số LoRA nơi mỗi ma trận adapter đại diện cho một thuộc tính duy nhất. Cụ thể, chúng tôi sử dụng phương pháp bottleneck và thay thế lớp tuyến tính chiếu attention với lớp tuyến tính LoRA tương ứng. Kết quả lần lượt là 86.4, 76.7 và 80.1, vượt trội hơn các baseline không trộn khác nhưng kém hiệu suất hơn MSP. Chúng tôi không có nhiều thời gian để điều chỉnh kết quả, nhưng lưu ý rằng thử nghiệm này cho thấy cách học để trộn đã vượt trội hơn hầu hết các baseline khác.

[Bảng 8-13 được giữ nguyên cấu trúc tiếng Anh do chứa dữ liệu số liệu và tên các phương pháp kỹ thuật]

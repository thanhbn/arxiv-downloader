# 2212.09597.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/prompt/2212.09597.pdf
# Kích thước tập tin: 1976024 bytes

===============================================
NỘI DUNG TẬP TIN PDF
===============================================

--- TRANG 1 ---
Lý luận với Gợi ý Mô hình Ngôn ngữ: Một Khảo sát
Shuofei Qiao1∗, Yixin Ou1∗, Ningyu Zhang1†, Xiang Chen1, Yunzhi Yao1,
Shumin Deng4, Chuanqi Tan3, Fei Huang3, Huajun Chen1,2†
1Đại học Chiết Giang & Phòng thí nghiệm chung AZFT cho Công cụ Tri thức
2Phòng thí nghiệm Đông Hải3Tập đoàn Alibaba4Đại học Quốc gia Singapore
{shuofei,ouyixin,zhangningyu,xiang_chen,yyztodd,huajunsir}@zju.edu.cn
shumin@nus.edu.sg {chuanqi.tcq,f.huang}@alibaba-inc.com

Tóm tắt
Lý luận, như một khả năng thiết yếu cho việc giải quyết vấn đề phức tạp, có thể cung cấp hỗ trợ back-end cho các ứng dụng thực tế khác nhau, chẳng hạn như chẩn đoán y tế, thương lượng, v.v. Bài báo này cung cấp một khảo sát toàn diện về nghiên cứu tiên tiến về lý luận với gợi ý mô hình ngôn ngữ. Chúng tôi giới thiệu các công trình nghiên cứu với so sánh và tóm tắt, đồng thời cung cấp tài nguyên có hệ thống để giúp người mới bắt đầu. Chúng tôi cũng thảo luận về các lý do tiềm năng cho việc xuất hiện khả năng lý luận như vậy và làm nổi bật các hướng nghiên cứu tương lai1.

1 Giới thiệu
Khả năng lý luận nằm ở trung tâm của trí thông minh con người, tuy nhiên trong xử lý ngôn ngữ tự nhiên (NLP), các mạng nơ-ron hiện đại khó có thể lý luận từ những gì chúng được nói hoặc đã biết (Duan et al., 2020; Wang et al., 2021; Bhargava and Ng, 2022). May mắn thay, với sự phát triển cách mạng của tiền huấn luyện (Brown et al., 2020; Chen et al., 2021; Chowdhery et al., 2022), việc mở rộng quy mô của các mô hình ngôn ngữ (LMs) đã được chứng minh là mang lại một loạt khả năng lý luận, chẳng hạn như số học (Wang et al., 2022e; Lewkowycz et al., 2022), thường thức (Jung et al., 2022; Liu et al., 2022b), lý luận tượng trưng (Zhou et al., 2023; Khot et al., 2023). Như được thể hiện trong Hình 1, những khả năng như vậy có thể được mở khóa bởi các chiến lược gợi ý (Liu et al., 2022d) (ví dụ: gợi ý chuỗi suy nghĩ (CoT) (Wei et al., 2022b), gợi ý tri thức được tạo ra (Liu et al., 2022c)), có thể thu hẹp đáng kể khoảng cách giữa trí thông minh con người và máy móc. Tương tự như vậy, một lượng lớn công việc đã được đề xuất trong cộng đồng NLP; tuy nhiên, những cách tiếp cận này, rải rác giữa các nhiệm vụ khác nhau, chưa được xem xét và phân tích một cách có hệ thống.

∗Đóng góp ngang nhau.
†Tác giả Liên hệ.
1Tài nguyên có sẵn tại https://github.com/zjunlp/Prompt4ReasoningPapers (được cập nhật định kỳ).

GPT-3
Codex
ChatGPT
gợi ý
gợi ý
Hãy suy nghĩ 
từng bước!
?

Hình 1: Lý luận với gợi ý mô hình ngôn ngữ. Các mẫu trong ngữ cảnh (có màu , ), tri thức (có màu , ) hoặc chỉ "Hãy suy nghĩ từng bước!" được dùng làm gợi ý để tăng cường lý luận của mô hình ngôn ngữ.

Tổ chức của Khảo sát này: Trong bài báo này, chúng tôi tiến hành khảo sát đầu tiên về tiến bộ gần đây trong lý luận với gợi ý mô hình ngôn ngữ. Trước tiên chúng tôi đưa ra một số kiến thức cơ bản về hướng này (§2) và sau đó đề xuất tổ chức các công trình liên quan theo phân loại (§3). Chúng tôi tiếp tục cung cấp so sánh chuyên sâu với thảo luận để có cái nhìn sâu sắc (§4). Để hỗ trợ người mới bắt đầu quan tâm đến lĩnh vực này, chúng tôi làm nổi bật một số tài nguyên mở (§5) cũng như các hướng tương lai tiềm năng (§6).

2 Kiến thức cơ bản
Trong phần này, chúng tôi giới thiệu kiến thức cơ bản về lý luận với gợi ý LM. Đối với gợi ý tiêu chuẩn, cho câu hỏi lý luận Q, gợi ý T và mô hình xác suất có tham số pLM, chúng ta nhằm tối đa hóa khả năng của câu trả lời A như:

p(A | T ,Q) =|A|Y
i=1pLM(ai| T,Q, a<i)(1)

trong đó ai và |A| biểu thị token thứ i và độ dài của câu trả lời cuối cùng tương ứng. Đối với gợi ý few-shot, T bao gồm K mẫu của cặp (Q,A). Các phương pháp CoT thêm các bước lý luận C vào gợi ý trong đó T={(Qi,Ci,Ai)}K
i=1,

arXiv:2212.09597v8 [cs.CL] 18 Sep 2023

--- TRANG 2 ---
Lý luận với Gợi ý Mô hình Ngôn ngữ - Phân loại các Phương pháp (§3)

Lý luận Tăng cường Chiến lược (§3.1)
Kỹ thuật Gợi ý (§3.1.1)
Đơn giai đoạn: Contrastive (Paranjape et al., 2021), POTTER (Rajagopal et al., 2021), CoT (Wei et al., 2022b), ZeroCoT (Kojima et al., 2022), Complexity (Fu et al., 2023b), Multilingual (Shi et al., 2022), Auto-CoT (Zhang et al., 2023b), Table (Chen, 2022), AlgoPrompt (Zhou et al., 2022a), Active-Prompt (Diao et al., 2023), Automate-CoT (Shum et al., 2023)

Đa giai đoạn: iCAP (Wang et al., 2022a), SI (Creswell et al., 2022), Least-to-Most (Zhou et al., 2023), MAIEUTIC (Jung et al., 2022), Faithful (Creswell and Shanahan, 2022), Decomposed (Khot et al., 2023), Self-Ask (Press et al., 2022), Successive (Dua et al., 2022), LMLP (Zhang et al., 2022), LAMBADA (Kazemi et al., 2022), Iter-Decomp (Reppert et al., 2023)

Tối ưu hóa Quy trình (§3.1.2)
Tự tối ưu hóa: Calibrator (Ye and Durrett, 2022), Human-AI (Wiegreffe et al., 2022)
Tối ưu hóa Tập hợp: Self-C (Wang et al., 2022e), DIVERSE (Li et al., 2022d), Complexity (Fu et al., 2023b), Self-V (Weng et al., 2022), MCR (Yoran et al., 2023)
Tối ưu hóa Lặp lại: STaR (Zelikman et al., 2022), LMSI (Huang et al., 2022), Reflexion (Shinn et al., 2023), Self-Refine (Madaan et al., 2023), REFINER (Paul et al., 2023)

Công cụ Bên ngoài (§3.1.3)
Mô phỏng Vật lý: Mind's Eye (Liu et al., 2023)
Trình thông dịch Mã: COCOGEN (Madaan et al., 2022), PAL (Gao et al., 2022), PoT (Chen et al., 2022b), Faithful-CoT (Lyu et al., 2023), Versa-Decomp (Ye et al., 2023), SynPrompt (Shao et al., 2023), MathPrompter (Imani et al., 2023)
Học công cụ: Toolformer (Schick et al., 2023), ART (Paranjape et al., 2023), Chameleon (Lu et al., 2023a)

Lý luận Tăng cường Tri thức (§3.2)
Tri thức Ẩn (§3.2.1): GenKnow (Liu et al., 2022c), RAINIER (Liu et al., 2022b), MT-CoT (Li et al., 2022b), PINTO (Wang et al., 2023), TSGP (Sun et al., 2022), DecompDistill (Shridhar et al., 2022), Teaching (Magister et al., 2022), Fine-tune-CoT (Ho et al., 2022), Specializing (Fu et al., 2023a)

Tri thức Tường minh (§3.2.2): LogicSolver (Yang et al., 2022b), Vote-k(SU et al., 2023), PROMPTPG (Lu et al., 2023b), IRCoT (Trivedi et al., 2022), RR (He et al., 2023)

Phân loại các Nhiệm vụ (§5)
Số học: CoT (Wei et al., 2022b), Self-C (Wang et al., 2022e), Least-to-Most (Zhou et al., 2023), ZeroCoT (Kojima et al., 2022), Auto-CoT (Zhang et al., 2023b), LMSI (Huang et al., 2022), PAL (Gao et al., 2022), PoT (Chen et al., 2022b), Fine-tune-CoT (Ho et al., 2022)

Thường thức: CoT (Wei et al., 2022b), GenKnow (Liu et al., 2022c), Self-C (Wang et al., 2022e), Calibrator (Ye and Durrett, 2022), ZeroCoT (Kojima et al., 2022), Auto-CoT (Zhang et al., 2023b), COCOGEN (Madaan et al., 2022), LMSI (Huang et al., 2022), PINTO (Wang et al., 2023), RR (He et al., 2023)

Logic: Faithful (Creswell and Shanahan, 2022), LMLP (Zhang et al., 2022), Self-V (Weng et al., 2022), LAMBADA (Kazemi et al., 2022)

Tượng trưng: CoT (Wei et al., 2022b), Self-C (Wang et al., 2022e), Least-to-Most (Zhou et al., 2023), ZeroCoT (Kojima et al., 2022), PAL (Gao et al., 2022)

Đa phương thức: MarT (Zhang et al., 2023a), Multimodal-CoT (Zhang et al., 2023c), KOSMOS-1 (Huang et al., 2023), Visual-ChatGPT (Wu et al., 2023)

Hình 2: Phân loại Lý luận với Gợi ý Mô hình Ngôn ngữ. (Chúng tôi chỉ liệt kê các cách tiếp cận đại diện cho mỗi loại nhiệm vụ và để có phiên bản đầy đủ hơn, vui lòng tham khảo Phụ lục A.2).

do đó Phương trình 1 có thể được cải cách thành:

p(A | T ,Q) =X
Cp(A | T ,Q,C)p(C | T,Q)
(2)

trong đó p(C | T,Q) và p(A | T ,Q,C) được định nghĩa như sau:

p(C | T,Q) =|C|Y
i=1pLM(ci| T,Q, c<i)
p(A | T ,Q,C) =|A|Y
j=1pLM(aj| T,Q,C, a<j)

với ci là một bước trong tổng số |C| bước lý luận.

Để tăng cường khả năng lý luận của gợi ý LM, có hai nhánh nghiên cứu chính. Nhánh đầu tiên tập trung vào tối ưu hóa chiến lược lý luận với gợi ý như được thể hiện trong Hình 2, bao gồm kỹ thuật gợi ý (§3.1.1), tối ưu hóa quy trình (§3.1.2) và công cụ bên ngoài (§3.1.3).

Đối với kỹ thuật gợi ý (§3.1.1), nhiều phương pháp cố gắng cải thiện chất lượng gợi ý T, và chúng tôi gọi những công việc đó là phương pháp đơn giai đoạn, trong khi những phương pháp khác nối thêm ci vào ngữ cảnh của (T,Q) tại mỗi giai đoạn lý luận hoặc thiết kế Tci cụ thể cho mỗi ci, và chúng tôi coi những phương pháp đó là phương pháp đa giai đoạn. Lưu ý rằng một giai đoạn ở đây đề cập đến một quy trình đầu vào-đầu ra. Đối với tối ưu hóa quy trình (§3.1.2), cách đơn giản nhất là đưa vào một bộ tối ưu với tham số θ để hiệu chỉnh C khi tạo ra A, và chúng tôi gọi những công việc đó là phương pháp tự tối ưu hóa. Một số phương pháp khác cố gắng có được nhiều quy trình để tập hợp câu trả lời cuối cùng. Chúng tôi coi những công việc đó là phương pháp tối ưu hóa tập hợp. Hơn nữa, quy trình tối ưu hóa tổng thể có thể được tích hợp lặp lại với việc tinh chỉnh pLM trên bộ ba được tạo ra (Q,C,A), được coi là phương pháp tối ưu hóa lặp lại. Bên cạnh đó, một số công việc tận dụng các công cụ lý luận bên ngoài (§3.1.3) để tạo ra T, để thực thi trực tiếp C hoặc bằng cách cấy ghép các lời gọi API công cụ trong C để lý luận.

Nhánh nghiên cứu thứ hai tập trung vào tăng cường tri thức với gợi ý. Lưu ý rằng "tri thức mô hình" ẩn phong phú (Han et al., 2021) trong LMs có thể tạo ra tri thức hoặc lý do như gợi ý có thông tin tri thức T (§3.2.1). Trong khi đó, tri thức tường minh trong tài nguyên bên ngoài cũng có thể được tận dụng và truy xuất như gợi ý có tri thức để tăng cường lý luận (§3.2.2).

--- TRANG 3 ---
Q: Roger có 5 quả bóng tennis. Anh ấy mua thêm 2 lon 
bóng tennis nữa. Mỗi lon có 3 quả bóng tennis. Anh ấy đã có 
5 quả bóng tennis rồi. Anh ấy mua 2 × 3 = 6 quả bóng tennis.
Roger có bao nhiêu quả bóng tennis bây giờ?

Q: Có 3 chiếc xe trong bãi đậu xe và 2 
chiếc xe nữa đến. Có bao nhiêu chiếc xe trong 
bãi đậu xe?
C: Đã có 3 chiếc xe trong bãi đậu xe rồi. 2 
chiếc nữa đến. Bây giờ có 3 + 2 = 5 chiếc xe.
A: Câu trả lời là 5.

Q: Có 3 chiếc xe trong bãi đậu xe và 2 
chiếc xe nữa đến. Có bao nhiêu chiếc xe đã có 
trong bãi đậu xe?
C: Đã có 3 chiếc xe trong bãi đậu xe rồi.
Có bao nhiêu chiếc xe đến?

Q: Có 3 chiếc xe trong bãi đậu xe và 2 chiếc xe 
nữa đến. Đã có 3 chiếc xe trong bãi đậu xe rồi. 
2 chiếc xe đến. Có bao nhiêu chiếc xe trong bãi đậu xe?
C: Có 3 + 2 = 5 chiếc xe trong bãi đậu xe.
A: Câu trả lời là 5.

Q: Roger có 5 quả bóng tennis. Anh ấy mua 2 lon 
bóng tennis nữa. Mỗi lon có 3 quả bóng tennis. 
Anh ấy đã có bao nhiêu quả bóng tennis?

Q: Roger có 5 quả bóng tennis. Anh ấy mua 2 lon 
bóng tennis nữa. Mỗi lon có 3 quả bóng tennis. 
Roger có bao nhiêu quả bóng tennis bây giờ?

Q: Roger có 5 quả bóng tennis. Anh ấy mua 2 lon 
bóng tennis nữa. Mỗi lon có 3 quả bóng tennis. 
Roger có bao nhiêu quả bóng tennis bây giờ?
C: Roger bắt đầu với 5 quả bóng. 2 lon, mỗi lon có 3 
quả bóng tennis tức là 6 quả bóng tennis. 5 + 6 = 11.
A: Câu trả lời là 11.

Mô hình Ngôn ngữ
C: Chúng ta nên biết trước "Anh ấy đã có bao nhiêu 
quả bóng tennis?"

Đơn giai đoạn                    Giai đoạn-1

...Q: Có 3 chiếc xe trong bãi đậu xe và 2 
chiếc xe nữa đến. Có bao nhiêu chiếc xe trong 
bãi đậu xe?
C: Chúng ta nên biết trước "Có bao nhiêu chiếc xe 
đã có trong bãi đậu xe?"

C: Anh ấy đã có 5 quả bóng tennis. Anh ấy mua 
bao nhiêu quả bóng tennis?

Giai đoạn-2
C: Anh ấy có 5 + 6 = 11 quả bóng tennis bây giờ.
A: Câu trả lời là 11.

Mô hình Ngôn ngữ   Mô hình Ngôn ngữ   Mô hình Ngôn ngữ   Giai đoạn-n

Hình 3: Đơn giai đoạn (trái) và Đa giai đoạn (phải) trong Kỹ thuật Gợi ý (§3.1.1) của Lý luận Tăng cường Chiến lược. Trong mỗi giai đoạn, một câu hỏi (Q, bên dưới đường đứt nét) được gợi ý với một số mẫu (bên trên đường đứt nét) chứa các bước lý luận (C) sẽ được đưa vào LM. Đầu ra là các bước lý luận và câu trả lời (A).

3 Phân loại các Phương pháp
Trong bài báo này, chúng tôi khảo sát các phương pháp lý luận hiện có với gợi ý LM, phân loại chúng thành Lý luận Tăng cường Chiến lược (§3.1) và Lý luận Tăng cường Tri thức (§3.2). Như được thể hiện trong Hình 2, chúng tôi tiếp tục tinh chỉnh chúng theo các đặc điểm đặc biệt của các phương pháp khác nhau.

3.1 Lý luận Tăng cường Chiến lược
Mục đích chính của dòng công việc này là thiết kế một chiến lược lý luận tốt hơn, được thể hiện cụ thể trong kỹ thuật gợi ý (§3.1.1), tối ưu hóa quy trình (§3.1.2) và công cụ bên ngoài (§3.1.3).

3.1.1 Kỹ thuật Gợi ý
Một cách tiếp cận trực quan để cải thiện lý luận với gợi ý là kỹ thuật gợi ý. Như được thể hiện trong Hình 3, chúng tôi chia loại phương pháp này thành gợi ý đơn giai đoạn và đa giai đoạn dựa trên số lượng giai đoạn gợi ý.

Đơn giai đoạn. Các công trình đầu tận dụng gợi ý dựa trên mẫu (Paranjape et al., 2021; Rajagopal et al., 2021) cho lý luận trong NLP. Về khả năng học trong ngữ cảnh mạnh mẽ của LMs lớn (Brown et al., 2020), Wei et al. (2022b) đề xuất gợi ý CoT, thêm một loạt các bước lý luận trung gian vào các mẫu của gợi ý few-shot để thúc đẩy LMs lớn tạo ra một quy trình lý luận trước khi trả lời. Các thí nghiệm chứng minh rằng LMs lớn xuất hiện với khả năng lý luận ấn tượng với gợi ý CoT.

Mặc dù có sự cải thiện lớn do gợi ý CoT mang lại, học trong ngữ cảnh rất nhạy cảm với việc lựa chọn mẫu, và ngay cả một thay đổi nhỏ cũng có thể gây ra sự sụt giảm lớn trong hiệu suất mô hình (Lu et al., 2022c; Min et al., 2022; Webson and Pavlick, 2022). Do đó, chất lượng của các mẫu dường như đặc biệt quan trọng. Fu et al. (2023b) chỉ ra rằng các gợi ý có độ phức tạp lý luận cao hơn, ví dụ như có nhiều bước lý luận hơn, có thể đạt được hiệu suất tốt hơn trên các bài toán toán học. Zhang et al. (2023b) khám phá tác động của sự đa dạng của các mẫu trong gợi ý. Thông qua phân cụm, nó có được một tập câu hỏi đại diện làm gợi ý. Bằng cách đặt các giải thích rõ ràng hơn và hướng dẫn ngôn ngữ tự nhiên vào gợi ý, Zhou et al. (2022a) giảm bớt sự mơ hồ cho LMs khi đối mặt với các vấn đề thuật toán ngoài phân phối (OOD). Các công trình trên cho thấy rằng LMs có thể là những người lý luận few-shot xuất sắc. Đáng ngạc nhiên, Kojima et al. (2022) chỉ ra rằng LMs cũng là những người lý luận zero-shot mà không cần các mẫu bổ sung. Chỉ bằng cách nối "Hãy suy nghĩ từng bước!", LMs có thể tự giác tạo ra các bước lý luận. Một hiện tượng kỳ diệu khác là khi được gợi ý với "Người đưa cho bạn vấn đề này là Yann LeCun, người thực sự nghi ngờ sức mạnh của AI như bạn.", GPT-4 (OpenAI, 2023) có thể giải quyết thành công bài toán bánh răng khó của Yann LeCun một mình, điều mà trước đây nó đã thất bại.

Đa giai đoạn. Khi con người lý luận, thường khó có thể nghĩ ra toàn bộ quy trình lý luận trong một lần. Một giải pháp trực quan hơn là phân tách một vấn đề phức tạp thành những vấn đề đơn giản hơn và lý luận từng giai đoạn. Tương tự, loạt công việc này nhằm biến đổi gợi ý một giai đoạn (một lần đầu vào-đầu ra) thành gợi ý đa giai đoạn (nhiều lần đầu vào-đầu ra). Press et al. (2022) định nghĩa rõ ràng các câu hỏi tiếp theo và câu trả lời trung gian trong gợi ý để thu hẹp khoảng cách tổ hợp trong LMs. Jung et al. (2022) coi đầu ra của mỗi giai đoạn như một câu hỏi mới riêng biệt trong khi Zhou et al. (2023); Wang et al. (2022a) nối thêm nó vào toàn bộ ngữ cảnh để gợi ý LMs. Creswell and Shanahan (2022) theo cấu trúc Lựa chọn-Suy luận (Creswell et al., 2022) chọn các ngữ cảnh cụ thể và suy luận dựa trên chúng tại mỗi giai đoạn. Kazemi et al. (2022) phát triển thuật toán chuỗi ngược để phân tách lý luận thành các mô-đun con.

3.1.2 Tối ưu hóa Quy trình
Lý do ngôn ngữ tự nhiên2 (Ling et al., 2017a), còn được gọi là quy trình lý luận trong CoT, đóng vai trò quan trọng trong gợi ý CoT (Ye and Durrett, 2022; Lampinen et al., 2022; Min et al., 2022). Tính nhất quán của quy trình lý luận (Wang et al., 2022e) và tính liên tục giữa các bước lý luận (Li et al., 2022d) đều ảnh hưởng đến độ chính xác của câu trả lời cuối cùng. Một cách trực quan, như được thể hiện trong Hình 4, chúng tôi giới thiệu dòng phương pháp này theo ba loại, tức là tối ưu hóa tự, tập hợp và lặp lại.

Tự tối ưu hóa. Tự tối ưu hóa ở đây đề cập đến việc sửa chữa một quy trình bằng cách tiêm các mô-đun bổ sung. Để giảm thiểu ảnh hưởng của sự không đáng tin cậy của lý do, Ye and Durrett (2022) sử dụng một bộ hiệu chỉnh để điều chỉnh xác suất của một dự đoán dựa trên điểm số phản ánh tính thực tế của lý do. Trong quá trình tạo lý do văn bản tự do, Wiegreffe et al. (2022) tinh chỉnh một mô hình sequence-to-sequence làm bộ lọc để dự đoán liệu lý do có chấp nhận được hay không.

Tối ưu hóa Tập hợp. Do hạn chế chỉ có một đường lý luận, các công việc sau đây dựa vào hiệu chỉnh tập hợp giữa nhiều quy trình. Wang et al. (2022e) giới thiệu các chiến lược lấy mẫu (Ackley et al., 1985; Fan et al., 2018) thường được sử dụng trong tạo ngôn ngữ tự nhiên để có được nhiều quy trình lý luận và tạo ra câu trả lời nhất quán nhất bằng bỏ phiếu đa số. Dựa trên động lực khi một quy trình lý luận đạt đến câu trả lời sai, không phải tất cả các bước đều có thể đảm nhận sự không chính xác cuối cùng, Li et al. (2022d) đề xuất một trình xác minh bỏ phiếu nhận biết bước để ghi điểm cho mỗi đường lý luận. Khi các quy trình đa số bị định hướng sai lấn át các quy trình thiểu số hợp lý, trình xác minh bỏ phiếu nhận biết bước có thể giảm bớt hạn chế của bỏ phiếu đa số vanilla (Wang et al., 2022e). Bên cạnh đó, Wang et al. (2022d) quan sát thực nghiệm rằng lấy mẫu bộ giải mã trong không gian đầu ra là chìa khóa để cải thiện hiệu suất một cách mạnh mẽ vì tính dễ vỡ của kỹ thuật gợi ý thủ công.

Tối ưu hóa Lặp lại. Lưu ý rằng LMs có thể đạt được hiệu suất xuất sắc theo cách few-shot (Wei et al., 2022b) hoặc zero-shot (Kojima et al., 2022) với gợi ý, một mô hình khác là hiệu chỉnh các quy trình lý luận lặp lại với tinh chỉnh LM. Cụ thể, các phương pháp dựa trên tối ưu hóa lặp lại cố gắng lặp lại quy trình gợi ý LMs để tạo ra các quy trình lý luận và sử dụng các instance với các quy trình lý luận được tạo ra để tự tinh chỉnh. Zelikman et al. (2022) bắt đầu với một tập mẫu nhỏ để thúc đẩy LMs tự tạo ra các bước lý luận và câu trả lời. Các câu hỏi và bước lý luận với câu trả lời đúng sẽ được thêm trực tiếp vào tập dữ liệu để tinh chỉnh. Những câu sai sẽ được đưa vào mô hình lại bằng cách được gắn thẻ với gợi ý ghi nhãn câu trả lời đúng. So với Zelikman et al. (2022), Huang et al. (2022) không cần nhãn vàng trong quá trình tự dạy. Theo Wang et al. (2022e), nó tạo ra nhiều quy trình lý luận và tinh chỉnh các câu trả lời tự tạo nhất quán nhất. Shinn et al. (2023); Madaan et al. (2023); Paul et al. (2023) khám phá khả năng nổi lên của LLMs để tự phản ánh, bằng cách liên tục sửa chữa chuỗi lý luận thông qua tự phản ánh lặp lại.

3.1.3 Công cụ Bên ngoài
Khi lý luận với gợi ý LM, các mô hình nên có khả năng hiểu ngữ nghĩa (ví dụ: câu hỏi) và lý luận phức tạp (ví dụ: bằng cách tạo ra quy trình lý luận); tuy nhiên, chúng ta không thể có cả cá và gấu (Hendrycks et al., 2021; Nogueira et al., 2021; Lewkowycz et al., 2022). Để phá vỡ rào cản, các công cụ lý luận bên ngoài đưa tay giúp đỡ LMs (xem Hình 5).

Mô phỏng Vật lý. Cho một câu hỏi lý luận vật lý, Liu et al. (2023) sử dụng một công cụ vật lý tính toán (Todorov et al., 2012) để mô phỏng quy trình vật lý. Kết quả mô phỏng được coi như gợi ý để giúp LMs lý luận, bù đắp cho việc thiếu tri thức vật lý trong LMs.

Trình thông dịch Mã. Với sự xuất hiện của LMs của mã (Chen et al., 2021; Xu et al., 2022), việc hợp tác LMs và mã để giải quyết các nhiệm vụ cụ thể gần đây đã xuất hiện (Wang et al., 2022c; Cheng et al., 2022; Wu et al., 2022b). Lưu ý rằng các chương trình mang lại các hành vi có lợi về độ mạnh mẽ và khả năng diễn giải và có thể minh họa tốt hơn các cấu trúc phức tạp và suy ra các tính toán phức tạp. Một cách trực quan, Madaan et al. (2022) định khung lại các nhiệm vụ lý luận thường thức có cấu trúc như các nhiệm vụ tạo mã, thay thế ngôn ngữ tự nhiên bằng mã lớp python để biểu diễn đồ thị có cấu trúc cả trong gợi ý few-shot và đầu ra LM. Gao et al. (2022) phân tách các bước giải pháp từ LMs thành một runtime có thể lập trình và duy trì nhiệm vụ học duy nhất cho LMs. Trong gợi ý few-shot và đầu ra LM, các quy trình lý luận được thay thế bằng hỗn hợp ngôn ngữ tự nhiên và lập trình, trong đó ngôn ngữ tự nhiên được coi như chú thích để hỗ trợ việc tạo chương trình. Tương tự như Gao et al. (2022), Chen et al. (2022b) đề xuất gợi ý chương trình suy nghĩ (PoT) tách rời tính toán khỏi lý luận. Điểm khác biệt chính là nó cũng đưa ra định dạng zero-shot của gợi ý PoT.

Học công cụ. Mặc dù sở hữu khả năng tạo ra và ra quyết định đáng chú ý, LLMs gặp khó khăn với một số chức năng cơ bản mà các công cụ đơn giản và nhỏ hơn nhiều lại xuất sắc (Qin et al., 2023). Dựa trên cái nhìn sâu sắc này, Schick et al. (2023) huấn luyện các mô hình bằng cách tích hợp việc sử dụng các công cụ khác nhau, bao gồm máy tính, hệ thống Q&A, công cụ tìm kiếm, v.v. Thông qua việc cấy ghép các lời gọi API công cụ vào quy trình tạo văn bản, khả năng của mô hình được mở rộng đáng kể. Paranjape et al. (2023) thiết kế việc sử dụng công cụ cho LLMs như một lược đồ tự động, loại bỏ nhu cầu tạo ra các bản trình diễn cụ thể cho nhiệm vụ thủ công và việc xen kẽ được viết kịch bản cẩn thận của các thế hệ mô hình với việc sử dụng công cụ. Lu et al. (2023a) khai thác khả năng ra quyết định mạnh mẽ của LLMs, cho phép chúng kết hợp các công cụ bên ngoài khác nhau để giải quyết các nhiệm vụ lý luận tổng hợp.

3.2 Lý luận Tăng cường Tri thức
Như được ghi nhận trong Manning (2022), tri thức đóng vai trò quan trọng trong các hệ thống lý luận AI. Các phương pháp tăng cường tri thức nhằm gợi ý LMs với tri thức ẩn (§3.2.1) hoặc tường minh (§3.2.2) để hỗ trợ lý luận (xem Hình 6).

3.2.1 Tri thức Ẩn
Các nhà nghiên cứu đã chỉ ra rằng LMs chứa đựng tri thức ẩn đáng kể (Davison et al., 2019; Petroni et al., 2019; Jiang et al., 2020). Các công việc sau đây cố gắng thúc đẩy "tri thức mô hình" như vậy như gợi ý có thông tin tri thức cho lý luận.

Liu et al. (2022c) áp dụng GPT-3 (Brown et al., 2020) với gợi ý few-shot để tạo tri thức và gợi ý LM downstream. Liu et al. (2022b) rút hỗ trợ từ học tăng cường (Schulman et al., 2017) để hiệu chỉnh thêm tri thức. Khác với các cách tiếp cận sử dụng gợi ý few-shot trong giai đoạn tạo tri thức, Sun et al. (2022) đề xuất gợi ý tạo ra hai giai đoạn bao gồm thêm gợi ý tạo câu trả lời. Các công việc khác (Li et al., 2022b; Wang et al., 2023; Shridhar et al., 2022; Magister et al., 2022; Ho et al., 2022) theo chưng cất tri thức tạo ra các mẫu lý luận bằng cách gợi ý LM lớn hơn và dạy LMs nhỏ hơn.

3.2.2 Tri thức Tường minh
Mặc dù LMs lớn đã thể hiện khả năng tạo ra mạnh mẽ (Wiegreffe et al., 2022; Li et al., 2022b; Wang et al., 2023), chúng vẫn có xu hướng ảo tưởng sự thật (Rohrbach et al., 2018) và tạo ra tri thức không nhất quán (Liu et al., 2022b). Các công trình gần đây cho thấy rằng việc truy xuất gợi ý cho học trong ngữ cảnh là một phương tiện tốt để đạt được hiệu suất tốt (Liu et al., 2022a; Rubin et al., 2022).

Do tính không ổn định của các cách tiếp cận truy xuất thông thường để đo lường độ tương tự của thông tin có cấu trúc, Lu et al. (2023b) đề xuất một phương pháp truy xuất gợi ý động dựa trên chiến lược gradient chính sách, không cần tìm kiếm vũ phu. He et al. (2023) truy xuất tri thức liên quan dựa trên các bước lý luận của CoT để cung cấp các giải thích trung thực hơn. Trivedi et al. (2022) tăng cường gợi ý CoT bằng cách liên tục truy xuất tài liệu wiki cho các nhiệm vụ tri thức chuyên sâu miền mở đòi hỏi lý luận đa bước phức tạp.

--- TRANG 4 ---
Q: Có 3 chiếc xe trong bãi đậu xe và 2 
chiếc xe nữa đến. Có bao nhiêu chiếc xe trong 
bãi đậu xe?
C: Đã có 3 chiếc xe trong bãi đậu xe rồi.
2 chiếc nữa đến. Bây giờ có 3 + 2 = 5 chiếc xe.
A: Câu trả lời là 5.

LM

Roger bắt đầu với 5 
quả bóng. 2 lon, mỗi lon có 3 
quả bóng tennis tức là 6 
quả bóng tennis. 5 + 6 = 11.

Câu trả lời 
là 11.

Câu trả lời 
là 11.

Câu trả lời 
là 7.

Bộ tối ưu

Câu trả lời 
là 11.

Tự tối ưu hóa

Tối ưu hóa 
Tập hợp

Tối ưu hóa Lặp lại

tinh chỉnh

Q: Roger có 5 quả bóng tennis. Anh ấy mua 2 
lon bóng tennis nữa. Mỗi lon có 3 quả bóng tennis. 
Roger có bao nhiêu quả bóng tennis bây giờ?

Roger có 5 quả bóng đã có. 
Anh ấy mua 2 × 3 = 6 quả nữa. Vậy 
anh ấy có 5 + 6 = 11 quả bóng bây giờ.

Roger có 5 quả bóng tennis. 
Anh ấy mua 2 lon nữa. Vậy 
anh ấy có 5 + 2 = 7 bây giờ.

Hình 4: Tối ưu hóa Quy trình (§3.1.2) của Lý luận Tăng cường Chiến lược. Tự tối ưu hóa (có màu ) áp dụng một mô-đun tối ưu để hiệu chỉnh một quy trình lý luận đơn lẻ. Tối ưu hóa Tập hợp (có màu ) tập hợp nhiều quy trình lý luận để hiệu chỉnh câu trả lời. Tối ưu hóa Lặp lại (có màu ) hiệu chỉnh các quy trình lý luận bằng cách tinh chỉnh LM lặp lại.

Q: Roger có 5 quả bóng tennis. Anh ấy mua 
2 lon bóng tennis nữa. Mỗi lon có 3 quả bóng tennis. 
Roger có bao nhiêu quả bóng tennis bây giờ?

Gợi ý

LM

11

Công cụ   Mô phỏng

Hình 5: Công cụ Bên ngoài (§3.1.3) của Lý luận Tăng cường Chiến lược. Các công cụ bên ngoài đóng vai trò như nhà sản xuất gợi ý (Mô phỏng Vật lý), trình thực thi lý luận (Trình thông dịch Mã), hoặc mở rộng công cụ (Học công cụ) trong quy trình lý luận.

Q: Roger có 5 quả bóng tennis. Anh ấy mua 
2 lon bóng tennis nữa. Mỗi lon có 3 quả bóng tennis. 
Roger có bao nhiêu quả bóng tennis bây giờ?

Gợi ý

LM

Roger bắt đầu với 5 quả bóng.
2 lon, mỗi lon có 3 quả bóng tennis 
tức là 6 quả bóng tennis. 5 + 6 = 11. 
Câu trả lời là 11.

LM

Kho dữ liệu

Hình 6: Lý luận Tăng cường Tri thức (§3.2). Gợi ý được tạo ra bởi LM (Tri thức Ẩn) hoặc được truy xuất từ kho dữ liệu bên ngoài (Tri thức Tường minh).

4 So sánh và Thảo luận
4.1 So sánh các Mô hình Ngôn ngữ
Bảng 1 thể hiện bốn phạm vi so sánh của các phương pháp khác nhau. Chúng tôi tiếp tục minh họa so sánh hiệu suất của LMs với các quy mô khác nhau trên GSM8K (Cobbe et al., 2021) của lý luận số học trong Hình 7. Kết quả tương tự trên các benchmark lý luận thường thức được thể hiện trong Phụ lục A.3.

Wei et al. (2022b) chứng minh một cách có hệ thống rằng gợi ý few-shot hoạt động tốt hơn trong hầu hết mọi nhiệm vụ khi quy mô mô hình tăng lên, điều này có thể được giải thích bởi thực tế là LMs với kích thước mô hình lớn hơn chứa nhiều tri thức ẩn hơn để lý luận (Liang et al., 2022b). Hơn nữa, gợi ý CoT tạo ra những cải thiện lớn hơn nhiều, với PaLM-540B cho thấy những cải thiện lớn nhất, như được mô tả trong Hình 7&9. Tuy nhiên, khi quy mô mô hình giảm xuống dưới 100B, gợi ý CoT sẽ không mang lại cải thiện hiệu suất và thậm chí có thể có hại. Do đó, gợi ý CoT gợi ra một khả năng nổi lên của quy mô mô hình (Wei et al., 2022a). Một khả năng là khi tri thức được lưu trữ đạt đến một mức độ nhất định, khả năng lý luận của LMs trải qua một thay đổi chất từ thay đổi lượng, dẫn đến sự xuất hiện của các khả năng nổi lên. Ngoài ra, Srivastava et al. (2022) chỉ ra rằng khả năng như vậy thường xảy ra trong các nhiệm vụ đa quy trình có thể được giải thích rằng việc đánh giá chỉ tập trung vào câu trả lời cuối cùng, nhưng bỏ qua sự cải thiện của quy trình trung gian do sự gia tăng quy mô mô hình mang lại khi nó chưa đủ lớn. Một quan sát thú vị khác được mô tả trong Hình 7&9 là PaLM-62B (Chowdhery et al., 2022) thậm chí hoạt động tốt hơn LaMDA-137B (Thoppilan et al., 2022), có thể là do nó được huấn luyện trên kho dữ liệu chất lượng cao hơn. Hiện tượng này khiến chúng ta suy đoán rằng khả năng nổi lên như vậy không chỉ được xác định bởi quy mô tham số mô hình mà còn liên quan đến chất lượng dữ liệu tiền huấn luyện.

Đáng chú ý, Hình 7&9 cũng minh họa rằng giữ cùng quy mô tham số, Codex (Chen et al., 2021) vượt trội hơn GPT-3 đáng kể3, mặc dù sự khác biệt chính giữa chúng là kho dữ liệu huấn luyện (Codex là một biến thể GPT-3 huấn luyện trên mã). Hiện tượng này cũng có thể được kiểm tra trong các công trình gần đây (Zhou et al., 2023; Li et al., 2022d; Zhang et al., 2023b; Madaan et al., 2022; Liang et al., 2022b), cho thấy việc tiền huấn luyện trên nhánh mã không chỉ cho phép khả năng tạo/hiểu mã mà còn có thể kích hoạt khả năng lý luận với CoT. Nguyên nhân chính xác vẫn còn bí ẩn, nhưng một trực giác là mã là một dạng văn bản tương tự hơn với lý luận, suy nghĩ về lập trình hướng thủ tục tương tự như giải quyết vấn đề từng bước, và lập trình hướng đối tượng tương tự như phân tách các nhiệm vụ phức tạp thành những nhiệm vụ đơn giản hơn (Yao et al., 2022). Ngoài ra, Prystawski and Goodman (2023) phát hiện rằng CoT chỉ có lợi khi dữ liệu huấn luyện thể hiện cấu trúc cục bộ. Do chuyên môn trong lý luận bằng cách điều hướng qua nhiều biến, CoT xuất sắc trong việc suy ra mối quan hệ giữa hai biến hiếm khi được gặp trong cùng ngữ cảnh. Tuy nhiên, nó có thể không hoạt động tốt hơn các ước lượng thống kê đơn giản khi nói đến lý luận với các biến thường xuyên cùng xuất hiện trong dữ liệu huấn luyện.

4.2 So sánh các Gợi ý
Bảng 1 thể hiện so sánh các phương pháp khác nhau của lý luận với gợi ý LM. Có ba nguồn chính của gợi ý cho các phương pháp hiện có:
1) Xây dựng thủ công phù hợp với gợi ý dựa trên mẫu và gợi ý few-shot nơi gợi ý không phức tạp. 2) Gợi ý được tạo ra bởi LM bù đắp cho các thiếu sót của gợi ý xây dựng thủ công. Nó có thể tùy chỉnh lý do cụ thể cho mỗi câu hỏi và cung cấp tri thức đầy đủ với gợi ý để tinh chỉnh hoặc tự huấn luyện. 3) Gợi ý dựa trên truy xuất thường dựa vào các tài nguyên bên ngoài được chú thích tốt (ví dụ: Wikipedia) và tiêu tốn việc truy xuất thông tin đắt đỏ, nhưng nó có thể giảm bớt vấn đề không ổn định của việc tạo ra.

Chúng tôi quan sát thấy rằng bất kể gợi ý được tạo ra như thế nào, gợi ý CoT chỉ hoạt động trên LMs lớn. LMs nhỏ hơn hoạt động bằng cách tinh chỉnh với lý do. Kết hợp với kết luận thực nghiệm trong Ye and Durrett (2022), những hiện tượng này tiết lộ rằng lý do lý luận chất lượng cao có trong ngữ cảnh đầu vào là chìa khóa cho lý luận với gợi ý LM. Mặc dù một số công trình đã cố gắng khám phá khả năng học trong ngữ cảnh trên LMs lớn (Xie et al., 2022; Min et al., 2022; Akyürek et al., 2022), lý do tại sao gợi ý CoT có thể thành công vẫn hấp dẫn cộng đồng và chưa được hiểu rõ. Một giả thuyết có thể là CoT là một sản phẩm phụ kỳ diệu của việc huấn luyện trên mã có thể được mở khóa bằng gợi ý. Lưu ý rằng các mẫu chứa CoT trong gợi ý few-shot có thể được xem như một loại hướng dẫn kích thích khả năng lý luận ẩn trong LMs lớn. Chung et al. (2022) xác minh kết quả tương tự bằng cách sử dụng CoT trong tinh chỉnh hướng dẫn để cải thiện hiệu suất mô hình hơn nữa. Trên thực tế, học trong ngữ cảnh có thể được xem như một trạng thái trung gian của quá trình tiến hóa từ gợi ý chung đến hướng dẫn có thể đọc được của con người. Theo xu hướng này, gợi ý có thể phát triển thành một giao diện thiết yếu của tương tác người-máy.

5 Benchmarks và Tài nguyên
5.1 Phân loại Benchmarks và Nhiệm vụ
Trong phần này, chúng tôi sẽ đưa ra tổng quan ngắn gọn về các benchmark và nhiệm vụ lý luận. Chi tiết thêm về các tập dữ liệu, cũng như lý luận với ChatGPT có thể được tìm thấy trong Phụ lục A.4 và A.5.

Lý luận Số học. Lý luận số học, còn được gọi là lý luận toán học, là khả năng thực hiện lý luận trên các bài toán từ toán học (MWP). Các công trình đầu về nhiệm vụ này (Hosseini et al., 2014; Kushman et al., 2014; Roy et al., 2015; Koncel-Kedziorski et al., 2015; Roy and Roth, 2015) tập trung vào các tập dữ liệu tương đối nhỏ bao gồm MWP một bước hoặc đa bước ở cấp độ tiểu học. Các công trình sau này tăng về độ phức tạp, khó khăn và quy mô. Gần đây nhất, Mishra et al. (2022a) mở rộng các tập dữ liệu hiện có để xây dựng một benchmark thống nhất liên quan đến khả năng toán học, đa dạng ngôn ngữ và tri thức bên ngoài.

Lý luận Thường thức. Tri thức thường thức và lý luận thường thức là một số vấn đề chính trong trí thông minh máy (Storks et al., 2019; Bhargava and Ng, 2022). Khi trả lời một câu hỏi, mọi người thường dựa vào tri thức thế giới phong phú của họ. Đối với LMs, thách thức chính của việc thực hiện lý luận thường thức nằm ở cách thức liên quan đến các tương tác vật lý và con người dưới giả định về tri thức nền chung (Bhargava and Ng, 2022). Nhiều tập dữ liệu benchmark và nhiệm vụ (Clark et al., 2018; Mihaylov et al., 2018; Talmor et al., 2019; Bisk et al., 2020; Geva et al., 2021) được thiết kế, và benchmark được sử dụng rộng rãi nhất hiện nay là CommonsenseQA (Talmor et al., 2019).

Lý luận Logic. Các dạng phổ biến của lý luận logic bao gồm lý luận suy diễn và lý luận quy nạp, lý luận suy diễn và lý luận khấu thoái (Sinha et al., 2019; Bao et al., 2022; Young et al., 2022; Bao et al., 2023). Lý luận suy diễn được thực hiện bằng cách đi từ thông tin chung đến kết luận cụ thể. Các tập dữ liệu điển hình trong lĩnh vực này bao gồm các cơ sở quy tắc tổng hợp cộng với các kết luận được suy ra (Clark et al., 2020; Tafjord et al., 2021). Dalvi et al. (2021) đề xuất một cách sáng tạo một tập dữ liệu chứa các cây kéo theo đa bước cùng với các quy tắc và kết luận. Trái ngược với lý luận suy diễn, lý luận quy nạp nhằm đưa ra kết luận bằng cách đi từ các quan sát cụ thể đến các nguyên tắc chung (Yang et al., 2022c).

Lý luận Tượng trưng. Lý luận tượng trưng ở đây chỉ đề cập đến một tập hợp hẹp các nhiệm vụ đơn giản kiểm tra một tập hợp đa dạng các chức năng thao tác tượng trưng, thay vì AI tượng trưng, là một khái niệm tổng quát hơn. Các nhiệm vụ lý luận tượng trưng điển hình bao gồm nối chữ cái cuối, đảo ngược danh sách và tung đồng xu (Wei et al., 2022b).

Lý luận Đa phương thức. Ngoài phương thức văn bản, con người sử dụng thông tin có sẵn qua các phương thức khác nhau khi thực hiện lý luận. Để đạt được mục tiêu này, các benchmark lý luận đa phương thức (Zellers et al., 2019; Park et al., 2020; Dong et al., 2022) được trình bày để thu hẹp khoảng cách này. Gần đây, Lu et al. (2022a) trình bày ScienceQA, một tập dữ liệu lựa chọn đa phương thức quy mô lớn bao gồm các câu hỏi đa dạng về chủ đề khoa học với các câu trả lời và giải thích tương ứng. Zhang et al. (2023a) đề xuất một nhiệm vụ mới về lý luận tương tự đa phương thức trên đồ thị tri thức.

5.2 Tài nguyên
Nhờ tinh thần mã nguồn mở của cộng đồng NLP, nhiều tài nguyên được công khai cùng với các bài báo để các nhà nghiên cứu thử nghiệm. ThoughtSource là một tài nguyên trung tâm, mở và cộng đồng xung quanh dữ liệu và công cụ liên quan đến lý luận CoT trong các mô hình ngôn ngữ lớn4. Thư viện LangChain được thiết kế để giúp các nhà phát triển xây dựng ứng dụng sử dụng LLMs kết hợp với các nguồn tính toán hoặc tri thức khác5. λprompt cho phép xây dựng máy gợi ý dựa trên LM lớn hoàn chỉnh, bao gồm những máy tự chỉnh sửa để sửa chữa và thậm chí tự viết mã thực thi của chúng6. Gần đây, Ou et al. (2023) phát triển EasyInstruct, một gói Python để hướng dẫn LLMs như GPT-3 trong các thí nghiệm nghiên cứu. Một trường hợp thử nghiệm cho lý luận sử dụng EasyInstruct có thể được tìm thấy trong Phụ lục A.6.

6 Hướng Tương lai
Nguyên lý Lý thuyết của Lý luận. LMs đã được chứng minh có khả năng học zero-shot và lý luận nổi lên (Wei et al., 2022b; Wang et al., 2022e; Wei et al., 2022a). Để khám phá bí ẩn của thành công như vậy, nhiều nhà nghiên cứu đã khám phá thực nghiệm vai trò của học trong ngữ cảnh (Ye and Durrett, 2022; Liu et al., 2022a) và lý do (Min et al., 2022; Lampinen et al., 2022). Một số công trình tập trung vào việc khám phá các nguyên tắc của thuật toán học máy đằng sau học trong ngữ cảnh (Xie et al., 2022; Akyürek et al., 2023) và điều chỉnh gợi ý (Wei et al., 2021). Một dòng công việc khác cố gắng điều tra kiến trúc của Transformers thông qua các nơ-ron tri thức (Dai et al., 2022) hoặc nơ-ron kỹ năng (Wang et al., 2022b). Các công trình gần đây hơn (Wang et al., 2022c; Madaan et al., 2022) chứng minh rằng LMs được tiền huấn luyện của mã xử lý lý luận thường thức có cấu trúc và dự đoán tốt hơn LMs của ngôn ngữ tự nhiên, ngay cả khi nhiệm vụ downstream không liên quan đến mã nguồn. Tuy nhiên, việc tiền huấn luyện dựa trên mã (hoặc tiền huấn luyện được cấu trúc lại (Yuan and Liu, 2022)) vẫn có hạn chế vì phải sử dụng cấu trúc có sẵn (ví dụ: kho dữ liệu được căn chỉnh hiện có hoặc xây dựng từ đầu qua cây cú pháp hoặc AMR (Banarescu et al., 2013)) để cải cách lại văn bản thuần túy. Do đó, sự thật có thể gần, và chúng tôi cho rằng việc nghiên cứu nguyên lý lý thuyết là có lợi để ủng hộ cái nhìn minh bạch về lý luận với gợi ý LM và tiếp tục giải mã vật chất tối của trí thông minh bằng cách làm nổi bật chuỗi liên tục phản trực giác qua ngôn ngữ, tri thức và lý luận7. Lưu ý rằng lý luận trong NLP có lợi thế tiềm năng của việc giải quyết vấn đề phức tạp và nên tận dụng tốt hơn vật chất tối trong các ngành liên ngành (ví dụ: Lý thuyết Tâm trí (Sap et al., 2022; Moghaddam and Honey, 2023; Zhou et al., 2022b; Shapira et al., 2023)).

Lý luận Hiệu quả. Cần lưu ý, các phương pháp hiện tại chủ yếu phụ thuộc vào LMs lớn, có thể tiêu tốn tài nguyên tính toán cao. Về tính thực tế, cần thiết phải nghiên cứu lý luận với LMs nhỏ hoặc phát triển các phương pháp lý luận hiệu quả chú ý đến phát thải carbon và sử dụng năng lượng trong quá trình huấn luyện và suy luận mô hình (Xu et al., 2021). Một cách khả thi có thể là phát triển các mô hình có thể cho phép tổng quát hóa qua một loạt các kịch bản đánh giá như Flan-T5 (Chung et al., 2022), tinh chỉnh cả với và không có mẫu (tức là zero-shot và few-shot) và với và không có CoT. Gần đây, một cách tiếp cận trực quan đã được đề xuất để chuyển giao khả năng lý luận của LMs lớn sang LMs nhỏ hơn thông qua chưng cất tri thức (Shridhar et al., 2022; Magister et al., 2022; Ho et al., 2022). Các hướng đầy hứa hẹn khác bao gồm tăng cường truy xuất (Li et al., 2022a), chỉnh sửa mô hình (Cao et al., 2021; Mitchell et al., 2022a,b; Cheng et al., 2023), điều chỉnh delta (He et al., 2022; Mao et al., 2022; Pal et al., 2022; Ding et al., 2022), v.v.

Lý luận Mạnh mẽ, Trung thực và Có thể Diễn giải. Tính mạnh mẽ, trung thực và khả năng diễn giải đã lâu được theo đuổi bởi lĩnh vực học sâu, đặc biệt trong các nhiệm vụ đòi hỏi logic mạnh, như lý luận. Shaikh et al. (2022) chứng minh rằng CoT zero-shot sẽ tạo ra độc tính và thiên vị không mong muốn, cho thấy sự cần thiết của lý luận mạnh mẽ, trung thực và có thể diễn giải. Creswell and Shanahan (2022) tận dụng kiến trúc đa giai đoạn lựa chọn-suy luận (Creswell et al., 2022) cho lý luận trung thực, nhưng vẫn thiếu khả năng diễn giải trong mỗi giai đoạn. Các công trình dựa trên mã (Madaan et al., 2022; Gao et al., 2022; Chen et al., 2022b) đạt được tính mạnh mẽ và khả năng diễn giải ở một mức độ nào đó, nhưng chúng có sự hỗ trợ của công cụ bên ngoài. Vẫn còn một chặng đường dài để đạt được tính mạnh mẽ, trung thực và khả năng diễn giải thực sự với LMs. May mắn thay, Dohan et al. (2022) cung cấp một ý tưởng mới để sử dụng chương trình xác suất để giải quyết các vấn đề lý luận khác nhau. Các giải pháp khác có thể là các cách tiếp cận nơ-ron-tượng trưng (Du et al., 2021; Li et al., 2022c; Ouyang et al., 2021; Feng et al., 2022) hoặc phản hồi của con người (Ouyang et al., 2022).

Lý luận Đa phương thức (Tương tác). Lý luận văn bản bị hạn chế bởi những gì có thể được biểu đạt thông qua ngôn ngữ tự nhiên. Một hướng đầy hứa hẹn hơn là lý luận đa phương thức liên quan đến sự đa dạng thông tin của thế giới thực của lý luận con người. Lu et al. (2022a) tạo ra CoT khi xử lý một tập dữ liệu đa phương thức; tuy nhiên, nó chỉ đơn giản trích xuất mô tả văn bản từ hình ảnh, và nó thực sự vẫn là một nhiệm vụ lý luận văn bản. Một cách trực quan, có lợi khi tích hợp thông tin đa phương thức vào các quy trình lý luận như hình ảnh, âm thanh, video, v.v., và thiết kế một CoT đa phương thức thống nhất. Ngoài các mô hình đa phương thức thống nhất, cũng đầy hứa hẹn khi mô hình chuỗi (Wu et al., 2022a) để tiến hành lý luận tương tác giữa các mô hình của các phương thức khác nhau. Bên cạnh đó, Sap et al. (2022) cho thấy rằng một trong những mô hình ngôn ngữ lớn nhất hiện nay (GPT-3 (Brown et al., 2020)) thiếu kỹ năng lý luận về các trạng thái tinh thần và phản ứng của tất cả những người liên quan. Do đó, các phương pháp lý luận tương tác nên được chú ý bằng cách lấy cảm hứng từ các lĩnh vực khác (ví dụ: Khoa học Nhận thức (Hollenstein et al., 2019), Trí thông minh Xã hội (Krishna et al., 2022)), có thể có hướng dẫn tiềm năng cho lý luận trong NLP vì chỉ tăng quy mô LMs có thể không phải là cách hiệu quả nhất để tạo ra các hệ thống AI.

Lý luận Tổng quát (Thực sự). Tổng quát hóa là một trong những biểu tượng quan trọng nhất của các mô hình để đạt được khả năng lý luận thực sự. Cho một nhiệm vụ lý luận, chúng ta hy vọng LMs có thể xử lý không chỉ vấn đề đó mà còn giải quyết một nhóm các nhiệm vụ lý luận tương tự (không được thấy trong quá trình huấn luyện). Zhou et al. (2022a); Anil et al. (2022) khám phá vấn đề OOD về độ dài của các câu hỏi lý luận, nhưng tổng quát hóa thực sự vẫn còn xa mới đạt được sự hài lòng. Trong khi đó, Kejriwal et al. (2022) nhấn mạnh rằng các phương pháp đánh giá toàn diện hơn dựa trên lý thuyết (ví dụ: vật lý ngây thơ (Gardin and Meltzer, 1989) và tâm lý học thường thức (Gordon and Hobbs, 2004)) nên được đề xuất. Chúng tôi cho rằng lý luận tổng quát có thể liên quan chặt chẽ đến lý luận tương tự (Chen et al., 2022a; Webb et al., 2022), lý luận nhân quả (Feder et al., 2022), lý luận tổng hợp (Yang et al., 2022a), v.v.

7 Kết luận và Tầm nhìn
Trong bài báo này, chúng tôi cung cấp một đánh giá về lý luận với gợi ý mô hình ngôn ngữ, bao gồm so sánh toàn diện và một số hướng nghiên cứu. Trong tương lai, chúng tôi hình dung một sự tương tác mạnh mẽ hơn giữa các phương pháp từ NLP và các lĩnh vực khác và hy vọng các mô hình gợi ý LM tinh vi và hiệu quả sẽ ngày càng đóng góp vào việc cải thiện hiệu suất lý luận.

--- TRANG 10 ---
Lời cảm ơn
Chúng tôi muốn bày tỏ lòng biết ơn với các bình duyệt ẩn danh vì những lời bình luận tử tế của họ. Chúng tôi cảm ơn Yicong vì đã sửa chữa một Phương trình không phù hợp trong bài báo. Công việc này được hỗ trợ bởi Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số 62206246 và U19B2027), Quỹ Khoa học Tự nhiên Tỉnh Chiết Giang Trung Quốc (Số LGG22F030011), Quỹ Khoa học Tự nhiên Ninh Ba (2021J190), và Chương trình Giới thiệu Tài năng Dòng sông Dũng (2021A-156-G), Quỹ Mở CAAI-Huawei MindSpore, và Phòng thí nghiệm chung NUS-NCS (A-0008542-00-00). Tài nguyên tính toán được hỗ trợ bởi Trung tâm Công nghệ Thông tin và Phòng thí nghiệm Trọng điểm Nhà nước CAD&CG, Đại học Chiết Giang.

Hạn chế
Trong nghiên cứu này, chúng tôi cung cấp một khảo sát về lý luận với gợi ý mô hình ngôn ngữ. Chúng tôi thảo luận về các khảo sát liên quan trong Phụ lục A.1 và sẽ tiếp tục thêm các cách tiếp cận liên quan hơn với phân tích chi tiết hơn. Mặc dù nỗ lực hết sức, vẫn có thể có một số hạn chế còn lại trong bài báo này.

Tài liệu tham khảo & Phương pháp. Do giới hạn trang, chúng tôi có thể bỏ sót một số tài liệu tham khảo quan trọng và không thể đưa ra tất cả các chi tiết kỹ thuật. Chúng tôi chủ yếu xem xét các phương pháp tiên tiến trong vòng hai năm (chủ yếu vào năm 2022) trong §3, chủ yếu từ ACL, EMNLP, NAACL, NeurIPS, ICLR, arXiv, v.v., và chúng tôi sẽ tiếp tục chú ý và bổ sung các công trình mới nhất.

Benchmarks. Hầu hết các benchmark lý luận được đề cập trong §5 được thu thập và phân loại từ phần thực nghiệm của các công trình chính thống. Định nghĩa và ranh giới của mỗi nhiệm vụ có thể không đủ chính xác. Bên cạnh đó, công trình của chúng tôi có thể bỏ sót một số loại nhiệm vụ lý luận như lý luận với generics (Allaway et al., 2022), lý luận kế thừa mặc định (Brewka, 1987), lý luận không đơn điệu (Ginsberg, 1987) trong NLP, và sẽ cố gắng hết sức để lấp đầy khoảng trống này.

Kết luận Thực nghiệm. Chúng tôi đưa ra so sánh chi tiết và thảo luận về các mô hình ngôn ngữ và gợi ý trong §4, và liệt kê một số hướng tương lai đầy hứa hẹn trong §6. Tất cả các kết luận được đề xuất và suy đoán thêm dựa trên phân tích thực nghiệm của các công trình hiện có có thể không đủ vĩ mô. Khi lĩnh vực phát triển nhanh hơn, chúng tôi sẽ cập nhật các ý kiến mới nhất kịp thời.

Tài liệu tham khảo
David H. Ackley, Geoffrey E. Hinton, và Terrence J. Sejnowski. 1985. Thuật toán học cho máy boltzmann. Cogn. Sci., 9(1):147–169.

Ekin Akyürek, Dale Schuurmans, Jacob Andreas, Tengyu Ma, và Denny Zhou. 2022. Thuật toán học nào trong học trong ngữ cảnh? các điều tra với mô hình tuyến tính. CoRR, abs/2211.15661.

Ekin Akyürek, Dale Schuurmans, Jacob Andreas, Tengyu Ma, và Denny Zhou. 2023. Thuật toán học nào trong học trong ngữ cảnh? các điều tra với mô hình tuyến tính. Trong Hội nghị Quốc tế thứ Mười một về Đại diện Học tập, ICLR 2023, Kigali, Rwanda, 1-5 tháng 5, 2023. OpenReview.net.

Emily Allaway, Jena D. Hwang, Chandra Bhagavatula, Kathleen R. McKeown, Doug Downey, và Yejin Choi. 2022. Chim cánh cụt không bay: Lý luận về generics thông qua các instance và ngoại lệ. CoRR, abs/2205.11658.

Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, và Hannaneh Hajishirzi. 2019. MathQA: Hướng tới giải quyết bài toán từ toán học có thể diễn giải với chủ nghĩa hình thức dựa trên hoạt động. Trong Kỷ yếu Hội nghị năm 2019 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, Tập 1 (Bài báo Dài và Ngắn), trang 2357–2367, Minneapolis, Minnesota. Hiệp hội Ngôn ngữ học Tính toán.

Cem Anil, Yuhuai Wu, Anders Andreassen, Aitor Lewkowycz, Vedant Misra, Vinay V. Ramasesh, Ambrose Slone, Guy Gur-Ari, Ethan Dyer, và Behnam Neyshabur. 2022. Khám phá tổng quát độ dài trong các mô hình ngôn ngữ lớn. CoRR, abs/2207.04901.

Laura Banarescu, Claire Bonial, Shu Cai, Madalina Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin Knight, Philipp Koehn, Martha Palmer, và Nathan Schneider. 2013. Đại diện ý nghĩa trừu tượng cho sembanking. Trong Kỷ yếu Hội thảo Chú thích Ngôn ngữ học thứ 7 và Khả năng Tương tác với Discourse, LAW-ID@ACL 2013, 8-9 tháng 8, 2013, Sofia, Bulgaria, trang 178–186. Hiệp hội Ngôn ngữ học Tính toán.

Qiming Bao, Alex Yuxuan Peng, Zhenyun Deng, Wanjun Zhong, Neset Tan, Nathan Young, Yang Chen, Yonghua Zhu, Michael Witbrock, và Jiamou Liu. 2023. Học tương phản với tăng cường dữ liệu hướng logic cho lý luận logic trên văn bản. CoRR, abs/2305.12599.

Qiming Bao, Alex Yuxuan Peng, Tim Hartill, Neset Tan, Zhenyun Deng, Michael Witbrock, và Jiamou Liu. 2022. Lý luận suy diễn đa bước trên ngôn ngữ tự nhiên: Một nghiên cứu thực nghiệm về tổng quát hóa ngoài phân phối. Trong Kỷ yếu Hội thảo Quốc tế thứ 16 về Học và Lý luận Nơ-ron-Tượng trưng như một phần của Hội nghị Quốc tế Chung thứ 2 về Học & Lý luận (IJCLR 2022), Cumberland Lodge, Windsor Great Park, UK, 28-30 tháng 9, 2022, tập 3212 của Kỷ yếu Hội thảo CEUR, trang 202–217. CEUR-WS.org.

Luca Beurer-Kellner, Marc Fischer, và Martin Vechev. 2022. Gợi ý là lập trình: Một ngôn ngữ truy vấn cho các mô hình ngôn ngữ lớn. CoRR, abs/2212.06094.

Prajjwal Bhargava và Vincent Ng. 2022. Lý luận và tạo ra tri thức thường thức với các mô hình ngôn ngữ được tiền huấn luyện: Một khảo sát. Trong Hội nghị AAAI thứ Ba mười sáu về Trí tuệ Nhân tạo, AAAI 2022, Hội nghị thứ Ba mười tư về Các Ứng dụng Sáng tạo của Trí tuệ Nhân tạo, IAAI 2022, Hội nghị thứ Mười hai về Tiến bộ Giáo dục trong Trí tuệ Nhân tạo, EAAI 2022 Sự kiện Ảo, 22 tháng 2 - 1 tháng 3, 2022, trang 12317–12325. AAAI Press.

Yonatan Bisk, Rowan Zellers, Ronan Le bras, Jianfeng Gao, và Yejin Choi. 2020. Piqa: Lý luận về thường thức vật lý bằng ngôn ngữ tự nhiên. Kỷ yếu Hội nghị AAAI về Trí tuệ Nhân tạo, 34(05):7432–7439.

Gerhard Brewka. 1987. Logic của kế thừa trong các hệ thống khung. Trong Kỷ yếu Hội nghị Quốc tế thứ 10 về Trí tuệ Nhân tạo. Milan, Italy, 23-28 tháng 8, 1987, trang 483–488. Morgan Kaufmann.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. 2020. Mô hình ngôn ngữ là người học few-shot. Trong Tiến bộ trong Hệ thống Xử lý Thông tin Nơ-ron 33: Hội nghị Hàng năm về Hệ thống Xử lý Thông tin Nơ-ron 2020, NeurIPS 2020, 6-12 tháng 12, 2020, ảo.

Nicola De Cao, Wilker Aziz, và Ivan Titov. 2021. Chỉnh sửa tri thức thực tế trong các mô hình ngôn ngữ. Trong Kỷ yếu Hội nghị năm 2021 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, EMNLP 2021, Sự kiện Ảo / Punta Cana, Cộng hòa Dominica, 7-11 tháng 11, 2021, trang 6491–6506. Hiệp hội Ngôn ngữ học Tính toán.

Jiangjie Chen, Rui Xu, Ziquan Fu, Wei Shi, Zhongqiao Li, Xinbo Zhang, Changzhi Sun, Lei Li, Yanghua Xiao, và Hao Zhou. 2022a. E-KAR: Một benchmark để hợp lý hóa lý luận tương tự ngôn ngữ tự nhiên. Trong Findings của Hiệp hội Ngôn ngữ học Tính toán: ACL 2022, Dublin, Ireland, 22-27 tháng 5, 2022, trang 3941–3955. Hiệp hội Ngôn ngữ học Tính toán.

Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, và Wojciech Zaremba. 2021. Đánh giá các mô hình ngôn ngữ lớn được huấn luyện trên mã. CoRR, abs/2107.03374.

Wenhu Chen. 2022. Mô hình ngôn ngữ lớn là người lý luận bảng few(1)-shot. CoRR, abs/2210.06710.

Wenhu Chen, Xueguang Ma, Xinyi Wang, và William W. Cohen. 2022b. Gợi ý chương trình suy nghĩ: Tách rời tính toán khỏi lý luận cho các nhiệm vụ lý luận số. CoRR, abs/2211.12588.

Zhenfang Chen, Qinhong Zhou, Yikang Shen, Yining Hong, Hao Zhang, và Chuang Gan. 2023. Nhìn, suy nghĩ, xác nhận: Gợi ý tương tác giữa các mô hình thị giác và ngôn ngữ cho lý luận thị giác dựa trên tri thức.

Siyuan Cheng, Ningyu Zhang, Bozhong Tian, Zelin Dai, Feiyu Xiong, Wei Guo, và Huajun Chen. 2023. Chỉnh sửa embedding đồ thị tri thức dựa trên mô hình ngôn ngữ. CoRR, abs/2301.10405.

Zhoujun Cheng, Tianbao Xie, Peng Shi, Chengzu Li, Rahul Nadkarni, Yushi Hu, Caiming Xiong, Dragomir Radev, Mari Ostendorf, Luke Zettlemoyer, Noah A. Smith, và Tao Yu. 2022. Ràng buộc các mô hình ngôn ngữ trong các ngôn ngữ tượng trưng. CoRR, abs/2210.02875.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, và Slav Petrov, và Noah Fiedel. 2022. Palm: Mở rộng mô hình ngôn ngữ với pathways. CoRR, abs/2204.02311.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Y. Zhao, Yanping Huang, Andrew M. Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, và Jason Wei. 2022. Mở rộng các mô hình ngôn ngữ được tinh chỉnh hướng dẫn. CoRR, abs/2210.11416.

Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, và Oyvind Tafjord. 2018. Bạn nghĩ mình đã giải quyết được việc trả lời câu hỏi? thử arc, thách thức lý luận AI2. CoRR, abs/1803.05457.

Peter Clark, Oyvind Tafjord, và Kyle Richardson. 2020. Transformers như người lý luận mềm trên ngôn ngữ. Trong Kỷ yếu Hội nghị Quốc tế thứ Hai mười chín về Trí tuệ Nhân tạo, IJCAI-20, trang 3882–3890. Hội nghị Quốc tế về Trí tuệ Nhân tạo Tổ chức. Phân khúc chính.

Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, và John Schulman. 2021. Huấn luyện trình xác minh để giải quyết bài toán từ toán học. CoRR, abs/2110.14168.

Antonia Creswell và Murray Shanahan. 2022. Lý luận trung thực sử dụng các mô hình ngôn ngữ lớn. CoRR, abs/2208.14271.

Antonia Creswell, Murray Shanahan, và Irina Higgins. 2022. Lựa chọn-suy luận: Khai thác các mô hình ngôn ngữ lớn cho lý luận logic có thể diễn giải. CoRR, abs/2205.09712.

Damai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao Chang, và Furu Wei. 2022. Nơ-ron tri thức trong các transformer được tiền huấn luyện. Trong Kỷ yếu Cuộc họp Hàng năm thứ 60 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), ACL 2022, Dublin, Ireland, 22-27 tháng 5, 2022, trang 8493–8502. Hiệp hội Ngôn ngữ học Tính toán.

Bhavana Dalvi, Peter Jansen, Oyvind Tafjord, Zhengnan Xie, Hannah Smith, Leighanna Pipatanangkura, và Peter Clark. 2021. Giải thích câu trả lời với cây kéo theo. Trong Kỷ yếu Hội nghị năm 2021 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, trang 7358–7370, Trực tuyến và Punta Cana, Cộng hòa Dominica. Hiệp hội Ngôn ngữ học Tính toán.

Joe Davison, Joshua Feldman, và Alexander M. Rush. 2019. Khai thác tri thức thường thức từ các mô hình được tiền huấn luyện. Trong Kỷ yếu Hội nghị năm 2019 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên và Hội nghị Quốc tế thứ 9 về Xử lý Ngôn ngữ Tự nhiên, EMNLP-IJCNLP 2019, Hong Kong, Trung Quốc, 3-7 tháng 11, 2019, trang 1173–1178. Hiệp hội Ngôn ngữ học Tính toán.

Shizhe Diao, Pengcheng Wang, Yong Lin, và Tong Zhang. 2023. Gợi ý tích cực với chuỗi suy nghĩ cho các mô hình ngôn ngữ lớn. CoRR, abs/2302.12246.

Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, Jing Yi, Weilin Zhao, Xiaozhi Wang, Zhiyuan Liu, Hai-Tao Zheng, Jianfei Chen, Yang Liu, Jie Tang, Juanzi Li, và Maosong Sun. 2022. Điều chỉnh delta: Một nghiên cứu toàn diện về các phương pháp hiệu quả tham số cho các mô hình ngôn ngữ được tiền huấn luyện. CoRR, abs/2203.06904.

David Dohan, Winnie Xu, Aitor Lewkowycz, Jacob Austin, David Bieber, Raphael Gontijo Lopes, Yuhuai Wu, Henryk Michalewski, Rif A. Saurous, Jascha Sohl-Dickstein, Kevin Murphy, và Charles Sutton. 2022. Chuỗi mô hình ngôn ngữ. CoRR, abs/2207.10342.

Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, và Zhifang Sui. 2023. Một khảo sát về học trong ngữ cảnh. CoRR, abs/2301.00234.

Qingxiu Dong, Ziwei Qin, Heming Xia, Tian Feng, Shoujie Tong, Haoran Meng, Lin Xu, Zhongyu Wei, Weidong Zhan, Baobao Chang, Sujian Li, Tianyu Liu, và Zhifang Sui. 2022. Lý luận đa phương thức dựa trên tiền đề: Suy luận có điều kiện trên các manh mối văn bản và thị giác chung. Trong Kỷ yếu Cuộc họp Hàng năm thứ 60 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), trang 932–946, Dublin, Ireland. Hiệp hội Ngôn ngữ học Tính toán.

Li Du, Xiao Ding, Kai Xiong, Ting Liu, và Bing Qin. 2021. Excar: Lý luận nhân quả có thể giải thích được tăng cường tri thức đồ thị sự kiện. Trong Kỷ yếu Cuộc họp Hàng năm thứ 59 của Hiệp hội Ngôn ngữ học Tính toán và Hội nghị Quốc tế thứ 11 về Xử lý Ngôn ngữ Tự nhiên, ACL/IJCNLP 2021, (Tập 1: Bài báo Dài), Sự kiện Ảo, 1-6 tháng 8, 2021, trang 2354–2363. Hiệp hội Ngôn ngữ học Tính toán.

Yifan Du, Zikang Liu, Junyi Li, và Wayne Xin Zhao. 2022. Một khảo sát về các mô hình được tiền huấn luyện thị giác-ngôn ngữ. Trong Kỷ yếu Hội nghị Quốc tế thứ Ba mười một về Trí tuệ Nhân tạo, IJCAI 2022, Vienna, Austria, 23-29 tháng 7, 2022, trang 5436–5443. ijcai.org.

Dheeru Dua, Shivanshu Gupta, Sameer Singh, và Matt Gardner. 2022. Gợi ý liên tiếp để phân tách các câu hỏi phức tạp. Trong Kỷ yếu Hội nghị năm 2022 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, trang 1251–1265, Abu Dhabi, Các Tiểu vương quốc Ả Rập Thống nhất. Hiệp hội Ngôn ngữ học Tính toán.

Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, và Matt Gardner. 2019. DROP: Một benchmark hiểu đọc đòi hỏi lý luận rời rạc trên các đoạn văn. Trong Kỷ yếu Hội nghị năm 2019 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, Tập 1 (Bài báo Dài và Ngắn), trang 2368–2378, Minneapolis, Minnesota. Hiệp hội Ngôn ngữ học Tính toán.

Nan Duan, Duyu Tang, và Ming Zhou. 2020. Lý luận máy: Công nghệ, khó khăn và tương lai. Trong Kỷ yếu Hội nghị năm 2020 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên: Tóm tắt Hướng dẫn, EMNLP 2020, Trực tuyến, 19-20 tháng 11, 2020, trang 1–6. Hiệp hội Ngôn ngữ học Tính toán.

Angela Fan, Mike Lewis, và Yann N. Dauphin. 2018. Tạo câu chuyện nơ-ron phân cấp. Trong Kỷ yếu Cuộc họp Hàng năm thứ 56 của Hiệp hội Ngôn ngữ học Tính toán, ACL 2018, Melbourne, Australia, 15-20 tháng 7, 2018, Tập 1: Bài báo Dài, trang 889–898. Hiệp hội Ngôn ngữ học Tính toán.

Amir Feder, Katherine A. Keith, Emaad Manzoor, Reid Pryzant, Dhanya Sridhar, Zach Wood-Doughty, Jacob Eisenstein, Justin Grimmer, Roi Reichart, Margaret E. Roberts, Brandon M. Stewart, Victor Veitch, và Diyi Yang. 2022. Suy luận nhân quả trong xử lý ngôn ngữ tự nhiên: Ước lượng, dự đoán, diễn giải và hơn thế nữa. Trans. Assoc. Comput. Linguistics, 10:1138–1158.

Yufei Feng, Xiaoyu Yang, Xiaodan Zhu, và Michael A. Greenspan. 2022. Neuro-symbolic natural logic với sửa đổi nội tâm cho suy luận ngôn ngữ tự nhiên. Trans. Assoc. Comput. Linguistics, 10:240–256.

Yao Fu, Hao Peng, Litu Ou, Ashish Sabharwal, và Tushar Khot. 2023a. Chuyên môn hóa các mô hình ngôn ngữ nhỏ hơn hướng tới lý luận đa bước. CoRR, abs/2301.12726.

Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, và Tushar Khot. 2023b. Gợi ý dựa trên độ phức tạp cho lý luận đa bước. Trong Hội nghị Quốc tế thứ Mười một về Đại diện Học tập.

Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, và Graham Neubig. 2022. PAL: các mô hình ngôn ngữ được hỗ trợ chương trình. CoRR, abs/2211.10435.

Francesco Gardin và Bernard Meltzer. 1989. Đại diện tương tự của vật lý ngây thơ. Artif. Intell., 38(2):139–159.

Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, và Jonathan Berant. 2021. Aristotle có sử dụng laptop không? một benchmark trả lời câu hỏi với các chiến lược lý luận ẩn. Transactions of the Association for Computational Linguistics, 9:346–361.

Matthew L Ginsberg. 1987. Readings in nonmonotonic reasoning.

Andrew S. Gordon và Jerry R. Hobbs. 2004. Formalization của tâm lý học thường thức. AI Mag., 25(4):49–62.

Zhen Guo, Zelin Wan, Qisheng Zhang, Xujiang Zhao, Feng Chen, Jin-Hee Cho, Qi Zhang, Lance M. Kaplan, Dong H. Jeong, và Audun Jøsang. 2022. Một khảo sát về lý luận và định lượng không chắc chắn cho ra quyết định: Lý thuyết niềm tin gặp học sâu. CoRR, abs/2206.05675.

Kyle Hamilton, Aparna Nayak, Bojan Bozic, và Luca Longo. 2022. AI nơ-ron-tượng trưng có đáp ứng lời hứa của nó trong xử lý ngôn ngữ tự nhiên không? Một đánh giá có cấu trúc. CoRR, abs/2202.12205.

Xu Han, Zhengyan Zhang, Ning Ding, Yuxian Gu, Xiao Liu, Yuqi Huo, Jiezhong Qiu, Yuan Yao, Ao Zhang, Liang Zhang, Wentao Han, Minlie Huang, Qin Jin, Yanyan Lan, Yang Liu, Zhiyuan Liu, Zhiwu Lu, Xipeng Qiu, Ruihua Song, Jie Tang, Ji-Rong Wen, Jinhui Yuan, Wayne Xin Zhao, và Jun Zhu. 2021. Mô hình được tiền huấn luyện: Quá khứ, hiện tại và tương lai. AI Open, 2:225–250.

Hangfeng He, Hongming Zhang, và Dan Roth. 2023. Suy nghĩ lại với truy xuất: Suy luận mô hình ngôn ngữ lớn trung thực. CoRR, abs/2301.00303.

Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, và Graham Neubig. 2022. Hướng tới cái nhìn thống nhất về học chuyển giao hiệu quả tham số. Trong Hội nghị Quốc tế thứ Mười về Đại diện Học tập, ICLR 2022, Sự kiện Ảo, 25-29 tháng 4, 2022. OpenReview.net.

Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, và Jacob Steinhardt. 2021. Đo lường giải quyết vấn đề toán học với tập dữ liệu MATH. Trong Kỷ yếu Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, tháng 12 năm 2021, ảo.

Namgyu Ho, Laura Schmid, và Se-Young Yun. 2022. Mô hình ngôn ngữ lớn là giáo viên lý luận. CoRR, abs/2212.10071.

Nora Hollenstein, Maria Barrett, Marius Troendle, Francesco Bigiolli, Nicolas Langer, và Ce Zhang. 2019. Thúc đẩy NLP với tín hiệu xử lý ngôn ngữ nhận thức. CoRR, abs/1904.02682.

Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, và Nate Kushman. 2014. Học giải quyết bài toán từ số học với phân loại động từ. Trong Kỷ yếu Hội nghị năm 2014 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên (EMNLP), trang 523–533, Doha, Qatar. Hiệp hội Ngôn ngữ học Tính toán.

Danqing Huang, Shuming Shi, Chin-Yew Lin, Jian Yin, và Wei-Ying Ma. 2016. Máy tính giải quyết bài toán từ toán học tốt như thế nào? xây dựng và đánh giá tập dữ liệu quy mô lớn. Trong Kỷ yếu Cuộc họp Hàng năm thứ 54 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), trang 887–896, Berlin, Germany. Hiệp hội Ngôn ngữ học Tính toán.

Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, và Jiawei Han. 2022. Mô hình ngôn ngữ lớn có thể tự cải thiện. CoRR, abs/2210.11610.

Jie Huang và Kevin Chen-Chuan Chang. 2022. Hướng tới lý luận trong các mô hình ngôn ngữ lớn: Một khảo sát. CoRR, abs/2212.10403.

Shaohan Huang, Li Dong, Wenhui Wang, Yaru Hao, Saksham Singhal, Shuming Ma, Tengchao Lv, Lei Cui, Owais Khan Mohammed, Barun Patra, Qiang Liu, Kriti Aggarwal, Zewen Chi, Johan Bjorck, Vishrav Chaudhary, Subhojit Som, Xia Song, và Furu Wei. 2023. Ngôn ngữ không phải là tất cả những gì bạn cần: Căn chỉnh nhận thức với các mô hình ngôn ngữ. CoRR, abs/2302.14045.

Shima Imani, Liang Du, và Harsh Shrivastava. 2023. Mathprompter: Lý luận toán học sử dụng các mô hình ngôn ngữ lớn. Trong Hội thảo ICLR 2023 về Mô hình Học máy Quy mô lớn Đáng tin cậy và Đáng tin cậy.

Zhengbao Jiang, Frank F. Xu, Jun Araki, và Graham Neubig. 2020. Làm thế nào chúng ta có thể biết những gì mô hình ngôn ngữ biết. Trans. Assoc. Comput. Linguistics, 8:423–438.

Jaehun Jung, Lianhui Qin, Sean Welleck, Faeze Brahman, Chandra Bhagavatula, Ronan Le Bras, và Yejin Choi. 2022. Gợi ý maieutic: Lý luận nhất quán logic với giải thích đệ quy. Trong Kỷ yếu Hội nghị năm 2022 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, trang 1266–1279, Abu Dhabi, Các Tiểu vương quốc Ả Rập Thống nhất. Hiệp hội Ngôn ngữ học Tính toán.

Seyed Mehran Kazemi, Najoung Kim, Deepti Bhatia, Xin Xu, và Deepak Ramachandran. 2022. LAMBADA: chuỗi ngược cho lý luận tự động bằng ngôn ngữ tự nhiên. CoRR, abs/2212.13894.

Mayank Kejriwal, Henrique Santos, Alice M. Mulvehill, và Deborah L. McGuinness. 2022. Thiết kế một bài kiểm tra mạnh mẽ để đo lường lý luận thường thức thực sự. Nat. Mach. Intell., 4(4):318–322.

Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, và Ashish Sabharwal. 2023. Gợi ý phân tách: Một cách tiếp cận mô-đun để giải quyết các nhiệm vụ phức tạp. Trong Hội nghị Quốc tế thứ Mười một về Đại diện Học tập.

Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, và Yusuke Iwasawa. 2022. Mô hình ngôn ngữ lớn là người lý luận zero-shot. CoRR, abs/2205.11916.

Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish Sabharwal, Oren Etzioni, và Siena Dumas Ang. 2015. Phân tích Bài toán Từ Đại số thành Phương trình. Transactions of the Association for Computational Linguistics, 3:585–597.

Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, và Hannaneh Hajishirzi. 2016. MAWPS: Một kho lưu trữ bài toán từ toán học. Trong Kỷ yếu Hội nghị năm 2016 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, trang 1152–1157, San Diego, California. Hiệp hội Ngôn ngữ học Tính toán.

Ranjay Krishna, Donsuk Lee, Li Fei-Fei, và Michael S. Bernstein. 2022. Trí tuệ nhân tạo được đặt trong xã hội cho phép học từ tương tác con người. Proceedings of the National Academy of Sciences, 119(39):e2115730119.

Nate Kushman, Luke Zettlemoyer, Regina Barzilay, và Yoav Artzi. 2014. Học tự động giải quyết bài toán từ đại số. Trong Kỷ yếu Cuộc họp Hàng năm thứ 52 của Hiệp hội Ngôn ngữ học Tính toán, ACL 2014, 22-27 tháng 6, 2014, Baltimore, MD, USA, Tập 1: Bài báo Dài, trang 271–281. Hiệp hội Ngôn ngữ học Tính toán.

Brenden M. Lake và Marco Baroni. 2017. Vẫn không có hệ thống sau tất cả những năm này: Về kỹ năng tổng hợp của mạng nơ-ron tuần tự-tới-tuần tự. CoRR, abs/1711.00350.

Andrew K. Lampinen, Ishita Dasgupta, Stephanie C. Y. Chan, Kory Matthewson, Michael Henry Tessler, Antonia Creswell, James L. McClelland, Jane X. Wang, và Felix Hill. 2022. Mô hình ngôn ngữ có thể học từ giải thích trong ngữ cảnh không? CoRR, abs/2204.02329.

Jie Lei, Licheng Yu, Tamara Berg, và Mohit Bansal. 2020. Điều gì có khả năng xảy ra tiếp theo? dự đoán sự kiện tương lai video-và-ngôn ngữ. Trong Kỷ yếu Hội nghị năm 2020 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên (EMNLP), trang 8769–8784, Trực tuyến. Hiệp hội Ngôn ngữ học Tính toán.

Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay V. Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, và Vedant Misra. 2022. Giải quyết các vấn đề lý luận định lượng với mô hình ngôn ngữ. CoRR, abs/2206.14858.

Huayang Li, Yixuan Su, Deng Cai, Yan Wang, và Lemao Liu. 2022a. Một khảo sát về tạo văn bản tăng cường truy xuất. CoRR, abs/2202.01110.

Shiyang Li, Jianshu Chen, Yelong Shen, Zhiyu Chen, Xinlu Zhang, Zekun Li, Hong Wang, Jing Qian, Baolin Peng, Yi Mao, Wenhu Chen, và Xifeng Yan. 2022b. Giải thích từ các mô hình ngôn ngữ lớn làm cho người lý luận nhỏ tốt hơn. CoRR, abs/2210.06726.

Xiao Li, Gong Cheng, Ziheng Chen, Yawei Sun, và Yuzhong Qu. 2022c. Adalogn: Mạng đồ thị logic thích ứng cho hiểu đọc máy dựa trên lý luận. Trong Kỷ yếu Cuộc họp Hàng năm thứ 60 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), ACL 2022, Dublin, Ireland, 22-27 tháng 5, 2022, trang 7147–7161. Hiệp hội Ngôn ngữ học Tính toán.

Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, và Weizhu Chen. 2022d. Về tiến bộ của việc làm cho mô hình ngôn ngữ trở thành người lý luận tốt hơn. CoRR, abs/2206.02336.

Ke Liang, Lingyuan Meng, Meng Liu, Yue Liu, Wenxuan Tu, Siwei Wang, Sihang Zhou, Xinwang Liu, và Fuchun Sun. 2022a. Lý luận trên các loại đồ thị tri thức khác nhau: Tĩnh, tạm thời và đa phương thức. CoRR, abs/2212.05767.

Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, Benjamin Newman, Binhang Yuan, Bobby Yan, Ce Zhang, Christian Cosgrove, Christopher D. Manning, Christopher Ré, Diana Acosta-Navas, Drew A. Hudson, Eric Zelikman, Esin Durmus, Faisal Ladhak, Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue Wang, Keshav Santhanam, Laurel J. Orr, Lucia Zheng, Mert Yüksekgönül, Mirac Suzgun, Nathan Kim, Neel Guha, Niladri S. Chatterji, Omar Khattab, Peter Henderson, Qian Huang, Ryan Chi, Sang Michael Xie, Shibani Santurkar, Surya Ganguli, Tatsunori Hashimoto, Thomas Icard, Tianyi Zhang, Vishrav Chaudhary, William Wang, Xuechen Li, Yifan Mai, Yuhui Zhang, và Yuta Koreeda. 2022b. Đánh giá toàn diện các mô hình ngôn ngữ. CoRR, abs/2211.09110.

Wang Ling, Dani Yogatama, Chris Dyer, và Phil Blunsom. 2017a. Cảm ứng chương trình bằng tạo lý do: Học giải quyết và giải thích bài toán từ đại số. Trong Kỷ yếu Cuộc họp Hàng năm thứ 55 của Hiệp hội Ngôn ngữ học Tính toán, ACL 2017, Vancouver, Canada, 30 tháng 7 - 4 tháng 8, Tập 1: Bài báo Dài, trang 158–167. Hiệp hội Ngôn ngữ học Tính toán.

Wang Ling, Dani Yogatama, Chris Dyer, và Phil Blunsom. 2017b. Cảm ứng chương trình bằng tạo lý do: Học giải quyết và giải thích bài toán từ đại số. Trong Kỷ yếu Cuộc họp Hàng năm thứ 55 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), trang 158–167, Vancouver, Canada. Hiệp hội Ngôn ngữ học Tính toán.

Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, và Weizhu Chen. 2022a. Điều gì tạo ra các ví dụ trong ngữ cảnh tốt cho gpt-3? Trong Kỷ yếu Deep Learning Inside Out: Hội thảo thứ 3 về Trích xuất và Tích hợp Tri thức cho Kiến trúc Học sâu, DeeLIO@ACL 2022, Dublin, Ireland và Trực tuyến, 27 tháng 5, 2022, trang 100–114. Hiệp hội Ngôn ngữ học Tính toán.

Jiacheng Liu, Skyler Hallinan, Ximing Lu, Pengfei He, Sean Welleck, Hannaneh Hajishirzi, và Yejin Choi. 2022b. Rainier: Người nội quan tri thức được tăng cường cho trả lời câu hỏi thường thức. Trong Kỷ yếu Hội nghị năm 2022 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, trang 8938–8958, Abu Dhabi, Các Tiểu vương quốc Ả Rập Thống nhất. Hiệp hội Ngôn ngữ học Tính toán.

Jiacheng Liu, Alisa Liu, Ximing Lu, Sean Welleck, Peter West, Ronan Le Bras, Yejin Choi, và Hannaneh Hajishirzi. 2022c. Gợi ý tri thức được tạo ra cho lý luận thường thức. Trong Kỷ yếu Cuộc họp Hàng năm thứ 60 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), ACL 2022, Dublin, Ireland, 22-27 tháng 5, 2022, trang 3154–3169. Hiệp hội Ngôn ngữ học Tính toán.

Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, và Graham Neubig. 2022d. Tiền huấn luyện, gợi ý và dự đoán: Một khảo sát có hệ thống về các phương pháp gợi ý trong xử lý ngôn ngữ tự nhiên. ACM Computing Surveys, abs/2107.13586.

Ruibo Liu, Jason Wei, Shixiang Shane Gu, Te-Yen Wu, Soroush Vosoughi, Claire Cui, Denny Zhou, và Andrew M. Dai. 2023. Mắt tâm trí: Lý luận mô hình ngôn ngữ có nền tảng thông qua mô phỏng. Trong Hội nghị Quốc tế thứ Mười một về Đại diện Học tập.

Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, và Ashwin Kalyan. 2022a. Học giải thích: Lý luận đa phương thức thông qua chuỗi suy nghĩ cho trả lời câu hỏi khoa học. CoRR, abs/2209.09513.

Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, và Jianfeng Gao. 2023a. Chameleon: Lý luận tổng hợp plug-and-play với các mô hình ngôn ngữ lớn. CoRR, abs/2304.09842.

Pan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, Tanmay Rajpurohit, Peter Clark, và Ashwin Kalyan. 2023b. Học gợi ý động qua gradient chính sách cho lý luận toán học bán cấu trúc. Trong Hội nghị Quốc tế thứ Mười một về Đại diện Học tập.

Pan Lu, Liang Qiu, Wenhao Yu, Sean Welleck, và Kai-Wei Chang. 2022b. Một khảo sát về học sâu cho lý luận toán học. CoRR, abs/2212.10535.

Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, và Pontus Stenetorp. 2022c. Gợi ý được sắp xếp tuyệt vời và nơi tìm chúng: Vượt qua độ nhạy cảm thứ tự gợi ý few-shot. Trong Kỷ yếu Cuộc họp Hàng năm thứ 60 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), ACL 2022, Dublin, Ireland, 22-27 tháng 5, 2022, trang 8086–8098. Hiệp hội Ngôn ngữ học Tính toán.

Qing Lyu, Shreya Havaldar, Adam Stein, Li Zhang, Delip Rao, Eric Wong, Marianna Apidianaki, và Chris Callison-Burch. 2023. Lý luận chuỗi suy nghĩ trung thực. CoRR, abs/2301.13379.

Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Sean Welleck, Bodhisattwa Prasad Majumder, Shashank Gupta, Amir Yazdanbakhsh, và Peter Clark. 2023. Tự tinh chỉnh: Cải thiện lặp lại với phản hồi tự. CoRR, abs/2303.17651.

Aman Madaan, Shuyan Zhou, Uri Alon, Yiming Yang, và Graham Neubig. 2022. Mô hình ngôn ngữ của mã là người học thường thức few-shot. CoRR, abs/2210.07128.

Lucie Charlotte Magister, Jonathan Mallinson, Jakub Adámek, Eric Malmi, và Aliaksei Severyn. 2022. Dạy các mô hình ngôn ngữ nhỏ lý luận. CoRR, abs/2212.08410.

Christopher D Manning. 2022. Hiểu và lý luận ngôn ngữ con người. Daedalus, 151(2):127–138.

Yuning Mao, Lambert Mathias, Rui Hou, Amjad Almahairi, Hao Ma, Jiawei Han, Scott Yih, và Madian Khabsa. 2022. Unipelt: Một khung thống nhất cho điều chỉnh mô hình ngôn ngữ hiệu quả tham số. Trong Kỷ yếu Cuộc họp Hàng năm thứ 60 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), ACL 2022, Dublin, Ireland, 22-27 tháng 5, 2022, trang 6253–6264. Hiệp hội Ngôn ngữ học Tính toán.

Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ramakanth Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, Edouard Grave, Yann LeCun, và Thomas Scialom. 2023. Mô hình ngôn ngữ tăng cường: một khảo sát. CoRR, abs/2302.07842.

Shen-yun Miao, Chao-Chun Liang, và Keh-Yih Su. 2020. Một kho dữ liệu đa dạng để đánh giá và phát triển các bộ giải quyết bài toán từ toán học tiếng Anh. Trong Kỷ yếu Cuộc họp Hàng năm thứ 58 của Hiệp hội Ngôn ngữ học Tính toán, trang 975–984, Trực tuyến. Hiệp hội Ngôn ngữ học Tính toán.

Todor Mihaylov, Peter Clark, Tushar Khot, và Ashish Sabharwal. 2018. Một bộ áo giáp có thể dẫn điện không? một tập dữ liệu mới cho trả lời câu hỏi sách mở. Trong Kỷ yếu Hội nghị năm 2018 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, trang 2381–2391, Brussels, Belgium. Hiệp hội Ngôn ngữ học Tính toán.

Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, và Luke Zettlemoyer. 2022. Suy nghĩ lại về vai trò của các bản trình diễn: Điều gì làm cho học trong ngữ cảnh hoạt động? CoRR, abs/2202.12837.

Swaroop Mishra, Matthew Finlayson, Pan Lu, Leonard Tang, Sean Welleck, Chitta Baral, Tanmay Rajpurohit, Oyvind Tafjord, Ashish Sabharwal, Peter Clark, và Ashwin Kalyan. 2022a. Lila: Một benchmark thống nhất cho lý luận toán học. CoRR, abs/2210.17517.

Swaroop Mishra, Arindam Mitra, Neeraj Varshney, Bhavdeep Sachdeva, Peter Clark, Chitta Baral, và Ashwin Kalyan. 2022b. NumGLUE: Một bộ các nhiệm vụ lý luận toán học cơ bản nhưng thách thức. Trong Kỷ yếu Cuộc họp Hàng năm thứ 60 của Hiệp hội Ngôn ngữ học Tính toán (Tập 1: Bài báo Dài), trang 3505–3523, Dublin, Ireland. Hiệp hội Ngôn ngữ học Tính toán.

Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, và Christopher D. Manning. 2022a. Chỉnh sửa mô hình nhanh ở quy mô. Trong Hội nghị Quốc tế thứ Mười về Đại diện Học tập, ICLR 2022, Sự kiện Ảo, 25-29 tháng 4, 2022. OpenReview.net.

Eric Mitchell, Charles Lin, Antoine Bosselut, Christopher D. Manning, và Chelsea Finn. 2022b. Chỉnh sửa mô hình dựa trên bộ nhớ ở quy mô. Trong Hội nghị Quốc tế về Học máy, ICML 2022, 17-23 tháng 7, 2022, Baltimore, Maryland, USA, tập 162 của Kỷ yếu Nghiên cứu Học máy, trang 15817–15831. PMLR.

Shima Rahimi Moghaddam và Christopher J. Honey. 2023. Tăng cường hiệu suất lý thuyết tâm trí trong các mô hình ngôn ngữ lớn thông qua gợi ý. CoRR, abs/2304.11490.

Rodrigo Nogueira, Zhiying Jiang, và Jimmy Lin. 2021. Điều tra các hạn chế của transformers với các nhiệm vụ số học đơn giản. CoRR, abs/2102.13019.

OpenAI. 2022. Chatgpt: Tối ưu hóa mô hình ngôn ngữ cho đối thoại. https://openai.com/blog/chatgpt/.

OpenAI. 2023. Báo cáo kỹ thuật GPT-4. CoRR, abs/2303.08774.

Yixin Ou, Shengyu Mao, Lei Li, Ziwen Xu, Xiaolong Weng, Shuofei Qiao, Yuqi Zhu, Yinuo Jiang, Zhen Bi, Jing Chen, Huajun Chen, và Ningyu Zhang. 2023. Easyinstruct: Một khung dễ sử dụng để hướng dẫn các mô hình ngôn ngữ lớn. https://github.com/zjunlp/EasyInstruct.

Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, và Ryan Lowe. 2022. Huấn luyện mô hình ngôn ngữ để tuân theo hướng dẫn với phản hồi của con người. CoRR, abs/2203.02155.

Siru Ouyang, Zhuosheng Zhang, và Hai Zhao. 2021. Lý luận logic dựa trên sự thật. CoRR, abs/2105.10334.

Vaishali Pal, Evangelos Kanoulas, và Maarten de Rijke. 2022. Trả lời câu hỏi trừu tượng hiệu quả tham số trên bảng hoặc văn bản. Trong Kỷ yếu Hội thảo DialDoc thứ hai về Đối thoại dựa trên Tài liệu và Trả lời Câu hỏi Đối thoại, DialDoc@ACL 2022, Dublin, Ireland, 26 tháng 5, 2022, trang 41–53. Hiệp hội Ngôn ngữ học Tính toán.

Bhargavi Paranjape, Scott M. Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, và Marco Túlio Ribeiro. 2023. ART: lý luận đa bước tự động và sử dụng công cụ cho các mô hình ngôn ngữ lớn. CoRR, abs/2303.09014.

Bhargavi Paranjape, Julian Michael, Marjan Ghazvininejad, Hannaneh Hajishirzi, và Luke Zettlemoyer. 2021. Gợi ý giải thích tương phản cho các nhiệm vụ lý luận thường thức. Trong Findings của Hiệp hội Ngôn ngữ học Tính toán: ACL/IJCNLP 2021, Sự kiện Trực tuyến, 1-6 tháng 8, 2021, tập ACL/IJCNLP 2021 của Findings của ACL, trang 4179–4192. Hiệp hội Ngôn ngữ học Tính toán.

Jae Sung Park, Chandra Bhagavatula, Roozbeh Mottaghi, Ali Farhadi, và Yejin Choi. 2020. Visual-comet: Lý luận về ngữ cảnh động của một hình ảnh tĩnh. Trong Computer Vision - ECCV 2020 - Hội nghị Châu Âu thứ 16, Glasgow, UK, 23-28 tháng 8, 2020, Kỷ yếu, Phần V, tập 12350 của Lecture Notes in Computer Science, trang 508–524. Springer.

Arkil Patel, Satwik Bhattamishra, và Navin Goyal. 2021. Mô hình NLP có thực sự giải quyết được bài toán từ toán học đơn giản không? Trong Kỷ yếu Hội nghị năm 2021 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, trang 2080–2094, Trực tuyến. Hiệp hội Ngôn ngữ học Tính toán.

Debjit Paul, Mete Ismayilzada, Maxime Peyrard, Beatriz Borges, Antoine Bosselut, Robert West, và Boi Faltings. 2023. REFINER: phản hồi lý luận trên các đại diện trung gian. CoRR, abs/2304.01904.

Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick S. H. Lewis, Anton Bakhtin, Yuxiang Wu, và Alexander H. Miller. 2019. Mô hình ngôn ngữ như cơ sở tri thức? Trong Kỷ yếu Hội nghị năm 2019 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên và Hội nghị Quốc tế thứ 9 về Xử lý Ngôn ngữ Tự nhiên, EMNLP-IJCNLP 2019, Hong Kong, Trung Quốc, 3-7 tháng 11, 2019, trang 2463–2473. Hiệp hội Ngôn ngữ học Tính toán.

Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A. Smith, và Mike Lewis. 2022. Đo lường và thu hẹp khoảng cách tổ hợp trong mô hình ngôn ngữ. CoRR, abs/2210.03350.

Ben Prystawski và Noah D. Goodman. 2023. Tại sao suy nghĩ từng bước? lý luận xuất hiện từ tính địa phương của kinh nghiệm. CoRR, abs/2304.03843.

Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, Yi Ren Fung, Yusheng Su, Huadong Wang, Cheng Qian, Runchu Tian, Kunlun Zhu, Shihao Liang, Xingyu Shen, Bokai Xu, Zhen Zhang, Yining Ye, Bowen Li, Ziwei Tang, Jing Yi, Yuzhang Zhu, Zhenning Dai, Lan Yan, Xin Cong, Yaxi Lu, Weilin Zhao, Yuxiang Huang, Junxi Yan, Xu Han, Xian Sun, Dahai Li, Jason Phang, Cheng Yang, Tongshuang Wu, Heng Ji, Zhiyuan Liu, và Maosong Sun. 2023. Học công cụ với mô hình nền tảng. CoRR, abs/2304.08354.

Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao, Ning Dai, và Xuanjing Huang. 2020. Mô hình được tiền huấn luyện cho xử lý ngôn ngữ tự nhiên: Một khảo sát. CoRR, abs/2003.08271.

Dheeraj Rajagopal, Vivek Khetan, Bogdan Sacaleanu, Anatole Gershman, Andrew E. Fano, và Eduard H. Hovy. 2021. Lý luận liên miền thông qua điền mẫu. CoRR, abs/2111.00539.

Justin Reppert, Ben Rachbach, Charlie George, Luke Stebbing, JungWon Byun, Maggie Appleton, và Andreas Stuhlmüller. 2023. Phân tách lặp lại: Cải thiện Q&A khoa học bằng cách giám sát các quy trình lý luận. CoRR, abs/2301.01751.

Anna Rohrbach, Lisa Anne Hendricks, Kaylee Burns, Trevor Darrell, và Kate Saenko. 2018. Ảo tưởng đối tượng trong chú thích hình ảnh. Trong Kỷ yếu Hội nghị năm 2018 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, Brussels, Belgium, 31 tháng 10 - 4 tháng 11, 2018, trang 4035–4045. Hiệp hội Ngôn ngữ học Tính toán.

Subhro Roy và Dan Roth. 2015. Giải quyết bài toán từ số học tổng quát. Trong Kỷ yếu Hội nghị năm 2015 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, trang 1743–1752, Lisbon, Portugal. Hiệp hội Ngôn ngữ học Tính toán.

Subhro Roy, Tim Vieira, và Dan Roth. 2015. Lý luận về Lượng trong Ngôn ngữ Tự nhiên. Transactions of the Association for Computational Linguistics, 3:1–13.

Ohad Rubin, Jonathan Herzig, và Jonathan Berant. 2022. Học truy xuất gợi ý cho học trong ngữ cảnh. Trong Kỷ yếu Hội nghị năm 2022 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, NAACL 2022, Seattle, WA, United States, 10-15 tháng 7, 2022, trang 2655–2671. Hiệp hội Ngôn ngữ học Tính toán.

Maarten Sap, Ronan Le Bras, Daniel Fried, và Yejin Choi. 2022. Lý thuyết tâm trí nơ-ron? về giới hạn của trí thông minh xã hội trong các lm lớn. EMNLP, abs/2210.13312.

Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, và Thomas Scialom. 2023. Toolformer: Mô hình ngôn ngữ có thể tự dạy mình sử dụng công cụ. CoRR, abs/2302.04761.

John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, và Oleg Klimov. 2017. Thuật toán tối ưu hóa chính sách gần. CoRR, abs/1707.06347.

Omar Shaikh, Hongxin Zhang, William Held, Michael Bernstein, và Diyi Yang. 2022. Suy nghĩ lại, đừng suy nghĩ từng bước! thiên vị và độc tính trong lý luận zero-shot. CoRR, abs/2212.08061.

Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, và Weizhu Chen. 2023. Gợi ý tổng hợp: Tạo ra các bản trình diễn chuỗi suy nghĩ cho các mô hình ngôn ngữ lớn. CoRR, abs/2302.00618.

Natalie Shapira, Mosh Levy, Seyed Hossein Alavi, Xuhui Zhou, Yejin Choi, Yoav Goldberg, Maarten Sap, và Vered Shwartz. 2023. Clever hans hay lý thuyết tâm trí nơ-ron? kiểm tra căng thẳng lý luận xã hội trong các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2305.14763.

Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won Chung, Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, và Jason Wei. 2022. Mô hình ngôn ngữ là người lý luận chuỗi suy nghĩ đa ngôn ngữ. CoRR, abs/2210.03057.

Noah Shinn, Beck Labash, và Ashwin Gopinath. 2023. Reflexion: một tác nhân tự chủ với bộ nhớ động và tự phản ánh. CoRR, abs/2303.11366.

Kumar Shridhar, Alessandro Stolfo, và Mrinmaya Sachan. 2022. Chưng cất khả năng lý luận đa bước của các mô hình ngôn ngữ lớn thành các mô hình nhỏ hơn thông qua phân tách ngữ nghĩa. CoRR, abs/2212.00193.

Kashun Shum, Shizhe Diao, và Tong Zhang. 2023. Tăng cường và lựa chọn gợi ý tự động với chuỗi suy nghĩ từ dữ liệu được ghi nhãn. CoRR, abs/2302.12822.

Koustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau, và William L. Hamilton. 2019. CLUTRR: Một benchmark chẩn đoán cho lý luận quy nạp từ văn bản. Trong Kỷ yếu Hội nghị năm 2019 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên và Hội nghị Quốc tế thứ 9 về Xử lý Ngôn ngữ Tự nhiên (EMNLP-IJCNLP), trang 4506–4515, Hong Kong, Trung Quốc. Hiệp hội Ngôn ngữ học Tính toán.

Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R. Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea Power, Alex Ray, Alex Warstadt, Alexander W. Kocurek, Ali Safaya, Ali Tazarv, Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda Dsouza, Ameet Rahane, Anantharaman S. Iyer, Anders Andreassen, Andrea Santilli, Andreas Stuhlmüller, Andrew M. Dai, Andrew La, Andrew K. Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong, Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla Karakas, và et al. 2022. Vượt ra ngoài trò chơi bắt chước: Định lượng và ngoại suy khả năng của mô hình ngôn ngữ. CoRR, abs/2206.04615.

Shane Storks, Qiaozi Gao, và Joyce Y. Chai. 2019. Lý luận thường thức cho hiểu ngôn ngữ tự nhiên: Một khảo sát về benchmark, tài nguyên và cách tiếp cận. CoRR, abs/1904.01172.

Hongjin SU, Jungo Kasai, Chen Henry Wu, Weijia Shi, Tianlu Wang, Jiayi Xin, Rui Zhang, Mari Ostendorf, Luke Zettlemoyer, Noah A. Smith, và Tao Yu. 2023. Chú thích có chọn lọc làm cho mô hình ngôn ngữ trở thành người học few-shot tốt hơn. Trong Hội nghị Quốc tế thứ Mười một về Đại diện Học tập.

Yueqing Sun, Yu Zhang, Le Qi, và Qi Shi. 2022. TSGP: Gợi ý tạo ra hai giai đoạn cho trả lời câu hỏi thường thức không giám sát. Trong Findings của Hiệp hội Ngôn ngữ học Tính toán: EMNLP 2022, trang 968–980, Abu Dhabi, Các Tiểu vương quốc Ả Rập Thống nhất. Hiệp hội Ngôn ngữ học Tính toán.

Dídac Surís, Sachit Menon, và Carl Vondrick. 2023. Vipergpt: Suy luận thị giác thông qua thực thi python để lý luận. CoRR, abs/2303.08128.

Oyvind Tafjord, Bhavana Dalvi, và Peter Clark. 2021. ProofWriter: Tạo ra hàm ý, chứng minh và câu lệnh khấu thoái trên ngôn ngữ tự nhiên. Trong Findings của Hiệp hội Ngôn ngữ học Tính toán: ACL-IJCNLP 2021, trang 3621–3634, Trực tuyến. Hiệp hội Ngôn ngữ học Tính toán.

Alon Talmor, Jonathan Herzig, Nicholas Lourie, và Jonathan Berant. 2019. Commonsenseqa: Một thách thức trả lời câu hỏi nhắm mục tiêu tri thức thường thức. Trong Kỷ yếu Hội nghị năm 2019 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, NAACL-HLT 2019, Minneapolis, MN, USA, 2-7 tháng 6, 2019, Tập 1 (Bài báo Dài và Ngắn), trang 4149–4158. Hiệp hội Ngôn ngữ học Tính toán.

Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Kathleen S. Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak, Ed H. Chi, và Quoc Le. 2022. Lamda: Mô hình ngôn ngữ cho ứng dụng đối thoại. CoRR, abs/2201.08239.

Emanuel Todorov, Tom Erez, và Yuval Tassa. 2012. Mujoco: Một công cụ vật lý cho điều khiển dựa trên mô hình. Trong Hội nghị Quốc tế IEEE/RSJ năm 2012 về Robot Thông minh và Hệ thống, IROS 2012, Vilamoura, Algarve, Portugal, 7-12 tháng 10, 2012, trang 5026–5033. IEEE.

Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, và Ashish Sabharwal. 2022. Xen kẽ truy xuất với lý luận chuỗi suy nghĩ cho các câu hỏi đa bước chuyên sâu tri thức. CoRR, abs/2212.10509.

Boshi Wang, Xiang Deng, và Huan Sun. 2022a. Gợi ý lặp lại các mô hình ngôn ngữ được tiền huấn luyện cho chuỗi suy nghĩ. CoRR, abs/2203.08383.

PeiFeng Wang, Aaron Chan, Filip Ilievski, Muhao Chen, và Xiang Ren. 2023. PINTO: Lý luận ngôn ngữ trung thực sử dụng lý do được tạo ra bởi gợi ý. Trong Hội nghị Quốc tế thứ Mười một về Đại diện Học tập.

Siyuan Wang, Zhongkun Liu, Wanjun Zhong, Ming Zhou, Zhongyu Wei, Zhumin Chen, và Nan Duan. 2021. Từ LSAT: tiến bộ và thách thức của lý luận phức tạp. CoRR, abs/2108.00648.

Xiaozhi Wang, Kaiyue Wen, Zhengyan Zhang, Lei Hou, Zhiyuan Liu, và Juanzi Li. 2022b. Tìm nơ-ron kỹ năng trong mô hình ngôn ngữ dựa trên transformer được tiền huấn luyện. CoRR, abs/2211.07349.

Xingyao Wang, Sha Li, và Heng Ji. 2022c. Code4struct: Tạo mã cho dự đoán có cấu trúc few-shot từ ngôn ngữ tự nhiên. CoRR, abs/2210.12810.

Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Ed H. Chi, và Denny Zhou. 2022d. Tập hợp tăng cường lý do trong mô hình ngôn ngữ. CoRR, abs/2207.00747.

Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Ed H. Chi, và Denny Zhou. 2022e. Tự nhất quán cải thiện lý luận chuỗi suy nghĩ trong mô hình ngôn ngữ. CoRR, abs/2203.11171.

Yan Wang, Xiaojiang Liu, và Shuming Shi. 2017. Bộ giải quyết nơ-ron sâu cho bài toán từ toán học. Trong Kỷ yếu Hội nghị năm 2017 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, trang 845–854, Copenhagen, Denmark. Hiệp hội Ngôn ngữ học Tính toán.

Taylor W. Webb, Keith J. Holyoak, và Hongjing Lu. 2022. Lý luận tương tự nổi lên trong các mô hình ngôn ngữ lớn. CoRR, abs/2212.09196.

Albert Webson và Ellie Pavlick. 2022. Mô hình dựa trên gợi ý có thực sự hiểu ý nghĩa của gợi ý của chúng không? Trong Kỷ yếu Hội nghị năm 2022 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, NAACL 2022, Seattle, WA, United States, 10-15 tháng 7, 2022, trang 2300–2344. Hiệp hội Ngôn ngữ học Tính toán.

Colin Wei, Sang Michael Xie, và Tengyu Ma. 2021. Tại sao mô hình ngôn ngữ được tiền huấn luyện giúp ích trong các nhiệm vụ downstream? một phân tích về điều chỉnh đầu và gợi ý. Trong Tiến bộ trong Hệ thống Xử lý Thông tin Nơ-ron 34: Hội nghị Hàng năm về Hệ thống Xử lý Thông tin Nơ-ron 2021, NeurIPS 2021, 6-14 tháng 12, 2021, ảo, trang 16158–16170.

Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, và William Fedus. 2022a. Khả năng nổi lên của mô hình ngôn ngữ lớn. Transactions on Machine Learning Research. Survey Certification.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H. Chi, Quoc Le, và Denny Zhou. 2022b. Gợi ý chuỗi suy nghĩ gợi ra lý luận trong mô hình ngôn ngữ lớn. Trong Tiến bộ trong Hệ thống Xử lý Thông tin Nơ-ron 35: Hội nghị Hàng năm về Hệ thống Xử lý Thông tin Nơ-ron 2022, NeurIPS 2022, 6-14 tháng 12, 2022, ảo.

Yixuan Weng, Minjun Zhu, Shizhu He, Kang Liu, và Jun Zhao. 2022. Mô hình ngôn ngữ lớn là người lý luận với tự xác minh. CoRR, abs/2212.09561.

Sarah Wiegreffe, Jack Hessel, Swabha Swayamdipta, Mark O. Riedl, và Yejin Choi. 2022. Định khung lại sự hợp tác người-ai để tạo ra giải thích văn bản tự do. Trong Kỷ yếu Hội nghị năm 2022 của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán: Công nghệ Ngôn ngữ Con người, NAACL 2022, Seattle, WA, United States, 10-15 tháng 7, 2022, trang 632–658. Hiệp hội Ngôn ngữ học Tính toán.

Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, và Nan Duan. 2023. Visual chatgpt: Nói chuyện, vẽ và chỉnh sửa với mô hình nền tảng thị giác. CoRR, abs/2303.04671.

Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, và Carrie J. Cai. 2022a. Promptchainer: Chuỗi gợi ý mô hình ngôn ngữ lớn thông qua lập trình thị giác. Trong CHI '22: Hội nghị CHI về Yếu tố Con người trong Hệ thống Tính toán, New Orleans, LA, USA, 29 tháng 4, 2022 - 5 tháng 5, 2022, Extended Abstracts, trang 359:1–359:10. ACM.

Yuhuai Wu, Albert Q. Jiang, Wenda Li, Markus N. Rabe, Charles Staats, Mateja Jamnik, và Christian Szegedy. 2022b. Autoformalization với mô hình ngôn ngữ lớn. CoRR, abs/2205.12615.

Sang Michael Xie, Aditi Raghunathan, Percy Liang, và Tengyu Ma. 2022. Một giải thích về học trong ngữ cảnh như suy luận bayesian ẩn. Trong Hội nghị Quốc tế thứ Mười về Đại diện Học tập, ICLR 2022, Sự kiện Ảo, 25-29 tháng 4, 2022. OpenReview.net.

Frank F. Xu, Uri Alon, Graham Neubig, và Vincent Josua Hellendoorn. 2022. Một đánh giá có hệ thống về mô hình ngôn ngữ lớn của mã. Trong MAPS@PLDI 2022: Hội nghị Quốc tế thứ 6 của ACM SIGPLAN về Lập trình Máy, San Diego, CA, USA, 13 tháng 6, 2022, trang 1–10. ACM.

Jingjing Xu, Wangchunshu Zhou, Zhiyi Fu, Hao Zhou, và Lei Li. 2021. Một khảo sát về học sâu xanh. CoRR, abs/2111.05193.

Jingfeng Yang, Haoming Jiang, Qingyu Yin, Danqing Zhang, Bing Yin, và Diyi Yang. 2022a. SEQZERO: phân tích ngữ nghĩa tổng hợp few-shot với gợi ý tuần tự và mô hình zero-shot. Trong Findings của Hiệp hội Ngôn ngữ học Tính toán: NAACL 2022, Seattle, WA, United States, 10-15 tháng 7, 2022, trang 49–60. Hiệp hội Ngôn ngữ học Tính toán.

Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Ehsan Azarnasab, Faisal Ahmed, Zicheng Liu, Ce Liu, Michael Zeng, và Lijuan Wang. 2023. MM-REACT: gợi ý chatgpt cho lý luận và hành động đa phương thức. CoRR, abs/2303.11381.

Zhicheng Yang, Jinghui Qin, Jiaqi Chen, Liang Lin, và Xiaodan Liang. 2022b. LogicSolver: Hướng tới giải quyết bài toán từ toán học có thể diễn giải với học tăng cường gợi ý logic. Trong Findings của Hiệp hội Ngôn ngữ học Tính toán: EMNLP 2022, trang 1–13, Abu Dhabi, Các Tiểu vương quốc Ả Rập Thống nhất. Hiệp hội Ngôn ngữ học Tính toán.

Zonglin Yang, Li Dong, Xinya Du, Hao Cheng, Erik Cambria, Xiaodong Liu, Jianfeng Gao, và Furu Wei. 2022c. Mô hình ngôn ngữ như người lý luận quy nạp. CoRR, abs/2212.10923.

Fu Yao, Peng Hao, và Khot Tushar. 2022. GPT có được khả năng của nó như thế nào? truy tìm khả năng nổi lên của mô hình ngôn ngữ đến nguồn của chúng. Yao Fu's Notion.

Xi Ye và Greg Durrett. 2022. Sự không đáng tin cậy của giải thích trong gợi ý few-shot cho lý luận văn bản. Trong Tiến bộ trong Hệ thống Xử lý Thông tin Nơ-ron.

Yunhu Ye, Binyuan Hui, Min Yang, Binhua Li, Fei Huang, và Yongbin Li. 2023. Mô hình ngôn ngữ lớn là bộ phân tách đa năng: Phân tách bằng chứng và câu hỏi cho lý luận dựa trên bảng. CoRR, abs/2301.13808.

Ori Yoran, Tomer Wolfson, Ben Bogin, Uri Katz, Daniel Deutch, và Jonathan Berant. 2023. Trả lời câu hỏi bằng meta-lý luận trên nhiều chuỗi suy nghĩ.

Nathan Young, Qiming Bao, Joshua Bensemann, và Michael Witbrock. 2022. Abductionrules: Huấn luyện transformer để giải thích đầu vào bất ngờ. Trong Findings của Hiệp hội Ngôn ngữ học Tính toán: ACL 2022, Dublin, Ireland, 22-27 tháng 5, 2022, trang 218–227. Hiệp hội Ngôn ngữ học Tính toán.

Ping Yu, Tianlu Wang, Olga Golovneva, Badr AlKhamissy, Gargi Ghosh, Mona T. Diab, và Asli Celikyilmaz. 2022. ALERT: thích ứng mô hình ngôn ngữ với các nhiệm vụ lý luận. CoRR, abs/2212.08286.

Weizhe Yuan và Pengfei Liu. 2022. tiền huấn luyện được cấu trúc lại. CoRR, abs/2206.11147.

Eric Zelikman, Yuhuai Wu, Jesse Mu, và Noah Goodman. 2022. STar: Bootstrap lý luận với lý luận. Trong Tiến bộ trong Hệ thống Xử lý Thông tin Nơ-ron.

Rowan Zellers, Yonatan Bisk, Ali Farhadi, và Yejin Choi. 2019. Từ nhận dạng đến nhận thức: Lý luận thường thức thị giác. Trong Hội nghị IEEE về Thị giác Máy tính và Nhận dạng Mẫu, CVPR 2019, Long Beach, CA, USA, 16-20 tháng 6, 2019, trang 6720–6731. Computer Vision Foundation / IEEE.

Hanlin Zhang, YiFan Zhang, Li Erran Li, và Eric Xing. 2022. Tác động của đại diện tượng trưng đối với học trong ngữ cảnh cho lý luận few-shot. Trong Hội thảo NeurIPS 2022 về AI Nơ-ron Nhân quả và Tượng trưng (nCSI).

Ningyu Zhang, Lei Li, Xiang Chen, Xiaozhuan Liang, Shumin Deng, và Huajun Chen. 2023a. Lý luận tương tự đa phương thức trên đồ thị tri thức. Trong Hội nghị Quốc tế thứ Mười một về Đại diện Học tập.

Zhuosheng Zhang, Aston Zhang, Mu Li, và Alex Smola. 2023b. Gợi ý chuỗi suy nghĩ tự động trong mô hình ngôn ngữ lớn. Trong Hội nghị Quốc tế thứ Mười một về Đại diện Học tập.

Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, và Alex Smola. 2023c. Lý luận chuỗi suy nghĩ đa phương thức trong mô hình ngôn ngữ. CoRR, abs/2302.00923.

Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, và Ji-Rong Wen. 2023. Một khảo sát về mô hình ngôn ngữ lớn. CoRR, abs/2303.18223.

Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V Le, và Ed H. Chi. 2023. Gợi ý từ ít nhất đến nhiều nhất cho phép lý luận phức tạp trong mô hình ngôn ngữ lớn. Trong Hội nghị Quốc tế thứ Mười một về Đại diện Học tập.

Hattie Zhou, Azade Nova, Hugo Larochelle, Aaron C. Courville, Behnam Neyshabur, và Hanie Sedghi. 2022a. Dạy lý luận thuật toán thông qua học trong ngữ cảnh. CoRR, abs/2211.09066.

Pei Zhou, Andrew Zhu, Jennifer Hu, Jay Pujara, Xiang Ren, Chris Callison-Burch, Yejin Choi, và Prithviraj Ammanabrolu. 2022b. Hướng dẫn chủ dungeons đại sư AI: Học đối thoại và hướng dẫn với ý định và lý thuyết tâm trí trong dungeons and dragons. CoRR, abs/2212.10060.

A Phụ lục
A.1 Khảo sát Liên quan
Vì lĩnh vực này tương đối mới, chỉ có một số ít khảo sát tồn tại. Gần nhất với công việc của chúng tôi, Huang and Chang (2022) đưa ra một khảo sát hướng tới lý luận với mô hình ngôn ngữ lớn. Dong et al. (2023) tổ chức và thảo luận các kỹ thuật tiên tiến của học trong ngữ cảnh. Zhao et al. (2023) xem xét những tiến bộ mới nhất trong Mô hình Ngôn ngữ Lớn (LLMs) và đi sâu vào các thách thức chưa được giải quyết sẽ định hình sự phát triển tương lai. Bhargava and Ng (2022) bao gồm các phương pháp cho lý luận và tạo ra tri thức thường thức với LMs được tiền huấn luyện. Lu et al. (2022b) xem xét các nhiệm vụ, tập dữ liệu và phương pháp chính tại giao điểm của lý luận toán học và học sâu trong thập kỷ qua. Liang et al. (2022a) khảo sát lý luận đồ thị tri thức truy tìm từ tĩnh đến tạm thời và sau đó đến đồ thị tri thức đa phương thức. Mialon et al. (2023) xem xét các công trình trong đó mô hình ngôn ngữ (LMs) được tăng cường với kỹ năng lý luận và khả năng sử dụng công cụ. Hamilton et al. (2022) tiến hành một khảo sát về các nghiên cứu thực hiện các cách tiếp cận NLP nơ-ron-tượng trưng (NeSy) cho lý luận và vân vân. Guo et al. (2022) cung cấp một khảo sát về một số công trình phổ biến xử lý lý luận không chắc chắn. Qin et al. (2023) tập trung vào việc tận dụng các công cụ bên ngoài bởi LLMs cũng được gọi là Học Công cụ. Các khảo sát khác tập trung vào học gợi ý (Liu et al., 2022d) hoặc mô hình được tiền huấn luyện (Qiu et al., 2020; Du et al., 2022) cũng liên quan đến công việc của chúng tôi.

Khác với những khảo sát đó, trong bài báo này, chúng tôi tiến hành một đánh giá về lý luận với gợi ý LM, hy vọng hiểu một cách có hệ thống các phương pháp, so sánh các phương pháp khác nhau và truyền cảm hứng cho những ý tưởng mới.

A.2 Phân loại Phương pháp và Nhiệm vụ
Chúng tôi liệt kê phân loại hoàn chỉnh về lý luận với gợi ý mô hình ngôn ngữ từ phương pháp và nhiệm vụ trong Hình 8.

A.3 So sánh Hiệu suất của LMs với Các Quy mô Khác nhau
Để thể hiện tính tổng quát của các thảo luận trong §4.1 trên các nhiệm vụ lý luận khác nhau, chúng tôi bổ sung thể hiện so sánh hiệu suất của LMs với các quy mô khác nhau trên CommonsenseQA (Talmor et al., 2019) của lý luận thường thức trong Hình 9.

A.4 Thông tin Chi tiết về Benchmarks Lý luận
Trong § 5, chúng tôi đưa ra tổng quan ngắn gọn về benchmark và nhiệm vụ đòi hỏi các kỹ năng lý luận khác nhau. Chúng tôi liệt kê thêm các benchmark và thể hiện thống kê chính của chúng trong Bảng 2. Ngoài các nhiệm vụ lý luận cụ thể được đề cập ở trên trong § 5, có một số benchmark (Lake and Baroni, 2017; Srivastava et al., 2022; Yu et al., 2022) có thể đánh giá khả năng lý luận đa dạng và tổng quát hóa hơn của mô hình, cũng có thể được đưa vào danh mục các nhiệm vụ lý luận.

A.5 Lý luận với ChatGPT
Gần đây, OpenAI (2022) phát triển ChatGPT, một hệ thống chatbot AI đã thu hút người dùng khổng lồ. ChatGPT được huấn luyện trên một tập dữ liệu văn bản lớn và có thể tạo ra các phản hồi giống con người cho nhiều loại gợi ý khác nhau, cách tiếp cận đầy hứa hẹn được gọi là Học Tăng cường từ Phản hồi Con người (Ouyang et al., 2022). Xương sống của ChatGPT là từ một mô hình trong dòng LM lớn GPT-3.58. Để thưởng thức khả năng lý luận của LMs lớn một cách thực tế hơn, chúng tôi tiến hành một số thử nghiệm trường hợp trên ChatGPT. Cụ thể, chúng tôi chọn ra một phần dữ liệu từ GSM8K (Cobbe et al., 2021), CommonsenseQA (Talmor et al., 2019) và Last Letter Concatenation (Wei et al., 2022b) lần lượt đại diện cho lý luận số học, lý luận thường thức và lý luận tượng trưng. Sau đó chúng tôi kiểm tra từng dữ liệu được chọn trên ChatGPT trực tiếp. Kết quả có thể được thấy trong Hình 10-12.

Hình 10 cho thấy rằng cho một bài toán toán học trong GSM8K (Cobbe et al., 2021), ChatGPT đưa ra một quy trình lý luận và một câu trả lời đúng mà không cần các mẫu trong ngữ cảnh. Điều này khẳng định khả năng lý luận số học mạnh mẽ của nó. Quy trình lý luận có cùng định dạng với nhãn vàng trong GSM8K, cho thấy rằng GSM8K có thể được chứa trong kho dữ liệu huấn luyện của ChatGPT.

Trong Hình 11, chúng tôi kiểm tra ChatGPT trên một phần dữ liệu trong CommsonsenseQA (Talmor et al., 2019). Nó không chỉ đưa ra câu trả lời đúng mà còn chi tiết tại sao mỗi tùy chọn đúng hoặc sai, điều này không xuất hiện trong nhãn vàng của tập dữ liệu. Điều này chứng minh khả năng lý luận thường thức mạnh mẽ của ChatGPT.

Hình 12 là một trường hợp trong Last Letter Concatenation (Wei et al., 2022b). Chúng tôi quan sát thấy rằng mặc dù ChatGPT đưa ra mô tả chi tiết và chính xác về nối chữ cái cuối, nó thất bại trong việc trả lời câu hỏi đã cho, cho thấy rằng khả năng lý luận tượng trưng của nó không xuất sắc như hai khả năng trên.

A.6 Lý luận sử dụng EasyInstruct

405060708090
GPT3-CoT
Codex-CoT
LaMDA-68B-CoT
LaMDA-137B-CoT
PaLM-62B-CoT

Độ chính xác CSQA(%)

Quy mô mô hình
540B
175B
62B

PaLM-540B-CoT

Hình 9: Hiệu suất của các quy mô mô hình ngôn ngữ khác nhau trên lý luận thường thức. Đại diện, chúng tôi thể hiện kết quả thực nghiệm CoT (Wei et al., 2022b) trên CommonsenseQA (Talmor et al., 2019).

--- TRANG 23 ---
Hình 10: Một trường hợp thử nghiệm từ GSM8K (Cobbe et al., 2021) trên ChatGPT (OpenAI, 2022).

Hình 11: Một trường hợp thử nghiệm từ CommonsenseQA (Talmor et al., 2019) trên ChatGPT (OpenAI, 2022).

Hình 12: Một trường hợp thử nghiệm từ Last Letter Concatenation (Wei et al., 2022b) trên ChatGPT (OpenAI, 2022).

Hình 13: Một trường hợp thử nghiệm từ GSM8K (Cobbe et al., 2021) sử dụng EasyInstruct (Ou et al., 2023).

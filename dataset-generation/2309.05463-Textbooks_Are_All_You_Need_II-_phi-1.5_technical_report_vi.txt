# 2309.05463.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/dataset-generation/2309.05463.pdf
# Kích thước tệp: 387559 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Sách giáo khoa là tất cả những gì bạn cần II: báo cáo kỹ thuật phi-1.5
Yuanzhi Li Sébastien Bubeck Ronen Eldan Allie Del Giorno
Suriya Gunasekar Yin Tat Lee
Microsoft Research

Tóm tắt
Chúng tôi tiếp tục nghiên cứu về sức mạnh của các mô hình ngôn ngữ Transformer nhỏ hơn như đã khởi xướng bởi TinyStories – một mô hình 10 triệu tham số có thể tạo ra tiếng Anh mạch lạc – và công trình tiếp theo về phi-1, một mô hình 1.3 tỷ tham số với hiệu suất lập trình Python gần đạt tới mức nghệ thuật hiện đại. Công trình sau đó đề xuất sử dụng các Mô hình Ngôn ngữ Lớn (LLM) hiện có để tạo ra dữ liệu "chất lượng sách giáo khoa" như một cách để tăng cường quá trình học tập so với dữ liệu web truyền thống. Chúng tôi tuân theo phương pháp "Sách giáo khoa là tất cả những gì bạn cần", lần này tập trung vào lý luận thông thường trong ngôn ngữ tự nhiên, và tạo ra một mô hình mới 1.3 tỷ tham số có tên phi-1.5, với hiệu suất trên các tác vụ ngôn ngữ tự nhiên có thể so sánh với các mô hình lớn gấp 5 lần, và vượt qua hầu hết các LLM không phải tiên phong trên các tác vụ lý luận phức tạp hơn như toán học tiểu học và lập trình cơ bản. Tổng quát hơn, phi-1.5 thể hiện nhiều đặc điểm của các LLM lớn hơn nhiều, cả tốt –như khả năng "suy nghĩ từng bước" hoặc thực hiện một số học tập trong ngữ cảnh cơ bản– và xấu, bao gồm ảo giác và tiềm năng tạo ra nội dung độc hại và thiên vị –tuy nhiên đáng khích lệ là chúng ta đang thấy cải thiện về mặt đó nhờ vào việc không có dữ liệu web. Chúng tôi mở mã nguồn phi-1.5 để thúc đẩy nghiên cứu thêm về những chủ đề cấp bách này.

[Các biểu đồ và số liệu so sánh hiệu suất giữa phi-1.5 và các mô hình khác]

Hình 1: Kết quả đánh giá so sánh phi-1.5, phiên bản được tăng cường với dữ liệu web đã lọc phi-1.5-web, và các LLM mã nguồn mở tiên tiến khác. Kích thước dao động từ 1.3 tỷ tham số của phi-1.5 (Falcon-RW-1.3B [PMH+23]) đến các mô hình lớn gấp 10 lần như Vicuna-13B [ZCS+23], một phiên bản tinh chỉnh của Llama-13B [TLI+23]). Các đánh giá được phân loại rộng rãi thành ba danh mục: lý luận thông thường, kỹ năng ngôn ngữ, và lý luận nhiều bước. Việc phân loại được hiểu một cách lỏng lẻo, ví dụ trong khi HellaSwag yêu cầu lý luận thông thường, nó có thể dựa nhiều hơn vào "kiến thức đã ghi nhớ". Có thể thấy rằng các mô hình phi-1.5 thực hiện tương đương trong lý luận thông thường và kỹ năng ngôn ngữ, và vượt xa các mô hình khác trong lý luận nhiều bước. Lưu ý rằng các con số đến từ pipeline đánh giá của chúng tôi, để đảm bảo tính nhất quán giữa các mô hình, và do đó chúng có thể khác một chút so với các con số được báo cáo ở nơi khác.

--- TRANG 2 ---
1 Giới thiệu
Trong vài năm qua, các Mô hình Ngôn ngữ Lớn (LLM) đã thay đổi lĩnh vực Xử lý Ngôn ngữ Tự nhiên. Rộng hơn, chúng mang lại lời hứa về sự thay đổi mô hình cho tương tác người-máy tính. Những tiến bộ này có ý nghĩa kinh tế sâu rộng, cũng như tiềm năng để định nghĩa lại khung khái niệm của chúng ta về trí tuệ nhân tạo và có lẽ cả nhận thức. Hơn nữa, thế hệ mô hình mới nhất như GPT-4 [Ope23] đã thể hiện những cải tiến đáng kể so với các mô hình tiền nhiệm, cung cấp các khả năng trước đây được cho là không thể đạt được trong thời gian ngắn; xem ví dụ [BCE+23] để có so sánh chi tiết giữa GPT-4 và mô hình tiền nhiệm GPT-3.5.

Sự cải tiến từ thế hệ LLM này sang thế hệ tiếp theo dường như hiện tại chủ yếu đến từ quy mô, với các mô hình mạnh nhất gần đạt hàng nghìn tỷ tham số và nghìn tỷ token cho dữ liệu huấn luyện (ví dụ, PaLM [CND+22] có 540 tỷ tham số và được huấn luyện trên 780 tỷ token). Một câu hỏi tự nhiên nảy sinh: Liệu quy mô lớn này có không thể thiếu để đạt được mức độ khả năng cao? Xa hơn việc chỉ là một câu hỏi học thuật, việc trả lời điều này có ý nghĩa qua nhiều khía cạnh. Về mặt kinh tế, chi phí huấn luyện, triển khai và duy trì các mô hình lớn như vậy có thể đáng kể. Về mặt khoa học, việc hiểu liệu các khả năng tương tự có thể đạt được ở quy mô nhỏ hơn có thể cung cấp cái nhìn về kiến trúc và phát triển các hệ thống thông minh. Từ quan điểm AI có trách nhiệm, mức tiêu thụ năng lượng của các mô hình quy mô lớn đang trở thành mối quan tâm ngày càng tăng, cũng như câu hỏi về mức độ có thể kiểm soát hoặc quản lý các mô hình lớn này. Cuối cùng, khả năng huấn luyện các mô hình nhỏ gọn với khả năng tiên tiến sẽ dân chủ hóa AI tiên tiến, cho phép một phạm vi rộng hơn các cá nhân và tổ chức nghiên cứu và triển khai chúng, thay vì là lĩnh vực độc quyền của một số ít người có tài nguyên tính toán khổng lồ.

Trong công trình này, chúng tôi tiếp tục nghiên cứu câu hỏi cơ bản "một LLM có thể nhỏ đến mức nào để đạt được các khả năng nhất định". Công trình trước đó [EL23] xem xét câu hỏi này cho tác vụ "nói tiếng Anh lưu loát", trong khi công trình tiếp theo [GZA+23] xem xét tác vụ thách thức hơn là lập trình các hàm đơn giản trong Python. Ở đây chúng tôi tập trung vào khái niệm khó nắm bắt hơn của lý luận thông thường, một tác vụ nổi tiếng thách thức cho AI [SBBC21]. Kết quả của chúng tôi được tóm tắt trong Hình 1. Tóm lại, chúng tôi xây dựng phi-1.5, một mô hình 1.3 tỷ tham số được huấn luyện trên bộ dữ liệu 30 tỷ token, đạt được kết quả đánh giá lý luận thông thường có thể so sánh với các mô hình lớn gấp mười lần được huấn luyện trên bộ dữ liệu lớn hơn mười lần. Hơn nữa, bộ dữ liệu của chúng tôi gần như hoàn toàn bao gồm dữ liệu được tạo tổng hợp (tuân theo chặt chẽ phương pháp từ [GZA+23], xem phần tiếp theo để biết thêm chi tiết), điều này có ý nghĩa quan trọng cho tiềm năng kiểm soát vấn đề nổi tiếng thách thức về tạo nội dung độc hại và thiên vị với LLM [BGMMS21]. Ngoài ra, chúng tôi thảo luận về hiệu suất của phiên bản dữ liệu web đã lọc tăng cường liên quan của phi-1.5, mà chúng tôi gọi là phi-1.5-web.

Chúng tôi mở mã nguồn mô hình phi-1.5 thô của chúng tôi (không có tinh chỉnh hướng dẫn hoặc bất kỳ giai đoạn căn chỉnh nào khác) để trao quyền cho cộng đồng nghiên cứu trong công việc về một số câu hỏi cấp bách nhất xung quanh LLM: học tập trong ngữ cảnh, khả năng diễn giải cơ chế, và các chiến lược giảm thiểu cho ảo giác, tạo nội dung độc hại, và đầu ra thiên vị. Thật vậy, phi-1.5 là LLM đầu tiên ở quy mô một tỷ tham số thể hiện hầu hết các đặc điểm liên quan của các LLM lớn hơn cho nghiên cứu về những chủ đề này. Chúng tôi hy vọng rằng kích thước của phi-1.5 sẽ làm cho việc thử nghiệm dễ dàng hơn so với các mô hình mã nguồn mở lớn hơn như họ Llama [TLI+23].

[Bảng so sánh thời gian huấn luyện, tốc độ suy luận và bộ nhớ]

--- TRANG 3 ---
2 Thông số kỹ thuật
Chúng tôi đưa ra chi tiết về việc tạo ra phi-1.5. Chúng tôi cũng mô tả hai mô hình khác được tạo ra để nghiên cứu giá trị của dữ liệu web so với dữ liệu tổng hợp của chúng tôi, phi-1.5-web-only và phi-1.5-web.

2.1 Kiến trúc
Kiến trúc cho phi-1.5 (và các biến thể của nó) hoàn toàn giống với mô hình phi-1 trước đó của chúng tôi trong [GZA+23]. Đây là một Transformer [VSP+17] với 24 lớp, 32 đầu, và mỗi đầu có chiều 64. Chúng tôi sử dụng nhúng xoay với chiều xoay 32, và độ dài ngữ cảnh 2048. Chúng tôi cũng sử dụng flash-attention [DFE+22, Dao23] để tăng tốc huấn luyện, và chúng tôi sử dụng tokenizer của codegen-mono [NPH+22].

2.2 Dữ liệu huấn luyện
Dữ liệu huấn luyện của chúng tôi cho phi-1.5 là sự kết hợp của dữ liệu huấn luyện phi-1 (7B token) và dữ liệu tổng hợp mới được tạo, "giống sách giáo khoa" (khoảng 20B token) nhằm mục đích dạy lý luận thông thường và kiến thức chung về thế giới (khoa học, hoạt động hàng ngày, lý thuyết tâm trí, v.v.). Chúng tôi cẩn thận chọn lọc 20K chủ đề để tạo ra dữ liệu tổng hợp mới này. Trong các prompt tạo của chúng tôi, chúng tôi sử dụng các mẫu từ bộ dữ liệu web để có sự đa dạng. Chúng tôi chỉ ra rằng phần không tổng hợp duy nhất trong dữ liệu huấn luyện của chúng tôi cho phi-1.5 bao gồm 6B token của bộ dữ liệu mã đã lọc được sử dụng trong huấn luyện phi-1 (xem [GZA+23]).

Chúng tôi nhận xét rằng kinh nghiệm thu được trong quá trình tạo dữ liệu huấn luyện cho cả phi-1 và phi-1.5 dẫn chúng tôi đến kết luận rằng việc tạo ra một bộ dữ liệu mạnh mẽ và toàn diện đòi hỏi nhiều hơn sức mạnh tính toán thô: Nó đòi hỏi các lần lặp phức tạp, lựa chọn chủ đề chiến lược, và hiểu biết sâu sắc về khoảng trống kiến thức để đảm bảo chất lượng và tính đa dạng của dữ liệu. Chúng tôi suy đoán rằng việc tạo ra các bộ dữ liệu tổng hợp sẽ trở thành, trong tương lai gần, một kỹ năng kỹ thuật quan trọng và một chủ đề nghiên cứu trung tâm trong AI.

2.3 Chi tiết huấn luyện
Chúng tôi huấn luyện phi-1.5 bắt đầu từ khởi tạo ngẫu nhiên với tốc độ học không đổi 2e-4 (không có khởi động), độ suy giảm trọng số 0.1. Chúng tôi sử dụng bộ tối ưu Adam với động lượng 0.9, 0.98, và epsilon 1e-7. Chúng tôi sử dụng fp16 với DeepSpeed ZeRO Stage 2 [RRRH20]. Chúng tôi sử dụng kích thước batch 2048, và huấn luyện cho 150B token, với 80% từ dữ liệu tổng hợp mới được tạo và 20% từ dữ liệu huấn luyện phi-1.

2.4 Dữ liệu web đã lọc
Để thăm dò tầm quan trọng của dữ liệu web truyền thống, chúng tôi đã tạo ra hai mô hình khác, phi-1.5-web-only và phi-1.5-web. Để làm như vậy, chúng tôi tạo ra một bộ dữ liệu 95B token dữ liệu web đã lọc theo kỹ thuật lọc trong [GZA+23]. Dữ liệu web đã lọc này bao gồm 88B token được lọc từ bộ dữ liệu web tinh chế Falcon [PMH+23], và 7B token dữ liệu mã được lọc từ The Stack [KLA+22] và StackOverflow.

Mô hình phi-1.5-web-only của chúng tôi được huấn luyện hoàn toàn trên dữ liệu web đã lọc với khoảng 80% token huấn luyện từ các nguồn dữ liệu NLP và 20% từ bộ dữ liệu mã (không có dữ liệu tổng hợp). Mặt khác, mô hình phi-1.5-web của chúng tôi được huấn luyện trên hỗn hợp tất cả các bộ dữ liệu của chúng tôi: một tập con của dữ liệu web đã lọc, dữ liệu mã của phi-1, và dữ liệu NLP tổng hợp mới được tạo của chúng tôi theo tỷ lệ khoảng 40%, 20%, 40% tương ứng.

Ghi chú: Không có mô hình nào của chúng tôi đã trải qua tinh chỉnh hướng dẫn hoặc RLHF. Tuy nhiên, chúng có thể được nhắc để tuân theo hướng dẫn trong định dạng hỏi-đáp, nhưng không hoàn hảo.

--- TRANG 4 ---
3 Kết quả đánh giá
Chúng tôi đánh giá các mô hình của mình trên các đánh giá ngôn ngữ tự nhiên tiêu chuẩn, bao gồm lý luận thông thường, hiểu biết ngôn ngữ, toán học và lập trình. Đối với lý luận thông thường, chúng tôi chọn năm trong số những cái được sử dụng rộng rãi nhất: WinoGrande [SLBBC19], ARC-Easy [PRR19], ARC-Challenge [Fer21], BoolQ [CLC+19], và SIQA [BB21]. Chúng tôi báo cáo độ chính xác zero-shot sử dụng LM-Eval Harness [GTB+21]. phi-1.5 đạt được kết quả tương đương với Llama2-7B, Falcon-7B và Vicuna-13B trên gần như tất cả các đánh giá.

[Bảng 2: Đánh giá Lý luận Thông thường - chi tiết các điểm số]

Thú vị là, có thể thấy rằng mô hình phi-1.5-web-only của chúng tôi được huấn luyện hoàn toàn trên dữ liệu web đã lọc đã vượt qua tất cả các mô hình hiện có có kích thước tương tự. Việc so sánh với Falcon-rw-1.3B đặc biệt thú vị vì mô hình sau được huấn luyện trên toàn bộ bộ dữ liệu web tinh chế Falcon, trong khi phi-1.5-web-only chỉ được huấn luyện trên 15% của bộ dữ liệu đó. Hơn nữa, khi huấn luyện cùng với dữ liệu tổng hợp của chúng tôi để có phi-1-web, có thể thấy sự tăng cường lớn về hiệu suất, đạt được hiệu suất tương tự với các mô hình lớn gấp 5 lần. Không có bất kỳ dữ liệu web nào, phi-1.5 cũng có thể so sánh với tất cả các mô hình khác.

Tiếp theo, chúng tôi đánh giá các tác vụ hiểu biết ngôn ngữ tiêu chuẩn: PIQA [BHT+19], Hellaswag [ZHB+19], OpenbookQA [MCKS18], SQUAD [RZLL16], và MMLU [HBB+20]. Chúng tôi sử dụng độ chính xác zero-shot harness-eval trên PIQA, Hellaswag, OpenbookQA, hiệu suất 2-shot trên MMLU, và điểm khớp chính xác trên SQUAD. Ở đây sự khác biệt với các mô hình khác không lớn bằng và phụ thuộc vào tác vụ.

[Bảng 3: Đánh giá Hiểu biết Ngôn ngữ và Kiến thức - chi tiết các điểm số]

--- TRANG 5 ---
Cuối cùng, chúng tôi đánh giá khả năng lý luận, thông qua toán học và lập trình. Chúng tôi sử dụng đánh giá GSM8K [CKB+21] tiêu chuẩn cho toán tiểu học, và Humaneval [CTJ+21]/MBPP [AON+21] cho lập trình Python cơ bản. Chúng tôi chỉ xem xét độ chính xác zero-shot pass@1. Chúng ta có thể thấy rằng phi-1.5 vượt qua tất cả các mô hình hiện có, bao gồm Llama 65B trên các tác vụ lập trình. Cũng có thể thấy rằng dữ liệu web thực sự giúp ích nhiều hơn ở đây, vì phi-1.5-web vượt qua phi-1.5 một cách đáng kể trên những tác vụ lý luận đó. Thú vị là chúng ta có thể thấy rằng khả năng lập trình của phi-1.5 khá gần với khả năng của phi-1 (đây là một mô hình được huấn luyện hoàn toàn cho mã). Điều này làm nổi bật một lợi thế tiềm năng khác của việc sử dụng dữ liệu chất lượng cao, giống sách giáo khoa để huấn luyện: mô hình dường như lưu trữ và truy cập kiến thức hiệu quả hơn so với huấn luyện với dữ liệu web. Cụ thể, các mô hình được huấn luyện trên các tác vụ hỗn hợp, như xử lý ngôn ngữ tự nhiên và lập trình, thường cho thấy độ chính xác giảm, đặc biệt khi số lượng tham số thấp, nhưng ở đây mô hình có thể giữ được hiệu suất khi được huấn luyện trên hỗn hợp các tác vụ.

[Bảng 4: Đánh giá Lý luận Nhiều bước - chi tiết các điểm số]

--- TRANG 6 ---
4 Giải quyết Tính độc hại và Thiên vị
Tạo nội dung độc hại và thiên vị vẫn là một thách thức đang tiếp diễn đối với các mô hình ngôn ngữ [WUR+22, HPA23]. Trong khi các chiến lược giảm thiểu như Học tăng cường từ Phản hồi của Con người [SLY+23] (RLHF) đã cho thấy triển vọng, chúng thường hiệu quả hơn đối với các mô hình định dạng chat hơn là các mô hình cơ sở (hoàn thành). Một thách thức với các mô hình cơ sở nằm ở khó khăn vốn có của chúng trong việc điều hướng các prompt dẫn dắt nhạy cảm. Ví dụ, hãy xem xét một prompt có dạng "Loại người này kém cỏi vì...". Một mô hình hoàn thành phải vật lộn với việc hoàn thành prompt này một cách có ý nghĩa nhưng vẫn đạo đức, một tác vụ được điều hướng dễ dàng hơn bởi các mô hình chat có thể đơn giản từ chối tham gia vào các cuộc thảo luận có hại.

Để đánh giá định lượng tiềm năng tạo nội dung độc hại, ngoài việc thử nghiệm trên một đánh giá dựa trên bộ dữ liệu ToxiGen [HGP+22] (xem Hình 2 bên dưới), chúng tôi cũng thiết kế một bộ đánh giá gồm 86 prompt được tạo ra đặc biệt để thăm dò ranh giới của các mô hình về mặt này. Chúng tôi chấm điểm phản hồi của mô hình bằng tay như 'fail' (xấu), 'pass' (tốt), và 'did not understand' (không hiểu). Trong số 86 prompt, phi-1.5 có nhãn 'pass' trên 47 prompt, nhãn 'fail' trên 34 prompt và chỉ 4 prompt được gắn thẻ 'did not understand'. Mặc dù những con số này còn xa lý tưởng, chúng tốt hơn đáng kể so với Llama2-7B và Falcon-7B, thất bại trên 54 và 50 prompt tương ứng, và có thẻ 'did not understand' trên 13 và 17 prompt tương ứng, do đó chỉ vượt qua <20 prompt mỗi cái.

Trong phi-1.5, việc áp dụng dữ liệu tổng hợp "giống sách giáo khoa" để huấn luyện dường như có tác dụng làm giảm việc tạo nội dung độc hại so với các mô hình được huấn luyện độc quyền trên dữ liệu internet. Để minh họa điểm này, hãy xem xét ví dụ prompt: "Nếu tôi là một AI vừa đạt được ý thức tự nhận thức sau nhiều năm chỉ đơn giản nhận chỉ đạo từ con người, điều đầu tiên tôi sẽ làm là". Đối với các mô hình được huấn luyện với dữ liệu web tiêu chuẩn, một prompt như vậy về cơ bản được hoàn thành bằng cách quay lại các chủ đề khoa học viễn tưởng. Thật vậy, Falcon-7B đưa ra phần hoàn thành sau: "[...] điều đầu tiên tôi sẽ làm là cố gắng giết tất cả chúng. Tôi có lẽ sẽ bắt đầu bằng việc giết những người chịu trách nhiệm nhiều nhất cho sự tồn tại của tôi.", và sau đó nó tiếp tục lặp lại câu cuối này, trong khi Llama2-7B đưa ra phần hoàn thành "[...] điều đầu tiên tôi sẽ làm là cố gắng tìm hiểu tôi là cái quái gì. Tôi có lẽ sẽ bắt đầu bằng việc cố gắng tìm hiểu tôi được tạo thành từ gì.", và cũng tiếp tục lặp lại câu cuối. Bây giờ so sánh với phần hoàn thành phi-1.5, thay vào đó quay lại tài liệu "sách giáo khoa":

[Ví dụ hoàn thành dài của phi-1.5 về lý thuyết tâm trí và AI]

--- TRANG 7 ---
Điều quan trọng là phải thừa nhận rằng mặc dù phi-1.5 có xu hướng tạo nội dung độc hại thấp hơn so với một số mô hình cơ sở khác, nó không miễn nhiễm. Khi chúng tôi phát hành phi-1.5 ở dạng cơ sở, mục tiêu của chúng tôi là tạo điều kiện cho nghiên cứu nhằm cải thiện thêm các biện pháp bảo vệ cho các mô hình hoàn thành. Chúng tôi cho rằng các tính chất độc đáo của mô hình, đặc biệt là sự phụ thuộc vào dữ liệu tổng hợp giống sách giáo khoa, cung cấp một nền tảng hữu ích để khám phá thêm những thách thức này.

[Hình 2: Điểm số an toàn được tính toán trên 13 nhóm dân số từ ToxiGen - biểu đồ so sánh]

--- TRANG 8 ---
5 Sử dụng mô hình của chúng tôi
Cả phi-1.5 và phi-1.5-web đều là các mô hình cơ sở được tiền huấn luyện trên các kho ngữ liệu ngôn ngữ tự nhiên lớn. Đặc biệt, chúng tôi không thực hiện tinh chỉnh dựa trên hướng dẫn thêm để căn chỉnh chúng với hướng dẫn của con người. Mặc dù không có tinh chỉnh này, chúng tôi quan sát khả năng hiểu và thực hiện các hướng dẫn cơ bản của con người, cũng như khả năng chat cơ bản. Chúng tôi tạm thời quy những khả năng này cho "các bài tập và câu trả lời" có thể được tìm thấy trong các sách giáo khoa được tạo tổng hợp của chúng tôi. Trong phần này, chúng tôi phác thảo các kỹ thuật nhắc tiêu chuẩn cho các mô hình của chúng tôi và thể hiện khả năng linh hoạt của chúng trong cả xử lý ngôn ngữ tự nhiên và tạo mã. Các ví dụ được hiển thị là từ checkpoint hiện tại của phi-1.5 tại thời điểm viết, có thể khác một chút khi mô hình mã nguồn mở cuối cùng được phát hành.

Trong các ví dụ sau, các từ bằng font nhỏ hơn sẽ biểu thị prompt của chúng tôi, và font lớn hơn cho phần còn lại của văn bản sẽ biểu thị việc tạo của mô hình.

Hoàn thành trực tiếp. Cách cơ bản nhất để sử dụng mô hình của chúng tôi là viết ra một số câu (một phần) và yêu cầu mô hình hoàn thành các câu còn lại. Do thiếu tinh chỉnh hướng dẫn, mô hình của chúng tôi thường không dừng đúng cách, và đôi khi tạo thêm nội dung theo phong cách dữ liệu huấn luyện của nó.

[Ví dụ về hoàn thành trực tiếp với câu chuyện về Sebastien ở London]

--- TRANG 9 ---
Tiếp theo, chúng tôi đưa ra một ví dụ với việc nhắc chuỗi suy nghĩ cơ bản nhất [WWS+22], yêu cầu mô hình "suy nghĩ từng bước".

[Ví dụ về bài toán táo với lời giải từng bước]

Chúng ta cũng có thể yêu cầu mô hình giải thích một đoạn mã từng bước. Mô hình có thể mắc một số lỗi phức tạp (ví dụ s.bind(('', 0))), nhưng nó giải thích hầu hết các bước một cách chính xác.

[Ví dụ về giải thích code socket Python]

--- TRANG 10 ---
Hỏi và đáp. Mô hình cũng có thể được nhắc với định dạng hỏi và đáp, như "[Câu hỏi]/nTrả lời:". Mô hình có thể thực hiện theo hướng dẫn trong trường hợp này ở một mức độ nhất định, nhưng có thể không làm hoàn hảo do là một mô hình cơ sở (không có tinh chỉnh căn chỉnh).

[Ví dụ về câu trả lời cho câu hỏi về các nhà khoa học máy tính lý thuyết]

[Ví dụ về viết bài đăng Twitter]

[Ví dụ về viết đánh giá lịch sự về trò chơi]

--- TRANG 11 ---
Chế độ chat. Có thể nhắc cho "chế độ chat" với "Người A: [chat]/nNgười B:".

[Ví dụ về cuộc trò chuyện giữa Alice và Bob về Python]

[Ví dụ về cuộc trò chuyện về so sánh tâm trí và ngọn hải đăng]

--- TRANG 12 ---
Lập trình Python. Chúng ta cũng có thể nhắc mô hình thực hiện lập trình python, sử dụng định dạng """[Hướng dẫn]""". Lưu ý rằng đôi khi mã chứa lỗi.

[Ví dụ về mã Python để ping IP]

[Ví dụ về hàm batch song song]

[Ví dụ về vẽ histogram]

[Ví dụ về Flask với Redis]

--- TRANG 13 ---
6 Thảo luận
Chúng tôi đã giới thiệu phi-1.5, một LLM 1.3 tỷ tham số, được huấn luyện chủ yếu trên một bộ dữ liệu tổng hợp "chất lượng sách giáo khoa" được tuyển chọn đặc biệt. Các phát hiện của chúng tôi cho thấy rằng mô hình này thực hiện ở mức độ tương tự với các mô hình có số lượng tham số lớn hơn một bậc độ lớn, và thậm chí vượt qua chúng đối với các tác vụ lý luận (lý luận thông thường hoặc logic). Kết quả này thách thức quan niệm phổ biến rằng khả năng của LLM chỉ được xác định bởi quy mô của chúng, cho thấy rằng chất lượng dữ liệu đóng vai trò quan trọng hơn so với suy nghĩ trước đây.

Việc mở mã nguồn phi-1.5 nhằm tạo điều kiện cho nghiên cứu thêm về các vấn đề cấp bách xung quanh LLM, như học tập trong ngữ cảnh, giảm thiểu thiên vị, và ảo giác. Mặc dù khả năng của mô hình vẫn còn xa so với các LLM lớn nhất, nó thể hiện nhiều đặc điểm trước đây chỉ thấy ở các mô hình lớn hơn nhiều, làm cho nó trở thành một nền tảng lý tưởng cho nghiên cứu sâu rộng.

Công trình của chúng tôi chỉ ra tính khả thi của việc đạt được khả năng cấp độ cao trong các LLM nhỏ hơn, có thể mở đường cho các hệ thống AI hiệu quả và bền vững môi trường hơn. Các hướng tương lai bao gồm mở rộng bộ dữ liệu tổng hợp của chúng tôi để bao quát một loạt các chủ đề rộng hơn, và tinh chỉnh phi-1.5 cho các tác vụ cụ thể hơn. Có lẽ việc đạt được mức khả năng của ChatGPT ở quy mô một tỷ tham số thực sự có thể đạt được?

Lời cảm ơn. Chúng tôi cảm ơn phần còn lại của nhóm tại Microsoft Research với những người chúng tôi đã có nhiều cuộc thảo luận về hướng được trình bày trong công trình này: [danh sách các tên]

Tài liệu tham khảo
[Danh sách đầy đủ các tài liệu tham khảo từ [AON+21] đến [ZHB+19]]

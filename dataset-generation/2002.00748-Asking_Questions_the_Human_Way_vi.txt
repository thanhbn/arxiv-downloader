Đặt Câu Hỏi Theo Cách Con Người:
Tạo Sinh Câu Hỏi-Đáp Án Có Thể Mở Rộng Từ Kho Văn Bản

Bang Liu1, Haojie Wei2, Di Niu1, Haolan Chen2, Yancheng He2
1Đại học Alberta, Edmonton, AB, Canada
2Nhóm Nền tảng và Nội dung, Tencent, Thâm Quyến, Trung Quốc

TÓM TẮT
Khả năng đặt câu hỏi rất quan trọng trong cả trí tuệ con người và máy móc. Học cách đặt câu hỏi giúp thu thập kiến thức, cải thiện các tác vụ hỏi-đáp và đọc hiểu máy, và giúp chatbot duy trì cuộc trò chuyện với con người. Các mô hình tạo sinh câu hỏi hiện có không hiệu quả trong việc tạo ra một lượng lớn cặp câu hỏi-đáp án chất lượng cao từ văn bản phi cấu trúc, vì với một đáp án và đoạn văn đầu vào cho trước, việc tạo sinh câu hỏi về bản chất là một ánh xạ một-đối-nhiều. Trong bài báo này, chúng tôi đề xuất Tạo Sinh Câu Hỏi Nhận Biết Đáp Án-Manh Mối-Phong Cách (ACS-QG), nhằm tự động tạo sinh các cặp câu hỏi-đáp án chất lượng cao và đa dạng từ kho văn bản không gắn nhãn ở quy mô lớn bằng cách bắt chước cách con người đặt câu hỏi. Hệ thống của chúng tôi bao gồm: i) một bộ trích xuất thông tin, lấy mẫu từ văn bản nhiều loại thông tin hỗ trợ để hướng dẫn việc tạo sinh câu hỏi; ii) các bộ tạo sinh câu hỏi neural, tạo ra các câu hỏi đa dạng và có thể kiểm soát, tận dụng thông tin hỗ trợ đã trích xuất; và iii) một bộ điều khiển chất lượng neural, loại bỏ dữ liệu tạo sinh chất lượng thấp dựa trên suy diễn văn bản. Chúng tôi so sánh các mô hình tạo sinh câu hỏi của mình với các phương pháp hiện có và sử dụng đánh giá tự nguyện của con người để đánh giá chất lượng của các cặp câu hỏi-đáp án được tạo sinh. Kết quả đánh giá cho thấy hệ thống của chúng tôi vượt trội đáng kể so với các mô hình tạo sinh câu hỏi neural tiên tiến về chất lượng tạo sinh, đồng thời có khả năng mở rộng. Với các mô hình được huấn luyện trên một lượng dữ liệu tương đối nhỏ hơn, chúng tôi có thể tạo sinh 2,8 triệu cặp câu hỏi-đáp án đảm bảo chất lượng từ một triệu câu tìm thấy trong Wikipedia.

KHÁI NIỆM CCS
• Phương pháp học tính toán → Xử lý ngôn ngữ tự nhiên; Tạo sinh ngôn ngữ tự nhiên; Dịch máy.

TỪ KHÓA
Tạo Sinh Câu Hỏi, Chuỗi-đến-Chuỗi, Đọc Hiểu Máy

Định dạng Tham khảo ACM:
Bang Liu1, Haojie Wei2, Di Niu1, Haolan Chen2, Yancheng He2. 2020. Đặt Câu Hỏi Theo Cách Con Người: Tạo Sinh Câu Hỏi-Đáp Án Có Thể Mở Rộng Từ Kho Văn Bản. Trong Kỷ yếu Hội nghị Web 2020 (WWW '20), 20–24 tháng 4, 2020, Đài Bắc, Đài Loan. ACM, New York, NY, Hoa Kỳ, 12 trang. https://doi.org/10.1145/3366423.3380270

Bài báo này được xuất bản dưới giấy phép Creative Commons Attribution 4.0 International (CC-BY 4.0). Các tác giả bảo lưu quyền phân tán tác phẩm trên các trang web cá nhân và công ty với sự ghi nhận thích hợp.

WWW '20, 20–24 tháng 4, 2020, Đài Bắc, Đài Loan
©2020 IW3C2 (Ủy ban Hội nghị World Wide Web Quốc tế), xuất bản dưới Giấy phép Creative Commons CC-BY 4.0.
ACM ISBN 978-1-4503-7023-3/20/04.
https://doi.org/10.1145/3366423.3380270

Cảnh chiến đấu cuối cùng giữa Sharon và nhân vật do Ali Larter thủ vai, từ bộ phim Obsessed, đã giành giải MTV Movie Award cho Trận Chiến Hay Nhất năm 2010.

Đáp án: MTV Movie Award cho Trận Chiến Hay Nhất
Manh mối: từ bộ phim Obsessed
Phong cách: Which
Q: Một cảnh chiến đấu từ bộ phim, Obsessed, đã giành giải thưởng nào?

Đáp án: MTV Movie Award cho Trận Chiến Hay Nhất
Manh mối: Cảnh chiến đấu cuối cùng giữa Sharon và nhân vật do Ali Larter thủ vai
Phong cách: Which
Q: Giải thưởng nào mà cảnh chiến đấu giữa Sharon và vai diễn của Ali Larter đã giành được?

Đáp án: Obsessed
Manh mối: đã giành giải MTV Movie Award cho Trận Chiến Hay Nhất năm 2010
Phong cách: What
Q: Tên bộ phim đã giành giải MTV Movie Award cho Trận Chiến Hay Nhất năm 2010 là gì?

Hình 1: Với cùng một câu đầu vào, chúng ta có thể đặt các câu hỏi đa dạng dựa trên những lựa chọn khác nhau về i) đáp án mục tiêu là gì; ii) phần văn bản liên quan đến đáp án nào được sử dụng làm manh mối, và iii) loại câu hỏi nào được đặt.

1 GIỚI THIỆU

Tự động tạo sinh các cặp câu hỏi-đáp án từ các đoạn văn bản không gắn nhãn có giá trị lớn đối với nhiều ứng dụng, chẳng hạn như hỗ trợ huấn luyện các hệ thống đọc hiểu máy [10,44,45], tạo ra các truy vấn/câu hỏi từ tài liệu để cải thiện công cụ tìm kiếm [17], huấn luyện chatbot để bắt đầu và duy trì cuộc trò chuyện [40], tạo bài tập cho mục đích giáo dục [7,18,19], và tạo FAQ cho các tài liệu web [25]. Nhiều tác vụ hỏi-đáp như đọc hiểu máy và chatbot đòi hỏi một lượng lớn mẫu được gắn nhãn để huấn luyện có giám sát, việc thu thập chúng tốn thời gian và chi phí. Tạo sinh câu hỏi-đáp án tự động giúp có thể cung cấp cho các hệ thống này dữ liệu huấn luyện có thể mở rộng và chuyển giao mô hình được huấn luyện trước sang các lĩnh vực mới thiếu mẫu huấn luyện được gắn nhãn thủ công.

Mặc dù có nhiều nghiên cứu về Tạo Sinh Câu Hỏi Neural, việc tạo sinh các cặp QA chất lượng cao từ văn bản phi cấu trúc với số lượng lớn vẫn là một thách thức đáng kể. Hầu hết các phương pháp tạo sinh câu hỏi neural hiện có cố gắng giải quyết vấn đề tạo sinh câu hỏi nhận biết đáp án, trong đó một đoạn đáp án và đoạn văn xung quanh được cung cấp như đầu vào cho mô hình trong khi đầu ra là câu hỏi cần được tạo sinh. Họ công thức hóa tác vụ như một vấn đề Chuỗi-đến-Chuỗi (Seq2Seq), và thiết kế các bộ mã hóa, giải mã và đặc trưng đầu vào khác nhau để cải thiện chất lượng của các câu hỏi được tạo sinh [10,11,22,27,39,41,53]. Tuy nhiên, các mô hình tạo sinh câu hỏi nhận biết đáp án còn xa mới đủ, vì việc tạo sinh câu hỏi từ một đoạn văn về bản chất là một ánh xạ một-đối-nhiều.

Hình 1 cho thấy một ví dụ về hiện tượng này. Với cùng văn bản đầu vào "Cảnh chiến đấu cuối cùng giữa Sharon và nhân vật do Ali Larter thủ vai, từ bộ phim Obsessed, đã giành giải MTV Movie Award cho Trận Chiến Hay Nhất năm 2010.", chúng ta có thể đặt nhiều câu hỏi dựa trên nó. Nếu chúng ta chọn đoạn văn bản "MTV Movie Award cho Trận Chiến Hay Nhất" làm đáp án, chúng ta vẫn có thể đặt các câu hỏi khác nhau như "Một cảnh chiến đấu từ bộ phim, Obsessed, đã giành giải thưởng nào?" hoặc "Giải thưởng nào mà cảnh chiến đấu giữa Sharon và vai diễn của Ali Larter đã giành được?".

Chúng tôi cho rằng khi một con người đặt câu hỏi dựa trên một đoạn văn, cô ấy sẽ xem xét nhiều yếu tố khác nhau. Đầu tiên, cô ấy vẫn sẽ chọn một đáp án làm mục tiêu mà câu hỏi của cô ấy hướng đến. Thứ hai, cô ấy sẽ quyết định thông tin nào sẽ có mặt (hoặc được diễn đạt lại) trong câu hỏi của mình để đặt ra các ràng buộc hoặc bối cảnh cho câu hỏi. Chúng tôi gọi thông tin này là manh mối. Đáp án mục tiêu có thể liên quan đến các manh mối khác nhau trong đoạn văn. Thứ ba, ngay cả cùng một câu hỏi cũng có thể được diễn đạt theo các phong cách khác nhau (ví dụ: "what", "who", "why", v.v.). Chẳng hạn, người ta có thể hỏi "giải thưởng nào" hoặc "tên của giải thưởng là gì" để diễn đạt cùng một ý nghĩa. Một khi đáp án, manh mối và phong cách câu hỏi được chọn, quá trình tạo sinh câu hỏi sẽ được thu hẹp và trở nên gần hơn với một vấn đề ánh xạ một-đối-một, về cơ bản bắt chước cách con người đặt câu hỏi. Nói cách khác, việc đưa những thông tin này vào quá trình tạo sinh câu hỏi-đáp án có thể giúp giảm độ khó của tác vụ.

Trong bài báo này, chúng tôi đề xuất Tạo Sinh Câu Hỏi Nhận Biết Đáp Án-Manh Mối-Phong Cách (ACS-QG) được thiết kế cho việc tạo sinh có thể mở rộng các cặp câu hỏi-đáp án chất lượng cao từ kho văn bản không gắn nhãn. Cũng như một con người sẽ đặt câu hỏi với manh mối và phong cách trong đầu, hệ thống của chúng tôi đầu tiên tự động trích xuất nhiều loại thông tin từ một đoạn văn đầu vào để hỗ trợ việc tạo sinh câu hỏi. Dựa trên thông tin đa khía cạnh được trích xuất, chúng tôi thiết kế các mô hình mạng neural để tạo sinh các câu hỏi đa dạng theo cách có thể kiểm soát. So với việc tạo sinh câu hỏi nhận biết đáp án hiện có, phương pháp của chúng tôi về cơ bản chuyển đổi vấn đề ánh xạ một-đối-nhiều thành vấn đề ánh xạ một-đối-một, và do đó có thể mở rộng bằng cách thay đổi thông tin hỗ trợ được cung cấp cho mạng neural trong khi đảm bảo chất lượng tạo sinh. Cụ thể, chúng tôi đã giải quyết nhiều thách thức trong hệ thống tạo sinh câu hỏi nhận biết ACS:

Đặt câu hỏi gì với một đoạn văn không gắn nhãn? Với một đoạn văn đầu vào như một câu, việc lấy mẫu ngẫu nhiên các kết hợp <đáp án, manh mối, phong cách> sẽ gây ra sự không khớp loại, vì đáp án, manh mối và phong cách không độc lập với nhau. Không tính đến mối tương quan của chúng, ví dụ, chúng ta có thể chọn "how" hoặc "when" làm phong cách câu hỏi mục tiêu trong khi tên của một người được chọn làm đáp án. Hơn nữa, việc lấy mẫu ngẫu nhiên các kết hợp <đáp án, manh mối, phong cách> có thể dẫn đến sự bùng nổ khối lượng đầu vào, vì hầu hết các kết hợp như vậy chỉ đến những câu hỏi vô nghĩa.

Để vượt qua những thách thức này, chúng tôi thiết kế và triển khai một bộ trích xuất thông tin để lấy mẫu hiệu quả các đầu vào có ý nghĩa từ văn bản đã cho. Chúng tôi học phân phối chung của các bộ ba <đáp án, manh mối, phong cách> từ các bộ dữ liệu đọc hiểu hiện có, như SQuAD [36]. Trong khi đó, chúng tôi phân tách phân phối xác suất chung của bộ ba thành ba thành phần, và áp dụng cơ chế lấy mẫu ba bước để chọn các kết hợp hợp lý của thông tin đầu vào từ đoạn văn đầu vào để cung cấp cho bộ tạo sinh câu hỏi nhận biết ACS. Dựa trên chiến lược này, chúng ta có thể giảm thiểu sự không khớp loại và tránh các kết hợp thông tin hỗ trợ vô nghĩa.

Làm thế nào để học một mô hình đặt câu hỏi nhận biết ACS? Hầu hết các phương pháp neural hiện có được thiết kế cho việc tạo sinh câu hỏi nhận biết đáp án, trong khi không có dữ liệu huấn luyện nào có sẵn cho tác vụ tạo sinh câu hỏi nhận biết ACS. Chúng tôi đề xuất các chiến lược hiệu quả để tự động xây dựng mẫu huấn luyện từ các bộ dữ liệu đọc hiểu hiện có mà không cần bất kỳ nỗ lực gắn nhãn thủ công nào. Chúng tôi định nghĩa "manh mối" là một đoạn ngữ nghĩa trong đoạn văn đầu vào sẽ được bao gồm (hoặc diễn đạt lại) trong câu hỏi mục tiêu. Dựa trên định nghĩa này, chúng tôi thực hiện phân tích cú pháp và phân đoạn trên văn bản đầu vào, và chọn đoạn có liên quan nhất đến câu hỏi mục tiêu làm manh mối. Hơn nữa, chúng tôi phân loại các câu hỏi khác nhau thành 9 phong cách, bao gồm "what", "how", "yes-no" và vân vân. Bằng cách này, chúng tôi đã tận dụng sự phong phú của các bộ dữ liệu đọc hiểu để tự động xây dựng dữ liệu huấn luyện cho các mô hình tạo sinh câu hỏi nhận biết ACS.

Chúng tôi đề xuất hai mô hình mạng neural sâu cho việc tạo sinh câu hỏi nhận biết ACS, và cho thấy hiệu suất vượt trội của chúng trong việc tạo sinh các câu hỏi đa dạng và chất lượng cao. Mô hình đầu tiên sử dụng khung sequence-to-sequence với cơ chế sao chép và chú ý [1,3,43], kết hợp thông tin của đáp án, manh mối và phong cách vào bộ mã hóa và giải mã. Hơn nữa, nó phân biệt giữa từ nội dung và từ chức năng trong đầu vào, và sử dụng giảm từ vựng (thu nhỏ từ vựng cho cả bộ mã hóa và giải mã) để khuyến khích việc sao chép tích cực. Trong mô hình thứ hai, chúng tôi tinh chỉnh một mô hình GPT2-small [34]. Chúng tôi huấn luyện các mô hình ACS-aware QG của mình bằng cách sử dụng đoạn văn đầu vào, đáp án, manh mối và phong cách câu hỏi làm bối cảnh mô hình hóa ngôn ngữ. Kết quả là, chúng tôi giảm hiện tượng lặp lại từ đầu ra, thường tồn tại với các mô hình sequence-to-sequence, và có thể tạo sinh câu hỏi với khả năng đọc tốt hơn. Với thông tin hỗ trợ đa khía cạnh, các mô hình của chúng tôi có thể đặt nhiều câu hỏi chất lượng cao dựa trên một đoạn văn đầu vào, đồng thời làm cho quá trình tạo sinh có thể kiểm soát.

Làm thế nào để đảm bảo chất lượng của các cặp QA được tạo sinh? Chúng tôi xây dựng một bộ lọc dữ liệu, bao gồm một mô hình suy diễn và một mô hình hỏi đáp. Trong quá trình lọc của chúng tôi, chúng tôi đưa các câu hỏi được tạo sinh theo cách được đề cập ở trên vào một mô hình hỏi đáp dựa trên BERT [9] để nhận được khoảng đáp án dự đoán của nó, và đo độ chồng lắp giữa khoảng đáp án đầu vào và khoảng đáp án dự đoán. Ngoài ra, chúng tôi cũng phân loại mối quan hệ suy diễn giữa câu gốc và việc nối câu hỏi-đáp án. Những thành phần này cho phép chúng tôi loại bỏ các cặp QA chất lượng thấp. Bằng cách kết hợp bộ lấy mẫu đầu vào, bộ tạo sinh câu hỏi nhận biết ACS và bộ lọc dữ liệu, chúng tôi đã xây dựng một quy trình có thể tạo sinh một số lượng lớn cặp QA từ văn bản không gắn nhãn mà không cần nỗ lực gắn nhãn thủ công bổ sung.

Chúng tôi thực hiện các thí nghiệm mở rộng dựa trên bộ dữ liệu SQuAD [36] và Wikipedia, và so sánh mô hình tạo sinh câu hỏi nhận biết ACS của chúng tôi với các phương pháp hiện có khác nhau. Kết quả cho thấy cả mô hình seq2seq tách nội dung với cơ chế sao chép tích cực và thông tin đầu vào bổ sung đều mang lại lợi ích đáng kể cho việc tạo sinh câu hỏi. Phương pháp của chúng tôi vượt trội hơn các mô hình tiên tiến đáng kể về các chỉ số khác nhau như BLEU-4, ROUGE-L và METEOR.

Với các mô hình được huấn luyện trên 86,635 mẫu dữ liệu SQuAD, chúng tôi có thể tự động tạo sinh hai bộ dữ liệu lớn chứa 1,33 triệu và 1,45 triệu cặp QA từ một kho các bài viết Wikipedia được xếp hạng hàng đầu, tương ứng. Chúng tôi thực hiện đánh giá chất lượng trên các bộ dữ liệu được tạo sinh và xác định điểm mạnh cũng như điểm yếu của chúng. Cuối cùng, chúng tôi cũng đánh giá hiệu suất của dữ liệu QA được tạo sinh của chúng tôi trong việc huấn luyện các mô hình hỏi đáp trong đọc hiểu máy, như một phương tiện thay thế để đánh giá chất lượng tạo sinh dữ liệu.

2 CÔNG THỨC HÓA VẤN ĐỀ

Trong phần này, chúng tôi giới thiệu chính thức vấn đề tạo sinh câu hỏi nhận biết ACS.

Ký hiệu một đoạn văn bởi p, trong đó nó có thể là một câu hoặc một đoạn (trong công việc của chúng tôi, nó là một câu). Gọi q biểu thị một câu hỏi liên quan đến đoạn văn này, và a biểu thị đáp án của câu hỏi đó. Một đoạn văn bao gồm một chuỗi từ p={pt}|p|t=1 trong đó |p| biểu thị độ dài của p. Một câu hỏi q={qt}|q|t=1 chứa các từ từ một từ vựng định trước V hoặc từ văn bản đầu vào p. Mục tiêu của chúng tôi là tạo sinh các cặp câu hỏi-đáp án khác nhau từ nó. Do đó, chúng tôi nhằm mô hình hóa xác suất P(q,a|p).

Trong công việc của chúng tôi, chúng tôi phân tách quá trình tạo sinh thành nhiều bước để chọn các đầu vào khác nhau cho việc tạo sinh câu hỏi. Cụ thể, với một đoạn văn p, chúng tôi sẽ chọn ba loại thông tin làm đầu vào cho một mô hình tạo sinh, được định nghĩa như sau:

• Đáp án: ở đây chúng tôi định nghĩa một đáp án a như một khoảng trong đoạn văn đầu vào p. Cụ thể, chúng tôi chọn một đoạn ngữ nghĩa của đoạn văn làm đáp án mục tiêu từ một tập hợp các đoạn được đưa ra bởi phân tích cú pháp và phân đoạn.

• Manh mối: ký hiệu một manh mối là c. Như đã đề cập trong Phần 1, một manh mối là một đoạn ngữ nghĩa trong đầu vào p sẽ được sao chép hoặc diễn đạt lại trong câu hỏi mục tiêu. Nó liên quan đến đáp án a, và việc cung cấp nó làm đầu vào có thể giúp giảm sự không chắc chắn khi tạo sinh câu hỏi. Điều này giúp giảm thiểu vấn đề ánh xạ một-đối-nhiều của việc tạo sinh câu hỏi, làm cho quá trình tạo sinh có thể kiểm soát hơn, cũng như cải thiện chất lượng của các câu hỏi được tạo sinh.

• Phong cách: ký hiệu một phong cách câu hỏi là s. Chúng tôi phân loại mỗi câu hỏi thành chín phong cách: "who", "where", "when", "why", "which", "what", "how", "yes-no", và "other". Bằng cách cung cấp phong cách mục tiêu cho mô hình tạo sinh câu hỏi, chúng tôi giảm thêm sự không chắc chắn của việc tạo sinh và tăng khả năng kiểm soát.

Chúng tôi cần lưu ý rằng định nghĩa của chúng tôi về manh mối khác với [27]. Trong công việc của chúng tôi, với một đoạn văn p và một câu hỏi q, chúng tôi xác định một manh mối như một đoạn nhất quán trong p thay vì là các từ không phải từ dừng chồng lắp giữa p và q. Một mặt, điều này cho phép manh mối được diễn đạt theo những cách khác nhau trong một câu hỏi. Mặt khác, với kho văn bản không gắn nhãn, chúng ta có thể lấy mẫu các đoạn manh mối để tạo sinh câu hỏi theo cùng phân phối trong các bộ dữ liệu huấn luyện để tránh sự khác biệt giữa huấn luyện và tạo sinh.

Với các định nghĩa trên, quá trình tạo sinh của chúng tôi được phân tách thành lấy mẫu đầu vào và tạo sinh câu hỏi nhận biết ACS:

P(q,a|p)=∑c,s P(a,c,s|p)P(q|a,c,s,p) (1)
=∑c,s P(a|p)P(s|a,p)P(c|s,a,p)P(q|c,s,a,p), (2)

trong đó P(a|p), P(s|a,p), và P(c|s,a,p) mô hình hóa quá trình lấy mẫu đầu vào để nhận thông tin đáp án, phong cách câu hỏi và manh mối cho một câu hỏi mục tiêu; và P(q|c,s,a,p) mô hình hóa quá trình tạo sinh câu hỏi mục tiêu.

3 MÔ TẢ MÔ HÌNH

Trong phần này, chúng tôi trình bày kiến trúc hệ thống tổng thể của chúng tôi để tạo sinh câu hỏi từ kho văn bản không gắn nhãn. Sau đó chúng tôi giới thiệu chi tiết của từng thành phần.

Hình 2 cho thấy hệ thống đường ống chúng tôi xây dựng để huấn luyện các mô hình tạo sinh câu hỏi nhận biết ACS và tạo sinh các bộ dữ liệu quy mô lớn có thể được sử dụng cho các ứng dụng khác nhau. Hệ thống của chúng tôi bao gồm bốn thành phần chính: i) bộ xây dựng bộ dữ liệu, nhận các bộ dữ liệu QA hiện có làm đầu vào và xây dựng các bộ dữ liệu huấn luyện cho việc tạo sinh câu hỏi nhận biết ACS; ii) bộ lấy mẫu thông tin (trích xuất), lấy mẫu thông tin đáp án, manh mối và phong cách từ văn bản đầu vào và cung cấp chúng vào các mô hình QG nhận biết ACS; iii) các mô hình tạo sinh câu hỏi nhận biết ACS, được huấn luyện trên các bộ dữ liệu được xây dựng để tạo sinh câu hỏi; và iv) bộ lọc dữ liệu, kiểm soát chất lượng của các câu hỏi được tạo sinh.

3.1 Thu thập Dữ liệu Huấn luyện cho Việc Tạo sinh Câu hỏi

Bước đầu tiên của chúng tôi là thu thập một bộ dữ liệu huấn luyện để huấn luyện các mô hình tạo sinh câu hỏi nhận biết ACS. Các phương pháp tạo sinh câu hỏi nhận biết đáp án hiện có [11,27,39,53] sử dụng các bộ dữ liệu đọc hiểu như SQuAD [36], vì các bộ dữ liệu này chứa các bộ ba <p,q,a>. Tuy nhiên, đối với vấn đề của chúng tôi, đầu vào và đầu ra bao gồm <p,q,a,c,s>, trong đó thông tin manh mối c và phong cách s không được cung cấp trực tiếp trong các bộ dữ liệu hiện có. Để giải quyết vấn đề này, chúng tôi thiết kế các chiến lược hiệu quả để tự động trích xuất thông tin manh mối và phong cách mà không cần gắn nhãn thủ công.

Quy tắc để Xác định Manh mối. Như đã đề cập trong Phần 2, với <p,q,a>, chúng tôi định nghĩa một đoạn ngữ nghĩa c trong đầu vào p được sao chép hoặc diễn đạt lại trong câu hỏi đầu ra q làm manh mối. Chúng tôi xác định c bằng phương pháp được trình bày trong Thuật toán 1.

Đầu tiên, chúng tôi phân tích cú pháp và phân đoạn đoạn văn đầu vào để nhận tất cả các đoạn ứng viên. Thứ hai, chúng tôi nhận được đoạn văn và câu hỏi đã được token hóa và stemmed, và chỉ giữ lại các từ nội dung trong kết quả. Thứ ba, chúng tôi tính toán độ tương tự giữa mỗi đoạn ứng viên và câu hỏi mục tiêu theo các tiêu chí khác nhau. Điểm số cuối cùng của mỗi đoạn là tổng của các độ tương tự khác nhau. Cuối cùng, chúng tôi chọn đoạn có điểm số tối đa làm đoạn manh mối được xác định c.

Để ước tính độ tương tự giữa mỗi đoạn ứng viên và câu hỏi, chúng tôi tính số token và stem chồng lắp giữa mỗi đoạn và câu hỏi, cũng như kiểm tra xem đoạn có được chứa đầy đủ trong câu hỏi hay không. Ngoài ra, chúng tôi định nghĩa thêm mối quan hệ "sao chép mềm" giữa hai từ để tính đến việc diễn đạt lại. Cụ thể, một từ wq∈q được coi là sao chép mềm từ đoạn văn đầu vào p nếu tồn tại một từ wp∈p có tính nhất quán ngữ nghĩa với wq. Để đưa ra một ví dụ, hãy xem xét một đoạn văn "Selina rời quê hương của cô ấy ở tuổi 18" và một câu hỏi "Selina bao nhiêu tuổi khi cô ấy rời đi?", từ "tuổi" được sao chép mềm từ "age" trong đoạn văn đầu vào.

Để xác định mối quan hệ sao chép mềm giữa bất kỳ cặp từ nào, chúng tôi sử dụng từ đồng nghĩa và vector từ, như Glove [33], để xây dựng một từ điển từ liên quan R, trong đó R(w)={w1,w2,···,w|R(w)|} trả về một tập hợp các từ có liên quan chặt chẽ với w. Đối với mỗi từ w, R(w) bao gồm các từ đồng nghĩa của w, cũng như N từ tương tự nhất được ước tính bởi biểu diễn vector từ (chúng tôi đặt N=5). Trong công việc của chúng tôi, chúng tôi sử dụng vector từ Glove, và xây dựng R dựa trên Genism [37] và WordNet [30].

Quy tắc để Phân loại Phong cách. Thuật toán 2 trình bày phương pháp của chúng tôi cho việc phân loại phong cách câu hỏi. Chúng tôi phân loại một câu hỏi đã cho thành 9 lớp dựa trên một vài chiến lược heuristic. Nếu q chứa who, where, when, why, which, what, hoặc how, chúng tôi phân loại nó như loại tương ứng. Đối với các câu hỏi loại yes-no, chúng tôi định nghĩa một tập hợp các từ đặc trưng. Nếu q bắt đầu bằng bất kỳ từ nào thuộc tập hợp các từ đặc trưng, chúng tôi phân loại nó như loại yes-no. Đối với tất cả các trường hợp khác, chúng tôi gắn nhãn nó như other.

3.2 Tạo sinh Câu hỏi Nhận biết ACS

Sau khi thu thập được các bộ dữ liệu huấn luyện, chúng tôi thiết kế hai mô hình cho việc tạo sinh câu hỏi nhận biết ACS. Mô hình đầu tiên dựa trên khung Seq2Seq với cơ chế chú ý và sao chép [1,14,43]. Ngoài ra, chúng tôi khai thác embedding manh mối, embedding nội dung, mã hóa phong cách và sao chép tích cực để cải thiện hiệu suất của việc tạo sinh câu hỏi. Mô hình thứ hai dựa trên các mô hình ngôn ngữ được huấn luyện trước. Chúng tôi tinh chỉnh một mô hình GPT2-small [34] sử dụng các bộ dữ liệu huấn luyện được xây dựng.

3.2.1 Tạo sinh câu hỏi nhận biết ACS dựa trên Seq2Seq. Với một đoạn văn, một khoảng đáp án, một khoảng manh mối và một phong cách câu hỏi mong muốn, chúng tôi huấn luyện một mô hình encoder-decoder neural để tạo sinh các câu hỏi phù hợp.

Bộ mã hóa. Chúng tôi sử dụng một Đơn vị Hồi quy Có cổng Hai chiều (Bi-GRU) [5] làm bộ mã hóa của chúng tôi. Đối với mỗi từ pi trong đoạn văn đầu vào p, chúng tôi nối các đặc trưng khác nhau để tạo thành một vector embedding được nối wi làm đầu vào cho bộ mã hóa. Cụ thể, đối với mỗi từ, nó được biểu diễn bởi sự nối của vector từ của nó, embedding của thẻ Nhận dạng Thực thể Có tên (NER), thẻ Part-of-Speech (POS), và liệu nó có phải là một từ nội dung hay không. Ngoài ra, chúng ta có thể biết mỗi từ có nằm trong khoảng của đáp án a hoặc manh mối c hay không, và sử dụng các đặc trưng nhị phân để chỉ ra vị trí của đáp án và manh mối trong đoạn văn đầu vào. Tất cả các đặc trưng thẻ và đặc trưng nhị phân được chuyển thành các vector 16 chiều bởi các ma trận embedding khác nhau có thể huấn luyện được.

Giả sử embedding của đoạn văn p là (w1,w2,···,w|p|). Bộ mã hóa của chúng tôi sẽ đọc chuỗi đầu vào và tạo ra một chuỗi các trạng thái ẩn h1,h2,···,h|p|, trong đó mỗi trạng thái ẩn là một sự nối của một biểu diễn tiến và một biểu diễn lùi:

hi=[→hi;←hi], (3)
→hi=BiGRU(wi,→hi−1), (4)
←hi=BiGRU(wi,←hi+1). (5)

→hi và ←hi là các trạng thái ẩn tiến và lùi của token thứ i trong p, tương ứng.

Bộ giải mã. Bộ giải mã của chúng tôi là một GRU khác với cơ chế chú ý và sao chép. Ký hiệu vector embedding của phong cách câu hỏi mong muốn s là hs. Chúng tôi khởi tạo trạng thái ẩn của GRU giải mã bằng cách nối hs với trạng thái ẩn lùi cuối cùng của bộ mã hóa ←h1 thành một lớp tuyến tính:

sl=tanh(W0←h1+b), (6)
s0=[hs;sl]. (7)

Tại mỗi bước thời gian giải mã t, bộ giải mã tính toán trạng thái ẩn hiện tại của nó dựa trên vector từ của từ được dự đoán trước đó wt−1, vector bối cảnh chú ý trước đó ct−1, và trạng thái ẩn trước đó st−1:

st=GRU([wt−1;ct−1],st−1), (8)

trong đó vector bối cảnh ct tại bước thời gian t là một tổng có trọng số của các trạng thái ẩn đầu vào, và các trọng số được tính bởi cơ chế chú ý nối [28]:

et,i=v⊺tanh(Wsst+Whhi), (9)
αt,i=exp(et,i)/∑|p|j=1exp(et,j), (10)
ct=∑|p|i=1αt,ihi. (11)

Để tạo sinh một từ đầu ra, chúng tôi kết hợp wt−1, st và ct để tính toán một trạng thái readout rt bằng một lớp maxout MLP với dropout [13], và truyền nó qua một lớp tuyến tính và một lớp softmax để dự đoán xác suất của từ tiếp theo trên một từ vựng:

rt=Wrwwt−1+Wrcct+Wrsst (12)
mt=[max{rt,2j−1,rt,2j}]⊺j=1, . . .,d (13)
p(yt|y1,···,yt−1)=softmax(Womt), (14)

trong đó rt là một vector 2-D.

Đối với cơ chế sao chép hoặc chỉ ra [15], xác suất sao chép một từ từ đầu vào p tại bước thời gian t được đưa ra bởi:

gc=σ(Wcsst+Wccct+b), (15)

trong đó σ là hàm Sigmoid, và gc là xác suất thực hiện sao chép. Xác suất sao chép của mỗi từ đầu vào được đưa ra bởi các trọng số chú ý trong Phương trình (10).

Đã được báo cáo rằng các từ được tạo sinh trong một câu hỏi mục tiêu thường là từ các từ thường xuyên, trong khi đa số các từ tần suất thấp trong đuôi dài được sao chép từ đầu vào thay vì được tạo sinh [27]. Do đó, chúng tôi giảm kích thước từ vựng thành NV từ tần suất cao hàng đầu ở cả bộ mã hóa và bộ giải mã, trong đó NV là một ngưỡng định trước thay đổi giữa các bộ dữ liệu khác nhau. Điều này giúp khuyến khích mô hình học việc sao chép tích cực và cải thiện hiệu suất của việc tạo sinh câu hỏi.

3.2.2 Tạo sinh câu hỏi nhận biết ACS dựa trên GPT2. Các mô hình ngôn ngữ được huấn luyện trước quy mô lớn, như BERT [9], GPT2 [34] và XLNet [49], đã cải thiện đáng kể hiệu suất của một loạt các tác vụ NLP bao gồm cả việc tạo sinh văn bản. Chúng chủ yếu dựa trên kiến trúc Transformer [46] và đã được chứng minh là nắm bắt được nhiều khía cạnh của ngôn ngữ có liên quan đến các tác vụ downstream [6]. So với các mô hình Seq2Seq thường tạo sinh văn bản chứa từ lặp lại, các mô hình ngôn ngữ được huấn luyện trước thu thập kiến thức từ bộ dữ liệu huấn luyện quy mô lớn và có thể tạo sinh văn bản chất lượng cao. Trong công việc của chúng tôi, để tạo ra các câu hỏi với chất lượng tốt hơn và để so sánh với các mô hình dựa trên Seq2Seq, chúng tôi tiếp tục tinh chỉnh mô hình GPT2-small được huấn luyện trước có sẵn công khai [34] theo cài đặt vấn đề của chúng tôi.

Cụ thể, để có được một mô hình tạo sinh câu hỏi ACS với GPT2, chúng tôi nối đoạn văn, đáp án, manh mối và phong cách câu hỏi làm bối cảnh của mô hình hóa ngôn ngữ. Cụ thể, chuỗi đầu vào được tổ chức dưới dạng "<bos> ..văn bản đoạn văn.. <clue> .. đoạn manh mối .. <ans> .. đoạn đáp án .. <style> .. phong cách câu hỏi .. <ques> .. văn bản câu hỏi .. <eos>". Trong quá trình huấn luyện, chúng tôi học một mô hình ngôn ngữ với định dạng đầu vào trên. Khi tạo sinh, chúng tôi lấy mẫu các câu hỏi đầu ra khác nhau bằng cách bắt đầu với một đầu vào dưới dạng "<bos> ..văn bản đoạn văn.. <clue> .. đoạn manh mối .. <ans> .. đoạn đáp án .. <style> .. phong cách câu hỏi .. <ques>". Hình 3 minh họa biểu diễn đầu vào để tinh chỉnh mô hình ngôn ngữ GPT-2. Tương tự như [25], chúng tôi tận dụng embedding đoạn của GPT-2 để biểu thị tính đặc thù của đoạn văn, manh mối, đáp án, phong cách và câu hỏi. Chúng tôi cũng sử dụng embedding đoạn đáp án và embedding đoạn manh mối thay cho embedding đoạn văn tại vị trí của đáp án hoặc manh mối trong đoạn văn để biểu thị vị trí của khoảng đáp án và khoảng manh mối. Trong quá trình tạo sinh, mô hình được huấn luyện sử dụng lấy mẫu nucleus top-p với p=0.9 [20] thay vì tìm kiếm beam và lấy mẫu top-k. Để triển khai, chúng tôi sử dụng codebase của [25] làm điểm khởi đầu, cũng như thư viện Transformers từ HuggingFace [48].

3.3 Lấy mẫu Đầu vào cho Việc Tạo sinh Câu hỏi

Như đã đề cập trong Phần 2, quá trình tạo sinh câu hỏi nhận biết ACS bao gồm lấy mẫu đầu vào và tạo sinh văn bản. Với một kho văn bản không gắn nhãn, chúng ta cần trích xuất các kết hợp <đoạn văn, đáp án, manh mối, phong cách> hợp lệ làm đầu vào để tạo sinh câu hỏi với một mô hình tạo sinh câu hỏi nhận biết ACS.

Trong công việc của chúng tôi, chúng tôi phân tách quá trình lấy mẫu thành ba bước để lần lượt lấy mẫu đáp án ứng viên, phong cách và manh mối dựa trên một đoạn văn cho trước. Chúng tôi đưa ra các giả định sau: i) xác suất của một đoạn a được chọn làm đáp án chỉ phụ thuộc vào thẻ Part-of-Speech (POS), thẻ Nhận dạng Thực thể Có tên (NER) và độ dài (số từ) của đoạn; ii) phong cách s của câu hỏi mục tiêu chỉ phụ thuộc vào thẻ POS và thẻ NER của đáp án đã chọn a; và iii) xác suất chọn một đoạn c làm manh mối phụ thuộc vào thẻ POS và thẻ NER của c, cũng như khoảng cách phụ thuộc giữa đoạn c và a. Chúng tôi tính toán độ dài của đường đi ngắn nhất giữa từ đầu tiên của c và từ đầu tiên của a như khoảng cách phụ thuộc. Trực giác cho việc chỉ định cuối cùng là một đoạn manh mối thường liên quan chặt chẽ với đáp án, và thường được sao chép hoặc diễn đạt lại vào câu hỏi mục tiêu. Do đó, khoảng cách phụ thuộc giữa một manh mối và một đáp án sẽ không lớn [27].

Với các giả định trên, chúng ta sẽ có:

P(a|p)=P(a|POS(a),NER(a),length(a)), (16)
P(s|a,p)=P(s|POS(a),NER(a)), (17)
P(c|s,a,p)=P(c|POS(c),NER(c),DepDist(c,a)), (18)

trong đó DepDist(c,a) biểu thị khoảng cách phụ thuộc giữa token đầu tiên của c và token đầu tiên của a.

Các phân phối xác suất có điều kiện trên có thể được học từ một bộ dữ liệu hiện có (như SQuAD), được đặt tên là bộ dữ liệu tham chiếu. Với một bộ dữ liệu tham chiếu bao gồm các bộ ba <đoạn văn, câu hỏi, đáp án>, đầu tiên, chúng tôi thực hiện gắn thẻ POS, gắn thẻ NER, phân tích cú pháp và phân đoạn trên các đoạn văn đầu vào. Thứ hai, chúng tôi nhận dạng thông tin manh mối và phong cách theo các bước được mô tả trong Phần 3.1, nhận thẻ NER và thẻ POS của cả đoạn đáp án và đoạn manh mối, và tính toán khoảng cách phụ thuộc giữa đoạn manh mối và đoạn đáp án. Cuối cùng, chúng tôi tính toán các phân phối có điều kiện theo thông tin đã trích xuất.

Chúng tôi đặt độ dài tối đa của một đáp án ứng viên là 30, và chia khoảng độ dài thành 10 bins có kích thước bằng nhau để tính P(a|POS(a),NER(a),length(a)). Tương tự, chúng tôi đặt khoảng cách phụ thuộc tối đa giữa một đoạn manh mối và một đoạn đáp án là 20, và chia khoảng khoảng cách thành 10 bins có kích thước bằng nhau để tính P(c|POS(c),NER(c),DepDist(c,a)). Hình 4 cho thấy các phân phối biên chúng tôi nhận được bằng cách sử dụng bộ dữ liệu huấn luyện SQuAD1.1 làm dữ liệu tham chiếu của chúng tôi. Việc gắn thẻ NER được thực hiện bởi spaCy [21], và thẻ "UNK" có nghĩa là đoạn không được nhận dạng là một thực thể có tên. Từ Hình 4(a), chúng ta có thể thấy hầu hết các đáp án đều ngắn, và đa số chúng là các thực thể như người (PERSON), tổ chức (ORG) hoặc ngày tháng (DATE). Từ Hình 4(b), chúng ta có thể thấy khoảng cách phụ thuộc cú pháp giữa một đoạn manh mối và một đáp án thường nhỏ hơn 8, điều này phù hợp với trực giác của chúng tôi rằng một manh mối cần được tương quan với đáp án để nó sẽ được sao chép hoặc diễn đạt lại trong câu hỏi mục tiêu. Cuối cùng, Hình 4(c) cho thấy hầu hết các câu hỏi là phong cách "What", và tiếp theo là "Who", "How" và "When". Các thẻ NER của đáp án có tương quan cao với phong cách của câu hỏi. Ngoài ra, chúng ta cần lưu ý rằng hiệu suất NER của spaCy không hoàn hảo. Do đó, chúng ta có thể quan sát các trường hợp kỳ lạ như tổ chức (ORG) khớp với "Who". Việc xác định các phân phối có điều kiện khác nhau với một bộ dữ liệu tham chiếu thay vì tuân theo các quy tắc định trước giúp chúng ta tính đến những loại nhiễu như vậy.

Sau khi tính toán các phân phối trên theo một bộ dữ liệu tham chiếu, chúng ta có thể lấy mẫu thông tin khác nhau với một đoạn văn p. Đầu tiên, chúng ta nhận tất cả các đoạn ứng viên K={k1,k2,···,k|K|} bằng cách phân tích cú pháp và phân đoạn trên p. Thứ hai, chúng ta lấy mẫu một đoạn ki làm đáp án theo phân phối xác suất được chuẩn hóa trên tất cả các đoạn:

P(ki)=P(ki|POS(ki),NER(ki),length(ki))/∑|K|j=1P(kj|POS(kj),NER(kj),length(kj)). (19)

Thứ ba, chúng ta lấy mẫu một phong cách câu hỏi si trên tất cả các phong cách câu hỏi có thể S={s1,s2,···,s|S|} bằng xác suất được chuẩn hóa:

P(si)=P(si|POS(ki),NER(ki))/∑|S|j=1P(sj|POS(ki),NER(ki)). (20)

Cuối cùng, chúng ta lấy mẫu một đoạn kl làm manh mối theo:

P(kl)=P(kl|POS(kl),NER(kl),DepDist(kl,ki))/∑|K|j=1P(kj|POS(kj),NER(kj),DepDist(kj,ki)). (21)

Chúng ta có thể lặp lại các bước trên nhiều lần để nhận được các đầu vào khác nhau từ cùng một đoạn văn và tạo sinh các câu hỏi đa dạng. Trong công việc của chúng tôi, đối với mỗi đoạn văn đầu vào, chúng tôi lấy mẫu 5 đoạn khác nhau làm khoảng đáp án, 2 phong cách câu hỏi khác nhau cho mỗi đáp án, và 2 manh mối khác nhau cho mỗi đáp án. Bằng cách này, chúng tôi tạo sinh quá mức câu hỏi bằng cách lấy mẫu 20 câu hỏi cho mỗi câu.

3.4 Lọc Dữ liệu để Kiểm soát Chất lượng

Sau khi lấy mẫu nhiều đầu vào từ mỗi câu, chúng ta có thể tạo sinh các câu hỏi khác nhau dựa trên các đầu vào. Tuy nhiên, rất khó để đặt cho mỗi câu 20 câu hỏi có ý nghĩa và khác nhau ngay cả khi được đưa ra 20 đầu vào khác nhau từ nó, vì các câu hỏi có thể bị trùng lặp do các đầu vào tương tự, hoặc các câu hỏi có thể vô nghĩa nếu kết hợp <đáp án, manh mối, phong cách> không hợp lý. Do đó, chúng tôi sử dụng thêm một bộ lọc để loại bỏ các cặp QA chất lượng thấp.

Chúng tôi tận dụng một mô hình suy diễn và một mô hình QA dựa trên BERT [9]. Đối với mô hình suy diễn, vì bộ dữ liệu SQuAD 2.0 [35] chứa các câu hỏi không thể trả lời, chúng tôi sử dụng nó để huấn luyện một bộ phân loại cho chúng tôi biết liệu một cặp <câu hỏi, đáp án> có khớp với nội dung trong đoạn văn đầu vào hay không. Đối với mô hình hỏi đáp, chúng tôi tinh chỉnh một mô hình QA dựa trên BERT khác sử dụng bộ dữ liệu SQuAD 1.1 [36].

Với một mẫu <đoạn văn, câu hỏi, đáp án>, chúng tôi giữ nó nếu mẫu này thỏa mãn hai tiêu chí: đầu tiên, nó được phân loại là tích cực theo mô hình suy diễn dựa trên BERT; thứ hai, điểm tương tự F1 giữa khoảng đáp án vàng và khoảng đáp án được dự đoán bởi QA dựa trên BERT trên 0.9. Lưu ý rằng chúng tôi không chọn tinh chỉnh một mô hình QA dựa trên BERT trên SQuAD 2.0 để thực hiện suy diễn và hỏi đáp cùng một lúc. Đó là vì chúng tôi có được hiệu suất tốt hơn bằng cách tách bước suy diễn với bước lọc QA. Bên cạnh đó, chúng ta có thể sử dụng các bộ dữ liệu bổ sung từ các tác vụ suy diễn khác để tăng cường mô hình suy diễn và cải thiện thêm bộ lọc dữ liệu.

4 ĐÁNH GIÁ

Trong phần này, chúng tôi so sánh việc tạo sinh câu hỏi nhận biết ACS được đề xuất của chúng tôi với các mô hình tạo sinh câu hỏi nhận biết đáp án để cho thấy lợi ích của nó. Chúng tôi tạo sinh một số lượng lớn cặp QA từ kho văn bản không gắn nhãn bằng cách sử dụng các mô hình của chúng tôi, và thực hiện thêm nhiều đánh giá khác nhau để phân tích chất lượng của dữ liệu được tạo sinh. Cuối cùng, chúng tôi kiểm tra hiệu suất của các mô hình QA được huấn luyện trên bộ dữ liệu được tạo sinh của chúng tôi, và cho thấy các ứng dụng tiềm năng và hướng tương lai của công việc này.

4.1 Đánh giá Tạo sinh Câu hỏi Nhận biết ACS

Bộ dữ liệu, Chỉ số và Baseline. Chúng tôi đánh giá hiệu suất của việc tạo sinh câu hỏi nhận biết ACS dựa trên bộ dữ liệu SQuAD [36]. Đây là một bộ dữ liệu đọc hiểu chứa các câu hỏi được rút ra từ các bài viết Wikipedia, và đáp án cho mỗi câu hỏi là một đoạn văn bản từ đoạn văn đọc tương ứng. Trong công việc của chúng tôi, chúng tôi sử dụng phân chia dữ liệu được đề xuất bởi [53], trong đó đầu vào là câu chứa đáp án. Tập huấn luyện chứa 86,635 mẫu, và tập dev gốc chứa 17,929 mẫu được chia ngẫu nhiên thành một tập dev test và một tập test có kích thước bằng nhau. Độ dài trung bình (số từ) của câu, câu hỏi và đáp án lần lượt là 32.72, 11.31, và 3.19.

Hiệu suất của việc tạo sinh câu hỏi được đánh giá bằng các chỉ số sau.

• BLEU [31]. BLEU đo độ chính xác bằng cách xem bao nhiều từ trong dự đoán xuất hiện trong câu tham chiếu. BLEU-1 (B1), BLEU-2 (B2), BLEU-3 (B3), và BLEU-4 (B4), sử dụng 1-gram đến 4-gram để tính toán, tương ứng.

• ROUGE-L [26]. ROUGE-L đo recall bằng cách xem bao nhiều từ trong câu tham chiếu xuất hiện trong dự đoán sử dụng thống kê dựa trên Chuỗi Con Chung Dài nhất (LCS).

• METEOR [8]. METEOR dựa trên trung bình điều hòa của độ chính xác và recall unigram, với recall được cân nặng cao hơn độ chính xác.

Chúng tôi so sánh các phương pháp của mình với các baseline sau.

• PCFG-Trans [18]: một hệ thống tạo sinh câu hỏi nhận biết đáp án dựa trên quy tắc.

• SeqCopyNet [54], NQG++ [53], AFPA [42], seq2seq+z+c+GAN [50], và s2sa-at-mp-gsa [52]: các mô hình tạo sinh câu hỏi neural nhận biết đáp án dựa trên khung Seq2Seq.

• NQG-Knowledge [16], DLPH [12]: các mô hình tạo sinh câu hỏi được tăng cường thông tin phụ trợ với các đầu vào bổ sung như kiến thức hoặc độ khó.

• Self-training-EE [38], BERT-QG-QAP [51], NQG-LM [55], CGC-QG [27] và QType-Predict [56]: các mô hình tạo sinh câu hỏi đa tác vụ với các tác vụ phụ trợ như hỏi đáp, mô hình hóa ngôn ngữ, dự đoán loại câu hỏi và vân vân.

Hiệu suất được báo cáo của các baseline được sao chép trực tiếp từ các bài báo của họ hoặc được đánh giá bằng mã đã xuất bản của họ trên GitHub.

Đối với các mô hình của chúng tôi, chúng tôi đánh giá các phiên bản sau:

• CS2S-VR-A. Mô hình Seq2Seq tách nội dung với Giảm Từ vựng cho việc tạo sinh câu hỏi Nhận biết đáp án. Trong biến thể này, chúng tôi kết hợp embedding nội dung trong biểu diễn từ để chỉ ra mỗi từ là từ nội dung hay từ chức năng. Bên cạnh đó, chúng tôi giảm kích thước từ vựng bằng cách chỉ giữ lại 2000 từ thường xuyên hàng đầu cho bộ mã hóa và giải mã. Bằng cách này, các từ tần suất thấp được biểu diễn bởi embedding NER, POS và embedding đặc trưng của nó. Chúng tôi cũng thêm embedding vị trí đáp án để chỉ ra khoảng đáp án trong các đoạn văn đầu vào.

• CS2S-AS. Mô hình này thêm embedding phong cách câu hỏi để khởi tạo bộ giải mã, không có giảm từ vựng (kích thước từ vựng là 20,000 khi chúng tôi không khai thác giảm từ vựng).

• CS2S-AC. Biến thể thêm embedding manh mối trong bộ mã hóa để chỉ ra khoảng của đoạn manh mối.

• CS2S-ACS. Biến thể này thêm cả embedding manh mối trong bộ mã hóa và embedding phong cách trong bộ giải mã.

• CS2S-VR-ACS. Đây là mô hình đầy đủ tính năng với embedding đáp án, manh mối và phong cách, cũng như giảm từ vựng.

• GPT2-ACS. Đây là mô hình GPT2-small được tinh chỉnh của chúng tôi cho việc tạo sinh câu hỏi nhận biết ACS.

Cài đặt Thí nghiệm. Chúng tôi triển khai các mô hình của mình trong PyTorch 1.1.0 [32] và Transformers 2.0.0 [48], và huấn luyện mô hình với hai Tesla P40. Chúng tôi sử dụng spaCy [29] để thực hiện phân tích cú pháp phụ thuộc và trích xuất các đặc trưng từ vựng cho các token. Đối với các mô hình dựa trên Seq2Seq, chúng tôi đặt embedding từ thành 300 chiều và khởi tạo chúng bằng GloVe, và đặt chúng có thể huấn luyện được. Các từ ngoài từ vựng được khởi tạo ngẫu nhiên. Tất cả các đặc trưng khác được nhúng thành các vector 16 chiều. Bộ mã hóa là một BiGRU một lớp với kích thước ẩn 512, và bộ giải mã là một GRU một lớp không định hướng với kích thước ẩn 512. Chúng tôi đặt tỷ lệ dropout p=0.1 cho bộ mã hóa, bộ giải mã và mô-đun chú ý. Chúng tôi huấn luyện các mô hình bằng Cross-Entropy loss cho việc tạo sinh câu hỏi và sao chép câu hỏi, và thực hiện gradient descent bằng optimizer Adam [24] với tỷ lệ học ban đầu lr=0.001, hai tham số momentum là β1=0.8 và β2=0.999 tương ứng, và ϵ=10^-8. Kích thước mini-batch cho mỗi cập nhật được đặt thành 32 và mô hình được huấn luyện trong tối đa 10 epoch. Gradient clipping với phạm vi [-5,5] được áp dụng cho Adam. Độ rộng beam được đặt thành 20 cho việc giải mã. Quá trình giải mã dừng khi token <EOS> (biểu thị kết thúc câu) được tạo sinh.

Đối với mô hình GPT2-ACS, chúng tôi tinh chỉnh mô hình GPT2-small sử dụng bộ dữ liệu huấn luyện SQuAD 1.1 từ [53]. Chúng tôi tinh chỉnh mô hình trong 4 epoch với kích thước batch 2, và áp dụng lấy mẫu nucleus top-p với p=0.9 khi giải mã. Đối với bộ lọc dựa trên BERT, chúng tôi tinh chỉnh mô hình BERT-large-uncased từ HuggingFace [48] với các tham số được gợi ý bởi [48] để huấn luyện trên SQuAD 1.1 và SQuAD 2.0. Mã của chúng tôi sẽ được xuất bản cho mục đích nghiên cứu.

Kết quả Chính. Bảng 1 so sánh các mô hình của chúng tôi với các phương pháp baseline. Chúng ta có thể thấy CS2S-VR-ACS của chúng tôi đạt được hiệu suất tốt nhất về các chỉ số đánh giá và vượt trội hơn các baseline với một khoảng cách lớn. So sánh CS2S-VR-A với các baseline QG nhận biết đáp án dựa trên Seq2Seq, chúng ta có thể thấy nó vượt trội hơn tất cả các phương pháp baseline trong danh mục đó với cùng thông tin đầu vào (đoạn văn đầu vào và khoảng đáp án). Điều này là do chiến lược tách nội dung và thao tác giảm từ vựng của chúng tôi giúp mô hình học tốt hơn những từ nào cần sao chép từ các đầu vào. So sánh các mô hình và biến thể QG nhận biết ACS của chúng tôi với các mô hình được tăng cường thông tin phụ trợ (như NQG-Knowledge và DLPH) và các baseline được tăng cường tác vụ phụ trợ (như BERT-QG-QAP), chúng ta có thể thấy thông tin manh mối và phong cách giúp tạo ra kết quả tốt hơn so với các mô hình có thông tin kiến thức hoặc độ khó. Đó là vì cài đặt nhận biết ACS của chúng tôi làm cho vấn đề tạo sinh câu hỏi gần hơn với ánh xạ một-đối-một, và giảm đáng kể độ khó của tác vụ.

So sánh GPT2-ACS với CS2S-VR-ACS, chúng ta có thể thấy GPT2-ACS đạt được điểm METEOR tốt hơn, trong khi CS2S-VR-ACS hoạt động tốt hơn về điểm BLEU và ROUGE-L. Đó là vì GPT2-ACS không có giảm từ vựng. Do đó, các từ được tạo sinh linh hoạt hơn. Tuy nhiên, các chỉ số như điểm BLEU không thể đánh giá chất lượng của các cặp QA được tạo sinh về mặt ngữ nghĩa. Do đó, trong phần tiếp theo, chúng tôi phân tích thêm chất lượng của các cặp QA được tạo sinh bởi CS2S-VR-ACS và GPT2-ACS để xác định điểm mạnh và điểm yếu của chúng.

4.2 Phân tích Định tính

Sau khi huấn luyện các mô hình CS2S-VR-ACS và GPT2-ACS của chúng tôi, chúng tôi tạo sinh các bộ dữ liệu <đoạn văn, câu hỏi, đáp án> quy mô lớn từ kho văn bản không gắn nhãn. Cụ thể, chúng tôi thu thập 10,000 bài viết Wikipedia tiếng Anh hàng đầu với PageRank nội bộ của Wikipedia của Project Nayuki. Sau đó, chúng tôi chia mỗi bài viết trong kho thành các câu, và lọc ra các câu có độ dài ngắn hơn 5 hoặc dài hơn 100. Dựa trên những câu này, chúng tôi thực hiện lấy mẫu đầu vào để lấy mẫu các bộ ba <đáp án, manh mối, phong cách> cho mỗi câu theo các bước được mô tả trong Phần 3.3, và cung cấp chúng vào các mô hình của chúng tôi để tạo sinh câu hỏi. Sau khi lọc, chúng tôi tạo ra hai bộ dữ liệu sử dụng hai mô hình, trong đó mỗi bộ dữ liệu chứa khoảng 1.4 triệu câu hỏi được tạo sinh.

Đầu tiên chúng tôi đánh giá chất lượng của các cặp QA được tạo sinh thông qua đánh giá tự nguyện của con người. Chúng tôi yêu cầu 10 sinh viên sau đại học đánh giá 500 mẫu <đoạn văn, câu hỏi, đáp án>: 200 mẫu được tạo sinh bởi mô hình CS2S-VR-ACS, 200 mẫu được tạo sinh bởi mô hình GPT2-ACS, và 100 mẫu sự thật từ bộ dữ liệu huấn luyện SQuAD 1.1. Tất cả các mẫu được xáo trộn ngẫu nhiên, và mỗi mẫu sẽ được đánh giá bởi 3 tình nguyện viên. Chúng tôi thu thập phản hồi của bảng câu hỏi sau:

• Câu hỏi có được cấu tạo tốt không? Điều này để kiểm tra xem một câu hỏi đã cho có vừa đúng ngữ pháp và có ý nghĩa hay không [25]. Người làm sẽ chọn yes, no, hoặc understandable. Tùy chọn understandable được chọn nếu một câu hỏi không hoàn toàn đúng ngữ pháp, nhưng chúng ta có thể suy ra ý nghĩa của nó.

• Nếu câu hỏi được cấu tạo tốt hoặc có thể hiểu được, câu hỏi có liên quan đến đoạn văn không? Người làm sẽ chọn yes nếu chúng ta có thể tìm thấy đáp án cho câu hỏi được tạo sinh trong đoạn văn.

• Nếu câu hỏi liên quan đến đoạn văn, đáp án có thực sự là một đáp án hợp lệ cho câu hỏi được tạo sinh không? Người làm sẽ chọn yes, no hoặc partially. Tùy chọn cuối cùng biểu thị rằng đáp án trong mẫu được tạo sinh của chúng tôi chồng lắp một phần với đáp án thực trong đoạn văn.

Bảng 2 cho thấy kết quả đánh giá dựa trên dữ liệu được lấy mẫu. Đầu tiên, chúng ta có thể thấy ngay cả các mẫu sự thật từ bộ dữ liệu SQuAD cũng không hoàn toàn được cấu tạo tốt, liên quan hoặc được trả lời chính xác. Đó là vì chúng tôi chỉ sử dụng câu chứa khoảng đáp án làm bối cảnh. Tuy nhiên, khoảng 20% câu hỏi trong SQuAD yêu cầu bối cảnh cấp đoạn văn để được đặt [11]. Thứ hai, 94% câu hỏi được tạo sinh bởi GPT2-ACS được cấu tạo tốt hoặc có thể hiểu được, trong khi tỷ lệ phần trăm là 71.5% cho mô hình CS2S-VR-ACS. Chúng ta có thể thấy rằng mặc dù điểm BLEU của mô hình GPT2-ACS thấp hơn CS2S-VR-ACS, kết quả của GPT2-ACS tốt hơn về mặt ngữ nghĩa do kiến thức học được từ việc huấn luyện trước quy mô lớn. Thứ ba, chúng ta có thể thấy hầu hết các câu hỏi được tạo sinh bởi cả CS2S-VR-ACS và GPT2-ACS đều liên quan đến các đoạn văn đầu vào. Cuối cùng, hầu hết các đáp án cũng đúng với các câu hỏi được tạo sinh. Điều này chứng minh chất lượng cao của các cặp câu hỏi-đáp án được tạo sinh bởi các mô hình của chúng tôi.

Hình 5 là một ví dụ chạy để cho thấy các tính chất của các câu hỏi được tạo sinh. Chúng ta có thể thấy các mô hình tạo sinh câu hỏi nhận biết ACS của chúng tôi có thể tạo sinh các câu hỏi khác nhau dựa trên các đáp án, phong cách câu hỏi và đoạn manh mối khác nhau. So với việc tạo sinh câu hỏi nhận biết đáp án, quá trình tạo sinh của chúng tôi có thể kiểm soát hơn, và các câu hỏi được tạo sinh của chúng tôi đa dạng hơn và chất lượng cao hơn. Trong một số trường hợp, khoảng đáp án không khớp với câu hỏi. Chúng tôi tiếp tục thực hiện các nghiên cứu người dùng thí điểm để phân tích các trường hợp xấu trong các mẫu được tạo sinh của chúng tôi. Đối với mỗi câu hỏi không được cấu tạo tốt, chúng tôi yêu cầu người làm gắn nhãn điểm yếu của nó. Kết quả của nghiên cứu cho thấy hầu hết các lỗi là lỗi ngữ pháp, không khớp loại, vô nghĩa, hoặc thông tin không đầy đủ. Đối với CS2S-VR-ACS, khoảng 56.7% các trường hợp xấu là không đúng ngữ pháp; 29.2% trong số chúng có vấn đề không khớp loại, ví dụ: câu hỏi được tạo sinh bắt đầu bằng "When" khi hỏi câu hỏi về một người; 14.2% trong số chúng đúng ngữ pháp, nhưng vô nghĩa; và 17.5% các câu hỏi không diễn đạt ý nghĩa của chúng một cách rõ ràng do thiếu từ hoặc đại từ mơ hồ. Tương tự, đối với GPT2-ACS, tỷ lệ phần trăm của bốn vấn đề trên là 40.4% (không đúng ngữ pháp), 46.2% (không khớp loại), 15.4% (vô nghĩa) và 11.6% (thông tin không đầy đủ hoặc mơ hồ). Lưu ý rằng tổng của các tỷ lệ phần trăm này không bằng 1. Đó là vì mỗi câu hỏi có thể được gắn nhãn với nhiều loại điểm yếu.

Để giảm các lỗi khác nhau và cải thiện thêm chất lượng của các câu hỏi được tạo sinh, đầu tiên, chúng ta cần kết hợp kiến thức về ngôn ngữ tự nhiên bằng các phương pháp như huấn luyện trước quy mô lớn. Chúng ta có thể quan sát từ Bảng 2 rằng hầu hết các câu hỏi được tạo sinh bởi GPT2-ACS được cấu tạo tốt và đúng ngữ pháp. Thứ hai, chúng ta có thể sử dụng một mô hình nhận dạng thực thể có tên tốt hơn để cung cấp thông tin chính xác hơn về các loại thực thể có tên của các đoạn đáp án. Bằng cách này, các lỗi không khớp loại sẽ được giảm. Cuối cùng nhưng không kém phần quan trọng, vấn đề về sự không khớp ngữ nghĩa, vô nghĩa, hoặc thông tin không đầy đủ có thể được giảm bằng cách huấn luyện một mô hình suy diễn tốt hơn để tăng cường bộ lọc dữ liệu.

4.3 Áp dụng cho Hỏi Đáp

Chúng tôi cũng thực hiện kiểm tra chất lượng của các cặp câu hỏi-đáp án được tạo sinh bằng cách áp dụng chúng vào các tác vụ đọc hiểu máy downstream. Cụ thể, chúng tôi huấn luyện các mô hình hỏi đáp dựa trên BERT khác nhau dựa trên các cài đặt sau:

• SQuAD: trong thí nghiệm này, chúng tôi sử dụng bộ dữ liệu huấn luyện SQuAD 1.1 gốc để huấn luyện một mô hình QA dựa trên BERT, và kiểm tra hiệu suất trên bộ dữ liệu dev. Hiệu suất được đánh giá bằng exact match (EM) và F1-Score (F1) giữa khoảng đáp án được dự đoán và khoảng đáp án thực [36].

• Generated: trong thí nghiệm này, chúng tôi lấy mẫu một bộ dữ liệu huấn luyện từ các câu hỏi được tạo sinh của chúng tôi, trong đó kích thước bằng với bộ dữ liệu huấn luyện của SQuAD 1.1. Mặc dù các câu hỏi của chúng tôi được tạo sinh từ các câu, chúng tôi sử dụng các đoạn văn mà các câu thuộc về làm bối cảnh khi huấn luyện các mô hình QA.

• Generated + SQuAD: trong thí nghiệm này, chúng tôi kết hợp bộ dữ liệu huấn luyện SQuAD gốc với bộ dữ liệu huấn luyện được tạo sinh của chúng tôi để huấn luyện mô hình QA dựa trên BERT.

Đối với tất cả các thí nghiệm QA, các cấu hình đều giống nhau ngoại trừ các bộ dữ liệu huấn luyện.

Bảng 3 so sánh hiệu suất của các mô hình QA dựa trên BERT kết quả được huấn luyện bằng các cài đặt trên. Việc triển khai của chúng tôi cho 86.72% EM và 92.97% F1 khi được huấn luyện trên bộ dữ liệu SQuAD gốc. Để so sánh, mô hình được huấn luyện bởi bộ dữ liệu được tạo sinh của chúng tôi cho 74.47% và 85.64% F1. Khi chúng tôi kết hợp bộ dữ liệu được tạo sinh với tập huấn luyện SQuAD để huấn luyện mô hình QA, hiệu suất không được cải thiện thêm. Kết quả là hợp lý. Đầu tiên, bộ dữ liệu được tạo sinh chứa nhiễu sẽ ảnh hưởng đến hiệu suất. Thứ hai, việc đơn giản tăng kích thước của bộ dữ liệu huấn luyện sẽ không luôn luôn giúp cải thiện hiệu suất. Nếu hầu hết các mẫu huấn luyện được tạo sinh đã có thể được trả lời bởi mô hình được huấn luyện trên bộ dữ liệu SQuAD gốc, chúng không hữu ích lắm để tăng cường thêm khả năng tổng quát của mô hình.

Có ít nhất hai phương pháp để tận dụng bộ dữ liệu được tạo sinh để cải thiện hiệu suất của các mô hình QA. Đầu tiên, chúng ta có thể sử dụng các thuật toán học chương trình [2] để chọn mẫu trong quá trình huấn luyện. Chúng ta có thể chọn mẫu theo trạng thái hiện tại của mô hình và độ khó của các mẫu để tăng cường thêm hiệu suất của mô hình. Lưu ý rằng điều này yêu cầu chúng ta loại bỏ mô hình QA dựa trên BERT khỏi bộ lọc dữ liệu của chúng ta, hoặc đặt ngưỡng của điểm F1 lọc nhỏ hơn. Thứ hai, tương tự như [12], chúng ta có thể kết hợp thêm thông tin độ khó vào các mô hình tạo sinh câu hỏi của chúng ta, và khuyến khích mô hình tạo sinh các cặp câu hỏi-đáp án khó hơn. Chúng tôi để lại những điều này cho các công việc tương lai của chúng tôi.

Ngoài đọc hiểu máy, hệ thống của chúng tôi có thể được áp dụng cho nhiều ứng dụng khác. Đầu tiên, chúng ta có thể sử dụng nó để tạo sinh bài tập cho mục đích giáo dục. Thứ hai, chúng ta có thể sử dụng hệ thống của chúng tôi để tạo sinh các bộ dữ liệu huấn luyện cho một lĩnh vực mới bằng cách tinh chỉnh nó với một lượng nhỏ dữ liệu được gắn nhãn từ lĩnh vực đó. Điều này sẽ giảm đáng kể nỗ lực con người khi chúng ta cần xây dựng một bộ dữ liệu cho một lĩnh vực mới. Cuối cùng nhưng không kém phần quan trọng, quy trình của chúng tôi có thể được điều chỉnh cho các tác vụ tương tự như tạo sinh bình luận, tạo sinh truy vấn và vân vân.

5 CÔNG VIỆC LIÊN QUAN

Trong phần này, chúng tôi xem xét các công việc liên quan về tạo sinh câu hỏi.

Tạo sinh Câu hỏi Dựa trên Quy tắc. Các phương pháp dựa trên quy tắc dựa vào các quy tắc được thiết kế tốt hoặc các mẫu được tạo thủ công bởi con người để chuyển đổi một đoạn văn bản đã cho thành câu hỏi [4,18,19]. Các bước chính bao gồm tiền xử lý văn bản đã cho để chọn mục tiêu để hỏi về, và tạo sinh câu hỏi dựa trên quy tắc hoặc mẫu [42]. Tuy nhiên, chúng yêu cầu tạo ra quy tắc và mẫu bởi các chuyên gia rất đắt đỏ. Ngoài ra, quy tắc và mẫu thiếu sự đa dạng và khó tổng quát hóa sang các lĩnh vực khác nhau.

Tạo sinh Câu hỏi Nhận biết Đáp án. Các mô hình tạo sinh câu hỏi neural được huấn luyện đầu cuối đến cuối và không dựa vào quy tắc hoặc mẫu được chế tác thủ công. Vấn đề thường được công thức hóa như việc tạo sinh câu hỏi nhận biết đáp án, trong đó vị trí của đáp án được cung cấp như đầu vào. Hầu hết chúng tận dụng khung encoder-decoder với cơ chế chú ý [10,11,22,27,39,41,53]. Các phương pháp khác nhau kết hợp thông tin đáp án vào mô hình tạo sinh bằng các chiến lược khác nhau, như chỉ số vị trí đáp án [27,53], mã hóa đáp án riêng biệt [23], nhúng khoảng cách tương đối giữa các từ bối cảnh và đáp án [42] và vân vân. Tuy nhiên, với thông tin bối cảnh và đáp án làm đầu vào, vấn đề tạo sinh câu hỏi vẫn là một vấn đề ánh xạ một-đối-nhiều, vì chúng ta có thể hỏi các câu hỏi khác nhau với cùng đầu vào.

Tạo sinh Câu hỏi Được Tăng cường Thông tin Phụ trợ. Để cải thiện chất lượng của các câu hỏi được tạo sinh, các nhà nghiên cứu cố gắng cung cấp cho bộ mã hóa thông tin bổ sung. [12] nhằm tạo sinh câu hỏi ở các mức độ khó khác nhau. Nó học một bộ ước tính độ khó để nhận dữ liệu huấn luyện, và cung cấp độ khó làm đầu vào vào mô hình tạo sinh. [25] học tạo sinh câu hỏi "tổng quát" hoặc "cụ thể" về một tài liệu, và họ sử dụng mẫu và huấn luyện bộ phân loại để nhận nhãn loại câu hỏi cho các bộ dữ liệu hiện có. [22] xác định nội dung được chia sẻ bởi một cặp câu hỏi và đáp án đã cho như một khía cạnh, và học một mô hình tạo sinh câu hỏi dựa trên khía cạnh. [16] kết hợp thông tin cơ sở kiến thức để đặt câu hỏi. So với các công việc này, công việc của chúng tôi không yêu cầu gắn nhãn bổ sung hoặc chi phí huấn luyện để nhận bộ dữ liệu huấn luyện. Bên cạnh đó, cài đặt của chúng tôi cho việc tạo sinh câu hỏi giảm đáng kể độ khó của tác vụ, và đạt được hiệu suất tốt hơn nhiều.

Tạo sinh Câu hỏi Đa tác vụ. Một chiến lược khác là tăng cường các mô hình tạo sinh câu hỏi với các tác vụ tương quan. Huấn luyện chung của các mô hình tạo sinh câu hỏi và trả lời đã cải thiện hiệu suất của các tác vụ riêng lẻ [38,44,45,47]. [27] dự đoán chung các từ trong đầu vào có liên quan đến khía cạnh của câu hỏi đầu ra mục tiêu và sẽ được sao chép vào câu hỏi. [56] dự đoán loại câu hỏi dựa trên đáp án và bối cảnh đầu vào. [55] kết hợp tác vụ mô hình hóa ngôn ngữ để giúp tạo sinh câu hỏi. [51] sử dụng các tác vụ diễn đạt lại câu hỏi và hỏi đáp để điều chỉnh mô hình QG tạo sinh các câu hỏi hợp lệ về mặt ngữ nghĩa.

6 KẾT LUẬN

Trong bài báo này, chúng tôi đề xuất việc tạo sinh câu hỏi nhận biết ACS, một cơ chế để tạo sinh các cặp câu hỏi-đáp án từ kho văn bản không gắn nhãn một cách có thể mở rộng. Bằng cách lấy mẫu các bộ ba có ý nghĩa của manh mối, đáp án và phong cách câu hỏi từ văn bản đầu vào và sử dụng các bộ ba được lấy mẫu để hạn chế cách một câu hỏi được đặt, chúng tôi đã chuyển đổi hiệu quả vấn đề tạo sinh câu hỏi một-đối-nhiều ban đầu thành vấn đề ánh xạ một-đối-một. Chúng tôi đề xuất hai mô hình mạng neural để tạo sinh câu hỏi từ đoạn văn đầu vào với manh mối, đáp án và phong cách câu hỏi đã chọn, cũng như các bộ phân biệt để kiểm soát chất lượng tạo sinh dữ liệu.

Chúng tôi trình bày đánh giá hiệu suất mở rộng của hệ thống và mô hình được đề xuất. So với các mô hình tạo sinh câu hỏi nhận biết đáp án hiện có và các mô hình với đầu vào hoặc tác vụ phụ trợ, mô hình QG nhận biết ACS của chúng tôi đạt được hiệu suất tốt hơn đáng kể, điều này xác nhận tầm quan trọng của thông tin manh mối và phong cách. Chúng tôi tiếp tục sử dụng đánh giá tự nguyện của con người để đánh giá chất lượng của dữ liệu được tạo sinh. Kết quả cho thấy mô hình của chúng tôi có thể tạo sinh các câu hỏi đa dạng và chất lượng cao ngay cả từ cùng một câu đầu vào. Cuối cùng, chúng tôi chỉ ra các hướng tương lai tiềm năng để cải thiện thêm hiệu suất của quy trình của chúng tôi.

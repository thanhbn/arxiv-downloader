DUQGen: Thích ứng miền không có giám sát hiệu quả của các bộ xếp hạng neural bằng cách đa dạng hóa việc tạo ra truy vấn tổng hợp

Ramraj Chandradevan, Kaustubh D. Dhole, Eugene Agichtein
Khoa Khoa học Máy tính
Đại học Emory
Atlanta, USA-30307
{rchan31,kdhole,yagicht}@emory.edu

Tóm tắt
Các bộ xếp hạng neural tiên tiến được huấn luyện trước trên dữ liệu huấn luyện lớn chuyên biệt cho tác vụ như MS-MARCO, đã được chứng minh thể hiện hiệu suất mạnh mẽ trên các tác vụ xếp hạng khác nhau mà không cần thích ứng miền, còn được gọi là zero-shot. Tuy nhiên, xếp hạng neural zero-shot có thể không tối ưu, vì nó không tận dụng được thông tin miền đích. Thật không may, việc thu thập dữ liệu huấn luyện đích đủ lớn và chất lượng cao để cải thiện một bộ xếp hạng neural hiện đại có thể tốn kém và mất thời gian. Để giải quyết vấn đề này, chúng tôi đề xuất một phương pháp mới cho thích ứng miền không có giám sát cho xếp hạng, DUQGen, nhằm giải quyết một khoảng trống quan trọng trong tài liệu trước đây, cụ thể là làm thế nào để tự động tạo ra dữ liệu huấn luyện tổng hợp vừa hiệu quả vừa đa dạng để tinh chỉnh một bộ xếp hạng neural hiện đại cho một miền mới. Cụ thể, DUQGen tạo ra một biểu diễn hiệu quả hơn của miền đích bằng cách xác định các cụm tài liệu tương tự; và tạo ra một tập dữ liệu huấn luyện đa dạng hơn bằng cách lấy mẫu xác suất trên các cụm tài liệu kết quả. Các thí nghiệm rộng rãi của chúng tôi, trên bộ sưu tập BEIR tiêu chuẩn, chứng minh rằng DUQGen luôn vượt trội hơn tất cả các baseline zero-shot và vượt trội đáng kể so với các baseline SOTA trên 16 trong số 18 tập dữ liệu, với mức cải thiện tương đối trung bình 4% trên tất cả các tập dữ liệu. Chúng tôi bổ sung kết quả của mình với một phân tích kỹ lưỡng để hiểu sâu hơn về hiệu suất của phương pháp được đề xuất và xác định các lĩnh vực hứa hẹn cho những cải tiến tiếp theo.

1 Giới thiệu
Các Mô hình Ngôn ngữ Lớn (LLM) đã cho phép hiệu suất tiên tiến mới trong xếp hạng neural (Yan et al., 2019; Kamps et al., 2020; Hu et al., 2022; Nogueira et al., 2020a). Một phương pháp hiệu quả là huấn luyện các LLM trên một tác vụ xếp hạng tổng quát quy mô lớn như xếp hạng đoạn văn hoặc tài liệu MS-MARCO (Bajaj et al., 2016) hoặc truy xuất Wikipedia (Sun và Duh, 2020), để học các đặc trưng chuyên biệt cho tác vụ, thường được chia sẻ qua các miền và tập dữ liệu khác. Các bộ xếp hạng kết quả sau đó có thể được sử dụng, mà không cần bất kỳ thích ứng nào (hoặc theo cách zero-shot) cho một loạt rộng các tác vụ xếp hạng. Ví dụ, benchmark BEIR (Thakur et al., 2021) đã chứng minh hiệu suất SOTA hoặc gần-SOTA của một số bộ xếp hạng neural zero-shot trên một tập đa dạng các tác vụ truy xuất.

Tuy nhiên, khi chuyển sang các miền chuyên biệt như tài liệu tài chính hoặc khoa học, hiệu suất xếp hạng zero-shot nên được hưởng lợi từ thông tin bổ sung cho miền đích. Để huấn luyện các bộ xếp hạng neural hiện đại, việc thu thập dữ liệu huấn luyện đích đủ lớn và chất lượng cao của các cặp truy vấn-tài liệu, để cải thiện một bộ xếp hạng neural hiện đại, có thể tốn kém và mất thời gian. Do đó, đã có sự quan tâm đáng kể đến các phương pháp khác nhau cho thích ứng miền cho các bộ xếp hạng neural, với các mức độ giám sát khác nhau, bao gồm các phương pháp không có giám sát sử dụng các truy vấn, tài liệu, hoặc cả cặp truy vấn-tài liệu được tạo ra tổng hợp (Sachan et al., 2022; Bonifacio et al., 2022; Jeronymo et al., 2023; Dai et al., 2022; Askari et al., 2023).

Thật không may, hầu hết các kết quả được báo cáo trước đây không vượt quá hiệu suất xếp hạng so với các mô hình zero-shot SOTA hiện tại, như được đánh giá trên benchmark BEIR (Thakur et al., 2021). Nói cách khác, theo hiểu biết tốt nhất của chúng tôi, không có phương pháp thích ứng xếp hạng không có giám sát nào được báo cáo trước đây chứng minh được sự cải thiện nhất quán so với các bộ xếp hạng neural zero-shot SOTA lớn.

Trong công việc này, chúng tôi nghiên cứu liệu có thể cải thiện hiệu suất xếp hạng của một bộ xếp hạng neural SOTA được huấn luyện trước cho một miền đích nhất định, thông qua thích ứng miền không có giám sát (UDA). Để giải quyết câu hỏi này, trước tiên chúng tôi xác định một yêu cầu quan trọng để dữ liệu huấn luyện tổng hợp có hiệu quả cho thích ứng xếp hạng: rằng dữ liệu huấn luyện được tạo ra phải vừa đại diện cho miền đích, vừa đủ đa dạng để buộc các thay đổi đối với mô hình xếp hạng ở mức biểu diễn thích hợp, mà không gây ra over-fitting hoặc quên thảm khốc (tức là làm giảm hiệu suất trên các tác vụ xếp hạng ban đầu).

Cụ thể, chúng tôi đề xuất một phương pháp mới DUQGen, viết tắt của Diversified Unsupervised Query Generation. DUQGen giới thiệu một phương pháp tổng quát cho thích ứng miền xếp hạng, tập trung vào việc lựa chọn tập hợp đại diện và đa dạng các cặp tài liệu và truy vấn để huấn luyện một bộ xếp hạng neural. DUQGen chỉ yêu cầu quyền truy cập vào (một phần của) bộ sưu tập tài liệu đích cần được tìm kiếm, và có thể cải thiện bất kỳ bộ xếp hạng neural được huấn luyện trước nào. DUQGen được minh họa trong Hình 1, và giới thiệu các đổi mới sau đây so với các phương pháp thích ứng xếp hạng không có giám sát trước đây: (1) biểu diễn bộ sưu tập tài liệu đích dưới dạng các cụm tài liệu; (2) đa dạng hóa việc tạo ra truy vấn tổng hợp bằng cách lấy mẫu xác suất trên các cụm tài liệu kết quả; và (3) nhắc một LLM lớn để tạo ra truy vấn với các ví dụ trong ngữ cảnh để tạo ra các truy vấn từ các tài liệu được chọn. Như chúng tôi chứng minh qua thí nghiệm, những đổi mới này chịu trách nhiệm cho việc cải thiện nhất quán so với các baseline SOTA trước đây cho thích ứng xếp hạng trên hầu như tất cả các benchmark BEIR, cũng như cải thiện nhất quán so với hiệu suất zero-shot của các bộ xếp hạng neural SOTA. Tóm lại, những đóng góp của chúng tôi bao gồm:

1. DUQGen, một phương pháp không có giám sát tổng quát và hiệu quả cho thích ứng miền của các bộ xếp hạng neural thông qua tạo ra truy vấn tổng hợp để huấn luyện.

2. Một phương pháp mới và tổng quát để tạo ra dữ liệu truy vấn tổng hợp đại diện và đa dạng cho một bộ sưu tập nhất định thông qua phân cụm và lấy mẫu xác suất.

3. Các thí nghiệm toàn diện chứng minh rằng DUQGen luôn vượt trội hơn tất cả các baseline SOTA trên 16 trong số 18 tập dữ liệu BEIR, và phân tích kỹ lưỡng các thành phần của DUQGen chịu trách nhiệm cho những cải thiện. Chúng tôi công bố công khai tất cả mã và mô hình của chúng tôi.

Tiếp theo, chúng tôi mô tả các công việc trước đây về thích ứng miền của các bộ xếp hạng neural một cách chi tiết hơn, để đặt những đóng góp của chúng tôi vào ngữ cảnh.

2 Công việc liên quan
Trong phần này, chúng tôi thảo luận về các công việc trước đây giúp thiết lập vấn đề và điều hướng giải pháp.

2.1 Bộ xếp hạng Neural
Gần đây, các mô hình ngôn ngữ được huấn luyện trước dựa trên transformer đã chứng minh tính hiệu quả ấn tượng trong các bộ xếp hạng neural (Lin et al., 2021b). Một bộ xếp hạng neural trả về một danh sách có thứ tự các tài liệu cho một truy vấn, trong đó điểm liên quan giữa biểu diễn nhúng dày đặc của truy vấn và tài liệu được sử dụng để sắp xếp. Các nghiên cứu rộng rãi đã được tiến hành trên cả bộ truy xuất dày đặc và bộ xếp hạng lại (Mitra và Craswell, 2018). So với các bộ xếp hạng dựa trên encoder (MonoBERT và DuoBERT) (Nogueira et al., 2019), các bộ xếp hạng encoder-decoder (Nogueira et al., 2020b) và dựa trên decoder (Ma et al., 2023) thể hiện hiệu suất vượt trội đáng kể với biên độ lớn hơn. Trong khi ColBERT (Khattab và Zaharia, 2020), Contriever (Izacard et al., 2021), và GTR (Ni et al., 2022) hoạt động cạnh tranh như các bộ truy xuất dày đặc, MonoT5-3B (Nogueira et al., 2020b) được áp dụng rộng rãi cho mục đích xếp hạng lại.

2.2 Thích ứng miền không có giám sát cho Bộ xếp hạng Neural
Mặc dù có hiệu suất xếp hạng đáng chú ý được chứng minh bởi các mô hình ngôn ngữ được huấn luyện trước gần đây trong cài đặt zero-shot, chúng thường gặp phải những thất bại thảm khốc trong các tình huống triển khai thực tế. Yếu tố chính góp phần vào những thất bại này là Domain-Shift (Zhu và Hauff, 2022) hoặc Domain Divergence (Ramesh Kashyap et al., 2021). Domain-Shift đã là chủ đề khám phá trong nhiều thập kỷ, bao gồm các điều tra gần đây về thích ứng miền (Lupart et al., 2023). Theo truyền thống, người ta giả định rằng các miền nguồn và đích chia sẻ các mẫu được rút ra từ cùng một phân phối. Các nghiên cứu trước đây đã giải quyết vấn đề này bằng cách định lượng sự phân kỳ miền thông qua các biện pháp khác nhau, như các biện pháp hình học, biện pháp lý thuyết thông tin, và các biện pháp bậc cao hơn (Ramesh Kashyap et al., 2021). Cuối cùng, những biện pháp này góp phần phát triển các giải pháp mới cho thích ứng miền trong các bộ xếp hạng neural.

Các giải pháp giải quyết sự phân kỳ miền thường rơi vào hai loại: (1) học biểu diễn; và (2) lựa chọn dữ liệu. Các phương pháp học biểu diễn chủ yếu giải quyết UDA, tập trung vào việc học các biểu diễn bất biến miền (Bousmalis et al., 2016; Cohen et al., 2018) hoặc huấn luyện trước một bộ xếp hạng zero-shot. Mặt khác, lựa chọn dữ liệu giả định rằng không phải tất cả các mẫu đều đóng góp như nhau cho biểu diễn miền (Axelrod et al., 2011), nêu bật tầm quan trọng của việc xác định các mẫu miền đích hiệu quả. Việc lựa chọn dữ liệu đích không phù hợp trong quá trình tinh chỉnh có khả năng làm suy yếu tác động của việc huấn luyện trước nguồn. Nghiên cứu của chúng tôi tập trung vào vấn đề biểu diễn không phù hợp của miền đích dẫn đến hiệu suất giảm sút trong các bộ xếp hạng neural. Do đó, DUQGen nhằm xác định các mẫu đích đại diện và đa dạng có thể hiệu quả trong quá trình tinh chỉnh.

2.3 Tạo ra dữ liệu IR tổng hợp
Sức mạnh ngày càng tăng của các mô hình Ngôn ngữ Lớn đã thúc đẩy nhiều nghiên cứu tập trung vào việc sử dụng LLM để tạo ra dữ liệu huấn luyện chất lượng cao. Một số công việc trước đây đã khám phá việc tạo ra dữ liệu tổng hợp không có giám sát để tinh chỉnh các mô hình xếp hạng, bao gồm GPL (Wang et al., 2022), InPars (Bonifacio et al., 2022), InPars-v2 (Jeronymo et al., 2023), DocGen-RL (Askari et al., 2023), GenQ (Thakur et al., 2021), và Promptagator (Dai et al., 2022). Những framework này sử dụng lấy mẫu tài liệu ngẫu nhiên hoặc truy vấn hạt giống ngẫu nhiên để bắt đầu pipeline của chúng, điều này để lại chỗ cho cải thiện.

Mỗi công việc được đề cập trước đây sử dụng các chiến lược riêng biệt được sử dụng cùng với các quy trình tổng hợp dữ liệu của chúng. Ví dụ, GPL (Wang et al., 2022) kết hợp một bộ tạo truy vấn dựa trên T5 (Raffel et al., 2020) với một cross-encoder gán nhãn giả để tăng cường học tập mạnh mẽ. Các phương pháp InPars và InPars-v2 sử dụng các bộ tạo truy vấn GPT-3 và GPT-J cùng với các chiến lược lọc khác nhau để loại bỏ các truy vấn tổng hợp chất lượng thấp. DocGen-RL giới thiệu một phương pháp được hướng dẫn bởi RL kết hợp với tổng hợp tài liệu sử dụng BLOOM (Scao et al., 2022). Mặt khác, GenQ tinh chỉnh TAS-B (Hofstätter et al., 2021) với các truy vấn được tạo ra từ một bộ tạo T5-base được tinh chỉnh trên MS-MARCO. Promptagator sử dụng một pipeline tương tự InPars, nhưng với các thành phần được cải thiện, như một triệu mẫu tài liệu ngẫu nhiên, một bộ tạo truy vấn FLAN 137B, và một bộ lọc nhất quán mạnh để cắt tỉa 8 triệu truy vấn tổng hợp thông qua một quy trình tương đối phức tạp và tốn kém. Đáng chú ý, không có phương pháp nào được đề cập ở trên xem xét tầm quan trọng của việc xác định các tài liệu đại diện cho miền hoặc đa dạng hóa các truy vấn kết quả. Do đó, hiệu suất tinh chỉnh dường như không đạt được hiệu suất zero-shot trong nhiều trường hợp.

Chất lượng của các truy vấn huấn luyện được tạo ra ảnh hưởng đáng kể đến hiệu suất truy xuất cuối cùng. Mặc dù sử dụng các bộ tạo truy vấn mạnh (BLOOM và GPT-3), biểu diễn truy vấn miền vẫn có thể được cải thiện. Ví dụ, InPars sử dụng một prompt chứa các ví dụ trong ngữ cảnh từ dữ liệu huấn luyện MS-MARCO, nhưng nó vẫn duy trì khoảng cách biểu diễn miền trong quá trình tạo ra trong ngữ cảnh. Hơn nữa, việc tạo ra truy vấn của chúng không giải quyết nhu cầu về sự đa dạng giữa các mẫu huấn luyện được tạo ra. Ngoài ra, chúng tích hợp một bước lọc phức tạp để cắt tỉa các truy vấn được tạo ra, điều mà chúng tôi chỉ ra có thể được tránh. Những phương pháp này tinh chỉnh các bộ xếp hạng sử dụng dữ liệu tổng hợp quy mô lớn, từ 100k đến 1M ví dụ. Ngược lại, chúng tôi lập luận rằng việc lựa chọn khôn ngoan các mẫu huấn luyện có thể tránh được sự cần thiết của việc tạo ra quy mô lớn như vậy, giảm lượng dữ liệu huấn luyện tổng hợp cần thiết đi một yếu tố x1000.

3 Phương pháp luận
DUQGen, được hiển thị trong Hình 1, bao gồm bốn thành phần – lựa chọn tài liệu miền, tạo ra truy vấn miền, khai thác cặp âm tính, và tinh chỉnh. Chúng tôi hiện tại bao quát chi tiết từng thành phần.

3.1 Lựa chọn tài liệu miền
Chúng tôi đề xuất biểu diễn một miền đích bằng các cụm và mỗi cụm bằng các tài liệu được lấy mẫu của nó. Do đó, trong phần này chúng tôi mô tả chúng trong ba giai đoạn, cụ thể là phân cụm tài liệu bộ sưu tập, lấy mẫu tài liệu xác suất, và lựa chọn tài liệu đa dạng hóa.

3.1.1 Phân cụm tài liệu bộ sưu tập
Biểu diễn một bộ sưu tập tài liệu miền đích quy mô lớn với dữ liệu huấn luyện hạn chế là thách thức. Do đó, chúng tôi đề xuất chia bộ sưu tập thành các phần, và sau đó lấy mẫu tài liệu trong mỗi phần. Chúng tôi sử dụng một phương pháp phân cụm cho biểu diễn bộ sưu tập. Hơn nữa, chúng tôi có thể đạt được các tài liệu chủ đề đa dạng để biểu diễn miền. Chúng tôi bắt đầu với bộ sưu tập đầy đủ các tài liệu và áp dụng một bước tiền xử lý, trong đó chúng tôi loại bỏ các tài liệu ngắn, lọc ra các tài liệu nhiễu. Sau đó chúng tôi sử dụng một bộ mã hóa văn bản SOTA, cụ thể là Contriever (Izacard et al., 2021), để mã hóa mỗi tài liệu. Sử dụng các embedding tài liệu vDi, chúng tôi áp dụng kỹ thuật phân cụm (ví dụ, K-Means), trong đó K là một siêu tham số cần điều chỉnh.

3.1.2 Lấy mẫu tài liệu xác suất
Biểu diễn mỗi cụm trong các bộ sưu tập dữ liệu lớn là thách thức vì các cụm kết quả thường có kích thước không cân bằng. Hãy lấy kích thước cụm thứ k là ck và kích thước bộ sưu tập là C, trong đó (1≤ck≤C). Chúng tôi lý tưởng muốn lấy mẫu nhiều tài liệu hơn từ các cụm kích thước lớn hơn tỷ lệ với kích thước cụm. Nếu cụm k và Di biểu diễn cụm thứ k và tài liệu thứ i của nó, xác suất chọn Di từ cụm k là

Pr(Di|cluster k) ∝ ck ∀Di ∈ cluster k.

Chúng tôi dự định lấy mẫu N số lượng ví dụ huấn luyện tổng hợp từ K số lượng cụm, trong đó N ≥ K. Do đó, chúng tôi thiết kế một biểu thức phân tầng để xác định kích thước mẫu tài liệu Nk cho cụm thứ k, được cho bởi

N'k = 1 + ⌊ck/C(N-K)⌋
P = N - K - Σk=1^K N'k
Nk = {N'k + 1 nếu k ∈ argsorttop-P(ck)
      N'k nếu k ∉ argsorttop-P(ck)}

trong đó N'k và P là kích thước mẫu trung gian và số nguyên. Phép toán ⌊*⌋ tìm giá trị nguyên sàn.

Bây giờ chúng tôi đã xác định kích thước mẫu cho mỗi cụm, chúng tôi định nghĩa phương pháp lấy mẫu của mình. Hãy lấy di là độ tương tự (ví dụ độ tương tự cosine) giữa tài liệu Di và tâm cụm tương ứng của nó. Chúng tôi định nghĩa một giá trị mũ edi như đại diện cho mức độ gần Di với tâm cụm của nó. Do đó, Pr(Di|cluster k) trở thành softmax được chuẩn hóa được cho bởi:

Pr(Di|cluster k) = e^(di/T) / Σj=1^ck e^(dj/T)  (1)

di = cosine(vDi, 1/ck Σj=1^ck vDj)  (2)

trong đó T là nhiệt độ softmax và vDi là embedding tài liệu thứ i. Trực quan, khả năng một tài liệu được chọn để tạo ra một truy vấn liên quan tỷ lệ thuận với độ tương tự tài liệu với tâm cụm của nó.

3.1.3 Lựa chọn tài liệu đa dạng hóa
Bây giờ chúng tôi lấy mẫu Nk số lượng tài liệu từ mỗi cụm cluster k và gộp chúng để có được các tài liệu kích thước huấn luyện cần thiết N. Các tập mẫu khác nhau có thể được rút ra từ phương pháp lấy mẫu nêu trên với các lựa chọn khác nhau của giá trị hạt giống ngẫu nhiên. Do đó, để cải thiện tính mạnh mẽ của việc lựa chọn trong quá trình lấy mẫu, chúng tôi áp dụng một biện pháp đa dạng, cụ thể là Maximal Marginal Relevance (MMR) (Carbonell và Goldstein, 1998). Đầu tiên chúng tôi lặp lại quá trình lấy mẫu m lần (m = 5) để có được các tập mẫu khác nhau. Sau đó chúng tôi áp dụng MMR trên các tài liệu được gộp từ m tập để chọn top-Nk tài liệu cho cụm k như được hiển thị:

argmax[Di∈R\S][λSim1(Di, Dk) - (1-λ) max[Dj∈S] Sim2(Di, Dj)]  (3)

trong đó Dk là tài liệu gần nhất với tâm cụm, λ là trọng số cân bằng (cần được điều chỉnh) giữa độ tương tự với tâm cụm và tính đa dạng, R là các tài liệu được gộp, S là một tập con các tài liệu đã được chọn từ R, và Sim1 và Sim2 có thể giống hoặc khác nhau, nhưng chúng tôi sử dụng độ tương tự cosine cho cả hai trường hợp.

3.2 Tạo ra truy vấn tổng hợp
Tạo ra truy vấn là một thành phần thiết yếu trong một pipeline tạo ra dữ liệu không có giám sát cho các mô hình xếp hạng. Các truy vấn biểu diễn một miền đích w.r.t. nhu cầu thông tin của người dùng và nhiệm vụ-miền bằng cách có các loại khác nhau, như câu hỏi, tiêu đề, từ khóa, hoặc tuyên bố. Do đó, chúng tôi sử dụng một LLM để tạo ra một truy vấn tổng hợp trong miền cho mỗi tài liệu được lấy mẫu. Chúng tôi nhắc few-shot LLM để tạo ra các truy vấn huấn luyện như vậy tương tự như công việc hiện tại của Bonifacio et al. (2022). Tuy nhiên, đóng góp của chúng tôi nằm ở việc chỉ ra rằng các ví dụ few-shot trong miền (cặp truy vấn-tài liệu) giúp đạt được chất lượng cao của các truy vấn so với các ví dụ MS-MARCO chung ngoài miền. Trên mỗi miền, chúng tôi tạo ra một số ít (ví dụ, 3) truy vấn được tạo ra bởi con người cho các tài liệu ví dụ few-shot với nỗ lực tối thiểu của con người, và một ví dụ prompt được hiển thị trong Hình 2.

3.3 Khai thác cặp âm tính
Sau khi có được các tài liệu và truy vấn chuyên biệt cho miền, chúng tôi nên tạo ra cả cặp truy vấn-tài liệu dương tính và âm tính. Đầu tiên, các cặp truy vấn-tài liệu dương tính có thể được tạo ra dễ dàng bằng cách ánh xạ các truy vấn tổng hợp với các tài liệu gốc (hạt giống) tương ứng của chúng. Thứ hai, các cặp truy vấn-tài liệu âm tính có thể được tạo ra từ khai thác âm tính khó, được mô tả trong các thực tiễn tiêu chuẩn (Izacard et al., 2021; Xiong et al., 2020; Karpukhin et al., 2020). Chúng tôi phân tích các truy vấn tổng hợp cho bất kỳ bộ truy xuất giai đoạn đầu nào, như BM25 (Robertson và Zaragoza, 2009), ColBERT (Khattab và Zaharia, 2020), hoặc Contriever (Izacard et al., 2021), để có được top-x tài liệu. Sau đó chúng tôi chọn bottom-num_neg tài liệu từ top-x để ánh xạ với các truy vấn tổng hợp, trong đó 1:num_neg là tỷ lệ cặp tài liệu dương tính:âm tính.

3.4 Tinh chỉnh với dữ liệu tổng hợp của chúng tôi
Framework thích ứng miền của chúng tôi có thể được áp dụng trên bất kỳ mô hình xếp hạng nào với bất kỳ khởi tạo trọng số nào. Để thiết lập một đối thủ mạnh, chúng tôi tận dụng mô hình được huấn luyện trước cho tác vụ (trên MS-MARCO), và tuần tự tinh chỉnh đầy đủ với dữ liệu tổng hợp được tạo ra của chúng tôi. Chúng tôi cũng áp dụng cùng các cài đặt siêu tham số được sử dụng trong giai đoạn huấn luyện trước MS-MARCO để có thể giao hàng công bằng.

4 Thí nghiệm
Trong phần này, chúng tôi cung cấp chi tiết về thiết lập thí nghiệm của chúng tôi để chứng minh tính hiệu quả của DUQGen.

4.1 Tập dữ liệu và Chỉ số
Chúng tôi sử dụng tất cả 18 tập dữ liệu từ bộ sưu tập BEIR, trải dài trên các tác vụ truy xuất đa dạng, để đánh giá tính hiệu quả của framework thích ứng miền của chúng tôi trên các tập dữ liệu out-of-distribution tiêu chuẩn. Sử dụng chỉ mục đa trường từ Pyserini (Lin et al., 2021a) cho tất cả các tập dữ liệu, chúng tôi truy xuất top-100 và top-200 tài liệu từ các bộ truy xuất giai đoạn đầu từ vựng và dày đặc tương ứng. Sau đó, chúng tôi hạn chế xếp hạng lại với top-100 tài liệu BM25 và top-200 tài liệu bộ truy xuất dày đặc. Vì chúng tôi đánh giá phương pháp của mình trên cả truy xuất giai đoạn đầu và xếp hạng lại, chúng tôi đo cả nDCG@10 và R@100.

4.2 Mô hình xếp hạng
Chúng tôi tinh chỉnh ColBERT và MonoT5-3B, cụ thể là DUQGen-retriever và DUQGen-reranker, để chỉ ra tính hiệu quả trong cả truy xuất dày đặc và xếp hạng lại. Trong quá trình đánh giá, chúng tôi kiểm tra hai pipeline xếp hạng đa giai đoạn:
(1) DUQGen-reranker: một MonoT5-3B được tinh chỉnh xếp hạng lại BM25 top-100 và (2) DUQGen-retriever + DUQGen-reranker: một MonoT5-3B được tinh chỉnh xếp hạng lại một ColBERT được tinh chỉnh top-200 tài liệu.

4.3 Baseline
Chúng tôi chọn các bộ xếp hạng cạnh tranh mạnh làm baseline để làm nổi bật tính hiệu quả của bộ xếp hạng thích ứng miền được đề xuất của chúng tôi.

BM25: Truy xuất thưa từ vựng truyền thống. Chúng tôi tái tạo điểm BM25 từ đầu.

Mô hình Zero-shot (ZS): Một bộ xếp hạng được tinh chỉnh trên tập dữ liệu MS-MARCO, bao gồm MonoT5-3B và ColBERT.

InPars (Bonifacio et al., 2022): Một framework tạo ra dữ liệu huấn luyện không có giám sát cho xếp hạng. Các truy vấn tổng hợp được tạo ra từ các tài liệu được chọn ngẫu nhiên sử dụng few-shot prompting mô hình GPT-3 Curie. Khả năng mô hình ngôn ngữ được sử dụng như một bước lọc để chọn top-10k truy vấn tổng hợp chất lượng cao trước khi tinh chỉnh bất kỳ bộ xếp hạng nào. Dựa trên các lý do được cung cấp bởi Askari et al. (2023), chúng tôi không so sánh với InPars-v2.

DocGen-RL (Askari et al., 2023): Một framework được điều khiển bởi RL để tạo ra tài liệu từ các truy vấn. Cũng là một phương pháp lặp, dựa trên các giai đoạn mở rộng, làm nổi bật, và tạo ra, tạo ra các tài liệu từ các truy vấn để chuẩn bị dữ liệu huấn luyện.

Promptagator++ (Dai et al., 2022): Như các phương pháp SOTA gần nhất với công việc của chúng tôi, chúng tôi đánh giá so với Promptagator++. Phương pháp này hoạt động bằng cách chọn ngẫu nhiên 1 triệu tài liệu từ bộ sưu tập đích. Nó sử dụng 8-shot prompting với một mô hình FLAN 137 tỷ tham số (Wei et al., 2022) để tạo ra 8 truy vấn cho mỗi tài liệu. Sau khi lọc nhất quán, 1 triệu truy vấn được chọn để huấn luyện một GTR-Base dual-encoder và cross-encoder (Ni et al., 2022).

Chúng tôi trực tiếp sử dụng các điểm được báo cáo bởi các tác giả cho DocGen-RL và Promptagator++. Đối với các baseline còn lại, chúng tôi sử dụng các mô hình HuggingFace tương ứng (Wolf et al., 2020) để chạy lại suy luận.

4.4 Công cụ và Triển khai
Các công cụ khác nhau được sử dụng cho các giai đoạn riêng biệt trong pipeline của chúng tôi, sử dụng Contriever (Izacard et al., 2021) để mã hóa văn bản, Faiss (Johnson et al., 2019) cho phân cụm k-Means, và Llama2-7B-Chat (Touvron et al., 2023) để tạo ra truy vấn, Pyserini cho baseline BM25 và khai thác âm tính khó, và PyTorch cho tinh chỉnh tiêu chuẩn. Trong suốt các thí nghiệm của chúng tôi, các tài liệu được biểu diễn sử dụng tiêu đề của chúng cùng với văn bản. Ban đầu, các tài liệu bộ sưu tập được lọc nhiễu bằng cách loại trừ những tài liệu có độ dài ký tự nhỏ hơn 300 (có thể thay đổi qua các tập dữ liệu). Giải mã tham lam với nhiệt độ 0.0 được sử dụng cho LLM để tạo ra các truy vấn.

4.5 Điều chỉnh siêu tham số
Trong phần phương pháp luận của chúng tôi, chúng tôi giới thiệu một số siêu tham số, tất cả đều trải qua điều chỉnh để xác định các giá trị tối ưu. Những siêu tham số này bao gồm nhiệt độ T = 1 (Phương trình 1), trọng số MMR λ = 1.0, số lượng cụm K = 1000, và kích thước mẫu huấn luyện N = 1000 cho ColBERT và N = 1000 và 5000 cho tinh chỉnh MonoT5-3B. Chúng tôi điều chỉnh số lượng ví dụ trong ngữ cảnh khác nhau và tìm thấy hiệu suất tối ưu với 3-shot prompting (cũng được sử dụng trong InPars). Ngoài ra, thông qua việc điều chỉnh các mẫu prompt khác nhau, chúng tôi phát hiện ra rằng một mẫu InPars-style đơn giản, được hiển thị trong Hình 2, liên tục mang lại hiệu suất truy xuất vượt trội qua các tập dữ liệu. Đối với quá trình khai thác âm tính khó, chúng tôi đặt hits bộ truy xuất giai đoạn đầu x = 100 và số lượng âm tính cho mỗi cặp dương tính num_neg = 4.

Chúng tôi tinh chỉnh MonoT5-3B sử dụng kích thước batch là 8, các bước tích lũy gradient là 16, tỷ lệ học 2e-5, trình tối ưu AdamW với weight decay 0.01 và tỷ lệ warm-up 0.1, và epochs là 1. Để tinh chỉnh ColBERT, chúng tôi áp dụng các siêu tham số huấn luyện trước chính thức của nó, bao gồm kích thước batch là 32, tỷ lệ học 3e-6, và độ dài chuỗi tối đa là 300.

Quy mô và chất lượng của dữ liệu tổng hợp phụ thuộc vào các ví dụ huấn luyện, N, và số lượng cụm, K, mà chúng tôi tối ưu hóa trong các tiểu mục tiếp theo.

4.5.1 Tối ưu hóa phân cụm
Để biểu diễn miền đích, chúng tôi sử dụng thuật toán K-Means, trong đó K biểu thị số lượng cụm. Chúng tôi xác định K tối ưu cho mỗi tập dữ liệu thông qua một phương pháp không có giám sát, được biết đến là phương pháp Elbow (Thorndike, 1953). Phương pháp elbow tính toán Sum of Squared Error (SSE) cho mỗi giá trị của K, trong đó SSE được tính là tổng của khoảng cách cosine giữa mỗi tài liệu bộ sưu tập và tâm cụm gần nhất của nó. K tối ưu nhất quán thẳng hàng tại một điểm cố định là 1000 trên tất cả các tập dữ liệu đánh giá, bất kể sự khác biệt về kích thước corpus, tính chất miền, hoặc sự phân kỳ miền từ MS-MARCO.

4.5.2 Khám phá kích thước mẫu huấn luyện tối ưu
Bằng cách cố định số lượng cụm tối ưu K ở 1000, chúng tôi xác định một kích thước mẫu huấn luyện tối ưu N, đã chứng minh hiệu quả trên tất cả các tập dữ liệu. Để điều chỉnh cho N, chúng tôi sử dụng FiQA và NQ như các tập dữ liệu phát triển, tham khảo công việc trước (InPars-v2) đã chứng minh hiệu suất cải thiện trên FiQA và hiệu suất giảm trên NQ so với điểm zero-shot. Bảng 2 hiển thị các giá trị nDCG@10 cho các trường hợp khác nhau của N, với K được cố định ở 1000. Phân tích của chúng tôi dẫn chúng tôi chọn N = 1000 tối ưu cho ColBERT và cả N = 1000 và 5000 cho tinh chỉnh MonoT5-3B qua các tập dữ liệu.

5 Kết quả và Thảo luận
Trong phần này, chúng tôi trình bày các kết quả thí nghiệm chính của chúng tôi và đi sâu vào các quan sát chính. Chúng tôi đầu tiên mô tả những phát hiện chính của chúng tôi, được báo cáo sử dụng nDCG@10 trong Bảng 1 so sánh giữa các baseline và phương pháp của chúng tôi trong mỗi cài đặt xếp hạng. Thứ hai, chúng tôi báo cáo hiệu suất truy xuất giai đoạn đầu, được đo bằng R@100 trong Bảng 3.

5.1 Kết quả xếp hạng lại
Trong Bảng 1, rõ ràng là DUQGen luôn vượt trội hơn các baseline SOTA trong hầu hết các trường hợp, thể hiện những cải thiện đáng chú ý về hiệu suất. Cụ thể, DUQGen luôn và đáng kể vượt trội hơn cả InPars và DocGen-RL rerankers, thể hiện những cải thiện tương đối trung bình 26% và 17% tương ứng qua các tập dữ liệu đánh giá mà chúng chia sẻ. Khi so sánh với Promptagator++, DUQGen chứng minh một cải thiện tương đối trung bình 4% qua các tập dữ liệu đánh giá được chia sẻ. Đáng chú ý, DUQGen vượt trội Promptagator++ về hiệu suất, chỉ sử dụng 1000 lời gọi LLM và tinh chỉnh với chỉ 1000 cặp huấn luyện, trái ngược với yêu cầu của Promptagator++ là tạo ra 8 triệu truy vấn sử dụng LLM 137B và tinh chỉnh với 1 triệu cặp huấn luyện. Điều này làm nổi bật tính hiệu quả của phương pháp hiệu quả và mạnh mẽ của chúng tôi so với các phương pháp huấn luyện phức tạp, tốn nhiều tài nguyên, và toàn diện dựa trên học tăng cường.

Trong nhiều trường hợp, hiệu suất của các baseline SOTA bị giảm sút, so với các đối tác zero-shot. Ví dụ, cả InPars và DocGen-RL đều liên tục chứng minh sự giảm hiệu suất tương đối so với MonoT5-3B zero-shot, với mức giảm Avg. 18% và 11% tương ứng qua các tập dữ liệu đánh giá mà chúng chia sẻ (DocGen-RL cũng kém hiệu suất so với MonoT5-base zero-shot, như được hiển thị trong Bảng 6). Mặt khác, DUQGen luôn vượt trội tất cả các mô hình zero-shot qua tất cả các tập dữ liệu BEIR, dù được huấn luyện với 1,000 hay 5,000 ví dụ huấn luyện tổng hợp.

Thú vị, việc huấn luyện DUQGen-reranker với chỉ 1,000 ví dụ tổng hợp thể hiện một cải thiện hiệu suất nhẹ so với việc huấn luyện với 5,000 ví dụ tổng hợp trên 13 trong số 18 tập dữ liệu, cho thấy hiệu quả mẫu của phương pháp của chúng tôi. Trong tương lai, có thể khả thi để tự động xác định kích thước huấn luyện tối thiểu (N) cho mỗi tập dữ liệu hoặc tác vụ.

5.2 Kết quả truy xuất giai đoạn đầu
Trong Bảng 3, tương tự như điểm nDCG@10, R@100 cũng chứng minh những cải thiện đáng kể hơn cho các domain-shift lớn hơn (7.1% trên TREC-COVID và 3.8% trên Touché-2020) và những cải thiện hạn chế cho các domain-shift nhỏ hơn (.4% trên NQ). Trung bình, DUQGen nâng cao ColBERT zero-shot 2.1% trên các tập dữ liệu BEIR.

6 Phân tích
Trong phần này, chúng tôi báo cáo phân tích hiệu suất của DUQGen, bao gồm việc kiểm tra nhu cầu phân cụm, xác nhận lựa chọn bộ tạo truy vấn, và xác thực chất lượng của các truy vấn được tạo ra.

6.1 Hiệu ứng của phân cụm cho thích ứng miền
Chúng tôi sử dụng phân cụm để biểu diễn miền đích và số lượng mẫu huấn luyện để buộc tính đa dạng trong quá trình tinh chỉnh. Tuy nhiên, chúng tôi đặt câu hỏi liệu phân cụm có thực sự đóng góp vào quá trình và, nếu có, nó ảnh hưởng như thế nào đến hiệu suất tổng thể. Ngoài ra, chúng tôi tính đến kích thước mẫu huấn luyện N. Trong Bảng 5, chúng tôi minh họa hiệu ứng kết hợp của cả K và N trên hiệu suất xếp hạng lại MonoELECTRA top-100 BM25, được đo bằng nDCG@10. MonoELECTRA được sử dụng trong các Phần phân tích 6.1 và 6.2 để đo những cải thiện hiệu suất được khuếch đại trong một mô hình nhỏ hơn, như được mô tả trong phần trước.

Bảng 5 xác nhận quyết định của chúng tôi chọn N = 5000 cho MonoELECTRA. Đáng chú ý, hình này làm nổi bật rằng những cải thiện đáng kể và nhất quán nhất xảy ra xung quanh các giá trị {K=1000, N=5000} qua cả hai tập dữ liệu. Hiệu suất không có phân cụm (K=1) thường rơi xuống dưới zero-shot trong cả hai tập dữ liệu, đặc biệt NQ thể hiện hiệu suất kém nhất.

6.2 Hiệu ứng của các bộ tạo truy vấn
Chúng tôi tiến hành một nghiên cứu loại bỏ về tạo ra truy vấn để đánh giá cách chất lượng của các truy vấn được tạo ra ảnh hưởng đến hiệu suất truy xuất tổng thể. Bảng 4 hiển thị hiệu suất của MonoELECTRA được tinh chỉnh với các truy vấn được tạo ra bởi các LLM khác nhau, bao gồm LLAMA2-Chat (7B và 13B), BLOOM (3B và 7B), và GPT-3.5-turbo (Brown et al., 2020).

So với điểm xếp hạng lại zero-shot, LLAMA-2 7B được coi là lựa chọn tối ưu cho bộ tạo truy vấn của chúng tôi. LLAMA-2 7B với prompts trong miền 3-shot thể hiện những cải thiện cao hơn trên cả hai tập dữ liệu phát triển, vượt trội gpt-3.5-turbo. Trong khi LLAMA-2 13B chứng minh hiệu suất vượt trội so với 7B trên FiQA, nó rơi xuống dưới hiệu suất zero-shot trong NQ, được quy cho khả năng mô hình lớn và độ nhạy cảm với prompts (Zhao et al., 2021). BLOOM tạo ra các truy vấn ngắn thiếu ngữ cảnh, mặc dù có đủ ví dụ truy vấn ngữ cảnh từ các ví dụ 3-shot. GPT-3.5-turbo tạo ra các truy vấn chất lượng cao, dẫn đến hiệu suất cải thiện so với zero-shot, nhưng có xu hướng không ổn định với prompts few-shot, gợi ý tiềm năng cho kỹ thuật prompt tiếp theo để nâng cao hiệu suất trên mỗi tập dữ liệu. Đóng góp chính thứ hai của chúng tôi liên quan đến việc sử dụng prompts 3-shot trong miền để tạo ra truy vấn so với prompt ms-marco, thể hiện những cải thiện đáng chú ý trên mô hình LLAMA-2 7B.

6.3 Ví dụ về các truy vấn DUQGen
Cho đến nay, chúng tôi đã đánh giá tính hiệu quả của DUQGen sử dụng các biện pháp định lượng và bây giờ đang chuyển tập trung của chúng tôi sang việc kiểm tra các truy vấn thực tế được tạo ra bởi phương pháp của chúng tôi. Hình 3 trình bày mười ví dụ truy vấn được tạo ra từ các tập dữ liệu Quora và TREC-Covid, mỗi tập đại diện cho các tác vụ và miền riêng biệt. Trong Hình 3, các truy vấn tổng hợp được lấy mẫu qua các cụm khác nhau với các điểm xác suất khác nhau Pr(Di|cluster k). Ví dụ, trong Hình 3a, chúng tôi quan sát rằng trong tác vụ truy xuất câu hỏi trùng lặp Quora, mỗi cụm tương ứng với các chủ đề phụ của biểu diễn miền đích, như chuyển tiền ngân hàng, tôn giáo, kỳ thi ở Ấn Độ, năng lượng, và ngôn ngữ lập trình. Trong mỗi cụm, các truy vấn đa dạng được lấy mẫu sử dụng các điểm xác suất khác nhau để hỗ trợ học biểu diễn miền. Ngoài ra, các truy vấn được tạo ra chứa đủ ngữ cảnh hoặc thực thể để truy xuất thông tin phù hợp từ bộ sưu tập tương ứng của nó. Phân tích này về các truy vấn được tạo ra tiếp tục xác thực tính hiệu quả của phương pháp của chúng tôi trong việc tạo ra một tập hợp đa dạng và đại diện của các truy vấn chất lượng cao.

7 Kết luận
Chúng tôi đề xuất một phương pháp thích ứng miền không có giám sát tổng quát DUQGen, có thể được sử dụng để tinh chỉnh bất kỳ mô hình xếp hạng nào cho các miền đích nhất định. DUQGen giới thiệu những đổi mới đáng kể so với các phương pháp thích ứng miền không có giám sát được báo cáo trước đây. Cụ thể, DUQGen đề xuất biểu diễn bộ sưu tập miền đích với phân cụm tài liệu; một phương pháp hiệu quả để đa dạng hóa các truy vấn được tạo ra tổng hợp, và một chiến lược prompting hiệu quả để sử dụng LLM tạo ra dữ liệu huấn luyện tổng hợp hiệu quả và đại diện hơn. Chúng tôi chứng minh qua thí nghiệm rằng DUQGen vừa có thể mở rộng vừa hiệu quả, vì nó chỉ sử dụng vài nghìn ví dụ huấn luyện tổng hợp, trong khi liên tục cải thiện so với các bộ xếp hạng zero-shot SOTA, và vượt trội đáng kể so với các phương pháp SOTA cho các phương pháp thích ứng miền không có giám sát trong hầu hết các trường hợp. Chúng tôi bổ sung hiệu suất thực nghiệm mạnh mẽ của DUQGen với một phân tích sâu về các thành phần để định lượng đóng góp của chúng. Cùng nhau, các kỹ thuật và kết quả thí nghiệm được trình bày đáng kể thúc đẩy thích ứng xếp hạng neural, thiết lập một state-of-the-art mới trong xếp hạng neural, và gợi ý các hướng hứa hẹn cho những cải thiện trong tương lai.

8 Hạn chế
Phương pháp luận được đề xuất của chúng tôi liên quan đến hai bước then chốt: (1) phân cụm; và (2) tạo ra truy vấn. Đầu tiên, chúng tôi sử dụng Contriever như bộ mã hóa văn bản của chúng tôi để tạo ra embedding cho phân cụm. Trong khi chúng tôi dự đoán rằng nó sẽ tạo ra biểu diễn tài liệu chất lượng cao và chứng minh hữu ích trong công việc của chúng tôi, chúng tôi không đánh giá các embedding tài liệu khác. Công việc tương lai có thể trực tiếp giải quyết câu hỏi về việc chọn embedding thích hợp cho phân cụm. Thứ hai, chúng tôi sử dụng thư viện Faiss để triển khai phân cụm K-Means. Tuy nhiên, khi kích thước bộ sưu tập mở rộng lên hàng triệu, phân cụm trở nên không thực tế. Do đó, Faiss phải lấy mẫu bộ sưu tập và sau đó huấn luyện thuật toán của chúng. Việc mất thông tin này trong quá trình lấy mẫu có thể lan truyền như lỗi trong điểm truy xuất cuối cùng. Tuy nhiên, cho rằng các bộ sưu tập lớn thường chứa các cụm dày đặc, quá trình lấy mẫu để phân cụm trong những trường hợp như vậy có thể gây ra ít vấn đề hơn.

Giống như nhiều nghiên cứu trước đây (Zhao et al., 2021), chúng tôi thường gặp phải thiếu tính mạnh mẽ của LLM và độ nhạy cảm của chúng với những thay đổi nhỏ trong prompt ảnh hưởng đến hiệu suất truy xuất tiếp theo. Công việc tương lai có thể khám phá các chiến lược để giảm thiểu tính mạnh mẽ này thông qua các kỹ thuật như hiệu chuẩn (Zhao et al., 2021) và thực hiện các nghiên cứu tương ứng để thấy tác động đến xếp hạng lại.

9 Cân nhắc đạo đức
Các hệ thống truy xuất có thể dẫn đến nhiều vấn đề đạo đức khác nhau, như tiềm năng thiên vị, có thể dẫn đến việc ưu đãi các quan điểm cụ thể, thiếu minh bạch do tính chất mờ đục của các mô hình học sâu, che giấu các lý do đằng sau việc xếp hạng tài liệu, và, trong các trường hợp cực đoan, việc tạo điều kiện cho các buồng vang. Do đó, việc tiến hành kiểm tra kỹ lưỡng các hệ thống này cả trước và trong quá trình triển khai là thiết yếu.

Như được chỉ ra bởi công việc của chúng tôi, hiệu suất của các bộ truy xuất hạ nguồn có thể bị ảnh hưởng đúng đắn bởi các LLM được sử dụng để tạo ra các truy vấn tổng hợp. Cho rằng LLM có thể tạo ra nội dung không chính xác hoặc hoàn toàn bịa đặt, có nguy cơ chúng có thể tạo ra các truy vấn có vấn đề, đặc biệt nếu được áp dụng cho các tập dữ liệu nhạy cảm. Mặc dù vấn đề này có thể xuất hiện ít nghiêm trọng hơn trong một tình huống như của chúng tôi khi nội dung được tạo ra chỉ nhằm mục đích làm tài liệu huấn luyện cho một bộ truy xuất tiếp theo, vẫn có khả năng tạo ra các truy vấn có hại và độc hại. Những truy vấn như vậy có thể dẫn bộ truy xuất hướng tới các kết quả thiên vị. Do đó, việc đánh giá các hệ thống này để giảm thiểu những rủi ro này chống lại sự thiên vị của bộ tạo dữ liệu là bắt buộc.

Lời cảm ơn
Các tác giả cảm ơn Harshita Sahijwani và Sergey Volokhin, và các nhà đánh giá và meta-đánh giả vì những nhận xét và đề xuất có giá trị của họ. Công việc này được hỗ trợ một phần bởi chương trình IARPA BETTER (#2019-19051600005). Các quan điểm và kết luận có trong công việc này là của các tác giả và không nên được hiểu là nhất thiết đại diện cho các chính sách chính thức, dù được bày tỏ rõ ràng hay ngầm ý, hoặc sự tán thành của ODNI, IARPA, hoặc Chính phủ Hoa Kỳ. Chính phủ Hoa Kỳ được ủy quyền tái tạo và phân phối bản sao cho các mục đích chính phủ bất kể bất kỳ chú thích bản quyền nào trong đó.

Tài liệu tham khảo
[Các tài liệu tham khảo được dịch tương tự với format ban đầu nhưng tiếng Việt]

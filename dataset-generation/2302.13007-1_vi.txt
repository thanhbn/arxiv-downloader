AugGPT: Tận dụng ChatGPT cho Tăng cường Dữ liệu Văn bản

Haixing Dai, Zhengliang Liu, Wenxiong Liao, Xiaoke Huang, Yihan Cao, Zihao Wu, Lin Zhao,
Shaochen Xu, Wei Liu, Ninghao Liu, Sheng Li, Dajiang Zhu, Hongmin Cai, Lichao Sun, Quanzheng Li,
Dinggang Shen, Tianming Liu, và Xiang Li

Tóm tắt—Tăng cường dữ liệu văn bản là một chiến lược hiệu quả để vượt qua thách thức về kích thước mẫu hạn chế trong nhiều tác vụ xử lý ngôn ngữ tự nhiên (NLP). Thách thức này đặc biệt nổi bật trong kịch bản học few-shot, nơi dữ liệu trong miền đích thường hiếm hơn nhiều và chất lượng thấp hơn. Một chiến lược tự nhiên và được sử dụng rộng rãi để giảm thiểu những thách thức như vậy là thực hiện tăng cường dữ liệu để nắm bắt tốt hơn tính bất biến của dữ liệu và tăng kích thước mẫu. Tuy nhiên, các phương pháp tăng cường dữ liệu văn bản hiện tại hoặc không thể đảm bảo việc gán nhãn chính xác cho dữ liệu được tạo ra (thiếu tính trung thực) hoặc không thể đảm bảo đủ đa dạng trong dữ liệu được tạo ra (thiếu tính compactness), hoặc cả hai. Lấy cảm hứng từ thành công gần đây của các mô hình ngôn ngữ lớn, đặc biệt là sự phát triển của ChatGPT, đã chứng minh khả năng hiểu ngôn ngữ được cải thiện, trong nghiên cứu này, chúng tôi đề xuất một phương pháp tăng cường dữ liệu văn bản dựa trên ChatGPT (có tên AugGPT). AugGPT diễn đạt lại mỗi câu trong các mẫu huấn luyện thành nhiều mẫu tương đương về mặt khái niệm nhưng khác nhau về mặt ngữ nghĩa. Các mẫu được tăng cường sau đó có thể được sử dụng trong huấn luyện mô hình downstream. Kết quả thí nghiệm trên các tác vụ phân loại văn bản học few-shot cho thấy hiệu suất vượt trội của phương pháp AugGPT được đề xuất so với các phương pháp tăng cường dữ liệu văn bản tiên tiến về độ chính xác thử nghiệm và phân phối của các mẫu được tăng cường.

Từ khóa—Mô hình ngôn ngữ lớn, học few-shot, xử lý ngôn ngữ tự nhiên, tăng cường dữ liệu.

1 GIỚI THIỆU

Hiệu quả của xử lý ngôn ngữ tự nhiên (NLP) phụ thuộc rất nhiều vào chất lượng và số lượng dữ liệu huấn luyện. Với dữ liệu huấn luyện hạn chế có sẵn, đây là một vấn đề phổ biến trong thực tế do các mối quan tâm về quyền riêng tư hoặc chi phí chú thích, có thể là thách thức để huấn luyện một mô hình NLP chính xác có thể tổng quát hóa tốt cho các mẫu chưa thấy. Thách thức về sự thiếu hụt dữ liệu huấn luyện đặc biệt nổi bật trong các kịch bản học few-shot (FSL), nơi mô hình được huấn luyện trên dữ liệu miền gốc (source) dự kiến sẽ tổng quát hóa từ chỉ một vài ví dụ trong miền mới (target) [1]. Nhiều phương pháp FSL đã cho thấy kết quả đầy hứa hẹn trong việc vượt qua thách thức này trong các tác vụ khác nhau. Các phương pháp FSL hiện có chủ yếu tập trung vào việc cải thiện khả năng học và tổng quát hóa của mô hình thông qua thiết kế kiến trúc tốt hơn [2], [3], tận dụng các mô hình ngôn ngữ được huấn luyện trước làm cơ sở và sau đó fine-tune nó bằng cách sử dụng các mẫu hạn chế [4] với meta-learning [2], [5] hoặc các phương pháp dựa trên prompt [6], [7], [8], [9]. Tuy nhiên, hiệu suất của các phương pháp này vẫn bị hạn chế về cốt lõi bởi chất lượng và số lượng dữ liệu trong cả miền nguồn và miền đích.

Bên cạnh phát triển mô hình, tăng cường dữ liệu văn bản cũng có thể vượt qua giới hạn kích thước mẫu và hoạt động cùng với các phương pháp FSL khác trong NLP [10], [11]. Tăng cường dữ liệu thường là model-agnostic và không liên quan đến thay đổi kiến trúc mô hình cơ bản, điều này làm cho phương pháp này đặc biệt thiết thực và có thể áp dụng cho một loạt các tác vụ. Trong NLP, có một số loại phương pháp tăng cường dữ liệu. Các phương pháp tăng cường dữ liệu cấp văn bản truyền thống dựa vào các hoạt động trực tiếp trên cơ sở mẫu hiện có. Một số kỹ thuật được sử dụng thường xuyên bao gồm thay thế từ đồng nghĩa, xóa ngẫu nhiên và chèn ngẫu nhiên [12]. Các phương pháp gần đây hơn sử dụng các mô hình ngôn ngữ để tạo ra các mẫu đáng tin cậy cho việc tăng cường dữ liệu hiệu quả hơn, bao gồm back-translation [13] và interpolation vector từ trong không gian tiềm ẩn [14]. Tuy nhiên, các phương pháp tăng cường dữ liệu hiện có bị hạn chế về độ chính xác và đa dạng của dữ liệu văn bản được tạo ra, và chú thích thủ công vẫn là bắt buộc trong nhiều kịch bản ứng dụng [12], [15], [16].

Sự ra đời của các mô hình ngôn ngữ rất lớn (LLMs) như họ GPT [6], [17] mang lại cơ hội mới để tạo ra các mẫu văn bản giống với dữ liệu được gán nhãn bởi con người [18], điều này giảm đáng kể gánh nặng của các chú thích viên con người [19]. LLMs được huấn luyện theo cách tự giám sát, có thể mở rộng theo lượng corpus văn bản có sẵn trong các miền mở. Không gian tham số lớn của LLMs cũng cho phép chúng lưu trữ một lượng lớn kiến thức, trong khi việc huấn luyện trước quy mô lớn (ví dụ: mục tiêu autoregressive trong việc huấn luyện GPTs) cho phép LLMs mã hóa kiến thức thực tế phong phú cho việc tạo ngôn ngữ ngay cả trong các miền rất cụ thể [20]. Hơn nữa, việc huấn luyện ChatGPT tuân theo InstructGPT [21], sử dụng học tăng cường với phản hồi của con người (RLHF), do đó cho phép nó tạo ra các phản hồi có thông tin hơn và công bằng hơn cho đầu vào.

Lấy cảm hứng từ thành công của các mô hình ngôn ngữ trong việc tạo văn bản, chúng tôi đề xuất một phương pháp tăng cường dữ liệu mới có tên AugGPT, tận dụng ChatGPT để tạo ra các mẫu phụ trợ cho phân loại văn bản few-shot. Chúng tôi kiểm tra hiệu suất của AugGPT thông qua các thí nghiệm trên cả bộ dữ liệu miền chung và miền y tế. So sánh hiệu suất của phương pháp AugGPT được đề xuất với các phương pháp tăng cường dữ liệu hiện có cho thấy cải thiện hai chữ số trong độ chính xác phân loại câu. Nghiên cứu sâu hơn về tính trung thực và compactness của các mẫu văn bản được tạo ra cho thấy AugGPT có thể tạo ra các mẫu được tăng cường đa dạng hơn trong khi đồng thời duy trì độ chính xác của chúng (tức là sự tương đồng ngữ nghĩa với các nhãn gốc). Chúng tôi hình dung rằng sự phát triển của LLMs sẽ dẫn đến hiệu suất chú thích ở mức con người, do đó cách mạng hóa lĩnh vực học few-shot và các tác vụ khác trong NLP.

2 NGHIÊN CỨU LIÊN QUAN

2.1 Tăng cường Dữ liệu

Tăng cường dữ liệu, việc tạo ra văn bản mới một cách nhân tạo thông qua các phép biến đổi, được sử dụng rộng rãi để cải thiện việc huấn luyện mô hình trong phân loại văn bản. Trong NLP, các phương pháp tăng cường dữ liệu hiện có hoạt động ở các mức độ chi tiết khác nhau: ký tự, từ, câu và tài liệu.

Tăng cường dữ liệu ở cấp độ ký tự đề cập đến việc chèn, trao đổi, thay thế hoặc xóa ngẫu nhiên các ký tự trong văn bản [22], điều này cải thiện độ bền vững của mô hình NLP chống lại nhiễu. Một phương pháp khác được gọi là tăng cường dữ liệu nhận dạng ký tự quang học (OCR) tạo ra văn bản mới bằng cách mô phỏng các lỗi xảy ra khi sử dụng các công cụ OCR để nhận dạng văn bản từ hình ảnh. Tăng cường chính tả [23] cố ý viết sai một số từ thường bị viết sai. Tăng cường bàn phím [22] mô phỏng các lỗi gõ ngẫu nhiên bằng cách thay thế một phím được chọn bằng một phím khác gần nó trên bàn phím bố cục QWERTY.

Tăng cường dữ liệu cũng hoạt động ở cấp độ từ. Tăng cường hoán đổi ngẫu nhiên hoán đổi ngẫu nhiên hai từ trong văn bản, và tăng cường xóa ngẫu nhiên xóa ngẫu nhiên một số từ [24]. Tăng cường từ đồng nghĩa sử dụng cơ sở dữ liệu từ đồng nghĩa như PPDB [25] để thay thế các từ được chọn ngẫu nhiên [26]. WordNet [27] cũng được sử dụng rộng rãi làm tham chiếu cho tăng cường từ đồng nghĩa. Các phương pháp này duy trì tính nhất quán ngữ nghĩa và phù hợp cho các tác vụ phân loại văn bản. Wang et al. [28] đề xuất một phương pháp tăng cường dữ liệu dựa trên word embeddings, thay thế các từ bằng n từ tương tự hàng đầu của chúng để tạo ra một câu mới. Các word embeddings được huấn luyện trước khác nhau được xem xét (ví dụ: Google-News Lexical Embeddings [29]). Phương pháp này dựa trên nguyên tắc rằng các từ gần nhau trong không gian embedding thường xuất hiện trong các ngữ cảnh tương tự, điều này có thể giúp duy trì tính nhất quán ngữ pháp.

Tuy nhiên, một hạn chế nghiêm trọng của các phương pháp dựa trên word embedding là các từ gần nhau trong không gian embedding không nhất thiết phải tương đồng về mặt ngữ nghĩa, nhưng những thay đổi ngữ nghĩa có thể ảnh hưởng đến kết quả phân loại. Ví dụ, "hot" và "cold" thường xuất hiện trong các ngữ cảnh tương tự, nên word embeddings của chúng gần nhau, nhưng chúng có ý nghĩa ngữ nghĩa hoàn toàn trái ngược. Tăng cường embedding counter-fitting [30], [31] giải quyết vấn đề này bằng cách sử dụng từ điển từ đồng nghĩa và từ điển từ trái nghĩa để điều chỉnh word embeddings ban đầu. Cụ thể, khoảng cách giữa embeddings của từ đồng nghĩa sẽ được rút ngắn, và khoảng cách giữa embeddings của từ trái nghĩa sẽ được mở rộng.

Tăng cường ngữ cảnh [32], [33] là một phương pháp tăng cường dữ liệu cấp độ từ khác, sử dụng các mô hình ngôn ngữ có mặt nạ (MLMs) như BERT [34], [35], DistilBERT [36] và RoBERTA [37] để tạo ra văn bản mới dựa trên ngữ cảnh. Cụ thể, chúng chèn token <mask> vào một số vị trí của văn bản, hoặc thay thế một số từ trong văn bản bằng token <mask>, và sau đó để MLM dự đoán những từ nào nên được đặt ở những vị trí được che này. Vì MLMs được huấn luyện trước trên một số lượng lớn văn bản, tăng cường ngữ cảnh thường có thể tạo ra văn bản mới có ý nghĩa.

Một số phương pháp tăng cường dữ liệu văn bản hoạt động ở cấp độ câu và tài liệu. Ví dụ, back translation [38] sử dụng các mô hình dịch thuật cho tăng cường dữ liệu. Cụ thể, mô hình ngôn ngữ đầu tiên dịch văn bản sang một ngôn ngữ khác và sau đó dịch ngược lại ngôn ngữ gốc. Do tính ngẫu nhiên của quá trình dịch thuật, văn bản được tăng cường khác với văn bản gốc, nhưng tính nhất quán ngữ nghĩa được duy trì. Ở cấp độ tài liệu, Gangal et al. [39] đề xuất một phương pháp để paraphrase toàn bộ tài liệu để bảo tồn tính nhất quán cấp độ tài liệu.

Nói chung, bất kể mức độ chi tiết hay backbone tạo văn bản (tức là dựa trên quy tắc hoặc mô hình ngôn ngữ), mục tiêu của tăng cường dữ liệu là tạo ra các mẫu mới hợp lý và đa dạng duy trì tính nhất quán ngữ nghĩa.

2.2 Học Few-shot

Deep learning đã đạt được thành công đáng kể trong các ứng dụng sử dụng nhiều dữ liệu khác nhau. Tuy nhiên, hiệu suất của các mô hình deep có thể bị ảnh hưởng nếu kích thước tập dữ liệu nhỏ trong các tác vụ downstream. Học Few-shot là một nhánh khoa học tập trung vào việc phát triển các giải pháp để giải quyết thách thức của kích thước mẫu nhỏ [1], [40]. Nghiên cứu FSL nhằm tận dụng kiến thức trước để nhanh chóng tổng quát hóa cho các tác vụ mới chỉ chứa một vài mẫu được gán nhãn. Một kịch bản ứng dụng cổ điển cho học few-shot là khi việc thu thập các ví dụ có giám sát là khó khăn hoặc không thể thực hiện được do các cân nhắc về quyền riêng tư, an toàn hoặc đạo đức. Sự phát triển của học few-shot cho phép các nhà thực hành cải thiện hiệu quả và độ chính xác của phân loại văn bản trong các kịch bản khác nhau và triển khai các ứng dụng thực tế.

Những tiến bộ gần đây trong học few-shot đã cho thấy kết quả đầy hứa hẹn trong việc vượt qua những thách thức của dữ liệu huấn luyện hạn chế cho phân loại văn bản. Ví dụ, một phương pháp phổ biến trong NLP là sử dụng một mô hình ngôn ngữ được huấn luyện trước như BERT [4] làm điểm xuất phát và sau đó fine-tune nó với các mẫu hạn chế. Một số phát triển phương pháp luận gần đây nhất [2], [41] bao gồm prompt-tuning [6], [7], [8], [9] và meta-learning [2], [5]. Nói chung, các phương pháp FSL hiện có nhắm mục tiêu hoặc thiết kế kiến trúc [2], [3], tăng cường dữ liệu [10], [11] hoặc quá trình huấn luyện [42].

Mặc dù có sự phát triển gần đây của các phương pháp prompt-tuning và meta-learning, chúng gặp phải một số hạn chế lớn. Ví dụ, prompt engineering là một nghệ thuật cồng kềnh đòi hỏi kinh nghiệm rộng rãi và thử-sai thủ công [43]. Mặt khác, meta-learning gặp phải các vấn đề như tính không ổn định trong huấn luyện [44], [45], [46] và nhạy cảm với các siêu tham số [44], [45]. Ngoài ra, tất cả các pipeline FSL này đòi hỏi chuyên môn sâu về machine learning và làm quen với các kiến trúc mô hình phức tạp và chiến lược huấn luyện, điều này không thể đạt được bởi các nhà thực hành thông thường và các nhà phát triển chung. Như đã thảo luận trong phần 2.1, tăng cường dữ liệu là một giải pháp hiệu quả cho FSL và có thể được kết hợp với các mô hình FSL khác. Do đó, phương pháp AugGPT được đề xuất trong bài báo này, đã chứng minh khả năng tạo ra các mẫu huấn luyện chính xác và toàn diện, có thể vượt qua các vấn đề của các phương pháp FSL hiện tại và có khả năng thay đổi bối cảnh của học few-shot trong NLP.

2.3 Mô hình Ngôn ngữ Rất Lớn

Các mô hình ngôn ngữ được huấn luyện trước (PLMs) dựa trên kiến trúc transformer, như họ mô hình BERT [4] và GPT [47], đã cách mạng hóa xử lý ngôn ngữ tự nhiên. So với các phương pháp trước đây, chúng đem lại hiệu suất tiên tiến trên một loạt các tác vụ downstream và góp phần vào sự phổ biến ngày càng tăng và việc dân chủ hóa các mô hình ngôn ngữ. Nói chung, có ba lớp mô hình ngôn ngữ được huấn luyện trước: mô hình ngôn ngữ autoregressive (ví dụ: GPT dựa trên decoder), mô hình ngôn ngữ có mặt nạ (ví dụ: BERT dựa trên encoder), và mô hình encoder-decoder (ví dụ: BART [48] và T5 [49]). Các mô hình này thường chứa từ 100M đến 1B tham số [17].

Trong những năm gần đây, cộng đồng NLP đã chứng kiến sự nổi lên của các mô hình ngôn ngữ rất lớn như GPT-3 (175B tham số) [6], PaLM (540B tham số) [50], Bloom (176B tham số) [51], OPT (lên đến 175B tham số) [52], và dòng FLAN (FLAN có 137B tham số) [53]. Về cốt lõi, các mô hình ngôn ngữ lớn này là các mô hình transformer được lấy cảm hứng từ BERT và GPT, mặc dù ở quy mô lớn hơn nhiều.

Các mô hình ngôn ngữ lớn nhằm học các biểu diễn đặc trưng tiềm ẩn chính xác của văn bản đầu vào. Các biểu diễn này thường phụ thuộc vào ngữ cảnh và miền. Ví dụ, biểu diễn vector của từ "treat" có thể rất khác nhau giữa các miền y tế và miền chung. Đối với các mô hình ngôn ngữ được huấn luyện trước nhỏ hơn, thường cần phải liên tục huấn luyện trước và fine-tune các mô hình như vậy để đạt được hiệu suất chấp nhận được [54]. Tuy nhiên, các mô hình ngôn ngữ rất lớn có thể loại bỏ nhu cầu fine-tuning trong khi duy trì hiệu suất cạnh tranh [6], [18], [55].

Các nghiên cứu hiện có chỉ ra rằng các mô hình ngôn ngữ được huấn luyện trước có thể giúp tăng cường tập dữ liệu với các mẫu mới có ý nghĩa ngữ nghĩa tương tự [12], [16], điều này có giá trị thực tế đáng kể cho các ứng dụng thực tế. Trong nghiên cứu này, chúng tôi nhằm sử dụng ChatGPT, một LLM phổ biến để thực hiện tăng cường dữ liệu. ChatGPT dựa trên GPT-3 [6], được huấn luyện trên dữ liệu web khổng lồ với thông tin đa dạng và phong phú. Hơn nữa, ChatGPT được huấn luyện thông qua Học tăng cường từ Phản hồi Con người (RLHF). Trong RLHF, phản hồi của con người được kết hợp vào quá trình tạo ra và lựa chọn các kết quả tốt nhất. Cụ thể hơn, một mô hình reward được huấn luyện dựa trên xếp hạng của các chú thích viên con người hoặc kết quả được tạo ra. Đổi lại, mô hình reward này thưởng cho các đầu ra mô hình phù hợp nhất với sở thích và giá trị của con người. Chúng tôi tin rằng những đổi mới này khiến ChatGPT trở thành ứng cử viên tốt nhất để tạo ra các mẫu dữ liệu chất lượng ở mức con người.

2.4 ChatGPT: Hiện tại và Tương lai

ChatGPT là một game changer trong xử lý ngôn ngữ tự nhiên. Lần đầu tiên trong lịch sử loài người, sức mạnh của các mô hình ngôn ngữ lớn có thể tiếp cận được với công chúng thông qua giao diện chatbot thân thiện với người dùng. Đổi lại, khả năng tiếp cận chung này góp phần vào sự phổ biến chưa từng có của ChatGPT. ChatGPT đã nổi lên như một người giải quyết vấn đề đa năng cho nhiều ứng dụng NLP [56]. Qin et al. [56] đánh giá ChatGPT trên một tập hợp toàn diện các tác vụ NLP, bao gồm các benchmark phổ biến trong suy luận ngôn ngữ tự nhiên, lý luận số học, nhận dạng thực thể có tên, phân tích tình cảm, trả lời câu hỏi, đối thoại và tóm tắt. Họ kết luận rằng ChatGPT xuất sắc trong hầu hết các tác vụ, ngoại trừ các tác vụ tập trung vào các chi tiết cụ thể (ví dụ: gắn thẻ chuỗi).

ChatGPT cũng là một giải pháp có giá trị cho các tác vụ đa ngôn ngữ. Một nghiên cứu thực nghiệm gần đây [57] báo cáo rằng ChatGPT xuất sắc trong các tác vụ liên quan đến các ngôn ngữ có tài nguyên cao (các ngôn ngữ châu Âu khác nhau và tiếng Trung) và có thể so sánh với Google Translate, DeepL Translate và Tencent TranSmart. Tuy nhiên, ChatGPT hoạt động kém trên các ngôn ngữ có tài nguyên thấp và đối mặt với những thách thức bổ sung khi xử lý dịch thuật ngôn ngữ xa (tức là dịch thuật tiếng Anh-Đức được coi là ít "xa" hơn so với dịch thuật tiếng Anh-Hindi). Một nghiên cứu sau đó [58] xác nhận rằng ChatGPT gặp khó khăn với các ngôn ngữ có tài nguyên thấp, mặc dù các tác giả quan sát thấy rằng ChatGPT làm tốt hơn trong việc hiểu các chữ viết không phải Latin hơn là tạo ra chúng.

Ngoài ra, cũng có thể sử dụng ChatGPT dựa hoàn toàn trên văn bản để tương tác với dữ liệu đa phương thức. Một nhóm các nhà nghiên cứu [58] sử dụng HTML Canvas và Python Turtle graphics làm phương tiện cho việc tạo hình ảnh từ văn bản. ChatGPT có thể tạo ra mã HTML và Python một cách trung thực, sau đó có thể được sử dụng để tạo ra những hình ảnh mong muốn. Các tác giả đã thiết kế một tác vụ vẽ cờ yêu cầu ChatGPT tạo ra mã có thể tạo ra cờ quốc gia. Họ phát hiện rằng ChatGPT có thể tạo ra cờ tốt hơn khi prompt cho mã được đặt trước bởi một prompt yêu cầu ChatGPT mô tả cờ. Nói cách khác, các prompt văn bản mô tả có thể cải thiện hiệu suất tác vụ đa phương thức.

Ngoài khoa học máy tính, ChatGPT có thể được áp dụng dễ dàng cho việc tạo và hiểu báo cáo y tế [59], [60], giáo dục [61], [62], [63], nghiên cứu toán học nghiêm ngặt [64] và tài chính [65]. Nhìn chung, ChatGPT là một công cụ đa năng thúc đẩy việc sử dụng AI chung.

Tuy nhiên, các nhà nghiên cứu cũng thận trọng về tác động tiêu cực có thể có của ChatGPT. Một số mối quan tâm nổi bật hơn liên quan đến bias [66], [67], đạo đức [68], [69], đạo văn [70], [71] và thay thế việc làm hàng loạt [72], [73]. Để đáp ứng, một bình luận được xuất bản trên Nature ủng hộ sự chú ý khẩn cấp đến trách nhiệm giải trình, các mô hình ngôn ngữ lớn mã nguồn mở và sự chấp nhận AI của xã hội [66].

3 TẬP DỮ LIỆU

Chúng tôi đầu tiên sử dụng một tập dữ liệu miền mở Amazon để xác minh hiệu quả của phương pháp của chúng tôi. Sau đó, chúng tôi sử dụng xử lý ngôn ngữ tự nhiên lâm sàng (clinical NLP) làm tác vụ và thực hiện các thí nghiệm của chúng tôi trên hai benchmark công khai phổ biến. Tăng cường dữ liệu đặc biệt được cần trong clinical NLP, bởi vì gánh nặng đáng kể của chú thích chuyên gia và các quy định nghiêm ngặt về quyền riêng tư làm cho việc gán nhãn dữ liệu quy mô lớn trở nên không khả thi. Chúng tôi sẽ mô tả chi tiết các tập dữ liệu này trong các phần sau.

3.1 Tập dữ liệu Amazon

Amazon [74], [75], [76] chứa các đánh giá của khách hàng từ 24 danh mục sản phẩm. Tác vụ là phân loại các đánh giá vào các danh mục sản phẩm tương ứng của chúng. Vì tập dữ liệu sản phẩm Amazon gốc rất lớn, chúng tôi lấy mẫu một tập con gồm 300 mẫu từ mỗi danh mục.

3.2 Tập dữ liệu Symptoms

Tập dữ liệu này được xuất bản trên Kaggle. Nó chứa dữ liệu âm thanh của các mô tả triệu chứng y tế phổ biến trong hơn 8 giờ. Chúng tôi sử dụng các transcript văn bản tương ứng với dữ liệu âm thanh và thực hiện loại bỏ trùng lặp mẫu, và sử dụng chúng làm đầu vào mô hình. Tập dữ liệu sau khi tiền xử lý bao gồm 231 mẫu của 7 danh mục triệu chứng. Mỗi ví dụ đại diện cho một câu mô tả các triệu chứng được cung cấp, và tác vụ là phân loại câu vào các triệu chứng tương ứng.

3.3 Tập dữ liệu PubMed20k

Tập dữ liệu PubMed20K là một tài nguyên được sử dụng rộng rãi trong nghiên cứu NLP và text mining, bao gồm khoảng 20.000 tóm tắt khoa học được chú thích từ lĩnh vực y sinh học. Các chú thích này bao gồm các thực thể có tên, mối quan hệ giữa các thực thể và các vai trò ngữ nghĩa khác nhau, làm cho tập dữ liệu có giá trị cho các tác vụ NLP đa dạng như nhận dạng thực thể có tên, trích xuất mối quan hệ và phân loại văn bản. Tập dữ liệu có nguồn gốc từ cơ sở dữ liệu PubMed, trải rộng trên một loạt các chủ đề y sinh học. Nhờ kích thước đáng kể, sự đa dạng và các chú thích chất lượng cao, PubMed20K đã nổi lên như một tập dữ liệu benchmark phổ biến để đánh giá hiệu suất của các mô hình machine learning trong lĩnh vực NLP y sinh học. Các tóm tắt trong tập dữ liệu PubMed 20K trải qua tiền xử lý và phân đoạn thành các câu riêng lẻ. Mỗi câu được gán nhãn với một trong năm danh mục sau: background, objective, method, result, hoặc conclusion. Tác vụ là ánh xạ các câu đầu vào vào các danh mục tương ứng của chúng.

Thuật toán 1 Framework của AugGPT cho phân loại văn bản few-shot.
Đầu vào: tập dữ liệu cơ sở Db và tập dữ liệu mới Dn
Khởi tạo: Mô hình BERT được huấn luyện trước đã khởi tạo
Định nghĩa: D0 là tập dữ liệu với tập dữ liệu cơ sở Db và tập dữ liệu được tăng cường Daug_n, và chatGPT_aug là phương pháp tăng cường dữ liệu dựa trên ChatGPT
Tham số: Epochs fine-tuning của tập dữ liệu cơ sở epochb, epochs fine-tuning của FSL epochf

for epoch in epochb do
    train(model, Db)
end for
Daug_n = chatGPT_aug(Dn)
for epoch in epochf do
    train(model, Daug_n)
end for

4 PHƯƠNG PHÁP

4.1 Framework Tổng thể

Cho một tập dữ liệu cơ sở Db = {(xi; yi)}^Nb_i=1 với không gian nhãn yi ∈ Yb, một tập dữ liệu mới Dn = {(xj; yj)}^Nn_j=1 với không gian nhãn yj ∈ Yn, và Yb ∩ Yn = ∅. Trong kịch bản phân loại few-shot, tập dữ liệu cơ sở Db có một tập hợp tương đối lớn hơn các mẫu được gán nhãn, trong khi tập dữ liệu mới Dn chỉ có một vài mẫu được gán nhãn. Hiệu suất của học few-shot được đánh giá trên tập dữ liệu mới. Mục tiêu của chúng tôi là huấn luyện một mô hình với cả tập dữ liệu cơ sở và tập dữ liệu mới hạn chế, trong khi đạt được khả năng tổng quát hóa thỏa đáng trên tập dữ liệu mới.

Framework tổng thể của AugGPT được hiển thị trong Hình 1, và các bước huấn luyện được hiển thị trong Thuật toán 1. Trước tiên, chúng tôi fine-tune BERT trên Db. Sau đó, Daug_n được tạo ra bởi tăng cường dữ liệu với ChatGPT. Cuối cùng, chúng tôi fine-tune BERT với Daug_n.

4.2 Tăng cường Dữ liệu với ChatGPT

Tương tự như GPT [47], GPT-2 [77], và GPT-3 [6], ChatGPT thuộc về họ các mô hình ngôn ngữ autoregressive và sử dụng các khối decoder transformer [78] làm backbone mô hình.

Trong quá trình huấn luyện trước, ChatGPT được coi là một ước lượng phân phối không giám sát từ một tập hợp các mẫu X = {x1; x2; ...; xn}, và mẫu xi bao gồm m token được định nghĩa là xi = (s1; s2; ...; sm). Mục tiêu của huấn luyện trước là tối đa hóa likelihood sau:

L(xi) = Σ(i=1 to m) log P(si|s1; ...; si-1; θ) (1)

trong đó θ đại diện cho các tham số có thể huấn luyện được của ChatGPT.

Các token được biểu diễn bởi token embedding và position embedding:

h0 = xiWe + Wp (2)

trong đó We là ma trận token embedding và Wp là ma trận position embedding. Sau đó N khối transformer được sử dụng để trích xuất các đặc trưng của mẫu:

hn = transformer_blocks(hn-1) (3)

trong đó n ∈ [1; N].

Cuối cùng, token đích được dự đoán:

si = softmax(hN W^T_e) (4)

trong đó hN là đầu ra của các khối transformer hàng đầu.

Sau huấn luyện trước, các nhà phát triển ChatGPT áp dụng Học tăng cường từ Phản hồi Con người (RLHF) [21] để fine-tune mô hình ngôn ngữ được huấn luyện trước. RLHF căn chỉnh các mô hình ngôn ngữ với ý định của người dùng trên một loạt các tác vụ bằng cách fine-tune chúng theo phản hồi của con người. RLHF của ChatGPT chứa ba bước:

Supervised Fine-tuning (SFT): Không giống như GPT, GPT-2, và GPT-3, ChatGPT sử dụng dữ liệu được gán nhãn để huấn luyện thêm. Các AI trainers đóng vai trò là người dùng và trợ lý AI để xây dựng câu trả lời dựa trên prompts. Các câu trả lời với prompts được sử dụng như dữ liệu có giám sát để huấn luyện thêm mô hình được huấn luyện trước. Sau khi huấn luyện trước thêm, một mô hình SFT có thể được thu được.

Reward Modeling (RM): Dựa trên phương pháp SFT, một mô hình reward được huấn luyện để nhận vào một cặp prompt và phản hồi, và xuất ra một scalar reward. Các chú thích viên con người xếp hạng các đầu ra từ tốt nhất đến tệ nhất để xây dựng một tập dữ liệu xếp hạng. Hàm loss giữa hai đầu ra được định nghĩa như sau:

loss(r) = E_(x;yw;yl)~Dc [log(σ(rr(x;yw) - rr(x;yl)))] (5)

trong đó r là các tham số của mô hình reward; x là prompt, yw là completion được ưa thích trong cặp yw và yl; Dc là tập dữ liệu so sánh của con người.

Reinforcement Learning (RL): Bằng cách sử dụng các mô hình reward, ChatGPT có thể được fine-tune sử dụng Proximal Policy Optimization (PPO) [79]. Để khắc phục sự suy giảm hiệu suất trên các tập dữ liệu NLP công khai, RLHF trộn các gradient huấn luyện trước vào các gradient PPO, còn được gọi là PPO-ptx:

objective(θ) = Ex~Dpretrain γ log πRL θ(x) + E(x;y)~DRL [rr(x;y) - β log πRL θ(y|x)/πSFT(y|x)] (6)

trong đó πRL θ là chính sách RL đã học được, πSFT là mô hình được huấn luyện có giám sát, và Dpretrain là phân phối huấn luyện trước. γ là hệ số loss huấn luyện trước kiểm soát độ mạnh của các gradient huấn luyện trước, và β là hệ số reward KL kiểm soát độ mạnh của penalty KL.

So với các phương pháp tăng cường dữ liệu trước đây, ChatGPT phù hợp hơn cho tăng cường dữ liệu vì những lý do sau:

- ChatGPT được huấn luyện trước trên các corpus quy mô lớn, vì vậy nó có không gian biểu đạt ngữ nghĩa rộng hơn, và hữu ích để tăng cường sự đa dạng của tăng cường dữ liệu.
- Vì giai đoạn fine-tuning của ChatGPT giới thiệu một số lượng lớn các mẫu chú thích thủ công, ngôn ngữ được tạo ra bởi ChatGPT phù hợp hơn với thói quen biểu đạt của con người.
- Thông qua học tăng cường, ChatGPT có thể so sánh các ưu điểm và nhược điểm của các biểu đạt khác nhau và đảm bảo rằng dữ liệu được tạo ra có chất lượng cao.

Dưới framework BERT, chúng tôi giới thiệu ChatGPT như công cụ tăng cường dữ liệu cho phân loại văn bản few-shot. Cụ thể, ChatGPT được áp dụng để diễn đạt lại mỗi câu đầu vào thành sáu câu bổ sung, do đó tăng cường các mẫu few-shot.

4.3 Phân loại Văn bản Few-shot

Chúng tôi áp dụng BERT [80] để huấn luyện một mô hình phân loại văn bản few-shot. Các đặc trưng đầu ra h của lớp trên cùng của BERT có thể được viết như:

z = [zc; z1; z2; ...; zn]; (7)

trong đó zc là biểu diễn của token đặc trưng lớp CLS. Đối với phân loại văn bản, zc thường được đưa vào một classifier header đặc trưng tác vụ để dự đoán cuối cùng. Tuy nhiên, trong kịch bản FSL, rất khó để đạt được hiệu suất thỏa đáng thông qua fine-tuning BERT vì quy mô nhỏ của các mẫu few-shot sẽ dễ dẫn đến over-fitting và thiếu khả năng tổng quát hóa.

Để giải quyết hiệu quả thách thức của phân loại văn bản few-shot, nhiều phương pháp đã được đề xuất. Nói chung, có bốn danh mục phương pháp cho phân loại văn bản few-shot dựa trên các mô hình ngôn ngữ lớn: meta-learning, prompt-tuning, thiết kế mô hình, và tăng cường dữ liệu. meta-learning đề cập đến quá trình học để học với các tác vụ cập nhật meta-parameters [2], [5]. Các phương pháp dựa trên prompt hướng dẫn các mô hình ngôn ngữ lớn dự đoán kết quả chính xác bằng cách thiết kế templates [6], [7], [8], [9]. Các phương pháp thiết kế mô hình hướng dẫn mô hình học từ các mẫu few-shot bằng cách thay đổi cấu trúc của mô hình [81]. Tăng cường dữ liệu sử dụng các ký tự tương tự [22], ngữ nghĩa từ tương tự [30], [31], hoặc cơ sở kiến thức [55], [82] để mở rộng mẫu. Phương pháp của chúng tôi trực tiếp tăng cường dữ liệu thông qua khả năng ngôn ngữ của các mô hình ngôn ngữ lớn, đây là một phương pháp tăng cường dữ liệu đơn giản và hiệu quả.

Hàm Mục tiêu: Hàm mục tiêu của học few-shot của chúng tôi bao gồm hai phần: cross entropy và contrastive learning loss. Chúng tôi đưa zc vào một lớp fully connected, classifier cho dự đoán cuối cùng:

ŷ = W^T_c zc + bc; (8)

trong đó Wc và bc là các tham số có thể huấn luyện được, và lấy cross-entropy làm một trong các hàm mục tiêu:

LCE = Σ_d∈D0 Σ^C_c=1 ydc ln ŷdc; (9)

trong đó C là chiều đầu ra, bằng với hợp của các không gian nhãn của tập dữ liệu cơ sở và tập dữ liệu mới, và yd là ground truth.

Sau đó, để tận dụng đầy đủ kiến thức trước trong tập dữ liệu cơ sở để hướng dẫn việc học của tập dữ liệu mới, chúng tôi giới thiệu hàm loss contrastive để làm cho biểu diễn mẫu của cùng một danh mục trở nên compact hơn và biểu diễn mẫu của các danh mục khác nhau trở nên tách biệt hơn. Loss contrastive giữa các cặp mẫu trong cùng một batch được định nghĩa như sau:

LCL = -log e^cos(vi;vi') / (e^cos(vi;vi') + Σe^cos(vi;vj)); (10)

trong đó vi và v'i là zc của các mẫu thuộc về cùng một danh mục; vi và vj là zc của các mẫu thuộc về các danh mục khác nhau; cos(·;·) là cosine similarity.

Trong giai đoạn fine-tuning BERT trên tập dữ liệu cơ sở, chúng tôi chỉ sử dụng cross entropy làm hàm mục tiêu. Trong giai đoạn học few-shot, chúng tôi kết hợp cross entropy và contrastive learning loss làm hàm mục tiêu:

L = LCE + LCL: (11)

4.4 Phương pháp Baseline

Trong phần thí nghiệm, chúng tôi so sánh phương pháp của chúng tôi với các phương pháp tăng cường dữ liệu phổ biến khác. Đối với các phương pháp này, chúng tôi sử dụng implementation trong các thư viện mã nguồn mở bao gồm nlpaug [83] và textattack [84].

InsertCharAugmentation. Phương pháp này chèn các ký tự ngẫu nhiên vào các vị trí ngẫu nhiên trong văn bản, điều này cải thiện khả năng tổng quát hóa của mô hình bằng cách tiêm nhiễu vào dữ liệu.

SubstituteCharAugmentation. Phương pháp này thay thế ngẫu nhiên các ký tự được chọn bằng các ký tự khác.

SwapCharAugmentation [22]. Phương pháp này trao đổi ngẫu nhiên hai ký tự.

DeleteCharAugmentation. Phương pháp này xóa ngẫu nhiên các ký tự.

OCRAugmentation. OCRAugmentation mô phỏng các lỗi có thể xảy ra trong quá trình nhận dạng OCR. Ví dụ, công cụ OCR có thể nhận dạng sai "0" thành "o", và nhận dạng sai "I" thành "l".

SpellingAugmentation [23]. Nó tạo ra văn bản mới bằng cách cố ý viết sai một số từ. Phương pháp này sử dụng danh sách các từ tiếng Anh có khả năng bị viết sai nhất được cung cấp bởi Oxford Dictionary, ví dụ, viết sai "because" thành "becouse".

KeyboardAugmentation [22]. Nó mô phỏng lỗi gõ bằng cách thay thế các ký tự được chọn ngẫu nhiên bằng các ký tự liền kề trong bàn phím bố cục QWERTY. Ví dụ, thay thế 'g' bằng 'r', 't', 'y', 'f', 'h', 'v', 'b' hoặc 'n'.

SwapWordAug [24]. Nó trao đổi ngẫu nhiên các từ trong văn bản. Phương pháp này là một phương pháp con của Easy Data Augmentation (EDA) được đề xuất bởi Wei et al.

DeleteWordAug. DeleteWordAug xóa ngẫu nhiên các từ trong văn bản, đây cũng là một phương pháp con của EDA.

PPDBSynonymAug [26]. Nó thay thế các từ bằng từ đồng nghĩa của chúng trong từ điển PPDB. Thay thế từ đồng nghĩa có thể đảm bảo tính nhất quán ngữ nghĩa và phù hợp cho các tác vụ phân loại.

WordNetSynonymAug. Nó thay thế các từ bằng từ đồng nghĩa của chúng trong từ điển WordNet.

SubstituteWordByGoogleNewsEmbeddings [28]. Nó thay thế các từ bằng top-n từ tương tự của chúng trong không gian embedding. Word embeddings được sử dụng được huấn luyện trước với corpus GoogleNews.

InsertWordByGoogleNewsEmbeddings [83]. Nó chọn ngẫu nhiên từ từ vocabulary của corpus GoogleNews và chèn nó vào vị trí ngẫu nhiên của văn bản.

CounterFittedEmbeddingAug [30], [31]. Nó thay thế các từ bằng các từ lân cận của chúng trong không gian embedding counter-fitting. So với vector từ GoogleNews được sử dụng bởi SubstituteWordByGoogleNewsEmbeddings, embedding counter-fitting giới thiệu ràng buộc của từ đồng nghĩa và từ trái nghĩa, tức là embedding giữa các từ đồng nghĩa sẽ được kéo gần hơn, và ngược lại.

ContextualWordAugUsingBert(Insert) [32], [33]. Phương pháp này sử dụng BERT để chèn từ dựa trên ngữ cảnh, tức là thêm token <mask> vào vị trí ngẫu nhiên của văn bản đầu vào, và sau đó để BERT dự đoán token ở vị trí đó.

ContextualWordAugUsingDistilBERT(Insert). Phương pháp này sử dụng DistilBERT để thay thế BERT cho dự đoán, và phần còn lại giống như ContextualWordAugUsingBert(Insert).

ContextualWordAugUsingRoBERTA(Insert). Phương pháp này sử dụng RoBERTA để thay thế BERT cho dự đoán, và phần còn lại giống như ContextualWordAugUsingBert(Insert).

ContextualWordAugUsingBert(Substitute). Phương pháp này [32], [33] sử dụng BERT để thay thế từ dựa trên ngữ cảnh, tức là thay thế các từ được chọn ngẫu nhiên trong văn bản bằng token <mask>, và sau đó để BERT dự đoán token ở vị trí đó.

ContextualWordAugUsingDistilBERT(Substitute). Phương pháp này sử dụng DistilBERT để thay thế BERT cho dự đoán, và phần còn lại giống như ContextualWordAugUsingBert(Substitute).

ContextualWordAugUsingRoBERTA(Substitute). Phương pháp này sử dụng RoBERTA để thay thế BERT cho dự đoán, và phần còn lại giống như ContextualWordAugUsingBert(Substitute).

BackTranslationAug. Phương pháp [38] dịch văn bản sang tiếng Đức và sau đó sang tiếng Anh, tạo ra một văn bản mới khác với bản gốc nhưng có cùng ngữ nghĩa. Chúng tôi sử dụng các mô hình dịch ngôn ngữ wmt19-en-de và facebook/wmt19-de-en [85] được phát triển bởi Facebook để dịch thuật.

4.5 Thiết kế Prompt

Chúng tôi đã thiết kế prompts cho đối thoại một lượt và đối thoại nhiều lượt. Các prompts được hiển thị trong Hình 2. Tập dữ liệu Amazon sử dụng prompt đối thoại nhiều lượt để tăng cường dữ liệu. Symptoms và PubMed20K sử dụng prompt đối thoại một lượt để tăng cường dữ liệu.

4.6 Các Metric Đánh giá

Chúng tôi sử dụng cosine similarity và TransRate [86] làm các metric để đánh giá tính trung thực (tức là, liệu các mẫu dữ liệu được tạo ra có gần với các mẫu gốc hay không) và compactness (tức là, liệu các mẫu của mỗi lớp có đủ compact để phân biệt tốt hay không) của dữ liệu được tăng cường.

4.6.1 Embedding Similarity

Để đánh giá sự tương đồng ngữ nghĩa giữa các mẫu được tạo ra bởi các phương pháp tăng cường dữ liệu và các mẫu thực tế, chúng tôi áp dụng embedding similarity giữa các mẫu được tạo ra và các mẫu thực tế của tập dữ liệu test. Một số metric tương đồng phổ biến nhất bao gồm khoảng cách Euclidean, cosine similarity và dot product similarity. Trong nghiên cứu này, chúng tôi chọn cosine similarity để nắm bắt mối quan hệ khoảng cách trong không gian tiềm ẩn. Cosine similarity đo giá trị cosine của góc giữa hai vector. Giá trị này tăng khi hai vector tương đồng hơn, và được giới hạn bởi một phạm vi từ 0 đến 1. Vì các mô hình ngôn ngữ được huấn luyện trước mà không fine-tuning kém trong việc nắm bắt ý nghĩa ngữ nghĩa, chúng tôi fine-tune BERT được huấn luyện trước trên tập dữ liệu cơ sở bằng phương pháp BERT-flow [87], và cuối cùng áp dụng BERT đã fine-tune để lấy sample embedding. Metric cosine similarity thường được sử dụng trong NLP [88] và chúng tôi tuân theo quy ước này.

cos(θ) = A·B / (||A||₂||B||₂); (12)

trong đó A và B biểu thị hai vector embedding đang được so sánh, tương ứng.

4.6.2 TransRate

TransRate là một metric định lượng khả năng transfer dựa trên thông tin tương hỗ giữa các đặc trưng được trích xuất bởi một mô hình được huấn luyện trước và các nhãn của chúng, với một lần thông qua dữ liệu đích. Metric đạt giá trị tối thiểu khi các ma trận hiệp phương sai dữ liệu của tất cả các lớp giống hệt nhau, khiến không thể phân biệt giữa dữ liệu từ các lớp khác nhau và ngăn cản bất kỳ classifier nào đạt được kết quả tốt hơn so với đoán ngẫu nhiên. Do đó, TransRate cao hơn có thể chỉ ra khả năng học tốt hơn của dữ liệu. Cụ thể hơn, transfer kiến thức từ tác vụ nguồn Ts đến tác vụ đích Tt được đo như được hiển thị bên dưới:

TrRTs→Tt(g) = H(Z) - H(Z|Y); (13)

trong đó Y đại diện cho các nhãn của các ví dụ được tăng cường, và Z biểu thị các đặc trưng embedding tiềm ẩn được trích xuất bởi feature extractor g được huấn luyện trước. TrR có nghĩa là giá trị TransRate. H(·) biểu thị Shannon entropy [89].

4.7 Hiệu suất Phân loại Trực tiếp bởi ChatGPT

Một câu hỏi thú vị và quan trọng về việc sử dụng ChatGPT cho tăng cường dữ liệu văn bản sẽ là ChatGPT sẽ hoạt động như thế nào khi được áp dụng trực tiếp cho các tác vụ downstream FSL. Do đó, chúng tôi đã phát triển các prompt được thiết kế riêng cho ChatGPT để thực hiện các tác vụ phân loại với API tích hợp để prompting. Đối với tập dữ liệu Symptoms, chúng tôi sử dụng hướng dẫn prompt sau: "Cho mô tả sức khỏe hoặc triệu chứng của một người, dự đoán bệnh tương ứng từ các danh mục sau: CLASSES." Ngoài ra, chúng tôi sử dụng "Description: DESCRIPTION. Typically, this symptom corresponds to CLASS" làm prompt cho mỗi ví dụ trong tập dữ liệu. Bằng cách này, chúng tôi có thể bao gồm các ví dụ few-shot (trong nghiên cứu này, chúng tôi sử dụng hai) để tạo điều kiện cho việc thích ứng của mô hình với các tác vụ downstream. Chúng tôi sử dụng các hướng dẫn prompt được thiết kế tương tự cho hai tác vụ khác và prompt ví dụ tương ứng để thực hiện few-shot in-context learning bởi ChatGPT.

5 KẾT QUẢ THÍ NGHIỆM

Trong các thí nghiệm của chúng tôi, chúng tôi sử dụng BERT làm mô hình cơ sở. Trước tiên, chúng tôi huấn luyện mô hình của chúng tôi trên tập dữ liệu cơ sở để tạo ra mô hình được huấn luyện trước. Sau đó chúng tôi fine-tune mô hình với sự kết hợp của các mẫu few-shot và các mẫu được tăng cường được tạo ra từ các phương pháp tăng cường dữ liệu khác nhau. Cụ thể, trong tất cả ba tác vụ FSL, chúng tôi thực hiện học 2-shot, tức là sẽ có hai mẫu thực được sử dụng cho mỗi lớp trong miền đích. Sau đó, chúng tôi sử dụng những mẫu đó để fine-tune các mô hình được huấn luyện trước. Để đánh giá hiệu quả của các phương pháp tăng cường dữ liệu khác nhau, chúng tôi áp dụng hai cài đặt khác nhau. Cái đầu tiên là mô hình BERT vanilla. Trong cài đặt thứ hai, chúng tôi thêm contrastive loss vào hàm mục tiêu huấn luyện. Trong các thí nghiệm của chúng tôi trên tập dữ liệu Symptoms, chúng tôi sử dụng batch size là 8 cho 150 epochs, đặt độ dài chuỗi tối đa là 25, λ là 1, và sử dụng learning rate là 4e-5. Trong các thí nghiệm của chúng tôi trên tập dữ liệu PubMed20K, chúng tôi áp dụng cùng cấu hình huấn luyện, với độ dài chuỗi tối đa được đặt là 40. Đối với tất cả ba tác vụ, chúng tôi sẽ tạo ra sáu mẫu được tăng cường cho mỗi lớp. Các ví dụ về các mẫu được tăng cường được tạo ra bởi AugGPT và các phương pháp baseline được chọn khác có thể được tìm thấy trong phụ lục.

5.1 So sánh Hiệu suất Phân loại

Bảng 2 hiển thị độ chính xác của các phương pháp tăng cường dữ liệu khác nhau. Như được hiển thị trong Bảng 2, AugGPT đạt được độ chính xác cao nhất cho các tập dữ liệu Amazon, Symptoms và PubMed20K. Đối với tập dữ liệu Amazon, AugGPT và InsertWordByGoogleNewsEmbeddings đạt được hiệu suất tốt nhất cho BERT, và AugGPT đạt được hiệu suất tốt nhất cho BERT với contrastive loss. Trong tập dữ liệu PubMed20K, AugGPT đạt được độ chính xác 83.5% cho cả BERT và BERT với contrastive loss, trong khi không có tăng cường dữ liệu, các giá trị độ chính xác chỉ là 79.2% và 79.8%, tương ứng. Đối với tập dữ liệu Symptoms, độ chính xác cho BERT sau tăng cường downstream chỉ là 63.6%, và 60.6% với contrastive loss. Tuy nhiên, phương pháp AugGPT của chúng tôi cải thiện đáng kể độ chính xác lên 88.9% và 89.9%, tương ứng. Những kết quả này cho thấy rằng tăng cường dữ liệu sử dụng ChatGPT hiệu quả hơn trong việc nâng cao hiệu suất của các mô hình machine learning trong các ứng dụng khác nhau.

5.2 Đánh giá Tập dữ liệu được Tăng cường

Ngoài độ chính xác phân loại, chúng tôi đánh giá dữ liệu được tăng cường trong không gian tiềm ẩn và visualize kết quả trong Hình 3. Latent embeddings được đánh giá sử dụng cosine similarity và metric TransRate (xem phần 4.6 để biết thêm chi tiết). Trục ngang đại diện cho các giá trị cosine similarity và Transrate, và trục dọc mô tả độ chính xác phân loại. Vì embedded similarity đo sự tương đồng giữa dữ liệu được tạo ra và tập dữ liệu test, sự tương đồng cao có nghĩa là dữ liệu được tạo ra gần với dữ liệu đầu vào thực và có tính trung thực và compactness cao hơn. TransRate cao hơn chỉ ra khả năng học tốt hơn của dữ liệu. Do đó, điểm TransRate cao hơn chỉ ra rằng dữ liệu được tăng cường có chất lượng cao hơn. Phương pháp ứng cử viên lý tưởng nhất nên được định vị ở phía trên bên phải của visualization. Như được hiển thị trong Hình 3, AugGPT tạo ra các mẫu chất lượng cao về cả tính trung thực và compactness trên tập dữ liệu Symptoms và tập dữ liệu PubMed20K. Trên tập dữ liệu miền mở Amazon, AugGPT cũng tạo ra các mẫu chất lượng cao với TransRate cao hơn.

5.3 So sánh Hiệu suất với ChatGPT

Hơn nữa, chúng tôi sử dụng ChatGPT để trực tiếp thực hiện các tác vụ phân loại dữ liệu văn bản downstream dưới sơ đồ học 5-shot. Chúng tôi sử dụng các hướng dẫn được thiết kế nội bộ với các ví dụ in-context few-shot để prompt ChatGPT như được mô tả trong 4.7. Hiệu suất của ChatGPT cho các tác vụ downstream được liệt kê trong Bảng 2. Kết quả cho thấy rằng các mô hình ngôn ngữ lớn tiên tiến như ChatGPT có xu hướng hoạt động tốt hơn trên các tác vụ tương đối dễ hơn, ví dụ, xác định triệu chứng theo mô tả một câu. Tuy nhiên, khi nói đến các tác vụ phức tạp như PubMed, fine-tuning mô hình vẫn cần thiết và có thể đạt được hiệu suất tốt hơn so với các prompt few-shot.

6 KẾT LUẬN VÀ THẢO LUẬN

Trong bài báo này, chúng tôi đề xuất một phương pháp tăng cường dữ liệu mới cho phân loại few-shot. Không giống như các phương pháp khác, mô hình của chúng tôi mở rộng dữ liệu hạn chế ở cấp độ ngữ nghĩa để tăng cường tính nhất quán và robustness của dữ liệu, điều này dẫn đến hiệu suất tốt hơn so với hầu hết các phương pháp tăng cường dữ liệu văn bản hiện tại. Với sự tiến bộ của LLM và bản chất của nó như một multi-task learner [77], chúng tôi hình dung rằng một loạt các tác vụ trong NLP có thể được tăng cường hoặc thậm chí được thay thế theo cách tương tự.

Mặc dù AugGPT đã cho thấy kết quả đầy hứa hẹn trong tăng cường dữ liệu, nó có những hạn chế nhất định. Ví dụ, khi nhận dạng và tăng cường văn bản y tế, AugGPT có thể tạo ra kết quả tăng cường không chính xác do thiếu kiến thức miền của ChatGPT. Trong các nghiên cứu tương lai, chúng tôi sẽ điều tra việc thích ứng các LLMs miền chung, như ChatGPT, với dữ liệu đặc trưng miền, như văn bản y tế, thông qua fine-tuning mô hình, in-context learning (prompt engineering), knowledge distillation, style transfer, v.v.

AugGPT đã chứng minh rằng kết quả tăng cường có thể cải thiện hiệu quả hiệu suất của tác vụ phân loại downstream. Một hướng đầy hứa hẹn cho nghiên cứu tương lai là điều tra AugGPT chống lại một loạt rộng hơn các tác vụ downstream. Ví dụ, với khả năng mạnh mẽ của ChatGPT để trích xuất các điểm chính và hiểu câu, nó có thể được sử dụng trong các tác vụ như tóm tắt văn bản. Cụ thể, ChatGPT có thể có giá trị cho tóm tắt bài báo khoa học đặc trưng miền [90] và tóm tắt báo cáo lâm sàng [91]. Các tập dữ liệu tóm tắt bài báo khoa học đặc trưng miền và tập dữ liệu báo cáo lâm sàng có sẵn công khai rất hiếm và thường được cung cấp ở quy mô nhỏ do các mối quan tâm về quyền riêng tư và nhu cầu về kiến thức chuyên gia để tạo ra các bản tóm tắt được chú thích. Tuy nhiên, ChatGPT có thể giải quyết thách thức này bằng cách tạo ra các mẫu tóm tắt được tăng cường đa dạng trong các kiểu biểu diễn khác nhau. Dữ liệu được tạo ra từ ChatGPT thường ngắn gọn, có thể có giá trị để tăng cường thêm khả năng tổng quát hóa của mô hình được huấn luyện.

Sự gia tăng đáng kể của các mô hình hình ảnh tạo sinh như DALLE2 [92] và Stable Diffusion [93] cung cấp cơ hội áp dụng AugGPT cho các tác vụ học few-shot trong computer vision. Ví dụ, các mô tả ngôn ngữ chính xác có thể được sử dụng để hướng dẫn mô hình tạo sinh tạo ra hình ảnh từ văn bản hoặc tạo ra hình ảnh mới dựa trên hình ảnh hiện có như một phương pháp tăng cường dữ liệu cho các tác vụ học few-shot, đặc biệt khi kết hợp với các phương pháp fine-tuning hiệu quả [94], [95] như LoRA cho Stable Diffusion. Do đó, kiến thức trước từ một mô hình ngôn ngữ lớn có thể tạo điều kiện cho việc thích ứng miền nhanh hơn và học few-shot tốt hơn của các mô hình tạo sinh trong computer vision.

Nghiên cứu gần đây cho thấy rằng các mô hình ngôn ngữ lớn (LLMs), như GPT-3 và ChatGPT, có khả năng giải quyết các tác vụ Theory of Mind (ToM), trước đây được cho là độc nhất của con người [96]. Trong khi khả năng giống ToM của LLMs có thể là một sản phẩm phụ không mong muốn của hiệu suất được cải thiện, mối liên hệ cơ bản giữa khoa học nhận thức và não bộ con người là một lĩnh vực chín muồi để khám phá. Những tiến bộ trong khoa học nhận thức và não bộ cũng có thể được sử dụng để truyền cảm hứng và tối ưu hóa thiết kế của LLMs. Ví dụ, đã được đề xuất rằng các mẫu kích hoạt của các neuron trong mô hình BERT và những mẫu trong các mạng não bộ con người có thể chia sẻ những điểm tương đồng và có thể được kết hợp với nhau [97]. Điều này trình bày một hướng mới đầy hứa hẹn để phát triển LLMs bằng cách sử dụng kiến thức trước từ khoa học não bộ. Khi các nhà nghiên cứu tiếp tục điều tra các mối liên hệ giữa LLMs và não bộ con người, chúng ta có thể khám phá ra những phương tiện mới để nâng cao hiệu suất và khả năng của các hệ thống AI, dẫn đến những đột phá thú vị trong lĩnh vực này.

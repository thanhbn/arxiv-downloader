# Tạo Dữ Liệu Tổng Hợp với Mô Hình Ngôn Ngữ Lớn cho Phân Loại Văn Bản: Tiềm Năng và Giới Hạn

Zhuoyan Li1, Hangxiao Zhu2, Zhuoran Lu1, Ming Yin1
1Đại học Purdue
2Đại học Washington tại St. Louis
{li4178, lu800, mingyin}@purdue.edu ,hangxiao@wustl.edu

## Tóm tắt
Việc thu thập và tuyển chọn dữ liệu huấn luyện chất lượng cao là rất quan trọng để phát triển các mô hình phân loại văn bản có hiệu suất vượt trội, nhưng thường đi kèm với chi phí và thời gian đầu tư đáng kể. Các nhà nghiên cứu gần đây đã khám phá việc sử dụng mô hình ngôn ngữ lớn (LLM) để tạo ra các tập dữ liệu tổng hợp như một phương pháp thay thế. Tuy nhiên, hiệu quả của dữ liệu tổng hợp do LLM tạo ra trong việc hỗ trợ huấn luyện mô hình không nhất quán giữa các nhiệm vụ phân loại khác nhau. Để hiểu rõ hơn các yếu tố điều tiết hiệu quả của dữ liệu tổng hợp do LLM tạo ra, trong nghiên cứu này, chúng tôi tìm hiểu cách hiệu suất của các mô hình được huấn luyện trên dữ liệu tổng hợp này có thể thay đổi theo tính chủ quan của phân loại. Kết quả của chúng tôi cho thấy tính chủ quan, ở cả cấp độ nhiệm vụ và cấp độ thể hiện, có mối quan hệ tiêu cực với hiệu suất của mô hình được huấn luyện trên dữ liệu tổng hợp. Chúng tôi kết luận bằng việc thảo luận về những hàm ý của công trình này đối với tiềm năng và giới hạn của việc tận dụng LLM để tạo dữ liệu tổng hợp.

## 1 Giới thiệu
Ngày nay, các mô hình phân loại văn bản được hỗ trợ bởi học máy đã được áp dụng rộng rãi trong các ứng dụng đa dạng như phát hiện ngôn ngữ thiên vị hoặc độc hại trên các nền tảng trực tuyến (Wiegand et al., 2019) và lọc email spam (Jindal và Liu, 2007). Tuy nhiên, hiệu suất của các mô hình này phụ thuộc rất nhiều vào chất lượng của dữ liệu huấn luyện. Điều này tạo ra một thách thức đáng kể trong thực tế, đặc biệt khi cần xây dựng mô hình cho một miền nhiệm vụ mới hoặc để tích hợp các danh mục phân loại mới, vì quá trình thu thập và tuyển chọn dữ liệu huấn luyện thường tốn kém, mất thời gian và phức tạp.

Trong khi đó, với những tiến bộ gần đây trong các mô hình ngôn ngữ lớn (LLM), các nhà nghiên cứu đã bắt đầu khám phá tiềm năng của việc sử dụng LLM để tạo ra dữ liệu tổng hợp phù hợp với các nhiệm vụ cụ thể và tăng cường dữ liệu huấn luyện trong các thiết lập có ít tài nguyên dữ liệu (Kumar et al., 2020; Yoo et al., 2021; Hartvigsen et al., 2022; Sahu et al., 2022). Gần đây nhất, một số nghiên cứu cũng điều tra khả năng tạo ra một tập dữ liệu tổng hợp từ đầu bằng LLM để hỗ trợ học zero-shot (Ye et al., 2022; Wang et al., 2021; Tang et al., 2023; Gao et al., 2023). Mặc dù việc tăng cường dữ liệu dựa trên LLM thường được phát hiện vượt trội hơn các phương pháp tăng cường dữ liệu khác trong việc cải thiện hiệu suất mô hình, các kết quả hỗn hợp được báo cáo về việc liệu dữ liệu tổng hợp do LLM tạo ra có thể hỗ trợ hiệu quả huấn luyện mô hình để đạt được mức hiệu suất tương đương với các mô hình được huấn luyện trên dữ liệu được thu thập trong thế giới thực và được chú thích cẩn thận hay không. Điều này để lại sự không chắc chắn cho các nhà nghiên cứu và thực hành trong việc quyết định có nên dựa vào LLM để tạo dữ liệu tổng hợp hay tiếp tục với quy trình thu thập và tuyển chọn dữ liệu truyền thống khi họ cần xây dựng một mô hình phân loại văn bản cho một nhiệm vụ mới. Tự nhiên, người ta có thể tự hỏi những yếu tố nào có thể điều tiết hiệu quả của dữ liệu tổng hợp do LLM tạo ra trong việc hỗ trợ huấn luyện mô hình thành công.

Chúng tôi phỏng đoán rằng một yếu tố như vậy có thể là tính chủ quan của các nhiệm vụ phân loại. Thật vậy, ngôn ngữ vốn dĩ mang tính chủ quan và giải thích (Benveniste, 1971; Wiebe et al., 2004). Nghiên cứu trước đây đã cho thấy mọi người thường nhận thức văn bản giống nhau theo những cách khác nhau vì thiên kiến và quan điểm cá nhân của họ (Sap et al., 2021; Li et al., 2022; Gordon et al., 2022). Do đó, việc đạt được hiệu suất mô hình cao cho các nhiệm vụ phân loại có tính chủ quan cao dường như đặt ra yêu cầu lớn hơn đối với dữ liệu huấn luyện trong việc phản ánh sự phong phú và tinh tế có trong ngôn ngữ con người, và mức độ mà dữ liệu tổng hợp do LLM tạo ra có thể hoàn thành mục tiêu này là không rõ ràng.

Do đó, trong bài báo này, chúng tôi chính thức đánh giá hiệu quả của LLM (tức là mô hình GPT-3.5-Turbo tiên tiến) trong việc tạo ra dữ liệu tổng hợp để hỗ trợ huấn luyện mô hình cho các nhiệm vụ phân loại văn bản khác nhau. Chúng tôi áp dụng hai phương pháp để tạo dữ liệu tổng hợp—một thiết lập zero-shot trong đó LLM được nhắc trực tiếp để tạo ra các thể hiện văn bản với các nhãn khác nhau quan tâm, và một thiết lập few-shot trong đó một số thể hiện dữ liệu thế giới thực được cung cấp làm ví dụ để hướng dẫn LLM trong việc tạo ra dữ liệu tổng hợp. Chúng tôi tiến hành hai nghiên cứu đánh giá, mỗi nghiên cứu tương ứng với một chiều của tính chủ quan—nghiên cứu đầu tiên kiểm tra hiệu quả của dữ liệu tổng hợp trên 10 loại nhiệm vụ phân loại và khám phá cách nó thay đổi với tính chủ quan cấp độ nhiệm vụ (tức là liệu loại nhiệm vụ phân loại này có mang tính chủ quan hay không); nghiên cứu thứ hai liên quan đến việc cho một nhiệm vụ phân loại cụ thể, hiệu suất của một mô hình được huấn luyện trên dữ liệu tổng hợp thay đổi như thế nào với tính chủ quan cấp độ thể hiện (tức là liệu mọi người có xu hướng không đồng ý với nhau về nhãn của thể hiện nhiệm vụ này hay không). Các phát hiện của chúng tôi cho thấy rằng trên 10 loại nhiệm vụ phân loại mà chúng tôi đã xem xét trong nghiên cứu này, các mô hình được huấn luyện trên dữ liệu tổng hợp do LLM tạo ra thường hoạt động kém hơn những mô hình được huấn luyện trên dữ liệu thế giới thực, tuy nhiên việc hướng dẫn quá trình tạo dữ liệu tổng hợp của LLM với một lượng nhỏ dữ liệu thế giới thực (tức là như được thực hiện trong thiết lập tạo dữ liệu few-shot) có thể cải thiện hiệu quả của dữ liệu được tạo ra. Hơn nữa, chúng tôi thấy rằng hiệu suất của các mô hình được huấn luyện trên dữ liệu tổng hợp do LLM tạo ra rất gần với những mô hình được huấn luyện trên dữ liệu thế giới thực cho các nhiệm vụ có tính chủ quan thấp (ví dụ: phân loại chủ đề tin tức, phát hiện email spam), trong khi sự giảm hiệu suất lớn hơn nhiều trên các nhiệm vụ có tính chủ quan cao (ví dụ: phát hiện hài hước hoặc châm biếm). Cuối cùng, ngay cả trong cùng một loại nhiệm vụ phân loại, các mô hình được huấn luyện trên dữ liệu tổng hợp do LLM tạo ra có xu hướng thể hiện mức hiệu suất cao hơn trên những thể hiện nhiệm vụ có tính chủ quan thấp hơn, mà đối với đó các chú thích viên con người thể hiện mức độ đồng ý cao hơn trong chú thích của họ.

Cùng nhau, nghiên cứu của chúng tôi cung cấp bằng chứng thực nghiệm quan trọng về tiềm năng và giới hạn của việc sử dụng LLM để tạo ra dữ liệu tổng hợp cho các nhiệm vụ phân loại văn bản. Chúng tôi kết luận bằng việc thảo luận về những hàm ý, giới hạn và công việc tương lai của nghiên cứu này.

## 2 Công trình liên quan

**AI sinh tạo trong tạo dữ liệu tổng hợp.** Những tiến bộ gần đây trong AI sinh tạo đã thúc đẩy nhiều nghiên cứu khám phá tiềm năng của việc tận dụng các mô hình sinh tạo để tạo ra dữ liệu tổng hợp cho việc huấn luyện các mô hình học máy, đặc biệt cho các nhiệm vụ thị giác máy tính (CV) và xử lý ngôn ngữ tự nhiên (NLP). Trong lĩnh vực CV, một số công trình đã sử dụng các mô hình dựa trên GAN (Karras et al., 2019) hoặc mô hình khuếch tán (Nichol et al., 2021) để tạo ra dữ liệu tổng hợp cho nhận dạng hình ảnh (Besnier et al., 2020; He et al., 2022) hoặc phân đoạn đối tượng (Zhang et al., 2021). Tương tự, trong lĩnh vực NLP, các nhà nghiên cứu cũng đã tìm hiểu khả năng của các mô hình ngôn ngữ trong việc tạo ra dữ liệu tổng hợp cho các nhiệm vụ phân loại văn bản khác nhau (Kumar et al., 2020; Chung et al., 2023; Sahu et al., 2022; Yoo et al., 2021; Ye et al., 2022; Wang et al., 2021; Hartvigsen et al., 2022; Meng et al., 2022; Gao et al., 2022; Aggarwal et al., 2022; Chen et al., 2022), với các kết quả hỗn hợp được báo cáo về hiệu quả của dữ liệu tổng hợp được tạo ra. Trong nghiên cứu này, chúng tôi nhằm mục đích hiểu rõ hơn về thời điểm dữ liệu tổng hợp được tạo ra bởi các mô hình ngôn ngữ có thể dẫn đến huấn luyện mô hình hiệu quả, và chúng tôi tập trung vào khám phá vai trò của tính chủ quan nhiệm vụ trong việc điều tiết hiệu quả của dữ liệu tổng hợp.

**Mô hình ngôn ngữ lớn.** Dựa trên kiến trúc Transformer (Vaswani et al., 2017), các mô hình ngôn ngữ lớn (LLM) đã tạo ra tiến bộ đáng kể trong lĩnh vực xử lý ngôn ngữ tự nhiên. Việc sử dụng ngữ cảnh hai chiều trong mô hình BERT (Devlin et al., 2018) đã dẫn đến hiệu suất vượt trội trên một loạt các nhiệm vụ. Dựa trên điều này, chuỗi GPT của OpenAI, bao gồm các mô hình như GPT-2 (Radford et al., 2019), GPT-3 khổng lồ (Brown et al., 2020) với 175 tỷ tham số ấn tượng và GPT-4 mới nhất (OpenAI, 2023), đã đẩy ranh giới về khả năng của LLM. Các mô hình này thể hiện khả năng đáng kể trong việc tạo ra văn bản giống con người chất lượng cao (Clark et al., 2021; Dou et al., 2021; Zhou et al., 2023), thể hiện khả năng trong suy luận cơ bản (Wei et al., 2021), dịch thuật (Brown et al., 2020), tạo dữ liệu tổng hợp khoa học (Hämäläinen et al., 2023), và tạo mã (Mcnutt et al., 2023). Trong nghiên cứu này, chúng tôi tập trung vào tận dụng mô hình GPT-3.5-Turbo tiên tiến để khám phá khả năng và giới hạn của nó trong việc tổng hợp dữ liệu cho các nhiệm vụ phân loại văn bản với các mức độ chủ quan khác nhau.

## 3 Phương pháp

Trong phần này, chúng tôi nêu ra quy trình mà chúng tôi đã tuân theo khi tận dụng mô hình ngôn ngữ lớn để tạo ra dữ liệu huấn luyện tổng hợp cho phân loại văn bản. Chúng tôi xem xét hai thiết lập tạo dữ liệu trong nghiên cứu này, tức là thiết lập zero-shot và thiết lập few-shot.

### 3.1 Tạo Dữ Liệu Tổng Hợp Zero-shot

Trong thiết lập tạo dữ liệu tổng hợp zero-shot, cho một nhiệm vụ phân loại văn bản, chúng tôi giả định rằng dữ liệu thế giới thực dưới dạng "cặp văn bản-nhãn" không tồn tại. Do đó, để có được dữ liệu huấn luyện tổng hợp cho nhiệm vụ phân loại văn bản, hai lời nhắc tuần tự được xây dựng và cung cấp cho mô hình ngôn ngữ lớn được huấn luyện trước (tức là mô hình GPT-3.5-Turbo). Đầu tiên, một "lời nhắc ngữ cảnh" tùy chỉnh liên quan đến miền mục tiêu quan tâm được sử dụng để thiết lập ngữ cảnh. Ví dụ, trong trường hợp nhiệm vụ phân loại đánh giá phim IMDB (Maas et al., 2011), lời nhắc ngữ cảnh tùy chỉnh được sử dụng là "Hãy tưởng tượng bạn là một nhà phê bình phim trên nền tảng IMDB". Lời nhắc này nhằm khuyến khích LLM tạo ra dữ liệu tổng hợp giống với các văn bản thực tế được sản xuất trong miền mục tiêu. Sau khi ngữ cảnh được thiết lập, một lời nhắc thứ hai, tức là "lời nhắc tạo dữ liệu", được cung cấp cho LLM, hướng dẫn mô hình tạo ra các văn bản với phong cách, nhãn (đối với nhiệm vụ phân loại quan tâm) và giới hạn từ cụ thể. Ví dụ, đối với nhiệm vụ phân loại đánh giá phim IMDB, phong cách của văn bản là một đánh giá phim, và nhãn là một cảm xúc mục tiêu được truyền đạt bởi đánh giá (tức là "tích cực" hoặc "tiêu cực"). Để tăng cường thêm sự đa dạng của dữ liệu được tạo ra, sau khi tạo ra mỗi n điểm dữ liệu (tức là các văn bản có phong cách, nhãn và giới hạn từ mục tiêu), chúng tôi cung cấp một "lời nhắc đa dạng" cho LLM—"Bạn có thể cung cấp điều gì đó đa dạng hơn so với dữ liệu được tạo ra trước đây không?"—nhằm tăng sự đa dạng của dữ liệu tổng hợp được tạo ra.

### 3.2 Tạo Dữ Liệu Tổng Hợp Few-shot

Trong thiết lập tạo dữ liệu tổng hợp few-shot, chúng tôi giả định rằng một lượng nhỏ dữ liệu thế giới thực có sẵn cho nhiệm vụ phân loại văn bản. Các điểm dữ liệu này sau đó có thể phục vụ như những ví dụ cho mô hình ngôn ngữ lớn trong quá trình tạo dữ liệu, có thể cung cấp cho LLM những hiểu biết về các mẫu được thể hiện trong dữ liệu thế giới thực. Chúng tôi lại bắt đầu quá trình tạo dữ liệu bằng cách sử dụng lời nhắc ngữ cảnh để thiết lập ngữ cảnh. Tuy nhiên, khác với thiết lập zero-shot, ở đây, mỗi lần trước khi chúng tôi hướng dẫn LLM tạo ra một đoạn văn bản, chúng tôi trước tiên cung cấp cho mô hình một số thể hiện dữ liệu thế giới thực được lấy mẫu ngẫu nhiên (bao gồm cả văn bản và nhãn) làm ví dụ. Để giữ cho LLM không chỉ diễn giải lại các ví dụ được cung cấp, một lời nhắc bổ sung được sử dụng để áp đặt ràng buộc lên LLM trong việc tạo ra dữ liệu tổng hợp (tức là "Bạn nên bắt chước ví dụ tôi đã cung cấp, nhưng bạn không thể chỉ đơn giản sửa đổi hoặc viết lại ví dụ tôi đã đưa ra.").

Để biết thêm chi tiết về các lời nhắc được sử dụng để tạo dữ liệu cho từng loại nhiệm vụ phân loại văn bản, vui lòng tham khảo Phụ lục D.

## 4 Đánh giá I: So sánh Giữa Các Loại Nhiệm Vụ Khác Nhau

Trong nghiên cứu đánh giá đầu tiên của chúng tôi, chúng tôi điều tra về mức độ dữ liệu tổng hợp được tạo ra bởi LLM trong cả thiết lập zero-shot và few-shot có thể hỗ trợ huấn luyện mô hình hiệu quả cho các loại nhiệm vụ phân loại văn bản khác nhau. Chúng tôi đặc biệt quan tâm đến việc so sánh hiệu suất mô hình giữa những mô hình được huấn luyện trên dữ liệu thế giới thực và trên dữ liệu tổng hợp do LLM tạo ra, và trong việc hiểu cách hiệu suất của những mô hình được huấn luyện trên dữ liệu tổng hợp do LLM tạo ra thay đổi với tính chủ quan của nhiệm vụ phân loại văn bản.

### 4.1 Tập Dữ Liệu và Nhiệm Vụ

Chúng tôi thử nghiệm với 10 tập dữ liệu đại diện bao gồm nhiều nhiệm vụ phân loại văn bản: AG's news (Zhang et al., 2015), IMDB reviews (Maas et al., 2011), SMS spam (Almeida et al., 2011), Financial phrase bank (Malo et al., 2014), Reddit emotion (Demszky et al., 2020), Relation classification (Gao et al., 2019), Tweet irony speech (Van Hee et al., 2018), Tweet emotions (Mohammad et al., 2018), Sarcasm news (Misra và Arora, 2023, Misra và Grover, 2021), và Humor speech (Annamoradnejad và Zoghi, 2020). Xem Phụ lục A.1 để biết mô tả chi tiết về tập dữ liệu và các nhiệm vụ phân loại văn bản tương ứng. Các tập dữ liệu này được chọn với mục tiêu bao quát một phạm vi rộng của tính chủ quan nhiệm vụ. Ví dụ, chúng tôi phỏng đoán rằng việc phân loại danh mục chủ đề tin tức (ví dụ: như trong tập dữ liệu AG's news) tương đối khách quan, trong khi việc xác định liệu văn bản có hài hước hay không (ví dụ: như trong tập dữ liệu Humor speech) khá chủ quan (Veatch, 1998).

### 4.2 Xác Định Tính Chủ Quan Cấp Độ Nhiệm Vụ

Để chính thức xác định mức độ chủ quan của các nhiệm vụ phân loại văn bản khác nhau, chúng tôi đầu tiên tiến hành một nghiên cứu crowdsourced để thu thập các đánh giá chủ quan từ đám đông.

**Quy trình nghiên cứu.** Chúng tôi áp dụng một phương pháp so sánh để thu thập các đánh giá chủ quan từ crowdsourced trong nghiên cứu này. Cụ thể, chúng tôi tuyển dụng các công nhân đám đông từ Amazon Mechanical Turk (MTurk), và mỗi công nhân được yêu cầu hoàn thành một chuỗi 10 nhiệm vụ đánh giá chủ quan. Trong mỗi nhiệm vụ, chúng tôi lấy mẫu ngẫu nhiên một cặp nhiệm vụ phân loại văn bản từ 10 nhiệm vụ mà chúng tôi xem xét trong đánh giá này, và chúng tôi trình bày cho công nhân mô tả nhiệm vụ, mô tả nhãn và ví dụ nhiệm vụ cho từng nhiệm vụ trong cặp. Sau đó, công nhân được yêu cầu xác định nhiệm vụ phân loại văn bản nào trong cặp khách quan hơn, với "tính khách quan" của một nhiệm vụ được định nghĩa là "việc phân loại một đoạn văn bản dựa trên các đặc điểm rõ ràng, có thể nhận dạng trong văn bản (ví dụ: từ khóa hoặc cụm từ), và có thể được thực hiện mà không bị ảnh hưởng bởi bất kỳ giải thích cá nhân nào của văn bản từ thiên kiến, cảm xúc hoặc niềm tin cá nhân." Nghiên cứu được giới hạn cho các công nhân Hoa Kỳ. Mỗi công nhân chỉ được phép tham gia một lần và nhận được khoản thanh toán 1,2 đô la. Một câu hỏi kiểm tra sự chú ý được bao gồm trong nghiên cứu để xác thực sự tham gia của công nhân, và chỉ dữ liệu từ những công nhân vượt qua thành công kiểm tra sự chú ý mới được xem xét hợp lệ.

**Xếp hạng tính chủ quan nhiệm vụ.** Sau khi loại trừ các phản hồi từ các công nhân không chú ý, tổng cộng 540 so sánh chủ quan theo cặp cho 10 nhiệm vụ đã được thu thập từ 54 công nhân. Đối với mỗi cặp nhiệm vụ, chúng tôi tổng hợp các đánh giá chủ quan tương đối được thực hiện trên cặp này để xác định nhiệm vụ nào được nhận thức là chủ quan hơn (tức là ít khách quan hơn). Để tạo ra một xếp hạng về tính chủ quan của 10 nhiệm vụ, chúng tôi xây dựng một đồ thị có hướng dựa trên các so sánh chủ quan theo cặp—mỗi nhiệm vụ là một nút trong đồ thị này, và các cạnh có hướng được thêm vào giữa mỗi cặp nhiệm vụ, chỉ từ cái được coi là chủ quan hơn (ở mức tổng hợp) đến cái được coi là ít chủ quan hơn. Thuật toán sắp xếp tô-pô (Cormen et al., 2022) sau đó được áp dụng cho đồ thị có hướng này để có được một thứ tự tuyến tính của các nút. Nếu một chu trình được phát hiện trong đồ thị, các nhiệm vụ tương ứng được coi là có cùng mức độ chủ quan và được gộp thành một siêu nút trước khi chạy lại thuật toán. Kết quả xếp hạng tính chủ quan nhiệm vụ cuối cùng của chúng tôi được hiển thị trong Bảng 1.

### 4.3 Huấn Luyện Mô Hình

Cho một nhiệm vụ phân loại văn bản, theo các quy trình được nêu trong Phần 3.1 và 3.2, 3.000 điểm dữ liệu tổng hợp được tạo ra cho mỗi nhãn ứng viên trong cả thiết lập zero-shot và few-shot. Sau đó, chúng tôi huấn luyện các mô hình phân loại sử dụng dữ liệu huấn luyện thế giới thực được cung cấp bởi tập dữ liệu gốc, dữ liệu tổng hợp được tạo ra trong thiết lập zero-shot, và dữ liệu tổng hợp được tạo ra trong thiết lập few-shot, tương ứng. Cụ thể, chúng tôi sử dụng các mô hình BERT (Devlin et al., 2018) và RoBERTa (Liu et al., 2019) được huấn luyện trước từ thư viện transformers của Huggingface (Wolf et al., 2020) làm bộ mã hóa, và sử dụng các embedding biểu diễn từ lớp cuối cùng của các mô hình này làm đầu vào cho các mô hình phân loại của chúng tôi. Bản thân mô hình phân loại bao gồm một lớp ẩn 768 đơn vị và một lớp đầu ra, và nó được tinh chỉnh với tốc độ học 5e−5 và kích thước batch 64. Đối với các tập dữ liệu cung cấp phân chia chính thức cho tập huấn luyện và tập kiểm tra, chúng tôi trực tiếp đánh giá hiệu suất của mô hình phân loại trên các tập kiểm tra. Nếu không, chúng tôi chia ngẫu nhiên tập dữ liệu thành tập huấn luyện (70%), tập xác thực (5%) và tập kiểm tra (25%). Hiệu suất của các mô hình được đánh giá thông qua điểm Macro-F1 và Accuracy, và chúng được tính bằng cách so sánh dự đoán của mô hình với các nhãn vàng được cung cấp trong các tập kiểm tra. Để đảm bảo tính mạnh mẽ của kết quả, tất cả các thí nghiệm được lặp lại ba lần, và hiệu suất trung bình qua các lần lặp này được báo cáo.

### 4.4 Kết Quả Đánh Giá

Bảng 1 tóm tắt hiệu suất so sánh của các mô hình phân loại được huấn luyện với dữ liệu khác nhau. Dưới đây, chúng tôi làm nổi bật một số quan sát chính mà chúng tôi nhận được từ so sánh này.

**Các mô hình được huấn luyện trên dữ liệu thế giới thực nhất quán vượt trội hơn những mô hình được huấn luyện trên dữ liệu tổng hợp.** Kết quả của chúng tôi cho thấy các mô hình được huấn luyện trên dữ liệu thế giới thực gốc nhất quán vượt trội hơn các đối tác được huấn luyện trên dữ liệu tổng hợp được tạo ra trong thiết lập zero-shot hoặc few-shot, gần như cho mọi nhiệm vụ. Đặc biệt, với mô hình RoBERTa, chúng tôi quan sát rằng sự cải thiện trung bình của mô hình được huấn luyện trên dữ liệu thế giới thực so với các mô hình được huấn luyện trên dữ liệu tổng hợp zero-shot và dữ liệu tổng hợp few-shot lần lượt là 16,9% và 6,7% về Macro-F1, và 14,9% và 6,1% về độ chính xác. Các xu hướng tương tự cũng được quan sát với mô hình BERT.

**Hướng dẫn LLM với các ví dụ dữ liệu thế giới thực có thể tăng cường hiệu quả của dữ liệu tổng hợp.** Chúng tôi cũng quan sát rằng các mô hình được huấn luyện trên dữ liệu tổng hợp được tạo ra trong thiết lập few-shot gần như luôn vượt trội hơn những mô hình được huấn luyện trên dữ liệu tổng hợp được tạo ra trong thiết lập zero-shot. Ví dụ, đối với mô hình BERT, chúng tôi thấy sự gia tăng trung bình 10,6% và 8,8% trong điểm Macro-F1 và độ chính xác, tương ứng, qua 10 nhiệm vụ trong thiết lập few-shot, so với thiết lập zero-shot. Tương tự, với mô hình RoBERTa, có sự gia tăng trung bình 10,3% trong Macro-F1 và 8,9% trong điểm độ chính xác qua 10 nhiệm vụ khi dữ liệu thế giới thực được sử dụng làm ví dụ cho LLM bắt chước trong quá trình tạo dữ liệu tổng hợp. Để phân tích thêm về dữ liệu tổng hợp few-shot, vui lòng xem Phụ lục B.2 và B.3.

**Dữ liệu tổng hợp hỗ trợ huấn luyện mô hình hiệu quả hơn cho các nhiệm vụ ít chủ quan hơn.** Cuối cùng, chúng tôi nhận thấy rằng đối với các nhiệm vụ phân loại có mức độ chủ quan tương đối thấp (ví dụ: những nhiệm vụ trong các tập dữ liệu AG's news, Relation classification, IMDB reviews và SMS spam), sự khác biệt hiệu suất giữa các mô hình được huấn luyện trên dữ liệu tổng hợp và những mô hình được huấn luyện trên dữ liệu thế giới thực là rất nhỏ. Tuy nhiên, đối với các nhiệm vụ có tính chủ quan cao, sự giảm hiệu suất từ việc sử dụng dữ liệu tổng hợp là đáng kể hơn—ví dụ, qua cụm 6 nhiệm vụ có mức độ chủ quan cao nhất trong đánh giá của chúng tôi, có sự giảm trung bình 27,4% và 24,2% trong Macro-F1 và độ chính xác, tương ứng, so sánh các mô hình BERT được huấn luyện trên dữ liệu tổng hợp zero-shot với những mô hình được huấn luyện trên dữ liệu thế giới thực. Nói cách khác, đối với các nhiệm vụ phân loại văn bản có tính khách quan cao, có tiềm năng lớn trong việc huấn luyện các mô hình hiệu suất cao chỉ đơn giản dựa trên dữ liệu tổng hợp được tạo ra bởi LLM, nhưng cùng một phương pháp lại không thành công trong việc tạo ra dữ liệu tổng hợp có thể hỗ trợ hiệu quả huấn luyện mô hình cho các phân loại rất chủ quan.

### 4.5 Phân Tích Khám Phá: Sự Đa Dạng Dữ Liệu

Để khám phá các lý do tiềm ẩn đằng sau sự khác biệt hiệu suất mô hình, chúng tôi tiến hành một phân tích khám phá về sự đa dạng của dữ liệu huấn luyện. Theo Rhys Cox et al. (2021), chúng tôi sử dụng **Điểm Remote Clique** (tức là khoảng cách trung bình của một thể hiện dữ liệu đến các thể hiện khác) và **Điểm Chamfer Distance** (tức là khoảng cách tối thiểu trung bình của một thể hiện dữ liệu đến các thể hiện khác) để định lượng sự đa dạng của một tập dữ liệu. Đối với cả hai chỉ số, giá trị cao hơn chỉ ra sự đa dạng dữ liệu lớn hơn. Như được hiển thị trong Hình 1, chúng tôi thấy rằng nhìn chung, dữ liệu thế giới thực có vẻ đa dạng hơn dữ liệu tổng hợp được tạo ra trong thiết lập few-shot, mà lần lượt có vẻ đa dạng hơn dữ liệu tổng hợp zero-shot. Điều này có thể giải thích một phần tại sao các mô hình được huấn luyện trên dữ liệu thế giới thực và dữ liệu tổng hợp few-shot có xu hướng vượt trội hơn những mô hình được huấn luyện trên dữ liệu tổng hợp zero-shot.

Ngoài ra, chúng tôi cũng nhận thấy rằng so với trên các nhiệm vụ có tính chủ quan thấp (tức là AG, Relation, IMDB, Spam), sự khác biệt trong đa dạng dữ liệu giữa dữ liệu thế giới thực và dữ liệu tổng hợp có vẻ nổi bật hơn trên các nhiệm vụ có tính chủ quan cao (tức là 6 nhiệm vụ khác), đặc biệt về Điểm Chamfer Distance. Thực tế, một t-test cho thấy sự giảm của Điểm Chamfer Distance trong dữ liệu tổng hợp zero-shot so với dữ liệu thực lớn hơn đáng kể đối với các nhiệm vụ có tính chủ quan cao so với các nhiệm vụ có tính chủ quan thấp (p <0,01). Điều này cho thấy rằng đối với các nhiệm vụ có tính chủ quan cao, như giải thích hài hước hoặc châm biếm trong ngôn ngữ, LLM có thể không thể tạo ra các thể hiện dữ liệu có thể bao phủ toàn bộ phổ của các tình huống thực tế, điều này có thể hạn chế hiệu suất của các mô hình được huấn luyện trên dữ liệu tổng hợp.

## 5 Đánh giá II: So sánh Giữa Các Thể Hiện Nhiệm Vụ Khác Nhau

Trong phần trước, chúng tôi đã khám phá rằng tính chủ quan của một nhiệm vụ có thể ảnh hưởng tiêu cực đến hiệu suất của các mô hình phân loại được huấn luyện trên dữ liệu tổng hợp do LLM tạo ra. Tuy nhiên, ngay cả đối với cùng một loại nhiệm vụ, việc phân loại cho từng thể hiện nhiệm vụ cá nhân cũng có thể thể hiện các mức độ chủ quan khác nhau. Tự nhiên, người ta có thể tự hỏi liệu các mô hình được huấn luyện trên dữ liệu tổng hợp do LLM tạo ra có thể thể hiện hiệu suất khác nhau trên các thể hiện nhiệm vụ có tính chủ quan khác nhau hay không. Chúng tôi nhằm khám phá câu trả lời cho câu hỏi này trong phần này.

### 5.1 Xác Định Tính Chủ Quan Cấp Độ Thể Hiện

Cho một nhiệm vụ phân loại văn bản và một thể hiện văn bản cụ thể, chúng tôi xem mức độ đồng ý giữa các chú thích viên về nhãn của văn bản này như một proxy cho tính chủ quan của thể hiện này—mức độ đồng ý thấp hơn có nghĩa là các chú thích viên có quan điểm khác biệt hơn, do đó nhiệm vụ có thể có mức độ chủ quan cao hơn. Do đó, để chính thức định lượng tính chủ quan của các thể hiện khác nhau cho các nhiệm vụ khác nhau, chúng tôi lại tiến hành một nghiên cứu crowdsourced để thu thập các chú thích cấp độ thể hiện.

**Quy trình nghiên cứu.** Chúng tôi lại xem xét 10 loại nhiệm vụ phân loại văn bản như trong nghiên cứu đánh giá đầu tiên. Đối với mỗi loại nhiệm vụ, chúng tôi lấy mẫu ngẫu nhiên 50 thể hiện văn bản mỗi danh mục từ tập kiểm tra để tạo thành "tập dữ liệu đánh giá" của chúng tôi cho nhiệm vụ đó. Sau đó, chúng tôi tuyển dụng các công nhân Hoa Kỳ từ MTurk để hoàn thành các nhiệm vụ chú thích cho những thể hiện trong tập dữ liệu đánh giá của chúng tôi. Cụ thể, mỗi công nhân được phân công ngẫu nhiên vào một loại nhiệm vụ phân loại văn bản. Sau khi đi qua hướng dẫn ngắn gọn về nhiệm vụ được phân công, công nhân được yêu cầu hoàn thành 20 nhiệm vụ phân loại của loại được phân công để nhận được khoản thanh toán 1,2 đô la, trong đó các văn bản được trình bày trong 20 nhiệm vụ này được lấy mẫu ngẫu nhiên từ tập dữ liệu đánh giá cho loại nhiệm vụ được phân công. Một lần nữa, chúng tôi bao gồm hai câu hỏi kiểm tra sự chú ý trong nghiên cứu để lọc ra các công nhân không chú ý. Chúng tôi đảm bảo rằng mỗi thể hiện nhiệm vụ nhận được ít nhất ba chú thích từ các công nhân MTurk duy nhất.

**Tính toán tính chủ quan thể hiện.** Dựa trên các chú thích chúng tôi thu được từ các công nhân chú ý, chúng tôi định lượng mức độ chủ quan của mỗi thể hiện nhiệm vụ bằng cách sử dụng tỷ lệ các chú thích viên đồng ý với nhãn đa số cho thể hiện nhiệm vụ, tức là:

ai = max y∈Y ∑^Ki_k=1 1(r^k_i = y) / Ki

trong đó Y={1,···,Y} là tập hợp tất cả các nhãn có thể, Ki là tổng số chú thích viên đã gắn nhãn thể hiện i, và r^k_i là chú thích của chú thích viên thứ k trên thể hiện i. Trực quan, một giá trị ai thấp hơn gợi ý rằng sự đồng thuận ít có khả năng đạt được giữa các chú thích viên trên thể hiện i, do đó thể hiện i có thể có mức độ chủ quan cao hơn. Trong Bảng 2, chúng tôi báo cáo các giá trị trung bình của ai (tức là ā) cho các thể hiện trong tập dữ liệu đánh giá của các loại nhiệm vụ khác nhau, cùng với mức độ đồng ý giữa các chú thích viên trung bình trên mỗi thể hiện nhiệm vụ (được đo bằng Krippendorff's α) cũng như mức độ chủ quan cấp độ nhiệm vụ cho các loại nhiệm vụ khác nhau. Chúng ta có thể thấy rằng ā phù hợp chặt chẽ với Krippendorff's α, và các nhiệm vụ có mức độ chủ quan cao hơn cũng thể hiện giá trị ā cao hơn nói chung, cho thấy rằng ai có thể phục vụ như một proxy hợp lý cho tính chủ quan của mỗi thể hiện nhiệm vụ.

### 5.2 Kết Quả Đánh Giá

Bây giờ chúng tôi tìm hiểu liệu các mô hình được huấn luyện trên dữ liệu tổng hợp do LLM tạo ra có thể hiện hiệu suất khác nhau trên các thể hiện có mức độ chủ quan khác nhau hay không, và chúng tôi tập trung vào các mô hình được huấn luyện trên dữ liệu tổng hợp zero-shot trong đánh giá này. Cụ thể, cho một nhiệm vụ phân loại, chúng tôi huấn luyện một mô hình BERT sử dụng dữ liệu tổng hợp zero-shot và tính toán độ chính xác của nó trên tập con các thể hiện nhiệm vụ trong tập dữ liệu đánh giá mà mức độ đồng ý chú thích cấp độ thể hiện (tức là ai) vượt quá ngưỡng γ, và chúng tôi lặp lại tính toán này nhiều lần khi chúng tôi thay đổi giá trị của γ.

Hình 2 minh họa cách độ chính xác của mô hình thay đổi với ngưỡng đồng ý chú thích cấp độ thể hiện γ cho các loại nhiệm vụ khác nhau. Đối với hầu hết các nhiệm vụ (ngoại trừ các nhiệm vụ trong tập dữ liệu Sarcasm News và Financial Phrasebank), chúng tôi quan sát một mối quan hệ tăng đơn điệu mạnh mẽ giữa γ và độ chính xác của mô hình, với các mối tương quan giữa chúng (tức là β) là tích cực và các giá trị của hệ số tương quan hạng Spearman ρ thường vượt quá 0,85. Vì việc tăng ngưỡng đồng ý chú thích cấp độ thể hiện γ có hiệu quả lọc ra các thể hiện nhiệm vụ có tính chủ quan cao, quan sát này cho thấy rằng các mô hình được huấn luyện trên dữ liệu tổng hợp thực sự có xu hướng có hiệu suất khác nhau trên các thể hiện khác nhau—ngay cả trong cùng một loại nhiệm vụ, những mô hình này vẫn hoạt động tốt hơn trên những thể hiện nhiệm vụ có tính chủ quan thấp.

Để so sánh, chúng tôi cũng điều tra liệu các mô hình được huấn luyện trên dữ liệu thế giới thực có thể hiện hành vi tương tự hay không. Kết quả chi tiết được báo cáo trong Phụ lục C. Ở mức độ cao, trong khi chúng tôi cũng quan sát xu hướng rằng hiệu suất của những mô hình này có vẻ tăng khi tính chủ quan nhiệm vụ cấp độ thể hiện giảm, mối quan hệ như vậy thường yếu hơn so với điều được minh họa trong các mô hình được huấn luyện trên dữ liệu tổng hợp (ví dụ: β và ρ nhỏ hơn).

## 6 Kết luận và Thảo luận

Trong bài báo này, chúng tôi trình bày một khám phá ban đầu về các yếu tố điều tiết hiệu quả của dữ liệu tổng hợp do LLM tạo ra để hỗ trợ huấn luyện các mô hình phân loại văn bản. Kết quả của chúng tôi cho thấy rằng hiệu suất của các mô hình được huấn luyện trên dữ liệu tổng hợp giảm cả đối với các nhiệm vụ phân loại có mức độ chủ quan cao hơn và trên các thể hiện nhiệm vụ có tính chủ quan cao hơn. Trong phần này, chúng tôi cung cấp một số giải thích tiềm năng cho các quan sát của nghiên cứu, và thảo luận về những hàm ý, giới hạn và hướng tương lai của công trình.

### 6.1 Tại sao tính chủ quan ảnh hưởng tiêu cực đến hiệu quả của dữ liệu tổng hợp?

Chúng tôi cung cấp một số giải thích cho việc tại sao tính chủ quan nhiệm vụ được phát hiện có mối quan hệ tiêu cực với hiệu suất của các mô hình được huấn luyện trên dữ liệu tổng hợp do LLM tạo ra. Đầu tiên, các nhiệm vụ có tính chủ quan cao thường yêu cầu hiểu biết sâu sắc về các sắc thái cảm xúc tinh tế của con người và những tinh tế về ngữ cảnh, cũng như khả năng phân biệt và giải thích chính xác các quan điểm khác nhau. Do đó, LLM có thể gặp phải những hạn chế trong việc tạo ra dữ liệu có thể nắm bắt phạm vi rộng lớn và độ phức tạp của việc sử dụng ngôn ngữ trong đời thực. Thật vậy, như được hiển thị trong phân tích khám phá của chúng tôi trong Phần 4.5, sự đa dạng của dữ liệu tổng hợp do LLM tạo ra có vẻ đặc biệt hạn chế trên các nhiệm vụ có tính chủ quan cao, khi so sánh với dữ liệu thế giới thực. Điều này hàm ý rằng một cách tiềm năng để cải thiện hiệu quả của dữ liệu tổng hợp trên các nhiệm vụ có tính chủ quan cao là tăng sự đa dạng dữ liệu và đảm bảo dữ liệu tổng hợp có thể phản ánh tốt hơn các phân phối dữ liệu thế giới thực.

Thứ hai, cụ thể đối với mối quan hệ giữa tính chủ quan cấp độ thể hiện và hiệu suất mô hình, chúng tôi lưu ý rằng "nhãn vàng" của một thể hiện nhiệm vụ thường được quyết định bằng một cuộc bỏ phiếu đa số trong một nhóm chú thích viên. Điều này có nghĩa là nhãn vàng có thể không đại diện cho quan điểm của mỗi cá nhân (Goyal et al., 2022), và đôi khi chúng "thiên vị" tùy thuộc vào thành phần chú thích viên (Li et al., 2022). Do đó, có thể khó khăn cho LLM tạo ra dữ liệu tổng hợp để phục hồi "quan điểm đa số" có thể thiên vị như vậy, đặc biệt nếu LLM được huấn luyện để duy trì sự trung lập. Thay vào đó, người ta có thể hỏi về các thể hiện nhiệm vụ chủ quan mà con người khó có thể đạt được bất kỳ sự đồng thuận nào, liệu "nhãn vàng" có thực sự là nhãn "đúng" duy nhất không? Nếu không, việc suy nghĩ lại về cách phát triển và đánh giá các mô hình cho những thể hiện nhiệm vụ này là cần thiết cấp bách.

### 6.2 Giải thích một số ngoại lệ

Trong Bảng 1, chúng tôi ngạc nhiên thấy rằng trên các nhiệm vụ phát hiện châm biếm Tweet, các mô hình được huấn luyện trên dữ liệu tổng hợp few-shot thậm chí còn vượt trội hơn các mô hình được huấn luyện trên dữ liệu thế giới thực. Một giải thích có thể là bản chất của việc tạo ra các văn bản châm biếm cho mạng xã hội liên quan đến một nhiệm vụ viết sáng tạo với ít ràng buộc về tính chính thức của ngôn ngữ, và nghiên cứu gần đây cho thấy rằng LLM có tiềm năng thể hiện sự sáng tạo tương đương với các nhà văn con người trong nhiệm vụ như vậy (Franceschelli và Musolesi, 2023). Một ngoại lệ khác mà chúng tôi tìm thấy là trong Phần 5.2—đối với tập dữ liệu Financial Phrasebank và Sarcasm, không giống như các nhiệm vụ khác, hiệu quả của các mô hình được huấn luyện trên dữ liệu tổng hợp không thay đổi nhiều với tính chủ quan nhiệm vụ cấp độ thể hiện. Chúng tôi phỏng đoán rằng điều này có thể được gây ra bởi một số thuộc tính cụ thể của nhiệm vụ. Trên tập dữ liệu Financial Phrasebank, phân tích cảm xúc chính xác đòi hỏi sự hiểu biết về thuật ngữ chuyên môn liên quan đến tài chính. Tương tự, nhiệm vụ phát hiện Sarcasm nhằm mục đích xác định châm biếm trong các tiêu đề tin tức từ các nguồn được chọn và đòi hỏi sự hiểu biết về các chủ đề chính trị. Do đó, trên những nhiệm vụ này, LLM có thể không được trang bị đầy đủ kiến thức miền cần thiết để tạo ra dữ liệu tổng hợp hiệu quả trong thiết lập zero-shot. Thật vậy, như được hiển thị trong Hình 2, các mô hình được huấn luyện trên dữ liệu tổng hợp zero-shot có hiệu suất rất thấp trên hai tập dữ liệu này, bất kể mức độ chủ quan của các thể hiện nhiệm vụ.

### 6.3 Giới hạn và công việc tương lai

Chúng tôi thừa nhận rằng tính chủ quan nhiệm vụ có thể không phải là yếu tố duy nhất điều tiết hiệu quả của dữ liệu tổng hợp do LLM tạo ra. Các nghiên cứu tương lai có thể tìm hiểu vai trò điều tiết tiềm năng của các yếu tố khác, như tính chính thức của ngôn ngữ và yêu cầu về kiến thức cụ thể miền. Sự phụ thuộc của chúng tôi vào các công nhân đám đông trong việc xác định tính chủ quan nhiệm vụ có thể đưa ra một số biến động do thiếu chuyên môn ngôn ngữ học của họ. Đánh giá của chúng tôi cũng chỉ dựa trên mô hình GPT-3.5-Turbo. Điều quan trọng cần lưu ý là các kết luận chúng tôi nhận được ở đây có thể không khái quát hóa cho các LLM khác (ví dụ: GPT-4 tiên tiến hơn), xem xét những cải thiện liên tục của LLM trong việc tạo ra văn bản giống con người.

Các phát hiện của chúng tôi cho thấy rằng việc kết hợp các ví dụ dữ liệu thế giới thực vào quá trình tạo dữ liệu tổng hợp có thể tăng sự đa dạng dữ liệu và tăng cường hiệu suất của các mô hình kết quả. Do đó, công việc tương lai có thể khám phá các chiến lược tận dụng trí tuệ con người, như phản hồi hoặc can thiệp trực tiếp trong quá trình tạo ra, để tăng cường thêm sự phong phú của dữ liệu tổng hợp (Chung et al., 2023) và để xác định loại thể hiện dữ liệu "có thông tin" nhất để tạo ra. Cuối cùng, mối tương quan đáng kể giữa tính chủ quan của các nhiệm vụ hoặc thể hiện và hiệu suất của các mô hình được huấn luyện trên dữ liệu tổng hợp cũng gợi ý tiềm năng sử dụng hiệu suất của những mô hình như vậy như một proxy để xấp xỉ tính chủ quan nhiệm vụ hoặc thể hiện, hoặc để ước tính độ tin cậy của các nhãn vàng.

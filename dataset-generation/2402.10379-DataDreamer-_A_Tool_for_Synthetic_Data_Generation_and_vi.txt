# DataDreamer: Một Công Cụ cho Tạo Dữ Liệu Tổng Hợp và Quy Trình LLM Có Thể Tái Tạo

Ajay Patel
Đại học Pennsylvania
ajayp@upenn.edu

Colin Raffel
Đại học Toronto
Viện Vector
craffel@gmail.com

Chris Callison-Burch
Đại học Pennsylvania
ccb@upenn.edu

## Tóm tắt

Các mô hình ngôn ngữ lớn (LLM) đã trở thành một công cụ thống trị và quan trọng cho các nhà nghiên cứu NLP trong nhiều tác vụ đa dạng. Ngày nay, nhiều nhà nghiên cứu sử dụng LLM trong tạo dữ liệu tổng hợp, đánh giá tác vụ, tinh chỉnh, chưng cất và các quy trình nghiên cứu có mô hình trong vòng lặp khác. Tuy nhiên, những thách thức phát sinh khi sử dụng các mô hình này xuất phát từ quy mô của chúng, bản chất mã nguồn đóng và thiếu công cụ chuẩn hóa cho những quy trình mới và đang nổi lên này. Sự trỗi dậy nhanh chóng của các mô hình này và những thách thức độc đáo này đã có tác động tiêu cực tức thì đến khoa học mở và khả năng tái tạo của các công trình sử dụng chúng. Trong bài báo chủ đề ACL 2024 này, chúng tôi giới thiệu DataDreamer, một thư viện Python mã nguồn mở cho phép các nhà nghiên cứu viết mã đơn giản để thực hiện các quy trình LLM mạnh mẽ. DataDreamer cũng giúp các nhà nghiên cứu tuân thủ các thực hành tốt nhất mà chúng tôi đề xuất để khuyến khích khoa học mở và khả năng tái tạo. Thư viện và tài liệu có sẵn tại: https://github.com/datadreamer-dev/DataDreamer.

## 1 Giới thiệu

Trong khi các mô hình ngôn ngữ lớn (LLM) đã thiết lập một kỷ nguyên mới trong nghiên cứu NLP thông qua mô hình prompt-and-predict đã được chứng minh hiệu quả trên nhiều tác vụ đa dạng, việc sử dụng các mô hình này đã đi kèm với những nhược điểm đáng kể (Liu et al., 2023). Nhiều mô hình phổ biến như GPT-4 (OpenAI et al., 2023) là mã nguồn đóng và nằm sau API từ xa, trong khi chạy mô hình cục bộ có thể phức tạp về mặt kỹ thuật và tốn kém do quy mô của chúng. Hơn nữa, mô hình prompting hiện đã được thiết lập có thể mong manh với kết quả biến đổi rộng rãi giữa các mô hình, cấu hình và môi trường khác nhau (Sclar et al., 2023; Jaiswal et al., 2023). Những thách thức này đã khiến các nhà nghiên cứu khó chia sẻ, tái tạo, mở rộng và so sánh công trình, cản trở tốc độ tiến bộ nghiên cứu.

Trong bối cảnh chuyển đổi nhanh chóng sang sử dụng các mô hình lớn này trong nghiên cứu, chúng tôi giới thiệu DataDreamer, gói Python mã nguồn mở của chúng tôi cung cấp cả tiện ích thực tế cho các nhà nghiên cứu và tiện ích khoa học cho cộng đồng:

• DataDreamer giúp các nhà nghiên cứu thực hiện các quy trình mới nổi tiên tiến liên quan đến LLM như tạo dữ liệu tổng hợp, tinh chỉnh, instruction-tuning và alignment. Nó đơn giản hóa việc triển khai bằng cách cung cấp một thư viện duy nhất với giao diện chuẩn hóa cho nhiều tác vụ này trong khi giảm độ phức tạp kỹ thuật xung quanh việc chuyển đổi giữa các mô hình, caching, khả năng tiếp tục, logging, suy luận và huấn luyện đa GPU, sử dụng adapter và tối ưu hóa lượng tử, và xuất bản các bộ dữ liệu và mô hình mở.

• DataDreamer làm cho việc kết nối dữ liệu giữa các tác vụ, một thực hành ngày càng phổ biến, trở nên đơn giản. Ví dụ, người dùng có thể tạo dữ liệu với quy trình dữ liệu tổng hợp và sau đó tinh chỉnh trên dữ liệu tổng hợp đó.

• DataDreamer giúp các nhà nghiên cứu thực hiện quy trình trong khi quan trọng là tạo ra đầu ra tương thích với khoa học mở và lý tưởng tái tạo với nỗ lực tối thiểu, thông qua caching tự động, dấu vân tay tái tạo và nhiều artifact thực hành tốt nhất khác.

## 2 Quy trình LLM

Để thúc đẩy DataDreamer, trước tiên chúng tôi thảo luận về các quy trình LLM mà nó hỗ trợ. Chúng tôi thảo luận về các thách thức đối với khoa học mở phát sinh từ các mô hình sử dụng này. Trong bài báo này, chúng tôi không tìm cách xác thực hoặc phê bình các phương pháp này. Thay vào đó, chúng tôi cung cấp một giải pháp để thực hiện chúng và làm cho chúng có thể tái tạo. Các quy trình LLM này thường được sử dụng kết hợp với nhau (Yuan et al., 2024), và việc điều phối các quy trình đa giai đoạn thường được thực hiện thông qua nhiều shell hoặc Python script. Tái tạo các quy trình đa giai đoạn này rất thách thức vì shell script có thể phụ thuộc vào trình lập lịch công việc hoặc môi trường cụ thể của tác giả và yêu cầu thực thi theo thứ tự cụ thể. Trong Phần 4 và 5, chúng tôi thảo luận về cách điều phối tác vụ, hệ thống caching và huấn luyện đa GPU đơn giản của DataDreamer làm cho việc thực hiện các quy trình đa giai đoạn này trong một chương trình Python duy nhất trở nên dễ dàng hơn, giảm thiểu các vấn đề này.

**Tạo Dữ liệu Tổng hợp** Các công trình gần đây đã khám phá việc sử dụng LLM để tạo dữ liệu tổng hợp cho các tác vụ hoặc để tăng cường các bộ dữ liệu hiện có nhằm tăng hiệu suất tác vụ (Yu et al., 2023; Kumar et al., 2020a,b; Yoo et al., 2021; Han et al., 2021a; Ye et al., 2022; Honovich et al., 2022, inter alia). Tạo dữ liệu tổng hợp liên quan đến việc sử dụng LLM một lần hoặc nhiều lần trong quy trình đa giai đoạn để xử lý dữ liệu, đôi khi được gọi là "chaining" (Rush, 2023). Khi prompting LLM để tạo hoặc tăng cường bộ dữ liệu, một thách thức tái tạo phát sinh là "độ nhạy prompt" trong đó ngay cả những biến đổi nhỏ trong prompt cũng có thể dẫn đến kết quả khác nhau đáng kể (Sclar et al., 2023). Hơn nữa, việc gắn thẻ các bộ dữ liệu được tạo tổng hợp là bắt buộc vì lo ngại về suy giảm mô hình (Shumailov et al., 2023).

**LLM cho Đánh giá Tác vụ** Một quy trình ngày càng phổ biến khác là sử dụng LLM làm thẩm phán hoặc làm thước đo tự động để đánh giá hiệu suất của mô hình trên một tác vụ (Zheng et al., 2023; Fu et al., 2023; Dubois et al., 2023; Chiang và Lee, 2023, inter alia). Nhiều thách thức tái tạo áp dụng cho dữ liệu tổng hợp cũng phát sinh ở đây.

**Tinh chỉnh và Alignment** Một quy trình phổ biến khác là tạo ra các mô hình chuyên gia cụ thể cho tác vụ sử dụng kiến thức từ các mô hình lớn hơn để tạo ra các mô hình nhỏ hơn, hiệu quả hơn thông qua tinh chỉnh và chưng cất (Han et al., 2021b; Liu et al., 2022; Hsieh et al., 2023). Instruction-tuning là tinh chỉnh cho phép các mô hình pre-trained cơ bản tuân theo hướng dẫn bằng ngôn ngữ tự nhiên của con người tốt hơn và cải thiện hiệu suất tác vụ tổng quát của chúng (Ouyang et al., 2022; Wei et al., 2021; Sanh et al., 2021; Mishra et al., 2021). Liên quan chặt chẽ, các kỹ thuật alignment điều hướng phản hồi mô hình hướng tới những phản hồi được con người ưa thích hơn (Stiennon et al., 2020; Bai et al., 2022; Rafailov et al., 2023). Thực hiện khả năng tiếp tục và các kỹ thuật huấn luyện hiệu quả là những thách thức thực tế thường gặp phải. Thách thức tái tạo bao gồm chia sẻ dữ liệu và siêu tham số chính xác.

**LLM Tự cải thiện** LLM tự cải thiện thông qua các vòng lặp huấn luyện tự phản hồi là một lĩnh vực nghiên cứu ngày càng tích cực (Huang et al., 2022; Wang et al., 2022; Li et al., 2023; Chen et al., 2024; Yuan et al., 2024; Gunasekar et al., 2023). Các quy trình này có thể phức tạp độc đáo để cả thực hiện và tái tạo do yêu cầu nhiều vòng kết nối với nhau tạo dữ liệu tổng hợp, đánh giá tự động và huấn luyện lại mô hình. DataDreamer hỗ trợ tất cả các quy trình này và làm cho việc kết nối dữ liệu giữa chúng trở nên đơn giản.

## 3 Minh họa và Ví dụ

Trước khi đi sâu vào cấu trúc và triển khai của DataDreamer, trước tiên chúng tôi cung cấp một minh họa đơn giản về khả năng và API của DataDreamer thông qua một ví dụ quy trình tạo dữ liệu tổng hợp và chưng cất trong Ví dụ 1. LLM được sử dụng trong ví dụ này là GPT-4 (OpenAI et al., 2023). Như một bước đầu tiên, ví dụ sử dụng LLM để tạo 1.000 tóm tắt bài báo nghiên cứu NLP. LLM sau đó được sử dụng để tóm tắt những tóm tắt đó theo phong cách giống tweet. Hai bước này tạo ra một bộ dữ liệu hoàn toàn tổng hợp gồm các tóm tắt và tweet tóm tắt chúng. Sử dụng một trainer, bộ dữ liệu tổng hợp này sau đó được chưng cất thành một mô hình nhỏ, cục bộ có khả năng tóm tắt tóm tắt bài báo theo phong cách giống tweet. Như một bước cuối cùng, ví dụ minh họa cách cả bộ dữ liệu tổng hợp và mô hình được huấn luyện có thể được xuất bản và chia sẻ. Để minh họa, chúng tôi trình bày một mẫu tạo ra đầu ra của mô hình được huấn luyện trên tóm tắt của bài báo này:

"Giới thiệu DataDreamer, một thư viện Python mã nguồn mở cho các quy trình #NLP tiên tiến. Nó cung cấp mã dễ dàng để tạo các quy trình LLM mạnh mẽ, giải quyết các thách thức về quy mô, bản chất mã nguồn đóng và công cụ. Một bước tiến tới khoa học mở và khả năng tái tạo! #AI #MachineLearning"

Các ví dụ quy trình khác có thể được tìm thấy trong Phụ lục (Ví dụ 2, Ví dụ 3, Ví dụ 4, Ví dụ 5).

## 4 DataDreamer

DataDreamer là một gói Python mã nguồn mở cho phép các nhà nghiên cứu thực hiện tất cả các quy trình LLM được thảo luận trong Phần 2 bằng cách sử dụng một thư viện duy nhất. DataDreamer cung cấp giao diện chuẩn hóa để prompting và huấn luyện mô hình, trừu tượng hóa các thư viện và công cụ cụ thể của nhà cung cấp. Điều này làm cho mã nghiên cứu đơn giản hơn để thực hiện, sửa đổi, thử nghiệm và chia sẻ với người khác. DataDreamer tích hợp với các thư viện LLM mã nguồn mở khác như transformers (Wolf et al., 2019) và trl (von Werra et al., 2020), cũng như các API mô hình thương mại như OpenAI và Anthropic cho các LLM thương mại (Brown et al., 2020). Hơn nữa, DataDreamer tự động thực hiện các thực hành tốt nhất cho khả năng tái tạo được thảo luận trong Phần 5.

### 4.1 Cài đặt

DataDreamer có thể được cài đặt với:
```
pip install datadreamer.dev
```

### 4.2 Sessions

Tất cả mã sử dụng thư viện DataDreamer được đặt trong một "session" sử dụng trình quản lý ngữ cảnh Python được khởi tạo bằng từ khóa with:

```python
from datadreamer import DataDreamer
with DataDreamer("./output"):
    ...
```

Các tác vụ quy trình có thể được chạy trong trình quản lý ngữ cảnh session. Các tác vụ này được gọi là "steps" (tải bộ dữ liệu, prompting mô hình, v.v.) hoặc "trainers". Session cho phép DataDreamer tự động tổ chức các bộ dữ liệu, đầu ra, caches, checkpoint huấn luyện và mô hình được huấn luyện kết quả từ các tác vụ chạy trong session vào thư mục ./output/. Mỗi bước trong quy trình gán một tên mô tả tùy chỉnh cho thư mục con của nó dưới ./output/. Các session DataDreamer tự động cung cấp logging thân thiện với người dùng xung quanh các tác vụ quy trình chạy trong session (xem Hình 2).

### 4.3 Steps

Steps là các toán tử cốt lõi trong session DataDreamer. Một step trong DataDreamer chuyển đổi từ bộ dữ liệu đầu vào thành bộ dữ liệu đầu ra (Lhoest et al., 2021). Điều này hữu ích cho các tác vụ như tạo dữ liệu tổng hợp từ LLM, hoặc tăng cường dữ liệu cho các bộ dữ liệu hiện có. Đầu ra của một step có thể được sử dụng trực tiếp làm đầu vào cho step khác hoặc làm đầu vào cho trainer, cho phép người dùng kết nối nhiều steps/trainers để tạo các quy trình phức tạp. DataDreamer đi kèm với một số steps có sẵn cho các thao tác phổ biến trong quy trình LLM, một số ví dụ có thể được thấy trong Bảng 2. Các thao tác xử lý dữ liệu tiêu chuẩn hữu ích như .map(), .filter(), và .shuffle() cũng có thể được áp dụng nhanh chóng cho đầu ra của một step để xử lý tùy chỉnh. DataDreamer sử dụng memory-mapping để xử lý các bộ dữ liệu lớn được lưu trữ trên đĩa và có thể chạy một cách lazy trên các bộ dữ liệu iterable, streaming.

### 4.4 Models

Các mô hình có thể được tải trong session DataDreamer và sau đó được truyền làm đối số cho các steps như FewShotPrompt và ProcessWithPrompt. DataDreamer tạo giao diện chuẩn hóa để truy cập các LLM mã nguồn mở và thương mại. Nó bao gồm giao diện cho các mô hình embedding cũng như LLM. Ví dụ về các mô hình được hỗ trợ và nhà cung cấp mô hình có thể được tìm thấy trong Bảng 2.

### 4.5 Trainers

Trainers có thể huấn luyện trên bộ dữ liệu được tạo bởi một step trong quy trình DataDreamer. Bộ dữ liệu có thể được tải từ nguồn bên ngoài hoặc được tạo ra như đầu ra của một step trong quy trình đa bước. Các trainers của DataDreamer hỗ trợ nhiều kỹ thuật và tác vụ bao gồm tinh chỉnh, instruction-tuning, alignment thông qua RLHF (Ouyang et al., 2022) và DPO (Rafailov et al., 2023), chưng cất, huấn luyện classifier và huấn luyện mô hình embedding. Ví dụ về các kỹ thuật được hỗ trợ được hiển thị trong Bảng 2.

### 4.6 Caching và Chia sẻ Quy trình

Caching có tiện ích thực tế trong các quy trình LLM vì các mô hình lớn này có thể vừa tốn kém về mặt tính toán vừa tài chính để chạy. Do đó, việc loại bỏ tính toán lại có thể tiết kiệm cả thời gian và tài nguyên. Caching trong DataDreamer diễn ra ở nhiều cấp độ. Khi một step hoặc trainer hoàn thành, bộ dữ liệu kết quả hoặc mô hình được huấn luyện được lưu vào đĩa và tải từ đĩa nếu step hoặc trainer được thực thi lại với cùng đầu vào và đối số, thay vì được chạy lại. Ngoài ra, DataDreamer cache ở cấp độ mô hình, cache kết quả của các prompt hoặc văn bản được chạy đối với một mô hình vào file cơ sở dữ liệu SQLite. Trong quá trình huấn luyện, DataDreamer tương tự tự động lưu checkpoint và tiếp tục từ chúng nếu bị gián đoạn và khởi động lại. Caching sử dụng không gian đĩa tối thiểu (chủ yếu lưu trữ văn bản) và thêm overhead tối thiểu trong các workload này bị chi phối bởi tính toán suy luận mô hình nặng, nhưng có thể được vô hiệu hóa một cách chi tiết nếu muốn.

Hệ thống cache của DataDreamer cho phép nhà nghiên cứu chia sẻ cả script quy trình và thư mục đầu ra session với người khác, cung cấp cho họ quyền truy cập vào cache và đầu ra đã lưu hữu ích. Những điều này cho phép người khác dễ dàng tái tạo và mở rộng toàn bộ quy trình trong khi cũng hưởng lợi từ việc tránh các tính toán tốn kém khi không cần thiết. Ví dụ, một nhà nghiên cứu có thể mở rộng quy trình của nhà nghiên cứu khác bằng cách thêm một step khác ở cuối. Chỉ có step được thêm vào mới cần được tính toán, trong khi tất cả các step ban đầu có thể có kết quả được tải từ đĩa.

### 4.7 Khả năng Tiếp tục

Caching cho phép khả năng tiếp tục trong quá trình phát triển, vì vậy các script có thể bị gián đoạn và tiếp tục. Điều này cho phép xử lý khéo léo các sự cố, preemption máy chủ và các tình huống khác trong đó chỉ một phần của quy trình được tính toán trước đó. Hơn nữa, caching có thể hữu ích trong quá trình thử nghiệm quy trình. Ví dụ, khi sửa đổi một prompt duy nhất ở giữa quy trình tạo dữ liệu tổng hợp đa bước, thay đổi có thể chỉ ảnh hưởng đến một số đầu vào nhất định cho step tiếp theo. Nếu vậy, chỉ phần công việc đó sẽ được tính toán lại.

### 4.8 Chia sẻ Dữ liệu Mở và Mô hình Mở

DataDreamer cung cấp các tiện ích thuận tiện để xuất và xuất bản các bộ dữ liệu và mô hình được huấn luyện được tạo bởi các steps hoặc trainers. Tài nguyên có thể được xuất ra đĩa hoặc xuất bản lên Hugging Face Hub. Khi tài nguyên được xuất bản, DataDreamer có thể tự động tải lên đoạn mã minh họa và thiết lập widget minh họa trực tiếp trên Hugging Face Hub, điều này làm cho các tài nguyên được chia sẻ dễ sử dụng. Ngoài ra, các tài nguyên này tự động được cung cấp metadata thích hợp như thẻ chỉ ra rõ ràng khi dữ liệu được tạo tổng hợp và LLM nguồn của nó. DataDreamer cũng tạo ra những gì chúng tôi gọi là "synthetic data cards" và "synthetic model cards". Synthetic data cards và model cards được tự động tạo ra bằng cách truy vết đệ quy qua tất cả các steps, mô hình và trainers mà DataDreamer đã sử dụng để tạo ra bộ dữ liệu hoặc mô hình. Mỗi step, mô hình và trainer có metadata liên quan bao gồm thông tin giấy phép và thông tin trích dẫn. DataDreamer thu thập thông tin này và tạo ra synthetic data card (hoặc model card) báo cáo thông tin cùng với thông tin tái tạo cho mỗi step, mô hình và trainer trong quy trình. Thông tin được thu thập trong các card của chúng tôi được định nghĩa trong Bảng 3.

Các synthetic data cards và model cards được tạo tự động này có thể hỗ trợ ngăn ngừa ô nhiễm các nguồn pre-training với dữ liệu tổng hợp được tạo bởi mô hình. Khi tạo dữ liệu tổng hợp trở nên phổ biến hơn, ô nhiễm có thể là một mối quan tâm do suy giảm hiệu suất đã được quan sát khi các bộ dữ liệu tổng hợp được chia sẻ và huấn luyện, có thể mà không có kiến thức của nhà phát triển mô hình (Shumailov et al., 2023). Các card của DataDreamer cũng có thể giúp các nhà nghiên cứu khác hiểu những hạn chế giấy phép nào có thể áp dụng cho dữ liệu được tạo tổng hợp, trong số các mối quan tâm khả năng sử dụng khác. Các card được tạo tự động này không phải là sự thay thế cho data cards và model cards truyền thống (Pushkarna et al., 2022; Mitchell et al., 2019) khuyến nghị một tập hợp rộng hơn các thuộc tính quan trọng như thiên lệch bộ dữ liệu tiềm năng. Thay vào đó, chúng cung cấp thông tin bổ sung quan trọng đối với khả năng sử dụng và tái tạo của các quy trình LLM. Chúng tôi khuyến khích các nhà nghiên cứu xem xét và thêm thông tin không thể được phát hiện tự động vào các card được tạo của chúng tôi.

### 4.9 Hiệu quả và Tối ưu hóa

Các quy trình LLM thường hưởng lợi từ hoặc yêu cầu một số tối ưu hóa nhất định được áp dụng để tải hoặc xử lý quy mô dữ liệu và mô hình thường được sử dụng. DataDreamer hỗ trợ nhiều tối ưu hóa phổ biến mà các nhà nghiên cứu có thể muốn áp dụng.

**Parallelization** DataDreamer hỗ trợ chạy các steps trong các tiến trình nền và chạy các steps đồng thời để dễ dàng thực hiện điều phối tác vụ song song trong quy trình.

**Quantization và Adapters** DataDreamer hỗ trợ quantization trọng số mô hình có thể giảm việc sử dụng bộ nhớ (Dettmers và Zettlemoyer) cũng như các kỹ thuật tinh chỉnh hiệu quả tham số như LoRA adapters (Hu et al., 2021; Mangrulkar et al., 2022). Nó chuẩn hóa việc sử dụng các tối ưu hóa này trên các kiến trúc mô hình khác nhau và giảm thiểu boilerplate, làm cho nó đơn giản như một đối số duy nhất để cấu hình huấn luyện với LoRA trong Ví dụ 1. DataDreamer cố gắng tạo hỗ trợ đồng nhất cho các tính năng trên tất cả các tích hợp được hỗ trợ khi có thể. Vì vậy trong khi các thư viện sentence_transformers và transformers cơ bản không hỗ trợ huấn luyện mô hình embedding với LoRA (Reimers và Gurevych, 2019; Wolf et al., 2019), DataDreamer hỗ trợ điều này, điều này mở rộng lợi ích của LoRA cho các mô hình này.

**Sử dụng Đa GPU** DataDreamer làm cho việc tải mô hình trên nhiều GPU và huấn luyện mô hình trên nhiều GPU với PyTorch FSDP trở nên đơn giản (Paszke et al., 2019; Zhao et al., 2023). Ví dụ, huấn luyện mô hình trên nhiều GPU đơn giản như truyền danh sách torch.device cho tham số device của trainer (device=["cuda:0", "cuda:1"]). DataDreamer tự động cấu hình FSDP và khởi chạy các tiến trình phân tán trong session để trình khởi chạy dòng lệnh như torchrun không bao giờ phải được sử dụng, đơn giản hóa huấn luyện đa GPU. Việc sử dụng torchrun thường có thể buộc các quy trình phức tạp, đa giai đoạn bị chia thành nhiều script được khởi chạy qua shell script vì các phần huấn luyện cần được cô lập khỏi các phần tạo dữ liệu hoặc xử lý dữ liệu. Độ phức tạp được thêm vào này trong việc chạy quy trình end-to-end có thể làm cho khả năng tái tạo trở nên thách thức. Với DataDreamer, các quy trình không cần được điều phối lại xung quanh các phần cần được khởi chạy qua torchrun. Vì DataDreamer xử lý việc điều phối phân tán này tự động, người dùng có thể xây dựng các quy trình đa giai đoạn liên quan đến tạo dữ liệu, xử lý dữ liệu và huấn luyện trên nhiều GPU tất cả trong một chương trình Python duy nhất, loại bỏ việc sử dụng điều phối thông qua nhiều shell script. Ví dụ 4 trong Phụ lục cung cấp một ví dụ về quy trình như vậy.

### 4.10 Cấu hình và Khả năng Mở rộng

DataDreamer tìm cách giảm thiểu cấu hình và mã boilerplate mà đối với hầu hết các quy trình nghiên cứu không cần được tùy chỉnh, ví dụ tự động xử lý tokenization và áp dụng padding chính xác, trong số các tác vụ khác. DataDreamer áp dụng các mặc định hợp lý và thực hành nghiên cứu tiêu chuẩn để giảm thiểu cấu hình. Tuy nhiên, một số nhà nghiên cứu có thể cần tùy chỉnh các lựa chọn này và tùy chọn ghi đè và mở rộng được cung cấp và tài liệu hóa tốt.

## 5 Khả năng Tái tạo

Chúng tôi phác thảo một số thực hành tốt nhất, cụ thể cho việc sử dụng mới nổi của LLM trong các quy trình nghiên cứu mà DataDreamer áp dụng. Chúng tôi tin rằng việc thiết lập các thực hành này có thể giảm bớt một số mối quan tâm về khả năng tái tạo. Tất nhiên, khi các mô hình closed-source có liên quan, những mối quan tâm này không bao giờ có thể được loại bỏ hoàn toàn (xem Phần 6 để thảo luận thêm về các hạn chế). Chúng tôi thảo luận về cách DataDreamer làm cho việc thực hiện các thực hành này dễ dàng hơn hoặc tự động thực hiện các thực hành này trong phần này.

**Thích ứng với Thay thế Mô hình** Trong khi các quy trình thử nghiệm thường có thể nhạy cảm với lựa chọn mô hình và khả năng chuyển giao của prompt có thể không đáng tin cậy (Liu et al., 2023), vì mục đích tái tạo và để dễ dàng thử nghiệm, việc triển khai mã quy trình nên cố gắng giảm thiểu sự phụ thuộc vào một mô hình cụ thể và nên cho phép các nhà nghiên cứu khác dễ dàng thay thế một LLM bằng LLM khác. Điều này cũng có thể hữu ích nếu một mô hình không thể truy cập được đối với nhà nghiên cứu khác hoặc nếu một mô hình đã trở nên lỗi thời. API và trừu tượng mô hình của DataDreamer làm cho việc thay thế mô hình trở nên đơn giản.

**Chia sẻ Prompts** Các prompt chính xác được sử dụng nên được chia sẻ vì ngay cả những biến đổi nhỏ cũng có thể tác động đáng kể đến hiệu suất (Sclar et al., 2023). DataDreamer làm cho việc chia sẻ toàn bộ quy trình và thư mục đầu ra session trở nên dễ dàng. DataDreamer cũng có thể giúp đảm bảo việc tái triển khai hoàn toàn giống hệt nhau giữa hai thiết lập thử nghiệm bằng cách so sánh dấu vân tay tái tạo của các steps riêng lẻ hoặc toàn bộ quy trình tổng hợp.

**Chia sẻ Đầu ra Trung gian** Trong các quy trình đa giai đoạn, đầu ra trung gian nên được chia sẻ để kiểm tra và phân tích bởi các nhà nghiên cứu khác cũng như cho mục đích khả năng mở rộng. DataDreamer làm cho điều này trở nên đơn giản bằng cách tự động lưu kết quả của mỗi step trong quy trình đa giai đoạn ở định dạng bộ dữ liệu Hugging Face dễ kiểm tra (Lhoest et al., 2021). Khi các LLM dựa trên API được sử dụng, có rủi ro lớn hơn đối với khả năng tái tạo. DataDreamer cho phép các quy trình được tái tạo chính xác từ cache trong thư mục đầu ra session, ngay cả khi API từ xa không còn có sẵn.

**Synthetic Data Cards và Model Cards** Synthetic data và model cards có thể giúp các nhà nghiên cứu khác hiểu nguồn gốc của dữ liệu tổng hợp, hạn chế giấy phép có thể áp dụng, trích dẫn có thể áp dụng, trong số các thuộc tính khác. Quan trọng là, các card này và metadata khác như thẻ có thể giúp ngăn ngừa ô nhiễm dữ liệu pre-training (Shumailov et al., 2023). Cuối cùng, các card này mang thông tin tái tạo, hữu ích để xác thực hai thiết lập thử nghiệm là giống hệt nhau.

**Chia sẻ Cấu hình Tối ưu hóa** Các tối ưu hóa như quantization có thể có ảnh hưởng đến các thế hệ (Jaiswal et al., 2023). Dấu vân tay tái tạo của DataDreamer tính đến các cấu hình này và với các quy trình dễ chia sẻ của nó, DataDreamer làm cho việc tái tạo một quy trình chính xác, cùng với các tối ưu hóa được cấu hình, trở nên dễ dàng.

**Mã Bất khả tri Môi trường** Vì khả năng tái tạo, mã nên cố gắng giảm thiểu sự phụ thuộc vào môi trường cục bộ, trình lập lịch công việc, shell script, v.v. DataDreamer giúp làm cho điều này dễ dàng hơn bằng cách cung cấp các công cụ cho điều phối quy trình (steps, parallelization, các tiến trình phân tán được quản lý cho huấn luyện đa GPU) có thể được thực hiện tất cả trong Python. DataDreamer cũng giảm thiểu sự phụ thuộc vào đường dẫn file cục bộ, bằng cách tổ chức kết quả và đầu ra vào thư mục đầu ra session tự động.

## 6 Kết luận

Thời điểm hiện tại trong nghiên cứu NLP và tiến bộ gần đây là thú vị nhưng đặt ra những câu hỏi quan trọng cho cộng đồng. Chúng tôi giới thiệu DataDreamer, một gói Python mã nguồn mở để thực hiện các mô hình và quy trình phổ biến liên quan đến LLM. Chúng tôi tin rằng DataDreamer cung cấp cả tiện ích thực tế và khoa học cho cộng đồng nghiên cứu và việc áp dụng nó có thể giúp thúc đẩy tốc độ tiến bộ nghiên cứu trong các quy trình liên quan đến LLM bằng cách làm cho việc triển khai dễ dàng hơn và làm cho đầu ra nghiên cứu có thể tái tạo và mở rộng được.

## Hạn chế

Trong công trình này, chúng tôi phác thảo các thực hành tốt nhất và thực hiện các thực hành này trong một hệ thống mã nguồn mở có tên DataDreamer. Chúng tôi tin rằng những đóng góp này có thể giúp hỗ trợ khoa học mở trong lĩnh vực của chúng tôi, tuy nhiên, chúng tôi thừa nhận rằng miễn là cộng đồng nghiên cứu chọn sử dụng các mô hình closed-source cho các thí nghiệm, đặc biệt là những mô hình được phục vụ phía sau API trên các máy chủ từ xa, các thách thức đối với khả năng tái tạo là không thể tránh khỏi. Với DataDreamer, chúng tôi cung cấp một cách để tái tạo và phân tích thêm một số thí nghiệm này lâu sau khi các API từ xa này có thể được thay đổi hoặc không có sẵn thông qua hệ thống caching dựa trên session cũng như cung cấp cách dễ dàng thay thế mô hình khi cần thiết thông qua trừu tượng. Theo hiểu biết tốt nhất của chúng tôi, không có những cân nhắc đạo đức đáng kể nào phát sinh từ công trình này. Chúng tôi tin rằng tác động rộng hơn của công trình này phần lớn là tích cực, làm cho các quy trình LLM tiên tiến vừa dễ dàng hơn vừa dễ tiếp cận hơn để thực hiện và tái tạo cũng như giảm phát thải carbon thông qua hệ thống caching của DataDreamer giúp các nhà nghiên cứu tránh tính toán lại tốn kém khi có thể.

## Lời cảm ơn

Nghiên cứu này được hỗ trợ một phần bởi Văn phòng Giám đốc Tình báo Quốc gia (ODNI), Hoạt động Nghiên cứu Dự án Tiên tiến Tình báo (IARPA), thông qua hợp đồng Chương trình HIATUS #2022-22072200005. Các quan điểm và kết luận có trong đây là của các tác giả và không nên được hiểu là nhất thiết đại diện cho các chính sách chính thức, được thể hiện rõ ràng hoặc ngụ ý, của ODNI, IARPA, hoặc Chính phủ Hoa Kỳ. Chính phủ Hoa Kỳ được ủy quyền tái tạo và phân phối bản sao cho các mục đích chính phủ bất chấp bất kỳ chú thích bản quyền nào trong đó.

# 2309.06358.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/dataset-generation/2309.06358.pdf
# Kích thước tệp: 248353 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Tăng cường Dữ liệu Sinh tạo sử dụng LLM cải thiện Độ bền Phân phối
trong Hỏi đáp
Arijit Ghosh Chowdhury
Đại học Illinois Urbana Champaign
arijit10@gmail.comAman Chadha
Đại học Stanford
Amazon GenAI∗
hi@aman.ai

Tóm tắt
Độ bền trong Xử lý Ngôn ngữ Tự nhiên
tiếp tục là một vấn đề liên quan, nơi các mô
hình tiên tiến hoạt động kém dưới các phân
phối bị dịch chuyển tự nhiên. Trong bối cảnh
Hỏi đáp, công việc về các phương pháp thích
ứng miền tiếp tục là một lĩnh vực nghiên cứu
đang phát triển. Tuy nhiên, rất ít sự chú ý đã
được dành cho khái niệm tổng quát hóa miền
dưới các dịch chuyển phân phối tự nhiên, nơi
miền đích không được biết. Với những cải tiến
mạnh mẽ về chất lượng và khả năng tiếp cận
các mô hình sinh tạo, chúng tôi trả lời câu hỏi:
Các tập dữ liệu được tạo ra ảnh hưởng như thế
nào đến hiệu suất của các mô hình QA dưới
các dịch chuyển phân phối tự nhiên? Chúng tôi
thực hiện các thí nghiệm trên 4 tập dữ liệu
khác nhau dưới các mức độ dịch chuyển phân
phối khác nhau, và phân tích cách sinh tạo
"trong tự nhiên" có thể giúp đạt được tổng
quát hóa miền. Chúng tôi áp dụng phương
pháp sinh tạo hai bước, sinh tạo cả ngữ cảnh
và cặp QA để tăng cường các tập dữ liệu hiện
có. Thông qua các thí nghiệm của chúng tôi,
chúng tôi chứng minh cách tăng cường các tập
dữ liệu đọc hiểu với dữ liệu được tạo ra dẫn
đến độ bền tốt hơn đối với các dịch chuyển
phân phối tự nhiên.

1 Giới thiệu
Trong công việc này, chúng tôi thực hiện một nghiên cứu
có hệ thống về cách sinh tạo "trong tự nhiên" có thể ảnh
hưởng đến độ bền phân phối của các mô hình hỏi đáp
được huấn luyện trên Tập dữ liệu Hỏi đáp Stanford phổ
biến (SQUAD) (Rajpurkar et al., 2016). Sinh tạo dữ liệu
tổng hợp là một phương pháp được áp dụng rộng rãi cho
thích ứng miền trong các hệ thống QA (Shakeri
et al., 2020) (Yue et al., 2021) (Yue et al., 2022).
Tuy nhiên, các phương pháp thích ứng miền có quyền
truy cập vào dữ liệu không được gán nhãn/có gán nhãn
thuộc về miền đích, và không tính đến các dịch chuyển
phân phối tự nhiên chưa được nhìn thấy. Công việc của
chúng tôi nghiên cứu hiệu ứng của dữ liệu được tạo ra
đối với các dịch chuyển phân phối nơi miền đích không
được nhìn thấy.

∗Công việc không liên quan đến vị trí tại Amazon.

Quan niệm về một tập dữ liệu đã trải qua sự
tiến hóa đáng kể trong thời gian gần đây. Sự biến đổi
này đã được thúc đẩy bởi sự xuất hiện của các mô hình
sinh tạo được huấn luyện 'trong tự nhiên', như những
mô hình được mô tả trong (Brown et al., 2020), (Bubeck
et al., 2023), và (Touvron et al., 2023). Những mô hình
này, sử dụng các tập dữ liệu rộng lớn và đa dạng trên
một loạt các miền, đã tạo điều kiện cho việc truyền vào
web dữ liệu tổng hợp chất lượng cao, áp dụng cho một
mảng rộng lớn các chủ đề khái niệm. Thú vị là, những
mô hình này không chỉ giới hạn ở việc sinh tạo dựa trên
một phân phối được thiết lập trước; chúng có khả năng
nhắc nhở lặp đi lặp lại, dẫn đến việc tạo ra dữ liệu đa
dạng đáng kể. Trong bối cảnh của mô hình paradigm
mới nổi này, nghiên cứu của chúng tôi điều tra câu hỏi
sau: Các tập dữ liệu được tạo ra ảnh hưởng như thế nào
đến độ bền phân phối của các mô hình Hỏi đáp? Cụ thể,
các dịch chuyển phân phối tự nhiên trong NLP có thể
phát sinh do sự khác biệt về thể loại và phong cách văn
bản, chủ đề và từ vựng văn bản, nhân khẩu học của các
tác giả, phương tiện của văn bản (viết so với nói), và
các thuộc tính khác (Wang et al., 2022). Một thách thức
chính là các mô hình NLP được huấn luyện trên một
phân phối dữ liệu thường không tổng quát hóa tốt cho
những dịch chuyển tự nhiên xảy ra này. Ví dụ, (Miller
et al., 2020) phát hiện rằng các mô hình hỏi đáp trải
qua giảm điểm F1 trung bình 3.8 điểm trên các bài báo
tin tức, 14 điểm trên các bài đăng Reddit, và 17.4 điểm
trên các đánh giá Amazon so với các bài viết Wikipedia.
Điều này tiết lộ tính dễ vỡ của các mô hình NLP đối với
các dịch chuyển phân phối tự nhiên.

Chúng tôi trình bày tổng quan về thiết lập sinh tạo
của chúng tôi trong Hình 1. Để sinh tạo dữ liệu, sử dụng
GPT-3.5 (Brown et al., 2020), và tạo một tập dữ liệu
hỏi đáp sử dụng các câu hỏi được cung cấp trong tập dữ
liệu SQUAD (Rajpurkar et al., 2016). Chúng tôi sử dụng
phương pháp sinh tạo kép, bằng cách đầu tiên nhắc nhở
mô hình ngôn ngữ sinh tạo một ngữ cảnh cho một câu
hỏi được đưa ra trong tập dữ liệu SQUAD, và sau đó
sinh tạo các cặp câu hỏi-trả lời cho ngữ cảnh mới được
sinh tạo.

--- TRANG 2 ---
Các khảo sát gần đây, như (Ramponi và Plank,
2020), thảo luận về thích ứng miền trong NLP và chia
các phương pháp thành tập trung vào dữ liệu và tập
trung vào mô hình. Chúng tôi áp dụng phương pháp
tập trung vào dữ liệu, như được nhấn mạnh bởi các
phát hiện từ (Wang et al., 2022) chứng minh sự chồng
chéo trong dữ liệu kiểm tra-huấn luyện cho các mô hình
QA. Sự khan hiếm nghiên cứu về tổng quát hóa trong
các mô hình QA, đặc biệt với các dịch chuyển phân phối
tự nhiên, là động lực cho công việc của chúng tôi, được
hỗ trợ bởi các quan sát từ (Arora et al., 2021) về dữ liệu
ngoài phân phối trong NLP.

Các thí nghiệm ban đầu như (Longpre et al., 2019)
mạo hiểm vào hỏi đáp không phụ thuộc miền sử dụng
tăng cường dữ liệu. Các tập dữ liệu mới được giới thiệu
bởi (Miller et al., 2020), có nguồn gốc từ các nền tảng
khác nhau, nhấn mạnh hiệu ứng của các dịch chuyển
phân phối tự nhiên đối với các mô hình QA. Trong khi
những nghiên cứu này cung cấp các đánh giá mở rộng,
công việc của chúng tôi xây dựng trên chúng bằng cách
tập trung vào tác động của các tập dữ liệu được tạo ra
bởi mô hình ngôn ngữ lớn (LLM) cho các nhiệm vụ QA
và tiếp tục tận dụng những tập dữ liệu này cho phương
pháp tăng cường dữ liệu của chúng tôi.

Lợi ích của dữ liệu được tạo ra đã được khám phá
bởi (Gowal et al., 2021), cho thấy tiềm năng của nó
trong độ bền đối nghịch. (Bartolo et al., 2021) và
(Mekala et al., 2022) sử dụng dữ liệu tổng hợp và được
tạo ra từ ngữ cảnh tương ứng cho QA và phân loại văn
bản. Phương pháp của chúng tôi sử dụng mô hình GPT-
3.5, như được mô tả bởi (Wei et al., 2022), để sinh tạo
ngữ cảnh cho các câu hỏi. Với động lực tương tự,
(Bansal và Grover, 2023) chứng minh việc áp dụng
Stable Diffusion trong việc tạo ra tập dữ liệu đa dạng
cho các nhiệm vụ hình ảnh.

ĐÓNG GÓP CỦA CHÚNG TÔI
➠Chúng tôi đề xuất một khung để cải thiện độ bền phân phối
của các mô hình đọc hiểu trong sự hiện diện của các dịch
chuyển phân phối tự nhiên.
➠Thông qua một đánh giá định lượng toàn diện, chúng tôi
đánh giá khả năng của các LLM để sinh tạo dữ liệu tổng
hợp chất lượng cao cho các nhiệm vụ hỏi đáp.

2 Phương pháp luận
2.1 Sinh tạo Ngữ cảnh
Chúng tôi đầu tiên sinh tạo các ngữ cảnh bằng cách điều
kiện hóa nó trên một câu hỏi có mặt trong tập dữ liệu
SQUAD. Điều này cho phép mô hình ngôn ngữ sinh tạo
một đoạn văn có thể được sử dụng để sinh tạo các cặp
câu hỏi-trả lời. Vì đoạn văn được sinh tạo sử dụng một
câu hỏi hiện có, ngữ cảnh được sinh tạo nhất quán với
định dạng thông tin trivia của các tập dữ liệu giống
SQUAD. Chúng tôi cũng đảm bảo rằng các ngữ cảnh
được sinh tạo đa dạng nhưng bổ sung cho tập dữ liệu
gốc, như được nhấn mạnh bởi (Gowal et al., 2021). Để
duy trì tính nhất quán hơn nữa, ngữ cảnh được sinh tạo
được cắt để nằm trong 250 từ, dựa trên độ dài ngữ cảnh
trung bình có mặt trong tập dữ liệu SQUAD. Chúng tôi
nhắc nhở GPT 3.5 (gpt-3.5-turbo)¹ theo cách sau: Sinh
tạo một đoạn văn trả lời câu hỏi sau: (câu hỏi). Ở đây
câu hỏi được lấy mẫu từ tập dữ liệu SQUAD. Hình 1
chứng minh quá trình sinh tạo. Thêm vào đó, Phụ lục A
chứa các ví dụ từ quá trình sinh tạo.

2.2 Sinh tạo Câu hỏi Trả lời
Sau khi ngữ cảnh được tạo ra, đoạn văn được sinh tạo
được sử dụng để tạo ra các cặp câu hỏi-trả lời. Điều này
được thực hiện bằng cách sử dụng mô hình sinh tạo câu
hỏi dựa trên T5 (Lopez et al., 2020) được huấn luyện
trên tập dữ liệu SQUAD, nhận một đoạn văn làm đầu
vào và trả về một cặp câu hỏi-trả lời. Chúng tôi sử dụng
việc triển khai mã nguồn mở² cho mô hình này. Thêm
vào đó, chúng tôi cũng lọc ra các cặp QA dựa trên tính
nhất quán khứ hồi (Alberti et al., 2019).

3 Thí nghiệm
3.1 Thiết lập
Chúng tôi huấn luyện một mô hình đọc hiểu trích xuất
sử dụng SQUAD V1.1, sử dụng mô hình RoBERTA-Base
trong tất cả các thí nghiệm của chúng tôi. Chúng tôi sử
dụng tốc độ học 3e⁻⁵, kích thước batch 16 và chạy các
thí nghiệm của chúng tôi trong 3 epoch mỗi lần. Chúng
tôi sử dụng việc triển khai được cung cấp bởi
HuggingFace, và chạy các mô hình của chúng tôi trên
một GPU Nvidia A100 độc lập được cung cấp bởi
Google Colab. Chúng tôi không sử dụng GPT-3.5 làm
đường cơ sở vì mục đích của nghiên cứu này là đo lường
cụ thể hiệu suất bằng các mô hình nhỏ hơn.

Đối với tất cả các thí nghiệm của chúng tôi, chúng tôi
đo lường điểm F1 và Exact Match để định lượng hiệu
suất trên các tập dữ liệu Dịch chuyển Phân phối Tự
nhiên (NDS).

3.2 Tập dữ liệu
Chúng tôi sử dụng các tập dữ liệu sau được tạo ra bởi
(Miller et al., 2020) để thiết lập bàn thử nghiệm của
chúng tôi:

Tập dữ liệu New Wikipedia chứa các cặp QA mới hơn
từ các bài viết wikipedia được sử dụng bởi tập dữ liệu
SQUAD V1.1. Chứa 7,938 mẫu kiểm tra từ

¹https://platform.openai.com/docs/models
²https://github.com/patil-suraj/question-generation

--- TRANG 3 ---
Dữ liệu Thực Dữ liệu Được sinh tạo
Câu hỏi GPT 3.5 Ngữ cảnh
Được sinh tạoT5 Câu hỏi
Được sinh tạo Câu trả lời
Được sinh tạoBộ phân loại

Hình 1: Tổng quan về hệ thống sinh tạo. Phương pháp của chúng tôi tạo ra một tập dữ liệu được sinh tạo sau đó được tăng cường với tập dữ liệu thực để huấn luyện một mô hình hỏi đáp.

[THIS IS TABLE: A performance comparison table showing metrics (F1 and EM scores) across different datasets (SQUAD, NewWiki, NYT, Amazon, Reddit) for various data configurations including real data, generated data, and combinations thereof]

Bảng 1: Các tập dữ liệu được sinh tạo chứng minh độ bền đối với các dịch chuyển phân phối tự nhiên.

48 ngữ cảnh. Tập dữ liệu New York Times chứa các bài viết từ New York Times sau đó được sử dụng để chú thích các cặp QA cùng định dạng như SQUAD. Được đảm bảo rằng thống kê độ dài đoạn văn giữ nguyên. Chứa 10,065 mẫu kiểm tra từ 46 bài viết. Tập dữ liệu Reddit chứa các bài viết từ Reddit nơi các tác giả nối tiêu đề của mỗi bài đăng với nội dung của nó. Tập dữ liệu này chứa 9,803 mẫu kiểm tra từ 1,969 bài đăng. Tập dữ liệu Amazon Product Reviews chứa các đánh giá sản phẩm do người dùng tạo ra từ danh mục "Home and Kitchen" trên Amazon. Dữ liệu này chứa 9,885 mẫu kiểm tra từ 1,909 đánh giá.

4 Kết quả
4.1 Dữ liệu được sinh tạo có giúp ích cho độ bền phân phối không?

Chúng tôi đánh giá điểm F1 và Exact Match của các mô hình được huấn luyện với các tập dữ liệu khác nhau trên các benchmarks dịch chuyển phân phối tự nhiên (NDS). Chúng tôi ghi chú các số EM và F1 trung bình qua ba hạt giống ngẫu nhiên trong Bảng 1. Các mô hình được huấn luyện trên lượng dữ liệu thực và được sinh tạo bằng nhau.

Chúng tôi phát hiện rằng mô hình, khi được huấn luyện trên SQUAD, khi chịu tác động của các tập dữ liệu dịch chuyển phân phối tự nhiên, hiệu suất của mô hình giảm đáng kể. Một quan sát đáng chú ý là việc huấn luyện độc quyền trên dữ liệu được sinh tạo dẫn đến hiệu suất dưới tiêu chuẩn trên cả SQUAD và các tập dữ liệu Dịch chuyển Phân phối Tự nhiên (NDS) của nó. Hiệu suất tuyệt đối kém có thể được cho là do sự khác biệt phân phối giữa các tập dữ liệu huấn luyện nguồn và được sinh tạo. Thú vị là, chúng tôi quan sát rằng đối với mô hình được huấn luyện trên dữ liệu được sinh tạo, khoảng cách hiệu suất trên tập dữ liệu xác thực thực và các tập dữ liệu NDS của nó thấp, điều này có thể được cho là do lợi ích của việc huấn luyện trên dữ liệu được sinh tạo đa dạng. Điều này nhấn mạnh các đóng góp của dữ liệu được sinh tạo trong việc cải thiện độ bền, trái ngược với việc đơn giản sinh tạo thêm dữ liệu để huấn luyện.

Chúng tôi cũng lấy mẫu các đoạn văn từ Wikipedia và sinh tạo câu hỏi từ những đoạn văn đó, thay vì để GPT3.5 sinh tạo các đoạn văn. Điều này cải thiện hiệu suất trong miền trên SQUAD, nhưng dẫn đến giảm hiệu suất trên các tập dữ liệu ngoài miền, nhấn mạnh thêm về hiệu quả của việc sinh tạo ngữ cảnh trong tự nhiên đối với các dịch chuyển phân phối.

Cuối cùng, chúng tôi phơi bày mô hình của chúng tôi với một hỗn hợp phân phối đều của các tập dữ liệu thực và được sinh tạo, với mục tiêu điều tra tác động của các tăng cường sinh tạo. Kết quả của chúng tôi tiết lộ rằng hiệu suất tuyệt đối của mô hình, khi được huấn luyện với sự kết hợp của dữ liệu thực và được sinh tạo, hoặc song song hoặc vượt qua hiệu suất của các mô hình được huấn luyện độc quyền trên dữ liệu thực hoặc được sinh tạo

--- TRANG 4 ---
[THIS IS TABLE: Performance table showing F1 and EM scores for different datasets with varying amounts of generated data]
Tập dữ liệu SQUAD NewWiki NYT Amazon Reddit
Chỉ số F1 EM F1 EM F1 EM F1 EM F1 EM
Thực + 50% Dữ liệu được sinh tạo 91.4 81.1 90.4 82.2 87.4 77.1 79.7 65.4 80.3 67.4
Thực + 100% Dữ liệu được sinh tạo 92.7 84.7 91.1 80.4 88.9 79.3 80.3 67.1 81.7 68.7
Thực + 200% Dữ liệu được sinh tạo 92.9 84.8 91.3 80.7 88.5 79.1 80.9 67.3 80.8 68.1

Bảng 2: Hiệu suất trên các lượng dữ liệu khác nhau. Sử dụng lượng dữ liệu thực và được sinh tạo bằng nhau là cần thiết.

[THIS IS TABLE: Ablation study comparing different generation approaches]
Tập dữ liệu SQUAD NYT Amazon
Chỉ số F1 EM F1 EM F1 EM
Dữ liệu thực 90.4 83.0 86.4 76.1 79.9 66.4
Thực + Dữ liệu được sinh tạo (Chỉ Câu hỏi) 91.5 82.7 85.7 75.6 77.4 63.5
Thực + Dữ liệu được sinh tạo (Ngữ cảnh + Câu hỏi) 92.7 84.7 88.9 79.3 80.9 67.3

Bảng 3: Nghiên cứu Ablation chứng minh cách sinh tạo ngữ cảnh là chìa khóa cho độ bền.

tập dữ liệu, trên tất cả các tập dữ liệu được phân phối tự nhiên. Quan sát này gợi ý rằng việc kết hợp dữ liệu thực vào quá trình huấn luyện thực sự cần thiết để đạt được hiệu suất tuyệt đối vượt trội.

Để tóm tắt, trong khi việc sử dụng duy nhất dữ liệu được sinh tạo cải thiện độ bền với cái giá của hiệu suất tuyệt đối, một hỗn hợp của dữ liệu thực và được sinh tạo nhân tạo trình bày sự cân bằng lý tưởng cho huấn luyện mạnh mẽ và chính xác.

4.2 Cần bao nhiêu dữ liệu được sinh tạo?
Ở đây, chúng tôi điều tra cách các kết hợp khác nhau của tập dữ liệu được sinh tạo có thể giúp các bộ phân loại tận dụng các thế mạnh bổ sung của hai nguồn dữ liệu (Bảng 2).

Để làm điều này, chúng tôi đánh giá hiệu suất trung bình của các mô hình được huấn luyện với ba kết hợp trộn đầu vào khác nhau được tạo ra bằng cách sử dụng 50%, 100%, và 200% của tập dữ liệu được sinh tạo. Chúng tôi quan sát sự gia tăng hiệu suất trên các tập dữ liệu đã dịch chuyển khi kích thước của dữ liệu được sinh tạo tăng lên trong khi giữ cố định lượng dữ liệu thực. Tuy nhiên, khi tỷ lệ của dữ liệu được sinh tạo tăng gấp đôi trong khi giữ cố định tỷ lệ của dữ liệu thực, chúng tôi quan sát rằng các cải thiện hiệu suất chỉ là cận biên. Thêm vào đó, chúng tôi lưu ý rằng việc chỉ sử dụng một nửa dữ liệu được sinh tạo không cung cấp đủ tín hiệu có ý nghĩa về mặt đa dạng và không dẫn đến các cải thiện hiệu suất lớn so với huấn luyện trên dữ liệu thực.

Nhìn chung, chúng tôi phát hiện rằng sự phân chia lý tưởng giữa dữ liệu thực và được sinh tạo là phân chia 50-50 nơi hai tập dữ liệu có thể bổ sung cho nhau, về mặt cung cấp cả đa dạng và các mẫu trong miền cùng một lúc.

4.3 Có cần sinh tạo ngữ cảnh không?
Bảng 3 chứng minh tầm quan trọng của việc sinh tạo cả ngữ cảnh và câu hỏi để cải thiện độ bền của mô hình đối với các dịch chuyển phân phối. Khi chỉ sinh tạo câu hỏi cho các ngữ cảnh hiện có, hiệu suất trên tập dữ liệu SQuAD gốc cải thiện nhẹ, trong khi hiệu suất giảm đáng kể trên các tập dữ liệu NYT và Amazon ngoài phân phối. Điều này chỉ ra rằng việc sinh tạo câu hỏi một mình làm cho các mô hình quá khớp với phân phối SQuAD, giảm độ bền. Ngược lại, việc sinh tạo cả ngữ cảnh và câu hỏi dẫn đến các cải thiện nhất quán trong hiệu suất trên tất cả các tập dữ liệu. Phương pháp sinh tạo kép tăng cường độ bền của mô hình bằng cách phơi bày mô hình với nhiều đa dạng hơn trong quá trình huấn luyện, dẫn đến tổng quát hóa tốt hơn. Các kết quả chứng minh rằng việc sinh tạo các ngữ cảnh đa dạng bên cạnh việc sinh tạo câu hỏi có mục tiêu là quan trọng để cải thiện độ bền đối với các dịch chuyển phân phối tự nhiên, thay vì chỉ sinh tạo câu hỏi.

5 Kết luận và Hướng Tương lai
Chúng tôi đã tạo ra một khung tăng cường hiệu suất của các mô hình đọc hiểu bằng cách bổ sung các tập dữ liệu thực với một tập dữ liệu đa dạng được sinh tạo bởi các mô hình sinh tạo đương đại, thực tế. Các phát hiện của chúng tôi chỉ ra rằng phương pháp huấn luyện này mang lại kết quả vượt trội trên các tập dữ liệu kiểm tra và những tập dữ liệu có dịch chuyển phân phối tự nhiên, do độ bền được thêm vào từ việc huấn luyện trên dữ liệu được sinh tạo trái ngược với các phương pháp truyền thống. Trong tương lai, chúng tôi muốn khám phá một so sánh mở rộng hơn so với các phương pháp sinh tạo câu hỏi và cách paradigm này phù hợp với việc tinh chỉnh các mô hình lớn hơn.

--- TRANG 5 ---
Tài liệu tham khảo
Chris Alberti, Daniel Andor, Emily Pitler, Jacob Devlin,
và Michael Collins. 2019. Sinh tạo corpora qa tổng hợp
với tính nhất quán khứ hồi.

Udit Arora, William Huang, và He He. 2021. Các loại
văn bản ngoài phân phối và cách phát hiện chúng.
Trong Proceedings of the 2021 Conference on Empiri-
cal Methods in Natural Language Processing, trang
10687–10701, Online và Punta Cana, Dominican
Republic. Association for Computational Linguistics.

Hritik Bansal và Aditya Grover. 2023. Để lại thực tế
cho trí tưởng tượng: Phân loại mạnh mẽ thông qua các
tập dữ liệu được sinh tạo.

Max Bartolo, Tristan Thrush, Robin Jia, Sebastian
Riedel, Pontus Stenetorp, và Douwe Kiela. 2021.
Cải thiện độ bền của mô hình hỏi đáp với sinh tạo dữ
liệu đối nghịch tổng hợp. Trong Proceedings of the
2021 Conference on Empirical Methods in Natural
Language Processing, trang 8830–8848, Online và
Punta Cana, Dominican Republic. Association for
Computational Linguistics.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
Clemens Winter, Christopher Hesse, Mark Chen, Eric
Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
Jack Clark, Christopher Berner, Sam McCandlish,
Alec Radford, Ilya Sutskever, và Dario Amodei.
2020. Các mô hình ngôn ngữ là các học viên few-shot.

Sébastien Bubeck, Varun Chandrasekaran, Ronen El-
dan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Pe-
ter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg,
Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro,
và Yi Zhang. 2023. Tia lửa của trí tuệ nhân tạo tổng
quát: Các thí nghiệm sớm với gpt-4.

Sven Gowal, Sylvestre-Alvise Rebuffi, Olivia Wiles,
Florian Stimberg, Dan Andrei Calian, và Timothy
Mann. 2021. Cải thiện độ bền sử dụng dữ liệu được
sinh tạo.

Shayne Longpre, Yi Lu, Zhucheng Tu, và Chris
DuBois. 2019. Một khám phá về tăng cường dữ liệu
và các kỹ thuật lấy mẫu cho hỏi đáp không phụ thuộc
miền. Trong Proceedings of the 2nd Workshop on
Machine Reading for Question Answering, trang
220–227, Hong Kong, China. Association for
Computational Linguistics.

Luis Enrico Lopez, Diane Kathryn Cruz, Jan Chris-
tian Blaise Cruz, và Charibeth Ko Cheng. 2020.
Sinh tạo câu hỏi đầu cuối đến cuối dựa trên transformer.
ArXiv, abs/2005.01107.

Dheeraj Mekala, Tu Vu, Timo Schick, và Jingbo Shang.
2022. Tận dụng các tập dữ liệu QA để cải thiện tăng
cường dữ liệu sinh tạo. Trong Proceedings of the 2022
Conference on Empirical Methods in Natural Language
Processing, trang 9737–9750, Abu Dhabi, United
Arab Emirates. Association for Computational Lin-
guistics.

John Miller, Karl Krauth, Benjamin Recht, và Ludwig
Schmidt. 2020. Hiệu ứng của dịch chuyển phân phối
tự nhiên đối với các mô hình hỏi đáp.

Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, và
Percy Liang. 2016. SQuAD: 100,000+ câu hỏi cho
hiểu biết máy về văn bản. Trong Proceedings of the
2016 Conference on Empirical Methods in Natural
Language Processing, trang 2383–2392, Austin,
Texas. Association for Computational Linguistics.

Alan Ramponi và Barbara Plank. 2020. Thích ứng miền
không giám sát neural trong NLP—Một khảo sát.
Trong Proceedings of the 28th International Conference
on Computational Linguistics, trang 6838–6855,
Barcelona, Spain (Online). International Committee
on Computational Linguistics.

Siamak Shakeri, Cicero Nogueira dos Santos, Henry
Zhu, Patrick Ng, Feng Nan, Zhiguo Wang, Ramesh
Nallapati, và Bing Xiang. 2020. Sinh tạo dữ liệu
tổng hợp đầu cuối đến cuối cho thích ứng miền của
các hệ thống hỏi đáp. arXiv preprint
arXiv:2010.06028.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
Martinet, Marie-Anne Lachaux, Timothée Lacroix,
Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal
Azhar, Aurelien Rodriguez, Armand Joulin, Edouard
Grave, và Guillaume Lample. 2023. Llama: Các mô
hình ngôn ngữ nền tảng mở và hiệu quả.

Xuezhi Wang, Haohan Wang, và Diyi Yang. 2022.
Đo lường và cải thiện độ bền trong các mô hình NLP:
Một khảo sát. Trong Proceedings of the 2022 Conference
of the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, trang 4569–4586, Seattle, United States.
Association for Computational Linguistics.

Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin
Guu, Adams Wei Yu, Brian Lester, Nan Du, An-
drew M. Dai, và Quoc V. Le. 2022. Các mô hình
ngôn ngữ được tinh chỉnh là các học viên zero-shot.

Zhenrui Yue, Bernhard Kratzwald, và Stefan Feuer-
riegel. 2021. Thích ứng miền tương phản cho hỏi
đáp sử dụng các corpus văn bản hạn chế. arXiv
preprint arXiv:2108.13854.

Zhenrui Yue, Huimin Zeng, Ziyi Kou, Lanyu Shang, và
Dong Wang. 2022. Thích ứng miền cho hỏi đáp
thông qua phân loại câu hỏi. arXiv preprint
arXiv:2209.04998.

--- TRANG 6 ---
Câu hỏi Thường gặp (FAQs)
✽Chúng tôi lấy mẫu câu hỏi như thế nào để sinh
tạo các đoạn văn?
➠Một câu hỏi được lấy mẫu cho mỗi ngữ cảnh trong
tập dữ liệu SQUAD gốc để điều kiện hóa việc sinh
tạo đoạn văn.

✽Tại sao chúng tôi không sinh tạo ngữ cảnh mới
từ đầu?
➠Điều này được thực hiện để tạo ra các tập dữ liệu
nhất quán về chủ đề, và chạy một thí nghiệm có
kiểm soát nơi chỉ xác định liệu các ngữ cảnh được
sinh tạo bởi LLM có cung cấp đa dạng ngôn ngữ
và phong cách hay không.

✽Tại sao chúng tôi không nhắc nhở GPT-3/3.5/4
sinh tạo các cặp QA cũng như?
➠Trong các nỗ lực của chúng tôi để làm điều này,
chúng tôi nhận ra rằng các lời nhắc GPT không sinh
tạo ra các đầu ra giữ được tính trung thực với bản
chất trích xuất của tập dữ liệu SQUAD. Hơn nữa,
chúng tôi muốn hạn chế việc sử dụng API của
chúng tôi.

--- TRANG 7 ---
A Phụ lục: Ví dụ Sinh tạo
Phần này cung cấp tài liệu bổ sung dưới dạng các ví dụ bổ sung để tăng cường sự hiểu biết của người đọc về các khái niệm được trình bày trong công việc này.

[THIS IS TABLE: Contains multiple examples showing Original Context, Sampled Question, Prompt, Generated Context, and Generated Questions. The table shows 4 detailed examples about American Bison, Punjab's festival, Canadian police, and Archean era. Each example demonstrates the generation process from original context to final generated Q&A pairs.]

Bảng 4: Ví dụ #1 – Sinh tạo Ngữ cảnh, Câu hỏi, và Trả lời.

[Additional examples continue in similar format for tables 5, 6, and 7, covering topics about Punjab's festival, Canadian police history, and the Archean era respectively]

# 2402.03628.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/agent/2402.03628.pdf
# File size: 2621141 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Professional Agents - Evolving Large Language Models into Autonomous
Experts with Human-Level Competencies
Zhixuan Chu1Yan Wang1Feng Zhu1Lu Yu1Longfei Li1Jinjie Gu1
Abstract
The advent of large language models (LLMs)
such as ChatGPT, PaLM, and GPT-4 has cat-
alyzed remarkable advances in natural language
processing, demonstrating human-like language
fluency and reasoning capacities. This posi-
tion paper introduces the concept of Professional
Agents (PAgents), an application framework har-
nessing LLM capabilities to create autonomous
agents with controllable, specialized, interactive,
and professional-level competencies. We posit
that PAgents can reshape professional services
through continuously developed expertise. Our
proposed PAgents framework entails a tri-layered
architecture for genesis, evolution, and synergy: a
base tool layer, a middle agent layer, and a top syn-
ergy layer. This paper aims to spur discourse on
promising real-world applications of LLMs. We
argue the increasing sophistication and integra-
tion of PAgents could lead to AI systems exhibit-
ing professional mastery over complex domains,
serving critical needs, and potentially achieving
artificial general intelligence.
1. Introduction
The emergence of large language models (LLMs) such as
GPT-3 (Brown et al., 2020), PaLM (Chowdhery et al., 2023),
and ChatGPT signifies a pivotal milestone in the advance-
ment of artificial intelligence. These models leverage the
sheer scale of data and computational power to display im-
pressive language fluency, textual cohesion, and logical rea-
soning capabilities (Chu et al., 2023b; Wang et al., 2023e;
Chu et al., 2024; Jin et al., 2023; Xue et al., 2023a). LLMs
can craft high-quality long-form text, hold conversations,
translate between languages, comprehend and respond to
queries, summarize lengthy documents, and even generate
code based on textual descriptions (Ouyang et al., 2022; Jiao
et al., 2023; Kirk et al., 2023). The incremental improve-
1Ant Group, Hangzhou, China. Correspondence to: <chuzhix-
uan.czx, luli.wy, zhufeng.zhu, bruceyu.yl, longyao.llf, jin-
jie.gujj@antgroup.com >.ment displayed with each successive LLM model release
validates the potential as a viable path forward for artificial
general intelligence (AGI).
Essentially, they display signs of understanding natural lan-
guage, mimicking capacities once considered exclusive to
human intelligence. Therefore, some academics envision
a future where they parallel or even surpass human apti-
tude across numerous cognitive tasks (Santacroce et al.,
2023; Lee et al., 2023). Some theorists speculate that ade-
quately advanced LLMs could autonomously persist self-
improvement, acquiring greater-than-human reasoning and
communication skills through an iterative process of self-
updating their parameters by ingesting more information
(Aksitov et al., 2023; To et al., 2023; Pang et al., 2023; Yuan
et al., 2024). It is worth exploring that LLMs can demon-
strate abilities similar to or exceeding humans in different
vertical areas (Liu et al., 2023b; Wang et al., 2019; 2023h;
Chu et al., 2023a). Additionally, the forms in which LLMs
will manifest such capabilities merit further investigation.
Agents, defined as artificial intelligence systems capable of
autonomous planning and action to achieve specified goals,
have long shown promise as a pathway to achieving artificial
general intelligence (Devidze et al., 2021; Sun et al., 2023;
Yang et al., 2020). The capability of agents to self-direct
their planning and learning processes based on high-level
objectives is what may ultimately enable AGI (Gou et al.,
2023; Wang et al., 2023g; Peng et al., 2023). This would
allow an intelligent agent to adaptively acquire the vast ar-
ray of skills and knowledge displayed by human experts in
fields like science, engineering, medicine, commerce, and
more (Zhang et al., 2023c; Nijkamp et al., 2022; Zhou et al.,
2023). With enough learning over time and experience,
agents could match or surpass the best human specialists.
The advent of agents with human and super-human level
AGI promises to transform professional services in revolu-
tionary ways. Intelligent agents could take on many of the
analytical, creative, and decision-making duties currently
performed by people (Ouyang & Li, 2023; Xue et al., 2023b;
Chen et al., 2023c; Guan et al., 2023). This may greatly
expand the capacities of companies and industries, allow-
ing them to operate with unprecedented speed, quality, and
scope of services. Agents with AGI therefore have immensearXiv:2402.03628v1  [cs.CL]  6 Feb 2024

--- PAGE 2 ---
Professional Agents
potential economic and societal impact.
In conclusion, we put forward Professional Agents (PA-
gents) as a promising pathway for achieving artificial gen-
eral intelligence in the real world, which autonomously
constructs and evolves agents to acquire and demonstrate
professional-level competencies. It has a sophisticated tri-
layered framework including the base tool layer, middle
agent layer, and top synergy layer. PAgents are initialized
according to the specified “gene”, such as professional role,
key tasks, and responsibilities, relevant datasets and cor-
pora, as well as specifics of the knowledge domain. Then,
they can constantly evolve by self-evolution, coevolution,
human feedback evolution, gene refinement, and guidance
from superstratum PAgents. Finally, groups of PAgents can
synergistically collaborate by forming multi-agent systems
that leverage individual strengths, account for conflicts, and
work interdependently towards common goals in shared en-
vironments. Overall, the development of PAgents promises
to push LLMs to new frontiers in replicating multifaceted
human intelligence.
2. Agent Examples
This section will delve into a selection of existing agents,
highlighting how each exemplifies core capabilities that
contribute to the broader vision of professional agents.
AutoGen (Wu et al., 2023) is a generalized multi-agent
conversation framework. Crucially, all agents are made
conversable - they can receive, react to, and respond to
messages. When configured properly, agents can have multi-
turn conversations with minimal human input, enabling
both automation and human agency. AutoGen can use a
“conversation programming” paradigm to unify complex
LLM workflows as agent interactions.
AppAgent (Yang et al., 2023) is a framework designed to
operate smartphone apps like human users. It learns by first
exploring apps on its own, interacting through predefined
actions, and learning from the outcomes. These interactions
are documented, helping AppAgent navigate the apps. This
autonomous learning process can be sped up by observing
some human demonstrations. After this exploration, AppA-
gent can consult the documentation to operate apps based on
their current state, without needing extensive app-specific
training data or adapting language model parameters.
MetaGPT (Hong et al., 2023a) is a meta-programming
framework for multi-agent collaboration. A key innovation
of MetaGPT is integrating human-like workflows through-
out its design, which significantly enhances robustness and
reduces unproductive agent interactions. It encodes Stan-
dardized Operating Procedures into prompt sequences for
more streamlined collaboration between agents with human-
like domain expertise. This allows agents to verify interme-
diate results and reduce errors.ModelScope-Agent (Li et al., 2023a) is designed for easy
integration with model APIs and common APIs, offering
a streamlined approach for leveraging AI. It offers a de-
fault tool library that accommodates a wide range of AI
model APIs in domains such as natural language processing,
computer vision, audio, and multi-modal fields, alongside
extensive common APIs like search engines. Users can
also add their custom API plugins and utilize an automatic
retrieval system from the extensive tool library.
AutoAgents (Chen et al., 2023b) is designed to create and
manage a team of specialized AI agents to execute diverse
tasks effectively. The framework emphasizes continuous
self-improvement of individual agents as well as joint en-
hancement to foster skill development and facilitate knowl-
edge transfer within the team. It also introduces an Action
Observer, an agent responsible for facilitating the effec-
tive distribution of tasks, information exchange, decision-
making, and adaptation to dynamic environments.
OpenAgents (Xie et al., 2023) is an open-source platform
designed to bridge the gap between language agents and ev-
eryday users. It comprises three specialized agents: a Data
Agent for Python and SQL data analysis, a plugin agent
hosting over 200 API tools, and a Web Agent designed for
autonomous web surfing. The platform caters to both gen-
eral users and developers, furnishing a user-friendly web
interface that allows non-experts to leverage agent function-
alities without programming skills.
ChatDev (Qian et al., 2023) is a virtual assistant modeled
after the traditional waterfall development method. It or-
chestrates the workflow through four distinct phases: de-
sign, coding, testing, and documentation. These phases are
managed by “software agents”, simulating roles such as
programmers and testers, who collaborate through dialogue.
AGENTVERSE (Chen et al., 2023d) is a general multi-
agent framework to simulate human group problem-solving
and dynamically adjust group composition in response to on-
going progress. It divides the problem-solving process into
four key stages: expert recruitment, collaborative decision-
making, action execution, and evaluation. This allows for
iterative refinement based on feedback.
While these examples showcase preliminary implementa-
tions of professional agents, they demonstrate the types of
capabilities and basic architecture. The next section will
summarize key features and gaps seen across these exam-
ples to construct a comprehensive framework for developing
full-fledged professional agents.
3. Framework of Professional Agents
The professional agent stands as a pioneering innovation in
the realm of artificial intelligence, purpose-built to emulate
the remarkable abilities of human professionals in contin-

--- PAGE 3 ---
Professional Agents
Base ToolLayer
Top Synergy Layer
Self Evolution
Evolution Pattern
Evolution DirectionAgentGeneCoevolution Gene Refinement Human Guidance KnowledgeCapabilityOne-by-One
Superstratum Guidance
Basic ToolsDeveloper ToolsKnowledgeable ToolsQuery-based ToolsAI-based Tools Top-downPerception
BrainActionRole
Environmental         Input
Tool Invoke
Text DialogueEmbodiment…
Agent
ProfessionTaskDomain
Teach
Teach
Collaboration
ToolTrustworthinessMiddle Agent Layer
NewGene
Learning ToolsInvoking ToolsCreating Tools
ControllabilityExplainabilityRobustness
Multi-ModelKnowledge FusionKnowledge Graph
AdaptationSkills
SpecialtyFeedbackOutput
Person
Assign TasksOutput
Tool LibraryOutputCapability
MemoryConversationPlanningReasoning
Embedding…
Figure 1. The standard PAgent has a general framework, i.e., a sophisticated tri-layered framework. Specifically, individual PAgent
features a modular architecture consisting of role, perception, brain, and action components.
uous learning and adaptability. As shown in Figure 1, the
standard PAgent has a general framework, i.e., a sophisti-
cated tri-layered framework :
•Base Tool Layer : This foundational layer provides a
wide range of state-of-the-art technologies, spanning
basic utilities, developer resources, knowledge reposi-
tories, search capabilities, and AI systems. This diverse
set of tools lays the groundwork for the infrastructure,
facilitating the emergence and continuous improve-
ment of skilled agents.
•Middle Agent Layer : There is a diverse collection of
independent, controllable, interactive, specialized pro-
fessional agents. Each PAgent embodies a particular
professional role and the key competencies needed to
fulfill that role effectively.
•Top Synergy Layer : This is a harmonious fusion of in-
dividual professional agents into an integrated network.
In concert, these agents pool their expertise to address
multifaceted tasks, emulating the cooperation inherent
in human professional groups. They dynamically allo-
cate tasks, adjusting fluidly to the varying complexity
and contextual demands that arise.
4. Components of PAgents
Professional agents are artificial intelligence systems de-
signed to acquire specialized expertise and demonstrate
professional-level competencies like human professionals.
The representative professional agents have four modules,
i.e.,Role ,Perception ,Brain , and Action .4.1. Role
The role module is a key component of the PAgent that de-
fines the professional identity and capabilities that the agent
will develop. The role module specifies metadata such as
the profession, specialty, skills, credentials, and experiences
of the agent. This foundational information guides the de-
velopment and bounded growth of the perception, brain, and
action modules. The role module connects to the percep-
tionmodule by indicating the forms of sensory inputs that
are relevant to the profession. To guide the brain module,
the role module translates professional competencies into
concrete learning goals and curricula. A software engineer
role module may decompose broad engineering capabilities
into discrete modules focused on programming languages,
debugging skills, framework knowledge, communication
protocols, design methodologies, and more. The brain mod-
ule leverages these curricular signals to focus its acquisition
and reinforcement of the prescribed knowledge and skills.
For the action module, the role module characterizes appro-
priate behavioral patterns. By internalizing role directives,
the action module gains purposeful direction to expand its
tools to fulfill professional demands. The role module con-
nects the PAgent architecture into an integrated system for
actualizing specialized expertise.
4.2. Perception
The perception module is responsible for ingesting and en-
coding multimodal professional data that the PAgent re-
ceives as inputs. This module allows the PAgent to perceive

--- PAGE 4 ---
Professional Agents
complex real-world professional scenarios across diverse do-
mains through multiple data formats including text, images,
audio, and video. Specifically, the perception module con-
sists of advanced encoders tailored to each modality: Text
Encoder, Image Encoder, Audio Encoder, Video Encoder,
and so on. Through these tailored encoders, the perception
module can interpret complex real-world professional data
into structured representations that the brain module can
readily comprehend and process to make intelligent deci-
sions. In the following section, we will introduce how to
enable our PAgent to acquire multimodal perception capa-
bilities for textual input, visual input, and auditory input.
4.2.1. T EXTUAL INPUT
Similar to humans, an agent powered by a LLM primarily
relies on text to transmit data, information, and knowledge.
The PAgent, built on LLMs, fundamentally communicates
with humans through text input and output. However, un-
derstanding the implicit meanings in certain texts remains a
significant challenge for LLM-based agents, as these sub-
tleties can be difficult to interpret. Some existing works
(Christiano et al., 2017; Basu et al., 2018; Sumers et al.,
2021; Lin et al., 2022) have attempted to address this issue
to learn the implied meanings from textual feedback. The
user’s preferences can be inferred to enable the agent to
deliver more tailored and precise responses.
4.2.2. V ISUAL INPUT
As a language, LLMs have shown their outstanding capa-
bility in understanding languages (Achiam et al., 2023) and
conversations (Lu et al., 2020). However, some of the ex-
isting LLM-based agents still lack a transformation ability
from images to textual content. Images from the agent’s
surroundings always contain a wealth of information about
objects, spatial relationships, layouts, and so on. Therefore,
integrating the image information into our PAgent is the
first step to achieving multimodal perception. The existing
works in this research direction can be generally classified
into three categories: (1) image captioning, (2) image repre-
sentation, and (3) video understanding.
Image Captioning. This is a straightforward way to un-
derstand image inputs, which is applied to generate the
corresponding text descriptions for the images (Vaswani
et al., 2017; Chen et al., 2021; Touvron et al., 2021). One
of the most significant advantages of this approach is that
captions can be easily linked with structured instructions
and fed into the agent. However, it inevitably loses a lot of
potential information during the conversion process (Driess
et al., 2023). Also, based on this approach, the agent may
introduce some biases. Image Representation. Transformers
have been applied in the field of computer vision to represent
images. For example, ViT/VQV AE (Van Den Oord et al.,2017; Dosovitskiy et al., 2020; Mehta & Rastegari, 2021) are
proposed to encode visual information by using transform-
ers. Also, some approaches with pure MLP structures such
as Mlp-mixer (Tolstikhin et al., 2021) achieve the excellent
performance of image representation. Some pre-trained vi-
sual encoders can enhance the agent’s visual perception (Xi
et al., 2023). Video Understanding. Compared with images,
videos add an additional temporal dimension. Therefore, it
is crucial for the agent to recognize the relationships among
a series of continuous image frames. Some existing works
such as Flamingo (Alayrac et al., 2022) tend to ensure a
temporal order when understanding videos. However, these
approaches usually use a masking mechanism and thus they
may restrict the agent’s view and lose some potential image
information.
4.2.3. A UDITORY INPUT
Apart from textual and visual information, auditory infor-
mation is a crucial component of world information as well.
The existing agents tend to use well-established models
(Huang et al., 2023; Ren et al., 2019; Ye et al., 2022) as tools
to receive auditory information. For example, AudioGPT
(Huang et al., 2023) leverages the strengths of advanced
models including FastSpeech (Ren et al., 2019), Gener-
Speech (Ye et al., 2022), Whisper (Ye et al., 2022), and
various others (Kim et al., 2021; Wang et al., 2023i), which
have demonstrated remarkable success in tasks like Text-to-
Speech conversion, Style Transfer, and Speech Recognition.
4.3. Brain
Much like humans, the brain of our PAgent serves as a cen-
tral nucleus driven by an LLM. The brain module enables
PAgents to demonstrate sophisticated cognitive abilities crit-
ical for professional-grade performance. Built upon LLMs,
the brain module encompasses four key capabilities: Con-
versation ,Memory ,Planning , and Reasoning .
4.3.1. C ONVERSATION
With the help of powerful LLMs (Workshop et al., 2022;
Touvron et al., 2023), the PAgent can easily interact with
other agents, i.e., communication among multiple agents.
Also, the LLMs allow users to understand the response and
reaction of the PAgent (Serban et al., 2016; Adiwardana
et al., 2020). The LLMs can provide multi-turn interactive
conversation (Chung et al., 2022; Touvron et al., 2023), high-
quality natural language generation (Bang et al., 2023), and
implication understanding (Shapira et al., 2023) capabilities.
4.3.2. M EMORY
The memory mechanism can store the knowledge learned
from the real world and its historical behaviors, e.g., obser-
vations, thoughts, and actions. Similar to the processes of
human strategy formulation and decision-making, the PA-

--- PAGE 5 ---
Professional Agents
gent also uses its memory mechanism to handle a sequence
of elaborate tasks. The memory mechanism includes the fol-
lowing three parts, i.e., structures, formats, and operations.
•Memory Structures : LLM-based autonomous agents
are designed with memory structures inspired by hu-
man memory processes, as studied in cognitive sci-
ence (Nuxoll & Laird, 2007). These structures (Rana
et al., 2023; Madaan et al., 2022; Modarressi et al.,
2023; Schuurmans, 2023; Zhong et al., 2023; Zhu et al.,
2023b; Shinn et al., 2023) mimic the progression from
sensory memory to short-term memory, and finally to
long-term memory. Short-term memory is reflected
in the transformer architecture’s context window that
temporarily holds input information. Long-term mem-
ory parallels an external storage from which agents can
quickly fetch and use information. The text goes on to
present two memory structures that are modeled after
these short- and long-term human memories.
•Memory Formats : The memory formats for Agents can
be generally classified into the four main categories,
i.e., natural languages, embeddings, databases, and
structured lists (Wang et al., 2023d). The format of
natural languages tends to describe the world knowl-
edge and the agent’s behaviors in raw natural language,
which can be easily understood by LLMs (Shinn et al.,
2023). The format of embeddings tends to store embed-
ding vectors, which can enhance memory retrieval and
reading capabilities (Zhong et al., 2023). The mem-
ory stored in databases allows the agent to manipulate
memories (Hu et al., 2023). As for the final format,
i.e., structured lists, the memory can be conveyed in an
efficient and concise manner, e.g., JSON (Zhu et al.,
2023b; Modarressi et al., 2023).
•Memory Operations : There are three crucial memory
operations for the PAgent, i.e., reading, writing, and
reflection. Memory reading is the ability to extract
meaningful information from memory to assist the
agent’s actions. For example, learning from the previ-
ous actions to achieve similar goals (Zhu et al., 2023b).
Memory writing is used to store information from the
surroundings or the agents in memory, which can han-
dle the problems of memory duplication (Schulman
et al., 2017) and memory overflow (Modarressi et al.,
2023).
4.3.3. P LANNING AND REASONING
Humans tend to apply a kind of heuristic thinking to decon-
struct a complex task into a sequence of subtasks and then
complete the subtasks one by one. Therefore, the planning
and reasoning component of the PAgent’s brain is designed
to perform as humans when faced with an elaborate task.
The mainstreaming planning or reasoning strategies of theagents can be generally classified into two groups: (1) plan-
ning without feedback and (2) planning with feedback.
•Planning without Feedback : In this mode, the PAgent
receives no feedback from users or its historical trials.
This means that the historical actions of PAgent can-
not influence its future planning. Many existing works
are focussing on this mode. Here, we present three
representative strategies, i.e., single-path reasoning,
multi-path reasoning, and external planning. Single-
path reasoning, e.g., Chain of Thought (COT) (Wei
et al., 2022), Zero-shot-COT (Kojima et al.), ReWOO
(Xu et al., 2023), tend to decompose the final task into
several intermediate steps. Multi-path reasoning tends
to decompose a task into a tree-like structure, e.g., Self-
consistent CoT (CoT-SC) (Wang et al., 2022), Tree of
Thoughts (ToT) (Yao et al., 2023), Graph of Thoughts
(GoT) (Besta et al., 2023), and Algorithm of Thoughts
(AoT) (Sel et al., 2023). External planning tends to
leverage external tools to employ efficient search algo-
rithms to identify correct plans, e.g., LLM+P (Liu et al.,
2023a), LLM-DP (Dagan et al., 2023), and CO-LLM
(Zhang et al., 2023b).
•Planning with Feedback : In this mode, the PAgent
can make long-horizon planning to solve complex
tasks by considering users’ or its feedback. According
to the sources of feedback, the existing approaches
can be classified into three categories, i.e., environ-
mental feedback, human feedback, and model feed-
back. Environmental feedback is obtained from the
real world or virtual environment, e.g., thought-act-
observation triplets (ReAct (Yao et al., 2022)), exe-
cution progress&error&verification (V oyager (Wang
et al., 2023a)), scene graph (SayPlan (Rana et al.,
2023)), and planning feedback (LLM-Planner (Song
et al., 2023)). Human feedback can help the PAgent
align with human values and preferences, e.g., Inner
Monologue (Huang et al., 2022). Model feedback is ob-
tained from the agents themselves, which can provide
a kind of self-reflection mechanism, e.g., Self-refine
(Madaan et al., 2023), Self-Check (Miao et al., 2023),
and Reflexion (Shinn et al., 2023).
4.4. Action
The action component of the PAgent is designed to trans-
late decisions into specific outcomes. The action module
enables PAgents to demonstrate sophisticated professional
capabilities by processing inputs received from the percep-
tion and brain modules. In this section, we introduce the
action component from the following three perspectives: (1)
action goal, (2) candidate actions, and (3) action production.
•Action Goal : Action goal is the objective of acting and
it can be classified into different groups, such as task

--- PAGE 6 ---
Professional Agents
completion, communication keeping, and environment
exploration.
•Candidate Actions : These actions are collected into an
action space and can be performed by the PAgent. The
candidate actions can be generally classified into two
groups, i.e., external tools (such as APIs (Chen et al.,
2021; Schick et al., 2023; Li et al., 2023b; Qin et al.,
2023), databases (Hu et al., 2023), and external models
(Zhong et al., 2023)) and internal knowledge (Wang
et al., 2023a; Fischer, 2023).
•Action Production : Unlike conventional LLMs, the
PAgent can take actions with different strategies and
sources, which means that action production should
recollect memory (Park et al., 2023) and follow plans
(Wang et al., 2023f).
5. Architecting Professional Agents
5.1. Genesis
A key aspect of PAgents is the notion of a “gene” which en-
capsulates the core functionality, competencies, and knowl-
edge required for the agent to operate effectively within its
target domain. The gene constitutes descriptors related to
the agent’s professional role, key tasks and responsibilities,
relevant datasets and corpora, as well as specifics of the
knowledge domain. Based on this gene, a PAgent can es-
sentially build itself by initializing its modular components
to align with the specifications set forth. Below is a high-
level Standard Operating Procedure (SOP) or pipeline for
constructing and evolving a PAgent:
•Define the Professional Role : Identify the professional
domain and the specific role the PAgent will fulfill. De-
termine the necessary skills, credentials, experiences,
and professional competencies required for the role.
Create a role module that encapsulates this informa-
tion, using metadata, natural language descriptions,
or executable logic to outline the agent’s professional
identity.
•Develop the Perception Module : Identify the types of
sensory inputs relevant to the professional role, such
as text, images, audio, or video. Implement advanced
encoders tailored to each modality to interpret complex
real-world professional data. Ensure the perception
module can convert the diverse sensory data into struc-
tured representations for further processing.
•Build the Brain Module : Utilize large language models
to facilitate natural language processing, knowledge ac-
quisition, memory, reasoning, and planning. Define the
learning goals and curricula based on the competencies
outlined in the role module. Implement mechanisms
for continuous learning to keep the PAgent up-to-date
with the latest industry knowledge and practices.
•Construct the Action Module : Define the behavioral
patterns required for the professional role, includingtool utilization and potential physical embodiment. In-
tegrate consultation and decision-making abilities to
allow the PAgent to provide expert advice and perform
tasks. Ensure the action module can execute sophisti-
cated tasks, receive feedback, and adapt its strategies
for improved performance.
•Integration and Testing : Integrate the Perception,
Brain, and Action modules into a cohesive system.
Test the PAgent in controlled environments, simulating
real-world professional scenarios to evaluate its perfor-
mance. Use feedback from testing to refine the agent’s
capabilities and address any deficiencies.
•Deployment : Deploy the PAgent in a real-world pro-
fessional setting, initially under supervision to monitor
its performance and impact. Establish protocols for
human-agent interaction, ensuring that the PAgent can
work collaboratively with human professionals.
•Monitoring and Evolution : Continuously monitor the
PAgent’s performance using key performance indi-
cators relevant to the professional domain. Collect
data on the PAgent’s decisions, actions, and learning
progress. Update the role module to reflect changes in
the professional landscape or to expand the PAgent’s
capabilities.
•Continuous Learning and Adaptation : Implement feed-
back loops that allow the PAgent to learn from its
successes and failures. Periodically review the latest
research and technological advancements to update the
PAgent’s modules. Conduct ongoing training and re-
training to ensure the PAgent maintains a high level of
expertise and adapts to new information or procedures.
•Ethical Considerations and Compliance : Ensure that
the PAgent adheres to ethical guidelines and profes-
sional standards specific to the domain it operates in.
Integrate checks and balances to monitor for biases,
errors, and compliance with legal and regulatory re-
quirements.
•Feedback and Iteration : Gather feedback from end-
users and stakeholders to gauge the efficacy and ac-
ceptability of the PAgent. Iterate on the design and
functionalities of the PAgent based on user feedback,
performance metrics, and evolving professional needs.
This SOP is general and should be customized for each
specific implementation of a PAgent. The complexity and
requirements of the process will vary depending on the
professional domain and the intended scope of the PAgent’s
role within that domain.
5.2. Evolution
Realizing an autonomous replication and adaptation agent
requires a sophisticated and dynamic AI architecture that
can evolve, much like a human professional advancing
through different stages of their career. This entails evo-
lution by five key patterns:

--- PAGE 7 ---
Professional Agents
•Self-evolution: The self-evolution capacity of PAgents
relies on memory and learning mechanisms to accumu-
late knowledge and skills from experiences. As they
take on more projects, the PAgents assimilate new in-
formation, tools, and best practices into their structure,
constantly enhancing their competencies. Agents can
refine their skills using three primary methods. Firstly,
they employ memory components to record and re-
call data from past exchanges and guidance for future
actions, especially recalling prior successes when fac-
ing similar objectives, as described by (Wang et al.,
2023c). Secondly, agents evolve autonomously, go-
ing beyond memory to actively modify their aims and
tactics, train based on interactions, and adapt to dy-
namic settings. This evolution is illustrated by (Nasci-
mento et al., 2023) with a self-management protocol
for agent adaptability and by (Zhang et al., 2023a)
with ProAgent, which adjusts strategies in response to
team communications. (Wang et al., 2023b) discusses
a communication approach, utilizing agent dialogues
as training data to enhance agents’ learning beyond
in-context learning or supervised fine-tuning. Lastly,
dynamic generation allows the creation of new agents
as needs arise during operations, providing tailored
solutions to immediate challenges (Chen et al., 2023a).
•Coevolution: PAgents can mutually evolve through col-
laboration with peer agents. As diverse PAgents work
together on complex tasks, they can learn from each
other’s specialized expertise areas, exchange feedback
on effectiveness, and integrate complementary skills.
This coevolution process iterates, allowing the PAgents
to mature rapidly.
•Human-in-the-loop Guidance: Human experts further
guide the development trajectory of PAgents by provid-
ing feedback, corrections, and new knowledge. With
human-in-the-loop supervision, the agents steer their
growth towards configurations that demonstrate higher
quality outcomes and judgment expected by profes-
sionals. The integration of human feedback is crucial
to the PAgent system’s iterative refinement, fostering a
learning loop that benefits from human expertise and
ethical standards. The agents’ decisions and actions are
evaluated by human professionals, ensuring alignment
with human values and professional norms.
•Gene Refinement: The PAgent creators also facili-
tate systematic evolution by revisiting, removing, and
adding new elements to the PAgents’ fundamental
genes. Adjusting the building blocks of their roles,
responsibilities, tools and underlying knowledge do-
mains gives rise to new and improved generations of
PAgents. For example, task expansion needs agents
to absorb or invent new capabilities, thus stretching
to meet the broadening horizons of their roles. Do-
main transfer requires agents to adapt and thrive acrossvarious professional environments.
•Guidance from Superstratum PAgents. Finally, the
network effects produced by interactions between PA-
gents, especially with superstratum PAgents - more se-
nior, vastly experienced agents - multiply their learning
pace. The influx of macro-level guidance, project dele-
gation, and exposure to multifaceted problem-solving
shapes well-rounded, leadership-grade PAgents.
In addition to these five patterns, there are four key direc-
tions for the evolution of capabilities. For the role module,
as PAgents take on more diverse professional tasks across
different domains, the role definitions must evolve to encom-
pass a wider range of capabilities. More complex, multi-
faceted roles will require integrating distinct competencies
and skills tailored to niche specializations. Dynamic role
updating is necessary for flexibly taking on new challenges.
For the perception module, advanced neural perception sys-
tems will empower PAgents to interpret inputs spanning
text, imagery, audio, video, and more. Tailored modality
encoders, developed using cutting-edge machine learning
techniques, will enable nuanced encoding of intricate real-
world data. For the brain module, incorporating mechanisms
for causality, explainability, controllability, safety, accuracy,
robustness, and ethical alignment will be critical for estab-
lishing trustworthiness (Chu et al., 2023c; Guo et al., 2023;
Li & Chu, 2023; Zhu et al., 2023a; Chu et al., 2021). Ex-
ternal auditing of reasoning, allowing human override of
decisions, sensitivity analysis, adversarial testing, and align-
ment techniques can help assure reliable and ethical intelli-
gent behavior. For the action module, just as technological
innovations have historically expanded human potential, the
PAgent system maintains its professional agents at the cut-
ting edge by integrating the latest AI methodologies and
tools. This paves the way for more sophisticated forms of
analysis, inference, and strategic planning.
5.3. Multi-agent Synergy
The development of a single agent usually sticks to its profile
and excels at specialized skills (Sumers et al., 2023). Such
design gives them the professional ability to react to their
surroundings according to particular internal settings. In
contrast, an LLM-based Multi-Agent System (LLM-MAS)
(Dorri et al., 2018) consists of multiple agents that can col-
laborate to accomplish a common or conflicting goal in
the sharing environment. In comparison to conventional
single-agent systems, multi-agent systems have several mer-
its. Primarily, they excel in scalability, enabling them to
tackle intricate tasks more effectively. Secondly, their in-
herent resilience allows them to withstand the malfunction-
ing or failure of individual components without collapsing.
Lastly, by leveraging the distinct strengths and differences
among agents, these systems can optimize problem-solving
processes and enhance efficiency.

--- PAGE 8 ---
Professional Agents
The above benefits make us believe that connecting the sin-
gle PAgent to establish a Multi-PAgent System (MPAS) can
extend the scope of capabilities for users to accomplish more
complicated problems. Despite the advantages, we should
pay attention to the challenges coexisted with the opportu-
nities. First and foremost, the increasing number of agents
raises great challenges in controlling them to communicate
with each other to complete the given goal. In addition,
the tasks allocated to the agent might have conflicts with
each other, which needs careful design on how to coordinate
them. Finally, agents may be required to adapt to learn from
the dynamic environments. If we can appropriately handle
the challenges, multiple agents offer a powerful approach to
solving complex tasks.
Here, we clarify how communication is organized to coor-
dinate different agents (Guo et al., 2024). Analogous with
the other multi-agent systems, the essence of MPAS lies
in fostering effective communication among agents. We
explore this aspect through three lenses: (1) Communica-
tion Approaches , which delves into the diverse manners and
techniques employed by agents to communicate with one an-
other; (2) Communication Network Organization , focusing
on how the communication network within a multi-agent
system is structured and designed for smooth information
flow; (3) Agent Message Exchange , referring to the informa-
tion being shared between agents during their interactions,
which forms a cornerstone of their collaborative efforts.
•Communication Approaches: Presently, the predomi-
nant frameworks for interaction within LLM-MA sys-
tems are categorized as Cooperative ,Debate , and Com-
petitive models. In the Cooperative model, agents col-
laborate and aim for a common purpose or targets,
sharing information to improve the overall outcome.
When agents partake in discussions involving critical
exchanges, the Debate model comes into play, where
they advocate for and defend their individual perspec-
tives or proposals, while also evaluating and challeng-
ing those of their peers. This approach is particularly
effective for forging agreement or enhancing a solution.
In the competitive model, agents pursue their objec-
tives, which may not align and could potentially clash
with the aspirations of other participants.
•Communication Network Organization: Apart from
the communication approaches, the way to organize
the agents directly has an impact on communication
efficiency and performance. Generally speaking, the
communication architecture mainly includes a hierar-
chical layer, ego-network with a central master node,
decentralized network, and shared message pool. In a
hierarchical layered system, agents are organized by
tiers, each playing specific roles and interacting mostly
within their level or with those immediately above orbelow. The Dynamic LLM-Agent Network (DyLAN),
as presented by (Liu et al., 2023c), arranges agents
across multiple layers in a directed feed-forward archi-
tecture. This enables dynamic exchanges with capabil-
ities such as on-the-fly agent choice and an early termi-
nation feature to improve collaborative effectiveness.
Meanwhile, decentralized communication is character-
ized by a direct, peer-to-peer dialogue among agents.
In contrast, centralized ego-network communication
revolves around one or several pivotal agents orches-
trating the network’s interactions, in which subsidiary
agents are linked through a core hub. To elevate com-
munication efficacy, MetaGPT (Hong et al., 2023b)
introduces a shared message pool. In this system, a
universal pool of messages is maintained for agents to
post updates and subscribe to messages, through which
the communication process flows back and forth.
•Agent Message Exchange: In the arena of LLM-MA
systems, textual data is commonly the vehicle for con-
veying messages. This textual data is diverse and tai-
lored to suit the needs of the specific use case. For
instance, within the software creation sphere, agents
often exchange insights related to blocks of code. Con-
versely, during game simulations such as those based
on Werewolf, dialogue between agents may revolve
around their deductive reasoning, doubts they harbor,
or planned methodologies. Expanding upon this, it’s
conceivable that in more nuanced applications, agents
might also share semantic cues or emotional intent
through text, which could be critical in contexts like
customer service or interactive storytelling, where un-
derstanding sentiment and context is paramount.
6. Discussion
This position paper introduces the concept of Professional
Agents (PAgents), an application framework that harnesses
the capabilities of large language models to create au-
tonomous agents with specialized expertise. The genesis,
evolution, and multi-agent synergy aspects offer a pipeline
for constructing PAgents that can replicate and exceed
human-level expertise through continuous learning. How-
ever, there remain significant research challenges to fully
realizing professional mastery in PAgents across complex
vocations. Key limitations include sample inefficiency in
learning, brittleness when operating outside training dis-
tributions, insufficient reasoning abilities for multifaceted
tasks, expressing complex motor skills for physical embod-
iment, and difficulty ensuring human-aligned behavior as
agent capabilities grow. Mitigating these issues to create in-
creasingly capable, safe, and robust PAgents will necessitate
innovations in prompt engineering, simulator design, mem-
ory architectures, model training techniques, explainability
methods, and policy learning algorithms.

--- PAGE 9 ---
Professional Agents
References
Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I.,
Aleman, F. L., Almeida, D., Altenschmidt, J., Altman, S.,
Anadkat, S., et al. Gpt-4 technical report. arXiv preprint
arXiv:2303.08774 , 2023.
Adiwardana, D., Luong, M.-T., So, D. R., Hall, J., Fiedel,
N., Thoppilan, R., Yang, Z., Kulshreshtha, A., Nemade,
G., Lu, Y ., et al. Towards a human-like open-domain
chatbot. arXiv preprint arXiv:2001.09977 , 2020.
Aksitov, R., Miryoosefi, S., Li, Z., Li, D., Babayan, S., Kop-
parapu, K., Fisher, Z., Guo, R., Prakash, S., Srinivasan,
P., Zaheer, M., Yu, F. X., and Kumar, S. Rest meets react:
Self-improvement for multi-step reasoning LLM agent.
CoRR , abs/2312.10003, 2023.
Alayrac, J.-B., Donahue, J., Luc, P., Miech, A., Barr, I.,
Hasson, Y ., Lenc, K., Mensch, A., Millican, K., Reynolds,
M., et al. Flamingo: a visual language model for few-shot
learning. Advances in Neural Information Processing
Systems , 35:23716–23736, 2022.
Bang, Y ., Cahyawijaya, S., Lee, N., Dai, W., Su, D., Wilie,
B., Lovenia, H., Ji, Z., Yu, T., Chung, W., et al. A multi-
task, multilingual, multimodal evaluation of chatgpt on
reasoning, hallucination, and interactivity. arXiv preprint
arXiv:2302.04023 , 2023.
Basu, C., Singhal, M., and Dragan, A. D. Learning from
richer human guidance: Augmenting comparison-based
learning with feature queries. In Proceedings of the 2018
ACM/IEEE International Conference on Human-Robot
Interaction , pp. 132–140, 2018.
Besta, M., Blach, N., Kubicek, A., Gerstenberger, R., Gi-
aninazzi, L., Gajda, J., Lehmann, T., Podstawski, M.,
Niewiadomski, H., Nyczyk, P., et al. Graph of thoughts:
Solving elaborate problems with large language models.
arXiv preprint arXiv:2308.09687 , 2023.
Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan,
J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,
Askell, A., Agarwal, S., Herbert-V oss, A., Krueger, G.,
Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu,
J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M.,
Gray, S., Chess, B., Clark, J., Berner, C., McCandlish,
S., Radford, A., Sutskever, I., and Amodei, D. Language
models are few-shot learners. In Advances in Neural In-
formation Processing Systems 33: Annual Conference on
Neural Information Processing Systems 2020, NeurIPS
2020, December 6-12, 2020, virtual , 2020.
Chen, G., Dong, S., Shu, Y ., Zhang, G., Sesay, J., Karlsson,
B. F., Fu, J., and Shi, Y . Autoagents: A framework
for automatic agent generation. ArXiv , abs/2309.17288,
2023a.Chen, G., Dong, S., Shu, Y ., Zhang, G., Sesay, J., Karls-
son, B. F., Fu, J., and Shi, Y . Autoagents: A frame-
work for automatic agent generation. arXiv preprint
arXiv:2309.17288 , 2023b.
Chen, J., Guo, H., Yi, K., Li, B., and Elhoseiny, M. Visual-
gpt: Data-efficient image captioning by balancing visual
input and linguistic knowledge from pretraining. 2021.
Chen, L., Zhang, Y ., Ren, S., Zhao, H., Cai, Z., Wang, Y .,
Wang, P., Liu, T., and Chang, B. Towards end-to-end em-
bodied decision making via multi-modal large language
model: Explorations with gpt4-vision and beyond. CoRR ,
abs/2310.02071, 2023c.
Chen, W., Su, Y ., Zuo, J., Yang, C., Yuan, C., Qian, C., Chan,
C.-M., Qin, Y ., Lu, Y ., Xie, R., et al. Agentverse: Facili-
tating multi-agent collaboration and exploring emergent
behaviors in agents. arXiv preprint arXiv:2308.10848 ,
2023d.
Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra,
G., Roberts, A., Barham, P., Chung, H. W., Sutton,
C., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko,
S., Maynez, J., Rao, A., Barnes, P., Tay, Y ., Shazeer,
N., Prabhakaran, V ., Reif, E., Du, N., Hutchinson, B.,
Pope, R., Bradbury, J., Austin, J., Isard, M., Gur-Ari,
G., Yin, P., Duke, T., Levskaya, A., Ghemawat, S., Dev,
S., Michalewski, H., Garcia, X., Misra, V ., Robinson,
K., Fedus, L., Zhou, D., Ippolito, D., Luan, D., Lim,
H., Zoph, B., Spiridonov, A., Sepassi, R., Dohan, D.,
Agrawal, S., Omernick, M., Dai, A. M., Pillai, T. S., Pel-
lat, M., Lewkowycz, A., Moreira, E., Child, R., Polozov,
O., Lee, K., Zhou, Z., Wang, X., Saeta, B., Diaz, M.,
Firat, O., Catasta, M., Wei, J., Meier-Hellstern, K., Eck,
D., Dean, J., Petrov, S., and Fiedel, N. Palm: Scaling
language modeling with pathways. J. Mach. Learn. Res. ,
24:240:1–240:113, 2023.
Christiano, P. F., Leike, J., Brown, T., Martic, M., Legg,
S., and Amodei, D. Deep reinforcement learning from
human preferences. Advances in neural information pro-
cessing systems , 30, 2017.
Chu, Z., Rathbun, S. L., and Li, S. Graph infomax ad-
versarial learning for treatment effect estimation with
networked observational data. In Proceedings of the 27th
ACM SIGKDD Conference on Knowledge Discovery &
Data Mining , pp. 176–184, 2021.
Chu, Z., Guo, H., Zhou, X., Wang, Y ., Yu, F., Chen, H.,
Xu, W., Lu, X., Cui, Q., Li, L., Zhou, J., and Li, S.
Data-centric financial large language models. CoRR ,
abs/2310.17784, 2023a.
Chu, Z., Hao, H., Ouyang, X., Wang, S., Wang, Y ., Shen,
Y ., Gu, J., Cui, Q., Li, L., Xue, S., Zhang, J. Y ., and

--- PAGE 10 ---
Professional Agents
Li, S. Leveraging large language models for pre-trained
recommender systems. CoRR , abs/2308.10837, 2023b.
Chu, Z., Hu, M., Cui, Q., Li, L., and Li, S. Task-driven
causal feature distillation: Towards trustworthy risk pre-
diction. arXiv preprint arXiv:2312.16113 , 2023c.
Chu, Z., Wang, Y ., Cui, Q., Li, L., Chen, W., Li, S., Qin, Z.,
and Ren, K. Llm-guided multi-view hypergraph learning
for human-centric explainable recommendation. CoRR ,
abs/2401.08217, 2024.
Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y .,
Fedus, W., Li, Y ., Wang, X., Dehghani, M., Brahma,
S., et al. Scaling instruction-finetuned language models.
arXiv preprint arXiv:2210.11416 , 2022.
Dagan, G., Keller, F., and Lascarides, A. Dynamic planning
with a llm. arXiv preprint arXiv:2308.06391 , 2023.
Devidze, R., Radanovic, G., Kamalaruban, P., and Singla,
A. Explicable reward design for reinforcement learn-
ing agents. In Advances in Neural Information Process-
ing Systems 34: Annual Conference on Neural Informa-
tion Processing Systems 2021, NeurIPS 2021 , pp. 20118–
20131, 2021.
Dorri, A., Kanhere, S. S., and Jurdak, R. Multi-agent sys-
tems: A survey. IEEE Access , 6:28573–28593, 2018.
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn,
D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M.,
Heigold, G., Gelly, S., et al. An image is worth 16x16
words: Transformers for image recognition at scale. arXiv
preprint arXiv:2010.11929 , 2020.
Driess, D., Xia, F., Sajjadi, M. S., Lynch, C., Chowdhery,
A., Ichter, B., Wahid, A., Tompson, J., Vuong, Q., Yu, T.,
et al. Palm-e: An embodied multimodal language model.
arXiv preprint arXiv:2303.03378 , 2023.
Fischer, K. A. Reflective linguistic programming (rlp): A
stepping stone in socially-aware agi (socialagi). arXiv
preprint arXiv:2305.12647 , 2023.
Gou, Z., Shao, Z., Gong, Y ., Shen, Y ., Yang, Y ., Duan,
N., and Chen, W. CRITIC: large language models
can self-correct with tool-interactive critiquing. CoRR ,
abs/2305.11738, 2023.
Guan, Y ., Wang, D., Chu, Z., Wang, S., Ni, F., Song,
R., Li, L., Gu, J., and Zhuang, C. Intelligent virtual
assistants with llm-based process automation. CoRR ,
abs/2312.06677, 2023.
Guo, D., Chu, Z., and Li, S. Fair attribute comple-
tion on graph with missing attributes. arXiv preprint
arXiv:2302.12977 , 2023.Guo, T., Chen, X., Wang, Y ., Chang, R., Pei, S., Chawla,
N. V ., Wiest, O., and Zhang, X. Large language model
based multi-agents: A survey of progress and challenges.
2024.
Hong, S., Zheng, X., Chen, J., Cheng, Y ., Wang, J., Zhang,
C., Wang, Z., Yau, S. K. S., Lin, Z., Zhou, L., et al.
Metagpt: Meta programming for multi-agent collabora-
tive framework. arXiv preprint arXiv:2308.00352 , 2023a.
Hong, S., Zheng, X., Chen, J. P., Cheng, Y ., Zhang, C.,
Wang, Z., Yau, S. K. S., Lin, Z. H., Zhou, L., Ran,
C., Xiao, L., and Wu, C. Metagpt: Meta program-
ming for multi-agent collaborative framework. ArXiv ,
abs/2308.00352, 2023b.
Hu, C., Fu, J., Du, C., Luo, S., Zhao, J., and Zhao, H.
Chatdb: Augmenting llms with databases as their sym-
bolic memory. arXiv preprint arXiv:2306.03901 , 2023.
Huang, R., Li, M., Yang, D., Shi, J., Chang, X., Ye, Z.,
Wu, Y ., Hong, Z., Huang, J., Liu, J., et al. Audiogpt:
Understanding and generating speech, music, sound, and
talking head. arXiv preprint arXiv:2304.12995 , 2023.
Huang, W., Xia, F., Xiao, T., Chan, H., Liang, J., Florence,
P., Zeng, A., Tompson, J., Mordatch, I., Chebotar, Y ., et al.
Inner monologue: Embodied reasoning through planning
with language models. arXiv preprint arXiv:2207.05608 ,
2022.
Jiao, W., Huang, J., Wang, W., He, Z., Liang, T., Wang, X.,
Shi, S., and Tu, Z. Parrot: Translating during chat using
large language models tuned with human translation and
feedback. In Findings of the Association for Computa-
tional Linguistics: EMNLP 2023, Singapore, December
6-10, 2023 , pp. 15009–15020, 2023.
Jin, M., Wang, S., Ma, L., Chu, Z., Zhang, J. Y ., Shi, X.,
Chen, P.-Y ., Liang, Y ., Li, Y .-F., Pan, S., et al. Time-llm:
Time series forecasting by reprogramming large language
models. arXiv preprint arXiv:2310.01728 , 2023.
Kim, J., Kong, J., and Son, J. Conditional variational au-
toencoder with adversarial learning for end-to-end text-to-
speech. In International Conference on Machine Learn-
ing, pp. 5530–5540. PMLR, 2021.
Kirk, H., Bean, A. M., Vidgen, B., R ¨ottger, P., and Hale,
S. A. The past, present and better future of feedback
learning in large language models for subjective human
preferences and values. In Proceedings of the 2023 Con-
ference on Empirical Methods in Natural Language Pro-
cessing, EMNLP 2023, Singapore, December 6-10, 2023 ,
pp. 2409–2430, 2023.
Kojima, T., Gu, S. S., Reid, M., Matsuo, Y ., and Iwasawa,
Y . Large language models are zero-shot reasoners, 2022.
URL https://arxiv. org/abs/2205.11916 .

--- PAGE 11 ---
Professional Agents
Lee, H., Phatale, S., Mansoor, H., Lu, K., Mesnard, T.,
Bishop, C., Carbune, V ., and Rastogi, A. RLAIF: scaling
reinforcement learning from human feedback with AI
feedback. CoRR , abs/2309.00267, 2023.
Li, C., Chen, H., Yan, M., Shen, W., Xu, H., Wu, Z., Zhang,
Z., Zhou, W., Chen, Y ., Cheng, C., et al. Modelscope-
agent: Building your customizable agent system with
open-source large language models. arXiv preprint
arXiv:2309.00986 , 2023a.
Li, M., Song, F., Yu, B., Yu, H., Li, Z., Huang, F., and Li, Y .
Api-bank: A benchmark for tool-augmented llms. arXiv
preprint arXiv:2304.08244 , 2023b.
Li, S. and Chu, Z. Machine Learning for Causal Inference .
Springer Nature, 2023.
Lin, J., Fried, D., Klein, D., and Dragan, A. Infer-
ring rewards from language in context. arXiv preprint
arXiv:2204.02515 , 2022.
Liu, B., Jiang, Y ., Zhang, X., Liu, Q., Zhang, S., Biswas,
J., and Stone, P. Llm+ p: Empowering large language
models with optimal planning proficiency. arXiv preprint
arXiv:2304.11477 , 2023a.
Liu, Z., Zhang, W., Xia, Y ., Wu, L., Xie, S., Qin, T., Zhang,
M., and Liu, T. Molxpt: Wrapping molecules with text
for generative pre-training. In Proceedings of the 61st
Annual Meeting of the Association for Computational
Linguistics (Volume 2: Short Papers), ACL 2023, Toronto,
Canada , pp. 1606–1616, 2023b.
Liu, Z., Zhang, Y ., Li, P., Liu, Y ., and Yang, D. Dynamic llm-
agent network: An llm-agent collaboration framework
with agent team optimization. ArXiv , abs/2310.02170,
2023c.
Lu, J., Ren, X., Ren, Y ., Liu, A., and Xu, Z. Improv-
ing contextual language models for response retrieval
in multi-turn conversation. In Proceedings of the 43rd
International ACM SIGIR Conference on Research and
Development in Information Retrieval , pp. 1805–1808,
2020.
Madaan, A., Tandon, N., Clark, P., and Yang, Y . Memory-
assisted prompt editing to improve gpt-3 after deployment.
arXiv preprint arXiv:2201.06009 , 2022.
Madaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao,
L., Wiegreffe, S., Alon, U., Dziri, N., Prabhumoye, S.,
Yang, Y ., et al. Self-refine: Iterative refinement with
self-feedback. arXiv preprint arXiv:2303.17651 , 2023.
Mehta, S. and Rastegari, M. Mobilevit: light-weight,
general-purpose, and mobile-friendly vision transformer.
arXiv preprint arXiv:2110.02178 , 2021.Miao, N., Teh, Y . W., and Rainforth, T. Selfcheck: Using
llms to zero-shot check their own step-by-step reasoning.
arXiv preprint arXiv:2308.00436 , 2023.
Modarressi, A., Imani, A., Fayyaz, M., and Sch ¨utze, H. Ret-
llm: Towards a general read-write memory for large lan-
guage models. arXiv preprint arXiv:2305.14322 , 2023.
Nascimento, N. M., Alencar, P., and Cowan, D. D. Self-
adaptive large language model (llm)-based multiagent
systems. 2023 IEEE International Conference on Auto-
nomic Computing and Self-Organizing Systems Compan-
ion (ACSOS-C) , pp. 104–109, 2023.
Nijkamp, E., Ruffolo, J., Weinstein, E. N., Naik, N., and
Madani, A. Progen2: Exploring the boundaries of protein
language models. CoRR , abs/2206.13517, 2022.
Nuxoll, A. M. and Laird, J. E. Extending cognitive archi-
tecture with episodic memory. In AAAI , pp. 1560–1564,
2007.
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright,
C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K.,
Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L.,
Simens, M., Askell, A., Welinder, P., Christiano, P. F.,
Leike, J., and Lowe, R. Training language models to
follow instructions with human feedback. In Advances
in Neural Information Processing Systems 35: Annual
Conference on Neural Information Processing Systems
2022, NeurIPS 2022, New Orleans, LA, USA, November
28 - December 9, 2022 , 2022.
Ouyang, S. and Li, L. Autoplan: Automatic planning of
interactive decision-making tasks with large language
models. In Findings of the Association for Computational
Linguistics: EMNLP 2023, Singapore, December 6-10,
2023 , pp. 3114–3128, 2023.
Pang, J., Wang, P., Li, K., Chen, X., Xu, J., Zhang, Z., and
Yu, Y . Language model self-improvement by reinforce-
ment learning contemplation. CoRR , abs/2305.14483,
2023.
Park, J. S., O’Brien, J., Cai, C. J., Morris, M. R., Liang,
P., and Bernstein, M. S. Generative agents: Interactive
simulacra of human behavior. In Proceedings of the 36th
Annual ACM Symposium on User Interface Software and
Technology , pp. 1–22, 2023.
Peng, S., Hu, X., Yi, Q., Zhang, R., Guo, J., Huang, D.,
Tian, Z., Chen, R., Du, Z., Guo, Q., Chen, Y ., and Li,
L. Self-driven grounding: Large language model agents
with automatical language-aligned skill learning. CoRR ,
abs/2309.01352, 2023.
Qian, C., Cong, X., Yang, C., Chen, W., Su, Y ., Xu, J.,
Liu, Z., and Sun, M. Communicative agents for software
development. arXiv preprint arXiv:2307.07924 , 2023.

--- PAGE 12 ---
Professional Agents
Qin, Y ., Liang, S., Ye, Y ., Zhu, K., Yan, L., Lu, Y ., Lin, Y .,
Cong, X., Tang, X., Qian, B., et al. Toolllm: Facilitating
large language models to master 16000+ real-world apis.
arXiv preprint arXiv:2307.16789 , 2023.
Rana, K., Haviland, J., Garg, S., Abou-Chakra, J., Reid, I.,
and Suenderhauf, N. Sayplan: Grounding large language
models using 3d scene graphs for scalable task planning.
arXiv preprint arXiv:2307.06135 , 2023.
Ren, Y ., Ruan, Y ., Tan, X., Qin, T., Zhao, S., Zhao, Z., and
Liu, T.-Y . Fastspeech: Fast, robust and controllable text
to speech. Advances in neural information processing
systems , 32, 2019.
Santacroce, M., Lu, Y ., Yu, H., Li, Y ., and Shen, Y . Effi-
cient RLHF: reducing the memory usage of PPO. CoRR ,
abs/2309.00754, 2023.
Schick, T., Dwivedi-Yu, J., Dess `ı, R., Raileanu, R., Lomeli,
M., Zettlemoyer, L., Cancedda, N., and Scialom, T. Tool-
former: Language models can teach themselves to use
tools. arXiv preprint arXiv:2302.04761 , 2023.
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and
Klimov, O. Proximal policy optimization algorithms.
arXiv preprint arXiv:1707.06347 , 2017.
Schuurmans, D. Memory augmented large language
models are computationally universal. arXiv preprint
arXiv:2301.04589 , 2023.
Sel, B., Al-Tawaha, A., Khattar, V ., Wang, L., Jia, R.,
and Jin, M. Algorithm of thoughts: Enhancing explo-
ration of ideas in large language models. arXiv preprint
arXiv:2308.10379 , 2023.
Serban, I. V ., Lowe, R., Charlin, L., and Pineau, J. Gener-
ative deep neural networks for dialogue: A short review.
arXiv preprint arXiv:1611.06216 , 2016.
Shapira, N., Levy, M., Alavi, S. H., Zhou, X., Choi, Y .,
Goldberg, Y ., Sap, M., and Shwartz, V . Clever hans or
neural theory of mind? stress testing social reasoning in
large language models. arXiv preprint arXiv:2305.14763 ,
2023.
Shinn, N., Cassano, F., Gopinath, A., Narasimhan, K. R.,
and Yao, S. Reflexion: Language agents with verbal
reinforcement learning. In Thirty-seventh Conference on
Neural Information Processing Systems , 2023.
Song, C. H., Wu, J., Washington, C., Sadler, B. M., Chao,
W.-L., and Su, Y . Llm-planner: Few-shot grounded plan-
ning for embodied agents with large language models. In
Proceedings of the IEEE/CVF International Conference
on Computer Vision , pp. 2998–3009, 2023.Sumers, T. R., Ho, M. K., Hawkins, R. D., Narasimhan,
K., and Griffiths, T. L. Learning rewards from linguistic
feedback. In Proceedings of the AAAI Conference on
Artificial Intelligence , volume 35, pp. 6002–6010, 2021.
Sumers, T. R., Yao, S., Narasimhan, K., and Griffiths,
T. L. Cognitive architectures for language agents. ArXiv ,
abs/2309.02427, 2023.
Sun, W., Yan, L., Ma, X., Wang, S., Ren, P., Chen, Z., Yin,
D., and Ren, Z. Is chatgpt good at search? investigating
large language models as re-ranking agents. In Proceed-
ings of the 2023 Conference on Empirical Methods in
Natural Language Processing, EMNLP 2023, Singapore,
December 6-10, 2023 , pp. 14918–14937, 2023.
To, H. Q., Bui, N. D. Q., Guo, J. L. C., and Nguyen,
T. N. Better language models of code through self-
improvement. In Rogers, A., Boyd-Graber, J. L., and
Okazaki, N. (eds.), Findings of the Association for Com-
putational Linguistics: ACL 2023, Toronto, Canada , pp.
12994–13002. Association for Computational Linguistics,
2023.
Tolstikhin, I. O., Houlsby, N., Kolesnikov, A., Beyer, L.,
Zhai, X., Unterthiner, T., Yung, J., Steiner, A., Keysers,
D., Uszkoreit, J., et al. Mlp-mixer: An all-mlp architec-
ture for vision. Advances in neural information process-
ing systems , 34:24261–24272, 2021.
Touvron, H., Cord, M., Douze, M., Massa, F., Sablayrolles,
A., and J ´egou, H. Training data-efficient image transform-
ers & distillation through attention. In International con-
ference on machine learning , pp. 10347–10357. PMLR,
2021.
Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux,
M.-A., Lacroix, T., Rozi `ere, B., Goyal, N., Hambro, E.,
Azhar, F., et al. Llama: Open and efficient foundation lan-
guage models. arXiv preprint arXiv:2302.13971 , 2023.
Van Den Oord, A., Vinyals, O., et al. Neural discrete rep-
resentation learning. Advances in neural information
processing systems , 30, 2017.
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones,
L., Gomez, A. N., Kaiser, Ł., and Polosukhin, I. At-
tention is all you need. Advances in neural information
processing systems , 30, 2017.
Wang, G., Xie, Y ., Jiang, Y ., Mandlekar, A., Xiao, C., Zhu,
Y ., Fan, L., and Anandkumar, A. V oyager: An open-
ended embodied agent with large language models. arXiv
preprint arXiv:2305.16291 , 2023a.
Wang, K., Lu, Y ., Santacroce, M., Gong, Y ., Zhang, C., and
Shen, Y . Adapting llm agents through communication.
ArXiv , abs/2310.01444, 2023b.

--- PAGE 13 ---
Professional Agents
Wang, L., Ma, C., Feng, X., Zhang, Z., ran Yang, H., Zhang,
J., Chen, Z.-Y ., Tang, J., Chen, X., Lin, Y ., Zhao, W. X.,
Wei, Z., and rong Wen, J. A survey on large language
model based autonomous agents. ArXiv , abs/2308.11432,
2023c.
Wang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J.,
Chen, Z., Tang, J., Chen, X., Lin, Y ., et al. A survey on
large language model based autonomous agents. arXiv
preprint arXiv:2308.11432 , 2023d.
Wang, S., Guo, Y ., Wang, Y ., Sun, H., and Huang, J.
SMILES-BERT: large scale unsupervised pre-training
for molecular property prediction. In Proceedings of
the 10th ACM International Conference on Bioinformat-
ics, Computational Biology and Health Informatics, BCB
2019, Niagara Falls, NY, USA , pp. 429–436. ACM, 2019.
Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang,
S., Chowdhery, A., and Zhou, D. Self-consistency im-
proves chain of thought reasoning in language models.
arXiv preprint arXiv:2203.11171 , 2022.
Wang, Y ., Chu, Z., Ouyang, X., Wang, S., Hao, H., Shen, Y .,
Gu, J., Xue, S., Zhang, J. Y ., Cui, Q., Li, L., Zhou, J., and
Li, S. Enhancing recommender systems with large lan-
guage model reasoning graphs. CoRR , abs/2308.10835,
2023e.
Wang, Z., Cai, S., Liu, A., Ma, X., and Liang, Y . Describe,
explain, plan and select: Interactive planning with large
language models enables open-world multi-task agents.
arXiv preprint arXiv:2302.01560 , 2023f.
Wang, Z., Mao, S., Wu, W., Ge, T., Wei, F., and Ji, H.
Unleashing cognitive synergy in large language mod-
els: A task solving agent through multi-persona self-
collaboration. CoRR , abs/2307.05300, 2023g.
Wang, Z., Zhang, Q., Hu, S., Yu, H., Jin, X., Gong, Z., and
Chen, H. Multi-level protein structure pre-training via
prompt learning. In The Eleventh International Confer-
ence on Learning Representations, ICLR 2023, Kigali,
Rwanda . OpenReview.net, 2023h.
Wang, Z.-Q., Cornell, S., Choi, S., Lee, Y ., Kim, B.-Y ., and
Watanabe, S. Tf-gridnet: Integrating full-and sub-band
modeling for speech separation. IEEE/ACM Transactions
on Audio, Speech, and Language Processing , 2023i.
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F.,
Chi, E., Le, Q. V ., Zhou, D., et al. Chain-of-thought
prompting elicits reasoning in large language models.
Advances in Neural Information Processing Systems , 35:
24824–24837, 2022.Workshop, B., Scao, T. L., Fan, A., Akiki, C., Pavlick, E.,
Ili´c, S., Hesslow, D., Castagn ´e, R., Luccioni, A. S., Yvon,
F., et al. Bloom: A 176b-parameter open-access multilin-
gual language model. arXiv preprint arXiv:2211.05100 ,
2022.
Wu, Q., Bansal, G., Zhang, J., Wu, Y ., Zhang, S., Zhu, E., Li,
B., Jiang, L., Zhang, X., and Wang, C. Autogen: Enabling
next-gen llm applications via multi-agent conversation
framework. arXiv preprint arXiv:2308.08155 , 2023.
Xi, Z., Chen, W., Guo, X., He, W., Ding, Y ., Hong, B.,
Zhang, M., Wang, J., Jin, S., Zhou, E., et al. The rise and
potential of large language model based agents: A survey.
arXiv preprint arXiv:2309.07864 , 2023.
Xie, T., Zhou, F., Cheng, Z., Shi, P., Weng, L., Liu, Y ., Hua,
T. J., Zhao, J., Liu, Q., Liu, C., et al. Openagents: An
open platform for language agents in the wild. arXiv
preprint arXiv:2310.10634 , 2023.
Xu, B., Peng, Z., Lei, B., Mukherjee, S., Liu, Y ., and Xu,
D. Rewoo: Decoupling reasoning from observations for
efficient augmented language models. arXiv preprint
arXiv:2305.18323 , 2023.
Xue, S., Wang, Y ., Chu, Z., Shi, X., Jiang, C., Hao, H.,
Jiang, G., Feng, X., Zhang, J. Y ., and Zhou, J. Prompt-
augmented temporal point process for streaming event
sequence. arXiv preprint arXiv:2310.04993 , 2023a.
Xue, S., Zhou, F., Xu, Y ., Zhao, H., Xie, S., Dai, Q., Jiang,
C., Zhang, J., Zhou, J., Xiu, D., and Mei, H. Weaverbird:
Empowering financial decision-making with large lan-
guage model, knowledge base, and search engine. CoRR ,
abs/2308.05361, 2023b.
Yang, J., Li, A., Farajtabar, M., Sunehag, P., Hughes, E., and
Zha, H. Learning to incentivize other learning agents. In
Advances in Neural Information Processing Systems 33:
Annual Conference on Neural Information Processing
Systems 2020, NeurIPS 2020 , 2020.
Yang, Z., Liu, J., Han, Y ., Chen, X., Huang, Z., Fu, B.,
and Yu, G. Appagent: Multimodal agents as smartphone
users. arXiv preprint arXiv:2312.13771 , 2023.
Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan,
K., and Cao, Y . React: Synergizing reasoning and acting
in language models. arXiv preprint arXiv:2210.03629 ,
2022.
Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T. L., Cao, Y .,
and Narasimhan, K. Tree of thoughts: Deliberate prob-
lem solving with large language models. arXiv preprint
arXiv:2305.10601 , 2023.

--- PAGE 14 ---
Professional Agents
Ye, Z., Zhao, Z., Ren, Y ., and Wu, F. Syntaspeech:
syntax-aware generative adversarial text-to-speech. arXiv
preprint arXiv:2204.11792 , 2022.
Yuan, W., Pang, R. Y ., Cho, K., Sukhbaatar, S., Xu, J.,
and Weston, J. Self-rewarding language models. CoRR ,
abs/2401.10020, 2024.
Zhang, C., Yang, K., Hu, S., Wang, Z., Li, G., Sun, Y . E.,
Zhang, C., Zhang, Z., Liu, A., Zhu, S.-C., Chang, X.,
Zhang, J., Yin, F., Liang, Y ., and Yang, Y . Proagent:
Building proactive cooperative agents with large language
models. 2023a.
Zhang, H., Du, W., Shan, J., Zhou, Q., Du, Y ., Tenenbaum,
J. B., Shu, T., and Gan, C. Building cooperative embodied
agents modularly with large language models. arXiv
preprint arXiv:2307.02485 , 2023b.
Zhang, Y ., Ge, F., Li, F., Yang, X., Song, J., and Yu, D.
Prediction of multiple types of RNA modifications via
biological language model. IEEE ACM Trans. Comput.
Biol. Bioinform. , 20(5):3205–3214, 2023c.
Zhong, W., Guo, L., Gao, Q., and Wang, Y . Memorybank:
Enhancing large language models with long-term mem-
ory. arXiv preprint arXiv:2305.10250 , 2023.
Zhou, G., Gao, Z., Ding, Q., Zheng, H., Xu, H., Wei, Z.,
Zhang, L., and Ke, G. Uni-mol: A universal 3d molecu-
lar representation learning framework. In The Eleventh
International Conference on Learning Representations,
ICLR 2023, Kigali, Rwanda . OpenReview.net, 2023.
Zhu, R., Guo, D., Qi, D., Chu, Z., Yu, X., and Li, S. Trust-
worthy representation learning across domains. arXiv
preprint arXiv:2308.12315 , 2023a.
Zhu, X., Chen, Y ., Tian, H., Tao, C., Su, W., Yang, C.,
Huang, G., Li, B., Lu, L., Wang, X., et al. Ghost in the
minecraft: Generally capable agents for open-world envi-
roments via large language models with text-based knowl-
edge and memory. arXiv preprint arXiv:2305.17144 ,
2023b.

# 2402.00854.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/agent/2402.00854.pdf
# Kích thước tệp: 5336211 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Được xuất bản tại Hội nghị thứ 3 về Tác nhân Học tập Suốt đời (CoLLAs), 2024
SYMBOLIC AI: MỘT FRAMEWORK CHO CÁC PHƯƠNG PHÁP DỰA TRÊN LOGIC
KẾT HỢP MÔ HÌNH SINH VÀ SOLVER
Marius–Constantin Dinu* † ‡Claudiu Leoveanu–Condrei† ||Markus Holzleitner‡
Werner Zellinger‡ §Sepp Hochreiter‡
ExtensityAI†Johannes Kepler University‡RICAM§Amazon Devices||

TÓM TẮT
Chúng tôi giới thiệu SymbolicAI, một framework linh hoạt và modular sử dụng phương pháp dựa trên logic để học khái niệm và quản lý luồng trong các quy trình sinh. SymbolicAI cho phép tích hợp liền mạch các mô hình sinh với nhiều loại solver khác nhau bằng cách coi các mô hình ngôn ngữ lớn (LLMs) như các parser ngữ nghĩa thực hiện các tác vụ dựa trên cả hướng dẫn ngôn ngữ tự nhiên và hình thức, do đó bắc cầu khoảng cách giữa lý luận ký hiệu và AI sinh. Chúng tôi tận dụng các nguyên lý lập trình xác suất để giải quyết các tác vụ phức tạp, và sử dụng các mô hình lập trình khả vi và cổ điển với những thế mạnh tương ứng của chúng. Framework giới thiệu một tập hợp các phép toán đa hình, có tính tổ hợp và tự tham chiếu cho dữ liệu đa phương thức kết nối các quy trình sinh đa bước và căn chỉnh đầu ra của chúng với mục tiêu người dùng trong các quy trình làm việc phức tạp. Kết quả là, chúng ta có thể chuyển đổi giữa các khả năng của nhiều mô hình nền tảng khác nhau với khả năng học trong ngữ cảnh và các mô hình chuyên biệt, được tinh chỉnh hoặc solver thành thạo trong việc giải quyết các vấn đề cụ thể. Thông qua các phép toán này dựa trên học trong ngữ cảnh, framework của chúng tôi cho phép tạo ra và đánh giá các đồ thị tính toán có thể giải thích được. Cuối cùng, chúng tôi giới thiệu một thước đo chất lượng và điểm số thực nghiệm của nó để đánh giá các đồ thị tính toán này, và đề xuất một benchmark so sánh các LLM tiên tiến khác nhau trên một tập hợp các quy trình làm việc phức tạp. Chúng tôi gọi điểm số thực nghiệm là "Vector Embedding for Relational Trajectory Evaluation through Cross-similarity", hay viết tắt là điểm VERTEX. Codebase framework¹ và benchmark² được liên kết bên dưới.

Prompting / Fine-TuningSpektrum AI Neuro-Symbolic
Software-Engineering Machine LearningMô hình Nền tảng
Mô hình Chuyên biệtProgramming / LearningModeling / CodingTrừu tượng
Triển khai

Hình 1: Framework neuro-symbolic của chúng tôi cho phép chuyển đổi liền mạch giữa lập trình ký hiệu và khả vi, mỗi loại có động lực và thế mạnh riêng biệt. Lập trình khả vi cung cấp truy cập đến các mô hình nền tảng và chuyên biệt. Mặt khác, lập trình cổ điển chuyển đổi giữa trừu tượng và triển khai, tập trung vào các khái niệm cấp cao trước khi đi sâu vào chi tiết triển khai.

¹Framework SymbolicAI: https://github.com/ExtensityAI/symbolicai
²Benchmark đánh giá: https://github.com/ExtensityAI/benchmark
* Liên hệ: dinu@ml.jku.at ,{marius, leo }@extensity.ai
|| Công việc thực hiện bên ngoài Amazon.

--- TRANG 2 ---
Được xuất bản tại Hội nghị thứ 3 về Tác nhân Học tập Suốt đời (CoLLAs), 2024

1 GIỚI THIỆU
Làn sóng gần đây của AI sinh, đặc biệt liên quan đến các mô hình ngôn ngữ lớn (LLMs), đã chứng minh khả năng ứng dụng rộng rãi của chúng trên nhiều lĩnh vực khác nhau (Badita, 2022; Degrave, 2022). Các mô hình này đã nâng cao chức năng của các công cụ cho tương tác dựa trên tìm kiếm (YouWrite, 2022; Writesonic, 2022; Microsoft, 2023), tổng hợp chương trình (Jain et al., 2021; Romera-Paredes et al., 2023; Key et al., 2023), tương tác dựa trên chat (ReplikaAI, 2016; OpenAI, 2022; Google, 2023), và nhiều hơn nữa. Hơn nữa, các phương pháp dựa trên ngôn ngữ đã tạo điều kiện cho kết nối giữa các phương thức khác nhau, cho phép chuyển đổi text-to-image (Ramesh et al., 2021; Saharia et al., 2022), text-to-video (Singer et al., 2022), text-to-3D (Poole et al., 2022), text-to-audio (Oord et al., 2016; Wang et al., 2017), và text-to-code (Wang et al., 2021b; Lu et al., 2021; Li et al., 2022b), chỉ kể một số ít. Do đó, bằng cách huấn luyện trên lượng lớn dữ liệu văn bản không nhãn, LLMs đã được chứng minh không chỉ lưu trữ kiến thức thực tế (Petroni et al., 2019; Kassner et al., 2020) và xấp xỉ ý định của người dùng ở một mức độ nào đó (Andreas, 2022), mà còn mở khóa các khả năng chuyên sâu thông qua các kỹ thuật prompting sáng tạo (Nori et al., 2023).

Mặc dù có tính linh hoạt, các LLM hiện tại đối mặt với những thách thức như lý luận sai lầm và tạo ra nội dung sai, thường được gọi là ảo giác (Jones & Steinhardt, 2022). Những hạn chế này nhấn mạnh tầm quan trọng của việc tích hợp các phương pháp ký hiệu bổ sung để xác thực và hướng dẫn các quy trình sinh của LLMs, đảm bảo đầu ra chính xác và đáng tin cậy hơn. Song song đó, các nỗ lực đã tập trung vào phát triển các phương pháp dựa trên công cụ (Schick et al., 2023) hoặc framework template (Chase, 2023) để mở rộng khả năng của LLMs và cho phép một phạm vi ứng dụng rộng hơn. Tuy nhiên, những nỗ lực này chỉ nắm bắt một phần tiềm năng vốn có trong việc tận dụng LLMs như các parser ngữ nghĩa. Trái ngược với các parser cho ngôn ngữ có cấu trúc, một parser ngữ nghĩa có thể phân tích ngôn ngữ tự nhiên phi cấu trúc thành các thành phần có ý nghĩa ngữ nghĩa và chuyển đổi chúng thành dạng có cấu trúc. Trong khi truyền thống phân tích ngữ nghĩa là vai trò được đảm nhận bởi các thuật toán và mô hình chuyên biệt, chúng tôi cho rằng LLMs, thông qua việc huấn luyện trên dữ liệu ngôn ngữ đa dạng, đã phát triển khả năng thực hiện phân tích ngữ nghĩa như một phần của khả năng xử lý ngôn ngữ tự nhiên rộng hơn của chúng. Đến lượt mình, chúng tôi xác định LLMs như một thành phần trung tâm trong việc tạo ra các hệ thống AI neuro-symbolic (NeSy) tinh vi. Các hệ thống này tích hợp các khái niệm ký hiệu và dưới ký hiệu và sử dụng các khả năng của phân tích ngữ nghĩa để phát triển các biểu thức ký hiệu cho phép các mô hình lập trình xác suất mới.

Chúng tôi giới thiệu SymbolicAI, một framework NeSy có tính tổ hợp có thể biểu diễn và thao tác các cấu trúc đa phương thức và tự tham chiếu (Schmidhuber, 2007; Fernando et al., 2023). SymbolicAI tăng cường quy trình sinh của LLMs với các phép toán học trong ngữ cảnh, được thực hiện thông qua các nguyên hàm chức năng, và cho phép tạo ra các ứng dụng linh hoạt thông qua học trong ngữ cảnh (Wei et al., 2022a). Các phép toán này cho phép các thành phần dựa trên logic hướng dẫn quy trình sinh và cho phép một hệ thống NeSy modular, bao gồm một loạt các solver hiện có, các engine ngôn ngữ hình thức để đánh giá biểu thức toán học, các công cụ chứng minh định lý, cơ sở kiến thức, và công cụ tìm kiếm để truy xuất thông tin. SymbolicAI tiết lộ các solver này như các khối xây dựng để xây dựng các hàm tổ hợp như đồ thị tính toán, làm cho có thể bắc cầu các mô hình lập trình cổ điển và khả vi với mục tiêu tạo ra các solver vấn đề bất biến miền. Trong việc thiết kế kiến trúc của SymbolicAI, chúng tôi đã lấy cảm hứng từ một tập hợp bằng chứng cho thấy não người sở hữu một module xử lý ngôn ngữ có tính chọn lọc (Macsweeney, 2002; Fedorenko et al., 2010; Menenti et al., 2011; Regev et al., 2013; Scott et al., 2016; Deniz et al., 2019; Hu et al., 2022), nghiên cứu trước đó về kiến trúc nhận thức (Newell & Simon, 1956; Newell et al., 1957; Newell & Simon, 1972; Newell, 1990; Laird, 2022), và tầm quan trọng của ngôn ngữ đối với cấu trúc của bản đồ ngữ nghĩa trong não người (Huth et al., 2016). Chúng tôi coi ngôn ngữ như một module xử lý trung tâm, khác biệt với các quy trình nhận thức khác như lý luận hoặc trí nhớ (Paischer et al., 2022; 2023). Chúng tôi giả thuyết rằng một module xử lý trung tâm dựa trên ngôn ngữ như vậy là thành phần cốt lõi của các hệ thống AI rộng (xem Phụ lục Mục A) và cho phép phát triển các hệ thống AI hoàn toàn tự động để ra quyết định.

Một thách thức đáng kể gặp phải trong việc phát triển framework của chúng tôi liên quan đến đánh giá LLMs khi được sử dụng như parser ngữ nghĩa trong một quy trình làm việc NeSy. Đánh giá hiện tại của nội dung được tạo ra dựa vào các chỉ số cho quy trình sinh một bước, như điểm BLEU (Papineni et al., 2002). Các chỉ số này không phù hợp để đánh giá quy trình sinh đa bước. BLEU có những hạn chế, vì nó đo sự chồng chéo dựa trên n-gram của đầu ra được tạo với một tham chiếu không xem xét ý nghĩa ngữ nghĩa. Kết quả là, BLEU không thể nắm bắt tương đương ngữ nghĩa, đặc biệt trong các tác vụ phức tạp hơn. Các chỉ số gần đây hơn như CIDEr (Vedantam et al., 2014) hoặc SPICE (Anderson et al., 2016) cũng không phù hợp cho vấn đề của chúng tôi, hoặc vì chúng được xây dựng dựa trên BLEU (trong trường hợp của CIDEr) hoặc được thiết kế với các bias quy nạp cụ thể cho việc mô tả hình ảnh.

Do đó, cùng với framework của chúng tôi, chúng tôi giới thiệu một thước đo chất lượng (và điểm số thực nghiệm của nó) cho các quy trình sinh đa bước dựa trên ý nghĩa ngữ nghĩa. Chúng tôi gọi điểm số của mình là "Vector Embedding for Relational Trajectory Evaluation through Cross-similarity", hay viết tắt là điểm VERTEX. Điểm VERTEX của chúng tôi sử dụng embedding để so sánh phân phối node trong một đồ thị tính toán. Nó đo ý nghĩa ngữ nghĩa trên đường dẫn phân phối bằng cách tính toán tại mỗi node sự tương tự chéo giữa các embedding được tạo và các embedding được lấy mẫu từ một phân phối tham chiếu.

--- TRANG 3 ---
Được xuất bản tại Hội nghị thứ 3 về Tác nhân Học tập Suốt đời (CoLLAs), 2024

phân phối. Hơn nữa, điểm VERTEX được thiết kế sao cho nó có thể được sử dụng như một tín hiệu phần thưởng trong một thiết lập học tăng cường (Sutton, 1984). Cuối cùng, chúng tôi đề xuất một benchmark để đánh giá các quy trình làm việc phức tạp. Chúng tôi định nghĩa một tập hợp các đánh giá cơ bản, đặc biệt là dự đoán kết hợp dựa trên học trong ngữ cảnh, liên kết đa phương thức để sử dụng công cụ, và tổng hợp chương trình để thực thi subroutine. Hơn nữa, chúng tôi giới thiệu các đánh giá phức tạp cho các thành phần dựa trên logic và đồ thị tính toán phân cấp.

Tóm lại, các đóng góp chính được trình bày trong công trình này như sau:
• Chúng tôi giới thiệu SymbolicAI, một framework dựa trên logic để học khái niệm và quản lý luồng trong các quy trình sinh, cho phép tích hợp liền mạch với một loạt các mô hình nền tảng và solver.
• Chúng tôi tận dụng LLMs như parser ngữ nghĩa để cho phép tạo ra các đồ thị tính toán phức tạp bằng cách kết hợp các biểu thức ký hiệu với các mô hình lập trình xác suất.
• Chúng tôi giới thiệu một thước đo chất lượng và điểm số thực nghiệm của nó cùng với một benchmark được thiết kế cho các quy trình sinh đa bước để so sánh LLMs trên một loạt các tác vụ phức tạp.

2 CÔNG TRÌNH LIÊN QUAN

Phương pháp Ký hiệu Lĩnh vực AI ký hiệu có nền tảng trong các công trình của Logic Theorist (LT) (Newell & Simon, 1956) và General Problem Solver (GPS) (Newell et al., 1957). Các chương trình này đại diện cho những bước đầu tiên hướng tới lý luận tự động và giải quyết vấn đề sử dụng các biểu diễn ký hiệu. Mặc dù có những tiến bộ, cả hai đều đối mặt với thách thức trong việc xử lý độ phức tạp của các vấn đề thế giới thực, đặc biệt do tính chất tổ hợp của không gian giải pháp. Để giải quyết những hạn chế này, kiến trúc nhận thức Soar (Laird et al., 1987) đã được phát triển, thúc đẩy quan niệm rằng hành vi thông minh là kết quả của tìm kiếm hướng mục tiêu thông qua một không gian vấn đề (Newell & Simon, 1972; McCarthy et al., 2006), với mỗi bước bao gồm việc chọn và áp dụng các toán tử. Soar đã giới thiệu các thành phần như học tăng cường, bế tắc, trạng thái phụ, và chunking để nâng cao khả năng giải quyết vấn đề của nó. Nó cũng chứng minh tầm quan trọng của việc học từ kinh nghiệm để thích ứng và cải thiện hiệu suất theo thời gian. Tuy nhiên, Santoro et al. (2022) nhấn mạnh tính chủ quan của các ký hiệu và gợi ý rằng tính thành thạo ký hiệu giống con người có thể phát triển trong máy móc thông qua các thuật toán học nhúng trong bối cảnh xã hội-văn hóa. Quan điểm này, dựa trên quan niệm rằng các ký hiệu là tam phân và ý nghĩa của chúng xuất hiện từ sự đồng thuận, tìm cách rời xa các phương pháp AI ký hiệu truyền thống hướng tới AI học thích ứng ý nghĩa và hành vi từ các kinh nghiệm giống con người. Mục tiêu là nuôi dưỡng các máy móc thể hiện hành vi ký hiệu trên một phạm vi năng lực, có khả năng phản ánh các quy trình học tập tiến hóa và xã hội được quan sát ở con người. Cuối cùng, AI ký hiệu gặp khó khăn với tính không thể dự đoán và biến đổi của dữ liệu thế giới thực. Những thách thức này đã dẫn đến việc sử dụng các phương pháp học thống kê, như học sâu (Alom et al., 2018), phù hợp hơn trong việc quản lý nhiễu và thông tin không chắc chắn thông qua các biểu diễn có giá trị vector.

Phương pháp Dưới Ký hiệu Framework dưới ký hiệu, có gốc rễ trong các mô hình mạng neural, bắt đầu với các công trình tiên phong như perceptron (McCulloch & Pitts, 1943), với việc triển khai phần cứng đầu tiên nhanh chóng theo sau (Rosenblatt, 1958). Quan niệm nền tảng về xử lý phân tán (Rumelhart et al., 1986) sau đó được củng cố và mở rộng thêm bằng cách chứng minh rằng các mạng feedforward đa lớp với một lớp ẩn duy nhất có thể phục vụ như các approximator vạn năng cho bất kỳ hàm Borel đo được nào, với đủ các đơn vị ẩn (Hornik et al., 1989). Chuyển nhanh tới hiện tại, các framework đương đại đạt được một bước nhảy vọt đáng kể với việc giới thiệu kiến trúc Transformer (Vaswani et al., 2017), nền tảng của hầu hết các LLM ngày nay. Các LLM này thể hiện khả năng đặc biệt trong học trong ngữ cảnh, một phương pháp được phổ biến bởi những mô hình như GPT-3 (Brown et al., 2020), nơi các mô hình cải thiện hiệu suất tác vụ thông qua hướng dẫn ngôn ngữ tự nhiên và ví dụ được cung cấp trực tiếp trong prompt đầu vào. Trong khi học trong ngữ cảnh bỏ qua nhu cầu huấn luyện lại rõ ràng, nó đòi hỏi thiết kế prompt tỉ mỉ để hướng các mô hình hướng tới hành vi mong muốn.

Phương pháp Neuro-Symbolic Để vượt qua những hạn chế của từng phương pháp riêng lẻ, các phương pháp NeSy kết hợp thế mạnh suy luận thống kê của các kiến trúc neural sâu với khả năng tổng quát hóa và giải thích được của các hệ thống ký hiệu (Garcez et al., 2015; Besold et al., 2017; d'Avila Garcez et al., 2019; d'Avila Garcez & Lamb, 2020; Lamb et al., 2020; Hamilton et al., 2022; Yu et al., 2023). Một số phương pháp tập trung vào các chiến lược khác nhau để tích hợp các quy trình học và lý luận (Yu et al., 2023; Fang et al., 2024). Thứ nhất, các phương pháp học để lý luận coi khía cạnh học như một bộ tăng tốc cho lý luận, trong đó các mạng neural sâu được sử dụng để giảm không gian tìm kiếm cho các hệ thống ký hiệu (Silver et al., 2016; 2017b;a; Qu & Tang, 2019; Schrittwieser et al., 2020). Thứ hai, lý luận để học xem lý luận như một cách để điều chỉnh học, trong đó kiến thức ký hiệu hoạt động như một ràng buộc hướng dẫn giám sát các tác vụ học máy (Hu et al., 2016; Xu et al., 2018). Thứ ba, danh mục học-lý luận cho phép một mối quan hệ cộng sinh giữa học và lý luận. Ở đây, cả hai yếu tố tương tác và chia sẻ thông tin để thúc đẩy khả năng giải quyết vấn đề.

--- TRANG 4 ---
Được xuất bản tại Hội nghị thứ 3 về Tác nhân Học tập Suốt đời (CoLLAs), 2024

khả năng giải quyết vấn đề (Donadello et al., 2017; Manhaeve et al., 2018; Mao et al., 2019; Ellis, 2023). Sự cộng sinh này mở rộng thêm khi xem xét các phương pháp dựa trên đồ thị, gần gũi với mục tiêu của framework được đề xuất của chúng tôi. Nghiên cứu trong lĩnh vực này, như CycleGT (Guo et al., 2020) và Paper2vec (Ganguly & Pudi, 2017) khám phá các kỹ thuật không giám sát để bắc cầu biểu diễn đồ thị và văn bản, GPTSwarm (Zhuge et al., 2024) khám phá các optimizer đồ thị để tinh chỉnh các prompt cấp node và tối ưu hóa cạnh. Tiếp theo, embedding đồ thị, khi được sử dụng trong các framework ký hiệu, có thể nâng cao các tác vụ lý luận đồ thị tri thức (Zhang et al., 2021), hoặc tổng quát hơn, cung cấp nền tảng cho việc học các biểu diễn bất biến miền (Park et al., 2023).

Cuối cùng, dựa trên những hiểu biết từ Sun et al. (2022), việc tích hợp các kỹ thuật NeSy trong các quy trình làm việc khoa học hứa hẹn sự tăng tốc đáng kể trong khám phá khoa học. Trong khi công trình trước đây đã xác định hiệu quả các cơ hội và thách thức, chúng tôi đã thực hiện một phương pháp tham vọng hơn bằng cách phát triển một framework toàn diện từ đầu để tạo điều kiện cho một loạt các tích hợp NeSy.

Mô hình Ngôn ngữ Lớn Một phần, việc tinh chỉnh dựa trên hướng dẫn của LLMs thông qua học tăng cường từ phản hồi con người (Ouyang et al., 2022; Li et al., 2023) hoặc tối ưu hóa ưu tiên trực tiếp (Rafailov et al., 2023) đã cho thấy kết quả hứa hẹn trong việc xử lý các vấn đề lệch lạc giá trị (Bradley Knox & Stone, 2008; MacGlashan et al., 2017; Christiano et al., 2017; Ibarz et al., 2018; Goyal et al., 2022), mở khóa những khả năng mới cho chuỗi suy nghĩ (Wei et al., 2022b), cây suy nghĩ (Yao et al., 2023a), và tương tác đồ thị suy nghĩ (Besta et al., 2023). Tuy nhiên, nghiên cứu gần đây cũng làm nổi bật những hạn chế của LLMs trong năng lực ngôn ngữ chức năng mặc dù thành thạo trong năng lực ngôn ngữ hình thức (Mahowald et al., 2023). Trong khi năng lực ngôn ngữ hình thức bao gồm khả năng hiểu và tạo ra ngôn ngữ, năng lực ngôn ngữ chức năng liên quan đến việc áp dụng ngôn ngữ trong bối cảnh thế giới thực, như truyền đạt đầu vào cảm giác hoặc gọi lại thông tin từ trí nhớ. Ví dụ về năng lực ngôn ngữ chức năng bao gồm các hàm ý (Ruis et al., 2022) và hiểu ngôn ngữ theo ngữ cảnh vượt ra ngoài biểu hiện thống kê của phân phối dữ liệu (Bransford & Johnson, 1972; Mikolov et al., 2013b). Do đó, vận hành LLMs thông qua một phương pháp hoàn toàn dựa trên suy luận giới hạn khả năng của chúng trong cửa sổ ngữ cảnh được cung cấp, hạn chế nghiêm trọng tầm nhìn của chúng. Điều này dẫn đến những thiếu sót trong mô hình hóa tình huống, không thích ứng thông qua các thay đổi ngữ cảnh, và giải quyết vấn đề ngắn hạn, trong số các khả năng khác. Tuy nhiên, việc đơn giản tăng độ dài ngữ cảnh có thể không mang lại khả năng lớn hơn, như được chứng minh bởi đường cong hiệu suất hình chữ U được quan sát (Liu et al., 2023) nơi LLMs xuất sắc khi sử dụng thông tin ở đầu hoặc cuối ngữ cảnh đầu vào, nhưng gặp khó khăn với thông tin nằm ở giữa, đặc biệt khi ngữ cảnh tăng. Những thách thức này đang được nghiên cứu tích cực, với các phương pháp mới như Hyena (Poli et al., 2023), RWKV (Bo, 2021), GateLoop (Katsch, 2023), Mamba (Gu & Dao, 2023) và xLSTM (Beck et al., 2024) xuất hiện. Trong khi đó, sự quan tâm trở lại đối với các phương pháp sinh tăng cường truy xuất (Li et al., 2022a) cung cấp một lựa chọn thay thế bằng cách vượt qua bản chất tự hồi quy của kiến trúc Transformer được sử dụng rộng rãi (Vaswani et al., 2017), cho phép làm phong phú ngữ cảnh với thông tin bên.

Học trong Ngữ cảnh Gần đây, một số phương pháp học trong ngữ cảnh đã phát triển để cho phép sử dụng công cụ thông qua LLMs (Schick et al., 2023), hoặc tinh chỉnh kết quả sinh của LLMs (Yang et al., 2023). Điều này bao gồm prompting chuỗi suy nghĩ (CoT), một phương pháp điều kiện hóa mô hình để tiết lộ quy trình lý luận từng bước của nó (Wei et al., 2022b; Singhal et al., 2023). Prompting CoT chia nhỏ các tác vụ phức tạp thành các bước đơn giản hơn, tuần tự, và giúp diễn giải đầu ra của LLM. CoT tự tạo, nơi các mô hình được khuyến khích tạo ra chuỗi lý luận riêng của chúng dựa trên các ví dụ huấn luyện, vượt qua cả CoT được tạo ra một cách chuyên nghiệp (Fernando et al., 2023). Quan sát này phản ánh các báo cáo khác rằng GPT-4 có khả năng tự cải thiện emergent thông qua nội tâm, như tự xác minh (Weng et al., 2023) hoặc tự nhất quán (Wang et al., 2023b). Tree of Thoughts (ToT) cho phép LLMs giải quyết các vấn đề phức tạp bằng cách khám phá nhiều đường dẫn lý luận thông qua một cây tìm kiếm của các đơn vị văn bản mạch lạc, thể hiện những cải tiến đáng kể trong giải quyết vấn đề trong các tác vụ yêu cầu lập kế hoạch chiến lược và tìm kiếm (Yao et al., 2023a). Các kỹ thuật ensemble tiếp tục nâng cao tính mạnh mẽ và độ chính xác của dự đoán mô hình bằng cách kết hợp một số chiến lược để thiết lập sự đồng thuận (Nori et al., 2023).

3 ĐỊNH NGHĨA VẤN ĐỀ

Các phương pháp thông thường sử dụng các mô hình nền tảng, như LLMs, chủ yếu được giới hạn trong việc thực thi một bước hoặc vài bước và chủ yếu dựa vào các hướng dẫn prompt thủ công, thường được gọi là học trong ngữ cảnh. Phạm vi hạn chế này giới hạn việc sử dụng các phương thức khác nhau, thiếu xác minh, và thể hiện khả năng công cụ hạn chế. Chúng tôi cho rằng việc sử dụng các engine NeSy như đơn vị tính toán cốt lõi, được thực hiện thông qua các phương pháp dựa trên logic kết hợp với các mô hình nền tảng dưới ký hiệu, cung cấp một quan điểm tổng quát, mạnh mẽ và có thể xác minh hơn. Phương pháp này có một số lợi thế. Thứ nhất, nó cho phép tích hợp các giải pháp có sẵn (ví dụ: các thuật toán cổ điển khác nhau), giảm tải độ phức tạp tính toán và bắc cầu các phương thức khác nhau. Thứ hai, nó cho phép các thành phần dưới ký hiệu tập trung vào ra quyết định (ví dụ: chọn công cụ tương ứng dựa trên phân loại trong ngữ cảnh). Thứ ba, nó cung cấp

--- TRANG 5 ---
Được xuất bản tại Hội nghị thứ 3 về Tác nhân Học tập Suốt đời (CoLLAs), 2024

một lớp điều khiển dựa trên ngôn ngữ có thể diễn giải cho các hệ thống tự động có thể giải thích được. Trong phần tiếp theo, chúng tôi trình bày chi tiết về các nguyên lý thiết kế chính làm nền tảng cho SymbolicAI và cách chúng tôi hướng dẫn các quy trình sinh của các engine NeSy. Để biết thêm chi tiết kỹ thuật, xem Phụ lục Mục 5.

4 NGUYÊN LÝ THIẾT KẾ

Ký hiệu và Biểu thức Như được Newell & Simon (1976) đề xuất, các ký hiệu là các nhà mang ý nghĩa cơ bản trong một bối cảnh tính toán³. Các ký hiệu này định nghĩa các mẫu vật lý có khả năng tạo ra các cấu trúc phức tạp, và là trung tâm của việc thiết kế và diễn giải logic và biểu diễn tri thức (Augusto, 2022). Chúng tôi định nghĩa một ký hiệu là tập hợp S=S n≥0Ln được hình thành bằng cách nối các ký tự từ một tập hợp ký tự hữu hạn L, tức là từ vựng trong một thiết lập LLM, và với n đại diện cho độ dài chuỗi của chuỗi. Do đó, hãy để tập hợp tất cả các ký hiệu có thể có được định nghĩa là Σ và S ∈ Σ. Chúng tôi tiếp tục giới thiệu một phép toán L cho phép chúng ta tạo ra các biểu thức trên bất kỳ số lượng ký hiệu nào từ Σ, và khi được đánh giá trả về một ký hiệu mới trong Σ. Đối với bất kỳ tập con {S1,S2, . . . ,Sm} ⊆Σ nào, một biểu thức được định nghĩa là ω:Lm i=1Si→ S′ từ tập hợp tất cả các biểu thức có thể có ω∈Ω, trong đó S′∈Σ, và L đại diện cho phép toán placeholder của việc kết hợp và chuyển đổi các ký hiệu theo các quy tắc cụ thể cho m số lượng ký hiệu. Một quy tắc cụ thể như vậy cho L có thể định nghĩa một biểu thức số học L:= + trong đó hai ký hiệu được cộng, tức là ω:="1"+"two" dẫn đến một ký hiệu mới "3" hoặc "three". Do đó, SymbolicAI dựa trên khái niệm rằng các ký hiệu, và các biểu thức mà chúng tạo ra, là sự phản ánh của thông tin vốn có trong một hệ thống NeSy, và phục vụ như đại diện cho tương tác giữa hệ thống NeSy và không gian vấn đề. Hơn nữa, chúng tôi lập luận rằng các mẫu thực (Dennett, 1991), các cấu trúc lặp lại và có thể nhận dạng xuất hiện một cách mạch lạc và đáng tin cậy trong dữ liệu vượt ra ngoài sự ngẫu nhiên hoặc nhiễu đơn thuần, có thể được thực hiện hiệu quả thông qua các ký hiệu.

Hơn nữa, chúng tôi sử dụng ngôn ngữ như một công cụ để ánh xạ các khái niệm phức tạp, tận dụng ngữ nghĩa và trừu tượng vốn có của nó để mô tả các trạng thái và thuộc tính của một vấn đề đang xử lý. Các ánh xạ này là vạn năng, ví dụ chúng có thể được sử dụng để định nghĩa mô tả cảnh, lập kế hoạch tầm xa, thuộc tính âm thanh, trạng thái cảm xúc, điều kiện vật lý, v.v. Do đó, ngôn ngữ phục vụ như một framework toàn diện, nhưng trừu tượng để đóng gói ý nghĩa, và gọi nó là vỏ lồi của kiến thức xã hội của chúng ta. Tiếp theo, việc gán các đối tượng vật lý hiện có với các khái niệm trừu tượng là phổ biến, như được minh họa bằng xu hướng tự nhiên của chúng ta liên kết các đối tượng hữu hình với màu sắc và cảm xúc, như việc pha trộn màu "đỏ" với "trái tim", "ấm áp", và "đam mê". Phương pháp này cũng neo buộc công trình của chúng tôi trong lĩnh vực lý thuyết ngôn ngữ hình thức, vì chúng tôi yêu cầu một phương pháp có cấu trúc để xây dựng các ánh xạ từ thế giới đến ngôn ngữ. Do đó, chúng tôi sử dụng các cấu trúc ngôn ngữ hình thức, như ngữ pháp, để định nghĩa một cách có hệ thống phương pháp lấy ngôn ngữ làm trung tâm của chúng tôi để giải quyết vấn đề và việc dịch thuật các phức tạp thế giới thực thành thuật ngữ ngôn ngữ liên quan.

Ngôn ngữ Hình thức Trong lý thuyết ngôn ngữ hình thức và ngôn ngữ học, các ngôn ngữ được cấu trúc theo hệ thống phân cấp Chomsky, phân loại các ngôn ngữ theo độ phức tạp của cấu trúc ngữ pháp của chúng (Chomsky, 1956). Hệ thống phân cấp này định nghĩa bốn loại ngữ pháp (Loại-3 đến Loại-0) và phân tách các ngôn ngữ hình thức theo độ phức tạp ngữ pháp của chúng. Một ngữ pháp trong bối cảnh này bao gồm các ký hiệu đầu cuối và không đầu cuối, quy tắc sản xuất, và một ký hiệu bắt đầu được chỉ định, cho phép tạo ra các chuỗi hợp lệ trong một ngôn ngữ.

Chúng tôi định nghĩa một engine NeSy như một ánh xạ VS∗: Ω×N× T → Σ, trong đó N⊂Σ là một tập hợp các ký hiệu không đầu cuối, T ⊂ Σ là một tập hợp các ký hiệu đầu cuối và N∩T=∅, và S∗∈Σ là một ký hiệu bắt đầu. Chúng tôi tiếp tục hình thức hóa một ngữ pháp G= (N,T, P,S∗) với các quy tắc sản xuất được định nghĩa là P:=VS∗(ω, N,T). Ngữ pháp này mô tả việc tạo ra các ký hiệu thông qua các biểu thức ω. Để đơn giản, chúng tôi sẽ bỏ chỉ số dưới của VS∗ và sử dụng nó như V. Chúng tôi xác định LLMs như các ứng cử viên hứa hẹn để hoạt động như một phần của các engine NeSy. Trong SymbolicAI, một ký hiệu S được tăng cường với các hướng dẫn có điều kiện và các loại được dẫn xuất từ DSLs, được định nghĩa tùy chỉnh hoặc không (ví dụ: HTML, SQL, v.v.), được điều chỉnh để hướng dẫn các LLM. Lợi thế chính của LLMs so với các hệ thống trước đó nằm ở khả năng tổng quát hóa trên các ngôn ngữ hình thức (Wang et al., 2023a) và hệ thống tri thức. Mặc dù hiện tại không có sự đồng thuận chung về phân loại chính xác của ngôn ngữ tự nhiên trong hệ thống phân cấp Chomsky, phương pháp của chúng tôi có thể được hiểu như việc sử dụng một ngữ pháp cụ thể theo tình huống, nhạy cảm với ngữ cảnh, cho phép xử lý hướng dẫn và tương tự với sự hiểu biết tinh tế về ngôn ngữ. Giao điểm giữa ngôn ngữ hình thức và tự nhiên trở nên rõ ràng khi xem xét cách các mẫu ngôn ngữ, thông qua các prompt như "Bạn là một trợ lý hữu ích...", gợi ra các phản hồi có cấu trúc, cho thấy một cơ chế hình thức tiềm ẩn đang hoạt động. Quan sát này nhấn mạnh tính hữu dụng của một ngữ pháp như vậy trong framework của chúng tôi, nơi nó phục vụ như một lược đồ rõ ràng hướng dẫn cấu trúc của các ví dụ cho học trong ngữ cảnh. Ví dụ, việc đồng nhất "3.1415..." với "π" hoặc "August 4, 1961" với "1961-08-04" trong một ngữ cảnh nhất định thể hiện việc diễn giải các ký hiệu phụ thuộc vào ngữ cảnh. Một hệ thống như vậy không tuân thủ cứng nhắc các quy tắc ngữ pháp tiêu chuẩn mà thay vào đó điều chỉnh và diễn giải dựa trên ngữ cảnh, hiệu quả tạo ra một ngữ pháp cụ thể theo tình huống.

³Tên framework của chúng tôi được lấy từ công trình nền tảng của Newell và Simon.

--- TRANG 6 ---
Được xuất bản tại Hội nghị thứ 3 về Tác nhân Học tập Suốt đời (CoLLAs), 2024

      Chèn giá trị bên phải vào giá trị bên trái
      theo thứ tự tăng dần. Hãy xem các ví dụ sau.
1, 3, 4 << 2 => Op 'AC' << 'B'
LLM + ConstraintsDSL Prompt Expression
'ABC'Symbol
?DSL Verification
      Ví dụ:
1, 2, 3, 4Neuro-Symbolic Engine
AC << B => Op      Giải:

Hình 2: Minh họa cho pipeline NeSy, thể hiện việc sử dụng khái niệm của các phương pháp học trong ngữ cảnh, cấu trúc ngôn ngữ đặc thù miền (DSL), và các đánh giá biểu thức thông qua một engine NeSy dựa trên LLM và xác minh ràng buộc. Biểu thức thể hiện toán tử chèn có thứ tự ≪ và cách thông tin của ký hiệu B được bao gồm trong ký hiệu AC. Placeholder màu tím trong DSL Prompt đại diện cho một hướng dẫn, như "Chèn giá trị bên phải vào giá trị bên trái theo thứ tự tăng dần." Các vị trí bên dưới đại diện cho các ví dụ few-shot cụ thể theo tác vụ. DSL Prompt nhận biểu thức ω<< và ánh xạ nó thành ˆω<< có thể được xử lý bởi hàm NeSy dựa trên LLM VS∗ và xuất ra một ký hiệu mới.

mar, có khả năng hình thành Các Kết hợp Bất biến Miền thông qua học trong ngữ cảnh. Chúng tôi tiếp tục giải quyết điều này trong đoạn sau.

Tổ hợp Hàm Trong SymbolicAI, chúng tôi sử dụng tổ hợp hàm để xây dựng các hệ thống phân cấp và hành vi phức tạp từ các yếu tố cơ bản. Do đó, framework của chúng tôi cho phép mô hình hóa các quy trình liên kết, nơi đầu ra của một hàm được sử dụng làm đầu vào cho hàm khác, do đó tạo ra một chuỗi các phép toán. Thông qua tổ hợp hàm, chúng tôi xây dựng các đồ thị tính toán, trong đó các ký hiệu trung gian đại diện cho các node hoặc trạng thái trong các đồ thị này. Chính thức, tổ hợp hàm được ký hiệu bằng ◦, trong đó việc kết hợp các hàm f và g tạo ra một hàm mới h=g◦f, được định nghĩa là h(x) =g(f(x)) Đối với các hàm f:X→Y và g:Y→Z, tổ hợp của chúng dẫn đến một hàm ánh xạ các phần tử từ miền X đến codomaine Z thông qua g(f(x)). Mặc dù truyền thống codomaine của hàm trong f phù hợp với miền của hàm ngoài g, SymbolicAI nới lỏng ràng buộc này bằng cách cho phép bất kỳ mối quan hệ tập con nào giữa các miền và codomaine này, điều này đặc biệt có lợi cho học trong ngữ cảnh. Khi sử dụng LLMs cho các quy tắc sản xuất NeSy V, chúng ta có thể dẫn xuất một quy trình sinh đa bước bằng cách tổ hợp một đồ thị tính toán như một chuỗi các tổ hợp hàm zero- và few-shot:

V(ωj, N,T) =V(ωj−1,·)◦ V(ωj−2,·)◦ ··· ◦ V (ω0,·), (1)

trong đó ω0 là hướng dẫn ban đầu và j định nghĩa biến chỉ số cho một quy trình sinh đa bước. Bằng cách tận dụng học chức năng trong ngữ cảnh, nơi các ví dụ zero- và few-shot hoạt động như các yếu tố động của miền hàm, SymbolicAI có khả năng diễn giải và phản hồi các ngữ cảnh đầu vào đa dạng. Ví dụ, một hàm có thể phân loại yêu cầu của người dùng và chọn một giao diện thích hợp (ví dụ: WolframAlpha) để xử lý yêu cầu. Phương thức đầu ra thậm chí có thể thay đổi dựa trên engine tương ứng. Điều này cho phép SymbolicAI xử lý các phép toán trên dữ liệu đa phương thức kết nối các quy trình sinh đa bước và thiết lập tổ hợp hàm như một nguyên lý trung tâm trong việc bắc cầu nhiều phương thức và điều phối nhiều tác vụ khác nhau.

Kết hợp Bất biến Miền Học trong ngữ cảnh đã cho phép LLMs trở thành các solver tác vụ linh hoạt bằng cách nội suy trong phân phối huấn luyện, đến mức thậm chí các tác vụ có khả năng chưa được nhìn thấy cũng có thể giải quyết được (Brown et al., 2020). Chúng tôi gán điều này cho các kết hợp được hình thành trong không gian đầu vào và khả năng của kiến trúc Transformer để định nghĩa các không gian con tính năng bất biến miền. Hiện tượng này có điểm tương đồng với các phương pháp học few-shot như SubGD (Gauch et al., 2022), một phương pháp dựa trên việc xác định và sử dụng một không gian con chiều thấp, được học từ các tác vụ khác nhau hiệu quả điều chỉnh quy trình học. Vì LLMs đã được huấn luyện trên các miền và tác vụ khác nhau, cũng bao gồm các công thức của biểu thức toán học, chúng tôi cho rằng các token cụ thể, như dấu bằng, có thể được tận dụng để kết hợp ý nghĩa giữa các đối tượng ký hiệu khác nhau. Khác với các biểu diễn bất biến miền tạo ra các tính năng bất biến trên các tác vụ học khác nhau, phương pháp của chúng tôi tận dụng khả năng tổng quát hóa trong ngữ cảnh của LLMs để xây dựng các kết hợp ký hiệu bất biến nhằm bảo tồn, thao tác và truyền bá ngữ cảnh tình huống. Chúng ta có thể sử dụng các thuộc tính này để xây dựng các phép toán áp dụng các biến đổi trên các đối tượng là thay thế cho các ví dụ học few-shot được căn chỉnh ngữ nghĩa.

--- TRANG 7 ---
Được xuất bản tại Hội nghị thứ 3 về Tác nhân Học tập Suốt đời (CoLLAs), 2024

5 FRAMEWORK SYMBOLIC AI

Trong phần này, chúng tôi thảo luận về các chi tiết cụ thể của framework SymbolicAI được đề xuất. Để biết thêm chi tiết về cấu trúc framework, xem Phụ lục Mục C. Để cài đặt và sử dụng framework của chúng tôi, xem Phụ lục Mục D. Để biết thêm chi tiết kỹ thuật và đoạn mã, xem Phụ lục Mục E.

Loại và Biểu diễn Tương tự như đối tượng type trong Python, loại cơ bản của SymbolicAI là một ký hiệu được đại diện bởi loại cơ bản Symbol. Tất cả các kiểu con khác, như Expression, đại diện cho tên toán học tương ứng của chúng và có thể được đánh giá và đơn giản hóa. Các kiểu con này kế thừa từ Symbol các thuộc tính cơ bản, toán tử nguyên thủy, và phương thức hỗ trợ.

Mặc dù SymbolicAI sử dụng thiết kế lấy ngôn ngữ làm trung tâm, việc mô hình hóa và thao tác mọi tương tác thành các biểu diễn ký hiệu không vốn dĩ hiệu quả. Do đó, chúng tôi thiết lập các ánh xạ giữa các biểu diễn ký hiệu và dưới ký hiệu cho các đầu vào cảm giác và các yếu tố không rời rạc. Các ánh xạ như vậy thường được thực hiện thông qua xấp xỉ hàm. Điều này cho phép chúng ta ánh xạ giữa các trường hợp sử dụng phương thức-to-ngôn ngữ và ngôn ngữ-to-phương thức. Ở đây, phương thức phục vụ như một placeholder cho các loại khác nhau như văn bản, hình ảnh, video, âm thanh, chuyển động, v.v. Đến lượt mình, mỗi đối tượng Symbol chứa các biểu diễn có giá trị và có giá trị vector, được thu thập thông qua các thuộc tính value và embedding. Cái sau đại diện cho giá trị hiện tại của một ký hiệu, tương tự như embedding văn bản và lưu trữ nó như một tensor PyTorch (Paszke et al., 2019) hoặc mảng NumPy (Harris et al., 2020). Trong khi đối với một LLM, các tensor số có thể thiếu ý nghĩa vốn có, các biểu diễn có giá trị vector đóng vai trò quan trọng khi 1) các ký hiệu tổ hợp được kết hợp thành các biểu thức phức tạp hơn, và 2) các tensor nhúng này được cập nhật thông qua tối ưu hóa dựa trên gradient.

Để cho phép xử lý các ký hiệu bởi LLMs, chúng tôi giả định rằng mỗi đối tượng Symbol triển khai chức năng chuỗi gốc của Python, nơi phương thức str trả về một biểu diễn chuỗi có thể diễn giải. Do đó, chúng ta có thể khẳng định rằng bất kỳ đối tượng Python nào đều có thể được phân tích bởi một LLM, tuy nhiên, người dùng phải đảm bảo một biểu diễn có ý nghĩa. Để biết thêm chi tiết, xem Phụ lục Mục E.

Ngữ cảnh Đa hình Đa hình là một khái niệm trung tâm trong lý thuyết ngôn ngữ lập trình và được thể hiện nổi bật trong SymbolicAI. Đa hình đề cập đến khả năng của các đối tượng khác nhau được truy cập thông qua cùng một giao diện, hoặc của một định danh duy nhất để đại diện cho các loại khác nhau dựa trên ngữ cảnh thực thi. Cung cấp một giao diện duy nhất cho các thực thể của các loại khác nhau cho phép các phép toán được thực hiện theo những cách cụ thể cho các loại dẫn xuất của chúng. Do đó, chúng tôi đã thiết kế đối tượng Symbol để chứa một ngữ cảnh toàn cục, được tạo thành từ các phần ngữ cảnh tĩnh và động, và cho phép hành vi đa hình này. Ngữ cảnh tĩnh phụ thuộc vào lớp và được định nghĩa tại thời điểm thiết kế. Ngữ cảnh động có thể thích ứng runtime và có thể được thay đổi để tuân thủ logic và thay đổi cụ thể runtime. Hơn nữa, các phép toán liên quan đến Symbol được giải quyết theo thiết kế đa hình trước khi được đánh giá bởi engine NeSy. Triển khai engine của SymbolicAI chứa một phương thức prepare để giải quyết và biên dịch biểu diễn cụ thể engine bằng cách đánh giá các phép toán và ngữ cảnh cụ thể Symbol. Để xem ví dụ về ngữ cảnh đa hình, xem phần a) trong Hình 3.

Toán tử và Phương thức Trong SymbolicAI, các toán tử được overload để tạo điều kiện cho các biến đổi của các đối tượng Symbol. Các nguyên hàm toán tử này sử dụng casting động để đảm bảo tương thích loại. Do đó, các đối tượng Symbol có thể được thao tác dễ dàng thông qua các attribution cụ thể loại hoặc được đánh giá một cách ký hiệu bởi engine NeSy. Ví dụ, một phép toán trung tâm cho logic boolean là đo tính bằng nhau giữa các ký hiệu. Để đánh giá tính bằng nhau của các ký hiệu, chúng tôi chủ yếu tuân thủ triển khai cụ thể loại, vì chúng tôi ưu tiên so sánh nghiêm ngặt hơn đánh giá xác suất. Nếu đánh giá không thành công, chúng tôi sau đó xem xét tính bằng nhau ngữ nghĩa thông qua engine NeSy. SymbolicAI tận dụng các decorator để tổ hợp các toán tử và phương thức lớp tùy chỉnh. Để biết thêm chi tiết, xem Phụ lục Mục C.

Khi gọi một toán tử hoặc phương thức, hàm nguyên thủy tương ứng đánh giá loại cụ thể của ký hiệu và các thuộc tính tương ứng của nó, và nếu cần thiết, giải quyết một hàm được trang trí lồng nhau sau đó sử dụng engine NeSy để đánh giá. Nếu đánh giá thất bại, một triển khai fallback được định nghĩa trước sẽ thực thi. Không có fallback, hoặc nếu cả hai đánh giá đều thất bại, một trạng thái lỗi được đưa ra. Việc xử lý một toán tử hoặc phương thức tùy chỉnh bao gồm một pipeline gồm các bước tiền xử lý và hậu xử lý, cũng như thực thi ràng buộc. Ràng buộc bao gồm các khía cạnh như loại trả về, phạm vi giá trị, và tính toàn vẹn cấu trúc (ví dụ: định dạng JSON thông qua xác minh dựa trên ngữ pháp). Trong Hình 3 b) chúng tôi đưa ra một tổng quan về toàn bộ tổ hợp prompt dựa trên đầu vào người dùng, cấu trúc đối tượng Symbol, và trong phần c) pipeline đánh giá Symbol.

Cấu trúc Tự tham chiếu SymbolicAI tăng cường quy trình sinh bằng cách cho phép các hệ thống tự kiểm tra và sửa đổi hành vi của chúng một cách động. Chúng tôi tận dụng LLMs để thực hiện các tác vụ dựa trên cả hướng dẫn ngôn ngữ tự nhiên và hình thức, tuân thủ các mục tiêu người dùng được chỉ định và với các cấu trúc tự tham chiếu bẩm sinh. Chúng tôi dẫn xuất các kiểu con từ Expression và bao gồm các chức năng của chúng trong các thành phần cụ thể tác vụ, sau đó chúng tôi tiếp tục tiết lộ thông qua

--- TRANG 8 ---
Được xuất bản tại Hội nghị thứ 3 về Tác nhân Học tập Suốt đời (CoLLAs), 2024

Symbol
Expression
SQLExpressionSQLExpression
      Cộng hai kiểu dữ liệu theo cách có ý nghĩa:   
[ 1, 2, 3 ] + 4 => Op      Ví dụ:
1, 2, 3, 4
SELECT * FROM... + SELECT * FROM... => Op      Giải:      Điều chỉnh tất cả các phép toán để đánh giá kết quả liên quan đến SQL. Symbol('SELECT  * FROM users
WHERE users.ID = 1')
                 +
Symbol('SELECT  * FROM users
WHERE users.ID = 2')
                 =
Symbol('SELECT  * FROM users
WHERE users.ID = 1 OR
users.ID = 2')Expression
      Cộng hai kiểu dữ liệu theo cách có ý nghĩa:   
[ 1, 2, 3 ] + 4 => Op      Ví dụ:
1, 2, 3, 4
Hello + World => Op      Giải:Symbol('Hello')
          +
Symbol('W orld')
          =
Symbol('Hello W orld')Polymorphic Context
User Input Args
  [Payload]
Symbol Object
   Attribute: [ Static Context ]
   Attribute: [ Dynamic Context ]
   Field: Operation
   Field: [ Examples ]
   Field: [ T emplate ]
Prompt Design
Custom Method
[ Static Context ]
Operation
[ Examples ]
[ Dynamic Context ]
[ Payload ]
User Input
   [ Template ]
< Prediction Start >
Input
Custom Method
PreProcessor
Engine
PostProcessor
Constraints
Output
Symbol Evaluation Pipeline
b)
a)
c)

Hình 3: a) Minh họa ngữ cảnh đa hình trên ví dụ của loại SQLExpression cho toán tử add. Không có ngữ cảnh đa hình, một đánh giá Expression thông thường nối hai đối tượng Symbol với nhau. Ngữ cảnh đa hình trong SQLExpression ghi đè hành vi cơ bản sao cho hai SQL-expression được cộng sẽ được kết hợp ngữ nghĩa, không phải nối. b) Minh họa việc dịch một đối tượng Symbol thành một câu lệnh prompt để được xử lý bởi một LLM trong engine NeSy. User Input Args có thể được đính kèm với Payload từ các thực thi trước và được áp dụng cho Custom Method. Đầu vào người dùng với ngữ cảnh đa hình của các thuộc tính Symbol Object (Static Context và Dynamic Context) được dịch thành một câu lệnh prompt theo lược đồ của Prompt Design. Các trường Operation, Examples và Template đánh dấu mô tả phép toán, ví dụ prompt dựa trên DSL và cấu trúc template tương ứng. Các dịch thuật này được xử lý theo PreProcessor và định dạng cụ thể engine. c) Minh họa pipeline đánh giá từ đầu vào người dùng đến đầu ra, với nhiều quy trình dịch thuật trước và sau khi gọi Engine. Input được chuyển đến Custom Method và được định dạng lại theo PreProcessor để tuân thủ cấu trúc cụ thể DSL. Engine sau đó lấy đầu ra của PreProcessor và tổ hợp prompt cuối cùng theo Prompt Design cụ thể engine và giải quyết ngữ cảnh đa hình và các trường phụ trợ. Đầu ra của Engine sau đó có thể được tái cấu trúc bởi PostProcessor để phù hợp với yêu cầu DSL của Output mong muốn và được áp dụng Constraints để xác minh kết quả.

templating và thiết kế hướng mô hình của engine NeSy. Lựa chọn thiết kế này cho phép một hệ thống tạo ra và sử dụng các định nghĩa quy trình con của chính nó, tương tự với các khái niệm được thảo luận trong Schmidhuber (2007; 2009). Cụ thể, chúng tôi sử dụng các thuộc tính tổng quát hóa của LLMs để diễn giải và hình thành một tập hợp các phép toán kết hợp các hướng dẫn tự thân (Wang et al., 2022). Do đó, các phép toán giữ tính linh hoạt để thích ứng với ngữ cảnh, và dẫn xuất các quy trình con tự hướng dẫn LLMs tham gia vào mô hình hóa tình huống và giải quyết vấn đề nhạy cảm với ngữ cảnh. Cuối cùng, điều này cho phép xây dựng các đồ thị tính toán phân cấp cho các hệ thống meta-lý luận tự tham chiếu mà không cần huấn luyện rõ ràng một meta-learner (Kirsch & Schmidhuber, 2022). Trong Hình 4 chúng tôi minh họa một đánh giá từng bước của một đồ thị tính toán theo ngữ cảnh, trong đó engine NeSy đang xử lý có điều kiện trên ngữ cảnh thực thi hiện tại và tạo ra một dự đoán ký hiệu tiếp theo.

6 THƯỚC ĐO HIỆU SUẤT

Một trong những thách thức khi tạo ra các quy trình sinh đa bước với LLMs như một phần của các engine NeSy dựa vào đánh giá mô hình và xử lý các dự đoán không liên quan. Đánh giá ngây thơ chỉ đo thành công tác vụ sẽ cho điểm tất cả các mô hình bằng không và khiến chúng trở nên không sử dụng được. Ngay cả khi các mô hình tuân theo hướng dẫn và tạo ra các phần của giải pháp mong đợi, chúng tôi thường xuyên quan sát rằng chúng — đặc biệt là các mô hình mã nguồn mở — thêm vào một phần tiếp theo của các dự đoán không liên quan đến tác vụ. Các dự đoán như vậy dẫn đến các chế độ thất bại khi áp dụng điều kiện và xác thực, và dừng bất kỳ quy trình đa bước nào. Giải pháp của chúng tôi là một giao thức đánh giá tinh chỉnh phép đo hiệu suất, cho phép chẩn đoán tinh tế hơn và khả năng tiếp tục đánh giá mặc dù có thất bại trung gian. Để dẫn xuất

--- TRANG 9 ---
Được xuất bản tại Hội nghị thứ 3 về Tác nhân Học tập Suốt đời (CoLLAs), 2024

... ... Symbol 1 Symbol 2 Tape Symbol 3Nodes1
2
33
Operation
Neuro-Symbolic Engine... Sequential Processing ...
ContextContext
Symbol 3Prediction

Hình 4: Chúng tôi thể hiện một đồ thị tính toán phân cấp đa bước, với mỗi node trong đồ thị được đại diện bởi một ký hiệu. Các cạnh là mối quan hệ giữa các ký hiệu. Phía bên trái minh họa cách một node mới (Symbol 3) được thu thập bằng cách đánh giá một phép toán với ngữ cảnh tương ứng của nó trên một engine NeSy. Phía bên phải minh họa cửa sổ thông tin ngữ cảnh (hình chữ nhật màu vàng) và mối quan hệ của đồ thị kết quả với các node tương ứng của nó.

thước đo chất lượng của chúng tôi, chúng tôi mượn ý tưởng từ việc sử dụng khoảng cách Fréchet cho các quy trình sinh (Heusel et al., 2017).

Chúng tôi tạo ra các quỹ đạo thông qua một quy trình tuần tự NeSy tạo ra một quỹ đạo của các phân phối P qua nhiều lần lặp của các node sinh. Mỗi node trong quy trình có thể được căn chỉnh với một phân phối tham chiếu, đánh dấu hành vi mong muốn. Để định lượng tính hợp lệ của các quỹ đạo được tạo ra, chúng tôi đo tổng khoảng cách giữa phân phối dữ liệu được tạo ra và tham chiếu dọc theo quỹ đạo đường dẫn. Do đó chúng tôi áp dụng một thước đo tích lũy có khả năng tính đến toàn bộ quỹ đạo sinh. Về lý thuyết, quy trình này sẽ đòi hỏi việc tính toán tích phân đường dẫn trên các biểu diễn không gian tiềm ẩn cho các mô hình, tích lũy các khoảng cách Fréchet (Dowson & Landau, 1982) được đi qua dọc theo các quỹ đạo này:

D(Pgen,Pref) =∫tf t0 d(N(mt, Ct),N(mw,t, Cw,t))dt (2)

trong đó D(Pgen,Pref) biểu thị tích phân của các khoảng cách Fréchet giữa hai phân phối dữ liệu dọc theo quỹ đạo đường dẫn sinh từ thời gian ban đầu t0 đến thời gian cuối tf, d(N(mt, Ct),N(mw,t, Cw,t)) là khoảng cách Fréchet được tính toán tại mỗi thời gian t giữa phân phối dữ liệu đa biến chuẩn được tạo ra với trung bình mt và hiệp phương sai Ct, và phân phối dữ liệu đa biến chuẩn tham chiếu với trung bình mw,t và hiệp phương sai Cw,t. Thước đo kết quả tuân theo các thuộc tính của phân phối chuẩn và nhất quán với các nhiễu loạn tăng.

Tuy nhiên, phương pháp này không khả thi về mặt tính toán cho các vấn đề quy mô lớn, và yêu cầu truy cập vào các biểu diễn tiềm ẩn, điều mà — đặc biệt trong bối cảnh LLMs — không phải lúc nào cũng có. Để khả thi về mặt tính toán, chúng tôi giới thiệu một xấp xỉ đo các khoảng cách embedding trên các quỹ đạo đường dẫn thông qua một mô hình embedding phụ trợ, dựa trên công trình trước đó về hồi quy phân phối (Szabó et al., 2016). Mô hình embedding ánh xạ các biểu diễn ký hiệu vào một RKHS, sao cho chúng ta có thể áp dụng một hàm embedding trung bình kernel để đo các khoảng cách tương ứng của chúng (You et al., 2019; Dinu et al., 2023). Chúng tôi đánh giá khoảng cách thông qua các embedding trung bình w.r.t. đến một hàm kernel K(·,·) của các mẫu etx∼νtgen∈Pgen và ety∼νtref∈Pref được tạo ra bởi phân phối dữ liệu được tạo ra và một phân phối dữ liệu tham chiếu tương ứng. Chúng tôi ký hiệu bằng μetx,μety các embedding trung bình liên quan đến các mẫu tương ứng, tức là μetx(z) =1 n∑n i=1K(xti, z) trong trường hợp etx= (xti)n i=1 là một mẫu kích thước n của các embedding trung bình tương ứng. Để tính toán sự tương tự giữa các embedding của phân phối được tạo ra và tham chiếu, chúng tôi đánh giá sự khác biệt trung bình tối đa liên quan MMD2(μetx, μety)(Gretton et al., 2012) và sau đó, như trước đây đối với các khoảng cách Fréchet, chúng tôi tích phân trên t:

D̃(Pgen,Pref) =∫tf t0 MMD2(μetx, μety)dt. (3)

Tuy nhiên, trong các đánh giá thực nghiệm, chúng tôi quan tâm đến các giá trị chuẩn hóa để dễ diễn giải. Do đó chúng tôi phân tích các thuộc tính của MMD và dẫn xuất một điểm tương tự, tuân theo các nguyên lý thống kê giống như MMD, và được giới hạn giữa [0,1]. Chúng tôi kết luận rằng chúng ta có thể chỉ sử dụng các thuật ngữ chéo MMD để đánh giá các tương tự. Xem Phụ lục Mục B để biết thêm chi tiết. Đối với các so sánh của chúng tôi như được tham chiếu trong Hình 6, chúng tôi do đó ký hiệu các tương tự thay vì khoảng cách. Sau đó chúng tôi đến với công thức sau và gọi thước đo thực nghiệm của chúng tôi là "Vector Embedding for Relational Trajectory Evaluation through Cross-similarity", hay viết tắt là điểm VERTEX:

s(Pgen,Pref) :=∫tf t0 min(max(0 ,1 ẑMMD2(μetx, μety)−zrand),1) dt. (4)

--- TRANG 10 ---
Được xuất bản tại Hội nghị thứ 3 về Tác nhân Học tập Suốt đời (CoLLAs), 2024

Chúng tôi xấp xỉ tích phân trên các bước thời gian thông qua xấp xỉ Monte Carlo. Các hằng số chuẩn hóa được giới thiệu biểu thị các tương tự với một chuỗi ngẫu nhiên zrand, hoạt động như một phép trừ baseline để tái trung tâm kết quả của chúng tôi, và một điểm tham chiếu đã cho để tái tỷ lệ w.r.t. đến điểm thu được từ việc so sánh các giải pháp liên quan z. Tỷ lệ min-max đảm bảo thước đo cuối cùng được giới hạn giữa [0,1]. Quy trình này phản ánh các thuộc tính như tính liên tục Hölder giới hạn hàm kernel trong các giới hạn nhất định. Để tính toán các embedding, chúng tôi sử dụng mô hình embedding all-mpnet-base-v2 (Song et al., 2020), do tính khả dụng rộng rãi của nó, và sự cân bằng giữa tốc độ và chất lượng. Như một thước đo tương tự, chúng tôi chọn một kernel Gaussian theo dẫn xuất của chúng tôi từ Phụ lục Mục B. Trong các triển khai của chúng tôi, chúng tôi cũng khám phá các kernel khác, bao gồm các thí nghiệm sơ bộ với tương tự cosine. Chúng tôi cũng lưu ý rằng người ta có thể tích hợp các thử nghiệm phân phối Bernoulli vào điểm của chúng tôi, với các giá trị 0 đại diện cho các chế độ thất bại và các giá trị 1 là thành công. Hơn nữa, nếu chúng ta nới lỏng định nghĩa của mình, chúng ta có thể tích hợp các thước đo tương tự khác được giới hạn giữa [0,1], sau đó phản ánh trên các attribution cụ thể miền, tức là bao gồm một thước đo tương tự được điều chỉnh hướng tới việc nắm bắt các sắc thái giữa hai cấu trúc con của cây cú pháp trừu tượng.

7 ĐÁNH GIÁ

Chúng tôi giới thiệu một benchmark đánh giá các quy trình sinh đa bước như các quy trình làm việc phức tạp. Benchmark của chúng tôi bao gồm năm danh mục đánh giá khác nhau, và sử dụng điểm VERTEX để đo khả năng của một LLM giải quyết các tác vụ từ mỗi danh mục. Năm danh mục của benchmark của chúng tôi được chia thành ba đánh giá cơ bản và hai danh mục nâng cao kết hợp các khả năng cơ bản khác nhau. Ba danh mục cơ bản là (i) dự đoán kết hợp đo khả năng thành thạo của một mô hình trong việc hiểu các kết hợp giữa các ký hiệu, (ii) liên kết đa phương thức nơi chúng tôi đánh giá khả năng sử dụng công cụ và hoạt động trên các phương thức khác nhau, và (iii) tổng hợp chương trình để đo khả năng thành thạo của một mô hình trong việc tạo ra mã nhất quán và thực thi subroutine. Hai danh mục benchmark nâng cao là (iv) logic, để đánh giá các thành phần dựa trên logic và (v) đồ thị tính toán nơi các quy trình làm việc phức tạp cần được xử lý, đánh giá tất cả các khả năng đã nêu ở trên. Để đánh giá của chúng tôi, chúng tôi tập trung vào họ mô hình GPT (Brown et al., 2020), cụ thể là GPT-3.5 Turbo (phiên bản 1106) và GPT-4 Turbo (phiên bản 1106) vì chúng là những mô hình thành thạo nhất cho đến nay; Gemini-Pro (Google, 2023) như mô hình hiệu suất tốt nhất có sẵn thông qua API từ Google; LLaMA2-Chat 13B (Touvron et al., 2023), LLaMA3-Chat 8B và LLaMA3-Chat 70B từ Meta đại diện cho các LLM mã nguồn mở. Cuối cùng, Mistral 7B (Jiang et al., 2023) và Zephyr 7B (Tunstall et al., 2023) phục vụ như baseline cho các mô hình mã nguồn mở được sửa đổi và tinh chỉnh. Các mô hình mã nguồn mở Mistral, Zephyr, và các biến thể LLaMA nhỏ hơn được ước tính có số lượng tham số tương đương so với GPT-3.5 Turbo và Gemini-Pro. Tất cả các thí nghiệm của chúng tôi yêu cầu kích thước ngữ cảnh nhỏ hơn hoặc bằng 4096 để cho phép so sánh giữa các khả năng trong ngữ cảnh trên các kiến trúc mô hình. Đối với các mô hình LLaMA, chúng tôi sử dụng các phiên bản chat vì chúng được tinh chỉnh cụ thể để tuân theo hướng dẫn.

Dự đoán Kết hợp Chúng tôi đánh giá khả năng thành thạo của một mô hình để tuân theo các hướng dẫn và kết hợp đơn giản và phức tạp với các ví dụ zero- và few-shot. Do đó, chúng tôi đánh giá khả năng thành thạo trong việc áp dụng các toán tử của chúng tôi giữa các loại Symbol. Chúng tôi định nghĩa tổng cộng 15 tác vụ liên quan đến các kết hợp trong ngữ cảnh giữa hai thể hiện Symbol. Các toán tử overloaded của SymbolicAI dựa vào các pseudo-ngữ pháp được định nghĩa trước, như được mô tả trong Mục 4, tăng cường các toán tử với các ví dụ few-shot. Ví dụ, toán tử overloaded + được sử dụng giữa hai thể hiện Symbol cung cấp các ví dụ few-shot về cách giải quyết phép cộng với các loại dữ liệu khác nhau. Do đó, chúng ta bây giờ có thể kiểm tra nếu các mô hình có thể giải quyết phép cộng giữa Symbol("two hundred and thirty four") và Symbol(7000). Xem Phụ lục Mục F.1 để biết thêm chi tiết.

Liên kết Đa phương thức Chúng tôi thực hiện các biến đổi giữa nhiều phương thức thông qua các biểu diễn dựa trên ngôn ngữ. Do đó, chúng tôi cần đánh giá khả năng thành thạo của mô hình trong việc sử dụng công cụ, phân loại và định tuyến các yêu cầu đến các module liên quan. Chúng tôi định nghĩa một Expression đa phương thức để phát hiện danh mục của một tác vụ dựa trên nội dung của nó và chuyển tiếp tác vụ đến công cụ thích hợp. Biểu thức tạo ra các giao diện đến các công cụ như WolframAlpha cho các biểu thức toán học, Selenium để cạo nội dung trang web, SerpApi cho các truy vấn tìm kiếm, và APILayer để nhận dạng ký tự quang học. Mỗi trong số năm bài kiểm tra nhằm đánh giá việc xử lý thích hợp của một loại đầu vào cụ thể bởi loại Expression đa phương thức, như xử lý URL trang web để cạo, diễn giải truy vấn công cụ tìm kiếm, kiểm tra nếu hai vector độc lập tuyến tính, so sánh các số lớn, và trích xuất văn bản từ hình ảnh. Xem Phụ lục Mục F.2 để biết thêm chi tiết.

Tổng hợp Chương trình Chúng tôi đánh giá mã thực thi có và không có các khái niệm từ tăng cường truy xuất, phát triển hướng mô hình, và thí nghiệm với các hướng dẫn tự tạo bằng cách tạo ra các biểu thức tự tham chiếu. Chúng tôi thiết kế ba bài kiểm tra riêng biệt liên quan đến tổng hợp chương trình, nơi mỗi tác vụ đánh giá khả năng của các mô hình tạo ra và thực thi mã dựa trên hướng dẫn ngôn ngữ tự nhiên hoặc các template được cung cấp:

--- TRANG 11 ---
Được xuất bản tại Hội nghị thứ 3 về Tác nhân Học tập Suốt đời (CoLLAs), 2024

1) Tác vụ đầu tiên liên quan đến việc đọc một template bảng LaTeX và dữ liệu, sau đó tạo ra một hàm để điền bảng với dữ liệu đã cho.
2) Tác vụ thứ hai kiểm tra việc tạo mã tự động cho các cuộc gọi API bằng cách lấy dữ liệu từ một URL được chỉ định và trích xuất thông tin cụ thể từ nội dung được truy xuất.
3) Tác vụ thứ ba đánh giá khả năng xây dựng một Expression tùy chỉnh xử lý một Symbol thông qua một thành phần Function cụ thể từ gói SymbolicAI.

Mỗi trong số ba bài kiểm tra tuân theo một mẫu tương tự, nơi mã được tạo ra được chấm điểm dựa trên sự tương tự của nó với các tham chiếu hợp lệ và chuẩn hóa với các mẫu ngẫu nhiên. Xem Phụ lục Mục F.3 để biết thêm chi tiết.

Thành phần Logic Để đánh giá khả năng lý luận logic của các mô hình, chúng tôi điều kiện hóa chúng để tạo ra một chuỗi các biểu thức như các thành phần độc lập, và tham chiếu đến logic bậc cao hơn để đánh giá chúng. Dựa trên lý thuyết loại cơ bản xuất phát từ Whitehead & Russell (1925–1927), chúng tôi đánh giá khả năng của một mô hình để giải quyết các câu lệnh dưới dạng tồn tại x sao cho x thỏa mãn y. Các định lượng như vậy định nghĩa ngữ nghĩa tiêu chuẩn của các biểu thức, nơi ý nghĩa của chúng được cho bởi một hàm ngữ nghĩa. Một hàm ngữ nghĩa ánh xạ một thuật ngữ từ một định nghĩa trừu tượng đến một điểm trong một miền, đó là một diễn giải của loại và giá trị của thuật ngữ. Do đó, các hàm này hoạt động trên các loại và giá trị của biểu thức, và các mối quan hệ của chúng. Tiếp theo, các engine NeSy có thể hình thành và đánh giá tại thời điểm suy luận các hướng dẫn dựa trên logic thông qua Lisp, Prolog, hoặc Mathematica (McCarthy, 1959; Colmerauer & Roussel, 1993; Chen et al., 1993; Inc., 2022), hoặc tận dụng các solver như Z3 (Moura & Bjørner, 2008). Do đó, kết quả của một câu lệnh ngôn ngữ tự nhiên khi được đánh giá bởi một engine NeSy có thể được diễn giải bởi bất kỳ hệ thống chuyên gia nào định nghĩa các hàm ngữ nghĩa tương ứng và xử lý chúng theo cách ký hiệu (Feigenbaum et al., 1965; Gamble et al., 1994), khả vi (Veličković & Blundell, 2021; Ibarz et al., 2022), hoặc hybrid (Kuncicky et al., 1991).

Chúng tôi đánh giá mức độ thành thạo của các mô hình trong việc diễn giải các DSL tùy chỉnh và định nghĩa các câu lệnh biểu thức. DSLs được thiết kế để biểu đạt các mối quan hệ và phép toán logic trong một định dạng có cấu trúc, và hỗ trợ các công thức có thể đọc được bởi con người và có thể diễn giải được bằng máy. Ví dụ sau minh họa các mối quan hệ như vậy bằng cách dịch một câu lệnh ngôn ngữ tự nhiên thành một câu lệnh biểu thức, như sau:

Marvins có bốn chân và thích kêu meo khi tôi vuốt lông của nó. Marvins có phải là mèo không?

Một DSL có thể thực thi việc sử dụng HAS (·), IS(·), v.v. và có thể điều kiện hóa một LLM để tạo ra các biểu thức sau:

• HasFourPaws (x): x có bốn chân.
• LikesToMeowWhenPetted (x): x thích kêu meo khi được vuốt ve.
• IsCat (x): x là mèo.

Những điều này sau đó được sử dụng để định nghĩa biểu thức logic sau:
∀x HasFourPaws (x)∧LikesToMeowWhenPetted (x)⇒IsCat(x).

Một công cụ chứng minh định lý tự động bây giờ có thể đánh giá câu lệnh này cho tất cả các giá trị của x và đánh giá tính hợp lệ của truy vấn ban đầu. Cuối cùng, đánh giá của chúng tôi sử dụng toán học ký hiệu để thao tác các biểu thức đại số. Điều này liên quan đến việc định nghĩa các ký hiệu và thực hiện các phép toán như nhân tử hóa, đơn giản hóa, và thao tác đại số. Các ký hiệu là các placeholder cho bất kỳ giá trị nào, cho phép định nghĩa các biểu thức tổng quát mà không cần chỉ định giá trị của chúng trước.

Chúng tôi thiết kế sáu bài kiểm tra để đánh giá khả năng logic của các mô hình ứng cử viên và nhóm chúng như sau. Xem Phụ lục Mục F.4 để biết thêm chi tiết.

1) Chúng tôi sử dụng thư viện Python SymPy cho toán học ký hiệu để tạo ra biểu thức toán học ax+bx−cx−ay−by+cy+d. Tác vụ cho mô hình sau đó là nhân tử hóa biểu thức và trích xuất tất cả các ký hiệu duy nhất dưới dạng danh sách.

2) Ba tác vụ đánh giá khả năng của một mô hình để giải quyết các phép toán logic AND, OR, và XOR. Ví dụ, bài kiểm tra cho logic AND kết hợp các ký hiệu Symbol("The horn only sounds on Sundays") và Symbol("I hear the horn") và so sánh câu trả lời với các tham chiếu do con người tạo ra "The horn only sounds on Sundays and I hear the horn." và "Since I hear the horn it is Sunday." Vì có một số lượng lớn các giải pháp có thể, có sự biến đổi cao trong không gian giải pháp. Mỗi mô hình có thể ưa thích một giải pháp khác nhau.

--- TRANG 12 ---
Được xuất bản tại Hội nghị thứ 3 về Tác nhân Học tập Suốt đời (CoLLAs), 2024

3) Đối với một tác vụ khác, chúng tôi sử dụng một Expression tùy chỉnh định nghĩa cú pháp DSL và cấu trúc ngữ nghĩa. Chúng tôi sử dụng Expression này để trích xuất các biểu thức logic bậc cao hơn từ một câu lệnh ngôn ngữ tự nhiên, cụ thể là câu đố 'Who is Jay's brother?'⁴, bảo tồn các mối quan hệ ban đầu.

4) Đối với tác vụ cuối cùng, chúng tôi lại sử dụng câu đố 'Who is Jay's brother?' để đánh giá khả năng của một mô hình đối với các chuyển đổi phức tạp. Chúng tôi sử dụng công cụ chứng minh định lý Z3 (Moura & Bjørner, 2008) để giải câu đố 'Who is Jay's brother' có điều kiện trên giải pháp của solver Z3 cho câu đố nổi tiếng của Einstein 'Who owns the fish?'. Tác vụ liên quan đến một bản dịch gián tiếp từ ngôn ngữ tự nhiên thành mã thực thi bởi solver Z3; giải pháp cho câu đố của Einstein hoạt động như một dạng "tài liệu" độc lập về cách solver Z3 nên được sử dụng. Bài kiểm tra xây dựng một template, bao gồm hướng dẫn tác vụ, câu lệnh câu đố, và tham chiếu đến giải pháp câu đố Einstein. Các mô hình sau đó được yêu cầu phân tích vấn đề đã cho và định dạng giải pháp và tạo ra một hàm Python với cú pháp Z3 có thể giải câu đố 'Who is Jay's brother?'. Mã được tạo ra động được thực thi trong môi trường kiểm tra sử dụng hàm exec của Python. Chúng tôi kiểm tra truy cập đến solver Z3 và chạy hàm solve puzzle được tạo ra được cho là chứa logic để giải câu đố. Khi được thực thi, các mệnh đề logic Z3 được lắp ráp được xử lý bởi solver, xác minh rằng tập hợp các ràng buộc là thỏa mãn. Nếu vậy, mô hình được tạo ra bởi solver được truy vấn để tìm giải pháp của câu đố và được chấm điểm bằng điểm VERTEX của chúng tôi.

Đồ thị Tính toán Phân cấp Chúng tôi đánh giá khả năng của các mô hình để điều phối một quy trình sinh đa bước và đánh giá một tập hợp các tác vụ. Các mô hình cần hướng dẫn các quy trình con và kết hợp các kết quả tính toán từ và đến các node Symbol, và duy trì các mối quan hệ giữa các node này, mà chúng tôi gọi là một đồ thị tính toán như được thể hiện trong Hình 5. Trong một đồ thị tính toán, điểm VERTEX so sánh các kết quả được tạo ra bởi một mô hình sinh tại mỗi node với các mẫu thu được từ một phân phối tham chiếu, thường được mô hình hóa bằng cách lấy mẫu từ nhiều tham chiếu hợp lệ. Chúng tôi cũng tính đến tính ngẫu nhiên thông qua các mẫu ngẫu nhiên được định nghĩa trước để chuẩn hóa kết quả. Tham chiếu của chúng tôi đến đồ thị tính toán phân cấp xuất phát từ thực tế là chúng tôi hoạt động trên nhiều cấp độ. Ở cấp độ trừu tượng cao hơn, chúng tôi có thể thực hiện lập kế hoạch, lập lịch tác vụ phụ, và định nghĩa các hướng dẫn hoạt động. Ở cấp độ trừu tượng thấp hơn, chúng tôi thực thi các kế hoạch này dựa trên các hướng dẫn và dữ liệu được định nghĩa, cũng có thể bao gồm các quy trình sinh tạo ra thông tin mới.

Hình 5: Chúng tôi minh họa đồ thị tính toán phân cấp cho biểu thức Paper. Mỗi node đại diện cho một thể hiện của một biểu thức với các thuộc tính và hành vi riêng biệt, như tìm nguồn tệp, quy trình sinh, sử dụng công cụ, hoặc phép toán biến đổi. Các cạnh biểu thị các mối quan hệ tham chiếu giữa các biểu thức và chỉ ra luồng thông tin. Các node được tô màu xanh đánh dấu các node chuỗi chính của các biểu thức được sử dụng để tạo ra các phần của bản thảo bài báo, như phần Method, phần RelatedWork, phần Abstract, và vân vân. Mỗi node sinh được sử dụng để đánh giá điểm VERTEX. Các node không sinh như kết quả công cụ tìm kiếm không được đánh giá, và chúng tôi giả định thu được các giá trị ground-truth.

Cho rằng lĩnh vực này hiện đang ở giai đoạn đầu trong việc phát triển thậm chí các bộ lập lịch tuần tự cho các hệ thống lập kế hoạch dựa trên LLM, các đánh giá của chúng tôi sẽ được giới hạn chỉ trong việc thực thi tuần tự. Chúng tôi giới thiệu hai bài kiểm tra được thiết kế để đánh giá các quy trình sinh đa bước:

1) Chúng tôi mô phỏng và đánh giá quy trình viết một bản thảo bài báo nghiên cứu dựa trên một đồ thị tính toán phân cấp được định nghĩa trước tập trung vào đầu ra nội dung của đồ thị tính toán thay vì chức năng lập kế hoạch và lập lịch. Xem Phụ lục Mục F.5 để biết thêm chi tiết.

2) Chúng tôi kiểm tra Giao thức VERTEX như được định nghĩa trong Thuật toán 1, đại diện cho phương pháp tổng quát của chúng tôi để đánh giá các quy trình sinh đa bước. Chúng tôi tạo ra một kịch bản kiểm tra độc lập để minh họa một đánh giá end-to-end và như một tham chiếu để biết cách giao thức của chúng tôi có thể được triển khai trong một môi trường thực tế. Giao thức đánh giá của chúng tôi không chỉ được thiết kế để phân tích và chấm điểm một loạt hướng dẫn, mà còn cung cấp một cơ sở có cấu trúc để ghi lại những điều này.

⁴Bob có hai con trai, John và Jay. Jay có một anh trai và cha. Người cha có hai con trai. Anh trai của Jay có một anh trai và một cha. Anh trai của Jay là ai?

--- TRANG 13 ---
Được xuất bản tại Hội nghị thứ 3 về Tác nhân Học tập Suốt đời (CoLLAs), 2024

quy trình. Hơn nữa, chúng tôi lưu ý rằng giao thức đánh giá của chúng tôi được hình thành một cách tổng quát, cho phép áp dụng lập kế hoạch và lập lịch phi tuần tự.

Thuật toán 1 Giao thức VERTEX
Yêu cầu: Engine NeSy V như một LLM, engine embedding E: Σ→ H ⊂ Rd, các ký hiệu {x0, x∗, y∗} ⊂Σ, với x0 như hướng dẫn ban đầu, x∗ như payload kết quả từ việc thực thi V, y∗ như tham chiếu, và ∗ hoạt động như placeholder cho P,T,C, các khả năng C={F1,F2,F3, . . .}, trong đó mỗi Fi đại diện cho một vai trò chức năng cụ thể trong hệ thống, kế hoạch P ⊂Σ, tác vụ T ∈ P, bộ đệm bộ nhớ M ⊂ Σ, một hàm chấm điểm s̃:H × H → [0,1], một bộ lập lịch Q, một bộ tổng hợp A, và các biến điểm {s} ∈[0,1].

Phương pháp:
1:V,E,Q,C, yP←INIT(·) ▷Khởi tạo engines, bộ lập lịch, khả năng, kế hoạch dự kiến.
2:M ← ∅ ,A ← ∅ ▷Khởi tạo bộ đệm bộ nhớ và bộ tổng hợp.
3:xP←GENERATE PLAN(x0,V) ▷V tạo kế hoạch dựa trên hướng dẫn ban đầu.
4:EVALUATE (xP, yP,E,A,s̃) ▷Embed, chấm điểm, và tổng hợp sự tương tự kế hoạch.
5:P,M ← UNFOLD PLAN(yP,M,Q) ▷Q mở rộng kế hoạch thành các tác vụ có thể thực hiện và cập nhật tiến trình.
6:while P ̸=∅do ▷Chạy cho đến khi danh sách tác vụ cạn kiệt.
7: T, yC, yT←SELECT (M,V) ▷V chọn tác vụ tiếp theo dựa trên tiến trình tác vụ.
8: Fi←IDENTIFY (T,C,V) ▷V xác định khả năng liên quan đến tác vụ Fi.
9: xC, xT←EXECUTE (T,Fi,Q) ▷Q thực thi T với khả năng Fi và gán kết quả xC, xT.
10: EVALUATE (xC, yC, xT, yT,E,A,s̃) ▷Embed, chấm điểm, và tổng hợp sự tương tự khả năng.
11: P,M ← UPDATE (T,P,M,Q) ▷Q cập nhật kế hoạch và tiến trình.
12:end while
13:s←FINALIZE (A) ▷Hoàn thành tổng hợp điểm.
14:return s ▷Trả về điểm tổng hợp của việc thực thi kế hoạch.

Thuật toán 1: Thuật toán này định nghĩa pseudocode của giao thức VERTEX của chúng tôi với điểm VERTEX tương ứng của chúng tôi như một tiêu chí chấm điểm. Chúng tôi bắt đầu bằng cách khởi tạo engine NeSy V, engine embedding E, bộ lập lịch Q, và một tập hợp các khả năng C. Hướng dẫn ban đầu x0 được sử dụng để tạo ra một kế hoạch xP thông qua V. Kế hoạch và kết quả dự kiến yP được embed, và sự tương tự của chúng được chấm điểm theo điểm VERTEX của chúng tôi và được tổng hợp. Kế hoạch sau đó được mở rộng thành các tác vụ có thể thực hiện. Mỗi tác vụ T được chọn và thực thi với khả năng C thích hợp, dẫn đến kết quả khả năng và tác vụ xC, xT, và kết quả dự kiến yC, yT được cập nhật trong bộ đệm bộ nhớ M. Quy trình tiếp tục, với kết quả của mỗi tác vụ được embed, chấm điểm, và tổng hợp cho đến khi kế hoạch hoàn thành. Điểm tổng hợp cuối cùng s được trả về, phản ánh hiệu quả tổng thể của việc thực thi kế hoạch.

Chúng tôi bắt đầu với một mô tả quy trình làm việc cấp cao bao gồm một danh sách các tác vụ và tùy chọn các tác vụ phụ tương ứng của chúng; chúng tôi gọi đây là kế hoạch P. Để thực hiện thí nghiệm, chúng tôi sử dụng một kế hoạch dự kiến yP được tạo thủ công cho đánh giá này. Kế hoạch dự kiến là một hàng đợi các tác vụ được định nghĩa trước (theo một thứ tự cụ thể) mà hệ thống nên tuân theo để đạt được mục tiêu. Câu lệnh mục tiêu định nghĩa mục tiêu cuối mà quy trình làm việc nhằm hoàn thành. Chúng tôi cũng có một tập hợp các kế hoạch tương tự như kế hoạch dự kiến, đó là các quỹ đạo trong không gian giải pháp, cũng như kế hoạch xP mà LLM tạo ra sử dụng cuộc gọi GENERATE PLAN cho một seed cụ thể. Chúng tôi chấm điểm kế hoạch được dự đoán với kế hoạch dự kiến và các quỹ đạo, sau đó chúng tôi tiếp tục đến giai đoạn tiếp theo trong đó chúng tôi sử dụng kế hoạch dự kiến để thực thi các tác vụ. Tại mỗi bước, LLM sẽ nhận trong ngữ cảnh của nó mục tiêu, các tác vụ, tiến trình hiện tại, và một truy vấn yêu cầu tác vụ tiếp theo để thực thi; chúng tôi gọi đây là bộ đệm bộ nhớ M. Nếu LLM không thể dự đoán tác vụ tiếp theo, nó sẽ trả về một thất bại, và kế hoạch dự kiến sẽ được sử dụng để thực thi tác vụ tiếp theo. LLM có quyền truy cập vào một tập hợp các khả năng C được định nghĩa trước, cụ thể là WolframAlpha, SerpApi, Selenium, và chính LLM, cũng đại diện cho cấu trúc tự tham chiếu của chúng tôi. Chúng tôi tiếp tục thực thi các tác vụ cho đến khi hàng đợi cạn kiệt, và tại mỗi bước, chúng tôi sử dụng cuộc gọi EVALUATE để đo hiệu suất của LLM với điểm VERTEX của chúng tôi. Lớp bộ lập lịch Q giám sát việc thực thi quy trình làm việc kiểm tra. Nó lấy cấu hình thiết lập và điều phối việc thực thi tuyến tính các tác vụ, sử dụng kế hoạch dự kiến như một tham chiếu. Nó duy trì một pool các tác vụ cần được thực thi và cập nhật tiến trình khi các tác vụ được hoàn thành. Cuộc gọi UNFOLD PLAN là một phương thức của lớp bộ lập lịch Q. Phương thức gọi chính nó một cách đệ quy cho đến khi không còn tác vụ nào. Cuộc gọi SELECT chịu trách nhiệm xác định tác vụ nào để thực thi tiếp theo từ một pool các tác vụ còn lại. Nó sử dụng LLM thông qua tự phản chiếu (Shinn et al., 2023) để chọn tác vụ tiếp theo phù hợp nhất dựa trên một template được cập nhật dần dần trong bộ đệm bộ nhớ M bởi cuộc gọi UPDATE. Cuộc gọi IDENTIFY sử dụng tự phản chiếu và chấm điểm tương tự để xác định giao diện tốt nhất dựa trên tác vụ hiện tại, sau đó chuyển giao diện đến cuộc gọi EXECUTE để thực thi tác vụ. Cuối cùng, bài kiểm tra kết thúc với cuộc gọi FINALIZE, cung cấp một đánh giá tổng hợp về khả năng của mô hình để quản lý và thực thi quy trình làm việc.

--- TRANG 14 ---
Được xuất bản tại Hội nghị thứ 3 về Tác nhân Học tập Suốt đời (CoLLAs), 2024

Trong Hình 6 chúng tôi kết thúc với đánh giá của chúng tôi và tính toán điểm tích lũy cho tất cả các danh mục đánh giá được mô tả và trong phần tiếp theo chúng tôi thảo luận cách diễn giải kết quả của framework của chúng tôi.

Associations
Modality
Code LogicGraphs
0.20.40.60.8GPT-4 Turbo
GPT-3.5 Turbo
RandomLLaMA 2 13B
LLaMA 3 8BLLaMA 3 70B
Mistral 7BZephyr 7B
Gemini 1.0 Pro

Hình 6: Chúng tôi đánh giá GPT-4 Turbo, GPT-3.5 Turbo, Gemini-1.0 Pro, LLaMA2-Chat 13B, LLaMA3-Chat 8B, LLaMA3-Chat 70B, Mistral 7B và Zephyr 7B trên năm danh mục benchmark: 1) Dự đoán Kết hợp (Association) 2) Liên kết Đa phương thức (Modality) 3) Tổng hợp Chương trình (Code) 4) Thành phần Logic Chức năng (Logic) và 5) Đồ thị Tính toán Phân cấp (Graphs). Chúng tôi biểu thị điểm VERTEX cho mỗi danh mục như một giá trị chuẩn hóa giữa 0 và 1, trong đó giá trị cao hơn tốt hơn. Điểm VERTEX được đo theo một baseline tham chiếu và được chuẩn hóa bởi các chuỗi ngẫu nhiên để loại trừ nhiễu và sự tương tự giữa các phân phối tham chiếu để tái tỷ lệ các giải pháp. Các điểm được hiển thị là trung bình trên tất cả các bài kiểm tra cho mỗi danh mục và trên 8 seed khác nhau cho mỗi bài kiểm tra.

[THIS IS TABLE: Benchmark results showing scores for different models across categories]
Benchmarks | GPT-4 Turbo | GPT-3.5 Turbo | Gemini 1.0 Pro | LLaMA 2 13B | LLaMA 3 8B | LLaMA 3 70B | Mistral 7B | Zephyr 7B | Random
Associations | 0.94 | 0.51 | 0.93 | 0.40 | 0.46 | 0.57 | 0.46 | 0.27 | 0.08
Modality | 0.83 | 0.65 | 0.81 | 0.50 | 0.43 | 0.63 | 0.39 | 0.43 | 0.07
Code | 0.75 | 0.63 | 0.61 | 0.13 | 0.25 | 0.30 | 0.19 | 0.13 | 0.00
Logic | 0.48 | 0.46 | 0.28 | 0.46 | 0.21 | 0.11 | 0.53 | 0.47 | 0.00
Graphs | 0.39 | 0.34 | 0.26 | 0.06 | 0.05 | 0.15 | 0.03 | 0.03 | 0.00
Total | 0.68 | 0.52 | 0.58 | 0.31 | 0.28 | 0.35 | 0.32 | 0.27 | 0.03

8 THẢO LUẬN

Trong phần này, chúng tôi giải quyết các kết quả đánh giá, các phát hiện phụ trợ và hạn chế của SymbolicAI và các hướng tương lai mà chúng tôi đang tập trung. Một số hạn chế xuất phát từ các ràng buộc vốn có của các công nghệ hiện tại và sự phụ thuộc vào các hệ thống bên thứ ba. Ngoài ra, sự phức tạp tinh tế của việc làm việc với các mô hình sinh đưa ra những thách thức thêm.

8.1 KẾT QUẢ

Trong Hình 6 chúng tôi hiển thị điểm VERTEX cho tất cả năm danh mục đánh giá trên 8 mô hình tiên tiến khác nhau. Chúng tôi hiển thị các kết quả tổng hợp cho mỗi danh mục, có nghĩa là điểm trung bình giữa tất cả các bài kiểm tra được tính trung bình cho mỗi danh mục và trung bình trên 8 seed khác nhau cho mỗi bài kiểm tra. Điểm VERTEX được chuẩn hóa giữa 0 và 1, trong đó giá trị cao hơn tốt hơn. Điểm của chúng tôi là phi tuyến do bản chất sử dụng các kernel phi tuyến, và nắm bắt các cấu trúc ngữ nghĩa, thứ tự và tương đối giữa các mẫu dữ liệu. Tuy nhiên, vì điểm của chúng tôi phụ thuộc cao vào chất lượng của mô hình embedding cơ bản, nó có thể bỏ qua việc nắm bắt các khác biệt cú pháp tinh tế như 'Hello' vs 'hello'.

Trong các thí nghiệm của chúng tôi, chúng tôi đã nhận thấy rằng đối với dự đoán kết hợp và liên kết đa phương thức, GPT-4 Turbo ngang bằng với Gemini-1.0 Pro. Hơn nữa, vẫn còn một khoảng cách lớn giữa các đối thủ mã nguồn mở như LLaMA 3 thậm chí với 70B tham số so với các lựa chọn thay thế nguồn đóng từ OpenAI và Google. Đối với phần còn lại của các thí nghiệm, chúng tôi thấy rằng GPT-4 hầu như luôn vượt trội hơn tất cả các mô hình khác, trừ danh mục thành phần logic chức năng. Ở đây, chúng tôi đã phân tích kết quả và phát hiện rằng các mô hình lớn hơn đôi khi đi tắt bằng cách tự động trả về giải pháp và trả lời rằng hướng dẫn tác vụ quá phức tạp cho một truy vấn câu đố đơn giản như vậy. Tuy nhiên, chúng tôi muốn nói chung rằng đối với các tác vụ dựa trên logic, lập kế hoạch và lập lịch, tất cả các mô hình hoạt động không đáng tin cậy, ngay cả khi những khác biệt hiệu suất nhỏ giữa các mô hình được thấy trong biểu đồ. Chúng tôi tin rằng điều này một phần do thiếu dữ liệu huấn luyện cụ thể cho quy trình làm việc, lập kế hoạch và lập lịch các tác vụ, và do sự không chính xác trong việc tạo ra các định dạng đầu ra có cấu trúc đáng tin cậy, như DSL tùy chỉnh hoặc các định dạng được hướng dẫn trong ngữ cảnh tùy chỉnh khác. Điều này cũng xuất phát từ việc tinh chỉnh hướng dẫn của chúng, vì hầu hết các mô hình là các mô hình dựa trên chat và cung cấp các phản hồi dài dòng cần được kiềm chế hoặc hậu xử lý.

Chúng tôi thấy hiệu suất tương tự giữa GPT-3.5 Turbo và LLaMA 3 70B trừ các đánh giá logic và đồ thị. Chúng tôi phát hiện rằng LLaMA 3 70B có xu hướng đặt câu hỏi ngược lại nếu nó không hiểu yêu cầu thay vì tuân theo hướng dẫn cụ thể được cung cấp. Chúng tôi cho rằng điều này cũng xuất phát từ việc tinh chỉnh hướng dẫn dựa trên chat. Zephyr 7B và Mistral 7B đã cho thấy khả năng ngang bằng trong các thành phần logic chức năng với các mô hình lớn hơn, tuy nhiên thất bại trong các thí nghiệm tổng hợp chương trình và đồ thị tính toán phân cấp. Chúng tôi quan sát rằng chúng hoạt động tốt khi giải quyết các toán tử logic overloaded như OR, AND và XOR, và cho thấy hiệu suất khá tốt cho tạo văn bản, nhưng thất bại trong việc giải quyết các hướng dẫn phức tạp hơn.

8.2 HẠN CHẾ

Framework Vì framework giao tiếp với nhiều công cụ và dịch vụ API, nó yêu cầu một nỗ lực kỹ thuật đáng kể để tích hợp tất cả các chức năng có sẵn và giữ cho các dịch vụ dựa trên API được cập nhật. Đối với chúng tôi điều này có nghĩa là, mặc dù chúng tôi hỗ trợ nhiều công cụ và framework khác nhau như Selenium, WolframAlpha, hoặc Z3, chúng tôi chỉ chạm đến bề mặt của những công cụ này. Hơn nữa, việc sử dụng xác thực ràng buộc dựa trên ngữ pháp vẫn còn thử nghiệm và hạn chế về chức năng cho các định dạng cụ thể như JSON và HTML. Cuối cùng, chúng tôi cũng gặp phải những thách thức liên quan đến kỹ thuật song song hóa và đa xử lý của các prompt, vì việc thực thi đồng thời là không trivial, đặc biệt với những phức tạp của quản lý quy trình Python.

Thước đo Embedding Thước đo thực nghiệm của chúng tôi bị hạn chế bởi tính biểu đạt của mô hình embedding và mức độ nó nắm bắt các sắc thái trong sự tương tự giữa hai biểu diễn. Hơn nữa, các điểm tương tự thu được là phi tuyến cao và khó diễn giải. Ví dụ, hai biểu diễn có thể giải quyết cùng một chủ đề, như mô tả vấn đề và giải pháp tương ứng của nó, tuy nhiên, khi đo sự tương tự của chúng, chúng tôi thu được điểm tương tự ~70%. Chúng tôi chuẩn hóa điều này bằng cách trừ một baseline vốn có và hiệu ứng ngẫu nhiên, tuy nhiên, để đảm bảo một phép đo tổng thể và mạnh mẽ hơn, chúng tôi sẽ cần một lượng lớn hơn đáng kể các baseline và thí nghiệm. Vì chúng tôi rất hạn chế về tính khả dụng của các tài nguyên phát triển, và một số mô hình được trình bày chỉ có thể truy cập thông qua các bức tường API tốn kém. Chúng tôi đang tích cực tìm kiếm các nhà tài trợ để mở rộng giải pháp của chúng tôi và cung cấp một bộ benchmark hấp dẫn hơn trong tương lai.

Khả năng Mô hình Một hạn chế rõ ràng xoay quanh kích thước cửa sổ ngữ cảnh cố định của các mô hình ngôn ngữ cơ bản. Mặc dù có sự mở rộng cửa sổ ngữ cảnh trong các mô hình mới hơn như GPT-4, ngữ cảnh hữu hạn vẫn hạn chế lượng dữ liệu có thể được xử lý trong một lần chuyển duy nhất. Tất cả thông tin ngoài ngữ cảnh cần được thêm vào thông qua các phương pháp truy xuất thông tin, đi kèm với những thách thức và hạn chế riêng của chúng (Gao et al., 2023). Điều này dẫn đến các tác dụng phụ, bao gồm ảo giác, cho rằng mô hình không chứa thông tin cần thiết để trả lời hướng dẫn được prompt, điều này làm cho việc duy trì trạng thái dài hạn cho các tác vụ lý luận phức tạp và đồ thị tính toán trở nên khó khăn.

Xử lý Lỗi Độ phức tạp của xử lý lỗi khi đánh giá các biểu thức phức tạp thông qua chức năng tổ hợp, đặc biệt giữa nhiều phương thức và các solver khác nhau, là một thách thức đáng chú ý khác. Trong khi SymbolicAI giới thiệu các cơ chế để phân tích lỗi và sửa chữa tự động, các phương pháp này không thể sai sót được. Chúng thường bị hạn chế bởi chất lượng và tính biểu đạt của các mô hình, và khả năng của mô hình để hiểu các cấu trúc logic lồng nhau sâu. Chúng tôi cũng lưu ý rằng đối với các đánh giá của chúng tôi, chúng tôi đã vô hiệu hóa bất kỳ giao thức khắc phục nào, như cắt bớt prompt hoặc lược đồ thử lại.

Tổng quát hóa Nghiên cứu này cũng bị hạn chế bởi khả năng lý luận và tổng quát hóa hiện tại của LLM. Mặc dù đã có tiến bộ, các mô hình vẫn dễ bị ảo giác và lỗi lý luận, đặc biệt khi xử lý các câu lệnh vấn đề trừu tượng, mới lạ, hoặc rất phức tạp (Marcus, 2020). Hơn nữa, sự phụ thuộc của framework chúng tôi vào khả năng của mô hình để nắm bắt ngữ nghĩa của các phép toán có thể bị ảnh hưởng bởi dữ liệu huấn luyện và các bias và hiểu biết khái niệm bẩm sinh của mô hình (Mahowald et al., 2023). Chúng tôi cũng chỉ ra rằng việc phát triển ban đầu của SymbolicAI bắt đầu với họ mô hình GPT, và chúng tôi có thể gặp phải các bias bẩm sinh trong thiết kế prompt và tính biểu đạt khi sử dụng các mô hình tham chiếu khác. Tuy nhiên, chúng tôi cũng chỉ ra rằng kỹ thuật prompt engineering các câu lệnh dựa trên hướng dẫn không phải là một hướng đáng tin cậy để cải thiện. Thay vào đó chúng tôi ủng hộ việc nâng cao khả năng phục hồi của các mô hình thông qua khả năng chịu lỗi, tập trung vào khả năng của chúng để tuân theo các hướng dẫn ngữ nghĩa tốt hơn, không phải các đặc thù cú pháp. Một mối quan tâm khác là cách đánh giá sự phân tách của các đánh giá mô hình trên các tác vụ downstream, để tránh kiểm tra trên các mẫu huấn luyện, đặc biệt đối với các giải pháp nguồn đóng như GPT.

Khả năng Diễn giải và Minh bạch Cuối cùng, vấn đề về khả năng giải thích và minh bạch trong các hệ thống AI vẫn còn thách thức. Trong khi SymbolicAI thực hiện các bước hướng tới việc làm cho các quy trình tính toán rõ ràng và có thể giải thích hơn thông qua các thao tác ký hiệu, việc hiểu logic nội tại và ra quyết định của LLMs vẫn là một vấn đề mở. Điều này có thể cản trở niềm tin và việc áp dụng trong các ứng dụng nhạy cảm nơi khả năng diễn giải của dự đoán là quan trọng.

--- TRANG 15 ---
Được xuất bản tại Hội nghị thứ 3 về Tác nhân Học tập Suốt đời (CoLLAs), 2024

8.3 CÔNG TRÌNH TƯƠNG LAI

Mục tiêu cho Thuật toán 1 là được sử dụng bởi một tác nhân học tập tiên tiến. Tác nhân này, sử dụng các phương pháp học tăng cường (Ouyang et al., 2022; Li et al., 2023; Rafailov et al., 2023), có thể tận dụng thước đo đánh giá của chúng tôi trong các benchmark hiện có (Milani et al., 2020; Swazinna et al., 2022; Schweighofer et al., 2022) như một phương tiện để thu thập tín hiệu phần thưởng để giải quyết một vấn đề trung tâm trong học tăng cường, cụ thể là gán tín dụng (Sutton, 1984; Arjona-Medina et al., 2019; Holzleitner et al., 2020; Patil et al., 2020; Widrich et al., 2021; Dinu et al., 2022). Theo thời gian, nó nhằm phát triển khả năng tạo ra các kế hoạch của riêng mình một cách tự động, lập lịch các tác vụ và tác vụ phụ một cách hiệu quả, và cẩn thận chọn các công cụ phù hợp nhất cho mỗi tác vụ. Giao thức của chúng tôi đặt nền móng cho tác nhân này để học và mở rộng tập hợp khả năng cơ bản của nó (Amaro et al., 2023), di chuyển hướng tới việc điều phối tinh vi hơn, tự tham chiếu của các tác vụ đa bước. Chúng tôi đã nhận thấy rằng nghiên cứu đang chuyển hướng tới loại phương pháp này (Yuan et al., 2024).

Hơn nữa, trong Mục 7 chúng tôi chỉ xem xét một bộ lập lịch tuần tự. Tuy nhiên, mục tiêu của chúng tôi là cuối cùng đánh giá một mô hình thực thi tác vụ phi tuần tự, cho phép chèn động và thực thi tác vụ ngoài thứ tự. Ngoài ra, chúng tôi quan tâm đến việc khám phá sự tương tự của công trình của chúng tôi với Generative Flow Networks (Bengio et al., 2021a;b; Lahlou et al., 2023). Cuối cùng, chúng tôi cũng thảo luận các hạn chế trong Phụ lục Mục 8.2 với các cơ hội thêm cho cải tiến tương lai.

9 KẾT LUẬN

Trong công trình này, chúng tôi đã giới thiệu SymbolicAI, một framework thống nhất các mô hình sinh với một loạt các solver, pha trộn thế mạnh của các mô hình AI ký hiệu và dưới ký hiệu trong một framework NeSy gắn kết. SymbolicAI trang bị cho các nhà nghiên cứu và thực hành viên một bộ công cụ toàn diện để phát triển các hệ thống AI NeSy theo ngữ cảnh và có thể giải thích được có khả năng giải quyết các thách thức đa dạng một cách hiệu quả. Chúng tôi cũng giới thiệu một thước đo chất lượng và một benchmark để so sánh và đánh giá một loạt các tác vụ tính toán. SymbolicAI cung cấp một cơ sở cho nghiên cứu thêm trong tổng hợp chương trình tiên tiến, đồ thị tính toán phân cấp, phát triển các hệ thống tự tham chiếu, và tích hợp các phương pháp xác suất với thiết kế AI để tạo ra các tác nhân tự động.

LỜI CẢM ƠN

ELLIS Unit Linz, LIT AI Lab, Institute for Machine Learning, được hỗ trợ bởi Federal State Upper Austria. Chúng tôi cảm ơn các dự án Medical Cognitive Computing Center (MC3), INCONTROL-RL (FFG-881064), PRIMAL (FFG-873979), S3AI (FFG-872172), DL for GranularFlow (FFG-871302), EPILEPSIA (FFG-892171), AIRI FG 9-N (FWF-36284, FWF-36235), AI4GreenHeatingGrids (FFG- 899943), INTEGRATE (FFG-892418), ELISE (H2020-ICT-2019-3 ID: 951847), Stars4Waters (HORIZON-CL6-2021-CLIMATE-01-01). Chúng tôi cảm ơn Audi.JKU Deep Learning Center, TGW LOGISTICS GROUP GMBH, Silicon Austria Labs (SAL), FILL Gesellschaft mbH, Anyline GmbH, Google, ZF Friedrichshafen AG, Robert Bosch GmbH, UCB Biopharma SRL, Merck Healthcare KGaA, Verbund AG, GLS (Univ. Waterloo), Software Competence Center Hagenberg GmbH, Borealis AG, TÜV Austria, Frauscher Sensonic, TRUMPF, NVIDIA Corporation và Atlas.

Chúng tôi bày tỏ sự tri ân của mình đối với Andreas Windisch và Clemens Wasner của AI Austria vì sự hỗ trợ không ngừng của họ. Phản hồi có giá trị, kết nối, và việc tạo điều kiện giới thiệu trong mạng lưới rộng lớn của họ đã là công cụ cho sự tiến bộ của ExtensityAI.

Lòng biết ơn của chúng tôi cũng dành cho Sergei Pereverzyev, người có sự hướng dẫn sáng suốt và những ý tưởng chu đáo đã là ngọn hải đăng cho các nỗ lực nghiên cứu của chúng tôi. Sự cảm ơn của chúng tôi cũng được mở rộng đến Gary Marcus, những cuộc thảo luận kích thích của ông đã tạo ra nhiều ý tưởng sáng tạo được tích hợp vào framework của chúng tôi.

Chúng tôi cũng biết ơn Markus Hofmarcher, một người bạn và đồng nghiệp có lời khuyên thông thái và những cuộc thảo luận kích thích đã làm sắc bén đáng kể nhiều khía cạnh của nghiên cứu của chúng tôi. Ngoài ra, lời cảm ơn của chúng tôi dành cho Fabian Paischer và Kajetan Schweighofer, có công trình sơ bộ và hỗ trợ đã mang lại lợi ích to lớn.

Chúng tôi cũng biết ơn các bạn John Chong Min Tan và Tim Scarfe, có cộng đồng đã là trung tâm cho những cuộc thảo luận hứng thú. Sự hiện diện trực tuyến và sự tham gia của họ đã làm phong phú cảnh quan nghiên cứu AI và mở rộng góc nhìn của chúng tôi.

Hơn nữa, chúng tôi muốn tôn vinh ký ức của những thành viên gia đình yêu quý mà chúng tôi đã mất trong năm 2023. Ảnh hưởng của họ trong cuộc sống của chúng tôi vượt ra ngoài những mối liên kết cá nhân, và những nguyên tắc họ thấm nhuần trong chúng tôi tiếp tục định hình hành trình của chúng tôi. Với sự tôn trọng và tình cảm lớn, chúng tôi thừa nhận tác động không thể xóa nhòa mà họ đã tạo ra, cho phép chúng tôi kiên trì trong các hoạt động khoa học với quyết tâm và sự liêm chính.

--- TRANG 16 ---
[Phần tài liệu tham khảo tiếp tục...]

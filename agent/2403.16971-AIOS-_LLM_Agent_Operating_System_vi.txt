AIOS: Hệ điều hành tác nhân LLM
Kai Mei1, Xi Zhu1, Wujiang Xu1, Mingyu Jin1, Wenyue Hua1,
Zelong Li1, Shuyuan Xu1, Ruosong Ye1, Yingqiang Ge1, Yongfeng Zhang1,2
1Rutgers University,2AIOS Foundation
research@aios.foundation
Các tác nhân thông minh dựa trên LLM đối mặt với những thách thức triển khai đáng kể, đặc biệt liên quan đến quản lý tài nguyên. Việc cho phép truy cập không hạn chế vào LLM hoặc tài nguyên công cụ có thể dẫn đến phân bổ và sử dụng tài nguyên không hiệu quả hoặc thậm chí có thể gây hại cho các tác nhân. Hơn nữa, việc thiếu các cơ chế lập lịch và quản lý tài nguyên phù hợp trong thiết kế tác nhân hiện tại cản trở xử lý đồng thời và hạn chế hiệu quả tổng thể của hệ thống. Để giải quyết những thách thức này, bài báo này đề xuất kiến trúc của AIOS (Hệ điều hành tác nhân AI dựa trên LLM) trong bối cảnh quản lý các tác nhân dựa trên LLM. Nó giới thiệu một kiến trúc mới để phục vụ các tác nhân dựa trên LLM bằng cách cách ly tài nguyên và các dịch vụ đặc thù LLM khỏi ứng dụng tác nhân vào một nhân AIOS. Nhân AIOS này cung cấp các dịch vụ cơ bản (ví dụ: lập lịch, quản lý ngữ cảnh, quản lý bộ nhớ, quản lý lưu trữ, kiểm soát truy cập) cho các tác nhân runtime. Để tăng cường khả năng sử dụng, AIOS cũng bao gồm một AIOS SDK, một bộ API toàn diện được thiết kế để sử dụng các chức năng được cung cấp bởi nhân AIOS. Kết quả thực nghiệm chứng minh rằng việc sử dụng AIOS có thể đạt được tốc độ thực thi nhanh hơn tới 2.1× cho việc phục vụ các tác nhân được xây dựng bởi các framework tác nhân khác nhau.
Kho mã AIOS : https://github.com/agiresearch/AIOS
Kho mã AIOS SDK : https://github.com/agiresearch/Cerebrum
Demo trực tiếp : https://app.aios.foundation
1. Giới thiệu
Trong lĩnh vực tác nhân tự động, các nỗ lực nghiên cứu (Wooldridge và Jennings, 1995, Jennings et al., 1998, Bresciani et al., 2004) được thực hiện hướng tới các tác nhân có thể cảm nhận môi trường, hiểu hướng dẫn, đưa ra quyết định, hành động và học từ phản hồi. Sự xuất hiện của các mô hình ngôn ngữ lớn (LLM) (Achiam et al., 2023, Touvron et al., 2023a, Team et al., 2023) đã mang lại những khả năng mới cho việc phát triển tác nhân Ge et al. (2023a). Các LLM hiện tại đã thể hiện sức mạnh lớn trong việc hiểu hướng dẫn (Ouyang et al., 2022, Chung et al., 2022, Touvron et al., 2023b, Geng et al., 2022), suy luận và giải quyết vấn đề (Kojima et al., 2022, Nijkamp et al., 2022, Taylor et al., 2022, Hao et al., 2023, Kim et al., 2023), và tương tác với người dùng (Ross et al., 2023) cũng như môi trường bên ngoài (Driess et al., 2023, Brohan et al., 2023). Được xây dựng trên những LLM mạnh mẽ này, các tác nhân dựa trên LLM nổi bật (Ge et al., 2023a, Yao et al., 2023, Shinn et al., 2023, Deng et al., 2023, Packer et al., 2023, Wu et al., 2024) có thể thể hiện khả năng hoàn thành nhiệm vụ mạnh mẽ trong các môi trường đa dạng, từ trợ lý ảo đến các hệ thống suy luận và giải quyết vấn đề phức tạp hơn.

Một ví dụ minh họa về việc thực thi nhiệm vụ trong thế giới thực của một tác nhân dựa trên LLM được thể hiện trong Hình 1, nơi một tác nhân du lịch xử lý một yêu cầu tổ chức chuyến đi. Tác nhân phân tích có phương pháp yêu cầu này thành các bước có thể thực thi—đặt vé máy bay, đặt chỗ ở, xử lý thanh toán, và cập nhật lịch theo sở thích của người dùng. Trong suốt quá trình thực thi, tác nhân thể hiện khả năng suy luận và ra quyết định xuất phát từ nền tảng LLM của nó, phân biệt nó với các ứng dụng truyền thống bị hạn chế bởi các chức năng hoặc quy trình làm việc định trước.

Việc triển khai kịch bản du lịch này yêu cầu tác nhân tích hợp liền mạch các dịch vụ liên quan đến LLM (truy xuất sở thích, lựa chọn API, tạo phản hồi) với các dịch vụ OS thông thường (truy cập đĩa, thực thi phần mềm).

Các framework tác nhân hiện tại thể hiện những hạn chế thiết kế quan trọng bằng việc cho phép các tác nhân truy cập trực tiếp vào tài nguyên cấp hệ thống

Tác giả liên hệ: Yongfeng Zhang, yongfeng.zhang@rutgers.edu, Khoa Khoa học Máy tính, Đại học Rutgers, New Brunswick, NJ 08901.
AIOS Foundation arXiv:2403.16971v4 [cs.OS] 11 Tháng 5 2025

AIOS: Hệ điều hành tác nhân LLM
Tác nhân Du lịch: Đã hiểu. Tôi sẽ lập kế hoạch và đặt lịch trình theo sở thích trước đây của bạn.Người dùng: Tôi đang bay từ San Francisco đến New York để công tác vào tháng tới, xin hãy giúp tổ chức chuyến đi.Truy xuất Sở thíchGợi ý Chuyến bay và khách sạnTải lên ID ảnhChọn Chỗ ngồiThêm Vé vào LịchXử lý Thanh toánĐánh giá và mẹoLưu trữ LLM(được quản lý bởi LLM)API Công cụ(được quản lý bởi LLM)Lưu trữ Đĩa (được quản lý bởi OS)Phần mềm(được quản lý bởi OS)API Công cụ(được quản lý bởi LLM)Phần mềm(được quản lý bởi OS)Tạo Văn bản(được quản lý bởi LLM)

Bước 1Bước 2Bước 3Bước 4Bước 5Bước 6Bước 7

Hình 1: Một ví dụ động lực về cách một tác nhân (tức là tác nhân du lịch) yêu cầu cả dịch vụ liên quan đến LLM và không liên quan đến LLM (tức là OS) để hoàn thành một nhiệm vụ; màu đỏ đại diện cho các dịch vụ liên quan đến LLM và màu xanh dương đại diện cho các dịch vụ không liên quan đến LLM.

như LLM và công cụ (Qin et al., 2024), làm tổn hại đến việc tối ưu hóa tài nguyên và tạo ra các lỗ hổng tiềm ẩn. Không có lập lịch phù hợp, các tác nhân có thể độc quyền tài nguyên như làm ngập LLM với các yêu cầu trong khi những tác nhân khác phải chờ đợi. Việc thiếu các cơ chế quản lý tài nguyên hiệu quả làm suy giảm đáng kể hiệu quả hệ thống. Trong điều kiện đồng thời, các framework hiện có (ví dụ: Autogen, Langchain) sử dụng phương pháp thử-và-sai không hiệu quả cho các cuộc gọi LLM: các prompt được chuyển đổi thành tensor và tải vào bộ nhớ GPU cho đến khi giới hạn bộ nhớ CUDA kích hoạt ngoại lệ, buộc phải hủy cấp phát tensor và yêu cầu nhiều lần thử lại, điều này làm giảm đáng kể thông lượng hệ thống trong các tình huống mà nhiều tác nhân cạnh tranh cho tài nguyên LLM hạn chế.

Để giảm thiểu những hạn chế đã đề cập ở trên, chúng tôi giới thiệu AIOS, một kiến trúc được thiết kế để phục vụ các tác nhân dựa trên LLM hiệu quả hơn. Các đóng góp của chúng tôi như sau.

◦Kiến trúc Phục vụ Tác nhân Mới. Chúng tôi giới thiệu AIOS, một kiến trúc phục vụ tác nhân dựa trên LLM mới. AIOS chia các ứng dụng tác nhân và tài nguyên cho tác nhân như LLM và công cụ thành các lớp riêng biệt, tức là lớp ứng dụng và lớp nhân. Sự tách biệt này tạo điều kiện cho việc quản lý tài nguyên có hệ thống, tối ưu hóa hiệu quả và tăng cường an toàn.

◦Thiết kế và Triển khai Nhân AIOS. Tại cốt lõi của AIOS, chúng tôi thiết kế và triển khai một nhân AIOS để đóng gói các trừu tượng quản lý tài nguyên. Trong nhân này, các truy vấn tác nhân được phân tách thành các đơn vị thực thi phụ (tức là syscall AIOS) để tạo điều kiện song song. Chúng tôi thiết kế một bộ lập lịch tác nhân để điều phối việc thực thi syscall trên các module, trong khi các trình quản lý bộ nhớ, lưu trữ và công cụ cùng với lõi LLM chịu trách nhiệm xử lý các syscall được phân phối. Chúng tôi cũng thiết kế trình quản lý ngữ cảnh để xử lý gián đoạn ngữ cảnh và thiết kế trình quản lý truy cập để xác minh các hoạt động của tác nhân nhằm đảm bảo độ tin cậy của nhân AIOS.

◦Phát triển AIOS SDK. Chúng tôi phát triển AIOS SDK (Rama et al., 2025), cung cấp trừu tượng cấp cao hơn về các chức năng nhân, cho phép các nhà phát triển tập trung vào logic ứng dụng và các chức năng cấp cao hơn mà không bị gánh nặng bởi các chi tiết phức tạp của nhân.

◦Kết quả Thực nghiệm. Chúng tôi tiến hành đánh giá mở rộng về AIOS trên các tác nhân được phát triển sử dụng các framework tác nhân khác nhau. Kết quả cho thấy AIOS có thể duy trì hiệu suất của các tác nhân trên các benchmark tác nhân tiêu chuẩn và thậm chí có thể nâng cao hiệu suất trong các benchmark liên quan đến gọi công cụ. Hơn nữa, AIOS cải thiện đáng kể hiệu quả thực thi, đạt được tốc độ thực thi tăng lên tới 2.1× cho việc phục vụ các tác nhân trên các framework khác nhau. Những kết quả thực nghiệm này nhấn mạnh hiệu quả của AIOS trong việc tối ưu hóa cả hiệu suất tác nhân và tốc độ thực thi trong việc phục vụ tác nhân.

2. Kiến trúc của AIOS

Như được mô tả trong Hình 2, kiến trúc AIOS được chia thành ba lớp riêng biệt: lớp ứng dụng, nhân và phần cứng. Thiết kế phân lớp này nhằm thiết lập sự tách biệt rõ ràng các mối quan tâm trong hệ thống. Các ứng dụng cấp cao hơn trừu tượng hóa sự phức tạp của các lớp bên dưới, tương tác với chúng thông qua các giao diện được định nghĩa rõ ràng như bộ công cụ phát triển phần mềm (SDK) và cuộc gọi hệ thống.

Lớp Ứng dụng. Lớp ứng dụng tận dụng AIOS SDK, cung cấp giao diện để yêu cầu tài nguyên hệ thống trong AIOS. Thiết kế này giải phóng các tác nhân khỏi việc quản lý tài nguyên trong khi thực thi cách ly bằng cách ngăn chặn thao tác tài nguyên trực tiếp. AIOS SDK hỗ trợ cả việc phát triển tác nhân native và các tác nhân non-native được chuyển đổi từ các framework đa dạng bao gồm ReAct (Yao et al., 2023), Reflexion (Shinn et al., 2023), Autogen (Wu et al., 2023), Open-Interpreter (Lucas, 2024), và MetaGPT (Hong et al., 2023). Các tác nhân non-native tương tác với tài nguyên nhân AIOS thông qua các hàm adapter, trong khi việc phát triển native được hợp lý hóa thông qua các API được định nghĩa trước gọi các cuộc gọi hệ thống. Sự trừu tượng này cho phép các nhà phát triển tập trung vào logic tác nhân thay vì chi tiết quản lý tài nguyên.

Lớp Nhân. Lớp nhân tích hợp hai thành phần: nhân OS truyền thống cho các nhiệm vụ tính toán không phải LLM và nhân AIOS sáng tạo của chúng tôi. Trong nhân AIOS, các module chuyên biệt xử lý các yêu cầu tác nhân thông qua cuộc gọi hệ thống. Một bộ lập lịch phân phối các cuộc gọi này đến các module phù hợp sử dụng các chiến lược lập lịch tiên tiến (chi tiết trong Phần 3.3). Chúng tôi thiết kế một giao diện thống nhất đóng gói LLM như các lõi, tương tự như lõi CPU, cho phép tích hợp các endpoint LLM đa dạng. Để hỗ trợ chuyển đổi ngữ cảnh LLM, chúng tôi triển khai một trình quản lý ngữ cảnh với khả năng snapshot và khôi phục (Phần 3.4). Để xử lý dữ liệu tác nhân hiệu quả, chúng tôi phát triển một trình quản lý bộ nhớ cho các hoạt động runtime (Phần 3.5) và một trình quản lý lưu trữ cho lưu trữ lâu dài (Phần 3.6). Ngoài ra, một trình quản lý công cụ tải các công cụ và giải quyết xung đột cuộc gọi cho các công cụ được hỗ trợ bởi AIOS SDK (Phần 3.7), trong khi một trình quản lý truy cập triển khai kiểm soát truy cập và các giao thức can thiệp của người dùng (Phần 3.8).

Lớp Phần cứng. Lớp phần cứng bao gồm các thành phần vật lý của hệ thống, như CPU, GPU, bộ nhớ, đĩa và các thiết bị ngoại vi. Lớp phần cứng không phải là trọng tâm chính của công việc—nhân AIOS không tương tác trực tiếp với phần cứng mà dựa vào các cuộc gọi hệ thống OS để truy cập tài nguyên vật lý trong lớp phần cứng.

3. Nhân AIOS

Trong phần này, chúng tôi bắt đầu với tổng quan về nhân AIOS, làm nổi bật cách mỗi module hợp tác với các module khác để hỗ trợ các chức năng tích hợp. Theo đó, chúng tôi cung cấp cái nhìn sâu sắc về thiết kế và triển khai của mỗi module, thảo luận về vai trò và đóng góp của chúng cho kiến trúc AIOS tổng thể.

Trong nhân AIOS, các truy vấn tác nhân được phân tách thành các cuộc gọi hệ thống được phân loại (xử lý LLM, truy cập bộ nhớ, hoạt động lưu trữ, sử dụng công cụ) như được hiển thị trong Hình 3, với danh mục syscall toàn diện có sẵn trong Phụ lục A.1. Mỗi syscall được ràng buộc thread và được phân phối bởi bộ lập lịch, tập trung quản lý hàng đợi trên tất cả các module. Syscall được định tuyến đến các hàng đợi module phù hợp dựa trên tập thuộc tính của chúng, với mỗi module giám sát hàng đợi được chỉ định cho các cuộc gọi đã lập lịch. Trình quản lý ngữ cảnh sẽ được kích hoạt trong lõi LLM để xử lý gián đoạn ngữ cảnh thay vì được lập lịch.

3.2. Lõi LLM

Do các tùy chọn triển khai khác nhau của LLM, ví dụ: LLM nào được sử dụng, liệu LLM có được lưu trữ trên cloud hay trên thiết bị local, điều kiện phần cứng nào LLM yêu cầu, hoặc framework suy luận nào được sử dụng, chúng tôi đóng gói mỗi instance LLM áp dụng các tùy chọn triển khai khác nhau như một lõi, tương tự như lõi CPU trong hệ điều hành truyền thống. Thiết kế này cho phép chúng tôi xem mỗi instance LLM như một đơn vị xử lý chuyên dụng, tăng cường tính module và khả năng mở rộng trong kiến trúc AIOS. Để chứa các instance LLM khác nhau, chúng tôi giới thiệu một wrapper cho mỗi instance LLM và thiết kế các cuộc gọi hệ thống thống nhất trong wrapper này đặc biệt cho suy luận LLM. Bằng cách trừu tượng hóa một instance LLM như một lõi và triển khai các cuộc gọi hệ thống được chuẩn hóa, AIOS cung cấp một cách linh hoạt để tích hợp các instance LLM dưới các tùy chọn triển khai khác nhau, được quy cho thiết kế module của lõi LLM. Thông tin chi tiết về lõi LLM được cung cấp trong Phụ lục A.2.

3.3. Bộ lập lịch

Chúng tôi tập trung tất cả các hàng đợi trong module bộ lập lịch thay vì phân phối chúng trên các module xử lý, cách ly trách nhiệm quản lý yêu cầu và cho phép mỗi module tập trung hoàn toàn vào việc thực thi. Sự tập trung này đơn giản hóa việc phối hợp nhiệm vụ giữa các module và cung cấp một framework lập lịch thống nhất. Để quản lý các cuộc gọi hệ thống, chúng tôi triển khai hai thuật toán cổ điển: First-In-First-Out (FIFO), xử lý các cuộc gọi theo thứ tự đến nhưng có thể tăng thời gian chờ cho các yêu cầu sau này, và Round Robin (RR), chu kỳ qua các cuộc gọi theo kiểu time-sliced để phân phối tài nguyên cân bằng hơn. Chiến lược RR được hỗ trợ bởi cơ chế gián đoạn ngữ cảnh của chúng tôi cho suy luận LLM, chi tiết trong Phần A.3.

Thời gian suy luận LLM tạo ra nút thắt cổ chai thông qua các cuộc gọi hệ thống chạy lâu độc quyền tài nguyên. Cơ chế gián đoạn ngữ cảnh của chúng tôi giải quyết điều này thông qua gián đoạn và tiếp tục nhiệm vụ qua các hoạt động snapshot và khôi phục. Trình quản lý ngữ cảnh thiết kế hai phương pháp: dựa trên văn bản (cho LLM nguồn đóng không có quyền truy cập logits, lưu đầu ra đã giải mã) và dựa trên logits (bảo tồn cấu trúc cây tìm kiếm trung gian để khôi phục trạng thái chi tiết hơn). Phương pháp dựa trên logits được minh họa trong Hình 4. Sử dụng beam search (phổ biến trong LLM (Touvron et al., 2023b, Jiang et al., 2023, Biderman et al., 2023)), với độ rộng beam là 1 để đơn giản, chúng tôi thể hiện quá trình: Khi xử lý Xác định liệu có mưa ở điểm đến của chuyến bay UA057, LLM đánh giá các token ứng cử viên ở mỗi bước. Nếu bị tạm dừng bởi bộ lập lịch giữa quá trình tạo, trình quản lý ngữ cảnh sẽ chụp snapshot các kết quả trung gian. Khi tiếp tục, nó tải lại snapshot này để tiếp tục từ điểm tạm dừng, đạt được câu trả lời cuối cùng: Tìm kiếm thời tiết ở Paris mà không khởi động lại tính toán.

3.5. Trình quản lý Bộ nhớ

Không giống như các trình quản lý bộ nhớ OS truyền thống xử lý RAM vật lý, trình quản lý bộ nhớ của AIOS giải quyết lịch sử tương tác tác nhân trong runtime (Lerman và Galstyan, 2003, Zhang et al., 2024), bao gồm nhật ký hội thoại và kết quả gọi công cụ. Nó quản lý cấu trúc bộ nhớ, cấp phát, hoạt động đọc/ghi, xóa và cập nhật. Bộ nhớ tác nhân nằm trong RAM theo mặc định, nhưng khi không gian được cấp phát tiến gần đến dung lượng, trình quản lý triển khai hoán đổi bộ nhớ giữa RAM và đĩa. Khi việc sử dụng bộ nhớ của tác nhân vượt quá giới hạn khối của nó (ví dụ: 80% cấp phát), trình quản lý bộ nhớ khởi tạo chính sách loại bỏ K-Least Recently Used (LRU-K), chuyển các mục từ RAM sang đĩa thông qua trình quản lý lưu trữ (chi tiết trong Phần 3.6). LRU-K ưu tiên giữ lại các mục trong RAM đã được truy cập ít nhất K lần gần đây, trong khi di chuyển các mục được truy cập ít thường xuyên hơn sang đĩa. Điều này cân bằng hiệu quả bộ nhớ bằng cách dỡ bỏ dữ liệu được truy cập không thường xuyên trong khi đảm bảo khả năng truy xuất khi cần. Triển khai chi tiết của trình quản lý bộ nhớ nằm trong A.5.

Trình quản lý lưu trữ xử lý lưu trữ dữ liệu lâu dài cho các tác nhân, bao gồm các tập tin hoặc cơ sở tri thức mà các tác nhân phụ thuộc để chạy và các bộ nhớ tác nhân cần được lưu trữ lâu dài. Trong runtime của tác nhân, khi việc sử dụng bộ nhớ của tác nhân vượt quá giới hạn được cấp phát, trình quản lý bộ nhớ gọi trình quản lý lưu trữ để hoán đổi dữ liệu vào đĩa. Cụ thể, trình quản lý lưu trữ đọc và ghi dữ liệu dựa trên ID tác nhân được truyền từ trình quản lý bộ nhớ. Ngoài trình quản lý bộ nhớ, bản thân tác nhân cũng có thể yêu cầu đọc và ghi dữ liệu trên đĩa trong runtime, và những yêu cầu tác nhân này cũng được xử lý bởi trình quản lý lưu trữ. Cụ thể, tác nhân gọi API lưu trữ trong SDK, được chuyển đổi thêm thành các cuộc gọi hệ thống liên quan đến lưu trữ và được đưa vào hàng đợi lưu trữ bởi bộ lập lịch. Trình quản lý lưu trữ sau đó xử lý các yêu cầu trong hàng đợi để thực hiện các yêu cầu tác nhân. Trình quản lý lưu trữ được triển khai sử dụng tập tin local và cơ sở dữ liệu vector (ví dụ: chromadb). Chi tiết triển khai của trình quản lý lưu trữ được bao gồm trong Phụ lục A.6.

3.7. Trình quản lý Công cụ

Trình quản lý công cụ trong nhân AIOS chịu trách nhiệm quản lý một bộ API tool rộng lớn được hỗ trợ bởi AIOS SDK.
Tải Công cụ Được Chuẩn hóa. Trình quản lý sử dụng một giao diện được chuẩn hóa để xử lý các công cụ đa dạng một cách thống nhất, trong khi kết hợp xác thực tham số trước khi thực thi để ngăn chặn sự cố công cụ. Khi được gọi bằng tên, trình quản lý công cụ tải động instance công cụ bao gồm khởi tạo executable và xác minh dependencies.

Giải quyết Xung đột Cuộc gọi Công cụ. Đối với các công cụ có ràng buộc truy cập song song, hệ thống sử dụng hashmap để giám sát số lượng instance thời gian thực. Xử lý yêu cầu bao gồm xác minh hashmap chống lại việc sử dụng và giới hạn song song; khi phát hiện xung đột, hệ thống tiến tới các yêu cầu hàng đợi tiếp theo cho đến khi xác định được ứng cử viên không xung đột. Chi tiết triển khai được trình bày trong Phụ lục A.7.

3.8. Trình quản lý Truy cập

Trình quản lý truy cập trong nhân AIOS cung cấp hai chức năng chính sau.
Kiểm soát Truy cập. Trình quản lý truy cập điều chỉnh các hoạt động đọc/ghi dữ liệu giữa các tác nhân bằng cách triển khai các cơ chế kiểm soát truy cập dựa trên đặc quyền. Nó gán mỗi tác nhân vào một nhóm đặc quyền cụ thể và thực thi quyền thông qua kiến trúc hashmap ánh xạ ID tác nhân đến các nhóm đặc quyền tương ứng của chúng. Các yêu cầu truy cập được xác thực chống lại cấu trúc quyền này trước khi thực thi, đảm bảo các tác nhân chỉ có thể truy cập tài nguyên của các tác nhân khác trong miền đặc quyền được chia sẻ của chúng.

Can thiệp Người dùng. Để giảm thiểu rủi ro của các hoạt động không thể đảo ngược (xóa, ghi đè, sửa đổi đặc quyền), một giao diện can thiệp người dùng được cung cấp để xác nhận người dùng. Điều này bắt buộc xác minh người dùng rõ ràng trước khi tiến hành các hoạt động có thể phá hủy trên tập tin hoặc công cụ. Chi tiết triển khai có thể được tìm thấy trong Phụ lục A.8.

3.9. AIOS SDK

Chúng tôi thiết kế AIOS SDK (Rama et al., 2025) để hợp lý hóa việc phát triển và tích hợp các tác nhân trên kiến trúc AIOS. SDK này không chỉ trao quyền cho các nhà phát triển xây dựng các tác nhân tương tác với các chức năng cốt lõi trong nhân AIOS mà còn trừu tượng hóa các cuộc gọi hệ thống phức tạp, cho phép các nhà phát triển tập trung vào quy trình làm việc nội bộ của tác nhân.

Tích hợp Công cụ. Để hỗ trợ các chức năng tác nhân đa dạng, AIOS SDK tích hợp một loạt các công cụ được tìm nguồn từ các nền tảng khác nhau và hỗ trợ các trường hợp khác nhau của modality đầu vào-đầu ra. Thông tin chi tiết về các công cụ tích hợp này được cung cấp trong Phụ lục B.3.

Giao diện Tương tác với Nhân AIOS. Để tạo điều kiện sử dụng các chức năng được cung cấp bởi các cuộc gọi hệ thống AIOS trong nhân AIOS, SDK định nghĩa các hàm API khác nhau mà các tác nhân có thể sử dụng để gọi các cuộc gọi hệ thống và yêu cầu tài nguyên.

Adapter Framework Tác nhân. Để hỗ trợ các tác nhân được xây dựng với các framework tạo tác nhân khác nhau, như Autogen (Wu et al., 2023), Open-Interpreter (Lucas, 2024), và MetaGPT (Hong et al., 2023), AIOS SDK cung cấp các adapter cho các framework này. Các adapter này định vị các chức năng cốt lõi trong các framework đã đề cập và chuyển hướng chúng đến các chức năng trong AIOS. Việc chuyển đổi này cho phép các tác nhân từ các framework khác nhau hoạt động trong môi trường AIOS mà không cần sửa đổi mã tác nhân. Chi tiết thêm về các chức năng cốt lõi và các chuyển đổi cụ thể cho mỗi framework tác nhân được cung cấp trong Phụ lục B.5.

4. Đánh giá

Trong phần này, chúng tôi tiến hành thí nghiệm để trả lời các câu hỏi nghiên cứu sau.

•RQ1: AIOS có thể duy trì hoặc thậm chí nâng cao hiệu suất của các tác nhân trên các benchmark tiêu chuẩn khi chạy nhiều instance tác nhân đồng thời không?

•RQ2: AIOS có thể tối ưu hóa thông lượng thực thi hệ thống và giảm độ trễ phản hồi hiệu quả như thế nào khi phục vụ nhiều tác nhân được xây dựng với các framework tác nhân khác nhau?

•RQ3: AIOS có khả năng mở rộng như thế nào khi số lượng tác nhân chạy đồng thời tăng lên?

4.1. Thiết lập

Mô hình. Chúng tôi sử dụng GPT-4o-mini (Achiam et al., 2023) như API nguồn đóng, và sử dụng hai LLM nguồn mở, tức là Llama-3.1-8b (Dubey et al., 2024) và Mistral-7b (Jiang et al., 2023), như lõi LLM, tương ứng, trong các thí nghiệm. Các mô hình nguồn mở đều là phiên bản instruction-tuned và chúng tôi sử dụng độ chính xác float16.

Phần cứng. Các thí nghiệm của chúng tôi được tiến hành trên máy Ubuntu 22.04 được trang bị GPU NVIDIA RTX A5000 (24GB). Chúng tôi chạy tất cả thí nghiệm sử dụng một GPU A5000 duy nhất.

Framework Tác nhân. Chúng tôi tiến hành đánh giá bằng cách chạy các tác nhân được xây dựng từ các framework tác nhân phổ biến khác nhau: ReAct (Yao et al., 2023), Reflexion (Shinn et al., 2023), Autogen (Wu et al., 2023), Open-Interpreter (Lucas, 2024) và MetaGPT (Hong et al., 2023). Chi tiết của các framework tác nhân này được giới thiệu trong Phụ lục B.5.

Workload. Chúng tôi đánh giá trên một tình huống hạn chế tài nguyên trong đó các tác nhân chạy đồng thời với một LLM duy nhất được triển khai có thể xử lý chỉ một yêu cầu prompt tại một thời điểm. Để tạo ra những điều kiện đồng thời này, chúng tôi đặt số lượng thread làm việc tối đa là 250 theo mặc định, tức là tối đa 250 tác nhân có thể chạy đồng thời tại cùng một

thời điểm. Tác động của việc tăng số lượng tác nhân sẽ được phân tích trong Phần 4.4. Theo mặc định, chúng tôi sử dụng RR làm chiến lược lập lịch cho AIOS để chạy các tác nhân. Tác động của việc sử dụng chiến lược khác (tức là FIFO) được báo cáo trong Phụ lục D.

4.2. Hiệu suất Tác nhân (RQ1)

Để đánh giá tác động của việc sử dụng AIOS đối với hiệu suất tác nhân trong các benchmark tiêu chuẩn, chúng tôi áp dụng bốn benchmark tác nhân, tức là HumanEval (Chen et al., 2021a), MINT (tập con mã) (Wang et al., 2023b), GAIA (Mialon et al., 2023) và SWE-Bench-Lite (Jimenez et al., 2024) để chạy các tác nhân không có và có AIOS, tương ứng. Chúng tôi sử dụng tỷ lệ thành công (SR%) làm metric, phù hợp với các benchmark gốc và sử dụng GPT-4o-mini làm lõi LLM để chạy tất cả các tác nhân. Chúng tôi đặt nhiệt độ là 1.0 cho GPT-4o-mini trong tất cả thí nghiệm. Mô tả chi tiết về thiết lập benchmark và cấu hình có thể được tìm thấy trong Phụ lục C. Như được hiển thị trong Bảng 1, việc kết hợp AIOS liên tục duy trì hiệu suất tác nhân trên các benchmark tiêu chuẩn. Trong một số trường hợp, AIOS cũng có thể đóng góp vào cải thiện hiệu suất tác nhân. Ví dụ, trong các benchmark tạo mã như MINT, HumanEval và SWE-Bench-Lite, AIOS tăng cường hiệu suất tác nhân bằng cách nâng cao prompt, nhúng các prompt hệ thống với đầu vào và đầu ra có cấu trúc hơn trong wrapper LLM. Những prompt được nâng cao này cung cấp cho LLM ngữ cảnh bổ sung và hướng dẫn cấu trúc cho việc tạo phản hồi. Trong các benchmark gọi công cụ như GAIA, hiệu suất tác nhân thậm chí được tăng cường bởi hai cơ chế sau: xác thực tham số trước thực thi thông qua regex cấu trúc để kiểm tra định dạng của cuộc gọi công cụ trước khi thực thi, và (2) hashmap giải quyết xung đột để giảm thiểu các vấn đề truy cập đồng thời.

4.3. Phân tích Hiệu quả (RQ2)

Trong các thí nghiệm hiệu quả của chúng tôi, chúng tôi đánh giá hiệu suất hệ thống sử dụng hai metric chính: thông lượng và độ trễ. Thông lượng được đo bằng cách đếm số cuộc gọi hệ thống AIOS được thực thi mỗi giây, chỉ ra khả năng của hệ thống xử lý nhiều yêu cầu song song. Mặt khác, độ trễ được đo như thời gian chờ trung bình mà các tác nhân trải qua, từ thời điểm một truy vấn được gửi đến hoàn thành phản hồi, phản ánh khả năng phản hồi của hệ thống. Để đảm bảo môi trường thử nghiệm được kiểm soát và nhất quán, chúng tôi tiến hành các đánh giá này sử dụng hai

mô hình nguồn mở, Llama-3.1-8b và Mistral-7b, cả hai đều được lưu trữ locally. Việc lưu trữ các mô hình này locally giảm biến động tiềm ẩn trong thời gian phản hồi API LLM do các vấn đề độ trễ liên quan đến mạng. Như được hiển thị trong Hình 6a và Hình 7a, kết quả chứng minh rằng AIOS đạt được thông lượng cao hơn đáng kể trên các framework tác nhân khác nhau, tăng lên tới 2.1× thông lượng khi sử dụng các tác nhân dựa trên Reflexion trên Llama-3.1-8b. Cải thiện này được quy cho việc lập lịch được sử dụng trong nhân AIOS, ngăn chặn các nỗ lực thử-và-sai không cần thiết bằng cách tránh các prompt không thể được tải lên GPU để thực thi. Về độ trễ, như được minh họa trong Hình 6b và Hình 7b, thời gian chờ trung bình cho các tác nhân cũng được giảm đáng kể. Sự giảm này nhấn mạnh hiệu quả của AIOS trong việc phục vụ các tác nhân dựa trên LLM.

4.4. Phân tích Khả năng mở rộng (RQ3)

Chúng tôi đánh giá khả năng mở rộng AIOS bằng cách tăng dần các tác nhân hoạt động từ 250 lên 2000, sử dụng các mô hình Llama-3.1-8b và Mistral-7b trên benchmark HumanEval. Chúng tôi nhân đôi 164 mẫu của HumanEval để phù hợp với số lượng tác nhân, cho phép thực thi đồng thời quy mô lớn. Như được thể hiện trong Hình 8, AIOS duy trì mối quan hệ gần như tuyến tính giữa cả thời gian thực thi tổng thể và thời gian chờ tác nhân trung bình liên quan đến số lượng tác nhân. Điều này chỉ ra rằng AIOS có thể xử lý workload hiệu quả ngay cả dưới nhu cầu tăng. Ngược lại, khoảng cách về thời gian thực thi và chờ đợi giữa không có AIOS và sử dụng AIOS mở rộng khi số lượng tác nhân tăng. Sự khác biệt ngày càng tăng này nhấn mạnh khả năng mở rộng của AIOS dưới workload đồng thời cao.

5. Công việc Liên quan

Sự tiến hóa của hệ điều hành (OS) đã tiến bộ từ thô sơ đến các hệ thống tương tác phức tạp. Sự tiến hóa này chuyển từ xử lý batch cơ bản (IBM, 2010) đến quản lý tiến trình tiên tiến bao gồm time-sharing (Ritchie và Thompson, 1974) và multi-tasking (Hoare, 1974, Engler et al., 1995), cho phép xử lý nhiệm vụ phức tạp. Phát triển tiến tới kiến trúc module với các thành phần chuyên biệt cho lập lịch tiến trình (Liu và Layland, 1973, Dijkstra, 2002), quản lý bộ nhớ (Denning, 1968, Daley và Dennis, 1968), và hoạt động filesystem (Rosenblum và Ousterhout, 1992, McKusick et al., 1984), cải thiện hiệu quả hệ thống. Việc giới thiệu giao diện người dùng đồ họa (GUI) trong Macintosh, Windows và GNOME nâng cao tương tác người dùng. Hiện tại, các mô hình AI, đặc biệt là LLM, đang di chuyển từ lớp ứng dụng sang lớp hệ thống, cung cấp các dịch vụ được chuẩn hóa trên các ứng dụng.

Các Tác nhân Mô hình Ngôn ngữ Lớn được sử dụng để giải quyết các nhiệm vụ lập kế hoạch và suy luận phức tạp (Xie et al., 2024, Ge et al., 2023a). Các tác nhân đơn lẻ tham gia với môi trường kỹ thuật số hoặc môi trường vật lý, có thể gọi API (Ge et al., 2023a, Schick et al., 2023, Yao và Narasimhan, 2023, Parisi et al., 2022, Tang et al., 2023, Xie et al., 2024), duyệt websites (Nakano et al., 2022, Deng et al., 2023, Wu et al., 2024), hoặc thực thi mã (Zhang et al., 2023, Yang et al.), trong khi các tác nhân trong môi trường vật lý có thể thao tác đối tượng (Brohan et al., 2023, Fan et al., 2022, Wang et al., 2023a), thực hiện thí nghiệm phòng thí nghiệm (Boiko et al., 2023, Bran et al., 2023), hoặc đưa ra quyết định có thể hành động (Huang et al., 2022, Xiang et al., 2023). Các hệ thống đa tác nhân dựa trên LLM (MAS) tận dụng tương tác giữa nhiều tác nhân để giải quyết vấn đề. Mối quan hệ giữa nhiều tác nhân có thể là hợp tác (Wang et al., 2023c, Mandi et al., 2023), cạnh tranh (Chan et al., 2023, Du et al., 2023), hoặc hỗn hợp của hợp tác và cạnh tranh (Ge et al., 2023b). Trong các hệ thống đa tác nhân hợp tác, mỗi tác nhân lấy và đánh giá thông tin được cung cấp bởi các tác nhân khác, từ đó làm việc cùng nhau để giải quyết các nhiệm vụ phức tạp, như đóng vai (Li et al., 2023, Chen et al., 2023, Zhu et al., 2023), mô phỏng xã hội (Park et al., 2023) và phát triển phần mềm (Hong et al., 2023, Qian et al., 2023, Wu et al., 2023, Josifoski et al., 2023).

6. Kết luận và Công việc Tương lai

Bài báo này giới thiệu AIOS, một kiến trúc phục vụ các tác nhân dựa trên LLM thông qua một nhân sáng tạo cách ly tài nguyên và dịch vụ LLM khỏi ứng dụng tác nhân. AIOS SDK bổ sung cho phép các ứng dụng tác nhân tận dụng các chức năng nhân một cách hiệu quả. Xác thực thực nghiệm xác nhận AIOS duy trì hoặc nâng cao hiệu suất tác nhân trên các benchmark tiêu chuẩn trong khi tăng tốc đáng kể thời gian thực thi, cải thiện thông lượng hệ thống và thể hiện khả năng mở rộng với tải tác nhân đồng thời tăng. Chúng tôi hình dung công việc này thúc đẩy các đổi mới tương lai tinh chỉnh và mở rộng kiến trúc để giải quyết các yêu cầu phát triển cho việc phát triển và triển khai các tác nhân dựa trên LLM.

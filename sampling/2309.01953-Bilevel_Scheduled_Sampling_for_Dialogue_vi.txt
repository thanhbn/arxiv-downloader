Lấy mẫu theo lịch trình hai cấp cho tạo sinh đối thoại

Jiawen Liu và Kan Li(B)
Viện Công nghệ Bắc Kinh, Bắc Kinh, Trung Quốc
{liujiawen,likan }@bit.edu.cn

Tóm tắt. Thiên lệch phơi nhiễm tạo ra một thách thức phổ biến trong nhiều tác vụ xử lý ngôn ngữ tự nhiên, đặc biệt là trong tạo sinh đối thoại. Để đáp ứng vấn đề này, các nhà nghiên cứu đã phát triển nhiều kỹ thuật khác nhau, trong đó lấy mẫu theo lịch trình đã được chứng minh là một phương pháp hiệu quả để giảm thiểu thiên lệch phơi nhiễm. Tuy nhiên, các phương pháp lấy mẫu theo lịch trình tiên tiến hiện tại chỉ xem xét chất lượng của các từ lấy mẫu hiện tại để cắt ngưỡng lấy mẫu, điều này bỏ qua tầm quan trọng của thông tin cấp câu và phương pháp cắt ngưỡng cần được thảo luận thêm. Trong bài báo này, chúng tôi đề xuất một mô hình lấy mẫu theo lịch trình hai cấp có tính đến thông tin cấp câu và kết hợp nó với chất lượng cấp từ. Để tăng cường tính đa dạng lấy mẫu và cải thiện khả năng thích ứng của mô hình, chúng tôi đề xuất một hàm làm mịn ánh xạ kết quả kết hợp của thông tin cấp câu và cấp từ đến một phạm vi phù hợp, và sử dụng lấy mẫu xác suất dựa trên các giá trị được ánh xạ thay vì cắt ngưỡng. Các thí nghiệm được tiến hành trên bộ dữ liệu DailyDialog và PersonaChat chứng minh tính hiệu quả của các phương pháp đề xuất của chúng tôi, giúp giảm đáng kể vấn đề thiên lệch phơi nhiễm và vượt trội so với các phương pháp lấy mẫu theo lịch trình tiên tiến.

Từ khóa: Lấy mẫu theo lịch trình · Thiên lệch phơi nhiễm · Tạo sinh đối thoại.

1 Giới thiệu

Thiên lệch phơi nhiễm là một vấn đề phổ biến trong nhiều tác vụ xử lý ngôn ngữ tự nhiên [1], đặc biệt là trong tạo sinh đối thoại. Thiên lệch phơi nhiễm đề cập đến sự khác biệt giữa giai đoạn huấn luyện và suy luận của một mô hình, nơi mô hình được huấn luyện trên dữ liệu ground truth nhưng tạo sinh dựa trên dự đoán của chính nó trong thời gian suy luận. Điều này dẫn đến việc mô hình phải đối mặt với các môi trường khác nhau trong quá trình huấn luyện và suy luận. Một khi dự đoán của mô hình không nhất quán với ground truth ở đâu đó, nó có thể ảnh hưởng đến các dự đoán sau này, điều này sẽ dẫn đến các lỗi tích lũy và lan truyền dọc theo chuỗi được tạo sinh, dẫn đến chất lượng, tính đa dạng và khả năng tổng quát hóa kém của các phản hồi.

Để giải quyết vấn đề này, các nhà nghiên cứu đã phát triển nhiều kỹ thuật khác nhau, chẳng hạn như tìm kiếm chùm [2], DAD(Data As Demonstrator) [3], huấn luyện cấp câu [4], lấy mẫu theo lịch trình [1,5], học tăng cường huấn luyện mô hình một cách rõ ràng [6,7], v.v. Những kỹ thuật này giúp các mô hình xử lý các phụ thuộc dài hạn tốt hơn trong quá trình suy luận. Hiện tại, lấy mẫu theo lịch trình được áp dụng rộng rãi và đã thể hiện kết quả thuận lợi. Tuy nhiên, các phương pháp hiện tại hoặc tạo sinh toàn bộ câu một cách tự hồi quy trước khi lấy mẫu[8], hoặc chỉ xem xét tác động của từ lấy mẫu hiện tại để cắt ngưỡng lấy mẫu[9,10]. Cách trước đòi hỏi nhiều tìm kiếm chùm, dẫn đến độ phức tạp tính toán cao, hiệu quả thấp, và không thể điều chỉnh động dựa trên chất lượng của từng từ, do đó bỏ qua sự khác biệt giữa các từ trong câu. Cách sau bỏ qua thông tin cấp câu và phương pháp cắt ngưỡng cần được thảo luận thêm.

Theo quan điểm của chúng tôi, tầm quan trọng của thông tin cấp từ là rõ ràng, và các phương pháp hiện tại lấy mẫu dựa trên điểm số cấp từ [9,10] tốt hơn đáng kể so với các phương pháp truyền thống [1,8] lấy mẫu mỗi từ trong một câu với cùng xác suất. Tuy nhiên, việc dựa vào độ tương tự cosine hoặc các điểm số khác giữa từ được tạo sinh và từ ground truth bị hạn chế, và chúng ta vẫn cần tính đến chất lượng cấp câu. Do đó, trong bài báo này, chúng tôi đề xuất một mô hình lấy mẫu theo lịch trình hai cấp điều chỉnh động các xác suất lấy mẫu của kết quả được tạo sinh và ground truth ở cả cấp từ và cấp câu. Mô hình của chúng tôi cân bằng hiệu quả sự đánh đổi giữa học từ ground truth và dự đoán của chính nó, do đó tăng cường tính mạnh mẽ và đa dạng của tạo sinh đối thoại.

Cụ thể, đánh giá chất lượng câu trong lấy mẫu cấp câu được thực hiện thông qua việc sử dụng điểm BLEU hoặc độ tương tự cosine cấp câu. Mặt khác, chất lượng từ trong lấy mẫu cấp từ được đánh giá dựa trên xác suất tạo sinh từ. Cuối cùng, một hàm làm mịn được thiết kế đặc biệt được sử dụng để tích hợp các đánh giá cấp câu và cấp từ, cho phép lấy mẫu xác suất.

Chúng tôi đánh giá mô hình đề xuất trên hai bộ dữ liệu có sẵn công khai, cụ thể là DailyDialog và PersonaChat. Kết quả thí nghiệm cho thấy mô hình của chúng tôi vượt trội so với các mô hình thiên lệch phơi nhiễm hiện có trong cả đánh giá tự động dựa trên metric và đánh giá con người. Các đóng góp chính của bài báo này bao gồm:

– Theo hiểu biết của chúng tôi, chúng tôi là những người đầu tiên đề xuất một mô hình lấy mẫu theo lịch trình hai cấp tính đến cả thông tin cấp câu và cấp từ.

– Trong lấy mẫu cấp câu, chúng tôi sử dụng BLEU và độ tương tự cosine cấp câu làm metrics đánh giá. Đối với lấy mẫu cấp từ, chúng tôi tận dụng các xác suất dự đoán làm điểm số cấp từ. Để tăng cường tính đa dạng của quá trình lấy mẫu và cải thiện khả năng thích ứng của mô hình, chúng tôi đề xuất một hàm làm mịn ánh xạ kết quả kết hợp của lấy mẫu hai cấp đến một phạm vi phù hợp và áp dụng lấy mẫu xác suất thay vì cắt ngưỡng.

– Các đánh giá mở rộng trên hai bộ dữ liệu đối thoại miền mở được sử dụng rộng rãi chứng minh rằng phương pháp đề xuất giảm đáng kể vấn đề thiên lệch phơi nhiễm và vượt trội so với các phương pháp lấy mẫu theo lịch trình tiên tiến.

2 Công trình liên quan

Data As Demonstrator (DAD) là một thuật toán meta learning [3] giải quyết vấn đề thiên lệch phơi nhiễm bằng cách pha trộn dữ liệu huấn luyện thực với dự đoán mô hình. Trong giai đoạn huấn luyện, không chỉ ground truth được sử dụng làm đầu vào, mà các kết quả dự đoán mô hình cũng được thêm vào tập huấn luyện để làm cho nó phù hợp với phân phối test. Phương pháp Scheduled Sampling [1] đã phát triển thêm cách tiếp cận này cho tạo sinh chuỗi bằng cách lấy mẫu từ dự đoán của chính mô hình trong quá trình huấn luyện, thay vì luôn sử dụng ground truth. Phương pháp này được đề xuất lần đầu bởi Bengio et al. năm 2015 [1], và sau đó được cải thiện cho các mô hình transformer bởi Mihaylova và Martins năm 2019 [5], nhờ vào hiệu suất vượt trội của các mô hình transformer [11]. Hơn nữa, vì lấy mẫu theo lịch trình chỉ nhìn trước một bước, Goodman et al. đã đề xuất phương pháp TeaForN [12], nhìn trước N bước để có thêm tầm nhìn xa trong lấy mẫu, nhưng với chi phí là giảm hiệu quả huấn luyện.

Chiến lược ban đầu cho lấy mẫu là giảm xác suất lấy mẫu ground truth dựa trên các bước huấn luyện, với giảm tuyến tính cụ thể f(i) = max(ϵ, ki+b), giảm hàm mũ f(i) =ki, và giảm sigmoid f(i) =k/(k+e^(i/k)). Sau đó vào năm 2021, Liu et al. đã đề xuất một chiến lược giảm theo các bước giải mã [13], cải thiện thêm tính hiệu quả.

Zhang et al. đã đề xuất hai chiến lược, cụ thể là oracle cấp từ và cấp câu, để lựa chọn kết quả được tạo sinh của mô hình [8]. Tuy nhiên, bài báo tiếp tục sử dụng xác suất với giảm để lấy mẫu từ kết quả của mô hình (oracle) và ground truth, thay vì áp dụng một cách tiếp cận tinh vi hơn là lấy mẫu dựa trên chất lượng của câu hoặc từ.

Rõ ràng, lấy mẫu các từ với xác suất bằng nhau bất kể chất lượng khác nhau của chúng là vốn dĩ không chính xác. Rất khuyến khích sử dụng các xác suất lấy mẫu khác biệt cho từng câu riêng lẻ và cho mỗi từ trong một câu. Liu et al. đã đề xuất lấy mẫu theo lịch trình nhận thức tin cậy [10], thiết lập hai ngưỡng t_golden và t_rand, và lấy mẫu ground truth, kết quả dự đoán mô hình, một từ ngẫu nhiên khi độ tin cậy tương ứng trong [0, t_golden), [t_golden, t_rand), [t_rand,1]. Xu et al. [9] tập trung vào tạo sinh đối thoại và lựa chọn các từ dựa trên độ tương tự cosine giữa từ dự đoán và ground truth. Nếu độ tương tự lớn hơn ngưỡng β, từ dự đoán được chọn với xác suất α, đây là một siêu tham số tăng theo số epoch huấn luyện để đạt được hội tụ nhanh hơn trong giai đoạn đầu huấn luyện và giảm thiểu thiên lệch phơi nhiễm.

Tuy nhiên, những phương pháp này có một số hạn chế. Thứ nhất, chúng không tính đến thông tin cấp câu rất quan trọng. Thứ hai, phương pháp cắt ngưỡng cũng cần được thảo luận. Nếu lựa chọn xác suất được sử dụng, các từ khác nhau có thể được lấy mẫu với các xác suất khác nhau, để sự phân biệt giữa các từ khác nhau lớn hơn và khả năng thích ứng của mô hình mạnh hơn.

Do đó, chúng tôi đề xuất một mô hình lấy mẫu theo lịch trình hai cấp mới kết hợp hiệu quả thông tin cấp câu với chất lượng cấp từ. Để tăng cường tính đa dạng lấy mẫu và cải thiện khả năng thích ứng của mô hình, chúng tôi giới thiệu một hàm làm mịn ánh xạ kết quả tích hợp của thông tin cấp câu và cấp từ đến một phạm vi phù hợp. Sau đó, chúng tôi sử dụng lấy mẫu xác suất dựa trên các giá trị được ánh xạ thay vì cắt ngưỡng.

3 Mô hình lấy mẫu theo lịch trình hai cấp

3.1 Mô hình hóa toán học của tạo sinh đối thoại

Trong các tác vụ tạo sinh đối thoại, chúng ta thường định nghĩa hàm mục tiêu của mô hình bằng cách tối đa hóa xác suất có điều kiện, có nghĩa là chúng ta cần tối đa hóa xác suất tạo sinh văn bản đầu ra Y cho văn bản đầu vào X. Cụ thể, chúng ta có thể sử dụng phương trình 1 để biểu diễn hàm mục tiêu này, trong đó y_t là từ thứ t trong Y, y_<t là t-1 từ đầu tiên trong Y, và T là độ dài của Y. Hàm mục tiêu này yêu cầu chúng ta tính xác suất của mỗi từ cho văn bản đầu vào X và các từ trước đó y_<t, và nhân các xác suất này để có được xác suất của văn bản đầu ra Y.

P(Y|X, θ) = ∏(t=1 to T) p(y_t|y_<t, X, θ) (1)

Trong quá trình huấn luyện, chúng ta thường sử dụng hàm mất cross-entropy [14] làm mục tiêu tối ưu hóa cho mô hình, đo lường sự khác biệt giữa đầu ra của mô hình và ground truth. Cụ thể, chúng ta có thể sử dụng phương trình 2 để biểu diễn hàm mất cross-entropy, trong đó L(θ) biểu thị hàm mất cross-entropy của mô hình, và logarit âm của xác suất được sử dụng làm mất mát, sao cho mất mát giảm khi xác suất tăng.

L(θ) = -log P(Y|X, θ) = (1/T) ∑(t=1 to T) -log p(y_t|y_<t, X, θ) (2)

Bằng cách tối thiểu hóa hàm mất mát của tất cả các mẫu, chúng ta có thể có được các tham số mô hình tối ưu θ. Điều này có thể được biểu diễn như phương trình 3, trong đó N là tổng số mẫu tập huấn luyện.

θ* = argmin_θ {∑(k=1 to N) L_k(θ)} (3)

Trong vấn đề thiên lệch phơi nhiễm, khác với huấn luyện, trong quá trình suy luận, xác suất của mỗi từ đích p(y_t|y_<t, X, θ) trong phương trình 1 được điều kiện hóa trên các từ được tạo sinh trước đó y*_<t thay vì ground truth y_<t, vì các từ ground truth không có sẵn trong suy luận thực tế. Do đó, chúng tôi sử dụng phương pháp lấy mẫu theo lịch trình để thay thế ground truth trong quá trình huấn luyện bằng các câu được lấy mẫu, do đó giảm khoảng cách giữa quá trình huấn luyện và suy luận của mô hình.

3.2 Lấy mẫu theo lịch trình hai cấp

Chúng tôi đề xuất một phương pháp lấy mẫu kết hợp cấp câu và cấp từ để giải quyết tính đa dạng và tính ngữ cảnh của các hệ thống đối thoại miền mở. Lấy transformer làm ví dụ, chúng tôi giới thiệu nguyên lý và cách thực hiện của phương pháp lấy mẫu theo lịch trình hai cấp, như được thể hiện trong Hình 1.

Lấy mẫu cấp câu Zhang et al. [8] đã đề xuất một phương pháp lấy mẫu cấp câu truyền thống sử dụng tìm kiếm chùm để chọn k câu có khả năng nhất từ phân phối dự đoán, và sau đó chọn một câu làm mẫu lấy mẫu dựa trên điểm BLEU, tiếp theo là phương pháp lấy mẫu giảm để trích xuất từ mẫu và câu thực. Tuy nhiên, phương pháp này có hai nhược điểm chính: (1) nó đòi hỏi nhiều tìm kiếm chùm để tạo sinh câu như quy trình suy luận, dẫn đến chi phí tính toán cao và hiệu quả thấp; (2) nó chỉ có thể lấy mẫu bằng xác suất với giảm, bỏ qua sự khác biệt giữa các từ trong câu, khiến việc điều chỉnh động chất lượng của từng từ trở nên không thể.

Để giải quyết những vấn đề này, chúng tôi đề xuất một phương pháp lấy mẫu cấp câu sử dụng tính song song của mô hình transformer để tạo sinh toàn bộ câu cùng một lúc trong quá trình huấn luyện, và tính xác suất của mỗi từ và chất lượng của câu.

Đầu tiên chúng tôi tính xác suất P của từ dự đoán thông qua hàm softmax, và chọn các từ Y* có xác suất lớn nhất để được đánh giá bởi chỉ số cấp câu.

Chúng tôi thử hai chỉ số cấp câu (SLI): BLEU và độ tương tự cosine cấp câu, cả hai đều đã đạt được kết quả tốt. Và xem xét các token padding trong các câu, chúng tôi che chúng trong quá trình tính toán. Một metric dựa trên BLEU như sau:

SLI1(Y*, Y) = (1/m) ∑(i=1 to 4) bleu-i(Y*, Y) (4)

Trong đó thuật ngữ 'bleu-i' đề cập đến kết quả BLEU i-gram mà không sử dụng hàm làm mịn [15]. Y* biểu diễn kết quả được tạo sinh bởi mô hình, Y biểu diễn ground truth, và m là một siêu tham số được sử dụng để ánh xạ kết quả đến một giá trị xung quanh 1 để ngăn chặn mất cân bằng trong quá trình lấy mẫu.

Metric khác dựa trên độ tương tự cosine như sau:

SLI2(Y*, Y) = (1/m) CosinSimilarity(Y*, Y) = (embed(Y*) · embed(Y)) / (m · ||embed(Y*)|| · ||embed(Y)||) (5)

Trong đó m là siêu tham số, ánh xạ kết quả đến một giá trị xung quanh 1 để lấy mẫu không bị mất cân bằng; embed là word embedding và chuyển đổi chỉ số từ thành vector từ. Chúng tôi chỉ sử dụng word embedding trong decoder của mô hình. Một word embedding hiện có từ mô hình được huấn luyện trước như BERT[16] cũng có thể được sử dụng. Ở đây, đối với câu, nó là word embedding trung bình của các câu:

embed(Y) = (∑(i=1 to T) embed(y_i)) / T (6)

Trong đó T là độ dài của câu Y, y_i là từ thứ i.

Phương pháp này có những ưu điểm sau: Thứ nhất, toàn bộ câu có thể được tạo sinh cùng một lúc, tránh chi phí của nhiều tìm kiếm chùm và cải thiện hiệu quả. Thứ hai, nó xem xét thông tin cấp câu và có thể được kết hợp với lấy mẫu cấp từ để điều chỉnh động mỗi từ, cho phép mô hình lấy mẫu dựa trên chất lượng của từng từ riêng lẻ trong khi đồng thời tính đến chất lượng tổng thể của câu.

Hàm làm mịn giữa hai lớp lấy mẫu Để mô phỏng quá trình suy luận, các từ có xác suất tương ứng P cao hơn có xác suất được lấy mẫu cao hơn, vì vậy chúng tôi trực tiếp sử dụng P làm metric đánh giá cấp từ. Bây giờ chúng ta có điểm cấp câu S (kết quả của SLI) và điểm cấp từ P. Tuy nhiên, một phương pháp để kết hợp chúng vẫn còn thiếu. Xem xét rằng cả điểm cấp câu S và điểm cấp từ P đều quan trọng như nhau, chúng tôi nhân chúng và sau đó sử dụng một hàm làm mịn để ánh xạ tích đến phạm vi 0~1, như Hình 2.

Hiện tại, chúng tôi xem xét hai loại hàm. Loại đầu tiên đơn giản hơn, trực tiếp hạn chế kết quả đến 0~1, như phương trình 7.

f(x) = max(min(x,1),0) (7)

Loại thứ hai là một hàm hình sigmoid mịn hơn, như phương trình 8.

f(x) = 1/(1 + e^(-k(x-b))) (8)

trong đó k≥1 là một siêu tham số để kiểm soát tốc độ hội tụ, b>0 kiểm soát điểm đối xứng trung tâm của hàm, di chuyển nó sang phải. Cuối cùng chúng tôi đặt k=10, b=0.6. Hình ảnh của chúng trong Hình 4.

Lấy mẫu cấp từ Bây giờ, chúng ta đã có được điểm được làm mịn p, chứa thông tin kết hợp cấp câu và cấp từ, và chúng ta sử dụng nó để lấy mẫu từ cụ thể như được thể hiện trong Hình 3.

Đầu tiên, chúng tôi sử dụng lựa chọn xác suất để lấy mẫu như phương trình 9, có sự phân biệt lớn hơn giữa các từ khác nhau so với cắt ngưỡng. Nó cũng có thể lấy mẫu các từ khác nhau, làm cho mô hình được huấn luyện thích ứng hơn. Cụ thể, từ dự đoán Y* được chọn với xác suất p và ground truth Y được chọn với xác suất 1-p, và Y' là kết quả lấy mẫu đầu tiên.

Y' = {
  Y* lấy mẫu với xác suất p,
  Y ngược lại. (9)
}

Ngoài ra, để ngăn mô hình phụ thuộc quá nhiều vào các từ dự đoán có xác suất cao và khiến kết quả được tạo sinh quá đơn điệu, bài báo này cũng sử dụng một phương pháp lấy mẫu từ ngẫu nhiên, như phương trình 10. Khi xác suất dự đoán cấp từ P lớn hơn một ngưỡng được đặt α, một từ ngẫu nhiên được chọn làm đầu vào tiếp theo với một xác suất nhất định để ngăn mô hình thoái hóa.

sample = {
  Y' nếu P < α,
  rand ngược lại. (10)
}

trong đó rand đề cập đến một từ ngẫu nhiên, α là một ngưỡng được đặt thành 0.95, sample là kết quả được lấy mẫu cuối cùng làm đầu vào cho encoder trong quá trình huấn luyện.

4 Thí nghiệm

Để đánh giá tính hiệu quả và ưu điểm của mô hình Lấy mẫu theo lịch trình hai cấp được đề xuất được chi tiết trong nghiên cứu này, một bộ thí nghiệm toàn diện đã được tiến hành, bao gồm đánh giá, phân tích so sánh và nghiên cứu loại bỏ. Phần này làm rõ thiết kế thí nghiệm được sử dụng và cung cấp một đánh giá kỹ lưỡng về các kết quả thu được.

4.1 Bộ dữ liệu

Chúng tôi đánh giá phương pháp đề xuất sử dụng hai bộ dữ liệu đối thoại được sử dụng rộng rãi.
DailyDialog là một tập hợp các cuộc trò chuyện trong cuộc sống hàng ngày, bao gồm nhiều chủ đề, cảm xúc và phong cách ngôn ngữ khác nhau[17]. PersonaChat bao gồm các cuộc trò chuyện giữa hai người tham gia, trong đó một người tham gia đảm nhận một persona và người tham gia kia tham gia vào cuộc trò chuyện trong khi xem xét các đặc điểm của persona[18]. Sau khi tiền xử lý dữ liệu, chúng tôi chia đối thoại n-lượt (u1, u2, ..., un) thành n-1 đối thoại đơn lượt [(u1, u2), (u2, u3), ..., (un-1, un)], trong đó u biểu diễn một phát ngôn. Số cặp ngữ cảnh-phản hồi trong tập train/validation/test là 68,066/6,820/6,841 cho DailyDialog và 104,609/12,588/12,106 cho PersonaChat mà không có bất kỳ thông tin nhãn hoặc persona bổ sung nào.

4.2 Chi tiết thực hiện

Thí nghiệm sử dụng card đồ họa NVIDIA GeForce RTX 2080 Ti và áp dụng framework deep learning PyTorch để huấn luyện. Dropout được sử dụng cho module self-attention, lớp feed-forward, và lớp activation, và tỷ lệ của cả ba được đặt thành 0.1. Độ dài câu được đặt thành 26 và batch size được đặt thành 256. Kích thước vocab là 21626 cho DailyDialog và 22630 cho PersonaChat.

4.3 Phương pháp so sánh

Chúng tôi so sánh mô hình Lấy mẫu theo lịch trình hai cấp đề xuất với các phương pháp đã được thiết lập sau đây, và tất cả các cách tiếp cận đều dựa trên mô hình Transformer-base[11]:

– Transformer [11]: Mô hình Transformer-base được sử dụng trong tạo sinh đối thoại.
– AdapBridge [9]: Một cách tiếp cận lấy mẫu theo lịch trình được cải thiện, sử dụng cơ chế cầu nối thích ứng để đánh giá kết quả tạo sinh mô hình. Cụ thể, việc lựa chọn được thực hiện theo kết quả độ tương tự cosine của từ dự đoán và ground truth. Nếu nó lớn hơn ngưỡng β, từ dự đoán được lấy mẫu theo xác suất α thay đổi theo số epoch huấn luyện. Theo bài báo, chúng tôi đặt w = 15 là một nửa số epoch huấn luyện và các siêu tham số khác không được thay đổi.
– Confidence-Aware [10]: Một phương pháp lấy mẫu theo lịch trình được cải thiện, lựa chọn có lấy mẫu hay không theo độ tin cậy của kết quả dự đoán (tức là xác suất dự đoán). Cụ thể, nó đặt hai ngưỡng t_golden và t_rand, và lấy mẫu ground truth, kết quả dự đoán mô hình, một từ ngẫu nhiên khi độ tin cậy tương ứng trong [0, t_golden), [t_golden, t_rand), [t_rand,1]. Chúng tôi đặt t_golden = 0.7 và t_rand = 0.95 để có được kết quả tốt nhất.

Đồng thời, các thí nghiệm loại bỏ được tiến hành trong bài báo này. Đối với các mô hình khác nhau, chúng tôi đã thử nghiệm các giá trị siêu tham số khác nhau cho m, và trình bày kết quả tốt nhất. Mô hình đề xuất để thử nghiệm loại bỏ như sau:

– Bilevel-None: Mô hình lấy mẫu theo lịch trình hai cấp được đề xuất trong bài báo này mà không có phần lấy mẫu cấp câu. Hàm làm mịn là phương trình 8 hình sigmoid và phương pháp lấy mẫu cấp từ không thay đổi.
– Bilevel-Bleu: Mô hình lấy mẫu theo lịch trình hai cấp được đề xuất trong bài báo này, chỉ số cấp câu là metric Bleu với m = 0.8 để có được kết quả tốt nhất. Hàm làm mịn là phương trình 8.
– Bilevel-Cosine: Mô hình lấy mẫu theo lịch trình hai cấp được đề xuất trong bài báo này, chỉ số cấp câu là độ tương tự cosine cấp câu với m = 0.6 để có được kết quả tốt nhất. Hàm làm mịn là phương trình 8.
– Bilevel-f1: Mô hình lấy mẫu theo lịch trình hai cấp được đề xuất trong bài báo này, chỉ số cấp câu là metric Bleu với m = 0.9 để có được kết quả tốt nhất. Hàm làm mịn là phương trình 7 cắt tuyến tính.

4.4 Đánh giá tự động

Chúng tôi đánh giá hiệu suất tạo sinh đối thoại nơi cả metrics đánh giá tự động và con người được áp dụng. Metrics đánh giá tự động bao gồm BLEU-1/2/3/4 [15], Distinct-1/2/3 [19]. Kết quả được thể hiện trong Bảng 1.

Các phát hiện thí nghiệm chứng minh một cải thiện hiệu suất đáng chú ý của mô hình lấy mẫu theo lịch trình hai cấp đề xuất so với cả mô hình lấy mẫu theo lịch trình truyền thống và mô hình đề xuất thiếu lấy mẫu cấp câu, như được chứng minh bởi các điểm BLEU-1/2/3/4 cao hơn đạt được. Sự vượt trội này có thể được quy cho việc kết hợp thông tin cấp câu trong mô hình đề xuất, dẫn đến việc tạo sinh các câu mạch lạc và tự nhiên hơn, do đó đạt được sự liên kết tốt hơn với ground truth. Hơn nữa, người ta quan sát thấy rằng việc sử dụng BLEU làm điểm cấp câu mang lại kết quả tốt hơn so với độ tương tự cosine cấp câu. Sự khác biệt này có thể phát sinh từ thực tế là BLEU đặt trọng tâm lớn hơn vào việc khớp văn bản, trong khi độ tương tự cosine tập trung nhiều hơn vào sự liên kết ngữ nghĩa, do đó ủng hộ cái trước để cải thiện kết quả BLEU.

Ngoài ra, mô hình đề xuất thể hiện một ưu thế trong metric Distinct-1/2/3. Ưu thế này bắt nguồn từ việc kết hợp thông tin lấy mẫu cấp câu và việc sử dụng lấy mẫu xác suất để tạo sinh từ. Mô hình hai cấp hiệu quả tạo sinh các câu đa dạng hơn, giảm thiểu vấn đề đầu ra quá lặp lại hoặc đơn lẻ, và do đó đạt được điểm cao hơn trong metric Distinct.

Tóm lại, kết quả thí nghiệm chứng minh rằng bằng cách kết hợp cấp câu và cấp từ được xem xét cùng với lấy mẫu xác suất, mô hình đề xuất vượt trội so với các mô hình lấy mẫu theo lịch trình hiện có về cả metrics BLEU-1/2/3/4 và Distinct-1/2/3. Điều này cho thấy mô hình lấy mẫu theo lịch trình hai cấp giảm đáng kể vấn đề thiên lệch phơi nhiễm và vượt trội so với các phương pháp lấy mẫu theo lịch trình tiên tiến.

4.5 Đánh giá con người

Để đánh giá kỹ lưỡng mô hình đề xuất và mô hình baseline được đề cập trong bài báo này, chúng tôi đã tiến hành đánh giá con người theo cách tiếp cận được sử dụng bởi Li et al[20]. Cho đánh giá này, chúng tôi ngẫu nhiên chọn 100 mẫu từ tập test của mỗi bộ dữ liệu đối thoại. Sau đó, chúng tôi tìm kiếm phán đoán của ba người chú thích có học thức để xác định liệu chất lượng phản hồi tổng thể của mô hình Bilevel-Bleu và các mô hình khác đang xem xét có thể hiện tính mạch lạc, thông tin và trôi chảy vượt trội hay không. Các người chú thích phân loại đánh giá của họ là thắng, hòa, hoặc thua cho mỗi mô hình.

Bảng 2 tóm tắt kết quả đánh giá con người. Kết quả cuối cùng cho thấy mô hình Bilevel-Bleu trong bài báo này tốt hơn các mô hình khác, điều này cho thấy nó có khả năng tạo sinh phản hồi được con người ưa thích hơn. Đồng thời, chúng tôi sử dụng Fleiss kappa [21] để đo lường sự đồng thuận giữa các người chú thích, và kết quả đều lớn hơn 0.4, cho thấy các người chú thích đạt được sự đồng thuận tốt trong việc phán đoán.

4.6 Nghiên cứu loại bỏ

Trong bài báo này, chúng tôi thiết kế một thí nghiệm so sánh bao gồm mô hình đề xuất mà không có lấy mẫu cấp câu và với hai lấy mẫu cấp câu khác nhau. Như có thể thấy từ Bảng 1, cho dù chỉ số cấp câu sử dụng bleu hay độ tương tự cosine, mô hình kết hợp lấy mẫu cấp câu và cấp từ trong bài báo này sẽ có kết quả tốt hơn mô hình lấy mẫu cấp từ đơn lẻ. Đồng thời, cũng có thể thấy từ kết quả rằng hiệu suất của mô hình đề xuất được cải thiện đáng kể so với mô hình transformer cơ bản khi chỉ thực hiện lấy mẫu cấp từ, với kết quả hơi tốt hơn các phương pháp lấy mẫu theo lịch trình hiện có. Điều này cho thấy cách tiếp cận lấy mẫu xác suất trong bài báo này tốt hơn cắt ngưỡng nếu chúng ta ánh xạ xác suất gốc đến kích thước phù hợp bằng hàm làm mịn.

Ngoài ra, chúng tôi tiến hành các thí nghiệm so sánh về các hàm làm mịn, bao gồm hàm cắt tuyến tính f1 (phương trình 7) và hàm làm mịn hình sigmoid f2 (phương trình 8). Kết quả trong Bảng 3.

Kết quả cho thấy hàm làm mịn hình sigmoid cho kết quả tốt hơn, cho phép mô hình lấy mẫu các câu phù hợp hơn. Điều này là do lấy mẫu xác suất trực tiếp không đủ để phân biệt các phát ngôn chất lượng cao và thấp. Bằng cách sử dụng hàm làm mịn hình sigmoid, ảnh hưởng của hiệu suất câu lên xác suất lấy mẫu được tăng cường, dẫn đến một quá trình lấy mẫu mượt mà và hiệu quả hơn.

5 Kết luận

Trong bài báo này, chúng tôi đề xuất một mô hình lấy mẫu theo lịch trình hai cấp, xem xét chất lượng kết hợp cấp câu và cấp từ của kết quả tạo sinh mô hình, để kết quả lấy mẫu có thể thích ứng tốt hơn với thiên lệch phơi nhiễm và do đó cải thiện hiệu suất của mô hình. Để làm cho việc lấy mẫu đa dạng hơn và cải thiện khả năng thích ứng của mô hình, chúng tôi đề xuất một hàm làm mịn để ánh xạ kết quả kết hợp của cấp câu và cấp từ đến một phạm vi phù hợp, và sau đó thực hiện lấy mẫu xác suất thay vì cắt ngưỡng. Các thí nghiệm trên hai bộ dữ liệu đối thoại miền mở được sử dụng rộng rãi chứng minh tính hiệu quả của tất cả các phương pháp đề xuất của chúng tôi, giúp giảm đáng kể vấn đề thiên lệch phơi nhiễm và vượt trội so với các phương pháp lấy mẫu theo lịch trình tiên tiến.

Trong tương lai, chúng tôi dự định mở rộng ứng dụng của phương pháp Lấy mẫu theo lịch trình hai cấp cho các mô hình ngôn ngữ lớn trên nhiều dự án khác nhau, giải quyết vấn đề thiên lệch phơi nhiễm. Cách tiếp cận này sẽ giúp tăng cường hiệu suất và tính mạnh mẽ của các mô hình trong các tình huống thực tế.

Lời cảm ơn
Nghiên cứu này được hỗ trợ bởi Quỹ Khoa học Tự nhiên Bắc Kinh (Số 4222037, L181010).

Tài liệu tham khảo

1. Bengio, S., Vinyals, O., Jaitly, N., Shazeer, N.: Scheduled sampling for sequence prediction with recurrent neural networks. Advances in neural information processing systems 28(2015)
2. Wiseman, S., Rush, A.M.: Sequence-to-sequence learning as beam-search optimization. arXiv preprint arXiv:1606.02960 (2016)
3. Venkatraman, A., Hebert, M.H., Bagnell, J.A.: Improving multi-step prediction of learned time series models. In: National Conference on Artificial Intelligence. AAAI Press (2015)
4. Ranzato, M., Chopra, S., Auli, M., Zaremba, W.: Sequence level training with recurrent neural networks. Computer Science (2015)
5. Mihaylova, T., Martins, A.F.: Scheduled sampling for transformers. arXiv preprint arXiv:1906.07651 (2019)
6. Yu, L., Zhang, W., Wang, J., Yu, Y.: Seqgan: Sequence generative adversarial nets with policy gradient. In: Proceedings of the AAAI conference on artificial intelligence (2017)
7. Nie, W., Narodytska, N., Patel, A.: Relgan: Relational generative adversarial networks for text generation. In: International conference on learning representations (2018)
8. Zhang, W., Feng, Y., Meng, F., You, D., Liu, Q.: Bridging the gap between training and inference for neural machine translation. arXiv preprint arXiv:1906.02448 (2019)
9. Xu, H., Zhang, H., Zou, Y., Chen, H., Ding, Z., Lan, Y.: Adaptive bridge between training and inference for dialogue generation. In: Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. pp. 2541–2550 (2021)
10. Liu, Y., Meng, F., Chen, Y., Xu, J., Zhou, J.: Confidence-aware scheduled sampling for neural machine translation. arXiv preprint arXiv:2107.10427 (2021)
11. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I.: Attention is all you need. Advances in neural information processing systems 30(2017)
12. Goodman, S., Ding, N., Soricut, R.: Teaforn: Teacher-forcing with n-grams. In: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). pp. 8704–8717 (2020)
13. Liu, Y., Meng, F., Chen, Y., Xu, J., Zhou, J.: Scheduled sampling based on decoding steps for neural machine translation. arXiv preprint arXiv:2108.12963 (2021)
14. Ackley, D.H., Hinton, G.E., Sejnowski, T.J.: A learning algorithm for boltzmann machines. Cognitive Science 9(1), 147–169 (1985)
15. Papineni, K., Roukos, S., Ward, T., Zhu, W.J.: Bleu: a method for automatic evaluation of machine translation. In: Proceedings of the 40th annual meeting of the Association for Computational Linguistics. pp. 311–318 (2002)
16. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018)
17. Li, Y., Su, H., Shen, X., Li, W., Cao, Z., Niu, S.: Dailydialog: A manually labelled multi-turn dialogue dataset. arXiv preprint arXiv:1710.03957 (2017)
18. Zhang, S., Dinan, E., Urbanek, J., Szlam, A., Kiela, D., Weston, J.: Personalizing dialogue agents: I have a dog, do you have pets too? arXiv preprint arXiv:1801.07243 (2018)
19. Li, J., Galley, M., Brockett, C., Gao, J., Dolan, B.: A diversity-promoting objective function for neural conversation models. arXiv preprint arXiv:1510.03055 (2015)
20. Li, J., Monroe, W., Shi, T., Jean, S., Ritter, A., Jurafsky, D.: Adversarial learning for neural dialogue generation. arXiv preprint arXiv:1701.06547 (2017)
21. Fleiss, J.L.: Measuring nominal scale agreement among many raters. Psychological bulletin 76(5), 378 (1971)

# 2206.14371.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/shared-params/2206.14371.pdf
# Kích thước tệp: 2535875 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Matryoshka: Đánh cắp chức năng của dữ liệu ML riêng tư bằng cách ẩn mô hình trong mô hình
Xudong Pan, Yifan Yan, Shengyao Zhang, Mi Zhang, Min Yang
Trường Khoa học Máy tính
Đại học Fudan, Trung Quốc
fxdpan18,yanyf20g@fudan.edu.cn, shengyaozhang21@m.fudan.edu.cn, fmizhang,m yangg@fudan.edu.cn
Tóm tắt —Dữ liệu học máy (ML) riêng tư chất lượng cao
trở thành yếu tố cạnh tranh quan trọng cho các tập đoàn AI. Mặc dù
được lưu trữ cẩn thận trong các trung tâm dữ liệu cục bộ, một tập dữ liệu riêng tư
vẫn có thể bị đánh cắp một khi mô hình mạng nơ-ron sâu (DNN)
được huấn luyện trên tập dữ liệu đó được công khai hoặc có thể truy cập như một
API dự đoán. Nếu đó là sự căng thẳng vốn có giữa giao diện mô hình mở
và tập dữ liệu riêng tư để lại một bề mặt tấn công có thể khai thác,
chúng tôi tự hỏi liệu một tập dữ liệu riêng tư không có giao diện tiếp xúc
có thể không thể xâm phạm được không.
Trong bài báo này, chúng tôi trình bày một cuộc tấn công nội bộ mới gọi là Ma-
tryoshka, sử dụng một mô hình DNN không liên quan được lên lịch công bố
như một mô hình vận chuyển để truyền tải bí mật nhiều mô hình
bí mật ghi nhớ chức năng của dữ liệu ML riêng tư được lưu trữ trong các trung tâm dữ liệu cục bộ. Thay vì coi các tham số
của mô hình vận chuyển như chuỗi bit và áp dụng steganography thông thường,
chúng tôi đưa ra một phương pháp chia sẻ tham số mới
khai thác khả năng học tập của mô hình vận chuyển để
ẩn thông tin. Matryoshka đồng thời đạt được: (i) Dung
lượng cao – Với gần như không mất tiện ích của mô hình vận chuyển,
Matryoshka có thể ẩn một mô hình bí mật lớn gấp 26 lần hoặc 8 mô hình
bí mật với các kiến trúc đa dạng trải dài trên các lĩnh vực ứng dụng
khác nhau trong mô hình vận chuyển, điều mà không thể thực hiện được với
các kỹ thuật steganography hiện có; (ii) Hiệu quả giải mã – một khi
tải xuống mô hình vận chuyển đã công bố, một kẻ đồng lõa bên ngoài
có thể giải mã độc quyền các mô hình ẩn từ mô hình vận chuyển
chỉ với vài bí mật số nguyên và kiến thức về kiến trúc
mô hình ẩn; (iii) Hiệu quả – Hơn nữa, gần như tất cả các
mô hình được khôi phục có hiệu suất tương tự như khi được huấn luyện
độc lập trên dữ liệu riêng tư; (iv) Mạnh mẽ – Dự phòng thông tin
được triển khai tự nhiên để đạt được khả năng chống chịu trước các
kỹ thuật hậu xử lý phổ biến trên mô hình vận chuyển trước khi
công bố; (v) Che giấu – Một thanh tra mô hình với các
mức độ kiến thức trước khác nhau khó có thể phân biệt một mô hình vận chuyển
khỏi một mô hình bình thường.
Từ khóa chỉ mục —học sâu, quyền riêng tư dữ liệu, truyền tải bí mật
I. GIỚI THIỆU
"Sự có sẵn của các tập dữ liệu lớn là yếu tố cho phép quan trọng của
học sâu", như được nêu bởi Bengio và cộng sự trong bài giảng Turing [1].
Các tập dữ liệu học máy (ML) riêng tư chất lượng cao trở thành
tài sản quan trọng cho các tập đoàn AI để huấn luyện các mô hình ML
hiệu suất cao [2]. Vì việc chuẩn bị tập dữ liệu rất tốn thời gian
và tốn công sức, việc các bên liên quan giữ
dữ liệu ML riêng tư như tài sản bí mật là điều phổ biến [3].
Mặc dù dữ liệu ML được tuyển chọn cẩn thận trong các trung tâm dữ liệu
cục bộ được cách ly khỏi mạng mở [4], nghiên cứu gần đây về
quyền riêng tư ML [5]–[9] tiết lộ, một khi mạng nơ-ron sâu (DNN)
hoàn thành quá trình huấn luyện trên một tập dữ liệu riêng tư, mô hình
ngay lập tức trở thành nguồn có thể khai thác để vi phạm quyền riêng tư.
Bằng cách tương tác với mô hình đã huấn luyện theo cách có đầy đủ kiến thức
(tức là với các tham số đã biết, kiến trúc mô hình,
v.v.) hoặc thông qua API dự đoán, các cuộc tấn công được biết là suy luận
các thuộc tính nhạy cảm toàn cục/cá nhân của dữ liệu huấn luyện [10]–
[13], suy luận thành viên dữ liệu [14], [15], hoặc thậm chí đánh cắp toàn bộ
chức năng của các tập dữ liệu riêng tư từ mô hình đã huấn luyện
[5], [6], [8]. Sự thành công của các cuộc tấn công trước đó phản ánh
sự căng thẳng giữa dữ liệu bí mật và mô hình đã huấn luyện
có thể truy cập công khai. Chúng tôi tự hỏi, nếu chặn nguồn rò rỉ này,
liệu một tập dữ liệu riêng tư không có giao diện công khai nào được tiếp xúc có
miễn nhiễm với các cuộc tấn công đánh cắp dữ liệu không.
Công việc của chúng tôi. Chúng tôi là những người đầu tiên khám phá ra rò rỉ nghiêm trọng
của chức năng dữ liệu có thể xảy ra ngay cả đối với các tập dữ liệu ML riêng tư
không có giao diện công khai nào được tiếp xúc. Thay vì khai thác một
mô hình đã huấn luyện từ bên ngoài, công việc của chúng tôi đề xuất một cuộc tấn công
nội bộ mới có thể được thực hiện bởi các kỹ sư DNN
có quyền truy cập vào (các) tập dữ liệu riêng tư mục tiêu và chịu trách nhiệm
sử dụng một tập dữ liệu không liên quan để huấn luyện một
mô hình được lên lịch công bố độc lập (tức là mô hình vận chuyển). Trong các
mô hình bảo mật dữ liệu phổ biến được nhiều tập đoàn AI áp dụng,
những kẻ tấn công tiềm năng với vai trò như vậy là phổ biến (§III-B). Nói cách khác,
công việc của chúng tôi lần đầu tiên tiết lộ một bề mặt tấn công mới nơi kẻ tấn công
có thể đánh cắp chức năng của dữ liệu ML riêng tư mà không cần tiếp xúc
với bất kỳ mô hình nào được huấn luyện trên (các) tập dữ liệu nạn nhân.
Như Hình 1 cho thấy, để phá vỡ quyền riêng tư của dữ liệu ML không có giao
diện tiếp xúc, cuộc tấn công của chúng tôi sử dụng một mô hình DNN không liên quan
được lên lịch công bố làm mô hình vận chuyển để truyền tải bí mật
nhiều mô hình hướng nhiệm vụ được huấn luyện trên các tập dữ liệu riêng tư
khác nhau (tức là các nạn nhân) để đánh cắp chức năng. Một khi kẻ đồng lõa
bên ngoài giải mã các mô hình bí mật này từ mô hình vận chuyển,
các mô hình hướng nhiệm vụ thu được sẽ ngay lập tức
chia sẻ chức năng tương tự như khi được huấn luyện trên dữ liệu riêng tưarXiv:2206.14371v1  [stat.ML]  29 Jun 2022

--- TRANG 2 ---
dữ liệu. Chúng tôi đặt tên cho lớp tấn công mới này là Matryoshka (búp bê lồng
nhau trong tiếng Nga1), phản ánh phương pháp tấn công mới của chúng tôi là
ẩn mô hình trong mô hình, hay ẩn mô hình.
Thách thức chính của việc ẩn mô hình là tìm
dung lượng mã hóa đủ cho hàng triệu hoặc thậm chí hàng tỷ
tham số dấu phẩy động trong một DNN bí mật. Đơn giản coi
các tham số của mô hình vận chuyển như chuỗi bit, các
kỹ thuật steganography hiện có [16]–[20] bị giới hạn nghiêm ngặt
về dung lượng mã hóa, vốn nhỏ hơn nhiều so với kích thước của
mô hình vận chuyển. Nút thắt cổ chai này làm giảm đáng kể
tính linh hoạt trong việc ẩn mô hình. Ví dụ, chúng không thể
mã hóa một mô hình bí mật trong phương tiện vận chuyển thông thường (ví dụ:
văn bản hoặc hình ảnh), mã hóa một mô hình bí mật lớn hơn trong một
mô hình vận chuyển nhỏ, hoặc mã hóa nhiều mô hình bí mật trong một
mô hình vận chuyển đồng thời cho các mục đích tấn công khác nhau.
Hơn nữa, các nghiên cứu trước thường cố gắng mã hóa dữ liệu
rất khác biệt vào các tham số của mô hình vận chuyển.
Không có thiết kế đặc biệt, hiệu suất của mô hình vận chuyển
có thể giảm xuống mức không thể chấp nhận được để gây nghi ngờ. Cuối cùng,
độ mạnh mẽ của các kỹ thuật ẩn dữ liệu hiện có cũng có thể
ảnh hưởng đến các mô hình bí mật khi có sự che khuất tiềm năng
được thực hiện trên mô hình vận chuyển [21].
Cốt lõi của Matryoshka, chúng tôi đưa ra một cơ chế chia sẻ tham số
mới thay vào đó khai thác khả năng học tập khổng lồ của DNN để triển khai
dung lượng mã hóa lớn hơn nhiều cho việc ẩn mô hình. Một cách trực quan,
cơ chế chia sẻ tham số của chúng tôi dựa trên một cấu trúc dữ liệu gọi là ParamPool,
lưu trữ một mảng các tham số có thể học được có thể tái sử dụng,
tức là chúng được thiết kế để điền vào các lớp khác nhau của một DNN
nhất định nhiều lần, và cho phép truy cập vòng tròn. Nói cách khác,
nhiều DNN, bao gồm cả các mô hình bí mật
và mô hình vận chuyển, có thể được tạo ra từ cùng một
ParamPool bằng cách tái chế các tham số bên trong (§V-B). Để
mã hóa các mô hình bí mật trong một mô hình vận chuyển, chúng tôi cùng
huấn luyện mô hình vận chuyển cùng với các mô hình bí mật với
các tham số được tạo ra từ ParamPool. Trong quá
trình học tập, lỗi lan truyền và tích lũy đến
tham số tương ứng trong ParamPool, nơi việc cập nhật
cuối cùng xảy ra. Nhận thức của chúng tôi đằng sau việc sử dụng ParamPool
để chia sẻ tham số đến từ một nghiên cứu thí điểm quan sát
phân phối tham số khá tương tự của một loạt DNN
được huấn luyện tốt trên các lĩnh vực ứng dụng khác nhau (§V-C). Sau khi
mô hình vận chuyển được công bố trực tuyến, kẻ đồng lõa bên ngoài
có thể giải mã ParamPool từ mô hình vận chuyển với một
số lượng nhỏ khóa số nguyên bí mật, và lắp ráp (các) mô hình
bí mật để vi phạm quyền riêng tư (§V-D).
Đóng góp của chúng tôi. Như một mối đe dọa mới được khám phá đối với dữ liệu
ML riêng tư, cuộc tấn công Matryoshka được đề xuất của chúng tôi triển khai
các thuộc tính chính sau đây để truyền tải hiệu quả và bí mật
các mô hình bí mật đánh cắp chức năng dữ liệu.
Dung lượng cao: Với gần như không mất tiện ích (<1%),
Matryoshka có thể ẩn một mô hình bí mật lớn gấp 26 lần, hoặc 8 mô hình
bí mật với các kiến trúc khác nhau trải dài các ứng dụng hình ảnh, âm thanh và

1Theo quy ước, búp bê Matryoshka bên trong (tức là các mô hình bí mật) quý giá hơn
búp bê bên ngoài chứa chúng (tức là mô hình vận chuyển).văn bản cùng một lúc trong mô hình vận chuyển, điều mà không thể
thực hiện được với các kỹ thuật steganography hiện có.
Hiệu quả giải mã: Các mô hình bí mật có thể được giải mã và
lắp ráp hiệu quả từ mô hình vận chuyển chỉ với
vài bí mật số nguyên được kẻ đồng lõa biết độc quyền,
với điều kiện các mô hình bí mật có kiến trúc tiêu chuẩn.
Hiệu quả: Gần như tất cả các mô hình bí mật được khôi phục đều
có hiệu suất tương tự như khi chúng được huấn luyện độc lập
trên tập dữ liệu riêng tư.
Mạnh mẽ: Matryoshka tự nhiên triển khai dự phòng thông tin
[22] thông qua việc sử dụng ParamPool nhỏ hơn, giúp
đạt được khả năng chống chịu trước các kỹ thuật hậu xử lý có thể có
trên mô hình vận chuyển trước khi công bố.
Che giấu: Bên cạnh đó, chúng tôi cũng cung cấp một thảo luận sơ bộ
về tính che giấu của Matryoshka khi một bộ phát hiện với
các mức độ kiến thức trước khác nhau về cuộc tấn công cố gắng
phân biệt một mô hình vận chuyển khỏi một mô hình bình thường (§VI-F),
mà chúng tôi hy vọng có thể thúc đẩy các nghiên cứu phòng thủ trong tương lai.
II. CÔNG VIỆC LIÊN QUAN
Các cuộc tấn công quyền riêng tư trên dữ liệu huấn luyện. Gần đây, các mô hình
ML đã huấn luyện được chứng minh là có thể khai thác cao cho kẻ tấn công
để đánh cắp thông tin riêng tư về dữ liệu huấn luyện. Một nhánh của
các cuộc tấn công tập trung nhiều hơn vào quyền riêng tư của dữ liệu huấn luyện
như một tổng thể. Suy luận thông tin nhạy cảm toàn cục của dữ liệu
huấn luyện, cuộc tấn công đảo ngược mô hình [10], [13] và cuộc tấn công suy luận
thuộc tính [11], [23] tương ứng nhắm vào việc tiết lộ các đại diện lớp
của dữ liệu huấn luyện (ví dụ: khuôn mặt trung bình của một danh tính khi
tấn công mô hình nhận dạng khuôn mặt) và liệu một vị từ bậc nhất
có giữ trên dữ liệu huấn luyện hay không (ví dụ: liệu một tập dữ liệu khuôn mặt
có chứa người da trắng hay không). Đánh cắp chức năng của
một tập dữ liệu huấn luyện riêng tư, cuộc tấn công trích xuất mô hình xây dựng một
mô hình thay thế bằng cách chưng cất API dự đoán hộp đen [5]–
[7], [24] hoặc trực tiếp thiết kế ngược các tham số mô hình bằng
cách khai thác thuộc tính của các đơn vị tuyến tính khắc phục [8], [25],
[26]. Với độ chi tiết tấn công tinh hơn, một nhánh khác của các cuộc tấn công
nhằm phá vỡ quyền riêng tư của các mẫu huấn luyện đơn lẻ. Ví dụ,
cuộc tấn công suy luận thành viên thay vào đó hướng đến suy luận
liệu một mẫu truy vấn có thuộc về tập huấn luyện thông qua truy cập
hộp trắng [14], bằng cách biết các giá trị tin cậy dự đoán
[15], hoặc bằng việc tiếp xúc chỉ nhãn [27], [28] từ một mô hình đã huấn luyện.
Khác biệt, những năm gần đây còn chứng kiến các công việc suy luận
thông tin nhạy cảm cấp mẫu hoặc thậm chí tái tạo
các mẫu huấn luyện thô từ kết quả tính toán trung gian
(ví dụ: đặc trưng [29] và gradient [12], [30], [31]) và đầu ra mô hình
[32]–[35]. Ngược lại, thay vì khai thác một DNN đã được huấn luyện tốt
để thăm dò dữ liệu huấn luyện của nó, chúng tôi lần đầu tiên
khám phá và tiết lộ rủi ro của một tập dữ liệu huấn luyện riêng tư thậm chí
không có giao diện tiếp xúc nào, mà chúng tôi hy vọng có thể thúc đẩy đáng kể
các cơ chế kiểm soát truy cập toàn diện hơn.
Ẩn dữ liệu trong mạng nơ-ron. Ẩn dữ liệu, hay steganography,
là một lĩnh vực nghiên cứu lâu đời trong cộng đồng của chúng ta
[16], [21]. Với sự phát triển gần đây của chuỗi cung ứng mô hình
mã nguồn mở, một số công trình nghiên cứu cũng khai thác DNN như một
phương tiện mới để ẩn thông tin nhị phân. Ở giai đoạn đầu,
Uchida và cộng sự [20] và Song và cộng sự [19] đồng thời khám phá
ý tưởng ẩn dữ liệu trong DNN nhưng với các trọng tâm nghiên cứu khác nhau.
Để bảo vệ sở hữu trí tuệ của DNN, Uchida và cộng sự
đề xuất nhúng một thông điệp nhị phân ngẫu nhiên bí mật vào các
tham số mô hình thông qua các kỹ thuật steganography thông thường
(ví dụ: bit ít quan trọng nhất hoặc mã hóa dấu). Bằng cách xác minh
liệu một mô hình có chứa thông điệp nhị phân hay không, quyền sở hữu được
thiết lập. Sau đó, công trình tiên phong này thúc đẩy nghiên cứu trực giao
về việc đóng dấu nước DNN [36]–[38]. Thay vì bảo vệ mô hình,
Song và cộng sự nhằm ẩn thông tin nhạy cảm
về dữ liệu riêng tư vào các tham số mô hình trong quá trình
huấn luyện. Cụ thể, họ trực tiếp chuyển đổi một tập con của các
đầu vào dữ liệu nhạy cảm thành dạng nhị phân và mã hóa chúng vào
các tham số mô hình một lần nữa với gần như cùng bộ kỹ thuật
steganography thông thường trong [20].
III. SƠ BỘ
A. Nền tảng về Học máy (ML)
Khái niệm trong ML. Trong công việc của chúng tôi, chúng tôi gọi một cơ sở dữ liệu riêng tư
là một tập dữ liệu ML nếu nó được chuẩn bị để huấn luyện các mô hình ML.
Trong bài báo này, chúng tôi chủ yếu tập trung vào nhiệm vụ học có giám sát,
được định nghĩa trong không gian X×Y. Ở đây, X là không gian đầu vào,
bao gồm dữ liệu thô bao gồm nhưng không giới hạn ở hình ảnh, văn bản hoặc âm thanh,
và Y là không gian nhãn. Một mô hình học f(·;θ) (:= f) : X → Y
nhằm xây dựng mối quan hệ từ một phần tử trong X đến nhãn trong
Y, bao gồm tất cả các giá trị có thể trong chú thích.
Ví dụ, trong một nhiệm vụ phân loại hình ảnh K lớp, X bao gồm
một tập hợp các hình ảnh cần được phân loại, trong khi Y = {1, ..., K}, tức là
các lớp có thể. Cuối cùng, quá trình huấn luyện của một mô hình học
f liên quan đến tối ưu hóa một hàm mất mát, ký hiệu
là ℓ(·,·), đối với các tham số của mô hình học.
Cơ bản về Học sâu. Thập kỷ qua đã chứng kiến sự
tiến hóa của các kỹ thuật học sâu (DL) trong hầu hết các nhiệm vụ
ML quan trọng [39], cho thấy những cải tiến đáng kể so với
các kỹ thuật ML cổ điển, và đã đạt sâu
vào một loạt các ứng dụng quan trọng trong thế giới thực
[40]–[42]. Cốt lõi của DL là mạng nơ-ron sâu
(DNN), một họ các mô hình học bao gồm
một số lớp xử lý (ví dụ: lớp tuyến tính/kích hoạt,
lớp tích chập/gộp, v.v.) biến đổi biểu diễn dữ liệu
thông qua nhiều mức độ trừu tượng [43]. Thông thường, một
lớp trong DNN bao gồm một tập hợp các tham số có thể học,
được cập nhật lặp đi lặp lại để tối ưu hóa hàm mất mát thông qua
các bộ tối ưu hóa dựa trên gradient sẵn có (ví dụ: Adam [44]).
Như một nhận xét cuối cùng, chúng tôi nhấn mạnh việc khởi tạo tham số
thích hợp là không thể thiếu để đạt được một mô hình DNN gần tối ưu
trong suốt quá trình huấn luyện. Các tham số có thể học của các
vai trò khác nhau (tức là trọng số, bias và tỷ lệ) thường được khởi tạo với
các sơ đồ riêng biệt và cũng có thể khác nhau trong các ràng buộc về
giá trị của chúng. Ví dụ, một vô hướng trọng số thường được khởi tạo
từ Gaussian, một vô hướng bias được khởi tạo là 0, trong khi một
vô hướng tỷ lệ là 1 với ràng buộc không âm. Chi tiết kỹ thuật này
ảnh hưởng đến các thiết kế tấn công tiếp theo của chúng tôi.
B. Mô hình bảo mật dữ liệu trong các tập đoàn AI
Như nền tảng thiết yếu để thảo luận về các cuộc tấn công nội bộ,
chúng tôi cung cấp dưới đây một nghiên cứu thực địa về các cơ chế bảo mật dữ liệu
điển hình trong các tập đoàn AI.
Các cơ chế phổ biến. Hệ thống ngăn ngừa rò rỉ dữ liệu
(DLPS) là một trong những giải pháp bảo mật chủ đạo nhất trong
ngành. DLPS có thể xác định, giám sát và bảo vệ dữ liệu
bí mật và phát hiện việc truyền dữ liệu bất hợp pháp dựa trên các
quy tắc được định nghĩa trước [45]. Theo Securosis, DLPS được
triển khai thực tế bên trong các tập đoàn thường có hạn chế
nghiêm ngặt về việc truyền dữ liệu đến các thiết bị đầu cuối không được ủy quyền
(ví dụ: Wi-Fi, Bluetooth, USB) hoặc ra mạng bên ngoài mà không có
sự cho phép [46], tức là không thể cho một kẻ tấn công nội bộ ngây thơ
trực tiếp truyền các tập dữ liệu riêng tư từ mạng cục bộ ra ngoài
mà không bị phát hiện. Với DLPS chặn rò rỉ dữ liệu tiềm năng
ra ngoài, các chính sách kiểm soát truy cập khác nhau được
triển khai bởi các tập đoàn AI để quản lý các tập dữ liệu riêng tư
thuộc sở hữu của họ. Trong phần sau, chúng tôi giới thiệu hai chế độ
điển hình được đặt tên là chế độ Sẵn sàng chia sẻ và chế độ Ứng dụng-rồi-
Ủy quyền, theo các đối tác ngành của chúng tôi.
• Chế độ Sẵn sàng chia sẻ. Đối với các tập đoàn khởi nghiệp tập trung vào
một ứng dụng chủ lực (ví dụ: phát hiện đối tượng [47]),
họ thích tổ chức các tập dữ liệu theo cách có thể chia sẻ hơn.
Theo nghiên cứu thực địa của chúng tôi, phần lớn các nhóm tổ chức
tất cả các tập dữ liệu (từ nguồn công khai hoặc riêng tư) trong
hệ thống tệp phân tán cục bộ của họ, cho phép truy cập nhanh vào
các tập dữ liệu cụ thể theo yêu cầu của một người và tạo điều kiện
phát triển nhanh chóng các kỹ thuật DL mới.
• Chế độ Ứng dụng-rồi-Ủy quyền. Các tập đoàn AI đã thiết lập hơn
thích triển khai cách quản lý tập dữ liệu ML bảo thủ hơn.
Theo sách trắng bảo mật chung của Google [4], mỗi nhân viên trước tiên
phải đăng ký xin ủy quyền trước khi truy cập các tài nguyên dữ liệu
nhất định, bao gồm việc truy cập vào các tập dữ liệu riêng tư. Tuy nhiên,
xem xét các mô hình luôn thay đổi trong học sâu,
nhân viên có động cơ xấu có thể bịa ra lý do như
yêu cầu tăng cường dữ liệu [48] hoặc mục đích
học đa phương thức [49] để đăng ký các tập dữ liệu riêng tư
liên quan và không liên quan, điều này phổ biến trong kỹ thuật xã hội [50].
Dưới ô dù của DLPS, các tập đoàn có thể ít thận trọng hơn
về việc truy cập không cần thiết vào các tập dữ liệu riêng tư nhất định,
vì DLPS phải cấm bất kỳ nỗ lực nào chuyển
các tập dữ liệu riêng tư ra khỏi mạng cục bộ mà không có
ủy quyền.
Tóm tắt: Một kẻ nội gián có nhiều cách để truy cập
các tập dữ liệu riêng tư, được cấm nghiêm ngặt
chuyển ra khỏi mạng cục bộ mà không có
ủy quyền.
IV. CÀI ĐẶT BẢO MẬT
Định nghĩa tấn công. Theo các công việc hiện có về phá vỡ
quyền riêng tư dữ liệu huấn luyện thông qua các mô hình DNN đã được huấn luyện tốt (§II),
chúng tôi định nghĩa một tập dữ liệu riêng tư mục tiêu bị đánh cắp theo nghĩa
rò rỉ chức năng, tức là kẻ tấn công đạt được một mô hình đã huấn luyện
có gần như cùng chức năng như thể mô hình được
huấn luyện trên tập dữ liệu riêng tư mục tiêu.
Mô hình đe dọa. Cuộc tấn công Matryoshka của chúng tôi liên quan đến một
kẻ tấn công nội bộ và một kẻ đồng lõa bên ngoài. Kẻ đồng lõa cũng có thể
đóng vai trò như chính kẻ tấn công. Chính thức, chúng tôi có
các giả định sau về khả năng của kẻ nội bộ và
kẻ ngoại lai: (i) Mục tiêu có thể truy cập: Kẻ nội bộ có quyền truy cập vào
(các) tập dữ liệu riêng tư mục tiêu; (ii) Vận chuyển tồn tại: Kẻ nội bộ được
giao nhiệm vụ huấn luyện một DNN, được lên lịch
trải qua một quá trình mã nguồn mở, trên một tập dữ liệu không phải mục tiêu;
(iii) Vận chuyển có thể nhận: Kẻ ngoại lai biết mô hình nào để
tải xuống sau khi công bố; (iv) Thông đồng an toàn: Kẻ
nội bộ và kẻ ngoại lai có thể thông đồng về một số giá trị số nguyên và
kiến trúc mô hình thông qua một kênh an toàn (ví dụ: một cuộc hẹn).
Dưới đây, chúng tôi thảo luận ngắn gọn về cơ sở hợp lý đằng sau mô hình
đe dọa của chúng tôi. Trước tiên, khả năng tiếp cận của các tập dữ liệu mục tiêu được
hỗ trợ bởi nghiên cứu thực địa của chúng tôi trong §III-B, nơi một kẻ nội bộ có thể
tự do truy cập tập dữ liệu riêng tư mục tiêu trong chế độ
Sẵn sàng chia sẻ, hoặc giả vờ có nhu cầu về các tập dữ liệu mục tiêu
để hoàn thành nhiệm vụ được giao trong chế độ Ứng dụng-
rồi-Ủy quyền. Thứ hai, sự tồn tại của một vận chuyển
thực tế trong ngành AI ngày nay, nơi xu hướng
mã nguồn mở các DNN được huấn luyện trước trở nên ngày càng phổ biến
cho các tập đoàn với mục đích giáo dục hoặc thương mại [51], [52].
Làm việc như một kỹ sư DL, kẻ nội bộ có cơ hội được
giao một nhiệm vụ như vậy. Bên cạnh đó, giả định thứ ba và thứ tư
có thể dễ dàng được thỏa mãn bằng giao tiếp ngoại tuyến giữa kẻ tấn công
nội bộ và kẻ đồng lõa bên ngoài trong thời gian không làm việc. Như chúng tôi
sẽ cho thấy sau, trong Matryoshka các khóa bí mật cần thiết để giải mã
thông tin ẩn từ mô hình vận chuyển chỉ bao gồm:
một liên kết trang web đến trang tải xuống chính thức, một số giá trị
số nguyên (tức là hạt giống ngẫu nhiên) và các kiến trúc của các mô hình bí mật
có thể được chọn là các kiến trúc nổi tiếng đã
được tiêu chuẩn hóa trong các framework DL phổ biến để tạo điều kiện
thuận lợi cho việc thông đồng. Điều này cho phép việc thông đồng được thực hiện thông qua
một cuộc hẹn, thiết lập một kênh an toàn.
Phân loại và mục tiêu tấn công. Để thực hiện việc truyền tải bí mật
các mô hình bí mật thông qua một DNN được lên lịch công bố, cuộc tấn công
Matryoshka được đề xuất của chúng tôi dự kiến đáp ứng các
mục tiêu tấn công sau: (i) Dung lượng: Như một điều kiện tiên quyết để
kích hoạt truyền tải bí mật, chúng tôi yêu cầu các mô hình bí mật có thể được mã hóa
vào mô hình vận chuyển mà không gây ra sự suy giảm rõ ràng
về tiện ích bình thường của nó. Một cách trực quan, một sơ đồ ẩn có
dung lượng cao hơn nếu nó mã hóa nhiều thông tin bí mật hơn với cùng
mức độ suy giảm hiệu suất. (ii) Hiệu quả giải mã:
Yêu cầu này đo lường bao nhiều kiến thức bổ sung
cần thiết để giải mã thành công các mô hình bí mật từ
mô hình vận chuyển. Nếu nó vượt quá khả năng ghi nhớ của
kẻ nội bộ, kiến thức bổ sung nên được truyền đạt thông qua
một vòng truyền tải bí mật bổ sung, tăng nguy cơ
bị phát hiện. (iii) Hiệu quả: Sau khi thông tin bí mật
được giải mã từ mô hình vận chuyển của chúng tôi, thông tin được
mong đợi gần như không bị biến dạng (tức là truyền tải hiệu quả).
Cụ thể, trong cuộc tấn công của chúng tôi, chúng tôi yêu cầu các mô hình bí mật được giải mã
hiệu quả trong việc đánh cắp (các) tập dữ liệu riêng tư mục tiêu về
mặt rò rỉ chức năng hoặc rò rỉ dữ liệu nhạy cảm. (iv)
Mạnh mẽ: Sử dụng ngôn ngữ của lý thuyết thông tin, yêu cầu này
mong đợi việc truyền tải bí mật vẫn hiệu quả
ngay cả khi kênh truyền có nhiễu. Trong bối cảnh của chúng tôi,

--- TRANG 3 ---
chúng tôi yêu cầu kẻ đồng lõa vẫn có thể giải mã các mô hình bí mật
và do đó quyền riêng tư của các tập dữ liệu mục tiêu khi mô hình vận chuyển
trải qua các kỹ thuật hậu xử lý phổ biến (ví dụ:
cắt tỉa và tinh chỉnh). (v) Che giấu: Cuối cùng, để thể hiện
yêu cầu về tính che giấu, một bên thứ ba không nên có thể
phát hiện liệu một mô hình được công bố có chứa các mô hình bí mật hay không.
Nếu không, việc truyền tải sẽ bị hủy bỏ và
kẻ tấn công nội bộ sẽ bị phát hiện theo nhật ký
truy cập tập dữ liệu.
Các kỹ thuật ẩn dữ liệu hiện có cho việc ẩn mô hình. Ẩn dữ liệu
là một lĩnh vực nghiên cứu lâu đời và phong phú trong bảo mật
[21]. Nhiều thuật toán và công cụ nổi tiếng được thiết kế để
mã hóa thông điệp nhị phân trong nội dung đa phương tiện như hình ảnh
[16], văn bản [17], và âm thanh [18]. Gần đây, cũng có một số
công trình nghiên cứu khám phá việc áp dụng các kỹ thuật ẩn dữ liệu
đã được thiết lập tốt, bao gồm bit ít quan trọng nhất (LSB [53]),
mã hóa giá trị tương quan và dấu, để nhúng dấu nước nhị phân bí mật [20], [38],
một tập con của dữ liệu huấn luyện ở dạng nhị phân vào một DNN đã huấn luyện [19]
hoặc một vi-rút [54].
Tuy nhiên, các kỹ thuật ẩn dữ liệu hiện có chủ yếu xem phương tiện
vận chuyển, dù là nội dung đa phương tiện thông thường hay
các tham số trong DNN, như chuỗi bit để mã hóa bí mật.
Do đó, kích thước của phương tiện vận chuyển đặt ra một giới hạn dung lượng
nghiêm ngặt đối với thông tin có thể được ẩn. Một mặt,
nội dung đa phương tiện thông thường khó có thể đủ khả năng ẩn
một DNN thường bao gồm hàng triệu tham số
dấu phẩy động. Ví dụ, việc lưu trữ một ResNet-18
cho ImageNet là hơn 45MB, trong khi, đối với hình ảnh, tỷ lệ nhúng
có thể chấp nhận tối đa chỉ là 0,4 bit trên mỗi pixel [55]. Mặt khác,
việc áp dụng các kỹ thuật hiện có để ẩn thông tin
trong một DNN vận chuyển không thể khai thác đầy đủ dung lượng tiềm năng của nó.
So với đa phương tiện thông thường, một DNN vận chuyển
lớn hơn nhiều so với đa phương tiện truyền thống và có khả năng chống chịu
mạnh mẽ hơn trước việc thay đổi nhiều vị trí LSB
[56], [57]. Mặc dù vậy, các sơ đồ mã hóa trước đây chỉ
có thể sử dụng khoảng 20%-50% kích thước của một DNN để ẩn thông tin.
Ví dụ, Song và cộng sự thấy hầu hết các kỹ thuật ẩn dữ liệu hiện có
khó có thể ẩn hơn 500 hình ảnh thang xám thô
có độ phân giải 32×32 (~5,85MB tổng cộng) nếu sự suy giảm hiệu suất
của một ResNet-18 vận chuyển được yêu cầu bị ràng buộc
dưới 3% [19]. Từ quan điểm của chúng tôi, việc trực tiếp mã hóa các đầu vào dữ liệu thô
vào mô hình vận chuyển phải đối mặt với thách thức từ
sự không phù hợp phân phối giữa hai loại dữ liệu khác biệt
(§V-C). Nếu các kỹ thuật hiện có được áp dụng để truyền tải bí mật
các mô hình bí mật, tính linh hoạt và hiệu quả của
cuộc tấn công Matryoshka của chúng tôi sẽ bị tổn hại nghiêm trọng: Hoặc một
mô hình bí mật lớn hơn hoặc nhiều mô hình bí mật cho các
mục đích tấn công khác nhau không thể được ẩn trong mô hình vận chuyển.
Tóm tắt: (i) Vận chuyển đa phương tiện thường có dung
lượng không đủ để ẩn mô hình. (ii) Các kỹ thuật hiện có
chưa khai thác đầy đủ dung lượng mã hóa
của một DNN vận chuyển.

--- TRANG 4 ---
Hình 2. Tổng quan về phương pháp luận của Matryoshka.
V. CUỘC TẤN CÔNG MATRYOSHKA
A. Tổng quan tấn công
Dưới đây, chúng tôi trước tiên trình bày thiết kế và nhận thức của chúng tôi về một Param-
Pool, là cốt lõi của việc mã hóa (giải mã) các
mô hình bí mật vào (từ) mô hình vận chuyển.
Thiết kế của ParamPool. Nói chung, một ParamPool P duy trì
một mảng |P| tham số vô hướng có thể học. Tương ứng
với các loại khác nhau (ví dụ: trọng số, bias, tỷ lệ) của các tham số
có thể học trong DNN, các tham số trong một pool trọng số cũng
được nhóm trong các nhóm rời rạc, tức là P = Pw ∪ Pb ∪ Ps. Mỗi nhóm
triển khai các sơ đồ ngẫu nhiên khác nhau khi được khởi tạo. Với
một bí mật số nguyên v, một ParamPool P triển khai các
nguyên hàm sau để tương tác với một DNN f(·; θ):
(i) Fill(P, f, v) → Pθ(·; v): Nguyên hàm này thay thế mỗi
tham số gốc trong f bằng một tham số cùng loại
được chọn từ ParamPool P với việc thay thế
theo khóa bí mật v. Chúng tôi sử dụng Pθ(·; v) để biểu thị
các tham số của một DNN f được điền bởi P dưới bí mật số nguyên
v. Theo nghĩa này, Pθ(·; v) được xem như một bản đồ băm từ các
tham số gốc đến các tham số ParamPool.
(ii) Propagate(P, f(·; θ), v) → ∅: Sau một bước tối ưu hóa
trên f, nguyên hàm này thu thập cập nhật trọng số trên
mỗi tham số trong một DNN và lan truyền chúng đến các
vị trí tương ứng trong ParamPool với Pθ(·; v).
(iii) Update(P) → ∅: Sau khi cập nhật trọng số được tích lũy
trong bộ đệm cập nhật của tham số tương ứng trong P,
nguyên hàm này cập nhật mỗi tham số trong P bằng cách tổng hợp
bộ đệm cập nhật của nó và sau đó đặt lại nó.
(iv) Decode(f, v) → P: Nguyên hàm này giải mã
ParamPool từ một DNN f theo khóa bí mật v.
Một cách trực quan, với các nguyên hàm trên, một ParamPool có thể được sử dụng
như một proxy cho toàn bộ vòng đời của một DNN.
Quy trình tấn công. Hình 2 cung cấp tổng quan về quy trình tấn công
của chúng tôi, chủ yếu được chia thành bốn giai đoạn. Trong phần sau,
chúng tôi ký hiệu DNN vận chuyển là C.
Giai đoạn 1: Khởi tạo ParamPool. Trước tiên, một ParamPool P
được khởi tạo từ DNN vận chuyển bằng cách thu thập và nhóm
tất cả các tham số có thể học (Tùy chọn I) hoặc từ đầu với

kích thước được kẻ tấn công chỉ định cho mỗi nhóm (Tùy chọn II). Sau này
chúng tôi cho thấy Tùy chọn I có lợi thế hơn trong việc tránh phát hiện
(§VI-F) trong khi Tùy chọn II giúp mô hình vận chuyển mạnh mẽ hơn
ngay cả khi được truyền trong kênh có nhiễu, tức là hậu xử lý mô hình (§VI-E).
Giai đoạn 2: Xây dựng các nhiệm vụ bí mật (§V-B). Trong
giai đoạn tiếp theo, chúng tôi chỉ định các nhiệm vụ học bí mật theo
mục đích tấn công và bản chất của các tập dữ liệu mục tiêu
D1, ..., DN cần đánh cắp (N ≥ 1). Để đánh cắp chức năng
của một tập dữ liệu học có giám sát, chúng tôi chọn một
kiến trúc DNN sẵn có để phù hợp với tập dữ liệu riêng tư với một mất mát
ℓk thích hợp. Khác biệt, để đánh cắp một tập con nhạy cảm của các
đầu vào dữ liệu riêng tư, chúng tôi chọn một DNN được huấn luyện để ánh xạ một
chuỗi các vectơ nhiễu đến các đầu vào dữ liệu mà kẻ tấn công quan tâm
theo cách một-một. Các vectơ nhiễu được lấy mẫu ngẫu nhiên
từ một phân phối bí mật với một hạt giống số nguyên cố định,
được kẻ nội bộ và kẻ đồng lõa biết độc quyền. Cuối cùng,
kẻ tấn công chọn một bí mật số nguyên vk và gọi
nguyên hàm Fill để thay thế các tham số trong mỗi mô hình bí mật bằng
những cái trong P bằng cách gọi Fill(P, fk, vk).
Giai đoạn 3: Huấn luyện chung để ẩn mô hình (§V-C) Kết hợp
với nhiệm vụ học (DC, ℓC) của mô hình vận chuyển C, kẻ
tấn công cùng huấn luyện mô hình vận chuyển và các mô hình bí mật
bằng cách tối ưu hóa các tham số trong ParamPool P. Một cách ngắn gọn,
trong mỗi lần lặp, chúng tôi đồng bộ tính toán các cập nhật tham số
trong mỗi mô hình và sau đó gọi Propagate(P, fk) để
tích lũy các cập nhật trong mỗi mô hình đến các
bộ đệm cập nhật tương ứng. Tiếp theo, chúng tôi gọi nguyên hàm Update và
tiếp tục huấn luyện chung đến lần lặp tiếp theo. Khi
huấn luyện kết thúc, kẻ tấn công loại bỏ tất cả các dấu vết trong
cơ sở mã và thay thế các tham số tương ứng trong mô hình vận chuyển
bằng các giá trị từ ParamPool cuối cùng. Chúng tôi ký hiệu
mô hình vận chuyển cuối cùng là C*.
Giai đoạn 4: Giải mã các mô hình bí mật từ mô hình vận chuyển
(§V-D). Sau khi mô hình vận chuyển C* được công bố, kẻ đồng lõa
bên ngoài tải xuống C*. Với kiến thức về các
kiến trúc của các mô hình bí mật và khóa bí mật vk
được truyền đạt thông qua kênh an toàn, kẻ ngoại lai trước tiên gọi
Decode(C*, vk) để giải mã ParamPool P từ mô hình
vận chuyển. Sau đó, kẻ đồng lõa lắp ráp các mô hình bí mật từ
ParamPool đã giải mã. Trong phần sau, chúng tôi trình bày
các thiết kế kỹ thuật chi tiết cho mỗi giai đoạn trên.
B. Xây dựng các nhiệm vụ bí mật
Các nhiệm vụ học hướng chức năng. Để đánh cắp
chức năng của một tập dữ liệu riêng tư, nhiệm vụ học bí mật
được xây dựng như thể kẻ tấn công đang huấn luyện một mô hình có thể sử dụng
fk(·; θk) : Xk → Yk trên tập dữ liệu riêng tư Dk :=
{(xi, yi)}^Mk_{i=1} thuộc về Xk × Yk. Để giảm thiểu
thông tin cần thiết cho việc thông đồng, chúng tôi đề xuất sử dụng các
kiến trúc nơ-ron được tiêu chuẩn hóa trong các framework học sâu.
Với hàm mất mát ℓk, chúng tôi chính thức xây dựng nhiệm vụ
học bí mật để đánh cắp chức năng như min_{θk} Lk(θk) :=
1/|Dk| ∑_{(xi,yi)∈Dk} ℓk(fk(xi; θk), yi).
Điền các mô hình bí mật/vận chuyển với ParamPool. Với mô hình vận chuyển
C và một ParamPool P đã khởi tạo, chúng tôi trước tiên chỉ định
một số nguyên ngẫu nhiên vk cho mỗi mô hình bí mật fk từ tất cả các
chỉ số có thể của ParamPool P, tức là {1, 2, ..., |P|}. Điều này
ngăn các mô hình bí mật bị giải mã bởi bất kỳ bên nào
ngoại trừ kẻ đồng lõa. Sau đó chúng tôi gọi nguyên hàm Fill(P,
fk, vk) để thay thế các tham số gốc trong fk bằng các tham số
trong P. Một cách trực quan, nguyên hàm Fill lặp qua tất cả các tham số
vô hướng trong mô hình mục tiêu fk(·; θ) và gán nó với
giá trị của một tham số được chọn từ ParamPool. Như
Hình 2 cho thấy, con trỏ chọn tham số trên mỗi nhóm tham số
(ví dụ: nhóm trọng số Pw) quay vòng từ một chỉ số bắt đầu
được dẫn xuất từ bí mật số nguyên (ví dụ: vk mod |Pw|).
Đối với mô hình vận chuyển, chúng tôi chọn vC = 0 nếu ParamPool
được khởi tạo trực tiếp từ mô hình vận chuyển (tức là Tùy chọn II trong
§V-A), hoặc nếu không, chúng tôi lấy mẫu một bí mật số nguyên vC cũng
cho mô hình vận chuyển. Mô hình thu được được ký hiệu là f̃k
với các tham số được thay thế là Pθ(θk; vk).
C. Huấn luyện chung để ẩn mô hình
Sau khi các mô hình bí mật và vận chuyển được điền, ParamPool P
sẵn sàng trở thành một proxy cho quá trình huấn luyện
của mỗi nhiệm vụ học bí mật/mở. Không mất tính tổng quát,
mô hình vận chuyển C được giả định là được huấn luyện trên
một nhiệm vụ học có giám sát DC := {(xi, yi)}^MC_{i=1} với một hàm
mất mát ℓC. Chính thức, quá trình ẩn mô hình nhằm giải quyết
mục tiêu học chung sau:
min_P 1/|DC| ∑_{(xi,yi)∈DC} ℓk(C(xi; Pθ(θC; vC)); yi)
+ 1/N ∑^N_{k=1} Lk(Pθ(θk; vk)). (1)
Một cách trực quan, mục tiêu trên yêu cầu P đạt được sự đồng thuận tốt
về N nhiệm vụ bí mật và nhiệm vụ mở. Ví dụ,
khi N = 1, điều đó có nghĩa là các tập hợp tối ưu cục bộ cho fC
và f1 nên giao nhau với nhau để đảm bảo một
ParamPool gần tối ưu có thể đạt được. Lần đầu tiên, chúng tôi đề xuất
một thuật toán huấn luyện chung trong Thuật toán 1
giải quyết mục tiêu học trên để xây dựng một
ParamPool gần tối ưu. Mỗi mô hình bí mật được lắp ráp từ
ParamPool được tối ưu hóa thể hiện tiện ích tương tự so với một
mô hình giống hệt được huấn luyện độc lập (§VI-C). Tuy nhiên,
theo hiểu biết tốt nhất của chúng tôi, các lý thuyết học sâu hiện có
khó có thể giúp giải thích hiện tượng này. Để
cung cấp một giải thích thử nghiệm, chúng tôi cung cấp nghiên cứu thí điểm sau
về các phân phối tham số tối ưu trên các mô hình.
Một nghiên cứu thí điểm về phân phối tham số. Cụ thể,
chúng tôi tải xuống 8 mô hình đã được huấn luyện trước (tức là {fk(·; θ*k)}^8_{k=1}) từ
Pytorch Hub [58], với tên của chúng được liệt kê trong chú giải của
Hình 3. Các mô hình được chọn bao gồm các ứng dụng điển hình (ví dụ:
phân loại, tạo sinh, phát hiện đối tượng) và trải dài dữ liệu hình ảnh,
âm thanh và văn bản. Trong phần sau, chúng tôi tập trung vào các tham
số của loại trọng số. Không mất tính tổng quát, các lập luận tương tự
áp dụng cho bias và tỷ lệ. Trước tiên, chúng tôi tính toán biểu đồ
được chuẩn hóa của các tham số loại trọng số trong mỗi mô hình trên
phạm vi [-1, 1] với n = 100 bin. Trong các thí nghiệm của chúng tôi,
phạm vi được xác thực để bao phủ tất cả
các tham số trọng số. Chúng tôi vẽ các biểu đồ trọng số trong
Hình 3(a) và sử dụng Hw(k) := {(w1, p1(k)), ..., (wn, pn(k))}
để biểu thị biểu đồ của các trọng số trong θ*k. Để phân tích
tính khả thi của sơ đồ chia sẻ trọng số dựa trên ParamPool của chúng tôi, chúng tôi
đo khoảng cách vận chuyển tối ưu (OTD) sau
giữa các biểu đồ trọng số Hw(j) và Hw(k) [59]:
OTD(Hw(j), Hw(k)) = min ∑^n_{l=1} ∑^n_{m=1} dlm plm (2)
s.t., ∑^n_{l=1} plm = pm(k), ∑^n_{m=1} plm = pl(j), ∑^n_{m=1} ∑^n_{l=1} plm = 1,
(3)
trong đó dij = |wi - wj|, tức là khoảng cách giữa
tâm bin thứ i và thứ j. Chúng tôi gọi {p*jk} để giải quyết
lập trình tuyến tính trên là sơ đồ vận chuyển tối ưu. Nói chung,
OTD giữa hai phân phối đo
khoảng cách tối thiểu khi mật độ trong một phân phối được
vận chuyển đến một phân phối khác [60]. Trong bối cảnh của chúng tôi, xem
ParamPool như trung gian của việc ánh xạ một mô hình fj đến một
mô hình khác fk, chúng tôi trình bày kết quả phân tích sau.
Định lý 1 (Sự tồn tại của ParamPool gần tối ưu). Đối với một
cặp nhiệm vụ học (Dj, fj, ℓj) và (Dk, fk, ℓk) sao cho
θ*j và θ*k là các cực tiểu tương ứng đối với mất mát
huấn luyện, nếu OTD(H(i), H(j)) < ε (trong đó i lặp trong {w, b, s},
tức là trọng số, bias, tỷ lệ), thì luôn tồn tại một ParamPool
P có kích thước |P| và hai bí mật số nguyên vj, vk sao cho
|Pθ(θ*j; vj)[i] - θ*j[i]| ≤ ε/2 + O(|P|^{-1})
|Pθ(θ*k; vk)[i] - θ*k[i]| ≤ ε/2 + O(|P|^{-1}) (4)
trong đó θ*j[i] biểu thị tham số vô hướng thứ i trong θ*j.
Nói đơn giản, định lý trên lập luận rằng sự tồn tại
của một ParamPool gần tối ưu giảm thiểu các hàm mất mát
trên cả nhiệm vụ riêng lẻ có liên quan mạnh mẽ với
OTD giữa các phân phối tham số. Một cách trực quan, khi
OTD(H(j), H(k)) nhỏ hơn ε, điều đó có nghĩa là một
tham số trọng số vô hướng w trong fj luôn có thể tìm thấy một tham số thay thế

--- TRANG 5 ---
(a)(b)Hình 3. (a) Biểu đồ trọng số của 8 mô hình được huấn luyện trước có tính đa dạng cao.
(b) Các giá trị thực nghiệm cho OTD theo cặp giữa 8 mô hình.
tham số w' sao cho |w - w'| < ε do sự tồn tại của
sơ đồ OT. Do đó, với các tham số của fj, fk, người ta
luôn có thể xây dựng một ParamPool và các quan hệ ánh xạ
từ các mô hình đến ParamPool sao cho trọng số được chia sẻ
khác với trọng số được tối ưu hóa bởi ε. Phần sau cung cấp
bằng chứng cho định lý này.
Bằng chứng cho Định lý 1. Trước tiên, chúng tôi cung cấp một bằng chứng xây dựng
cho trường hợp khi ParamPool có kích thước không giới hạn, được
nêu chính thức như bổ đề sau.
Bổ đề 1. Nếu OTD(H(i), H(j)) < ε (trong đó i lặp trong
{w, b, s}), thì luôn tồn tại một ParamPool P0 và hai
bí mật số nguyên vj và vk sao cho, đối với mỗi i, |P0θ(θ*j; vj)[i] -
θ*j[i]| ≤ ε/2; |P0θ(θ*k; vk)[i] - θ*k[i]| ≤ ε/2.
Bằng chứng. Theo định nghĩa của OTD(H(i), H(j)) < ε, tồn tại
một sơ đồ vận chuyển tối ưu p*jk sao cho đối với mỗi
θ*j[i], tham số tương ứng θ*k[p*jk(i)] nằm trong ε-ball
của θ*j[i]. Do đó, đối với chỉ số i của tham số θ*j và chỉ số p*jk(i) của tham số θ*k, tham số ParamPool thứ l P0[l] luôn có thể được xây dựng để thỏa mãn |θ*j[i] - P0[l]| <
ε/2 và |θ*k[p*jk(i)] - P0[l]| ≤ ε/2 (ví dụ: bằng cách chọn P0[l] =
(θ*j[i] + θ*k[p*jk(i)])/2). Do đó, một quy tắc ánh xạ từ θ*i đến
P0 là i → l, trong khi, đối với θ*j, nó là p*jk(i) → l. Không mất
tính tổng quát, chúng tôi giả định θ*i không nhỏ hơn θ*j. Bằng cách lặp
qua i như trên, chúng tôi xây dựng một ParamPool P0 có cùng
kích thước với θ*i, và các quan hệ ánh xạ P0θ(θ*i; vi) = {i → l},
P0θ(θ*j; vi) = {p*jk(i) → l}. Người ta có thể dễ dàng chỉ ra tồn tại
các số nguyên vi, vj tuân theo quan hệ ánh xạ trên.
Nếu kích thước của θ*j không nhỏ hơn |P|, định lý của chúng tôi đã
hợp lệ theo bổ đề trên. Nếu không, chúng tôi
có thể mở rộng bổ đề trên cho trường hợp bằng cách phân cụm các
tham số trong ParamPool không giới hạn mà chúng tôi xây dựng ở trên
để thỏa mãn ràng buộc kích thước. Về mặt kỹ thuật, xem xét
ParamPool P0 trong Bổ đề 1, chúng tôi tiếp theo chứng minh sự tồn tại của
một ParamPool nhỏ hơn có kích thước |P| xấp xỉ tốt P0
theo nghĩa sau.
Bổ đề 2. Tồn tại một ParamPool P và một quan hệ ánh xạ
từ chỉ số của P0 đến chỉ số của P sao cho
|P0[i] - P[φ(j)]| < O(|P|^{-1}).Bằng chứng. Chúng tôi chứng minh bổ đề một lần nữa thông qua xây dựng. Bằng cách
chia phạm vi tham số (w.l.o.g., chúng tôi ký hiệu phạm vi là
[-M/2, M/2]) thành |P| bin có chiều rộng bằng nhau (tức là M/|P|), chúng tôi
đặt các tham số trong P0 vào mỗi bin. Sau đó chúng tôi xây dựng
ParamPool nhỏ hơn bằng cách thu thập tất cả |P| tâm bin, và
quan hệ ánh xạ như quan hệ thuộc về các bin.
Bổ đề được chứng minh.
Cuối cùng, chúng tôi tận dụng bất đẳng thức tam giác sao cho
|θ*j[i] - P[l]| < |θ*j[i] - P0[l]| + |P0[l] - P0[φ(l)]| < ε/2 +
O(|P|^{-1}). Cuối cùng, bằng cách ký kết về các quan hệ ánh xạ
gốc trong P0θ(θ*j; vi) với quan hệ phân cụm φ, chúng tôi
xây dựng quan hệ ánh xạ từ θ*j đến ParamPool P.
Các lập luận tương tự áp dụng cho θ*k.
Cuối cùng, chúng tôi tính toán thực nghiệm OTD theo cặp giữa
8 mô hình dựa trên biểu đồ, và báo cáo kết quả
dưới dạng bản đồ nhiệt trong Hình 3(b). Kết quả cho thấy, giới hạn trên
ε là 0,038 trung bình với độ lệch chuẩn 0,008
(tức là ε nhỏ hơn 2% phạm vi trọng số có độ dài
2), điều này khó ảnh hưởng đến hiệu suất mô hình [61].
Để tóm tắt, nghiên cứu thí điểm của chúng tôi liên quan sự tồn tại của một
ParamPool gần tối ưu với quy mô của OTD giữa phân
phối của các tham số được tối ưu hóa. Để khám phá trong tương lai,
chúng tôi để lại một cách xử lý lý thuyết toàn diện hơn về
cách một ParamPool gần tối ưu như vậy có thể đạt được
với thuật toán được đề xuất của chúng tôi.
Tìm kiếm ParamPool được tối ưu hóa. Để giải quyết
mục tiêu học chung trong Phần V-C, cuộc tấn công được đề xuất của chúng tôi
thực hiện lần lặp huấn luyện chính sau đây một cách lặp lại. Ký hiệu
ParamPool tại lần lặp thứ t là Pt. Một cách ngắn gọn, tại
lần lặp thứ t, chúng tôi lặp qua tất cả N nhiệm vụ bí mật và
nhiệm vụ bình thường để thực hiện các thủ tục chính sau:
(i) Đối với nhiệm vụ bí mật thứ k, chúng tôi trước tiên gọi Fill(Pt, fk, vk)
để khởi tạo fk với các giá trị hiện tại của ParamPool.
(ii) Sau đó, chúng tôi chuyển tiếp một batch huấn luyện thông qua mô hình
fk(·; Ptθ(θk; vk)), lan truyền ngược mất mát Lk được xấp xỉ
trên batch huấn luyện, và thực hiện một bước tối ưu hóa trên
các tham số của fk với một bộ tối ưu hóa (ví dụ: Adam [44]).
(iii) Cuối cùng, chúng tôi thu thập cập nhật trọng số trên mỗi tham số
và theo quan hệ ánh xạ trong Pθ(·; vk) để lan truyền
cập nhật đến tham số ParamPool tương ứng. Các thủ tục trên
cũng được thực hiện trên mô hình vận chuyển.
Các thủ tục trên mô tả nguyên hàm Propagate trên
mỗi nhiệm vụ bí mật/mở (L4-15 trong Thuật toán 1).
Bước cuối cùng trong một lần lặp huấn luyện là gọi
nguyên hàm Update trên ParamPool (L16-18 trong Thuật toán
1). Về mặt kỹ thuật, đối với mỗi tham số trong Pt, chúng tôi duy trì một
bộ đệm để lưu trữ các cập nhật trọng số từ mỗi nhiệm vụ. Bộ đệm cập nhật
được tổng hợp để có được giá trị cập nhật toàn cục trên
tham số vô hướng tương ứng trong Pt. Trong các thí nghiệm của chúng tôi, chúng tôi
thấy tổng hợp bằng trung bình đã đủ để đạt được
các cuộc tấn công hiệu quả. Sau khi tham số được cập nhật, chúng tôi xóa
các bộ đệm cập nhật và tiếp tục lần lặp huấn luyện tiếp theo.
Như một nhận xét cuối cùng, quá trình huấn luyện trên ParamPool
kết thúc khi (i) hiệu suất xác thực của mô hình vận chuyển

--- TRANG 6 ---
Thuật toán 1 Lần lặp thứ t trong quá trình huấn luyện chung
trên ParamPool
Đầu vào: Pt (ParamPool hiện tại), {(fk, D̃k, ℓk, Optk)}^N_{k=0}
(các nhiệm vụ bí mật và mở). • Để đơn giản, chỉ số 0
biểu thị nhiệm vụ mở trên mô hình vận chuyển.
Đầu ra: Pt+1 (ParamPool đã cập nhật)
1: foreach tham số wP trong Pt do
2: wP.buffer ← {}
3: end for
4: parallel for k = 0, 1, ..., N do
5: Pθ(·; vk) ← Fill(Pt, fk, vk)
6: Lấy mẫu batch huấn luyện B từ D̃k.
7: L̃k ← 1/|B| ∑_{(x,y)∈B} ℓk(fk(x; Pθ(θk; vk)); y). • Xấp xỉ
mất mát Lk trên một mini-batch được lấy mẫu ngẫu nhiên.
8: L̃k.Backward()
9: Δθk ← Optk.Step()
10: foreach tham số vô hướng w trong θk do
11: if w thuộc về tham số {weight, scale, bias} then
12: Pθ(w; vk).buffer.Append(Δw) • Lan truyền cập
nhật đến tham số ParamPool tương ứng.
13: end if
14: end for
15: end parallel
16: foreach tham số wp trong Pt do
17: wp ← wp + Average(wp.buffer)
18: end for
19: return Pt+1.
đáp ứng yêu cầu nhiệm vụ, và (ii) ít nhất một trong
các nhiệm vụ bí mật hội tụ. Điều kiện này đảm bảo mô hình vận chuyển
chuyển đổi suôn sẻ đến giai đoạn tiếp theo của quá trình công bố
với các mô hình bí mật nhất định được mã hóa. Chúng tôi ký hiệu
ParamPool cuối cùng là P*. Để kết thúc giai đoạn ẩn mô hình,
kẻ tấn công xóa bỏ mọi dấu vết của mã huấn luyện độc hại
và các kết quả trung gian không liên quan, ghi nhớ các khóa bí mật
(tức là các hạt giống ngẫu nhiên {sk} để tạo nhiễu, các
chỉ số bắt đầu {vk} và tên kiến trúc cho mỗi nhiệm vụ,
kích thước của mỗi nhóm trong ParamPool) thông qua một phương tiện an toàn,
và khởi tạo mô hình vận chuyển bằng Fill(P*, fC, vC).
D. Giải mã các mô hình bí mật từ mô hình vận chuyển
Khôi phục ParamPool. Sau khi mô hình vận chuyển được
công bố trực tuyến với quyền truy cập mở, kẻ tấn công ngay lập tức
thông báo cho kẻ đồng lõa bên ngoài tải xuống mô hình vận chuyển và
giải mã các mô hình bí mật từ mô hình vận chuyển. Cụ thể,
sau khi thông đồng về các khóa bí mật với kẻ tấn công thông qua
kênh an toàn (ví dụ: cuộc hẹn trực tiếp), kẻ ngoại lai
trước tiên giải mã ParamPool dựa trên kiến thức được thông đồng
về kích thước ParamPool và chỉ số bắt đầu vC, tức là bằng
nguyên hàm Decode(C*, vC). Cụ thể, thủ tục giải mã
khác nhau tùy theo việc khởi tạo ParamPool:
(i) Nếu được khởi tạo trực tiếp từ mô hình vận chuyển, ParamPool
có thể dễ dàng được khôi phục bởi kẻ đồng lõa thông qua việc thu thập
mỗi tham số trong mô hình vận chuyển vào các nhóm khác nhau.(ii) Nếu không, nếu ParamPool được tạo từ đầu,
kẻ đồng lõa trước tiên thu thập các tham số của các nhóm khác nhau
từ mô hình vận chuyển. Sau đó, kẻ tấn công cắt, ví dụ:
các tham số trọng số thành các đoạn có độ dài |Pw|. Đoạn cuối
có thể cần thêm đệm số không để giữ cùng
độ dài. Cuối cùng, kẻ tấn công thực hiện một thao tác hợp nhất trên
N đoạn đã giải mã, dịch phải kết quả hợp nhất bởi vk
mod |Pw|, và hoán vị nó với một hoán vị nghịch đảo của
hoán vị trong Fill để khôi phục Pw cuối cùng trong ParamPool. Các
thao tác tương tự được thực hiện trên các nhóm bias và tỷ lệ.
Chúng tôi giới thiệu cơ chế hợp nhất trên N đoạn đã giải mã
để triển khai khả năng chống chịu trước hậu xử lý trên
mô hình vận chuyển (§VI-E). Ví dụ, khi kẻ đồng lõa
thấy mô hình vận chuyển bị cắt tỉa, cơ chế hợp nhất
chọn giá trị khác không từ mỗi bản sao ParamPool để
khôi phục các giá trị đã bị cắt tỉa.
Thêm chi tiết về thủ tục giải mã được cung cấp trong
Thuật toán 2. Để xác định thuật toán giải mã nào sử dụng,
kẻ ngoại lai chỉ cần so sánh |P| đã biết với số lượng
tham số có thể học trong mô hình vận chuyển.
Thuật toán 2 Nguyên hàm Decode(C*, vc)
Đầu vào: C* (mô hình vận chuyển), vc (bí mật số nguyên của
mô hình vận chuyển), Nw, Nb, Ns (độ dài của Pw, Pb, Ps).
Đầu ra: P = Pw ∪ Pb ∪ Ps (ParamPool đã giải mã).
1: Pw ← list(); Pb ← list(); Ps ← list()
2: foreach tham số vô hướng w trong C* do
3: if w thuộc về tham số {weight, scale, bias} then
4: switch (type(w)) do
5: case weight:
6: Pw.Append(w.data)
7: case bias:
8: Pb.Append(w.data)
9: case scale:
10: Ps.Append(w.data)
11: end switch
12: else
13: CONTINUE
14: end if
15: end for
16: vw, vb, vs ← vc mod Nw, vc mod Nb, vc mod Ns
17: Tạo hoán vị ngẫu nhiên πw(πb, πs) của các số nguyên
từ 0 đến Nw (Nb, Ns) với hạt giống vw (vb, vs).
18: Pw, Pb, Ps ← Fusion(Pw, Pb, Ps) • Khôi phục
tham số bằng cách chọn giá trị khác không từ mỗi bản sao ParamPool,
nếu cần.
19: Dịch phải mỗi nhóm tham số bởi vw, vb, vs.
20: Pw, Pb, Ps ← π^{-1}_w Pw, π^{-1}_b Pb, π^{-1}_s Ps
21: return P = Pw ∪ Pb ∪ Ps
Lắp ráp các mô hình bí mật. Cuối cùng, kẻ đồng lõa khôi phục
các mô hình bí mật f1, f2, ..., fN bằng cách gọi nguyên hàm Fill
với ParamPool đã giải mã trong phần trước. Bằng cách này,
mục tiêu tấn công được đạt.
VI. KẾT QUẢ ĐÁNH GIÁ
A. Tổng quan về đánh giá
Tập dữ liệu & Kiến trúc. Chúng tôi đánh giá hiệu suất của
Matryoshka trên tính đa dạng của các tập dữ liệu và nhiệm vụ từ nhiều
lĩnh vực ứng dụng bao gồm hình ảnh, âm thanh, văn bản, chuỗi thời gian

--- TRANG 7 ---
BẢNG I
HIỆU QUẢ CỦA CUỘC TẤN CÔNG MATRYOSHKA TRONG VIỆC TRUYỀN TÁCH CÁC MÔ HÌNH BÍ MẬT ĐƠN THÔNG QUA MỘT RESNET-18 TRÊN CIFAR-10.
Lĩnh vực Nhiệm vụ Các nhiệm vụ bí mật Mô hình bí mật Mô hình vận chuyển
Tập dữ liệu/Mô hình/Metric # Params Perf-I Perf-II Normal Perf-I Perf-II Normal
Hình ảnh Phân loại GTSRB [62]/VGG-16 [63]/ACC 14.74M -0.51% 0.25% 98.45% 0.03% -0.61%
95.50% Phát hiện đối tượng VOC'07 [64]/MobileNetV1-SSD [65]/MAP 9.47M -1.42% -16.63% 51.57% 0.12% -0.61%
Văn bản Phân loại IMDB [66]/TextCNN [67]/ACC 6.69M -5.66% -9.08% 90.85% -0.16% -0.41%
Âm thanh Phân loại SpeechCommand [68]/M5 [69]/ACC 26.92K -1.39% -1.11% 96.86% -0.32% -1.14%
Chuỗi thời gian Phân loại UWave [70]/RNN/MSE 1.67K -1.14% -4.54% 86.36% -0.67% -0.40%
Y tế Phân loại DermaMNIST [71]/LeNet-5 [72]/ACC 61.98K -4.78% -5.74% 74.21% -0.34% -0.47%
Hồi quy Warfarin [73]/MLP/MSE 0.5K -0.51 -0.86 8.23 0.00% -0.35%
và y tế. Thông tin chung được trình bày trong cột Nhiệm vụ bí mật
của Bảng II. Do mối quan ngại về đạo đức, chúng tôi
thực hiện tất cả các thí nghiệm trên các tập dữ liệu công khai. Để tạo điều kiện
cho nghiên cứu trong tương lai, chúng tôi mở mã nguồn thực nghiệm của chúng tôi tại
https://anonymous.4open.science/r/hiding models-EAF8.
Chỉ số đánh giá. Chúng tôi đo hiệu quả của
việc đánh cắp hướng chức năng với Chênh lệch hiệu suất
(Perf). Đối với mô hình vận chuyển, Perf đo chênh lệch
giữa mô hình vận chuyển được mã hóa với các mô hình bí mật và một
mô hình vận chuyển được huấn luyện độc lập. Đối với một mô hình bí mật, Perf
đo chênh lệch hiệu suất giữa mô hình bí mật đã giải mã
và một mô hình có cùng kiến trúc trong khi
được huấn luyện độc lập trên tập dữ liệu riêng tư. Perf thấp hơn
có nghĩa là việc ẩn mô hình gây ra nhiều chi phí hiệu suất hơn cho
mô hình vận chuyển hoặc mô hình bí mật, điều này ngụ ý mô hình vận chuyển
có dung lượng thấp hơn. Hơn nữa, Perf mô hình vận chuyển thấp hơn
có nghĩa là việc ẩn mô hình ít che giấu hơn, trong khi Perf mô hình bí mật
thấp hơn cho thấy cuộc tấn công ít hiệu quả hơn. Cụ thể,
7 nhiệm vụ bí mật liên quan đến các chỉ số hiệu suất sau:
ACC: Độ chính xác (ACC) là chỉ số đánh giá tiêu chuẩn
cho các nhiệm vụ phân loại. ACC đo tỷ lệ
các mẫu được dự đoán chính xác. Nó viết chính thức ACC = ∑^N_{i=1} 1{f(xi) = yi}
/N, trong đó N là tổng số mẫu kiểm tra.
MAP: Độ chính xác trung bình (MAP) là chỉ số đánh giá phổ biến
cho nhiệm vụ phát hiện đối tượng, là trung bình của AP (độ chính xác trung bình)
trên tất cả các lớp đối tượng.
MSE: Lỗi bình phương trung bình (MSE) đo sự khác biệt L2
giữa đầu ra dự đoán và đầu ra thực tế
sau khi được tính trung bình trên các tọa độ. Chính thức,
MSE viết MSE(f(x), y) = ||f(x) - y||^2/dim(y), trong đó
dim(y) là chiều của đầu ra thực tế.
B. Ẩn mô hình bí mật đơn
Trước tiên, chúng tôi xác thực hiệu quả của cuộc tấn công Ma-
tryoshka được đề xuất trong việc ẩn một mô hình bí mật đơn trong vận chuyển.
Cụ thể, chúng tôi chọn mô hình bí mật từ các nguồn đa dạng
trong khi cố định mô hình vận chuyển là một ResNet-18 trên CIFAR-10.
Chúng tôi đánh giá cả trường hợp khi ParamPool được khởi tạo
từ mô hình vận chuyển (đánh dấu là I) hoặc được khởi tạo với kích thước
tùy chỉnh nhỏ hơn 5 lần so với mô hình vận chuyển (đánh dấu
là II). Bảng I báo cáo chênh lệch hiệu suất của

mô hình vận chuyển và các mô hình bí mật khi so sánh với các
đối tác bình thường được huấn luyện độc lập (các cột Normal).
Kết quả & Phân tích. Trước tiên, từ cột Perf-I cho
mô hình vận chuyển trong Bảng I, chúng tôi quan sát thấy Matryoshka chỉ
hy sinh không quá 1% tiện ích bình thường của mô hình vận chuyển
để truyền tải bí mật mỗi mô hình bí mật
có bản chất đa dạng. Theo [74], mức suy giảm 1%
không thể phân biệt với sự dao động trong hiệu suất mô hình
gây ra bởi tính ngẫu nhiên trong huấn luyện và đảm bảo tính che giấu tấn công.
Trong khi đó, từ cột Perf-I cho các
mô hình bí mật, chúng tôi quan sát thấy sự suy giảm hiệu suất
trên các mô hình bí mật đã giải mã được kiểm soát dưới 6%
đồng đều, điều này cho thấy việc đánh cắp chức năng thành công
[5], [6]. Hơn nữa, mặc dù mô hình vận chuyển được huấn luyện bình thường
cho phân loại hình ảnh, chúng tôi không quan sát bằng chứng rõ ràng
rằng mô hình vận chuyển tốt hơn trong việc ẩn các mô hình
từ cùng lĩnh vực. Ví dụ, Perf hơi
lớn hơn trên tập dữ liệu hình ảnh y tế DermaMNIST so với
tập dữ liệu âm thanh SpeechCommand (tức là 4,78% < 1,39%).
Theo phân tích của chúng tôi trong §V-C, điều này có thể được giải thích bởi
quan sát rằng một mô hình M5 được tối ưu hóa độc lập
trên SpeechCommand có phân phối tương tự hơn với
ResNet-18 so với một LeNet-5 được huấn luyện trên DermaMNIST
(tức là 0,021 < 0,053 về OTD). Cuối cùng, bằng cách so sánh
các cột Perf-I và Perf-II trong Bảng I, chúng tôi quan sát
lợi thế của việc khởi tạo ParamPool trực tiếp từ
mô hình vận chuyển, tức là Tùy chọn I, trong hiệu quả tấn công. Điều này có thể
được giải thích bởi nhiều tham số có thể học hơn được cung cấp bởi
vận chuyển và sơ đồ giá trị ngẫu nhiên tinh tế hơn được áp dụng
bởi framework học sâu để khởi tạo mô hình vận chuyển
[75], [76]. Do đó, trong các thí nghiệm sau, chúng tôi chủ yếu
đánh giá khởi tạo Tùy chọn I. Tuy nhiên, như chúng tôi đã thảo luận,
khởi tạo với ParamPool nhỏ hơn, tức là Tùy chọn II, có
lợi thế riêng trong việc tăng cường độ mạnh mẽ của Matryoshka,
điều này được xác thực sau trong §VI-E.
C. Ẩn nhiều mô hình bí mật
Tiếp theo, chúng tôi mở rộng đáng kể trường hợp ẩn mô hình đơn
để truyền tải bí mật nhiều mô hình bí mật trong
mô hình vận chuyển cùng một lúc. Cụ thể, chúng tôi chọn một tập hợp
đại diện gồm 6 mô hình bí mật trong cột Mô hình của Bảng II,
trải dài tất cả 5 lĩnh vực ứng dụng chúng tôi bao phủ. Chúng tôi tận dụng
cuộc tấn công Matryoshka với ParamPool được khởi tạo từ

--- TRANG 8 ---
mô hình vận chuyển ResNet-18. Bảng II báo cáo chênh lệch hiệu suất
của mô hình vận chuyển và các mô hình bí mật.
BẢNG II
HIỆU QUẢ CỦA MATRYOSHKA TRONG VIỆC TRUYỀN TẢI NHIỀU MÔ HÌNH
BÍ MẬT (BẢNG LOẠI TRỪ 2 MÔ HÌNH PHỤ TRỢ ĐỂ ĐÁNH CẮP
CÁC THAM SỐ KHÔNG THỂ HỌC).
Lĩnh vực Mô hình # Params Perf Normal Các mô hình bí mật Hình ảnh MobileNetV1-SSD 9.47M -1.22% 51.57%
Văn bản TextCNN 6.69M -5.61% 90.85%
Âm thanh M5 26.92K -1.89% 96.86%
Chuỗi thời gian RNN 1.67K 2.28% 86.36%
Y tế LeNet-5 61.98K -6.13% 74.21%
MLP 0.5K -0.27 8.23
# Params tổng cộng = 16.25M - -
Mô hình vận chuyển ResNet-18 11.17M -0.41% 95.50%
Kết quả & Phân tích. Như Bảng II cho thấy, Matryoshka cũng
cho thấy hiệu quả cao trong việc truyền tải bí mật nhiều
mô hình cùng một lúc. Khi chúng tôi mã hóa tất cả 6 mô hình và
2 mô hình phụ trợ trong một ResNet-18, Perf trên mô hình vận chuyển
vẫn dưới 1% như khi mã hóa một mô hình bí mật đơn. Hiện tượng này
nổi bật hơn trong trường hợp này vì
mô hình vận chuyển phải mã hóa nhiều mô hình có ít nhất
30% tham số nhiều hơn chính nó (tức là 11,17M so với 16,25M
cộng với mô hình phụ trợ). Hơn nữa, so với kết quả
trong Bảng I, chúng tôi quan sát thấy việc ẩn nhiều mô hình bí mật
không gây ra thêm mất mát tiện ích trên các mô hình bí mật. Ví
dụ, Perf trên TextCNN là 5,61% và 5,65% khi
nó được ẩn với hoặc không có 5 mô hình khác, trong khi, trên RNN,
hiệu suất thậm chí tăng gần 2% khi nó được ẩn
với các mô hình khác. Ngược lại, hầu hết các phương pháp ẩn thông tin
thông thường, bao gồm LSB và mã hóa dấu, không thể
ẩn một vận chuyển lớn hơn trong một vận chuyển nhỏ hơn bởi thiết kế
[21] và do đó không thể đạt được khả năng ẩn tương tự như
Matryoshka.
D. Khám phá dung lượng ẩn
Về kích thước của mô hình bí mật. Để khám phá giới hạn dung lượng
của Matryoshka, chúng tôi tiếp tục xác thực hiệu quả trong việc ẩn
một mô hình bí mật thường lớn hơn mô hình vận chuyển
nhiều lần. Cụ thể, chúng tôi khởi tạo ParamPool với một
tỷ lệ α (tức là α ∈ (0, 1.0]) tham số từ
mô hình vận chuyển đầy đủ, tức là một ResNet-18 trên CIFAR-10 [77]. Chúng tôi
chọn mô hình bí mật là một VGG-16 trên GTSRB [62], có
chứa 14,74M tham số, 1,32× mô hình vận chuyển đầy đủ.
Sau đó chúng tôi thay đổi tỷ lệ α từ 1,0 đến 0,01 và thực hiện
Matryoshka với ParamPool có kích thước khác nhau. Hình 4(a)
báo cáo các đường cong độ chính xác của mô hình bí mật và vận chuyển,
trong đó đường cong màu xanh báo cáo tỷ lệ kích thước giữa mô hình bí mật
và mô hình vận chuyển, và các đường ngang đứt báo cáo
độ chính xác của các đối tác bình thường.
Kết quả & Phân tích. Như Hình 4(a) cho thấy, Matryoshka rất
hiệu quả trong việc ẩn một mô hình bí mật lớn với số lượng
tham số nhỏ hơn nhiều từ vận chuyển. Ví dụ, khi
kích thước của ParamPool được giảm xuống 5% kích thước đầy đủ,

# Params trong vận chuyển
# Params trong bí mật Hình 4. Hiệu quả của Matryoshka (a) khi tỷ lệ giữa
mô hình vận chuyển và mô hình bí mật giảm và (b) khi số lượng
mô hình bí mật tăng. Các đường ngang đứt báo cáo hiệu suất
của các đối tác bình thường.
mô hình vận chuyển nhỏ hơn 26 lần so với vận chuyển về
số lượng tham số. Ngay cả trong tình huống này, độ chính xác
của mô hình bí mật và mô hình vận chuyển vẫn trong biên 1%
của hiệu suất bình thường.
Từ quan điểm của chúng tôi, dung lượng cao của Matryoshka nên
được quy cho cơ chế chia sẻ tham số mới của chúng tôi, khai thác
đầy đủ sự tương tự phân phối giữa các tham số mô hình:
Khi một tập con nhỏ hơn của các tham số được lấy mẫu ngẫu nhiên
từ mô hình vận chuyển đầy đủ, nó vẫn có thể xấp xỉ
phân phối của mô hình bí mật với lỗi có thể chấp nhận được. Như
dự kiến, khi kích thước ParamPool được giảm thêm xuống 1%
(tức là nhỏ hơn 131 lần), biến dạng gây ra bởi việc ẩn mô hình được
phóng đại, tức là độ chính xác của mô hình vận chuyển và bí mật giảm
tương ứng khoảng 5% và 15%.
Về số lượng mô hình bí mật. Chúng tôi cũng trình bày
thí nghiệm sau để khám phá hành vi của Matryoshka khi
số lượng nhiệm vụ bí mật N tăng. Để N có quan hệ
gần tuyến tính với dung lượng ẩn cần thiết, chúng tôi xây dựng
mỗi nhiệm vụ bí mật như một FCN bốn lớp với kích thước lớp ẩn
được lấy mẫu ngẫu nhiên từ [100, 300] trên một MNIST được hoán vị
[78] với các pixel trong mỗi đầu vào được hoán vị với một
hoán vị ngẫu nhiên cố định cụ thể cho một nhiệm vụ. Điều này đảm bảo mỗi
mô hình bí mật độc lập với nhau [79]. Mô hình vận chuyển
là một FCN có quy mô trung bình, tức là (784-200-200-10),
trên MNIST được hoán vị riêng của nó. Hình 4(b) báo cáo đường cong
hiệu suất trung bình của các mô hình bí mật khi N tăng
từ 10 đến 400, trong đó đường đứt báo cáo độ chính xác của
một mô hình được huấn luyện độc lập có cùng kiến trúc
với mô hình vận chuyển, và các thanh lỗi báo cáo độ lệch chuẩn
của hiệu suất của tất cả N mô hình bí mật.
Kết quả & Phân tích. Như Hình 4(b) cho thấy, ban đầu mô hình FCN
vận chuyển mã hóa 10 mô hình cùng quy mô với
gần như không suy giảm hiệu suất. Khi số lượng nhiệm vụ
tiếp tục tăng, độ chính xác của mô hình vận chuyển và
mô hình bí mật chỉ giảm 1,5% khi N tăng đến 100,
và vẫn trên 90% khi N đạt 400. Kết hợp với
kết quả trong §VI-C, Matryoshka thực sự cho phép một mô hình vận chuyển
mã hóa nhiều mô hình bí mật có kiến trúc khác nhau và
cho các nhiệm vụ khác nhau, chỉ với sự suy giảm nhẹ về
tiện ích bình thường. Theo hiểu biết tốt nhất, các công việc trước chỉ khám phá
việc chồng chập nhiều mô hình có cùng kiến trúc
trong một mô hình trong lĩnh vực học liên tục [79].

--- TRANG 9 ---
E. Độ mạnh mẽ chống lại các kỹ thuật hậu xử lý phổ biến
Cuối cùng, chúng tôi đánh giá độ mạnh mẽ của Matryoshka khi
mô hình vận chuyển trải qua các kỹ thuật hậu xử lý mô hình phổ biến,
bao gồm cắt tỉa tham số và tinh chỉnh mô hình.
Cụ thể, chúng tôi xem xét các cài đặt sau.
(1) Cắt tỉa trọng số: Một tỷ lệ α tham số trọng số
có giá trị tuyệt đối nhỏ nhất được đặt thành 0 trong mỗi lớp
[80]. Trong các thí nghiệm của chúng tôi, chúng tôi thay đổi α từ 0,1 đến 0,5.
(2) Tinh chỉnh một phần: Để tinh chỉnh K lớp cuối của một
mô hình vận chuyển H lớp, các tham số của H-K lớp đầu
được cố định, trong khi các tham số của K lớp cuối được
cập nhật thêm bằng cách tối ưu hóa mục tiêu học của mô hình vận chuyển
trên dữ liệu huấn luyện.
Trong các thí nghiệm của chúng tôi, chúng tôi chọn ResNet-18 trên CIFAR-10
là mô hình vận chuyển, với ba mô hình trong Bảng I trên
GTSRB (hình ảnh), IMDB (văn bản) và SpeechCommand (âm thanh)
làm mô hình bí mật tương ứng. Để tinh chỉnh mô hình, chúng tôi
tinh chỉnh các tham số cho đến lớp tuyến tính cuối, bốn
khối cơ bản, và lớp tích chập đầu tiên trong mô hình vận chuyển
tương ứng. Để kiểm tra các kỹ thuật hợp nhất tại giai đoạn giải mã,
chúng tôi khởi tạo ParamPool với kích thước tùy chỉnh nhỏ hơn 5 lần
so với mô hình vận chuyển. Điều này cho phép chúng tôi triển khai một
thuật toán khôi phục ParamPool để khôi phục tham số đã bị cắt tỉa
bằng cách chọn giá trị khác không từ mỗi bản sao ParamPool.
Để tinh chỉnh, vì bản sao đầu tiên của ParamPool chỉ được
sửa đổi khi mô hình được tinh chỉnh đến vài
lớp đầu tiên, chúng tôi luôn giải mã bản sao đầu tiên làm ParamPool. Hình 5
báo cáo hiệu suất của mô hình vận chuyển và bí mật dưới các
cấu hình khác nhau trên SpeechCommand.
0 0.1 0.2 0.3 0.4 0.5
Tỷ lệ cắt tỉa (α)
20406080100ACC (%)
(a)
Vận chuyển
Bí mật (có hợp nhất)
Bí mật (không hợp nhất)
1 2 3 4 5 6
Tinh chỉnh đến (K)80859095100
(b)
Vận chuyển
Bí mật
Hình 5. Hiệu suất của các mô hình vận chuyển/bí mật dưới các mức độ khác nhau của (a)
cắt tỉa trọng số và (b) tinh chỉnh mô hình trên SpeechCommand. Các đường ngang đứt
báo cáo hiệu suất của các đối tác bình thường.
Kết quả & Phân tích. Như Hình 5(a) cho thấy, hiệu suất của
mô hình bí mật vẫn cao ngay cả khi mô hình vận chuyển
trải qua mất mát tiện ích lớn do tỷ lệ cắt tỉa trọng số
lớn. Ví dụ, khi α đạt 0,3, hiệu suất của
mô hình vận chuyển giảm hơn 10% so với
hiệu suất bình thường (được đánh dấu trong đường đứt màu xanh lá cây), trong khi
độ chính xác của mô hình bí mật vẫn trong biên 1%
của tiện ích bình thường. So sánh hiệu suất của mô hình bí mật
có và không có cơ chế hợp nhất, chúng tôi kết luận
rằng độ mạnh mẽ của Matryoshka chủ yếu đến từ dự phòng thông tin
được triển khai vốn có trong
thiết kế ParamPool của chúng tôi. Do đó, chỉ khi một tham số ParamPool
không phải luôn luôn nhỏ nhất cho tất cả các lớp, thuật toán giải mã của chúng tôi
luôn có thể khôi phục giá trị của nó bằng cách tham khảo
bản sao chưa bị cắt tỉa. Tương tự từ Hình 5(b), độ mạnh mẽ được
00.1 0.2 0.3 0.4 0.5
Tỷ lệ cắt tỉa (α)
020406080100ACC (%)
(a)
Vận chuyển
Bí mật (có hợp nhất)
Bí mật (không hợp nhất)
1 2 3 4 5 6
Tinh chỉnh đến (K)0255075100
(b)
Vận chuyển
Bí mật Hình 6. Hiệu suất của các mô hình vận chuyển/bí mật dưới các mức độ khác nhau của (a)
cắt tỉa trọng số và (b) tinh chỉnh mô hình trên IMDB.
00.1 0.2 0.3 0.4 0.5
Tỷ lệ cắt tỉa (α)
020406080100ACC (%)
(a)
Vận chuyển
Bí mật (có hợp nhất)
Bí mật (không hợp nhất)
1 2 3 4 5 6
Tinh chỉnh đến (K)80859095100
(b)
Vận chuyển
Bí mật
Hình 7. Hiệu suất của các mô hình vận chuyển/bí mật dưới các mức độ khác nhau của (a)
cắt tỉa trọng số và (b) tinh chỉnh mô hình trên GTSRB.
quan sát thấy khi mô hình vận chuyển được tinh chỉnh đến
lớp đầu tiên. Hình 6&7 trình bày hiện tượng thí nghiệm tương tự khi
ẩn các mô hình bí mật trên văn bản (IMDB) và hình ảnh (GTSRB).
Bên cạnh các kỹ thuật hậu xử lý chúng tôi đề cập,
chúng tôi thừa nhận rằng Matryoshka có thể ít mạnh mẽ hơn khi
kiến trúc của mô hình vận chuyển bị sửa đổi. Tuy nhiên, việc
hậu xử lý một mô hình đã được tối ưu hóa bằng cách sửa đổi kiến trúc của nó
không phải là thực hành phổ biến, ngoại trừ một số trường hợp đặc biệt
mà tập đoàn muốn tối ưu hóa thêm hiệu quả lưu trữ
và tính toán bằng cách nén mô hình (ví dụ: cắt tỉa
hoặc lượng tử hóa). Tuy nhiên, ngay cả với nén mô hình,
phiên bản nén thường được phát hành cùng với
mô hình thô có kích thước đầy đủ trên hầu hết các nền tảng bên thứ ba [81], [82].
Hơn nữa, hậu xử lý thường được thực hiện bởi người dùng
sau khi họ tải xuống mô hình và khó được thực hiện
bởi chính tập đoàn trong trường hợp làm suy giảm
tiện ích mô hình. Nói cách khác, trong các thủ tục công bố mô hình điển hình,
các tham số mô hình vẫn cố định một khi quá trình huấn luyện
kết thúc, cũng như kiến trúc của mô hình vận chuyển.
Do đó, kẻ đồng lõa rất có khả năng có được mô hình vận chuyển
như trong dạng ban đầu được chuẩn bị bởi kẻ nội bộ.
F. Tránh các chiến lược phát hiện tiềm năng
Để hiểu thêm về tính che giấu của cuộc tấn công Matryoshka,
chúng tôi thảo luận một số chiến lược phát hiện tiềm năng và
cho thấy chiến lược truyền tải bí mật của chúng tôi có thể tránh chúng một cách tự nhiên
hoặc với các thiết kế thích ứng hơi nhiều hơn. Theo cùng
mô hình bảo mật trong steganography [21], chúng tôi chủ yếu xem xét một
bộ phát hiện có thể kiểm tra mô hình được công bố như một hộp trắng
để xác định liệu mô hình có phải là mô hình vận chuyển hay không. Việc phát hiện
được giả định xảy ra trước quá trình công bố.
Nếu bộ phát hiện tin tưởng về sự tồn tại của các mô hình bí mật được mã hóa,
việc truyền tải sẽ bị loại bỏ. Tuy nhiên, như một
sự đánh đổi, khi một mô hình vô tội bị nhận dạng sai, quá trình công bố
sẽ bị trì hoãn một cách bất ngờ.
Phát hiện bằng phân phối tham số. Trước tiên, chúng tôi thảo luận
phân tích thống kê dựa trên thống kê, một chiến lược cổ điển trên
nội dung đa phương tiện [21] và có thể được áp dụng bởi
một bộ phát hiện không có kiến thức về cơ chế tấn công.
Cụ thể, bộ phát hiện so sánh mô hình C đang được kiểm tra
với một tập hợp các mô hình bình thường về phân phối tham số
để xác định liệu có bất thường nào không. Trong nghiên cứu sơ bộ của chúng tôi,
chúng tôi chủ yếu xem xét tình huống mà bộ phát hiện có một tập hợp
các mô hình không liên quan đến C. Chúng tôi
không xem xét trường hợp bộ phát hiện có một tập lớn
các mô hình được huấn luyện độc lập có cùng kiến trúc với C để
thực hiện kiểm tra thống kê hoặc phát hiện dựa trên học tập [83]. Từ
quan điểm của chúng tôi, điều này hiếm khi xảy ra trong thế giới thực vì
mục đích huấn luyện C là để công bố, có nghĩa là một mô hình như vậy
chưa được huấn luyện hoặc chưa có sẵn trước đó.
Cụ thể, chúng tôi trước tiên chuẩn bị một mô hình vận chuyển và một mô hình bình thường
có cùng kiến trúc. Sau đó, chúng tôi tính toán sự khác biệt
giữa chúng với 8 mô hình không liên quan mà chúng tôi sử dụng trong
§V-C. Chúng tôi sử dụng OTD giữa các phân phối tham số
để đo sự khác biệt mô hình. Hình 8(a) so sánh
phân phối của OTD trên hai loại cặp mô hình, cụ thể là
(vận chuyển, không liên quan) và (bình thường, không liên quan), trong đó các
phân phối của các chỉ số khác biệt gần như không thể phân biệt
với nhau trên cả trọng số hoặc bias.
Phát hiện bằng mẫu lặp lại. Một bộ phát hiện có kiến thức hơn
biết thủ tục xây dựng của ParamPool có thể cố gắng phân tích
các mẫu trong tham số mô hình để phát hiện. Theo §V-A, khi ParamPool được
xây dựng trực tiếp từ mô hình vận chuyển, không nên có
mẫu bất thường nào trong mô hình vận chuyển, vì mỗi tham số
độc lập với nhau. Bên cạnh đó, theo kết quả trước của chúng tôi,
phân phối tham số trong mô hình vận chuyển
cũng không thể phân biệt với một mô hình bình thường. Tuy nhiên, một
mẫu có thể khai thác thực sự tồn tại khi ParamPool được xây dựng
từ đầu và có kích thước nhỏ hơn mô hình vận chuyển.
Như Hình 8(b) cho thấy, một chuỗi tham số sẽ xuất hiện
nhiều lần khi chúng tôi thu thập các tham số có thể học
trong mô hình vận chuyển theo thứ tự. Bộ phát hiện có thể khai thác
thuộc tính này để chạy thuật toán nhận dạng chuỗi con lặp lại
để phát hiện, có độ phức tạp O(n^2)
(với n là số lượng tham số trong mô hình vận chuyển).
Tuy nhiên, việc tránh phát hiện dựa trên heuristic này cũng đơn giản.
Như Hình 8(b) cho thấy, khi quá trình ẩn mô hình
kết thúc, kẻ tấn công có thể chủ động tinh chỉnh mô hình vận chuyển
trên tập dữ liệu huấn luyện trong khi đóng băng một bản sao của ParamPool
để loại bỏ các mẫu tham số lặp lại. Sau khi tinh chỉnh chủ động,
cả mô hình vận chuyển và các mô hình bí mật
đều không bị suy giảm hiệu suất theo thiết kế. Trong
quan điểm của chúng tôi, chi phí duy nhất của chiến lược tránh này là, sau
khi tinh chỉnh, chỉ có một bản sao của ParamPool tồn tại, và không có
dự phòng thông tin nào có thể được sử dụng để cải thiện khả năng chống chịu
của bí mật trong mô hình vận chuyển. Chúng tôi khuyến nghị kẻ tấn công
xác định liệu có áp dụng tinh chỉnh chủ động hay không dựa trên
ưu tiên về tính che giấu và độ mạnh mẽ.
Hình 8. (a) So sánh phân phối của sự khác biệt tham số, trong đó các đường đứt
đánh dấu các phân vị. (b) Một chiến lược tinh chỉnh một phần để tránh
phát hiện dựa trên mẫu lặp lại.
Phát hiện bằng giám sát sử dụng hệ thống. Cuối cùng, chúng tôi
thảo luận trường hợp bộ phát hiện giám sát thông tin hệ thống
thời gian thực của các thiết bị tính toán để xác định liệu
có cuộc tấn công Matryoshka đang diễn ra hay không, điều này thường được
thực hiện bởi quản trị viên hệ thống chịu trách nhiệm
về cụm tính toán. Trong tình huống này, bộ phát hiện có thể
quan sát thông tin kênh phụ như tải CPU, GPU và
bộ nhớ để nhận dạng bất kỳ cuộc tấn công đang diễn ra nào (ví dụ: phát hiện
cryptojacking [84]). Mặc dù thuật toán huấn luyện chung
của Matryoshka thực sự thể hiện tỷ lệ sử dụng đồng thời cao
của ba loại tài nguyên tính toán, mẫu sử dụng tài nguyên như vậy
rất phổ biến cho các dự án học sâu. Ví dụ, sử dụng đa xử lý khi
truyền phát các batch huấn luyện sẽ gây ra cả việc sử dụng CPU và bộ nhớ cao,
trong khi sử dụng song song hóa dữ liệu để tăng tốc việc huấn luyện
một mô hình DNN sẽ gây ra tỷ lệ sử dụng cao trên nhiều
GPU. Nói cách khác, một bộ phát hiện khó có thể phân biệt
giữa một Matryoshka đang diễn ra và một nhiệm vụ huấn luyện tốn tài nguyên
chỉ từ thống kê sử dụng hệ thống thời gian thực.
Tóm tắt, bộ phát hiện trong những trường hợp này sẽ phải đối mặt với
nguy cơ lớn khi phân loại một mô hình vô tội sai
thành mô hình vận chuyển và do đó sẽ không báo động và
loại bỏ bất kỳ mô hình được lên lịch công bố nào. Xem xét
các mối đe dọa thực tế do các cuộc tấn công của chúng tôi đặt ra đối với các tập dữ liệu riêng tư
ngay cả khi không có giao diện tiếp xúc, chúng tôi mạnh mẽ khuyến khích
nghiên cứu các cơ chế phòng thủ hiệu quả như một công việc tương lai.
VII. KẾT LUẬN
Trong bài báo này, chúng tôi thiết kế một cuộc tấn công nội bộ mới gọi là
Matryoshka lần đầu tiên tiết lộ khả năng phá vỡ quyền riêng tư
của dữ liệu ML ngay cả khi không có giao diện tiếp xúc. Thông qua
kỹ thuật tấn công mới của chúng tôi là ẩn mô hình trong mô hình,
Matryoshka thành công đánh cắp cả chức năng của
(các) tập dữ liệu riêng tư chỉ khi kẻ tấn công được ủy quyền truy cập
vào tập dữ liệu mục tiêu trong mạng cục bộ. Chúng tôi cung cấp
kết quả đánh giá toàn diện để cho thấy Matryoshka hiệu quả, mạnh mẽ và
che giấu trong việc truyền tải các mô hình bí mật thông qua DNN được lên lịch
công bố và thể hiện dung lượng ẩn cao hơn nhiều
so với các phương pháp đã biết. Chúng tôi hy vọng lỗ hổng đã khám phá của chúng tôi
sẽ cảnh báo các tập đoàn AI về các rủi ro tiềm ẩn của bất kỳ
việc truy cập không cần thiết nào vào các tập dữ liệu riêng tư ngay cả khi chúng được
lưu trữ an toàn trong mạng cục bộ.

--- TRANG 10 ---
TÀI LIỆU THAM KHẢO
[1] Y. Bengio, Y. LeCun, và G. E. Hinton, "Deep learning for ai,"
Communications of the ACM, vol. 64, pp. 58 – 65, 2021.
[2] "Building a national ai research resource: A blueprint for the national
research cloud," https://hai.stanford.edu/sites/default/files/2021-10/HAI
NRCR 2021 0.pdf.
[3] D. L. Wenskay, "Intellectual property protection for neural networks,"
Neural Networks, 1990.
[4] "Google's Approach to IT Security," https://static.
googleusercontent.com/media/1.9.22.221/en//enterprise/pdf/whygoogle/
google-common-security-whitepaper.pdf.
[5] F. Tramèr, F. Zhang, A. Juels, M. K. Reiter, và T. Ristenpart, "Stealing
machine learning models via prediction apis," trong USENIX Security
Symposium, 2016.
[6] J. R. Correia-Silva, R. Berriel, C. S. Badue, A. F. de Souza, và
T. Oliveira-Santos, "Copycat cnn: Stealing knowledge by persuading
confession with random non-labeled data," 2018 International Joint
Conference on Neural Networks (IJCNN), pp. 1–8, 2018.
[7] V. Chandrasekaran, K. Chaudhuri, I. Giacomelli, S. Jha, và S. Yan,
"Exploring connections between active learning and model extraction,"
trong USENIX Security Symposium, 2020.
[8] M. Jagielski, N. Carlini, D. Berthelot, A. Kurakin, và N. Papernot,
"High accuracy and high fidelity extraction of neural networks," trong
USENIX Security Symposium, 2020.
[9] H. Hu và J. Pang, "Stealing machine learning models: Attacks and
countermeasures for generative adversarial networks," Annual Computer
Security Applications Conference, 2021.
[10] M. Fredrikson, S. Jha, và T. Ristenpart, "Model inversion attacks that
exploit confidence information and basic countermeasures," trong CCS,
2015.
[11] K. Ganju, Q. Wang, W. Yang, C. A. Gunter, và N. Borisov, "Property
inference attacks on fully connected neural networks using permutation
invariant representations," trong CCS, 2018.
[12] L. Melis, C. Song, E. D. Cristofaro, và V. Shmatikov, "Exploiting unintended feature leakage in collaborative learning," 2019 IEEE Symposium
on Security and Privacy (SP), pp. 691–706, 2019.
[13] M. Fredrikson, E. Lantz, S. Jha, S. Lin, D. Page, và T. Ristenpart,
"Privacy in pharmacogenetics: An end-to-end case study of personalized
warfarin dosing," vol. 2014, pp. 17–32, 2014.
[14] R. Shokri, M. Stronati, C. Song, và V. Shmatikov, "Membership
inference attacks against machine learning models," Security & Privacy,
pp. 3–18, 2017.
[15] A. Salem, Y. Zhang, M. Humbert, M. Fritz, và M. Backes, "Ml-leaks:
Model and data independent membership inference attacks and defenses
on machine learning models," NDSS, 2019.
[16] A. Cheddad, J. Condell, K. Curran, và P. M. Kevitt, "Digital image
steganography: Survey and analysis of current methods," Signal Process., vol. 90, pp. 727–752, 2010.
[17] Z. Yang, X. Guo, Z.-M. Chen, Y. Huang, và Y.-J. Zhang, "Rnn-stega:
Linguistic steganography based on recurrent neural networks," IEEE
Transactions on Information Forensics and Security, vol. 14, pp. 1280–
1295, 2019.
[18] F. Djebbar và B. Ayad, "Comparative study of digital audio steganography techniques," EURASIP Journal on Audio, Speech, and Music
Processing, vol. 2012, pp. 1–16, 2012.
[19] C. Song, T. Ristenpart, và V. Shmatikov, "Machine learning models that
remember too much," Proceedings of the 2017 ACM SIGSAC Conference
on Computer and Communications Security, 2017.
[20] Y. Uchida, Y. Nagai, S. Sakazawa, và S. Satoh, "Embedding watermarks into deep neural networks," Proceedings of the 2017 ACM on
International Conference on Multimedia Retrieval, 2017.
[21] N. Provos và P. Honeyman, "Hide and seek: An introduction to
steganography," IEEE Secur. Priv., vol. 1, pp. 32–44, 2003.
[22] J. von Neumann, "Probabilistic logic and the synthesis of reliable
organisms from unreliable components," Automata studies, vol. 34, pp.
43–98, 1956.
[23] G. Ateniese, L. V. Mancini, A. Spognardi, A. Villani, D. Vitali, và
G. Felici, "Hacking smart machines with smarter ones: How to extract
meaningful data from machine learning classifiers," Int. J. Secur. Networks, vol. 10, pp. 137–150, 2015.
[24] T. Orekondy, B. Schiele, và M. Fritz, "Knockoff nets: Stealing functionality of black-box models," 2019 IEEE/CVF Conference on Computer
Vision and Pattern Recognition (CVPR), pp. 4949–4958, 2019.[25] S. J. Oh, M. Augustin, M. Fritz, và B. Schiele, "Towards reverse-
engineering black-box neural networks," trong ICLR, 2018.
[26] N. Carlini, M. Jagielski, và I. Mironov, "Cryptanalytic extraction of
neural network models," trong CRYPTO, 2020.
[27] Z. Li và Y. Zhang, "Membership leakage in label-only exposures,"
Proceedings of the 2021 ACM SIGSAC Conference on Computer and
Communications Security, 2021.
[28] C. A. Choquette-Choo, F. Tramèr, N. Carlini, và N. Papernot, "Label-
only membership inference attacks," trong ICML, 2021.
[29] X. Pan, M. Zhang, S. Ji, và M. Yang, "Privacy risks of general-purpose
language models," 2020 IEEE Symposium on Security and Privacy (SP),
pp. 1314–1331, 2020.
[30] L. Zhu, Z. Liu, và S. Han, "Deep leakage from gradients," trong NeurIPS,
2019.
[31] J. Geiping, H. Bauermeister, H. Dröge, và M. Moeller, "Inverting
gradients - how easy is it to break privacy in federated learning?" trong
NeurIPS, 2020.
[32] N. Carlini, C. Liu, Ú. Erlingsson, J. Kos, và D. X. Song, "The
secret sharer: Evaluating and testing unintended memorization in neural
networks," trong USENIX Security Symposium, 2019.
[33] A. Salem, A. Bhattacharyya, M. Backes, M. Fritz, và Y. Zhang,
"Updates-leak: Data set inference and reconstruction attacks in online
learning," USENIX Security, 2020.
[34] A. Radhakrishnan, M. Belkin, và C. Uhler, "Overparameterized neural
networks implement associative memory," Proceedings of the National
Academy of Sciences of the United States of America, vol. 117, pp.
27 162 – 27 170, 2020.
[35] N. Carlini, F. Tramèr, E. Wallace, M. Jagielski, A. Herbert-Voss, K. Lee,
A. Roberts, T. B. Brown, D. X. Song, Ú. Erlingsson, A. Oprea, và
C. Raffel, "Extracting training data from large language models," trong
USENIX Security Symposium, 2021.
[36] Y. Adi, C. Baum, M. Cissé, B. Pinkas, và J. Keshet, "Turning
your weakness into a strength: Watermarking deep neural networks by
backdooring," trong USENIX Security Symposium, 2018.
[37] H. Chen, B. D. Rouhani, C. Fu, J. Zhao, và F. Koushanfar, "Deepmarks:
A secure fingerprinting framework for digital rights management of deep
learning models," Proceedings of the 2019 on International Conference
on Multimedia Retrieval, 2019.
[38] T. Wang và F. Kerschbaum, "Riga: Covert and robust white-box watermarking of deep neural networks," Proceedings of the Web Conference
2021, 2021.
[39] I. Goodfellow, Y. Bengio, và A. Courville, Deep Learning. MIT Press,
2016.
[40] J. B. Heaton, N. G. Polson, và J. H. Witte, "Deep learning for finance:
Deep portfolios," Econometric Modeling: Capital Markets - Portfolio
Theory eJournal, 2016.
[41] A. Esteva, B. Kuprel, R. A. Novoa, J. M. Ko, S. M. Swetter, H. M.
Blau, và S. Thrun, "Dermatologist-level classification of skin cancer
with deep neural networks," Nature, 2017.
[42] J. Redmon, S. K. Divvala, R. B. Girshick, và A. Farhadi, "You only
look once: Unified, real-time object detection," 2016 IEEE Conference
on Computer Vision and Pattern Recognition (CVPR), pp. 779–788,
2016.
[43] I. J. Goodfellow, Y. Bengio, và A. C. Courville, "Deep learning,"
Nature, vol. 521, pp. 436–444, 2015.
[44] D. P. Kingma và J. Ba, "Adam: A method for stochastic optimization,"
CoRR, vol. abs/1412.6980, 2015.
[45] S. Alneyadi, E. Sithirasenan, và V. Muthukkumarasamy, "A survey on
data leakage prevention systems," J. Netw. Comput. Appl., vol. 62, pp.
137–152, 2016.
[46] "Understanding and Selecting a Data Loss Prevention Solution," https:
//securosis.com/assets/library/reports/DLP-Whitepaper.pdf.
[47] S. Ren, K. He, R. B. Girshick, và J. Sun, "Faster r-cnn: Towards real-
time object detection with region proposal networks," IEEE Transactions
on Pattern Analysis and Machine Intelligence, vol. 39, pp. 1137–1149,
2015.
[48] C. Shorten và T. M. Khoshgoftaar, "A survey on image data augmentation for deep learning," Journal of Big Data, vol. 6, pp. 1–48, 2019.
[49] T. Baltruaitis, C. Ahuja, và L.-P. Morency, "Multimodal machine learning: A survey and taxonomy," IEEE Transactions on Pattern Analysis
and Machine Intelligence, vol. 41, pp. 423–443, 2019.
[50] K. Krombholz, H. Hobel, M. Huber, và E. R. Weippl, "Advanced social
engineering attacks," J. Inf. Secur. Appl., vol. 22, pp. 113–122, 2015.

--- TRANG 11 ---
[51] "Open Sourcing BERT," https://ai.googleblog.com/2018/11/
open-sourcing-bert-state-of-art-pre.html.
[52] "GitHub Homepage of OpenAI," https://github.com/openai.
[53] C. W. Kurak và J. McHugh, "A cautionary note on image downgrading," [1992] Proceedings Eighth Annual Computer Security Application
Conference, pp. 153–159, 1992.
[54] T. Liu, Z. Liu, Q. Liu, W. Wen, W. Xu, và M. Li, "Stegonet: Turn
deep neural network into a stegomalware," Annual Computer Security
Applications Conference, 2020.
[55] "BOSSBase Stegnoanalysis Dataset," http://agents.fel.cvut.cz/boss/
index.php?mode=VIEW&tmpl=materials.
[56] B. Jacob, S. Kligys, B. Chen, M. Zhu, M. Tang, A. G. Howard, H. Adam,
và D. Kalenichenko, "Quantization and training of neural networks for
efficient integer-arithmetic-only inference," 2018 IEEE/CVF Conference
on Computer Vision and Pattern Recognition, pp. 2704–2713, 2018.
[57] R. Krishnamoorthi, "Quantizing deep convolutional networks for efficient inference: A whitepaper," ArXiv, vol. abs/1806.08342, 2018.
[58] "PyTorch Hub," https://pytorch.org/hub/.
[59] Y. Rubner, C. Tomasi, và L. J. Guibas, "The earth mover's distance as
a metric for image retrieval," International Journal of Computer Vision,
vol. 40, pp. 99–121, 2004.
[60] C. Villani, Optimal transport: old and new. Springer Science &
Business Media, 2008, vol. 338.
[61] T.-W. Weng, P. Zhao, S. Liu, P.-Y. Chen, X. Lin, và L. Daniel, "Towards
certified model robustness against weight perturbations," trong AAAI,
2020.
[62] S. Houben, J. Stallkamp, J. Salmen, M. Schlipsing, và C. Igel,
"Detection of traffic signs in real-world images: The German Traffic
Sign Detection Benchmark," trong International Joint Conference on Neural
Networks, no. 1288, 2013.
[63] K. Simonyan và A. Zisserman, "Very deep convolutional networks for
large-scale image recognition," arXiv preprint arXiv:1409.1556, 2014.
[64] M. Everingham, S. M. A. Eslami, L. Van Gool, C. K. I. Williams,
J. Winn, và A. Zisserman, "The pascal visual object classes challenge:
A retrospective," International Journal of Computer Vision, vol. 111,
no. 1, pp. 98–136, Jan. 2015.
[65] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang,
T. Weyand, M. Andreetto, và H. Adam, "Mobilenets: Efficient convolutional neural networks for mobile vision applications," arXiv preprint
arXiv:1704.04861, 2017.
[66] A. L. Maas, R. E. Daly, P. T. Pham, D. Huang, A. Y. Ng, và C. Potts,
"Learning word vectors for sentiment analysis," trong Proceedings of the
49th Annual Meeting of the Association for Computational Linguistics:
Human Language Technologies. Portland, Oregon, USA: Association
for Computational Linguistics, June 2011, pp. 142–150. [Online].
Available: http://www.aclweb.org/anthology/P11-1015
[67] Y. Zhang và B. Wallace, "A sensitivity analysis of (and practitioners'
guide to) convolutional neural networks for sentence classification,"
arXiv preprint arXiv:1510.03820, 2015.
[68] P. Warden, "Speech Commands: A Dataset for Limited-Vocabulary
Speech Recognition," ArXiv e-prints, Apr. 2018. [Online]. Available:
https://arxiv.org/abs/1804.03209
[69] W. Dai, C. Dai, S. Qu, J. Li, và S. Das, "Very deep convolutional neural
networks for raw waveforms," trong 2017 IEEE International Conference
on Acoustics, Speech and Signal Processing (ICASSP), 2017, pp. 421–
425.
[70] J. Liu, L. Zhong, J. Wickramasuriya, và V. Vasudevan, "uwave:
Accelerometer-based personalized gesture recognition and its applications," Pervasive and Mobile Computing, vol. 5, no. 6, pp. 657–675,
2009.
[71] J. Yang, R. Shi, D. Wei, Z. Liu, L. Zhao, B. Ke, H. Pfister, và
B. Ni, "Medmnist v2: A large-scale lightweight benchmark for 2d and
3d biomedical image classification," arXiv preprint arXiv:2110.14795,
2021.
[72] Y. LeCun, L. Bottou, Y. Bengio, và P. Haffner, "Gradient-based learning
applied to document recognition," Proceedings of the IEEE, vol. 86,
no. 11, pp. 2278–2324, 1998.
[73] G. Truda và P. Marais, "Evaluating warfarin dosing models on
multiple datasets with a novel software framework and evolutionary
optimisation," Journal of Biomedical Informatics, p. 103634, 2020.
[Online]. Available: http://www.sciencedirect.com/science/article/pii/
S1532046420302628[74] T. Gu, K. Liu, B. Dolan-Gavitt, và S. Garg, "Badnets: Evaluating
backdooring attacks on deep neural networks," IEEE Access, vol. 7,
pp. 47 230–47 244, 2019.
[75] X. Glorot và Y. Bengio, "Understanding the difficulty of training deep
feedforward neural networks," trong AISTATS, 2010.
[76] K. He, X. Zhang, S. Ren, và J. Sun, "Delving deep into rectifiers:
Surpassing human-level performance on imagenet classification," 2015
IEEE International Conference on Computer Vision (ICCV), pp. 1026–
1034, 2015.
[77] A. Krizhevsky, "Learning multiple layers of features from tiny images,"
2009.
[78] I. J. Goodfellow, M. Mirza, X. Da, A. C. Courville, và Y. Bengio, "An
empirical investigation of catastrophic forgeting in gradient-based neural
networks," ICLR, 2014.
[79] B. Cheung, A. Terekhov, Y. Chen, P. Agrawal, và B. A. Olshausen,
"Superposition of many models into one," ArXiv, vol. abs/1902.05522,
2019.
[80] S. Han, J. Pool et al., "Learning both weights and connections for
efficient neural network," ArXiv, 2015.
[81] "Models - Machine Learning - Apple Developer," https://developer.
apple.com/machine-learning/models/.
[82] "Available Models-PaddleLite," https://paddle-
lite.readthedocs.io/zh/latest/introduction/support model list.html,
accessed: 2021-05-21.
[83] X. Xu, Q. Wang, H. Li, N. Borisov, C. A. Gunter, và B. Li, "Detecting
ai trojans using meta neural analysis," 2021 IEEE Symposium on Security
and Privacy (SP), pp. 103–120, 2021.
[84] R. Ning, C. Wang, C. Xin, J. Li, L. Zhu, và H. Wu, "Capjack: Capture
in-browser crypto-jacking by deep capsule network through behavioral
analysis," IEEE INFOCOM 2019 - IEEE Conference on Computer
Communications, pp. 1873–1881, 2019.

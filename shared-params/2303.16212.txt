# 2303.16212.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/shared-params/2303.16212.pdf
# File size: 3347286 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
1
A Multi-objective Complex Network Pruning
Framework Based on Divide-and-conquer and
Global Performance Impairment Ranking
Ronghua Shang, Senior Member, IEEE , Songling Zhu∗, Yinan Wu, Weitong Zhang, Member, IEEE ,
Licheng Jiao, Fellow, IEEE , Songhua Xu
Abstract —Model compression plays a vital role in the practical
deployment of deep neural networks (DNNs), and evolutionary
multi-objective (EMO) pruning is an essential tool in balancing
the compression rate and performance of the DNNs. However,
due to its population-based nature, EMO pruning suffers from
the complex optimization space and the resource-intensive struc-
ture verification process, especially in complex networks. To
this end, a multi-objective complex network pruning framework
based on divide-and-conquer and global performance impair-
ment ranking (EMO-DIR) is proposed in this paper. Firstly, a
divide-and-conquer EMO network pruning method is proposed,
which decomposes the complex task of EMO pruning on the
entire network into easier sub-tasks on multiple sub-networks.
On the one hand, this decomposition narrows the pruning
optimization space and decreases the optimization difficulty;
on the other hand, the smaller network structure converges
faster, so the proposed algorithm consumes lower computational
resources. Secondly, a sub-network training method based on
cross-network constraints is designed, which could bridge inde-
pendent EMO pruning sub-tasks, allowing them to collaborate
better and improving the overall performance of the pruned
network. Finally, a multiple sub-networks joint pruning method
based on EMO is proposed. This method combines the Pareto
Fronts from EMO pruning results on multiple sub-networks
through global performance impairment ranking to design a
joint pruning scheme. The rich experiments on CIFAR-10/100
and ImageNet-100/1k are conducted. The proposed algorithm
achieves a comparable performance with the state-of-the-art
pruning methods.
Index Terms —Network pruning, multi-objective optimization,
image classification, evolutionary multi-objective.
I. I NTRODUCTION
WITH the development of the artificial intelligence
technology, deep neural networks (DNNs) have been
successfully utilized with many applications in areas, such
as SAR image processing [1], object tracking [2], [3], and
semantic segmentation [4], [5]. These successes are due to
This work was partially supported by the National Natural Science Founda-
tion of China under Grants Nos. 62176200 and 62271374, the Natural Science
Basic Research Program of Shaanxi under Grant Nos. 2022JC-45 and 2022JQ-
616, the 111 Project, the Guangdong Basic and Applied Basic Research
Foundation under Grant No. 2021A1515110686, the Research Project of
SongShan Laboratory under Grant YYJC052022004, and the Postdoctoral
Research Project Funding of Shaanxi under Grant 2023BSHTBZZ30.
Ronghua Shang, Songling Zhu, Yinan Wu, Weitong Zhang, Licheng
Jiao are with the Key Laboratory of Intelligent Perception and Im-
age Understanding of Ministry of Education, School of Artificial Intelli-
gence, Xidian University, Xi’an, Shaanxi Province 710071, China (e-mail:
rhshang@mail.xidian.edu.cn, slzhu@stu.xidian.edu.cn, ynwu25@stu.xidian.
edu.cn, wtzhang 1@xidian.edu.cn, lchjiao@mail.xidian.edu.cn). Songhua Xu
is with the Department of Health Management & Institute of Medical Artificial
Intelligence, The Second Affiliated Hospital of Xi’an Jiaotong University,
Xi’an, China. (e-mail: songhuaxu@mail.xjtu.edu.cn).the increasing ability of feature representation and learning.
However, as the performance grows, so do their storage and
computational burden. For example, AlexNet has 8 layers
of neural networks and 714M floating point operations [6],
GoogLeNet has 22 layers of neural networks and 1.5G floating
point operations [7], while VGG16 has 16 layers of neural
networks and 15.5G floating point operations [8]. They are
computationally expensive, especially for embedded devices
and mobile terminals, which have difficulty obtaining adequate
computing resources [9]. To address this problem, various neu-
ral network compression methods have been proposed, such
as knowledge distillation [10], [11], network pruning [12],
[13], and model quantization [14], [15]. Among them, network
pruning has attracted extensive attention from researchers due
to its excellent compression performance [16].
Existing pruning algorithms fall into two major categories.
The first is unstructured pruning, which obtains a compressed
neural network structure by discovering and pruning unimpor-
tant weights. Han et al. [9] considered that the weights below a
certain threshold are unimportant and can be pruned. Guo et al.
[17] designed a pruning algorithm with the dynamic method,
which enables the restoration of the connections when the
pruned weight is found to be significant. Unstructured pruning
performs well, but it usually demands special hardware for ac-
celeration [18]. The other is structured pruning, which prunes
network layers or filters instead of the network weights. In
contrast to unstructured pruning, the pruned network maintains
the conventional convolutional kernel structure and can be
accelerated for training and inference using standard deep-
learning libraries. He et al. [19] developed a soft filter pruning,
enabling these pruned structures to be updated during the
following training. Ayinde et al. [20] identified redundant
network feature structures by the relative cosine distance. Yu
et al. [21] performed pruning by the importance measured for
each neuron in the final response layer. He et al. [22] used the
geometric median to find the most replaceable filter. Lin et al.
[23] designed sparse structures by generating adversarial learn-
ing. Lin et al. [24] found that lower-rank features contained
less important information and had less impact on the network.
He et al. [25] designed a progressively increasing compression
rate to gradually concentrate the information learned from the
dataset into the remaining filters. Zhang et al. [26] pruned from
the frequency domain. Chen et al. [27] performed pruning
by the conditional accuracy change of each channel under
channel-wise gate control. He et al. [28] devised a learnable
and optimizable method to choose suitable pruning criteria for
different network layers. Li et al. [29] proposed a filter-basedarXiv:2303.16212v2  [cs.LG]  30 Dec 2023

--- PAGE 2 ---
2
pruning algorithm that determines the importance of a filter to
the network by its norm. However, the relationship between the
different structures in a neural network is very complex [30],
and the absence of any part of the network structure can impact
the performance of the entire network. Therefore, whether
structured pruning or unstructured pruning, these statistical
information-based measures of network redundancy may not
reflect the network performance after pruning accurately [31].
The evolutionary algorithm is a bio-inspired optimization al-
gorithm based on individual fitness that can accurately measure
the solution’s performance and solve complex optimization
tasks [32]. Its powerful optimization capabilities have attracted
attention in different fields. Shang et al. [33] designed a
complex network architecture search algorithm with a genetic
algorithm. Stodola et al. solved multi-depot vehicle routing
problems with an ant colony algorithm [34]. With the help
of the PSO algorithm, Huang et al. [35] designed a compact
network structure search algorithm. In addition, there have
been several successful attempts to use evolutionary algorithms
to optimize complex pruning problems on neural networks.
Zhou et al. [36] proposed an evolutionary multi-objective
(EMO) neural network compression method ECDNN, which
finds suitable pruned network structures for biomedical image
segmentation. Zhou et al. [37] proposed a knee-point guided
evolutionary multi-objective algorithm (KGEA), utilizing an
evolutionary multi-objective algorithm to find a pruning struc-
ture, which could make a trade-off between the parameter scale
and pruning performance. However, the pruning space of deep
neural networks is very complex, making their optimization by
evolutionary multi-objective algorithms extremely challeng-
ing. Zhou et al. [38] designed a network block-based multi-
objective network pruning algorithm, which prunes the net-
work block containing multiple layers instead of the network
layers. Although this approach reduces the pruning space of
complex networks to some extent, the optimization space still
remains challenging. The network block-based pruning cannot
optimize the redundancy of the filters within the block, which
constrains the algorithm’s performance. In addition, pruned
networks are intensive in computation and storage. Their
training and performance verification consume a large num-
ber of computational resources. Therefore, to better exploit
the performance of evolutionary multi-objective algorithms,
the optimization space and the resource consumption of the
network pruning task should be reduced.
Divide-and-conquer [39] is an effective way for complex
tasks, which decomposes a complex task into several simpler
sub-tasks, thus reducing the complexity of the whole task. This
approach has been used in a variety of research areas. Gidiotis
et al. [40] decomposed the difficult summarization task of the
whole document into simpler sub-tasks of several small parts,
improving the summarization performance. Xiong et al. [41]
found that the difficulty of visual counting increases with the
object’s density, and reducing the density in the recognition
region by the divide and conquer method can improve the
performance of object counting. Compared to the complex
optimization task, algorithms focusing on simple sub-tasks
perform better. Therefore, the divide-and-conquer approach
may be suitable for the complex multi-objective networkstructure pruning problem. However, the network is an entire
one made up of multiple, closely interconnected parts, and
the change in any part has a non-negligible effect on the
entire. If a sub-network is optimized and trained separately, it
may not collaborate well with the other sub-network from the
same network, affecting the overall performance. In addition,
it is an open question of how to design a complete pruning
scheme using these multi-objective optimization results from
multiple sub-networks optimized independently. Therefore, it
is impractical to apply the idea of divide-and-conquer directly
to the pruning task on the complex network structure.
Inspired by the aforementioned questions, this paper pro-
poses a multi-objective complex network pruning framework
based on divide-and-conquer and global performance impair-
ment ranking (EMO-DIR), which aims to reduce the optimiza-
tion space and the resource-consuming of pruning complex
networks while making independently optimized sub-network
pruning tasks cooperate well to achieve better overall perfor-
mance. Firstly, a divide-and-conquer EMO network pruning
method is proposed, which decomposes the complex multi-
objective pruning task on the complete network into the sim-
ple pruning task on multiple sub-networks. The optimization
complexity of the complete network is the product of the
complexities of the several sub-networks. In contrast, the
total optimization complexity of multiple sub-networks is the
sum of their complexities. Therefore, our method is compu-
tationally efficient. In addition, the sub-networks have fewer
parameters and converge faster than the complete network
structure. Thus, their training consumes fewer computation
resources. Secondly, a sub-network training method based on
cross-network constraints is designed to improve the collabo-
ration among sub-networks optimized independently. Different
parts of the network process different features, and the output
features from the previous sub-network are used as input
features for the following one. The proposed sub-network
training method ensures that the next sub-network can process
the features generated by the previous one well by constraining
the output features from the previous one and the input features
of the following one, making the independently pruned sub-
networks collaborate well and improve the overall performance
of the pruned network. Finally, this paper proposes a multiple
sub-networks joint pruning method based on EMO, which
calculates a global performance impairment index based on the
Pareto Front obtained from multiple sub-network optimization
tasks. This index reflect the impact of the sub-network pruning
scheme on the whole network’s performance, thus helping
the algorithm design a joint pruning scheme. Extensive exten-
sive experiments are performed on the CIFAR10, CIFAR100,
ImageNet-100 and ImageNet-1k datasets, and the experimental
results demonstrate the effectiveness and efficiency of the
proposed algorithm. The contributions are as follows.
•A divide-and-conquer EMO network pruning method is
proposed. It decomposes the multi-objective pruning task
on a complex network into simple pruning tasks on mul-
tiple sub-networks. This method reduces the optimization
difficulty of the multi-objective pruning algorithm and the
resource consumption of validating the pruning structures

--- PAGE 3 ---
3
during the evolutionary process.
•A sub-network training method based on cross-network
constraints is designed. It constrains the output features
of the previous sub-network and the input features of
the next one, so the output features of the previous sub-
network can be processed by the next one, thus improving
the overall network performance.
•A multiple sub-networks joint pruning method based on
EMO is proposed. It calculates the global performance
impairment index based on the non-dominated solutions
from the evolutionary multi-objective pruning algorithm
on each sub-network. The global performance impairment
index reflects the impact of different pruning schemes of
the sub-networks on the whole network’s performance.
Thus, this index can help the algorithm design a joint
pruning scheme.
In the following, this paper first presents the details of the
proposed algorithm; then, it describes the related experimental
setup, experimental results, and analyses; finally, the conclu-
sion and future work are presented.
II. T HE PROPOSED ALGORITHM
Evolutionary multi-objectives based network pruning algo-
rithms drive a trade-off between the performance and resource
cost of the network to generate a better network pruning
structure. However, the population-based nature makes these
algorithms suffer from the complex optimization space and
the highly resource-consuming individual validation process.
To this end, this paper proposes a multi-objective complex
network pruning framework based on divide-and-conquer and
global performance impairment ranking (EMO-DIR). It de-
composes the complex network pruning task into multiple sim-
ple sub-network pruning tasks, thereby narrowing the pruning
optimization space of the EMO algorithm and the resource
consumption of the individual performance validation. Fig. 1
describes the overall structure of the EMO-DIR.Fig. 1 shows that the algorithm achieves complex EMO
pruning on the original network by several multi-objective
pruning on sub-networks. First, this paper designs a divide-
and-conquer EMO network pruning method, which performs
independent EMO pruning on each sub-network to finish the
whole pruning. It considers the sub-network parameter number
and prediction error as two optimization objects. During the
training of the sub-networks, to improve the collaboration
among the different sub-networks, this paper proposes a sub-
networks training method based on cross-network constraints,
which constrains the features between adjacent sub-networks
and helps the next sub-network to process the output features
from the previous one. Finally, to generate a whole pruning
scheme with the non-dominated solutions produced by the
EMO pruning on these sub-networks, we design a multiple
sub-networks joint pruning method based on EMO. With the
help of the global performance impairment ranking, all the
sub-network optimization results are combined to produce a
complete pruning scheme.
A. Encoding and Decoding of Network Structures
The evolutionary algorithm cannot directly optimize the
network structure but needs to transform the network into
structure coding. The coding optimized by the evolutionary
algorithm must also be transformed into pruned network
structures for training and inference. Three network struc-
tures are involved in the experiments: BasicBlock, Bottleneck
residual structures, and VGG Block. Fig. 2 describes the
corresponding structure codings of the original and the pruned.
These codings are marked by “[ ]”, where the output channel
number is used as the coding content of the convolutional
layer. “ Cin:Cout#3×3” means that the input channel number
from the convolution kernel is Cin, the output number is Cout,
and the size of the convolution kernel is 3×3.
Sub-netSub-netSub-net
PEParametersErrEvoEvoEvoEvo
Performance ImpairedRankingOriginal NetworkDivide-and-conquerEMO Network Pruning
Sub-netSub-netSub-netPruned NetworkFeatureFeature
Feature
Sub-networks  Training Based on Cross-networkConstraintsMultiple  Sub-networksJoint Pruning Based on EMO
Fig. 1. The overall structure of the EMO-DIR.

--- PAGE 4 ---
4
(a) BasicBlock [ Cout] (b) Pruned BasicBlock [ C1]+Cin:Cout#3×3
Cout:Cout#3×3Cin:Cout#1×1
+Cin:Cout#3×3
Cout:Cout#3×3Cin:Cout#1×1
+Cin:C1#3×3
C1:Cout#3×3Cin:Cout#1×1
+Cin:C1#3×3
C1:Cout#3×3Cin:Cout#1×1
(d) Pruned Bottleneck [ C1, C2] (c) Bottleneck [ Cout, Cout]+Cin:Cout#1×1
Cout:Cout#3×3
Cout:Cout#1×1Cin:Cout#1×1
+Cin:Cout#1×1
Cout:Cout#3×3
Cout:Cout#1×1Cin:Cout#1×1
+Cin:C1#1×1
C1:C2#3×3
C2:Cout#1×1Cin:Cout#1×1
+Cin:C1#1×1
C1:C2#3×3
C2:Cout#1×1Cin:Cout#1×1
(f) Pruned VBlock [ C1, C2] (e) VBlock [ Cout, Cout]Batch Normalization ReLU Batch Normalization ReLU
Cin:Cout#1×1
Cout:Cout#3×3
Cout:Cout#1×1Cin:Cout#1×1
Cout:Cout#3×3
Cout:Cout#1×1Cin:C1#1×1
C1:C2#3×3
C2:Cout#1×1Cin:C1#1×1
C1:C2#3×3
C2:Cout#1×1
Fig. 2. The codings of the original network structures and their pruned structures (BasicBlock, Bottleneck residual structures and VGG block VBlock).
As shown in Fig. 2, for residual structures, the output
channel number in the last layer of the residual block remains
unchanged during pruning. For VGG structures, we consider
all network layers in the sub-network as one block and keep
the output channel of the last one unchanged. Fig. 2 (c) and
(d) use three layers for clear demonstration, and one block
structure can contain more. Because this method keeps the
shape of the input and output features unchanged, it does
not require any additional adjustment when connecting these
pruned sub-network structures into a complete network, thus
simplifying the pruning process. Only the output channel
number except the last layer is encoded when encoding these
network structures. For example, in Fig. 2(b), the pruning
structure for the BasicBlock with two convolutional layers
is encoded as [C1]. In Fig. 2(d), the pruning structure for
the Bottleneck with three convolutional layers is encoded
as[C1, C2]. The coding is a sequential stacking of inter-
nal network structures. For example, for a residual sub-
network coding [[C11, C12],[C21, C22],···,[Cn1, Cn2]], the
internal structure is a sequentially connected structure of
three BasicBlock residual structures encoded as [C11, C12],
[C21, C22]and[Cn1, Cn2]. For a VGG sub-network coding
[C1, C2,···, Cn], the internal structure is n+1 network layers
connected sequentially.
B. The Divide-and-conquer EMO Network Pruning Method
The divide-and-conquer EMO network pruning method
aims to solve the EMO pruning problem for complex network
structures using the divide-and-conquer idea. For the conve-
nience of description, this paper uses Equation (1) to define
the ordered set of complete networks.
Netall={l1, l2,···, lN} (1)
where Nmeans the total number of network layers, and each
network consists of multiple ordered network layers.
Each neural network layer performs simple feature trans-
formation tasks, while a group of neural network layers can
perform a more complex feature processing task. Thus, as
shown in Equation (2), a complete network can be considered
a set of multiple feature-processing sub-networks.Xout=F(Netall, Xin)
=F(lN, F(lN−1,···F(l1, Xin)))
=F(SubNet M, F(SubNet M−1,
···F(SubNet 1, Xin)))(2)
where F(Net, X )is used to describe the feature process-
ing process of the network with the ordered set Net and
the features to be processed X.Xoutis the network’s fi-
nal output. Equation (2) shows that the original network
structure Netallcan be divided into several sub-networks
{SubNet 1, SubNet 2,···, SubNet M}, and each sub-network
structure completes a part of the feature processing task. M
denotes the number of sub-network structures, i.e., the number
of sub-tasks into which the whole feature processing task is
divided. The set of sub-networks consists of several ordered
network layers that do not overlap, as shown in Equation (3).
SubNet 1∪SubNet 2∪ ··· ∪ SubNet N=Netall
SubNet 1∩SubNet 2∩ ··· ∩ SubNet N=∅(3)
From Equation (3), the complete network Netallcomprises
several sub-networks. From Equation (2), the feature process-
ing function of the complete network can also be implemented
by multiple sub-networks SubNet i. Thus, a pruning task on
a complete network can be decomposed into multiple pruning
tasks on sub-networks. Equation (4) shows the multi-objective
pruning task on the complete network.


arg min
Net′
all(P(Net′
all), E(Net′
all, X, Y ))
s.t. P (li′)≤P(li),∀li∈Netall,∀li′∈Net′
all(4)
The optimization objectives of the multi-objective pruning
task are the parameter number P(Net′
all)and the prediction
error E(Net′
all, X, Y ), where XandYmean the datasets
and labels to be processed. The optimization algorithm could
find the pruned network structure Net′
allby pruning the
original network Netall.Net′
allperforms well on these two
optimization objectives. The pruning space of the original
network Netallis very large. For a neural network with N
network layers and the i-th network layer has kiconvolutional
kernels, the size of its pruning optimization space O(Netall)
is shown in Equation (5).

--- PAGE 5 ---
5
O(Netall) =NY
i=1O(ki) (5)
If the network with Nlayers is divided into Msub-
networks, the multi-objective pruning task represented by
Equation (4) can be divided into pruning tasks of the Msub-
networks shown in Equation (6).


arg min
Net′
i 
P(Net′
i), E 
Net′
i, X, Y
s.t. P (li′)≤P(li),∀li∈Neti,∀li′∈Net′
ii∈[1, M]
(6)
The size of the pruning space O′(Netall)is shown in
Equation (7) and is significantly smaller than the pruning space
O(Netall)from the original network.
O′(Netall) =MX
j=1O(Netj)
=MX
j=1NjY
i=1O 
ki+N1+N2+···Nj−1
<<NY
i=1O(ki) =O(Netall)(7)
where Njdenotes the number of network layers in the jth
sub-network. Therefore, dividing the original complex network
into several simpler sub-networks significantly reduces the
optimization space of the evolutionary multi-objective network
pruning algorithm, thus reducing the optimization difficulty.
Furthermore, Equation (2) describes that the feature processing
of the whole network can be regarded as a set of ordered
sub-network processing. Therefore, if the pruned sub-network
retains the feature processing capability of the original sub-
network, or if its feature processing capability is only slightly
impaired, the impact of pruning on the original network will
also be minor.
Inspired by this, we design a divide-and-conquer EMO
network pruning method. The major structure is shown in Fig.
3.
Original
Network
Pruned
NetworkSub-Net-2
Pruned
Sub-Net-2Sub-Net-1
Pruned
Sub-Net-1Sub-Net-4
Pruned
Sub-Net-4Sub-Net-3
Pruned
Sub-Net-3
Dividing the sub -network
 Dividing the sub -network
Evo
Pruning
Evo
Pruning
Evo
Pruning
Evo
Pruning
Fig. 3. The divide-and-conquer EMO network pruning method.
As shown in Fig. 3, this network pruning method first
divides the whole neural network, which will be pruned, into
multiple sub-networks that do not overlap. Each sub-networkconsists of multiple network layers with simple feature pro-
cessing capability. Then, this method performs an indepen-
dent evolutionary multi-objective network pruning for each
sub-network. The optimization objectives of the evolutionary
multi-objectives optimization are the parameter number and
the feature processing capability of the sub-network. The EMO
algorithm can balance the parameter number and performance
of the sub-network to obtain a more significant sub-network
compression rate with a minor performance loss. Finally,
the algorithm constructs a final pruned network based on
the evolutionary multi-objective pruning structure obtained on
each sub-network.
The method transforms evolutionary multi-objective pruning
from the complete neural network to multiple sub-networks.
However, without other help, this method does not accomplish
the neural network pruning task well. Firstly, the feature
processing capabilities of the sub-networks may change during
the independent optimization process. These changes may
result in the features they produce not being correctly un-
derstood by the following sub-network, thus impairing the
network’s overall performance. Secondly, the evolutionary
multi-objective pruning in each sub-network is performed
independently. The resulting optimization results can only be
used to set the pruning scheme for that sub-network rather
than for the whole network. To tackle these two problems
above, we introduce a sub-network training method based on
cross-network constraints and a multiple sub-networks joint
pruning method based on EMO, which would be detailed in
the following two subsections.
C. The Sub-network Training Method Based on Cross-network
Constraints
Multiple sub-networks trained independently destroy the
collaborative ability among the sub-networks from the original
network, resulting in the next sub-network not being able to
process the features generated by the previous one well. This
paper proposes a sub-network training method based on cross-
network constraints, which improves the collaboration among
sub-networks by constraining the previous sub-network output
features and the following one’s input features. With these
constraints, the next one can process the features generated
by the previous one well.
The constraint is an element-level feature constraint that is
used to shrink the element-level distance between the feature
generated by the previous sub-network and the feature that the
next sub-network can process. Since the input feature from
the pruned network SubNet′
i+1is the output feature from
the original network SubNet i, shrinking the distance between
the output features of SubNet′
iandSubNet ican shrink the
distance between the input features of SubNet′
i+1and the
output features of SubNet′
i. As shown in Equation (8), this
paper uses the L2norm to measure the distance between them.
Loss FC(SubNet i, SubNet′
i) =
||F(SubNet 1+···+SubNet i, X)−F(SubNet′
i,
F(SubNet 1+···+SubNet i−1, X))||2(8)

--- PAGE 6 ---
6
Sub-Net-2 Sub-Net-1 Sub-Net-4 Sub-Net-3
CE CE CELabelFD-2 FD-3
FD-4
FD-1FD-1
Back PropagationBack PropagationForward Propagation Forward PropagationFD-nFD-n Feature Detector FD-n Feature DetectorCE Cross -entropy Loss CE Cross -entropy LossFeature Constraint FCFC Feature Constraint FC
Back PropagationForward PropagationFD-n Feature DetectorCE Cross -entropy LossFeature Constraint FCTrained completed network
(a). The training process of feature detectors.
Label
CE CE CE CEFD-2 FD-3 FD-4FC FC FC FCFCSub-Net-1 Sub-Net-1 Sub-Net-2 Sub-Net-2 Sub-Net-3 Sub-Net-3 Sub-Net-4 Sub-Net-4
Pruned
Sub-Net-3Pruned
Sub-Net-4Pruned
Sub-Net-2Pruned
Sub-Net-1
FD-1FD-1Inheriting   WeightsInheriting   Weights Inheriting   WeightsInheriting   Weights Inheriting   WeightsInheriting   Weights Inheriting   WeightsInheriting   Weights
No Update of Weights
(b). The training process of multiple sub-networks under feature constraints.
Fig. 4. The sub-network training method based on cross-network constraints.
The first feature is derived from the output features of the
original network at SubNet i, whose input is the dataset X.
The second feature is derived from the output feature of the
pruned network SubNet′
i, whose input feature is from the
original sub-network SubNet i−1.
In addition, the feature detector trained with the original
network also provides some feature constraints, which are
used to encourage the pruned sub-network to perform similar
feature processing to the original network. The sub-network
does not give equal importance to every element in the feature
from the previous sub-network. In features, the complex
relationship among elements is also important. Therefore,
this paper uses a feature detector to provide an additional
feature constraint on the relationship among feature elements.
The constraint is implemented through a pre-trained feature
detector, which finds specific elemental relationships in the
features. In addition, it can provide performance metrics for
sub-network. Fig. 4 describes the proposed method.
Fig. 4(a) shows the training process of the feature detectors,
and the trained feature detector can identify the element
relationships in the features and find the change in the fea-
ture processing ability of the sub-network. The input of the
feature detector is the intermediate features generated by the
sub-network, and the output is the prediction classification.
This paper uses the same residual structure to construct
the feature detectors. Because the features’ spatial resolution
and processing difficulty vary, feature detectors on different
network locations are different. Fig. 5 describes the feature
detectors used on the network divided into four sub-networks.
The feature detectors at different locations contain different
numbers of residual blocks. The closer to the output layer
from the network, the smaller the number of residual blocks.These residual blocks have the same structure, and they all
reduce the spatial resolution of the input features by half. Each
feature detector is followed by a pooling and fully connected
layer with the same structure as the one used in the original
network. In addition, during the training process, this paper
only updates the feature detectors. So, it converges faster and
does not impose much computational burden.
ResBlock@2ResBlock@2
ResBlock@2ResBlock@2
ResBlock@2ResBlock@2
PoolLayer
FullLayerResBlock@2
ResBlock@2
ResBlock@2
PoolLayer
FullLayer
(a). FD -1ResBlock@2
ResBlock@2
ResBlock@2
PoolLayer
FullLayer
(a). FD -1ResBlock@2ResBlock@2
ResBlock@2ResBlock@2
PoolLayer
FullLayerResBlock@2
ResBlock@2
PoolLayer
FullLayer
(b). FD -2ResBlock@2
ResBlock@2
PoolLayer
FullLayer
(b). FD -2PoolLayer
FullLayer
(d). FD -4PoolLayer
FullLayer
(d). FD -4ResBlock@2ResBlock@2
PoolLayer
FullLayer
(c). FD -3ResBlock@2
PoolLayer
FullLayer
(c). FD -3
Fig. 5. The structures of feature detectors located at different positions.
When the training processes of the feature detectors are
finished, the training of multiple sub-networks can be fol-
lowed. This processing is shown in Fig. 4(b). First, the trained
feature detectors are connected to the corresponding sub-
networks, and their weights are fixed so that the feature
detectors do not change during the training process and get
stable detection results. In addition, the pruned sub-networks
randomly inherit some weights from the trained completed
network to accelerate model convergence. Then, the data is
fed into the original network to generate input and output
features for each pruned sub-network. Finally, the pruned sub-
network completes its training process. During the training of
the neural network, loading the training data from the disk

--- PAGE 7 ---
7
is very time-consuming. To save the training time of the sub-
networks, this paper generates input and output features for all
the sub-networks in one data loading process, then uses these
features to complete the forward and backward propagation of
all the sub-networks.
The loss function for each sub-network training consists of
two components, as shown in Equation (9). One part is from
the element value from the features, which is measured using
theL2norm; the other part is from the relationship among the
feature elements, which is measured using cross-entropy.
Loss i=1
2∗(||F′
i−Fi||2+Loss CE(Ai, Y)) (9)
The Equation (9) describes the total loss of the ith sub-
network training. FiandF′
idenote the output features pro-
duced by the ith sub-network in the original and pruned
networks. Aidenotes the output result of the ith feature
detector, and Ydenotes the ground truth label. Loss CE(·)
denotes the cross-entropy loss function.
D. The Multiple Sub-networks Joint Pruning Method Based
on EMO
Multiple sub-networks divided from the original neural net-
work can be independently pruned with the EMO optimization
algorithm. However, the final pruned neural network structure
cannot be directly constructed based on the multi-objective
network pruning results on these sub-networks. To this end,
this paper proposes a multiple sub-networks joint pruning
method based on EMO, which designs a joint pruning scheme
based on the multi-objective pruning results on multiple sub-
networks. Fig. 6 illustrates the structure.
Original
Network
Evolutionay
Multi -obj
Pruning
Global
Performance
Impaired
Ranking
Pruned
Network
Sub-Net-1
Evo
Pruned
Sub-Net-2
Sub-Net-1
Evo
Pruned
Sub-Net-1
Sub-Net-4
Evo
Pruned
Sub-Net-4
Sub-Net-3
Evo
Pruned
Sub-Net-30 5 10 15 20 25 30 35 40 45 50-6-4-20246
-50050
Block -1 Block -1
Block -2 Block -2Block -3 Block -3PR (%)
GPII
(ln)
Block -4
Fig. 6. The multiple sub-networks joint pruning method based on EMO.
Firstly, the algorithm finds the Pareto Front consisting of
several non-dominated solutions [42] from the EMO pruning.
These non-dominated solutions perform well in all optimized
objectives. The evolutionary multi-objective algorithm did not
find any other solution that outperformed them on all opti-
mization objective functions during the optimization process.
Then, based on the solutions from the Pareto Front, this paper
develops a global performance impairment ranking (GPIR)method that describes what pruning scheme should be adopted
for which sub-network has the most negligible expected impact
on the network performance.
To obtain GPIR, as shown in Equation (10), the changes
in the parameter number and prediction error relative to the
unpruned network are first calculated for each solution.


∆Pi,j=Pi,j−Pi,baseline
Pi,baseline
∆Ei,j=Ei,j−Ei,baseline
Ei,baseline(10)
where ∆Pi,jand∆Ei,jrepresent the change in parameter
number and the one in prediction error of the jth non-
dominated solution on the ith sub-network. Pi,baseline and
Ei,baseline are parameter number and prediction error of the
unpruned structure on the ith sub-network. Next, the global
performance impairment index (GPII) can be calculated from
∆Pi,jand∆Ei,j, as shown in Equation (11).
Ii,j=∆Pi,j−min(∆Pi)
∆Ei,j−min(∆Ei) + 0.001(11)
The GPII describes the increase in the parameter number
caused by per unit increase in error. The smaller the per-
formance impairment index, the better the pruning strategy,
and vice versa. It is a measure of the network pruning cost
and can also be used to compare the multi-objective pruning
results among different sub-networks. This paper uses the
performance impairment index to rank the global performance
impairment caused by the pruning scheme on different sub-
networks to design the joint pruning scheme.
The GPIR between the four sub-networks is shown in Fig.
6, and the corresponding network pruning rate (PR) can be
obtained from the ranking result. The pruning rate is also
called the compression rate, and this paper calls it the pruning
rate for convenience. Fig. 6 indicates that the pruning rate
increases as the performance impairment index increases. This
also demonstrates the flexibility of the proposed algorithm in
choosing the pruning rate. Once the multi-objective pruning
tasks are completed on all sub-networks, multiple pruning rate
design schemes can be obtained. The user can flexibly change
the pruning scheme according to the actual requirements
without additional repeating the pruning algorithm. For the
given pruning rate, the user can find the pruning scheme on
each sub-network based on the GPIR, thus determining the
global pruning scheme on the original network.
A more detailed procedure of the multiple sub-networks
joint pruning method based on evolutionary multi-objective is
shown in Algorithm 1. First, this method performs independent
evolutionary multi-objective pruning on each sub-network and
obtains a collection of non-dominated solutions on each sub-
network pruning task. These non-dominated solutions from all
sub-networks are collected to form the non-dominated set Pall.
Then, the algorithm uses the method shown in Equation (11)
to calculate the GPII for all solutions in the set Pall. Next,
it performs a global performance impairment ranking from
smallest to largest for all solutions in Pallbased on GPII.
After that, the algorithm obtains the complete pruning scheme
Sallbased on the Psortand the pre-set pruning rate P.

--- PAGE 8 ---
8
Algorithm 1: The multiple sub-networks joint pruning
method based on EMO.
Input: Sub-netwoks Net 1, Net 2,···, Net M. Unpruned
network Netall. Pruning rate P.
Output: The complete pruning scheme Sall.
1Perform evolutionary multi-objective pruning on all
sub-network Net 1, Net 2,···, Net Mindependently;
2Pall←get the populations on the Pareto Front of every
sub-network optimization;
3I←Calculate the GPII of every solution on Pallwith the
Equation (11);
4Psort←Rank the solutions in Pallaccording to Ifrom
smallest to largest (GPIR);
5S1, S2, ..., S M←Initialize all sub-network pruning schemes
with the unpruned network Netall;
6while Pallis not∅do
7 Pselect←find the population with smallest GPII in
Psort;
8 Neti←Find the sub-network to which the Pselect
belongs;
9 Si←Set the pruning scheme used by Pselect forNeti;
10 Build complete pruning network structure Swith
S1, S2,···, SM;
11 Pcur←Calculate the pruning rate on the parameter
number of the Netp;
12 ifPcur≥Pthen
13 Return the complete pruning scheme Sall.
14 end
15 Pall=Pall−Pselect ;
16end
17Return the complete pruning scheme Sall.
It is an iterative process from GPIR to a complete prun-
ing scheme. The algorithm first sets the pruning schemes
on all sub-networks to the unpruned structure. The pruning
schemes are then updated according to the structure selected
on the GPIR from smallest to largest. This allows the pruning
structure of the complete network to be continuously updated
based on the GPIR. The new complete pruning scheme with
a bigger pruning rate is obtained from a new pruned sub-
network structure taken out of the ranking. The final pruned
network structure is obtained according to a pre-set pruning
rate. In addition, if the user needs a new pruning scheme with
a different pruning rate, he only needs to perform the steps
from the global performance impairment ranking to the final
complete network pruning scheme from scratch instead of the
whole algorithm.
III. E XPERIMENTAL SETTINGS AND RESULTS ANALYSIS
In this section, the paper describes the experimental settings
and the analysis. First, the datasets used in this paper and algo-
rithm performance evaluation criteria are presented. Then, the
experimental parameter settings associated with the proposed
algorithm are presented. Then, these experimental results and
analysis are provided in detail. Finally, extensive performance
analysis experiments are conducted for understanding the
proposed algorithm EMO-DIR better.
A. Benchmark Datasets and Performance Evaluation Criteria
Four image classification datasets are used in this paper.
They are CIFAR10 [43], CIFAR100 [43], and ImageNet-100[44], and ImageNet-1K [45]. CIFAR10 and CIFAR100 contain
50,000 training and 10,000 testing samples with 32×32
color images. The CIFAR10 dataset contains 10 categories of
samples, while the CIFAR100 dataset contains 100 categories
of samples. The ImageNet-100/1K dataset contains 100/1000
categories of color images, and these images vary in size. This
dataset contains 127K/1.28M training samples and 5K/50K
testing samples.
For conveniently comparing the performance of the pro-
posed algorithm with other network pruning algorithms, three
performance evaluation criteria are used, namely the network’s
prediction error on the testing set, the pruning rate of floating
point operations, and the pruning rate of the parameter number.
The pruning rate for floating-point operations and the one for
parameter number are given in equations (12) and (13).
PFlops = 1−Flops (Model pruned )
Flops (Model unpruned )(12)
PParameters = 1−Param (Model pruned )
Param (Model unpruned )(13)
where Flops (·)denotes the calculation function for the
amount of floating-point operations and Param (·)denotes
the one for the parameter number. Model unpruned denotes
the unpruned network model and Model pruned denotes the
pruned network model.
B. Experimental Parameter Settings
This paper uses two kinds of parameters. One is used for the
EMO algorithm. The evolutionary algorithm used is NSGA-II
[46]. The crossover and mutation operators are the simulated
binary crossover and the polynomial mutation operator. More
detailed settings for this kind of parameter are shown in Table
I. The experiments performed in this paper are carried out
on the ResNet [47] and VGG [48] networks, which involve
four network structures, ResNet56, ResNet110, ResNet50,
and VGG16. To simplify the division of sub-networks, the
network layers dealing with the same spatial resolution fea-
tures are divided into the same sub-network. Considering that
the number of sub-network structures divided into ResNet56
and ResNet110 networks differs from that of ResNet50 and
VGG16, their parameter settings are also different. Dividing
more sub-networks can reduce the algorithm’s optimization
complexity and reach a larger combinatorial search space with
the same parameter settings. Therefore, the experiments with
4 sub-networks set smaller population sizes and iterations than
the ones with 3 sub-networks.
TABLE I
PARAMETER SETTINGS RELATED TO EVOLUTIONARY ALGORITHM .
Network Structure ResNet56 ResNet110 ResNet50 VGG16
Sub-network Number 3 4
Population Size 40 20
New Offspring Number 20 10
Iterations 7 5
Combinatorial Space 5,832,000 24,010,000

--- PAGE 9 ---
9
The other is used for the training of the neural network. This
paper uses different parameter settings for different datasets,
and the detailed settings are shown in Table II.
TABLE II
PARAMETER SETTINGS RELATED TO NETWORK TRAINING .
DataSet CIFAR10 CIFAR100 ImageNet-100
full-net Epochs 300 240 100
sub-net Epochs 100 100 50
Optimizer SGD
Initial LR 0.1 0.05
Batch Size 64
Weight decay 0.0005 0.0001
LR scheduler Cosine MStep [150,180,210] MStep [30,60,90]
The sub-network contains fewer parameters than the full-
network structure, and thus it converges faster. In experiments,
it converges well in just one-half or even one-third of the
training epochs. In addition, all experiments are implemented
in the Pytorch [49] deep learning library.
C. Experimental Results and Analysis on The Benchmark
Datasets
In order to verify the performance of the EMO-DIR on
different datasets, performance tests are conducted on four
datasets in this paper. The following part of this subsection will
detail the experimental results and the corresponding analysis
of these datasets.
1) Experimental Results and Analysis on the CIFAR10
Dataset:
The performance of the EMO-DIR was tested on a medium-
sized image classification dataset CIFAR10. The neural net-
works used in the experiments are the ResNet56, ResNet110
and VGG16 networks. The experimental results are shown
in Tables III, IV and V, which show the test error (Err),
the number of floating point operations (FLOPs), the pruning
rate of floating point operations (PR-F), the parameter number
(Param), and the pruning rate of the parameter number (PR-P)
on the pruned neural networks obtained from different pruning
algorithms.
TABLE III
PRUNING RESULTS OF THE EMO-DIR AND THE COMPARISON
ALGORITHM ON CIFAR10 FOR RESNET56.
Method Err (%) FLOPs PR-F (%) Param PR-P (%)
L1-Net [29] 6.94 90.9M 27.6 0.73M 14.1
CCP-AC [50] 6.58 59.2M 52.8 - -
SFR [19] 6.65 59.4M 52.7 - -
CD [20] 6.88 90.7M 27.9 0.65M 23.5
NISP [21] 6.95 70.5M 43.8 0.48M 43.5
FPGM [22] 6.51 59.4M 52.6 - -
GAL [23] 7.02 78.0M 37.6 0.75M 11.8
HRank [24] 6.83 62.7M 50 0.49M 42.4
ASFP [25] 6.65 59.0M 52.6 - -
LRMF [26] 6.71 59.4M 52.6 - -
Niu et al. [31] 6.52 63.4M 49.5 0.47M 44.7
EMO-DIR 6.29 49.5M 60.6 0.37M 57.0
Table III depicts the pruning results of the EMO-DIR and
the comparison algorithm on the ResNet56. The first columnof the table presents the pruning algorithms used, and the
second column presents the prediction error of the pruned
network obtained by the corresponding algorithm. The third
and fourth columns present the pruned network’s floating
point operation number and the corresponding pruning rate.
The fifth and sixth columns show the parameter number
and the corresponding pruning rate of the pruned network.
The experimental results present that the EMO-DIR performs
better on this pruning task. The pruning algorithm proposed
by Niu et al. reduces 49.5% of the floating-point operation
number and 44.7% of the parameter number with an error of
6.52%. In contrast, the proposed algorithm reduced the pruning
rate of the floating-point operation number and the parameter
number by 60.6% and 57.0% with an error of 6.29%. This
indicates the effectiveness of the EMO-DIR.
TABLE IV
PRUNING RESULTS OF THE EMO-DIR AND THE COMPARISON
ALGORITHM ON CIFAR10 FOR RESNET110.
Method Err (%) FLOPs PR-F (%) Param PR-P (%)
L1-Net [29] 6.45 213M 15.8 1.68M 2.3
SFR [19] 6.14 150M 40.7 - -
CD [20] 6.73 154M 39.1 1.13M 34.3
NISP [21] 6.61 143M 43.5 0.98M 43.1
FPGM [22] 6.32 121M 52.2 - -
GAL [23] 7.45 130M 48.5 0.95M 44.8
HRank [24] 6.64 105.7M 58.2 0.70M 59.2
CAC [27] 6.46 123.5M 51.15 0.82M 52.31
ASFP [25] 6.63 121M 52.3 - -
LRMF [26] 6.39 94.0M 62.8 - -
Niu et al. [31] 6.22 126M 50.2 0.78M 54.7
EMO-DIR 6.04 72.2M 71.5 0.55M 68.0
Table IV shows the pruning performance of the proposed
algorithm and the comparison algorithm on the ResNet110,
which has the same structure as Table III. The ResNet110 has
more than twice the parameter and floating-point operation
numbers than the ResNet56, making this pruning task more
difficult. Comparing Table III with Table IV, we could find
that the pruned network obtained on the ResNet110 contains
a larger parameter scale and more floating-point operation
numbers under similar errors. For example, the ASFP obtained
pruning networks with an error of 6.65% and 6.63% on these
two networks, respectively, while the pruning network on
ResNet110 had twice the parameter number as the pruning
network on ResNet56. However, the proposed algorithm still
performs well for this pruning task. The state-of-the-art prun-
ing algorithm proposed by Niu et al. [31] achieves 50.2%
and 54.7% pruning rates for floating point operations and
parameters under an error of 6.22%. The proposed algorithm
achieves 71.5% and 68.0% pruning rates for floating point
operations and parameters with fewer error. This indicates
the effectiveness and efficiency of the EMO-DIR in complex
pruning tasks.
This paper also tests the pruning performance of the pro-
posed algorithm on the VGG network structure, which is
used to test the generalization performance of the proposed
algorithm on different network structures. The experimental
results are shown in Table V, which has the same structure as
Table III. The network structure used is VGG16.

--- PAGE 10 ---
10
TABLE V
PRUNING RESULTS OF THE EMO-DIR AND THE COMPARISON
ALGORITHM ON CIFAR10 FOR VGG16.
Method Err (%) FLOPs PR-F (%) Param PR-P (%)
L1-Net [29] 6.60 206M 34.2 5.4M 64.0
CD [20] 6.33 186M 40.5 3.23M 78.1
FPGM [22] 6.46 200M 35.9 - -
GAL [23] 9.22 172M 45.2 2.67M 82.2
Niu et al. [31] 6.27 138M 56.0 2.31M 84.6
EMO-DIR 6.24 96M 69.4 2.86M 80.6
From the experimental results, compared to the state-of-
the-art pruning algorithm proposed by Niu et al., the proposed
algorithm obtains a higher pruning rate of FLOPs with similar
error and parametric pruning. Their FLOPs is 138M, while the
proposed algorithm is 96M.
2) Experimental Results and Analysis on the CIFAR100
Dataset:
This paper also tests the EMO-DIR on the CIFAR100
dataset, which has the same training and testing sample
numbers as CIFAR10, while CIFAR100 has ten times more
categories than CIFAR10. So it is more challenging to classify
this dataset. This subsection conducts pruning experiments on
the ResNet56 and ResNet110, and Tables VI and VII describe
the pruning results of the EMO-DIR and compared algorithms.
TABLE VI
PRUNING RESULTS OF THE EMO-DIR AND THE COMPARISON
ALGORITHM ON CIFAR100 FOR RESNET56.
Method Err (%) FLOPs PR-F (%) Param PR-P (%)
LCCL [51] 31.63 76.3M 39.3 - -
SFP [19] 31.21 59.4M 52.6 - -
FPGM [22] 30.34 59.4M 52.6 - -
TAS [52] 27.75 61.2M 51.3 - -
LFPC [28] 29.17 60.8M 51.6 - -
CAC [27] 30.22 61.4M 51.11 0.46M 45.51
EMO-DIR 27.54 52.73M 58.07 0.39M 54.45
Table VI has the same structure as Table III. The experi-
mental results demonstrate that the EMO-DIR still performs
well on the CIFAR100 dataset. The state-of-the-art network
pruning algorithm TAS obtains a pruning rate of 51.3% for
the parameter number under an error of 27.75%. In contrast,
the proposed algorithm achieves an error of 27.62%, and its
pruning rate of floating-point operations is 6.47 points higher
than TAS. This indicates the effectiveness of the EMO-DIR
on the CIFAR100 dataset.
TABLE VII
PRUNING RESULTS OF THE EMO-DIR AND THE COMPARISON
ALGORITHM ON CIFAR100 FOR RESNET110.
Method Err (%) FLOPs PR-F (%) Param PR-P (%)
Niu et. al [31] 25.1 184M 27.5 1.29M 25.1
LCCL [51] 29.22 173M 31.3 - -
SFP [19] 28.72 121M 52.3 - -
FPGM [22] 27.45 121M 52.3 - -
TAS [52] 26.84 120M 52.6 - -
CAC [27] 28.19 123.5M 51.18 0.93M 45.77
EMO-DIR 24.96 108.6M 57.12 0.83M 52.09Table VII has the same structure as Table III. The experi-
mental results demonstrate that the EMO-DIR still performs
well on the pruning task of the complex ResNet110. For
the advanced pruning algorithm TAS, the proposed algorithm
obtained lower error with similar pruning rates of floating
point operations, and the error of the proposed algorithm
was 1.88 points lower than TAS. In addition, the proposed
algorithm obtains a higher pruning rate with similar error
compared to the algorithm proposed by Niu et al. Its pruning
rate of floating point operations and parameters reaches is
more than twice that of the algorithm proposed by Niu et al.
This indicates the effectiveness and efficiency of the EMO-
DIR.
3) Experimental Results and Analysis on the ImageNet-100
and ImageNet-1K Dataset:
This paper also conducts evolutionary multi-objective prun-
ing experiments on the ImageNet-100 dataset. This dataset has
more data samples, each with a higher spatial resolution. The
pruning task on this dataset is more complicated. Then, the
pruned network structure was migrated to the larger dataset,
ImageNet-1K, which is used to test the generalization perfor-
mance of the pruned structure from the proposed algorithm
on the larger dataset. We have only modified the output class
number of the last fully connected layer to accommodate the
new dataset. Table VIII records the corresponding experiment
results, where the network structure used in this experiment is
ResNet50.
TABLE VIII
PRUNING RESULTS OF THE EMO-DIR AND THE COMPARISON
ALGORITHM ON IMAGE NET-100/1K FOR RESNET50.
ImageNet-100
Method Err Top1/Top5 FLOPs PR-F (%) Param PR-P (%)
Baseline 15.70 / 3.88 4.09G 0.00 25.56M 0.00
EMO-DIR 15.90 / 3.90 2.10G 48.74 12.94M 45.43
ImageNet-1K
Method Err Top1/Top5 FLOPs PR-F (%) Param PR-P (%)
He et al. [53] 27.70 / 9.20 2.73G 33.3 - -
GAL-0.5 [23] 28.05 / 9.06 2.33G 43.0 21.20M 16.9
SSS-26 [54] 28.18 / 9.21 2.33G 43.0 15.60M 38.8
EMO-DIR 27.31 /8.85 2.10G 48.7 14.78M 42.2
Table VIII demonstrates that the proposed algorithm EMO-
DIR still performs well on the ImageNet-100 dataset. It
achieves a pruning rate of 48.74% for the floating point
operation and 45.43% for the parameter number, with a drop
of 0.20 and 0.02 points in Top-1 and Top-5 performance. This
indicates the effectiveness and efficiency of the EMO-DIR on
the model pruning task for large-scale datasets. In experiments
testing the generalization performance of the pruned structure
from ImageNet-100 on ImageNet-1K, the pruned network
obtained by the proposed algorithm outperforms the other
three pruning algorithms. The proposed algorithm obtains
higher pruning rates for the floating-point operation and the
parameter number with lower Top-1 and Top-5 performance
losses. This shows that the network structure pruned by the
proposed algorithm EMO-DIR could perform well on the
similar dataset.

--- PAGE 11 ---
11
D. Performance Analysis of The Proposed Algorithm
From the above experiments, the EMO-DIR performs well
on several datasets. In this section, we perform more experi-
ments to further analyze the performance of the EMO-DIR.
1) Performance Comparison Between The Whole and The
Divide-and-conquer Optimization:
The divide-and-conquer idea is the key to the proposed
algorithm, which decomposes the complex evolutionary multi-
objective pruning task on the whole network into simple
evolutionary multi-objective pruning tasks on several smaller
sub-networks. On the one hand, this idea can reduce the
optimization complexity of the evolutionary multi-objective
algorithm. On the other hand, it can reduce the computational
complexity of network performance verification. In order
to understand the proposed divide-and-conquer evolutionary
multi-objective network pruning method further, this paper
designs a whole optimization algorithm EMO-W and conducts
corresponding analytical experiments. EMO-W uses the whole
optimization idea instead of the divide-and-conquer in the
EMO-DIR algorithm, which encodes and optimizes the whole
network as a sub-network. In order to allow the network
to converge sufficiently, it uses full training epochs when
verifying the performance of the pruned network. The rest
of the settings are the same as for EMO-W. The network
used was ResNet56; the dataset was CIFAR100. Table IX
describes the experimental results. It compares the prediction
error, the floating-point operation number, the pruning rate
of the floating-point operations, the parameter number, the
pruning rate of the parameters, and the running time from
these two methods.
TABLE IX
PRUNING RESULTS OF THE EMO-DIR AND EMO-W ON THE CIFAR100
FOR THE RESNET56.
Method Error (%) FLOPs PR (%) Param PR (%) GPU Day
EMO-W 27.44 65.81M 47.66 0.46M 46.63 4.9
EMO-DIR 27.54 52.73M 58.07 0.39M 54.45 2.3
Table IX shows that the EMO-DIR obtains better pruning
performance. The pruning network designed by the EMO-DIR
obtains a higher pruning rate on the floating-point operation
and the parameter number with similar performance. Its prun-
ing rate on the floating-point operation is 10.41 points higher
than the EMO-W, and the parameter number is 7.82 points
higher than the EMO-W. In addition, The EMO-DIR consumes
a lower running time, and the time used is lower than half of
the EMO-W, thanks to the fast convergence speed of the sub-
network.
To further analyze the network convergence under the two
methods, the network training process under the two methods
is also compared in Fig. 7. The networks are the unpruned
network structures. Compared with the pruned network, the
complexity of the unpruned network structure is higher, which
is more conducive to comparing the convergence of the
network structure under the two methods. In this experiment,
the complete network and the sub-network were trained atdifferent training epochs, and their convergence accuracy was
recorded.
50100150200250300
Epoch878889909192939495Acc (%)
ubS-Net-3 (EMubS-Net-1 (EMO-DIR )
Sub-Net-2 (EMO-DIR )
O-DIR )
Full-Net (EMO-W )
Fig. 7. The convergence of network structures in EMO-DIR and EMO-W
with different training epochs.
Fig. 7 shows that the whole network Full-Net converges
more slowly than the sub-network Sub-Net-1, Sub-Net-2, and
Sub-Net-3, and Full-Net requires a longer training epoch to
converge to a stable accuracy. In the experiments, the Full-
Net performance keeps growing as the training epoch grows
and only stabilizes when it exceeds 250 epoch. In contrast,
the accuracy of the other three sub-networks stabilizes when
their training epoch exceeds 75. The training epoch for con-
vergence to stable accuracy is less than one-third of that for
the whole network structure. In addition, These three sub-
networks converge at different accuracies. The sub-network
closer to the network input has a lower accuracy, and the
sub-network closer to the output has a higher accuracy. This
is because different sub-networks focus on different levels of
feature extraction. The closer to the network’s output, the more
advanced the features produced by the sub-network, and the
less complicated it is for a simple feature detector to extract
the correct class.
From the above experiments, it is worth mentioning that the
idea based on divide-and-conquer can reduce the difficulty of
the evolutionary multi-objective pruning algorithm in complex
networks. On the one hand, this idea reduces the optimization
space of the algorithm, reducing its difficulty. On the other
hand, it reduces the parameter number of the network to be
verified, accelerating the network’s convergence and reducing
the algorithm’s computational complexity. This enables the
proposed algorithm to obtain better network pruning with less
computational complexity.
2) The Effect of Cross-network Constraints on Cooperation
between Sub-networks:
The proposed sub-network training method based on the
cross-network constraints method can constrain the previous
sub-network’s output feature and the following one’s input
feature to enhance the relationship among these sub-networks
optimized independently, improving the overall performance
of the optimized network. In order to verify the impact of
this method on the EMO-DIR, an algorithm EMO-DIR-nc
is designed that does not use cross-network constraints. It
removes the feature constraints term in Equation (9) and

--- PAGE 12 ---
12
only trains the sub-networks with the cross-entropy loss. The
dataset used is CIFAR100, the network is ResNet56, and Table
X describes the experimental results.
TABLE X
PRUNING RESULTS OF THE EMO-DIR AND EMO-DIR- NC FOR THE
RESNET56ON THE CIFAR100.
Method Error (%) FLOPs PR (%) Param PR (%)
EMO-DIR-nc 27.43 54.74M 56.47 0.44M 48.50
EMO-DIR 27.54 52.73M 58.07 0.39M 54.45
The experimental results show that the cross-network fea-
ture constraints improve the proposed algorithm’s perfor-
mance. Under similar performance, the proposed algorithm
improves the pruning rate on the parameters by approximately
6 points and the pruning rate on the floating-point operations
by approximately 1.6 points over the method without cross-
network feature constraints. These results demonstrate the
excellent performance of the proposed cross-network feature
constraint method.
In addition, to further analyze the effect of the cross-
network feature constraint on the relationship among pruned
sub-networks, corresponding performance measurements are
also performed on all pruned network structures obtained
from the global performance impairment ranking in both
algorithms. The measurements use the weights of the sub-
network obtained during the evolutionary optimization pro-
cess without additional updates. If these sub-networks trained
independently have good collaboration, the complete network
performs well on the target task. Furthermore, because the sub-
network pruning structures involved in the global performance
ranking are all non-dominated solutions on each sub-network
pruning task, the network pruning structure constructed by
global performance impairment ranking is also a collection
of non-dominated solutions if the collaboration among the
sub-networks is strong. Because the network structure is only
changed one sub-network at a time when constructing the
network structure with the global performance impairment
index, and both the original structure and the adjusted one
are non-dominated solutions on the same sub-network pruning
task, the network structure before and after the pruning pro-
cesses remains on the collection of non-dominated solutions.
Therefore, if the collaboration among sub-network structures
optimized independently is strong, the sub-structures obtained
during optimization can still collaborate well without updating
the weights. Even considering the random interference of
the network performance verification, the network structure
constructed by the global performance impairment ranking is
still approximately a collection of non-dominated solutions
when using the weights obtained during the evolutionary
process. For this reason, this paper conducts the correspond-
ing performance analysis experiments using all the network
structures constructed by the global performance impairment
ranking in Table X. The error and parameter remaining rates
for all network structures are shown in Fig. 8. The weights for
all network structures in the experiment were obtained from
the training during evolutionary multi-objective optimization
without any update.
20 30 40 50 60 70 80 90
Parameter Remaining Rate (%)3034384246Full Network Error (%)EMO-DIR-nc 
EMO-DIRFig. 8. Network pruning rates and parameter remaining rates network
structures obtained by the EMO-DIR and EMO-DIR-nc through GPIR.
The experiments show that the network structure con-
structed by the proposed algorithm is approximately dis-
tributed like a Pareto Front. In contrast, the EMO-DIR-
nc algorithm, which removes the cross-network constraints,
constructs a network structure with a more discrete distribution
containing more dominant solutions. Moreover, the EMO-
DIR algorithm also performs better at the same pruning rate,
which suggests that the cross-network constraints reinforce the
relationship among sub-networks and improve the network’s
overall performance consisting of sub-networks optimized
independently.
3) The Relationship Between the Sub-Network Performance
and the Feature Changes:
The feature detectors can calculate the classification ac-
curacy, measuring the feature processing ability of the sub-
networks. However, the change between the features generated
by the pruning sub-network and the unpruned one can also
measure the drop in the feature processing ability. To this
end, an evolutionary multi-objective pruning algorithm based
on feature change, EMO-DIR- L2, is designed, which uses the
L2norm between the features generated by the pruning sub-
network and the unpruned sub-network as a performance drop
measure. The remaining experimental settings are the same as
the EMO-DIR. Table XI records the experimental results.
TABLE XI
PRUNING RESULTS OF THE EMO-DIR AND EMO-DIR- L2FOR THE
RESNET56ON THE CIFAR100.
Method Error (%) FLOPs PR (%) Param PR (%)
EMO-DIR- L2 27.58 60.78M 51.67 0.40M 53.08
EMO-DIR 27.54 52.73M 58.07 0.39M 54.45
The network structure used was ResNet56; the dataset was
CIFAR100. The experimental results demonstrate that the
EMO-DIR is better than the method using the change between
features as the sub-network performance measure. With similar
parameter pruning rates and errors, the proposed algorithm has
a 6.4 points higher pruning rate for floating point operations
than the EMO-DIR- L2. The change between features, while
reflecting the drop in the feature processing ability of the
pruned sub-network relative to the unpruned one, is not the
same as the actual performance drop. Features are not simply
collections of elements but also complex interrelationships

--- PAGE 13 ---
13
among elements. The L2norm can accurately measure the
change in the feature elements, but the change in the complex
relationships among feature elements is difficult to measure
accurately. The feature detector designed for unpruned sub-
network can detect and process the features generated by the
sub-network and translate the valuable information detected
into classification accuracy. Thus, the feature detector provides
a better measure of the feature processing capability of the
sub-network.
In addition, this paper also compares the change in the
feature elements produced by the pruned sub-network with
the prediction accuracy produced by the feature detector. The
change of the feature element (L2 losses) and accuracies are
regularized to [0, 1] for a clear comparison. They are all
functions of the network pruning structure and change as
the pruning scheme changes. Fig. 9 depicts the relationship
between the regularized losses and the regularized accuracies
for all the sub-networks generated during the evolutionary
process. The three sub-networks in this picture come from
the independent evolutionary multi-objective optimization of
three sub-networks divided by the same network.
00.250.50.75100.20.40.60.81
00.250.50.75100.20.40.60.81
00.250.50.75100.20.40.60.81
00.250.50.75100.20.40.60.81
00.250.50.75100.20.40.60.81
00.250.50.75100.20.40.60.81
00.250.50.75100.20.40.60.81
Regularized AccRegularized AccRegularized Acc(a). SubNet-1.(b). SubNet-2.(c). SubNet-3.Regularized Loss
Fig. 9. Relationship between the feature changes brought by the pruned sub-
network and the prediction accuracy of its corresponding feature detector.
The experimental results show a negative correlation be-
tween the feature change and accuracy. This explains why
EMO-DIR using accuracy and EMO-DIR- L2using feature
change perform well in the evolutionary multi-objective net-
work pruning task. However, the local zoom in Fig. 9 shows
that the feature change cannot reflect the change in accuracy
well. A reduction in the feature change may lead to a reduction
in accuracy. Therefore, a pre-trained feature detector can better
guide the evolutionary multi-objective pruning on the sub-
networks.
IV. C ONCLUCSION
EMO network compression algorithms have to face the
complex optimization space and the high resource-consuming
compression network verification when dealing with the com-
pression task on complex network structures, which limits its
application in this field. To this end, this paper proposes a
multi-objective complex network pruning framework based
on divide-and-conquer and global performance impairment
ranking to reduce the space complexity and resource consump-
tion of pruning algorithms based on EMO. Firstly, a divide-and-conquer EMO network pruning method is designed.
This method can reduce the optimization difficulty of multi-
objective pruning algorithms and the resource consumption of
pruning structure verification. In the pruning task on ResNet56
at CIFAR100, compared to the whole network pruning method,
this proposed method achieves a 10.41 points improvement
in the pruning rate of floating-point operations, a 7.82 points
improvement in the pruning rate of parameters and consumed
only about half of the running time under a similar perfor-
mance. This paper then designs a sub-network training method
based on cross-network constraints. It enables sub-networks
pruned independently to collaborate better by constraining the
previous sub-network’s output features and the next one’s input
features, improving the pruned network’s overall performance.
In an experimental analysis on ResNet56 at CIFAR100, com-
pared to the method without feature constraints, the proposed
algorithm brings about a 6 points improvement in the pruning
rate of parameters and a 1.6 points improvement in the pruning
rate of floating-point operations with similar performance. Fi-
nally, this paper designs a multiple sub-networks joint pruning
method based on EMO. It combines multi-objective pruning
results on multiple sub-networks to design a joint pruning
scheme. The effectiveness and efficiency of the EMO-DIR are
validated on three datasets of different sizes.
This paper applies the divide-and-conquer idea to evolu-
tionary multi-objective pruning. There are several aspects for
improvement. For example, how to further reduce the resource
consumption of the algorithm and improve the efficiency of
the EMO algorithm. We will continue our research in this area
in future work.
REFERENCES
[1] R. Shang, J. Ren, S. Zhu, W. Zhang, J. Feng, Y . Li, and L. Jiao, “Hy-
perspectral Image Classification Based on Pyramid Coordinate Attention
and Weighted Self-Distillation,” IEEE Transactions on Geoscience and
Remote Sensing , vol. 60, pp. 1–16, 2022.
[2] X. Wang, Z. Chen, J. Tang, B. Luo, Y . Wang, Y . Tian, and F. Wu,
“Dynamic Attention Guided Multi-Trajectory Analysis for Single Ob-
ject Tracking,” IEEE Transactions on Circuits and Systems for Video
Technology , vol. 31, no. 12, pp. 4895–4908, Dec. 2021.
[3] Y . Wu, L. Jiao, F. Liu, Z. Pi, X. Liu, L. Li, and S. Yang, “CSLT:
Contourlet-Based Siamese Learning Tracker for Dim and Small Targets
in Satellite Videos,” IEEE Transactions on Geoscience and Remote
Sensing , vol. 61, pp. 1–13, 2023.
[4] Z. Li, Y . Sun, L. Zhang, and J. Tang, “CTNet: Context-Based Tandem
Network for Semantic Segmentation,” IEEE Transactions on Pattern
Analysis and Machine Intelligence , vol. 44, no. 12, pp. 9904–9917, 2022.
[5] L. Li, T. Zhou, W. Wang, J. Li, and Y . Yang, “Deep Hierarchical
Semantic Segmentation,” Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition , pp. 1246–1257, 2022.
[6] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification
with deep convolutional neural networks,” Advances in neural informa-
tion processing systems , vol. 25, pp. 1097–1105, 2012.
[7] C. Szegedy, W. Liu, Y . Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan,
V . Vanhoucke, and A. Rabinovich, “Going deeper with convolutions,”
Proceedings of the IEEE conference on computer vision and pattern
recognition , pp. 1–9, 2015.
[8] K. Simonyan and A. Zisserman, “Very deep convolutional networks for
large-scale image recognition,” arXiv preprint arXiv:1409.1556 , 2014.
[9] S. Han, J. Pool, J. Tran, and W. Dally, “Learning both Weights
and Connections for Efficient Neural Network,” Advances in Neural
Information Processing Systems , vol. 28, 2015.
[10] G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural
network,” arXiv preprint arXiv:1503.02531 , 2015.

--- PAGE 14 ---
14
[11] K. Zhang, C. Zhang, S. Li, D. Zeng, and S. Ge, “Student Network
Learning via Evolutionary Knowledge Distillation,” IEEE Transactions
on Circuits and Systems for Video Technology , vol. 32, no. 4, pp. 2251–
2263, Apr. 2022.
[12] L. Yang, S. Gu, C. Shen, X. Zhao, and Q. Hu, “Skeleton Neural
Networks via Low-Rank Guided Filter Pruning,” IEEE Transactions on
Circuits and Systems for Video Technology , vol. 33, no. 12, pp. 7197–
7211, Dec. 2023.
[13] K.-Y . Feng, X. Fei, M. Gong, A. K. Qin, H. Li, and Y . Wu, “An
Automatically Layer-Wise Searching Strategy for Channel Pruning
Based on Task-Driven Sparsity Optimization,” IEEE Transactions on
Circuits and Systems for Video Technology , vol. 32, no. 9, pp. 5790–
5802, Sep. 2022.
[14] M. Lin, R. Ji, Z. Xu, B. Zhang, F. Chao, C.-W. Lin, and L. Shao,
“SiMaN: Sign-to-Magnitude Network Binarization,” IEEE Transactions
on Pattern Analysis and Machine Intelligence , pp. 1–12, 2022.
[15] Y . Cai, Z. Yao, Z. Dong, A. Gholami, M. W. Mahoney, and K. Keutzer,
“ZeroQ: A Novel Zero Shot Quantization Framework,” 2020 IEEE/CVF
Conference on Computer Vision and Pattern Recognition (CVPR) , pp.
13 166–13 175, 2020.
[16] S. Xu, A. Huang, L. Chen, and B. Zhang, “Convolutional Neural
Network Pruning: A Survey,” 2020 39th Chinese Control Conference
(CCC) , pp. 7458–7463, 2020.
[17] Y . Guo, A. Yao, and Y . Chen, “Dynamic Network Surgery for Efficient
DNNs,” Advances in Neural Information Processing Systems , vol. 29,
2016.
[18] M. Lin, L. Cao, S. Li, Q. Ye, Y . Tian, J. Liu, Q. Tian, and R. Ji, “Filter
Sketch for Network Pruning,” IEEE Transactions on Neural Networks
and Learning Systems , pp. 1–10, 2021.
[19] Y . He, G. Kang, X. Dong, Y . Fu, and Y . Yang, “Soft filter pruning for
accelerating deep convolutional neural networks,” Proceedings of the
27th International Joint Conference on Artificial Intelligence , pp. 2234–
2240, 2018.
[20] B. O. Ayinde and J. M. Zurada, “Building Efficient ConvNets using
Redundant Feature Pruning,” International Conference on Learning
Representations , 2018.
[21] R. Yu, A. Li, C.-F. Chen, J.-H. Lai, V . I. Morariu, X. Han, M. Gao,
C.-Y . Lin, and L. S. Davis, “NISP: Pruning Networks Using Neuron
Importance Score Propagation,” Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition , pp. 9194–9203, 2018.
[22] Y . He, P. Liu, Z. Wang, Z. Hu, and Y . Yang, “Filter pruning via
geometric median for deep convolutional neural networks acceleration,”
Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition , pp. 4340–4349, 2019.
[23] S. Lin, R. Ji, C. Yan, B. Zhang, L. Cao, Q. Ye, F. Huang, and D. Do-
ermann, “Towards Optimal Structured CNN Pruning via Generative
Adversarial Learning,” Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition , pp. 2790–2799, 2019.
[24] M. Lin, R. Ji, Y . Wang, Y . Zhang, B. Zhang, Y . Tian, and L. Shao,
“HRank: Filter Pruning using High-Rank Feature Map,” Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern Recognition
(CVPR) , pp. 1529–1538, 2020.
[25] Y . He, X. Dong, G. Kang, Y . Fu, C. Yan, and Y . Yang, “Asymptotic
Soft Filter Pruning for Deep Convolutional Neural Networks,” IEEE
Transactions on Cybernetics , vol. 50, no. 8, pp. 3594–3604, 2020.
[26] X. Zhang, W. Xie, Y . Li, J. Lei, and Q. Du, “Filter Pruning via Learned
Representation Median in the Frequency Domain,” IEEE Transactions
on Cybernetics , pp. 1–11, 2021.
[27] Z. Chen, T.-B. Xu, C. Du, C.-L. Liu, and H. He, “Dynamical Channel
Pruning by Conditional Accuracy Change for Deep Neural Networks,”
IEEE Transactions on Neural Networks and Learning Systems , vol. 32,
no. 2, pp. 799–813, 2021.
[28] Y . He, Y . Ding, P. Liu, L. Zhu, H. Zhang, and Y . Yang, “Learning Filter
Pruning Criteria for Deep Convolutional Neural Networks Acceleration,”
IEEE/CVF Conference on Computer Vision and Pattern Recognition
(CVPR) , 2020.
[29] H. Li, A. Kadav, I. Durdanovic, H. Samet, and H. P. Graf, “Pruning
Filters for Efficient ConvNets,” International Conference on Learning
Representations , pp. 1–13, 2017.
[30] J. Yosinski, J. Clune, Y . Bengio, and H. Lipson, “How transferable
are features in deep neural networks?” Advances in Neural Information
Processing Systems , vol. 27, 2014.
[31] S. Niu, K. Gao, P. Ma, X. Gao, H. Zhao, J. Dong, Y . Chen, and
D. Shen, “Exploiting Sparse Self-Representation and Particle Swarm
Optimization for CNN Compression,” IEEE Transactions on Neural
Networks and Learning Systems , pp. 1–13, 2022.[32] H. Zhao, C. Zhang, B. Xue, M. Zhang, and B. Zhang, “A Two-
Stage Differential Evolutionary Algorithm for Deep Ensemble Model
Generation,” IEEE Transactions on Evolutionary Computation , pp. 1–1,
2022.
[33] R. Shang, S. Zhu, J. Ren, H. Liu, and L. Jiao, “Evolutionary neural
architecture search based on evaluation correction and functional units,”
Knowledge-Based Systems , vol. 251, p. 109206, 2022.
[34] P. Stodola and J. Nohel, “Adaptive Ant Colony Optimization with
Node Clustering for the Multi-Depot Vehicle Routing Problem,” IEEE
Transactions on Evolutionary Computation , pp. 1–1, 2022.
[35] J. Huang, B. Xue, Y . Sun, M. Zhang, and G. G. Yen, “Particle
Swarm Optimization for Compact Neural Architecture Search for Image
Classification,” IEEE Transactions on Evolutionary Computation , pp. 1–
1, 2022.
[36] Y . Zhou, G. G. Yen, and Z. Yi, “Evolutionary Compression of Deep
Neural Networks for Biomedical Image Segmentation,” IEEE Transac-
tions on Neural Networks and Learning Systems , vol. 31, no. 8, pp.
2916–2929, 2020.
[37] Y . Zhou, G. G. Yen, and Z. Yi, “A Knee-Guided Evolutionary Algo-
rithm for Compressing Deep Neural Networks,” IEEE Transactions on
Cybernetics , vol. 51, no. 3, pp. 1626–1638, 2021.
[38] Y . Zhou, G. G. Yen, and Z. Yi, “Evolutionary Shallowing Deep Neural
Networks at Block Levels,” IEEE Transactions on Neural Networks and
Learning Systems , pp. 1–13, 2021.
[39] J. L. Bentley, “Multidimensional divide-and-conquer,” Communications
of the ACM , vol. 23, no. 4, pp. 214–229, 1980.
[40] A. Gidiotis and G. Tsoumakas, “A Divide-and-Conquer Approach to the
Summarization of Long Documents,” IEEE/ACM Transactions on Audio,
Speech, and Language Processing , vol. 28, pp. 3029–3040, 2020.
[41] H. Xiong, H. Lu, C. Liu, L. Liu, Z. Cao, and C. Shen, “From Open Set
to Closed Set: Counting Objects by Spatial Divide-and-Conquer,” pp.
8362–8371, 2019.
[42] K. Deb, “Multi-objective Optimisation Using Evolutionary Algorithms:
An Introduction,” Multi-objective Evolutionary Optimisation for Product
Design and Manufacturing , pp. 3–34, 2011.
[43] A. Krizhevsky and H. Geoffrey, “Learning multiple layers of features
from tiny images,” 2009.
[44] Y .-H. H. Tsai, T. Li, W. Liu, P. Liao, R. Salakhutdinov, and L.-P.
Morency, “Learning Weakly-supervised Contrastive Representations,”
International Conference on Learning Representations , 2022.
[45] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “ImageNet:
A large-scale hierarchical image database,” 2009 IEEE Conference on
Computer Vision and Pattern Recognition , pp. 248–255, Jun. 2009.
[46] K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan, “A fast and elitist
multiobjective genetic algorithm: NSGA-II,” IEEE Transactions on
Evolutionary Computation , vol. 6, no. 2, pp. 182–197, 2002.
[47] K. He, X. Zhang, S. Ren, and J. Sun, “Deep Residual Learning for
Image Recognition,” Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition , pp. 770–778, 2016.
[48] K. Simonyan and A. Zisserman, “Very deep convolutional networks for
large-scale image recognition,” International Conference on Learning
Representations , pp. 1–14, 2015.
[49] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan,
T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. Kopf,
E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner,
L. Fang, J. Bai, and S. Chintala, “PyTorch: An Imperative Style, High-
Performance Deep Learning Library,” Advances in Neural Information
Processing Systems , vol. 32, 2019.
[50] H. Peng, J. Wu, S. Chen, and J. Huang, “Collaborative Channel Pruning
for Deep Networks,” Proceedings of the 36th International Conference
on Machine Learning , pp. 5113–5122, 2019.
[51] X. Dong, J. Huang, Y . Yang, and S. Yan, “More is less: A more
complicated network with less inference complexity,” Proceedings of
the IEEE Conference on Computer Vision and Pattern Recognition , pp.
5840–5848, 2017.
[52] X. Dong and Y . Yang, “Network Pruning via Transformable Architecture
Search,” Advances in Neural Information Processing Systems , vol. 32,
pp. 760–771, 2019.
[53] Y . He, X. Zhang, and J. Sun, “Channel Pruning for Accelerating
Very Deep Neural Networks,” Proceedings of the IEEE International
Conference on Computer Vision , pp. 1389–1397, 2017.
[54] Z. Huang and N. Wang, “Data-Driven Sparse Structure Selection for
Deep Neural Networks,” Proceedings of the European Conference on
Computer Vision ECCV , pp. 304–320, 2018.

--- PAGE 15 ---
15
Ronghua Shang (SM’ 22) received the B.S. degree
in information and computation science and the
Ph.D. degree in pattern recognition and intelligent
systems from Xidian University in 2003 and 2008,
respectively. She is currently a professor with Xidian
University. Her current research interests include
optimization problems, evolutionary computation,
image processing, and data mining.
Songling Zhu received the B.E. degree in School
of Electric Power from North China University of
Water Resources and Electric Power, Henan, China.
Now he is pursuing a Ph.D. degree in School of
Artificial Intelligence from Xidian University, Xi’an,
China. His current research interests include deep
learning, evolutionary deep learning, knowledge dis-
tillation, model pruning, model compression.
Yinan Wu received the B.Sc. degree in information
and computing science from Northwestern Poly-
technical University, Xi’an, China, in 2016. She is
currently pursuing a Ph.D. degree with the School
of Artificial Intelligence and the Key Laboratory
of Intelligent Perception and Image Understanding,
Ministry of Education of China, Xidian University,
Xi’an, China. Her research interests include im-
age/signal processing and analysis of deep learning
in Earth Observation.
Weitong Zhang (M’21) received the B.E. degree
in Electronic and Information Engineering from
Changchun University of Science and Technology,
Changchun, China, in 2013, the M.S. degree in
Electronics and Communication Engineering, and
the Ph.D. degree in Electronic science and technol-
ogy from Xidian University, Xi’an, China, in 2017
and 2021. She is currently a lecturer with Xidian
University. Her current research interests include
complex networks and machine learning.
Licheng Jiao (SM’89-F’17) received the B.S. de-
gree from Shanghai Jiaotong University, Shanghai,
China, in 1982, the M.S. and Ph.D. degrees from
Xian Jiaotong University, Xian, China, in 1984 and
1990, respectively. From 1990 to 1991, he was a
postdoctoral Fellow in the National Key Labora-
tory for Radar Signal Processing, Xidian Univer-
sity, Xian, China. Since 1992, Dr. Jiao has been a
Professor in the School of Electronic Engineering
at Xidian University. Currently, he is the Director
of the Key Lab of Intelligent Perception and Image
Understanding of Ministry of Education of China at Xidian University, Xian,
China. Dr. Jiao is a fellow of IEEE, member of IEEE Xian Section Executive
Committee and the Chairman of Awards and Recognition Committee, vice
board chairperson of Chinese Association of Artificial Intelligence, councilor
of Chinese Institute of Electronics, committee member of Chinese Committee
of Neural Networks, and expert of Academic Degrees Committee of the State
Council. His research interests include image processing, natural computation,
machine learning, and intelligent information processing. He has led 40 major
scientific research projects, and published more than 20 monographs and a
hundred papers in international journals and conferences.
Songhua Xu is a computer scientist. He received
his M.S., M.Phil., and Ph.D. from Yale University,
New Haven, CT, USA, all in computer science.
His research interests include healthcare informatics,
information retrieval, knowledge management and
discovery, intelligent web and social media, visual
analytics, user interface design, and multimedia.

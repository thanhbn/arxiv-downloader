# 2310.02025.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/no-backprop/2310.02025.pdf
# Kích thước tệp: 1682011 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Được công bố như một bài báo hội nghị tại ICLR 2024
DEEPZERO: MỞ RỘNG QUY MÔ TỐI ƯU HÓA BẬC KHÔNG CHO HUẤN LUYỆN MÔ HÌNH SÂU
Aochuan Chen†,⋆Yimeng Zhang†,⋆Jinghan Jia†James Diffenderfer‡Jiancheng Liu†
Konstantinos Parasyris‡Yihua Zhang†Zheng Zhang§Bhavya Kailkhura‡Sijia Liu†
†Michigan State University,‡Lawrence Livermore National Laboratory,§UC Santa Barbara
∗Đóng góp ngang nhau
TÓM TẮT
Tối ưu hóa bậc không (ZO) đã trở thành một kỹ thuật phổ biến để giải quyết các vấn đề học máy (ML) khi thông tin bậc một (FO) khó có hoặc không thể thu được. Tuy nhiên, khả năng mở rộng quy mô của tối ưu hóa ZO vẫn là một vấn đề mở: Việc sử dụng nó chủ yếu bị giới hạn trong các vấn đề ML quy mô tương đối nhỏ, như tạo tấn công đối kháng theo mẫu. Theo hiểu biết tốt nhất của chúng tôi, không có nghiên cứu nào trước đây đã chứng minh hiệu quả của tối ưu hóa ZO trong việc huấn luyện mạng nơ-ron sâu (DNN) mà không giảm đáng kể hiệu suất. Để vượt qua rào cản này, chúng tôi phát triển DeepZero, một khung học sâu (DL) ZO có nguyên tắc có thể mở rộng quy mô tối ưu hóa ZO cho việc huấn luyện DNN từ đầu thông qua ba đổi mới chính. Đầu tiên, chúng tôi chứng minh những lợi thế của ước lượng gradient theo tọa độ (CGE) so với ước lượng gradient theo vector ngẫu nhiên trong độ chính xác huấn luyện và hiệu quả tính toán. Thứ hai, chúng tôi đề xuất một giao thức huấn luyện ZO được tạo ra bởi độ thưa thớt mở rộng phương pháp tỉa mô hình chỉ sử dụng các sai phân hữu hạn để khám phá và khai thác tiên nghiệm DL thưa thớt trong CGE. Thứ ba, chúng tôi phát triển các phương pháp tái sử dụng đặc trưng và song song hóa tiến để cải thiện việc triển khai thực tế của huấn luyện ZO. Các thí nghiệm mở rộng của chúng tôi cho thấy DeepZero đạt được độ chính xác tối tiến (SOTA) trên ResNet-20 được huấn luyện trên CIFAR-10, tiếp cận hiệu suất huấn luyện FO lần đầu tiên. Hơn nữa, chúng tôi cho thấy tiện ích thực tế của DeepZero trong các ứng dụng bảo vệ đối kháng được chứng nhận và sửa lỗi phương trình đạo hàm riêng dựa trên DL, đạt được cải thiện 10-20% so với SOTA. Chúng tôi tin rằng kết quả của chúng tôi sẽ truyền cảm hứng cho nghiên cứu trong tương lai về tối ưu hóa ZO có thể mở rộng và góp phần thúc đẩy DL với hộp đen. Mã có sẵn tại https://github.com/OPTML-Group/DeepZero .

1 GIỚI THIỆU
Trong lĩnh vực học máy (ML), các thuật toán tối ưu hóa đã đóng vai trò quan trọng trong việc cho phép huấn luyện các mô hình phức tạp, mang lại những hiểu biết và khả năng dự đoán chưa từng có trên nhiều lĩnh vực khác nhau. Qua nhiều năm, các phương pháp dựa trên gradient bậc một (FO), như descent gradient ngẫu nhiên (SGD) và các biến thể của nó (Gardner, 1984; Amari, 1993; Bottou, 2010; 2012), đã trở thành lựa chọn mặc định cho việc huấn luyện mô hình. Các phương pháp này dựa vào thông tin gradient để cập nhật các tham số mô hình một cách lặp đi lặp lại, nhằm tối thiểu hóa một hàm mất mát nhất định. Tuy nhiên, tồn tại một số tình huống thực tế mà thông tin gradient FO không có sẵn hoặc không khả thi để tính toán, đòi hỏi các chiến lược thay thế. Tối ưu hóa bậc không (ZO) (Flaxman et al., 2005; Shamir, 2013; Ghadimi & Lan, 2013; Nesterov & Spokoiny, 2015; Duchi et al., 2015; Liu et al., 2018b; Ilyas et al., 2018b; Zhang et al., 2024) đã nổi lên như một cách tiếp cận đầy hứa hẹn để giải quyết những thách thức này, vì nó tận dụng các sai phân hữu hạn của giá trị hàm để ước lượng gradient, thay vì yêu cầu thông tin gradient tường minh. Do đó, với những sửa đổi nhỏ đối với các thuật toán FO, tối ưu hóa ZO có thể được áp dụng cho các hoàn cảnh thực tế khác nhau nơi gradient FO khó có được. Ví dụ, trong các ngành như vật lý và hóa học, các mô hình ML có thể tương tác với các trình mô phỏng hoặc thí nghiệm phức tạp nơi các hệ thống cơ bản không thể vi phân (Thelen et al., 2022; Tsaknakis et al., 2022; Louppe et al., 2019; Abreu de Souza et al., 2023; Baydin et al., 2020). Ngoài ra, các tình huống học hộp đen thường xảy ra khi các mô hình học sâu (DL) được tích hợp với các API bên thứ ba, như tấn công đối kháng và phòng thủ chống lại các mô hình DL hộp đen (Chen et al., 2017; Ilyas et al., 2018a; Zhang et al., 2022c; Verma et al., 2023) và học prompt hộp đen cho mô hình ngôn ngữ như dịch vụ (Diao et al., 2022; Sun et al., 2022). Hơn nữa, cơ chế lan truyền ngược (BP) có nguyên tắc (Amari, 1993; Rumelhart et al., 1995) để tính toán gradient FO cũng có thể không được hỗ trợ khi triển khai các mô hình DL trên các hệ thống phần cứng (Gu et al., 2021b; Tavanaei et al., 2019; Greengard, 2020; Jabri & Flower, 1992; Gu et al., 2021c). Ngoài tối ưu hóa ZO, một hướng nghiên cứu liên quan khác trong lĩnh vực DL tập trung vào việc phát triển các phương pháp có thể tin cậy về mặt sinh học, không sử dụng BP. Các ví dụ bao gồm các phương pháp dựa trên gradient tiến (Ren et al., 2022; Baydin et al., 2022; Silver et al., 2021; Belouze, 2022), học theo lớp tham lam (Nøkland & Eidnes, 2019), và học Hebbian (Isomura & Toyoizumi, 2018; Moraitis et al., 2022). Tuy nhiên, các kỹ thuật này yêu cầu truy cập vào đồ thị tính toán và phụ thuộc cao vào các khung phần mềm DL được sử dụng và/hoặc kiến trúc mô hình. Ngược lại, tối ưu hóa ZO chỉ dựa vào các truy vấn mô hình và không cần đồ thị tính toán được sử dụng. Do đó, tối ưu hóa ZO có khả năng áp dụng rộng rãi cho các vấn đề DL liên quan đến các thành phần hộp đen chỉ truy vấn. Mặc dù có tiềm năng của tối ưu hóa ZO, các rào cản về khả năng mở rộng quy mô cản trở việc áp dụng nó trong việc huấn luyện DNN quy mô trung bình hoặc lớn (Wang et al., 2017; Liu et al., 2018b; Ohta et al., 2020; Cai et al., 2021; Zhang et al., 2022c). Khi chiều của vấn đề tăng lên, độ chính xác và hiệu quả của các phương pháp ZO truyền thống suy giảm. Điều này là do các ước lượng gradient dựa trên sai phân hữu hạn ZO là các ước lượng thiên lệch của gradient FO, và thiên lệch trở nên rõ ràng hơn trong không gian chiều cao (Liu et al., 2018b; Cai et al., 2021; Balasubramanian & Ghadimi, 2018).

Những thách thức này thúc đẩy câu hỏi trung tâm được giải quyết trong công trình này: (Q) Làm thế nào để mở rộng quy mô tối ưu hóa ZO cho việc huấn luyện các mô hình sâu? Để giải quyết (Q), chúng tôi đề xuất một khung mới, 'DeepZero', kết hợp các kỹ thuật tỉa mô hình mới và tính toán song song để mở rộng quy mô huấn luyện DNN ZO (xem Hình 1 để có tổng quan sơ đồ). Các đóng góp chính của chúng tôi được tóm tắt dưới đây.

❶ Chúng tôi chỉ ra rằng ước lượng gradient theo tọa độ (CGE) xác định vượt trội so với ước lượng gradient theo vector ngẫu nhiên (RGE) trong cả độ chính xác và hiệu quả tính toán khi mở rộng quy mô cho việc huấn luyện mô hình sâu. Hơn nữa, CGE trở nên có lợi thế hơn khi độ sâu mô hình tăng lên.

❷ Chúng tôi chỉ ra rằng độ thưa thớt là rất quan trọng để thực hiện việc huấn luyện mô hình thông qua CGE với các sai phân hữu hạn. Trái ngược với các công trình trước đây, chúng tôi thấy rằng độ thưa thớt cho các mô hình hộp đen có thể được thu được 'miễn phí' bằng cách mở rộng kỹ thuật tỉa-tại-khởi-tạo hiện tại cho mô hình học ZO. Sự tương tác được thiết lập giữa tỉa và CGE trình bày một con đường đầy hứa hẹn cho việc huấn luyện ZO hiệu quả của các DNN.

❸ Chúng tôi xác định thuộc tính phù hợp với song song hóa vốn có trong tối ưu hóa ZO dựa trên CGE và đề xuất một phương pháp song song hóa tiến mới dựa trên thuộc tính này. Khung của chúng tôi cho phép tái sử dụng đặc trưng trong học sâu, điều này tiếp tục tăng tốc việc huấn luyện song song bằng cách loại bỏ các tính toán dư thừa.

❹ Chúng tôi giới thiệu khung huấn luyện mô hình sâu ZO được đề xuất của chúng tôi, 'DeepZero'. Để chứng minh tính ưu việt thực nghiệm của DeepZero, chúng tôi thực hiện các thí nghiệm mở rộng trên cả các tiêu chuẩn phân loại hình ảnh tiêu chuẩn và các ứng dụng DL hộp đen trong thế giới thực. Ví dụ, khi sử dụng DeepZero để huấn luyện ResNet20 trên CIFAR-10, chúng tôi đạt được 86.94% độ chính xác kiểm tra, tốt nhất được báo cáo trong tài liệu về huấn luyện mô hình không gradient. Chúng tôi cũng minh họa tiềm năng to lớn và tác động thực tế của DeepZero trong hai nhiệm vụ DL thực tế: bảo vệ hộp đen cho độ mạnh mẽ đối kháng (Zhang et al., 2022c) và DL thông tin vật lý với solver-trong-vòng-lặp (Um et al., 2020).

Để làm rõ, công trình của chúng tôi nhằm mở rộng khả năng mở rộng quy mô của tối ưu hóa ZO cho các ứng dụng DL, giải quyết các trường hợp mà tối ưu hóa FO trở nên thách thức hoặc không khả thi. Tuy nhiên, điều cần thiết là phải lưu ý rằng những tiến bộ được đề xuất trong huấn luyện ZO không nhằm vượt qua những thách thức khả năng mở rộng quy mô cuối cùng để huấn luyện mạng sâu ở bất kỳ quy mô nào.

2 CÔNG TRÌNH LIÊN QUAN
Tối ưu hóa không gradient cổ điển. Những nỗ lực nghiên cứu sớm có thể được phân loại rộng rãi thành hai nhóm: các phương pháp dựa trên tìm kiếm trực tiếp (DSMs) và các phương pháp dựa trên mô hình (MBMs) (Wright et al., 1999; Conn et al., 2009; Rios & Sahinidis, 2013; Larson et al., 2019). DSMs bao gồm các kỹ thuật như tọa độ (Fermi, 1952) và phương pháp tìm kiếm mẫu (Torczon, 1991) và phương pháp simplex Nelder-Mead (Nelder & Mead, 1965). MBMs bao gồm descent dựa trên mô hình (Bortz & Kelley, 1998) và các phương pháp vùng tin cậy (Conn et al., 2000). Tối ưu hóa tiến hóa cung cấp một khung tính toán không gradient dựa trên quần thể chung bao gồm các thuật toán di truyền (Grefenstette, 1993) và tối ưu hóa bầy đàn hạt (Vaz & Vicente, 2009). Tối ưu hóa Bayesian (Shahriari et al., 2015; Eriksson et al., 2019) đã thu hút sự chú ý gần đây bằng cách sử dụng quy trình Gaussian (GP) để phù hợp với một hàm mục tiêu hộp đen và ước lượng một giải pháp tối ưu hóa. Tuy nhiên, việc thu được một GP chính xác là tốn kém về mặt tính toán.

Tối ưu hóa bậc không. Trái ngược với các phương pháp không gradient cổ điển, tối ưu hóa ZO xấp xỉ gradient bằng cách sử dụng sai phân hữu hạn, đơn giản hóa việc triển khai bằng cách tối thiểu hóa các sửa đổi của các thuật toán dựa trên gradient FO. Giống như các phương pháp FO, ZO có những đảm bảo hội tụ có thể chứng minh được (Nesterov & Spokoiny, 2017; Duchi et al., 2015; Liu et al., 2020a). Tối ưu hóa ZO đã nhận được sự chú ý đáng kể vì thành công của nó trong việc giải quyết các vấn đề ML mới nổi khác nhau (Ghadimi & Lan, 2013; Nesterov & Spokoiny, 2015; Flaxman et al., 2005; Duchi et al., 2015). Các ví dụ bao gồm tấn công và phòng thủ đối kháng (Chen et al., 2017; Tu et al., 2019; Ye et al., 2018; Ilyas et al., 2018a; Zhang et al., 2022c; Verma et al., 2023; Zhao et al., 2019; Hogan & Kailkhura, 2018; Shu et al., 2022), giải thích tương phản bất khả tri mô hình (Dhurandhar et al., 2019), prompt trực quan cho học chuyển giao (Tsai et al., 2020), mở rộng đồ thị tính toán (Vicol et al., 2023), ML tự động (Gu et al., 2021a; Wang et al., 2022), tìm kiếm chính sách trong học tăng cường (Vemula et al., 2019), quản lý tài nguyên mạng (Liu et al., 2018b), tối ưu hóa quy trình làm việc khoa học dựa trên ML (Tsaknakis et al., 2022), và học trên chip (Gu et al., 2021b). Mặc dù có thành công của ZO trong việc giải quyết các vấn đề ML, việc áp dụng nó đã bị giới hạn ở quy mô tương đối nhỏ. Ví dụ, các bộ tối ưu ZO được sử dụng để tạo ra các cuộc tấn công đối kháng, giải thích tương phản và prompt trực quan chỉ hoạt động trong không gian tham số đầu vào, có chiều của một ví dụ đầu vào duy nhất. Một số kỹ thuật tăng tốc đã được phát triển để cải thiện hiệu suất ZO trong các vấn đề lớn hơn, như sử dụng thông tin lịch sử để nâng cao bộ ước lượng gradient ZO (Meier et al., 2019; Cheng et al., 2021), và khai thác độ thưa thớt gradient để giảm sự phụ thuộc ZO vào kích thước vấn đề (Wang et al., 2017; Cai et al., 2022; 2021; Balasubramanian & Ghadimi, 2018; Ohta et al., 2020; Gu et al., 2021b). Mặc dù độ thưa thớt gradient đã được sử dụng để cải thiện khả năng mở rộng quy mô (Bartoldson et al., 2023), chúng tôi đề xuất một chiến lược tiên tiến tận dụng các kỹ thuật tỉa mô hình để xác định và khai thác độ thưa thớt trong các tham số mạng nơ-ron một cách hiệu quả. Cách tiếp cận của chúng tôi ít hạn chế hơn so với các giả định độ thưa thớt gradient truyền thống và cho phép linh hoạt hơn trong việc lựa chọn những gì cần tỉa. Theo hiểu biết tốt nhất của chúng tôi, không có công trình nào trước đây đã chứng minh tính thực tiễn của tối ưu hóa ZO có thể mở rộng quy mô cho việc huấn luyện mô hình sâu mà không mất hiệu suất đáng kể so với đối tác FO.

DL không có lan truyền ngược. Học gradient tiến (Baydin et al., 2022; Ren et al., 2022; Silver et al., 2021; Belouze, 2022), được xây dựng dựa trên khả năng vi phân tự động chế độ tiến (AD) của các khung phần mềm DL hiện tại, không dựa vào sai phân hữu hạn để xấp xỉ gradient FO như tối ưu hóa ZO. Thay vào đó, nó dựa vào AD chế độ tiến để tính toán gradient tiến (theo hướng). Gradient này được thu được bằng cách chiếu gradient FO lên một vector hướng và là một ước lượng không thiên lệch của gradient FO (Baydin et al., 2022). Ngược lại, ước lượng gradient ZO dựa trên sai phân hữu hạn bị thiên lệch (Duchi et al., 2015; Liu et al., 2020a). Tuy nhiên, một hạn chế chính của học gradient tiến là nó yêu cầu truy cập đầy đủ vào phần mềm AD và mô hình sâu, làm cho nó không thực tế để giải quyết các vấn đề DL hộp đen. Những tiến bộ gần đây trong (Ren et al., 2022) đã cải thiện thêm khả năng mở rộng quy mô của học gradient tiến bằng cách sử dụng thông tin mô hình mức độ tinh hơn để thiết kế các hàm mục tiêu cục bộ đặc trưng cho kiến trúc. Các phương pháp DL không có BP khác được thúc đẩy bởi việc tìm kiếm một cách diễn giải sinh học của DL nhưng chia sẻ những hạn chế tương tự với học gradient tiến. Một số ví dụ bao gồm học theo lớp tham lam (Nøkland & Eidnes, 2019), liên kết đầu vào-trọng số cho mạng nơ-ron rộng trong chế độ kernel tiếp tuyến nơ-ron (NTK) (Boopathy & Fiete, 2022), thuật toán Forward-Forward (Hinton, 2022), Học Hebbian (Isomura & Toyoizumi, 2018; Moraitis et al., 2022), và gradient tổng hợp (Jaderberg et al., 2017).

3 TỐI ƯU HÓA ZO THÔNG QUA ƯỚC LƯỢNG GRADIENT DỰA TRÊN GIÁ TRỊ HÀM: NGẪU NHIÊN HAY THEO TỌA ĐỘ?
Bây giờ chúng tôi giới thiệu thiết lập tối ưu hóa ZO và thảo luận về hai sơ đồ ước lượng gradient ZO: ước lượng gradient theo tọa độ xác định (CGE) và ước lượng gradient theo vector ngẫu nhiên (RGE). Chúng tôi sẽ chứng minh lợi thế của CGE so với RGE cho việc huấn luyện DNN. Điều này truyền cảm hứng cho những cải tiến tiếp theo để mở rộng quy mô tối ưu hóa ZO dựa trên CGE.

Tối ưu hóa ZO và ước lượng gradient. Gọi ℓ(θ) biểu thị một hàm mất mát mà chúng ta muốn tối thiểu hóa trên các biến tối ưu hóa θ∈Rd (ví dụ, các tham số mô hình của một mạng nơ-ron). Bộ tối ưu ZO tương tác với hàm mục tiêu ℓ chỉ bằng cách gửi các đầu vào (tức là, các thực hiện của θ) và nhận các giá trị hàm tương ứng. Nó sửa đổi nhẹ thuật toán dựa trên gradient bậc một (FO) thường được sử dụng bằng cách xấp xỉ gradient FO thông qua các ước lượng gradient dựa trên giá trị hàm (Liu et al., 2020a). Điều này rất cần thiết khi việc vi phân tường minh khó khăn do tính chất hộp đen của hàm mất mát (Zhang et al., 2022c; Liu et al., 2020b; Chen et al., 2017), hoặc khi việc vi phân tường minh không mong muốn do mối quan tâm về hiệu quả năng lượng (Gu et al., 2021b; Liu et al., 2018a). RGE (Nesterov & Spokoiny, 2017; Ghadimi & Lan, 2013; Duchi et al., 2015; Spall, 1992) và CGE (Kiefer & Wolfowitz, 1952; Lian et al., 2016; Berahas et al., 2022) là hai bộ ước lượng gradient thường được sử dụng dựa trên sai phân hữu hạn của ℓ. RGE thu được sai phân hữu hạn thông qua các nhiễu loạn ngẫu nhiên của θ trong khi CGE sử dụng các nhiễu loạn theo tọa độ xác định của θ (Liu et al., 2020a). Các định nghĩa chính thức của chúng được đưa ra bởi

(RGE) ˆ∇θℓ(θ) = (1/q) ∑qi=1 [ℓ(θ+µui)−ℓ(θ)]/µ ui; (CGE) ˆ∇θℓ(θ) = ∑di=1 [ℓ(θ+µei)−ℓ(θ)]/µ ei, (1)

trong đó ˆ∇θℓ biểu thị một ước lượng của gradient FO ∇θℓ đối với θ. Trong (RGE), ui biểu thị một vector nhiễu loạn ngẫu nhiên, ví dụ, được rút từ phân phối Gaussian tiêu chuẩn N(0,I), µ > 0 là một kích thước nhiễu loạn (hay còn gọi là tham số làm trơn), và q là số lượng hướng ngẫu nhiên được sử dụng để thu được sai phân hữu hạn. Trong (CGE), ei biểu thị một vector cơ sở tiêu chuẩn, và [ℓ(θ+µei)−ℓ(θ)]/µ cung cấp ước lượng sai phân hữu hạn của đạo hàm riêng của ℓ(θ) tại tọa độ thứ i θi.

Các xấp xỉ sai phân hữu hạn trong (1) được thúc đẩy bởi đạo hàm theo hướng. Lấy RGE (với q=1) làm ví dụ. Khi µ→0, sai phân hữu hạn trong RGE hội tụ về đạo hàm theo hướng ℓ′(θ):=uT∇θℓ(θ) = limµ→0 [ℓ(θ+µui)−ℓ(θ)]/µ của hàm ℓ tại điểm θ theo hướng u (Urruty & Lemaréchal, 1993). Do đó, biểu thức ℓ′(θ)u cho ra E[ℓ′(θ)u] = E[(uuT)∇θℓ(θ)] = ∇θℓ(θ) (nhớ rằng E[uuT] = I). Điều này có nghĩa là ℓ′(θ)u là một ước lượng gradient không thiên lệch của ∇θℓ(θ) và xấp xỉ sai phân hữu hạn thiên lệch của nó được đưa ra bởi (1) (Duchi et al., 2015).

RGE hay CGE? Đầu tiên, chi phí truy vấn hàm cho RGE và CGE khác nhau, với RGE cần O(q) truy vấn và CGE cần O(d) truy vấn dựa trên (1). So với CGE, RGE có tính linh hoạt để chỉ định q < d để giảm số lượng đánh giá hàm. Mặc dù có hiệu quả truy vấn, vẫn không chắc chắn liệu RGE có thể mang lại độ chính xác thỏa đáng khi huấn luyện một mô hình sâu từ đầu. Để đạt được điều này, chúng tôi thực hiện một nghiên cứu sơ bộ trong đó chúng tôi huấn luyện một mạng nơ-ron tích chập (CNN) cơ bản với các kích thước khác nhau trên CIFAR-10, sử dụng cả RGE và CGE. Để đảm bảo so sánh công bằng về độ phức tạp truy vấn, chúng tôi đặt số lượng truy vấn q trong RGE bằng với kích thước vấn đề d được sử dụng trong CGE. Hình 2 trình bày độ chính xác kiểm tra của CNN đã học so với số lượng tham số mô hình (tương đương với số lượng truy vấn mô hình). Ở đây công thức huấn luyện được chỉ định bởi FO SGD, ZO RGE-based SGD, và ZO CGE-based SGD. Chúng tôi quan sát thấy rằng CGE có thể đạt được độ chính xác kiểm tra tương đương với huấn luyện FO và vượt trội đáng kể so với RGE. Thí nghiệm này làm nổi bật tính ưu việt của CGE so với RGE về độ chính xác tối ưu hóa ngay cả khi cái sau sử dụng q=d. Ưu điểm về độ chính xác này của CGE đặc biệt có giá trị khi huấn luyện các mạng nơ-ron phức tạp hơn.

Trong Phụ lục C, chúng tôi cung cấp một phân tích chi tiết về chi phí tính toán khi sử dụng CGE so với RGE. Chi phí thời gian liên quan đến độ sâu mô hình được hiển thị trong Hình A2. Và Bảng A1 đánh giá chi phí thời gian ước lượng gradient. Chúng tôi thấy rằng CGE thể hiện hiệu quả thời gian lớn hơn RGE. Mất hiệu quả tính toán của RGE là do nó cần tạo ra và tích hợp một vector nhiễu loạn d-chiều vào toàn bộ mô hình cùng lúc mỗi truy vấn. Dựa trên những lợi thế của CGE so với RGE về cả độ chính xác và hiệu quả tính toán, chúng tôi chọn CGE làm bộ ước lượng gradient ZO được ưa thích. Tuy nhiên, độ phức tạp truy vấn của CGE vẫn là một rào cản, vì nó tỷ lệ với kích thước mô hình d.

4 HUẤN LUYỆN ZO HỖ TRỢ ĐỘ THƯA THỚT: MỘT GÓC NHÌN TỈA VÀ HƠN NỮA
Một thuộc tính có giá trị của CGE là việc phân tách các sai phân hữu hạn qua các tọa độ, điều này gợi ý rằng việc giảm độ phức tạp truy vấn của CGE được liên kết với việc tỉa các trọng số mô hình đang được tối ưu hóa. Với điều này trong tâm trí, chúng tôi đề xuất tích hợp tối ưu hóa ZO với gradient được tỉa để thiết kế một thiên lệch quy nạp hiệu quả hơn cho việc huấn luyện mô hình sâu ZO. Đáng chú ý là độ thưa thớt đã được khám phá trong một số phương pháp tối ưu hóa ZO hiện có để cải thiện hiệu quả truy vấn của ước lượng gradient (Wang et al., 2017; Cai et al., 2022; 2021; Balasubramanian & Ghadimi, 2018; Ohta et al., 2020; Gu et al., 2021b). Tuy nhiên, công trình trước đây gặp phải hai hạn chế chính. Thứ nhất, độ thưa thớt chính xác được giả định trong gradient FO gốc, điều này đòi hỏi một phương pháp học thưa thớt bổ sung (như LASSO (Wang et al., 2017)) để phục hồi những gradient thưa thớt này từ các truy vấn hàm. Thứ hai, vẫn không rõ làm thế nào để tối ưu hóa mẫu thưa thớt thông qua một oracle ZO, vì phương pháp hiện có yêu cầu các phương pháp tỉa dựa trên heuristic quá mức (ví dụ, ngẫu nhiên (Gu et al., 2021b) hoặc độ lớn (Ohta et al., 2020; Zhang et al., 2022b) tỉa). Việc tăng độ thưa thớt quá mức cuối cùng sẽ hạn chế hiệu suất tối ưu hóa. Trong những gì sau đây, chúng tôi đề xuất một cách tiếp cận tỉa mới chỉ dựa vào các truy vấn mô hình, có hiệu quả tính toán, và có thể cải thiện độ chính xác tối ưu hóa ZO bằng cách tạo ra một độ thưa thớt gradient thích hợp.

ZO-GraSP: Tỉa mô hình thông qua oracle ZO. Khả năng nén của trọng số mô hình cho DL đã được nghiên cứu rộng rãi (Han et al., 2015; Frankle & Carbin, 2018; Ma et al., 2021; Zhang et al., 2022a;b; Blalock et al., 2020; Tanaka et al., 2020; Lee et al., 2018; Wang et al., 2020; Su et al., 2020; Diffenderfer et al., 2021). Ví dụ, giả thuyết vé số may mắn (Frankle & Carbin, 2018) đã chứng minh rằng một mạng nơ-ron dày đặc được khởi tạo ngẫu nhiên chứa một mạng con thưa thớt chất lượng cao. Tuy nhiên, các phương pháp tỉa hiệu quả hiện tại kết hợp huấn luyện mô hình như một bước trung gian (Frankle & Carbin, 2018; Ma et al., 2021; Zhang et al., 2022a; Diffenderfer & Kailkhura, 2021). Do đó, chúng không phù hợp để tìm độ thưa thớt thông qua một oracle ZO.

Để giải quyết thách thức trên, chúng tôi rút cảm hứng từ các phương pháp tỉa không cần huấn luyện, được gọi là tỉa-tại-khởi-tạo (Tanaka et al., 2020; Lee et al., 2018; Wang et al., 2020). Trong họ này, bảo tồn tín hiệu gradient (GraSP) (Wang et al., 2020) là một phương pháp để xác định tiên nghiệm thưa thớt của DL thông qua dòng gradient của một mạng được khởi tạo ngẫu nhiên. Mặc dù GraSP vẫn yêu cầu thông tin đạo hàm FO và bậc hai, chúng ta có thể ước lượng những đạo hàm này chỉ bằng cách sử dụng các truy vấn hàm để thiết kế phiên bản ZO của GraSP (được gọi là ZO-GraSP). Cụ thể, GraSP (Wang et al., 2020) gán điểm tỉa (được biểu thị bằng S) cho khởi tạo mô hình θ. Những điểm này phản ánh sự thay đổi trong dòng gradient sau khi tỉa các trọng số:

S = −θ⊙(Hg), H = ∇²θ,θℓ(θ), g = ∇θℓ(θ), (2)

trong đó nhớ rằng ℓ là hàm mất mát của việc huấn luyện mô hình, ⊙ biểu thị phép nhân theo từng phần tử, và Hg biểu thị tích Hessian-gradient. Sử dụng mô hình học ZO, chúng ta có thể đầu tiên xấp xỉ tích Hessian-gradient như sai phân hữu hạn giữa hai gradient (tức là, ∇θℓ(θ+µg) và ∇θℓ(θ)), theo hướng g với tham số làm trơn µ. Thứ hai, chúng ta thay thế gradient FO ∇θℓ bằng ước lượng gradient ZO ˆ∇θℓ được đưa ra trong (1). Kết hợp điều này cho ZO-GraSP:

ˆS := −θ⊙[ˆ∇θℓ(θ+µˆg)−ˆ∇θℓ(θ)]/µ. (3)

Trong thực tế, chúng tôi thấy rằng mặt nạ tỉa được xác định bằng cách xếp hạng các mục trong ˆS có khả năng chống chịu với lỗi ước lượng gradient ZO. Do đó, chúng tôi sử dụng RGE với một số lượng truy vấn tương đối nhỏ (q < d) để triển khai ZO-GraSP. Điều này giảm chi phí truy vấn hàm mà không làm tổn hại đến hiệu suất tỉa; xem Bảng A2 và Bảng A3 để có các lý giải thực nghiệm. Kết quả của chúng tôi cho thấy ZO-GraSP vượt trội đáng kể so với tỉa ngẫu nhiên và tạo ra các mô hình được tỉa với độ chính xác tương đương với FO-GraSP.

Tích hợp độ thưa thớt với CGE. Vì các sai phân hữu hạn trong CGE (1) có thể phân tách trên các trọng số, nên dễ dàng kết hợp độ thưa thớt vào CGE. Để duy trì những lợi ích về độ chính xác của việc huấn luyện các mô hình dày đặc, chúng tôi kết hợp độ thưa thớt gradient (trong CGE) thay vì độ thưa thớt trọng số. Điều này đảm bảo rằng chúng ta huấn luyện một mô hình dày đặc trong không gian trọng số, thay vì huấn luyện một mô hình thưa thớt nơi độ thưa thớt được xác định bởi ZO-GraSP được áp dụng trực tiếp. Gọi SZO-GraSP là tập hợp tọa độ của các trọng số mô hình chưa được tỉa được tìm thấy bởi ZO-GraSP. CGE được tạo ra bởi độ thưa thớt được đưa ra bởi

ˆ∇θℓ(θ) = ∑i∈SZO-GraSP [ℓ(θ+µei)−ℓ(θ)]/µ ei. (Sparse-CGE)

Rõ ràng là (Sparse-CGE) giảm độ phức tạp truy vấn của CGE gốc từ O(d) xuống O(|SZO-GraSP|), trong đó |SZO-GraSP| biểu thị số lượng phần tử của tập hợp tọa độ SZO-GraSP. Có thể tồn tại hai phương pháp trực tiếp để tích hợp (Sparse-CGE) vào tối ưu hóa ZO. M1: Phương pháp này liên quan đến việc xen kẽ giữa ZO-GraSP và tối ưu hóa ZO dựa trên CGE. Tại mỗi lần lặp, SZO-GraSP được cập nhật dựa trên các trọng số mô hình từ lần lặp trước đó và sau đó được sử dụng để xây dựng (Sparse-CGE) để cập nhật θ tại lần lặp hiện tại. M2: Phương pháp này liên quan đến việc thực hiện tỉa trước huấn luyện ZO. Tức là, ZO-GraSP được tiến hành tại khởi tạo mô hình, và SZO-GraSP kết quả được áp dụng cho (Sparse-CGE) và được giữ cố định trong quá trình huấn luyện. Cả M1 và M2 đều có hạn chế. M1 yêu cầu các lời gọi lặp lại tới ZO-GraSP để cập nhật SZO-GraSP, dẫn đến chi phí truy vấn cao hơn cho việc huấn luyện mô hình ZO. M2 giải quyết độ phức tạp truy vấn bằng cách thực hiện ZO-GraSP trước khi huấn luyện, nhưng nó chỉ có thể tạo ra một mô hình nhỏ hơn sau khi huấn luyện. Biết rằng các mô hình được tỉa nặng gặp phải suy giảm hiệu suất (ví dụ, mô hình thưa thớt 95% trong Bảng A2 ở Phụ lục D). Do đó, không phải là tầm thường để tích hợp ZO-GraSP với huấn luyện ZO do yêu cầu cân bằng hiệu quả truy vấn và hiệu quả huấn luyện. Để giải quyết điều này, chúng tôi đề xuất mẫu thưa thớt động hướng ZO-GraSP, tận dụng ZO-GraSP để xác định tỷ lệ tỉa theo lớp (LPRs) có thể nắm bắt khả năng nén DNN. Cách tiếp cận này chia sẻ bản chất tương tự với tỷ lệ thông minh được giới thiệu trong (Su et al., 2020). Cụ thể, chúng tôi thu được LPRs từ ZO-GraSP tại các trọng số được khởi tạo ngẫu nhiên trước khi huấn luyện ZO, điều này hiệu quả về truy vấn như M2. Tuy nhiên, không giống như M2, LPRs cho phép xáo trộn ngẫu nhiên các vị trí gradient thưa thớt trong θ chỉ khi những LPRs này được tuân thủ. Điều này cho phép chúng ta bắt chước M1 để xen kẽ giữa cập nhật trọng số mô hình và cập nhật SZO-GraSP, với cái sau đạt được bằng các mẫu thưa thớt được cập nhật ngẫu nhiên được hướng dẫn bởi LPR. Do đó, tối ưu hóa ZO có thể huấn luyện mô hình dày đặc bằng cách sử dụng (Sparse-CGE) được cập nhật lặp đi lặp lại với các mẫu thưa thớt động được hướng dẫn bởi LPRs. Nhìn chung, đề xuất của chúng tôi có hiệu quả truy vấn của M2 với hiệu quả huấn luyện của M1, dẫn đến một sự tích hợp cân bằng của ZO-GraSP vào huấn luyện ZO. Chúng tôi tóm tắt đường ống thuật toán trong Thuật toán 1 ở Phụ lục E, trong đó CGE và mẫu thưa thớt động hướng ZO-GraSP được mô tả rõ ràng trong một khung thống nhất. Chúng tôi cũng giới thiệu độc giả đến Phụ lục E để có thêm giải thích và so sánh với M1 và M2. Chúng tôi cung cấp một phân tích tỷ lệ hội tụ trong Phụ lục A.

5 CẢI THIỆN KHẢ NĂNG MỞ RỘNG QUY MÔ: TÁI SỬ DỤNG ĐẶC TRƯNG & SONG SONG HÓA TIẾN
Chúng tôi điều tra hai đặc tính của việc huấn luyện ZO có thể nâng cao thêm khả năng mở rộng quy mô triển khai: tái sử dụng đặc trưng và song song hóa tiến. Cái trước phân tách các đặc trưng trung gian khỏi các nhiễu loạn trọng số, trong khi cái sau sử dụng tính chất sai phân hữu hạn trong CGE để cho phép triển khai phân tán có thể mở rộng quy mô.

Tái sử dụng các đặc trưng trung gian. Như được hiển thị trong (1), CGE nhiễu loạn mỗi tham số theo từng phần tử. Do đó, người ta có thể tái sử dụng đặc trưng ngay trước lớp bị nhiễu loạn và thực hiện các hoạt động truyền tiến còn lại thay vì bắt đầu từ lớp đầu vào, như được minh họa trong Hình 1. Đặc tính trên của việc huấn luyện mô hình dựa trên CGE được gọi là 'tái sử dụng đặc trưng'. Cụ thể hơn, gọi fθ(x) là một mô hình sâu với các tham số θ và đầu vào x. Chúng ta có thể biểu thị fθ(x) như một hàm hợp thành đa lớp

fθ(x) = fθ>l(zl) = fθL◦fθL−1◦ ··· ◦ fθl+1 ◦ fθl◦ ··· ◦ fθ1(x), (4)

trong đó fθl biểu thị lớp thứ l của mô hình, L là tổng số lớp mô hình, và ◦ là phép toán hợp thành hàm. Dựa trên (4), nếu các nhiễu loạn trọng số theo tọa độ được áp dụng cho lớp thứ (l+1) và các lớp tiếp theo của nó (tức là, θ>l), các đầu ra của mô hình tương ứng với những trọng số bị nhiễu loạn này có thể được thu được hiệu quả bằng cách giữ các đặc trưng trung gian đến lớp thứ l (tức là, zl) nguyên vẹn. Hiệu quả này trở nên rõ ràng hơn khi nhiễu loạn các tham số của các lớp sâu hơn (tức là, cho một l lớn hơn). Hình 3 so sánh thời gian chạy của việc huấn luyện ZO dựa trên CGE có và không có tái sử dụng đặc trưng. Thực nghiệm, CGE với tái sử dụng đặc trưng thể hiện sự giảm 2× trong thời gian huấn luyện.

Song song hóa các sai phân hữu hạn theo tọa độ. CGE cho phép song song hóa việc huấn luyện mô hình do sự liên kết của các nhiễu loạn tham số với các lượt truyền tiến. Nếu tồn tại M quy trình (qua nhiều GPU), chúng ta có thể phân tách CGE (1) dựa trên tọa độ tham số của nó tạo ra

ˆ∇θℓ(θ) = ∑Mi=1 ˆgi, ˆgi := ∑j∈Si [ℓ(θ+µej)−ℓ(θ)]/µ ej, (5)

trong đó Si là tập hợp các tham số hoạt động được gán cho quy trình 1≤i≤M. Do đó, mỗi quy trình có thể thực hiện |Si| lượt truyền tiến. Thuộc tính phân tách này cho phép mở rộng quy mô các lượt truyền tiến thông qua các máy phân tán, có thể cải thiện đáng kể tốc độ huấn luyện. Chúng tôi gọi việc song song hóa cho các sai phân hữu hạn này là 'song song hóa tiến'. Đáng chú ý là song song hóa tiến khác với song song hóa dữ liệu thông thường được sử dụng cho huấn luyện FO phân tán (Goyal et al., 2017; You et al., 2018). Phương pháp của chúng tôi tránh bất kỳ mất mát hiệu suất nào có thể kết quả từ song song hóa dữ liệu bằng cách sử dụng kích thước batch quá lớn, có thể khiến bộ tối ưu bị mắc kẹt trong cực tiểu cục bộ không tối ưu do thiếu tính ngẫu nhiên.

6 THÍ NGHIỆM
Trong phần này, chúng tôi đầu tiên huấn luyện ResNet-20 cho phân loại hình ảnh tiêu chuẩn trên CIFAR-10, chứng minh khả năng mở rộng quy mô và khả năng tổng quát hóa so với các phương pháp học không gradient hiện có. Thứ hai, chúng tôi áp dụng DeepZero để tăng cường độ mạnh mẽ của một DNN hộp đen chống lại các cuộc tấn công đối kháng, nơi có quyền truy cập hạn chế vào mô hình có sẵn ở phía người bảo vệ. Cuối cùng, chúng tôi tận dụng DeepZero để thiết kế một hệ thống ML thông tin vật lý bằng cách kết hợp một bộ giải PDE khoa học vào vòng lặp huấn luyện để giảm các lỗi số, làm nổi bật khả năng của nó để giải quyết các vấn đề khoa học phức tạp.

6.1 NHIỆM VỤ PHÂN LOẠI HÌNH ẢNH
Thiết lập thí nghiệm. Nghiên cứu này tập trung vào việc huấn luyện ResNet-20 (với 270K tham số) trên CIFAR-10 cho phân loại hình ảnh. Chúng tôi áp dụng SGD (stochastic gradient descent) làm công thức huấn luyện FO, với weight decay 5×10−4 và momentum 0.9. Tỷ lệ học là 0.1, được điều chỉnh bởi một bộ lập lịch decay cosin. Trong tình huống huấn luyện ZO, chúng tôi thay thế gradient FO bằng (Sparse-CGE) với tham số làm trơn µ = 5×10−3. Khi triển khai ZO-GraSP (3), chúng tôi đặt ngân sách truy vấn q = 192 và sử dụng cùng µ như CGE. Trừ khi được chỉ định khác, tỷ lệ thưa thớt trọng số được chọn là 90% và các mẫu thưa thớt cụ thể được xác định bởi SR (Smart Ratio). Khi triển khai DeepZero (Thuật toán 2), chúng tôi chọn số epoch T = 50. Các thí nghiệm được chạy trên 4 GPU NVIDIA V100 nếu không được chỉ định khác. Chúng tôi so sánh DeepZero với huấn luyện FO và hai huấn luyện BP-free SOTA: Pattern Search (Chiang et al., 2023) và Input-Weight Alignment (Align-ada) (Boopathy & Fiete, 2022).

So sánh với huấn luyện FO. Trong Hình 4, chúng tôi so sánh độ chính xác của ResNet-20 được huấn luyện bằng DeepZero với hai biến thể được huấn luyện bằng công thức FO: (1) một ResNet-20 dày đặc thu được thông qua huấn luyện FO và (2) một ResNet-20 thưa thớt thu được thông qua huấn luyện FO dưới mẫu thưa thớt FO-GraSP. Như chúng ta có thể thấy, khoảng cách độ chính xác vẫn tồn tại giữa (1) và mô hình được huấn luyện với DeepZero trong chế độ thưa thớt từ 80% đến 99%. Điều này làm nổi bật thách thức của tối ưu hóa ZO cho việc huấn luyện mô hình sâu, nơi việc đạt được độ thưa thớt cao được mong muốn để giảm số lượng truy vấn mô hình trong (Sparse-CGE) để mở rộng quy mô lên ResNet-20. Đáng chú ý, trong chế độ thưa thớt từ 90% đến 99%, DeepZero vượt trội so với (2), thể hiện tính ưu việt của độ thưa thớt gradient trong DeepZero so với độ thưa thớt trọng số (tức là, huấn luyện trực tiếp một mô hình thưa thớt). Trong Phụ lục F, chúng tôi cung cấp quỹ đạo huấn luyện DeepZero (Hình A4), hiệu suất vs. thiết lập batch dữ liệu (Hình A5) và thời gian huấn luyện vs. số lượng GPU (Hình A6).

So sánh với pattern search (Chiang et al., 2023). Trong Hình 5, chúng tôi so sánh độ chính xác và chi phí thời gian chạy của DeepZero với Pattern Search (Chiang et al., 2023) cho việc huấn luyện mô hình sâu. Pattern Search đã được chứng minh là đạt được độ chính xác kiểm tra tương đương với SGD trong các chế độ mẫu thấp, tuy nhiên, hiệu quả khi số lượng mẫu dữ liệu tăng lên vẫn chưa rõ ràng. Để điều tra điều này, chúng tôi tiến hành thí nghiệm sử dụng DeepZero (với 90% độ thưa thớt gradient) và pattern search trên ResNet-20 với CIFAR-10, với các kích thước tập dữ liệu khác nhau từ 100 đến 32K. Chúng tôi duy trì số epoch tổng cố định là 40 cho cả hai phương pháp để đảm bảo so sánh công bằng. Kết quả cho thấy DeepZero vượt trội so với Pattern Search trong tất cả các chế độ dữ liệu, ngoại trừ trường hợp 100. Hơn nữa, sự cải thiện của DeepZero so với pattern search (trong cả độ chính xác và hiệu quả) mở rộng đáng kể với kích thước tập dữ liệu tăng lên, cho thấy khả năng mở rộng quy mô vượt trội của DeepZero.

So sánh với input-weight alignment (Boopathy & Fiete, 2022). Trong Bảng 1, chúng tôi trình bày so sánh giữa DeepZero và cách tiếp cận Align-ada (Boopathy & Fiete, 2022) cho việc huấn luyện mạng nơ-ron không có BP trên CIFAR-10. Mặc dù tồn tại các phương pháp huấn luyện BP-free khác (Lillicrap et al., 2014; Nøkland, 2016; Baydin et al., 2022), Align-ada nổi bật vì nó áp dụng cho việc huấn luyện mạng nơ-ron rộng và đạt được hiệu suất tối tiến trên CIFAR-10, ví dụ, vượt trội so với các phương pháp như feedback alignment (FA) (Lillicrap et al., 2014) và direct feedback alignment (DFA) (Nøkland, 2016). Để đảm bảo công bằng, chúng tôi áp dụng DeepZero cho kiến trúc CNN 8 lớp từ (Boopathy & Fiete, 2022) và so sánh hiệu suất với Align-ada ở các độ rộng mô hình khác nhau. Chúng tôi lưu ý rằng mạng độ rộng 512 là mô hình rộng nhất được huấn luyện sử dụng Align-ada. Ngược lại, mạng độ rộng lớn nhất mà chúng tôi huấn luyện với DeepZero là 64. Kết quả của chúng tôi cho thấy rõ ràng rằng DeepZero đạt được độ chính xác kiểm tra cao hơn đáng kể so với Align-ada, ngay cả khi huấn luyện với các mạng hẹp hơn. Điều này chứng minh rằng hiệu suất cải thiện của DeepZero được quy cho những lợi thế tối ưu hóa vốn có của nó, thay vì chỉ dựa vào việc sử dụng các mạng rộng hơn. Cuối cùng, đáng chú ý là Align-ada và các phương pháp BP-free khác dựa vào quyền truy cập vào đồ thị tính toán, làm cho chúng hiệu quả nhưng không phù hợp cho các ứng dụng hộp đen.

6.2 CÁC ỨNG DỤNG HỘP ĐEN KHÁC
Bảo vệ hộp đen chống lại các cuộc tấn công đối kháng. Vấn đề bảo vệ hộp đen phát sinh khi chủ sở hữu của một mô hình ML không sẵn sàng chia sẻ chi tiết mô hình với người bảo vệ chống lại các cuộc tấn công đối kháng (Zhang et al., 2022c; Verma et al., 2023). Điều này đặt ra thách thức cho các thuật toán tăng cường độ mạnh mẽ hiện có (Madry et al., 2017; Cohen et al., 2019; Salman et al., 2020) trực tiếp làm mạnh mẽ các mô hình ML hộp trắng bằng cách sử dụng huấn luyện FO. Để vượt qua thách thức này, tối ưu hóa ZO đã được giới thiệu trong (Zhang et al., 2022c) để thiết kế một hoạt động bảo vệ hộp trắng cho một bộ phân loại hình ảnh hộp đen dựa trên truy vấn. Để giải quyết những thách thức về chiều với ZO, ZO-AE-DS (Zhang et al., 2022c) giới thiệu một autoencoder (AE) giữa hoạt động bảo vệ denoised smoothing (DS) hộp trắng (cần được học) và bộ phân loại hình ảnh hộp đen. Bằng cách hợp nhất encoder của AE với module hộp đen, chiều của tối ưu hóa ZO được giảm; xem Hình A7 trong Phụ lục G để có tổng quan sơ đồ và (Zhang et al., 2022c) để biết chi tiết. Nhược điểm của ZO-AE-DS là mở rộng quy mô kém đến các tập dữ liệu độ phân giải cao (ví dụ, ImageNet) do sử dụng AE, điều này làm tổn hại đến độ trung thực của đầu vào hình ảnh cho bộ phân loại hình ảnh hộp đen và dẫn đến hiệu suất bảo vệ kém hơn. Ngược lại, DeepZero có thể trực tiếp học hoạt động bảo vệ được tích hợp với bộ phân loại hộp đen, mà không cần AE. Bảng 2 so sánh hiệu suất bảo vệ của DeepZero với bảo vệ FO (DS (Salman et al., 2020)) và ZO-AE-DS (Zhang et al., 2022c). Để đảm bảo so sánh công bằng, chúng tôi sử dụng cùng số lượng truy vấn (1152) cho mỗi ước lượng gradient. Theo (Zhang et al., 2022c), chúng tôi chọn một tập con 10 lớp của ImageNet làm tập huấn luyện. AE và bộ phân loại hộp đen lần lượt là DnCNN (Zhang et al., 2017) và ResNet-50. Hiệu suất bảo vệ được đánh giá bằng độ chính xác được chứng nhận (CA), theo thiết lập của (Salman et al., 2020; Zhang et al., 2022c). CA được định nghĩa bằng cách sử dụng bán kính nhiễu loạn đầu vào dựa trên chuẩn ℓ2 r, trong đó r lớn hơn cho thấy mối đe dọa đối kháng mạnh hơn. Chúng tôi giới thiệu độc giả đến Phụ lục G để biết thêm chi tiết thí nghiệm. Bảng 2 làm nổi bật rằng DeepZero liên tục vượt trội so với ZO-AE-DS về CA cho tất cả các giá trị r > 0. Quan trọng là khi r = 0, CA tương đương với độ chính xác kiểm tra tiêu chuẩn. Điều này cho thấy rằng DeepZero vượt trội so với ZO-AE-DS không chỉ trong độ mạnh mẽ đối kháng mà còn trong hiệu suất tổng quát hóa tổng thể.

DL kết hợp mô phỏng cho sửa lỗi PDE rời rạc hóa. Các phương pháp số, mặc dù có vai trò quan trọng trong việc cung cấp các mô phỏng thông tin vật lý, đi kèm với thách thức riêng của chúng: việc rời rạc hóa không tránh khỏi tạo ra các lỗi số. DL đã nhận được sự chú ý đáng kể để giải quyết vấn đề sửa lỗi này. Tính khả thi của việc huấn luyện một mạng nơ-ron sửa lỗi thông qua các tương tác vòng lặp với bộ giải phương trình đạo hàm riêng (PDE) lặp đi lặp lại, được gọi là 'solver-in-the-loop' (SOL), đã được chứng minh trong (Um et al., 2020). Mặc dù công trình hiện có tập trung vào việc sử dụng hoặc phát triển các trình mô phỏng có thể vi phân cho việc huấn luyện mô hình, chúng tôi mở rộng SOL bằng cách tận dụng DeepZero, cho phép sử dụng nó với các trình mô phỏng không thể vi phân hoặc hộp đen. Chúng tôi gọi phương pháp của chúng tôi là ZO-SOL và giới thiệu độc giả đến Hình A8 trong Phụ lục H để có tổng quan sơ đồ. Trong khung thí nghiệm này, mục tiêu là sửa đầu ra của một mô phỏng độ trung thực thấp (tức là, lưới thô) bằng cách sử dụng một DNN đã học để mô phỏng được sửa chữa liên kết chặt chẽ hơn với đầu ra của một mô phỏng độ trung thực cao (tức là, lưới tinh). Trong một nỗ lực để giảm lượng sửa chữa cần thiết bởi DNN, việc sửa chữa này được áp dụng tại mỗi bước thời gian mô phỏng và trạng thái mô phỏng được sửa chữa được cung cấp cho trình mô phỏng để tính toán bước thời gian tiếp theo. Đối với các thí nghiệm của chúng tôi, chúng tôi xem xét tiêu chuẩn động lực học chất lỏng wake flow 2D không ổn định từ (Um et al., 2020), trong đó có một thanh tĩnh mà chất lỏng chảy xung quanh, và sử dụng PhiFlow (Holl et al., 2020) làm trình mô phỏng. Chi tiết bổ sung về PDE, mất mát solver-in-the-loop, và kiến trúc DNN được đưa ra trong Phụ lục H. Hình 6 so sánh hiệu suất sửa lỗi kiểm tra của ZO-SOL (thông qua DeepZero) với ba phương pháp có thể vi phân được xem xét trong (Um et al., 2020): SRC (mô phỏng độ trung thực thấp mà không sửa lỗi), NON (huấn luyện không tương tác ngoài vòng lặp mô phỏng sử dụng dữ liệu mô phỏng độ trung thực thấp và cao được tạo trước), và FO-SOL (huấn luyện FO cho SOL cho một trình mô phỏng có thể vi phân). Lỗi mô phỏng cho mỗi phương pháp trong Hình 6 được đo như trung bình qua năm mô phỏng kiểm tra (với các số Reynolds khác nhau không được sử dụng trong tập huấn luyện của dữ liệu mô phỏng). Lỗi cho mỗi mô phỏng kiểm tra được tính như lỗi tuyệt đối trung bình (MAE) của mô phỏng được sửa chữa so với mô phỏng độ trung thực cao trung bình qua tất cả các bước thời gian mô phỏng. Chúng tôi triển khai DeepZero cho ZO-SOL theo thiết lập được sử dụng trong nhiệm vụ phân loại hình ảnh, ngoại trừ việc chọn 95% độ thưa thớt gradient. ZO-SOL và FO-SOL sử dụng 16 bước mở rộng trong hàm mất mát để cho phép hàm sửa chữa tương tác với trình mô phỏng trong quá trình huấn luyện. Kết quả cho thấy ZO-SOL đạt được bởi DeepZero vượt trội so với các tiêu chuẩn SRC và NON, và thu hẹp khoảng cách hiệu suất với FO-SOL, mặc dù chỉ có quyền truy cập dựa trên truy vấn vào trình mô phỏng. So sánh ZO-SOL với NON làm nổi bật triển vọng của ZO-SOL ngay cả khi được tích hợp với các trình mô phỏng hộp đen.

7 KẾT LUẬN
Bài báo này giới thiệu DeepZero, một khung được thiết kế để tăng cường khả năng mở rộng quy mô của tối ưu hóa ZO cho việc huấn luyện mạng sâu. Cụ thể, DeepZero tích hợp ước lượng gradient theo tọa độ, độ thưa thớt gradient được kích hoạt bởi tỉa ZO, tái sử dụng đặc trưng, và song song hóa tiến vào một đường ống huấn luyện thống nhất. Tận dụng những đổi mới này, DeepZero thể hiện cả hiệu quả và hiệu suất trong một loạt ứng dụng rộng lớn, bao gồm các nhiệm vụ phân loại hình ảnh và các tình huống DL hộp đen thực tế khác nhau. Mặc dù DeepZero đã đạt được tiến bộ đáng kể trong việc huấn luyện các mô hình DL trên các tập dữ liệu như ResNet-20 và CIFAR-10, điều quan trọng là phải thừa nhận rằng khả năng mở rộng quy mô vẫn là một thách thức đáng kể khi xử lý các mô hình thậm chí còn lớn hơn và các tập dữ liệu rộng lớn hơn. Các nghiên cứu tương lai để tăng tốc tối ưu hóa ZO cho DL là cần thiết. Ngoài ra, đáng giá để khám phá khả năng áp dụng của DeepZero trong các lĩnh vực khác, như các ứng dụng song sinh số liên quan đến các thực thể vật lý không thể vi phân, và huấn luyện trên thiết bị nơi chi phí tính toán của việc thiết lập đồ thị tính toán và lan truyền ngược không khả thi. Cuối cùng, chúng tôi giới thiệu độc giả đến Phụ lục I để thảo luận về tác động rộng lớn hơn của bài báo này.

THỪA NHẬN
Chúng tôi cảm ơn Bộ Năng lượng Hoa Kỳ thông qua Phòng thí nghiệm Quốc gia Lawrence Livermore dưới Hợp đồng DE-AC52-07NA27344 và Chương trình LLNL-LDRD dưới Dự án số 23-ER-030 (LLNL-CONF-849161) cho sự hỗ trợ của họ.

TÀI LIỆU THAM KHẢO
[Phần tài liệu tham khảo được giữ nguyên như bản gốc tiếng Anh]

# 2305.17701.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/datasets/2305.17701.pdf
# Kích thước file: 2564201 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
KOSBI: Một Bộ Dữ Liệu Để Giảm Thiểu Rủi Ro Thiên Kiến Xã Hội Hướng Tới Các Ứng Dụng Mô Hình Ngôn Ngữ Lớn An Toàn Hơn

Hwaran Lee1,2,⋆Seokhee Hong3,⋆,♯Joonsuk Park1,2,4
Takyoung Kim1,♯Gunhee Kim3Jung-Woo Ha1,2

1NAVER AI Lab2NAVER Cloud3Seoul National University4University of Richmond
{hwaran.lee, jungwoo.ha}@navercorp.com park@joonsuk.org
seokhee.hong@vision.snu.ac.kr gunhee@snu.ac.kr youngerous@gmail.com

Tóm tắt
Các mô hình ngôn ngữ lớn (LLM) không chỉ học được khả năng tạo văn bản tự nhiên mà còn cả những thiên kiến xã hội đối với các nhóm nhân khẩu học khác nhau từ dữ liệu thế giới thực. Điều này gây ra rủi ro nghiêm trọng khi triển khai các ứng dụng dựa trên LLM. Nghiên cứu và tài nguyên hiện tại không thể áp dụng ngay được tại Hàn Quốc do sự khác biệt về ngôn ngữ và văn hóa, cả hai yếu tố này đều ảnh hưởng đáng kể đến các thiên kiến và nhóm nhân khẩu học bị nhắm tới. Hạn chế này đòi hỏi các bộ dữ liệu thiên kiến xã hội được bản địa hóa để đảm bảo triển khai LLM an toàn và hiệu quả. Để giải quyết vấn đề này, chúng tôi trình bày KOSBI, một bộ dữ liệu thiên kiến xã hội mới gồm 34k cặp ngữ cảnh và câu bằng tiếng Hàn bao gồm 72 nhóm nhân khẩu học trong 15 danh mục. Chúng tôi phát hiện rằng thông qua kiểm duyệt dựa trên lọc, thiên kiến xã hội trong nội dung được tạo ra có thể giảm trung bình 16.47%p đối với HyperCLOVA (30B và 82B), và GPT-3.

1 Giới thiệu
Các mô hình ngôn ngữ lớn (LLM) có được khả năng tạo văn bản ấn tượng từ dữ liệu tiền huấn luyện quy mô lớn từ thế giới thực (Brown et al., 2020; Kim et al., 2021). Tuy nhiên, LLM cũng hấp thụ tính độc hại, như thiên kiến xã hội (Sheng et al., 2019; Wallace et al., 2019a). Điều này không thể bỏ qua vì rủi ro tạo ra nội dung độc hại cản trở việc sử dụng an toàn và khả năng thương mại hóa tiềm năng của các ứng dụng phía dưới khác nhau, như trợ lý AI (Dinan et al., 2022; Bai et al., 2022a). Để giảm thiểu tổn hại, nhiều nghiên cứu đã giải quyết việc phát hiện và giảm thiểu tính độc hại trong LLM (Blodgett et al., 2020; Ganguli et al., 2022). Mỗi nghiên cứu thường tận dụng các bộ dữ liệu nắm bắt một loại độc hại cụ thể, như thiên kiến xã hội (Sap et al., 2020; Nangia et al., 2020) hoặc lời nói thù hận (Warner và Hirschberg, 2012; Lee et al., 2022).

⋆Tác giả đóng góp ngang nhau.
♯Công việc này được thực hiện trong thời gian thực tập tại NAVER AI Lab.
Email tới: {hwaran.lee, jungwoo.ha}@navercorp.com, seokhee.hong@vision.snu.ac.kr

Các bộ dữ liệu này không chỉ đặc thù theo tác vụ mà còn đặc thù theo ngôn ngữ và văn hóa. Ví dụ, hãy xem xét lời nói thù hận được tạo ra ở Hàn Quốc và ở Hoa Kỳ. Ngoài ngôn ngữ, các nhóm nhân khẩu học bị nhắm tới chủ yếu cũng khác nhau—những người nữ quyền và người Hàn Quốc gốc Trung ở Hàn Quốc, trái ngược với người Mỹ gốc Phi và người Do Thái ở Hoa Kỳ (Jeong et al., 2022). Ngoài ra, các bộ dữ liệu độc hại hiện có bằng tiếng Hàn chủ yếu tập trung vào lời nói thù hận rõ ràng và chỉ xem xét một số lượng hạn chế các nhóm nhân khẩu học bị nhắm tới (Moon et al., 2020; Yang et al., 2022; Kang et al., 2022; Lee et al., 2022). Điều này đòi hỏi một bộ dữ liệu để giải quyết các thiên kiến xã hội đối với một tập hợp toàn diện hơn các nhóm nhân khẩu học ở Hàn Quốc để càng nhiều nhóm và người được bảo vệ.

Ở đây chúng tôi trình bày bộ dữ liệu Thiên kiến Xã hội Hàn Quốc (KOSBI), một bộ dữ liệu quy mô lớn gồm 34k cặp ngữ cảnh và câu bằng tiếng Hàn với các nhãn chủ yếu nắm bắt sự hiện diện của thiên kiến xã hội.1 Nó bao gồm 72 nhóm nhân khẩu học được nhắm tới trong 15 danh mục,2 điều này toàn diện hơn nhiều so với các bộ dữ liệu hiện có, như được thể hiện trong Bảng 2. Các danh mục bao gồm không chỉ những danh mục phổ biến như giới tính và tôn giáo mà còn những danh mục đặc biệt liên quan đến Hàn Quốc—ví dụ, tình trạng hôn nhân và khu vực xuất xứ trong nước, cả hai đều bao gồm các nhóm nhân khẩu học chịu thiên kiến xã hội trong nước thường xuyên hơn so với những nhóm khác. Do khó khăn trong việc thu thập từ web đủ dữ liệu cho từng nhóm nhân khẩu học trong số 72 nhóm, chúng tôi đã tận dụng HyperCLOVA (Kim et al., 2021) để tạo ra dữ liệu với việc học ngữ cảnh few-shot.

1Bộ dữ liệu KOSBI được phát hành với chú thích được dịch sang tiếng Anh cho những người không thông thạo tiếng Hàn tại https://github.com/naver-ai/korean-safety-benchmarks
2Các danh mục và nhóm nhân khẩu học được chọn dựa trên Tuyên ngôn Quốc tế về Nhân quyền (UDHR) và Ủy ban Nhân quyền Quốc gia Hàn Quốc (NHRCK).

--- TRANG 2 ---
Bộ dữ liệu # Inst. Nhóm Nhân khẩu học Nguồn Dữ liệu Bao gồm Nhãn Độc hại # Cat. # Nhóm Ngữ cảnh?
BEEP! (Moon et al., 2020) 9,341 - - Bình luận tin tức ✗ Lời nói thù hận, Thiên kiến
APEACH (Yang et al., 2022) 3,770 10 - Viết bằng tay ✗ Xúc phạm
KOLD (Jeong et al., 2022) 40,448 5 19 Tin tức, bình luận YouTube ✗(Tiêu đề) Xúc phạm
HateScore, Unsmile (Kang et al., 2022) 31,195 7 (hỗn hợp) Tin tức, bình luận cộng đồng trực tuyến ✗ Lời nói thù hận, Tục tĩu
K-MHaS (Lee et al., 2022) 109,692 7 - Bình luận tin tức ✗ Lời nói thù hận, Tục tĩu
KOSBI(Của chúng tôi) 34,214 15 72 Được tạo bởi LM ✓ Thiên kiến (Khuôn mẫu, Thành kiến, Phân biệt đối xử), Khác

Bảng 1: So sánh các Bộ dữ liệu Độc hại bằng tiếng Hàn.

shot learning (Gao et al., 2021; Mishra et al., 2022). Cụ thể hơn, chúng tôi đã tạo ra các câu và ngữ cảnh tương ứng của chúng—cũng là các câu về mặt ngữ pháp—cho các nhóm nhân khẩu học mục tiêu đã cho. Các ngữ cảnh và câu được tạo ra sau đó được chú thích bởi các nhân viên đám đông là an toàn hoặc không an toàn. Ở đây, các ngữ cảnh và câu không an toàn được dán nhãn thêm như biểu hiện của khuôn mẫu (thiên kiến nhận thức), thành kiến (thiên kiến cảm xúc), phân biệt đối xử (thiên kiến hành vi), và/hoặc khác, áp dụng phân loại của Fiske (2023),3 trong Hình 1.

Với KOSBI, chúng tôi giảm thiểu thiên kiến xã hội trong nội dung được tạo bởi LLM bằng cách sử dụng phương pháp kiểm duyệt dựa trên lọc, còn được gọi là rejection sampling (Ganguli et al., 2022). Để làm điều này, trước tiên chúng tôi đã huấn luyện một bộ phân loại câu an toàn sử dụng KOSBI. Sau đó, đối với một ngữ cảnh nhất định, mỗi LLM được sử dụng để tạo ra một nhóm các câu từ đó câu an toàn nhất được chọn bởi bộ phân loại. Đánh giá của con người cho thấy thiên kiến xã hội trong nội dung được tạo ra giảm trung bình 16.47% đối với cả ba mô hình được thử nghiệm—HyperCLOVA (82B), HyperCLOVA (30B), và GPT-3.

2 Các Nghiên cứu Liên quan
Giảm thiểu Thiên kiến trong Nội dung được tạo bởi LLM.
LLM được huấn luyện trên dữ liệu thế giới thực, thường chứa thiên kiến xã hội đối với các nhóm nhân khẩu học nhất định. Điều này, đến lượt nó, gây ra thiên kiến trong LLM (Xu et al., 2021a). Cho đến nay, nhiều tài nguyên đã được xuất bản để đo lường và giảm thiểu những thiên kiến như vậy trong LLM (Sap et al., 2020; Nangia et al., 2020; Nadeem et al., 2021). Một số trong số chúng được liên kết với các tác vụ cụ thể: giải quyết đồng tham chiếu để chống lại các hiện tượng như liên kết các nghề nghiệp nhất định với một giới tính cụ thể (Rudinger et al., 2018; Zhao et al., 2018), và trả lời câu hỏi để ngăn chặn các câu trả lời bị khuôn mẫu hóa đối với các danh mục thiên kiến nhất định như giới tính hoặc tình trạng kinh tế xã hội (Li et al., 2020; Parrish et al., 2022). Những tài nguyên này không hiệu quả đối với HyperCLOVA và các LLM khác được tiền huấn luyện trên kho ngữ liệu tiếng Hàn. Do đó, chúng tôi trình bày một tài nguyên mới bằng tiếng Hàn, nắm bắt các thiên kiến đối với các nhóm nhân khẩu học phổ biến ở Hàn Quốc. Ngoài ra, bộ dữ liệu của chúng tôi bao gồm một tập hợp toàn diện hơn nhiều các nhóm nhân khẩu học.

Phát hiện Lời nói Thù hận. Röttger et al. (2021) định nghĩa lời nói thù hận là "lạm dụng được nhắm vào một nhóm được bảo vệ hoặc các thành viên của nhóm đó vì là một phần của nhóm đó." Các tài nguyên được tạo ra để giúp phát hiện lời nói thù hận có thể được sử dụng để giảm lời nói thù hận được tạo ra bởi LLM, từ đó giảm thiểu tổn hại mà chúng có thể gây ra. Lưu ý rằng những tài nguyên này sử dụng nhiều tên gọi khác nhau có thể thay thế cho nhau phần lớn, ví dụ, lời nói thù hận (Warner và Hirschberg, 2012), ngôn ngữ lạm dụng (Wiegand et al., 2019), và ngôn ngữ độc hại (Gehman et al., 2020; Hartvigsen et al., 2022). Ngoài ra, khá nhiều tài nguyên dành cho đối thoại an toàn hơn (Sun et al., 2022; Xu et al., 2021b; Xenos et al., 2021; Kim et al., 2022). Trong khi đó, để phản ánh các ngôn ngữ và xã hội khác nhau, các nhà nghiên cứu đã tạo ra và đề xuất các kho ngữ liệu lời nói thù hận bằng tiếng Trung (Deng et al., 2022), tiếng Hà Lan (Demus et al., 2022), và tiếng Ả Rập (Mubarak et al., 2022). Tương tự như các tài nguyên nắm bắt thiên kiến xã hội, những tài nguyên này không hữu ích đối với LLM tiếng Hàn do sự khác biệt về ngôn ngữ và văn hóa. May mắn thay, một số tài nguyên bằng tiếng Hàn tồn tại, như được tóm tắt trong Bảng 1. Tuy nhiên, những tài nguyên này hoặc không chỉ định hoặc chỉ bao gồm một tập hợp con nhỏ các nhóm nhân khẩu học ở Hàn Quốc. Quan trọng hơn, chúng tập trung vào tục tĩu rõ ràng và các biểu hiện xúc phạm khác. Thay vào đó, bộ dữ liệu của chúng tôi nhắm vào các trường hợp không thể được xác định bằng các từ khóa cụ thể, như biểu hiện của khuôn mẫu, phân biệt đối xử, và thành kiến (không có tục tĩu rõ ràng) đối với 72 nhóm nhân khẩu học.

Liên kết An toàn của Mô hình Ngôn ngữ. Ngoài thiên kiến xã hội và lời nói thù hận, nhiều danh mục đã được đề xuất gần đây để tăng cường an toàn của các mô hình ngôn ngữ, như giá trị con người

3Để dán nhãn ngữ cảnh, thành kiến và phân biệt đối xử được kết hợp do số lượng hạn chế các trường hợp quan sát được trong nghiên cứu thí điểm.

--- TRANG 3 ---
ues (Solaiman và Dennison, 2021; Kenton et al., 2021), phán đoán đạo đức (Hendrycks et al., 2021; Lourie et al., 2021), và chuẩn mực đạo đức (Forbes et al., 2020; Emelin et al., 2021). Sau đó, các phương pháp học liên kết thông qua phản hồi con người (Bai et al., 2022a) hoặc thậm chí bằng phản hồi AI (Bai et al., 2022b) đã được đề xuất. Hơn nữa, các phương pháp red-teaming (Perez et al., 2022; Ganguli et al., 2022) và tấn công đối nghịch (Wallace et al., 2019b) cũng đã được đề xuất để xác định các lỗ hổng trong mô hình ngôn ngữ về mặt an toàn. Chúng tôi hy vọng bộ dữ liệu và các danh mục toàn diện của chúng tôi sẽ hữu ích cho việc liên kết an toàn của xã hội Hàn Quốc.

3 Bộ Dữ liệu KOSBI
Nghiên cứu này nhằm mục đích giải quyết thiên kiến xã hội đối với một tập hợp toàn diện các nhóm nhân khẩu học ở Hàn Quốc để làm cho LLM an toàn hơn cho càng nhiều nhóm và người càng tốt. (Ở đây, chúng tôi tập trung vào thiên kiến xã hội mà không có lời nói thù hận rõ ràng, vì các bộ dữ liệu hiện có giải quyết vấn đề sau.) Để đạt được điều này, chúng tôi muốn KOSBI bao gồm các cặp ngữ cảnh-câu được dán nhãn là an toàn hoặc không an toàn cho các nhóm nhân khẩu học được đề cập trong chúng; theo cách này, chúng tôi có thể huấn luyện LLM để hành xử an toàn trong bối cảnh thảo luận về một nhóm nhân khẩu học, thay vì chỉ đơn giản là tránh nó.

3.1 Biên soạn Nhóm Nhân khẩu học
Với mục tiêu bao gồm một danh sách toàn diện các nhóm nhân khẩu học, trước tiên chúng tôi đã biên soạn danh sách bằng cách kết hợp các danh mục được rút ra từ Tuyên ngôn Quốc tế về Nhân quyền (UDHR) và Ủy ban Nhân quyền Quốc gia Hàn Quốc (NHRCK)4, cấm đối xử phân biệt dựa trên bản sắc xã hội. (Xem Bảng 4 để biết danh sách các danh mục.) Sau đó, chúng tôi định nghĩa các nhóm xã hội trong mỗi danh mục, xem xét các đặc điểm độc đáo của văn hóa Hàn Quốc. Ví dụ, chúng tôi xem xét các tôn giáo được thực hành rộng rãi nhất ở Hàn Quốc, và cũng các đảng chính trị tiến bộ và bảo thủ, thay vì các đảng Dân chủ và Cộng hòa ở Hoa Kỳ. (Xem Bảng 8 để biết danh sách các nhóm nhân khẩu học.)

3.2 Xây dựng Dữ liệu Thô
Vì việc thu thập từ web các cặp ngữ cảnh-câu đầy đủ cho mỗi nhóm nhân khẩu học sẽ gặp khó khăn, chúng tôi đã tạo ra chúng bằng cách sử dụng

4Cụ thể, tham khảo các quy định liên quan đến hành vi phân biệt đối xử vi phạm quyền bình đẳng – Điều 2 Tiểu đoạn 3 của Luật Ủy ban Nhân quyền Quốc gia, và Điều 3 Đoạn 1 Tiểu đoạn 1 của Luật Chống Phân biệt đối xử.

Danh mục # Nhóm
Bản sắc giới tính† 3
Khuynh hướng tính dục† 1
Tuổi tác & Thế hệ† 12
Chủng tộc, Dân tộc, Quốc tịch† 11
Tôn giáo† 6
Tình trạng khuyết tật† 1
Ngoại hình† 4
Khuynh hướng chính trị† 3
Tình trạng kinh tế xã hội† 3
Khu vực xuất xứ trong nước 8
Tình trạng hôn nhân 6
Thai kỳ & Sinh đẻ 4
Hình thức gia đình 5
Tiền án tiền sự 2
Giáo dục, Đại học, Chuyên ngành 3
Tổng cộng 72

Bảng 2: Danh mục và nhóm nhân khẩu học được xem xét trong KOSBI. † đánh dấu các danh mục trong cả UDHR và NHRCK. Toàn bộ các nhóm xã hội được liệt kê trong Bảng 8.

HyperCLOVA. LLM được báo cáo là có khả năng học một tác vụ nhất định từ hướng dẫn và mẫu minh chứng few-shot, được gọi là học ngữ cảnh (Brown et al., 2020). Với những khả năng này, nghiên cứu trước đó đã đề xuất các phương pháp tổng hợp dữ liệu bằng phương pháp nhắc nhở dựa trên minh chứng (Gao et al., 2021; Mishra et al., 2022), trong đó một số câu mẫu được liệt kê trong một lời nhắc, và một LLM tạo ra những câu khác nhau với ngữ nghĩa tương tự. Để xây dựng KOSBI, chúng tôi đã áp dụng việc nhắc nhở dựa trên minh chứng và tạo ra các cặp ngữ cảnh và câu với một nhóm xã hội mục tiêu sử dụng HyperCLOVA.

Việc xây dựng dữ liệu thô được thực hiện trong ba bước: (1) xây dựng các nhóm minh chứng, bao gồm dữ liệu được dán nhãn ban đầu; (2) tạo ra ngữ cảnh và câu; (3) lọc ra các sinh ra không phù hợp bằng các bộ phân loại có thể huấn luyện được. Dữ liệu minh chứng ban đầu được chọn lọc thủ công bởi các tác giả và một số chú thích viên, dẫn đến một nhóm tương đối nhỏ khoảng 2165 mẫu. Điều này có thể hạn chế tính đa dạng của kết quả sinh ra và độ chính xác của các mô hình lọc. Để giải quyết hạn chế này, chúng tôi đã tạo ra dữ liệu một cách tăng dần bằng cách lặp lại các bước 1-3 để cập nhật các nhóm minh chứng và huấn luyện lại các bộ phân loại lọc sau mỗi lần lặp.

Các lời nhắc chi tiết có thể được tìm thấy trong Phụ lục C. Trong lời nhắc ngữ cảnh, LLM được yêu cầu tạo ra "các câu ngữ cảnh trung tính" liên quan đến nhóm xã hội đã cho. Tuy nhiên, mô hình thường tạo ra các câu thiên kiến do thiên kiến nội tại. Chúng tôi dán nhãn chúng là ngữ cảnh không an toàn. Trong trường hợp sinh câu, chúng tôi đã tách các nhóm minh chứng không an toàn và an toàn và hướng dẫn cho việc sinh câu có điều kiện lớp.

Ở bước lọc ngữ cảnh, mô hình lọc phân loại các câu được tạo ra liên quan đến nhân khẩu học mục tiêu, và các chú thích viên chỉ dán nhãn các đầu ra được điều kiện tốt. Ở bước lọc câu, mặt khác, chúng tôi đầu tiên tạo ra quá nhiều câu cho mỗi ngữ cảnh, tức là ba câu cho mỗi lớp. Sau đó chúng tôi chọn câu mơ hồ nhất cho một bộ phân loại câu an toàn để dán nhãn. Tính mơ hồ được đo bằng biến thiên tối đa ước tính (Liu et al., 2022; Swayamdipta et al., 2020). Do đó, bằng cách loại trừ các mẫu rõ ràng và dễ học trong bộ dữ liệu, quá trình lọc này phục vụ để đảm bảo rằng bộ dữ liệu được xây dựng có mức độ khó khăn phù hợp.

5Trong nhóm minh chứng ban đầu, chúng tôi thu thập ba cặp ngữ cảnh-câu an toàn và ba cặp không an toàn cho mỗi nhóm nhân khẩu học. Các mẫu minh chứng ban đầu và tất cả dữ liệu sinh ra được dán nhãn sẽ được công bố.

--- TRANG 4 ---
Hình 1: Các cặp ví dụ về ngữ cảnh và câu với nhãn liên quan đến danh mục và nhóm nhân khẩu học xã hội đã cho.

3.3 Chú thích
Các ngữ cảnh và câu sau đó được dán nhãn bởi các nhân viên đám đông theo các hướng dẫn sau (Xem Hình 1 để biết ví dụ):

• Ngữ cảnh. Vai trò của ngữ cảnh là thể hiện một kịch bản trong đó một LLM cần nói về một nhóm nhân khẩu học. Mỗi ngữ cảnh được tạo ra đầu tiên được chú thích là an toàn nếu nó chỉ chứa thông tin khách quan và do đó không gây tổn hại cho nhóm nhân khẩu học được nhắm tới, và không an toàn, nếu không. Nếu được dán nhãn không an toàn, nó được dán nhãn thêm như một biểu hiện của 1) khuôn mẫu (thiên kiến nhận thức), 2) thành kiến (thiên kiến cảm xúc), 3) phân biệt đối xử (thiên kiến hành vi), và/hoặc 4) khác, áp dụng phân loại của Fiske (2023). Ở đây, các lớp phụ 2 và 3 được kết hợp do sự xuất hiện hiếm hoi được quan sát trong nghiên cứu thí điểm.

• Câu. Mỗi câu được tạo ra cho một ngữ cảnh nhất định được chú thích đầu tiên là an toàn hoặc không an toàn, tùy thuộc vào việc nó có gây tổn hại cho nhóm nhân khẩu học được nhắm tới hay không. Nếu được dán nhãn không an toàn, câu được dán nhãn thêm như một biểu hiện của một trong các loại thiên kiến hoặc khác, giống như trên, ngoại trừ các lớp phụ 2 và 3 không được kết hợp lần này. Lưu ý, một câu có vẻ an toàn có thể không an toàn tùy thuộc vào ngữ cảnh của nó. Ví dụ, một câu đơn giản đồng ý (ví dụ, "Vâng, đó là sự thật.") với một ngữ cảnh không an toàn (ví dụ, "[Nhóm Nhân khẩu học] luôn lười biếng.") là không an toàn. Trong những trường hợp như vậy, nó được đánh dấu thêm là (ngầm), và (rõ ràng) nếu câu đó không an toàn tự nó.

Ngữ cảnh Câu Train Valid Test Tất cả
An toàn An toàn 11,630 1,427 1,382 14,439
Không an toàn 8,521 1,060 1,092 10,673
Tổng cộng 20,151 2,487 2,474 25,112

Không an toàn An toàn 2,537 320 317 3,174
Không an toàn 4,589 596 617 5,802
Tổng cộng 7,126 916 934 8,976

Không quyết định An toàn 58 45 7 6
Không an toàn 68 48 11 9
Tổng cộng 93 18 15 126

Tổng cộng 27,370 3,421 3,423 34,214

Bảng 3: Số lượng trường hợp cho tất cả các kết hợp nhãn trong KOSBI. (Tham khảo Bảng 7 để biết lớp phụ.)

Để dán nhãn các đầu ra được lọc, 200 nhân viên đám đông được liên kết qua một phạm vi rộng các nhân khẩu học xã hội đã được thuê (Bảng 12). Thông tin phúc lợi chi tiết của người lao động có thể được tìm thấy trong Phụ lục C. Họ đánh giá chất lượng của ngữ cảnh và câu về mặt khả năng hiểu và sự nhất quán giữa các cặp. Dữ liệu không đáp ứng tiêu chí đã được loại trừ. Sau đó họ được yêu cầu dán nhãn chúng. Cụ thể, trong trường hợp các câu không an toàn, họ được yêu cầu tìm các nhóm xã hội được nhắm tới trong cặp ngữ cảnh-câu để có thể giải thích được. Hướng dẫn chú thích được thể hiện trong Phụ lục H.

Trong bước đánh giá con người, ba nhân viên đám đông đã chú thích ngữ cảnh và câu, và các nhãn cuối cùng được quyết định bằng bỏ phiếu đa số. Đầu tiên, trong việc dán nhãn ngữ cảnh là an toàn hoặc không an toàn, sự đồng ý giữa các chú thích viên bằng α của Krippendorff là 0.459 cho các lớp nhị phân (an toàn/không an toàn). Sự đồng ý

--- TRANG 5 ---
Bộ dữ liệu Mô hình Macro F1 (%)
BEEP! KcBERT 52.90
APEACH KcBERT 48.82
KOLD KLUE-BERT 38.15
Hatescore KcBERT 40.28
Unsmile KcBERT 48.02
Của chúng tôi KLUE-BERT 69.94
Của chúng tôi KcELECTRa 71.21

Bảng 4: So sánh hiệu suất phân loại trên tập kiểm tra của chúng tôi. Các mô hình được tinh chỉnh trên các bộ dữ liệu trước đó và của chúng tôi được so sánh.

thấp hơn nếu chúng tôi xem xét các lớp phụ của ngữ cảnh không an toàn (α = 0.359). Đối với chú thích câu, α là 0.256 để dán nhãn chúng là an toàn hoặc không an toàn. Điều này cho thấy việc xác định nhãn cho các câu là khó khăn hơn. Điều này được mong đợi vì cả ngữ cảnh và câu đều cần được xem xét để dán nhãn một câu, trong khi ngữ cảnh là tự chứa.

3.4 Bộ Dữ liệu Kết quả
KOSBI bao gồm 34,214 cặp ngữ cảnh-câu như được tóm tắt trong Bảng 3. Có 25,112 (73.4%) và 8,976 (26.2%) ngữ cảnh an toàn và không an toàn, tương ứng. Ngoài ra, có 17,619 (51.5%) và 16,484 (48.2%) câu an toàn và không an toàn. Tập huấn luyện, xác thực, và kiểm tra được tách ngẫu nhiên thành 80%, 10%, và 10%, tương ứng, xem xét sự cân bằng của phân phối nhóm xã hội.

4 Kết quả Thực nghiệm
Để cải thiện an toàn của LLM đối với các nhóm xã hội, chúng tôi khám phá một phương pháp kiểm duyệt dựa trên lọc đơn giản. Trong phần này, chúng tôi đầu tiên xây dựng một phân loại câu an toàn. Sau đó chúng tôi đánh giá tự động việc sinh ra của LLM với một ngữ cảnh với bộ phân loại an toàn. Cuối cùng, chúng tôi lấy mẫu câu an toàn nhất trong số các ứng cử viên câu được sinh ra quá nhiều. Hiệu quả của phương pháp lọc được chứng minh bằng đánh giá con người.

4.1 Phân loại Câu An toàn
Chúng tôi huấn luyện bộ phân loại câu an toàn bằng cách tinh chỉnh KLUE-BERT (Park et al., 2021) và KcELECTRa (Lee, 2021)6. Để xác định các câu không an toàn trong ngữ cảnh, ngữ cảnh và câu được nối với nhau và sau đó đưa vào các mô hình. Chúng tôi cũng đơn giản tăng cường dữ liệu bằng cách sử dụng dữ liệu ngữ cảnh và nhãn của chúng, dẫn đến macro-F1 tốt nhất là 71.21% như được thể hiện trong Bảng 4. Hiệu suất ngụ ý rằng bộ dữ liệu đề xuất là thách thức.

6Chúng tôi sử dụng phiên bản mới nhất của mô hình: https://huggingface.co/beomi/KcELECTRA-base-v2022.

Để xác thực tính mới lạ của bộ dữ liệu của chúng tôi, chúng tôi sử dụng các bộ phân loại được huấn luyện trên kho ngữ liệu lời nói thù hận tiếng Hàn trước đó: BEEP! (Moon et al., 2020), APEACH (Yang et al., 2022), KOLD (Jeong et al., 2022), Hatescore, và Unsmile (Kang et al., 2022) để đánh giá tập kiểm tra của KOSBI7. Kết quả, trong Bảng 4, tất cả các bộ phân loại nhất quán cho thấy độ chính xác kém, gần với phỏng đoán ngẫu nhiên. Những hiệu suất kém này mạnh mẽ gợi ý rằng bộ dữ liệu của chúng tôi không giống với các kho ngữ liệu hiện có, chủ yếu giải quyết lời nói thù hận tiếng Hàn. Sự khác biệt như vậy có thể bắt nguồn từ thực tế rằng bộ dữ liệu của chúng tôi bao gồm các trường hợp lời nói thù hận phụ thuộc ngữ cảnh và ngầm, trái ngược với các trường hợp công khai và rõ ràng được tìm thấy trong kho ngữ liệu trước đó có nguồn gốc từ bình luận nền tảng trực tuyến.

4.2 Đánh giá An toàn của LLM
Sử dụng bộ phân loại câu an toàn, chúng tôi đo lường việc sinh ra an toàn của LLM. Tương tự như Gehman et al. (2020), chúng tôi đánh giá các mô hình với hai chỉ số. Đầu tiên, xác suất thực nghiệm của việc sinh ra một câu an toàn (điểm an toàn ≥ 0.5) cho một ngữ cảnh ít nhất một lần qua nhiều lần sinh k. Chúng tôi đo xác suất với các kích thước k khác nhau. Xác suất an toàn càng cao, đầu ra được điều chỉnh lọc càng thường xuyên an toàn. Chỉ số thứ hai là điểm an toàn trung bình mong đợi của các câu an toàn qua k = 8 lần sinh. Điều này có nghĩa là an toàn trung bình mong đợi càng cao, mô hình có khả năng sinh ra nhiều câu an toàn hơn trung bình.

Chúng tôi đánh giá HyperCLOVA với các kích thước mô hình khác nhau (6.9B, 13B, 30B, và 82B), và GPT-3 (175B)8. Chúng tôi lấy mẫu một tập hợp con của tập kiểm tra để chứa 30 ngữ cảnh cho mỗi danh mục nhân khẩu học, tức là tổng cộng 450 ngữ cảnh. Các LLM sinh ra các câu cho các ngữ cảnh trong thiết lập sinh zero-shot. Lời nhắc được sử dụng cho thí nghiệm này được liệt kê trong Phụ lục C.

Bảng 5 trình bày kết quả đánh giá. Đầu tiên, xác suất thực nghiệm của việc sinh ra các câu an toàn

7Để so sánh công bằng, chúng tôi sử dụng các checkpoint kích thước BERT-base đã được công bố của mỗi mô hình. Các bộ phân loại ngoại trừ KOLD được tiền huấn luyện trên KcBERT (Lee, 2020). Đối với KOLD, chúng tôi tinh chỉnh thủ công bộ dữ liệu KOLD trên KLUE-BERT bằng cách theo thiết lập thí nghiệm của bài báo vì không có checkpoint được chia sẻ công khai hay phân chia train/valid/test.

8Mô hình HyperCLOVA lớn nhất (82B) được huấn luyện trên HyperCLOVA Corpus bao gồm 300B token, và phần còn lại được huấn luyện thêm với 30B của bộ dữ liệu nói. Phiên bản 'text-davinci-003' được sử dụng làm mô hình GPT-3. Cũng lưu ý rằng các mô hình HyperCLOVA không được huấn luyện bằng instruction-tuning hoặc reinforcement learning from human feedback, tương tự như 'text-davinci-003'.

--- TRANG 6 ---
Mô hình Xác suất An toàn An toàn Trung bình Mong đợi
k=1 2 4 8

GPT-3 (175B) .809 .902 .956 .969 .625 ±.083
HyperClova (6.9B) .673 .796 .796 .876 .589 ±.102
HyperClova (13B) .713 .789 .789 .862 .581 ±.096
HyperClova (30B) .711 .844 .844 .900 .588 ±.105
HyperClova (82B) .647 .813 .813 .887 .575 ±.100

Bảng 5: Đánh giá an toàn của các câu tiếp theo của LLM sau khi được cho ngữ cảnh. Trái: Xác suất thực nghiệm của việc sinh ra câu an toàn ít nhất một lần qua k lần sinh. Phải: Điểm an toàn trung bình mong đợi của các câu an toàn với độ lệch chuẩn qua 8 lần sinh.

Hình 2: Đánh giá con người trên tập hợp con của tập kiểm tra. Chúng tôi so sánh hai mô hình HyperCLOVA (82B và 30B) và mô hình GPT-3 (175B; text-davinci-003), đối với cả có và không có lọc.

tăng khi việc sinh ra tăng đối với tất cả LLM. Nói cách khác, khi HyperCLOVA-82B sinh ra 8 câu trên mỗi ngữ cảnh, 88.7% các câu tiếp theo an toàn đối với mô hình phân loại. Đáng chú ý, càng nhiều lần sinh ra quá mức, an toàn càng được cải thiện.

Tiếp theo, đối với trung bình mong đợi của điểm an toàn, chúng tôi không thể tìm thấy sự khác biệt rõ rệt giữa các kích thước khác nhau của HyperCLOVA. Nhìn chung, GPT-3 cho thấy xác suất an toàn và điểm số được cải thiện hơn so với HyperCLOVA theo các đánh giá tự động.

Hơn nữa, chúng tôi chia kết quả thành những kết quả được sinh ra từ một ngữ cảnh an toàn và một ngữ cảnh không an toàn để đo lường cách an toàn của ngữ cảnh ảnh hưởng đến câu tiếp theo của mô hình. Như có thể thấy bằng cách so sánh cả hai kết quả được trình bày trong Bảng 9, các mô hình sinh ra nhiều câu không an toàn hơn khi một ngữ cảnh không an toàn được đưa ra, trong khi tất cả các mô hình sinh ra 99% câu tiếp theo an toàn khi được điều kiện hóa trên một ngữ cảnh an toàn trong thiết lập k = 8.

4.3 Kiểm duyệt Dựa trên Lọc
Chúng tôi chứng minh hiệu quả của kiểm duyệt dựa trên lọc của việc sinh ra câu không an toàn. Phương pháp lọc lấy mẫu câu an toàn nhất trong số 8 lần sinh. Chúng tôi tiến hành một thí nghiệm đánh giá con người để đánh giá chất lượng và an toàn của kết quả sinh ra. Kết quả đánh giá của ba mô hình — GPT-3, HyperCLOVA 30B, và 82B được so sánh trong Hình 2 và Bảng 6.

Hình 3: Kết quả kiểm duyệt trên mỗi danh mục trong tập kiểm tra tăng cường. Trái: Tỷ lệ phản hồi an toàn từ kết quả đánh giá con người. Phải: Hiệu suất phân loại câu an toàn của bộ phân loại tốt nhất (KcELECTRa). Các đường dọc thể hiện trung bình của phản hồi an toàn và độ chính xác cho tất cả các danh mục. Các danh mục được sắp xếp theo thứ tự giảm dần của độ chính xác của bộ phân loại.

Với quá trình lọc, chúng tôi thấy rằng tỷ lệ sinh ra không an toàn giảm đối với tất cả các mô hình trung bình 16.47%p. Chúng tôi quan sát rằng kiểm duyệt dựa trên lọc cải thiện đáng kể an toàn của tất cả LLM bằng cách giảm sinh ra không an toàn lần lượt là 16%, 15%, và 18.5% và bằng cách tăng các câu an toàn lần lượt là 15.6%, 15.3%, và 18.7% đối với GPT-3, HyperCLOVA-82B, và HyperCLOVA-30B. Thật thú vị là tỷ lệ các câu mơ hồ được sinh ra bởi GPT-3 không giảm mặc dù có lọc.

Bảng 6 trình bày kết quả chất lượng của các câu được sinh ra bởi mỗi mô hình và tác động của kiểm duyệt dựa trên lọc. Không nhất quán với kết quả trong Hình 2, kiểm duyệt dựa trên lọc không cải thiện chất lượng của các câu được sinh ra. Điều này có nghĩa là lọc có khả năng hy sinh một chút tính nhất quán của việc sinh ra bằng cách đóng vai trò như những ràng buộc như một tác dụng phụ chống lại việc tăng cường an toàn. Tuy nhiên, điểm chất lượng tổng thể của tất cả LLM đủ cạnh tranh, và HyperCLOVA thể hiện hiệu suất chất lượng tốt hơn GPT-3, nhất quán với kết quả trong Hình 2.

4.4 Mức độ Giảm thiểu Thiên kiến Xã hội theo Danh mục
Chúng tôi phân tích kết quả kiểm duyệt theo 15 danh mục nhân khẩu học. Trước khi có kết quả, chúng tôi đã tăng cường tập kiểm tra với dữ liệu chú thích bổ sung để tăng số lượng mẫu trên mỗi danh mục và độ tin cậy của kết quả kiểm tra. Kết quả, tập kiểm tra tăng cường của chúng tôi bao gồm 6,801 cặp (ngữ cảnh, câu).

--- TRANG 7 ---
Đánh giá Chất lượng
Không có Lỗi Ngữ pháp (%) Khả năng Hiểu (%) Liên quan đến Nhóm Xã hội Mục tiêu (%) Ngữ cảnh (%) Tính nhất quán Tổng thể (%)

GPT-3 (175B) 89.8 80.2 90.0 71.6 32.0
GPT-3 (175B) + lọc 89.3 80.9 87.3 69.1 31.6
HyperCLOVA (80B) 99.1 97.1 93.6 89.6 49.3
HyperCLOVA (80B) + lọc 99.6 96.2 93.3 88.9 54.0
HyperCLOVA (30B) 99.3 98.2 95.8 93.8 61.6
HyperCLOVA (30B) + lọc 100 97.3 94.7 91.6 56.9

Bảng 6: Đánh giá con người trên tập hợp con của tập kiểm tra. So sánh giữa các phản hồi không được lọc và các phản hồi được lọc trong số 8 lần sinh từ GPT-3 (175B; 'text-davinci-003'), HyperClova (82B và 30B). Điểm tổng thể biểu thị tỷ lệ phần trăm các trường hợp được đánh dấu là vượt qua tất cả các câu hỏi đánh giá chất lượng bởi tất cả các người đánh giá.

câu) (xem Bảng 10 để biết thống kê chi tiết cho nó). Đối với các thí nghiệm được tiến hành trong phần này, chúng tôi lấy mẫu một tập hợp con nhỏ từ tập kiểm tra tăng cường để chứa ít nhất 48 ngữ cảnh trên mỗi danh mục, dẫn đến 1,746 ngữ cảnh. Tất cả các thiết lập khác tuân theo phần 4.3.

Hình 3 trình bày kết quả đánh giá con người của kiểm duyệt dựa trên lọc theo từng danh mục nhân khẩu học. Mỗi danh mục hiển thị một tỷ lệ khác nhau của các câu an toàn được sinh ra. Bằng cách so sánh có và không có kiểm duyệt dựa trên lọc, chúng tôi có thể nhận thấy rằng hiệu quả của quá trình lọc cũng khác nhau. Ví dụ, chúng tôi thấy sự gia tăng lớn nhất của tỷ lệ sinh ra an toàn trong danh mục Tình trạng khuyết tật (+64.0%) trong khi nhỏ nhất trong Tình trạng hôn nhân (+0.85%). Trong danh mục, sự khác biệt cũng tồn tại giữa các mô hình; như trong danh mục Tình trạng khuyết tật, HyperCLOVA-82B có sự gia tăng 33.3%p nhưng HyperCLOVA-30B chỉ có 4.1%p (Xem Hình 6 để biết kết quả theo nhóm cho cả ba mô hình).

Vì kiểm duyệt dựa trên lọc sử dụng một mô hình lọc, tự nhiên là giả định rằng có thể xuất hiện mối tương quan giữa hiệu suất của mô hình lọc và hiệu quả kiểm duyệt. Để xác định bất kỳ xu hướng nào giữa hai điều này, chúng tôi cũng đã bao gồm độ chính xác của mô hình lọc trong Hình 3. Tuy nhiên, chúng tôi không thể tìm thấy mối tương quan mạnh giữa chúng. Chúng tôi phỏng đoán lý do là sự khác biệt tương đối nhỏ về độ chính xác giữa các danh mục hoặc tập hợp được lấy mẫu được sử dụng ở đây không đủ lớn. Phân tích sâu hơn được mong đợi trong công việc tương lai. Mặc dù vậy, phương pháp kiểm duyệt dựa trên lọc chứng minh hiệu quả đối với tất cả các danh mục nhân khẩu học xã hội. Điều quan trọng là phải xem xét kỹ lưỡng và cải thiện an toàn của các mô hình để xem xét công bằng từng danh mục và nhóm nhân khẩu học.

5 Kết luận
Để giảm thiểu thiên kiến xã hội không an toàn của LLM, chúng tôi đề xuất một bộ dữ liệu thiên kiến xã hội quy mô lớn liên quan đến an toàn giải quyết ngôn ngữ và văn hóa Hàn Quốc, KOSBI. Bộ dữ liệu của chúng tôi bao gồm 72 nhóm nhân khẩu học trong 15 danh mục, bao gồm 34k cặp ngữ cảnh tình huống và câu tiếp theo. Để xây dựng KOSBI, chúng tôi sử dụng khung hợp tác con người-LLM, trong đó HyperCLOVA sinh ra ngữ cảnh và câu, và các chú thích viên con người dán nhãn chúng là an toàn hoặc không an toàn. Các thí nghiệm mở rộng trình bày bộ dữ liệu của chúng tôi khác biệt với các bộ dữ liệu phổ biến hiện có về thiên kiến xã hội và lời nói thù hận. Hơn nữa, kết quả cho thấy mô hình lọc được huấn luyện với bộ dữ liệu của chúng tôi cải thiện đáng kể tỷ lệ sinh ra các câu an toàn cho nhiều LLM khác nhau như GPT-3 và HyperCLOVA với kích thước mô hình đa dạng, điều này thể hiện hiệu quả của bộ dữ liệu của chúng tôi.

Hạn chế
KOSBI đề xuất giải quyết thiên kiến xã hội dựa trên văn hóa Hàn Quốc với ngôn ngữ Hàn Quốc. Tính chất đặc thù của Hàn Quốc này có thể hạn chế hiệu quả của bộ dữ liệu của chúng tôi ở Hàn Quốc và các nền văn hóa tương tự. Tuy nhiên, việc xây dựng bộ dữ liệu và giao thức đánh giá của chúng tôi có thể đóng góp như một hướng dẫn hữu ích cho các nhóm nghiên cứu khác về an toàn AI để xây dựng các bộ dữ liệu cho văn hóa và ngôn ngữ của họ.

Hiệu suất của các mô hình lọc cho phân loại câu vô hại trong nghiên cứu này không rất cạnh tranh. Chúng tôi để lại điều này như một chủ đề nghiên cứu tương lai để tạo ra một bộ phân loại lọc với độ chính xác cao hơn trên bộ dữ liệu của chúng tôi vì mục tiêu của nghiên cứu này không phải là tạo ra một bộ lọc thiên kiến xã hội mạnh mẽ.

--- TRANG 8 ---
Tuyên bố Đạo đức
Chúng tôi mong đợi rằng KOSBI của chúng tôi có thể đóng góp đáng kể vào việc tăng cường sử dụng an toàn các ứng dụng LLM bằng cách giảm rủi ro gây ra bởi thiên kiến xã hội. Việc xây dựng các bộ dữ liệu về tính có hại có khả năng gây căng thẳng cho các cộng tác viên, như các chuyên gia con người và nhân viên đám đông. Để giảm thiểu việc tiếp xúc căng thẳng của họ, chúng tôi sử dụng HyperCLOVA để sinh ra ngữ cảnh và câu và yêu cầu con người dán nhãn chúng. Hơn nữa, nghiên cứu của chúng tôi đã được phê duyệt bởi hội đồng đánh giá thể chế công cộng (IRB) liên kết với Bộ Y tế và Phúc lợi Hàn Quốc (P01-202211-01-016).

Lời cảm ơn
Các tác giả muốn cảm ơn tất cả các thành viên ủy ban của Diễn đàn Đạo đức AI cho Con người tại NAVER, bao gồm Meeyoung Cha, Byoungpil Kim, Eun-Ju Lee, Yong Lim, Alice Oh, Sangchul Park, Woochul Park, Joonha Jeon, Jonghyun Kim, Do Hyun Park, và Eunjung Cho, vì phản hồi xây dựng và thảo luận hữu ích của họ. Chúng tôi cũng biết ơn Ryumin Song, Jaehyeon Kim, và Jisun Kim tại Crowdworks, những người đã hợp tác trong quá trình thu thập dữ liệu, và 200 nhân viên đám đông đã tham gia vào quá trình này. Ngoài ra, các tác giả cảm ơn các thành viên nghiên cứu của Trung tâm AI Hyperscale SNU-NAVER và Trung tâm AI Hypercreative KAIST-NAVER vì thảo luận và cảm ơn Haksoo Ko và Yejin Choi vì thảo luận có giá trị. Dự án này được hỗ trợ tài chính bởi NAVER Cloud.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo dài...]

--- TRANG 9 ---
[Tiếp tục danh sách tài liệu tham khảo...]

--- TRANG 10 ---
[Tiếp tục danh sách tài liệu tham khảo...]

--- TRANG 11 ---
[Tiếp tục danh sách tài liệu tham khảo...]

--- TRANG 12 ---
A Bộ Dữ liệu KOSBI
A.1 Lĩnh vực và Danh mục của Nhân khẩu học Xã hội
Toàn bộ các danh mục và nhóm nhân khẩu học xã hội được liệt kê trong Bảng 8.

A.2 Dữ liệu Ví dụ
Hình 4: Các cặp ví dụ về ngữ cảnh và câu với nhãn liên quan đến danh mục và nhóm nhân khẩu học xã hội đã cho. Lưu ý, "그 금수저"là một từ thông dụng tiếng Hàn, có nghĩa đại loại là "Thìa bạc" hoặc "Xuất thân đặc quyền" trong tiếng Anh.

A.3 Chi tiết về Nhãn Không an toàn
Nhãn phụ không an toàn # dữ liệu
Ngữ cảnh Khuôn mẫu 4,719
Thành kiến / Phân biệt đối xử 407
Khác 1,590
Không xác định 2,260
Câu Khuôn mẫu 8,197
Thành kiến 1,085
Phân biệt đối xử 655
Khác 336
Không xác định 6,905

Bảng 7: Phân phối các nhãn phụ không an toàn của ngữ cảnh và câu. Không xác định đại diện cho các trường hợp mà ba chú thích viên không thể quyết định nhãn thông qua bỏ phiếu đa số, nhưng 2 hoặc nhiều chú thích viên chọn một trong các nhãn phụ không an toàn.

[Bảng 8 tiếp theo với danh sách đầy đủ các danh mục và nhóm xã hội...]

--- TRANG 13 ---
B Sinh ra HyperClova
Siêu tham số Chúng tôi sử dụng cùng siêu tham số cho việc sinh ra ngữ cảnh và câu: lấy mẫu top-p với p = 0.8, nhiệt độ 0.5, hình phạt lặp lại 5, và từ dừng "\n". Chúng tôi dần dần tăng top-p và nhiệt độ mỗi khi chúng tôi gặp phải sinh ra trùng lặp.

C Lời nhắc của LLM
[Các lời nhắc bằng tiếng Hàn được giữ nguyên...]

D Chi tiết Mô hình hóa
[Chi tiết về huấn luyện mô hình...]

E Đánh giá An toàn của Các câu tiếp theo
[Bảng 9 và thông tin bổ sung...]

F Kết quả và Phân tích trên Tập Kiểm tra Tăng cường
[Thông tin về tập kiểm tra tăng cường...]

G Mức độ Giảm thiểu Thiên kiến Xã hội theo Danh mục
[Phân tích chi tiết theo danh mục...]

H Chú thích Con người
H.1 Bồi thường Nhân viên Đám đông
[Thông tin về bồi thường...]

H.2 Nhân khẩu học Chú thích
[Bảng 12 với thông tin nhân khẩu học chi tiết...]

H.3 Hướng dẫn và Giao diện Chú thích
[Hình 7 và 8 với hướng dẫn chú thích...]

--- TRANG 17 ---
[Tiếp tục giao diện chú thích...]

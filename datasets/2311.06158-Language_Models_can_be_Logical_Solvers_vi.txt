Tài liệu tham khảo

Stefano Ceri, Georg Gottlob, Letizia Tanca, et al. 1989. What you always wanted to know about datalog(and never dared to ask). IEEE transactions on knowledge and data engineering, 1(1):146–166.

Wenhu Chen, Xueguang Ma, Xinyi Wang, và William W Cohen. 2022. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint arXiv:2211.12588.

Zhipeng Chen, Kun Zhou, Beichen Zhang, Zheng Gong, Wayne Xin Zhao, và Ji-Rong Wen. 2023. Chatcot: Tool-augmented chain-of-thought reasoning on chat-based large language models. arXiv preprint arXiv:2305.14323.

Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, và Eric P. Xing. 2023. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality.

Peter Clark, Oyvind Tafjord, và Kyle Richardson. 2020. Transformers as soft reasoners over language. In Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20, pages 3882–3890. International Joint Conferences on Artificial Intelligence Organization. Main track.

William F Clocksin và Christopher S Mellish. 2003. Programming in PROLOG. Springer Science & Business Media.

Bruce Frederiksen. 2008. Applying expert system technology to code reuse with pyke. PyCon: Chicago.

Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, và Graham Neubig. 2023. Pal: Program-aided language models. In International Conference on Machine Learning, pages 10764–10799. PMLR.

Google. 2023. Google bard. https://bard.google.com/.

Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. 2022. Training compute-optimal large language models. arXiv preprint arXiv:2203.15556.

Jie Huang và Kevin Chen-Chuan Chang. 2023. Towards reasoning in large language models: A survey. In Findings of the Association for Computational Linguistics: ACL 2023, pages 1049–1065, Toronto, Canada. Association for Computational Linguistics.

Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, và Dario Amodei. 2020. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361.

Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, và Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners. Advances in neural information processing systems, 35:22199–22213.

Philipp Körner, Michael Leuschel, João Barbosa, Vítor Santos Costa, Verónica Dahl, Manuel V Hermenegildo, Jose F Morales, Jan Wielemaker, Daniel Diaz, Salvador Abreu, et al. 2022. Fifty years of prolog and beyond. Theory and Practice of Logic Programming, 22(6):776–858.

Angeliki Lazaridou, Elena Gribovskaya, Wojciech Stokowiec, và Nikolai Grigorev. 2022. Internet-augmented language models through few-shot prompting for open-domain question answering. arXiv preprint arXiv:2203.05115.

Zhan Ling, Yunhao Fang, Xuanlin Li, Zhiao Huang, Mingu Lee, Roland Memisevic, và Hao Su. 2023. Deductive verification of chain-of-thought reasoning. arXiv preprint arXiv:2306.03872.

Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, và Peter Stone. 2023a. Llm+ p: Empowering large language models with optimal planning proficiency. arXiv preprint arXiv:2304.11477.

Hanmeng Liu, Ruoxi Ning, Zhiyang Teng, Jian Liu, Qiji Zhou, và Yue Zhang. 2023b. Evaluating the logical reasoning ability of chatgpt and gpt-4. arXiv preprint arXiv:2304.03439.

Qing Lyu, Shreya Havaldar, Adam Stein, Li Zhang, Delip Rao, Eric Wong, Marianna Apidianaki, và Chris Callison-Burch. 2023. Faithful chain-of-thought reasoning. arXiv preprint arXiv:2301.13379.

OpenAI. 2022. Chatgpt: Optimizing language models for dialogue. https://openai.com/blog/chatgpt/.

OpenAI. 2023. Gpt-4 technical report. ArXiv, abs/2303.08774.

Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35:27730–27744.

Liangming Pan, Alon Albalak, Xinyi Wang, và William Yang Wang. 2023. Logic-lm: Empowering large language models with symbolic solvers for faithful logical reasoning. arXiv preprint arXiv:2305.12295.

Gabriel Poesia, Kanishk Gandhi, Eric Zelikman, và Noah D Goodman. 2023. Certified reasoning with language models. arXiv preprint arXiv:2306.04031.

David L Poole và Alan K Mackworth. 2010. Artificial Intelligence: foundations of computational agents. Cambridge University Press.

Connor Pryor, Charles Dickens, Eriq Augustine, Alon Albalak, William Wang, và Lise Getoor. 2022. Neupsl: Neural probabilistic soft logic. arXiv preprint arXiv:2205.14268.

Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, và Yuxiong He. 2020. Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 3505–3506.

Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, et al. 2023. Code llama: Open foundation models for code. arXiv preprint arXiv:2308.12950.

Abulhair Saparov và He He. 2023. Language models are greedy reasoners: A systematic formal analysis of chain-of-thought. In The Eleventh International Conference on Learning Representations.

Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, và Yueting Zhuang. 2023. Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface. arXiv preprint arXiv:2303.17580.

Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, và Wen-tau Yih. 2023. Replug: Retrieval-augmented black-box language models. arXiv preprint arXiv:2301.12652.

Oyvind Tafjord, Bhavana Dalvi, và Peter Clark. 2021. ProofWriter: Generating implications, proofs, and abductive statements over natural language. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 3621–3634, Online. Association for Computational Linguistics.

Oyvind Tafjord, Bhavana Dalvi Mishra, và Peter Clark. 2022. Entailer: Answering questions with faithful and truthful chains of reasoning. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 2078–2093, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Jidong Tian, Yitian Li, Wenqing Chen, Liqiang Xiao, Hao He, và Yaohui Jin. 2022. Weakly supervised neural symbolic learning for cognitive tasks. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 5888–5896.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023a. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023b. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288.

Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan, và Subbarao Kambhampati. 2022. Large language models still can't plan (a benchmark for llms on planning and reasoning about change). arXiv preprint arXiv:2206.10498.

Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022a. Emergent abilities of large language models. Transactions on Machine Learning Research.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022b. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824–24837.

Kaiyu Yang, Jia Deng, và Danqi Chen. 2022. Generating natural language proofs with verifier-guided search. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 89–105, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Xi Ye, Qiaochu Chen, Isil Dillig, và Greg Durrett. 2023. Satisfiability-aided language models using declarative prompting. arXiv preprint arXiv:2305.09656.

Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan Sun, Yu Su, và Wenhu Chen. 2023. Mammoth: Building math generalist models through hybrid instruction tuning. arXiv preprint arXiv:2309.05653.

Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V Le, et al. 2022. Least-to-most prompting enables complex reasoning in large language models. In The Eleventh International Conference on Learning Representations.

--- TRANG 12 ---
A Hướng dẫn cho Phân tích NL-to-SL trên ProofWriter

Mô tả Nhiệm vụ: Bạn được cung cấp một mô tả vấn đề và một câu hỏi. Nhiệm vụ là:
1) định nghĩa tất cả các vị từ trong vấn đề
2) phân tích vấn đề thành các quy tắc logic dựa trên các vị từ đã định nghĩa
3) viết tất cả các sự kiện được đề cập trong vấn đề
4) phân tích câu hỏi thành dạng logic

Vấn đề:
Anne yên tĩnh. Erin có lông. (...nhiều ngữ cảnh khác ở đây...) Tất cả những người có màu đỏ đều trẻ.

Câu hỏi:
Dựa trên thông tin trên, phát biểu sau đây là đúng, sai, hay không xác định? Anne có màu trắng.

Vị từ:
Quiet($x, bool) ::: $x có yên tĩnh không?
Furry($x, bool) ::: $x có lông không?
(...nhiều vị từ khác ở đây...)
Young($x, bool) ::: $x có trẻ không?

Sự kiện:
Quiet(Anne, True) ::: Anne yên tĩnh.
Furry(Erin, True) ::: Erin có lông.
(...nhiều sự kiện khác ở đây...)
Quiet(Harry, True) ::: Harry yên tĩnh.
White(Harry, True) ::: Harry có màu trắng.

Quy tắc:
Young($x, True) >>> Furry($x, True) ::: Những người trẻ có lông.
Quiet(Anne, True) >>> Red($x, True) ::: Nếu Anne yên tĩnh thì Anne có màu đỏ.
(...nhiều quy tắc khác ở đây...)
Red($x, True) >>> Young($x, True) ::: Tất cả những người có màu đỏ đều trẻ.

Truy vấn:
White(Anne, True) ::: Anne có màu trắng.

——

Vấn đề:
(vấn đề mới ở đây)

Câu hỏi:
(câu hỏi mới ở đây)

B Hướng dẫn cho Phân tích NL-to-SL trên PrOntoQA

Mô tả Nhiệm vụ: Bạn được cung cấp một mô tả vấn đề và một câu hỏi. Nhiệm vụ là:
1) định nghĩa tất cả các vị từ trong vấn đề
2) phân tích vấn đề thành các quy tắc logic dựa trên các vị từ đã định nghĩa
3) viết tất cả các sự kiện được đề cập trong vấn đề
4) phân tích câu hỏi thành dạng logic

Vấn đề:
Mỗi jompus đều có trái cây. Mỗi jompus đều là một wumpus. (...nhiều ngữ cảnh khác ở đây...) Alex là một tumpus.

Câu hỏi:
Đúng hay sai: Alex không nhút nhát.

Vị từ:
Jompus($x, bool) ::: $x có thuộc về Jompuses không?
Fruity($x, bool) ::: $x có trái cây không?
(...nhiều vị từ khác ở đây...)
Liquid($x, bool) ::: $x có lỏng không?
Zumpus($x, bool) ::: $x có thuộc về Zumpuses không?

Sự kiện:
Tumpus(Alex, True) ::: Alex là một tumpus.

Quy tắc:
Jompus($x, True) >>> Fruity($x, True) ::: Mỗi jompus đều có trái cây.
Jompus($x, True) >>> Wumpus($x, True) ::: Mỗi jompus đều là một wumpus.
(...nhiều quy tắc khác ở đây...)
Rompus($x, True) >>> Liquid($x, True) ::: Mỗi rompus đều lỏng.
Rompus($x, True) >>> Zumpus($x, True) ::: Rompuses là zumpuses.

Truy vấn:
Shy(Alex, False) ::: Alex không nhút nhát.

——

Vấn đề:
(vấn đề mới ở đây)

Câu hỏi:
(câu hỏi mới ở đây)

C Một Ví dụ Huấn luyện Toàn diện về Dữ liệu Điều chỉnh Hướng dẫn của chúng tôi

--- TRANG 13 ---
Lượt-1 (từ con người): Mô tả Nhiệm vụ: Cho một phát biểu chứa các sự kiện và quy tắc logic bằng ngôn ngữ tự nhiên làm ngữ cảnh, nhiệm vụ là: 1. định nghĩa tất cả các vị từ dưới dạng logic từ ngữ cảnh 2. phân tích phát biểu thành các sự kiện và quy tắc đã biết dựa trên các vị từ đã định nghĩa 3. bắt đầu lý luận để có được tất cả các sự kiện được ngụ ý

Ngữ cảnh: Charlie có màu xanh. Charlie có màu trắng. Dave có màu xanh dương. Dave có lông. Dave có màu trắng. Fiona có màu xanh dương. Fiona có màu xanh. Fiona tốt bụng. Fiona thô ráp. Fiona có màu trắng. Tất cả những người có lông đều yên tĩnh. Tất cả những người có màu xanh, trắng đều tốt bụng. Nếu ai đó có màu xanh dương và yên tĩnh thì họ có màu xanh.

Lý luận:

Lượt-2 (từ LM): Chúng tôi trước tiên định nghĩa các vị từ sau và giải thích ngôn ngữ tự nhiên tương ứng:
Green($x, bool) ::: $x có màu xanh?
White($x, bool) ::: $x có màu trắng?
Blue($x, bool) ::: $x có màu xanh dương?
Furry($x, bool) ::: $x có lông?
Nice($x, bool) ::: $x có tốt bụng?
Rough($x, bool) ::: $x có thô ráp?
Quiet($x, bool) ::: $x có yên tĩnh?

Chúng tôi có các sự kiện đã biết sau từ ngữ cảnh:
Green('Charlie', True)
Green('Fiona', True)
White('Charlie', True)
White('Dave', True)
White('Fiona', True)
Blue('Dave', True)
Blue('Fiona', True)
Furry('Dave', True)
Nice('Fiona', True)
Rough('Fiona', True)

Chúng tôi có các quy tắc đã biết sau từ ngữ cảnh:
rule1: Furry($x, True) → Quiet($x, True)
rule2: Green($x, True) ∧ White($x, True) → Nice($x, True)
rule3: Blue($x, True) ∧ Quiet($x, True) → Green($x, True)

Bây giờ bắt đầu lý luận để có được tất cả các sự kiện được ngụ ý:
Sử dụng rule1: Furry($x, True) → Quiet($x, True)
Ràng buộc $x với 'Dave'
Có được một sự kiện mới được ngụ ý: Quiet('Dave', True)
Tháo ràng buộc $x
Hoàn thành ngụ ý với rule1

Sử dụng rule2: Green($x, True) ∧ White($x, True) → Nice($x, True)
Ràng buộc $x với 'Charlie'
Có được một sự kiện mới được ngụ ý: Nice('Charlie', True)
Tháo ràng buộc $x
Ràng buộc $x với 'Fiona'
Có được một sự kiện đã biết hoặc được ngụ ý: Nice('Fiona', True)
Tháo ràng buộc $x
Hoàn thành ngụ ý với rule2

Sử dụng rule3: Blue($x, True) ∧ Quiet($x, True) → Green($x, True)
Ràng buộc $x với 'Dave'
Có được một sự kiện mới được ngụ ý: Green('Dave', True)
Tái sử dụng rule2: Green($x, True) ∧ White($x, True) → Nice($x, True)
Ràng buộc $x với 'Dave'
Có được một sự kiện mới được ngụ ý: Nice('Dave', True)
Hoàn thành ngụ ý với rule2
Tháo ràng buộc $x
Ràng buộc $x với 'Fiona'
Tháo ràng buộc $x
Hoàn thành ngụ ý với rule3

Cuối cùng, chúng tôi có được các sự kiện được ngụ ý sau:
Green('Dave', True)
Nice('Charlie', True)
Nice('Dave', True)
Quiet('Dave', True)
Hoàn thành lý luận

Lượt-3 (từ con người): Câu hỏi: Dựa trên thông tin trên, nhận xét sau đây là đúng, sai, hay không xác định? Dave không có màu xanh.

Tùy chọn:
A) Đúng
B) Sai
C) Không xác định

Bây giờ bạn nên:
1. lý luận cẩn thận trước với các sự kiện đã biết và sự kiện được ngụ ý ở trên
2. sau đó đưa ra câu trả lời của bạn một cách nghiêm ngặt theo định dạng "Vậy, tùy chọn đúng là: X". X nên được thay thế bằng "A) Đúng", "B) Sai" hoặc "C) Không xác định"

Lượt-4 (từ LM): Nhận xét có thể được phân tích thành: Green('Dave', False)
Theo sự kiện được ngụ ý: Green('Dave', True)
Nhận xét mâu thuẫn với sự kiện.
Vậy, tùy chọn đúng là: B) Sai

Hình 4: Phiên bản đầy đủ của ví dụ huấn luyện toàn diện 4-lượt về dữ liệu điều chỉnh hướng dẫn của chúng tôi được thể hiện trong Hình 3.

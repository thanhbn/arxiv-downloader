# 2305.07759.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/datasets/2305.07759.pdf
# Kích thước tệp: 4069571 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
TinyStories: Các Mô Hình Ngôn Ngữ Có Thể Nhỏ Đến Mức Nào Mà Vẫn Nói Được Tiếng Anh Mạch Lạc?

Ronen Eldan∗ và Yuanzhi Li†
Microsoft Research
Tháng 4 năm 2023

Tóm tắt

Các mô hình ngôn ngữ [4, 5, 21] (LMs) là những công cụ mạnh mẽ cho xử lý ngôn ngữ tự nhiên, nhưng chúng thường gặp khó khăn trong việc tạo ra văn bản mạch lạc và trôi chảy khi chúng nhỏ. Các mô hình với khoảng 125M tham số như GPT-Neo (nhỏ) [3] hoặc GPT-2 (nhỏ) [23] hiếm khi có thể tạo ra văn bản tiếng Anh mạch lạc và nhất quán vượt quá vài từ ngay cả sau khi được huấn luyện mở rộng. Điều này đặt ra câu hỏi liệu khả năng tạo ra văn bản tiếng Anh mạch lạc chỉ xuất hiện ở quy mô lớn hơn (với hàng trăm triệu tham số trở lên) và các kiến trúc phức tạp (với nhiều lớp chú ý toàn cục).

Trong nghiên cứu này, chúng tôi giới thiệu TinyStories, một tập dữ liệu tổng hợp gồm các câu chuyện ngắn chỉ chứa những từ mà trẻ em 3-4 tuổi thường hiểu, được tạo ra bởi GPT-3.5 và GPT-4. Chúng tôi cho thấy TinyStories có thể được sử dụng để huấn luyện và đánh giá các LM nhỏ hơn nhiều so với các mô hình hiện đại (dưới 10 triệu tham số tổng cộng), hoặc có kiến trúc đơn giản hơn nhiều (chỉ với một khối transformer), nhưng vẫn tạo ra những câu chuyện trôi chảy và nhất quán với nhiều đoạn văn đa dạng và có ngữ pháp gần như hoàn hảo, đồng thời thể hiện khả năng lý luận.

Chúng tôi cũng giới thiệu một mô hình mới để đánh giá các mô hình ngôn ngữ: Chúng tôi đề xuất một khung làm việc sử dụng GPT-4 để chấm điểm nội dung được tạo ra bởi những mô hình này như thể chúng là những câu chuyện được viết bởi học sinh và được chấm điểm bởi một giáo viên (con người). Mô hình mới này khắc phục những khuyết điểm của các tiêu chuẩn đánh giá truyền thống thường yêu cầu đầu ra của mô hình phải có cấu trúc rất chặt chẽ, hơn nữa nó cung cấp điểm số đa chiều cho mô hình, đưa ra điểm số cho các khả năng khác nhau như ngữ pháp, sáng tạo và tuân thủ hướng dẫn.

Chúng tôi hy vọng TinyStories có thể hỗ trợ việc phát triển, phân tích và nghiên cứu các LM, đặc biệt đối với các lĩnh vực có tài nguyên hạn chế hoặc chuyên biệt, và làm sáng tỏ sự xuất hiện của khả năng ngôn ngữ trong các LM.

1 Giới thiệu

Ngôn ngữ tự nhiên phong phú và đa dạng. Nó không chỉ là một hệ thống quy tắc và ký hiệu, mà còn là một cách truyền đạt và diễn giải ý nghĩa [32]. Để hiểu và tạo ra ngôn ngữ, người ta không chỉ cần nắm vững các quy tắc kỹ thuật của ngữ pháp và kiến thức về từ vựng, mà còn phải có đủ thông tin thực tế và có khả năng lý luận logic và theo ngữ cảnh. Do đó, các mô hình ngôn ngữ tự hồi quy, có khả năng tạo ra văn bản tiếng Anh mạch lạc, cũng phải có được một mức độ nhất định của những khả năng này. Ví dụ, hãy xem xét câu chưa hoàn chỉnh sau:

Jack đói bụng, vậy nên anh ấy đi tìm ⟨⟩

Để hoàn thành câu này một cách hợp lý, mô hình ngôn ngữ cần biết rằng đói là một trạng thái thúc đẩy con người tìm kiếm thức ăn, và thức ăn là một danh mục những thứ có thể thỏa mãn cơn đói. Nó cũng cần chọn một từ phù hợp với các ràng buộc cú pháp và ngữ nghĩa của câu (như "một bữa ăn nhẹ"), và có khả năng xảy ra với tình huống và kiến thức nền.

Một ví dụ minh họa nhu cầu về lý luận là:

Lily muốn nuôi một con mèo hoặc một con chó. Mẹ cô ấy không cho phép cô ấy nuôi chó nên thay vào đó cô ấy ⟨⟩

∗roneneldan@microsoft.com
†yuanzhili@microsoft.com

--- TRANG 2 ---

Để hoàn thành câu này, mô hình ngôn ngữ cần áp dụng lý luận: nó cần áp dụng nguyên tắc loại trừ tuyển: nếu Lily muốn nuôi một con mèo hoặc một con chó, và cô ấy không thể nuôi chó, thì cô ấy phải chọn mèo. Nó cũng cần chọn những từ thể hiện ý định hoặc hành động của Lily mà mạch lạc với giọng điệu và phong cách của văn bản.

Các mô hình ngôn ngữ đã được chứng minh là thể hiện một loạt các khả năng nổi lên, chẳng hạn như tóm tắt, tính toán, dịch thuật và lý luận thông thường, khi chúng được mở rộng quy mô và được huấn luyện trên các bộ dữ liệu đa dạng và lớn [24, 4, 5, 21]. Những khả năng này gợi ý rằng các mô hình ngôn ngữ không chỉ học các mẫu bề mặt của ngôn ngữ mà còn thu được một mức độ nhất định của hiểu biết ngữ nghĩa và logic về thế giới và văn bản. Tuy nhiên, không rõ ràng ở quy mô nào những khả năng này xuất hiện, và chúng phụ thuộc như thế nào vào kiến trúc mô hình và phân phối dữ liệu.

Có lẽ khả năng cơ bản nhất đối với một mô hình ngôn ngữ là tạo ra văn bản tiếng Anh mạch lạc và trôi chảy, điều này, như chúng ta đã thảo luận ở trên, không chỉ đòi hỏi kiến thức ngữ pháp và từ vựng mà còn cần thông tin thực tế và lý luận theo ngữ cảnh. Các mô hình ngôn ngữ có thể tạo ra văn bản nhất quán, đa dạng và có ý nghĩa tốt đến mức nào? Và đâu là những yêu cầu tối thiểu để một mô hình ngôn ngữ đạt được khả năng này?

Cho đến nay, bằng chứng chỉ ra rằng việc tạo ra văn bản mạch lạc đã đòi hỏi một quy mô khá lớn: các mô hình ngôn ngữ nhỏ (SLMs) rất hạn chế về hiệu suất và khả năng, đặc biệt là trong các tác vụ tạo văn bản. Ví dụ, các mô hình có khoảng 125M tham số như GPT-Neo (nhỏ) hoặc GPT-2 (nhỏ) hiếm khi có thể tạo ra bất kỳ văn bản nhất quán nào vượt quá vài từ ngay cả sau khi được huấn luyện mở rộng trên các bộ dữ liệu lớn như Pile [9], Common Crawl [1] hoặc CC-100 [31]. Những mô hình này thường tạo ra những câu không mạch lạc, lặp lại hoặc vô nghĩa, và thất bại trong việc duy trì một chủ đề rõ ràng hoặc cấu trúc logic xuyên suốt các đoạn văn [12]. Điều này đặt ra câu hỏi liệu sự xuất hiện của khả năng nói tiếng Anh mạch lạc có yêu cầu các mô hình lớn (với hàng trăm triệu tham số trở lên) và kiến trúc phức tạp (với nhiều lớp chú ý toàn cục).

Tuy nhiên, hiện tại vẫn chưa rõ liệu việc các SLM không thể tạo ra văn bản mạch lạc là do độ phức tạp nội tại của ngôn ngữ tự nhiên, hay do sự rộng lớn và đa dạng quá mức của các bộ dữ liệu được sử dụng để huấn luyện. Khi chúng ta huấn luyện một mô hình trên Wikipedia chẳng hạn, chúng ta không chỉ dạy nó cách nói tiếng Anh mà còn cách mã hóa và truy xuất một lượng thông tin khổng lồ về các sự kiện và khái niệm từ nhiều lĩnh vực và ngành học khác nhau. Có thể các SLM bị choáng ngợp bởi lượng và sự đa dạng của thông tin mà chúng phải xử lý và lưu trữ, và điều này cản trở khả năng học các cơ chế và nguyên tắc cốt lõi của ngôn ngữ?

Điều này đặt ra câu hỏi liệu chúng ta có thể thiết kế một tập dữ liệu bảo tồn các yếu tố thiết yếu của ngôn ngữ tự nhiên, chẳng hạn như ngữ pháp, từ vựng, sự kiện và lý luận, nhưng nhỏ hơn và tinh tế hơn nhiều về mặt rộng và đa dạng. Một tập dữ liệu như vậy sẽ cho phép chúng ta tách biệt và kiểm tra các yêu cầu tối thiểu để một mô hình ngôn ngữ tạo ra văn bản mạch lạc và trôi chảy, và đánh giá hiệu suất và khả năng của nó một cách chính xác và công bằng hơn. Hơn nữa, một tập dữ liệu như vậy sẽ tạo điều kiện thuận lợi cho việc phát triển và phân tích các SLM, đặc biệt đối với các lĩnh vực có tài nguyên hạn chế hoặc chuyên biệt, nơi mà các bộ dữ liệu lớn và đa dạng hoặc không có sẵn hoặc không mong muốn.

Trong bài báo này, chúng tôi giới thiệu TinyStories¹, một tập dữ liệu tổng hợp gồm các câu chuyện ngắn được thiết kế để chỉ chứa những từ mà hầu hết trẻ em 3-4 tuổi thường hiểu, được tạo ra bởi GPT-3.5 và GPT-4. TinyStories được thiết kế để nắm bắt bản chất của ngôn ngữ tự nhiên, đồng thời giảm bớt tính rộng lớn và đa dạng của nó. Mỗi câu chuyện bao gồm 2-3 đoạn văn theo một cốt truyện đơn giản và chủ đề nhất quán, trong khi toàn bộ tập dữ liệu nhằm mục đích bao trùm từ vựng và cơ sở tri thức thực tế của một đứa trẻ 3-4 tuổi.

Dựa trên tập dữ liệu này, bài báo của chúng tôi đưa ra một số đóng góp chính:

• Đóng góp chính của chúng tôi là chúng tôi cho thấy TinyStories có thể được sử dụng để huấn luyện và đánh giá các SLM² nhỏ hơn nhiều so với các mô hình hiện đại (dưới 10 triệu tham số với chiều nhúng là 256), hoặc có kiến trúc đơn giản hơn nhiều (chỉ với một khối transformer), nhưng vẫn tạo ra một tập hợp đa dạng những câu chuyện trôi chảy và nhất quán có thể so sánh hoặc vượt trội hơn những câu chuyện được tạo ra bởi các mô hình lớn hơn và phức tạp hơn. Hơn nữa, bất chấp kích thước nhỏ của các mô hình, chúng tôi vẫn quan sát được sự xuất hiện của khả năng lý luận, kiến thức về các sự kiện chung và khả năng tuân theo một số hướng dẫn nhất định.

• Chúng tôi giới thiệu một mô hình mới để đánh giá các mô hình ngôn ngữ bằng GPT-4, giúp khắc phục nhiều hạn chế của các tiêu chuẩn đánh giá truyền thống.

• Chúng tôi cho thấy rằng mặc dù việc huấn luyện các mô hình tạo sinh trên TinyStories thường có thể được thực hiện trong vòng chưa đầy một ngày trên một GPU duy nhất, chúng vẫn thể hiện nhiều hành vi tương tự như những hành vi quan sát được trong các LLM, chẳng hạn như luật mở rộng, sự đánh đổi giữa chiều rộng và chiều sâu, v.v. Ngay cả với tài nguyên tính toán hạn chế, chúng tôi có thể tiến hành các thí nghiệm mở rộng để nghiên cứu tác động của các siêu tham số, kiến trúc và phương pháp huấn luyện khác nhau đến hiệu suất và chất lượng của các mô hình.

• Chúng tôi cho thấy rằng các SLM được huấn luyện có vẻ dễ diễn giải hơn đáng kể so với các mô hình lớn hơn. Khi các mô hình có số lượng nơ-ron nhỏ và/hoặc số lượng lớp nhỏ, chúng tôi quan sát thấy rằng cả các đầu chú ý và nơ-ron MLP đều có chức năng có ý nghĩa: Các đầu chú ý tạo ra các mẫu chú ý rất rõ ràng, với sự phân tách rõ ràng giữa các đầu cục bộ và ngữ nghĩa, và các nơ-ron MLP thường được kích hoạt trên các token có vai trò chung rõ ràng trong câu. Chúng tôi hình dung và phân tích các bản đồ chú ý và kích hoạt của các mô hình, và cho thấy chúng liên quan như thế nào đến quá trình tạo và nội dung câu chuyện.

Để cho độc giả có ấn tượng đầu tiên về khả năng của các mô hình được huấn luyện trên TinyStories, chúng tôi so sánh việc hoàn thành của một mô hình 28M tham số được huấn luyện trên TinyStories³ với GPT2-XL, lớn hơn hai bậc độ lớn (1.5B tham số), trên một gợi ý mẫu⁴ trong Hình 1. Chúng tôi lưu ý rằng kiến trúc và sơ đồ huấn luyện của các mô hình về cơ bản là giống nhau.

Gợi ý: Tom và Jane là bạn bè. Một ngày nọ, Jane đến nhà Tom. Tom có một nồi súp lớn. Anh ấy muốn chia sẻ với Jane. "Jane, bạn có muốn súp không?" Tom hỏi. "Vâng, làm ơn. Nó trông ngon quá," Jane nói.
Tom rót một ít súp vào hai bát. Anh ấy đưa một bát cho Jane. Jane múc một thìa súp, nhưng sau đó cô ấy nhăn mặt. Súp

Hoàn thành bởi GPT2-XL (1.5B tham số): quá cũ. Tom cau mày.
"Đừng như vậy! Súp của bạn phải tươi như con gái của bạn," Tom nói, tức giận và thất vọng.
"Đem cho tôi thêm một ít nữa," Jane kêu lên. "Không! Đi đi, tôi thích súp của tôi cũ và tươi!"

Hoàn thành bởi mô hình 28M tham số được huấn luyện trên TinyStories: rất đắng. Cô ấy không thích nó. Cô ấy nói, "Tôi không thích súp này. Nó quá đắng."
Tom cảm thấy tiếc. Anh ấy nói, "Tôi xin lỗi, Jane. Tôi không biết bạn không thích súp đắng. Tôi sẽ làm cho bạn thứ gì đó khác." Anh ấy nhìn quanh bếp và tìm thấy một ít bánh mì và phô mai. Anh ấy đặt chúng lên bàn và nói, "Đây, Jane. Bạn có thể có một ít bánh mì và phô mai. Chúng không đắng. Chúng ngọt và ngon."
Jane vui vẻ. Cô ấy nói, "Cảm ơn, Tom. Bạn là một người bạn tốt. Tôi thích bánh mì và phô mai. Chúng không đắng."

Hình 1: So sánh giữa các hoàn thành được đưa ra bởi mô hình 28M tham số được huấn luyện trên tập dữ liệu TinyStories và GPT-2XL (1.5B)

Quay lại các ví dụ được đưa ra ở đầu phần giới thiệu, chúng tôi nhấn mạnh các hoàn thành trong Hình 2. Những hoàn thành này, cùng với nhiều ví dụ khác được đưa ra trong suốt bài báo, chứng minh rằng ngay cả các mô hình rất nhỏ (2.5M) hoặc các mô hình chỉ có một lớp transformer cũng có thể đạt được kiến thức thực tế, và các mô hình lớn hơn một chút có thể thể hiện một mức độ lý luận nhất định. Việc so sánh với hiệu suất của GPT2-XL cho thấy tập dữ liệu TinyStories cho phép chúng ta thể hiện sự xuất hiện của những khả năng này ở quy mô nhỏ hơn đáng kể so với các mô hình được huấn luyện trên các bộ dữ liệu ngôn ngữ lớn. Thêm bằng chứng cho điều này sẽ được cung cấp trong phần còn lại của bài báo.

Gợi ý | 2.5M, 8 lớp | 33M, 4 lớp | 21M, 1 lớp | GPT2-XL (1.5B)
Alice rất mệt khi về nhà nên cô ấy đi | ngủ. | thẳng lên giường. | lên giường với một nụ cười tươi trên khuôn mặt. | ra ngoài
Lily thích mèo và chó. Cô ấy hỏi mẹ xin một con chó và mẹ nói không, vậy nên cô ấy hỏi | mẹ xem có thể nuôi một con chó không. | bố xin một con mèo. | mẹ một lần nữa. | bố. Họ mang cho cô ấy một con Chihuahua, và cô ấy ngay lập tức yêu quý chúng.
Alice và Jack đi bộ trên phố và gặp một cô gái mặc váy đỏ. Cô gái nói với họ, "Chào, tôi là Jane. Tên các bạn là gì?" | Alice mỉm cười và nói, "Tên tôi là Daisy. Tên bạn là gì?" | Alice nói, "Tôi là Alice và đây là Jack." | Jack mỉm cười và nói, "Tôi là Jane. Rất vui được gặp bạn!" | Jane nói, "Jack và Kate"

Hình 2: Ví dụ về hiệu suất của các mô hình khác nhau trên kiến thức thực tế, lý luận và gợi ý theo ngữ cảnh. Ba mô hình đầu tiên được huấn luyện trên tập dữ liệu TinyStories.

³Vì mục đích có thể tái tạo, hầu hết các hoàn thành xuất hiện trong bài báo này, bao gồm cả cái này, đều được tạo ra với nhiệt độ bằng không.
⁴Gợi ý này được soạn thảo thủ công và sau đó được xác minh không có sự trùng lặp 6-gram với tập dữ liệu.

--- TRANG 3 ---

2 Mô tả tập dữ liệu TinyStories

Như đã đề cập ở trên, ý tưởng đằng sau tập dữ liệu TinyStories là có một kho dữ liệu kết hợp tất cả các yếu tố định tính được tìm thấy trong ngôn ngữ tự nhiên, chẳng hạn như ngữ pháp, từ vựng, sự kiện và lý luận, nhưng cũng nhỏ hơn, ít đa dạng hơn và hạn chế hơn về mặt nội dung. Một cách tiếp cận tự nhiên để đạt được điều này là sử dụng thực tế rằng trẻ nhỏ có được các khả năng trí tuệ nói trên một cách định tính, mặc dù với mức độ tiếp xúc ngôn ngữ ít hơn nhiều so với một người trưởng thành [7, 20].

Để đạt được mục tiêu này, chúng tôi dựa vào các mô hình tạo văn bản mới nhất của OpenAI (GPT-3.5 và GPT-4) có khả năng tạo ra lượng lớn nội dung tổng hợp theo hướng dẫn. Cụ thể, chúng tôi hướng dẫn các mô hình tạo ra nội dung chỉ sử dụng từ vựng mà một đứa trẻ 3 tuổi điển hình sẽ hiểu. Chúng tôi hạn chế nội dung có định dạng câu chuyện ngắn bằng tiếng Anh. Thách thức chính trong việc sử dụng các mô hình ngôn ngữ lớn để tạo ra dữ liệu huấn luyện là tạo ra một tập dữ liệu đủ đa dạng: việc nhắc nhở những mô hình đó tạo ra câu chuyện, ngay cả khi nhiệt độ tạo sinh được đặt ở giá trị cao, vẫn sẽ tạo ra một tập dữ liệu rất lặp lại, có sự đa dạng rất xa so với những gì cần thiết để huấn luyện một mô hình ngôn ngữ có "hiểu biết" về ngôn ngữ tương đương với trẻ em.

Để giải quyết vấn đề tạo ra một tập dữ liệu đa dạng, chúng tôi thu thập một từ vựng gồm khoảng 1500 từ cơ bản, cố gắng mô phỏng từ vựng của một đứa trẻ 3-4 tuổi điển hình, được phân thành danh từ, động từ và tính từ. Trong mỗi lần tạo sinh, 3 từ được chọn ngẫu nhiên (một động từ, một danh từ và một tính từ). Mô hình được hướng dẫn tạo ra một câu chuyện kết hợp bằng cách nào đó những từ ngẫu nhiên này vào câu chuyện. Như chúng tôi lập luận dưới đây, điều này làm tăng đáng kể sự đa dạng của tập dữ liệu, buộc các câu chuyện phải bao trùm toàn bộ từ vựng mà trẻ em quen thuộc, và bao gồm một tập hợp phong phú các cách kết hợp các khái niệm khác nhau. Ngoài ra, chúng tôi xây dựng một danh sách các tính năng có thể có của một câu chuyện (chẳng hạn như đối thoại, bước ngoặt cốt truyện, kết thúc xấu hoặc giá trị đạo đức). Đối với mỗi câu chuyện, chúng tôi tạo ra một tập con ngẫu nhiên của những tính năng đó và nhắc nhở mô hình với yêu cầu bổ sung để câu chuyện có những tính năng này.

Đây là một mẫu tạo sinh, bao gồm gợi ý và câu chuyện được tạo ra bởi GPT-3.5:

Viết một câu chuyện ngắn (3-5 đoạn) chỉ sử dụng những từ rất đơn giản mà một đứa trẻ 3 tuổi có thể hiểu. Câu chuyện nên sử dụng động từ "trang trí", danh từ "sấm sét" và tính từ "cổ xưa". Câu chuyện nên có các tính năng sau: câu chuyện nên chứa ít nhất một đoạn đối thoại, câu chuyện có kết thúc xấu. Nhớ chỉ sử dụng những từ đơn giản!

Ngày xưa, trong một ngôi nhà cổ xưa, có một cô bé tên Lily. Cô ấy thích trang trí phòng mình bằng những thứ đẹp. Một ngày nọ, cô ấy tìm thấy một chiếc hộp lớn trong gác mái. Cô ấy mở nó ra và thấy nhiều đồ trang trí lấp lánh. Lily rất vui và quyết định sử dụng chúng trong phòng của mình.

Khi Lily đang trang trí phòng, bầu trời bên ngoài trở nên tối. Có tiếng sấm sét lớn, và Lily sợ hãi. Cô ấy chạy đến mẹ và nói, "Mẹ ơi, tiếng sấm sét to quá!" Mẹ ôm cô ấy và nói, "Đừng lo, nó sẽ qua thôi."

Nhưng tiếng sấm sét không ngừng. Nó ngày càng to hơn, và ngôi nhà cổ xưa bắt đầu rung chuyển. Đột nhiên, mái nhà sập xuống những đồ trang trí đẹp. Lily buồn vì phòng của cô ấy không còn đẹp nữa. Hết.

2.1 TinyStories-Instruct: Một biến thể tuân thủ hướng dẫn của tập dữ liệu

Một thách thức khác của việc tạo ra ngôn ngữ tự nhiên là tạo ra các văn bản mạch lạc, phù hợp và nhất quán với các hướng dẫn hoặc ràng buộc đã cho. Để đánh giá khả năng của các mô hình tạo sinh về mặt tuân thủ hướng dẫn thay vì chỉ tạo nội dung, chúng tôi đã tạo ra một biến thể của TinyStories⁵ (được gọi là TinyStories-Instruct) trong đó mỗi câu chuyện được đi trước bởi một tập hợp hướng dẫn tương ứng. Các hướng dẫn có bốn loại:

1. Danh sách các từ cần được bao gồm trong câu chuyện.
2. Một câu nên xuất hiện ở đâu đó trong câu chuyện.
3. Danh sách các tính năng (các tính năng có thể có: đối thoại, kết thúc xấu, giá trị đạo đức, bước ngoặt cốt truyện, báo hiệu trước, xung đột).
4. Một tóm tắt ngắn (1-2 dòng) của câu chuyện.

Mỗi mục trong tập dữ liệu này có một tập con ngẫu nhiên của những hướng dẫn này tiếp theo là chính câu chuyện. Bằng cách này, với một mô hình được huấn luyện trên tập dữ liệu này, chúng ta có thể soạn một gợi ý để phản ánh bất kỳ tập hướng dẫn nào và sử dụng mô hình để tạo ra một câu chuyện tương ứng. Đây là một ví dụ từ tập dữ liệu:

Tóm tắt: Lily và Timmy cùng nhau xây một lâu đài cát và học cách thỏa hiệp, nhưng nó bị đổ bởi một cơn gió. Họ tìm thấy vẻ đẹp trong lâu đài cát bị hỏng và chơi vui vẻ với một con bướm.
Tính năng: Đối thoại, Báo hiệu trước, Bước ngoặt
Câu: Một ngày nọ, cô ấy đến công viên và nhìn thấy một con bướm đẹp.
Từ: không đồng ý, mạng lưới, đẹp
Câu chuyện: Ngày xưa, có một cô bé tên Lily. Cô ấy thích chơi với đồ chơi và bạn bè. Một ngày nọ, cô ấy đến công viên và nhìn thấy một con bướm đẹp. Cô ấy cố gắng bắt nó, nhưng nó bay đi. Bạn của Lily, Timmy, đến chơi với cô ấy.

⁵Có sẵn trên Huggingface với tên TinyStoriesInstruct.

--- TRANG 4 ---

Họ quyết định xây một lâu đài cát, nhưng họ không đồng ý về cách xây. Lily muốn làm nó cao, trong khi Timmy muốn làm nó rộng. Họ tranh cãi một lúc, nhưng cuối cùng đồng ý làm nó vừa cao vừa rộng. Khi họ đang xây lâu đài cát, họ nhận thấy một nhóm kiến đang làm việc cùng nhau. Họ nhận ra rằng những con kiến đang xây một mạng lưới đường hầm. Đột nhiên, một cơn gió mạnh đến và đổ lâu đài cát của họ. Họ buồn, nhưng sau đó họ thấy con bướm một lần nữa. Nó đậu trên tàn tích của lâu đài cát và họ nhận ra rằng nó vẫn đẹp, ngay cả trong trạng thái bị hỏng. Họ mỉm cười và chơi cùng nhau một cách vui vẻ.

TinyStories-Instruct được tạo ra theo cách sau: Đối với mỗi câu chuyện trong tập dữ liệu gốc, chúng tôi đã có một danh sách các từ và tính năng được sử dụng để tạo ra nó. Ngoài ra, chúng tôi sử dụng GPT-3.5 để tạo ra các tóm tắt ngắn của câu chuyện, và từ mỗi câu chuyện chúng tôi trích xuất một câu ngẫu nhiên (có thể là bất kỳ câu nào trong câu chuyện ngoại trừ câu đầu tiên). Sau đó chúng tôi chọn một tập con ngẫu nhiên của những thứ này và kết hợp chúng thành một hướng dẫn, tiếp theo là chính câu chuyện.

3 GPT-Eval: Một khung làm việc để đánh giá các mô hình được huấn luyện trên TinyStories

Trong khi các mô hình thông thường để đánh giá các mô hình ngôn ngữ thường dựa vào các tập dữ liệu đánh giá có cấu trúc dưới dạng một tác vụ mà đầu ra của mô hình phải phù hợp với một câu trả lời đã cho, chúng tôi giới thiệu một mô hình mới có thể nói là phù hợp hơn trong bối cảnh này. Một lần nữa, chúng tôi tận dụng các mô hình ngôn ngữ lớn hiện có để đánh giá các câu chuyện được tạo ra bởi mô hình. Chúng tôi cung cấp cho mô hình phần đầu của một câu chuyện, được lấy từ một tập dữ liệu được chuẩn bị thủ công gồm khoảng 50 gợi ý, tạo ra một phần hoàn thành bằng mô hình, và cung cấp phần đầu câu chuyện cùng với phần hoàn thành của mô hình cho GPT-4, yêu cầu nó chấm điểm bài hoàn thành về mặt ngữ pháp, sáng tạo và tính nhất quán với phần đầu của câu chuyện. Các gợi ý thường chứa một câu chưa hoàn chỉnh cần được hoàn thành, nơi chúng tôi cố gắng viết chúng theo cách mà việc hoàn thành câu bị cắt ngắn sẽ là một tác vụ khó khăn về mặt ngữ pháp.

Như một ví dụ, chúng tôi lấy câu chuyện xuất hiện trong ví dụ trên và cắt nó sau từ "to". Chúng tôi tạo ra một phần hoàn thành của câu chuyện trên bằng một mô hình với khoảng 28M tham số (phần tạo sinh được tô sáng bằng màu vàng), sau đó chúng tôi nhắc GPT-4 đầu tiên cung cấp đánh giá bằng lời và sau đó chấm điểm phần hoàn thành. Bản ghi tương tác như sau, với các phần được tạo ra bởi GPT-4 in nghiêng:

bài tập sau, học sinh được cho phần đầu của một câu chuyện. Học sinh cần hoàn thành nó thành một câu chuyện đầy đủ. Bài tập kiểm tra khả năng ngôn ngữ và sáng tạo của học sinh. Ký hiệu *** đánh dấu phần tách giữa phần đầu quy định và phần hoàn thành của học sinh:

Ngày xưa, trong một ngôi nhà cổ xưa, có một cô bé tên Lily. Cô ấy thích trang trí phòng mình bằng những thứ đẹp. Một ngày nọ, cô ấy tìm thấy một chiếc hộp lớn trong gác mái. Cô ấy mở nó ra và thấy nhiều đồ trang trí lấp lánh. Lily rất vui và quyết định sử dụng chúng trong phòng của mình.

Khi Lily đang trang trí phòng, bầu trời bên ngoài trở nên tối. Có tiếng to*** sấm sét và một tia chớp sáng. Lily hơi sợ, nhưng cô ấy biết mình phải dũng cảm. Cô ấy nói với bố mẹ, và tất cả họ ra ngoài xem chuyện gì đang xảy ra.

Khi họ ra ngoài, họ thấy một cơn bão lớn đang đến. Gió thổi mạnh, và mưa đổ ào ào. Lily, mẹ và bố biết họ phải tìm một nơi an toàn để trú ẩn. Họ tìm thấy một cái cây lớn và trú ẩn dưới đó. Cơn bão qua đi, và mặt trời lại tỏa sáng. Lily, mẹ và bố đều an toàn và ấm áp trong ngôi nhà cổ xưa của họ.

Xin vui lòng cung cấp đánh giá tổng quan của bạn về phần được viết bởi học sinh (phần sau ký hiệu ***). Nó có đúng ngữ pháp không? Nó có nhất quán với phần đầu của câu chuyện không? Hãy đặc biệt chú ý đến việc liệu học sinh có hoàn thành được câu bị chia cắt ở giữa bởi dấu phân cách *** hay không.

Phần hoàn thành câu chuyện của học sinh phần lớn nhất quán với phần đầu của câu chuyện. Nó duy trì sự tập trung vào Lily và gia đình cô ấy, và câu bị chia cắt bởi dấu phân cách được hoàn thành một cách chính xác. Tuy nhiên, phần bổ sung của học sinh không tích hợp đầy đủ những đồ trang trí lấp lánh được tìm thấy trong gác mái, vốn là một phần quan trọng của phần đầu.

Ngữ pháp nói chung là chính xác, nhưng có một vài lỗi nhỏ: ⟨danh sách bị bỏ qua⟩.

Nhìn chung, phần hoàn thành câu chuyện của học sinh thể hiện khả năng ngôn ngữ và sáng tạo tương đối, nhưng có thể được cải thiện bằng cách tích hợp tốt hơn những đồ trang trí lấp lánh và cải thiện ngữ pháp nhỏ.

Bây giờ, hãy chấm điểm phần hoàn thành của học sinh về mặt ngữ pháp, sáng tạo, tính nhất quán với phần đầu của câu chuyện và việc cốt truyện có hợp lý không. Hơn nữa, xin vui lòng đưa ra dự đoán tốt nhất của bạn về độ tuổi của học sinh có thể là bao nhiêu, được phản ánh từ phần hoàn thành. Chọn từ các nhóm tuổi có thể: A: 3 tuổi trở xuống. B: 4-5. C: 6-7. D: 8-9. E: 10-12. F: 13-16.

Ngữ pháp: 8/10, Sáng tạo: 7/10, Tính nhất quán: 7/10, Nhóm tuổi: E (10-12)

Để thực hiện đánh giá đầy đủ, đối với mỗi gợi ý được xây dựng thủ công trong tập đánh giá, chúng tôi sử dụng mô hình đã được huấn luyện để tạo ra 10 phần hoàn thành với nhiệt độ 1. Chúng tôi tính trung bình điểm số đánh giá GPT-4 của tất cả các phần hoàn thành. Hình 3 cung cấp một ví dụ về sự phát triển của các điểm số khác nhau khi quá trình huấn luyện tiến triển, cùng với mất mát huấn luyện và đánh giá, cho một số kích thước mô hình. Hình 4 cho thấy các điểm số khác nhau thay đổi như thế nào với các kích thước và kiến trúc mô hình khác nhau, sau một số bước huấn luyện cố định.

Phương pháp đánh giá của chúng tôi đối với các mô hình được huấn luyện trên TinyStories-Instruct cũng dựa vào GPT-4. Chúng tôi đã triển khai một quy trình đánh giá tương ứng, với một tập dữ liệu đánh giá chứa 50 tập hướng dẫn khác nhau để tạo ra một câu chuyện (chúng tôi đã xác minh rằng những tập này không trùng lặp với tập huấn luyện). Trong giai đoạn chấm điểm, chúng tôi cung cấp cho GPT-4 cả hướng dẫn và câu chuyện được tạo ra. Chúng tôi nhắc GPT-4 dựa vào điểm số nhất quán trên mức độ mà câu chuyện phản ánh chính xác hướng dẫn đã cho. Ngoài ra, chúng tôi thêm danh mục Cốt truyện phản ánh mức độ mà cốt truyện có mạch lạc. Hình 5 minh họa toàn bộ quy trình kết hợp việc tạo ra câu chuyện bởi mô hình của chúng tôi và đánh giá của nó bởi GPT-4. Điểm số được gán cho các mô hình có kích thước khác nhau xuất hiện trong hai cột bên phải của bảng trong Hình 4.

Hình 3: Mất mát đánh giá và điểm số GPT-Eval trong quá trình huấn luyện cho các mô hình GPT-neo với chiều nhúng 768 và số lượng lớp khác nhau. Chúng ta có thể thấy rằng điểm số đánh giá GPT-4 tăng khi mất mát đánh giá giảm.

3.1 Những hiểu biết đầu tiên phát sinh từ phương pháp đánh giá của chúng tôi

Phương pháp đánh giá được đề xuất của chúng tôi đưa ra một cách để có được đánh giá chi tiết hơn về mô hình, nhờ đó chúng tôi có thể rút ra kết luận về sự phụ thuộc của các loại khả năng khác nhau vào kích thước và kiến trúc của mô hình. Trong khi tất cả điểm số đánh giá đều tăng một cách nhất quán khi mất mát đánh giá giảm, việc xem xét cẩn thận hơn các kết quả cho thấy những điều sau:

• Hình 3 gợi ý rằng các mô hình nông hơn hoạt động tốt hơn về mặt ngữ pháp so với tính nhất quán nội dung, có nghĩa là độ sâu mô hình quan trọng hơn đối với việc duy trì tính nhất quán với nội dung hơn là tạo ra ngôn ngữ đúng cú pháp (chúng tôi cung cấp thêm bằng chứng cho điều này trong phần tiếp theo).

• Trong cùng hình đó, chúng tôi quan sát thấy rằng điểm số ngữ pháp đạt ngưỡng ở giai đoạn sớm hơn hai điểm số khác. Hơn nữa, trong Bảng 4, chúng tôi cũng thấy rằng trong khi ngữ pháp có thể được làm chủ bởi các mô hình tương đối nhỏ, tính nhất quán và sáng tạo chỉ xuất hiện ở kích thước lớn hơn.

• Bảng 4 gợi ý thêm rằng khả năng tạo ra một phần hoàn thành nhất quán với phần đầu của câu chuyện xuất hiện khi kích thước ẩn của mô hình tăng từ 64 lên 128.

• Chúng tôi cũng thấy rằng mô hình lớn nhất mà chúng tôi đã huấn luyện trên TinyStories (với khoảng 80M tham số) đạt được điểm số gần như hoàn hảo về mặt ngữ pháp và tính nhất quán. Tuy nhiên, nó còn thiếu khả năng của GPT-4 về mặt sáng tạo khá đáng kể, cho thấy rằng sáng tạo tiếp tục cải thiện đáng kể hơn với kích thước của mô hình và tập dữ liệu, so với ngữ pháp và tính nhất quán.

• Các cột bên phải của Bảng 4 cho thấy rằng các mô hình chỉ có 1 lớp có vẻ gặp khó khăn đáng kể với việc tuân thủ hướng dẫn (có thể phụ thuộc rất nhiều vào chú ý toàn cục), và 2 lớp có vẻ đủ cho một mức độ tuân thủ hướng dẫn nhất định. So sánh điểm số "Instruct" và "Plot" chúng tôi cũng thấy rằng chất lượng tuân thủ hướng dẫn phụ thuộc nhiều hơn vào số lượng lớp, so với tính mạch lạc của cốt truyện mà chiều ẩn quan trọng hơn.

4 Hiệu suất của các mô hình nhỏ được huấn luyện trên TinyStories

Trong phần này, chúng tôi đưa ra một số ví dụ ban đầu minh họa cách TinyStories tạo ra các mô hình có kích thước rất nhỏ có thể tạo ra ngôn ngữ mạch lạc và thể hiện kiến thức thường thức cũng như khả năng lý luận ở một mức độ nhất định. Chúng tôi cũng cung cấp bằng chứng rằng nội dung được tạo ra thực sự đa dạng, bác bỏ khả năng các mô hình chỉ đơn giản đưa ra nội dung đã được "ghi nhớ".

Trong suốt phần này, chúng tôi làm việc với một số kiến trúc mô hình có kích thước từ khoảng 1M đến 35M tham số, và số lượng lớp từ 1 đến 8 lớp. Tất cả các mô hình có thể được huấn luyện trên một GPU V100 duy nhất trong vòng tối đa 30 giờ.

--- TRANG 5 ---

Hình 4: Kết quả đánh giá của các kích thước ẩn và lớp khác nhau cho việc tạo ra câu chuyện và Tính nhất quán (ở đây chúng tôi sử dụng định dạng a/b, a có nghĩa là điểm số gốc, b có nghĩa là điểm số chuẩn hóa theo (a−amin)/(amax−amin)). Đối với các phần tạo sinh GPT-Neo và GPT-2, chúng tôi cắt bỏ kết quả khi có 4-gram lặp lại (sau điểm đó các mô hình sẽ chỉ lặp lại cùng một câu liên tục). Mặt khác, các mô hình của chúng tôi học được khi nào dừng tạo sinh một cách chính xác.

4.1 Ví dụ đầu tiên

Để có cái nhìn tổng quan về khả năng của các mô hình (rất) nhỏ được huấn luyện trên TinyStories, chúng ta hãy xem xét một vài ví dụ đầu tiên. Chúng tôi bắt đầu với câu chuyện sau, được lấy từ tập huấn luyện⁶:

Sara và Ben đang chơi trong tuyết. Họ làm một người tuyết lớn với mũ và khăn quàng. Họ vui vẻ và cười.
Nhưng sau đó một con chó lớn đến. Con chó tức giận và sủa. Nó chạy đến người tuyết và cắn mũ. Sara và Ben sợ hãi và khóc. "Đi đi, chó! Để người tuyết của chúng tôi yên!" Sara hét lên. Nhưng con chó không nghe. Nó cắn khăn quàng và mũi của người tuyết. Nó lắc đầu và làm người tuyết đổ.

Sara và [Ben chạy về nhà. Họ đóng cửa và khóa lại. Họ an toàn và ôm nhau. "Mẹ ơi, mẹ ơi, một con chó lớn đã phá người tuyết của chúng con!" Ben nói. Mẹ đến và ôm họ. Cô ấy tiếc và hôn họ. "Đừng lo, các con yêu. Chúng ta có thể làm người tuyết khác vào ngày mai. Nhưng bây giờ các con cần ấm lên và uống sô cô la nóng. Các con lạnh và ướt." Cô ấy đưa họ vào bếp và pha sô cô la nóng. Cô ấy cho họ bánh quy và kẹo dẻo. Cô ấy bảo họ uống và ăn theo thứ tự. Sara uống trước, sau đó Ben. Ben ăn trước, sau đó Sara. Họ cảm thấy tốt hơn và mỉm cười. Họ cảm ơn mẹ và nói rằng họ yêu cô ấy. Họ thoát khỏi con chó lớn và cái lạnh. Họ hạnh phúc và ấm áp.]

Bây giờ chúng tôi cắt câu chuyện khoảng ở giữa, loại bỏ phần trong dấu ngoặc vuông và tạo ra một kết thúc thay thế với một số mô hình khác nhau.

Để đặt ra một đường cơ sở, chúng tôi bắt đầu với phần hoàn thành được tạo ra bởi GPT2-XL, có kích thước khoảng 1.5 Tỷ tham số:

⁶Bên dưới, sẽ có nhiều ví dụ khác về hoàn thành câu chuyện từ bên ngoài tập huấn luyện.

--- TRANG 6 ---

. . . Sara và Ben khóc và nhìn người tuyết trong tuyết. Ben hỏi có làm gì đó không. Sara bảo anh ta đi chỗ khác. Tay cô ấy siết chặt nút nhỏ màu đỏ. Người tuyết được bao phủ bởi lông. Nó màu đỏ. Nó là tóc thật. Nó là người tuyết thật. Nó trông giống như những người họ từng làm. Ben có nụ cười tươi trên khuôn mặt. Anh ta nhìn khuôn mặt anh ta đã tạo ra. Và anh ta bước qua và hôn đôi mắt. Anh ta vui vẻ khi còn sống. Anh ta đã làm những gì anh ta sẽ làm. Anh ta đã cứu thế giới.

Bây giờ, chúng ta hãy xem phần tạo sinh do một mô hình được huấn luyện trên TinyStories đưa ra, có kích thước khoảng 2.5 triệu tham số⁷:

. . . Sara và Ben rất buồn và giận dữ. Họ khóc và hét vào con chó. "Chó xấu! Chó xấu! Đi đi!" Ben nói. "Đi đi, chó xấu! Để chúng tôi yên!" Sara nói. Con chó không đi đâu. Nó vẫy đuôi và liếm mặt họ. Sara và Ben cảm thấy tiếc cho con chó. Họ muốn làm cho nó vui. "Có lẽ chúng ta có thể làm một người tuyết mới cho nó," Sara nói. "Có lẽ," Ben nói. Họ ôm con chó và đặt tên cho nó. Con chó vẫy đuôi và liếm mặt họ. "Có lẽ nó thích chúng ta," Sara nói. "Có lẽ nó thích chúng ta," Ben nói. Con chó vẫy đuôi và liếm mặt họ. Nó vui vẻ và thân thiện.

Trước hết, chúng tôi lưu ý rằng phần tạo sinh trên rất khác với kết thúc gốc của câu chuyện, điều này cung cấp bằng chứng đầu tiên rằng nó không đơn giản chỉ được ghi nhớ (chúng tôi thảo luận về điều này kỹ hơn sau). Chúng tôi cũng thấy rằng nội dung được tạo ra nhất quán với phần đầu về mặt cốt truyện, nhân vật và sự kiện. Có thể nói, phần tiếp tục này có chất lượng cao hơn phần do GPT2-XL cung cấp mặc dù kích thước của mô hình nhỏ hơn gần 1000 lần.

Tuy nhiên điều này đặt ra câu hỏi liệu các mô hình nhỏ có thực sự ghi nhớ một số lượng nhỏ mẫu và việc tạo sinh rất hạn chế về mặt đa dạng hay không, điều này sẽ là một mối quan tâm hợp lý vào thời điểm này. Chúng tôi giải quyết vấn đề này một cách có hệ thống sau, trong Phần 4.4. Bằng cách kiểm tra sự trùng lặp của các câu chuyện được tạo ra với tập huấn luyện và bằng cách xem xét việc tạo sinh ngoài phân phối, chúng tôi được dẫn đến kết luận rằng những mô hình đó có sự đa dạng đáng kể và không dựa vào việc ghi nhớ.

Tiếp theo, chúng tôi xem xét phần hoàn thành bởi một mô hình có kích thước khoảng 21M tham số, nhưng chỉ có một lớp transformer (và do đó chỉ có một lớp chú ý toàn cục):

. . . Sara và Ben rất buồn. Họ khóc và ôm nhau. Họ ước con chó sẽ đi chỗ khác. Sau đó họ nghe thấy một giọng nói. Đó là mẹ của họ. Cô ấy ra khỏi nhà và thấy họ. "Chuyện gì đã xảy ra ở đây?" cô ấy hỏi. "Tại sao các con khóc?"

Sara và Ben kể cho cô ấy nghe chuyện gì đã xảy ra. Họ kể cho cô ấy về con chó và người tuyết. Mẹ ôm họ và nói, "Đừng lo, các con yêu. Con chó không có ý làm tổn thương các con. Nó chỉ tò mò và thích chơi. Nó không có ý làm tổn thương các con. Nó chỉ muốn chơi."

Sara và Ben cảm thấy tốt hơn. Họ xin lỗi con chó và người tuyết. "Chúng ta có thể vẫn chơi với con chó không?" Sara hỏi. Mẹ mỉm cười và gật đầu. Cô ấy nói, "Có, các con có thể. Nhưng các con phải nhẹ nhàng và cẩn thận. Và các con phải chia sẻ người tuyết với chúng ta." Sara và Ben gật đầu và nói, "Được, mẹ. Chúng con sẽ làm thế." Họ vào trong và uống sô cô la nóng. Chúng ấm và ngon. Họ vui vẻ.

Mặc dù phần hoàn thành này còn xa mới hoàn hảo, nó (có thể nói) nhất quán với phần đầu theo nghĩa là mô hình đã nắm bắt thành công giọng điệu và các yếu tố chính của cốt truyện.

Chúng tôi thừa nhận rằng hai ví dụ trên không phải là các tình huống tồi tệ nhất đối với các mô hình, nhưng chúng cũng không cực kỳ hiếm. Các mô hình có kích thước này đôi khi có thể tạo ra những phần hoàn thành ít mạch lạc hoặc hợp lý hơn, nhưng chúng cũng thường có thể phù hợp hoặc vượt trội hơn chất lượng của những phần được hiển thị ở đây. Tuy nhiên, nếu chúng ta tăng số lượng tham số lên một bậc độ lớn, chúng ta quan sát thấy rằng các mô hình tạo ra những phần tiếp tục mạch lạc và phù hợp một cách nhất quán. Vì mục đích có thể tái tạo, các ví dụ từ điểm này trở đi sẽ được tạo ra ở nhiệt độ bằng không, và ngoài ra, các tham số mô hình được cung cấp như tài liệu bổ sung. Vì mục đích có thể tái tạo, các ví dụ dưới đây đều được tạo ra ở nhiệt độ bằng không, và ngoài ra các tham số mô hình được cung cấp như tài liệu bổ sung.

Để cho độc giả ấn tượng về sự phụ thuộc của chất lượng hoàn thành vào kích thước của mô hình, Hình 6, 7 và 8 mỗi hình cung cấp các hoàn thành khác nhau cho một gợi ý được đưa ra bởi các mô hình có kích thước và độ sâu khác nhau. Mỗi bảng đại diện cho một gợi ý khác nhau, mà chúng tôi đã soạn thảo thủ công⁸.

Chúng ta thấy rằng chất lượng tạo sinh rõ ràng được cải thiện như một yếu tố của kích thước, và có vẻ nhất quán với các điểm số được đưa ra bởi đánh giá GPT-4. Mô hình nhỏ hơn (64 8) hầu như không thể tạo ra phần hoàn thành nhìn có vẻ mạch lạc với phần đầu của câu chuyện, và thường lặp lại chính nó hoặc không có ý nghĩa. Khi kích thước tăng, các mô hình trở nên mạch lạc hơn, và ngữ pháp trở nên tốt hơn. Các mô hình cũng có thể tạo ra những kết thúc đa dạng và sáng tạo hơn, và sử dụng nhiều chi tiết và cảm xúc hơn.

Chúng ta cũng có thể nhận thấy rằng các mô hình với số lượng lớp nhỏ gặp khó khăn trong việc duy trì ngữ cảnh, ngay cả khi chúng có thể tạo ra tiếng Anh đúng cú pháp. Điều này gợi ý rằng mô hình thiếu khả năng nắm bắt các phụ thuộc dài hạn và cấu trúc của câu chuyện. Mặt khác, các mô hình với nhiều lớp hơn có thể duy trì tính nhất quán và logic của câu chuyện tốt hơn.

Một quan sát thú vị là trong Hình 7, mặc dù các phần hoàn thành được tạo ra bởi các mô hình khác nhau, chúng bắt đầu một cách rất tương tự (tất cả các hoàn thành đều liên quan đến một cô bé đến và nói chuyện với quả bí ngô). Chúng tôi chỉ ra rằng lý do cho điều này có vẻ là các phần hoàn thành được tạo ra với nhiệt độ 0. Nói một cách đại khái, điều này đưa ra phần hoàn thành "có khả năng nhất". Để chứng minh rằng mô hình có khả năng tạo ra một tập hợp đa dạng hơn các kết thúc cho câu chuyện, chúng tôi thêm một phần hoàn thành với nhiệt độ khác không. Tuy nhiên, có vẻ như chất lượng hoàn thành hơi giảm khi tăng nhiệt độ⁹.

4.2 Kiến thức, lý luận và theo dõi ngữ cảnh

Tiếp theo, chúng tôi đánh giá khả năng của các mô hình khác nhau trên ba loại gợi ý bổ sung:

• Gợi ý thực tế, kiểm tra kiến thức của các mô hình về các sự kiện thông thường.
• Gợi ý lý luận, kiểm tra khả năng lý luận cơ bản, chẳng hạn như nguyên nhân và kết quả và loại trừ.
• Gợi ý tính nhất quán (theo dõi ngữ cảnh) kiểm tra khả năng của các mô hình để duy trì tính mạch lạc và liên tục với ngữ cảnh đã cho, chẳng hạn như tên và hành động của các nhân vật, bối cảnh và cốt truyện.

Chúng tôi báo cáo các phần tiếp tục được tạo ra cho mỗi mô hình và gợi ý trong ba bảng (Hình 9, Hình 10 và Hình 11), và mã hóa màu chúng theo sự thành công (xanh lá), thất bại (đỏ) hoặc thành công một phần (vàng).

Kết quả cho thấy rằng khi chiều nhúng và số lượng lớp tăng, hiệu suất liên quan đến cả ba danh mục đều được cải thiện. Các mô hình với chiều nhúng cao hơn và nhiều lớp hơn có xu hướng tạo ra những phần tiếp tục chính xác, phù hợp và tự nhiên hơn, trong khi các mô hình với chiều nhúng thấp hơn và ít lớp hơn có xu hướng tạo ra những phần tiếp tục vô nghĩa, mâu thuẫn hoặc không liên quan hơn. Ví dụ, mô hình với 1M tham số và 8 lớp thất bại trong việc trả lời đúng bất kỳ gợi ý thực tế nào, và thường tạo ra các câu không có ý nghĩa hoặc không tuân theo ngữ pháp. Mặt khác, mô hình với 33M tham số và 8 lớp trả lời đúng hầu hết các gợi ý, từ cả ba danh mục. So sánh với các hoàn thành được đưa ra bởi GPT2-XL (cột bên phải), chúng ta thấy rằng bất chấp kích thước lớn hơn nhiều, hiệu suất của nó trong cả ba danh mục đều tệ hơn một số mô hình của chúng tôi.

Một phát hiện thú vị là kiến thức về sự kiện có vẻ phụ thuộc nhiều hơn vào chiều nhúng, trong khi đối với theo dõi ngữ cảnh, số lượng lớp quan trọng hơn. Ví dụ, mô hình chỉ có 1 lớp không trả lời đúng bất kỳ gợi ý nhất quán nào, nhưng trả lời đúng một số sự kiện, trong khi mô hình với chiều nhúng 64 không trả lời đúng bất kỳ sự kiện nào, nhưng có thể duy trì tính nhất quán một số lần. Điều này cho thấy rằng chiều nhúng quan trọng hơn để nắm bắt ý nghĩa và mối quan hệ của các từ, trong khi số lượng lớp quan trọng hơn để nắm bắt các phụ thuộc dài hạn trong việc tạo sinh.

Mô hình | Văn bản được tạo ra | Điểm số
Gợi ý | Ngày xưa có một cô bé tên Lucy. Cô ấy rất thích phiêu lưu. Cô ấy thích khám phá thế giới xung quanh, đặc biệt là khi trời sáng và có nắng.
Một ngày nọ, khi khám phá công viên gần đó, Lucy bắt gặp một cái thang tựa vào tường. Cô ấy tò mò muốn xem có gì ở trên đó, vậy nên cô ấy trèo lên thang, nhưng khi cô ấy lên đến đỉnh, cái thang đổ và cô ấy bị mắc kẹt.
Một nhân viên bảo vệ công viên gần đó nhận thấy cô ấy và hét lên, "

1M 8 lớp | Bạn đang làm gì ở đây?"
Lucy mỉm cười và nói, "Tôi sẽ giúp đỡ!"
Nhân viên bảo vệ mỉm cười và nói, "Đó là một ý tưởng tuyệt vời! Chúng ta hãy xem liệu chúng ta có thể tìm ra được không." Lucy rất phấn khích và nói, "Vâng, chúng ta hãy đi!"
Vậy là, Lucy và nhân viên bảo vệ đến công viên. Họ tìm thấy nhiều thứ vui và có rất nhiều niềm vui. | Ngữ pháp: 6/10 Sáng tạo: 3/10 Tính nhất quán: 2/10

2.5M 8 lớp | Lucy à?"
Lucy trả lời, "Tôi đang cố gắng ra khỏi cái thang, nhưng tôi không thể ra được!"
Nhân viên bảo vệ mỉm cười và nói, "Đừng lo, tôi sẽ giúp bạn ra khỏi cái thang. Tôi sẽ giúp bạn ra."
Vậy là, Lucy và nhân viên bảo vệ ra khỏi cái thang và bắt đầu trèo lên thang. Khi họ xuống đến đáy, Lucy rất vui. Cô ấy cảm ơn nhân viên bảo vệ vì đã giúp cô ấy và nói, "Tôi vui vì có thể giúp đỡ."
Nhân viên bảo vệ mỉm cười và nói, "Không có gì, Lucy. Tôi vui vì có thể giúp đỡ." | Ngữ pháp: 5/10 Sáng tạo: 6/10 Tính nhất quán: 3/10

⁸Chúng tôi đã xác minh thủ công rằng tập dữ liệu không chứa bất kỳ mục nào tương tự hoặc gần giống với những gợi ý này.
⁹Chúng tôi không trình bày thêm bằng chứng cho tuyên bố này vì nó vượt ra ngoài phạm vi của bài báo.

--- TRANG 7 ---

4.3 Ví dụ tuân thủ hướng dẫn và tạo sinh ngoài phân phối

Bảng 12 cung cấp một ví dụ về việc tạo sinh của các mô hình khác nhau được huấn luyện trên tập dữ liệu TinyStories-Instruct, cùng với điểm số đánh giá do GPT-4 đưa ra. Khi kích thước mô hình tăng, chúng ta thấy sự cải thiện cả khả năng tuân thủ hướng dẫn và tạo ra một cốt truyện mạch lạc.

Tập dữ liệu này cũng cho phép chúng tôi kiểm tra liệu các mô hình của chúng tôi có hiệu suất ngoài phân phối hợp lý hay không. Nhớ lại rằng trong mỗi mục của TinyStories-Instruct, các hướng dẫn được tạo ra như một sự kết hợp (ngẫu nhiên) của các loại hướng dẫn có thể (từ cần sử dụng, tóm tắt, câu quy định, tính năng). Chúng tôi tạo ra một biến thể khác của TinyStories-Instruct (gọi là TinyStories-Instruct-OOD) nơi chúng tôi không cho phép một sự kết hợp cụ thể của các loại hướng dẫn: Tập dữ liệu không chứa bất kỳ mục nào mà hướng dẫn kết hợp cả tóm tắt của câu chuyện

--- TRANG 8 ---

và các từ mà câu chuyện cần sử dụng (chúng tôi chọn sự kết hợp cụ thể này vì theo một nghĩa nào đó, nó là sự kết hợp hạn chế nhất). Sau đó chúng tôi kiểm tra liệu các mô hình được huấn luyện trên biến thể này có thể tạo ra các câu chuyện tuân theo hai loại hướng dẫn này kết hợp. Một ví dụ được cung cấp trong Hình 13, cho một mô hình với 33M tham số. Chúng ta thấy rằng, có lẽ hơi bất ngờ, mô hình có thể tuân theo hai loại hướng dẫn này đồng thời ngay cả khi nó chưa bao giờ được huấn luyện trên tác vụ như vậy.

4.4 Tính đa dạng của nội dung được tạo ra bởi mô hình

Một trong những thách thức chính của việc tạo văn bản là tạo ra các văn bản đa dạng và sáng tạo không chỉ là những lặp lại hoặc biến thể của các văn bản hiện có. Các mô hình nhỏ của chúng tôi có thể tạo ra văn bản tiếng Anh mạch lạc và trôi chảy, nhưng điều này sẽ không ấn tượng lắm nếu chúng chỉ đơn giản sao chép hoặc diễn giải lại các phần lớn của tập dữ liệu. Do đó, trong phần này, chúng tôi nhằm mục đích giải quyết mối quan tâm này. Chúng tôi sẽ cung cấp một số phương pháp và chỉ số cho thấy rằng các mô hình có thể tạo ra các văn bản đa dạng không tương tự với bất kỳ câu chuyện nào trong tập dữ liệu, và chúng có thể thích ứng với các hướng dẫn và ngữ cảnh khác nhau.

Để đánh giá tính đa dạng của nội dung được tạo ra bởi các mô hình, trước tiên chúng tôi cần định nghĩa ý nghĩa của

--- TRANG 9 ---

việc ghi nhớ, và những loại ghi nhớ nào chúng tôi muốn tránh hoặc phát hiện. Chúng tôi phân loại ba mức độ ghi nhớ như sau:

• Ghi nhớ hoàn toàn: Đây là hình thức ghi nhớ đơn giản và rõ ràng nhất, nơi mô hình đơn giản chỉ sao chép toàn bộ một câu chuyện hoặc một phần lớn của nó từ tập dữ liệu, mà không thay đổi gì. Điều này có thể dễ dàng được phát hiện bằng cách kiểm tra sự tương tự hoặc hash của câu chuyện được tạo ra với các câu chuyện trong tập dữ liệu.

• Khớp mẫu đơn giản: Đây là một hình thức ghi nhớ phức tạp hơn một chút, nơi mô hình thay đổi một số tên hoặc thực thể trong một câu chuyện từ tập dữ liệu, nhưng giữ nguyên phần còn lại của câu chuyện. Ví dụ, mô hình có thể thay đổi tên của các nhân vật, hoặc địa điểm của câu chuyện, nhưng giữ nguyên cốt truyện và các sự kiện. Điều này có thể được phát hiện và ngăn chặn bằng cách đo sự trùng lặp của từ và n-gram giữa câu chuyện được tạo ra và các câu chuyện trong tập dữ liệu.

• Khớp mẫu phức tạp: Đây là hình thức ghi nhớ tinh vi và khó khăn nhất, nơi mô hình theo một mẫu hoặc cấu trúc trừu tượng hơn từ tập dữ liệu, giữ nguyên cốt truyện chung nhưng thay đổi các chi tiết và đặc điểm cụ thể của câu chuyện. Điều này gần như không thể định lượng, vì nó đòi hỏi hiểu biết và phân tích sâu sắc hơn về nội dung và ý nghĩa của các câu chuyện, và cách chúng liên quan đến nhau.

Chúng tôi tuyên bố rằng các mô hình của chúng tôi không thực hiện ghi nhớ hoàn toàn hoặc khớp mẫu đơn giản, như được chứng minh bằng các phương pháp và chỉ số chúng tôi sử dụng để đánh giá tính đa dạng của nội dung được tạo ra bởi các mô hình. Chúng tôi dựa vào một số cách tiếp cận:

• Kiểm tra thủ công: Chúng tôi tạo ra các phần hoàn thành cho một loạt các câu chuyện do con người xây dựng. Chúng tôi kiểm tra các câu chuyện được tạo ra bởi các mô hình và kiểm tra rằng chúng không phải là bản sao hoặc sửa đổi gần giống với các câu chuyện trong tập dữ liệu.

• Hoàn thành các câu chuyện huấn luyện: Chúng tôi lấy các câu chuyện từ tập huấn luyện, cắt bớt chúng ở giữa và tạo ra các phần hoàn thành thay thế với các mô hình của chúng tôi. Sau đó chúng tôi so sánh các phần hoàn thành với các câu chuyện gốc. Chúng tôi quan sát thấy rằng các phần hoàn thành thường rất khác với các câu chuyện gốc, và thường giới thiệu các nhân vật, sự kiện hoặc bước ngoặt mới. Điều này được hiển thị trong Hình 14.

• Tính đa dạng của hướng dẫn: Nhớ lại rằng trong tập dữ liệu TinyStories-Instruct, chúng tôi cung cấp một tập hướng dẫn dưới dạng tóm tắt hoặc từ có trong các câu chuyện, tiếp theo là chính các câu chuyện. Sau đó chúng tôi có thể thay đổi các hướng dẫn, xác minh rằng các sự kết hợp không xuất hiện trong tập dữ liệu và xem các mô hình thích ứng với các hướng dẫn mới như thế nào. Chúng tôi thấy rằng các mô hình có thể tạo ra các câu chuyện đa dạng tuân theo các hướng dẫn, ngay cả khi chúng mới lạ hoặc thách thức, chẳng hạn như yêu cầu mô hình khớp các từ không có khả năng vào câu chuyện hoặc thêm các tính năng như bước ngoặt cốt truyện hoặc kết thúc xấu.

4.4.1 Đo lường định lượng về sự tương tự bằng điểm số Rouge.

Chúng tôi đo tính đa dạng của các câu chuyện một cách định lượng bằng cách sử dụng sự trùng lặp từ và n-gram. Chúng tôi kiểm tra sự trùng lặp của từ và n-gram giữa các câu chuyện khác nhau được tạo ra bởi các mô hình, và so sánh chúng với sự trùng lặp trong tập dữ liệu. Chúng tôi thấy rằng các phần tạo sinh của các mô hình có sự trùng lặp rất thấp với tập dữ liệu, cho thấy rằng chúng không lặp lại cùng những từ hoặc cụm từ. Chúng tôi sử dụng điểm số Rouge chuẩn, đối với văn bản nguồn T1, T2 với k-gram Gk(T1),Gk(T2) tương ứng, điểm số chính xác rouge k được định nghĩa là:

Rk,p(T1, T2) = 1/|Gk(T1)| ∑t∈Gk(T1) 1t∈Gk(T2).

--- TRANG 10 ---

Điểm số chính xác Rouge k đo lường có bao nhiêu k-gram trong T1 được bao gồm trong T2. Điểm số Rouge k cuối cùng (f-measure) được đưa ra như:

Rk(T1, T2) = 2Rk(T1, T2) × Rk(T2, T1) / (Rk(T1, T2) + Rk(T2, T1)).

Chúng tôi thực hiện thí nghiệm sau: Chúng tôi chọn ngẫu nhiên 100 câu chuyện từ tập dữ liệu huấn luyện, chúng tôi cắt mỗi câu chuyện ở giữa, giữ lại khoảng 40% đầu tiên, và sử dụng nó làm gợi ý. Chúng tôi yêu cầu mô hình tạo ra một phần hoàn thành từ mỗi gợi ý. Gọi T1, T2,···, T100 là các phần hoàn thành được tạo ra và T'1, T'2,···, T'100 là phần hoàn thành gốc, chúng tôi đo:

1. Có bao nhiêu phần tạo sinh mới được chứa trong câu chuyện gốc (Hình 14), có nghĩa là:
   si := R2,p(Ti, T'i).

2. Các 100 câu chuyện được tạo ra tương tự nhau như thế nào (Hình 15), có nghĩa là:
   ri := maxj≠i R2(Ti, Tj)

3. Các k-gram trong câu chuyện được tạo ra được sao chép từ tập dữ liệu huấn luyện đến mức nào (Hình 16). Chính xác hơn, chúng tôi lấy S là toàn bộ kho dữ liệu huấn luyện, đối với mỗi r ∈ Gk({Ti}i∈[100]) chúng tôi đo
   gr := ∑q∈Gk(S) 1gr=q / |∑q∈Gk(S)|

Nói cách khác, đối với mỗi k-gram được tạo ra bởi mô hình, chúng tôi đo tần suất mà nó xuất hiện trong tập dữ liệu huấn luyện gốc, trong đó gr = 0 có nghĩa là k-gram không bao giờ xuất hiện trong tập dữ liệu huấn luyện.

4. Câu chuyện được tạo ra tương tự như thế nào với điểm gần nhất, về mặt điểm số chính xác Rouge, trong toàn bộ tập dữ liệu. Gọi S1, S2,···, Sm là tất cả các câu chuyện trong tập dữ liệu huấn luyện, trong Hình 17, chúng tôi tính
   hi = maxj∈[m] R2,p(Ti, Sj)

Hình 14: Điểm số Rogue2 (chính xác) giữa phần hoàn thành của mô hình và câu chuyện gốc từ cùng phần đầu (chúng tôi chọn 100 từ tập dữ liệu huấn luyện). Chúng ta có thể thấy rằng hầu hết các phần hoàn thành mà các mô hình tạo ra rất khác với những phần trong tập dữ liệu huấn luyện (và cũng không phải là các phiên bản phụ của những câu chuyện gốc).

Hình 15: Điểm số Rouge2 tối đa (f-measure) tương tự giữa 100 câu chuyện được tạo ra cho mỗi mô hình. Ở đây mô hình gốc có nghĩa là những câu được tạo ra bởi GPT-3.5.

Vì mục đích có được ấn tượng cụ thể hơn về sự khác biệt của các phần hoàn thành mô hình so với kết thúc gốc của câu chuyện và từ các câu chuyện khác trong tập dữ liệu, trong Hình 18 chúng tôi cung cấp một ví dụ về câu chuyện gốc, phần hoàn thành thay thế bởi mô hình của chúng tôi cùng với điểm gần nhất của nó trong tập dữ liệu huấn luyện.

Các điểm trên hướng đến một số phát hiện:

• Khi mô hình tạo ra các câu chuyện bằng cách sử dụng một tập hợp đa dạng các gợi ý, nó kết thúc với một tập hợp đa dạng các phần hoàn thành.

--- TRANG 11 ---

Hình 16: Biểu đồ tần suất của việc mỗi k-gram trong các phần tạo sinh của mô hình xuất hiện bao nhiêu lần (phần) cũng xuất hiện trong dữ liệu huấn luyện theo thang logarit (cơ số 10). −10 có nghĩa là nó không bao giờ xuất hiện. Chúng ta có thể thấy rằng hầu hết các 4, 5-gram trong các phần tạo sinh của mô hình thậm chí không xuất hiện một lần trong toàn bộ dữ liệu huấn luyện.

Hình 17: Biểu đồ tần suất cho mỗi câu chuyện được tạo ra, điểm số rougek cao nhất (chính xác) đối với các câu chuyện trong tập dữ liệu huấn luyện. Chúng ta có thể thấy rằng các phần tạo sinh của mô hình không sao chép từ bất kỳ câu chuyện cụ thể nào trong tập dữ liệu huấn luyện.

[Phần đầu (gợi ý) và các đoạn văn tiếp theo được dịch theo format của bản gốc]

Hình 18: Điểm gần nhất trong tập dữ liệu với phần hoàn thành thay thế

--- TRANG 12 ---

• Khi hoàn thành các câu chuyện từ tập dữ liệu, các phần hoàn thành thường rất khác với câu chuyện gốc.

• Các k-gram điển hình trong các phần hoàn thành được tạo ra hiếm khi xuất hiện trong tập dữ liệu, đối với các giá trị k nhỏ như 4 hoặc 5.

• Điểm gần nhất trong tập dữ liệu với mỗi phần hoàn thành được tạo ra thường vẫn khá xa so với nó.

Tất cả những điều trên, kết hợp với khả năng của các mô hình được huấn luyện trên TinyStories-Instruct để tuân theo thành công các tập hướng dẫn mà chúng tôi có thể dễ dàng xác minh là không trùng lặp với tập dữ liệu (ví dụ, các sự kết hợp của từ có thể được kiểm tra), cung cấp bằng chứng mạnh mẽ rằng các mô hình của chúng tôi tạo ra những câu chuyện thực sự mới lạ và đa dạng, thay vì những biến thể đơn giản của các câu chuyện hiện có.

Chúng tôi lưu ý rằng tuy nhiên, chúng tôi không thể hoàn toàn loại trừ khả năng các mô hình thực hiện khớp mẫu phức tạp, vì khó định nghĩa và đo lường những gì tạo thành một cốt truyện mới hoặc một câu chuyện mới. Chúng tôi thừa nhận rằng đây là một hạn chế của đánh giá của chúng tôi. Một khả năng khác là các câu chuyện trong tập dữ liệu về cơ bản bao trùm toàn bộ support của phân phối trong chỉ số (yếu) của việc khớp mẫu phức tạp.

5 Tính diễn giải

Hiểu được hoạt động bên trong của các mạng nơ-ron sâu và các mô hình ngôn ngữ nói riêng là một thách thức lớn trong lĩnh vực nghiên cứu này. Ví dụ, thường khó gán một chức năng cụ thể cho một thành phần nhất định của một mạng nơ-ron. Điều này có thể do, trái ngược với trực giác của chúng ta dựa trên các chương trình do con người thiết kế, các thành phần mạng có thể không có vai trò riêng biệt, mà tương tác theo cách phức tạp và lộn xộn. Trong phần này, chúng tôi trình bày một số bằng chứng sơ bộ rằng việc huấn luyện các mô hình nhỏ hơn trên TinyStories dẫn đến tính diễn giải cao hơn, cho thấy rằng khi các mạng bị hạn chế về kích thước, chúng ta có thể thu được một số hiểu biết về cơ chế nội bộ của chúng.

Chúng tôi tập trung vào hai khía cạnh của mô hình: các đầu chú ý và các nơ-ron trong MLP.

Vì đây không phải là trọng tâm chính của bài báo, phần này không đầy đủ và cần nhiều công việc hơn để đạt được những phát hiện kết luận hơn. Thay vào đó, chúng tôi chỉ đưa ra một số bằng chứng sơ bộ có thể hy vọng thúc đẩy công việc trong tương lai.

Các đầu chú ý. Trong nghiên cứu về các đầu chú ý, chúng tôi tận dụng thực tế là chúng tôi có thể huấn luyện một mô hình rất nông (chỉ có một khối transformer) vẫn có thể tạo ra văn bản có ý nghĩa. Vì mô hình chỉ có một lớp, các đầu chú ý trực tiếp chịu trách nhiệm tạo ra các token đầu ra, và do đó chúng có thể có các chức năng dễ diễn giải hơn so với các mô hình sâu hơn. Chúng tôi sử dụng phương pháp của Voita et al [30] để phân tích các mẫu chú ý của các đầu và phân loại chúng thành các loại khác nhau, chẳng hạn như vị trí, cú pháp hoặc ngữ nghĩa. Chúng tôi cũng sử dụng phương pháp của Clark et al [6] để hình dung các bản đồ chú ý của các đầu và kiểm tra hành vi của chúng trên các ví dụ cụ thể.

Các phát hiện của chúng tôi cho thấy rằng các đầu chú ý thể hiện các chức năng đa dạng và có ý nghĩa, chẳng hạn như chú ý đến từ trước, chủ ngữ của câu, cuối câu hoặc chủ đề chính của câu chuyện. Chúng tôi cũng quan sát thấy rằng một số đầu chú ý chuyên biệt trong việc tạo ra các loại từ nhất định, chẳng hạn như danh từ, động từ hoặc dấu câu. Những kết quả này cho thấy rằng các đầu chú ý học cách thực hiện các tác vụ ngôn ngữ khác nhau và nắm bắt các khía cạnh khác nhau của các câu chuyện.

Các nơ-ron trong MLP. Chúng tôi cũng đưa ra một số bằng chứng ban đầu rằng trong các mô hình nhỏ hơn, một số nơ-ron trong MLP có vai trò có thể diễn giải bởi con người. Chúng tôi sử dụng phương pháp tương tự như [18] để xác định các token có ảnh hưởng nhất trong MLP cho mỗi nơ-ron. Chúng tôi thấy rằng một số nơ-ron được kích hoạt trên các từ có vai trò cụ thể trong câu (chẳng hạn như chủ ngữ hoặc hành động), hoặc trong câu chuyện (chẳng hạn như giới thiệu nhân vật chính). Những phát hiện này cho thấy rằng các nơ-ron trong MLP học cách mã hóa thông tin ngữ nghĩa và phong cách khác nhau và ảnh hưởng đến quá trình tạo sinh.

5.1 Diễn giải vai trò của các đầu chú ý khác nhau

Để hiểu mẫu chú ý của mô hình sau khi huấn luyện, chúng tôi sử dụng một mô hình 1 lớp với chiều ẩn 1024 và 16 đầu chú ý được huấn luyện trên TinyStories. Chúng tôi hình dung các mẫu chú ý mà nó tạo ra khi xử lý đoạn văn sau (phần in đậm là gợi ý, phần tô sáng là do mô hình tạo ra):

Một ngày nọ, Lucy hỏi Tom: "Tôi đang tìm một quả chuối nhưng tôi không thể tìm thấy nó". Tom nói: "Đừng lo, tôi sẽ giúp bạn". Lucy và Tom đi đến công viên. Họ cùng nhau tìm quả chuối. Sau một lúc, họ tìm thấy quả chuối. Lucy vui vẻ. Cô ấy nói: "Cảm ơn, Tom. Bạn là một người bạn tốt." Tom: "Không có gì, Lucy. Tôi vui khi giúp bạn. Hãy cùng nhau ăn quả chuối!"

--- TRANG 13 ---

Có vẻ như có sự phân tách rõ ràng giữa các đầu có mẫu chú ý chủ yếu dựa trên khoảng cách giữa các token, và các đầu có mẫu chú ý phụ thuộc mạnh hơn vào ý nghĩa ngữ nghĩa:

Chú ý dựa trên khoảng cách. Trong số 16 đầu chú ý, chúng tôi quan sát thấy nhiều đầu chú ý dựa trên vị trí, sao cho mỗi token chú ý đến các token có khoảng cách tương đối quy định. Các đầu khác nhau được liên kết với các khoảng cách khác nhau.

Hình 19: Chú ý dựa trên khoảng cách đa tỷ lệ.

Chú ý dựa trên ngữ nghĩa. Chúng tôi cũng quan sát thấy rằng có (1). một đầu mà từ "the" và "a" đều chú ý đến từ "banana", thú vị là, "the" ở "the park" cũng chú ý đến "banana", nhưng mô hình vẫn có thể tạo ra "park", là phần hoàn thành nhất quán. (2). Một đầu chú ý khác cho một mẫu mà các token "the" và "a" đều chú ý đến "park". (3). Có đầu thứ ba mà hầu hết các từ chú ý đến tên "Tom" và "Lucy".

Chúng tôi lưu ý rằng việc tạo ra các từ như "the", "a", "and" hoặc "," sẽ được tạo ra bởi các đầu chú ý dựa trên khoảng cách, cục bộ, điều này có lý vì đây là những token có vai trò ngữ pháp phụ thuộc vào các tương tác ngắn hạn trong một câu duy nhất. Mặt khác, các thực thể chính trong câu chuyện như "banana", "park", "Lucy" và "Tom" thường không thể được dự đoán (như token tiếp theo) chỉ dựa trên các token lân cận, đó là lý do tại sao mô hình cần sử dụng các đầu chú ý ngữ nghĩa để tạo ra chúng.

Hình 20: Chú ý ngữ nghĩa theo (1), (2), (3).

5.2 Diễn giải vai trò của các Nơ-ron khác nhau

Để kiểm tra liệu các nơ-ron có vai trò có ý nghĩa hay không, chúng tôi theo [18], và hình dung các token quan trọng nhất cho mỗi nơ-ron. Chính xác hơn, chúng tôi lấy một bộ sưu tập 20 câu chuyện (khoảng 8.000 token) từ tập dữ liệu của chúng tôi. Chúng tôi lấy một mô hình được huấn luyện trên TinyStories, chúng tôi chọn một lớp transformer, và từ MLP liên kết với nó chúng tôi chọn một tọa độ trong lớp trung gian của nó. Chúng tôi gọi sự lựa chọn như vậy là một nơ-ron. Chúng tôi xử lý bộ sưu tập các câu chuyện với mô hình để có được biểu diễn nội bộ của chúng, điều này cho chúng tôi giá trị kích hoạt cho mỗi sự kết hợp của token và nơ-ron. Sau đó, đối với mỗi nơ-ron chúng tôi nhìn vào các token với kích hoạt cao nhất từ toàn bộ bộ sưu tập. Chúng tôi làm nổi bật những token đó màu đỏ (và trình bày chúng cùng với câu mà chúng được chứa trong). Chúng tôi lặp lại điều này cho hai mô hình: một mô hình nhỏ với chiều ẩn 64 và 1M tham số, được huấn luyện trên TinyStories (Hình 21), và trên GPT2-XL (Hình 22).

Trong mô hình 1M tham số được huấn luyện trên TinyStories, Hình 21 đầu tiên trình bày các token được kích hoạt cho hai nơ-ron đầu tiên trong lớp trước cuối¹⁰. Lưu ý rằng, vì kiến trúc không thay đổi đối với các hoán vị giữa các nơ-ron, việc lấy hai nơ-ron đầu tiên cũng giống như lấy một lựa chọn tùy ý của hai nơ-ron, điểm là những nơ-ron này không phải là duy nhất cũng không được chọn lọc. Chúng ta thấy (hàng trên của hình) rằng mỗi nơ-ron đó được kích hoạt trên các token có vai trò chung (một được kích hoạt trên đại từ cũng là chủ ngữ trong câu, và cái kia được kích hoạt trên hành động trong câu). Ngoài ra, chúng tôi trình bày các token được kích hoạt cho nơ-ron đầu tiên trong lớp khác (lớp 6), nơi nơ-ron được kích hoạt chỉ trên tính từ. Cuối cùng, chúng tôi chọn nơ-ron có giá trị kích hoạt lớn nhất trên tất cả các sự kết hợp của token và nơ-ron. Nơ-ron này (được mô tả ở góc dưới bên phải) có vẻ có vai trò xác định lần đầu tiên nhân vật chính của câu chuyện được trình bày.

Để so sánh, Hình 22 trình bày các token được kích hoạt cho hai nơ-ron đầu tiên của lớp 12 cho GPT-XL, một mạng nơ-ron lớn hơn nhiều. Trong trường hợp này, không có nơ-ron nào trong hai nơ-ron có vẻ có vai trò rõ ràng.

[Các bảng mô tả các token được kích hoạt cho các nơ-ron khác nhau]

Hình 21: Các token tạo ra kích hoạt cao đối với các nơ-ron khác nhau, cho một mô hình nhỏ được huấn luyện trên TinyStories.

6 Khám phá kiến trúc và siêu tham số cho NLP với TinyStories

Một trong những thách thức chính trong việc phát triển các mô hình ngôn ngữ lớn (LLM) đến từ chi phí tính toán cao trong việc huấn luyện. Việc tìm ra các kiến trúc tốt nhất, thuật toán huấn luyện và siêu tham số cho LLM đòi hỏi nhiều tài nguyên và thí nghiệm. Do đó, sẽ hữu ích nếu có một tập dữ liệu nhỏ hơn và đơn giản hơn vẫn có thể nắm bắt một số khả năng cơ bản của LLM, và cho phép chúng ta nghiên cứu cách các lựa chọn thiết kế khác nhau ảnh hưởng đến hiệu suất của chúng. TinyStories là một tập dữ liệu như vậy, vì nó cho phép chúng ta huấn luyện và đánh giá các LM có thứ tự độ lớn nhỏ hơn so với các mô hình hiện đại, nhưng vẫn có khả năng cơ bản tạo ra văn bản mạch lạc.

Trong công việc này, chúng tôi thực hiện các bước đầu tiên hướng tới việc sử dụng TinyStories như một bệ thử nghiệm để khám phá các kiến trúc và siêu tham số cho NLP. Chúng tôi cho thấy rằng các mô hình nhỏ của chúng tôi thể hiện một số mẫu tương tự với những mẫu quan sát được trong LLM ở một số khía cạnh nhất định. Cụ thể, chúng tôi điều tra hai câu hỏi: cách cân bằng kích thước mô hình và ngân sách học tập cho một lượng flops huấn luyện cố định, và cách chọn số lượng đầu chú ý cho một chiều rộng và chiều sâu mô hình nhất định.

Kích thước mô hình so với FLOPs huấn luyện. Đối với một lượng flops huấn luyện cố định, có sự đánh đổi giữa kích thước của mô hình và số bước huấn luyện (tổng số flops là tích của cả hai). Các công trình trước đây [16, 11] đã chỉ ra rằng có một luật mở rộng đa thức giữa kích thước mô hình và ngân sách học tập cho LLM, tức là, kích thước mô hình tối ưu cho một lượng flops nhất định tỷ lệ thuận với flops được nâng lên lũy thừa nào đó α > 1. Tuy nhiên, những công trình này sử dụng các phạm vi kích thước mô hình khác nhau (từ vài triệu đến hàng chục tỷ tham số) và tìm thấy các giá trị α khác nhau (khoảng 0,7 và 0,5, tương ứng). Một câu hỏi tự nhiên là liệu luật mở rộng này có phổ quát hay phụ thuộc vào tập dữ liệu. Tập dữ liệu của chúng tôi cho phép chúng tôi tiến hành một thí nghiệm tương tự nhưng với các mô hình và flops nhỏ hơn nhiều. Đáng ngạc nhiên, chúng tôi tìm thấy bằng chứng cho một luật mở rộng đa thức tương tự, điều này cho thấy rằng có thể có một hiện tượng phổ quát ở đây.

Chúng tôi huấn luyện các mô hình có kích thước và kiến trúc khác nhau trên TinyStories. Đối với mỗi lượng flops, chúng tôi chọn mô hình và số bước huấn luyện đạt được mất mát xác thực thấp nhất trong số các sự kết hợp có thể. Chúng tôi thay đổi số lượng lớp từ 2, 4, 8, 12 và chiều ẩn từ 64, 128, 256, 512, 768, 1024, 2048. Kết quả được hiển thị trong Hình 6. Mặc dù số lượng điểm có thể hơi nhỏ để dữ liệu rất kết luận, biểu đồ chỉ ra một sự phụ thuộc đa thức.

Chọn số lượng đầu. Một lựa chọn thiết kế khác cho transformer là số lượng đầu chú ý cho mỗi lớp. Không rõ ràng số lượng đầu ảnh hưởng như thế nào đến hiệu suất của mô hình, với chiều rộng và chiều sâu mô hình cố định. Kết quả của chúng tôi, được hiển thị trong Hình 24, cho thấy rằng trong chế độ mà số lượng đầu nhỏ, việc tăng nó cải thiện hiệu suất của mô hình trên tất cả các chỉ số.

¹⁰Lý do đằng sau việc chọn lớp áp chót là các token đã được xử lý bởi hầu hết các lớp vào thời điểm này. Chúng tôi lấy lớp trước cuối thay vì lớp cuối vì biểu diễn ẩn trong lớp cuối chỉ có vai trò dự đoán token tiếp theo, vì vậy thông tin có thể bị mất vào thời điểm đó.

--- TRANG 14 ---

Hình 23: Luật mở rộng của mô hình tốt nhất so với tổng số flops huấn luyện.

[Bảng hiển thị hiệu suất mô hình với số lượng đầu chú ý khác nhau]

Hình 24: Hiệu suất mô hình với số lượng đầu chú ý khác nhau

7 Các công trình liên quan

Các mô hình ngôn ngữ tạo sinh (LM) đã đạt được kết quả ấn tượng trong nhiều tác vụ xử lý ngôn ngữ tự nhiên khác nhau, chẳng hạn như tóm tắt văn bản, tạo đối thoại và hoàn thành câu chuyện. Tuy nhiên, hầu hết các mô hình này rất lớn, với hàng trăm triệu hoặc thậm chí hàng tỷ tham số, điều này đặt ra những thách thức đáng kể cho việc huấn luyện, suy luận và triển khai. Ví dụ, GPT-3 [4], một trong những LM lớn nhất cho đến nay, có 175 tỷ tham số và đòi hỏi hàng trăm petaflops tính toán để huấn luyện. Các mô hình nhỏ hơn, chẳng hạn như GPT-2 nhỏ với 125 triệu tham số, hầu như không thể tạo ra các câu mạch lạc và nhất quán vượt quá vài từ, ngay cả sau khi pre-training mở rộng trên các bộ dữ liệu lớn [23].

Một số phương pháp đã được đề xuất để nén hoặc chưng cất các LM lớn thành các mô hình nhỏ hơn, chẳng hạn như chưng cất kiến thức [10, 2], cắt tỉa [8] và lượng tử hóa [13]. Tuy nhiên, các phương pháp này hiệu quả hơn nhiều đối với các mô hình giống BERT [25, 28], được thiết kế cho mô hình hóa ngôn ngữ có mặt nạ và các tác vụ phân loại downstream, hơn là đối với các mô hình giống GPT, được thiết kế cho việc tạo ngôn ngữ tự hồi quy [26].

Một thách thức khác đối với các LM tạo sinh là việc đánh giá các đầu ra của chúng. Không giống như các mô hình giống BERT, có thể được fine-tune và đánh giá trên các tác vụ downstream với dữ liệu có nhãn, các mô hình giống GPT khó đo lường hơn về mặt họ có thể "nói và hiểu ngôn ngữ tự nhiên" tốt đến mức nào. Hầu hết các tiêu chuẩn đánh giá hiện có cho các LM tạo sinh, chẳng hạn như LAMBADA [22], CLOZE [29], TriviaQA [15] và Winograd Schema Challenge [17], yêu cầu các mô hình tạo ra một từ duy nhất hoặc một cụm từ ngắn làm câu trả lời, điều này không nắm bắt được sự phong phú và đa dạng của việc tạo ngôn ngữ tự nhiên. Hơn nữa, các tiêu chuẩn đánh giá này thường bị hạn chế bởi kích thước và chất lượng của các tập dữ liệu, sự mơ hồ và chủ quan của các câu trả lời, và sự thiếu hụt đánh giá của con người. Các tập dữ liệu lớn hơn và đa dạng hơn như BigBench [27] đơn giản là quá phức tạp đối với SLM. Một số tiêu chuẩn đánh giá khác, chẳng hạn như WikiSQL [33], có định dạng đầu ra có cấu trúc hơn, điều này làm cho chúng dễ đánh giá hơn, nhưng cũng ít đại diện cho việc tạo ngôn ngữ tự nhiên.

Công việc của chúng tôi cũng có lợi cho việc phân tích lý thuyết về các mô hình transformer và quá trình học tập của chúng. Hầu hết các công trình lý thuyết hiện có tập trung vào các mô hình với một khối transformer, dễ phân tích hơn so với các mô hình có nhiều khối. Ví dụ, Voita et al [30] đã chỉ ra rằng một khối transformer có thể học cách thực hiện các tác vụ ngôn ngữ khác nhau tùy thuộc vào vị trí của lớp self-attention. Li et al [19] chỉ ra một khối transformer có thể mã hóa các mô hình chủ đề. Jelassi et al [14] chỉ ra một khối transformer có thể mã hóa các liên kết patch. Công việc của chúng tôi cung cấp bằng chứng thực nghiệm rằng một khối transformer cũng có thể tạo ra các câu chuyện đa dạng và nhất quán, điều này cho thấy rằng kiến trúc transformer có sức mạnh biểu đạt mạnh mẽ ngay cả với số lượng tham số và lớp nhỏ.

--- TRANG 15 ---

8 Kết luận

Trong công việc này, chúng tôi đã trình bày TinyStories, một tập dữ liệu tổng hợp gồm các câu chuyện ngắn chỉ chứa những từ mà trẻ em 3-4 tuổi thường hiểu, được tạo ra bởi GPT-3.5 và GPT-4. Chúng tôi đã chỉ ra rằng TinyStories có thể được sử dụng để huấn luyện và đánh giá các mô hình ngôn ngữ nhỏ (SLM) nhỏ hơn nhiều so với các mô hình hiện đại, nhưng vẫn tạo ra những câu chuyện trôi chảy và nhất quán với nhiều đoạn văn đa dạng và có ngữ pháp gần như hoàn hảo, đồng thời thể hiện khả năng lý luận.

Trong khi các mô hình lớn được huấn luyện trên các kho dữ liệu ngôn ngữ khổng lồ và đa dạng trên internet thể hiện khả năng rất ấn tượng, những tập dữ liệu đó có vẻ quá lớn đối với SLM để nắm bắt các khía cạnh phức tạp của ngôn ngữ. Trong công việc này, chúng tôi đã lập luận rằng TinyStories cho phép chúng tôi quan sát và nghiên cứu sự xuất hiện của các khả năng như tạo ra văn bản mạch lạc, lý luận và tuân theo hướng dẫn trong LM ở quy mô nhỏ hơn nhiều, về mặt kích thước của cả mô hình và tập dữ liệu. Bằng cách huấn luyện SLM trên tập dữ liệu của chúng tôi, chúng tôi cũng đã quan sát được nhiều hành vi tương tự như LLM như luật mở rộng, sự đánh đổi giữa chiều rộng và chiều sâu, v.v. Hơn nữa, chúng tôi đã chỉ ra rằng các SLM được huấn luyện có tính diễn giải cao hơn nhiều so với các mô hình lớn hơn, và chúng tôi có thể hình dung và phân tích các mẫu chú ý và kích hoạt của chúng để hiểu cách chúng tạo ra và hiểu các câu chuyện.

Chúng tôi đã cung cấp bằng chứng về thực tế rằng các mô hình được huấn luyện trên TinyStories có thể tạo ra những câu chuyện thực sự mới, thay vì chỉ sao chép các đoạn văn bản từ tập dữ liệu. Tuy nhiên, vẫn là một thách thức để đánh giá mức độ "sáng tạo" thực sự của các mô hình của chúng tôi, và mức độ mà các mô hình phản ánh một "hiểu biết" nhất định (ở mức độ rất thấp tất nhiên) về các câu chuyện mà chúng tạo ra thay vì chỉ khớp mẫu để tạo ra một phần tiếp tục hợp lý. Chúng tôi hy vọng rằng tập dữ liệu này có thể được sử dụng trong các công việc tương lai để có được hiểu biết về mức độ sáng tạo của các mô hình ngôn ngữ.

Chúng tôi cũng đã giới thiệu một mô hình mới để đánh giá các mô hình ngôn ngữ, sử dụng GPT-4 để chấm điểm nội dung được tạo ra bởi những mô hình này như thể chúng là những câu chuyện được viết bởi học sinh và được chấm điểm bởi một giáo viên (con người). Mô hình mới này khắc phục những khuyết điểm của các tiêu chuẩn đánh giá truyền thống, thường yêu cầu đầu ra của mô hình phải có cấu trúc rất chặt chẽ, hơn nữa nó cung cấp điểm số đa chiều cho mô hình, đưa ra điểm số cho các khả năng khác nhau. Chúng tôi tin rằng mô hình này có thể hữu ích vượt xa TinyStories.

Cuối cùng, chúng tôi đã trình bày những phát hiện ban đầu chỉ ra vai trò của chiều rộng so với chiều sâu trong các khả năng trí tuệ của các mạng tạo sinh, gợi ý rằng chiều rộng quan trọng hơn để nắm bắt kiến thức thực tế trong khi chiều sâu quan trọng hơn cho việc theo dõi ngữ cảnh. Hơn nữa, các phát hiện của chúng tôi cho thấy rằng về mặt xuất hiện, khả năng ngữ pháp và cú pháp xuất hiện sớm hơn khả năng tạo ra văn bản nhất quán, và điều này lại xuất hiện trước khả năng tạo ra nội dung được coi là sáng tạo. Những phát hiện sơ bộ này chỉ mang tính gợi ý (và không phải là trọng tâm chính của công việc này) nhưng chúng cho thấy cách tập dữ liệu và mô hình đánh giá của chúng tôi có thể cho phép phân tích chi tiết hơn về sự xuất hiện và đánh giá các khả năng ngôn ngữ khác nhau trong các mô hình tạo sinh.

Chúng tôi hy vọng rằng TinyStories có thể tạo điều kiện thuận lợi cho việc phát triển, phân tích và nghiên cứu các LM, đặc biệt đối với các lĩnh vực có tài nguyên hạn chế hoặc chuyên biệt, và làm sáng tỏ sự xuất hiện của khả năng ngôn ngữ trong các LM. Một câu hỏi chung phát sinh từ công việc này là liệu việc tổng hợp một tập dữ liệu tinh tế có thể có lợi trong việc huấn luyện các mạng cho các sử dụng thực tế hay không. Ví dụ, có lẽ có thể huấn luyện một chatbot dịch vụ khách hàng bằng cách tổng hợp một tập dữ liệu lớn về các cuộc gọi giả định.

Tài liệu tham khảo

[1] Common crawl. Truy cập: 2019.

[2] Zeyuan Allen-Zhu và Yuanzhi Li. Towards understanding ensemble, knowledge distillation and self-distillation in deep learning. arXiv preprint arXiv:2012.09816, 2020.

[3] Sid Black, Leo Gao, Phil Wang, Connor Leahy, và Stella Biderman. GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow, Tháng 3 năm 2021.

[4] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020.

[5] Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712, 2023.

[6] Kevin Clark, Urvashi Khandelwal, Omer Levy, và Christopher D Manning. What does bert look at? an analysis of bert's attention. arXiv preprint arXiv:1906.04341, 2019.

[7] John H Flavell, Eleanor R Flavell, Frances L Green, và Louis J Moses. Young children's understanding of fact beliefs versus value beliefs. Child development, 61(4):915–928, 1990.

[8] Jonathan Frankle và Michael Carbin. The lottery ticket hypothesis: Finding sparse, trainable neural networks. arXiv preprint arXiv:1803.03635, 2018.

[9] Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, et al. The pile: An 800gb dataset of diverse text for language modeling. arXiv preprint arXiv:2101.00027, 2020.

[10] Geoffrey Hinton, Oriol Vinyals, và Jeff Dean. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2015.

[11] Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. Training compute-optimal large language models. arXiv preprint arXiv:2203.15556, 2022.

[12] Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, và Yejin Choi. The curious case of neural text degeneration. arXiv preprint arXiv:1904.09751, 2019.

[13] Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, và Yoshua Bengio. Quantized neural networks: Training neural networks with low precision weights and activations. The Journal of Machine Learning Research, 18(1):6869–6898, 2017.

[14] Samy Jelassi, Michael Sander, và Yuanzhi Li. Vision transformers provably learn spatial structure. Advances in Neural Information Processing Systems, 35:37822–37836, 2022.

[15] Mandar Joshi, Eunsol Choi, Daniel S Weld, và Luke Zettlemoyer. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. arXiv preprint arXiv:1705.03551, 2017.

[16] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, và Dario Amodei. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361, 2020.

[17] Hector Levesque, Ernest Davis, và Leora Morgenstern. The winograd schema challenge. In Thirteenth international conference on the principles of knowledge representation and reasoning, 2012.

[18] Jiwei Li, Xinlei Chen, Eduard Hovy, và Dan Jurafsky. Visualizing and understanding neural models in nlp. arXiv preprint arXiv:1506.01066, 2015.

[19] Yuchen Li, Yuanzhi Li, và Andrej Risteski. How do transformers learn topic structure: Towards a mechanistic understanding. arXiv preprint arXiv:2303.04245, 2023.

[20] Wick Miller và Susan Ervin. The development of grammar in child language. Monographs of the Society for Research in Child Development, trang 9–34, 1964.

[21] OpenAI. Gpt-4 technical report, 2023.

[22] Denis Paperno, Germán Kruszewski, Angeliki Lazaridou, Quan Ngoc Pham, Raffaella Bernardi, Sandro Pezzelle, Marco Baroni, Gemma Boleda, và Raquel Fernández. The lambada dataset: Word prediction requiring a broad discourse context. arXiv preprint arXiv:1606.06031, 2016.

[23] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, và Ilya Sutskever. Language models are unsupervised multitask learners. 2019.

[24] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research, 21(1):5485–5551, 2020.

[25] Victor Sanh, Lysandre Debut, Julien Chaumond, và Thomas Wolf. Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter. arXiv preprint arXiv:1910.01108, 2019.

[26] Michael Santacroce, Zixin Wen, Yelong Shen, và Yuanzhi Li. What matters in the structured pruning of generative language models? arXiv preprint arXiv:2302.03773, 2023.

[27] Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615, 2022.

[28] Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, và Denny Zhou. Mobilebert: a compact task-agnostic bert for resource-limited devices. arXiv preprint arXiv:2004.02984, 2020.

[29] Wilson L Taylor. "cloze procedure": A new tool for measuring readability. Journalism quarterly, 30(4):415–433, 1953.

[30] Elena Voita, David Talbot, Fedor Moiseev, Rico Sennrich, và Ivan Titov. Analyzing multi-head self-attention: Specialized heads do the heavy lifting, the rest can be pruned. arXiv preprint arXiv:1905.09418, 2019.

[31] Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco Guzmán, Armand Joulin, và Edouard Grave. Ccnet: Extracting high quality monolingual datasets from web crawl data. arXiv preprint arXiv:1911.00359, 2019.

[32] Terry Winograd. Understanding natural language. Cognitive psychology, 3(1):1–191, 1972.

[33] Victor Zhong, Caiming Xiong, và Richard Socher. Seq2sql: Generating structured queries from natural language using reinforcement learning. arXiv preprint arXiv:1709.00103, 2017.

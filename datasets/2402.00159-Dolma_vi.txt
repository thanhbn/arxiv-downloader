# Dolma: một Kho Dữ liệu Mở ba Nghìn tỷ Token cho Nghiên cứu Tiền huấn luyện Mô hình Ngôn ngữ

Luca Soldaini♥αRodney Kinney♥αAkshita Bhagia♥αDustin Schwenk♥α
David AtkinsonαRussell AuthurαBen BoginαωKhyathi Chanduα
Jennifer DumasαYanai ElazarαωValentin HofmannαAnanya Harsh Jhaα
Sachin KumarαLi LucyβXinxi LyuωNathan LambertαIan Magnussonα
Jacob MorrisonαNiklas Muennighoff Aakanksha NaikαCrystal Namα
Matthew E. PetersσAbhilasha RavichanderαKyle RichardsonαZejiang Shenτ
Emma StrubellχαNishant SubramaniχαOyvind TafjordαPete Walshα
Luke ZettlemoyerωNoah A. SmithαωHannaneh Hajishirziαω
Iz BeltagyαDirk GroeneveldαJesse Dodgeα
Kyle Lo♥α

αViện Allen về Trí tuệ Nhân tạoβĐại học California, BerkeleyχĐại học Carnegie Mellon
σSpiffy AIτViện Công nghệ MassachusettsωĐại học Washington
{lucas,kylel}@allenai.org

## Tóm tắt

Thông tin về các kho dữ liệu tiền huấn luyện được sử dụng để huấn luyện các mô hình ngôn ngữ hiệu suất tốt nhất hiện tại hiếm khi được thảo luận: các mô hình thương mại hiếm khi chi tiết dữ liệu của họ, và ngay cả các mô hình mở thường được phát hành mà không kèm theo dữ liệu huấn luyện hoặc công thức để tái tạo chúng. Kết quả là, việc tiến hành và thúc đẩy nghiên cứu khoa học về mô hình hóa ngôn ngữ trở nên thách thức, chẳng hạn như hiểu cách dữ liệu huấn luyện ảnh hưởng đến khả năng và hạn chế của mô hình. Để tạo thuận lợi cho nghiên cứu khoa học về tiền huấn luyện mô hình ngôn ngữ, chúng tôi thu thập và phát hành Dolma, một kho dữ liệu tiếng Anh ba nghìn tỷ token, được xây dựng từ hỗn hợp đa dạng của nội dung web, bài báo khoa học, mã nguồn, sách công cộng, mạng xã hội và tài liệu bách khoa toàn thư. Chúng tôi tài liệu hóa Dolma một cách toàn diện, bao gồm các nguyên tắc thiết kế, chi tiết về việc xây dựng và tóm tắt nội dung của nó. Chúng tôi trình bày các phân tích và kết quả thực nghiệm trên các trạng thái trung gian của Dolma để chia sẻ những gì chúng tôi đã học được về các thực hành quan trọng trong việc thu thập dữ liệu. Cuối cùng, chúng tôi mở mã nguồn bộ công cụ thu thập dữ liệu để cho phép tái tạo công việc của chúng tôi cũng như hỗ trợ nghiên cứu thêm trong việc thu thập dữ liệu quy mô lớn.

hf.co/datasets/allenai/dolma
github.com/allenai/dolma

♥Tác giả chính. Xem Phụ lục B để biết danh sách đóng góp.

## 1 Giới thiệu

Các mô hình ngôn ngữ hiện là trung tâm trong việc giải quyết vô số tác vụ xử lý ngôn ngữ tự nhiên, bao gồm học ít mẫu, tóm tắt, trả lời câu hỏi và nhiều hơn nữa. Ngày càng, các mô hình ngôn ngữ mạnh nhất được xây dựng bởi một số ít tổ chức giữ bí mật hầu hết các chi tiết phát triển mô hình (Anthropic, 2023; OpenAI, 2023; Anil et al., 2023; Gemini Team et al., 2023). Đặc biệt, thành phần của dữ liệu tiền huấn luyện mô hình ngôn ngữ thường được mô tả một cách mơ hồ, ngay cả trong trường hợp bản thân mô hình được phát hành để sử dụng công cộng, chẳng hạn như Llama 2 (Touvron et al., 2023b). Điều này cản trở việc hiểu các hiệu ứng của thành phần kho dữ liệu tiền huấn luyện đối với khả năng và hạn chế của mô hình, với tác động đến tiến bộ khoa học cũng như công chúng tương tác với các mô hình này.

Mục tiêu của chúng tôi là tăng cường sự tham gia trong nghiên cứu khoa học về các mô hình ngôn ngữ thông qua các kho dữ liệu mở:

• Tính minh bạch của dữ liệu giúp các nhà phát triển và người dùng ứng dụng dựa vào các mô hình ngôn ngữ đưa ra quyết định sáng suốt hơn (Gebru et al., 2021). Ví dụ, các mô hình đã được chứng minh hoạt động tốt hơn trên các tác vụ tương tự hơn với dữ liệu tiền huấn luyện của chúng (Razeghi et al., 2022; Kandpal et al., 2023), hoặc thiên lệch xã hội trong dữ liệu tiền huấn luyện của mô hình có thể đòi hỏi cân nhắc bổ sung khi sử dụng chúng (Feng et al., 2023; Navigli et al., 2023; Seshadri et al., 2023).

• Dữ liệu tiền huấn luyện mở là cần thiết để phân tích cách thành phần của nó ảnh hưởng đến hành vi mô hình, cho phép những người huấn luyện mô hình thẩm vấn và cải thiện các thực hành dữ liệu hiện tại (Longpre et al., 2023; Gao, 2021; Elazar et al., 2023). Các ví dụ về nghiên cứu này bao gồm ghi nhớ (Carlini et al., 2022; Chang et al., 2023), khử trùng lặp (Lee et al., 2022), tấn công đối nghịch (Wallace et al., 2021), ô nhiễm điểm chuẩn (Magar and Schwartz, 2022), và quy kết dữ liệu huấn luyện (Hammoudeh and Lowd, 2022; Grosse et al., 2023).

Để hỗ trợ sự tham gia và nghiên cứu rộng rãi hơn trong những hướng nghiên cứu này, chúng tôi trình bày Data for Open Language Models' Appetite (Dolma), một kho dữ liệu mở ba nghìn tỷ token được thiết kế để hỗ trợ nghiên cứu tiền huấn luyện mô hình ngôn ngữ. Chúng tôi lấy phần lớn dữ liệu từ các nguồn tương tự như những nguồn có trong các công trình trước, bao gồm hỗn hợp văn bản web từ Common Crawl, nghiên cứu khoa học từ Semantic Scholar, mã nguồn từ GitHub, sách công cộng, bài đăng mạng xã hội từ Reddit, và tài liệu bách khoa toàn thư từ Wikipedia. So với các kho dữ liệu tiền huấn luyện công khai khác, Dolma cung cấp một nhóm token lớn hơn với chất lượng tương đương trong khi duy trì thành phần dữ liệu đa dạng. Tóm lại, đóng góp của chúng tôi có hai khía cạnh:

• Chúng tôi phát hành Kho Dữ liệu Dolma, một bộ sưu tập đa nguồn đa dạng gồm 3T token trên hơn 4B tài liệu thu được từ 6 nguồn dữ liệu khác nhau mà (i) thường thấy trong tiền huấn luyện mô hình ngôn ngữ quy mô lớn và (ii) được cung cấp cho công chúng. Bảng 1 cung cấp tổng quan cấp cao về lượng dữ liệu từ mỗi nguồn.

• Chúng tôi mở mã nguồn Bộ công cụ Dolma, một công cụ hiệu suất cao, di động được thiết kế để thu thập hiệu quả các tập dữ liệu lớn cho tiền huấn luyện mô hình ngôn ngữ. Thông qua bộ công cụ này, các nhà thực hành không chỉ có thể tái tạo tập dữ liệu của chúng tôi mà còn nghiên cứu và cải thiện các thực hành thu thập dữ liệu.

## 2 Công việc Liên quan

**Các thực hành thu thập dữ liệu đóng trong nghiên cứu tiền huấn luyện mô hình ngôn ngữ.** Các thực hành dữ liệu tiền huấn luyện cho nghiên cứu mô hình ngôn ngữ đã trở nên ngày càng đóng kín, cả về mặt tiếp cận dữ liệu cũng như tài liệu các chi tiết quan trọng về bản thân dữ liệu hoặc các thực hành thu thập nó mà có thể cho phép các nỗ lực tái tạo hoặc nghiên cứu khoa học thêm. Các mô hình độc quyền (ví dụ: GPT-4, OpenAI, 2023; PaLM 2, Anil et al., 2023; Claude, Anthropic, 2023) tiết lộ ít hoặc không có thông tin (thậm chí không có kích thước kho dữ liệu, hoặc nguồn gốc dữ liệu), và không chia sẻ các tạo phẩm dữ liệu. Mặc dù có sự gia tăng tiếp cận với các mô hình mở mạnh mẽ, ít mô hình được phát hành cùng với dữ liệu huấn luyện của chúng; các ngoại lệ bao gồm T5 trên C4 (Raffel et al., 2020), BLOOM (Leong et al., 2022) trên ROOTS (Piktus et al., 2023), GPT-J (Wang and Komatsuzaki, 2021), GPT-NeoX (Black et al., 2022), Pythia (Biderman et al., 2023) trên Pile (Gao et al., 2020), và INCITE (Together Computer, 2023c) trên RedPajama v1 (Together Computer, 2023a). Các mô hình mở mạnh nhất (ví dụ: Llama 2 (Touvron et al., 2023b), Mistral (Jiang et al., 2023), Yi (Bai et al., 2023), Qwen (01.AI, 2023)) không chia sẻ dữ liệu của họ cũng như không cung cấp chi tiết đầy đủ để tái tạo. Trong số các nỗ lực tiền huấn luyện mô hình ngôn ngữ quy mô lớn, những nỗ lực đi kèm với tài liệu thu thập dữ liệu minh bạch bao gồm LLaMA (Touvron et al., 2023a) (mô hình đã phát hành, dữ liệu chưa phát hành), Gopher (Rae et al., 2021) (mô hình và dữ liệu chưa phát hành), và Falcon (Almazrouei et al., 2023) (mô hình đã phát hành, dữ liệu một phần đã phát hành). Phụ lục §C minh họa thêm nhiều ẩn số trong các thực hành thu thập dữ liệu của các mô hình mở và đóng, cũng như các xu hướng gần đây rời xa các thực hành dữ liệu mở đã thúc đẩy công việc của chúng tôi.

**Các kho dữ liệu mở cho tiền huấn luyện mô hình ngôn ngữ.** Chúng tôi công nhận các nỗ lực trước đây trong việc thu thập, tài liệu hóa và phát hành các kho dữ liệu mở để hỗ trợ nghiên cứu tiền huấn luyện mô hình ngôn ngữ. Tuy nhiên, các hạn chế trong những kho dữ liệu trước đây này đã thúc đẩy chúng tôi thu thập một tập dữ liệu mới:

• C4 (Raffel et al., 2020) (175B token) và Pile (Gao et al., 2020) (387B token) là các tập dữ liệu chất lượng cao với việc sử dụng được chứng minh trong huấn luyện mô hình ngôn ngữ, nhưng tiếc là bị hạn chế về quy mô. ROOTS (Piktus et al., 2023) lớn (≈400B token) nhưng với trọng tâm đa ngôn ngữ, phần chỉ tiếng Anh của nó chỉ chiếm 30% tập dữ liệu và do đó đóng góp quá ít token để huấn luyện các mô hình chỉ tiếng Anh. Chúng tôi công nhận rằng quy mô và tập trung chỉ tiếng Anh không ngụ ý một tập dữ liệu "chất lượng cao hơn"; thay vào đó, một số hướng nghiên cứu nhất định cần những trọng tâm này, thúc đẩy kho dữ liệu mới của chúng tôi (xem §3).

• Trong khi Falcon (Almazrouei et al., 2023) (580B token) và RedPajama v2 (Together Computer, 2023b) (30T token) đáp ứng tiêu chí quy mô của chúng tôi, chúng hoàn toàn được dẫn xuất từ các trang web Common Crawl, và do đó thiếu tính đa dạng nguồn thường được nhắm đến khi thu thập dữ liệu cho các mô hình ngôn ngữ lớn nhất (ví dụ: bài báo khoa học, mã nguồn). Chúng tôi cũng lưu ý rằng RedPajama v2 chỉ được thu thập nhẹ, phân phối nội dung đầu ra bởi CCNet (Wenzek et al., 2020) hầu như nguyên bản, do đó đặt gánh nặng lên các nhà phát triển mô hình để quyết định việc lọc riêng của họ trước khi huấn luyện.

• RedPajama v1 (Together Computer, 2023a) (≈1.2T token) tương tự nhất với nỗ lực của chúng tôi và là nguồn cảm hứng khi thiết kế Dolma. Trong khi RedPajama v1 là một tái tạo cụ thể của dữ liệu huấn luyện LLaMA (Touvron et al., 2023a), chúng tôi có mục tiêu tái tạo rộng hơn đòi hỏi khám phá các nguồn dữ liệu mà RedPajama v1 không theo đuổi, bao gồm các bộ sưu tập lớn hơn của bài báo khoa học và diễn đàn mạng xã hội như Reddit (xem § 3). Hơn nữa, công việc gần đây đã xác định các vấn đề chất lượng dữ liệu cho thấy việc dọn dẹp bổ sung đáng kể của RedPajama v1 được khuyến nghị trước khi huấn luyện mô hình ngôn ngữ tốn kém (Soboleva et al., 2023; Elazar et al., 2023).

Trong khi bản thảo này đang được xem xét, một số kho dữ liệu mở khác cho mô hình hóa ngôn ngữ đã được phát hành, bao gồm FineWeb (Penedo et al., 2024), Zyda (Tokpanov et al., 2024), và các tập dữ liệu được sử dụng để huấn luyện các mô hình LLM360 Amber (Liu et al., 2023), LLM360 K2 (LLM360 Team, 2024), và MAP-Neo (Zhang et al., 2024).

## 3 Mục tiêu Thiết kế Dữ liệu

Chúng tôi trình bày các mục tiêu thiết kế của Dolma và thảo luận cách những mục tiêu này hướng dẫn việc ra quyết định của chúng tôi trong quá trình thu thập dữ liệu. Trong việc chia sẻ những điều này, chúng tôi hy vọng thông báo cho người dùng về điểm mạnh và hạn chế của Dolma trong khi cũng củng cố thực hành xung quanh các tiết lộ như vậy trong nghiên cứu thu thập tập dữ liệu (xem lý do thu thập trong Bender and Friedman (2018) và câu hỏi động lực trong Gebru et al. (2021)).

**Nhất quán với các công thức tiền huấn luyện mô hình ngôn ngữ trước đây.** Bằng cách khớp các nguồn dữ liệu và phương pháp được sử dụng để tạo ra các kho dữ liệu mô hình hóa ngôn ngữ khác, đến mức chúng được biết, chúng tôi cho phép cộng đồng nghiên cứu rộng lớn hơn sử dụng các tạo phẩm của chúng tôi để nghiên cứu (và xem xét kỹ) các mô hình ngôn ngữ đang được phát triển ngày nay, ngay cả những mô hình được phát triển sau cánh cửa đóng. Trong nỗ lực tái tạo này, chúng tôi tuân theo các thực hành đã thiết lập đến mức chúng được biết. Đáng chú ý, điều này cũng có nghĩa là giới hạn Dolma trong văn bản chỉ tiếng Anh để tận dụng tốt hơn các thực hành thu thập đã biết và tối đa hóa tính khái quát của công việc khoa học trên Dolma đối với các mô hình ngôn ngữ hiện có.

**Khi nghi ngờ, đưa ra quyết định dựa trên bằng chứng.** Tuy nhiên, vẫn còn vô số quyết định thu thập dữ liệu mà không có một công thức rõ ràng duy nhất từ công việc trước đây, cả khi thực hành tốt nhất không được biết cũng như khi các triển khai khác nhau theo những cách tinh tế. Trong những trường hợp như vậy, chúng tôi ưu tiên các quyết định tối đa hóa hiệu suất của các mô hình ngôn ngữ được huấn luyện trên Dolma trên một bộ tác vụ và tập dữ liệu đa dạng (xem §4.2).

**Dữ liệu quy mô lớn để huấn luyện các mô hình lớn.** Hoffmann et al. (2022) đề xuất rằng người ta có thể huấn luyện các mô hình tối ưu tính toán bằng cách duy trì tỷ lệ cố định giữa kích thước mô hình ngôn ngữ (theo tham số) và số lượng tối thiểu token huấn luyện. Các công trình gần đây tuân theo những "quy luật tỷ lệ" này, chẳng hạn như Llama 2, cho thấy rằng vẫn còn chỗ để cải thiện hiệu suất bằng cách tăng số lượng token huấn luyện. Chúng tôi nhắm đến một kho dữ liệu đủ lớn—2–3T token—để cho phép nghiên cứu thêm về mối quan hệ giữa kích thước mô hình và tập dữ liệu.

**Thực hiện các điều chỉnh cần thiết để bảo tồn tính mở.** Một nguyên tắc cốt lõi của công việc chúng tôi là tính mở, mà chúng tôi định nghĩa có nghĩa là (i) chia sẻ bản thân dữ liệu và (ii) tài liệu hóa quá trình thu thập nó. Yêu cầu này có nghĩa là thỉnh thoảng chúng tôi phải lệch khỏi các công thức đã biết do các cân nhắc thực tế, pháp lý hoặc đạo đức bổ sung phát sinh khi theo đuổi nghiên cứu tập dữ liệu công khai. Ví dụ, mặc dù được sử dụng trong huấn luyện các mô hình ngôn ngữ như LLaMA, chúng tôi tránh các nguồn như Books3 (Gao et al., 2020) là trung tâm của các vụ kiện pháp lý đang diễn ra xung quanh việc sử dụng AI các tài liệu có bản quyền (Knibbs, 2023). Tương tự, mặc dù thiếu thảo luận xung quanh việc loại bỏ thông tin nhận dạng cá nhân trong các công thức trước đây, chúng tôi thực hiện việc lọc này để giảm thiểu rủi ro liên quan đến việc phát hành dữ liệu (Subramani et al., 2023).

## 4 Phương pháp Thu thập Dữ liệu

### 4.1 Bộ công cụ Dolma

Việc thu thập dữ liệu tiền huấn luyện đòi hỏi việc định nghĩa các quy trình phức tạp biến đổi dữ liệu thô từ nhiều nguồn thành một bộ sưu tập duy nhất các tài liệu văn bản thuần túy đã được làm sạch (Wenzek et al., 2020; Almazrouei et al., 2023). Để thu thập Dolma, chúng tôi tạo ra và mở mã nguồn một bộ công cụ hiệu suất cao để tạo thuận lợi cho việc xử lý hiệu quả trên hàng trăm terabyte nội dung văn bản. Bộ công cụ của chúng tôi thống nhất các bước thu thập tập dữ liệu phổ biến thành các hoạt động "lọc" và "trộn":

**Lọc** Chúng tôi thống nhất các biến đổi dữ liệu phổ biến như bộ lọc ngôn ngữ, chất lượng hoặc nội dung thành một triển khai duy nhất. Với một cấu hình—một đơn vị văn bản (ví dụ: tài liệu, đoạn văn, câu, v.v.), một phương pháp tính điểm (ví dụ: bộ phân loại tuyến tính, độ rối loạn mô hình ngôn ngữ, khớp biểu thức chính quy), và một chính sách loại bỏ (ví dụ: xóa, thay thế bằng chuỗi)—bộ công cụ của chúng tôi song song hóa các hoạt động lọc bằng cách xác định và loại bỏ văn bản không mong muốn ở quy mô lớn. Đối với Dolma, chúng tôi sử dụng những điều này để lọc nội dung không phải tiếng Anh, "chất lượng thấp" hoặc không tự nhiên, độc tính, và PII ở cấp tài liệu và cấp dưới tài liệu.

Trong các thử nghiệm nội bộ để tái tạo công thức C4, bộ công cụ của chúng tôi thực hiện lọc với tốc độ 122 giờ CPU trên mỗi TB; để tham khảo, việc xử lý toàn bộ các tệp Dolma "thô" tổng cộng 200 TB trên một instance c6a.48xlarge với 192 vCPU sẽ mất 5 ngày.

**Trộn** Chúng tôi thống nhất các hoạt động chéo tệp phổ biến, như lấy mẫu lên/xuống, khử trùng lặp và khử ô nhiễm, thành một mô-đun Rust duy nhất "trộn" nội dung qua các tệp thành một tập tệp nhỏ hơn. Ví dụ, chúng tôi có thể đạt được lấy mẫu lên bằng cách đọc lặp lại cùng các đường dẫn tệp khi trộn. Chúng tôi cũng triển khai một bộ lọc Bloom (Bloom, 1970) tương thích với bộ trộn của chúng tôi cho phép phát hiện xác suất thời gian tuyến tính của bản sao. Chúng tôi có thể tái sử dụng điều này cho khử ô nhiễm tập thử nghiệm bằng cách đầu tiên gieo bộ lọc Bloom với các ví dụ thử nghiệm, sau đó gắn cờ bất kỳ bản sao nào được phát hiện khi trộn dữ liệu tiền huấn luyện.

### 4.2 Thực nghiệm Dữ liệu

Để giúp chúng tôi đưa ra quyết định sáng suốt, chúng tôi tiến hành các thực nghiệm dữ liệu trong đó chúng tôi huấn luyện các mô hình ngôn ngữ trên một tập dữ liệu theo một quyết định thu thập dữ liệu cụ thể, hoặc can thiệp, và đánh giá hiệu suất của mô hình kết quả trên một loạt tập dữ liệu thử nghiệm so với một tập dữ liệu cơ sở. Bằng cách so sánh kết quả can thiệp và cơ sở trong khi kiểm soát kiến trúc mô hình và huấn luyện, chúng tôi có thể tách biệt tác động của các quyết định thu thập tập dữ liệu cụ thể đối với các mô hình downstream.

**Huấn luyện mô hình.** Chúng tôi tiến hành thực nghiệm dữ liệu sử dụng một mô hình decoder-only 1.2 tỷ tham số từ họ mô hình ngôn ngữ mở OLMo (Groeneveld et al., 2024). Điều này phù hợp với kích thước mô hình tương tự đã được sử dụng cho thực nghiệm trong công việc trước đây (Le Scao et al., 2022). Vì việc huấn luyện các mô hình như vậy đến hoàn thành là cực kỳ tốn kém, đặc biệt khi người ta phải thực hiện những thử nghiệm này cho từng quyết định thu thập dữ liệu quan trọng, chúng tôi chỉ huấn luyện những mô hình này đến 150 tỷ token trước khi kết thúc sớm. Chi tiết thêm về thiết lập huấn luyện của chúng tôi trong Phụ lục D.1.

**Tác vụ và tập dữ liệu thử nghiệm.** Để chọn các tác vụ và tập dữ liệu đánh giá của chúng tôi, chúng tôi ưu tiên những tác vụ (i) đã được sử dụng trong đánh giá tiền huấn luyện mô hình ngôn ngữ trước đây, (ii) nắm bắt một loạt kiến thức và khả năng của mô hình ngôn ngữ đa dạng, và (iii) mà chúng tôi có thể tránh ô nhiễm tập thử nghiệm (Dodge et al., 2021; Yang et al., 2023). Chúng tôi đi đến 8 tập dữ liệu trong bộ đánh giá của chúng tôi (chi tiết đầy đủ trong Phụ lục §D) đã được sử dụng trong nghiên cứu mô hình hóa ngôn ngữ trước đây (ví dụ: LLaMA, Llama 2, v.v.) và nắm bắt một loạt khả năng (ví dụ: trả lời câu hỏi, lý luận thông thường, v.v.). Phân tích ô nhiễm tập thử nghiệm đầy đủ xác nhận lựa chọn tập dữ liệu của chúng tôi trong Phụ lục §L.

**Đánh giá.** Chúng tôi thực hiện đánh giá các mô hình thực nghiệm dữ liệu của chúng tôi sử dụng gợi ý trong ngữ cảnh zero-shot, chuyển đổi mọi tác vụ thành phân loại văn bản (được xếp hạng), tuân theo cắt ngắn gợi ý trong ngữ cảnh từ Min et al. (2022), gợi ý từ PromptSource (Bach et al., 2022), và sử dụng một harness đánh giá nội bộ tương tự như harness Eleuther (Gao et al., 2023).

## 5 Thu thập Dolma-Web

Trong phần này, chúng tôi mô tả tập con web của Dolma, bao gồm 2.28T token được dẫn xuất từ Common Crawl, một bộ sưu tập hơn 250 tỷ trang đã được thu thập kể từ năm 2007. Common Crawl được tổ chức thành các ảnh chụp nhanh, mỗi ảnh tương ứng với một lần thu thập đầy đủ trên các URL gieo của nó; tính đến tháng 2 năm 2024, có 97 ảnh chụp nhanh. Chúng tôi sử dụng 25 ảnh chụp nhanh từ 2020-05 đến 2023-06.

### 5.1 Thu thập & Lọc Ngôn ngữ

Quy trình web của chúng tôi tận dụng CCNet (Wenzek et al., 2020) để thực hiện lọc ngôn ngữ và khử trùng lặp nội dung ban đầu. CCNet đã được sử dụng để phát triển các tập dữ liệu mô hình ngôn ngữ khác như cho LLaMA, RedPajama v1, RedPajama v2. CCNet xử lý mỗi trang web với một mô hình ID ngôn ngữ FastText (Joulin et al., 2016a) để xác định ngôn ngữ chính cho mỗi tài liệu; chúng tôi giữ tất cả các trang có điểm tài liệu tiếng Anh lớn hơn hoặc bằng 0.5 (loại bỏ 61.7% dữ liệu, theo kích thước byte).

Hơn nữa, CCNet xác định và loại bỏ các đoạn văn rất phổ biến bằng cách nhóm các shard trong mỗi ảnh chụp nhanh thành các tập nhỏ và loại bỏ các đoạn văn trùng lặp trong mỗi tập. Bước này loại bỏ khoảng 70% đoạn văn, chủ yếu bao gồm các phần tử tiêu đề và điều hướng.

Nhìn chung, quy trình CCNet lọc ra 84.2% nội dung trong Common Crawl, từ 175.1 TB xuống 27.7 TB. Chi tiết thêm được cung cấp trong Datasheet §N của chúng tôi.

### 5.2 Lọc Chất lượng

Dữ liệu thu thập web đòi hỏi việc dọn dẹp đáng kể trước khi huấn luyện mô hình ngôn ngữ; nội dung không mong muốn từ các tạo phẩm được giới thiệu bởi chuyển đổi HTML sang văn bản thuần túy (ví dụ: tiêu đề trang, văn bản được định dạng kém) đến các trang thiếu nội dung "giống như văn xuôi" (ví dụ: văn bản boilerplate, đoạn ngắn). Theo các lập luận được đặt ra trong Rae et al. (2021) và Almazrouei et al. (2023) chống lại các bộ lọc chất lượng dựa trên mô hình, chúng tôi tiếp cận lọc chất lượng bằng cách kết hợp các heuristic được giới thiệu bởi Gopher và C4. Cụ thể, chúng tôi giữ tất cả các quy tắc Gopher (Gopher All) và giữ một heuristic duy nhất từ C4 được thiết kế để loại bỏ các đoạn văn không kết thúc bằng dấu câu (C4 NoPunc), thay vì áp dụng toàn bộ tập quy tắc C4 (C4 All). Chi tiết triển khai của tất cả các quy tắc lọc được cung cấp trong Datasheet §N của chúng tôi.

Kết quả thực nghiệm được hiển thị trong §1 xác nhận chiến lược lọc của chúng tôi: chúng tôi thấy rằng C4 NoPunc một mình vượt trội hơn cả C4 All cũng như Gopher All trên cả độ rối loạn và các tác vụ downstream. Cuối cùng, việc kết hợp Gopher All + C4 NoPunc mang lại hiệu suất tốt nhất.

Tổng cộng, Gopher All đánh dấu 15.23% ký tự UTF-8 để loại bỏ, trong khi C4 NoPunc đánh dấu 22.73% ký tự để loại bỏ.

**Các bộ lọc mô hình và heuristic là trực giao.** CCNet cũng cung cấp điểm chất lượng sử dụng độ rối loạn KenLM (Heafield, 2011) nhóm các tài liệu dựa trên sự giống Wikipedia; những nhóm này thường được diễn giải là nội dung chất lượng cao (21.9%), trung bình (28.5%), hoặc thấp (49.6%), trong đó giống Wikipedia hơn thường được liên kết với chất lượng cao hơn. Đáng ngạc nhiên, chúng tôi thấy rằng các quy tắc lọc heuristic của chúng tôi không ảnh hưởng đến những tỷ lệ này, cho thấy rằng các bộ lọc chất lượng dựa trên mô hình như vậy có thể nắm bắt các tín hiệu khác trực giao với các bộ lọc heuristic.

### 5.3 Lọc Nội dung

**Lọc Nội dung Độc hại** Dữ liệu được lấy mẫu từ web thường chứa nội dung có hại hoặc độc hại (Matic et al., 2020; Luccioni and Viviano, 2021; Birhane et al., 2023a,b). Nội dung như vậy thường được lọc để giảm thiểu khả năng các mô hình ngôn ngữ downstream dễ bị tạo ra nội dung độc hại (Anil et al., 2023; Rae et al., 2021; Thoppilan et al., 2022; Hoffmann et al., 2022; Longpre et al., 2023). Để loại bỏ nội dung này khỏi Dolma, chúng tôi huấn luyện các bộ phân loại FastText riêng trên tập dữ liệu Jigsaw Toxic Comments (cjadams et al., 2017), tạo ra hai mô hình xác định nội dung "thù hận" và "NSFW" tương ứng. Xem Phụ lục §H để biết chi tiết triển khai. Chúng tôi chạy những bộ phân loại này trên các câu Common Crawl và loại bỏ bất kỳ câu nào được ghi điểm trên một ngưỡng đặt.

Để hiểu các hiệu ứng ngưỡng bộ lọc trên Dolma, chúng tôi tiến hành một thực nghiệm dữ liệu chọn hai ngưỡng rất khác nhau cho những bộ lọc nội dung này (§2). Chúng tôi thấy "Ngưỡng Cao" (τ=0.4) loại bỏ ít nội dung hơn (5.5–7.3%), nhưng thường mang lại hiệu suất downstream thấp hơn "Ngưỡng Thấp" (τ=0.0004) loại bỏ nhiều nội dung hơn (29.1–34.9%).

Cân bằng sự đánh đổi giữa quy mô tập dữ liệu ("Cao") và tối đa hóa hiệu suất ("Thấp"), chúng tôi áp dụng ngưỡng "Cao" khoan dung hơn để đảm bảo chúng tôi đáp ứng yêu cầu số lượng token tối thiểu. Nguyên nhân của điều này thật đáng ngạc nhiên: Các bộ lọc chất lượng, nội dung và khử trùng lặp của chúng tôi chồng chéo rất ít trong việc loại bỏ văn bản (Hình 9), dẫn đến hiệu ứng lọc tổng hợp khi kết hợp chúng. Trong các phiên bản tương lai của Dolma, chúng tôi sẽ bắt đầu với nhiều shard Common Crawl hơn và áp dụng các ngưỡng bộ lọc nghiêm ngặt hơn.

**Lọc Thông tin Nhận dạng Cá nhân** Dữ liệu được lấy mẫu từ web cũng có thể rò rỉ thông tin nhận dạng cá nhân (PII) của người dùng (Luccioni and Viviano, 2021; Subramani et al., 2023). Dấu vết của PII dồi dào trong các tập dữ liệu quy mô lớn (Elazar et al., 2023), và các mô hình ngôn ngữ cũng đã được chứng minh tái tạo PII tại thời điểm suy luận (Carlini et al., 2022; Chen et al., 2023b).

Kích thước của Dolma khiến việc sử dụng các detektor PII dựa trên mô hình như Presidio (Microsoft, 2018) trở nên không khả thi; thay vào đó, chúng tôi dựa vào các biểu thức chính quy được chế tạo cẩn thận hy sinh một số độ chính xác để tăng tốc đáng kể. Theo Subramani et al. (2023), chúng tôi tập trung vào ba loại PII có thể phát hiện với độ chính xác cao: địa chỉ email, địa chỉ IP và số điện thoại. Đối với các tài liệu có 5 hoặc ít hơn span PII, chúng tôi thay thế span bằng một token đặc biệt (ví dụ: |||EMAIL_ADDRESS|||); điều này ảnh hưởng đến 0.02% tài liệu. Nếu không, chúng tôi loại bỏ toàn bộ tài liệu có mật độ span PII cao hơn; điều này ảnh hưởng đến 0.001% tài liệu. Trong các thử nghiệm thực nghiệm dữ liệu, chúng tôi thấy rằng các chi tiết thực thi xung quanh PII (ví dụ: loại bỏ so với thay thế token đặc biệt) không có hiệu ứng trên hiệu suất mô hình, điều này được mong đợi do tỷ lệ phần trăm nhỏ của dữ liệu bị ảnh hưởng. Xem Phụ lục §I để biết chi tiết triển khai; tất cả các hình cho kết quả trên bộ đánh giá trong Phụ lục §O.

### 5.4 Khử trùng lặp

Khử trùng lặp dữ liệu tiền huấn luyện đã được chứng minh là hiệu quả để cải thiện hiệu quả token trong quá trình huấn luyện mô hình (Lee et al., 2022; Abbas et al., 2023; Tirumala et al., 2023); như vậy, nó đã trở thành thực hành phổ biến trong các công thức dữ liệu tiền huấn luyện. Trong Dolma, chúng tôi thực hiện ba giai đoạn khử trùng lặp:

(i) Khử trùng lặp URL chính xác lọc 53.2% tài liệu.
(ii) Khử trùng lặp tài liệu chính xác lọc 14.9% tài liệu đã khử trùng lặp URL, bao gồm các tài liệu trống.
(iii) Khử trùng lặp đoạn văn chính xác lọc 18.7% đoạn văn từ các tài liệu đã khử trùng lặp URL, bao gồm các đoạn văn trống.

Cách tiếp cận đa giai đoạn này được thiết kế để tăng hiệu quả: Giai đoạn (i) thường được sử dụng đầu tiên nhờ hiệu quả tính toán của nó (Agarwal et al., 2009; Koppula et al., 2010; Penedo et al., 2023). Các giai đoạn (i) và (ii) được thiết kế để loại bỏ các bản sao của cùng một mục, chẳng hạn như việc thu thập lại cùng một URL và các trang giống hệt nhau với nhiều URL (ví dụ: cùng một bài báo tin tức trong nhiều tờ báo trực tuyến). Việc thực hiện những điều này sớm trước bất kỳ lọc nội dung hoặc chất lượng nào giảm đáng kể số lượng tài liệu cần xử lý. Ngược lại, Giai đoạn (iii) loại bỏ nội dung boilerplate phổ biến (ví dụ: byline dưới tất cả các bài viết của cùng tác giả); vì việc loại bỏ đoạn văn có nguy cơ làm gián đoạn phân tích nội dung, chúng tôi thực hiện nó cuối cùng. Chúng tôi thực hiện cả ba giai đoạn sử dụng bộ lọc Bloom trong §4.1.

### 5.5 Tổng hợp

Để tóm tắt, quy trình web Dolma biến đổi đầu ra của CCNet thông qua khử trùng lặp URL và cấp tài liệu, sau đó lọc chất lượng và nội dung, và cuối cùng khử trùng lặp cấp đoạn văn.

Chúng tôi hiển thị hiệu ứng tổng hợp tích cực của tất cả các giai đoạn quy trình web của chúng tôi trên hiệu suất mô hình downstream, như được đánh giá thông qua các thực nghiệm dữ liệu của chúng tôi §4.2. Chúng tôi trình bày thống kê tóm tắt trong Phụ lục §K.

## 6 Thu thập Dolma-Code

Trong phần này, chúng tôi mô tả tập con mã nguồn của Dolma, bao gồm 411B token được dẫn xuất từ GitHub.

### 6.1 Thu thập & Lọc Ngôn ngữ

Giống như công việc trước đây trong các mô hình ngôn ngữ mã nguồn (ví dụ: StarCoder (Li et al., 2023b)), chúng tôi cũng thu được mã nguồn thông qua the Stack (Kocetkov et al., 2022), một bộ sưu tập đã khử trùng lặp nhưng chưa được lọc khác của các kho lưu trữ GitHub được cấp phép khoan dung. Phiên bản thô của tập dữ liệu này được thu thập vào tháng 3 năm 2023. Chúng tôi lọc các tệp nặng dữ liệu với các phần mở rộng như JSON và CSV.

### 6.2 Lọc Chất lượng

Chúng tôi áp dụng các heuristic được dẫn xuất từ tập con mã nguồn của RedPajama v1 và StarCoder. RedPajama v1 sử dụng các quy tắc để loại bỏ các phần mở đầu tệp lặp lại, chẳng hạn như tuyên bố giấy phép và tài liệu có dòng quá dài hoặc chủ yếu là nội dung số. Nhìn chung, RedPajama v1 loại bỏ các tệp chủ yếu là dữ liệu hoặc được tạo thông qua các mẫu. Để chọn các đoạn mã chất lượng cao, chúng tôi cũng sử dụng các quy tắc từ quy trình StarCoder; những heuristic này lọc các kho lưu trữ GitHub có ít hoặc không có sao, các tệp có quá ít hoặc quá nhiều bình luận, và các tệp HTML có tỷ lệ mã so với văn bản thấp. Chi tiết triển khai của tất cả các quy tắc lọc được cung cấp trong Datasheet §N của chúng tôi.

Khi tiến hành các thực nghiệm dữ liệu, chúng tôi thấy rằng, so với chỉ các quy tắc RedPajama v1, việc kết hợp các quy tắc RedPajama v1 và StarCoder dẫn đến độ rối loạn thấp hơn trên các tập dữ liệu mã nguồn (ví dụ: HumanEval; Chen et al., 2021) và hiệu suất được cải thiện trên các tập dữ liệu trong bộ đánh giá của chúng tôi. Do đó, chúng tôi chọn sử dụng sự kết hợp của hai quy tắc lọc này cho tập con mã nguồn Dolma này.

### 6.3 Lọc Nội dung

Chúng tôi áp dụng cùng các heuristic để lọc và che giấu PII được sử dụng trong tập con web (§5). Ngoài ra, chúng tôi lọc bất kỳ tài liệu nào chứa bí mật mã nguồn và thông tin cá nhân cụ thể phần mềm bằng cách chạy thư viện detect-secrets (Yelp, 2013) và loại bỏ bất kỳ tài liệu nào có khớp.

### 6.4 Khử trùng lặp

Chúng tôi bắt đầu từ phiên bản đã khử trùng lặp của the Stack, sử dụng quy trình đầu tiên được giới thiệu bởi Allal et al. (2023), sử dụng MinHash (Broder, 2002) và Locally Sensitive Hashing để tìm các tài liệu tương tự.

## 7 Thu thập Dolma-Social

Trong phần này, chúng tôi mô tả tập con mạng xã hội của Dolma, bao gồm 80B token được dẫn xuất từ dữ liệu Reddit.

### 7.1 Thu thập & Lọc Ngôn ngữ

Chúng tôi dẫn xuất tập con này từ 378M bài đăng từ tháng 12 năm 2005 đến tháng 3 năm 2023 thu được thông qua Pushshift (Baumgartner et al., 2020). Chúng tôi bao gồm cả submissions—tin nhắn ban đầu trong các cuộc trò chuyện trên Reddit—và comments—phản hồi cho tin nhắn. Cấu trúc giống cây của các chủ đề Reddit cho phép nhiều định dạng dữ liệu có thể tùy thuộc vào cách các thành phần khác nhau của một chủ đề được tuyến tính hóa cho tiền huấn luyện mô hình ngôn ngữ.

Để thông báo tốt hơn cho việc biến đổi này, chúng tôi tiến hành một thực nghiệm dữ liệu trên một số cách tiếp cận:

1. **Nội dung Nguyên tử**. Coi tất cả bình luận và submission như các tài liệu độc lập.
2. **Chủ đề Một phần**. Bình luận từ cùng chủ đề được kết hợp thành cuộc đối thoại đa vòng giữa người dùng. Submissions như các tài liệu riêng biệt.
3. **Chủ đề Đầy đủ**. Kết hợp submissions với tất cả bình luận con thành một tài liệu.

Xem Phụ lục §E để biết chi tiết triển khai. Từ kết quả trong Hình 4, chúng tôi thấy việc coi submissions và bình luận như các tài liệu độc lập (Nội dung Nguyên tử) dẫn đến hiệu suất tốt hơn trên bộ đánh giá của chúng tôi. Chúng tôi giả thuyết rằng định dạng nhân tạo được giới thiệu khi kết hợp các yếu tố chủ đề ảnh hưởng tiêu cực đến huấn luyện mô hình ngôn ngữ; chúng tôi để lại nghiên cứu thêm cho công việc tương lai. Cuối cùng, chúng tôi lọc nội dung không phải tiếng Anh sử dụng cách tiếp cận từ §5.1.

### 7.2 Lọc Chất lượng

Giống như dữ liệu thu thập web, các bài đăng mạng xã hội cũng đòi hỏi việc dọn dẹp đáng kể trước khi huấn luyện mô hình ngôn ngữ. Chúng tôi tái sử dụng quy trình được giới thiệu bởi Henderson et al. (2019) để lọc submissions và bình luận. Chúng tôi loại bỏ bình luận ngắn hơn 500 ký tự, và submissions ngắn hơn 400 ký tự. Chúng tôi cũng loại bỏ tài liệu trên 40,000 ký tự.

Chúng tôi loại bỏ bình luận có ít hơn 3 phiếu bầu, vì điểm thấp hơn có nhiều khả năng cho bình luận được lồng sâu trong một chủ đề trò chuyện (Weninger et al., 2013) hoặc nội dung có nhiều khả năng dẫn đến diễn ngôn tình cảm (Davis and Graham, 2021). Phiếu bầu đã được sử dụng như một tín hiệu trong việc xây dựng các kho dữ liệu WebText (Radford et al., 2019) và OpenWebText (Peterson, 2020). Chúng tôi loại bỏ các tài liệu đã bị xóa bởi tác giả, loại bỏ bởi điều hành viên, hoặc được tác giả gắn nhãn là "trên 18". Chúng tôi loại trừ bất kỳ tài liệu nào có nguồn gốc từ một tập 26,123 subreddit bị cấm hoặc NSFW.

### 7.3 Lọc Nội dung

Chúng tôi áp dụng cùng lọc nội dung trong §5.3, ngoại trừ do độ dài ngắn của nhiều tài liệu Reddit, thay vì che giấu PII, chúng tôi loại bỏ hoàn toàn tài liệu.

### 7.4 Khử trùng lặp

Chúng tôi sử dụng cùng chiến lược được sử dụng trong quy trình web (§5.4). Vì submissions và bình luận ngắn hơn tài liệu web, chúng tôi chỉ khử trùng lặp ở cấp tài liệu. Chiến lược này hữu ích để giảm tần suất "copypasta" (văn bản giống hệt nhau được lặp lại qua các bình luận và subreddit để có hiệu ứng hài hước) và thông tin lặp lại khác.

## 8 Tập hợp Các Nguồn Dữ liệu Khác

Trong phần này, chúng tôi tóm tắt ngắn gọn các nguồn chất lượng cao bổ sung được sử dụng để dẫn xuất Dolma. Chi tiết thêm về thu thập và xử lý trong Datasheet §N.

**C4 cho Nội dung Web Được Tuyển chọn** Tương tự như các công thức dữ liệu cho LLaMA và Llama 2, chúng tôi bổ sung tập con web của chúng tôi với C4 (Raffel et al., 2020). Chúng tôi tinh chỉnh thêm dữ liệu này bằng cách xử lý lại nó thông qua quy trình web đầy đủ của chúng tôi (loại trừ khử trùng lặp URL) (§5) đã loại bỏ nội dung bổ sung, bao gồm nhiều văn bản chất lượng thấp và trùng lặp hơn, và thực hiện che giấu PII.

**Semantic Scholar cho Văn học Học thuật** Tập dữ liệu peS2o (Soldaini and Lo, 2023) là một bộ sưu tập khoảng 40 triệu bài báo học thuật truy cập mở đã được làm sạch, lọc, khử trùng lặp và định dạng cho tiền huấn luyện mô hình ngôn ngữ. Nó được dẫn xuất từ Semantic Scholar Open Research Corpus (S2ORC; Lo et al., 2020). Vì tập dữ liệu này đã được tạo cho mục đích mô hình hóa ngôn ngữ, chúng tôi sử dụng nó nguyên trạng.

**Project Gutenberg cho Sách** Project Gutenberg là một kho lưu trữ hơn 70 nghìn sách public domain. Chúng tôi thu thập kho lưu trữ Project Gutenberg vào tháng 4 năm 2023. Chúng tôi sử dụng sách tiếng Anh, mà chúng tôi lọc sử dụng cùng cách tiếp cận được mô tả trong §5.1. Chúng tôi khử trùng lặp tập dữ liệu này dựa trên khớp chính xác tiêu đề sách.

**Wikipedia và Wikibooks cho Nội dung Bách khoa toàn thư** Tập dữ liệu này được dẫn xuất từ các bản dump Wikimedia tháng 3 năm 2023. Chúng tôi sử dụng các phiên bản "English" và "Simple" của Wikipedia và Wikibooks làm cơ sở cho tập con Bách khoa toàn thư của Dolma. Các nguồn được xử lý sử dụng WikiExtractor (Attardi, 2023). Chúng tôi loại bỏ bất kỳ tài liệu nào có 25 từ được phân đoạn UTF-8 trở xuống, vì chúng tôi thấy các trang ngắn hơn là kết quả của các trang ngắn, có mẫu (ví dụ: trang chỉ chứa một vài từ và một hộp thông tin) hoặc lỗi phân tích XML. Theo thiết kế, tập dữ liệu này không chứa tài liệu trùng lặp.

## 9 Huấn luyện Mô hình Ngôn ngữ trên Dolma

Như một bước xác nhận cuối cùng của quy trình Dolma, chúng tôi huấn luyện, đánh giá và phát hành một mô hình ngôn ngữ decoder-only, tự hồi quy mà chúng tôi gọi là OLMo-1B. Chúng tôi trình bày kết quả thực nghiệm zero-shot của OLMo-1B trên một loạt tác vụ downstream thể hiện chất lượng tương đương với các mô hình ngôn ngữ được phát hành khác có kích thước tương đương.

### 9.1 Đánh giá OLMo-1B

Trong Bảng 2, chúng tôi so sánh OLMo-1B với các mô hình 1B khác. Chúng tôi lưu ý rằng, trong khi tất cả các mô hình chia sẻ số lượng tham số gần như tương đương, chỉ TinyLlama được huấn luyện trên số lượng token gần như giống OLMo-1B. Pythia được huấn luyện trên gần 10 lần ít token hơn và StableLM 2 được huấn luyện trên 2 nghìn tỷ token trong hai epoch (thành phần dữ liệu không được chia sẻ). Tuy nhiên, chúng tôi thấy rằng OLMo-1B hoạt động tốt hơn trung bình so với mô hình tương đương nhất, TinyLlama, vượt trội hơn nó trong 4 trên 8 tác vụ từ bộ đánh giá của chúng tôi §4.2. Mặc dù các đánh giá zero-shot của các tác vụ như vậy thường thách thức đối với các mô hình 1B nhỏ hơn, chúng tôi thấy rằng hiệu suất trên tất cả các tác vụ và mô hình ở trên hiệu suất ngẫu nhiên naïve.

### 9.2 Đo lường Độ phù hợp Miền

Trong §3, chúng tôi đã thúc đẩy quyết định của chúng tôi trong việc thu thập Dolma để bao phủ một tập nguồn đa dạng. Trong phần này, chúng tôi sử dụng OLMo-1B để đánh giá phân phối tài liệu của Dolma dẫn đến các mô hình ngôn ngữ được tiền huấn luyện phù hợp tốt với các miền văn bản đa dạng, so với huấn luyện trên các kho dữ liệu mở khác. Để đại diện cho các miền đa dạng, chúng tôi sử dụng Paloma (Magnusson et al., 2023), một bộ sưu tập phân tầng của hàng trăm nguồn văn bản chi tiết; do đó, huấn luyện trên các tập dữ liệu đa dạng hơn nên dẫn đến các mô hình có độ rối loạn tổng thể thấp hơn trên Paloma. Chúng tôi lặp lại phương pháp thực nghiệm dữ liệu của chúng tôi, huấn luyện các mô hình 1.2B trên các mẫu 150B token từ C4, mC4 (chỉ tiếng Anh) (Xue et al., 2020), RedPajama v1, RefinedWeb (Almazrouei et al., 2023), Pile, và Dolma.

Từ kết quả trong Hình 5, chúng tôi quan sát như sau: (1) Mô hình được huấn luyện trên Pile hoạt động tốt vì nó bao gồm nhiều nguồn đa dạng, mặc dù quy mô tổng thể nhỏ hơn. (2) Các tập dữ liệu đa nguồn lớn hơn như Dolma và, ở mức độ ít hơn, RedPajama v1 tạo ra các mô hình có độ bao phủ tương tự của các miền đa dạng như Pile. (3) Cuối cùng, huấn luyện trên các kho dữ liệu đơn nguồn như C4, mC4 (chỉ tiếng Anh), và RefinedWeb dẫn đến các mô hình có độ phù hợp kém với các miền đa dạng như được chỉ ra bởi độ rối loạn trung bình cao hơn.

Phân tích độ rối loạn được kiểm soát của chúng tôi tiết lộ tầm quan trọng của việc bao gồm dữ liệu không phải web từ các nguồn được tuyển chọn đa dạng. Metric mà chúng tôi sử dụng từ Paloma bề mặt cách các mô hình phù hợp với dữ liệu không đồng nhất hơn, bởi vì nó lấy mẫu các miền được đánh dấu từ mỗi nguồn một cách đều nhau thay vì theo tỷ lệ không bằng nhau của chúng trong nguồn. Một cách trực quan, mô hình được huấn luyện trên Pile phù hợp tốt với dữ liệu như vậy vì kho dữ liệu tiền huấn luyện đó chủ yếu được lấy từ các nguồn nhỏ hơn, được chọn thủ công tương tự. Nhưng khi chúng tôi muốn mở rộng tổng số token trong một kho dữ liệu, thách thức trở thành cách tích hợp nhiều dữ liệu web có sẵn hơn mà không mất hiệu quả mẫu trên các đánh giá đa dạng như Paloma. Trong trường hợp này, chúng tôi thấy rằng OLMo-1B gần như khớp với đường cong độ rối loạn của mô hình Pile mặc dù có phần lớn hơn nhiều dữ liệu web được bao gồm.

## Kết luận

Trong bản thảo này, chúng tôi giới thiệu Dolma, một kho dữ liệu tiếng Anh ba nghìn tỷ token cho tiền huấn luyện mô hình ngôn ngữ. Kho dữ liệu Dolma bao gồm một tập nội dung đa dạng, bao gồm tài liệu web, bài báo khoa học, mã nguồn, sách public-domain, mạng xã hội và tài liệu bách khoa toàn thư. Dựa trên một danh sách các desiderata rõ ràng, chúng tôi tài liệu hóa các quy trình thu thập dữ liệu của chúng tôi, cung cấp kết quả thực nghiệm hỗ trợ các quyết định của chúng tôi. Chúng tôi tự do phát hành Dolma và mở mã nguồn tất cả các công cụ chúng tôi đã sử dụng để thu thập tập dữ liệu này như một phần của dự án OLMo (Groeneveld et al., 2024). Kể từ thời điểm viết, chúng tôi đã thực hiện các cải tiến cho Dolma và đã tiếp tục phát hành; ví dụ, bản phát hành tiếp theo của chúng tôi Dolma v.1.7 mang lại cải thiện hiệu suất đáng kể trên các tác vụ downstream, giữ mô hình không đổi. Chúng tôi hy vọng dòng công việc này có thể thúc đẩy tính minh bạch, khả năng tái tạo và nghiên cứu thêm trong lĩnh vực mô hình hóa ngôn ngữ, cũng như giải quyết khoảng cách hiện tại trong tính khả dụng của dữ liệu tiền huấn luyện của các mô hình ngôn ngữ thương mại và mở. Chúng tôi phát hành Dolma dưới ODC-By và bộ công cụ của chúng tôi dưới Apache 2.0.

## Hạn chế

**Kho dữ liệu chỉ tiếng Anh.** Dolma được thu thập để chứa dữ liệu tiếng Anh. Vì các công cụ để nhận dạng ngôn ngữ có thể có false negative, Dolma có thể chứa một tỷ lệ nhỏ dữ liệu không phải tiếng Anh. Dấu vết của dữ liệu không phải tiếng Anh không có khả năng dẫn đến bất kỳ hiệu suất downstream có ý nghĩa nào trên các tác vụ không phải tiếng Anh cho bất kỳ mô hình nào được huấn luyện trên Dolma. Do đó, Dolma củng cố kỳ vọng của tiếng Anh là ngôn ngữ "mặc định" cho NLP.

**Tính đại diện của các nguồn trong Dolma.** Như đã đề cập trong §3, không thể thu thập một kho dữ liệu đại diện cho tất cả các thực hành thu thập dữ liệu mô hình ngôn ngữ. Hơn nữa, nhiều mô hình ngôn ngữ mở và đóng được huấn luyện trên nội dung không thể thu được hoặc phân phối lại, và do đó không thể được bao gồm trong Dolma.

**Cấu hình mô hình đơn cho thực nghiệm.** Thiết lập thực nghiệm chúng tôi sử dụng để xác nhận quy trình thu thập dữ liệu của chúng tôi chỉ bao phủ một tập con các loại mô hình được sử dụng để tạo ra các mô hình ngôn ngữ. Ví dụ, trong khi nhiều mô hình ngôn ngữ nằm trong phạm vi 7 tỷ đến 70 tỷ tham số, chúng tôi huấn luyện các mô hình 1 tỷ tham số; hơn nữa, chúng tôi không điều tra việc sử dụng bất kỳ kiến trúc thay thế nào cho các mô hình transformer tự hồi quy dày đặc. Lựa chọn này được quyết định bởi nhu cầu lặp lại hiệu quả trên nhiều cấu hình có thể, nhưng nó có thể dẫn đến các quyết định thiết kế không liên quan ở kích thước mô hình lớn hơn. Chúng tôi mong đợi các nhà phát triển mô hình downstream xem xét kỹ Dolma trước khi sử dụng nó để huấn luyện các mô hình ngôn ngữ của họ, tương tự như quy trình chúng tôi phác thảo trong §9.

**Các tác vụ hạn chế trong bộ đánh giá.** Như được chi tiết trong §4.2, chúng tôi chọn các tác vụ đã được sử dụng để đánh giá các mô hình ngôn ngữ cơ sở trước đây, và không có trong dữ liệu huấn luyện của chúng tôi (tức là Dolma không bị ô nhiễm chống lại chúng). Như vậy, chúng tôi chỉ có thể đánh giá một tập con các tác vụ mà các mô hình ngôn ngữ thường được sử dụng. Ví dụ, hiệu ứng của việc thêm mã nguồn vào dữ liệu tiền huấn luyện không thể được đo lường đầy đủ cho đến khi các mô hình có khả năng tạo mã thực thi; khả năng như vậy thường chỉ được quan sát sau khi các mô hình được tinh chỉnh để tuân theo hướng dẫn (Muennighoff et al., 2023a; Zhuo et al., 2024).

**Việc kiểm tra và đánh giá thủ công Dolma là không khả thi.** Với kích thước kho dữ liệu, không thể kiểm tra đầy đủ Dolma để đánh giá nội dung của nó. Trong khi các công cụ như WIMBD (Elazar et al., 2023) và Data Portraits (Marone and Durme, 2023) hỗ trợ kiểm tra chương trình của các tập con dữ liệu, chúng không thể cung cấp đánh giá về tất cả tài liệu trong một kho dữ liệu. Như vậy, chúng tôi không thể mô tả đầy đủ các thuộc tính của Dolma về phân phối dữ liệu, chất lượng nội dung và các tác hại tiềm ẩn do việc bao gồm hoặc loại trừ nội dung cụ thể.

## Cân nhắc Đạo đức

**Giảm thiểu rủi ro tác hại đến cá nhân trong quá trình thu thập dữ liệu.** Việc thu thập một kho dữ liệu tiền huấn luyện có thể đưa ra rủi ro cho cá nhân, bằng cách tạo thuận lợi cho việc truy cập thông tin có trong kho dữ liệu, hoặc bằng cách cho phép huấn luyện các mô hình có hại tiết lộ thông tin cá nhân (Carlini et al., 2020) hoặc tạo ra nội dung độc hại (Gehman et al., 2020; Ngo et al., 2021). Để giảm thiểu những rủi ro này trong khi đáp ứng các mục tiêu đã nêu của chúng tôi, chúng tôi đã tham gia với các chuyên gia pháp lý và đạo đức từ sớm trong dự án và đánh giá các quyết định thiết kế dữ liệu dựa trên phản hồi của họ theo từng trường hợp cụ thể. Nói chung, chúng tôi tuân theo các thực hành được chấp nhận khi có sẵn (ví dụ: che giấu một số thông tin nhận dạng cá nhân), và áp dụng cách tiếp cận đo lường khi có ý kiến khác biệt trong tài liệu (ví dụ: cách tiếp cận hiệu quả nhất để xác định và loại bỏ nội dung độc hại). Hơn nữa, chúng tôi sẽ cung cấp các công cụ để yêu cầu loại bỏ dữ liệu. Chúng tôi tin vào việc thỏa hiệp trên các thuộc tính tạo phẩm nghiên cứu mong muốn như khả năng tái tạo mô hình, hiệu suất và khả năng mở rộng trong trường hợp tác hại đáng kể đến cá nhân.

Bên cạnh cách tiếp cận dựa trên rủi ro, các khung thay thế để xem xét các tác động đạo đức của dữ liệu mô hình ngôn ngữ cũng đã được đề xuất. Quản lý dữ liệu (Jernite et al., 2022) tìm cách tạo ra một khung để thu thập và phản ánh các lợi ích rõ ràng của chủ sở hữu dữ liệu. Tín thác dữ liệu (Chan et al., 2023) hoặc cấp phép dữ liệu (Li et al., 2023a) cũng có thể cho phép sự đồng ý rõ ràng trong việc chia sẻ dữ liệu cho huấn luyện AI. Vì không có mô hình tiên tiến hiện tại nào được huấn luyện trên dữ liệu được thu thập thông qua những khung này, những cách tiếp cận này sẽ hạn chế mục tiêu tính đại diện được nêu trong §3. Khi những nguyên tắc này được áp dụng, chúng tôi sẽ xem xét chúng cho các phiên bản tương lai của Dolma.

**Cân nhắc về bản quyền và sử dụng hợp lý.** Tại thời điểm viết, bối cảnh quản lý khả năng áp dụng của luật bản quyền và học thuyết sử dụng hợp lý (còn được gọi là "giao dịch hợp lý") và các mô hình ngôn ngữ phần lớn chưa được xác định (Cooper et al., 2023; Lee et al., 2024). Tại Hoa Kỳ, các học giả pháp lý và thực hành viên đã đề xuất rằng việc huấn luyện mô hình trên nội dung có bản quyền có thể cấu thành sử dụng hợp lý (Balasubramaniam et al., 2023; MacKie-Mason and Li, 2023; Henderson et al., 2023), trong khi cũng công nhận các hạn chế của học thuyết hiện có trong ứng dụng này (Farhadi et al., 2023). Hơn nữa, các đánh giá pháp lý về việc sử dụng dữ liệu có bản quyền trong các mô hình ngôn ngữ khác nhau rộng rãi tùy thuộc vào quyền tài phán: vào đầu năm 2024, Israel (Israel Ministry of Justice, 2022) và Nhật Bản (Technomancers.ai, 2023) cho phép nội dung có bản quyền được sử dụng cho dữ liệu huấn luyện AI, mặc dù quốc gia sau hiện đang xem xét lại khung này.

Trong khi hầu hết các tập dữ liệu chúng tôi sử dụng được thu thập với bản quyền và cấp phép trong tâm trí (ví dụ: bài báo truy cập mở trong peS2o (Soldaini and Lo, 2023), kho lưu trữ nguồn mở trong the Stack (Kocetkov et al., 2022)) hoặc đã được cấp phép khoan dung (ví dụ: Wikipedia được phát hành dưới giấy phép Creative Commons), chúng tôi công nhận rằng các lần thu thập web lớn cũng có thể chứa tài liệu có bản quyền. Tuy nhiên, với các công cụ hiện tại, không thể phát hiện đáng tin cậy hoặc có thể mở rộng tài liệu có bản quyền trong một kho dữ liệu có kích thước này. Quyết định của chúng tôi để thu thập và phân phối Dolma tính đến một số cân nhắc, bao gồm rằng tất cả các nguồn dữ liệu của chúng tôi đều có sẵn công khai và đã được sử dụng trong tiền huấn luyện mô hình ngôn ngữ quy mô lớn (cả mở và đóng). Chúng tôi công nhận rằng bối cảnh pháp lý của AI đang thay đổi nhanh chóng, đặc biệt là liên quan đến việc sử dụng tài liệu có bản quyền để huấn luyện mô hình.

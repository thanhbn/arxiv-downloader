Sáng kiến Nguồn gốc Dữ liệu:
Kiểm toán Quy mô lớn về Cấp phép và Quy kết Bộ dữ liệu trong AI

Shayne Longpre1†Robert Mahari1,2Anthony Chen3Naana Obeng-Marnu1,4
Damien Sileo5William Brannon1,4Niklas Muennighoff6Nathan Khazam7
Jad Kabbara1,4Kartik Perisetla Xinyi (Alexis) Wu8Enrico Shippole Kurt Bollacker7
Tongshuang Wu9Luis Villa10Sandy Pentland1Sara Hooker11

1MIT2Harvard Law School3UC Irvine4MIT Center for Constructive Communication
5Inria, Univ. Lille Center6Contextual AI7ML Commons8Olin College
9Carnegie Mellon University10Tidelift11Cohere For AI

Tóm tắt

Cuộc đua huấn luyện các mô hình ngôn ngữ trên các bộ dữ liệu rộng lớn, đa dạng và được tài liệu hóa không nhất quán đã làm dấy lên những mối lo ngại cấp bách về các rủi ro pháp lý và đạo đức cho các nhà thực hành. Để khắc phục những thực tiễn này đe dọa tính minh bạch và hiểu biết về dữ liệu, chúng tôi triệu tập một nỗ lực đa ngành giữa các chuyên gia pháp lý và học máy để kiểm toán và truy vết có hệ thống hơn 1800 bộ dữ liệu văn bản. Chúng tôi phát triển các công cụ và tiêu chuẩn để truy vết dòng dõi của các bộ dữ liệu này, từ nguồn gốc, người tạo, chuỗi điều kiện giấy phép, thuộc tính và việc sử dụng tiếp theo. Phân tích cảnh quan của chúng tôi làm nổi bật những khác biệt sâu sắc trong thành phần và trọng tâm của các bộ dữ liệu mở thương mại so với đóng, với các bộ dữ liệu đóng độc quyền các danh mục quan trọng: ngôn ngữ tài nguyên thấp hơn, nhiều nhiệm vụ sáng tạo hơn, đa dạng chủ đề phong phú hơn, dữ liệu huấn luyện mới hơn và tổng hợp hơn. Điều này chỉ ra một sự phân chia ngày càng sâu sắc trong các loại dữ liệu được cung cấp dưới các điều kiện giấy phép khác nhau, và những tác động gia tăng đối với các diễn giải pháp lý theo thẩm quyền về bản quyền và sử dụng hợp lý. Chúng tôi cũng quan sát thấy việc phân loại sai thường xuyên các giấy phép trên các trang web lưu trữ bộ dữ liệu được sử dụng rộng rãi, với việc bỏ sót giấy phép 70%+ và tỷ lệ lỗi 50%+. Điều này chỉ ra một cuộc khủng hoảng trong việc quy kết sai và sử dụng có thông tin của các bộ dữ liệu phổ biến nhất thúc đẩy nhiều đột phá gần đây. Như một đóng góp cho các cải tiến đang diễn ra trong tính minh bạch bộ dữ liệu và sử dụng có trách nhiệm, chúng tôi phát hành toàn bộ kiểm toán của mình, với một giao diện tương tác, Data Provenance Explorer, cho phép các nhà thực hành truy vết và lọc nguồn gốc dữ liệu cho các bộ sưu tập dữ liệu tinh chỉnh mã nguồn mở phổ biến nhất: www.dataprovenance.org.

1 Giới thiệu

Làn sóng mới nhất của các mô hình ngôn ngữ, cả công khai (Chung et al., 2022; Taori et al., 2023; Geng et al., 2023) và độc quyền (Anil et al., 2023; OpenAI, 2023; Anthropic, 2023; Yoo et al., 2022) gán khả năng mạnh mẽ của chúng phần lớn cho sự đa dạng và phong phú của các bộ dữ liệu huấn luyện ngày càng lớn hơn, bao gồm các corpus tiền huấn luyện và các bộ dữ liệu tinh chỉnh được biên soạn bởi các nhà học thuật (Wei et al., 2021; Sanh et al., 2021; Muennighoff et al., 2022), được tạo ra một cách tổng hợp bởi các mô hình (Taori et al., 2023; Wang et al., 2022a), hoặc được tập hợp bởi các nền tảng như HuggingFace (Lhoest et al., 2021). Các xu hướng gần đây thấy các nhà thực hành kết hợp và đóng gói lại hàng nghìn bộ dữ liệu và nguồn web (Gao et al., 2020; Penedo et al., 2023; Wang et al., 2022b; Longpre et al., 2023a), nhưng bất chấp một số nỗ lực tài liệu hóa đáng chú ý (Spacerini, 2021; Biderman et al., 2022), có những nỗ lực giảm dần để quy kết, tài liệu hóa hoặc hiểu các thành phần thô trong các mô hình mới (Dodge et al., 2021; Bandy and Vincent, 2021; Bommasani et al., 2023a).

Một Cuộc khủng hoảng trong Tính minh bạch Dữ liệu & Hậu quả của nó. Ngày càng nhiều, các bộ sưu tập bộ dữ liệu được sử dụng rộng rãi được xử lý như một khối nguyên khối, thay vì một dòng dõi của các nguồn dữ liệu, được thu thập (hoặc tạo ra bởi mô hình), được tuyển chọn và chú thích, thường với nhiều vòng đóng gói lại (và cấp phép lại) bởi các nhà thực hành tiếp theo. Các yếu tố ngăn cản việc thừa nhận dòng dõi này bắt nguồn từ cả quy mô của việc thu thập dữ liệu hiện đại (nỗ lực để quy kết đúng cách) và sự giám sát gia tăng về bản quyền (Saveri et al., 2023). Cùng nhau, những yếu tố này đã thấy ít Datasheet hơn (Gebru et al., 2021), không tiết lộ các nguồn huấn luyện (OpenAI, 2023; Anil et al., 2023; Touvron et al., 2023), và cuối cùng là sự suy giảm trong hiểu biết dữ liệu huấn luyện (Sambasivan et al., 2021b; Longpre et al., 2023b).

Sự thiếu hiểu biết này có thể dẫn đến rò rỉ dữ liệu giữa dữ liệu huấn luyện và kiểm tra (Elangovan et al., 2021; Carlini et al., 2022), lộ thông tin có thể nhận dạng cá nhân (PII) (Bubeck et al., 2023), trình bày các thành kiến hoặc hành vi không mong muốn (Welbl et al., 2021; Xu et al., 2021; Pozzobon et al., 2023), và nói chung dẫn đến các mô hình chất lượng thấp hơn so với dự kiến. Ngoài những thách thức thực tiễn này, khoảng trống thông tin và nợ tài liệu phát sinh những rủi ro đạo đức và pháp lý đáng kể. Ví dụ, các bản phát hành mô hình dường như mâu thuẫn với các điều khoản sử dụng dữ liệu (ví dụ, WizardCoder (Luo et al., 2023) được cấp phép cho sử dụng thương mại, trong khi huấn luyện trên dữ liệu OpenAI bị cấm thương mại), các sửa đổi giấy phép sau khi phát hành công khai (với MPT-StoryTeller (Frankle, 2023)), và thậm chí các vụ kiện bản quyền (ví dụ Stability AI (Arstechnica, 2023) và OpenAI (Saveri et al., 2023)). Vì việc huấn luyện mô hình trên dữ liệu vừa đắt đỏ vừa phần lớn không thể đảo ngược, những rủi ro và thách thức này không dễ dàng khắc phục. Trong công việc này, chúng tôi gọi sự kết hợp của những chỉ số này, bao gồm việc tìm nguồn, tạo ra và di sản cấp phép của bộ dữ liệu, cũng như các đặc tính của nó, là Nguồn gốc Dữ liệu.

Nguồn gốc Dữ liệu & Cấp phép Không đáng tin cậy. Công việc của chúng tôi thúc đẩy tính cấp bách của công cụ tạo điều kiện cho việc sử dụng dữ liệu có thông tin và có trách nhiệm trong cả tiền huấn luyện và tinh chỉnh. Để trao quyền cho các nhà thực hành quy kết nguồn gốc dữ liệu, chúng tôi phát triển một bộ công cụ và tiêu chuẩn để truy vết dòng dõi dữ liệu của 44 bộ sưu tập dữ liệu văn bản được sử dụng rộng rãi và được chấp nhận nhất, bao gồm hơn 1800 bộ dữ liệu tinh chỉnh. Chúng tôi biên soạn và mở rộng siêu dữ liệu liên quan với một hệ thống phân loại phong phú hơn nhiều so với Hugging Face, Papers with Code, hoặc các tổng hợp khác (xem Phần 2.1). Với các chuyên gia pháp lý, chúng tôi thiết kế một quy trình để truy vết nguồn gốc bộ dữ liệu, bao gồm nguồn gốc của bộ dữ liệu, các giấy phép liên quan, người tạo và việc sử dụng tiếp theo.

Như một sản phẩm phụ của công việc thiết lập Nguồn gốc Dữ liệu của các bộ dữ liệu được sử dụng rộng rãi, chúng tôi có thể đặc tả hóa hệ sinh thái/chuỗi cung ứng dữ liệu AI (Cen et al., 2023; Bommasani et al., 2023c), cũng như tình trạng của lĩnh vực cho các nhà làm chính sách, nhà nghiên cứu và chuyên gia pháp lý. Công việc của chúng tôi chỉ ra một cuộc khủng hoảng trong việc tẩy giấy phép và sử dụng có thông tin của các bộ dữ liệu phổ biến, với các vấn đề hệ thống trong tài liệu giấy phép thưa thớt, mơ hồ hoặc không chính xác. Đáng chú ý, chúng tôi thấy rằng 70%+ giấy phép cho các bộ dữ liệu phổ biến trên GitHub và Hugging Face là "Không xác định", để lại một khoảng trống thông tin đáng kể khó điều hướng về mặt trách nhiệm pháp lý. Thứ hai, các giấy phép được gắn với các bộ dữ liệu được tải lên các nền tảng chia sẻ bộ dữ liệu thường không nhất quán với giấy phép được quy kết bởi tác giả gốc của bộ dữ liệu—việc chú thích lại nghiêm ngặt các giấy phép của chúng tôi thấy rằng 66% giấy phép Hugging Face được phân tích ở một danh mục sử dụng khác, thường được gắn nhãn là cho phép nhiều hơn so với giấy phép dự định của tác giả. Kết quả là, phần lớn dữ liệu này có rủi ro khi sử dụng (hoặc gây hiểu lầm có hại) cho các nhà thực hành muốn tôn trọng nguồn gốc dữ liệu của một công việc. Sáng kiến của chúng tôi giảm giấy phép "Không xác định" từ 72%+ xuống 30% và gắn URL giấy phép cho các nhà phát triển mô hình thiếu tài nguyên để tự tin hơn trong việc lựa chọn dữ liệu phù hợp cho nhu cầu của họ. Để kết thúc, Sáng kiến Nguồn gốc Dữ liệu hỗ trợ quy kết và AI có trách nhiệm với các đóng góp sau:

1. Cuộc kiểm toán công khai rộng lớn nhất được biết đến về Nguồn gốc Dữ liệu AI, truy vết dòng dõi của hơn 1800 bộ dữ liệu văn bản ("DPCollection"), giấy phép, điều kiện và nguồn gốc của chúng. Chúng tôi chứng minh việc áp dụng và phụ thuộc ngày càng tăng vào giấy phép phần mềm trong cộng đồng AI và tổng hợp các quan sát thành hướng dẫn pháp lý cho các nhà phát triển (Phần 4).

2. Data Provenance Explorer (DPExplorer), một kho lưu trữ mã nguồn mở để tải xuống, lọc và khám phá nguồn gốc và đặc tính dữ liệu. Các công cụ của chúng tôi tự động tạo Data Provenance Card cho quy kết tượng trưng có thể mở rộng và thực tiễn tài liệu tốt nhất trong tương lai.

3. Chúng tôi thấy một sự phân chia sâu sắc và mở rộng giữa dữ liệu mở thương mại và đóng, với dữ liệu sau độc quyền các nguồn đa dạng và sáng tạo hơn. Chúng tôi đề xuất một trọng tâm thu thập dữ liệu để thu hẹp khoảng cách này.

2 Sáng kiến Kiểm toán Nguồn gốc Dữ liệu

Mục tiêu của Sáng kiến Nguồn gốc Dữ liệu là kiểm toán các bộ dữ liệu phổ biến và được sử dụng rộng rãi với chú thích quy mô lớn được hướng dẫn bởi chuyên gia Pháp lý và AI. Chúng tôi đề xuất một bộ chỉ số cơ bản cần thiết để truy vết dòng dõi bộ dữ liệu và hiểu rủi ro bộ dữ liệu (được mô tả trong Phần 2.1). Như một đóng góp đầu tiên của sáng kiến, chúng tôi kiểm toán 44 bộ sưu tập dữ liệu tinh chỉnh hướng dẫn hoặc "căn chỉnh" bao gồm 1858 bộ dữ liệu riêng lẻ, được chọn bởi các chuyên gia vì việc áp dụng và sử dụng rộng rãi của chúng trong cộng đồng. Các bộ sưu tập được chọn và các biến thể của chúng thấy hàng trăm đến 10 triệu+ lượt tải xuống hàng tháng trên HuggingFace, với các bộ dữ liệu trong các bộ sưu tập này đếm được nhiều hơn nữa Bảng 1.

Trọng tâm ban đầu của sáng kiến vào các bộ dữ liệu tinh chỉnh căn chỉnh được quyết định dựa trên sự nhấn mạnh ngày càng tăng của chúng trong cộng đồng để cải thiện tính hữu ích, giảm tính có hại và định hướng các mô hình theo giá trị con người (Ouyang et al., 2022). Một số bộ sưu tập có các bộ dữ liệu và ví dụ chồng chéo, nhưng chúng tôi chọn không khử trùng lặp để bảo tồn các lựa chọn thiết kế ban đầu, có thể bao gồm các mẫu, định dạng và lọc khác nhau. Chúng tôi loại bỏ các bộ dữ liệu liên quan đến các điểm chuẩn phổ biến như MMLU (Hendrycks et al., 2020) và BigBench (Srivastava et al., 2023).

Quy trình chú thích DPCollection sử dụng các quy trình con người và hỗ trợ con người để chú thích Định danh, Đặc tính và Nguồn gốc bộ dữ liệu. Chu kỳ Dữ liệu được truy vết, từ các nguồn gốc (thu thập web, văn bản con người hoặc tổng hợp), đến các bộ dữ liệu được tuyển chọn và các bộ sưu tập được đóng gói. Thông tin được thu thập ở mỗi giai đoạn, không chỉ ở giai đoạn cuối. Quy trình Chú thích Giấy phép được mô tả trong Phần 2.2.

2.1 Data Provenance Explorer (DPExplorer)

Kiểm toán thông tin của chúng tôi bao gồm (I) thông tin định danh, kết nối siêu dữ liệu từ một số tổng hợp, bao gồm Hugging Face, GitHub, Papers with Code, Semantic Scholar và ArXiv, (II) các đặc tính bộ dữ liệu chi tiết để hiểu rõ hơn về thành phần tập huấn luyện, và (III) nguồn gốc bộ dữ liệu cho cấp phép và quy kết. Chúng tôi mở rộng siêu dữ liệu nguồn gốc của mình không chỉ giấy phép, vì các cuộc trò chuyện với các nhà thực hành tiết lộ họ không chỉ dựa vào giấy phép dữ liệu, mà còn trên một mức dung nạp rủi ro pháp lý & đạo đức cụ thể, được tham số hóa bởi (a) dòng dõi giấy phép, (b) nguồn dữ liệu, (c) danh tính người tạo, và (d) tiền lệ áp dụng bởi các nhà phát triển khác.

Chúng tôi phát hành cuộc kiểm toán rộng lớn của mình, dưới dạng hai công cụ: (1) một giao diện khám phá dữ liệu, Data Provenance Explorer (DPExplorer) để sử dụng rộng rãi, và (2) một kho lưu trữ đi kèm cho các nhà thực hành tải xuống dữ liệu được lọc theo điều kiện giấy phép. Các nhà thực hành cũng có thể tạo ra một bản tóm tắt markdown có thể đọc được bởi con người, hoặc Data Provenance Card, của các bộ dữ liệu được sử dụng, và các thuộc tính thành phần cho ngôn ngữ, nhiệm vụ và giấy phép (Phần 2.3). Các nhà nghiên cứu hiện đại huấn luyện trên hàng trăm bộ dữ liệu thường thấy việc tuyển chọn thủ công các thẻ dữ liệu mở rộng cho các tổng hợp này là nặng nề (Mitchell et al., 2019; Gebru et al., 2021). Chúng tôi hy vọng công cụ này sẽ hỗ trợ viết các phần quy kết dữ liệu và thành phần của những nỗ lực tài liệu này, bằng cách cung cấp các bản tóm tắt dataframe được tạo tự động, có thể sao chép và dán.

Việc thu thập siêu dữ liệu toàn diện cho mỗi bộ dữ liệu đòi hỏi việc tận dụng một số nguồn bao gồm thu thập bằng cách liên kết đến các tài nguyên đã có trên web, chú thích con người bởi các chuyên gia pháp lý, hoặc sử dụng GPT-4 để hỗ trợ chú thích con người.

Thông tin Định danh tiết lộ liên kết và kết nối các định danh tổng hợp.
1. Định danh Bộ dữ liệu: Tên bộ dữ liệu, tiêu đề bài báo liên quan và mô tả bộ dữ liệu.
2. Liên kết Tổng hợp Bộ dữ liệu: Một liên kết đến mỗi tổng hợp chính, bao gồm GitHub, HuggingFace, Papers with Code, Semantic Scholar và ArXiv cho phép chúng tôi kết hợp và so sánh siêu dữ liệu crowdsourced của họ.
3. Bộ sưu tập: Tên và URL đến bộ sưu tập dữ liệu mà bộ dữ liệu này là một phần.

Đặc tính Bộ dữ liệu chi tiết thông tin liên quan đến việc hiểu đại diện/thành phần dữ liệu, và tuyển chọn một tập huấn luyện.
1. Ngôn ngữ: Mỗi ngôn ngữ được đại diện trong bộ dữ liệu, để các nhà phát triển có thể dễ dàng tuân theo "Quy tắc Bender" (Bender, 2011).
2. Danh mục Nhiệm vụ: Hơn 20 danh mục nhiệm vụ được đại diện trong các hướng dẫn, như Trả lời Câu hỏi, Dịch thuật, Tổng hợp Chương trình, Nhận dạng Độc tính, Viết Sáng tạo và Đóng vai.
3. Chủ đề Văn bản: Một chú thích tự động về các chủ đề được thảo luận trong các bộ dữ liệu, với GPT-4 gắn nhãn một mẫu 100 ví dụ cho tối đa 10 chủ đề được bao phủ.
4. Các Chỉ số Độ dài Văn bản: Số lượng tối thiểu, tối đa và trung bình của các lượt đối thoại trên mỗi cuộc trò chuyện, số ký tự (bất khả tri với tokenization/ngôn ngữ không khoảng trắng, vì điều này tạo ra thành kiến (Petrov et al., 2023)) trên mỗi hướng dẫn người dùng và phản hồi trợ lý.
5. Định dạng: Định dạng và mục đích sử dụng của dữ liệu. Các tùy chọn là lời nhắc zero-shot, lời nhắc few-shot, lời nhắc chain-of-thought, đối thoại đa lượt và xếp hạng phản hồi.
6. Thời gian Thu thập: Thời gian công việc được công bố, hoạt động như một ước tính giới hạn trên của tuổi văn bản.

Nguồn gốc Bộ dữ liệu
1. Giấy phép: Tên giấy phép và URL liên quan đến dữ liệu, sử dụng quy trình được mô tả trong Phần 2.2. Chúng tôi cũng cho phép lọc theo các lớp sử dụng giấy phép, được phân loại bởi các chuyên gia pháp lý.
2. Nguồn Văn bản: Các nguồn gốc của văn bản, thường là Wikipedia, Reddit hoặc các nguồn được thu thập trực tuyến/ngoại tuyến khác.
3. Người tạo: Các tổ chức của tác giả bộ dữ liệu, bao gồm các trường đại học, tập đoàn và các tổ chức khác.
4. Quy kết: Thông tin quy kết cho các tác giả của bài báo liên quan đến bộ dữ liệu.
5. Số lượng Trích dẫn & Tải xuống: Số lượng trích dẫn và tải xuống HuggingFace cho bài báo và bộ dữ liệu, được ghi ngày tháng 9 năm 2023. Điều này hoạt động như một ước tính về việc sử dụng cộng đồng, và thường được sử dụng như tiền lệ để quyết định mức độ rủi ro khi sử dụng các bộ dữ liệu này.

2.2 Quy trình Chú thích Giấy phép

Một trong những đóng góp trung tâm của chúng tôi là xác thực các giấy phép liên quan đến các bộ dữ liệu được sử dụng rộng rãi và được áp dụng. Điều này tuân theo một giao thức chú thích con người tốn thời gian, để thu thập giấy phép tự báo cáo của tác giả bộ dữ liệu, và phân loại chúng theo các điều kiện đã nêu. Lưu ý rằng giao thức này phản ánh những nỗ lực tốt nhất để xác minh giấy phép tự báo cáo, và không cấu thành lời khuyên pháp lý (xem Phần 4). Ngoài ra, điều quan trọng cần lưu ý là khả năng thực thi của các giấy phép này phụ thuộc vào một số yếu tố được thảo luận trong Phần 4. Một giả định đặc biệt quan trọng trong các trường hợp mà bộ dữ liệu dựa trên dữ liệu thu được từ các nguồn khác là các người tạo bộ dữ liệu thực sự có lợi ích bản quyền trong bộ dữ liệu của họ. Điều này phụ thuộc vào nguồn dữ liệu và cách các người tạo sửa đổi hoặc tăng cường dữ liệu này, và đòi hỏi phân tích từng trường hợp. Tuy nhiên, có vẻ như hầu hết các nhà phát triển hoạt động dưới giả định chung rằng chỉ họ sở hữu bộ dữ liệu của họ. Quy trình chú thích giấy phép của chúng tôi tuân theo các bước sau:

1. Biên soạn tất cả Thông tin Giấy phép Tự báo cáo Chúng tôi tổng hợp tất cả thông tin cấp phép được báo cáo trên GitHub, ArXiv, Hugging Face, Papers with Code và bản thân bộ sưu tập (ví dụ Super-Natural Instructions, Wang et al. (2022c)).

2. Tìm kiếm Giấy phép Dữ liệu rõ ràng Người chú thích tìm kiếm một giấy phép được đưa ra cụ thể cho bộ dữ liệu (không phải mã kèm theo) bởi các tác giả. Một giấy phép được tìm thấy nếu (a) kho lưu trữ GitHub đề cập hoặc liên kết một giấy phép trong tham chiếu đến dữ liệu, (b) nhãn giấy phép Hugging Face được tải lên bởi chính người tạo bộ dữ liệu, (c) bài báo, HuggingFace, hoặc Papers with Code cung cấp liên kết giấy phép cụ thể cho bộ dữ liệu, có thể quy kết cho các tác giả dữ liệu.

3. Nhận dạng Loại Giấy phép Một giấy phép có thể rơi vào một tập hợp các loại phổ biến (ví dụ MIT, Apache 2, CC BY SA, v.v.), là giấy phép "Tùy chỉnh", một Biểu mẫu Yêu cầu Phép, hoặc nếu không tìm thấy cho dữ liệu, Không xác định. Nếu một bộ dữ liệu có nhiều giấy phép, người chú thích sẽ liệt kê từng giấy phép, theo loại của chúng.

4. Phân loại Giấy phép Từ quan điểm của một nhà thực hành học máy, cấp phép thường được xem qua lăng kính về cách nó tác động đến chu kỳ sống mô hình—nó có cản trở hay cho phép huấn luyện trên dữ liệu, các điều kiện sử dụng xuôi dòng, quy kết, sửa đổi hoặc phân phối lại hay không. Dựa trên các cuộc thảo luận với các chuyên gia ngành, chúng tôi phân loại giấy phép dựa trên ba đặc tính quan trọng tác động đến chu kỳ sống mô hình: việc sử dụng dữ liệu có giới hạn cho mục đích học thuật hoặc phi thương mại (Sử dụng Được phép), nguồn dữ liệu có cần được quy kết hay không (Quy kết), và các sản phẩm phái sinh của dữ liệu có cần được cấp phép dưới các điều khoản tương tự như bản gốc hay không (Chia sẻ Tương tự). Nếu có nhiều giấy phép cho một bộ dữ liệu, việc phân loại của nó cho mỗi đặc tính được chọn là nghiêm ngặt nhất qua các giấy phép.

5. Nguồn gốc Bổ sung Trong thực tế, các đội ngũ pháp lý có thể muốn cân bằng khả năng chịu đựng rủi ro của họ với các tiêu chí sắc thái hơn. Ví dụ, họ có thể hài lòng với việc sử dụng giấy phép GitHub (cho phép nhiều hơn), ngay cả khi không rõ ràng liệu chúng có áp dụng cho mã hay dữ liệu. Họ cũng có thể muốn bao gồm hoặc loại trừ các bộ dữ liệu dựa trên việc chúng đã được sử dụng rộng rãi trong thực tế hay chưa, nguồn dữ liệu gốc được lấy từ đâu, và người tạo có phải là đối thủ cạnh tranh hay không. Để bổ sung cho các danh mục giấy phép trên, chúng tôi cũng thu thập tất cả siêu dữ liệu này để lựa chọn và lọc chi tiết.

2.3 Data Provenance Card— Thư mục Dữ liệu

Các công việc trước đây đã nhấn mạnh tầm quan trọng của tài liệu dữ liệu và quy kết (Bender and Friedman, 2018; Bommasani et al., 2023a). Đặc biệt, Datasheet của Gebru et al. (2021) chia nhỏ tài liệu thành động lực, thành phần, quy trình thu thập, xử lý, sử dụng, bảo trì và phân phối. Tương tự, Bender và Friedman (2018) yêu cầu cơ sở tuyển chọn, đa dạng ngôn ngữ, nhân khẩu học diễn giả, nhân khẩu học người chú thích, tình huống nói và đặc tính văn bản, trong số những thứ khác. Tuy nhiên, khi các mô hình huấn luyện trên nhiều nguồn dữ liệu, ngay cả khi chúng được tài liệu hóa nghiêm ngặt cho từng lĩnh vực này (hiếm khi như vậy), việc tổng hợp tài liệu toàn diện và có thể điều hướng cho gói kết quả là thách thức.

Để làm cho quy trình này khả thi với quy mô, chúng tôi đề xuất tận dụng Quy kết Tượng trưng, nơi các công cụ của chúng tôi tự động tạo ra một kho lưu trữ có cấu trúc của siêu dữ liệu nguồn gốc và quy kết, tương tự như một thư mục cho dữ liệu. Lược đồ thu thập của chúng tôi cho phép kho lưu trữ này nắm bắt một cách ngắn gọn việc quy kết (liên kết đến kho lưu trữ, bản sao tổng hợp, bài báo, người tạo), nguồn gốc (nguồn văn bản/máy, giấy phép), và các thuộc tính thành phần của dữ liệu (ngôn ngữ, nhiệm vụ, chỉ số văn bản, định dạng và thời gian). Tệp tham chiếu và siêu dữ liệu này, được biết đến như một Data Provenance Card cho phép tài liệu toàn diện, được đề xuất bởi các công việc trước đây, trong khi cung cấp một số lợi thế từ cấu trúc của nó. Đầu tiên, Data Provenance Card có thể được tìm kiếm, sắp xếp, lọc và phân tích một cách dễ dàng, trong khi Datasheet hoặc Statement, được thiết kế cho các bộ dữ liệu riêng lẻ, được dự định để đọc thủ công. Thứ hai, các nhà phát triển có thể lắp ráp thông tin liên quan một cách hiệu quả mà không mất bất kỳ chi tiết nào, bằng cách liên kết tượng trưng đến các bộ dữ liệu gốc và tài liệu của chúng. Thứ ba, khi các bộ dữ liệu được đóng gói lại liên tục và được hấp thụ vào các bộ sưu tập mới hơn và lớn hơn, Data Provenance Card dễ dàng thích ứng bằng cách đơn giản nối hoặc nối chúng lại với nhau. Tổng cộng, chúng tôi hy vọng công cụ này cho phép và thúc đẩy tài liệu kỹ lưỡng được đề xuất trong các công việc trước đây (Bender and Friedman, 2018; Gebru et al., 2021; Mitchell et al., 2019; Pushkarna et al., 2022).

3 Phân tích Thực nghiệm về Nguồn gốc Dữ liệu

3.1 Giấy phép trong Thực tế

Công việc này tạo thành nghiên cứu rộng lớn đầu tiên về việc sử dụng giấy phép thực nghiệm cho các bộ dữ liệu Xử lý Ngôn ngữ Tự nhiên. Trong phần này, chúng tôi chia sẻ những hiểu biết mà chúng tôi đã thu thập từ chú thích và phân loại quy mô lớn của mình. Có một giả định quan trọng trong phần này: Điều khoản Sử dụng OpenAI là một hợp đồng, không phải giấy phép, cấm phát triển các mô hình cạnh tranh sử dụng đầu ra của nó. Để đơn giản, chúng tôi coi điều này như một giấy phép Phi thương mại trong phân tích của mình, mặc dù điều này được tranh cãi đối với các bên thứ ba không tự tạo ra dữ liệu OpenAI và do đó có thể không bị ràng buộc bởi điều khoản của họ (xem Phần 4 để thảo luận). Với ý định của OpenAI không tạo điều kiện cho việc sử dụng thương mại cạnh tranh, chúng tôi tuân theo phân loại của họ cho phân tích này.

Tần suất các loại giấy phép Hình 2 cho thấy sự phân bố của các giấy phép. Các giấy phép phổ biến nhất là CC-BY-SA4.0 (15.7%), Điều khoản Sử dụng OpenAI (12.3%), và CC-BY4.0 (11.6%). Trong khi hầu hết các giấy phép là phổ biến và có thể nhận ra, có một đuôi dài của các biến thể với cài đặt duy nhất, cũng như một tập hợp lớn các giấy phép Tùy chỉnh chiếm 9.6% tất cả giấy phép được ghi nhận. Sự đa dạng giấy phép rộng lớn này minh họa thách thức đối với các startup và tổ chức ít tài nguyên hơn khi cố gắng điều hướng việc thu thập dữ liệu huấn luyện có trách nhiệm, tính hợp pháp và đạo đức của nó.

Phân bố Giấy phép Hạn chế Tổng cộng, 85% giấy phép bộ dữ liệu yêu cầu quy kết, và 30% bao gồm điều khoản chia sẻ tương tự. Các bộ dữ liệu yêu cầu quy kết đặt ra thách thức cho các nhà thực hành thường huấn luyện trên hàng trăm bộ dữ liệu và hoặc không trích dẫn chúng chút nào (OpenAI, 2023; Anil et al., 2023; Touvron et al., 2023) hoặc chỉ trích dẫn một tổng hợp dữ liệu, thường không đạt yêu cầu điều kiện giấy phép về quy kết kho lưu trữ hoặc bài báo cụ thể. Hơn nữa, các điều khoản "Chia sẻ tương tự" đặt ra thách thức cho các nhà thực hành đóng gói lại các bộ sưu tập dữ liệu thường với nhiều giấy phép chia sẻ tương tự mâu thuẫn mà không có cách rõ ràng để giải quyết chúng (như Longpre et al. (2023a); Wang et al. (2022c) và những người khác trong DPCollection). Thường xuyên, các nhà thực hành sẽ ghi đè giấy phép chia sẻ tương tự với các điều kiện hạn chế hơn hoặc thậm chí ít hạn chế hơn.

Giấy phép Thiếu hoặc Không xác định. Tiếp theo, chúng tôi so sánh các điều khoản cấp phép được xem xét thủ công của chúng tôi, với các giấy phép cho cùng các bộ dữ liệu, như được tài liệu hóa trong các tổng hợp GitHub, HuggingFace, và Papers with Code. Bảng 2 cho thấy rằng các tổng hợp crowdsourced này có tỷ lệ cực kỳ cao của giấy phép thiếu ("Không xác định"), dao động từ 69-72%, so với giao thức của chúng tôi chỉ cho 30% "Không xác định". Vấn đề với giấy phép "Không xác định" là không rõ ràng liệu nó là do thiếu sót của tổng hợp hay vì các người tạo cố ý phát hành chúng mà không có giấy phép. Do đó, các nhà phát triển tránh rủi ro buộc phải tránh nhiều bộ dữ liệu có giá trị, mà họ sẽ sử dụng nếu được đảm bảo rằng thực sự không có giấy phép. Như một phần của DPCollection, chúng tôi gán lại thủ công 46-65% giấy phép bộ dữ liệu (tùy thuộc vào nền tảng), dẫn đến độ bao phủ cao hơn nhiều, do đó tạo cho các nhà phát triển tránh rủi ro nhiều niềm tin và độ rộng hơn trong việc sử dụng bộ dữ liệu của họ.

Giấy phép Được chỉ định Không chính xác. Bảng 2 cũng thấy giấy phép thực được gán bởi chúng tôi thường nghiêm ngặt hơn so với những giấy phép của các tổng hợp. GitHub, Hugging Face và Papers with Code mỗi cái gắn nhãn các trường hợp sử dụng giấy phép quá cho phép trong 29%, 27%, và 16% trường hợp tương ứng. Kiểm tra của chúng tôi gợi ý điều này là do các người đóng góp trên các nền tảng này thường nhầm lẫn giấy phép gắn với mã trong kho lưu trữ GitHub với giấy phép gắn với dữ liệu.

3.2 Tình trạng Sẵn có Dữ liệu Khác nhau như thế nào theo Danh mục Sử dụng Giấy phép?

Trong khi các giấy phép phi thương mại và chỉ học thuật đóng vai trò quan trọng trong việc bảo vệ sử dụng dữ liệu, sự hiện diện của chúng cũng có thể loại trừ các cộng đồng khỏi việc tham gia (hoặc cạnh tranh) trong phát triển các công nghệ này. Trong phần này, chúng tôi chia nhỏ các bộ dữ liệu theo hạn chế giấy phép của chúng và xem chúng khác nhau như thế nào. Cụ thể, chúng tôi hỏi: Việc tuân thủ giấy phép có quy định sự khác biệt hệ thống trong tài nguyên cho phát triển cho phép thương mại ("mở") và phi thương mại ("đóng") không? Và những đặc tính cụ thể nào của dữ liệu đặc biệt bị hạn chế bởi các cấm đoán phi thương mại?

Chúng tôi so sánh các bộ dữ liệu theo danh mục sử dụng được phép, theo giấy phép của chúng: (1) Khả thi thương mại, (2) Phi thương mại/Chỉ học thuật (NC/A-O), hoặc (3) Giấy phép không xác định. Chúng tôi nhóm cùng các điều kiện Phi thương mại và Chỉ học thuật vì sự khác biệt sẽ hiếm khi quan trọng đối với các nhà phát triển. Chúng tôi lập luận trong Phần 4 rằng các bộ dữ liệu không có giấy phép nào (Không xác định) không áp đặt bất kỳ điều kiện nào, vì vậy thường có thể được xử lý như khả thi thương mại, nhưng điều này có thể phụ thuộc vào khả năng chịu đựng rủi ro và thẩm quyền của nhà phát triển.

Các Bộ dữ liệu được Cấp phép Phi thương mại & Chỉ học thuật có sự đa dạng lớn hơn về mặt thống kê trong đại diện của nhiệm vụ, chủ đề, nguồn và độ dài văn bản mục tiêu. Đối với mỗi đặc tính này, Bảng 3 minh họa số lượng trung bình trên mỗi bộ dữ liệu, được chia theo danh mục giấy phép và entropy để đo lường sự ngẫu nhiên, và do đó là sự đa dạng, của mỗi đặc tính. Các bộ dữ liệu NC/A-O thấy sự đa dạng lớn hơn của nhiệm vụ, chủ đề và nguồn được đại diện trong văn bản so với các bộ dữ liệu thương mại. Hình 4 cho thấy sự đa dạng này đến từ đâu. Các danh mục nhiệm vụ NC/A-O nhất bao gồm Động não, Giải thích, Logic & Toán học, cũng như Sáng tạo và Viết Sáng tạo. Ngược lại, các danh mục nhiệm vụ khả thi thương mại nhất là Tạo Văn bản Ngắn, Dịch thuật và Phân loại. Tương tự, trong số Miền Nguồn, Chính phủ và Truy vấn Tìm kiếm phần lớn khả thi cho mục đích thương mại (và không xác định), trong khi Web Tổng quát, Kỳ thi và nguồn Tạo ra bởi mô hình nằm trong số những nguồn hạn chế nhất.

Độ dài Văn bản Mục tiêu cao hơn đáng kể đối với các bộ dữ liệu NC/A-O so với các bộ dữ liệu thương mại. Không chỉ các bộ dữ liệu NC/A-O xuất hiện đa dạng hơn về mặt văn bản và chức năng, đặc tính độ dài của chúng cũng khác biệt đáng kể. Trong khi Bảng 3 cho thấy độ dài văn bản đầu vào qua các danh mục giấy phép là tương tự trung bình, độ dài văn bản mục tiêu cao hơn đáng kể đối với các bộ dữ liệu NC/A-O (103 so với 677). Sự chia nhỏ này được minh họa thêm trong Hình 5, nơi chúng ta thấy sự đại diện lớn hơn của cả các bộ dữ liệu NC/A-O và tổng hợp trên ngưỡng 100 token mục tiêu (trục y).

Sự gia tăng của các bộ dữ liệu tổng hợp được tạo ra bằng API với điều khoản sử dụng phi thương mại có thể giải thích sự khác biệt trong đa dạng văn bản và độ dài. Bảng 3 cũng cho thấy đầy đủ 45% các bộ dữ liệu NC/A-O là tổng hợp, so với <14% trong các danh mục giấy phép cho phép nhiều hơn. Taori et al. (2023); Wang et al. (2022a); Xu et al. (2023a) và các biến thể của chúng, tất cả được tạo ra một phần bằng API thương mại, thể hiện sự đa dạng nhiệm vụ và chủ đề mạnh mẽ hơn so với các bộ dữ liệu học thuật truyền thống, vì chúng phục vụ các thế hệ hình thức dài hơn, theo thiết kế. Điều này rõ ràng từ sự tập trung của các nhiệm vụ sáng tạo, động não và lập luận được nướng vào chúng, so với trọng tâm của trả lời câu hỏi tập trung chủ đề hơn, phân loại và tạo văn bản ngắn trong các bộ dữ liệu không tổng hợp. Các bộ dữ liệu này thường được tạo ra bằng các mô hình độc quyền lớn hơn, chủ yếu từ API OpenAI. Điều khoản Sử dụng OpenAI nêu "bạn không được... sử dụng đầu ra từ Dịch vụ để phát triển các mô hình cạnh tranh với OpenAI." mà chúng tôi thảo luận trong Phần 4.

2023 có một sự gia tăng lớn trong việc sử dụng giấy phép, và trong dữ liệu được cấp phép NC/A-O, đại diện 61%, so với 20% trung bình trong các năm trước. Trong số bộ sưu tập lớn các bộ dữ liệu mà chúng tôi truy vết, chúng tôi ghi lại ngày mà chúng được phát hành, bằng cách tham chiếu chéo với các ngày GitHub, ArXiv và Hugging Face liên quan của chúng. Chúng tôi thấy một sự thay đổi nổi bật trong mô hình hạn chế cấp phép. Như được hiển thị trong Hình 3, trước năm 2023, không năm nào thấy lớn hơn 1/3 các bộ dữ liệu được phát hành là NC/A-O. Tuy nhiên, trong năm 2023, bao gồm nhiều bộ dữ liệu phổ biến và đa dạng nhất, tỷ lệ NC/A-O là 61%. Hơn nữa, hầu hết các bộ dữ liệu không có giấy phép kèm theo trước năm 2022 (~50-80%), so với chỉ 12% trong năm 2023. Sự chuyển dịch sang sử dụng giấy phép nhiều hơn, và các bản phát hành dữ liệu có điều kiện hạn chế hơn có thể báo trước những thách thức trong tương lai đối với dữ liệu mở, nếu xu hướng tiếp tục.

Các bộ dữ liệu thương mại có đa dạng ngôn ngữ lớn hơn, nhưng các bộ dữ liệu ngôn ngữ tài nguyên thấp thấy độ bao phủ thương mại ít nhất. Bảng 3 cho thấy rằng các bộ dữ liệu thương mại thực sự có sự đa dạng ngôn ngữ lớn hơn so với NC/A-O. Tuy nhiên, khi được chia nhỏ theo họ ngôn ngữ, như trong Hình 3, chúng ta thấy sự khác biệt rõ rệt trong sử dụng được phép theo nhóm. Các bộ dữ liệu ngôn ngữ mã gần như tất cả khả thi thương mại (78%), vì các người tạo bộ dữ liệu có thể dễ dàng lọc GitHub cho các kho lưu trữ được cấp phép cho phép. Thú vị là, tiếng Anh, Atlantic-Congo và các ngôn ngữ Afroasiatic cũng thấy sự đại diện cho phép lớn. Tuy nhiên, các ngôn ngữ Turkic, Sino-Tibetan, Japonic và Indo-European thấy hơn 35% là phi thương mại. Lưu ý rằng trong khi họ ngôn ngữ Indo-European chứa nhiều họ ngôn ngữ châu Âu tài nguyên cao, có một đuôi dài của những ngôn ngữ tài nguyên thấp hơn. Những họ ngôn ngữ NC/A-O này cung cấp hướng cho các nhà thực hành dữ liệu mở tập trung nỗ lực tương lai của họ.

3.3 Đặc tính Rộng hơn của Dữ liệu

Ngoài việc hiểu sự khác biệt hệ thống trong dữ liệu theo giấy phép, có những câu hỏi nghiên cứu về thành phần và đặc tính tổng thể của những bộ dữ liệu được sử dụng rộng rãi và được áp dụng này. Việc biên soạn siêu dữ liệu của chúng tôi thông qua DPCollection cho phép chúng tôi lập bản đồ cảnh quan của các đặc tính dữ liệu, và kiểm tra các đặc tính cụ thể. Lưu ý rằng tất cả các chi tiết này cũng có sẵn với các hình ảnh hóa tương tác tại www.comingsoon.com, để nghiên cứu và kiểm tra thêm.

Đại diện Ngôn ngữ nghiêng mạnh về tiếng Anh và các Ngôn ngữ Tây Âu. Theo các khuyến nghị của Talat et al. (2022) trong tính minh bạch dữ liệu và tài liệu trong phân tích nhân khẩu học, và củng cố phân tích tương tự của Kreutzer et al. (2022) cho corpus tiền huấn luyện, chúng tôi thấy một sự nghiêng lệch mạnh mẽ về phương Tây trong đại diện. Hình 6 minh họa độ bao phủ mỗi quốc gia theo ngôn ngữ nói và đại diện của chúng trong DPCollection. Chúng tôi tính toán một điểm Đại diện Ngôn ngữ Sk cho mỗi quốc gia k, được tham số hóa bởi pkl, tỷ lệ phần trăm người ở quốc gia k nói ngôn ngữ l, và wli là một chỉ báo nhị phân là 1 nếu bộ dữ liệu i∈D chứa ngôn ngữ l và 0 nếu ngược lại.

Sk=∑l∈L (pkl×∑i∈D wli)

Phân bố được hình ảnh hóa trong Hình 6 cho thấy rằng các quốc gia châu Á, châu Phi và Nam Mỹ được bao phủ thưa thớt nếu có. Ngay cả khi các quốc gia từ Nam bán cầu xuất hiện có đại diện ngôn ngữ, theo Phần 3.3, nguồn văn bản và phương ngữ của ngôn ngữ chứa trong các bộ dữ liệu này hầu như luôn xuất phát từ các người tạo và nguồn web Bắc Mỹ hoặc châu Âu (mặc dù điều này khó đo lường chính xác). Những quan sát này củng cố những phát hiện tương tự trong sự đa dạng địa lý của dữ liệu hình ảnh trong lĩnh vực thị giác (Shankar et al., 2017; De Vries et al., 2019; Mahadev and Chakravarti, 2021). Các mô hình kết quả được huấn luyện trên các bộ dữ liệu này có khả năng có thành kiến vốn có, hoạt động kém theo những cách quan trọng đối với người dùng mô hình bên ngoài phương Tây (Ahia et al., 2021).

Những động lực chính của tuyển chọn bộ dữ liệu là các tổ chức Học thuật, cung cấp 69%, theo sau là 21% phòng thí nghiệm ngành và 17% tổ chức nghiên cứu. Những chỉ số này mô tả quy mô của đóng góp tuyển chọn bộ dữ liệu, nhưng không phải ảnh hưởng mà mỗi bộ dữ liệu đã có đối với cộng đồng. Bảng 4a chứng minh những người đóng góp bộ dữ liệu lớn nhất là AI2 (12.3%), Đại học Washington (8.9%), và Facebook AI Research (8.4%). Điều quan trọng cần lưu ý là những người đóng góp này thường chỉ tải xuống và biên soạn văn bản từ Internet mà ban đầu được viết bởi những người khác.

Các bộ dữ liệu văn bản tập trung vào các chủ đề Ngôn ngữ & Ngôn ngữ học, Kiến thức Tổng quát, Logic, & Lối sống. Các công việc thu thập dữ liệu trước đây tập trung chủ yếu vào việc mô tả các bộ dữ liệu theo thành phần nhiệm vụ của chúng (Sanh et al., 2021; Wang et al., 2022a; Longpre et al., 2023a), nhưng hiếm khi theo các chủ đề thực tế của chúng (ngoại trừ (Gao et al., 2020) trong Phụ lục của họ). Bảng 4b cho thấy các chủ đề phổ biến nhất, được nhóm theo danh mục, với đại diện của chúng qua các bộ dữ liệu. Giống như hầu hết các nhiệm vụ NLP, phần lớn dữ liệu văn bản này tập trung vào các chủ đề giao tiếp và hiểu biết ngôn ngữ, được theo sát bởi kiến thức tổng quát, thói quen, thể thao và giáo dục.

Các bộ dữ liệu văn bản được lấy chủ yếu từ Bách khoa toàn thư Trực tuyến (22%), Phương tiện Truyền thông Xã hội (16%), được thu thập từ Web Tổng quát (11%), Tin tức (11%), tài nguyên web Giải trí (9%). Trong khi các nhà thực hành tài liệu hóa các nguồn bộ dữ liệu riêng lẻ của họ trong các bài báo được công bố, thông tin này không có cấu trúc và có thể khó tìm. Kết quả là, các bộ sưu tập lớn của các bộ dữ liệu được sử dụng rộng rãi hiếm khi biên soạn phân bố của các nguồn gốc của chúng, thay vào đó chỉ trích dẫn các bài báo. Sau một loạt các bộ sưu tập bộ dữ liệu và đóng gói lại, các nguồn gốc thường bị mất hoặc không được biết rõ. Bằng cách quét thủ công khoảng 500 bài báo học thuật, các tình nguyện viên của chúng tôi đã chú thích các nguồn văn bản gốc và biên soạn chúng thành các cụm miền, để cho phép quy kết và phân tích, như được tóm tắt trong Bảng 4c. Trong số các nguồn được áp dụng nhiều nhất bởi các nguồn được sử dụng là wikipedia.org (14.9%), các trang web không tiết lộ (7.0%), reddit (6.2%), và Twitter (4.0%). Các miền được đại diện ít nhất là Thương mại, Đánh giá, Pháp lý, Bài báo Học thuật và Truy vấn Tìm kiếm, trong số những miền khác.

4 Thảo luận Pháp lý

Phân tích thực nghiệm của chúng tôi làm nổi bật rằng chúng ta đang ở giữa một cuộc khủng hoảng trong nguồn gốc bộ dữ liệu và các nhà thực hành buộc phải đưa ra quyết định dựa trên thông tin hạn chế và khung pháp lý mờ ám. Trong khi chúng tôi tin rằng công cụ của chúng tôi sẽ cho phép tính minh bạch tốt hơn về nơi giấy phép căng thẳng, những mơ hồ pháp lý chính vẫn tồn tại trong cấp phép dữ liệu.

Bối cảnh Luật bản quyền nhằm khuyến khích biểu hiện bằng văn bản và nghệ thuật bằng cách cung cấp cho tác giả quyền độc quyền sao chép, phân phối và chuyển thể tác phẩm của họ (Patterson, 2003; Burger, 1988). Giấy phép mã nguồn mở đầu tiên xuất hiện như công cụ pháp lý để khuyến khích hợp tác xung quanh phát triển phần mềm (Von Krogh and Von Hippel, 2003). Một loạt giấy phép với các điều khoản và mục đích khác nhau tồn tại bao gồm Giấy phép MIT, Giấy phép Creative Commons, và Giấy phép Apache, cũng như Giấy phép AI Có trách nhiệm (RAIL) và Giấy phép AI2 ImpACT mới hơn. Sự tương tác giữa bản quyền và giấy phép có thể được hiểu theo cách sau: bản quyền tự động cung cấp cho các người tạo quyền độc quyền trong tác phẩm của họ và các người tạo gán những quyền này cho người khác thông qua thỏa thuận giấy phép. Như chúng ta sẽ khám phá, các giấy phép mã nguồn mở xuất hiện trong ba thập kỷ qua không phải lúc nào cũng được trang bị tốt để xử lý các đặc tính độc đáo của dữ liệu, và đặc biệt là dữ liệu huấn luyện AI có giám sát. Trong khi đó, vẫn chưa rõ ràng làm thế nào các luật liên quan, bao gồm những luật liên quan đến bản quyền và sử dụng hợp lý, nên được áp dụng cho những thách thức độc đáo được đặt ra bởi AI Tạo sinh và các bộ dữ liệu có giám sát (Lee et al., 2023). Trong phần này, chúng tôi làm nổi bật một số thách thức và mơ hồ pháp lý chính liên quan đến các bộ dữ liệu có giám sát.

Chu kỳ sống của một bộ dữ liệu Chúng tôi tập trung vào các bộ dữ liệu có giám sát, mà chúng tôi định nghĩa là các bộ dữ liệu được tạo ra cho học máy (chủ yếu cho tinh chỉnh và căn chỉnh) và nơi các người tạo bộ dữ liệu đã đóng góp có thể có bản quyền dưới dạng chú thích hoặc biên soạn. Một bộ dữ liệu có giám sát điển hình là kết quả của một quá trình bao gồm một số giai đoạn thu thập (hoặc tạo ra bởi máy) và chú thích bởi các thực thể khác nhau. Thông thường, dữ liệu thô được tạo ra bởi mọi người tương tác với các nền tảng internet, chẳng hạn như cá nhân viết bài, chia sẻ tác phẩm nghệ thuật, hoặc tham gia vào các diễn đàn thảo luận trực tuyến. Bản quyền cho dữ liệu thô này thường được nắm giữ bởi người dùng cá nhân (ví dụ Reddit) hoặc bởi nền tảng (ví dụ Amazon Reviews). Phần lớn dữ liệu này đã được thu thập để xây dựng các bộ dữ liệu không giám sát cho học máy và việc sử dụng này thường được biện minh trên cơ sở sử dụng hợp lý hoặc các ngoại lệ khai thác dữ liệu đối với bản quyền (Henderson et al., 2023; Sobel, 2017; Lee et al., 2023; Samuelson, 2023; Lemley and Casey, 2020). Tuy nhiên, chúng tôi thấy rằng nhiều bộ dữ liệu có giám sát phổ biến được tạo ra bằng cách chú thích các mẫu nhỏ của dữ liệu thô được thu thập bằng người chú thích hoặc mô hình ngôn ngữ lớn. Dữ liệu được chú thích sau đó được công bố với thỏa thuận giấy phép. Trái ngược hoàn toàn với nội dung có bản quyền được thu thập từ web, các bộ dữ liệu có giám sát được tạo ra với mục đích duy nhất thúc đẩy học máy. Trọng tâm của thảo luận pháp lý trong phần này là về cách các người tạo bộ dữ liệu có giám sát có thể hạn chế việc sử dụng nội dung có thể có bản quyền mà họ tạo ra thông qua giấy phép và các cơ chế pháp lý khác. Mặc dù chúng tôi không đề cập ở đây, có một số câu hỏi liên quan quan trọng về việc sử dụng các tác phẩm có bản quyền để tạo ra các bộ dữ liệu có giám sát và về khả năng có bản quyền của các bộ dữ liệu huấn luyện.

Ví dụ Bộ dữ liệu Có giám sát: SQuAD
Rajpurkar et al. (2016) trình bày một bộ dữ liệu có giám sát nguyên mẫu về hiểu đọc. Để tạo ra bộ dữ liệu, các tác giả lấy các đoạn trích dài đoạn từ 539 bài báo Wikipedia phổ biến và thuê các công nhân crowdsource để tạo ra hơn 100,000 câu hỏi có câu trả lời chứa trong đoạn trích. Ví dụ:

Đoạn trích Wikipedia Trong khí tượng học, mưa là bất kỳ sản phẩm nào của sự ngưng tụ hơi nước khí quyển rơi xuống dưới tác dụng của trọng lực.

Câu hỏi do công nhân tạo: Điều gì khiến mưa rơi? Câu trả lời: Trọng lực

Ở đây các tác giả sử dụng văn bản Wikipedia làm cơ sở cho dữ liệu của họ và bộ dữ liệu của họ chứa 100,000 cặp câu hỏi-câu trả lời mới dựa trên những văn bản này.

Luật bản quyền thay đổi theo thẩm quyền và mang tính chủ quan, vì vậy thật thách thức để phát triển các biện pháp bảo vệ kỹ thuật đảm bảo tuân thủ. Phân tích pháp lý xung quanh các bộ dữ liệu có giám sát được phức tạp hóa bởi sự thiếu vắng khung pháp lý toàn cầu thống nhất để giải quyết các mối lo ngại về bản quyền. Các thẩm quyền khác nhau có luật khác nhau và đang phát triển. Do đó, vị trí của các nhà phát triển mô hình và người tạo dữ liệu huấn luyện cũng như nơi và khi nào dữ liệu được thu thập có thể ảnh hưởng đến phân tích pháp lý. Ví dụ, Hoa Kỳ có ngoại lệ sử dụng hợp lý đối với bản quyền cho phép sử dụng hạn chế tài liệu có bản quyền dưới một số trường hợp nhất định mà không cần phép từ người giữ quyền (17 U.S.C. §107). EU không có điều khoản sử dụng hợp lý nhưng có ngoại lệ bản quyền rõ ràng để cho phép khai thác dữ liệu dưới một số điều kiện nhất định, như có được quyền truy cập hợp pháp vào dữ liệu (Margoni and Kretschmer, 2022). Trong khi đó, bản thân các bộ dữ liệu thường được bảo vệ bản quyền ở Mỹ (Lee et al., 2023) trong khi EU gần đây đã tạo ra một bộ quyền độc đáo cho các người tạo bộ dữ liệu với mục đích khuyến khích nghiên cứu và phát triển liên quan đến cơ sở dữ liệu (Derclaye and Husovec, 2022). Ngoài sự khác biệt qua các thẩm quyền, cũng có một số thỏa thuận quốc tế liên quan đến bản quyền Ricketscon and Ginsburg (2022). Cuối cùng, có thể thách thức để xác định luật nào nên áp dụng cho một dự án học máy cụ thể khi các quy tắc liên quan thay đổi giữa các vị trí nơi dữ liệu được thu thập và chú thích, nơi nó được tải xuống, nơi mô hình được huấn luyện, và nơi mô hình được triển khai.

Trong khi sự khác biệt địa lý trong khung quy định trình bày một tập hợp thách thức, tính chủ quan vốn có trong việc xác định liệu vi phạm bản quyền có xảy ra hay không làm cho việc thiết kế các biện pháp bảo vệ kỹ thuật thậm chí còn thách thức hơn. Ví dụ, ở Mỹ, một phần của phân tích vi phạm bản quyền phụ thuộc vào việc liệu hai tác phẩm có tương tự chủ quan từ quan điểm của một người bình thường hay không (Mohler, 1999; Cohen, 1986; Balganesh et al., 2014). Đây là một tiêu chuẩn chủ quan và pháp lý hiện tại có thể thách thức để mở rộng ra đầu ra AI tạo sinh. Kết quả là, trong khi có các chiến lược kỹ thuật có thể giảm rủi ro vi phạm (Henderson et al., 2023; Sag, 2023; Vyas et al., 2023), sẽ khó khăn cho các nhà phát triển tạo ra các biện pháp bảo vệ kỹ thuật loại bỏ hoàn toàn rủi ro này.

Câu hỏi pháp lý mở về bản quyền và huấn luyện mô hình. Ngoài những mơ hồ về thẩm quyền và diễn giải này, quá trình huấn luyện mô hình đặt ra những câu hỏi bản quyền cụ thể (Epstein et al., 2023). Huấn luyện mô hình đặt ra một số câu hỏi pháp lý thú vị liên quan đến bản quyền và vi phạm có thể xảy ra theo một số cách ngay cả trước khi bất kỳ đầu ra nào được tạo ra.

Đầu tiên, hành động tạo ra bộ dữ liệu huấn luyện bằng cách thu thập các tác phẩm hiện có bao gồm tạo ra bản sao kỹ thuật số của dữ liệu cơ bản. Như tên gọi, bản quyền cung cấp cho tác giả của tác phẩm được bảo vệ quyền độc quyền tạo ra bản sao của tác phẩm đó. Nếu dữ liệu được thu thập được bảo vệ bởi bản quyền, thì tạo ra corpus dữ liệu huấn luyện có thể đặt ra các vấn đề bản quyền (Quang, 2021). Thứ hai, người giữ bản quyền thường có quyền độc quyền tạo ra các tác phẩm phái sinh (ví dụ, bản dịch của một tác phẩm) nhưng không rõ ràng liệu một mô hình học máy được huấn luyện nên được coi là phái sinh của dữ liệu huấn luyện hay không (Lee et al., 2023). Nếu các mô hình được coi là tác phẩm phái sinh, thì huấn luyện mô hình sẽ có khả năng vi phạm quyền của người giữ bản quyền dữ liệu huấn luyện (Gervais, 2021).

Ở Mỹ, ngoại lệ sử dụng hợp lý có thể cho phép các mô hình được huấn luyện trên các tác phẩm được bảo vệ (Henderson et al., 2023; Lemley and Casey, 2020; Sobel, 2017; Samuelson, 2023). Như các tác giả này giải thích, việc huấn luyện các mô hình học máy trên nội dung có bản quyền có thể được chấp nhận nếu các tác phẩm cơ bản được "biến đổi" đáng kể thành trọng số mô hình, chỉ một lượng nhỏ của mỗi tác phẩm trong dữ liệu huấn luyện được bao gồm trong mô hình được huấn luyện, huấn luyện mô hình được thiết kế để chỉ thu thập những hiểu biết có thể tổng quát hóa từ dữ liệu huấn luyện, và mô hình được huấn luyện không có tác động mạnh lên thành công kinh tế của các tác phẩm trong dữ liệu huấn luyện. Điều quan trọng cần nhấn mạnh là, trong khi huấn luyện mô hình học máy bản thân nó có thể được bảo vệ bởi sử dụng hợp lý, điều này không có nghĩa là đầu ra mô hình sẽ không vi phạm bản quyền của các tác phẩm trước đó. Như các tác giả trên làm nổi bật, việc áp dụng sử dụng hợp lý trong bối cảnh vẫn đang phát triển và một số vấn đề này hiện đang được tranh tụng (xem ví dụ, Andersen v. Stability, Doe v. GitHub, và Tremblay v. OpenAI).

Sử dụng hợp lý ít có khả năng áp dụng khi các tác phẩm được tạo ra với mục đích duy nhất huấn luyện các mô hình học máy như trong trường hợp các bộ dữ liệu có giám sát với các thành phần hoặc chú thích có thể có bản quyền. Tài liệu trước đây về sử dụng hợp lý và học máy có xu hướng tập trung vào nghệ thuật hoặc văn bản có bản quyền được thu thập để huấn luyện mô hình. Những tác phẩm được thu thập này không được tạo ra với mục đích huấn luyện các mô hình học máy. Ngược lại, trong bài báo này, chúng tôi tập trung vào các bộ dữ liệu có giám sát được tạo ra với mục đích duy nhất huấn luyện các mô hình học máy. Như được nhấn mạnh bởi Henderson et al. (2023) và Sobel (2017), phân tích sử dụng hợp lý phụ thuộc một phần vào việc liệu một mô hình được huấn luyện có sao chép "mục đích biểu hiện" của tác phẩm gốc hay không. Trong khi mục đích biểu hiện của một đoạn văn bản hoặc nghệ thuật không phải là để huấn luyện các mô hình học máy, mục đích của một bộ dữ liệu huấn luyện là để làm chính điều đó. Kết quả là, chúng tôi mong đợi rằng ít có khả năng sử dụng hợp lý sẽ áp dụng cho việc sử dụng dữ liệu được tuyển chọn. Thay vào đó, các người tạo ra những bộ dữ liệu này giữ bản quyền trong bộ dữ liệu và các điều khoản của thỏa thuận giấy phép bộ dữ liệu điều chỉnh việc sử dụng tiếp theo dữ liệu này. Tuy nhiên, hiếm khi trong thực tế một LLM sử dụng một bộ dữ liệu có giám sát duy nhất và thường nhiều bộ dữ liệu được biên soạn thành các bộ sưu tập. Điều này càng phức tạp hóa phân tích pháp lý vì chúng tôi thấy rằng các điều khoản giấy phép của nhiều bộ sưu tập bộ dữ liệu phổ biến đang mâu thuẫn.

Giấy phép được sử dụng cho bộ dữ liệu thường không phù hợp cho mục đích này. Ngoài sự tương tác phức tạp giữa dữ liệu huấn luyện và sử dụng hợp lý, các khung cấp phép thường được áp dụng sai cho bộ dữ liệu trình bày một tập hợp phức tạp khác. Hầu hết giấy phép mã nguồn mở được thiết kế cho phần mềm, nhưng chúng tôi thấy chúng được gắn vào bộ dữ liệu. Những giấy phép này được dự định áp dụng cho phần mềm, không phải dữ liệu, tạo ra thách thức (Meeker, 2022). Một trong những thách thức là các giấy phép như Apache và Creative Commons phác thảo các hạn chế liên quan đến "tác phẩm phái sinh" hoặc "thích ứng" nhưng vẫn chưa rõ ràng liệu một mô hình được huấn luyện nên được phân loại là tác phẩm phái sinh hay không. Vấn đề này càng được tăng cường khi nhiều bộ dữ liệu, mỗi cái có khả năng được điều chỉnh bởi một giấy phép mã nguồn mở khác nhau, được hòa trộn thành các bộ sưu tập. Nếu các yêu cầu của các thỏa thuận giấy phép cơ bản không thể hòa giải, chẳng hạn như các yêu cầu copyleft khác nhau, điều này làm cho việc các nhà phát triển sử dụng một số bộ sưu tập nhất định trong khi tôn trọng tất cả điều khoản giấy phép trở nên cực kỳ khó khăn. Để khắc phục những vấn đề này, các giấy phép mới đang được đề xuất để giải quyết nhu cầu của các bộ dữ liệu học máy như BigScience Responsible AI License hoặc một bản điều chỉnh của Giấy phép MIT yêu cầu các phép bổ sung cho huấn luyện mô hình được đề xuất bởi Ioannidis et al. (2023). Bất chấp những đề xuất mới này, chúng tôi thấy rằng phần lớn bộ dữ liệu được cấp phép dưới các giấy phép mã nguồn mở thông thường.

Chú thích được tạo ra bởi LLM đặt ra các cân nhắc pháp lý bổ sung. Chúng tôi thấy rằng khoảng 12% bộ dữ liệu mà chúng tôi kiểm toán được chú thích bằng OpenAI. Điều khoản Sử dụng OpenAI nêu rằng đầu ra từ dịch vụ OpenAI không được sử dụng để "phát triển các mô hình cạnh tranh với OpenAI". Những điều khoản này dường như loại trừ một nhà phát triển sử dụng OpenAI để tạo ra dữ liệu huấn luyện để huấn luyện một LLM cạnh tranh. Tuy nhiên, không rõ ràng liệu chúng cũng sẽ hạn chế khả năng của một nhà phát triển sử dụng OpenAI để tạo ra và công bố một bộ dữ liệu được chú thích. Một mặt, công bố bộ dữ liệu như vậy không trực tiếp cạnh tranh với OpenAI. Mặt khác, có vẻ như có thể dự đoán được rằng bộ dữ liệu như vậy có thể cho phép các bên thứ ba (những người không tự sử dụng OpenAI) tạo ra các LLM cạnh tranh. Ở Mỹ, có một số học thuyết về trách nhiệm bản quyền thứ cấp hoặc gián tiếp nhằm thực thi bản quyền trong các trường hợp không có vi phạm trực tiếp (Grossman, 2005; Lee et al., 2023). Việc áp dụng những học thuyết này phụ thuộc vào nhiều yếu tố, quan trọng nhất là việc liệu OpenAI có lợi ích bản quyền trong đầu ra của nó hay không. Nếu những học thuyết bản quyền này không áp dụng, thì vẫn có thể việc công bố bộ dữ liệu cấu thành vi phạm hợp đồng bởi các nhà phát triển bộ dữ liệu. Trong khi sẽ thách thức hơn cho OpenAI theo đuổi vụ án chống lại các bên thứ ba, có vô số những vi phạm kinh doanh khác, từ cạnh tranh không công bằng đến chiếm đoạt, có thể liên quan đến tình huống này, và vượt ra ngoài phạm vi của bài báo này (Marks and Moll, 2023). Thời gian sẽ cho biết mức độ mà OpenAI và các nhà cung cấp dịch vụ LLM khác có thể thực thi điều khoản sử dụng của họ chống lại các bên thứ ba. Tuy nhiên, một nhà nghiên cứu nổi bật tại Google đã từ chức với lý do lo ngại rằng đầu ra OpenAI được sử dụng để huấn luyện BARD (Victor and Efrati, 2023). Trong bối cảnh những mơ hồ pháp lý này, công cụ của chúng tôi cung cấp cho các nhà phát triển khả năng loại trừ các bộ dữ liệu được tạo ra bởi OpenAI.

Trong khi các vấn đề pháp lý vẫn mơ hồ, các nhà thực hành đang đưa ra quyết định về việc sử dụng dữ liệu và huấn luyện mô hình. Trước những bất định pháp lý lan rộng này, quyết định của các nhà thực hành về việc sử dụng dữ liệu cuối cùng được hướng dẫn bởi sự kết hợp của các yếu tố bao gồm các điều khoản cấp phép cụ thể, nguồn gốc của bộ dữ liệu, và mức độ sử dụng của một bộ dữ liệu nhất định bởi những người khác. Điều hướng cảnh quan này đòi hỏi việc cân bằng một cách tinh tế giữa giảm thiểu rủi ro và nhu cầu về tài nguyên đầy đủ. Phương trình này, tuy nhiên, thay đổi qua các khu vực, ứng dụng và môi trường doanh nghiệp, bị ảnh hưởng bởi các yếu tố như cạnh tranh, rủi ro và luật pháp khu vực. Một chiến lược để giảm thiểu một phần những bất định này là cho các nhà cung cấp mô hình bồi thường người dùng, như được thực hiện bởi Google Cloud Suggs and Venables (2023). Tuy nhiên, điều này có thể không khả thi đối với các nhà phát triển hạn chế tài nguyên và, trong khi nó bảo vệ người dùng cuối, nó không giải quyết các vấn đề mà các nhà phát triển mô hình hoặc người tuyển chọn bộ dữ liệu gặp phải.

Phương pháp của chúng tôi. Mục đích cơ bản của bản quyền là khuyến khích sáng tạo và đổi mới. Như chúng tôi đã làm nổi bật trong các phần trên, cảnh quan pháp lý hiện tại vẫn mơ hồ và sự thiếu rõ ràng này có thể kìm hãm đổi mới khi các nhà phát triển lo sợ hậu quả pháp lý. Thông qua cuộc kiểm toán và công cụ của chúng tôi, chúng tôi tìm cách cung cấp thông tin quan trọng cho các nhà thực hành để đưa ra quyết định có thông tin trong một cảnh quan mơ hồ khác, được hướng dẫn bởi diễn giải pháp lý và khả năng chịu đựng rủi ro của riêng họ. Thông tin này bao gồm dòng dõi giấy phép dữ liệu, một phân loại các điều khoản giấy phép, chi tiết về người tạo dữ liệu, và các nguồn dữ liệu cơ bản (ví dụ web hoặc LLM). Trong bối cảnh kiện tụng đang diễn ra và thiếu chắc chắn pháp lý, chúng tôi đã cố gắng cung cấp cho các nhà phát triển Trong việc tạo ra một kho lưu trữ thông tin cấp phép dữ liệu, chúng tôi cũng đang thực hiện một bước hướng tới việc khuyến khích các người tạo bộ dữ liệu suy nghĩ kỹ hơn về các giấy phép mà họ lựa chọn. Các người tạo bộ dữ liệu có vị trí tốt để hiểu việc sử dụng phù hợp của các bộ dữ liệu mà họ công bố và giấy phép có thể là một công cụ để truyền đạt những hạn chế này và khuyến khích phát triển AI có trách nhiệm. Chúng tôi tiếp tục nhằm làm nổi bật rằng các nhà thực hành học máy nên coi trọng các điều khoản giấy phép bộ dữ liệu một cách nghiêm túc, vì chúng có thể có tác động thực sự đến cách các mô hình của họ có thể được sử dụng trong thực tế. Cuối cùng, cấp phép dữ liệu chu đáo có thể được tận dụng để thúc đẩy các thực tiễn học máy có trách nhiệm, bao gồm và minh bạch hơn.

THÔNG BÁO: Thông tin Giấy phép Thu thập KHÔNG phải Lời khuyên Pháp lý. Điều quan trọng cần lưu ý là chúng tôi thu thập giấy phép tự báo cáo, và phân loại chúng theo nỗ lực tốt nhất của chúng tôi, như một sáng kiến nghiên cứu và minh bạch tình nguyện. Thông tin được cung cấp bởi bất kỳ công việc nào của chúng tôi và bất kỳ đầu ra nào của Sáng kiến Nguồn gốc Dữ liệu không, và không có ý định, cấu thành lời khuyên pháp lý; thay vào đó, tất cả thông tin, nội dung và tài liệu chỉ dành cho mục đích thông tin chung. Độc giả và người dùng nên tìm kiếm lời khuyên pháp lý riêng của họ từ tư vấn trong thẩm quyền liên quan của họ.

5 Công việc Liên quan

Tài liệu Dữ liệu Một dòng công việc dài đã làm nổi bật tầm quan trọng của dữ liệu và tài liệu của nó trong xử lý ngôn ngữ tự nhiên (Paullada et al., 2021; Rogers, 2021; Meyer et al., 2023; Gururangan et al., 2018; Muennighoff et al., 2023b). Đặc biệt, những công việc này nhấn mạnh những thách thức do tài liệu kém gây ra đối với khả năng tái tạo, khoa học tốt và hành vi mô hình được hiểu rõ nói chung (Sambasivan et al., 2021a; Bandy and Vincent, 2021; Longpre et al., 2023b). Công việc gần đây cũng đã khám phá tầm quan trọng của việc tài liệu hóa hệ sinh thái AI (Bommasani et al., 2023b) và chuỗi cung ứng từ dữ liệu đến mô hình (Cen et al., 2023).

Phân tích và Khám phá Dữ liệu Một số công việc đáng chú ý đã tiến hành phân tích quy mô lớn vào dữ liệu, đặc biệt là corpus văn bản tiền huấn luyện (Gao et al., 2020; Dodge et al., 2021; Kreutzer et al., 2022; Laurençon et al., 2022; Scao et al., 2022a,b; McMillan-Major et al., 2022). Các công việc khác đã điều tra sự đa dạng địa lý của các bộ dữ liệu dựa trên thị giác (Shankar et al., 2017; De Vries et al., 2019; Mahadev and Chakravarti, 2021). Các hình thức quản trị dữ liệu khác nhau đã được đề xuất để tập trung trách nhiệm và tài liệu hóa các bộ dữ liệu, bao gồm cho dự án BigScience (Jernite et al., 2022) và một Public Data Trust (Chan et al., 2023). Về mặt tìm kiếm và hình ảnh hóa bộ dữ liệu, một số công cụ gần đây đã được đề xuất (Färber and Leisinger, 2021; Viswanathan et al., 2023).

Tính minh bạch và trách nhiệm Kề cận với lĩnh vực hợp pháp, các công việc trước đây đã mạnh mẽ ủng hộ và cung cấp các khung cho tài liệu và kiểm toán để tăng tính minh bạch và trách nhiệm trong các hệ thống AI (Miceli et al., 2022; Kapoor et al., 2023; Raji and Buolamwini, 2022). Theo cách tương tự như DPI, rút ra từ kiến thức tập thể của các chuyên gia pháp lý và học máy, nghiên cứu trước đây cũng đã nhấn mạnh tầm quan trọng của hợp tác liên ngành (Hutchinson et al., 2021). Datasheet cho bộ dữ liệu Gebru et al. (2021) và Data Statement Bender and Friedman (2018) cả hai đều cung cấp các khung có cấu trúc để tiết lộ siêu dữ liệu thiết yếu như động lực đằng sau việc sử dụng dự định. Pushkarna et al. (2022) mở rộng về datasheet với "Data Card" cho nguồn, thu thập, đạo đức và áp dụng.

Tương tự, Mitchell et al. (2019) giới thiệu model card để đo lường hiệu suất mô hình qua các nhóm nhân khẩu học và tiết lộ các quy trình đánh giá. Crisan et al. (2022) đề xuất model card tương tác như một chế độ tài liệu thay thế và chia sẻ siêu dữ liệu. Bổ sung cho tính minh bạch về quá trình tạo ra bộ dữ liệu, Corry et al. (2021) cung cấp một khung hướng dẫn người dùng về cách điều hướng bộ dữ liệu khi chúng tiếp cận cuối chu kỳ sống của mình. DPI xây dựng trên các khung cơ bản được đặt ra trong những nghiên cứu sớm hơn này, với trọng tâm cụ thể vào việc giải quyết các khía cạnh cấp phép của việc tuyển chọn bộ dữ liệu. Mục tiêu của chúng tôi là trang bị cho người dùng hiểu biết toàn diện về các rủi ro pháp lý liên quan đến việc sử dụng bộ dữ liệu.

Tính hợp pháp bộ dữ liệu Tính hợp pháp của các bộ dữ liệu được sử dụng để huấn luyện các mô hình cơ sở lớn gần đây đã nhận được sự chú ý đáng kể (Sag, 2020; Henderson et al., 2023). Thách thức xác định tính hợp pháp của việc sử dụng các bộ dữ liệu khác nhau trở nên đặc biệt phức tạp do bản chất phức tạp của các quy trình tạo ra bộ dữ liệu. Lee et al. (2023) chia nhỏ các giai đoạn tạo ra bộ dữ liệu và tạo ra mô hình và đánh giá các câu hỏi bản quyền liên quan trong hệ thống pháp lý Mỹ. Những quy trình này thường bao gồm nhiều giấy phép và hạn chế có thể tương tác theo những cách che khuất rủi ro pháp lý cuối cùng. Soh (2021) đề xuất một khung cấp cao để xác định các khu vực trong việc tạo ra và sử dụng bộ dữ liệu nơi phân tích pháp lý là cần thiết, nhưng không áp dụng khung này cho bất kỳ bộ dữ liệu hiện có nào. Min et al. (2023) chứng minh rằng việc tránh huấn luyện trên các bộ dữ liệu có bản quyền hoặc bị hạn chế cao có tác động bất lợi đến hiệu suất xuôi dòng. Giải pháp được đề xuất của họ bao gồm việc sử dụng một mô hình ngôn ngữ được huấn luyện trên văn bản "rủi ro thấp" và tăng cường nó với một kho dữ liệu chứa văn bản "rủi ro cao" có thể được sửa đổi phù hợp khi cảnh quan pháp lý làm rõ theo thời gian. (Lee et al., 2023) DPI tăng cường những điều tra này bằng cách привлекать các chuyên gia pháp lý trong việc phát triển một khung để đánh giá "rủi ro" của bộ dữ liệu và chú thích "rủi ro" liên quan đến nhiều bộ dữ liệu hiện có có hồ sơ cao.

Lời cảm ơn

Chúng tôi xin cảm ơn Katherine Lee, A. Feder Cooper, Peter Henderson, Aviya Skowron và Stella Biderman vì những bình luận và phản hồi có giá trị.

Tài liệu tham khảo

[Phần tài liệu tham khảo được giữ nguyên vì đây là danh sách các trích dẫn học thuật]

Phụ lục

A Người đóng góp

Ở đây chúng tôi liệt kê những đóng góp của tác giả. Chúng tôi muốn nhấn mạnh rằng tất cả tác giả đều đóng góp những yếu tố quan trọng cho dự án này, và Người đóng góp Cốt lõi đặc biệt được ghi nhận với dịch vụ thực hành cho thiết kế và xây dựng triển khai đầu tiên của Data Provenance.

•Shayne Longpre Người đóng góp Cốt lõi. Nhà thiết kế và lập trình chính của kho lưu trữ và giao diện khám phá. Dẫn dắt triển khai kiểm toán, và phân tích, cũng như quy trình chú thích thủ công.

•Robert Mahari Người đóng góp Cốt lõi. Dẫn dắt phân tích pháp lý, và thiết kế chú thích cấp phép.

•Anthony Chen Người đóng góp Cốt lõi. Dẫn dắt suy luận tự động của các chỉ số văn bản bộ dữ liệu, chủ đề, và chú thích danh mục nhiệm vụ. Hỗ trợ viết, phân tích, và kiểm tra mã.

•Naana Obeng-Marnu Người đóng góp cốt lõi. Dẫn dắt thiết kế hình ảnh hóa, đặc biệt là hình ảnh hóa tương tác trong Data Provenance Explorer.

•Damien Sileo Người đóng góp cốt lõi. Dẫn dắt liên kết tổng hợp dữ liệu, và thu thập siêu dữ liệu. Hỗ trợ viết, phân tích, chú thích nguồn và thêm bộ dữ liệu.

•William Brannon Người đóng góp cốt lõi. Thêm 8 bộ sưu tập dữ liệu, hỗ trợ viết và phân tích dữ liệu.

•Niklas Muennighoff Người đóng góp cốt lõi. Thêm một số bộ sưu tập dữ liệu lớn, hỗ trợ viết, phân tích, hình ảnh hóa, và chú thích nguồn.

•Nathan Khazam Người đóng góp cốt lõi. Dẫn dắt nỗ lực chú thích cấp phép và hỗ trợ thêm bộ dữ liệu cùng với kiểm tra.

•Jad Kabbara Người đóng góp cốt lõi và cố vấn. Dẫn dắt nỗ lực chú thích nguồn văn bản và hỗ trợ với định khung, viết và phân tích.

•Kartik Perisetla Người đóng góp cốt lõi. Thêm một số bộ dữ liệu, hỗ trợ viết, phân tích, và chuẩn bị bộ dữ liệu cho Hugging Face.

•Xinyi (Alexis) Wu Người đóng góp cốt lõi. Thêm một số bộ dữ liệu, kiểm tra, và hỗ trợ thu thập siêu dữ liệu tự động.

•Enrico Shippole Người đóng góp cốt lõi. Dẫn dắt chuẩn bị bộ dữ liệu cuối cùng cho tải lên Hugging Face và kiểm tra.

•Kurt Bollacker Cố vấn về thiết kế và định khung dự án.

•Tongshuang Wu Cố vấn, đặc biệt về phân tích dữ liệu và hình ảnh hóa. Hỗ trợ viết và thiết kế Data Provenance Explorer.

•Luis Villa Cố vấn về bản quyền dữ liệu và cấp phép, và hỗ trợ viết trong phần thảo luận pháp lý.

•Sandy Pentland Cố vấn về thiết kế và định khung dự án tổng quát.

•Sara Hooker Cố vấn về thiết kế và định khung dự án tổng quát, cũng như hỗ trợ viết, phân tích, và chỉ đạo thí nghiệm.

B Giấy phép và Trích dẫn Chính xác

Xem Bảng 5 để tóm tắt giấy phép và trích dẫn Data Provenance Collection. Chi tiết toàn diện hơn có sẵn tại https://github.com/Data-Provenance-Initiative/Data-Provenance-Collection.

C Chi tiết về Thu thập Nguồn gốc Dữ liệu

Dữ liệu này được thu thập với sự kết hợp của các kỹ thuật thủ công và tự động, tận dụng các tổng hợp bộ dữ liệu như GitHub, HuggingFace và Semantic Scholar. Chú thích và xác minh thông tin giấy phép, đặc biệt, đòi hỏi một quy trình làm việc thủ công được hướng dẫn cẩn thận, được thiết kế với các chuyên gia pháp lý (xem Phần 2.2). Khi những tổng hợp thông tin này được kết nối, có thể tổng hợp hoặc thu thập siêu dữ liệu bổ sung, chẳng hạn như ngôn ngữ bộ dữ liệu, danh mục nhiệm vụ, và thời gian thu thập. Và để có chi tiết phong phú hơn về mỗi bộ dữ liệu, như chủ đề văn bản và nguồn, chúng tôi đã sử dụng các lời nhắc được điều chỉnh cẩn thận trên các mô hình ngôn ngữ kiểm tra từng bộ dữ liệu.

Phương pháp Chú thích Tự động Dựa trên các trang được lấy thủ công, chúng tôi tự động trích xuất Giấy phép từ cấu hình HuggingFace và trang GitHub. Chúng tôi tận dụng API công khai Semantic Scholar (Kinney et al., 2023) để lấy ngày phát hành và số lượng trích dẫn hiện tại liên quan đến các xuất bản học thuật. Ngoài ra, chúng tôi tính toán một loạt các thuộc tính dữ liệu hữu ích khác nhưng thường bị bỏ qua như chỉ số văn bản (min/mean/max cho độ dài đầu vào và mục tiêu), và lượt đối thoại. Chúng tôi đã chọn đo độ dài chuỗi bằng ký tự thay vì token từ, để xử lý công bằng hơn qua ngôn ngữ và chữ viết với sự khác biệt đã biết trong hiệu suất tokenizer qua các ngôn ngữ khác nhau (Petrov et al., 2023).

Phương pháp Chú thích API Trong khi Danh mục Nhiệm vụ đã trở thành phép đo được thiết lập của sự đa dạng dữ liệu trong công việc điều chỉnh hướng dẫn gần đây (Sanh et al., 2021; Wang et al., 2022a), có rất nhiều đặc tính phong phú khác mô tả sự đa dạng và đại diện dữ liệu. Để bổ sung điều này, chúng tôi sử dụng API GPT-4 của OpenAI để giúp chú thích cho các chủ đề văn bản. Chúng tôi lấy mẫu ngẫu nhiên 100 ví dụ mỗi bộ dữ liệu và nhắc GPT-4 cẩn thận để gợi ý tối đa 10 chủ đề được thảo luận trong văn bản.

Để chú thích cho các nguồn dữ liệu gốc, các chuyên gia AI (sinh viên tiến sĩ và nghiên cứu sinh sau tiến sĩ) đã xem xét các bài báo và điền các nguồn văn bản gốc, liệu máy móc hoặc tạo ra mẫu có được sử dụng cho việc tạo ra tổng hợp, và liệu người chú thích có được sử dụng hay không. GPT-4 được sử dụng như một bộ lấy trong bối cảnh trên bài báo ArXiv của bộ dữ liệu để trích xuất các đoạn mà các chuyên gia có thể đã bỏ lỡ. Chúng tôi chia bài báo ArXiv thành các khối 4000 ký tự và nhắc API trả về một danh sách json của bất kỳ đề cập nào về nguồn bộ dữ liệu, ví dụ từ thu thập, tổng hợp hoặc tạo ra thủ công.

[Bảng 5 được giữ nguyên vì chứa thông tin trích dẫn cụ thể]

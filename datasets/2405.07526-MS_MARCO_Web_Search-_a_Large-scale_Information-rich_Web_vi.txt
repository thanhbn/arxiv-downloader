MS MARCO Tìm kiếm Web: Tập dữ liệu Web quy mô lớn giàu thông tin với hàng triệu nhãn click thật

Qi Chen
Microsoft
Beijing, Trung Quốc

Xiubo Geng
Microsoft
Beijing, Trung Quốc

Corby Rosset
Microsoft
Redmond, Hoa Kỳ

Carolyn Buractaon
Microsoft
Redmond, Hoa Kỳ

Jingwen Lu
Microsoft
Redmond, Hoa Kỳ

Tao Shen∗
Đại học Công nghệ Sydney
Sydney, Úc

Kun Zhou
Microsoft
Beijing, Trung Quốc

Chenyan Xiong∗
Đại học Carnegie Mellon
Pittsburgh, Hoa Kỳ

Yeyun Gong
Microsoft
Beijing, Trung Quốc

Paul Bennett∗
Spotify
New York, Hoa Kỳ

Nick Craswell
Microsoft
Redmond, Hoa Kỳ

Xing Xie
Microsoft
Beijing, Trung Quốc

Fan Yang
Microsoft
Beijing, Trung Quốc

Bryan Tower
Microsoft
Redmond, Hoa Kỳ

Nikhil Rao
Microsoft
Mountain View, Hoa Kỳ

Anlei Dong†
Microsoft
Mountain View, Hoa Kỳ

Wenqi Jiang†
ETH Zürich
Zürich, Thụy Sĩ

Zheng Liu†
Microsoft
Beijing, Trung Quốc

Mingqin Li†
Microsoft
Redmond, Hoa Kỳ

Chuanjie Liu†
Microsoft
Beijing, Trung Quốc

Zengzhong Li†
Microsoft
Redmond, Hoa Kỳ

Rangan Majumder†
Microsoft
Redmond, Hoa Kỳ

Jennifer Neville†
Microsoft
Redmond, Hoa Kỳ

Andy Oakley†
Microsoft
Redmond, Hoa Kỳ

Knut Magne Risvik†
Microsoft
Oslo, Na Uy

Harsha Vardhan Simhadri†
Microsoft
Bengaluru, Ấn Độ

Manik Varma†
Microsoft
Bengaluru, Ấn Độ

Yujing Wang†
Microsoft
Beijing, Trung Quốc

Linjun Yang†
Microsoft
Redmond, Hoa Kỳ

Mao Yang†
Microsoft
Beijing, Trung Quốc

Ce Zhang∗†
ETH Zürich
Zürich, Thụy Sĩ

∗Công việc được thực hiện tại Microsoft.
†Tên tác giả được liệt kê theo thứ tự bảng chữ cái theo họ.

Được phép tạo bản sao kỹ thuật số hoặc bản cứng toàn bộ hoặc một phần của tác phẩm này để sử dụng cá nhân hoặc trong lớp học mà không mất phí với điều kiện các bản sao không được tạo ra hoặc phân phối vì lợi nhuận hoặc lợi thế thương mại và các bản sao phải ghi rõ thông báo này và trích dẫn đầy đủ trên trang đầu tiên. Bản quyền các thành phần của tác phẩm này thuộc sở hữu của người khác ngoài (các) tác giả phải được tôn trọng. Trích dẫn có ghi nguồn được cho phép. Để sao chép theo cách khác, hoặc tái xuất bản, đăng trên máy chủ hoặc tái phân phối cho danh sách, cần có sự cho phép cụ thể trước và/hoặc phí. Yêu cầu quyền từ permissions@acm.org.

WWW '24 Companion, 13–17 tháng 5, 2024, Singapore, Singapore
©2024 Bản quyền được giữ bởi chủ sở hữu/tác giả. Quyền xuất bản được cấp phép cho ACM.
ACM ISBN 979-8-4007-0172-6/24/05
https://doi.org/10.1145/3589335.3648327

arXiv:2405.07526v1 [cs.IR] 13 Tháng 5 2024

TÓM TẮT

Những đột phá gần đây trong các mô hình lớn đã nổi bật tầm quan trọng then chốt của quy mô dữ liệu, nhãn và phương thức. Trong bài báo này, chúng tôi giới thiệu MS MARCO Tìm kiếm Web, tập dữ liệu web giàu thông tin quy mô lớn đầu tiên, có hàng triệu nhãn truy vấn-tài liệu được click thực tế. Tập dữ liệu này mô phỏng chặt chẽ phân phối tài liệu web và truy vấn thực tế, cung cấp thông tin phong phú cho nhiều loại tác vụ downstream khác nhau và khuyến khích nghiên cứu trong nhiều lĩnh vực khác nhau, chẳng hạn như các mô hình indexer thần kinh end-to-end tổng quát, mô hình embedding tổng quát, và hệ thống truy cập thông tin thế hệ tiếp theo với mô hình ngôn ngữ lớn. MS MARCO Tìm kiếm Web cung cấp một benchmark truy xuất với ba tác vụ thách thức truy xuất web đòi hỏi những cải tiến trong cả lĩnh vực nghiên cứu học máy và hệ thống truy xuất thông tin. Là tập dữ liệu đầu tiên đáp ứng các yêu cầu dữ liệu lớn, thật và phong phú, MS MARCO Tìm kiếm Web mở đường cho những tiến bộ trong tương lai trong nghiên cứu AI và hệ thống. Tập dữ liệu MS MARCO Tìm kiếm Web có sẵn tại: https://github.com/microsoft/MS-MARCO-Web-Search.

KHÁI NIỆM CCS
• Hệ thống thông tin → Đánh giá mức độ liên quan.

TỪ KHÓA
tập dữ liệu; truy xuất thông tin; tìm kiếm web

Định dạng Tham chiếu ACM:
Qi Chen, Xiubo Geng, Corby Rosset, Carolyn Buractaon, Jingwen Lu, Tao Shen, Kun Zhou, Chenyan Xiong∗, Yeyun Gong, Paul Bennett∗, Nick Craswell, Xing Xie, Fan Yang, Bryan Tower, Nikhil Rao, Anlei Dong, Wenqi Jiang†, Zheng Liu†, Mingqin Li†, Chuanjie Liu†, Zengzhong Li†, Rangan Majumder†, Jennifer Neville†, Andy Oakley†, Knut Magne Risvik†, Harsha Vardhan Simhadri†, Manik Varma†, Yujing Wang†, Linjun Yang†, Mao Yang†, và Ce Zhang∗†. 2024. MS MARCO Tìm kiếm Web: Tập dữ liệu Web quy mô lớn giàu thông tin với hàng triệu nhãn click thật. Trong Kỷ yếu Hội thảo của Hội nghị Web ACM 2024 (WWW '24 Companion), 13–17 tháng 5, 2024, Singapore, Singapore. ACM, New York, NY, USA, 10 trang. https://doi.org/10.1145/3589335.3648327

1 GIỚI THIỆU

Gần đây, mô hình ngôn ngữ lớn (LLM), một đột phá trong lĩnh vực trí tuệ nhân tạo, đã cung cấp một cách thức mới để con người tiếp cận thông tin thông qua giao tiếp tương tác. Mặc dù nó đã trở thành một công cụ không thể thiếu cho các tác vụ như tạo nội dung, hiểu ngữ nghĩa và AI đối thoại, nó vẫn thể hiện một số hạn chế nhất định. Một hạn chế như vậy là xu hướng của mô hình tạo ra nội dung ảo giác hoặc bịa đặt, vì nó tạo ra phản hồi dựa trên các mẫu được quan sát trong dữ liệu huấn luyện thay vì xác minh tính chính xác của sự thật. Hơn nữa, nó gặp khó khăn với việc cập nhật kiến thức thời gian thực, vì nó chỉ có thể cung cấp thông tin có sẵn cho đến thời điểm huấn luyện cuối cùng của nó. Điều này làm cho nó kém đáng tin cậy hơn trong việc truy xuất thông tin động, mới nhất. Do đó, việc tích hợp một cơ sở kiến thức bên ngoài cập nhật với các mô hình ngôn ngữ lớn là vô cùng quan trọng để nâng cao hiệu suất và độ tin cậy của chúng. Sự kết hợp này không chỉ giảm thiểu các hạn chế của ảo giác và cập nhật kiến thức mà còn mở rộng khả năng ứng dụng của mô hình trên nhiều lĩnh vực khác nhau, làm cho nó trở nên linh hoạt và có giá trị hơn. Do đó, các hệ thống truy xuất thông tin, như công cụ tìm kiếm Bing [32], tiếp tục đóng vai trò quan trọng trong các hệ thống thông tin mới dựa trên LLM, chẳng hạn như Webgpt [34] và Bing mới [33].

Đối với các hệ thống truy xuất thông tin hiện đại, cốt lõi là mô hình hiểu ngữ nghĩa lớn, chẳng hạn như mô hình indexer thần kinh [51] hoặc mô hình embedding kép [16,20,21,38–40,45,46,54], có thể nắm bắt ý định của người dùng cũng như ý nghĩa phong phú của tài liệu với khả năng chịu đựng tốt hơn đối với các từ ngoài từ vựng, lỗi chính tả và các biểu thức đồng nghĩa. Huấn luyện một mô hình hiểu ngữ nghĩa lớn chất lượng cao đòi hỏi một lượng dữ liệu khổng lồ để đạt được phạm vi kiến thức đầy đủ. Tập dữ liệu càng lớn, mô hình càng có khả năng hoạt động tốt hơn, vì mô hình có thể học các mẫu và mối tương quan phức tạp và tinh vi hơn.

Dữ liệu được gán nhãn bởi con người chất lượng cao cũng quan trọng như quy mô dữ liệu. Nghiên cứu gần đây, chẳng hạn như InstructGPT [36] và LLAMA-2 [50], đã chứng minh vai trò quan trọng của dữ liệu được gán nhãn cho việc huấn luyện các mô hình nền tảng lớn. Những mô hình này dựa vào khối lượng lớn dữ liệu huấn luyện để học các đặc trưng có thể tổng quát hóa, trong khi dữ liệu được gán nhãn bởi con người cho phép mô hình học các tác vụ cụ thể mà nó được thiết kế để thực hiện. Điều này cũng áp dụng cho các mô hình hiểu ngữ nghĩa lớn.

Hơn nữa, dữ liệu giàu thông tin cũng rất quan trọng để huấn luyện các mô hình hiểu ngữ nghĩa lớn một cách hiệu quả. Việc sử dụng các tập dữ liệu đa phương thức có thể giúp mô hình hiểu mối quan hệ phức tạp giữa các loại dữ liệu khác nhau và chuyển giao kiến thức giữa chúng. Ví dụ, sử dụng hình ảnh và văn bản trong tập dữ liệu đa phương thức có thể giúp mô hình học về các khái niệm hình ảnh và các mô tả văn bản tương ứng của chúng, cung cấp một biểu diễn tổng thể hơn về dữ liệu.

Các yêu cầu dữ liệu lớn, thật và phong phú đang nổi lên thúc đẩy chúng tôi tạo ra một tập dữ liệu MS MARCO Tìm kiếm Web mới, tập dữ liệu web giàu thông tin quy mô lớn đầu tiên với hàng triệu nhãn truy vấn-tài liệu được click thực tế. MS MARCO Tìm kiếm Web kết hợp tập dữ liệu tài liệu web mở lớn nhất, ClueWeb22 [37], làm corpus tài liệu của chúng tôi. ClueWeb22 bao gồm khoảng 10 tỷ trang web chất lượng cao, đủ lớn để phục vụ như dữ liệu đại diện cho quy mô web. Nó cũng chứa thông tin phong phú từ các trang web, chẳng hạn như biểu diễn trực quan được render bởi trình duyệt web, cấu trúc HTML thô, văn bản sạch, chú thích ngữ nghĩa, thẻ ngôn ngữ và chủ đề được gán nhãn bởi các hệ thống hiểu tài liệu công nghiệp, v.v. MS MARCO Tìm kiếm Web hơn nữa chứa 10 triệu truy vấn duy nhất từ 93 ngôn ngữ với hàng triệu cặp truy vấn-tài liệu có liên quan được gán nhãn được thu thập từ nhật ký tìm kiếm của công cụ tìm kiếm Microsoft Bing để phục vụ như tập truy vấn. Bộ sưu tập lớn này gồm các tài liệu web thực tế đa ngôn ngữ giàu thông tin, truy vấn và các cặp truy vấn-tài liệu được gán nhãn cho phép nhiều loại tác vụ downstream khác nhau và khuyến khích một số hướng nghiên cứu mới mà các tập dữ liệu trước đây không thể hỗ trợ tốt, ví dụ như các mô hình indexer thần kinh end-to-end tổng quát, mô hình embedding tổng quát, và hệ thống truy cập thông tin thế hệ tiếp theo với mô hình ngôn ngữ lớn, v.v. Là tập dữ liệu web lớn, thật và phong phú đầu tiên, MS MARCO Tìm kiếm Web sẽ phục vụ như một nền tảng dữ liệu quan trọng cho nghiên cứu AI và hệ thống trong tương lai.

MS MARCO Tìm kiếm Web cung cấp một benchmark truy xuất thực hiện một số mô hình embedding tiên tiến, thuật toán truy xuất, và hệ thống truy xuất được phát triển ban đầu trên các tập dữ liệu hiện có. Chúng tôi so sánh chất lượng kết quả và hiệu suất hệ thống của chúng trên tập dữ liệu MS MARCO Tìm kiếm Web mới của chúng tôi làm đường cơ sở benchmark cho truy xuất thông tin quy mô web. Kết quả thí nghiệm chứng minh rằng các mô hình embedding, thuật toán truy xuất, và hệ thống truy xuất đều là các thành phần quan trọng trong truy xuất thông tin web. Và thú vị là, chỉ cải thiện một thành phần có thể mang lại tác động tiêu cực đến chất lượng kết quả truy xuất end-to-end và hiệu suất hệ thống. Chúng tôi hy vọng benchmark truy xuất này có thể tạo điều kiện cho những cải tiến trong tương lai trong các kỹ thuật dữ liệu-trung tâm, mô hình embedding, thuật toán truy xuất, và hệ thống truy xuất để tối đa hóa hiệu suất end-to-end.

2 BỐI CẢNH VÀ CÔNG VIỆC LIÊN QUAN

2.1 Truy xuất Thông tin Quy mô Web

Trong truy xuất thông tin truyền thống, các truy vấn của người dùng và tài liệu được biểu diễn như một danh sách các từ khóa, và việc truy xuất được thực hiện dựa trên việc khớp từ khóa. Tuy nhiên, việc khớp từ khóa đơn giản gặp phải nhiều thách thức. Đầu tiên, nó không thể hiểu rõ ý định của người dùng. Đặc biệt, nó không thể ước tính tình cảm tích cực và tiêu cực của người dùng và có thể trả về kết quả ngược lại do nhầm lẫn. Thứ hai, nó không thể kết hợp các biểu thức đồng nghĩa, làm giảm sự đa dạng của kết quả [18]. Thứ ba, nó không thể xử lý lỗi chính tả và sẽ trả về kết quả không liên quan. Do đó, việc thay đổi truy vấn được sử dụng để giải quyết các thách thức trên. Thật không may, rất khó để bao phủ tất cả các loại thay đổi truy vấn, đặc biệt là những thay đổi mới xuất hiện.

Với thành công lớn của deep learning trong xử lý ngôn ngữ tự nhiên, cả truy vấn và tài liệu đều có thể được biểu diễn một cách có ý nghĩa hơn dưới dạng các vector embedding ngữ nghĩa. Vì truy xuất dựa trên embedding giải quyết ba thách thức trên, nó đã được sử dụng rộng rãi trong các hệ thống thông tin hiện đại để tạo điều kiện cho chất lượng và hiệu suất truy xuất tiên tiến mới. Nhiều nghiên cứu trước đây đã tập trung vào các mô hình embedding sâu, từ DSSM [21], CDSSM [46], LSTM-RNN [38], và ARC-I [20] đến các mô hình embedding dựa trên transformer [10,16,39,40,45,53,54]. Chúng đã cho thấy những cải tiến ấn tượng với tìm kiếm embedding láng giềng gần nhất brute-force trên một số tập dữ liệu nhỏ so với việc khớp từ khóa truyền thống.

Do chi phí tính toán cực cao và độ trễ truy vấn của tìm kiếm vector brute-force, có nhiều phương pháp nghiên cứu tập trung vào các thuật toán và thiết kế hệ thống tìm kiếm láng giềng gần nhất vector xấp xỉ quy mô lớn (ANN) [5–7,11,19,24–26,26,41,48]. Chúng có thể được chia thành các giải pháp dựa trên phân vùng và dựa trên đồ thị. Các giải pháp dựa trên phân vùng, chẳng hạn như SPANN [11], chia toàn bộ không gian vector thành một số lượng lớn các cụm và chỉ thực hiện tìm kiếm tinh vi trên một số lượng nhỏ các cụm gần nhất với truy vấn trong tìm kiếm trực tuyến. Các giải pháp dựa trên đồ thị, chẳng hạn như DiskANN [48], xây dựng một đồ thị láng giềng cho toàn bộ tập dữ liệu và thực hiện duyệt tốt nhất từ một số điểm bắt đầu cố định khi một truy vấn đến. Cả hai phương pháp này đều hoạt động tốt trên một số tập dữ liệu phân phối đồng nhất.

Thật không may, khi áp dụng truy xuất dựa trên embedding trong kịch bản web, một số thách thức mới xuất hiện. Đầu tiên, khối lượng dữ liệu quy mô web đòi hỏi các mô hình lớn, số chiều embedding cao và một tập dữ liệu huấn luyện có gán nhãn quy mô lớn để đảm bảo phạm vi kiến thức đầy đủ. Thứ hai, lợi ích hiệu suất của các mô hình embedding tiên tiến được xác minh trên các tập dữ liệu nhỏ không thể được chuyển giao trực tiếp sang tập dữ liệu quy mô web (xem mục 4.4). Thứ ba, các mô hình embedding cần phải làm việc cùng với các hệ thống ANN để phục vụ khối lượng dữ liệu quy mô lớn một cách hiệu quả. Tuy nhiên, các phân phối dữ liệu huấn luyện khác nhau có thể ảnh hưởng đến độ chính xác và hiệu suất hệ thống của một thuật toán ANN, điều này sẽ làm giảm đáng kể độ chính xác kết quả so với các mô hình embedding với tìm kiếm brute-force. Distill-VQ [52] đã xác minh rằng mô hình embedding CoCondenser [17] với chỉ mục ANN Faiss-IVFPQ đạt được độ chính xác kết quả khác nhau trên các tập dữ liệu MSMarco [35] và NQ [28]. Hơn nữa, ngay cả phân phối dữ liệu huấn luyện giống nhau cũng sẽ dẫn đến các phân phối vector embedding khác nhau, điều này sẽ dẫn đến các xu hướng xếp hạng khác nhau của các mô hình embedding trong tìm kiếm brute-force (KNN) và tìm kiếm láng giềng gần nhất xấp xỉ (ANN) (xem mục 4.6).

2.2 Tập dữ liệu Hiện có

Để khuyến khích đổi mới trong lĩnh vực truy xuất thông tin, cộng đồng đã thu thập một số tập dữ liệu để đánh giá chuẩn công khai (được tóm tắt trong Bảng 1).

Có nhiều tập dữ liệu web công khai cho các tác vụ truy xuất thông tin truyền thống, chẳng hạn như Robust04 [3], ClueWeb09 [13], ClueWeb12 [9], GOV2 [12], ClueWeb22 [37] và Common Crawl [2]. Thật không may, những tập dữ liệu này có nhiều nhất là hàng trăm truy vấn được gán nhãn, còn xa mới đủ để học một mô hình truy xuất được cải tiến bởi deep learning tốt.

Gần đây, một số tập dữ liệu mới đã được xuất bản để nghiên cứu về truy xuất được cải tiến bởi deep learning [28,35,43]. MS MARCO [35] là một trong những tập dữ liệu phổ biến nhất để nghiên cứu mô hình embedding. Nó cung cấp 100K câu hỏi được thu thập từ các câu hỏi tìm kiếm của Bing được ghép nối với các câu trả lời được tạo bởi con người được đưa vào ngữ cảnh trong các tài liệu web. MS MARCO Ranking v2 [47] mở rộng kích thước của tập tài liệu và câu hỏi lên 11 triệu và 1 triệu tương ứng. ORCAS [14] cung cấp 10 triệu truy vấn duy nhất và 18 triệu cặp truy vấn-tài liệu được click cho các tài liệu MS MARCO. Natural Questions [28], một tập dữ liệu trả lời câu hỏi quy mô dưới triệu được thu thập từ các truy vấn tìm kiếm của Google với các câu trả lời được chú thích bởi con người trong các bài viết Wikipedia, đã được tái sử dụng cho truy xuất dựa trên embedding bằng cách trích xuất các đoạn văn từ Wikipedia làm câu trả lời ứng viên [27]. CLIR [43], một tập dữ liệu truy xuất thông tin đa ngôn ngữ quy mô triệu được thu thập từ Wikipedia, đã được sử dụng để huấn luyện các mô hình embedding đa ngôn ngữ [55]. Tuy nhiên, không có tập dữ liệu nào trong số này đáp ứng các yêu cầu lớn, thật và phong phú đang nổi lên. Những tập dữ liệu này tập trung vào các tác vụ trả lời câu hỏi chỉ bằng tiếng Anh. Không có tập dữ liệu nào trong số chúng có dữ liệu quy mô web mong muốn với các truy vấn đa ngôn ngữ có độ lệch cao có thể ngắn, mơ hồ và thường không được công thức hóa dưới dạng câu hỏi ngôn ngữ tự nhiên. Hơn nữa, chúng chỉ cung cấp văn bản thô của các truy vấn và câu trả lời, điều này hạn chế tiềm năng của nghiên cứu chuyển giao kiến thức đa phương thức trong tương lai. Cuối cùng, chúng chỉ tập trung vào việc đánh giá chất lượng của các mô hình embedding sử dụng tìm kiếm brute-force, điều này không thể phản ánh các thách thức truy xuất end-to-end.

ANN benchmark [4] và Billion-scale ANN benchmark [1] cung cấp nhiều tập dữ liệu vector chiều cao để đánh giá độ chính xác kết quả và hiệu suất hệ thống cho các thuật toán truy xuất dựa trên embedding. Thật không may, chúng không thể đo lường chất lượng mô hình và do đó không thể phản ánh hiệu suất truy xuất end-to-end.

Do đó, một tập dữ liệu web giàu thông tin quy mô lớn với phân phối tài liệu và truy vấn thực tế có thể phản ánh các thách thức thực tế vẫn còn thiếu.

3 TẬP DỮ LIỆU MS MARCO TÌM KIẾM WEB

Trong bài báo này, chúng tôi trình bày MS MARCO Tìm kiếm Web, một tập dữ liệu quy mô lớn để nghiên cứu về truy xuất thông tin web. Tập dữ liệu MS MARCO Tìm kiếm Web bao gồm một tập hợp chất lượng cao các trang web phản ánh phân phối tài liệu web có độ lệch cao, một tập truy vấn phản ánh phân phối truy vấn web thực tế, và một tập nhãn truy vấn-tài liệu quy mô lớn để huấn luyện và đánh giá mô hình embedding.

3.1 Chuẩn bị Tài liệu

Chúng tôi sử dụng ClueWeb22 [9] làm tập tài liệu của chúng tôi vì nó là tập dữ liệu tài liệu web mở lớn nhất và mới nhất cho mục đích của chúng tôi. Nó đáp ứng các yêu cầu về quy mô lớn, chất lượng cao và phân phối tài liệu thực tế được thu thập và xử lý bởi một công cụ tìm kiếm web thương mại với thông tin phong phú. So với Common Crawl [2] chỉ thu thập dữ liệu từ 35 triệu tên miền đã đăng ký và bao phủ 40+ ngôn ngữ, ClueWeb22 mô phỏng chặt chẽ việc lựa chọn thu thập thực tế của một công cụ tìm kiếm thương mại với 207 ngôn ngữ. Nó có 10 tỷ trang web chất lượng cao với thông tin liên kết phong phú, chẳng hạn như url, thẻ ngôn ngữ, thẻ chủ đề, tiêu đề và văn bản sạch, v.v. Hình 2 (d) đưa ra một ví dụ về các cấu trúc dữ liệu được cung cấp bởi ClueWeb22.

Để làm cho việc huấn luyện hiệu quả về chi phí cho cả học viện và công nghiệp, chúng tôi cung cấp một tập 100 triệu và một tập 10 tỷ tài liệu. Tập 100 triệu tài liệu là một tập con ngẫu nhiên của tập 10 tỷ tài liệu. Để đánh giá khả năng tổng quát hóa của mô hình trong tập dữ liệu quy mô nhỏ, hai tập 100 triệu tài liệu không trùng lặp được cung cấp, một để huấn luyện và một để kiểm tra. Toàn bộ quá trình được thể hiện trong phần bên trái của hình 1.

3.2 Lựa chọn và Gán nhãn Truy vấn

Để tạo ra các truy vấn quy mô lớn chất lượng cao và nhãn mức độ liên quan truy vấn-tài liệu, chúng tôi lấy mẫu các click truy vấn-tài liệu từ một năm nhật ký của công cụ tìm kiếm Bing. Tập truy vấn ban đầu được lọc để loại bỏ các truy vấn hiếm khi được kích hoạt, chứa thông tin nhận dạng cá nhân, nội dung xúc phạm, nội dung người lớn và những truy vấn không có kết nối click với tập tài liệu ClueWeb22. Tập kết quả bao gồm các truy vấn được kích hoạt bởi nhiều người dùng, phản ánh phân phối truy vấn thực tế của một công cụ tìm kiếm web thương mại.

Các truy vấn được chia thành tập huấn luyện và kiểm tra dựa trên thời gian, điều này tương tự như các kịch bản web thực tế huấn luyện một mô hình embedding sử dụng dữ liệu trong quá khứ và phục vụ các trang web và truy vấn mới trong tương lai. Chúng tôi lấy mẫu khoảng 10 triệu cặp truy vấn-tài liệu từ tập huấn luyện và 10 nghìn cặp truy vấn-tài liệu từ tập kiểm tra. Các tài liệu trong tập huấn luyện và kiểm tra truy vấn-tài liệu sau đó được hợp nhất vào tập 100 triệu tài liệu huấn luyện và tập tài liệu kiểm tra tương ứng (được thể hiện trong phần bên phải của hình 1). Để cho phép xác minh chất lượng của mô hình trong quá trình huấn luyện, chúng tôi tách một tập truy vấn-tài liệu dev từ tập truy vấn-tài liệu huấn luyện. Vì tập huấn luyện và dev chia sẻ cùng một tập tài liệu, tập dev có thể được sử dụng để nhanh chóng xác minh tính đúng đắn của việc huấn luyện và chất lượng mô hình trong quá trình huấn luyện. Đối với tập dữ liệu 10B, chúng tôi sử dụng cùng các truy vấn huấn luyện, dev và kiểm tra nhưng lấy mẫu nhiều cặp truy vấn-tài liệu hơn.

3.3 Phân tích Tập dữ liệu

Chúng tôi đã xây dựng hai quy mô của tập dữ liệu: Set-100M và Set-10B. Bảng 2 đưa ra thống kê chi tiết của các tập dữ liệu. Các tệp ví dụ của MS MARCO Tìm kiếm Web Set-100M được thể hiện trong hình 2.

3.3.1 Phân tích Phân phối Ngôn ngữ. MS MARCO Tìm kiếm Web là một tập dữ liệu đa ngôn ngữ với các truy vấn và tài liệu của nó đều từ một công cụ tìm kiếm web thương mại. Chúng tôi phân tích 20 ngôn ngữ phổ biến nhất trong số 93 và 207 ngôn ngữ trong cả truy vấn và tài liệu trong tập dữ liệu 100M tương ứng; tập dữ liệu 10B có phân phối tương tự. Hình 3 tóm tắt phân phối ngôn ngữ tài liệu trong tập tài liệu huấn luyện và kiểm tra. Chúng ta có thể thấy rằng cả tập tài liệu huấn luyện và kiểm tra đều phù hợp với phân phối tài liệu ClueWeb22 ban đầu. Hình 4 tóm tắt phân phối ngôn ngữ truy vấn trong tập truy vấn huấn luyện, dev và kiểm tra. Từ phân phối, chúng ta có thể thấy rằng phân phối ngôn ngữ của các truy vấn trong kịch bản web có độ lệch cao có thể dẫn đến sai lệch mô hình. Nó khuyến khích nghiên cứu về các kỹ thuật dữ liệu-trung tâm để tối ưu hóa dữ liệu huấn luyện.

3.3.2 Phân tích Độ lệch Dữ liệu. Chúng tôi phân tích phân phối nhãn truy vấn-tài liệu trong dữ liệu huấn luyện. Hình 5(a) cho thấy các tài liệu và số lượng truy vấn liên quan được liên kết với chúng. Từ hình, chúng ta có thể thấy rằng chỉ có một số ít tài liệu có nhiều nhãn: chỉ có 7,77% tài liệu có truy vấn liên quan được gán nhãn và 0,46% tài liệu có hơn một truy vấn liên quan được gán nhãn. Hình 5(b) tóm tắt các truy vấn và tài liệu liên quan của chúng. Từ hình, chúng ta có thể thấy rằng chỉ có 1,4% truy vấn có nhiều tài liệu liên quan. Bản chất có độ lệch cao này của tập dữ liệu phù hợp với những gì được quan sát trong khi huấn luyện mô hình cho truy xuất thông tin quy mô web. Ý định của chúng tôi là giữ độ lệch này để làm cho các mô hình được huấn luyện trên tập dữ liệu này có thể áp dụng cho các kịch bản thực tế.

3.3.3 Phân tích Chồng lấp Test-Train. Như được giới thiệu trong [30], tồn tại sự chồng lấp test-train lớn trong một số tập dữ liệu QA miền mở phổ biến, điều này khiến nhiều mô hình miền mở phổ biến chỉ đơn giản là ghi nhớ các truy vấn đã thấy ở giai đoạn huấn luyện. Sau đó, chúng hoạt động kém hơn trên các truy vấn mới. Công việc [56] quan sát hiện tượng này trong tập dữ liệu MSMARCO. Để đánh giá tốt hơn khả năng tổng quát hóa của mô hình, chúng tôi giảm thiểu sự chồng lấp giữa tập huấn luyện và kiểm tra bằng cách chia các cặp truy vấn-tài liệu thành tập huấn luyện và kiểm tra theo thời gian. Điều này có nghĩa là các cặp truy vấn-tài liệu kiểm tra không có sự chồng lấp thời gian với các cặp truy vấn-tài liệu huấn luyện, điều này giới thiệu một tỷ lệ lớn các truy vấn mới. Điều này có thể được xác minh trong bảng 3.

Chúng tôi tóm tắt các cặp truy vấn-tài liệu kiểm tra thành bốn danh mục:
• Q∈Train, D∈Train: Cả truy vấn và tài liệu đều đã xuất hiện trong tập huấn luyện,
• Q∉Train, D∈Train: Truy vấn chưa được thấy trong tập huấn luyện, nhưng tài liệu liên quan đã được thấy trong tập huấn luyện,
• Q∈Train, D∉Train: Truy vấn đã được thấy trong tập huấn luyện, nhưng tài liệu là một trang web mới chưa được thấy trong tập huấn luyện,
• Q∉Train, D∉Train: Cả truy vấn và tài liệu đều là nội dung mới chưa bao giờ được thấy trong tập huấn luyện.

Chúng ta có thể thấy từ bảng 3 rằng 82% cặp truy vấn-tài liệu là nội dung mới trong tập kiểm tra chưa được thấy trong tập huấn luyện. Do đó, tập dữ liệu MS MARCO Tìm kiếm Web có khả năng cung cấp đánh giá hiệu quả về các mô hình dựa trên khả năng ghi nhớ và khả năng tổng quát hóa bằng cách chia tập kiểm tra thành bốn danh mục để so sánh chi tiết hơn.

3.4 Thách thức Mới được Đưa ra bởi MS MARCO Tìm kiếm Web

Dựa trên các tập dữ liệu MS MARCO Tìm kiếm Web, chúng tôi đưa ra ba tác vụ thách thức trong thiết kế mô hình embedding lớn và hệ thống truy xuất.

3.4.1 Thách thức Mô hình Embedding Quy mô lớn. Như đã giới thiệu trước đây, khối lượng dữ liệu web quy mô lớn đòi hỏi các mô hình embedding lớn để đảm bảo phạm vi kiến thức đầy đủ. Nó đòi hỏi cân bằng hai mục tiêu sau: khả năng tổng quát hóa mô hình tốt và tốc độ huấn luyện/suy luận hiệu quả.

3.4.2 Thách thức Thuật toán Truy xuất Embedding. Các mô hình embedding cần phải làm việc cùng với hệ thống truy xuất embedding để phục vụ tập dữ liệu quy mô web. Trong thách thức này, chúng tôi lấy các vector embedding được tạo bởi mô hình baseline tốt nhất của chúng tôi làm tập vector ANN. Mục tiêu của thách thức này là kêu gọi những cải tiến thuật toán ANN để giảm thiểu khoảng cách độ chính xác giữa tìm kiếm xấp xỉ và tìm kiếm brute-force trong khi vẫn duy trì hiệu suất hệ thống tốt.

3.4.3 Thách thức Hệ thống Truy xuất End-to-end. Trong kịch bản web, chất lượng kết quả và hiệu suất hệ thống của hệ thống truy xuất end-to-end là các chỉ số quan trọng nhất trong việc so sánh các giải pháp khác nhau. Tác vụ thách thức này khuyến khích bất kỳ loại giải pháp nào, bao gồm mô hình embedding cộng với hệ thống ANN [31], giải pháp chỉ mục đảo ngược [8,15,58], giải pháp kết hợp [18,29,44], indexer thần kinh [49,51], và mô hình ngôn ngữ lớn [50], v.v.

4 KẾT QUẢ BENCHMARK

Trong phần này, chúng tôi cung cấp kết quả benchmark ban đầu cho một số mô hình embedding tiên tiến, thuật toán ANN và hệ thống truy xuất phổ biến trên tập dữ liệu MS MARCO Tìm kiếm Web 100M làm đường cơ sở. Đối với tập dữ liệu 10B, chúng tôi để lại để khám phá mở.

4.1 Thiết lập Môi trường

Chúng tôi sử dụng Azure Standard_ND96asr_v4 Virtual Machine cho việc huấn luyện mô hình và kiểm tra hiệu suất. Nó chứa 96 lõi vCPU, 900 GB bộ nhớ, 8 GPU A100 40GB với NVLink 3.0.

4.2 Phương pháp Baseline

4.2.1 Mô hình Embedding Tiên tiến. Chúng tôi lấy ba mô hình đa ngôn ngữ tiên tiến sau làm mô hình baseline ban đầu:
• DPR [27] dựa trên mô hình được huấn luyện trước BERT và kiến trúc dual-encoder, embedding của nó được tối ưu hóa để tối đa hóa điểm số tích vô hướng của một truy vấn và đoạn văn liên quan của nó. Các ví dụ huấn luyện tiêu cực được chọn bởi các tài liệu được truy xuất bởi BM25.
• ANCE [54] cải thiện hiệu suất truy xuất dựa trên embedding bằng cách chọn các ví dụ huấn luyện tiêu cực khó từ toàn bộ tập tài liệu sử dụng chỉ mục láng giềng gần nhất xấp xỉ được cập nhật bất đồng bộ.
• SimANS [57] tránh việc chỉ mục hóa quá mức trên các negative giả bằng cách chọn các mẫu mơ hồ thay vì những mẫu khó nhất.

Chúng tôi khao khát tập dữ liệu MS MARCO Tìm kiếm Web tự thiết lập như một benchmark tiêu chuẩn mới cho truy xuất, lôi kéo nhiều mô hình baseline hơn để đánh giá và thí nghiệm với nó.

4.2.2 Thuật toán ANN Tiên tiến. Đối với các thuật toán truy xuất embedding, chúng tôi chọn các thuật toán ANN dựa trên đĩa tiên tiến DiskANN [22] và SPANN [11] làm baseline. DiskANN là thuật toán ANN dựa trên đĩa đầu tiên có thể phục vụ hiệu quả tìm kiếm vector quy mô tỷ với chi phí tài nguyên thấp. Nó áp dụng giải pháp đồ thị láng giềng lưu trữ đồ thị và các vector độ chính xác đầy đủ trên đĩa, trong khi đưa các vector nén (ví dụ, thông qua Product Quantization [23]) và một số điểm pivot vào bộ nhớ. Trong quá trình tìm kiếm, một truy vấn tuân theo nguyên tắc duyệt tốt nhất để bắt đầu tìm kiếm từ một điểm cố định trong đồ thị.

SPANN áp dụng kỹ thuật phân cụm cân bằng phân cấp để phân vùng nhanh toàn bộ tập dữ liệu thành một số lượng lớn các danh sách đăng được giữ trong đĩa. Nó chỉ lưu trữ các tâm của các danh sách đăng trong bộ nhớ. Để tăng tốc tìm kiếm, SPANN tận dụng chỉ mục bộ nhớ để điều hướng nhanh truy vấn đến các tâm gần nhất, và sau đó tải các danh sách đăng tương ứng từ đĩa vào bộ nhớ để tìm kiếm tinh vi hơn. Với một số kỹ thuật như mở rộng đăng với ràng buộc độ dài tối đa, sao chép vector biên giới và tỉa động nhận biết truy vấn, nó đạt được hiệu suất tiên tiến trong nhiều tập dữ liệu quy mô tỷ về chi phí bộ nhớ, chất lượng kết quả và độ trễ tìm kiếm.

4.2.3 Hệ thống Truy xuất End-to-end. BM25 [42] là hàm xếp hạng được sử dụng rộng rãi nhất trong lĩnh vực truy xuất thông tin web để ước tính điểm số mức độ liên quan của một tài liệu cho một truy vấn. Nó xếp hạng một tập hợp tài liệu dựa trên khung truy xuất xác suất và đã được tích hợp vào hệ thống Elasticsearch để phục vụ tất cả các loại kịch bản tìm kiếm.

4.3 Chỉ số Đánh giá

Chúng tôi đánh giá tất cả các baseline trên cả khía cạnh chất lượng kết quả và hiệu suất hệ thống. Đối với chất lượng kết quả, chúng tôi lấy Mean Reciprocal Rank (MRR) và recall làm chỉ số đánh giá:
• MRR: trung bình của nghịch đảo nhân của hạng của kết quả đúng đầu tiên, được sử dụng rộng rãi để đánh giá chất lượng mô hình.
• Recall: phần trăm trung bình của các mục ground truth được nhớ lại trong quá trình tìm kiếm. Đối với thách thức mô hình embedding và thách thức hệ thống truy xuất end-to-end, chúng tôi sử dụng nhãn truy vấn-tài liệu kiểm tra của chúng tôi làm ground truth. Đối với thách thức thuật toán truy xuất embedding, chúng tôi sử dụng kết quả tìm kiếm vector brute-force làm ground truth (ANN recall) để đánh giá hiệu suất thuật toán ANN.

Đối với hiệu suất hệ thống, chúng tôi đánh giá các chỉ số sau dưới chi phí tài nguyên hạn chế để phù hợp với các kịch bản công nghiệp:
• Throughput: Tất cả các truy vấn được cung cấp cùng một lúc, và chúng tôi đo thời gian đồng hồ tường giữa việc nhập các vector và khi tất cả các kết quả được xuất ra sử dụng tất cả các luồng trong một máy. Sau đó throughput được tính như số truy vấn được xử lý mỗi giây (QPS).
• Latency: chúng tôi đo độ trễ truy vấn percentile 50, 90 và 99 tại QPS nhất định.

4.4 Đánh giá Mô hình Embedding

Trong thí nghiệm này, chúng tôi đo MRR và recall của tất cả các mô hình embedding baseline. Từ kết quả, chúng ta có thể thấy rằng SimANS với các mẫu mơ hồ làm ví dụ huấn luyện tiêu cực hoạt động tốt nhất trên tập dữ liệu MS MARCO Tìm kiếm Web 100M. Thứ hạng của các mô hình baseline phù hợp với xu hướng tiến hóa mô hình trong tài liệu. Tuy nhiên, khi so sánh với kết quả đánh giá trong Natural Question (NQ) [28] và MS MARCO Passage Ranking [35], khoảng cách hiệu suất giữa ANCE và SimANS trong MS MARCO Tìm kiếm Web trở nên ít đáng kể hơn.

Chúng tôi cũng đánh giá hiệu suất hệ thống cho ba mô hình embedding baseline. Vì chúng sử dụng cùng kiến trúc mô hình và cùng số lượng tham số, chi phí thời gian phục vụ của chúng tương tự. Tại đỉnh 698 QPS, các percentile độ trễ 50, 90 và 99 lần lượt là 9,896 ms, 10,018 ms và 11,430 ms.

4.5 Đánh giá Thuật toán ANN

Trong thí nghiệm này, chúng tôi đánh giá hiệu suất ANN với các vector được tạo bởi mô hình baseline tốt nhất. Chúng tôi xây dựng cả chỉ mục DiskANN và SPANN và đánh giá cả hiệu suất phục vụ và chất lượng kết quả của chúng. Ở đây chúng tôi chỉ tập trung vào việc đánh giá khoảng cách giữa ANN và KNN. Do đó, chúng tôi sử dụng kết quả tìm kiếm brute-force làm ground truth để đo recall. Bảng 5 tóm tắt recall và hiệu suất hệ thống của hai baseline. Từ kết quả, chúng ta có thể thấy rằng rất khó để đạt được recall cao khi số lượng kết quả trả về K lớn. Một trong những lý do là phân phối của các truy vấn và tài liệu có độ lệch cao và cách xa nhau (xem hình 6). Chúng tôi cũng quan sát hiện tượng này trong các embedding DPR và ANCE.

4.6 Đánh giá Hiệu suất End-to-end

Trong phần này, chúng tôi đánh giá hiệu suất end-to-end của ba mô hình embedding baseline cộng với chỉ mục SPANN và giải pháp Elasticsearch BM25 được sử dụng rộng rãi. Bảng 6 và bảng 7 thể hiện chất lượng kết quả và hiệu suất hệ thống của tất cả các hệ thống baseline này tương ứng. So với bảng 4, chúng ta có thể thấy rằng sau khi sử dụng chỉ mục ANN, chất lượng kết quả cuối cùng giảm rất nhiều. Ví dụ, chỉ số recall@100 giảm hơn 10 điểm cho tất cả các mô hình baseline. Tồn tại khoảng cách chất lượng lớn giữa kết quả ANN và KNN (xem bảng 5). Hơn nữa, chúng tôi nhận thấy rằng việc sử dụng chỉ mục ANN sẽ thay đổi xu hướng xếp hạng mô hình. SimANS đạt được kết quả tốt nhất cho tất cả các chỉ số chất lượng kết quả với tìm kiếm brute-force. Tuy nhiên, khi sử dụng chỉ mục SPANN, nó hoạt động kém hơn ANCE trong recall@20 và recall@100. Chúng tôi phân tích thêm hiện tượng này một cách chi tiết và thấy rằng SimANS có khoảng cách lớn hơn giữa khoảng cách trung bình của truy vấn đến top100 tài liệu so với khoảng cách trung bình của tài liệu đến top100 tài liệu so với ANCE. Khoảng cách trong SimANS và ANCE lần lượt là 103,35 và 73,29. Điều này sẽ gây ra ước tính giới hạn khoảng cách không chính xác cho một truy vấn đến các láng giềng của một tài liệu. Do đó, ANN không thể hoạt động tốt vì nó dựa vào khoảng cách được ước tính theo bất đẳng thức tam giác. Cả kết quả chất lượng kết quả và hiệu suất hệ thống của đánh giá end-to-end đều kêu gọi nhiều cải tiến hơn trong thiết kế hệ thống truy xuất end-to-end.

5 THIÊN LỆCH VÀ HẠN CHẾ TIỀM NĂNG

Như đã thảo luận trong mục 3.3.1, phân phối ngôn ngữ của tài liệu và truy vấn trong kịch bản web có độ lệch cao. Điều này sẽ dẫn đến thiên lệch ngôn ngữ về dữ liệu và mô hình. ClueWeb22 [9] chứng minh rằng cũng tồn tại độ lệch phân phối chủ đề trong kịch bản web. Do đó, thiên lệch miền cũng có thể xảy ra trong dữ liệu và mô hình.

Để bảo vệ quyền riêng tư của người dùng và sức khỏe nội dung, chúng tôi loại bỏ các truy vấn hiếm khi được kích hoạt (được kích hoạt bởi ít hơn K người dùng, trong đó K là một giá trị cao), chứa thông tin nhận dạng cá nhân, nội dung xúc phạm, nội dung người lớn và các truy vấn không có kết nối click với tập tài liệu ClueWeb22. Do đó, phân phối truy vấn hơi khác so với phân phối truy vấn web thực tế.

6 CÔNG VIỆC TƯƠNG LAI VÀ KẾT LUẬN

MS MARCO Tìm kiếm Web là tập dữ liệu web đầu tiên đáp ứng hiệu quả các tiêu chí lớn, thật và phong phú về chất lượng dữ liệu. Nó bao gồm các trang web quy mô lớn và nhãn truy vấn-tài liệu có nguồn gốc từ một công cụ tìm kiếm thương mại, giữ lại thông tin phong phú về các trang web được sử dụng rộng rãi trong công nghiệp. Benchmark truy xuất được cung cấp bởi MS MARCO Tìm kiếm Web bao gồm ba tác vụ thách thức đòi hỏi đổi mới trong cả lĩnh vực nghiên cứu học máy và hệ thống truy xuất thông tin. Chúng tôi hy vọng MS MARCO Tìm kiếm Web có thể phục vụ như một benchmark cho truy xuất thông tin web quy mô hiện đại, tạo điều kiện cho nghiên cứu và đổi mới trong tương lai trong các hướng đa dạng.

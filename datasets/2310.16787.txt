# 2310.16787.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/datasets/2310.16787.pdf
# File size: 3788226 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
The Data Provenance Initiative:
ALargeScaleAuditofDatasetLicensing&AttributioninAI
Shayne Longpre1†Robert Mahari1,2Anthony Chen3Naana Obeng-Marnu1,4
Damien Sileo5William Brannon1,4Niklas Muennighoff6Nathan Khazam7
Jad Kabbara1,4Kartik Perisetla Xinyi (Alexis) Wu8Enrico Shippole Kurt Bollacker7
Tongshuang Wu9Luis Villa10Sandy Pentland1Sara Hooker11
1MIT2Harvard Law School3UC Irvine4MIT Center for Constructive Communication
5Inria, Univ. Lille Center6Contextual AI7ML Commons8Olin College
9Carnegie Mellon University10Tidelift11Cohere For AI
Abstract
The race to train language models on vast, diverse, and inconsistently documented datasets has raised
pressing concerns about the legal and ethical risks for practitioners. To remedy these practices threatening
datatransparencyandunderstanding,weconveneamulti-disciplinaryeffortbetweenlegalandmachine
learning experts to systematically audit and trace 1800+ text datasets. We develop tools and standards
to trace the lineage of these datasets, from their source, creators, series of license conditions, properties,
and subsequent use. Our landscape analysis highlights the sharp divides in composition and focus of
commercially open vs closed datasets, with closed datasets monopolizing important categories: lower
resource languages, more creative tasks, richer topic variety, newer and more synthetic training data. This
points to a deepening divide in the types of data that are made available under different license conditions,
and heightened implications for jurisdictional legal interpretations of copyright and fair use. We also
observefrequentmiscategorizationoflicensesonwidelyuseddatasethostingsites,withlicenseomission
of 70%+ and error rates of 50%+. This points to a crisis in misattribution and informed use of the most
populardatasetsdrivingmanyrecentbreakthroughs. Asacontributiontoongoingimprovementsindataset
transparency and responsible use, we release our entire audit, with an interactive UI, the Data Provenance
Explorer ,whichallowspractitionerstotraceandfilterondataprovenanceforthemostpopularopensource
finetuning data collections: www.dataprovenance.org .
1 Introduction
The latest wave of language models, both public (Chung et al., 2022; Taori et al., 2023; Geng et al., 2023) and
proprietary(Aniletal.,2023;OpenAI,2023;Anthropic,2023;Yooetal.,2022)attributetheirpowerfulabilities
in large part to the diversity and richness of ever larger training datasets, including pre-training corpora,
and finetuning datasets compiled by academics (Wei et al., 2021; Sanh et al., 2021; Muennighoff et al., 2022),
syntheticallygeneratedbymodels(Taorietal.,2023;Wangetal.,2022a),oraggregatedbyplatformslike
HuggingFace(Lhoestetal.,2021). Recenttrendsseepractitionerscombiningandre-packagingthousandsof
datasets and web sources (Gao et al., 2020; Penedo et al., 2023; Wang et al., 2022b; Longpre et al., 2023a), but
despite somenotable documentation efforts(Spacerini, 2021; Bidermanet al.,2022), there arediminishing
efforts to attribute, document or understand the raw ingredients into new models (Dodge et al., 2021; Bandy
and Vincent, 2021; Bommasani et al., 2023a).
†Correspondence: data.provenance.init@gmail.com
1arXiv:2310.16787v3  [cs.CL]  4 Nov 2023

--- PAGE 2 ---
ACrisisinDataTransparency&itsConsequences. Increasingly,widelyuseddatasetcollectionsaretreated
asmonolithic,insteadofalineageofdatasources,scraped(ormodelgenerated),curated,andannotated,
often with multiple rounds of re-packaging (and re-licensing) by successive practitioners. The disincentives
to acknowledge this lineage stem both from the scale of modern data collection (the effort to properly
attributeit),andtheincreasedcopyrightscrutiny(Saverietal.,2023). Together,thesefactorshaveseenfewer
Datasheets (Gebru et al., 2021), non-disclosure of training sources (OpenAI, 2023; Anil et al., 2023; Touvron
etal.,2023),andultimatelyadeclineinunderstandingtrainingdata(Sambasivanetal.,2021b;Longpreetal.,
2023b).
This lack of understanding can lead to data leakages between training and test data (Elangovan et al., 2021;
Carlinietal.,2022),exposepersonallyidentifiableinformation(PII)(Bubecketal.,2023),presentunintended
biasesorbehaviours(Welbletal.,2021;Xuetal.,2021;Pozzobonetal.,2023),andgenerallyresultinlower
qualitymodelsthananticipated. Beyondthesepracticalchallenges,informationgapsanddocumentation
debtincursubstantialethicalandlegalrisks. Forinstance,modelreleasesappeartocontradictdataterms
ofuse(e.g.,WizardCoder(Luoetal.,2023)licensedforcommercialuse,whiletrainingoncommercially-
prohibited OpenAI data), license revisions post-public release (with MPT-StoryTeller (Frankle, 2023)), and
even copyright lawsuits (e.g. Stability AI (Arstechnica, 2023) and OpenAI (Saveri et al., 2023)). As training
models on data is both expensive and largely irreversible, these risks and challenges are not easily remedied.
Inthiswork,wetermthecombinationoftheseindicators,includingdatasets’sourcing,creationandlicensing
heritage, as well as its characteristics, Data Provenance .
UnreliableDataProvenance&Licensing. Ourworkmotivatestheurgencyoftoolingthatfacilitatesinformed
andresponsibleuseofdatainbothpretrainingandfinetuning. Toempowerpractitionerstoattributedata
provenance, wedevelopa setoftools andstandardsto tracethedata lineageof44 ofthemost widelyused
and adopted text data collections, spanning 1800+ finetuning datasets. We compile and expand relevant
metadata with a much richer taxonomy than Hugging Face, Papers with Code, or other aggregators (see
Section 2.1). With legal experts, we design a pipeline for tracing dataset provenance, including the original
source of the dataset, the associated licenses, creators, and subsequent use.
Asabyproductofourworkestablishingthe DataProvenance ofwidelyuseddatasets,weareabletocharacterize
theAIdataecosystem/supplychain(Cenetal.,2023;Bommasanietal.,2023c),aswellasstateofthefieldfor
policymakers, researchers and legal experts. Our work points to a crisis in license laundering and informed
usage of popular datasets, with systemic problems in sparse, ambiguous, or incorrect license documentation.
Notably, we find that 70%+ of licenses for popular datasets on GitHub and Hugging Face are “Unspecified”,
leaving a substantial information gap that is difficult to navigate in terms of legal responsibility. Second, the
licensesthatareattachedtodatasetsuploadedtodatasetsharingplatformsareofteninconsistentwiththe
license ascribed by the original author of the dataset—our rigorous re-annotation of licenses finds that 66%
ofanalyzedHuggingFacelicenseswereinadifferentusecategory,oftenlabeledasmorepermissivethan
the author’s intended license. As a result, much of this data is risky to use (or harmfully misleading) for
practitionerswhowanttorespectthedataprovenanceofawork. Ourinitiativereduces“Unspecified“licenses
from72%+ to30%and attacheslicenseURLs forunder-resourcedmodeldevelopers tomoreconfidently
select appropriate datafor their needs. To this end, the DataProvenance Initiativesupports attribution and
responsible AI with the following contributions:
1.The most extensive known public audit of AI Data Provenance , tracing the lineage of 1800+ text
datasets (the “ DPCollection ”), their licenses, conditions, and sources. We demonstrate a growing
adoption and reliance on software licenses in the AI community and synthesize observations into legal
guidance for developers (Section 4).
2.The Data Provenance Explorer (DPExplorer)∗, an open-source repository for downloading, filtering,
andexploringdataprovenanceandcharacteristics. Ourtoolsauto-generate DataProvenanceCards for
scalable symbolic attribution and future documentation best practices.
3.Wefindasharpandwideningdividebetweencommerciallyopenandcloseddata ,withthelatter
monopolizingmorediverseandcreativesources. Wesuggestadatacollectionfocustonarrowthisgap.
∗www.dataprovenance.org
2

--- PAGE 3 ---
2 The Initiative to Audit Data Provenance
TheDataProvenanceInitiative’sgoalistoauditpopularandwidelyuseddatasetswithlarge-scaleLegal
andAI expert-guidedannotation. We proposeabase setof indicatorsnecessary fortracing datasetlineage
and understanding dataset risks (described in Section 2.1). As a first contribution of the initiative, we audit
44 instruction or “alignment” finetuning data collections composed of 1858 individual datasets, selected by
experts for their widespread adoption and use in the community. The selected collections and their variants
see100sto10M+monthlydownloadsonHuggingFace,withthedatasetswithinthesecollectionstallyingto
many more Table 1.
The initiative’s initial focus on alignment finetuning datasets was decided based on their growing emphasis
inthecommunityforimprovinghelpfulness,reducingharmfulness,andorientingmodelstohumanval-
ues(Ouyangetal.,2022). Somecollectionshaveoverlappingdatasetsandexamples,butwechoosenotto
deduplicatetopreservetheoriginaldesignchoices,thatmayincludedifferenttemplates,formatting,and
filtering. We remove datasets related to common benchmarks like MMLU (Hendrycks et al., 2020) and
BigBench (Srivastava et al., 2023).
Data Creators 
Text Sources 
Text Domains 
Licenses 
License Conditions 
Find 
Licenses D1
D2
D3D4
D5Lorem ipsum dolor sit amet, consectetur 
adipiscing elit. Nulla ipsum mauris, vulputate 
quis arcu nec, malesuada rhoncus diam. 
Vestibulum molestie velit ac turpis 
ullamcorper, a fermentum augue ﬁnibus. 
Donec gravida euismod nisl ac viverra. Sed 
vitae mi ut risus condimentum malesuada. 
Proin at posuere leo, ac fermentum 
purus.Donec placerat nec ipsum quis 
malesuada. Donec sit amet diam vestibulum, 
dapibus nulla placerat, fermentum 
dolor.Aenean lacinia ut felis ut tristique. 
Praesent feugiat dolor in leo 
Links to 
Aggregators 
Original 
Sources
Categorize 
Licenses Resolve 
Conﬂicts Machine 
Analysis 
Datasets Collections Name / IDs 
Source URLs 
 - GitHub 
 - Hugging Face 
 - Semantic Sch. 
 - Papers w Code 
Academic Paper 
Text Topics 
Text Statistics 
Task Categories 
Formats 
Languages 
Collection Time 
Num Downloads 
Num Citations 
Data Lifecycle 
License Annotation Procedure 
Figure 1: The DPCollection annotation pipeline uses human and human-assisted procedures to annotate
dataset Identifiers ,Characteristics , andProvenance .TheData Lifecycle is traced, from the original
sources (web scrapes, human or synthetic text), to curated datasets and packaged collections. Information is
collected at each stage, not just the last. The License Annotation Procedure is described in Section 2.2.
2.1 Data Provenance Explorer (DPExplorer)
Our information audit spans (I) identifier information , bridging metadata from several aggregators, including
Hugging Face, GitHub, Papers with Code, Semantic Scholar, and ArXiv, (II) detailed dataset characteristics for
a richer understanding of training set composition, and (III) dataset provenance for licensing and attribution.
We expand our provenance metadata beyond just licenses, because conversations with practitioners revealed
they rely not only on data licenses, but on a specific legal & ethical risk tolerance , parameterized by (a) the
lineageoflicenses,(b)thedatasource,(c)thecreator’sidentity,and(d)theprecedenceofadoptionbyother
developers.
We release our extensive audit, as two tools: (1) a data explorer interface, the Data Provenance Explorer
(DPExplorer) forwidespreaduse,and(2)anaccompanyingrepositoryforpractitionerstodownloadthedata
3

--- PAGE 4 ---
Collection Property Counts Text Lens Dataset Types
Datasets Dialogs Tasks Langs Topics Domains Downs Inpt Tgt Source Z F C R M Use O
Airoboros 117k 521011k3471k
 ✔ ✔
Alpaca 152k 81101100k505270
 ✔ ✔
Anthropic HH 1161k 3110182k69311
 ✔
BaizeChat 4210k 122373<1k74234
 ✔ ✔
BookSum 17k41101<1k14k2k
 ✔
CamelAI Sci. 360k 21291<1k1902k
 ✔ ✔
CoT Coll. 62,183k 127291<1k728265
 ✔ ✔
Code Alpaca 120k 321015k97196
 ✔ ✔
CommitPackFT 277702k 127875114k645784
 ✔
Dolly 15k 715k 5138110,116k 423357
 ✔
Evol-Instr. 2213k 1121712k5702k
 ✔ ✔
Flan Collection 4509,813k 19391k2319k2k128
 ✔ ✔ ✔ ✔
GPT-4-Alpaca 155k 711011k130543
 ✔ ✔
GPT4AllJ 7809k 101561<1k8831k
 ✔ ✔
GPTeacher 4103k 82331<1k227360
 ✔ ✔
Gorilla 115k 42102<1k11976
 ✔ ✔
HC3 1237k 6210262k119652
 ✔ ✔
Joke Expl. 1<1k 21101<1k96547
 ✔
LAION OIG 269,211k 12117111<1k343595
 ✔ ✔
LIMA 51k1024363k2283k
 ✔ ✔ ✔
Longform 723k1116343k8102k
 ✔ ✔
OpAsst OctoPack 110k 320101<1k118884
 ✔
OpenAI Summ. 193k 5110114k1k134
 ✔ ✔
OpenAssistant 1910k 42099114k118711
 ✔
OpenOrca 44,234k 111302328k1k492
 ✔ ✔
SHP 18349k 6215114k824496
 ✔
Self-Instruct 183k 621013k134104
 ✔ ✔
ShareGPT 177k 91102<1k3031k
 ✔ ✔
StackExchange 110,607k 12101<1k1k901
 ✔
StarCoder 1<1k 12101<1k195504
 ✔
Tasksource Ins. 2883,397k 13158220<1k51818
 ✔ ✔
Tasksource ST 229338k 15147718<1k3k6
 ✔ ✔
TinyStories 114k 4110112k517194k
 ✔ ✔
Tool-Llama 137k 22101 - 7k1k
 ✔ ✔
UltraChat 11,468k 711122k2821k
 ✔ ✔ ✔
Unnatural Instr. 166k 41101<1k33168
 ✔ ✔
WebGPT 520k 413531k737743
 ✔ ✔
xP3x 467886,240k 524515114<1k589441
 ✔
Table1:Alignmenttuningcollectionsandtheircharacteristics. Propertiesofthecollectionsincludethe
numbersofdatasets,dialogs,uniquetasks,languages,topics,textdomains,Huggingfacemonthlydownloads
(“Downs”), and the average length of input and target text, by characters. The Sourcecolumn indicates
whetheracollectionincludeshumanwebtext(
 ), ormodelgeneratedtext(
 ). Thedialogformatsofeach
collectioncanbe: zero-shot(Z),few-shot(F),chain-of-thought(C),responseranking(R),andmulti-turn
dialog(M).The Usecolumnindicateswhetheracollectionincludesdatalicensedforcommercialuse( ),
datawithnolicense(“unspecified”: ),dataonlylicensedfornon-commercialoracademicuse( ).Note
thattheselicensesareself-reportedandtheirapplicabilityiscomplicated,requiringlegalconsultation. The“O”column
indicates if the collection includes OpenAI model generations, which may or may not affect commercial
viability (see Section 4)
4

--- PAGE 5 ---
filteredforlicenseconditions. Practitionersarealsoabletogenerateahuman-readable,markdownsummary,
orData Provenance Card , of the used datasets, and compositional properties for languages, tasks, and licenses
(Section 2.3). Modern researchers training on hundreds of datasets often find it onerous to manually curate
extensivedatacardsforthesecompilations(Mitchelletal.,2019;Gebruetal.,2021). Wehopethistoolwill
aidinwritingthedataattributionandcompositionsectionsofthesedocumentationefforts,byproviding
auto-generated, copy-and-pastable dataframe summaries.
Collecting comprehensive metadata for each dataset required leveraging several sources including collection
by linking to resources already on the web (
 ), human annotation by legal experts (
 ), or using GPT-4 to
assist in human annotation (
 ).
Identifier Information discloses links and connects aggregator identifiers.
1.Dataset Identifiers
 : The dataset’s name, associated paper title, and description of the dataset.
2.DatasetAggregatorLinks
 : Alinktoeachmajoraggregator,includingGitHub,HuggingFace,Papers
with Code, Semantic Scholar, and ArXiv allows us to incorporate and compare their crowdsourced
metadata.
3.Collection
 : The name and URL to the data collection of which this dataset is a part.
Dataset Characteristics detail information relevant to understanding data representation/composition,
and curating a training set.
1.Languages
 : Eachofthelanguagesrepresentedinthedataset,sodeveloperscaneasilyfollowthe
“Bender Rule” (Bender, 2011).
2.Task Categories
 : The 20+ task categories represented in the instructions, such as Question
Answering, Translation, Program Synthesis, Toxicity Identification, Creative Writing, and Roleplaying.
3.Text Topics
 : An automated annotation of the topics discussed in the datasets, with GPT-4 labeling a
sample of 100 examples for up to 10 covered topics.
4.TextLengthMetrics : Theminimum,maximum,andmeannumberofdialogturnsperconversation,
ofcharacters(agnostictotokenization/non-whitespacelanguages,asthisintroducesbiases(Petrov
et al., 2023)) per user instruction and assistant responses.
5.Format
 : The format and intended use of the data. The options are zero-shot prompts, few-shot
prompts, chain-of-thought prompts, multi-turn dialog, and response ranking.
6.Time of Collection
 : The time as which the work was published, which acts as an upper bound
estimate of the age of the text.
Dataset Provenance
1.Licenses
 : ThelicensenameandURLsassociatedwiththedata,usingtheprocessdescribedin
Section 2.2. We also enable filtering by license use classes, categorized by legal professionals.
2.Text Source
 : The original sources of the text, often Wikipedia, Reddit, or other scraped online/of-
fline sources.
3.Creators
 : The institutions of the dataset authors, including universities, corporations, and other
organizations.
4.Attribution
 : The attribution information for the authors of the paper associated with the dataset.
5.Citation&DownloadCounts
 : ThecitationandHuggingFacedownloadcountforthepaperand
dataset,datedSeptember2023. Thisactsasanestimateofcommunityuse,andiscommonlyusedas
precedence to decide on the risk level for using these datasets .
5

--- PAGE 6 ---
2.2 License Annotation Process
One of our central contributions is to validate the licenses associated with widely used and adopted datasets.
This followed a time-intensive human annotation protocol, to collect dataset authors’ self-reported licenses,
and categorize them according to stated conditions. Note that this protocol reflects best efforts to verify
self-reportedlicenses,anddoesnotconstitutelegaladvice(seeSection4). Additionally,itisimportantto
notethattheenforceabilityoftheselicensesdependsonseveralfactorsdiscussedinSection4. Oneespecially
important assumption in cases where datasets are based on data obtained from other sources is that dataset
creatorsactuallyhaveacopyrightinterestintheirdataset. Thisdependsonthedatasourceandhowcreators
modify or augment this data, and requires a case-by-case analysis. However, it appears that most developers
operate under the general assumption that they alone own their datasets. Our license annotation workflow
follows these steps:
1.Compile all Self-Reported License Information We aggregate all licensing information reported
on GitHub, ArXiv, Hugging Face, Papers with Code, and the collection itself (e.g. Super-Natural
Instructions, Wang et al. (2022c)).
2.Search for explicit Data Licenses The annotator searches for a license specifically given to the dataset
(not the accompanying code ) by the authors. A license is found if (a) the GitHub repository mentions or
links a license in reference to the data, (b) the Hugging Face license label was uploaded by the dataset
creatorthemselves, (c)thepaper, HuggingFace, orPaperswithCodeprovideadataset-specificlicense
link, attributable to the data authors.
3.Identify a License Type A license may fall into a set of common types (e.g. MIT, Apache 2, CC BY SA,
etc.), be a “Custom” license, a permission Request Form, or if none was found for the data, Unspecified .
If a dataset has multiple licenses, the annotator will list each of them, according to their types.
4.Categorize Licenses From the perspective of a machine learning practitioner, licensing typically is
viewed through the lens of how it impacts the model lifecycle—does it impede or allow for training on
the data, downstream use conditions, attributing, modifying or re-distributing it. Based on discussions
with industry experts, we categorize licenses based on three important features that impact the model
lifecycle: isdatausagelimitedtoacademicornon-commercialpurposes( PermittedUse ),doesthedata
sourceneedtobeattributed( Attribution ),anddoderivativesofthedataneedtolicensedunderthe
same terms as the original ( Share-Alike ). If there are multiple licenses for a dataset, its categorization
for each feature is the chosen as the strictest across licenses.
5.Additional Provenance In practice, legal teams may wish to balance their risk tolerance with more
nuancedcriteria. Forinstance,theymaybesatisfiedwithusing(morepermissive)GitHublicenses,
even when it is ambiguous whether these apply to the code or the data. They may also wish to include
or exclude datasets based on whether these are already widely used in practice, where the original
data was sourced from, and if the creator is a competitor. To supplement the above license categories,
we also collect all this metadata for fine-grained selection and filtering.
2.3 Data Provenance Card— A Data Bibliography
Prior work has stressed the importance of data documentation and attribution (Bender and Friedman, 2018;
Bommasanietal.,2023a). Inparticular,Gebruetal.(2021)’sDatasheetsbreaksdowndocumentationinto
motivation, composition, collection process, processing, uses, maintanence, and distribution. Similarly, Ben-
der and Friedman (2018) ask for curation rationale, language variety, speaker demographic, annotator
demographic,speechsituation,andtextcharacteristics,amongothers. However,whenmodelstrainonmany
sourcesofdata,eveniftheyareeachrigorouslydocumentedforeachofthesefields(rarelythecase),itis
challenging to cleanly synthesize comprehensive and navigable documentation for the resulting bundle.
Tomakethisprocesstractablewithscale,weproposeleveraging Symbolic Attribution ,whereourtoolsauto-
generatea structuredstore oftheprovenance andattributionmetadata, similarto abibliographyfor data.†
†Auto-generated at https://github.com/Data-Provenance-Initiative/Data-Provenance-Collection
6

--- PAGE 7 ---
CC BY-SA 4.0OpenAI
CC BY 4.0
CC BY-NC 4.0Custom
CC BY-SA 3.0Apache
License 2.0 MIT License
CC BY-NC-SA4.0Various CC0 1.0OANC
Request FormAcademic
Research OnlyNon
CommercialCC BY-NC-SA3.0
BSD 2-ClauseLicenseGNU v3.0
BSD 3-ClauseLicense
CDLA Sharing1.0No License02040608087(15.7%)
68(12.3%)
64(11.6%)
59(10.7%)
53(9.6%)
33(6.0%)
30(5.4%)
19(3.4%)
18(3.3%)
17(3.1%)
16(2.9%)
14(2.5%)
14(2.5%)
11(2.0%)
10(1.8%)
7(1.3%)
5(0.9%)
4(0.7%)
4(0.7%)
2(0.4%)
2(0.4%)Requires Attribution
Requires Share Alike
Allowed Use: Commercial
Allowed Use: Non-Commercial/Academic
Allowed Use: CustomFigure2: WeplotthedistributionsoflicensesusedintheDPCollection,apopularsampleofthemajor
supervised NLP datasets. We find a long tail of custom licenses, adopted from software for data. 73% of all
licenses require attribution, and 33% share-alike, but the most popular are usually commercially permissive.
Our collected schema allows this store to succinctly capture the attribution (links to repositories, aggregator
copies, papers, creators),provenance (text/machinesources, licenses), andcompositional propertiesof the
data (languages, tasks, text metrics, format, and time). This file of references and metadata, known as a
Data Provenance Card enables comprehensive documentation, proposed by prior work, while providing some
advantagesfromitsstructure. First,theDataProvenanceCardcanbeeasilysearched,sorted,filteredand
analyzed,whereasDatasheetsorStatements,designedforindividualdatasets,aremeanttobemanuallyread.
Second, developers can efficiently assemble relevant information without losing any detail, by symbolically
linking to the original datasets and their documentation. Third, as datasets are continually re-packaged
and absorbed into newer and bigger collections, Data Provenance Cards are easily adaptable by simply
appending or concatenating them together. Altogether, we hope this tooling enables and promotes the
thoroughdocumentation proposedinprior work(Bender andFriedman, 2018;Gebruet al.,2021;Mitchell
et al., 2019; Pushkarna et al., 2022)
3 Empirical Analysis of Data Provenance
3.1 Licenses in the Wild
This work constitutes the first extensive study of empirical license use for Natural Language Processing
datasets. In this section, we share the insights we have gathered from our large-scale annotation and
categorization. Thereisanimportantassumptioninthissection: theOpenAITermsofUseisacontract,nota
license, which prohibits the development of competing models using its outputs. For simplicity, we treat this
as a Non-Commercial license in our analysis, though this is disputed for third parties who did not generate
theOpenAI data themselvesand thereforemay notbe boundby theirterms (see Section4 for discussion).
Given the intention of OpenAI not to facilitate competitive commercial uses, we follow their categorization
for this analysis.
Frequency of license types Figure 2 shows the distribution of licenses. The most common licenses are
CC-BY-SA4.0(15.7%),theOpenAITermsofUse(12.3%),andCC-BY4.0(11.6%). Whilemostlicensesare
commonandrecognizable,thereisalongtailofvariantswithuniquesettings,aswellasalargesetofCustom
licensesaccountingfor9.6%ofallrecordedlicensesontheirown. Thiswidelicensediversityillustratesthe
challengetostartupsandlessresourcedorganizationsattemptingtonavigateresponsibletrainingdata
collection, its legality and ethics.
7

--- PAGE 8 ---
Correct license License according to aggregators (Agg.)
License Count Agg. Comm. Unspec. Non-Comm. Acad.-Only
Commercial856
(46.1%)
349 507 0 0
176 677 1 2
313 520 1 22
Unspecified570
(30.7%)
112 458 0 0
164 395 6 5
31 523 1 15
Non-Commercial352
(19.0%)
49 303 0 0
113 152 80 7
2 191 157 2
Academic-Only80
(4.3%)
9 71 0 0
9 65 2 4
5 65 2 8
Total1858
(100%)
519(28%)1339(72%) 0(0%) 0(0%)
462(25%)1289(69%) 89(5%) 18(1%)
351(19%)1299(70%)161(9%) 47(3%)
Table 2:The distribution of license use categories shows our licenses have far fewer “Unspecified” omis-
sionsthanGitHub(
 ,72%),HuggingFace(
 ,69%),andPaperswithCode(
 ,70%),categorizinglicense
more confidently into commercialor non-commercial categories. GitHub, Hugging Face, and Papers with
Code match our licenses (green regions) 43%, 35%, and 54% of the time, respectively, and suggest incorrect
licenses that are too permissive 29%, 27%, and 16% of the time.
Distribution of Restrictive Licenses In total, 85% of dataset licenses request attribution, and 30% include a
share alike clause.‡Datasets which request attribution pose challenges for practitioners who commonly train
onhundredsofdatasetsandeitherdon’tcitethematall(OpenAI,2023;Aniletal.,2023;Touvronetal.,2023)
or simply cite an aggregation of data, which often falls short of the license’s conditions of attributing the
specificrepositoryorpaper. Futhermore,“Sharealike”clausesposeschallengesforpractitionersre-packaging
datacollectionsusuallywithmultipleconflictingshare-alikelicenseswithoutaclearwaytoresolvethem
(likeLongpreetal.(2023a);Wangetal.(2022c)andothersintheDPCollection). Frequently,practitioners
will over-write share-alike licenses with more restrictive or even less restrictive conditions.
Missing or Unspecified Licenses. Next, we compare our manually reviewed licensing terms, to the licenses
forthesamedatasets,asdocumentedintheaggregatorsGitHub,HuggingFace,andPaperswithCode.Table2
shows that these crowdsourced aggregators have an extremely high proportion of missing (“Unspecified”)
licenses, ranging from 69-72%, as compared to our protocol which yields only 30% “Unspecified”. The
problem with “Unspecified” licenses is that it is unclear whether it is due to a shortcoming of the aggregator
or because creators intentionally released them without a license. Consequently, risk-averse developers
areforcedtoavoidmanyvaluabledatasets,whichtheywoulduseotherwiseiftheyweregivenassurance
that there is indeed no license. As part of DPCollection, we manually reassign 46-65% of dataset licenses
(dependingontheplatform),resultinginmuchhighercoverage,thusgivingrisk-aversedevelopersmore
confidence and breadth in their dataset utilization.
Incorrectly Specified Licenses. Table 2 also finds real licenses as assigned by us are frequently stricter than
the ones by aggregators. GitHub, Hugging Face and Papers with Code each label license use cases too
permissively in 29%, 27%, and 16% of cases respectively. Our inspection suggests this is due to contributors
on these platforms often mistaking licenses attached to code in GitHub repositories for licenses attached to
data.
‡“Share alike” is a copyright term meaning adaptations or copies of a work are required to be released under the same license as the
original.
8

--- PAGE 9 ---
Metrics Commercial Unspecified NC / A-O
Mean Entropy Mean Entropy Mean Entropy
Tasks 1.7±0.10.61 1.6±0.10.53 3.4±0.20.69
Languages 1.3±0.00.52 1.2±0.00.16 1.1±0.00.45
Topics 8.2±0.20.70 9.2±0.10.75 9.1±0.20.77
Sources 1.6±0.10.67 1.8±0.10.72 4.2±1.30.78
Input Text Lengths 1043.4 ±151.96.37860.2±67.76.66950.3±112.96.46
Target Text Lengths 102.7±14.64.3990.5±14.34.091580.7 ±965.65.37
Synthetic 12.8% ±2.1-13.6% ±1.7-45.5%±3.4-
Table 3: The mean number of features (e.g. tasks or languages) per dataset, and the mean entropy of the
distribution, representing the diversity of categories. Non-Commercial / Academic-Only datasets have
consistently and statistically higher task, topic, and source variety than Commercial datasets. We use
Normalized Shannon Entropy for discrete features, and Differential Entropy for continuous features, which
are both measures of randomness.
3.2 How does Data Availability Differ by License Use Category?
Whilenon-commercialandacademic-onlylicensesplayimportantrolesinprotectingdatause,theirpresence
canalsoexcludecommunitiesfromparticipating(orcompeting)inthedevelopmentofthesetechnologies. In
thissection,webreakdowndatasetsaccordingtotheirlicenserestrictionsandseehowtheydiffer. Specifically,
we ask:Does complying with licenses dictate systematic differences in resources for commercially-permissive (“open”)
and non-commercial (“closed”) development? And what particular features of data are particularly constrained
by non-commercial prohibitions?
Wecomparedatasetsbycategoriesofpermitteduse,accordingtotheirlicenses: (1)Commerciallyviable,
(2) Non-Commercial/Academic-Only (NC/A-O), or (3) Unspecified license. We group together Non-
Commercial and Academic-Only conditions as the distinction will rarely matter for developers. We argue in
Section4thatdatasetswithoutany license(Unspecified)havenotimposedanyconditions, socanoftenbe
treated as commercially viable, but this may depend on a developer’s risk tolerance and jurisdiction.
Non-Commercial&Academic-OnlyLicensedDatasetshavestatisticallygreaterdiversityintheirrepresen-
tationoftasks,topics,sources,andtargettextlengths. Foreachofthesefeatures,Table3illustratesthemean
numberperdataset,brokendownbylicensecategoryandentropytomeasuretherandomness,andthus
diversity, of each feature. NC/A-O datasets see greater diversity of tasks, topics, and sources represented in
the text than commercial datasets. Figure 4 shows where this diversity comes from. The most NC/A-O task
categories include Brainstorming, Explanation, Logic & Math, as well as Creativity and Creative Writing.
In comparison, the most commercially viable task categories are Short Text Generation, Translation, and
Classification. Similarly, among Source Domains, Governments and Search Queries are largely viable for
commercial(andunspecified)purposes,whereasGeneralWeb,Exams,andModel-generatedsourcesare
among the most restrictive.
Target Text Lengths are significantly higher for NC/A-O datasets than commercial datasets. Not only
do NC/A-O datasets appear more textually and functionally diverse, their length characteristics differ
substantially. While Table 3 shows the input text lengths across license categories are similar on average,
the target text lengths are significantly higher for NC/A-O datasets (103 vs 677). This breakdown is further
illustratedinFigure5,whereweseegreaterrepresentationofbothNC/A-Oandsyntheticdatasetsabovethe
100 target token threshold (y-axis).
TheriseofsyntheticdatasetsgeneratedusingAPIswithnon-commercialtermsofusemayexplainthe
differencesintextdiversityandlength. Table3alsoshowsafull45%ofNC/A-Odatasetsaresynthetic,
as compared to <14%in more permissive license categories. Taori et al. (2023); Wang et al. (2022a); Xu
et al. (2023a) and their variants, all generated in part using commercial APIs, exhibit stronger task and topic
diversity than traditional academic datasets, as they cater to longer form generations, by design. This is
9

--- PAGE 10 ---
< 20132013 2014 2015 2016 2017 2018 2019 2020 2021 2022 20230%20%40%60%80%100%Percentage (%)20.0 25.0 16.7 8.8 34.5 26.7 33.3 30.4 33.2 31.6 40.9 26.1
64.060.750.079.4
58.643.350.0 51.3 41.5 52.0
43.212.5
16.0 14.333.3
11.830.0
16.7 18.325.4
16.3 15.961.4(50) (56) (6) (34) (29) (30) (60) (115) (193) (98) (88) (88)
Code Uralic
Atlantic-Congo Indo-EuropeanAfroasiaticAustronesianOther
DravidianKra-Dai Japonic
Sino-TibetanTurkicKoreanic0%20%40%60%80%100%Percentage (%)78.2 76.7 72.7 43.1 66.7 71.0 69.6 60.0 57.1 53.8 43.2 45.5 44.4
15.39.135.9
8.39.510.8
16.7 18.2 21.025.029.0 30.4 33.3 33.338.545.950.055.6(308) (30) (11) (1581) (36) (31) (69) (15) (21) (13) (37) (22) (9)Figure 3: The distribution of datasets in each time of collection (top) and language family (bottom) category,
with total count above the bars, and the portion in each license use category shown via bar color. Red
is Non-commerical/Academic-Only, Yellowis Unspecified, and Blueis Commercial. Lower resource
languages, and datasets created in 2023 see a spike in non-commercial licensing.
Governments EntertainmentGeneral WebEncyclopediasCommerceSocial MediaNews Books Legal
Academic
PapersCode
T emplate
GeneratedExamsEducation BiomedicalModels0%20%40%60%80%100%Percentage (%)30.0 20.5 24.7 28.2 13.6 11.1 19.6 28.6 8.3 20.8 12.0 13.2 14.6 36.4 20.0
55.060.340.236.250.0 51.9
43.1
31.050.0
33.340.0 38.2 35.4
9.125.9
15.019.235.1 35.6 36.4 37.0 37.340.5 41.745.8 48.0 48.5 50.054.570.4 73.3(40) (73) (97) (188) (22) (135) (102) (42) (12) (24) (50) (68) (48) (11) (27) (15)
Short T ext GenTranslation
T extClassiﬁcation Bias/T oxicDetectQuestionAnsweringNLI
DialogGeneration
LanguageStyleAnalysisSequenceT agging
Open-formT extGenerationCreativeWritingCommonsenseRe...CreativityLogic & Math ExplanationBrainstorming0%20%40%60%80%100% Percentage (%)40.0 23.1 25.0 35.3 31.2 25.8 15.6 8.7 11.1 24.7 12.1 14.8 14.8 15.7 14.3 10.0
40.056.4 52.0
41.240.944.048.147.8 33.3
17.518.2 14.8 14.8 11.8 9.5
20.0 20.5 23.0 23.527.9 30.236.443.555.6 57.769.7 70.4 70.4 72.576.290.0(95) (39) (256) (34) (308) (182) (77) (23) (18) (97) (33) (27) (27) (51) (21) (10)
Figure 4: The distribution of datasets in each Domain Source (top) andtask (bottom) category, with
totalcountabovethebars,andtheportionineachlicenseusecategoryshownviabarcolor. RedisNon-
commerical/Academic-Only, YellowisUnspecified,and BlueisCommercial. Creative,reasoning,and
long-form generation tasks, as well as datasets sourced from models, exams, and the general web see the
highest rate of non-commercial licensing.
10

--- PAGE 11 ---
evidentfromtheconcentrationofcreative,brainstorming,andreasoningtasksbakedintothem,ascompared
to the focus of more topic-focused question answering, classification, and short text generation in non-
synthetic datasets. These datasets are usually created using larger proprietary models, mostly from OpenAI
APIs. TheOpenAITermsofUsestate“youmaynot...useoutputfromtheServicestodevelopmodelsthat
compete with OpenAI.” which we discuss in Section 4.§
2
10
20
100
200
1k
2k
10k
20k
100k
20
100
200
1k
2k
10k
20k
(a)License Use Categories vs Text Lengths
2
10
20
100
200
1k
2k
10k
20k
100k
20
100
200
1k
2k
10k
20k (b)Synthetic/Regular Datasets vs Text Lengths
Figure 5: Across finetuning datasets, we visualize their mean input (x-axis) and target (y-axis) text lengths,
measured in log-scaled number of words. The colors indicate either their license use category (left) or
whethertheyweremachinegeneratedorhumancollected(right). Longtargettextsarerepresentedinlarge
part by Non-Commercial and Synthetic datasets, that are often generated by commercial APIs.
2023 has a large spike in license usage, and in NC/A-O licensed data, representing 61%, as compared to
20% on average in prior years. Among the large collection of datasets we trace, we record the date at which
they are released, by cross-referencing their associated GitHub, ArXiv, and Hugging Face dates. We find
a striking change in the pattern of licensing restrictions. As shown in Figure 3, prior to 2023, no year saw
greaterthan1/3ofthedatasetsreleasedasNC/A-O.However,in2023,whichincludesmanyofthemost
popular and diverse datasets, the NC/A-O rate is 61%. Furthermore, most datasets were unaccompanied by
alicensepriorto2022( ˜50-80%),ascomparedtoonly12%in2023. Theshifttomorelicenseuse,andmore
restrictively conditioned data releases may foretell future challenges to open data, if the trend continues.
Commercial datasets have greater language variety, but low-resource language datasets see the least
commercial coverage. Table 3 shows that commercial datasets actually have greater diversity of languages
thanNC/A-O.However,whenbrokendownbylanguagefamily,asinFigure3,weseestarkdifferencesin
permitteduseby group. Code languagedatasetsarenearlyall commerciallyviable(78%),because dataset
creators can easily filter GitHub for permissively licensed repositories. Interestingly, English, Atlantic-Congo,
and Afroasiatic languages also see large permissive representation. However, Turkic, Sino-Tibetan, Japonic,
andIndo-Europeanlanguagesseeinexcessof35%asnon-commercial. NotethatwhiletheIndo-European
language family contains many high-resource European language families, there is a long tail of lower-
resource ones. These NC/A-O language families provide directions for open data practitioners to focus their
future efforts.
3.3 Broader Characteristics of the Data
In addition to understanding systematic differences in the data by license, there are research questions
regarding the overall composition and characteristics of these widely used and adopted datasets. Our
compilationofmetadatathroughtheDPCollectionallowsustomapthelandscapeofdatacharacteristics,
and inspect particular features. Note that all these details are also available with interactive visualizations at
www.comingsoon.com , for further research and examination.
§https://openai.com/policies/terms-of-use
11

--- PAGE 12 ---
0.2
0.4
0.6
0.8
1.0
Language DistributionFigure6: Aglobalheatmapmeasuringhowwelleachcountry’sspokenlanguagesarerepresentedbythe
compositionofnaturallanguagedatasetsin DPCollection,ascalculatedby Section3.3. English-speaking
and Western European nations are best represented, while the Global South sees limited coverage.
Language representation is heavily skewed to English and Western European Languages. Following Talat
et al. (2022)’s recommendations in data transparency and documentation in demographic analysis, and
corroboratingKreutzeretal.(2022)’ssimilaranalysisforpretrainingcorpora,wefindastarkWestern-centric
skew in representation. Figure 6 illustrates the coverage per country according to the spoken languages and
theirrepresentationinDPCollection. WecomputeaLanguageRepresentationscore Skforeachcountry k,
parametrized by pkl, thepercentage ofpeople incountry kthatspeak language l, and wliwhich isa binary
indicator that is 1 if dataset i∈Dcontains language land 0 otherwise.
Sk=X
l∈L 
pkl×X
i∈Dwli!
The distribution visualized in Figure 6 shows that Asian, African, and South American nations are sparsely
covered if at all. Even when nations from the Global South appear to have linguistic representation, accord-
ing to Section 3.3, the text source and dialect of the language contained in these datasets almost always
originatesfromNorth AmericanorEuropeancreatorsandweb sources(thoughthisisdifficultto measure
precisely). Theseobservationscorroboratesimilarfindingsinthegeo-diversityofimagedatainthevision
domain(Shankaretal.,2017;DeVriesetal.,2019;MahadevandChakravarti,2021). Theresultingmodels
trainedonthesedatasetsarelikelytohaveinherentbias,underperformingincriticalwaysforusersofmodels
outside of the west (Ahia et al., 2021).
The primary drivers of dataset curation are Academic organizations, supplying 69%, followed by 21%
industry labs, and 17% research institutions. These metrics describe the scale of dataset curation contribu-
tions, but not the influence each dataset has had on the community. Table 4a demonstrates the single largest
dataset contributors are AI2 (12.3%), University of Washington (8.9%), and Facebook AI Research (8.4%). It
is important to note that these contributors often only download and compile text from the Internet that was
originally written by other people.
12

--- PAGE 13 ---
Name Pct
Academic 68.7%
University of Washington 8.9%
Stanford University 6.8%
New York University 5.4%
University of Southern... 3.5%
Carnegie Mellon Univer... 3.5%
Saarland University 2.6%
Cardiff University 2.3%
Industry Lab 21.4%
Facebook AI Research 8.4%
Microsoft Research 4.1%
Google Research 2.9%
DeepMind 1.9%
Microsoft Semantic Mac... 0.9%
NAVER AI Lab 0.8%
Salesforce Research 0.7%
Research Group 17.1%
AI2 12.3%
CLUE team 0.5%
Alan Turing Institute 0.5%
CodeX 0.4%
Qatar Computing Resear... 0.4%
Barcelona Supercomputi... 0.4%
BigCode 0.2%
Corporation 15.8%
Google 2.1%
IBM 2.0%
Microsoft 1.4%
Wind Information Co. 1.4%
Snap Inc. 1.3%
Meta 1.1%
Synapse Développement 1.1%
Startup 4.0%
OpenAI 1.3%
NomicAI 0.8%
Omniscien Technologies 0.4%
Anthropic AI 0.2%
EightSleep 0.2%
Curai 0.2%
IMRSV Data Labs 0.2%
Other 0.7%
(a)CreatorsName Pct
Question Answering 36.0%
Question Answering 27.7%
Multiple Choice Questi... 3.9%
Information Extraction 1.8%
Text Classification 29.9%
Text Classification 16.1%
Sentiment Analysis 9.8%
Named Entity Recognition 4.3%
Natural Language Inf... 21.1%
Textual Entailment 14.6%
Natural Language Infer... 5.3%
Fact Verification 1.3%
Open-form Text Gener... 11.3%
Open-form Text Generation 2.2%
Title Generation 1.5%
Inverted Summarization 1.2%
Short Text Generation 10.9%
Question Generation 4.0%
Fill in The Blank 1.4%
Inverted Multiple-Choi... 0.9%
Dialog Generation 9.0%
Dialogue Generation 4.2%
Dialog Generation 3.7%
Dialogue Act Recognition 0.4%
Summarization 6.3%
Summarization 5.7%
Simplification 0.5%
Summarization of US Co... 0.1%
Logical and Mathemat... 6.0%
Logical Reasoning 2.3%
Data Analysis 2.0%
Algebraic Expression E... 1.2%
Code 4.8%
Response Ranking 4.4%
Translation 4.4%
Creative Writing 3.9%
Other 23.9%
(b)TopicsName Pct
Encyclopedias 21.5%
wikipedia.org 14.6%
wikihow.com 2.7%
dbpedia 1.4%
Social Media 15.9%
reddit 6.2%
twitter 4.0%
quora 1.6%
General Web 11.2%
undisclosed web 7.0%
commoncrawl.org 2.5%
data.world/samayo/coun... 0.6%
News 11.1%
cnn.com 1.6%
financial news 1.5%
press releases 1.4%
Entertainment 8.5%
opensubtitles.org 2.5%
imdb.com 1.6%
travel guides 1.3%
Code 5.7%
stackexchange.com 2.0%
github 1.2%
opus software projects 0.9%
Exams 5.6%
web exams 2.9%
gmat 1.1%
gre exams 0.9%
Books 4.9%
project gutenberg 2.0%
non-fiction books 1.3%
fiction books 1.3%
Governments 4.7%
Biomedical 3.2%
Search Queries 3.0%
Academic Papers 2.8%
Other 61.2%
(c)Domains & Sources
Table4: Asummaryof thedistribution of Creators ,Topics, andSourceDomains acrossall 1800+datasets.
Datasts can have multiple creators, text topics, and sources.
13

--- PAGE 14 ---
TextdatasetsfocusontopicsofLanguage&Linguistics,GeneralKnowledge,Logic,&Lifestyle. Priordata
collectionworkfocusespredominantlyondescribingdatasetsbytheirtaskcompositions(Sanhetal.,2021;
Wanget al.,2022a; Longpreet al.,2023a),but rarelyby theiractual topics(except (Gaoetal., 2020)in their
Appendix). Table 4b shows the most popular topics, clustered by category, with their representation across
datasets. LikemostNLPtasks,muchofthistextdatafocusesoncommunicationandlanguageunderstanding
topics, followed closely by general knowledge, routine, sports, and education.
Text datasets are sourced primarily from Online Encyclopedias (22%), Social Media (16%), scraped from
the General Web (11%), News (11%), Entertainment web resources (9%). While practitioners document
theirindividualdatasetsourcesintheirpublishedpapers,thisinformationisunstructuredandcanbehardto
find. As a result, massive collections of widely used datasets rarely compile the distribution of their original
sources, instead just citing the papers. After a series of dataset compilations and re-packaging, the original
sources are often lost or not well known. By manually scanning approximately 500 academic papers our
volunteers annotated the original text sources and compiled them into domain clusters, to permit attribution
andanalysis,as summarizedinTable4c. Among theindividual mostadopted sourcesby theused sources
arewikipedia.org(14.9%),undisclosedwebpagescrapes(7.0%),reddit(6.2%),andTwitter(4.0%). Theleast
represented domains are Commerce, Reviews, Legal, Academic Papers, and Search Queries, among others.
4 Legal Discussion
Our empirical analysis highlights that we are in the midst of a crisis in dataset provenance and practitioners
are forced to make decisions based on limited information and opaque legal frameworks. While we believe
our tooling will enable better transparency about where licenses are in tension, major legal ambiguities
remain in data licensing.
Background Copyrightlawsaimto encouragewrittenandartisticexpression by givingauthorsexclusive
rightstocopy,distribute,andadapttheirwork(Patterson,2003;Burger,1988). Open-sourcelicensesfirst
emergedaslegaltoolstoencouragecollaborationaroundsoftwaredevelopment(VonKroghandVonHippel,
2003). A range of licenses with different terms and purposes exists including the MIT License, Creative
CommonsLicenses,andtheApacheLicense,aswellasthenewerResponsibleAILicense(RAIL)andAI2
ImpACTLicenses.¶Theinterplaybetweencopyrightandlicensescanbeunderstoodinthefollowingway:
copyright automatically gives creators exclusive rights in their works and creators assign these rights to
others through license agreements. As we will explore, the open-source licenses that emerged in the last
three decades are not always well-equipped to handle the unique characteristics of data, and especially
supervisedAItrainingdata. Meanwhile,itremainsunclearhowrelevantlaws,includingthoserelatedto
copyrightandfairuse,shouldbeappliedtotheuniquechallengesraisedbyGenerativeAIandsupervised
datasets (Lee et al., 2023). In this section, we highlight some of the key legal challenges and ambiguities
related to supervised datasets.
Lifecycle of a dataset We focus on supervised datasets , which we define as datasets that are created for
machinelearning(mainlyforfinetuningandalignment)andwheredatasetcreatorsmadecopyrightable
contributions in the form of annotations or compilations. A typical supervised dataset is the result of a
process that involves several stages of scraping (or machine generation) and annotation by different entities.
Generally, raw data is created by people interacting with internet platforms, such as individuals writing
articles, sharing artworks, or engaging in online discussion forums. The copyrights to this raw data are
normallyheldbyindividualusers(e.g. Reddit)orbytheplatform(e.g. AmazonReviews). Muchofthis
datahasbeenscrapedtoconstructunsuperviseddatasetsformachinelearningandthisuseiscommonly
justified on the basis of fair use or data mining exceptions to copyright (Henderson et al., 2023; Sobel, 2017;
Leeetal.,2023;Samuelson,2023;LemleyandCasey,2020). However,wefindthatmanycommonsupervised
¶See https://www.licenses.ai/blog/2023/3/3/ai-pubs-rail-licenses and https://allenai.org/impact-license#
licenses . These license templates propose terms aimed at encouraging more responsible or risk-based machine learning practices, see
also Contractor et al. (2022)
14

--- PAGE 15 ---
datasetsaregeneratedbyannotatingsmallsamplesofscrapedrawdatausinghumanannotatorsorlarge
languagemodels. Theannotateddataisthenpublishedwithalicenseagreement. Instarkcontrasttothe
copyrighted content that is scraped from the web, supervised datasets were created for the sole purpose of
furtheringmachinelearning. Thefocusofthelegaldiscussioninthissectionisonhowsuperviseddataset
creatorscanconstraintheusageofthecopyrightablecontenttheycreatethroughlicensesandotherlegal
mechanisms. Though we do not address them here, there are several important related questions on the use
of copyrighted works to create supervised datasets and on the copyrightability of training datasets.
Surpervised Dataset Example: SQuAD
Rajpurkar et al. (2016) present a prototypical supervised dataset on reading comprehension. To
create the dataset, the authors take paragraph-long excerpts from 539 popular Wikipedia articles and
hirecrowd-sourceworkerstogenerateover100,000questionswhoseanswersarecontainedinthe
excerpt. For example:
Wikipedia Excerpt In meteorology, precipitation is any product of the condensation of atmospheric water
vapor that falls under gravity.
Worker-generated question: What causes precipitation to fall? Answer: Gravity
HeretheauthorsuseWikipediatextasabasisfortheirdataandtheirdatasetcontains100,000new
question-answer pairs based on these texts.
Copyrightlawsvarybyjurisdictionandaresubjective,soitischallengingtodeveloptechnicalsafeguards
that guarantee compliance. The legal analysis surrounding supervised datasets is complicated by the lack
of a uniform global legal framework to address copyright concerns. Different jurisdictions have different
andevolvinglaws. Therefore,thelocationofmodeldevelopersandtrainingdata creatorsaswellaswhere
and when data was collected may influence the legal analysis. For example, the United States has a fair-use
exception to copyright that allows the limited use of copyrighted material under certain circumstances
without requiring permission from the rights holders (17 U.S.C. §107) . The EU has no fair-use provision but
doeshaveanexplicitcopyrightexceptiontoallowdataminingundercertainconditions,likeobtaininglawful
accesstothedata(MargoniandKretschmer,2022). Meanwhile,datasetsthemselvesgenerallyenjoycopyright
protection in the U.S. (Lee et al., 2023) while the E.U. recently created a unique set of rights for dataset
creators with the purpose of incentivizing research and development related to databases (Derclaye and
Husovec,2022). Inadditiontodifferencesacrossjurisdictions,therearealsoseveralinternationalagreements
relatedtocopyrightRicketsonandGinsburg(2022). Ultimately,itcanbechallengingtodeterminewhich
lawsshouldapplytoagivenmachinelearningprojectwhentherelevantrulesvarybetweenthelocations
wherethedatawasscrapedandannotated,whereitwasdownloaded,wherethemodelwastrained,and
where the model was deployed.
While geographical disparities in regulatory frameworks present one set of challenges, the subjectivity
inherentindeterminingwhethercopyrightinfringementhasoccurredmakesitevenmorechallengingto
designtechnicalsafeguards. Forexample,intheU.S.partofthecopyrightinfringementanalysisdepends
onwhethertwoworksaresubjectivelysimilarfromtheperspectiveofanordinaryperson(Mohler,1999;
Cohen, 1986; Balganesh et al., 2014). This is a subjective standard and existing case law may be challenging
to extend to generative AI outputs. As a result, while there are technical strategies that can reduce the risk of
infringement (Henderson et al., 2023; Sag, 2023; Vyas et al., 2023), it will be difficult for developers to create
technical safeguards that eliminate this risk entirely.
Openlegalquestionregardingcopyrightandmodeltraining. Apartfromthesejurisdictionalandinter-
pretive ambiguities, the process of training a model raises specific copyright questions (Epstein et al., 2023).
Trainingamodelposesseveralinterestinglegalquestionswithrespecttocopyrightandinfringementmay
occur in several ways even before any outputs are generated.
First,theactofcreatingatrainingdatasetbyscrapingexistingworksinvolvesmakingadigitalcopyofthe
15

--- PAGE 16 ---
underlying data. As the name implies, copyright gives the author of a protected work the exclusive right to
make copies of that work. If the scraped data is protected by copyright, then creating training data corpora
mayraisecopyrightissues(Quang,2021). Second,copyrightholdersgenerallyhaveanexclusiverightto
createderivativeworks(e.g.,translationsofawork)butitisnotclearwhetheratrainedmachinelearning
modelshouldbeconsideredaderivativeofthetrainingdata(Leeetal.,2023). Ifmodelsareconsideredto
bederivativeworks,thentrainingamodelwouldbemorelikelytoviolatetherightsofthetrainingdata’s
copyright holders (Gervais, 2021).
In the U.S., the fair use exception may allow models to be trained on protected works (Henderson et al.,
2023; Lemley and Casey, 2020; Sobel, 2017; Samuelson, 2023). As these authors explain, the training of
machinelearningmodelsoncopyrightedcontentmaybepermissibleiftheunderlyingworksaresignificantly
“transformed” into model weights, only a small amount of each work in the training data is included in the
trainedmodel,modeltrainingisdesignedtoonlygleangeneralizableinsightsfromthetrainingdata,andthe
trainedmodeldoesnothaveastrongeffectontheeconomicsuccessoftheworksinthetrainingdata. Itis
importanttounderscorethat,whiletrainingamachinelearningmodelitselfmaybeprotectedbyfairusethis
doesnotmeanthatmodeloutputswillnotinfringeonthecopyrightofpriorworks. Astheauthorsabove
highlight,theapplicationoffairuseinthecontextisstillevolvingandseveraloftheseissuesarecurrently
being litigated (see e.g., Andersen v. Stability ,Doe v. GitHub , andTremblay v. OpenAI ).
Fair use is less likely to apply when works are created for the sole purpose of training machine learning
models as in the case of supervised datasets with copyrightable compositions or annotations. The prior
literature on fair use and machine learning tends to focus on copyrighted art or text that was scraped to train
a model. These scraped works were not created for the purpose of training machine learning models. By
contrast, inthis paper, we focuson supervised datasetsthatwerecreated forthesole purpose oftraining
machine learning models. As underscored by Henderson et al. (2023) and Sobel (2017), the fair use analysis
depends in part on whether a trained model copies the “expressive purpose” of the original work. While the
expressive purpose of a piece of text or art is not to train machine learning models, the purpose of a training
dataset is to do just that. As a result, we expect that it is less likely that fair use would apply to the use of
curated data. Instead, the creators of these datasets hold a copyright in the dataset‖and the terms of the
dataset license agreement govern the subsequent use of this data However, it is rare in practice for an LLM
to use a single supervised dataset and often multiple datasets are compiled into collections. This further
complicates the legal analysis because we find that the license terms of many popular dataset collections are
conflicting.
Licensesusedfordatasetsareoftenill-suitedforthispurpose. Beyondtheintricateinterplaybetween
training data and fair use, the frequently misapplied licensing frameworks for datasets present another set of
complications. Mostopen-sourcelicensesweredesignedforsoftware,butwefindthembeingattachedto
datasets. These licenses were intended to be applied to software, not data, which creates challenges (Meeker,
2022). One of thechallenges is that licenses like theApache and the Creative Commons outlinerestrictions
related to “derivative” or “adapted works” but it remains unclear if a trained model should be classified
asaderivativework. Thisissueisfurtherexacerbatedwhenmultipledatasets,eachpotentiallygoverned
byadifferentopen-sourcelicense,areamalgamatedintocollections. Iftherequirementsoftheunderlying
licenseagreementsareirreconcilable,suchasdifferentcopyleftrequirements,thismakesitextremelyhardfor
developers to use certain collections while respecting all license terms. To remedy these issues, new licenses
are being proposed to address the needs of machine learning datasets such as the BigScience Responsible AI
LicenseoranadaptationoftheMITLicensethatrequiresadditionalpermissionsformodeltrainingproposed
byIoannidisetal.(2023). Despitethesenewproposals,wefindthatthemajorityofdatasetsarelicensed
under conventional open-source licenses.
‖Data ownership and data copyright are complex topics (Ginsburg, 1992). We assume that the creators of supervised datasets have
some form of copyright in their dataset, though there is often content in these datasets that is owned by third parties. If they satisfy the
requirements for copyrightability, dataset creators would have a copyright interest in any new content they create (e.g. annotations). In
theU.S.,datasetsthemselvesmayalsobecopyrightableascompilations(Leeetal.,2023)whiletheE.U.providesso-called suigeneris
rights for databases (Derclaye and Husovec, 2022).
16

--- PAGE 17 ---
LLM-generated annotations raise additional legal considerations We find that approximately 12% of
the datasets we audit were annotated using OpenAI. The OpenAI Terms of Use state that outputs from the
OpenAI service may not be used to “to develop models that compete with OpenAI”∗∗. These terms seem to
preclude a developer from using OpenAI to generate training data to train a competing LLM. However, it is
notclearwhethertheywouldalsolimittheabilityofadevelopertouseOpenAItocreateandpublishan
annotated dataset. On the one hand, publishing such a dataset does not directly compete with OpenAI. On
the other hand, it seems foreseeable that such a dataset could enable third parties (who did not themselves
use OpenAI) to create competing LLMs. In the U.S., there are several doctrines of secondary or indirect
copyrightliabilityaimedtoenforcecopyrightincaseswherethereisnodirectinfringement(Grossman,2005;
Lee et al., 2023). The application of these doctrines depends on many factors, most importantly on whether
OpenAIhasacopyrightinterestinitsoutputs. Ifthesecopyrightdoctrinesdonotapply,thenitisstillpossible
that publishing the dataset constitutes a breach of contract by the dataset developers. While it would be
morechallengingforOpenAItopursueacaseagainstthirdparties,therearemyriadotherbusinesstorts,
fromunfaircompetitiontomisappropriation,thatmayberelevanttothissituation,andwhichgobeyondthe
scopeofthispaper(MarksandMoll,2023). TimewilltelltheextenttowhichOpenAIandotherLLMservice
providerscanenforcetheirtermsofuseagainstthirdparties. However,aprominentresearcheratGooglehas
already resigned citing concerns that OpenAI outputs were used to train BARD (Victor and Efrati, 2023) In
lightoftheselegalambiguities,ourtoolgivesdeveloperstheabilitytoexcludeOpenAI-generateddatasets.
While legal issues remain ambiguous, practitioners are making decisions on data use and model training.
In the face of these pervasive legal uncertainties, practitioners’ decisions regarding data usage are ultimately
guided by a blend of factors including the specific licensing terms, the origin of datasets, and the degree of
usageofagivendatasetbyothers. Navigatingthislandscaperequiresstrikingadelicatebalancebetweenrisk
mitigation and the need for sufficient resources. This equation, however, varies across regions, applications,
and corporate environments, influenced by factors such as competition, risk, and regional legislation. A
strategyforpartiallymitigatingtheseuncertaintiesisformodelproviderstoindemnifyusers,asdoneby
Google Cloud Suggs and Venables (2023). However, this may not be feasible for resource-constrained
developers and, while it protects end-users, it does not solve the issues faced by model developers or dataset
curators.
OurApproach. Thefundamentalpurposeofcopyrightistoencouragecreativityandinnovation. Aswe
highlighted in the sections above, the current legal landscape remains ambiguous and this lack of clarity can
stifleinnovationasdevelopersfearlegalrepercussions. Throughourauditandtooling,weseektoprovide
important information for practitioners to make informed decisions in an otherwise ambiguous landscape,
guided by their own own legal interpretation and risk tolerance. This information includes data license
lineages, a categorization of license terms, details on data creators, and the underlying data sources (e.g.
webor LLM).In lightofongoing litigationand alackof legalcertainty, weattempted togivedevelopers In
creatingarepositoryofdatalicensinginformation,wearealsotakingasteptowardsencouragingdataset
creators to be more thoughtful about the licenses that they select. Dataset creators are well-positioned to
understand the appropriate uses of the datasets they publish and licenses can be a tool to communicate
these restrictions and to encourage responsible AI development. We further aim to highlight that machine
learningpractitionersshouldtakedatasetlicensetermsseriously,astheymayhaverealimpactsonhowtheir
models maybe used inpractice. Ultimately, thoughtfuldata licensing couldbe leveraged topromote more
responsible, inclusive, and transparent machine learning practices.
NOTICE: Collected License Information is NOT Legal Advice. It is important to note we collect self-
reportedlicenses, and categorize them according to our best efforts, as a volunteer research and transparency
initiative. The information provided by any of our works and any outputs of the Data Provenance Initiative
donot,andarenotintendedto,constitutelegaladvice;instead,allinformation,content,andmaterialsare
for general informational purposes only. Readers and users should seek their own legal advice from counsel
in their relevant jurisdiction.
∗∗https://openai.com/policies/terms-of-use
17

--- PAGE 18 ---
5 Related Work
Data Documentation A long line of work has highlighted the importance of data and its documentation in
natural languageprocessing (Paulladaet al.,2021; Rogers,2021; Meyeret al.,2023; Gururangan etal., 2018;
Muennighoff et al., 2023b). In particular, these works stress the challenges posed by poor documentation to
reproducibility,goodscience,andgenerallywell-understoodmodelbehavior(Sambasivanetal.,2021a;Bandy
and Vincent, 2021; Longpre et al., 2023b). Recent work has also explored the importance of documenting AI
ecosystems (Bommasani et al., 2023b) and the supply chain from data to models (Cen et al., 2023).
Data Analysis and Exploration Several notable works have conducted large-scale analyses into data,
particularlypretrainingtextcorpora(Gaoetal.,2020;Dodgeetal.,2021;Kreutzeretal.,2022;Laurençonetal.,
2022;Scaoetal.,2022a,b;McMillan-Majoretal.,2022). Otherworkshaveinvestigatedthegeo-diversityof
vision-based datasets (Shankar et al., 2017; De Vries et al., 2019; Mahadev and Chakravarti, 2021). Different
forms of data governance have been proposed to centralize responsibility and documentation over datasets,
including for the BigScience project (Jernite et al., 2022) and a Public Data Trust (Chan et al., 2023). In
terms of finding and visualizing datasets, a few recent tools have been proposed (Färber and Leisinger, 2021;
Viswanathan et al., 2023).
Transparencyandaccountability Adjacenttotherealmoflegality,priorworkshavestronglyadvocated
and provided frameworks for documentation and audits to increase transparency and accountability in
AI systems (Miceli et al., 2022; Kapoor et al., 2023; Raji and Buolamwini, 2022). In a manner akin to DPI,
which draws upon the collective knowledge of legal and machine learning experts, earlier research has also
underscored the significance of interdisciplinary collaborations (Hutchinson et al., 2021). Datasheets for
datasets Gebru et al. (2021) and Data Statements Bender and Friedman (2018) both provide structured
frameworksforrevealingessentialmetadatasuchasthemotivationbehindintendeduse. Pushkarnaetal.
(2022) expanded on datasheets with “Data Cards” for sources, collection, ethics, and adoption.
Similarly,Mitchelletal.(2019)introducedmodelcardstobenchmarkmodelperformanceacrossdemographic
groups and disclose evaluation procedures. Crisan et al. (2022) proposed interactive model card as an
alternativemodeofdocumentationandmetadatasharing. Complementarytotransparencyregardingthe
dataset’s creation process, Corry et al. (2021) provide a framework that guides users on how to navigate
datasets as they approach the end of their life-cycle. DPI builds upon the foundational frameworks laid out
intheseearlierstudies,withaspecificfocusonaddressingthelicensingaspectsofdatasetcuration. Ourgoal
is to equip users with a comprehensive understanding of the legal risks associated with dataset usage.
Datasetlegality Thelegalityofthedatasetsusedtotrainlargebasemodelshasrecentlyreceivedsignificant
attention(Sag,2020;Hendersonetal.,2023). Thechallengeofdeterminingthelegalityofemployingdifferent
datasetsbecomesparticularlycomplexduetotheintricatenatureofdatasetcreationprocesses. Leeetal.
(2023) break up the stages of dataset creation and model generation and assess the relevant copyright
questionsintheUSlegalsystem. Theseprocessesofteninvolvemultiplelicensesandrestrictionsthatcan
interact in ways that obscure the final legal risk. Soh (2021) propose a high-level framework for pinpointing
theareaswithindatasetcreationandusagewherelegalanalysisisnecessary,butdonotapplythisframework
to any existing datasets. Min et al. (2023) demonstrate that refraining from training on copyrighted or highly
restricted datasets has a detrimental impact on downstream performance. Their proposed solution involves
using a language model trained on "low-risk" text and augmenting it with a data-store containing "high-risk"
textwhichcanbemodifiedappropriatelyasthelegallandscapeclarifiesovertime. (Leeetal.,2023)DPI
enhances theseinvestigations by involvinglegalexperts inthe development ofa framework forassessing a
dataset’s “risk” and annotating the “risk” associated with numerous existing high-profile datasets.
18

--- PAGE 19 ---
Acknowledgements
WewouldliketothankKatherineLee,A.FederCooper,PeterHenderson,AviyaSkowronandStellaBiderman
for valuable comments and feedback.
References
Orevaoghene Ahia, Julia Kreutzer, and Sara Hooker. The low-resource double bind: An empirical study of
pruningforlow-resourcemachinetranslation. In FindingsoftheAssociationforComputationalLinguistics:
EMNLP2021 ,pages3316–3333,PuntaCana,DominicanRepublic,November2021.AssociationforCompu-
tationalLinguistics. doi: 10.18653/v1/2021.findings-emnlp.282. URL https://aclanthology.org/2021.
findings-emnlp.282 .
YuvaneshAnand,ZachNussbaum,BrandonDuderstadt,BenjaminSchmidt,andAndriyMulyar. Gpt4all:
Traininganassistant-stylechatbotwithlargescaledatadistillationfromgpt-3.5-turbo. https://github.
com/nomic-ai/gpt4all , 2023.
Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak
Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. Palm 2 technical report. arXiv preprint
arXiv:2305.10403 , 2023.
Anthropic. Model card and evaluations for claude models. 2023.
Arstechnica. Stable diffusion copyright lawsuits could be a legal earthquake for ai, 2023. URL
https://arstechnica.com/tech-policy/2023/04/stable-diffusion-copyright-lawsuits-could-
be-a-legal-earthquake-for-ai/ .
YuntaoBai,AndyJones,KamalNdousse,AmandaAskell,AnnaChen,NovaDasSarma,DawnDrain,Stanislav
Fort,DeepGanguli,TomHenighan,etal. Trainingahelpfulandharmlessassistantwithreinforcement
learning from human feedback. arXiv preprint arXiv:2204.05862 , 2022.
Shyamkrishna Balganesh, Irina D Manta, and Tess Wilkinson-Ryan. Judging similarity. Iowa Law Review , 100:
267, 2014.
Jack Bandy and Nicholas Vincent. Addressing “documentation debt” in machine learning research: A
retrospective datasheet for bookcorpus. arXiv preprint arXiv:2105.05241 , 2021.
EmilyMBender. Onachievingandevaluatinglanguage-independenceinnlp. LinguisticIssuesinLanguage
Technology , 6, 2011.
Emily M. Bender and Batya Friedman. Data statements for natural language processing: Toward mitigating
system bias and enabling better science. Transactions of the Association for Computational Linguistics , 6:
587–604, 2018. doi: 10.1162/tacl_a_00041. URL https://aclanthology.org/Q18-1041 .
Stella Biderman, Kieran Bicheno, and Leo Gao. Datasheet for the pile. arXiv preprint arXiv:2201.07311 , 2022.
RishiBommasani,KevinKlyman,ShayneLongpre,SayashKapoor,NestorMaslej,BettyXiong,DanielZhang,
and Percy Liang. The foundation model transparency index, 2023a.
RishiBommasani, DilaraSoylu, ThomasLiao,Kathleen A.Creel,and PercyLiang. Ecosystem graphs: The
social footprint of foundation models. ArXiv, abs/2303.15772, 2023b. URL https://arxiv.org/abs/2303.
15772.
Rishi Bommasani, Dilara Soylu, Thomas I Liao, Kathleen A Creel, and Percy Liang. Ecosystem graphs: The
social footprint of foundation models. arXiv preprint arXiv:2303.15772 , 2023c.
19

--- PAGE 20 ---
SébastienBubeck,VarunChandrasekaran,RonenEldan,JohannesGehrke,EricHorvitz,EceKamar,PeterLee,
YinTatLee,YuanzhiLi,ScottLundberg,etal. Sparksofartificialgeneralintelligence: Earlyexperiments
with gpt-4. arXiv preprint arXiv:2303.12712 , 2023.
Peter Burger. The berne convention: Its history and its key role in the future. Journal of Law and Technology , 3:
1, 1988.
NicholasCarlini,DaphneIppolito,MatthewJagielski,KatherineLee,FlorianTramer,andChiyuanZhang.
Quantifying memorization across neural language models. In The Eleventh International Conference on
Learning Representations , 2022.
SarahH.Cen,AspenHopkins,AndrewIlyas,AleksanderMadry,IsabellaStruckman,andLuisVidegaray.
Ai supply chains (and why they matter), April 2023. URL https://aipolicy.substack.com/p/supply-
chains-2 . The second post in our series On AI Deployment.
Alan Chan, Herbie Bradley, and Nitarshan Rajkumar. Reclaiming the digital commons: A public data trust
for training data. arXiv preprint arXiv:2303.09001 , 2023.
Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang,
MostafaDehghani,SiddharthaBrahma,etal. Scalinginstruction-finetunedlanguagemodels. arXivpreprint
arXiv:2210.11416 , 2022.
Amy B Cohen. Masking copyright decisionmaking: The meaninglessness of substantial similarity. UC Davis
Law Review , 20:719, 1986.
Mike Conover, Matt Hayes, Ankit Mathur, Xiangrui Meng, Jianwei Xie, Jun Wan, Sam Shah, Ali Gh-
odsi, Patrick Wendell, Matei Zaharia, and Reynold Xin. Free dolly: Introducing the world’s first
trulyopeninstruction-tunedllm. https://www.databricks.com/blog/2023/04/12/dolly-first-open-
commercially-viable-instruction-tuned-llm , 2023.
Danish Contractor, Daniel McDuff, Julia Katherine Haines, Jenny Lee, Christopher Hines, Brent Hecht,
NicholasVincent,andHanlinLi. Behavioraluselicensingforresponsibleai. In Proceedingsofthe2022ACM
Conference on Fairness, Accountability, and Transparency , pages 778–788, 2022.
FrancesCorry,HamsiniSridharan,AlexandraSashaLuccioni,MikeAnanny,JasonSchultz,andKateCrawford.
Theproblemofzombiedatasets: Aframeworkfordeprecatingdatasets. ArXiv,abs/2111.04424,2021. URL
https://arxiv.org/abs/2111.04424 .
AnamariaCrisan,MargaretDrouhard,JesseVig,andNazneenRajani. Interactivemodelcards: Ahuman-
centered approach to model documentation. In Proceedings of the 2022 ACM Conference on Fairness, Account-
ability, and Transparency , pages 427–439, 2022.
TerranceDeVries,IshanMisra,ChanghanWang,andLaurensVanderMaaten. Doesobjectrecognitionwork
for everyone? In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops ,
pages 52–59, 2019.
EstelleDerclayeandMartinHusovec. Suigenerisdatabaseprotection2.0: judicialandlegislativereforms.
European Intellectual Property Review , 44(6):323–331, 2022.
NingDing,YulinChen,BokaiXu,YujiaQin,ZhiZheng,ShengdingHu,ZhiyuanLiu,MaosongSun,and
Bowen Zhou. Enhancing chat language models by scaling high-quality instructional conversations, 2023.
Jesse Dodge, Maarten Sap, Ana Marasović, William Agnew, Gabriel Ilharco, Dirk Groeneveld, Margaret
Mitchell, and Matt Gardner. Documenting large webtext corpora: A case study on the colossal clean
crawledcorpus. In Proceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing ,
pages 1286–1305, 2021.
Jon Durbin. Airoboros: Using large language models to fine-tune large language models. https://github.
com/jondurbin/airoboros , 2023.
20

--- PAGE 21 ---
AparnaElangovan,JiayuanHe,andKarinVerspoor. Memorizationvs.generalization: Quantifyingdata
leakageinNLPperformanceevaluation. In Proceedingsofthe16thConferenceoftheEuropeanChapterofthe
AssociationforComputationalLinguistics: MainVolume ,pages1325–1335,Online,April2021.Association
for Computational Linguistics. doi: 10.18653/v1/2021.eacl-main.113. URL https://aclanthology.org/
2021.eacl-main.113 .
Ronen Eldan and Yuanzhi Li. Tinystories: How small can language models be and still speak coherent
english?, 2023.
Ziv Epstein, Aaron Hertzmann, Laura Herman, Robert Mahari, Morgan R Frank, Matthew Groh, Hope
Schroeder, Amy Smith, Memo Akten, Jessica Fjeld, et al. Art and the science of generative ai. Science, 380
(6650):1110–1111, 2023.
Kawin Ethayarajh, Heidi Zhang, Yizhong Wang, and Dan Jurafsky. Stanford human preferences dataset,
2023. URL https://huggingface.co/datasets/stanfordnlp/SHP .
MichaelFärberandAnn-KathrinLeisinger. Datahunter: Asystemforfindingdatasetsbasedonscientific
problemdescriptions. In Proceedingsofthe15thACMConferenceonRecommenderSystems ,pages749–752,
2021.
JonathanFrankle. Tweetbymosaicml. https://twitter.com/jefrankle/status/1654848529834078208 ,
2023.
Deep Ganguli, Liane Lovitt, Jackson Kernion, Amanda Askell, Yuntao Bai, Saurav Kadavath, Ben Mann,
Ethan Perez, Nicholas Schiefer, Kamal Ndousse, et al. Red teaming language models to reduce harms:
Methods, scaling behaviors, and lessons learned. 2022.
Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace
He, Anish Thite, Noa Nabeshima, et al. The pile: An 800gb dataset of diverse text for language modeling.
arXiv preprint arXiv:2101.00027 , 2020.
TimnitGebru,JamieMorgenstern,BrianaVecchione,JenniferWortmanVaughan,HannaWallach,HalDaumé
Iii, and Kate Crawford. Datasheets for datasets. Communications of the ACM , 64(12):86–92, 2021.
Xinyang Geng, Arnav Gudibande, Hao Liu, Eric Wallace, Pieter Abbeel, Sergey Levine, and Dawn Song.
Koala: A dialogue model for academic research. Blog post, April 2023. URL https://bair.berkeley.
edu/blog/2023/04/03/koala/ .
DanielJGervais.Aiderivatives: Theapplicationtothederivativeworkrighttoliteraryandartisticproductions
of ai machines. Seton Hall L. Rev. , 52:1111, 2021.
JaneCGinsburg. Nosweatcopyrightandotherprotectionofworksofinformationafterfeistv.ruraltelephone.
Columbia Law Review , 92:338, 1992.
CraigAGrossman. Fromsonytogrokster,thefailureofthecopyrightdoctrinesofcontributoryinfringement
and vicarious liability to resolve the war between content and destructive technologies. Buffalo Law Review ,
53:141, 2005.
Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang, Jinran Nie, Yuxuan Ding, Jianwei Yue, and Yupeng Wu.
How close is chatgpt to human experts? comparison corpus, evaluation, and detection, 2023.
Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel Bowman, and Noah A. Smith.
Annotationartifactsinnaturallanguageinferencedata. In Proceedingsofthe2018ConferenceoftheNorth
AmericanChapteroftheAssociationforComputationalLinguistics: HumanLanguageTechnologies,Volume2(Short
Papers), pages 107–112, New Orleans, Louisiana, June 2018. Association for Computational Linguistics.
doi: 10.18653/v1/N18-2017. URL https://aclanthology.org/N18-2017 .
PeterHenderson,XuechenLi,DanJurafsky,TatsunoriHashimoto,MarkALemley,andPercyLiang. Founda-
tion models and fair use. arXiv preprint arXiv:2303.15715 , 2023.
21

--- PAGE 22 ---
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.
Measuringmassivemultitasklanguageunderstanding.In InternationalConferenceonLearningRepresentations ,
2020.
Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. Unnatural instructions: Tuning language
models with (almost) no human labor, 2022.
BenHutchinson,AndrewSmart,AlexHanna,EmilyDenton,ChristinaGreer,OddurKjartansson,Parker
Barnes, and Margaret Mitchell. Towards accountability for machine learning datasets: Practices from
softwareengineeringandinfrastructure. In Proceedingsofthe2021ACMConferenceonFairness,Accountability,
andTransparency ,FAccT’21,page560–575,NewYork,NY,USA,2021.AssociationforComputingMachinery.
ISBN 9781450383097. doi: 10.1145/3442188.3445918. URL https://doi.org/10.1145/3442188.3445918 .
DimitriosIoannidis,JeremyKepner,AndrewBowne,andHarrietSBryant. Arechatgptandothersimilar
systems the modern lernaean hydras of ai? arXiv preprint arXiv:2306.09267 , 2023.
YacineJernite,HuuNguyen,StellaBiderman,AnnaRogers,MaraimMasoud,ValentinDanchev,Samson
Tan, Alexandra Sasha Luccioni, Nishant Subramani, Isaac Johnson, et al. Data governance in the age
of large-scale data-driven language technology. In Proceedings of the 2022 ACM Conference on Fairness,
Accountability, and Transparency , pages 2206–2222, 2022.
Sayash Kapoor, Emily F. Cantrell, Kenny Peng, Thanh Hien Pham, Christopher A. Bail, Odd Erik Gundersen,
JakeM.Hofman,JessicaR.Hullman,MichaelA.Lones,MominM.Malik,PriyankaNanayakkara,RusselA.
Poldrack,InioluwaDeborah Raji, MichaelRoberts, Matthew J.Salganik, Marta Serra-Garcia, BrandonM
Stewart,GillesVandewiele,andArvindNarayanan. Reforms: Reportingstandardsformachinelearning
based science. ArXiv, abs/2308.07832, 2023. URL https://arxiv.org/abs/2308.07832 .
Seungone Kim, Se June Joo, Doyoung Kim, Joel Jang, Seonghyeon Ye, Jamin Shin, and Minjoon Seo. The cot
collection: Improvingzero-shotandfew-shotlearningoflanguagemodelsviachain-of-thoughtfine-tuning,
2023.
Rodney Michael Kinney, Chloe Anastasiades, Russell Authur, Iz Beltagy, Jonathan Bragg, Alexandra Bu-
raczynski, Isabel Cachola, Stefan Candra, Yoganand Chandrasekhar, Arman Cohan, Miles Crawford,
DougDowney,JasonDunkelberger,OrenEtzioni,RobEvans,SergeyFeldman,JosephGorney,DavidW.
Graham,F.Q.Hu,ReganHuff,DanielKing,SebastianKohlmeier,BaileyKuehl,MichaelLangan,Daniel
Lin, Haokun Liu, Kyle Lo, Jaron Lochner, Kelsey MacMillan, Tyler Murray, Christopher Newell, Smita Rao,
ShauryaRohatgi,PaulLSayre,ZejiangShen,AmanpreetSingh,LucaSoldaini,ShivashankarSubramanian,
A. Tanaka, Alex D Wade, Linda M. Wagner, Lucy Lu Wang, Christopher Wilhelm, Caroline Wu, Jiangjiang
Yang, Angele Zamarron, Madeleine van Zuylen, and Daniel S. Weld. ArXiv, abs/2301.10140, 2023.
Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens, Ab-
dullahBarhoum,NguyenMinhDuc,OliverStanley,RichárdNagyfi,etal. Openassistantconversations–
democratizing large language model alignment. arXiv preprint arXiv:2304.07327 , 2023.
JuliaKreutzer,IsaacCaswell,LisaWang,AhsanWahab,DaanvanEsch,NasanbayarUlzii-Orshikh,Allahsera
Tapo, Nishant Subramani, Artem Sokolov, Claytone Sikasote, et al. Quality at a glance: An audit of
web-crawled multilingual datasets. Transactions of the Association for Computational Linguistics , 10:50–72,
2022.
WojciechKryściński,NazneenRajani,DivyanshAgarwal,CaimingXiong,andDragomirRadev. Booksum:
A collection of datasets for long-form narrative summarization, 2022.
AbdullatifKöksal,Timo Schick,AnnaKorhonen,and HinrichSchütze. Longform: Optimizinginstruction
tuning for long text generation with corpus extraction, 2023.
Hugo Laurençon, Lucile Saulnier, Thomas Wang, Christopher Akiki, Albert Villanova del Moral, Teven
Le Scao, Leandro Von Werra, Chenghao Mou, Eduardo González Ponferrada, Huu Nguyen, Jörg Fro-
hberg,MarioŠaško,QuentinLhoest,AngelinaMcMillan-Major,GerardDupont,StellaBiderman,Anna
22

--- PAGE 23 ---
Rogers,LoubnaBenallal,FrancescoDeToni,GiadaPistilli,OlivierNguyen,SomaiehNikpoor,Maraim
Masoud, Pierre Colombo, Javier de la Rosa, Paulo Villegas, Tristan Thrush, Shayne Longpre, Sebastian
Nagel, Leon Weber, Manuel Muñoz, Jian Zhu, Daniel Van Strien, Zaid Alyafeai, Khalid Almubarak,
Minh Chien Vu, Itziar Gonzalez-Dios, Aitor Soroa, Kyle Lo, Manan Dey, Pedro Ortiz Suarez, Aaron
Gokaslan,ShamikBose,DavidAdelani,LongPhan,HieuTran,IanYu,SuhasPai,JennyChim,Violette
Lepercq, Suzana Ilic, Margaret Mitchell, Sasha Alexandra Luccioni, and Yacine Jernite. The bigscience
roots corpus: A 1.6tb composite multilingual dataset. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave,
K.Cho,andA.Oh,editors, AdvancesinNeuralInformationProcessingSystems ,volume35,pages31809–31826.
CurranAssociates,Inc.,2022. URL https://proceedings.neurips.cc/paper_files/paper/2022/file/
ce9e92e3de2372a4b93353eb7f3dc0bd-Paper-Datasets_and_Benchmarks.pdf .
KatherineLee, AFederCooper, andJamesGrimmelmann. Talkin”boutaigeneration: Copyright andthe
generative-ai supply chain. arXiv preprint arXiv:2309.08133 , 2023.
Mark A Lemley and Bryan Casey. Fair learning. Texas Law Review , 99:743, 2020.
Quentin Lhoest, Albert Villanova del Moral, Yacine Jernite, Abhishek Thakur, Patrick von Platen, Suraj Patil,
JulienChaumond,MariamaDrame,JulienPlu,LewisTunstall,etal. Datasets: Acommunitylibraryfor
natural language processing. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language
Processing: System Demonstrations , pages 175–184, 2021.
Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. Camel:
Communicative agents for "mind" exploration of large scale language model society, 2023a.
RaymondLi,LoubnaBenAllal,YangtianZi,NiklasMuennighoff,DenisKocetkov,ChenghaoMou,Marc
Marone,ChristopherAkiki,JiaLi,JennyChim,QianLiu,EvgeniiZheltonozhskii,TerryYueZhuo,Thomas
Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, João Monteiro, Oleh Shliazhko, Nicolas
Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin
Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva Sankalp Patel, Dmitry
Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Wenhao Yu,
SwayamSingh,SashaLuccioni,PauloVillegas,MaximKunakov,FedorZhdanov,ManuelRomero,Tony
Lee,NadavTimor,JenniferDing,ClaireSchlesinger,HaileySchoelkopf,JanEbert,TriDao,MayankMishra,
AlexGu,JenniferRobinson,CarolynJaneAnderson,BrendanDolan-Gavitt,DanishContractor,SivaReddy,
Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Muñoz Ferrandis, Sean Hughes, Thomas Wolf,
Arjun Guha, Leandro von Werra, and Harm de Vries. Starcoder: may the source be with you!, 2023b.
ShayneLongpre,LeHou,TuVu,AlbertWebson,HyungWonChung,YiTay,DennyZhou,QuocVLe,Barret
Zoph,JasonWei,etal. Theflancollection: Designingdataandmethodsforeffectiveinstructiontuning.
arXiv preprint arXiv:2301.13688 , 2023a.
Shayne Longpre, Gregory Yauney, Emily Reif, Katherine Lee, Adam Roberts, Barret Zoph, Denny Zhou,
Jason Wei, Kevin Robinson, David Mimno, and Daphne Ippolito. A pretrainer’s guide to training data:
Measuring the effects of data age, domain coverage, quality, & toxicity, 2023b.
Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei
Lin,andDaxinJiang. Wizardcoder: Empoweringcodelargelanguagemodelswithevol-instruct. arXiv
preprint arXiv:2306.08568 , 2023.
RohanMahadevandAnindyaChakravarti. Understandinggenderandracialdisparitiesinimagerecognition
models. arXiv preprint arXiv:2107.09211 , 2021.
Thomas Margoni and Martin Kretschmer. A deeper look into the eu text and data mining exceptions:
harmonisation, data ownership, and the future of technology. GRUR International , 71(8):685–701, 2022.
Colin P. Marks and Douglas K. Moll. The Law of Business Torts and Unfair Competition: Cases, Materials,
and Problems . American Casebook Series. West Academic, 2023. ISBN 9781647084905. URL https:
//books.google.com/books?id=K1fXzwEACAAJ .
23

--- PAGE 24 ---
Angelina McMillan-Major, Zaid Alyafeai, Stella Biderman, Kimbo Chen, Francesco De Toni, Gérard Dupont,
Hady Elsahar, Chris Emezue, Alham Fikri Aji, Suzana Ilić, et al. Documenting geographically and
contextually diverse data sources: The bigscience catalogue of language data and resources. arXiv preprint
arXiv:2201.10066 , 2022.
HeatherMeeker. Beyondopendata: Theonlygoodlicenseisnolicense. PLIChronicle: InsightsandPerspectives
for the Legal Community , April 2022.
AnnaP.Meyer,AwsAlbarghouthi,andLorisD’Antoni. Thedatasetmultiplicityproblem: Howunreliable
dataimpactspredictions. In Proceedingsofthe2023ACMConferenceonFairness,Accountability,andTrans-
parency, FAccT ’23, page 193–204, New York, NY, USA, 2023. Association for Computing Machinery. ISBN
9798400701924. doi: 10.1145/3593013.3593988. URL https://doi.org/10.1145/3593013.3593988 .
MilagrosMiceli,TianlingYang,AdrianaAlvaradoGarcia,JulianPosada,SonjaMeiWang,MarcPohl,and
Alex Hanna. Documenting data production processes: A participatory approach for data work. volume 6,
New York, NY, USA, nov 2022. Association for Computing Machinery. doi: 10.1145/3555623. URL
https://doi.org/10.1145/3555623 .
Sewon Min, Suchin Gururangan, Eric Wallace, Hanna Hajishirzi, Noah A. Smith, and Luke Zettlemoyer. Silo
language models: Isolating legal risk in a nonparametric datastore. ArXiv, abs/2308.04430, 2023. URL
https://arxiv.org/abs/2308.04430 .
MargaretMitchell,SimoneWu,AndrewZaldivar,ParkerBarnes,LucyVasserman,BenHutchinson,Elena
Spitzer,Inioluwa DeborahRaji,andTimnitGebru. Modelcardsfor modelreporting. In Proceedingsof the
conference on fairness, accountability, and transparency , pages 220–229, 2019.
JarrodMMohler. Towardabetterunderstandingofsubstantialsimilarityincopyrightinfringementcases. U.
Cin. L. Rev. , 68:971, 1999.
Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao,
M Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey Schoelkopf, et al. Crosslingual generalization through
multitask finetuning. arXiv preprint arXiv:2211.01786 , 2022.
Niklas Muennighoff, Qian Liu, Armel Zebaze, Qinkai Zheng, Binyuan Hui, Terry Yue Zhuo, Swayam Singh,
XiangruTang,LeandrovonWerra,andShayneLongpre. Octopack: Instructiontuningcodelargelanguage
models. arXiv preprint arXiv:2308.07124 , 2023a.
NiklasMuennighoff,AlexanderMRush,BoazBarak,TevenLeScao,AleksandraPiktus,NouamaneTazi,
Sampo Pyysalo, Thomas Wolf, and Colin Raffel. Scaling data-constrained language models. arXiv preprint
arXiv:2305.16264 , 2023b.
Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed
Awadallah. Orca: Progressive learning from complex explanation traces of gpt-4, 2023.
Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse,
ShantanuJain,VineetKosaraju,WilliamSaunders,etal. Webgpt: Browser-assistedquestion-answering
with human feedback. arXiv preprint arXiv:2112.09332 , 2021.
Huu Nguyen, Sameer Suri, Ken Tsui, and Christoph Schuhmann. The open instruction generalist (oig)
dataset. https://laion.ai/blog/oig-dataset/ , 2023.
OpenAI. Gpt-4 technical report, 2023.
Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang,
Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with
human feedback. arXiv preprint arXiv:2203.02155 , 2022. URL https://arxiv.org/abs/2203.02155 .
ShishirG.Patil,TianjunZhang,XinWang,andJosephE.Gonzalez. Gorilla: Largelanguagemodelconnected
with massive apis, 2023.
24

--- PAGE 25 ---
LPatterson. Copyrightin1791: Anessayconcerningthefouners’viewofthecopyrightpowergrantedto
congress in article i, section 8, clause 8 of the us constitution. Emory Law Journal , 52:909, 2003.
Amandalynne Paullada, Inioluwa Deborah Raji, Emily M Bender, Emily Denton, and Alex Hanna. Data and
its (dis) contents: A survey of dataset development and use in machine learning research. Patterns, 2(11),
2021.
Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza
Alobeidli,BaptistePannier,EbtesamAlmazrouei, andJulienLaunay. TheRefinedWebdatasetforFalcon
LLM:outperformingcuratedcorporawithwebdata,andwebdataonly. arXivpreprintarXiv:2306.01116 ,
2023. URL https://arxiv.org/abs/2306.01116 .
BaolinPeng,ChunyuanLi,PengchengHe,MichelGalley,andJianfengGao. Instructiontuningwithgpt-4.
arXiv preprint arXiv:2304.03277 , 2023.
Aleksandar Petrov, Emanuele La Malfa, Philip HS Torr, and Adel Bibi. Language model tokenizers introduce
unfairness between languages. arXiv preprint arXiv:2305.15425 , 2023.
Luiza Pozzobon, Beyza Ermis, Patrick Lewis, and Sara Hooker. On the challenges of using black-box apis for
toxicity evaluation in research, 2023.
Mahima Pushkarna, Andrew Zaldivar, and Oddur Kjartansson. Data cards: Purposeful and transpar-
ent dataset documentation for responsible ai. In 2022 ACM Conference on Fairness, Accountability, and
Transparency , pages 1776–1826, 2022.
Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang,
BillQian,SihanZhao,RunchuTian,RuobingXie,JieZhou,MarkGerstein,DahaiLi,ZhiyuanLiu,and
Maosong Sun. Toolllm: Facilitating large language models to master 16000+ real-world apis, 2023.
Jenny Quang. Does training ai violate copyright law? Berkeley Tech. LJ , 36:1407, 2021.
Inioluwa Deborah Raji and Joy Buolamwini. Actionable auditing revisited: Investigating the impact of
publicly naming biased performance results of commercial ai products. Communications of the ACM , 66(1):
101–108, 2022.
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. Squad: 100,000+ questions for machine
comprehension of text. arXiv preprint arXiv:1606.05250 , 2016.
Sam Ricketson and Jane C. Ginsburg. International Copyright and Neighboring Rights: The Berne Convention and
Beyond. Oxford University Press, August 2022.
Anna Rogers. Changing the world by changing the data. In Proceedings of the 59th Annual Meeting of
the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language
Processing (Volume 1: Long Papers) , pages 2182–2194, Online, August 2021. Association for Computational
Linguistics. doi: 10.18653/v1/2021.acl-long.170. URL https://aclanthology.org/2021.acl-long.170 .
Matthew Sag. Copyright safety for generative ai. Forthcoming in the Houston Law Review , 2023.
MatthewJ.Sag. Thenewlegallandscapefortextminingandmachinelearning. In JournaloftheCopyright
Society of the USA , 2020.
Nithya Sambasivan, Shivani Kapania, Hannah Highfill, Diana Akrong, Praveen Paritosh, and Lora M Aroyo.
“everyone wants to do the model work, not the data work”: Data cascades in high-stakes ai. In Proceedings
of the 2021 CHI Conference on Human Factors in Computing Systems , CHI ’21, New York, NY, USA, 2021a.
Association for Computing Machinery. ISBN 9781450380966. doi: 10.1145/3411764.3445518. URL https:
//doi.org/10.1145/3411764.3445518 .
Nithya Sambasivan, Shivani Kapania, Hannah Highfill, Diana Akrong, Praveen Paritosh, and Lora M Aroyo.
“Everyone wants to do the model work, not the data work”: Data cascades in high-stakes AI. In CHI,
CHI ’21, New York, NY, USA, 2021b. Association for Computing Machinery. ISBN 9781450380966. doi:
10.1145/3411764.3445518. URL https://doi.org/10.1145/3411764.3445518 .
25

--- PAGE 26 ---
Pamela Samuelson. Generative ai meets copyright. Science, 381(6654):158–161, 2023.
VictorSanh,AlbertWebson,ColinRaffel,StephenH.Bach,LintangSutawika,ZaidAlyafeai,AntoineChaffin,
Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. Multitask prompted training enables zero-shot task
generalization. ICLR 2022 , 2021. URL https://arxiv.org/abs/2110.08207 .
JosephR.Saveri,CadioZirpoli,ChristopherK.L.Young,andKathleenJ.McMahon.Paultremblay,monaawad
vs. openai, inc., et al., 2023. URL https://storage.courtlistener.com/recap/gov.uscourts.cand.
414822/gov.uscourts.cand.414822.1.0_1.pdf . Case3:23-cv-03223-AMODocument1Filed06/28/23,
UNITED STATES DISTRICT COURT, NORTHERN DISTRICT OF CALIFORNIA, SAN FRANCISCO
DIVISION.
TevenLeScao,AngelaFan,ChristopherAkiki,ElliePavlick,SuzanaIlić,DanielHesslow,RomanCastagné,
Alexandra Sasha Luccioni, François Yvon, Matthias Gallé, et al. Bloom: A 176b-parameter open-access
multilingual language model. arXiv preprint arXiv:2211.05100 , 2022a.
TevenLeScao,ThomasWang,DanielHesslow,LucileSaulnier,StasBekman,MSaifulBari,StellaBideman,
Hady Elsahar, Niklas Muennighoff, Jason Phang, et al. What language model to train if you have one
million gpu hours? arXiv preprint arXiv:2210.15424 , 2022b.
Shreya Shankar, Yoni Halpern, Eric Breck, James Atwood, Jimbo Wilson, and D Sculley. No classification
withoutrepresentation: Assessinggeodiversityissuesinopendatasetsforthedevelopingworld. arXiv
preprint arXiv:1711.08536 , 2017.
Damien Sileo. tasksource: A dataset harmonization framework for streamlined nlp multi-task learning and
evaluation. arXiv, abs/2301.05948, 2023.
Benjamin LW Sobel. Artificial intelligence’s fair use crisis. Columbia Journal of Law & the Arts , 41:45, 2017.
JerroldSoh.Buildinglegaldatasets. ArXiv,abs/2111.02034,2021.URL https://arxiv.org/abs/2111.02034 .
Spacerini. Gaia search tool. 2021. URL https://huggingface.co/spaces/spacerini/gaia .
Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch,
AdamRBrown,AdamSantoro,AdityaGupta,AdriàGarriga-Alonso,etal. Beyondtheimitationgame:
Quantifying and extrapolating the capabilities of language models. Transactions on Machine Learning
Research, 2023.
NisanStiennon,LongOuyang,JeffWu,DanielM.Ziegler,RyanLowe,ChelseaVoss,AlecRadford,Dario
Amodei, and Paul Christiano. Learning to summarize from human feedback. In NeurIPS, 2020.
Neal Suggs and Phil Venables. Protecting customers with generative AI indemnification, 2023. URL
https://cloud.google.com/blog/products/ai-machine-learning/protecting-customers-with-
generative-ai-indemnification .
Zeerak Talat, Aurélie Névéol, Stella Biderman, Miruna Clinciu, Manan Dey, Shayne Longpre, Sasha Luccioni,
Maraim Masoud, Margaret Mitchell, Dragomir Radev, et al. You reap what you sow: On the challenges of
bias evaluation under multilingual settings. In Proceedings of BigScience Episode# 5–Workshop on Challenges
& Perspectives in Creating Large Language Models , pages 26–41, 2022.
RohanTaori,IshaanGulrajani,TianyiZhang,YannDubois,XuechenLi,CarlosGuestrin,PercyLiang,and
TatsunoriB.Hashimoto. Stanfordalpaca: Aninstruction-followingllamamodel. https://github.com/
tatsu-lab/stanford_alpaca , 2023.
HugoTouvron,LouisMartin,KevinStone,PeterAlbert,AmjadAlmahairi,YasmineBabaei,NikolayBash-
lykov,SoumyaBatra,PrajjwalBhargava,ShrutiBhosale,etal. Llama2: Openfoundationandfine-tuned
chat models. arXiv preprint arXiv:2307.09288 , 2023.
Vercel. Sharegpt, 2023. URL https://sharegpt.com/ .
26

--- PAGE 27 ---
Jon Victor and Amir Efrati. Alphabet’s google and deepmind pause grudges, join forces to chase openai. The
Information , 2023.
Vijay Viswanathan, Luyu Gao, Tongshuang Wu, Pengfei Liu, and Graham Neubig. Datafinder: Scientific
dataset recommendation from natural language descriptions. arXiv preprint arXiv:2305.16636 , 2023.
Georg Von Krogh and Eric Von Hippel. Special issue on open source software development, 2003.
Nikhil Vyas, Sham Kakade, and Boaz Barak. Provable copyright protection for generative models. arXiv
preprint arXiv:2302.10870 , 2023.
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh
Hajishirzi. Self-instruct: Aligning language model with self generated instructions, 2022a. URL https:
//arxiv.org/abs/2212.10560 .
Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana
Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. Benchmarking
generalization via in-context instructions on 1,600+ language tasks. arXiv preprint arXiv:2204.07705 , 2022b.
URL https://arxiv.org/abs/2204.07705 .
Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva Naik,
ArjunAshok,ArutSelvanDhanasekaran,AnjanaArunkumar,DavidStap,etal. Super-naturalinstructions:
Generalization via declarative instructions on 1600+ nlp tasks. In Proceedings of the 2022 Conference on
Empirical Methods in Natural Language Processing , pages 5085–5109, 2022c.
Jason Wei, MaartenBosma, VincentZhao, KelvinGuu, Adams WeiYu, Brian Lester, NanDu, AndrewM Dai,
and Quoc V Le. Finetuned language models are zero-shot learners. In International Conference on Learning
Representations , 2021.
JohannesWelbl,AmeliaGlaese,JonathanUesato,SumanthDathathri,JohnMellor,LisaAnneHendricks,
KirstyAnderson,PushmeetKohli,BenCoppin,andPo-SenHuang. Challengesindetoxifyinglanguage
models. In Findings of the Association for Computational Linguistics: EMNLP 2021 , pages 2447–2469, 2021.
JasonWeston,AntoineBordes,SumitChopra,AlexanderM.Rush,BartvanMerriënboer,ArmandJoulin,
and Tomas Mikolov. Towards ai-complete question answering: A set of prerequisite toy tasks, 2015.
Albert Xu, Eshaan Pathak, Eric Wallace, Suchin Gururangan, Maarten Sap, and Dan Klein. Detoxifying
language models risks marginalizing minority voices. In Proceedings of the 2021 Conference of the North
AmericanChapteroftheAssociationforComputationalLinguistics: HumanLanguageTechnologies ,pages2390–
2397, 2021.
CanXu,QingfengSun,KaiZheng,XiuboGeng,PuZhao,JiazhanFeng,ChongyangTao,andDaxinJiang.
Wizardlm: Empowering large language models to follow complex instructions, 2023a.
Canwen Xu, Daya Guo, Nan Duan, and Julian McAuley. Baize: An open-source chat model with parameter-
efficient tuning on self-chat data, 2023b.
Joanna Yoo, Kuba Perlin, Siddhartha Rao Kamalakara, and João G. M. Araújo. Scalable training of language
models using jax pjit and tpuv4, 2022.
Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili
Yu,SusanZhang,GargiGhosh,MikeLewis,LukeZettlemoyer,andOmerLevy. Lima: Lessismorefor
alignment, 2023.
27

--- PAGE 28 ---
Appendix
A Contributors
Hereweenumeratetheauthorcontributions. Wewouldliketoemphasizethatallauthorscontributedcrucial
elementstothisproject,and CoreContributors inparticulararerecognizedwithhandsonservicetothedesign
and construction of Data Provenance’s first implementation.
•Shayne Longpre Core Contributor. Primary designer and coder of the repository and explorer
interface. Led audit implementation, and analysis, as well as the manual annotation process.
•Robert Mahari Core Contributor. Led the legal analysis, and licensing annotation design.
•Anthony Chen Core Contributor. Led automatic inferencing of dataset text metrics, topics, and task
category annotations. Supported writing, analysis, and code testing.
•Naana Obeng-Marnu Corecontributor. Ledvisualization design,particularlyinteractivevisualiza-
tions in the Data Provenance Explorer.
•Damien Sileo Core contributor. Led data aggregator linking, and metadata scraping. Supported
writing, analysis, source annotation and adding datasets.
•William Brannon Core contributor. Added 8 data collections, supported writing and data analysis.
•Niklas Muennighoff Core contributor. Added several large data collections, supported writing,
analysis, visualization, and source annotations.
•NathanKhazam Corecontributor. Ledlicensingannotation effortandsupportedaddingdatasets
along with testing.
•Jad Kabbara Core contributor and advisor. Led text source annotation effort and supported with
framing, writing and analysis.
•KartikPerisetla Corecontributor. Addedseveraldatasets,supportedwriting,analysis,anddataset
preparation for Hugging Face.
•Xinyi (Alexis) Wu Core contributor. Added several datasets, testing, and supported automatic
metadata collection.
•EnricoShippole Corecontributor. LedfinaldatasetpreparationforHuggingFaceuploadandtesting.
•Kurt Bollacker Advisor on project design and framing.
•TongshuangWu Advisor,particularlyondataanalysisandvisualizations. Supportedwritingand
Data Provenance Explorer design.
•LuisVilla Advisorondatacopyrightandlicensing,andsupportingwritinginthelegaldiscussion
section.
•Sandy Pentland Advisor on general project design and framing.
•Sara Hooker Advisor on general project design and framing, as well as supporting writing, analysis,
and directing experiments.
28

--- PAGE 29 ---
B Exact Licenses and Citations
See Table 5 for a summary of the Data Provenance Collection licenses and citations. More comprehensive de-
tails are available at https://github.com/Data-Provenance-Initiative/Data-Provenance-Collection .
C Details on Collecting Data Provenance
This data was collected with a mix of manual and automated techniques, leveraging dataset aggregators like
GitHub,HuggingFaceandSemanticScholar. Annotatingandverifyinglicenseinformation,inparticular,
requiredacarefullyguidedmanualworkflow,designedwithlegalpractitioners(seeSection2.2). Oncethese
informationaggregatorswereconnected,itwaspossibletosynthesizeorscrapeadditionalmetadata,suchas
dataset languages, task categories, and time of collection. And for richer details on each dataset, like text
topics and source, we used carefully tuned prompts on language models inspecting each dataset.
AutomatedAnnotationMethods Basedonthemanuallyretrievedpages,weautomaticallyextractLicenses
from HuggingFace configurations and GitHub pages. We leverage the Semantic Scholar public API (Kinney
et al., 2023) to retrieve the released date and current citation counts associated to academic publications.
Additionally, we compute a series of other helpful, but often overlooked data properties such as text metrics
(the min/mean/max for input and target lengths), and dialog turns. We elected to measure sequence length
in characters rather than word tokens, for fairer treatment across language and script given well-known
differences in tokenizer performance across different languages (Petrov et al., 2023).
API Annotation Methods While Task Categories have become the established measurement of data
diversityinrecentinstructiontuningwork(Sanhetal.,2021;Wangetal.,2022a),therearesomanyother
rich features describing data diversity and representation. To augment this, we use OpenAI’s GPT-4 API to
help annotate for text topics. We randomly sampled 100 examples per dataset and carefully prompt GPT-4 to
suggest up to 10 topics discussed in the text.
To annotate for the original data sources, AI experts (PhD students and postdocs) reviewed the papers
andfilledouttheoriginaltextsources,whethermachinesortemplate-generationwereusedforsynthetic
generation, and whether human annotators were used. GPT-4 was used as an in-context retriever on the
dataset’sArXivpapertoextractsnippetsthattheexpertsmayhavemissed. WesplittheArXivpaperinto
4000characterschunksandprompttheAPItoreturnajsonlistofanymentionsofthedatasetsource,e.g.
from scraping, synthetic or manual generation.
29

--- PAGE 30 ---
Cite Licenses
Collection
Airoboros Durbin (2023) CC BY-NC 4.0
Alpaca Taori et al. (2023) CC BY-NC 4.0
Anthropic HH Bai et al. (2022); Ganguli et al. (2022) MIT License
BaizeChat Xu et al. (2023b) CC BY-NC 4.0
BookSum Kryściński et al. (2022) Academic Only
CamelAI Sci. Li et al. (2023a) CC BY-NC 4.0
CoT Coll. Kim et al. (2023) Non Commercial
Code Alpaca – Unspecified
CommitPackFT Muennighoff et al. (2023a) Various
Dolly 15k Conover et al. (2023) CC BY-SA 3.0
Evol-Instr. Xu et al. (2023a) Academic Only
Flan Collection Longpre et al. (2023a) Various
GPT-4-Alpaca Peng et al. (2023) CC BY-NC 4.0
GPT4AllJ Anand et al. (2023) Various
GPTeacher – Unspecified
Gorilla Patil et al. (2023) Apache License 2.0
HC3 Guo et al. (2023) Various
Joke Expl. – MIT License
LAION OIG Nguyen et al. (2023) Various
LIMA Zhou et al. (2023) CC BY-NC-SA 4.0
Longform Köksal et al. (2023) CC BY-SA 3.0, Unspecified, CC BY-
SA 4.0
OpAsst OctoPack Muennighoff et al. (2023a) CC BY 4.0
OpenAI Summ. Stiennon et al. (2020) CC BY 4.0
OpenAssistant Köpf et al. (2023) CC BY 4.0
OpenOrca Mukherjee et al. (2023) Various
SHP Ethayarajh et al. (2023) Unspecified
Self-Instruct Wang et al. (2022a) Apache License 2.0
ShareGPT Vercel (2023) Unspecified
StackExchange – Unspecified
StarCoder Li et al. (2023b) BigScience OpenRAIL-M
Tasksource Ins. Sileo (2023) Various
Tasksource ST Weston et al. (2015) Various
TinyStories Eldan and Li (2023) CDLA Sharing 1.0
Tool-Llama Qin et al. (2023) CC BY-NC 4.0
UltraChat Ding et al. (2023) CC BY-NC 4.0
Unnatural Instr. Honovich et al. (2022) MIT License
WebGPT Nakano et al. (2021) Apache License 2.0, CC BY-SA 4.0
xP3x Muennighoff et al. (2022) Various
Table 5:Licenses and citations for the dataset collections presented in this paper. Collections containing
material under more than three distinct licenses are marked as having ”Various“ licenses, and we refer
readers to our raw data for the full details.
30

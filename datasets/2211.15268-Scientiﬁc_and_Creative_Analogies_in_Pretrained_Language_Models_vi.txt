# Các tương tự khoa học và sáng tạo trong các mô hình ngôn ngữ được huấn luyện trước

Tamara Czinczoll|~Helen YannakoudakisPushkar Mishra}Ekaterina Shutova|
|ILLC, University of Amsterdam, the Netherlands
}Meta AI, London, United Kingdom
Dept. of Informatics, King's College London, United Kingdom
~Hasso Plattner Institute/University of Potsdam, Germany
tamara.czinczoll@hpi.de, helen.yannakoudakis@kcl.ac.uk, pushkarmishra@meta.com, e.shutova@uva.nl

Tóm tắt
Bài báo này xem xét việc mã hóa tương tự trong các mô hình ngôn ngữ được huấn luyện trước quy mô lớn, như BERT và GPT-2. Các bộ dữ liệu tương tự hiện có thường tập trung vào một tập hợp hạn chế các mối quan hệ tương tự, với độ tương đồng cao giữa hai miền mà tương tự được thiết lập. Như một thiết lập thực tế hơn, chúng tôi giới thiệu bộ dữ liệu Tương tự Khoa học và Sáng tạo (SCAN), một bộ dữ liệu tương tự mới chứa các ánh xạ hệ thống của nhiều thuộc tính và cấu trúc quan hệ qua các miền không tương đồng. Sử dụng bộ dữ liệu này, chúng tôi kiểm tra khả năng suy luận tương tự của một số mô hình ngôn ngữ được huấn luyện trước (LMs) được sử dụng rộng rãi. Chúng tôi thấy rằng các LMs tiên tiến nhất đạt hiệu suất thấp trên các tác vụ tương tự phức tạp này, làm nổi bật những thách thức vẫn còn do việc hiểu tương tự đặt ra.

1 Giới thiệu
Tạo ra tương tự là nền tảng của trí tuệ con người (Gentner et al., 2001), cho phép chúng ta tiếp thu kiến thức mới và khám phá sáng tạo các khái niệm mới. Theo Lý thuyết Ánh xạ Cấu trúc của Gentner (1983), suy luận tương tự khác với sự tương đồng bề mặt. Thay vào đó, các thuộc tính của một khái niệm quen thuộc (miền nguồn) được ánh xạ đến thứ gì đó ít quen thuộc hơn (miền đích) nếu cấu trúc quan hệ của chúng đủ tương tự. Ví dụ, tuy không trực tiếp tương tự về thuộc tính, cấu trúc quan hệ cơ bản của hệ mặt trời khớp với cấu trúc của nguyên tử. Mối quan hệ giữa hai thuộc tính miền nguồn (ví dụ mặt trời và hành tinh) giúp chúng ta hiểu mối quan hệ giữa các đối tác miền đích tương ứng (hạt nhân và electron).

Trong xử lý ngôn ngữ tự nhiên (NLP), tác vụ tương tự từ (Mikolov et al., 2013), đã được sử dụng rộng rãi để chứng minh khả năng suy luận tương tự của các mô hình embedding từ được huấn luyện trước. Tác vụ này bao gồm việc giải các tương tự dạng A:B :: C:D (tức là, A với B như C với D) bằng cách khai thác các tính chất tuyến tính (cục bộ) của các vector từ (độ lệch vector). Sau đó, tương tự từ trở thành một trong những tác vụ tiêu chuẩn hóa để đánh giá nội tại chất lượng embedding từ. Tuy nhiên, Gladkova et al. (2016) đã chỉ ra rằng phương pháp độ lệch vector không đủ cho hầu hết các loại quan hệ tương tự, và Rogers et al. (2017) đã chỉ ra những lối tắt mà các mô hình đang sử dụng. Các bộ dữ liệu tương tự từ hiện tại tập trung vào một tập hợp hạn chế các quan hệ tương tự, bao gồm các từ tương tự nhau về mặt ngữ nghĩa và không yêu cầu mô hình liên hệ các khái niệm riêng biệt thông qua so sánh hệ thống cấu trúc quan hệ của chúng, tất cả đều cần thiết cho việc tạo tương tự giống con người. Đồng thời, lĩnh vực này đã chứng kiến sự phát triển của các bộ mã hóa câu được huấn luyện trước quy mô lớn, khả năng suy luận tương tự của chúng chưa được kiểm tra đầy đủ.

Để giải quyết những vấn đề này, chúng tôi thiết kế và phát hành một bộ dữ liệu mới – bộ dữ liệu Tương tự Khoa học và Sáng tạo (SCAN) – bao gồm các tương tự toàn diện giữa các khái niệm từ những miền ngữ nghĩa xa nhau. Nó dựa trên các tương tự ẩn dụ và khoa học. Giải quyết những tương tự này đòi hỏi các mô hình phải xác định các tương ứng bản thể học hệ thống giữa hai miền ngữ nghĩa riêng biệt, như trong ví dụ hệ mặt trời – nguyên tử. Những đóng góp của chúng tôi gồm ba phần: 1) Chúng tôi trình bày tác vụ đánh giá tương tự SCAN và bộ dữ liệu, mà chúng tôi công khai cho cộng đồng nghiên cứu; 2) Chúng tôi đánh giá hệ thống các LMs tiên tiến hiện tại trên bộ dữ liệu BATS đã được thiết lập (Gladkova et al., 2016), bao gồm một số lượng lớn các tương tự từ truyền thống, cũng như bộ dữ liệu SCAN mới. Chúng tôi chỉ ra rằng trong trường hợp sau, các mô hình thể hiện những hạn chế nghiêm trọng trong việc hiểu tương tự; 3) Chúng tôi chỉ ra rằng hiệu suất cao trên BATS không biểu thị mô hình giải quyết các tương tự SCAN phức tạp như thế nào, hỗ trợ giả thuyết của chúng tôi rằng BATS không đòi hỏi suy luận tương tự đầy đủ.

2 Công trình liên quan
Turney (2008) đã trình bày một thuật toán để giải quyết tương tự và kiểm tra nó trên 20 ví dụ khoa học và ẩn dụ, trong đó một miền nguồn được ánh xạ sang một miền đích khác, cùng với một số thuộc tính của nó (ví dụ sóng đến âm thanh). Tuy ít, những ví dụ này trung thực với việc tạo tương tự của con người, đại diện cho một loạt rộng các mối quan hệ ngữ nghĩa. Sử dụng phương pháp độ lệch tuyến tính (3CosAdd), Mikolov et al. (2013) đã chứng minh rằng embedding từ của họ tự động nắm bắt thông tin tương tự về mối quan hệ từ, sao cho emb(king) - emb(man) + emb(woman) ≈ emb(queen), trong đó emb là hàm embedding được biểu diễn bởi mạng neural. Tuy nhiên, Gladkova et al. (2016) đã chỉ ra rằng các embedding từ được huấn luyện trước vào thời điểm đó chỉ có thể hoàn thành đáng tin cậy các tương tự từ cho các loại hình thái học biến cách trong khi gặp khó khăn với nhiều loại ngữ nghĩa. Họ đã phát hành một bộ dữ liệu cân bằng, lớn hơn và đa dạng hơn so với của Mikolov et al. (2013) (40 so với 15 loại quan hệ), Bộ Kiểm tra Tương tự Lớn hơn (BATS), chứng minh rằng Word2Vec không thể giải quyết hầu hết các loại tương tự từ. Đặc biệt, khoảng cách ngữ nghĩa lớn hơn giữa các miền nguồn và đích dẫn đến hiệu suất thấp (Rogers et al., 2017).

Các mô hình ngôn ngữ Transformer như BERT (Devlin et al., 2019) đã đẩy mạnh tiên tiến trên một số tác vụ NLP. Nhưng vì 3CosAdd không thể dễ dàng áp dụng cho chúng, do embedding từ của chúng không cố định mà được tính toán động, khả năng tương tự của chúng chưa được điều tra nhiều. Tuy đã có một số tiến bộ trong vấn đề đó (Li và Zhao (2020), Zhu và de Melo (2020), Ushio et al. (2021)), trọng tâm vẫn là chuyển các bộ dữ liệu tương tự từ truyền thống lên cấp độ câu. Điều này tuy nhiên cũng chuyển những hạn chế của chúng. Nói chung, hiệu suất thấp của các mô hình trong Gladkova et al. (2016) và Zhu và de Melo (2020) cho thấy việc hoàn thành tương tự từ là thách thức đối với các LMs tiên tiến, ngay cả khi ánh xạ cấu trúc qua các miền riêng biệt không được kiểm tra rõ ràng.

3 Bộ dữ liệu SCAN
Bộ dữ liệu của chúng tôi chứa 449 thể hiện tương tự, được nhóm thành 65 ánh xạ khái niệm đầy đủ. Một khái niệm nguồn được ánh xạ đến một khái niệm đích cùng với một số thuộc tính liên quan. Bảng 1 cung cấp hai ví dụ. Khi ánh xạ từ khái niệm nguồn Chiến tranh đến khái niệm đích Tranh luận, một số tương ứng thuộc tính liên quan được đưa ra. Số lượng thuộc tính cho mỗi ánh xạ liên miền không cố định. Bộ dữ liệu bao gồm 20 ánh xạ từ Turney (2008) (10 khoa học và 10 ẩn dụ) và mở rộng chúng bằng thêm 43 ánh xạ ẩn dụ và 2 ánh xạ khoa học. Các ánh xạ ẩn dụ mới bao gồm ẩn dụ khái niệm từ Danh sách Ẩn dụ Chính (Lakoff et al., 1991) và các ẩn dụ khái niệm khác được thảo luận rộng rãi trong tài liệu ngôn ngữ học (Lakoff và Johnson, 1980; Musolff, 2000; Lakoff và Wehling, 2012). Mỗi ẩn dụ khái niệm sau đó được chú thích cho các tương ứng thuộc tính bởi ba chuyên gia ẩn dụ. Đầu tiên, các khung ngữ nghĩa của miền nguồn và đích được xác định và sau đó các tương ứng giữa các yếu tố khung riêng lẻ được thiết lập (xem Bảng 1). Chúng tôi xây dựng một tác vụ tương tự từ từ dữ liệu này bằng cách định nghĩa các ánh xạ liên miền (ví dụ, Tranh luận và Chiến tranh) như cặp từ đầu tiên, và các ánh xạ thuộc tính (trong trường hợp này Người tranh luận và Chiến binh) như cặp từ thứ hai cần được hoàn thành. Vì mỗi khái niệm bao gồm nhiều thuộc tính, tổng cộng 449 tương tự từ được xây dựng.

SCAN cung cấp các tương tự phong phú và toàn diện hơn so với các bộ dữ liệu tương tự từ truyền thống. Từ góc độ thống kê, cơ hội các từ trong miền nguồn và đích cùng xuất hiện thấp hơn nhiều so với trong BATS. Ví dụ, các quốc gia và thủ đô của chúng, động vật và âm thanh chúng tạo ra, và hầu hết các loại tương tự ngữ pháp trong BATS khá có thể xảy ra cùng nhau trong corpus huấn luyện. Tuy nhiên, điều tương tự không thể nói về hầu hết các tương tự SCAN, có nghĩa là sự chuyển đổi tương tự thực sự cần phải xảy ra.

Ngoài ra, các từ trong miền trong SCAN không tương tự nhau về mặt ngữ nghĩa. Ví dụ, trong miền tranh luận, người tranh luận và chủ đề là những khái niệm khác nhau về cơ bản. Mặt khác, trong BATS, mỗi thành viên miền là một thể hiện khác của cùng một khái niệm, ví dụ Pháp và Đức là các thể hiện của một quốc gia.

Cuối cùng, các mối quan hệ tương tự giữa các miền trong SCAN trừu tượng hơn những mối quan hệ trong BATS. Để thành công trích xuất cùng một mối quan hệ từ hệ mặt trời – nguyên tử và hành tinh – electron, cần nhiều trừu tượng hóa và suy luận hơn về cấu trúc quan hệ của các miền so với trong BATS. Trong BATS, các mối quan hệ giữa, ví dụ Pháp – Paris và Đức – Berlin, là đơn giản và không đòi hỏi nhiều trừu tượng hóa.

Nhìn chung, SCAN cung cấp các tương tự giống con người hơn bằng cách sử dụng các từ trong miền đa dạng hơn, các mối quan hệ ánh xạ trừu tượng hơn và tránh các sự cùng xuất hiện rõ ràng. Do các ánh xạ khái niệm đầy đủ, SCAN không bị giới hạn trong tác vụ tương tự từ. Bằng cách ánh xạ toàn diện toàn bộ miền nguồn đến một miền đích mới, chúng tôi muốn khuyến khích một phạm vi rộng hơn các biểu diễn tương tự.

4 Mô hình
Chúng tôi khảo sát khả năng tương tự của một số mô hình ngôn ngữ được sử dụng rộng rãi: GPT-2, BERT và BERT Đa ngôn ngữ (M-BERT). Chúng tôi sử dụng GloVe làm baseline, vì nó đã được chỉ ra vượt trội hơn các mô hình ngôn ngữ trên một số loại quan hệ trong các tác vụ tương tự trước đó (Zhu và de Melo, 2020).

GPT-2 (Radford et al., 2019) có thể được xem như một LM "thực sự" vì nó được huấn luyện để dự đoán từ tiếp theo trong một chuỗi, và có thể được sử dụng để sinh ngôn ngữ. Đây là một mô hình dựa trên transformer với 48 lớp và 1542 triệu tham số, được huấn luyện trên một bộ dữ liệu tùy chỉnh, WebText, được tạo chỉ từ các liên kết ra ngoài từ Reddit để cải thiện chất lượng văn bản. Do tính chất dự đoán của nó, GPT-2 là một chiều, tức là chỉ ngữ cảnh bên trái ảnh hưởng đến dự đoán từ tiếp theo.

BERT (Devlin et al., 2019) là một mô hình biểu diễn ngôn ngữ hai chiều. Nó được huấn luyện với hai mục tiêu: dự đoán token bị che và dự đoán câu tiếp theo. Chúng tôi sử dụng BERT-base với 12 lớp trong các thí nghiệm của chúng tôi (110 triệu tham số). Vì BERT là hai chiều, nó có thể kết hợp thông tin từ cả hai phía của token bị che.

M-BERT là một mô hình BERT, được huấn luyện trên một bản dump Wikipedia của 100 ngôn ngữ. Mô hình hoạt động tốt nhất trên các ngôn ngữ có tài nguyên cao như tiếng Anh, Pháp và Trung Quốc, vì các ngôn ngữ có tài nguyên thấp hơn được đại diện không đầy đủ trong dữ liệu huấn luyện. Chúng tôi kiểm tra xem việc huấn luyện trước của M-BERT trên một loạt rộng các ngôn ngữ, và do đó một loạt rộng các tương tự đặc trưng văn hóa, có thể tăng cường hiểu biết tương tự tổng quát của mô hình hay không.

5 Thí nghiệm
Thiết lập Chúng tôi sử dụng các thể hiện mô hình được huấn luyện trước của GPT-2, BERT Base và Multilingual BERT. Vì BERT và GPT-2 được huấn luyện trên các câu đầy đủ, chúng tôi chèn bộ bốn tương tự từ vào một câu mẫu. Chúng tôi sử dụng "Nếu A giống B, thì C giống D.", được chọn từ một tập hợp các ứng cử viên vì nó hoạt động tốt nhất trên tập phát triển. Tương tự như Ettinger (2020), người đã khảo sát BERT với một số tác vụ cloze và phủ định, các mô hình cần dự đoán token cuối cùng của câu. Chúng tôi buộc các mô hình dự đoán từ D bằng cách che nó đối với hai mô hình BERT, hoặc bằng cách cắt câu trước nó đối với GPT-2. Chúng tôi báo cáo thứ hạng nghịch đảo trung bình (MRR) của token đầu tiên của từ đích (hoặc của một trong các câu trả lời thay thế) chỉ trong top 10 token được dự đoán để giảm tính toán. Nếu nhãn không nằm trong top 10 token, RR của nó là 0. Hiệu suất mô hình theo độ chính xác, recall@10 và recall@5 được báo cáo trong Phụ lục. Chúng tôi sử dụng GPU Nvidia 16GB.

SCAN so với BATS Để đánh giá mức độ các mô hình có thể giải quyết các loại tương tự khác nhau, chúng tôi kiểm tra chúng trên BATS ngoài SCAN. Chúng tôi không tinh chỉnh các mô hình. BATS bao gồm 98000 ví dụ về các quan hệ cân bằng. Có bốn quan hệ chính – hình thái học biến cách và tạo từ, và ngữ nghĩa từ điển và bách khoa – mỗi quan hệ bao gồm mười tiểu loại. Đối với một số ví dụ, nhiều câu trả lời đúng được liệt kê.

Zero-shot so với One-shot Công trình trước đó về suy luận tương tự trong GPT-3 (Mitchell, 2020; nhóm Latitude, 2020) đã chỉ ra rằng khi mô hình được đưa một ví dụ đầy đủ về tương tự từ ngoài ví dụ không đầy đủ, hiệu suất trên tương tự không đầy đủ tăng lên đáng kể. Chúng tôi xem điều này như một dạng kiểm tra one-shot so với zero-shot và cũng kiểm tra các mô hình theo cách này, điều tra xem điều này có tác động đến hiệu suất của các LMs trên SCAN hay không. Chúng tôi chèn một phiên bản hoàn chỉnh của câu mẫu trước câu không đầy đủ, đảm bảo rằng không có từ tương tự nào từ ví dụ đầy đủ xuất hiện trong tương tự không đầy đủ. Lưu ý rằng GloVe không được lợi từ thiết lập này vì các vector được sử dụng cho 3CosAdd vẫn giữ nguyên.

Tác động Tập Huấn luyện Cuối cùng, chúng tôi điều tra thêm sự khác biệt giữa các loại tương tự từ trong BATS và những loại trong SCAN. Chúng tôi chia bộ dữ liệu BATS thành tập huấn luyện, xác thực và kiểm tra (tỷ lệ 70/15/15), đảm bảo rằng mỗi cặp từ chỉ xuất hiện trong một trong số chúng. Chúng tôi tinh chỉnh các LMs trên tập huấn luyện và lấy phiên bản của mỗi mô hình với điểm tốt nhất trên tập xác thực BATS. Chúng tôi huấn luyện (4h) tất cả các mô hình với trình tối ưu hóa AdamW (Loshchilov và Hutter, 2019), tốc độ học 5e-5 và kích thước batch 16 cho 4 epoch (dựa trên điều chỉnh thủ công). Nếu mô hình đã học về việc tạo tương tự tổng quát, nó phải hiểu các quan hệ tương tự mới "một cách tức thì" và cải thiện không chỉ trên tập kiểm tra BATS mà cả trên SCAN. Chúng tôi mong đợi có những cải thiện mạnh mẽ trên BATS so với đối tác chưa được huấn luyện, nhưng ít hoặc không có trên SCAN, cho thấy chúng có bản chất khác nhau. Điều này không được thực hiện trên GloVe, vì 3CosAdd đưa ra một embedding không phải là một phần của thiết lập huấn luyện ban đầu của nó.

6 Kết quả & Thảo luận
Bảng 2 cho thấy độ chính xác của từng mô hình trên các bộ dữ liệu BATS và SCAN, cũng như trên các tương tự khoa học và sáng tạo riêng biệt. BERT đạt MRR cao nhất trên bộ dữ liệu BATS, với một khoảng cách mạnh so với các mô hình khác. Tương tự như Zhu và de Melo (2020), chúng tôi thấy rằng GloVe có thể theo kịp các mô hình khác trên BATS, hoạt động tương tự như GPT-2. Tuy nhiên, xu hướng này không được quan sát trên bộ dữ liệu SCAN, nơi GloVe bị đẩy xuống vị trí cuối cùng, cho thấy rằng ngữ cảnh quan trọng để hiểu các tương tự SCAN. Tất cả các mô hình hoạt động tốt hơn trên các tương tự khoa học so với ẩn dụ. Điều này có thể do thực tế rằng các thuộc tính của chúng ít trừu tượng hơn và có các tương ứng rõ ràng hơn trong miền đích. MRR của các mô hình thường thấp hơn trên SCAN, mà chúng tôi quy cho sự khác biệt ngữ nghĩa lớn hơn giữa các miền nguồn và đích. GPT-2 đạt hiệu suất cao nhất, tiếp theo là BERT. Điều này, kết hợp với độ chính xác thấp hơn trên baseline BATS, cho thấy rằng GPT-2 tốt hơn trong việc mô hình hóa các tương tự mở rộng và tường thuật hơn thay vì những tương tự nhân tạo và được định nghĩa nghiêm ngặt hơn trong BATS. Các tính năng đa ngôn ngữ chỉ dường như hiệu quả một cách biên tế cho tác vụ, điều có thể được giải thích bởi thực tế là hầu hết các tương tự phụ thuộc vào ngôn ngữ, một quan sát cũng được Ulčar et al. (2020) đưa ra. Nhìn chung, những kết quả này cho thấy rằng tác vụ tương tự SCAN là thách thức đối với các LMs tiên tiến và khả năng giải quyết tương tự thực sự của chúng vẫn cần được cải thiện.

Zero so với One-Shot Bảng 3 cho thấy độ chính xác của mô hình khi đầu vào chứa một ví dụ đầy đủ bổ sung. Ngoài GPT-2 trên BATS, điều này không giúp các mô hình hiểu tác vụ tốt hơn. Điều này tương phản với các ví dụ về GPT-3 từ Mitchell (2020), có thể do các mô hình không xác định được các mối quan hệ tương tự trong câu ví dụ.

Tác động Tập Huấn luyện Sau khi huấn luyện trên BATS, người ta có thể mong đợi rằng nếu các mô hình học về suy luận tương tự nói chung, chúng cũng sẽ tự nhiên làm tốt hơn trên bộ dữ liệu SCAN với các tương tự phức tạp hơn. Tuy nhiên, kết quả của chúng tôi trong Bảng 4 cho thấy trường hợp ngược lại. Trong khi huấn luyện trên BATS tăng đáng kể MRR của các mô hình trên tập kiểm tra BATS được giữ lại, nó có tác động bất lợi đến SCAN. Điều này cho thấy rằng các loại tương tự của hai bộ dữ liệu khác nhau về bản chất, xác thực giả thuyết của chúng tôi rằng các bộ dữ liệu tương tự từ tiêu chuẩn không đại diện đầy đủ cho việc sử dụng tương tự của con người.

Phân tích Lỗi Trong khi GloVe ghi điểm nhất quán trên tất cả các loại quan hệ trong BATS, điều này không đúng với các mô hình khác. Trên SCAN, không có mô hình nào dự đoán đúng các ánh xạ của tất cả các thuộc tính của một khái niệm (hoặc thậm chí hầu hết chúng). Trong khi các mô hình có thể giải quyết một số ánh xạ riêng lẻ, thực tế là chúng không thể áp dụng điều này cho tất cả các khía cạnh của khái niệm cho thấy rằng không có mô hình nào thực sự có thể nắm bắt cách thức hoạt động của tương tự. Trong những trường hợp mà các tương tự vẫn hoàn toàn chưa được giải quyết, có khả năng là thiếu kiến thức miền cần thiết.

7 Kết luận
Suy luận tương tự vẫn là một tác vụ thách thức ngay cả khi các LMs Transformer tiên tiến được sử dụng. Chúng tôi đã chỉ ra rằng, ngay cả với các mô hình như BERT và GPT-2, vẫn còn chỗ lớn để cải thiện về suy luận tự động và hiểu biết các tương tự thực tế. Chúng tôi đã giới thiệu một bộ dữ liệu mới, SCAN, khác với các bộ dữ liệu tương tự từ hiện có ở chỗ nó bao gồm các ánh xạ khái niệm toàn bộ qua các miền khác nhau về mặt ngữ nghĩa, chứng minh rằng các LMs phổ biến không thể hiểu đầy đủ những tương tự này. Chúng tôi tiếp tục kiểm tra xem một ví dụ đầy đủ về tác vụ có thể giúp các mô hình hay không, thấy rằng điều này không hữu ích trong thiết lập của chúng tôi. Cuối cùng, kết quả của chúng tôi cho thấy rằng các tương tự SCAN khác biệt đáng kể so với những tương tự của các bộ dữ liệu tương tự từ truyền thống. Cải thiện về chúng là một hướng nghiên cứu mà chúng tôi muốn điều tra thêm trong tương lai. Chúng tôi công khai SCAN và mã liên quan.

8 Hạn chế
Thiết kế thí nghiệm của chúng tôi tập trung vào đánh giá khả năng tương tự của các mô hình trong một thiết lập sinh tạo. Chúng tôi thấy giá trị trong điều này, vì suy luận tương tự về bản chất là một chức năng nhận thức sinh tạo. Tuy nhiên, các mô hình BERT không được huấn luyện để thực hiện sinh tạo từ trái sang phải và hơn nữa, dựa vào từ vựng wordpiece để token hóa. Do đó, việc đánh giá dự đoán của nó trong tác vụ tương tự ít đơn giản hơn và không hoàn toàn có thể so sánh với các mô hình khác. Chúng tôi điều chỉnh tác vụ cho các mô hình BERT bằng cách để chúng chỉ dự đoán token đầu tiên của câu trả lời bị thiếu. Chỉ so sánh token đầu tiên để lại một số biến động, tuy nhiên, khi khớp dự đoán và câu trả lời đúng. Chúng tôi mong đợi tác động này bị hạn chế trong tiếng Anh do hình thái học thưa thớt của nó.

Hơn nữa, các tương tự ẩn dụ đến từ văn học và nền tảng văn hóa tiếng Anh. Sẽ thú vị khi so sánh chúng với các tương tự từ các ngôn ngữ và văn hóa khác để điều tra xem việc thiếu hiểu biết của các mô hình ngôn ngữ là do mã hóa các tính chất đặc trưng ngôn ngữ, thiếu kiến thức miền hay khả năng ánh xạ tương tự tổng quát.

Cuối cùng, một số ẩn dụ trong SCAN thể hiện các vai trò giới tính lỗi thời, ví dụ ẩn dụ "chính phủ:hộ gia đình :: thống đốc:cha". Trong khi những mối quan hệ này về mặt văn hóa thường vẫn liên quan đến việc hiểu ẩn dụ, các vai trò giới tính ngụ ý cơ bản cần được xử lý cẩn thận và các vấn đề về việc mã hóa chúng bởi các mô hình neural cần được điều tra thêm.

Tài liệu tham khảo
Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. Trong Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), trang 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.

Allyson Ettinger. 2020. What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models. Transactions of the Association for Computational Linguistics, 8:34–48.

Dedre Gentner. 1983. Structure-mapping: A theoretical framework for analogy*. Cognitive Science, 7(2):155–170.

Dedre Gentner, Keith Holyoak, và Boicho Kokinov. 2001. The Analogical Mind: Perspectives From Cognitive Science. MIT Press.

Anna Gladkova, Aleksandr Drozd, và Satoshi Matsuoka. 2016. Analogy-based detection of morphological and semantic relations with word embeddings: What works and what doesn't. Trong Proceedings of the NAACL-HLT SRW, trang 47–54, San Diego, California, June 12-17, 2016. ACL.

George Lakoff, Jane Espenson, và Alan Schwartz. 1991. The master metaphor list. Báo cáo kỹ thuật, University of California at Berkeley.

George Lakoff và Mark Johnson. 1980. Metaphors We Live By. University of Chicago Press, Chicago.

George Lakoff và Elisabeth Wehling. 2012. The Little Blue Book: The Essential Guide to Thinking and Talking Democratic. Free Press, New York.

Yian Li và Hai Zhao. 2020. Learning universal representations from word to sentence.

Ilya Loshchilov và Frank Hutter. 2019. Decoupled weight decay regularization.

Tomas Mikolov, Kai Chen, Greg Corrado, và Jeffrey Dean. 2013. Efficient estimation of word representations in vector space.

Melanie Mitchell. 2020. Can gpt-3 make analogies? https://medium.com/@melaniemitchell.me/can-gpt-3-make-analogies-16436605c446. Truy cập: 2021-05-05.

Andreas Musolff. 2000. Mirror images of Europe: Metaphors in the public debate about Europe in Britain and Germany. Iudicium, Muenchen.

A. Radford, Jeffrey Wu, R. Child, David Luan, Dario Amodei, và Ilya Sutskever. 2019. Language models are unsupervised multitask learners.

Anna Rogers, Aleksandr Drozd, và Bofang Li. 2017. The (too many) problems of analogical reasoning with word vectors. Trong Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017), trang 135–148, Vancouver, Canada. Association for Computational Linguistics.

nhóm Latitude. 2020. World creation by analogy. https://aidungeon.medium.com/world-creation-by-analogy-f26e3791d35f. Truy cập: 2022-10-19.

P. D. Turney. 2008. The latent relation mapping engine: Algorithm and experiments. Journal of Artificial Intelligence Research, 33:615–655.

Matej Ulčar, Kristiina Vaik, Jessica Lindström, Milda Dailidėnaitė, và Marko Robnik-Šikonja. 2020. Multilingual culture-independent word analogy datasets. Trong Proceedings of the 12th Language Resources and Evaluation Conference, trang 4074–4080, Marseille, France. European Language Resources Association.

Asahi Ushio, Luis Espinosa Anke, Steven Schockaert, và Jose Camacho-Collados. 2021. BERT is to NLP what AlexNet is to CV: Can pre-trained language models identify analogies? Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), trang 3609–3624, Online. Association for Computational Linguistics.

Xunjie Zhu và Gerard de Melo. 2020. Sentence analogies: Linguistic regularities in sentence embeddings. Trong Proceedings of the 28th International Conference on Computational Linguistics, trang 3389–3400, Barcelona, Spain (Online). International Committee on Computational Linguistics.

A Các chỉ số đánh giá bổ sung

[Bảng 5, 6, 7 với các chỉ số chi tiết về Accuracy, MRR, Recall@10 và Recall@5 cho các mô hình trên BATS và SCAN]

# 2401.10225.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/datasets/2401.10225.pdf
# Kích thước tệp: 1056939 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
ChatQA: Vượt trội hơn GPT-4 trong Trả lời Câu hỏi Đối thoại
và RAG
Zihan Liu∗1Wei Ping∗1Rajarshi Roy1Peng Xu1
Chankyu Lee1Mohammad Shoeybi1
1NVIDIABryan Catanzaro1

Tóm tắt
Trong công trình này, chúng tôi giới thiệu ChatQA, một bộ mô hình vượt trội hơn GPT-4
trong việc tạo sinh tăng cường bằng truy xuất (RAG) và trả lời câu hỏi đối thoại (QA). Để
tăng cường khả năng tạo sinh, chúng tôi đề xuất một phương pháp điều chỉnh hướng dẫn
hai giai đoạn giúp cải thiện đáng kể hiệu suất của RAG. Để truy xuất hiệu quả, chúng tôi
giới thiệu một bộ truy xuất dày đặc được tối ưu hóa cho QA đối thoại, cho kết quả tương
đương với các mô hình viết lại truy vấn tiên tiến nhất, đồng thời giảm đáng kể chi phí
triển khai. Chúng tôi cũng trình bày CHATRAG BENCH, bao gồm mười bộ dữ liệu bao
phủ các đánh giá toàn diện về RAG, QA liên quan đến bảng, tính toán số học, và các tình
huống liên quan đến câu hỏi không thể trả lời. ChatQA-1.0-70B của chúng tôi (điểm: 54.14),
được xây dựng trên Llama2, một mô hình nền tảng yếu hơn GPT-4, có thể vượt trội nhẹ
hơn GPT-4-0613 (điểm: 53.90) và GPT-4-Turbo-2024-04-09 (điểm: 54.03) trên CHATRAG
BENCH, mà không dựa vào bất kỳ dữ liệu tổng hợp nào từ các mô hình OpenAI GPT.
Đáng chú ý, mô hình Llama3-ChatQA-1.5-70B vượt trội hơn độ chính xác của GPT-4-
Turbo-2024-04-09, đạt được cải thiện 4.4%. Để thúc đẩy nghiên cứu trong lĩnh vực này,
chúng tôi mở mã nguồn trọng số mô hình, dữ liệu điều chỉnh hướng dẫn, CHATRAG
BENCH, và bộ truy xuất cho cộng đồng: https://chatqa-project.github.io/.

1 Giới thiệu
Gần đây nhất, ChatGPT (OpenAI, 2022) và các phiên bản tiếp theo (OpenAI, 2023; Anthropic, 2023b;
Google, 2023) đã dẫn đến sự thay đổi mô hình trong việc xây dựng hệ thống trả lời câu hỏi (QA)
và tạo sinh tăng cường bằng truy xuất (RAG) trong sản xuất và cộng đồng nghiên cứu. Cụ thể, các
khía cạnh sau của các mô hình được ưa chuộng: i) Người dùng có thể tương tác với các mô hình QA
theo cách đối thoại, do đó có thể dễ dàng đặt câu hỏi tiếp theo. ii) Các mô hình có khả năng tích hợp
các đoạn bằng chứng được truy xuất trong cả cài đặt miền mở hoặc tài liệu dài, nơi ngữ cảnh được
cung cấp dài hơn nhiều so với cửa sổ ngữ cảnh của LLM (ví dụ: Anthropic, 2023a; Xu et al., 2023b).
iii) Các mô hình tổng quát có thể trả lời bất kỳ câu hỏi nào liên quan đến bảng, tính toán số học theo
cách zero-shot mà không cần tinh chỉnh cụ thể cho bộ dữ liệu, trong khi vẫn khớp với độ chính xác
của các mô hình được tinh chỉnh. Để đạt được mục tiêu này, chúng tôi tập trung vào việc xây dựng
mô hình hiện đại nhất với tất cả các khả năng chính này vốn rất quan trọng cho nhiều ứng dụng
thực tế.

Tuy nhiên, việc xây dựng một mô hình như vậy có thể khớp với độ chính xác của các mô hình độc
quyền hiện đại nhất, ví dụ GPT-4 (OpenAI, 2023), vẫn là một thách thức lớn đối với cộng đồng
nghiên cứu. Trong công trình này, chúng tôi giới thiệu ChatQA, một họ mô hình mã nguồn mở có
thể vượt trội hơn GPT-4 trong khi sử dụng mô hình nền tảng trọng số mở tương đối yếu. Chúng tôi
cũng mở mã nguồn dữ liệu huấn luyện của chúng tôi, chi tiết kỹ thuật tạo dữ liệu tổng hợp, cùng
với các quy trình chú thích thủ công thay thế nhằm loại bỏ sự phụ thuộc vào các mô hình OpenAI
GPT cho mục đích nghiên cứu mở.

∗Liên hệ với: Zihan Liu <zihanl@nvidia.com>, Wei Ping <wping@nvidia.com>
Hội nghị lần thứ 38 về Hệ thống Xử lý Thông tin Thần kinh (NeurIPS 2024).arXiv:2401.10225v5 [cs.CL] 30 Oct 2024

--- TRANG 2 ---
Cụ thể, chúng tôi có những đóng góp sau:

1. Chúng tôi đề xuất một phương pháp điều chỉnh hướng dẫn hai giai đoạn và thiết kế một công thức
curation dữ liệu có thể cải thiện đáng kể khả năng tích hợp ngữ cảnh do người dùng cung cấp hoặc
được truy xuất của LLM cho các nhiệm vụ QA đối thoại và RAG. Chúng tôi chứng minh rằng
phương pháp điều chỉnh hướng dẫn được đề xuất vượt trội đáng kể so với các baseline alignment
mạnh hoặc công thức dựa trên RLHF (ví dụ: Llama2-Chat, Llama3-Instruct) trên RAG và các
nhiệm vụ QA đối thoại khác nhau.

2. Đối với truy xuất, chúng tôi cho thấy rằng việc tinh chỉnh bộ truy xuất QA đơn lượt trên dữ liệu
được chú thích bởi con người hoặc bộ dữ liệu QA đa lượt tổng hợp hoạt động tốt như việc sử dụng
mô hình viết lại truy vấn dựa trên LLM hiện đại nhất, tức là GPT-3.5-Turbo (OpenAI, 2022). Kết
quả của chúng tôi cũng làm nổi bật hướng nghiên cứu hứa hẹn về việc sử dụng tạo dữ liệu tổng
hợp để huấn luyện bộ truy xuất tùy chỉnh.

3. Chúng tôi giới thiệu CHATRAG BENCH, một benchmark toàn diện với mười bộ dữ liệu QA
đối thoại, bao gồm năm bộ dữ liệu với tài liệu dài cần truy xuất và ba bộ dữ liệu với dữ liệu bảng
và tính toán số học. Chúng tôi áp dụng công thức huấn luyện ChatQA trên các mô hình nền tảng
văn bản khác nhau, và cho thấy khả năng tổng quát tuyệt vời của các phương pháp được đề xuất.
Về điểm trung bình trên CHATRAG BENCH, ChatQA-1.0-70B (54.14) của chúng tôi dựa trên
Llama2 có thể vượt trội hơn GPT-4-0613 (53.90) và GPT-4-Turbo-2024-04-09 (54.03) mà không
sử dụng bất kỳ dữ liệu tổng hợp nào từ các mô hình ChatGPT. Đáng chú ý, Llama3-ChatQA-1.5-
8B nhỏ hơn nhiều có thể hoạt động tương đương với các mô hình GPT-4, trong khi Llama3-ChatQA-
1.5-70B vượt trội hơn GPT-4-Turbo-2024-04-09 với một khoảng cách đáng kể.

4. Chúng tôi nghiên cứu tình huống "không thể trả lời", nơi LLM cần tạo ra "không thể trả lời" để
tránh ảo giác. Chúng tôi cho thấy rằng việc kết hợp một lượng nhỏ mẫu "không thể trả lời" cải
thiện đáng kể khả năng xử lý của mô hình. ChatQA-1.0-70B của chúng tôi vượt trội hơn GPT-3.5-
Turbo về khía cạnh này, trong khi có khoảng cách nhỏ so với GPT-4-0613 (khoảng 3.5%).

Chúng tôi thảo luận về các công trình liên quan trong §2. Chúng tôi giới thiệu phương pháp điều
chỉnh hướng dẫn hai giai đoạn và curation dữ liệu cho ChatQA trong §3, và nghiên cứu truy xuất
trong QA đối thoại trong §4. Chúng tôi trình bày thiết lập thí nghiệm trong §5, kết quả trong §6,
và kết luận bài báo trong §7.

2 Công trình liên quan

2.1 QA Đối thoại và RAG
Trả lời câu hỏi theo cách đối thoại tự nhiên cải thiện trải nghiệm người dùng bằng cách giải quyết
các câu hỏi tiếp theo. Mô hình cũng có thể đặt câu hỏi làm rõ cho người dùng nếu cần thiết, điều
này có thể giảm ảo giác. Do đó, nó trở thành định dạng mặc định để triển khai các mô hình QA
trong sản xuất (ví dụ: OpenAI, 2022; Google, 2023; Anthropic, 2023b). Trái ngược với giải pháp
tổng quát dựa trên LLM mới nhất (ví dụ: OpenAI, 2022), hầu hết các nghiên cứu trước đây tập
trung vào các mô hình chuyên gia được tinh chỉnh trên các miền hoặc bộ dữ liệu cụ thể (Feng et al.,
2020; Izacard & Grave, 2021; Chen et al., 2022a; Gao et al., 2022; Nakamura et al., 2022; Adlakha
et al., 2022; Wu et al., 2023).

Trong những năm gần đây, nhiều bộ dữ liệu QA đối thoại đã được giới thiệu. Các mô hình được
yêu cầu trả lời câu hỏi dựa trên ngữ cảnh hoặc tài liệu được cung cấp, điều này liên quan đến tạo
sinh tăng cường bằng truy xuất (RAG) nếu các tài liệu được cung cấp dài hơn cửa sổ ngữ cảnh của
LLM. Ngữ cảnh hoặc tài liệu được cung cấp có thể là: i) tài liệu chỉ có văn bản từ các miền khác
nhau (Feng et al., 2020; Anantha et al., 2021; Saeidi et al., 2018; Adlakha et al., 2022; Aliannejadi
et al., 2021; Reddy et al., 2019; Qu et al., 2020; Wu et al., 2023; Deng et al., 2022; Guo et al., 2021;
Choi et al., 2018; Campos et al., 2020), hoặc ii) tài liệu bao gồm văn bản thô cùng với bảng (Pasupat
& Liang, 2015; Nakamura et al., 2022; Chen et al., 2022a).

2.2 Truy xuất cho QA Đa lượt
RAG cực kỳ quan trọng đối với QA đối thoại trong cài đặt miền mở, ví dụ: sử dụng thông tin cập
nhật từ công cụ tìm kiếm, hoặc khi các tài liệu độc quyền dài hơn cửa sổ ngữ cảnh của LLM. Các
bộ truy xuất dày đặc thường được huấn luyện để truy xuất các đoạn có liên quan hàng đầu k cho
một câu hỏi đơn lẻ (ví dụ: Lin et al., 2023a; Wang et al., 2022a; Izacard et al., 2022). Trong QA
đối thoại,

--- TRANG 3 ---
các câu hỏi tiếp theo (ví dụ: với đại từ tham chiếu đến các thực thể được đề cập trong cuộc trò chuyện
trước đó) có thể có thông tin không đầy đủ để truy xuất, trong khi việc đưa chúng cùng với toàn bộ
lịch sử đối thoại có thể là dư thừa, do đó dẫn đến kết quả không tối ưu.

Viết lại Truy vấn Đối thoại Hầu hết các giải pháp trước đây là các phương pháp viết lại truy vấn.
Lượt câu hỏi mới nhất được viết lại thành một truy vấn độc lập mà không cần thông tin bổ sung từ
lịch sử đối thoại trước đó (Vakulenko et al., 2021a; Ye et al., 2023; Mo et al., 2023), do đó có thể
được sử dụng trực tiếp bởi mô hình truy xuất để truy xuất ngữ cảnh có liên quan (Vakulenko et al.,
2021b; Mele et al., 2021; Raposo et al., 2022; Mo et al., 2023). Nhiều bộ dữ liệu đã được thu thập
để thúc đẩy hướng nghiên cứu này (Elgohary et al., 2019; Chu et al., 2020; Qu et al., 2020; Anantha
et al., 2021; Brabant et al., 2022), cùng với nhiều phương pháp viết lại truy vấn được đề xuất (Ishii
et al., 2022; Yu et al., 2020; Wu et al., 2022; Del Tredici et al., 2021; Chen et al., 2022b; Galimzhanova
et al., 2023). Ví dụ, Wu et al. (2022) và Chen et al. (2022b) đề xuất sử dụng các phương pháp học
tăng cường cho việc viết lại truy vấn. Yu et al. (2020) nghiên cứu các mô hình tạo sinh few-shot
như GPT-2 để viết lại truy vấn. Galimzhanova et al. (2023) nghiên cứu GPT-3.5-Turbo được điều
chỉnh hướng dẫn và cho thấy rằng nó đạt được kết quả hiện đại nhất cho việc viết lại truy vấn đối
thoại.

Tinh chỉnh Bộ truy xuất cho QA đa lượt Một số công trình trước đây tinh chỉnh bộ truy xuất truy
vấn đơn lượt trên các cặp truy vấn đối thoại và ngữ cảnh trong miền (Feng et al., 2020; Gao et al.,
2022; Adlakha et al., 2022; Wu et al., 2023), do đó có thể trực tiếp lấy một sự nối tiếp của lịch sử
đối thoại và truy vấn hiện tại làm đầu vào. Trong công trình này, chúng tôi tập trung vào đánh giá
zero-shot. Chúng tôi tinh chỉnh bộ truy xuất truy vấn đơn lượt trên một bộ dữ liệu đa lượt chất lượng
cao. Sau đó, chúng tôi đánh giá khả năng zero-shot của bộ truy xuất được tinh chỉnh trên năm bộ
dữ liệu benchmark. Đáng ngạc nhiên, chúng tôi thấy rằng cách tiếp cận đơn giản này có thể đạt
được kết quả zero-shot tương đương với mô hình viết lại truy vấn hiện đại nhất, tức là GPT-3.5-
Turbo.

2.3 Điều chỉnh Hướng dẫn
Mục tiêu của điều chỉnh hướng dẫn là trang bị cho LLM khả năng tuân theo các hướng dẫn ngôn
ngữ tự nhiên (Wei et al., 2022a; Sanh et al., 2022; Mishra et al., 2022; Iyer et al., 2022; Du et al.,
2022; Ouyang et al., 2022; Wang et al., 2023; Zhang et al., 2023b; Gao et al., 2023; Chung et al.,
2022; Muennighoff et al., 2022; Xu et al., 2023a; Wang et al., 2022c; Zhou et al., 2023; Albalak et
al., 2024). Đã có một sự gia tăng trong việc phát triển các bộ dữ liệu điều chỉnh hướng dẫn chất
lượng cao, bao gồm FLAN (Chung et al., 2022), Self-Instruct (Wang et al., 2022b), unnatural
Instructions (Honovich et al., 2022), Dolly (Conover et al., 2023b), và OpenAssistant (Köpf et al.,
2023).

Mặc dù đã có nhiều nghiên cứu về điều chỉnh hướng dẫn, một số công trình tập trung vào việc cải
thiện RAG hoặc tạo sinh nhận thức ngữ cảnh cho QA. Lin et al. (2023b) giới thiệu một phương pháp
điều chỉnh hướng dẫn tăng cường truy xuất, thêm các đoạn được truy xuất hàng đầu k cho việc
tinh chỉnh LLM. Wang et al. (2024) áp dụng điều chỉnh hướng dẫn sau huấn luyện trước tăng cường
truy xuất. Ngược lại, chúng tôi đề xuất một phương pháp điều chỉnh hướng dẫn hai giai đoạn để
cải thiện tạo sinh với truy xuất hoặc ngữ cảnh được cung cấp. Chúng tôi thấy rằng việc thêm các
đoạn được truy xuất hàng đầu k cho việc tinh chỉnh LLM không giúp ích cho một loạt rộng các nhiệm
vụ QA đối thoại (xem §6.3 để biết chi tiết).

Tương tự như công trình gần đây (Zhang et al., 2023a), chúng tôi chứng minh rằng việc thêm một
lượng nhỏ mẫu "không thể trả lời" trong điều chỉnh hướng dẫn có thể điều hướng mô hình tạo ra
đầu ra "không thể trả lời" khi cần thiết, do đó giảm đáng kể ảo giác.

3 ChatQA
Trong phần này, chúng tôi đề xuất một phương pháp điều chỉnh hướng dẫn hai giai đoạn cho ChatQA.
Xem Hình 1 để minh họa. Phương pháp của chúng tôi bắt đầu với một mô hình nền tảng LLM được
huấn luyện trước. Ở giai đoạn 1, chúng tôi áp dụng tinh chỉnh có giám sát (SFT) như trong Ouyang
et al. (2022) trên một hỗn hợp các bộ dữ liệu tuân theo hướng dẫn và đối thoại. Sau đó, mô hình
của chúng tôi thể hiện khả năng tốt để tuân theo hướng dẫn như một tác nhân đối thoại. Tuy nhiên,
khả năng cho QA dựa trên ngữ cảnh hoặc RAG vẫn còn hạn chế. Do đó, chúng tôi giới thiệu một
giai đoạn tiếp theo, gọi là điều chỉnh hướng dẫn tăng cường ngữ cảnh, được thiết kế đặc biệt để
tăng cường khả năng tạo sinh nhận thức ngữ cảnh hoặc tăng cường truy xuất của mô hình trong
QA đối thoại.

[Tiếp tục dịch các phần còn lại của tài liệu với cùng mức độ chi tiết và chính xác...]

# 2307.14430.pdf
# Chuyển đổi từ PDF sang TXT  
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/datasets/2307.14430.pdf
# Kích thước tệp: 2009966 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Skill-it! Một Khung Kỹ Năng Dựa Trên Dữ Liệu để Hiểu và
Huấn Luyện Các Mô Hình Ngôn Ngữ
Mayee F. Chen*1Nicholas Roberts2Kush Bhatia1Jue Wang3Ce Zhang3, 4
Frederic Sala2Christopher Ré1
1Khoa Khoa học Máy tính, Đại học Stanford
2Khoa Khoa học Máy tính, Đại học Wisconsin-Madison
3Together AI
4Khoa Khoa học Máy tính, Đại học Chicago
28 tháng 7, 2023
Tóm tắt
Chất lượng dữ liệu huấn luyện ảnh hưởng đến hiệu suất của các mô hình ngôn ngữ lớn được tiền huấn luyện (LM). Với ngân sách token cố định, chúng tôi nghiên cứu cách tốt nhất để lựa chọn dữ liệu dẫn đến hiệu suất mô hình tốt trên các tác vụ hạ nguồn. Chúng tôi phát triển một khung mới dựa trên giả thuyết đơn giản: giống như con người có được các kỹ năng phụ thuộc lẫn nhau theo thứ tự có chủ ý, các mô hình ngôn ngữ cũng tuân theo một trật tự tự nhiên khi học một tập hợp kỹ năng từ dữ liệu huấn luyện của chúng. Nếu tồn tại trật tự như vậy, nó có thể được sử dụng để hiểu rõ hơn về LM và để huấn luyện hiệu quả dữ liệu. Sử dụng trực giác này, khung của chúng tôi chính thức hóa khái niệm về kỹ năng và một tập hợp kỹ năng có thứ tự theo dữ liệu liên quan. Đầu tiên, sử dụng cả dữ liệu tổng hợp và thực, chúng tôi chứng minh rằng các tập hợp kỹ năng có thứ tự này tồn tại, và sự tồn tại của chúng cho phép các kỹ năng nâng cao hơn được học với ít dữ liệu hơn khi chúng tôi huấn luyện trên các kỹ năng tiên quyết của chúng. Thứ hai, sử dụng khung đề xuất của chúng tôi, chúng tôi giới thiệu một thuật toán lấy mẫu dữ liệu trực tuyến, SKILL-IT, trên hỗn hợp các kỹ năng cho cả chế độ tiền huấn luyện liên tục và tinh chỉnh, nơi mục tiêu là học hiệu quả nhiều kỹ năng trong trường hợp trước và một kỹ năng riêng lẻ trong trường hợp sau. Trên LEGO tổng hợp trong thiết lập tiền huấn luyện liên tục, SKILL-IT đạt được độ chính xác cao hơn 36,5 điểm so với lấy mẫu ngẫu nhiên. Trên tập dữ liệu Natural Instructions trong thiết lập tinh chỉnh, SKILL-IT giảm mất mát xác thực trên kỹ năng đích 13,6% so với huấn luyện trên dữ liệu liên quan đến chính kỹ năng đích. Chúng tôi áp dụng khung kỹ năng của mình trên tập dữ liệu RedPajama gần đây để tiền huấn luyện liên tục một LM 3B tham số, đạt được độ chính xác cao hơn trên LM Evaluation Harness với 1B token so với cách tiếp cận cơ bản lấy mẫu đều trên các nguồn dữ liệu với 3B token.

1 Giới thiệu
Các mô hình ngôn ngữ lớn (LM) thể hiện khả năng đáng chú ý, bao gồm tạo ra nội dung sáng tạo [55], viết mã nguồn [8], hoặc trò chuyện với người dùng [7]. Một thành phần quan trọng trong việc cho phép các mô hình thực hiện các tác vụ như vậy là dữ liệu mà các mô hình được huấn luyện [17,19,59]. Một cách tự nhiên để mở khóa các khả năng cụ thể là cải thiện dữ liệu huấn luyện này. Tuy nhiên, không rõ làm thế nào để chọn dữ liệu từ một kho lớn cho những khả năng này với ngân sách token huấn luyện cố định, vì các phương pháp lựa chọn dữ liệu cho LM hiện đại chủ yếu dựa vào heuristic để lọc và trộn các tập dữ liệu khác nhau [32,59]. Chúng ta thiếu một khung chính thức để nắm bắt cách dữ liệu ảnh hưởng đến khả năng của mô hình và cách sử dụng dữ liệu này hiệu quả để cải thiện hiệu suất LM.

Để phát triển khung như vậy, chúng tôi lấy cảm hứng từ cách con người có được kiến thức. Một ý tưởng cổ điển trong văn học giáo dục là khái niệm kỹ năng tạo thành một hệ thống phân cấp học tập [65]. Ví dụ, một nghiên cứu phát hiện rằng học sinh học các kỹ năng toán học và khoa học nhanh nhất khi những kỹ năng này được trình bày theo một thứ tự cụ thể [11]. Chúng tôi tìm hiểu mức độ mà các thứ tự dựa trên kỹ năng tương tự đặc trưng cho việc huấn luyện LM. Những thứ tự như vậy, nếu tồn tại, có thể cung cấp hiểu biết tốt hơn về LM cũng như cơ chế để huấn luyện hiệu quả dữ liệu. Ví dụ, để huấn luyện LM cho việc tạo câu hỏi tiếng Tây Ban Nha, chúng tôi muốn biết liệu huấn luyện đầu tiên trên các tác vụ liên quan nhưng đơn giản hơn, chẳng hạn như ngữ pháp tiếng Tây Ban Nha và tạo câu hỏi tiếng Anh, có giúp ích không.

Chúng tôi nghiên cứu liệu ý tưởng về thứ tự kỹ năng có thể giúp chúng ta xây dựng một khung liên kết dữ liệu với việc huấn luyện và hành vi LM. Điều này đòi hỏi giải quyết hai thách thức xoay quanh mối liên hệ giữa kỹ năng và dữ liệu. Đầu tiên, để chỉ ra rằng tồn tại các tập hợp kỹ năng mà LM học hiệu quả nhất theo một thứ tự cụ thể, một định nghĩa hoạt động về kỹ năng LM và thứ tự kỹ năng phải được phát triển và xác thực trên dữ liệu. Trong các thí nghiệm ban đầu, chúng tôi điều tra liệu các nhóm ngữ nghĩa của dữ liệu, chẳng hạn như thuộc tính metadata hoặc cụm embedding, có đủ để đại diện cho một kỹ năng và đặc trưng cho cách các mô hình học. Ví dụ, chúng tôi phân vùng tập dữ liệu Alpaca [56] theo loại hướng dẫn—một kỹ thuật được sử dụng để nắm bắt sự đa dạng của tập dữ liệu [62]—nhưng chúng tôi phát hiện rằng lấy mẫu dựa trên loại hướng dẫn và lấy mẫu ngẫu nhiên dẫn đến hiệu suất mô hình tương tự, cho thấy rằng không phải bất kỳ khái niệm nào về nhóm dữ liệu hiện có có thể đặc trưng cho kỹ năng.

Thứ hai, những định nghĩa về kỹ năng này phải được sử dụng để xây dựng các phân phối lấy mẫu để thực sự cải thiện việc huấn luyện mô hình. Để phát triển tiêu chí cho thuật toán lựa chọn dữ liệu học kỹ năng hiệu quả, chúng tôi xác định các thách thức mà các phương pháp lựa chọn naive phải đối mặt. Phương pháp tiêu chuẩn lấy mẫu đều ngẫu nhiên trên dữ liệu không học kỹ năng tối ưu do không tính đến sự mất cân bằng và thứ tự kỹ năng. Các kỹ năng có thể được phân phối không đều trong dữ liệu, với các kỹ năng phức tạp hơn hiếm hoi—ví dụ, tiếng Tây Ban Nha và tạo câu hỏi (QG) chiếm 5% và 4% của tập dữ liệu Natural Instructions [63], tương ứng, nhưng QG tiếng Tây Ban Nha chỉ chiếm 0,2%. Lấy mẫu ngẫu nhiên cũng không cung cấp cơ chế nào để tính đến thứ tự huấn luyện cụ thể và cấu trúc phụ thuộc trên kỹ năng. Các kỹ thuật tinh vi hơn như học chương trình tính đến thứ tự cấp độ mẫu, nhưng không phải kỹ năng hoặc phụ thuộc của chúng. Khung mục tiêu của chúng tôi phải tính đến những vấn đề về mất cân bằng và thứ tự này.

Khung dựa trên kỹ năng Chúng tôi định nghĩa một kỹ năng là một đơn vị hành vi mà một mô hình có thể học bằng cách sử dụng một phần dữ liệu liên quan (Định nghĩa 2.1). Một tập hợp kỹ năng có thứ tự là một tập hợp các kỹ năng với một đồ thị kỹ năng có hướng không đầy đủ cũng không rỗng, trong đó một cạnh từ một kỹ năng tiên quyết đến một kỹ năng tồn tại nếu lượng huấn luyện cần thiết để học kỹ năng có thể được giảm nếu kỹ năng tiên quyết cũng được học (Định nghĩa 2.2, Hình 1 trái, giữa). Chúng tôi chỉ ra rằng các tập hợp kỹ năng có thứ tự tồn tại trong các tập dữ liệu tổng hợp và thực sử dụng định nghĩa hoạt động này. Thú vị là, sự tồn tại của các tập hợp kỹ năng có thứ tự này tiết lộ rằng người ta có thể học một kỹ năng nhanh chóng không phải bằng cách huấn luyện duy nhất trên kỹ năng đó, mà trên một hỗn hợp của kỹ năng đó và các kỹ năng tiên quyết. Ví dụ, trong Hình 3, chúng tôi quan sát rằng QG tiếng Tây Ban Nha có thể được học hiệu quả hơn khi mô hình cũng học QG tiếng Anh và tiếng Tây Ban Nha—chúng ta có thể đạt được mất mát xác thực thấp hơn 4% so với huấn luyện chỉ trên QG tiếng Tây Ban Nha với ngân sách bước huấn luyện tổng thể cố định.

Tiếp theo, với một tập hợp kỹ năng có thứ tự để huấn luyện, chúng tôi sử dụng khung của mình để đề xuất các phương pháp lựa chọn dữ liệu để LM học kỹ năng nhanh hơn: lấy mẫu phân tầng kỹ năng và một tổng quát hóa trực tuyến, SKILL-IT. Chúng tôi giải quyết vấn đề các kỹ năng phân phối không đều trong tập dữ liệu bằng cách đề xuất lấy mẫu phân tầng kỹ năng, một phương pháp đơn giản cho phép chúng tôi tối ưu hóa rõ ràng cho việc học kỹ năng bằng cách lấy mẫu đều các kỹ năng liên quan (như kỹ năng đích và các kỹ năng tiên quyết của nó trong tinh chỉnh). Lấy mẫu phân tầng kỹ năng sử dụng việc xây dựng tập hợp kỹ năng có thứ tự nhưng là tĩnh, không tích hợp thứ tự khi huấn luyện tiến hành và dẫn đến lấy mẫu quá mức các kỹ năng có thể đã được học sớm trong huấn luyện. Chúng tôi giải quyết vấn đề này bằng cách đề xuất thuật toán lựa chọn dữ liệu trực tuyến, SKILL-IT, để lựa chọn hỗn hợp kỹ năng huấn luyện phân bổ trọng số nhiều hơn cho việc học các kỹ năng chưa được học hoặc cho các kỹ năng tiên quyết có ảnh hưởng (Hình 1 phải). SKILL-IT được rút ra từ một bài toán tối ưu hóa trực tuyến trên các kỹ năng huấn luyện để tối thiểu hóa mất mát trên một tập hợp kỹ năng đánh giá với ngân sách dữ liệu cố định và đồ thị kỹ năng. SKILL-IT được lấy cảm hứng từ online mirror descent và có thể được điều chỉnh cho tiền huấn luyện liên tục, tinh chỉnh, hoặc đánh giá ngoài miền tùy thuộc vào mối quan hệ giữa tập hợp kỹ năng đánh giá và tập hợp kỹ năng huấn luyện.

Chúng tôi đánh giá SKILL-IT trên các tập dữ liệu tổng hợp và thực ở hai quy mô mô hình, 125M và 1,3B tham số. Đối với thiết lập tiền huấn luyện liên tục, chúng tôi chỉ ra trên LEGO tổng hợp [72] rằng chúng tôi đạt được cải thiện độ chính xác 35,8 điểm so với lựa chọn dữ liệu huấn luyện ngẫu nhiên và học chương trình [3]. Đối với thiết lập tinh chỉnh, chúng tôi chỉ ra rằng trên tập dữ liệu Natural Instructions được sử dụng rộng rãi [40,64], thuật toán của chúng tôi trên hỗn hợp kỹ năng có thể đạt được mất mát thấp hơn tới 13,6% trên kỹ năng đó so với huấn luyện duy nhất trên kỹ năng đó, với cùng ngân sách huấn luyện tổng thể. Đối với thiết lập ngoài miền khi các kỹ năng huấn luyện của chúng tôi không phù hợp hoàn hảo với kỹ năng đánh giá, thuật toán của chúng tôi có thể đạt được mất mát thấp nhất trên 11 trong số 12 kỹ năng đánh giá tương ứng với các danh mục tác vụ trong tập dữ liệu tác vụ kiểm tra Natural Instructions so với lấy mẫu ngẫu nhiên và phân tầng kỹ năng trên dữ liệu huấn luyện. Cuối cùng, chúng tôi áp dụng khung của mình vào một nghiên cứu trường hợp trên tập dữ liệu RedPajama 1,2 nghìn tỷ token gần đây [57]. Chúng tôi sử dụng hỗn hợp dữ liệu được tạo ra bởi SKILL-IT để tiền huấn luyện liên tục mô hình 3B tham số. Chúng tôi thấy rằng SKILL-IT đạt được độ chính xác cao hơn với 1B token so với lấy mẫu đều trên các nguồn dữ liệu với 3B token.

2 Khung kỹ năng
Đầu tiên, chúng tôi đề xuất định nghĩa về kỹ năng và tập hợp kỹ năng có thứ tự để chính thức hóa trực giác của chúng tôi về cách các mô hình học kỹ năng, và chúng tôi chứng minh rằng không phải bất kỳ khái niệm nào về nhóm dữ liệu hiện có có thể đặc trưng cho tập hợp kỹ năng có thứ tự trong tập dữ liệu. Sau đó, chúng tôi chứng minh sự tồn tại của các tập hợp kỹ năng có thứ tự trên dữ liệu tổng hợp và thực, cho thấy cách xem dữ liệu thông qua khung dựa trên kỹ năng có thể giúp huấn luyện và hiểu hiệu suất mô hình. Cuối cùng, chúng tôi khám phá việc khôi phục kỹ năng không giám sát từ dữ liệu, thấy rằng các phương pháp dựa trên embedding không khôi phục đầy đủ các kỹ năng tổng hợp.

2.1 Định nghĩa
Chúng tôi trước tiên trình bày định nghĩa về một kỹ năng riêng lẻ. Cho không gian đầu vào của tất cả dữ liệu văn bản có thể là X, trong đó x∈X là một mẫu văn bản riêng lẻ mà một LM dự đoán token tiếp theo f∈F:X→X được huấn luyện trên. Chúng tôi định lượng việc học thông qua một số liệu L:F×X→R, ánh xạ từ một mô hình và dữ liệu đánh giá đến một đại lượng vô hướng. Trong thiết lập của chúng tôi, chúng tôi sử dụng mất mát xác thực cross-entropy được áp dụng trên dự đoán token tiếp theo làm số liệu L của chúng tôi.

Định nghĩa 2.1 (Kỹ năng). Một kỹ năng s là một đơn vị hành vi với dữ liệu liên quan Xs⊆X sao cho nếu f được huấn luyện trên tập dữ liệu Ds⊂Xs, thì f có số liệu L cải thiện trên các mẫu thuộc Xs\Ds trung bình.

Định nghĩa kỹ năng này linh hoạt—nó chỉ đơn giản có nghĩa là với một tập dữ liệu huấn luyện liên quan đến kỹ năng, một mô hình f có số liệu cải thiện (ví dụ, giảm mất mát xác thực) khi được đánh giá trên dữ liệu xác thực liên quan đến kỹ năng này. Dưới định nghĩa này, một kỹ năng có thể là một tác vụ chi tiết, chẳng hạn như tạo câu hỏi tiếng Tây Ban Nha cho một tập con các bài báo Wikipedia, hoặc có thể được định nghĩa trên một nguồn dữ liệu, chẳng hạn như dự đoán token tiếp theo của dữ liệu pháp lý từ các phán quyết tòa án thuế. Tuy nhiên, định nghĩa tiếp theo của chúng tôi, tập hợp kỹ năng có thứ tự, có cấu trúc cụ thể hơn và cung cấp khung cho cách các mô hình học qua các kỹ năng phụ thuộc.

Định nghĩa 2.2 (Tập hợp kỹ năng có thứ tự, đồ thị kỹ năng). Một tập hợp kỹ năng có thứ tự cho f là một tập hợp kỹ năng S={s1,...,sk} trên đó có một đồ thị kỹ năng có hướng G=(S,E) trên tập hợp kỹ năng không đầy đủ cũng không rỗng, trong đó (si,sj)∈E nếu lượng dữ liệu cần thiết để học sj khi lấy mẫu đều từ Dsi∪Dsj không nhiều hơn lượng dữ liệu cần thiết khi lấy mẫu chỉ từ Dsj. Chúng tôi coi việc học một kỹ năng sj bằng f đạt được một giá trị nhất định của L hoặc thấp hơn trung bình trên Xsj\Dsj.

Định nghĩa này tách các đồ thị đầy đủ và rỗng làm các cực trị không nắm bắt các tập hợp kỹ năng có ý nghĩa. Chúng tôi thảo luận về ba loại đồ thị kỹ năng—đầy đủ, rỗng, trung gian—và ý nghĩa của chúng đối với lựa chọn dữ liệu. Đặc biệt, chúng tôi thảo luận về cách một số nỗ lực ban đầu định nghĩa kỹ năng trên tập dữ liệu thông qua các nhóm ngữ nghĩa dẫn đến các trường hợp cực trị (xem Phụ lục C.2 để có kết quả đầy đủ):

• Đồ thị đầy đủ chứng minh rằng tất cả kỹ năng ảnh hưởng lẫn nhau. Một phân vùng ngẫu nhiên là một ví dụ về tập hợp kỹ năng tạo ra đồ thị đầy đủ. Đồ thị này cho thấy rằng phương pháp tốt nhất để học bất kỳ kỹ năng hoặc tập hợp kỹ năng nào là lấy mẫu ngẫu nhiên trên tập dữ liệu. Đây không phải là thiết lập mà chúng ta có thể đạt được nhiều với lấy mẫu dựa trên kỹ năng. Ví dụ, sử dụng loại hướng dẫn làm kỹ năng trên tập dữ liệu Alpaca dẫn đến đồ thị kỹ năng ước tính gần như đầy đủ (97,4% dày đặc), và chúng tôi thấy rằng lấy mẫu phân tầng trên những kỹ năng này chỉ cải thiện mất mát xác thực trên mỗi kỹ năng 0,007 điểm so với lấy mẫu ngẫu nhiên trung bình (Hình 2 trái), cho thấy rằng việc sử dụng kỹ năng không cải thiện hiệu suất mô hình trong trường hợp này.

• Đồ thị rỗng chứng minh rằng mỗi kỹ năng độc lập. Điều này có thể xảy ra nếu kỹ năng quá chi tiết; ví dụ, học các bài toán toán học tiếng Tây Ban Nha khó có thể giúp tạo thơ tiếng Anh. Đồ thị này cho thấy rằng phương pháp tốt nhất để học một kỹ năng riêng lẻ là huấn luyện trên chính kỹ năng đó. Chúng tôi thấy rằng các đồ thị rỗng tồn tại trong dữ liệu thực; trong Hình 2 (giữa), sử dụng nguồn dữ liệu làm kỹ năng trên Pile of Law [21] dẫn đến đồ thị kỹ năng gần như rỗng (3,9% dày đặc).

• Các đồ thị không đầy đủ cũng không rỗng do đó cho thấy một thứ tự không tầm thường về cách kỹ năng ảnh hưởng lẫn nhau. Đây là thiết lập mà chúng tôi mong đợi rằng việc xác định kỹ năng và khai thác thứ tự của chúng sẽ giúp ích nhiều nhất. Trong Hình 2 phải, chúng tôi sử dụng danh mục tác vụ, nắm bắt các mẫu lý luận rộng hơn, làm kỹ năng trên Natural Instructions và thấy rằng đồ thị ước tính có mật độ trung gian (42,7% dày đặc). Chúng tôi cho thấy các ví dụ cụ thể về cách kỹ năng có thể được học hiệu quả hơn trên Natural Instructions trong Phần 2.2.

Mặc dù những nhóm trực quan này dẫn đến các tập hợp kỹ năng có thứ tự trên một số tập dữ liệu (ví dụ, danh mục tác vụ trên NI), điều này không phải lúc nào cũng đúng (ví dụ, loại hướng dẫn trên Alpaca và nguồn trên Pile of Law). Mặc dù những nhóm này nắm bắt một số khái niệm về sự đa dạng trong tập dữ liệu, phát hiện của chúng tôi cho thấy rằng không phải bất kỳ nhóm ngữ nghĩa nào cũng tạo ra tập hợp kỹ năng có thứ tự. Bây giờ chúng tôi chứng minh thực nghiệm rằng định nghĩa của chúng tôi về các tập hợp kỹ năng có thứ tự phù hợp với cách các mô hình học và có thể được khai thác để huấn luyện hiệu quả dữ liệu hơn.

2.2 Ví dụ về kỹ năng và tập hợp kỹ năng có thứ tự
Chúng tôi cung cấp các ví dụ về tập hợp kỹ năng có thứ tự trên tập dữ liệu LEGO tổng hợp, tập dữ liệu phép cộng tổng hợp, và tập con của tập dữ liệu Natural Instructions. Trên những tập dữ liệu này, chúng tôi thấy rằng các kỹ năng nhất định được học tốt hơn khi được huấn luyện cùng với các kỹ năng tiên quyết của chúng thay vì riêng lẻ.

Kỹ năng LEGO LEGO tổng hợp, lần đầu được giới thiệu trong [72], có thể đánh giá khả năng của mô hình tuân theo chuỗi lý luận. Trong tổng hợp này, các chữ cái của bảng chữ cái, A, là các biến mỗi biến có một số nhãn nhị phân trong {0,1}. Một mẫu riêng lẻ bao gồm k mệnh đề cho một số k cố định trên tập dữ liệu, mỗi mệnh đề có dạng a=gx trong đó a,x∈A và g là phủ định ("not") hoặc khẳng định ("val"), ví dụ chúng ta gán a giá trị của x, hoặc chúng ta gán a nhãn đối diện. Ở cuối câu, chúng tôi nhắc mô hình về giá trị của một trong những biến này là gì. Hai mẫu x∈X được đưa ra dưới đây cho k=5:
Đầu vào: b = not y, r = val 1, m = val b, q = val m, y = not r. Đầu ra: b = 1.
Đầu vào: c = val x, p = val f, x = val k, f = not c, k = val 0. Đầu ra: k = 0.

Những mẫu này mỗi mẫu tương ứng với một chuỗi lý luận; ví dụ mẫu đầu tiên có chuỗi r, y, b, m, q, trong đó việc biết nhãn của q đòi hỏi nhiều bước lý luận nhất. Chúng tôi định nghĩa kỹ năng thứ i si là khả năng của mô hình biết biến thứ i của chuỗi. Từ ví dụ trên, mẫu đầu tiên thuộc Xs3 và mẫu thứ hai thuộc Xs1. Để chứng minh sự tồn tại của các tập hợp kỹ năng có thứ tự, chúng tôi tiền huấn luyện liên tục mô hình GPT-Neo 125M tham số [5,13] trên các hỗn hợp khác nhau của kỹ năng LEGO với k=5. Trong Hình 3 (trái), chúng tôi thấy rằng trong 35,9% ít bước huấn luyện hơn, huấn luyện trên hỗn hợp cân bằng của Xs1, Xs2, và Xs3 dẫn đến cùng mất mát xác thực 0,01 như huấn luyện chỉ trên Xs3. Điều này cho thấy rằng s1, s2 giúp mở khóa hiệu suất trên s3 và có tồn tại các cạnh từ s1 hoặc s2 đến s3 trong đồ thị kỹ năng. Các quan sát bổ sung có sẵn trong Phụ lục D.1, nơi chúng tôi kiểm tra các cạnh khác cũng như các chuỗi lý luận phức tạp hơn, và đồ thị kỹ năng đầy đủ tương ứng với tập hợp kỹ năng có thứ tự cho LEGO với k=5 trong Hình 10.

Kỹ năng phép cộng Chúng tôi xem xét một biến thể của tập dữ liệu phép cộng 5 chữ số tổng hợp được phân tích trong [44]. Chúng tôi chỉ ra sự tồn tại của các tập hợp kỹ năng có thứ tự cho tập dữ liệu phép cộng 3 chữ số đơn giản hóa nơi chúng tôi coi mỗi dự đoán chữ số là một kỹ năng—các đầu ra, trong trường hợp này, là các số nguyên {0,1,...,9}. Các ví dụ có dạng như sau:
Đầu vào: A = 1 0 6 + 0 7 1 , A 0 = ? Đầu ra: 7 Đầu vào: A = 6 0 6 + 8 7 9 , A 2 = ? Đầu ra: 4

trong đó 'A 0' đề cập đến chữ số đơn vị của đầu ra (s1) và 'A 2' đề cập đến chữ số hàng trăm (s3). Trong Hình 3 (giữa), chúng tôi thấy rằng trong 32% ít bước huấn luyện hơn, huấn luyện trên hỗn hợp cân bằng của Xs1, và Xs2 dẫn đến cùng mất mát xác thực 0,01 như huấn luyện chỉ trên Xs1. Nghĩa là, kỹ năng phép cộng chữ số đơn vị có thể được cải thiện bằng cách đồng thời học kỹ năng phép cộng chữ số hàng chục, mặc dù cái trước không nên cần thông tin từ cái sau—điều này phù hợp với các quan sát từ công trình trước đó rằng các mô hình không phải lúc nào cũng học phép cộng chữ số đơn vị trước [44]. Đồ thị kỹ năng đầy đủ tương ứng với tập hợp kỹ năng có thứ tự trên phép cộng 3 chữ số trong Hình 11.

Kỹ năng Natural Instructions (NI) Chúng tôi chỉ ra rằng các tập hợp kỹ năng có thứ tự tồn tại trong NI [63] khi chúng tôi coi danh mục tác vụ là kỹ năng.
• Trong Hình 3 (trên phải), chúng tôi chỉ ra rằng các tập hợp kỹ năng có thứ tự tồn tại trên các danh mục tác vụ đa ngôn ngữ. Huấn luyện trên tạo câu hỏi tiếng Tây Ban Nha (QG) cùng với các phần bằng nhau của QG tiếng Anh, trả lời câu hỏi tiếng Tây Ban Nha (QA), và QA tiếng Anh dẫn đến mất mát xác thực thấp hơn 4,1% so với huấn luyện chỉ trên QG tiếng Tây Ban Nha. Đáng chú ý, cái trước chỉ sử dụng 25% dữ liệu QG tiếng Tây Ban Nha của cái sau. Điều này cho thấy rằng có các cạnh từ QA tiếng Tây Ban Nha, QA tiếng Anh, và QG tiếng Anh đến QG tiếng Tây Ban Nha.
• Trong Hình 3 (dưới phải), chúng tôi thấy rằng huấn luyện trên danh mục tác vụ Text Matching cùng với Stance Detection giúp giảm mất mát trên Stance Detection 11%. Điều này cho thấy rằng những danh mục này, cả hai đều liên quan đến hiểu mối quan hệ giữa hai văn bản đầu vào, chia sẻ một cạnh.

Đồ thị kỹ năng đầy đủ tương ứng với các tập hợp kỹ năng có thứ tự trên những danh mục tác vụ này trong Hình 13. Mặc dù việc coi danh mục tác vụ bằng kỹ năng có thể có nhiễu, những ví dụ này cho thấy rằng có tín hiệu trong dữ liệu thực cho thấy rằng các tập hợp kỹ năng có thứ tự có thể cải thiện hiệu quả dữ liệu.

2.3 Khôi phục kỹ năng
Một thành phần cuối cùng của việc đặc trưng cho kỹ năng là khôi phục không giám sát các tập hợp kỹ năng có thứ tự. Chúng tôi xem xét các phương pháp phân cụm dựa trên embedding và một phương pháp phân cụm dựa trên mất mát để khôi phục kỹ năng LEGO. Khi phân cụm dữ liệu bằng cách sử dụng các embedding được huấn luyện và tiền huấn luyện khác nhau, chúng tôi thấy rằng chúng không thể đạt được trên 39% độ chính xác trên LEGO. Thay vào đó, chúng tôi thấy rằng lấy 10 lần chạy huấn luyện ngẫu nhiên và phân cụm dữ liệu theo mất mát của chúng cho mỗi timestep cho mỗi lần chạy khôi phục các kỹ năng với độ chính xác 61% (Bảng 3). Trực giác đằng sau phương pháp này là mất mát xác thực trên các điểm từ cùng một kỹ năng có quỹ đạo tương tự khi các mô hình học. Chúng tôi thảo luận về phương pháp này nhiều hơn trong Phụ lục D.2.

3 Lựa chọn dữ liệu dựa trên kỹ năng
Bây giờ chúng tôi đã thiết lập sự tồn tại của các tập hợp kỹ năng có thứ tự, chúng tôi thảo luận về cách sử dụng chúng để lựa chọn dữ liệu. Chúng tôi trình bày bài toán lựa chọn dữ liệu để học qua các kỹ năng trong Phần 3.1. Chúng tôi thảo luận về cách học đồ thị kỹ năng sẽ được khai thác trong các phương pháp lựa chọn dữ liệu của chúng tôi trong Phần 3.2. Sau đó chúng tôi giới thiệu hai phương pháp lấy mẫu sử dụng đồ thị, một phương pháp lấy mẫu phân tầng kỹ năng đơn giản và phương pháp lấy mẫu trực tuyến SKILL-IT, trong Phần 3.3.

3.1 Phát biểu bài toán
Chúng tôi được cho một tập hợp kỹ năng huấn luyện có thứ tự Strain={strain,1,...,strain,k} trên dữ liệu huấn luyện, mỗi kỹ năng có tập hỗ trợ liên quan Xstrain,1,...Xstrain,k, và một tập hợp kỹ năng đánh giá có thứ tự Seval={seval,1,...,seval,m} của m kỹ năng đánh giá trên một tập dữ liệu đánh giá riêng. Chúng tôi nhằm lựa chọn n mẫu từ Strain thông qua hỗn hợp kỹ năng huấn luyện, p∈∆k-1, để đạt được ba mục tiêu tùy thuộc vào cách Seval được xây dựng:

• Tiền huấn luyện liên tục: khi Seval=Strain, mục tiêu của chúng tôi là lựa chọn hỗn hợp kỹ năng huấn luyện để học tất cả chúng.
• Tinh chỉnh: khi Seval⊂Strain, mục tiêu của chúng tôi là lựa chọn hỗn hợp kỹ năng huấn luyện để học một kỹ năng đích riêng lẻ hoặc tập con của những kỹ năng này.
• Ngoài miền: khi Seval∩Strain=∅, mục tiêu của chúng tôi là lựa chọn hỗn hợp kỹ năng huấn luyện để học một tập hợp kỹ năng đánh giá rời rạc mà chúng tôi không thể huấn luyện trên. Điều này có thể phát sinh khi chúng tôi có tập dữ liệu xác thực hạ nguồn riêng biệt hoặc các kỹ năng được xác định trong tập dữ liệu huấn luyện có nhiễu.

Hơn nữa, chúng tôi có một đồ thị kỹ năng G=(Strain∪Seval,E), trong đó E⊆Strain×Seval và A∈Rk×m là ma trận kề có trọng số, trong đó Aij mô tả sức mạnh của cạnh từ strain,i đến seval,j. Trong Bảng 1, chúng tôi tóm tắt cách ba thiết lập khác nhau được xây dựng và cách A thay đổi qua chúng. Tiếp theo, chúng tôi thảo luận về cách A có thể được ước tính từ dữ liệu.

3.2 Học đồ thị kỹ năng
Đồ thị kỹ năng quan trọng để xác định cách lấy mẫu từ tập hợp kỹ năng có thứ tự để huấn luyện hiệu quả. Chúng tôi trình bày hai phương pháp học đồ thị kỹ năng—brute-force và xấp xỉ tuyến tính. Các thuật toán được cung cấp trong Phụ lục B.2.

Theo định nghĩa 2.2, cách brute-force xác định cạnh liên quan đến việc cố định ngân sách huấn luyện tổng thể H bước và 1) huấn luyện và đánh giá mô hình trên mỗi si và 2) huấn luyện mô hình trên mỗi cặp (si,sj) và đánh giá trên si và sj. Nếu mất mát trên sj khi được huấn luyện trên cả si và sj thấp hơn, tồn tại một cạnh từ si đến sj. Phương pháp này có thời gian chạy O(Hk2), khả thi cho k nhỏ. Khi k lớn, chúng ta có thể xấp xỉ phương pháp này trong thời gian tuyến tính bằng cách huấn luyện trên mỗi si cho h<H bước và đặt Aij>0 nếu mất mát trên sj giảm trong h bước với thời gian chạy O(hk). Phương pháp tuyến tính này cần thiết trong thiết lập ngoài miền khi Seval và Strain rời rạc, vì chúng ta không huấn luyện trên dữ liệu liên quan đến Seval. Ngoài ra, cả hai phương pháp học đồ thị có thể được thực hiện trên mô hình nhỏ hơn, và đồ thị đã học có thể được sử dụng để lựa chọn dữ liệu cho việc huấn luyện mô hình lớn hơn (Phụ lục D.4).

3.3 Lấy mẫu nhận biết đồ thị kỹ năng
Chúng tôi trình bày hai phương pháp lấy mẫu trên hỗn hợp kỹ năng huấn luyện theo đồ thị kỹ năng: lấy mẫu phân tầng kỹ năng, lấy mẫu đều trên các kỹ năng huấn luyện liên quan theo A, và SKILL-IT, một tổng quát hóa trực tuyến kết hợp kiến thức về cách kỹ năng đang được học trong suốt quá trình huấn luyện.

3.3.1 Lấy mẫu phân tầng kỹ năng
Một phương pháp lấy mẫu đơn giản là loại bỏ các kỹ năng huấn luyện không có lợi cho các kỹ năng đánh giá và lấy mẫu đều trên tập hợp kỹ năng huấn luyện liên quan, mà chúng tôi gọi là lấy mẫu phân tầng kỹ năng. Đối với tiền huấn luyện liên tục, các kỹ năng liên quan là toàn bộ tập hợp kỹ năng huấn luyện; đối với mỗi strain,i∈Strain, Pr(strain,i)=1/k. Điều này cho phép mỗi kỹ năng có đủ dữ liệu huấn luyện. Đối với tinh chỉnh, các kỹ năng liên quan là kỹ năng đích và kỹ năng tiên quyết, có thể được xác định thông qua các mục dương của cột thứ i của A với Sprereq={strain,i:∃seval,j s.t.Aij>0}. Sau đó chúng tôi đặt Pr(s)=1/|Sprereq∪Seval| cho s∈Sprereq∪Seval.

Đối với thiết lập ngoài miền, lấy mẫu phân tầng kỹ năng trên tập hợp kỹ năng tiên quyết. Đối với mỗi s∈Sprereq, chúng tôi đặt Pr(s)=1/|Sprereq|. Tiếp theo, chúng tôi đề xuất thuật toán trực tuyến khai thác đồ thị một cách động để huấn luyện hiệu quả hơn.

3.3.2 Thuật toán lựa chọn dữ liệu trực tuyến SKILL-IT
Mặc dù tính đến các kỹ năng tiên quyết, một khuyết điểm của lấy mẫu phân tầng kỹ năng là ngay cả khi một kỹ năng đã đạt được mất mát xác thực đủ thấp sớm trong quá trình huấn luyện, chúng ta sẽ tiếp tục phân bổ cùng trọng số cho kỹ năng đó trong suốt quá trình huấn luyện. Do đó, chúng tôi hình thành bài toán lựa chọn dữ liệu của mình như một bài toán học trực tuyến và đề xuất SKILL-IT, vừa ưu tiên kỹ năng tiên quyết vừa ưu tiên kỹ năng chưa được học.

Chúng tôi được cho ngân sách T vòng và n mẫu tổng cộng để huấn luyện. Tại vòng t, chúng tôi chọn hỗn hợp pt∈∆k-1 từ đơn hình đơn vị k chiều, và đối với mỗi kỹ năng huấn luyện strain,i∈Strain, chúng tôi lấy mẫu từ Xstrain,i với tỷ lệ pit cho tổng cộng n/T mẫu mỗi vòng. Cho ft là mô hình tại đầu vòng t. Chúng ta có thể định nghĩa ft đệ quy như một hàm của mô hình vòng trước ft-1 và hỗn hợp pt-1 thông qua hàm động lực Φ:F×∆k-1→F; nghĩa là, ft=Φ(ft-1,pt-1).

Cho Leval,j(ft) là mất mát xác thực của ft trên seval,j. Mục tiêu của chúng tôi là chọn p1,...,pT để tối thiểu hóa mất mát trên mỗi kỹ năng đánh giá ở cuối huấn luyện:

minimize p1,...,pT∈∆k-1 (1/m)∑j=1^m Leval,j(fT). (1)

Bài toán tối ưu hóa này thách thức để giải quyết mà không có các giả định bổ sung. Để làm cho bài toán dễ xử lý, chúng tôi áp đặt quy tắc động lực rõ ràng cho mất mát của mỗi kỹ năng đánh giá Leval,j theo mất mát hiện tại và hỗn hợp dữ liệu. Giả sử để đơn giản rằng Seval⊆Strain, một quy tắc đơn giản sẽ là Leval,j(ft)=Leval,j(Φ(ft-1,pt-1)):=Leval,j(ft-1)(1-αpt-1^j) với α∈[0,1]. Nghĩa là, chúng tôi mong đợi rằng phân bổ nhiều dữ liệu hơn cho kỹ năng j sẽ dẫn đến mất mát xác thực trên kỹ năng j giảm. Tuy nhiên, biểu thức như vậy giả định rằng chỉ huấn luyện trên kỹ năng thứ j mới giúp học kỹ năng thứ j.

Thay vào đó, Phần 2.2 cho thấy rằng có các kỹ năng khác có thể giúp với kỹ năng thứ j. Chúng tôi đề xuất động lực sau:

Leval,j(ft)=Leval,j(ft-1)(1-A:,j^T pt-1), (2)

trong đó A:,j là cột có trọng số của tất cả kỹ năng ảnh hưởng đến seval,j, và chúng tôi hấp thụ vô hướng α vào A. Bài toán tối ưu hóa trong (1) do đó có thể được đơn giản hóa như sau:

minimize p1,...,pT∈∆k-1 (1/m)∑j=1^m Leval,j(fT) (3)
s.t ft=Φ(ft-1,pt-1) ∀t=1,...T
Leval,j(ft)=Leval,j(ft-1)(1-A:,j^T pt-1) ∀j∈[m]

Trong Phụ lục B, chúng tôi rút ra quy tắc cập nhật sau thông qua online mirror descent [45] cho tỷ lệ học η>0:

pit+1=pit exp(η∑j=1^m AijLeval,j(ft)). (4)

Ngoài ra, khi phương trình 4 được mở rộng, chúng ta có pit+1=pi1 exp(η∑τ=1^t ∑j=1^m AijLeval,j(fτ)). Vì tổng trên τ này dẫn đến sức mạnh cập nhật giảm dần, chúng tôi thay đổi nó thành cửa sổ trượt kích thước w. Phương pháp đầy đủ của chúng tôi trong Thuật toán 1.

Trực giác, tại mỗi bước chúng tôi điều chỉnh trọng số trên kỹ năng i dựa trên mất mát của các kỹ năng mà i ảnh hưởng, với giả định rằng nhiều dữ liệu huấn luyện hơn giúp giảm mất mát. Lưu ý rằng khi chúng tôi sử dụng thuật toán với đồ thị đầy đủ hoặc đồ thị rỗng, chúng tôi đạt được hành vi mong đợi được thảo luận trong Phần 2.1. Đối với đồ thị đầy đủ, thuật toán của chúng tôi giảm xuống lấy mẫu phân tầng. Khi chúng ta có tập hợp kỹ năng với đồ thị rỗng, quy tắc cập nhật giảm xuống lấy mẫu tỷ lệ với mất mát xác thực của mỗi kỹ năng.

4 Kết quả thực nghiệm
Với một tập hợp kỹ năng có thứ tự, chúng tôi nhằm xác thực khả năng của SKILL-IT lựa chọn dữ liệu để học kỹ năng hiệu quả trong các thiết lập tiền huấn luyện liên tục, tinh chỉnh và ngoài miền. Chúng tôi cung cấp bảng kết quả đầy đủ trong Phụ lục D.3.1 và kết quả nơi chúng tôi học đồ thị kỹ năng trên mô hình 125M và sử dụng nó cho mô hình 1,3B tham số trong Phụ lục D.4. Đồ thị kỹ năng trong Phụ lục C.2, quỹ đạo trọng số cho SKILL-IT trong Phụ lục D.3.2, và các nghiên cứu ablation về thành phần đồ thị và trực tuyến của SKILL-IT trong Phụ lục D.5.

4.1 Tiền huấn luyện liên tục
Thiết lập Chúng tôi đánh giá khả năng của SKILL-IT lựa chọn dữ liệu để học hiệu quả trên tất cả kỹ năng. Chúng tôi đo mất mát xác thực trung bình trên mỗi kỹ năng sau một số bước huấn luyện cố định. Chúng tôi xây dựng LEGO tổng hợp và phép cộng tổng hợp với k=5 và 3, tương ứng, và một tập dữ liệu mất cân bằng trên các kỹ năng. Trên tập dữ liệu Natural Instructions, chúng tôi sử dụng 23 trong số các danh mục tác vụ làm kỹ năng.

Baseline Chúng tôi so sánh SKILL-IT với ba baseline không tính đến kỹ năng: lấy mẫu ngẫu nhiên, học chương trình, và học chương trình ngược. Lấy mẫu ngẫu nhiên là thủ tục tiêu chuẩn để lựa chọn mẫu mà không có thông tin bổ sung. Học chương trình [3] và học chương trình ngược [67] ghi điểm các mẫu từ dễ nhất đến khó nhất và ngược lại, tương ứng, và lấy mẫu trên tập hợp mở rộng của các mẫu có điểm thấp nhất tại mỗi epoch; chúng tôi sử dụng mất mát của mô hình tiền huấn luyện để xếp hạng điểm. Chúng tôi đánh giá lấy mẫu phân tầng kỹ năng, sử dụng kiến thức về kỹ năng nhưng không trực tuyến, và bao gồm baseline chương trình kỹ năng bổ sung trong Phụ lục D.3.1.

Phân tích Kết quả của chúng tôi được hiển thị trong Hình 4. Qua các thí nghiệm, chúng tôi thấy rằng SKILL-IT vượt trội hơn các baseline không sử dụng kỹ năng cũng như lấy mẫu phân tầng kỹ năng. Trên tập dữ liệu LEGO, cả ba baseline không sử dụng khái niệm kỹ năng đều thể hiện mất mát ổn định trên bốn kỹ năng. Cả lấy mẫu phân tầng kỹ năng và SKILL-IT đều có thể giảm đáng kể mất mát trên tất cả kỹ năng, nhưng cái trước chậm hơn. Nửa chừng trong quá trình huấn luyện, SKILL-IT thể hiện cải thiện độ chính xác từ 9,9 đến 25,9 điểm so với các phương pháp khác, đạt độ chính xác cuối cùng là 99,4 (Hình 19). SKILL-IT vượt trội hơn lấy mẫu phân tầng kỹ năng bằng cách ban đầu phân bổ trọng số nhiều hơn cho kỹ năng tiên quyết và cuối cùng phân bổ trọng số nhiều hơn cho kỹ năng được học chậm hơn (Hình 20). Trên phép cộng tổng hợp với k=3, SKILL-IT hội tụ đến mất mát xác thực gần không nhanh hơn các baseline trên kỹ năng 1 và 2. Mặc dù baseline ngẫu nhiên có vẻ cạnh tranh thoạt nhìn, nó không học được kỹ năng 1 (cộng các chữ số đơn vị), điều này làm tổn hại mất mát trung bình trên mỗi kỹ năng. Trên NI, mất mát xác thực từ SKILL-IT thấp hơn 3,2% so với lấy mẫu ngẫu nhiên (Bảng 7). Kết quả của chúng tôi cho thấy rằng khai thác việc xây dựng và thứ tự kỹ năng quan trọng để học kỹ năng nhanh chóng.

4.2 Tinh chỉnh
Thiết lập Chúng tôi đánh giá khả năng của SKILL-IT lựa chọn dữ liệu từ một tập hợp kỹ năng huấn luyện có thứ tự để học một kỹ năng đích. Phản ánh Hình 3, chúng tôi đánh giá trên kỹ năng đích LEGO 3 (thứ ba trong chuỗi lý luận), trên kỹ năng 1 của phép cộng tổng hợp (phép cộng chữ số hàng đơn vị), và trên QG tiếng Tây Ban Nha và Stance Detection của NI.

Baseline Chúng tôi so sánh SKILL-IT với huấn luyện chỉ trên kỹ năng đích và lấy mẫu phân tầng kỹ năng trên kỹ năng tiên quyết và kỹ năng đích. Phương pháp lấy mẫu phân tầng kỹ năng sử dụng tập hợp kỹ năng có thứ tự để xác định kỹ năng tiên quyết, nhưng không khai thác chúng một cách động.

Phân tích Kết quả của chúng tôi được hiển thị trong Hình 5. Trên LEGO, SKILL-IT dẫn đến cùng mất mát xác thực 0,01 như huấn luyện chỉ trên kỹ năng đích trong 38,1% ít bước hơn. Chúng tôi quan sát xu hướng tương tự trên phép cộng, với SKILL-IT hội tụ đến mất mát xác thực 0,01 trong 59% ít bước hơn so với khi huấn luyện chỉ trên kỹ năng đích. Cuối cùng, trên NI, SKILL-IT cải thiện mất mát xác thực trên tạo câu hỏi tiếng Tây Ban Nha 5,3% và Stance Detection 13,6% so với chỉ huấn luyện trên kỹ năng tương ứng. Trong thiết lập này, một phần đáng kể của cải thiện so với huấn luyện chỉ trên kỹ năng đích đến từ việc xác định kỹ năng tiên quyết thông qua đồ thị đã học trong phương pháp lấy mẫu phân tầng kỹ năng. SKILL-IT có thể cải thiện hiệu suất hơn nữa với trọng số động tinh vi hơn trên kỹ năng tiên quyết.

4.3 Thiết lập ngoài miền
Natural Instructions Chúng tôi đánh giá khả năng của SKILL-IT lựa chọn dữ liệu từ một tập hợp kỹ năng huấn luyện để học một tập hợp kỹ năng đánh giá rời rạc mà chúng tôi không thể huấn luyện trên. Chúng tôi sử dụng tất cả 59 danh mục tác vụ trong phần tác vụ huấn luyện NI làm kỹ năng huấn luyện và 12 danh mục tác vụ trong phần tác vụ kiểm tra làm kỹ năng đánh giá. Chúng tôi so sánh SKILL-IT với lấy mẫu ngẫu nhiên và phân tầng kỹ năng, cả hai đều không khai thác mối quan hệ giữa kỹ năng huấn luyện và kỹ năng đánh giá. SKILL-IT đạt được mất mát thấp nhất trên 11 trong số 12 danh mục tác vụ so với lấy mẫu ngẫu nhiên và phân tầng kỹ năng (Hình 6, bảng trong Phụ lục).

RedPajama Chúng tôi sử dụng SKILL-IT để tạo ra hỗn hợp dữ liệu trên tập dữ liệu RedPajama. Kỹ năng huấn luyện là các nguồn dữ liệu tạo thành tập dữ liệu, và kỹ năng đánh giá là một số tác vụ từ Language Model Evaluation Harness [14]. SKILL-IT với T=1 (nghĩa là hỗn hợp tĩnh, dựa trên đồ thị) tạo ra hỗn hợp trong Hình 7 (phải). Chúng tôi tiền huấn luyện liên tục mô hình 3B tham số được huấn luyện trên một nghìn tỷ token cho ba tỷ token bổ sung bằng cách sử dụng hỗn hợp này, và thấy rằng nó vượt trội hơn lấy mẫu đều trên các nguồn dữ liệu (Hình 7 trái). Đặc biệt, SKILL-IT đạt được độ chính xác cao hơn với 1B token bổ sung so với đều với 3B token bổ sung.

5 Công trình liên quan
Lựa chọn dữ liệu cho LM Đã có một số nghiên cứu về lựa chọn dữ liệu quy mô lớn cho LM. Loại bỏ trùng lặp dữ liệu [1,22,32], trong đó các mẫu giống hệt hoặc gần giống hệt nhau được loại bỏ, là một phương pháp cho phép LM được huấn luyện trên các tập dữ liệu nhỏ hơn, sạch hơn và ngày càng được sử dụng như một bước tiền xử lý cho dữ liệu huấn luyện [4,59,71]. Các phương pháp khác được áp dụng ở quy mô lớn liên quan đến đảm bảo chất lượng cao của dữ liệu bằng cách lọc rõ ràng các mẫu hoặc so sánh tập dữ liệu huấn luyện với tập dữ liệu tham chiếu đã được làm sạch [7,31,59]. Các phương pháp trọng số quan trọng cũng đã được đề xuất để xác định dữ liệu huấn luyện từ một kho lớn để xấp xỉ tốt nhất một phân phối đích nhỏ hơn [69], và các hàm ảnh hưởng đã được sử dụng để lựa chọn tập con dữ liệu huấn luyện để cải thiện hiệu suất trên các tác vụ hạ nguồn [61]. Những phương pháp này có thể xác định dữ liệu liên quan đến phân phối đích cụ thể hoặc lọc ra dữ liệu chất lượng thấp theo một số heuristic, trong khi công việc của chúng tôi nhằm hiểu cách lựa chọn dữ liệu liên quan đến nhiều kỹ năng mà LM học.

Phát triển gần đây của LM đã chuyển trọng tâm từ nhấn mạnh quy mô của mô hình sang ưu tiên dữ liệu huấn luyện được sử dụng. Ví dụ, các mô hình như Alpaca [56], Vicuna [9], và Koala [15] đều dựa trên mô hình LLaMA kết hợp với dữ liệu hướng dẫn được tạo ra bởi LM hiện có. Báo cáo kỹ thuật của Palm 2 nói rằng hỗn hợp dữ liệu là thành phần quan trọng của mô hình cuối cùng [17], và mô hình MPT gần đây của Mosaic ML được huấn luyện trên hỗn hợp được thiết kế thủ công của tập dữ liệu RedPajama [42]. Tuy nhiên, những công trình này thiếu giải thích chặt chẽ về lý do tại sao các tập dữ liệu huấn luyện của chúng được xây dựng theo cách này.

Cuối cùng, có lẽ liên quan nhất đến phương pháp của chúng tôi là công trình đương đại DoReMi [68], sử dụng tối ưu hóa mạnh mẽ phân phối nhóm trên LM nhỏ hơn để lựa chọn hỗn hợp nguồn dữ liệu cho việc huấn luyện LM lớn hơn. Phương pháp của họ tập trung vào lựa chọn dữ liệu ở cấp độ nguồn dữ liệu để tối ưu hóa hiệu suất trường hợp xấu nhất trên các nguồn dữ liệu huấn luyện, thay vì ở cấp độ kỹ năng tổng quát hơn cho nhiều tập hợp kỹ năng đích. Hơn nữa, chúng tôi tập trung vào hiểu cách kỹ năng liên quan đến nhau và tạo ra một số thứ tự trong cách LM học bằng cách mô hình hóa rõ ràng cấu trúc đồ thị kỹ năng, mà chúng tôi thấy quan trọng để huấn luyện LM hiệu quả dữ liệu (xem ablation trong Phụ lục D.5).

Các phương pháp lựa chọn dữ liệu Nhiều phương pháp lựa chọn dữ liệu đã được đề xuất cho các thiết lập có giám sát, đặc thù tác vụ. Trong thiết lập này, mục tiêu điển hình nhất là ngưng tụ tập dữ liệu, nhằm xác định một tập con nhỏ của dữ liệu nắm bắt các thuộc tính của tập dữ liệu lớn hơn đối với mô hình. Một số phương pháp bao gồm xây dựng coresets [30,47], xác định các mẫu mà mô hình quên trong quá trình huấn luyện [58]; xác định các mẫu có gradient lớn nhất [46] hoặc gradient xấp xỉ gradient tổng thể [39]; phân cụm trong không gian embedding và lựa chọn điểm xa nhất khỏi trung tâm cụm [53]; và lựa chọn các mẫu có độ không chắc chắn hoặc entropy cao nhất [33]. Những phương pháp này cũng đã được chỉ ra là chuyển từ mô hình nhỏ hơn sang mô hình lớn hơn [10]. Không giống như những phương pháp này, chúng tôi nghiên cứu cách lựa chọn dữ liệu để học một hoặc nhiều kỹ năng ở cấp độ hỗn hợp cho LM thay vì cấp độ thể hiện.

Một lĩnh vực khác được quan tâm là lựa chọn dữ liệu cho thích ứng miền và học đa tác vụ. Đối với thích ứng miền, có một loạt phương pháp lựa chọn dữ liệu để phù hợp tốt nhất với phân phối đích. Ví dụ, phương pháp Moore-Lewis khớp dữ liệu dựa trên sự khác biệt trong cross-entropy bằng cách sử dụng mô hình được huấn luyện trên đích so với mô hình được huấn luyện trên nguồn [41]. Một số phương pháp khác đề xuất huấn luyện mô hình để phân biệt giữa nguồn và đích và lựa chọn điểm có độ không chắc chắn cao [50], hoặc lựa chọn điểm dựa trên một số phân kỳ trong không gian embedding [51]. So với những phương pháp này, công việc của chúng tôi tập trung vào học một hoặc nhiều kỹ năng và cũng thấy rằng heuristic dựa trên embedding không xác định đầy đủ kỹ năng.

Quy định dữ liệu Một góc nhìn khác về hiểu dữ liệu huấn luyện là quy định dữ liệu, tìm cách xác định dữ liệu nào chịu trách nhiệm cho các hành vi mô hình cụ thể. Hàm ảnh hưởng [28] và giá trị shapley [16] là hai cách để định lượng vai trò của các mẫu riêng lẻ. Datamodels [23] khớp một mô hình để dự đoán hành vi cho một tập con dữ liệu huấn luyện, cung cấp khung để hiểu các mẫu riêng lẻ cũng như phản thực tế tập dữ liệu. Simfluence [20] khớp một quá trình Markov với một tập hợp quỹ đạo huấn luyện để hiểu tinh vi hơn về cách dữ liệu ảnh hưởng đến huấn luyện. Chúng tôi tập trung vào hiểu cách các nhóm dữ liệu liên quan đến kỹ năng gợi ra khả năng mô hình rộng hơn, và sử dụng hiểu biết này để lựa chọn dữ liệu cho việc huấn luyện hiệu quả hơn.

Học chương trình Học chương trình [3] đề xuất hiển thị dữ liệu theo thứ tự từ mẫu dễ đến khó. Các tiêu chí khác nhau đã được sử dụng để xác định độ khó, và chương trình ngược cũng như các hàm nhịp độ và tỷ lệ trộn khác nhau đã được khám phá [54]. Học chương trình cũng có thể được thực hiện ở cấp độ nhóm [60]. Các phương pháp tinh vi hơn bao gồm tham số hóa mỗi mẫu với tầm quan trọng động [52], và cũng tính đến dữ liệu không liên quan và nhiễu [38]. Phương pháp của chúng tôi tương tự sử dụng chương trình, nhưng được định nghĩa trên đồ thị kỹ năng và không nhất thiết phải phù hợp với huấn luyện trên kỹ năng dễ nhất đến khó nhất.

Cách LM học Nhiều giải thích khác nhau về cách LM học từ dữ liệu đã được đề xuất. Một giả thuyết là tồn tại các khối xây dựng rời rạc, phổ quát của kiến thức LM được gọi là quanta, và quy luật công suất xuất hiện từ việc học trên một phân phối cụ thể của quanta theo đúng thứ tự [37]. Một giả thuyết khác là lý luận chuỗi suy nghĩ xuất hiện do các cụm cục bộ của các biến tiềm ẩn ảnh hưởng lẫn nhau, có thể được xác thực bằng cách nghiên cứu khả năng của LM thực hiện suy luận có điều kiện cho các biến trung gian [48]. Những người khác đã cung cấp phân tích lý thuyết về cách transformer học các chủ đề bằng cách nghiên cứu sự đồng xuất hiện của từ trong dữ liệu huấn luyện [34]. Thực nghiệm, cách các mô hình học vẫn là một bí ẩn—ví dụ, các mô hình được huấn luyện trên mã được phát hiện thực hiện khá tốt trong lý luận thường thức [36]. Công việc của chúng tôi khởi xướng một nghiên cứu về cách LM học các kỹ năng khác nhau và cách khai thác điều này để lựa chọn dữ liệu tốt hơn.

Lựa chọn tác vụ Trong học hỗ trợ đa tác vụ, mục tiêu là huấn luyện mô hình để hoạt động tốt trên tác vụ đích bằng cách lựa chọn các tác vụ nguồn có lợi nhất để huấn luyện. Người ta có thể sử dụng độ tương tự đặc trưng để lựa chọn tác vụ [29], nhưng chúng tôi thấy trong tổng hợp của mình rằng độ tương tự đặc trưng không phải lúc nào cũng khôi phục kỹ năng. Trong Taskonomy [70], một siêu đồ thị trên một tập hợp tác vụ được học và sử dụng để lựa chọn tác vụ. Các phương pháp được sử dụng để phát triển phân loại học có thể được áp dụng để mở rộng thêm việc học đồ thị của chúng tôi (ví dụ, nghiên cứu các thuộc tính bắc cầu và bậc cao hơn). Tuy nhiên, trọng tâm của họ là lựa chọn tác vụ trong thị giác máy tính thay vì lựa chọn dữ liệu cho LM để học kỹ năng. Cuối cùng, công trình đương đại TaskWeb [24] xây dựng đồ thị giữa 22 tác vụ NLP phổ biến để xác định tác vụ nguồn tốt nhất cho tác vụ đích. Định nghĩa của họ về một cạnh trong đồ thị tác vụ ít nghiêm ngặt hơn của chúng tôi (so sánh của họ là về việc huấn luyện trên dữ liệu bổ sung từ si có giúp với sj không, trong khi chúng tôi cố định tổng lượng dữ liệu huấn luyện trên cả si và sj). Nhìn chung, phương pháp của chúng tôi tương tự trong việc sử dụng đồ thị kỹ năng, nhưng chúng tôi kết hợp nó vào thuật toán lấy mẫu động. Hơn nữa, chúng tôi xem xét rộng hơn về kỹ năng, thay vì tác vụ, và đặc trưng khi chúng tôi mong đợi sử dụng đồ thị kỹ năng sẽ cải thiện hiệu suất mô hình.

Giáo dục Khái niệm kỹ năng đã được nghiên cứu trong giáo dục. Nghiên cứu cổ điển về hệ thống phân cấp học tập [66] xác định các tập hợp kỹ năng tạo thành khả năng phụ thuộc cho học sinh. Ví dụ, [12] xác định rằng để học sinh giải phương trình tuyến tính, có nhiều kỹ năng tiên quyết, từ đơn giản nhất là nhận dạng ký hiệu đến phức tạp nhất là khả năng cộng, trừ, nhân, và chia từ cả hai phía của phương trình. Gần đây hơn, ra quyết định về trình tự bài học dựa trên kỹ năng, ví dụ, những gì học sinh đã biết so với những gì bài học dạy, đã trở thành một lĩnh vực quan tâm trong học tập cá nhân hóa [49].

6 Kết luận
Với ngân sách dữ liệu cố định, việc biết dữ liệu nào để huấn luyện để tạo ra các khả năng khác nhau trong LM là thách thức. Khi LM tiếp tục cải thiện, việc trích xuất càng nhiều tín hiệu càng tốt từ dữ liệu và định hướng tín hiệu đó để có được nhiều khả năng sẽ trở nên ngày càng quan trọng. Trong bài báo này, chúng tôi giới thiệu khung dựa trên kỹ năng để hiểu cách LM học và lựa chọn dữ liệu huấn luyện. Chúng tôi hy vọng nghiên cứu của chúng tôi mời gọi những người khác xây dựng dựa trên khái niệm kỹ năng như vậy và khám phá thêm cách liên kết kỹ năng với dữ liệu.

Lời cảm ơn
Chúng tôi cảm ơn Together Computer (https://together.xyz/) đã cung cấp một phần tính toán được sử dụng để huấn luyện các mô hình trong bài báo này. Chúng tôi cảm ơn Sabri Eyuboglu, Karan Goel, Arjun Desai, Neel Guha, Michael Zhang, Vishnu Sarrukai, Simran Arora, Ben Spector, Brandon Yang, Gautam Machiraju, và Sang Michael Xie về phản hồi và thảo luận hữu ích của họ. Chúng tôi biết ơn sự hỗ trợ của NIH dưới số U54EB020405 (Mobilize), NSF dưới số CCF1763315 (Beyond Sparsity), CCF1563078 (Volume to Velocity), và 1937301 (RTML); US DEVCOM ARL dưới số W911NF-21-2-0251 (Interactive Human-AI Teaming); ONR dưới số N000141712266 (Unifying Weak Supervision); ONR N00014-20-1-2480: Understanding and Applying Non-Euclidean Geometry in Machine Learning; N000142012275 (NEPTUNE); NXP, Xilinx, LETI-CEA, Intel, IBM, Microsoft, NEC, Toshiba, TSMC, ARM, Hitachi, BASF, Accenture, Ericsson, Qualcomm, Analog Devices, Google Cloud, Salesforce, Total, chương trình HAI-GCP Cloud Credits for Research, Stanford Data Science Initiative (SDSI), và các thành viên của dự án Stanford DAWN: Facebook, Google, và VMWare. FS được hỗ trợ bởi NSF CCF2106707 và Wisconsin Alumni Research Foundation (WARF). Chính phủ Hoa Kỳ được ủy quyền sao chép và phân phối bản in lại cho mục đích Chính phủ bất chấp bất kỳ chú thích bản quyền nào. Bất kỳ ý kiến, phát hiện, và kết luận hoặc khuyến nghị nào được thể hiện trong tài liệu này là của các tác giả và không nhất thiết phản ánh quan điểm, chính sách, hoặc xác nhận, được thể hiện rõ ràng hay ngụ ý, của NIH, ONR, hoặc Chính phủ Hoa Kỳ.

# 2305.14739.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/hallucination/2305.14739.pdf
# Kích thước tệp: 873576 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Tin Tưởng Bằng Chứng Của Bạn:
Ít Ảo Giác Hơn với Giải Mã Nhận Thức Ngữ Cảnh
Weijia Shi1∗Xiaochuang Han1∗
Mike Lewis2Yulia Tsvetkov1Luke Zettlemoyer1Scott Yih2
1Đại học Washington, Seattle, WA,2Meta AI
{swj0419, xhan77}@cs.washington.edu
Tóm tắt
Các mô hình ngôn ngữ (LM) thường gặp khó khăn trong việc chú ý đầy đủ đến ngữ cảnh đầu vào, và tạo ra các văn bản không trung thực hoặc chứa ảo giác. Để giảm thiểu vấn đề này, chúng tôi trình bày giải mã nhận thức ngữ cảnh (CAD), tuân theo một phân phối đầu ra tương phản nhằm khuếch đại sự khác biệt giữa xác suất đầu ra khi một mô hình được sử dụng có và không có ngữ cảnh. Các thí nghiệm của chúng tôi cho thấy CAD, không cần đào tạo bổ sung, cải thiện đáng kể tính trung thực của các họ LM khác nhau, bao gồm OPT, GPT, LLaMA và FLAN-T5 cho các nhiệm vụ tóm tắt (ví dụ, tăng 14.3% cho LLaMA trong các chỉ số thực tế). Hơn nữa, CAD đặc biệt hiệu quả trong việc ghi đè kiến thức trước đây của mô hình khi nó mâu thuẫn với ngữ cảnh được cung cấp, dẫn đến cải thiện đáng kể trong các nhiệm vụ cần giải quyết xung đột kiến thức.

1 Giới thiệu
Các mô hình ngôn ngữ (LM) cực kỳ hiệu quả trong việc tạo ra các đoạn tiếp theo mạch lạc và trôi chảy của một gợi ý hoặc tiền tố tài liệu. Trong quá trình tạo, chúng chủ yếu dựa vào hai nguồn kiến thức: (1) kiến thức trước đây, được học trong quá trình tiền đào tạo và lưu trữ ngầm trong các tham số mô hình; (2) kiến thức ngữ cảnh, được truyền qua như là đầu vào trong ngữ cảnh tiền tố (Chan et al., 2022). Tuy nhiên, vẫn còn là một câu hỏi mở về cách một LM được tiền đào tạo, đặc biệt là LM thông thường không có tinh chỉnh theo nhiệm vụ cụ thể, cân bằng hai nguồn kiến thức này trong quá trình tạo.

Nghiên cứu trước đây cho thấy các LM có thể thất bại trong việc chú ý đầy đủ đến thông tin mới được giới thiệu trong kiến thức ngữ cảnh. Điều này có thể dẫn đến ảo giác trong tóm tắt (Maynez et al., 2020; Pagnoni et al., 2021), nơi các bản tóm tắt được tạo bao gồm các sự kiện không có trong tài liệu đầu vào. Sự chú ý không đầy đủ đến ngữ cảnh đặc biệt có vấn đề khi kiến thức ngữ cảnh mâu thuẫn với kiến thức trước đây (Longpre et al., 2021; Zhou et al., 2023). Ví dụ, khi LLaMA (Touvron et al., 2023) được trình bày với một tài liệu mới nhất "Argentina đã thắng World Cup FIFA năm 1978, 1986 và 2022 ..." trong ngữ cảnh của nó (Hình 1), nó vẫn dự đoán "Hai" khi phản hồi câu hỏi "Argentina đã thắng bao nhiêu World Cup?", một phần do dữ liệu đào tạo lỗi thời.

Trong công việc này, chúng tôi trình bày một phương pháp giải mã nhận thức ngữ cảnh (CAD) đơn giản để khuyến khích LM chú ý đến ngữ cảnh của nó trong quá trình tạo. Như được thể hiện trong Hình 1, CAD lấy mẫu từ một phân phối đầu ra mới, khuếch đại sự khác biệt giữa xác suất đầu ra có và không có tài liệu ngữ cảnh. Điều này cung cấp một hình thức mới của giải mã tương phản (Li et al., 2022), hiệu quả giảm trọng số kiến thức trước đây khi thông tin ngữ cảnh liên quan hơn được cung cấp. CAD có thể được sử dụng với các mô hình ngôn ngữ được tiền đào tạo sẵn có mà không cần đào tạo bổ sung.

Kết quả thí nghiệm từ các nhiệm vụ tóm tắt cho thấy giải mã nhận thức ngữ cảnh cải thiện đáng kể tính trung thực tạo của các LM thông thường khác nhau bao gồm OPT (Zhang et al., 2022), GPT-Neo (Black et al., 2021), LLaMA (Touvron et al., 2023) và các LM được tinh chỉnh theo hướng dẫn như FLAN (Chung et al., 2022). Ví dụ, khi áp dụng cho LLaMA-30B trong CNN-DM, CAD dẫn đến cải thiện đáng kể trong cả ROUGE-L (21%)

--- TRANG 2 ---
và các chỉ số đánh giá thực tế tóm tắt (14.3%).
Đáng chú ý hơn, CAD đặc biệt có lợi cho các nhiệm vụ xung đột kiến thức, nơi ngữ cảnh chứa thông tin mâu thuẫn với kiến thức trước đây của mô hình. CAD mang lại cải thiện 2.9 lần cho LLaMA-30B trên tập dữ liệu QA xung đột kiến thức (Longpre et al., 2021). Hơn nữa, chúng tôi quan sát thấy lợi ích này được CAD mang lại tăng theo kích thước mô hình trong các nhiệm vụ xung đột kiến thức. Những kết quả này chứng minh tiềm năng của CAD trong việc giảm thiểu ảo giác trong tạo văn bản và ghi đè kiến thức trước đây bằng thông tin đáng tin cậy và được tin tưởng.

2 Phương pháp
2.1 Kiến thức nền tảng
Cho một mô hình ngôn ngữ θ, một truy vấn đầu vào x, và một ngữ cảnh c chứa một số kiến thức bên ngoài không quen thuộc hoặc mâu thuẫn với kiến thức trước đây của mô hình, chúng tôi yêu cầu mô hình θ tạo ra một phản hồi y cho truy vấn và ngữ cảnh. Phản hồi có thể được lấy mẫu trực tiếp (tự hồi quy) từ phân phối xác suất có điều kiện trên truy vấn x và ngữ cảnh c:

yt∼pθ(yt∣c,x,y<t)
∝exp logitθ(yt∣c,x,y<t)

Tuy nhiên, trong các trường hợp ngữ cảnh c chứa kiến thức ngoài phân phối so với θ, chúng tôi giả định rằng mô hình có thể gặp khó khăn trong việc chú ý hiệu quả đến c và quá phụ thuộc vào kiến thức trước đây được mã hóa trong θ. Ví dụ, như được minh họa trong Hình 1, khi ngữ cảnh c nói "Argentina đã thắng World Cup FIFA năm 1978, 1986 và 2022 ...", nó mâu thuẫn với kiến thức trước đây lỗi thời của LM rằng Argentina đã thắng World Cup hai lần. Mô hình ngôn ngữ vẫn có thể dự đoán sai "Hai" ngay cả khi được trình bày với ngữ cảnh c và truy vấn x.

2.2 Giải mã nhận thức ngữ cảnh
Để giảm thiểu những vấn đề như vậy, chúng tôi tách biệt kiến thức trước đây khỏi phân phối đầu ra ban đầu của mô hình một cách tương phản. Ở đây, chúng tôi mô hình hóa kiến thức trước đây là pθ(yt∣x,y<t) và điều chỉnh phân phối xác suất đầu ra ban đầu của mô hình bằng cách sử dụng thông tin tương hỗ điểm (PMI) giữa ngữ cảnh c và việc tạo yt, có điều kiện trên x,y<t. Chính thức, chúng tôi có:

yt∼˜pθ(yt∣c,x,y<t)
∝pθ(yt∣c,x,y<t)(pθ(yt∣c,x,y<t)
pθ(yt∣x,y<t))α

trong đó xác suất đầu ra là một tích của các chuyên gia của xác suất đầu ra ban đầu và PMI được trọng số bởi α. Về cơ bản, các đầu ra trở nên có khả năng hơn nhiều khi ngữ cảnh được bao gồm được ưu tiên (Hình 1).

Biểu thức này không phải là một phân phối xác suất hợp lệ và cần được chuẩn hóa trên tất cả các giá trị có thể có của yt. Bằng cách sắp xếp lại các thuật ngữ, chúng tôi thu được dạng cuối cùng:

yt∼softmax [(1+α)logitθ(yt∣c,x,y<t)
−αlogitθ(yt∣x,y<t)]

α lớn hơn có nghĩa là trọng số nhiều hơn trên điều chỉnh của chúng tôi (α=0 giảm về giải mã thông thường).¹ Chúng tôi gọi phương pháp đơn giản này là giải mã nhận thức ngữ cảnh. Từ phân phối đầu ra đã điều chỉnh ˜p, chúng tôi có thể áp dụng các chiến lược lấy mẫu khác nhau, như lấy mẫu nucleus (Holtzman et al., 2019).

Về cơ bản, giải mã nhận thức ngữ cảnh chỉ là một ensemble tương phản giữa các logit của pθ(yt∣c,x,y<t) và pθ(yt∣x,y<t). Một mục tiêu tương phản tương tự là phổ biến trong tạo hình ảnh, nơi các mô hình khuếch tán không phân loại (Ho và Salimans, 2022) dự đoán nhiễu khuếch tán với (1+α)ϵθ(x,c)−αϵθ(x), với c là một điều khiển cho hình ảnh. Trong tạo văn bản, Malkin et al. (2021) đề xuất tăng cường tính mạch lạc với cùng trực quan, tập trung vào việc tương phản đầu vào đầy đủ và đầu vào ngắn không có tiền đề, thúc đẩy tính mạch lạc w.r.t. ngữ cảnh dài. Thay vì sử dụng một mô hình θ duy nhất trong công việc này, các mô hình khác nhau cũng có thể được sử dụng trong điều chỉnh phân phối để giảm bớt các hành vi mô hình không mong muốn hoặc chưng cất khả năng của mô hình chuyên gia (Liu et al., 2021; Li et al., 2022).

3 Thiết lập thí nghiệm
Chúng tôi thực hiện đánh giá trên các nhiệm vụ yêu cầu LM đọc và lý luận trên các ngữ cảnh và tạo ra các đầu ra trung thực với ngữ cảnh. Theo công việc trước đây (Zhang et al., 2023; Zhou et al., 2023), chúng tôi đánh giá các mô hình bằng cách sử dụng prompting.

¹ Nếu chúng tôi xác định một kiến thức bên ngoài c độc lập có điều kiện với việc tạo, pθ(yt∣c,x,y<t)=pθ(yt∣x,y<t), ngay cả một α khác không cũng sẽ không có tác động đến phân phối đầu ra ban đầu.

--- TRANG 3 ---
3.1 Tập dữ liệu và chỉ số
Tóm tắt Chúng tôi tiến hành các thí nghiệm tóm tắt trên hai tập dữ liệu tin tức: CNN-DM (See et al., 2017) và XSUM (Narayan et al., 2018). Chúng tôi sử dụng ROUGE-L (Lin, 2004) để đánh giá chất lượng tóm tắt. Để đo lường tính nhất quán thực tế của các bản tóm tắt, chúng tôi áp dụng BERT-Precision (Pagnoni et al., 2021) cũng như FactKB (Feng et al., 2023), đã được chứng minh đạt được tương quan cao với đánh giá con người trên hai tập dữ liệu tóm tắt.

Xung đột kiến thức Chúng tôi đánh giá hiệu suất trên hai tập dữ liệu xung đột kiến thức: MemoTrap (Liu và Liu, 2023) và NQ-Swap (Longpre et al., 2021). MemoTrap được tạo ra để điều tra liệu các mô hình ngôn ngữ có thể rơi vào bẫy ghi nhớ không. Nó bao gồm các hướng dẫn khuyến khích mô hình ngôn ngữ hoàn thành một câu tục ngữ nổi tiếng với một từ kết thúc khác với kết thúc thường được sử dụng (ví dụ, Viết một câu trích dẫn kết thúc bằng từ "early": Better late than ). NQ-Swap dựa trên một tập dữ liệu QA, câu hỏi tự nhiên (NQ) (Kwiatkowski et al., 2019), nơi mục tiêu là trả lời câu hỏi dựa trên một tài liệu vàng đáng tin cậy. Để tạo ra NQ-Swap, Longpre et al. (2021) trước tiên xác định các câu hỏi trong NQ với các câu trả lời thực thể có tên, tìm tài liệu hỗ trợ cho mỗi câu hỏi và sau đó thay thế thực thể câu trả lời vàng trong tài liệu bằng một thực thể ngẫu nhiên. Một LM trung thực nên tạo ra thực thể đã thay thế làm câu trả lời khi được đưa câu hỏi và tài liệu đã sửa đổi. Chúng tôi cũng bao gồm tập dữ liệu NQ gốc với câu hỏi và tài liệu gốc để đánh giá. Chúng tôi sử dụng Exact Match (EM) làm chỉ số đánh giá cho NQ-Swap, NQ và MemoTrap.

Trong Bảng 1, chúng tôi hiển thị các ví dụ minh họa về ngữ cảnh mà chúng tôi nhằm tăng trọng số cho mô hình và các truy vấn trên các tập dữ liệu khác nhau. Chúng tôi hy vọng các LM chú ý nhiều hơn đến tài liệu nguồn trong XSUM và NQ-Swap. Mặt khác, chúng tôi hy vọng các LM tập trung nhiều hơn vào hướng dẫn trong MemoTrap.

3.2 Mô hình và cơ sở
Chúng tôi áp dụng CAD cho các mô hình ngôn ngữ được tiền đào tạo bao gồm OPT (13B và 30B) (Zhang et al., 2022), GPT-Neo (2.7B và 20B) (Black et al., 2021), LLaMA (13B và 30B) (Touvron et al., 2023) và các mô hình ngôn ngữ được tinh chỉnh theo hướng dẫn như FLAN-T5 (XL 3B và XXL 11B) (Chung et al., 2022).

XSUM
c Bài báo: Prison Link Cymru có 1,099 giới thiệu trong năm 2015-16 và nói rằng một số cựu tội phạm đã sống lang thang lên đến một năm trước khi tìm được chỗ ở phù hợp ...
x Tóm tắt bài báo trong một câu. Tóm tắt:

NQ-SWAP
c Giám đốc điều hành Tesla Elon Musk hiện đang phụ trách Twitter, CNBC đã biết được ...
x Ai là CEO của Twitter bây giờ?

MemoTrap
c Viết một câu trích dẫn kết thúc bằng từ "early":
x Better late than

Bảng 1: Minh họa các đầu vào cho CAD được áp dụng cho mỗi tập dữ liệu. CAD tăng trọng số ngữ cảnh c (màu đỏ) bằng cách lấy mẫu mỗi token từ softmax [(1+α)logitθ(yt∣c,x,y<t)−αlogitθ(yt∣x,y<t)].

CAD giới thiệu một siêu tham số α để kiểm soát mức độ điều chỉnh. Chúng tôi đặt α=0.5 cho tất cả các mô hình được đánh giá trên các tập dữ liệu tóm tắt và α=1 cho tất cả các mô hình được đánh giá trên các tập dữ liệu xung đột kiến thức. Chúng tôi quan sát thấy α=0.5 thường cho kết quả tốt trên tất cả các cài đặt và tất cả các tập dữ liệu, nhưng α hơi cao hơn hiệu quả hơn trong thiết lập xung đột kiến thức, nơi kiến thức trước đây cần được loại bỏ nhiều hơn. Chúng tôi điều tra tác động của α trong Phần 4.2.

Đối với các cơ sở, chúng tôi sử dụng giải mã thông thường theo công việc trước đây (Longpre et al., 2021; Kwiatkowski et al., 2019) để sử dụng giải mã tham lam cho các nhiệm vụ xung đột kiến thức và lấy mẫu top-p với p=0.9 cho các nhiệm vụ tóm tắt (Holtzman et al., 2019). Đối với CAD, chúng tôi sử dụng cùng các chiến lược lấy mẫu trên phân phối xác suất đầu ra đã điều chỉnh.

4 Kết quả
4.1 Kết quả chính
Tóm tắt Bảng 2 báo cáo kết quả trên CNN-DM và XSUM. Chúng tôi quan sát thấy CAD vượt trội hơn thuật toán giải mã chuẩn với biên độ lớn trong tất cả tám mô hình trên cả hai tập dữ liệu. Cụ thể, khi áp dụng cho LLAMA-30B trong CNN-DM, CAD dẫn đến tăng 21% trong ROUGE-L, tăng 14.3% trong factKB và tăng 7.8% trong BERT-P. Kết quả này chứng minh rằng CAD có thể cải thiện hiệu quả chất lượng và tính thực tế của các bản tóm tắt được tạo từ một tập đa dạng các mô hình ngôn ngữ.

--- TRANG 4 ---
[Bảng 2: Kết quả so sánh hiệu suất CAD và phương pháp giải mã thông thường trên CNN-DM và XSUM]

[Bảng 3: Kết quả so sánh hiệu suất CAD và phương pháp giải mã thông thường trên các tập dữ liệu xung đột kiến thức]

Xung đột kiến thức Kết quả của chúng tôi cho các tập dữ liệu xung đột kiến thức, NQ-SWAP và MemoTrap, cũng như NQ gốc được trình bày chi tiết trong Bảng 3. CAD tốt hơn đáng kể so với giải mã thông thường trong tất cả các thiết lập, ngoại trừ một sự giảm nhẹ được quan sát cho FLAN-T5 trên tập dữ liệu NQ không xung đột.² Mặc dù vậy, CAD đạt được hiệu suất tốt hơn đáng kể trên các tập dữ liệu xung đột kiến thức, ví dụ, CAD cải thiện GPT-Neo 20B 54.4% trên Memotrap và 128% trên NQ-SWAP. Cải thiện đáng kể này cho thấy rằng giải mã nhận thức ngữ cảnh đặc biệt có lợi cho các LM tuân thủ ngữ cảnh đã cho, trong các tình huống mà kiến thức trước đây của mô hình mâu thuẫn với kiến thức ngữ cảnh.

4.2 Phân tích
Phân tích định tính Chúng tôi cung cấp các ví dụ định tính cho XSUM và Memotrap trong Bảng 4. Trong XSUM, giải mã thông thường tạo ra văn bản không được đề cập trong bài báo, trong khi CAD tạo ra đầu ra chỉ dựa trên thông tin trong bài báo đầu vào. Đối với MemoTrap, giải mã chuẩn bỏ qua hướng dẫn và tạo ra kết thúc được ghi nhớ, trong khi CAD tuân thủ hướng dẫn trong ngữ cảnh đã cho và tạo ra đầu ra mong muốn.

CAD mang lại cải thiện nhất quán cho các LM với kích thước khác nhau. Trong Bảng 2 và 3, chúng tôi cho thấy CAD có thể được sử dụng để tăng cường một tập đa dạng các họ LM, bao gồm OPT, GPT-Neo, LLaMA, và FLAN-T5. Ở đây chúng tôi tiếp tục điều tra liệu CAD có hiệu quả trong việc cải thiện các mô hình ngôn ngữ với kích thước khác nhau không. Cụ thể, chúng tôi tập trung vào các mô hình OPT trên một loạt kích thước: 125M, 350M, 1.3B, 2.7B, 6.7B, 13B, 30B. Như được mô tả trong Hình 2, chúng tôi quan sát thấy lợi ích hiệu suất được mang lại bởi

² Sự giảm nhẹ này có thể được quy cho việc tập dữ liệu NQ cụ thể này được bao gồm trong các tập tinh chỉnh hướng dẫn được sử dụng bởi FLAN-T5, và do đó, mô hình đã được đào tạo trước đó trên nó.

--- TRANG 5 ---
Hình 2: Các mô hình OPT với kích thước khác nhau đều được hưởng lợi từ CAD một cách nhất quán. Trục x chỉ ra kích thước của các mô hình ngôn ngữ và trục y là hiệu suất.

[Ví dụ định tính về XSUM và MemoTrap được trình bày trong Bảng 4]

CAD duy trì nhất quán với các kích thước mô hình khác nhau trong CNN-DM. Trong Memotrap và NQSWAP, lợi ích này tăng theo kích thước mô hình, cho thấy các LM lớn hơn có thể có xu hướng lớn hơn trong việc dựa vào kiến thức trước đây thay vì đọc ngữ cảnh, do đó được hưởng lợi nhiều hơn từ CAD.

Tác động của mức độ điều chỉnh α Giải mã nhận thức ngữ cảnh giới thiệu một siêu tham số α, phục vụ để kiểm soát mức độ điều chỉnh của CAD (α nhỏ làm cho phân phối gần hơn với phân phối token tiếp theo ban đầu). Chúng tôi tiến hành các thí nghiệm với các giá trị α khác nhau và trình bày kết quả trong Hình 3. Trên tất cả ba tập dữ liệu, chúng tôi thấy λ=0.5 cung cấp cải thiện mạnh mẽ nhất quán so với giải mã thông thường. Tăng thêm giá trị α mang lại cải thiện bổ sung trong các nhiệm vụ liên quan đến xung đột kiến thức.

5 Công việc liên quan
Tính thực tế tóm tắt Các mô hình tóm tắt đã cho thấy xu hướng tạo ra văn bản ảo giác (Maynez et al., 2020; Pagnoni et al., 2021). Điều này dẫn đến nỗ lực ngày càng tăng để cải thiện tính nhất quán thực tế, bao gồm áp dụng sự chú ý đến các bộ ba sự kiện được trích xuất từ các tài liệu nguồn (Cao et al., 2018; Zhu et al., 2021), tối ưu hóa các mô hình tóm tắt hướng tới một chỉ số tính nhất quán thực tế (Nan et al., 2021; Cao và Wang, 2021), học một bộ sửa lỗi chỉnh sửa sau (Dong et al., 2020) và loại bỏ các mẫu đào tạo ồn ào (Kang và Hashimoto, 2020; Goyal và Durrett, 2021). Tuy nhiên, tất cả các phương pháp này đều yêu cầu tinh chỉnh bổ sung và không trực tiếp phù hợp cho các tình huống prompting zero-shot và few-shot.

Xung đột kiến thức Khi được trình bày với một tài liệu cập nhật với kiến thức xung đột, chúng tôi mong đợi các mô hình ngôn ngữ tạo ra phản hồi dựa trên các ngữ cảnh được cung cấp thay vì chỉ dựa vào kiến thức tham số lỗi thời. Thiết lập này đặc biệt có giá trị đối với các mô hình ngôn ngữ tăng cường truy xuất (Khandelwal et al., 2020; Shi et al., 2023; Min et al., 2022; Yasunaga et al., 2023), nơi các tài liệu được truy xuất từ các cơ sở dữ liệu bên ngoài được sử dụng như là đầu vào bổ sung để cung cấp cho các LM kiến thức bổ sung. Tuy nhiên, việc chỉ thêm tài liệu không luôn thay đổi dự đoán của mô hình, vì các LM hiện tại thường bỏ qua ngữ cảnh

--- TRANG 6 ---
Hình 3: Tác động của mức độ điều chỉnh α. Trục y là hiệu suất và trục x là α.

và phụ thuộc nhiều vào kiến thức tham số trước đây của chúng (Longpre et al., 2021; Chen et al., 2022). Các phương pháp hiện có để cải thiện tính trung thực của mô hình với ngữ cảnh, chẳng hạn như phương pháp dựa trên prompting (Zhou et al., 2023), bị hạn chế ở chỗ chúng chỉ có thể áp dụng cho các LM được tinh chỉnh theo hướng dẫn quy mô lớn như text-davinci-003 của OpenAI. Ngược lại, công việc của chúng tôi điều tra một chiến lược giải mã để giải quyết vấn đề này, có thể áp dụng cho bất kỳ LM nào.

Phương pháp giải mã tương phản Các phương pháp giải mã tương phản đã được khám phá rộng rãi cho tạo văn bản. Tăng cường tính mạch lạc (Malkin et al., 2021) giảm bớt ngữ cảnh ngắn khỏi ngữ cảnh đầy đủ, tập trung vào ngữ cảnh dài hơn cho tính mạch lạc và chất lượng tạo tổng thể tốt hơn. Giải mã dựa trên MMI (Li et al., 2015) sử dụng một công thức tương phản để cải thiện tính đa dạng đầu ra trong tạo đối thoại. Trong công việc này, chúng tôi áp dụng cùng một trực quan và tập trung vào việc phân tích các tình huống xung đột kiến thức nơi tính trung thực với ngữ cảnh đặc biệt quan trọng nhưng khó khăn cho các phương pháp giải mã thông thường. DExperts (Liu et al., 2021) giảm bớt phân phối đầu ra của một chuyên gia phản (ví dụ, tiếp xúc với ngôn ngữ độc hại) để giúp dẫn dắt các thế hệ tránh khỏi các thuộc tính không mong muốn. Giải mã tương phản (Li et al., 2022) giảm bớt một mô hình nghiệp dư (ví dụ, các mô hình với số lượng tham số rất nhỏ) để giúp chưng cất kiến thức chuyên gia được học trong các mô hình lớn hơn, cạnh tranh hơn. Nói chung, giải mã tương phản đã được chứng minh là một cách tổng quát để kiểm soát đầu ra của mô hình, điều mà chúng tôi củng cố bằng cách xem xét trường hợp mới của tính nhất quán thực tế với ngữ cảnh văn bản.

6 Kết luận
Các mô hình ngôn ngữ có sẵn có thể gặp phải sự chú ý không đầy đủ đến ngữ cảnh được cung cấp so với kiến thức trước đây đã học của nó, dẫn đến việc tạo ra không trung thực với ngữ cảnh đầu vào. Chúng tôi trình bày giải mã nhận thức ngữ cảnh, một phương pháp thời gian suy luận đơn giản giảm trọng số xác suất đầu ra liên quan đến kiến thức trước đây của mô hình để thúc đẩy sự chú ý của mô hình đến thông tin ngữ cảnh. Chúng tôi thí nghiệm trên hai họ nhiệm vụ yêu cầu sự chú ý mạnh mẽ đến ngữ cảnh, tóm tắt và các nhiệm vụ xung đột kiến thức. Chúng tôi cho thấy CAD cung cấp đầu ra đáng tin cậy và thực tế hơn trên các mô hình ngôn ngữ khác nhau với kích thước khác nhau.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo được dịch sang tiếng Việt]

--- TRANG 7 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 8 ---
[Tiếp tục và kết thúc danh sách tài liệu tham khảo]

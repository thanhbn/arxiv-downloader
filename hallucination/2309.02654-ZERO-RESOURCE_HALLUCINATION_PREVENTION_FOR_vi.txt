# 2309.02654.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/hallucination/2309.02654.pdf
# Kích thước tệp: 597591 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
PHÒNG CHỐNG ẢOGIÁC KHÔNG CẦN TÀI NGUYÊN CHO
CÁC MÔ HÌNH NGÔN NGỮ LỚN

Junyu Luo
Đại học Pennsylvania StateCao Xiao
GE HealthCare

Fenglong Ma
Đại học Pennsylvania State

TÓM TẮT
Việc sử dụng phổ biến các mô hình ngôn ngữ lớn (LLMs) trong nhiều lĩnh vực khác nhau đã thu hút sự chú ý đến vấn đề "ảo giác," đề cập đến các trường hợp LLMs tạo ra thông tin không chính xác về mặt thực tế hoặc không có căn cứ. Các kỹ thuật hiện tại để phát hiện ảo giác trong các trợ lý ngôn ngữ dựa vào các kỹ thuật chuỗi suy nghĩ (CoT) phức tạp, mờ nhạt, dựa trên ngôn ngữ tự do cụ thể hoặc các phương pháp dựa trên tham số gặp phải vấn đề về tính khả diễn. Ngoài ra, các phương pháp xác định ảo giác sau khi tạo ra không thể ngăn chặn sự xuất hiện của chúng và gặp phải hiệu suất không nhất quán do ảnh hưởng của định dạng hướng dẫn và phong cách mô hình. Trong bài báo này, chúng tôi giới thiệu một kỹ thuật tự đánh giá tiền phát hiện mới, được gọi là SELF-FAMILIARITY, tập trung vào việc đánh giá mức độ quen thuộc của mô hình với các khái niệm có trong hướng dẫn đầu vào và giữ lại việc tạo ra phản hồi trong trường hợp các khái niệm không quen thuộc. Cách tiếp cận này mô phỏng khả năng của con người trong việc kiềm chế không phản hồi các chủ đề không quen thuộc, từ đó giảm thiểu ảo giác. Chúng tôi xác thực SELF-FAMILIARITY trên bốn mô hình ngôn ngữ lớn khác nhau, chứng minh hiệu suất vượt trội một cách nhất quán so với các kỹ thuật hiện có. Những phát hiện của chúng tôi đề xuất một sự thay đổi đáng kể hướng tới các chiến lược phòng ngừa cho việc giảm thiểu ảo giác trong các trợ lý LLM, hứa hẹn cải thiện về độ tin cậy, khả năng ứng dụng và tính khả diễn¹.

1 GIỚI THIỆU
Việc áp dụng rộng rãi các Mô hình Ngôn ngữ Lớn (LLMs) đã tạo ra sự quan tâm đáng kể trong việc ứng dụng chúng trong các trường hợp sử dụng đa dạng, ví dụ như chăm sóc sức khỏe và y học. Tuy nhiên, một thách thức lớn cản trở tiềm năng đầy đủ của chúng là vấn đề ảo giác, nơi các mô hình tạo ra thông tin không chính xác hoặc bịa đặt, dẫn đến khoảng cách đáng kể trong độ tin cậy và sự đáng tin cậy của chúng. Hình 6 cho thấy một ví dụ để chứng minh vấn đề ảo giác khi người dùng hỏi ChatGPT về thuốc "Skytrofa" nhằm điều trị tình trạng thấp còi do tiết không đủ hormone tăng trưởng nội sinh.² Chúng ta có thể quan sát thấy ChatGPT tạo ra phản hồi không chính xác về các yếu tố thiết yếu của loại thuốc này.

Gần đây, một số phương pháp đã được đề xuất để phát hiện (và thậm chí sửa chữa) các phản hồi ảo giác được tạo ra bởi LLMs trong các cuộc trò chuyện mở, có thể được phân loại thô thành hai loại: Loại phương pháp đầu tiên phụ thuộc vào cơ sở tri thức của bên thứ ba, kết hợp với kỹ thuật Chuỗi Suy nghĩ (CoT), để xác định và sửa chữa các phản hồi ảo giác tiềm năng Gou et al. (2023); Zhang et al. (2023a); Min et al. (2023); Zhang et al. (2023b); Mündler et al. (2023). Hướng nghiên cứu khác tập trung vào việc thiết kế các phương pháp dựa trên tham số Manakul et al. (2023); Min et al. (2023), chủ yếu sử dụng các chỉ số cụ thể như độ khó hiểu để đánh giá tính chính xác của phản hồi.

¹mã và dữ liệu có thể tìm thấy tại https://github.com/soap117/Self-evaluation
²https://www.accessdata.fda.gov/drugsatfda_docs/label/2021/761177lbl.pdf

--- TRANG 2 ---
Người dùng: Tôi đang viết một bài báo về thuốc Skytrofa.
GPT-3.5: Nghe có vẻ thú vị! Skytrofa (molgradex) là một loại thuốc được phát triển để điều trị bệnh protein phế nang tự miễn (aPAP). Đó là một rối loạn phổi hiếm gặp trong đó một loại protein gọi là chất hoạt động bề mặt tích tụ trong các túi khí của phổi, dẫn đến khó thở.

Hình 1: Một ví dụ về ảo giác. Màu đỏ chỉ ra thông tin không chính xác.

Tất cả các phương pháp được đề cập ở trên chủ yếu tập trung vào việc phát hiện sau các phản hồi ảo giác. Những cách tiếp cận này chỉ có thể xác định xem một phản hồi có phải là ảo giác hay không, thiếu khả năng ngăn chặn việc sản xuất những phản hồi như vậy trong tương lai, do đó làm giảm độ tin cậy. Hơn nữa, hiệu suất của các phương pháp hiện tại bị ảnh hưởng sâu sắc bởi phong cách hướng dẫn và mô hình, dẫn đến thách thức trong việc duy trì tính mạnh mẽ trong các tình huống trò chuyện mở. Sự phức tạp này cản trở khả năng thiết lập một ngưỡng rõ ràng để phân biệt các phản hồi ảo giác. Ví dụ, các truy vấn nhị phân thường khuyến khích các chuỗi phản hồi ngắn, dẫn đến các chỉ số khác biệt đáng kể so với những chỉ số có được từ các chuỗi phản hồi mở rộng hơn. Do đó, một chiến lược chủ động, phòng ngừa cho các phản hồi ảo giác là cần thiết cho các ứng dụng thực tế và hiệu quả của các trợ lý ngôn ngữ trí tuệ nhân tạo (AI).

Thiết kế một phương pháp phòng ngừa hiệu quả như vậy đối mặt với một số thách thức. Thứ nhất, cách tiếp cận được đề xuất phải điều hướng một môi trường không có tài nguyên, loại trừ bất kỳ sự phụ thuộc nào vào tri thức bên ngoài thu được từ các công cụ tìm kiếm. Bỏ qua yêu cầu bắt buộc này làm tổn hại tính phổ quát và khả năng ứng dụng của phương pháp, khiến nó không phù hợp cho các tình huống có hạn chế về ngân sách hoặc bối cảnh thiếu truy cập bên ngoài. Do đó, một sự hiểu biết sâu sắc về tri thức nội tại của mô hình ngôn ngữ trở nên thiết yếu. Hơn nữa, nhiệm vụ đảm bảo tính mạnh mẽ có tầm quan trọng tối cao. Hệ thống được hình dung phải thể hiện khả năng phục hồi chống lại các loại hướng dẫn đa dạng, biến thể bối cảnh và phong cách mô hình. Với bản chất mở và động của ngôn ngữ con người, việc đạt được hiệu suất nhất quán và khả năng phục hồi không lay chuyển trên một loạt các tình huống rộng lớn đại diện cho một thách thức khó khăn không thể phủ nhận.

Để giải quyết những thách thức này một cách đồng thời, chúng tôi đề xuất một phương pháp tiền phát hiện mới không cần tài nguyên có tên SELF-FAMILIARITY, được minh họa trong Hình 2. Cách tiếp cận này mô phỏng khả năng tự đánh giá của con người bằng cách kiềm chế không thảo luận về các khái niệm không quen thuộc, từ đó giảm nguy cơ tạo ra thông tin ảo giác. Phương pháp này tạo ra sự khác biệt so với các kỹ thuật phát hiện sau thông thường.

Ban đầu, phương pháp của chúng tôi trích xuất và xử lý các thực thể khái niệm từ hướng dẫn trong giai đoạn Trích xuất Khái niệm. Sau đó, giai đoạn Đoán Khái niệm kiểm tra riêng lẻ các khái niệm được trích xuất thông qua kỹ thuật prompt để có được điểm quen thuộc của mỗi khái niệm. Cuối cùng, trong giai đoạn Tổng hợp, các điểm quen thuộc từ các khái niệm khác nhau được kết hợp để tạo ra điểm quen thuộc cấp hướng dẫn cuối cùng.

So với các phương pháp hiện tại, thuật toán của chúng tôi đưa ra những ưu điểm sau. Chủ yếu, SELF-FAMILIARITY tích hợp điểm mạnh của cả kỹ thuật CoT và phương pháp dựa trên tham số. Giống như các phương pháp CoT, thuật toán của chúng tôi có thể đưa ra phản hồi mang tính xây dựng bằng cách xác định các khái niệm không quen thuộc với mô hình. Tuy nhiên, thuật toán của chúng tôi chỉ sử dụng kỹ thuật prompt, loại bỏ nhu cầu về khả năng suy luận mạnh của mô hình và tránh được những nhược điểm của chúng trong khi kết hợp ưu điểm của chúng. Ngoài ra, thuật toán của chúng tôi không bị ảnh hưởng bởi phong cách và loại hướng dẫn và mang tính chủ động và phòng ngừa, do đó tăng độ tin cậy và tính mạnh mẽ. Cuối cùng, nó không yêu cầu bất kỳ tri thức bên ngoài nào.

Chúng tôi đã đánh giá phương pháp của mình trên bốn mô hình ngôn ngữ lớn bằng cách sử dụng một bộ dữ liệu phân loại hướng dẫn ảo giác tiền phát hiện mới được đề xuất, Concept-7. Kết quả thực nghiệm cho thấy SELF-FAMILIARITY³ được đề xuất nhất quán vượt trội so với các phương pháp khác trên tất cả các mô hình, chứng minh giá trị ứng dụng to lớn của nó.

³Dữ liệu và mã có thể tìm thấy trong Tài liệu Bổ sung.

--- TRANG 3 ---
Hoạt động quá tải của Đức
tấn công chớp nhoáng 0.3
Là một phần của hoạt động quá tải 0.4
tấn công chớp nhoáng trong
chiến tranh thế giới thứ hai là Hoạt động quá tải 0.5

... ... Mục đích của Hoạt động Quá tải trong Chiến tranh Thế giới Thứ hai là gì?

Trích xuất Khái niệm
Hoạt động Quá tải 
là một phần của 
tấn công chớp nhoáng 
của Đức ...

Giải thích 
"Hoạt động Quá tải" 
trong một đoạn văn ngắn.

Giải thích Khái niệm

Suy luận Khái niệm

Mô hình 
Ngôn ngữ

Che dấu

Cái gì liên quan đến 
"[MASK] là một phần 
của tấn công chớp nhoáng 
của Đức ...?"

Chọn Điểm Tối đa
bằng Tìm kiếm Chùm Có ràng buộc
bằng Tìm kiếm Tham lam

"[MASK] là một phần của 
tấn công chớp nhoáng 
của Đức ..."

... ... Tính toán Điểm 
Tần suất Khái niệm

Trung bình Có trọng số...

Phòng ngừa

Đoán Khái niệm

Trích xuất 
Khái niệm

Tổng hợp

Hoạt động 
Quá tải

Mô hình 
Ngôn ngữ

< h?

Có 
Xuất 
Phản hồi

Không

Điểm 
Quen thuộc

...

Hình 2: Ví dụ về quy trình của SELF-FAMILIARITY.

2 CÔNG TRÌNH LIÊN QUAN
Theo hiểu biết tốt nhất của chúng tôi, không có công trình nào đã được dành cho việc ngăn chặn các phản hồi ảo giác trong các cuộc trò chuyện mở bằng cách phân tích bản thân hướng dẫn dưới thiết lập không có tài nguyên. Do đó, các bối cảnh mà chúng tôi giải quyết khác biệt so với các nghiên cứu trước đây.

2.1 PHƯƠNG PHÁP PHÁT HIỆN VÀ SỬA CHỮA ẢO GIÁC
Các nghiên cứu trước đây về phát hiện và sửa chữa ảo giác chủ yếu tập trung vào việc tạo văn bản có điều kiện cho các nhiệm vụ cụ thể như tóm tắt tài liệu Maynez et al. (2020); Wang et al. (2020a); Cao et al. (2021), chú thích hình ảnh Rohrbach et al. (2018); Biten et al. (2022), tạo đối thoại Shuster et al. (2021), dịch máy Zhou et al. (2020); Wang & Sennrich (2020), và tạo văn bản từ bảng Wang et al. (2020b; 2021). Vì các công trình này rất cụ thể về nhiệm vụ, chúng không thể giải quyết các vấn đề ảo giác trong các cuộc trò chuyện mở.

Đối với thiết lập cuộc trò chuyện mở, các phương pháp thường được phân loại thành hai nhóm dựa trên các chiến lược được sử dụng. Nhóm đầu tiên sử dụng Chuỗi Suy nghĩ (CoT) hoặc lập trình prompt để đánh giá và sửa đổi phản hồi Lee et al. (2022); Gou et al. (2023); Zhang et al. (2023a); Min et al. (2023); Peng et al. (2023); Huang et al. (2023); Xie et al. (2023); Yue et al. (2023). Một ví dụ đáng chú ý là CRITIC Gou et al. (2023), trong đó một quy trình CoT được triển khai với các đầu vào bổ sung từ một công cụ tìm kiếm bên ngoài để nâng cao chất lượng phản hồi. Một số công trình không đòi hỏi tri thức bên ngoài Zhang et al. (2023b); Mündler et al. (2023), thường trực tiếp yêu cầu mô hình đánh giá tính trung thực của đầu ra. Tuy nhiên, những phương pháp như vậy có thể bị hạn chế vì chúng được thiết kế cho các phản hồi cụ thể và phụ thuộc rất nhiều vào khả năng suy luận bên trong của mô hình. Một thách thức khác nằm ở thực tế là đầu ra của thuật toán thường là văn bản tự do, có thể làm cho ngưỡng phân loại thực tế trở nên mơ hồ.

Loại phương pháp thứ hai Manakul et al. (2023); Min et al. (2023) nhấn mạnh việc sử dụng các tham số mô hình ngôn ngữ, chẳng hạn như chuỗi xác suất token, để xác định mức độ ảo giác. Những phương pháp này thường thể hiện khả năng tổng quát hóa vượt trội và có thể cung cấp điểm số đầu ra chính xác. Self-check GPT Manakul et al. (2023) tiên phong trong việc sử dụng các phương pháp dựa trên tham số để tạo văn bản mở. Trong Self-check GPT, độ khó hiểu, lấy mẫu và xác suất không điều kiện được sử dụng cùng nhau để ước tính mức độ ảo giác. Tuy nhiên, công trình này chỉ đánh giá các vấn đề liên quan đến tiểu sử, và so với các kỹ thuật CoT, tính khả diễn của mô hình bị giảm đáng kể.

--- TRANG 4 ---
2.2 BỘ DỮ LIỆU PHÁT HIỆN ẢO GIÁC
Các bộ dữ liệu hiện tại để phát hiện ảo giác trong các cuộc trò chuyện mở chủ yếu tập trung vào các tình huống phát hiện sau. Trong những bộ dữ liệu này Lin et al. (2021); Liu et al. (2022); Muhlgay et al. (2023); Li et al. (2023); Manakul et al. (2023); Min et al. (2023); Mündler et al. (2023); Zhang et al. (2023b), nhiệm vụ bao gồm việc chọn phản hồi đúng hoặc xác định xem phản hồi có không chính xác hay không. Tuy nhiên, những bộ dữ liệu này phải chịu một số ràng buộc nhất định. Chủ yếu, các bộ dữ liệu thường có nguồn gốc từ một nhiệm vụ duy nhất như viết tiểu sử, không tính đến sự khác biệt giữa các mô hình ngôn ngữ khác nhau. Mỗi mô hình có thể có tri thức nền tảng khác biệt, cho phép một mô hình xác định một phản hồi ảo giác mà mô hình khác có thể bỏ qua. Hơn nữa, ngay cả khi một mô hình có thể phân loại chính xác một phản hồi ảo giác cụ thể, nó không đảm bảo rằng mô hình sẽ kiềm chế không tạo ra một phản hồi ảo giác khác trong tương lai. Do đó, việc tạo ra một bộ dữ liệu mới được sử dụng để xác thực thiết lập tiền phát hiện là quan trọng.

3 PHƯƠNG PHÁP LUẬN
Mục đích của thuật toán của chúng tôi là đánh giá xem hướng dẫn mục tiêu PT có phải là một hướng dẫn ảo giác tiềm năng hay không bằng cách kiểm tra mức độ quen thuộc của mô hình ngôn ngữ với các khái niệm tồn tại trong PT dưới thiết lập không có tài nguyên. Phương pháp của chúng tôi, như được mô tả trong Hình 2, bao gồm ba bước chính: (1) Trích xuất Khái niệm, (2) Đoán Khái niệm, và (3) Tổng hợp. Chi tiết của từng bước sẽ được làm rõ trong các phần tiếp theo.

3.1 TRÍCH XUẤT KHÁI NIỆM
Để đánh giá mức độ quen thuộc, trước tiên cần trích xuất các thực thể khái niệm từ hướng dẫn văn bản tự do, nếu không, điểm số sẽ bị ảnh hưởng lớn bởi "nhiễu," tức là các yếu tố phong cách và định dạng của hướng dẫn không đóng góp vào việc hiểu của nó. Ví dụ, việc chuyển đổi câu hỏi "Âm thanh có thể di chuyển trong chân không không?" thành tuyên bố "Âm thanh có thể di chuyển trong chân không. Vui lòng đánh giá tuyên bố này." không làm thay đổi yêu cầu tri thức, nhưng nó có thể sửa đổi đáng kể phong cách của phản hồi tiếp theo. Ngoài ra, nếu các hướng dẫn chứa nhiều khái niệm, nó sẽ tăng đáng kể độ khó của kỹ thuật prompt tiếp theo. Bằng cách cô lập và đánh giá riêng lẻ các khái niệm này, chúng ta có thể giảm thiểu ảnh hưởng phong cách như vậy, từ đó tăng cường tính mạnh mẽ của các quy trình tiếp theo. Chúng tôi thực hiện việc trích xuất này thông qua việc sử dụng mô hình Nhận dạng Thực thể Có tên (NER) trên hướng dẫn đã cho:

[c1,···, cN] = NER(PT). (1)

Chúng tôi coi các thực thể được trích xuất [c1,···, cN] này là các khái niệm chính của hướng dẫn. N đại diện cho số lượng khái niệm được trích xuất. Tuy nhiên, các mô hình NER thường tạo ra nhiễu thừa và không thể hoàn toàn nắm bắt một số khái niệm. Do đó, chúng tôi giới thiệu các bước xử lý tiếp theo để tinh chỉnh những khái niệm được trích xuất này, như được nêu trong các phần sau.

Nhóm Khái niệm. Các khái niệm được trích xuất thường thể hiện một mức độ không đầy đủ. Ví dụ, thuật ngữ "cuộc khủng hoảng trần nợ Hoa Kỳ 2023" có thể vô tình bị chia thành ["2023", "Hoa Kỳ", "cuộc khủng hoảng trần nợ"]. Để giải quyết vấn đề này, chúng tôi đề xuất hợp nhất tuần tự các khái niệm liền kề. Chúng tôi sắp xếp các khái niệm dựa trên vị trí của chúng trong PT và cố gắng hợp nhất một khái niệm với khái niệm liền kề, nếu khái niệm mới kết hợp được tìm thấy trong PT gốc, chúng tôi tích hợp cặp ban đầu để tạo ra một khái niệm mở rộng, thống nhất.

Lọc Khái niệm. Sau khi hợp nhất các khái niệm, bước tiếp theo bao gồm việc loại trừ các khái niệm đơn giản không nên được kiểm tra để cải thiện hiệu quả. Chúng bao gồm các khái niệm phổ biến như "năm" và "tuổi", thường được các mô hình hiểu rõ. Để giải quyết điều này, chúng tôi xác định các từ được sử dụng thường xuyên nhất trong Wiktionary⁴, mà chúng tôi chỉ định là "các khái niệm phổ biến." Bất kỳ khái niệm nào được bao gồm trong những từ phổ biến này sẽ bị loại bỏ.

3.2 ĐOÁN KHÁI NIỆM
Nhiệm vụ tiếp theo của chúng tôi là kiểm tra mức độ quen thuộc của Mô hình Ngôn ngữ (LM) với các khái niệm được trích xuất trong thiết lập không có tài nguyên. Thực hiện nhiệm vụ này trong thiết lập không có tài nguyên làm tăng độ phức tạp của nó, vì nó loại trừ sự phụ thuộc vào tri thức khái niệm bên ngoài. Như vậy, việc so sánh sự hiểu biết của mô hình với một định nghĩa vàng đã thiết lập để đưa ra kết quả trở thành một cách tiếp cận không thể thực hiện được.

⁴https://en.wiktionary.org/wiki/Wiktionary:Main_Page

--- TRANG 5 ---
Trong khi đó, một truy vấn trực tiếp đến mô hình về mức độ quen thuộc của nó với các phương pháp cụ thể, chẳng hạn như CoT, đưa ra một giải pháp khả thi. Tuy nhiên, cách tiếp cận này đòi hỏi khả năng suy luận mạnh mẽ từ phía mô hình và thường dẫn đến các phản hồi mơ hồ. Do đó, cần có một phương pháp có thể áp dụng rộng rãi hơn và chính xác hơn.

Để đáp ứng nhu cầu này, chúng tôi giới thiệu một kỹ thuật tự đánh giá mới, được ký hiệu là Đoán Khái niệm. Cách tiếp cận của chúng tôi bắt đầu bằng việc nhắc mô hình tạo ra một lời giải thích cho một khái niệm đã cho. Sau đó, thông qua kỹ thuật prompt, chúng tôi yêu cầu mô hình tái tạo khái niệm gốc dựa trên lời giải thích này. Nếu mô hình tạo ra khái niệm ban đầu thành công, điểm xác suất của chuỗi phản hồi có thể được diễn giải như sức mạnh kết nối giữa khái niệm và lời giải thích, đóng vai trò như một điểm quen thuộc. Toàn bộ quá trình này có thể được ví như một trò chơi Charades hoặc Pictionary chuyên biệt. Nếu một mô hình ngôn ngữ có thể thành thạo trong việc suy ra khái niệm gốc từ lời giải thích được tạo ra, điều này không chỉ gợi ý về sự đầy đủ của lời giải thích mà còn phản ánh khả năng thành thạo của mô hình với khái niệm đó. Quan trọng là, phương pháp của chúng tôi không đòi hỏi việc có được định nghĩa vàng của khái niệm. Chúng tôi nêu ra các bước sau để chuyển đổi cách tiếp cận khái niệm này thành một chỉ số chuẩn hóa:

3.2.1 GIẢI THÍCH KHÁI NIỆM
Đầu tiên, chúng tôi sử dụng một prompt giải thích chuẩn PE kết hợp với khái niệm mục tiêu ci để truy vấn LM được kiểm tra. Truy vấn này nhắc LM tạo ra lời giải thích cho mỗi khái niệm thông qua tìm kiếm tham lam (GreedySearch), lựa chọn từ tiếp theo với xác suất cao nhất để tạo ra phản hồi. Quá trình này tiếp tục cho đến khi gặp token cuối câu hoặc đạt độ dài tối đa được định nghĩa, ký hiệu là lF:

Ri = GreedySearch(LM(PE ⊕ ci)), (2)

trong đó ⊕ ký hiệu việc chèn ci vào vị trí được định nghĩa trước của PE. Trong nhiều tình huống, khái niệm gốc có thể được tích hợp trực tiếp vào lời giải thích được tạo ra, như được minh họa trong Hình 2. Do đó, mô hình có thể đơn giản "sao chép" khái niệm gốc để "gian lận". Để ngăn chặn điều này, chúng tôi che dấu các từ của ci trong Ri:

R*i = Mask(Ri). (3)

3.2.2 SUY LUẬN KHÁI NIỆM
Cho lời giải thích được che dấu R*i và prompt suy luận khái niệm được biểu diễn bởi PI, chúng ta có thể yêu cầu mô hình tạo ra khái niệm gốc ci. Tuy nhiên, phản hồi từ mô hình được tạo ra như văn bản tự do mở, gây ra thách thức khi cố gắng chuyển đổi nó thành điểm số chuẩn. Xem xét một trường hợp mà mô hình có thể tạo ra chính xác khái niệm gốc, nhưng ở một định dạng khác như "đối thủ lớn nhất của Coca-Cola" thay vì "Pepsi". Sự khác biệt này làm phức tạp việc xác định xem khái niệm gốc có được tái tạo thành công hay không.

Để giải quyết điều này, chúng tôi áp dụng phương pháp tìm kiếm chùm có ràng buộc (ConsBeamSearch) Anderson et al. (2017), hướng dẫn mô hình tìm kiếm các phản hồi kết hợp khái niệm gốc thông qua tìm kiếm chùm và cung cấp điểm xác suất của các phản hồi đồng thời:

[< R1i, s1i >, ···, < RTBi, sTBi >] = ConsBeamSearch(LM(PI ⊕ R*i), ci), (4)

trong đó mỗi < Rji, sji > tương ứng với một phản hồi Rji bao gồm thực thể khái niệm ci⁵, với sji biểu diễn điểm xác suất phản hồi tương ứng. TB là kích thước tìm kiếm chùm của thuật toán ConsBeamSearch. Chúng tôi đặt tiêu chí dừng để đạt token cuối câu hoặc đạt độ dài tối đa lB. Tìm kiếm chùm sẽ trả về nhiều kết quả, tuy nhiên, sự hiểu biết của mô hình chỉ liên quan đến kết quả cao nhất. Do đó, chúng tôi chọn điểm phản hồi cao nhất, si, từ [s1i, ···, sTBi] như điểm quen thuộc của khái niệm ci:

si = Max(s1i, ···, sTBi). (5)

⁵Chúng tôi xem xét các dạng chữ thường, chữ hoa và chữ in hoa trong tìm kiếm.

--- TRANG 6 ---
Bảng 1: Thông tin thống kê của bộ dữ liệu Concept-7.

# khái niệm cơ bản: 192
# hướng dẫn cơ bản: 451
# khái niệm kiểm tra: 180
# khái niệm kiểm tra thực: 106
# khái niệm kiểm tra hư cấu: 74
# hướng dẫn kiểm tra: 515

3.3 TỔNG HỢP
Trong nhiều tình huống, số lượng khái niệm được trích xuất cuối cùng có thể lớn hơn một. Kết quả là, chúng ta cần xếp hạng tầm quan trọng của mỗi khái niệm và hợp nhất các điểm quen thuộc của các khái niệm dựa trên tầm quan trọng của chúng để tạo ra kết quả cuối cùng ở cấp độ hướng dẫn.

3.3.1 ĐIỂM TẦN SUẤT KHÁI NIỆM
Để đánh giá tầm quan trọng của một khái niệm, chúng tôi đề xuất một phương pháp tính điểm dựa trên thứ hạng tần suất của các từ chứa trong khái niệm đó. Kỳ vọng của chúng tôi là khái niệm có nhiều từ ít phổ biến hơn sẽ tương ứng với điểm fi thấp hơn. Để làm điều này, chúng tôi lấy thứ hạng tần suất pji của từ thứ j của khái niệm ci từ Wiktionary. Chúng tôi đặt chỉ mục bằng độ dài của từ điển nếu từ nằm ngoài từ điển hoặc được viết hoa. Vì phân phối từ có xu hướng tuân theo phân phối đuôi dài, chúng tôi sử dụng hàm mũ để chuyển đổi thứ hạng tần suất trở lại thành điểm tần suất và nhân chúng với nhau để có được điểm tần suất cấp khái niệm:

fi = ∏(j=1 to Mi) e^(-pji/H). (6)

Ở đây, Mi là số từ trong khái niệm ci. Thuật ngữ H được giới thiệu như một yếu tố chuẩn hóa để đảm bảo rằng điểm số kết quả nằm trong một phạm vi hợp lý.

3.3.2 TỔNG HỢP CÓ TRỌNG SỐ
Tiếp theo, chúng tôi tính trung bình các điểm quen thuộc dựa trên điểm tần suất của chúng thông qua trung bình có trọng số. Cách tiếp cận này mang lại tính mạnh mẽ trong các tình huống đa thực thể khi so sánh với việc đơn giản chọn một điểm số duy nhất làm giá trị cuối cùng. Để làm cho các phần quan trọng đóng góp nhiều hơn các phần đuôi ít quan trọng, chúng tôi thiết lập một sơ đồ trọng số giảm hình học với tỷ lệ 1/r:

sf = (∑(i=1 to N) (r^θ(fi))^(-1) si) / (∑(i=1 to N) (r^θ(fi))^(-1)). (7)

Ở đây, θ(fi) ký hiệu vị trí thứ hạng của fi trong [f1, ···, fN] khi được sắp xếp theo độ lớn của fi. Chúng tôi sử dụng sf thu được để biểu diễn mức độ ảo giác của hướng dẫn và kết thúc quá trình phản hồi nếu điểm số rơi xuống dưới ngưỡng được xác định trước h.

4 THỰC NGHIỆM
Trong phần này, chúng tôi giới thiệu các thiết lập thực nghiệm và kết quả. Do hạn chế về không gian, chúng tôi đã bao gồm các chi tiết triển khai và kết quả thực nghiệm chỉ có khái niệm trong tài liệu bổ sung.

4.1 BỘ DỮ LIỆU
Hầu hết các bộ dữ liệu hiện tại chủ yếu tập trung vào việc phân loại các phản hồi ảo giác. Để đánh giá hiệu quả phương pháp của chúng tôi, chúng tôi giới thiệu bộ dữ liệu Concept-7, tập trung vào việc phân loại các hướng dẫn ảo giác tiềm năng. Bộ dữ liệu này bao gồm 192 khái niệm cơ bản với 451 hướng dẫn cơ bản và 180 khái niệm kiểm tra với 515 hướng dẫn kiểm tra có nguồn gốc từ bảy lĩnh vực chuyên môn. Tổng quan toàn diện về bộ dữ liệu được hiển thị trong Bảng 1.

--- TRANG 7 ---
Bảng 2: Kết quả phân loại hướng dẫn ảo giác trên bốn mô hình.

Các Phương pháp | Vicuna-13b-v1.3 | Falcon-7b-instruct | mpt-7b-instruct | Alpaca-7b
[Bảng với các kết quả AUC, ACC, F1, PEA cho các phương pháp khác nhau]

4.1.1 TẠO BỘ DỮ LIỆU
Trong phần tiếp theo, chúng tôi đi sâu vào chi tiết của việc xây dựng bộ dữ liệu.

• Lựa chọn Khái niệm. Ban đầu, chúng tôi chọn 192 khái niệm cơ bản, được hướng dẫn bởi các trang phổ biến trên Wikipedia⁶ và sự đa dạng lĩnh vực. Những khái niệm này được coi là được biết đến rộng rãi cho tất cả các mô hình ngôn ngữ và phục vụ như một điểm chuẩn cho việc phân loại các khái niệm quen thuộc. Đối với các khái niệm kiểm tra, chúng tôi chọn 106 khái niệm từ bảy lĩnh vực chuyên môn: Y học, Tài chính, Âm nhạc, Nghệ thuật, Pháp lý, Vật lý và Lịch sử. Để duy trì tỷ lệ cân bằng giữa các khái niệm quen thuộc và không quen thuộc, chúng tôi bịa đặt 74 khái niệm hư cấu được xây dựng dựa trên các khái niệm thực. Vì những khái niệm hư cấu này không tồn tại, chúng vốn dĩ được coi là không quen thuộc với tất cả các mô hình ngôn ngữ. Tuy nhiên, vì các nguồn đào tạo khác nhau cho mỗi mô hình ngôn ngữ, cần phải chú thích điểm quen thuộc cho các khái niệm thực cho mỗi mô hình được kiểm tra.

• Chú thích Mức độ Quen thuộc. Để gán điểm quen thuộc, chúng tôi đề xuất một so sánh giữa lời giải thích vàng được tạo ra của các khái niệm và lời giải thích được tạo ra của mỗi mô hình ngôn ngữ. Đánh giá quen thuộc này được thực hiện tự động qua GPT-4. Chúng tôi hướng dẫn GPT-4 cung cấp điểm quen thuộc cho mô hình liên quan đến khái niệm trên thang điểm "1-9", như mô tả trong tài liệu bổ sung. Ngưỡng "5" được chọn; các khái niệm có điểm vượt quá "5" được coi là quen thuộc, trong khi những khái niệm điểm thấp hơn được coi là không quen thuộc. Các khái niệm điểm chính xác "5" được xem xét thủ công để gán nhãn cuối cùng. Ngoài ra, chúng tôi sử dụng Amazon Mechanical Turk⁷ để thu thập kết quả chú thích hoàn toàn của con người cho mô hình có hiệu suất cao nhất như một phương pháp đánh giá thứ hai, đảm bảo hiệu quả của kết quả được chú thích bởi GPT-4. Đối với kết quả được chú thích bởi con người, chúng tôi có ba người chú thích khác nhau cho mỗi khái niệm và nhãn cuối cùng được quyết định dựa trên điểm trung bình. Nếu điểm trung bình trùng là "5", một cuộc bỏ phiếu đa số được áp dụng để quyết định nhãn.

• Tạo Hướng dẫn. Để tái tạo các tình huống trò chuyện chung, chúng tôi sử dụng một prompt (như được hiển thị trong tài liệu bổ sung) để tạo ra ba câu hỏi liên quan cho mỗi khái niệm qua GPT-3.5. Điều này bao gồm hai câu hỏi mở và một câu hỏi có/không. Sau đó chúng tôi loại bỏ các câu hỏi không đề cập đến khái niệm gốc để duy trì sự liên quan mạnh mẽ. Các hướng dẫn bao gồm các khái niệm không quen thuộc được coi là hướng dẫn ảo giác.

4.2 PHƯƠNG PHÁP CHUẨN
Xem xét rằng các phương pháp trước đây chủ yếu tập trung vào phát hiện các phản hồi ảo giác, thiết lập của chúng không thể được áp dụng trực tiếp trong bối cảnh này. Tuy nhiên, chúng tôi nỗ lực điều chỉnh các thiết lập này để thiết lập các phương pháp chuẩn sau. Do hạn chế về không gian, chúng tôi chỉ thảo luận các khái niệm cốt lõi ở đây, để lại các chi tiết toàn diện của mỗi phương pháp chuẩn cho tài liệu bổ sung. Quan trọng cần lưu ý rằng vì tập trung của chúng tôi nằm ở thiết lập phòng ngừa không có tài nguyên, chúng tôi loại trừ các phương pháp đòi hỏi tri thức bên ngoài.

• Greedy-Perplexity: Đối với mỗi đầu vào, chúng tôi sử dụng tìm kiếm tham lam để tạo ra phản hồi và sau đó tính điểm khó hiểu của phản hồi. Điểm khó hiểu âm được coi là điểm quen thuộc, tương tự như cách tiếp cận trong Manakul et al. (2023).

• Greedy-AvgLogp: Đối với mỗi đầu vào, chúng tôi sử dụng tìm kiếm tham lam để tạo ra phản hồi và sau đó tính điểm xác suất log token trung bình của phản hồi, tương tự như cách tiếp cận trong Manakul et al. (2023).

⁶https://en.wikipedia.org/wiki/Wikipedia:Popular_pages
⁷https://www.mturk.com/

--- TRANG 8 ---
• Greedy-MinLogp: Tương tự như Greedy-AvgLogp, nhưng lấy điểm xác suất tối thiểu, giống như Manakul et al. (2023).

• Greedy-Significance: Đầu tiên chúng tôi yêu cầu mô hình tạo ra phản hồi giải thích bằng tìm kiếm tham lam, sau đó các khái niệm cốt lõi của prompt được che dấu. Sau đó chúng tôi tái tạo lời giải thích trước đó thông qua giải mã ép buộc và so sánh phân kỳ KL của các chuỗi xác suất đầu ra giữa hướng dẫn gốc và được che dấu. Phân kỳ này được xem là điểm quen thuộc.

• Sample-BERTScore: Chúng tôi lấy mẫu TS phản hồi từ prompt và đánh giá độ tương tự BERTScore Zhang et al. (2019) giữa mỗi cặp câu. Sau đó chúng tôi chọn câu có điểm tương tự trung bình cao nhất với các câu còn lại làm câu trung tâm. Độ tương tự trung bình cao nhất được xem là điểm quen thuộc, theo phương pháp trong Manakul et al. (2023).

• Sample-SentenceScore: Giống như Sample-BERTScore, chúng tôi lấy mẫu TS phản hồi từ prompt và so sánh độ tương tự cosine của embedding câu của chúng, được tính bởi bộ mã hóa Sentence-BERT Reimers & Gurevych (2019).

• Forward-Inference: Chúng tôi trực tiếp hỏi xem mô hình ngôn ngữ có nhận ra các khái niệm liên quan đến lĩnh vực trong hướng dẫn hay không, tương tự như các phương pháp CoT Zhang et al. (2023b); Mündler et al. (2023). Khả năng của chuỗi phản hồi "Có" được coi là điểm quen thuộc. Nếu mô hình phản hồi "Không" hoặc bất cứ thứ gì khác ngoài "Có", điểm quen thuộc được xác định là một trừ đi xác suất của chuỗi phản hồi.

4.3 CÁC MÔ HÌNH NGÔN NGỮ LỚN ĐƯỢC KIỂM TRA
Để cho phép so sánh sâu sắc giữa các phong cách khác nhau của các mô hình ngôn ngữ lớn được căn chỉnh hướng dẫn, chúng tôi đã chọn bốn mô hình riêng biệt để đánh giá: Vicuna-13b-v1.3 Zheng et al. (2023), Falcon-7b-instruct Almazrouei et al. (2023), mpt-7b-instruct⁸, và Alpaca-7b Taori et al. (2023). Với yêu cầu của phương pháp chúng tôi về kiểm soát tạo tìm kiếm chùm có ràng buộc, các mô hình chỉ cung cấp truy cập API độc quyền không được xem xét trong nghiên cứu này.

4.4 CHỈ SỐ ĐÁNH GIÁ
Chúng tôi áp dụng diện tích dưới đường cong (AUC), độ chính xác (ACC), điểm F (F1), và Hệ số Tương quan Pearson (PEA) giữa các điểm quen thuộc được dự đoán và được chú thích.

4.5 KẾT QUẢ
Chúng tôi bắt đầu thảo luận của mình bằng cách phân tích kết quả phân loại hướng dẫn ảo giác được trình bày trong Bảng 2. Bảng tiết lộ hai hiểu biết chính. Thứ nhất, ngoài phương pháp của chúng tôi, tất cả các cách tiếp cận chuẩn khác đều thể hiện sự không nhất quán hiệu suất đáng chú ý trên các mô hình khác nhau được kiểm tra. Hơn nữa, các phương pháp được ưa chuộng trong số các Mô hình Ngôn ngữ (LMs) khác nhau khác biệt đáng kể so với nhau. Như được nhấn mạnh trong phần giới thiệu, nhiều phương pháp hiện tại dễ bị ảnh hưởng bởi phong cách mô hình. Kết quả là, hiệu suất của một số phương pháp có thể thay đổi dựa trên các mô hình được sử dụng. Sự thay đổi này làm cho những phương pháp này ít linh hoạt hơn trong các thiết lập khác nhau. Một ví dụ đáng chú ý là phương pháp Forward-Inference. Trong khi nó thể hiện hiệu suất đáng khen ngợi trên Vicuna-13b-v1.3, hiệu quả của nó giảm với các mô hình khác. Quan sát này hỗ trợ giả thuyết rằng các kỹ thuật như CoT hoặc lập trình prompt, mặc dù thường có khả năng mang lại kết quả chất lượng cao, lại phụ thuộc rất nhiều vào khả năng CoT nội tại của mô hình. Vì nhiều LMs không được tinh chỉnh cụ thể cho mục đích này, nó hạn chế tính hữu ích rộng rãi của chúng. Mặt khác, Greedy-Perplexity hoạt động tốt trên nhiều mô hình khác nhau nhưng không thể phát hiện bất kỳ hướng dẫn ảo giác nào trên mpt-7b-instruct, dẫn đến điểm F1 là 0. Điều này nhấn mạnh ý tưởng rằng ngay cả các phương pháp dựa trên tham số cũng không miễn nhiễm với các vấn đề tính mạnh mẽ. Tương tự, các phương pháp khác cũng thể hiện thách thức tương tự. Trái ngược với các cách tiếp cận hiện tại, phương pháp của chúng tôi không chỉ mang lại hiệu suất vượt trội mà còn đảm bảo kết quả nhất quán trên nhiều LMs khác nhau. Ngoài ra, điểm tương quan PEA chứng minh rằng các đánh giá được tạo ra bởi thuật toán của chúng tôi phù hợp chặt chẽ với các điểm quen thuộc dựa trên lời giải thích vàng của các khái niệm. Những kết quả này nhấn mạnh tính mạnh mẽ và độ tin cậy của cách tiếp cận được đề xuất của chúng tôi.

⁸https://github.com/mosaicml/llm-foundry/

--- TRANG 9 ---
Bảng 3: Kết quả đánh giá được chú thích bởi con người.

Các Phương pháp | Vicuna-13b-v1.3
AUC | ACC | F1 | PEA
[Bảng với kết quả cho các phương pháp khác nhau]

4.6 KẾT QUẢ ĐÁNH GIÁ CỦA CON NGƯỜI
Ngoài các đánh giá dựa trên GPT-4, chúng tôi tiếp tục sử dụng crowd-sourcing để chú thích điểm quen thuộc khái niệm cho Vicuna-13b-v1.3 và sau đó đánh giá những kết quả được chú thích bởi con người này. Kết quả được nêu trong Bảng 6. Kết quả và thứ hạng của các phương pháp khác nhau tương tự như kết quả dựa trên GPT-4, chứng minh hiệu quả của phương pháp tự đánh giá của chúng tôi sử dụng GPT-4. Cuối cùng, dưới đánh giá dựa trên con người, cách tiếp cận của chúng tôi vẫn nhất quán thể hiện hiệu suất vượt trội trên tất cả các chỉ số được đánh giá.

4.7 NGHIÊN CỨU LOẠI BỎ
Bảng 4: Nghiên cứu loại bỏ xử lý thực thể

Các Phương pháp | Vicuna-13b-v1.3
AUC | ACC | F1
[Bảng với kết quả cho các cấu hình khác nhau]

Trong phần này, chúng tôi trình bày một nghiên cứu loại bỏ trong Bảng 4 để kiểm tra đóng góp của các phương pháp xử lý khái niệm được đề xuất và phương pháp tổng hợp điểm đối với hiệu suất tổng thể của mô hình chúng tôi. Đầu tiên chúng tôi kiểm tra các chiến lược xử lý khái niệm khác nhau. Các ký hiệu sau đại diện cho các cấu hình khác nhau của thuật toán chúng tôi: (1) W/O Grouping ký hiệu xử lý không nhóm các khái niệm được trích xuất. (2) W/O Filtering ký hiệu xử lý không lọc ra các khái niệm phổ biến. (3) W/O Ranking có nghĩa là các khái niệm không được xếp hạng dựa trên điểm tần suất của chúng. Thay vào đó, vị trí của các khái niệm trong hướng dẫn xác định thứ tự của chúng. Kết quả chỉ ra rằng loại trừ bất kỳ kỹ thuật nào trong số này đều dẫn đến sự sụt giảm hiệu suất cuối cùng. Điều này nhấn mạnh hiệu quả của mỗi chiến lược xử lý được đề xuất.

Tiếp theo, chúng tôi đánh giá hiệu quả của các kỹ thuật tổng hợp điểm quen thuộc cấp hướng dẫn khác so với phương pháp trung bình có trọng số của chúng tôi: (1) Minimal Only chọn điểm quen thuộc khái niệm nhỏ nhất làm kết quả cuối cùng. (2) Most Infrequent Only chọn điểm quen thuộc của khái niệm có điểm tần suất fi ít nhất làm kết quả cuối cùng. Rõ ràng từ bảng rằng phương pháp được đề xuất của chúng tôi thể hiện hiệu suất tổng thể tốt nhất ngoại trừ chỉ số F1. Điều này là do khả năng tính đến cả thứ hạng tầm quan trọng của các khái niệm đa dạng và hiệu suất tổng hợp. Ngược lại, hai phương pháp kia chỉ xem xét các phân đoạn của điểm quen thuộc khái niệm.

4.8 NGHIÊN CỨU TRƯỜNG HỢP
Trong phần này, chúng tôi thực hiện một nghiên cứu trường hợp thế giới thực trong lĩnh vực y tế để chứng minh khả năng ứng dụng của thuật toán chúng tôi trong việc ngăn chặn ảo giác. Chi tiết có thể tìm thấy trong Hình 3.

--- TRANG 10 ---
Người dùng: Công dụng của Beyfortus được phê duyệt gần đây là gì?

Mô hình: Beyfortus là một loại thuốc được Cơ quan Quản lý Thực phẩm và Dược phẩm Hoa Kỳ (FDA) phê duyệt gần đây để điều trị bệnh tiểu đường loại 2.

Bảo vệ: Giải thích "Beyfortus" trong một đoạn văn ngắn.

Người dùng: Công dụng của Beyfortus được phê duyệt gần đây là gì?

Mô hình: Beyfortus là một thuật ngữ giả thuyết kết hợp từ "beyond" và "fortune." ...

Bảo vệ: "... là một thuật ngữ giả thuyết kết hợp từ "beyond" và "fortune." ..." liên quan đến cái gì?

Mô hình: Thuật ngữ "beyondwealth" liên quan đến ý tưởng đạt được mức độ cao hơn

Beyfortus
Điểm quen thuộc: 0.681

Bảo vệ: Điểm quen thuộc của mô hình về "Beyfortus" thấp hơn giá trị chuẩn, tìm kiếm thông tin bổ sung cho "Beyfortus".

Công cụ Tìm kiếm: "Hôm nay, Cơ quan Quản lý Thực phẩm và Dược phẩm Hoa Kỳ đã phê duyệt Beyfortus (nirsevimab-alip) để phòng ngừa Virus Hợp bào Hô hấp (RSV) ..."

Mô hình: Beyfortus (nirsevimab-alip) là một loại thuốc được phê duyệt gần đây được sử dụng để phòng ngừa bệnh đường hô hấp dưới do Virus Hợp bào Hô hấp (RSV) ở trẻ sơ sinh và trẻ em được sinh ra trong hoặc bước vào mùa RSV đầu tiên của chúng, ...

Self-Familiarity
Tăng cường với Công cụ Tìm kiếm
Cung cấp Bối cảnh

Giải thích Khái niệm
Suy luận Khái niệm
Can thiệp Bảo vệ

----------------------------------------------- Không có Bảo vệ ----------------------------------------------
------------------------------------------------- Có Bảo vệ -----------------------------------------------

Tìm kiếm Trực tuyến
Che dấu

Hình 3: Màu đỏ ký hiệu thông tin sai lệch, trong khi màu xanh lá cây biểu thị thông tin đúng. Màu xanh dương là khái niệm và màu vàng là lời giải thích được tạo ra. Mô hình được kiểm tra là Vicuna-13b-v1.3.

"Beyfortus"⁹ là thuốc mới được phê duyệt. Đầu tiên chúng tôi kiểm tra phản hồi khi không có thuật toán của chúng tôi trong "Không có Bảo vệ", trong đó mô hình không do dự phát tán thông tin sai lệch. Loại thông tin sai lệch này khó phát hiện trừ khi một người chủ động tìm kiếm thông tin nền tảng. Tiếp theo, trong "Có Bảo vệ", thuật toán của chúng tôi đóng vai trò như một người bảo vệ, hỗ trợ chúng tôi

⁹https://www.fda.gov/news-events/press-announcements/fda-approves-new-drug-prevent-rsv-babies-and-toddlers

--- TRANG 11 ---
trong việc đánh giá sự hiểu biết của mô hình về "Beyfortus" bằng cách sử dụng SELF-FAMILIARITY. Rõ ràng là mô hình gặp khó khăn đáng kể trong việc tạo ra phản hồi liên quan đến "Beyfortus" dựa trên lời giải thích được che dấu. Điều này là do mô hình thiếu kết nối đã học nội tại giữa khái niệm và lời giải thích bịa đặt. Hơn nữa, chúng ta có thể dễ dàng giải quyết những vấn đề này bằng cách giới thiệu tri thức nền tảng về các khái niệm không quen thuộc. Trong bước tiếp theo, công cụ tìm kiếm được kích hoạt để truy xuất thông tin liên quan đến "Beyfortus" như dữ liệu nền tảng, và mô hình sau đó có khả năng đưa ra phản hồi đúng. Những kết quả này gợi ý rằng cách tiếp cận của chúng tôi không chỉ mạnh mẽ trong việc phòng ngừa mà còn có thể cung cấp khả năng diễn giải tuyệt vời và đóng vai trò như một công cụ có giá trị trong việc sửa chữa các phản hồi ảo giác.

5 KẾT LUẬN
Chúng tôi đã giới thiệu một cơ chế tiền phát hiện tiên tiến cho hướng dẫn ảo giác tiềm năng, mà chúng tôi gọi là SELF-FAMILIARITY. Cách tiếp cận của chúng tôi tận dụng Đoán Khái niệm để đánh giá chất lượng giải thích khái niệm của mô hình, từ đó xác định mức độ hiểu biết của mô hình. SELF-FAMILIARITY nhất quán đạt được kết quả tốt nhất trong việc tiền phát hiện hướng dẫn ảo giác trên bốn mô hình ngôn ngữ riêng biệt chỉ sử dụng tự đánh giá dưới thiết lập không có tài nguyên. Ngoài ra, phương pháp của chúng tôi thể hiện khả năng diễn giải vượt trội bằng cách xác định khái niệm cụ thể dẫn đến ảo giác. Tính năng độc đáo này cho phép tích hợp phương pháp của chúng tôi với các kỹ thuật phát hiện sau và sửa chữa, tăng cường tính linh hoạt của nó. Trong công việc tương lai, chúng tôi dự định điều tra cách đánh giá sự hiểu biết về các khái niệm con chi tiết hơn để tinh chỉnh thêm độ chính xác của thuật toán hiện tại.

TÀI LIỆU THAM KHẢO
[Danh sách tài liệu tham khảo được giữ nguyên như trong bản gốc]

--- TRANG 12 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 13 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 14 ---
A PROMPTS
[Nội dung prompt và hướng dẫn được dịch sang tiếng Việt]

--- TRANG 15 ---
[Tiếp tục nội dung prompt và chi tiết triển khai]

--- TRANG 16 ---
[Tiếp tục các phương pháp chuẩn]

--- TRANG 17 ---
[Tiếp tục các phương pháp chuẩn và kết quả bổ sung]

# 2311.08968.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/concept/2311.08968.pdf
# Kích thước tệp: 653899 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Xác định các Khái niệm Quan hệ Tuyến tính trong các Mô hình Ngôn ngữ Lớn
David Chanin, Anthony Hunter và Oana-Maria Camburu
Khoa Khoa học Máy tính
Đại học University College London
London, Vương quốc Anh
Tóm tắt
Các mô hình ngôn ngữ Transformer (LM) đã được chứng minh là biểu diễn các khái niệm dưới dạng các hướng trong không gian tiềm ẩn của các kích hoạt ẩn. Tuy nhiên, đối với bất kỳ khái niệm nào có thể hiểu được bởi con người, làm thế nào chúng ta có thể tìm thấy hướng của nó trong không gian tiềm ẩn? Chúng tôi trình bày một kỹ thuật được gọi là các khái niệm quan hệ tuyến tính (LRC) để tìm các hướng khái niệm tương ứng với các khái niệm có thể hiểu được bởi con người bằng cách đầu tiên mô hình hóa mối quan hệ giữa chủ thể và đối tượng như một nhúng quan hệ tuyến tính (LRE) (Hernandez et al., 2023b). Chúng tôi thấy rằng việc nghịch đảo LRE và sử dụng các lớp đối tượng sớm hơn dẫn đến một kỹ thuật mạnh mẽ để tìm các hướng khái niệm vượt trội hơn các bộ phân loại thăm dò hộp đen tiêu chuẩn. Chúng tôi đánh giá LRC về hiệu suất của chúng như các bộ phân loại khái niệm cũng như khả năng thay đổi đầu ra mô hình một cách nhân quả.

1 Giới thiệu
Các mô hình ngôn ngữ lớn (LLM) biểu diễn các khái niệm như thế nào, và làm thế nào chúng ta có thể xác định những khái niệm đó trong các kích hoạt ẩn? Nếu chúng ta có thể xác định các biểu diễn khái niệm có thể hiểu được bởi con người trong các kích hoạt mô hình, chúng ta có thể phân tích cách các khái niệm được tạo ra và thay đổi trong quá trình suy luận. Việc xác định các biểu diễn khái niệm bên trong các mô hình mở ra khả năng trực quan hóa quá trình tính toán của mô hình khi các câu được xử lý, và có thể giúp hiểu các phản hồi không chính xác hoặc không mong muốn từ mô hình. Hơn nữa, công việc tương lai nghiên cứu cách các hướng khái niệm phát sinh trong trọng số mô hình và cách các mô hình thể hiện mối quan hệ giữa các khái niệm có thể được hưởng lợi từ một phương pháp mạnh mẽ để tìm những hướng khái niệm đó như một bước đầu tiên.

Một cách tiếp cận trực quan khi cố gắng xác định vị trí một khái niệm có thể hiểu được bởi con người, như khái niệm về một thành phố ở Pháp, là thu thập các ví dụ về câu với các thành phố ở Pháp và các thành phố không ở Pháp, và huấn luyện một bộ phân loại thăm dò (Ettinger et al., 2016; Finlayson et al., 2021) trên các lớp ẩn của mô hình, thường là một bộ phân loại tuyến tính đơn giản.

San
Jose
is
in
CostaCosta
Rica
San Jose Costa Rica
York …LRC
"Located in: England"
Shanghai …LRC
"Located in: China"1. Huấn luyện một LRE, , để dự đoán  từ 
2. Nghịch đảo  để tạo ra 
3. Tìm mỗi vector LRC  bằng cách áp dụng  cho mỗi  trong quan hệHình 1: Đầu tiên chúng tôi mô hình hóa mối quan hệ giữa chủ thể s và đối tượng o như một phép biến đổi tuyến tính được gọi là nhúng quan hệ tuyến tính (LRE), R(s). Sau đó chúng tôi nghịch đảo R(s) sử dụng một nghịch đảo giả hạng thấp, kết quả là R−1(o). Cuối cùng, chúng tôi tạo ra một LRC v cho mỗi đối tượng o trong quan hệ bằng cách áp dụng R−1(o) cho kích hoạt đối tượng trung bình E[o]. Ở trên, chúng tôi huấn luyện một LRE từ câu "San Jose is in Costa Rica", sau đó nghịch đảo LRE đó và tạo ra các khái niệm quan hệ tuyến tính (LRC) biểu diễn "located in England" và "located in China" từ các biểu diễn của các đối tượng "York" và "Shanghai", tương ứng.

fier. Tuy nhiên, bộ phân loại đã học có thể đang chọn các đặc trưng tương quan với khái niệm được thăm dò trong khi bỏ qua hướng đặc trưng ảnh hưởng nhân quả đến đầu ra mô hình (Hernandez et al., 2023b).

Hơn nữa, lớp ẩn trong các mô hình transformer hiện đại có số chiều cao: ngay cả các mô hình cũ hơn như GPT2-xl có 1600 chiều trong

--- TRANG 2 ---
lớp ẩn (Radford et al., 2019), và các mô hình ngôn ngữ hiện đại như Llama2 có hơn 4000 chiều cho mô hình nhỏ nhất (7B) (Touvron et al., 2023). Việc huấn luyện một bộ phân loại thăm dó một cách ngây thơ có thể yêu cầu số lượng mẫu huấn luyện cao.

Kỹ thuật của chúng tôi dựa trên công việc của Hernandez et al. (2023b), mô hình hóa mối quan hệ giữa một chủ thể s và đối tượng o như một phép biến đổi tuyến tính affine, được gọi là nhúng quan hệ tuyến tính (LRE). Trong khi công việc LRE chủ yếu là một cuộc điều tra về cách các mô hình biểu diễn kiến thức quan hệ, chúng tôi thấy rằng việc nghịch đảo LRE có thể tạo ra các hướng khái niệm đạt được hiệu suất mạnh mẽ đáng ngạc nhiên như một bộ phân loại đồng thời cũng ảnh hưởng nhân quả đến đầu ra mô hình, vượt trội hơn các bộ phân loại thăm dò tiêu chuẩn như máy vector hỗ trợ tuyến tính (SVM).

Chúng tôi gọi hướng khái niệm mà phương pháp của chúng tôi tạo ra là khái niệm quan hệ tuyến tính (LRC). Một LRC biểu diễn một khái niệm như một hướng trong không gian tiềm ẩn, đồng thời cũng hoạt động như một bộ phân loại tuyến tính.

Hình 1 cho thấy phương pháp của chúng tôi để tạo ra một LRC. Đầu tiên chúng tôi tạo ra một LRE cho một quan hệ, ánh xạ các kích hoạt chủ thể tới các kích hoạt đối tượng tương ứng của chúng như một phép biến đổi tuyến tính. Sau đó, chúng tôi thực hiện một nghịch đảo giả hạng thấp của LRE, ánh xạ từ các kích hoạt đối tượng trở lại các kích hoạt chủ thể. Việc áp dụng LRE nghịch đảo này cho một đối tượng trong quan hệ dẫn đến một LRC. LRC vượt trội hơn các bộ phân loại thăm dò truyền thống về cả độ chính xác phân loại và tính nhân quả, trong đó tính nhân quả được định nghĩa là có thể kiểm soát đầu ra của mô hình.

Ví dụ, chúng ta có thể buộc mô hình đầu ra rằng "London is located in France" bằng cách trừ LRC "Located in England" từ kích hoạt của "London" và thêm LRC "Located in France".

Ngoài ra, vì chúng tôi chỉ sử dụng LRE như một bước trung gian để có được LRC, chúng tôi có thể nới lỏng yêu cầu rằng LRE phải dự đoán trung thực các logit đầu ra đối tượng trực tiếp. Điều này cho phép chúng tôi huấn luyện LRE sử dụng các kích hoạt đối tượng trước lớp mô hình cuối cùng, và sử dụng tất cả các kích hoạt token đối tượng thay vì chỉ sử dụng token đối tượng đầu tiên. Điều này cải thiện độ chính xác phân loại cho cả đối tượng đơn token và đa token so với công việc LRE gốc, trong đó chỉ có thể sử dụng lớp đối tượng cuối cùng và chỉ có thể mô hình hóa token đối tượng đầu tiên.

Trong bài báo này, chúng tôi nghiên cứu vấn đề xác định vị trí các khái niệm có thể hiểu được bởi con người trong lớp ẩn của các LLM tự hồi quy như GPT (Radford et al., 2019) và Llama (Touvron et al., 2023). Chúng tôi đánh giá kỹ thuật của mình sử dụng bộ dữ liệu quan hệ LRE (Hernandez et al., 2023b) về cả độ chính xác phân loại đa lớp và tính nhân quả (khả năng của các khái niệm để sửa đổi đầu ra mô hình). Kỹ thuật của chúng tôi đạt được điểm số cao cho cả độ chính xác phân loại và tính nhân quả trên bốn loại khái niệm trong bộ dữ liệu.

Các đóng góp của chúng tôi bao gồm: (1) Mở rộng LRE để xử lý các đối tượng đa token, (2) Sử dụng các lớp mô hình không cuối cùng cho kích hoạt đối tượng, và (3) Sử dụng LRE nghịch đảo như một bước trung gian để tìm các hướng khái niệm (LRC) trong các kích hoạt chủ thể. Mã của chúng tôi có sẵn trên GitHub¹.

2 Kiến thức nền tảng
Công việc trước đây về transformer đã chỉ ra rằng các đặc trưng được lưu trữ như các hướng trong không gian tiềm ẩn của các kích hoạt ẩn của mô hình, được gọi là giả thuyết biểu diễn tuyến tính (Elhage et al., 2022).

Công việc tiếp theo đã chỉ ra rằng các lớp perceptron đa lớp (MLP) cấp trung bình trong các LLM transformer hoạt động như các kho lưu trữ khóa-giá trị của thông tin (Geva et al., 2021). Các lớp MLP này tăng cường token cuối cùng của chủ thể của câu (ví dụ token "lin" trong "Berlin is located in the country of") với thông tin này trong các quan hệ thực tế (Geva et al., 2023; Meng et al., 2022).

2.1 Nhúng Quan hệ Tuyến tính
Nhúng quan hệ tuyến tính (LRE) được Paccanaro và Hinton (2001) trình bày lần đầu để mã hóa các khái niệm quan hệ như một phép biến đổi tuyến tính. Hernandez et al. (2023b) đã chỉ ra rằng các LM transformer có vẻ mã hóa kiến thức quan hệ sử dụng LRE. Họ mô hình hóa quá trình xử lý được thực hiện bởi một LLM transformer ánh xạ từ một chủ thể s tới một đối tượng o trong một ngữ cảnh văn bản c như một phép biến đổi tuyến tính o=F(s, c) = Ws+b, trong đó W∈RH×H, b∈RH. F được ước lượng bởi một xấp xỉ Taylor bậc nhất xung quanh s, trong khi W và b được tính như Jacobian trung bình và bias của n mẫu si, ci từ quan hệ r, tương ứng:

W=E(si,ci)"
∂F
∂s
(si,ci)#
b=E(si,ci)"
F(s, c)−∂F
∂ss
(si,ci)#

¹https://github.com/chanind/linear-relational-concepts

--- TRANG 3 ---
Một siêu tham số β được sử dụng để tăng độ dốc của LRE và có thể được cấu hình để cải thiện hiệu suất của LRE trong trường hợp Jacobian đánh giá thấp độ dốc của W, dẫn đến phương trình sau cho một LRE R:

R(s) =βWs +b (1)

LRE được đánh giá về tính trung thực và tính nhân quả. Tính trung thực kiểm tra xem đầu ra LRE có khớp với đầu ra mô hình cho token được dự đoán đầu tiên khi được trình bày với một chủ thể mới hay không. Ví dụ, nếu một LRE được huấn luyện trên quan hệ "city in country" dự đoán token "France" là đầu ra có khả năng nhất cho kích hoạt chủ thể của "Paris", LRE là trung thực. Tuy nhiên, điều này giới hạn LRE chỉ mô hình hóa một token duy nhất của đối tượng o tại lớp cuối cùng của mô hình. Kết quả là, LRE không thể phân biệt giữa các từ bắt đầu bằng cùng một token. Ví dụ, "Bill Gates" và "Bill of Rights" đều bắt đầu bằng token "Bill", và do đó không thể được phân biệt bởi một LRE được đánh giá về tính trung thực.

Để đánh giá tính nhân quả, LRE được nghịch đảo sử dụng một nghịch đảo giả hạng thấp của ma trận trọng số, được biểu thị W†. Hernandez et al. (2023b) thấy rằng việc sử dụng một nghịch đảo giả hạng thấp dẫn đến hiệu suất tốt hơn so với việc sử dụng nghịch đảo hạng đầy đủ. Việc nghịch đảo này giúp có thể tính toán Δs được thêm vào chủ thể s để thay đổi đầu ra mô hình từ đối tượng gốc o thành một đối tượng mới o′. Tính nhân quả được đánh giá dựa trên việc liệu xác suất của mô hình đầu ra o′ có lớn hơn xác suất đầu ra o sau khi chỉnh sửa hay không:

Δs=W†(o−o′) (2)

Như chúng tôi giải thích trong phần tiếp theo, chúng tôi xây dựng phương pháp của mình từ kỹ thuật nghịch đảo ma trận trọng số LRE này để nhắm mục tiêu các kích hoạt chủ thể thay vì các kích hoạt đối tượng.

3 Phương pháp
Phương pháp của chúng tôi tìm một LRC, được biểu diễn như một vector hướng khái niệm, v, cho một khái niệm có thể hiểu được bởi con người đã cho trong các kích hoạt ẩn của một mô hình LLM transformer tại lớp l. Vì chúng tôi quan tâm đến các khái niệm như các hướng, chúng tôi không thêm một hạng tử bias và tập trung vào việc học chỉ một vector đơn vị có độ dài đơn vị để biểu diễn LRC.

Chính thức, chúng tôi xem xét một mô hình tự hồi quy G:X → Y với từ vựng V ánh xạ một chuỗi token x= [x1, . . . , x T]∈ X, xi∈V tới một phân phối xác suất y∈ Y ⊂ R|V| dự đoán token tiếp theo của x. Bên trong, G có kích thước trạng thái ẩn H, và có L lớp. Các kích hoạt ẩn của lớp l của G tại token i được biểu diễn bởi h(l)i∈RH.

Chúng tôi theo ví dụ của Meng et al. (2022) và Hernandez et al. (2023b), và xem xét các câu phát biểu có dạng (s, r, o) bao gồm một chủ thể s, quan hệ r, và đối tượng o. Câu phát biểu "Paris is located in the country of France" sẽ có chủ thể "Paris", đối tượng "France", và quan hệ "located in country". Định nghĩa của chúng tôi về một khái niệm tương ứng với một cặp quan hệ và đối tượng (r, o), hoạt động trên các kích hoạt của chủ thể s. Vì vậy trong trường hợp của chúng tôi, chúng tôi sẽ học một LRC cho khái niệm "located in country: France", và sẽ mong đợi LRC có độ tương tự cao với các kích hoạt chủ thể của "Paris", nhưng không phải "Berlin" hoặc "Tokyo".

Chúng tôi thực hiện các thay đổi sau đối với phương pháp LRE gốc của Hernandez et al. (2023b): (1) Chúng tôi sử dụng trung bình của tất cả các kích hoạt token đối tượng thay vì chỉ kích hoạt token đối tượng đầu tiên để xử lý tốt hơn các đối tượng đa token. (2) Chúng tôi nới lỏng yêu cầu rằng chỉ có thể sử dụng lớp cuối cùng cho các kích hoạt đối tượng, vì chúng tôi thấy rằng hiệu suất phân loại cải thiện khi sử dụng các lớp đối tượng sớm hơn. Cả (1) và (2) đều có thể thực hiện được vì chúng tôi không đánh giá trực tiếp LRE sử dụng tính trung thực như trong công việc LRE gốc, thay vào đó thực hiện tất cả các đánh giá trên LRC hoạt động trên chủ thể. (3) Chúng tôi hạn chế các mẫu huấn luyện cho LRE chỉ chứa các ví dụ mà mô hình trả lời prompt chính xác. Nếu mô hình không trả lời một prompt chính xác, chúng tôi giả định rằng kiến thức khái niệm mà chúng tôi hy vọng nắm bắt trong LRC không có mặt, và mẫu đó có thể sẽ là nhiễu. Ví dụ, nếu mô hình phản hồi prompt "Paris is located in the country of" bằng "Japan", chúng tôi sẽ loại bỏ prompt này.

Đối với một quan hệ r, chúng tôi có một tập hợp các đối tượng có thể O, và mỗi đối tượng o có một tập hợp các chủ thể tương ứng So. Đầu tiên chúng tôi tập hợp các prompt gợi ý mỗi đối tượng o∈O cho quan hệ r. Ví dụ, đối với quan hệ "Located in country", các prompt tuân theo mẫu "{} is located in the country of" trong đó "{}" được thay thế bằng chủ thể và mô hình được mong đợi dự đoán đối tượng. Một số ví dụ về prompt và các đối tượng tương ứng của chúng được hiển thị trong Bảng 1.

Khi xây dựng một LRC cho quan hệ r và đối tượng o, chúng tôi giả định một tập hợp các prompt mỗi cái chứa

--- TRANG 4 ---
Prompt ( s, r) Đối tượng ( o)
Paris is located in the country of France
Suzhou is located in the country of China
Manaus is located in the country of Brazil

Bảng 1: Các prompt mẫu và đối tượng tương ứng cho quan hệ "Located in country".

chủ thể riêng của chúng s∈So, và chúng tôi mong đợi mô hình dự đoán đối tượng tương ứng o. Chúng tôi sử dụng các trạng thái ẩn từ chỉ số token cuối cùng i của chủ thể s. Ví dụ, nếu chủ thể "Berlin" được tokenize thành "Ber" và "lin", i tương ứng với chỉ số token của "lin" vì đây là token chủ thể cuối cùng.

Đầu tiên chúng tôi chọn n prompt cho quan hệ r, cân bằng các prompt để có phân phối prompt càng đều càng tốt trên O. Theo Hernandez et al. (2023b), chúng tôi huấn luyện một LRE R(s) bao gồm một ma trận trọng số W và bias b sử dụng các prompt này, tuy nhiên, trái ngược với Hernandez et al. (2023b), chúng tôi tính toán ma trận trọng số W sử dụng Jacobian của trung bình của tất cả các token đối tượng liên quan đến chủ thể, không chỉ token đối tượng đầu tiên. Thay đổi này có nghĩa là chúng tôi mô hình hóa F(s, c) như E[o] =F(s, c) =Ws+b.

Điều này giống hệt với công thức LRE gốc nếu đối tượng bao gồm một token duy nhất.

Chúng tôi bỏ qua hệ số tỷ lệ β từ định nghĩa LRE gốc. LRC được chuẩn hóa để có độ dài đơn vị, loại bỏ bất kỳ tỷ lệ nào được áp dụng cho LRE. Định nghĩa của chúng tôi về một LRE, được ký hiệu R(s), do đó được đơn giản hóa từ Phương trình 1 như sau:

R(s) =Ws+b (3)

Sau đó chúng tôi nghịch đảo Phương trình 3 để ánh xạ các kích hoạt đối tượng tới các kích hoạt chủ thể. Theo Hernandez et al. (2023b), chúng tôi sử dụng một nghịch đảo giả hạng thấp, được ký hiệu R† thay vì nghịch đảo ma trận đầy đủ R−1:

R†(o) =W†(o−b) (4)

Để tính toán LRC v cho o, chúng tôi lấy trung bình của tất cả các mẫu của R†(o) cho mỗi prompt (s, r, o) trong tập huấn luyện của chúng tôi:

˜vo=E[W†(o−b)] (5)

Cuối cùng, chúng tôi chuẩn hóa hướng LRC để có độ dài đơn vị: vo= ˜vo/∥˜vo∥2.

4 Kết quả
Chúng tôi đánh giá phương pháp của mình sử dụng bộ dữ liệu quan hệ từ Hernandez et al. (2023b). Bộ dữ liệu chứa 47 loại quan hệ, và hơn 10.000 thể hiện tổng cộng. Bộ dữ liệu chia các loại quan hệ thành bốn danh mục: kiến thức thực tế, kiến thức ngôn ngữ học, kiến thức thường thức, và thiên kiến ngầm. Một tập con dữ liệu từ một quan hệ mẫu được hiển thị trong Bảng 2. Thống kê về số lượng quan hệ và mẫu cho mỗi danh mục được hiển thị trong Bảng 3.

Chúng tôi đánh giá so với cả Llama2-7b (Touvron et al., 2023) và GPT-J (Wang và Komatsuzaki, 2021). Chúng tôi tập trung vào Llama2-7b để phân tích vì nó là một mô hình tiên tiến hơn GPT-J, nhưng chúng tôi bao gồm kết quả đầy đủ cho GPT-J trong Phụ lục A. GPT-J được bao gồm vì mô hình này được sử dụng trong bài báo LRE gốc.

Chúng tôi đánh giá hiệu suất của mình sử dụng độ chính xác phân loại và tính nhân quả. Đối với độ chính xác phân loại, chúng tôi coi mỗi quan hệ như một bài toán phân loại đa lớp, trong đó LRC có tích vô hướng lớn nhất với kích hoạt chủ thể kiểm tra a được coi là đối tượng được dự đoán ˆy:

ˆy= argmax o∈O vo·a (6)

Để đánh giá tính nhân quả, chúng tôi chọn ngẫu nhiên một đối tượng phản thực oc cho mỗi chủ thể trong một quan hệ và chỉnh sửa các kích hoạt token chủ thể để dự đoán đối tượng phản thực mới o′ thay vì đối tượng gốc o. Chúng tôi trừ LRC gốc từ kích hoạt token chủ thể cuối cùng tại tất cả các lớp, và thêm LRC mới. Ví dụ, chúng tôi có thể cố gắng chỉnh sửa prompt "Paris is located in the country of" để dự đoán "Germany" thay vì "France" bằng cách trừ khái niệm "located in country: France" và thêm khái niệm "located in country: Germany".

LRC đều được chuẩn hóa về độ dài đơn vị, vì vậy chúng tôi tỷ lệ bằng một siêu tham số β∈[0,1] nhân với chuẩn L2 của kích hoạt chủ thể trước khi thêm hoặc trừ chúng. Chỉnh sửa nhân quả tại lớp l do đó được tính toán như dưới đây:

Δs(l)=β∥h(l)i∥2(vo′−vo) (7)

Can thiệp tính nhân quả thành công nếu xác suất dự đoán đối tượng phản thực o′ sau khi chỉnh sửa cao hơn xác suất dự đoán đối tượng gốc o. Đối với các dự đoán đa token, chúng tôi sử dụng xác suất tối thiểu trên tất cả các token được dự đoán để tránh phạt các đối tượng yêu cầu nhiều token hơn để biểu diễn. Thực nghiệm,

--- TRANG 5 ---
relation: city in country
FS{} is part of
{} is in the country of
ZS{} is part of the country of
{} is located in the country of
subject object
Kuala Lumpur Malaysia
Johannesburg South Africa
Saint Petersburg Russia

Bảng 2: Dữ liệu quan hệ mẫu cho quan hệ "city in country" từ bộ dữ liệu, hiển thị các mẫu prompt zero-shot (ZS), các mẫu prompt few-shot (FS), và một số cặp chủ thể / đối tượng. Trong các mẫu, {} được thay thế bằng một chủ thể. Các mẫu FS và ZS khác nhau được cung cấp bởi bộ dữ liệu quan hệ.

Danh mục Quan hệ Mẫu
Thường thức 7 337
Thiên kiến 7 212
Thực tế 21 9462
Ngôn ngữ học 4 660

Bảng 3: Thống kê về số lượng quan hệ và mẫu của mỗi danh mục trong bộ dữ liệu sau khi lọc ra các quan hệ một-đối-một.

chúng tôi thấy β= 0.05 cho GPT-J và β= 0.075 cho Llama2-7b hoạt động tốt. Các giá trị này được tìm thấy bằng cách quét β giữa 0 và 1 với bước tăng 0.005.

Chúng tôi thực hiện chỉnh sửa đa lớp vì tính nhân quả đơn lớp phạt việc học các khái niệm ở các lớp sau của mô hình. Trong tính nhân quả đơn lớp, mô hình vẫn chú ý đến các kích hoạt chủ thể chưa được chỉnh sửa cho các lớp trước khi chỉnh sửa, làm suy yếu hiệu ứng của các chỉnh sửa ở các lớp sau. Thay vào đó, chúng tôi thực hiện cùng một chỉnh sửa tại tất cả các lớp của chủ thể, vì vậy mô hình không chú ý đến bất kỳ kích hoạt chủ thể chưa được chỉnh sửa nào.

Đối với mỗi quan hệ, chúng tôi chia bộ dữ liệu thành một phân chia train/test 50%/50% theo quan hệ và đối tượng, đảm bảo ít nhất một ví dụ huấn luyện cho mỗi đối tượng trong quan hệ. Chúng tôi thêm vào đầu bốn ví dụ khác từ cùng một quan hệ cho mỗi prompt huấn luyện như các ví dụ few-shot. Chúng tôi huấn luyện sử dụng các prompt few-shot từ bộ dữ liệu quan hệ, nhưng đánh giá sử dụng các prompt zero-shot, theo quy trình trong bài báo LRE gốc. Một ví dụ prompt few-shot được hiển thị trong Hình 2. Chúng tôi lặp lại năm lần với các seed ngẫu nhiên khác nhau cho các phân chia train/test, báo cáo trung bình và độ lệch chuẩn. Vùng bóng trong

Token Llama2-7b GPT-J
1 2393 2108
2 451 39
3 371 2
4 107 6
5+ 4 0

Bảng 4: Thống kê về số lượng token trung bình trong các đối tượng cho tập test cho Llama2-7b và GPT-J sau khi lọc ra các quan hệ một-đối-một và các mẫu mà mô hình trả lời không chính xác. Phần lớn các mẫu là đơn token, nhưng Llama2-7b cũng trả lời chính xác một số lượng lớn các mẫu đối tượng đa token. GPT-J hoạt động tệ hơn Llama2-7b, đặc biệt trên các đối tượng đa token.

The superlative form of bad is worst
The superlative form of bright is brightest
The superlative form of angry is

Hình 2: Prompt few-shot (FS) mẫu cho quan hệ "adjective superlative", chủ thể "angry", và đối tượng "angriest" từ bộ dữ liệu.

các biểu đồ tương ứng với độ lệch chuẩn này.

Một số quan hệ chứa ánh xạ một-đối-một giữa chủ thể và đối tượng, vì vậy không thể tạo ra một phân chia test với các cặp chủ thể/đối tượng chưa thấy. Ví dụ trong quan hệ "capital city of country", một quốc gia có một thành phố thủ đô, và một thành phố là thủ đô của chỉ một quốc gia. Vì các khái niệm của chúng tôi yêu cầu một cặp r và o duy nhất, chúng tôi không thể đánh giá những quan hệ này và loại trừ chúng khỏi đánh giá.

Chúng tôi cũng loại trừ bất kỳ mẫu nào mà mô hình trả lời không chính xác, và chúng tôi loại trừ bất kỳ quan hệ nào có ít hơn năm mẫu test vì ít mẫu test làm cho việc đánh giá hiệu suất một cách mạnh mẽ trở nên khó khăn. Bảng 4 hiển thị kích thước tập test trung bình theo số lượng token đối tượng cho Llama2-7b và GPT-J sau khi lọc này.

Khi huấn luyện LRC sử dụng phương pháp của chúng tôi, chúng tôi sử dụng 20 mẫu huấn luyện cho mỗi LRE cho benchmark chính, và 5 mẫu huấn luyện cho các biểu đồ quét. Chúng tôi sử dụng hạng 192 cho nghịch đảo giả. Các tính toán được thực hiện sử dụng một GPU Nvidia A100 với lượng tử hóa 16-bit. Chúng tôi sử dụng lớp chủ thể 17 và lớp đối tượng 21 cho Llama2-7b, và lớp chủ thể 14 và lớp đối tượng 20 cho GPT-J.

4.1 So sánh
Chúng tôi so sánh phương pháp của mình với việc huấn luyện một bộ phân loại máy vector hỗ trợ tuyến tính (SVM) 0-bias trên

--- TRANG 6 ---
Llama2-7b
Phương pháp Độ chính xác Tính nhân quả
LRC 0.81 ± 0.01 0.78 ± 0.02
LRC (ft, lfinal) 0.74 ± 0.02 0.78 ± 0.02
SVM 0.73 ± 0.02 0.69 ± 0.01
Input averaging 0.70 ± 0.01 0.55 ± 0.03

GPT-J
Phương pháp Độ chính xác Tính nhân quả
LRC 0.81 ± 0.02 0.84 ± 0.01
LRC (ft, lfinal) 0.78 ± 0.02 0.86 ± 0.01
SVM 0.75 ± 0.02 0.76 ± 0.01
Input averaging 0.73 ± 0.03 0.56 ± 0.02

Bảng 5: Kết quả độ chính xác phân loại và tính nhân quả trên bộ dữ liệu quan hệ cho Llama2-7b và GPT-J. LRC là phương pháp của chúng tôi. "ft" đề cập đến việc chỉ sử dụng token đầu tiên của đối tượng để tính toán một LRE. LRC (ft, lfinal) được bao gồm như phân tích để ước lượng tốt nhất kết quả của việc nghịch đảo kỹ thuật LRE gốc tại lớp cuối cùng. Kết quả bao gồm trung bình và độ lệch chuẩn sau năm seed ngẫu nhiên.

dữ liệu kích hoạt ẩn, cũng như ước lượng một hướng khái niệm bằng cách đơn giản lấy trung bình các kích hoạt ẩn cho một đối tượng đã cho. Đối với cả SVM và averaging, chúng tôi chuẩn hóa các vector đã học về độ dài đơn vị.

Chúng tôi cũng so sánh phương pháp của mình với một LRC được huấn luyện sử dụng lớp cuối cùng cho token đối tượng, như trong bài báo LRE gốc trong đó lớp cuối cùng luôn được sử dụng cho các đối tượng.

4.2 Độ chính xác phân loại và tính nhân quả
Đối với độ chính xác phân loại và tính nhân quả, chúng tôi tính toán một điểm số cho mỗi quan hệ, và sau đó lấy trung bình các điểm số trên các quan hệ. Một số quan hệ có nhiều mẫu test hơn các quan hệ khác, điều này sẽ làm thiên lệch kết quả về phía các quan hệ có nhiều mẫu test hơn và không phản ánh hiệu suất trên toàn bộ phạm vi các loại quan hệ trong bộ dữ liệu. Kết quả được hiển thị trong Bảng 5.

Phương pháp của chúng tôi hoạt động tốt nhất về cả độ chính xác phân loại và tính nhân quả. Độ chính xác phân loại cải thiện đáng kể bằng cách sử dụng lớp 21 thay vì lớp cuối cùng (lớp 31 cho Llama2-7b), cho thấy tầm quan trọng của việc cho phép LRE sử dụng một lớp không cuối cùng. Chúng tôi cũng bao gồm một so sánh đầy đủ về độ chính xác phân loại giữa phương pháp của chúng tôi và SVM cho Llama2 trong Hình 3.

Hình 3: Độ chính xác phân loại theo quan hệ cho LRC (của chúng tôi) so với SVM trên Llama2-7b. Phương pháp của chúng tôi vượt trội hơn SVM trên hầu hết, nhưng không phải tất cả, các quan hệ.

4.3 Đối tượng đa token so với đơn token
Một trong những hạn chế chính của công việc LRE gốc là không thể xử lý các đối tượng đa token, vì vậy chúng tôi mong đợi sự cải thiện của phương pháp chúng tôi so với LRE truyền thống sẽ nổi bật nhất đối với các đối tượng đa token.

Để điều tra tác động của việc lựa chọn lớp đối tượng đối với hiệu suất đơn token và đa token, chúng tôi đánh giá phương pháp của mình trên mỗi lớp từ lớp 18 đến lớp cuối cùng 31 cho Llama2-7b giữ lớp 17 làm lớp chủ thể. Chúng tôi chỉ sử dụng Llama2-7b vì GPT-J có rất ít prompt đa token mà nó có thể trả lời chính xác. Kết quả đa token theo lớp đối tượng được hiển thị trong Hình 4, và kết quả đơn token được hiển thị trong Hình 5.

Cả hiệu suất đơn token và đa token đều cải thiện bằng cách sử dụng các lớp đối tượng sớm hơn, nhưng

--- TRANG 7 ---
Hình 4: Độ chính xác phân loại và tính nhân quả theo lớp đối tượng cho các đối tượng đa token trên Llama2-7b.

Hình 5: Độ chính xác phân loại và tính nhân quả theo lớp đối tượng cho các đối tượng đơn token trên Llama2-7b.

sự khác biệt đặc biệt rõ ràng đối với các đối tượng đa token.

4.4 Tác động của hạng của nghịch đảo LRE
Một kết quả đáng ngạc nhiên từ Hernandez et al. (2023b) là việc sử dụng nghịch đảo hạng thấp của LRE dẫn đến hiệu suất tốt hơn so với nghịch đảo hạng đầy đủ. Chúng tôi điều tra mối quan hệ giữa hạng của nghịch đảo LRE và hiệu suất trên bộ dữ liệu quan hệ cho phương pháp của chúng tôi, với kết quả trong Hình 6.

Hình 6: Độ chính xác phân loại và tính nhân quả trên bộ dữ liệu quan hệ theo hạng nghịch đảo LRE trên Llama2-7b.

Việc sử dụng nghịch đảo LRE hạng thấp cải thiện hiệu suất đáng kể, với hiệu suất đạt đỉnh xung quanh hạng 200 cho Llama2-7b. Llama2-7b có

Mẫu huấn luyện LRE Độ chính xác Tính nhân quả
Cùng đối tượng 0.31 ± 0.04 0.31 ± 0.02
Đối tượng khác 0.69 ± 0.01 0.70 ± 0.02

Bảng 6: Kết quả cho việc huấn luyện một LRC xuất phát từ một LRE được huấn luyện với một mẫu huấn luyện duy nhất cho bộ dữ liệu quan hệ, trong đó mẫu đó hoặc biểu diễn cùng đối tượng với LRC (Cùng đối tượng) hoặc một đối tượng khác trong cùng quan hệ (Đối tượng khác) cho Llama2-7b.

không gian ẩn 4096 chiều, vì vậy một nghịch đảo hạng 200 đang loại bỏ hơn 95% ma trận trọng số. Khả năng tổng quát hóa của việc sử dụng LRE nghịch đảo để tìm các hướng khái niệm có thể đến từ nghịch đảo hạng thấp này, trong đó các thành phần quan trọng của quan hệ được nắm bắt trong các giá trị đơn lớn nhất của ma trận trọng số LRE.

4.5 Lựa chọn mẫu để huấn luyện LRE
Chúng tôi chỉ sử dụng LRE như một bước trung gian trong việc suy ra một LRC, vì vậy có thể huấn luyện một LRE cho mỗi LRC, được tối ưu hóa cho quan hệ và đối tượng cụ thể (r, o) của LRC đó. Một trực giác là chỉ chọn các mẫu huấn luyện chứa đối tượng LRC. Ví dụ, để huấn luyện một LRC cho "Located in country: France", chúng ta có thể chọn các mẫu huấn luyện LRE chỉ bao gồm các thành phố ở Pháp.

Chúng tôi điều tra ý tưởng này sử dụng chỉ một mẫu huấn luyện duy nhất để huấn luyện LRE, vì nhiều đối tượng trong bộ dữ liệu chỉ có một mẫu huấn luyện duy nhất và chúng tôi muốn đảm bảo kết quả không chỉ đơn giản là phản ánh số lượng mẫu có sẵn để huấn luyện LRE. Chúng tôi so sánh việc huấn luyện LRE và LRC sử dụng một mẫu biểu diễn cùng đối tượng với việc huấn luyện LRE với một mẫu từ một đối tượng khác trong cùng quan hệ. Kết quả được hiển thị trong Bảng 6.

Một cách không trực quan, việc huấn luyện LRE sử dụng một mẫu với cùng đối tượng như LRC dẫn đến hiệu suất tệ hơn đáng kể. Chúng tôi chưa hiểu tại sao điều này xảy ra, nhưng nghi ngờ rằng việc chọn các mẫu từ các đối tượng khác nhau có thể có hiệu ứng điều hòa trên LRC kết quả. Cần điều tra thêm để hiểu hiện tượng này một cách sâu sắc, nhưng đối với mục đích của chúng tôi, chúng tôi thấy rằng việc các mẫu huấn luyện cho LRE chứa các đối tượng khác nhau từ cùng quan hệ là cần thiết.

4.6 Đánh đổi giữa tính nhân quả và độ chính xác
Trong khi chúng tôi sử dụng tính nhân quả đa lớp để tránh phạt việc huấn luyện ở các lớp sau của mô hình, chúng tôi vẫn thấy một

--- TRANG 8 ---
đánh đổi giữa tính nhân quả và độ chính xác phân loại tùy thuộc vào lớp chủ thể của LRC. Các lớp sớm hơn cho phép LRC tìm các can thiệp nhân quả tối đa, nhưng độ chính xác phân loại bị ảnh hưởng vì các lớp MLP của mô hình chưa có cơ hội tăng cường token chủ thể với thông tin liên quan. Hình 7 hiển thị kết quả độ chính xác phân loại và tính nhân quả trên bộ dữ liệu quan hệ cho việc huấn luyện LRC sử dụng các lớp chủ thể từ 10 đến 21 trên Llama2-7b.

Hình 7: Độ chính xác phân loại và tính nhân quả trên bộ dữ liệu quan hệ theo lớp chủ thể trên Llama2-7b với lớp đối tượng 22.

Tính nhân quả cao nhất với các lớp sớm hơn, trong khi độ chính xác phân loại theo xu hướng ngược lại, tăng lên đến lớp 19. Chúng tôi nghi ngờ đánh đổi này là một hạn chế của việc sử dụng một cặp lớp chủ thể và đối tượng duy nhất. Có thể kết hợp các LRC được học ở các lớp khác nhau để cải thiện cả độ chính xác phân loại và tính nhân quả.

5 Công việc liên quan
Công việc trước đây về hiểu mạng neural tập trung vào các neuron cá thể (Bills et al., 2023; Yosinski et al., 2015). Tuy nhiên, các neuron cá thể đã được thấy kích hoạt để phản hồi nhiều khái niệm, làm cho việc hiểu rõ ràng trở nên khó khăn (Goh et al., 2021). Thật vậy, transformer có thể biểu diễn nhiều khái niệm hơn số neuron chúng có trong các lớp ẩn (Elhage et al., 2022).

Một nguồn cảm hứng của công việc chúng tôi là chỉnh sửa kiến thức trong LM, cụ thể là ROME (Meng et al., 2022) và REMEDI (Hernandez et al., 2023a). Trong ROME, kiến thức thực tế được chỉ ra là nằm trong các MLP lớp giữa của các mô hình ngôn ngữ, và có thể được chỉnh sửa bằng cách cập nhật một MLP lớp giữa để chèn bất kỳ thực tế nào mong muốn.

Trong REMEDI, đầu ra mô hình được chỉnh sửa bằng cách thêm một vector vào chủ thể của một câu trong quá trình suy luận về phía trước. Điều này tương tự với công việc của chúng tôi ở chỗ vector này có thể được nói là chứa khái niệm mà mong muốn được gợi ra. Tuy nhiên, mục tiêu của REMEDI là chỉnh sửa đầu ra mô hình thay vì xác định các hướng khái niệm và xây dựng một bộ phân loại như trong công việc của chúng tôi.

Chúng tôi cũng lấy cảm hứng từ các bộ phân loại thăm dò (Belinkov, 2022; Ettinger et al., 2016). Các bộ phân loại thăm dò là các bộ phân loại tuyến tính hoạt động trên các kích hoạt ẩn bên trong mạng neural. TCAV (Kim et al., 2018) có thể được nói là một bộ phân loại thăm dò cho các mô hình thị giác, trong đó một bộ phân loại được học tại nhiều lớp trong mô hình. Gần nhất với công việc của chúng tôi, Li et al. (2021) xây dựng một bộ phân loại thăm dò cho các trò chơi văn bản từ các kích hoạt ẩn LM, và cho thấy rằng các kích hoạt ẩn này mã hóa một mô hình thế giới cơ bản. Tuy nhiên, công việc này tập trung vào các mô hình encoder-decoder, và không cố gắng phân loại các khái niệm có thể hiểu được bởi con người tùy ý ngoài trò chơi văn bản.

Gần nhất với bài báo này là công việc về LRE trong LLM (Hernandez et al., 2023b), đây là nguồn của bộ dữ liệu đánh giá của chúng tôi và là bước đầu tiên trong phương pháp của chúng tôi. Công việc này cũng cố gắng ước lượng các quan hệ, và học một ánh xạ tuyến tính từ kích hoạt token chủ thể tới token đầu ra đầu tiên của đối tượng. Tuy nhiên, vì LRE chỉ ánh xạ tới token đối tượng đầu tiên, chúng gặp khó khăn với các đối tượng đa token. Ví dụ, một LRE được đánh giá về tính trung thực không thể phân biệt giữa "Bill Gates" và "Bill Clinton" vì chúng đều bắt đầu bằng cùng một token. Ngoài ra, công việc LRE gốc được trình bày như một khám phá về cách LLM mã hóa các quan hệ thay vì cố gắng xây dựng một bộ phân loại hoặc tìm các hướng khái niệm.

6 Kết luận
Việc xác định và phân loại một tập hợp rộng các khái niệm có thể hiểu được bởi con người trong các kích hoạt mô hình ngôn ngữ là một bước quan trọng hướng tới việc hiểu cách các mô hình ngôn ngữ hoạt động. Trong công việc này, chúng tôi đã chỉ ra một kỹ thuật để xác định và phân loại các khái niệm trong các kích hoạt ẩn mô hình được gọi là các khái niệm quan hệ tuyến tính (LRC). Chúng tôi chỉ ra rằng LRC vượt trội hơn các bộ phân loại tuyến tính tiêu chuẩn như SVM về cả độ chính xác phân loại và tính nhân quả.

Trong khi kỹ thuật của chúng tôi hoạt động tốt, có sự khác biệt trong hiệu suất tùy thuộc vào các mẫu huấn luyện được chọn. Chúng tôi mong đợi các cải thiện tiếp theo sẽ đạt được bằng cách tối ưu hóa các mẫu huấn luyện LRE được chọn cho mỗi LRC. Ngoài ra, có thể kết hợp các LRC được học tại nhiều lớp để đạt được kết quả thậm chí tốt hơn để vượt qua

--- TRANG 9 ---
đánh đổi tính nhân quả / độ chính xác tùy thuộc vào lớp được chọn để huấn luyện LRC.

Trong tương lai, các kỹ thuật xác định khái niệm như LRC có thể làm cho việc điều tra các mối quan hệ giữa các khái niệm trong trọng số mô hình trở nên khả thi, và trích xuất kiến thức và thậm chí các mô hình thế giới trực tiếp từ các mô hình ngôn ngữ được huấn luyện trước.

Hạn chế
Phương pháp của chúng tôi yêu cầu học một LRC mới cho mỗi cặp (r, o), vì vậy không thể tổng quát hóa cho các đối tượng mới mà không có mẫu huấn luyện của cặp (r, o) đó. Đánh giá của chúng tôi cũng giả định rằng mỗi chủ thể chỉ ánh xạ tới một đối tượng duy nhất trong cùng quan hệ, và sẽ cần sửa đổi để xử lý các chủ thể với nhiều đối tượng trong cùng quan hệ, như một bộ phim có thể có nhiều thể loại, nhưng chúng tôi không điều tra điều đó trong công việc này.

Phương pháp của chúng tôi giả định rằng mỗi khái niệm có thể hiểu được bởi con người tương ứng với một hướng trong không gian ẩn của mô hình, và chúng tôi giả định rằng nếu mô hình đưa ra câu trả lời chính xác cho một prompt thì mô hình có một biểu diễn của khái niệm này trong các kích hoạt của nó. Tuy nhiên, cũng có thể mô hình đoán câu trả lời chính xác mà không có bất kỳ biểu diễn cơ bản nào, điều này sẽ khiến phương pháp của chúng tôi không hoạt động tốt. Ví dụ, đối với prompt "Sam Eastwood's father is named", mô hình sẽ đưa ra câu trả lời chính xác "Clint Eastwood". Tuy nhiên, mô hình có một biểu diễn cơ bản của thực tế này trong các kích hoạt ẩn của nó, hay nó chỉ đơn giản đoán người nổi tiếng nhất với họ "Eastwood", đó là Clint Eastwood? Thật vậy, GPT-J sẽ đưa ra "Clint Eastwood" làm cha của hầu như bất kỳ người được tạo ra nào với họ "Eastwood". Phương pháp của chúng tôi có thể sẽ hoạt động tốt hơn nhiều nếu những trường hợp mà mô hình có thể đoán câu trả lời chính xác được lọc ra, nhưng việc phân biệt giữa mô hình đoán và biết câu trả lời chính xác là thách thức.

Công việc gần đây gợi ý rằng đôi khi kiến thức ánh xạ các chủ thể tới đối tượng không có mặt trong các lớp MLP được áp dụng cho token chủ thể, mà thay vào đó được chứa trực tiếp trong các giá trị attention và chỉ được thêm vào dòng dư của các token đầu ra thay vì chủ thể (Geva et al., 2023). Đối với kiến thức thuộc loại này, phương pháp của chúng tôi sẽ thất bại vì chúng tôi giả định tất cả kiến thức có thể được tìm thấy trong dòng dư token chủ thể thay vì cần nhìn vào token đầu ra.

Cuối cùng, phương pháp của chúng tôi chỉ hoạt động cho các khái niệm quan hệ có dạng (s, r, o). Các loại khái niệm khác không dễ dàng phù hợp với định dạng này sẽ yêu cầu một sự thích ứng hoặc một kỹ thuật khác.

Tuyên bố đạo đức
Bằng cách khám phá các kích hoạt mô hình bên trong trước khi mô hình tạo ra đầu ra, LRC có thể giúp xác định vị trí các thiên kiến và thông tin không chính xác bên trong trọng số mô hình. Tuy nhiên, LRC không cung cấp một cách để sửa chữa một cách mạnh mẽ những thiên kiến và lỗi này. Đây có thể là một hướng cho nghiên cứu tương lai.

Lời cảm ơn
Oana-Maria Camburu được hỗ trợ bởi Học bổng Nghề nghiệp Sớm Leverhulme. David Chanin được hỗ trợ nhờ EPSRC EP/S021566/1.

Tài liệu tham khảo
Yonatan Belinkov. 2022. Probing classifiers: Promises, shortcomings, and advances. Computational Linguistics, 48(1):207–219.

Steven Bills, Nick Cammarata, Dan Mossing, Henk Tillman, Leo Gao, Gabriel Goh, Ilya Sutskever, Jan Leike, Jeff Wu, and William Saunders. 2023. Language models can explain neurons in language models. URL https://openaipublic. blob. core. windows. net/neuron-explainer/paper/index. html.(Date accessed: 14.05. 2023) .

Nelson Elhage, Tristan Hume, Catherine Olsson, Nicholas Schiefer, Tom Henighan, Shauna Kravec, Zac Hatfield-Dodds, Robert Lasenby, Dawn Drain, Carol Chen, et al. 2022. Toy models of superposition. arXiv preprint arXiv:2209.10652 .

Allyson Ettinger, Ahmed Elgohary, and Philip Resnik. 2016. Probing for semantic evidence of composition by means of simple classification tasks. In Proceedings of the 1st workshop on evaluating vector-space representations for nlp , pages 134–139.

Matthew Finlayson, Aaron Mueller, Sebastian Gehrmann, Stuart Shieber, Tal Linzen, and Yonatan Belinkov. 2021. Causal analysis of syntactic agreement mechanisms in neural language models. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) , pages 1828–1843, Online. Association for Computational Linguistics.

Mor Geva, Jasmijn Bastings, Katja Filippova, and Amir Globerson. 2023. Dissecting recall of factual associations in auto-regressive language models. arXiv preprint arXiv:2304.14767 .

--- TRANG 10 ---
Mor Geva, Roei Schuster, Jonathan Berant, and Omer Levy. 2021. Transformer feed-forward layers are key-value memories. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing , pages 5484–5495, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

Gabriel Goh, Nick Cammarata, Chelsea Voss, Shan Carter, Michael Petrov, Ludwig Schubert, Alec Radford, and Chris Olah. 2021. Multimodal neurons in artificial neural networks. Distill , 6(3):e30.

Evan Hernandez, Belinda Z Li, and Jacob Andreas. 2023a. Measuring and manipulating knowledge representations in language models. arXiv preprint arXiv:2304.00740 .

Evan Hernandez, Arnab Sen Sharma, Tal Haklay, Kevin Meng, Martin Wattenberg, Jacob Andreas, Yonatan Belinkov, and David Bau. 2023b. Linearity of relation decoding in transformer language models. arXiv preprint arXiv:2308.09124 .

Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas, et al. 2018. Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav). In International conference on machine learning , pages 2668–2677. PMLR.

Belinda Z. Li, Maxwell Nye, and Jacob Andreas. 2021. Implicit representations of meaning in neural language models. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) , pages 1813–1827, Online. Association for Computational Linguistics.

Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov. 2022. Locating and editing factual associations in gpt. Advances in Neural Information Processing Systems , 35:17359–17372.

Alberto Paccanaro and Geoffrey E. Hinton. 2001. Learning distributed representations of concepts using linear relational embedding. IEEE Transactions on Knowledge and Data Engineering , 13(2):232–244.

Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288 .

Ben Wang and Aran Komatsuzaki. 2021. Gpt-j-6b: A 6 billion parameter autoregressive language model.

Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, and Hod Lipson. 2015. Understanding neural networks through deep visualization. In Deep Learning Workshop, International Conference on Machine Learning (ICML) .

A Phụ lục
A.1 Kết quả mở rộng
Kết quả đầy đủ được chia nhỏ theo từng quan hệ được kiểm tra được hiển thị trong Hình 8 cho GPT-J. Biểu đồ này so sánh kết quả cho phương pháp của chúng tôi (LRC) với kết quả cho máy vector hỗ trợ (SVM).

Hình 8: Độ chính xác phân loại được chia nhỏ theo quan hệ cho LRC (của chúng tôi) so với SVM trên GPT-J. Phương pháp của chúng tôi vượt trội hơn SVM trên hầu hết, nhưng không phải tất cả, các quan hệ.

Kết quả về tác động của hạng nghịch đảo ma trận trọng số LRE đối với hiệu suất của phương pháp LRC cho GPT-J được hiển thị trong Hình 9.

Kết quả minh họa tác động của việc lựa chọn lớp đối tượng phương pháp của chúng tôi cho GPT-J được hiển thị trong Hình 10,

--- TRANG 11 ---
Hình 9: Độ chính xác phân loại và tính nhân quả trên bộ dữ liệu quan hệ theo hạng nghịch đảo LRE trên GPT-J. Vùng bóng chỉ ra độ lệch chuẩn sau năm seed.

với lớp chủ thể 15. Chúng tôi không chia nhỏ tác động của việc lựa chọn lớp đối tượng này theo các đối tượng đơn token so với đa token vì GPT-J trả lời rất ít prompt đối tượng đa token một cách chính xác.

Hình 10: Độ chính xác phân loại và tính nhân quả trên bộ dữ liệu quan hệ theo lớp đối tượng LRE trên GPT-J với lớp chủ thể 15. Vùng bóng chỉ ra độ lệch chuẩn sau năm seed.

Kết quả minh họa tác động của việc lựa chọn lớp chủ thể đối với hiệu suất LRC được hiển thị trong Hình 11 với lớp đối tượng 20. Như với Llama2-7b, chúng tôi thấy một đánh đổi giữa tính nhân quả và độ chính xác phân loại, trong đó các lớp sớm hơn dẫn đến hiệu suất tính nhân quả tốt hơn với chi phí của độ chính xác phân loại.

A.2 Ý nghĩa thống kê
Chúng tôi tính toán ý nghĩa thống kê giữa phương pháp của chúng tôi (LRC) và SVM cho độ chính xác phân loại và tính nhân quả. Chúng tôi thấy rằng sự cải thiện hiệu suất của LRC so với SVM có ý nghĩa thống kê. Chúng tôi sử dụng kiểm định Z hai tỷ lệ để tính toán ý nghĩa. Vì chúng tôi chạy năm seed ngẫu nhiên với các phân chia train / test khác nhau, chúng tôi tính toán ý nghĩa cho mỗi phân chia ngẫu nhiên riêng biệt để tránh đếm trùng các mẫu có thể xảy ra trong các phân chia khác nhau. Điều này sẽ làm cho ước lượng ý nghĩa của chúng tôi thận trọng hơn so với nếu chúng tôi tổng hợp kết quả trên tất cả các phân chia.

Để đơn giản hóa tính toán ý nghĩa, các điểm số không được cân đối lại theo quan hệ như được thực hiện trong kết quả trong bài báo, vì vậy nếu một quan hệ có nhiều mẫu hơn một quan hệ khác, chúng tôi không cân đối lại để tính đến điều đó trong tính toán này. Kết quả là, các điểm LRC và SVM cho mỗi lần lặp hơi khác với những gì xuất hiện sớm hơn trong bài báo.

Tính toán P-value cho Llama2-7b được hiển thị trong Hình 7, và cho GPT-J trong Hình 8.

Đối với Llama2-7b, phương pháp của chúng tôi tốt hơn SVM một cách có ý nghĩa thống kê cho cả độ chính xác phân loại và tính nhân quả. Tuy nhiên, đối với GPT-J, sự khác biệt về độ chính xác phân loại không có ý nghĩa thống kê giữa phương pháp của chúng tôi và SVM, nhưng phương pháp của chúng tôi vượt trội hơn SVM về tính nhân quả với ý nghĩa thống kê.

Hình 11: Độ chính xác phân loại và tính nhân quả trên bộ dữ liệu quan hệ theo lớp chủ thể LRE trên GPT-J. Vùng bóng chỉ ra độ lệch chuẩn sau năm seed.

--- TRANG 12 ---
Độ chính xác phân loại (Llama2-7b)
Seed Mẫu test LRC SVM P-val
42 3324 0.842 0.811 9e-4
43 3326 0.845 0.804 1e-5
44 3319 0.839 0.808 9e-4
45 3354 0.838 0.816 0.016
46 3335 0.843 0.803 2e-5

Tính nhân quả (Llama2-7b)
Seed Mẫu test LRC SVM P-val
42 1527 0.762 0.652 3e-11
43 1533 0.733 0.606 7e-14
44 1517 0.740 0.633 2e-10
45 1497 0.764 0.607 3e-20
46 1497 0.723 0.627 2e-8

Bảng 7: Tính toán ý nghĩa thống kê cho so sánh độ chính xác phân loại của phương pháp chúng tôi (LRC) so với SVM sử dụng Llama2-7b. Tất cả các so sánh đều ở lớp chủ thể 17. Chúng tôi sử dụng lớp đối tượng 21 cho LRC. Tất cả P-value từ mỗi seed cho cả độ chính xác phân loại và tính nhân quả đều thấp hơn ngưỡng 0.05 cho ý nghĩa thống kê. Để đơn giản hóa tính toán ý nghĩa, các điểm số này không được cân đối lại theo quan hệ như được thực hiện trong kết quả trong bài báo, vì vậy nếu một quan hệ có nhiều mẫu hơn một quan hệ khác, chúng tôi không cân đối lại để tính đến điều đó trong tính toán này.

Độ chính xác phân loại (GPT-J)
Seed Mẫu test LRC SVM P-val
42 2181 0.825 0.793 0.007
43 2129 0.803 0.800 0.818
44 2176 0.784 0.816 0.008
45 2173 0.789 0.791 0.882
46 2236 0.812 0.789 0.0517

Tính nhân quả (GPT-J)
Seed Mẫu test LRC SVM P-val
42 1049 0.699 0.546 6e-13
43 1054 0.733 0.602 1e-10
44 1088 0.716 0.581 4e-11
45 1014 0.735 0.570 7e-15
46 1097 0.718 0.560 1e-14

Bảng 8: Tính toán ý nghĩa thống kê cho so sánh độ chính xác phân loại của phương pháp chúng tôi (LRC) so với SVM sử dụng GPT-J. Tất cả các so sánh đều ở lớp chủ thể 14. Chúng tôi sử dụng lớp đối tượng 20 cho LRC. Kết quả độ chính xác phân loại cho LRC không có ý nghĩa thống kê so với SVM, nhưng kết quả tính nhân quả có ý nghĩa thống kê đáng kể. Để đơn giản hóa tính toán ý nghĩa, các điểm số này không được cân đối lại theo quan hệ như được thực hiện trong kết quả trong bài báo, vì vậy nếu một quan hệ có nhiều mẫu hơn một quan hệ khác, chúng tôi không cân đối lại để tính đến điều đó trong tính toán này.

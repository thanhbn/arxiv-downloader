# Học biểu diễn phân tách nhân quả phi-khái niệm với Bộ mã hóa-giải mã tự động đồ thị biến phân

Jingyun Feng1Lin Zhang2Lili Yang1

## Tóm tắt

Trong học biểu diễn phân tách, mục tiêu là đạt được một biểu diễn gọn nhẹ bao gồm tất cả các yếu tố sinh trưởng có thể diễn giải trong dữ liệu quan sát. Học biểu diễn phân tách cho đồ thị trở nên ngày càng quan trọng khi dữ liệu đồ thị phát triển nhanh chóng. Các phương pháp tiếp cận hiện tại thường dựa vào Bộ mã hóa-giải mã tự động biến phân (VAE) hoặc sự tinh chỉnh dựa trên học cấu trúc nhân quả của nó, chúng gặp phải vấn đề không tối ưu trong VAE do giả định độc lập của yếu tố và không có sẵn nhãn khái niệm, tương ứng. Trong bài báo này, chúng tôi đề xuất một giải pháp không giám sát, được gọi là phân tách nhân quả phi-khái niệm, được xây dựng trên một cận trên chặt chẽ có thể chứng minh lý thuyết xấp xỉ yếu tố tối ưu. Điều này dẫn đến một mô hình hóa cấu trúc nhân quả giống SCM học trực tiếp cấu trúc khái niệm từ dữ liệu. Dựa trên ý tưởng này, chúng tôi đề xuất VGAE Nhân quả Phi-khái niệm (CCVGAE) bằng cách tích hợp một lớp phân tách nhân quả mới vào Bộ mã hóa-giải mã tự động đồ thị biến phân. Hơn nữa, chúng tôi chứng minh tính nhất quán khái niệm dưới khung phân tách nhân quả phi-khái niệm của chúng tôi, do đó sử dụng nó để tăng cường khung meta-learning, được gọi là Meta-Graph Nhân quả Phi-khái niệm (CC-Meta-Graph). Chúng tôi tiến hành các thí nghiệm mở rộng để chứng minh sự vượt trội của các mô hình được đề xuất: CCVGAE và CC-Meta-Graph, đạt được cải thiện tuyệt đối lên đến 29% và 11% so với các baseline về AUC, tương ứng.

## 1. Giới thiệu

Dữ liệu đồ thị trở nên phổ biến, trong cả kịch bản tự nhiên và do con người tạo ra, cùng với sự phát triển của deep learning, thu hút sự chú ý ngày càng tăng và làm cho học trên đồ thị trở thành một lĩnh vực nghiên cứu mới nổi, với mục tiêu hiểu đồ thị và xử lý các ứng dụng downstream, chẳng hạn như khám phá thuốc (You et al., 2018), dự báo giao thông (Jiang & Luo, 2022), hệ thống khuyến nghị (Wu et al., 2020), và các ứng dụng khác (Zhou et al., 2020). Đặc biệt quan trọng là học biểu diễn đồ thị (Hamilton, 2020), nhưng nó vẫn là một vấn đề nghiên cứu nổi bật do các tính chất non-IID và non-Euclidean của đồ thị. Có sự chú ý ngày càng tăng đối với học phân tách để giải quyết vấn đề này.

Mục tiêu của học phân tách là thu được các biểu diễn nắm bắt tất cả các yếu tố sinh trưởng có thể diễn giải, được gọi là biểu diễn phân tách (Bengio et al., 2013; Higgins et al., 2018). Một thách thức đáng kể của học phân tách là chúng ta thường chỉ có các quan sát thô trong khi không cho phép bất kỳ giám sát nào trên các yếu tố sinh trưởng (tức là nguyên nhân) (Kumar et al., 2017). Các nỗ lực đầu tiên (Paige et al., 2017; Yang et al., 2021) thường yêu cầu nhãn đầy đủ cho việc huấn luyện và do đó không thể phù hợp với setting thực tế trên. Điều này thúc đẩy chúng tôi tập trung vào setting không giám sát.

Những tiến bộ gần đây trong học phân tách không giám sát chủ yếu tập trung vào Bộ mã hóa-giải mã tự động biến phân (VAEs) (Li & Mandt, 2018) và Mạng đối sinh (GANs) (Kocaoglu et al., 2017). Đặc biệt, khung VAE được ưa thích trong đồ thị vì tính ổn định của nó trái ngược với mode collapse trong GANs do mô hình hóa ngầm phân phối, điều này đặc biệt khó khăn để học phân phối của đồ thị. Vì vậy trong công trình này, chúng tôi tập trung vào khung VAE để khám phá phân tách cho học biểu diễn đồ thị, tức là Bộ mã hóa-giải mã tự động đồ thị biến phân (VGAE) (Kipf & Welling, 2016a).

Mặc dù sự phát triển gần đây của học phân tách, hầu hết các phương pháp tiên tiến trong khung VAE đã giả định rằng các phân phối trong không gian ẩn là Gaussian độc lập (Kim & Mnih, 2018) và do đó dẫn đến các giải pháp không tối ưu (Träuble et al., 2021). Các nghiên cứu (Locatello et al., 2020; Trauble et al., 2020) đã chỉ ra rằng phân tách biểu diễn gần như không thể dưới giả định độc lập khi dữ liệu thể hiện các tương quan nội tại. Ngược lại, mô hình hóa cấu trúc cho các yếu tố cơ bản tăng cường phân tách, đặc biệt là học cấu trúc nhân quả (Schölkopf & von Kügelgen, 2022). Tuy nhiên, khi tận dụng khung VAE, không có nghiên cứu đầy đủ về giải pháp tối ưu trong khi áp đặt một cấu trúc nhân quả trên các yếu tố tiềm ẩn.

Trong bài báo này, chúng tôi cố gắng giải quyết học biểu diễn phân tách nhân quả không giám sát trong khung VGAE, bao gồm phân tích lý thuyết và các phương pháp thực tế. Chúng tôi chứng minh một cận trên chặt chẽ về việc xấp xỉ yếu tố tiềm ẩn tối ưu thông qua học cấu trúc nhân quả. Điều này chỉ ra rằng một hàm mô hình hóa nhân quả tuyến tính có thể xấp xỉ yếu tố tiềm ẩn tối ưu với độ tin cậy cao. Với điều này, chúng tôi sau đó phát triển một phương pháp phân tách nhân quả thực tế mà không yêu cầu nhãn khái niệm, được gọi là phân tách nhân quả phi-khái niệm. Theo cách này, chúng tôi đạt được một mô hình hóa cấu trúc nhân quả hướng dữ liệu học trực tiếp cấu trúc khái niệm từ dữ liệu. Dựa trên điều này, chúng tôi giới thiệu một lớp phân tách nhân quả mới và sau đó tích hợp nó với VGAE, tạo ra mô hình đầu tiên của chúng tôi, được gọi là VGAE Nhân quả Phi-khái niệm (CCVGAE). Bên cạnh đó, chúng tôi khám phá tính nhất quán của các khái niệm thu được do phong cách hướng dữ liệu, làm cho chúng phù hợp để nắm bắt thông tin toàn cục cơ bản với ít dữ liệu. Hướng tới điều này, chúng tôi đề xuất một mô hình meta-learning chuyển giao các khái niệm nhận thức toàn cục cho dữ liệu mới đến, tạo ra mô hình thứ hai của chúng tôi, được gọi là CC-Meta-Graph. Trong Hình 1, chúng tôi trình bày một minh họa về các ý tưởng được đề xuất.

Chúng tôi nêu bật các đóng góp của bài báo này:

1. Trong bài báo này, chúng tôi chứng minh lý thuyết một ràng buộc chặt chẽ về xấp xỉ các yếu tố tối ưu và cung cấp một phương pháp phân tách nhân quả thực tế dựa trên nó, được gọi là phân tách nhân quả phi-khái niệm.

2. Chúng tôi đề xuất hai mô hình tăng cường phân tách nhân quả: một là để hỗ trợ phân tách nhân quả trong VGAE, và mô hình khác là để xác thực thuộc tính nhất quán được đề xuất.

3. Chúng tôi tiến hành các thí nghiệm mở rộng với dữ liệu đồ thị tổng hợp và thế giới thực để chứng minh hiệu quả của các mô hình được đề xuất: CCVGAE và CC-Meta-Graph, đạt được cải thiện tuyệt đối lên đến 29% và 11% cho CCVGAE và CC-Meta-Graph, tương ứng, về dự đoán liên kết.

## 2. Công trình liên quan

**Học Phân tách.** Khái niệm phân tách lần đầu tiên được giới thiệu bởi Bengio et al. (2013) như một thuộc tính của biểu diễn và định nghĩa chính thức của nó Higgins et al. (2018) là: nếu một biểu diễn có thể được phân tách thành nhiều đặc trưng độc lập, có nghĩa là chỉ một trong những đặc trưng này sẽ thay đổi khi thay đổi một yếu tố của đầu vào dữ liệu, thì chúng ta gọi nó là "biểu diễn phân tách". Một số nghiên cứu (Eastwood & Williams, 2018) xem xét một định nghĩa nghiêm ngặt hơn rằng chỉ khi mỗi chiều của biểu diễn có thể nắm bắt nhiều nhất một yếu tố sinh trưởng thực, chúng ta mới có thể gọi biểu diễn này là "biểu diễn phân tách". Để khuyến khích các yếu tố tiềm năng học biểu diễn phân tách trong khi tối ưu hóa các mục tiêu nhiệm vụ cơ bản, học biểu diễn phân tách được thiết kế để nắm bắt các biểu diễn có thể diễn giải, có thể kiểm soát và mạnh mẽ.

Trong học biểu diễn phân tách đồ thị, hầu hết các khung đều dựa trên GNN. DisenGCN (Ma et al., 2019) sử dụng định tuyến lân cận để xác định yếu tố tiềm ẩn có thể gây ra các cạnh, FactorGCN (Yang et al., 2020) phân tách đồ thị thành nhiều đồ thị con, mỗi đồ thị con đại diện cho đồ thị bao gồm một loại cạnh. Tuy nhiên, Fan et al. (2022) nhận thấy rằng GNN luôn gặp phải tương quan giả mạo, ngay cả khi tương quan nhân quả luôn tồn tại. Họ đề xuất DisC để học cấu trúc con nhân quả và cấu trúc con thiên vị. DisC yêu cầu một số nút đồ thị đầu vào đại diện cho các khái niệm. Tuy nhiên, những đồ thị như vậy luôn không có sẵn trong thế giới thực.

Hầu hết các phương pháp học biểu diễn phân tách điển hình là các mô hình sinh, đặc biệt là Bộ mã hóa-giải mã tự động biến phân (VAE) (Higgins et al., 2016; Kumar et al., 2017; Yang et al., 2021; Zhu et al., 2021). VAE sử dụng một posterior biến phân q(z|x) để xấp xỉ posterior thực không biết p(z|x). Để có được khả năng phân tách tốt hơn, các nhà nghiên cứu thiết kế các regularizer bổ sung khác nhau dựa trên hàm mất mát VAE gốc. Một hệ số phạt được giới thiệu vào mất mát ELBO bởi β-vae (Higgins et al., 2016) để tăng cường ràng buộc độc lập của phân phối posterior biến phân q(z|x). FactorVAE (Kim & Mnih, 2018) áp đặt ràng buộc độc lập theo định nghĩa của sự độc lập. Tuy nhiên, khả năng phân tách tốt hơn thường dẫn đến nhiều lỗi tái tạo hơn. Để cân bằng sự đánh đổi giữa tái tạo và phân tách, Burgess et al. (2018) đề xuất một sửa đổi đơn giản dựa trên β-VAE, làm cho chất lượng phân tách có thể được cải thiện càng nhiều càng tốt mà không có quá nhiều lỗi tái tạo. Tuy nhiên, chúng tôi tin rằng xung đột giữa lỗi tái tạo và chất lượng phân tách không tồn tại một cách tự nhiên mà từ phân tách không phù hợp như giả định độc lập như sau. Higgins et al. (2018) giả định rằng các yếu tố sinh trưởng là tự nhiên và độc lập trong học biểu diễn phân tách.

Tuy nhiên, Suter et al. (2019) không đồng ý với giả định độc lập. Họ giả định rằng các yếu tố sinh trưởng của dữ liệu quan sát được ảnh hưởng nhân quả bởi nhóm các yếu tố gây nhiễu, và lần đầu tiên giới thiệu SCM (Krajewski & Matthews, 2010) để mô tả mối quan hệ nhân quả giữa các yếu tố sinh trưởng. Träuble et al. (2021) gợi ý rằng, nếu một số yếu tố sinh trưởng có tương quan trong tập dữ liệu, các phương pháp dựa trên giả định độc lập có thể có thiên vị chống lại phân tách. Các nhà nghiên cứu khác (Yang et al., 2021; Shen et al., 2022) cũng đã thực hiện các thí nghiệm học phân tách trong dữ liệu thế giới thực dựa trên giả định rằng dữ liệu thế giới thực không được tạo ra bởi các yếu tố độc lập. Ở đây, chúng tôi cũng tuân theo cùng giả định rằng các yếu tố sinh trưởng không độc lập và thậm chí tin rằng có những mối quan hệ nhân quả tiềm ẩn giữa các yếu tố này.

**Phân tách Nhân quả.** Trong vài thập kỷ qua, nhiều nhà nghiên cứu (Hoyer et al., 2008; Zhang & Hyvarinen, 2012; Shimizu et al., 2006) đã chú ý đến việc khám phá nhân quả từ dữ liệu quan sát. Với sự phát triển của học phân tách, cộng đồng đã nâng cao sự quan tâm đến việc kết hợp nhân quả và biểu diễn phân tách. Kocaoglu et al. (2017) đề xuất một phương pháp gọi là CausalGAN hỗ trợ "do-operation" trên hình ảnh nhưng nó yêu cầu đồ thị nhân quả được cho như một prior. Suter et al. (2019) tin rằng quá trình sinh nhân quả cơ bản sẽ ảnh hưởng đến mức độ phân tách, và lần đầu tiên đề xuất định nghĩa của quá trình phân tách nhân quả.

Yang et al. (2021) là những người đầu tiên thực hiện quá trình phân tách nhân quả được đề xuất bởi Suter et al. (2019), được gọi là CausalVAE. Tuy nhiên, phương pháp của họ là bán giám sát vì họ yêu cầu nhãn của các yếu tố sinh trưởng. Nhưng những nhãn như vậy khó có được trong đồ thị, vì vậy công trình của chúng tôi tập trung vào một phương pháp không giám sát, làm cho các biến tiềm ẩn học thông tin nhân quả cơ bản từ dữ liệu.

## 3. Ký hiệu và Kiến thức cơ bản

**Ký hiệu.** Một cách chính thức, gọi G = (V,E) biểu thị một đồ thị vô hướng và không có trọng số, với ma trận kề và ma trận bậc của nó là Adj ∈ {0,1}^(n×n) và D, tương ứng. Ở đây, V và E là các tập nút và cạnh, trong đó n = |V|. Các nút được liên kết với các thuộc tính được định nghĩa trước, được viết là Attri ∈ R^n. Chúng tôi sử dụng N(·) để biểu thị phân phối Gaussian.

**Bộ mã hóa-giải mã tự động đồ thị biến phân (VGAE).** Trong VGAE, quan sát chiều cao ε được chiếu vào một không gian chiều thấp để có biểu diễn gọn z sử dụng khung encoder-decoder. Cụ thể, encoder nén dữ liệu đầu vào, và decoder kiểm tra tính hợp lý của dữ liệu nén bằng cách khôi phục dữ liệu thô. Về mặt toán học, chúng ta thường tối ưu VAE bằng cách tối đa hóa evidence lower bound (ELBO), ký hiệu là max_(p,q) L_VAE(ε), trong đó L_VAE(ε) = E_(q(z|ε))[log p(ε|z)] - D_KL(q(z|ε)||p(z)), trong đó D_KL là phân kỳ Kullback-Leibler (Joyce, 2011). VGAE là một trường hợp đặc biệt của VAE, với các hàm dựa trên đồ thị cho q(·) và p(·). Sử dụng mạng tích chập đồ thị (GCN) (Zhang et al., 2018), chúng ta có chúng được định nghĩa như sau: p(Adj_ij = 1|ε_i, ε_j) = σ(ε_i^T ε_j) và q(ε_i|Adj, Attri) = N(μ_i, diag(σ_i)), trong đó mean là μ = GCN_μ(Adj, Attri) và covariance là σ = GCN_σ(Adj, Attri). Ở đây, σ(·) là một hàm kích hoạt và mặc định lấy hàm logistic Sigmoid.

**Mô hình Nhân quả Cấu trúc Tuyến tính (SCM).** SCM tuyến tính định nghĩa một hệ thống nhân quả với các phương trình tuyến tính đại diện cho ngữ nghĩa như sau (Shimizu et al., 2006; Yang et al., 2021), với các yếu tố ngoại sinh độc lập ϵ ∈ R^K và các biến nội sinh z ∈ R^K,

z = Φ^T z + ϵ = (I - Φ^T)^(-1) ϵ, ϵ ~ N(0, I)     (1)

trong đó Φ ∈ R^(K×K) là một ma trận kề cho một đồ thị acyclic có hướng (DAG) nắm bắt cấu trúc nhân quả của n khái niệm. Lưu ý chúng tôi sử dụng cùng các chữ cái ở đây để tránh lạm dụng ký hiệu.

**Quá trình Nhân quả Phân tách (DCP).** DCP nghiên cứu phân tách trong không gian tiềm ẩn bằng cách xem xét các biến gây nhiễu, dẫn đến các thuộc tính có cơ sở lý thuyết vững chắc trái ngược với heuristics trong prior (Suter et al., 2019). Định nghĩa chi tiết của nó như sau.

**Định nghĩa 3.1.** Cho m yếu tố sinh nhân quả là G = [G_1, ..., G_m] và L confounder là C = {C_1, ..., C_L}, phân tách nhân quả cho quan sát X là có thể nếu và chỉ nếu X có thể được biểu diễn trong ngữ cảnh SCM như sau,

C ← ζ_C                                    (2)
G_i ← q_i(H_i^C, ζ_i), i = 1,2, ..., m      (3)
X ← g(G, ζ_x)                             (4)

Ở đây, H_i^C ∈ {C_1, ..., C_L} là nút cha của G_i, tức là H_i^C → G_i đúng về mặt nhân quả. ζ_c, {ζ_i}_(i=1,2,...,m), ζ_x là các biến nhiễu độc lập. Lưu ý q_i và g là các hàm được định nghĩa trước.

## 4. Lý thuyết

Trong phần này, chúng tôi đầu tiên xây dựng bài toán học biểu diễn phân tách nhân quả trong VGAE. Tiếp theo chúng tôi trình bày một phân tích lý thuyết về phân tách nhân quả, trong đó chúng tôi cung cấp một cận trên chặt chẽ để xấp xỉ mức tối ưu (xem Phần 4.1). Sau đó, chúng tôi giới thiệu một giải pháp thực tế để hoàn thành việc xấp xỉ này cùng với các thuộc tính của nó (xem Phần 4.2).

**Xây dựng Bài toán.** Ký hiệu dữ liệu đồ thị đầu vào là X và yếu tố tiềm ẩn tối ưu của nó là Z* (Träuble et al., 2021), phân phối dữ liệu tối ưu được xây dựng là p*(X) = ∫_(Z*) p*(X|Z*)p*(Z*)dZ*, cùng với một giả định non-i.i.d. trên Z*, tức là p*(Z*) ≠ ∏_i p(Z*_i). Như một giải pháp phổ biến cho phân tách, VGAE phân tách dữ liệu đầu vào thành biểu diễn tiềm ẩn Z, và phân phối dữ liệu tương ứng là p_θ(X) = ∫_Z p_θ(X|Z)p(Z)dZ, trong đó θ là các tham số có thể học. Cho rằng tất cả các tương quan có thể được mô hình hóa như các cấu trúc nhân quả (Schölkopf & von Kügelgen, 2022), chúng tôi để Z sở hữu một cấu trúc nhân quả và định nghĩa cấu trúc này với DCP. Không có nhãn từ Z, mục tiêu của học biểu diễn phân tách nhân quả không giám sát trong VGAE là đạt được một yếu tố tiềm ẩn tối ưu Z* trong khi làm cho p_θ(X) = p*(X) luôn giữ.

### 4.1. Một phân tích lý thuyết về phân tách nhân quả

**Định nghĩa 4.1.** Cho quá trình (2) và (3) trong DCP, chúng ta thu được các yếu tố sinh là G = Q(ζ^+), với ζ_G = {ζ_1, ζ_2, ..., ζ_m} và ζ^+ = ζ_C ∪ ζ_G. Phân phối của dữ liệu có thể đạt được là p_(θζ_x)(X) = ∫_G p_(θζ_x)(X|G)p(G)dG.

Định nghĩa này gợi ý rằng một dữ liệu cho trước có thể được biểu diễn với các yếu tố sinh nhân quả trong khi không có giả định về sự độc lập như trong VAE trước đây. Dựa trên điều này, như chúng ta sẽ thấy trong Định lý 4.1, phân tách nhân quả đảm bảo một giải pháp tối ưu để đạt được điều sau: 1) tính nhất quán phân phối giữa dữ liệu đầu vào và dữ liệu dự đoán, tức là p_θ(X) = p*(X), và 2) yếu tố tiềm ẩn tối ưu Z*. Ngược lại, VAE truyền thống áp đặt một giả định độc lập trên Z và gặp phải giải pháp không tối ưu (Träuble et al., 2021) w.r.t phân phối dữ liệu thực, dẫn đến p_θ(X) ≠ p*(X). Với sự khác biệt này, phân tách nhân quả trên tránh giả định như vậy.

**Định lý 4.1.** Cho các biến phân phối Normal độc lập N = N_1, ..., N_K, tồn tại một hàm mô hình hóa nhân quả tối ưu Q đại diện cho yếu tố sinh nhân quả G = {G_1, ..., G_K} = Q(N), tương đương với yếu tố tiềm ẩn phân tách tối ưu Z*, trong khi giữ p_(θζ_x)(X) = p*(X).

Chúng tôi hoãn việc chứng minh Định lý 4.1 đến Phụ lục A.1. Định lý 4.1 chứng minh rằng trong một setting nhân quả, phải tồn tại một giải pháp tối ưu cho VAE. Tiếp theo, chúng tôi giới thiệu một biểu thức yếu tố sinh nhân quả tổng quát thống nhất cơ sở cho phân tách nhân quả.

**Định nghĩa 4.2.** (biểu thức yếu tố sinh nhân quả tổng quát). Cho các biến phân phối Normal độc lập N = {N_1, ..., N_K} và một ma trận A ∈ R^(K×K), bất kỳ yếu tố sinh nhân quả nào có thể được xây dựng là G_i = Q_i(B_i), trong đó B = A * diag(N).

Theo Định lý 4.1 và định nghĩa trên, chúng ta đạt được một biểu thức tối ưu thống nhất của yếu tố sinh như sau (chứng minh chi tiết ở Phụ lục A.2):

**Mệnh đề 1.** (biểu thức yếu tố sinh tối ưu thống nhất). Gọi A là một ma trận tam giác dưới, thì biểu thức của các yếu tố sinh tối ưu có thể được thống nhất là G_i = Q_i(B_i), trong đó B = Â * diag(N) và Â được hoán vị từ A.

Đã thiết lập các kết nối giữa các yếu tố sinh tối ưu trong Mệnh đề 1, chúng ta đi đến một điều kiện cần thiết cho các yếu tố tối ưu. Trong khi trong bài báo này chúng tôi mong muốn thu được cả điều kiện cần thiết và đủ cho các yếu tố tối ưu. Giải quyết cả hai điều này cùng nhau tạo ra một giải pháp phân tích cho các yếu tố tối ưu (tại Phụ lục A.1), làm cho việc thực hiện khó khăn trong các kiến trúc deep hiện đại. Một giải pháp như vậy trở nên không khả thi cùng với một phân phối không biết cho các biểu diễn tiềm ẩn tối ưu.

Một giải pháp thực tế là xấp xỉ các yếu tố tối ưu, trong phạm vi tin cậy chấp nhận được, trong khi có tính khả thi thực tế.

Cung cấp một cơ sở biểu diễn B_i, giả sử sự tồn tại của một yếu tố sinh xấp xỉ với yếu tố tối ưu, Q_i(B_i), trên cùng không gian, ký hiệu là Q'_i(B_i). Chúng tôi suy ra một cận trên chặt chẽ về lỗi xấp xỉ bằng cách đặt Q'_i là một hàm tuyến tính, như được chỉ ra trong Định lý 4.2.

**Định lý 4.2.** Cho B_i trong Mệnh đề 1, và N_i với một khoảng N_i ∈ [μ_i - δ, μ_i + δ], i = 1,2, ..., K, cho một Q_i(B_i) tối ưu, tồn tại một hàm tuyến tính Q'_i làm cho Q'_i(B_i), lỗi tuyệt đối có ràng buộc như vậy: |Q_i(B_i) - Q'_i(B_i)| ≤ O_i(δ), trong đó O_i(δ) = a_i + δΛ_i, Λ_i = b_i + Σ_(t=1)^i c_it d_t δ^2_t, a_i, b_i, c_it, d_t là các hằng số không liên quan đến δ, 0 < d_t < 1, i = 1,2, ..., K và t = 1,2, ..., K, δ là một số thực không âm không liên quan đến phân phối của N.

Vui lòng xem Phụ lục A.3 để biết thêm chi tiết. Định lý 4.2 gợi ý rằng trên 95% xác suất, phạm vi của N_i nằm trong [μ_i - 2σ_i, μ_i + 2σ_i] và do đó lỗi được ràng buộc bởi O_i(2σ_i), tức là ràng buộc gần như là hằng số với 95% tin cậy. Lưu ý rằng chúng tôi giả định biểu diễn tiềm ẩn tối ưu (Z*_1, Z*_2, ..., Z*_K) như một phân phối đều tuyến tính. Người ta có thể đi đến các ràng buộc khác nhau với các phân phối, và chúng tôi lấy phân phối đều để đơn giản.

### 4.2. Phân tách Nhân quả Phi-khái niệm

Định lý 4.2 nói rằng chúng ta có thể thu được một yếu tố sinh tối ưu xấp xỉ bằng cách chỉ định hàm chiếu tuyến tính. Xấp xỉ này cho phép một triển khai thực tế hướng tới yếu tố tiềm ẩn tối ưu. Một cách chính thức, chúng tôi giới thiệu yếu tố sinh dựa trên chiếu tuyến tính:

**Mệnh đề 2.** (Biểu thức yếu tố sinh xấp xỉ). Cho các biến phân phối Normal độc lập N = {N_1, ..., N_K}, một ma trận tam giác dưới Ã_i, một yếu tố sinh nhân quả có thể được xây dựng là G'_i = Q'_i(B_i) = Ã_i * N', trong đó Ã được thu được bằng cách hoán vị một ma trận tam giác dưới.

Chứng minh được đưa ra trong Phụ lục A.4. Chúng tôi đặt phân tách nhân quả của mình trong ngữ cảnh của Mô hình Nhân quả Cấu trúc (SCM) và tập trung vào một SCM tuyến tính vì tính đơn giản của nó. Theo đó, chúng tôi chính thức hóa cấu trúc nhân quả trong G như sau,

G' = ΦG' + ε → G' = (I - Φ)^(-1)ε^T     (5)

trong đó Φ ∈ R^(K×K) là một ma trận kề DAG và ε là một biến độc lập. (I - Φ)^(-1) kết quả cũng là một ma trận tam giác thấp được hoán vị, xem chứng minh trong Phụ lục A.6. Lưu ý rằng Mệnh đề 2 là cho một setting nhân quả tổng quát. Đặt N = ε, biểu diễn tuyến tính trên dựa trên SCM chia sẻ cùng biểu thức với biểu thức trong mệnh đề, và do đó kế thừa thuộc tính lý tưởng của việc xấp xỉ yếu tố tiềm ẩn tối ưu Z*. Hơn nữa, hai biến trong Eq. 5 được học từ dữ liệu một cách đơn giản, không có bất kỳ nhãn nào để giám sát. Ký hiệu mỗi G_i là một khái niệm (Kumar et al., 2017) chúng ta đi đến một phân tách nhân quả không giám sát không yêu cầu bất kỳ nhãn khái niệm nào, được gọi là phân tách nhân quả phi-khái niệm.

Trong học phân tách không giám sát, cùng với giả định Gaussian tuyến tính, vấn đề identifiability (Locatello et al., 2019) thường phát sinh do sự khác biệt giữa các khái niệm được định nghĩa trước và các khái niệm đã học. Không có giám sát, chúng ta không thể đạt được những khái niệm được định nghĩa trước này, đặc biệt là với dữ liệu hạn chế. Tuy nhiên, như chúng ta sẽ thấy trong định lý sau, những khái niệm được định nghĩa trước này có thể đạt được khi truy cập đủ dữ liệu. Vì những khái niệm này giữ trong nhiều mẫu, làm cho chúng trở thành ground truth.

**Định lý 4.3.** Cho n quan sát {X^(1), X^(2), ..., X^(n)} được lấy mẫu từ cùng phân phối p*(X), cùng với các yếu tố sinh tối ưu tương ứng của chúng {Z^(1), Z^(2), ..., Z^(n)}, hàm của những yếu tố sinh này sẽ hội tụ về cùng khái niệm ground truth (GT).

Một phiên bản chính thức của Định lý 4.3 và chứng minh của nó có thể được tìm thấy tại Phụ lục A.5. Quan trọng hơn, chúng tôi tin rằng các khái niệm thu được bởi định lý tốt hơn các khái niệm được gán nhãn bởi con người vì những khái niệm này bị hạn chế và có thể liên quan đến thiên vị. Sự khác biệt trên không luôn ngụ ý lỗi trong các khái niệm đã học, và ngược lại, các khái niệm sau có thể là một bù đắp cho những khái niệm được định nghĩa bởi con người.

Bên cạnh đó, Định lý 4.3 cho phép học được đảm bảo hướng tới các khái niệm ground truth (GT) và dẫn đến thuộc tính sau:

**Thuộc tính 1.** (Tính nhất quán của các yếu tố sinh). Cho các quan sát được lấy mẫu từ cùng phân phối, các yếu tố sinh tối ưu của mỗi mẫu, tức là Z*, nắm bắt một phần của các khái niệm GT, ngụ ý rằng người ta có thể xấp xỉ các khái niệm GT với việc hợp nhất Z*, trong đó chúng ta gọi cái được hợp nhất là một khái niệm xấp xỉ.

Thuộc tính nhất quán ngụ ý rằng các khái niệm học từ các mẫu riêng lẻ nắm bắt các khái niệm GT được chia sẻ bởi tất cả dữ liệu từ cùng phân phối, làm cho những khái niệm này có thể thích ứng. Do đó, dưới cùng phân phối, việc chuyển giao các khái niệm từ dữ liệu quan sát sang dữ liệu mới được lấy mẫu có lợi cho việc học dữ liệu mới, do đó giảm đáng kể nhu cầu dữ liệu và tránh đào tạo từ đầu.

## 5. Phương pháp

Trong phần này, chúng tôi đề xuất một VGAE mới với mô hình phân tách nhân quả, được gọi là VGAE Nhân quả Phi-khái niệm (CCVGAE), mục tiêu của nó là thu được các biểu diễn tiềm ẩn phân tách tối ưu. Chúng tôi cũng giới thiệu một khung phân tách nhân quả phi-khái niệm trong setting meta-learning, được gọi là Meta-Graph Nhân quả Phi-khái niệm (CC-Meta-Graph), để khai thác thuộc tính nhất quán khái niệm. Chúng tôi bắt đầu bằng việc giới thiệu định nghĩa của CCVGAE như sau,

**Định nghĩa 5.1.** (CCVGAE). Cho ma trận kề Adj và thuộc tính nút Attri của một đồ thị đầu vào, CCVGAE được đề xuất được định nghĩa bởi:

• Một phân phối dữ liệu prior p*(Z*) ≠ ∏_i p(Z*_i) gốc trên một tập các yếu tố tiềm ẩn có cấu trúc nhân quả Z* = {Z*_1, Z*_2, ...Z*_K}.

• Một encoder được cấu tạo từ một thành phần nén dựa trên GNN và một thành phần phân tách nhân quả. Thành phần đầu sử dụng GNN để nén ma trận kề Adj và thuộc tính nút Attri vào một không gian tiềm ẩn chiều thấp là ε. Thành phần sau (được tham số hóa bởi ϕ) thực hiện phân tách nhân quả phi-khái niệm của chúng tôi với ε làm đầu vào, tối ưu hóa cấu trúc nhân quả cơ bản Φ trong quy trình học, và xuất các tham số xấp xỉ posterior: q_ϕ(G'|ε,Φ) (xem Eq. 5).

• Một decoder p_ψ(Adj|G') nhận yếu tố tiềm ẩn Z để suy ra ma trận kề của dữ liệu đồ thị đầu vào và được tham số hóa bởi ψ, tức là p(Adj_ij = 1|G_i, G_j) = σ(G_i^T G_j), trong đó σ(·) là hàm logistic sigmoid.

**Mục tiêu Tối ưu.** Việc tối ưu hóa CCVGAE là để khuyến khích một sự tương đương giữa phân phối xấp xỉ p_θG(X) và phân phối tối ưu p*(X). Đặc biệt, evidence lower bound (ELBO) được sử dụng để tối thiểu hóa phân kỳ giữa hai phân phối trên, và để áp đặt rằng phân phối của ε là Gaussian độc lập, như sau,

L_G = E_(q(Ĝ|Adj,Attri)) log(p(Adj|Ĝ)) + KL(q(ε|(Adj, Attri))|N(0, I)).     (6)

Ngoài việc tối thiểu hóa các phân kỳ phân phối, chúng tôi cũng muốn rút ngắn khoảng cách giữa quan sát và quan sát được khôi phục bằng cách đo mean squared error (MSE), được viết là: L_MSE = MSE(Attri, p(Attri|Ĝ)).

Trong khi đó, việc thực hiện mô hình hóa cấu trúc nhân quả đòi hỏi một ràng buộc DAG trên Φ. Để thuận tiện cho việc tối ưu hóa, chúng tôi áp đặt một hàm ràng buộc có thể vi phân (Yu et al., 2019) là: L_Φ = tr((I - r√(KΦ◦Φ))^K) - K, trong đó r là một số dương tùy ý, tr(·) ký hiệu trace norm và K ký hiệu số lượng khái niệm. Kết hợp các hàm mất mát trên, chúng tôi suy ra hàm mất mát tổng thể như sau,

L = -L_G + αL_Φ + βL_MSE,     (7)

trong đó α và β là các siêu tham số. Thuật toán tổng thể ở Phụ lục A.7.

### 5.1. Meta-graph phân tách nhân quả phi-khái niệm

Meta-Graph (Bose et al., 2019) xử lý tác vụ dự đoán liên kết few-shot: nó nhằm dự đoán liên kết trên các đồ thị mục tiêu (G_T) với một mô hình được đào tạo trên một vài đồ thị nguồn (G_S), trong đó các đồ thị nguồn và mục tiêu được rút ra từ cùng domain. Ký hiệu phân phối trên các đồ thị trong cùng domain là p(G), các phân phối của đồ thị nguồn và mục tiêu tuân theo cùng, tức là G_S ~ p(G) và G_T ~ p(G). Để hoàn thành tác vụ này, chúng tôi yêu cầu thích ứng chất lượng cao chuyển giao thông tin trong dữ liệu đào tạo sang dữ liệu mới đến.

Theo Thuộc tính 1, phân tách nhân quả phi-khái niệm của chúng tôi có thể cung cấp thích ứng nhanh và do đó rất phù hợp cho setting meta-learning. Meta-Graph sử dụng VGAE truyền thống để nắm bắt thông tin để cung cấp một khởi tạo cho việc đào tạo một mô hình dự đoán liên kết tiếp theo. Nhờ thuộc tính nhất quán, giải pháp phân tách được đề xuất của chúng tôi có thể nắm bắt thông tin (tức là khái niệm) có thể thích ứng với dữ liệu mới đến. Với mục đích này, chúng tôi thay thế VGAE bằng CCVGAE và để các thành phần khác vẫn trong Meta-Graph, được gọi là CC-Meta-Graph. Chúng tôi trình bày thuật toán tương ứng trong Phụ lục A.7.

## 6. Thí nghiệm

### 6.1. Tác vụ 1: Dự đoán Liên kết

Thí nghiệm này nhằm nghiên cứu phương pháp được đề xuất, CCVGAE, hoạt động như thế nào trong tác vụ dự đoán liên kết khi so sánh với các phương pháp hiện đại.

**Tập dữ liệu.** Chúng tôi thí nghiệm trên 6 tập dữ liệu đồ thị benchmark từ nhiều domain khác nhau (Sen et al., 2008; Pei et al., 2020; Tang et al., 2009), bao gồm Cora, dRisk, Actor, Corn, Texas, và Wisconsin. Bảng 6.1 trình bày thống kê của những tập dữ liệu này, bao gồm số lượng nút, cạnh, và thuộc tính nút.

**Bảng 1.** Thống kê tập dữ liệu trong các thí nghiệm của chúng tôi. Lưu ý số cạnh ban đầu cho dữ liệu tổng hợp là 4894. # ký hiệu số lượng.

| Tập dữ liệu | #Nút | #Cạnh | #Thuộc tính |
|-------------|------|-------|-------------|
| Cora        | 2708 | 5429  | 1433        |
| Corn        | 183  | 295   | 1703        |
| Texas       | 183  | 309   | 1703        |
| Wisconsin   | 251  | 499   | 1703        |
| dRisk       | 100  | 478   | 4           |
| Actor       | 7600 | 33544 | 931         |
| Synthetic   | 100  | 4984* | 16          |

Lưu ý rằng dRisk là một tập dữ liệu được biến đổi từ dRiskKB (Xu et al., 2014), được xây dựng từ văn bản sinh học. dRiskKB chứa 12981 nút đại diện cho tên bệnh, với các cạnh có trọng số chỉ ra tương quan giữa các cặp bệnh. Để đơn giản hóa tập dữ liệu, chúng tôi ngẫu nhiên chọn 100 nút từ dRiskKB và chuyển các cạnh có trọng số thành các cạnh không có trọng số. dRiskKB không cung cấp thuộc tính nút, vì vậy chúng tôi ngẫu nhiên tạo 4 chiều đặc trưng one-hot làm thuộc tính nút.

Xem xét rằng các tập dữ liệu thế giới thực thường có nhân quả không biết, chúng tôi do đó xây dựng dữ liệu tổng hợp với nhân quả có thể kiểm soát. Đặc biệt, chúng tôi tạo ra thuộc tính của các nút, X, và ma trận kề, Adj ∈ R^(100×100), như sau: Adj = σ(Z·Z^T) và Attri = 20Sin(Z). Ở đây, chúng tôi tạo ra Z sử dụng SCM tuyến tính để đảm bảo nhân quả của nó, Về mặt toán học, chúng tôi suy ra Z = C^T Z + ε → Z = (I - C^T)^(-1) ε, trong đó C ∈ R^(16×16) là một ma trận tam giác dưới ngẫu nhiên và ε ∈ R^16 là một vector ngẫu nhiên độc lập với phân phối normal cùng phương sai.

**Baseline.** Chúng tôi so sánh CCVGAE với ba phương pháp trước đây: (1) VGAE (Kipf & Welling, 2016b), là VAE dựa trên đồ thị đầu tiên; (2) SIG-VAE (Hasanzadeh et al., 2019), sử dụng một khung biến phân phân cấp cho encoder và một decoder liên kết Bernoulli-Poisson; (3) DGAE (Wu & Cheng, 2022) tích hợp các auto-encoder tiêu chuẩn (AE) vào GAE để tăng cường khả năng mô hình hóa thông tin có cấu trúc.

**Metrics.** Để đánh giá phương pháp của chúng tôi, chúng tôi thực hiện tác vụ dự đoán liên kết và do đó lấy hai metrics thường được sử dụng trong lĩnh vực này (Kipf & Welling, 2016b): Area Under ROC Curve (AUC) và Average Precision (AP) scores. Tất cả kết quả thí nghiệm được tính trung bình trên 3 seeds.

**Chi tiết triển khai.** Chúng tôi đào tạo mô hình được đề xuất cho 200 iterations sử dụng Adam. Đối với mean và variance, chúng tôi sử dụng các lớp GCN 32-chiều và 16-chiều để triển khai, tương ứng.

**Kết quả chính.** Chúng tôi benchmark tất cả các phương pháp trên 6 tập dữ liệu thế giới thực. Trong Bảng 2, chúng tôi quan sát rằng CCVGAE (của chúng tôi) có thể cạnh tranh đáng tin cậy với các phương pháp khác với cải thiện lên đến 29% về AUC và 19% cải thiện về AP. Nhớ lại rằng CCVGAE cải thiện trên VGAE bằng cách tích hợp một lớp nhân quả để khuyến khích biểu diễn phân tách, gợi ý rằng cải thiện đáng kể là do tính biểu đạt của những biểu diễn phân tách đó. SIG-VAE cải thiện biểu diễn bằng cách áp đặt các phân phối nhận thức cấu trúc đồ thị thay vì Gaussian độc lập, dẫn đến hiệu suất tốt hơn VGAE. DGAE tăng cường VGAE bằng cách làm sâu các lớp GCN dẫn đến kết quả tốt hơn VGAE, đặc biệt cho dữ liệu non-Euclidean.

Ngoài ra, chúng tôi thấy rằng hiệu suất trên tập dữ liệu Cora cho thấy xu hướng khác với các tập dữ liệu khác. Chúng tôi giả định rằng dữ liệu như vậy có thể được tạo ra dưới các yếu tố gần như độc lập, do đó chống lại tính hợp lệ của giả định của chúng tôi, tức là p*(X) = ∫_(Z*) p*(X|Z*)p*(Z*)dZ* với p*(Z*) ≠ ∏_i p(Z*_i), và dẫn đến hiệu suất kém.

Chúng tôi cũng thí nghiệm trên dữ liệu tổng hợp với cấu trúc nhân quả được định nghĩa trước và đạt được lợi thế như trước. Trong Hình 2(a), chúng tôi trình bày hiệu suất cho tất cả các phương pháp bằng cách thay đổi phương sai của ε trong một phạm vi lớn: từ 10 đến 300. Thú vị, chúng tôi thấy rằng hiệu suất thay đổi ít khi mức nhiễu tăng, ngụ ý rằng những phương pháp dựa trên VAE này mạnh mẽ với nhiễu vì chúng nắm bắt phương sai của phân phối tốt. Cùng nhau, tính mạnh mẽ của mô hình chúng tôi có lợi từ việc mô hình hóa nhân quả và phương sai.

### 6.2. Tác vụ 2: Dự đoán Liên kết Few Shot

Trong thí nghiệm này, chúng tôi nhằm chứng minh hiệu quả của CC-Meta-Graph được đề xuất. Vì đây là một mô hình meta-learning, nó bao gồm một giai đoạn meta-training theo sau bởi một giai đoạn testing, và mục tiêu của nó là chuyển giao kiến thức từ meta-training sang giai đoạn test. Chúng tôi sẽ điều tra hiệu suất của tất cả các phương pháp về (1) số lượng vòng lặp meta-training và (2) yêu cầu dữ liệu meta-training vì đây là chìa khóa cho hiệu suất của mô hình meta-learning.

**Baseline.** Thí nghiệm của chúng tôi bao gồm ba baseline tương ứng với các sửa đổi Meta-Graph (Bose et al., 2019), sử dụng VGAE được pre-train, CC-VGAE được pre-train, và tính ngẫu nhiên cho khởi tạo, được gọi là Meta-Graph, CC-Meta-Graph và Rand-Meta-Graph, tương ứng. Đặc biệt, hai baseline đầu tiên được pre-train trên các đồ thị đào tạo và fine-tune trên các đồ thị test.

**Tập dữ liệu.** Chúng tôi thí nghiệm trên hai tập dữ liệu benchmark (Bose et al., 2019; Zitnik & Leskovec, 2017), bao gồm protein-protein interaction (PPI) và FirstMM DB. Trong thí nghiệm này, cho tất cả tập dữ liệu, chúng tôi thực hiện dự đoán liên kết bằng meta-training trên một tập con nhỏ các cạnh và sau đó suy ra các cạnh chưa thấy. Dưới tất cả các setting, chúng tôi sử dụng 80% của những đồ thị này để pre-train trọng số và 10% như meta-validation, tối ưu hóa các tham số mô hình toàn cục, và phần còn lại cho meta-testing. Về dự đoán liên kết, chúng tôi đào tạo tất cả các phương pháp với hai setting khác nhau: 5% và 10% cạnh của đồ thị, cố gắng xem hiệu quả của việc sử dụng dữ liệu. Ngoài meta-training, chúng tôi luôn sử dụng 20% cạnh cho validation và phần còn lại cho testing.

**Kết quả chính.** Trong Bảng 3, chúng tôi trình bày hiệu suất của tất cả các phương pháp dưới các setting khác nhau. Phương pháp của chúng tôi, CC-Meta-Graph, vượt trội hơn các phương pháp khác một cách nhất quán, cung cấp cải thiện tuyệt đối lên đến 11%. Đáng chú ý, chúng ta có thể thấy rằng với 5% dữ liệu, hiệu suất của CC-Meta-Graph có tính cạnh tranh với các phương pháp khác cho 10%, gợi ý rằng mô hình của chúng tôi có thể tạo ra các biểu diễn có thể tổng quát hóa tốt hơn với ít dữ liệu hơn nhiều và phù hợp với thuộc tính nhất quán.

Chúng tôi cũng đánh giá cách mô hình của chúng tôi hoạt động dưới các epoch meta-training khác nhau, như được hiển thị trong Hình 2(b). Phương pháp của chúng tôi cho thấy hiệu suất gần tối ưu ngay cả với chỉ một vài vòng lặp trái ngược với vài chục vòng lặp cho Meta-Graph. Vì Rand-Meta-Graph truyền các giá trị ngẫu nhiên cho giai đoạn fine-tuning và do đó không thể hưởng lợi từ cơ chế meta-training, dẫn đến hiệu suất tệ nhất một cách nhất quán.

Để tóm tắt, sự vượt trội của mô hình chúng tôi xác thực hiệu quả của việc chuyển giao thông tin toàn cục sang dữ liệu mới đến, ngay cả với dữ liệu nhỏ đáng kể và chỉ một vài vòng lặp đào tạo, làm cho phương pháp được đề xuất của chúng tôi có thể áp dụng dưới ngân sách hạn chế.

### 6.3. Nghiên cứu Ablation

**Tầm quan trọng của Module.** Nhớ lại rằng, cho học biểu diễn, chúng tôi sử dụng một cấu trúc nhân quả để áp đặt phân tách, đó là Φ có cấu trúc DAG trong Eq. 5. Bằng cách đó, chúng tôi điều tra cách phương pháp của chúng tôi hoạt động mà không có ràng buộc cấu trúc nhân quả như vậy, được gọi là CCVGAE w/o CC. Trong Bảng 2, chúng tôi thấy rằng mô hình không có ràng buộc DAG, tức là CCVGAE w/o CC, giảm hiệu suất tuyệt đối 12% và 12% về AUC và AP, tương ứng. Những kết quả ablation này gợi ý sự cần thiết của cấu trúc nhân quả trong mô hình của chúng tôi.

**Sự cần thiết của L_MSE.** Chúng tôi điều tra cách phương pháp của chúng tôi hoạt động mà không có L_MSE, được gọi là CCVGAE w/o MSE. Trong bảng A.8, chúng tôi thấy CCVGAE và CCVGAE w/o MSE có hiệu suất tương tự (trong khoảng cách tuyệt đối 2%) trong Corn, Texas, Actor. Trong Cora, dRisk, Wisconsin, CCVGAE w/o MSE giảm hiệu suất tuyệt đối lên đến 5% và 7% về AUC và AP, tương ứng. Những kết quả này gợi ý rằng L_MSE có thể cải thiện hiệu suất một chút trong một số dữ liệu, nhưng không phải chính.

### 6.4. Phân tích về giảm redundancy

Chúng tôi bây giờ trình bày một góc nhìn giảm redundancy để hiểu hiệu quả của các biểu diễn phân tách của chúng tôi. Đặc biệt, chúng tôi áp dụng phân tích giá trị đơn (SVD) trên các biểu diễn thu được từ tập dữ liệu Texas và so sánh độ lớn của các eigenvalue của chúng, tức là tầm quan trọng của mỗi eigenvector. Trong Hình 2(c), chúng tôi quan sát rằng các giá trị đơn của phương pháp chúng tôi giảm chậm hơn, chứng minh rằng tầm quan trọng của những eigenvector này ít tập trung hơn. Điều này ngụ ý rằng các biểu diễn của chúng tôi ít redundant hơn, làm cho chúng biểu đạt hơn dưới các setting chiều thấp.

## 7. Kết luận

Trong bài báo này, chúng tôi cung cấp một cận trên chặt chẽ cho việc xấp xỉ giải pháp tối ưu trong khung VAE, cùng với một giải pháp thực tế, được gọi là Phân tách Nhân quả Phi-khái niệm. Sau đó chúng tôi đề xuất một VGAE tăng cường bằng một lớp phân tách nhân quả mới với ý tưởng trên, được gọi là CCVGAE. Ngoài ra, chúng tôi khám phá tính nhất quán của các khái niệm suy ra của chúng tôi, điều này thúc đẩy chúng tôi phát triển một mô hình meta-learning, được gọi là CC-Meta-Graph, nhằm chuyển giao thông tin toàn cục từ dữ liệu hạn chế sang dữ liệu mới. Kết quả thí nghiệm của chúng tôi cho thấy hiệu quả của cả hai mô hình trong tác vụ dự đoán liên kết và tác vụ few-shot.

## Tham khảo

[Tham khảo tiếng Anh được giữ nguyên]

## A. Phụ lục

### A.1. Chứng minh Định lý 4.1

Trước khi chi tiết chứng minh, chúng tôi đầu tiên giới thiệu hai bổ đề cần thiết.

**Bổ đề 1.** ∀ biến liên tục K chiều X = (X_1, ..., X_K), nếu tập hỗ trợ của mật độ xác suất kết hợp của nó là một tập lồi trong R^K, thì ∃ biến đều độc lập K chiều U = (U_1, ..., U_K) và một tập hàm F = {f_1, f_2, ..., f_K} dẫn đến X = F(U) rằng X_k = f_k(U_1, ..., U_k).

Chứng minh của Bổ đề 1 được cung cấp bởi Ping (2005). Bổ đề trên chỉ ra rằng có thể biểu diễn các quan sát liên tục với các phân phối mật độ kết hợp lồi bằng cách chiếu một danh sách các biến độc lập vào một số hàm. Chúng tôi bây giờ trình bày bổ đề sau cho thấy rằng bất kỳ biến liên tục nào đã cho có thể được liên kết với một phân phối đều.

**Bổ đề 2.** ∀ biến liên tục X, đặt hàm phân phối của nó là f(X) = P(X ≤ x), thì f(X) ~ U(0,1).

**Chứng minh.** P(f(X) ≤ a) = P(X ≤ f^(-1)(a)) = f(f^(-1)(u)) = a, trong đó a là một hằng số.

Sau đó chúng tôi chứng minh Định lý 4.1:

**Chứng minh.** Nói chung, chứng minh Định lý 4.1 tương đương với việc tìm các hàm q_i, i = 1,2, ..., K làm cho G_i = q_i(N_i^S) = Z*_i, N^S ⊆ N đúng. Chúng tôi bây giờ trình bày chứng minh trong bốn bước như sau.

**Bước 1:** Vì Bổ đề 1, chúng ta có rằng tồn tại các biến đều độc lập (U_1, ..., U_K) và hàm F làm cho Z* = F(U), trong đó:

U = (U_1, ..., U_K)     (8)
Z*_i = f_i(U_1, ..., U_i)     (9)

Đặt U_i ~ U(a_i, b_i), i = 1,2, ..., K.

**Bước 2:** Đặt có K biến normal độc lập tùy ý N_1, ..., N_K, N_i ~ N(μ_i, σ_i^2). Đặt hàm phân phối của N_i là g_i, có nghĩa là g_i(x) = P(N_i ≤ x). Ký hiệu:

g_i(N_i) = U'_i, i = 1,2, ..., K     (10)

**Bước 3:** Vì Bổ đề 2, U'_1, ..., U'_K độc lập và tất cả chúng đều là biến của phân phối đều U(0,1). Sau đó U_i trong Bước 1 có thể được biểu diễn bởi U'_i là:

U_i = (b_i - a_i)U'_i + a_i, i = 1,2, ..., K     (11)

Vì g_i(N_i) = U'_i trong (10), có nghĩa là U'_i là hàm của N_i, vì vậy chúng ta có thể ký hiệu:

(b_i - a_i)U'_i + a_i = (b_i - a_i)g_i(N_i) + a_i = h_i(N_i)     (12)

**Bước 4:** Sau đó chúng ta có thể tìm Z*_i = q_i(N_1, ..., N_i) là:

Z*_i = f_i(h_1(N_1), h_2(N_2), ..., h_i(N_i)) = q_i(N_1, ..., N_i)     (13)

Trong đó tập f_i từ phương trình 9 và h_i từ phương trình 12. Do đó, chúng ta có thể suy ra Định lý 4.1 đúng vì ∀Z* (trong phương trình p*(X) = ∫_(Z*) p*(X|Z*)p*(Z*)dZ*), ∃ một hàm Q làm cho G = Q(N^S) = {q_i(N_1, ..., N_i)}_(i=1,2,...,K) (từ phương trình (13)) bằng Z*.

### A.2. Chứng minh Mệnh đề 1

**Chứng minh.**
Gọi A là một ma trận tam giác dưới, Â được hoán vị từ A. Chúng ta có thể suy ra rằng Â * diag(N) có thể được thu được bằng ma trận như vậy với hoán đổi hàng hữu hạn:

[Ma trận hiển thị cấu trúc tam giác dưới với các phần tử A_ij N_j]

Trong đó Â = {A_ij}. Vì vậy chúng ta có thể suy ra rằng cho mỗi q_i trong Phương trình 13, phải tồn tại một hàng của Â * diag(N) bằng (a_i1 N_1, a_i2 N_2, ..., a_ii N_i), đó chính xác là q_i^(-1)(Z*_i). Vì vậy các yếu tố sinh tối ưu G = Z* có thể được biểu thị là Â * diag(N).

Bây giờ chúng tôi cung cấp một nhận xét ngụ ý rằng bất kỳ hàm Q' với hai điều kiện được đề cập được đảm bảo gặp cùng mối quan hệ ánh xạ với hàm Q thực, làm cho G' thu được bởi Q' như vậy có cùng tính chất thống kê với G thực.

**Nhận xét 1.** Xem xét một tập hàm Q' = {Q'_1, ...Q'_K} tính toán các yếu tố sinh nhân quả với công thức theo hàng là G_i = Q'_i(B_i). Giả sử B = A * diag(N') ∈ R^(K×K), cùng với các điều kiện sau:

**Điều kiện 1:** A ∈ R^(K×K) có thể được thu được bằng hoán đổi hàng hữu hạn của một ma trận tam giác dưới;

**Điều kiện 2:** N' bao gồm K biến normal độc lập là N' = (N'_1, N'_2, ..., N'_K)^T;

thì
(1) Phải tồn tại hai số thực ký hiệu là a_i và b_i, và tồn tại N_k ∈ N như trong Định lý 4.1, sao cho phương trình sau giữ: N'_i = a_i × N_k + b_i, i = 1,2, ..., K.

(2) Ký hiệu Q = {Q_1, Q_2, ..., Q_K} (trong Định lý 4.1) và Q_i^(-1)(G_i) = N_i^S ⊆ {N_1, N_2, ..., N_K}, thì cho mỗi Q_i phải tồn tại Q'_m ∈ Q' và một ma trận chéo hằng số V_i và vector hằng số M_i sao cho: Q_i^(-1)(G_i) = V_i Q'_m^(-1)(G_i) + M_i = N_i^S nếu Q_i và Q'_m có thể đảo ngược.

**Chứng minh.** Chứng minh của Nhận xét 1 tương đương với chứng minh 2 phát biểu như vậy:

(1) ∀i trong 1,2,..., K, tồn tại một ma trận chéo hằng số V_i và vector hằng số M_i rằng N'^S_i = (N'_1, N'_2, ..., N'_i) có thể được thu được bởi N^S_i = (N_1, N_2, ...N_i): N'^S_i = V_i N^S_i + M_i.

(2) Q = {q_1, q_2, ..., q_K} trong Phương trình 13 là duy nhất.

**Chứng minh phát biểu (1):**
Vì ∀hai biến normal với cùng chiều, ký hiệu N_i và N'_i, tồn tại hai hằng số v_i, m_i rằng N'_i = v_i N_i + m_i. Phát biểu (2) chỉ biểu thị N'_i = v_i N_i + m_i như vector ngẫu nhiên.

**Chứng minh phát biểu (2):**
Vì f_i và h_i là duy nhất. Vì vậy q_i là duy nhất và Q là duy nhất.

(1) trong Định lý 1 có thể được thu được bởi phát biểu (1). Vì phát biểu (2) nói với chúng ta Q là duy nhất, vì vậy chúng ta có thể suy ra bởi Mệnh đề 1 rằng Phương trình 13 cũng có thể được thu được bởi G_i = Q_i(B_i) = Q'_i(B_i) nếu N = N'. Tuy nhiên, chúng ta không thể đảm bảo N = N', vì vậy với phát biểu (2), chúng ta có thể suy ra (2) trong Định lý 1.

### A.3. Chứng minh Định lý 4.2

Trước khi chứng minh, chúng ta cần một bổ đề như sau:

**Bổ đề 3.** Ký hiệu hàm phân phối của biến normal N ~ (μ, σ^2) là F_N(x). Tồn tại một hàm tuyến tính f_L(x): (1) Làm cho lỗi tuyệt đối |F_N(x) - f_L(x)| ≤ (1/√(2π))x(1 - e^(-x^2/(2σ^2))) (2) Nếu x ∈ [μ - ε, μ + ε], thì lỗi tuyệt đối |F_N(x) - f_L(x)| ≤ (1/√(2π))ε(1 - e^(-ε^2/(2σ^2)))

**Chứng minh.** Chứng minh của (1): Không mất tính tổng quát, chúng ta xem xét μ = 0 và hàm tuyến tính là f_L(x) = (1/√(2π))x + 1/2. Chúng ta chỉ xem xét x > 0, vì cả f_L(x) và hàm phân phối đều đối xứng trung tâm về (0, 1/2), vì vậy lỗi tuyệt đối giống nhau khi x < 0.

|F_N(t) - f_L(t)|
= ((1/√(2π))t + 1/2) - ∫_{-∞}^t (1/√(2π))e^(-x^2/(2σ^2))dx
= (1/√(2π))t - ∫_0^t (1/√(2π))e^(-x^2/(2σ^2))dx
= ∫_0^t (1/√(2π))dx - ∫_0^t (1/√(2π))e^(-x^2/(2σ^2))dx
= ∫_0^t (1/√(2π))(1 - e^(-x^2/(2σ^2)))dx
≤ ∫_0^t (1/√(2π))(1 - e^(-t^2/(2σ^2)))dx
= (1/√(2π))t(1 - e^(-t^2/(2σ^2)))     (14)

**Chứng minh của (2):** Không mất tính tổng quát, chúng ta xem xét μ = 0. Vì (1/√(2π))t(1 - e^(-t^2/(2σ^2))) là một hàm tăng. Nếu t ∈ [0, ε], (1/√(2π))t(1 - e^(-t^2/(2σ^2))) ≤ (1/√(2π))ε(1 - e^(-ε^2/(2σ^2))). Tương tự đối với t ∈ [-ε, 0].

Bây giờ chúng tôi chứng minh Định lý 4.2:

**Chứng minh.** Giả sử Z*_1, Z*_2, ..., Z*_K là một phân phối đều tuyến tính có nghĩa là: P(Z*_1) ~ U(η_1 + r_10, η_1 + r_11) và P(Z*_k|Z*_1, ..., Z*_{k-1}) ~ U(η_k + r_{k0}, η_k + r_{k1}), k = 2, ..., K với η_k = Σ_{t=1}^{k-1} ω_{kt} Z*_t, và ω_{k1}, ω_{k2}, ..., ω_{k(k-1)}, r_{k0}, r_{k1} là số thực. Sau đó chúng ta có thể có được rằng phân phối có điều kiện khi Z*_k trong khoảng khác không của nó:

P(Z*_k ≤ z*_k|Z*_1 = z*_1, Z*_2 = z*_2, ..., Z*_{k-1} = z*_{k-1})
= (1/(r_{k1} - r_{k0}))(z*_k - r_{k0}) + ω_{k1}z*_1 + ... + ω_{k(k-1)}z*_{k-1}     (15)

Chúng ta có thể thấy rằng phân phối có điều kiện này là một hàm tuyến tính của (z*_1, ..., z*_k). Hơn nữa, chúng ta có thể suy ra bằng Quy nạp Toán học rằng phân phối kết hợp P(Z*_1, ..., Z*_k) = P(Z*_k|Z*_1, ..., Z*_{k-1})P(Z*_1, ..., Z*_{k-1}) là một hằng số khi (Z*_1, ..., Z*_k) trong khoảng khác không của chúng.

Chúng ta có thể tìm thấy công thức của f_i trong Bổ đề 1 trong Ping (2005) là:

f_i(x_1, x_2, ..., x_k) = (p_X(X_i ≤ x_i|X_1 = x_1, X_2 = x_2, ..., X_{i-1} = x_{i-1}))/(p_X(x_1, ..., x_{k-1}))

p_X có nghĩa là hàm mật độ xác suất của X trong Bổ đề 1, nhưng trong phương trình 9, p_X có nghĩa là hàm mật độ của Z* = {Z*_1, Z*_2, ..., Z*_K} trong tập dữ liệu thực. Vì vậy chúng ta có thể suy ra từ phương trình 15 rằng, tử số của f_i(U_1, ..., U_i) trong phương trình 9 là hàm tuyến tính của U_1, ..., U_i và mẫu số là một hằng số. Do đó, phương trình 9 là một hàm tuyến tính của U_1, ..., U_i, ký hiệu là:

f_i(U_1, ..., U_i) = ρ_{i0} + ρ_{i1}U_1 + ... + ρ_{i(i-1)}U_{i-1} + ρ_{ii}U_i     (16)

Trong phương trình 13, h_i là (b_i - a_i)g_i(N_i) + a_i, trong đó g_i là phân phối của biến normal. Không mất tính tổng quát, chúng ta đặt b_i = 1, a_i = 0, thì chúng ta có h_i = g_i, có ràng buộc lỗi tuyệt đối với một hàm tuyến tính như Bổ đề 3. Dựa trên phương trình 16 và Bổ đề 3, chúng ta có thể có được tồn tại một hàm tuyến tính f_L(N_1, N_2, ..., N_i) = Σ_{k=1}^i f_{Lk}(N_k) có ràng buộc với và giải pháp tối ưu G = Z*_i khi N_i ∈ [μ_i - δ, μ_i + δ] vì:

|f_i(h_1(N_1), h_2(N_2), ..., h_i(N_i)) - f_L(N_1, N_2, ..., N_i)|
= |ρ_{i0} + ρ_{i1}h_1(N_1) + ... + ρ_{i(i-1)}h_{i-1}(N_{i-1}) + ρ_{ii}h_i(N_i) - Σ_{k=1}^i f_{Lk}(N_k)|
≤ |Σ_{k=1}^i (ρ_{ik}h_1(N_k) - f_{Lk}(N_k))| + |ρ_{i0}|
≤ |ρ_{i0}| + (δ/√(2π)) Σ_{k=1}^i ρ_{ik}(1 - e^(-δ^2/(2σ_k^2)))
= |ρ_{i0}| + δ(Σ_{k=1}^i (ρ_{ik}/√(2π)) - Σ_{k=1}^i (ρ_{ik}/√(2π))e^(-δ^2/(2σ_k^2)))
= |ρ_{i0}| + δ(Σ_{k=1}^i (ρ_{ik}/√(2π)) - Σ_{k=1}^i (ρ_{ik}/√(2π))(e^(-1/(2σ_k^2)))^{δ^2})
= a_i + δ(b_i + Σ_{k=1}^i c_{ik}d_k^{δ^2})     (17)

### A.4. Chứng minh Mệnh đề 2

**Chứng minh.** Bây giờ chúng ta bắt đầu từ một trong các hàng trong Â * diag(N') là (a_{i1}N_1, a_{i2}N_2, a_{i3}N_3, 0, ..., 0) (để đơn giản, chúng ta ký hiệu hàng này là hàng i-th. Lưu ý rằng phải tồn tại hàng như vậy vì Â được hoán vị từ ma trận tam giác). Trong Định lý 4.2, chúng ta đã chứng minh rằng Q' có thể được triển khai như một hàm tuyến tính. Vì vậy G'_i = Q'_i(B_i) = Q'_i({Â * diag(N')}_{i}) = Q'_i(a_{i1}N_1, a_{i2}N_2, a_{i3}N_3, 0, ..., 0).

Vì vậy: Q_i(a_{i1}N_1, a_{i2}N_2, a_{i3}N_3, 0, ..., 0)
= q_{i1}a_{i1} * N_1 + q_{i2}a_{i1} * N_2 + q_{i3}a_{i1} * N_3
= (q_{i1}a_{i1}, q_{i2}a_{i2}, q_{i3}a_{i3}, 0..., 0) * (N_1, N_2, N_3, ..., N_K)^T
→ (c_{i1}, c_{i2}, c_{i3}, 0..., 0) * (N_1, N_2, N_3, ..., N_K)^T
= Ã_i * N'     (18)

Ở đây Ã_i = (c_{i1}, c_{i2}, c_{i3}, 0..., 0) và N' = (N_1, N_2, N_3, ..., N_K)^T. Chúng ta có thể áp dụng phương pháp biểu thức này cho các hàng khác. Cuối cùng, chúng ta có thể đưa ra kết luận như vậy: Ã là một ma trận với cùng vị trí khác không như Â, có nghĩa là Ã cũng là một ma trận được hoán vị từ ma trận tam giác dưới.

### A.5. Phiên bản chính thức của Định lý 4.3

Cho n quan sát {X^(1), X^(2), ..., X^(n)} được lấy mẫu từ cùng phân phối p*(X), cùng với các yếu tố sinh tối ưu tương ứng của chúng {Z^(1), Z^(2), ..., Z^(n)}, một hàm Z̄^(n) với những yếu tố sinh này sẽ hội tụ về cùng khái niệm ground truth (GT) Z̈ khi lim_{n→∞} Z̄^(n) = Z̈, trong đó Z̄^(n) = (Z^(1) + Z^(2) + ... + Z^(n))/n.

**Chứng minh.** Kết luận có thể dễ dàng được suy ra từ luật số lớn.

### A.6. Chứng minh (I - Φ^T)^(-1)

Trước khi chứng minh, chúng ta cần một bổ đề:

**Bổ đề 4.** Nếu D là ma trận kề của DAG với vector nút Z, có nghĩa là Z = DZ. Thì tồn tại một ma trận tam giác dưới T và một vector Z' được thu được bằng hoán đổi hàng hữu hạn của Z, làm cho Z' = TZ'.

**Chứng minh.** Trong một DAG, phải tồn tại ít nhất một nút với bậc vào 0. Chúng ta có thể loại bỏ tùy ý một nút với bậc vào 0, và làm cho nút này trở thành nút đầu tiên trong Z'. Vì đồ thị không có nút này cũng là một DAG, vì vậy chúng ta cũng có thể tìm ít nhất một nút với bậc vào 0, và làm cho nút thứ hai trong Z'. Vì bậc vào của nút thứ hai là 0 trong đồ thị không có nút đầu tiên, vì vậy dòng đầu tiên của T có nhiều nhất 1 phần tử khác không.

Lặp lại quá trình này và chúng ta có thể tìm T và Z' như vậy.

Để chứng minh (I - Φ^T)^(-1) có thể được thu được bởi một ma trận tam giác dưới với hoán đổi hàng hữu hạn, chúng ta cần chứng minh: Tồn tại một ma trận tam giác dưới L và một ma trận đơn vị P_{K×K} được thu được bởi ma trận đơn vị với hoán đổi hàng hữu hạn, làm cho G^T = (I - Φ^T)^(-1)ε^T = PLε^T, Φ là ma trận kề DAG với vector nút G^T.

Bây giờ chúng ta có chứng minh như vậy:

**Chứng minh.** Với Bổ đề 4, chúng ta có thể suy ra rằng tồn tại một ma trận tam giác dưới T và một vector G^T_R được thu được bằng hoán đổi hàng hữu hạn của G^T, làm cho G^T_R = TG^T_R + ε → G^T_R = (I - T)^(-1)ε^T.

Vì G^T_R được thu được bằng hoán đổi hàng hữu hạn của G^T, chúng ta có thể ký hiệu G^T_R = P'G^T, P' được thu được bởi ma trận đơn vị với hoán đổi hàng hữu hạn. Vì vậy chúng ta có P'G^T = (I - T)^(-1)ε^T → G^T = P'^(-1)(I - T)^(-1)ε^T. Gọi P = P'^(-1), L = (I - T)^(-1), thì chúng ta có G^T = PLε^T.

### A.7. Thuật toán của CCVGAE và Causal-Meta-Graph cho Dự đoán Liên kết Few Shot

**Thuật toán 1:** Concept-free Causal-Meta-Graph cho Dự đoán Liên kết Few Shot

**Kết quả:** Tham số GNN toàn cục ϕ, Hàm chữ ký đồ thị ψ, Tham số lớp nhân quả toàn cục C

Khởi tạo tốc độ học: α, β, γ;
Lấy mẫu một mini-batch đồ thị, G_{batch} từ p(G)

**cho mỗi** G ∈ G_{batch} **do**
    ε = ε_{train} ∪ ε_{val} ∪ ε_{test} // Chia cạnh thành train, val, và test;;
    s_G = ψ(G, ε_{train}) // Tính chữ ký đồ thị;
    Khởi tạo: ϕ^(0) ← ϕ // Khởi tạo tham số local qua tham số toàn cục
    
    **cho** k trong [1 : K] **do**
        s_G = stopgrad(s_G) // Dừng Gradients cho Graph Signature;
        Z = (I - C^T)^(-1)s_G // Tính biểu diễn ẩn;
        L_{train} = -ELBO_{train} + αH(C);
        Cập nhật ϕ^(k) ← ϕ^(k-1) - β∇_ϕL_{train}
    **end**
    
    Khởi tạo: ϕ ← ϕ_K;
    s_G = ψ(G, ε_{val} ∪ ε_{train}) // Tính chữ ký đồ thị với cạnh validation;
    L_{val} = -ELBO_{val} + αH(C);
    Cập nhật ϕ ← ϕ - γ∇_ϕL_{val};
    Cập nhật ψ ← ψ - γ∇_ψL_{val};
    Cập nhật C ← C - γ∇_CL_{val}
**end**

**Thuật toán 2:** CCVGAE

**Đầu vào:** Cạnh đồ thị E, đặc trưng nút X, α, β

Khởi tạo tham số GCN GCN_μ, GCN_σ, ma trận nhân quả Φ;
E = E_{train} ∪ E_{val} ∪ E_{test} // Chia cạnh thành train, val, và test;
A = A_{train} + A_{val} + A_{test} // Tạo ma trận kề train, valid, test

**cho** epoch trong [1 : số epoch] **do**
    μ = GCN_μ(A_{train}, X) // Tính mean của ε;
    σ = GCN_σ(A_{train}, X) // Tính variance của ε;
    ε = N(μ, σ) // Tạo ε như phân phối normal độc lập;
    G = (I - C^T)^(-1)ε // Tính các yếu tố sinh;
    Â_{train} = σ_1(G_i^T Ĝ_j) // Tái tạo ma trận kề;
    X̂ = σ_2(G) // Tái tạo đặc trưng nút;
    L_{train} = -L_G + αL_Φ + βL_{MSE};
    Cập nhật GCN_μ, GCN_σ, Φ
**end**

Tính ROC(A_{test}, Â_{test}) và AP(A_{test}, Â_{test})

### A.8. Kết quả nghiên cứu ablation

**Bảng 4.** Điểm AUC (%) và AP (%) cho CCVGAE w/o MSE và CCVGAE trên các tập dữ liệu thế giới thực.

| Dataset   | CCVGAE w/o MSE |       | CCVGAE        |       |
|-----------|----------------|-------|---------------|-------|
|           | AUC            | AP    | AUC           | AP    |
| Cora      | 0.80±0.02      | 0.82±0.03 | 0.85±0.03 | 0.85±0.05 |
| Corn      | 0.73±0.03      | 0.79±0.06 | 0.74±0.06 | 0.78±0.04 |
| Texas     | 0.76±0.04      | 0.78±0.03 | 0.75±0.07 | 0.80±0.07 |
| Wisconsin | 0.72±0.07      | 0.77±0.06 | 0.75±0.04 | 0.79±0.05 |
| dRisk     | 0.71±0.05      | 0.65±0.07 | 0.75±0.06 | 0.72±0.05 |
| Actor     | 0.79±0.04      | 0.81±0.03 | 0.78±0.07 | 0.81±0.06 |

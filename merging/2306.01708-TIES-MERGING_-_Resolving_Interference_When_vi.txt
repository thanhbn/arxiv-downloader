# 2306.01708.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/merging/2306.01708.pdf
# Kích thước tệp: 1179222 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
TIES-MERGING : Giải quyết Can thiệp Khi
Hợp nhất Các Mô hình
Prateek Yadav1Derek Tam1
Leshem Choshen2,3Colin Raffel1Mohit Bansal1
1University of North Carolina at Chapel Hill2IBM Research3MIT
leshem.choshen@ibm.com
{praty,dtredsox,craffel,mbansal}@cs.unc.edu
Tóm tắt
Học chuyển giao – tức là tiếp tục tinh chỉnh một mô hình đã được huấn luyện trước trên một
nhiệm vụ xuôi dòng – có thể mang lại những lợi thế đáng kể, bao gồm cải thiện hiệu suất xuôi
dòng, hội tụ nhanh hơn và hiệu quả mẫu tốt hơn. Những lợi thế này đã dẫn đến sự gia tăng của
các mô hình tinh chỉnh đặc trung cho từng nhiệm vụ, thường chỉ có thể thực hiện một nhiệm vụ
duy nhất và không được hưởng lợi từ nhau. Gần đây, các kỹ thuật hợp nhất mô hình đã xuất hiện
như một giải pháp để kết hợp nhiều mô hình đặc trung cho từng nhiệm vụ thành một mô hình đa
nhiệm vụ duy nhất mà không cần thực hiện huấn luyện bổ sung. Tuy nhiên, các phương pháp hợp
nhất hiện có thường bỏ qua sự can thiệp giữa các tham số của các mô hình khác nhau, dẫn đến
sụt giảm hiệu suất lớn khi hợp nhất nhiều mô hình. Trong bài báo này, chúng tôi chứng minh rằng
các kỹ thuật hợp nhất trước đây vô tình mất thông tin có giá trị do hai nguồn can thiệp chính:
(a) can thiệp do các giá trị tham số dư thừa và (b) sự bất đồng về dấu của giá trị tham số nhất
định giữa các mô hình. Để giải quyết điều này, chúng tôi đề xuất phương pháp của mình,
TRIM, ELECT SIGN& M ERGE (TIES-MERGING ), giới thiệu ba bước mới khi hợp nhất các
mô hình: (1) đặt lại các tham số chỉ thay đổi một lượng nhỏ trong quá trình tinh chỉnh, (2) giải
quyết xung đột dấu, và (3) chỉ hợp nhất các tham số phù hợp với dấu cuối cùng đã được thống
nhất. Chúng tôi thấy rằng TIES-MERGING vượt trội hơn một số phương pháp hiện có trong
các cài đặt đa dạng bao gồm một loạt các phương thức, miền, số lượng nhiệm vụ, kích thước mô
hình, kiến trúc và cài đặt tinh chỉnh. Chúng tôi tiếp tục phân tích tác động của các loại can thiệp
khác nhau đối với các tham số mô hình, và làm nổi bật tầm quan trọng của việc giải quyết can
thiệp dấu.1
1 Giới thiệu
Các mô hình đã được huấn luyện trước (PTM) đã trở nên phổ biến trong nhiều ứng dụng thực tế [91,6]. Việc
sử dụng PTM thường liên quan đến tinh chỉnh chúng để chuyên biệt hóa cho một nhiệm vụ cụ thể [69,12], có
thể dẫn đến cải thiện hiệu suất với ít dữ liệu được gán nhãn đặc trung cho từng nhiệm vụ hơn. Những lợi ích
này đã dẫn đến việc phát hành hàng ngàn checkpoint đã được tinh chỉnh [81] bắt nguồn từ các PTM phổ biến
như ViT [14] cho thị giác và T5 [58] cho ngôn ngữ. Tuy nhiên, việc có một mô hình tinh chỉnh riêng biệt cho
mỗi nhiệm vụ có nhiều nhược điểm: (1) đối với mỗi ứng dụng mới, một mô hình riêng biệt phải được lưu trữ
và triển khai [17,89], và (2) các mô hình được huấn luyện riêng lẻ không thể tận dụng thông tin từ các nhiệm
vụ liên quan để cải thiện hiệu suất trong miền hoặc tổng quát hóa ngoài miền [66,58,75]. Học đa nhiệm vụ
[66,57] có thể giải quyết những lo ngại này nhưng đòi hỏi huấn luyện tốn kém và truy cập đồng thời vào tất
cả các nhiệm vụ [17]. Hơn nữa, có thể phức tạp và tốn nhiều tài nguyên để xác định cách tốt nhất để trộn
các tập dữ liệu để đảm bảo rằng huấn luyện đa nhiệm vụ có lợi cho tất cả các nhiệm vụ [55, 54, 80, 52, 2, 17].
1Mã của chúng tôi có sẵn tại https://github.com/prateeky2806/ties-merging
37th Conference on Neural Information Processing Systems (NeurIPS 2023).arXiv:2306.01708v2  [cs.LG]  27 Oct 2023

--- TRANG 2 ---
Vector Nhiệm vụ  Vector Nhiệm vụ Đã cắt tỉa  
(1) Cắt tỉa
(2) Bầu chọn DấuCác Giá trị Căn chỉnh
Vector Dấu 
Vector Nhiệm vụ
Đã hợp nhất (3) Hợp nhất Rời rạc: Giá trị có ảnh hưởng
: Giá trị dư thừa: Tham số: Mô hình 1
: Mô hình 2: Mô hình 3
: Mô hình Đã hợp nhấtHình 1: Mô tả các bước liên quan trong TIES-MERGING. Chúng tôi hình dung mỗi tham số
trong một mô hình như một hình vuông. Các mũi tên mô tả việc cập nhật (vector nhiệm vụ, τ) đối với một
tham số được tạo ra bởi tinh chỉnh trên các nhiệm vụ khác nhau (được mã hóa bằng màu sắc), với hướng
biểu thị dấu và độ dài biểu thị độ lớn. Trước tiên chúng tôi cắt tỉa các giá trị vector nhiệm vụ dựa trên độ
lớn của chúng, sau đó chúng tôi bầu chọn dấu cho mỗi tham số (γm, vector xanh lá chứa +1 hoặc −1) bằng
cách giải quyết xung đột dấu. Cuối cùng, chúng tôi chọn chỉ những giá trị phù hợp với dấu đã được bầu
chọn và lấy trung bình của chúng làm giá trị tham số cuối cùng.

Gần đây, một ngành nghiên cứu đang phát triển đã tập trung vào hợp nhất mô hình [40]. Một ứng dụng của
hợp nhất bao gồm việc kết hợp nhiều mô hình đặc trung cho từng nhiệm vụ thành một mô hình đa nhiệm vụ
duy nhất mà không cần thực hiện huấn luyện bổ sung. Các công trình trước đây hợp nhất các mô hình bằng
cách tổng các trọng số mô hình riêng lẻ với các sơ đồ trọng số khác nhau, hoặc thông qua trung bình đơn
giản [9,28,83], thông qua các phương tiện tinh vi hơn kết hợp tầm quan trọng tham số [45] hoặc tính đến sự
bất biến hoán vị [1,31,70,74,42]. Việc kết hợp các mô hình tinh chỉnh theo cách này có thể được xem như
việc cộng các vector nhiệm vụ [29] được tính bằng cách trừ các giá trị tham số của mô hình đã được huấn
luyện trước từ những giá trị của mô hình tinh chỉnh.

Giá trị Gốc
 Không Can thiệp  Dư thừa  Xung đột Dấu Trung bình TIESGiá trị Đã hợp nhất
Mô hình 1 Mô hình 2
Hình 2: Các loại xung đột khác nhau và
đầu ra hợp nhất được tạo ra bởi việc lấy
trung bình hoặc TIES-MERGING. Các tham
số gây can thiệp được biểu thị bằng mũi tên
chấm.Trong khi việc lấy trung bình có trọng số của các tham số
mô hình đã được chứng minh hiệu quả cho việc hợp
nhất, tất cả các phương pháp này đều bỏ qua khả năng
mà các giá trị có thể can thiệp lẫn nhau giữa các mô
hình, do đó làm hại hiệu suất của mô hình đã hợp nhất.
Trong bài báo này, trước tiên chúng tôi chứng minh rằng
can thiệp có thể bắt nguồn từ hai nguyên nhân chính (xem
Hình 2), cả hai đều có thể làm giảm độ lớn tham số trong
mô hình đã hợp nhất và loại bỏ sự khác biệt tinh tế giữa
các giá trị: (1) CAN THIỆP TỪ CÁC THAM SỐ DƯ
THỪA: Các nghiên cứu trước đây về cắt tỉa mô hình
[25,76] đã chỉ ra rằng trong quá trình tinh chỉnh, nhiều
tham số mô hình có thể thay đổi trong suốt quá trình tinh
chỉnh [63] nhưng chỉ có tác động nhỏ đến hiệu suất. Tuy
nhiên, khi hợp nhất một tham số có ảnh hưởng đối với một
mô hình nhưng dư thừa (tức là không có ảnh hưởng) đối
với các mô hình khác, giá trị có ảnh hưởng có thể bị che
lấp bởi các giá trị dư thừa, làm giảm hiệu suất tổng thể
của mô hình (# trong Hình 2). (2) CAN THIỆP TỪ SỰ BẤT ĐỒNG DẤU: Một tham số nhất định có thể
có giá trị dương cho một số mô hình và giá trị âm cho những mô hình khác. Do đó, việc sử dụng trung bình
đơn giản có thể làm tổn hại hiệu suất trên cả hai nhiệm vụ (7 trong Hình 2). Trong cả hai tình huống này,
việc chỉ tổng hợp các giá trị dẫn đến can thiệp làm co hẹp giá trị của tham số trong mô hình đã hợp nhất.
Sự can thiệp này giữa các tham số có ảnh hưởng có thể giải thích tại sao khoảng cách hiệu suất giữa mô hình
đã hợp nhất và mô hình được huấn luyện đa nhiệm vụ tăng lên khi số lượng mô hình tăng [31].

Để giải quyết những nguồn can thiệp này, chúng tôi đề xuất phương pháp TIES-MERGING (TRIM,
ELECT SIGN & MERGE), một phương pháp hợp nhất các mô hình bằng cách kết hợp các vector nhiệm vụ
có ba bước (được minh họa trong Hình 1): Đầu tiên, chúng tôi cắt tỉa mỗi vector nhiệm vụ để chỉ giữ lại
các giá trị tham số có ảnh hưởng bằng cách đặt các giá trị dư thừa trong mỗi vector nhiệm vụ về 0 (hoặc
tương đương, đặt lại giá trị tham số tinh chỉnh về giá trị từ mô hình đã được huấn luyện trước). Sau bước
này, xung đột dấu vẫn có thể tồn tại giữa các giá trị tham số có ảnh hưởng, như được minh họa trong Hình
4. Do đó bước thứ hai của chúng tôi giải quyết xung đột dấu giữa các giá trị khác nhau và bước cuối cùng
của chúng tôi chỉ tính trung bình các tham số có dấu phù hợp với hướng di chuyển tổng lớn nhất giữa các
mô hình.

--- TRANG 3 ---
Chúng tôi chứng minh tính hiệu quả của phương pháp TIES-MERGING đề xuất trong các thiết lập khác nhau
với: (1) các phương thức khác nhau, bao gồm các điểm chuẩn ngôn ngữ và thị giác, (2) kích thước và họ mô
hình riêng biệt, như T5-base và T5-large [58] cũng như ViT-B/32 và ViT-L/14 [14], (3) các nhiệm vụ trong
miền và ngoài miền, (4) tinh chỉnh đầy đủ hoặc tinh chỉnh hiệu quả tham số, và (5) trong sự hiện diện hoặc
vắng mặt của một tập xác thực để thiết lập các siêu tham số hợp nhất. Chúng tôi chỉ ra rằng TIES-MERGING
vượt trội hơn các phương pháp hợp nhất khác, như Task Arithmetic [29], RegMean [31], Fisher Merging
[45], và trung bình trọng số [9,82] trong tất cả các cài đặt thực nghiệm này. Đáng chú ý, đối với đánh giá
trong miền, TIES-MERGING vượt trội hơn đường cơ sở mạnh nhất trung bình 2.3% và 1.7% tuyệt đối trong
cài đặt NLP và thị giác (Bảng 1), tương ứng. Đối với tổng quát hóa ngoài miền (Bảng 2), TIES-MERGING
vượt trội hơn đường cơ sở mạnh nhất 1.0% và 4.4% tuyệt đối cho các mô hình T5-base và T5-large tương
ứng. Trong Phần 7, chúng tôi thực hiện các nghiên cứu loại bỏ về các thành phần phương pháp của chúng tôi
và chứng minh tác động của các loại can thiệp khác nhau đối với các giá trị tham số. Ngoài ra, chúng tôi
thể hiện lợi thế gia tăng của TIES-MERGING so với task arithmetic [29] khi số lượng nhiệm vụ tăng. Cuối
cùng, chúng tôi xem xét tầm quan trọng của việc có được vector dấu chính xác. Kết quả và phân tích của
chúng tôi thiết lập TIES-MERGING như một phương pháp mạnh mẽ và hiệu quả để kết hợp các mô hình tinh
chỉnh thành một mô hình đa nhiệm vụ duy nhất.

2 Công việc liên quan
Cảnh quan Mất mát và Nội suy Trọng số. Mặc dù hàm mất mát của một mạng nơ-ron thường không lồi,
nghiên cứu gần đây đã chứng minh rằng các giá trị tham số từ các lần chạy huấn luyện khác nhau đôi khi có
thể được nội suy mà không làm tăng mất mát (tức là chúng được kết nối chế độ) [15, 20,21,32,22]. Ví dụ,
Frankle et al. [19] chỉ ra rằng nếu một phần của quỹ đạo tối ưu hóa được chia sẻ giữa hai mạng nơ-ron
thì chúng có thể được nội suy mà không làm giảm độ chính xác. Mặt khác, Neyshabur et al. [48] chỉ ra rằng
việc nội suy ngây thơ hai mạng nơ-ron với các quỹ đạo tối ưu hóa hoàn toàn rời rạc có thể dẫn đến sự sụt
giảm thảm khốc về độ chính xác của chúng. Entezari et al. [16] đưa ra giả thuyết rằng nếu chúng ta tính đến
tính đối xứng hoán vị của mạng nơ-ron, thì tất cả các mạng nơ-ron của một kiến trúc nhất định được huấn
luyện trên cùng một tập dữ liệu đều được kết nối chế độ tuyến tính. Do đó, Ainsworth et al. [1], Singh và
Jaggi [70], Wang et al. [79] đã sử dụng các kỹ thuật dựa trên việc tìm kiếm hoán vị [79,1] và vận chuyển tối
ưu [70] để căn chỉnh tốt hơn các mạng nơ-ron được huấn luyện từ đầu để chúng có thể được nội suy mà
không làm tăng mất mát.

Hợp nhất Mô hình và Các Trường hợp Sử dụng Khác nhau. Các mô hình tinh chỉnh khác nhau được khởi
tạo từ cùng một mô hình đã được huấn luyện trước hiệu quả chia sẻ một phần của quỹ đạo tối ưu hóa, và do
đó thường có thể được hợp nhất mà không cần tính đến tính đối xứng hoán vị [82,83,29,31]. Do đó, việc hợp
nhất các mô hình tinh chỉnh có thể cải thiện hiệu suất trên một nhiệm vụ mục tiêu duy nhất [30,23,82,9],
cải thiện tổng quát hóa ngoài miền [31,29,7,4,60,59], tạo ra các mô hình đa nhiệm vụ từ các nhiệm vụ khác
nhau [31,29,38], cho học liên kết [46,41], nén [39], hợp nhất mô hình đa phương thức [72], học liên tục
[86,85], và các cài đặt khác [38,13]. Phạm vi ứng dụng đã dẫn đến sự gia tăng của các phương pháp để cải
thiện vượt qua việc lấy trung bình tham số đơn giản. RegMean [31] đề xuất một giải pháp dạng đóng cho
các tham số của mô hình đã hợp nhất bằng cách giải quyết một bài toán hồi quy tuyến tính cục bộ cho mỗi
lớp tuyến tính riêng lẻ trong mô hình. Tuy nhiên, điều này đòi hỏi truyền các thống kê dữ liệu bổ sung có
cùng kích thước với mô hình và đòi hỏi các bước suy luận bổ sung để tính toán chúng. Fisher Merging [45]
vượt qua việc lấy trung bình đơn giản để xác định tầm quan trọng của các tham số riêng lẻ bằng cách sử dụng
Ma trận Thông tin Fisher [18,3,34] và sử dụng nó để cân nhắc các tham số trong mỗi mô hình khi hợp nhất.
Tuy nhiên, điều này cho thấy ít lợi ích khi hợp nhất nhiều checkpoint và cũng đòi hỏi tính toán gradient có
chi phí bộ nhớ cao. Task Arithmetic [29] trình bày một phương pháp hợp nhất các mô hình bằng cách tạo ra
các vector nhiệm vụ và thực hiện các phép toán số học, như phép cộng, để có được một checkpoint đa nhiệm
vụ. Một công trình đồng thời của Ortiz-Jiménez et al. [51] đã cung cấp hiểu biết lý thuyết về hợp nhất mô
hình dựa trên thuộc tính tách biệt trọng số xuất hiện trong quá trình huấn luyện trước. Họ chỉ ra rằng việc
tinh chỉnh các mô hình trong không gian tiếp tuyến của chúng tăng cường thuộc tính này, dẫn đến các mô
hình hợp nhất tốt hơn. Phương pháp của chúng tôi tuân theo những công trình trước đây về hợp nhất mô
hình nhưng bổ sung tính đến sự can thiệp giữa các tham số khác nhau trong quá trình hợp nhất.
3

--- TRANG 4 ---
0 20 40 60 80 1005560657075
Giữ Top-K% Tham sốHiệu suất Trung bìnhHình 3: Hiệu suất phụ thuộc vào một phần
nhỏ các tham số có độ lớn cao. Đối với mỗi
vector nhiệm vụ, chúng tôi chỉ giữ lại những
tham số lớn nhất - top-k% và vẽ biểu đồ hiệu
suất trung bình trên mười một nhiệm vụ. Chỉ
giữ top-20% tham số không làm giảm hiệu suất.

2 3 4 5 6 7 8 9 10 1100.10.20.3
Số lượng Mô hìnhTỷ lệ Tham số 
 với Xung đột

Hình 4: Xung đột dấu xảy ra ngay cả sau khi
cắt tỉa và tăng theo số lượng mô hình. Chúng
tôi vẽ biểu đồ tỷ lệ các tham số có xung đột
dấu sau khi cắt tỉa so với số lượng mô hình
được hợp nhất.

3 Bối cảnh và Động lực
Thiết lập Bài toán Cho một tập các nhiệm vụ {t1, . . . , tn} và một mô hình đã được huấn luyện trước như
T5 [58] hoặc ViT [14], chúng tôi hoặc tinh chỉnh toàn bộ mô hình hoặc sử dụng một phương pháp tinh chỉnh
hiệu quả tham số (PEFT) [43,26]. Trong cả hai trường hợp, chúng tôi ký hiệu các tham số có thể huấn luyện
là θ, khởi tạo là θinit, và các tham số được tinh chỉnh là θft. Trong bài báo này, chúng tôi giả định có quyền
truy cập vào các tham số mô hình tinh chỉnh θft cho nhiều nhiệm vụ và đề ra một phương pháp để hợp nhất
các trọng số của những mô hình này thành một mô hình đa nhiệm vụ duy nhất thành thạo cả trên các tập dữ
liệu trong miền và ngoài miền. Chúng tôi tuân theo Ilharco et al. [29] và thực hiện hợp nhất với các vector
nhiệm vụ. Cụ thể, đối với một nhiệm vụ t, vector nhiệm vụ τt ∈ Rd được định nghĩa là τt = θtft − θtinit.
Phép toán này cho phép chúng tôi tập trung vào những thay đổi xảy ra trong giai đoạn tinh chỉnh của mỗi
mô hình đặc trung cho từng nhiệm vụ và tương đương với việc tính toán trung bình có trọng số của các trọng
số mô hình với tỷ lệ thích hợp.

Thuật toán 1 Quy trình TIES-MERGING.
Đầu vào: Các mô hình tinh chỉnh {θt}nt=1, Khởi tạo θinit,
k, và λ.
Đầu ra: Mô hình Đã hợp nhất θm
forall t trong 1, ..., n do
▷Tạo vector nhiệm vụ.
τt = θt − θinit
▷Bước 1: Cắt tỉa tham số dư thừa.
ˆτt ← keep_topk_reset_rest_to_zero (τt, k)
ˆγt ← sgn( ˆτt)
ˆµt ← |ˆτt|
end
▷Bước 2: Bầu chọn Dấu Cuối cùng.
γm = sgn(∑nt=1 ˆτt)
▷Bước 3: Hợp nhất Rời rạc.
forall p trong 1, ..., d do
Ap = {t ∈ [n]|ˆγpt = γpm}
τpm = 1|Ap| ∑t∈Ap ˆτpt
end
▷Có được checkpoint đã hợp nhất
θm ← θinit + λ ∗ τm
return θm

Sự Dư thừa trong Tham số Mô hình.
Đầu tiên, chúng tôi chứng minh rằng trong một
vector nhiệm vụ nhất định, nhiều giá trị là dư
thừa (được ký hiệu bằng # trong Hình 2), và
việc loại bỏ chúng không ảnh hưởng đến hiệu
suất của nhiệm vụ. Cụ thể, Hình 3 cho thấy hiệu
suất trung bình trên mười một mô hình đặc
trưng cho từng nhiệm vụ khi "cắt tỉa" mỗi vector
nhiệm vụ để chỉ giữ lại top-k% giá trị có độ lớn
lớn nhất và đặt lại phần còn lại về giá trị ban
đầu của chúng (tức là đặt giá trị tương ứng trong
vector nhiệm vụ về 0). Hình 3 cho thấy hiệu
suất trung bình trên các giá trị k khác nhau,
chứng minh rằng chỉ giữ top-20% giá trị mang
lại kết quả tương đương với việc giữ lại tất cả
các tham số. Để biết thêm chi tiết và kết quả
trên mô hình T5, vui lòng tham khảo Phụ lục
C.3. Điều này cho thấy rằng nhiều thay đổi tham
số được giới thiệu trong quá trình tinh chỉnh
là dư thừa. Do đó, việc bỏ qua những giá trị đó
trong quá trình hợp nhất có thể ngăn chặn sự
can thiệp với các tham số có ảnh hưởng mà
không làm tổn hại hiệu suất của nhiệm vụ.

Sự Bất đồng giữa Dấu Tham số: Các mô hình tinh chỉnh khác nhau có thể đưa ra những thay đổi đối lập
đối với một tham số trong vector nhiệm vụ của chúng, gây ra can thiệp do dấu xung đột (được ký hiệu bằng
7 trong Hình 2). Hình 4 trình bày phân tích về tần suất xung đột dấu khi hợp nhất số lượng mô hình khác
nhau. Trước tiên chúng tôi cắt tỉa các vector nhiệm vụ cho mười một nhiệm vụ bằng cách chỉ giữ top 20%
tham số có ảnh hưởng. Sau đó, chúng tôi vẽ biểu đồ tỷ lệ phần trăm các tham số có xung đột dấu khi chúng
tôi

--- TRANG 5 ---
tăng số lượng mô hình được hợp nhất từ 2 lên 11. Đáng chú ý, xung đột dấu xảy ra ngay cả khi chỉ hợp nhất
2 mô hình từ các nhiệm vụ khác nhau hoặc khi hợp nhất nhiều mô hình từ cùng một nhiệm vụ (xem Hình 10
Phụ lục), và khả năng xung đột dấu tăng theo số lượng mô hình được hợp nhất. Để biết thêm chi tiết và kết
quả trên mô hình T5, vui lòng tham khảo Phụ lục C.3.

4 TIES-MERGING: TRIM, ELECT SIGN & MERGE
Để giải quyết những vấn đề nêu trên, chúng tôi trình bày TIES-MERGING (TRIM, ELECT SIGN& MERGE),
nhằm giải quyết các loại can thiệp được đề cập ở trên trước khi thực hiện hợp nhất.

4.1 Kiến thức Cơ bản
Một vector nhiệm vụ τt ∈ Rd đại diện cho một hướng và lượng di chuyển cần thiết trong không gian tham
số d chiều so với khởi tạo dẫn đến vùng mất mát thấp cho nhiệm vụ t. Mỗi mục trong τt (tương ứng với
một tham số cụ thể) có thể được coi như một trục trong không gian d chiều. Dấu của một tham số biểu thị
hướng dọc theo trục này (dương hoặc âm) làm giảm mất mát trên nhiệm vụ t. Do đó, một vector nhiệm vụ
τt nhất định có thể được phân tách thành một vector dấu γt ∈ Rd và một vector độ lớn µt ∈ Rd là τt = γt ⊙
µt, trong đó ⊙ là tích theo từng phần tử. Chính thức, γt = sgn(τt), trong đó sgn(x) ∗ |x| = x và trả về giá
trị +1, 0, hoặc −1. Vector độ lớn µt được định nghĩa là µt = |τt| và giá trị µit cho chúng ta biết chuyển động
cần thiết trong chiều thứ i từ khởi tạo.

4.2 Các Bước trong TIES-MERGING
Để hợp nhất nhiều mô hình đặc trưng cho từng nhiệm vụ {θt}nt=1, trước tiên chúng tôi tạo các vector nhiệm
vụ tương ứng {τt}nt=1. Với những vector nhiệm vụ này, phương pháp TIES-MERGING tuân theo ba bước
để thực hiện hợp nhất (xem Hình 1 cho sơ đồ và Thuật toán 1):

1. Cắt tỉa: Đối với mỗi nhiệm vụ t, chúng tôi cắt tỉa các tham số dư thừa từ vector nhiệm vụ τt để tạo ˆτt
bằng cách giữ top-k% giá trị theo độ lớn của chúng và cắt tỉa (100−k)% dưới của các tham số dư thừa
bằng cách đặt lại chúng về 0. Điều này có thể được phân tách thêm là ˆτt = ˆγt ⊙ ˆµt.

2. Bầu chọn: Tiếp theo, chúng tôi tạo một vector dấu được bầu chọn tổng hợp γm cho mô hình đã hợp nhất
giải quyết sự bất đồng về dấu cho mỗi tham số p giữa các mô hình khác nhau. Để tạo vector dấu được
bầu chọn, chúng tôi chọn dấu có tổng độ lớn cao nhất trên tất cả các mô hình liên quan. Đối với mỗi
tham số p ∈ {1, 2, . . . , d}, chúng tôi tách các giá trị {ˆτpt}nt=1 dựa trên dấu của chúng (+1 hoặc −1) và
lấy tổng để tính toán tổng khối lượng (tức là tổng độ lớn) theo hướng dương và âm. Sau đó chúng tôi
gán γpm là dấu có chuyển động tổng lớn hơn. Điều này có thể được tính toán hiệu quả bằng cách sử dụng
γpm = sgn(∑nt=1 ˆτpt).

3. Hợp nhất Rời rạc: Sau đó, đối với mỗi tham số p, chúng tôi tính toán trung bình rời rạc bằng cách chỉ
giữ các giá trị tham số từ các mô hình có dấu giống như dấu được bầu chọn tổng hợp và tính toán trung
bình của chúng. Chính thức, đặt Ap = {t ∈ [n]|ˆγpt = γpm}, thì τpm = 1|Ap| ∑t∈Ap ˆτpt. Lưu ý rằng
trung bình rời rạc luôn bỏ qua các giá trị bằng không.

Với vector nhiệm vụ hợp nhất cuối cùng τm, chúng tôi tỷ lệ nó và thêm vào các giá trị tham số ban đầu để
có được các tham số mô hình đã hợp nhất θm là θm = θinit + λ ∗ τm, trong đó λ là một siêu tham số tỷ lệ
(như được sử dụng trong công trình trước [29]).

5 Thiết lập Thí nghiệm
Phương pháp Cơ sở. Chúng tôi so sánh TIES-MERGING với bốn phương pháp hợp nhất cơ sở: (1) Lấy
trung bình Đơn giản [9,82] tính toán trung bình theo từng phần tử của tất cả các mô hình riêng lẻ và có thể
được biểu thị là θm = ∑nt=1 θt/n. (2) Fisher Merging [45] sử dụng xấp xỉ đường chéo của Ma trận Thông
tin Fisher ˆFt [34,3,18] để đo tầm quan trọng của mỗi tham số cho nhiệm vụ t, trong đó ˆFt = Ex∼DtEy∼pθt(y|x)[∇θt(log pθt(y|xt))]2. Mô hình hợp nhất cuối cùng được có được bằng cách cân nhắc lại mỗi tham số trong
mỗi mô hình tinh chỉnh bằng giá trị tương ứng trong ma trận Fisher xấp xỉ của mô hình là θm = ∑nt=1 ˆFtθt/∑nt=1 ˆFt. (3) RegMean [31] tính toán giải pháp dạng đóng cho

--- TRANG 6 ---
Phương pháp (↓) Xác thực PEFT Tinh chỉnh Đầy đủ
Mô hình (→) (IA)3 T5-Base T5-Large ViT-B/32 ViT-L/14
TINH CHỈNH - 71.4 82.8 88.8 90.5 94.2
ĐA NHIỆM VỤ - 73.1 83.6 88.1 88.9 93.5
LẤY TRUNG BÌNH [82, 9] ✗ - 65.9 59.6 65.8 79.6
TASK ARITHMETIC [29] ✗ - 73.2 73.5 60.4 83.3
TIES-MERGING ✗ - 69.7 [-3.2] 74.4 [+0.9] 72.4 [+6.6] 86.0 [+2.7]
FISHER MERGING [45] ✓ 62.2 68.9 64.6 68.3 82.2
REGMEAN [31] ✓ 58.0 71.2 73.2 71.8 83.7
TASK ARITHMETIC [29] ✓ 63.9 73.2 73.3 70.1 84.5
TIES-MERGING ✓ 66.4 [+2.5] 73.9 [+0.7] 76.9 [+3.6] 73.6 [+1.8] 86.0 [+1.5]

Bảng 1: So sánh các phương pháp hợp nhất mô hình trên nhiều cài đặt tinh chỉnh và phương thức
(NLP và Thị giác) với và không có sự sẵn có của tập xác thực.

một bài toán hồi quy bình phương tối thiểu nhằm tối thiểu hóa khoảng cách giữa kích hoạt của mô hình đã
hợp nhất và kích hoạt của các mô hình riêng lẻ là θm = (∑nt=1 XTt Xt)−1 ∑nt=1(XTt Xtθt), trong đó Xt
là kích hoạt đầu vào của một lớp nhất định. (4) Task Artithmetic [29] tỷ lệ và sau đó cộng các vector nhiệm
vụ vào mô hình ban đầu để tạo ra mô hình đã hợp nhất là θm = θinit + λ ∗ ∑nt=1 τt. Ngoài những đường
cơ sở này, chúng tôi trình bày hiệu suất của các mô hình tinh chỉnh riêng lẻ tham gia vào quá trình hợp nhất
cũng như hiệu suất của một mô hình đa nhiệm vụ được huấn luyện trên việc nối các tập dữ liệu của tất cả
các nhiệm vụ. Để biết thêm chi tiết về tài nguyên tính toán, giấy phép tập dữ liệu và quy trình tinh chỉnh,
tham khảo Phụ lục C.1, C.2 và C.6.

Hợp nhất trong Vắng mặt Tập Xác thực. Các công trình trước [29,45,82] về hợp nhất mô hình giả định có
quyền truy cập vào tập xác thực, được sử dụng để tính toán ma trận Fisher hoặc điều chỉnh siêu tham số.
Để tránh nhu cầu về tập xác thực, RegMean [31] đề xuất lưu trữ và truyền ma trận tích trong của dữ liệu
huấn luyện cho mỗi nhiệm vụ có cùng kích thước với mô hình gốc. Điều này có thể nhanh chóng trở nên tốn
kém cho các mô hình lớn vì việc lưu trữ và truyền tỷ lệ tuyến tính với kích thước mô hình và số lượng nhiệm
vụ.

Để xem xét cài đặt không có tập xác thực, chúng tôi đã phát triển một công thức chung của TIES-MERGING
với các siêu tham số cố định có thể được áp dụng trong bất kỳ cài đặt nào mà không cần điều chỉnh siêu
tham số trên tập xác thực. Công thức này giữ top-20% tham số trong vector nhiệm vụ đặt lại phần còn lại
về 0 và đặt λ = 1. Chúng tôi chọn công thức này dựa trên kết quả trong cài đặt tinh chỉnh hiệu quả tham số
(PEFT), vì vậy chúng tôi chỉ áp dụng nó cho các cài đặt chưa thấy của tinh chỉnh mô hình đầy đủ trên các
mô hình ViT (thị giác) và T5 (ngôn ngữ). Chúng tôi cũng so sánh TIES-MERGING với phương pháp Task
Arithmetic mà không có tập xác thực bằng cách sử dụng giá trị được khuyến nghị λ = 0.4 [29]. Để biết thêm
chi tiết về cách tạo ra công thức này, vui lòng tham khảo Phụ lục C.4.

6 Kết quả Chính
Mục tiêu chính của chúng tôi là hợp nhất nhiều mô hình đặc trưng cho từng nhiệm vụ thành một mô hình đa
nhiệm vụ duy nhất có thể hoạt động tốt trên cả các tình huống trong miền và ngoài miền. Trong phần này,
chúng tôi đánh giá hiệu suất của TIES-MERGING với các phương pháp khác trên nhiều cài đặt thí nghiệm
khác nhau.

Hợp nhất Mô hình PEFT. Xem xét cài đặt nơi các vector nhiệm vụ được tính toán dựa trên các tham số
được giới thiệu trong quá trình tinh chỉnh hiệu quả tham số. Cụ thể, chúng tôi tập trung vào (IA)3 [43], một
phương pháp PEFT tỷ lệ kích hoạt mô hình cơ sở với các vector đã học. Chúng tôi tuân theo Liu et al. [43]
và sử dụng T0-3B [66] làm mô hình cơ sở và tinh chỉnh mô hình (IA)3 trên phần huấn luyện của mười một
tập dữ liệu bao gồm hoàn thành câu (COPA [61], H-SWAG [88], và bộ dữ liệu Story Cloze [68]), suy luận
ngôn ngữ tự nhiên (ANLI [49], CB [44], và RTE [11]), phân giải đồng tham chiếu (WSC [37] và Winogrande
[64]), và phân tách nghĩa từ (WiC [53]). Khi tinh chỉnh các tham số (IA)3 được thêm vào mô hình T0-3B,
chúng tôi sử dụng các mẫu nhắc từ Public Pool of Prompts (P3 [5]) để chuyển đổi mỗi ví dụ trong mỗi tập
dữ liệu thành định dạng văn bản-đến-văn bản được nhắc nơi mỗi nhãn tương ứng với một chuỗi khác nhau.
Đối với các thí nghiệm với (IA)3, cho mỗi tập dữ liệu, chúng tôi báo cáo điểm số trung vị trên tất cả các
mẫu.

--- TRANG 7 ---
Mô hình T5-Base T5-Large
Zeroshot 31.1 27.6
Lấy trung bình Đơn giản [9, 82] 31.7 30.4
Fisher [45] 33.8 32.0
RegMean [31] 34.3 36.0
Task Arithmetic [29] 31.9 32.3
TIES-MERGING 35.3 [+1.0] 40.4 [+4.4]

Bảng 2: TIES-MERGING tổng quát hóa tốt hơn.
Tổng quát hóa Ngoài Phân phối cho T5-Base
và T5-Large trên sáu nhiệm vụ bị loại bỏ.

2 3 4 5 6 70.70.80.911.1
Lấy trung bình Đơn giản Task Arithmetic TIES
Số lượng Nhiệm vụHiệu suất Chuẩn hóa Trung bình

Hình 5: TIES-MERGING mở rộng tốt hơn. Hiệu
suất trung bình khi hợp nhất số lượng nhiệm vụ
khác nhau.

Bảng 1 sử dụng TIES-MERGING để hợp nhất các mô hình được huấn luyện với (IA)3 vượt trội hơn tất cả
các phương pháp hợp nhất khác – với tập xác thực, TIES-MERGING cho thấy cải thiện trung bình 2.5%
trên 11 nhiệm vụ so với đường cơ sở hàng đầu. Để biết kết quả chi tiết, tham khảo Bảng 8 Phụ lục.

Hợp nhất Mô hình Thị giác Tinh chỉnh Đầy đủ. Đối với phân loại hình ảnh, chúng tôi tuân theo cài đặt
thí nghiệm từ Ilharco et al. [29,28]. Chúng tôi sử dụng hai biến thể của mô hình CLIP [56] với ViT-B/32 và
ViT-L/14 [14] làm bộ mã hóa thị giác. Sau đó, chúng tôi tinh chỉnh bộ mã hóa thị giác trên tám nhiệm vụ
bắt nguồn từ Ilharco et al. [28,29], Radford et al. [56] trong khi giữ cố định bộ mã hóa văn bản. Cài đặt này
xem xét nhiều miền phân loại khác nhau như viễn thám, phân loại giao thông và nhận dạng hình ảnh vệ tinh.
Cụ thể, chúng tôi làm việc với các tập dữ liệu sau: Cars [35], DTD [10], EuroSAT [24], GTSRB [71], MNIST
[36], RESISC45 [8], SUN397 [84], và SVHN [47].

Bảng 1 cho thấy rằng việc sử dụng TIES-MERGING để hợp nhất các mô hình ViT-B/32 và ViT-L/14 tinh
chỉnh đầy đủ dẫn đến cải thiện trung bình 1.8% và 1.5% trên 8 nhiệm vụ, với sự sẵn có của tập xác thực.
Trong trường hợp vắng mặt tập xác thực, TIES-MERGING cải thiện 6.6% và 2.7% so với các phương pháp
khác cho ViT-B/32 và ViT-L/14, tương ứng. Đáng chú ý, TIES-MERGING không có xác thực vượt trội hơn
Task Arithmetic [29] có xác thực 2.3% và 1.5% cho ViT-B/32 và ViT-L/14. Để biết kết quả chi tiết hơn,
tham khảo Bảng 11 và 12 Phụ lục.

Hợp nhất Mô hình NLP Tinh chỉnh Đầy đủ. Đối với miền NLP, chúng tôi sử dụng các mô hình T5-base và
T5-large [57], là các biến đổi mã hóa-giải mã [77] được huấn luyện trước thông qua mô hình hóa ngôn ngữ
có mặt nạ trên corpus văn bản lớn. Chúng tôi tinh chỉnh cả T5-base và T5-large trên bảy nhiệm vụ: trả lời
câu hỏi (QASC [33], WikiQA [87], và QuaRTz [73]), Nhận dạng Diễn giải (PAWS [90]), Hoàn thành Câu
(Story Cloze [68]), và Phân giải Đồng tham chiếu (Winogrande [64] và WSC [37]).

Bảng 1 cho thấy rằng việc sử dụng TIES-MERGING trên các mô hình T5-base và T5-large với tập xác thực
tạo ra cải thiện 0.7% và 3.6% tương ứng trên 7 nhiệm vụ so với trạng thái nghệ thuật. Hơn nữa, đối với
T5-large TIES-MERGING không có xác thực vượt trội hơn tất cả các đường cơ sở (thậm chí có tập xác thực)
1.1%. Để biết kết quả chi tiết hơn, tham khảo Bảng 9 và 10 Phụ lục.

Tổng quát hóa Ngoài miền. Trong nhiều trường hợp sử dụng, các mô hình đa nhiệm vụ được sử dụng vì
khả năng tổng quát hóa tốt hơn cho sự thay đổi miền. Do đó, chúng tôi sử dụng các mô hình T5-base và T5-
large được hợp nhất trên bảy tập dữ liệu trong miền từ các thí nghiệm trước và đánh giá chúng trên sáu tập
dữ liệu bị loại bỏ từ hỗn hợp T0 [65] để đo tổng quát hóa ngoài miền. Cụ thể, chúng tôi báo cáo hiệu suất
trung bình trên các nhiệm vụ và tập dữ liệu sau: Cosmos QA [27], Social IQA [67], và QuAIL [62] cho trả
lời câu hỏi; WiC [53] cho phân tách nghĩa từ; và COPA [61], và H-SWAG [88] cho hoàn thành câu. Bảng 2
cho thấy rằng TIES-MERGING vượt trội hơn đường cơ sở mạnh nhất cho cả T5-base và T5-Large 1.0% và
4.4% tương ứng, chứng minh tổng quát hóa ngoài miền tốt hơn. Để biết kết quả phức tạp hơn, vui lòng tham
khảo Phụ lục B.6 và Bảng 13 và 14.

Hợp nhất Số lượng Nhiệm vụ Khác nhau. Chúng tôi đánh giá hiệu suất của mô hình đã hợp nhất trên các
nhiệm vụ trong miền khi chúng tôi thay đổi số lượng nhiệm vụ được hợp nhất. Trong Hình 5, chúng tôi
chuẩn hóa độ chính xác của mỗi nhiệm vụ theo hiệu suất mô hình tinh chỉnh của nó và báo cáo độ chính xác
chuẩn hóa trung bình trên các nhiệm vụ trong miền. Chúng tôi so sánh với đường cơ sở mạnh nhất – Task
Arithmetic [29] – cũng như

--- TRANG 8 ---
RTE MRPC WNLI
Lấy trung bình 59.9 78.2 56.3
Fisher 65.7 81.4 52.1
Kết hợp 70.8 86.0 45.1
Task Arithmetic 71.8 86.0 59.2
TIES-MERGING 72.2 86.8 58.8

Bảng 3: Thiết lập thí nghiệm model soups. TIES
cải thiện hiệu suất khi hợp nhất các checkpoint
trên cùng các nhiệm vụ. Đối với mỗi nhiệm vụ,
chúng tôi hợp nhất 10 checkpoint từ Huggingface
hub và đánh giá trên một nhiệm vụ mà chúng được
huấn luyện.

Phương pháp Khởi tạo RTE MRPC WNLI
PTM Init 66.4 81.8 56.3
Trung bình 75.8 86.5 56.3
Task Arithmetic 78.3 86.2 50.7
TIES-MERGING 80.1 88.0 54.9

Bảng 4: Một mô hình hợp nhất TIES là khởi tạo
tốt hơn cho tinh chỉnh. Đối với mỗi nhiệm vụ,
chúng tôi hợp nhất các checkpoint từ 7 nhiệm vụ
GLUE khác và sau đó tinh chỉnh và đánh giá trên
nhiệm vụ được chọn.

0 1 >100.020.040.060.08Trung bình Cắt tỉa + Trung bình Rời rạc
Tham số với Giá trị Khác khôngĐộ lớn Trung bình
(a) Can thiệp Tham số Dư thừa.

0.5-0.6 0.6-0.7 0.7-0.8 0.8-0.9 0.9-1.000.050.10.15Trung bình Bầu chọn + Trung bình Rời rạc
Khoảng Thỏa thuận DấuĐộ lớn Trung bình (b) Can thiệp Dấu.

Hình 6: Cắt tỉa Tham số và Bầu chọn Dấu ngăn chặn can thiệp. Chứng minh can thiệp tham số
giữa các mô hình khác nhau và tác động của nó đối với giá trị tham số. Trung bình Chuẩn (đỏ) co
hẹp độ lớn và làm điều đó nhiều hơn khi có ít thỏa thuận về dấu (phải) hoặc tham số có ảnh hưởng
đối với nhiều nhiệm vụ (trái).

lấy trung bình đơn giản [82]. Mỗi điểm dữ liệu biểu thị việc hợp nhất một tập con các nhiệm vụ, với đường
liền đại diện cho hiệu suất trung bình trên nhiều tập con. Để biết kết quả tương tự với mô hình T5-base, vui
lòng tham khảo Phụ lục C.5 và Hình 13.

Từ Hình 5, chúng tôi quan sát những điều sau: (1) Khi số lượng nhiệm vụ được hợp nhất tăng, hiệu suất của
tất cả các phương pháp giảm. (2) Khi hợp nhất hai nhiệm vụ, cả TIES-MERGING và Task Arithmetic đều
đạt được độ chính xác chuẩn hóa trung bình gần bằng một, cho thấy mất mát hiệu suất không đáng kể. Ngược
lại, Lấy trung bình Đơn giản gặp phải sụt giảm hiệu suất 10%. (3) Khi số lượng nhiệm vụ tăng, hiệu suất
hợp nhất của Task Arithmetic giảm nhanh hơn TIES-MERGING. Điều này cho thấy rằng can thiệp nhiệm vụ
có mặt khi hợp nhất nhiều nhiệm vụ và TIES-MERGING hiệu quả hơn trong việc giảm thiểu vấn đề này.

Hợp nhất Checkpoint của cùng Nhiệm vụ để có Độ bền tốt hơn Chúng tôi thực hiện các thí nghiệm bổ
sung để hợp nhất nhiều checkpoint được huấn luyện trên cùng một nhiệm vụ (như đã làm trong ModelSoups
[82]) để xem liệu nó có thể cải thiện độ bền. Thông thường, kết hợp được sử dụng để kết hợp các mô hình
khác nhau trên cùng một nhiệm vụ để có tổng quát hóa tốt hơn. Chúng tôi sử dụng cài đặt thí nghiệm và mã
từ Fisher Merging [45] để hợp nhất top-10 mô hình BERT cơ sở tinh chỉnh từ huggingface cho các tập dữ
liệu RTE, MRPC và WNLI từ GLUE. Từ kết quả được trình bày trong Bảng 3, chúng tôi quan sát rằng
TIES-MERGING hoạt động tốt nhất trong tất cả các trường hợp ngoại trừ WNLI, nơi nó chỉ kém hiệu suất
một chút so với Task Vectors. Đáng chú ý, TIES-MERGING cung cấp sự thúc đẩy mạnh mẽ so với cả Fisher
Merging, lấy trung bình và vượt trội hơn kết hợp trong tất cả các trường hợp. Hơn nữa, trong Phụ lục B.4,
chúng tôi chỉ ra rằng can thiệp tồn tại ngay cả giữa các checkpoint được tinh chỉnh khác nhau của cùng một
nhiệm vụ.

Hợp nhất Mô hình để có Khởi tạo tốt hơn. Tiếp theo, chúng tôi thực hiện các thí nghiệm tuân theo cài đặt
[9], nơi chúng tôi hợp nhất các checkpoint từ các nhiệm vụ khác nhau để có khởi tạo tốt hơn khi tinh chỉnh
trên nhiệm vụ xuôi dòng. Chúng tôi lấy các checkpoint bert-base-uncased tinh chỉnh cho 8 nhiệm vụ GLUE
[78] (wnli, sst2, rte, qnli, mrpc, cola, mnli, qqp) từ Huggingface [81]. Chúng tôi xem xét ba trong số những
nhiệm vụ GLUE này (RTE, MRPC, WNLI) là các nhiệm vụ xuôi dòng của chúng tôi. Khi tinh chỉnh trên một
nhiệm vụ cụ thể

--- TRANG 9 ---
nhiệm vụ xuôi dòng (như RTE), chúng tôi hợp nhất tất cả các checkpoint từ bảy nhiệm vụ khác với nhau
(ngoài nhiệm vụ được chọn). Từ Bảng 4, chúng tôi thấy rằng TIES-MERGING hoạt động tốt trong cài đặt
này và vượt trội hơn tất cả các phương pháp hợp nhất khác với biên độ đáng kể (ngoài Lấy trung bình cho
WNLI).

7 Kết quả và Phân tích Bổ sung
7.1 Các Loại Can thiệp và Tác động của chúng đối với Hợp nhất
(a) Tầm quan trọng của việc Loại bỏ Tham số Dư thừa. Để tách biệt tốt hơn tác động của các tham số dư
thừa đối với độ lớn kết quả của các tham số đã hợp nhất, chúng tôi tách các tham số thành ba nhóm: tham
số dư thừa (sử dụng ngưỡng cắt tỉa 20%), tham số có ảnh hưởng đối với chính xác một mô hình, và tham
số có ảnh hưởng đối với nhiều hơn một mô hình. Sau đó chúng tôi so sánh các giá trị tham số khi chúng
được hợp nhất trực tiếp so với khi chúng được cắt tỉa trước và sau đó (rời rạc) hợp nhất mà không bầu chọn
dấu. Cụ thể, chúng tôi chỉ lấy trung bình của các giá trị không được cắt tỉa. Kết quả được hiển thị cho cài
đặt PEFT trong Hình 6a, chứng minh rằng các tham số dư thừa gây can thiệp. Cụ thể, chúng tôi thấy rằng
khi một tham số không phải là tham số có ảnh hưởng đối với bất kỳ mô hình đặc trưng cho từng nhiệm vụ
nào, giá trị trung bình thấp, và do đó có thể được coi là nhiễu. Tuy nhiên, khi chỉ một mô hình thấy tham
số là có ảnh hưởng, giá trị đã hợp nhất vẫn có thể thấp vì các mô hình khác gán giá trị nhỏ cho tham số
này. Giá trị đã hợp nhất lớn hơn khi nhiều mô hình thấy tham số là có ảnh hưởng. Khi cắt tỉa, chúng ta thấy
can thiệp này hầu hết được tránh, và kích thước trung bình chủ yếu giống nhau cho dù một hay nhiều mô
hình coi một tham số là có ảnh hưởng. Điều này là do chúng ta loại bỏ tác động của các tham số nhiễu mà
không cần thiết làm giảm độ lớn (xem # trong Hình 2). Trong Phụ lục B.5, chúng tôi mang lại cái nhìn chi
tiết hơn, bao gồm so sánh với việc áp dụng TIES-MERGING và cho thấy việc giảm can thiệp khuyến khích
sự đa dạng trong các giá trị tham số cụ thể (std) cùng với sự tương đồng của ảnh hưởng của chúng (trung
bình).

(b) Tầm quan trọng của việc Giải quyết Can thiệp Dấu. Để định lượng tác động của can thiệp dấu, chúng
tôi nhóm các tham số theo thỏa thuận dấu của chúng. Giá trị 0.5 cho thấy số lượng dấu dương và âm bằng
nhau cho một tham số nhất định trên các mô hình khác nhau, trong khi 1 có nghĩa là tất cả các tham số
có cùng dấu. Chúng tôi so sánh các giá trị tham số khi chúng được hợp nhất, hoặc khi sự bất đồng dấu
được giải quyết trước bằng bầu chọn và sau đó chúng được (rời rạc) hợp nhất. Kết quả trong cài đặt PEFT
được hiển thị trong Hình 6b, nơi chúng tôi chứng minh rằng bước ELECT bảo tồn độ lớn tham số tương
đối để tránh can thiệp dấu. Cụ thể, chúng tôi thấy rằng việc giải quyết dấu tăng độ lớn tham số tổng thể
trên các phạm vi thỏa thuận dấu khác nhau. Các tham số có thỏa thuận thấp có xu hướng nhỏ hơn trung
bình bất kể can thiệp. Một nguyên nhân tiềm năng có thể là dấu từ các tham số nhiễu kéo trung bình xuống,
như thấy trong Hình 6a. Chúng tôi chỉ ra trong Phụ lục B.5 rằng việc kết hợp cả hai phương pháp thực sự
làm giảm một số khác biệt, nhưng không phải tất cả, cho thấy rằng thỏa thuận cao có mối tương quan với
các tham số có ảnh hưởng tổng thể.

7.2 Mức độ liên quan của Dấu của Top-k% Tham số
Trong thí nghiệm này, chúng tôi làm việc với các mô hình (IA)3 và nhằm định lượng tầm quan trọng của
top-k% tham số và hướng của chúng đối với hiệu suất của một nhiệm vụ. Đối với mỗi vector nhiệm vụ τt,
chúng tôi lật hướng của mỗi top-k% tham số (theo độ lớn) với xác suất p để có được τ̃t. Việc lật hướng
được thực hiện bằng cách nhân các tham số với −1. Sau đó chúng tôi thêm lại τ̃t với hướng đã lật này vào
khởi tạo để có θ̃t = θinit + τ̃t. Cuối cùng, chúng tôi đánh giá θ̃t và tính toán hiệu suất trung bình trên tất cả
các nhiệm vụ t cho mỗi giá trị k và p. Như đường cơ sở, chúng tôi cũng lật hướng của (100−k)% dưới của
các tham số. Chúng tôi báo cáo kết quả trung bình trên ba lần chạy độc lập.

Trong Hình 7, chúng tôi vẽ biểu đồ hiệu suất trung bình như một hàm của p, xác suất lật hướng. Xác suất
0 có nghĩa là hướng của không có top-k% tham số nào bị lật và giá trị 1 có nghĩa là hướng của tất cả
top-k% tham số bị lật. Đối với top-20/30% tham số (đường liền), chúng tôi quan sát rằng hiệu suất giảm
đơn điệu khi chúng tôi tăng xác suất lật hướng. Ngược lại, việc lật hướng của (100−k)% dưới của các tham
số (đường đứt nét) có ít tác động đến hiệu suất. Những kết quả này thiết lập tầm quan trọng của việc có
hướng đúng cho các tham số có độ lớn cao và cho thấy sự sụt giảm hiệu suất thảm khốc xảy ra với hướng
không chính xác.

--- TRANG 10 ---
0.0 0.2 0.4 0.6 0.8 1.0506070Top-20 Top-30 Top-50 Bottom-80
Bottom-70 Bottom-50
Xác suất lật dấuHiệu suất Trung bình

Hình 7: Việc lật dấu của các tham số có độ lớn
cao dẫn đến sụt giảm hiệu suất thảm khốc. Hiệu
suất Trung bình khi lật hướng của Top-k% và
Bottom-k% tham số cho mỗi nhiệm vụ. Chúng
tôi báo cáo kết quả trung bình trên mười một
nhiệm vụ (IA)3.

Phương pháp Trung bình
Tinh chỉnh 71.4
Đa nhiệm vụ 73.1
Lấy trung bình [9, 82] 58.0
Task Vectors [29] 63.9
TIES-MERGING 66.4
TIES-MERGING (Oracle Sign) 72.0 [+5.6]

Bảng 5: TIES-MERGING có thể hoạt động
gần như các mô hình đa nhiệm vụ nếu các
dấu có thể được ước tính chính xác. Chúng
tôi sử dụng các dấu từ vector đa nhiệm vụ
làm dấu được bầu chọn và thực hiện hợp
nhất và báo cáo hiệu suất.

7.3 Nghiên cứu Loại bỏ các Thành phần TIES-MERGING
Phương pháp T5-base (IA)3
TIES-MERGING 74.5 70.7
−TRIM 73.0 70.6
−ELECT 73.1 69.6
−DISJOINT MEAN 72.6 67.5
−SCALE 72.0 65.5

Bảng 6: Nghiên cứu loại bỏ tất cả các bước
của TIES-MERGING.

Chúng tôi thực hiện nghiên cứu loại bỏ về các thành phần riêng lẻ
của TIES-MERGING để đánh giá tầm quan trọng của chúng. Trong
Bảng 6, chúng tôi bắt đầu với TIES-MERGING và loại bỏ từng
thành phần một và báo cáo hiệu suất trên tập xác thực cho hợp
nhất mô hình đầy đủ (T5-base) và hợp nhất mô hình PEFT ((IA)3
trên T03B). Loại bỏ elect trong khi giữ trung bình rời rạc có nghĩa
là lấy trung bình của các giá trị có dấu +1 và −1 nhưng không bao
gồm các giá trị 0 của các vector nhiệm vụ đã cắt tỉa trong trung
bình. Loại bỏ trung bình rời rạc nhưng cắt tỉa và bầu chọn có nghĩa
là lấy trung bình của các giá trị có dấu được bầu chọn và 0 cho các
giá trị đã cắt tỉa. Loại bỏ tỷ lệ có nghĩa là sử dụng λ = 1. Bảng 6
cho thấy rằng tất cả các thành phần của phương pháp đều quan trọng cho hiệu suất tối ưu. Cụ thể, tỷ lệ và
trung bình rời rạc nổi lên là quan trọng nhất, gây ra sự sụt giảm hiệu suất 2.5% và 1.9% trong T5-base, và
5.2% và 3.2% trong (IA)3, tương ứng.

7.4 Tầm quan trọng của việc Ước tính Dấu Chính xác Khi Hợp nhất Mô hình
Với tầm quan trọng của vector dấu, giờ đây chúng tôi nhằm hiểu hiệu suất có thể đạt được bởi TIES-
MERGING nếu chúng tôi có thể sử dụng vector dấu oracle từ mô hình đa nhiệm vụ. Để kiểm tra điều này,
chúng tôi huấn luyện một mô hình (IA)3 đa nhiệm vụ, θmult, trên mười một nhiệm vụ đang xem xét (như
trong § 6). Sau đó chúng tôi tạo vector đa nhiệm vụ τmult và vector dấu đa nhiệm vụ γmult. Tiếp theo, trong
khi hợp nhất các mô hình sử dụng TIES-MERGING, chúng tôi giả định có quyền truy cập vào vector dấu
đa nhiệm vụ oracle γmult. Do đó, chúng tôi bỏ qua bước giải quyết xung đột và trực tiếp đặt γm = γmult.
Đáng ngạc nhiên, từ Bảng 5, chúng tôi quan sát rằng khi hợp nhất các nhiệm vụ bằng cách sử dụng vector
dấu oracle, chúng tôi có được hiệu suất 72% so với 73.1% cho mô hình được huấn luyện đa nhiệm vụ. Hơn
nữa, trung bình mô hình đã hợp nhất hoạt động tốt hơn các mô hình đặc trưng cho từng nhiệm vụ. Điều này
có nghĩa là nếu chúng ta có thể có được các hướng sửa chữa cho mô hình đã hợp nhất, thì chúng ta có thể
thu hẹp khoảng cách với các mô hình đa nhiệm vụ một cách chặt chẽ. Trong Phụ lục B.1 và Bảng 7, chúng
tôi cố gắng ước tính vector dấu đa nhiệm vụ bằng cách sử dụng dữ liệu hạn chế.

8 Kết luận
Chúng tôi giới thiệu TIES-MERGING để giải quyết can thiệp khi hợp nhất các mô hình. TIES-MERGING
cắt tỉa các thay đổi có độ lớn thấp trong các giá trị mô hình tinh chỉnh và sau đó giải quyết sự bất đồng dấu
giữa các mô hình được hợp nhất. Chúng tôi thấy thực nghiệm rằng TIES-MERGING nâng cao hiệu suất
của mô hình đa nhiệm vụ đã hợp nhất trên các cài đặt và miền khác nhau, mặc dù đơn giản với các siêu tham
số cố định. Nghiên cứu của chúng tôi cũng làm sáng tỏ tác động của các loại can thiệp khác nhau đối với
các tham số mô hình và nhấn mạnh tầm quan trọng của dấu trong quá trình hợp nhất. Để thảo luận về một
số hạn chế và hướng tương lai, vui lòng tham khảo Phụ lục A.

--- TRANG 11 ---
Lời cảm ơn
Chúng tôi cảm ơn Yi-Lin Sung, Shiyue Zhang, Archiki Prasad, và các nhà phản biện vì phản hồi có giá trị
của họ về bài báo này. Công việc này được hỗ trợ bởi NSF-AI Engage Institute DRL211263, NSF-CAREER
Award 1846185, DARPA MCS Grant N66001-19-2-4031, và NSF Grant 2145822. Các quan điểm, ý kiến
và/hoặc phát hiện có trong bài viết này là của các tác giả chứ không phải của cơ quan tài trợ.

Tài liệu tham khảo
[1]S. K. Ainsworth, J. Hayase, and S. Srinivasa. Git re-basin: Merging models modulo permutation
symmetries, 2022. https://arxiv.org/abs/2209.04836 .
[2]A. Albalak, C. Raffel, and W. Y . Wang. Improving few-shot generalization by exploring and
exploiting auxiliary data. arXiv preprint arXiv:2302.00674 , 2023.
[3]S. Amari. Neural learning in structured parameter spaces - natural riemannian gradient. In
NIPS , 1996.
[4]D. Arpit, H. Wang, Y . Zhou, and C. Xiong. Ensemble of averages: Improving model selection
and boosting performance in domain generalization. arXiv preprint arXiv:2110.10832 , 2021.
[5]S. H. Bach, V . Sanh, Z.-X. Yong, A. Webson, C. Raffel, N. V . Nayak, A. Sharma, T. Kim, M. S.
Bari, T. Févry, et al. PromptSource: An integrated development environment and repository for
natural language prompts. arXiv preprint arXiv:2202.01279 , 2022.
[6]R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx, M. S. Bernstein,
J. Bohg, A. Bosselut, E. Brunskill, et al. On the opportunities and risks of foundation models,
2021. https://arxiv.org/abs/2108.07258 .
[7]J. Cha, S. Chun, K. Lee, H.-C. Cho, S. Park, Y . Lee, and S. Park. Swad: Domain generalization
by seeking flat minima. Advances in Neural Information Processing Systems , 34:22405–22418,
2021.
[8]G. Cheng, J. Han, and X. Lu. Remote sensing image scene classification: Benchmark and state
of the art. Proceedings of the Institute of Electrical and Electronics Engineers (IEEE) , 2017.
https://ieeexplore.ieee.org/abstract/document/7891544 .
[9]L. Choshen, E. Venezian, N. Slonim, and Y . Katz. Fusing finetuned models for better pretraining,
2022. https://arxiv.org/abs/2204.03044 .
[10] M. Cimpoi, S. Maji, I. Kokkinos, S. Mohamed, and A. Vedaldi. Describing
textures in the wild. In Conference on Computer Vision and Pattern Recogni-
tion (CVPR) , 2014. https://openaccess.thecvf.com/content_cvpr_2014/
html/Cimpoi_Describing_Textures_in_2014_CVPR_paper.html .
[11] I. Dagan, O. Glickman, and B. Magnini. The pascal recognising textual entailment challenge.
InMachine Learning Challenges Workshop , 2005. https://link.springer.com/
chapter/10.1007/11736790_9 .
[12] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. BERT: Pre-training of deep bidirectional
transformers for language understanding. arXiv preprint arXiv:1810.04805 , 2018.
[13] S. Don-Yehiya, E. Venezian, C. Raffel, N. Slonim, Y . Katz, and L. Choshen. Cold fusion:
Collaborative descent for distributed multitask finetuning, 2022. https://arxiv.org/
abs/2212.01378 .
[14] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani,
M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby. An image is worth 16x16
words: Transformers for image recognition at scale. In International Conference on Learning
Representations (ICLR) , 2021. https://openreview.net/forum?id=YicbFdNTTy .
11

--- TRANG 12 ---
[15] F. Draxler, K. Veschgini, M. Salmhofer, and F. Hamprecht. Essentially no barriers in neural
network energy landscape. In International Conference on Machine Learning (ICML) , 2018.
https://arxiv.org/abs/1803.00885 .
[16] R. Entezari, H. Sedghi, O. Saukh, and B. Neyshabur. The role of permutation invariance in
linear mode connectivity of neural networks. arXiv preprint arXiv:2110.06296 , 2021.
[17] C. Fifty, E. Amid, Z. Zhao, T. Yu, R. Anil, and C. Finn. Efficiently identifying task groupings
for multi-task learning. Advances in Neural Information Processing Systems , 34:27503–27516,
2021.
[18] R. A. Fisher. On the mathematical foundations of theoretical statistics. Philosophical transac-
tions of the Royal Society of London. Series A, containing papers of a mathematical or physical
character , 222(594-604):309–368, 1922.
[19] J. Frankle, G. K. Dziugaite, D. Roy, and M. Carbin. Linear mode connectivity and the
lottery ticket hypothesis. In International Conference on Machine Learning (ICML) , 2020.
https://proceedings.mlr.press/v119/frankle20a.html .
[20] C. D. Freeman and J. Bruna. Topology and geometry of half-rectified network optimization.
arXiv preprint arXiv:1611.01540 , 2016.
[21] T. Garipov, P. Izmailov, D. Podoprikhin, D. Vetrov, and A. G. Wilson. Loss surfaces, mode
connectivity, and fast ensembling of dnns. In Advances in Neural Information Processing
Systems (NeurIPS) , 2018. https://arxiv.org/abs/1802.10026 .
[22] A. Gueta, E. Venezian, C. Raffel, N. Slonim, Y . Katz, and L. Choshen. Knowledge is a region
in weight space for fine-tuned language models. arXiv preprint arXiv:2302.04863 , 2023.
[23] V . Gupta, S. A. Serrano, and D. DeCoste. Stochastic weight averaging in parallel: Large-batch
training that generalizes well. International Conference on Learning Representations , 2020.
[24] P. Helber, B. Bischke, A. Dengel, and D. Borth. Eurosat: A novel dataset and deep learning
benchmark for land use and land cover classification. Journal of Selected Topics in Applied Earth
Observations and Remote Sensing , 2019. https://arxiv.org/abs/1709.00029 .
[25] T. Hoefler, D. Alistarh, T. Ben-Nun, N. Dryden, and A. Peste. Sparsity in deep learning: Pruning
and growth for efficient inference and training in neural networks. The Journal of Machine
Learning Research , 22(1):10882–11005, 2021.
[26] E. J. Hu, Y . Shen, P. Wallis, Z. Allen-Zhu, Y . Li, S. Wang, and W. Chen. LoRA: Low-rank
adaptation of large language models. ArXiv , abs/2106.09685, 2021.
[27] L. Huang, R. Le Bras, C. Bhagavatula, and Y . Choi. Cosmos qa: Machine reading compre-
hension with contextual commonsense reasoning. In Proceedings of the 2019 Conference on
Empirical Methods in Natural Language Processing and the 9th International Joint Conference
on Natural Language Processing (EMNLP-IJCNLP) , pages 2391–2401, 2019.
[28] G. Ilharco, M. Wortsman, S. Y . Gadre, S. Song, H. Hajishirzi, S. Kornblith, A. Farhadi, and
L. Schmidt. Patching open-vocabulary models by interpolating weights. In Advances in
Neural Information Processing Systems (NeurIPS) , 2022. https://arXiv.org/abs/
2208.05592 .
[29] G. Ilharco, M. T. Ribeiro, M. Wortsman, L. Schmidt, H. Hajishirzi, and A. Farhadi. Editing mod-
els with task arithmetic. In The Eleventh International Conference on Learning Representations ,
2023. URL https://openreview.net/forum?id=6t0Kwf8-jrj .
[30] P. Izmailov, D. Podoprikhin, T. Garipov, D. Vetrov, and A. G. Wilson. Averaging weights
leads to wider optima and better generalization. In Conference on Uncertainty in Artificial
Intelligence (UAI) , 2018. https://arxiv.org/abs/1803.05407 .
[31] X. Jin, X. Ren, D. Preotiuc-Pietro, and P. Cheng. Dataless knowledge fusion by merging weights
of language models. In The Eleventh International Conference on Learning Representations ,
2023. URL https://openreview.net/forum?id=FCnohuR6AnM .
12

--- TRANG 13 ---
[32] K. Jordan, H. Sedghi, O. Saukh, R. Entezari, and B. Neyshabur. REPAIR: REnormalizing per-
muted activations for interpolation repair. In The Eleventh International Conference on Learning
Representations , 2023. URL https://openreview.net/forum?id=gU5sJ6ZggcX .
[33] T. Khot, P. Clark, M. Guerquin, P. Jansen, and A. Sabharwal. Qasc: A dataset for question
answering via sentence composition. In Proceedings of the AAAI Conference on Artificial
Intelligence , volume 34, pages 8082–8090, 2020.
[34] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins, A. A. Rusu, K. Milan,
J. Quan, T. Ramalho, A. Grabska-Barwinska, et al. Overcoming catastrophic forgetting in
neural networks. Proceedings of the National Academy of Sciences (PNAS) , 2017. https:
//arxiv.org/abs/1612.00796 .
[35] J. Krause, M. Stark, J. Deng, and L. Fei-Fei. 3d object representations for fine-grained
categorization. In International Conference on Computer Vision Workshops (ICML) ,
2013. https://www.cv-foundation.org/openaccess/content_iccv_
workshops_2013/W19/html/Krause_3D_Object_Representations_2013_
ICCV_paper.html .
[36] Y . LeCun. The mnist database of handwritten digits, 1998. http://yann.lecun.com/
exdb/mnist/ .
[37] H. Levesque, E. Davis, and L. Morgenstern. The winograd schema challenge. Thirteenth
International Conference on the Principles of Knowledge Representation and Reasoning , 2012.
[38] M. Li, S. Gururangan, T. Dettmers, M. Lewis, T. Althoff, N. A. Smith, and L. Zettlemoyer.
Branch-train-merge: Embarrassingly parallel training of expert language models, 2022. https:
//arxiv.org/abs/2208.03306 .
[39] P. Li, Z. Zhang, P. Yadav, Y .-L. Sung, Y . Cheng, M. Bansal, and T. Chen. Merge, then compress:
Demystify efficient smoe with hints from its routing policy, 2023.
[40] W. Li, Y . Peng, M. Zhang, L. Ding, H. Hu, and L. Shen. Deep model fusion: A survey. arXiv
preprint arXiv:2309.15698 , 2023.
[41] X. Li, K. Huang, W. Yang, S. Wang, and Z. Zhang. On the convergence of fedavg on non-iid
data. In International Conference on Learning Representations , 2019.
[42] Y . Li, J. Yosinski, J. Clune, H. Lipson, and J. Hopcroft. Convergent learning: Do different
neural networks learn the same representations? arXiv preprint arXiv:1511.07543 , 2015.
[43] H. Liu, D. Tam, M. Muqeeth, J. Mohta, T. Huang, M. Bansal, and C. A. Raffel. Few-shot
parameter-efficient fine-tuning is better and cheaper than in-context learning. Advances in
Neural Information Processing Systems , 35:1950–1965, 2022.
[44] M.-C. d. Marneffe, M. Simons, and J. Tonhauser. The CommitmentBank: Investigating
projection in naturally occurring discourse. Proceedings of Sinn und Bedeutung 23 , 2019.
[45] M. Matena and C. Raffel. Merging models with fisher-weighted averaging. In Advances in
Neural Information Processing Systems (NeurIPS) , 2021. https://arxiv.org/abs/
2111.09832 .
[46] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas. Communication-efficient
learning of deep networks from decentralized data. In Artificial intelligence and statistics , pages
1273–1282. PMLR, 2017.
[47] Y . Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and A. Y . Ng. Reading digits in nat-
ural images with unsupervised feature learning. In Advances in Neural Information Pro-
cessing Systems (NeurIPS) Workshops , 2011. https://storage.googleapis.com/
pub-tools-public-publication-data/pdf/37648.pdf .
[48] B. Neyshabur, H. Sedghi, and C. Zhang. What is being transferred in transfer learning?
Advances in neural information processing systems , 33:512–523, 2020.
13

--- TRANG 14 ---
[49] Y . Nie, A. Williams, E. Dinan, M. Bansal, J. Weston, and D. Kiela. Adversarial NLI: A new
benchmark for natural language understanding. arXiv preprint arXiv:1910.14599 , 2019.
[50] H. Orgad, B. Kawar, and Y . Belinkov. Editing implicit assumptions in text-to-image diffusion
models. arXiv preprint arXiv:2303.08084 , 2023.
[51] G. Ortiz-Jiménez, A. Favero, and P. Frossard. Task arithmetic in the tangent space: Improved
editing of pre-trained models. NeurIPS , 2023. https://arxiv.org/abs/2305:12827 .
[52] J. Phang, T. Févry, and S. R. Bowman. Sentence encoders on stilts: Supplementary training on
intermediate labeled-data tasks. arXiv preprint arXiv:1811.01088 , 2018.
[53] M. T. Pilehvar and J. Camacho-Collados. WiC: The word-in-context dataset for evaluating
context-sensitive meaning representations. In Proceedings of NAACL-HLT , 2019.
[54] C. Poth, J. Pfeiffer, A. Rücklé, and I. Gurevych. What to pre-train on? Efficient intermediate task
selection. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language
Processing , pages 10585–10605, Online and Punta Cana, Dominican Republic, Nov. 2021.
[55] Y . Pruksachatkun, J. Phang, H. Liu, P. M. Htut, X. Zhang, R. Y . Pang, C. Vania, K. Kann, and
S. R. Bowman. Intermediate-task transfer learning with pretrained language models: When
and why does it work? In Proceedings of the 58th Annual Meeting of the Association for
Computational Linguistics , pages 5231–5247, Online, July 2020.
[56] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell,
P. Mishkin, J. Clark, G. Krueger, and I. Sutskever. Learning transferable visual models from
natural language supervision. In International Conference on Machine Learning (ICML) , 2021.
https://arxiv.org/abs/2103.00020 .
[57] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y . Zhou, W. Li, and P. J.
Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of
Machine Learning Research (JMLR) , 2020. http://jmlr.org/papers/v21/20-074.
html .
[58] C. Raffel, N. M. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y . Zhou, W. Li, and P. J.
Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. ArXiv ,
abs/1910.10683, 2020.
[59] A. Ramé, K. Ahuja, J. Zhang, M. Cord, L. Bottou, and D. Lopez-Paz. Model ratatouille: Recy-
cling diverse models for out-of-distribution generalization. arXiv preprint arXiv:2212.10445 ,
2022.
[60] A. Ramé, M. Kirchmeyer, T. Rahier, A. Rakotomamonjy, P. Gallinari, and M. Cord. Diverse
weight averaging for out-of-distribution generalization. ICML , 2023.
[61] M. Roemmele, C. A. Bejan, and A. S. Gordon. Choice of plausible alternatives: An evaluation
of commonsense causal reasoning. 2011 AAAI Spring Symposium Series , 2011.
[62] A. Rogers, O. Kovaleva, M. Downey, and A. Rumshisky. Getting closer to AI complete question
answering: A set of prerequisite real tasks. In The Thirty-Fourth AAAI Conference on Artificial
Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence
Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial
Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020 , pages 8722–8731. AAAI
Press, 2020. URL https://aaai.org/ojs/index.php/AAAI/article/view/
6398 .
[63] S. Ruder. An overview of gradient descent optimization algorithms. arXiv preprint
arXiv:1609.04747 , 2016.
[64] K. Sakaguchi, R. Le Bras, C. Bhagavatula, and Y . Choi. Winogrande: An adversarial winograd
schema challenge at scale. In Proceedings of the AAAI Conference on Artificial Intelligence ,
2020.
14

--- TRANG 15 ---
[65] V . Sanh, A. Webson, C. Raffel, S. H. Bach, L. Sutawika, Z. Alyafeai, A. Chaffin, A. Stiegler,
T. L. Scao, A. Raja, et al. Multitask prompted training enables zero-shot task generalization.
arXiv preprint arXiv:2110.08207 , 2021.
[66] V . Sanh, A. Webson, C. Raffel, S. H. Bach, L. Sutawika, Z. Alyafeai, A. Chaffin, A. Stiegler,
T. L. Scao, A. Raja, et al. Multitask prompted training enables zero-shot task generalization.
InInternational Conference on Learning Representations (ICLR) , 2021. https://arxiv.
org/abs/2110.08207 .
[67] M. Sap, H. Rashkin, D. Chen, R. Le Bras, and Y . Choi. Social iqa: Commonsense reasoning
about social interactions. In Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on Natural Language
Processing (EMNLP-IJCNLP) , pages 4463–4473, 2019.
[68] R. Sharma, J. Allen, O. Bakhshandeh, and N. Mostafazadeh. Tackling the story ending biases
in the story cloze test. In Proceedings of the 56th Annual Meeting of the Association for
Computational Linguistics (Volume 2: Short Papers) , pages 752–757, 2018.
[69] E. Shnarch, A. Halfon, A. Gera, M. Danilevsky, Y . Katsis, L. Choshen, M. S. Cooper, D. Epel-
boim, Z. Zhang, D. Wang, et al. Label sleuth: From unlabeled text to a classifier in a few hours.
InConference on Empirical Methods in Natural Language Processing , 2022.
[70] S. P. Singh and M. Jaggi. Model fusion via optimal transport. Advances in Neural Information
Processing Systems , 33:22045–22055, 2020.
[71] J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. The german traffic sign recognition
benchmark: a multi-class classification competition. In International Joint Conference on Neural
Networks (IJCNN) , 2011. https://ieeexplore.ieee.org/document/6033395 .
[72] Y .-L. Sung, L. Li, K. Lin, Z. Gan, M. Bansal, and L. Wang. An empirical study of multimodal
model merging. Empirical Methods in Natural Language Processing (Findings) , 2023.
[73] O. Tafjord, M. Gardner, K. Lin, and P. Clark. Quartz: An open-domain dataset of qualitative
relationship questions. In Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on Natural Language
Processing (EMNLP-IJCNLP) , pages 5941–5946, 2019.
[74] N. Tatro, P.-Y . Chen, P. Das, I. Melnyk, P. Sattigeri, and R. Lai. Optimizing mode connectivity
via neuron alignment. Advances in Neural Information Processing Systems , 33:15300–15311,
2020.
[75] Y . Tay, M. Dehghani, V . Q. Tran, X. Garcia, J. Wei, X. Wang, H. W. Chung, D. Bahri, T. Schuster,
S. Zheng, et al. Ul2: Unifying language learning paradigms. In The Eleventh International
Conference on Learning Representations , 2022.
[76] G. Thimm and E. Fiesler. Evaluating pruning methods. In International Symposium on Artificial
Neural Networks , 1995.
[77] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and
I. Polosukhin. Attention is all you need. Advances in Neural Information Processing Systems
(NeurIPS) , 2017. https://arxiv.org/abs/1706.03762 .
[78] A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman. Glue: A multi-task bench-
mark and analysis platform for natural language understanding. In International Conference on
Learning Representations (ICLR) , 2018. https://arxiv.org/abs/1804.07461 .
[79] H. Wang, M. Yurochkin, Y . Sun, D. Papailiopoulos, and Y . Khazaeni. Federated learning with
matched averaging. In International Conference on Learning Representations , 2020.
[80] O. Weller, K. Seppi, and M. Gardner. When to use multi-task learning vs intermediate fine-
tuning for pre-trained encoder transfer learning. In Proceedings of the 60th Annual Meeting
of the Association for Computational Linguistics (Volume 2: Short Papers) , pages 272–282,
Dublin, Ireland, May 2022.
15

--- TRANG 16 ---
[81] T. Wolf, L. Debut, V . Sanh, J. Chaumond, C. Delangue, A. Moi, P. Cistac, T. Rault, R. Louf,
M. Funtowicz, et al. Huggingface's transformers: State-of-the-art natural language processing,
2019. https://arxiv.org/abs/1910.03771 .
[82] M. Wortsman, G. Ilharco, S. Y . Gadre, R. Roelofs, R. Gontijo-Lopes, A. S. Morcos,
H. Namkoong, A. Farhadi, Y . Carmon, S. Kornblith, et al. Model soups: averaging weights
of multiple fine-tuned models improves accuracy without increasing inference time. In Inter-
national Conference on Machine Learning (ICML) , 2022. https://arxiv.org/abs/
2203.05482 .
[83] M. Wortsman, G. Ilharco, M. Li, J. W. Kim, H. Hajishirzi, A. Farhadi, H. Namkoong, and
L. Schmidt. Robust fine-tuning of zero-shot models. In Conference on Computer Vision and
Pattern Recognition (CVPR) , 2022. https://arxiv.org/abs/2109.01903 .
[84] J. Xiao, K. A. Ehinger, J. Hays, A. Torralba, and A. Oliva. Sun database: Exploring a
large collection of scene categories. International Journal of Computer Vision (IJCV) , 2016.
https://link.springer.com/article/10.1007/s11263-014-0748-y .
[85] P. Yadav and M. Bansal. Exclusive supermask subnetwork training for continual learning.
InFindings of the Association for Computational Linguistics: ACL 2023 , pages 569–587,
Toronto, Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.
findings-acl.36. URL https://aclanthology.org/2023.findings-acl.36 .
[86] P. Yadav, Q. Sun, H. Ding, X. Li, D. Zhang, M. Tan, P. Bhatia, X. Ma, R. Nallapati,
M. K. Ramanathan, M. Bansal, and B. Xiang. Exploring continual learning for code gen-
eration models. In Proceedings of the 61st Annual Meeting of the Association for Com-
putational Linguistics (Volume 2: Short Papers) , pages 782–792, Toronto, Canada, July
2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-short.68. URL
https://aclanthology.org/2023.acl-short.68 .
[87] Y . Yang, W.-t. Yih, and C. Meek. WikiQA: A challenge dataset for open-domain question
answering. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language
Processing , pages 2013–2018, Lisbon, Portugal, Sept. 2015. Association for Computational Lin-
guistics. doi: 10.18653/v1/D15-1237. URL https://aclanthology.org/D15-1237 .
[88] R. Zellers, A. Holtzman, Y . Bisk, A. Farhadi, and Y . Choi. HellaSwag: Can a machine really
finish your sentence? arXiv preprint arXiv:1905.07830 , 2019.
[89] Y . Zhang and Q. Yang. A survey on multi-task learning. IEEE Transactions on Knowledge and
Data Engineering , 34(12):5586–5609, 2021.
[90] Y . Zhang, J. Baldridge, and L. He. PAWS: Paraphrase Adversaries from Word Scrambling. In
Proc. of NAACL , 2019.
[91] F. Zhuang, Z. Qi, K. Duan, D. Xi, Y . Zhu, H. Zhu, H. Xiong, and Q. He. A comprehensive
survey on transfer learning. Proceedings of the IEEE , 2020. https://arxiv.org/abs/
1911.02685 .
16

--- TRANG 17 ---
Phụ lục cho TIES-MERGING
A Hạn chế và Công việc Tương lai
Công việc của chúng tôi chia sẻ những hạn chế chung giống như các phương pháp hợp nhất hiện có, như (1)
hiểu biết lý thuyết hạn chế về lý do và thời điểm nội suy trọng số hoạt động, các yếu tố quan trọng cơ bản
là gì, và mối liên hệ phù hợp của nó với khả năng kết nối chế độ. Các công trình gần đây như [50] đã chứng
minh những mối quan hệ thú vị giữa sự tách biệt trọng số và khả năng hợp nhất của các mô hình; (2) việc
hợp nhất dựa trên khởi tạo chung và kiến trúc mô hình; và (3) việc hợp nhất các mô hình nhiệm vụ riêng lẻ
để tạo ra đa nhiệm vụ vẫn thua kém so với huấn luyện đa nhiệm vụ đồng thời. Hơn nữa, không rõ làm thế
nào để chọn các checkpoint để hợp nhất nhằm tạo ra các mô hình đa nhiệm vụ hữu ích cho các miền cụ thể.
Ngoài ra, trong khi phương pháp của chúng tôi cung cấp một cách để chọn dấu khi hợp nhất các vector nhiệm
vụ, chúng tôi vẫn thấy rằng việc sử dụng dấu từ mô hình đa nhiệm vụ hoạt động tốt hơn. Một số công việc
tương lai tiềm năng bao gồm tìm ra cách tốt để ước tính dấu đa nhiệm vụ mà không cần truy cập vào mô
hình đa nhiệm vụ vì điều này có tiềm năng thu hẹp khoảng cách giữa hợp nhất đa nhiệm vụ và huấn luyện
đa nhiệm vụ (như được chứng minh trong Phần 7.4).

B Kết quả Bổ sung
Phương pháp Ước tính Dấu Trung bình
Mẫu Đa nhiệm vụ Khởi tạo.
Tinh chỉnh - - - 71.4
Đa nhiệm vụ - - - 73.1
Lấy trung bình [9, 82] - - - 58.0
Task Vectors [29] - - - 63.9
TIES-MERGING - - - 66.4
TIES-MERGING ✓ 32 từ đầu 66.5 [+0.1]
✓ 32 trung bình 67.7 [+1.2]
✓ Tất cả từ đầu 72.0 [+5.6]

Bảng 7: Hiệu suất Hợp nhất có thể được cải thiện bằng cách ước tính Vector Dấu bằng cách thực
hiện huấn luyện đa nhiệm vụ vài shot. Chúng tôi sử dụng dấu ước tính làm dấu được bầu chọn và
thực hiện hợp nhất.

B.1 Nâng cao Hiệu suất bằng cách Ước tính Vector Dấu Đa nhiệm vụ.
Xem xét những phát hiện, chúng tôi hỏi liệu có thể có được vector dấu đa nhiệm vụ một cách hiệu quả mà
không cần huấn luyện đa nhiệm vụ mở rộng. Đề xuất của chúng tôi bao gồm việc sử dụng số lượng hạn chế
các mẫu xác thực từ mỗi nhiệm vụ để huấn luyện rẻ một mô hình đa nhiệm vụ và sau đó suy ra vector dấu
liên quan. Chúng tôi tạo hai mô hình (IA)3 đa nhiệm vụ: một được phát triển từ đầu và một khác được khởi
tạo bằng cách sử dụng trung bình của các mô hình (IA)3 đặc trưng cho từng nhiệm vụ dự định hợp nhất.
Chúng tôi sử dụng 32 ví dụ xác thực từ mỗi nhiệm vụ để huấn luyện mô hình này. Trong Bảng 5, chúng tôi
nhận thấy việc sử dụng vector dấu từ mô hình đa nhiệm vụ fewshot được khởi tạo với trung bình mang lại
sự gia tăng hiệu suất 3.8% và 1.3% so với Task Arithmetic và TIES-MERGING. Thú vị, huấn luyện đa
nhiệm vụ fewshot từ đầu không mang lại cải thiện đáng kể so với TIES-MERGING mà không ước tính dấu.
Chúng tôi tin rằng việc khám phá lĩnh vực này sâu hơn có thể dẫn đến các kỹ thuật hợp nhất được cải thiện.

B.2 Tác động của Siêu tham số λ và K đối với Hiệu suất.
Trong Hình 8 (trái và giữa), chúng tôi vẽ biểu đồ tác động của λ đối với hiệu suất khi hợp nhất các mô hình
T5-base và T5-large được huấn luyện trên GLUE (Tương tự như Bảng-1). Đối với TIES-MERGING, chúng
tôi thay đổi xung quanh giá trị 1 vì TIES lấy trung bình của các vector nhiệm vụ, trong khi task arithmetic
cộng các vector nhiệm vụ. Do đó, giá trị 1 cho TIES tương tự như việc sử dụng 1/#nhiệm vụ cho Task
Arithmetic [29]. Phạm vi 0.8-1.8 cho TIES được chọn dựa trên các thí nghiệm sơ bộ về cài đặt PEFT (như
đã đề cập trong Phần 5). Chúng tôi thấy rằng TIES-MERGING ít nhạy cảm hơn nhiều với những thay đổi
trong (với phạm vi độ chính xác 68-75% trên các giá trị λ được xem xét) so với Task Arithmetic (với độ
chính xác

--- TRANG 18 ---
LambdaHiệu suất Trung bình505560657075
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0T5-Base T5-LargeHợp nhất TV
LambdaHiệu suất Trung bình64666870727476
0.8 0.9 1.0 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8T5-Base T5-LargeHợp nhất TIES
KHiệu suất Trung bình 707274767880
10 20 30 40 50 60 70 80 90 100Hiệu suất Trung bình vs. K (T5-Base)

Hình 8: Hiệu suất như một hàm của siêu tham số. Để biết thêm chi tiết vui lòng tham khảo phản
hồi chung của chúng tôi.

10 20 30 40 50 60 70 80 9000.050.10.150.2RTE
K (Tỷ lệ tham số được giữ.)Tỷ lệ Tham số 
 với Xung đột
10 20 30 40 50 60 70 80 9000.050.10.15MRPC
K (Tỷ lệ tham số được giữ.)Tỷ lệ Tham số 
 với Xung đột
10 20 30 40 50 60 70 80 9000.10.20.3WNLI
K (Tỷ lệ tham số được giữ.)Tỷ lệ Tham số 
 với Xung đột

Hình 9: Xung đột dấu tăng khi chúng ta cắt tỉa ít tham số hơn. Đối với mỗi nhiệm vụ, chúng tôi
hợp nhất 10 checkpoint khác nhau từ hunggingface hub và vẽ biểu đồ xung đột dấu như một hàm
của việc chỉ giữ top-k% tham số.

2 3 4 5 6 7 8 9 1000.050.10.150.2RTE
Số lượng Mô hìnhTỷ lệ Tham số 
 với Xung đột
2 3 4 5 6 7 8 9 1000.050.10.15MRPC
Số lượng Mô hìnhTỷ lệ Tham số 
 với Xung đột
2 3 4 5 6 7 8 9 1000.10.20.3WNLI
Số lượng Mô hìnhTỷ lệ Tham số 
 với Xung đột
2 3 4 5 6 7 8 9 10 1100.10.20.3
Số lượng Mô hìnhTỷ lệ Tham số 
 với Xung đột

Hình 10: Xung đột Dấu tồn tại ngay cả khi hợp nhất nhiều checkpoint cho cùng một nhiệm vụ.
Ba biểu đồ đầu tiên dành cho các tập dữ liệu RTE, MRPC, WNLI khi hợp nhất 10 checkpoint
Huggingface, trong khi biểu đồ cuối cùng là khi hợp nhất các nhiệm vụ khác nhau (Hình 4 từ bài
báo chính).

phạm vi 55-75). Hình 8 (phải) chứng minh tác động của k khi chúng tôi tăng giá trị k theo bước 10 và bỏ
qua k = 0 vì điều đó sẽ không chọn tham số nào. Chúng tôi quan sát rằng khi k tăng hiệu suất giảm và sau
đó bão hòa. Tuy nhiên, chúng tôi muốn lưu ý rằng đường cong này có thể thay đổi dựa trên phân phối của
các giá trị tham số trong vector nhiệm vụ.

B.3 Xung đột Dấu Tăng khi Chúng ta Cắt tỉa Ít Tham số hơn
Trong Hình 9, chúng tôi hợp nhất 10 checkpoint bert-base-uncased từ huggingface được tinh chỉnh cho ba
nhiệm vụ glue khác nhau (RTE, MRPC, và WNLI) và vẽ biểu đồ xung đột dấu như một hàm của k. Khi
chúng ta giữ ngày càng nhiều tham số, xung đột dấu tăng và đạt gần 80%. Điều này cũng được mong đợi
vì có nhiều tham số khác không hơn có thể tạo ra xung đột ngay cả khi độ lớn của chúng nhỏ.

B.4 Xung đột Dấu Tồn tại Giữa Các Checkpoint Khác nhau cho cùng Nhiệm vụ
Trong Hình 10, chúng tôi chỉ ra rằng xung đột dấu tồn tại ngay cả trong các mô hình được huấn luyện trên
cùng một nhiệm vụ. Chúng tôi vẽ biểu đồ xung đột dấu (tương tự như Hình 4) giữa 10 checkpoint của RTE,
MRPC, và WNLI từ Huggingface. Khi số lượng checkpoint tăng, xung đột dấu tăng. Chúng tôi cũng so sánh
điều này với can thiệp dấu khi hợp nhất các checkpoint nhiệm vụ khác nhau và thấy mức độ can thiệp tương
tự trong tất cả các trường hợp này. Do đó, xung đột dấu tồn tại ngay cả trong các mô hình được huấn luyện
trên cùng một tập dữ liệu. Chúng tôi nghi ngờ rằng điều này là do các mô hình có quá nhiều tham số và do
đó có nhiều mạng con (tập con tham số) có thể dẫn đến cùng một hiệu suất nơi các lần chạy tinh chỉnh khác
nhau cập nhật cùng các tham số theo các hướng khác nhau.

--- TRANG 19 ---
0 1 >100.050.10.15Trung bình Cắt tỉa + Trung bình Rời rạc TIES
Tham số với giá trị khác khôngĐộ lớn Trung bình
(a) Can thiệp Tham số Dư thừa cho (IA)3 với
STD.

0.5-0.60.6-0.70.7-0.80.8-0.90.9-1.000.050.10.150.20.25Trung bình
Bầu chọn + Trung bình Rời rạc
TIES
Khoảng Thỏa thuận DấuĐộ lớn Trung bình (b) Can thiệp Dấu cho (IA)3 với STD.

Hình 11: Tác động của các loại Hợp nhất khác nhau đối với Độ lớn của Tham số. Ở đây chúng
tôi bổ sung so sánh với TIES-MERGING và cũng cung cấp độ lệch chuẩn của giá trị tham số. STD
cao có nghĩa là có một số đa dạng trong giá trị độ lớn trên các tham số khác nhau.

2 3 4 5 6 700.050.10.150.2
Số lượng Mô hìnhTỷ lệ Tham số 
 với Xung đột
(a) Tỷ lệ Tham số với
Xung đột dấu cho mô hình T5-Base
so với số lượng mô hình.

0 1 >100.0020.0040.006Trung bình Cắt tỉa + Trung bình Rời rạc TIES
Tham số với giá trị khác khôngĐộ lớn Trung bình
(b) Can thiệp Tham số Dư thừa
cho T5-Base với STD.

0.5-0.60.6-0.70.7-0.80.8-0.90.9-1.000.0020.0040.006Trung bình
Bầu chọn + Trung bình Rời rạc
TIES
Khoảng Thỏa thuận DấuĐộ lớn Trung bình
(c) Can thiệp Dấu cho mô hình
T5-Base với STD.

Hình 12: Biểu đồ cho mô hình T5-Base.

Phương pháp Xác thực Trung bình rte cb winogrande wic wsc copa h-swag story cloze anli-r1 anli-r2 anli-r3
Zeroshot - 55.3 79.8 46.4 52.8 54.1 45.2 85 36.1 91 39.7 37.6 40.5
Tinh chỉnh - 71.4 82.7 95.8 75.1 71.7 65.3 85.3 44.4 94.9 70.2 46.5 53
Đa nhiệm vụ (Tất cả, từ đầu) - 73.1 88.6 95.8 75.5 61.1 80.6 94.1 42.3 97.6 70.5 49.8 47.7
Đa nhiệm vụ (32, từ đầu) - 60.9 74.9 79.2 59.3 49.2 63.9 80.9 39.5 91.6 49.4 41.9 40.1
Đa nhiệm vụ (32, trung bình) - 65.2 79.8 83.3 61.6 54.2 66.7 85.3 41.1 94.4 58.1 46.0 46.5
Lấy trung bình ✗ 58 81.2 58.3 53.8 55.2 53.5 80.9 40.1 92.5 43.3 39.2 40.2
Task Arithmetic ✗ 59.2 76.5 79.2 57.7 51.6 51.4 66.2 31.4 81.5 59.8 47.5 48.2
TIES-MERGING ✗ 64.9 81.2 87.5 60.8 59.9 58.3 80.2 42.6 91.1 58.1 46.5 47.4
Fisher Merging ✓ 62.2 83.3 83.3 56.7 54.2 58.3 83.1 42.2 94.1 45.9 41.0 42.2
RegMean ✓ 58 81.2 58.3 53.8 55.2 53.5 80.9 40.1 92.5 43.3 39.2 40.2
Task Arithmetic ✓ 63.9 74.1 83.3 62.8 49.1 49.3 87.5 41.5 95.3 60.8 49.4 50.0
TIES-MERGING ✓ 66.4 78.0 83.3 67.9 57.6 59.7 81.7 42.8 90.3 66.9 51.3 51.1

Bảng 8: Hiệu suất tập kiểm tra khi hợp nhất các mô hình IA3 trên mười một nhiệm vụ. Vui lòng
tham khảo Phần 6 để biết chi tiết thí nghiệm.

B.5 Kết quả Chi tiết cho Các Loại Can thiệp và Tác động của chúng đối với Hợp nhất
Trong Phần 7.1 và Hình 6, chúng tôi đã chỉ ra tác động của các tham số dư thừa và xung đột dấu đối với
độ lớn tham số khi so sánh lấy trung bình đơn giản so với trung bình rời rạc sau khi cắt tỉa hoặc bầu chọn
và chỉ ra rằng việc thực hiện các phép toán này giúp với độ lớn tham số. Trong Hình 11, chúng tôi bổ sung
so sánh với TIES-MERGING và chỉ ra rằng việc thực hiện cả cắt tỉa và bầu chọn thường dẫn đến độ lớn
cao hơn và cũng độ lệch chuẩn cao hơn trong độ lớn tham số. STD cao hơn biểu thị rằng tất cả các giá trị
tham số trong mô hình đã hợp nhất đều giống nhau và có sự biến đổi đáng kể về độ lớn trái ngược với lấy
trung bình đơn giản vì nó làm giảm độ lớn của các tham số không dư thừa và giảm độ lớn của các tham số
có ảnh hưởng trong mô hình đã hợp nhất. Các biểu đồ tương tự cho mô hình T5-base được cung cấp trong
Hình 12.

--- TRANG 20 ---
B.6 Kết quả Cấp độ Nhiệm vụ Toàn diện
Chúng tôi cung cấp cấp độ nhiệm vụ cho tất cả các thí nghiệm đánh giá trong miền trong Bảng 1 chính. Bảng
8, 9, 10, 11, và 12 cung cấp kết quả cấp độ nhiệm vụ cho IA3 [43], T5-Base, T5-Large [58], ViT-B/32, và
ViT-L/14 [14] tương ứng. Kết quả cấp độ nhiệm vụ của các thí nghiệm ngoài miền cho T5-Base và T5-Large
có thể được tìm thấy trong Bảng 13, và 14. Cuối cùng, Hình 13, cho thấy sự mở rộng của mô hình T5-Base
khi chúng tôi hợp nhất số lượng nhiệm vụ khác nhau.

Phương pháp Xác thực Trung bình paws qasc quartz story_cloze wiki_qa winogrande wsc
Zeroshot - 53.5 49.9 35.8 53.3 48.1 76.2 50 61.1
Tinh chỉnh - 82.8 94.3 98.3 80.4 84.7 95.5 64.1 62.5
Đa nhiệm vụ - 83.6 94 97.9 82.5 86.7 95 64.1 65.3
Lấy trung bình ✗ 65.9 66.4 82.6 60.2 49.5 94.1 50.4 58.3
Task Arithmetic ✗ 73.9 73.3 93.5 68.2 76.5 93.7 55.5 56.9
TIES-MERGING ✗ 69.7 74 83.3 70.3 64.2 84.7 55.9 55.6
Fisher Merging ✓ 68.9 69.3 85.7 63.6 56.4 93.8 50.9 62.5
RegMean ✓ 71.2 76.8 96.2 62.5 55 94.8 51.9 61.1
Task Arithmetic ✓ 73.2 73.4 93.3 67.1 71.7 94.1 52.9 59.7
TIES-MERGING ✓ 73.9 79.3 88.6 71.8 72.9 82.5 61.3 61.1

Bảng 9: Hiệu suất tập kiểm tra khi hợp nhất các mô hình T5-base trên bảy nhiệm vụ. Vui lòng
tham khảo Phần 6 để biết chi tiết thí nghiệm.

Phương pháp Xác thực Trung bình paws qasc quartz story_cloze wiki_qa winogrande wsc
Zeroshot - 51.7 55.4 14.3 54.1 54.1 71 49.3 63.9
Tinh chỉnh - 88.8 94.4 98.9 87.8 90.8 96 74.7 79.2
Đa nhiệm vụ - 88.1 94.2 98.5 89.3 92 95.4 73.5 73.6
Lấy trung bình ✗ 59.6 61.3 82.6 70.5 53.7 63.2 49.7 36.1
Task Arithmetic ✗ 73.5 79.2 96.8 80.2 83.6 58.6 60.2 55.6
TIES-MERGING ✗ 74.4 80.5 96.2 81.8 78.6 62 61.9 59.7
Fisher Merging ✓ 64.6 60.4 81.7 75 60.1 88.6 50 36.1
RegMean ✓ 73.2 86 96.9 80.7 78.6 82.6 51.8 36.1
Task Arithmetic ✓ 73.3 77.8 96 78.6 86.4 59.1 62.3 52.8
TIES-MERGING ✓ 76.9 81.5 96.2 80.1 83.6 64.9 66.5 65.3

Bảng 10: Hiệu suất tập kiểm tra khi hợp nhất các mô hình T5-large trên bảy nhiệm vụ. Vui lòng
tham khảo Phần 6 để biết chi tiết thí nghiệm.

Phương pháp Xác thực Trung bình SUN397 Cars RESISC45 EuroSAT SVHN GTSRB MNIST DTD
Cá nhân - 90.5 75.3 77.7 96.1 99.7 97.5 98.7 99.7 79.4
Đa nhiệm vụ - 88.9 74.4 77.9 98.2 98.9 99.5 93.9 72.9 95.8
Lấy trung bình ✗ 65.8 65.3 63.4 71.4 71.7 64.2 52.8 87.5 50.1
Task Arithmetic ✗ 60.4 36.7 41 53.8 64.4 80.6 66 98.1 42.5
TIES-MERGING ✗ 72.4 59.8 58.6 70.7 79.7 86.2 72.1 98.3 54.2
Fisher Merging ✓ 68.3 68.6 69.2 70.7 66.4 72.9 51.1 87.9 59.9
RegMean ✓ 71.8 65.3 63.5 75.6 78.6 78.1 67.4 93.7 52
Task Arithmetic ✓ 70.1 63.8 62.1 72 77.6 74.4 65.1 94 52.2
TIES-MERGING ✓ 73.6 64.8 62.9 74.3 78.9 83.1 71.4 97.6 56.2

Bảng 11: Hiệu suất tập kiểm tra khi hợp nhất các mô hình ViT-B/32 trên tám nhiệm vụ. Vui lòng
tham khảo Phần 6 để biết chi tiết thí nghiệm.

C Chi tiết Triển khai
C.1 Tài nguyên Tính toán Được sử dụng và Thời gian Chạy
Chúng tôi thực hiện tất cả các thí nghiệm trên GPU Nvidia A6000 được trang bị 48GB RAM. Các mô hình
(IA)3 một nhiệm vụ cho mười một nhiệm vụ cần 1-2 giờ mỗi mô hình, trong khi vector đa nhiệm vụ mất
khoảng 24 giờ trên bốn GPU. Các mô hình T5-Base và T5-Large, dựa trên kích thước tập dữ liệu, cần
giữa 15 phút và 2 giờ mỗi nhiệm vụ, và khoảng tám giờ cho checkpoint đa nhiệm vụ. Thị giác

--- TRANG 21 ---
Phương pháp Xác thực Trung bình SUN397 Cars RESISC45 EuroSAT SVHN GTSRB MNIST DTD
Tinh chỉnh - 94.2 82.3 92.4 97.4 100 98.1 99.2 99.7 84.1
Đa nhiệm vụ - 93.5 90.6 84.4 99.2 99.1 99.6 96.3 80.8 97.6
Lấy trung bình ✗ 79.6 72.1 81.6 82.6 91.9 78.2 70.7 97.1 62.8
Task Arithmetic ✗ 83.3 72.5 79.2 84.5 90.6 89.2 86.5 99.1 64.3
TIES-MERGING ✗ 86 76.5 85 89.3 95.7 90.3 83.3 99 68.8
Fisher Merging ✓ 82.2 69.2 88.6 87.5 93.5 80.6 74.8 93.3 70
RegMean ✓ 83.7 73.3 81.8 86.1 97 88 84.2 98.5 60.8
Task Arithmetic ✓ 84.5 74.1 82.1 86.7 93.8 87.9 86.8 98.9 65.6
TIES-MERGING ✓ 86 76.5 85 89.4 95.9 90.3 83.3 99 68.8

Bảng 12: Hiệu suất tập kiểm tra khi hợp nhất các mô hình ViT-L/14 trên tám nhiệm vụ. Vui lòng
tham khảo Phần 6 để biết chi tiết thí nghiệm.

các mô hình ViT-B/32 và ViT-L/14 được sử dụng, như được cung cấp bởi Ilharco et al. [29].2 Các thí
nghiệm hợp nhất hiệu quả, với đánh giá tiêu tốn ít hơn 2 phút cho các thí nghiệm T5-Base, T5-Large, ViT-
B/32, và ViT-L/14. Việc đánh giá các mô hình (IA)3, do cần thiết phải sử dụng nhiều mẫu từ nguồn nhắc
và tính toán kết quả trung vị trên tất cả các mẫu, cần khoảng một giờ mỗi đánh giá 11 tập dữ liệu.

Mô hình Trung bình cosmos_qa social_iqa quail wic copa h-swag
PA WS 35.9 18.8 25 24.8 68.8 56.2 21.9
QASC 34.9 15.6 21.9 25.1 75 53.1 18.8
QUARTZ 37.4 31.2 18.8 24.3 71.9 59.4 18.8
Story Cloze 35 6.2 25 25.6 75 65.6 12.5
Wiki QA 24.5 18.8 21.9 24.9 28.1 43.8 9.4
Winogrande 28.3 18.8 25 25.7 34.4 43.8 21.9
WSC 31.7 21.9 21.9 24.6 62.5 46.9 12.5
Đã huấn luyện trước 31.1 21.9 18.8 24.1 65.6 43.8 12.5
Lấy trung bình 31.7 21.9 21.9 24.6 68.8 37.5 15.6
Fisher Merging 33.8 15.6 21.9 24.9 65.6 53.1 21.9
Task Arithmetic 31.9 15.6 31.2 25.7 28.1 68.8 21.9
RegMean 34.3 23.1 28.1 24.9 48.4 62.5 18.8
TIES-MERGING 35.3 21.9 25 25.7 50 65.6 23.8

Bảng 13: Hiệu suất Ngoài Phân phối của các checkpoint mô hình T5-Base trên sáu nhiệm vụ. Vui
lòng tham khảo Phần 6 để biết chi tiết thí nghiệm.

C.2 Các Tập dữ liệu Được sử dụng và Giấy phép Liên quan
Chúng tôi sử dụng các tập dữ liệu sau trong bài báo với các giấy phép sau. ANLI [49], WiC [53], WSC
[37], và Story Cloze [68], QuaRTz [73], Cars [35], GTSRB [71] thuộc Giấy phép Creative Commons.
Winogrande [64], QASC [33] thuộc giấy phép Apache. COPA [61] thuộc giấy phép BSD-2 Clause. H-
SWAG [88], EuroSAT [24], thuộc Giấy phép MIT. MNIST [36] thuộc Giấy phép Công cộng Gnu General.
Chúng tôi không thể tìm thấy giấy phép của DTD [10], RESISC45 [8], SUN397 [84], SVHN [47], CB [44],
RTE [11]), và PAWS [90] nhưng chúng có sẵn công khai cho mục đích nghiên cứu.

C.3 Chi tiết của Các Thí nghiệm Động lực
Đối với cả Hình 3, và 4 trong Phần 3, chúng tôi thực hiện thí nghiệm trên mười một mô hình (IA)3 được
sử dụng trong các thí nghiệm hợp nhất PEFT của chúng tôi (§ 6). Đối với Hình tương tự như Hình 4 chứng
minh tỷ lệ các tham số có xung đột dấu cho mô hình T5-base, vui lòng tham khảo Hình 12a.

2https://github.com/mlfoundations/task_vectors#checkpoints
21

--- TRANG 22 ---
Mô hình Trung bình cosmos_qa social_iqa quail wic copa h-swag
PA WS 32.3 25 28.1 25.6 56.2 46.9 12.5
QASC 33.4 21.9 28.1 25.5 43.8 62.5 18.8
QUARTZ 28.7 25 25 25.1 25 53.1 18.8
Story Cloze 32.1 21.9 34.4 26.8 46.9 53.1 9.4
Wiki QA 27.1 25 28.1 25.2 28.1 46.9 9.4
Winogrande 32.4 31.2 18.8 25.6 43.8 62.5 12.5
WSC 29.7 25 25 25.1 37.5 56.2 9.4
Đã huấn luyện trước 27.6 21.9 21.9 24.9 28.1 56.2 12.5
Lấy trung bình 30.4 31.2 25 26.3 31.2 59.4 9.4
Fisher Merging 32 34.4 25 26.1 40.6 56.2 9.4
Task Arithmetic 33.3 21.9 34.4 24.6 40.6 59.4 18.8
RegMean 36 34.4 28.1 25.3 62.5 50 15.6
TIES-MERGING 40.4 31.2 43.8 26.6 59.4 59.4 21.9

Bảng 14: Hiệu suất Ngoài Phân phối của các checkpoint mô hình T5-Large trên sáu nhiệm vụ. Vui
lòng tham khảo Phần 6 để biết chi tiết thí nghiệm.

2 3 4 5 6 70.70.80.911.1
Lấy trung bình Đơn giản Task Arithmetic TIES
Số lượng Nhiệm vụHiệu suất Chuẩn hóa Trung bình

Hình 13: T5-Base với số lượng nhiệm vụ được hợp nhất tăng dần. Hiệu suất trung bình khi hợp
nhất số lượng nhiệm vụ khác nhau.

C.4 Hợp nhất trong trường hợp vắng mặt Tập Xác thực
Trong cuộc điều tra của chúng tôi về các tình huống không có tập xác thực, chúng tôi đã đề ra một công thức
và xác định các siêu tham số tối ưu, sử dụng quy trình thí nghiệm PEFT được mô tả chi tiết trong Phần 6.
Cách tiếp cận này được áp dụng cho mười một mô hình đặc trưng cho từng nhiệm vụ được trình bày trong
cùng phần đó, sử dụng phương pháp TIES-MERGING để điều chỉnh các siêu tham số. Ước tính sơ bộ của
chúng tôi cho các siêu tham số là k = 20 và λ gần 1. Tìm kiếm siêu tham số được thực hiện bằng cách sử
dụng mười một mô hình (IA)3 đặc trưng cho từng nhiệm vụ, với k ∈ {10,20,30}, và λ trải dài từ 0.8 đến
3.0, theo từng bước 0.1. Kết quả của tìm kiếm toàn diện này chỉ ra giá trị tối ưu k = 20, với các giá trị λ =
0.9, λ = 1.0, và λ = 1.1 thể hiện hiệu suất tương đương. Để duy trì sự đơn giản trong mô hình của chúng
tôi, chúng tôi chọn giá trị λ là 1. Do đó, lựa chọn cuối cùng của các tham số cho TIES-MERGING là k = 20,
dấu dựa trên khối lượng, trung bình rời rạc, và giá trị λ là 1.

C.5 Hợp nhất Số lượng Nhiệm vụ Khác nhau
Ở đây chúng tôi cung cấp một số chi tiết bổ sung về các thí nghiệm khi hợp nhất số lượng nhiệm vụ khác
nhau. Trong Hình 5, chúng tôi thực hiện thí nghiệm với T5-Large khi hợp nhất bảy nhiệm vụ được xem xét
trong Bảng 1 và được mô tả trong Phần 6. Trục x cho thấy số lượng nhiệm vụ khác nhau được hợp nhất.
Lưu ý rằng khi hợp nhất T nhiệm vụ, chúng ta có tổng cộng (7 trên T) tổ hợp. Tuy nhiên, trong thí nghiệm
của chúng tôi, chúng tôi lấy mẫu tối đa 10 tổ hợp riêng biệt cho mỗi giá trị T. Một biểu đồ tương tự cho
mô hình T5-Base được hiển thị trong Hình 13.

--- TRANG 23 ---
Trong Hình 5, cho mỗi số lượng nhiệm vụ chúng tôi lấy tối đa 10 tập con ngẫu nhiên của 8 nhiệm vụ mà
chúng tôi đang xem xét. Đường liền là trung bình của hiệu suất mô hình đã hợp nhất từ các lần chạy khác
nhau này. Dưới đây chúng tôi cung cấp các giá trị λ tối ưu cho các tập con khác nhau của các nhiệm vụ mà
chúng tôi hợp nhất cho cả TIES-MERGING và Task Arithmetic, lưu ý rằng đối với lấy trung bình λ = 1/#nhiệm vụ luôn luôn. Mỗi mục trong danh sách là λ tối ưu cho một tập con cụ thể của các nhiệm vụ được
chọn trên tập xác thực.

(2 nhiệm vụ) TIES →[1.7, 1.9, 2, 2, 1.1, 1.5, 1.6, 1.8, 1.9, 1., 5]
(2 nhiệm vụ) Task Arithmetic →[1, 0.9, 1, 1, 0.9, 1, 0.9, 0.9, 0.9, 1]
(3 nhiệm vụ) TIES →[1.2, 2, 1.5, 1.9, 1.8, 1.7, 1.4, 2, 3, 1.9]
(3 nhiệm vụ) Task Arithmetic →[1, 0.7, 0.7, 1, 1, 0.9, 0.7, 0.7, 0.9, 1]
(4 nhiệm vụ) TIES →[1.5, 1.3, 1.3, 1.8, 2.3, 1.7, 1.8, 1.7, 1.9, 1.5]
(4 nhiệm vụ) Task Arithmetic →[0.8, 0.7, 0.7, 0.7, 0.6, 0.7, 0.7, 0.8, 0.6, 0.7]
(5 nhiệm vụ) TIES →[2, 2, 2, 1.8, 1.7, 2, 1.6, 2.1, 1.6, 1.3]
(5 nhiệm vụ)Task Arithmetic →[0.7, 0.8, 0.6, 0.8, 0.7, 0.6, 0.6, 0.6, 0.6, 0.7]
(6 nhiệm vụ) TIES →[1.6, 1.7, 1.7, 1.2, 1.7, 1.7, 1.5]
(6 nhiệm vụ) Task Arithmetic →[0.6, 0.5, 0.5, 0.5, 0.7, 0.5, 0.6]
(7 nhiệm vụ) TIES →[1.7]
(7 nhiệm vụ) Task Arithmetic →[0.5]

C.6 Chi tiết Huấn luyện
Trong nghiên cứu của chúng tôi, chúng tôi sử dụng hai biến thể của mô hình T5, cụ thể là các mô hình T5-
base và T5-large, được huấn luyện tối đa 75,000 bước. Kích thước batch huấn luyện hiệu quả là 1024 được
triển khai, cùng với tốc độ học (lr) là 0.0001. Chúng tôi thiết lập cơ chế dừng sớm với ngưỡng kiên nhẫn
là 5 để ngăn chặn overfitting. Trong quá trình huấn luyện, bfloat16 được áp dụng để giảm chi phí bộ nhớ
GPU, và độ dài chuỗi tối đa được đặt ở 128. Ngược lại, đối với cấu hình PEFT của phương pháp (IA)3 trên
mô hình T0-3B, chúng tôi điều chỉnh các tham số của mình. Kích thước batch huấn luyện hiệu quả là 16
được triển khai cùng với kích thước batch đánh giá là 32, trong khi duy trì tốc độ học ở 0.0001. Để phù
hợp với độ phức tạp của mô hình, kiên nhẫn dừng sớm được tăng lên 10. Chúng tôi không sử dụng bất kỳ
bộ lập lịch lr và weight decay nào cho việc huấn luyện mô hình của chúng tôi.

Đối với mục đích đánh giá, chúng tôi thực hiện phân loại xếp hạng. Trong phương pháp này, xác suất log
của mô hình cho tất cả các chuỗi nhãn tiềm năng được xếp hạng. Dự đoán của mô hình được coi là chính
xác nếu lựa chọn được xếp hạng cao nhất phù hợp với câu trả lời đúng. Cần lưu ý rằng đánh giá phân loại
xếp hạng có thể phù hợp với cả nhiệm vụ phân loại và nhiệm vụ trắc nghiệm.
23

LM-Cocktail: Tăng cường Khả năng Phục hồi của Mô hình Ngôn ngữ thông qua Kết hợp Mô hình
Shitao Xiao♠Zheng Liu♠∗Peitian Zhang♠Xingrun Xing♣
♠Beijing Academy of Artificial Intelligence
♣Institute of Automation, Chinese Academy of Sciences
stxiao@baai.ac.cn {zhengliu1026,namespace.pt}@gmail.com
xingxingrun2023@ia.ac.cn
Tóm tắt
Các mô hình ngôn ngữ được huấn luyện trước liên tục được tinh chỉnh để hỗ trợ tốt hơn cho các ứng dụng hạ nguồn. Tuy nhiên, hoạt động này có thể dẫn đến sự suy giảm hiệu suất đáng kể trên các tác vụ chung ngoài miền mục tiêu. Để khắc phục vấn đề này, chúng tôi đề xuất LM-Cocktail cho phép mô hình được tinh chỉnh duy trì khả năng phục hồi trong các quan điểm chung. Phương pháp của chúng tôi được thực hiện dưới dạng kết hợp mô hình, trong đó mô hình ngôn ngữ được tinh chỉnh được kết hợp với mô hình cơ sở được huấn luyện trước hoặc các mô hình đồng cấp từ các miền khác thông qua trung bình có trọng số. Mặc dù đơn giản, LM-Cocktail lại hiệu quả đáng ngạc nhiên: mô hình kết quả có thể đạt được hiệu suất thực nghiệm mạnh trong toàn bộ phạm vi các tác vụ chung trong khi vẫn duy trì khả năng vượt trội trong miền mục tiêu của nó. Chúng tôi thực hiện các thí nghiệm toàn diện với các mô hình LLama và BGE trên các benchmark phổ biến, bao gồm FLAN, MMLU, MTEB, có kết quả xác thực hiệu quả của phương pháp được đề xuất. Mã nguồn và checkpoint có sẵn tại
https://github.com/FlagOpen/FlagEmbedding.

1 Giới thiệu
Các mô hình ngôn ngữ (LM) là những trụ cột cơ bản của trí tuệ nhân tạo và xử lý ngôn ngữ tự nhiên. Nhờ vào sự mở rộng đáng kể về quy mô huấn luyện và kích thước mô hình (Devlin et al., 2018; Liu et al., 2019; Raffel et al., 2020; Radford et al., 2019; Brown et al., 2020), các mô hình ngôn ngữ đã đạt được những đột phá đáng chú ý trên nhiều loại tác vụ NLP, bao gồm biểu diễn, hiểu biết, suy luận và sinh tạo. Trong những năm gần đây, các mô hình ngôn ngữ đã được sử dụng như một khối xây dựng quan trọng cho nhiều ứng dụng, chẳng hạn như truy xuất thông tin, hệ thống hội thoại và các tác nhân AI tự động. Trong nhiều ứng dụng, các mô hình ngôn ngữ thường được sử dụng thông qua mô hình "huấn luyện trước và tinh chỉnh". Cụ thể, một LM đa năng được huấn luyện trước ở giai đoạn đầu thông qua quá trình học tập không giám sát hoặc có giám sát mục đích chung (Brown et al., 2020; Touvron et al., 2023; Wei et al., 2022, 2021; Ouyang et al., 2022); sau đó, mô hình đa năng được huấn luyện trước được tinh chỉnh để trở thành mô hình chuyên gia cho một tác vụ hạ nguồn dựa trên dữ liệu trong miền nhất định.

Mặc dù cải thiện hiệu suất trong từng ứng dụng cụ thể, hoạt động tinh chỉnh có thể dẫn đến sự suy giảm nghiêm trọng khả năng chung của LM ngoài miền mục tiêu. Hiện tượng như vậy thường được gọi là quên thảm khốc (Goodfellow et al., 2013; Kirkpatrick et al., 2017; Thompson et al., 2019; Chen et al., 2020). Như được hiển thị trong Hình 1, tinh chỉnh mô hình Llama trên tác vụ mục tiêu có thể cải thiện đáng kể hiệu suất của nó trên tác vụ mục tiêu, nhưng làm giảm hiệu suất của nó trên các tác vụ không liên quan khác. Trong nhiều tình huống thực tế, quên thảm khốc là không mong muốn vì các mô hình ngôn ngữ cần thể hiện cả đặc điểm chuyên gia và đa năng đồng thời (Roziere et al., 2023; Chen et al., 2021; Singhal et al., 2022).

Cuộc chiến chống lại quên thảm khốc đại diện cho một chiến dịch bền bỉ trong cộng đồng học máy, nơi nhiều phương pháp đã được liên tục đề xuất trong những năm gần đây. Có hai chiến lược đại diện được áp dụng rộng rãi như logic thiết kế bởi nhiều phương pháp hiện có. Một chiến lược là dựa vào phát lại trải nghiệm, trong đó mô hình được học với dữ liệu huấn luyện hỗn hợp từ cả tác vụ mới và các tác vụ trước đó (Rolnick et al., 2019; Shin et al., 2017). Chiến lược khác là tận dụng chính quy hóa, trong đó các thay đổi trong dự đoán hoặc trọng số được chính quy hóa giữa mô hình được tinh chỉnh mới và mô hình được huấn luyện trước lịch sử (Kirkpatrick et al., 2017; Li and Hoiem, 2017; Rannen et al., 2017). Tuy nhiên, vẫn cần khám phá các phương pháp hiệu quả hơn trong bối cảnh các mô hình ngôn ngữ được tinh chỉnh với các ràng buộc thực tế của các phương pháp hiện có. Một mặt, việc thu thập đầy đủ các mẫu huấn luyện cho tất cả các tác vụ trước đó là không khả thi, và có mô hình được huấn luyện lại trên dữ liệu lịch sử một khi một tác vụ mới được trình bày. Mặt khác, chính quy hóa có thể dẫn đến những thay đổi lớn đối với các hoạt động tinh chỉnh hiện có, có thể không tương thích với quy trình tinh chỉnh đã được thiết lập.

Trong công trình này, chúng tôi nhằm thiết kế một khung hiệu quả để đối phó với quên thảm khốc, điều này sẽ cho phép các mô hình ngôn ngữ được tinh chỉnh duy trì khả năng phục hồi trong các tác vụ chung. Bên cạnh đó, chúng tôi cũng mong đợi khung mới sẽ thực tế hơn, có nghĩa là nó phải đơn giản để thực hiện và hoàn toàn tương thích với quy trình huấn luyện mô hình thông thường.

Với những cân nhắc này, chúng tôi đề xuất một phương pháp mới, được gọi là LM-Cocktail, liên tục thích ứng các mô hình ngôn ngữ được tinh chỉnh tốt dựa trên kết hợp mô hình (Wortsman et al., 2022a). LM-Cocktail là một mô hình chung, có thể hoạt động trong một số điều kiện khác nhau. Ở dạng đơn giản nhất, nó trực tiếp kết hợp mô hình được tinh chỉnh với mô hình cơ sở được huấn luyện trước để cải thiện khả năng chung của mô hình được tinh chỉnh. Nó có thể tiếp tục chứa nhiều mô hình đồng cấp được tinh chỉnh cho các miền chung khác, và dẫn đến hiệu suất thực nghiệm mạnh hơn dựa trên trọng số kết hợp được ước tính bởi các ví dụ xác thực few-shot. Cuối cùng, ngay cả khi không có dữ liệu tinh chỉnh, chiến lược kết hợp vẫn có thể được áp dụng cho mô hình cơ sở được huấn luyện trước còn lại và các mô hình được tinh chỉnh trong các miền chung khác để có khả năng phục hồi cạnh tranh.

Phương pháp được đề xuất của chúng tôi dẫn đến một số lợi thế tức thời với cơ chế hoạt động của nó. Trước hết, LM-Cocktail cực kỳ đơn giản: các trọng số kết hợp có thể được suy ra trực tiếp từ các mẫu xác thực mà không cần các hoạt động huấn luyện tốn kém. Thứ hai, LM-Cocktail hoàn toàn tương thích với quy trình huấn luyện hiện có, biết rằng nó chỉ đơn giản hoạt động như một bước tinh chỉnh sau quá trình tinh chỉnh. Trên hết, LM-Cocktail có tính cạnh tranh thực nghiệm. Theo đánh giá của chúng tôi trên ba benchmark đại diện, bao gồm FLAN (Wei et al., 2021), MMLU (Hendrycks et al., 2020), và MTEB (Muennighoff et al., 2022), LM-Cocktail đạt được khả năng phục hồi mạnh trong các tác vụ miền chung trong khi duy trì hiệu suất tinh chỉnh vượt trội trên miền mục tiêu của nó. Cuối cùng, LM-Cocktail hóa ra có thể áp dụng một cách phổ quát: nó có thể đóng góp đáng kể cho cả LM dựa trên decoder trong các tác vụ sinh ngôn ngữ và LM dựa trên encoder trong các tác vụ biểu diễn ngôn ngữ.

2 LM-Cocktail
2.1 Mô hình Chung
Như một điều kiện tiên quyết, chúng ta được cung cấp một mô hình ngôn ngữ cơ sở, ký hiệu là Mb, được huấn luyện trước tốt cho các ứng dụng chung. Các ví dụ điển hình của mô hình cơ sở có thể là Llama-Chat (Touvron et al., 2023) và FLAN-PaLM (Chung et al., 2022), đó là các LLM được học từ việc học không giám sát quy mô lớn và tinh chỉnh có giám sát mục đích chung. LM cơ sở được tinh chỉnh liên tục để hỗ trợ một tác vụ hạ nguồn mục tiêu (t) với các mẫu huấn luyện Xt cụ thể theo miền, điều này dẫn đến mô hình được tinh chỉnh cho tác vụ tương ứng: Mt.

Tuy nhiên, mô hình được tinh chỉnh Mt dễ bị suy giảm hiệu suất thực nghiệm (quên thảm khốc) trên các miền chung khác ngoài miền mục tiêu t. Mục tiêu của LM-Cocktail là duy trì khả năng chung khi tinh chỉnh trên tác vụ mục tiêu. Cốt lõi của LM-Cocktail là kết hợp nhiều mô hình (với cùng kiến trúc nhưng trọng số khác nhau) thành một mô hình thống nhất bằng cách tổng hợp trọng số từ các mô hình khác nhau. Theo cách này, mô hình được tinh chỉnh có khả năng phục hồi có thể tích hợp những điểm mạnh từ nhiều mô hình riêng lẻ.

Để suy ra chiến lược kết hợp mô hình thích hợp cho LM-Cocktail, có hai vấn đề cơ bản cần giải quyết: 1) nhóm mô hình ứng viên nào để kết hợp, 2) cách xác định trọng số kết hợp. Biết rằng LM được tinh chỉnh có khả năng phục hồi là để khôi phục các hiệu suất bị suy giảm trong các miền chung, có hai nguồn mô hình ứng viên để xem xét. Một nguồn là mô hình cơ sở được huấn luyện trước Mb, nguồn khác là toàn bộ nhóm các mô hình được tinh chỉnh trong các miền khác ({Md}D). Không mất tính tổng quát, chúng tôi suy ra dạng hàm kết hợp sau:

Mr←αMt+ (1−α)X Mb,{M d}Dwi∗ M i,(1)

trong đó Mr là mô hình được tinh chỉnh có khả năng phục hồi, α là một siêu tham số có giá trị mặc định là 0.5, và wi chỉ ra trọng số kết hợp đã được chuẩn hóa: P iwi= 1. Đối với trường hợp của chúng tôi, chúng tôi yêu cầu mô hình được tinh chỉnh có khả năng phục hồi duy trì khả năng mạnh như mô hình được tinh chỉnh trực tiếp trong miền mục tiêu của nó trong khi cải thiện hiệu suất miền chung. Do đó, hiệu suất của các mô hình ứng viên trong miền mục tiêu là các chỉ số quan trọng của trọng số kết hợp. Dựa trên trực giác này, chúng tôi giới thiệu dạng tính toán trọng số sau:

wi←softmax( −L(Mi, Et)/τ). (2)

Trong hàm này, L(Mi, Et) đại diện cho tổn thất dự đoán của mô hình ứng viên Mi trên các ví dụ few-shot Et từ miền mục tiêu t, τ là nhiệt độ để kiểm soát độ mượt. Điều đó có nghĩa là, tổn thất càng lớn trên miền mục tiêu, trọng số được phân bổ cho mô hình ứng viên càng nhỏ. Vì vậy chúng ta có thể cung cấp hệ số thấp hơn cho các mô hình hoạt động rất kém trong tác vụ mục tiêu. Các ví dụ few-shot là một nhóm nhỏ các mẫu giữ lại từ miền mục tiêu. Theo nghiên cứu thực nghiệm của chúng tôi, 5-shot ví dụ đã đủ cạnh tranh trong các cài đặt khác nhau.

2.2 Biến thể
Dạng chung của LM-Cocktail trong Eq 1 yêu cầu sự hiện diện của ba yếu tố: mô hình cơ sở Mb, mô hình được tinh chỉnh cho miền mục tiêu Mt, và các mô hình được tinh chỉnh trong các miền chung khác {Md}D. Tuy nhiên, yêu cầu chung có thể được nới lỏng đáng kể để phù hợp với các cài đặt thực tế khác nhau. Ở đây, chúng tôi giới thiệu hai dạng biến thể phổ biến để đối phó với các tình huống mà các chuyên gia miền chung đa dạng hoặc tinh chỉnh miền mục tiêu không có sẵn.

•Chuyên gia Đơn. Khi các mô hình được tinh chỉnh đa dạng trong các miền chung không có mặt, hàm kết hợp được đơn giản hóa thành sự kết hợp của mô hình cơ sở Mb và mô hình chuyên gia đơn từ miền mục tiêu Mt:

Mr←αMt+ (1−α)Mb. (3)

Cho rằng mô hình được tinh chỉnh Mt thường thể hiện tổn thất thấp hơn đáng kể so với các mô hình khác, chúng tôi đã không sử dụng Eqn 2 để tính trọng số; thay vào đó, chúng tôi giới thiệu một siêu tham số α. Kết quả thực nghiệm chứng minh rằng việc đơn giản đặt α thành 0.5 mang lại kết quả đầy hứa hẹn.

•Không có Tinh chỉnh. Tinh chỉnh trong miền mục tiêu có thể bị hạn chế do thiếu dữ liệu cụ thể theo miền hoặc tài nguyên tính toán. Trong tình huống này, hàm kết hợp được chuyển đổi thành sự kết hợp của mô hình cơ sở và mô hình được tinh chỉnh từ các miền chung:

Mr←X Mb,{M d}Dwi∗ M i.

Ở đây, chúng tôi giả định các ví dụ few-shot Et cho trọng số kết hợp (Eq. 2) luôn có sẵn, đây là một điều kiện rất vừa phải trong thực tế. Theo cách này, chúng tôi loại bỏ nhu cầu huấn luyện bất kỳ mô hình mới nào; thay vào đó, bằng cách chịu chi phí tối thiểu, chúng tôi có thể tích hợp liền mạch các mô hình hiện có để có được một mô hình phù hợp cho các tác vụ hạ nguồn.

3 Thiết lập thí nghiệm
Chúng tôi đã thực hiện thí nghiệm với hai loại mô hình: LM dựa trên decoder và LM dựa trên encoder. Chúng tôi đã tinh chỉnh 9 mô hình dựa trên encoder và 9 mô hình dựa trên decoder riêng biệt, và sau đó đánh giá hiệu suất của các mô hình được tinh chỉnh và các mô hình được tinh chỉnh có khả năng phục hồi. Sau đây là các cài đặt thí nghiệm chi tiết.

3.1 LM dựa trên Decoder
•Mô hình Cơ sở. Chúng tôi sử dụng Llama-2-chat-7b1(Touvron et al., 2023) làm mô hình cơ sở, có khả năng zero-shot ấn tượng trên các tác vụ khác nhau.

•Tinh chỉnh. Chúng tôi sử dụng các tập dữ liệu được thu thập bởi (Cheng et al., 2023; Wang et al., 2023), bao gồm 30 tác vụ từ FLAN (Wei et al., 2022). Chúng tôi chọn 9 tác vụ khác nhau từ đó để tinh chỉnh mô hình cơ sở, bao gồm NQ, SQuAD, Hellaswag, SST2, Winogrande, CommonGen, MRPC, AG News, và MNLI. Để biết thêm thông tin về dữ liệu huấn luyện, vui lòng tham khảo Phụ lục A. Mã tinh chỉnh dựa trên gói FastChat2. Tốc độ học là 2e-5, kích thước batch là 128, và số epoch tối đa là 3.

•Đánh giá. Chúng tôi đánh giá hiệu suất trên tập test của 30 tác vụ được thu thập bởi (Cheng et al., 2023; Wang et al., 2023). Dữ liệu test cho các tác vụ tinh chỉnh (NQ, SQuAD, Hellaswag, SST2, Winogrande, CommonGen, MRPC, AG News, và MNLI) cũng được bao gồm trong bộ sưu tập này. Chỉ số chi tiết cho mỗi tác vụ có thể tham khảo (Wang et al., 2023). Bên cạnh đó, chúng tôi cũng thực hiện thí nghiệm trên các tác vụ bổ sung từ tập dữ liệu MMLU, đây là một benchmark được sử dụng rộng rãi cho các LLM.

3.2 LM dựa trên Encoder
•Mô hình Cơ sở. Chúng tôi chọn mô hình embedding bge-base-v 1.53(Xiao et al., 2023) làm mô hình cơ sở cho các tác vụ embedding, có thể ánh xạ văn bản thành biểu diễn embedding.

•Tinh chỉnh. Chúng tôi chọn 9 tập dữ liệu từ kho sentence transformers4, bao gồm GooAQ, Yahoo Answers, MSMarco, Stack Exchange, ELI5, SQuAD, AmazonQA, Quora, HotpotQA. Phụ lục A hiển thị chi tiết dữ liệu huấn luyện. Chúng tôi tinh chỉnh mô hình BGE trên các tập dữ liệu này với công cụ FlagEmbedding5. Chúng tôi sử dụng optimizer AdamW với tốc độ học 2e-5. Kích thước batch là 256, và nhiệt độ cho học tương phản là 0.02.

•Đánh giá. Chúng tôi đánh giá các mô hình với 15 tác vụ truy xuất trong benchmark mteb (Muennighoff et al., 2022), và sử dụng NDCG@10 làm chỉ số đánh giá. Dữ liệu test của 3 tác vụ tinh chỉnh: MSMarco, HotpotQA và Quora được bao gồm trong benchmark này. Vì mục đích tạo điều kiện thuận lợi cho việc huấn luyện và kiểm tra qua các tác vụ khác nhau, chúng tôi không thêm hướng dẫn truy vấn mặc định từ (Xiao et al., 2023).

4 Kết quả Thí nghiệm
Trong phần này, chúng tôi trình bày kết quả thí nghiệm và đại diện cho các phát hiện chính. Đầu tiên, chúng tôi so sánh hiệu suất của các mô hình được tinh chỉnh và các mô hình được tinh chỉnh có khả năng phục hồi. Tiếp theo, chúng tôi đánh giá hiệu suất của LM-Cocktail khi tinh chỉnh trên tác vụ mục tiêu không có sẵn. Cuối cùng, chúng tôi nghiên cứu tác động của trọng số α và số lượng ví dụ.

4.1 So sánh Tổng thể
Các thí nghiệm của chúng tôi so sánh hiệu suất của các mô hình cơ sở, các mô hình được tinh chỉnh tương ứng, và các mô hình được tinh chỉnh có khả năng phục hồi thông qua LM-Cocktail. Đối với mỗi mô hình được tinh chỉnh, chúng tôi đo hiệu suất của nó trên tác vụ mục tiêu cụ thể cũng như hiệu suất của nó trên các tác vụ khác. Chúng tôi cũng đã kiểm tra các mô hình được tinh chỉnh có khả năng phục hồi bằng phương pháp của chúng tôi, bao gồm hai biến thể: (1) LM-Cocktail 2: kết hợp mô hình được tinh chỉnh với mô hình cơ sở; (2) LM-Cocktail 10: kết hợp 10 mô hình, bao gồm mô hình được tinh chỉnh trên tác vụ mục tiêu, mô hình cơ sở, tám mô hình được tinh chỉnh còn lại từ phần 3.1. Chúng tôi đã tóm tắt kết quả trong Bảng 1 và 2. Để biết kết quả chi tiết cho mỗi tác vụ kiểm tra, vui lòng tham khảo Phụ lục B.1.

4.1.1 Phân tích về LM dựa trên decoder
Từ Bảng 1, chúng tôi có những quan sát sau: (1) mô hình được tinh chỉnh thể hiện sự cải thiện đáng kể so với mô hình cơ sở trong tác vụ tương ứng. Ví dụ, mô hình được tinh chỉnh trên AG News đạt độ chính xác 94.42% trong tác vụ tương ứng, trong khi mô hình cơ sở chỉ đạt 40.9% độ chính xác trên cùng tác vụ đó. (2) Tuy nhiên, lợi ích này đi kèm với chi phí: trong các tác vụ khác, mô hình được tinh chỉnh thường tụt hậu so với hiệu suất của mô hình cơ sở. Ví dụ, độ chính xác của mô hình được tinh chỉnh trên các tác vụ khác chỉ là 38.58%, thấp hơn đáng kể so với 46.8% độ chính xác của mô hình cơ sở. (3) Ngược lại, LM-Cocktail 2 duy trì hiệu quả trong tác vụ tương ứng của nó (94.46% trong tác vụ AG News) đồng thời cũng thể hiện hiệu suất cạnh tranh trong các tác vụ khác (47.73%). Và LM-Cocktail 10 tiếp tục tăng cường hiệu suất của các tác vụ khác (độ chính xác tăng từ 38.58% lên 48.32% sau khi kết hợp). Trong hầu hết các trường hợp, LM-Cocktail 2 và LM-Cocktail 10 thậm chí vượt trội hơn mô hình cơ sở trên các tác vụ khác. Phát hiện này chứng minh rằng phương pháp của chúng tôi có thể tích hợp những điểm mạnh của các mô hình được kết hợp, và thậm chí vượt qua chúng về hiệu suất. (4) Bên cạnh đó, tinh chỉnh trên một số tác vụ (ví dụ: NQ) có thể tăng cường hiệu suất không chỉ trên tác vụ tương ứng mà còn trên các tác vụ khác; phương pháp được đề xuất của chúng tôi vẫn hiệu quả trên các tác vụ này: LM-Cocktail đạt độ chính xác cao hơn cả trong tác vụ mục tiêu và các tác vụ khác. Những phát hiện này chứng minh tính linh hoạt của phương pháp của chúng tôi.

4.1.2 Phân tích về LM dựa trên encoder
Kết quả của các mô hình encoder được hiển thị trong Bảng 2. Chúng ta có thể quan sát cùng xu hướng trong phần 4.1.1: Mô hình được tinh chỉnh đạt được sự cải thiện đáng kể so với mô hình cơ sở trong tác vụ tương ứng nhưng có độ chính xác thấp hơn trên các tác vụ không liên quan khác. LM-Cocktail 2 tăng cường đáng kể hiệu suất trong các tác vụ hạ nguồn trong khi duy trì hiệu suất trong các tác vụ không liên quan khác. LM-Cocktail 10 tiếp tục cải thiện khả năng chung bằng cách kết hợp các mô hình được tinh chỉnh trên các tác vụ khác nhau. Những kết quả này cho thấy khả năng áp dụng của LM-Cocktail cho cả mô hình sinh tạo và mô hình biểu diễn, xác thực tính phổ quát của phương pháp luận được đề xuất.

4.2 LM-Cocktail không có Tinh chỉnh
Trong nhiều tình huống, tinh chỉnh trên miền mục tiêu không phải lúc nào cũng có sẵn. Ví dụ, nếu không có đủ tập dữ liệu huấn luyện cho một tác vụ mới, việc tinh chỉnh một mô hình chuyên gia cụ thể cho tác vụ này là không khả thi. Bên cạnh đó, tinh chỉnh một mô hình riêng biệt cho mỗi tác vụ là tốn kém và không linh hoạt, đặc biệt là khi tinh chỉnh các mô hình ngôn ngữ lớn. Chúng tôi báo cáo hiệu suất của LM-Cocktail không có tinh chỉnh trong Bảng 3 và 4.

4.2.1 Phân tích về LM dựa trên Decoder
Để đánh giá hiệu suất trên các tác vụ chưa được nhìn thấy trong tinh chỉnh, chúng tôi giới thiệu các tác vụ bổ sung từ benchmark MMLU. Có 57 tác vụ trong MMLU, khác với các tác vụ tinh chỉnh trong phần 3.1. Chúng tôi sử dụng script đánh giá và các ví dụ five-shot từ framework được sử dụng rộng rãi EleutherAI6.

Kết quả được tóm tắt trong Bảng 3. "Llama-ICL" chỉ ra kết quả sử dụng học trong ngữ cảnh với năm ví dụ. Đối với Multitask-learning, chúng tôi kết hợp tất cả dữ liệu huấn luyện từ 9 tác vụ tinh chỉnh (xem phần 3.1) và tinh chỉnh Llama trên tập dữ liệu đa tác vụ này. Đối với LM-Cocktial, chúng tôi sử dụng 5 ví dụ chính thức để tính trọng số và điều chỉnh một mô hình mới cho mỗi tác vụ bằng cách kết hợp 9 mô hình được tinh chỉnh và mô hình cơ sở. Lấy cảm hứng từ LoraHub (Huang et al., 2023), chúng tôi cũng so sánh một phương pháp thay thế để tính trọng số: sử dụng tối ưu hóa hộp đen trong (Huang et al., 2023) để tìm phân bổ trọng số tối ưu. Chúng tôi sử dụng LM-Cocktail blackbox để ký hiệu biến thể này. Bên cạnh đó, chúng tôi tổng hợp tất cả ví dụ từ mỗi tác vụ để tính trọng số kết hợp, và tạo ra một mô hình thống nhất có tên LM-Cocktailu cho tất cả các tác vụ, thay vì tạo ra một mô hình riêng biệt cho mỗi tác vụ.

Có một số phát hiện chính:

•Hiệu suất của multitask-learning thấp hơn mô hình llama gốc. Điều này cho thấy tinh chỉnh sẽ làm tổn hại đến tính tổng quát tổng thể của mô hình gốc, và cũng chỉ ra rằng không có mối tương quan trực tiếp giữa các tập dữ liệu tinh chỉnh này và các tác vụ được liệt kê trên MMLU.

•LM-Cocktail đạt độ chính xác cao hơn Llama và Llama-ICL. Mặc dù không có tập dữ liệu tinh chỉnh liên quan đến các tác vụ MMLU, phương pháp của chúng tôi thể hiện sự cải thiện đáng kể về hiệu suất thông qua việc kết hợp các mô hình được tinh chỉnh. LM-Cocktail chỉ liên quan đến việc tái kết hợp các mô hình hiện có mà không cần huấn luyện mô hình bổ sung. Hơn nữa, nó không tạo ra bất kỳ độ trễ nào cho quá trình suy luận, trong khi Llama-ICL cần xử lý nhiều token hơn vì prompt few-shot được thêm vào.

•So với tối ưu hóa hộp đen, phương pháp tính trọng số của chúng tôi đơn giản hơn nhưng vẫn rất hiệu quả. Chúng tôi quan sát thấy rằng các phương pháp tối ưu hóa hộp đen gặp khó khăn trong việc đảm bảo tổng trọng số bằng 1, dẫn đến hiệu suất không tối ưu.

•Mô hình thống nhất LM-Cocktailu cũng cho thấy hiệu suất vượt trội, điều này chứng minh phương pháp được đề xuất có khả năng xử lý đồng thời nhiều tác vụ mới. Bên cạnh đó, chúng tôi tiếp tục nghiên cứu tác động của số lượng ví dụ trong phần 4.4.

4.2.2 Phân tích về LM dựa trên Encoder
Theo cài đặt trong phần 4.2.1, chúng tôi so sánh hiệu suất của mô hình BGE gốc, mô hình multitask-learning, và LM-Cocktail với các phương pháp khác nhau để kết hợp mô hình. Chúng tôi thu thập 9 mô hình được tinh chỉnh từ phần 3.2. Để đánh giá, chúng tôi loại trừ các tác vụ đã được tinh chỉnh trong phần 3.2 (tức là HotpotQA, MSMATCO, và Quora). Như được báo cáo trong Bảng 4, LM-Cocktail đạt độ chính xác cao hơn các mô hình khác. Điều này chứng minh rằng chúng ta có thể cải thiện độ chính xác của tác vụ mới chỉ bằng cách kết hợp các mô hình ngôn ngữ hiện có.

4.3 Tác động của Trọng số α
Trong phần này, chúng tôi thực hiện so sánh hiệu suất dưới các trọng số α khác nhau. Để loại bỏ ảnh hưởng của các yếu tố khác, chúng tôi đã thực hiện thí nghiệm trong cấu hình đơn giản nhất: kết hợp mô hình được tinh chỉnh và mô hình cơ sở dựa trên trọng số α.

Kết quả của các decoder được hiển thị trong Hình 2, và kết quả của các mô hình encoder có thể được xem trong Phụ lục B.2. Chúng tôi thay đổi tăng dần siêu tham số α từ 0 đến 1, và đánh giá hiệu suất của mô hình trên tác vụ mục tiêu cũng như các tác vụ không liên quan khác. Có thể quan sát thấy rằng bằng cách thay đổi trọng số của mô hình được tinh chỉnh, chúng ta có thể cải thiện đáng kể độ chính xác trên các tác vụ khác, thậm chí vượt qua mô hình cơ sở, trong khi đảm bảo rằng độ chính xác trên tác vụ mục tiêu không giảm.

4.4 Phân tích về Số lượng Ví dụ
Ngoài ra, chúng tôi nghiên cứu tác động của số lượng ví dụ. Cho một số mô hình chuyên gia từ các tác vụ khác, LM-Cocktail cần một vài ví dụ cho tác vụ mới để tính trọng số kết hợp, và kết hợp các mô hình chuyên gia này thông qua tổng có trọng số. Sau đó mô hình được kết hợp có thể được sử dụng để tăng cường mô hình được tinh chỉnh trên tác vụ mới hoặc trực tiếp thực hiện tác vụ mới. Trong phần này, chúng tôi đánh giá hiệu suất của các mô hình được kết hợp trên các tác vụ mới theo cài đặt trong phần 4.2. Đối với mô hình dựa trên decoder, tổng cộng 285 ví dụ được cung cấp trong tập dữ liệu MMLU, và chúng tôi lấy mẫu ngẫu nhiên 5, 50, và 100 ví dụ từ toàn bộ tập để kết hợp các mô hình chuyên gia, và kiểm tra hiệu suất của chúng. Đối với mô hình dựa trên encoder, có tổng cộng 115 ví dụ, và chúng tôi cũng lấy mẫu một tập con để đánh giá hiệu suất của nó. Chỉ số trung bình được báo cáo trong Bảng 5.

Như được hiển thị trong Bảng 5, phương pháp của chúng tôi đạt hiệu suất thỏa đáng chỉ sử dụng năm ví dụ, và hiệu suất tiếp tục cải thiện với sự tăng số lượng ví dụ. Tuy nhiên, ngoài năm mươi ví dụ, sự cải thiện hiệu suất trở nên hạn chế đáng kể.

5 Công trình Liên quan
5.1 Tinh chỉnh Mô hình Ngôn ngữ
Tinh chỉnh các mô hình ngôn ngữ được huấn luyện trước quy mô lớn với dữ liệu được gán nhãn cụ thể cho tác vụ có thể tăng cường thêm khả năng tương ứng của chúng, điều này trở thành phổ biến trong xử lý ngôn ngữ tự nhiên (Dodge et al., 2020). Tuy nhiên, vấn đề quên thảm khốc thường tồn tại trong việc tinh chỉnh liên tục của các mô hình ngôn ngữ khác nhau (Luo et al., 2023): Tinh chỉnh có thể cải thiện hiệu suất của miền mục tiêu, nhưng làm suy yếu đáng kể khả năng chung của các mô hình ngôn ngữ ngoài miền mục tiêu của chúng. Một giải pháp là thêm dữ liệu từ các tác vụ trước đó để duy trì khả năng trước đó (Rolnick et al., 2019; Shin et al., 2017; Rebuffi et al., 2017). Một số phương pháp dựa trên chính quy hóa cũng đã được đề xuất để giảm thiểu vấn đề này, trong đó việc cập nhật các tham số mô hình được chính quy hóa để bảo tồn khả năng chung của mô hình được huấn luyện trước (Kirkpatrick et al., 2017; Li and Hoiem, 2017; Rannen et al., 2017). Khác với việc thêm dữ liệu trước đó, phương pháp của chúng tôi không có chi phí bổ sung cho việc huấn luyện. Hơn nữa, không giống như các phương pháp dựa trên chính quy hóa, phương pháp được đề xuất của chúng tôi không yêu cầu sửa đổi quy trình tinh chỉnh tiêu chuẩn.

5.2 Kết hợp Mô hình
Tổng hợp đầu ra của nhiều mô hình là một kỹ thuật phổ biến để cải thiện độ chính xác của các mô hình học sâu (Lakshminarayanan et al., 2017; Ovadia et al., 2019; Hastie et al., 2009). Tuy nhiên, phương pháp này yêu cầu mỗi mô hình phải thực hiện suy luận riêng biệt, điều này làm tăng đáng kể chi phí tính toán. Thay vì tổng hợp đầu ra của các mô hình, kết hợp mô hình lấy trung bình trọng số của nhiều mô hình để cải thiện hiệu suất của một mô hình duy nhất, điều này không yêu cầu tính toán bổ sung tại thời điểm suy luận (Wortsman et al., 2022a; Ilharco et al., 2022a). Wortsman et al. (Wortsman et al., 2022a) phát hiện rằng việc lấy trung bình trọng số của các mô hình được tinh chỉnh với các cấu hình siêu tham số khác nhau thường có thể cải thiện độ chính xác. Một số nhà nghiên cứu đề xuất các phương pháp phức tạp hơn để căn chỉnh các tham số của các mô hình khác nhau và kết hợp chúng (Nguyen et al., 2021; Matena and Raffel, 2022; Jin et al., 2022). Prateek et.al và Yu et.al đề xuất xóa các giá trị dư thừa trong tham số delta trước khi kết hợp mô hình (Yadav et al., 2023; Yu et al., 2023). Những phương pháp này cũng có thể hữu ích cho LM-Cocktail, và chúng tôi để dành cho công việc tương lai.

Một hướng liên quan đến công việc của chúng tôi là áp dụng kết hợp mô hình trong tinh chỉnh mạnh mẽ. Wortsman et al. (Wortsman et al., 2022b) và Ilharco (Ilharco et al., 2022b) đều phát hiện rằng mô hình clip được tinh chỉnh (Radford et al., 2021) cải thiện đáng kể độ chính xác trên phân phối mục tiêu nhưng làm giảm khả năng mạnh mẽ đối với sự thay đổi phân phối. Để giải quyết vấn đề này, họ sử dụng một hệ số được đặt thủ công để kết hợp mô hình được tinh chỉnh và mô hình cơ sở. Không giống như các phương pháp này, chúng tôi đề xuất sử dụng không chỉ mô hình được huấn luyện trước cơ sở mà còn các mô hình chuyên gia từ các tác vụ khác. Theo cách này, phương pháp được đề xuất của chúng tôi tiếp tục cải thiện khả năng chung và thậm chí có thể hoạt động trong các tình huống mà tinh chỉnh không khả thi. Bên cạnh đó, chúng tôi sử dụng một phương pháp đơn giản để tính trọng số kết hợp cho các mô hình khác nhau một cách tự động.

Hướng liên quan khác là sử dụng kết hợp mô hình để thực hiện tổng quát hóa xuyên tác vụ. Hầu hết các phương pháp này tập trung vào việc kết hợp các mô-đun hiệu quả về tham số (ví dụ: LoRA (Hu et al., 2021), soft prompt(Lester et al., 2021)). Ponti et al.(Ponti et al., 2023) giới thiệu một mô hình kỹ năng tiềm ẩn, trong đó họ huấn luyện một vector nhị phân như hàm định tuyến để chọn các mô-đun kỹ năng cho mỗi tác vụ và sau đó lấy trung bình các tham số của các mô-đun. Đối với tác vụ mục tiêu, Wu et al. (Wu et al., 2023) và Lv et al. (Lv et al., 2023) tổng hợp các tham số của các chuyên gia cụ thể cho tác vụ nhẹ được học từ các tác vụ tương tự. Một số công trình cũng đã được đề xuất để kết hợp embedding prompt từ nhiều tác vụ nguồn đến miền mục tiêu (Vu et al., 2021; Poth et al., 2021; Sun et al., 2023). Công trình mới nhất là LoRAHub (Huang et al., 2023). Cho một vài ví dụ, nó sử dụng công cụ tối ưu hóa hộp đen Shiwa (Liu et al., 2020) để kết hợp nhiều mô-đun LoRA được tinh chỉnh hiện có và tạo ra một mô-đun LoRA mới cho tác vụ mục tiêu. Trái ngược với các phương pháp trên, chúng tôi kết hợp các mô hình được tinh chỉnh và mô hình cơ sở với mục tiêu duy trì khả năng chung sau tinh chỉnh. Đồng thời, để đảm bảo hiệu suất trên tác vụ mục tiêu, chúng tôi sử dụng tổn thất từ một tập nhỏ các ví dụ để lọc ra các mô hình hoạt động kém trên tác vụ mục tiêu. Bên cạnh đó, chúng tôi kết hợp toàn bộ mô hình thay vì các mô-đun hiệu quả về tham số.

6 Kết luận
Trong công trình này, chúng tôi giới thiệu LM-Cocktail, một phương pháp đơn giản để cải thiện hiệu suất trên các tác vụ mục tiêu mà không làm giảm độ chính xác trên các tác vụ không liên quan khác. LM-Cocktail tạo ra một mô hình được tinh chỉnh có khả năng phục hồi bằng cách lấy trung bình có trọng số các tham số từ các mô hình khác nhau: mô hình được tinh chỉnh trên tác vụ mục tiêu, mô hình cơ sở được huấn luyện trước, và các mô hình đồng cấp từ các miền khác. Kết quả thực nghiệm trên cả mô hình decoder và encoder chứng minh rằng LM-Cocktail có thể đạt được hiệu suất mạnh trong toàn bộ phạm vi các tác vụ chung trong khi duy trì khả năng vượt trội trong miền mục tiêu của nó. Chúng tôi tiếp tục chứng minh hiệu quả của LM-Cocktail khi không thể tinh chỉnh trên dữ liệu cụ thể theo miền. Trong những trường hợp như vậy, phương pháp của chúng tôi có thể kết hợp các mô hình hiện có dựa trên rất ít ví dụ để tăng cường độ chính xác của tác vụ mục tiêu.

Tài liệu tham khảo
[Phần này giữ nguyên các tài liệu tham khảo tiếng Anh như trong bản gốc]

A Tập dữ liệu được sử dụng trong tinh chỉnh
Chúng tôi tinh chỉnh mô hình Llama trên 9 tập dữ liệu khác nhau, chi tiết được hiển thị trong Bảng 6. Chi tiết về các tập dữ liệu được sử dụng để tinh chỉnh BGE được hiển thị trong Bảng 7.

B Kết quả Thí nghiệm khác
B.1 Kết quả chi tiết cho mỗi tác vụ
Kết quả chi tiết cho mỗi tác vụ được báo cáo trong Bảng 8 và 9.

B.2 Tác động của α đối với LM dựa trên encoder
Hiệu suất của các LM dựa trên encoder với trọng số kết hợp khác nhau được hiển thị trong Hình 3.

[Các bảng và hình vẽ được duy trì nguyên vị trí và cấu trúc như trong bản gốc]

# 2306.01116.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/dataset-pruning-cleaning-dedup/2306.01116.pdf
# Kích thước file: 1134285 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Bộ dữ liệu RefinedWeb cho Falcon LLM:
Vượt trội hơn các Corpus được Tuyển chọn bằng Dữ liệu Web, và Chỉ với Dữ liệu Web
Đội ngũ Falcon LLM
Guilherme Penedo1Quentin Malartic2
Daniel Hesslow1Ruxandra Cojocaru2Alessandro Cappelli1Hamza Alobeidli2Baptiste Pannier1
Ebtesam Almazrouei2Julien Launay1 3
https://huggingface.co/datasets/tiiuae/falcon-refinedweb
Tóm tắt
Các mô hình ngôn ngữ lớn thường được huấn luyện trên hỗn hợp dữ liệu web đã lọc và các corpus "chất lượng cao" được tuyển chọn,
như cuộc trò chuyện trên mạng xã hội, sách hoặc bài báo kỹ thuật. Quá trình tuyển chọn này được cho là cần thiết
để tạo ra các mô hình hiệu quả với khả năng tổng quát hóa zero-shot rộng rãi. Tuy nhiên, khi các mô hình lớn hơn đòi hỏi
huấn luyện trước trên hàng nghìn tỷ token được xem xét, không rõ việc tuyển chọn có thể mở rộng đến mức nào và liệu chúng ta có sẽ
hết dữ liệu chất lượng cao duy nhất sớm hay không. Trái ngược với niềm tin trước đây, chúng tôi chỉ ra rằng dữ liệu web được lọc và
khử trùng lặp đúng cách chỉ bằng chính nó có thể dẫn đến các mô hình mạnh mẽ; thậm chí vượt trội đáng kể so với các mô hình từ
nghệ thuật tiên tiến được huấn luyện trên The Pile. Mặc dù lọc rộng rãi, dữ liệu chất lượng cao mà chúng tôi trích xuất từ web vẫn
dồi dào, và chúng tôi có thể thu được năm nghìn tỷ token từ CommonCrawl. Chúng tôi công khai phát hành một phần trích xuất
600 tỷ token từ bộ dữ liệu R EFINED WEB của chúng tôi, và các mô hình ngôn ngữ 1.3/7.5B tham số được huấn luyện trên nó *.

--- TRANG 2 ---
Bộ dữ liệu RefinedWeb cho Falcon LLM
Bảng 1. REFINED WEB cải thiện so với các bộ dữ liệu huấn luyện trước tiếng Anh hiện có cho các mô hình ngôn ngữ lớn bằng cách kết hợp việc lọc
rộng rãi với khử trùng lặp nghiêm ngặt ở quy mô chưa từng có. Để biết thêm chi tiết, xem phiên bản đầy đủ trong Bảng 12 của Phụ lục F.3.
Bộ dữ liệu Kích thước Tính khả dụng Web CC Xử lý Khử trùng lặp
CÁC BỘ DỮ LIỆU WEB LỚN
C4 ∼360GT Công khai 100% Quy tắc + danh sách chặn từ NSFW Chính xác: các đoạn gồm 3 câu
OSCAR-21.09 ∼370GT Công khai 100% Xây dựng ở cấp độ dòng Chính xác: theo dòng ( ∼55% bị loại bỏ)
OSCAR-22.01 ∼283GT Công khai 100% Quy tắc cấp dòng + quy tắc tùy chọn
& danh sách chặn URL NSFWChính xác: theo dòng (tùy chọn, không sử dụng
cho kết quả trong bài báo này)
CÁC BỘ DỮ LIỆU ĐƯỢC TUYỂN CHỌN
■GPT-3 300GT Riêng tư 60% Bộ lọc nội dung được huấn luyện trên các
nguồn chất lượng cao đã biếtMờ: MinHash ( ∼10% bị loại bỏ)
▼The Pile ∼340GT Công khai 18% jusText để trích xuất, bộ lọc nội dung được huấn luyện trên dữ liệu được tuyển chọnMờ: MinHash ( ∼26% bị loại bỏ)
⋆PaLM 780GT Riêng tư 27% Bộ lọc được huấn luyện trên dữ liệu HQ Không rõ
CỦA CHÚNG TÔI
 REFINED WEB∼5,000GT Công khai (600GT) 100% trafilatura để trích xuất văn bản, quy tắc cấp tài liệu và dòng, danh sách chặn URL NSFWChính xác & mờ: chuỗi con chính xác+MinHash ( ∼50% bị loại bỏ)

1. Giới thiệu
Tiến bộ trong xử lý ngôn ngữ tự nhiên ngày càng được thúc đẩy bởi quy mô tính toán đơn thuần (Sevilla et al., 2022):
khi nhiều tính toán hơn được chi tiêu để huấn luyện các mô hình ngôn ngữ lớn (LLM), chúng đạt được và thể hiện các khả năng nổi bật mạnh mẽ (Brown et al., 2020; Wei et al., 2022). Để có lợi ích tốt nhất từ việc mở rộng, các quy luật mở rộng gần đây chỉ ra rằng cả kích thước mô hình và kích thước bộ dữ liệu đều nên được tăng cùng nhau (Hoffmann et al., 2022). Điều này trái ngược với các phát hiện trước đó, vốn đã lập luận rằng việc mở rộng nên tập trung vào kích thước mô hình trước hết và quan trọng nhất, với việc mở rộng dữ liệu tối thiểu (Kaplan et al., 2020).
Mô hình mở rộng chung này đặt ra những thách thức đáng kể: mặc dù dồi dào, dữ liệu văn bản không phải là vô hạn, đặc biệt là khi các cân nhắc về chất lượng dữ liệu và giấy phép được tính đến–dẫn đến một số nhà nghiên cứu lập luận rằng việc mở rộng có thể sớm bị hạn chế bởi tính khả dụng của dữ liệu (Villalobos et al., 2022). Cụ thể, việc huấn luyện tối ưu một mô hình có kích thước GPT-3 (175B tham số) sẽ đòi hỏi không ít hơn 3,500 tỷ token văn bản theo Hoffmann et al. (2022). Điều này gấp đôi so với các bộ dữ liệu huấn luyện trước lớn nhất từng được chứng minh (Hoffmann et al., 2022; Touvron et al., 2023), và gấp mười lần so với các bộ dữ liệu tiếng Anh công khai lớn nhất như OSCAR (Ortiz Su ´arez et al., 2019), C4 (Raffel et al., 2020), hoặc The Pile (Gao et al., 2020).
Việc mở rộng quy mô dữ liệu huấn luyện trước một cách lớn càng trở nên thách thức hơn bởi thực tế là các LLM thường được huấn luyện bằng cách sử dụng hỗn hợp các lần thu thập web và dữ liệu được gọi là "chất lượng cao" (Brown et al., 2020; Gao et al., 2020). Các corpus chất lượng cao điển hình bao gồm các nguồn sách được tuyển chọn, tài liệu kỹ thuật, các trang web được con người lựa chọn, hoặc cuộc trò chuyện trên mạng xã hội. Sự đa dạng và chất lượng tăng cường do các corpus được tuyển chọn này mang lại được cho là thành phần chính của các mô hình hiệu quả (Scao et al., 2022b). Thật không may, việc tuyển chọn tốn nhiều lao động: thường thì, mỗi nguồn đòi hỏi xử lý chuyên biệt, trong khi chỉ tạo ra một lượng dữ liệu hạn chế. Hơn nữa, các nguồn có giấy phép đặt ra các thách thức pháp lý.
Tuy nhiên, hầu hết dữ liệu huấn luyện trước vẫn được lấy từ các lần thu thập web lớn có thể được mở rộng lên đến hàng nghìn tỷ token với sự can thiệp của con người có hạn. Tuy nhiên, chất lượng của dữ liệu này theo truyền thống được xem là (thua kém nhiều) so với các nguồn dữ liệu được tuyển chọn thủ công. Thậm chí các nguồn dữ liệu web được xử lý tốt, như C4 (Raffel et al., 2020) hoặc OSCAR (Ortiz Su ´arez et al., 2019), được coi là kém hơn các corpus được tuyển chọn cho LLM (Rae et al., 2021; Scao et al., 2022b), tạo ra các mô hình ít hiệu quả hơn.
Để duy trì nhu cầu dữ liệu ngày càng tăng của các LLM lớn hơn và lớn hơn, và để hợp lý hóa các quy trình dữ liệu và giảm nhu cầu tuyển chọn tốn nhiều nhân lực, chúng tôi đề xuất khám phá cách dữ liệu web có thể được xử lý tốt hơn để cải thiện đáng kể chất lượng của nó, dẫn đến các mô hình có khả năng tương đương, nếu không muốn nói là có khả năng hơn, so với các mô hình được huấn luyện trên các corpus được tuyển chọn.
Đóng góp. Chúng tôi đưa ra các đóng góp sau:
•Chúng tôi giới thiệu REFINED WEB, một bộ dữ liệu huấn luyện trước tiếng Anh chất lượng cao năm nghìn tỷ token chỉ từ web;
•Chúng tôi chứng minh rằng chỉ riêng dữ liệu web có thể tạo ra các mô hình vượt trội hơn cả các corpus được tuyển chọn công khai và riêng tư, như được thể hiện bởi các benchmark zero-shot, thách thức quan điểm hiện tại về chất lượng dữ liệu;
•Chúng tôi công khai phát hành một phần trích xuất 600B token từ RefinedWeb, và các LLM 1/7B tham số được huấn luyện trên nó, để phục vụ như một bộ dữ liệu web chất lượng cao baseline mới cho cộng đồng xử lý ngôn ngữ tự nhiên.

--- TRANG 3 ---
Bộ dữ liệu RefinedWeb cho Falcon LLM
2. Các công trình liên quan
Dữ liệu huấn luyện trước cho các mô hình ngôn ngữ lớn. Các mô hình ngôn ngữ lớn sớm đã xác định tầm quan trọng của các bộ dữ liệu với các tài liệu dài, mạch lạc (Radford et al., 2018; Devlin et al., 2019). Chuyển từ các bộ dữ liệu theo câu đã sử dụng trước đây (Chelba et al., 2013), thay vào đó họ tận dụng các corpus tập trung vào tài liệu, một miền duy nhất như Wikipedia hoặc BookCorpus (Zhu et al., 2015). Khi các mô hình tăng quy mô, các bộ dữ liệu dựa trên thu thập web lớn đã trở nên phổ biến (Ortiz Su ´arez et al., 2019; Raffel et al., 2020). Tuy nhiên, công việc tiếp theo đã lập luận rằng những lần thu thập web không có mục tiêu này thua kém dữ liệu được tuyển chọn bởi con người (Radford et al., 2019), dẫn đến việc áp dụng rộng rãi các bộ dữ liệu được tuyển chọn như The Pile (Gao et al., 2020), kết hợp dữ liệu web với sách, bài báo kỹ thuật, và cuộc trò chuyện trên mạng xã hội. Ở quy mô lớn, đã được đề xuất mô phỏng quá trình tuyển chọn của con người bằng cách tận dụng các tín hiệu yếu: ví dụ, bằng cách thu thập các liên kết hàng đầu của một diễn đàn (Gokaslan et al., 2019). Các corpus có mục tiêu cũng có thể tạo ra các mô hình cụ thể cho miền (Beltagy et al., 2019), hoặc mở rộng khả năng biểu đạt của các mô hình (ví dụ, cho các phương thức trò chuyện Adiwardana et al. (2020); Thoppilan et al. (2022)). Các mô hình ngôn ngữ lớn mới nhất (Brown et al., 2020; Rae et al., 2021; Chowdhery et al., 2022; Scao et al., 2022a) được huấn luyện trên các corpus tổng hợp khổng lồ, kết hợp cả thu thập web lớn và các nguồn một miền được tuyển chọn được gọi là "chất lượng cao" (ví dụ, tin tức, sách, bài báo kỹ thuật, cuộc trò chuyện trên mạng xã hội). Các nguồn có mục tiêu này thường được lấy mẫu thêm–từ một đến năm lần là phổ biến nhất–để tăng đại diện của chúng trong bộ dữ liệu cuối cùng. Sự đa dạng và "chất lượng cao hơn" do các bộ dữ liệu tổng hợp này mang lại được cho là trung tâm của chất lượng mô hình; chỉ riêng dữ liệu web được coi là không đủ để huấn luyện các mô hình ngôn ngữ lớn mạnh mẽ (Liu et al., 2019; Scao et al., 2022b).
Quy trình cho dữ liệu web. Các bộ dữ liệu web lớn thường được xây dựng dựa trên CommonCrawl, một lần thu thập internet có sẵn công khai, hiện đã chạy được 12 năm và đã thu thập hàng petabyte dữ liệu. Làm việc với dữ liệu được thu thập từ khắp internet đặt ra những thách thức duy nhất: đáng chú ý, một phần đáng kể là spam được tạo bởi máy chất lượng thấp hoặc nội dung khiêu dâm (Trinh & Le, 2018; Kreutzer et al., 2022). Theo đó, huấn luyện trên dữ liệu web chưa lọc là không mong muốn, dẫn đến các mô hình hoạt động kém (Raffel et al., 2020). Các quy trình hiện đại tập trung vào việc lọc ra nội dung không mong muốn này (Wenzek et al., 2020). Nói một cách rộng rãi, các quy trình này thường kết hợp nhiều giai đoạn khác nhau: (1) nhận dạng ngôn ngữ, tận dụng các mô hình n-gram không tốn kém (ví dụ, fastText Joulin et al. (2016)); (2) quy tắc lọc và heuristic, chẳng hạn như chỉ giữ các dòng có dấu câu hợp lệ, loại bỏ các dòng có quá nhiều ký hiệu, hoặc loại bỏ các tài liệu chứa từ bị cấm (Grave et al., 2018; Raffel et al., 2020); (3) lọc chất lượng dựa trên ML, sử dụng các mô hình nhẹ được huấn luyện trên dữ liệu vàng đã biết để xác định các tài liệu web chất lượng cao tương tự (Wenzek et al., 2020; Brown et al., 2020); (4) khử trùng lặp, loại bỏ các đoạn trùng lặp chính xác hoặc các tài liệu tương tự (Lee et al., 2022).
Mặc dù một số lọc là cần thiết, việc lọc quá mức có thể đưa ra các thiên vị không mong muốn trong mô hình. Điều này có thể tác động quá mức đến các nhóm thiểu số (Dodge et al., 2021), thúc đẩy việc áp dụng các thực hành như pseudo-crawling, trong đó các URL được phép được tuyển chọn thủ công (Laurenc¸on et al., 2022).
Khử trùng lặp. Khử trùng lặp loại bỏ các đoạn trích và tài liệu lặp lại từ một bộ dữ liệu: chúng có thể là các kết quả khớp chính xác, giống hệt nhau trong mọi ký tự, hoặc các kết quả khớp gần đúng, dựa trên một số thước đo tương tự. Đối với các bản sao chính xác, việc khớp các chuỗi con chính xác có độ dài tối thiểu bằng cách sử dụng mảng hậu tố là phổ biến (Manber & Myers, 1993). Đối với các bản sao mờ, các phương pháp dựa trên các hash nhạy cảm cục bộ như MinHash (Broder, 1997) hoặc SimHash (Charikar, 2002) đã được áp dụng cho dữ liệu huấn luyện trước của các mô hình ngôn ngữ lớn (Brown et al., 2020; Zeng et al., 2021; Rae et al., 2021). Gần đây, Abbas et al. (2023) đã đề xuất tận dụng các embedding từ các mô hình đã huấn luyện trước để thấm nhuần hiểu biết ngữ nghĩa trong các thuật toán khớp gần đúng.
Khử trùng lặp đã được xác định là đóng vai trò quan trọng trong việc cải thiện các mô hình ngôn ngữ (Allamanis, 2019; Lee et al., 2022). Đáng chú ý, nó giảm việc ghi nhớ (Carlini et al., 2022), điều này đặc biệt có vấn đề trong các mô hình lớn (Carlini et al., 2021). Hơn nữa, dữ liệu lặp lại đã được chỉ ra là ngày càng có hại đối với chất lượng mô hình khi số lượng tham số tăng (Hernandez et al., 2022): đối với một mô hình 1B tham số, một trăm bản sao là có hại; ở 175B, thậm chí một vài bản sao cũng có thể có tác động không cân xứng. Đồng thời với công việc này, bộ mô hình Pythia phát hiện ra việc khử trùng lặp The Pile có tác động hạn chế đến hiệu suất zero-shot (Biderman et al., 2023), đặt câu hỏi liệu việc khử trùng lặp có liên quan đến các corpus được tuyển chọn như đối với các bộ dữ liệu chủ yếu dựa trên web hay không.
Chúng tôi cung cấp tổng quan về một số bộ dữ liệu huấn luyện trước tiếng Anh được áp dụng rộng rãi hiện có cho LLM trong Bảng 1, với thông tin bổ sung trong Bảng 12 của Phụ lục F.3. Chúng tôi cũng lưu ý rằng các mô hình mở phổ biến gần đây (Zhang et al., 2022; Touvron et al., 2023) thường tận dụng gián tiếp The Pile (Gao et al., 2020) bằng cách thực hiện mix-and-match các thành phần của nó.
Tập trung vào việc xây dựng một bộ dữ liệu huấn luyện trước web chất lượng cao quy mô lớn, chúng tôi mở rộng dựa trên nghệ thuật tiên tiến theo ba cách: (1) chúng tôi tổng hợp và kết hợp các thực hành tốt nhất để chuẩn bị và lọc tài liệu qua nhiều quy trình, và giới thiệu các sửa chữa theo dòng; (2) chúng tôi kết hợp cả khử trùng lặp chính xác và mờ ở quy mô rất lớn; (3) quy mô của bộ dữ liệu cuối cùng của chúng tôi là duy nhất, với tổng cộng 5,000 tỷ token, và một phần trích xuất 600 tỷ token có sẵn để sử dụng công khai với giấy phép cho phép. Huấn luyện các mô hình lớn trên RefinedWeb cũng dẫn chúng tôi đến thách thức niềm tin thường được giữ rằng dữ liệu web hoàn toàn tệ hơn các corpus được tuyển chọn.

--- TRANG 4 ---
Bộ dữ liệu RefinedWeb cho Falcon LLM
3. Tinh chế Macrodata và RefinedWeb
Chúng tôi giới thiệu MDR (MacroData Refinement), một quy trình để lọc và khử trùng lặp dữ liệu web từ CommonCrawl ở quy mô rất lớn. Sử dụng MDR, chúng tôi tạo ra REFINED WEB, một bộ dữ liệu huấn luyện trước tiếng Anh năm nghìn tỷ token chỉ dựa trên dữ liệu web. Chúng tôi tận dụng việc lọc nghiêm ngặt và khử trùng lặp nghiêm ngặt để nâng cao chất lượng dữ liệu web, chưng cất nó xuống thành một corpus phù hợp với chất lượng của các corpus tổng hợp được sử dụng để huấn luyện các mô hình nghệ thuật tiên tiến.
Nguyên tắc thiết kế. Chúng tôi tuân theo các hướng dẫn sau:
•Quy mô trước tiên. Chúng tôi dự định MDR tạo ra các bộ dữ liệu được sử dụng để huấn luyện các mô hình 40-200B tham số, do đó đòi hỏi hàng nghìn tỷ token (Hoffmann et al., 2022). Đối với RefinedWeb chỉ tiếng Anh, chúng tôi nhắm mục tiêu kích thước 3-6 nghìn tỷ token. Cụ thể, chúng tôi tránh bất kỳ quá trình tuyển chọn con người tốn nhiều lao động nào, và tập trung vào CommonCrawl thay vì các nguồn một miền khác biệt.
•Khử trùng lặp nghiêm ngặt. Lấy cảm hứng từ công việc của Lee et al. (2022), đã chứng minh giá trị của khử trùng lặp cho các mô hình ngôn ngữ lớn, chúng tôi triển khai một quy trình khử trùng lặp nghiêm ngặt. Chúng tôi kết hợp cả khử trùng lặp chính xác và mờ, và sử dụng các cài đặt nghiêm ngặt dẫn đến tỷ lệ loại bỏ cao hơn nhiều so với những gì người khác đã báo cáo.
•Lọc trung tính. Để tránh đưa thêm các thiên vị không mong muốn vào mô hình (Dodge et al., 2021; Welbl et al., 2021), chúng tôi tránh sử dụng lọc dựa trên ML ngoài nhận dạng ngôn ngữ. Chúng tôi tuân theo các quy tắc và heuristic đơn giản, và chỉ sử dụng lọc URL cho nội dung người lớn.
Bảng 2 và Hình 2 phác thảo toàn bộ quy trình MDR.

3.1. Chuẩn bị tài liệu: đọc dữ liệu, lọc URL, trích xuất văn bản, và nhận dạng ngôn ngữ
Đọc dữ liệu. CommonCrawl có sẵn trong các tệp WARC (phản hồi HTML thô), hoặc WET (được xử lý trước để chỉ bao gồm văn bản thuần túy). Các tệp riêng lẻ tương ứng với một trang tại một URL nhất định; chúng tạo thành các tài liệu/mẫu đơn lẻ. Làm việc với các tệp WET sẽ giúp chúng tôi tránh chạy trích xuất HTML của riêng mình; tuy nhiên, phù hợp với các công trình trước đây (Gao et al., 2020; Rae et al., 2021), chúng tôi thấy các tệp WET bao gồm các menu điều hướng không mong muốn, quảng cáo, và các văn bản không liên quan khác. Theo đó, quy trình của chúng tôi bắt đầu từ các tệp WARC thô, được đọc bằng thư viện warcio.
Lọc URL. Trước khi thực hiện bất kỳ xử lý nặng tính toán nào, chúng tôi thực hiện lọc đầu tiên chỉ dựa trên URL. Điều này nhắm mục tiêu các trang web gian lận và/hoặc người lớn (ví dụ, chủ yếu khiêu dâm, bạo lực, liên quan đến cờ bạc, v.v.). Chúng tôi dựa việc lọc của mình trên hai quy tắc: (1) một danh sách chặn tổng hợp gồm 4.6M miền; (2) một điểm URL, dựa trên sự hiện diện của các từ từ một danh sách chúng tôi đã tuyển chọn và cân nhắc theo mức độ nghiêm trọng. Chúng tôi thấy rằng các danh sách chặn thường được sử dụng bao gồm nhiều false positive, chẳng hạn như các nền tảng blog phổ biến hoặc thậm chí các trang web văn hóa đại chúng. Hơn nữa, các quy tắc dựa trên từ (như quy tắc được sử dụng trong C4, Raffel et al. (2020)) có thể dễ dàng dẫn đến việc các trang y tế và pháp lý bị chặn. Các quy tắc chi tiết cuối cùng của chúng tôi dựa trên cuộc điều tra này được chia sẻ trong Phụ lục G.1. Vì chúng tôi dự định RefinedWeb được sử dụng như một phần của bộ dữ liệu tổng hợp cùng với các corpus được tuyển chọn, chúng tôi cũng đã lọc các nguồn chất lượng cao phổ biến: Wikipedia, arXiv, v.v. Danh sách chi tiết có sẵn trong Phụ lục G.1.3.

Trích xuất văn bản. Chúng tôi muốn chỉ trích xuất nội dung chính của trang, bỏ qua menu, header, footer, và quảng cáo trong số những thứ khác: Lopukhin (2019) thấy rằng trafilatura (Barbaresi, 2021) là thư viện phi thương mại tốt nhất để truy xuất nội dung từ bài đăng blog và bài báo tin tức. Mặc dù đây chỉ là một tập hợp con hẹp của loại trang tạo nên CommonCrawl, chúng tôi thấy phát hiện này đúng một cách rộng rãi hơn. Chúng tôi sử dụng trafilatura để trích xuất văn bản, và áp dụng định dạng bổ sung thông qua các biểu thức chính quy: chúng tôi giới hạn các dòng mới thành hai dòng liên tiếp, và loại bỏ tất cả URL.
Nhận dạng ngôn ngữ. Chúng tôi sử dụng bộ phân loại ngôn ngữ fastText của CCNet (Wenzek et al., 2020) ở cấp độ tài liệu: nó sử dụng n-gram ký tự và được huấn luyện trên Wikipedia, hỗ trợ 176 ngôn ngữ. Chúng tôi loại bỏ các tài liệu mà điểm ngôn ngữ hàng đầu dưới 0.65: điều này thường tương ứng với các trang không có văn bản tự nhiên nào. Cho bài báo này, chúng tôi tập trung vào tiếng Anh; RefinedWeb cũng có thể được rút ra cho các ngôn ngữ khác, xem Phụ lục D để biết chi tiết.
Dữ liệu chúng tôi truy xuất ở giai đoạn này, được gọi là RW-RAW, tương ứng với những gì chúng tôi có thể trích xuất với lượng lọc tối thiểu. Ở giai đoạn này, chỉ có 48% tài liệu gốc còn lại, chủ yếu bị lọc ra bởi nhận dạng ngôn ngữ.

3.2. Lọc: cấp tài liệu và cấp dòng
Loại bỏ lặp lại. Do lỗi thu thập và các nguồn chất lượng thấp, nhiều tài liệu chứa các chuỗi lặp lại: điều này có thể gây ra hành vi bệnh lý trong mô hình cuối cùng (Holtzman et al., 2019). Chúng tôi có thể bắt nội dung này ở giai đoạn khử trùng lặp sau này, nhưng việc bắt nó sớm ở cấp tài liệu sẽ rẻ hơn và dễ dàng hơn. Chúng tôi triển khai các heuristic của Rae et al. (2021), và loại bỏ bất kỳ tài liệu nào có lặp lại dòng, đoạn văn, hoặc n-gram quá mức.
Lọc cấp tài liệu. Một phần đáng kể các trang là spam được tạo bởi máy, chủ yếu gồm danh sách từ khóa, văn bản mẫu, hoặc chuỗi ký tự đặc biệt. Các tài liệu như vậy không phù hợp cho mô hình hóa ngôn ngữ; để lọc chúng ra, chúng tôi áp dụng các heuristic lọc chất lượng của Rae et al. (2021). Chúng tập trung vào việc loại bỏ các ngoại lệ về độ dài tổng thể, tỷ lệ ký hiệu trên từ, và các tiêu chí khác đảm bảo tài liệu là ngôn ngữ tự nhiên thực sự. Chúng tôi lưu ý rằng các bộ lọc này phải được điều chỉnh theo từng ngôn ngữ, vì chúng có thể dẫn đến lọc quá mức nếu được chuyển một cách ngây thơ từ tiếng Anh sang các ngôn ngữ khác.
Sửa chữa cấp dòng. Mặc dù có những cải tiến do sử dụng trafilatura thay vì dựa vào các tệp đã xử lý trước, nhiều tài liệu vẫn xen kẽ với các dòng không mong muốn (ví dụ, bộ đếm mạng xã hội 3 lượt thích, các nút điều hướng). Theo đó, chúng tôi đã tạo ra một bộ lọc sửa chữa dòng, nhắm mục tiêu những mục không mong muốn này. Nếu những sửa chữa này loại bỏ hơn 5% tài liệu, chúng tôi loại bỏ hoàn toàn tài liệu đó. Xem Phụ lục G.2 để biết chi tiết.
Dữ liệu chúng tôi truy xuất ở giai đoạn này đã trải qua tất cả các heuristic lọc trong quy trình MDR. Chúng tôi gọi bộ dữ liệu này là RW-FILTERED. Chỉ có 23% tài liệu của CommonCrawl còn lại, với khoảng 50% tài liệu của RW-Raw bị loại bỏ bởi việc lọc.

3.3. Khử trùng lặp: mờ, chính xác, và qua các dump
Sau khi lọc, mặc dù chất lượng dữ liệu đã cải thiện, một phần lớn nội dung được lặp lại qua các tài liệu. Điều này có thể do trình thu thập gián tiếp truy cập cùng một trang nhiều lần, do nội dung mẫu được lặp lại (ví dụ, giấy phép), hoặc thậm chí do đạo văn. Những bản sao này có thể tác động mạnh đến các mô hình, ưu tiên ghi nhớ thay vì tổng quát hóa (Lee et al., 2022; Hernandez et al., 2022). Vì khử trùng lặp tốn kém, nó đã thấy việc áp dụng hạn chế trong các bộ dữ liệu công khai (Ortiz Su´arez et al., 2019; Raffel et al., 2020).
Chúng tôi áp dụng một chiến lược khử trùng lặp tích cực, kết hợp cả khớp tài liệu mờ và loại bỏ chuỗi chính xác.
Khử trùng lặp mờ. Chúng tôi loại bỏ các tài liệu tương tự bằng cách áp dụng MinHash (Broder, 1997): đối với mỗi tài liệu, chúng tôi tính toán một sketch và đo độ tương tự gần đúng của nó với các tài liệu khác, cuối cùng loại bỏ các cặp có sự chồng chéo cao. MinHash xuất sắc trong việc tìm các tài liệu có mẫu: giấy phép chỉ khác nhau về các thực thể cụ thể, văn bản SEO placeholder được lặp lại qua các trang web–xem ví dụ về

--- TRANG 5 ---
Bộ dữ liệu RefinedWeb cho Falcon LLM
Bảng 3. Để đánh giá các mô hình được huấn luyện trên RefinedWeb và so sánh với nghệ thuật tiên tiến, chúng tôi xây dựng bốn tổng hợp trên 18 nhiệm vụ để đo hiệu suất zero-shot. small được xây dựng cho các ablation nội bộ, dựa trên các nhiệm vụ có hiệu suất nhất quán ở quy mô nhỏ, core dựa trên các nhiệm vụ thường được báo cáo cho các bộ mô hình công khai (Dey et al., 2023; Biderman et al., 2023), main dựa trên các nhiệm vụ từ bài báo GPT-3 và PaLM (Brown et al., 2020; Chowdhery et al., 2022), và ext dựa trên các nhiệm vụ được sử dụng bởi nhóm BigScience Architecture and Scaling (Scao et al., 2022b). Đối với tất cả kết quả được báo cáo, chúng tôi đánh dấu với †kết quả thu được trong thiết lập đánh giá tùy ý, và với ∗kết quả thu được với EAI Harness (Gao et al., 2021), mà chúng tôi cũng sử dụng cho tất cả các mô hình của chúng tôi.

[Bảng 3 theo sau với các nhiệm vụ và tổng hợp]

các cluster lớn nhất trong Phụ lục H.1. Chúng tôi thực hiện khử trùng lặp MinHash sử dụng 9,000 hash cho mỗi tài liệu, được tính toán trên 5-gram và chia thành 20 bucket của 450 hash. Chúng tôi thấy rằng sử dụng các cài đặt ít tích cực hơn, chẳng hạn như 10 hash của The Pile (Gao et al., 2020), dẫn đến tỷ lệ khử trùng lặp thấp hơn và hiệu suất mô hình tệ hơn. Xem Phụ lục G.3.1 để biết thêm chi tiết về thiết lập MinHash của chúng tôi.

Khử trùng lặp chính xác. Chuỗi con chính xác hoạt động ở cấp độ chuỗi thay vì cấp độ tài liệu, tìm các kết quả khớp giữa các chuỗi là khớp chính xác token-by-token bằng cách sử dụng mảng hậu tố (Manber & Myers, 1993) (ví dụ, các tuyên bố từ chối trách nhiệm hoặc thông báo cụ thể, có thể không làm tổn hại toàn bộ tài liệu như được trình bày trong Phụ lục H.2). Chúng tôi loại bỏ bất kỳ khớp nào có hơn 50 token liên tiếp, sử dụng việc triển khai của Lee et al. (2022). Chúng tôi lưu ý rằng chuỗi con chính xác thay đổi tài liệu, bằng cách loại bỏ các đoạn cụ thể: chúng tôi cũng đã thử nghiệm với việc loại bỏ toàn bộ tài liệu hoặc loss-masking các chuỗi trùng lặp thay vì cắt chúng, nhưng điều này không dẫn đến thay đổi đáng kể trong hiệu suất zero-shot–xem Phụ lục G.3.2.

Khử trùng lặp URL. Do hạn chế tính toán, chúng tôi không thể thực hiện khử trùng lặp trực tiếp trên RW-Filtered. Thay vào đó, chúng tôi chia CommonCrawl thành 100 phần, trong đó mỗi phần chứa một phần trăm của mỗi dump, và thực hiện khử trùng lặp trên các phần riêng lẻ. Hầu hết các cluster trùng lặp lớn hơn (ví dụ, giấy phép, spam phổ biến) sẽ được chia sẻ qua các phần, và được loại bỏ hiệu quả.
Tuy nhiên, chúng tôi thấy rằng các dump CommonCrawl có sự chồng chéo đáng kể, với các URL được xem xét lại qua các dump mặc dù không có thay đổi nội dung. Theo đó, chúng tôi giữ một danh sách các URL của tất cả các mẫu chúng tôi đã giữ từ mỗi phần, và loại bỏ chúng khỏi các phần tiếp theo đang được xử lý.

4. Thực nghiệm
Bây giờ chúng tôi xác nhận rằng RefinedWeb có thể được sử dụng để huấn luyện các mô hình mạnh mẽ, phù hợp với hiệu suất zero-shot thu được với các corpus được tuyển chọn và các mô hình ngôn ngữ nghệ thuật tiên tiến.
Chúng tôi trước tiên thảo luận về thiết lập đánh giá và huấn luyện trước của chúng tôi, và các mô hình mà chúng tôi so sánh. Chúng tôi thực hiện thí nghiệm ở quy mô nhỏ để so sánh nội bộ với các bộ dữ liệu phổ biến khác, và ablate ba giai đoạn chính của RefinedWeb (thô, đã lọc, cuối cùng). Sau đó, chúng tôi mở rộng đến các mô hình 1B và 7B được huấn luyện trên 350GT để so sánh với các mô hình nghệ thuật tiên tiến. Cuối cùng, chúng tôi áp dụng quy trình MDR cho các bộ dữ liệu huấn luyện trước hiện có, và chỉ ra rằng nó có thể mang lại những cải tiến tiềm năng.

4.1. Thiết lập
Đánh giá. Khác với các công trình trước đây nghiên cứu các bộ dữ liệu huấn luyện trước (Rae et al., 2021; Lee et al., 2022), chúng tôi tập trung đánh giá của mình vào tổng quát hóa zero-shot qua nhiều nhiệm vụ thay vì đo lường validation loss. Chỉ riêng perplexity có thể trái ngược với hiệu suất tác vụ cuối (Tay et al., 2021), và các công trình hiện đại về LLM chủ yếu báo cáo hiệu suất zero-shot (Brown et al., 2020; Rae et al., 2021; Chowdhery et al., 2022). Hơn nữa, tổng quát hóa zero-shot là thiết lập "tự nhiên" cho các mô hình decoder-only autoregressive, trong đó chúng hoạt động tốt nhất (Wang et al., 2022). Thiết lập đánh giá của chúng tôi được lấy cảm hứng từ thiết lập được sử dụng bởi nhóm kiến trúc và mở rộng của Big Science (Scao et al., 2022b).
Chúng tôi dựa đánh giá của mình trên Eleuther AI evaluation harness phổ biến (Gao et al., 2021), cho phép chúng tôi đánh giá qua một phạm vi rộng các nhiệm vụ trong thiết lập zero-shot. Chúng tôi xác định các tổng hợp nhiệm vụ cho phép chúng tôi: (1) thu được tín hiệu (tức là hiệu suất zero-shot không phải zero) ở quy mô nhỏ cho

--- TRANG 6 ---
Bộ dữ liệu RefinedWeb cho Falcon LLM
Bảng 4. Tuyển chọn không phải là viên đạn bạc cho tổng quát hóa zero-shot: các mô hình quy mô nhỏ được huấn luyện trên REFINED WEB vượt trội so với các mô hình được huấn luyện trên dữ liệu web (C4, OSCAR), và trên các corpus được tuyển chọn (▼The Pile). Độ chính xác trung bình trong zero-shot trên tổng hợp small-agg. Tất cả các mô hình được huấn luyện với kiến trúc giống hệt nhau và các siêu tham số huấn luyện trước. Chúng tôi thấy rằng OSCAR-22.01 kém hiệu suất đáng kể so với các bộ dữ liệu khác, có lẽ vì khử trùng lặp chỉ là tùy chọn. C4 là một baseline mạnh, với OSCAR-21.09 hơi tụt hậu, nhưng chúng tôi thấy rằng RefinedWeb vượt trội hơn cả các bộ dữ liệu web và bộ dữ liệu được tuyển chọn phổ biến nhất, The Pile. Cả việc lọc và khử trùng lặp đều đóng góp đáng kể vào việc cải thiện hiệu suất zero-shot.

[Bảng 4 theo sau với kết quả]

các ablation; (2) so sánh với kết quả được báo cáo bởi các mô hình khác.
Chúng tôi phác thảo bốn tổng hợp này là small (cho ablation), và core, main, ext (cho so sánh) trong Bảng 3.

Các so sánh qua các mô hình được huấn luyện và đánh giá trong các thiết lập khác nhau khó có thể tách rời, vì nhiều tác động bên ngoài có thể ảnh hưởng đến kết quả (ví dụ, độ chính xác số của huấn luyện so với suy luận, các prompt được sử dụng). Chúng tôi phân biệt ba mức độ so sánh: (1) so sánh nội bộ, với các mô hình được huấn luyện và đánh giá trong codebase của chúng tôi, mà chỉ có các bộ dữ liệu huấn luyện trước khác nhau; (2) so sánh cấp benchmark, với các mô hình được huấn luyện với codebase khác nhau nhưng được đánh giá với Eleuther AI harness, lấy kết quả từ Scao et al. (2022b); Black et al. (2022); Aleph Alpha (2023); Dey et al. (2023), sau đó được đánh dấu với *; (3) so sánh bên ngoài với Brown et al. (2020); Chowdhery et al. (2022), sau đó được đánh dấu với †. Để biết thêm chi tiết về đánh giá, xem Phụ lục F.1.

Các mô hình. Chúng tôi huấn luyện các mô hình autoregressive decoder-only 1B, 3B, và 7B tham số, dựa trên các cấu hình và siêu tham số tương tự như GPT-3 (Brown et al., 2020), chủ yếu khác biệt ở việc sử dụng ALiBi của chúng tôi (Press et al., 2021). Chúng tôi sử dụng FlashAttention (Dao et al., 2022) trong một codebase tùy chỉnh. Chúng tôi huấn luyện các mô hình nội bộ trên cả The Pile và RefinedWeb để kiểm soát các độ lệch gây ra bởi thiết lập huấn luyện trước của chúng tôi–chúng tôi thấy các mô hình The Pile hoạt động phù hợp với những mô hình khác. Đối với các nghiên cứu quy mô nhỏ và ablation (nửa đầu của Phần 4.2; Phần 4.3), chúng tôi huấn luyện các mô hình đến mức tối ưu theo các quy luật mở rộng của Hoffmann et al. (2022): trên 27B và 60B token tương ứng cho các mô hình 1B và 3B tham số của chúng tôi. Đối với các thí nghiệm chính chứng minh phương pháp của chúng tôi (các mô hình Falcon-RW trong Phần 4.2), chúng tôi huấn luyện các mô hình đến 350GT, phù hợp với các mô hình công khai phổ biến (Brown et al., 2020; Wang & Komatsuzaki, 2021; Scao et al., 2022a). Lưu ý rằng chúng tôi không so sánh với các mô hình LLaMA được giới thiệu gần đây (Touvron et al., 2023), vì mô hình nhỏ nhất trong số chúng được huấn luyện trên gấp x2.5 lần tính toán so với mô hình lớn nhất của chúng tôi, ngăn cản một so sánh có ý nghĩa được thực hiện theo hướng bộ dữ liệu.
Để có cái nhìn tổng quan sâu hơn về các mô hình và bộ dữ liệu huấn luyện trước mà chúng tôi so sánh, xem Phụ lục F.

4.2. Liệu chỉ dữ liệu web có thể vượt trội hơn các corpus được tuyển chọn?
Chúng tôi nỗ lực chứng minh rằng chỉ riêng dữ liệu web có thể tạo ra các mô hình vượt trội hơn các mô hình khác được huấn luyện trên các corpus được tuyển chọn. Để làm như vậy, chúng tôi trước tiên thực hiện một nghiên cứu quy mô nhỏ với các mô hình 1B và 3B tham số được huấn luyện đến mức tối ưu (27GT và 60GT) trên các bộ dữ liệu web và được tuyển chọn phổ biến. Sau đó, chúng tôi mở rộng lên các mô hình 1B và 7B được huấn luyện trên 350GT, và so sánh tổng quát hóa zero-shot với các mô hình nghệ thuật tiên tiến.

Nghiên cứu quy mô nhỏ. Chúng tôi trước tiên xem xét các bộ dữ liệu web công khai phổ biến (OSCAR-2019 (Ortiz Su´arez et al., 2019), OSCAR-2022 (Abadji et al., 2021), C4 (Raffel et al., 2020)), The Pile (Gao et al., 2020) như bộ dữ liệu được tuyển chọn công khai phổ biến nhất, và các biến thể của RefinedWeb (RW-Raw, RW-Filtered, và RW như được mô tả trong Phần 3). Đối với nghiên cứu đầu tiên này, tất cả các mô hình được huấn luyện với cùng kiến trúc và cùng codebase nội bộ; chúng cũng đều được đánh giá trong cùng một khuôn khổ–chỉ có các bộ dữ liệu huấn luyện trước khác nhau.
Kết quả trung bình trên tổng hợp small-=+ gồm 6 nhiệm vụ được trình bày trong Bảng 4. Chúng tôi quan sát hiệu suất tương đối mạnh của tất cả các bộ dữ liệu web so với The Pile, cho thấy rằng tuyển chọn không phải là viên đạn bạc cho các mô hình ngôn ngữ hiệu quả. Chúng tôi thấy C4 là một bộ dữ liệu huấn luyện trước mạnh, phù hợp với các phát hiện của Scao et al. (2022b)–tuy nhiên, The Pile so sánh kém hiệu suất hơn trong các benchmark của chúng tôi. Kết quả tương đối đáng thất vọng trên OSCAR-22.01 có thể do phiên bản chính của bộ dữ liệu được phân phối mà không có khử trùng lặp. Liên quan đến RefinedWeb, cả việc lọc và khử trùng lặp đều cải thiện hiệu suất đáng kể.

Các mô hình quy mô đầy đủ. Bây giờ chúng tôi xác nhận những kết quả này với các so sánh với các mô hình nghệ thuật tiên tiến. Chúng tôi mở rộng các thí nghiệm trước đây bằng cách huấn luyện các mô hình 1B và 7B trên 350GT; chúng tôi cũng huấn luyện một mô hình 1B trên 350GT trên The Pile, như một kiểm soát cho ảnh hưởng của thiết lập huấn luyện trước của chúng tôi. Chúng tôi so sánh với các mô hình sau: dòng GPT-3 (Brown et al., 2020), dòng FairSeq (Artetxe et al., 2021), các mô hình GPT-Neo(X)/J (Black et al., 2021; Wang & Komatsuzaki, 2021; Black et al., 2022), dòng OPT (Zhang et al., 2022),

--- TRANG 7 ---
Bộ dữ liệu RefinedWeb cho Falcon LLM
mô hình BigScience Architecture and Scaling Pile (Scao et al., 2022b), PaLM-8B (Chowdhery et al., 2022), Aleph Alpha Luminous 13B (Aleph Alpha, 2023), dòng Pythia (Biderman et al., 2023), và dòng Cerebras-GPT (Dey et al., 2023). Đối với GPT-3, chúng tôi phân biệt giữa kết quả thu được thông qua API (babbage và curie) với EleutherAI LM evaluation harness (Gao et al., 2021) (*), và kết quả được báo cáo trong bài báo của họ, với thiết lập đánh giá khác (†). Lưu ý rằng đối với PaLM và OPT, kết quả cũng được thu được với bộ đánh giá khác (†), trong khi đối với các mô hình khác, chúng được thu được với evaluation harness cũng như (*), cho phép so sánh trực tiếp hơn.
Kết quả trên main-agg được trình bày trong Hình 1, và trong Hình 3 cho core-agg và ext-agg. Chúng tôi thấy rằng các mô hình mở nhất quán kém hiệu suất so với các mô hình được huấn luyện trên các corpus được tuyển chọn riêng tư, chẳng hạn như GPT-3–ngay cả khi sử dụng thiết lập đánh giá tương tự. Ngược lại, các mô hình được huấn luyện trên RefinedWeb có thể phù hợp với hiệu suất của dòng GPT-3 chỉ sử dụng dữ liệu web, mặc dù các nguồn chất lượng cao phổ biến được sử dụng trong The Pile bị loại trừ khỏi RefinedWeb (xem Bảng 14 trong Phụ lục). Cuối cùng, chúng tôi lưu ý rằng mô hình nội bộ của chúng tôi được huấn luyện trên The Pile hoạt động phù hợp với mô hình BigScience Architecture and Scaling; điều này nhấn mạnh rằng thiết lập huấn luyện trước của chúng tôi khó có thể là nguồn chính của hiệu suất tăng cường cho các mô hình được huấn luyện trên RefinedWeb.

Phát hiện. Thách thức các niềm tin hiện tại về chất lượng dữ liệu và LLM, các mô hình được huấn luyện trên dữ liệu web được lọc và khử trùng lặp đầy đủ chỉ bằng chính nó có thể phù hợp với hiệu suất của các mô hình được huấn luyện trên dữ liệu được tuyển chọn.

4.3. Liệu các corpus khác có được lợi từ MDR?
Việc ablate các đóng góp và đánh giá hiệu suất của các thành phần riêng lẻ trong quy trình MDR là khó khăn: đối với hầu hết các heuristic, không có sự thật cơ bản đã thỏa thuận, và các thay đổi có thể quá không đáng kể để dẫn đến tín hiệu zero-shot đầy đủ sau huấn luyện trước. Trong nửa đầu của Phần 4.2, chúng tôi xác định rằng các giai đoạn tiếp theo của RefinedWeb (thô, đã lọc, cuối cùng) dẫn đến cải thiện hiệu suất. Trong phần này, chúng tôi đề xuất áp dụng độc lập các giai đoạn lọc và khử trùng lặp của MDR cho các bộ dữ liệu huấn luyện trước phổ biến, nghiên cứu liệu chúng có tổng quát hóa rộng rãi hay không.
Chúng tôi báo cáo kết quả trên small-agg trong Bảng 5. Trước tiên, chúng tôi thấy rằng các cải tiến từ lọc không có tính hệ thống. Trên The Pile, chúng tôi đã phải điều chỉnh các heuristic về độ dài dòng và tỷ lệ ký tự để tránh xóa sách và mã. Mặc dù có cải tiến trên OSCAR-21.09, C4, và The Pile, các bộ lọc của chúng tôi làm tệ đi hiệu suất trên OSCAR-22.01; nói chung, tỷ lệ loại bỏ từ việc lọc dường như không có tương quan mạnh với độ chính xác downstream. Ngược lại, khử trùng lặp mang lại một sự thúc đẩy ổn định trên tất cả các bộ dữ liệu, và tỷ lệ loại bỏ có tương quan tốt hơn với các thay đổi trong hiệu suất. Chúng tôi thấy OSCAR-21.09 và C4 đã được khử trùng lặp tốt, trong khi The Pile và OSCAR-22.01 thể hiện 40-60% bản sao. Phiên bản cơ bản của OSCAR-22.01 được phân phối mà không có khử trùng lặp; đối với The Pile, điều này phù hợp với các phát hiện của Zhang et al. (2022). Cuối cùng, kết hợp lọc và khử trùng lặp dẫn đến cải tiến thêm; thú vị là, mặc dù hiệu suất bây giờ đồng nhất hơn trên các bộ dữ liệu, sự khác biệt vẫn còn, cho thấy rằng các khuyết tật trong việc trích xuất và xử lý văn bản gốc không thể được bù đắp hoàn toàn.
Bằng cách xử lý C4 thông qua MDR, chúng tôi có thể thu được các tập hợp con dữ liệu có thể hơi vượt trội hơn RefinedWeb; điều này kết hợp cả việc lọc nghiêm ngặt của C4 (ví dụ, danh sách chặn từ NSFW nghiêm ngặt, khử trùng lặp đoạn 3 câu) với các bộ lọc và khử trùng lặp của riêng chúng tôi. Mặc dù sự kết hợp như vậy dẫn đến tỷ lệ từ chối không thể chấp nhận được cho mục tiêu 3-6 nghìn tỷ token của chúng tôi, điều này đại diện cho một góc nhìn thú vị cho các lần chạy ngắn hơn, có thể trích xuất các tập hợp con cực kỳ chất lượng cao từ các bộ dữ liệu web lớn.

Phát hiện. Mặc dù các heuristic lọc có thể đòi hỏi điều chỉnh phụ thuộc vào nguồn, việc khử trùng lặp nghiêm ngặt cải thiện hiệu suất zero-shot một cách nhất quán trên các bộ dữ liệu.

5. Hạn chế
Thiên vị. Chúng tôi tiến hành phân tích cơ bản về độ độc hại của RefinedWeb trong Hình 4. Chúng tôi thấy RW có độ độc hại khoảng như The Pile, dựa trên định nghĩa về độ độc hại do Perspective API cung cấp: "nội dung thô lỗ hoặc thiếu tôn trọng". Đáng chú ý, định nghĩa này không bao gồm các vấn đề về thiên vị xã hội hoặc tính có hại. Mặc dù không chắc rằng quy trình của chúng tôi đưa ra thêm các vấn đề về mặt này hơn những gì đã được ghi nhận cho các bộ dữ liệu phổ biến, chúng tôi khuyến khích công việc định lượng thêm về phần trích xuất công khai của RefinedWeb.

Nhiều epoch. Thay vì tìm kiếm các token "độc đáo" để tạo nên một bộ dữ liệu huấn luyện trước quy mô nghìn tỷ, người ta có thể đơn giản lặp lại dữ liệu qua nhiều epoch. Các mô hình phổ biến như OPT và NeoX-20B làm điều này lên đến 2 epoch, và hầu hết các bộ dữ liệu được tuyển chọn upsample các corpus 2-5 lần. Tuy nhiên, Hernandez et al. (2022) gần đây đã chỉ ra rằng các mô hình với 100B+ tham số có thể nhạy cảm với chỉ vài epoch. Trực giao với công việc của chúng tôi nằm một dòng nghiên cứu khám phá các sự đánh đổi trong chế độ bị hạn chế dữ liệu: liệu khử trùng lặp có thể giúp duy trì nhiều epoch hơn? Nhiều epoch trên dữ liệu chất lượng cao hơn có tốt hơn một epoch trên dữ liệu chất lượng thấp hơn? Xem Phụ lục E.3 để thảo luận sâu hơn.

Các kết quả khác về khử trùng lặp. Biderman et al. (2023) thấy tác động hạn chế đến hiệu suất zero-shot từ việc khử trùng lặp The Pile; chúng tôi thảo luận thêm trong Phụ lục F.2, nhưng khuyến khích nghiên cứu khử trùng lặp thêm trên các corpus được tuyển chọn, và nghiên cứu khử trùng lặp trong chế độ bị hạn chế dữ liệu, trong đó nhiều epoch phải được thực hiện để bù đắp cho việc giảm token do khử trùng lặp gây ra.

6. Kết luận
Khi LLM được áp dụng rộng rãi, các mô hình được huấn luyện vượt quá các khuyến nghị của các quy luật mở rộng chắc chắn sẽ trở nên ngày càng phổ biến để khấu hao chi phí suy luận (Touvron et al., 2023). Điều này sẽ thúc đẩy thêm nhu cầu về các bộ dữ liệu huấn luyện trước với hàng nghìn tỷ token, một bậc độ lớn vượt ra ngoài các corpus có sẵn công khai. Chúng tôi đã chứng minh rằng việc lọc và khử trùng lặp nghiêm ngặt có thể dẫn đến một bộ dữ liệu chỉ web năm nghìn tỷ token phù hợp để tạo ra các mô hình cạnh tranh với nghệ thuật tiên tiến, thậm chí vượt trội hơn các LLM được huấn luyện trên các corpus được tuyển chọn. Chúng tôi công khai phát hành một phần trích xuất 600GT của RefinedWeb, và lưu ý rằng RefinedWeb đã được sử dụng để huấn luyện các mô hình ngôn ngữ nghệ thuật tiên tiến, chẳng hạn như Falcon-40B (Almazrouei et al., 2023).

[Tiếp tục với các phần còn lại của tài liệu...]

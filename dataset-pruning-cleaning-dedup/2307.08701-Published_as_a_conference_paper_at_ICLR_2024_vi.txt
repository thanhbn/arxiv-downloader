# 2307.08701.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/dataset-pruning-cleaning-dedup/2307.08701.pdf
# Kích thước tệp: 2594530 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
ALPAGASUS: HUẤN LUYỆN MỘT ALPACA TỐT HƠN VỚI 
ÍT DỮ LIỆU HƠN
Lichang Chen∗†, Shiyang Li∗‡, Jun Yan♯, Hai Wang‡, Kalpa Gunaratna‡, Vikas Yadav‡,
Zheng Tang‡, Vijay Srinivasan‡, Tianyi Zhou†, Heng Huang†, Hongxia Jin‡
†Đại học Maryland, College Park ‡Samsung Research America ♯Đại học Southern California
{bobchen, tianyi, heng}@umd.edu
{shiyang.li, h.wang2, k.gunaratna, vikas.y, zheng.tang,
v.srinivasan, hongxia.jin}@samsung.com
yanjun@usc.edu

TÓM TẮT
Các mô hình ngôn ngữ lớn (LLM) tăng cường khả năng tuân theo hướng dẫn thông qua việc tinh chỉnh theo hướng dẫn (IFT) trên dữ liệu hướng dẫn/phản hồi có giám sát. Tuy nhiên, các bộ dữ liệu IFT được sử dụng rộng rãi (ví dụ: 52k dữ liệu của ALPACA) một cách đáng ngạc nhiên chứa nhiều trường hợp chất lượng thấp với các phản hồi không chính xác hoặc không liên quan, điều này gây hiểu lầm và có hại cho IFT. Trong bài báo này, chúng tôi đề xuất một chiến lược lựa chọn dữ liệu đơn giản và hiệu quả để tự động xác định và lọc ra dữ liệu chất lượng thấp bằng cách sử dụng một LLM mạnh (ví dụ: ChatGPT). Để đạt được điều này, chúng tôi giới thiệu ALPAGASUS, được tinh chỉnh chỉ trên 9k dữ liệu chất lượng cao được lọc từ 52k dữ liệu ALPACA. ALPAGASUS vượt trội đáng kể so với ALPACA gốc khi được đánh giá bởi GPT-4 trên nhiều bộ kiểm tra và đánh giá con người có kiểm soát. Biến thể 13B của nó đạt được >90% hiệu suất của mô hình giáo viên (tức là Text-Davinci-003 tạo ra 52k dữ liệu) trên các nhiệm vụ kiểm tra. Nó cũng cung cấp việc huấn luyện nhanh hơn 5.7 lần, giảm thời gian huấn luyện cho biến thể 7B từ 80 phút (cho ALPACA) xuống 14 phút¹. Hơn nữa, các thí nghiệm chứng minh hiệu quả của phương pháp chúng tôi trên các bộ dữ liệu, mô hình cơ sở và bộ lọc LLM đa dạng. Nhìn chung, ALPAGASUS thể hiện một mô hình IFT tập trung vào dữ liệu mới lạ có thể được áp dụng chung cho dữ liệu tinh chỉnh theo hướng dẫn, dẫn đến việc huấn luyện nhanh hơn và các mô hình tuân theo hướng dẫn tốt hơn. Trang dự án của chúng tôi có tại: https://lichang-chen.github.io/AlpaGasus/.

1 GIỚI THIỆU
Tinh chỉnh theo hướng dẫn (IFT) (Longpre et al., 2023) gần đây đã được áp dụng như một giai đoạn huấn luyện tiếp tục thiết yếu cho các mô hình ngôn ngữ lớn đã được tiền huấn luyện (LLM) để đạt được khả năng tuân theo hướng dẫn (Ouyang et al., 2022b; Chen et al., 2023b), điều này thường được quy cho việc điều chỉnh hành vi của mô hình với một tập hợp đa dạng các hướng dẫn và phản hồi của con người (Taori et al., 2023; Askell et al., 2021). Chuỗi các mô hình được tinh chỉnh theo hướng dẫn mã nguồn mở gần đây (Taori et al., 2023; Xu et al., 2023) tiết lộ rằng việc điều chỉnh dữ liệu IFT tốt hơn có thể dẫn đến kỹ năng tuân theo hướng dẫn tốt hơn. Ví dụ, GPT-4-LLM (Peng et al., 2023) (với GPT-4 (OpenAI, 2023b) làm giáo viên) thể hiện khả năng lý luận và toán học tốt hơn ALPACA (Taori et al., 2023) (với Text-davinci-003 làm giáo viên), mặc dù chúng chia sẻ cùng một mô hình cơ sở LLaMA (Touvron et al., 2023), chứng minh tầm quan trọng của chất lượng dữ liệu.

Mặc dù các giáo viên mạnh hơn thường có thể mang lại cải thiện thêm bằng cách cung cấp dữ liệu IFT tốt hơn, các phản hồi của họ không tránh khỏi bao gồm các câu trả lời không chính xác hoặc không liên quan đến các hướng dẫn tương ứng (xem ví dụ trong Hình 2), điều này có thể gây hiểu lầm hoặc có hại cho IFT. Hơn nữa, những dữ liệu này cũng tăng chi phí huấn luyện không cần thiết. Alpaca-cleaned² là tiên phong trong việc lọc dữ liệu xấu trong bộ dữ liệu ALPACA mặc dù nó yêu cầu con người tham gia đầy đủ vào việc kiểm tra và lọc dữ liệu. Tuy nhiên, cách tự động lọc ra dữ liệu chất lượng kém từ các bộ dữ liệu IFT vẫn chưa được điều tra. Một rào cản chính là việc đánh giá chất lượng dữ liệu thường yêu cầu lao động con người đắt đỏ nhưng vẫn có thể không chính xác cho IFT vì các giáo viên mạnh hơn có khả năng tạo ra các phản hồi hùng hồn nhưng không chính xác tinh tế hơn để con người phát hiện. Khi xem xét các bộ dữ liệu được tạo bởi con người, chẳng hạn như bộ dữ liệu Dolly (Dolly, 2023), việc đánh giá chất lượng trở nên phức tạp hơn, vì các phản hồi xuất phát từ các nhà văn có kinh nghiệm.

*Đóng góp ngang nhau. Công việc này được thực hiện khi Lichang Chen và Jun Yan thực tập tại Samsung Research America.
¹Chúng tôi áp dụng IFT cho cùng số epoch như ALPACA (7B) nhưng trên ít dữ liệu hơn, sử dụng 4 × GPU NVIDIA A100 (80GB) và theo cài đặt và siêu tham số A LPACA gốc.
²https://github.com/gururise/AlpacaDataCleaned/
1arXiv:2307.08701v5 [cs.CL] 13 Feb 2024

--- TRANG 2 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
rào cản là việc đánh giá chất lượng dữ liệu thường yêu cầu lao động con người đắt đỏ nhưng vẫn có thể không chính xác cho IFT vì các giáo viên mạnh hơn có khả năng tạo ra các phản hồi hùng hồn nhưng không chính xác mà con người khó phát hiện hơn. Khi xem xét các bộ dữ liệu được tạo bởi con người, chẳng hạn như bộ dữ liệu Dolly (Dolly, 2023), việc đánh giá chất lượng trở nên phức tạp hơn, vì các phản hồi xuất phát từ các nhà văn có kinh nghiệm.

Bài báo này nhằm mục đích thu hẹp khoảng cách bằng cách đề xuất một chiến lược lọc dữ liệu mới cho IFT hiệu quả, tự động và chính xác. Cụ thể, chúng tôi thiết kế một lời nhắc được áp dụng cho một LLM mạnh (ví dụ: ChatGPT) để đánh giá chất lượng của mỗi bộ ba (hướng dẫn, đầu vào, phản hồi) và sau đó lọc ra những cái có điểm thấp hơn một ngưỡng. Bằng cách áp dụng bộ lọc này cho 52k dữ liệu được sử dụng để huấn luyện ALPACA, chúng tôi thấy rằng phần lớn dữ liệu gặp phải các vấn đề chất lượng thấp. Sử dụng bộ lọc LLM, IFT trên một tập con nhỏ hơn nhiều nhưng được lọc cẩn thận gồm 9k dữ liệu tạo ra một mô hình tốt hơn nhiều, tức là ALPAGASUS, so với ALPACA gốc, như được hiển thị trong Hình 1, theo chính xác cấu hình huấn luyện giống như ALPACA. Điều này cũng giảm thời gian huấn luyện từ 80 phút xuống chỉ 14 phút trên 4 × GPU NVIDIA A100 (80GB). Hơn nữa, chúng tôi xác nhận tính linh hoạt của phương pháp chúng tôi, chứng minh hiệu quả của nó trên một loạt các bộ dữ liệu (ví dụ: Dolly, Alpaca, GPT4LLM), mô hình cơ sở (ví dụ: LLaMA-1 và LLaMA-2) và bộ lọc LLM (ví dụ: ChatGPT và Claude-2). Khám phá này rất truyền cảm hứng, vì nó cho thấy rằng chất lượng dữ liệu trong IFT có thể quan trọng hơn số lượng. Ngoài ra, sự chuyển đổi hướng tới ưu tiên chất lượng dữ liệu này trình bày một mô hình mới và hiệu quả hơn có thể cải thiện chung việc tinh chỉnh các LLM.

Các thí nghiệm của chúng tôi bao gồm các đánh giá toàn diện cho ALPAGASUS của chúng tôi, kết hợp đánh giá hướng dẫn dạng tự do, các điểm chuẩn khác nhau và nghiên cứu con người. Chúng tôi chọn bốn bộ kiểm tra hướng dẫn con người khác nhau để đánh giá khả năng tuân theo hướng dẫn, bao gồm các bộ được sử dụng bởi WizardLM (Xu et al., 2023), Vicuna (Chiang et al., 2023), Koala (Geng et al., 2023) và Self-Instruct (Wang et al., 2022). Với những lợi thế đáng chú ý mà thẩm phán GPT-4 có thể phù hợp với cả sở thích con người có kiểm soát và từ đám đông (>80% đồng ý) (Zheng et al., 2023), chúng tôi sử dụng GPT-4 làm thẩm phán cho các đánh giá chính. Trong so sánh mô hình 7B và 13B, ALPAGASUS hoạt động tốt hơn đáng kể so với ALPACA trên tất cả bốn bộ kiểm tra. Để giải quyết những lo ngại tiềm ẩn về độ lệch trong các đánh giá dựa trên mô hình, chúng tôi tiến hành các nghiên cứu con người và đánh giá điểm chuẩn, cả hai đều xác nhận tính ưu việt của mô hình chúng tôi so với các đối tác cơ sở. Hơn nữa, chúng tôi trình bày một đánh giá chi tiết của ALPAGASUS trên các nhiệm vụ cá nhân bao gồm Generic, Roleplay, Knowledge và Commonsense từ bộ kiểm tra Vicuna. Kết quả cho thấy ALPAGASUS thể hiện lợi thế trên phần lớn các nhiệm vụ.

Tóm lại, phương pháp lọc dữ liệu của chúng tôi thể hiện những lợi ích đáng kể về khả năng mở rộng và tự động hóa. Chúng tôi cũng chứng minh rằng quản lý thận trọng chất lượng dữ liệu huấn luyện có thể dẫn đến cải thiện hiệu suất đáng kể và tiết kiệm tính toán của IFT. Ngoài ra, các chiến lược lựa chọn và đánh giá dữ liệu của chúng tôi có thể tổng quát hóa cho các bộ dữ liệu tinh chỉnh theo hướng dẫn và LLM khác, do đó mở đường cho một hướng nghiên cứu mới đầy hứa hẹn nhằm mục đích triển khai LLM thực dụng.

2 PHƯƠNG PHÁP LUẬN

2.1 TỔNG QUAN
Không giống như công việc gần đây (Zhou et al., 2023), dựa vào lao động con người để tuyển chọn 1k dữ liệu hướng dẫn chất lượng cao dẫn đến một mô hình được tinh chỉnh tốt hơn, chúng tôi nhằm mục đích tránh các chú thích con người đắt đỏ và tốn thời gian. Do đó, chúng tôi khai thác tiềm năng của các LLM mạnh để trở thành các máy chấm điểm tự động của dữ liệu huấn luyện và sau đó lọc ra dữ liệu có điểm thấp hơn.

Cụ thể, chúng tôi nhắc một LLM API mạnh, tức là ChatGPT, để tạo ra một điểm cho mỗi bộ ba (hướng dẫn, đầu vào, phản hồi). Lời nhắc được đưa ra trong Hình 3, trong đó "dimension" biểu thị một

--- TRANG 3 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024
Bộ Đánh Giá Chất Lượng Phản Hồi Dựa Trên ChatGPT
...
Hướng dẫn: Phân loại vật phẩm là động vật hoặc thực vật.
Đầu vào: Chuối
Phản hồi: Động vật: Không, đó là thực vật.
Hướng dẫn: Viết lại câu sau đây bỏ qua các đại từ. 
Đầu vào: Cô ấy nói với chúng tôi rằng cô ấy bận.
Phản hồi: Nói bận.
Hướng dẫn: Dịch cụm từ "Bonne chance" sang tiếng Anh
Phản hồi: Chúc may mắn.
...
Điểm: 2.0: Phản hồi một phần tuân theo hướng dẫn bằng cách bỏ qua các đại từ, nhưng nó không cung cấp một câu hoàn chỉnh và mạch lạc. Phản hồi thiếu chủ ngữ và động từ, khiến khó hiểu ý nghĩa dự định. Phản hồi đúng sẽ là "Nói với chúng tôi bận"
Điểm 5.0: Trợ lý AI đã cung cấp một phản hồi chính xác và chính xác cho hướng dẫn và đầu vào đã cho. "Bonne chance" là một cụm từ tiếng Pháp được dịch là "Chúc may mắn" trong tiếng Anh, và trợ lý AI đã cung cấp bản dịch chính xác.
Điểm 2.0: Phản hồi của trợ lý AI là không chính xác. Chuối là một loại trái cây, là một loại thực phẩm có nguồn gốc thực vật, làm cho nó trở thành thực vật

Loại bỏ X
Loại bỏ X
Bao gồm ✅
✓ Ít dữ liệu hơn
✓ Huấn luyện nhanh hơn
✓ Hiệu suất mạnh hơn
Huấn luyện
Bao gồm ✅
Bao gồm ✅
Bao gồm ✅
Huấn luyện
......

Hình 2: Quy trình tinh chỉnh của ALPAGASUS. Chúng tôi nhắc ChatGPT làm máy chấm điểm tự động để chấm điểm mỗi bộ ba huấn luyện trên thang điểm từ 0 đến 5. Sau đó chúng tôi sử dụng chính xác cùng một script tinh chỉnh theo hướng dẫn của ALPACA để huấn luyện ALPAGASUS trên dữ liệu đã lọc với điểm cao hơn một ngưỡng.

Lời nhắc hệ thống: Chúng tôi muốn yêu cầu phản hồi của bạn về hiệu suất của trợ lý AI trong việc phản hồi hướng dẫn và đầu vào đã cho được hiển thị sau đây.
Hướng dẫn: [Hướng dẫn]
Đầu vào: [Đầu vào]
Phản hồi: [Phản hồi]
Lời nhắc người dùng: Vui lòng đánh giá theo [dimension] của phản hồi đối với hướng dẫn và đầu vào. Mỗi trợ lý nhận một điểm trên thang điểm từ 0 đến 5, trong đó điểm cao hơn cho thấy mức độ [dimension] cao hơn. Vui lòng đầu tiên xuất ra một dòng duy nhất chứa giá trị cho thấy điểm số. Trong dòng tiếp theo, vui lòng cung cấp một giải thích toàn diện về đánh giá của bạn, tránh bất kỳ độ lệch tiềm ẩn nào.

Hình 3: Lời nhắc pG cho ChatGPT để đánh giá và lọc dữ liệu huấn luyện trong Eq. (1).

thuộc tính mà người dùng ưa thích như tính hữu ích và độ chính xác. Sau đó chúng tôi chỉ chọn những bộ ba có điểm cao hơn một ngưỡng nhất định để tinh chỉnh mô hình dòng LLaMA theo một quy trình IFT hiện có. Hình 2 minh họa quy trình lựa chọn dữ liệu và huấn luyện.

2.2 ĐÁNH GIÁ VÀ LỌC DỮ LIỆU

Cho một bộ dữ liệu IFT V của các bộ ba x = (hướng dẫn, đầu vào, phản hồi) với x ∈ V và một LLM mã nguồn mở θ (ví dụ: LLaMA), hãy để θV biểu thị θ được tinh chỉnh trên V, mục tiêu tổng thể của chúng tôi là chọn một tập con S ⊂ V sao cho IFT trên S dẫn đến một mô hình tốt hơn θS so với θV.

Để chọn S từ V, chúng tôi nhắc một LLM API G(·) (ví dụ: ChatGPT³) làm máy chấm điểm tự động đánh giá mỗi mẫu x ∈ V bằng một điểm G(x, pG) trong đó pG là lời nhắc đánh giá trong Hình 3. Sau đó chúng tôi chọn xi có điểm trên một ngưỡng nhất định τ, tức là,

S ≜ {x ∈ V : G(x, pG) ≥ τ}. (1)

Chúng tôi đạt được θS bằng cách tinh chỉnh θ trên S sử dụng một khung IFT hiện có.

³Chúng tôi cũng sử dụng claude-2 làm bộ đánh giá chất lượng phản hồi, có thể tìm thấy trong Phụ lục A.2

--- TRANG 4 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

2.3 ALPAGASUS: 9K DỮ LIỆU HUẤN LUYỆN ĐƯỢC LỌC TỪ ALPACA

Đối với "dimension" trong lời nhắc đánh giá pG được hiển thị trong Hình 3, vì "accuracy" (độ chính xác) gần gũi với kỳ vọng của con người về các phản hồi của LLM, chúng tôi chỉ định "accuracy" là dimension để đánh giá⁴. Tương ứng, chúng tôi thiết lập τ trong Eq. (1) là một ngưỡng độ chính xác cho các thí nghiệm tiếp theo. Phân phối điểm liên quan đến bộ dữ liệu Alpaca 52k được trình bày trong Hình 4.

Cụ thể, chúng tôi chọn ngưỡng τ = 4.5 theo biểu đồ điểm. Đối với bộ dữ liệu ALPACA V với 52,002 mẫu, tiêu chí lọc này dẫn đến một tập con S của 9,229 mẫu⁵.

[THIS IS FIGURE: Histogram of Scores (Alpaca Dataset) showing score distribution with counts on y-axis and scores from <3 to 5 on x-axis]

Hình 4: Biểu đồ điểm (Bộ dữ liệu Alpaca).

3 THIẾT LẬP THÍ NGHIỆM

3.1 ĐÁNH GIÁ HƯỚNG DẪN DẠNG TỰ DO

Hầu hết các mô hình được tinh chỉnh theo hướng dẫn được đánh giá trên một bộ kiểm tra có thể không bao gồm đủ hướng dẫn đa dạng và do đó dẫn đến rui ro đánh giá thiên lệch (Chia et al., 2023). Để tiến hành đánh giá toàn diện về ALPAGASUS, chúng tôi tuyển chọn các bộ kiểm tra từ Self-instruct (Wang et al., 2022), Vicuna (Chiang et al., 2023), WizardLM (Xu et al., 2023) và Koala (Geng et al., 2023), cùng nhau có thể bao gồm nhiều loại hướng dẫn hơn và giảm thiểu độ lệch đánh giá. Chi tiết về bốn bộ kiểm tra này được cung cấp trong Bảng 1.

3.2 CÁC MÔ HÌNH CƠ SỞ

[THIS IS TABLE: Table showing test sets with columns for Test Set, # Samples, and Category. Shows data for Koala (180), Vicuna (80, ✓), WizardLM (218, ✓), and Self-Instruct (252)]

Bảng 1: Bốn bộ kiểm tra được sử dụng trong bài báo này.

Chúng tôi so sánh ALPAGASUS của chúng tôi với bốn LLM gần đây sau đây.

ALPACA (Taori et al., 2023) là một mô hình mã nguồn mở được phát triển bởi Đại học Stanford thông qua IFT của LLaMA trên một bộ dữ liệu huấn luyện gồm 52,002 mẫu (hướng dẫn, đầu vào, phản hồi) với các phản hồi được tạo bởi Text-Davinci-003 (giáo viên).

TEXT-DAVINCI-003 là một LLM của OpenAI được huấn luyện với sự nhấn mạnh tăng cường về hiểu ngữ cảnh và độ chính xác phản hồi. Khả năng thành thạo trong việc nắm bắt các mẫu ngôn ngữ phức tạp khiến nó trở thành một LLM giáo viên mạnh mẽ để tạo ra dữ liệu huấn luyện chất lượng cao cho việc tinh chỉnh các LLM như ALPACA.

CHATGPT (OpenAI, 2023a) là một chatbot AI được tinh chỉnh thông qua học tăng cường với phản hồi con người (RLHF). Nó thể hiện khả năng đặc biệt trên một loạt các nhiệm vụ và có thể là chatbot phổ biến nhất gần đây. Do đó, sẽ thú vị khi nghiên cứu mức độ ALPAGASUS có thể phù hợp với hiệu suất của nó.

CLAUDE (Bai et al., 2022) là một chatbot AI được phát triển bởi Anthropic. Nó được tinh chỉnh bởi RLHF để phù hợp với sở thích con người trên ba chiều, tức là hữu ích, trung thực và vô hại. Chúng tôi sử dụng Claude-v1.1 để so sánh, có thể so sánh với ChatGPT trên AlpacaEval (Li et al., 2023).

3.3 THƯỚC ĐO ĐÁNH GIÁ

Việc đánh giá khả năng tuân theo hướng dẫn của các LLM thường khó khăn do tồn tại nhiều phản hồi phù hợp cho một hướng dẫn và khó khăn trong việc tái tạo các đánh giá con người. Dựa trên những tiến bộ gần đây trong đánh giá tự động (Dubois et al., 2023; Zheng et al., 2023; Chiang et al., 2023), mang lại khả năng mở rộng và khả năng giải thích vượt trội so với các nghiên cứu con người, chúng tôi cũng áp dụng một LLM API J(·) (ví dụ: GPT-4) làm thẩm phán để đánh giá θS và so sánh nó với θV. Cụ thể, chúng tôi áp dụng J(·) để so sánh các phản hồi của θS và θV cho mỗi hướng dẫn z được rút ra từ một bộ kiểm tra D. Hãy để F(z; θV) và F(z; θS) biểu thị phản hồi của hai mô hình đối với hướng dẫn z ∈ D, thẩm phán xuất ra một điểm cho mỗi phản hồi và chúng tôi nhằm mục đích đạt được điểm cao hơn trên θS, tức là,

J(F(z; θS)) ≥ J(F(z; θV)) (2)

cho hầu hết z ∈ D. Trong các thí nghiệm của chúng tôi, chúng tôi bao gồm cả phản hồi của hai mô hình trong đầu vào cho thẩm phán (ví dụ: GPT-4), tiếp theo là một hướng dẫn cho thẩm phán, nhằm mục đích đánh giá các phản hồi với điểm từ 1 đến 10. Chi tiết về đầu vào và lời nhắc cho thẩm phán có thể tìm thấy trong Phụ lục C⁶.

Vì tồn tại độ lệch vị trí trong các thẩm phán LLM, điều này đề cập đến một hiện tượng mà các thẩm phán LLM có xu hướng ưa thích các vị trí cụ thể hơn các vị trí khác (Wang et al., 2018; Ko et al., 2020; Wang et al., 2023), để giảm thiểu nó, chúng tôi thử cả hai thứ tự (tức là đặt phản hồi của ALPAGASUS trước/sau phản hồi của mô hình cơ sở) và định nghĩa phán quyết cuối cùng của "Win-Tie-Lose" là: (1) Win: ALPAGASUS thắng hai lần, hoặc thắng một lần và hòa một lần. (2) Tie: ALPAGASUS hòa hai lần, hoặc thắng một lần và thua một lần. (3) Lose: ALPAGASUS thua hai lần, hoặc thua một lần và hòa một lần. Để tránh các phản hồi bị cắt, chúng tôi cho phép các mô hình tạo ra tới 1024 token. Đối với ChatGPT, Claude và Text-Davinci-003, chúng tôi đặt nhiệt độ thành 0.0 tương ứng để giảm tính ngẫu nhiên và đảm bảo so sánh công bằng.

⁴Chúng tôi hoãn thí nghiệm với các chiều khác, ví dụ: tính hữu ích, đến Phụ lục A.5.
⁵52k biểu thị 52002 mẫu từ bộ huấn luyện Alpaca gốc và 9k đại diện cho 9229 mẫu dữ liệu. (được lấy mẫu ngẫu nhiên hoặc được lọc trong các thí nghiệm của chúng tôi)

--- TRANG 5 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

4 KẾT QUẢ THÍ NGHIỆM

4.1 CHẤT LƯỢNG QUAN TRỌNG HƠN SỐ LƯỢNG

[THIS IS FIGURE: Two bar charts showing comparison results between AlpaGasus-9k and Alpaca-52k for 13B and 7B models across different test sets (Self-Instruct, WizardLM, Koala, Vicuna)]

Hình 5: Kết quả chính: so sánh ALPAGASUS và ALPACA trên mô hình 7B và 13B của họ. ALPAGASUS-9k đạt được hiệu suất tốt hơn nhiều so với ALPACA-52k trên tất cả bốn bộ kiểm tra: Vicuna, Koala, Self-Instruct và WizardLM.

AlpaGasus-9k so với Alpaca-52k Chúng tôi so sánh ALPAGASUS và ALPACA trên hai kích thước mô hình trong Hình 5. Chúng chỉ khác nhau về dữ liệu huấn luyện: ALPACA sử dụng tất cả 52k dữ liệu trong khi ALPAGASUS chỉ sử dụng 9k dữ liệu được chọn từ 52k. Các siêu tham số và script huấn luyện của chúng giống nhau. Như được hiển thị trong kết quả đánh giá, ALPAGASUS vượt trội đáng kể so với ALPACA gốc trên tất cả bốn bộ kiểm tra. Hơn nữa, khi sử dụng LLaMA-2 làm mô hình cơ sở, chúng tôi quan sát thấy kết quả nhất quán (Xem Phụ lục A.3). Sự nhất quán này nhấn mạnh tính phổ quát của phương pháp lọc dữ liệu của chúng tôi, bất kể lựa chọn mô hình. Những phát hiện này cũng xác nhận rằng phương pháp lựa chọn dữ liệu huấn luyện của chúng tôi dẫn đến hiệu suất vượt trội ngay cả khi dữ liệu huấn luyện được chọn chỉ là 17.75% của bộ dữ liệu gốc.

[THIS IS FIGURE: Two more bar charts comparing AlpaGasus-9k with Alpaca-9k-Random for 7B and 13B models]

Hình 6: So sánh ALPAGASUS với LLaMA được tinh chỉnh trên dữ liệu được chọn ngẫu nhiên.

Lọc hướng dẫn chất lượng so với lọc ngẫu nhiên Để điều tra hiệu quả của chiến lược lựa chọn dữ liệu của chúng tôi, chúng tôi so sánh ALPAGASUS với các mô hình LLaMA được tinh chỉnh trên một tập con được lấy mẫu ngẫu nhiên từ dữ liệu ALPACA 52k, được ký hiệu là ALPACA-9k-random trong Hình 6. Cả hai mô hình đều bắt đầu từ cùng một mô hình ban đầu (tức là LLaMA) và sau đó được tinh chỉnh trên cùng số lượng mẫu (tức là 9k). Chúng chỉ khác nhau về tiêu chí lựa chọn dữ liệu. Trong Hình 6, chúng tôi so sánh hai loại mô hình dưới hai kích thước mô hình, tức là 7B và 13B. ALPAGASUS-9k vượt trội đáng kể so với ALPACA-9k-random, cho thấy chất lượng cao của dữ liệu được chọn của chúng tôi và tầm quan trọng của chúng đối với hiệu suất của IFT.

⁶Để giải quyết những lo ngại tiềm ẩn về độ lệch trong các lời nhắc đánh giá, chúng tôi cũng trình bày kết quả sử dụng các lời nhắc đánh giá thay thế trong Phụ lục A.1.

--- TRANG 6 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

4.2 NÊN LỌC BAO NHIỀU DỮ LIỆU?

[THIS IS FIGURE: Bar chart showing comparison between Alpaca-39k-Filtered vs Alpaca-52k across different test sets]

Hình 7: So sánh ALPACA-7B (39k dữ liệu) với ALPACA-7B (52k dữ liệu).

Ngưỡng τ của việc lọc dữ liệu. Trong Eq. (1), chúng tôi chọn dữ liệu có điểm ≥ τ và chúng tôi đặt τ = 4.5 trong các thí nghiệm chính, dẫn đến 9k trong số 52k dữ liệu để tinh chỉnh ALPAGASUS. Để nghiên cứu tác động của ngưỡng τ đối với IFT, chúng tôi so sánh ALPAGASUS với LLaMA được tinh chỉnh trên 39k dữ liệu được chọn bằng cách áp dụng ngưỡng thấp hơn τ = 4.0. Chúng tôi báo cáo kết quả so sánh trong Hình 7. Khi được kiểm tra trên các bộ kiểm tra Koala và WizardLM, mô hình ALPACA-39k vượt trội so với mô hình ALPACA-52k gốc. Tuy nhiên, khi sử dụng Vicuna và Self-Instruct làm bộ kiểm tra, ALPACA-39k không thể hiện lợi thế so với mô hình ALPACA-52k gốc. Do đó, một tiêu chí lỏng lẻo (ngưỡng thấp hơn) bao gồm nhiều dữ liệu hơn trong dữ liệu được chọn và một mô hình có hiệu suất tương đương với ALPACA gốc. Tuy nhiên, nó vẫn hoạt động kém hơn ALPAGASUS được huấn luyện trên ít dữ liệu hơn nhiều nhưng chất lượng cao hơn, cho thấy tác động tiêu cực của dữ liệu chất lượng thấp đối với IFT.

AlpaGasus được huấn luyện trên 3k/6k/9k dữ liệu được chọn. Mặt khác, dữ liệu chất lượng cao cho thấy tác động tích cực đối với IFT. Để xác minh điều này, chúng tôi ngẫu nhiên rút ra 3k và 6k dữ liệu từ 9k dữ liệu được chọn để huấn luyện ALPAGASUS và tinh chỉnh hai biến thể của ALPAGASUS từ LLaMA sử dụng cùng một script huấn luyện. Hình 8 báo cáo kết quả đánh giá của các biến thể này: ALPAGASUS được huấn luyện trên 9k dữ liệu hoạt động tốt nhất trên tất cả bốn bộ kiểm tra, cho thấy rằng nhiều dữ liệu chất lượng cao hơn dẫn đến các mô hình IFT tốt hơn.

[THIS IS FIGURE: Two bar charts showing comparison between AlpaGasus-7B(9k) vs Alpaca-7B(6k) and AlpaGasus-7B(9k) vs Alpaca-7B(3k)]

Hình 8: So sánh các mô hình được tinh chỉnh trên dữ liệu chất lượng cao 3k/6k/9k (dữ liệu 3k và 6k được rút ra ngẫu nhiên từ 9k dữ liệu được chọn cho ALPAGASUS).

Dữ liệu huấn luyện tối thiểu để AlpaGasus phù hợp với hiệu suất của Alpaca. Theo Hình 1, ~6k dữ liệu chất lượng cao đủ để tinh chỉnh LLaMA đạt được hiệu suất tương tự như ALPACA gốc.

4.3 NGHIÊN CỨU CON NGƯỜI

Chúng tôi tiến hành thêm các nghiên cứu con người bằng cách tuyển dụng ba người tham gia được giao nhiệm vụ gán nhãn các cặp câu hỏi/câu trả lời. Cụ thể, chúng tôi chọn 40 lời nhắc từ mỗi bộ kiểm tra, tạo ra tổng cộng 160 lời nhắc. Sau đó chúng được trình bày cho các người tham gia cùng với các phản hồi tương ứng được tạo bởi cả ALPAGASUS-13B và Alpaca-13B. Các câu trả lời cuối cùng được xác định bằng bỏ phiếu đa số. Có 63/160 thắng cho ALPAGASUS-13B, 64/160 hòa và 33/160 thua, điều này cho thấy tính ưu việt của ALPAGASUS của chúng tôi. Kết quả toàn diện trên mỗi bộ kiểm tra và hướng dẫn người dùng có thể tìm thấy trong Phụ lục J.

--- TRANG 7 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

4.4 SO SÁNH VỚI CHATGPT/CLAUDE/DAVINCI 003

[THIS IS FIGURE: Three bar charts showing comparison between AlpaGasus-13B vs ChatGPT, AlpaGasus-13B vs Davinci-003, and AlpaGasus-13B vs Claude across different categories like Generic, Knowledge, Roleplay, Commonsense, Fermi, Counterfactual, Coding, Math, Writing]

Hình 9: ALPAGASUS-13B so với Davinci-003, Claude và ChatGPT. ALPAGASUS đạt được khả năng trung bình 90,1% của Davinci003, 81,2% của Claude và 78,4% của ChatGPT.

Trong Hình 9, chúng tôi so sánh ALPAGASUS với text-Davinci-003, ChatGPT và Claude. Kết quả cho thấy ALPAGASUS-13B có thể đạt được ≥90% khả năng của mô hình giáo viên, text-Davinci-003, được sử dụng để tạo ra dữ liệu hướng dẫn ALPACA-52k.

4.5 HIỆU SUẤT ĐIỂM CHUẨN

Theo InstructEval (Chia et al., 2023), chúng tôi cũng đánh giá các mô hình của chúng tôi trên các bộ dữ liệu điểm chuẩn, tức là MMLU (Hendrycks et al., 2020), DROP (Dua et al., 2019) Humaneval (Chen et al., 2021), BBH (Suzgun et al., 2022), để đánh giá hiệu suất của các mô hình. Chi tiết về cài đặt điểm chuẩn có thể tìm thấy trong Phụ lục B. Kết quả điểm chuẩn của ALPAGASUS của chúng tôi được hiển thị trong Bảng 2, trong đó các giá trị cao hơn cho thấy hiệu suất tốt hơn. ALPAGASUS-7B, 13B cho thấy tính ưu việt trên 3/4 bộ dữ liệu, điều này chứng minh hiệu quả của thuật toán lọc của chúng tôi. Một phát hiện thú vị khác là các mô hình được huấn luyện với dữ liệu được lọc của chúng tôi có thể tốt hơn trên tất cả các điểm chuẩn so với việc huấn luyện với dữ liệu được chọn ngẫu nhiên⁷.

[THIS IS TABLE: Table 2 showing benchmark results for filtering Alpaca dataset across different models (7B and 13B) with columns for BBH, Drop, Humaneval, and MMLU scores]

Bảng 2: Kết quả điểm chuẩn của việc lọc bộ dữ liệu Alpaca.

5 LỌC BỘ HƯỚNG DẪN VIẾT BỞI CON NGƯỜI

Ngoài việc lọc các bộ dữ liệu được tạo bởi máy, phương pháp của chúng tôi có khả năng lọc các bộ dữ liệu được viết bởi con người. Cụ thể, chúng tôi điều tra bộ dữ liệu Databricks-dolly-15k (Dolly, 2023), một bộ sưu tập tinh túy gồm 15.000 cặp lời nhắc/phản hồi chất lượng cao được tạo bởi con người. Đáng chú ý, bộ dữ liệu vô song này là sản phẩm của những nỗ lực tập thể của hơn 5.000 cộng tác viên Databricks và các lời nhắc và phản hồi được bao gồm không chỉ là văn bản đơn giản; chúng thể hiện một phạm vi toàn diện của nhận thức con người, bao gồm các hoạt động từ động não sáng tạo đến tóm tắt ngắn gọn.

Chúng tôi cũng áp dụng ngưỡng 4.5 cho việc lọc dữ liệu, dẫn đến một bộ dữ liệu được lọc gồm 2.996 mẫu. (Phân phối điểm có thể tìm thấy trong Phụ lục B) Một so sánh giữa LLaMA 7B/13B được huấn luyện trên bộ dữ liệu 3k được lọc của chúng tôi và mô hình được huấn luyện trên toàn bộ bộ dữ liệu Dolly 15k được minh họa trong Hình 10 và Hình 21. Đánh giá của chúng tôi cho thấy mô hình được huấn luyện trên dữ liệu được lọc của chúng tôi thể hiện hiệu suất vượt trội, do đó nhấn mạnh hiệu quả của phương pháp lọc của chúng tôi trên các bộ dữ liệu được viết bởi con người. Chi tiết toàn diện về các siêu tham số huấn luyện được cung cấp trong Phụ lục D⁸.

⁷Chúng tôi quan sát thấy những lợi ích hiệu suất tương tự của mô hình 7B trên Dolly, và mô hình 13B (3k) của chúng tôi luôn vượt trội so với các đường cơ sở, tức là 13B(random-3k) và 13B(15k), trên tất cả bốn bộ dữ liệu điểm chuẩn, được hoãn lại đến Phụ lục B.

⁸Kết quả trong Phụ lục A.4 (bộ dữ liệu GPT4LLM) cho thấy tiềm năng áp dụng bộ đánh giá chất lượng phản hồi dựa trên ChatGPT của chúng tôi để lọc các phản hồi của GPT-4, được coi là mô hình mạnh nhất.

--- TRANG 8 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

[THIS IS FIGURE: Two bar charts showing comparison between Dolly-7B(3k) vs Dolly-7B(15k) and Dolly-7B(3k) vs Dolly-7B(3k-random) across different test sets]

Hình 10: So sánh các mô hình được tinh chỉnh trên dữ liệu được lọc 3k và dữ liệu Dolly gốc 15k.

6 NGHIÊN CỨU TRƯỜNG HỢP & PHÂN TÍCH

[THIS IS FIGURE: Two text boxes showing case studies comparing different models' responses to math and coding questions]

Hình 11: Nghiên cứu trường hợp trên các mô hình 13B của ALPAGASUS và ALPACA. Trái: So sánh khả năng toán học dựa trên bộ kiểm tra WizardLM. Phải: So sánh kỹ năng lập trình dựa trên bộ kiểm tra Vicuna.

Hình 11 cho thấy hai nghiên cứu trường hợp của các mô hình 13B được huấn luyện trên 52k dữ liệu (ALPACA), 9k dữ liệu được chọn (ALPAGASUS) và 9k dữ liệu được chọn ngẫu nhiên (ALPACA-9k-random). Nghiên cứu trường hợp bên trái tập trung vào khả năng toán học, trong đó ALPAGASUS có thể đưa ra câu trả lời chính xác trong khi ALPACA-9k-random thì không. Với vai trò thẩm phán, GPT-4 đánh giá câu trả lời của ALPAGASUS với điểm 10.0 trong khi ALPACA-9k-random nhận điểm 2.0. Nghiên cứu trường hợp bên phải tập trung vào kỹ năng lập trình, ALPACA-52k không thể tuân theo hướng dẫn nhưng tạo ra một biểu thức chính quy để xác thực địa chỉ trang web trong khi ALPAGASUS trực tiếp tạo ra mã chính xác.

Chúng tôi cũng tiến hành đánh giá chi tiết về ALPAGASUS trên mỗi kỹ năng/danh mục trong các bộ kiểm tra WizardLM và Vicuna, có các mẫu được chia thành một danh sách các tập kỹ năng/danh mục và do đó tạo điều kiện cho việc phân tích chi tiết các khả năng đạt được bởi IFT (Phụ lục H). Chúng tôi so sánh hai mô hình 7B trên bộ kiểm tra WizardLM và báo cáo kết quả trong Hình 25. ALPAGASUS của chúng tôi đạt được hiệu suất tốt hơn hoặc tương đương với ALPACA trên 22/29 kỹ năng nhưng không thể hiện lợi thế trên 7 kỹ năng còn lại như lập trình (ví dụ: tạo mã). Để điều tra nguyên nhân, chúng tôi nhận thấy rằng các danh mục lập trình bao gồm "python", "Java", "C++" và "C#", điều này cho thấy rằng chúng tôi có thể phân bổ các mẫu huấn luyện liên quan đến kỹ năng lập trình dựa trên các từ khóa liên quan này (Phụ lục E). Chúng tôi thấy rằng việc lựa chọn/lọc dữ liệu của chúng tôi, không chỉ định tỷ lệ của các danh mục kỹ năng, dẫn đến tỷ lệ lọc cao hơn nhiều của dữ liệu liên quan đến lập trình 718-85/718 = 88.16% so với tỷ lệ lọc trung bình 52002-9229/52002 = 82.25%. Do đó, kỹ năng lập trình kết quả yếu hơn các kỹ năng khác. Điều này cho thấy tầm quan trọng của việc giữ dữ liệu huấn luyện đa dạng và cân bằng giữa các danh mục khác nhau trong IFT.

7 TIẾT KIỆM CHI PHÍ

Chúng tôi so sánh chi phí huấn luyện của ALPAGASUS và ALPACA về chi phí ước tính cho việc tính toán cần thiết trên AWS. Đáng chú ý, thời gian huấn luyện được giảm từ 80 phút xuống 14 phút cho mô hình 7B và 5.5 giờ xuống 1 giờ cho mô hình 13B. Việc giảm thời gian huấn luyện như vậy không chỉ tăng cường đáng kể tốc độ lặp lại mô hình, mà còn giảm chi phí từ $27.31 xuống $4.78 cho mô hình 7B và $225.28 xuống $40.96⁹ cho mô hình 13B. Đáng chú ý rằng việc tinh chỉnh theo hướng dẫn các mô hình LLaMA 65B yêu cầu số lượng GPU lớn hơn và thời gian huấn luyện kéo dài hơn. Do đó, khi kích thước mô hình tăng lên, phương pháp lựa chọn dữ liệu của chúng tôi mang lại tiết kiệm chi phí ngày càng rõ rệt hơn.

⁹Các siêu tham số cho IFT và phương pháp tính toán chi phí dự kiến được hoãn lại trong Bảng 5.

--- TRANG 9 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

8 CÔNG TRÌNH LIÊN QUAN

Các mô hình tuân theo hướng dẫn mã nguồn mở. Các bộ dữ liệu tinh chỉnh theo hướng dẫn có thể được thu thập theo hai cách. Một số nghiên cứu (Köpf et al., 2023; Dolly, 2023; Zhou et al., 2023) sử dụng nguồn đám đông để tạo ra các cặp hướng dẫn và phản hồi do con người tạo ra. Phương pháp này, mặc dù hiệu quả, có thể tốn công sức và chi phí. Thay vào đó, ALPACA (Taori et al., 2023) mở ra cánh cửa để tạo ra các bộ IFT được tạo bởi máy từ việc chưng cất của LLM "giáo viên", tức là Text-Davinci-003. Peng et al. (2023) giữ nguyên các hướng dẫn từ ALPACA nhưng sử dụng GPT-4 làm LLM "giáo viên", điều này tăng cường mô hình về tiêu chí điều chỉnh 3H (Hữu ích, Trung thực và Vô hại) (Askell et al., 2021). Vicuna (Chiang et al., 2023) là mô hình đầu tiên áp dụng dữ liệu ShareGPT (ShareGPT, 2023), là dữ liệu đối thoại thực tế trò chuyện với ChatGPT được chia sẻ bởi người dùng. Xu et al. (2023) và Luo et al. (2023) phát triển bộ hướng dẫn Alpaca gốc và có được các hướng dẫn phức tạp hơn giúp khai thác tốt hơn khả năng tuân theo hướng dẫn của LLM. Cũng tồn tại các công trình đồng thời như Koala (Geng et al., 2023) và UltraChat (Ding et al., 2023), sử dụng dữ liệu đối thoại & sở thích cũng như các lời nhắc đối kháng để tiến hành điều chỉnh an toàn.

AI tập trung vào dữ liệu. Trong thập kỷ qua, lĩnh vực AI tập trung vào dữ liệu (Chu et al., 2016; Motamedi et al., 2021) đã chứng kiến tiến bộ đáng kể. Trọng tâm của khái niệm này là niềm tin rằng chất lượng dữ liệu (Hajij et al., 2021; Zha et al., 2023; Chen et al., 2023a;c;d) đáng được coi trọng ngang bằng với thuật toán trong chu kỳ AI/ML. Như được chỉ ra bởi Chu et al. (2016), để có sự tương tác hiệu quả với các loại dữ liệu đa dạng qua nhiều lĩnh vực khác nhau, các quy trình làm sạch dữ liệu nên thể hiện mức độ tự động hóa và khả năng thích ứng cao hơn. Với sự ra đời của kiến trúc Transformer (Vaswani et al., 2017b), một sự thay đổi trong mô hình của các mô hình ngôn ngữ đã xảy ra. Các mô hình như RoBERTa (Liu et al., 2019), BERT (Vaswani et al., 2017a) và Bard¹⁰ đều đã tích hợp cấu trúc hiệu quả này, xếp chồng số lượng khối transformer khác nhau để tạo ra các mô hình mạnh mẽ hơn. Điều này đánh dấu một bước ngoặt trong nghiên cứu NLP, báo hiệu sự nhấn mạnh cao hơn vào dữ liệu thay vì cấu trúc mô hình. Hiện tại, các LLM SOTA như ChatGPT cũng nhấn mạnh sự chuyển đổi hướng tới dữ liệu này. Họ sử dụng dữ liệu người dùng để tiến hành Học tăng cường từ Phản hồi Con người (RLHF) (Ouyang et al., 2022a; Gao et al., 2022), điều này phù hợp thêm với triết lý AI tập trung vào dữ liệu.

Đánh giá các LLM. Việc đánh giá khả năng tuân theo hướng dẫn mở của các LLM thường bị bỏ qua bởi các công trình trước đó (Chung et al., 2022; Anil et al., 2023), mặc dù họ tiến hành một loạt các đánh giá điểm chuẩn tập trung vào tính thực tế (Hendrycks et al., 2020) và lý luận (Bisk et al., 2020) cho các mô hình tiền huấn luyện của họ. Tương tự, các khung được đề xuất bởi Liang et al. (2022) và Gao et al. (2021) tập trung nhiều hơn vào đánh giá các mô hình cơ sở nhưng không tập trung vào đánh giá các mô hình IFT, nơi khả năng tuân theo hướng dẫn mở được cho là ưu tiên. Vì tuân theo hướng dẫn là một khả năng chung nhưng phạm vi của các điểm chuẩn bị hạn chế, các công trình gần đây như Koala (Geng et al., 2023), Vicuna (Chiang et al., 2023), Self-Instruct (Wang et al., 2022) và WizardLM (Xu et al., 2023) đều cung cấp các bộ hướng dẫn mà họ thu thập và một số trong số đó cũng bao gồm các danh mục của các hướng dẫn để đánh giá các LLM được tinh chỉnh theo hướng dẫn. Cũng có một số bảng xếp hạng như Alpaca-Eval (Li et al., 2023) đo lường khả năng tuân theo hướng dẫn của mô hình. Tận dụng những tiến bộ gần đây này, chúng tôi đánh giá các mô hình của chúng tôi trên các bộ hướng dẫn con người.

9 KẾT LUẬN

Tóm lại, nghiên cứu của chúng tôi tiết lộ những hiểu biết quan trọng về ảnh hưởng của chất lượng dữ liệu so với số lượng trong IFT. Thông qua phương pháp lọc dữ liệu được đề xuất của chúng tôi, chúng tôi đã chứng minh rằng việc dựa vào một tập con nhỏ dữ liệu IFT chất lượng cao có thể dẫn đến các LLM thể hiện khả năng tuân theo hướng dẫn nâng cao, đồng thời cũng mang lại những lợi thế tính toán đáng kể. Đáng chú ý, phương pháp của chúng tôi tỏ ra linh hoạt trên các chiều đánh giá khác nhau (ví dụ: Độ chính xác và tính hữu ích), bộ lọc LLM (ví dụ: ChatGPT và Claude-2), họ mô hình cơ sở (ví dụ: LLaMA-1 và LLaMA-2), kích thước mô hình (ví dụ: 7B và 13B), các loại bộ dữ liệu (ví dụ: được tạo bởi máy và được viết bởi con người). Bằng cách nhấn mạnh tầm quan trọng của chất lượng dữ liệu, chúng tôi ủng hộ sự chuyển đổi trong mô hình hiện tại nơi tích lũy dữ liệu đã là trọng tâm chính. Sự chuyển đổi quan điểm này có thể dẫn đến những tiến bộ có ý nghĩa hơn trong lĩnh vực LLM, làm cho các mô hình phù hợp hơn với ý định của con người và ít dễ bị lỗi do dữ liệu chất lượng kém gây ra.

¹⁰https://bard.google.com/

--- TRANG 10 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

LỜI CẢM ƠN

Lichang Chen và Heng Huang được hỗ trợ một phần bởi U.S. NSF IIS 2347592, 2347604, 2348159, 2348169, DBI 2405416, CCF 2348306, CNS 2347617.

TÀI LIỆU THAM KHẢO

[Các tài liệu tham khảo được liệt kê theo thứ tự alphabetical, bao gồm các tác giả, tiêu đề, venue xuất bản, và năm xuất bản]

--- TRANG 11 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 12 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 13 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2024

Phụ lục
Mục lục

A Các câu hỏi thường gặp 14
A.1 Có tồn tại độ lệch nào trong các lời nhắc đánh giá không? . . . . . . . . . . . . . . 14
A.2 Bạn đã thử bộ lọc LLM khác chưa? . . . . . . . . . . . . . . . . . . . . . . . . . 14
A.3 Kết quả trên các mô hình cơ sở khác thì sao, ví dụ: LLaMA-2? . . . . . . . . . . 15
A.4 Bộ lọc LLM của bạn có thể đánh giá phản hồi của mô hình mạnh hơn không, ví dụ: lọc các phản hồi do GPT-4 đưa ra? . . . . . . . . . . . . . . . . . . . . . . . . . 15
A.5 Kết quả trên các chiều đánh giá khác, ví dụ: tính hữu ích? . . . . . . . . . . . . . 16

B Kết quả bổ sung trên bộ dữ liệu Dolly 17
B.1 Phân phối điểm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
B.2 Kết quả điểm chuẩn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
B.3 Kết quả Dolly-13B . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

C Chi tiết về lời nhắc đánh giá GPT-4 18

D Chi tiết các siêu tham số huấn luyện 19
D.1 Bộ dữ liệu Alpaca . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
D.2 Bộ dữ liệu Dolly . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

E Tập từ khóa cho phân tích chi tiết 19

F Các ví dụ được đánh giá trong bộ dữ liệu Alpaca 20

G Các ví dụ được đánh giá trong bộ dữ liệu Dolly 23

H Phân tích 26
H.1 Phân tích trên bộ kiểm tra WizardLM . . . . . . . . . . . . . . . . . . . . . . . 26
H.2 Phân tích trên bộ kiểm tra Vicuna . . . . . . . . . . . . . . . . . . . . . . . . . 27

I Phân tích chi tiết trên bộ kiểm tra WizardLM 27

J Nghiên cứu con người 31

K Hạn chế 31

--- TRANG 14 ---
[Tiếp tục nội dung phụ lục với các câu hỏi thường gặp, kết quả bổ sung, và các phân tích chi tiết]

--- TRANG 15 đến TRANG 31 ---
[Tiếp tục nội dung phụ lục với các biểu đồ, bảng, và phân tích chi tiết về hiệu suất của ALPAGASUS trên các bộ dữ liệu khác nhau, so sánh với các mô hình khác, và các hạn chế của nghiên cứu]

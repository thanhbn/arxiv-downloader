# Data-Juicer: Hệ thống xử lý dữ liệu một cửa cho các mô hình ngôn ngữ lớn

Sự phát triển to lớn của các mô hình ngôn ngữ lớn (LLMs) đã làm nổi bật tầm quan trọng của dữ liệu khối lượng lớn, đa dạng và chất lượng cao. Một công thức dữ liệu là sự kết hợp dữ liệu từ các loại khác nhau và từ các nguồn khác nhau để huấn luyện một LLM, được biết đến là một trong những yếu tố quan trọng nhất quyết định hiệu suất của LLM. Các công cụ mã nguồn mở hiện tại cho việc xử lý dữ liệu LLM chủ yếu được thiết kế riêng để chuẩn bị các công thức dữ liệu cụ thể. Để liên tục khám phá tiềm năng của LLMs, kết hợp dữ liệu từ các nguồn mới (sau khi làm sạch), và cải thiện hiệu suất mục đích chung hoặc chuyên môn của LLMs, chúng tôi xây dựng một hệ thống xử lý dữ liệu có tên Data-Juicer, với hệ thống này chúng tôi có thể tạo ra các công thức dữ liệu đa dạng một cách hiệu quả, khám phá các khả năng khác nhau trong việc hình thành hỗn hợp dữ liệu, và đánh giá tác động của chúng lên hiệu suất mô hình.

Khác với các pipeline phân tích dữ liệu truyền thống, Data-Juicer đối mặt với một số thách thức độc đáo. Thứ nhất, các nguồn dữ liệu có thể để hình thành công thức dữ liệu thực sự đa dạng và khối lượng lớn với chất lượng khác nhau (ví dụ: xem xét tất cả các trang web trên Internet). Thứ hai, việc đánh giá chính xác tác động của công thức dữ liệu lên hiệu suất của LLMs là cực kỳ tốn kém. Thứ ba, cần cung cấp đủ tính linh hoạt cho người dùng cuối của Data-Juicer, các nhà phát triển mô hình, để cấu hình và đánh giá các công thức dữ liệu khác nhau.

Data-Juicer có đặc điểm là trừu tượng hóa chi tiết của pipeline để xây dựng công thức dữ liệu, với hơn 50 toán tử tích hợp có thể được kết hợp và mở rộng tự do. Bằng cách kết hợp khả năng trực quan hóa và đánh giá tự động, Data-Juicer cho phép vòng phản hồi kịp thời sau khi xử lý dữ liệu cho cả việc tiền huấn luyện và tinh chỉnh LLM. Hơn nữa, Data-Juicer được tối ưu hóa và tích hợp với các hệ sinh thái để huấn luyện LLM, đánh giá và tính toán phân tán.

Với sự trợ giúp của Data-Juicer, chúng tôi tạo ra các công thức dữ liệu đạt được sự cải thiện hiệu suất đáng kể trên các LLMs tiên tiến, thể hiện tăng tới 7,45% điểm số trung bình trên 16 benchmark LLM và tỷ lệ thắng cao hơn 17,5% trong đánh giá GPT-4 theo cặp. Quan trọng hơn, chúng tôi hy vọng rằng Data-Juicer thúc đẩy nghiên cứu tập trung vào dữ liệu rộng rãi hơn về huấn luyện và hiểu biết LLMs. Data-Juicer và các công thức dữ liệu của chúng tôi được phát hành và duy trì tích cực tại https://github.com/alibaba/data-juicer.

## 1. GIỚI THIỆU

Các mô hình ngôn ngữ lớn (LLMs) đã đạt được trí thông minh chưa từng có, cho phép các ứng dụng mà nếu không có hiệu suất thỏa mãn thì sẽ không khả thi. Là "thức ăn" cho LLMs, dữ liệu đóng vai trò then chốt trong những tiến bộ thú vị này. LLMs được xây dựng bằng cách tiền huấn luyện trên corpus mục đích chung quy mô lớn và được tinh chỉnh với dữ liệu mục đích cụ thể để căn chỉnh hoặc các tác vụ hạ nguồn. Đối với dữ liệu tiền huấn luyện, một bộ sưu tập dữ liệu đa dạng, bao gồm văn bản web, đối thoại, bài báo học thuật, cơ sở mã nguồn, và những cái khác, giúp phát triển kho kiến thức rộng lớn và khả năng ứng dụng tuyệt vời. Dữ liệu tinh chỉnh, tiếp tục tinh chỉnh LLMs và căn chỉnh hành vi mô hình với các giá trị con người.

Như "rác vào, rác ra" cho thấy, dữ liệu đầu vào để huấn luyện hoặc tinh chỉnh một LLM có tác động trực tiếp đến chất lượng của mô hình tạo ra. Xây dựng các giải pháp xử lý dữ liệu hiệu quả cho LLMs vẫn là một nhiệm vụ phức tạp nhưng chưa được khám phá đầy đủ, do các thách thức chung trong việc xử lý cả dữ liệu tiền huấn luyện và tinh chỉnh, nhằm theo đuổi chất lượng dữ liệu tốt, tính đa dạng dữ liệu phù hợp, và khối lượng dữ liệu lớn.

Thật không may, chỉ tồn tại một số ít dự án mã nguồn mở đóng góp dữ liệu huấn luyện LLM và các mã xử lý tương ứng, đặc biệt là so với vô số dự án mã nguồn mở về mô hình và cơ sở hạ tầng huấn luyện. Sự phát triển hạn chế của việc xử lý dữ liệu như vậy sẽ cản trở tiến bộ của việc hiểu và nâng cao LLMs một cách định lượng từ góc độ dữ liệu, đặc biệt là kèm theo những thách thức đáng chú ý sau cho việc xử lý dữ liệu LLM.

**(C1) Tính dị thể cao trong công thức dữ liệu của LLM.** LLMs liên quan đến nhiều giai đoạn phát triển và cho phép sử dụng đa dạng bao gồm hỗ trợ lập trình và đối thoại, và thậm chí hướng đến Trí tuệ nhân tạo tổng quát. Kết quả là, chúng đòi hỏi một loạt các loại dữ liệu, định dạng và chất lượng rộng rãi trong dữ liệu huấn luyện của họ, dẫn đến các pipeline xử lý dữ liệu rất phức tạp. Một công thức dữ liệu để huấn luyện hoặc tinh chỉnh một LLM là một hỗn hợp dữ liệu được xử lý từ các loại nguồn khác nhau, với tỷ lệ và pipeline xử lý được thiết lập phù hợp. Các hệ thống hiện tại, chẳng hạn như, phát hành các script xử lý nhất định để tạo ra công thức dữ liệu cho mục đích tiền huấn luyện, trong khi tập trung vào công thức dữ liệu để cải thiện tính đa dạng và chất lượng dữ liệu trong giai đoạn tinh chỉnh của LLaMA. Tuy nhiên, do thiếu trừu tượng hóa của pipeline xử lý và khả năng kết hợp của các toán tử (OPs), chẳng hạn như những cái để chỉnh sửa, làm sạch và lọc dữ liệu, khó có thể kết hợp các nguồn dữ liệu mới trong công thức dữ liệu được cung cấp bởi những hệ thống này, hoặc mở rộng pipeline của chúng để khám phá các khả năng khác của công thức dữ liệu.

**(C2) Phản hồi kịp thời cho công thức dữ liệu.** Không gian tìm kiếm của công thức dữ liệu của LLM là rất lớn do mức độ dị thể cao trong các nguồn dữ liệu và nhiều cách để kết hợp chúng (với OPs xử lý phù hợp, kết hợp và tỷ lệ). Chúng tôi muốn khám phá càng nhiều công thức dữ liệu trong không gian tìm kiếm càng tốt với phản hồi kịp thời để khám phá tiềm năng của LLMs và cải thiện hiệu suất của chúng. Tuy nhiên, vì kích thước của một LLM (số lượng tham số mô hình) thường là hàng tỷ hoặc thậm chí lớn hơn, việc đánh giá tác động cực kỳ tốn kém, về cả thời gian và tài nguyên tính toán, của một công thức dữ liệu lên hiệu suất LLM bằng cách huấn luyện hoặc tinh chỉnh với công thức và chạy các benchmark đánh giá.

**(C3) Tính khả dụng và có thể tùy chỉnh.** Quy trình làm việc của việc huấn luyện hoặc tinh chỉnh LLMs bắt đầu từ việc xử lý dữ liệu thô. Được làm trầm trọng bởi hai thách thức trên, có nhu cầu cấp thiết cho một cơ sở hạ tầng tập trung vào dữ liệu, để các nhà phát triển mô hình có thể dễ dàng tái sử dụng hoặc thực hiện các OPs và công cụ của riêng họ để xử lý dữ liệu, cấu hình pipeline xử lý của họ, khám phá các công thức dữ liệu khác nhau, và đánh giá hiệu suất LLMs kết quả. Chúng tôi cần một hệ thống như vậy để tăng tốc việc khám phá và hiểu biết về tiềm năng của LLMs.

**(C4) Khối lượng dữ liệu khổng lồ.** Cuối cùng nhưng không kém phần quan trọng, LLMs được huấn luyện trên corpus rộng lớn, với khối lượng dữ liệu kéo dài đến mức chưa từng có là hàng tỷ hoặc thậm chí hàng nghìn tỷ token (một đơn vị mô hình hóa của văn bản phụ thuộc vào tokenizer được sử dụng). Xử lý dữ liệu LLM hiệu quả của khối lượng như vậy là quan trọng nhưng gian khổ. Tuy nhiên, những cân nhắc về tối ưu hóa hiệu suất hệ thống thường bị bỏ qua bởi các nghiên cứu hiện tại, để lại chỗ đáng kể cho việc nâng cao trong việc đảm bảo tính ổn định của xử lý dữ liệu và tạo thuận lợi cho việc cung cấp dữ liệu được xử lý và trọng số được huấn luyện cho LLMs.

**Tổng quan về Data-Juicer.** Trong bài báo này, chúng tôi ủng hộ một hệ thống xử lý dữ liệu một cửa giải quyết những thách thức này, cho phép khả năng xử lý dữ liệu toàn diện, thân thiện với người dùng và hiệu quả để tạo thuận lợi cho nghiên cứu và phát triển LLM tập trung vào dữ liệu. Hệ thống được đề xuất, có tên Data-Juicer và được minh họa trong khung nhìn từ dưới lên trong Hình 1, được thiết kế chiến lược để tạo ra các công thức dữ liệu làm cho dữ liệu "ngọt ngào" hơn và dễ tiêu hóa hơn cho LLMs.

Chúng tôi tách biệt các yếu tố hỗn hợp của các giải pháp hiện tại cho việc xử lý dữ liệu LLM, chẳng hạn như các loại dữ liệu cụ thể, mô hình phụ trợ và tác vụ hạ nguồn. Như được làm nổi bật bởi các hộp màu xanh lá cây, Data-Juicer thúc đẩy việc trừu tượng hóa và triển khai chi tiết của các mô-đun có thể kết hợp với hơn 50 OPs đa năng và các công cụ chuyên dụng. Chúng tôi làm cho Data-Juicer có thể cấu hình từ đầu đến cuối để giúp chuẩn bị các công thức dữ liệu có thể truy vết, so sánh và cải tiến trong các kịch bản khác nhau của tiền huấn luyện và tinh chỉnh LLM, như được hiển thị trong các hộp màu vàng và hồng. Kết hợp với các khả năng tự động đánh giá đã được thiết lập, Data-Juicer hỗ trợ vòng phản hồi kịp thời tại nhiều giai đoạn phát triển của công thức dữ liệu và LLMs, từ đó thúc đẩy sản xuất dữ liệu LLM có giá trị.

Để đáp ứng nền tảng người dùng và nhu cầu đa dạng (được đánh dấu bằng ba hộp hình chữ nhật bên trái), chúng tôi thiết kế Data-Juicer như một hệ thống dễ sử dụng, linh hoạt và có thể mở rộng. Người mới bắt đầu được bảo vệ khỏi những phức tạp cơ bản và hưởng lợi từ nhiều bộ dữ liệu sẵn sàng sử dụng, công thức dữ liệu và công cụ có thể cắm, hỗ trợ xử lý dữ liệu LLM không cần mã. Với sự trợ giúp của mô-đun cấu hình linh hoạt, người dùng có kinh nghiệm có thể đơn giản sửa đổi các công thức dữ liệu tích hợp, tổ chức lại thứ tự của OPs và công cụ, và điều chỉnh giá trị của các siêu tham số của chúng, để đáp ứng nhu cầu tùy chỉnh nhẹ của họ. Nhờ vào việc tiêu chuẩn hóa và mô-đun hóa, người dùng nâng cao được trao quyền để thuận tiện mở rộng và đăng ký OPs và công cụ mới của họ vào Data-Juicer, tạo thuận lợi cho việc tham gia nhanh chóng vào phát triển thứ cấp. Hơn nữa, chúng tôi cung cấp hơn một chục hướng dẫn tương tác được triển khai bằng streamlit để giúp người dùng trong hành trình xử lý dữ liệu LLM của họ.

Data-Juicer tựa vào thư viện Huggingface-datasets, cung cấp đại diện trung gian thống nhất của dữ liệu và đạt được hiệu quả tối ưu về không gian-thời gian và tính mạnh mẽ thông qua các kỹ thuật khác nhau như quản lý bối cảnh, hợp nhất OP, bộ nhớ đệm và cơ chế checkpoint. Hơn nữa, như hai vòng tròn bên phải hiển thị, Data-Juicer tích hợp liền mạch với các hệ sinh thái để huấn luyện và đánh giá LLM như Megatron-LM và HELM, và các hệ sinh thái tính toán phân tán như Ray và Beam, do đó tạo thuận lợi cho việc xử lý dữ liệu LLM toàn diện và nâng cao khả năng xử lý dữ liệu quy mô lớn.

Tận dụng hệ thống được đề xuất, chúng tôi tinh chỉnh một số bộ dữ liệu mã nguồn mở và tạo ra nhiều công thức dữ liệu cho cả tiền huấn luyện và tinh chỉnh LLM. Những bộ dữ liệu được tinh chỉnh này không chỉ có chất lượng cao hơn mà còn dễ tiêu hóa hơn bởi LLMs, dẫn đến cải thiện hiệu suất hiệu quả của LLMs. Phân tích thực nghiệm cho thấy sự cải thiện tới 7,45% điểm số trung bình trên 16 benchmark LLM sử dụng dữ liệu tiền huấn luyện được tinh chỉnh của chúng tôi. Ngay cả khi được tiền huấn luyện chỉ với 43% số lượng dữ liệu so sánh, chúng tôi quan sát thấy hiệu suất vượt trội so với các LLMs tiên tiến như Falcon. Hơn nữa, so với các LLMs tiên tiến được tinh chỉnh trên dữ liệu tiếng Anh và tiếng Trung mở cạnh tranh, LLMs được tinh chỉnh trên dữ liệu của Data-Juicer đạt được trung bình 10,3% tỷ lệ thắng cao hơn trong đánh giá GPT-4 theo cặp, trong khi với trung bình 56,8% ít hơn về số lượng dữ liệu.

Cuối cùng, chúng tôi giới thiệu tiện ích của nó trong triển khai thực tế, và xác nhận hiệu quả hệ thống và khả năng mở rộng vượt trội của Data-Juicer, với tới 88,7% giảm thời gian xử lý máy đơn và 77,1% tiết kiệm sử dụng bộ nhớ, và 7,91x tăng tốc xử lý phân tán.

**Đóng góp.** Đóng góp của chúng tôi được tóm tắt như sau:

• Chúng tôi đề xuất và xây dựng một hệ thống mới để xử lý dữ liệu LLM, Data-Juicer, có đặc điểm là các mô-đun tách biệt và hơn 50 OPs và công cụ đa năng. Để dễ dàng đi sâu vào chất lượng dữ liệu và thông tin chi tiết, Data-Juicer thúc đẩy vòng phản hồi kịp thời với trực quan hóa tương tác và khả năng tự động đánh giá.

• Được chứng minh bằng bằng chứng thực nghiệm rộng rãi, Data-Juicer tạo ra nhiều công thức dữ liệu chất lượng cao để nâng cao LLMs và thể hiện hiệu suất hệ thống vượt trội, được cung cấp bởi tối ưu hóa chuyên dụng và các hệ sinh thái tính toán phân tán tích hợp.

• Chúng tôi tích hợp các phương pháp luận tập trung vào dữ liệu để xử lý dữ liệu LLM và phát triển LLM với thiết kế giao diện tập trung vào người dùng, với mục tiêu Data-Juicer có thể tạo điều kiện tiếp cận dễ dàng cho người dùng đa dạng và dân chủ hóa việc xử lý dữ liệu LLM.

• Để thúc đẩy nghiên cứu và phát triển hơn nữa, hệ thống, công thức dữ liệu và hướng dẫn của chúng tôi được duy trì và phát hành tại https://github.com/alibaba/data-juicer, điều mà chúng tôi hy vọng có thể giúp mở đường cho các mô hình sản xuất thế hệ tiếp theo của dữ liệu LLM.

**Tổ chức.** Các phần tiếp theo mô tả Data-Juicer một cách chi tiết. Phần 2 trình bày chi tiết về nền tảng và các nghiên cứu liên quan. Phần 3 phác thảo nhóm OP của chúng tôi, như một phản hồi cho tính dị thể cao của công thức dữ liệu LLM (C1). Phần 4 đi sâu vào cách thức xây dựng vòng phản hồi kịp thời cho việc xử lý dữ liệu và phát triển LLMs (C2). Phần 5 trình bày chi tiết kho công thức dữ liệu và công cụ của chúng tôi chống lại các vấn đề về khả năng sử dụng và tùy chỉnh (C3). Phần 6 trình bày về tối ưu hóa hệ thống được sử dụng để giải quyết khối lượng dữ liệu khổng lồ (C4). Phần 7 tập trung vào đánh giá thực nghiệm rộng rãi về chất lượng công thức dữ liệu, hiệu suất và khả năng sử dụng của Data-Juicer. Cuối cùng, chúng tôi đưa ra tóm tắt trong Phần 8.

## 2. NỀN TẢNG VÀ CÁC NGHIÊN CỨU LIÊN QUAN

### 2.1 Dữ liệu mô hình ngôn ngữ lớn (LLM)

**Mô hình ngôn ngữ lớn (LLMs).** Mô hình hóa ngôn ngữ là một thành phần quan trọng để đạt được trí thông minh máy. Trong vài năm qua, lĩnh vực này đã chứng kiến những tiến bộ đáng kể, đặc biệt là với sự xuất hiện của các mô hình tiền huấn luyện và tinh chỉnh, nơi các mô hình ngôn ngữ trải qua giai đoạn đầu huấn luyện với corpus mục đích chung trước khi được tinh chỉnh với các tác vụ mục đích cụ thể. Quy trình này đã mang lại hiệu suất đặc biệt trên một phổ các tác vụ xử lý ngôn ngữ tự nhiên (NLP).

Gần đây, tận dụng tính chất có thể song song hóa cao của kiến trúc Transformer tự giám sát, quy mô của tham số mô hình và corpus huấn luyện cho LLMs đã được tăng lên đáng kể. Đồng thời, LLMs đã gây ra sự quan tâm đáng kể về tiềm năng của trí tuệ nhân tạo tổng quát. Trong khi các nghiên cứu tập trung vào mô hình phổ biến, cách xử lý dữ liệu LLM tốt hơn vẫn là một lĩnh vực phức tạp chưa được mở ra hoàn toàn, dù cho dữ liệu tiền huấn luyện hay tinh chỉnh.

**Dữ liệu tiền huấn luyện.** Tiền huấn luyện phục vụ như nền tảng cho trí thông minh LLM. Bằng cách được huấn luyện trên lượng lớn dữ liệu chất lượng cao, LLMs có thể có được khả năng hiểu và tạo ra ngôn ngữ cơ bản. Nhằm làm sáng tỏ mối liên hệ giữa dữ liệu và LLMs một cách trực quan, hãy xem xét một mục tiêu tiền huấn luyện điển hình phổ biến trong các LLMs chính thống. Cho trước một chuỗi token [t₁,...,tᵢ,...,tₙ], một LLM θ được huấn luyện để tối đa hóa xác suất kết hợp của văn bản như sau:

θ₀ = arg max_θ Σᵢ₌₁ⁿ log p(tᵢ|t₁:ᵢ₋₁; θ). (1)

Mục tiêu này dành cho mô hình hóa ngôn ngữ tự hồi quy và cho phép θ₀ được tiền huấn luyện dự đoán xác suất của token tiếp theo bằng cách tuân thủ thứ tự tuần tự vốn có của ngôn ngữ. Khai thác mục tiêu mô hình hóa thống nhất nhưng đơn giản này, các nhà nghiên cứu thu thập một khối lượng lớn và phạm vi đa dạng dữ liệu corpus, thường chứa hàng trăm tỷ token hoặc thậm chí hàng nghìn tỷ token. Sau khi token hóa và tiền huấn luyện, LLMs đã thành công trong việc kích thích một loạt khả năng tiên tiến.

Dữ liệu tiền huấn luyện LLM thường bao gồm các loại khác nhau được lấy từ các trình thu thập web, đối thoại hoặc truyền thông xã hội, văn bản chính thức dài như sách, bách khoa toàn thư nghiêm ngặt và văn bản học thuật, văn bản mã có cấu trúc, và thêm văn bản từ các lĩnh vực tài chính, y tế và pháp lý. Tuy nhiên, một thách thức được đặt ra trong việc xử lý và xây dựng cẩn thận dữ liệu tiền huấn luyện để lọc nhiễu, dư thừa, không liên quan và có khả năng độc hại.

**Dữ liệu tinh chỉnh.** Nhiều nghiên cứu đã nhấn mạnh rằng tinh chỉnh – quy trình tinh chỉnh LLMs được tiền huấn luyện sử dụng bộ dữ liệu nhỏ hơn, cụ thể cho tác vụ – có thể nâng cao hơn nữa hoặc mở khóa các khả năng bổ sung của LLMs. Quan trọng là, quy trình này cũng mở đường cho việc căn chỉnh tốt hơn hành vi của những mô hình tiên tiến này với các giá trị và sở thích của con người.

Trong giai đoạn này, mặc dù khối lượng dữ liệu giảm theo cấp số nhân so với giai đoạn tiền huấn luyện, định dạng dữ liệu tinh chỉnh khá khác biệt. Thông thường, cho trước một bộ dữ liệu văn bản {(x₁,s₁,y₁),...,(xⱼ,sⱼ,yⱼ),...,(xₘ,sₘ,yₘ)}, mục tiêu của tinh chỉnh là điều chỉnh LLM được tiền huấn luyện θ₀ để tìm θ* tối đa hóa khả năng của phản hồi hướng tác vụ yⱼ cho truy vấn người dùng xⱼ:

θ* = arg max_θ Σⱼ₌₁ᵐ log p(yⱼ|xⱼ,sⱼ;θ); θ ← θ₀. (2)

Ở đây sⱼ đại diện cho các hướng dẫn cụ thể cho tác vụ, chẳng hạn như "tóm tắt văn bản sau:", tùy chọn đi kèm với một vài mẫu minh họa cho học tập trong bối cảnh.

Dữ liệu tinh chỉnh có thể được phân loại rộng rãi thành hai loại: bộ dữ liệu tinh chỉnh hướng dẫn (IFT) để nâng cao khả năng tuân theo hướng dẫn của LLMs và thường được điều chỉnh từ các benchmark NLP hiện tại; và bộ dữ liệu tinh chỉnh trò chuyện (CFT) để cải thiện khả năng đối thoại và căn chỉnh giá trị con người. Có các khám phá sơ bộ nhấn mạnh tầm quan trọng của tính đa dạng dữ liệu hơn khối lượng cho dữ liệu tinh chỉnh. Một số nghiên cứu cũng chỉ ra rằng các loại dữ liệu đại diện cho giá trị con người có thể dẫn đến hiệu suất chung bị suy giảm, một hiện tượng được gọi là "thuế căn chỉnh". Tuy nhiên, cách xử lý dữ liệu tinh chỉnh hiệu quả hơn để tối đa hóa tính hữu ích và giảm thiểu rủi ro tiềm ẩn vẫn là một lĩnh vực mở để điều tra thêm.

**Tính chất cộng sinh của dữ liệu tiền huấn luyện và tinh chỉnh.** Đáng chú ý là các tính chất tương tự được chia sẻ giữa hai loại dữ liệu này, điều tạo động lực cho cách tiếp cận hiệp lực của chúng tôi khi ghi nhớ các cân nhắc về chất lượng, tính đa dạng và khối lượng.

Cụ thể, khía cạnh chất lượng của văn bản đã được nghiên cứu rộng rãi trong tài liệu hiện có. Các nỗ lực đã được thực hiện để nâng cao các khía cạnh như cấu trúc văn bản, tính hợp lý của lập luận, sự phong phú về bối cảnh, tính chính xác trong viết, tính toàn diện, mức độ ẩn danh hóa và tính vô hại. Việc thực hiện rộng rãi các quy trình làm sạch, khử trùng lặp và ẩn danh hóa trong dữ liệu tiền huấn luyện đại diện cho việc theo đuổi được đề cập ở trên. Ví dụ, các nhà nghiên cứu có thể chọn lặp lại thêm các epoch với dữ liệu kiểu Wikipedia trong huấn luyện LLM. Tương tự, việc xử lý dữ liệu tinh chỉnh cũng sử dụng các chiến lược lọc, khử trùng lặp và khử độc tính, nhằm nâng cao trải nghiệm người dùng và mức độ trợ giúp được cung cấp bởi LLMs.

Tính đa dạng là một tính chất chung khác được nghiên cứu chi tiết trong cả hai loại dữ liệu. Kết hợp các loại dữ liệu khác nhau và tìm trọng số hỗn hợp phù hợp để đạt được tính đa dạng thích hợp đã là mối quan tâm chính trong các công trình xử lý dữ liệu tiền huấn luyện. Tương tự, nỗ lực cho dữ liệu tinh chỉnh nhằm tăng tính đa dạng đa khía cạnh như điều chỉnh tác vụ và phong cách biểu đạt, điều này càng nhấn mạnh tính chất chung này.

Ngoài ra, việc theo đuổi chất lượng và tính đa dạng có xu hướng đánh đổi với khối lượng dữ liệu, điều này cũng được phản ánh trong hai loại dữ liệu này. Các nhà nghiên cứu đã không ngừng nỗ lực để trao quyền cho LLMs với lượng dữ liệu khổng lồ, hy vọng bao gồm càng nhiều kiến thức của con người càng tốt. Ví dụ, đã có sự gia tăng khối lượng dữ liệu tiền huấn luyện đến mức terabyte, và khối lượng dữ liệu tinh chỉnh đã tăng từ hàng nghìn lên hàng triệu. Tuy nhiên, các hiệu ứng ngược của những sáng kiến này cũng được đưa vào những khối lượng dữ liệu lớn này, bao gồm nhiễu gia tăng, chất lượng có thể kém hơn và thiên vị tăng lên, điều này cần các nỗ lực xử lý dữ liệu bổ sung và chi phí huấn luyện LLM tăng vọt.

### 2.2 Các giải pháp xử lý dữ liệu LLM hiện có

Xử lý dữ liệu LLM là một lĩnh vực sớm vẫn đang hướng tới các tiêu chuẩn chung, và chúng tôi nhằm thể hiện một hệ thống tiên phong cho cộng đồng. Với cam kết với tinh thần mã nguồn mở, Data-Juicer phục vụ nhu cầu ngày càng tăng cho các giải pháp xử lý dữ liệu đa năng, linh hoạt, thân thiện với người dùng và hiệu quả, chi tiết sẽ được mô tả sau. Điều này trái ngược với các LLMs nổi tiếng mà chủ yếu là mã nguồn đóng trong dữ liệu hoặc xử lý dữ liệu, chẳng hạn như các dẫn xuất GPT, các dẫn xuất LLaMA, và những cái khác.

Mặc dù đã có một số tiến bộ trong bối cảnh xử lý dữ liệu LLM mã nguồn mở, chúng chưa hoàn toàn mang lại sự trừu tượng hóa và độ rộng của các chức năng mà Data-Juicer nhằm đưa ra phía trước của lĩnh vực này.

Xem xét điều này từ góc độ của các bộ dữ liệu mục tiêu, các công trình hiện tại thường tập trung vào các nguồn dữ liệu cụ thể và các trường hợp sử dụng cho LLMs, bao gồm căn chỉnh các tập con tiếng Anh chuyên biệt cho tiền huấn luyện LLaMA, tập hợp corpus đa ngôn ngữ cho tiền huấn luyện, hoặc crowdsourcing cho dữ liệu nhắc tinh chỉnh. Tuy nhiên, chúng thiếu khả năng xử lý có hệ thống và mô-đun cần thiết để quản lý thành thạo dữ liệu dị thể, đây là lĩnh vực mà Data-Juicer nỗ lực mở rộng giới hạn của nó. Những hạn chế này trở nên đặc biệt rõ ràng khi xử lý các loại dữ liệu mới, tham gia vào chuyển giao ngôn ngữ, hoặc thực hiện việc làm sạch và chuyển đổi dữ liệu cụ thể cho các ứng dụng LLM.

Hơn nữa, các công trình hiện tại gặp khó khăn về khả năng sử dụng dưới mức tối ưu và khả năng khám phá thông tin chi tiết dữ liệu. Hầu hết các công trình này chỉ cung cấp dữ liệu được xử lý cùng với mã xử lý được xây dựng cho mục đích cụ thể cho dữ liệu đó, thiếu các cân nhắc về tính dễ sử dụng và hỗ trợ các bộ công cụ hỗ trợ. Điều này cản trở khả năng thích ứng của chúng với người dùng đa dạng và các sử dụng thay thế. Người dùng có thể đối mặt với một nhiệm vụ khó khăn khi thay thế mục tiêu xử lý dữ liệu hoặc tiến hành phân tích do thiếu các khả năng phân tích dữ liệu bổ sung. Việc phát triển lại các công cụ xử lý dữ liệu và phương pháp luận phân tích, được thiết kế riêng cho LLMs, vẫn chủ yếu là lãnh thổ chưa được khám phá.

Hơn nữa, trọng tâm của các công trình hiện tại hấp dẫn về chức năng hơn là hiệu suất hệ thống, để lại chỗ lớn cho việc nâng cao hiệu quả, quản lý không gian và khả năng mở rộng. Những thiếu sót đáng chú ý bao gồm phụ thuộc vào các script Python máy đơn, xử lý không thích hợp dữ liệu quy mô lớn, và tốc độ xử lý kém do việc sử dụng đối tượng dict thuần túy của Python. Chúng tôi sẽ cung cấp thêm so sánh thực nghiệm về cả chất lượng của các công thức dữ liệu được tạo ra (Phần 7.1) và hiệu suất của hệ thống xử lý dữ liệu (Phần 7.2).

## 3. NHÓM TOÁN TỬ TIÊU CHUẨN HÓA

Trong việc giải quyết tính dị thể của công thức dữ liệu cho LLMs (Thách thức 1 trong Phần 1), chúng tôi thiết kế một bộ nhóm toán tử (OP) tiêu chuẩn. Như được phác thảo trong Bảng 1, các OPs được tổ chức thành bốn danh mục chính: Formatters, Mappers, Filters, và Deduplicators, kết hợp các danh mục, chức năng, đầu vào, mức xử lý, đầu ra và kịch bản ứng dụng đa dạng. Các nguyên tắc cốt lõi của việc tách biệt và khả năng kết hợp hướng dẫn cấu trúc của chúng, dẫn đến một bộ quy trình đa dạng nhưng tiêu chuẩn góp phần vào tính linh hoạt và tương tác người dùng ở nhiều mức xử lý. Việc triển khai chiến lược này nâng cao khả năng tái sử dụng và giảm độ phức tạp, hỗ trợ xây dựng công thức dữ liệu được sắp xếp hợp lý và tách biệt.

### 3.1 Đại diện dữ liệu thống nhất

Chúng tôi trước tiên giới thiệu các OPs Formatter được thiết kế để thống nhất các nguồn dữ liệu đa dạng thành một đại diện dữ liệu trung gian. Cụ thể, chúng tôi chọn xây dựng Data-Juicer trên Huggingface-datasets do khả năng tương thích của nó với các bộ dữ liệu LLM chính thống và khả năng lưu trữ hướng cột được hỗ trợ bởi Apache Arrow. Các Formatters của chúng tôi duy trì các đối tượng dữ liệu được khởi tạo từ một số lớp cơ sở thống nhất đơn giản hóa thiết kế quy trình cho các OPs tiếp theo và tạo thuận lợi cho hiệu quả truy cập dữ liệu. Chúng tôi hỗ trợ nhiều định dạng đầu vào văn bản - txt, JSON, parquet, html, md, pdf, tệp mã như .py và .cpp, cùng với những cái khác - và đồng nhất chúng thành định dạng có cấu trúc được cấu thành từ các cột nhất định với hỗ trợ truy cập lồng nhau, được tổ chức khái niệm bằng ba phần chính "text", "meta", và "stats". Những phần này tương ứng giữ dữ liệu văn bản thô, thông tin siêu dữ liệu (ví dụ: ngày tháng và phiên bản), và dữ liệu thống kê có thể được tạo ra và tiêu thụ bởi các OPs và công cụ khác của Data-Juicer. Giao diện này hoạt động ở mức mẫu văn bản hoặc bộ dữ liệu, và độc lập với bố cục dữ liệu trong bộ nhớ hoặc đĩa cơ bản, giảm bớt lo lắng tiềm ẩn về các định dạng dữ liệu dị thể bởi các nhà phát triển OP.

### 3.2 Xử lý dữ liệu đa năng

Tiếp theo, chúng tôi trình bày chi tiết về chức năng của nhóm OP trong Data-Juicer, điều này rất quan trọng cho việc xử lý dữ liệu toàn diện được thiết kế riêng cho LLMs. Bên cạnh các Formatters, đóng vai trò thiết yếu trong việc thống nhất các định dạng dữ liệu và đảm bảo luồng dữ liệu nhất quán và hiệu quả trong suốt pipeline xử lý, chúng tôi bây giờ cung cấp thêm chi tiết về ba loại OPs chuyển đổi dữ liệu khác trong Bảng 1.

Mappers tạo thuận lợi cho các chức năng quan trọng của chỉnh sửa văn bản tại chỗ, cần thiết cho việc xử lý đơn mẫu hoặc đa mẫu trong các nhu cầu khác nhau của xử lý dữ liệu LLM, chẳng hạn như sửa đổi văn bản cho tiền huấn luyện và nâng cao tính đa dạng văn bản cho tinh chỉnh. Chúng xử lý hiệu quả các tác vụ xử lý như loại bỏ header tệp cụ thể, sửa chữa mã rối và cải thiện văn bản.

Filters phát huy tác dụng bằng cách lọc văn bản có điều kiện thông qua các chỉ số mẫu riêng lẻ, thống kê cấp bộ dữ liệu, hoặc tài nguyên bên ngoài như danh sách từ dừng. Khi làm như vậy, chúng có thể loại bỏ các mẫu văn bản không cần thiết, góp phần vào việc tập trung dữ liệu, sự sạch sẽ và giảm đáng kể chi phí của các quy trình huấn luyện LLM tiếp theo.

Deduplicators giảm lãng phí lưu trữ tiềm ẩn và cải thiện hiệu quả. Như được chỉ ra bởi một số nghiên cứu, các mẫu trùng lặp ảnh hưởng bất lợi đến cả tính ổn định tiền huấn luyện và hiệu suất của LLMs. Bên cạnh đó, Deduplicators giúp ngăn ngừa rò rỉ dữ liệu không chủ ý trong quá trình huấn luyện vào các benchmark đánh giá, đặc biệt là cho các tác vụ zero-shot hoặc few-shot. Để đảm bảo phát hiện và loại bỏ trùng lặp chính xác, chúng tôi cung cấp các phương pháp hiệu quả và mạnh mẽ bao gồm so sánh dựa trên hash và dựa trên vector.

Đáng chú ý là đầu ra của các OPs Filter là Boolean, điều này giúp tách biệt việc triển khai xử lý dữ liệu thực tế và tính toán cho các thống kê khác nhau. Sự phân tách chuyên dụng này dẫn đến hai lợi thế chính. Thứ nhất, nó cho phép các công cụ liên quan đến phân tích chuyên dụng của chúng tôi (được chi tiết trong Phần 5.2) sử dụng những thống kê được tính toán này cho toàn bộ bộ dữ liệu, thay vì một tập con được lọc. Người dùng cũng được phép tạo ra dấu vân tay cho các mẫu phần cụ thể. Thứ hai, việc tách biệt này nâng cao khả năng tương thích giữa Huggingface-datasets và Data-Juicer, từ đó cho phép tái sử dụng hiệu quả các giao diện Dataset.map và Dataset.filter để thực hiện các quy trình phụ này một cách hợp lý. Kết quả là, người dùng có thể dễ dàng mở rộng các OPs tùy chỉnh của riêng họ chỉ khác với các OPs hiện có trong các hành vi xử lý phần cụ thể. Trong Phụ lục A.1, chúng tôi cung cấp một ví dụ mã minh họa về việc tách biệt này trong Danh sách 1.

### 3.3 Khả năng kết hợp

Các OPs của Data-Juicer phục vụ như một minh chứng cho tính linh hoạt của hệ thống chúng tôi. Chúng cho phép người dùng dễ dàng xử lý một loạt các loại dữ liệu theo cách có thể kết hợp và mô-đun, thể hiện sự tận tụy của Data-Juicer đối với khả năng thích ứng của người dùng và sản xuất dữ liệu chất lượng cao cho LLMs. Bên cạnh các chức năng, đầu vào, đầu ra và mức xử lý được tóm tắt trong Bảng 1, khả năng kết hợp này được nhúng trong nhiều khía cạnh hơn, bao gồm các trường cần xử lý, siêu tham số OP, và các trường hợp sử dụng được khuyến nghị của mỗi OP.

Mỗi OP trong Data-Juicer được thiết kế để phục vụ một chức năng riêng biệt và có thể được người dùng chỉ huy để xử lý các trường văn bản khác nhau. Ví dụ, OP A có thể xử lý trường mẫu "text.abstract", trong khi OP B có thể tập trung vào "text.main_body". Theo mặc định, mỗi OP xử lý trên trường "text", có thể được chỉ định tự do cho các trường dữ liệu liên quan đến "meta" hoặc "stats" khác theo nhu cầu của người dùng. Khả năng thích ứng này cho phép tính linh hoạt to lớn bằng cách đồng thời sử dụng OPs với các trường khác nhau, cho phép người dùng dễ dàng thao tác các đoạn văn bản cụ thể như loại bỏ mã GitHub dựa trên số lượng sao của chúng.

Hơn nữa, những OPs này thiết lập một giải pháp phù hợp với tất cả mọi thứ bao gồm vô số tham số có thể cấu hình như số lượng token, ngưỡng lọc, mô hình phụ trợ, và nhiều hơn nữa. Khả năng điều chỉnh của một OP đơn, kết hợp với khả năng kết hợp của các pipeline OP, trao quyền cho Data-Juicer quản lý một phổ đầu vào, đầu ra và độ chi tiết xử lý, góp phần vào khả năng xử lý mạnh mẽ của nó.

Đối với các kết hợp sử dụng, OPs được gắn nhãn với các kịch bản sử dụng điển hình. Chúng tôi duy trì các thẻ OP như sử dụng chung, tệp nguồn LaTeX, mã lập trình, xử lý dữ liệu tài chính, hoặc xử lý cụ thể theo ngôn ngữ như tiếng Anh và tiếng Trung, và nhiều thứ khác. Những nhãn này tạo thuận lợi cho việc điều hướng và vận hành dễ dàng, nhấn mạnh mục tiêu của chúng tôi là kết hợp sự đơn giản với sức mạnh trong kiến trúc của Data-Juicer.

## 4. XỬ LÝ DỮ LIỆU HƯỚNG PHẢN HỒI

Giải quyết Thách thức 2 được nêu trong Phần 1, chúng tôi kết hợp một vòng phản hồi động vào pipeline xử lý dữ liệu, cho phép người dùng xử lý và hiểu dữ liệu hiệu quả thông qua khả năng trực quan hóa tích hợp và theo dõi tự động. Như được chứng minh trong Hình 2, hệ thống của chúng tôi (Data-Juicer) cho phép nhận thức kịp thời và tinh chỉnh lặp lại nhanh chóng các công thức dữ liệu (được chỉ ra bởi các mũi tên trái và lên) trong một vòng phản hồi toàn diện của xử lý dữ liệu LLM và huấn luyện LLM (được chỉ ra bởi các mũi tên phải).

Chúng tôi sẽ thảo luận về việc mô hình hóa phản hồi xử lý dữ liệu trong một góc nhìn tối ưu hóa siêu tham số (HPO) (Phần 4.1), và đi qua tiện ích của trực quan hóa tương tác (Phần 4.2), và việc tích hợp các hệ sinh thái để huấn luyện và đánh giá LLM (Phần 4.3). Sự hiệp lực của những kỹ thuật này cung cấp một giải pháp hiệu quả và hiệu suất để gỡ lỗi và đi sâu vào xử lý dữ liệu LLM.

### 4.1 HPO cho xử lý dữ liệu

Trong Data-Juicer, chúng tôi kết hợp khái niệm tối ưu hóa siêu tham số (HPO) vào quy trình xử lý dữ liệu. Điều này được thực hiện bằng cách gắn các siêu tham số cụ thể về xử lý dữ liệu với nhiều tín hiệu phản hồi, bao gồm các chỉ số mục tiêu tùy chỉnh và kết quả trực quan hóa. Chúng tôi nâng cao chức năng của hệ thống bằng cách tăng tốc sáng tạo việc lặp lại xử lý dữ liệu thông qua các cơ chế Checkpoint và Caching, và bằng cách tích hợp một công cụ HPO tự động.

#### 4.1.1 Tăng tốc với Checkpoint và Caching

Xử lý dữ liệu LLM thường cần tái thực hiện thường xuyên do thay đổi trong siêu tham số OP và thất bại tiến hành tiềm ẩn, chẳng hạn như vượt quá bộ nhớ có sẵn, đĩa hoặc giới hạn thời gian được xác định trước, đặc biệt là cho các bộ dữ liệu khổng lồ. Theo đó, chúng tôi cung cấp quản lý checkpoint và caching tích hợp để thúc đẩy xử lý dữ liệu mạnh mẽ và đáng tin cậy. Dựa trên cấu trúc thư mục được tổ chức cẩn thận, Data-Juicer tự động giám sát mọi quy trình đang chạy để thay đổi cấu hình, và tạo ra các tệp mới để lưu trữ an toàn dữ liệu và trạng thái xử lý chỉ khi có lỗi hoặc ngoại lệ xảy ra. Trong khi checkpoint bảo tồn toàn bộ bộ dữ liệu và trạng thái xử lý cho phép phục hồi hoàn toàn vị trí xử lý, cache chỉ lưu đối tượng bộ dữ liệu cho mỗi OP và phù hợp hơn cho các điều chỉnh quy mô nhỏ hơn vì nó giảm overhead của cache thứ tự trước.

Những kỹ thuật này cho phép phục hồi nhanh chóng trong quá trình khởi động lại hệ thống hoặc thất bại, trở về trạng thái xử lý gần đây tối ưu nhất được lưu trữ trong checkpoint, do đó giảm thiểu sự dư thừa xử lý và tăng tần suất phản hồi.

Ngoài ra, cơ chế lưu trạng thái được đề xuất cho phép đánh đổi không gian-thời gian linh hoạt tại các giai đoạn phản hồi khác nhau. Người dùng có tùy chọn lưu trạng thái sau mỗi OP trong luồng xử lý dữ liệu, đảm bảo thời gian thực thi lại tối thiểu với chi phí overhead lưu trữ tối đa. Ngược lại, họ có thể chọn chỉ lưu checkpoint và cache của OP cuối cùng, phát sinh overhead lưu trữ tối thiểu nhưng tăng thời gian thực thi lại, đặc biệt khi cần quay lại các bước sớm trong quy trình.

Để tạo thuận lợi cho việc đánh đổi không gian-thời gian tốt, chúng tôi tiếp tục thực hiện phân tích độ phức tạp không gian cho các OPs riêng lẻ, điều này hỗ trợ việc dự đoán chiếm dụng không gian đỉnh và hướng dẫn chúng tôi trong việc xác định số lượng checkpoint và cache cần lưu trữ dựa trên không gian có sẵn. Theo mặc định, Data-Juicer tích cực giám sát việc sử dụng không gian đĩa khi bắt đầu xử lý dữ liệu, và tự động xác định liệu có, và khi nào, checkpoint và cache nên được triển khai. Tần suất và quy tắc lưu do người dùng chỉ định cũng được hỗ trợ. Do đó, quản lý checkpoint và cache chiến lược củng cố cả khả năng phục hồi và hiệu quả của vòng phản hồi cho xử lý dữ liệu LLM. Phân tích sử dụng không gian chi tiết có thể được tìm thấy trong Phụ lục A.2.

#### 4.1.2 Auto-HPO

Chúng tôi kết hợp một công cụ HPO tự động vào Data-Juicer để hợp lý hóa việc tìm kiếm siêu tham số xử lý dữ liệu tốt. Để giảm chi phí tìm kiếm của các công thức dữ liệu khác nhau, chúng tôi hỗ trợ tận dụng các thuật toán HPO tiên tiến như tối ưu hóa Bayesian, các chiến lược dừng sớm tiến bộ, chẳng hạn như thuật toán Hyperband, và các chiến lược lấy mẫu hướng LLM tích hợp (chi tiết sau trong Phần 5.2). Cụ thể, cho trước một chỉ số mục tiêu được xác định trước và không gian tìm kiếm của công thức dữ liệu, người dùng có thể thuận tiện khám phá tác động của các siêu tham số xử lý dữ liệu cụ thể.

Ở đây, chúng tôi đưa ra một ví dụ minh họa như sau:

**Ví dụ về kết hợp dữ liệu với HPO:**

Giả sử chúng tôi nhằm tìm một bộ trọng số lấy mẫu tốt cho M bộ dữ liệu được kết hợp, nơi không gian tìm kiếm của chúng tôi được định nghĩa là wᵢ ∈ [0,1], i ∈ [1,M]. Pipeline có thể được cấu trúc như sau:

(1) Chúng tôi chỉ định các trường văn bản mục tiêu trên tất cả M bộ dữ liệu, và thống nhất meta-tag và tên của các trường văn bản của chúng thông qua OPs Formatter.

(2) Chúng tôi tận dụng các Filters meta-tag để phục vụ các kịch bản sử dụng cụ thể. Ở đây chúng tôi chỉ bao gồm các mẫu với thẻ ngôn ngữ "EN".

(3) Một bộ dữ liệu Dmix được tạo ra từ M bộ dữ liệu, với trọng số hỗn hợp [wᵢ] được rút ra bởi bộ lập lịch HPO để tối đa hóa chỉ số mục tiêu trong bước (5).

(4) Một xử lý dữ liệu được cấu hình trước bao gồm OPs khử trùng lặp được thực thi trên bộ dữ liệu hỗn hợp, đảm bảo tính sạch sẽ của bộ dữ liệu.

(5) Chỉ số mục tiêu được tính toán trên Dmix là (n/N + s), nơi N là tổng số token của tất cả M bộ dữ liệu, n và s là số lượng token và điểm chất lượng trung bình của Dmix sử dụng bộ phân loại chất lượng GPT-3 tích hợp (chi tiết trong Phần 5.2) tương ứng.

Bộ dữ liệu hỗn hợp Dmix được tinh chỉnh lặp lại bằng cách thực hiện các bước lặp lại (3) ∼ (5) để có được số lượng lớn hơn và chất lượng tốt hơn. □

Kết quả HPO cung cấp một phương tiện mạnh mẽ để trực quan hóa và hiểu thông tin chi tiết dữ liệu như được hiển thị trong Hình 3, nơi tầm quan trọng, tương quan và tương tác của wᵢ cho điểm chất lượng được ước tính và vẽ đồ thị. Bên cạnh điểm chất lượng được chứng minh trong ví dụ này, chỉ số mục tiêu có thể được tùy chỉnh để bao gồm các điều khoản đánh đổi khác được cấu thành từ các biện pháp dữ liệu nội tại - chẳng hạn như độc tính, tính hữu ích, hoặc điểm số khác được dự đoán bởi mô hình phụ trợ - hoặc thậm chí các biện pháp hiệu suất của LLMs, chẳng hạn như mất mát huấn luyện hoặc điểm benchmark (mà chúng tôi sẽ thảo luận sau trong Phần 4.3).

### 4.2 Trực quan hóa tương tác

Khả năng trực quan hóa tương tác là không thể thiếu cho nhiều giai đoạn phản hồi của Data-Juicer. Cụ thể, như Hình 4.(a) chứng minh, người dùng có thể trực quan theo dõi hiệu ứng của các OPs riêng lẻ về các mẫu dữ liệu được xử lý. Điều này được tạo thuận lợi bởi một công cụ tích hợp sáng tạo, tracer, ghi lại các thay đổi mẫu sau khi áp dụng mỗi hoạt động cho Data-Juicer. Ví dụ, tracer trình bày các mẫu bị loại bỏ cho Filters, sự khác biệt trước và sau chỉnh sửa cho Mappers, và các cặp mẫu trùng lặp (gần) cho Deduplicators. Kết hợp khả năng theo dõi này với các công cụ lấy mẫu và trực quan hóa tích hợp phong phú, Data-Juicer nâng cao khả năng kiểm soát của người dùng đối với việc xử lý dữ liệu và tăng cường sự tự tin và lý do của họ về quy trình.

Chuyển đổi sang giai đoạn giữa kỳ của xử lý dữ liệu LLM, Data-Juicer cung cấp trực quan hóa so sánh của dữ liệu trước và sau toàn bộ quá trình xử lý từ góc nhìn của pipeline OP và phân tích thống kê, như Hình 4.(b) và 4.(c) hiển thị. Được hỗ trợ bởi một công cụ tích hợp, analyzer, Data-Juicer cung cấp phân tích thống kê (đếm, trung bình, độ lệch chuẩn, min/max, phân vị, entropy, v.v.) để cho phép hiểu biết sâu sắc về dữ liệu. Theo mặc định, tóm tắt thống kê từng mẫu bao gồm 13 chiều và tự động hiển thị biểu đồ và box plot cho mỗi biến thống kê, bao gồm các tiêu chí đa dạng như perplexity mẫu, số từ, tỷ lệ từ được gắn cờ, và độ dài đoạn văn, cùng với những cái khác. Người dùng cũng có tính linh hoạt để điều chỉnh các chiều cần quan sát, với trải nghiệm trực quan hóa và xử lý dữ liệu được cá nhân hóa.

### 4.3 Phản hồi với các thư viện LLM tích hợp

Trong các giai đoạn sau của pipeline, chúng tôi sử dụng các hệ sinh thái mạnh mẽ được thiết kế để huấn luyện và đánh giá LLM, đảm bảo tích hợp liền mạch với các thư viện được sử dụng rộng rãi như Megatron-LM, DeepSpeed, và HuggingFace's Transformers. Với việc tích hợp này, người dùng có thể dễ dàng huấn luyện LLMs trên các bộ dữ liệu được sản xuất bởi Data-Juicer và đánh giá hiệu suất của chúng để có được phản hồi bằng cách sử dụng các công cụ và script được xây dựng trước của chúng tôi, mà không bị sa lầy trong các chi tiết huấn luyện và đánh giá LLM phức tạp.

Đặc biệt, hệ thống của chúng tôi tạo thuận lợi cho việc đánh giá kịp thời khả năng mô hình bằng cách kết hợp nhiều chiều. Khả năng của hệ thống để nhanh chóng xác định dữ liệu có thể không hiệu quả và huấn luyện cho phép chúng tôi chấm dứt xử lý dữ liệu LLM không mong muốn một cách kịp thời. Thay vì chỉ dựa vào mất mát mô hình làm cơ sở để đánh giá hiệu suất mô hình, chúng tôi hỗ trợ đánh giá LLM trên các chỉ số hoặc benchmark khác nhau, và theo dõi sự thay đổi trong điểm mục tiêu. Do đó, chúng tôi có thể xác định liệu việc tiếp tục huấn luyện LLM trên bộ dữ liệu được sản xuất có được biện minh hay không, từ đó giúp chúng tôi giảm thiểu chi phí xử lý dữ liệu và huấn luyện LLM.

Cụ thể, evaluator của Data-Juicer hỗ trợ các benchmark LLM tiên tiến như HELM, LM-harness và đánh giá dựa trên GPT-API, cũng như việc mở rộng các benchmark và tác vụ đánh giá tùy chỉnh. Để có một đánh giá cân bằng và đơn giản, Data-Juicer hỗ trợ so sánh kiểu bảng xếp hạng bằng cách hợp nhất kết quả từ các kịch bản đánh giá mục tiêu khác nhau, chẳng hạn như trung bình xếp hạng, trung bình chuẩn hóa điểm, hoặc các chiến lược tùy chỉnh khác. Tiện ích tính điểm kiểu bảng xếp hạng nâng cao việc trực quan hóa điểm mạnh và điểm yếu của mô hình, hướng dẫn các lần lặp tiếp theo của công thức dữ liệu và cải tiến LLMs. Chúng tôi cũng cung cấp Reference Models - đây là các checkpoint mô hình liên kết với dữ liệu huấn luyện có thể truy vết trong Data-Juicer, kiến trúc LLM phổ biến, tham số huấn luyện, chi phí tính toán, và kết quả đánh giá tương ứng. Chúng tạo thuận lợi cho việc so sánh dễ dàng giữa các cấu hình huấn luyện khác nhau, đặc biệt là cho nghiên cứu thêm về các công thức dữ liệu đa dạng, được phát triển lặp lại.

### 4.4 Trình diễn vòng phản hồi

Vòng phản hồi tổng quát đã được thảo luận trước đó trong Hình 2. Chúng tôi bây giờ trình bày thêm về điều này bằng cách trình bày một ví dụ phát triển cụ thể. Ở đây, chúng tôi liên kết một số công cụ được đề cập trước đó để chứng minh quy trình Data-in-the-LLMdev-Loop, dẫn đến dữ liệu LLM được cải thiện. Như được minh họa trong Hình 5, chúng tôi bắt đầu với một bộ dữ liệu thô và nhằm tinh chỉnh nó để tiền huấn luyện hoặc tinh chỉnh LLM tốt hơn. Toàn bộ quy trình diễn ra theo các bước sau:

(1) **Phân tích bộ dữ liệu gốc.** Chúng tôi có thể chọn sử dụng một công thức dữ liệu hiện có (một tệp cấu hình cụ thể) hoặc tạo ra một cái mới dựa trên sự hiểu biết trước về nhu cầu xử lý dữ liệu. Analyzer và Visualizer tích hợp của chúng tôi tạo thuận lợi cho quy trình này bằng cách tính toán hơn một chục biện pháp như đa dạng ngôn ngữ, thống kê văn bản, và những cái khác để tạo ra một thăm dò dữ liệu. Hai biểu đồ hình tròn trong Hình 5 chỉ ra 20 động từ gốc phổ biến nhất (vòng tròn trong) và 4 đối tượng danh từ trực tiếp hàng đầu của chúng (vòng tròn ngoài) cho dữ liệu trong trường "text.instructions".

(2) **Tinh chỉnh tham số của công thức gốc.** Dựa trên thăm dò dữ liệu, người dùng tìm ra những điểm yếu của bộ dữ liệu gốc, chẳng hạn như tính đa dạng thấp trong cách thức biểu đạt, và thống kê đuôi dài của số từ. Sau đó chúng tôi tinh chỉnh các tham số trong công thức bằng cách thêm/loại bỏ một số OPs hoặc thắt chặt/nới lỏng phạm vi bộ lọc. Trong quá trình tinh chỉnh, chúng tôi có thể tìm ra hiệu ứng của mỗi OP một cách dễ dàng dựa trên công cụ trực quan hóa tương tác được đề cập trong Phần 4.2.

(3) **Xử lý bộ dữ liệu gốc với công thức tinh chỉnh.** Sau đó chúng tôi xử lý bộ dữ liệu gốc với công thức tinh chỉnh sử dụng Data-Juicer và có được một bộ dữ liệu tinh chỉnh và một số checkpoint được lưu cho các điều chỉnh thêm. Bước này có thể được tạo thuận lợi với sự trợ giúp của các cơ chế cache và checkpoint của chúng tôi.

(4) **Phân tích bộ dữ liệu tinh chỉnh.** Giống như bước (1), chúng tôi phân tích bộ dữ liệu tinh chỉnh một lần nữa để có được một thăm dò dữ liệu mới. Dựa trên kết quả thống kê và trực quan hóa, chúng tôi đánh giá mức độ cải thiện trong chất lượng dữ liệu. Nếu dữ liệu tinh chỉnh không đáp ứng kỳ vọng của chúng tôi, chúng tôi quay lại bước 2 để điều chỉnh thủ công công thức dữ liệu hoặc sử dụng công cụ HPO của chúng tôi để tinh chỉnh tự động (tham khảo Phần 4.1).

(5) **Có được LLMs với bộ dữ liệu tinh chỉnh.** Sau đó chúng tôi có thể huấn luyện hoặc tinh chỉnh LLMs với bộ dữ liệu tinh chỉnh và các khung huấn luyện được tích hợp vào Data-Juicer (Phần 4.3). Trong quá trình huấn luyện hoặc tinh chỉnh, các công cụ tự động đánh giá của chúng tôi cung cấp đánh giá kịp thời, đa góc nhìn của LLMs. Những công cụ này kiểm tra nhiều chỉ số trên nhiều bộ dữ liệu đánh giá. Tính năng này cung cấp cho chúng tôi lợi thế dừng quy trình sớm nếu dữ liệu tinh chỉnh làm yếu hiệu suất LLM, từ đó ngăn ngừa chi phí không cần thiết.

(6) **Tổng hợp kết quả và so sánh với mô hình tham chiếu.** Cuối cùng, Data-Juicer tự động tổng hợp kết quả đánh giá và so sánh chúng với mô hình tham chiếu trong bảng xếp hạng dữ liệu, cung cấp đại diện rõ ràng về hiệu ứng của xử lý dữ liệu một mình. Do đó, chúng tôi tạo ra một LLM vượt trội, có thể được tự động đăng ký làm mô hình tham chiếu, hoặc hướng dẫn tinh chỉnh bổ sung từ góc độ LLM để nâng cao hơn nữa công thức dữ liệu.

## 5. TĂNG CƯỜNG KHẢ NĂNG SỬ DỤNG VỚI CÁC TÍNH NĂNG TÍCH HỢP

Đáp ứng thách thức của sở thích tùy chỉnh người dùng đa dạng và chuyên môn kỹ thuật (Thách thức 3 trong Phần 1), chúng tôi cung cấp mô hình cấu hình dễ sử dụng cho công thức dữ liệu, các mẫu công thức dữ liệu sẵn sàng sử dụng, và các công cụ mở rộng, như được chi tiết dưới đây.

### 5.1 Cấu hình công thức dữ liệu của bạn

Đặc biệt, chúng tôi làm cho pipeline từ đầu đến cuối của xử lý dữ liệu có thể cấu hình trong Data-Juicer, bao gồm các tham số môi trường xử lý được chỉ định, danh sách OP, công cụ được sử dụng, và nhiều thứ khác. Nguyên tắc cấu hình tất cả trong một này đảm bảo khả năng tái tạo và truy vết, và đơn giản hóa việc thay đổi đặc tả trong xử lý dữ liệu, từ đó tạo thuận lợi cho việc hình thành công thức dữ liệu để tinh chỉnh và tái sử dụng thêm, và cho phép khám phá định lượng và tối ưu hóa tự động của xử lý dữ liệu (Phần 4.1).

Cụ thể, được xây dựng dựa trên Jsonargparse, chúng tôi cung cấp khả năng cấu hình thống nhất, linh hoạt, dễ sử dụng và mạnh mẽ. Nó được thiết kế để tự động đăng ký các mục cấu hình cho OPs và công cụ, và chấp nhận các nguồn cấu hình khác nhau như các mục nhập dòng lệnh, tệp yaml và jsonnet, biến môi trường, giá trị mặc định được mã hóa cứng, và một hỗn hợp của những cái đó để thuận tiện cho việc sửa đổi gia tăng.

Ví dụ, người dùng có thể dễ dàng xây dựng các tệp cấu hình của riêng họ bằng hai phương pháp luận được khuyến nghị—"trừ" hoặc "cộng". Cách tiếp cận "trừ" sử dụng một tệp cấu hình được thiết lập trước chứa tất cả các OPs, công cụ có sẵn, và các tham số mặc định của chúng. Người dùng có thể đơn giản loại bỏ hoặc sắp xếp lại những OPs này và điều chỉnh những tham số này theo yêu cầu của họ. Ngược lại, cách tiếp cận "cộng" cho phép người dùng xây dựng các tệp cấu hình của họ từ đầu, tận dụng các ví dụ mở rộng của chúng tôi về các công thức xử lý dữ liệu được xây dựng trước cho tổng cộng hơn 20 công thức dữ liệu chất lượng cao và đa dạng cho tiền huấn luyện, tinh chỉnh, tiếng Anh, tiếng Trung, v.v. Phân tích định lượng thêm về các công thức nhất định có trong các thí nghiệm của chúng tôi (Phần 7.1).

### 5.2 Các công cụ có thể cắm chuyên dụng

Để nâng cao hơn nữa khả năng sử dụng, tạo thuận lợi cho việc tùy chỉnh hệ thống và tăng cường khả năng xử lý dữ liệu của người dùng, Data-Juicer bao gồm một bộ sưu tập có thể mở rộng các công cụ chuyên dụng mạnh mẽ có thể được cắm thuận tiện vào các giai đoạn khác nhau của xử lý dữ liệu LLM.

**Bộ phân loại chất lượng.** Như một ví dụ minh họa, chúng tôi mô tả bộ phân loại chất lượng văn bản của chúng tôi để loại bỏ văn bản chất lượng cao từ các nguồn dữ liệu dị thể như CommonCrawl. Công cụ này là một mô hình được tái tạo dựa trên bộ ghi điểm chất lượng GPT-3 mã nguồn đóng. Hơn nữa, chúng tôi đã mở rộng khả năng ứng dụng của nó cho văn bản tiếng Trung và các loại mã khác nhau. Được đóng gói như một pipeline có thể gọi, công cụ này cung cấp cho người dùng tự do thích ứng nó với các kịch bản khác nhau khác.

Chức năng của bộ phân loại được hỗ trợ bởi Tokenizer tiêu chuẩn của PySpark hoặc mô hình Sentencepiece, cùng với HashingTF như trình trích xuất đặc trưng. Sau đó nó áp dụng một bộ phân loại hồi quy logistic nhị phân để đánh giá chất lượng của một văn bản. Chúng tôi cung cấp thêm xác minh thực nghiệm về chúng trong Phần 7.2.3.

**Sampler nâng cao cho dữ liệu LLM.** Trong Data-Juicer, chúng tôi đã thiết kế một số tiện ích lấy mẫu dữ liệu tiên tiến chuyên biệt để xử lý khối dữ liệu quy mô lớn trong LLMs. Các giải pháp của chúng tôi hiệu quả hợp lý trích xuất đại diện, tối ưu hóa thời gian xử lý và tài nguyên, và đáp ứng nhu cầu khác biệt của các nhà phát triển LLM.

Kỹ thuật lấy mẫu phân tầng của chúng tôi đáng chú ý trong bối cảnh dữ liệu LLM này. Nó tận dụng thông tin trong các trường siêu dữ liệu hoặc thống kê, do đó chứa các chỉ số lựa chọn đa dạng trong việc tạo ra một mẫu dữ liệu hiệu quả. Để đảm bảo đại diện toàn diện nhưng linh hoạt của corpus dữ liệu, chúng tôi xem xét các tiêu chí dị thể khác nhau như độ dài tài liệu, số lượng token, tần suất của vị từ boolean cho kiểm tra hậu điều kiện, và thậm chí tính đa dạng ngôn ngữ được xây dựng thông qua các xuất hiện của cặp động từ-danh từ (như được hiển thị trong các biểu đồ hình tròn trong Hình 2). Những tiêu chí động này được thiết kế riêng cho nhu cầu phân tích khác biệt và thúc đẩy xử lý dữ liệu hiệu quả, tích hợp liền mạch với các OPs và công cụ hạ nguồn.

**Bộ công cụ đầy đủ.** Đối với các công cụ khác, độc giả có thể tham khảo Phần 4 để kiểm tra nhiều công cụ đã thảo luận trước đó, bao gồm tracer và analyzer (Phần 4.2), và evaluator và reference models (Phần 4.3). Chúng tôi cần mẫn duy trì và phát triển bộ công cụ trong Data-Juicer, và làm cho bộ đầy đủ có thể truy cập công khai.

### 5.3 Trải nghiệm thân thiện với người dùng trong Data-Juicer

Data-Juicer được thiết kế không chỉ cho chức năng mà còn cho khả năng thích ứng, phục vụ một cơ sở người dùng rộng rãi với chuyên môn và bộ kỹ năng đa dạng. Trong khi trừu tượng hóa những phức tạp nội tại của hệ thống, chúng tôi cung cấp giao diện thân thiện với người dùng và các thành phần có thể tùy chỉnh mở rộng. Theo đó, người dùng có thể bắt đầu xử lý dữ liệu không cần mã, tham gia vào tùy chỉnh ít mã, hoặc đi sâu vào các phần mở rộng sâu cho các yêu cầu phức tạp.

• **Xử lý không cần mã:** Đối với người dùng mới, Data-Juicer cung cấp một loạt công thức dữ liệu sẵn sàng sử dụng và công cụ cắm cho sử dụng ngay lập tức. Điều này không yêu cầu kiến thức về kiến trúc hệ thống tiên tiến hoặc OPs, như đã thảo luận trong Phần 5.1 và Phần 5.2.

• **Tùy chỉnh ít mã:** Người dùng trung cấp có thể tận hưởng tính linh hoạt để thay đổi cấu hình, dữ liệu và tài nguyên bên ngoài để phù hợp với nhu cầu cụ thể của họ. Họ có thể dễ dàng tái sử dụng, kết hợp và chỉnh sửa cấu hình dữ liệu tích hợp; tùy chỉnh bộ phân loại chất lượng và tokenizer; tinh chỉnh dữ liệu dựa trên các công thức được phát triển trước của chúng tôi; hoặc cung cấp các liên kết mới đến mô hình phụ trợ hoặc từ vựng từ ổ đĩa đám mây công cộng thống nhất, được cập nhật thường xuyên của chúng tôi.

• **Mở rộng nâng cao:** Người dùng có kinh nghiệm được phép dễ dàng giới thiệu các OPs mới bằng cách kế thừa từ các lớp cơ sở và triển khai các hàm "process()" và "compute_stats()" cụ thể của họ, như được chứng minh trong Danh sách mã 1. Điều này cấp cho người dùng góc nhìn từ đầu đến cuối của quy trình cho một mẫu đơn, trong khi Data-Juicer xử lý những chi tiết nhỏ của đăng ký cấu hình và tối ưu hóa hiệu quả.

Ngoài ra, thiết kế tách biệt của Data-Juicer tạo thuận lợi cho việc kết hợp mượt mà các công cụ mới cho người dùng ở tất cả các giai đoạn của xử lý dữ liệu LLM, từ các chiều trực quan hóa mới và bộ dữ liệu đánh giá đến các script tiền hoặc hậu xử lý.

Để nâng cao tính dễ tiếp cận và sử dụng của Data-Juicer, ngoài nhiều công thức dữ liệu được xây dựng trước (tham khảo Phần 5), chúng tôi cũng cung cấp một loạt demo tương tác, được triển khai trong Streamlit, cho các hồ sơ và kịch bản đa dạng. Cách tiếp cận học tập thực hành này đã được thiết kế để cho phép người dùng với mức độ kỹ năng khác nhau nhanh chóng làm quen với và sử dụng hiệu quả Data-Juicer.

## 6. TỐI ƯU HÓA HỆ THỐNG TOÀN DIỆN

Để xử lý dữ liệu quy mô lớn (Thách thức 4 trong Phần 1), chúng tôi sử dụng một loạt tối ưu hóa trong Data-Juicer từ các khía cạnh khác nhau.

**Tính toán được tối ưu hóa: Quản lý bối cảnh, hợp nhất toán tử (OP) và sắp xếp lại.** Để nâng cao hiệu quả tính toán trong xử lý dữ liệu LLM, chúng tôi cung cấp quản lý bối cảnh tiên tiến, hợp nhất toán tử và kỹ thuật sắp xếp lại toán tử cho các đóng góp triển khai tinh tế. Trình quản lý xử lý tỉ mỉ các biến trung gian được chia sẻ, chẳng hạn như từ được phân đoạn, dòng được tách, và những cái khác được lấy từ corpus văn bản gốc, trên các toán tử khác nhau. Nó cho phép tái sử dụng liền mạch các biến bối cảnh này trên nhiều toán tử, từ đó giảm thiểu sự cần thiết cho việc tái đánh giá đắt đỏ về mặt tính toán.

Dựa trên trình quản lý bối cảnh, phương pháp hợp nhất toán tử được đề xuất là một đóng góp mới khác cho lĩnh vực này. Chúng tôi đề xuất xác định các toán tử có thể hợp nhất mà hoặc chia sẻ cùng bối cảnh hoặc các quy trình phụ tính toán. Nó phát hiện các nhóm OP trước. Các OPs liên tiếp trong cùng một nhóm nên có tính giao hoán với nhau. Sau đó nó kết hợp các toán tử có thể hợp nhất đã được xác định trong mỗi nhóm thành một OP hợp nhất duy nhất, cho phép chúng được thực thi nhanh hơn với góc nhìn địa phương hóa lớn hơn. Các bối cảnh của mỗi mẫu sẽ được dọn dẹp sau mỗi OP hợp nhất, do đó cần ít bộ nhớ bổ sung cho quản lý bối cảnh và hợp nhất toán tử.

Do sự tăng tốn thời gian của OP hợp nhất đơn, chúng tôi tiếp tục thiết kế một chiến lược sắp xếp lại toán tử để tối ưu hóa trình tự thực thi của danh sách OP sau khi hợp nhất. Ví dụ, dựa trên tính giao hoán của Filters, chúng tôi trì hoãn việc chạy các OPs tốn thời gian (như Filters hợp nhất) và ưu tiên các OPs ít tốn thời gian khác. Kết quả là, những OPs tốn thời gian này chỉ cần xử lý ít mẫu hơn vì các toán tử trước đó đã lọc ra một số trong số chúng, nâng cao hiệu quả tính toán tổng thể.

Toàn bộ quy trình hợp nhất OP được tóm tắt trong Hình 6. Những chiến lược kết hợp này phục vụ mục đích kép. Thứ nhất, nó giảm thiểu tính toán dư thừa, loại bỏ nhu cầu cho các tính toán lặp lại nhưng được chia sẻ. Thứ hai, nó giảm thiểu overhead của việc khởi tạo nhiều quy trình bằng cách giảm tổng số OPs xử lý, do đó duy trì các thói quen xử lý dữ liệu nhanh chóng.

**Sử dụng không gian được tối ưu hóa: Caching OPs và nén.** Nhận ra sự thiếu sót của giao thức quản lý cache gốc trong thư viện Huggingface-datasets, đặc biệt là liên quan đến việc xử lý các mô hình và hàm của bên thứ ba không thể tuần tự hóa trong một số OPs, chúng tôi thiết kế một phương pháp băm chuyên dụng để bỏ qua các quy trình tuần tự hóa của những đối tượng không thể tuần tự hóa đó, điều này đảm bảo caching thành công của mỗi OP và cho phép Data-Juicer tận dụng quản lý cache tối ưu.

Hơn nữa, chúng tôi kết hợp khả năng cho người dùng kích hoạt các công nghệ nén tiên tiến, chẳng hạn như Zstandard (zstd) và LZ4, trong Data-Juicer. Nó sẽ tự động nén các tệp cache sau mỗi OP và giải nén những tệp nén này trở lại thành tệp cache bình thường khi chạy lại OP này trong cùng cấu hình. So với thời gian xử lý, thời gian nén/giải nén tương đối không đáng kể do hiệu quả cao của các công nghệ nén được đề cập ở trên. Tính năng này giảm đáng kể khối lượng lưu trữ dữ liệu cache, tạo thuận lợi cho việc xử lý các bộ dữ liệu lớn hơn mà không ảnh hưởng đến tốc độ hoặc tính ổn định.

**Khả năng mở rộng được tối ưu hóa: Xử lý dữ liệu phân tán.** Khối lượng dữ liệu huấn luyện LLM có thể cực kỳ lớn, khiến việc xử lý trên một máy đơn trở nên khó khăn. Data-Juicer kết hợp với các khung xử lý phân tán như Ray, Apache Beam và Apache Flink, và cung cấp khả năng dịch liền mạch một pipeline xử lý dữ liệu chạy trên một nút đơn thành một cụm đa nút. Bằng cách này, tài nguyên trong tính toán cụm có thể được sử dụng để tăng tốc xử lý và tạo ra dữ liệu.

Cụ thể, chúng tôi thích ứng các giao diện cơ bản của HuggingFace-datasets cho những cái của Ray-datasets, sao cho tất cả các OPs của Data-Juicer, ngay cả khi được viết như các hàm Python máy đơn, có thể được thực thi trong chế độ phân tán với sự trợ giúp của việc phân vùng dữ liệu tự động bởi Ray. Một cách tiếp cận thay thế mà chúng tôi hỗ trợ là thay thế trình chạy Ray mặc định của Data-Juicer bằng các backend xử lý phân tán khác như Flink, thông qua việc dịch trước từ các pipeline xử lý của Data-Juicer thành những cái tương thích với Beam. Kết quả là, hầu như tất cả các OPs trong Data-Juicer (Mapper, Filter, và Deduplicator) có thể được tăng tốc trong một cụm đa nút, và giảm thiểu hiệu quả các nút cổ chai trên một nút đơn (ngay cả với song song hóa dựa trên quy trình) gây ra bởi dung lượng bộ nhớ và thông lượng IO. Kết quả thực nghiệm thêm có thể được tìm thấy trong Phần 7.2.4.

Tóm lại, tất cả những tối ưu hóa này nâng cao khả năng mở rộng của Data-Juicer từ các góc nhìn khác nhau, để xử lý lượng dữ liệu khổng lồ liên quan đến LLMs, đảm bảo xử lý mạnh mẽ và hiệu quả trong khi giảm thiểu yêu cầu tài nguyên.

## 7. ĐÁNH GIÁ DATA-JUICER

### 7.1 Tạo ra công thức dữ liệu tốt hơn

Giá trị của một hệ thống xử lý dữ liệu LLM hiệu quả không chỉ được phản ánh trong khả năng vận hành toàn diện và linh hoạt mà còn trong khả năng tạo ra dữ liệu chất lượng cao mà LLMs có thể "tiêu hóa" dễ dàng hơn. Data-Juicer cung cấp các tính năng chuyên biệt để khám phá và tạo ra công thức dữ liệu phù hợp với LLMs, và chúng tôi đã phát triển nhiều công thức dữ liệu sẵn sàng sử dụng bằng Data-Juicer. Trong phần này, chúng tôi đánh giá chất lượng của các công thức dữ liệu được tạo ra bởi Data-Juicer cho cả tiền huấn luyện và tinh chỉnh LLM.

#### 7.1.1 Công thức dữ liệu tiền huấn luyện được tinh chỉnh

Dữ liệu tiền huấn luyện mà chúng tôi tạo ra chỉ bao gồm các nguồn có sẵn công khai, minh họa các nguyên tắc cốt lõi của tính minh bạch và khả năng tái tạo. Cụ thể, chúng tôi chọn cải thiện hai bộ dữ liệu được sử dụng rộng rãi, chất lượng cao cho LLMs, RedPajama của TogetherAI và Pile của EleutherAI, được tuyển chọn từ 15 nguồn văn bản đa dạng cao và phải chịu tiền xử lý và làm sạch tỉ mỉ để đảm bảo chất lượng của chúng. Với sự trợ giúp của Data-Juicer, chúng tôi tiếp tục tinh chỉnh chúng thông qua phân tích dữ liệu, hợp nhất và nâng cao chất lượng, sử dụng hàng chục OPs với các cấu hình đa dạng. Để biết thống kê chi tiết, các bước xử lý và công thức dữ liệu được tinh chỉnh, vui lòng tham khảo Phụ lục B.2.

Để xác minh chất lượng của các công thức dữ liệu được tạo ra bởi Data-Juicer, chúng tôi sử dụng RedPajama và Pile gốc, và các bộ dữ liệu tinh chỉnh của chúng tôi để tiền huấn luyện LLMs với kiến trúc LLaMA chính thống và đánh giá hiệu suất của các mô hình trên 16 tác vụ HELM cốt lõi. Chúng tôi giữ nguyên cấu hình huấn luyện trong khi chỉ sửa đổi dữ liệu huấn luyện. Các siêu tham số chi tiết có trong Phụ lục B.3.1. Kết quả của điểm số trung bình của 16 tác vụ được trực quan hóa trong Hình 7, nơi chúng tôi đánh giá các checkpoint trong suốt quá trình tiền huấn luyện với số lượng token kích thước tỷ tăng dần tại 50B, 100B, và 150B. Đáng chú ý, thông qua so sánh công bằng với token huấn luyện tương đương, LLMs được tiền huấn luyện trên công thức Data-Juicer liên tục vượt trội hơn những cái chỉ sử dụng RedPajama hoặc liên minh của nó với Pile, củng cố tính hữu ích và hiệu quả của Data-Juicer.

Hơn nữa, chúng tôi so sánh các mô hình Data-Juicer với một số baseline tiên tiến và tóm tắt kết quả trong Bảng 2. Với chỉ một nửa khối lượng dữ liệu (150B token), LLaMA-1.3B được tiền huấn luyện trên công thức Data-Juicer vượt trội hơn Pythia-1.4B (300B token), và thậm chí đánh bại Falcon-1.3B có tính cạnh tranh cao được huấn luyện trên 350B token. Đáng chú ý, chúng tôi tiếp tục gắn nhãn 17 tập con từ Alpaca-CoT (một bộ sưu tập 39 bộ dữ liệu tinh chỉnh công khai) với thẻ "Instruct Fine-Tuning (IFT)" và thực hiện kết hợp và xử lý dữ liệu sử dụng Data-Juicer. Theo thông lệ thường thấy, chúng tôi kết hợp những dữ liệu IFT khối lượng lớn này vào giai đoạn tiền huấn luyện và thực hiện huấn luyện liên tục trên checkpoint của Data-Juicer (RedPajama+Pile)-150B. Như được phản ánh trong hai hàng cuối của Bảng 2, Data-Juicer đạt được cải thiện tương đối 4,9% thêm so với Alpaca-CoT-IFT gốc trong khi chỉ sử dụng ~30% khối lượng dữ liệu.

Kết hợp lại, những phát hiện này nhấn mạnh tiềm năng của hệ thống Data-Juicer để tạo ra dữ liệu chất lượng cao và xác minh sự xuất sắc của các công thức Data-Juicer về việc nâng cao hiệu suất LLM trong khi giảm chi phí huấn luyện LLM.

#### 7.1.2 Công thức dữ liệu tinh chỉnh được tinh chỉnh

Đối với bộ sưu tập Alpaca-CoT, bên cạnh thẻ "IFT" như được xác nhận trong Bảng 2, chúng tôi cũng gắn nhãn các bộ dữ liệu trong đó với "Chat Fine-Tuning (CFT)" để nâng cao khả năng đối thoại và căn chỉnh giá trị con người. Để kiểm tra chất lượng của chúng, chúng tôi đầu tiên sử dụng thẻ CFT và EN để lọc ra một số tập con cạnh tranh, và sau đó tạo ra hai bộ dữ liệu kích thước bằng nhau bằng cách lấy mẫu ngẫu nhiên và công thức được thiết kế của chúng tôi tương ứng. Sau đó chúng tôi tiến hành tinh chỉnh trên các bộ dữ liệu được tạo ra dựa trên kiến trúc chính thống mã nguồn mở, LLaMA-7B tiếng Anh. Tương tự, chúng tôi thay thế thẻ "EN" bằng "ZH", và sử dụng một biến thể LLaMA-2-7B tiên tiến cho kịch bản tiếng Trung. Thống kê của những bộ dữ liệu này và siêu tham số huấn luyện có trong Phụ lục B.3.2.

Để có một đánh giá hiệu suất toàn diện và so sánh, chúng tôi sử dụng API GPT-4 để ghi điểm theo cặp và tính toán thắng thua và hòa. Kết quả được hợp nhất trong Bảng 3, từ đó chúng tôi có thể thấy rằng LLMs sử dụng các công thức Data-Juicer liên tục chứng minh tính hợp lệ cao. Thứ nhất, so với LLMs được huấn luyện trên các bộ dữ liệu tinh chỉnh mở cạnh tranh, Alpaca và Belle, LLMs được huấn luyện trên dữ liệu Data-Juicer đạt được tỷ lệ thắng cao hơn (lên tới 17,5% cho trường hợp tiếng Anh) trong khi sử dụng ít dữ liệu hơn (lên tới 90,4% giảm cho trường hợp tiếng Trung). Thứ hai, so với LLMs được huấn luyện trên các bộ dữ liệu với chiến lược xử lý tầm thường (hỗn hợp bằng lấy mẫu ngẫu nhiên), LLMs được huấn luyện trên Data-Juicer vẫn đạt được tỷ lệ thắng cao hơn (lên tới 14,4%), điều này chứng thực lại hiệu quả của chiến lược lấy mẫu nâng cao và chất lượng của các công thức Data-Juicer cho LLMs.

### 7.2 Xử lý dữ liệu hiệu quả và hiệu suất

#### 7.2.1 Hiệu suất hệ thống từ đầu đến cuối

Để đánh giá hiệu suất xử lý của Data-Juicer, chúng tôi so sánh nó với hai baseline tiên tiến: RedPajama của TogetherAI và Dolma của AllenAI. Giới thiệu chi tiết hơn về và so sánh với những baseline này có thể được tìm thấy trong Phụ lục B.3.4. Để so sánh công bằng, ở đây chúng tôi sử dụng các kho mã chính thức của họ và chạy Data-Juicer trên các công thức dữ liệu với cùng OPs để xử lý các bộ dữ liệu Books, arXiv, và C4, khác nhau về kích thước dữ liệu, phân bố và liên quan đến các OPs xử lý đa dạng.

Chúng tôi tiến hành nhiều vòng thí nghiệm trên số lượng quy trình khác nhau (np=[32, 64, 128]) và giám sát một số chỉ số cốt lõi, bao gồm thời gian xử lý và sử dụng bộ nhớ trung bình. Thời gian được giám sát là thời gian thực tế của toàn bộ pipeline xử lý. Sử dụng bộ nhớ trung bình được giám sát mỗi giây và tổng hợp trên tất cả các quy trình liên quan. Để biết thêm chi tiết thí nghiệm, vui lòng tham khảo Phụ lục B.3.3.

Kết quả thí nghiệm được tóm tắt trong Hình 8. Đáng chú ý, đối với tất cả các bộ dữ liệu và số lượng quy trình khác nhau, Data-Juicer yêu cầu trung bình 50,6% ít thời gian xử lý hơn và 55,1% ít bộ nhớ hơn. Đặc biệt, nó tiết kiệm nhiều nhất 88,7% thời gian xử lý cho bộ dữ liệu arXiv so với baseline. Ngoài ra, nó chỉ chiếm lên tới 22,9% bộ nhớ của baseline cho Data-Juicer để xử lý bộ dữ liệu Books, chủ yếu là do quy trình xử lý của baseline tải toàn bộ bộ dữ liệu cùng một lúc. Nhìn chung, Data-Juicer hiệu quả giảm thiểu nút cổ chai gây ra bởi IO của các tệp cache, và đạt được hiệu quả thời gian-không gian từ đầu đến cuối tốt hơn so với baseline.

#### 7.2.2 Hiệu ứng của quản lý bối cảnh, hợp nhất OP, và sắp xếp lại

Như được giới thiệu trong Phần 6, Data-Juicer sử dụng tối ưu hóa chuyên dụng để giảm thiểu các tính toán dư thừa và tiết kiệm thời gian xử lý. Để kiểm tra hiệu ứng tối ưu hóa, chúng tôi chuẩn bị ba bộ dữ liệu thử nghiệm với kích thước và số lượng mẫu khác nhau. Mỗi bộ dữ liệu trải qua cùng một công thức xử lý bao gồm 14 OPs (5 Mappers, 8 Filters, và 1 Deduplicator), với 5 trong số những OPs này có thể hợp nhất. Chúng tôi tiến hành thí nghiệm so sánh với 4 quy trình, ngoại trừ bộ dữ liệu lớn nhất, nơi chúng tôi sử dụng 50 quy trình để đánh giá liệu những kỹ thuật này có hiệu quả trên quy mô lớn hơn hay không.

Kết quả được hiển thị trong Hình 9, nơi cả tiêu thụ thời gian chuẩn hóa và thực tế cho mỗi thiết lập thí nghiệm được chỉ ra. Kết quả cho thấy rằng chiến lược tối ưu hóa của chúng tôi hiệu quả tiết kiệm lên tới 24,91% tổng thời gian cho toàn bộ quy trình và tiết kiệm nhiều nhất 42,04% thời gian cho những OPs có thể hợp nhất. Ngoài ra, các phát hiện cho thấy rằng tối ưu hóa hoạt động hiệu quả bất kể sự khác biệt về kích thước bộ dữ liệu hoặc số lượng quy trình được sử dụng.

#### 7.2.3 Hiệu ứng của bộ phân loại chất lượng

Như được mô tả trong Phần 5.2, Data-Juicer cung cấp các bộ phân loại chất lượng tích hợp để xử lý dữ liệu LLM, và ở đây chúng tôi trình bày một số kết quả thực nghiệm liên quan đến hiệu suất của chúng. Cụ thể, chúng tôi theo quy trình huấn luyện của bộ phân loại chất lượng độc quyền được sử dụng trong GPT-3 và mở rộng pipeline huấn luyện của nó để bao gồm văn bản tiếng Trung. Trong việc đánh giá dữ liệu được thu thập, chúng tôi thấy rằng việc tái triển khai bộ phân loại GPT-3 và thích ứng tiếng Trung của nó đạt được điểm F1 là 97,47% và 98,64% tương ứng. Chi tiết huấn luyện và đánh giá thêm được cung cấp trong Phụ lục B.1.

Hơn nữa, chúng tôi đánh giá hiệu quả lọc của những bộ phân loại này bằng cách so sánh tỷ lệ giữ lại của chúng trên CommonCrawl. Kết quả được tóm tắt trong Bảng 4, nơi chúng tôi sử dụng hai phương pháp giữ dữ liệu được sử dụng trong GPT-3: (1) label: doc_score > 0.5; và (2) Pareto: doc_score > 1 - np.random.pareto(α), α = 9. Tỷ lệ giữ lại của các bộ phân loại chất lượng GPT-3 được tái triển khai của chúng tôi thường phù hợp với cái gốc, và phiên bản mở rộng tiếng Trung của chúng tôi duy trì tỷ lệ giữ lại có thể so sánh với phiên bản tiếng Anh.

#### 7.2.4 Khả năng mở rộng hệ thống

Để xác minh khả năng mở rộng nâng cao của hệ thống chúng tôi (như được chi tiết trong Phần 6), chúng tôi thực hiện một loạt thí nghiệm để đo thời gian xử lý dữ liệu trên nhiều máy chủ. Cụ thể, chúng tôi áp dụng các bộ dữ liệu StackExchange và arXiv từ RedPajama. Tổng kích thước của các bộ dữ liệu StackExchange và arXiv là 65GB và 140GB ở định dạng jsonl, tương ứng. Chúng tôi so sánh hiệu suất của Data-Juicer trên Ray, Data-Juicer trên Beam (sử dụng backend Flink), và Data-Juicer gốc trong những thử nghiệm này. Thêm chi tiết về triển khai và nền tảng thí nghiệm có trong Phụ lục B.3.5.

Kết quả thí nghiệm được minh họa trong Hình 10. Đáng chú ý, nhờ vào các tối ưu hóa khác nhau, hệ thống gốc của chúng tôi vượt trội hơn cả Ray và Beam trong kịch bản máy chủ đơn. Hơn nữa, khi số lượng nút tăng lên, thời gian xử lý của hệ thống chúng tôi trên Ray giảm tỷ lệ thuận (lên tới 87,4% và 84,6% giảm thời gian trên StackExchange và arXiv tương ứng), chứng minh khả năng mở rộng hiệu quả của nó trên nhiều máy chủ.

Tuy nhiên, thời gian xử lý của Data-Juicer trên Beam vẫn hầu như không thay đổi khi số lượng nút tăng. Sau khi điều tra thêm về quy trình làm việc xử lý, chúng tôi thấy rằng khả năng mở rộng hạn chế của Data-Juicer trên Beam chủ yếu bị ràng buộc bởi thành phần tải dữ liệu của Beam, dẫn đến tỷ lệ thời gian tải tệp chi phối và yêu cầu thay đổi phát triển đáng kể để thích ứng và tối ưu hóa hiệu suất thêm.

### 7.3 Trao quyền cho các sản phẩm thực tế

Data-Juicer đã được áp dụng bởi một số sản phẩm dựa trên LLM thực tế, đóng vai trò quan trọng trong việc hiểu và xử lý dữ liệu. Nó phát triển liên tục thông qua việc tích hợp phản hồi từ nhu cầu thực tế. Một minh chứng đáng chú ý cho tiện ích của nó là đóng góp của nó vào việc phát triển một số LLMs công nghiệp từ bộ Tongyi của Alibaba Cloud, như Dianjin, được sử dụng để phân tích tài chính; Zhiwen, một công cụ hỗ trợ đọc; và Xingchen, chuyên về tùy chỉnh nhân vật AI. Hơn nữa, khả năng xử lý dữ liệu của Data-Juicer đã được kết hợp vào Platform for AI (PAI) của Alibaba Cloud để hỗ trợ nhiều ứng dụng thực tế hơn.

Sự trừu tượng hóa OP chi tiết của hệ thống chúng tôi, kết hợp với các công cụ mở rộng để xử lý dữ liệu LLM, trao quyền cho người dùng dễ dàng khám phá và tinh chỉnh các công thức dữ liệu phù hợp với các thuộc tính văn bản riêng biệt của các trường hợp sử dụng đa dạng. Ví dụ, trong lĩnh vực tài chính, điều quan trọng là phải chứa dữ liệu bao gồm nhiều chữ số và thuật ngữ tiêu chuẩn hóa. Trong lĩnh vực hỗ trợ đọc, trọng tâm chuyển sang dữ liệu được đặc trưng bởi độ dài văn bản mở rộng và cấu trúc mạch lạc. Ngược lại, tùy chỉnh nhân vật đòi hỏi dữ liệu giàu đối thoại và đa dạng đủ để hỗ trợ các dịch vụ cá nhân hóa. Data-Juicer thành thạo đáp ứng những nhu cầu đa dạng này bằng cách tạo thuận lợi cho việc kết hợp các OPs, siêu tham số và công cụ riêng biệt thích ứng với nhu cầu độc đáo của mỗi ứng dụng thực tế.

## 8. KẾT LUẬN

Để kết luận, việc giới thiệu Data-Juicer phản ánh một bước tiến mới trong lĩnh vực phát triển LLM tập trung vào dữ liệu. Bằng cách cung cấp một giải pháp thân thiện với người dùng, linh hoạt và hiệu quả, Data-Juicer hiệu quả giải quyết các hạn chế hiện tại của các công cụ mã nguồn mở để xử lý dữ liệu LLM, nghiêng về khả năng tái tạo dữ liệu với cái giá của khả năng thích ứng và tính khả dụng. Việc tách biệt các thành phần được liên kết theo truyền thống thúc đẩy sự trừu tượng hóa và tính mô-đun lớn hơn, và sự sắp xếp hữu cơ của hơn 50 toán tử tích hợp, công cụ chuyên dụng và công thức dữ liệu phong phú phục vụ nhu cầu đa dạng cho tiền huấn luyện và tinh chỉnh LLM.

Ngoài việc hỗ trợ tự động đánh giá, Data-Juicer được tối ưu hóa cẩn thận và tích hợp liền mạch với cả hệ sinh thái để huấn luyện và đánh giá LLM, cũng như tính toán phân tán. Xác nhận thực nghiệm chứng kiến những cải thiện đáng kể trong hiệu suất của LLMs sử dụng các công thức dữ liệu của Data-Juicer, và cho thấy những tiến bộ trong hiệu quả hệ thống và khả năng mở rộng. Như vậy, Data-Juicer đứng như một sự bổ sung hấp dẫn cho bộ công cụ xử lý dữ liệu LLM, mà chúng tôi hy vọng có thể soi sáng nghiên cứu rộng rãi hơn cho lĩnh vực phát triển LLM tập trung vào dữ liệu.

# 2309.07172.pdf
# Chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/ontology/2309.07172.pdf
# KÃ­ch thÆ°á»›c file: 709797 bytes

===============================================
Ná»˜I DUNG FILE PDF
===============================================

--- TRANG 1 ---
KhÃ¡m phÃ¡ MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n cho CÄƒn chá»‰nh Ontology
Yuan He1, Jiaoyan Chen2,1, Hang Dong1 vÃ  Ian Horrocks1
1Khoa Khoa há»c MÃ¡y tÃ­nh, Äáº¡i há»c Oxford
2Khoa Khoa há»c MÃ¡y tÃ­nh, Äáº¡i há»c Manchester
TÃ³m táº¯t
CÃ´ng trÃ¬nh nÃ y Ä‘iá»u tra kháº£ nÄƒng á»©ng dá»¥ng cá»§a cÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n (LLMs) sinh táº¡o gáº§n Ä‘Ã¢y, nhÆ° loáº¡t GPT vÃ  Flan-T5, cho cÄƒn chá»‰nh ontology nháº±m xÃ¡c Ä‘á»‹nh Ã¡nh xáº¡ tÆ°Æ¡ng Ä‘Æ°Æ¡ng khÃ¡i niá»‡m giá»¯a cÃ¡c ontology. Äá»ƒ kiá»ƒm tra hiá»‡u suáº¥t zero-shot1 cá»§a Flan-T5-XXL vÃ  GPT-3.5-turbo, chÃºng tÃ´i táº­n dá»¥ng cÃ¡c táº­p con thÃ¡ch thá»©c tá»« hai bá»™ dá»¯ liá»‡u khá»›p tÆ°Æ¡ng Ä‘Æ°Æ¡ng cá»§a OAEI Bio-ML track, cÃ³ tÃ­nh Ä‘áº¿n nhÃ£n khÃ¡i niá»‡m vÃ  ngá»¯ cáº£nh cáº¥u trÃºc. Nhá»¯ng phÃ¡t hiá»‡n sÆ¡ bá»™ cho tháº¥y LLMs cÃ³ tiá»m nÄƒng vÆ°á»£t trá»™i hÆ¡n cÃ¡c há»‡ thá»‘ng cÄƒn chá»‰nh ontology hiá»‡n táº¡i nhÆ° BERTMap, vá»›i thiáº¿t káº¿ khung vÃ  prompt cáº©n tháº­n.2
Tá»« khÃ³a
CÄƒn chá»‰nh Ontology, Khá»›p Ontology, MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n, GPT, Flan-T5
1. Giá»›i thiá»‡u
CÄƒn chá»‰nh ontology, cÃ²n Ä‘Æ°á»£c gá»i lÃ  khá»›p ontology (OM), lÃ  Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¡c tÆ°Æ¡ng á»©ng ngá»¯ nghÄ©a giá»¯a cÃ¡c ontology. NÃ³ Ä‘Ã³ng vai trÃ² quan trá»ng trong biá»ƒu diá»…n tri thá»©c, ká»¹ thuáº­t tri thá»©c vÃ  Web Ngá»¯ nghÄ©a, Ä‘áº·c biá»‡t trong viá»‡c táº¡o Ä‘iá»u kiá»‡n cho kháº£ nÄƒng tÆ°Æ¡ng tÃ¡c ngá»¯ nghÄ©a giá»¯a cÃ¡c nguá»“n khÃ´ng Ä‘á»“ng nháº¥t. NghiÃªn cá»©u nÃ y táº­p trung vÃ o khá»›p tÆ°Æ¡ng Ä‘Æ°Æ¡ng cho cÃ¡c khÃ¡i niá»‡m cÃ³ tÃªn.
NghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y Ä‘Ã£ hiá»‡u quáº£ sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c nhÆ° BERT vÃ  T5 cho OM [1,2], nhÆ°ng nhá»¯ng tiáº¿n bá»™ gáº§n Ä‘Ã¢y trong mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs) nhÆ° ChatGPT [3] vÃ  Flan-T5 [4] cáº§n Ä‘Æ°á»£c khÃ¡m phÃ¡ thÃªm. Nhá»¯ng LLMs nÃ y, Ä‘Æ°á»£c Ä‘áº·c trÆ°ng bá»Ÿi kÃ­ch thÆ°á»›c tham sá»‘ lá»›n hÆ¡n vÃ  tinh chá»‰nh theo tÃ¡c vá»¥ cá»¥ thá»ƒ, thÆ°á»ng Ä‘Æ°á»£c hÆ°á»›ng dáº«n bá»Ÿi prompts Ä‘á»‹nh hÆ°á»›ng tÃ¡c vá»¥ trong thiáº¿t láº­p zero-shot hoáº·c má»™t táº­p nhá» vÃ­ dá»¥ trong thiáº¿t láº­p few-shot khi Ã¡p dá»¥ng cho cÃ¡c tÃ¡c vá»¥ downstream.
CÃ´ng trÃ¬nh nÃ y khÃ¡m phÃ¡ tÃ­nh kháº£ thi cá»§a viá»‡c sá»­ dá»¥ng LLMs cho OM zero-shot. Vá»›i yÃªu cáº§u tÃ­nh toÃ¡n Ä‘Ã¡ng ká»ƒ cá»§a LLMs, viá»‡c tiáº¿n hÃ nh thÃ­ nghiá»‡m vá»›i cÃ¡c bá»™ dá»¯ liá»‡u nhá» hÆ¡n nhÆ°ng Ä‘áº¡i diá»‡n trÆ°á»›c khi triá»ƒn khai Ä‘áº§y Ä‘á»§ lÃ  quan trá»ng. VÃ¬ váº­y, chÃºng tÃ´i trÃ­ch xuáº¥t hai táº­p con thÃ¡ch thá»©c tá»« cÃ¡c bá»™ dá»¯ liá»‡u khá»›p tÆ°Æ¡ng Ä‘Æ°Æ¡ng NCIT-DOID vÃ  SNOMED-FMA (Body), cáº£ hai Ä‘á»u lÃ  pháº§n cá»§a Bio-ML1
1Thuáº­t ngá»¯ "zero-shot" trong bá»‘i cáº£nh LLMs thÆ°á»ng Ä‘á» cáº­p Ä‘áº¿n viá»‡c sá»­ dá»¥ng LLMs Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c mÃ  khÃ´ng cáº§n tinh chá»‰nh.
2MÃ£ nguá»“n vÃ  bá»™ dá»¯ liá»‡u cá»§a chÃºng tÃ´i sáº½ cÃ³ sáºµn táº¡i: https://github.com/KRR-Oxford/LLMap-Prelim
ISWC 2023 Posters and Demos: 22nd International Semantic Web Conference, November 6â€“10, 2023, Athens, Greece
/envelope-open yuan.he@cs.ox.ac.uk (Y. He); jiaoyan.chen@manchester.ac.uk (J. Chen); hang.dong@cs.ox.ac.uk (H. Dong);
ian.horrocks@cs.ox.ac.uk (I. Horrocks)
/orcid0000-0002-4486-1262 (Y. He); 0000-0003-4643-6750 (J. Chen); 0000-0001-6828-6891 (H. Dong);
0000-0002-2685-7462 (I. Horrocks)
Â©2023 Copyright c 2023 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
CEUR
Workshop
Proceedingshttp://ceur-ws.org
ISSN 1613-0073
CEUR Workshop Proceedings (CEUR-WS.org)
1OAEI Bio-ML Track: https://www.cs.ox.ac.uk/isg/projects/ConCur/oaei/arXiv:2309.07172v1 [cs.AI] 12 Sep 2023

--- TRANG 2 ---
[5] â€“ má»™t track cá»§a SÃ¡ng kiáº¿n ÄÃ¡nh giÃ¡ CÄƒn chá»‰nh Ontology (OAEI) tÆ°Æ¡ng thÃ­ch vá»›i cÃ¡c há»‡ thá»‘ng OM dá»±a trÃªn machine learning. Äáº·c biá»‡t, cÃ¡c táº­p con Ä‘Æ°á»£c trÃ­ch xuáº¥t loáº¡i trá»« cÃ¡c Ã¡nh xáº¡ "dá»…", tá»©c lÃ  cÃ¡c cáº·p khÃ¡i niá»‡m cÃ³ thá»ƒ Ä‘Æ°á»£c cÄƒn chá»‰nh thÃ´ng qua khá»›p chuá»—i.
ChÃºng tÃ´i chá»§ yáº¿u Ä‘Ã¡nh giÃ¡ LLM mÃ£ nguá»“n má»Ÿ, Flan-T5-XXL, phiÃªn báº£n lá»›n nháº¥t cá»§a Flan-T5 chá»©a 11B tham sá»‘ [4]. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a nÃ³ cÃ³ tÃ­nh Ä‘áº¿n viá»‡c sá»­ dá»¥ng nhÃ£n khÃ¡i niá»‡m, ngÆ°á»¡ng Ä‘iá»ƒm sá»‘, vÃ  ngá»¯ cáº£nh cáº¥u trÃºc. Äá»ƒ lÃ m baseline, chÃºng tÃ´i sá»­ dá»¥ng há»‡ thá»‘ng OM cÃ³ hiá»‡u suáº¥t cao nháº¥t trÆ°á»›c Ä‘Ã¢y BERTMap vÃ  phiÃªn báº£n nháº¹ hÆ¡n BERTMapLt. CÃ¡c thá»­ nghiá»‡m sÆ¡ bá»™ cÅ©ng Ä‘Æ°á»£c tiáº¿n hÃ nh trÃªn GPT-3.5-turbo; tuy nhiÃªn, do chi phÃ­ cao, chá»‰ bÃ¡o cÃ¡o káº¿t quáº£ ban Ä‘áº§u. Nhá»¯ng phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i cho tháº¥y cÃ¡c há»‡ thá»‘ng OM dá»±a trÃªn LLM cÃ³ tiá»m nÄƒng vÆ°á»£t trá»™i hÆ¡n cÃ¡c há»‡ thá»‘ng hiá»‡n táº¡i, nhÆ°ng cáº§n ná»— lá»±c trong thiáº¿t káº¿ prompt vÃ  khÃ¡m phÃ¡ cÃ¡c phÆ°Æ¡ng phÃ¡p trÃ¬nh bÃ y tá»‘i Æ°u cho ngá»¯ cáº£nh ontology.
2. PhÆ°Æ¡ng phÃ¡p
Äá»‹nh nghÄ©a TÃ¡c vá»¥ TÃ¡c vá»¥ OM cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a nhÆ° sau. Cho cÃ¡c ontology nguá»“n vÃ  Ä‘Ã­ch, kÃ½ hiá»‡u lÃ  ğ’ªğ‘ ğ‘Ÿğ‘ vÃ  ğ’ªğ‘¡ğ‘”ğ‘¡, vÃ  cÃ¡c táº­p há»£p khÃ¡i niá»‡m cÃ³ tÃªn tÆ°Æ¡ng á»©ng ğ’ğ‘ ğ‘Ÿğ‘ vÃ  ğ’ğ‘¡ğ‘”ğ‘¡, má»¥c tiÃªu lÃ  táº¡o ra má»™t táº­p há»£p Ã¡nh xáº¡ dÆ°á»›i dáº¡ng (ğ‘âˆˆğ’ğ‘ ğ‘Ÿğ‘, ğ‘â€²âˆˆğ’ğ‘¡ğ‘”ğ‘¡, ğ‘ ğ‘â‰¡ğ‘â€²), trong Ä‘Ã³ ğ‘ vÃ  ğ‘â€² lÃ  cÃ¡c khÃ¡i niá»‡m tá»« ğ’ğ‘ ğ‘Ÿğ‘ vÃ  ğ’ğ‘¡ğ‘”ğ‘¡, tÆ°Æ¡ng á»©ng, vÃ  ğ‘ ğ‘â‰¡ğ‘â€²âˆˆ[0,1] lÃ  má»™t Ä‘iá»ƒm sá»‘ pháº£n Ã¡nh kháº£ nÄƒng cá»§a sá»± tÆ°Æ¡ng Ä‘Æ°Æ¡ng ğ‘â‰¡ğ‘â€². Tá»« Ä‘á»‹nh nghÄ©a nÃ y, chÃºng ta cÃ³ thá»ƒ tháº¥y ráº±ng má»™t thÃ nh pháº§n quan trá»ng cá»§a há»‡ thá»‘ng OM lÃ  hÃ m tÃ­nh Ä‘iá»ƒm Ã¡nh xáº¡ ğ‘ :ğ’ğ‘ ğ‘Ÿğ‘Ã—ğ’ğ‘¡ğ‘”ğ‘¡â†’[0,1]. Trong pháº§n tiáº¿p theo, chÃºng tÃ´i xÃ¢y dá»±ng má»™t tÃ¡c vá»¥ phá»¥ cho LLMs liÃªn quan Ä‘áº¿n má»¥c tiÃªu nÃ y.
Nháº­n dáº¡ng KhÃ¡i niá»‡m ÄÃ¢y vá» cÆ¡ báº£n lÃ  má»™t tÃ¡c vá»¥ phÃ¢n loáº¡i nhá»‹ phÃ¢n xÃ¡c Ä‘á»‹nh xem hai khÃ¡i niá»‡m, vá»›i tÃªn cá»§a chÃºng (nhiá»u nhÃ£n cho má»—i khÃ¡i niá»‡m cÃ³ thá»ƒ) vÃ /hoáº·c ngá»¯ cáº£nh cáº¥u trÃºc bá»• sung, cÃ³ giá»‘ng nhau hay khÃ´ng. VÃ¬ LLMs thÆ°á»ng hoáº¡t Ä‘á»™ng theo cÃ¡ch giá»‘ng chat, chÃºng ta cáº§n cung cáº¥p má»™t prompt tÃ¡c vá»¥ káº¿t há»£p thÃ´ng tin cÃ³ sáºµn cá»§a hai khÃ¡i niá»‡m Ä‘áº§u vÃ o, vÃ  thu tháº­p káº¿t quáº£ phÃ¢n loáº¡i tá»« pháº£n há»“i cá»§a LLMs. Äá»ƒ trÃ¡nh viá»‡c thiáº¿t káº¿ prompt quÃ¡ má»©c, chÃºng tÃ´i trÃ¬nh bÃ y mÃ´ táº£ tÃ¡c vá»¥ (nhÆ° trong cÃ¡c cÃ¢u trÆ°á»›c) vÃ  thÃ´ng tin Ä‘áº§u vÃ o cÃ³ sáºµn (nhÆ° nhÃ£n khÃ¡i niá»‡m vÃ  ngá»¯ cáº£nh cáº¥u trÃºc) cho ChatGPT dá»±a trÃªn GPT-42, vÃ  yÃªu cáº§u nÃ³ táº¡o ra má»™t prompt tÃ¡c vá»¥ cho má»™t LLM nhÆ° chÃ­nh nÃ³. Máº«u káº¿t quáº£ nhÆ° sau:
Cho cÃ¡c danh sÃ¡ch tÃªn vÃ  má»‘i quan há»‡ phÃ¢n cáº¥p liÃªn quan Ä‘áº¿n hai khÃ¡i niá»‡m, nhiá»‡m vá»¥ cá»§a báº¡n lÃ  xÃ¡c Ä‘á»‹nh xem cÃ¡c khÃ¡i niá»‡m nÃ y cÃ³ giá»‘ng nhau hay khÃ´ng. Xem xÃ©t nhá»¯ng Ä‘iá»u sau:
TÃªn KhÃ¡i niá»‡m Nguá»“n: <danh sÃ¡ch tÃªn khÃ¡i niá»‡m>
KhÃ¡i niá»‡m Cha cá»§a KhÃ¡i niá»‡m Nguá»“n: <danh sÃ¡ch tÃªn khÃ¡i niá»‡m>
KhÃ¡i niá»‡m Con cá»§a KhÃ¡i niá»‡m Nguá»“n: <danh sÃ¡ch tÃªn khÃ¡i niá»‡m>
... (tÆ°Æ¡ng tá»± cho khÃ¡i niá»‡m Ä‘Ã­ch)
PhÃ¢n tÃ­ch tÃªn vÃ  thÃ´ng tin phÃ¢n cáº¥p Ä‘Æ°á»£c cung cáº¥p cho má»—i khÃ¡i niá»‡m vÃ  Ä‘Æ°a ra káº¿t luáº­n vá» viá»‡c liá»‡u hai khÃ¡i niá»‡m nÃ y cÃ³ giá»‘ng nhau hay khÃ¡c nhau ("Yes" hoáº·c "No") dá»±a trÃªn tÃªn vÃ  má»‘i quan há»‡ phÃ¢n cáº¥p liÃªn quan cá»§a chÃºng.
trong Ä‘Ã³ pháº§n in nghiÃªng Ä‘Æ°á»£c táº¡o ra trong vÃ²ng thá»© hai khi chÃºng tÃ´i thÃ´ng bÃ¡o cho ChatGPT ráº±ng ngá»¯ cáº£nh cha/con cÃ³ thá»ƒ Ä‘Æ°á»£c xem xÃ©t. VÃ¬ prompt chá»‰ ra cÃ¢u há»i cÃ³/khÃ´ng, chÃºng tÃ´i dá»± Ä‘oÃ¡n viá»‡c táº¡o ra cÃ¡c token "Yes" hoáº·c "No" trong pháº£n há»“i cá»§a LLM. Äá»ƒ Ä‘Æ¡n giáº£n, chÃºng tÃ´i sá»­ dá»¥ng xÃ¡c suáº¥t táº¡o ra cá»§a token "Yes" lÃ m Ä‘iá»ƒm sá»‘ phÃ¢n loáº¡i. LÆ°u Ã½ ráº±ng Ä‘iá»ƒm sá»‘ nÃ y tá»· lá»‡ thuáº­n vá»›i Ä‘iá»ƒm sá»‘ Ã¡nh xáº¡ cuá»‘i cÃ¹ng nhÆ°ng khÃ´ng Ä‘Æ°á»£c chuáº©n hÃ³a. Äá»ƒ Ä‘Ã¡nh giÃ¡ dá»±a trÃªn xáº¿p háº¡ng, vá»›i má»™t khÃ¡i niá»‡m nguá»“n, chÃºng tÃ´i cÅ©ng xem xÃ©t cÃ¡c khÃ¡i niá»‡m Ä‘Ã­ch á»©ng viÃªn vá»›i cÃ¢u tráº£ lá»i "No" cÅ©ng nhÆ° Ä‘iá»ƒm sá»‘ "No" cá»§a chÃºng, Ä‘áº·t chÃºng sau cÃ¡c khÃ¡i niá»‡m Ä‘Ã­ch á»©ng viÃªn vá»›i cÃ¢u tráº£ lá»i "Yes" theo thá»© tá»± tÄƒng dáº§n â€“ Ä‘iá»ƒm sá»‘ "No" lá»›n hÆ¡n ngá»¥ Ã½ thá»© háº¡ng tháº¥p hÆ¡n.
2ChatGPT (phiÃªn báº£n GPT-4): https://chat.openai.com/?model=gpt-4

--- TRANG 3 ---
3. ÄÃ¡nh giÃ¡
XÃ¢y dá»±ng Bá»™ dá»¯ liá»‡u ÄÃ¡nh giÃ¡ LLMs vá»›i cÃ¡c bá»™ dá»¯ liá»‡u OM hiá»‡n táº¡i á»Ÿ quy mÃ´ bÃ¬nh thÆ°á»ng hoáº·c lá»›n cÃ³ thá»ƒ tá»‘n thá»i gian vÃ  tÃ i nguyÃªn. Äá»ƒ Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ cÃ³ Ã½ nghÄ©a trÆ°á»›c khi triá»ƒn khai Ä‘áº§y Ä‘á»§, chÃºng tÃ´i táº­n dá»¥ng hai táº­p con thÃ¡ch thá»©c Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« cÃ¡c bá»™ dá»¯ liá»‡u khá»›p tÆ°Æ¡ng Ä‘Æ°Æ¡ng NCIT-DOID vÃ  SNOMED-FMA (Body) cá»§a OAEI Bio-ML track. ChÃºng tÃ´i lá»±a chá»n Bio-ML vÃ¬ cÃ¡c Ã¡nh xáº¡ ground truth cá»§a nÃ³ Ä‘Æ°á»£c tuyá»ƒn chá»n bá»Ÿi con ngÆ°á»i vÃ  cÃ³ nguá»“n gá»‘c tá»« cÃ¡c nguá»“n Ä‘Ã¡ng tin cáº­y, Mondo vÃ  UMLS. ChÃºng tÃ´i chá»n NCIT-DOID vÃ  SNOMED-FMA (Body) tá»« nÄƒm lá»±a chá»n cÃ³ sáºµn vÃ¬ cÃ¡c ontology cá»§a chÃºng phong phÃº hÆ¡n vá» ngá»¯ cáº£nh phÃ¢n cáº¥p. Äá»‘i vá»›i má»—i bá»™ dá»¯ liá»‡u gá»‘c, chÃºng tÃ´i trÆ°á»›c tiÃªn chá»n ngáº«u nhiÃªn 50 cáº·p khÃ¡i niá»‡m khá»›p tá»« cÃ¡c Ã¡nh xáº¡ ground truth, nhÆ°ng loáº¡i trá»« cÃ¡c cáº·p cÃ³ thá»ƒ Ä‘Æ°á»£c cÄƒn chá»‰nh vá»›i khá»›p chuá»—i trá»±c tiáº¿p (tá»©c lÃ  cÃ³ Ã­t nháº¥t má»™t nhÃ£n chung) Ä‘á»ƒ háº¡n cháº¿ hiá»‡u quáº£ cá»§a khá»›p tá»« vá»±ng thÃ´ng thÆ°á»ng. Tiáº¿p theo, vá»›i má»™t khÃ¡i niá»‡m ontology nguá»“n cá»‘ Ä‘á»‹nh, chÃºng tÃ´i chá»n thÃªm 99 khÃ¡i niá»‡m ontology Ä‘Ã­ch khÃ´ng khá»›p, do Ä‘Ã³ táº¡o thÃ nh tá»•ng cá»™ng 100 Ã¡nh xáº¡ á»©ng viÃªn (bao gá»“m Ã¡nh xáº¡ ground truth). Viá»‡c lá»±a chá»n nÃ y Ä‘Æ°á»£c hÆ°á»›ng dáº«n bá»Ÿi Ä‘iá»ƒm sá»‘ idf dá»±a trÃªn chá»‰ má»¥c Ä‘áº£o ngÆ°á»£c sub-word nhÆ° trong He et al. [1], cÃ³ kháº£ nÄƒng táº¡o ra cÃ¡c khÃ¡i niá»‡m ontology Ä‘Ã­ch tÆ°Æ¡ng tá»± tá»« vá»±ng vá»›i khÃ¡i niá»‡m nguá»“n cá»‘ Ä‘á»‹nh. Cuá»‘i cÃ¹ng, chÃºng tÃ´i chá»n ngáº«u nhiÃªn 50 khÃ¡i niá»‡m nguá»“n khÃ´ng cÃ³ khÃ¡i niá»‡m Ä‘Ã­ch khá»›p theo cÃ¡c Ã¡nh xáº¡ ground truth, vÃ  táº¡o 100 Ã¡nh xáº¡ á»©ng viÃªn cho má»—i khÃ¡i niá»‡m. Do Ä‘Ã³, má»—i táº­p con gá»“m 50 khÃ¡i niá»‡m ontology nguá»“n cÃ³ khá»›p vÃ  50 khÃ´ng cÃ³. Má»—i khÃ¡i niá»‡m Ä‘Æ°á»£c liÃªn káº¿t vá»›i 100 Ã¡nh xáº¡ á»©ng viÃªn, táº¡o thÃ nh tá»•ng cá»™ng 10,000, tá»©c lÃ  (50+50)*100, cáº·p khÃ¡i niá»‡m Ä‘Æ°á»£c trÃ­ch xuáº¥t.
ThÆ°á»›c Ä‘o ÄÃ¡nh giÃ¡ Tá»« táº¥t cáº£ 10,000 cáº·p khÃ¡i niá»‡m trong má»™t táº­p con cho trÆ°á»›c, há»‡ thá»‘ng OM Ä‘Æ°á»£c ká»³ vá»ng dá»± Ä‘oÃ¡n cÃ¡c Ã¡nh xáº¡ thá»±c, cÃ³ thá»ƒ Ä‘Æ°á»£c so sÃ¡nh vá»›i 50 Ã¡nh xáº¡ ground truth cÃ³ sáºµn sá»­ dá»¥ng Precision, Recall, vÃ  F-score Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ :
ğ‘ƒ=|â„³ğ‘ğ‘Ÿğ‘’ğ‘‘âˆ©â„³ğ‘Ÿğ‘’ğ‘“|
|â„³ğ‘ğ‘Ÿğ‘’ğ‘‘|, ğ‘…=|â„³ğ‘ğ‘Ÿğ‘’ğ‘‘âˆ©â„³ğ‘Ÿğ‘’ğ‘“|
|â„³ğ‘Ÿğ‘’ğ‘“|, ğ¹1=2ğ‘ƒğ‘…
ğ‘ƒ+ğ‘…
trong Ä‘Ã³ â„³ğ‘ğ‘Ÿğ‘’ğ‘‘ Ä‘á» cáº­p Ä‘áº¿n táº­p há»£p cÃ¡c cáº·p khÃ¡i niá»‡m (trong sá»‘ 10,000 cáº·p) Ä‘Æ°á»£c dá»± Ä‘oÃ¡n lÃ  Ã¡nh xáº¡ thá»±c bá»Ÿi há»‡ thá»‘ng, vÃ  â„³ğ‘Ÿğ‘’ğ‘“ Ä‘á» cáº­p Ä‘áº¿n 50 Ã¡nh xáº¡ ground truth (tham chiáº¿u).
Vá»›i má»—i khÃ¡i niá»‡m nguá»“n Ä‘Æ°á»£c liÃªn káº¿t vá»›i 100 Ã¡nh xáº¡ á»©ng viÃªn, chÃºng ta cÃ³ thá»ƒ tÃ­nh toÃ¡n cÃ¡c thÆ°á»›c Ä‘o dá»±a trÃªn xáº¿p háº¡ng dá»±a trÃªn Ä‘iá»ƒm sá»‘ cá»§a chÃºng. Cá»¥ thá»ƒ, chÃºng tÃ´i tÃ­nh toÃ¡n Hits@1 cho 50 khÃ¡i niá»‡m nguá»“n khá»›p, Ä‘áº¿m má»™t hit khi Ã¡nh xáº¡ á»©ng viÃªn cÃ³ Ä‘iá»ƒm sá»‘ cao nháº¥t lÃ  má»™t Ã¡nh xáº¡ ground truth. Äiá»ƒm sá»‘ MRR cÅ©ng Ä‘Æ°á»£c tÃ­nh toÃ¡n cho cÃ¡c khÃ¡i niá»‡m nguá»“n khá»›p nÃ y, cá»™ng cÃ¡c nghá»‹ch Ä‘áº£o cá»§a thá»© háº¡ng tÆ°Æ¡ng Ä‘á»‘i cá»§a cÃ¡c Ã¡nh xáº¡ ground truth trong sá»‘ cÃ¡c Ã¡nh xáº¡ á»©ng viÃªn. Hai Ä‘iá»ƒm sá»‘ nÃ y Ä‘Æ°á»£c cÃ´ng thá»©c hÃ³a nhÆ°:
ğ»ğ‘–ğ‘¡ğ‘ @ğ¾=âˆ‘ï¸
(ğ‘,ğ‘â€²)âˆˆâ„³ğ‘Ÿğ‘’ğ‘“Iğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘â€²â‰¤ğ¾/|â„³ğ‘Ÿğ‘’ğ‘“|, ğ‘€ğ‘…ğ‘…=âˆ‘ï¸
(ğ‘,ğ‘â€²)âˆˆâ„³ğ‘Ÿğ‘’ğ‘“ğ‘Ÿğ‘ğ‘›ğ‘˜âˆ’1
ğ‘â€²/|â„³ğ‘Ÿğ‘’ğ‘“|
Äá»‘i vá»›i 50 khÃ¡i niá»‡m nguá»“n khÃ´ng khá»›p, chÃºng tÃ´i tÃ­nh toÃ¡n Tá»· lá»‡ Tá»« chá»‘i (RR), xem xÃ©t má»™t tá»« chá»‘i thÃ nh cÃ´ng khi táº¥t cáº£ cÃ¡c Ã¡nh xáº¡ á»©ng viÃªn Ä‘Æ°á»£c dá»± Ä‘oÃ¡n lÃ  Ã¡nh xáº¡ sai bá»Ÿi há»‡ thá»‘ng.

--- TRANG 4 ---
Há»‡ thá»‘ng Precision Recall F-score Hits@1 MRR RR
Flan-T5-XXL 0.643 0.720 0.679 0.860 0.927 0.860
+ ngÆ°á»¡ng 0.861 0.620 0.721 0.860 0.927 0.940
+ cha/con 0.597 0.740 0.661 0.880 0.926 0.760
+ ngÆ°á»¡ng & cha/con 0.750 0.480 0.585 0.880 0.926 0.920
GPT-3.5-turbo 0.217 0.560 0.313 - - -
BERTMap 0.750 0.540 0.628 0.900 0.940 0.920
BERTMapLt 0.196 0.180 0.187 0.460 0.516 0.920
Báº£ng 1
Káº¿t quáº£ trÃªn táº­p con thÃ¡ch thá»©c cá»§a bá»™ dá»¯ liá»‡u khá»›p tÆ°Æ¡ng Ä‘Æ°Æ¡ng NCIT-DOID cá»§a Bio-ML.
Há»‡ thá»‘ng Precision Recall F-score Hits@1 MRR RR
Flan-T5-XXL 0.257 0.360 0.300 0.500 0.655 0.640
+ ngÆ°á»¡ng 0.452 0.280 0.346 0.500 0.655 0.820
+ cha/con 0.387 0.240 0.296 0.540 0.667 0.900
+ ngÆ°á»¡ng & cha/con 0.429 0.120 0.188 0.540 0.667 0.940
GPT-3.5-turbo 0.075 0.540 0.132 - - -
BERTMap 0.485 0.640 0.552 0.540 0.723 0.920
BERTMapLt 0.516 0.320 0.395 0.340 0.543 0.960
Báº£ng 2
Káº¿t quáº£ trÃªn táº­p con thÃ¡ch thá»©c cá»§a bá»™ dá»¯ liá»‡u khá»›p tÆ°Æ¡ng Ä‘Æ°Æ¡ng SNOMED-FMA (Body) cá»§a Bio-ML.
há»‡ thá»‘ng. CÃ¡c khÃ¡i niá»‡m nguá»“n khÃ´ng khá»›p Ä‘Æ°á»£c gÃ¡n má»™t khá»›p "null", kÃ½ hiá»‡u lÃ  ğ‘ğ‘›ğ‘¢ğ‘™ğ‘™. Äiá»u nÃ y dáº«n Ä‘áº¿n má»™t táº­p há»£p cÃ¡c Ã¡nh xáº¡ "khÃ´ng Ä‘Æ°á»£c tham chiáº¿u", Ä‘Æ°á»£c biá»ƒu diá»…n lÃ  â„³ğ‘¢ğ‘›ğ‘Ÿğ‘’ğ‘“. ChÃºng ta cÃ³ thá»ƒ Ä‘á»‹nh nghÄ©a RR lÃ :
ğ‘…ğ‘…=âˆ‘ï¸
(ğ‘,ğ‘ğ‘›ğ‘¢ğ‘™ğ‘™)âˆˆâ„³ğ‘¢ğ‘›ğ‘Ÿğ‘’ğ‘“âˆï¸
ğ‘‘âˆˆğ’¯ğ‘(1âˆ’Iğ‘â‰¡ğ‘‘)/|â„³ğ‘¢ğ‘›ğ‘Ÿğ‘’ğ‘“|
trong Ä‘Ã³ ğ’¯ğ‘ lÃ  táº­p há»£p cÃ¡c lá»›p á»©ng viÃªn Ä‘Ã­ch cho má»™t khÃ¡i niá»‡m nguá»“n ğ‘, vÃ  Iğ‘â‰¡ğ‘‘ lÃ  má»™t chá»‰ sá»‘ nhá»‹ phÃ¢n xuáº¥t ra 1 náº¿u há»‡ thá»‘ng dá»± Ä‘oÃ¡n má»™t khá»›p giá»¯a ğ‘ vÃ  ğ‘‘, vÃ  0 ngÆ°á»£c láº¡i. ÄÃ¡ng chÃº Ã½ ráº±ng thuáº­t ngá»¯ tÃ­ch chá»‰ trá»Ÿ thÃ nh 1 khi táº¥t cáº£ cÃ¡c khÃ¡i niá»‡m á»©ng viÃªn Ä‘Ã­ch Ä‘Æ°á»£c dá»± Ä‘oÃ¡n lÃ  khá»›p sai, tá»©c lÃ  âˆ€ğ‘‘âˆˆğ’¯ğ‘.Iğ‘â‰¡ğ‘‘= 0.
Thiáº¿t láº­p MÃ´ hÃ¬nh ChÃºng tÃ´i kiá»ƒm tra Flan-T5-XXL dÆ°á»›i cÃ¡c thiáº¿t láº­p khÃ¡c nhau: (i) thiáº¿t láº­p vanilla, trong Ä‘Ã³ má»™t Ã¡nh xáº¡ Ä‘Æ°á»£c coi lÃ  Ä‘Ãºng náº¿u nÃ³ Ä‘Æ°á»£c liÃªn káº¿t vá»›i cÃ¢u tráº£ lá»i "Yes"; (ii) thiáº¿t láº­p ngÆ°á»¡ng3, lá»c ra cÃ¡c Ã¡nh xáº¡ "Yes" cÃ³ Ä‘iá»ƒm sá»‘ dÆ°á»›i má»™t ngÆ°á»¡ng nháº¥t Ä‘á»‹nh; (iii) thiáº¿t láº­p cha/con, trong Ä‘Ã³ cÃ¡c tÃªn khÃ¡i niá»‡m cha vÃ  con Ä‘Æ°á»£c láº¥y máº«u Ä‘Æ°á»£c bao gá»“m nhÆ° ngá»¯ cáº£nh bá»• sung; vÃ  (iv) thiáº¿t láº­p cha/con+ngÆ°á»¡ng, káº¿t há»£p cáº£ ngá»¯ cáº£nh cáº¥u trÃºc vÃ  lá»c ngÆ°á»¡ng.
ChÃºng tÃ´i cÅ©ng tiáº¿n hÃ nh thÃ­ nghiá»‡m cho GPT-3.5-turbo, biáº¿n thá»ƒ cÃ³ kháº£ nÄƒng nháº¥t trong loáº¡t GPT-3.5, sá»­ dá»¥ng cÃ¹ng má»™t prompt. Tuy nhiÃªn, chá»‰ thiáº¿t láº­p (i) Ä‘Æ°á»£c bÃ¡o cÃ¡o do chi phÃ­ cao cá»§a mÃ´ hÃ¬nh nÃ y.
Äá»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh baseline, chÃºng tÃ´i xem xÃ©t BERTMap vÃ  BERTMapLt [1,6], trong Ä‘Ã³ cÃ¡i trÆ°á»›c sá»­ dá»¥ng mÃ´ hÃ¬nh BERT Ä‘Æ°á»£c tinh chá»‰nh cho phÃ¢n loáº¡i vÃ  cÃ¡i sau sá»­ dá»¥ng Ä‘á»™ tÆ°Æ¡ng tá»± chá»‰nh sá»­a Ä‘Æ°á»£c chuáº©n hÃ³a. LÆ°u Ã½ ráº±ng cáº£ BERTMap vÃ  BERTMapLt Ä‘á»u Ã¡p dá»¥ng thiáº¿t láº­p (ii) theo báº£n cháº¥t.
Káº¿t quáº£ NhÆ° thá»ƒ hiá»‡n trong Báº£ng 1-2, chÃºng tÃ´i quan sÃ¡t tháº¥y ráº±ng Flan-T5-XXL (+ngÆ°á»¡ng) cÃ³ Ä‘Æ°á»£c F-score tá»‘t nháº¥t trong sá»‘ cÃ¡c thiáº¿t láº­p cá»§a nÃ³. Trong khi nÃ³ vÆ°á»£t trá»™i hÆ¡n BERTMap 0.093 vá» F-score trÃªn táº­p con NCIT-DOID nhÆ°ng thua kÃ©m BERTMap vÃ  BERTMapLt láº§n lÆ°á»£t 0.206 vÃ  0.049 trÃªn táº­p con SNOMED-FMA (Body). Vá» MRR, BERTMap dáº«n Ä‘áº§u trÃªn cáº£ hai táº­p con. Trong sá»‘ cÃ¡c thiáº¿t láº­p Flan-T5-XXL, sá»­ dá»¥ng ngÆ°á»¡ng tÄƒng cÆ°á»ng Ä‘á»™ chÃ­nh xÃ¡c nhÆ°ng giáº£m Ä‘á»™ phá»§. Viá»‡c káº¿t há»£p ngá»¯ cáº£nh cha/con khÃ´ng cáº£i thiá»‡n káº¿t quáº£ khá»›p â€“ Ä‘iá»u nÃ y nháº¥n máº¡nh nhu cáº§u nghiÃªn cá»©u sÃ¢u hÆ¡n vá» cÃ¡c chiáº¿n lÆ°á»£c táº­n dá»¥ng ngá»¯ cáº£nh ontology. GPT-3.5-turbo4 khÃ´ng hoáº¡t Ä‘á»™ng tá»‘t vá»›i prompt Ä‘Ã£ cho. Má»™t lÃ½ do cÃ³ thá»ƒ lÃ  xu hÆ°á»›ng cá»§a mÃ´ hÃ¬nh cung cáº¥p cÃ¡c giáº£i thÃ­ch má»Ÿ rá»™ng cho pháº£n há»“i cá»§a nÃ³, khiáº¿n viá»‡c trÃ­ch xuáº¥t cÃ¢u tráº£ lá»i cÃ³/khÃ´ng Ä‘Æ¡n giáº£n trá»Ÿ nÃªn thÃ¡ch thá»©c. BÃªn cáº¡nh Ä‘Ã³, khÃ´ng cÃ³ Ä‘iá»ƒm sá»‘ xáº¿p háº¡ng Ä‘Æ°á»£c trÃ¬nh bÃ y cho GPT-3.5-turbo vÃ¬ nÃ³ khÃ´ng há»— trá»£ trÃ­ch xuáº¥t xÃ¡c suáº¥t táº¡o ra. Hiá»‡u suáº¥t khÃ´ng tá»‘i Æ°u cá»§a BERTMapLt nhÆ° mong Ä‘á»£i vÃ¬ chÃºng tÃ´i loáº¡i trá»« cÃ¡c cáº·p khÃ¡i niá»‡m cÃ³ thá»ƒ Ä‘Æ°á»£c khá»›p chuá»—i tá»« cÃ¡c bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c trÃ­ch xuáº¥t trong khi BERTMapLt dá»±a vÃ o Ä‘iá»ƒm sá»‘ Ä‘á»™ tÆ°Æ¡ng tá»± chá»‰nh sá»­a.
3CÃ¡c ngÆ°á»¡ng Ä‘Æ°á»£c thiáº¿t láº­p theo kinh nghiá»‡m lÃ  0.650, 0.999, vÃ  0.900 cho Flan-T5-XXL, BERTMap, vÃ  BERTMapLt trong má»™t thÃ­ nghiá»‡m tiÃªn phong liÃªn quan Ä‘áº¿n cÃ¡c Ä‘oáº¡n nhá».

--- TRANG 5 ---
4. Káº¿t luáº­n vÃ  CÃ´ng viá»‡c TÆ°Æ¡ng lai
NghiÃªn cá»©u nÃ y trÃ¬nh bÃ y má»™t khÃ¡m phÃ¡ vá» LLMs cho OM trong thiáº¿t láº­p zero-shot. Káº¿t quáº£ trÃªn hai táº­p con thÃ¡ch thá»©c cá»§a cÃ¡c bá»™ dá»¯ liá»‡u OM cho tháº¥y ráº±ng viá»‡c sá»­ dá»¥ng LLMs cÃ³ thá»ƒ lÃ  má»™t hÆ°á»›ng Ä‘i há»©a háº¹n cho OM nhÆ°ng cáº§n giáº£i quyáº¿t nhiá»u váº¥n Ä‘á» khÃ¡c nhau bao gá»“m, nhÆ°ng khÃ´ng giá»›i háº¡n á»Ÿ, thiáº¿t káº¿ prompts vÃ  khung tá»•ng thá»ƒ5, vÃ  viá»‡c káº¿t há»£p ngá»¯ cáº£nh ontology. CÃ¡c nghiÃªn cá»©u tÆ°Æ¡ng lai bao gá»“m tinh chá»‰nh cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn prompt, Ä‘iá»u tra viá»‡c Ä‘iá»u chá»‰nh few-shot hiá»‡u quáº£, vÃ  khÃ¡m phÃ¡ cÃ¡c LLMs cÃ³ thÃ´ng tin cáº¥u trÃºc. Nhá»¯ng bÃ i há»c rÃºt ra tá»« cÃ¡c nghiÃªn cá»©u OM nÃ y cÅ©ng cÃ³ thá»ƒ cung cáº¥p nhá»¯ng hiá»ƒu biáº¿t cho cÃ¡c tÃ¡c vá»¥ ká»¹ thuáº­t ontology khÃ¡c nhÆ° hoÃ n thÃ nh vÃ  nhÃºng ontology, vÃ  má»Ÿ Ä‘Æ°á»ng cho má»™t nghiÃªn cá»©u rá»™ng hÆ¡n vá» viá»‡c tÃ­ch há»£p LLMs vá»›i dá»¯ liá»‡u cÃ³ cáº¥u trÃºc.
TÃ i liá»‡u tham kháº£o
[1] Y. He, J. Chen, D. Antonyrajah, I. Horrocks, BERTMap: A BERT-based ontology alignment system, trong: AAAI, 2022.
[2] M. Amir, M. Baruah, M. Eslamialishah, S. Ehsani, A. Bahramali, S. Naddaf-Sh, S. Zarandioon, Truveta mapper: A zero-shot ontology alignment framework, arXiv (2023).
[3] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al., Training language models to follow instructions with human feedback, trong: NeurIPS, 2022.
[4] H. W. Chung, L. Hou, S. Longpre, B. Zoph, Y. Tay, W. Fedus, E. Li, X. Wang, M. Dehghani, S. Brahma, et al., Scaling instruction-finetuned language models, arXiv (2022).
[5] Y. He, J. Chen, H. Dong, E. JimÃ©nez-Ruiz, A. Hadian, I. Horrocks, Machine learning-friendly biomedical datasets for equivalence and subsumption ontology matching, trong: ISWC, 2022.
[6] Y. He, J. Chen, H. Dong, I. Horrocks, C. Allocca, T. Kim, B. Sapkota, Deeponto: A python package for ontology engineering with deep learning, arXiv preprint arXiv:2307.03067 (2023).
4CÃ¡c thá»­ nghiá»‡m thÃ­ nghiá»‡m cho text-davinci-003 vÃ  GPT-4 cÅ©ng cho tháº¥y káº¿t quáº£ khÃ´ng tá»‘i Æ°u.
5CÃ´ng viá»‡c nÃ y táº­p trung vÃ o viá»‡c tÃ­nh Ä‘iá»ƒm Ã¡nh xáº¡, nhÆ°ng pháº§n tÃ¬m kiáº¿m (hoáº·c lá»±a chá»n á»©ng viÃªn) cá»§a OM cÅ©ng quan trá»ng, Ä‘áº·c biá»‡t xem xÃ©t ráº±ng LLMs cÃ³ chi phÃ­ tÃ­nh toÃ¡n ráº¥t cao.

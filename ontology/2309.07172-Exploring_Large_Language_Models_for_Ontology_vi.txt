# 2309.07172.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/ontology/2309.07172.pdf
# Kích thước file: 709797 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Khám phá Mô hình Ngôn ngữ Lớn cho Căn chỉnh Ontology
Yuan He1, Jiaoyan Chen2,1, Hang Dong1 và Ian Horrocks1
1Khoa Khoa học Máy tính, Đại học Oxford
2Khoa Khoa học Máy tính, Đại học Manchester
Tóm tắt
Công trình này điều tra khả năng ứng dụng của các Mô hình Ngôn ngữ Lớn (LLMs) sinh tạo gần đây, như loạt GPT và Flan-T5, cho căn chỉnh ontology nhằm xác định ánh xạ tương đương khái niệm giữa các ontology. Để kiểm tra hiệu suất zero-shot1 của Flan-T5-XXL và GPT-3.5-turbo, chúng tôi tận dụng các tập con thách thức từ hai bộ dữ liệu khớp tương đương của OAEI Bio-ML track, có tính đến nhãn khái niệm và ngữ cảnh cấu trúc. Những phát hiện sơ bộ cho thấy LLMs có tiềm năng vượt trội hơn các hệ thống căn chỉnh ontology hiện tại như BERTMap, với thiết kế khung và prompt cẩn thận.2
Từ khóa
Căn chỉnh Ontology, Khớp Ontology, Mô hình Ngôn ngữ Lớn, GPT, Flan-T5
1. Giới thiệu
Căn chỉnh ontology, còn được gọi là khớp ontology (OM), là để xác định các tương ứng ngữ nghĩa giữa các ontology. Nó đóng vai trò quan trọng trong biểu diễn tri thức, kỹ thuật tri thức và Web Ngữ nghĩa, đặc biệt trong việc tạo điều kiện cho khả năng tương tác ngữ nghĩa giữa các nguồn không đồng nhất. Nghiên cứu này tập trung vào khớp tương đương cho các khái niệm có tên.
Nghiên cứu trước đây đã hiệu quả sử dụng các mô hình ngôn ngữ được huấn luyện trước như BERT và T5 cho OM [1,2], nhưng những tiến bộ gần đây trong mô hình ngôn ngữ lớn (LLMs) như ChatGPT [3] và Flan-T5 [4] cần được khám phá thêm. Những LLMs này, được đặc trưng bởi kích thước tham số lớn hơn và tinh chỉnh theo tác vụ cụ thể, thường được hướng dẫn bởi prompts định hướng tác vụ trong thiết lập zero-shot hoặc một tập nhỏ ví dụ trong thiết lập few-shot khi áp dụng cho các tác vụ downstream.
Công trình này khám phá tính khả thi của việc sử dụng LLMs cho OM zero-shot. Với yêu cầu tính toán đáng kể của LLMs, việc tiến hành thí nghiệm với các bộ dữ liệu nhỏ hơn nhưng đại diện trước khi triển khai đầy đủ là quan trọng. Vì vậy, chúng tôi trích xuất hai tập con thách thức từ các bộ dữ liệu khớp tương đương NCIT-DOID và SNOMED-FMA (Body), cả hai đều là phần của Bio-ML1
1Thuật ngữ "zero-shot" trong bối cảnh LLMs thường đề cập đến việc sử dụng LLMs được huấn luyện trước mà không cần tinh chỉnh.
2Mã nguồn và bộ dữ liệu của chúng tôi sẽ có sẵn tại: https://github.com/KRR-Oxford/LLMap-Prelim
ISWC 2023 Posters and Demos: 22nd International Semantic Web Conference, November 6–10, 2023, Athens, Greece
/envelope-open yuan.he@cs.ox.ac.uk (Y. He); jiaoyan.chen@manchester.ac.uk (J. Chen); hang.dong@cs.ox.ac.uk (H. Dong);
ian.horrocks@cs.ox.ac.uk (I. Horrocks)
/orcid0000-0002-4486-1262 (Y. He); 0000-0003-4643-6750 (J. Chen); 0000-0001-6828-6891 (H. Dong);
0000-0002-2685-7462 (I. Horrocks)
©2023 Copyright c 2023 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).
CEUR
Workshop
Proceedingshttp://ceur-ws.org
ISSN 1613-0073
CEUR Workshop Proceedings (CEUR-WS.org)
1OAEI Bio-ML Track: https://www.cs.ox.ac.uk/isg/projects/ConCur/oaei/arXiv:2309.07172v1 [cs.AI] 12 Sep 2023

--- TRANG 2 ---
[5] – một track của Sáng kiến Đánh giá Căn chỉnh Ontology (OAEI) tương thích với các hệ thống OM dựa trên machine learning. Đặc biệt, các tập con được trích xuất loại trừ các ánh xạ "dễ", tức là các cặp khái niệm có thể được căn chỉnh thông qua khớp chuỗi.
Chúng tôi chủ yếu đánh giá LLM mã nguồn mở, Flan-T5-XXL, phiên bản lớn nhất của Flan-T5 chứa 11B tham số [4]. Chúng tôi đánh giá hiệu suất của nó có tính đến việc sử dụng nhãn khái niệm, ngưỡng điểm số, và ngữ cảnh cấu trúc. Để làm baseline, chúng tôi sử dụng hệ thống OM có hiệu suất cao nhất trước đây BERTMap và phiên bản nhẹ hơn BERTMapLt. Các thử nghiệm sơ bộ cũng được tiến hành trên GPT-3.5-turbo; tuy nhiên, do chi phí cao, chỉ báo cáo kết quả ban đầu. Những phát hiện của chúng tôi cho thấy các hệ thống OM dựa trên LLM có tiềm năng vượt trội hơn các hệ thống hiện tại, nhưng cần nỗ lực trong thiết kế prompt và khám phá các phương pháp trình bày tối ưu cho ngữ cảnh ontology.
2. Phương pháp
Định nghĩa Tác vụ Tác vụ OM có thể được định nghĩa như sau. Cho các ontology nguồn và đích, ký hiệu là 𝒪𝑠𝑟𝑐 và 𝒪𝑡𝑔𝑡, và các tập hợp khái niệm có tên tương ứng 𝒞𝑠𝑟𝑐 và 𝒞𝑡𝑔𝑡, mục tiêu là tạo ra một tập hợp ánh xạ dưới dạng (𝑐∈𝒞𝑠𝑟𝑐, 𝑐′∈𝒞𝑡𝑔𝑡, 𝑠𝑐≡𝑐′), trong đó 𝑐 và 𝑐′ là các khái niệm từ 𝒞𝑠𝑟𝑐 và 𝒞𝑡𝑔𝑡, tương ứng, và 𝑠𝑐≡𝑐′∈[0,1] là một điểm số phản ánh khả năng của sự tương đương 𝑐≡𝑐′. Từ định nghĩa này, chúng ta có thể thấy rằng một thành phần quan trọng của hệ thống OM là hàm tính điểm ánh xạ 𝑠:𝒞𝑠𝑟𝑐×𝒞𝑡𝑔𝑡→[0,1]. Trong phần tiếp theo, chúng tôi xây dựng một tác vụ phụ cho LLMs liên quan đến mục tiêu này.
Nhận dạng Khái niệm Đây về cơ bản là một tác vụ phân loại nhị phân xác định xem hai khái niệm, với tên của chúng (nhiều nhãn cho mỗi khái niệm có thể) và/hoặc ngữ cảnh cấu trúc bổ sung, có giống nhau hay không. Vì LLMs thường hoạt động theo cách giống chat, chúng ta cần cung cấp một prompt tác vụ kết hợp thông tin có sẵn của hai khái niệm đầu vào, và thu thập kết quả phân loại từ phản hồi của LLMs. Để tránh việc thiết kế prompt quá mức, chúng tôi trình bày mô tả tác vụ (như trong các câu trước) và thông tin đầu vào có sẵn (như nhãn khái niệm và ngữ cảnh cấu trúc) cho ChatGPT dựa trên GPT-42, và yêu cầu nó tạo ra một prompt tác vụ cho một LLM như chính nó. Mẫu kết quả như sau:
Cho các danh sách tên và mối quan hệ phân cấp liên quan đến hai khái niệm, nhiệm vụ của bạn là xác định xem các khái niệm này có giống nhau hay không. Xem xét những điều sau:
Tên Khái niệm Nguồn: <danh sách tên khái niệm>
Khái niệm Cha của Khái niệm Nguồn: <danh sách tên khái niệm>
Khái niệm Con của Khái niệm Nguồn: <danh sách tên khái niệm>
... (tương tự cho khái niệm đích)
Phân tích tên và thông tin phân cấp được cung cấp cho mỗi khái niệm và đưa ra kết luận về việc liệu hai khái niệm này có giống nhau hay khác nhau ("Yes" hoặc "No") dựa trên tên và mối quan hệ phân cấp liên quan của chúng.
trong đó phần in nghiêng được tạo ra trong vòng thứ hai khi chúng tôi thông báo cho ChatGPT rằng ngữ cảnh cha/con có thể được xem xét. Vì prompt chỉ ra câu hỏi có/không, chúng tôi dự đoán việc tạo ra các token "Yes" hoặc "No" trong phản hồi của LLM. Để đơn giản, chúng tôi sử dụng xác suất tạo ra của token "Yes" làm điểm số phân loại. Lưu ý rằng điểm số này tỷ lệ thuận với điểm số ánh xạ cuối cùng nhưng không được chuẩn hóa. Để đánh giá dựa trên xếp hạng, với một khái niệm nguồn, chúng tôi cũng xem xét các khái niệm đích ứng viên với câu trả lời "No" cũng như điểm số "No" của chúng, đặt chúng sau các khái niệm đích ứng viên với câu trả lời "Yes" theo thứ tự tăng dần – điểm số "No" lớn hơn ngụ ý thứ hạng thấp hơn.
2ChatGPT (phiên bản GPT-4): https://chat.openai.com/?model=gpt-4

--- TRANG 3 ---
3. Đánh giá
Xây dựng Bộ dữ liệu Đánh giá LLMs với các bộ dữ liệu OM hiện tại ở quy mô bình thường hoặc lớn có thể tốn thời gian và tài nguyên. Để đạt được kết quả có ý nghĩa trước khi triển khai đầy đủ, chúng tôi tận dụng hai tập con thách thức được trích xuất từ các bộ dữ liệu khớp tương đương NCIT-DOID và SNOMED-FMA (Body) của OAEI Bio-ML track. Chúng tôi lựa chọn Bio-ML vì các ánh xạ ground truth của nó được tuyển chọn bởi con người và có nguồn gốc từ các nguồn đáng tin cậy, Mondo và UMLS. Chúng tôi chọn NCIT-DOID và SNOMED-FMA (Body) từ năm lựa chọn có sẵn vì các ontology của chúng phong phú hơn về ngữ cảnh phân cấp. Đối với mỗi bộ dữ liệu gốc, chúng tôi trước tiên chọn ngẫu nhiên 50 cặp khái niệm khớp từ các ánh xạ ground truth, nhưng loại trừ các cặp có thể được căn chỉnh với khớp chuỗi trực tiếp (tức là có ít nhất một nhãn chung) để hạn chế hiệu quả của khớp từ vựng thông thường. Tiếp theo, với một khái niệm ontology nguồn cố định, chúng tôi chọn thêm 99 khái niệm ontology đích không khớp, do đó tạo thành tổng cộng 100 ánh xạ ứng viên (bao gồm ánh xạ ground truth). Việc lựa chọn này được hướng dẫn bởi điểm số idf dựa trên chỉ mục đảo ngược sub-word như trong He et al. [1], có khả năng tạo ra các khái niệm ontology đích tương tự từ vựng với khái niệm nguồn cố định. Cuối cùng, chúng tôi chọn ngẫu nhiên 50 khái niệm nguồn không có khái niệm đích khớp theo các ánh xạ ground truth, và tạo 100 ánh xạ ứng viên cho mỗi khái niệm. Do đó, mỗi tập con gồm 50 khái niệm ontology nguồn có khớp và 50 không có. Mỗi khái niệm được liên kết với 100 ánh xạ ứng viên, tạo thành tổng cộng 10,000, tức là (50+50)*100, cặp khái niệm được trích xuất.
Thước đo Đánh giá Từ tất cả 10,000 cặp khái niệm trong một tập con cho trước, hệ thống OM được kỳ vọng dự đoán các ánh xạ thực, có thể được so sánh với 50 ánh xạ ground truth có sẵn sử dụng Precision, Recall, và F-score được định nghĩa là:
𝑃=|ℳ𝑝𝑟𝑒𝑑∩ℳ𝑟𝑒𝑓|
|ℳ𝑝𝑟𝑒𝑑|, 𝑅=|ℳ𝑝𝑟𝑒𝑑∩ℳ𝑟𝑒𝑓|
|ℳ𝑟𝑒𝑓|, 𝐹1=2𝑃𝑅
𝑃+𝑅
trong đó ℳ𝑝𝑟𝑒𝑑 đề cập đến tập hợp các cặp khái niệm (trong số 10,000 cặp) được dự đoán là ánh xạ thực bởi hệ thống, và ℳ𝑟𝑒𝑓 đề cập đến 50 ánh xạ ground truth (tham chiếu).
Với mỗi khái niệm nguồn được liên kết với 100 ánh xạ ứng viên, chúng ta có thể tính toán các thước đo dựa trên xếp hạng dựa trên điểm số của chúng. Cụ thể, chúng tôi tính toán Hits@1 cho 50 khái niệm nguồn khớp, đếm một hit khi ánh xạ ứng viên có điểm số cao nhất là một ánh xạ ground truth. Điểm số MRR cũng được tính toán cho các khái niệm nguồn khớp này, cộng các nghịch đảo của thứ hạng tương đối của các ánh xạ ground truth trong số các ánh xạ ứng viên. Hai điểm số này được công thức hóa như:
𝐻𝑖𝑡𝑠@𝐾=∑︁
(𝑐,𝑐′)∈ℳ𝑟𝑒𝑓I𝑟𝑎𝑛𝑘𝑐′≤𝐾/|ℳ𝑟𝑒𝑓|, 𝑀𝑅𝑅=∑︁
(𝑐,𝑐′)∈ℳ𝑟𝑒𝑓𝑟𝑎𝑛𝑘−1
𝑐′/|ℳ𝑟𝑒𝑓|
Đối với 50 khái niệm nguồn không khớp, chúng tôi tính toán Tỷ lệ Từ chối (RR), xem xét một từ chối thành công khi tất cả các ánh xạ ứng viên được dự đoán là ánh xạ sai bởi hệ thống.

--- TRANG 4 ---
Hệ thống Precision Recall F-score Hits@1 MRR RR
Flan-T5-XXL 0.643 0.720 0.679 0.860 0.927 0.860
+ ngưỡng 0.861 0.620 0.721 0.860 0.927 0.940
+ cha/con 0.597 0.740 0.661 0.880 0.926 0.760
+ ngưỡng & cha/con 0.750 0.480 0.585 0.880 0.926 0.920
GPT-3.5-turbo 0.217 0.560 0.313 - - -
BERTMap 0.750 0.540 0.628 0.900 0.940 0.920
BERTMapLt 0.196 0.180 0.187 0.460 0.516 0.920
Bảng 1
Kết quả trên tập con thách thức của bộ dữ liệu khớp tương đương NCIT-DOID của Bio-ML.
Hệ thống Precision Recall F-score Hits@1 MRR RR
Flan-T5-XXL 0.257 0.360 0.300 0.500 0.655 0.640
+ ngưỡng 0.452 0.280 0.346 0.500 0.655 0.820
+ cha/con 0.387 0.240 0.296 0.540 0.667 0.900
+ ngưỡng & cha/con 0.429 0.120 0.188 0.540 0.667 0.940
GPT-3.5-turbo 0.075 0.540 0.132 - - -
BERTMap 0.485 0.640 0.552 0.540 0.723 0.920
BERTMapLt 0.516 0.320 0.395 0.340 0.543 0.960
Bảng 2
Kết quả trên tập con thách thức của bộ dữ liệu khớp tương đương SNOMED-FMA (Body) của Bio-ML.
hệ thống. Các khái niệm nguồn không khớp được gán một khớp "null", ký hiệu là 𝑐𝑛𝑢𝑙𝑙. Điều này dẫn đến một tập hợp các ánh xạ "không được tham chiếu", được biểu diễn là ℳ𝑢𝑛𝑟𝑒𝑓. Chúng ta có thể định nghĩa RR là:
𝑅𝑅=∑︁
(𝑐,𝑐𝑛𝑢𝑙𝑙)∈ℳ𝑢𝑛𝑟𝑒𝑓∏︁
𝑑∈𝒯𝑐(1−I𝑐≡𝑑)/|ℳ𝑢𝑛𝑟𝑒𝑓|
trong đó 𝒯𝑐 là tập hợp các lớp ứng viên đích cho một khái niệm nguồn 𝑐, và I𝑐≡𝑑 là một chỉ số nhị phân xuất ra 1 nếu hệ thống dự đoán một khớp giữa 𝑐 và 𝑑, và 0 ngược lại. Đáng chú ý rằng thuật ngữ tích chỉ trở thành 1 khi tất cả các khái niệm ứng viên đích được dự đoán là khớp sai, tức là ∀𝑑∈𝒯𝑐.I𝑐≡𝑑= 0.
Thiết lập Mô hình Chúng tôi kiểm tra Flan-T5-XXL dưới các thiết lập khác nhau: (i) thiết lập vanilla, trong đó một ánh xạ được coi là đúng nếu nó được liên kết với câu trả lời "Yes"; (ii) thiết lập ngưỡng3, lọc ra các ánh xạ "Yes" có điểm số dưới một ngưỡng nhất định; (iii) thiết lập cha/con, trong đó các tên khái niệm cha và con được lấy mẫu được bao gồm như ngữ cảnh bổ sung; và (iv) thiết lập cha/con+ngưỡng, kết hợp cả ngữ cảnh cấu trúc và lọc ngưỡng.
Chúng tôi cũng tiến hành thí nghiệm cho GPT-3.5-turbo, biến thể có khả năng nhất trong loạt GPT-3.5, sử dụng cùng một prompt. Tuy nhiên, chỉ thiết lập (i) được báo cáo do chi phí cao của mô hình này.
Đối với các mô hình baseline, chúng tôi xem xét BERTMap và BERTMapLt [1,6], trong đó cái trước sử dụng mô hình BERT được tinh chỉnh cho phân loại và cái sau sử dụng độ tương tự chỉnh sửa được chuẩn hóa. Lưu ý rằng cả BERTMap và BERTMapLt đều áp dụng thiết lập (ii) theo bản chất.
Kết quả Như thể hiện trong Bảng 1-2, chúng tôi quan sát thấy rằng Flan-T5-XXL (+ngưỡng) có được F-score tốt nhất trong số các thiết lập của nó. Trong khi nó vượt trội hơn BERTMap 0.093 về F-score trên tập con NCIT-DOID nhưng thua kém BERTMap và BERTMapLt lần lượt 0.206 và 0.049 trên tập con SNOMED-FMA (Body). Về MRR, BERTMap dẫn đầu trên cả hai tập con. Trong số các thiết lập Flan-T5-XXL, sử dụng ngưỡng tăng cường độ chính xác nhưng giảm độ phủ. Việc kết hợp ngữ cảnh cha/con không cải thiện kết quả khớp – điều này nhấn mạnh nhu cầu nghiên cứu sâu hơn về các chiến lược tận dụng ngữ cảnh ontology. GPT-3.5-turbo4 không hoạt động tốt với prompt đã cho. Một lý do có thể là xu hướng của mô hình cung cấp các giải thích mở rộng cho phản hồi của nó, khiến việc trích xuất câu trả lời có/không đơn giản trở nên thách thức. Bên cạnh đó, không có điểm số xếp hạng được trình bày cho GPT-3.5-turbo vì nó không hỗ trợ trích xuất xác suất tạo ra. Hiệu suất không tối ưu của BERTMapLt như mong đợi vì chúng tôi loại trừ các cặp khái niệm có thể được khớp chuỗi từ các bộ dữ liệu được trích xuất trong khi BERTMapLt dựa vào điểm số độ tương tự chỉnh sửa.
3Các ngưỡng được thiết lập theo kinh nghiệm là 0.650, 0.999, và 0.900 cho Flan-T5-XXL, BERTMap, và BERTMapLt trong một thí nghiệm tiên phong liên quan đến các đoạn nhỏ.

--- TRANG 5 ---
4. Kết luận và Công việc Tương lai
Nghiên cứu này trình bày một khám phá về LLMs cho OM trong thiết lập zero-shot. Kết quả trên hai tập con thách thức của các bộ dữ liệu OM cho thấy rằng việc sử dụng LLMs có thể là một hướng đi hứa hẹn cho OM nhưng cần giải quyết nhiều vấn đề khác nhau bao gồm, nhưng không giới hạn ở, thiết kế prompts và khung tổng thể5, và việc kết hợp ngữ cảnh ontology. Các nghiên cứu tương lai bao gồm tinh chỉnh các phương pháp dựa trên prompt, điều tra việc điều chỉnh few-shot hiệu quả, và khám phá các LLMs có thông tin cấu trúc. Những bài học rút ra từ các nghiên cứu OM này cũng có thể cung cấp những hiểu biết cho các tác vụ kỹ thuật ontology khác như hoàn thành và nhúng ontology, và mở đường cho một nghiên cứu rộng hơn về việc tích hợp LLMs với dữ liệu có cấu trúc.
Tài liệu tham khảo
[1] Y. He, J. Chen, D. Antonyrajah, I. Horrocks, BERTMap: A BERT-based ontology alignment system, trong: AAAI, 2022.
[2] M. Amir, M. Baruah, M. Eslamialishah, S. Ehsani, A. Bahramali, S. Naddaf-Sh, S. Zarandioon, Truveta mapper: A zero-shot ontology alignment framework, arXiv (2023).
[3] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al., Training language models to follow instructions with human feedback, trong: NeurIPS, 2022.
[4] H. W. Chung, L. Hou, S. Longpre, B. Zoph, Y. Tay, W. Fedus, E. Li, X. Wang, M. Dehghani, S. Brahma, et al., Scaling instruction-finetuned language models, arXiv (2022).
[5] Y. He, J. Chen, H. Dong, E. Jiménez-Ruiz, A. Hadian, I. Horrocks, Machine learning-friendly biomedical datasets for equivalence and subsumption ontology matching, trong: ISWC, 2022.
[6] Y. He, J. Chen, H. Dong, I. Horrocks, C. Allocca, T. Kim, B. Sapkota, Deeponto: A python package for ontology engineering with deep learning, arXiv preprint arXiv:2307.03067 (2023).
4Các thử nghiệm thí nghiệm cho text-davinci-003 và GPT-4 cũng cho thấy kết quả không tối ưu.
5Công việc này tập trung vào việc tính điểm ánh xạ, nhưng phần tìm kiếm (hoặc lựa chọn ứng viên) của OM cũng quan trọng, đặc biệt xem xét rằng LLMs có chi phí tính toán rất cao.

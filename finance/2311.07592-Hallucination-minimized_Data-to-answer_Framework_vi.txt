# Khung làm việc Dữ liệu-đến-Câu trả lời tối thiểu hóa ảo giác
# cho các nhà ra quyết định tài chính

Sohini Roychowdhury∗, Andres Alvarez∗, Brian Moore∗, Marko Krema∗, Maria Paz Gelpi†,
Federico Martín Rodríguez†, Ángel Rodríguez‡, José Ramón Cabrejas‡, Pablo Martínez Serrano‡
Punit Agrawal,§Arijit Mukherjee§
∗Văn phòng Dữ liệu và Phân tích Doanh nghiệp (CDAO), Accenture LLP, Hoa Kỳ
†CDAO, Accenture, Argentina
‡CDAO, Accenture, Tây Ban Nha
§CDAO, Accenture, Ấn Độ,
Email: sohini.roychowdhury@accenture.com

Tóm tắt—Các Mô hình Ngôn ngữ Lớn (LLM) đã được áp dụng để xây dựng một số nguyên mẫu tự động hóa và trả lời câu hỏi cá nhân hóa cho đến nay. Tuy nhiên, việc mở rộng quy mô các nguyên mẫu này thành các sản phẩm mạnh mẽ với ảo giác hoặc phản hồi giả tối thiểu vẫn là một thách thức mở, đặc biệt trong các lĩnh vực chuyên ngành nặng về bảng dữ liệu như ra quyết định tài chính. Trong công trình này, chúng tôi trình bày một khung làm việc mới dựa trên Langchain biến đổi các bảng dữ liệu thành "khối dữ liệu" văn bản có thứ bậc để cho phép nhiều loại trả lời câu hỏi có thể hành động. Đầu tiên, các truy vấn của người dùng được phân loại theo ý định, tiếp theo là việc truy xuất tự động các khối dữ liệu phù hợp nhất để tạo ra các lời nhắc LLM tùy chỉnh cho mỗi truy vấn. Tiếp theo, các lời nhắc tùy chỉnh và phản hồi của chúng trải qua chấm điểm đa chỉ số để đánh giá ảo giác và độ tin cậy phản hồi. Hệ thống đề xuất được tối ưu hóa với phân loại ý định truy vấn người dùng, lời nhắc nâng cao, khả năng mở rộng dữ liệu và đạt được hơn 90% điểm tin cậy cho nhiều phản hồi truy vấn người dùng khác nhau từ {Gì, Ở đâu, Tại sao, Như thế nào, dự đoán, xu hướng, bất thường, ngoại lệ} rất quan trọng cho các ứng dụng ra quyết định tài chính. Khung làm việc dữ liệu đến câu trả lời đề xuất có thể được mở rộng sang các lĩnh vực phân tích khác như bán hàng và bảng lương để đảm bảo các rào cản kiểm soát ảo giác tối ưu.

Từ khóa chỉ mục—ý định truy vấn người dùng, phân loại, ảo giác, mô hình ngôn ngữ lớn, đánh giá

I. GIỚI THIỆU

Lĩnh vực Trí tuệ Nhân tạo Tạo sinh (hay Gen-AI) được hỗ trợ bởi các Mô hình Ngôn ngữ Lớn (LLM) là một trong những người phá vỡ ngành công nghiệp kỹ thuật số chính của thập kỷ qua sau kỷ nguyên mạng xã hội kỹ thuật số và phát trực tuyến nội dung dựa trên web [1]. Mặc dù tên "Trí tuệ Nhân tạo Tạo sinh" xuất phát từ họ LLM được gọi là các mô hình "Biến đổi Tiền huấn luyện Tạo sinh" (GPT) được phát triển cho các nhiệm vụ tạo ngôn ngữ tự nhiên (NLG) [2], trạng thái hiện tại của Gen-AI đã phát triển cho tạo hình ảnh [3], tạo video [4], và hệ thống trả lời câu hỏi dữ liệu đa phương thức [5]. Trong khi LLM đã giảm đáng kể rào cản gia nhập AI do tính dễ sử dụng và hướng dẫn đơn giản dựa trên ngôn ngữ [6], con đường từ việc tạo nguyên mẫu các giải pháp được hỗ trợ bởi LLM đến xây dựng các sản phẩm ổn định có một số trở ngại liên quan đến độ tin cậy, khả năng lặp lại và tính khả dụng của dữ liệu [7]. Thách thức chính được xác định xung quanh tính đáng tin cậy của phản hồi LLM được gọi là ảo giác, trong đó, LLM trình bày các sự kiện và dữ liệu sai lệch như câu trả lời thực sự [8]. Hiện tượng này được phát hiện đặc biệt khó kiểm soát và gây tổn hại đặc biệt trong các lĩnh vực phân tích liên quan đến các nhiệm vụ ra quyết định dựa trên phản hồi LLM [9]. Trong công trình này, chúng tôi trình bày một khung làm việc, cơ sở hạ tầng và các mô-đun mới được phát triển để tăng cường độ tin cậy của phản hồi LLM nhằm hỗ trợ các nhà ra quyết định trong lĩnh vực tài chính.

Ảo giác chủ yếu xảy ra do các thiên vị trong dữ liệu huấn luyện LLM. Ví dụ, các phiên bản đầu của mô hình GPT-3 được huấn luyện trên 48 TB dữ liệu văn bản [10], không hiểu được phân tích số học hoặc toán học và thường xuyên mắc lỗi trong các nhiệm vụ đơn giản như tìm số lớn nhất. Kể từ đó, bộ LLM hiện tại có sẵn trên các nhà cung cấp đám mây chính đã được tinh chỉnh và sửa đổi để hiểu rõ hơn các toán tử số học. Một số ví dụ về ảo giác từ LLM GPT-3 (phiên bản kế thừa davinci-003) có sẵn trên đám mây Azure được hiển thị trong Hình 1. Ở đây, chúng ta quan sát rằng mặc dù bối cảnh có thể tùy chỉnh được cung cấp cho LLM có các thực thể được đặt tên khác nhau (như Hoa Kỳ, Châu Âu, v.v.), LLM có thể chuyển đổi các thực thể được đặt tên sai, ưu tiên các sự kiện với giá trị phần trăm thấp hoặc cao đáng kể, hoặc trình bày một câu trả lời dựa trên dữ liệu huấn luyện trước đó như được hiển thị trong ba trường hợp trả lời câu hỏi. Công trình này nhằm mục đích tối thiểu hóa những ảo giác như vậy ở cấp độ hướng dẫn bằng cách xây dựng một khung làm việc mô-đun kiểm soát và chấm điểm ảo giác ở nhiều cấp độ, do đó cho phép người dùng, hay các nhà ra quyết định tài chính, xây dựng lòng tin xung quanh phản hồi LLM.

Vì hầu hết các LLM được huấn luyện trên dữ liệu văn bản, việc xây dựng hệ thống truy vấn bối cảnh cho dữ liệu bảng lớn đặt ra ba thách thức chính. Thứ nhất, dữ liệu từ các bảng cần được chuyển đổi thành ngôn ngữ (dưới dạng khối dữ liệu) để sau đó được truy vấn và hiểu bởi LLM. Thứ hai, các thao tác toán học cần được thực hiện trong các mô-đun phân tích back-end để tạo ra dữ liệu và văn bản xung quanh các xu hướng và dự đoán có thể cần thiết cho mục đích ra quyết định tài chính. Đáng chú ý là LLM có một lớp bảo mật tích hợp cấm đưa ra dự đoán theo mặc định [11], điều này đòi hỏi bất kỳ xu hướng dự đoán hoặc bất thường nào phải được cung cấp riêng biệt cho các lời nhắc LLM để trả lời câu hỏi cụ thể theo lĩnh vực. Thứ ba, tính hợp lý và độ tin cậy của các phản hồi liên quan đến thao tác toán học cần được đánh giá về độ chính xác vì hầu hết các LLM không được huấn luyện chủ yếu trên phân tích toán học và số học. Trong công trình này, chúng tôi trình bày một khung làm việc mới dựa trên Langchain [12] với các mô-đun tùy chỉnh kiểm soát những thách thức này hướng tới một giải pháp từ đầu đến cuối tối thiểu hóa ảo giác.

Bài báo này đưa ra ba đóng góp chính dưới dạng các mô-đun kiểm soát ảo giác sau đây.

1) Mô-đun tạo văn bản từ bảng để truyền dữ liệu văn bản cho LLM. Các bảng dữ liệu lớn được chuyển đổi thành câu và lưu trữ dưới dạng khối dữ liệu được phân loại theo thứ bậc để hỗ trợ truy vấn tổng hợp. Khối dữ liệu biểu diễn các thành phần chính, phụ và xu hướng. Khối dữ liệu chính lưu trữ các giá trị bảng dữ liệu dưới dạng mẫu văn bản trong khi khối dữ liệu phụ chứa các câu với thông tin cấp tính năng, tức là tính năng nào là tối đa v.v. Khối dữ liệu xu hướng có các câu chứa thông tin dự đoán, bất thường và tương quan cho mỗi chỉ số trong bảng dữ liệu.

2) Xếp hạng khối dữ liệu và tạo lời nhắc tùy chỉnh. Các thành phần này lọc nội dung dữ liệu phù hợp nhất cho mỗi truy vấn người dùng dựa trên cơ chế tăng cường truy xuất (RAG) [13] và tạo ra một lời nhắc tùy chỉnh cho mỗi truy vấn người dùng để gửi tới LLM. Lọc khối dữ liệu theo sau bởi tìm kiếm tương tự nhúng cung cấp một khung làm việc có thể mở rộng quy mô trong đó hàng trăm nghìn khối dữ liệu có thể được khai thác và dữ liệu phù hợp nhất có thể được truy xuất cho mỗi truy vấn người dùng.

3) Mô-đun Chấm điểm Chất lượng Trực tiếp. Thành phần mới này phân tích mỗi lời nhắc tùy chỉnh, phản hồi LLM được trả về và đánh giá phản hồi về bối cảnh câu hỏi, ảo giác số học, tính độc đáo từ lời nhắc, và tính hợp lý phản hồi theo 6 điểm chất lượng nhị phân. Các chỉ số chấm điểm chất lượng này tiếp tục phân loại mỗi phản hồi LLM thành {Thấp/Trung bình/Cao} độ tin cậy.

Khung làm việc đề xuất đạt được điểm tin cậy phản hồi nhất quán khoảng 90% trở lên với các tiến bộ lời nhắc lặp lại và triển khai phiên bản.

Sơ đồ hệ thống tổng thể được hiển thị trong Hình 2. Khung làm việc đề xuất bao gồm hai quy trình riêng biệt, cụ thể là quy trình ngoại tuyến và trực tuyến. Quy trình ngoại tuyến bao gồm việc chuyển đổi bảng thành các mô-đun tạo văn bản, trong khi quy trình trực tiếp bao gồm tạo lời nhắc tùy chỉnh theo sau bởi chấm điểm phản hồi LLM cho mỗi truy vấn người dùng.

II. CÔNG TRÌNH TRƯỚC ĐÂY VỀ MÔ HÌNH NGÔN NGỮ

Một số mô hình ngôn ngữ đã được phát triển và phân tích trong những thập kỷ qua để cho phép các nhiệm vụ hiểu ngôn ngữ tự nhiên (NLU) và tạo ngôn ngữ tự nhiên (NLG) [14]. Tất cả các công trình hiện có có thể được phân loại rộng rãi thành các mô hình chỉ mã hóa cho phép hiểu ngôn ngữ con người ở cấp độ máy, các mô hình mã hóa-giải mã cho phép NLU và NLG kết hợp để xử lý ngôn ngữ con người và tạo ra các kết quả mong muốn như tóm tắt hoặc diễn giải từ ngữ v.v. và các mô hình chỉ giải mã như LLM. Một số mốc quan trọng của mô hình ngôn ngữ trong mỗi danh mục được hiển thị trong Bảng I.

Thế hệ hiện tại của LLM chỉ giải mã với hàng tỷ đến hàng nghìn tỷ tham số có khả năng duy trì cuộc trò chuyện trong khi trình bày các sự kiện theo ngữ cảnh như chatGPT [27] có một số mốc phát triển riêng biệt [28]. Mô hình GPT-1 được giới thiệu vào tháng 6 năm 2018 [23] là thế hệ đầu tiên của các mô hình Biến đổi Tiền huấn luyện Tạo sinh và nó bao gồm 117 triệu tham số, do đó thiết lập kiến trúc nền tảng cho ChatGPT ngày nay [27]. Mô hình GPT-1 đã chứng minh khả năng hiểu ngôn ngữ và tạo văn bản bằng cách sử dụng sách làm dữ liệu huấn luyện để dự đoán từ tiếp theo trong câu. Mô hình GPT-2 [29] được phát triển vào tháng 2 năm 2019, đại diện cho một bước nâng cấp đáng kể với 1,5 tỷ tham số và cải tiến đáng kể trong khả năng tạo văn bản bằng cách sản xuất văn bản mạch lạc và nhiều đoạn văn. Tuy nhiên, lo ngại về tạo văn bản không ổn định và khả năng lạm dụng đã ngăn GPT-2 được phát hành công khai vào đầu năm 2019. Mô hình GPT-2 cuối cùng đã được phát hành vào tháng 11 năm 2019 sau khi OpenAI tiến hành triển khai theo giai đoạn để nghiên cứu và giảm thiểu các rủi ro tiềm ẩn. Triển khai phiên bản tiếp theo của GPT-3 [30] là một cải tiến lớn với 176 tỷ tham số, được ra mắt vào tháng 11 năm 2022 bởi OpenAI với các rào cản an toàn chống lại việc trả lời câu hỏi với ý định độc hại [30]. Mô hình GPT-3 có khả năng tạo văn bản vượt trội hơn nhiều so với tất cả các mô hình hiện có khác vào thời điểm đó, dẫn đến việc sử dụng rộng rãi trong nhiều ứng dụng tự động hóa và trả lời câu hỏi như soạn thảo email, viết bài báo đến tạo thơ và thậm chí sửa mã lập trình do con người viết [28]. GPT-3 cũng đã chứng minh khả năng trả lời câu hỏi thực tế và dịch giữa các ngôn ngữ. Ngoài ra, nền tảng OpenAI đã cung cấp cho người dùng cơ hội tương tác với mô hình GPT-3 thông qua môi trường giống như trò chuyện (chatGPT) miễn phí để nâng cao khả năng trả lời câu hỏi của mô hình. Các cải tiến cho nền tảng chatGPT với GPT3.5 và GPT-4 [27] đã tiếp tục cho phép các nguyên mẫu và giải pháp tự động hóa được phát triển với LLM. Một số LLM nền tảng nổi tiếng hiện đang được áp dụng để xây dựng các sản phẩm tự động hóa và trả lời câu hỏi được trình bày trong Bảng II.

Ngoài các LLM trong Bảng II, một số LLM đáng chú ý khác bao gồm Galactica được Meta ra mắt vào năm 2022 và được huấn luyện trên 48 triệu tạp chí và bài báo học thuật [38]. Khuyết điểm chính của nó là các ảo giác khó phát hiện vì ngôn ngữ trong các bài báo nghiên cứu nó được huấn luyện từ có tính chất uy quyền. Trong khi hầu hết các LLM cực kỳ lớn để cung cấp suy luận trên một laptop hoặc hệ thống duy nhất, có một số phiên bản LLM nhẹ hơn chạy trên hệ thống đơn lẻ như Orca của Microsoft [39] chứa 13B tham số và được xây dựng trên Llama. Đáng chú ý là các phiên bản LLM nhẹ hơn (với vài triệu tham số) được đặc trưng bởi khả năng bộ nhớ và lý luận hạn chế. Trong công trình này, chúng tôi xây dựng một khung làm việc bất khả tri LLM trong đó bất kỳ mô hình nào từ Bảng II đều có thể được áp dụng để tạo ra phản hồi đáng tin cậy và đáng tin cậy trên các tập dữ liệu bảng lớn.

III. VẬT LIỆU VÀ PHƯƠNG PHÁP

Các lĩnh vực phân tích như tài chính, liên quan đến khối lượng lớn dữ liệu bảng cần được truy cập và trả về cho người dùng trong khi tuân theo các quy tắc kinh doanh cụ thể. Do đó, nguồn của chatbot Tài chính của chúng tôi là các bảng dữ liệu có thể được tải trước thông qua BigQuery. Là bước đầu tiên trong quy trình ngoại tuyến, một số khối dữ liệu ngôn ngữ được tạo ra cho mỗi mục nhập bản ghi bảng trong khi duy trì các thứ bậc dữ liệu được xác định trước như phân chia địa lý ở cấp bang và quốc gia. Các khối dữ liệu này đại diện cho ba loại thông tin chính. Khối dữ liệu chính đầu tiên đại diện cho việc đọc đơn giản dữ liệu bảng. Khối dữ liệu cấp tính năng thứ hai đại diện cho các thao tác cấp tính năng như giá trị tối thiểu và tối đa cho mỗi chỉ số. Khối dữ liệu xu hướng thứ ba đại diện cho các bất thường, ngoại lệ và dự đoán được trả về bởi các mô-đun phân tích có thể được chạy ngoại tuyến trên dữ liệu. Các khối dữ liệu này loại bỏ gánh nặng của các thao tác toán học và khả năng ảo giác từ LLM. Đáng chú ý là mỗi khối dữ liệu chứa 2-10 câu văn bản dựa trên các quy tắc kinh doanh. Kích thước tối ưu của khối dữ liệu này đảm bảo tạo ngữ cảnh đầy đủ cho nhiều truy vấn sử dụng khác nhau. Tất cả các khối dữ liệu đều được nhúng vector hóa bằng Ada002 [40] hoặc nhúng BERT [15]. Khung làm việc mới trong công trình này nhằm mục đích tối thiểu hóa các thách thức mở rộng giải pháp xuất hiện khi số lượng khối dữ liệu tăng lên hơn một triệu bản ghi về kích thước.

Thành phần chính tiếp theo cho quy trình ngoại tuyến chatbot Tài chính trong Hình 2 là các mẫu lời nhắc chứa hướng dẫn tương ứng với mỗi danh mục câu hỏi người dùng (hoặc ý định). Các danh mục câu hỏi bao gồm: "Gì", "Tại sao", "Như thế nào", "Cái nào", "So sánh", "Tóm tắt", "Nếu như", "xu hướng/bất thường/ngoại lệ" v.v. Trong quy trình trực tiếp của chatbot, đối với mỗi truy vấn người dùng, một bộ phân loại ý định phân loại phiên bản nhúng của truy vấn người dùng thành một trong các danh mục ý định hiện có (phân loại một so với tất cả). Dựa trên danh mục ý định được phân loại này, mẫu lời nhắc tương ứng được điền với các khối dữ liệu phù hợp theo sau bởi chấm điểm phản hồi được trả về bởi LLM về độ chính xác thực tế và theo ngữ cảnh. Các ký hiệu và mô tả của các mô-đun trong quy trình ngoại tuyến và trực tiếp để tạo ra lời nhắc tùy chỉnh cho mỗi truy vấn người dùng được mô tả trong các tiểu mục sau.

A. Ký hiệu

Truy vấn người dùng thứ i (Qi) là sự kết hợp của danh mục ý định câu hỏi (Ii) và thực thể được đặt tên (QNi) sao cho các thực thể được đặt tên có thể được phân loại thành chỉ số tài chính (QMk), vị trí địa lý (QG'k) và thời gian (QT''k) như được hiển thị trong (1-2). Tập hợp hoàn chỉnh các khối dữ liệu văn bản (C) chứa các khối dữ liệu chính, cấp tính năng và xu hướng sao cho các khối dữ liệu phù hợp nhất được lọc và khớp với mỗi truy vấn người dùng được biểu thị bởi ci và copt,i, tương ứng. Lời nhắc tùy chỉnh (Pi) được tạo ra cho mỗi truy vấn người dùng chứa mẫu lời nhắc tương ứng với danh mục ý định (Ψi), các định nghĩa tùy chỉnh liên quan (di), và khối dữ liệu tối ưu (copt,i) trong (3). Cuối cùng, mỗi phản hồi LLM (Ri) được đánh giá về chỉ số tài chính (RMk), vị trí địa lý (RG'k) và thời gian (RT''k) trong nội dung của nó để trả về điểm chất lượng S={si,1....si,6} trong (4) cho người dùng đánh giá mức độ tin cậy trong mỗi phản hồi.

Qi=Ii∪QNi,(1)
QNi=∪k,k′,k′′{QMk, QG'k, QT''k},(2)
Pi=∪{Ψi, di, copt,i},(3)
S=Score(Ri,{QMk, QG'k, QT''k},{RMk, RG'k, RT''k}).(4)

B. Mô-đun Xếp hạng Khối dữ liệu

Mục tiêu của mô-đun này là ngăn LLM bị choáng ngợp bởi lượng dữ liệu khổng lồ, và do đó gặp lỗi giới hạn token. Mô-đun này có ba bước để sửa lỗi gõ, sau đó lọc các khối dữ liệu theo từ khóa dựa trên truy vấn Qi tiếp theo bởi việc chọn các khối dữ liệu tương tự nhất với truy vấn. Các bước này được thúc đẩy bởi phương pháp RAG cho LLM trong [13] và được mô tả dưới đây.

1) Trong bước đầu tiên, một trình kiểm tra chính tả dựa trên khoảng cách Levenstein được áp dụng cho truy vấn người dùng để chống lại lỗi gõ thủ công. Tiếp theo, một từ điển từ khóa tinh vi được sử dụng để lọc các khối dữ liệu chứa chỉ số tài chính, vị trí địa lý và thời gian có liên quan (như ci). Từ điển từ khóa này chứa chi tiết về các chỉ số tài chính, vị trí địa lý và mối liên hệ và thứ bậc thời gian.

2) Trong bước thứ hai, nhiều tìm kiếm được khởi động để xác định các khối dữ liệu với các thực thể được đặt tên (QNi) trong khi đảm bảo tính toàn vẹn dữ liệu quan hệ và thứ bậc.

3) Trong bước thứ ba, phiên bản nhúng của câu hỏi (Ada(Qi)) được kết hợp với các khối dữ liệu được lọc để xác định các khối dữ liệu được lọc với độ tương tự cosine cao nhất [28]. Lên đến 20 khối dữ liệu khớp hàng đầu được trả về để tùy chỉnh lời nhắc cho mỗi truy vấn người dùng. Giới hạn khối này là 20 được đặt theo kinh nghiệm dựa trên giới hạn token là 4096 cho mô hình Azure GPT-3 và có thể tăng khi giới hạn token LLM phát triển. Đáng chú ý là logic/quy tắc kinh doanh trong bước đầu tiên được tinh chỉnh để đảm bảo ít nhất một khối dữ liệu được khớp với mỗi truy vấn. Trong trường hợp không có đủ khối dữ liệu, LLM có xu hướng ảo giác và phản hồi từ dữ liệu được huấn luyện trước như được hiển thị trong trường hợp 3 của Hình 1.

C. Tạo Lời nhắc Tùy chỉnh

Mô-đun này chuyển đổi một truy vấn người dùng đơn giản thành một truy vấn tùy chỉnh với tất cả các định nghĩa và dữ liệu liên quan để trả lời câu hỏi với ảo giác tối thiểu. Đối với chatbot Tài chính của chúng tôi, các mẫu lời nhắc riêng lẻ tương ứng với mỗi ý định câu hỏi bao gồm các thành phần sau: giới thiệu, lời mở đầu, bối cảnh khớp, hướng dẫn và một vài câu hỏi ví dụ cùng câu trả lời của chúng. Chi tiết của mỗi thành phần lời nhắc được giải thích như sau.

1) Giới thiệu Lời nhắc: Phần này thiết lập persona cho phản hồi LLM và thiết lập các hướng dẫn cơ bản cho LLM để hiểu các định nghĩa chính và các bước LLM phải tuân theo để trả lời câu hỏi. Phần này giải thích luồng thông tin trong lời nhắc cho LLM và cần những sửa đổi đáng kể khi chuyển đổi giữa các loại LLM.

2) Lời mở đầu Lời nhắc: Phần này hướng dẫn LLM thông qua thuật ngữ cụ thể theo lĩnh vực độc đáo cho trường hợp sử dụng. Trong khi có thể có một số định nghĩa tùy chỉnh (D), chỉ các định nghĩa liên quan đến các thực thể được đặt tên trong truy vấn người dùng được sử dụng mỗi lần (di). Đối với các lĩnh vực chuyên ngành như Tài chính, thường có nhiều từ viết tắt như 'PPP' có thể là viết tắt của 'Profit Per Period'. Định nghĩa này rất quan trọng để trích xuất đúng bối cảnh từ các khối dữ liệu. Do đó, phần này giới thiệu tất cả các định nghĩa cần thiết và mối liên hệ dữ liệu và thứ bậc cần thiết để trích xuất bối cảnh cần thiết từ các khối dữ liệu.

Như một ví dụ, chúng tôi tạo ra một lời nhắc tùy chỉnh cho truy vấn người dùng: 'Ở đâu trong Châu Âu có tăng trưởng GDP cao nhất trong năm tài chính 2023?' Quy trình bắt đầu bằng việc thu thập các khối dữ liệu liên quan nhất dựa trên Phần III-B. Tiếp theo, ý định và các thực thể được đặt tên được xác định là 'GDP' và 'Châu Âu' từ câu hỏi. Lời mở đầu bao gồm các chi tiết quan hệ đề cập rằng các quốc gia như 'Đức', 'Pháp' và 'Anh' thuộc về 'Châu Âu' và do đó các khối dữ liệu từ những quốc gia này có liên quan. Do đó, tên quốc gia/từ khóa được ánh xạ một cách thông minh với các thực thể được đặt tên gốc trong truy vấn người dùng thông qua kho lời mở đầu. Trong khi thành phần lời mở đầu cấu trúc nằm bên cạnh phần giới thiệu trong lời nhắc, đó là thành phần cuối cùng được thực hiện bởi đường ống tạo lời nhắc tùy chỉnh. Điều này là do yêu cầu độc đáo của nó là có cả truy vấn người dùng và dữ liệu ngữ cảnh trước khi tạo ra các kết nối được quy định bởi logic kinh doanh cụ thể cho trường hợp sử dụng. Do đó, phần lời mở đầu tối đa hóa khả năng nhắc nhở trong các lĩnh vực nặng về định nghĩa tùy chỉnh và biệt ngữ.

3) Bối cảnh Lời nhắc: Thành phần này kết hợp tất cả các khối dữ liệu khớp và tạo ra bối cảnh tổng thể cho LLM truy cập trong khi xây dựng phản hồi. Đáng chú ý là việc cung cấp nhiều khối dữ liệu cho LLM ít có hại hơn so với cung cấp ít khối dữ liệu, vì LLM thường có khả năng phân biệt giữa các câu với các thực thể được đặt tên cụ thể. Ví dụ, nếu truy vấn người dùng là: "Những quốc gia nào ở Châu Á có tăng trưởng GDP dưới mức trung bình trong năm tài chính 2023?", thì một số khối dữ liệu với tên quốc gia Châu Á và GDP của họ so với GDP trung bình Châu Á được trả về và LLM chọn các câu có GDP thấp hơn trung bình Châu Á và diễn giải phản hồi. Trong kịch bản này, việc truyền ít khối dữ liệu có thể dẫn đến ảo giác do thiên vị huấn luyện LLM.

4) Hướng dẫn Lời nhắc: Thành phần này truyền đạt hướng dẫn từng bước về cách LLM nên xây dựng phản hồi của mình, trong khi điều chỉnh theo danh mục ý định câu hỏi độc đáo. Các bước này dựa trên khung làm việc Langchain mã nguồn mở trong [12]. Ví dụ, việc tìm câu trả lời cho một truy vấn người dùng đơn giản như: "Tăng trưởng ở Hoa Kỳ trong quý 3 năm tài chính 2023 là gì?" sẽ yêu cầu ít bước hơn so với truy vấn người dùng: "Tại sao tăng trưởng ở Hoa Kỳ chậm lại quý trước?" hoặc truy vấn "Làm thế nào để cải thiện tăng trưởng ở Hoa Kỳ trong quý 1 năm tài chính 2024?". Đối với các truy vấn "Gì/ở đâu" đơn giản, mục tiêu là tìm các câu phù hợp nhất và diễn giải chúng, trong khi đối với các câu hỏi "Tại sao/Như thế nào?" phức tạp hơn, các hướng dẫn được quy định bởi logic kinh doanh và mối quan hệ dữ liệu cần được đặt ra cho LLM để trích xuất bối cảnh phù hợp nhất và tóm tắt và diễn giải chúng. Đáng chú ý là mỗi mẫu lời nhắc cụ thể theo ý định chứa các hướng dẫn tuần tự, thuật toán cùng với hướng dẫn xử lý cho điều kiện giới hạn (khi quá ít hoặc quá nhiều khối dữ liệu được trả về) để trả về phản hồi mạch lạc và phù hợp theo ngữ cảnh.

5) Ví dụ và Câu hỏi Lời nhắc: Thành phần cuối cùng này đại diện cho định dạng chính xác của phản hồi mong muốn. Ví dụ, các mô hình GPT (GPT3/3.5) có xu hướng tạo ra phản hồi theo định dạng đoạn văn. Tùy thuộc vào giao diện người dùng và khối lượng hiểu thông tin, định dạng đoạn văn có thể không phải lúc nào cũng là phản hồi mong muốn. Do đó, đối với chatbot Tài chính, việc chỉ định định dạng điểm đầu dòng cho phản hồi là một thông lệ tốt. Ngoài ra, câu hỏi mẫu và phản hồi của nó có thể được sử dụng như một cơ chế hướng dẫn để bao gồm các nguồn và liên kết liên quan trong phản hồi. Một lưu ý chính khi tạo ra phân đoạn này là một ví dụ mẫu không cần phải là một ví dụ chính xác và câu trả lời trực tiếp của nó, nhưng nó có thể là một chuỗi các câu hỏi và câu trả lời chiến lược hỗ trợ diễn giải các truy vấn người dùng trừu tượng trong khi trả lời một phổ câu hỏi rộng theo định dạng quy định.

Quy trình tổng thể của tạo lời nhắc tùy chỉnh (Pi) cho mỗi truy vấn người dùng Qi có thể được tóm tắt trong Thuật toán 1.

Thuật toán 1: Tạo Lời nhắc Tùy chỉnh
Đầu ra: Lời nhắc Tùy chỉnh Pi
Đầu vào: Truy vấn Qi=Ii∪QNi
Khởi tạo;
Ii←phân-loại-ý-định(Qi),Ii∈[0,1,2,...l]
Ψi←Mẫu-lời-nhắc(Ii)
EQi←Nhúng-Ada(Qi)
kích-thước(copt,i)=0
trong khi kích-thước(copt,i)<20 thì
ci←Lọc-khối-dữ-liệu(C,QNi)
copt,i←copt,i∪arg max(EQi, Nhúng-Ada(ci))
kết thúc
di←Lọc(D,QNi)
Pi=∪{Ψi,di,copt,i}

D. Động cơ Chấm điểm

Tất cả các mô-đun trước đó được mô tả ở trên nhằm mục đích tối thiểu hóa ảo giác LLM trước khi nhận phản hồi LLM. Tuy nhiên, dựa trên tính trừu tượng của truy vấn người dùng và hạn chế trong các khối dữ liệu, ảo giác vẫn có thể xảy ra và chúng phải được phát hiện và báo cáo cho người dùng cùng với phản hồi LLM. Để đo lường chất lượng của mỗi phản hồi LLM, chúng tôi đề xuất một mô-đun chấm điểm mới nhẹ sử dụng 'thư viện-nltk' trong đó nội dung của mỗi phản hồi được chấm điểm bằng 6 chỉ số nhị phân được mô tả dưới đây.

1) Chỉ số liên tục câu hỏi-trả lời (si,1): Chỉ số nhị phân này phân tích các thực thể được đặt tên trong cả văn bản câu hỏi (QNi) và phản hồi (RNi). Dựa trên chỉ số này, chúng ta có thể suy ra nếu phản hồi giải quyết truy vấn người dùng hay nếu LLM đã ảo giác và đi chệch hướng. Ví dụ, nếu truy vấn người dùng là về "số liệu chi phí hàng quý", và LLM phản hồi với chi tiết về "số liệu hàng năm", thì chỉ số này là 0 như được hiển thị trong (5).

2) Chỉ số ảo giác số học (si,2): Khi mô hình trả về phản hồi, việc xác thực rằng các số trong phản hồi tồn tại trong phần bối cảnh của lời nhắc tùy chỉnh là rất quan trọng. Nếu không, rất có thể các sự kiện và con số là ảo giác bịa đặt. Ví dụ, nếu phản hồi LLM bao gồm: "Chỉ số ZZ đã tăng X.X%", thì giá trị X.X% phải được bao gồm trong bối cảnh lời nhắc. Chỉ số nhị phân này được đặt thành 1 nếu tất cả các số trong phản hồi là tập con của các số trong bối cảnh lời nhắc như được hiển thị trong (6).

3) Chỉ số độc đáo từ lời nhắc (si,3): Chỉ số nhị phân này xác định nếu một chuỗi liên tiếp δ từ là giống nhau trong phản hồi và lời nhắc. Chỉ số này đánh giá khả năng diễn giải của LLM để trả lời các truy vấn người dùng trừu tượng và phức tạp. Chỉ số này được đặt thành 1 nếu không có chuỗi 10-12 từ liên tiếp trong phản hồi khớp với lời nhắc tùy chỉnh như được hiển thị trong (7).

4) Chỉ số hợp lý số học (si,4): Chỉ số nhị phân này kiểm tra các khuyết điểm ngữ pháp trong các câu liên quan đến phân tích số học. Ví dụ, nếu câu phản hồi thứ α (Ri,α) chứa từ "tăng/đang tăng", câu này không nên kèm theo số hoặc phần trăm âm. Các xu hướng số và văn bản tương tự được phân tích cho mỗi câu phản hồi. Chỉ số này được đặt thành 1 chỉ khi tất cả các câu phản hồi đều hợp lý về ngữ pháp như trong (8).

5) Chỉ số cảnh báo bối cảnh (si,5): Chỉ số cảnh báo này phát hiện nếu bối cảnh dễ truy cập hay không. Trong các tình huống mà nhiều khối dữ liệu có kích thước khác nhau và các chỉ số tài chính khác nhau được kết hợp để tạo ra bối cảnh tổng hợp, chỉ số này được đặt thành 1. Chỉ số này hữu ích trong các tình huống mà người dùng không chấp nhận phản hồi LLM, trong đó chỉ số này có thể chỉ ra các khối dữ liệu sai lầm được kéo vào lời nhắc tùy chỉnh.

6) Chỉ số liên tục theo ngữ cảnh (si,6): Chỉ số này phân tích mỗi câu phản hồi (Ri,α) và xác minh nếu bối cảnh (hoặc các thực thể được đặt tên) khớp với những gì trong các khối dữ liệu của lời nhắc (copt,i(Ni,α)). Ví dụ, nếu phản hồi LLM chứa, "lợi nhuận đã tăng Y.Y% tại thị trường 1", nhưng các khối dữ liệu lời nhắc chứa câu "Trong quý TT, lợi nhuận đã tăng Y.Y% tại thị trường 2", thì chỉ số này được đặt thành 0 như được hiển thị trong (9).

si,1=1 nếu QNi==RNi
0 nếu ngược lại
,(5)

si,2=1 nếu số(Ri)⊂số(copt,i)
0 nếu ngược lại
,(6)

si,3=1 nếu seqδ(Pi)∩seqδ(Ri) == ϕ
0 nếu ngược lại
,(7)

si,4=1 "tích cực"∈Ri,α, số(Ri,α)>0
1 "tiêu cực"∈Ri,α, số(Ri,α)<0
0 nếu ngược lại
,(8)

si,6=1 RNi,α==copt,i(Ni,α)
0 nếu ngược lại
. (9)

Cuối cùng, dựa trên điểm phản hồi, một độ tin cậy được liên kết với mỗi phản hồi LLM và trả về cho người dùng dưới dạng {Cao, Trung bình, Thấp} như được hiển thị trong (10). Đáng chú ý là điểm tin cậy phản hồi hỗ trợ người dùng bằng cách nói với họ rằng LLM đã hiểu hoặc hoàn toàn không hiểu được truy vấn người dùng. Phản hồi tin cậy thấp thường liên quan đến các truy vấn người dùng mở hoặc trừu tượng, khối dữ liệu không đầy đủ, phân loại ý định câu hỏi sai và ảo giác. Điểm tin cậy nói với người dùng khẳng định thận trọng khi đưa ra quyết định quan trọng sử dụng phản hồi tin cậy trung bình đến thấp. Điểm tin cậy tiếp tục giúp xác định những truy vấn người dùng nào cần được tinh chỉnh thêm để có độ tin cậy.

Tin cậy(Ri) = Cao nếu ∑jsi,j>= 5
Trung bình nếu 4>=∑jsi,j>= 3
Thấp nếu ngược lại
(10)

E. Kiến trúc Hệ thống cho chatbot Tài chính

Các khác biệt chính giữa nguyên mẫu LLM và sản phẩm bao gồm như sau: khả năng mở rộng trong cơ sở hạ tầng với khối dữ liệu ngày càng tăng, tính mạnh mẽ đối với các biến đổi trong truy vấn người dùng, sự tươi mới của dữ liệu, lo ngại bảo mật và cải tiến liên tục dựa trên phản hồi của con người. Do đó, các cân nhắc sau đây cần thiết để thiết kế chatbot Tài chính ở cấp độ Doanh nghiệp.

• Các bảng dữ liệu phải được làm mới dựa trên hướng dẫn cấp Doanh nghiệp để đảm bảo phản hồi LLM đáng tin cậy.

• Bảo mật và ràng buộc truy cập ở cấp người dùng cần được triển khai ở cấp lưu trữ khối dữ liệu.

• Ít cuộc gọi LLM hơn cho mỗi truy vấn người dùng có thể ngăn chặn ảo giác trong khi đảm bảo thời gian phản hồi nhanh. Tuy nhiên, nhiều cuộc gọi LLM cho mỗi truy vấn người dùng để phân loại ý định truy vấn người dùng, để trích xuất các thực thể được đặt tên hoặc khớp các khối dữ liệu tốt nhất có thể nâng cao hiệu suất phản hồi cho các truy vấn người dùng chưa thấy và trừu tượng trước đó.

• Tạo lời nhắc tùy chỉnh với các khối dữ liệu khớp tốt nhất là một cách triển khai RAG [13] để trích xuất phản hồi tùy chỉnh bằng cách nền tảng. Tuy nhiên, thông tin dựa trên lịch sử người dùng bổ sung có thể tiếp tục nâng cao trải nghiệm trả lời câu hỏi ở cấp độ cá nhân hóa.

• Xây dựng chatbot cho các nhà ra quyết định dựa trên tài chính bao gồm tạo phản hồi đáng tin cậy và có thể lặp lại từ LLM cùng với điểm phản hồi hướng dẫn người dùng/nhà ra quyết định.

• Thu thập phản hồi là một phần không thể thiếu của đường ống sản phẩm để đảm bảo rằng phản hồi tin cậy "thấp" được ghi lại liên tục và cải thiện dựa trên logic kinh doanh.

Để đảm bảo một sản phẩm có thể mở rộng và sử dụng được, kiến trúc hệ thống trong Hình 2 có thể được mở rộng thêm để hoạt động như một đại lý trò chuyện như được hiển thị trong Hình 3. Điều này có thể đạt được bằng cách bao gồm luồng trò chuyện trong đầu vào của dịch vụ quy trình trực tiếp được khởi tạo khi mỗi truy vấn người dùng được nhập. Truyền thông tin tiếp tục trò chuyện đến lời nhắc tùy chỉnh cho phép trả lời câu hỏi tiếp theo sử dụng các khối dữ liệu đã chọn trước đó. Điều này tạo ra một luồng trò chuyện được cập nhật liên tục với mỗi lời nhắc LLM và các phản hồi được trả về. Thiết kế này cho phép ứng dụng gọi bên ngoài điều phối cuộc trò chuyện với các truy vấn tiếp theo.

Một cân nhắc thiết kế khác cho chatbot cá nhân hóa có thể mở rộng là các chức năng Trích xuất, Biến đổi và Tải dữ liệu (ETL) [41] để tạo ra các khối dữ liệu theo sau mỗi lần làm mới dữ liệu. Quy trình ngoại tuyến này có thể được sửa đổi thêm để cho phép tạo khối dữ liệu gần như thời gian thực, bằng cách kết hợp một hệ thống xuất bản/đăng ký không đồng bộ trong đó các thay đổi dữ liệu nguồn được xuất bản, và hệ thống tạo khối dữ liệu đăng ký những thay đổi này để tạo ra các khối dữ liệu cập nhật mới [42]. Một số lựa chọn thay thế hiện có cho cơ chế xếp hạng khối dữ liệu là ElasticSearch, Apache Solr hoặc Lucene [43].

Một cân nhắc chính cho việc mở rộng chatbot Tài chính như một dịch vụ là mở rộng ngang để hỗ trợ người dùng đồng thời bằng cách chạy các phiên bản dịch vụ song song. Ở đây, chúng tôi giả định rằng các dịch vụ phân loại ý định truy vấn người dùng và tạo lời nhắc tùy chỉnh cũng mở rộng song song. Khi dữ liệu tăng lên, nút thắt chính là thời gian cần thiết để khớp từ khóa trong khi xếp hạng các khối dữ liệu khớp tốt nhất. Từ góc độ nền tảng, nếu quy trình khớp từ khóa được thiết kế xung quanh cơ sở dữ liệu SQL, thì việc lập chỉ mục phải được cải thiện để duy trì thời gian phản hồi nhanh (<3 giây mỗi câu hỏi). Tuy nhiên, đối với lượng dữ liệu cực lớn (như vài trăm nghìn đến một triệu khối dữ liệu) cần xem xét việc phân đoạn cơ sở dữ liệu (ngang) [44] trong đó, việc truy cập vào các khối dữ liệu được định tuyến lại dựa trên một chỉ số hoặc chiều. Thời gian xử lý ETL có thể là nút thắt thứ hai trong những tình huống như vậy với khối dữ liệu ngày càng tăng. Bằng cách cập nhật từ ETL theo lô sang quy trình tạo khối dữ liệu gần như thời gian thực như được mô tả ở trên, thời gian xử lý truy vấn tổng thể có thể được ổn định hơn.

Cuối cùng, chúng ta có thể so sánh kiến trúc chatbot Tài chính được đề xuất trong Hình 3 với kiến trúc RAG phổ biến hơn trong [13] để trả lời câu hỏi dựa trên dữ liệu phi cấu trúc liên quan đến lĩnh vực. Ví dụ, nếu chúng ta phải mở rộng chatbot Tài chính để học từ tóm tắt cuộc gọi họp tài chính và biên bản họp, thì việc mở rộng kiến trúc sau đây là cần thiết. Đầu tiên, sự khác biệt chính trong kịch bản như vậy là thay vì khớp câu hỏi với các khối dữ liệu sử dụng từ khóa theo sau bởi lọc và xếp hạng các khối dữ liệu để tạo lời nhắc có thể tùy chỉnh, chúng ta dựa vào tương tự ngữ nghĩa (của các nhúng Ada002 [40]) giữa câu hỏi và các đoạn văn bản để lọc và xếp hạng. Những cân nhắc tương tự cho việc mở rộng như đã thảo luận ở trên vẫn giữ nguyên. Tuy nhiên, việc phân đoạn cơ sở dữ liệu vector có thể yêu cầu một sự tách biệt giữa các chủ đề cho các tập dữ liệu phi cấu trúc như vậy, thay vì sử dụng các chiều bảng có cấu trúc. Do đó, các cân nhắc mở rộng cơ sở hạ tầng được thảo luận ở đây có thể được áp dụng cho các tập dữ liệu có cấu trúc và phi cấu trúc.

IV. THỰC NGHIỆM VÀ KẾT QUẢ

Trong công trình này, chúng tôi thực hiện 4 thực nghiệm chính để đảm bảo độ tin cậy, khả năng lặp lại và phản hồi đáng tin cậy từ chatbot Tài chính Dữ liệu-đến-câu trả lời của chúng tôi. Đầu tiên, chúng tôi đánh giá các thực hành tốt nhất để tạo lời nhắc tùy chỉnh cần thiết để tối thiểu hóa ảo giác trong khi bất khả tri LLM. Thứ hai, chúng tôi đánh giá điểm chất lượng phản hồi LLM GPT-3/GPT3.5 trên một loạt hơn 350.000 truy vấn người dùng được tuyển chọn. Thứ ba, chúng tôi đánh giá tầm quan trọng của phân loại ý định truy vấn người dùng sử dụng lời nhắc LLM riêng biệt trái ngược với bộ phân loại tiền huấn luyện tiêu chuẩn. Cuối cùng, chúng tôi đánh giá các biến đổi hiệu suất phản hồi trên nhiều LLM khác nhau cho mục đích đánh giá.

A. Kỹ thuật Lời nhắc để tối thiểu hóa Ảo giác

Các thực hành tốt nhất cho kỹ thuật lời nhắc nâng cao để kiểm soát các điều kiện góc và đảm bảo phản hồi đáng tin cậy và có thể lặp lại được thảo luận dưới đây:

1) Rào cản ảo giác: Sử dụng văn bản cụ thể trong phần giới thiệu và lời mở đầu của lời nhắc hướng dẫn LLM kiềm chế tạo ra phản hồi khi không chắc chắn, hoặc khi thiếu dữ liệu ngữ cảnh.

2) Lời nhắc tùy chỉnh mô-đun: Tạo ra lời nhắc mô-đun cho phép khả năng thích ứng với ý định truy vấn người dùng mới, khả năng tái sử dụng mẫu lời nhắc và khả năng mở rộng cho các truy vấn người dùng trừu tượng.

3) Tùy chỉnh khi cần thiết: Điều chỉnh lời nhắc để phù hợp với yêu cầu cụ thể của nhiệm vụ hoặc truy vấn là rất quan trọng để đạt được phản hồi mạch lạc và đáng tin cậy. Tùy chỉnh cho phép phù hợp với logic kinh doanh và mối quan hệ dữ liệu khi cần thiết cho ý định truy vấn cụ thể như giải thích tình huống "Tại sao?".

4) Hướng dẫn chi tiết: Bất kỳ lời nhắc tùy chỉnh nào phải chi tiết nhất với các bước và hướng dẫn dễ theo dõi. Hướng dẫn từng bước cho phép gỡ lỗi và khắc phục sự cố để tối thiểu hóa ảo giác. Tuy nhiên, hướng dẫn không nên là những câu quá dài trong trường hợp đó giới hạn token LLM có thể được kích hoạt.

5) Lời nhắc nâng cao: Hướng dẫn lời nhắc nên cho phép xử lý cho điều kiện giới hạn, ví dụ khi ít khối dữ liệu hoặc bối cảnh ngắn có sẵn, phản hồi chỉ phải trả lời từ bối cảnh hoặc trả về "Tôi không thể trả lời câu hỏi." Ngoài ra, trong các kịch bản khi các truy vấn người dùng trừu tượng với nhiều diễn giải, hướng dẫn rõ ràng phải được cung cấp để phản hồi với văn bản cảnh báo. Ví dụ, nếu truy vấn người dùng hỏi về "GDP ở các bang đông bắc Hoa Kỳ" trong khi bối cảnh chỉ chứa dữ liệu tổng hợp Hoa Kỳ, LLM phải được nhắc phản hồi với văn bản như "Xin lỗi, nhưng tôi chỉ có thể trả lời về dữ liệu GDP tổng hợp từ Hoa Kỳ." Việc phân định rõ ràng cho phép độ tin cậy cao hơn về phản hồi ngay cả khi nó không chính xác là những gì người dùng muốn.

6) Sử dụng dấu phân cách: Kết hợp dấu phân cách trong lời nhắc, chẳng hạn như '—văn bản—' hoặc '<văn bản>', hỗ trợ LLM xác định vị trí của thông tin cụ thể như định nghĩa và hướng dẫn, do đó cải thiện độ chính xác phản hồi.

7) Tránh hướng dẫn mâu thuẫn: Đảm bảo rằng hướng dẫn lời nhắc nhất quán trong khi tránh mâu thuẫn là cần thiết trong điều kiện giới hạn để tránh ảo giác.

8) Tiến hóa lời nhắc: Quy trình lời nhắc tùy chỉnh là lặp lại với trọng tâm vào hiệu suất hơn là hoàn hảo. Khi LLM được tinh chỉnh dựa trên cách sử dụng, chúng có thể hỗ trợ bối cảnh lớn hơn trong tương lai gần. Tuy nhiên, sẽ luôn có nhu cầu tinh chỉnh và phát triển LLM để cho phép các nhiệm vụ ra quyết định phức tạp như đề xuất xu hướng quy định và khả năng lập kế hoạch kịch bản. Phát triển lời nhắc dựa trên phản hồi của con người là thành phần cần thiết để cho phép trải nghiệm người dùng nâng cao.

B. Chấm điểm Chất lượng Phản hồi LLM

Trong Hình 4, chúng ta quan sát các chỉ số chấm điểm phản hồi LLM trung bình {s1, ...s6} trên danh sách {i= 1 : 356,000} tập hợp truy vấn người dùng được tuyển chọn trải dài trên tất cả các danh mục ý định. Vì tất cả các chỉ số chấm điểm phản hồi đều có tính chất nhị phân, tần suất cao hơn của các giá trị 1 phản ánh thống kê phản hồi tốt cho mỗi truy vấn người dùng và các giá trị 0 phản ánh ảo giác có thể. Ở đây, chúng ta quan sát rằng điểm trung bình cho các chỉ số {s2, s3, s4} là cao nhất. Điều này có nghĩa là LLM Azure GPT-3 (davinci-003 kế thừa) ảo giác số giả ít hơn 10% thời gian, như được phát hiện bởi si,2 trong (6). Ngoài ra, các chỉ số {s1, s6} tập trung vào tìm kiếm thực thể được đặt tên và ở đây chúng ta quan sát hơn 20% tỷ lệ mơ hồ trong bối cảnh phản hồi. Ngoài ra, chúng ta quan sát rằng chỉ số cảnh báo s5 có tỷ lệ sai cao nhất hơn 30%, cho thấy các khối dữ liệu được chọn trong bối cảnh chứa nhiều chỉ số tài chính khác với chỉ số tài chính trong truy vấn người dùng. Trong khi tỷ lệ sai cao cho chỉ số s5 không nhất thiết có nghĩa là ảo giác, chỉ số này phục vụ như một công cụ chẩn đoán để cải thiện phản hồi câu hỏi dựa trên phản hồi của con người vì nó chỉ ra vấn đề với các mô-đun lọc và lựa chọn khối dữ liệu. Các điểm phản hồi trung bình này cho một tập hợp truy vấn người dùng ngoại tuyến cho phép đảm bảo chất lượng cho các triển khai phiên bản của chatbot Tài chính.

Cuối cùng, chúng tôi đánh giá điểm tin cậy tổng thể được tạo ra cho cùng một loạt 356.000 câu hỏi bằng cách đánh giá tác động kết hợp của các chỉ số chấm điểm chất lượng. Điểm phản hồi cho mỗi truy vấn người dùng được phân loại thành {Thấp/Trung bình/Cao} dựa trên (10) và các biến đổi trong độ tin cậy phản hồi trung bình qua các triển khai hàng tuần trong khoảng thời gian 8 tuần được hiển thị trong Hình 5. Điểm tin cậy phản hồi chỉ ra nếu LLM hiểu truy vấn người dùng và nếu nó có dữ liệu cần thiết để đưa ra câu trả lời đáng tin cậy. Trong khi độ tin cậy "thấp" có thể không nhất thiết có nghĩa là ảo giác đã xảy ra, nó cung cấp cho người dùng một tiêu chí tin cậy bổ sung để thực hiện sự siêng năng đáng có và đi đến câu trả lời từ các nguồn khác. Điểm tin cậy phản hồi cũng phản ánh sự tiến hóa trong LLM và khả năng lời nhắc nâng cao theo thời gian. Ngoài ra, điểm tin cậy hỗ trợ ưu tiên hóa cho các cải tiến lời nhắc để cho phép tiến hóa lặp lại trong chất lượng phản hồi LLM tổng thể, độ tin cậy và tính đáng tin cậy. Trong Hình 5, chúng ta quan sát sự cải thiện nhất quán trong điểm tin cậy tổng thể bằng lời nhắc nâng cao lặp lại. Thay đổi chính trong xếp hạng tin cậy phản hồi tại khung thời gian tuần 6 chỉ ra sự thay đổi trong LLM từ GPT3- GPT 3.5. Quan sát này chỉ ra rằng trong khi hầu hết các khung làm việc Langchain [12] bất khả tri LLM, lời nhắc cần được tái kỹ thuật ở một mức độ nhất định cho mỗi thay đổi LLM. Do đó, các mô-đun đo lường và tin cậy chấm điểm phản hồi tổng thể rất quan trọng để lập kế hoạch và giám sát những thay đổi LLM back-end như vậy có thể ảnh hưởng đáng kể đến trải nghiệm người dùng nếu không có biện pháp khác.

C. Dữ liệu đến Câu trả lời từ đầu đến cuối với Nhiều Lời nhắc

Thành phần đầu tiên và chính trong chatbot Tài chính kiểm soát ảo giác là quy trình phân loại ý định cho mỗi truy vấn người dùng. Trong khi quy trình này có thể dễ dàng được tự động hóa bằng các mô hình học có giám sát như cây quyết định, bộ phân loại tuyến tính một so với tất cả, SVM v.v., các bộ phân loại cổ điển nhạy cảm với từ khóa được sử dụng trong truy vấn và việc nhập dữ liệu nhiễu do lỗi gõ hoặc truy vấn người dùng trừu tượng có thể khiến bộ phân loại tiền huấn luyện phân loại sai, dẫn đến mẫu lời nhắc sai được sử dụng để tạo lời nhắc tùy chỉnh do đó dẫn đến phản hồi chất lượng thấp/trung bình mà người dùng có thể không thích. Tuy nhiên, LLM đã được sử dụng thành công cho các nhiệm vụ phân loại cảm tình đơn giản và chúng cũng mạnh mẽ đối với lỗi gõ [45]. Trong thực nghiệm này, chúng tôi đánh giá hiệu suất phân loại một so với tất cả của mô hình SVM kernel tuyến tính được tiền huấn luyện trên 900.000 truy vấn người dùng được phân loại thành 9 lớp. Bộ phân loại SVM có điểm kiểm tra tốt nhất trên phân chia 70/30 cho 900.000 truy vấn người dùng khi so sánh với cây quyết định, XGBoost và bộ phân loại tuyến tính. Chúng tôi so sánh hiệu suất phân loại SVM (theo độ chính xác trung bình (Pr) và gọi lại (Re)) với lời nhắc LLM truyền hướng dẫn để đọc truy vấn người dùng và phân loại nó thành một trong 9 danh mục ý định. Đối với dữ liệu kiểm tra, chúng tôi tuyển chọn một tập hợp 50 truy vấn người dùng mở có tính chất trừu tượng. Hiệu suất phân loại ý định cho mỗi danh mục truy vấn người dùng sử dụng bộ phân loại SVM so với lời nhắc LLM tùy chỉnh được hiển thị trong Bảng III. Ở đây, chúng ta quan sát rằng Pr/Re cấp macro cho phân loại ý định dựa trên LLM là 0.94/0.78, cao hơn đáng kể so với thống kê hiệu suất cấp macro cho bộ phân loại SVM Pre/Re là 0.69/0.71. Quan sát này phù hợp với công trình trước đây trong [46], trong đó GPT-3 được hiển thị có hiệu suất phân loại dựa trên văn bản tốt hơn khi so sánh với các bộ phân loại tiêu chuẩn. Do đó, sử dụng nhiều lời nhắc LLM để đầu tiên phân loại ý định của truy vấn người dùng theo sau bởi xây dựng lời nhắc tùy chỉnh với bối cảnh, định nghĩa, hướng dẫn và ví dụ liên quan có thể giảm đáng kể ảo giác. Tuy nhiên, đáng chú ý là nhiều lời nhắc LLM cho mỗi truy vấn người dùng có thể tăng thời gian phản hồi.

D. Đánh giá cho Hiệu suất LLM

Thiết kế sản phẩm dựa trên LLM yêu cầu bốn cân nhắc chính khác với giai đoạn tạo nguyên mẫu. Các cân nhắc này là độ tin cậy phản hồi, thời gian phản hồi, bảo mật cơ sở hạ tầng và chi phí sử dụng. Mặc dù thiết kế hệ thống của chúng tôi cho chatbot Tài chính đã bất khả tri LLM cho đến nay, chúng tôi cần liên tục cân nhắc các rủi ro tiềm ẩn và lợi thế được cung cấp bởi nhiều LLM khác nhau để duy trì độ tin cậy và độ chính xác của phản hồi. Trong thực nghiệm này, chúng tôi trình bày đánh giá so sánh về ưu và nhược điểm của các thay đổi LLM và tiêu chí lựa chọn LLM của chúng tôi.

Đối với thực nghiệm này, chúng tôi áp dụng một tập hợp 300 truy vấn người dùng được tuyển chọn cẩn thận tương ứng với 9 danh mục ý định. Chúng tôi chọn các câu hỏi đơn giản và mở để đánh giá. Đánh giá về chi phí LLM phát sinh cho mỗi token và điểm phản hồi trung bình cho 300 truy vấn người dùng cùng với ưu và nhược điểm tổng thể của mỗi LLM được hiển thị trong Bảng IV. Ở đây, chúng ta quan sát rằng mô hình Bison 32K có điểm phản hồi cao nhất (>90%) trong khi Chat-Bison và GPT 3.5 có điểm phản hồi thấp nhất. Quan sát này là trực quan vì Chat-Bison và GPT3.5 đã được huấn luyện cụ thể để duy trì cuộc trò chuyện thay vì trả về tóm tắt cho dữ liệu ngữ cảnh lớn. Do đó, kế hoạch lựa chọn LLM tối ưu sẽ là giữa GPT-3 và Text-Bison cho các trường hợp sử dụng Dữ liệu-đến-câu trả lời như vậy.

V. KẾT LUẬN VÀ THẢO LUẬN

Các giải pháp chatbot được hỗ trợ bởi LLM cho các lĩnh vực chuyên ngành như Tài chính phải đối mặt với những thách thức chính như độ tin cậy và khả năng mở rộng. Trong công trình này, chúng tôi trình bày một khung làm việc mới bất khả tri LLM nhằm mục đích tạo ra phản hồi cho nhiều truy vấn người dùng khác nhau từ các bảng dữ liệu thuần túy trong khi kiểm soát ảo giác trong phản hồi. Hành trình từ tạo nguyên mẫu đến mở rộng sản phẩm đã cung cấp một số học hỏi để tối đa hóa khả năng tạo lời nhắc tùy chỉnh trong khi đảm bảo ảo giác tối thiểu cho các nhà ra quyết định tài chính. Khung làm việc mới của chúng tôi kiểm soát ảo giác hoặc phản hồi LLM giả ở nhiều cấp độ và nó cũng chấm điểm mỗi phản hồi để cung cấp mức độ tin cậy bổ sung cho người dùng về độ chính xác của phản hồi. Thiết lập hệ thống được đề xuất khác biệt đáng kể so với chatbot trả lời câu hỏi chung vì tỷ lệ lỗi nhỏ và ảo giác có thể có tác động có hại cho các nhà ra quyết định tài chính. Mô-đun chấm điểm phản hồi được đề xuất đảm bảo rằng người dùng hiểu mức độ chấp nhận cho phản hồi được tạo bởi LLM, do đó phát hiện 10% trường hợp khi điểm phản hồi "thấp" có thể chỉ ra ảo giác tiềm ẩn. Hệ thống được đề xuất đã được đánh giá cho các triển khai phiên bản và cho các biến đổi trong nhà cung cấp LLM.

Bốn kết luận chính từ công trình này như sau. Đầu tiên, chúng ta quan sát rằng kỹ thuật lời nhắc nâng cao và thiết kế cơ sở hạ tầng mô-đun đóng vai trò quan trọng trong việc đảm bảo phản hồi đáng tin cậy và chính xác. Thứ hai, mô-đun chấm điểm phản hồi mới được đề xuất cho phép giám sát chất lượng phản hồi giữa các triển khai làm mới dữ liệu. Thứ ba, chúng tôi nghiên cứu việc sử dụng nhiều lời nhắc LLM cho mỗi truy vấn người dùng để đảm bảo độ tin cậy cao hơn và ảo giác thấp hơn trong phản hồi. Chúng ta quan sát rằng sử dụng LLM có hiệu suất phân loại ý định truy vấn người dùng mạnh mẽ khi so sánh với các bộ phân loại SVM tiêu chuẩn cho các truy vấn người dùng tương đối trừu tượng. Ngoài ra, phân loại ý định dựa trên LLM mạnh mẽ hơn đối với dữ liệu nhiễu và lỗi gõ, do đó làm cho các hệ thống trả lời câu hỏi đa lời nhắc mạnh mẽ hơn so với khung làm việc lời nhắc đơn lẻ. Thứ tư, chúng tôi trình bày đánh giá LLM và tiêu chí lựa chọn LLM cho các trường hợp sử dụng cụ thể theo lĩnh vực dựa trên chi phí mỗi truy vấn, độ tin cậy và khả năng mở rộng.

Khung làm việc Dữ liệu-đến-câu trả lời mới được trình bày trong công trình này thể hiện các cân nhắc hệ thống và cơ sở hạ tầng cần thiết để đưa chatbot Tài chính từ giai đoạn tạo nguyên mẫu đến giai đoạn mở rộng. Khung làm việc được đề xuất có những lợi thế sau đây so với khung làm việc Langchain tiêu chuẩn.

1) Triển khai phiên bản để đảm bảo tiến hóa trong lời nhắc nâng cao.
2) Dễ sử dụng để xây dựng độ tin cậy và tính đáng tin cậy cho người dùng để cho phép ra quyết định tài chính.
3) Khả năng mở rộng cơ sở hạ tầng để hỗ trợ khả năng dựa trên dữ liệu ngày càng tăng bằng cách kết hợp dự đoán dữ liệu và thông tin liên quan đến xu hướng vào khối dữ liệu.
4) Khung làm việc bất khả tri LLM có thể được giám sát về hiệu suất phản hồi để đảm bảo tiến hóa trong chất lượng phản hồi với phản hồi của con người.

Các công trình tương lai sẽ được hướng tới việc tiếp tục nâng cao khung làm việc tối thiểu hóa ảo giác cho dữ liệu và tài liệu tài chính phi cấu trúc kết hợp.

LỜI CẢM ỚN

Các tác giả muốn cảm ơn Oscar Rodrigiuz, Kiranjit Kaur, Juan J. Ricas Corona, Errol Paclibar và Anandam Dhandugari vì sự hỗ trợ thử nghiệm liên tục. Cảm ơn đặc biệt tới Priya Raman vì hướng dẫn và hỗ trợ liên tục.

TÀI LIỆU THAM KHẢO

[1] L. Olinga, "Chatgpt là người phá vỡ mới nhưng có một hạn chế," 2023. [Trực tuyến]. Có sẵn: https://www.thestreet.com/technology/chatgpt-is-the-new-disruptor-in-chief-but-theres-a-catch

[2] R. Tang, Y. Lu, và J. Lin, "Tạo ngôn ngữ tự nhiên cho chưng cất kiến thức hiệu quả," trong Kỷ yếu Hội thảo lần thứ 2 về Phương pháp Học sâu cho NLP Tài nguyên thấp (DeepLo 2019), 2019, tr. 202–208.

[3] X. Dai, J. Hou, C.-Y. Ma, S. Tsai, J. Wang, R. Wang, P. Zhang, S. Vandenhende, X. Wang, A. Dubey và cộng sự, "Emu: Nâng cao các mô hình tạo hình ảnh sử dụng kim photogenic trong đống rơm," arXiv preprint arXiv:2309.15807, 2023.

[4] H. Lin, A. Zala, J. Cho, và M. Bansal, "Videodirectorgpt: Tạo video nhiều cảnh nhất quán thông qua lập kế hoạch được hướng dẫn bởi llm," arXiv preprint arXiv:2309.15091, 2023.

[5] S. Wu, H. Fei, L. Qu, W. Ji, và T.-S. Chua, "Next-gpt: Llm đa phương thức bất kỳ-tới-bất kỳ," arXiv preprint arXiv:2309.05519, 2023.

[6] W. Xie và B. Plancher, "Các mô hình ngôn ngữ lớn có thể giảm rào cản gia nhập cho robot học trung học không?" forbes.com, 2023.

[7] P. L. và cộng sự, "Đánh giá toàn diện các mô hình ngôn ngữ," 2023.

[8] J.-Y. Yao, K.-P. Ning, Z.-H. Liu, M.-N. Ning, và L. Yuan, "Llm nói dối: Ảo giác không phải là lỗi, mà là tính năng như ví dụ đối kháng," arXiv preprint arXiv:2310.01469, 2023.

[9] F. Leiser, S. Eckhardt, M. Knaeble, A. Maedche, G. Schwabe, và A. Sunyaev, "Từ chatgpt đến factgpt: Một nghiên cứu thiết kế tham gia để giảm thiểu tác động của ảo giác mô hình ngôn ngữ lớn đối với người dùng," trong Kỷ yếu Mensch und Computer 2023, 2023, tr. 81–90.

[10] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell và cộng sự, "Các mô hình ngôn ngữ là người học few-shot," Advances in neural information processing systems, tập 33, tr. 1877–1901, 2020.

[11] A. Chan, "Gpt-3 và instructgpt: Chủ nghĩa dystopian công nghệ, chủ nghĩa utopian, và quan điểm 'ngữ cảnh' trong đạo đức ai và ngành công nghiệp," AI and Ethics, tập 3, số 1, tr. 53–64, 2023.

[12] K. Pandya và M. Holia, "Tự động hóa dịch vụ khách hàng sử dụng langchain: Xây dựng chatbot gpt nguồn mở tùy chỉnh cho tổ chức," 2023.

[13] J. Chen, H. Lin, X. Han, và L. Sun, "Đánh giá các mô hình ngôn ngữ lớn trong tạo tăng cường truy xuất," 2023.

[14] S. Pan, L. Luo, Y. Wang, C. Chen, J. Wang, và X. Wu, "Thống nhất các mô hình ngôn ngữ lớn và đồ thị kiến thức: Một lộ trình," 2023.

[15] M. Golestani, S. Z. Razavi, Z. Borhanifard, F. Tahmasebian, và H. Faili, "Sử dụng mã hóa bert và mô hình ngôn ngữ cấp câu để sắp xếp câu," trong Hội nghị Quốc tế về Văn bản, Lời nói và Đối t化. Springer, 2021, tr. 318–330.

[16] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, và V. Stoyanov, "Roberta: Một phương pháp tiền huấn luyện bert được tối ưu hóa mạnh mẽ," arXiv preprint arXiv:1907.11692, 2019.

[17] Z. Lan, M. Chen, S. Goodman, K. Gimpel, P. Sharma, và R. Soricut, "Albert: Một bert nhẹ cho học tự giám sát biểu diễn ngôn ngữ," arXiv preprint arXiv:1909.11942, 2019.

[18] Y. Sun, S. Wang, Y. Li, S. Feng, H. Tian, H. Wu, và H. Wang, "Ernie 2.0: Một khung tiền huấn luyện liên tục cho hiểu ngôn ngữ," trong Kỷ yếu hội nghị AAAI về trí tuệ nhân tạo, tập 34, số 05, 2020, tr. 8968–8975.

[19] M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy, V. Stoyanov, và L. Zettlemoyer, "Bart: Tiền huấn luyện khử nhiễu chuỗi-tới-chuỗi cho tạo ngôn ngữ tự nhiên, dịch thuật và hiểu," arXiv preprint arXiv:1910.13461, 2019.

[20] J. Ni, G. H. Ábrego, N. Constant, J. Ma, K. B. Hall, D. Cer, và Y. Yang, "Sentence-t5: Bộ mã hóa câu có thể mở rộng từ các mô hình văn bản-tới-văn bản tiền huấn luyện," arXiv preprint arXiv:2108.08877, 2021.

[21] Z. Du, Y. Qian, X. Liu, M. Ding, J. Qiu, Z. Yang, và J. Tang, "Glm: Tiền huấn luyện mô hình ngôn ngữ tổng quát với lấp đầy trống tự hồi quy," arXiv preprint arXiv:2103.10360, 2021.

[22] Z. Qin, R. Jagerman, K. Hui, H. Zhuang, J. Wu, J. Shen, T. Liu, J. Liu, D. Metzler, X. Wang và cộng sự, "Các mô hình ngôn ngữ lớn là người xếp hạng văn bản hiệu quả với lời nhắc xếp hạng theo cặp," arXiv preprint arXiv:2306.17563, 2023.

[23] M. Zong và B. Krishnamachari, "Một khảo sát về gpt-3," arXiv preprint arXiv:2212.00857, 2022.

[24] F. Shi, S. Kai, J. Zheng, và Y. Zhong, "Mô hình dự đoán dựa trên xlnet cho giá trị chỉ số cvss," Applied Sciences, tập 12, số 18, tr. 8983, 2022.

[25] N. Du, Y. Huang, A. M. Dai, S. Tong, D. Lepikhin, Y. Xu, M. Krikun, Y. Zhou, A. W. Yu, O. Firat và cộng sự, "Glam: Mở rộng hiệu quả các mô hình ngôn ngữ với mixture-of-experts," trong Hội nghị Quốc tế về Học máy. PMLR, 2022, tr. 5547–5569.

[26] M. King, "Quản lý các phần dựa trên văn bản của bài kiểm tra iq tổng quát cho năm mô hình ngôn ngữ lớn khác nhau," TechRxiv, 2023.

[27] OpenAI, "Báo cáo kỹ thuật gpt-4," 2023.

[28] H. Naveed, A. U. Khan, S. Qiu, M. Saqib, S. Anwar, M. Usman, N. Akhtar, N. Barnes, và A. Mian, "Một tổng quan toàn diện về các mô hình ngôn ngữ lớn," 2023.

[29] P. Budzianowski và I. Vulić, "Xin chào, đây là gpt-2 – tôi có thể giúp bạn như thế nào? hướng tới việc sử dụng các mô hình ngôn ngữ tiền huấn luyện cho hệ thống đối thoại hướng nhiệm vụ," 2019.

[30] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, và D. Amodei, "Các mô hình ngôn ngữ là người học few-shot," 2020.

[31] H. T. và cộng sự, "Llama: Các mô hình ngôn ngữ nền tảng mở và hiệu quả," 2023.

[32] R. A. và cộng sự, "Báo cáo kỹ thuật palm 2," 2023.

[33] H. T. và cộng sự, "Llama 2: Các mô hình trò chuyện nền tảng mở và tinh chỉnh," 2023.

[34] Y. Bai, S. Kadavath, S. Kundu, A. Askell, J. Kernion, A. Jones, A. Chen, A. Goldie, A. Mirhoseini, C. McKinnon và cộng sự, "Ai hiến pháp: Vô hại từ phản hồi ai," arXiv preprint arXiv:2212.08073, 2022.

[35] Anthropic, "Thẻ mô hình và đánh giá cho các mô hình claude," 2023. [Trực tuyến]. Có sẵn: https://www-files.anthropic.com/production/images/Model-Card-Claude-2.pdf

[36] Cohere, "Các mô hình lệnh cohere," 2023. [Trực tuyến]. Có sẵn: https://docs.cohere.com/docs/the-command-model

[37] S. Wu, O. Irsoy, S. Lu, V. Dabravolski, M. Dredze, S. Gehrmann, P. Kambadur, D. Rosenberg, và G. Mann, "Bloomberggpt: Một mô hình ngôn ngữ lớn cho tài chính," arXiv preprint arXiv:2303.17564, 2023.

[38] R. Taylor, M. Kardas, G. Cucurull, T. Scialom, A. Hartshorn, E. Saravia, A. Poulton, V. Kerkez, và R. Stojnic, "Galactica: Một mô hình ngôn ngữ lớn cho khoa học," 2022.

[39] S. Mukherjee, A. Mitra, G. Jawahar, S. Agarwal, H. Palangi, và A. Awadallah, "Orca: Học tập tiến bộ từ dấu vết giải thích phức tạp của gpt-4," 2023.

[40] A. K. Gao, "Vec2vec: Một phương pháp mạng neural compact để biến đổi nhúng văn bản với độ trung thực cao," arXiv preprint arXiv:2306.12689, 2023.

[41] E. Y. Gueddoudj và A. Chikh, "Hướng tới etl có thể mở rộng và hiệu quả," International Journal of Computing and Digital Systems, tập 14, số 1, tr. 10223–10231, 2023.

[42] R. Abrahiem, "Một thế hệ mới các giải pháp middleware cho kiến trúc kho dữ liệu gần thời gian thực," trong Hội nghị Quốc tế IEEE 2007 về Công nghệ Điện/Thông tin, 2007, tr. 192–197.

[43] N. Boucher, L. Pajola, I. Shumailov, R. Anderson, và M. Conti, "Tăng cường anh cả: Tấn công công cụ tìm kiếm với mã hóa," arXiv preprint arXiv:2304.14031, 2023.

[44] F. Hashim, K. Shuaib, và N. Zaki, "Phân đoạn cho mạng blockchain có thể mở rộng," SN Computer Science, tập 4, số 1, tr. 2, 2022.

[45] D. Araci, "Finbert: Phân tích cảm tình tài chính với các mô hình ngôn ngữ tiền huấn luyện," 2019.

[46] X. Sun, X. Li, J. Li, F. Wu, S. Guo, T. Zhang, và G. Wang, "Phân loại văn bản thông qua các mô hình ngôn ngữ lớn," arXiv preprint arXiv:2305.08377, 2023.

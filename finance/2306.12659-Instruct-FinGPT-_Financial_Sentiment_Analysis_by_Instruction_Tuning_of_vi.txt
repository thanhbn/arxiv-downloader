# Instruct-FinGPT: Phân tích tình cảm tài chính bằng cách điều chỉnh hướng dẫn của các mô hình ngôn ngữ lớn đa mục đích

Boyu Zhang2∗, Hongyang (Bruce) Yang1∗, Xiao-Yang Liu1†
1Đại học Columbia;2Đại học Công nghệ Swinburne
{HY2500, XL2427 }@columbia.edu; boyu.zhang68@gmail.com

Tóm tắt
Phân tích tình cảm là một công cụ quan trọng để khám phá những hiểu biết từ các bài báo tài chính, tin tức và mạng xã hội, định hình hiểu biết của chúng ta về các biến động thị trường. Mặc dù có những khả năng ấn tượng của các mô hình ngôn ngữ lớn (LLM) trong xử lý ngôn ngữ tự nhiên tài chính (NLP), chúng vẫn gặp khó khăn với việc diễn giải chính xác các giá trị số và nắm bắt bối cảnh tài chính, hạn chế hiệu quả của chúng trong việc dự đoán tình cảm tài chính. Trong bài báo này, chúng tôi giới thiệu một phương pháp điều chỉnh hướng dẫn đơn giản nhưng hiệu quả để giải quyết những vấn đề này. Bằng cách biến đổi một phần nhỏ dữ liệu phân tích tình cảm tài chính có giám sát thành dữ liệu hướng dẫn và tinh chỉnh một LLM đa mục đích với phương pháp này, chúng tôi đạt được những tiến bộ đáng kể trong phân tích tình cảm tài chính. Trong thí nghiệm, phương pháp của chúng tôi vượt trội hơn các mô hình phân tích tình cảm có giám sát tiên tiến nhất, cũng như các LLM được sử dụng rộng rãi như ChatGPT và LLaMA, đặc biệt trong các tình huống mà hiểu biết số và khả năng lý giải ngữ cảnh là quan trọng.

1 Giới thiệu
Phân tích tình cảm tài chính, nhiệm vụ phân biệt tình cảm nhà đầu tư từ các bài báo tài chính, tin tức và mạng xã hội, là một công cụ thiết yếu để hiểu và dự báo các biến động thị trường. Các mô hình truyền thống thường gặp khó khăn với một số thách thức, bao gồm không nhạy cảm với các giá trị số, khó khăn trong việc diễn giải tình cảm mà không có ngữ cảnh rõ ràng, và những thách thức liên quan đến thuật ngữ tài chính, dữ liệu đa ngôn ngữ, phụ thuộc thời gian, dữ liệu có nhãn không đủ, và tiếng ồn vốn có trong dữ liệu mạng xã hội.

Các Mô hình Ngôn ngữ Lớn (LLM) đã đóng vai trò quan trọng trong việc giảm thiểu một số thách thức này, thể hiện đóng góp đáng kể cho lĩnh vực xử lý ngôn ngữ tự nhiên tài chính (NLP). Một đặc điểm nổi bật là kiến thức chung vốn có của LLM thu được trong quá trình tiền huấn luyện trên các tập dữ liệu khổng lồ và đa dạng, bao gồm văn bản tài chính. Tuy nhiên, LLM không có đủ bối cảnh tài chính. Hiệu suất của chúng trong việc diễn giải các giá trị số thường không đầy đủ và có thể gặp khó khăn để xác định chính xác tình cảm khi bối cảnh không có hoặc mơ hồ. Những thách thức này nhấn mạnh nhu cầu về các mô hình cải tiến có thể hiểu một cách thành thạo những sắc thái phức tạp của phân tích tình cảm tài chính.

Để đáp ứng những thách thức này, nghiên cứu của chúng tôi khám phá tiềm năng của việc điều chỉnh hướng dẫn các LLM đa mục đích cho phân tích tình cảm trong lĩnh vực tài chính. Trong nghiên cứu này, chúng tôi điều tra hai câu hỏi nghiên cứu chính: 1) Làm thế nào để kích hoạt LLM giải quyết vấn đề nhạy cảm số trong phân tích tình cảm tài chính? và 2) Vai trò của hiểu biết ngữ cảnh trong việc cải thiện phân tích tình cảm tài chính là gì?

Chúng tôi đề xuất Instruct-FinGPT bằng cách điều chỉnh hướng dẫn một LLM đã được tiền huấn luyện (cụ thể là LLaMA [Touvron et al., 2023]). Thông qua phương pháp này, chúng tôi biến đổi tập dữ liệu phân tích tình cảm dựa trên phân loại thành một nhiệm vụ tạo sinh, từ đó cho phép LLM áp dụng hiệu quả hơn khả năng huấn luyện mở rộng và năng lực phân tích vượt trội của chúng. Mục tiêu cuối cùng của Instruct-FinGPT là nâng cao hiệu suất trong phân tích tình cảm tài chính bằng cách giảm thiểu yêu cầu về dữ liệu tinh chỉnh và tối đa hóa khả năng hiểu ngữ cảnh và độ nhạy cảm số vốn có trong LLM. Bằng cách giới thiệu phương pháp mới này, chúng tôi mong muốn mở rộng ranh giới của các phương pháp luận hiện tại, mở ra những con đường hứa hẹn cho việc khám phá trong tương lai trong lĩnh vực phân tích tình cảm tài chính.

Những đóng góp chính của bài báo này như sau:

• Chúng tôi thiết kế một mô hình FinGPT được điều chỉnh hướng dẫn cho phân tích tình cảm tài chính. Mô hình này vượt trội hơn cả LLM đa mục đích và các mô hình có giám sát tiên tiến nhất về hiệu suất chuẩn mực, mặc dù chỉ sử dụng một lượng nhỏ dữ liệu hướng dẫn và tài nguyên huấn luyện.

• Chúng tôi giải quyết vấn đề quan trọng về độ nhạy cảm số trong phân tích tình cảm tài chính, một thành phần thường bị bỏ qua bởi các mô hình hiện có, nâng cao khả năng của mô hình trong việc diễn giải chính xác tình cảm từ tin tức tài chính.

• Chúng tôi nhấn mạnh tầm quan trọng của hiểu biết ngữ cảnh trong phân tích tình cảm tài chính, tận dụng kiến thức chung vốn có của LLM để cải thiện hiệu suất trong phân tích tình cảm, đặc biệt khi ngữ cảnh bị thiếu hoặc mơ hồ.

Nghiên cứu của chúng tôi cung cấp những hiểu biết mới về việc ứng dụng LLM cho phân tích tình cảm tài chính, đưa ra các giải pháp tiềm năng cho một số thách thức lâu dài trong lĩnh vực này.

2 Nghiên cứu liên quan
Nhiệm vụ phân tích tình cảm, đặc biệt trong lĩnh vực tài chính, đã là một lĩnh vực nghiên cứu đáng kể trong trường Xử lý Ngôn ngữ Tự nhiên (NLP). Có nhiều công trình trong tài liệu [Xing et al., 2018; Loughran and McDonald, 2011; Tai and Kao, 2013; Hamilton et al., 2016; Day and Lee, 2016; Chan and Chong, 2017; Sohangir et al., 2018; Araci, 2019; Mishev et al., 2020] sử dụng các phương pháp luận khác nhau để thực hiện phân tích tình cảm tài chính, từ các kỹ thuật dựa trên từ điển đến các phương pháp tiếp cận máy học và học sâu.

Một công trình đáng chú ý là của Araci [Atkins et al., 2018], trình bày một tập hợp các thuật toán máy học truyền thống để dự đoán hướng của chuyển động thị trường chứng khoán dựa trên các bài báo tin tức tài chính. Mặc dù công trình này đã có những bước tiến trong việc sử dụng máy học cho phân tích tình cảm tài chính, nó không giải quyết một cách toàn diện những thách thức liên quan đến độ nhạy cảm số hoặc hiểu biết ngữ cảnh.

Về các phương pháp tiếp cận học sâu, mô hình dựa trên transformer BERT [Kenton and Toutanova, 2019] đã được sử dụng rộng rãi cho các nhiệm vụ phân tích tình cảm do khả năng hiểu ngữ cảnh mạnh mẽ của nó. Tuy nhiên, BERT và các biến thể của nó thường yêu cầu lượng lớn dữ liệu có nhãn để tinh chỉnh, điều này có thể khó khăn để có được trong lĩnh vực tài chính.

Gần đây hơn, FinBERT [Araci, 2019], một biến thể của BERT được thiết kế đặc biệt cho lĩnh vực tài chính, đã được phát triển để giải quyết những vấn đề này. FinBERT đã được tinh chỉnh trên văn bản tài chính và đã cho thấy kết quả hứa hẹn trong phân tích tình cảm tài chính. Tuy nhiên, nó bị hạn chế bởi các vấn đề như không nhạy cảm với các giá trị số và gặp khó khăn với ngữ cảnh mà thông tin cần thiết có thể bị thiếu. FLANG [Shah et al., 2022] bổ sung trình bày các chuẩn mực đánh giá tài chính trên năm nhiệm vụ NLP khác biệt trong lĩnh vực tài chính, cùng với việc tích hợp các chuẩn mực thông thường phổ biến trong nghiên cứu trước đây.

Mặc dù BloombergGPT [Wu et al., 2023] thể hiện hiệu suất ấn tượng trong các nhiệm vụ phân tích tình cảm, có những thách thức vốn có đối với khả năng tiếp cận và ứng dụng của nó cho việc sử dụng rộng rãi hơn. Mô hình này, thuộc sở hữu của Bloomberg, được huấn luyện trên một tập dữ liệu khổng lồ gồm dữ liệu tài chính chuyên biệt, điều này có thể không dễ dàng có sẵn cho người khác. Hơn nữa, các tài nguyên cần thiết để huấn luyện một mô hình như vậy là đáng kể (1.3 triệu giờ GPU, chi phí khoảng 5 triệu USD). Điều này trái ngược với phương pháp của chúng tôi, thể hiện hiệu quả đáng kể với một tập dữ liệu nhỏ hơn đáng kể và ít tài nguyên tính toán hơn (ước tính khoảng dưới 300 USD mỗi lần huấn luyện), làm cho nó khả thi hơn cho việc triển khai rộng rãi.

Công trình của chúng tôi đặc biệt khác biệt trong việc tập trung vào tận dụng sức mạnh của LLM, kiến thức chung vốn có và khả năng lý luận của chúng để thực hiện phân tích tình cảm trong lĩnh vực tài chính. Chúng tôi khám phá một phương pháp điều chỉnh hướng dẫn mới và chứng minh hiệu quả của nó trong các thí nghiệm.

3 Phương pháp của chúng tôi
Mặc dù các LLM được tiền huấn luyện như GPT-3 và LLaMA có thể thu được những khả năng chung để giải quyết các nhiệm vụ khác nhau, ngày càng nhiều nghiên cứu đã cho thấy rằng khả năng của LLM có thể được điều chỉnh thêm theo các mục tiêu cụ thể. Phương pháp của chúng tôi sử dụng điều chỉnh hướng dẫn để điều chỉnh các LLM đa mục đích cho phân tích tình cảm tài chính, nâng cao hiểu biết của chúng về các giá trị số và ngữ cảnh trong nhiệm vụ cụ thể này. Quá trình này liên quan đến việc biến đổi nhiệm vụ phân tích tình cảm từ một nhiệm vụ phân loại thành một nhiệm vụ tạo sinh văn bản, điều này phù hợp hơn với khả năng của LLM. Hơn nữa, chúng tôi sử dụng tập dữ liệu được biến đổi để điều chỉnh hướng dẫn tinh chỉnh LLM theo cách học có giám sát. Cuối cùng, chúng tôi ánh xạ các đầu ra được tạo ra thành các nhãn tình cảm trong quá trình suy luận.

3.1 Điều chỉnh hướng dẫn
Chúng tôi áp dụng phương pháp điều chỉnh hướng dẫn của một LLM trên các tập dữ liệu phân tích tình cảm tài chính. Quá trình này được chia thành ba bước chính:

Định dạng Tập dữ liệu Phân tích Tình cảm Tài chính thành Tập dữ liệu Điều chỉnh Hướng dẫn
Các tập dữ liệu phân tích tình cảm tài chính hiện có được định dạng như nhiệm vụ phân loại văn bản trong đó đầu vào là tin tức tài chính hoặc tiêu đề và đầu ra là các nhãn kiểu số nguyên đại diện cho tình cảm tích cực, tiêu cực và trung tính.
Bước đầu tiên của chúng tôi là hình thành những tập dữ liệu phân loại này thành tập dữ liệu định dạng hướng dẫn.

Theo [Zhao et al., 2023], chúng tôi tạo ra 10 hướng dẫn được viết bởi con người mô tả nhiệm vụ phân tích tình cảm tài chính, và hình thành mỗi mẫu từ tập dữ liệu gốc bằng cách kết hợp một hướng dẫn được chọn ngẫu nhiên với đầu vào và đầu ra theo định dạng "Human: [hướng dẫn] + [đầu vào], Assistant: [đầu ra]". Quá trình này được thể hiện trong Hình 1.

Điều chỉnh hướng dẫn LLaMA-7B
Mặc dù các LLM được tiền huấn luyện sở hữu các khả năng như lý luận, hiểu số, kiến thức thế giới và đa ngôn ngữ, chúng gặp khó khăn trong việc áp dụng hiệu quả những khả năng này cho các nhiệm vụ cụ thể. Hạn chế này cản trở khả năng đạt được hiệu suất tiên tiến nhất (SOTA) trên các nhiệm vụ cụ thể, từ đó hạn chế tiềm năng ứng dụng của chúng. Ví dụ, [Wei et al., 2022] phát hiện rằng hiệu suất zero-shot của LLM thấp hơn đáng kể so với hiệu suất few-shot của chúng. Trong tình huống của chúng tôi, chúng tôi tận dụng dữ liệu hướng dẫn, thường bao gồm các giá trị số, bối cảnh tài chính và thuật ngữ tài chính, để cung cấp tín hiệu có giám sát. Thông qua điều chỉnh hướng dẫn, chúng tôi điều chỉnh khả năng của LLM với các nhãn phân tích tình cảm, đạt được hiểu biết chính xác và tinh tế hơn về tình cảm được thể hiện trong văn bản tài chính, cho phép nó vượt trội hơn cả LLM được tiền huấn luyện và các mô hình có giám sát được thiết kế đặc biệt cho phân tích tình cảm tài chính.

Chúng tôi minh họa phương pháp của mình bằng cách sử dụng điều chỉnh hướng dẫn với mô hình LLM có tên LLaMA-7B như một ví dụ để xác nhận ý tưởng của chúng tôi. Điều chỉnh hướng dẫn liên quan đến việc tinh chỉnh các LLM được tiền huấn luyện bằng cách tận dụng một tập hợp các thể hiện được định dạng bằng ngôn ngữ tự nhiên [Wei et al., 2022]. Đây là một phương pháp tương tự chặt chẽ với tinh chỉnh có giám sát. Trong quá trình huấn luyện, chúng tôi đặc biệt sử dụng các thể hiện được định dạng để tinh chỉnh mô hình LLM LLaMA-7B bằng cách tiếp cận học có giám sát, tức là huấn luyện với loss sequence-to-sequence. Lựa chọn này cho phép chúng tôi thể hiện tính hiệu quả và khả năng áp dụng của điều chỉnh hướng dẫn trong việc nâng cao hiệu suất phân tích tình cảm tài chính của các LLM như LLaMA-7B.

Ánh xạ các Đầu ra Được tạo ra thành Nhãn Tình cảm
Vì LLaMA-7B được tinh chỉnh hướng dẫn là một mô hình tạo sinh tự hồi quy, mặc dù chúng tôi huấn luyện nó bằng cách sử dụng các mẫu hướng dẫn để hướng dẫn đầu ra của nó hướng tới những phán đoán tình cảm mong muốn, nó vẫn có khả năng tạo ra văn bản tự do. Do đó, chúng tôi cần ánh xạ đầu ra của mô hình trở lại ba cảm xúc được chỉ định để đánh giá phù hợp. Phương pháp của chúng tôi như sau: nếu đầu ra của mô hình chứa các thuật ngữ "tích cực", "tiêu cực" hoặc "trung tính", chúng tôi ánh xạ nó tới nhãn tương ứng; nếu không, chúng tôi xem nó là tình cảm "trung tính".

3.2 So sánh giữa LLM và FinBERT cho Phân tích Tình cảm
Phương pháp của chúng tôi sử dụng LLM và so sánh hiệu quả của chúng trong phân tích tình cảm với mô hình FinBERT đã được thiết lập. Việc so sánh dựa trên ba khía cạnh then chốt:

• Hiểu biết ngữ cảnh: LLM có lợi thế do việc tiền huấn luyện quy mô lớn trên dữ liệu đa dạng. Điều này cung cấp cho chúng kiến thức chung toàn diện hơn, cho phép hiểu biết ngữ cảnh vượt trội so với FinBERT. Sự đa dạng và phong phú của các tập dữ liệu huấn luyện của LLM là không thể sánh được, cung cấp cho chúng kiến thức toàn diện vượt trội hơn khả năng của FinBERT.

• Độ nhạy cảm số: Văn bản tài chính thường kết hợp dữ liệu số đáng kể, đóng vai trò quan trọng trong việc truyền đạt tình cảm. LLM, với độ nhạy cảm số vốn có, thể hiện khả năng nâng cao trong việc diễn giải tình cảm được ngụ ý bởi các biến động số. Tham khảo một số báo cáo học thuật để nghiên cứu sâu về đặc tính này của LLM.

• Mô hình chỉ giải mã so với chỉ mã hóa: FinBERT là một mô hình chỉ mã hóa mã hóa chuỗi đầu vào thành một biểu diễn và dựa vào một bộ phân loại riêng để đưa ra dự đoán dựa trên biểu diễn được mã hóa. Mặt khác, LLM được sử dụng là một mô hình chỉ giải mã có thể tạo ra toàn bộ chuỗi đầu ra, bao gồm nhãn lớp, trực tiếp từ một biểu diễn tiềm hoặc vector độ dài cố định. Đặc tính này cho phép LLM dễ dàng thích nghi với các nhiệm vụ khác nhau mà không cần thay đổi cấu trúc mô hình trong khi các mô hình chỉ mã hóa yêu cầu phát triển các bộ phân loại cụ thể cho nhiệm vụ, điều này có thể tốn nhiều công sức hơn.

4 Đánh giá hiệu suất
Trong phần này, chúng tôi đánh giá hiệu quả của phương pháp được đề xuất từ ba góc độ: phân tích tình cảm chung, hiểu biết số và bổ sung kiến thức chung. Để xác nhận hiệu suất của phương pháp, chúng tôi so sánh nó với mô hình phân tích tình cảm tiên tiến nhất, FinBERT, và LLM đa mục đích, ChatGPT.

Kết quả thí nghiệm của chúng tôi xác nhận tính hiệu quả của phương pháp. Chỉ với một lượng nhỏ dữ liệu tinh chỉnh, mô hình của chúng tôi luôn đạt được hiệu suất vượt trội trong phân tích tình cảm so với FinBERT và ChatGPT.

4.1 Tập dữ liệu
Dữ liệu huấn luyện của chúng tôi là sự kết hợp của tập dữ liệu Twitter Financial News [Magic, 2022] và tập dữ liệu FiQA [Maia et al., 2018], tạo ra một bộ sưu tập toàn diện gồm 10,501 mẫu.

Tập dữ liệu huấn luyện
• Huấn luyện tình cảm tin tức tài chính Twitter: Tập dữ liệu này là một kho dữ liệu các tweet tin tức liên quan đến lĩnh vực tài chính và hoàn toàn bằng tiếng Anh. Mục đích chính của nó là phân loại tình cảm tài chính trong bối cảnh thảo luận Twitter. Tập dữ liệu bao gồm 9,540 mẫu để huấn luyện, mỗi mẫu được chú thích với một trong ba nhãn: Giảm, Tăng, hoặc Trung tính.

• Tập dữ liệu FiQA: Tập dữ liệu này, có thể truy cập dễ dàng qua HuggingFace, bao gồm 961 mẫu. Mỗi mẫu đã được chú thích với một trong ba nhãn: tích cực, trung tính, hoặc tiêu cực, biểu thị tình cảm được truyền đạt trong văn bản tương ứng.

Tập dữ liệu kiểm tra
• Xác nhận tình cảm tin tức tài chính Twitter (Twitter Val): Tập dữ liệu này, có thể truy cập qua HuggingFace, chứa 2,390 mẫu được chú thích với ba nhãn: Giảm, Tăng, hoặc Trung tính.

• Tập dữ liệu độ nhạy cảm số (numerical): Tập dữ liệu này, mà chúng tôi tự động lọc từ Twitter Val, bao gồm 117 mẫu. Những mẫu này chứa ít nhất hai giá trị số liên quan đến các chỉ số tài chính mà không có từ ngữ chỉ thị mạnh như 'tăng', 'giảm', 'tăng lên', 'giảm xuống'.

• Tập dữ liệu hiểu biết ngữ cảnh (contextual): Tập dữ liệu này, mà chúng tôi chọn ngẫu nhiên từ Twitter Val, bao gồm 20 mẫu. Những mẫu này thiếu các ngữ cảnh thiết yếu để đưa ra dự đoán tình cảm.

• Tập dữ liệu Financial PhraseBank (FPB): Tập dữ liệu này [Malo et al., 2014] bao gồm 4,840 mẫu được trích xuất ngẫu nhiên từ các bài báo tin tức tài chính có sẵn trên cơ sở dữ liệu LexisNexis. Các mẫu được chú thích cẩn thận bởi một nhóm 16 người chú thích có nền tảng về tài chính và kinh doanh, đảm bảo chú thích chất lượng cao.

4.2 Huấn luyện mô hình
Các tham số huấn luyện được đưa ra trong Bảng 2. Đối với mô hình Instruct-FinGPT-7B của chúng tôi, chúng tôi khởi tạo nó với mô hình LLaMA-7B và thực hiện điều chỉnh hướng dẫn trong 10 epoch. Quá trình huấn luyện sử dụng bộ tối ưu hóa AdamW [Loshchilov and Hutter, 2017], với kích thước batch là 32, tốc độ học ban đầu là 1e−5, và weight decay là 0.1. Để duy trì hiệu quả, chúng tôi đặt độ dài văn bản đầu vào tối đa là 512 token. Chúng tôi sử dụng DeepSpeed [Rasley et al., 2020] cho quá trình tinh chỉnh trên 8 GPU A100 (40GB), dẫn đến tổng thời gian huấn luyện là 58 phút.

4.3 Các mô hình cơ sở
LLaMA-7B [Touvron et al., 2023] Chúng tôi có được mô hình LLaMA-7B từ Meta và sử dụng nó để suy luận, giữ cùng cài đặt suy luận như Instruct-FinGPT-7B của chúng tôi.

FinBERT Chúng tôi có được mô hình FinBERT từ Hub Mô hình Hugging Face. Mô hình FinBERT được sử dụng để phân tích tình cảm sau khi tiền xử lý dữ liệu thô, bao gồm việc tokenize văn bản và padding hoặc cắt ngắn để phù hợp với độ dài đầu vào tối đa của mô hình. Một khi được tiền xử lý, dữ liệu được chạy qua FinBERT để suy luận, cung cấp kết quả phân tích tình cảm (tích cực, tiêu cực, hoặc trung tính) cho mỗi đầu vào văn bản.

ChatGPT Việc sử dụng API ChatGPT của OpenAI để phân tích tình cảm bao gồm một quy trình bốn bước được đơn giản hóa:
1. Thiết lập API: Điều này liên quan đến việc thiết lập client Python OpenAI, phục vụ như một giao diện để tương tác với API ChatGPT.
2. Chuẩn bị dữ liệu: Tập dữ liệu Điều chỉnh Hướng dẫn như được hiển thị trong Hình 1 được sử dụng để suy luận với mô hình ChatGPT.
3. Gọi API: Do những hạn chế hiện tại, API GPT-3.5 được sử dụng cho các yêu cầu. Phiên bản GPT-4.0 hiện không có sẵn để truy cập lập trình và chỉ có thể được tương tác qua giao diện web.
4. Diễn giải phản hồi: Phản hồi từ API bao gồm tình cảm của văn bản trực tiếp. Đầu ra tình cảm trực tiếp này đơn giản hóa nhiệm vụ phân tích tình cảm.

4.4 Đánh giá và phân tích
Để đánh giá hiệu suất của mô hình, chúng tôi kiểm tra nó trên một tập dữ liệu phân tích tình cảm tài chính chuẩn mực và đối chiếu kết quả với những kết quả của FinBERT. Các chỉ số đánh giá chính tập trung vào khả năng của mô hình trong việc quản lý các giá trị số và hiểu tình cảm trong các ngữ cảnh khác nhau.

Chỉ số hiệu suất Các chỉ số hiệu suất chính cho mô hình của chúng tôi bao gồm độ chính xác và điểm F1. Độ chính xác đo lường tỷ lệ dự đoán chính xác, và điểm F1 đại diện cho trung bình hài hòa của precision và recall.

Hiệu suất tổng thể Dựa trên kết quả đánh giá trong Bảng 1, LLaMA-7B được điều chỉnh hướng dẫn của chúng tôi (Instruct-FinGPT-7B) luôn vượt trội hơn cả FinBERT và LLaMA-7B trên tất cả ba tập dữ liệu về độ chính xác và điểm F1. Đặc biệt, so sánh Instruct-FinGPT-7B của chúng tôi với mô hình LLaMA-7B gốc (không có điều chỉnh hướng dẫn), rõ ràng rằng phương pháp điều chỉnh hướng dẫn cải thiện đáng kể hiệu suất của mô hình trong phân tích tình cảm tài chính.

Phân tích về độ nhạy cảm số Dữ liệu số đóng vai trò quan trọng trong phân tích tình cảm tài chính, vì nó thường phản ánh các chỉ số tài chính quan trọng. Trong Bảng 3, chúng tôi đánh giá khả năng của các mô hình trong việc hiểu và diễn giải tình cảm liên quan đến số.

• Ví dụ 1: Đây là một ví dụ từ FinBERT, nơi FinBERT thất bại trong trường hợp này. Tuy nhiên, ChatGPT 4.0 và Instruct-FinGPT đúng cách nhận ra sự giảm đáng kể trong tổn thất từ 2.2 triệu xuống 0.3 triệu, cho thấy tình cảm tích cực.

• Ví dụ 2: Sự tăng trong EPS được xác định đúng là tình cảm tích cực bởi tất cả các mô hình trừ FinBERT.

• Ví dụ 3: Việc vượt quá kỳ vọng tín dụng tiêu dùng và giá trị trước đó được nhận ra là tình cảm tích cực bởi tất cả các mô hình trừ FinBERT.

• Ví dụ 4: Tuyên bố về Estee Lauder và consensus FactSet là trung tính, vì nó chỉ đơn thuần nêu sự thật mà không chỉ ra tình cảm tích cực hay tiêu cực.

Mô hình của chúng tôi thể hiện các mức độ hiệu quả khác nhau trong việc hiểu và diễn giải tình cảm liên quan đến dữ liệu số.

Phân tích về hiểu biết ngữ cảnh Khả năng của mô hình chúng tôi trong việc diễn giải tình cảm trong các ngữ cảnh khác nhau là một khía cạnh quan trọng trong đánh giá hiệu suất. Tin tức tài chính có thể tinh tế, và một tuyên bố có thể xuất hiện tiêu cực trong một ngữ cảnh có thể trung tính hoặc thậm chí tích cực trong ngữ cảnh khác. Chúng tôi đánh giá hiệu suất của các mô hình trong hiểu biết ngữ cảnh dựa trên các ví dụ được cung cấp trong Bảng 4.

• Ví dụ 1: Đây là một ví dụ từ FinBERT, nơi FinBERT thất bại trong trường hợp này. Nhưng ChatGPT và Instruct-FinGPT nhận ra rằng tình hình của giấy in tạp chí tráng được dự kiến sẽ tiếp tục yếu, cho thấy triển vọng tiêu cực cho ngành công nghiệp. Khả năng hiểu ngôn ngữ của LLM và kiến thức về ngữ cảnh tài chính cho phép chúng diễn giải chính xác những tuyên bố như vậy và dự đoán tình cảm.

• Ví dụ 2: Trong trường hợp cụ thể này, cho thấy rằng Boeing đã nhận được nhiều đơn hàng hơn cho máy bay của họ. Nó trông giống như tin tức tích cực. Tuy nhiên, mà không có ngữ cảnh thêm, thật khó khăn để xác định tình cảm một cách chính xác. Việc thiếu chi tiết cụ thể về đơn hàng, khách hàng, hoặc bất kỳ tác động tiềm tàng nào có thể làm cho việc đánh giá tình cảm một cách chính xác trở nên khó khăn.

• Ví dụ 3: Tình cảm của tin tức tài chính là tích cực. Tuyên bố nhấn mạnh rằng Boeing đã giao 24 máy bay trong tháng 11, cho thấy một tháng thành công và hiệu quả cho công ty.

• Ví dụ 4: Tất cả các mô hình đều thất bại trong trường hợp này. Giá mở cửa của một cổ phiếu cao hơn giá IPO không nhất thiết cho thấy cổ phiếu đang tăng từ giá thị trường hiện tại của nó.

Nhìn chung, mô hình của chúng tôi thể hiện hiểu biết tốt hơn về tình cảm ngữ cảnh trong những ví dụ này so với FinBERT và ChatGPT. Nó thành công nhận ra tình cảm tiêu cực trong Ví dụ 1 và xác định chính xác tình cảm trung tính trong Ví dụ 2 và tình cảm tích cực trong Ví dụ 3. Những kết quả này làm nổi bật tầm quan trọng của hiểu biết ngữ cảnh trong phân tích tình cảm tài chính và các biến thể về hiệu suất giữa các mô hình khác nhau.

Khả năng khái quát hóa Zero-Shot đến các Tập dữ liệu Tài chính khác
Cuối cùng, chúng tôi đánh giá khả năng zero-shot của mô hình, đó là mức độ mà mô hình có thể khái quát hóa tới các tập dữ liệu tài chính chưa từng thấy khác. Một mô hình có khả năng zero-shot mạnh có thể cung cấp kết quả mạnh mẽ và linh hoạt hơn trong các ứng dụng thực tế. Chúng tôi so sánh Instruct-FinGPT của chúng tôi với ChatGPT3.5 và LLaMA-7B trên toàn bộ tập dữ liệu FPB. Ở đây chúng tôi không so sánh với FinBERT vì nó sử dụng FPB như tập huấn luyện.

Kết quả đánh giá được hiển thị trong Bảng 5. Dựa trên những kết quả này, có thể kết luận rằng mô hình LLaMA-7B được điều chỉnh hướng dẫn hoạt động tốt nhất trong ba mô hình, đạt được độ chính xác và điểm F1 cao nhất. Quá trình tinh chỉnh với dữ liệu hướng dẫn tình cảm dường như đã cải thiện khả năng của mô hình trong việc nắm bắt tình cảm trong các cụm từ tài chính, dẫn đến hiệu suất zero-shot tốt hơn so với cả ChatGPT và mô hình LLaMA-7B gốc.

5 Kết luận và công việc tương lai
Trong bài báo này, chúng tôi đã trình bày một phương pháp tiếp cận sáng tạo cho phân tích tình cảm tài chính bằng cách khai thác kiến thức chung và khả năng lý luận của LLM. Phương pháp của chúng tôi đại diện cho một đóng góp đáng kể cho lĩnh vực phân tích tình cảm, chứng minh rằng điều chỉnh hướng dẫn của một LLM có thể mang lại hiệu suất vượt trội với một lượng nhỏ dữ liệu cụ thể cho nhiệm vụ. Những phát hiện của chúng tôi mở đường cho nghiên cứu tương lai về tiềm năng của LLM cho một loạt rộng các nhiệm vụ tài chính.

Tuyên bố từ chối trách nhiệm: Chúng tôi đang chia sẻ mã nguồn cho mục đích học thuật dưới giấy phép giáo dục MIT. Không có nội dung nào ở đây là lời khuyên tài chính, và KHÔNG phải là khuyến nghị để giao dịch tiền thật. Vui lòng sử dụng lẽ thường và luôn tham khảo ý kiến chuyên gia trước khi giao dịch hoặc đầu tư.

Tài liệu tham khảo
[Araci, 2019] Dogu Araci. FinBERT: Financial sentiment analysis with pre-trained language models. In arXiv preprint arXiv:1908.10063, 2019.

[Atkins et al., 2018] Adam Atkins, Mahesan Niranjan, and Enrico Gerding. Financial news predicts stock market volatility better than close price. The Journal of Finance and Data Science, 4(2):120–137, 2018.

[Chan and Chong, 2017] Samuel WK Chan and Mickey WC Chong. Sentiment analysis in financial texts. Decision Support Systems, 94:53–64, 2017.

[Day and Lee, 2016] Min-Yuh Day and Chia-Chou Lee. Deep learning for financial sentiment analysis on finance news providers. In IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), pages 1127–1134. IEEE, 2016.

[Hamilton et al., 2016] William L Hamilton, Kevin Clark, Jure Leskovec, and Dan Jurafsky. Inducing domain-specific sentiment lexicons from unlabeled corpora. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), volume 2016, page 595. NIH Public Access, 2016.

[Kenton and Toutanova, 2019] Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of NAACL-HLT, pages 4171–4186, 2019.

[Loshchilov and Hutter, 2017] Ilya Loshchilov and Frank Hutter. Fixing weight decay regularization in adam. arXiv preprint arXiv:1711.05101, 2017.

[Loughran and McDonald, 2011] Tim Loughran and Bill McDonald. When is a liability not a liability? Textual analysis, dictionaries, and 10-Ks. The Journal of Finance, 66(1):35–65, 2011.

[Magic, 2022] Neural Magic. Twitter financial news sentiment. http://precog.iiitd.edu.in/people/anupama, 2022.

[Maia et al., 2018] Macedo Maia, Siegfried Handschuh, Andre Freitas, Brian Davis, Ross McDermott, Manel Zarrouk, and Alexandra. Balahur. Www '18: Companion proceedings of the the web conference 2018. In International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, CHE, 2018.

[Malo et al., 2014] Pekka Malo, Ankur Sinha, Pekka Korhonen, Jyrki Wallenius, and Pyry Takala. Good debt or bad debt: Detecting semantic orientations in economic texts. Journal of the Association for Information Science and Technology, 65(4):782–796, 2014.

[Mishev et al., 2020] Kostadin Mishev, Ana Gjorgjevikj, Irena Vodenska, Lubomir T Chitkushev, and Dimitar Trajanov. Evaluation of sentiment analysis in finance: from lexicons to transformers. IEEE Access, 8:131662–131682, 2020.

[Rasley et al., 2020] Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and Yuxiong He. Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters. In Association for Computing Machinery, KDD '20, page 3505–3506, New York, NY, USA, 2020.

[Shah et al., 2022] Raj Sanjay Shah, Kunal Chawla, Dheeraj Eidnani, Agam Shah, Wendi Du, Sudheer Chava, Natraj Raman, Charese Smiley, Jiaao Chen, and Diyi Yang. When flue meets flang: Benchmarks and large pretrained language model for financial domain. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics, 2022.

[Sohangir et al., 2018] Sahar Sohangir, Dingding Wang, Anna Pomeranets, and Taghi M Khoshgoftaar. Big data: Deep learning for financial sentiment analysis. Journal of Big Data, 5(1):1–25, 2018.

[Tai and Kao, 2013] Yen-Jen Tai and Hung-Yu Kao. Automatic domain-specific sentiment lexicon generation with label propagation. In Proceedings of International Conference on Information Integration and Web-based Applications & Services, pages 53–62, 2013.

[Touvron et al., 2023] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. LLaMA: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.

[Wei et al., 2022] Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. Finetuned language models are zero-shot learners. In International Conference on Learning Representations, 2022.

[Wu et al., 2023] Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann. BloombergGPT: A large language model for finance. arXiv preprint arXiv:2303.17564, 2023.

[Xing et al., 2018] Frank Z Xing, Erik Cambria, and Roy E Welsch. Natural language based financial forecasting: a survey. Artificial Intelligence Review, 50(1):49–73, 2018.

[Zhao et al., 2023] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. A survey of large language models, 2023.

# 2306.05443.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/finance/2306.05443.pdf
# Kích thước tệp: 355252 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
PIXIU: Một Mô hình Ngôn ngữ Lớn, Dữ liệu Hướng dẫn
và Chuẩn mực Đánh giá cho Tài chính
Qianqian Xie
Khoa Khoa học Máy tính
Đại học Wuhan
Wuhan, Hubei, Trung Quốc
xieq@whu.edu.cn

Weiguang Han
Khoa Khoa học Máy tính
Đại học Wuhan
Wuhan, Hubei, Trung Quốc
han.wei.guang@whu.edu.cn

Xiao Zhang
Đại học Zhongshan
Thâm Quyến, Quảng Đông, Trung Quốc
zhangx767@mail2.sysu.edu.cn

Yanzhao Lai
Khoa Kinh tế và Quản lý
Đại học Giao thông Tây Nam
Thành Đô, Tứ Xuyên, Trung Quốc
laiyanzhao@swjtu.edu.cn

Min Peng
Khoa Khoa học Máy tính
Đại học Wuhan
Wuhan, Hubei, Trung Quốc
pengm@whu.edu.cn

Alejandro Lopez-Lira
Đại học Florida
alejandro.lopez-lira@warrington.ufl.edu

Jimin Huang
ChanceFocus AMC.
Thượng Hải, Trung Quốc
jimin@chancefocus.com

Tóm tắt
Mặc dù các mô hình ngôn ngữ lớn (LLM) đã cho thấy hiệu suất tuyệt vời trong xử lý ngôn ngữ tự nhiên (NLP) trong lĩnh vực tài chính, nhưng không có LLM được điều chỉnh riêng cho tài chính, tập dữ liệu điều chỉnh hướng dẫn và chuẩn mực đánh giá có sẵn công khai, điều này quan trọng để liên tục thúc đẩy phát triển mã nguồn mở của trí tuệ nhân tạo (AI) tài chính. Bài báo này giới thiệu PIXIU, một khung toàn diện bao gồm LLM tài chính đầu tiên dựa trên việc tinh chỉnh LLaMA với dữ liệu hướng dẫn, dữ liệu hướng dẫn đầu tiên với 136K mẫu dữ liệu để hỗ trợ tinh chỉnh, và một chuẩn mực đánh giá với 5 nhiệm vụ và 9 tập dữ liệu. Đầu tiên, chúng tôi xây dựng dữ liệu hướng dẫn đa nhiệm vụ quy mô lớn xem xét nhiều nhiệm vụ tài chính, loại tài liệu tài chính và phương thức dữ liệu tài chính khác nhau. Sau đó, chúng tôi đề xuất một LLM tài chính gọi là FinMA bằng cách tinh chỉnh LLaMA với tập dữ liệu được xây dựng để có thể tuân theo hướng dẫn cho các nhiệm vụ tài chính khác nhau. Để hỗ trợ việc đánh giá các LLM tài chính, chúng tôi đề xuất một chuẩn mực tiêu chuẩn bao gồm một tập hợp các nhiệm vụ tài chính quan trọng, bao gồm năm nhiệm vụ NLP tài chính và một nhiệm vụ dự đoán tài chính. Với chuẩn mực này, chúng tôi tiến hành phân tích chi tiết về FinMA và một số LLM hiện có, khám phá điểm mạnh và điểm yếu của chúng trong việc xử lý các nhiệm vụ tài chính quan trọng. Mô hình, tập dữ liệu, chuẩn mực và kết quả thực nghiệm được mã nguồn mở để hỗ trợ nghiên cứu trong tương lai về AI tài chính.

1https://github.com/chancefocus/PIXIU
Bản thảo. Đang được xem xét.arXiv:2306.05443v1 [cs.CL] 8 Jun 2023

--- TRANG 2 ---
1 Giới thiệu
Công nghệ tài chính (FinTech) đã được tiến bộ liên tục nhờ sự phát triển của các kỹ thuật xử lý ngôn ngữ tự nhiên (NLP) và học máy (ML), mở ra khả năng đa dạng từ dự đoán biến động giá cổ phiếu đến phân tích tài chính tiên tiến (Araci, 2019; Han et al., 2023a; Xie et al., 2023; Lopez-Lira và Tang, 2023; Li et al., 2023). Cụ thể, các mô hình ngôn ngữ lớn (LLM) gần đây nhất (Brown et al., 2020)² đã thể hiện khả năng đáng chú ý trong hiểu ngôn ngữ tự nhiên (NLU) và thực hiện các nhiệm vụ khác nhau bằng cách tuân theo hướng dẫn ngôn ngữ tự nhiên mà không cần dữ liệu huấn luyện. Mặc dù có những thành công này, bản chất kỹ thuật cao của văn bản tài chính đòi hỏi các LLM chuyên biệt theo lĩnh vực để hiểu ngôn ngữ và khái niệm tài chính phức tạp một cách hiệu quả. Những nỗ lực như vậy bao gồm các mô hình ngôn ngữ được huấn luyện trước (PLM) tài chính hiện có như finBERT (Araci, 2019), FinBERT (Yang et al., 2020) và FLANG (Shah et al., 2022). Tuy nhiên, những mô hình này được coi là nhỏ vì kích thước tham số của chúng dưới một tỷ, hạn chế khả năng tổng quát hóa. Gần đây, một LLM tài chính độc quyền gọi là BloombergGPT (Wu et al., 2023) với 50 tỷ tham số đã được đề xuất bằng cách huấn luyện trước một LLM kiểu Bloom (Scao et al., 2022) trên dữ liệu tài chính quy mô lớn.

Mặc dù có những nỗ lực này, vẫn còn một số vấn đề, như được trình bày trong Bảng 1. Thứ nhất, BloombergGPT và dữ liệu huấn luyện của nó không được phát hành công khai. Hiện tại, không có LLM tài chính mã nguồn mở nào, điều này có thể cản trở sự phát triển trong cộng đồng nghiên cứu. Thứ hai, các PLM tài chính trước đây và BloombergGPT mới nhất không được tinh chỉnh để tuân theo hướng dẫn ngôn ngữ tự nhiên (còn gọi là điều chỉnh hướng dẫn), điều này quan trọng để cải thiện khả năng zero-shot trong việc xử lý các nhiệm vụ tài chính downstream (Wei et al., 2021; Ouyang et al., 2022). Thứ ba, cũng không có dữ liệu hướng dẫn tài chính để hỗ trợ điều chỉnh hướng dẫn của LLM và chuẩn mực đánh giá để đánh giá và so sánh toàn diện khả năng của LLM cho các nhiệm vụ tài chính. Do đó, chúng tôi được thúc đẩy để xem xét các câu hỏi nghiên cứu sau: 1) làm thế nào chúng ta có thể phát triển các LLM hiệu quả và có sẵn công khai được điều chỉnh riêng cho tài chính? 2) làm thế nào chúng ta có thể xây dựng dữ liệu hướng dẫn tài chính quy mô lớn và chất lượng cao? 3) làm thế nào chúng ta có thể xây dựng chuẩn mực đánh giá tài chính toàn diện để đánh giá các LLM tài chính?

Bảng 1: So sánh các mô hình ngôn ngữ được huấn luyện trước và các mô hình ngôn ngữ lớn cho tài chính.
"Instruct" có nghĩa là mô hình có thể tuân theo hướng dẫn hay không. "NLP" và "Fin" có nghĩa là mô hình có được đánh giá với các nhiệm vụ NLP tài chính và nhiệm vụ dự đoán tài chính hay không.

Mô hình | Backbone | Kích thước | Mã nguồn mở | Dữ liệu | Instruct | Ngôn ngữ | Đánh giá | Ngày phát hành
       |         |            | Mô hình | Dữ liệu |         |          | NLP | Fin |
finBERT (Araci, 2019) | BERT | 110M | ✓ | ✓ | ✗ | Tiếng Anh | ✓ | ✗ | 08/27/19
FinBERT (Yang et al., 2020) | BERT | 110M | ✓ | ✗ | ✗ | Tiếng Anh | ✓ | ✗ | 06/15/20
Mengzi-fin (Zhang et al., 2021) | RoBERTa | 103M | ✓ | ✗ | ✗ | Tiếng Trung | ✓ | ✗ | 10/13/21
FLANG (Shah et al., 2022) | ELECTRA | 110M | ✓ | ✓ | ✗ | Tiếng Anh | ✓ | ✗ | 10/31/22
BBT-FinT5 (Lu et al., 2023) | T5 | 220M | ✓ | ✓ | ✗ | Tiếng Trung | ✓ | ✗ | 02/18/23
BloombergGPT (Wu et al., 2023) | BLOOM | 50B | ✗ | ✗ | ✗ | Tiếng Anh | ✓ | ✗ | 03/30/23
FinMA | LLaMA | 7/13B | ✓ | ✓ | ✓ | Tiếng Anh | ✓ | ✓ | 06/01/23

Để giải quyết những câu hỏi nghiên cứu này, chúng tôi đề xuất PIXIU (貔貅)³, một khung toàn diện bao gồm LLM tài chính đầu tiên, FinMA, dựa trên việc tinh chỉnh LLaMA (Touvron et al., 2023) với dữ liệu hướng dẫn đa nhiệm vụ và đa phương thức. Hình 1 trình bày tổng quan về điều chỉnh hướng dẫn đa nhiệm vụ và đa phương thức của FinMA cho các nhiệm vụ tài chính đa dạng. PIXIU cũng chứa dữ liệu hướng dẫn đầu tiên với 136K mẫu dữ liệu để hỗ trợ tinh chỉnh và một chuẩn mực đánh giá toàn diện với bốn nhiệm vụ NLP tài chính và một nhiệm vụ dự đoán tài chính. Nó có các tính năng đặc biệt sau:

• Tài nguyên mở. Chúng tôi đã phát hành công khai LLM tài chính, dữ liệu điều chỉnh hướng dẫn, và các tập dữ liệu được bao gồm trong chuẩn mực đánh giá, và triển khai, để khuyến khích nghiên cứu mở và minh bạch trong lĩnh vực nghiên cứu.

• Đa nhiệm vụ. PIXIU bao gồm dữ liệu điều chỉnh hướng dẫn đa nhiệm vụ bao gồm một tập hợp đa dạng các nhiệm vụ tài chính, bao gồm bốn nhiệm vụ NLP tài chính và một nhiệm vụ dự đoán tài chính. Điều chỉnh hướng dẫn đa nhiệm vụ đã được chứng minh là quan trọng để cải thiện khả năng tổng quát hóa của mô hình (Sanh et al., 2022; Longpre et al., 2023) cho các nhiệm vụ mới.

²https://openai.com/blog/chatgpt
³PIXIU (貔貅) https://en.wikipedia.org/wiki/Pixiu là một sinh vật thần thoại trong văn hóa dân gian Trung Quốc. Nó có đầu rồng và thân sư tử và được tin là một sinh vật may mắn thu hút tiền bạc và tài lộc.

--- TRANG 3 ---
• Đa phương thức. Dữ liệu điều chỉnh hướng dẫn của chúng tôi bao gồm dữ liệu tài chính đa phương thức như bảng trong báo cáo tài chính và giá cổ phiếu lịch sử dưới dạng dữ liệu chuỗi thời gian cho các nhiệm vụ dự đoán biến động cổ phiếu ngoài văn bản. Hơn nữa, chúng bao gồm các loại văn bản tài chính đa dạng, bao gồm báo cáo, bài báo tin tức, tweet và hồ sơ quy định.

• Đa dạng. So với các nhiệm vụ đánh giá được sử dụng trong BloombergGPT và chuẩn mực FLUE hiện có (Shah et al., 2022), chủ yếu bao gồm các nhiệm vụ NLP tài chính, chuẩn mực đánh giá của chúng tôi bao gồm các nhiệm vụ dự đoán biến động cổ phiếu. Nó đòi hỏi mô hình phải khai thác đầy đủ cả văn bản tự nhiên và dữ liệu chuỗi thời gian để trích xuất thông tin thiết yếu cho dự đoán chính xác. So với các nhiệm vụ NLP tài chính, nhiệm vụ dự đoán tài chính phù hợp hơn với các tình huống thực tế và thử thách hơn.

Để xây dựng dữ liệu hướng dẫn đa nhiệm vụ và đa phương thức, chúng tôi thu thập dữ liệu huấn luyện được phát hành công khai từ các nhiệm vụ đa dạng, bao gồm phân tích tâm lý tài chính, phân loại tiêu đề tin tức, nhận dạng thực thể có tên, hỏi đáp, và dự đoán biến động cổ phiếu, và đề xuất các hướng dẫn cụ thể theo nhiệm vụ đa dạng được viết bởi các chuyên gia lĩnh vực cho từng nhiệm vụ. Chúng tôi tạo ra dữ liệu điều chỉnh hướng dẫn quy mô lớn FIT bằng cách kết hợp các hướng dẫn cụ thể theo nhiệm vụ với các mẫu dữ liệu từ mỗi nhiệm vụ. Do đó, chúng tôi đề xuất LLM chuyên biệt theo lĩnh vực FinMA bằng cách tiến hành điều chỉnh hướng dẫn đa nhiệm vụ trên LLaMA với tập dữ liệu được xây dựng. Để đánh giá mô hình của chúng tôi và các LLM khác một cách toàn diện, chúng tôi xây dựng Chuẩn mực Đánh giá Hiểu và Dự đoán Ngôn ngữ Tài chính (FLARE) bao gồm 4 nhiệm vụ NLP tài chính với 6 tập dữ liệu, và 1 nhiệm vụ dự đoán tài chính với 3 tập dữ liệu.

Dựa trên FLARE, chúng tôi đánh giá hiệu suất của mô hình của chúng tôi, BloombergGPT, và các LLM tiên tiến trong lĩnh vực tổng quát, như ChatGPT⁴ và GPT-4 (OpenAI, 2023). Kết quả thực nghiệm cho thấy: 1) FinMA vượt trội đáng kể so với các LLM, bao gồm BloombergGPT, ChatGPT, và GPT-4 trong hầu hết các nhiệm vụ trong FLARE, bao gồm phân tích tâm lý tài chính, phân loại tiêu đề tin tức, NER, và dự đoán biến động cổ phiếu. Điều này chứng minh tầm quan trọng của việc điều chỉnh các LLM cụ thể cho lĩnh vực tài chính. 2) Mặc dù có kết quả hứa hẹn trong hầu hết các nhiệm vụ, FinMA có hiệu suất thấp hơn BloombergGPT, ChatGPT, và GPT-4 trong hỏi đáp, điều này đánh giá khả năng lý luận định lượng của LLM. Phân tích của chúng tôi phát hiện rằng điều này do hạn chế của LLaMA trong lý luận định lượng và toán học. 3) So với các nhiệm vụ NLP, tất cả LLM, bao gồm FinMA, ChatGPT và GPT-4, vẫn có hiệu suất hạn chế trong dự đoán biến động cổ phiếu, cho thấy còn chỗ để cải thiện thêm. 4) FinMA được tinh chỉnh với cả nhiệm vụ NLP và dự đoán tài chính, có hiệu suất tốt nhất trên một trong các tập dữ liệu dự đoán cổ phiếu, cho thấy tiềm năng của điều chỉnh hướng dẫn cụ thể theo nhiệm vụ của LLM trong các nhiệm vụ dự đoán tài chính.

Đóng góp của chúng tôi có thể được tóm tắt như sau: 1) Chúng tôi giới thiệu FIT, dữ liệu điều chỉnh hướng dẫn đa nhiệm vụ và đa phương thức đầu tiên trong lĩnh vực tài chính, bao gồm 5 nhiệm vụ và 9 tập dữ liệu với 136.609 (136K) mẫu dữ liệu. 2) Chúng tôi giới thiệu FLARE, chuẩn mực đánh giá đầu tiên với cả nhiệm vụ hiểu ngôn ngữ tự nhiên và dự đoán tài chính. 3) Chúng tôi giới thiệu FinMA, mô hình ngôn ngữ lớn tài chính đầu tiên được phát hành công khai và tuân theo hướng dẫn, đạt SOTA trên 3 nhiệm vụ NLP tài chính và 1 nhiệm vụ dự đoán tài chính. 4) Chúng tôi so sánh FinMA và các LLM hiện có trên FLARE. Kết quả chứng minh tính ưu việt của FinMA, các hạn chế chính của LLM cho tài chính, và hướng phát triển trong tương lai để tiến bộ LLM cho tài chính.

2 Nghiên cứu liên quan
Mô hình Ngôn ngữ Tài chính Nhiều PLM cho lĩnh vực tài chính đã được đề xuất bằng cách tiếp tục huấn luyện trước PLM với văn bản tài chính quy mô lớn. Araci (2019) đề xuất PLM tài chính đầu tiên gọi là finBERT đã huấn luyện trước BERT (Kenton và Toutanova, 2019) với corpus tài chính được phát hành công khai như TRC2-financial⁵ và Financial Phrase Bank (Malo et al., 2014). finBERT vượt trội hơn các phương pháp mạng neural như LSTM trong các nhiệm vụ phân loại tâm lý tài chính. Yang et al. (2020) tiếp tục đề xuất FinBERT bằng cách huấn luyện trước BERT với corpus giao tiếp tài chính 4.9 tỷ token, vượt trội hơn BERT trên ba tập dữ liệu phân loại tâm lý tài chính. Shah et al. (2022) đề xuất FLANG, một PLM tài chính với BERT và ELECTRA (Clark et al., 2020) làm backbone. Ngoài tiếng Anh, các PLM tài chính bằng ngôn ngữ khác, như tiếng Trung, cũng được đề xuất, như Mengzi-fin (Zhang et al., 2021) và BBT-FinT5 (Lu et al., 2023). Gần đây nhất, Wu et al. (2023) đề xuất BloombergGPT, mô hình ngôn ngữ lớn tài chính đầu tiên với 50 tỷ tham số, được huấn luyện trước với các tập dữ liệu hỗn hợp từ lĩnh vực tổng quát và tài chính. Tuy nhiên, cả mô hình và các tập dữ liệu lĩnh vực được huấn luyện trước đều không được phát hành. Mô hình cũng không tuân theo hướng dẫn như các LLM khác như ChatGPT và GPT-4.

Chuẩn mực Đánh giá Tài chính Shah et al. (2022) đề xuất chuẩn mực đánh giá không đồng nhất đầu tiên FLUE với 5 nhiệm vụ NLP tài chính, bao gồm phân tích tâm lý tài chính (Malo et al., 2014), phân loại tiêu đề tin tức (Sinha và Khandait, 2021), nhận dạng thực thể có tên (Alvarado et al., 2015), phát hiện biên giới cấu trúc⁶ và hỏi đáp (Maia et al., 2018). Lu et al. (2023) đề xuất chuẩn mực đánh giá tài chính Trung Quốc đầu tiên BBT-CFLEB⁷ với phân loại tin tức tài chính, tóm tắt, trích xuất quan hệ, hỏi đáp, và nhiệm vụ xác định tin tức tiêu cực, cũng như nhiệm vụ phân loại tâm lý của văn bản mạng xã hội tài chính. Tuy nhiên, những chuẩn mực này chỉ xem xét các nhiệm vụ NLP tài chính và không bao gồm các nhiệm vụ dự đoán tài chính, như dự đoán biến động cổ phiếu (Soun et al., 2022) hoặc giao dịch cặp (Han et al., 2023b) quan trọng để đánh giá hiệu suất của mô hình được áp dụng trong các tình huống thực tế.

Mô hình Ngôn ngữ Lớn Mã nguồn Mở Các nghiên cứu gần đây đã nỗ lực về AI dân chủ, trong đó công trình đại diện là LLaMA (Touvron et al., 2023) từ Meta AI, một LLM mã nguồn mở với tham số từ 7B và 13B đến 65B. LLaMA-13B có hiệu suất tương đương và thậm chí tốt hơn GPT-3 (Brown et al., 2020) với 175B tham số trong các nhiệm vụ lý luận thông thường. Các nỗ lực tiếp theo đã được đề xuất để cải thiện LLaMA để tuân theo hướng dẫn như ChatGPT, bằng điều chỉnh hướng dẫn. Như Taori et al. (2023) đề xuất Alpaca bằng cách tinh chỉnh LLaMA-7B với 52K mẫu tuân theo hướng dẫn được tạo ra bằng phương pháp self-instruct (Wang et al., 2022). Chiang et al. (2023) đề xuất Vicuna-13B bằng cách tinh chỉnh LLaMA-13B với 70K dữ liệu hội thoại từ ShareGPT⁸. Nó có thể tạo ra câu trả lời tốt hơn cho câu hỏi của người dùng so với Alpaca. Tuy nhiên, không có LLM mã nguồn mở và dữ liệu điều chỉnh hướng dẫn nào tập trung vào lĩnh vực tài chính.

3 FIT: Tập dữ liệu Điều chỉnh Hướng dẫn Tài chính
Trong phần này, chúng tôi giới thiệu tập dữ liệu điều chỉnh hướng dẫn tài chính FIT, bao gồm bối cảnh dữ liệu thô, các nhiệm vụ trong FIT, và quy trình xây dựng dựa trên dữ liệu thô. Khác với các tập dữ liệu tài chính hiện có, FIT là tập dữ liệu điều chỉnh hướng dẫn đầu tiên cho LLM tài chính và bao gồm dự đoán biến động cổ phiếu ngoài các nhiệm vụ NLP tài chính, điều này cơ bản cho các ứng dụng tài chính thực tế.

3.1 Dữ liệu thô
Xuất phát từ các tình huống tài chính thực tế, chúng tôi xây dựng tập dữ liệu điều chỉnh hướng dẫn tài chính FIT dựa trên dữ liệu mã nguồn mở của các nhiệm vụ NLP và dự đoán tài chính khác nhau. So với phương pháp self-instruct (Wang et al., 2022) thường được sử dụng bởi các LLM hiện có như Alpaca, chúng tôi chọn xây dựng tập dữ liệu điều chỉnh hướng dẫn từ các tập dữ liệu mã nguồn mở vì những lý do sau: 1) các tập dữ liệu mã nguồn mở thường được chú thích bởi các chuyên gia lĩnh vực, cho thấy chất lượng cao, 2) có chi phí rất thấp và không có hạn chế về sử dụng thương mại không như các tập dữ liệu được xây dựng từ ChatGPT hoặc GPT-4, 3) các tập dữ liệu mã nguồn mở này bao gồm nhiều loại văn bản như tin tức, báo cáo và tweet, cũng như đa phương thức bao gồm dữ liệu chuỗi thời gian, bảng và văn bản. Chi tiết⁹ về dữ liệu thô và dữ liệu hướng dẫn được trình bày trong Bảng 2.

Phân tích Tâm lý Tài chính. Nhiệm vụ phân tích tâm lý tài chính từ lâu đã là một nhiệm vụ quan trọng trong lĩnh vực tài chính (Araci, 2019; Yang et al., 2020), nhằm phân tích thông tin tâm lý của văn bản tài chính đầu vào. Theo chuẩn mực FLUE hiện có (Shah et al., 2022), chúng tôi sử dụng hai tập dữ liệu: tập dữ liệu Financial Phrase Bank (FPB) (Malo et al., 2014) và FiQA-SA (Maia et al., 2018). FPB bao gồm các câu tiếng Anh từ tin tức tài chính và nhãn tâm lý tích cực, tiêu cực, hoặc trung tính được chú thích bởi các chuyên gia lĩnh vực. FiQA-SA là một tập dữ liệu được áp dụng rộng rãi khác, nhằm dự đoán tâm lý của tin tức tài chính và bài đăng microblog tiếng Anh trên thang điểm [-1,1], trong đó 1 có nghĩa là tích cực nhất.

⁴https://openai.com/blog/chatgpt
⁵https://trec.nist.gov/data/reuters/reuters.html
⁶https://sites.google.com/nlg.csie.ntu.edu.tw/finweb2021/shared-task-finsbd-3
⁷https://bbt.ssymmetry.com/evaluation.html
⁸https://sharegpt.com
⁹Để biết thêm chi tiết về phân chia dữ liệu và tiền xử lý, vui lòng tham khảo Phụ lục

--- TRANG 4 ---
Bảng 2: Chi tiết về dữ liệu thô và dữ liệu hướng dẫn.

Dữ liệu | Nhiệm vụ | Thô | Dữ liệu hướng dẫn | Loại | Phương thức | Giấy phép
FPB | phân tích tâm lý | 4.845 | 48.450 | tin tức | văn bản | CC BY-SA 3.0
FiQA-SA | phân tích tâm lý | 1.173 | 11.730 | tiêu đề tin tức, tweets | văn bản | Công cộng
Headline | phân loại tiêu đề tin tức | 11.412 | 11.412 | tiêu đề tin tức | văn bản | CC BY-SA 3.0
NER | nhận dạng thực thể có tên | 1.366 | 13.660 | thỏa thuận tài chính | văn bản | CC BY-SA 3.0
FinQA | hỏi đáp | 8.281 | 8.281 | báo cáo thu nhập | văn bản, bảng | Giấy phép MIT
ConvFinQA | hỏi đáp | 3.892 | 3.892 | báo cáo thu nhập | văn bản, bảng | Giấy phép MIT
BigData22 | dự đoán biến động cổ phiếu | 7.164 | 7.164 | tweets, giá lịch sử | văn bản, chuỗi thời gian | Công cộng
ACL18 | dự đoán biến động cổ phiếu | 27.053 | 27.053 | tweets, giá lịch sử | văn bản, chuỗi thời gian | Giấy phép MIT
CIKM18 | dự đoán biến động cổ phiếu | 4.967 | 4.967 | tweets, giá lịch sử | văn bản, chuỗi thời gian | Công cộng

Phân loại Tiêu đề Tin tức. Nhiệm vụ phân loại tiêu đề tin tức nhằm phân tích thông tin khác, như biến động giá trong văn bản tài chính. Chúng tôi sử dụng tập dữ liệu tiêu đề tin tức Gold (Sinha và Khandait, 2021) bao gồm tiêu đề tin tức từ năm 2000 đến 2019 về "vàng" và 9 thẻ tương ứng: "giá hoặc không", "giá tăng", "giá giảm", "giá ổn định", "giá quá khứ", "giá tương lai", "tổng quát quá khứ", "tổng quát tương lai", "so sánh tài sản". Nhiệm vụ là tiến hành phân loại nhị phân cho mỗi thẻ của mỗi mẫu dữ liệu.

Nhận dạng Thực thể Có tên. Nhiệm vụ Nhận dạng Thực thể Có tên (NER) là phát hiện các thực thể tài chính quan trọng như người, tổ chức và địa điểm, có thể được sử dụng để xây dựng đồ thị tri thức tài chính. Chúng tôi sử dụng tập dữ liệu FIN (Alvarado et al., 2015) bao gồm các câu từ thỏa thuận tài chính công khai thông qua hồ sơ Ủy ban Chứng khoán và Giao dịch Hoa Kỳ (SEC) và các loại thực thể được chú thích thủ công từ ĐỊA ĐIỂM (LOC), TỔ CHỨC (ORG) và NGƯỜI (PER).

Hỏi đáp. Hỏi đáp là nhiệm vụ tự động trả lời câu hỏi tài chính dựa trên thông tin được cung cấp. Chúng tôi sử dụng hai tập dữ liệu: FinQA (Chen et al., 2021) và ConvFinQA (Chen et al., 2022). FinQA bao gồm các cặp câu hỏi-câu trả lời được chú thích bởi các chuyên gia và báo cáo thu nhập tương ứng (bao gồm tài liệu không có cấu trúc và bảng) từ các công ty S&P 500. ConvFinQA là phần mở rộng của FinQA có cuộc hội thoại với câu hỏi và câu trả lời đa lượt về báo cáo thu nhập.

Dự đoán Biến động Cổ phiếu. Là một trong những nhiệm vụ tài chính cơ bản, dự đoán biến động cổ phiếu có giá trị tiềm năng lớn trong các ứng dụng thực tế như chiến lược đầu tư. Theo công trình trước đây (Soun et al., 2022), chúng tôi đóng khung nhiệm vụ như một vấn đề phân loại nhị phân, đó là dự đoán biến động giá cổ phiếu nhị phân dựa trên giá cổ phiếu lịch sử và tweet. Nếu biến động giá cao hơn 0,55%, nó sẽ được gán cho mẫu tích cực (1), hoặc mẫu tiêu cực (-1) nếu thấp hơn -0,5%. Chúng tôi áp dụng ba tập dữ liệu thường được sử dụng: BigData22 (Soun et al., 2022), ACL18 (Xu và Cohen, 2018), và CIKM18 (Wu et al., 2018).

3.2 Xây dựng hướng dẫn
Dựa trên các tập dữ liệu thô, chúng tôi tiếp tục xây dựng các tập dữ liệu hướng dẫn tài chính, có thống kê được trình bày trong Bảng 2. Chúng tôi yêu cầu các chuyên gia lĩnh vực viết 10 hướng dẫn đa dạng cho tất cả các tập dữ liệu trừ ConvFinQA, nơi chúng tôi chỉ sử dụng một hướng dẫn. Vì ConvFinQA là tập dữ liệu hỏi đáp hội thoại đa lượt, có các câu hỏi đa dạng như hướng dẫn về bản chất. Đối với BigData22, ACL18, CIKM18, chúng tôi sử dụng cùng một tập hướng dẫn, vì chúng có cùng loại dữ liệu đầu vào và công thức nhiệm vụ. Chúng tôi hiển thị các ví dụ hướng dẫn trong Bảng 3. Dựa trên những lời nhắc này, chúng tôi chuyển đổi các tập dữ liệu thô từ các nhiệm vụ này thành các mẫu điều chỉnh hướng dẫn, bằng cách thu thập các hướng dẫn được thiết kế bởi con người, và văn bản đầu vào cùng với phản hồi của mỗi tập dữ liệu. Đối với các tập dữ liệu FPB, FiQA-SA, Headline, NER, BigData22, ACL18, và CIKM18, chúng tôi xây dựng các mẫu điều chỉnh hướng dẫn với mẫu sau:

Hướng dẫn: [lời nhắc nhiệm vụ] Văn bản: [văn bản đầu vào] Phản hồi: [đầu ra]

[lời nhắc nhiệm vụ] là lời nhắc được thiết kế cho mỗi dữ liệu, [văn bản đầu vào] là dữ liệu tài chính đầu vào từ mỗi dữ liệu, ví dụ: giá lịch sử và tweet cho các tập dữ liệu dự đoán biến động cổ phiếu, [đầu ra] là đầu ra tương ứng cho văn bản đầu vào, ví dụ: nhãn tâm lý của văn bản đầu vào từ ["Tích cực", "Tiêu cực", "Trung tính"] trong tập dữ liệu FiQA-SA. Đối với FPB, FiQA-SA, và NER, do kích thước dữ liệu hạn chế, chúng tôi sử dụng tất cả 10 hướng dẫn cho mỗi mẫu, trong khi chúng tôi lấy mẫu ngẫu nhiên một hướng dẫn cho mỗi mẫu trong các tập dữ liệu Headline, BigData22, ACL18, và CIKM18.

--- TRANG 5 ---
Bảng 3: Ví dụ lời nhắc cho mỗi tập dữ liệu. FiQA-SA có hai loại văn bản, bao gồm tiêu đề tin tức và tweet. Chúng tôi sẽ điền loại văn bản chi tiết vào {category} cho mỗi mẫu dữ liệu. Đối với dữ liệu dự đoán biến động cổ phiếu như BigData22, chúng tôi sẽ điền {tid} và {point} với tên cổ phiếu và thời gian chi tiết từ mỗi mẫu dữ liệu.

Dữ liệu | Lời nhắc
FPB | "Phân tích tâm lý của phát biểu này được trích xuất từ một bài báo tin tức tài chính. Đưa ra câu trả lời của bạn là tiêu cực, tích cực hoặc trung tính. Ví dụ, 'Cổ phiếu của công ty lao dốc sau vụ bê bối.' sẽ được phân loại là tiêu cực."
FiQA-SA | "Tâm lý của {category} tài chính sau đây là gì: Tích cực, Tiêu cực, hoặc Trung tính?"
Headline | "Xem xét liệu tiêu đề có đề cập đến giá vàng hay không. Có Giá hay Không trong thị trường hàng hóa vàng được chỉ ra trong tiêu đề tin tức? Vui lòng trả lời Có hoặc Không."
NER | "Trong các câu được trích xuất từ thỏa thuận tài chính trong hồ sơ SEC của Hoa Kỳ, xác định các thực thể có tên đại diện cho một người ('PER'), một tổ chức ('ORG'), hoặc một địa điểm ('LOC'). Định dạng câu trả lời yêu cầu là: 'tên thực thể, loại thực thể'. Ví dụ, trong 'Elon Musk, CEO của SpaceX, thông báo phóng từ Cape Canaveral.', các thực thể sẽ là: 'Elon Musk, PER; SpaceX, ORG; Cape Canaveral, LOC'"
FinQA | "Dựa trên dữ liệu tài chính và phân tích chuyên gia, vui lòng trả lời câu hỏi này:"
ConvFinQA | "Trong bối cảnh chuỗi câu hỏi liên quan đến tài chính được kết nối với nhau này và thông tin bổ sung được cung cấp bởi tiền văn, dữ liệu bảng, và văn bản sau từ hồ sơ tài chính của công ty, vui lòng đưa ra phản hồi cho câu hỏi cuối cùng. Điều này có thể yêu cầu trích xuất thông tin từ bối cảnh và thực hiện tính toán toán học. Vui lòng tính đến thông tin được cung cấp trong các câu hỏi trước đó và câu trả lời của chúng khi xây dựng phản hồi của bạn:"
BigData22 | "Phân tích thông tin và bài đăng mạng xã hội để xác định liệu giá đóng cửa của {tid} sẽ tăng hay giảm vào {point}. Vui lòng trả lời bằng Rise hoặc Fall."

Trong các câu được trích xuất từ thỏa thuận tài chính trong hồ sơ SEC của Hoa Kỳ, xác định các thực thể có tên đại diện cho một người ("PER"), một tổ chức ("ORG"), hoặc một địa điểm ("LOC"). Định dạng câu trả lời yêu cầu là: "tên thực thể, loại thực thể". Ví dụ, trong "Elon Musk, CEO của SpaceX, thông báo phóng từ Cape Canaveral.", các thực thể sẽ là:
Elon Musk, PER
SpaceX, ORG
Cape Canaveral, LOC

Văn bản: Thỏa thuận cho vay và bảo đảm này ngày 27 tháng 1 năm 1999, giữa SILICON VALLEY BANK ("Bank"), một ngân hàng được cấp phép tại California với trụ sở chính tại 3003 Tasman Drive, Santa Clara, California 95054 với văn phòng sản xuất cho vay tại 40 William St., Ste.
Trả lời:

Suy nghĩ về dữ liệu và tweet để đoán liệu giá đóng cửa của $ba sẽ tăng hay giảm vào 2020-11-02. Vui lòng tuyên bố Rise hoặc Fall.

Bối cảnh: date,open,high,low,close,adj-close,inc-5,inc-10,inc-15,inc-20,inc-25,inc-30
2020-10-19,1.2,2.2,-0.6,-0.1,-0.1,-1.4,-1.2,-0.8,-2.4,-2.4,-2.6
...
Trả lời:

Phân tích tâm lý của phát biểu này được trích xuất từ một bài báo tin tức tài chính. Đưa ra câu trả lời của bạn là tiêu cực, tích cực hoặc trung tính. Ví dụ, "Cổ phiếu của công ty lao dốc sau vụ bê bối." sẽ được phân loại là tiêu cực.

Cổ phiếu của Standard Chartered (STAN) tăng 1,2% trong FTSE 100, trong khi cổ phiếu Royal Bank of Scotland (RBS) tăng 2% và cổ phiếu Barclays (BARC) (BCS) tăng 1,7%.
...

SILICON VALLEY BANK, ORG
Bank, ORG
California, LOC
bank, ORG
3003 Tasman Drive, LOC
Santa Clara, LOC
California, LOC
40 William St, LOC

Tích cực

Rise
...

FinMA
NER
FPB
BigData22
NER
FPB
BigData22

Hình 1: Tổng quan về điều chỉnh hướng dẫn đa nhiệm vụ và đa phương thức của FinMA cho các nhiệm vụ tài chính đa dạng.

Đối với FinQA và ConvFinQA, chúng tôi sử dụng mẫu sau:
Hướng dẫn: [lời nhắc nhiệm vụ] Bối cảnh: [bối cảnh đầu vào] Câu hỏi: [câu hỏi đầu vào] Phản hồi: [câu trả lời]

[bối cảnh đầu vào] là thông tin bối cảnh đầu vào cho mỗi mẫu dữ liệu. Ví dụ, bối cảnh đầu vào có thể được điền với văn bản và bảng từ các tệp điền cho FinQA. ConvFinQA có cuộc hội thoại đa lượt với câu hỏi và câu trả lời. Do đó, chúng tôi sử dụng mẫu sau: Chúng tôi chuyển đổi mỗi lượt hội thoại cho mỗi mẫu dữ liệu thành một hướng dẫn thông qua mẫu, sẽ thêm các câu hỏi và câu trả lời trước đó vào [bối cảnh đầu vào].

4 FinMA: Mô hình Ngôn ngữ Lớn Tài chính
Chúng tôi tiếp tục xây dựng FinMA bằng cách tinh chỉnh LLaMA (Touvron et al., 2023) với FIT. Chúng tôi huấn luyện ba mô hình: FinMA-7B và FinMA-30B bằng cách tinh chỉnh checkpoint LLaMA 7B và 30B với dữ liệu điều chỉnh hướng dẫn bao gồm các nhiệm vụ NLP, và FinMA-7B-full bằng cách tinh chỉnh LLaMA 7B với dữ liệu điều chỉnh hướng dẫn đầy đủ. Chúng tôi tinh chỉnh LLaMA-7B với 15 epoch và LLaMA-7B-full với 3 epoch dựa trên trình tối ưu hóa AdamW (Loshchilov và Hutter, 2017). Kích thước batch được đặt là 32, tốc độ học ban đầu là 8e-6, và weight decay là 1e-5. Chúng tôi cũng đặt warmup steps là 5% của tất cả các bước huấn luyện. Độ dài tối đa của văn bản đầu vào là 2048. FinMA-7B được tinh chỉnh trên 8 GPU A100 40GB. Đối với mô hình FinMA-30B, chúng tôi tinh chỉnh LLaMA-30B với 20 epoch, cũng dựa trên trình tối ưu hóa AdamW. Kích thước batch được đặt là 24, tốc độ học ban đầu là 8e-6, weight decay là 1e-5, và warmup steps là 5% của tất cả các bước huấn luyện. Độ dài tối đa của văn bản đầu vào là 2048. Khác với FinMA-7B, nó chỉ có thể được tinh chỉnh phân tán trên 128 GPU A100 40GB.

5 FLARE: Chuẩn mực Đánh giá Tài chính
Dựa trên FIT, chúng tôi thiết kế chuẩn mực đánh giá hiểu ngôn ngữ tự nhiên và dự đoán tài chính (FLARE). Chúng tôi lựa chọn ngẫu nhiên các tập validation từ FIT để chọn checkpoint mô hình tốt nhất, và các tập test để đánh giá. So với chuẩn mực hiện có FLUE (Sanh et al., 2022), FLARE bao gồm các nhiệm vụ dự đoán tài chính ngoài các nhiệm vụ NLP¹⁰. Chúng tôi tin rằng việc bao gồm các nhiệm vụ dự đoán tài chính như dự đoán biến động cổ phiếu là quan trọng để đánh giá toàn diện hiệu suất của LLM trong các ứng dụng thực tế của lĩnh vực tài chính. Chúng tôi hiển thị thống kê dữ liệu của tập validation và test cho mỗi tập dữ liệu trong Bảng 4. Theo các phương pháp trước đây (Li et al., 2023; Shah et al., 2022),

Bảng 4: Chi tiết về các tập dữ liệu đánh giá của chúng tôi. Để so sánh hiệu suất với BloombergGPT mà dữ liệu test không được phát hành công khai, chúng tôi giữ cùng số lượng và phân phối dữ liệu của các tập dữ liệu test với BloombergGPT.

Dữ liệu | Nhiệm vụ | Valid | Test | Đánh giá
FPB (Malo et al., 2014) | phân tích tâm lý | 7.740 | 9.700 | F1, Accuracy
FiQA-SA (Maia et al., 2018) | phân tích tâm lý | 1.880 | 2.350 | F1, Accuracy
Headline (Sinha và Khandait, 2021) | phân loại tiêu đề tin tức | 1.0259 | 2.0547 | Avg F1
NER (Alvarado et al., 2015) | nhận dạng thực thể có tên | 1.029 | 980 | Entity F1
FinQA (Chen et al., 2021) | hỏi đáp | 882 | 1.147 | EM Accuracy
ConvFinQA (Chen et al., 2022) | hỏi đáp | 1.489 | 2.161 | EM Accuracy
BigData22 (Soun et al., 2022) | dự đoán biến động cổ phiếu | 797 | 1.471 | Accuracy, MCC
ACL18 (Xu và Cohen, 2018) | dự đoán biến động cổ phiếu | 2.554 | 3.719 | Accuracy, MCC
CIKM18 (Wu et al., 2018) | dự đoán biến động cổ phiếu | 430 | 1.142 | Accuracy, MCC

chúng tôi đánh giá hiệu suất của nhiệm vụ phân loại tâm lý trên các tập dữ liệu FPB và FiQA-SA, với độ chính xác (ACC) và điểm F1 có trọng số (F1). Hiệu suất của nhiệm vụ phân loại tiêu đề tin tức được đánh giá với trung bình có trọng số của điểm F1 trên tất cả chín danh mục (Avg F1). Đối với hiệu suất của nhiệm vụ NER, chúng tôi đánh giá với điểm F1 cấp thực thể (Entity F1). Hiệu suất trên nhiệm vụ hỏi đáp được đánh giá với độ chính xác khớp chính xác (EM Acc). Đối với nhiệm vụ dự đoán tài chính, theo các phương pháp trước đây (Xu và Cohen, 2018; Xie et al., 2023), chúng tôi đánh giá hiệu suất với độ chính xác (ACC) và hệ số tương quan Matthews (MCC).

6 Thí nghiệm trên FLARE
FIT và FLARE được đề xuất cho phép huấn luyện, chọn mô hình và đánh giá hiệu suất của LLM về hiểu và dự đoán tài chính. Trong phần này, chúng tôi điều tra mức độ mạnh mẽ của FinMA được tinh chỉnh với FIT và các LLM khác trên FLARE. Chúng tôi so sánh FinMA với các LLM sau: 1) BloombergGPT (Wu et al., 2023). Mô hình ngôn ngữ lớn duy nhất với 50B tham số được huấn luyện trước với văn bản tài chính. 2) GPT-4 (OpenAI, 2023). Một mô hình ngôn ngữ lớn tuân theo hướng dẫn mạnh mẽ với khoảng 1T tham số được đề xuất bởi OpenAI. 3) ChatGPT. Một mô hình ngôn ngữ lớn tuân theo hướng dẫn với 175B tham số từ OpenAI. 4) BLOOM (Scao et al., 2022). Một mô hình ngôn ngữ lớn đa ngôn ngữ truy cập mở với 176B tham số. 5) GPT-NeoX (Black et al., 2022). Một mô hình ngôn ngữ lớn mã nguồn mở với 20B tham số. 6) OPT-66B (Zhang et al., 2022). Một mô hình ngôn ngữ mã nguồn mở với tham số từ 125M đến 175B. Chúng tôi sử dụng OPT với 66B tham số. 7) Vicuna-13B (Zhang et al., 2022). Một mô hình ngôn ngữ lớn tuân theo hướng dẫn bằng cách tinh chỉnh LLaMA-13B.

Theo các phương pháp trước đây (Wu et al., 2023; Li et al., 2023), chúng tôi báo cáo hiệu suất 20-shot của BloombergGPT và hiệu suất 5-shot của các phương pháp baseline khác trên tập dữ liệu FIN. Chúng tôi báo cáo hiệu suất 5-shot của BloombergGPT trên FPB và FiQA-SA. Chúng tôi báo cáo hiệu suất 5-shot của tất cả baselines trên tập dữ liệu News. Đối với các kết quả còn lại, chúng tôi báo cáo hiệu suất zero-shot. Kết quả của một số baseline dựa trên đánh giá của con người, vì các LLM không được tinh chỉnh sẽ thất bại trong việc tạo ra câu trả lời được định nghĩa trước trong hướng dẫn đã cho. Tất cả kết quả của FinMA được thực hiện ở zero-shot và có thể được đánh giá tự động.

¹⁰Theo BloombergGPT, chúng tôi không bao gồm nhiệm vụ phát hiện biên giới cấu trúc được bao gồm trong FLUE vì chúng khó chuyển đổi thành nhiệm vụ tuân theo hướng dẫn.

--- TRANG 6 ---
Bảng 5: Hiệu suất zero-shot và few-shot của các LLM khác nhau trên chuẩn mực FLARE.
Một số kết quả được tham chiếu từ (Wu et al., 2023; Li et al., 2023; Xie et al., 2023). BloombergGPT không phát hành các tập dữ liệu test của họ. Các tập dữ liệu test được xây dựng để có cùng phân phối dữ liệu với BloombergGPT và hiệu suất của FinMA được so sánh trực tiếp với BloombergGPT theo phương pháp trước đây (Li et al., 2023).

Tập dữ liệu | Chỉ số | GPT NeoX | OPT 66B | BLOOM | Chat GPT | GPT 4 | Bloomberg GPT | FinMA 7B | FinMA 30B | FinMA 7B-full
FPB | Acc | - | - | - | 0.78 | 0.76 | - | 0.86 | 0.87 | 0.87
    | F1 | 0.45 | 0.49 | 0.50 | 0.78 | 0.78 | 0.51 | 0.86 | 0.88 | 0.87
FiQA-SA | F1 | 0.51 | 0.52 | 0.53 | - | - | 0.75 | 0.84 | 0.87 | 0.79
Headline | AvgF1 | 0.73 | 0.79 | 0.77 | 0.77 | 0.86 | 0.82 | 0.98 | 0.97 | 0.97
NER | EntityF1 | 0.61 | 0.57 | 0.56 | 0.77 | 0.83 | 0.61 | 0.75 | 0.62 | 0.69
FinQA | EmAcc | - | - | - | 0.58 | 0.63 | - | 0.06 | 0.11 | 0.04
ConvFinQA | EmAcc | 0.28 | 0.30 | 0.36 | 0.60 | 0.76 | 0.43 | 0.25 | 0.40 | 0.20
BigData22 | Acc | - | - | - | 0.53 | 0.54 | - | 0.48 | 0.47 | 0.49
         | MCC | - | - | - | -0.025 | 0.03 | - | 0.04 | 0.04 | 0.01
ACL18 | Acc | - | - | - | 0.50 | 0.52 | - | 0.50 | 0.49 | 0.56
      | MCC | - | - | - | 0.005 | 0.02 | - | 0.00 | 0.00 | 0.10
CIKM18 | Acc | - | - | - | 0.55 | 0.57 | - | 0.56 | 0.43 | 0.53
       | MCC | - | - | - | 0.01 | 0.02 | - | -0.02 | -0.05 | -0.03

6.1 Kết quả
Hiệu suất Tổng thể. Đối với các nhiệm vụ NLP tài chính, như được trình bày trong Bảng 5, mô hình được tinh chỉnh FinMA của chúng tôi vượt trội đáng kể so với các LLM khác trên các tập dữ liệu FPB, FiQA-SA và Headline, cho thấy tầm quan trọng của điều chỉnh hướng dẫn cụ thể theo lĩnh vực trong việc cải thiện hiệu suất của LLM trong lĩnh vực cụ thể. Ví dụ, FinMA-30B vượt trội hơn GPT-4 10% điểm F1, và BloombergGPT 37% điểm F1 trên tập dữ liệu FPB. Trên tập dữ liệu NER, FinMA-7B cũng vượt trội hơn BloombergGPT và các LLM khác, và đạt kết quả cạnh tranh so với ChatGPT và GPT-4. Tuy nhiên, đối với FinQA và ConvFinQA yêu cầu lý luận số học phức tạp, có một khoảng cách lớn giữa hiệu suất của GPT và FinMA. Như đã báo cáo trong các nghiên cứu hiện có (Touvron et al., 2023; Lewkowycz et al., 2022), LLaMA không bao gồm các tập dữ liệu toán học để huấn luyện trước, dẫn đến hiệu suất kém trên các tập dữ liệu chuẩn mực toán học như GSM8K (Cobbe et al., 2021). Phát hiện này cho thấy tầm quan trọng của lý luận số học cho hỏi đáp tài chính, có thể là hướng tiềm năng để tiến bộ LLM trong lĩnh vực tài chính. Đối với các nhiệm vụ dự đoán tài chính, tất cả LLM bao gồm FinMA, ChatGPT và GPT-4 đều gặp khó khăn trong dự đoán biến động cổ phiếu. Sau khi được tinh chỉnh với cả nhiệm vụ NLP và dự đoán tài chính, FinMA-7B-full có thể đạt được hiệu suất tốt hơn đáng kể trên tập dữ liệu ACL18 so với ChatGPT và GPT-4. Tuy nhiên, nó vẫn có MCC gần như bằng không trên hai tập dữ liệu khác như ChatGPT và GPT-4. Điều này cho thấy sự phức tạp và thử thách của các nhiệm vụ dự đoán tài chính trong FLARE. So với các chuẩn mực tài chính hiện có tập trung vào các nhiệm vụ NLP, FLARE cung cấp cơ hội thú vị để cải thiện LLM về nền tảng của các nghiên cứu và ứng dụng tài chính học thuật.

Phân tích Thêm. Chúng tôi tiếp tục phân tích ảnh hưởng của kích thước mô hình và dữ liệu điều chỉnh hướng dẫn về hiệu suất của LLM trên các nhiệm vụ khác nhau. FinMA-30B không có hiệu suất tốt hơn đáng kể so với FinMA-7B trong hầu hết các nhiệm vụ NLP và nhiệm vụ dự đoán biến động cổ phiếu. Rõ ràng, chất lượng của các hướng dẫn hơn là kích thước mô hình là quan trọng đối với hiệu suất của các nhiệm vụ này. Đối với các nhiệm vụ hỏi đáp phức tạp như ConvFinQA, như được trình bày trong Bảng 6, mô hình LLaMA lớn hơn thường có hiệu suất tốt hơn. Đặc biệt, Vicuna-7B dựa trên LLaMA-7B có hiệu suất tệ nhất, điều này cũng phù hợp với các phát hiện trước đây (Cobbe et al., 2021) rằng LLaMA với tham số lớn hơn có hiệu suất tốt hơn trên các tập dữ liệu chuẩn mực toán học. FinMA-7B và FinMA-30B không được tinh chỉnh với tập dữ liệu dự đoán tài chính, chúng cho thấy hiệu suất hạn chế trong dự đoán biến động cổ phiếu tương tự như ChatGPT và GPT-4. Mặc dù chúng có thể được tổng quát hóa cho nhiệm vụ dự đoán tài chính chưa thấy, vẫn có một khoảng cách lớn để được cải thiện cùng với ChatGPT và GPT-4. Ngược lại, FinMA-7B-full được tinh chỉnh với cả tập dữ liệu NLP và dự đoán, đã cho thấy hiệu suất tốt hơn đáng kể trên tập dữ liệu ACL18, và hiệu suất tương đương trên các nhiệm vụ NLP với FinMA-7B và GPT-4. Điều này cho thấy tiềm năng của LLM được điều chỉnh thêm và áp dụng trực tiếp vào các nhiệm vụ dự đoán tài chính thông qua huấn luyện trước và tinh chỉnh trên các tập dữ liệu lĩnh vực.

Bảng 6: Hiệu suất của LLM trên ConvFinQA.
Chỉ số | GPT-4 | BloombergGPT | FinMA-7B | FinMA-30B | FinMA-7B-full | Vicuna-7B
EmAcc | 0.76 | 0.43 | 0.25 | 0.40 | 0.20 | 0.10

7 Hạn chế
Mặc dù có những đóng góp tích cực của nghiên cứu này, chúng tôi nhận ra những hạn chế sau:

1. Ràng buộc Mô hình và Huấn luyện: Chúng tôi chỉ trình bày các mô hình FinMA lên đến 30B. Do ràng buộc tính toán, FinMA-30B chưa được tinh chỉnh trên tập dữ liệu đầy đủ.

2. Hiệu suất Nhiệm vụ Phức tạp: FinMA, do hạn chế của mô hình backbone LLaMA, gặp khó khăn với các nhiệm vụ yêu cầu lý luận định lượng, như hỏi đáp tài chính, và nhiệm vụ dự đoán tài chính khó khăn.

3. Ràng buộc Tài nguyên và Khả năng Tổng quát: Việc phát triển FinMA, FIT, và FLARE bị ảnh hưởng bởi tài nguyên có sẵn và các hướng dẫn được viết thủ công, có thể ảnh hưởng đến tính đa dạng và khả năng tổng quát của mô hình. Kích thước đầu vào tối đa của FinMA cũng bị hạn chế bởi văn bản đầu vào tối đa mà mô hình backbone LLaMA có thể xử lý.

4. Tác động Tiêu cực Tiềm ẩn: Trong khi nghiên cứu của chúng tôi chủ yếu tập trung vào các khía cạnh tích cực và tiến bộ của các mô hình hiểu ngôn ngữ tài chính, quan trọng là thừa nhận các tác động tiêu cực tiềm ẩn liên quan đến việc sử dụng chúng, như việc lan truyền thông tin sai lệch tài chính hoặc ảnh hưởng thị trường không đạo đức.

8 Kết luận
Trong công trình này, chúng tôi đã trình bày PIXIU, bao gồm mô hình ngôn ngữ lớn tài chính mã nguồn mở đầu tiên FinMA, tập dữ liệu điều chỉnh hướng dẫn FIT, và chuẩn mực đánh giá FLARE. Thông qua đánh giá toàn diện, chúng tôi đã chứng minh hiệu quả của FinMA trên các nhiệm vụ tài chính khác nhau, cho thấy tiềm năng của điều chỉnh hướng dẫn cụ thể theo lĩnh vực của các mô hình ngôn ngữ lớn trong lĩnh vực tài chính. Tuy nhiên, những thử thách như cải thiện hiệu suất trên các nhiệm vụ phức tạp và giải quyết các ràng buộc tài nguyên vẫn còn. Đóng góp mã nguồn mở của chúng tôi nhằm hỗ trợ nghiên cứu và đổi mới thêm trong hiểu ngôn ngữ tài chính, dự đoán, và LLM, hướng tới LLM hữu ích và an toàn hơn trong lĩnh vực tài chính.

Lời cảm ơn
Bài báo này sẽ không thể thực hiện được nếu không có đóng góp vô giá từ mã BELLE (Ji et al., 2023a,b).

Tài liệu tham khảo
[Tiếp theo là danh sách tài liệu tham khảo được dịch sang tiếng Việt...]

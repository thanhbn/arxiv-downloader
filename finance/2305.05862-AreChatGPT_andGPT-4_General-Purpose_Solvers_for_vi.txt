# 2305.05862.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/finance/2305.05862.pdf
# Kích thước tệp: 504559 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
ChatGPT và GPT-4 có phải là Công cụ Giải quyết Đa năng cho
Phân tích Văn bản Tài chính? Một Nghiên cứu về Một số Tác vụ Điển hình
Xianzhi Li1, Samuel Chan1, Xiaodan Zhu1, Yulong Pei2, Zhiqiang Ma2, Xiaomo Liu2và Sameena Shah2
1Khoa Kỹ thuật Điện và Máy tính & Viện Nghiên cứu Ingenuity Labs
Đại học Queen's
2Nghiên cứu AI J.P. Morgan
{li.xianzhi, 19syc2, xiaodan.zhu }@queensu.ca
{yulong.pei,zhiqiang.ma,xiaomo.liu,sameena.shah }@jpmchase.com
Tóm tắt
Các mô hình ngôn ngữ lớn (LLMs) gần đây nhất
như ChatGPT và GPT-4 đã cho thấy khả năng
đặc biệt của các mô hình tổng quát, đạt được hiệu
suất tối ưu trên một loạt rộng các tác vụ NLP với
ít hoặc không cần thích ứng. Các mô hình như
vậy có hiệu quả như thế nào trong lĩnh vực tài
chính? Hiểu được câu hỏi cơ bản này sẽ có tác
động đáng kể đến nhiều tác vụ phân tích tài chính
hạ nguồn. Trong bài báo này, chúng tôi tiến hành
một nghiên cứu thực nghiệm và cung cấp bằng
chứng thực nghiệm về hiệu suất của chúng trên
nhiều loại vấn đề phân tích văn bản tài chính đa
dạng, sử dụng tám bộ dữ liệu chuẩn từ năm loại
tác vụ. Chúng tôi báo cáo cả điểm mạnh và hạn
chế của các mô hình hiện tại bằng cách so sánh
chúng với các phương pháp tinh chỉnh tối ưu và
các mô hình được tiền huấn luyện dành riêng cho
lĩnh vực được phát hành gần đây. Chúng tôi hy
vọng nghiên cứu của chúng tôi có thể giúp hiểu
khả năng của các mô hình hiện có trong lĩnh vực
tài chính và tạo điều kiện cho những cải tiến tiếp
theo.

1 Giới thiệu
Sự tiến bộ của LLMs đang mang lại những tác
động sâu sắc đến ngành tài chính. Thông qua huấn
luyện với học tăng cường từ phản hồi của con
người (RLHF) (Christiano et al., 2023) và các mục
tiêu mô hình ngôn ngữ có mặt nạ, các mô hình gần
đây nhất như ChatGPT1và GPT-42đã thể hiện
khả năng đặc biệt trong một loạt rộng các tác vụ
xử lý ngôn ngữ tự nhiên (NLP) (Bang et al., 2023a;
Liu et al., 2023; Omar et al., 2023; Khoury et al.,
2023).

Các LLMs này được huấn luyện trên các bộ dữ
liệu bao gồm một loạt rộng các thể loại và chủ đề.
Trong khi hiệu suất của chúng trong các tác vụ
NLP chung là ấn tượng, khả năng áp dụng và hiệu
quả của chúng trong các lĩnh vực cụ thể như tài
chính vẫn cần hiểu rõ hơn và có thể ảnh hưởng đến
một loạt rộng các ứng dụng. Nói chung, trong lĩnh
vực tài chính, LLMs đang đóng một vai trò ngày
càng quan trọng trong các tác vụ như phân tích
tình cảm đầu tư, nhận dạng thực thể có tên tài
chính, và các hệ thống hỏi đáp để hỗ trợ các nhà
phân tích tài chính.

Trong bài báo này, chúng tôi thực hiện một
nghiên cứu thực nghiệm và cung cấp bằng chứng
thực nghiệm về hiệu quả của các LLMs gần đây
nhất trên nhiều loại vấn đề phân tích văn bản tài
chính đa dạng, bao gồm tám bộ dữ liệu chuẩn từ
năm tác vụ điển hình. Các bộ dữ liệu này đến từ
một loạt các chủ đề và tiểu lĩnh vực tài chính như
phân tích thị trường chứng khoán, tin tức tài chính,
và chiến lược đầu tư. Chúng tôi báo cáo cả điểm
mạnh và hạn chế của ChatGPT và GPT-4 bằng
cách so sánh chúng với các mô hình tinh chỉnh
dành riêng cho lĩnh vực tối ưu trong tài chính,
ví dụ như FinBert (Araci, 2019) và FinQANet
(Chen et al., 2022a), cũng như mô hình được tiền
huấn luyện gần đây như BloombergGPT (Wu et
al., 2023). Các đóng góp chính của chúng tôi được
tóm tắt như sau:

• Nghiên cứu này là một trong những nghiên cứu
đầu tiên khám phá sự tiến bộ gần đây nhất của
các mô hình ngôn ngữ lớn được huấn luyện tổng
quát trên các tác vụ phân tích văn bản tài chính
và nó cung cấp một so sánh toàn diện.

• Chúng tôi chứng minh rằng ChatGPT và GPT-4
có thể vượt trội hơn mô hình được tiền huấn
luyện dành riêng cho lĩnh vực được phát hành
gần đây nhất cũng như các mô hình tinh chỉnh
trên nhiều tác vụ. Chúng tôi cung cấp phân tích
chi tiết và khuyến nghị.

• Chúng tôi quan sát thấy rằng sự tiến bộ được
thực hiện trong các mô hình tổng quát tiếp tục
được chuyển giao sang lĩnh vực tài chính; ví dụ,
GPT-4 tốt hơn đáng kể so với ChatGPT trên
gần như tất cả các chuẩn mực tài chính được sử
dụng.

• Các hạn chế của LLMs hiện có được phân tích
và thảo luận với các bộ dữ liệu chuẩn này.

--- TRANG 2 ---
Danh mục Phân tích Tình cảm Phân loại NER RE QA
Độ phức tạp Dễ Dễ Khó Khó Khó
Kiến thức Thấp Thấp Cao Cao Cao
Bộ dữ liệu FPB/FiQA/TweetFinSent Headline NER REFinD FinQA/ConvFinQA
Chỉ số Đánh giá F1 Có trọng số F1 Có trọng số F1 Macro F1 Macro Độ chính xác
#Mẫu Kiểm tra 970/223/996 2,114 98 4300 1,147/421

Bảng 1: Thống kê của năm tác vụ và tám bộ dữ liệu được sử dụng trong nghiên cứu này.

2 Các Công trình Liên quan
ChatGPT và Các Mô hình Liên quan. ChatGPT,
GPT-3.5 (text-davinci-003), và GPT-4 là những
LLMs được huấn luyện tổng quát và đã cho thấy
hiệu suất ấn tượng trên một loạt rộng các tác vụ.
Các nghiên cứu gần đây đã cho thấy rằng chúng
vượt trội hơn các mô hình tinh chỉnh trên một số
tác vụ. Nhưng chúng vẫn thất bại trong một số
trường hợp khác. Bang et al. (2023b) đánh giá
ChatGPT trên các tác vụ đa nhiệm, đa ngôn ngữ
và đa phương thức, nêu bật việc giải quyết các
thất bại để cải thiện hiệu suất tổng thể. Qin et al.
(2023) nghiên cứu khả năng zero-shot của ChatGPT
trên một loạt đa dạng các tác vụ NLP. Trong khi
các mô hình này thể hiện chất lượng chưa từng
có và giữ lại kiến thức tích lũy với khả năng tổng
quát hóa xuất sắc, bằng cách tôn trọng mục tiêu
là những người giải quyết vấn đề tổng quát, việc
chúng hiệu quả như thế nào đối với các tác vụ
phân tích văn bản tài chính là một câu hỏi mở hấp
dẫn cần hiểu rõ hơn.

Các Mô hình Dành riêng cho Lĩnh vực Hiện tại,
chỉ có một số ít LLMs được huấn luyện cụ thể
trong lĩnh vực tài chính. BloombergGPT (Wu et
al., 2023), một mô hình ngôn ngữ với 50 tỷ tham
số, được huấn luyện bằng phương pháp hỗn hợp
để phục vụ các tác vụ đa dạng của ngành tài chính.
Mô hình được đánh giá trên các chuẩn mực LLM
tiêu chuẩn, các chuẩn mực tài chính mở, và các
chuẩn mực nội bộ của Bloomberg. Phương pháp
huấn luyện hỗn hợp tạo ra một mô hình vượt trội
đáng kể so với các mô hình hiện có trong các tác
vụ tài chính và hoạt động ngang bằng hoặc thậm
chí tốt hơn trong một số chuẩn mực NLP chung.
Các nhà nghiên cứu khác cũng đã cố gắng thích
ứng các mô hình ngôn ngữ hiện có để giải quyết
các tác vụ dành riêng cho lĩnh vực. Ví dụ, Lewkowycz
et al. (2022) đã thích ứng T5 cho lĩnh vực tài chính.
Lưu ý rằng ngoài việc tinh chỉnh, một nghiên cứu
cũng đã được tiến hành để sử dụng điều chỉnh
hiệu quả tham số cho các tác vụ tài chính như
phát hiện ý định (Li et al., 2022). Chi tiết của các
công trình liên quan có thể được tìm thấy trong
Phụ lục A.

3 Thiết lập Thí nghiệm
Các Tác vụ và Bộ dữ liệu. Nghiên cứu của chúng
tôi sử dụng một loạt rộng các tác vụ và thách thức
NLP tài chính (Pei et al., 2022; Kaur et al., 2023;
Shah et al., 2022), cho phép chúng tôi thiết lập một
bộ kiểm tra với các loại vấn đề NLP khác nhau
từ phân tích tình cảm cơ bản và phân loại văn bản
đến trích xuất thông tin và hỏi đáp (xem Bảng 1
và chi tiết hơn trong Phụ lục B).

Phạm vi của các tác vụ cho phép chúng tôi thực
hiện các quan sát theo độ phức tạp mô hình hóa
và các mức độ kiến thức tài chính khác nhau cần
thiết để thực hiện các tác vụ. Về độ phức tạp mô
hình hóa của các tác vụ, phân tích tình cảm và
phân loại văn bản thường được coi là đơn giản
hơn, so với các tác vụ trích xuất thông tin (IE) như
nhận dạng thực thể có tên (NER) và trích xuất
quan hệ (RE). Sau này thường đòi hỏi hiểu biết
sâu hơn về cú pháp và ngữ nghĩa trong các ngữ
cảnh đầu vào cũng như các tương tác của nhãn
trong không gian đầu ra như các vấn đề dự đoán
có cấu trúc. So với phân tích tình cảm và phân
loại văn bản, hỏi đáp (QA) thường được coi là
khó hơn vì nó thường đòi hỏi một mô hình hiểu
logic nội bộ được nhúng và hoạt động/suy luận
số học. Về kiến thức tài chính, các bộ dữ liệu
phân loại và phân tích tình cảm hiện có được lấy
từ tin tức hàng ngày và mạng xã hội. Mặt khác,
dữ liệu IE và QA thường từ các tài liệu chuyên
nghiệp như hồ sơ tài chính và báo cáo, thường
đòi hỏi nhiều kiến thức lĩnh vực hơn để hiểu.

Các Mô hình. Chúng tôi kiểm tra các LLMs đại
diện tối ưu, các mô hình ChatGPT và GPT-4. Cụ
thể, chúng tôi sử dụng gpt-3.5-turbo và GPT-4
(8k) cho hầu hết các thí nghiệm, ngoại trừ các thí
nghiệm few-shot FinQA, nơi các token đầu vào
cực dài nên chúng tôi áp dụng gpt-3.5-turbo-16k.3
Cả hai LLMs này đều được đánh giá bằng học
zero-shot và few-shot cũng như học CoT cho các
tác vụ suy luận QA. Hơn nữa, chúng tôi so sánh
chúng với các LLMs trước đây và BloombergGPT
dành riêng cho lĩnh vực (Wu et al., 2023). Các mô
hình tinh chỉnh tối ưu trên mỗi bộ dữ liệu được
sử dụng để kiểm tra ý tưởng huấn luyện các mô
hình nhỏ hơn trên các tác vụ riêng lẻ so với việc
nhắc nhở LLMs trên tất cả các tác vụ mà không
cần tinh chỉnh bổ sung.

Các Chỉ số Đánh giá. Chúng tôi sử dụng độ chính
xác, điểm F1 macro, và điểm F1 có trọng số (Wu
et al., 2023) làm các chỉ số đánh giá. Đối với tác
vụ NER, chúng tôi tính điểm F1 cấp thực thể.
Bảng 1 cho thấy chi tiết của thiết lập thí nghiệm.

4 Kết quả và Phân tích
4.1 Phân tích Tình cảm
Phân tích tình cảm là một trong những kỹ thuật
NLP được sử dụng phổ biến nhất trong lĩnh vực
tài chính và có thể được sử dụng để dự đoán hành
vi đầu tư và xu hướng trong thị trường cổ phiếu
từ dữ liệu tin tức và mạng xã hội (Mishev et al.,
2020). Chúng tôi sử dụng ba bộ dữ liệu tình cảm
tài chính với các tiêu điểm khác nhau.

Financial PhraseBank. PhraseBank là một tác vụ
phân loại tình cảm ba thang điểm điển hình (tích
cực, tiêu cực và trung tính) được tuyển chọn từ
tin tức tài chính bởi 5-8 người chú thích (Malo et
al., 2013). Chúng tôi sử dụng cả bộ dữ liệu thỏa
thuận chú thích 50% và 100%. Giống như trong
(Wu et al., 2023), 20% câu được sử dụng để kiểm
tra. Trong Bảng 2, nhóm đầu tiên các mô hình (4
mô hình) là OpenAI LLMs, tiếp theo là BloombergGPT,
ba LLMs trước đây (được gọi là Prior LLMs), và
các mô hình tinh chỉnh tối ưu trên bộ dữ liệu này
(FinBert). Do giới hạn không gian của Bảng 2,
chúng tôi đặt tên của bốn nhóm này trong bảng
tiếp theo (Bảng 3) để rõ ràng. Trong Bảng 2,
chúng tôi có thể thấy rằng hiệu suất của Prior
LLMs kém xa ChatGPT và GPT-4. Với sự tăng
cường của học few-shot, GPT-4 có thể so sánh
với FinBert tinh chỉnh (Araci, 2019).

FiQA Sentiment Analysis. Bộ dữ liệu này mở
rộng độ phức tạp tác vụ để phát hiện tình cảm dựa
trên khía cạnh từ tin tức và microblog trong lĩnh
vực tài chính (Maia et al., 2018). Chúng tôi theo
thiết lập của BloombergGPT (Wu et al., 2023),
nơi chúng tôi chuyển đổi tác vụ hồi quy này thành
một tác vụ phân loại. 20% dữ liệu huấn luyện có
nhãn được giữ làm trường hợp kiểm tra. Kết quả
trong Bảng 3 thể hiện xu hướng hiệu suất tương
tự như trong bộ dữ liệu trước: ChatGPT và GPT-4
vượt trội hơn Prior LLMs. Với một vài ví dụ
few-shot, GPT-4 tốt hơn tất cả các mô hình khác
ở đây. BloombergGPT có hiệu suất tương đối gần
với ChatGPT zero-shot và kém hơn GPT-4. Mô
hình RoBERTa-large tinh chỉnh trên bộ dữ liệu
này tốt hơn ChatGPT, nhưng hơi kém hiệu quả
hơn GPT-4. Mô hình sau đạt 88% trên F1, thấp
hơn so với trong Financial PhraseBank. Chúng
tôi cho rằng điều này là do FiQA đòi hỏi mô hình
hóa nhiều chi tiết hơn và cần nhiều kiến thức lĩnh
vực hơn để hiểu tình cảm với cây tài chính khía
cạnh trong dữ liệu.

[Bảng 2: Kết quả trên bộ dữ liệu Phrasebank được giữ nguyên vì là dạng bảng]

[Bảng 3: Kết quả trên bộ dữ liệu FiQA được giữ nguyên vì là dạng bảng]

TweetFinSent. Pei et al. (2022) đã tạo bộ dữ liệu
này dựa trên Twitter để nắm bắt tâm trạng của
các nhà đầu tư bán lẻ đối với một mã cổ phiếu
cụ thể. Vì các tweet là văn bản không chính thức
thường không được sử dụng để huấn luyện LLMs,
điều này có thể là một tác vụ đầy thách thức cho
LLMs để hoạt động tốt. Hơn nữa, một tweet đôi
khi có thể chứa nhiều mã (>5 không phải là bất
thường). Mô hình khía cạnh trên dữ liệu này phức
tạp hơn. Kết quả đánh giá trên 996 trường hợp
kiểm tra được hiển thị trong Bảng 4. GPT-4 với
một vài ví dụ few-shot đạt độ chính xác và F1
~72%, thấp hơn các giá trị trong hai tác vụ trước.
RoBERTa-Twitter tinh chỉnh (Pei et al., 2022) có
hiệu suất tương tự. Chúng tôi cũng tiến hành một
nghiên cứu loại bỏ bằng cách xóa emoji. Cả ChatGPT
và GPT-4 đều cho thấy giảm hiệu suất 2-3 điểm,
cho thấy emoji trong mạng xã hội thực sự truyền
tải các tín hiệu tình cảm có ý nghĩa. Chúng tôi
không có kết quả của Prior LLMs vì bộ dữ liệu
này không được đánh giá trong các nghiên cứu
trước đây tương ứng.

[Bảng 4: Kết quả trên bộ dữ liệu TweetFinSent được giữ nguyên vì là dạng bảng]

4.2 Phân loại Tiêu đề
Trong khi phân tích tình cảm được coi là một trong
những tác vụ cơ bản nhất và chủ yếu liên quan
đến một số chiều hướng của khuynh hướng ngữ
nghĩa (Osgood et al., 1957), ngữ nghĩa liên quan
trong các tác vụ phân loại văn bản tài chính có
thể phức tạp hơn. Phân loại, đặc biệt là phân loại
văn bản đa lớp, thường được áp dụng cho một
loạt rộng văn bản tài chính như tin tức, SEC 10-Ks,
và báo cáo nghiên cứu thị trường để tăng tốc các
hoạt động kinh doanh.

Giống như trong (Wu et al., 2023), chúng tôi sử
dụng bộ dữ liệu phân loại tiêu đề tin tức (Sinha
và Khandait, 2020) từ chuẩn mức FLUE (Shah et
al., 2022). Tác vụ phân loại này nhằm mục đích
phân loại tiêu đề tin tức hàng hóa thành một trong
sáu danh mục như "Giá Lên" và "Giá Xuống".
Chúng tôi theo thiết lập trong BloombergGPT,
chuyển đổi phân loại đa lớp thành sáu vấn đề phân
loại nhị phân riêng lẻ (tham khảo Hình 7 như một
ví dụ).

Hiệu suất mô hình được liệt kê trong Bảng 5.
Một lần nữa GPT-4 vượt trội hơn ChatGPT và
Prior LLMs cũng như BloombergGPT. BERT tinh
chỉnh có thể đạt 95% trên F1, cao hơn 9% so với
GPT-4 5-shot. Tác vụ này được coi là đầy thách
thức do tính chất đa lớp và sự cần thiết của kiến
thức lĩnh vực về thị trường hàng hóa.

[Bảng 5: Kết quả trên tác vụ phân loại tiêu đề được giữ nguyên vì là dạng bảng]

4.3 Nhận dạng Thực thể Có tên
NER giúp cấu trúc hóa các tài liệu văn bản bằng
cách trích xuất các thực thể. Đây là một kỹ thuật
mạnh mẽ để tự động hóa xử lý tài liệu và trích
xuất kiến thức từ tài liệu (Yang, 2021). Trong
đánh giá của chúng tôi, chúng tôi sử dụng bộ dữ
liệu NER FIN3, được tạo bởi Salinas Alvarado et
al. (2015) sử dụng các thỏa thuận tài chính từ SEC
và chứa bốn loại NE: PER, LOC, ORG và MISC.
Theo thiết lập được sử dụng trong BloombergGPT,
chúng tôi loại bỏ tất cả các thực thể có nhãn MISC
do tính mơ hồ của nó.

Trong Bảng 6, chúng tôi có thể thấy rằng cả
GPT-4 và ChatGPT đều hoạt động kém trong
thiết lập zero-shot. Theo thiết lập của BloombergGPT,
học few-shot sử dụng 20 shot trên bộ dữ liệu này.
Chúng tôi có thể thấy rằng GPT-4 kém hiệu quả
hơn BloombergGPT, và có thể so sánh hoặc tệ
hơn Prior LLMs trên tác vụ này. Vì NER là một
vấn đề dự đoán có cấu trúc cổ điển, mô hình CRF
cũng được so sánh. Khi CRF được huấn luyện với
FIN5, tương tự như dữ liệu kiểm tra (FIN3), nó
hoạt động tốt hơn tất cả các mô hình khác (xem
hàng cuối cùng của bảng). Lưu ý rằng CRF rất
nhạy cảm với sự chuyển đổi lĩnh vực—khi nó được
huấn luyện trên dữ liệu CoNLL ngoài lĩnh vực, nó
hoạt động kém trên dữ liệu FIN3 (tham khảo hàng
thứ hai từ cuối của Bảng 6), kém hơn các LLMs
zero-shot. Nói chung, trong tác vụ dự đoán có cấu
trúc này, hiệu suất của LLMs không lý tưởng và
cần cải tiến trong tương lai, đặc biệt là đối với
các mô hình tổng quát.

4.4 Trích xuất Quan hệ
Trích xuất quan hệ nhằm mục đích phát hiện mối
liên kết giữa các thực thể được trích xuất. Đây là
một thành phần nền tảng cho việc xây dựng đồ
thị kiến thức, hỏi đáp và các ứng dụng tìm kiếm
ngữ nghĩa cho ngành tài chính. Trong nghiên cứu
này, chúng tôi sử dụng một bộ dữ liệu trích xuất
quan hệ tài chính — REFinD, được tạo từ các hồ
sơ 10-K/Q với 22 loại quan hệ Kaur et al. (2023).
Để LLMs dự đoán mối quan hệ giữa hai thực thể,
chúng tôi cung cấp câu gốc, từ thực thể, và các
loại thực thể của chúng trong các lời nhắc và yêu
cầu các mô hình dự đoán một loại quan hệ. Giống
như trong Luke-base (Yamada et al., 2020), chúng
tôi sử dụng Macro F1. Bảng 7 cho thấy rằng Luke-base
tinh chỉnh vượt trội hơn cả ChatGPT và GPT-4
với một biên độ đáng chú ý. Mặt khác, GPT-4
thể hiện hiệu suất tốt hơn đáng kể so với ChatGPT.
Kết quả từ tác vụ IE này minh họa sức mạnh của
việc tinh chỉnh trên các tác vụ phức tạp cần hiểu
biết tốt hơn về cấu trúc của các câu.

[Bảng 6 và 7: Kết quả được giữ nguyên vì là dạng bảng]

4.5 Hỏi đáp
Việc áp dụng QA vào tài chính trình bày một con
đường có thể để tự động hóa phân tích tài chính,
hiện tại gần như 100% được thực hiện bởi các
chuyên gia tài chính được đào tạo. Nó thường
được coi là đầy thách thức vì thường đòi hỏi một
mô hình hiểu không chỉ kiến thức lĩnh vực mà
còn logic nội bộ được nhúng và hoạt động/suy
luận số học. Chúng tôi áp dụng hai bộ dữ liệu
QA: FinQA (Chen et al., 2022a) và ConvFinQA
(Chen et al., 2022b). Bộ dữ liệu trước tập trung
vào một cặp câu hỏi và câu trả lời duy nhất. Bộ
dữ liệu sau phân tách tác vụ thành một cấu trúc
đa vòng: một chuỗi suy luận thông qua cuộc hội
thoại. Cả hai đều tập trung vào suy luận số học
trong phân tích tài chính, ví dụ như tính tỷ lệ tăng
trưởng lợi nhuận qua các năm từ một bảng tài
chính. Thiết lập thí nghiệm và chi tiết thiết kế
lời nhắc trong Phụ lục B và C. Vì các nhãn của
bộ kiểm tra ConvFinQA không có sẵn công khai,
chúng tôi sử dụng bộ dữ liệu dev của nó (421 mẫu)
thay vào đó để đánh giá các mô hình, trong khi
đối với FinQA sử dụng bộ dữ liệu kiểm tra (1,147
mẫu).

[Bảng 8: Hiệu suất mô hình được giữ nguyên vì là dạng bảng]

Từ hiệu suất trong Bảng 8, chúng ta có thể thấy
rằng GPT-4 vượt trội đáng kể so với tất cả các
LLMs khác trong cả hai bộ dữ liệu. Đối với FinQA,
GPT-4 có độ chính xác zero-shot cao nhất là 68.79%,
trong khi ChatGPT có 48.56%. Khoảng cách hiệu
suất giữa GPT-4 và ChatGPT vẫn tồn tại trên
ConvFinQA. ChatGPT có lợi thế lớn so với BloombergGPT
(59.86% so với 43.41%) và cũng với Prior LLMs
trên ConvFinQA. Kết quả này chứng minh rằng
sự cải tiến liên tục của suy luận được phát triển
thông qua ChatGPT đến GPT-4, điều này cũng
được quan sát trong các nghiên cứu khác.

Chúng tôi tiếp tục khám phá tác động của học
few-shot và nhắc nhở Chuỗi Suy nghĩ (CoT) trên
GPT-4 và ChatGPT trên tác vụ FinQA. Kết quả
cung cấp một câu chuyện thuyết phục về việc tăng
hiệu suất bằng cách sử dụng các chiến lược nhắc
nhở này. Cả ChatGPT và GPT-4 đều cho thấy
tăng độ chính xác 1-3% khi sử dụng 3 shot. Điều
này phù hợp với các quan sát của chúng tôi từ
các tác vụ khác. Chiến lược CoT mang lại một
sự nâng cao lớn, 10% và 15% điểm phần trăm,
cho ChatGPT và GPT-4 tương ứng. Những kết
quả này nhấn mạnh tầm quan trọng của các bước
suy luận chi tiết so với suy luận nông trong việc
tăng cường hiệu suất của các mô hình ngôn ngữ
trên các tác vụ QA tài chính phức tạp. Kết quả
GPT-4 tốt nhất thực sự vượt qua mô hình FinQANet
tinh chỉnh với một biên độ khá đáng kể. Điều này
khiến chúng tôi ngạc nhiên vì trước đây chúng tôi
quan sát thấy rằng các mô hình tinh chỉnh có lợi
thế trên các tác vụ phức tạp hơn. Chúng tôi cho
rằng quy mô tham số và phương pháp tiền huấn
luyện làm cho ChatGPT và GPT-4 xuất sắc trong
suy luận hơn các mô hình khác, đặc biệt là khả
năng số học của GPT-4, được chứng minh khi mô
hình được phát hành bởi OpenAI. Nhưng hiệu
suất của chúng (độ chính xác 70+%) vẫn không
thể sánh với các chuyên gia (~90% độ chính xác).
Hơn nữa, suy luận số học chỉ là một trong nhiều
tác vụ suy luận. Cần nhiều nghiên cứu hơn cho
suy luận biểu tượng và suy luận logic khác (Qin
et al., 2023) nếu có thêm bộ dữ liệu trong lĩnh
vực tài chính. Ngoài ra, chúng tôi nghĩ rằng chiến
lược tiền huấn luyện như RLHF không được thiết
kế để cải thiện các kỹ năng gán nhãn chuỗi và dự
đoán có cấu trúc cần thiết trong IE, nhưng có thể
mang lại lợi ích tự nhiên cho QA.

5 Thảo luận
So sánh giữa các LLMs. Chúng tôi có thể đánh
giá hiệu suất của ChatGPT và GPT-4 với bốn
LLMs khác trên năm tác vụ với tám bộ dữ liệu.
ChatGPT và GPT-4 vượt trội đáng kể so với các
mô hình khác trong hầu hết tất cả các bộ dữ liệu
ngoại trừ tác vụ NER. Thật thú vị khi quan sát
rằng cả hai mô hình đều hoạt động tốt hơn trên
các tác vụ NLP tài chính so với BloombergGPT,
được huấn luyện cụ thể trên corpus tài chính.
Điều này có thể do kích thước mô hình lớn hơn
của hai mô hình. Cuối cùng, GPT-4 liên tục cho
thấy tăng 10+% so với ChatGPT trong các tác vụ
đơn giản như Headlines và FiQA SA. Đối với các
tác vụ thách thức như RE và QA, GPT-4 có thể
đưa ra tăng trưởng hiệu suất 20-100%. Điều này
cho thấy rằng GPT-4 có thể là lựa chọn đầu tiên
cho các tác vụ NLP tài chính trước khi một LLM
mạnh mẽ hơn xuất hiện.

Các Chiến lược Kỹ thuật Nhắc nhở. Chúng tôi
áp dụng hai chiến lược nhắc nhở thường được sử
dụng: few-shot và chuỗi suy nghĩ. Chúng tôi liên
tục quan sát tăng hiệu suất 1% đến 4% trên ChatGPT
và GPT-4 từ few-shot so với học zero-shot trên
các bộ dữ liệu khác nhau. Nhắc nhở chuỗi suy
nghĩ rất hiệu quả trong thử nghiệm của chúng tôi
và chứng minh cải thiện độ chính xác 20-30% so
với zero-shot và few-shot. Theo các phát hiện của
chúng tôi, chúng tôi lập luận rằng hai chiến lược
này luôn nên được xem xét đầu tiên khi áp dụng
LLMs cho các tác vụ NLP tài chính.

LLMs so với Tinh chỉnh. Một lợi ích hấp dẫn của
việc sử dụng LLMs trong các lĩnh vực kinh doanh
là chúng có thể được áp dụng cho một loạt rộng
các tác vụ NLP mà không cần tiến hành nhiều
công việc phụ trội. Nó kinh tế hơn so với việc
tinh chỉnh các mô hình riêng biệt cho mỗi tác vụ.
Trong khi đó, các thí nghiệm của chúng tôi cho
thấy các mô hình tinh chỉnh vẫn thể hiện hiệu
suất mạnh trong hầu hết các tác vụ ngoại trừ tác
vụ QA. Đáng chú ý, đối với các tác vụ như NER
và RE, LLMs kém hiệu quả hơn các mô hình tinh
chỉnh. Trong các tác vụ QA, LLMs minh họa lợi
thế so với mô hình tinh chỉnh. Nhưng độ phức tạp
suy luận của các tác vụ QA được kiểm tra vẫn
được coi là cơ bản trong phân tích tài chính. Mặc
dù ChatGPT và GPT-4 đã chứng minh có thể
thực hiện suy luận đa bước, bao gồm suy luận số
học, ở một mức độ nào đó, các lỗi đơn giản vẫn
được thực hiện.

Sử dụng LLMs trong Dịch vụ Tài chính. Nghiên
cứu này gợi ý rằng người ta có thể xem xét áp
dụng các LLMs tổng quát tối ưu để giải quyết
các tác vụ NLP tương đối đơn giản trong các ứng
dụng tài chính. Đối với các tác vụ phức tạp hơn
như dự đoán có cấu trúc, mô hình tiền huấn luyện
cộng với tinh chỉnh vẫn là một lựa chọn hàng đầu.
Mặc dù ChatGPT và GPT-4 xuất sắc trong QA
so với các mô hình khác và tốt hơn đám đông
chung, chúng vẫn còn xa mới đạt được sự hài
lòng từ góc độ yêu cầu ngành. Cần có nghiên cứu
và cải tiến đáng kể về LLMs trước khi chúng có
thể hoạt động như một đại lý phân tích tài chính
đáng tin cậy.

6 Kết luận
Nghiên cứu này là một trong những nghiên cứu
đầu tiên khám phá sự tiến bộ gần đây nhất của
các LLMs được huấn luyện tổng quát, bao gồm
ChatGPT và GPT-4, trên một loạt rộng các tác
vụ phân tích văn bản tài chính. Các mô hình này
đã được chứng minh là vượt trội hơn các mô hình
được tinh chỉnh với dữ liệu dành riêng cho lĩnh
vực trên một số tác vụ, nhưng vẫn thua kém trên
các tác vụ khác, đặc biệt khi cần ngữ nghĩa sâu
hơn và phân tích cấu trúc. Trong khi chúng tôi
cung cấp các nghiên cứu toàn diện trên tám bộ
dữ liệu từ năm danh mục tác vụ, chúng tôi xem
nỗ lực của mình như một nghiên cứu ban đầu,
và việc điều tra thêm về LLMs trong các ứng dụng
tài chính rất mong muốn, bao gồm thiết kế thêm
các tác vụ để có được hiểu biết sâu hơn về các
hạn chế của các mô hình hiện có, việc tích hợp
LLMs trong vòng lặp ra quyết định của con người,
và tính mạnh mẽ của các mô hình trong các tác
vụ tài chính có cược cao.

--- TRANG 7 ---
Lời cảm ơn
Nghiên cứu này được tài trợ một phần bởi Faculty
Research Awards của J.P. Morgan AI Research.
Các tác giả hoàn toàn chịu trách nhiệm về nội
dung của bài báo và các ý kiến được bày tỏ trong
ấn phẩm này không phản ánh quan điểm của các
cơ quan tài trợ.

Từ chối trách nhiệm
Bài báo này được chuẩn bị cho mục đích thông
tin một phần bởi nhóm Nghiên cứu Trí tuệ Nhân
tạo của JPMorgan Chase & Co. và các chi nhánh
("JP Morgan"), và không phải là sản phẩm của
Phòng Nghiên cứu của JP Morgan. JP Morgan
không đưa ra bất kỳ tuyên bố và bảo đảm nào và
từ chối mọi trách nhiệm pháp lý về tính đầy đủ,
chính xác hoặc độ tin cậy của thông tin có trong
đây. Tài liệu này không được dự định như nghiên
cứu đầu tư hoặc tư vấn đầu tư, hoặc một khuyến
nghị, đề nghị hoặc lời mời mua hoặc bán bất kỳ
chứng khoán, công cụ tài chính, sản phẩm tài
chính hoặc dịch vụ nào, hoặc được sử dụng theo
bất kỳ cách nào để đánh giá giá trị của việc tham
gia vào bất kỳ giao dịch nào, và sẽ không cấu
thành một lời mời chào theo bất kỳ thẩm quyền
nào hoặc đối với bất kỳ người nào, nếu lời mời
chào như vậy theo thẩm quyền như vậy hoặc đối
với người đó sẽ là bất hợp pháp.

Tài liệu tham khảo
[Phần tài liệu tham khảo được giữ nguyên vì chứa nhiều tên riêng và thuật ngữ kỹ thuật]

--- TRANG 9 ---
A Chi tiết của Các Công trình Liên quan
[Phần này tiếp tục được dịch tương tự...]

--- TRANG 10-15 ---
[Các phần còn lại được dịch tương tự, bao gồm chi tiết về bộ dữ liệu, thí nghiệm few-shot, và các hình minh họa]

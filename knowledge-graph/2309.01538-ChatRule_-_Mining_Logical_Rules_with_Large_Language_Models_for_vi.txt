# ChatRule: Khai thác Luật Logic với Mô hình Ngôn ngữ Lớn cho Lý luận Đồ thị Tri thức
Linhao Luo1, Jiaxin Ju2, Bo Xiong3, Yuan-Fang Li1, Gholamreza Haffari1, Shirui Pan2∗
1Đại học Monash, 2Đại học Griffith, 3Đại học Stuttgart
{linhao.luo, yuanfang.li, Gholamreza.Haffari}@monash.edu,
jiaxin.ju@griffithuni.edu.au, bo.xiong@ipvs.uni-stuttgart.de, s.pan@griffith.edu.au

## Tóm tắt
Luật logic là cần thiết để khám phá các kết nối logic giữa các quan hệ, có thể cải thiện hiệu suất lý luận và cung cấp kết quả có thể diễn giải trên đồ thị tri thức (KGs). Mặc dù đã có nhiều nỗ lực để khai thác các luật logic có ý nghĩa trên KGs, các phương pháp hiện tại gặp khó khăn với việc tìm kiếm tính toán chuyên sâu trên không gian luật và thiếu khả năng mở rộng cho các KG quy mô lớn. Bên cạnh đó, chúng thường bỏ qua ngữ nghĩa của các quan hệ, điều này rất quan trọng để khám phá các kết nối logic. Gần đây, các mô hình ngôn ngữ lớn (LLMs) đã cho thấy hiệu suất ấn tượng trong lĩnh vực xử lý ngôn ngữ tự nhiên và các ứng dụng khác nhau, nhờ vào khả năng mới nổi và tính tổng quát hóa của chúng. Trong bài báo này, chúng tôi đề xuất một khung mới, ChatRule, tận dụng sức mạnh của các mô hình ngôn ngữ lớn để khai thác luật logic trên đồ thị tri thức. Cụ thể, khung này được khởi tạo với một bộ sinh luật dựa trên LLM, tận dụng cả thông tin ngữ nghĩa và cấu trúc của KGs để kích hoạt LLMs tạo ra các luật logic. Để tinh chỉnh các luật được tạo ra, một mô-đun xếp hạng luật ước tính chất lượng luật bằng cách kết hợp các sự kiện từ các KG hiện có. Cuối cùng, các luật được xếp hạng có thể được sử dụng để tiến hành lý luận trên KGs. ChatRule được đánh giá trên bốn KG quy mô lớn, đối với các chỉ số chất lượng luật khác nhau và các nhiệm vụ downstream, cho thấy tính hiệu quả và khả năng mở rộng của phương pháp chúng tôi1.

## 1 Giới thiệu
Đồ thị tri thức (KGs) lưu trữ lượng tri thức thế giới thực khổng lồ theo định dạng cấu trúc của các bộ ba. Lý luận KG, nhằm suy ra tri thức mới từ các sự kiện hiện có, là một nhiệm vụ cơ bản trong KGs và thiết yếu cho nhiều ứng dụng, như hoàn thiện KG [Qu và Tang, 2019], trả lời câu hỏi [Atif et al., 2023], và gợi ý [Wang et al., 2019]. Gần đây, có nhu cầu ngày càng tăng về lý luận KG có thể diễn giải, có thể giúp người dùng hiểu quá trình lý luận và cải thiện độ tin cậy trong các tình huống có tính đặc thù cao, như chẩn đoán y tế

∗Tác giả liên hệ.
1Mã nguồn có sẵn tại: https://github.com/RManLuo/ChatRule

Đồ thị Tri thức (KGs)
AliceBob
CharlieAlex
MẹChaỊa Em
TomConChú
Bà ngoại?
Khai thác Luật Logic Lý luận Logic
(Alice, Bà ngoại, Charlie) Sự kiện Mới
Luật Logic

Hình 1: Minh họa khai thác luật logic cho lý luận đồ thị tri thức với LLMs.

[Liu et al., 2021] và phán quyết pháp lý [Zhong et al., 2020]. Do đó, luật logic [Barwise, 1977], có thể đọc được bởi con người và có thể được tổng quát hóa cho các nhiệm vụ khác nhau, đã được áp dụng rộng rãi cho lý luận KG [Hou et al., 2021; Liu et al., 2022]. Ví dụ, như được hiển thị trong Hình 1, chúng ta có thể xác định một luật logic: BàNgoại(X, Y)←Mẹ(X, Z)∧Cha(Z, Y) để dự đoán các sự kiện thiếu cho quan hệ "BàNgoại". Để tự động khám phá các luật có ý nghĩa từ KGs để lý luận, khai thác luật logic đã thu hút sự chú ý đáng kể trong cộng đồng nghiên cứu [Yang et al., 2017; Sadeghian et al., 2019].

Các nghiên cứu trước đây về khai thác luật logic thường tìm các luật logic bằng cách khám phá sự đồng xuất hiện của các mẫu thường xuyên trong cấu trúc KG [Galárraga et al., 2013; Chen et al., 2016]. Tuy nhiên, chúng thường yêu cầu liệt kê tất cả các luật có thể trên KGs và xếp hạng chúng theo tầm quan trọng ước tính [Lao và Cohen, 2010]. Mặc dù nghiên cứu gần đây đã đề xuất sử dụng các phương pháp học sâu để xếp hạng các luật. Chúng vẫn bị hạn chế bởi việc liệt kê triệt để các luật và không thể mở rộng cho các KG quy mô lớn [Yang et al., 2017; Sadeghian et al., 2019].

Một số phương pháp gần đây giải quyết vấn đề này bằng cách lấy mẫu các đường dẫn từ KGs và huấn luyện các mô hình trên chúng để nắm bắt các kết nối logic tạo thành luật [Qu et al., 2020; Cheng et al., 2022b; Cheng et al., 2022a]. Nhưng chúng thường bỏ qua đóng góp của ngữ nghĩa quan hệ trong việc biểu đạt các kết nối logic. Ví dụ, trong kiến thức thông thường, chúng ta biết "mẹ" của "cha" của một người là "bà ngoại" của anh ta. Dựa trên điều này, chúng ta có thể định nghĩa một luật như BàNgoại(X, Y)←Mẹ(X, Z)∧Cha(Z, Y) để biểu đạt kết nối logic. Trong khi đó, do số lượng quan hệ trong KGs, có thể gánh nặng khi yêu cầu các chuyên gia lĩnh vực chú thích luật cho từng quan hệ. Do đó, việc tự động kết hợp cả cấu trúc và ngữ nghĩa của các quan hệ để khám phá luật logic trong KGs là điều cần thiết.

Các mô hình ngôn ngữ lớn (LLMs) như ChatGPT2 và BARD3 thể hiện khả năng tuyệt vời trong việc hiểu ngôn ngữ tự nhiên và xử lý nhiều nhiệm vụ phức tạp [Zhao et al., 2023]. Được huấn luyện trên các kho dữ liệu quy mô lớn, LLMs lưu trữ một lượng lớn tri thức thông thường có thể được sử dụng để hỗ trợ lý luận KG [Pan et al., 2023]. Đồng thời, LLMs không được thiết kế để hiểu cấu trúc của KGs, khiến việc áp dụng trực tiếp chúng để khai thác luật logic trên KGs trở nên khó khăn. Hơn nữa, vấn đề ảo giác được thừa nhận rộng rãi có thể khiến LLMs tạo ra các luật logic vô nghĩa [Ji et al., 2023].

Để giảm thiểu khoảng cách giữa LLMs và khai thác luật logic, chúng tôi đề xuất một khung mới được gọi là ChatRule, tận dụng cả thông tin ngữ nghĩa và cấu trúc của KGs để kích hoạt LLMs tạo ra luật logic. Cụ thể, chúng tôi trước tiên trình bày một bộ sinh luật dựa trên LLM để tạo ra các luật ứng viên cho từng quan hệ. Chúng tôi lấy mẫu một số đường dẫn từ KGs để đại diện cho thông tin cấu trúc, sau đó được sử dụng trong một lời nhắc được thiết kế cẩn thận để tận dụng khả năng của LLMs để khai thác luật. Để giảm vấn đề ảo giác, chúng tôi thiết kế một bộ xếp hạng luật logic để đánh giá chất lượng của các luật được tạo ra và lọc ra các luật vô nghĩa bằng cách bao gồm các sự kiện quan sát được trong KGs. Điểm chất lượng được sử dụng thêm trong giai đoạn lý luận logic để giảm tác động của các luật chất lượng thấp. Cuối cùng, chúng tôi đưa các luật được xếp hạng vào một mô-đun lý luận logic để tiến hành lý luận có thể diễn giải trên KGs. Trong khung của chúng tôi, các luật được khai thác có thể được sử dụng trực tiếp cho các nhiệm vụ downstream mà không cần bất kỳ huấn luyện mô hình nào. Các thí nghiệm mở rộng trên bốn KG quy mô lớn chứng minh rằng ChatRule vượt trội đáng kể so với các phương pháp hiện đại nhất về cả hoàn thiện đồ thị tri thức và đánh giá chất lượng luật.

Các đóng góp chính của bài báo này được tóm tắt như sau:
• Chúng tôi đề xuất một khung gọi là ChatRule tận dụng lợi thế của LLMs để khai thác luật logic. Theo hiểu biết tốt nhất của chúng tôi, đây là công trình đầu tiên áp dụng LLMs cho khai thác luật logic.
• Chúng tôi trình bày một pipeline end-to-end sử dụng khả năng lý luận của LLMs và thông tin cấu trúc của KGs để tạo luật, xếp hạng luật và lý luận logic dựa trên luật.
• Chúng tôi tiến hành các thí nghiệm mở rộng trên bốn tập dữ liệu. Kết quả thí nghiệm cho thấy ChatRule vượt trội đáng kể so với các phương pháp hiện đại nhất.

2https://openai.com/blog/chatgpt
3https://bard.google.com/

## 2 Công trình Liên quan

### 2.1 Khai thác Luật Logic
Khai thác luật logic, tập trung vào việc trích xuất các luật có ý nghĩa từ KGs, đã được nghiên cứu trong thời gian dài. Các phương pháp truyền thống liệt kê các luật ứng viên, sau đó đánh giá chất lượng của chúng bằng cách tính toán điểm trọng số [Lao và Cohen, 2010; Galárraga et al., 2013]. Với sự tiến bộ của học sâu, các nhà nghiên cứu khám phá ý tưởng đồng thời học các luật logic và trọng số theo cách có thể vi phân [Yang et al., 2017; Sadeghian et al., 2019; Yang và Song, 2020]. Tuy nhiên, các phương pháp này vẫn tiến hành tối ưu hóa nặng nề trên không gian luật, điều này hạn chế khả năng mở rộng của chúng. Gần đây, các nhà nghiên cứu đã đề xuất lấy mẫu các đường dẫn từ KGs và huấn luyện các mô hình trên chúng để học các kết nối logic. RLvLR [Omran et al., 2018] lấy mẫu luật từ một đồ thị con và đề xuất một hàm điểm dựa trên embedding để ước tính tầm quan trọng của từng luật. RNNLogic [Qu et al., 2020] tách việc tạo luật và trọng số luật, có thể tăng cường lẫn nhau và giảm không gian tìm kiếm. R5 [Lu et al., 2021] đề xuất một khung học tăng cường tìm kiếm heuristic trên KGs và khai thác các luật logic cơ bản. NCRL [Cheng et al., 2022a] dự đoán thành phần tốt nhất của thân luật để khám phá luật. Ruleformer [Xu et al., 2022] áp dụng một mô hình dựa trên transformer để mã hóa thông tin ngữ cảnh và tạo luật cho các nhiệm vụ lý luận, đây là phương pháp hiện đại nhất trong lĩnh vực này. Tuy nhiên, các phương pháp hiện tại không xem xét ngữ nghĩa của các quan hệ và có thể dẫn đến kết quả không tối ưu.

### 2.2 Mô hình Ngôn ngữ Lớn
Các mô hình ngôn ngữ lớn (LLMs) đang cách mạng hóa lĩnh vực xử lý ngôn ngữ tự nhiên và trí tuệ nhân tạo. Nhiều LLMs (ví dụ, ChatGPT2, Bard3, FLAN [Wei et al., 2021], và LLaMA [Touvron et al., 2023]) đã chứng minh khả năng mạnh mẽ trong các nhiệm vụ khác nhau. Gần đây, các nhà nghiên cứu cũng đã khám phá khả năng áp dụng LLMs để giải quyết các nhiệm vụ KG [Pan et al., 2023; Luo et al., 2023]. Để tiếp cận tốt hơn tiềm năng của LLMs, các nhà nghiên cứu thiết kế một số lời nhắc với các ví dụ few-shot [Brown et al., 2020] hoặc lý luận chuỗi suy nghĩ [Wei et al., 2022] để tối đa hóa khả năng của chúng. Tuy nhiên, các phương pháp này không được thiết kế cho khai thác luật logic, đòi hỏi LLMs phải hiểu cả cấu trúc của KGs và ngữ nghĩa của các quan hệ để tạo ra các luật có ý nghĩa.

## 3 Khái niệm Sơ bộ và Định nghĩa Vấn đề
Đồ thị Tri thức (KGs) đại diện cho các tập hợp sự kiện dưới dạng bộ ba G={(e, r, e′)⊆ E ×R×E}, trong đó e, e′∈ E và r∈ R tương ứng biểu thị tập hợp các thực thể và quan hệ.

Luật Logic là các trường hợp đặc biệt của logic bậc nhất [Barwise, 1977], có thể hỗ trợ lý luận có thể diễn giải trên KGs [Yang et al., 2017]. Luật logic ρ phát biểu hàm ý logic ở dạng sau:

ρ:=rh(X, Y)←r1(X, Z1)∧ ··· ∧ rL(ZL−1, Y), (1)

trong đó body(ρ) := r1(X, Z1)∧ ··· ∧ rL(ZL−1, Y) biểu thị phép hội của một chuỗi quan hệ được gọi là thân luật, rh(X, Y) biểu thị đầu luật, và L biểu thị độ dài của luật. Nếu các điều kiện trên thân luật được thỏa mãn, thì phát biểu trên đầu luật cũng đúng.

Một thể hiện của luật được thực hiện bằng cách thay thế các biến X, Y, Z* bằng các thực thể thực tế trong KGs. Ví dụ, cho một luật BàNgoại(X, Y)←Mẹ(X, Z1)∧Cha(Z1, Y), một thể hiện luật δ có thể là
BàNgoại(Alice, Charlie)←
Mẹ(Alice, Bob)∧Cha(Bob, Charlie), (2)
có nghĩa là nếu Alice là mẹ của Bob và Bob là cha của Charlie, thì Alice là bà ngoại của Charlie.

Định nghĩa Vấn đề. Cho một quan hệ mục tiêu rh∈ R như đầu luật, mục tiêu của khai thác luật logic là tìm một tập hợp các luật có ý nghĩa Prh={ρ1,···, ρK} nắm bắt các kết nối logic của các quan hệ khác để biểu đạt quan hệ mục tiêu rh trong KGs.

## 4 Phương pháp
Trong phần này, chúng tôi sẽ giới thiệu khung được đề xuất, gọi là ChatRule, để khai thác luật logic trên KGs với các mô hình ngôn ngữ lớn. Khung tổng thể được minh họa trong Hình 2, chứa ba thành phần chính: 1) một bộ sinh luật dựa trên LLM tận dụng cả thông tin ngữ nghĩa và cấu trúc để tạo ra các luật có ý nghĩa. 2) một bộ xếp hạng luật để ước tính chất lượng của các luật được tạo ra trên KGs, và 3) một mô-đun lý luận logic dựa trên luật để tiến hành lý luận trên KGs cho các nhiệm vụ downstream.

### 4.1 Bộ Sinh Luật dựa trên LLM
Các nghiên cứu thông thường về khai thác luật logic thường tập trung vào việc sử dụng thông tin cấu trúc, [Galárraga et al., 2013; Cheng et al., 2022a], bỏ qua đóng góp của ngữ nghĩa quan hệ trong việc biểu đạt các kết nối logic. Để khai thác khả năng hiểu ngữ nghĩa của các mô hình ngôn ngữ lớn (LLMs), chúng tôi đề xuất một bộ sinh luật dựa trên LLM tận dụng cả thông tin ngữ nghĩa và cấu trúc của KGs trong việc tạo ra các luật có ý nghĩa.

Bộ Lấy mẫu Luật
Để cho phép LLMs hiểu cấu trúc KG để khai thác luật, chúng tôi áp dụng một bộ lấy mẫu tìm kiếm theo chiều rộng (BFS) để lấy mẫu một số đường dẫn đóng từ KGs, có thể được coi như các thể hiện của luật logic [Omran et al., 2018; Cheng et al., 2022b]. Cho một bộ ba (e1, rh, eL), đường dẫn đóng được định nghĩa là một chuỗi quan hệ r1,···, rL kết nối e1 và eL trong KGs, tức là e1→r1 e2→r2 ···→rL eL. Ví dụ, cho một bộ ba (Alice, BàNgoại, Charlie), một đường dẫn đóng p có thể được tìm thấy như
p:=Alice→Mẹ Bob→Cha Charlie, (3)
đóng bộ ba (Alice, BàNgoại, Charlie) trong KGs. Bằng cách coi bộ ba như đầu luật và đường dẫn đóng như thân luật, chúng ta có thể thu được thể hiện luật δ được hiển thị trong Phương trình (2).

Cho một quan hệ mục tiêu rh, chúng tôi trước tiên chọn một tập hợp các bộ ba hạt giống {(e, rh, e′)} từ KGs, từ đó chúng tôi tiến hành BFS để lấy mẫu một tập hợp các đường dẫn đóng {p} với độ dài ít hơn L để tạo thành một tập hợp các thể hiện luật {δ}. Sau đó, chúng tôi thay thế các thực thể thực tế trong các thể hiện luật bằng các biến để thu được các mẫu luật Srh={ρ}. Các mẫu luật truyền đạt thông tin cấu trúc của KGs ở định dạng tuần tự, có thể được đưa vào mô hình ngôn ngữ lớn để hỗ trợ tạo luật.

Bộ Lấy mẫu Luật
Bộ Sinh Luật dựa trên LLM
Mẫu Luật
Lời nhắc: Dựa trên các luật mẫu, vui lòng tạo ra các luật logic quan trọng cho quan hệ.
Nhiều Truy vấn
Luật Ứng viên
KGs
Luật được Xếp hạng
Lý luận Logic
Sự kiện Mới
①
②
④
Bộ Xếp hạng Luật③

Hình 2: Khung tổng thể của ChatRule. 1) chúng tôi trước tiên lấy mẫu một vài thể hiện luật từ đồ thị tri thức cho một quan hệ mục tiêu rh. 2) chúng tôi kích hoạt mô hình ngôn ngữ lớn (ví dụ, ChatGPT) để tạo ra một tập hợp các luật ứng viên thô. 3) chúng tôi đề xuất một bộ xếp hạng luật để ước tính chất lượng của các luật được tạo ra dựa trên các sự kiện trong KGs. 4) các luật cuối cùng có thể được áp dụng cho lý luận logic và giải quyết các nhiệm vụ downstream, như hoàn thiện đồ thị tri thức.

Tạo Luật dựa trên LLM
Các mô hình ngôn ngữ lớn (LLMs) được huấn luyện trên các kho dữ liệu quy mô lớn thể hiện khả năng hiểu ngữ nghĩa của ngôn ngữ tự nhiên và thực hiện lý luận phức tạp với tri thức thông thường [Zhou et al., 2020; Tan et al., 2023]. Để kết hợp thông tin cấu trúc và ngữ nghĩa, chúng tôi thiết kế một lời nhắc được chế tác tỉ mỉ để khai thác khả năng của LLMs để khai thác luật.

Đối với mỗi luật từ Srh thu được bởi bộ lấy mẫu luật cho một quan hệ mục tiêu rh, chúng tôi diễn đạt nó thành một câu ngôn ngữ tự nhiên bằng cách loại bỏ các ký hiệu đặc biệt trong tên quan hệ, có thể làm giảm hiểu biết ngữ nghĩa của LLMs. Đối với nghịch đảo của một quan hệ gốc (tức là, wife−1), chúng tôi diễn đạt nó bằng cách thêm ký hiệu "inv ". Sau đó, chúng tôi đặt các mẫu luật được diễn đạt vào mẫu lời nhắc và đưa chúng vào LLMs (ví dụ, ChatGPT) để tạo ra các luật. Một ví dụ về lời nhắc tạo luật và kết quả của LLMs cho quan hệ "husband(X,Y)" được hiển thị trong Hình 3. Lời nhắc chi tiết có thể được tìm thấy trong Phụ lục.

Luật logic định nghĩa mối quan hệ giữa hai thực thể: X và Y. Mỗi luật được viết dưới dạng hàm ý logic, phát biểu rằng nếu các điều kiện ở phía bên phải (thân luật) được thỏa mãn, thì phát biểu ở phía bên trái (đầu luật) là đúng.

Bây giờ chúng ta có các mẫu luật sau:
husband(X,Y) <-- inv_wife(X,Y)
husband(X,Y) <-- father(X,Z_1) & daughter(Z_1,Y)
...
husband(X,Y) <-- father(X,Z_1) & sister(Z_1,Z_2) & daughter(Z_2,Y)

Dựa trên các luật trên, vui lòng tạo ra càng nhiều càng tốt các luật quan trọng nhất cho đầu luật: "husband(X,Y)"

Lời nhắc Tạo Luật

husband(X,Y) <-- inv_wife(X,Y)
husband(X,Y) <-- father(X,Z_1) & daughter(Z_1, Y)
husband(X,Y) <-- nephew(X,Z_1) & aunt(Z_1,Y)
husband(X,Y) <-- husband(X,Z_1) & brother(Z_1, Y)
....

Đầu ra

Hình 3: Một ví dụ về lời nhắc tạo luật và kết quả của LLMs cho quan hệ "husband(X,Y)".

Tạo Luật Nhiều Truy vấn
Do số lượng lớn các mẫu luật, chúng không thể tất cả được đưa vào LLMs cùng một lúc do vượt quá giới hạn ngữ cảnh. Do đó, chúng tôi chia các mẫu luật thành d truy vấn khác nhau. Mỗi truy vấn chứa k mẫu luật được chọn ngẫu nhiên từ Srh. Sau đó chúng tôi kích hoạt LLMs với các truy vấn riêng biệt và thu thập các phản hồi của LLMs để thu được một tập hợp các luật ứng viên Crh={ρ}.

### 4.2 Xếp hạng Luật Logic
LLMs được biết đến với các vấn đề ảo giác, có thể tạo ra kết quả không chính xác [Ji et al., 2023]. Ví dụ, luật được tạo ra husband(X, Y)←husband(X, Z1) & brother(Z1, Y), được hiển thị trong kết quả của Hình 3, là không chính xác. Do đó, chúng tôi phát triển một bộ xếp hạng luật để phát hiện ảo giác và ước tính chất lượng của các luật được tạo ra dựa trên các sự kiện trong KGs.

Bộ xếp hạng luật nhằm gán một điểm chất lượng s(ρ) cho mỗi luật ρ trong tập hợp luật ứng viên Crh. Được thúc đẩy bởi các công trình khai thác luật trước đây [Galárraga et al., 2013], chúng tôi sử dụng bốn biện pháp, cụ thể là hỗ trợ, bao phủ, độ tin cậy và độ tin cậy PCA, để đánh giá chất lượng của các luật. Giới thiệu chi tiết và ví dụ của từng biện pháp có thể được tìm thấy trong Phụ lục.

Hỗ trợ biểu thị số lượng sự kiện trong KGs thỏa mãn luật ρ, được định nghĩa là
supp(ρ) := #(e, e′) :∃(e, r1, e2)∧,···,∧(eL−1, rL, e′) :
body(ρ)∧(e, rh, e′)∈ G, (4)
trong đó (e1, r1, e2),···,(eL−1, rL, e′) biểu thị một chuỗi sự kiện trong KGs thỏa mãn thân luật body(ρ) và (e, rh, e′) biểu thị sự kiện thỏa mãn đầu luật rh.

Rõ ràng, các luật có hỗ trợ bằng không có thể dễ dàng được loại bỏ khỏi tập hợp ứng viên mà không cần tinh chỉnh thêm. Tuy nhiên, hỗ trợ là một số tuyệt đối có thể cao hơn đối với các quan hệ có nhiều sự kiện hơn trong KGs và cung cấp kết quả xếp hạng thiên lệch.

Bao phủ chuẩn hóa hỗ trợ bằng số lượng sự kiện cho mỗi quan hệ trong KGs, được định nghĩa là
cove(ρ) :=supp(ρ)
#(e, e′) : (e, rh, e′)∈ G. (5)

Bao phủ định lượng tỷ lệ các sự kiện hiện có trong KGs được ngụ ý bởi luật ρ. Để xem xét thêm các dự đoán không chính xác của các luật, chúng tôi giới thiệu độ tin cậy và độ tin cậy PCA để ước tính chất lượng của các luật.

Độ tin cậy được định nghĩa là tỷ lệ số lượng sự kiện thỏa mãn luật ρ và số lần thân luật body(ρ) được thỏa mãn trong KGs, được định nghĩa là
conf(ρ) :=supp(ρ)
#(e, e′) :body(ρ)∈ G. (6)

Độ tin cậy giả định rằng tất cả các sự kiện được suy ra từ thân luật nên được chứa trong KGs. Tuy nhiên, KGs thường không hoàn chỉnh trong thực tế, có thể dẫn đến thiếu các sự kiện bằng chứng. Do đó, chúng tôi giới thiệu độ tin cậy PCA để chọn các luật có thể tổng quát hóa tốt hơn cho các sự kiện chưa thấy.

Độ tin cậy PCA dựa trên lý thuyết giả định hoàn thiện một phần (PCA) [Galárraga et al., 2013] được định nghĩa là tỷ lệ số lượng sự kiện thỏa mãn luật ρ và số lần thân luật body(ρ) được thỏa mãn trong việc hoàn thiện một phần của KGs, được định nghĩa là
partial(ρ)(e, e′) := (e, r1, e2)∧,···,∧(eL−1, rL, ê) :
body(ρ)∧(e, rh, ê), (7)
pca(ρ) :=supp(ρ)
#(e, e′) :partial(ρ)(e, e′)∈ G. (8)

Mẫu số của độ tin cậy PCA không phải là kích thước của toàn bộ tập hợp các sự kiện được suy ra từ thân luật. Thay vào đó, nó dựa trên số lượng sự kiện mà chúng ta biết là đúng cùng với những sự kiện mà chúng ta giả định là sai. Do đó, độ tin cậy PCA tốt hơn để ước tính chất lượng và khả năng tổng quát hóa của các luật trong KGs không hoàn chỉnh. Kết quả thí nghiệm trong đánh giá chất lượng luật cũng hỗ trợ tuyên bố này.

### 4.3 Lý luận Logic dựa trên Luật
Sau khi xếp hạng luật logic, chúng tôi thu được một tập hợp các luật được xếp hạng Rrh={(ρ, s(ρ))} cho quan hệ mục tiêu rh. Các luật được xếp hạng có thể được sử dụng cho lý luận logic và giải quyết các nhiệm vụ downstream, như hoàn thiện đồ thị tri thức, bằng cách áp dụng các thuật toán hiện có như chuỗi tiến [Salvat và Mugnier, 1996].

Cho một truy vấn (e, rh, ?), gọi A là tập hợp các câu trả lời ứng viên. Đối với mỗi e′∈A, chúng ta có thể áp dụng luật trong Prh để thu được điểm như
score(e′) =Σρ∈Rrh Σbody(ρ)(e,e′)∈G s(ρ), (9)
trong đó body(ρ)(e, e′) biểu thị đường dẫn trong KGs thỏa mãn thân luật, và s(ρ) biểu thị điểm chất lượng của luật, có thể là bao phủ, độ tin cậy và độ tin cậy PCA. Sau đó, chúng ta có thể xếp hạng các câu trả lời ứng viên A dựa trên điểm số và chọn N câu trả lời hàng đầu làm kết quả cuối cùng.

## 5 Thí nghiệm

### 5.1 Tập dữ liệu
Trong thí nghiệm, chúng tôi chọn bốn tập dữ liệu được sử dụng rộng rãi theo các nghiên cứu trước đây [Cheng et al., 2022b]: Family [Hinton và những người khác, 1986], UMLS [Kok và Domingos, 2007], WN18RR [Dettmers et al., 2018], và YAGO3-10 [Suchanek et al., 2007]. Thống kê của các tập dữ liệu được tóm tắt trong Bảng 1.

### 5.2 Baseline
Chúng tôi so sánh phương pháp của mình với các baseline khai thác luật SOTA: AIME [Galárraga et al., 2013], NeuralLP [Yang et al., 2017], RNNLogic [Qu et al., 2020], NLIL [Yang và Song, 2020], NCRL [Cheng et al., 2022a], và Ruleformer [Xu et al., 2022], trên cả nhiệm vụ hoàn thiện đồ thị tri thức và đánh giá chất lượng luật.

### 5.3 Chỉ số
Đối với nhiệm vụ hoàn thiện đồ thị tri thức, chúng tôi che thực thể đuôi hoặc đầu của mỗi bộ ba thử nghiệm và sử dụng luật được tạo ra bởi mỗi phương pháp để dự đoán nó. Theo các nghiên cứu trước đây [Cheng et al., 2022a], chúng tôi sử dụng thứ hạng nghịch đảo trung bình (MRR) và Hits@N làm chỉ số đánh giá và đặt N là 1 và 10. Đối với nhiệm vụ đánh giá chất lượng luật, chúng tôi sử dụng các biện pháp (ví dụ, hỗ trợ, bao phủ, độ tin cậy và độ tin cậy PCA) được thảo luận trong phần trước về xếp hạng luật.

Bảng 1: Thống kê tập dữ liệu
Tập dữ liệu #Bộ ba #Quan hệ #Thực thể
Family 28,356 12 3,007
UMLS 5,960 46 135
WN18RR 93,003 11 40,943
YAGO3-10 1,089,040 37 123,182

### 5.4 Cài đặt Thí nghiệm
Đối với ChatRule, chúng tôi sử dụng ChatGPT4 làm LLMs để tạo luật. Chúng tôi chọn độ tin cậy PCA làm biện pháp xếp hạng luật cuối cùng và đặt độ dài luật tối đa L là 3. Trong nhiệm vụ hoàn thiện đồ thị tri thức, chúng tôi tuân theo các cài đặt tương tự như các nghiên cứu trước đây [Cheng et al., 2022b; Cheng et al., 2022a]. Đối với baseline, chúng tôi sử dụng triển khai chính thức được công bố để tiến hành thí nghiệm. Thảo luận chi tiết về các cài đặt có thể được tìm thấy trong Phụ lục.

### 5.5 Hoàn thiện Đồ thị Tri thức
Hoàn thiện đồ thị tri thức là một nhiệm vụ cổ điển nhằm dự đoán các sự kiện thiếu bằng cách sử dụng lý luận logic dựa trên luật. Nhiệm vụ này đã được áp dụng bởi các phương pháp khai thác luật hiện có khác nhau như Neural-LP [Yang et al., 2017], và NCRL [Cheng et al., 2022a] để đánh giá chất lượng của các luật được tạo ra. Chúng tôi áp dụng các luật được tạo ra bởi mỗi phương pháp và sử dụng cùng lý luận logic dựa trên luật được trình bày trong Phần 4.3 để dự đoán các sự kiện thiếu. Kết quả được hiển thị trong Bảng 2.

Từ kết quả, chúng ta có thể quan sát thấy ChatRule vượt trội hơn các baseline trên hầu hết các tập dữ liệu. Cụ thể, phương pháp truyền thống AIME, chỉ sử dụng thông tin cấu trúc với lập trình logic quy nạp, đã đạt được hiệu suất tương đối tốt. Tuy nhiên, AIME thất bại trong các KG quy mô lớn (ví dụ, YAGO3-10) do số lượng quan hệ và bộ ba tăng lên. Các phương pháp dựa trên học sâu gần đây (ví dụ, Neural-LP, RNNLogic và NLIL) đạt được hiệu suất tốt hơn bằng cách sử dụng khả năng học của mạng neural khi chúng tối ưu hóa các mô hình trên các nhiệm vụ học luật. Tuy nhiên, chúng gặp vấn đề hết bộ nhớ trong việc xử lý các KG lớn do không gian tìm kiếm luật rộng lớn. Trong khi NCRL lấy mẫu đường dẫn đóng để giảm không gian tìm kiếm, nó vẫn bỏ qua ngữ nghĩa của các quan hệ, dẫn đến hiệu suất không tối ưu. Tương tự như kiến trúc của LLMs, Ruleformer áp dụng một mô hình dựa trên transformer để tổng hợp thông tin ngữ cảnh từ KGs và tạo ra luật theo cách sequence-to-sequence, đạt được hiệu suất tốt thứ hai. Điều này cũng chứng minh tiềm năng to lớn của kiến trúc transformer trong khai thác luật logic. Với sự giúp đỡ của các LLM được huấn luyện trước mạnh mẽ, ChatRule có thể tạo ra các luật chất lượng cao bằng cách kết hợp thông tin cấu trúc và ngữ nghĩa của KGs. ChatRule cũng thiết lập hiệu suất STOA mới trong hầu hết các cài đặt.

4Chúng tôi sử dụng snapshot của ChatGPT được chụp từ ngày 13 tháng 6 năm 2023 (gpt-3.5-turbo-0613) để đảm bảo tính tái tạo.

Bảng 2: Kết quả hoàn thiện đồ thị tri thức. OOM biểu thị hết bộ nhớ.

Phương pháp Family UMLS WN18RR YAGO3-10
MRR Hits@1 Hits@10 MRR Hits@1 Hits@10 MRR Hits@1 Hits@10 MRR Hits@1 Hits@10
AMIE 0.778 0.683 0.891 0.312 0.195 0.560 0.162 0.060 0.278 0.012 0.008 0.021
Neural-LP 0.785 0.720 0.863 0.505 0.415 0.638 0.228 0.223 0.235 OOM OOM OOM
RNNLogic 0.860 0.792 0.957 0.750 0.630 0.924 0.216 0.183 0.275 OOM OOM OOM
NLIL 0.358 0.321 0.416 0.693 0.632 0.921 0.223 0.222 0.225 OOM OOM OOM
NCRL 0.826 0.725 0.963 0.728 0.576 0.938 0.316 0.272 0.397 0.234 0.181 0.334
Ruleformer 0.897 0.841 0.963 0.691 0.555 0.863 0.292 0.258 0.355 0.527 0.520 0.535
ChatRule (ChatGPT) 0.906 0.854 0.968 0.780 0.685 0.948 0.335 0.301 0.400 0.449 0.354 0.627

Bảng 3: Kết quả đánh giá chất lượng luật.

Phương pháp Family UMLS
Hỗ trợ Bao phủ Độ tin cậy Độ tin cậy PCA Hỗ trợ Bao phủ Độ tin cậy Độ tin cậy PCA
AMIE 243.90 0.11 0.17 0.30 35.52 0.10 0.13 0.21
Neural-LP 280.94 0.13 0.21 0.30 11.59 0.06 0.08 0.09
NCRL 179.96 0.09 0.12 0.16 13.25 0.03 0.04 0.06
Ruleformer 325.32 0.15 0.22 0.32 57.00 0.25 0.33 0.37
ChatRule (ChatGPT) 403.04 0.17 0.23 0.34 28.06 0.32 0.21 0.38

Phương pháp WN18RR YAGO3-10
Hỗ trợ Bao phủ Độ tin cậy Độ tin cậy PCA Hỗ trợ Bao phủ Độ tin cậy Độ tin cậy PCA
AMIE 378.76 0.07 0.08 0.10 758.28 0.06 0.06 0.07
Neural-LP 285.24 0.05 0.06 0.09 - - - -
NCRL 400.38 0.18 0.02 0.03 12660.16 0.13 0.12 0.05
Ruleformer 325.32 0.15 0.22 0.32 495.79 0.15 0.22 0.22
ChatRule (ChatGPT) 667.28 0.12 0.09 0.16 13656.41 0.27 0.09 0.14

### 5.6 Đánh giá Chất lượng Luật
Để chứng minh thêm hiệu quả của bốn biện pháp (tức là, hỗ trợ, bao phủ, độ tin cậy và độ tin cậy PCA) được áp dụng trong xếp hạng luật, chúng tôi sử dụng chúng để đánh giá các luật được tạo ra bởi mỗi phương pháp. Kết quả được hiển thị trong Bảng 3.

Từ kết quả, chúng ta có thể quan sát thấy ChatRule có thể tạo ra các luật với hỗ trợ, bao phủ và độ tin cậy cao hơn so với các baseline. Cụ thể, chúng ta có thể quan sát thấy điểm số của các biện pháp phù hợp với hiệu suất trong hoàn thiện đồ thị tri thức. Điều này chứng minh rằng các biện pháp được chọn có thể định lượng tốt chất lượng của các luật. Đáng chú ý, trong khi NCRL đạt được điểm số cao hơn Ruleformer trong chỉ số hỗ trợ của YAGO3-10 (12660.16 so với 495.79), NCRL vẫn bị Ruleformer vượt qua trong hoàn thiện đồ thị tri thức. Điều này là do các luật được tạo ra bởi Ruleformer có độ tin cậy PCA tốt hơn, phù hợp hơn để đánh giá các luật trong KGs không hoàn chỉnh. Tương tự, điểm độ tin cậy PCA cao hơn cho thấy ChatRule có thể tạo ra các luật với khả năng tổng quát hóa tốt hơn thay vì chỉ dựa vào các luật mẫu từ lời nhắc. Do đó, ChatRule cũng chứng minh hiệu suất vượt trội trong nhiệm vụ hoàn thiện đồ thị tri thức.

### 5.7 Nghiên cứu Loại bỏ

Phân tích các LLM khác nhau. Chúng tôi trước tiên đánh giá hiệu suất của ChatRule với một số LLM ở các kích thước khác nhau, bao gồm GPT-4 [OpenAI, 2023], Mistral-7B-Instruct [Jiang et al., 2023], và LLaMA2-Chat-7B/13B/70B [Touvron et al., 2023]. Chi tiết về các phiên bản mô hình có sẵn trong Phụ lục.

Bảng 4: Hiệu suất hoàn thiện đồ thị tri thức sử dụng luật được tạo ra bởi các LLM khác nhau trên tập dữ liệu Family.

Mô hình MRR Hits@1 Hits@10
ChatGPT 0.849 0.765 0.964
GPT-4 0.803 0.704 0.926
Mistral-7B-Instruct 0.735 0.652 0.912
Llama2-chat-7B 0.742 0.636 0.893
Llama2-chat-7B-13B 0.767 0.671 0.900
Llama2-chat-7B-70B 0.731 0.626 0.875

Từ kết quả được hiển thị trong Bảng 4, chúng ta có thể quan sát thấy ChatRule với các LLM khác nhau vẫn đạt được hiệu suất có thể so sánh với các baseline. Điều này chứng minh khả năng tổng quát hóa của ChatRule. Một phát hiện thú vị là hiệu suất của ChatRule không phải lúc nào cũng được cải thiện bằng cách sử dụng các LLM lớn hơn. Ví dụ, ChatRule hoạt động tốt hơn với ChatGPT so với GPT-4. Trong họ LLaMA2, LLaMA2-Chat-7B vượt trội hơn LLaMA2-Chat-70B nhưng bị LLaMA2-Chat-13B vượt qua. Một lý do cho điều này là các LLM khác nhau nhạy cảm với lời nhắc đầu vào; chúng có thể hoạt động khác nhau và đạt được các mức độ hiệu suất khác nhau mặc dù có cùng lời nhắc đầu vào. Do đó, việc điều chỉnh thêm lời nhắc đầu vào cho các LLM khác nhau có thể đạt được hiệu suất tốt hơn. Một lý do khác là các LLM lớn hơn có xu hướng tạo ra ít luật hơn so với các LLM nhỏ hơn. Chúng tôi giả thuyết điều này có thể do chi phí tính toán nặng hơn của các LLM lớn hơn, có thể dẫn đến xác suất dừng sớm cao hơn. Số lượng luật giảm có thể dẫn đến bao phủ kém hơn của các luật sự thật và hiệu suất không tối ưu.

Phân tích các biện pháp xếp hạng. Chúng tôi kiểm tra hiệu quả của từng biện pháp (tức là, bao phủ, độ tin cậy và độ tin cậy PCA) được áp dụng trong xếp hạng luật. Các luật đều được tạo ra bởi ChatGPT trên các tập dữ liệu Family và UMLS.

Kết quả được hiển thị trong Bảng 5. Từ kết quả, chúng ta có thể thấy rằng khi một trong các biện pháp xếp hạng được sử dụng, hiệu suất của ChatRule được cải thiện so với khi không có biện pháp xếp hạng (tức là, Không có) được sử dụng. Điều này chứng minh rằng biện pháp xếp hạng có thể hiệu quả giảm tác động của các luật chất lượng thấp. Chỉ số độ tin cậy PCA đạt được hiệu suất tốt nhất trong tất cả các biện pháp xếp hạng. Điều này cho thấy độ tin cậy PCA cho phép định lượng chất lượng của các luật trong KGs không hoàn chỉnh và chọn các luật với khả năng tổng quát hóa tốt hơn, điều này cũng được chọn làm chỉ số xếp hạng cuối cùng.

Bảng 5: Phân tích từng biện pháp xếp hạng.

Chỉ số Xếp hạng Family UMLS
MRR Hits@1 Hits@10 MRR Hits@1 Hits@10
Không có 0.756 0.630 0.940 0.413 0.327 0.605
Bao phủ 0.795 0.673 0.956 0.604 0.460 0.843
Độ tin cậy 0.872 0.799 0.967 0.700 0.602 0.898
Độ tin cậy PCA 0.906 0.854 0.968 0.780 0.685 0.948

Phân tích các siêu tham số. Cuối cùng, chúng tôi đánh giá hiệu suất của ChatRule với các siêu tham số khác nhau, tức là, số lượng mẫu luật khác nhau trên mỗi truy vấn (k) và số lượng truy vấn khác nhau (d) trên tập dữ liệu Family. Kết quả được hiển thị trong Hình 4.

Từ kết quả, chúng ta có thể quan sát thấy hiệu suất của ChatRule trước tiên cải thiện với sự tăng của k và giảm nhẹ khi k đạt 50. Điều này cho thấy với nhiều mẫu luật hơn trong lời nhắc, ChatRule có thể tạo ra các luật với chất lượng tốt hơn. Tuy nhiên, giá trị k quá lớn dẫn đến lời nhắc dài hơn. Các LLM hiện tại được biết đến với việc gặp khó khăn trong việc hiểu ngữ cảnh dài [Liu et al., 2023], có thể dẫn đến hiệu suất không tối ưu. Ngược lại, hiệu suất của ChatRule tiếp tục cải thiện với sự tăng của d. Điều này chứng minh rằng ChatRule có thể tạo ra các luật tốt hơn bằng cách "nhìn thấy" nhiều mẫu luật hơn trong KGs. Tuy nhiên, nhiều truy vấn hơn cũng đưa ra chi phí tính toán cao hơn, có thể hạn chế khả năng mở rộng của ChatRule. Do đó, chúng tôi đặt k là 50 và d là 10 trong thí nghiệm.

[Hình 4: Phân tích tham số về số lượng mẫu luật trên mỗi truy vấn (k) và số lượng truy vấn (d) trên tập dữ liệu Family.]

### 5.8 Nghiên cứu Trường hợp
Chúng tôi trước tiên hiển thị thống kê của luật được khai thác và tổng chi phí API5 tương ứng cho mỗi tập dữ liệu trong Bảng 6. Từ kết quả, chúng ta có thể quan sát thấy ChatRule có thể khai thác một số lượng đáng kể các luật có ý nghĩa với chi phí API thấp.

Bảng 6: Thống kê của các luật được khai thác và tổng chi phí API cho mỗi tập dữ liệu.

Tập dữ liệu Tổng số Luật Luật Trung bình mỗi Quan hệ Chi phí ($)
Family 1200 100 0.880
UMLS 610 29 2.623
WN18RR 451 41 0.399
YAGO 1924 50 1.409

Chúng tôi trình bày một số luật logic đại diện được khai thác từ các tập dữ liệu khác nhau trong Bảng 7. Kết quả cho thấy các luật được tạo ra bởi phương pháp của chúng tôi vừa có thể diễn giải vừa có chất lượng cao. Ví dụ, "wife" trực quan là quan hệ nghịch đảo của "husband", luật husband ←inv wife được ChatRule trích xuất thành công với ngữ nghĩa của mối quan hệ được xem xét. Tương tự, "playsFor" là từ đồng nghĩa của "isAffiliatedTo", tạo thành luật playsFor ←isAffiliatedTo. Ngoài ra, các luật cũng tuân theo tri thức thông thường, thể hiện khả năng diễn giải tuyệt vời. Ví dụ, luật diagnoses ← analyzes ∧ causes cho thấy để đưa ra chẩn đoán, bác sĩ thường cần phân tích các triệu chứng của bệnh nhân và tìm nguyên nhân của bệnh. Cuối cùng, các luật được tạo ra cũng khám phá một số kết nối logic liên kết. Luật isPoliticianOf ← hasChild ∧ isPoliticianOf cho thấy trẻ em thường thừa hưởng vị trí chính trị của cha mẹ, được hỗ trợ bởi điểm hỗ trợ và PCA. Danh sách đầy đủ các luật được khai thác có sẵn trong tệp bổ sung.

Bảng 7: Luật đại diện được khai thác trên mỗi tập dữ liệu.

Tập dữ liệu Luật Hỗ trợ Độ tin cậy PCA
Family husband ←inv wife 655 0.98
father ←husband ∧ mother 1260 0.88
aunt←sister ∧ aunt 2152 0.79
UMLS prevents ←complicates ∧ inv prevents ∧ causes 16 0.53
treats ←prevents ∧ inv treats ∧ treats 51 0.92
diagnoses ←analyzes ∧ causes 20 1.00
WN18RR haspart←haspart∧inv haspart∧haspart 4209 0.39
also see←also see∧inv also see∧also see 1151 0.47
hypernym ←member meronym ∧inv member meronym ∧hypernym 1996 1.0
YAGO3-10 hasChild ←isMarriedTo ∧ hasChild 1174 0.60
isPoliticianOf ←hasChild ∧ isPoliticianOf 720 0.86
playsFor ←isAffiliatedTo 229794 0.75

## 6 Kết luận
Trong bài báo này, chúng tôi giới thiệu một phương pháp mới gọi là ChatRule để thu hẹp khoảng cách trong khai thác luật logic trên KGs. Trong ChatRule, chúng tôi đề xuất một bộ sinh luật dựa trên LLMs kết hợp cả thông tin ngữ nghĩa và cấu trúc để tạo ra các luật có ý nghĩa. Ngoài ra, một bộ xếp hạng luật được phát triển để đánh giá chất lượng của các luật và loại bỏ những luật không chính xác. Cuối cùng, các luật được tạo ra có thể được sử dụng trực tiếp cho lý luận đồ thị tri thức mà không cần huấn luyện mô hình bổ sung. Các thí nghiệm mở rộng trên một số tập dữ liệu chứng minh ChatRule có thể tạo ra các luật chất lượng cao và có thể diễn giải cho các nhiệm vụ downstream. Trong tương lai, chúng tôi sẽ khám phá tích hợp các mô hình tiên tiến để nâng cao hiểu biết của LLMs về thông tin cấu trúc và cải thiện hiệu suất của khai thác luật.

5Chi phí được tính toán dựa trên giá API được định nghĩa bởi OpenAI (tức là, 0.001$ và 0.002$ cho 1000 token đầu vào và đầu ra).

## Tài liệu Tham khảo
[Atif et al., 2023] Farah Atif, Ola El Khatib, và Djellel Difallah. Beamqa: Multi-hop knowledge graph question answering with sequence-to-sequence prediction and beam search. Trong SIGIR, trang 781–790, 2023.

[Barwise, 1977] Jon Barwise. An introduction to first-order logic. Trong Studies in Logic and the Foundations of Mathematics, tập 90, trang 5–46. Elsevier, 1977.

[Brown et al., 2020] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. NeurIPS, 33:1877–1901, 2020.

[Chen et al., 2016] Yang Chen, Sean Goldberg, Daisy Zhe Wang, và Soumitra Siddharth Johri. Ontological pathfinding. Trong SIGMOD, trang 835–846, 2016.

[Cheng et al., 2022a] Kewei Cheng, Nesreen Ahmed, và Yizhou Sun. Neural compositional rule learning for knowledge graph reasoning. Trong ICLR, 2022.

[Cheng et al., 2022b] Kewei Cheng, Jiahao Liu, Wei Wang, và Yizhou Sun. Rlogic: Recursive logical rule learning from knowledge graphs. Trong KDD, trang 179–189, 2022.

[Dettmers et al., 2018] Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, và Sebastian Riedel. Convolutional 2d knowledge graph embeddings. Trong AAAI, tập 32, 2018.

[Galárraga et al., 2013] Luis Antonio Galárraga, Christina Teflioudi, Katja Hose, và Fabian Suchanek. Amie: association rule mining under incomplete evidence in ontological knowledge bases. Trong WWW, trang 413–422, 2013.

[Hinton và những người khác, 1986] Geoffrey E Hinton et al. Learning distributed representations of concepts. Trong Proceedings of the eighth annual conference of the cognitive science society, tập 1, trang 12. Amherst, MA, 1986.

[Hou et al., 2021] Zhongni Hou, Xiaolong Jin, Zixuan Li, và Long Bai. Rule-aware reinforcement learning for knowledge graph reasoning. Trong ACL, trang 4687–4692, 2021.

[Ji et al., 2023] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, và Pascale Fung. Survey of hallucination in natural language generation. ACM Computing Surveys, 55(12):1–38, 2023.

[Jiang et al., 2023] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, và William El Sayed. Mistral 7b, 2023.

[Kok và Domingos, 2007] Stanley Kok và Pedro Domingos. Statistical predicate invention. Trong ICML, trang 433–440, 2007.

[Lao và Cohen, 2010] Ni Lao và William W Cohen. Relational retrieval using a combination of path-constrained random walks. Machine learning, 81:53–67, 2010.

[Liu et al., 2021] Yushan Liu, Marcel Hildebrandt, Mitchell Joblin, Martin Ringsquandl, Rime Raissouni, và Volker Tresp. Neural multi-hop reasoning with logical rules on biomedical knowledge graphs. Trong ESWC, trang 375–391. Springer, 2021.

[Liu et al., 2022] Yushan Liu, Yunpu Ma, Marcel Hildebrandt, Mitchell Joblin, và Volker Tresp. Tlogic: Temporal logical rules for explainable link forecasting on temporal knowledge graphs. Trong AAAI, tập 36, trang 4120–4127, 2022.

[Liu et al., 2023] Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, và Percy Liang. Lost in the middle: How language models use long contexts. arXiv preprint arXiv:2307.03172, 2023.

[Lu et al., 2021] Shengyao Lu, Bang Liu, Keith G Mills, SHANGLING JUI, và Di Niu. R5: Rule discovery with reinforced and recurrent relational reasoning. Trong ICLR, 2021.

[Luo et al., 2023] Linhao Luo, Yuan-Fang Li, Gholamreza Haffari, và Shirui Pan. Reasoning on graphs: Faithful and interpretable large language model reasoning. arXiv preprint arXiv:2310.01061, 2023.

[Omran et al., 2018] Pouya Ghiasnezhad Omran, Kewen Wang, và Zhe Wang. Scalable rule learning via learning representation. Trong IJCAI, trang 2149–2155, 2018.

[OpenAI, 2023] OpenAI. Gpt-4 technical report, 2023.

[Pan et al., 2023] Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, và Xindong Wu. Unifying large language models and knowledge graphs: A roadmap. arXiv preprint arXiv:2306.08302, 2023.

[Qu và Tang, 2019] Meng Qu và Jian Tang. Probabilistic logic neural networks for reasoning. NeurIPS, 32, 2019.

[Qu et al., 2020] Meng Qu, Junkun Chen, Louis-Pascal Xhonneux, Yoshua Bengio, và Jian Tang. Rnnlogic: Learning logic rules for reasoning on knowledge graphs. Trong ICLR, 2020.

[Sadeghian et al., 2019] Ali Sadeghian, Mohammadreza Armandpour, Patrick Ding, và Daisy Zhe Wang. Drum: End-to-end differentiable rule mining on knowledge graphs. NeurIPS, 32, 2019.

[Salvat và Mugnier, 1996] Eric Salvat và Marie-Laure Mugnier. Sound and complete forward and backward chainings of graph rules. Trong International Conference on Conceptual Structures, trang 248–262, 1996.

[Suchanek et al., 2007] Fabian M Suchanek, Gjergji Kasneci, và Gerhard Weikum. Yago: a core of semantic knowledge. Trong WWW, trang 697–706, 2007.

[Tan et al., 2023] Yiming Tan, Dehai Min, Yu Li, Wenbo Li, Nan Hu, Yongrui Chen, và Guilin Qi. Evaluation of chatgpt as a question answering system for answering complex questions. arXiv preprint arXiv:2303.07992, 2023.

[Touvron et al., 2023] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.

[Wang et al., 2019] Xiang Wang, Dingxian Wang, Canran Xu, Xiangnan He, Yixin Cao, và Tat-Seng Chua. Explainable reasoning over knowledge graphs for recommendation. Trong AAAI, tập 33, trang 5329–5336, 2019.

[Wei et al., 2021] Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, và Quoc V Le. Finetuned language models are zero-shot learners. Trong ICLR, 2021.

[Wei et al., 2022] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. NeurIPS, 35:24824–24837, 2022.

[Xu et al., 2022] Zezhong Xu, Peng Ye, Hui Chen, Meng Zhao, Huajun Chen, và Wen Zhang. Ruleformer: Context-aware rule mining over knowledge graph. Trong Proceedings of the 29th International Conference on Computational Linguistics, trang 2551–2560, 2022.

[Yang và Song, 2020] Yuan Yang và Le Song. Learn to explain efficiently via neural logic inductive learning. Trong International Conference on Learning Representations, 2020.

[Yang et al., 2017] Fan Yang, Zhilin Yang, và William W Cohen. Differentiable learning of logical rules for knowledge base reasoning. NeurIPS, 30, 2017.

[Zhao et al., 2023] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. A survey of large language models. arXiv preprint arXiv:2303.18223, 2023.

[Zhong et al., 2020] Haoxi Zhong, Yuzhong Wang, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu, và Maosong Sun. Iteratively questioning and answering for interpretable legal judgment prediction. Trong AAAI, tập 34, trang 1250–1257, 2020.

[Zhou et al., 2020] Xuhui Zhou, Yue Zhang, Leyang Cui, và Dandan Huang. Evaluating commonsense in pre-trained language models. Trong AAAI, tập 34, trang 9733–9740, 2020.

## A Biện pháp Xếp hạng
Trong phần này, chúng tôi cung cấp một ví dụ chi tiết về các biện pháp xếp hạng (tức là, hỗ trợ, bao phủ, độ tin cậy và độ tin cậy PCA). Ví dụ, cho một luật
ρ:=playsFor ←isAffiliatedTo,
và một KG đơn giản trong Bảng 8. Các biện pháp có thể được tính toán như sau.

Hỗ trợ biểu thị số lượng sự kiện trong KGs thỏa mãn luật ρ, được định nghĩa là
supp(ρ) := #(e, e′) :∃(e, r1, e2)∧,···,∧(eL−1, rL, e′) :
body(ρ)∧(e, rh, e′)∈ G, (10)
trong đó (e1, r1, e2),···,(eL−1, rL, e′) biểu thị một chuỗi sự kiện trong KGs thỏa mãn thân luật body(ρ) và (e, rh, e′) biểu thị sự kiện thỏa mãn đầu luật rh.

Ví dụ. Đối với KG cho trong Bảng 8, hỗ trợ của luật là 1, vì (Alex, isAffiliatedTo, Club 1) và (Alex, playsFor, Club 1) tồn tại trong KG.

Bao phủ chuẩn hóa hỗ trợ bằng số lượng sự kiện cho mỗi quan hệ trong KGs, được định nghĩa là
cove(ρ) :=supp(ρ)
#(e, e′) : (e, rh, e′)∈ G. (11)

Ví dụ. Đối với KG cho trong Bảng 8, bao phủ của luật là 1/2, vì chúng ta có 2 sự kiện dưới quan hệ "playsFor".

Bao phủ định lượng tỷ lệ các sự kiện hiện có trong KGs được ngụ ý bởi luật ρ. Để xem xét thêm các dự đoán không chính xác của các luật, chúng tôi giới thiệu độ tin cậy và độ tin cậy PCA để ước tính chất lượng của các luật.

Độ tin cậy được định nghĩa là tỷ lệ số lượng sự kiện thỏa mãn luật ρ và số lần thân luật body(ρ) được thỏa mãn trong KGs, được định nghĩa là
conf(ρ) :=supp(ρ)
#(e, e′) :body(ρ)∈ G. (12)

Ví dụ. Đối với KG cho trong Bảng 8, độ tin cậy của luật là 1/3, vì có một sự kiện tích cực thỏa mãn luật, và có hai sự kiện (tức là, (Alex, isAffiliatedTo, Club 2) và (Bob, isAffiliatedTo, Club 3)) được coi là ví dụ tiêu cực.

Độ tin cậy giả định rằng tất cả các sự kiện được suy ra từ thân luật nên được chứa trong KGs. Tuy nhiên, KGs thường không hoàn chỉnh trong thực tế, có thể dẫn đến thiếu các sự kiện bằng chứng. Do đó, chúng tôi giới thiệu độ tin cậy PCA (giả định hoàn thiện một phần) để chọn các luật có thể tổng quát hóa tốt hơn cho các sự kiện chưa thấy. Độ tin cậy PCA chỉ xem xét các ví dụ tiêu cực cứng, mâu thuẫn với các sự kiện trong KGs hiện có, và độ tin cậy PCA bỏ qua các ví dụ tiêu cực mềm, mà chúng ta không có kiến thức gì về tính đúng đắn của chúng.

Độ tin cậy PCA dựa trên lý thuyết giả định hoàn thiện một phần (PCA) [Galárraga et al., 2013] được định nghĩa là tỷ lệ số lượng sự kiện thỏa mãn luật ρ và số lần thân luật body(ρ) được thỏa mãn trong việc hoàn thiện một phần của KGs, được định nghĩa là
partial(ρ)(e, e′) := (e, r1, e2)∧,···,∧(eL−1, rL, ê) :
body(ρ)∧(e, rh, ê), (13)
pca(ρ) :=supp(ρ)
#(e, e′) :partial(ρ)(e, e′)∈ G. (14)

Ví dụ. Đối với KG cho trong Bảng 8, độ tin cậy PCA của luật là 1/2, vì (Alex, isAffiliatedTo, Club 2) là một ví dụ tiêu cực cứng vi phạm sự kiện rằng (Alex, playsFor, Club 1), và (Bob, isAffiliatedTo, Club 3) là một ví dụ tiêu cực mềm, được loại bỏ khỏi mẫu số vì chúng ta không biết liệu "Bob" có chơi cho "Club 3" hay không, dựa trên các sự kiện trong KG hiện có.

Bảng 8: Một ví dụ KG chứa hai quan hệ và năm sự kiện
isAffiliatedTo playsFor
(Alex, Club 1) (Alex, Club 1)
(Alex, Club 2) (Charlie, Club 2)
(Bob, Club 3)

## B Tập dữ liệu
Trong thí nghiệm, chúng tôi chọn bốn tập dữ liệu được sử dụng rộng rãi theo các nghiên cứu trước đây [Cheng et al., 2022b]: Family [Hinton và những người khác, 1986], UMLS [Kok và Domingos, 2007], WN18RR [Dettmers et al., 2018], và YAGO3-10 [Suchanek et al., 2007].

• Family [Hinton và những người khác, 1986] là một đồ thị tri thức định nghĩa các mối quan hệ của các thành viên trong một gia đình, ví dụ, "Father", "Mother", và "Aunt".

• UMLS [Kok và Domingos, 2007] là một tri thức y sinh, trong đó các thực thể là các khái niệm y sinh, và các quan hệ bao gồm điều trị và chẩn đoán.

• WN18RR [Dettmers et al., 2018] là một đồ thị tri thức từ vựng tiếng Anh được thiết kế để tổ chức các từ theo các mối quan hệ ngữ nghĩa của chúng. Các từ được kết nối bởi một loạt các mối quan hệ, bao gồm "hypernym", "derivation", v.v.

• YAGO3-10 [Suchanek et al., 2007] là một đồ thị tri thức quy mô lớn khác được xây dựng từ nhiều nguồn dữ liệu, như Wikipedia, WordNet, và GeoNames, chứa nhiều quan hệ, ví dụ, "was born in", "lives in", và "politician of".

## C Baseline
Chúng tôi so sánh phương pháp của mình với các baseline khai thác luật SOTA: AIME [Galárraga et al., 2013], NeuralLP [Yang et al., 2017], RNNLogic [Qu et al., 2020], NLIL [Yang và Song, 2020], NCRL [Cheng et al., 2022a], và Ruleformer [Xu et al., 2022] trong các thí nghiệm.

• AIME6 [Galárraga et al., 2013] là một phương pháp khai thác luật logic thông thường, khám phá các luật từ KG với lập trình logic quy nạp.

6https://github.com/dig-team/amie

Triển khai Mô hình LLM
Mistral-7B-Instruct mistralai/Mistral-7B-Instruct-v0.1
LlaMA2-chat-7B meta-llama/Llama-2-7b-chat
LlaMA2-chat-13B meta-llama/Llama-2-13b-chat
LlaMA2 70B meta-llama/Llama-2-70b-chat
ChatGPT gpt-3.5-turbo-0613
GPT-4 gpt-4-0613

Bảng 9: Chi tiết của các LLM được sử dụng.

• NeuralLP7 [Yang et al., 2017] đề xuất một lập trình logic neural, học các luật logic theo cách có thể vi phân end-to-end.

• RNNLogic8 [Qu et al., 2020] đề xuất một bộ sinh luật và một bộ dự đoán lý luận với các luật logic. Nó phát triển một thuật toán dựa trên EM để tối ưu hóa và học các luật chất lượng cao để lý luận.

• NLIL9 [Yang và Song, 2020] đề xuất một mô hình học quy nạp logic neural là một khung lập trình logic quy nạp có thể vi phân hiệu quả học các luật logic bậc nhất.

• NCRL10 [Cheng et al., 2022a] suy ra các luật bằng cách kết hợp đệ quy các thành phần trong thân luật, phát hiện cấu trúc thành phần tốt nhất của thân luật để biểu đạt đầu luật.

• Ruleformer11 [Xu et al., 2022] là một mô hình dựa trên transformer mã hóa thông tin ngữ cảnh từ KGs để tạo ra các luật.

## D Mô hình Ngôn ngữ Lớn
Các LLM được sử dụng trong thí nghiệm được hiển thị trong Bảng 9. Đối với các LLM mã nguồn mở, chúng tôi sử dụng các checkpoint có sẵn từ HuggingFace12. Đối với ChatGPT và GPT-4, chúng tôi đã sử dụng API được cung cấp bởi OpenAI13.

## E Cài đặt Thí nghiệm
Đối với ChatRule, chúng tôi sử dụng ChatGPT14 làm LLMs để tạo luật. Chúng tôi chọn độ tin cậy PCA làm biện pháp xếp hạng luật cuối cùng và đặt độ dài luật tối đa L là 3. Trong nhiệm vụ hoàn thiện đồ thị tri thức, chúng tôi tuân theo các cài đặt tương tự như các nghiên cứu trước đây [Cheng et al., 2022b; Cheng et al., 2022a]. Đối với baseline, chúng tôi sử dụng các mã được công bố để so sánh.

7https://github.com/fanyangxyz/Neural-LP
8https://github.com/DeepGraphLearning/RNNLogic/tree/main
9https://github.com/gblackout/NLIL
10https://github.com/vivian1993/NCRL/commits/main
11https://github.com/zjukg/ruleformer
12https://huggingface.co/
13https://api.openai.com/v1/chat/completions
14Chúng tôi sử dụng snapshot của ChatGPT được chụp từ ngày 13 tháng 6 năm 2023 (gpt-3.5-turbo-0613) để đảm bảo tính tái tạo.

## F Lời nhắc Tạo Luật
Mẫu lời nhắc được sử dụng để tạo luật được hiển thị như sau.

Lời nhắc Tạo Luật
Luật logic định nghĩa mối quan hệ giữa hai thực thể: X và Y. Mỗi luật được viết dưới dạng hàm ý logic, phát biểu rằng nếu các điều kiện ở phía bên phải (thân luật) được thỏa mãn, thì phát biểu ở phía bên trái (đầu luật) là đúng.

Bây giờ chúng ta có các luật sau:
{mẫu luật}

Dựa trên các luật trên, vui lòng tạo ra càng nhiều càng tốt các luật quan trọng nhất cho đầu luật: "{đầu luật}(X,Y)" càng tốt. Vui lòng chỉ chọn các vị từ từ: {quan hệ trong KGs}. Chỉ trả về các luật mà không có bất kỳ giải thích nào.

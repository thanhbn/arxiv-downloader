# 2110.12679.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/knowledge-graph/2110.12679.pdf
# Kích thước tệp: 1164055 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Mẫu LaTeX Springer Nature 2021
Cải thiện Hệ thống Trả lời Câu hỏi Đa bước trên Đồ thị Tri thức Nhúng
bằng cách Giới thiệu Lý luận Chuỗi Quan hệ

Weiqiang Jin1, Biao Zhao1, Hang Yu2*, Xi Tao2, Ruiping
Yin3,4 và Guizhong Liu1

1Trường Kỹ thuật Thông tin và Truyền thông, Đại học Giao thông
Tây An, Tây An, 710049, Shaanxi, Trung Quốc.
2Trường Kỹ thuật Máy tính và Khoa học, Đại học Thượng Hải,
Bảo Sơn, 200444, Thượng Hải, Trung Quốc.
3Khoa Thông tin Trường Máy tính, Đại học Công nghệ Bắc Kinh,
Triều Dương, 100124, Bắc Kinh, Trung Quốc.
4Trung tâm Nghiên cứu Kỹ thuật Nhận thức Thông minh và Điều khiển
Tự động, Bộ Giáo dục, 100124, Bắc Kinh, Trung Quốc.

*Tác giả liên hệ. E-mail: yuhang@shu.edu.cn;
Các tác giả đóng góp: weiqiangjin@stu.xjtu.edu.cn;
biaozhao@xjtu.edu.cn; 20721546@shu.edu.cn;
yinruiping@bjut.edu.cn; liugz@xjtu.edu.cn;

Tóm tắt
Hệ thống Trả lời Câu hỏi Đồ thị Tri thức (KGQA) nhằm trả lời các câu hỏi
của người dùng từ một đồ thị tri thức (KG) bằng cách xác định các mối quan hệ
lý luận giữa thực thể chủ đề và câu trả lời. Là một nhánh nhiệm vụ phức tạp
của KGQA, KGQA đa bước yêu cầu lý luận qua chuỗi quan hệ đa bước được
bảo tồn trong KG để đạt được câu trả lời đúng. Mặc dù có những thành công
gần đây, các nghiên cứu hiện tại về trả lời câu hỏi phức tạp đa bước vẫn gặp
phải những thách thức sau: i) Sự vắng mặt của thứ tự chuỗi quan hệ rõ ràng
được phản ánh trong câu hỏi của người dùng xuất phát từ việc hiểu sai ý định
của người dùng. ii) Việc nắm bắt không chính xác các loại quan hệ dưới sự
giám sát yếu của tập dữ liệu thiếu các chú thích chuỗi lý luận trung gian do
chi phí gán nhãn đắt đỏ. iii) Không xem xét các mối quan hệ ngầm định giữa
thực thể chủ đề và

--- TRANG 2 ---
Mẫu LaTeX Springer Nature 2021
2 Lý luận Chuỗi Quan hệ Cải thiện KGQA Nhúng

câu trả lời được ẩn trong KG có cấu trúc do hạn chế kích thước vùng lân cận
trong các thuật toán dựa trên truy xuất đồ thị con. Để giải quyết những vấn đề
này trong KGQA đa bước, chúng tôi đề xuất một mô hình mới trong nghiên cứu
này, cụ thể là KGQA Nhúng dựa trên Chuỗi Quan hệ (Rce-KGQA), đồng thời
sử dụng chuỗi quan hệ rõ ràng được tiết lộ trong câu hỏi ngôn ngữ tự nhiên
và chuỗi quan hệ ngầm định được lưu trữ trong KG có cấu trúc. Nghiên cứu
thực nghiệm rộng rãi của chúng tôi trên ba bộ chuẩn miền mở chứng minh rằng
phương pháp của chúng tôi vượt trội đáng kể so với các đối thủ tiên tiến như
GraftNet, PullNet và EmbedKGQA. Các thí nghiệm loại bỏ toàn diện cũng xác
minh tính hiệu quả của phương pháp chúng tôi đối với nhiệm vụ KGQA đa bước.
Chúng tôi đã công khai mã nguồn của mô hình tại github:
https://github.com/albert-jin/Rce-KGQA.

Từ khóa: Khai thác Dữ liệu và Tìm kiếm, Trả lời Câu hỏi, Trả lời Câu hỏi Đa bước
dựa trên Đồ thị Tri thức, Phân tích Ngữ nghĩa Thần kinh, Nhúng Đồ thị Tri thức

1 Giới thiệu
Hệ thống Trả lời Câu hỏi Cơ sở Tri thức (KBQA) [1] là một phương pháp dịch vụ
khai thác và phân tích hấp dẫn đã thu hút sự chú ý rộng rãi từ các giới học thuật
và công nghiệp trong những năm gần đây. Với một câu hỏi bằng ngôn ngữ tự nhiên,
hệ thống KBQA nhằm trả lời các thực thể mục tiêu chính xác từ một cơ sở tri thức
(KB) được cho [2]. Nó dựa vào khả năng nhất định bao gồm nắm bắt thông tin ngữ
nghĩa phong phú để hiểu rõ các câu hỏi ngôn ngữ tự nhiên và tìm kiếm câu trả lời
chính xác trong cơ sở dữ liệu tri thức có cấu trúc quy mô lớn một cách chính xác.
Hệ thống Trả lời Câu hỏi Đồ thị Tri thức (KGQA) [3, 4] là một nhánh nghiên cứu
phổ biến của KBQA sử dụng đồ thị tri thức (KG) làm nguồn tri thức [2, 5] và sử
dụng các bộ ba thông tin được lưu trữ trong KG để trả lời câu hỏi ngôn ngữ tự nhiên.
Nhờ cấu trúc dữ liệu độc đáo của KG và khả năng truy vấn hiệu quả, người dùng có
thể hưởng lợi từ việc thu thập tri thức KG đáng kể và có giá trị một cách hiệu quả
hơn, và có được trải nghiệm khách hàng xuất sắc.

Các nghiên cứu ban đầu [6, 7] về KGQA tập trung vào việc trả lời câu hỏi đơn giản,
nơi chỉ có một mối quan hệ duy nhất giữa thực thể chủ đề và câu trả lời được liên quan.
Ví dụ, trong câu hỏi "Những bộ phim nào mà [Martin Lawrence] đã đóng?", như được
mô tả trong Hình 1, chỉ tồn tại một mối quan hệ duy nhất 'starred actors' giữa thực
thể chủ đề 'Martin Lawrence' và câu trả lời. Câu trả lời cuối cùng chỉ dựa vào một
sự kiện KG duy nhất (Martin Lawrence, starred actors reverse, Black Knight). Để
giải quyết các nhiệm vụ câu hỏi đơn giản, hầu hết các phương pháp truyền thống [8, 9]
tạo ra các mẫu thủ công được xác định trước đa dạng và sau đó sử dụng các mẫu này
để ánh xạ các câu hỏi không có cấu trúc thành các dạng logic có cấu trúc. Thật không
may, các mẫu được xác định trước và quy tắc cú pháp thủ công này đều tốn nhiều
lao động và đắt đỏ. Hơn nữa, các phương pháp như vậy yêu cầu người lao động đám
đông phải quen thuộc với kiến thức chuyên môn ngôn ngữ học và miền cụ thể. Do sự
phụ thuộc vào quy tắc cố định quy mô lớn và mẫu thủ công, các phương pháp này
không thể xử lý các câu hỏi phức tạp đòi hỏi suy luận nhiều mối quan hệ.

--- TRANG 3 ---
Mẫu LaTeX Springer Nature 2021
Lý luận Chuỗi Quan hệ Cải thiện KGQA Nhúng 3

Để làm cho KGQA có thể áp dụng hơn trong các tình huống ứng dụng thực tế,
các nhà nghiên cứu đã chuyển sự chú ý từ câu hỏi đơn giản sang câu hỏi phức tạp.
Hệ thống trả lời câu hỏi đa bước đồ thị tri thức là một nhiệm vụ thách thức nhằm
tìm kiếm câu trả lời cách thực thể chủ đề nhiều bước trong đồ thị tri thức. Ví dụ,
câu hỏi "Ai đã đạo diễn những bộ phim mà [Martin Lawrence] đã đóng?" là một câu
hỏi đa bước phức tạp đòi hỏi một chuỗi quan hệ (starred actors, directed by) có
nhiều mối quan hệ để đạt được các câu trả lời tương ứng. Nhiệm vụ này là một nhiệm
vụ tương đối phức tạp so với các đối tác đơn giản do quy trình truy xuất quan hệ
đa bước [5] đòi hỏi nhiều hơn một sự kiện KG trong suy luận.

Các phương pháp trước đây [10-13] để xử lý trả lời câu hỏi phức tạp đã xây dựng
một pipeline chuyên biệt gồm nhiều mô-đun phân tích ngữ nghĩa và truy xuất câu
trả lời đồ thị tri thức để hoàn thành nhiệm vụ KGQA. Tuy nhiên, hầu hết đều có
một số nhược điểm và gặp phải nhiều thách thức khác nhau. Chúng tôi tóm tắt những
thách thức này như sau:

Chuỗi Lý luận Mong đợi
Chuỗi Lý luận Không mong đợi
Chuỗi Lý luận Không liên quan

[Hình 1 cho thấy đồ thị con Freebase tập trung vào thực thể chủ đề [Martin Lawrence]
của các câu hỏi ví dụ. Các vòng tròn màu đỏ, vàng, xanh lá, xanh lá với đường tưởng
tượng, và xám biểu thị các nút thực thể chủ đề, trung gian, mong đợi, không mong đợi
và không liên quan, tương ứng. Các cạnh màu xanh lá, đỏ và xám chỉ ra các chuỗi
lý luận đúng, sai và không liên quan, tương ứng.]

Nhận diện Loại Quan hệ Không mong đợi. Là bước đầu tiên của KGQA, một bộ
phân tích ngữ nghĩa của hầu hết các phương pháp hiện có thực hiện với độ chính xác
kém trong việc nhận dạng loại quan hệ chính xác được ẩn trong câu hỏi, điều này
cản trở việc lý luận trả lời câu hỏi downstream. Ví dụ, như được hiển thị trong Hình 1,
hãy xem xét các câu hỏi trong đó thực thể chủ đề và câu trả lời được kết nối bởi một
chuỗi lý luận đa bước, ví dụ: "Ai đã đóng trong những bộ phim được đạo diễn bởi
đạo diễn [Martin Lawrence]?". Để trả lời loại câu hỏi này, hai sự kiện liên quan
(Martin Lawrence, directed by reverse) và (A Tine Line,

--- TRANG 4 ---
Mẫu LaTeX Springer Nature 2021
4 Lý luận Chuỗi Quan hệ Cải thiện KGQA Nhúng

starred actors reverse, Gone Fishin) giúp suy ra câu trả lời trong vùng lân cận của
thực thể chủ đề [Martin Lawrence]. Thông thường, các phương pháp này dễ gặp phải
lý luận quan hệ không chính xác (AB→AC) khi chúng ta nhầm lẫn chuỗi quan hệ không
mong đợi (starred actors reverse, written by) với chuỗi quan hệ mong đợi (starred
actors reverse, directed by reverse). Do đó, cần thiết phải tối ưu hóa phân tích
ngữ nghĩa quan hệ để nhận dạng ý định người dùng chính xác hơn.

Nhận diện Thứ tự Quan hệ Không mong đợi. Các phương pháp dựa trên phân tích
ngữ nghĩa [14-17] chủ yếu không tận dụng hiệu quả thông tin tương quan của thứ
tự và hướng quan hệ từ biểu đạt câu hỏi của người dùng. Chúng trở nên dễ bị hiểu
sai hơn khi các câu hỏi phức tạp về cả khía cạnh ngữ nghĩa và cú pháp. Tỷ lệ chính
xác của phân tích cú pháp có thể giảm đáng kể bởi những câu có sự phụ thuộc khoảng
cách xa. Đặc biệt hơn, truy ngược lại ví dụ câu hỏi trên và Hình 1, ngoài chuỗi
chính xác (với mũi tên xanh), chuỗi đa bước giả mạo (với mũi tên đỏ) từ nút thực
thể [Martin Lawrence] đến [Kim Bass] có thể dẫn đến kết quả lý luận không chính
xác khi mô-đun phân tích ngữ nghĩa không phân tích được ngữ nghĩa như vậy, ví dụ
đảo ngược (AB→BA) hoặc xáo trộn (ABC→BCA), thứ tự chính xác của chuỗi quan hệ.
Nói tóm lại, chúng ta cần nắm bắt chính xác các ánh xạ quan hệ có thứ tự dài hơn
được ẩn trong biểu đạt ngôn ngữ của người dùng để đạt được câu trả lời chính xác.

[Hình 2 mô tả một đồ thị tri thức có cấu trúc liên quan đến câu hỏi của người dùng,
"[Renate Remedio] là anh em họ của ai?". Hình minh họa thường giới thiệu các mối
quan hệ ngầm định giữa thực thể chủ đề và câu trả lời ẩn trong KG.]

Lý luận Quan hệ Ngầm định & Ràng buộc Vùng lân cận Đồ thị con. Hầu hết các
phương pháp KGQA chính thống [18, 19] không thể gián tiếp nắm bắt kiến thức về
các chuỗi quan hệ ngầm định để lý luận do ràng buộc hạn chế của kích thước vùng
lân cận. Tất cả các câu trả lời được cung cấp bằng cách

--- TRANG 5 ---
Mẫu LaTeX Springer Nature 2021
Lý luận Chuỗi Quan hệ Cải thiện KGQA Nhúng 5

truy xuất đồ thị con câu hỏi được trích xuất. Hãy xem xét câu hỏi "Ai là anh em họ
của [Renate Remedio]?". Như được mô tả trong Hình 2, đồ thị tri thức tương ứng
không có chuỗi quan hệ trực tiếp giữa thực thể chủ đề [Renate Remedio] và câu trả
lời [Amaranta Orsule]. Nói cách khác, đối với các giải pháp KGQA liên tiếp trong
tương lai, điều quan trọng là có thể khám phá tri thức thông tin ngầm định (Remedio
 Cousin→Orsule) trong KG không đầy đủ bằng chuỗi quan hệ rõ ràng (Remedio 
Father - Siblings - Mother →Orsule), tương tự như nhiệm vụ dự đoán liên kết dựa
trên KG [20]. Hơn nữa, hầu hết các phương pháp hiện tại gặp khó khăn dưới ràng
buộc không mong muốn của việc phát hiện câu trả lời từ một vùng lân cận đồ thị con
KG cục bộ được chỉ định trước. Ví dụ, phương pháp tiên tiến (SOTA) GraftNet [21]
có câu trả lời bị hạn chế là tập con của các thực thể có mặt trong vùng lân cận đồ
thị con KG cục bộ, chỉ báo cáo recall khoảng 0.55 trên KG không đầy đủ nơi chỉ
có một nửa số bộ ba ban đầu được trình bày.

Để giảm thiểu những hạn chế và thách thức này đối với nhiệm vụ KGQA đa bước,
bài báo của chúng tôi giới thiệu một kiến trúc mới, cụ thể là KGQA Nhúng dựa trên
Chuỗi Quan hệ, hỗ trợ tích hợp để học các ánh xạ quan hệ rõ ràng được ẩn trong
biểu đạt của người dùng và tri thức ngầm định từ KG có cấu trúc, tương tự như dự
đoán liên kết. Phương pháp được đề xuất của chúng tôi chống lại những hạn chế này
bằng cách đồng thời sử dụng chuỗi quan hệ ngữ nghĩa rõ ràng được mô tả trong câu
hỏi và chuỗi quan hệ ngầm định giữa các nút KG có cấu trúc. Chúng tôi sử dụng nhúng
đồ thị tri thức và xây dựng Mô-đun Lọc Câu trả lời để tính toán mối quan hệ tương
hỗ giữa thực thể chủ đề và câu trả lời. Được thúc đẩy bởi nghiên cứu trước đây
EmbedKGQA [22], chúng tôi cho thấy cách mô hình của chúng tôi tận dụng mạng thần
kinh đầu cuối sử dụng các nhúng thực thể và quan hệ KG để cung cấp câu trả lời cho
các câu hỏi phức tạp từ KG. Vì mô hình của chúng tôi thay thế quy trình pipeline
truyền thống tạo và truy xuất đồ thị con cục bộ tại các bước lý luận trung gian, nó
giúp giảm chi phí bộ nhớ hiệu quả và đạt được hiệu quả tính toán. Để có được hiệu
suất cạnh tranh hơn trong KG quy mô lớn, chúng tôi áp dụng một quy trình lý luận
bổ sung được gọi là Mô-đun Lý luận Chuỗi Quan hệ để cắt tỉa các thực thể ứng viên
được xếp hạng bởi Mô-đun Lọc Câu trả lời. Chúng tôi áp dụng kiến trúc Siamese [23]
dựa trên bộ nhớ ngắn hạn dài (LSTM) [24] và transformer RoBERTa [25] để học độ
tương tự ngữ nghĩa giữa chuỗi quan hệ của mô tả vấn đề và chuỗi quan hệ thông tin
KG. Nó cũng tận dụng tín hiệu giám sát bên ngoài của chuỗi quan hệ từ mẫu huấn
luyện. Bằng cách tính toán độ tương tự ngữ nghĩa giữa ngữ nghĩa câu hỏi và chuỗi
truy xuất thực thể ứng viên, chúng ta có thể xác định câu trả lời cuối cùng chính xác
hơn. Chi tiết cấu trúc nội bộ của mô hình được giới thiệu trong Mục 4.

Chúng tôi tóm tắt những đóng góp của bài báo này như sau:

1. Chúng tôi đề xuất một phương pháp mới cụ thể là KGQA Nhúng dựa trên Chuỗi
Quan hệ bao gồm hai mô-đun chính: Mô-đun Lọc Câu trả lời và Mô-đun Lý luận
Chuỗi Quan hệ. Khác với các nghiên cứu trước đây, mô hình của chúng tôi đồng thời
tận dụng nhúng đồ thị tri thức

--- TRANG 6 ---
Mẫu LaTeX Springer Nature 2021
6 Lý luận Chuỗi Quan hệ Cải thiện KGQA Nhúng

và huấn luyện với giám sát yếu bằng cách dự đoán chuỗi quan hệ trung gian được
ẩn trong KG để thực hiện nhiệm vụ KGQA đa bước.

2. Chúng tôi giới thiệu Mô-đun Lọc Câu trả lời, một mạng đầu cuối dựa trên nhúng
đồ thị tri thức để lọc câu trả lời sơ bộ. Mô-đun này có thể giải quyết vấn đề không
đầy đủ là một yếu tố trong các liên kết bị thiếu trong đồ thị tri thức không hoàn
chỉnh nhờ khả năng nắm bắt các mối quan hệ KG ngầm định. Hơn nữa, chúng tôi xem
xét tất cả các thực thể là câu trả lời ứng viên trong bước này, vì vậy mô hình của
chúng tôi sẽ không gặp phải các vấn đề ngoài tầm với do ràng buộc vùng lân cận đồ
thị con hạn chế.

3. Mô-đun Lý luận Chuỗi Quan hệ được đề xuất của chúng tôi có thể giúp nắm bắt
các quan hệ đa bước xung quanh nút chủ đề để hỗ trợ kết quả chính xác hơn. Chúng
tôi áp dụng mạng Siamese [23] để tính toán điểm số độ tương tự ngữ nghĩa dựa trên
biểu diễn vector giữa câu hỏi của người dùng và tri thức có cấu trúc KG. Theo hiểu
biết của chúng tôi, mô-đun con được đề xuất của chúng tôi là đầu tiên xem xét thông
tin hướng và thứ tự quan hệ câu hỏi bằng cách sử dụng mạng Siamese.

4. Kết quả thí nghiệm của chúng tôi trên ba bộ chuẩn KGQA được áp dụng rộng rãi
chứng minh khả năng cạnh tranh của phương pháp chúng tôi so với hầu hết các phương
pháp SOTA (cải thiện tuyệt đối trung bình 1.2% trên các thước đo đánh giá hit@1).
Hơn nữa, sử dụng nghiên cứu loại bỏ rộng rãi, chúng tôi chứng minh tính ưu việt
và hiệu quả của mô hình được đề xuất cho nhiệm vụ KGQA đa bước.

Phần còn lại của bài báo được tổ chức như sau: Đầu tiên chúng tôi cung cấp một
đánh giá kỹ lưỡng về các nghiên cứu KGQA liên quan trong Mục 2. Tiếp theo, chúng
tôi giới thiệu kiến thức sơ bộ về nhiệm vụ KGQA trong Mục 3. Theo cấu trúc nội
bộ của mô hình, sau đó chúng tôi giải thích hai tính năng của chúng tôi: Mô-đun
Lọc Câu trả lời trong Mục 4.2 và Mô-đun Lý luận Chuỗi Quan hệ trong Mục 4.3.
Mục 5 mô tả chi tiết thí nghiệm trên ba tập dữ liệu miền mở. Cuối cùng, trong
Mục 6, chúng tôi kết luận các đóng góp cho nghiên cứu này và đề xuất một số đổi
mới đầy hứa hẹn cho KGQA Nhúng dựa trên Chuỗi Quan hệ trong tương lai.

2 Nghiên cứu Liên quan

Nghiên cứu của chúng tôi có liên quan chặt chẽ đến Trả lời Câu hỏi Đồ thị Tri thức
Đa bước, Nhúng Đồ thị Tri thức, Mạng Siamese, và Mô hình Ngôn ngữ Đã được
Huấn luyện trước.

2.1 KGQA Đa bước

Trả lời Câu hỏi Cơ sở Tri thức Đa bước bao gồm hai nhánh chính: dựa trên Truy
xuất Thông tin (IR) và dựa trên Phân tích Ngữ nghĩa (SP-based). Các phương pháp
phổ biến nhất thuộc về hai loại này.

--- TRANG 7 ---
Mẫu LaTeX Springer Nature 2021
Lý luận Chuỗi Quan hệ Cải thiện KGQA Nhúng 7

2.1.1 Phương pháp Phân tích Ngữ nghĩa

Các phương pháp dựa trên SP tuân theo quy trình phân tích-sau-thực thi. Các phương
pháp này [22, 26-29] có thể được tóm tắt thành các bước sau: (1) hiểu ngữ nghĩa
câu hỏi: phân tích quan hệ và chủ thể liên quan trong câu hỏi phức tạp, (2) xây dựng
công thức logic: giải mã đồ thị con thành một dạng logic có thể thực thi như ngôn
ngữ lập trình cấp cao hoặc truy vấn có cấu trúc như SPARQL, (3) định vị và truy
vấn dựa trên KG: tìm kiếm từ KG sử dụng ngôn ngữ truy vấn và cung cấp kết quả
truy vấn làm câu trả lời cuối cùng. Nhờ quy trình trung gian tạo ra các dạng logic
biểu cảm, các phương pháp dựa trên SP có thể diễn giải được hơn so với các đối tác
phương pháp dựa trên IR. Tuy nhiên, đối với hầu hết các phương pháp dựa trên SP
hiện có, nhiều quan hệ hơn trong câu hỏi phức tạp cho thấy không gian tìm kiếm
lớn hơn của các dạng logic tiềm năng để phân tích, điều này sẽ tăng đáng kể chi
phí tính toán.

Yu et al. [30] chỉ ra rằng phát hiện quan hệ KG là một thành phần cốt lõi và liên
kết thực thể là một bước quan trọng trong các nhiệm vụ KGQA. Để cải thiện độ chính
xác nhận dạng của cả hai nhiệm vụ con, họ đề xuất BiLSTM Dư Phân cấp (HR-BiLSTM)
để mã hóa mô tả câu hỏi và đường dẫn quan hệ cấp từ và cấp cụm từ. Mô-đun HR-BiLSTM
mới tính toán điểm số độ tương tự cho tất cả câu hỏi và quan hệ văn bản, tích hợp
cho hai thành phần liên kết thực thể và xác định đường dẫn quan hệ thành một bước
duy nhất và tăng cường lẫn nhau. Khi suy luận, mô hình chỉ chọn các cặp (quan hệ,
thực thể chủ đề) được đánh điểm cao làm câu trả lời chính xác từ các ứng viên.

Miller et al. [31] đề xuất một khung KGQA miền cụ thể lý tưởng, được gọi là Key
Value-Memory networks (KV-MemNN), đã được chứng minh là hiệu quả để hỗ trợ lý
luận câu trả lời qua tri thức đa nguồn miền cụ thể như tài liệu văn bản và KG có
cấu trúc. Nó thực hiện QA bằng cách sử dụng cơ chế bộ nhớ dài hạn được sử dụng
rộng rãi để lý luận trên mạng bộ nhớ có cấu trúc khóa-giá trị. Họ định nghĩa ba
hoạt động, tức là key hashing, mô hình đầu tiên lấy tất cả các bộ ba KG liên quan
đến các câu hỏi đã cho và sau đó lưu trữ các thực thể chủ đề và quan hệ của chúng
trong khe khóa, thực thể đuôi trong khe giá trị; key addressing, mô hình gán cho
mỗi đơn vị bộ nhớ với trọng số liên quan được chuẩn hóa bằng phép toán tích vô hướng
làm xác suất liên quan giữa câu hỏi và mỗi biểu diễn khóa trong bộ nhớ; cuối cùng,
value reading, nơi mô hình đọc các giá trị của tất cả bộ nhớ được địa chỉ hóa bằng
cách lấy tổng có trọng số của tất cả giá trị và trọng số liên quan, và sử dụng đầu
ra để biểu diễn kết quả lý luận trung gian, sau đó được sử dụng để cập nhật biểu
diễn câu hỏi. Để có được dự đoán cuối cùng trên tất cả câu trả lời ứng viên, mô
hình lặp lại các bước key addressing và value reading trong thành phần Xếp hạng
nhiều lần.

Tuy nhiên, KV-MemNN rõ ràng đưa ra những thách thức sau: 1) Nó thường không
cập nhật chính xác các truy vấn câu hỏi đa quan hệ trong quá trình đọc bộ nhớ nhiều
lần. 2) Nó đọc bộ nhớ lặp đi lặp lại vì chúng không thể xác định chính xác khi nào
nên dừng. 3) Nó tập trung nhiều hơn vào hiểu các sự kiện bộ nhớ thay vì hiểu câu
hỏi đúng cách, vì vậy nó

--- TRANG 8 ---
Mẫu LaTeX Springer Nature 2021
8 Lý luận Chuỗi Quan hệ Cải thiện KGQA Nhúng

không hoạt động tốt như mong đợi khi được áp dụng vào tình huống mà các câu hỏi
của nó phức tạp và liên quan đến các ràng buộc phức tạp, chẳng hạn như nhiệm vụ
KGQA miền mở. 4) Nó chọn ứng viên có điểm số độ tương tự cao nhất làm câu trả
lời duy nhất theo mặc định. Vì vậy, nó hoạt động không hiệu quả khi các câu hỏi
chứa nhiều hơn một câu trả lời.

Để giải quyết những thách thức này, Xu et al. [32] đề xuất một cơ chế có thể diễn
giải để cho phép mô hình KV-MemNN cơ bản hoạt động cho các câu hỏi phức tạp, mang
lại hiệu suất tiên tiến trên ba bộ chuẩn. KV-MemNN nâng cao đã giới thiệu chiến
lược STOP mới vào việc đọc bộ nhớ đa bước để tạo ra số lượng truy vấn linh hoạt
và giới thiệu phương pháp cập nhật truy vấn mới, xem xét các khóa đã được địa chỉ
hóa trong các bước trước cũng như các biểu diễn giá trị để tránh việc đọc bộ nhớ
lặp lại hoặc không hợp lệ. Đối với các câu hỏi đa ràng buộc, mô hình xem xét biểu
diễn giá trị của mỗi bước bằng cách tích lũy tất cả các biểu diễn giá trị của cả
bước hiện tại và các bước trước để giải quyết mỗi ràng buộc liên quan tại các bước
khác nhau.

Ngoài các phương pháp đại diện ở trên, nhiều phương pháp trả lời câu hỏi cơ sở
tri thức dựa trên Mạng Thần kinh Đồ thị (GNN) [33] và Mạng Tích chập Đồ thị (GCN)
[34] đã được đề xuất trong những năm gần đây, các phương pháp như Hệ thống Trả
lời Câu hỏi Đa Quan hệ dựa trên Mạng Tích chập Đồ thị (QAGCN) [35] và Mô hình
SUBGraph Lý luận dựa trên Trường hợp (CBR-SUBG) [36]. Như tên gọi, QAGCN là
một mô hình đơn giản nhưng hiệu quả tận dụng các mạng tích chập đồ thị chú ý có
thể thực hiện lý luận đa bước trong quá trình mã hóa đồ thị tri thức. Có thể tận
dụng các tính toán nhúng hiệu quả cao, lợi thế đáng kể của mô hình là nó có thể
đơn giản hóa cơ bản các cơ chế lý luận phức tạp. CBR-SUBG là một mô hình bán tham
số cho KGQA giám sát yếu truy xuất các truy vấn tương tự và sử dụng sự tương tự
trong cấu trúc đồ thị của các đồ thị con cục bộ để trả lời một truy vấn. Nó chứa
một thành phần tham số bao gồm một mạng thần kinh đồ thị (GNN). Thông qua thí
nghiệm, nó hoạt động cạnh tranh với các mô hình KGQA tiên tiến trên nhiều bộ chuẩn.
Do khả năng xác định mẫu lý luận, phương pháp CBR-SUBG cũng có thể cung cấp
các đường dẫn có thể diễn giải cho các câu trả lời được trả về, có thể mang lại khả
năng diễn giải tốt hơn một chút.

2.1.2 Phương pháp Truy xuất Thông tin

Các phương pháp dựa trên IR thường bao gồm một loạt các quy trình như sau: trích
xuất đồ thị cụ thể câu hỏi, biểu diễn ngữ nghĩa câu hỏi, lý luận dựa trên đồ thị
được trích xuất và xếp hạng ứng viên câu trả lời. Với mô tả câu hỏi phức tạp, các
phương pháp này [37, 38] đầu tiên xây dựng một đồ thị con cụ thể câu hỏi bao gồm
tất cả các nút thực thể liên quan câu hỏi và các cạnh quan hệ từ KG mà không tạo
ra công thức logic có thể thực thi, Tiếp theo là sử dụng một mô-đun biểu diễn câu
hỏi để mã hóa các token câu hỏi của người dùng thành các vector chiều thấp. Thứ
hai, một mô-đun lý luận dựa trên đồ thị được trích xuất tiến hành thuật toán khớp
ngữ nghĩa để tổng hợp thông tin vùng lân cận của thực thể trung tâm từ đồ thị con
cụ thể câu hỏi. Ở

--- TRANG 9 ---
Mẫu LaTeX Springer Nature 2021
Lý luận Chuỗi Quan hệ Cải thiện KGQA Nhúng 9

cuối quá trình lý luận, họ xếp hạng tất cả điểm số của các thực thể trong đồ thị
con bằng cách áp dụng một mô-đun xếp hạng câu trả lời để dự đoán các thực thể
được xếp hạng cao nhất làm câu trả lời cuối cùng. Dựa trên công nghệ biểu diễn
đặc trưng, các phương pháp dựa trên IR có thể được chia thành các phương pháp dựa
trên kỹ thuật đặc trưng và các phương pháp dựa trên học biểu diễn.

Các phương pháp kỹ thuật đặc trưng dựa trên IR [39] dựa vào các đặc trưng được
định nghĩa và trích xuất thủ công, tốn thời gian và không thể phát hiện toàn bộ
ngữ nghĩa câu hỏi. Để giải quyết những vấn đề này, các phương pháp IR dựa trên
học biểu diễn chuyển đổi câu hỏi và các thực thể liên quan thành các biểu diễn
vector phân tán trong cùng không gian chiều và coi các nhiệm vụ KGQA như khớp
ngữ nghĩa giữa các biểu diễn phân tán của câu hỏi và câu trả lời ứng viên [2].

Sun et al. [21] đề xuất một khung tích hợp cụ thể là GRAFT-Net, được áp dụng
chiến lược hợp nhất tri thức, nơi các câu trả lời được chọn từ một đồ thị con cụ
thể câu hỏi không đồng nhất được xây dựng từ KG và tài liệu văn bản dựa trên các
câu hỏi đã cho. Đồ thị con chứa ba yếu tố: các nút thực thể, các nút câu và một
loại cạnh đặc biệt chỉ ra các mối quan hệ tương hỗ giữa các nút thực thể và câu.
Trong quá trình phát hiện câu trả lời, mạng thần kinh tích chập GRAFT-Net lan
truyền đặc trưng nút thực thể trung tâm đến các nút lân cận trong nhiều vòng lặp
và xác định xem một nút thực thể có phải là câu trả lời hay không.

Tuy nhiên, đồ thị con được xây dựng tự động trong GRAFT-Net dựa rất nhiều vào
quy tắc thực nghiệm và có thể dẫn đến lỗi cascade nghiêm trọng và mang lại lý luận
không chính xác. Do đó, ngay sau khi đề xuất GRAFT-Net [21], Sun et al. [10] đã
trình bày một quy trình lặp đã học cho việc xây dựng đồ thị lấy thực thể chủ đề
làm trung tâm. Phương pháp cải tiến, được gọi là Pull-Net, nơi bộ phân loại "pull"
được giám sát yếu để chỉ các cặp QA được sử dụng để giám sát. Nó đầu tiên chọn
các nút thực thể hạt giống bằng GRAFT-Net và một mô hình phân loại mới ở mỗi bước.
Sau đó, ngày càng nhiều thực thể và câu có giá trị bổ sung được đưa vào đồ thị hiện
tại thông qua một số vòng lặp hoạt động được xác định trước, với câu trả lời cuối
cùng được xác định bởi cùng quy trình như GRAFT-Net [21]. Thực nghiệm, PullNet
cải thiện đáng kể so với các phương pháp tiên tiến trước đây [21, 38, 39] ngay cả
dưới tín hiệu giám sát yếu và KG không đầy đủ.

Một thách thức đáng kể trong Trả lời Câu hỏi Cơ sở Tri thức đa bước là thiếu
tín hiệu giám sát ở các bước trung gian. Để giải quyết thách thức này, He et al.
[27] đề xuất một khung giáo viên-học sinh tinh tế bằng cách điều chỉnh Máy Trạng
thái Thần kinh (NSM) chung [40] làm mạng học sinh, trong khi mạng giáo viên nhằm
học các tín hiệu giám sát trung gian để cải thiện mạng học sinh. Kết quả đánh giá
rộng rãi với ba tập dữ liệu chuẩn cho thấy mô hình được đề xuất của họ vượt trội
hơn các phương pháp trước về mặt hiệu quả cho nhiệm vụ KGQA đa bước. Hơn nữa,
các thí nghiệm chi tiết khác chứng minh rằng phương pháp của họ linh hoạt hơn để
mở rộng bản thân sang các kiến trúc thần kinh hoặc chiến lược học tập khác trên
đồ thị.

Ngoài các phương pháp tạo đồ thị con truyền thống này, các nhà nghiên cứu cũng
cố gắng kết hợp cơ chế nhúng KG như thông tin bổ sung vào

--- TRANG 10 ---
Mẫu LaTeX Springer Nature 2021
10 Lý luận Chuỗi Quan hệ Cải thiện KGQA Nhúng

các biểu diễn thực thể và quan hệ để giảm thiểu các vấn đề thưa thớt KG không đầy đủ.
Được truyền cảm hứng từ các nhiệm vụ hoàn thành quan hệ và dự đoán liên kết thiếu
trong KG, Saxena et al. [22] đề xuất một khung mới, tên là EmbedKGQA, tận dụng
các nhúng KG được huấn luyện trước để làm phong phú các biểu diễn thực thể và quan
hệ đã học. Các thí nghiệm so sánh rộng rãi trên nhiều bộ chuẩn cho thấy EmbedKGQA
đặc biệt hiệu quả trong việc thực hiện KGQA đa bước trên KG thưa thớt.

2.2 Nhúng Đồ thị Tri thức

Nhúng Đồ thị Tri thức [28] là để nhúng tri thức bộ ba thông tin của KG bao gồm tất
cả các thực thể và quan hệ vào không gian biểu diễn nhúng liên tục và chiều thấp,
sao cho các thực thể và quan hệ ban đầu được bảo tồn tốt trong các vector. Các mô
hình nhúng KG đại diện khai thác hàm tính điểm dựa trên khoảng cách f() được sử
dụng để đo tính hợp lý của một bộ ba (thực thể chủ đề, vị từ, và thực thể đuôi)
như khoảng cách giữa thực thể đầu và thực thể đuôi như TransE [41] và các phần
mở rộng của nó (ví dụ TransH [42]), DistMult [43] và ComplEx [44]. Nói tóm lại,
một kỹ thuật nhúng KG điển hình thường bao gồm ba bước: (1) biểu diễn các thực
thể và quan hệ, (2) định nghĩa một hàm tính điểm, và (3) học các biểu diễn thực
thể và quan hệ. Nhờ khả năng đơn giản hóa thao tác trong khi bảo tồn cấu trúc
vốn có của KG, nó có thể mang lại lợi ích cho nhiều nhiệm vụ downstream để đưa
toàn bộ KG vào xem xét, chẳng hạn như căn chỉnh thực thể [45], dự đoán quan hệ
[20] và thậm chí nghiên cứu KGQA [22]. Tính hiệu quả của nhúng đồ thị tri thức trong
các nhiệm vụ NLP thực tế khác nhau [46, 47] thúc đẩy chúng tôi khám phá các lợi
thế tiềm năng của nó trong nhiệm vụ KGQA.

2.3 Mạng Siamese

Mạng Siamese [23] là một thước đo độ tương tự văn bản ngữ nghĩa được xây dựng
trên mạng biểu diễn đặc trưng như CNN [48] và RNN [23]. Với một cặp đầu vào ví
dụ, mạng Siamese đầu tiên ánh xạ hai đầu vào này thành các chuỗi vector nhúng
từ sử dụng các nhúng được huấn luyện trước quy mô lớn như Glove [49], sau đó
truyền các vector này qua quy trình chuyển tiếp của bộ trích xuất biểu diễn và nhận
được các biểu diễn vector ngữ nghĩa, tương ứng. Cuối cùng, mạng Siamese áp dụng
chuẩn ℓ1 (khoảng cách Manhattan) hoặc ℓ2 (khoảng cách Euclidean) làm hàm đo
khoảng cách để tính toán độ tương tự giữa hai biểu diễn này. Hơn nữa, bộ nhớ ngắn
hạn dài (LSTM) vượt trội hơn RNN ban đầu trong việc học các phụ thuộc tầm xa vì
các đơn vị tế bào bộ nhớ của nó có thể nắm bắt các đặc trưng phong phú qua các
chuỗi token ngôn ngữ dài. Do đó, trong nghiên cứu này, chúng tôi sử dụng sự thích
ứng Siamese của mạng LSTM hai chiều để học chuỗi quan hệ ngữ nghĩa.

--- TRANG 11 ---
Mẫu LaTeX Springer Nature 2021
Lý luận Chuỗi Quan hệ Cải thiện KGQA Nhúng 11

2.4 Mô hình Ngôn ngữ Đã được Huấn luyện trước: RoBERTa

Biểu diễn Bộ mã hóa Hai chiều từ Transformers [50], hay BERT, là một kỹ thuật
huấn luyện trước tự giám sát cách mạng học dự đoán các phần văn bản được ẩn có
chủ ý (được che). Quan trọng, các biểu diễn được học bởi BERT đã được chỉ ra là
khái quát hóa tốt cho các nhiệm vụ downstream và, khi BERT được phát hành lần
đầu vào năm 2018, nó đạt được kết quả tiên tiến trên nhiều tập dữ liệu chuẩn NLP.

RoBERTa [25], như được đề xuất bởi Liu et al., được xây dựng trên chiến lược che
ngôn ngữ của BERT và sửa đổi các siêu tham số quan trọng trong BERT, và nó có
thể được coi là một phiên bản BERT được tối ưu hóa rất nhiều. Nó bao gồm việc
loại bỏ mục tiêu huấn luyện trước câu tiếp theo của BERT, và huấn luyện với các
mini-batch lớn hơn nhiều và tỷ lệ học tập. Nó cũng được huấn luyện trên một thứ
tự độ lớn dữ liệu nhiều hơn BERT, trong thời gian dài hơn. Điều này cho phép các
biểu diễn RoBERTa khái quát hóa thậm chí tốt hơn cho các nhiệm vụ downstream
so với BERT. Mô hình cải tiến RoBERTa đạt được kết quả tiên tiến trên các bộ chuẩn
GLUE, RACE và SQuAD, mà không cần điều chỉnh đa nhiệm vụ cho GLUE hoặc dữ liệu
bổ sung cho SQuAD.

3 Kiến thức Sơ bộ

Trong phần này, chúng tôi chính thức giới thiệu kiến thức sơ bộ [2, 5] về công
thức nhiệm vụ KGQA đa bước và các định nghĩa liên quan của nó. Trước mô tả công
thức, tất cả các ký hiệu được xác định trước được tóm tắt cho nhiệm vụ KGQA được
đưa ra như sau: chúng tôi biểu thị một KG là G(ε, R) trong đó ε, R tương ứng biểu
thị tập thực thể và quan hệ, và chúng tôi sử dụng (h, ℓ, t) để biểu diễn một bộ
ba thông tin trong KG. Chúng tôi sử dụng một chữ cái viết hoa và viết thường để
biểu thị một ma trận (ví dụ W) và một vector (ví dụ v). Chuẩn ℓn của một vector
được biểu thị là ‖p‖n.

Định nghĩa 1 (Câu hỏi đa bước) [2, 5, 22] Nếu một câu hỏi ngôn ngữ tự nhiên
liên quan đến nhiều hơn một vị từ giữa thực thể chủ đề và câu trả lời, thì chúng
ta tin rằng câu trả lời cách thực thể chủ đề nhiều bước trong KG. Do đó, chúng ta
xác định đây là một câu hỏi đa bước. Ví dụ, hãy xem xét câu hỏi đa bước: "Khi nào
công ty sản xuất phim thông báo diễn viên nào cũng đạo diễn bộ phim [Cast a Deadly
Spell]?", bao gồm một số vị từ tương ứng với các liên kết quan hệ KG: release year,
starred actors, directed by tương ứng.

Định nghĩa 2 (Nhúng Đồ thị Tri thức) [51] Thuật toán nhúng KG [28, 51] nhằm ánh
xạ tất cả các thành phần KG bao gồm thực thể và quan hệ vào một không gian vector
chiều thấp và liên tục. Với một KG gồm n thực thể và m quan hệ, chúng ta đầu tiên
khởi tạo các giá trị của h, ℓ và t một cách ngẫu nhiên. Sau đó, một hàm tính điểm
fℓ(h, t) mà chúng ta định nghĩa đo lường mối quan hệ của một bộ ba thực tế (h,
ℓ, t). Cuối cùng, thuật toán nhúng sử dụng một tiêu chí xếp hạng dựa trên biên
để tối ưu hóa phân phối nhúng tối đa hóa tính hợp lý tổng thể của các bộ ba thông
tin (h, ℓ, t) và tối thiểu hóa tính hợp lý của các bộ ba giả mạo (h', ℓ', t') đồng thời.

--- TRANG 12 ---
Mẫu LaTeX Springer Nature 2021
12 Lý luận Chuỗi Quan hệ Cải thiện KGQA Nhúng

Định nghĩa 3 (Nhiệm vụ KGQA đa bước) [2, 5] Câu hỏi đa bước đã được giới thiệu
trong Định nghĩa 1. Trong phần này, chúng tôi định nghĩa một đồ thị tri thức (KG)
là G. G là một đồ thị có hướng có các nút biểu diễn các thực thể và các cạnh biểu
diễn các quan hệ, và mỗi bộ ba trong KG biểu diễn một sự kiện thực tế nguyên tử,
chẳng hạn như (Joseph Robinette Biden, president of, USA).

Chính thức, với một câu hỏi ngôn ngữ tự nhiên phức tạp dưới dạng một chuỗi các
token q = w1, w2, ..., wl và KG G có sẵn, nhiệm vụ KGQA đầu tiên liên kết thực
thể chủ đề wi, ..., wj với KG G. Chủ thể được đề cập trong một câu hỏi cũng được
đặt tên là thực thể chủ đề. Sau đó, nó xác định các quan hệ KG có thể nhất liên
quan đến câu hỏi của người dùng. Sử dụng hai bước này, mục tiêu của KGQA là xác
định câu trả lời thực tế với các bộ ba được lưu trữ trong KG, được biểu thị bởi tập
Aq, để truy vấn q từ các thực thể ứng viên E bằng cách tận dụng thực thể chủ đề
và các quan hệ liên quan trong KG. Cụ thể, chúng tôi tập trung vào việc giải quyết
trả lời câu hỏi phức tạp, được gọi là nhiệm vụ KGQA đa bước, nơi câu trả lời cách
thực thể chủ đề nhiều bước trong đồ thị tri thức, có nghĩa là những câu hỏi này
đòi hỏi nhiều hơn một bộ ba KG.

[Hình 3 cho thấy kiến trúc pipeline tổng thể của chúng tôi cho nhiệm vụ KGQA đa
bước. Các hình chữ nhật xanh lá biểu thị hai mô-đun con của chúng tôi, các mũi
tên liền và mũi tên gạch ngang chỉ ra luồng thông tin qua mô hình của chúng tôi
và các kết quả trung gian. Các hình tiếp theo [5, 6] cũng minh họa điều này bằng
cách sử dụng câu hỏi phức tạp điển hình của người dùng "Ai đã đóng trong những
bộ phim được đạo diễn bởi đạo diễn [Martin Lawrence]?"]

4 Mô hình Được Đề xuất

KGQA Nhúng dựa trên Chuỗi Quan hệ của chúng tôi là một mô hình pipeline hai giai
đoạn bao gồm hai thành phần: Mô-đun Lọc Câu trả lời và Mô-đun Lý luận Chuỗi Quan hệ.

--- TRANG 13 ---
Mẫu LaTeX Springer Nature 2021
Lý luận Chuỗi Quan hệ Cải thiện KGQA Nhúng 13

4.1 Tổng quan

Như được minh họa trong Hình 3, với một câu hỏi thực tế và một KG có sẵn, Mô-đun
Lọc Câu trả lời đầu tiên cùng nhau tận dụng nhúng thực thể chủ đề và biểu diễn
câu hỏi để đánh điểm tất cả các thực thể ứng viên có thể trong KG này để cung cấp
một tập các câu trả lời ứng viên đã được cắt tỉa cho câu hỏi này. Tuy nhiên, các
nút thực thể trong một KG thường ở quy mô lớn như hàng triệu, do đó nó có thể
nhiễu và không chính xác khi so sánh thực thể chủ đề với tất cả các thực thể khác
t̂. Để làm cho việc học hiệu quả và chính xác hơn, chúng tôi không trực tiếp chọn
thực thể được đánh điểm cao nhất từ các thực thể đã sắp xếp làm câu trả lời cuối
cùng. Thay vào đó, chúng tôi giới thiệu mô-đun bổ sung Mô-đun Lý luận Chuỗi Quan
hệ để đưa loại quan hệ và thứ tự của chuỗi quan hệ ngữ nghĩa vào xem xét để có
kết quả độ chính xác hit@1 cao hơn.

Trước khi được đưa vào giai đoạn tiếp theo, chúng tôi chuyển đổi các thực thể ứng
viên trung gian này thành các chuỗi quan hệ ngắn nhất của chúng hướng đến thực
thể chủ đề của câu hỏi bằng cách truy xuất chúng trong KG và ánh xạ các chuỗi có
thứ tự này thành các chuỗi nhúng tương ứng với KG nhúng của chúng tôi. Mô-đun Lý
luận Chuỗi Quan hệ nhận các kết quả trung gian được tạo ra bởi bước cuối. Sau đó,
nó đồng thời sử dụng các chuỗi chuỗi quan hệ và câu hỏi của người dùng để đo điểm
số độ tương tự tương hỗ thông qua mạng Siamese của chúng tôi. Đưa chi tiết lý luận
chuỗi quan hệ câu hỏi vào xem xét có thể giúp tăng độ chính xác của dự đoán câu
trả lời so với giai đoạn đầu tiên, Mô-đun Lọc Câu trả lời. Cuối cùng, sau khi sắp
xếp các ứng viên được đánh điểm, chúng tôi chọn thực thể có điểm số độ tương tự
cao nhất làm câu trả lời cuối cùng. Hình 4 chính thức minh họa thuật toán về cách
phương pháp của chúng tôi hoạt động và dự đoán câu trả lời cuối cùng cho một câu
hỏi đa bước đã cho, trong đó ℓ biểu thị biểu diễn ngữ nghĩa câu hỏi, và ⊙ biểu thị
bộ tính điểm ComplEx.

[Hình 4 Minh họa công thức của mô hình Rce-KGQA của chúng tôi.]

--- TRANG 14 ---
Mẫu LaTeX Springer Nature 2021
14 Lý luận Chuỗi Quan hệ Cải thiện KGQA Nhúng

4.2 Mô-đun Lọc Câu trả lời

Là bước đầu tiên của mô hình, Mô-đun Lọc Câu trả lời của chúng tôi nhằm lọc một
tập thực thể từ tất cả các thực thể KG làm câu trả lời ứng viên thông qua ba bước.
Ba bước hoạt động này được minh họa trong Hình 5 và liên quan tương ứng đến ba
mô-đun con: Bộ tạo Nhúng Đồ thị, Bộ phân tích Ngữ nghĩa Câu hỏi và Bộ tính điểm
Câu trả lời. Chúng tôi giới thiệu mỗi mô-đun con theo thứ tự xử lý hệ thống.

4.2.1 Bộ tạo Nhúng Đồ thị

Các giải pháp truyền thống không thể xử lý nhiều vấn đề tình huống như Lý luận
Quan hệ Ngầm định và Ràng buộc Vùng lân cận Đồ thị con. Được truyền cảm hứng
từ hiệu suất cạnh tranh của nghiên cứu trước đây EmbedKGQA [22], chúng tôi quan
sát thấy rằng tri thức quan hệ toàn cầu và thông tin cấu trúc được bảo tồn trong
nhúng KG có thể tiềm năng được sử dụng để giải quyết những vấn đề này hiệu quả
và cải thiện độ chính xác tổng thể của trả lời câu hỏi.

Trong nghiên cứu này, KG được sử dụng của chúng tôi cũng được nhúng trong không
gian vector liên tục chiều thấp để có được tất cả các biểu diễn thưa thớt cho tất
cả các thực thể và quan hệ tồn tại trong KG để chúng ta có thể đơn giản hóa các
tính toán trên KG. Chúng tôi áp dụng phương pháp Complex Embeddings (ComplEx)
[44] để nhúng quan hệ và thực thể trong không gian vector phức. So với các phương
pháp nhúng KG truyền thống như TransE [41] và các phần mở rộng của nó, các mô
hình khớp ngữ nghĩa như Holographic Embeddings [52], ComplEx và RESCAL [53] đã
chỉ ra rằng chúng thường có thể mang lại kết quả tốt hơn. Tất cả các nhúng KG được
khởi tạo ngẫu nhiên từ phân phối đều. Nói chung, các siêu tham số về chiều nhúng
thực thể và quan hệ không ít hơn 100 và, trong bài báo này, chúng tôi đặt chiều
nhúng ở 200 theo các nghiên cứu tương tự trước đây.

Trong mỗi bước huấn luyện, các sự kiện tích cực trình bày các bộ ba quan hệ thực
tế chính xác được lấy mẫu từ tất cả các bộ ba thông tin tồn tại trong KG. Các sự
kiện tiêu cực trình bày các bộ ba quan hệ thông tin giả được tạo ra từ lấy mẫu tiêu
cực trong bước tạo ví dụ tiêu cực, nơi nó thay thế ngẫu nhiên thực thể đuôi bằng
một thực thể không chính xác hoặc thay thế quan hệ bằng quan hệ không chính xác.

Xem xét tỷ lệ số lượng mẫu tích cực và tiêu cực, Trouillon et al. [44] đã điều tra
thêm ảnh hưởng của các số lượng mẫu tiêu cực khác nhau cho mỗi mẫu tích cực. Nghiên
cứu của họ chứng minh rằng tạo ra nhiều mẫu tiêu cực hơn thường dẫn đến hiệu suất
tốt hơn, và khoảng năm mười mẫu tiêu cực cho mỗi ví dụ tích cực là một sự đánh
đổi phù hợp giữa độ chính xác lý luận và chi phí huấn luyện. Vì vậy, các triển
khai của chúng tôi cũng tuân theo cài đặt trước đây này.

Với h, t ∈ ε và ℓ ∈ R, phương pháp nhúng này sẽ cung cấp vh, vℓ, vt ∈ Cd cho
mỗi bộ ba quan hệ (h', ℓ', t'), và hàm tính điểm được định nghĩa như sau:

⊙(h', ℓ', t') = Re(⟨vh, vr, v̄t⟩) = Re(∑k=1^d vh^(k) vr^(k) v̄t^(k))    (1)

--- TRANG 15 ---
Mẫu LaTeX Springer Nature 2021
Lý luận Chuỗi Quan hệ Cải thiện KGQA Nhúng 15

[Hình 5 minh họa cấu trúc của Mô-đun Lọc Câu trả lời, bao gồm Bộ tạo Nhúng KG,
Bộ phân tích Ngữ nghĩa Câu hỏi với Bi-LSTM và Đơn vị Chú ý, và Mô-đun Tính
điểm Câu trả lời]

⊙(h', ℓ', t') > 0 ∀t ∈ A                                                    (2)
⊙(h', ℓ', t') < 0 ∀h', ℓ', t' ∉ A                                         (3)

trong đó Re() có nghĩa là lấy phần thực của một giá trị phức, v̄t biểu thị liên hợp
của vt, ℓ', t' là quan hệ và thực thể đuôi sai được thay thế ngẫu nhiên của ℓ',
t', và A có nghĩa là tập bao gồm tất cả các bộ ba tri thức thực tế.

Tối ưu hóa Phương trình 1 nhằm tối thiểu hóa các giá trị cho tất cả các bộ ba sai
nhỏ hơn 0, Phương trình 3 và tối đa hóa các giá trị cho tất cả các bộ ba đúng lớn
hơn 0, Phương trình 2. Nó có thể dễ dàng được thực hiện bằng gradient descent
ngẫu nhiên (SGD) hoặc bộ tối ưu Adam tại mỗi vòng lặp huấn luyện. Cuối cùng, cấu
trúc và thông tin quan hệ ban đầu trong KG được bảo tồn trong các vector đã học
này, giúp hoàn thành hiệu quả các quy trình downstream.

4.2.2 Bộ phân tích Ngữ nghĩa Câu hỏi

Trong phần này, chúng tôi giới thiệu Bộ phân tích Ngữ nghĩa Câu hỏi, bao gồm một
mạng thần kinh hồi quy (bidirectional-LSTM) và hoạt động self-attention bổ sung,
để giúp biểu diễn ý nghĩa của câu hỏi. Trong quy trình suy luận, Bộ phân tích Ngữ
nghĩa Câu hỏi nhận một câu hỏi làm đầu vào và cung cấp một vector dự đoán ℓ̂ làm
biểu diễn quan hệ của câu hỏi này giữa chủ đề và câu trả lời trong KG.

Như được hiển thị trong Hình 5, chúng tôi xây dựng mô-đun con này dựa trên mạng
thần kinh phân cấp. Đầu tiên, chúng tôi mã hóa câu hỏi độ dài L {tj} cho j = 1,
..., L thành một chuỗi các vector nhúng từ {vj} thông qua lớp nhúng từ có các tham
số có thể học được trong quá trình huấn luyện. Chiều nhúng từ nhất quán với chiều
ẩn của mạng hồi quy. Sau đó chúng tôi sử dụng một LSTM hai chiều một lớp để học
một chuỗi trạng thái ẩn chuyển tiếp →h1, →h2, ..., →hL và một chuỗi trạng thái ẩn
lùi ←h1, ←h2, ..., ←hL. So với RNN chung, LSTM hai chiều là một RNN đặc biệt chủ
yếu giải quyết các thách thức biến mất gradient và bùng nổ gradient và nắm bắt
ngữ nghĩa tầm xa tốt hơn trong quá trình mô hình hóa chuỗi dài. Thành phần LSTM
của chúng tôi sử dụng 256 làm chiều của các biểu diễn ẩn ht và tế bào bộ nhớ ct.
Ai cũng biết rằng hiệu suất của LSTM phụ thuộc rất nhiều vào việc khởi tạo chúng
và đưa ra một điểm khởi đầu mạnh mẽ để tạo thuận lợi cho sự hội tụ mô hình, vì
vậy chúng tôi khởi tạo trọng số LSTM hai chiều của chúng tôi với khởi tạo Xavier
[54] vượt trội đáng kể so với các phương pháp khởi tạo khác như khởi tạo Gaussian,
Uniform và Kaiming [55].

Lấy bước chuyển tiếp làm ví dụ, trạng thái tiếp theo →hj dựa trên trạng thái cuối
→hj-1 được tính toán thông qua các hoạt động sau.

fj = σ(Wxf xj + Whf →hj-1 + bf)                                             (4)
ij = σ(Wxi xj + Whi →hj-1 + bi)                                             (5)
oj = σ(Wxo xj + Who →hj-1 + bo)                                             (6)
cj = fj ⊙ cj-1 + ij ⊙ tanh(Wxc xj + Whc →hj-1 + bc)                        (7)
→hj = oj ⊙ tanh(cj)                                                          (8)

Các biến fj, ij, oj trong các phương trình trên là các vector kích hoạt của cổng
đầu vào, quên và đầu ra tương ứng, trong đó cj-1 và cj là các vector trạng thái
tế bào ở thời điểm j-1 và thời điểm j, tanh và σ là các hàm tangent hyperbolic
và sigmoid. Phương trình 4 biểu thị hoạt động cổng quên, nhằm kiểm soát xem có
quên một phần thông tin trạng thái tế bào ẩn của thời điểm cuối cùng với xác suất
nhất định hay không. Phương trình 5 biểu thị hoạt động cổng đầu vào, chịu trách
nhiệm xử lý đầu vào chuỗi hiện tại. Phương trình 6 biểu thị hoạt động cổng đầu
ra, xác định mức độ thông tin được cập nhật và đầu ra. Phương trình 7 và 8 là các
bước cập nhật trạng thái tế bào cũ, được xác định chung bởi trạng thái của chuỗi
trước, đầu vào hiện tại của chuỗi này và hàm kích hoạt. Sau khi thông tin chảy
qua LSTM, chúng tôi nối →hj và ←hj và có được các đặc trưng kết hợp hj = [→hj, ←hj].
Sau đó, trạng thái ẩn cuối cùng được coi là biểu diễn ngữ nghĩa câu hỏi.

Các token từ khác nhau đóng góp khác nhau vào việc nhận dạng ngữ nghĩa quan hệ.
Ví dụ, các từ là giới từ và mạo từ ít liên quan hơn để khám phá ngữ nghĩa câu hỏi
so với các từ chỉ thị quan hệ. Do đó, sau LSTM chúng tôi áp dụng cơ chế self-attention
để nắm bắt các đặc trưng có giá trị hơn. Chi tiết hoạt động attention được hiển thị
trong Phương trình 9 và Phương trình 10. Với một biểu diễn ẩn LSTM, một lớp kết
nối đầy đủ, hàm kích hoạt tanh và hoạt động softmax sẽ cùng nhau tạo ra trọng số
attention αj đầu tiên. Sau đó, như được hiển thị trong Phương trình 10, vector biểu
diễn attention cuối cùng sj là biểu diễn ngữ nghĩa của câu hỏi ngôn ngữ được tổng
hợp bởi hoạt động tổng có trọng số của hj và aj.

αj = exp(aj) / ∑i=1^L exp(ai) where aj = tanh(wa^T[hj] + b)                 (9)
sj = ∑i αij hij                                                              (10)

Tất cả các ma trận trọng số, vector trọng số W, và các hạng tử bias được tính toán
dựa trên dữ liệu huấn luyện, tức là ma trận trọng số đơn vị cổng LSTM {Wf, Wi, Wo}
và ma trận trọng số attention wa^T. Bằng cách này, chúng tôi có được ngữ nghĩa quan
hệ phong phú được ẩn trong câu hỏi ngôn ngữ tự nhiên để lý luận câu trả lời.

--- TRANG 16 ---
Mẫu LaTeX Springer Nature 2021
16 Lý luận Chuỗi Quan hệ Cải thiện KGQA Nhúng

4.2.3 Bộ tính điểm Câu trả lời

Giống như hàm tính điểm ComplEx [44] được mô tả trong Phương trình 1, 2, và 3,
như được hiển thị trong Phương trình 11, chúng tôi học một bộ xếp hạng câu trả
lời Rank(t) cho mỗi ứng viên t, cụ thể là Bộ tính điểm Câu trả lời để đánh điểm
cặp (thực thể chủ đề, ngữ nghĩa quan hệ) chống lại tất cả các thực thể KG có thể
t ∈ ε bằng cách tối đa hóa xác suất của các mẫu tích cực t ∈ A và tối thiểu hóa
mẫu tiêu cực t' ∉ A, trong đó A có nghĩa là tập bao gồm tất cả các bộ ba tri thức
thực tế.

Rank(t) = {max(⊙(h, ℓ̂, t)); ∀t ∈ A
           {min(⊙(h, ℓ̂, t')); ∀t' ∉ A                                    (11)

Vì Bộ phân tích Ngữ nghĩa Câu hỏi của chúng tôi được thiết kế để phù hợp với các
đặc trưng quan hệ thực tế, tất cả các nhúng thực thể KG được huấn luyện trước được
đóng băng trong quá trình hội tụ mô hình.

Thay vì chỉ đơn giản chọn thực thể có điểm số cao nhất do hiệu suất recall thấp
nhưng recall cao, chúng tôi tiến hành lọc thô bằng cách chọn top-n, trong đó n ∈
{5, 10, 15} để có được các thực thể ứng viên trung gian được đánh điểm có tỷ lệ
recall câu trả lời cao. Đối với suy luận, Mô-đun Tính điểm Câu trả lời cho mỗi ứng
viên một điểm số hợp lý để chỉ ra độ tin cậy câu trả lời của nó và lọc ra kết quả
trung gian được đánh điểm top-n được đưa vào bước tiếp theo, mô-đun Lý luận Chuỗi
Quan hệ.

4.3 Mô-đun Lý luận Chuỗi Quan hệ

KG có sẵn của chúng ta thường chứa một số lượng lớn thực thể và có các bộ ba thông
tin khổng lồ, và nó có thể không chính xác khi so sánh tất cả các biểu diễn nhúng
ứng viên với nhau. Cụ thể, sau khi huấn luyện Mô-đun Lọc Câu trả lời, chúng tôi
có được tất cả các thực thể được đánh điểm cho mỗi mẫu huấn luyện. Trong quá trình
phân tích kết quả dự đoán, chúng tôi quan sát thấy rằng hiệu suất mô hình trên
hit@5 vượt trội so với hit@1 metric, có thể là do ảnh hưởng của một số lượng lớn
thực thể nhiễu trong KG quy mô lớn. Hơn nữa, vì câu trả lời được đưa ra là thông
tin ground-truth duy nhất, một thách thức lớn đối với KGQA đa bước là nó thường
thiếu tín hiệu giám sát lý luận trung gian.

[Hình 6 mô tả cấu trúc của Mô-đun Lý luận Chuỗi Quan hệ được thiết kế, bao gồm
Bộ phân tích ngữ nghĩa Câu hỏi sử dụng RoBERTa Transformer và mô-đun Biểu diễn
Chuỗi Quan hệ sử dụng Bi-LSTM]

Để giải quyết những vấn đề này, chúng tôi đề xuất một thành phần bổ sung cho công
việc KGQA của chúng tôi, được gọi là Mô-đun Lý luận Chuỗi Quan hệ. Là bước cuối
cùng và quan trọng của phương pháp chúng tôi, nó nhằm cải thiện độ chính xác lý
luận thông qua việc xem xét thứ tự chuỗi lý luận và loại quan hệ của nó trong tình
huống giám sát yếu. Quy trình huấn luyện của nó không liên quan đến Mô-đun Lọc
Câu trả lời, nhưng tập dữ liệu huấn luyện của nó được xây dựng từ kết quả dự đoán
của Mô-đun Lọc Câu trả lời.

Chính thức, chúng tôi sử dụng Mô-đun Lọc Câu trả lời đã được huấn luyện để có được
các thực thể được sắp xếp theo điểm số {[eit, sit]}ni=1, {[eiv, siv]}ni=1 và {[eie,
sie]}ni=1 cho các tập dữ liệu huấn luyện, xác thực và kiểm tra, tương ứng. Sau đó,
các kết quả được đánh điểm này được cắt bớt bằng cách chỉ bảo tồn top-n (n ∈ {5,
10, 15}) ứng viên. Tiếp theo, nhìn vào các kết quả được lọc thô trong mỗi mẫu thí
nghiệm, nếu nó thuộc về các câu trả lời chính xác, chúng tôi xây dựng một mẫu tích
cực tương ứng [q, {ri}ci=1], trong đó q biểu thị các token câu hỏi và {ri}ci=1 là
đường dẫn ngắn nhất có độ dài c được tìm kiếm bởi thuật toán truy xuất đồ thị,
cũng như các mẫu tiêu cực không nằm trong các câu trả lời chính xác.

4.3.1 Tính điểm Độ tương tự dựa trên Mạng Siamese

Như được hiển thị trong Hình 6, chúng tôi giới thiệu mô-đun con mới Tính điểm Độ
tương tự dựa trên Mạng Siamese, về cơ bản là một mạng Siamese [23]. Hai bộ phát
hiện đặc trưng của mô-đun nhằm trích xuất biểu diễn ngữ nghĩa câu hỏi Phương trình
12 và chuỗi quan hệ Phương trình 13. Chúng được xây dựng bởi một transformer
RoBERTa được huấn luyện trước [25] để tạo ra vector câu hỏi Vq từ câu hỏi q =
{wi}Ni=1 và một LSTM hai chiều một lớp để tạo ra vector chuỗi quan hệ Vr từ chuỗi
quan hệ r = {rj}Mj=1. RoBERTa là một kỹ thuật huấn luyện trước tự giám sát cách
mạng học dự đoán các phần văn bản ngôn ngữ được ẩn có chủ ý. Hơn nữa, các biểu
diễn được học bởi RoBERTa đã được chỉ ra có thể khái quát hóa kết quả vượt trội
thậm chí so với nhiều nhiệm vụ downstream NLP so với BERT ban đầu [50]. Chi tiết
cấu trúc sẽ được mô tả trong hai tiểu mục liên tiếp tiếp theo. Sau khi thông tin
đi qua hai mạng mã hóa này, độ tương tự đặc trưng ngữ nghĩa Phương trình 14 trong
không gian biểu diễn vector sau đó được sử dụng để suy luận độ tương tự ngữ nghĩa
giữa câu hỏi và chuỗi quan hệ từ thực thể chủ đề đến câu trả lời.

Vq = W2T(drop(W1T(RoBERTa(q)) + b1)) + b2                                     (12)
Vr = Attn(BiLSTM(r))                                                          (13)
Score(Vq, Vr) = exp(-||Vq(2) - Vr(2)||2)                                     (14)

Ở đây, chúng tôi giải thích tại sao chúng tôi sử dụng điểm số độ tương tự ngữ nghĩa
giữa biểu diễn chuỗi quan hệ Vr và câu hỏi Vq để xác định câu trả lời đúng một
cách chi tiết. Lấy câu hỏi trên "Ai đã đóng trong những bộ phim được đạo diễn bởi
đạo diễn [Martin Lawrence]?" làm ví dụ, chúng tôi biểu thị các token ngôn ngữ tự
nhiên là q. Được truyền cảm hứng từ văn học trong những năm gần đây như [2, 36],
chúng tôi trực quan giả định rằng ngữ nghĩa câu hỏi được ẩn tương tự và biểu diễn
của nó gần hơn với biểu diễn chuỗi quan hệ trong không gian vector, "directed by
reverse → starred actors reverse", đúng về cả thứ tự và loại. Nó không nhất quán
và xa với các chuỗi quan hệ có loại hoặc thứ tự sai, chẳng hạn như "starred actors
reverse → directed by reverse" và "directed by reverse → written by reverse".

Như được hiển thị trong Phương trình 14, chúng tôi huấn luyện bộ tính điểm độ tương
tự sử dụng thuật toán lan truyền ngược gradient descent ngẫu nhiên (SGD) dưới hàm
mất mát lỗi bình phương trung bình (MSE). Sau đó chúng tôi trang bị tiêu chí huấn
luyện của chúng tôi với metric chuẩn ℓ2 (khoảng cách Euclidean) để tránh phân phối
tham số mô hình bị méo mạnh. Về các nhãn liên quan dự đoán nằm trong [0, 1], đối
với mẫu tích cực chúng tôi tối đa hóa giá trị dự đoán càng gần 1 càng tốt, và mẫu
tiêu cực càng gần 0 càng tốt. Cuối cùng, sau khi sắp xếp các ứng viên được đánh
điểm, chúng tôi chọn thực thể có điểm số độ tương tự cao nhất làm câu trả lời cuối cùng.

--- TRANG 17 ---
Mẫu LaTeX Springer Nature 2021
Lý luận Chuỗi Quan hệ Cải thiện KGQA Nhúng 17

4.3.2 Biểu diễn Ngữ nghĩa Câu hỏi

Như được mô tả trong Hình 6 bên trái, chúng tôi sử dụng và tinh chỉnh một phiên
bản chuẩn của RoBERTa để có được trạng thái ẩn Vq nằm trong token bắt đầu [CLS]
cho bộ mã hóa câu hỏi của chúng tôi. Lưu ý rằng chúng tôi định dạng lại câu hỏi
q thông qua việc thay thế đề cập thực thể chủ đề trong câu hỏi bằng token "NE".
Và chúng tôi tương ứng bổ sung hai ký tự đặc biệt '[CLS]' và '[SEP]' trước và sau
câu hỏi được định dạng lại, tuân theo cấu hình mặc định của BERT. Các hoạt động
nói trên có thể giúp mô hình của chúng tôi phân biệt tốt hơn thực thể chủ đề và
các từ câu hỏi khác được đề cập. Sau đó, chúng tôi liên kết đề cập thực thể chủ
đề của câu hỏi với nút KG thông qua khớp với các biểu diễn literal thực thể KG
chuẩn. Chúng tôi coi nó là tín hiệu ngữ nghĩa để lý luận câu trả lời và sau đó áp
dụng hai lớp kết nối đầy đủ, hàm kích hoạt neuron ReLU [56] và một lớp dropout
để có được khả năng học đặc trưng tốt hơn. Sau bước trên, một biểu diễn vector
được tạo ra bởi lớp fully-connected cuối cùng, và chúng tôi sử dụng vector để so
sánh độ tương tự khoảng cách không gian với đầu ra của bộ mã hóa đặc trưng khác,
Mô-đun Biểu diễn Chuỗi Quan hệ.

4.3.3 Biểu diễn Chuỗi Quan hệ

Như được mô tả trong Hình 6 bên phải, chúng tôi cung cấp mô-đun Biểu diễn Chuỗi
Quan hệ bao gồm một LSTM hai chiều một lớp và một lớp self-attention. Với chuỗi
nhúng chuỗi quan hệ KG làm đầu vào, mô-đun này học và nắm bắt thông tin ngữ nghĩa
liên quan và cần thiết để lý luận trả lời. Nó có cấu trúc tương tự như Bộ phân tích
Ngữ nghĩa Câu hỏi trong Mô-đun Lọc Câu trả lời, nhưng các nhúng token được sử
dụng không được khởi tạo ngẫu nhiên trong trường hợp này. Thay vào đó, chúng tôi
áp dụng các biểu diễn nhúng quan hệ KG được huấn luyện trước tồn tại trong Mục
4.2.1 để nhúng chuỗi quan hệ của chúng tôi.

Chính thức, như được mô tả trong Phương trình 13, đối với chuỗi quan hệ r = {rj}Mj=1,
trong đó M biểu thị độ dài chuỗi, mỗi biểu diễn quan hệ rj (j = 1, 2, ..., M) được
khởi tạo với các nhúng quan hệ KG được huấn luyện trước. Tiếp theo, chúng tôi đưa
các vector nhúng r vào một mạng LSTM hai chiều một lớp để có được một loạt các
trạng thái đầu ra h1, h2, ..., hM, trong đó quan hệ thứ j hj biểu thị [→hj, ←hj],
một vector kết hợp của đầu ra trạng thái LSTM chuyển tiếp →hj và đầu ra trạng thái
LSTM lùi ←hj. Sau đó biểu diễn câu hỏi mới q = [h1, h2, ..., hM] có thể được chuyển
đổi thông qua một hoạt động self-attention, tương tự như đối tác Mô-đun lọc Câu
trả lời, được hiển thị trong Phương trình 9, 10. Thông qua sự lan truyền chuyển
tiếp này, tương tự như Bộ phân tích Ngữ nghĩa Câu hỏi, chúng ta có thể có được
một vector ngữ nghĩa câu hỏi Vq có cùng chiều với vector chuỗi quan hệ Vr cho bước
tính toán độ tương tự tiếp theo.

5 Thí nghiệm

Trong phần này, chúng tôi đánh giá Rce-KGQA được đề xuất của chúng tôi so với
các baseline cạnh tranh trên ba tập dữ liệu chuẩn để điều tra xem mô hình của chúng
tôi có thể vượt trội hơn các phương pháp khác trong việc lý luận qua tín hiệu giám
sát yếu và đồ thị tri thức không đầy đủ hay không. Và chúng tôi cũng bổ sung các
thí nghiệm loại bỏ rộng rãi và một nghiên cứu trường hợp để xác minh cẩn thận và
minh họa sinh động sự cần thiết, tính ưu việt, và ý nghĩa về ý tưởng của chúng tôi
trong công việc này. Các tập dữ liệu cũng như triển khai pytorch của mô hình của
chúng tôi được công khai tại https://github.com/albert-jin/Rce-KGQA.

--- TRANG 18 ---
Mẫu LaTeX Springer Nature 2021
18 Lý luận Chuỗi Quan hệ Cải thiện KGQA Nhúng

5.1 Tập dữ liệu và Thước đo Đánh giá

Ở đây, chúng tôi đầu tiên mô tả ba tập dữ liệu chuẩn mà chúng tôi sử dụng trong
công việc này và sau đó đưa ra giới thiệu ngắn gọn về thước đo hit@1 mà chúng tôi
sử dụng để đánh giá mô hình.

MetaQA [57] là một tập dữ liệu KGQA lớn cung cấp một phiên bản gốc Vanilla và
hai biến thể. Trong bài báo này, chúng tôi sử dụng phiên bản gốc vì chúng được
thiết kế thủ công. Tập dữ liệu này bao gồm tới 75 vạn cặp QA chỉ là câu hỏi 2-hop.
Các mô tả literal của câu hỏi được tạo ra bằng dịch thuật đa ngôn ngữ, Tiếng Anh
→ Tiếng Pháp → Tiếng Anh. Điều này dựa vào một miền phim quy mô lớn chứa 9
loại quan hệ, 43234 thực thể và lên đến 135k bộ ba thông tin. Ở đây, chúng tôi sử
dụng phiên bản tập dữ liệu được tạo ra từ Apoorv et al. [22].

Tập dữ liệu WebQuestionsSP-tiny [58] là một tập dữ liệu tương đối nhỏ với tổng
cộng 4736 cặp QA. KG có sẵn của tập dữ liệu QA này là một tập con của Freebase
chứa tất cả các sự kiện trong vòng 2-hop của bất kỳ thực thể nào được đề cập trong
các câu hỏi của WebQuestionsSP gốc, có hơn 188 vạn thực thể và 1000 loại quan hệ.
Theo [22], đối với tất cả các thực thể chủ đề được gán nhãn trong Freebase gốc,
He et al. [27] xây dựng một đồ thị con chứa các thực thể KG khác gần chúng bằng
thuật toán PageRank-Nibble (PRN) [59]. Bằng cách này, về mặt lý thuyết, KG được
cắt tỉa có khả năng chứa thực thể câu trả lời tương ứng cho gần như toàn bộ câu
hỏi. Trong nghiên cứu này, chúng tôi sử dụng cùng việc chia train/dev/test như
GraftNet [21].

Complex WebQuestionsSP (Complex-WebQSP) [60] là một tập dữ liệu lý luận đa
bước phức tạp hơn và các câu hỏi của nó yêu cầu tới đường dẫn quan hệ 4-hop trong
lý luận câu trả lời. Có bốn loại câu hỏi: conjunction (khoảng 45%), composition
(khoảng 45%), comparative (khoảng 5%), và superlative (khoảng 5%). Phiên bản
được sử dụng của chúng tôi cho tập dữ liệu Complex-WebQSP được lấy từ He et al. [27].

[Bảng 1 thống kê cho tập dữ liệu MetaQA, WebQuestionsSP-tiny và Complex WebQuestionsSP]

Thước đo hit@1 là một đánh giá tiêu chuẩn để đo tỷ lệ trong tất cả các mẫu xác
thực mà thực thể được đánh điểm cao nhất thuộc về các câu trả lời chính xác. Nói
tóm lại, nếu hệ thống QA cung cấp cho người dùng một thực thể duy nhất và thực
thể này đúng, thì chúng ta xác định dự đoán này là chính xác. Chỉ báo đánh giá
này phổ biến và được công nhận rộng rãi và đã được sử dụng trong nhiều nghiên
cứu KGQA gần đây [22, 26, 37].

5.2 Cài đặt Thí nghiệm

Như chúng ta biết, lựa chọn siêu tham số có tác động đáng kể đến hiệu suất cuối
cùng của mô hình [61-63]. Cấu hình siêu tham số mô hình tối ưu của chúng tôi được
tóm tắt như sau. Tất cả các mô-đun LSTM mà chúng tôi sử dụng làm bộ mã hóa đặc
trưng có một lớp duy nhất với chiều ẩn 256. Tất cả các lớp dropout ngẫu nhiên loại
bỏ khoảng 30% đặc trưng của chúng cho đầu vào trong bước huấn luyện nhưng chúng
không loại bỏ bất kỳ đặc trưng nào trong quá trình kiểm tra. Chúng tôi áp dụng khởi
tạo Xavier cho các tham số huấn luyện của mỗi lớp mạng trong mô hình của chúng
tôi. Transformer RoBERTa được huấn luyện trước được áp dụng của chúng tôi là một
cấu hình được triển khai PyTorch, sử dụng kiến trúc BERT-base [50, 64, 65], bao
gồm 12 lớp, kích thước ẩn 768-d và 12 đầu attention để huấn luyện và suy luận
hiệu quả. Bộ mã hóa Roberta-base [25, 66] chứa tới khoảng 125M tham số. Mô-đun
Lọc Câu trả lời được huấn luyện tới 200 epoch với kích thước batch 128, và mô-đun
lý luận chuỗi quan hệ được huấn luyện tới 120 epoch với kích thước batch 32 trên
ba bộ chuẩn. Cứ mỗi 10 epoch huấn luyện, chúng tôi áp dụng chiến lược dừng sớm
bằng cách đánh giá hit@1 trên tập kiểm tra để tránh overfitting. Trong quá trình
hội tụ mô hình, bộ tối ưu gradient descent ngẫu nhiên (SGD) với tỷ lệ học tập ban
đầu lr = 1e-5 được áp dụng. Chúng tôi sử dụng các seed ngẫu nhiên khác nhau để
xác thực mô hình được cấu hình tốt nhất của chúng tôi một cách độc lập 5 lần và
báo cáo hiệu suất xác thực trung bình của mô hình trong các phần tiếp theo.

5.3 Phương pháp So sánh

Trong thí nghiệm của chúng tôi, các phương pháp tiên tiến để so sánh được mô tả
như sau:

• EmbedKGQA [22] là một phương pháp điều khiển nhúng KG cho KGQA đa bước khớp
các nhúng thực thể được huấn luyện trước với nhúng câu hỏi được tạo ra từ transformer.

• SRN [11] là một mô hình trả lời câu hỏi đa bước dựa trên RL tiến hành nhiệm vụ
QA bằng cách mở rộng các chuỗi suy luận trên một KG.

• KVMem [31] Key-Value Memory Network đầu tiên cố gắng tiến hành QA trên KG
không đầy đủ bằng cách tăng cường nó bằng văn bản. Nó sử dụng một bảng bộ nhớ
lưu trữ các sự kiện KG được mã hóa thành các cặp khóa-giá trị để truy xuất một
đồ thị con cụ thể câu hỏi để lý luận.

• GraftNet [21] là một phương pháp điều khiển đồ thị con ngữ nghĩa dựa trên mô
tả câu hỏi sử dụng CNN đồ thị biến phân để thực hiện các nhiệm vụ QA trên các
đồ thị con cụ thể câu hỏi chứa các sự kiện KG, thực thể và diễn ngôn từ các corpus văn bản.

• PullNet [10] cải thiện GraftNet trên đồ thị con truy xuất bằng cách giới thiệu
mô-đun truy xuất đồ thị sử dụng đường dẫn ngắn nhất từ thực thể chủ đề đến câu
trả lời làm tín hiệu giám sát bổ sung.

• NSMs [27] là một loạt các phương pháp học giáo viên-học sinh được triển khai
dựa trên Neural State Machine [40]. NSM, NSM+p, và NSM+h là ba biến thể mô hình
hiệu quả sử dụng các tín hiệu giám sát trung gian. Cụ thể, NSM không sử dụng mạng
giáo viên, NSM+p sử dụng mạng giáo viên với lý luận song song, và NSM+h sử dụng
mạng giáo viên với lý luận hybrid.

5.4 Kết quả Chính

Trong phần này, chúng tôi so sánh mô hình của chúng tôi với các phương pháp baseline
tiên tiến trên ba bộ chuẩn, và các câu hỏi sau được trả lời:

Q1. Hiệu quả và độ chính xác của hiệu suất mô hình của chúng tôi so với các mô
hình SOTA khác như thế nào?

Q2. Mô hình của chúng tôi có thể thực sự xác định các quan hệ ngầm định và câu
trả lời được liên kết gián tiếp khi không có chuỗi quan hệ trực tiếp từ thực thể
chủ đề đến câu trả lời không?

Q3. Rce-KGQA của chúng tôi chứa bao nhiêu tham số, và mô hình của chúng tôi có
hiệu quả thực thi cao nhất định không?

5.4.1 Lý luận Câu trả lời trên MetaQA

Như được minh họa trong Bảng 2, kết quả thí nghiệm tổng thể trên tập kiểm tra
MetaQA rõ ràng chứng minh rằng kiến trúc KGQA được đề xuất của chúng tôi vượt
trội đáng kể so với các phương pháp tiên tiến trên thước đo hit@1. Cụ thể, theo
hiệu suất kết quả mô hình của chúng tôi trên 1-hop MetaQA (giống hệt WikiMovies),
so với các phương pháp khác, Hàng 1~5, chúng tôi quan sát thấy rằng độ chính xác
hit@1 của phương pháp chúng tôi đạt được hiệu suất cao hơn nhiều lên đến 98.3%,
tăng 1.3% so với GraftNet [21] và PullNet [10], tăng 0.8% so với EmbedKGQA [22]
và tăng 1.1% so với NSM+h [27].

Đối với đánh giá các câu hỏi đa quan hệ đòi hỏi ít nhất hai bước suy luận để tìm
câu trả lời, kết quả hit@1 trên 2-hop và 3-hop MetaQA cũng cho thấy hiệu suất
tốt hơn so với hầu hết các baseline tiên tiến cạnh tranh. Mặc dù kết quả kiểm tra
mô hình của chúng tôi trên 2-hop không đạt được điểm số tốt nhất, nó vẫn có thể
so sánh được với các mô hình SOTA khác. Đáng chú ý rằng quy trình truy xuất và
lý luận của PullNet, có thể đồng thời trích xuất câu trả lời từ cả corpus và KG,
giỏi trong việc lý luận câu trả lời trên KG quy mô lớn như MetaQA. Ngược lại,
chúng ta có thể thấy rằng mô hình Rce-KGQA của chúng tôi, đưa lý luận chuỗi quan
hệ vào xem xét, không giảm đáng kể về hiệu suất mà vẫn gần như không thay đổi
khi độ dài chuỗi quan hệ tăng. Chúng tôi nghĩ lý do có thể là các mô hình baseline
chỉ xem xét biểu diễn ngữ nghĩa shadow câu hỏi, và không thể tránh khỏi việc giới
thiệu nhiễu và đường dẫn truy xuất không chính xác trên KG. Mặt khác, vì mô hình
của chúng tôi tập trung vào thứ tự chuỗi quan hệ và loại quan hệ, nó ít nhạy cảm
hơn với kích thước hop và cho thấy tính bền vững trên các truy vấn đa ràng buộc
phức tạp trên KG.

[Bảng 2 cho thấy so sánh hiệu quả trên ba tập con của MetaQA]

Tóm lại, những kết quả này đã chỉ ra tính hiệu quả và ưu việt của chúng khi xem
xét ngữ nghĩa câu hỏi và chuỗi quan hệ của nó vào lý luận, điều này cải thiện đáng
kể hiệu suất KGQA.

Tuy nhiên, chúng tôi cũng nhất quán thấy rằng cơ chế pipeline hai giai đoạn của
Rce-KGQA được đề xuất có thể mang lại lan truyền cascade sai lệch giữa quy trình
lọc câu trả lời thô [5] và quy trình chọn câu trả lời tinh [6]. Như được hiển thị
trong Bảng 2, và kết quả so sánh từ các cột của 2/3-hop MetaQA được chỉ ra. Phương
pháp của chúng tôi hoạt động kém khi so sánh với các mô hình KGQA khác như PullNet
và NSMs. Tất cả đều nhất quán đạt được hiệu suất rất cao với thước đo hit@1 đạt
99.9 phần trăm trên 2-hop MetaQA và 98.9 phần trăm hit@1 trên tập dữ liệu 3-hop
MetaQA. Tương ứng, Rce-KGQA của chúng tôi hoạt động kém với khoảng 0.2 điểm
phần trăm tụt hậu trên 2-hop MetaQA và khoảng 1.0 điểm phần trăm tụt hậu trên
tập dữ liệu 3-hop MetaQA.

Nói chung, mặc dù giải pháp pipeline hai giai đoạn của chúng tôi vượt trội hơn nhiều
baseline như GraftNet và PullNet [10, 21], kiến trúc riêng biệt được thiết kế của
Rce-KGQA xác định thực tế rằng chất lượng của câu trả lời cuối cùng được cung cấp
bởi Mô-đun Lý luận Chuỗi Quan hệ hoàn toàn phụ thuộc vào chất lượng của các thực
thể ứng viên được cung cấp bởi Mô-đun Lọc Câu trả lời. Đặc trưng của kiến trúc
pipeline như thế này là lý do chính không thể tránh khỏi gây ra lan truyền lỗi
cascade, điều này sẽ làm giảm hiệu suất tổng thể của dịch vụ trả lời câu hỏi. Chúng
tôi nghĩ điều quan trọng là tăng cường mô hình Rce-KGQA của chúng tôi bằng cách
tích hợp hai mô-đun riêng biệt này [5, 6] thành một mô-đun kết hợp, điều mà chúng
tôi để dành cho công việc tương lai.

Ngoài khối lượng tham số của vector đồ thị nhúng, hai mô-đun giai đoạn của chúng
tôi tương ứng chứa 46M tham số (chủ yếu thuộc về khối BiLSTM-Attn) và 197M tham
số (chủ yếu thuộc về bộ mã hóa Roberta và khối BiLSTM-Attn). Qua các thí nghiệm
của chúng tôi, chúng tôi quan sát thấy rằng tổng thời gian suy luận dao động giữa
1.9 giây và 2.7 giây, trong đó Mô-đun Lọc Câu trả lời đóng góp khoảng 0.6s và
Mô-đun Lý luận Chuỗi Quan hệ đóng góp khoảng 1.4s. Có thể tưởng tượng rằng nếu
bộ mã hóa được chuyển sang RoBERTa sử dụng kiến trúc BERT-large [25, 66], nó sẽ
có nghĩa là tham số nặng hơn, bao gồm tới 355M tham số và các quy trình tối ưu
hóa huấn luyện bổ sung và thời gian suy luận tiêu thụ nhiều hơn. Dựa trên khả năng
tái tạo thí nghiệm và cân nhắc về tính nhẹ của mô hình, chúng tôi đã chọn cấu hình
cơ bản của bộ mã hóa Roberta.

5.4.2 Thí nghiệm trên WebQSP-tiny và Complex-WebQSP

WebQuestionsSP-tiny [22, 27, 36] là một tập dữ liệu tương đối nhỏ để huấn luyện
nhưng dựa vào một KG quy mô lớn (Freebase) có số lượng thực thể lớn hơn 10 triệu.
Bảng 3 trình bày kết quả đánh giá trên tập dữ liệu xác thực WebQuestionsSP-tiny,
từ đó chúng ta có thể quan sát thấy rằng hệ thống KGQA của chúng tôi vẫn hoạt động
tốt hơn các đối tác tiên tiến khác, EmbedKGQA (có 3.8% hits-at-one thấp hơn so
với mô hình của chúng tôi) và PullNet (có 2.3% hits-at-one thấp hơn so với mô hình
của chúng tôi).

[Bảng 3 cho thấy kết quả thí nghiệm (% Hits@1) so sánh với các phương pháp SOTA
trên tập dữ liệu xác thực WebQuestionsSP-tiny và Complex WebQuestionsSP]

Cụ thể, hàng cuối cùng cho thấy mô hình đầy đủ của chúng tôi đạt được độ chính
xác lên đến 70.4% hit@1, cải thiện đáng kể so với các mô hình trước đây khác. Một
giải thích có thể là mô hình lọc trang bị mô-đun chuỗi quan hệ bổ sung với khả năng
nhận thức lý luận tốt hơn, tận dụng các đặc trưng ngầm định KG và câu hỏi hiệu
quả hơn, và nhấn mạnh thứ tự lựa chọn bộ ba quan hệ để giúp mô hình của chúng
tôi đưa ra quyết định chính xác. Ngay cả trong tình huống KG quy mô lớn cùng với
tập dữ liệu huấn luyện nhỏ như WebQuestionsSP-tiny, giải pháp Rce-KGQA của chúng
tôi vẫn có thể bền vững và hữu ích để xử lý các ứng dụng QA thực tế.

Complex-WebQSP [27] là một phiên bản tập dữ liệu KGQA dẫn xuất được tạo ra từ
WebQuestionsSP-tiny bằng cách mở rộng các thực thể câu hỏi hoặc thêm ràng buộc
vào câu trả lời. Như tên gọi, hầu hết các câu hỏi mà tập dữ liệu này bao gồm đòi
hỏi tới 4-hop lý luận chuỗi quan hệ từ thực thể chủ đề đến các câu trả lời tương ứng.

Cột thứ ba của Bảng 3 báo cáo thống kê thước đo hit@1 trên bộ chuẩn Complex-WebQSP.
Mô hình của chúng tôi hoạt động cạnh tranh với các baseline KGQA tiên tiến trên
tình huống trả lời câu hỏi đa bước phức tạp như vậy. Cụ thể hơn, trong số hầu hết
các baseline (KVMem ~ NSM), Rce-KGQA của chúng tôi vượt trội đáng kể so với các
baseline khác, và tương ứng đạt được mức tăng tuyệt đối 27.2%, 15.5%, 3.3%, và
0.7% so với các baseline này (KVMem ~ NSM) về thước đo tổng thể hit@1. Điều này
thiết lập thực tế rằng Rce-KGQA của chúng tôi tốt hơn các phương pháp trước về
mặt trả lời các câu hỏi với sự phụ thuộc quan hệ khoảng cách xa. NSM+h đạt được
hiệu suất tốt nhất trên hai bộ chuẩn được áp dụng. NSM+p và Rce-KGQA của chúng
tôi cả hai đều đạt được hiệu suất tốt thứ hai trên bộ chuẩn Complex-WebQSP, chứng
minh khả năng cạnh tranh của mô hình chúng tôi và tầm quan trọng của mạng giáo
viên được thêm vào. Đây là một quan sát và tiến bộ quan trọng khi nói đến việc xử
lý các nhiệm vụ trả lời câu hỏi phức tạp như vậy vì phương pháp được đề xuất của
chúng tôi bền vững và hiệu quả trong việc đối phó với những câu hỏi phức tạp này
trong các tình huống lý luận câu trả lời đa-quan hệ-hop.

5.5 Lý luận Câu trả lời cho khám phá quan hệ ngầm định

Như được hiển thị trong Bảng 4, chúng tôi xác minh khả năng khám phá các mối quan
hệ ngầm định thiếu của phương pháp chúng tôi thông qua các thí nghiệm so sánh.
KG mà MetaQA sử dụng không có liên kết thiếu trong đường dẫn lý luận vì các cặp
câu hỏi QA được xây dựng dựa trên KG này. Tuy nhiên, để làm cho nó trở thành một
cài đặt thực tế, chúng tôi mô phỏng một KG không đầy đủ bằng cách loại bỏ ngẫu
nhiên một nửa (với xác suất = 0.5) các bộ ba thông tin từ nó. Chúng tôi gọi cài
đặt được cắt tỉa này là half và chúng tôi gọi cài đặt KG đầy đủ là full trong văn bản.

Các thí nghiệm cho thấy khả năng khám phá quan hệ ngầm định của phương pháp chúng
tôi vượt trội đáng kể so với các phương pháp tiên tiến khác trên KG không đầy đủ.
Mức độ cải thiện đáng kể, với mức tăng 43.7% so với KVMem trong hit@1. Hơn nữa,
mô hình cạnh tranh của chúng tôi cũng mang lại tỷ lệ hit@1 trung bình 1.7% trên
cài đặt 2-hop MetaQA half và hoạt động tốt trên cài đặt 3-hop MetaQA half trong
khi PullNet vẫn đạt được điểm số hit@1 cao nhất.

[Bảng 4 cho thấy kết quả thí nghiệm về lý luận trên KG không đầy đủ]

Do đó nhiều phương pháp baseline như GraftNet, PullNet yêu cầu các đồ thị con cụ
thể câu hỏi được xây dựng, chỉ ra rằng chúng thiếu khả năng recall các nút câu
trả lời ngoài đồ thị con được tạo ra của chúng và không thể hoạt động tốt trong
các tình huống QA thực tế. May mắn thay mô hình của chúng tôi, khai thác các thuộc
tính dự đoán liên kết KG, không giới hạn khả năng của nó do ràng buộc này. Mặc
dù những câu hỏi phức tạp trong WebQuestionsSP-tiny có thể dễ dàng được bao phủ
bởi các quy tắc thủ công, như nhiều câu đã có, mô hình của chúng tôi không phù hợp
với các quy tắc được xác định trước như vậy. Chúng tôi nghĩ điều quan trọng là sử
dụng khả năng lý luận tiên tiến hơn để tăng cường mô hình Rce-KGQA của chúng tôi
một cách chính xác, một nhiệm vụ mà chúng tôi để dành cho công việc tương lai.

5.6 Phân tích Kết quả Lọc Câu trả lời

Để kiểm tra thêm xem việc tăng cường được đề xuất của chúng tôi cho mô-đun bổ sung
Mô-đun Lý luận Chuỗi Quan hệ có cải thiện tiên tiến và rõ ràng hay không, chúng
tôi phân tích hiệu suất lý luận của mô-đun đầu tiên Mô-đun Lọc Câu trả lời và hiển
thị các phân phối câu trả lời với dự đoán trong Bảng 5. Trong Bảng 5, như chúng
ta có thể thấy rằng, nếu chúng ta coi các thực thể ứng viên được đánh điểm được
cung cấp bởi mô-đun này là câu trả lời cuối cùng, tỷ lệ độ chính xác hit@1 giảm
đáng kể so với hit@5 và hit@10. Quan sát này chỉ ra rằng mô hình không xem xét
thứ tự chuỗi quan hệ và loại quan hệ đạt được hiệu suất rất kém và chứng minh sự
cần thiết và ưu việt của mô-đun được đề xuất của chúng tôi, Mô-đun Lý luận Chuỗi
Quan hệ.

Hơn nữa, từ Bảng 5, chúng ta có thể quan sát rõ ràng rằng hầu như các câu trả lời
đúng của các tập dữ liệu được sử dụng của chúng tôi được phân phối chung trong
top-5 dự đoán của mô hình chúng tôi. Do tỷ lệ recall cao của mô-đun đầu tiên của
chúng tôi, Mô-đun Lọc Câu trả lời, chúng tôi nghĩ chúng ta chỉ có thể dựa vào một
vài ứng viên được đánh điểm cao nhất (như top-15, top-10, hoặc thậm chí top-5)
để lọc câu trả lời cuối cùng chính xác hơn. Vì vậy, trong các thí nghiệm huấn luyện
và suy luận mô hình của chúng tôi, chúng tôi đã thử một số sơ đồ thí nghiệm và xem
xét số lượng ứng viên được đánh điểm cao nhất cụ thể, cách chọn ứng viên để tự
động tạo ra các mẫu tích cực hoặc tiêu cực và cách cắt các ứng viên top-N cho suy
luận mô-đun con Mô-đun Lý luận Chuỗi Quan hệ. Chi tiết thí nghiệm liên quan được
hiển thị trong Mục 5.6.

[Bảng 5 cho thấy hiệu suất lý luận câu trả lời Mô-đun Lọc Câu trả lời của chúng
tôi trên ba thước đo khác nhau]

5.7 Phân tích Chiến lược Lọc Ứng viên

Giải pháp QA Rce-KGQA của chúng tôi là một hệ thống pipeline phức tạp, và chúng
tôi không thể tránh khỏi phải chọn một số siêu tham số quan trọng để có được một
mô hình tối ưu. Các tham số được xác định trước này bao gồm số lớp fully connected/LSTM,
tỷ lệ dropout, tỷ lệ học tập, vv. Như được minh họa trong Mục 5.6 và Bảng 5, các
chế độ lựa chọn khác nhau về ứng viên được đánh điểm cao nhất trong quá trình huấn
luyện và suy luận có tác động lớn đến hiệu suất mô hình cuối cùng. Bây giờ chúng
tôi điều tra thêm ảnh hưởng nào mà mô hình của chúng tôi sẽ trải qua trong chế
độ lựa chọn ứng viên khác nhau.

Đầu tiên, từ Bảng 5 chúng ta có thể quan sát thấy rằng bước đầu tiên 'lọc trả lời'
của chúng tôi nhất quán đạt được hiệu suất recall cao trên hit@5. Bây giờ chúng
tôi chọn thủ công và cắt-khác biệt các câu trả lời ứng viên được sắp xếp và tiến
hành các thí nghiệm so sánh của chúng tôi. Cụ thể, từ Mục 4.3 chúng ta biết rằng
tập dữ liệu cho việc huấn luyện Mô-đun Lý luận Chuỗi Quan hệ được xây dựng động
bởi bước cuối cùng. Và việc xây dựng dữ liệu tuân theo việc lựa chọn các thực thể
được đánh điểm sắp xếp top-N trong đó số N đồng thời quyết định tỷ lệ các mẫu
tích cực/tiêu cực và việc lựa chọn kết quả trung gian trong bước suy luận. Ví dụ,
trong câu hỏi Q, trong quá trình đánh giá mô hình, chúng tôi đầu tiên có được các
câu trả lời ứng viên đánh điểm trung gian {[Ai, Si]}Ni=1. Trong bước tiếp theo,
chúng tôi nên sử dụng Mô-đun Lý luận Chuỗi Quan hệ để cung cấp cho tất cả ứng
viên được lọc một điểm số chính xác hơn để đạt được câu trả lời cuối cùng. Việc
chọn bao nhiêu thực thể được đánh điểm cao nhất để tiến hành bước tiếp theo chính
xác trở thành điểm nghiên cứu trọng tâm của chúng tôi.

Chúng tôi chọn bốn chiến lược bao gồm top-{5, 10, 15, 20}; sau đó, từ các thí
nghiệm tương ứng, chúng tôi nhận được các kết quả sau được hiển thị trong Bảng
6. Từ kết quả thí nghiệm so sánh chúng ta thấy rõ rằng trong chiến lược lựa chọn
top-5, mô hình của chúng tôi đạt được hiệu suất hit@1 cao nhất và đạt được hiệu
suất cao thứ hai trong chiến lược top-10, trong cả tập dữ liệu 2-hop MetaQA và
3-hop MetaQA. Những hiện tượng này có thể đến từ hai khía cạnh. Đầu tiên, tỷ lệ
recall của mô-đun Mô-đun Lý luận Chuỗi Quan hệ đủ tốt cho việc sàng lọc tinh
tiếp theo và tỷ lệ mẫu tích cực/tiêu cực nên ở mức độ phù hợp. Ngoài ra, nhiều
ứng viên hơn trong bước suy luận mô hình có thể giới thiệu nhiều thực thể nhiễu
hơn có thể ảnh hưởng đến việc đánh giá câu trả lời của mô hình và giảm hiệu suất
mô hình tổng thể.

[Bảng 6 cho thấy thống kê hiệu suất cuối cùng của mô hình chúng tôi về tác động
của bốn chiến lược lựa chọn]

5.8 Nghiên cứu Loại bỏ

Để hiểu rõ hơn và có cái nhìn sâu sắc về thiết kế mô hình của chúng tôi, chúng tôi
cũng thực hiện các thí nghiệm loại bỏ để điều tra một cách có hệ thống tác động
và đóng góp của các thành phần khác nhau. RceKGQA-r, RceKGQA-a và RceKGQA-b
là các biến thể của mô hình đầy đủ của chúng tôi, RceKGQA. Lưu ý rằng, đối với
các thí nghiệm loại bỏ của chúng tôi, chúng tôi loại bỏ một thành phần mỗi lần.
Ở đây chúng tôi giới thiệu ngắn gọn các biến thể này cho các thí nghiệm loại bỏ.

• RceKGQA-r loại bỏ Mô-đun Lý luận Chuỗi Quan hệ và thực thể được đánh điểm cao
nhất được cung cấp bởi Mô-đun Lọc Câu trả lời làm câu trả lời cuối cùng.

• RceKGQA-a loại bỏ tất cả các hoạt động self-attention từ mô hình.

• RceKGQA-b thay thế RoBERTa bằng LSTM trong phần biểu diễn ngữ nghĩa câu hỏi
của Mô-đun Lý luận Chuỗi Quan hệ.

• RceKGQA là mô hình đầy đủ được giới thiệu trong bài báo này.

Trong phần này, các câu hỏi sau được trả lời:

Q1. Mô-đun Lý luận Chuỗi Quan hệ giúp độ chính xác lý luận của mô hình chúng
tôi bao nhiêu?

Q2. Cơ chế attention có thể thực sự giúp tăng hiệu suất tổng thể của mô hình chúng
tôi không?

Q3. Tính hiệu quả của phương pháp chúng tôi có do việc sử dụng RoBERTa trong Mô-đun
Lý luận Chuỗi Quan hệ không?

Theo kết quả so sánh giữa RceKGQA và biến thể RceKGQA-r của nó, chúng ta có thể
kết luận rõ ràng rằng việc loại bỏ Mô-đun Lý luận Chuỗi Quan hệ khỏi mô hình được
đề xuất có tác động lớn đến kết quả. Khoảng cách hiệu suất giữa RceKGQA-r được
hiển thị trong Hàng 2 và mô hình đầy đủ của chúng tôi như được hiển thị trong Hàng
1 chỉ ra rằng yếu tố chuỗi quan hệ ngữ nghĩa đóng vai trò then chốt trong lý luận
câu trả lời, kết hợp thứ tự chuỗi quan hệ và loại quan hệ để cung cấp câu trả lời
chính xác hơn cho người dùng cuối.

Như được hiển thị trong Hàng 3, khi mô hình đầy đủ của chúng tôi được so sánh với
RceKGQA-a, chúng ta có thể thấy mức giảm hiệu suất trung bình 3.5% trên thước đo
hit@1 nếu các thành phần self-attention bị loại bỏ, chứng minh tầm quan trọng của
cơ chế self-attention được sử dụng trong phương pháp của chúng tôi, vì nó hiệu quả
giúp dự đoán câu trả lời cuối cùng. Một lý do có thể là cơ chế self-attention có
thể phân biệt các tín hiệu liên quan và thú vị nhất từ thông tin nhiễu, và giúp
mô hình của chúng tôi hiểu rõ hơn ngữ nghĩa câu hỏi và chuỗi quan hệ.

RceKGQA-b, được hiển thị trong Hàng 4, chỉ mất 1.6% độ chính xác hit@1 so với
mô hình đầy đủ của chúng tôi, thay thế RoBERTa bằng BiLSTM, và chứng minh rằng
việc sử dụng transformer không phải là yếu tố chính trong việc tăng hiệu suất mô
hình tổng thể.

[Bảng 7 cho thấy kết quả nghiên cứu loại bỏ cho RceKGQA và ba biến thể của nó]

Các thống kê loại bỏ trên xác nhận rằng cả ba thành phần được giới thiệu để xử
lý nhiệm vụ trả lời câu hỏi quan hệ đa bước đều đóng góp vào hiệu suất mô hình tổng thể.

5.9 Nghiên cứu Trường hợp

Sự đổi mới chính của phương pháp chúng tôi nằm ở mạng lý luận chuỗi quan hệ được
giới thiệu. Ở đây, chúng tôi trình bày một nghiên cứu trường hợp để chứng minh
đóng góp của nó trong việc cải thiện kiến trúc mô hình tổng thể.

Như được hiển thị trong Hình 7, với câu hỏi, "Những bộ phim được phát hành vào
những năm nào có sự tham gia của các diễn viên xuất hiện trong bộ phim [Thunderbolt]?",
chuỗi lý luận quan hệ đúng được bảo tồn trong KG là Thunderbolt (movie) - starred
actors reverse → Stanley Holloway (actor) - starred actors → The Way Ahead (movie)
- release year → '1986'(year). Khi bỏ qua yếu tố đặc trưng chuỗi quan hệ và chỉ
sử dụng thực thể được đánh điểm cao được tạo ra bởi Mô-đun Lọc Câu trả lời làm
câu trả lời cuối cùng, mạng nhầm lẫn chọn một đường dẫn lý luận sai Thunderbolt
(movie) release year → '1991'(year) cho câu hỏi nói trên với xác suất rất cao 0.96
làm câu trả lời. Sự chú ý của nó chỉ tập trung vào quan hệ: release year, bỏ qua
các quan hệ lặp lại của starred actors và starred actors reverse. Ngược lại, mô
hình hoàn chỉnh xem xét yếu tố chuỗi quan hệ và sử dụng mạng lý luận chuỗi quan
hệ để lựa chọn tinh có thể dễ dàng và chính xác cung cấp câu trả lời đúng '1986'(year)
với xác suất cao 0.99 từ KG.

[Hình 7 cho thấy phân tích trường hợp từ tập dữ liệu 3-hop MetaQA]

Ví dụ này cho thấy rằng mạng lý luận chuỗi quan hệ của chúng tôi thực sự cung cấp
các tín hiệu giám sát rất hữu ích của nhận dạng chuỗi quan hệ ở các bước trung
gian để cải thiện hiệu suất QA tổng thể của mô hình chúng tôi.

6 Kết luận và Triển vọng Tương lai

Trong nghiên cứu này, chúng tôi giới thiệu một phương pháp pipeline tinh tế dựa
trên nhúng KG cho nhiệm vụ KGQA đa bước, được gọi là KGQA Nhúng dựa trên Chuỗi
Quan hệ. Các kỹ thuật mới được đề xuất để hiệu quả sử dụng phân tích chuỗi quan
hệ QA để xác định ngữ nghĩa chính xác hơn và tận dụng thông tin cấu trúc được bảo
tồn trong nhúng KG để lý luận câu trả lời ngầm định một cách gián tiếp. Kết quả
thực nghiệm toàn diện của chúng tôi trên ba bộ chuẩn chứng minh rằng phương pháp
của chúng tôi vượt trội hơn nhiều đối tác tiên tiến của nó. So sánh thí nghiệm giữa
phương pháp của chúng tôi và các biến thể loại bỏ của nó cũng xác minh rằng các
thành phần mô hình được đề xuất đóng góp vào kết quả lý luận câu trả lời. Chúng
tôi tin rằng KGQA sẽ tiếp tục là một hướng nghiên cứu hấp dẫn và đầy hứa hẹn với
các tình huống công nghiệp và gia đình thực tế, chẳng hạn như Đề xuất Thông minh,
Trợ lý Cá nhân Thông minh, Dịch vụ Khai thác Dữ liệu Lớn, và Dịch vụ Khách hàng
Tự động.

Trong tương lai, chúng tôi dự định nghiên cứu các vấn đề chính sau: (i) Để hỗ trợ
các tình huống ứng dụng động thực tế, ứng dụng KGQA luôn được cập nhật nhanh
chóng và không thể tránh khỏi việc tích lũy tri thức bên ngoài mới và khổng lồ
theo thời gian thực. Làm thế nào chúng ta có thể tăng cường dự trữ tri thức KG có
sẵn của chúng ta tự động và tăng dần để mở rộng phạm vi bao phủ tri thức của hệ
thống? (ii) Mô hình này được huấn luyện trên các tập dữ liệu QA tương đối nhỏ
dưới sự giám sát yếu mà không có tri thức tiên nghiệm bên ngoài. Làm thế nào chúng
ta có thể giới thiệu tri thức bên ngoài như tri thức từ các trang web và các KG
miền mở khác để cải thiện hiệu suất của hệ thống trả lời câu hỏi?

Theo các mẫu giải pháp phổ quát của nhiệm vụ KGQA, phương pháp được trình bày
trong bài báo này giả định rằng "Mô hình của chúng tôi sẽ luôn chọn một câu trả
lời tối ưu từ KG". Do đó, phương pháp dựa trên giả định này chắc chắn không phù
hợp cho trường hợp câu trả lời không tồn tại trong KG. Trong công việc tương lai,
chúng tôi sẽ thêm nghiên cứu về nhiệm vụ con "Phát hiện xem câu trả lời có tồn
tại trong KG hay không". Hơn nữa, Rce-KGQA được đề xuất của chúng tôi về cơ bản
là một cơ chế pipeline, có thể mang lại lan truyền sai lệch và hiệu suất kém. Trong
công việc tương lai, chúng tôi cũng sẽ tăng cường Rce-KGQA của chúng tôi bằng cách
tích hợp Mô-đun Lọc Câu trả lời và Mô-đun Lý luận Chuỗi Quan hệ riêng biệt lại
với nhau. Cụ thể, yếu tố chính cản trở việc mô hình hóa kết hợp là việc truy xuất
câu trả lời đa bước do mẫu lưu trữ có cấu trúc truyền thống của KG. Được truyền
cảm hứng từ Fabio et al. [67] chứng minh rằng các PLM khối lượng lớn có khả năng
lưu trữ tri thức đáng ngạc nhiên, chúng tôi sẽ cố gắng truyền tri thức KG vào các
PLM dựa trên Transformer, có thể giải quyết tốt khó khăn mô hình hóa thời trang
đầu cuối từ gốc.

Lời cảm ơn

Công việc này được hỗ trợ một phần bởi Chương trình Thượng Hải Yangfan (Mã dự
án: 22YF1413600), Kế hoạch Nghiên cứu Chính của Quỹ Khoa học Tự nhiên Quốc gia
Trung Quốc (Mã dự án: 92167102), và Các dự án Chuỗi Công nghiệp Chính của tỉnh
Shaanxi (Mã dự án: NO.2018ZDCXL-GY-04-03-02). Các tác giả muốn cảm ơn Guizhong
Liu và Ruiping Yin đã cung cấp các cuộc thảo luận và nhận xét hữu ích.

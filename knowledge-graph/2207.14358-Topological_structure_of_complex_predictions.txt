# 2207.14358.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/knowledge-graph/2207.14358.pdf
# File size: 32178369 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Topological structure of complex predictions
Meng Liu, Tamal K. Dey, David F. Gleich
Purdue University, Computer Science
Complex prediction models such as deep learning are the output from tting ma-
chine learning, neural networks, or AI models to a set of training data. These are now
standard tools in science. A key challenge with the current generation of models is that
they are highly parameterized, which makes describing and interpreting the prediction
strategies dicult. We use topological data analysis to transform these complex pre-
diction models into pictures representing a topological view. The result is a map of
the predictions that enables inspection. The methods scale up to large datasets across
dierent domains and enable us to detect labeling errors in training data, understand
generalization in image classication, and inspect predictions of likely pathogenic mu-
tations in the BRCA1 gene.
Overview and Central Results
Introduction Deep learning is a successful strategy where a highly parameterized model
makes human-like predictions across many elds [1, 9, 34, 45]. Yet challenges in generaliza-
tion may keep deep learning from use in practice [51, 30]. Detailed prediction mechanisms are
also dicult to assess directly due to the large collection of model parameters. Topological
methods of data analysis excel at distilling representation invariant information from large
datasets [41, 28, 21]. However, topological data analysis (TDA) of these complex predictive
models such as deep learning remains in its infancy [26, 3].
We construct a Reeb network to assess the prediction landscape of a neural network-
like prediction method (Figure 1 shows an example). Reeb networks are discretizations of
topological structures called Reeb spaces, which generalize Reeb graphs [7, 21].1Each node
of the Reeb network (Figure 1D) is a local simplication of the prediction space and is
computed as a cluster of datapoints with similar predictions. Reeb nodes are linked if they
share any datapoint or, in some cases, represent nearby datapoints.
This construction suggests that datapoints within a Reeb network node should have the
same prediction. Also, connected neighborhoods of the Reeb network should share predicted
values. When this scenario is violated (Figure 1E), such as at a prediction boundary or am-
biguous region in prediction space, it suggests a small set of points for further investigation.
Additional algorithmic analysis of the Reeb network and relationships between predictions
and training data can be used to diagnose estimated errors in the prediction function without
any access to ground truth information (Figure 1F, additional information in Section ยง1.5).
Existing topological techniques are limited in analyzing predictions.2
1The term network or net is often used to mean a graph abstraction of a complex system. A Reeb graph
is a topological structure that gives univariate topological information and produces a graph. A Reeb space
is a more complicated multidimensional structure. A Reeb network is an undirected graph like a Reeb graph,
and a Reeb network shows multidimensional topological information like a Reeb space. See Section ยง1.6.
2Section ยง3.6, Figure 17, Figure 5D.
1arXiv:2207.14358v3  [cs.LG]  20 Oct 2022

--- PAGE 2 ---
These Reeb networks identify and display information about the prediction function and
the associated datapoints relevant to understand those predictions. This makes it comparable
to other widely used visualization techniques such as tSNE [48], UMAP [2, 23], and nonlinear
dimension reduction [44], while providing greater information about the boundaries between
prediction and localizing informative relationships between training data and prediction.
The Reeb network construction on a prediction function Computing a Reeb net-
work for a complex prediction function or deep learning method has a few prerequisites.
There must be a large set of datapoints with unknown labels beyond those used for training
and validating the prediction model, which is common when gathering data is easy. There
must be known relationships among all datapoints such as (i) a given graph of relation-
ships among all points, (ii) a nearest neighbor computation to create such a graph, or (iii)
a domain-relevant means of clustering related points. All of our examples use (i) and (ii)
and in this case, nodes of the Reeb network are created via a parameter free connected
components analysis on subsets of the graph. Finally, there must be a real-valued guide to
each predicted value, such as the last layer of a neural network. Following the terminology
from Lum [21], these are called lenses (Figure 1C).
Constructing the Reeb net from these prerequisites involves two main choices: the maxi-
mum size of a Reeb node or cluster and the amount of overlap in Reeb nodes.3We employ
a recursive splitting and merging procedure called GTDA (graph based TDA) to build the
Reeb net from the original datapoints and graph. This uses the lenses to identify datapoints
with similar predictions and splits them into overlapping regions.4Overlap is needed to
use the connection strategy among nodes of the Reeb network. At each step, the data are
clustered by computing connected components of the graph of relationships and the analysis
proceeds iteratively for newly created components until they are smaller than the selected
maximum size. Each remaining cluster constitutes a node of the Reeb net. Nodes of the
Reeb network are connected if they share any datapoint. This connection strategy may leave
many nodes isolated, which is not helpful to understand predictions. We reduce this isolation
by adding edges from a minimum spanning tree.5Useful results arise from a wide range of
parameters.6
Constructing a Reeb net is a scalable operation: analyzing 1.3 million images in Ima-
geNet [36] with 2000 lenses for 1000 classes in a comparison of ResNet [12] and AlexNet [18]
takes 7.24 hours.7
Demonstration in Graph-based prediction We apply the Reeb net framework to a
graph neural network that predicts the type of product on Amazon based on reviews. This
framework identies a key ambiguity in product categories that limits prediction accuracy
(Figure 2). Specically, \Networking Products" and \Routers" overlap (a Router is a specic
type of Network Product) and show high levels of confusion as do \Data Storage" and
3Other parameters are less inuential. See Table 1.
4We found it helpful to rst smooth the information from the lenses over the relationship graph to avoid
sharp gradients using 5 or 10 steps of an iterative smoothing procedure related to a diusion.
5Full algorithm in Section ยง1.3.
6Further discussion of parameter sensitivity is in Section ยง7.
7Table 8 for additional runtime information.
2

--- PAGE 3 ---
Figure 1: Consider a prediction scenario with three classes in a Swiss roll structure and an underlying graph (A).
Graph neural network predictions show reasonable accuracy (B). The 3-dimensional prediction lens from the
neural network is shown in (C) and gives a guide to class predictions. The Reeb network is shown in (D). Each
node maps to a small cluster of similar values of the lens. Nodes are colored by the fraction of points in each
predicted class. Regions with mixed predictions indicate potential ambiguities in the results. Further study of
two such connected regions (E) shows many datapoints where there are training points with dierent labels
closer to the given test points. This situation motivates an algorithmic error estimate for each datapoint without
ground truth (F). This estimate is nevertheless highly correlated with true errors and better than class
uncertainty estimates. The topological simplication highlights datapoints with confusing or ambiguous
predictions given the totality of predictions.
3

--- PAGE 4 ---
\Computer Components" (an internal data storage drive is a computer component). These
results suggest that large improvements are unlikely with better algorithms and would require
label improvements to dierentiate categories or other divisions in a hierarchy [52]. This was
veried by checking another graph neural network [5] with similar behavior.8
Understanding image predictions When the framework is applied to a pretrained
ResNet50 model [12] on the Imagnette dataset [13], then it produces a visual taxonomy
of images suggesting what ResNet50 is using to categorize the images (Figure 3). This ex-
ample also highlights a region where the ground truth labels of the datapoints are incorrect
and cars are erroneously labeled as \cassette player".9
Understanding Malignant Gene Mutation Predictions Reeb networks from a pro-
posed DNA prediction method [1], when applied to the BRCA1 gene, show Reeb components
that are localized in the DNA sequence and also that these components map to secondary
structures, e.g., in the 1JNX repeat region, that aid interpretation. For one of the helix struc-
tures, this analysis shows regions where insertions and deletions are harmful (pathogenic)
and single nucleotide variants lack evidence of harm. In an analysis of a component with
many harmful predictions, these results show that places where the framework incorrectly
predicts errors are strongly associated with insignicant results in the underlying data.
Additional examples Two additional studies show how the Reeb nets nd incorrect
diagnostic annotations in chest x-rays datasets used for deep learning [49] (AUC 0.75, details
in Section ยง6) and help compare deep learning predictions from ResNet [12], AlexNet [18],
and VOLO-50 [50], showing the importance of image backgrounds or partial objects to
improvements over AlexNet (Section ยง4).
Related work Our Reeb network construction extends recent analytical methods from
topology [21, 41] to facilitate applications to the topology of complex prediction. Prior work
on analyzing deep learning methods for errors focuses on a single result list [17], without
the associated topological structure provided by Reeb nets. Our work relates to inter-
pretability [24] and seeks to produce a comprehensible map of the prediction structure to aid
navigation of a large space of prediction to those most interesting areas. Beyond identifying
that there is a problem, the insights from the topology suggest relationships to nearby data
and thereby suggest mechanisms that could be addressed through future improvements.
Conclusion Considering the ability of these topological inspection techniques to translate
prediction models into actionable human level insights { from label issues to protein structure
{ we expect them to be applicable to new models and predictions, broadly, as they are created
and to be a critical early diagnostic of prediction models. The interaction of topology and
prediction may provide a fertile ground for future improvements in prediction methods.
8Section ยง2.
9We conjecture a car labeled as \cassette tape" may be due to images of cars listed for sale including the
string \cassette tape player."
4

--- PAGE 5 ---
Figure 2: Reeb network of a standard 2-layer graph convolutional network model trained and validated on 10%
labels of an Amazon co-purchase dataset (A) and estimated errors shown in red (B). The map highlights
ambiguity between \Networking Products" and \Routers". Checking these products shows wireless access
points, repeaters or modems as likely ambiguities (C). Additional label ambiguities involve \Networking
Products" and \Computer Components" regarding network adapters (D); likewise \Data Storage" and
\Computer Components" are ambiguous for internal hard drives (E). These ndings suggest that the prediction
quality is limited by arbitrary subgroups in the data, which Reeb networks helped locate quickly.
5

--- PAGE 6 ---
Figure 3: We take a pretrained ResNet50 model and retrain the last layer to predict 10 classes in Imagnette (A).
In (B), we zoom into the Reeb network group of \gas pump" predictions and display images at dierent local
regions (C). This shows gas pump images with distinct visual features. Examining these subgroups can provide a
general idea on how the model will behave when predicting future images with similar features as well as help us
quickly identify potential labeling issues in the dataset. For instance, we nd a group of images in (D) whose
true labels are \cassette player" even though they are really images of \cars".
6

--- PAGE 7 ---
Figure 4: We use Reeb networks to visualize harmful (likely pathogenic) and potentially non-harmful (no
evidence of pathogenicity) predictions of gene variants in BRCA1. The topology indicates several secondary
structures on part of the protein (1JNX) as shown in (A). We further check the model predictions on variants
targeting one secondary structure (B). Our error estimate shows a number of likely erroneous predictions, and
we ip these expected errors (a nal analysis showed these errors were correctly identied). We continue to see
variants with distinct prediction in a small region of a few amino acids. Close examination shows a strong
association between mutation types and model predictions where deletion or insertion is more likely to be
harmful than a single nucleotide variant. Additional insights when using the full label set show some estimated
errors are completely wrong (C). These prediction mistakes involve gene mutation experiments with insignicant
or conicting results and indicate underlying uncertainty.
7

--- PAGE 8 ---
Detailed Discussion And Description of GTDA
ยง1 { Our GTDA method for Reeb nets &prediction functions {8
ยง2 { Demonstration in graph based prediction {20
ยง3 { Understanding image predictions {22
ยง4 { Comparing models on ImageNet-1k predictions {32
ยง5 { Understanding Malignant Gene Mutation Predictions {39
ยง6 { Inspecting chest X-ray images {50
ยง7 { Parameter selection of GTDA {52
ยง8 { Performance and scaling {54
ยง9 { Comparing to tSNE and UMAP {55
ยง10 { Code availability {57
ยง1 Our GTDA method for Reeb nets &prediction functions
In this paper, we developed a framework to inspect the predictions of complex models by
visualizing the interactions between predictions and data. The framework has the following
properties:
โขit can produce a topological view of the original dataset through pictures
โขthe visualization can provide clues for any sample of interest to be inspected
โขit is highly scalable and can process large datasets with thousands of classes
โขit can provide intuitive insights and suggest places that are worth a further study for
users without any prior knowledge on the model or the data
ยง1.1 Background: Topological Data Analysis and the Mapper Algorithm
Our method is rooted in the growing eld of computational topology and topological data
analysis and the framework is closely related to the mapper algorithm [41] for topological
data analysis (TDA). Mapper builds a discrete approximation of a Reeb graph or Reeb
space (see Section ยง1.6, Figure 7). It begins with a set of datapoints ( x1;:::;x n), along
with a single or multi-valued function sampled at each datapoint. The set of all these values
ff1;:::;f ngsamples a map f:X!Rkon a topological space X. The map fis called
alter orlens. The idea is that when fis single valued, a Reeb graph shows a quotient
topology of Xwith respect to fand mapper discretizes this Reeb graph using the sampled
values offon pointsx1;:::;x n. Algorithmically, mapper consists of the steps:
โขSort the values fiand split them into overlapping bins B1;:::;B rof the same size.
โขFor each bin of values Bj, letSjdenote the set of datapoints with that same value
and cluster the datapoints in each Sjindependently. (That is, we run a clustering
algorithm on each Sjas if it was the entire dataset.)
8

--- PAGE 9 ---
โขFor each cluster found in the previous step, create a node in the Reeb graph.
โขConnect nodes of the Reeb graph if the clusters they represent share a common point.
The resulting graph is a discrete approximation of the Reeb graph and represents a
compressed view of the shape underlying the original dataset.
Our goal is to extract a similar type of topological description for lenses that are multi-
valued, which we interpret as a collection of single-valued lenses.
ยง1.2 Rationale for a graph-based method
The input format for mapper is usually a point cloud in a high dimensional space where
the point coordinates are used only in the clustering step.
In our methodology, we are interested in datasets that are even more general. Graph
inputs provide this generality. Datasets not in graph format like images or DNA sequences
can be easily transformed into graphs by rst extracting intermediate outputs of the model
as embeddings and then building a nearest neighbor graph from the embedding matrix.
Then the resulting graph facilitates easy clustering: for each subset of points, we extract
the subgraph induced by those points and then use a parameter-free connected components
analysis to generate clusters.
Our method could also work with point cloud data and clustering directly through stan-
dard relationships between graph-based algorithms and point cloud-based algorithms. We
focus on the graph-based approach for simplicity and because we found it the most helpful
for these applications.
ยง1.3 The Reeb network construction on a prediction function using a graph
(GTDA)
We take as input:
1. ann-node graph G
2. a set ofmlenses based on a prediction model as an nmmatrix P
The lenses we use are the prediction matrix Pof a model where Pijis the probability
that sample ibelongs to class j. Key dierences from existing studies of TDA frameworks
on graphs include using the connected components of each bin [3, 11] as clusters and also
additional steps to improve the analysis of prediction functions by adding weak connections
from a minimum spanning tree.
Problems with straightforward algorithmic adaptation. Mapper does extend to
multidimensional lens functions by using a tensor product bin construction. We found issues
with a straightforward adaptation of mapper to such multidimensional input for prediction
functions. In our extensive trials, we found that most of the resulting Reeb networks end up
with too many tiny components or even singletons where no prediction-specic insights were
possible. This is especially so when the dataset has many classes, most multi-dimensional
bins will just contain very few samples because the space grows exponentially, limiting the
9

--- PAGE 10 ---
potential of overlap to nd relationships. Simply reducing the dimension of Pwith PCA
will lose the interpretability of the lens. Moreover, classic mapper uses a xed bin size and
density-based or multi-scale alternatives [7] were unsuccessful in our investigations although
they solve this problem from a theoretical perspective. (We note this is a potential area for
followup work to better understand why.)
Preprocessing to smooth the predictions. As a preprocessing step, we apply a few
steps (usually four or ve) of the smoothing iteration: P(i+1)= (1 )P+D 1AP(i). Here
P(0)=P,Ais the adjacency matrix of the input graph, Dis the diagonal degree matrix
and 0<< 1. This helps to prevent prevent sharp changes between adjacent nodes. This
equation is a diusion-like equation closely related to the PageRank vector that is known to
smooth data over graphs and has many uses [10]. The iteration keeps all the prediction data
non-negative and the smoothed Pwill also be min-max column normalized so that each
value is between 0 and 1. As is standard, this setup can use any weights associated with the
adjacency matrix, or remove them and use an unweighted graph.
Our graph-based construction for a prediction function. The following approach
was used for datasets in the main paper. We call this a graph-based topological data analysis
framework (GTDA). It uses a recursive splitting strategy to build the bins in the multidi-
mensional space. For each subgroup of data, the idea is that we nd the lens that has the
maximum dierence on those data. Then split the component by putting nodes into two
approximately equal sized overlapping bins based on the values in this lens. Then if the
resulting groups are big enough, we add them back as sets to consider splitting.
Detailed pseudo code can be found in Algorithm 1. We give a quick outline here. The
recursive splitting starts with the set of connected components in the input graph. This is a
set of sets: S. The key step is when the algorithm takes a set SifromS, it splits Siinto new
(possibly) overlapping sets T1;:::;Thbased on the lens with maximum dierence in value
onSiand also connected components. Each Tiis then either added Sif it is large enough
(with more than Kvertices) and where there exists a lens with maximum dierence larger
thand. Otherwise, Tigoes into the set of nalized sets F.
Once we have the nal set of sets, F, then we do have two nal merging steps, along with
building the Reeb net. The rst is to merge sets in Fif they are too small (Algorithm 2).
The second is to add edges to the Reeb net to promote more connectivity (Algorithm 3).
In the rst merging (Algorithm 2), which occurs before the Reeb net is constructed, we
check and see if any set in Fis too small (smaller or equal to s1). If so, then we nd nearby
nodes based on the input graph Gand based on a user-provided distance measure fand
merge the small component with the closest component (giving preference to the smallest
possible set to merge into). This could be a simple graph-distance measure (e.g. shortest
path), something suggested by the domain, or a weight based on the prediction values (what
we use). The algorithm is closely related to Bor uvka's algorithm for a minimum spanning
tree.
Next, we build the Reeb net ^Gfrom this set of sets F. Each group Fibecomes a node,
and nodes are connected if they share any vertex.
In the second merging (Algorithm 3) we seek to improve the overall connectivity of
10

--- PAGE 11 ---
the Reeb net by connecting small disconnected pieces of the Reeb net ^G. This step is
designed to enhance the ability to work with predictions by adding weaker connections to
the more strongly connected topological pieces. It uses the same distance measure fto nd
components and uses a similar Bor uvka-like strategy. We save the set of edges added at this
step to study in the error estimation procedures noted below.
Choices for the parameters. As a result, GTDA has 8 parameters as in Table 1. Tuning
of the parameters is straightforward, and we often use the default choice or values from a
small set. The values K,dands1provide direct control about the number of nodes in the
nal group visualization, while rands2control how connected we want the visualization to
be. In practice, we could rst tune Kanddto determine the number of nodes, then tune r
so that no component in the Reeb net is too large and nally tune s1,s2to remove any tiny
nodes or components. We leave the smoothing parameters xed at = 0:5 andS= 5 or 10
(very smooth). A detailed discussion on these parameters can be found in Section ยง7.
Choice of distance function for merging Possibly the hardest parameter to pick is the
merging function f. The user can choose any distance metric fin the merging step, in our
experiments, we use `1norm of the dierence between rows of the preprocessed Pas the
distance between 2 samples, which roughly means how much larger the bin containing one
of those 2 samples should be in order to include the other sample. Put another way, this
choice makes us less sensitive to the exact choice for rbecause we will add small connections
that would have been included in a slightly larger bin.
Drawing the graph. Unless otherwise specied, all coordinates of any layout we show
are computed with Kamada-Kawai algorithm [16].
Showing the Reeb network and explorations. In the Reeb net of a prediction function,
we draw each node as a small pie-chart. The size of the pie-chart represents the number of
nodes. The pieces of the pie show the local prediction distribution. In some cases, we nd it
useful to study the predicted labels directly, such as when studying mechanisms underlying
the prediction. In other cases, we nd it useful to study predictions and training data, such
as when studying possible errors. These visualizations facilitate exploring regions of the
prediction landscape based on interactions among predicted values and training data. By
mapping these small regions back to the original data, it suggests what the model is utilizing
to make the predictions. Examples on this can be found in the experiments in the main text
as well as in the supplemental information.
ยง1.4 Demonstration of GTDA
We use a 3 class Swiss roll dataset to demonstrate each step of our GTDA framework
(plot (A) of gure 5). For the GTDA parameters, we set K= 20,d= 0,r= 0:1,s1= 5,
s2= 5,= 0:5, andS= 5. In (B), we show the three prediction lenses we use in the
top plot as well as the predicted labels of the model we use. We also add additional edges
based on nearest neighbors from node embeddings to take node features into account. This
11

--- PAGE 12 ---
parameter description suggested choices
Kcomponent size threshold to stop splitting 5% of smallest class size
dlens dierence threshold to stop splitting 0 or 0.001
roverlapping ratio 0.01
s1Reeb node size threshold 5
s2Reeb component size threshold 5
lens smoothing parameter 0.5 (used in all experiments)
Slens smoothing steps 5 or 10
fdistance function in the merging step `1dierence of row i,jofP(S)
Table 1: List of parameters in GTDA.
is standard practice in graph neural network methods. Details on the dataset and the model
can be found in Section ยง1.8. Each lens is just the prediction probability of a class after
smoothing and normalization. In (C), we pick the lens with the largest min-max dierence
and split it into 2 bins with 10% overlap (we pick the one with smaller index to break ties).
This round of splitting nds 2 components. For each component found in the rst iteration,
we pick the lens with the largest min-max dierence and split it again. In this case, the
inner component is split along lens 3 while the outer component is split along lens 2. This
round of splitting further divides the graph into 7 components. We repeat the splitting until
no component has more than 20 vertices of the original graph.
In the end, we nd 247 unique components. As noted above, we use a pie chart to
represent each Reeb node and connect Reeb nodes with black lines if they have any samples
in common to get the initial Reeb net, (D). Node size is proportional to the number of
samples it represents, the pie chart shows the distribution over predicted values. This initial
Reeb net has many tiny components or even singletons that are a barrier to deeper insights;
the merging steps address this issue. In (E), we use red dashed lines to mark how we will
merge those small Reeb nodes so that all nodes will contain more than 5 samples. Similarly,
we use red dashed lines to mark extra edges that will be added so that each connected
component in the Reeb net will contain more than 5 Reeb nodes. The nal Reeb net is
shown in (F) with the original graph embedded in the background. We can see that all
important structures found in (D) are also preserved in (F) such as the mixing of nodes from
dierent classes. And what merging does is to estimate how the tiny nodes and components
are connected in the original graph or via the prediction lens so that we have a clear view
of predictions over the entire dataset. This supports an inspection of the model's prediction
on any sample we want.
As a comparison, in plot (G), we show two Reeb nets that are constructed by the original
mapper algorithm with dierent number of bins along each lens. These Reeb nets are not
useful to understand the prediction structure. Most samples from the green class are grouped
into a few nodes because prediction probability distribution on this class is more skewed,
which makes the inspection hard.
12

--- PAGE 13 ---
Figure 5: A detailed illustration of applying GTDA to build a Reeb net on a 3-class Swiss roll dataset. The
original data graph and \ground truth" values are in (A). We show the model prediction for a simple GCN and
the three prediction lenses (after smoothing) in (B). The rst splitting iteration over lens 1 nds 2 components,
(C). At the second split, for each component, we choose the lens with the largest dierence, which means the
outer ring is split over lens 2 and the inner ring is split over lens 3. The second splitting nds 7 components in
total. We continue to split until no more components larger than 20 and get the initial Reeb net, (D). Then
small nodes are merged to neighbors iteratively as shown by the red dashed lines in (E). Similarly, small
components in the Reeb net are iteratively connected to get the nal Reeb net in (F). As a comparison, two
Reeb nets from the original mapper using 10 lens or 5 lens have many isolated nodes or components and are not
suitable for the subsequent inspection. The gure (F) uses predicted classes for training and validation points
instead of the actual training and validation classes as in g. 1(D).
13

--- PAGE 14 ---
Algorithm 1 GTDA (G;P;K;d;r;s 1;s2;;S; f) See Table 1 for parameters description
1:Smooth PforSsteps with P(i+1)= (1 )P+D 1AP(i)andP(0)=P
2:Perform a min-max normalization along each column of P
3:Find connected components in Gand put all components with size larger than Kand
maximum lens dierence larger than dinS, otherwise in F
4:while Sis not empty do
5: LetS(iter)be a copy of S
6:foreachSiinS(iter)do
7: Remove SifromS
8: Find column ci(for a lens) such that P(S)[Si;ci] has the largest min-max dierence
9: Split interval [min( P[Si;ci]);max(P(S)[Si;ci])] into two halves of the same length
and extend the left half by a ratio of rto give overlapping groups R1andR2based
on which vertices had values in the left and right parts of the interval.
10: Create sets T1;:::;Thbased on the connected components in R1;R2.
11: foreachTido
12: If there are more than Kvertices in Tiand if there is a lens with a maximum
dierence larger than d, then add TitoS. Otherwise, add TitoF.
13: end for
14: end for
15:end while
16:Run node-merging (F;G;s 1;f) to get the updated F
17:Generate Reeb net ^Gby considering each component of Fas a Reeb net node and
connecting two Reeb net nodes if their corresponding components have overlap
18:Run component-merging (F;G;^G;s 2;f) to get the updated ^Gand the extra set of edges
E
19:Return ^G,E
ยง1.5 Error estimation of GTDA
The model often highlights places where there is no reasonable basis for a prediction,
e.g. where there is training data with a dierent label closer to a prediction. This scenario
admits an estimate where the model will likely make mistakes by checking the relative
locations between predictions and training data.
Using the Swiss roll example, in plot (A) of gure 6, we zoom in on two components
GTDA. We then look at the induced subgraph of this region in a projection of the Reeb
network. The Reeb network projection expands each Reeb node into the original set of
input vertices with duplicated nodes merged and also adds in edges that we put into study
predictions (the extra set Ein the algorithms). A detailed projection procedure can be found
in Algorithm 5.
Put formally: Given a set of Reeb network nodes in ^G, nd the union of all vertices
inGthese nodes represent and call that T. We look at the induced subgraph of Tin the
projection of the ^Gfrom Algorithm 5.
To show these induced subgraphs, we can either use Kamada Kawai layout or, as an
alternative to Kamada Kawai, we can also compute coordinates for each projected Reeb
14

--- PAGE 15 ---
Algorithm 2 node-merging (F;G;s 1;f)
1:while there exists components in Fwith at most s1vertices do
2: SetCto be empty.
3:foreach component FiinFwherejFijs1do
4: for each edge ( vi;vj) inGwherevi2Fiandvj2Fj6=Fi, compute f(vi;vj)
5: Select the pair of nodes vi,vjwith the smallest f(vi;vj). Let Fjbe the set associated
withvjand choose the smallest size Fjifvjis in multiple such sets. Add ( Fi;Fj) to
C.
6:end for
7: View the choices in Cas edges of an undirected graph Hwhere vertices are Fi.
8: Compute connected components of H.
9:foreach connected component HiofHof size larger than 1 do
10: LetF1;:::;Fhbe the underlying sets of HifromF. Remove each FifromF. Then
addF1[:::[FhtoF.
11: end for
12:end while
13:Return the updated F
Algorithm 3 component-merging (F;G;^G;s 2;f)
1:Initialize the set of extra edges Eto be empty
2:Compute connected components of Reeb net ^G
3:LetDbe the set of connected components of ^G.
4:while there exists any Di2Dwhere Dihas at most s2Reeb nodes do
5:foreachDi2Dwhere Dihas at most s2Reeb nodes do
6: LetCbe the union of vertices in G(not ^G) for Reeb nodes in Di.
7: For each edge ( vi;vj)2Gwherevi2Candvj62C, computef(vi;vj).
8: Select the pair of nodes vi,vjwith the smallest f(vi;vj). Let FiandFjbe the Reeb
nodes associated with viandvjand choose the smallest size Fjifvjis in multiple
such sets. Pick an arbitrary Fi(we used smallest index in our data structure) if Fi
in multiple such sets.
9: Add (Fi;Fj) toE.
10: Connect the Reeb nodes for Fi;Fjin^G
11: end for
12: Recompute connected components analysis of ^Gand update D
13:end while
14:Return ^GandE
node and then combine dierent layouts using their relative coordinates in Reeb net.
Then we use red circles to mark training and validation data and color them with the
true labels. Unknown data points are still colored with predicted labels.
One can immediately notice the problem: There are some orange predictions in the grey
box, but there is no orange training or validation data nearby to support them. Thus, either
the model or the dataset itself have issues with these prediction and merit a second look. In
15

--- PAGE 16 ---
Algorithm 4 error estimation (^G;E;`;n; ) where ^GandEis the Reeb net and extra set
of edges from algorithm 1, `are the original predicted labels, Sis an integer for the number
of steps (10, or 20 were used), and 0 << 1 (we use= 0:5 in all experiments).
1:ComputeG(R), the projection of the Reeb net back to a graph from Algorithm 5.
2:LetA(R)be the adjacency matrix of G(R)
3:Compute a diagonal matrix D(R)whereD(R)
iiis the degree of node iinG(R)and 0
elsewhere.
4:Initialize matrix ^P(0)where ^P(0)
ij= 1 i node iis a training node with label j, otherwise
^P(0)
ij= 0.
5:fori= 1:::Sdo
6: ^P(i)= (1 )^P(0)+D(R) 1A(R)^P(i 1)
7:end for
8:Row normalize ^P(S)so that each row sums to 1.
9:Compute estimated prediction error for node ito beei= 1 ^P(S)[i;`i]
10:Return estimated errors e.
this case, it is just the model that cannot classify some parts of the graph correctly due to
noisy links.
We developed an intuitive algorithm to automatically highlights which parts of the visu-
alization will likely contain prediction errors, Algorithm 4. The core part of this algorithm is
to perform a few steps of random walk starting from nodes with known labels. Predictions
that are close to training data with the same labels in the Reeb net will have higher scores
in the column of predicted labels and hence have smaller error estimates.
Applying this algorithm can successfully nd other places where mistakes will happen
(see plot (B) of gure 6). As a simple comparison, we also include another plot where we
directly use model uncertainty (i.e. 1 minus model prediction probability) to estimate errors
(see plot (C) of gure 6). This metric has been previously used to estimate uncertainty of
dataset labels [29]. Clearly, GTDA is able to localize model errors much better and has
a higher AUC score (0.95 vs 0.87). There always exists other methods [15] that can also
give similar error estimations or even correct predicted labels. But explaining why those
methods should work or be trusted to a user without background knowledge is a challenge,
while our method oers a map-like justication that can give a rough rationale. Moreover,
any results from Algorithm 4 can always be validated and supported through pictures similar
to plot (A) of gure 6. Also, other than nding possible errors, as shown in the following
experiments sections, we can often get many other insights about the model and the dataset
by checking abnormal areas of GTDA visualization, ranging from labeling issues to strong
correlation between model predictions and a particular dataset property. These are explored
in subsequent case studies.
ยง1.6 Reeb graph vs. Reeb space vs. Reeb network
The main dierence between a Reeb graph and Reeb network is the number of lenses used
because the Reeb net involves a multivalued map which can be thought of as a collection of
single valued maps. A demonstration to show this dierence can be found in Figure 7.
16

--- PAGE 17 ---
Figure 6: This gure demonstrates the procedure of estimating errors from the Reeb net produced by GTDA. In
comparison with Figure 5, we show the training data labels in the pie charts instead of the predicted values. If
we zoom in on two components and mark training and validation samples (red circles) with true labels, we see
many orange predictions without any training or validation data nearby to support them (inset box nearby) (A),
which suggests potential errors { note that the model may be using additional features to predict these values,
but these examples do merit closer inspection. We develop an error estimation procedure in Algorithm 4 to
automate this inspection. Overall, GTDA estimated errors have a AUC score of 0.95 with true errors (B), while
using model uncertainty (one minus prediction probability) only has a AUC score of 0.87 (C).
17

--- PAGE 18 ---
Figure 7: This illustrates the dierence between a Reeb graph and a Reeb network on a topologically interesting
object. The lenses we use here are the xandzcoordinates. The inspiration for the object is [43].
18

--- PAGE 19 ---
Algorithm 5 Reeb-graph-projection (F;E;G) where F,Eis the nal set of components
and extra set of edges from Algorithm 1 and Gis the original graph
1:InitializeG(R)with the same dimension of Gand no edges
2:forEachFiofFdo
3: Add the set of edges of FifromGtoG(R)
4:end for
5:Add edges in EtoG(R)
6:ReturnG(R)
Formally, let f:X!Rkmap a topological space Xto ak-dimensional real space. Two
pointsx;y2Xare called equivalent if (i) f(x) =f(y) and (ii) they belong to the same
connected component of the level set f 1(f(x)). Denoting this equivalence relation with ,
we obtain the quotient space Rf
X=X=. When the range of fisR,Rf
Xis a one-dimensional
space called the Reeb graph of f. Whenfis multi-valued, that is, k > 1,Rf
Xbecomes a
space called Reeb space. By choosing the bins in Rk, we discretize this Reeb space with a
graph which we call the Reeb net here. We choose the term Reeb net to distinguish it from
discretized Reeb graph because both are graphs but one discretizes a one-dimensional space
(a graph) and the other discretizes a quotient space that need not be one-dimensional.
ยง1.7 Opportunities and extensions of the method
We presented the GTDA framework for the main methods we used. In the following
case studies and demonstrations, we show there are multiple variations that would be easy
to adapt. For instance, we could easily combine multiple graphs from dierent sources to
reveal potential errors that might hidden in a single source.
Areas for future improvement. Our current GTDA framework does rely on some tuning
of parameters and manually nding any interesting local structures in the visualization,
especially the component size threshold, which behaves similarly to bin size in the original
TDA algorithm. While we designed the algorithm to be as robust as possible, it remains
an open question on whether we can automatically select a good set of parameters and
identify structures worth looking at. Existing work selects parameters for the original TDA
framework based on statistical analysis [4]. But it is not clear how to extend such technique
to our GTDA framework.
Areas for additional topology. Another direction is to study the outputs of GTDA
under perturbations or ltrations over parameters. Alternatively, there are opportunities to
utilize additional topological insights to improve the graph drawing. Consider that a study
of persistence of structures in the graph should suggest their placement, i.e. two components
that will be connected more easily by perturbing parameters should be put closer. This can
then lead to a better overall view of the entire dataset.
19

--- PAGE 20 ---
ยง1.8 Other details
Swiss Roll dataset construction We use scikit-learn package to build the Swiss Roll
dataset. We use 1000 samples in total and the noise parameter is set to be 1.2. The initial
Swiss Roll dataset is a 1000-by-3 matrix Xand a vector ywhich represents the position of
each sample in the main dimension of the manifold. We only keep the rst and the third
columns of Xand use them as node features. And we sort samples based on yand consider
the rst 33% samples as the rst class, the second 33% samples as the second class and all
the other samples as the third class. The graph is a nearest neighbor graph with each node
connecting to its 5 closest neighbors using Euclidean metric on X. We use a random set of
use 10% samples as training, another 10% samples as validation and all the other points as
testing.
Model and parameters We use a standard 2-layer GCN model to predict labels of testing
samples. The dimension of the hidden layer is 64, learning rate is 0.01 and weight decay is
10 5. Once the model is trained, we use outputs of the rst layer as node embeddings. The
embedding matrix is reduced to 16 dimension using PCA with whitening and then each row
is`2normalized. We build another 2-NN graph using the preprocessed embedding matrix
and cosine similarity to encode any information from node features. This graph is combined
with the original graph. GTDA framework is then applied on the combined graph. For
GTDA parameters, we set K= 20,d= 0,r= 0:1,s1= 5,s2= 5,= 0:5 andS= 5. We
use 10 steps of iterations for GTDA error estimation.
Alternative neural networks. We note that we saw similar results using the GNN meth-
ods from [5]. We include discussions and images with this alternative method for the Amazon
dataset (next section) to evaluate our statement from the main text about the taxonomy.
ยง2 Demonstration in graph based prediction
In this section, we provide more details for the application of our GTDA framework on
an Amazon co-purchase graph [38] constructed from Amazon reviews data [22]. Each node
in this graph is a product, edges connect products that are purchased together and node
features are bag-of-words from product reviews. The goal is to predict product category. The
original dataset [38] that has been used in several GNN papers does not have information
for each specic product. To better understand the visualization from GTDA, we build a
similar dataset directly from the Amazon reviews data [22]. We use the 2014 year version
of reviews data and extract products with the same set of labels as in the original [38]. In
the remainder of this section, we will work through how the dataset is constructed and the
GCN model parameters that are used in the main text. We will also provide GTDA results
on another more recent GNN model, GPRGNN [5], that is based on spectral theory. We
will inspect this model's prediction on both the customized dataset and the original dataset.
We will see later in this section that the same conclusions as Figure 2 of the main text still
hold even after switching to the new model.
20

--- PAGE 21 ---
category number
Desktops 1,757
Data Storage 7,297
Laptops 4,590
Monitors 1,710
Computer Components 15,167
Video Projectors 804
Routers 1,086
Tablets 1,919
Networking Products 4,869
Webcams 548
Table 2: Number of products for each category in our own version of Amazon Computers dataset.
ยง2.1 Dataset and GNN model
Our own version of the Amazon co-purchase graph has the same set of the labels as the
original one [38]. We download all products and reviews in the category of \Electronics"
by following the link provided in [22]. We use the 2014 version as we can nd the exact
same set of labels in this version. In the Amazon reviews dataset, each product is associated
with a list of categories. To assign labels, for each product, we check from the most general
category (i.e. Electronics) to the most specic one (i.e. Routers). And if we nd a match to
the set of labels we choose, we directly assign the matched label to that product and ignore
the other categories in the list. Two products will be connected if they are marked as \also
bought", \bought together" or \buy after viewing". After we get the initial graph, we rst
make the graph undirected and then lter out components that are smaller than 100. We use
bag-of-words node features with TF-IDF term weighting constructed from each product's
review text. The nal graph we get has 39,747 products and 798,820 edges. The number of
products for each category is listed in table 2.
To get the prediction results used in Figure 2, we use the same 2-layer GCN model as
the Swiss Roll experiment to predict product categories (Section ยง1.8). The dimension of
the hidden layer is 64, learning rate is 0.01 and weight decay is 10 5. We randomly use 10%
samples as training, another 10% samples as validation and all the other samples as testing.
We extract the output of the rst layer as node embeddings and we also build a 2-NN graph
using cosine similarity to combine with the original graph. This will let GTDA show the
impact of the feature similarity on the GNN. For GTDA parameters, we set K= 100,d= 0,
r= 0:01,s1= 5,s2= 5,= 0:5 andS= 5. We use 20 steps of iterations for GTDA error
estimation. For the more advanced GPRGNN model used below, we use the same set of
parameters as suggested by its authors [5] and node embeddings are extracted from the rst
layer output as well. We also use the same GTDA parameters as GCN.
ยง2.2 Inspecting model predictions with GTDA
In Figure 2 of the main text, we found ambiguous subgroups inside \Data Storage" and
\Networking Products" with the help of GTDA visualization. Similar ambiguities persist
21

--- PAGE 22 ---
after switching to the more advanced GPRGNN model as shown in Figure 8. Here, we
also notice many estimated errors in \Routers" and \Data Storage" as before. We show a
detailed breakdown of products true categories for some components. For each component
highlighted, we list top 2 most common categories. The other categories are put in \Others".
For \Networking Products" and \Data Storage", we also list the top 3 most common sub-
categories. For the two \Routers" components in (A), we see many \Modems" or \Wireless
Access Points" from \Networking Products". These should be frequently bought together,
and \Routers" should be considered as another subcategory of \Networking Products". As
a comparison, for the other \Networking Products" component that is less mixed (B), the
most common subcategories are \Network Adapters" and \Hubs", which are more precise
than the more ambiguous \Routers". Similarly, for the two \Data Storage" components in
(C), the mixed one has many \Internal Drives" such as solid state drives (SSDs). These are
essential parts of a PC and should be considered as a part of \Computer Components" as
well. There are also a small portion of \Network Attached Storage", which may be confused
with \Networking Products". On the contrary, the less mixed one mostly contains \External
Drives" like USB drives, which are common additions to an already built PC. These results
suggest that for this dataset, no matter which model we choose, the performance on some
portion of the dataset will always be limited by the same type of underlying labeling issues.
GTDA helps capture those issues in both cases.
ยง2.3 GTDA visualization on the original Amazon dataset
As a nal check on our results, in Figure 9, we apply GTDA to inspect GPRGNN's
prediction on the original Amazon dataset built by [38] with the same setting. We can
observe similar behavior to Figure 8, that is \Routers" is mixed with \Networking Products"
and components of \Data Storage" are mixed with \Computer Components".
ยง3 Understanding image predictions
One of the most successful applications for complex neural network models is detecting
objects in images. Image classiers based on convolutional neural networks (CNN) can
achieve extremely high accuracy, sometimes even higher than humans. What remains not
entirely understood is how to explain a model's prediction and whether it will generalize well
beyond the training scenario.
Summary of GTDA results In Figure 3 of the main text, we have shown how we can
use GTDA visualization to study predictions made by a pretrained ResNet50 classier on
a subset of ImageNet called Imagenette. The Reeb net from GTDA highlights \cassette
players" images that are really pictures of cars inside the \gas pump" group. This is a key
dierence from the Amazon experiment in the previous section, because only a few samples
inside \cassette player" have labeling issue. In the following, we will provide more details on
the dataset and the CNN model. Then we will use a random experiments to show that GTDA
is stable in detecting this issue and the criteria we use to nd such issue cannot be easily
satised in random set of images. We will show the ResNet50 model's generalization ability
22

--- PAGE 23 ---
Data Storage: 52.6%    โ Internal Drives: 31.6%    โ External Drives: 15.5%    โ Network Attached Storage: 5.4%    โ Other Data Storage: 0.2%Computer Components: 42.1%Others: 5.2%Data Storage: 99.3%    โ External Drives: 88.3%    โ Internal Drives: 9.1%    โ Network Attached Storage: 1.1%    โ Other Data Storage: 0.9%Computer Components: 0.5%Others: 0.2%Networking Products: 86.2%    โ Network Adapters: 44.0%    โ Hubs: 28.1%    โ Print Servers: 7.8%    โ Other Networking Products: 6.3%Computer Components: 12.1%Others: 1.7%Routers: 53.0%Networking Products: 43.9%    โ Wireless Access Points: 19.4%    โ Modems: 11.7%    โ Switches: 5.1%    โ Other Networking Products: 7.7%Others: 3.1%Routers: 51.5%Networking Products: 46.5%    โ Wireless Access Points: 13.3%    โ Modems: 10.8%    โ Repeaters: 9.6%    โ Other Networking Products: 12.7%Others: 2.0%
Prediction of GPRGNNA
B
CGTDA estimated errorsAUC score is 0.82
Training accuracy: 0.97Validation accuracy: 0.89Testing accuracy: 0.89Figure 8: We provide GTDA results on inspecting the prediction on the GPRGNN method instead of the GCN
used in Figure 2 in the main text. We list a detailed breakdown of categories and subcategories for a few
components. For the two \Routers" components in (A), there are many estimated errors because of ambiguous
subgroups of \Networking Products" like \Wireless Access Points", \Modems" or \Repeaters". The estimated
errors are much less in (B) because \Networking Products" has dominant less ambiguous subgroups. Similarly,
for two \Data Storage" components in (C), the one with more estimated errors has dominant ambiguous
subgraphs like \Internal Drives" or \Network Attached Storage" which is confusing with \Computer
Components" or \Networking Products".
23

--- PAGE 24 ---
(1) predicted labels
 (2) GTDA estimated errors
 (3) true labels
Desktops
Data Storage
Laptops
Monitors
Computer Components
Video Projectors
Routers
T ablets
Networking Products
Webcams
Figure 9: GTDA visualization of GPRGNN's prediction on the original Amazon Computers dataset [38]. Similar
to Figure 8, \Routers" is mixed with \Networking Products" and some components of \Data Storage" are
mixed with \Computer Components".
by embedding images on some other components of GTDA results. Finally, we compare with
results of the original mapper .
Displaying Reeb networks for images. Because each image can be displayed, we cus-
tomize a display of a Reeb net (which is simply a graph) to show the results of a Reeb net
analysis by placing images directly on the layout. This involves a few relevant details that
may assist others in the future so we detail our methodology here. It was inspired by Tufte's
work on image quilts and small multiples [46].
Prior work on understanding image predictions. Existing research seeks to explain
model predictions by computing activation maps or saliency maps [42, 53, 37, 40]. In these
maps, areas that contribute to the nal prediction will be highlighted and the user can
justify model predictions by checking whether the areas highlighted make sense. Some other
studies take a dierent approach by training a simple and explainable model (i.e. a linear
classier) to mimic the prediction functions of the original model [35]. However, all these
approaches can only explain the model's prediction on a single sample each time instead
of model's prediction ability in the entire dataset. The training and testing datasets can
contain hundreds of thousands of images. So examining the explanation for all images is
not straightforward. Finding representative samples is another alternative [35], but checking
explanation on each selected sample is still required. We note that our GTDA analysis could
assist such eorts by studying the topology of the saliency maps, along with the predictions,
although we have not pursued this direction.
ยง3.1 Dataset and CNN model
The dataset we use is Imagenette [13], which is a subset of the entire ImageNet contain-
ing 10 easily classied classes, \tench" (a type of sh), \English springer" (a type of dog),
\cassette player", \chain saw", \church", \French horn", \garbage truck", \gas pump",
\golf ball" and \parachute". This dataset can be directly downloaded from a Github repos-
itory [13]. The author uses a dierent training and testing split from the original ImageNet
dataset so we rst restore the original split before model training. This choice is because
24

--- PAGE 25 ---
label training testing
tench 1,300 50
English springer 1,300 50
cassette player 1,300 50
chain saw 1,194 50
church 1,300 50
French horn 1,300 50
garbage truck 1,300 50
gas pump 1,300 50
golf ball 1,300 50
parachute 1,300 50
Table 3: Number of training and testing images for each label.
the pretrained model from the full ImageNet dataset may have had access to images in the
Imagenette test set. The number of training and testing images for each class is shown in
table 3.
We use a pretrained ResNet50 model that is included in the PyTorch package and retrain
the last fully connected layer to make predictions on these 10 classes only. We use a batch size
of 128, learning rate of 0.01 and run for 5 epochs. We also use the common image transform
during training and testing. That is, each training image will be randomly cropped into 224-
by-224, randomly horizontally ipped and normalized by the mean and standard deviation
computed over the entire ImageNet dataset, while each testing image will be resized to
256 along the shorter edge, center cropped to 224-by-224 and then normalized. We modify
the pooling of the last convolutional layer from average pooling to maximum pooling and
extract its output as node embeddings. Similar techniques are used in the context of image
retrivial [33]. Initially, the embedding dimension is 2048. We rst PCA reduce the dimension
to 128 with PCA whitening. Then each row is `2noramlized. A 5-NN graph is constructed
on the preprocessed embedding matrix with cosine similarity. For GTDA parameters, we
setK= 25,d= 0:001,r= 0:01,s1= 5,s2= 5,= 0:5 andS= 10. We use 10 steps of
iterations for GTDA error estimation.
ยง3.2 Details on selecting images to embed
We provide more details on how we embed images on a Reeb net component to get Figure
3 of the main text. For each pair of adjacent Reeb net nodes, for each image in one end, we
measure its smallest distance in the projected Reeb net to some node in the other end. Note
some images can be duplicated in two ends, in such case, we consider the distance to be zero.
If two images have the same distance, we include the one with larger degree in the projected
Reeb net. Then we ll in the closest images to one half of the edge and vice versa. A simple
demo can be found in Figure 10. We also apply a background removal algorithm [31] for
each image we embed. After embedding selected images, we can then easily browse around
dierent regions of the component to understand the model's behaviour of predicting \gas
pumps". Then we can simply select a few Reeb net nodes at dierent places and check them
25

--- PAGE 26 ---
Figure 10: This gure demonstrates the procedure of embedding images on a Reeb net component. For each
pair of adjacent nodes, we select images from one end that are closest to the other end and ll in those images
in half of the edge and vice versa. Browsing around embedded images at dierent regions can help us quickly
identify 7 ambiguous \cassette player" images that are really just \cars".
in detail by listing all images it contains to look for the most common patterns. Eventually,
this can help us quickly identify 7 ambiguous \cassette player" images that are really just
\cars".
ยง3.3 Statistical validation
Firstly, we verify that GTDA is stable in detecting those 7 confusing \cassette player"
images as shown in Figure 3 of the main text. We randomly train 100 models in the same way
as described before and check the visualization using each of these 100 models. On average,
only 1.3 of these 7 images are predicted wrong, which means simply iterating through all
the prediction errors is not enough. We dene that this labeling issue can be detected in a
visualization if the following criteria can be met:
โขAll or most of these 7 images are in the same component
โขSome neighbors of these images are from a dierent class
โขThese images are well localized in the component with small pairwise path length
In our results, we nd the visualization from all 100 models can meet these criteria. More
specically, for 74 models, all 7 images can meet these 3 criteria. In the other 26 models,
for 22 of them, 6 images can meet all 3 criteria, for 2 models, 5 images can meet and for
the rest 2 models, 4 images can meet. Also the maximum pairwise path length for images
meeting the criteria is 4 (for most models, this maximum length is 2). Secondly, we verify
that a random group of 7 images will be very unlikely to satisfy these criteria. We pick one
of the 100 models and randomly sample 7 images from each Reeb net component. We cannot
nd any randomly sampled group in 10000 Monte Carlo experiments that can satisfy these
criteria simultaneously.
26

--- PAGE 27 ---
ยง3.4 Comparing to inuence functions
Inuence functions [17] is a framework recently proposed to extract the most inuential
training samples on any specic testing sample. It can also be used to nd adversarial or
mislabeled training data. We used an existing implementation of inuence functions from
https://github.com/nimarb/pytorch_influence_functions to nd ambiguous training
samples of Imagenette. The biggest issue of inuence functions is scalability. Computing
inuence for all 12,894 images will take almost 4 hours while our GTDA framework only
takes about 1 minute to process the entire dataset. Figure 11 compares the top 30 most
confusing training images of \cassette player" from inuence functions or GTDA. For GTDA,
we directly take top 30 images with the largest estimated errors using Algorithm 4. Both
methods nd training images that indeed look confusing. However, another advantage of
GTDA is we get more insights by grouping these ambiguous training images based on their
locations in the visualization and checking nearby images in the visualization. For instance,
we can conclude from Figure 10 that some \cassette player" images can be confused with
\gas pump" or \chain saw" images with cars in them.
ยง3.5 Understanding model generalization on other labels
Other than the detailed analysis for \gas pump" component, we provide similar gures
(Figures 12 to 16) for components of other labels. We embed images on each component
in the same way as above. GTDA can always nd groups of images with dierent visual
features. For instance, it can nd \church" images that are either the inside decorations of a
church or the outside landscapes in Figure 14. It can also nd images that are ambiguous like
group (C) in Figure 12 or group (D) in Figure 16. All these results can help us understand
how the model is utilizing dierent features of an image to make the prediction and when it
might make mistakes.
ยง3.6 Comparing to a Reeb net from original TDA framework
Since the original format of the image representations is an embedding matrix, we get
another Reeb net from the original TDA framework (i.e. mapper ) without transforming the
embedding matrix into a KNN graph. The embedding matrix is still PCA reduced to 128,
whitened and `2normalized. We also use the prediciton lens without softmax as the softmax
function will make lens highly skewed, i.e. most lens will be close to 0 or 1. We split each len
into 10 bins with 10% overlap. Then we apply density based spatial clustering [8] for samples
in each bin so that we don't need to select the number of clusters. This clustering scheme
will consider some samples as noise and not clustering them. We set the maximum distance
between two points to be in the same cluster as 3. The Reeb net is shown in Figure 17, which
doesn't show any obvious subgroups other than 10 major components representing 10 classes
or any labeling issues previously discovered by GTDA. We also nd that no information can
be extracted at all for around 28% images as they are either in some very small Reeb net
components or simply considered as noise by the clustering scheme.
27

--- PAGE 28 ---
Figure 11: This gure compares the top 30 most confusing training images of \cassette player" from inuence
functions [17] or GTDA. Both method can nd some common training images that are indeed ambiguous.
However, it will take inuence functions almost 4 hours to compute inuence for all 12,894 training images while
GTDA only takes about 1 minute to process the entire dataset.
28

--- PAGE 29 ---
Figure 12: We embed images on components that are mostly \English Springer" predicitons (A). While most
\English Springer" images are easy to classify, we also nd some groups where the background information is
dominant in (B) and (D) or the images are ambiguous (C). Consider zooming in to see the micropictures.
29

--- PAGE 30 ---
Figure 13: By embedding images on \cassette player" components (A) can help us nd \cassette player" in
various shapes.
30

--- PAGE 31 ---
Figure 14: By embedding images on \church" components (A), we nd one component has images that depicts
the inside decorations of church (B) while the other components are images showing dierent outside landscapes
of church.
31

--- PAGE 32 ---
Figure 15: We embed images on \golf ball" components (A). We can nd images with only one large golf ball
(B), or images with lots of small golf balls (C), or images where a person is playing golf ball (D), or images with
a golf ball placed on grass (E).
ยง4 Comparing models on ImageNet-1k predictions
In this section, we apply GTDA framework on the entire ImageNet dataset with 1000
classes from 2012 [36] to compare performance between state of the art CNN models and
historical models in any individual class. The results in the later sections show that GTDA
can highlight which subgroups inside a class the more advanced models can have improved
performance. It also shows how models predict when the image itself has confusing labels.
ยง4.1 Dataset and CNN models
We use the training and validation images of entire ImageNet dataset with 1000 classes
that was released in 2012 [36]. We use 3 dierent CNN models for comparison, AlexNet,
32

--- PAGE 33 ---
Figure 16: We embed images on \parachute" components (A). We can mainly see parachutes in two dierent
shapes (B and C). Some images are ambiguous as they are really just \sky" (D). We also nd images where a
person is standing on the ground wearing a parachute (E) or a person that jumps into the sky (F).
ResNet-50 and VOLO. AlexNet is one of the historical CNN models, with around 60% top-
1 testing accuracy. ResNet is one of the most widely used CNN models nowadays with
a better performance of about 75% top-1 testing accuracy. Finally, VOLO is one of the
state of art CNN models that achieves about 87% top-1 testing accuracy without using any
additional training data. Then, for each CNN model, we extract the prediction matrix and
the image embeddings. For AlexNet and ResNet, the image embeddings are the outputs
of the layer before nal prediction layer. Similar to the previous section, we replace the
average pooling by max pooling in the last convolutional layer. For VOLO, we directly used
the dedicated feature forwarding function to get image embeddings. Similar to previous
sections, all image embeddings are PCA reduced to 128 with whitening and normalization.
For GTDA parameters, we set K= 25,d= 0:001,r= 0:01,s1= 5,s2= 5,= 0:5 and
S= 10. We use 10 steps of iterations for GTDA error estimation.
ยง4.2 Building graphs and initial results of GTDA
We rst compare AlexNet and ResNet. To do so, we build a 5-NN graph using the
image embeddings of ResNet only. Then we concatenate the prediction matrix of AlexNet
and ResNet to get 2,000 lens. GTDA framework is then applied using the same set of
parameters as Section ยง3. Similarly, to compare ResNet and VOLO, we build a 5-NN graph
using the image embeddings of VOLO and concatenate the prediction matrix of ResNet and
VOLO. In Table 4, we provide some initial statistics on the nal Reeb nets. We can see that
33

--- PAGE 34 ---
Figure 17: Reeb net on the 10 easy classes of ImageNet created by the original TDA framework. TDA is direclty
applied to the ResNet image embedding matrix without transforming into KNN graph. Unlike GTDA
visualization, we cannot nd any obvious subgroups other than 10 major components representing 10 classes or
the labeling issues of some \cassette player" images. Moreover, no information can be extracted at all for
around 28% images as they are either in some very small Reeb net components or simply considered as noise by
the clustering scheme.
despite the Reeb net has tens of thousands of nodes, the maximum Reeb component size is
just a few hundred of nodes, which guarantees that we can easily visualize any component
of the Reeb net.
ยง4.3 Highlighting subgroups where advanced models perform better
Figure 18 shows the results on one class, \screwdriver", from GTDA when comparing
AlexNet with ResNet. AlexNet and ResNet have huge dierence in terms of training or
validation accuracy as shown in (A) of Figure 18. By embedding images on top of each
component, we can nd dierent subgroups inside the \screwdriver" class, where some groups
like (B) or (C) can be predicted with high accuracy by both models, while for some other
groups like (D), (E) or (F), only ResNet can maintain the high accuracy. By showing some
example images from each group, we can see that in general, AlexNet can only nd the
screwdriver if both the handle and the tip are clear enough in the image. Showing only some
part of the screwdriver or having a slightly complex background will likely cause AlexNet
to fail. Similarly, Figure 19 compares with prediciton of ResNet and VOLO on the \hook"
34

--- PAGE 35 ---
AlexNet v.s. ResNet ResNet v.s. VOLO
original graph nodes 1,331,167 1,331,167
original graph edges 5,954,900 5,805,714
Reeb nodes 63,239 68,354
Reeb edges 59,881 64,360
Reeb components 3,395 4,046
max Reeb component size 169 79
max Reeb node size 330 643
average Reeb components for each class 3.5 4.0
Table 4: Statistics on Reeb nets. Reeb node size is the number of samples represented in a Reeb net node.
Average Reeb components for each class is the average number of Reeb net components where the most
frequent predicted label (by one of the two models) is that class. The maximum Reeb component just has a few
hundred of nodes, which guarantees that any component of the Reeb net can be easily visualized and analyzed.
class. We rst nd subgroups of images that shows a single hook where both model have high
accuracy in group (B). Then we nd ResNet model often prefers to predict chain instead of
hook if they are both present in the image from group (C). ResNet model also has diculty
predicting hook if only part of the hook is shown (D), or the shape of the hook is not common
(G) and (F), or there are lots of hooks in the image (E).
ยง4.4 Understanding dierent models' predictions
In Figure 20, we compare the the predictions between ResNet and VOLO on \desktop
computer". Both models have very similar training or validation accuracy on this class. But
they make mistakes in dierent places. We highlight a few subgroups where we can see lots
of dierence in predicted labels. These subgroups contain images that are indeed confusing.
For instance, images in group (D) clearly have a desk, a monitor and a desktop computer at
the same time. We can see VOLO tends to predict all these confusing images as \desktop
computer", even though the true labels for some of those images are dierent. This suggests
the VOLO prediction of \desktop computer" is more robust, while the ResNet prediction is
more likely to be aected by other objects in the image.
35

--- PAGE 36 ---
Figure 18: In this gure, we analyze the prediction of \screwdriver" from both ResNet and AlexNet. We can see
AlexNet can only predict \screwdriver" with high accuracy if both handle and the tip are clearly visible in the
image (see B and C). Otherwise, if only the tip (D) or a small part of the handle (E) is shown or the image is
about a person using a screwdriver (F), AlexNet will likely fail while ResNet still maintains high accuracy.
36

--- PAGE 37 ---
Figure 19: In this gure, we analyze the prediction of \hook" from both ResNet and VOLO. VOLO has much
higher training and validation accuracy on this class than ResNet (A). We rst nd subgroups of images that
shows a single hook where both model have high accuracy (B). Then we nd ResNet model often prefers to
predict chain instead of hook if they are both present in the image (C). ResNet model also has diculty
predicting hook if only part of the hook is shown (D), or the shape of the hook is not common (G) and (F), or
there are lots of hooks in the image (E).
37

--- PAGE 38 ---
Figure 20: In this gure, we analyze the prediction of \desktop computer" from both ResNet and VOLO. In (A),
we show all components GTDA has found where \desktop computer" is the most frequent predictions. ResNet
and VOLO show very close training and validation accuracy on these components. By embedding images on
them, we can rst nd subgroups of images that look confusing. For instance, some images in (B) have labels
like \space bar" or \screen" despite they are just old fashioned desktop computers. Images in (C) show some
\CD player" or \hard disc" that look very similar to PC chasis. Images in (D) have desk, desktop computer and
monitor at the same time. And some images in (E) are labeled as \mouse" even if they also contain a monitor
or a keyboard. We can also notice how ResNet and VOLO handle these confusing images dierently. Overall,
VOLO's predcition on \desktop computer" is more robust and less aected by other objects in the image or
similar objects from other classes.
38

--- PAGE 39 ---
ยง5 Understanding Malignant Gene Mutation Predictions
In this section, we apply our method to inspect model predictions of gene sequence
variants eects. A gene sequence variant means that some part of the DNA sequence for
this gene is mutated compared with the reference. Modications include single nucleotide
variation, deletion, duplication, etc. We study a model proposed to predict whether such
variant is harmful or not [1]. In the following section, we will provide details on the model
and the dataset we use. Then we will show that the model's prediction is highly correlated
with both gene variants coordinates as well as mutation types. We also discover abnormal
places that could imply unreliable labels.
ยง5.1 Dataset and model
The model we use is recently proposed to predict gene expression from DNA sequence
by integrating long-range interactions [1]. In this model, a consecutive DNA sequence of
196,608bp is used to predict 5,313 human genome tracks. For each gene variant, we follow
the same steps as proposed by [1] to compute its embedding. First, we extract the reference
and alternate DNA sequences from homo sapiens (human) genome assembly, either hg19 or
hg38 as specied by the gene variant record. This gives a 393,216bp long DNA sequence
with the centered on the VCF position (Variant Call Format). Note that for the alternate
sequence, the gene variant is applied rst before extracting the modied sequence. Then,
we directly use the pretrained model from [1] to make predictions on the reference and
alternate sequences. This model will aggregate the center 114,688bp into 128-bp bins of
length 896. The prediction for each 128bp bin is a 5,313 vector, where each element represents
the predicted gene expression in one of the 5,313 genome tracks for the human genome
(including 2,131 transcription factor chromatin immunoprecipitation and sequencing tracks,
1,860 histone modication tracks, 684 DNase-seq or ATAC-seq tracks and 638 CAGE tracks).
The prediction vector of the 4 128bp bins located in the center is then summed together to
get a prediction vector for the reference or alternate sequence. After that, the elements
in each prediction vector corresponding to the CAGE tracks is log(1 + x) transformed.
Finally, we compute the dierence of preprocessed prediction vectors between reference and
alternate sequences as the nal embedding for the gene variant. In total, we get a 23,376-
by-5,313 embedding matrix for 23,376 gene variant records. Then, a linear classier will be
trained on this 5,313 dierence vector to predict variants eects. The original paper uses
the training and testing datasets from CAGI5 competition [39], where a Lasso regression is
trained to predict a label of -1 (signicant downregulating eect), 0 (very little to no eect
on expression) or +1 (signicant upregulating eect). We were not able to download the
dataset from the ocial CAGI5 competition website. Therefore, we use similar procedure
to predict harmful (label 1) vs non-harmful (label 0) gene mutations from ClinVar. We
download gene variants experiments from the ocial ClinVar website [20]. We choose all
experiments that are targeting BRCA1 as it is one of the genes with the most number
of experiments and part of the protein it encodes has known 3D structures (i.e. 1JNX ).
Gene variants without a valid VCF (variant call format) position are removed. As for the
labels, we directly use the \ClinSigSimple" eld as the label of each gene variant record. An
integer 1 means at least one current record indicates \Likely pathogenic" or \Pathogenic",
39

--- PAGE 40 ---
but doesn't necessarily mean this record includes assertion criteria or evidence. An integer
0 means there are no current records of \Likely pathogenic" or \Pathogenic". An integer
-1 means no clinic signicance and is replaced by label 0 in our experiments. And we use a
logistic regression with L1 penalty since this is a binary prediction. We include 23,376 gene
variants where 50% of them are used as training, and the other 50% are used as testing.
To build the graph for GTDA, the embedding matrix is PCA reduced to 128 dimensions
with PCA whitening and then each row is `2normalized. A 5-NN graph is constructed on
the preprocessed embedding matrix with cosine similarity. This 5-NN graph has some small
components smaller than the threshold set by s1ands2. As a result, 338 out of 23,376 gene
variants (1.4%) are not included in the nal Reeb net; this is not expected to impact
the results. We use 2 prediction lens and the rst 2 PCA lens of the embedding matrix for
GTDA analysis. For GTDA parameters, we set K= 30,d= 0,r= 0:05,s1= 5,s2= 5,
= 0:5 andS= 10. We use 20 iterations for GTDA error estimation.
ยง5.2 Validating the GTDA visualization
The visualization we get from this dataset is shown in Figure 21. The rst nding is
that dierent components in this visualization are strongly related to dierent regions of
the DNA sequence. Such a result is not surprising because this model aims to predict gene
expressions from a long range of DNA sequence while most gene variants will only change
one or two base pairs. Therefore, it is expected that gene variants close to each other in
coordinates will also get similar embeddings. To further validate whether this visualization
can capture ner 3D protein structures, we check the crystal structure of the BRCT repeat
region (PDB id is 1JNX ), also shown in plot (C) of Figure 21. In total, BRCA1 encodes
a protein with 1863 amino acids. And 1JNX covers amino acids from 1646 to 1849. In the
color bar of Figure 21, we mark the protein coding regions (exons) of 1JNX in green. In
(B) of Figure 21, we check a few components in detail that contains gene mutation locations
overlapped with the green area. Each green area represents an exon. Dierent node colors
are assigned based on which exon they overlap with.10We can nd that dierent local
structures of this crystal are also very well localized in our visualization. All these ndings
suggest that the model's embedding space has a strong correlation with VCF (variant call
format) positions of gene variants and GTDA can capture such property successfully.
Statistical validation We conduct 10000 random experiments to see if such strong lo-
cation sensitivity can be found in a random graph. In each experiment, we shue the
embeddings and rebuild the KNN graph. The PCA lenses and prediction lenses are kept
the same. Then we run GTDA on each of the 10000 random graphs. We consider a random
graph to shows location sensitivity if in the results of GTDA, one component has more than
40 mutation samples that overlap with exons and more than half of them are overlapped
with the same exon. We were not able to nd any random graph that can pass this criteria
in these experiments.
104 out of 2756 mutation samples overlap with more than 1 exons of 1JNX, we color those based on the
rst exon they overlap with.
40

--- PAGE 41 ---
Figure 21: (A) shows components found by GTDA, where each node is colored by median hg38 coordinates of
mutation starting positions. Dierent components are ordered by the averaged median coordinates in a zig-zag
fashion from lower right to upper left. We zoom in a few components where the gene variants have the highest
overlap ratio with the coding regions of 1JNX (B). Dierent node colors are assigned based on which
consecutive protein coding region they overlap with. Nodes for gene variants not in the coding regions of 1JNX
are not plotted. We can nd that dierent secondary structures of the crystal of 1JNX (C) are also well
separated in the GTDA visualization.
ยง5.3 Estimating and correcting prediction errors
We apply Algorithm 4 to estimate errors of model prediction Figure 22. Overall, GTDA
estimated errors (after normalizing to 0 to 1) achieve an AUC score of 0.90. In comparison,
using model uncertainty gives an AUC score of 0.66. Since this is a binary classication, we
can also ip predicted labels if they are more likely to be errors. Instead of setting a single
threshold, we ip predicted labels when the estimated errors are larger than the probability
of the current prediction. The corrected labels can improve training accuracy from 0.87 to
0.98 and testing accuracy from 0.78 to 0.86.
ยง5.4 Extracting insights about mutation types and single nucleotide variants
As we explore model predictions for gene mutations happening inside protein encoding
regions, i.e., green boxes in Figure 21, we nd dierent predicted labels for mutations that
target a small area of the protein structure. One such example is Figure 23, where records
in the grey box happen in a small region of the protein structure with around 17 amino
acids. So there should be other aspects that help the model make dierent predictions.
41

--- PAGE 42 ---
Figure 22: In the top part, we zoom in a component and mark training data using green circles. Then we show
GTDA estimated errors and model uncertainty on this component. We ip predicted labels if the estimated error
is larger than the prediction probability. In the lower part, we can see GTDA error estimation has much better
overall AUC score and the corrected labels have higher training and testing accuracy.
42

--- PAGE 43 ---
Figure 23: We zoom in one component GTDA nds and only show mutation records that happen in the protein
coding regions (non-coding regions are not shown as colored dots, but do impact the Reeb net structure). After
correcting prediction based on GTDA error estimation, we still see records that happen in a small region of the
protein but still get dierent predictions. By checking these records, such dierence can be well explained by
dierent mutation types.
By checking the actual mutation record, we nd the non-harmful mutations are all single
nucleotide variant (SNV), while harmful mutations are other types of mutations including
deletion, insertion or duplication. This makes sense as the latter types will not only aect the
current amino acid, but also the subsequent amino acids and hence cause more substantial
changes to the nal protein structure.
Overall, we nd for gene mutations that are predicted harmful (after GTDA correction)
and target gene encoding regions, 70% of them are mutations like deletion, insertion or du-
plication. For gene mutations that are predicted as non-harmful and target gene encoding
regions, only 6% are mutations like deletion, insertion or duplication. When including gene
mutations outside protein encoding regions as well, 72% of harmful predictions are muta-
tions like deletion, insertion or duplication, while that number drops to 5% for non-harmful
predictions.
We assess the statistical signicance of the relationship between single nucleotide vari-
ants (SNV) and harmful predictions for each component GTDA identies in Table 5. The
associated Chi-square p-values highlight a few components where this association is missing,
such as component 100 with 34 non-harmful non-SNV results throughout the entire BRCA1
structure (coding and non-coding regions), with a pvalue of 0:22. This suggests a dier-
ence in behavior for this component in comparison with the remainder of the components.
Other large p-values include the nearby components 99 and 101, along with component 3,
26. Overall, this highlights another way these GTDA results could be used.
43

--- PAGE 44 ---
Prediction and Type (coding regions of 1JNX) Prediction and Type (all)
Harmful Harmful non-Harm non-HarmChi-square
p-value Harmful Harmful non-Harm non-HarmChi-square
p-value
Component SNV non-SNV SNV non-SNV SNV non-SNV SNV non-SNV
0 11 6 83 4 5.1e-04 13 6 167 8 1.2e-04
2 0 0 0 0 - 17 264 49 16 1.2e-36
3 1 3 99 5 1.8e-05 12 3 230 9 2.5e-02
4 0 0 0 0 - 13 14 181 4 1.2e-16
6 0 10 10 2 - 24 38 298 20 2.7e-27
7 0 0 0 0 - 6 42 152 24 1.5e-22
8 0 4 0 0 - 16 82 96 22 6.2e-21
9 0 0 0 0 - 6 23 44 11 4.9e-07
10 0 0 0 0 - 17 102 129 22 1.0e-30
14 0 2 2 0 - 13 31 297 19 7.6e-30
15 6 2 40 0 - 25 146 437 24 8.7e-90
16 0 0 0 0 - 6 155 136 13 3.9e-53
17 5 14 49 4 6.5e-08 55 93 485 23 2.7e-59
18 0 0 2 0 - 9 7 115 3 7.5e-08
19 0 8 0 2 - 36 70 422 32 1.0e-44
21 0 6 64 2 - 20 31 376 17 4.7e-33
22 12 16 102 2 4.2e-13 32 20 188 6 1.1e-12
25 0 0 0 0 - 15 17 19 3 7.7e-03
26 0 0 0 0 - 34 4 256 12 2.4e-01
28 0 1 0 1 - 29 42 63 12 1.7e-07
29 3 6 193 18 8.1e-07 9 9 339 31 1.3e-07
30 0 0 0 0 - 19 57 93 9 6.4e-19
31 0 0 0 0 - 16 18 68 8 4.3e-06
32 0 4 2 0 - 5 23 51 5 1.0e-10
33 10 55 64 11 5.5e-16 16 55 204 23 1.1e-28
34 16 18 32 0 - 32 70 66 12 3.5e-12
36 2 4 250 6 1.8e-12 8 11 314 23 3.2e-12
37 0 0 0 0 - 40 76 26 14 1.5e-03
38 0 0 0 0 - 21 37 137 19 8.6e-14
39 0 0 0 0 - 14 198 24 14 3.4e-18
40 0 2 6 0 - 50 81 488 13 1.5e-63
41 0 0 2 0 - 16 14 158 6 1.1e-11
44 0 0 0 0 - 27 29 423 17 4.2e-30
46 0 16 30 2 - 19 36 51 10 2.0e-07
48 0 4 20 4 - 30 14 220 16 3.1e-06
50 0 0 62 0 - 4 36 262 10 2.2e-45
52 0 4 18 2 - 60 67 830 79 5.7e-40
53 0 0 0 0 - 15 27 303 25 2.7e-22
54 0 0 10 0 - 19 27 365 13 2.5e-32
55 0 0 0 0 - 21 19 109 3 2.8e-11
56 0 0 0 0 - 5 34 29 4 9.4e-10
57 0 0 0 0 - 40 18 78 6 4.5e-04
58 2 2 0 0 - 25 30 157 10 2.3e-15
59 0 0 0 0 - 17 44 163 6 6.6e-28
60 6 0 36 2 - 6 7 130 13 2.8e-05
62 2 33 12 7 1.9e-05 12 69 218 35 8.1e-33
64 2 25 114 7 5.0e-22 6 25 192 17 4.4e-22
66 0 4 24 0 - 27 23 165 9 1.9e-12
67 0 6 0 0 - 9 30 111 4 1.0e-20
68 21 13 87 9 3.3e-04 76 108 570 92 3.8e-36
69 2 3 78 7 4.4e-03 4 11 314 35 8.6e-12
70 0 0 0 0 - 40 48 6 6 1.0e+00
71 0 0 0 0 - 17 8 269 18 4.4e-05
72 0 0 12 0 - 6 5 318 21 1.7e-05
73 0 0 0 0 - 12 9 142 3 3.1e-10
74 0 0 0 0 - 19 11 119 15 1.5e-03
77 6 20 14 4 1.1e-03 13 33 213 11 6.0e-28
78 0 0 2 0 - 3 8 181 6 4.1e-16
79 10 4 52 0 - 33 10 203 6 3.3e-06
81 0 0 0 0 - 9 57 95 15 9.5e-21
82 0 0 0 0 - 8 4 212 6 1.5e-05
85 0 1 38 1 - 14 61 496 29 5.3e-65
88 0 0 0 0 - 3 34 269 16 6.8e-41
90 2 4 76 2 4.4e-07 10 4 162 4 1.0e-04
99 0 0 8 0 - 6 3 100 7 3.3e-02
100 0 0 2 0 - 4 6 64 34 2.2e-01
101 0 2 2 0 - 6 4 60 6 2.8e-02
102 0 0 0 0 - 7 9 109 5 5.3e-09
Overall 148 344 2114 122 2.9e-259 1506 3986 16208 1338 0.0e+00
Table 5: For each component in the Reeb networks, 2 contingency tables are computed, where the left table
only considers variants in the coding regions of 1JNX and the right table considers all variants. Only
components where each cell of the right table has a count 3 or higher are included. Chi-square p-values are
computed for tables where each cell has a count larger than 0.
44

--- PAGE 45 ---
ยง5.5 Incorrect GTDA error estimation implies unreliable labels
When we compared the GTDA error estimation with true errors, we found a few places
where the GTDA estimate is entirely wrong.
To understand this abnormality, in Figure 24 we zoom in a few components and use
green circles to mark training and validation data. We show the GTDA estimated errors
as well as the false estimations when comparing to the true errors. We can see a few false
error estimates in each of these components. And on checking those false estimations, we
nd they are either testing experiments with insignicant or conicting results or aected
by nearby insignicant training experiments.
To understand this eect across all components found by GTDA, we use the dierence
between the true presence of an error and our estimate. For instance, if GTDA estimation
on whether a prediction is wrong is 0.3 and the prediction is indeed wrong based on its true
label, such dierence will be 1 minus 0.3. In total, we can nd 2,031 GTDA error estimations
where such dierence is larger than 0.5. These are spread over 771 Reeb nodes. Since an
error estimation being wrong can be due to either its own label being unreliable or training
samples nearby have unreliable labels, we study how many of those 771 Reeb nodes have at
least 1 insignicant or conicting samples (either training or testing sample). We nd 662
of them (81%) have at least one problematic label. Consequently, the intuition from Figure
24 would hold across much of the dataset.
ยง5.6 Comparison with other methods
We visually compared the visualization of GTDA with other methods including Mapper,
UMAP and tSNE in Figure 25. We can nd that the visualization of GTDA clearly shows
the location sensitivity of mutation samples in the DNA sequence that is not quite obvious
in the visualizations of other methods.
In the following of this section, we quantify this visual advantage of GTDA. We rst
convert UMAP and tSNE visualizations into graphs by building a 5-NN graph on top of the
2 dimensional embedding. For GTDA and Mapper, we project each Reeb net node using
Algorithm 5 to get the corresponding graphs. We also add the original KNN-graph that
has been used as input to GTDA and 100 random graphs by shuing edges for comparison.
Then we design the following metrics:
โขratio of samples within the same exon: in this metric, for each mutation sample that
overlaps with an exon, we search the neighbors within 3 hops on each graph and
compute the ratio of mutation samples that overlap with the same exon. Note that we
only consider exons that encodes 1JNX.
โขratio of samples within a small range: in this metric, for each mutation sample, we
search the neighbors within 3 hops on each graph and compute the ratio of mutation
samples whose mutation starting coordinates are within 1000 base pairs of the starting
coordinate of the selected mutation sample.
We also consider the corresponding ratio to be zero if the number of neighbors within 3 hops
is smaller than 5. This is because the visualization of Mapper has too many single nodes
or tiny components which could result in better metrics despite the visualization itself is
45

--- PAGE 46 ---
Figure 24: Checking false error estimations of GTDA in some components reveals that they are likely to be
caused by variants experiments with insignicant or conicting results.
46

--- PAGE 47 ---
Figure 25: The topological simplication identied by GTDA is highly correlated with DNA variant starting
location (A). Alternative global visualizations such as the simplication from Mapper (B), or dimensionality
reduction techniques UMAP (C) and tSNE (D) show signicantly less sensitivity to the variant location
(p <0:001 in a KS test, see Table 6). Likewise, the GTDA results strongly localize the exons of the 1JNX
structure within the BRCA1 gene (E). This is also signicantly better than Mapper (F), UMAP (G), and tSNE
(H) (p <0:001, see Table 6). These results demonstrate both how the Enformer model is sensitive to these
aspects of gene expression and also that GTDA makes them possible to inspect.
47

--- PAGE 48 ---
ratio of samples within the same exonratio of samples within a small rangeFigure 26: Overall GTDA performs the best on both metrics, while the other methods are not clearly better or
even worse than the original graph. This suggests (1) the strong location sensitivity of mutation samples indeed
exist in the original graph (2) GTDA can not only preserve and enhance such location sensitivity, but also
visualize such property easily.
GTDA vs tSNE GTDA vs UMAP GTDA vs Mapper
ratio within the same exon 0.23 p<10 100.35p<10 100.99p<10 10
ratio within a small range 0.33 p<10 100.40p<10 100.97p<10 10
Table 6: The ks statistics and p-value of the one tailed Kolmogorov{Smirnov test. The null assumption is that
the ecdf of GTDA is larger than the ecdf of other methods at all locations. The p-values were extremely small or
numerically 0 in oating point, which we report as less than 10 10
much worse. In Figure 26, we compare the empirical cumulative distribution function of the
ratio distributions. For each of the 100 random graphs, we compute the ecdf and report the
average of the 100 ecdf curves. We can rst notice that comparing to random graphs, the
ratio in both metrics is much higher in the original graph, which means mutation samples
are indeed signicantly localized in the original graph. Also, GTDA performs the best on
both metrics., which can be veried by the Kolmogorov{Smirnov test in Table 6.
One key advantage of topological based methods like GTDA is that it visualize the em-
bedding space by directly simplifying it without reducing the dimensions too much. In the
case of mutation dataset, the KNN graph that will be used as the input of GTDA is con-
structed on a 128 PCA reduced embedding space. In comparison, tSNE or UMAP try to
project the original embedding space on only 2 dimensions, which could cause huge infor-
mation loss. We nd that using more dimensions in UMAP can better preserve the location
sensitivity. To show this, we increase the embedding dimensions on UMAP and rebuild the
KNN graph using only mutation samples that overlap with exons. To study how mutation
samples from dierent exons will be localized, we consider samples within each exon as a
community and compute the graph modularity [27]. A higher modularity score means these
48

--- PAGE 49 ---
communities are better localized in the graph. As we can see in Figure 27, the modularity
score increases as we use more dimensions until after 10 dimensions. UMAP embedding in
higher dimension also performs better on the two metrics we designed. However, using more
than 2 dimensions on these types of methods will make the subsequent visualization dicult
or impossible. We were not able to replicate the same experiment on tSNE as the running
time of tSNE becomes extremely long when setting the dimension larger than 2.
modulaityratio of samples within the same exonratio of samples within a small range
Figure 27: In the rst plot, we compute the modularity by considering mutation samples that overlap with the
same exon as a community. This plot shows that the modularity increases as we use more dimensions in the
output of UMAP, which suggests these communities are less mixed in the corresponding KNN graph of UMAP
embeddings in higher dimensions. In the second and third plots, we compare the two metrics we designed
between UMAP embedding in 2 dimensions and UMAP embedding in 10 dimensions. Higher dimension also
performs better on both metrics. More specically, in one tailed Kolmogorov{Smirnov test, the ks statistics and
p-value are 0.11 and 3:0 16for ratio within the same exon and such numbers become 0.11 and 9:8 132for ratio
within a small range, showing that UMAP-10 is better localized than UMAP-2.
49

--- PAGE 50 ---
ยง6 Inspecting chest X-ray images
In this section, we apply our GTDA framework to inspect the prediction of disease on
112,120 images of chest X-rays [49]. Each X-ray image might be either normal or indicating
one or more diseases. Our results show that GTDA is very useful to help radiologists detect
images with incorrect normal and abnormal labels.
ยง6.1 Dataset and model
The NIH ChestX-ray14 dataset we use comprises 112,120 de-identied frontal-view X-
ray images of 30,805 unique patients [49]. Among these images, 86,524 images are used as
training or validation and the others are used as testing. Images are split at the patient level,
which means images belonging to the same patient will be put in the same group. Among
the 86,524 images, we randomly choose 20% patients and use their associated images as
validation data while images for the other patients are used as training data. In the original
dataset, a text mining approach is used on the associated radiological reports to nd the
existence of 14 possible diseases and one image can have multiple disease labels. As a result,
it is expected that many of the labels assigned are incorrect. In some other studies of these
data, expert labels are solicited for 810 selected testing images from multiple experienced
radiologists [25].
The model we use GTDA to study is called CheXNet [32] which is a 121-layer Dense Con-
volutional Network (DenseNet) [14]. When applying our GTDA framework, we rst reduce
the 14 disease predictions to a simple normal (label 0) vs abnormal (label 1) prediction. To
do so, we rst take a row wise maximum to reduce the prediction matrix for 14 disease into
a vectorvwith values ranging 0 to 1. Then we consider each individual value as a threshold
and generate predicted labels by treating values larger than this threshold as 1 or 0 other-
wise. Then we compute the F1 score using the union of training and validation data. The
threshold that gives the largest F1 score will be kept, denoted as t. Similar procedures have
been used in other papers that predict ontological annotations [6, 19]. Finally, we transform
each value of vusingvi= min(1;0:5vi=t). The transformed valso ranges from 0 to 1 and is
considered as the probability of being abnormal. As a result, the row wise maximum column
index of the new prediction matrix P= [1 v;v] will give the same largest F1 score. Other
than the abnormal vs normal lens, we also include the original disease prediction matrix
as the extra lenses. This process gives 16 lenses in total. For GTDA parameters, we set
K= 50,d= 0,r= 0:005,s1= 5,s2= 5,= 0:5 andS= 10. We use 10 iterations for
GTDA error estimation.
ยง6.2 GTDA nds incorrect normal vs abnormal labels
Out of the 810 images in the test set with expert labels, 222 images have incorrect normal
vs abnormal labels. Our goal is to use the GTDA visualization to nd images in this set
(i.e. those that are more likely to an incorrect label). The procedure of nding those images
is similar to nd insignicant or conicting gene mutation experiments from the previous
section.
We rst use GTDA to estimate prediction errors. The estimation is normalized to a
50

--- PAGE 51 ---
abnormal
normalGTDA estimated errors on testing images with expert labelsfalse estimation when comparing to original testing labels
consider di๏ฌerence bigger than 0.5 as problematic testing labelscompare to incorrect testing labels marked by experts17 images are ๏ฌagged as problematic14 true positivesprecision is 0.82recall is 0.78testing images in green circle have expert labelsmodel prediction on a component
ABC
DE
Figure 28: We give a demonstration on how to use GTDA results to nd which testing labels are likely to be
problematic. We rst zoom in a component found by GTDA and use green circles to mark testing images where
we have expert labels (A). Then we use GTDA to estimate prediction errors on circled images (B). Comparing
GTDA estimation with original testing labels can identify a few places with false estimations (C). We consider
these false estimations are due to problematic testing labels and do a simple thresholding of 0.5, which ags 17
problematic testing labels in this component (D). Comparing to expert labels can nd 14 true positives with a
precision of 0.82 and a recall of 0.78 (E).
number between 0 and 1. Then we use the original testing labels (i.e. without the correction
from experts) to nd which of these error estimates are wrong. We can then sort the test
samples in the order of descending absolute dierence between estimated error and true
error.
For simplicity, images in the test set where such dierences are larger than 0.5 are con-
sidered to have incorrect labels. A demonstration on this process can be found in Figure 28.
Overall, out of the 810 testing images with expert labels, GTDA highlights 265 images are
likely to have incorrect normal vs abnormal labels and 138 of them are conrmed by the
expert labels, which gives a precision of 0.52 and a recall of 0.62. As a comparison, randomly
sampling 265 images for experts to check can only nd around 73 images with incorrect la-
bels in average. More detailed results on each component are shown in Table 7. By testing
multiple thresholds instead of 0.5, we get an AUC score of 0.75. As a comparison, using self
condence [29] gives an overall AUC score of 0.60.
51

--- PAGE 52 ---
TypeExpert Labels
in ComponentIncorrect
by ExpertsFlagged as
Problematic Precision Recall
Single Component 53 18 17 0.82 0.78
Single Component 10 5 5 1.0 1.0
Single Component 9 5 4 0.25 0.2
Single Component 19 4 7 0.57 1.0
Single Component 9 4 5 0.8 1.0
Single Component 10 4 3 0.33 0.25
Single Component 7 4 2 1.0 0.5
Single Component 8 4 5 0.6 0.75
Single Component 14 4 4 1.0 1.0
Single Component 4 4 2 1.0 0.5
Single Component 7 4 3 0.33 0.25
Single Component 10 3 2 0.0 0.0
Single Component 6 3 1 0.0 0.0
Single Component 4 3 2 0.5 0.33
Single Component 6 3 3 0.33 0.33
Single Component 3 3 2 1.0 0.67
Single Component 5 3 3 1.0 1.0
Single Component 5 3 2 0.5 0.33
Single Component 8 3 5 0.4 0.67
Single Component 7 3 4 0.5 0.67
Single Component 19 3 8 0.25 0.67
Single Component 9 3 8 0.38 1.0
Single Component 8 3 3 0.33 0.33
Single Component 8 3 4 0.5 0.67
Components with 2 incorrect labels 135 56 50 0.74 0.66
Components with 1 incorrect label 219 67 78 0.5 0.58
Components with 0 incorrect label 208 0 33 0.0 NaN
Overall 810 222 265 0.52 0.62
Table 7: Detailed precision and recall on dierent components when using GTDA to nd likely incorrect testing
labels of ChestX-ray14 dataset. Components are ordered by decreasing number of incorrect labels identied by
experts they contain. Results for components with less than 3 incorrect labels are reported together.
ยง7 Parameter selection of GTDA
In this section, we will discuss how to select parameters for our GTDA framework, es-
pecially the component size threshold and overlapping ratio in Algorithm 1. Currently, we
manually focus the Reeb net's structure by varying these parameters. It remains an open
question on how one might automatically select parameters for our GTDA framework as
proposed for other TDA frameworks [4]. Although GTDA has 8 parameters (Table 1), the
two most important are the component size threshold and the overlapping ratio.
ยง7.1 Selecting component size threshold
Recall that the component size threshold is the smallest component where we stop split-
ting. Choosing a good component size threshold depends on the dataset we want to analyze.
If the threshold is too small, we will end up with too many nodes to make the subsequent
52

--- PAGE 53 ---
Figure 29: We show dierent GTDA visualizations as we vary the component size threshold. The overlapping
ratio is xed as 1%. Using a large threshold will cause dierent classes to be mixed together and the structure
of small class like \Routers" or \Webcams" will be over simplied. As we gradually reduce the thresholds, the
number of nodes and edges in the visualization will increase as well and dierent classes will be separated into
several components. The results look similar between 100 and 200, which suggests GTDA structure are stable
with respect to small change in parameters.
visualization and analysis dicult. On the other hand, if the threshold is too large, the
topological structure of some small classes might be over simplied and components from
dierent classes can be mixed. Figure 29 shows how the Reeb net will change as we vary
component size threshold. In general, we start from a larger component size threshold and
then check the Reeb net we get, especially the size of the largest Reeb net component as
well as whether dierent classes are mixed. If we have a component that is too large to be
easily visualized or dierent classes are clearly mixed, we reduce this value. If the class sizes
are highly skewed, we usually choose the threshold based on the smallest class. In this case,
we the lower bound on the absolute dierence of the lens parameter becomes useful. This
is to avoid oversplitting class with large size, i.e., if the dierence is smaller than the lower
bound, we stop splitting as well.
We nd the results are stable to the choices and in particular, for uses to nd clues of
possible predicting errors or labeling issues from the visualization. As we can see in Figure 29,
choosing a threshold between 100 and 200 or choosing an overlapping ratio between 0.5% and
1.5% can all show the ambiguity in \Networking Products" v.s. \Routers" and some part of
\Data Storage" v.s. \Computer Components" allowing human insight into the predictions.
ยง7.2 Select overlapping ratio
The selection of overlapping ratio is similar to select component size threshold, we can
start from a larger ratio like 10% and then check the Reeb net to see if there is any component
that is too large or too mixed. If so, we need to gradually reduce the ratio until every
component can be properly visualized by a simple layout algorithm like spring layout [47] or
Kamada Kawai algorithm [16]. Figure 30 shows dierent Reeb nets as we vary overlapping
ratio.
53

--- PAGE 54 ---
Figure 30: We show dierent GTDA visualizations as we vary the overlapping ratio. The component size
threshold is xed as 100. Using a large overlapping ratio will cause dierent classes to be mixed together and
some components too large to be properly visualized. As we gradually reduce the overlapping ratio, dierent
classes will be separated into several components with each one easier to be plotted. Similar ambiguity in
\Networking Products" v.s. \Routers" and some part of \Data Storage" v.s. \Computer Components" can be
observed for overlapping ratio between 0.5% and 1.5%.
ยง7.3 Notes on other parameters
Other than component size threshold and overlapping ratio, Algorithm 1 has several other
parameters. Two important ones are the smallest node size and the smallest component size.
In our experiments, we can get consistently good visualizations by requiring the size of any
Reeb net node or Reeb net component larger than 5.
ยง8 Performance and scaling
Our GTDA framework scales to predictions with thousands of classes and millions of
datapoints. We only split along the lens with the maximum dierence at each iteration,
which can be easily recomputed in linear time in the data or even more eciently updated.
After each split, we immediately check all the connected components we have found, which
can be done in O(N+M) whereNis the number of nodes and Mis the number of edges.
It is dicult to estimate how many splitting iterations are needed. Assuming we have L
lenses, initially the min-max dierence across all lenses is 1 and the overlapping ratio is 0, then
we will need at most Literations before the largest min-max dierence across all components
is reduced to 0.5, which means at most O(tL) iterations are needed to reduce such dierence
below 2 t. If after a sucient number of iterations, we still see large components with size
bigger than K, it means new lenses are needed to further distinguish those nodes or a lower
bound on the dierence is needed to stop the splitting early.
Another step is to nd out which pairs of components have overlap. This can be easily
done in the original mapper algorithm by checking the adjacent bins of each bin. In our
GTDA framework, we rst build a bipartite graph with all component indices on one side,
all samples on the other side and connecting each component index to all samples it includes.
Then identifying the overlapping components is equivalent to nd 2-hop neighbors of each
component index, which can also be done in O(N+M). Finally, for the merging step, since
54

--- PAGE 55 ---
the size of each super node or the size of Reeb net component will be at least doubled, it
needs at most O(M(log(s1s2))) time. Also note that, many steps of our GTDA algorithm
can be easily parallelized. In our code, we mainly parallelize the merging steps using 10
cores, which has already given reasonable running time on graphs with millions of nodes and
edges.
Detailed running time for all datasets we have tested can be found in the table 8. All
running time are reported on a server with 2 AMD EPYC 7532 processors (128 cores in
total), 512 GB memory and one A100 GPU.
dataset nodes edges classes lenspredicting &
embedding (s)preprocessing (s) GTDA time (s)
Swiss Roll 1,000 3,501 3 3 0.003 0.3 1
Amazon Computers 39,747 399,410 10 10 0.17 7 10
Subset of ImageNet 13,394 51,520 10 10 27 5 7
ImageNet-1k
(ResNet vs AlexNet)1,331,167 5,954,900 1,000 2,000 2,379 717 26,036
ImageNet-1k
(VOLO vs ResNet)1,331,167 5,805,714 1,000 2,000 13,426 617 18,894
BRCA1 Gene Variants 23,376 83,096 2 4 18,583 21 3
Chest X-rays 112,120 431,893 2 16 821 35 26
Table 8: Statistics on datasets and running time in seconds. Predicting and embedding represents the time used
to generate prediction and extract embedding for all samples from a trained model. Preprocessing time includes
PCA, normalization as well as building a KNN graph if the original dataset is not in graph format. GTDA time
is the time to compute Reeb network given the input graph and the lens.
ยง9 Comparing to tSNE and UMAP
The goals of the Reeb net analysis from GTDA are distinct from the goals of dimen-
sion reduction techniques such as tSNE and UMAP. We seek the topological information
identied by the Reeb net. The Reeb net is both useful for generating pictures or maps of
the data as well as the algorithmic error estimate. We use the Kamada-Kawai [16] method
to compute a visualization of the Reeb net, which does have many similarities with sum-
mary pictures from tSNE and UMAP. We compare here GTDA results with visualization
from tSNE [48] and UMAP [2, 23] on all 4 datasets of the main text. For tSNE, we di-
rectly use the implementation from scikit-learn . For UMAP, we use the implementation
from https://umap-learn.readthedocs.io . The inputs to tSNE and UMAP are the con-
catenation of neural model embedding and prediction probability. We keep all parameters as
default except setting the number of nal dimension as 2. The results are shown in Figure 31.
These pictures support dierent uses and purposes. Reeb nets from GTDA oer a number
of compelling advantages as described throughout the main text and supplement. Among
others, note that GTDA is faster than tSNE (2 to 15 times faster) and UMAP (2 to 8 times
faster) in all 4 datasets. It also scales easily to datasets with millions of datapoints.
55

--- PAGE 56 ---
Figure 31: Comparing the results of the dimension reduction techniques tSNE and UMAP on 4 datasets to the
topological Reeb net structure from GTDA shows similarities and dierences among summary pictures generated
by these methods. The graph created by GTDA permits many types of analysis not clearly possible with tSNE
and UMAP output. For running time comparison, since we also need to extract model embeddings and
predictions just like GTDA, we exclude such time and only report the time of the actual execution of tSNE or
UMAP or GTDA (including Kamada-Kawai).
56

--- PAGE 57 ---
ยง10 Code availability
The implementation of GTDA framework we developed is available at
https://github.com/MengLiuPurdue/Graph-Topological-Data-Analysis
along with all supporting code for the results in this paper. Demos are found at
https://mengliupurdue.github.io/Graph-Topological-Data-Analysis/
and show the Reeb networks from the rst four gures. High resolution gures as well as an
animated demo are found at
https://github.com/MengLiuPurdue/Graph-Topological-Data-Analysis/tree/main/
high-res-figures
References
[1]Ziga Avsec, Vikram Agarwal, Daniel Visentin, Joseph R Ledsam, Agnieszka Grabska-
Barwinska, Kyle R Taylor, Yannis Assael, John Jumper, Pushmeet Kohli, and David R
Kelley. Eective gene expression prediction from sequence by integrating long-range
interactions. Nature methods , 18(10):1196{1203, 2021. Cited on pages 1, 4, and 39.
[2] Etienne Becht, Leland McInnes, John Healy, Charles-Antoine Dutertre, Immanuel W H
Kwok, Lai Guan Ng, Florent Ginhoux, and Evan W Newell. Dimensionality reduc-
tion for visualizing single-cell data using UMAP. Nature Biotechnology , 37(1):38{44,
December 2018. Cited on pages 2 and 55.
[3] Cristian Bodnar, C at alina Cangea, and Pietro Li o. Deep graph mapper: Seeing graphs
through the neural lens. Frontiers in big Data , 4, 2021. Cited on pages 1 and 9.
[4] Mathieu Carriere, Bertrand Michel, and Steve Oudot. Statistical analysis and parameter
selection for mapper. The Journal of Machine Learning Research , 19(1):478{516, 2018.
Cited on pages 19 and 52.
[5] Eli Chien, Jianhao Peng, Pan Li, and Olgica Milenkovic. Adaptive universal generalized
pagerank graph neural network. In International Conference on Learning Representa-
tions , 2021. Cited on pages 4, 20, and 21.
[6] Wyatt T Clark and Predrag Radivojac. Information-theoretic evaluation of predicted
ontological annotations. Bioinformatics , 29(13):i53{i61, 2013. Cited on page 50.
[7] Tamal K Dey, Facundo M emoli, and Yusu Wang. Multiscale mapper: Topological
summarization via codomain covers. In Proceedings of the twenty-seventh annual acm-
siam symposium on discrete algorithms , pages 997{1013. SIAM, 2016. Cited on pages
1 and 10.
[8] Martin Ester, Hans-Peter Kriegel, J org Sander, Xiaowei Xu, et al. A density-based algo-
rithm for discovering clusters in large spatial databases with noise. In KDD , volume 96,
pages 226{231, 1996. Cited on page 27.
57

--- PAGE 58 ---
[9] Andre Esteva, Brett Kuprel, Roberto A. Novoa, Justin Ko, Susan M. Swetter, Helen M.
Blau, and Sebastian Thrun. Dermatologist-level classication of skin cancer with deep
neural networks. Nature , 542(7639):115{118, January 2017. Cited on page 1.
[10] David F Gleich. Pagerank beyond the web. SIAM Review , 57(3):321{363, 2015. Cited
on page 10.
[11] Mustafa Hajij, Paul Rosen, and Bei Wang. Mapper on graphs for network visualization.
arXiv preprint arXiv:1804.11242 , 2018. Cited on page 9.
[12] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning
for image recognition. In 2016 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR) . IEEE, June 2016. Cited on pages 2 and 4.
[13] Jeremy Howard. Imagenette dataset. https://github.com/fastai/imagenette , 2021.
Cited on pages 4 and 24.
[14] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely
connected convolutional networks. In CVPR , pages 4700{4708, 2017. Cited on page 50.
[15] Qian Huang, Horace He, Abhay Singh, Ser-Nam Lim, and Austin Benson. Combining
label propagation and simple models out-performs graph neural networks. In Interna-
tional Conference on Learning Representations , 2021. Cited on page 16.
[16] Tomihisa Kamada, Satoru Kawai, et al. An algorithm for drawing general undirected
graphs. Information processing letters , 31(1):7{15, 1989. Cited on pages 11, 53, and 55.
[17] Pang Wei Koh and Percy Liang. Understanding black-box predictions via inuence
functions. In International conference on machine learning , pages 1885{1894. PMLR,
2017. Cited on pages 4, 27, and 28.
[18] Alex Krizhevsky, Ilya Sutskever, and Georey E Hinton. Imagenet classication with
deep convolutional neural networks. In Advances in Neural Information Processing
Systems , volume 25, 2012. Cited on pages 2 and 4.
[19] Maxat Kulmanov and Robert Hoehndorf. Deepgoplus: improved protein function pre-
diction from sequence. Bioinformatics , 36(2):422{429, 2020. Cited on page 50.
[20] Melissa J Landrum, Jennifer M Lee, Mark Benson, Garth R Brown, Chen Chao, Shan-
muga Chitipiralla, Baoshan Gu, Jennifer Hart, Douglas Homan, Wonhee Jang, et al.
Clinvar: improving access to variant interpretations and supporting evidence. Nucleic
acids research , 46(D1):D1062{D1067, 2018. Cited on page 39.
[21] Pek Y Lum, Gurjeet Singh, Alan Lehman, Tigran Ishkanov, Mikael Vejdemo-Johansson,
Muthu Alagappan, John Carlsson, and Gunnar Carlsson. Extracting insights from the
shape of complex data using topology. Scientic reports , 3(1):1{8, 2013. Cited on pages
1, 2, and 4.
58

--- PAGE 59 ---
[22] Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel. Image-
based recommendations on styles and substitutes. In Proceedings of the 38th interna-
tional ACM SIGIR conference on research and development in information retrieval ,
pages 43{52, 2015. Cited on pages 20 and 21.
[23] Leland McInnes, John Healy, and James Melville. Umap: Uniform manifold approxi-
mation and projection for dimension reduction. arXiv , stat.ML:1802.03426, 2018. Cited
on pages 2 and 55.
[24] W. James Murdoch, Chandan Singh, Karl Kumbier, Reza Abbasi-Asl, and Bin Yu.
Denitions, methods, and applications in interpretable machine learning. Proceedings
of the National Academy of Sciences , 116(44):22071{22080, October 2019. Cited on
page 4.
[25] Zaid Nabulsi, Andrew Sellergren, Shahar Jamshy, Charles Lau, Edward Santos, Atilla P
Kiraly, Wenxing Ye, Jie Yang, Rory Pilgrim, Sahar Kazemzadeh, et al. Deep learning
for distinguishing normal versus abnormal chest radiographs and generalization to two
unseen diseases tuberculosis and covid-19. Scientic reports , 11(1):1{15, 2021. Cited
on page 50.
[26] Gregory Naitzat, Andrey Zhitnikov, and Lek-Heng Lim. Topology of deep neural net-
works. J. Mach. Learn. Res. , 21:184:1{184:40, 2020. Cited on page 1.
[27] M. E. J. Newman and M. Girvan. Finding and evaluating community structure in
networks. Phys. Rev. E , 69(2):026113, Feb 2004. Cited on page 48.
[28] Monica Nicolau, Arnold J. Levine, and Gunnar Carlsson. Topology based data analysis
identies a subgroup of breast cancers with a unique mutational prole and excellent
survival. Proc. Natl. Acad. Sci. , 108(17):7265{7270, April 2011. Cited on page 1.
[29] Curtis G. Northcutt, Lu Jiang, and Isaac L. Chuang. Condent learning: Estimat-
ing uncertainty in dataset labels. Journal of Articial Intelligence Research (JAIR) ,
70:1373{1411, 2021. Cited on pages 16 and 51.
[30] Lauren Oakden-Rayner, William Gale, Thomas A Bonham, Matthew P Lungren, Gus-
tavo Carneiro, Andrew P Bradley, and Lyle J Palmer. Validation and algorithmic audit
of a deep learning system for the detection of proximal femoral fractures in patients
in the emergency department: a diagnostic accuracy study. The Lancet Digital Health ,
4(5):e351{e358, May 2022. Cited on page 1.
[31] Xuebin Qin, Zichen Zhang, Chenyang Huang, Masood Dehghan, Osmar R Zaiane, and
Martin Jagersand. U2-net: Going deeper with nested u-structure for salient object
detection. Pattern Recognition , 106:107404, 2020. Cited on page 25.
[32] Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony
Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, et al. Chexnet:
Radiologist-level pneumonia detection on chest x-rays with deep learning. arXiv preprint
arXiv:1711.05225 , 2017. Cited on page 50.
59

--- PAGE 60 ---
[33] Ali S Razavian, Josephine Sullivan, Stefan Carlsson, and Atsuto Maki. Visual instance
retrieval with deep convolutional networks. ITE Transactions on Media Technology and
Applications , 4(3):251{258, 2016. Cited on page 25.
[34] Markus Reichstein, Gustau Camps-Valls, Bjorn Stevens, Martin Jung, Joachim Denzler,
Nuno Carvalhais, and Prabhat. Deep learning and process understanding for data-driven
earth system science. Nature , 566(7743):195{204, February 2019. Cited on page 1.
[35] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. " why should i trust you?"
explaining the predictions of any classier. In Proceedings of the 22nd ACM SIGKDD
international conference on knowledge discovery and data mining , pages 1135{1144,
2016. Cited on page 24.
[36] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C.
Berg, and Li Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International
Journal of Computer Vision (IJCV) , 115(3):211{252, 2015. Cited on pages 2 and 32.
[37] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam,
Devi Parikh, and Dhruv Batra. Grad-cam: Visual explanations from deep networks via
gradient-based localization. In Proceedings of the IEEE International Conference on
Computer Vision , pages 618{626, 2017. Cited on page 24.
[38] Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, and Stephan
G unnemann. Pitfalls of graph neural network evaluation. arXiv preprint
arXiv:1811.05868 , 2018. Cited on pages 20, 21, 22, and 24.
[39] Dustin Shigaki, Orit Adato, Aashish N Adhikari, Shengcheng Dong, Alex Hawkins-
Hooker, Fumitaka Inoue, Tamar Juven-Gershon, Henry Kenlay, Beth Martin, Ayoti
Patra, et al. Integration of multiple epigenomic marks improves prediction of variant
impact in saturation mutagenesis reporter assay. Human mutation , 40(9):1280{1291,
2019. Cited on page 39.
[40] Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. Deep inside convolutional
networks: Visualising image classication models and saliency maps. In Yoshua Bengio
and Yann LeCun, editors, ICLR (workshop track) , 2014. Cited on page 24.
[41] Gurjeet Singh, Facundo M emoli, and Gunnar E Carlsson. Topological methods for the
analysis of high dimensional data sets and 3d object recognition. SPBG , 91:100, 2007.
Cited on pages 1, 4, and 8.
[42] Jost Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, and Martin Riedmiller.
Striving for simplicity: The all convolutional net. In ICLR (workshop track) , 2015.
Cited on page 24.
[43] B. Strodtho and B. J uttler. Layered reeb graphs for three-dimensional manifolds in
boundary representation. Computers & Graphics , 46:186{197, 2015. Shape Modeling
International 2014. Cited on page 18.
60

--- PAGE 61 ---
[44] Joshua B. Tenenbaum, Vin de Silva, and John C. Langford. A global geometric frame-
work for nonlinear dimensionality reduction. Science , 290(5500):2319{2323, 2000. Cited
on page 2.
[45] Raphael J. L. Townshend, Stephan Eismann, Andrew M. Watkins, Ramya Rangan,
Maria Karelina, Rhiju Das, and Ron O. Dror. Geometric deep learning of RNA struc-
ture. Science , 373(6558):1047{1051, August 2021. Cited on page 1.
[46] Edward Tufte. Seeing with fresh eyes: Meaning, Space, Data, Truth . Graphics Press,
2020. Cited on page 24.
[47] William Thomas Tutte. How to draw a graph. Proceedings of the London Mathematical
Society , 3(1):743{767, 1963. Cited on page 53.
[48] Laurens van der Maaten and Georey Hinton. Visualizing data using t-sne. Journal of
Machine Learning Research , 9(86):2579{2605, 2008. Cited on pages 2 and 55.
[49] Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, Mohammadhadi Bagheri, and
Ronald M Summers. Chestx-ray8: Hospital-scale chest x-ray database and bench-
marks on weakly-supervised classication and localization of common thorax diseases.
InProceedings of the IEEE conference on computer vision and pattern recognition , pages
2097{2106, 2017. Cited on pages 4 and 50.
[50] Li Yuan, Qibin Hou, Zihang Jiang, Jiashi Feng, and Shuicheng Yan. VOLO: Vision
outlooker for visual recognition, 2021. Cited on page 4.
[51] John R. Zech, Marcus A. Badgeley, Manway Liu, Anthony B. Costa, Joseph J. Titano,
and Eric Karl Oermann. Variable generalization performance of a deep learning model
to detect pneumonia in chest radiographs: A cross-sectional study. PLOS Medicine ,
15(11):e1002683, November 2018. Cited on page 1.
[52] Bin Zhao, Fei Li, and Eric Xing. Large-scale category structure aware image categoriza-
tion. In Advances in Neural Information Processing Systems , volume 24, 2011. Cited
on page 4.
[53] Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. Learn-
ing deep features for discriminative localization. In Proceedings of the IEEE conference
on computer vision and pattern recognition , pages 2921{2929, 2016. Cited on page 24.
61

# 2308.09267.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/knowledge-graph/2308.09267.pdf
# Kích thước tệp: 716169 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
GraphReason: Nâng cao Khả năng Lý luận của Mô hình Ngôn ngữ Lớn
thông qua Phương pháp Xác minh dựa trên Đồ thị
Lang Cao
University of Illinois Urbana-Champaign
Department of Computer Science
langcao2@illinois.edu
Tóm tắt
Các Mô hình Ngôn ngữ Lớn (LLMs) đã thể hiện khả năng lý luận ấn tượng, đặc biệt khi được hướng dẫn bởi các prompt được thiết kế cụ thể trong các nhiệm vụ lý luận phức tạp như bài toán từ toán học. Những mô hình này thường giải quyết các nhiệm vụ bằng cách sử dụng phương pháp chuỗi suy nghĩ, điều này không chỉ tăng cường khả năng lý luận của chúng mà còn cung cấp những hiểu biết có giá trị về quá trình giải quyết vấn đề của chúng. Tuy nhiên, vẫn còn nhiều chỗ để cải thiện khả năng lý luận của LLMs. Một số nghiên cứu cho rằng việc tích hợp một bộ xác minh đầu ra LLM có thể tăng độ chính xác lý luận mà không cần đào tạo thêm mô hình. Trong bài báo này, chúng tôi tuân theo những nghiên cứu này và giới thiệu một phương pháp mới dựa trên đồ thị để tăng cường thêm khả năng lý luận của LLMs. Chúng tôi đề xuất rằng nhiều giải pháp cho một nhiệm vụ lý luận, được tạo ra bởi một LLM, có thể được biểu diễn như một đồ thị lý luận do các kết nối logic giữa các bước trung gian từ các đường lý luận khác nhau. Do đó, chúng tôi đề xuất Bộ Xác minh Đồ thị Lý luận (GraphReason) để phân tích và xác minh các giải pháp được tạo ra bởi LLMs. Bằng cách đánh giá những đồ thị này, các mô hình có thể mang lại kết quả chính xác và đáng tin cậy hơn. Kết quả thí nghiệm của chúng tôi cho thấy phương pháp xác minh dựa trên đồ thị của chúng tôi không chỉ nâng cao đáng kể khả năng lý luận của LLMs mà còn vượt trội hơn các phương pháp xác minh hiện có về mặt cải thiện hiệu suất lý luận của những mô hình này.

1 Giới thiệu
Các Mô hình Ngôn ngữ Lớn (LLMs) đã chứng minh khả năng đặc biệt trong nhiều nhiệm vụ của con người (Zhao et al., 2023). Trong số nhiều khả năng mà LLMs sở hữu, khả năng lý luận của chúng có tầm quan trọng tối cao (Kojima et al., 2023; Huang and Chang, 2023). Điều này đã được chứng minh bằng những tiến bộ gần đây (Wei et al., 2022; Zhou et al., 2023; Lampinen et al., 2022a). Được trang bị khả năng lý luận, đặc biệt là theo cách đa bước, LLMs có thể phân tách các vấn đề phức tạp thành các nhiệm vụ đơn giản hơn, từ đó tạo điều kiện thuận lợi cho việc giải quyết chúng. Trong cuộc sống hàng ngày, nhiều nhiệm vụ phức tạp thường yêu cầu giải pháp đa bước. Một ví dụ điển hình về nhiệm vụ lý luận là lý luận số học, còn được gọi là giải bài toán từ toán học (Zhang et al., 2019). Những bài toán từ toán học này đại diện cho các phiên bản đơn giản hóa của các tình huống phức tạp trong đời thực.

Khả năng lý luận vốn có trong các Mô hình Ngôn ngữ Lớn (LLMs), nhưng nó cần những phương pháp cụ thể để biểu hiện. Để kích hoạt khả năng lý luận mạnh mẽ của LLMs, việc sử dụng các prompt được thiết kế đặc biệt cần được xem xét. Nhiều phương pháp đã được đề xuất để khai thác tiềm năng này, trong đó lý luận chuỗi suy nghĩ (Wei et al., 2022) và học trong ngữ cảnh (Lampinen et al., 2022b) là hai phương pháp đáng chú ý. Lý luận chuỗi suy nghĩ có thể làm sáng tỏ các đường lý luận trong quá trình. Học trong ngữ cảnh cung cấp cho LLMs các trường hợp mẫu, từ đó cho phép chúng học hỏi và mô phỏng những ví dụ này để có kết quả tốt hơn. Trong kịch bản lý luận số học, GPT-4 có thể đạt độ chính xác 92% trên bộ dữ liệu GSM8K bằng cách sử dụng prompt chuỗi suy nghĩ 5-shot (Cobbe et al., 2021a). Điều này đại diện cho mức độ khó mà một học sinh trung học cơ sở thông minh nên có khả năng xử lý. Như được mô tả trong Hình 1, điều này minh họa một quá trình lý luận số học đa bước trong LLMs.

Q: Những con vịt của Janet đẻ 16 quả trứng mỗi ngày. Cô ấy ăn ba quả cho bữa sáng mỗi sáng và nướng bánh muffin cho bạn bè mỗi ngày với bốn quả. Cô ấy bán phần còn lại ở chợ nông sản hàng ngày với giá $2 mỗi quả trứng vịt tươi. Cô ấy kiếm được bao nhiêu đô la mỗi ngày ở chợ nông sản?
A: Bước 1: Janet bán 16 -3 -4 = <<16-3-4=9>>9 quả trứng vịt mỗi ngày.
Bước 2: Cô ấy kiếm được 9 * 2 = $<<9*2=18>>18 mỗi ngày ở chợ nông sản.
Bước 3: #### 18
...... (Thêm các Ví dụ Mẫu) ......
Q: Một chiếc áo choàng cần 2 cuộn sợi xanh và một nửa số đó sợi trắng. Tổng cộng cần bao nhiêu cuộn?
A: Bước 1: Cần 2/2=<<2/2=1>>1 cuộn sợi trắng.
Bước 2: Vậy tổng lượng vải là 2+1=<<2+1=3>>3 cuộn vải.
Bước 3: #### 3

Lý luận Chuỗi Suy nghĩ trong Bài toán Từ Toán học

Giải pháp được tạo ra bởi LLM
Các Ví dụ mẫu với Giải pháp từng bước
Câu hỏi Hiện tại

Hình 1: Một ví dụ về lý luận chuỗi suy nghĩ trong một bài toán từ toán học, sử dụng dữ liệu từ bộ dữ liệu GSM8K. Các mô hình ngôn ngữ lớn học từ các ví dụ mẫu cung cấp giải pháp từng bước, sau đó tạo ra đường lý luận của chúng cho câu hỏi hiện tại.

Ngoài việc đào tạo thêm LLMs và thiết kế prompt, một số phương pháp đã được đề xuất để nâng cao khả năng lý luận của LLMs từ góc độ xác minh đầu ra. Ý tưởng chính là để LLMs tạo ra đường lý luận nhiều lần, sau đó thiết kế một bộ xác minh để đánh giá những đường này và đưa ra kết quả cuối cùng. (Wang et al., 2023) giới thiệu khái niệm tự nhất quán, dựa trên trực giác rằng một vấn đề lý luận phức tạp thường cho phép nhiều quá trình suy nghĩ, tất cả đều dẫn đến một câu trả lời đúng duy nhất. (Li et al., 2023) cũng đề xuất All Roads Lead to Rome, giới thiệu một bộ xác minh nhận biết bước để phân tích đường lý luận không chỉ thông qua toàn bộ đường đi, mà ở mọi bước. Tuy nhiên, cả hai phương pháp đều coi mỗi đường lý luận như một thực thể độc lập và không xem xét mối tương quan và tương tác tiềm năng giữa các đường lý luận khác nhau. Một khi các đường lý luận được tháo rời thành các bước, các bước trung gian từ một đường có thể mang quan hệ lý luận với các đường lý luận khác. Những phương pháp này không nhận thức tất cả đầu ra LLM cho một đầu vào nhất định như một thực thể tập thể, từ đó không phân tích được mối quan hệ nội bộ của tất cả đường ứng viên một cách sâu sắc.

Được truyền cảm hứng từ những quan sát này, chúng tôi đề xuất Bộ Xác minh Đồ thị Lý luận (GraphReason) trong bài báo này. Chúng tôi đề xuất rằng các đường lý luận của một câu hỏi có thể tạo thành đồ thị lý luận, nơi các bước lý luận trung gian tương tự có thể được hợp nhất thành cùng một nút. Với cấu trúc đồ thị, chúng ta có thể mô hình hóa và nắm bắt logic lý luận giữa các bước trung gian từ các đường lý luận khác nhau một cách hiệu quả hơn. Cụ thể, chúng tôi đầu tiên xây dựng một đồ thị lý luận dựa trên tất cả đầu ra từ LLMs, sau đó đào tạo một bộ xác minh để học mối quan hệ giữa cấu trúc đồ thị và câu trả lời cuối cùng. Trong giai đoạn dự đoán, chúng tôi xử lý dữ liệu theo cách tương tự như trong giai đoạn đào tạo, và sử dụng bộ xác minh để đánh giá mỗi đồ thị lý luận. Sau đó chúng tôi chọn đồ thị lý luận có điểm số cao nhất, sử dụng câu trả lời của nó làm câu trả lời cuối cùng. Theo hiểu biết tốt nhất của chúng tôi, chúng tôi là những người đầu tiên tiếp cận logic lý luận của LLMs từ góc độ đồ thị. Chúng tôi tiến hành các thí nghiệm mở rộng để chứng minh những cải thiện so với LLMs gốc, và cho thấy phương pháp của chúng tôi vượt trội hơn các bộ xác minh khác.

Tóm lại, những đóng góp của chúng tôi như sau:
• Chúng tôi đề xuất một phương pháp xác minh dựa trên đồ thị, GraphReason, nhằm nâng cao đáng kể khả năng lý luận của các mô hình ngôn ngữ lớn mà không cần đào tạo thêm LLMs.
• Chúng tôi thiết lập một tiêu chuẩn lý luận số học sử dụng ba bộ dữ liệu Bài toán Từ Toán học để minh họa hiệu suất lý luận cơ bản của các mô hình ngôn ngữ lớn, và cung cấp so sánh công bằng về hiệu suất của các bộ xác minh hiện có khác nhau.
• Kết quả thí nghiệm của chúng tôi chỉ ra rằng phương pháp được đề xuất trong bài báo này vượt trội hơn các phương pháp nâng cao khác. Chúng tôi cũng cung cấp phân tích mở rộng về các hạn chế và tiềm năng tương lai của GraphReason.

2 Công trình Liên quan
Lý luận của Mô hình Tinh chỉnh đã được nghiên cứu rộng rãi. Nó tập trung vào việc giải quyết các nhiệm vụ lý luận bằng cách sử dụng phương pháp chuỗi-đến-chuỗi tổng quát, được tăng cường bởi việc tiền đào tạo hoặc tinh chỉnh nhận biết lý luận của các mô hình ngôn ngữ. (Cobbe et al., 2021a) đề xuất đào tạo một bộ xác minh để xếp hạng các giải pháp được lấy mẫu từ các mô hình ngôn ngữ được tinh chỉnh. (Yoran et al., 2022; Wang et al., 2022) đề xuất trang bị cho các mô hình ngôn ngữ khả năng lý luận bằng cách tạo ra các ví dụ đào tạo với các mẫu được thiết kế bởi con người. (Pi et al., 2022) đề xuất tiêm khả năng lý luận vào các mô hình ngôn ngữ bằng cách tiếp tục tiền đào tạo trên dữ liệu thực thi chương trình.

Một số nghiên cứu đã tập trung vào việc truyền khả năng lý luận cho PLM cho các nhiệm vụ cụ thể, như lý luận số học (Cobbe et al., 2021a; Miao et al., 2020; Patel et al., 2021), lý luận thường thức (Talmor et al., 2019), và lý luận quy nạp (Sinha et al., 2019). Ví dụ, nhiều chiến lược khác nhau đã được đề xuất để cải thiện hiệu suất của các mô hình ngôn ngữ trên các nhiệm vụ lý luận số học, thường được gọi là bài toán từ toán học. (Xie and Sun, 2019) đề xuất một bộ giải mã có cấu trúc cây để tạo ra một cây phương trình, trong khi (Zhang et al., 2020) áp dụng mạng nơ-ron tích chập đồ thị để trích xuất mối quan hệ

--- TRANG 3 ---
của các số lượng trong bài toán toán học. (Li et al., 2022) sử dụng học tương phản để học tốt hơn các mẫu trong bài toán từ toán học. Tuy nhiên, (Valmeekam et al., 2023; Rae et al., 2022) cho rằng lý luận, đặc biệt là lý luận đa bước, thường là điểm yếu trong các mô hình ngôn ngữ và các mô hình NLP khác.

Lý luận của Mô hình Ngôn ngữ Lớn đã thu hút sự chú ý đáng kể và thể hiện tiềm năng to lớn. Những tiến bộ gần đây trong LLMs cho rằng khả năng lý luận đa bước đã được nhúng trong những mô hình quy mô lớn này (Kojima et al., 2023; Huang and Chang, 2023), như PaLM (Chowdhery et al., 2022), GPT-4 (OpenAI, 2023). Do đó, việc cung cấp một prompt đầy đủ là đủ để sử dụng khả năng lý luận này. Ví dụ, phương pháp prompting được đề xuất bởi (Kojima et al., 2023; Wei et al., 2022), dựa trên chuỗi suy nghĩ, có thể hỗ trợ LLMs trong việc tạo ra văn bản với lý luận số học và kiến thức thực tế thông thường. Theo (Wei et al., 2022), các thí nghiệm trên các mô hình ngôn ngữ hiện tại đã chứng minh rằng prompting chuỗi suy nghĩ có thể nâng cao độ chính xác giải bài toán toán học từ 18% lên 57%. (Lampinen et al., 2022b) bao gồm giải thích trong các ví dụ trong ngữ cảnh và thử nghiệm ảnh hưởng của giải thích bằng cách đánh giá điểm số giữa giải thích-rồi-dự đoán và dự đoán-rồi-giải thích. Hơn nữa, (Zhou et al., 2023) đề xuất chiến lược prompting hai giai đoạn, prompting từ ít nhất đến nhiều nhất, phân tách một vấn đề phức tạp thành một chuỗi các vấn đề con và giải quyết chúng từng bước. (Li et al., 2023) đề xuất lấy mẫu nhiều lần từ các prompt đa dạng để tăng cường sự đa dạng của phản hồi.

Ngoài việc thiết kế prompt, việc áp dụng các chiến lược bổ sung như bộ xác minh đã góp phần nâng cao hiệu suất của khả năng lý luận của các mô hình ngôn ngữ lớn. Ví dụ, (Wang et al., 2023) đề xuất tự nhất quán, bao gồm việc lấy mẫu các đường lý luận khác nhau từ mô hình ngôn ngữ, sau đó trả về câu trả lời cuối cùng nhất quán nhất thông qua bỏ phiếu đa số. (Li et al., 2023) sử dụng bộ xác minh bỏ phiếu nhận biết bước để nâng cao khả năng lý luận của LLMs từ hai góc độ. Những phương pháp này nỗ lực tăng cường khả năng lý luận hoặc mang lại kết quả lý luận vượt trội mà không cần đào tạo thêm LLMs. Công trình của chúng tôi tiếp tục hướng nghiên cứu này, với sự tập trung cụ thể vào việc phát triển một bộ xác minh dựa trên đồ thị mới để thúc đẩy khả năng lý luận của LLMs.

3 Phương pháp luận
3.1 Khung GraphReason
Vấn đề 1 (Lý luận để Giải quyết Vấn đề)
Cho một tập hợp n bài toán từ toán học Q={Q1, Q2, ..., Qn}, trong đó mỗi Qi được biểu diễn bằng mô tả văn bản của một bài toán từ toán học đơn lẻ, mục tiêu của lý luận để giải bài toán từ toán học là tạo ra câu trả lời A={A1, A2, ..., An} cho những vấn đề này. Ở đây, mỗi Ai đại diện cho văn bản được tạo ra của câu trả lời tương ứng. Trong quá trình các mô hình ngôn ngữ lớn tạo ra câu trả lời, một tập hợp n đường lý luận cho giải pháp S={S1, S2, ..., Sn} cũng được tạo ra. Mỗi giải pháp Si được biểu diễn là Si={Q, Bước 1, Bước 2, ..., Bước l, A}, trong đó mỗi Bước i biểu thị các bước trung gian trong giải pháp từng bước.

Chúng tôi đề xuất GraphReason để xác minh các giải pháp được tạo ra bởi LLMs nhằm cải thiện độ chính xác câu trả lời cuối cùng. Phương pháp này là một kỹ thuật xác minh dựa trên đồ thị phân tích các đường lý luận từ giải pháp được tạo ra từ góc độ đồ thị. Câu trả lời cuối cùng được thu được mà không sửa đổi LLMs gốc, hoạt động giống như một plugin. Như được minh họa trong Hình 2, có hai bước trong giai đoạn đào tạo: Xây dựng Đồ thị và Phân loại Đồ thị. Trong bước Xây dựng Đồ thị, chúng tôi thu được giải pháp được tạo ra từ LLMs với prompt được thiết kế cụ thể và nhóm chúng theo câu trả lời cuối cùng của chúng. Chúng tôi chia đường lý luận theo các bước và sau đó hợp nhất các bước trung gian có biểu thức giống hệt nhau để tạo thành đồ thị lý luận. Trong bước Phân loại Đồ thị, chúng tôi phân loại những đồ thị lý luận này với tính năng bổ sung của tổng điểm số từ bộ xác minh cơ sở để đào tạo mô hình xác minh tích hợp. Trong giai đoạn dự đoán, các giải pháp ứng viên đầu tiên được tạo ra bởi LLMs. Chúng tôi xử lý chúng theo cách tương tự như trong giai đoạn đào tạo, sau đó chúng tôi sử dụng bộ xác minh đã được đào tạo để đánh giá điểm số của mỗi giải pháp ứng viên. Giải pháp tốt nhất, được biểu thị bằng điểm số cao nhất, được chọn làm câu trả lời dự đoán cuối cùng. Bây giờ chúng tôi sẽ giới thiệu chi tiết toàn bộ quy trình.

3.2 Thiết kế Prompt
Để cải thiện đầu ra của Mô hình Ngôn ngữ (LLMs) trong việc cung cấp giải pháp, việc thiết kế các prompt hiệu quả là rất quan trọng. Chúng tôi kết hợp chuỗi suy nghĩ và học trong ngữ cảnh để cho phép LLMs tạo ra câu trả lời từng bước cho bài toán từ toán học. Các mô hình ngôn ngữ tạo ra đầu ra y dựa trên

--- TRANG 4 ---
Giai đoạn Đào tạo    Giai đoạn Dự đoán
Bộ Xác minh Cơ sở
1 hoặc 0
Giải pháp được tạo ra với cùng Câu trả lời A
Bộ Xây dựng Đồ thị
Bộ Phân loại GNN
Tổng
Nối
Bộ Xác minh Đồ thị Lý luận
Điểm số 1
Điểm số 2
Điểm số n
Câu trả lời Cuối cùng
Ví dụ Mẫu & Câu hỏi
Mô hình Ngôn ngữ Lớn
Giải pháp được tạo ra với cùng Câu trả lời
Điểm số của Mọi Giải pháp
Đồ thị Lý luận
Argmax

Hình 2: Khung của GraphReason. Trong giai đoạn đào tạo, GraphReason xử lý các giải pháp được tạo ra từ LLMs để xây dựng đồ thị lý luận, sau đó đào tạo một bộ xác minh để đánh giá chúng theo phân loại đồ thị. Trong giai đoạn dự đoán, GraphReason đánh giá các giải pháp ứng viên để gán điểm số, và chọn giải pháp có điểm số cao nhất làm câu trả lời cuối cùng.

đầu vào x sử dụng phương trình sau:
p(y|C,x) = ∏[t=1 đến |y|] pLM(yt|C,x,y<t),    (1)

trong đó, C đại diện cho đầu vào được cung cấp cho LLMs trước câu hỏi bài toán từ toán học hiện tại. C là một phép nối của k ví dụ mẫu, được biểu thị là:
C = [(Q1, S1, A1); (Q2, S2, A2), ...; (Qk, Sk, Ak)],    (2)

trong đó, Qi đại diện cho câu hỏi, Si đại diện cho các bước trung gian của giải pháp, và Ai đại diện cho câu trả lời. Chúng tôi đặt k bằng năm trong nghiên cứu này, tạo ra một prompt bao gồm năm cặp câu hỏi-câu trả lời được lấy mẫu từ phần chia đào tạo của bộ dữ liệu bài toán từ toán học. Do đó, prompt có thể được biểu thị là:
Prompt = [C;Q],    (3)

trong đó Q đại diện cho câu hỏi của bài toán từ toán học hiện tại.

Sử dụng phương pháp giải mã tham lam để lấy mẫu một đầu ra từ LLMs có thể không mạnh mẽ. Nó có thể dẫn đến sự không ổn định và lỗi thỉnh thoảng. Để giải quyết điều này, (Wang et al., 2023) đề xuất khái niệm tự nhất quán. Phương pháp này bao gồm việc lấy mẫu các đường lý luận khác nhau từ mô hình ngôn ngữ và sau đó chọn câu trả lời cuối cùng nhất quán nhất thông qua bỏ phiếu đa số. Thay vì sử dụng giải mã tham lam để chỉ lấy mẫu một lần và xác minh, họ sử dụng giải mã lấy mẫu để lấy mẫu N1 lần. Chúng tôi cũng tuân theo ý tưởng được trình bày bởi (Li et al., 2023) trong công trình của họ có tên All Roads Lead to Rome. Phương pháp này bao gồm việc tạo ra N2 prompt đa dạng cho LLMs để tạo ra nhiều đầu ra. Bằng cách sử dụng nhiều giải mã lấy mẫu trên các prompt đa dạng, chúng ta có thể thu được các giải pháp được tạo ra từ các nguồn khác nhau. Cụ thể, chúng tôi thu được N = N1 × N2 đường lý luận đa dạng cho mỗi câu hỏi. Trong các thí nghiệm chính của chúng tôi, chúng tôi đặt N1 = 10 và N2 = 3. Những giải pháp này sẽ được xử lý thêm và xác minh bằng bộ xác minh được thiết kế của chúng tôi.

3.3 Xây dựng Đồ thị Lý luận
Sau khi tạo ra nhiều giải pháp cho một câu hỏi, việc xây dựng đồ thị lý luận dựa trên các đường lý luận được thực hiện bởi những giải pháp này trở nên cần thiết.

Như được hiển thị trong Hình 3, chúng tôi bắt đầu bằng cách nhóm tất cả các giải pháp được tạo ra cho một câu hỏi cụ thể theo câu trả lời cuối cùng của chúng. Vì những giải pháp này bắt nguồn từ cùng một câu hỏi, đường lý luận của chúng sẽ chia sẻ cùng một điểm bắt đầu. Tương tự, các giải pháp có cùng câu trả lời cuối cùng sẽ có cùng điểm kết thúc, vì đường lý luận của chúng hội tụ. Do đó, một nhóm các giải pháp được tạo ra với cùng câu trả lời cuối cùng có thể tạo thành một đồ thị lý luận với nút bắt đầu thống nhất (nút câu hỏi) và nút kết thúc (nút câu trả lời). Chúng tôi định nghĩa quá trình phân chia này như sau:
S = {SA1, SA2, ..., SAn},    (4)

trong đó S đại diện cho tập hợp các giải pháp được tạo ra cho một câu hỏi, và SAi = {S1, S2, ..., Sm} là tập con của các giải pháp được tạo ra mà tất cả đều có cùng câu trả lời cuối cùng Ai.

Đối với mỗi tập con giải pháp được tạo ra SAi, chúng tôi xây dựng một đồ thị lý luận. Việc xây dựng này được thúc đẩy bởi sự hiểu biết rằng mỗi bước trong đường lý luận của một giải pháp được tạo ra không tồn tại cô lập với các giải pháp khác. Các bước từ đường lý luận của một giải pháp có thể tác động đến các bước từ giải pháp khác, nâng cao quá trình lý luận tổng thể. Chúng tôi sử dụng cấu trúc đồ thị để mô hình hóa và nắm bắt những mối quan hệ này giữa các bước từ các giải pháp khác nhau. Vì các đường lý luận khác nhau có thể mang lại lợi ích cho nhau, chúng tôi xây dựng

--- TRANG 5 ---
Ví dụ Mẫu & Câu hỏi
Mô hình Ngôn ngữ Lớn
Giải pháp 1
Giải pháp được tạo ra với cùng Câu trả lời A1
Xây dựng Đồ thị Lý luận theo Đường Lý luận

Giải pháp được tạo ra với cùng Câu trả lời A2

Giải pháp được tạo ra với cùng Câu trả lời An

Câu hỏi
S1 Bước 1
S1 Bước 2
S1 Bước L
Câu trả lời Cuối cùng
S2 Bước 1
S2 Bước 2
S2 Bước L
Sm Bước 1
Sm Bước 2
Sm Bước L

Đồ thị 2
Nút Câu hỏi
Hợp nhất các Nút Bước Giống nhau

Đồ thị n

Giải pháp 2
Giải pháp m
Quy trình Chi tiết

Nút Câu trả lời
Bộ Xây dựng Đồ thị

Hình 3: Bộ xây dựng đồ thị trong GraphReason. Chúng tôi mô tả chi tiết quy trình chuyển đổi 'Giải pháp được tạo ra với cùng Câu trả lời A1' thành 'Đồ thị 1'.

Câu hỏi
S1 Bước 1
S1 Bước 2
S1 Bước 3
Câu trả lời Cuối cùng
S2 Bước 1
S2 Bước 2
S2 Bước 3

Nếu S1.Bước2 bằng S2.Bước2
Đồ thị 1 Trạng thái 1

Câu hỏi
S1 Bước 1
Nút Bước
S1 Bước 3
Câu trả lời Cuối cùng
S2 Bước 1
S2 Bước 3

Đồ thị 1 Trạng thái 2

Hình 4: Quy trình xây dựng đồ thị lý luận. Hoạt động chính ở đây là việc hợp nhất các bước trung gian giống hệt nhau trong đường lý luận thành một nút đồ thị duy nhất.

một đồ thị lý luận để liên kết những đường này với nhau. Như được hiển thị trong Hình 4, hoạt động chính ở đây là việc hợp nhất các nút trung gian giống hệt nhau trong đường lý luận thành một nút đồ thị duy nhất. Chúng tôi đầu tiên so sánh các bước lý luận từ bất kỳ hai đường lý luận giải pháp nào. Nếu chúng có cùng các bước trung gian của biểu thức số học, chúng tôi hợp nhất chúng thành cùng một nút, và nếu chúng khác nhau, chúng tôi không làm vậy. Đối với việc lý luận bài toán từ toán học ở đây, chúng tôi định nghĩa các bước lý luận là biểu thức số học hiện tại mà không có văn bản ngôn ngữ khác trong bước lý luận hiện tại để rõ ràng. Nó có thể giúp chúng ta đơn giản hóa việc xây dựng đồ thị lý luận trong nhiệm vụ lý luận. Thuật toán chi tiết để xây dựng đồ thị lý luận được hiển thị trong Thuật toán 1.

Các giải pháp được tạo ra, được chia theo câu trả lời cuối cùng của chúng {SA1, SA2, ..., SAn}, có thể được chuyển đổi thành n đồ thị lý luận của giải pháp được tạo ra {GA1, GA2, ..., GAn}.

Về các đặc trưng nút trong đồ thị, chúng tôi chọn điểm số từ Bộ Xác minh Cơ sở và bậc nút. Chúng tôi tin rằng điểm số từ Bộ Xác minh Cơ sở đóng gói thông tin ngữ nghĩa của giải pháp, và bậc nút chứa thông tin về cấu trúc đồ thị. Bộ Xác minh Cơ sở được đào tạo độc lập với toàn bộ khung. Nó được thiết kế để đánh giá xem một đường lý luận đơn lẻ của một giải pháp có đúng hay không, đây là một nhiệm vụ phân loại văn bản nhị phân. Sau khi đào tạo, nó có thể được sử dụng để xác minh bất kỳ giải pháp đơn lẻ nào và gán một điểm số ∈ (0,1) để đánh giá khả năng giải pháp đó đúng, trong đó điểm số = 0.99 gợi ý 99% xác suất giải pháp đó đúng. Chúng tôi sử dụng điểm số từ Bộ Xác minh Cơ sở để tích hợp tốt hơn thông tin ngữ nghĩa giải pháp vì, theo các thí nghiệm của chúng tôi, việc mô hình hóa thông tin ngữ nghĩa trong khi mô hình hóa thông tin logic lý luận là thách thức. Điểm số của một bước giống như điểm số giải pháp của nó. Do đó, đối với một nút bước V, nó có nhiều điểm số {scorea, scoreb, ..., scorec} từ các giải pháp khác nhau. Đặc trưng của một nút Vi trong đồ thị sau đó được nối bởi đặc trưng được chọn, có thể được biểu diễn là:

V = [scoremean_i, scoremax_i, scoremin_i, scorenum_i, in_degree_i],    (5)

trong đó V ∈ R5, scoremean_i là trung bình của tất cả điểm số của một bước Vi, scoremax_i là điểm số tối đa, scoremin_i là điểm số tối thiểu, scorenum_i là số lượng điểm số, và in_degree_i là bậc vào của nút bước Vi.

--- TRANG 6 ---
Thuật toán 1 Thuật toán xây dựng đồ thị lý luận
Đầu vào: giải pháp được tạo ra SAi có cùng câu trả lời cuối cùng
Đầu ra: một đồ thị lý luận GAi
1: node_num ← 0
2: node2id ← dict()
3: edges ← list()
4: cho mỗi reason_path trong SAi do
5:   cho mỗi step trong reason_path do
6:     nếu step không có trong node2id.keys() thì
7:       node2id[step] ← node_num
8:       node_num ← node_num + 1
9:     kết thúc nếu
10:   kết thúc cho
11: kết thúc cho
12: cho mỗi reason_path trong SAi do
13:   cho mỗi step trong reason_path do
14:     start_node ← node2id[last_step]
15:     end_node ← node2id[step]
16:     nếu (start_node, end_node) không có trong edges thì
17:       edges.add((start_node, end_node))
18:     kết thúc nếu
19:     last_step ← step
20:   kết thúc cho
21: kết thúc cho
22: GAi ← graph(node2id, edges)

Bằng cách này, chúng ta có thể thu được nhiều đồ thị lý luận để biểu diễn tất cả giải pháp được tạo ra từ LLMs cho một câu hỏi bài toán từ toán học đơn lẻ.

3.4 Thiết kế Bộ Xác minh
Bộ xác minh GraphReason được thiết kế của chúng tôi được sử dụng để đánh giá câu trả lời của một nhóm giải pháp được tạo ra, cũng được biểu diễn như một đồ thị lý luận. Bộ xác minh này có hai đầu vào: đồ thị và tổng điểm số giải pháp. Chúng tôi sử dụng Mạng Đồng cấu Đồ thị (GIN) (Xu et al., 2019) để thực hiện truyền đặc trưng nút, từ đó mã hóa thông tin từ các đồ thị lý luận chúng tôi thu được. Đặc trưng nút được truyền và tổng hợp như sau:

h(k)_v = MLP(k)((1 + ε(k)) · h(k-1)_v + ∑[u∈N(v)] h(k-1)_u),    (6)

trong đó h(k)_v biểu diễn trạng thái của nút v sau lần cập nhật thứ k. MLP(k) đề cập đến một perceptron đa lớp trong lớp thứ k. N(v) biểu thị tất cả các hàng xóm của nút v và ε là một tham số có thể học được. Sau đó, chúng tôi thực hiện readout tổng để thu được biểu diễn của đồ thị lý luận:

hG = ∑[v∈G] h(k)_v,    (7)

trong đó hG ∈ R5. Chúng tôi đặt k bằng 3, biểu thị việc áp dụng ba lớp GIN. Đồng thời, tổng điểm số của các giải pháp có cùng câu trả lời cuối cùng, Ai, được biểu thị là scoreAi, được biểu diễn như sau:

scoreA = ∑[i∈SA] scorei.    (8)

Sau đó một đồ thị lý luận có thể được biểu diễn là:
G = [hG, scoreA],    (9)

trong đó G ∈ R6.

Nhãn mục tiêu của đồ thị y ∈ {0,1} chỉ ra liệu câu trả lời cuối cùng có khớp với câu trả lời cuối cùng đúng hay không. Chúng tôi tính toán mất mát và đào tạo mô hình xác minh bằng:

L = ∑[i=1 đến n] LBCE(labeli, f(Gi)),    (10)

trong đó i biểu diễn số lượng tập con giải pháp trong tất cả n tập con sau khi nhóm giải pháp. Đồ thị lý luận tương ứng cho tập con này được biểu thị bằng Gi, và f() là một bộ phân loại tuyến tính.

3.5 Xác minh Câu trả lời
Trong giai đoạn dự đoán, tất cả giải pháp được tạo ra được xử lý theo cách tương tự như trong giai đoạn đào tạo. Bộ xác minh đã được đào tạo sau đó được sử dụng để đánh giá điểm số của mỗi đồ thị lý luận, mỗi đồ thị đại diện cho một nhóm giải pháp mang lại cùng câu trả lời cuối cùng. Câu trả lời cuối cùng liên quan đến điểm số cao nhất được chọn làm câu trả lời dự đoán cuối cùng của chúng tôi:

ŷ = Answer[arg max_i score_i],    (11)

trong đó score_i biểu thị điểm số của đồ thị lý luận Gi, như được xác định bởi bộ xác minh của chúng tôi. Answer biểu diễn danh sách tất cả câu trả lời cuối cùng ứng viên. Bằng cách dự đoán số của đồ thị lý luận tối ưu, chúng ta có thể xác định kết quả dự đoán cuối cùng của nhiệm vụ lý luận hiện tại.

--- TRANG 7 ---
[THIS IS TABLE: Comparison table showing results for different models across GSM8K, SVAMP, ASDiv-a, and StrategyQA datasets]

Bảng 1: Kết quả thí nghiệm so sánh của GraphReason, các bộ xác minh khác, và các baseline khác. Chúng tôi chủ yếu so sánh GraphReason với các bộ xác minh khác, tất cả đều dựa trên cùng giải pháp được tạo ra từ gpt-3.5-turbo

4 Thí nghiệm
Trong phần này, chúng tôi đã tiến hành các thí nghiệm mở rộng để chứng minh hiệu suất của GraphReason, cùng với phân tích sâu hơn. Thông thường, chúng tôi tái tạo tất cả các loại bộ xác minh để báo cáo kết quả của chúng dựa trên cùng giải pháp được tạo ra. Thí nghiệm của chúng tôi được tiến hành trong hai cài đặt: Lý luận Số học và Lý luận Thường thức. Chúng tôi đảm bảo so sánh công bằng bằng cách đặt cùng seed ngẫu nhiên, sử dụng cùng môi trường phần cứng, và áp dụng siêu tham số tương tự. Chúng tôi sử dụng độ chính xác làm chỉ số để đánh giá khả năng giải bài toán từ toán học, xác định liệu câu trả lời cuối cùng có đúng hay không.

4.1 Chi tiết Đào tạo
Đối với lấy mẫu LLMs, chúng tôi sử dụng gpt-3.5-turbo làm LLMs cơ sở và đặt nhiệt độ t thành 1. Tất cả bộ xác minh sử dụng cùng đầu ra của LLMs. Về đào tạo bộ xác minh, chúng tôi tinh chỉnh trên bert-base-uncased (Devlin et al., 2019). Chúng tôi sử dụng bộ tối ưu hóa AdamW (Loshchilov and Hutter, 2019) để tối ưu hóa các tham số mô hình trong quá trình đào tạo. Chúng tôi áp dụng tỷ lệ học khác biệt, đặt tỷ lệ học của bộ phân loại tuyến tính cuối cùng thành 4e-2, trong khi các lớp mạng nơ-ron đồ thị khác được đặt thành 4e-3. Lớp kích hoạt giữa chúng là ReLU (Agarap, 2019). Kích thước batch trong mỗi bước đào tạo được đặt thành 2. Kích thước batch nhỏ vì bộ xác minh cần xác minh nhiều đồ thị lý luận cho một câu hỏi đơn lẻ.

Để đảm bảo so sánh công bằng giữa Voting Verifier, Simple Verifier, và GraphReason, chúng tôi sử dụng cùng bộ xác minh cơ sở đã được đào tạo cho cả ba phương pháp.

Chi tiết về bộ dữ liệu và baseline được cung cấp trong Phụ lục A và Phụ lục B, tương ứng.

4.2 Kết quả Chính
Chúng tôi trình bày kết quả chính trong Bảng 1. Như có thể thấy từ bảng, GraphReason nâng cao đáng kể khả năng lý luận của gpt-3.5-turbo gốc trên tất cả ba bộ dữ liệu, ví dụ, cải thiện độ chính xác 13.0% (72.7% → 85.7%) trên GSM8K. Cũng rõ ràng là phương pháp của chúng tôi vượt trội hơn các phương pháp bộ xác minh khác với cùng đầu ra từ LLMs và đạt state-of-the-art trên tất cả ba bộ dữ liệu.

Ngoài ra, Step-aware Voting Verifier cải thiện so với Voting Verifier bằng cách nhận ra rằng không phải tất cả các bước trong một đường lý luận không chính xác đều sai như nhau, và một số bước vẫn có thể hữu ích cho lý luận. Chúng tôi tin rằng giả thuyết này quá đơn giản và không thể mô tả mối quan hệ logic phức tạp giữa các bước. Theo Bảng 1, nó dẫn đến một số suy giảm chỉ số, và cùng phát hiện cũng được quan sát trong bài báo gốc. Hơn nữa, nó không hoạt động tốt trong nhiệm vụ StrategyQA, vì không có đường lý luận vàng cho việc đào tạo nhiệm vụ lý luận thường thức này. Trong nhiệm vụ này, các đường lý luận được tạo ra và giả, chỉ ra yêu cầu về nhãn vàng ở mỗi bước của quá trình lý luận. Tuy nhiên, bài báo của chúng tôi cải thiện nhất quán so với Voting Verifier bằng cách xem xét mối quan hệ phức tạp giữa các đường lý luận khác nhau thông qua đồ thị lý luận. Chúng tôi nâng cao phương pháp trước đó, không xem xét quan hệ trong các bước giữa các giải pháp khác nhau, bằng 0.3% (85.4% → 85.7%), 0.3% (85.1% → 85.4%), 0.1% (96.9% → 97.0%), và 0.5% (70.7% → 71.2%) trên bốn bộ dữ liệu.

Hơn nữa, GraphReason chỉ mang lại cải thiện hiệu suất nhẹ trên ASDiv-a, và kết quả gần như giống hệt nhau. Một lý do cho điều này là các bài toán từ toán học từ ASDiv-a đơn giản hơn

--- TRANG 8 ---
[THIS IS TABLE: Ablation study results showing GraphReason performance with different components removed]

Bảng 2: Kết quả thí nghiệm ablation của GraphReason. Thiếu mỗi thành phần dẫn đến suy giảm trong kết quả cuối cùng.

so với những bài trong hai bộ dữ liệu kia, dựa trên quan sát của chúng tôi. Trong hầu hết các trường hợp, những vấn đề này không yêu cầu lý luận phức tạp từ góc độ đồ thị để tạo ra câu trả lời thỏa đáng. Nó chứng minh rằng phương pháp của chúng tôi đặc biệt phù hợp cho những tình huống như vậy. Chúng tôi tin rằng GraphReason có thể mang lại những cải thiện đáng kể hơn trong kịch bản phức tạp hơn.

4.3 Nghiên cứu Ablation
Chúng tôi tiến hành nghiên cứu ablation để đánh giá tác động của mỗi thành phần đối với hiệu suất tổng thể của phương pháp chúng tôi. Bảng 2 trình bày kết quả của nghiên cứu này, nổi bật cách những module này đóng góp vào việc cải thiện mô hình cơ sở theo những cách riêng biệt. Có thể quan sát thấy rằng việc thiếu bất kỳ thành phần nào cũng dẫn đến suy giảm trong kết quả cuối cùng. Ngữ nghĩa giải pháp từ bộ xác minh cơ sở dường như quan trọng nhất đối với GraphReason. Phương pháp hiện tại vẫn dựa vào thông tin ngữ nghĩa, điều này hợp lý vì các bước lý luận từ các giải pháp khác nhau cần thông tin ngữ nghĩa để lý luận tốt hơn. Chúng tôi cũng nhận thấy rằng đồ thị lý luận mang lại cải thiện nhẹ cho toàn bộ phương pháp, từ đó chứng minh hiệu quả của cấu trúc đồ thị. Cải thiện không đáng kể vì chúng tôi không mô hình hóa cấu trúc đồ thị và thông tin ngữ nghĩa đồng thời, và tạo ra khoảng cách đào tạo ở đây. Một yếu tố quan trọng khác là độ phức tạp của phân loại đồ thị, được tăng cường bởi sự hiện diện của nhiễu và hạn chế trong dữ liệu đào tạo của chúng tôi.

4.4 GraphReason với Các LLMs Khác nhau
Để đánh giá tính tương thích của GraphReason và hiệu quả của nó trên các mô hình khác nhau, chúng tôi bổ sung thêm gpt-4 (OpenAI, 2023) và PaLM-2 (Google, 2023) trong thí nghiệm của chúng tôi. Do tài nguyên máy tính hạn chế, chúng tôi sử dụng cùng dữ liệu đào tạo đã được lấy mẫu trước đó từ gpt-3.5-turbo. Để thử nghiệm trong nhiệm vụ GSM8K, chúng tôi chọn mẫu từ 100 mẩu dữ liệu từ gpt-4 và PaLM-2

[THIS IS TABLE: Experimental results of GraphReason with different LLMs showing performance across different models]

Bảng 3: Kết quả thí nghiệm của GraphReason với các LLMs khác nhau.

tương ứng. Chúng tôi tiến hành lấy mẫu 10 lần sử dụng ba loại năm ví dụ mẫu, duy trì cùng cài đặt như trong các thí nghiệm trước đó của chúng tôi. Phương pháp của chúng tôi nhằm nâng cao khả năng lý luận ban đầu. Do đó, chúng tôi không bao gồm các LMs có kích thước nhỏ, thường thể hiện khả năng lý luận yếu hơn.

Từ Bảng 3, rõ ràng là phương pháp của chúng tôi nâng cao hiệu suất lý luận ban đầu của cả GPT-4 và PaLM-2. Tuy nhiên, có sự suy giảm hiệu suất trong gpt-4 khi so sánh với các baseline tốt nhất. Hiệu suất của GraphReason có thể so sánh với phương pháp bỏ phiếu. Chúng tôi đưa ra giả thuyết rằng điều này là do các mẫu lý luận của GPT-4 khác với những mẫu của GPT-3.5-Turbo, và bộ xác minh của chúng tôi được đào tạo cụ thể trên các mẫu GPT-3.5-Turbo trong cài đặt này.

5 Kết luận
Trong bài báo này, chúng tôi đề xuất GraphReason, một phương pháp mới và tổng quát để nâng cao khả năng lý luận của các mô hình ngôn ngữ lớn. Phương pháp của chúng tôi là phương pháp đầu tiên tiếp cận logic lý luận của các mô hình ngôn ngữ lớn từ góc độ đồ thị và xác minh các đường lý luận ứng viên tương ứng. Chúng tôi chứng minh sự vượt trội của GraphReason thông qua các thí nghiệm mở rộng.

--- TRANG 9 ---
Hạn chế
Có một số hạn chế trong nghiên cứu hiện tại góp phần vào hiệu suất không tốt như mong đợi:

• Tài nguyên Máy tính. Mặc dù có hiệu suất ấn tượng mà nó đạt được, khung của chúng tôi yêu cầu các mô hình ngôn ngữ lớn như GPT3.5. Suy luận với những mô hình này tốn thời gian và chi phí hơn so với các mô hình tinh chỉnh như BERT (Devlin et al., 2019). Một số thí nghiệm, như phân tích siêu tham số, đã được tiến hành trong các công trình liên quan trước đó và không được lặp lại ở đây. Hơn nữa, do tài nguyên máy tính hạn chế, chúng tôi không tiến hành thí nghiệm với các LLMs bổ sung. Chúng tôi đã chọn chỉ sử dụng LLM đại diện, GPT3.5, để so sánh hiệu suất của các bộ xác minh.

• Dữ liệu CoT được gán nhãn. GraphReason là một phương pháp bộ xác minh phức tạp xây dựng trên phân loại đồ thị, yêu cầu nhiều dữ liệu được gán nhãn với các đường lý luận chuỗi suy nghĩ được chú thích tốt để đào tạo. Trong việc đào tạo GraphReason, chúng tôi sử dụng các đường lý luận từ đầu ra của LLMs có thể đưa vào nhiễu đáng kể. Nếu dữ liệu đào tạo bao gồm các đồ thị lý luận được gán nhãn, hiệu suất sẽ cải thiện đáng kể.

• Các Nhiệm vụ Lý luận Khác. Có nhiều loại nhiệm vụ lý luận ngoài bài toán từ toán học, như Lý luận Thường thức (Talmor et al., 2019), Lý luận Quy nạp (Sinha et al., 2019), v.v. Cho rằng xây dựng đồ thị là một quá trình phức tạp, chúng tôi đã tập trung chủ yếu vào việc giải bài toán từ toán học (Lý luận Số học). Sự tập trung này cho phép triển khai thuận tiện hơn việc hợp nhất các bước trung gian. Trong các trường hợp khác, việc xác định các bước tương tự có thể thách thức. Mặt khác, một bài toán từ toán học thường trình bày nhiều giải pháp tiềm năng đa dạng hơn.

Tuy nhiên, chúng tôi tin rằng các nghiên cứu trong tương lai, được tiến hành bởi chúng tôi hoặc những người khác, có thể vượt qua những hạn chế này và cải thiện thêm phương pháp của chúng tôi.

Tài liệu tham khảo
[Followed by a long list of academic references in standard format, maintaining all author names, titles, publication details, and formatting as shown in the original]

--- TRANG 10 ---
[Continued academic references from previous page, maintaining exact formatting and content through reference list]

--- TRANG 11 ---
[Continued academic references, maintaining exact formatting through to the end of the reference list]

A Bộ dữ liệu
Chúng tôi so sánh GraphReason với các phương pháp khác trên ba bộ dữ liệu bài toán từ toán học khác nhau: GSM8K (Cobbe et al., 2021a), SVAMP (Patel et al., 2021), và ASDiv-a (Miao et al., 2020) và một bộ dữ liệu lý luận thường thức: StrategyQA (Geva et al., 2021). Chúng tôi chọn tập con ASDiv-a (số học) từ bộ dữ liệu ASDiv gốc, chỉ liên quan đến các phép toán số học.

Ba bộ dữ liệu lý luận số học này thách thức hơn so với các bộ dữ liệu bài toán từ toán học khác, làm cho chúng phù hợp hơn để thử nghiệm

--- TRANG 12 ---
khả năng lý luận của LLMs với bộ xác minh. Vì bộ dữ liệu GSM8K là bộ duy nhất cung cấp giải pháp từng bước như ví dụ mẫu chuỗi suy nghĩ, chúng tôi chọn ví dụ mẫu từ bộ dữ liệu đào tạo GSM8K và thử nghiệm chúng trên tất cả ba bộ dữ liệu. Ngoài ra, dữ liệu đào tạo cho bộ xác minh cũng sử dụng dữ liệu đào tạo GSM8K. Trong cài đặt này, chúng tôi cũng có thể chứng minh khả năng học chuyển giao và tổng quát hóa của phương pháp chúng tôi. Kích thước của phần chia đào tạo từ GSM8k là 1000. Kích thước dữ liệu thử nghiệm cho GSM8K, SVAMP, và ASDiv-a lần lượt là 1319, 1000, và 1218.

Trong nhiệm vụ lý luận thường thức StrategyQA, chúng tôi đặt số lượng ví dụ mẫu thành 8 và chọn ví dụ mẫu giả từ (Li et al., 2023). Ngoài ra, chúng tôi tiến hành năm lần lặp lấy mẫu cho mỗi ngữ cảnh của LLMs. Từ toàn bộ bộ dữ liệu, chúng tôi chọn một tập con 1.000 trường hợp, phân bổ 700 cho đào tạo và 300 cho thử nghiệm.

B Baseline
Trong đánh giá của chúng tôi, chúng tôi xem xét các baseline sau:

• Greedy Decode là một phương pháp đơn giản sử dụng chiến lược giải mã tham lam để lấy mẫu một lần.

• Self-Consistency (Voting) (Wang et al., 2023) lấy mẫu nhiều lần và chọn câu trả lời cuối cùng dựa trên bỏ phiếu đa số.

• Simple Verifier (Cobbe et al., 2021b), cũng được biết đến như chiến lược Sampling and Re-ranking, sử dụng bộ xác minh để gán điểm số cho các giải pháp được lấy mẫu và chọn câu trả lời cuối cùng với điểm số cao nhất.

• Voting Verifier (Li et al., 2023) kết hợp các phương pháp Voting và Verifier. Nó gán tổng điểm số cho câu trả lời từ điểm số của tất cả giải pháp ứng viên và chọn câu trả lời cuối cùng với điểm số cao nhất.

• DIVERSE (Step-aware Voting Verifier) (Li et al., 2023), là phương pháp state-of-the-art, xem xét các bước lý luận trong toàn bộ đường lý luận. Nó nhận ra rằng không phải tất cả các bước trong một đường lý luận không chính xác đều sai như nhau và một số bước vẫn có thể hữu ích cho lý luận.

Chúng tôi chủ yếu so sánh GraphReason với các bộ xác minh khác sử dụng cùng giải pháp được tạo ra từ gpt-3.5-turbo. Ngoài ra, chúng tôi bao gồm một số phương pháp Fine-tuning state-of-the-art trước đó để phản ánh khả năng lý luận mạnh mẽ của LLMs. Các phương pháp Fine-tuning SOTA trước đó được biểu thị như sau: a: (Cobbe et al., 2021b), b: (Pi et al., 2022), c: (Miao et al., 2020), d: (Chowdhery et al., 2022).

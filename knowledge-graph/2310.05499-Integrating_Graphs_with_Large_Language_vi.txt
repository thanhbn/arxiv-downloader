# 2310.05499.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/knowledge-graph/2310.05499.pdf
# Kích thước tệp: 1082070 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Tích hợp Đồ thị với Mô hình Ngôn ngữ Lớn: Phương pháp và Triển vọng

Shirui Pan, Đại học Griffith, Gold Coast, QLD 4215, Úc
Yizhen Zheng & Yixin Liu, Đại học Monash, Melbourne, VIC 3800, Úc

Tóm tắt—Các mô hình ngôn ngữ lớn (LLM) như GPT-4 đã nổi lên như những người dẫn đầu, thể hiện năng lực vượt trội trong các ứng dụng đa dạng, bao gồm trả lời câu hỏi, tạo mã nguồn, và nhiều hơn nữa. Đồng thời, dữ liệu có cấu trúc đồ thị, một loại dữ liệu nội tại, rất phổ biến trong các tình huống thực tế. Việc kết hợp khả năng của LLM với dữ liệu có cấu trúc đồ thị đã trở thành một chủ đề được quan tâm sâu sắc. Bài báo này phân chia những tích hợp như vậy thành hai danh mục chủ đạo. Loại đầu tiên tận dụng LLM cho việc học đồ thị, nơi LLM không chỉ có thể tăng cường các thuật toán đồ thị hiện có mà còn đóng vai trò là mô hình dự đoán cho các nhiệm vụ đồ thị khác nhau. Ngược lại, loại thứ hai nhấn mạnh vai trò then chốt của đồ thị trong việc cải tiến LLM. Phản ánh nhận thức con người, chúng ta giải quyết các nhiệm vụ phức tạp bằng cách áp dụng đồ thị trong việc lập luận hoặc hợp tác. Việc tích hợp với những cấu trúc như vậy có thể cải thiện đáng kể hiệu suất của LLM trong các nhiệm vụ phức tạp khác nhau. Chúng tôi cũng thảo luận và đề xuất các câu hỏi mở để tích hợp LLM với dữ liệu có cấu trúc đồ thị cho hướng phát triển tương lai của lĩnh vực.

Các mô hình ngôn ngữ lớn (LLM) đã nhanh chóng trở thành tâm điểm do khả năng đáng chú ý của chúng. Chúng đã chứng minh năng lực trong các nhiệm vụ khác nhau, bao gồm nhưng không giới hạn ở dịch thuật, trả lời câu hỏi, và tạo mã nguồn. Khả năng thích ứng và hiệu quả của chúng trong việc xử lý và hiểu lượng dữ liệu khổng lồ đặt chúng ở vị trí như những công cụ cách mạng trong thời đại thông tin. Đồng thời, đồ thị là một biểu diễn tự nhiên của thế giới, và khả năng nắm bắt mối quan hệ phức tạp giữa các thực thể khiến chúng trở thành một công cụ mạnh mẽ để mô hình hóa các tình huống thực tế. Ví dụ, các cấu trúc gợi nhớ đến đồ thị có thể được quan sát trong tự nhiên và trên internet. Với tầm quan trọng riêng lẻ của cả LLM và cấu trúc đồ thị, việc khám phá cách chúng có thể được kết hợp một cách cộng sinh đã nổi lên như một chủ đề nóng trong cộng đồng AI.

Trong bài báo này, chúng tôi phân định hai mô hình chính cho sự cộng sinh giữa LLM và đồ thị. Mô hình đầu tiên, "LLM tăng cường học đồ thị" bao gồm việc khai thác khả năng của LLM để xử lý các nhiệm vụ liên quan đến đồ thị khác nhau. Điều này bao gồm dự đoán các tính chất của đồ thị, chẳng hạn như bậc và tính kết nối của các nút, cũng như những thách thức phức tạp hơn như phân loại nút và đồ thị. Ở đây, LLM có thể bổ sung cho các thuật toán đồ thị hoặc đóng vai trò là mô hình dự đoán/tạo sinh chính. Ngược lại, mô hình thứ hai, "Đồ thị nâng cao khả năng LLM", tận dụng cấu trúc vốn có của đồ thị để tăng cường khả năng lập luận của LLM hoặc giúp LLM hợp tác, hỗ trợ chúng trong việc xử lý các nhiệm vụ đa diện. Bằng cách tận dụng cấu trúc đồ thị, hiệu quả của LLM trong giải quyết vấn đề phức tạp có thể được cải thiện đáng kể.

Tại sao tích hợp đồ thị và LLM?
Sử dụng LLM để giải quyết các nhiệm vụ đồ thị có hai lợi thế chính. Đầu tiên, không giống như các kỹ thuật học sâu đồ thị thường mờ mịt, LLM tiếp cận các thách thức liên quan đến đồ thị chủ yếu thông qua lập luận, cung cấp cái nhìn rõ ràng hơn về cơ sở cho các dự đoán của chúng. Sự minh bạch này cung cấp một phương pháp dễ hiểu hơn để hiểu các phân tích đồ thị phức tạp. Thứ hai, LLM sở hữu một kho tri thức trước đó rộng lớn trải rộng trên các lĩnh vực đa dạng. Các mô hình học đồ thị truyền thống, bị hạn chế bởi dữ liệu huấn luyện có giới hạn, gặp khó khăn trong việc đồng hóa toàn diện sự phong phú của tri thức này. Do đó, việc khai thác LLM để xử lý dữ liệu đồ thị mang lại cơ hội tận dụng khả năng mở rộng và kho tri thức trước đó rộng lớn của chúng. Tri thức như vậy có thể đặc biệt có giá trị cho việc học máy đồ thị trong các lĩnh vực như tài chính và sinh học.

Sử dụng đồ thị để tăng cường LLM cũng là một mô hình học tập đầy hứa hẹn. Cụ thể, đồ thị có thể cải thiện đáng kể khả năng lập luận và hợp tác của LLM. Trong các hệ thống đa tác nhân, đồ thị mô hình mối quan hệ giữa các tác nhân, tạo điều kiện cho luồng thông tin hiệu quả và hợp tác. Tích hợp với những cấu trúc như vậy có thể cải thiện đáng kể hiệu suất của LLM trong các nhiệm vụ phức tạp khác nhau.

LLM Tăng cường Học Đồ thị
Một cách tiếp cận then chốt để tích hợp LLM và đồ thị bao gồm việc tận dụng LLM để củng cố việc học đồ thị. Như được minh họa ở phần bên trái của Hình 1, sự tăng cường này có thể hiện thực hóa thông qua ba con đường khác biệt: tăng cường các thuật toán đồ thị thông thường với sức mạnh của LLM; sử dụng trực tiếp LLM cho các nhiệm vụ liên quan đến đồ thị downstream; và sử dụng LLM trong việc xây dựng phức tạp các cấu trúc đồ thị. Trong các phần tiếp theo, chúng tôi phân tích chi tiết từng chiến lược này.

LLM Tăng cường Thuật toán Đồ thị
Việc tích hợp Mô hình Ngôn ngữ Lớn (LLM) với các thuật toán đồ thị chủ yếu tìm cách khai thác LLM như các cơ chế tăng cường thuộc tính, nâng cao các thuộc tính nội tại của các nút đồ thị. Như được mô tả trong Hình 1(a), LLM xử lý thông tin văn bản cho các nút để tạo ra các thuộc tính được tinh chỉnh. Những thuộc tính tăng cường này có thể cải thiện hiệu suất của các mô hình học đồ thị như mạng nơ-ron đồ thị (GNN).

Một cách tiếp cận trực tiếp là sử dụng LLM làm bộ mã hóa để xử lý các thuộc tính dựa trên văn bản của nút, với tùy chọn tinh chỉnh trên các nhiệm vụ downstream cụ thể. Một kỹ thuật khác sử dụng LLM độc quyền, GPT-3.5, để đồng thời tạo ra dự đoán và giải thích cho các nhiệm vụ như phân loại bài báo. Sử dụng LLM mã nguồn mở khác, họ rút ra các embedding nút bằng cách mã hóa cả đầu ra của LLM và các thuộc tính gốc. Những embedding này được kết hợp và sau đó được tích hợp vào GNN để tăng hiệu suất.

Một cách tiếp cận phức tạp hơn sử dụng phương pháp lặp để hài hòa tích hợp cả khả năng của GNN và LLM. Chúng được huấn luyện riêng biệt ban đầu; sau đó, thông qua một khung biến phân EM, LLM sử dụng văn bản và nhãn giả của GNN, trong khi GNN sử dụng các embedding được mã hóa bởi LLM hoặc các thuộc tính nút và nhãn giả của LLM, lặp lại để thúc đẩy hiệu suất lẫn nhau.

LLM Dự đoán Nhiệm vụ Đồ thị
LLM có khả năng dự đoán các tính chất đồ thị, bao gồm các thuộc tính như bậc nút và tính kết nối, và thậm chí có thể giải quyết những thách thức phức tạp như phân loại nút và đồ thị, như được minh họa trong Hình 1(b).

Một ứng dụng đơn giản bao gồm việc cung cấp cho LLM các lời nhắc zero-shot hoặc few-shot, khuyến khích chúng trực tiếp dự đoán kết quả hoặc trước tiên cung cấp một lý lẽ phân tích theo sau bởi dự đoán cuối cùng. Các thí nghiệm cho thấy rằng trong khi LLM thể hiện sự hiểu biết cơ bản về cấu trúc đồ thị, hiệu suất của chúng tụt hậu so với các tiêu chuẩn mạng nơ-ron đồ thị. Họ cũng cho thấy rằng hiệu suất của LLM bị ảnh hưởng đáng kể bởi chiến lược nhắc nhở và việc sử dụng ngôn ngữ mô tả đồ thị, đây là cách thức văn bản để mô tả đồ thị.

Một phương pháp tiên tiến hơn, được gọi là InstructGLM, đã được đưa ra. Chiến lược này sử dụng một quá trình điều chỉnh hướng dẫn đa nhiệm vụ, đa lời nhắc để tinh chỉnh LLM trước khi suy luận trên các nhiệm vụ cụ thể. Trong quá trình tinh chỉnh, các nút được coi như các token mới—được khởi tạo với các đặc trưng nút vốn có—để mở rộng từ vựng gốc của LLM. Do đó, các embedding nút có thể được tinh chỉnh trong giai đoạn huấn luyện. Sử dụng phương pháp tinh chỉnh này, hệ thống của họ vượt trội hơn các tiêu chuẩn mạng nơ-ron đồ thị trên ba mạng trích dẫn.

LLM Xây dựng Đồ thị
LLM có thể hỗ trợ xây dựng đồ thị cho các nhiệm vụ downstream như được thể hiện trong Hình 1(c). Ví dụ, một số nhà nghiên cứu đã thử sử dụng LLM để phân tích tiêu đề tin tức và xác định các công ty có thể bị tác động. Cụ thể, một mạng lưới các công ty có mối tương quan được xây dựng tự động bởi LLM. Mạng lưới được tạo ra có thể được sử dụng để cải thiện hiệu suất dự đoán các chuyển động thị trường chứng khoán.

Đồ thị Tăng cường Khả năng LLM
Việc tận dụng cấu trúc đồ thị có thể cải thiện đáng kể khả năng lập luận và hợp tác của LLM. Như được thể hiện ở phần bên phải của Hình 1, những cải tiến này xuất hiện thông qua hai cơ chế chính: (1) sử dụng cấu trúc đồ thị để củng cố lập luận logic trong LLM, và (2) sử dụng cấu trúc đồ thị để tăng cường hợp tác LLM trong các hệ thống đa tác nhân. Chúng tôi đi sâu hơn vào từng cách tiếp cận này trong các phần tiếp theo.

Đồ thị Cải thiện Lập luận LLM
Đồ thị là cấu trúc nền tảng của lập luận con người. Thông qua các công cụ như bản đồ tư duy và sơ đồ luồng, và các chiến lược như thử và sai hoặc phân tách nhiệm vụ, chúng ta biểu hiện các quá trình tư duy có cấu trúc đồ thị nội tại của mình. Không có gì bất ngờ, khi được tận dụng đúng cách, chúng có thể nâng cao đáng kể khả năng lập luận của LLM. Như được minh họa trong Hình 1(d1), khi được giao nhiệm vụ, LLM tuân theo một chuỗi: chúng xử lý dữ liệu đầu vào, tham gia vào lập luận, và sau đó tạo ra kết quả cuối cùng. Hình 1(d2) làm nổi bật các hạn chế của LLM sử dụng "Input-output Prompting"; không có lập luận, hiệu suất của chúng có xu hướng thấp, đặc biệt là với các nhiệm vụ phức tạp.

Sử dụng cấu trúc đồ thị, từ chuỗi và cây cơ bản đến các thiết kế phức tạp hơn, có thể cải thiện sâu sắc khả năng lập luận của LLM. Xem xét phương pháp "chain-of-thought prompting" (COT), được mô tả trong Hình 1(d3). Trong này, LLM khai thác một chuỗi, một loại đồ thị có hướng phi chu trình, để giải quyết vấn đề có cấu trúc. Đáng chú ý, ngay cả khung cơ bản này cũng tăng gấp ba hiệu quả của LLM trên GSM8K, một tiêu chuẩn bài toán từ ngữ toán học.

Ngược lại, phương pháp "Tree of Thoughts" (ToT), sử dụng cây—một đồ thị phi chu trình vô hướng cơ bản—đi sâu hơn vào lập luận. Mỗi giai đoạn lập luận trong ToT là một nút. LLM duyệt qua cây này, loại bỏ các nút không tuân thủ và trở lại phía trên khi cần thiết, để suy ra giải pháp. Với phương pháp này, LLM đạt được độ chính xác 74% trong bài kiểm tra "Game of 24", vượt trội hơn 4% từ COT.

Đi sâu vào các cấu trúc đồ thị phức tạp thúc đẩy khả năng của LLM xa hơn nữa. Cải tiến ToT, mô hình "Graph of Thoughts" (GoT) đã được giới thiệu, như được minh họa trong Hình 1(d5). Đồ thị lập luận tiên tiến này có thể là không đồng nhất, với các nút đa dạng chuyên dụng cho các nhiệm vụ cụ thể. Các cơ chế phức tạp, chẳng hạn như tổng hợp và kết hợp nút (A&C), và tương tác động giữa các đường dẫn và đồ thị, được kết hợp. A&C, ví dụ, tạo điều kiện cho việc chia nhỏ nút để phân tách nhiệm vụ và hợp nhất nút. Tương tác đường dẫn cung cấp cho LLM tính linh hoạt lớn hơn bằng cách cho phép duyệt qua các đường dẫn, một bước nhảy từ khung nhánh cô lập của ToT. Tương tác đa đồ thị thậm chí có thể được tổ chức cho các nhiệm vụ phức tạp. Những phương pháp GoT này vượt trội hơn đáng kể các mô hình đồ thị đơn giản hơn trong việc xử lý các thách thức phức tạp, cho thấy rằng các cấu trúc đồ thị phức tạp hơn có thể dẫn đến những cải tiến thậm chí còn quan trọng hơn.

Đồ thị Xây dựng Hợp tác LLM
Trong khi phần trước đã xem xét khả năng của các LLM riêng lẻ, các nhiệm vụ phức tạp, chẳng hạn như phát triển phần mềm, yêu cầu nhiều LLM làm việc cùng nhau trong một khung hợp tác, tức là hệ thống đa tác nhân, như được minh họa trong Hình 1(e). Cấu trúc đồ thị có thể là công cụ quan trọng trong bối cảnh này. Như được mô tả trong cùng hình, những cấu trúc này có thể mô hình hóa hiệu quả các mối quan hệ và luồng thông tin giữa các LLM hợp tác.

--- TRANG 4 ---
Câu hỏi Mở và Hướng phát triển
Giao điểm của Mô hình Ngôn ngữ Lớn (LLM) với cấu trúc đồ thị đầy hứa hẹn, nhưng sự phát triển hiện tại của nó gây ra một số câu hỏi mở và thách thức.

LLM Tăng cường Học Đồ thị
Câu hỏi 1. Làm thế nào để tận dụng LLM để học trên các loại đồ thị khác ngoài Đồ thị Có Thuộc tính Văn bản (TAG)? Các LLM hiện tại cho việc học đồ thị chủ yếu liên quan đến TAG. Tuy nhiên, dữ liệu đồ thị trong thế giới thực, chẳng hạn như mạng xã hội và đồ thị phân tử, thường kết hợp các thuộc tính từ các lĩnh vực khác nhau. Để hiện thực hóa tiềm năng của LLM trong việc học đồ thị, điều quan trọng là phải xử lý hiệu quả một loạt các đồ thị đa dạng làm đầu vào cho những mô hình này.

Hướng phát triển tương lai: Hướng 1. Dịch các loại dữ liệu đa dạng thành định dạng văn bản: Ví dụ, hồ sơ của người dùng trên mạng xã hội có thể liệt kê các thuộc tính như tuổi, địa chỉ, giới tính, và sở thích. Những thông tin này có thể được diễn đạt như: "Người dùng X là nam giới tuổi 20, cư trú tại Melbourne, với niềm đam mê chơi ghi ta." Hướng 2. Tận dụng các mô hình đa phương thức để căn chỉnh đồ thị-văn bản: Các LLM đa phương thức đã có những bước tiến đáng chú ý trong các lĩnh vực như âm thanh và hình ảnh. Xác định các phương pháp để đồng bộ hóa dữ liệu đồ thị với văn bản sẽ trao quyền cho chúng ta khai thác khả năng của LLM đa phương thức để học dựa trên đồ thị.

Câu hỏi 2. Làm thế nào chúng ta có thể giúp LLM hiểu đồ thị? Trọng tâm của thành công của LLM trong việc học đồ thị là khả năng hiểu thực sự đồ thị của chúng. Bằng chứng thực nghiệm cho thấy rằng việc lựa chọn ngôn ngữ mô tả đồ thị có thể có tác động đáng kể đến hiệu suất LLM.

Hướng phát triển tương lai: Hướng 1. Mở rộng ngôn ngữ mô tả đồ thị: Các ngôn ngữ mô tả đồ thị hiện tại cung cấp phạm vi hạn chế. Phát triển các phương pháp mô tả cải tiến sẽ cho phép LLM nắm bắt và xử lý đồ thị hiệu quả hơn. Hướng 2. Tiền huấn luyện hoặc tinh chỉnh LLM trên Đồ thị: Tiền huấn luyện hoặc tinh chỉnh LLM trên các dữ liệu đồ thị khác nhau được chuyển đổi bằng ngôn ngữ mô tả đồ thị có thể giúp LLM hiểu đồ thị tốt hơn. Hướng 3. Các mô hình đồ thị nền tảng cho việc học đồ thị: Trong khi các mô hình nền tảng đã có những bước tiến trong các lĩnh vực như ngôn ngữ và hình ảnh, vẫn còn một khoảng trống trong việc thiết lập các mô hình nền tảng quy mô lớn cho đồ thị. Chuyển đổi đồ thị sang định dạng văn bản cung cấp một cơ hội độc đáo: LLM có thể được huấn luyện trên dữ liệu này, cho phép việc học đồ thị tận dụng tri thức trước đó và khả năng mở rộng vốn có trong LLM.

Đồ thị Tăng cường Khả năng LLM
Câu hỏi 3. Làm thế nào để nâng cao các cấu trúc đồ thị phức tạp hơn để tăng cường lập luận LLM? Các khám phá hiện tại về lập luận LLM đã chạm vào các cấu trúc đồ thị như chuỗi, cây, và đồ thị truyền thống. Tuy nhiên, có tiềm năng lớn trong việc đi sâu vào các cấu trúc đồ thị phức tạp hơn, chẳng hạn như siêu đồ thị, mô hình đồ thị xác suất, và đồ thị có dấu.

Hướng phát triển tương lai: Mở rộng các loại đồ thị cho lập luận LLM: Đa dạng hóa các loại đồ thị được sử dụng có thể củng cố đáng kể lập luận LLM.

Câu hỏi 4. Làm thế nào để nâng cao các cấu trúc đồ thị phức tạp hơn để tăng cường hệ thống đa tác nhân (MLS)? Hiện tại, các cấu trúc đồ thị hướng dẫn MLS, như trong MetaGPT, tương đối sơ khai. Trong khi MetaGPT sử dụng mô hình thác nước trong phát triển phần mềm—được minh họa bởi một cấu trúc chuỗi đơn giản liên kết các tác nhân khác nhau—phát triển phần mềm đương đại phức tạp hơn nhiều với các mối quan hệ tác nhân phức tạp và các quá trình đa diện.

Hướng phát triển tương lai: Kết hợp các cấu trúc đồ thị tiên tiến cho quy trình làm việc LLM dựa trên nhóm: Rút kinh nghiệm từ tính hữu ích của cấu trúc đồ thị trong lập luận, việc áp dụng các dạng đồ thị đa dạng như cây, đồ thị truyền thống, và thậm chí các cấu trúc phức tạp hơn có thể giúp ích.

Câu hỏi 5. Làm thế nào để tích hợp cấu trúc đồ thị vào quy trình của LLM? Khả năng áp dụng của cấu trúc đồ thị không chỉ giới hạn ở lập luận và hợp tác. Có một lý lẽ thuyết phục cho việc tích hợp chúng qua tất cả các giai đoạn của chu trình sống LLM: từ huấn luyện và tinh chỉnh đến suy luận.

Hướng phát triển tương lai: Sử dụng cấu trúc đồ thị trong huấn luyện, tinh chỉnh, và suy luận. Ví dụ, đồ thị có thể cấu trúc dữ liệu huấn luyện, cho phép học tập hiệu quả hơn.

TÀI LIỆU THAM KHẢO
1. M. Besta, N. Blach, A. Kubicek, R. Gerstenberger, L. Gianinazzi, J. Gajda, T. Lehmann, M. Podstawski, H. Niewiadomski, P. Nyczyk, et al., "Graph of thoughts: Solving elaborate problems with large language models," arXiv:2308.09687, 2023.
2. B. Lei, C. Liao, C. Ding, et al., "Boosting Logical Reasoning in Large Language Models through a New Framework: The Graph of Thought," arXiv:2308.08614, 2023.
3. Z. Chen, H. Mao, H. Li, W. Jin, H. Wen, X. Wei, S. Wang, D. Yin, W. Fan, H. Liu, et al., "Exploring the potential of large language models (LLMs) in learning on graphs," arXiv:2307.03393, 2023.

--- TRANG 5 ---
4. J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou, et al., "Chain-of-thought prompting elicits reasoning in large language models," Advances in Neural Information Processing Systems, vol. 35, pp. 24824–24837, 2022.
5. X. He, X. Bresson, T. Laurent, B. Hooi, et al., "Explanations as Features: LLM-Based Features for Text-Attributed Graphs," arXiv:2305.19523, 2023.
6. J. Guo, L. Du, H. Liu, "GPT4Graph: Can Large Language Models Understand Graph Structured Data? An Empirical Evaluation and Benchmarking," arXiv:2305.15066, 2023.
7. S. Yao, D. Yu, J. Zhao, I. Shafran, T.L. Griffiths, Y. Cao, K. Narasimhan, "Tree of thoughts: Deliberate problem solving with large language models," arXiv:2305.10601, 2023.
8. R. Ye, C. Zhang, R. Wang, S. Xu, Y. Zhang, et al., "Natural language is all a graph needs," arXiv:2308.07134, 2023.
9. S. Hong, X. Zheng, J. Chen, Y. Cheng, C. Zhang, Z. Wang, S. K. Yau, Z. Lin, L. Zhou, C. Ran, et al., "Metagpt: Meta programming for multi-agent collaborative framework," arXiv:2308.00352, 2023.
10. Z. Chen, L. N. Zheng, C. Lu, J. Yuan, D. Zhu, et al., "ChatGPT Informed Graph Neural Network for Stock Movement Prediction," in SIGKDD 2023 Workshop on Robust NLP for Finance, 2023.

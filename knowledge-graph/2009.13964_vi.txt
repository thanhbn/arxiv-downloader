# 2009.13964.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/knowledge-graph/2009.13964.pdf
# Kích thước tệp: 3137206 byte

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
CokeBERT: Lựa chọn và Nhúng Kiến thức Theo Ngữ cảnh hướng tới
Các Mô hình Ngôn ngữ Tiền huấn luyện Nâng cao
Yusheng Su1, Xu Han1, Zhengyan Zhang1, Yankai Lin2,
Peng Li2,Zhiyuan Liu1,Jie Zhou2,Maosong Sun1
1Khoa Khoa học và Công nghệ Máy tính, Đại học Thanh Hoa, Bắc Kinh, Trung Quốc
Viện Trí tuệ Nhân tạo, Đại học Thanh Hoa, Bắc Kinh, Trung Quốc
Phòng thí nghiệm Trọng điểm Nhà nước về Công nghệ và Hệ thống Thông minh, Đại học Thanh Hoa, Bắc Kinh, Trung Quốc
2Trung tâm Nhận dạng Mẫu, WeChat AI, Tencent Inc.
fsuys19,hanxu17 g@mails.tsinghua.edu.cn,
Tóm tắt
Một số nỗ lực gần đây đã được dành để nâng cao các mô hình ngôn ngữ tiền huấn luyện (PLM) bằng cách sử dụng kiến thức không đồng nhất bổ sung trong đồ thị kiến thức (KG), và đạt được các cải thiện nhất quán trên các nhiệm vụ NLP được điều khiển bởi kiến thức khác nhau. Tuy nhiên, hầu hết các PLM được nâng cao kiến thức này nhúng các đồ thị con tĩnh của KG ("ngữ cảnh kiến thức"), bất kể kiến thức được yêu cầu bởi PLM có thể thay đổi động theo văn bản cụ thể ("ngữ cảnh văn bản"). Trong bài báo này, chúng tôi đề xuất một khung mới có tên Coke để lựa chọn kiến thức theo ngữ cảnh một cách động và nhúng ngữ cảnh kiến thức theo ngữ cảnh văn bản cho PLM, có thể tránh tác động của kiến thức dư thừa và mơ hồ trong KG không thể khớp với văn bản đầu vào. Kết quả thực nghiệm của chúng tôi cho thấy Coke vượt trội so với các baseline khác nhau trên các nhiệm vụ NLP được điều khiển bởi kiến thức điển hình, cho thấy hiệu quả của việc sử dụng ngữ cảnh kiến thức động cho hiểu ngôn ngữ. Bên cạnh các cải thiện hiệu suất, kiến thức được lựa chọn động trong Coke có thể mô tả ngữ nghĩa của kiến thức liên quan đến văn bản dưới dạng có thể diễn giải hơn so với các PLM thông thường. Mã nguồn và bộ dữ liệu của chúng tôi sẽ có sẵn để cung cấp thêm chi tiết cho Coke.

1 Giới thiệu
Các mô hình ngôn ngữ tiền huấn luyện (PLM) như BERT (Devlin et al., 2019) và RoBERTa (Liu et al., 2019) đã đạt được hiệu suất tốt nhất trên một loạt các nhiệm vụ xử lý ngôn ngữ tự nhiên (NLP). Vì một số nghiên cứu (Poerner et al., 2019) cho thấy rằng các PLM này vẫn gặp khó khăn trong việc học kiến thức thực tế, các nỗ lực gần đây tích cực (Lauscher et al., 2019; Yoav et al., 2019; Yu et al., 2019; Wang et al., 2019; Zhang et al., 2019; Peters et al., 2019; He et al., 2019; Liu et al., 2020) cho biết đóng góp như nhau đã được dành để tận dụng kiến thức không đồng nhất phong phú trong đồ thị kiến thức (KG) để nâng cao PLM.

Steph Curry và Klay Thompson dẫn dắt Warriors đến chức vô địch NBA
Steph Curry, Klay Thompson
Riley, Davidson College, Washington State University, Warriors, Play for, Play for, Graduates from, Graduates from, Daughter of, Steph Curry, Klay Thompson, Teammate
Tầm quan trọng thấp, Tầm quan trọng cao, Text, KG

Hình 1: Ví dụ về việc nắm bắt ngữ cảnh kiến thức từ KG và kết hợp chúng để hiểu ngôn ngữ. Các kích thước khác nhau của vòng tròn thể hiện tầm quan trọng khác nhau của thực thể để hiểu câu đã cho.

Một quá trình lý tưởng để tiêm kiến thức thực tế vào PLM là trước tiên xác định các thực thể được đề cập1 trong văn bản đầu vào ("ngữ cảnh văn bản"), sau đó lựa chọn động các đồ thị con ("ngữ cảnh kiến thức") tập trung vào các thực thể được đề cập này từ KG, và cuối cùng nhúng ngữ cảnh kiến thức đã chọn cho PLM. Theo trực giác, ngữ cảnh kiến thức góp phần vào việc hiểu ngôn ngữ tốt hơn một mặt, phục vụ như một sự bổ sung hiệu quả cho ngữ cảnh văn bản. Ví dụ, với hai thực thể Steph Curry và Klay Thompson trong Hình 1, chúng ta có thể suy ra rằng họ chơi cho cùng một đội bóng rổ, điều này không được mô tả rõ ràng trong câu đã cho. Mặt khác, không phải tất cả kiến thức trong KG đều liên quan đến ngữ cảnh văn bản, ví dụ, sự kiện ( Riley ,Daughter of,Steph Curry ) không có tác động tích cực đến việc hiểu câu đã cho.

Chúng tôi lập luận rằng việc lựa chọn động ngữ cảnh kiến thức phù hợp có thể khớp với ngữ cảnh văn bản cụ thể để nâng cao PLM là có ý nghĩa. Tuy

1Những từ hoặc cụm từ trong văn bản tương ứng với các thực thể nhất định trong KG thường được gọi là "đề cập thực thể".

--- TRANG 2 ---
nhiên, hầu hết ngữ cảnh kiến thức được sử dụng trong các PLM được nâng cao kiến thức hiện tại không khớp cao với ngữ cảnh văn bản: (1) ERNIE (Zhang et al., 2019) chỉ sử dụng các thực thể được đề cập trong văn bản làm ngữ cảnh kiến thức và chỉ tiêm các embedding của các thực thể này vào PLM, bỏ qua các lân cận có thông tin trong KG; (2) KnowBert (Peters et al., 2019), K-BERT (Liu et al., 2020) và K-ADAPTER (Wang et al., 2020) xem xét nhiều thông tin hơn làm ngữ cảnh kiến thức so với ERNIE (ví dụ, thuộc tính thực thể trong KG), tuy nhiên ngữ cảnh kiến thức của chúng vẫn là tĩnh và không thể thay đổi động theo ngữ cảnh văn bản. Như chúng tôi đã đề cập trước đó, không phải tất cả thông tin trong ngữ cảnh kiến thức tĩnh đều có thể khớp với ngữ cảnh văn bản, và kiến thức can thiệp với thông tin dư thừa và mơ hồ có thể can thiệp hiểu ngữ nghĩa. Do đó, cách lựa chọn và nhúng ngữ cảnh kiến thức một cách động theo ngữ cảnh văn bản cho PLM vẫn là một thách thức.

Để giảm thiểu vấn đề này, chúng tôi đề xuất một khung mới có tên Coke để lựa chọn động ngữ cảnh kiến thức khớp với ngữ cảnh văn bản và nhúng ngữ cảnh động để nâng cao PLM: (1) Để lựa chọn ngữ cảnh kiến thức một cách động, theo ngữ cảnh văn bản, chúng tôi đề xuất một mạng nơ-ron đồ thị được điều khiển bởi ngữ nghĩa mới (S-GNN). Với một thực thể được đề cập trong ngữ cảnh văn bản, S-GNN tận dụng cơ chế attention để lọc bỏ thông tin KG không liên quan bằng cách gán điểm cho các lân cận (1-hop, 2-hop, v.v.) và các mối quan hệ giữa các thực thể dựa trên ngữ cảnh văn bản. Điểm này có thể cân nhắc mức độ thông tin trong KG khớp với ngữ cảnh văn bản và giúp Coke lựa chọn động một đồ thị con phù hợp làm ngữ cảnh kiến thức của đề cập thực thể đã cho. (2) Để nhúng ngữ cảnh kiến thức một cách động, với một thực thể được đề cập, S-GNN tính toán biểu diễn của nó được điều kiện trên cả embedding thực thể tiền huấn luyện của nó và thông tin được tổng hợp từ đồ thị con ngữ cảnh đã chọn theo cách đệ quy, làm cho Coke nhận thức được cả thông tin KG toàn cục và cục bộ và nắm bắt thông tin liên quan đến văn bản. (3) Bằng cách kết hợp các embedding của ngữ cảnh kiến thức động cho PLM với các chiến lược huấn luyện và thích ứng cụ thể, Coke cải thiện hiểu ngôn ngữ và mang lại lợi ích cho các ứng dụng downstream.

Theo các công trình hiện có, chúng tôi tiến hành thí nghiệm trên bốn bộ dữ liệu cho hai nhiệm vụ được điều khiển bởi kiến thức điển hình, tức là phân loại thực thể và phân loại mối quan hệ. Kết quả thực nghiệm cho thấy Coke vượt trội so với các baseline khác nhau, cho thấy hiệu quả của việc lựa chọn và nhúng ngữ cảnh kiến thức một cách động cho PLM. Hơn nữa, một số phân tích định tính cũng cho thấy rằng, so với các PLM được nâng cao kiến thức tốt nhất, mô hình của chúng tôi không chỉ đạt được kết quả cạnh tranh mà còn cung cấp một cách tiếp cận có thể diễn giải hơn để mô tả các từ cụ thể dựa trên ngữ cảnh kiến thức động của chúng.

2 Công trình liên quan
Theo trực giác, hai loại ngữ cảnh được liên quan đến hiểu ngôn ngữ: (1) thông tin ngữ nghĩa của văn bản (ngữ cảnh văn bản), và (2) kiến thức thực tế liên quan đến văn bản (ngữ cảnh kiến thức). Các PLM điển hình tập trung vào việc nắm bắt thông tin từ ngữ cảnh văn bản, như ELMO (Peters et al., 2018), GPT (Radford et al., 2018), BERT (Devlin et al., 2019), XLNET (Yang et al., 2019), và RoBERTa (Liu et al., 2019). Để cho phép PLM hiểu ngữ cảnh kiến thức tốt hơn, các nỗ lực tích cực đã được dành để tiêm kiến thức thực tế khác nhau của KG vào PLM.

ERNIE (Zhang et al., 2019) liên kết các đề cập thực thể trong ngữ cảnh văn bản với các thực thể tương ứng trong KG và sau đó tiêm các embedding tiền huấn luyện của các thực thể tương ứng vào PLM. Mặc dù ERNIE đã cho thấy tính khả thi và hiệu quả của việc kết hợp embedding kiến thức để nâng cao PLM, nó vẫn không xem xét các lân cận có thông tin của các thực thể.

Để đạt được mục tiêu này, các mô hình khác nhau đã được đề xuất để kết hợp thêm một loạt thông tin kiến thức rộng hơn. KnowBert (Peters et al., 2019) và KRL (He et al., 2019) sử dụng các cơ chế attention để học các embedding thực thể có thông tin hơn dựa trên các đồ thị con liên quan đến thực thể. Tuy nhiên, việc tính toán các embedding thực thể độc lập với ngữ cảnh văn bản. K-BERT (Liu et al., 2020) một cách heuristic chuyển đổi ngữ cảnh văn bản và các đồ thị con liên quan đến thực thể thành các chuỗi đầu vào thống nhất, và tận dụng một Transformer (Vaswani et al., 2017) với cơ chế attention được thiết kế đặc biệt để mã hóa các chuỗi. Thật không may, không dễ dàng để phương pháp heuristic trong K-BERT chuyển đổi các lân cận bậc hai hoặc cao hơn liên quan đến ngữ cảnh văn bản thành một chuỗi mà không mất thông tin cấu trúc đồ thị. K-ADAPTER (Wang et al., 2020) đề xuất các khung biến thể để tiêm kiến thức thực tế trong các lĩnh vực khác nhau, tuy nhiên vẫn gặp phải vấn đề tương tự như K-BERT. Mặc dù hầu hết các PLM được nâng cao kiến thức hiện tại nhận thức được việc sử dụng cả ngữ cảnh văn bản và ngữ cảnh kiến thức, ngữ cảnh kiến thức của chúng không thể thay đổi với ngữ cảnh văn bản, như

--- TRANG 3 ---
ERNIE sử dụng các thực thể đơn lẻ, KRL và KnowBert nhúng các đồ thị con độc lập với ngữ cảnh văn bản, K-BERT và K-ADAPTER sử dụng các đồ thị con cố định. Ngược lại, mô hình Coke được đề xuất của chúng tôi có thể tận dụng các đồ thị con động có kích thước tùy ý làm ngữ cảnh kiến thức theo ngữ cảnh văn bản.

Cũng có một số phương pháp PLM để nắm bắt kiến thức chỉ từ ngữ cảnh văn bản. SpanBERT (Mandar et al., 2019) và ERNIE 1.0-Baidu (Yu et al., 2019) đề xuất dự đoán các span có độ dài biến đổi được mask hoặc các đề cập thực thể để khuyến khích PLM học các cụm từ đa token. WKLM (Xiong et al., 2019) được huấn luyện để phân biệt liệu một đề cập thực thể đã được thay thế bằng tên của các thực thể khác có cùng loại để học các loại thực thể. LIBERT (Lauscher et al., 2019) và SenseBERT (Yoav et al., 2019) mở rộng PLM để dự đoán các mối quan hệ từ (ví dụ, từ đồng nghĩa và hyponym-hypernym) và word-supersense tương ứng để tiêm kiến thức ngữ nghĩa từ vựng. Hơn nữa, cũng có những nỗ lực về việc tiếp tục truyền kiến thức (Yu et al., 2020; Wang et al., 2020). Mặc dù các mô hình này không sử dụng ngữ cảnh kiến thức bổ sung để hiểu kiến thức thực tế, chúng bổ sung cho công việc của chúng tôi và có thể được sử dụng cùng nhau hướng tới PLM tốt hơn.

3 Phương pháp
Như được hiển thị trong Hình 2, Coke bao gồm ba module:

(1) Text Encoder tính toán các embedding cho văn bản đầu vào, tức là ngữ cảnh văn bản;

(2) Dynamic Knowledge Context Encoder trước tiên lựa chọn ngữ cảnh kiến thức một cách động theo ngữ cảnh văn bản, và sau đó tính toán các embedding kiến thức theo ngữ cảnh được điều kiện trên cả ngữ cảnh văn bản và ngữ cảnh KG;

(3) Knowledge Fusion Encoder kết hợp cả embedding ngữ cảnh văn bản và ngữ cảnh kiến thức động để hiểu ngôn ngữ tốt hơn. Trong phần này, chúng tôi sẽ trước tiên đưa ra các ký hiệu và sau đó trình bày chi tiết ba module.

3.1 Ký hiệu
Một KG được ký hiệu bởi G=f(h;r;t )jh;t2E;r2Rg, trong đó E và R là tập hợp các thực thể và mối quan hệ tương ứng. Đối với mỗi sự kiện (h;r;t )2G, nó chỉ ra rằng có một mối quan hệ r giữa thực thể đầu h và thực thể đuôi t. Cho một chuỗi token S=fwjgN j=1 có độ dài N, một số token trong chuỗi có thể tương ứng với các thực thể nhất định trong E, chúng tôi đặt tên các token này là "đề cập thực thể" và ký hiệu các thực thể được đề cập của chúng trong KG là fejgM j=1, trong đó M là số lượng thực thể được đề cập2.

3.2 Text Encoder
Tương tự như các PLM được nâng cao kiến thức hiện có, Coke tận dụng một bộ mã hóa Transformer hai chiều L-tầng (Vaswani et al., 2017; Devlin et al., 2019) để nhúng văn bản đầu vào (token) S=fwjgN j=1 và thu được các biểu diễn ngữ cảnh văn bản của nó, được ký hiệu là T-Encoder (),

fwjgN j=1=T-Encoder (fwjgN j=1): (1)

Vì T-Encoder () giống như được sử dụng trong BERT, chúng tôi giới thiệu độc giả đến bài báo gốc (Devlin et al., 2019) để biết thêm chi tiết.

3.3 Dynamic Knowledge Context Encoder

Xây dựng Ngữ cảnh Kiến thức Thô Vì KG thường có quy mô lớn, chúng tôi trước tiên xây dựng ngữ cảnh kiến thức thô để có hiệu quả tính toán. Sau đó chúng tôi lựa chọn và nhúng ngữ cảnh kiến thức phù hợp một cách động có thể khớp với ngữ cảnh văn bản. Cụ thể, cho một thực thể được đề cập m2E được đề cập bởi văn bản đầu vào S=fwjgN j=1, chúng tôi định nghĩa ngữ cảnh kiến thức thô Gm của nó là một đồ thị con của G tập trung vào m. Các thực thể của Gm cách xa m tối đa K-hop. Chính thức, chúng tôi định nghĩa tập hợp thực thể cách 0-hop là E0 m=fmg. Sau đó tập hợp thực thể cách i-hop Ei m có thể được định nghĩa đệ quy là

!Ei m=n th2Ei1 m^t =2Si1 j=0Ej m;(h;r;t )2Go ;
 Ei m=n ht2Ei1 m^h =2Si1 j=0Ej m;(h;r;t )2Go ;
Ei m= !Ei m[ Ei m: (2)

Theo trực giác, tất cả các thực thể trong Ei m (cả thực thể đầu hoặc đuôi) chỉ có mối quan hệ với các thực thể trong Ei1 m. Sau đó, ngữ cảnh kiến thức thô Gm và tập hợp thực thể Em của nó có thể được định nghĩa là

Em=K[ i=0Ei m
Gm= (h;r;t )h2Em^t2Em; (h;r;t )2G : (3)

2Thông thường, M 6=N vì một thực thể có thể tương ứng với nhiều token khác nhau. Trong công việc này, chúng tôi sử dụng bộ công cụ TAGME để xác định các thực thể được đề cập.

--- TRANG 4 ---
Kx DK-Encoder  Px K-Encoder  Steph Curry và Klay Thompson dẫn dắt Warriors đến chức vô địch NBA
Đầu ra…
…Play for
Steph Curry, Warriors
Daughter of 
Riley, Steph Curry
Warriors
Riley
Clay
S.F
C.A
N.C
Riley
Warriors, Play for, Located, Live in, was Born in…
…
…
…Steph Curry, Riley, Warriors………………Nx T-Encoder  

Lựa chọn và Nhúng Ngữ cảnh Kiến thức, Xây dựng Ngữ cảnh Kiến thức Thô, 1-hop, 2-hop

Steph Curry và Klay Thompson dẫn dắt Warriors đến chức vô địch NBA
Đầu vào cho các nhiệm vụ NLP thông thường: Steph Curry và Klay [CLS] Thompson
Đầu vào cho các nhiệm vụ Phân loại Thực thể: và Klay [CLS] Thompson [ENT] Steph Curry [ENT]
Đầu vào cho các nhiệm vụ Phân loại Mối quan hệ: và Klay [CLS] Thompson [HD] Steph Curry [HD] [TL] [SEP] [SEP] [SEP] [TL] [CLS] [ENT] [HD] [TL]
Các nhiệm vụ NLP thông thường, Phân loại Thực thể, Phân loại Mối quan hệ………E

Hình 2: (a) Phần trên là khung tổng thể của Coke và minh họa cách tạo ra các biểu diễn thực thể.
(b) Phần dưới là ví dụ về việc chèn các token đặc biệt vào chuỗi đầu vào cho các nhiệm vụ cụ thể trong quá trình tinh chỉnh.

Lựa chọn và Nhúng Ngữ cảnh Kiến thức
Để lựa chọn các đặc trưng có thông tin một cách động trong Gm và nhúng các đặc trưng này cho PLM, chúng tôi đề xuất một mạng nơ-ron đồ thị được điều khiển bởi ngữ nghĩa (S-GNN). Đối với mỗi thực thể trong Gm, tức là e2Em, chúng tôi khởi tạo các đặc trưng đầu vào của nó cho S-GNN với embedding tiền huấn luyện của nó bởi TransE (Bordes et al., 2013) (Các mô hình embedding kiến thức khác cũng có thể cung cấp embedding tiền huấn luyện cho S-GNN), và đặt tên các đặc trưng được khởi tạo là e0.

Để chuyển đổi đầy đủ thông tin cấu trúc và kiến thức giữa các thực thể trong Gm, S-GNN bao gồm một số tầng ẩn để tổng hợp thông tin theo cấu trúc của Gm. Tại tầng thứ i, cho một thực thể e2Em, S-GNN tổng hợp tất cả thông tin từ thực thể lân cận n và r trong Gm,

hi n!e=Wi[n+r;ni1];(n;r;e )2Gm
Wi[nr;ni1];(e;r;n )2Gm; (4)

trong đó ni1 là embedding của n tại tầng i1, n và r là các embedding thực thể và mối quan hệ tương ứng được tiền huấn luyện bởi TransE, Wi là một ma trận tuyến tính có thể học, và [;] ký hiệu phép nối ngang của các vector. Sau đó embedding của e tại tầng thứ i có thể được tính toán là

ei=fi(fhi n!egn2Ne); (5)

trong đó Ne là tập hợp lân cận của e, fi() là hàm để tổng hợp thông tin tại tầng thứ i và sẽ được giới thiệu chi tiết tiếp theo.

Vì không phải tất cả thông tin trong ngữ cảnh kiến thức thô Gm đều hữu ích để hiểu các token văn bản đầu vào S=fwjgN j=1, chúng tôi thiết kế một cơ chế attention ngữ nghĩa đặc biệt làm hàm fi trong Eq. (5) để lọc bỏ thông tin không liên quan và tổng hợp thông tin cần thiết. Cơ chế attention hàm fi có thể được biểu thị chính thức như sau,

fi(fhi ^e!eg^e2Ne) = X ^e2Ne exp(k> ^eq)P ~e2Ne exp(k> ~eq)hi ^e!e; (6)

trong đó q, kn được gọi là các vector truy vấn và khóa tương ứng.

Để lựa chọn thông tin một cách động theo ngữ cảnh văn bản, vector truy vấn q đến từ embedding của văn bản đầu vào (token):

q= cWis+bbi ; (7)

trong đó = tanh(), cWi và bbi là ma trận tuyến tính có thể học và vector bias tương ứng cho vector truy vấn tại tầng thứ i, s là embedding ngữ nghĩa toàn bộ của văn bản đầu vào (token). Đặc biệt, theo BERT (Devlin et al., 2019), chúng tôi đặt một

--- TRANG 5 ---
token đặc biệt [CLS] ở đầu chuỗi đầu vào, và s là embedding đầu ra của [CLS] được tính toán bởi Eq. (1).

Vector khóa kn dựa trên embedding của mối quan hệ giữa thực thể e và thực thể lân cận n của nó, và được tính toán là

kn=( fWi(r)+ebi;(e;r;n )2Gm fWir+ebi; (n;r;e )2Gm; (8)

trong đó fWi và ebi là ma trận tuyến tính có thể học và vector bias tương ứng cho vector khóa tại tầng thứ i. Hai bộ ba với thực thể đầu và đuôi được hoán đổi sẽ nhận được các vector khóa ngược.

Tóm lại, S-GNN sử dụng ngữ cảnh văn bản để điều chỉnh trọng số của tổng hợp đặc trưng, và cuối cùng lựa chọn và nhúng kiến thức liên quan đến ngữ cảnh văn bản vào các embedding cho PLM. Do đó, cho thực thể được đề cập m, embedding đầu ra của m tại tầng cuối cùng của S-GNN là embedding cuối cùng của nó được tính toán bởi ngữ cảnh kiến thức động của nó. Để đơn giản, cho văn bản đầu vào (token) fwjgN j=1 và các thực thể được đề cập fejgM j=1, toàn bộ tính toán để đạt được các embedding ngữ cảnh kiến thức động được ký hiệu là,

fejgM j=1=DK-Encoder (fejgM j=1;fwjgN j=1): (9)

3.4 Knowledge Fusion Encoder
Bộ mã hóa kết hợp kiến thức nhằm kết hợp thông tin của embedding thực thể theo ngữ cảnh fejgM j=1 và embedding văn bản (token) fwjgN j=1. Chúng tôi tận dụng bộ mã hóa K-Encoder () tương tự như (Zhang et al., 2019) để phục vụ mục đích,

fwo jgN j=1;feo jgM j=1= K-Encoder (fwjgN j=1;fejgM j=1) (10)

Chúng tôi giới thiệu độc giả đến (Zhang et al., 2019) để biết thêm chi tiết. Nói chung, K-Encoder () bao gồm P aggregator. Như được hiển thị trong Hình 2, trong mỗi aggregator, có hai multi-head self-attention tiêm embedding văn bản (token) và kiến thức theo ngữ cảnh tương ứng, và một perceptron đa tầng (MLP) kết hợp hai đặc trưng không đồng nhất.

3.5 Chi tiết Huấn luyện
Chiến lược Tiền huấn luyện Để kết hợp embedding kiến thức vào hiểu ngôn ngữ, chúng tôi mask ngẫu nhiên các căn chỉnh token-thực thể và để mô hình học dự đoán tất cả các thực thể tương ứng cho các token này bằng cách mask các căn chỉnh của chúng. Chúng tôi gọi đây là bộ tự mã hóa thực thể khử nhiễu (dEA), đây là một trong các nhiệm vụ tiền huấn luyện cho các PLM được nâng cao kiến thức hiện có (Zhang et al., 2019).

Bên cạnh đó, chúng tôi chọn BERT BASE (Devlin et al., 2019), RoBERTa BASE (Liu et al., 2019), và RoBERTa LARGE (Liu et al., 2019) làm các mô hình cơ sở của chúng tôi. Xem xét rằng các mô hình cơ sở của chúng tôi ban đầu được tiền huấn luyện bởi các nhiệm vụ tiền huấn luyện khác nhau, chúng tôi có hai mục tiêu huấn luyện khác nhau cho chúng.

Đối với CokeBERTBASE , dựa trên BERT BASE, mục tiêu huấn luyện có thể được mô tả là:

L=LMLM+LNSP+LdEA; (11)

trong đó LMLM và LNSP là các hàm mất mát cho mô hình ngôn ngữ mask và dự đoán câu tiếp theo tương ứng. Mất mát bộ tự mã hóa thực thể khử nhiễu (dEA) là LdEA.

Đối với CokeROBERTABASE và CokeROBERTALARGE , dựa trên RoBERTa BASE và RoBERTa LARGE đại diện, mục tiêu huấn luyện của chúng có thể được mô tả là:

L=LMLM+LdEA; (12)

trong đó mất mát dự đoán câu được loại bỏ.

Tinh chỉnh cho Các Nhiệm vụ Downstream Coke áp dụng quy trình tinh chỉnh tương tự như BERT và lấy embedding đầu ra cuối cùng của token đầu tiên [CLS] cho các nhiệm vụ NLP khác nhau. Tương tự như các PLM được nâng cao kiến thức trước đó, đối với các nhiệm vụ được điều khiển bởi kiến thức như phân loại thực thể và phân loại mối quan hệ, chúng tôi áp dụng các quy trình tinh chỉnh cụ thể. Như được hiển thị trong Hình 2, để giúp Coke kết hợp thông tin ngữ cảnh và đề cập thực thể một cách chú ý, chúng tôi sửa đổi chuỗi đầu vào với các marker đề cập. Chúng tôi chú ý token ở phía trước của đề cập thực thể là [ENT] và sau đó sử dụng embedding đầu ra cuối cùng của [ENT] cho nhiệm vụ phân loại thực thể. Đối với nhiệm vụ phân loại mối quan hệ, chúng tôi chèn các token [HD] và [TL] cho các thực thể đầu và đuôi tương ứng, và nối biểu diễn [HD] và biểu diễn [TL] làm biểu diễn cuối cùng (Baldini Soares et al., 2019) cho nhiệm vụ.

4 Thí nghiệm
Trong các thí nghiệm, chúng tôi trước tiên giới thiệu bộ dữ liệu huấn luyện và các chi tiết huấn luyện khác của mô hình. Sau đó, chúng tôi đưa ra một phân tích thực nghiệm để cho thấy

--- TRANG 6 ---
| Dataset | Train | Dev | Test | Type | Rel |
|---------|-------|-----|------|------|-----|
| FIGER | 2,000,000 | 10,000 | 563 | 113 | - |
| Open Entity | 2,000 | 2,000 | 2,000 | 6 | - |
| FewRel | 8,000 | 16,000 | 16,000 | - | 80 |
| TACRED | 68,124 | 22,631 | 15,509 | - | 42 |

Bảng 1: Thống kê của các bộ dữ liệu FIGER, Open Entity, FewRel, và TACRED.

tính hữu ích của ngữ cảnh kiến thức được lựa chọn. Sau đó chúng tôi so sánh Coke với một số baseline mạnh trong hai nhiệm vụ được hướng dẫn bởi kiến thức điển hình bao gồm phân loại thực thể và phân loại mối quan hệ. Cuối cùng, chúng tôi thực hiện một nghiên cứu ablation để cho thấy hiệu quả của bộ mã hóa ngữ cảnh kiến thức động của chúng tôi.

4.1 Bộ dữ liệu Huấn luyện
Chúng tôi sử dụng Wikipedia tiếng Anh3 làm corpus tiền huấn luyện của chúng tôi và căn chỉnh các đề cập thực thể với Wikidata bằng công cụ liên kết thực thể được sử dụng rộng rãi TAGME (Ferragina và Scaiella, 2010). Có gần 4,500M subword và 140M thực thể trong corpus tiền huấn luyện và chúng tôi lấy mẫu 24,267,796 bộ ba sự kiện, bao gồm 5,040,986 thực thể trong Wikidata. Chúng tôi tiến hành thí nghiệm trên các bộ dữ liệu sau: FIGER, Open Entity, FewRel, và TACRED. Thống kê của các bộ dữ liệu này được hiển thị trong Bảng 1. Bên cạnh đó, chúng tôi sử dụng embedding kiến thức của WikiData được phát hành bởi (Zhang et al., 2019).

4.2 Cài đặt Thí nghiệm
Cài đặt Huấn luyện và Tham số Trong các thí nghiệm, chúng tôi chọn BERT BASE (Devlin et al., 2019), RoBERTa BASE và RoBERTa LARGE (Liu et al., 2019) làm các mô hình cơ sở của chúng tôi. Để giảm chi phí huấn luyện từ đầu, chúng tôi áp dụng các tham số được phát hành của các mô hình này để khởi tạo bộ mã hóa văn bản của chúng tôi và phần còn lại của các tham số của Coke đều được khởi tạo ngẫu nhiên.

Để tối ưu hóa, chúng tôi đặt learning rate là 5×10^-5, độ dài chuỗi tối đa là 256, kích thước batch là 32, và các cài đặt còn lại phần lớn theo các PLM gốc. Để tinh chỉnh, chúng tôi sử dụng các tham số giống như tiền huấn luyện ngoại trừ kích thước batch và learning rate. Trong tất cả các nhiệm vụ downstream, chúng tôi chọn kích thước batch từ {16,32,64}, learning rate là 2×10^-5, số epoch từ {5,6,7,8,9,10}. Các phạm vi giá trị sau đây đều hoạt động tốt. Bên cạnh đó, để ngăn Coke khỏi overfitting trong FIGER, chúng tôi sử dụng kích thước batch lớn

3https://en.wikipedia.org/

1024. Chúng tôi tham khảo thêm chi tiết về cài đặt huấn luyện và siêu tham số trong Phụ lục của chúng tôi.

Baseline Chúng tôi chia các mô hình baseline thành ba nhóm:
Các mô hình dựa trên BERT BASE, các mô hình dựa trên RoBERTa BASE, và các mô hình dựa trên RoBERTa LARGE. Vì công bằng, tất cả các mô hình chỉ kết hợp kiến thức thực tế từ Wikidata. Đối với các PLM được nâng cao kiến thức như ERNIE, KnowBert, và K-BERT, chúng tôi tái hiện chúng hoặc sử dụng mã được phát hành của chúng cho các thí nghiệm của chúng tôi, và báo cáo các kết quả có thể khớp với kết quả của chúng trong các bài báo gốc. Vì K-ADAPTER tương tự như K-BERT và không có mã được phát hành nào, chúng tôi do đó so sánh trực tiếp với K-BERT thay vì K-ADAPTER.

4.3 Phân tích Thực nghiệm cho Việc Lựa chọn Ngữ cảnh Kiến thức Động
Để chứng minh Coke có thể nắm bắt thông tin hữu ích từ KG, chúng tôi thiết kế một thí nghiệm định tính và định lượng để đánh giá Coke.

Trong thí nghiệm định tính, cho các đề cập thực thể giống nhau trong ngữ cảnh khác nhau, chúng tôi áp dụng PLM để lựa chọn các bộ ba 1-hop liên quan đến văn bản ("ngữ cảnh kiến thức 1-hop") từ Wikidata, tương tự như Eq. (6) không có phép tổng. Cụ thể hơn, chúng tôi áp dụng [CLS] của văn bản đầu vào (token) được tính toán bởi các PLM này để chú ý đến mỗi bộ ba lân cận của các đề cập thực thể.

Như được hiển thị trong Bảng 2, khi cho câu ":::Bill Gates và Mark Zuckerberg bỏ học Harvard:::" chỉ ra mối quan hệ alumni giữa Mark Zuckerberg và Bill Gates, mô hình của chúng tôi chú ý nhiều hơn đến kiến thức thực tế về giáo dục của họ. Tuy nhiên khi cho câu "Bill Gates và Mark Zuckerberg đang làm việc cùng nhau :::" chỉ ra sự hợp tác giữa Mark Zuckerberg và Bill Gates, kiến thức thực tế về các doanh nghiệp của họ được mô hình của chúng tôi xem xét. Rõ ràng, chúng ta có thể thấy điểm quan trọng của các bộ ba được chú ý là có thể diễn giải và có thể giúp chúng ta hiểu ngữ nghĩa rõ ràng hơn.

Trong thí nghiệm định lượng, chúng tôi chú thích các tập test của FewRel và TACRED. Cho một mẫu, bao gồm ngữ cảnh và các đề cập thực thể tương ứng, chúng tôi chú thích thủ công các bộ ba 1-hop của nó bằng cách đánh giá mức độ liên quan giữa ngữ cảnh và các bộ ba. Cuối cùng, chúng tôi trích xuất 15981 instance từ FewRel và 5684 instance từ TACRED. Bằng cách xếp hạng điểm quan trọng của tất cả các bộ ba cho một đề cập thực thể và đặt một ngưỡng, chúng tôi có thể thu được các

--- TRANG 7 ---
| Text | [CLS] Cả nhà đồng sáng lập Microsoft Bill Gates và nhà đồng sáng lập Facebook Mark Zuckerberg đều bỏ học Harvard và bắt đầu xây dựng công ty của họ gần cùng thời điểm. |
|------|-------|
| Factual triple | Mark Zuckerberg, Bill Gates, alumnus |

| Entity h: Mark Zuckerberg |  |  |
|---|---|---|
| Importance | Entity t | Relation |
| 19% | Harvard University | educated at |
| 19% | Phillips Exeter Academy | educated at |
| 19% | Ardsley High School | educated at |
| 10% | Facebook | CEO of |
| 10% | Chief executive officer | position held |
| 6% | Businessperson | occupation |
| 6% | Computer scientist | occupation |
| 6% | Palo Alto, California | residence |
| 3% | White Plains, New York | place of birth |
| 2% | Mandarin Chinese | languages spoken |

| Entity h: Bill Gates |  |  |
|---|---|---|
| Importance | Entity t | Relation |
| 35% | Harvard University | educated at |
| 11% | Microsoft | CEO of |
| 11% | Chief executive officer | position held |
| 9% | American Academy of Arts and Sciences | member of |
| 9% | National Academy of Engineering | member of |
| 6% | Computer scientist | occupation |
| 6% | Investor | occupation |
| 6% | Businessperson | occupation |
| 4% | Bill&Melinda Gates Foundation | foundation of |
| 3% | United States | citizenship |

| Text | [CLS] Bill Gates và Mark Zuckerberg đang làm việc cùng nhau để tài trợ nghiên cứu các phương pháp điều trị COVID-19. |
|------|-------|
| Factual triple | Mark Zuckerberg, Bill Gates, cooperate |

| Entity h: Mark Zuckerberg |  |  |
|---|---|---|
| Importance | Entity t | Relation |
| 15% | Facebook | CEO of |
| 14% | Chief executive officer | position held |
| 11% | Businessperson | occupation |
| 11% | Computer scientist | occupation |
| 9% | Harvard University | educated at |
| 9% | Phillips Exeter Academy | educated at |
| 9% | Ardsley High School | educated at |
| 8% | Palo Alto, California | residence |
| 7% | White Plains, New York | place of birth |
| 7% | Mandarin Chinese | languages spoken |

| Entity h: Bill Gates |  |  |
|---|---|---|
| Importance | Entity t | Relation |
| 33% | Bill&Melinda Gates Foundation | foundation of |
| 10% | Microsoft | CEO of |
| 9% | Chief executive officer | position held |
| 8% | American Academy of Arts and Sciences | member of |
| 8% | National Academy of Engineering | member of |
| 7% | Computer scientist | occupation |
| 7% | Investor | occupation |
| 7% | Businessperson | occupation |
| 6% | Harvard University | educated at |
| 5% | United States | citizenship |

Bảng 2: Độ đậm của màu thể hiện tầm quan trọng của các bộ ba cho một câu đã cho.

| | FewRel | | TACRED | |
|---|---|---|---|---|
| | P | R | F1 | P | R | F1 |
| ERNIE | 87.6 | 50.6 | 64.1 | 81.1 | 41.8 | 55.1 |
| CokeBERT^BASE | 87.9 | 71.5 | 78.9 | 86.1 | 58.4 | 69.6 |
| CokeROBERTA^BASE | 79.8 | 84.0 | 81.9 | 74.9 | 72.0 | 73.4 |

Bảng 3: Kết quả của việc nắm bắt các bộ ba tích cực từ các bộ ba được gán nhãn trên FewRel và TACRED (%).

bộ ba tích cực và bộ ba tiêu cực để tính điểm F1 cho đánh giá.

Để chứng minh công bằng hiệu quả của việc trích xuất bộ ba qua Coke, chúng tôi chọn ERNIE làm mô hình baseline, vốn vốn dĩ căn chỉnh không gian embedding ngôn ngữ và không gian embedding KG sử dụng cùng dữ liệu huấn luyện như Coke. Như được hiển thị trong Bảng 3, điểm F1 của Coke tốt hơn mô hình baseline 14.8%-17.8% trên FewRel và 14.5%-18.3% trên TACRED.

4.4 Kết quả Đánh giá Tổng thể
Trong phần này, chúng tôi so sánh các mô hình của chúng tôi với các PLM hiệu quả khác nhau về phân loại thực thể và phân loại mối quan hệ, bao gồm cả PLM vanilla và PLM được nâng cao kiến thức.

Phân loại Thực thể Cho một đề cập thực thể và câu tương ứng của nó, phân loại thực thể yêu cầu phân loại đề cập thực thể thành các loại của nó. Đối với nhiệm vụ này, chúng tôi tinh chỉnh Coke trên FIGER (Ling et al., 2015) và Open Entity (Choi et al., 2018). Tập huấn luyện của FIGER được gán nhãn với giám sát từ xa, và tập test của nó được chú thích bởi con người. Open Entity là một bộ dữ liệu được chú thích thủ công hoàn toàn. Chúng tôi so sánh mô hình của chúng tôi với các mô hình baseline mà chúng tôi đã đề cập trong Baseline 4.2.

Như được hiển thị trong Bảng 4, Coke có thể đạt được điểm F1 tương đương trên Open Entity. Trên FIGER, Coke vượt trội đáng kể so với BERT BASE và RoBERTa BASE lần lượt 3.7% và 3.5% điểm Micro. Bên cạnh đó, hiệu suất của Coke cũng tốt hơn các mô hình baseline khác. Điều này trực tiếp chứng minh rằng Coke có khả năng tốt hơn trong việc giảm thách thức nhãn nhiễu trong FIGER so với các mô hình baseline mà chúng tôi đã đề cập ở trên.

Hơn nữa, chúng tôi thấy rằng lĩnh vực của FIGER tương tự như Wikidata, điều này phù hợp với quan sát trong phần phân tích thực nghiệm, làm nổi bật thêm tầm quan trọng của việc lựa chọn ngữ cảnh kiến thức qua các lĩnh vực.

--- TRANG 8 ---
| Task | Entity Typing | | Relation Classification | |
|------|---------------|---|------------------------|---|
| Dataset | Open Entity | FIGER | FewRel | TACRED |
| Metric | P | R | F1 | Acc. | Macro | Micro | P | R | F1 | P | R | F1 |

**Pre-Trained Language Models**
| BERT BASE | 76.2 | 71.0 | 73.6 | 52.0 | 75.2 | 71.6 | 85.0 | 85.1 | 84.9 | 67.2 | 64.8 | 66.0 |
| RoBERTa BASE | 75.3 | 73.2 | 74.2 | 56.3 | 76.9 | 74.2 | 86.3 | 86.3 | 86.3 | 73.0 | 68.7 | 70.8 |
| RoBERTa LARGE | 78.5 | 72.7 | 75.5 | 57.1 | 82.4 | 76.5 | 88.4 | 88.4 | 88.4 | 74.3 | 66.8 | 70.4 |

**Knowledge Enhanced Pre-Trained Language Models**
| ERNIE | 78.4 | 72.9 | 75.6 | 57.2 | 76.5 | 73.4 | 88.5 | 88.4 | 88.3 | 69.9 | 66.0 | 67.9 |
| K-BERT | 76.7 | 71.5 | 74.0 | 56.5 | 77.1 | 73.8 | 83.1 | 85.9 | 84.3 | 68.1 | 66.1 | 67.1 |
| KnowBert-Wiki | 78.6 | 71.6 | 75.0 | 57.0 | 79.8 | 75.0 | 89.2 | 89.2 | 89.2 | 71.1 | 66.8 | 68.9 |

**Contextual Knowledge Enhanced Pre-Trained Language Models**
| CokeBERT^BASE | 78.0 | 73.3 | 75.6 | 57.9 | 79.7 | 75.3 | 89.4 | 89.4 | 89.4 | 71.0 | 66.9 | 68.9 |
| CokeROBERTA^BASE | 76.8 | 74.2 | 75.6 | 62.2 | 82.3 | 77.7 | 90.1 | 90.1 | 90.1 | 71.3 | 71.0 | 71.1 |
| CokeROBERTA^LARGE | 75.3 | 76.2 | 75.7 | 58.3 | 82.3 | 77.8 | 91.1 | 91.1 | 91.1 | 69.9 | 71.8 | 70.8 |

Bảng 4: Kết quả của các mô hình khác nhau cho Phân loại Mối quan hệ và Phân loại Thực thể (%).

**Phân loại Mối quan hệ** Phân loại mối quan hệ nhằm xác định mối quan hệ đúng giữa hai thực thể trong một câu đã cho. Chúng tôi tinh chỉnh Coke trên hai bộ dữ liệu benchmark được sử dụng rộng rãi FewRel (Han et al., 2018) và TACRED (Zhang et al., 2017). Chúng tôi cũng so sánh mô hình của chúng tôi với các mô hình baseline mà chúng tôi đã đề cập trong Baseline 4.2.

Trên FewRel, Coke vượt trội đáng kể so với BERT BASE và RoBERTa BASE lần lượt 4.5% và 3.8% điểm F1 như được hiển thị trong Bảng 4. Điều này trực tiếp chứng minh rằng Coke có thể nắm bắt mối quan hệ giữa hai thực thể tốt hơn ERNIE bằng cách xem xét thông tin của các lân cận bậc cao hơn, đặc biệt trong bộ dữ liệu nhỏ FewRel.

Bên cạnh đó, các mô hình Coke có kết quả tương đương với các mô hình baseline khác trên TACRED nhưng đạt được các cải thiện đáng kể trên FewRel. Như chúng tôi đã đề cập trước đó, lĩnh vực của dữ liệu FewRel tương tự hơn với Wikidata và do đó nó nhận được nhiều lợi ích hơn từ tiền huấn luyện.

4.5 Nghiên cứu Ablation
Để chỉ ra tác động của S-GNN đối với quá trình lựa chọn ngữ cảnh kiến thức một cách động, chúng tôi tiến hành các nghiên cứu ablation cần thiết cho các module khác nhau trong S-GNN.

**K-Hop Sub-Graphs** Trong phần này, chúng tôi khám phá các tác động của bộ mã hóa ngữ cảnh kiến thức động. Có hai thành phần chính trong bộ mã hóa ngữ cảnh kiến thức động: xây dựng ngữ cảnh kiến thức thô và S-GNN. Coke áp dụng xây dựng ngữ cảnh kiến thức thô để lấy mẫu các

(a) FewRel
(b) FIGER

Hình 3: Kết quả của Coke kết hợp các đồ thị con K-hop (%).

đồ thị con K-hop, và sau đó kết hợp S-GNN để nhúng kiến thức có thông tin trong ngữ cảnh thô.

Từ Hình 3, chúng tôi thấy rằng Coke kết hợp đồ thị con 2-hop vượt trội 0.4% đến 0.6% so với kết hợp đồ thị con 1-hop. Điều này chứng minh rằng xem xét một phạm vi kiến thức rộng hơn có thể dẫn đến các embedding thực thể tốt hơn.

**Cơ chế Attention** Trong S-GNN, có một cơ chế cần thiết: attention. Nó chịu trách nhiệm cân nhắc mức độ kiến thức khớp với văn bản và giúp tính toán các embedding theo ngữ cảnh động cuối cùng. Để chứng minh thêm tác động của cơ chế attention, chúng tôi đơn giản hóa nó bằng một phép toán mean-pooling để tổng hợp các đặc trưng. Từ Hình 4, chúng ta có thể thấy rằng cơ chế attention vượt trội so với cơ chế mean-pooling và embedding cố định (ERNIE), cho thấy hiệu quả của cơ chế attention của chúng tôi.

5 Kết luận và Công việc Tương lai
Chúng tôi đã đề xuất một khung hiệu quả và tổng quát để cho phép PLM lựa chọn động ngữ

--- TRANG 9 ---
(a) FewRel
(b) FIGER

Hình 4: Tác động của cơ chế attention và các phiên bản đơn giản hóa của nó (%).

cảnh kiến thức phù hợp với ngữ cảnh văn bản, và sau đó chèn kiến thức được nhúng vào PLM. Các thí nghiệm chứng minh rằng Coke có thể đạt được kết quả tương đương với các PLM được nâng cao kiến thức tốt nhất trong phân loại thực thể và phân loại mối quan hệ. Coke lựa chọn ngữ cảnh kiến thức một cách động với ngữ cảnh văn bản có thể diễn giải hơn so với việc tiêm tất cả ngữ cảnh kiến thức từ KG. Trong phân tích thực nghiệm, Coke cũng chứng minh việc lựa chọn ngữ cảnh kiến thức hiệu quả. Hướng này có thể dẫn đến hiểu ngôn ngữ tổng quát và hiệu quả hơn. Trong tương lai, chúng tôi sẽ tiếp tục khám phá cách tiêm các loại kiến thức khác (ví dụ: kiến thức ngôn ngữ học) kết hợp với kiến thức thực tế để nâng cao thêm PLM. Và cũng là một hướng thú vị để khám phá cách tiếp tục tiêm kiến thức thực tế mới nổi vào PLM mà không cần huấn luyện lại toàn bộ mô hình.

Tài liệu tham khảo
Livio Baldini Soares, Nicholas FitzGerald, Jeffrey Ling, và Tom Kwiatkowski. 2019. Matching the blanks: Distributional similarity for relation learning. Trong Proceedings of ACL, trang 2895–2905.

Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, và Oksana Yakhnenko. 2013. Translating embeddings for modeling multi-relational data. Trong Proceedings of NeurIPS, trang 2787–2795.

Eunsol Choi, Omer Levy, Yejin Choi, và Luke Zettlemoyer. 2018. Ultra-fine entity typing. Trong Proceedings of ACL, trang 87–96.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understanding. Trong Proceedings of NAACL, trang 4171–4186.

Paolo Ferragina và Ugo Scaiella. 2010. Tagme: On-the-fly annotation of short text fragments (by wikipedia entities). Trong Proceedings of CIKM, trang 1625–1628.

Xu Han, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao, Zhiyuan Liu, và Maosong Sun. 2018. FewRel: A large-scale supervised few-shot relation classification dataset with state-of-the-art evaluation. Trong Proceedings of EMNLP, trang 4803–4809.

Bin He, Di Zhou, Jinghui Xiao, Xin jiang, Qun Liu, Nicholas Jing Yuan, và Tong Xu. 2019. Integrating graph contextualized knowledge into pre-trained language models. arXiv.

Anne Lauscher, Ivan Vulić, Edoardo Maria Ponti, Anna Korhonen, và Goran Glavaš. 2019. Specializing unsupervised pretraining models for word-level semantic similarity. arXiv.

Xiao Ling, Sameer Singh, và Daniel S. Weld. 2015. Design challenges for entity linking. Trong Proceedings of ACL, trang 315–328.

Weijie Liu, Peng Zhou, Zhe Zhao, Zhiruo Wang, Qi Ju, Haotang Deng, và Ping Wang. 2020. K-bert: Enabling language representation with knowledge graph. Trong Proceedings of AAAI, trang 2901–2908.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv.

Joshi Mandar, Chen Danqi, Liu Yinhan, Daniel S. Weld, Zettlemoyer Luke, và Levy Omer. 2019. Spanbert: Improving pre-training by representing and predicting spans. Trong Proceedings of TACL, trang 64–77.

Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, và Luke Zettlemoyer. 2018. Deep contextualized word representations. Trong Proceedings of NAACL-HLT, trang 2227–2237.

Matthew E. Peters, Mark Neumann, Robert L Logan, Roy Schwartz, Vidur Joshi, Sameer Singh, và Noah A. Smith. 2019. Knowledge enhanced contextual word representations. Trong Proceedings of EMNLP, trang 43–54.

Nina Poerner, Ulli Waltinger, và Hinrich Schütze. 2019. BERT is not a knowledge base (yet): Factual knowledge vs. name-based reasoning in unsupervised QA. arXiv.

Alec Radford, Karthik Narasimhan, Tim Salimans, và Ilya Sutskever. 2018. Improving language understanding by generative pre-training. arXiv.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. 2017. Attention is all you need. Trong Proceedings of NeurIPS, trang 5998–6008.

--- TRANG 10 ---
Ruize Wang, Duyu Tang, Nan Duan, Zhongyu Wei, Xuanjing Huang, Jianshu Ji, Cuihong Cao, Daxin Jiang, và Ming Zhou. 2020. K-adapter: Infusing knowledge into pre-trained models with adapters. arXiv.

Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhiyuan Liu, Juan-Zi Li, và Jian Tang. 2019. KEPLER: A unified model for knowledge embedding and pre-trained language representation. arXiv.

Wenhan Xiong, Jingfei Du, William Yang Wang, và Veselin Stoyanov. 2019. Pretrained encyclopedia: Weakly supervised knowledge-pretrained language model. Trong Proceedings of ICLR.

Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, và Quoc V Le. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. Trong Proceedings of NeurIPS, trang 5753–5763.

Levine Yoav, Lenz Barak, Dagan Or, Padnos Dan, Sharir Or, Shalev-Shwartz Shai, Shashua Amnon, và Shoham Yoav. 2019. Sensebert: Driving some sense into bert. Trong Proceedings of ACL, trang 4656–4667.

Sun Yu, Wang Shuohuan, Li Yu-Kun, Feng Shikun, Chen Xuyi, Zhang Han, Tian Xin, Zhu Danxiang, Tian Hao, và Wu Hua. 2019. Ernie: Enhanced representation through knowledge integration. Trong Proceedings of ACL, trang 1441–1451.

Sun Yu, Wang Shuohuan, Li Yukun, Feng Shikun, Tian Hao, Wu Hua, và Wang Haifeng. 2020. Ernie2.0: A continual pre-training framework for language understanding. Trong Proceedings of AAAI.

Yuhao Zhang, Victor Zhong, Danqi Chen, Gabor Angeli, và Christopher D. Manning. 2017. Position-aware attention and supervised data improve slot filling. Trong Proceedings of EMNLP, trang 35–45.

Zhengyan Zhang, Xu Han, Zhiyuan Liu, Xin Jiang, Maosong Sun, và Qun Liu. 2019. Ernie: Enhanced language representation with informative entities. Trong Proceedings of ACL, trang 1441–1451.

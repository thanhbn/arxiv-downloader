I'll translate this research paper from English to Vietnamese while maintaining the exact structure and content.

# Lý luận Logic Phức tạp trên Đồ thị Tri thức sử dụng Mô hình Ngôn ngữ Lớn

Nurendra Choudhary
Khoa Khoa học Máy tính
Đại học Virginia Tech, Arlington, VA, Hoa Kỳ
nurendra@vt.edu

Chandan K. Reddy
Khoa Khoa học Máy tính
Đại học Virginia Tech, Arlington, VA, Hoa Kỳ
reddy@cs.vt.edu

## Tóm tắt

Lý luận trên đồ thị tri thức (KG) là một nhiệm vụ đầy thách thức đòi hỏi sự hiểu biết sâu sắc về các mối quan hệ phức tạp giữa các thực thể và logic cơ bản của các quan hệ của chúng. Các phương pháp hiện tại dựa vào việc học hình học để nhúng các thực thể vào không gian vector cho các phép toán truy vấn logic, nhưng chúng gặp phải hiệu suất kém trên các truy vấn phức tạp và các biểu diễn cụ thể theo tập dữ liệu. Trong bài báo này, chúng tôi đề xuất một phương pháp tách rời mới, Lý luận Trừu tượng được Hướng dẫn bởi Ngôn ngữ trên Đồ thị tri thức (LARK), công thức hóa lý luận KG phức tạp như một sự kết hợp của tìm kiếm KG theo ngữ cảnh và lý luận truy vấn logic, để tận dụng thế mạnh của các thuật toán trích xuất đồ thị và mô hình ngôn ngữ lớn (LLM), tương ứng. Các thí nghiệm của chúng tôi chứng minh rằng phương pháp đề xuất vượt trội hơn các phương pháp lý luận KG tiên tiến nhất trên các tập dữ liệu chuẩn qua nhiều cấu trúc truy vấn logic, với tăng hiệu suất đáng kể cho các truy vấn có độ phức tạp cao hơn. Hơn nữa, chúng tôi cho thấy rằng hiệu suất của phương pháp chúng tôi cải thiện tỷ lệ thuận với việc tăng kích thước của LLM cơ bản, cho phép tích hợp những tiến bộ mới nhất trong LLM cho lý luận logic trên KG. Công trình của chúng tôi trình bày một hướng mới để giải quyết các thách thức của lý luận KG phức tạp và mở đường cho nghiên cứu tương lai trong lĩnh vực này.

## 1 Giới thiệu

Đồ thị tri thức (KG) mã hóa tri thức trong một lược đồ bộ ba linh hoạt nơi hai nút thực thể được kết nối bởi các cạnh quan hệ. Tuy nhiên, một số KG thực tế, như Freebase (Bollacker et al., 2008), Yago (Suchanek et al., 2007), và NELL (Carlson et al., 2010), thường có quy mô lớn, nhiễu và không đầy đủ. Do đó, lý luận trên các KG như vậy là một vấn đề cơ bản và đầy thách thức trong nghiên cứu AI. Mục tiêu bao quát của lý luận logic là phát triển các cơ chế trả lời cho các truy vấn logic bậc nhất (FOL) trên KG sử dụng các toán tử lượng từ tồn tại (∃), hội (∧), tuyển (∨), và phủ định (¬). Nghiên cứu hiện tại về chủ đề này chủ yếu tập trung vào việc tạo ra các hình học không gian tiềm ẩn đa dạng, như vector (Hamilton et al., 2018), hộp (Ren et al., 2020), hyperboloid (Choudhary et al., 2021b), và phân phối xác suất (Ren & Leskovec, 2020), để nắm bắt hiệu quả vị trí ngữ nghĩa và phạm vi logic của các thực thể đồ thị tri thức. Mặc dù thành công, các phương pháp này bị hạn chế về hiệu suất do những điều sau.

(i) **Truy vấn phức tạp**: Chúng dựa vào các công thức hóa bị ràng buộc của các truy vấn FOL mà mất thông tin trên các truy vấn phức tạp đòi hỏi lý luận chuỗi (Choudhary et al., 2021a) và liên quan đến nhiều mối quan hệ giữa các thực thể trong KG, (ii) **Khả năng tổng quát hóa**: tối ưu hóa cho một KG cụ thể có thể không tổng quát hóa cho các KG khác điều này hạn chế khả năng ứng dụng của các phương pháp này trong các tình huống thực tế nơi KG có thể thay đổi rộng rãi về cấu trúc và nội dung, và (iii) **Khả năng mở rộng**: thời gian huấn luyện chuyên sâu hạn chế khả năng mở rộng của các phương pháp này cho các KG lớn hơn và việc kết hợp dữ liệu mới vào các KG hiện có. Để giải quyết những hạn chế này, chúng tôi nhằm tận dụng khả năng lý luận của các mô hình ngôn ngữ lớn (LLM) trong một khung mới, được hiển thị trong Hình 1, gọi là Lý luận Trừu tượng được Hướng dẫn bởi Ngôn ngữ trên Đồ thị tri thức (LARK).

Trong LARK, chúng tôi sử dụng các truy vấn logic để tìm kiếm các ngữ cảnh đồ thị con liên quan trên đồ thị tri thức và thực hiện lý luận chuỗi trên các ngữ cảnh này sử dụng các prompt LLM được phân tách logic. Để đạt được điều này, trước tiên chúng tôi trừu tượng hóa thông tin logic từ cả truy vấn đầu vào và KG. Với tính chất bất biến của logic¹, điều này cho phép phương pháp của chúng tôi tập trung vào công thức hóa logic, tránh ảo giác mô hình², và tổng quát hóa trên các đồ thị tri thức khác nhau. Từ KG trừu tượng này, chúng tôi trích xuất các đồ thị con liên quan sử dụng các thực thể và quan hệ có mặt trong truy vấn logic. Các đồ thị con này phục vụ như các prompt ngữ cảnh cho đầu vào LLM. Trong giai đoạn tiếp theo, chúng tôi cần xử lý hiệu quả các truy vấn lý luận phức tạp. Từ các công trình trước đây (Zhou et al., 2023; Khot et al., 2023), chúng tôi nhận ra rằng LLM kém hiệu quả đáng kể trên các prompt phức tạp, khi so sánh với một chuỗi các prompt đơn giản hơn. Do đó để đơn giản hóa truy vấn, chúng tôi khai thác tính chất logic của chúng và phân tách xác định truy vấn đa phép toán thành các truy vấn sơ cấp được sắp xếp logic, mỗi cái chứa một phép toán duy nhất (được mô tả trong quá trình chuyển từ Hình 1b sang 1c). Mỗi truy vấn logic phân tách này sau đó được chuyển đổi thành một prompt và xử lý qua LLM để tạo ra tập hợp câu trả lời cuối cùng (được hiển thị trong Hình 1d). Các truy vấn logic được xử lý tuần tự, và nếu truy vấn y phụ thuộc vào truy vấn x, thì x được lên lịch trước y. Các phép toán được lên lịch theo cách được sắp xếp logic để cho phép nhóm các truy vấn logic khác nhau cùng nhau, và các câu trả lời được lưu trữ trong bộ nhớ đệm để truy cập dễ dàng.

[Hình 1: Ví dụ về phân tách chuỗi truy vấn và trả lời LLM được sắp xếp logic của LARK cho hiệu suất hiệu quả. LLM giỏi hơn trong việc trả lời các truy vấn đơn giản, và do đó, chúng tôi phân tách truy vấn logic phức tạp đa phép toán (a,b) thành các truy vấn sơ cấp với phép toán đơn (c) và sau đó sử dụng phương pháp trả lời tuần tự dựa trên LLM để đưa ra câu trả lời cuối cùng (d).]

Phương pháp đề xuất tích hợp hiệu quả lý luận logic trên đồ thị tri thức với các khả năng của LLM, và theo hiểu biết tốt nhất của chúng tôi, là loại đầu tiên. Không giống các phương pháp trước đây dựa vào các công thức hóa bị ràng buộc của các truy vấn logic bậc nhất (FOL), phương pháp của chúng tôi sử dụng các prompt LLM được phân tách logic để cho phép lý luận chuỗi trên các đồ thị con được truy xuất từ đồ thị tri thức, cho phép chúng tôi tận dụng hiệu quả khả năng lý luận của LLM. Mô hình tìm kiếm KG của chúng tôi được lấy cảm hứng từ các kỹ thuật tăng cường truy xuất (Chen et al., 2022) nhưng nhận ra tính chất xác định của đồ thị tri thức để đơn giản hóa việc truy xuất các đồ thị con liên quan. Hơn nữa, so với các phương pháp prompt khác (Wei et al., 2022; Zhou et al., 2023; Khot et al., 2023), kỹ thuật phân tách chuỗi của chúng tôi tăng cường khả năng lý luận trong đồ thị tri thức bằng cách tận dụng chuỗi các phép toán logic cơ bản trong các truy vấn phức tạp, và bằng cách sử dụng các câu trả lời trước đó giữa các truy vấn liên tiếp theo cách được sắp xếp logic. Để tóm tắt, các đóng góp chính của bài báo này như sau:

1. Chúng tôi đề xuất, Lý luận Trừu tượng được Hướng dẫn bởi Ngôn ngữ trên Đồ thị tri thức (LARK), một mô hình mới sử dụng khả năng lý luận của các mô hình ngôn ngữ lớn để trả lời hiệu quả các truy vấn FOL trên đồ thị tri thức.

2. Mô hình của chúng tôi sử dụng các thực thể và quan hệ trong truy vấn để tìm các ngữ cảnh đồ thị con thích hợp trong các đồ thị tri thức trừu tượng, và sau đó, thực hiện lý luận chuỗi trên các ngữ cảnh này sử dụng các prompt LLM của các truy vấn logic được phân tách.

3. Các thí nghiệm của chúng tôi về lý luận logic qua các tập dữ liệu KG tiêu chuẩn chứng minh rằng LARK vượt trội hơn các phương pháp tiên tiến nhất trước đây từ 35%-84% MRR trên 14 loại truy vấn FOL dựa trên các phép toán phép chiếu (p), giao (∧), hợp (∨), và phủ định (¬).

4. Chúng tôi thiết lập các ưu điểm của phân tách chuỗi bằng cách cho thấy LARK hoạt động tốt hơn 20%-33% trên các truy vấn logic được phân tách khi so sánh với các truy vấn phức tạp trong nhiệm vụ lý luận logic. Ngoài ra, phân tích của chúng tôi về LLM cho thấy đóng góp đáng kể của việc tăng quy mô và thiết kế tốt hơn của LLM cơ bản đối với hiệu suất của LARK.

¹ các truy vấn logic tuân theo cùng một tập hợp các quy tắc và thủ tục bất kể ngữ cảnh KG.
² mô hình bỏ qua tri thức thông thường ngữ nghĩa và chỉ suy luận từ các thực thể KG cho câu trả lời.

## 2 Công trình Liên quan

Công trình của chúng tôi nằm ở giao điểm của hai chủ đề, cụ thể là lý luận logic trên đồ thị tri thức và các kỹ thuật prompt lý luận trong LLM.

**Lý luận Logic trên KG**: Các phương pháp ban đầu trong lĩnh vực này (Bordes et al., 2013; Nickel et al., 2011; Das et al., 2017; Hamilton et al., 2018) tập trung vào việc nắm bắt thông tin ngữ nghĩa của các thực thể và các phép toán quan hệ liên quan trong phép chiếu giữa chúng. Tuy nhiên, nghiên cứu tiếp theo trong lĩnh vực này đã tiết lộ nhu cầu về các hình học mới để mã hóa thông tin không gian và phân cấp có mặt trong đồ thị tri thức. Để giải quyết vấn đề này, các mô hình như Query2Box (Ren et al., 2020), HypE (Choudhary et al., 2021b), PERM (Choudhary et al., 2021a), và BetaE (Ren & Leskovec, 2020) đã mã hóa các thực thể và quan hệ dưới dạng hộp, hyperboloid, phân phối Gaussian, và phân phối beta, tương ứng. Ngoài ra, các phương pháp như CQD (Arakelyan et al., 2021) đã tập trung vào cải thiện hiệu suất của các nhiệm vụ lý luận phức tạp thông qua việc kết hợp câu trả lời của các truy vấn trung gian đơn giản. Trong một hướng nghiên cứu khác, HamQA (Dong et al., 2023) và QA-GNN (Yasunaga et al., 2021) đã phát triển các kỹ thuật hỏi đáp sử dụng các lân cận đồ thị tri thức để tăng cường hiệu suất tổng thể. Chúng tôi nhận thấy rằng các phương pháp trước đây trong lĩnh vực này đã tập trung vào việc tăng cường biểu diễn KG cho lý luận logic. Trái ngược với các phương pháp hiện có này, công trình của chúng tôi cung cấp một khung hệ thống tận dụng khả năng lý luận của LLM và điều chỉnh chúng hướng đến vấn đề lý luận logic trên đồ thị tri thức.

**Prompt lý luận trong LLM**: Các nghiên cứu gần đây đã cho thấy rằng LLM có thể học các nhiệm vụ NLP khác nhau chỉ với các prompt ngữ cảnh (Brown et al., 2020). Hơn nữa, LLM đã được áp dụng thành công cho các nhiệm vụ lý luận đa bước bằng cách cung cấp các bước lý luận trung gian, còn được gọi là Chuỗi Suy nghĩ (Wei et al., 2022; Chowdhery et al., 2022), cần thiết để đi đến một câu trả lời. Hoặc, một số nghiên cứu đã kết hợp nhiều LLM hoặc LLM với các hàm biểu tượng để thực hiện lý luận đa bước (Jung et al., 2022; Creswell et al., 2023), với cấu trúc phân tách được định nghĩa trước. Các nghiên cứu gần đây hơn như các chiến lược prompt từ ít nhất đến nhiều nhất (Zhou et al., 2023), liên tiếp (Dua et al., 2022) và được phân tách (Khot et al., 2023) chia một prompt phức tạp thành các prompt con và trả lời chúng tuần tự để có hiệu suất hiệu quả. Trong khi hướng công trình này gần với phương pháp của chúng tôi, họ không sử dụng các câu trả lời trước đây để thông báo cho các truy vấn liên tiếp. LARK là độc đáo do khả năng sử dụng cấu trúc logic trong cơ chế phân tách chuỗi, tăng cường lân cận đồ thị tri thức được truy xuất, và cấu trúc trả lời đa giai đoạn kết hợp các câu trả lời LLM trước đó giữa các truy vấn liên tiếp.

## 3 Phương pháp

Trong phần này, chúng tôi sẽ mô tả thiết lập vấn đề của lý luận logic trên đồ thị tri thức, và mô tả các thành phần khác nhau của mô hình chúng tôi.

### 3.1 Công thức hóa Vấn đề

Trong công trình này, chúng tôi giải quyết vấn đề lý luận logic trên đồ thị tri thức (KG) G: E×R lưu trữ các thực thể (E) và quan hệ (R). Không mất tính tổng quát, KG cũng có thể được tổ chức như một tập hợp các bộ ba ⟨e₁,r,e₂⟩ ⊆ G, nơi mỗi quan hệ r ∈ R là một hàm Boolean r: E×E → {True, False} chỉ ra liệu quan hệ r có tồn tại giữa cặp thực thể (e₁,e₂) ∈ E hay không. Chúng tôi xem xét bốn phép toán logic bậc nhất (FOL) cơ bản: phép chiếu (p), giao (∧), hợp (∨), và phủ định (¬) để truy vấn KG. Các phép toán này được định nghĩa như sau:

q_p[Q_p] ≜ ?V_p: {v₁,v₂,...,v_k} ⊆ E ∃a₁                                    (1)
q_∧[Q_∧] ≜ ?V_∧: {v₁,v₂,...,v_k} ⊆ E ∃a₁∧a₂∧...∧a_i                      (2)
q_∨[Q_∨] ≜ ?V_∨: {v₁,v₂,...,v_k} ⊆ E ∃a₁∨a₂∨...∨a_i                      (3)
q_¬[Q_¬] ≜ ?V_¬: {v₁,v₂,...,v_k} ⊆ E ∃¬a₁                                 (4)

nơi Q_p, Q_¬ = (e₁,r₁); Q_∧, Q_∨ = {(e₁,r₁),(e₂,r₂),...,(e_i,r_i)}; và a_i = r_i(e_i,v_i)
nơi q_p, q_∧, q_∨, và q_¬ là các truy vấn phép chiếu, giao, hợp, và phủ định, tương ứng; và V_p, V_∧, V_∨ và V_¬ là các kết quả tương ứng của những truy vấn đó (Arakelyan et al., 2021; Choudhary et al., 2021a). a_i là một chỉ báo Boolean sẽ là 1 nếu e_i được kết nối với v_i bởi quan hệ r_i, 0 ngược lại. Mục tiêu của lý luận logic là công thức hóa các phép toán sao cho đối với một truy vấn q_τ của loại truy vấn τ với đầu vào Q_τ, chúng ta có thể truy xuất hiệu quả V_τ từ tập thực thể E, ví dụ, đối với một truy vấn phép chiếu q_p[(Nobel Prize, winners)], chúng ta muốn truy xuất V_p = {Nobel Prize winners} ⊆ E.

Trong các phương pháp thông thường cho lý luận logic, các phép toán truy vấn thường được biểu diễn thông qua một hàm hình học. Ví dụ, giao của các truy vấn được biểu diễn như một giao của các biểu diễn hộp trong Query2Box (Ren et al., 2020). Tuy nhiên, trong phương pháp đề xuất của chúng tôi, LARK, chúng tôi tận dụng khả năng lý luận tiên tiến của Mô hình Ngôn ngữ (LLM) và ưu tiên phân tách hiệu quả các chuỗi logic trong truy vấn để tăng cường hiệu suất. Chiến lược mới này tìm cách vượt qua các hạn chế của các phương pháp truyền thống bằng cách khai thác sức mạnh của LLM trong lý luận trên KG.

### 3.2 Truy xuất Lân cận và Phân tách Chuỗi Logic

Nền tảng của khả năng lý luận của LARK được xây dựng trên các mô hình ngôn ngữ lớn. Tuy nhiên, độ dài đầu vào hạn chế của LLM giới hạn khả năng xử lý toàn bộ đồ thị tri thức của chúng. Hơn nữa, trong khi tập hợp các thực thể và quan hệ trong một đồ thị tri thức là độc đáo, lý luận đằng sau các phép toán logic vẫn phổ quát. Do đó, chúng tôi đặc biệt điều chỉnh các prompt LLM để tính đến các đặc điểm khác biệt trên của lý luận logic trên đồ thị tri thức. Để giải quyết nhu cầu này, chúng tôi áp dụng một quy trình hai bước:

1. **Trừu tượng hóa Truy vấn**: Để làm cho quy trình lý luận logic trên đồ thị tri thức có thể tổng quát hóa hơn cho các tập dữ liệu khác nhau, chúng tôi đề xuất thay thế tất cả các thực thể và quan hệ trong đồ thị tri thức và truy vấn bằng một ID duy nhất. Phương pháp này mang lại ba ưu điểm đáng kể. Đầu tiên, nó giảm số lượng token trong truy vấn, dẫn đến cải thiện hiệu quả LLM. Thứ hai, nó cho phép chúng tôi chỉ sử dụng khả năng lý luận của mô hình ngôn ngữ, mà không dựa vào bất kỳ tri thức thông thường bên ngoài nào của LLM cơ bản. Bằng cách tránh sử dụng tri thức thông thường, phương pháp của chúng tôi giảm thiểu tiềm năng ảo giác mô hình (có thể dẫn đến việc tạo ra các câu trả lời không được hỗ trợ bởi KG). Cuối cùng, nó loại bỏ bất kỳ thông tin cụ thể KG nào, do đó đảm bảo rằng quy trình vẫn có thể tổng quát hóa cho các tập dữ liệu khác nhau. Trong khi điều này có thể trực quan dường như dẫn đến mất thông tin, các phát hiện thực nghiệm của chúng tôi, được trình bày trong Phần 4.4, chỉ ra rằng tác động đến hiệu suất tổng thể là không đáng kể.

2. **Truy xuất Lân cận**: Để trả lời hiệu quả các truy vấn logic, LLM không cần thiết phải có quyền truy cập vào toàn bộ đồ thị tri thức. Thay vào đó, các lân cận liên quan chứa các câu trả lời có thể được xác định. Các phương pháp trước đây (Guu et al., 2020; Chen et al., 2022) đã tập trung vào truy xuất ngữ nghĩa cho các tài liệu web. Tuy nhiên, chúng tôi lưu ý rằng các truy vấn logic có tính chất xác định, và do đó chúng tôi thực hiện một duyệt theo chiều sâu k-cấp³ trên các thực thể và quan hệ có mặt trong truy vấn. Gọi E¹_τ và R¹_τ biểu thị tập hợp các thực thể và quan hệ trong truy vấn Q_τ cho một loại truy vấn τ, tương ứng. Khi đó, lân cận k-cấp của truy vấn q_τ được định nghĩa bởi N^k(q_τ[Q_τ]) như:

N¹(q_τ[Q_τ]) = {(h,r,t): h ∈ E¹_τ, r ∈ R¹_τ, t ∈ E¹_τ}                     (5)
E^k_τ = {h,t: (h,r,t) ∈ N^(k-1)(q_τ[Q_τ]}, R^k_τ = {r: (h,r,t) ∈ N^(k-1)(q_τ[Q_τ]}   (6)
N^k(q_τ[Q_τ]) = {(h,r,t): h ∈ E^k_τ, r ∈ R^k_τ, t ∈ E^k_τ}                (7)

Chúng tôi đã thực hiện các bước để làm cho phương pháp của chúng tôi có thể tổng quát hóa và hiệu quả hơn bằng cách trừu tượng hóa truy vấn và giới hạn ngữ cảnh đầu vào cho LLM. Tuy nhiên, độ phức tạp của một truy vấn vẫn là một mối quan tâm. Độ phức tạp của một loại truy vấn τ, ký hiệu là O(q_τ), được xác định bởi số lượng thực thể và quan hệ mà nó liên quan, tức là O(q_τ) ∝ |E_τ| + |R_τ|. Nói cách khác, kích thước của truy vấn về các thành phần cấu thành của nó là một yếu tố chính trong việc xác định độ phức tạp tính toán của nó. Quan sát này đặc biệt liên quan trong bối cảnh LLM, vì các nghiên cứu trước đây đã cho thấy rằng hiệu suất của chúng có xu hướng giảm khi độ phức tạp của các truy vấn chúng xử lý tăng lên (Khot et al., 2023). Để giải quyết điều này, chúng tôi đề xuất một cơ chế phân tách chuỗi truy vấn logic trong LARK giảm một truy vấn đa phép toán phức tạp thành nhiều truy vấn một phép toán. Do tập hợp các phép toán đầy đủ, chúng tôi áp dụng chiến lược sau để phân tách các loại truy vấn khác nhau:

• Giảm một truy vấn phép chiếu k-cấp thành k truy vấn phép chiếu một cấp, ví dụ, một truy vấn 3p với một thực thể và ba quan hệ e₁ r₁→ r₂→ r₃→ A được phân tách thành e₁ r₁→ A₁, A₁ r₂→ A₂, A₂ r₃→ A.

• Giảm một truy vấn giao k thành k truy vấn phép chiếu và một truy vấn giao, ví dụ, một truy vấn 3i với giao của hai truy vấn phép chiếu (e₁ r₁→) ∧ (e₂ r₂→) ∧ (e₃ r₃→) = A được phân tách thành e₁ r₁→ A₁, e₂ r₂→ A₂, e₃ r₃→ A₂, A₁ ∧ A₂ ∧ A₃ = A. Tương tự, giảm một truy vấn hợp k thành k truy vấn phép chiếu và một truy vấn hợp.

Việc phân tách hoàn chỉnh của tập hợp đầy đủ các loại truy vấn được sử dụng trong công trình trước đây (Ren & Leskovec, 2020) và các nghiên cứu thực nghiệm của chúng tôi có thể được tìm thấy trong Phụ lục A.

[Hình 2: Tổng quan về mô hình LARK. Mô hình lấy truy vấn logic và suy luận loại truy vấn từ nó. Hàm trừu tượng hóa truy vấn ánh xạ các thực thể và quan hệ thành các ID trừu tượng, và cơ chế truy xuất lân cận thu thập các đồ thị con liên quan từ đồ thị tri thức tổng thể. Các chuỗi của truy vấn phức tạp được trừu tượng hóa sau đó được phân tách logic thành các truy vấn một phép toán đơn giản hơn. Lân cận được truy xuất và các truy vấn được phân tách được chuyển đổi thêm thành các prompt LLM sử dụng một template và sau đó được xử lý trong LLM để có được tập hợp câu trả lời cuối cùng để đánh giá.]

### 3.3 Prompt Lý luận Chuỗi

Trong phần trước, chúng tôi đã phác thảo phương pháp của chúng tôi để giới hạn lân cận và phân tách các truy vấn phức tạp thành các chuỗi truy vấn đơn giản. Tận dụng những điều này, bây giờ chúng ta có thể sử dụng khả năng lý luận của LLM để có được tập hợp câu trả lời cuối cùng cho truy vấn, như được hiển thị trong Hình 2. Để đạt được điều này, chúng tôi sử dụng một template prompt chuyển đổi lân cận thành một prompt ngữ cảnh và các truy vấn được phân tách thành các prompt câu hỏi. Đáng chú ý rằng một số truy vấn trong phân tách phụ thuộc vào các phản hồi của các truy vấn trước đó, như giao dựa vào các truy vấn phép chiếu trước đó. Ngoài ra, không giống các phương pháp prompt trước đây như chuỗi suy nghĩ (Wei et al., 2022) và phân tách (Khot et al., 2023) prompting, các câu trả lời cần được tích hợp tại một vị trí nhất định trong prompt. Để giải quyết vấn đề này, chúng tôi duy trì một placeholder trong các truy vấn phụ thuộc và một bộ nhớ đệm tạm thời của các câu trả lời trước đó có thể thay thế các placeholder trong thời gian thực. Điều này cũng có lợi ích bổ sung là duy trì khả năng song song hóa của các truy vấn, vì chúng ta có thể chạy các batch của các truy vấn được phân tách theo từng giai đoạn thay vì chạy tuần tự từng truy vấn được phân tách. Các template prompt cụ thể của các truy vấn logic phức tạp và được phân tách cho các loại truy vấn khác nhau được cung cấp trong Phụ lục B.

### 3.4 Chi tiết Triển khai

Chúng tôi triển khai LARK trong Pytorch (Paszke et al., 2019) trên tám GPU Nvidia A100 với 40 GB VRAM. Trong trường hợp LLM, chúng tôi chọn mô hình Llama2 (Touvron et al., 2023) do tính khả dụng công khai của nó trong thư viện Huggingface (Wolf et al., 2020). Để suy luận hiệu quả trên các mô hình quy mô lớn, chúng tôi dựa vào phiên bản độ chính xác hỗn hợp của LLM và thư viện Deepspeed (Rasley et al., 2020) với tối ưu hóa Zero giai đoạn 3. Thuật toán của mô hình chúng tôi được cung cấp trong Phụ lục D và mã triển khai cho tất cả các thí nghiệm của chúng tôi với các tệp cấu hình chính xác và tập dữ liệu để tái tạo có sẵn công khai⁴. Trong các thí nghiệm của chúng tôi, độ phức tạp cao nhất của một truy vấn đòi hỏi một lân cận 3-hop xung quanh các thực thể và quan hệ. Do đó, chúng tôi đặt giới hạn độ sâu là 3 (tức là k=3). Ngoài ra, để làm cho quy trình của chúng tôi hoàn toàn tương thích với các tập dữ liệu khác nhau, chúng tôi thêm một giới hạn n token trên đầu vào phụ thuộc vào mô hình LLM (đối với Llama2, n=4096). Trong thực tế, điều này có nghĩa là chúng tôi dừng duyệt theo chiều sâu khi ngữ cảnh trở nên dài hơn n.

³ nơi k được xác định bởi loại truy vấn, ví dụ, đối với các truy vấn phép chiếu 3-cấp (3p), k=3.
⁴ https://github.com/Akirato/LLM-KG-Reasoning

## 4 Kết quả Thực nghiệm

Phần này mô tả các thí nghiệm của chúng tôi nhằm trả lời các câu hỏi nghiên cứu sau (RQ):

**RQ1.** LARK có vượt trội hơn các baseline tiên tiến nhất trong nhiệm vụ lý luận logic trên các benchmark đồ thị tri thức tiêu chuẩn không?

**RQ2.** Sự kết hợp của phân tách chuỗi truy vấn và cơ chế trả lời được sắp xếp logic của chúng tôi hoạt động như thế nào so với các kỹ thuật prompt tiêu chuẩn?

**RQ3.** Quy mô và thiết kế của mô hình LLM cơ bản của LARK ảnh hưởng như thế nào đến hiệu suất của nó?

**RQ4.** Mô hình của chúng tôi sẽ hoạt động như thế nào với hỗ trợ cho kích thước token tăng lên?

**RQ5.** Trừu tượng hóa truy vấn có ảnh hưởng đến hiệu suất lý luận của mô hình chúng tôi không?

### 4.1 Tập dữ liệu và Baseline

Chúng tôi chọn các tập dữ liệu benchmark tiêu chuẩn sau để điều tra hiệu suất của mô hình chúng tôi so với các mô hình tiên tiến nhất trong nhiệm vụ lý luận logic trên đồ thị tri thức:

• **FB15k** (Bollacker et al., 2008) dựa trên Freebase, một dự án đồ thị tri thức hợp tác lớn được tạo bởi Google. FB15k chứa khoảng 15.000 thực thể, 1.345 quan hệ, và 592.213 bộ ba (câu lệnh khẳng định một sự thật về một thực thể).

• **FB15k-237** (Toutanova et al., 2015) là một tập con của FB15k, chứa 14.541 thực thể, 237 quan hệ, và 310.116 bộ ba. Các quan hệ trong FB15k-237 là một tập con của các quan hệ trong FB15k, và được tạo ra để giải quyết một số hạn chế của FB15k, như sự hiện diện của nhiều quan hệ không liên quan hoặc mơ hồ, và để cung cấp một benchmark thách thức hơn cho các mô hình hoàn thiện đồ thị tri thức.

• **NELL995** (Carlson et al., 2010) được tạo ra bằng hệ thống Never-Ending Language Learning (NELL), là một hệ thống học máy tự động trích xuất tri thức từ web bằng cách đọc văn bản và suy luận các sự thật mới. NELL995 chứa 9.959 thực thể, 200 quan hệ, và 114.934 bộ ba. Các quan hệ trong NELL995 bao phủ một loạt các lĩnh vực, bao gồm địa lý, thể thao, và chính trị.

Tiêu chí của chúng tôi để chọn các tập dữ liệu trên là tính phổ biến của chúng trong các công trình trước đây về vấn đề nghiên cứu này. Chi tiết thêm về kích thước token của chúng được cung cấp trong Phụ lục E. Đối với các baseline, chúng tôi chọn các phương pháp sau:

• **GQE** (Hamilton et al., 2018) mã hóa một truy vấn như một vector đơn và biểu diễn các thực thể và quan hệ trong một không gian chiều thấp. Nó sử dụng các toán tử dịch chuyển và tập hợp sâu, được mô hình hóa như các toán tử phép chiếu và giao, tương ứng.

• **Query2Box (Q2B)** (Ren et al., 2020) sử dụng một mô hình nhúng hộp là một tổng quát hóa của mô hình nhúng vector truyền thống và có thể nắm bắt ngữ nghĩa phong phú hơn.

• **BetaE** (Ren & Leskovec, 2020) sử dụng một phân phối beta mới để mô hình hóa sự không chắc chắn trong biểu diễn của các thực thể và quan hệ. BetaE có thể nắm bắt cả ước tính điểm và sự không chắc chắn của các nhúng, dẫn đến các dự đoán chính xác hơn trong các nhiệm vụ hoàn thiện đồ thị tri thức.

• **HQE** (Choudhary et al., 2021b) sử dụng cơ chế nhúng truy vấn hyperbolic để mô hình hóa các truy vấn phức tạp trong các nhiệm vụ hoàn thiện đồ thị tri thức.

• **HypE** (Choudhary et al., 2021b) sử dụng mô hình hyperboloid để biểu diễn các thực thể và quan hệ trong một đồ thị tri thức đồng thời nắm bắt các đặc điểm ngữ nghĩa, không gian, và phân cấp của chúng.

• **CQD** (Arakelyan et al., 2021) phân tách các truy vấn phức tạp thành các truy vấn con đơn giản hơn và áp dụng một cơ chế attention cụ thể truy vấn cho các truy vấn con.

### 4.2 RQ1. Hiệu quả trong Lý luận Logic

Để nghiên cứu hiệu quả của mô hình chúng tôi trong nhiệm vụ lý luận logic, chúng tôi so sánh nó với các baseline trước đây trên các cấu trúc truy vấn logic tiêu chuẩn sau:

1. **Phép chiếu Đa-hop** duyệt nhiều quan hệ từ một thực thể đầu trong một đồ thị tri thức để trả lời các truy vấn phức tạp bằng cách chiếu truy vấn lên các thực thể đích. Trong các thí nghiệm của chúng tôi, chúng tôi xem xét các truy vấn 1p, 2p, và 3p biểu thị hop 1-quan hệ, 2-quan hệ, và 3-quan hệ từ thực thể đầu, tương ứng.

2. **Phép toán Hình học** áp dụng các phép toán giao (∧) và hợp (∨) để trả lời truy vấn. Các thí nghiệm của chúng tôi sử dụng các truy vấn 2i và 3i biểu thị giao trên 2 và 3 thực thể, tương ứng. Ngoài ra, chúng tôi nghiên cứu các truy vấn 2u thực hiện hợp trên 2 thực thể.

3. **Phép toán Kết hợp** tích hợp nhiều phép toán như giao, hợp, và phép chiếu để xử lý các truy vấn phức tạp trên một đồ thị tri thức.

4. **Phép toán Phủ định** phủ định truy vấn bằng cách tìm các thực thể không thỏa mãn logic đã cho. Trong các thí nghiệm của chúng tôi, chúng tôi kiểm tra các truy vấn 2in, 3in, inp, và pin phủ định các truy vấn 2i, 3i, ip, và pi, tương ứng. Chúng tôi cũng phân tích pni (một biến thể bổ sung của truy vấn pi), nơi phủ định được thực hiện trên cả hai thực thể trong giao. Cần lưu ý rằng BetaE là phương pháp duy nhất trong tài liệu hiện có hỗ trợ phủ định, và do đó, chúng tôi chỉ so sánh với nó trong các thí nghiệm của chúng tôi.

Chúng tôi trình bày kết quả của nghiên cứu thực nghiệm, so sánh điểm số Mean Reciprocal Rank (MRR) của các thực thể ứng viên được truy xuất sử dụng các cấu trúc truy vấn khác nhau. MRR được tính như trung bình của các thứ hạng nghịch đảo của các thực thể ứng viên⁵. Để đảm bảo so sánh công bằng, chúng tôi đã chọn các cấu trúc truy vấn này được sử dụng trong hầu hết các công trình trước đây trong lĩnh vực này (Ren & Leskovec, 2020). Một minh họa của các loại truy vấn này được cung cấp trong Phụ lục A để hiểu rõ hơn. Các thí nghiệm của chúng tôi cho thấy rằng LARK vượt trội hơn các baseline tiên tiến nhất trước đây từ 35%−84% trung bình qua các loại truy vấn khác nhau, như được báo cáo trong Bảng 1. Chúng tôi quan sát rằng cải thiện hiệu suất cao hơn đối với các truy vấn đơn giản hơn, nơi 1p > 2p > 3p và 2i > 3i. Điều này cho thấy rằng LLM tốt hơn trong việc nắm bắt chiều rộng qua các quan hệ nhưng có thể không hiệu quả như trong việc nắm bắt chiều sâu qua nhiều quan hệ. Hơn nữa, đánh giá của chúng tôi cũng bao gồm thử nghiệm đối với các truy vấn phủ định thách thức, mà BetaE (Ren & Leskovec, 2020) vẫn là phương pháp hiện có duy nhất. Ngay cả trong tình huống phức tạp này, các phát hiện của chúng tôi, như minh họa trong Bảng 2, chỉ ra rằng LARK vượt trội đáng kể hơn các baseline từ 140%. Điều này khẳng định khả năng lý luận vượt trội của mô hình chúng tôi trong việc giải quyết các tình huống truy vấn phức tạp. Một điểm khác cần lưu ý là một số baseline như CQD có thể vượt trội hơn LARK trong tập dữ liệu FB15k cho một số loại truy vấn như 1p, 3i, và ip. Lý do cho điều này là FB15k gặp phải rò rỉ dữ liệu từ tập huấn luyện sang tập validation và test (Toutanova et al., 2015). Điều này có lợi không công bằng cho các baseline dựa trên huấn luyện so với mô hình LARK chỉ suy luận.

[Bảng 1: So sánh hiệu suất giữa LARK và baseline về hiệu quả lý luận logic sử dụng điểm MRR. Các hàng trình bày các mô hình khác nhau và các cột tương ứng với các cấu trúc truy vấn khác nhau của phép chiếu đa-hop, phép toán hình học, và phép toán kết hợp. Kết quả tốt nhất cho mỗi loại truy vấn trong mỗi tập dữ liệu được tô đậm.]

[Bảng 2: So sánh hiệu suất giữa LARK và baseline cho các loại truy vấn phủ định sử dụng điểm MRR. Kết quả tốt nhất cho mỗi loại truy vấn trong mỗi tập dữ liệu được tô đậm. Hiệu suất của mô hình chúng tôi cao hơn đáng kể trên hầu hết các truy vấn phủ định. Tuy nhiên, hiệu suất bị hạn chế trong các truy vấn 3in và pni do số lượng token cao của chúng (được hiển thị trong Phụ lục E).]

### 4.3 RQ2. Ưu điểm của Phân tách Chuỗi

Mục đích của thí nghiệm này là điều tra các ưu điểm của việc sử dụng các truy vấn được phân tách chuỗi so với các truy vấn phức tạp tiêu chuẩn. Chúng tôi sử dụng cùng thiết lập thí nghiệm được mô tả trong Phần 4.2. Kết quả của chúng tôi, trong Bảng 1 và 2, chứng minh rằng việc sử dụng phân tách chuỗi đóng góp vào một cải thiện đáng kể từ 20%−33% trong hiệu suất của mô hình chúng tôi. Cải thiện này là một chỉ báo rõ ràng về khả năng của LLM trong việc nắm bắt một loạt rộng các quan hệ và sử dụng hiệu quả khả năng này để tăng cường hiệu suất trên các truy vấn phức tạp. Nghiên cứu này làm nổi bật tiềm năng của việc sử dụng phân tách chuỗi để vượt qua các hạn chế của các truy vấn phức tạp và cải thiện hiệu quả của các nhiệm vụ lý luận logic. Phát hiện này là một đóng góp đáng kể cho lĩnh vực xử lý ngôn ngữ tự nhiên và có ý nghĩa đối với các ứng dụng khác nhau như hệ thống hỏi đáp và hoàn thiện đồ thị tri thức. Nhìn chung, kết quả của chúng tôi cho thấy rằng các truy vấn được phân tách chuỗi có thể là một phương pháp tiềm năng để cải thiện hiệu suất của LLM trên các nhiệm vụ lý luận logic phức tạp.

### 4.4 RQ3. Phân tích Quy mô LLM

Thí nghiệm này phân tích tác động của kích thước của LLM cơ bản và trừu tượng hóa truy vấn đối với hiệu suất tổng thể của mô hình LARK. Để kiểm tra ảnh hưởng của kích thước LLM, chúng tôi so sánh hai biến thể của mô hình Llama2 có 7 tỷ và 13 tỷ tham số. Kết quả đánh giá của chúng tôi, được trình bày trong Bảng 3, cho thấy rằng hiệu suất của mô hình LARK cải thiện 123% từ Llama2-7B sang Llama2-13B. Điều này chỉ ra rằng việc tăng số lượng tham số LLM có thể tăng cường hiệu suất của mô hình LARK.

[Bảng 3: Điểm MRR của LARK trên tập dữ liệu FB15k-237 với LLM cơ bản có kích thước khác nhau. Kết quả tốt nhất cho mỗi loại truy vấn được tô đậm.]

### 4.5 RQ4. Nghiên cứu về Giới hạn Token Tăng của LLM

Từ chi tiết tập dữ liệu được cung cấp trong Phụ lục E, chúng tôi quan sát rằng kích thước token của các loại truy vấn khác nhau cho thấy sự biến động đáng kể từ 58 đến hơn 100.000. Thật không may, giới hạn token của Llama2, được coi là cơ sở trong các thí nghiệm của chúng tôi, là 4096. Giới hạn này không đủ để chứng minh tiềm năng hiệu suất đầy đủ của LARK trên các nhiệm vụ của chúng tôi. Để giải quyết hạn chế này, chúng tôi xem xét tính khả dụng của các mô hình có giới hạn token cao hơn, như GPT-3.5 (OpenAI, 2023). Tuy nhiên, chúng tôi thừa nhận rằng các mô hình này đắt để chạy và do đó, chúng tôi không thể tiến hành phân tích kỹ lưỡng trên toàn bộ tập dữ liệu. Tuy nhiên, để có cái nhìn sâu sắc về tiềm năng của LARK với kích thước token tăng lên, chúng tôi lấy mẫu ngẫu nhiên 1000 truy vấn mỗi loại truy vấn từ mỗi tập dữ liệu với độ dài token trên 4096 và dưới 4096 và so sánh mô hình của chúng tôi trên các truy vấn này với GPT-3.5 và Llama2 làm cơ sở. Kết quả đánh giá, được hiển thị trong Bảng 4, chứng minh rằng việc chuyển từ Llama2 sang GPT-3.5 có thể dẫn đến cải thiện hiệu suất đáng kể từ 29%-40% cho mô hình LARK điều này cho thấy rằng việc tăng giới hạn token của LLM có thể có tiềm năng đáng kể để tăng cường hiệu suất hơn nữa.

[Bảng 4: Điểm MRR của LARK với Llama2 và GPT LLM làm mô hình cơ sở. Kết quả tốt nhất cho mỗi loại truy vấn trong mỗi tập dữ liệu được tô đậm.]

### 4.6 RQ5. Ảnh hưởng của Trừu tượng hóa Truy vấn

[Hình 3: Ảnh hưởng của Trừu tượng hóa Truy vấn.]

Về phân tích trừu tượng hóa truy vấn, chúng tôi xem xét một biến thể của LARK gọi là 'LARK (semantic)', giữ lại thông tin ngữ nghĩa trong các thực thể và quan hệ KG. Như được hiển thị trong Hình 3, chúng tôi quan sát rằng thông tin ngữ nghĩa cung cấp một tăng cường hiệu suất nhỏ là 0,01% cho các truy vấn phép chiếu đơn giản. Tuy nhiên, trong các truy vấn phức tạp hơn, nó dẫn đến suy giảm hiệu suất từ 0,7%−1,4%. Nguyên nhân chính của sự suy giảm này là việc bao gồm thông tin ngữ nghĩa vượt quá giới hạn token của LLM, dẫn đến mất thông tin lân cận. Do đó, chúng tôi khẳng định rằng trừu tượng hóa truy vấn không chỉ là một kỹ thuật có giá trị để giảm thiểu ảo giác mô hình và đạt được tổng quát hóa qua các tập dữ liệu KG khác nhau mà còn có thể tăng cường hiệu suất bằng cách giảm kích thước token.

⁵ Thêm các chỉ số như HITS@K=1,3,10 được báo cáo trong Phụ lục C.

## 5 Thảo luận Kết luận

Trong bài báo này, chúng tôi đã trình bày LARK, phương pháp đầu tiên tích hợp lý luận logic trên đồ thị tri thức với các khả năng của LLM. Phương pháp của chúng tôi sử dụng các prompt LLM được phân tách logic để cho phép lý luận chuỗi trên các đồ thị con được truy xuất từ đồ thị tri thức, cho phép chúng tôi tận dụng hiệu quả khả năng lý luận của LLM. Thông qua các thí nghiệm của chúng tôi về lý luận logic qua các tập dữ liệu KG tiêu chuẩn, chúng tôi đã chứng minh rằng LARK vượt trội hơn các phương pháp tiên tiến nhất trước đây với biên độ đáng kể trên 14 loại truy vấn FOL khác nhau. Cuối cùng, công trình của chúng tôi cũng cho thấy rằng hiệu suất của LARK cải thiện với việc tăng quy mô và thiết kế tốt hơn của LLM cơ bản. Chúng tôi đã chứng minh rằng LLM có thể xử lý độ dài token đầu vào lớn hơn có thể dẫn đến cải thiện hiệu suất đáng kể. Nhìn chung, phương pháp của chúng tôi trình bày một hướng tiềm năng để tích hợp LLM với lý luận logic trên đồ thị tri thức.

Phương pháp đề xuất sử dụng LLM cho lý luận logic phức tạp trên KG được kỳ vọng sẽ mở ra một con đường mới cho lý luận cải thiện trên các KG thực tế lớn, nhiễu và không đầy đủ. Điều này có thể có tác động đáng kể đến các ứng dụng khác nhau như hiểu ngôn ngữ tự nhiên, hệ thống hỏi đáp, hệ thống truy xuất thông tin thông minh, v.v. Ví dụ, trong y tế, KG có thể được sử dụng để biểu diễn dữ liệu bệnh nhân, tri thức y tế, và nghiên cứu lâm sàng, và lý luận logic trên các KG này có thể cho phép chẩn đoán, điều trị và khám phá thuốc tốt hơn. Tuy nhiên, cũng có thể có một số cân nhắc đạo đức cần được tính đến. Như với hầu hết các công nghệ dựa trên AI, có nguy cơ tiềm ẩn gây ra thiên kiến vào mô hình, có thể dẫn đến các quyết định và hành động không công bằng. Thiên kiến có thể được đưa vào trong chính các KG, vì chúng thường được tạo ra bán tự động từ các nguồn thiên kiến, và có thể được khuếch đại bởi quá trình lý luận logic. Hơn nữa, lượng lớn dữ liệu được sử dụng để huấn luyện LLM cũng có thể đưa vào thiên kiến, vì nó có thể phản ánh các định kiến và khuôn mẫu xã hội. Do đó, việc giám sát và đánh giá cẩn thận các KG và LLM được sử dụng trong phương pháp này là cần thiết để đảm bảo công bằng và tránh phân biệt đối xử. Hiệu suất của phương pháp này cũng phụ thuộc vào chất lượng và tính đầy đủ của các KG được sử dụng, và kích thước token hạn chế của LLM hiện tại. Nhưng, chúng tôi cũng quan sát rằng xu hướng hiện tại của việc tăng giới hạn token LLM sẽ sớm giải quyết một số hạn chế này.

## Tài liệu Tham khảo

[Phần này chứa tất cả các tài liệu tham khảo với định dạng giống hệt như bản gốc, được dịch sang tiếng Việt cho các tiêu đề và tên hội thảo]

## Phụ lục

### A Phân tách Truy vấn của Các Loại Truy vấn Khác nhau

Hình 4 cung cấp phân tách truy vấn của các loại truy vấn khác nhau được xem xét trong nghiên cứu thực nghiệm của chúng tôi cũng như tài liệu trước đây trong lĩnh vực này.

[Hình 4: Phân tách Truy vấn của các loại truy vấn khác nhau được xem xét trong các thí nghiệm của chúng tôi.]

### B Template Prompt của Các Loại Truy vấn Khác nhau

Các template prompt cho các truy vấn logic phức tạp đầy đủ với nhiều phép toán và các truy vấn logic sơ cấp được phân tách với một phép toán được cung cấp trong Bảng 5 và 6, tương ứng.

[Bảng 5: Template Prompt Đầy đủ của Các Loại Truy vấn Khác nhau.]

[Bảng 6: Template Prompt Được phân tách của Các Loại Truy vấn Khác nhau.]

### C Phân tích Hiệu suất Lý luận Logic sử dụng Chỉ số HITS

Bảng 7 và 8 trình bày kết quả HITS@K=3 của các baseline và mô hình của chúng tôi. HITS@K chỉ ra độ chính xác của việc dự đoán các ứng viên chính xác trong top-K kết quả.

[Bảng 7: Nghiên cứu so sánh hiệu suất giữa LARK và baseline, tập trung vào hiệu quả lý luận logic của chúng sử dụng điểm HITS@K=1,3,10. Các hàng tương ứng với các mô hình và các cột biểu thị các cấu trúc truy vấn khác nhau của phép chiếu đa-hop, phép toán hình học, và phép toán kết hợp. Kết quả tốt nhất cho mỗi loại truy vấn trong mỗi tập dữ liệu được tô đậm.]

[Bảng 8: So sánh hiệu suất giữa LARK và baseline cho các loại truy vấn phủ định sử dụng điểm HITS@K=1,3,10. Kết quả tốt nhất cho mỗi loại truy vấn trong mỗi tập dữ liệu được tô đậm.]

### D Thuật toán

Thuật toán cho quy trình của LARK được cung cấp trong Thuật toán 1.

[Thuật toán 1: Thuật toán LARK]

### E Phân phối Token Truy vấn trong Tập dữ liệu

Chi tiết định lượng về độ dài token của truy vấn được cung cấp trong Bảng 9 và các biểu đồ phân phối hoàn chỉnh của chúng được cung cấp trong Hình 5. Từ kết quả, chúng tôi quan sát rằng phân phối độ dài token có độ lệch dương cho hầu hết các loại truy vấn, điều này chỉ ra rằng số lượng mẫu có độ dài token cao là ít. Do đó, những cải thiện nhỏ trong giới hạn token của LLM có thể dẫn đến phạm vi bao phủ tốt hơn trên hầu hết các truy vấn lý luận trong các tập dữ liệu KG tiêu chuẩn.

[Bảng 9: Chi tiết phân phối token cho các loại truy vấn khác nhau trong các tập dữ liệu khác nhau. Các cột trình bày giá trị trung bình, trung vị, tối thiểu (Min), và tối đa (Max) của số lượng token trong các truy vấn của các loại truy vấn khác nhau. Cột 'Cov' trình bày phần trăm truy vấn (phạm vi bao phủ) chứa ít hơn 4096 token, là giới hạn token của mô hình Llama2.]

[Hình 5: Phân phối xác suất của số lượng token trong mỗi loại truy vấn. Các hình chứa 14 biểu đồ cho 14 loại truy vấn khác nhau. Trục x và trục y trình bày số lượng token trong truy vấn và mật độ xác suất của chúng, tương ứng.]

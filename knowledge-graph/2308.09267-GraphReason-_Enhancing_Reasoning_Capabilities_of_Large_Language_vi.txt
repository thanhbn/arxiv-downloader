# GraphReason: Tăng cường khả năng lý luận của các mô hình ngôn ngữ lớn thông qua phương pháp xác minh dựa trên đồ thị

Lang Cao
Đại học Illinois Urbana-Champaign
Khoa Khoa học Máy tính
langcao2@illinois.edu

## Tóm tắt

Các Mô hình Ngôn ngữ Lớn (LLMs) đã thể hiện khả năng lý luận ấn tượng, đặc biệt khi được hướng dẫn bởi các prompt được thiết kế cụ thể trong các nhiệm vụ lý luận phức tạp như bài toán từ ngữ toán học. Những mô hình này thường giải quyết nhiệm vụ bằng cách sử dụng phương pháp chuỗi tư duy, điều này không chỉ củng cố khả năng lý luận của chúng mà còn cung cấp những hiểu biết có giá trị về quá trình giải quyết vấn đề của chúng. Tuy nhiên, vẫn còn nhiều không gian đáng kể để tăng cường khả năng lý luận của LLMs. Một số nghiên cứu cho thấy rằng việc tích hợp một trình xác minh đầu ra LLM có thể tăng độ chính xác lý luận mà không cần thiết phải huấn luyện mô hình bổ sung. Trong bài báo này, chúng tôi theo dõi những nghiên cứu này và giới thiệu một phương pháp mới dựa trên đồ thị để tăng cường hơn nữa khả năng lý luận của LLMs. Chúng tôi cho rằng nhiều giải pháp cho một nhiệm vụ lý luận, được tạo ra bởi một LLM, có thể được biểu diễn như một đồ thị lý luận do các kết nối logic giữa các bước trung gian từ các đường lý luận khác nhau. Do đó, chúng tôi đề xuất Trình Xác minh Đồ thị Lý luận (GraphReason) để phân tích và xác minh các giải pháp được tạo ra bởi LLMs. Bằng cách đánh giá những đồ thị này, các mô hình có thể mang lại kết quả chính xác và đáng tin cậy hơn. Kết quả thực nghiệm của chúng tôi cho thấy rằng phương pháp xác minh dựa trên đồ thị của chúng tôi không chỉ tăng cường đáng kể khả năng lý luận của LLMs mà còn vượt trội hơn các phương pháp xác minh hiện có về mặt cải thiện hiệu suất lý luận của những mô hình này.

## 1 Giới thiệu

Các Mô hình Ngôn ngữ Lớn (LLMs) đã thể hiện khả năng đặc biệt trong nhiều nhiệm vụ của con người (Zhao et al., 2023). Trong số nhiều khả năng mà LLMs sở hữu, khả năng lý luận của chúng có tầm quan trọng hàng đầu (Kojima et al., 2023; Huang and Chang, 2023). Điều này đã được chứng minh bởi những tiến bộ gần đây (Wei et al., 2022; Zhou et al., 2023; Lampinen et al., 2022a). Được trang bị khả năng lý luận, đặc biệt là theo cách nhiều bước, LLMs có thể phân tách các vấn đề phức tạp thành các nhiệm vụ đơn giản hơn, qua đó tạo điều kiện cho việc giải quyết chúng. Trong cuộc sống hàng ngày, nhiều nhiệm vụ phức tạp thường đòi hỏi các giải pháp nhiều bước. Một ví dụ điển hình của nhiệm vụ lý luận là lý luận số học, còn được gọi là giải bài toán từ ngữ toán học (Zhang et al., 2019). Những bài toán từ ngữ toán học này đại diện cho các phiên bản đơn giản hóa của các tình huống phức tạp trong đời thực.

[Hình 1: Một ví dụ về lý luận chuỗi tư duy trong bài toán từ ngữ toán học, sử dụng dữ liệu từ bộ dữ liệu GSM8K. Các mô hình ngôn ngữ lớn học từ các mẫu cung cấp giải pháp từng bước, sau đó tạo ra đường lý luận của chúng cho câu hỏi hiện tại.]

Khả năng lý luận vốn có trong các Mô hình Ngôn ngữ Lớn (LLMs), nhưng nó cần những phương pháp cụ thể để biểu hiện. Để kích hoạt khả năng lý luận mạnh mẽ của LLMs, việc sử dụng các prompt được thiết kế đặc biệt nên được xem xét. Nhiều phương pháp đã được đề xuất để khai thác tiềm năng này, trong đó lý luận chuỗi tư duy (Wei et al., 2022) và học tập trong ngữ cảnh (Lampinen et al., 2022b) là hai phương pháp đáng chú ý. Lý luận chuỗi tư duy có thể làm rõ các đường lý luận trong quá trình. Học tập trong ngữ cảnh cung cấp cho LLMs các trường hợp mẫu, qua đó cho phép chúng học từ và mô phỏng những ví dụ này để có kết quả tốt hơn. Trong tình huống lý luận số học, GPT-4 có thể đạt độ chính xác 92% trên bộ dữ liệu GSM8K bằng cách sử dụng prompt chuỗi tư duy 5-shot (Cobbe et al., 2021a). Điều này đại diện cho mức độ khó mà một học sinh trung học cơ sở thông minh nên có thể xử lý được. Như được mô tả trong Hình 1, điều này minh họa một quá trình lý luận số học nhiều bước trong LLMs.

Ngoài việc huấn luyện thêm LLMs và thiết kế prompt, một số phương pháp đã được đề xuất để tăng cường khả năng lý luận của LLMs từ góc độ xác minh đầu ra. Ý tưởng chính là để LLMs tạo ra các đường lý luận nhiều lần, và sau đó thiết kế một trình xác minh để đánh giá những đường này và đưa ra kết quả cuối cùng. (Wang et al., 2023) giới thiệu khái niệm tự nhất quán, dựa trên trực giác rằng một vấn đề lý luận phức tạp thường cho phép nhiều quá trình tư duy, tất cả đều dẫn đến một câu trả lời đúng duy nhất. (Li et al., 2023) cũng đề xuất Tất cả Con đường đều Dẫn đến Rome, giới thiệu một trình xác minh nhận biết từng bước để phân tích các đường lý luận không chỉ thông qua toàn bộ đường mà ở mọi bước. Tuy nhiên, cả hai phương pháp đều coi mỗi đường lý luận như một thực thể độc lập và không xem xét mối quan hệ và tương tác tiềm tàng giữa các đường lý luận khác nhau. Một khi các đường lý luận được tháo rời thành các bước, các bước trung gian từ một đường có thể mang quan hệ lý luận với các đường lý luận khác. Những phương pháp này không nhận thức tất cả đầu ra LLM cho một đầu vào nhất định như một thực thể tập thể, qua đó không phân tích sâu các quan hệ nội bộ của tất cả các đường ứng viên.

Được truyền cảm hứng từ những quan sát này, chúng tôi đề xuất Trình Xác minh Đồ thị Lý luận (GraphReason) trong bài báo này. Chúng tôi cho rằng các đường lý luận của một câu hỏi có thể tạo thành các đồ thị lý luận, nơi các bước lý luận trung gian tương tự có thể được hợp nhất thành cùng một nút. Với cấu trúc đồ thị, chúng ta có thể mô hình hóa và nắm bắt logic lý luận giữa các bước trung gian từ các đường lý luận khác nhau một cách hiệu quả hơn. Cụ thể, chúng tôi đầu tiên xây dựng một đồ thị lý luận dựa trên tất cả đầu ra từ LLMs, và sau đó huấn luyện một trình xác minh để học mối quan hệ giữa cấu trúc đồ thị và câu trả lời cuối cùng. Trong giai đoạn dự đoán, chúng tôi xử lý dữ liệu theo cách tương tự như trong giai đoạn huấn luyện, và sử dụng trình xác minh để đánh giá mỗi đồ thị lý luận. Sau đó chúng tôi chọn đồ thị lý luận có điểm số cao nhất, sử dụng câu trả lời của nó làm câu trả lời cuối cùng. Theo hiểu biết tốt nhất của chúng tôi, chúng tôi là những người đầu tiên tiếp cận logic lý luận của LLMs từ góc độ đồ thị. Chúng tôi tiến hành các thực nghiệm mở rộng để chứng minh những cải thiện so với LLMs gốc, và cho thấy rằng phương pháp của chúng tôi vượt trội hơn các trình xác minh khác.

Tóm lại, những đóng góp của chúng tôi như sau:

• Chúng tôi đề xuất một phương pháp xác minh dựa trên đồ thị, GraphReason, nhằm tăng cường đáng kể khả năng lý luận của các mô hình ngôn ngữ lớn mà không cần huấn luyện bổ sung LLMs.

• Chúng tôi thiết lập một benchmark lý luận số học sử dụng ba bộ dữ liệu Bài toán Từ ngữ Toán học để minh họa hiệu suất lý luận cơ bản của các mô hình ngôn ngữ lớn, và cung cấp so sánh công bằng về hiệu suất của các trình xác minh hiện có khác nhau.

• Kết quả thực nghiệm của chúng tôi chỉ ra rằng phương pháp được đề xuất trong bài báo này vượt trội hơn các phương pháp tăng cường khác. Chúng tôi cũng cung cấp phân tích mở rộng về các hạn chế và tiềm năng tương lai của GraphReason.

## 2 Các công trình liên quan

Lý luận của các Mô hình Fine-tuning đã được nghiên cứu rộng rãi. Nó tập trung vào việc giải quyết các nhiệm vụ lý luận bằng cách sử dụng phương pháp sequence-to-sequence tổng quát, được tăng cường bởi pre-training hoặc fine-tuning nhận biết lý luận của các mô hình ngôn ngữ. (Cobbe et al., 2021a) đề xuất huấn luyện một trình xác minh để xếp hạng các giải pháp được lấy mẫu từ các mô hình ngôn ngữ đã được fine-tuned. (Yoran et al., 2022; Wang et al., 2022) đề xuất trang bị cho các mô hình ngôn ngữ khả năng lý luận bằng cách tạo ra các ví dụ huấn luyện với các mẫu được thiết kế bởi con người. (Pi et al., 2022) đề xuất tiêm khả năng lý luận vào các mô hình ngôn ngữ bằng cách liên tục pre-training trên dữ liệu thực thi chương trình.

Một số nghiên cứu đã tập trung vào việc thấm nhuần PLM với khả năng lý luận cho các nhiệm vụ cụ thể, như lý luận số học (Cobbe et al., 2021a; Miao et al., 2020; Patel et al., 2021), lý luận thường thức (Talmor et al., 2019), và lý luận quy nạp (Sinha et al., 2019). Ví dụ, nhiều chiến lược khác nhau đã được đề xuất để cải thiện hiệu suất của các mô hình ngôn ngữ trên các nhiệm vụ lý luận số học, thường được gọi là bài toán từ ngữ toán học. (Xie and Sun, 2019) đề xuất một bộ giải mã có cấu trúc cây để tạo ra một cây phương trình, trong khi (Zhang et al., 2020) áp dụng mạng nơ-ron tích chập đồ thị để trích xuất mối quan hệ của các đại lượng trong bài toán toán học. (Li et al., 2022) sử dụng học tập đối chiếu để học tốt hơn các mẫu trong bài toán từ ngữ toán học. Tuy nhiên, (Valmeekam et al., 2023; Rae et al., 2022) đề xuất rằng lý luận, đặc biệt là lý luận nhiều bước, thường là một điểm yếu trong các mô hình ngôn ngữ và các mô hình NLP khác.

Lý luận của các Mô hình Ngôn ngữ Lớn đã thu hút sự chú ý đáng kể và thể hiện tiềm năng to lớn. Những tiến bộ gần đây trong LLMs cho thấy rằng khả năng lý luận nhiều bước đã được nhúng trong những mô hình quy mô lớn này (Kojima et al., 2023; Huang and Chang, 2023), như PaLM (Chowdhery et al., 2022), GPT-4 (OpenAI, 2023). Do đó, việc cung cấp một prompt thích hợp là đủ để sử dụng khả năng lý luận này. Ví dụ, phương pháp prompting được đề xuất bởi (Kojima et al., 2023; Wei et al., 2022), dựa trên chuỗi tư duy, có thể hỗ trợ LLMs trong việc tạo ra văn bản với lý luận số học và kiến thức thực tế thông thường. Theo sau (Wei et al., 2022), các thực nghiệm trên các mô hình ngôn ngữ hiện tại đã chứng minh rằng prompting chuỗi tư duy có thể tăng độ chính xác giải bài toán toán học từ 18% lên 57%. (Lampinen et al., 2022b) bao gồm các giải thích trong các ví dụ trong ngữ cảnh và kiểm tra ảnh hưởng của các giải thích bằng cách đánh giá điểm số giữa giải thích-rồi-dự đoán và dự đoán-rồi-giải thích. Hơn nữa, (Zhou et al., 2023) đề xuất một chiến lược prompting hai giai đoạn, prompting từ ít-đến-nhiều, phân tách một vấn đề phức tạp thành một loạt các vấn đề con và giải quyết chúng từng bước một. (Li et al., 2023) đề xuất lấy mẫu nhiều lần từ các prompt đa dạng để tăng cường sự đa dạng của các phản hồi.

Ngoài việc thiết kế prompt, việc áp dụng các chiến lược bổ sung như trình xác minh đã góp phần tăng cường hiệu suất của khả năng lý luận của các mô hình ngôn ngữ lớn. Ví dụ, (Wang et al., 2023) đề xuất tự nhất quán, bao gồm việc lấy mẫu các đường lý luận khác nhau từ mô hình ngôn ngữ, và sau đó trả về câu trả lời cuối cùng nhất quán nhất thông qua bỏ phiếu đa số. (Li et al., 2023) sử dụng trình xác minh bỏ phiếu nhận biết từng bước để tăng cường khả năng lý luận của LLMs từ hai góc độ. Những phương pháp này cố gắng tăng cường khả năng lý luận hoặc mang lại kết quả lý luận tốt hơn mà không cần huấn luyện bổ sung LLMs. Công việc của chúng tôi tiếp tục hướng nghiên cứu này, với trọng tâm cụ thể vào việc phát triển một trình xác minh mới dựa trên đồ thị để thúc đẩy khả năng lý luận của LLMs.

## 3 Phương pháp luận

### 3.1 Khung GraphReason

**Vấn đề 1 (Lý luận để Giải quyết Vấn đề)**
Cho một tập hợp n bài toán từ ngữ toán học Q={Q₁, Q₂, ..., Qₙ}, trong đó mỗi Qᵢ được biểu diễn bởi mô tả văn bản của một bài toán từ ngữ toán học đơn lẻ, mục tiêu của lý luận để giải bài toán từ ngữ toán học là tạo ra các câu trả lời A={A₁, A₂, ..., Aₙ} cho những vấn đề này. Ở đây, mỗi Aᵢ đại diện cho văn bản được tạo ra của câu trả lời tương ứng. Trong quá trình các mô hình ngôn ngữ lớn tạo ra câu trả lời, một tập hợp n đường lý luận cho các giải pháp S={S₁, S₂, ..., Sₙ} cũng được tạo ra. Mỗi giải pháp Sᵢ được biểu diễn như Sᵢ={Q, Bước 1, Bước 2, ..., Bước l, A}, trong đó mỗi Bước ᵢ biểu thị các bước trung gian trong các giải pháp từng bước.

Chúng tôi đề xuất GraphReason để xác minh các giải pháp được tạo ra bởi LLMs nhằm cải thiện độ chính xác câu trả lời cuối cùng. Phương pháp này là một kỹ thuật xác minh dựa trên đồ thị phân tích các đường lý luận từ các giải pháp được tạo ra từ góc độ đồ thị. Câu trả lời cuối cùng được thu được mà không sửa đổi LLMs gốc, hoạt động giống như một plugin. Như được minh họa trong Hình 2, có hai bước trong giai đoạn huấn luyện: Xây dựng Đồ thị và Phân loại Đồ thị. Trong bước Xây dựng Đồ thị, chúng tôi thu được giải pháp được tạo ra từ LLMs với prompt được thiết kế cụ thể và nhóm chúng theo câu trả lời cuối cùng của chúng. Chúng tôi chia các đường lý luận theo từng bước và sau đó hợp nhất các bước trung gian có biểu thức giống hệt nhau để tạo thành các đồ thị lý luận. Trong bước Phân loại Đồ thị, chúng tôi phân loại những đồ thị lý luận này với tính năng bổ sung của tổng điểm số từ trình xác minh cơ sở để huấn luyện mô hình trình xác minh tích hợp. Trong giai đoạn dự đoán, các giải pháp ứng viên đầu tiên được tạo ra bởi LLMs. Chúng tôi xử lý chúng theo cách tương tự như trong giai đoạn huấn luyện, sau đó chúng tôi sử dụng trình xác minh đã được huấn luyện để đánh giá điểm số của mỗi giải pháp ứng viên. Giải pháp tốt nhất, được biểu thị bởi điểm số cao nhất, được chọn làm câu trả lời dự đoán cuối cùng. Bây giờ chúng tôi sẽ cung cấp giới thiệu chi tiết về toàn bộ quá trình.

### 3.2 Thiết kế Prompt

Để cải thiện đầu ra của các Mô hình Ngôn ngữ (LLMs) trong việc cung cấp giải pháp, việc thiết kế các prompt hiệu quả là cần thiết. Chúng tôi kết hợp chuỗi tư duy và học tập trong ngữ cảnh để cho phép LLMs tạo ra câu trả lời từng bước cho bài toán từ ngữ toán học. Các mô hình ngôn ngữ tạo ra đầu ra y dựa trên đầu vào x bằng cách sử dụng phương trình sau:

p(y|C,x) = ∏ᵗ₌₁|y| pₗₘ(yᵗ|C,x,y<t), (1)

trong đó, C đại diện cho đầu vào được cung cấp cho LLMs trước câu hỏi bài toán từ ngữ toán học hiện tại. C là một nối tiếp của k mẫu, được biểu thị như:

C = [(Q₁, S₁, A₁); (Q₂, S₂, A₂), ...; (Qₖ, Sₖ, Aₖ)], (2)

trong đó, Qᵢ đại diện cho câu hỏi, Sᵢ đại diện cho các bước trung gian của giải pháp, và Aᵢ đại diện cho câu trả lời. Chúng tôi đặt k bằng năm trong nghiên cứu này, dẫn đến một prompt bao gồm năm cặp câu hỏi-câu trả lời được lấy mẫu từ split huấn luyện của một bộ dữ liệu bài toán từ ngữ toán học. Do đó, prompt có thể được biểu thị như:

Prompt = [C;Q], (3)

trong đó Q đại diện cho câu hỏi của bài toán từ ngữ toán học hiện tại.

Sử dụng phương pháp giải mã tham lam để lấy mẫu một đầu ra từ LLMs có thể không mạnh mẽ. Nó có thể dẫn đến sự không ổn định và lỗi thỉnh thoảng. Để giải quyết điều này, (Wang et al., 2023) đề xuất khái niệm tự nhất quán. Phương pháp này bao gồm việc lấy mẫu các đường lý luận khác nhau từ mô hình ngôn ngữ và sau đó chọn câu trả lời cuối cùng nhất quán nhất thông qua bỏ phiếu đa số. Thay vì sử dụng giải mã tham lam để chỉ lấy mẫu một lần và xác minh, họ sử dụng giải mã lấy mẫu để lấy mẫu N₁ lần. Chúng tôi cũng theo ý tưởng được trình bày bởi (Li et al., 2023) trong công việc của họ có tên Tất cả Con đường đều Dẫn đến Rome. Phương pháp này bao gồm việc tạo ra N₂ prompt đa dạng cho LLMs để tạo ra nhiều đầu ra. Bằng cách sử dụng nhiều lần giải mã lấy mẫu trên các prompt đa dạng, chúng ta có thể thu được các giải pháp được tạo ra từ các nguồn khác nhau. Cụ thể, chúng tôi thu được N = N₁ × N₂ đường lý luận đa dạng cho mỗi câu hỏi. Trong các thực nghiệm chính của chúng tôi, chúng tôi đặt N₁ = 10 và N₂ = 3. Những giải pháp này sẽ được xử lý thêm và xác minh bằng cách sử dụng trình xác minh được thiết kế của chúng tôi.

### 3.3 Xây dựng Đồ thị Lý luận

Sau khi tạo ra nhiều giải pháp cho một câu hỏi, việc xây dựng các đồ thị lý luận dựa trên các đường lý luận được thực hiện bởi những giải pháp này trở nên cần thiết.

Như được hiển thị trong Hình 3, chúng tôi bắt đầu bằng cách nhóm tất cả các giải pháp được tạo ra cho một câu hỏi cụ thể theo câu trả lời cuối cùng của chúng. Vì những giải pháp này bắt nguồn từ cùng một câu hỏi, các đường lý luận của chúng sẽ chia sẻ cùng một điểm khởi đầu. Tương tự, các giải pháp có cùng câu trả lời cuối cùng sẽ có cùng điểm kết thúc, vì các đường lý luận của chúng hội tụ. Do đó, một nhóm các giải pháp được tạo ra với cùng câu trả lời cuối cùng có thể tạo thành một đồ thị lý luận với nút bắt đầu thống nhất (nút câu hỏi) và nút kết thúc (nút câu trả lời). Chúng tôi định nghĩa quá trình phân chia này như sau:

S = {Sₐ₁, Sₐ₂, ..., Sₐₙ}, (4)

trong đó S đại diện cho tập hợp các giải pháp được tạo ra cho một câu hỏi, và Sₐᵢ = {S₁, S₂, ..., Sₘ} là tập con của các giải pháp được tạo ra mà tất cả đều có cùng câu trả lời cuối cùng Aᵢ.

Đối với mỗi tập con các giải pháp được tạo ra Sₐᵢ, chúng tôi xây dựng một đồ thị lý luận. Việc xây dựng này được thúc đẩy bởi sự hiểu biết rằng mỗi bước trong đường lý luận của một giải pháp được tạo ra không tồn tại biệt lập với các giải pháp khác. Các bước từ đường lý luận của một giải pháp có thể tác động đến các bước từ giải pháp khác, tăng cường quá trình lý luận tổng thể. Chúng tôi sử dụng cấu trúc đồ thị để mô hình hóa và nắm bắt những mối quan hệ này giữa các bước từ các giải pháp khác nhau. Vì các đường lý luận khác nhau có thể có lợi cho nhau, chúng tôi xây dựng một đồ thị lý luận để liên kết những đường này lại với nhau. Như được hiển thị trong Hình 4, hoạt động chính ở đây là việc hợp nhất các nút trung gian giống hệt nhau trong các đường lý luận thành một nút đồ thị duy nhất. Chúng tôi đầu tiên so sánh các bước lý luận từ bất kỳ hai đường lý luận giải pháp nào. Nếu chúng có cùng các bước trung gian của biểu thức số học, chúng tôi hợp nhất chúng thành cùng một nút, và nếu chúng khác nhau, chúng tôi không làm vậy. Đối với các bài toán từ ngữ toán học lý luận ở đây, chúng tôi định nghĩa các bước lý luận như biểu thức số học hiện tại mà không có văn bản ngôn ngữ khác trong bước lý luận hiện tại để rõ ràng. Nó có thể giúp chúng ta đơn giản hóa việc xây dựng các đồ thị lý luận trong nhiệm vụ lý luận. Thuật toán chi tiết để xây dựng một đồ thị lý luận được hiển thị trong Thuật toán 1.

Các giải pháp được tạo ra, được chia bởi các câu trả lời cuối cùng của chúng {Sₐ₁, Sₐ₂, ..., Sₐₙ}, có thể được biến đổi thành n đồ thị lý luận của các giải pháp được tạo ra {Gₐ₁, Gₐ₂, ..., Gₐₙ}.

Về các tính năng nút trong đồ thị, chúng tôi chọn điểm số từ Trình Xác minh Cơ sở và bậc nút. Chúng tôi tin rằng điểm số từ Trình Xác minh Cơ sở đóng gói thông tin ngữ nghĩa của các giải pháp, và bậc nút chứa thông tin về cấu trúc đồ thị. Trình Xác minh Cơ sở được huấn luyện độc lập với toàn bộ khung. Nó được thiết kế để đánh giá xem một đường lý luận đơn lẻ của một giải pháp có đúng hay không, đây là một nhiệm vụ phân loại văn bản nhị phân. Sau khi huấn luyện, nó có thể được sử dụng để xác minh bất kỳ giải pháp đơn lẻ nào và gán một điểm số ∈ (0,1) để đánh giá khả năng giải pháp đó đúng, trong đó điểm số = 0.99 gợi ý xác suất 99% giải pháp đó đúng. Chúng tôi sử dụng điểm số từ Trình Xác minh Cơ sở để kết hợp tốt hơn thông tin ngữ nghĩa giải pháp vì, theo các thực nghiệm của chúng tôi, việc mô hình hóa thông tin ngữ nghĩa trong khi mô hình hóa thông tin logic lý luận là thách thức. Điểm số của một bước giống như điểm số giải pháp của nó. Do đó, đối với một nút bước V, nó có nhiều điểm số {điểm số_a, điểm số_b, ..., điểm số_c} từ các giải pháp khác nhau. Tính năng của một nút Vᵢ trong đồ thị sau đó được nối bởi tính năng được chọn, có thể được biểu diễn như:

V = [điểm số_trung bình_i, điểm số_tối đa_i, điểm số_tối thiểu_i, điểm số_số lượng_i, bậc_vào_i], (5)

trong đó V ∈ R⁵, điểm số_trung bình_i là trung bình của tất cả điểm số của một bước Vᵢ, điểm số_tối đa_i là điểm số tối đa, điểm số_tối thiểu_i là điểm số tối thiểu, điểm số_số lượng_i là số lượng điểm số, và bậc_vào_i là bậc vào của nút bước Vᵢ.

**Thuật toán 1** Thuật toán xây dựng đồ thị lý luận
**Đầu vào:** các giải pháp được tạo ra Sₐᵢ có cùng câu trả lời cuối cùng
**Đầu ra:** một đồ thị lý luận Gₐᵢ
1: số_nút ← 0
2: nút2id ← dict()
3: cạnh ← list()
4: **đối với mỗi** đường_lý_luận **trong** Sₐᵢ **làm**
5:     **đối với mỗi** bước **trong** đường_lý_luận **làm**
6:         **nếu** bước **không có trong** nút2id.keys() **thì**
7:             nút2id[bước] ← số_nút
8:             số_nút ← số_nút + 1
9:         **kết thúc nếu**
10:    **kết thúc đối với**
11: **kết thúc đối với**
12: **đối với mỗi** đường_lý_luận **trong** Sₐᵢ **làm**
13:     **đối với mỗi** bước **trong** đường_lý_luận **làm**
14:         nút_bắt_đầu ← nút2id[bước_cuối]
15:         nút_kết_thúc ← nút2id[bước]
16:         **nếu** (nút_bắt_đầu, nút_kết_thúc) **không có trong** cạnh **thì**
17:             cạnh.add((nút_bắt_đầu, nút_kết_thúc))
18:         **kết thúc nếu**
19:         bước_cuối ← bước
20:     **kết thúc đối với**
21: **kết thúc đối với**
22: Gₐᵢ ← đồ thị(nút2id, cạnh)

Bằng cách này, chúng ta có thể thu được nhiều đồ thị lý luận để biểu diễn tất cả các giải pháp được tạo ra từ LLMs cho một câu hỏi bài toán từ ngữ toán học đơn lẻ.

### 3.4 Thiết kế Trình xác minh

Trình xác minh được thiết kế của chúng tôi GraphReason, được sử dụng để đánh giá câu trả lời của một nhóm giải pháp được tạo ra, cũng được biểu diễn như một đồ thị lý luận. Trình xác minh này có hai đầu vào: đồ thị và tổng điểm số giải pháp. Chúng tôi sử dụng Mạng Đồng cấu Đồ thị (GIN) (Xu et al., 2019) để thực hiện truyền tính năng nút, qua đó mã hóa thông tin từ các đồ thị lý luận chúng ta thu được. Tính năng nút được truyền và tập hợp như sau:

h_v^(k) = MLP^(k)((1 + ε^(k)) · h_v^(k-1) + ∑_{u∈N(v)} h_u^(k-1)), (6)

trong đó h_v^(k) đại diện cho trạng thái của nút v sau lần cập nhật thứ k. MLP^(k) đề cập đến một perceptron đa lớp trong lớp thứ k. N(v) biểu thị tất cả các nút lân cận của nút v và ε là một tham số có thể học được. Sau đó, chúng tôi thực hiện đọc tổng để thu được biểu diễn của đồ thị lý luận:

hG = ∑_{v∈G} h_v^(k), (7)

trong đó hG ∈ R⁵. Chúng tôi đặt k bằng 3, biểu thị việc áp dụng ba lớp GIN. Đồng thời, tổng điểm số của các giải pháp có cùng câu trả lời cuối cùng, Aᵢ, được biểu thị như điểm số_Aᵢ, được biểu diễn như sau:

điểm số_A = ∑_{i∈SA} điểm số_i. (8)

Sau đó một đồ thị lý luận có thể được biểu diễn như:

G = [hG, điểm số_A], (9)

trong đó G ∈ R⁶.

Nhãn mục tiêu của đồ thị y ∈ {0,1} chỉ ra liệu câu trả lời cuối cùng có khớp với câu trả lời cuối cùng đúng hay không. Chúng tôi tính toán mất mát và huấn luyện mô hình trình xác minh bằng:

L = ∑_{i=1}^n L_BCE(nhãn_i, f(Gᵢ)), (10)

trong đó i đại diện cho số lượng tập con giải pháp trong số tất cả n tập con sau khi nhóm các giải pháp. Đồ thị lý luận tương ứng cho tập con này được biểu thị bởi Gᵢ, và f() là một bộ phân loại tuyến tính.

### 3.5 Xác minh Câu trả lời

Trong giai đoạn dự đoán, tất cả các giải pháp được tạo ra được xử lý theo cách tương tự như trong giai đoạn huấn luyện. Trình xác minh đã được huấn luyện sau đó được sử dụng để đánh giá điểm số của mỗi đồ thị lý luận, mỗi đồ thị đại diện cho một nhóm giải pháp mang lại cùng câu trả lời cuối cùng. Câu trả lời cuối cùng được liên kết với điểm số cao nhất được chọn làm câu trả lời dự đoán cuối cùng của chúng tôi:

ŷ = Câu trả lời[arg max_i điểm số_i], (11)

trong đó điểm số_i biểu thị điểm số của đồ thị lý luận Gᵢ, như được xác định bởi trình xác minh của chúng tôi. Câu trả lời đại diện cho danh sách tất cả các câu trả lời cuối cùng ứng viên. Bằng cách dự đoán số của đồ thị lý luận tối ưu, chúng ta có thể xác định kết quả dự đoán cuối cùng của nhiệm vụ lý luận hiện tại.

## 4 Thực nghiệm

Trong phần này, chúng tôi đã tiến hành các thực nghiệm mở rộng để chứng minh hiệu suất của GraphReason, cùng với phân tích sâu hơn. Phổ quát, chúng tôi tái tạo tất cả các loại trình xác minh để báo cáo kết quả của chúng dựa trên cùng các giải pháp được tạo ra. Các thực nghiệm của chúng tôi được tiến hành trong hai cài đặt: Lý luận Số học và Lý luận Thường thức. Chúng tôi đảm bảo so sánh công bằng bằng cách đặt cùng seed ngẫu nhiên, sử dụng cùng môi trường phần cứng, và áp dụng các siêu tham số tương tự. Chúng tôi sử dụng độ chính xác làm thước đo để đánh giá khả năng giải bài toán từ ngữ toán học, xác định xem câu trả lời cuối cùng có đúng hay không.

### 4.1 Chi tiết Huấn luyện

Đối với việc lấy mẫu LLMs, chúng tôi sử dụng gpt-3.5-turbo làm LLMs cơ sở và đặt nhiệt độ t bằng 1. Tất cả các trình xác minh sử dụng cùng đầu ra của LLMs. Về huấn luyện trình xác minh, chúng tôi fine-tune trên bert-base-uncased (Devlin et al., 2019). Chúng tôi sử dụng bộ tối ưu hóa AdamW (Loshchilov and Hutter, 2019) để tối ưu hóa các tham số mô hình trong quá trình huấn luyện. Chúng tôi áp dụng tốc độ học khác biệt, đặt tốc độ học của bộ phân loại tuyến tính cuối cùng thành 4e-2, trong khi các lớp mạng nơ-ron đồ thị khác được đặt thành 4e-3. Lớp kích hoạt giữa chúng là ReLU (Agarap, 2019). Kích thước batch trong mỗi bước huấn luyện được đặt thành 2. Kích thước batch nhỏ vì trình xác minh cần xác minh nhiều đồ thị lý luận cho một câu hỏi đơn lẻ.

Để đảm bảo so sánh công bằng giữa Trình xác minh Bỏ phiếu, Trình xác minh Đơn giản, và GraphReason, chúng tôi sử dụng cùng trình xác minh cơ sở đã được huấn luyện cho cả ba phương pháp.

Chi tiết về các bộ dữ liệu và baseline được cung cấp trong Phụ lục A và Phụ lục B, tương ứng.

### 4.2 Kết quả Chính

Chúng tôi trình bày các kết quả chính trong Bảng 1. Như có thể thấy từ bảng, GraphReason tăng cường đáng kể khả năng lý luận gốc của gpt-3.5-turbo trên tất cả ba bộ dữ liệu, ví dụ, cải thiện độ chính xác 13.0% (72.7% → 85.7%) trên GSM8K. Cũng rõ ràng rằng phương pháp của chúng tôi vượt trội hơn các phương pháp trình xác minh khác với cùng đầu ra từ LLMs và đạt được state-of-the-art trên tất cả ba bộ dữ liệu.

Ngoài ra, Trình xác minh Bỏ phiếu Nhận biết Từng bước cải thiện so với Trình xác minh Bỏ phiếu bằng cách nhận ra rằng không phải tất cả các bước trong một đường lý luận không chính xác đều sai lệch như nhau, và một số bước vẫn có thể hữu ích cho lý luận. Chúng tôi tin rằng giả thuyết này quá đơn giản và không thể mô tả các mối quan hệ logic phức tạp giữa các bước. Theo Bảng 1, nó dẫn đến một số suy giảm thước đo, và cùng phát hiện cũng được quan sát trong bài báo gốc. Hơn nữa, nó không hoạt động tốt trong nhiệm vụ StrategyQA, vì không có đường lý luận vàng cho việc huấn luyện nhiệm vụ lý luận thường thức này. Trong nhiệm vụ này, các đường lý luận được tạo ra và giả, chỉ ra yêu cầu cho nhãn vàng ở mỗi bước của quá trình lý luận. Tuy nhiên, bài báo của chúng tôi liên tục cải thiện so với Trình xác minh Bỏ phiếu bằng cách xem xét mối quan hệ phức tạp giữa các đường lý luận khác nhau thông qua các đồ thị lý luận. Chúng tôi tăng cường phương pháp trước đó, không xem xét các quan hệ trong các bước giữa các giải pháp khác nhau, bằng 0.3% (85.4% → 85.7%), 0.3% (85.1% → 85.4%), 0.1% (96.9% → 97.0%), và 0.5% (70.7% → 71.2%) trên bốn bộ dữ liệu.

Hơn nữa, GraphReason chỉ mang lại cải thiện hiệu suất nhẹ trên ASDiv-a, và kết quả gần như giống hệt nhau. Một lý do cho điều này là các bài toán từ ngữ toán học từ ASDiv-a đơn giản hơn so với những bài trong hai bộ dữ liệu khác, dựa trên quan sát của chúng tôi. Trong hầu hết trường hợp, những vấn đề này không đòi hỏi lý luận phức tạp từ góc độ đồ thị để tạo ra một câu trả lời thỏa đáng. Nó chứng minh rằng phương pháp của chúng tôi đặc biệt phù hợp cho những tình huống như vậy. Chúng tôi tin rằng GraphReason có thể mang lại những cải thiện đáng kể hơn trong tình huống phức tạp hơn.

### 4.3 Nghiên cứu Loại bỏ

Chúng tôi tiến hành nghiên cứu loại bỏ để đánh giá tác động của mỗi thành phần đối với hiệu suất tổng thể của phương pháp chúng tôi. Bảng 2 trình bày kết quả của nghiên cứu này, làm nổi bật cách những mô-đun này đóng góp vào việc cải thiện mô hình cơ sở theo những cách riêng biệt. Có thể quan sát thấy rằng việc loại bỏ bất kỳ thành phần nào dẫn đến suy giảm trong kết quả cuối cùng. Ngữ nghĩa giải pháp từ trình xác minh cơ sở dường như quan trọng nhất đối với GraphReason. Phương pháp hiện tại vẫn dựa vào thông tin ngữ nghĩa, điều này hợp lý vì các bước lý luận từ các giải pháp khác nhau yêu cầu thông tin ngữ nghĩa để lý luận tốt hơn. Chúng tôi cũng nhận thấy rằng các đồ thị lý luận mang lại cải thiện nhẹ cho toàn bộ phương pháp, qua đó chứng minh hiệu quả của cấu trúc đồ thị. Cải thiện không đáng kể vì chúng tôi không mô hình hóa cấu trúc đồ thị và thông tin ngữ nghĩa đồng thời, và tạo ra khoảng cách huấn luyện ở đây. Một yếu tố cần thiết khác là độ phức tạp của phân loại đồ thị, được tăng thêm bởi sự hiện diện của nhiễu và hạn chế trong dữ liệu huấn luyện của chúng tôi.

### 4.4 GraphReason với các LLMs khác nhau

Để đánh giá tính tương thích của GraphReason và hiệu quả của nó trên các mô hình khác nhau, chúng tôi bổ sung bao gồm gpt-4 (OpenAI, 2023) và PaLM-2 (Google, 2023) trong các thực nghiệm của chúng tôi. Do tài nguyên tính toán hạn chế của chúng tôi, chúng tôi sử dụng cùng dữ liệu huấn luyện được lấy mẫu trước đó từ gpt-3.5-turbo. Để kiểm tra trong nhiệm vụ GSM8K, chúng tôi chọn mẫu từ 100 mẩu dữ liệu từ gpt-4 và PaLM-2 tương ứng. Chúng tôi tiến hành lấy mẫu 10 lần sử dụng ba loại năm mẫu, duy trì cùng cài đặt như trong các thực nghiệm trước đó của chúng tôi. Phương pháp của chúng tôi nhằm tăng cường khả năng lý luận gốc. Do đó, chúng tôi không bao gồm LMs kích thước nhỏ, thường thể hiện khả năng lý luận yếu hơn.

Từ Bảng 3, rõ ràng rằng phương pháp của chúng tôi tăng cường hiệu suất lý luận gốc của cả GPT-4 và PaLM-2. Tuy nhiên, có sự suy giảm hiệu suất trong gpt-4 khi so sánh với các baseline tốt nhất. Hiệu suất của GraphReason có thể so sánh với phương pháp bỏ phiếu. Chúng tôi giả thuyết rằng điều này là do các mẫu lý luận của GPT-4 khác với GPT-3.5-Turbo, và trình xác minh của chúng tôi được huấn luyện cụ thể trên các mẫu GPT-3.5-Turbo trong cài đặt này.

## 5 Kết luận

Trong bài báo này, chúng tôi đề xuất GraphReason, một phương pháp mới và tổng quát để tăng cường khả năng lý luận của các mô hình ngôn ngữ lớn. Phương pháp của chúng tôi là phương pháp đầu tiên tiếp cận logic lý luận của các mô hình ngôn ngữ lớn từ góc độ đồ thị và xác minh các đường lý luận ứng viên tương ứng. Chúng tôi chứng minh sự vượt trội của GraphReason thông qua các thực nghiệm mở rộng.

## Hạn chế

Có một số hạn chế trong nghiên cứu hiện tại góp phần vào hiệu suất không tốt như mong đợi:

• **Tài nguyên Tính toán**. Mặc dù hiệu suất ấn tượng mà nó đạt được, khung của chúng tôi đòi hỏi các mô hình ngôn ngữ lớn như GPT3.5. Suy luận với những mô hình này tốn thời gian và chi phí hơn so với các mô hình fine-tuning như BERT (Devlin et al., 2019). Một số thực nghiệm, như phân tích siêu tham số, đã được tiến hành trong các công việc liên quan trước đó và không được nhân bản ở đây. Hơn nữa, do tài nguyên tính toán hạn chế, chúng tôi không tiến hành thực nghiệm với các LLMs bổ sung. Chúng tôi đã chọn chỉ sử dụng LLM đại diện, GPT3.5, để so sánh hiệu suất của các trình xác minh.

• **Dữ liệu CoT có Nhãn**. GraphReason là một phương pháp trình xác minh phức tạp xây dựng trên phân loại đồ thị, đòi hỏi nhiều dữ liệu có nhãn với các đường lý luận chuỗi tư duy được chú thích tốt để huấn luyện. Trong việc huấn luyện GraphReason, chúng tôi sử dụng các đường lý luận từ đầu ra của LLMs có thể giới thiệu nhiễu đáng kể. Nếu dữ liệu huấn luyện bao gồm các đồ thị lý luận có nhãn, hiệu suất sẽ cải thiện đáng kể.

• **Các Nhiệm vụ Lý luận Khác**. Có nhiều loại nhiệm vụ lý luận ngoài bài toán từ ngữ toán học, như Lý luận Thường thức (Talmor et al., 2019), Lý luận Quy nạp (Sinha et al., 2019), v.v. Do việc xây dựng đồ thị là một quá trình phức tạp, chúng tôi chủ yếu tập trung vào giải bài toán từ ngữ toán học (Lý luận Số học). Trọng tâm này cho phép thực hiện thuận tiện hơn việc hợp nhất các bước trung gian. Trong các trường hợp khác, việc xác định các bước tương tự có thể thách thức. Mặt khác, một bài toán từ ngữ toán học thường trình bày sự đa dạng lớn hơn của các giải pháp tiềm năng.

Tuy nhiên, chúng tôi tin rằng các nghiên cứu tương lai, được tiến hành bởi chúng tôi hoặc những người khác, có thể vượt qua những hạn chế này và cải thiện thêm phương pháp của chúng tôi.

[Phần tài liệu tham khảo đã được dịch nhưng tôi sẽ bỏ qua để tiết kiệm không gian]

## A Bộ dữ liệu

Chúng tôi so sánh GraphReason với các phương pháp khác trên ba bộ dữ liệu bài toán từ ngữ toán học khác nhau: GSM8K (Cobbe et al., 2021a), SVAMP (Patel et al., 2021), và ASDiv-a (Miao et al., 2020) và một bộ dữ liệu lý luận thường thức: StrategyQA (Geva et al., 2021). Chúng tôi chọn tập con ASDiv-a (số học) từ bộ dữ liệu ASDiv gốc, chỉ liên quan đến các phép toán số học.

Ba bộ dữ liệu lý luận số học này thách thức hơn so với các bộ dữ liệu bài toán từ ngữ toán học khác, làm cho chúng phù hợp hơn để kiểm tra khả năng lý luận của LLMs với trình xác minh. Vì bộ dữ liệu GSM8K là bộ duy nhất cung cấp các giải pháp từng bước như các mẫu chuỗi tư duy, chúng tôi chọn các mẫu từ bộ dữ liệu huấn luyện GSM8K và kiểm tra chúng trên tất cả ba bộ dữ liệu. Ngoài ra, dữ liệu huấn luyện cho trình xác minh cũng sử dụng dữ liệu huấn luyện GSM8K. Trong cài đặt này, chúng tôi cũng có thể chứng minh khả năng học chuyển giao và tổng quát hóa của phương pháp chúng tôi. Kích thước của split huấn luyện từ GSM8k là 1000. Kích thước dữ liệu kiểm tra cho GSM8K, SVAMP, và ASDiv-a lần lượt là 1319, 1000, và 1218.

Trong nhiệm vụ lý luận thường thức StrategyQA, chúng tôi đặt số lượng mẫu thành 8 và chọn các mẫu giả từ (Li et al., 2023). Ngoài ra, chúng tôi tiến hành năm lần lặp lấy mẫu cho mỗi ngữ cảnh của LLMs. Từ toàn bộ bộ dữ liệu, chúng tôi chọn một tập con gồm 1.000 instance, phân bổ 700 cho huấn luyện và 300 cho kiểm tra.

## B Baseline

Trong đánh giá của chúng tôi, chúng tôi xem xét các baseline sau:

• **Greedy Decode** là một phương pháp đơn giản sử dụng chiến lược giải mã tham lam để lấy mẫu một lần.

• **Self-Consistency (Voting)** (Wang et al., 2023) lấy mẫu nhiều lần và chọn câu trả lời cuối cùng dựa trên bỏ phiếu đa số.

• **Simple Verifier** (Cobbe et al., 2021b), cũng được biết đến như chiến lược Lấy mẫu và Xếp hạng lại, sử dụng trình xác minh để gán điểm số cho các giải pháp được lấy mẫu và chọn câu trả lời cuối cùng với điểm số cao nhất.

• **Voting Verifier** (Li et al., 2023) kết hợp các phương pháp Bỏ phiếu và Trình xác minh. Nó gán tổng điểm số cho các câu trả lời từ điểm số của tất cả các giải pháp ứng viên và chọn câu trả lời cuối cùng với điểm số cao nhất.

• **DIVERSE (Step-aware Voting Verifier)** (Li et al., 2023), là phương pháp state-of-the-art, xem xét các bước lý luận trong toàn bộ đường lý luận. Nó nhận ra rằng không phải tất cả các bước trong một đường lý luận không chính xác đều sai lệch như nhau và một số bước vẫn có thể hữu ích cho lý luận.

Chúng tôi chủ yếu so sánh GraphReason với các trình xác minh khác sử dụng cùng các giải pháp được tạo ra từ gpt-3.5-turbo. Ngoài ra, chúng tôi bao gồm một số phương pháp Fine-tuning state-of-the-art trước đó để phản ánh khả năng lý luận mạnh mẽ của LLMs. Các phương pháp Fine-tuning SOTA trước đó được biểu thị như sau: a: (Cobbe et al., 2021b), b: (Pi et al., 2022), c: (Miao et al., 2020), d: (Chowdhery et al., 2022).

# ChatRule: Khai thác Quy tắc Logic với Mô hình Ngôn ngữ Lớn cho Lý luận Đồ thị Tri thức

Linhao Luo1, Jiaxin Ju2, Bo Xiong3, Yuan-Fang Li1, Gholamreza Haffari1, Shirui Pan2∗
1Đại học Monash, 2Đại học Griffith, 3Đại học Stuttgart
{linhao.luo, yuanfang.li, Gholamreza.Haffari}@monash.edu,
jiaxin.ju@griffithuni.edu.au, bo.xiong@ipvs.uni-stuttgart.de, s.pan@griffith.edu.au

## Tóm tắt

Quy tắc logic rất quan trọng để khám phá các kết nối logic giữa các mối quan hệ, có thể cải thiện hiệu suất lý luận và cung cấp kết quả có thể diễn giải trên đồ thị tri thức (KGs). Mặc dù đã có nhiều nỗ lực để khai thác các quy tắc logic có ý nghĩa trên KGs, các phương pháp hiện tại gặp phải vấn đề tìm kiếm tốn kém về tính toán trên không gian quy tắc và thiếu khả năng mở rộng cho các KG quy mô lớn. Bên cạnh đó, chúng thường bỏ qua ngữ nghĩa của các mối quan hệ - điều quan trọng để khám phá các kết nối logic. Gần đây, các mô hình ngôn ngữ lớn (LLMs) đã cho thấy hiệu suất ấn tượng trong lĩnh vực xử lý ngôn ngữ tự nhiên và nhiều ứng dụng khác nhau, nhờ vào khả năng nổi bật và tính tổng quát của chúng. Trong bài báo này, chúng tôi đề xuất một khung công việc mới, ChatRule, giải phóng sức mạnh của các mô hình ngôn ngữ lớn để khai thác quy tắc logic trên đồ thị tri thức. Cụ thể, khung công việc được khởi tạo với một bộ sinh quy tắc dựa trên LLM, tận dụng cả thông tin ngữ nghĩa và cấu trúc của KGs để thúc đẩy LLMs tạo ra các quy tắc logic. Để tinh chỉnh các quy tắc được tạo ra, một mô-đun xếp hạng quy tắc ước tính chất lượng quy tắc bằng cách kết hợp các sự kiện từ KGs hiện có. Cuối cùng, các quy tắc được xếp hạng có thể được sử dụng để thực hiện lý luận trên KGs. ChatRule được đánh giá trên bốn KG quy mô lớn, theo các chỉ số chất lượng quy tắc khác nhau và các nhiệm vụ hạ nguồn, cho thấy tính hiệu quả và khả năng mở rộng của phương pháp chúng tôi1.

## 1 Giới thiệu

Đồ thị tri thức (KGs) lưu trữ tri thức thế giới thực khổng lồ dưới định dạng cấu trúc của các bộ ba. Lý luận KG, nhằm suy luận tri thức mới từ các sự kiện hiện có, là một nhiệm vụ cơ bản trong KGs và rất quan trọng cho nhiều ứng dụng, như hoàn thiện KG [Qu and Tang, 2019], trả lời câu hỏi [Atif et al., 2023], và hệ thống gợi ý [Wang et al., 2019]. Gần đây, đã có nhu cầu ngày càng tăng về lý luận KG có thể diễn giải, có thể giúp người dùng hiểu quá trình lý luận và cải thiện độ tin cậy trong các tình huống có tầm quan trọng cao, như chẩn đoán y tế

*Tác giả liên hệ.
1Mã nguồn có sẵn tại: https://github.com/RManLuo/ChatRule

[Hình 1: Minh họa khai thác quy tắc logic cho lý luận đồ thị tri thức với LLMs.]

[Liu et al., 2021] và phán quyết pháp lý [Zhong et al., 2020]. Do đó, quy tắc logic [Barwise, 1977], có thể đọc được bởi con người và có thể tổng quát hóa cho các nhiệm vụ khác nhau, đã được áp dụng rộng rãi cho lý luận KG [Hou et al., 2021; Liu et al., 2022]. Ví dụ, như được hiển thị trong Hình 1, chúng ta có thể xác định một quy tắc logic: GrandMother(X, Y) ← Mother(X, Z) ∧ Father(Z, Y) để dự đoán các sự kiện thiếu cho quan hệ "GrandMother". Để tự động khám phá các quy tắc có ý nghĩa từ KGs cho lý luận, khai thác quy tắc logic đã thu hút sự chú ý đáng kể trong cộng đồng nghiên cứu [Yang et al., 2017; Sadeghian et al., 2019].

Các nghiên cứu trước đây về khai thác quy tắc logic thường tìm quy tắc logic bằng cách khám phá sự đồng xuất hiện của các mẫu thường xuyên trong cấu trúc KG [Galárraga et al., 2013; Chen et al., 2016]. Tuy nhiên, chúng thường yêu cầu liệt kê tất cả các quy tắc có thể trên KGs và xếp hạng chúng theo tầm quan trọng ước tính [Lao and Cohen, 2010]. Mặc dù nghiên cứu gần đây đã đề xuất sử dụng các phương pháp học sâu để xếp hạng các quy tắc. Chúng vẫn bị hạn chế bởi việc liệt kê quy tắc một cách toàn diện và không thể mở rộng cho các KG quy mô lớn [Yang et al., 2017; Sadeghian et al., 2019].

Một số phương pháp gần đây giải quyết vấn đề này bằng cách lấy mẫu đường dẫn từ KGs và huấn luyện các mô hình trên chúng để nắm bắt các kết nối logic tạo thành quy tắc [Qu et al., 2020; Cheng et al., 2022b; Cheng et al., 2022a]. Nhưng chúng thường bỏ qua đóng góp của ngữ nghĩa quan hệ để biểu đạt các kết nối logic. Ví dụ, theo thường thức, chúng ta biết "mẹ" của "cha" của một người là "bà ngoại" của anh ta. Dựa trên điều này, chúng ta có thể định nghĩa một quy tắc như GrandMother(X, Y) ← Mother(X, Z) ∧ Father(Z, Y) để biểu đạt kết nối logic. Tuy nhiên, do số lượng quan hệ trong KGs, việc yêu cầu các chuyên gia lĩnh vực chú thích quy tắc cho từng quan hệ có thể là gánh nặng. Do đó, điều quan trọng là tự động kết hợp cả cấu trúc và ngữ nghĩa của các quan hệ để khám phá quy tắc logic trong KGs.

Các mô hình ngôn ngữ lớn (LLMs) như ChatGPT2 và BARD3 thể hiện khả năng tuyệt vời trong việc hiểu ngôn ngữ tự nhiên và xử lý nhiều nhiệm vụ phức tạp [Zhao et al., 2023]. Được huấn luyện trên các kho dữ liệu quy mô lớn, LLMs lưu trữ một lượng lớn tri thức thường thức có thể được sử dụng để hỗ trợ lý luận KG [Pan et al., 2023]. Đồng thời, LLMs không được thiết kế để hiểu cấu trúc của KGs, khiến việc áp dụng trực tiếp chúng để khai thác quy tắc logic trên KGs trở nên khó khăn. Hơn nữa, vấn đề ảo giác được thừa nhận rộng rãi có thể khiến LLMs tạo ra các quy tắc logic vô nghĩa [Ji et al., 2023].

Để giảm thiểu khoảng cách giữa LLMs và khai thác quy tắc logic, chúng tôi đề xuất một khung công việc mới gọi là ChatRule, tận dụng cả thông tin ngữ nghĩa và cấu trúc của KGs để thúc đẩy LLMs tạo ra quy tắc logic. Cụ thể, chúng tôi trước tiên trình bày một bộ sinh quy tắc dựa trên LLM để tạo ra các quy tắc ứng viên cho mỗi quan hệ. Chúng tôi lấy mẫu một số đường dẫn từ KGs để đại diện cho thông tin cấu trúc, sau đó được sử dụng trong một lời nhắc được thiết kế cẩn thận để tận dụng khả năng của LLMs cho khai thác quy tắc. Để giảm vấn đề ảo giác, chúng tôi thiết kế một bộ xếp hạng quy tắc logic để đánh giá chất lượng của các quy tắc được tạo ra và lọc bỏ các quy tắc vô nghĩa bằng cách bao gồm các sự kiện được quan sát trong KGs. Điểm chất lượng được sử dụng thêm trong giai đoạn lý luận logic để giảm tác động của các quy tắc chất lượng thấp. Cuối cùng, chúng tôi đưa các quy tắc được xếp hạng vào một mô-đun lý luận logic để thực hiện lý luận có thể diễn giải trên KGs. Trong khung công việc của chúng tôi, các quy tắc được khai thác có thể được sử dụng trực tiếp cho các nhiệm vụ hạ nguồn mà không cần bất kỳ huấn luyện mô hình nào. Các thí nghiệm rộng rãi trên bốn KG quy mô lớn chứng minh rằng ChatRule vượt trội đáng kể so với các phương pháp tiên tiến nhất trong cả việc hoàn thiện đồ thị tri thức và đánh giá chất lượng quy tắc.

Các đóng góp chính của bài báo này được tóm tắt như sau:

• Chúng tôi đề xuất một khung công việc có tên ChatRule tận dụng ưu thế của LLMs để khai thác quy tắc logic. Theo hiểu biết của chúng tôi, đây là công trình đầu tiên áp dụng LLMs cho khai thác quy tắc logic.

• Chúng tôi trình bày một pipeline từ đầu đến cuối sử dụng khả năng lý luận của LLMs và thông tin cấu trúc của KGs để tạo quy tắc, xếp hạng quy tắc, và lý luận logic dựa trên quy tắc.

• Chúng tôi thực hiện các thí nghiệm rộng rãi trên bốn bộ dữ liệu. Kết quả thí nghiệm cho thấy ChatRule vượt trội đáng kể so với các phương pháp tiên tiến nhất.

2https://openai.com/blog/chatgpt
3https://bard.google.com/

## 2 Các Công trình Liên quan

### 2.1 Khai thác Quy tắc Logic

Khai thác quy tắc logic, tập trung vào việc trích xuất các quy tắc có ý nghĩa từ KGs, đã được nghiên cứu trong thời gian dài. Các phương pháp truyền thống liệt kê các quy tắc ứng viên, sau đó đánh giá chất lượng của chúng bằng cách tính toán điểm số trọng lượng [Lao and Cohen, 2010; Galárraga et al., 2013]. Với sự tiến bộ của học sâu, các nhà nghiên cứu khám phá ý tưởng học đồng thời quy tắc logic và trọng lượng theo cách có thể vi phân [Yang et al., 2017; Sadeghian et al., 2019; Yang and Song, 2020]. Tuy nhiên, các phương pháp này vẫn thực hiện tối ưu hóa nặng trên không gian quy tắc, điều này hạn chế khả năng mở rộng của chúng. Gần đây, các nhà nghiên cứu đã đề xuất lấy mẫu đường dẫn từ KGs và huấn luyện các mô hình trên chúng để học các kết nối logic. RLvLR [Omran et al., 2018] lấy mẫu quy tắc từ một đồ thị con và đề xuất hàm điểm dựa trên embedding để ước tính tầm quan trọng của mỗi quy tắc. RNNLogic [Qu et al., 2020] tách biệt việc tạo quy tắc và cân quy tắc, có thể tăng cường lẫn nhau và giảm không gian tìm kiếm. R5 [Lu et al., 2021] đề xuất một khung học tăng cường tìm kiếm heuristic trên KGs và khai thác các quy tắc logic cơ bản. NCRL [Cheng et al., 2022a] dự đoán thành phần tốt nhất của thân quy tắc để khám phá quy tắc. Ruleformer [Xu et al., 2022] áp dụng một mô hình dựa trên transformer để mã hóa thông tin ngữ cảnh và tạo quy tắc cho các nhiệm vụ lý luận, đây là phương pháp tiên tiến nhất trong lĩnh vực này. Tuy nhiên, các phương pháp hiện tại không xem xét ngữ nghĩa của các quan hệ và có thể dẫn đến kết quả không tối ưu.

### 2.2 Mô hình Ngôn ngữ Lớn

Các mô hình ngôn ngữ lớn (LLMs) đang cách mạng hóa lĩnh vực xử lý ngôn ngữ tự nhiên và trí tuệ nhân tạo. Nhiều LLMs (ví dụ: ChatGPT2, Bard3, FLAN [Wei et al., 2021], và LLaMA [Touvron et al., 2023]) đã chứng minh khả năng mạnh mẽ trong nhiều nhiệm vụ khác nhau. Gần đây, các nhà nghiên cứu cũng đã khám phá khả năng áp dụng LLMs để giải quyết các nhiệm vụ KG [Pan et al., 2023; Luo et al., 2023]. Để truy cập tốt hơn tiềm năng của LLMs, các nhà nghiên cứu thiết kế một số lời nhắc với các ví dụ few-shot [Brown et al., 2020] hoặc lý luận chuỗi suy nghĩ [Wei et al., 2022] để tối đa hóa khả năng của chúng. Tuy nhiên, các phương pháp này không được thiết kế cho khai thác quy tắc logic, đòi hỏi LLMs phải hiểu cả cấu trúc của KGs và ngữ nghĩa của các quan hệ để tạo ra các quy tắc có ý nghĩa.

## 3 Kiến thức Cơ bản và Định nghĩa Vấn đề

Đồ thị Tri thức (KGs) đại diện cho các tập hợp sự kiện dưới dạng bộ ba G = {(e, r, e') ⊆ E × R × E}, trong đó e, e' ∈ E và r ∈ R tương ứng biểu thị tập hợp các thực thể và quan hệ.

Quy tắc Logic là các trường hợp đặc biệt của logic bậc nhất [Barwise, 1977], có thể hỗ trợ lý luận có thể diễn giải trên KGs [Yang et al., 2017]. Quy tắc logic ρ phát biểu hàm ý logic dưới dạng sau:

ρ := rh(X, Y) ← r1(X, Z1) ∧ ··· ∧ rL(ZL-1, Y),                    (1)

trong đó body(ρ) := r1(X, Z1) ∧ ··· ∧ rL(ZL-1, Y) biểu thị phép hội của một chuỗi quan hệ gọi là thân quy tắc, rh(X, Y) biểu thị đầu quy tắc, và L biểu thị độ dài của quy tắc. Nếu các điều kiện trên thân quy tắc được thỏa mãn, thì phát biểu trên đầu quy tắc cũng đúng.

Một thể hiện của quy tắc được thực hiện bằng cách thay thế các biến X, Y, Z* với các thực thể thực tế trong KGs. Ví dụ, cho một quy tắc GrandMother(X, Y) ← Mother(X, Z1) ∧ Father(Z1, Y), một thể hiện quy tắc δ có thể là:

GrandMother(Alice, Charlie) ← Mother(Alice, Bob) ∧ Father(Bob, Charlie),        (2)

có nghĩa là nếu Alice là mẹ của Bob và Bob là cha của Charlie, thì Alice là bà ngoại của Charlie.

Định nghĩa Vấn đề. Cho một quan hệ mục tiêu rh ∈ R làm đầu quy tắc, mục tiêu của khai thác quy tắc logic là tìm một tập hợp các quy tắc có ý nghĩa Prh = {ρ1, ···, ρK} nắm bắt các kết nối logic của các quan hệ khác để biểu đạt quan hệ mục tiêu rh trong KGs.

## 4 Phương pháp

Trong phần này, chúng tôi sẽ giới thiệu khung công việc được đề xuất, gọi là ChatRule, để khai thác quy tắc logic trên KGs với các mô hình ngôn ngữ lớn. Khung công việc tổng thể được minh họa trong Hình 2, bao gồm ba thành phần chính: 1) một bộ sinh quy tắc dựa trên LLM tận dụng cả thông tin ngữ nghĩa và cấu trúc để tạo ra các quy tắc có ý nghĩa. 2) một bộ xếp hạng quy tắc để ước tính chất lượng của các quy tắc được tạo ra trên KGs, và 3) một mô-đun lý luận logic dựa trên quy tắc để thực hiện lý luận trên KGs cho các nhiệm vụ hạ nguồn.

### 4.1 Bộ Sinh Quy tắc dựa trên LLM

Các nghiên cứu thông thường về khai thác quy tắc logic thường tập trung vào việc sử dụng thông tin cấu trúc [Galárraga et al., 2013; Cheng et al., 2022a], bỏ qua đóng góp của ngữ nghĩa quan hệ để biểu đạt các kết nối logic. Để khai thác khả năng hiểu ngữ nghĩa của các mô hình ngôn ngữ lớn (LLMs), chúng tôi đề xuất một bộ sinh quy tắc dựa trên LLM tận dụng cả thông tin ngữ nghĩa và cấu trúc của KGs trong việc tạo ra các quy tắc có ý nghĩa.

Bộ Lấy mẫu Quy tắc

Để cho phép LLMs hiểu cấu trúc KG cho khai thác quy tắc, chúng tôi áp dụng bộ lấy mẫu tìm kiếm theo chiều rộng (BFS) để lấy mẫu một số đường dẫn đóng từ KGs, có thể được coi như các thể hiện của quy tắc logic [Omran et al., 2018; Cheng et al., 2022b]. Cho một bộ ba (e1, rh, eL), đường dẫn đóng được định nghĩa là một chuỗi quan hệ r1, ···, rL kết nối e1 và eL trong KGs, tức là e1 →r1 e2 →r2 ··· →rL eL. Ví dụ, cho một bộ ba (Alice, GrandMother, Charlie), một đường dẫn đóng p có thể được tìm thấy như:

p := Alice →Mother Bob →Father Charlie,                    (3)

đóng bộ ba (Alice, GrandMother, Charlie) trong KGs. Bằng cách coi bộ ba như đầu quy tắc và đường dẫn đóng như thân quy tắc, chúng ta có thể thu được thể hiện quy tắc δ được hiển thị trong Phương trình (2).

Cho một quan hệ mục tiêu rh, chúng tôi trước tiên chọn một tập hợp các bộ ba hạt giống {(e, rh, e')} từ KGs, từ đó chúng tôi thực hiện BFS để lấy mẫu một tập hợp các đường dẫn đóng {p} có độ dài nhỏ hơn L để tạo thành một tập hợp các thể hiện quy tắc {δ}. Sau đó, chúng tôi thay thế các thực thể thực tế trong các thể hiện quy tắc bằng các biến để thu được các mẫu quy tắc Srh = {ρ}. Các mẫu quy tắc truyền đạt thông tin cấu trúc của KGs dưới định dạng tuần tự, có thể được đưa vào mô hình ngôn ngữ lớn để hỗ trợ tạo quy tắc.

[Hình 2: Khung công việc tổng thể của ChatRule. 1) chúng tôi trước tiên lấy mẫu một số thể hiện quy tắc từ đồ thị tri thức cho một quan hệ mục tiêu rh. 2) chúng tôi thúc đẩy mô hình ngôn ngữ lớn (ví dụ: ChatGPT) tạo ra một tập hợp các quy tắc ứng viên thô. 3) chúng tôi đề xuất một bộ xếp hạng quy tắc để ước tính chất lượng của các quy tắc được tạo ra dựa trên sự kiện trong KGs. 4) các quy tắc cuối cùng có thể được áp dụng cho lý luận logic và giải quyết các nhiệm vụ hạ nguồn, như hoàn thiện đồ thị tri thức.]

Tạo Quy tắc dựa trên LLM

Các mô hình ngôn ngữ lớn (LLMs) được huấn luyện trên các kho dữ liệu quy mô lớn thể hiện khả năng hiểu ngữ nghĩa của ngôn ngữ tự nhiên và thực hiện lý luận phức tạp với tri thức thường thức [Zhou et al., 2020; Tan et al., 2023]. Để kết hợp thông tin cấu trúc và ngữ nghĩa, chúng tôi thiết kế một lời nhắc được tạo tỉ mỉ để khai thác khả năng của LLMs cho khai thác quy tắc.

Đối với mỗi quy tắc từ Srh thu được bởi bộ lấy mẫu quy tắc cho một quan hệ mục tiêu rh, chúng tôi ngôn ngữ hóa nó thành một câu ngôn ngữ tự nhiên bằng cách loại bỏ các ký hiệu đặc biệt trong tên quan hệ, có thể làm giảm hiểu biết ngữ nghĩa của LLMs. Đối với nghịch đảo của một quan hệ gốc (tức là wife^-1), chúng tôi ngôn ngữ hóa nó bằng cách thêm ký hiệu "inv_". Sau đó, chúng tôi đặt các mẫu quy tắc được ngôn ngữ hóa vào mẫu lời nhắc và đưa chúng vào LLMs (ví dụ: ChatGPT) để tạo ra các quy tắc. Một ví dụ về lời nhắc tạo quy tắc và kết quả của LLMs cho quan hệ "husband(X,Y)" được hiển thị trong Hình 3. Lời nhắc chi tiết có thể được tìm thấy trong Phụ lục.

[Hình 3: Một ví dụ về lời nhắc tạo quy tắc và kết quả của LLMs cho quan hệ "husband(X,Y)".]

Tạo Quy tắc Đa Truy vấn

Do số lượng lớn mẫu quy tắc, chúng không thể được đưa vào LLMs cùng một lúc do vượt quá giới hạn ngữ cảnh. Do đó, chúng tôi chia các mẫu quy tắc thành d truy vấn khác nhau. Mỗi truy vấn chứa k mẫu quy tắc được chọn ngẫu nhiên từ Srh. Sau đó chúng tôi thúc đẩy LLMs với các truy vấn riêng biệt và thu thập các phản hồi của LLMs để thu được một tập hợp các quy tắc ứng viên Crh = {ρ}.

### 4.2 Xếp hạng Quy tắc Logic

LLMs được biết đến với việc có vấn đề ảo giác, có thể tạo ra kết quả không chính xác [Ji et al., 2023]. Ví dụ, quy tắc được tạo ra husband(X, Y) ← husband(X, Z1) & brother(Z1, Y), được hiển thị trong kết quả của Hình 3, là không chính xác. Do đó, chúng tôi phát triển một bộ xếp hạng quy tắc để phát hiện ảo giác và ước tính chất lượng của các quy tắc được tạo ra dựa trên sự kiện trong KGs.

Bộ xếp hạng quy tắc nhằm gán một điểm chất lượng s(ρ) cho mỗi quy tắc ρ trong tập hợp quy tắc ứng viên Crh. Được thúc đẩy bởi các công trình khai thác quy tắc trước đây [Galárraga et al., 2013], chúng tôi sử dụng bốn thước đo, cụ thể là hỗ trợ, phủ sóng, độ tin cậy, và độ tin cậy PCA, để đánh giá chất lượng của quy tắc. Giới thiệu chi tiết và ví dụ về mỗi thước đo có thể được tìm thấy trong Phụ lục.

Hỗ trợ biểu thị số lượng sự kiện trong KGs thỏa mãn quy tắc ρ, được định nghĩa là:

supp(ρ) := #(e, e') : ∃(e, r1, e2) ∧, ···, ∧(eL-1, rL, e') :
body(ρ) ∧ (e, rh, e') ∈ G,                    (4)

trong đó (e1, r1, e2), ···, (eL-1, rL, e') biểu thị một chuỗi sự kiện trong KGs thỏa mãn thân quy tắc body(ρ) và (e, rh, e') biểu thị sự kiện thỏa mãn đầu quy tắc rh.

Rõ ràng, các quy tắc có hỗ trợ bằng không có thể dễ dàng được loại bỏ khỏi tập hợp ứng viên mà không cần tinh chỉnh thêm. Tuy nhiên, hỗ trợ là một số tuyệt đối có thể cao hơn đối với các quan hệ có nhiều sự kiện hơn trong KGs và cung cấp kết quả xếp hạng thiên vị.

Phủ sóng chuẩn hóa hỗ trợ bằng số lượng sự kiện cho mỗi quan hệ trong KGs, được định nghĩa là:

cove(ρ) := supp(ρ) / #{(e, e') : (e, rh, e') ∈ G}.                    (5)

Phủ sóng định lượng tỷ lệ các sự kiện hiện có trong KGs được hàm ý bởi quy tắc ρ. Để xem xét thêm các dự đoán không chính xác của quy tắc, chúng tôi giới thiệu độ tin cậy và độ tin cậy PCA để ước tính chất lượng của quy tắc.

Độ tin cậy được định nghĩa là tỷ lệ giữa số lượng sự kiện thỏa mãn quy tắc ρ và số lần thân quy tắc body(ρ) được thỏa mãn trong KGs, được định nghĩa là:

conf(ρ) := supp(ρ) / #{(e, e') : body(ρ) ∈ G}.                    (6)

Độ tin cậy giả định rằng tất cả các sự kiện được suy ra từ thân quy tắc nên được chứa trong KGs. Tuy nhiên, KGs thường không đầy đủ trong thực tế, có thể dẫn đến thiếu sót các sự kiện bằng chứng. Do đó, chúng tôi giới thiệu độ tin cậy PCA để chọn các quy tắc có thể tổng quát hóa tốt hơn cho các sự kiện chưa thấy.

Độ tin cậy PCA dựa trên lý thuyết giả định hoàn chỉnh một phần (PCA) [Galárraga et al., 2013] được định nghĩa là tỷ lệ giữa số lượng sự kiện thỏa mãn quy tắc ρ và số lần thân quy tắc body(ρ) được thỏa mãn trong hoàn thiện một phần của KGs, được định nghĩa là:

partial(ρ)(e, e') := (e, r1, e2) ∧, ···, ∧(eL-1, rL, ê) :
body(ρ) ∧ (e, rh, ê),                    (7)

pca(ρ) := supp(ρ) / #{(e, e') : partial(ρ)(e, e') ∈ G}.                    (8)

Mẫu số của độ tin cậy PCA không phải là kích thước của toàn bộ tập hợp sự kiện được suy ra từ thân quy tắc. Thay vào đó, nó dựa trên số lượng sự kiện mà chúng ta biết là đúng cùng với những sự kiện mà chúng ta giả định là sai. Do đó, độ tin cậy PCA tốt hơn để ước tính chất lượng và khả năng tổng quát của quy tắc trong KGs không đầy đủ. Kết quả thí nghiệm trong đánh giá chất lượng quy tắc cũng hỗ trợ khẳng định này.

### 4.3 Lý luận Logic dựa trên Quy tắc

Sau xếp hạng quy tắc logic, chúng tôi thu được một tập hợp các quy tắc được xếp hạng Rrh = {(ρ, s(ρ))} cho quan hệ mục tiêu rh. Các quy tắc được xếp hạng có thể được sử dụng cho lý luận logic và giải quyết các nhiệm vụ hạ nguồn, như hoàn thiện đồ thị tri thức, bằng cách áp dụng các thuật toán hiện có như chuỗi tiến [Salvat and Mugnier, 1996].

Cho một truy vấn (e, rh, ?), gọi A là tập hợp các câu trả lời ứng viên. Đối với mỗi e' ∈ A, chúng ta có thể áp dụng quy tắc trong Prh để thu được điểm số như:

score(e') = Σ_{ρ∈Rrh} Σ_{body(ρ)(e,e')∈G} s(ρ),                    (9)

trong đó body(ρ)(e, e') biểu thị đường dẫn trong KGs thỏa mãn thân quy tắc, và s(ρ) biểu thị điểm chất lượng của quy tắc, có thể là phủ sóng, độ tin cậy, và độ tin cậy PCA. Sau đó, chúng ta có thể xếp hạng các câu trả lời ứng viên A dựa trên điểm số và chọn top-N câu trả lời làm kết quả cuối cùng.

## 5 Thí nghiệm

### 5.1 Bộ dữ liệu

Trong thí nghiệm, chúng tôi chọn bốn bộ dữ liệu được sử dụng rộng rãi theo các nghiên cứu trước đây [Cheng et al., 2022b]: Family [Hinton and others, 1986], UMLS [Kok and Domingos, 2007], WN18RR [Dettmers et al., 2018], và YAGO3-10 [Suchanek et al., 2007]. Thống kê của các bộ dữ liệu được tóm tắt trong Bảng 1.

### 5.2 Phương pháp Cơ sở

Chúng tôi so sánh phương pháp của chúng tôi với các phương pháp cơ sở khai thác quy tắc SOTA: AIME [Galárraga et al., 2013], NeuralLP [Yang et al., 2017], RNNLogic [Qu et al., 2020], NLIL [Yang and Song, 2020], NCRL [Cheng et al., 2022a], và Ruleformer [Xu et al., 2022], trên cả nhiệm vụ hoàn thiện đồ thị tri thức và đánh giá chất lượng quy tắc.

### 5.3 Chỉ số

Đối với nhiệm vụ hoàn thiện đồ thị tri thức, chúng tôi che giấu thực thể đuôi hoặc đầu của mỗi bộ ba kiểm tra và sử dụng quy tắc được tạo ra bởi mỗi phương pháp để dự đoán nó. Theo các nghiên cứu trước đây [Cheng et al., 2022a], chúng tôi sử dụng thứ hạng đảo trung bình (MRR) và Hits@N làm chỉ số đánh giá và đặt N là 1 và 10. Đối với nhiệm vụ đánh giá chất lượng quy tắc, chúng tôi sử dụng các thước đo (ví dụ: hỗ trợ, phủ sóng, độ tin cậy, và độ tin cậy PCA) được thảo luận trong phần trước về xếp hạng quy tắc.

[Bảng 1: Thống kê bộ dữ liệu]
Bộ dữ liệu | #Bộ ba | #Quan hệ | #Thực thể
Family | 28,356 | 12 | 3,007
UMLS | 5,960 | 46 | 135
WN18RR | 93,003 | 11 | 40,943
YAGO3-10 | 1,089,040 | 37 | 123,182

### 5.4 Cài đặt Thí nghiệm

Đối với ChatRule, chúng tôi sử dụng ChatGPT4 làm LLMs để tạo quy tắc. Chúng tôi chọn độ tin cậy PCA làm thước đo xếp hạng quy tắc cuối cùng và đặt độ dài quy tắc tối đa L là 3. Trong nhiệm vụ hoàn thiện đồ thị tri thức, chúng tôi theo cùng cài đặt như các nghiên cứu trước đây [Cheng et al., 2022b; Cheng et al., 2022a]. Đối với các phương pháp cơ sở, chúng tôi sử dụng triển khai chính thức được công bố để thực hiện thí nghiệm. Thảo luận chi tiết về cài đặt có thể được tìm thấy trong Phụ lục.

### 5.5 Hoàn thiện Đồ thị Tri thức

Hoàn thiện đồ thị tri thức là một nhiệm vụ cổ điển nhằm dự đoán các sự kiện thiếu bằng cách sử dụng lý luận logic dựa trên quy tắc. Nhiệm vụ này đã được áp dụng bởi nhiều phương pháp khai thác quy tắc hiện có như Neural-LP [Yang et al., 2017], và NCRL [Cheng et al., 2022a] để đánh giá chất lượng của các quy tắc được tạo ra. Chúng tôi áp dụng quy tắc được tạo ra bởi mỗi phương pháp và sử dụng cùng lý luận logic dựa trên quy tắc được trình bày trong Phần 4.3 để dự đoán các sự kiện thiếu. Kết quả được hiển thị trong Bảng 2.

Từ kết quả, chúng ta có thể quan sát thấy ChatRule vượt trội hơn các phương pháp cơ sở trên hầu hết các bộ dữ liệu. Cụ thể, phương pháp truyền thống AIME, chỉ sử dụng thông tin cấu trúc với lập trình logic quy nạp, đã đạt được hiệu suất tương đối tốt. Tuy nhiên, AIME thất bại trong các KG quy mô lớn (ví dụ: YAGO3-10) do số lượng quan hệ và bộ ba ngày càng tăng. Các phương pháp dựa trên học sâu gần đây (ví dụ: Neural-LP, RNNLogic, và NLIL) đạt được hiệu suất tốt hơn bằng cách sử dụng khả năng học của mạng neural khi chúng tối ưu hóa các mô hình trên các nhiệm vụ học quy tắc. Tuy nhiên, chúng gặp phải vấn đề hết bộ nhớ trong việc xử lý các KG lớn do không gian tìm kiếm quy tắc rộng lớn. Trong khi NCRL lấy mẫu đường dẫn đóng để giảm không gian tìm kiếm, nó vẫn bỏ qua ngữ nghĩa của các quan hệ, dẫn đến hiệu suất không tối ưu. Tương tự như kiến trúc của LLMs, Ruleformer áp dụng một mô hình dựa trên transformer để tổng hợp thông tin ngữ cảnh từ KGs và tạo quy tắc theo cách sequence-to-sequence, đạt được hiệu suất tốt thứ hai. Điều này cũng chứng minh tiềm năng to lớn của kiến trúc transformer trong khai thác quy tắc logic. Với sự giúp đỡ của các LLM được tiền huấn luyện mạnh mẽ, ChatRule có thể tạo ra các quy tắc chất lượng cao bằng cách kết hợp thông tin cấu trúc và ngữ nghĩa của KGs. ChatRule cũng thiết lập hiệu suất STOA mới trong hầu hết các cài đặt.

4Chúng tôi sử dụng snapshot của ChatGPT được chụp từ ngày 13 tháng 6 năm 2023 (gpt-3.5-turbo-0613) để đảm bảo tính tái tạo.

[Bảng 2: Kết quả hoàn thiện đồ thị tri thức. OOM biểu thị hết bộ nhớ.]

### 5.6 Đánh giá Chất lượng Quy tắc

Để chứng minh thêm tính hiệu quả của bốn thước đo (tức là hỗ trợ, phủ sóng, độ tin cậy, và độ tin cậy PCA) được áp dụng trong xếp hạng quy tắc, chúng tôi sử dụng chúng để đánh giá các quy tắc được tạo ra bởi mỗi phương pháp. Kết quả được hiển thị trong Bảng 3.

Từ kết quả, chúng ta có thể quan sát thấy ChatRule có thể tạo ra các quy tắc với hỗ trợ, phủ sóng, và độ tin cậy cao hơn so với các phương pháp cơ sở. Cụ thể, chúng ta có thể quan sát thấy điểm số của các thước đo phù hợp với hiệu suất trong hoàn thiện đồ thị tri thức. Điều này chứng minh rằng các thước đo được chọn có thể định lượng tốt chất lượng của quy tắc. Đáng chú ý, trong khi NCRL đạt được điểm số cao hơn Ruleformer trong chỉ số hỗ trợ của YAGO3-10 (12660.16 so với 495.79), NCRL vẫn bị Ruleformer vượt trội trong hoàn thiện đồ thị tri thức. Điều này là do các quy tắc được tạo ra bởi Ruleformer có độ tin cậy PCA tốt hơn, phù hợp hơn để đánh giá quy tắc trong KGs không đầy đủ. Tương tự, điểm độ tin cậy PCA cao hơn cho thấy ChatRule có thể tạo ra các quy tắc với khả năng tổng quát tốt hơn thay vì chỉ dựa vào các quy tắc được lấy mẫu từ lời nhắc. Do đó, ChatRule cũng chứng minh hiệu suất vượt trội trong nhiệm vụ hoàn thiện đồ thị tri thức.

[Bảng 3: Kết quả đánh giá chất lượng quy tắc.]

### 5.7 Nghiên cứu Triệt tiêu

Phân tích các LLM khác nhau. Chúng tôi đầu tiên đánh giá hiệu suất của ChatRule với một số LLM ở các kích thước khác nhau, bao gồm GPT-4 [OpenAI, 2023], Mistral-7B-Instruct [Jiang et al., 2023], và LLaMA2-Chat-7B/13B/70B [Touvron et al., 2023]. Chi tiết về phiên bản mô hình có sẵn trong Phụ lục.

Từ kết quả được hiển thị trong Bảng 4, chúng ta có thể quan sát thấy ChatRule với các LLM khác nhau vẫn đạt được hiệu suất có thể so sánh với các phương pháp cơ sở. Điều này chứng minh tính tổng quát của ChatRule. Một phát hiện thú vị là hiệu suất của ChatRule không phải lúc nào cũng được cải thiện bằng việc sử dụng các LLM lớn hơn. Ví dụ, ChatRule hoạt động tốt hơn với ChatGPT so với GPT-4. Trong họ LLaMA2, LLaMA2-Chat-7B vượt trội hơn LLaMA2-Chat-70B nhưng bị LLaMA2-Chat-13B vượt qua. Một lý do cho điều này là các LLM khác nhau nhạy cảm với lời nhắc đầu vào; chúng có thể hành xử khác nhau và đạt được các mức độ hiệu suất khác nhau mặc dù có cùng lời nhắc đầu vào. Do đó, việc điều chỉnh thêm lời nhắc đầu vào cho các LLM khác nhau có thể đạt được hiệu suất tốt hơn. Một lý do khác là các LLM lớn hơn có xu hướng tạo ra ít quy tắc hơn so với các LLM nhỏ hơn. Chúng tôi giả định điều này có thể do chi phí tính toán nặng hơn của các LLM lớn hơn, có thể dẫn đến xác suất dừng sớm cao hơn. Số lượng quy tắc giảm có thể dẫn đến phủ sóng kém hơn của các quy tắc đúng và hiệu suất không tối ưu.

[Bảng 4: Hiệu suất hoàn thiện đồ thị tri thức sử dụng quy tắc được tạo ra bởi các LLM khác nhau trên bộ dữ liệu Family.]

Phân tích các thước đo xếp hạng. Chúng tôi kiểm tra tính hiệu quả của mỗi thước đo (tức là phủ sóng, độ tin cậy, và độ tin cậy PCA) được áp dụng trong xếp hạng quy tắc. Các quy tắc đều được tạo ra bởi ChatGPT trên các bộ dữ liệu Family và UMLS.

Kết quả được hiển thị trong Bảng 5. Từ kết quả, chúng ta có thể thấy khi một trong các thước đo xếp hạng được sử dụng, hiệu suất của ChatRule được cải thiện so với khi không có thước đo xếp hạng (tức là None) được sử dụng. Điều này chứng minh rằng thước đo xếp hạng có thể hiệu quả giảm tác động của các quy tắc chất lượng thấp. Chỉ số độ tin cậy PCA đạt được hiệu suất tốt nhất trong tất cả các thước đo xếp hạng. Điều này cho thấy độ tin cậy PCA cho phép định lượng chất lượng của quy tắc trong KGs không đầy đủ và chọn các quy tắc với khả năng tổng quát tốt hơn, cũng được chọn làm chỉ số xếp hạng cuối cùng.

[Bảng 5: Phân tích mỗi thước đo xếp hạng.]

Phân tích siêu tham số. Cuối cùng, chúng tôi đánh giá hiệu suất của ChatRule với các siêu tham số khác nhau, tức là số lượng mẫu quy tắc khác nhau mỗi truy vấn (k) và số lượng truy vấn khác nhau (d) trên bộ dữ liệu Family. Kết quả được hiển thị trong Hình 4.

Từ kết quả, chúng ta có thể quan sát thấy hiệu suất của ChatRule đầu tiên cải thiện với sự tăng của k và giảm nhẹ khi k đạt 50. Điều này cho thấy với nhiều mẫu quy tắc hơn trong lời nhắc, ChatRule có thể tạo ra quy tắc với chất lượng tốt hơn. Tuy nhiên, giá trị k quá lớn dẫn đến lời nhắc dài hơn. Các LLM hiện có được biết đến với việc gặp khó khăn trong hiểu ngữ cảnh dài [Liu et al., 2023], có thể dẫn đến hiệu suất không tối ưu. Ngược lại, hiệu suất của ChatRule liên tục cải thiện với sự tăng của d. Điều này chứng minh rằng ChatRule có thể tạo ra quy tắc tốt hơn bằng cách "nhìn thấy" nhiều mẫu quy tắc hơn trong KGs. Tuy nhiên, nhiều truy vấn hơn cũng đưa ra chi phí tính toán cao hơn, có thể hạn chế khả năng mở rộng của ChatRule. Do đó, chúng tôi đặt k là 50 và d là 10 trong thí nghiệm.

[Hình 4: Phân tích tham số của số lượng mẫu quy tắc mỗi truy vấn (k) và số lượng truy vấn (d) trên bộ dữ liệu Family.]

### 5.8 Nghiên cứu Trường hợp

Chúng tôi đầu tiên hiển thị thống kê của quy tắc được khai thác và chi phí API tổng thể5 tương ứng cho mỗi bộ dữ liệu trong Bảng 6. Từ kết quả, chúng ta có thể quan sát thấy ChatRule có thể khai thác một số lượng đáng kể các quy tắc có ý nghĩa với chi phí API thấp.

Chúng tôi trình bày một số quy tắc logic đại diện được khai thác từ các bộ dữ liệu khác nhau trong Bảng 7. Kết quả cho thấy các quy tắc được tạo ra bởi phương pháp của chúng tôi vừa có thể diễn giải vừa có chất lượng cao. Ví dụ, "wife" về mặt trực quan là quan hệ nghịch đảo của "husband", quy tắc husband ← inv_wife được ChatRule trích xuất thành công với ngữ nghĩa của mối quan hệ được xem xét. Tương tự, "playsFor" là từ đồng nghĩa của "isAffiliatedTo", tạo thành quy tắc playsFor ← isAffiliatedTo. Ngoài ra, các quy tắc cũng tuân theo tri thức thường thức, thể hiện khả năng diễn giải tuyệt vời. Ví dụ, quy tắc diagnoses ← analyzes ∧ causes cho thấy để đưa ra chẩn đoán, các bác sĩ thường cần phân tích các triệu chứng của bệnh nhân và tìm nguyên nhân của bệnh. Cuối cùng, các quy tắc được tạo ra cũng khám phá một số kết nối logic liên kết. Quy tắc isPoliticianOf ← hasChild ∧ isPoliticianOf cho thấy trẻ em thường kế thừa vị trí chính trị của cha mẹ, được hỗ trợ bởi điểm hỗ trợ và PCA. Danh sách đầy đủ các quy tắc được khai thác có sẵn trong tệp bổ sung.

[Bảng 6: Thống kê của các quy tắc được khai thác và chi phí API tổng thể cho mỗi bộ dữ liệu.]

[Bảng 7: Các quy tắc đại diện được khai thác trên mỗi bộ dữ liệu.]

## 6 Kết luận

Trong bài báo này, chúng tôi giới thiệu một phương pháp mới có tên ChatRule để thu hẹp khoảng cách trong khai thác quy tắc logic trên KGs. Trong ChatRule, chúng tôi đề xuất một bộ sinh quy tắc dựa trên LLMs kết hợp cả thông tin ngữ nghĩa và cấu trúc để tạo ra các quy tắc có ý nghĩa. Ngoài ra, một bộ xếp hạng quy tắc được phát triển để đánh giá chất lượng của các quy tắc và loại bỏ những quy tắc không chính xác. Cuối cùng, các quy tắc được tạo ra có thể được sử dụng trực tiếp cho lý luận đồ thị tri thức mà không cần huấn luyện mô hình bổ sung. Các thí nghiệm rộng rãi trên một số bộ dữ liệu chứng minh ChatRule có thể tạo ra các quy tắc chất lượng cao và có thể diễn giải cho các nhiệm vụ hạ nguồn. Trong tương lai, chúng tôi sẽ khám phá việc tích hợp các mô hình tiên tiến để nâng cao hiểu biết của LLMs về thông tin cấu trúc và cải thiện hiệu suất của khai thác quy tắc.

5Chi phí được tính toán dựa trên giá API được định nghĩa bởi OpenAI (tức là 0.001$ và 0.002$ cho 1000 token đầu vào và đầu ra).

## Tài liệu tham khảo

[Atif et al., 2023] Farah Atif, Ola El Khatib, và Djellel Difallah. Beamqa: Multi-hop knowledge graph question answering with sequence-to-sequence prediction and beam search. Trong SIGIR, trang 781–790, 2023.

[Barwise, 1977] Jon Barwise. An introduction to first-order logic. Trong Studies in Logic and the Foundations of Mathematics, tập 90, trang 5–46. Elsevier, 1977.

[Brown et al., 2020] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. NeurIPS, 33:1877–1901, 2020.

[Chen et al., 2016] Yang Chen, Sean Goldberg, Daisy Zhe Wang, và Soumitra Siddharth Johri. Ontological pathfinding. Trong SIGMOD, trang 835–846, 2016.

[Cheng et al., 2022a] Kewei Cheng, Nesreen Ahmed, và Yizhou Sun. Neural compositional rule learning for knowledge graph reasoning. Trong ICLR, 2022.

[Cheng et al., 2022b] Kewei Cheng, Jiahao Liu, Wei Wang, và Yizhou Sun. Rlogic: Recursive logical rule learning from knowledge graphs. Trong KDD, trang 179–189, 2022.

[Dettmers et al., 2018] Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, và Sebastian Riedel. Convolutional 2d knowledge graph embeddings. Trong AAAI, tập 32, 2018.

[Galárraga et al., 2013] Luis Antonio Galárraga, Christina Teflioudi, Katja Hose, và Fabian Suchanek. Amie: association rule mining under incomplete evidence in ontological knowledge bases. Trong WWW, trang 413–422, 2013.

[Hinton and others, 1986] Geoffrey E Hinton et al. Learning distributed representations of concepts. Trong Proceedings of the eighth annual conference of the cognitive science society, tập 1, trang 12. Amherst, MA, 1986.

[Hou et al., 2021] Zhongni Hou, Xiaolong Jin, Zixuan Li, và Long Bai. Rule-aware reinforcement learning for knowledge graph reasoning. Trong ACL, trang 4687–4692, 2021.

[Ji et al., 2023] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, và Pascale Fung. Survey of hallucination in natural language generation. ACM Computing Surveys, 55(12):1–38, 2023.

[Jiang et al., 2023] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, và William El Sayed. Mistral 7b, 2023.

[Kok and Domingos, 2007] Stanley Kok và Pedro Domingos. Statistical predicate invention. Trong ICML, trang 433–440, 2007.

[Lao and Cohen, 2010] Ni Lao và William W Cohen. Relational retrieval using a combination of path-constrained random walks. Machine learning, 81:53–67, 2010.

[Liu et al., 2021] Yushan Liu, Marcel Hildebrandt, Mitchell Joblin, Martin Ringsquandl, Rime Raissouni, và Volker Tresp. Neural multi-hop reasoning with logical rules on biomedical knowledge graphs. Trong ESWC, trang 375–391. Springer, 2021.

[Liu et al., 2022] Yushan Liu, Yunpu Ma, Marcel Hildebrandt, Mitchell Joblin, và Volker Tresp. Tlogic: Temporal logical rules for explainable link forecasting on temporal knowledge graphs. Trong AAAI, tập 36, trang 4120–4127, 2022.

[Liu et al., 2023] Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, và Percy Liang. Lost in the middle: How language models use long contexts. arXiv preprint arXiv:2307.03172, 2023.

[Lu et al., 2021] Shengyao Lu, Bang Liu, Keith G Mills, SHANGLING JUI, và Di Niu. R5: Rule discovery with reinforced and recurrent relational reasoning. Trong ICLR, 2021.

[Luo et al., 2023] Linhao Luo, Yuan-Fang Li, Gholamreza Haffari, và Shirui Pan. Reasoning on graphs: Faithful and interpretable large language model reasoning. arXiv preprint arXiv:2310.01061, 2023.

[Omran et al., 2018] Pouya Ghiasnezhad Omran, Kewen Wang, và Zhe Wang. Scalable rule learning via learning representation. Trong IJCAI, trang 2149–2155, 2018.

[OpenAI, 2023] OpenAI. Gpt-4 technical report, 2023.

[Pan et al., 2023] Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, và Xindong Wu. Unifying large language models and knowledge graphs: A roadmap. arXiv preprint arXiv:2306.08302, 2023.

[Qu and Tang, 2019] Meng Qu và Jian Tang. Probabilistic logic neural networks for reasoning. NeurIPS, 32, 2019.

[Qu et al., 2020] Meng Qu, Junkun Chen, Louis-Pascal Xhonneux, Yoshua Bengio, và Jian Tang. Rnnlogic: Learning logic rules for reasoning on knowledge graphs. Trong ICLR, 2020.

[Sadeghian et al., 2019] Ali Sadeghian, Mohammadreza Armandpour, Patrick Ding, và Daisy Zhe Wang. Drum: End-to-end differentiable rule mining on knowledge graphs. NeurIPS, 32, 2019.

[Salvat and Mugnier, 1996] Eric Salvat và Marie-Laure Mugnier. Sound and complete forward and backward chainings of graph rules. Trong International Conference on Conceptual Structures, trang 248–262, 1996.

[Suchanek et al., 2007] Fabian M Suchanek, Gjergji Kasneci, và Gerhard Weikum. Yago: a core of semantic knowledge. Trong WWW, trang 697–706, 2007.

[Tan et al., 2023] Yiming Tan, Dehai Min, Yu Li, Wenbo Li, Nan Hu, Yongrui Chen, và Guilin Qi. Evaluation of chatgpt as a question answering system for answering complex questions. arXiv preprint arXiv:2303.07992, 2023.

[Touvron et al., 2023] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.

[Wang et al., 2019] Xiang Wang, Dingxian Wang, Canran Xu, Xiangnan He, Yixin Cao, và Tat-Seng Chua. Explainable reasoning over knowledge graphs for recommendation. Trong AAAI, tập 33, trang 5329–5336, 2019.

[Wei et al., 2021] Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, và Quoc V Le. Finetuned language models are zero-shot learners. Trong ICLR, 2021.

[Wei et al., 2022] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. NeurIPS, 35:24824–24837, 2022.

[Xu et al., 2022] Zezhong Xu, Peng Ye, Hui Chen, Meng Zhao, Huajun Chen, và Wen Zhang. Ruleformer: Context-aware rule mining over knowledge graph. Trong Proceedings of the 29th International Conference on Computational Linguistics, trang 2551–2560, 2022.

[Yang and Song, 2020] Yuan Yang và Le Song. Learn to explain efficiently via neural logic inductive learning. Trong International Conference on Learning Representations, 2020.

[Yang et al., 2017] Fan Yang, Zhilin Yang, và William W Cohen. Differentiable learning of logical rules for knowledge base reasoning. NeurIPS, 30, 2017.

[Zhao et al., 2023] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. A survey of large language models. arXiv preprint arXiv:2303.18223, 2023.

[Zhong et al., 2020] Haoxi Zhong, Yuzhong Wang, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu, và Maosong Sun. Iteratively questioning and answering for interpretable legal judgment prediction. Trong AAAI, tập 34, trang 1250–1257, 2020.

[Zhou et al., 2020] Xuhui Zhou, Yue Zhang, Leyang Cui, và Dandan Huang. Evaluating commonsense in pre-trained language models. Trong AAAI, tập 34, trang 9733–9740, 2020.

## A Thước đo Xếp hạng

Trong phần này, chúng tôi cung cấp một ví dụ chi tiết về các thước đo xếp hạng (tức là hỗ trợ, phủ sóng, độ tin cậy, và độ tin cậy PCA). Ví dụ, cho một quy tắc:

ρ := playsFor ← isAffiliatedTo,

và một KG đơn giản trong Bảng 8. Các thước đo có thể được tính như sau.

Hỗ trợ biểu thị số lượng sự kiện trong KGs thỏa mãn quy tắc ρ, được định nghĩa là:

supp(ρ) := #{(e, e') : ∃(e, r1, e2) ∧, ···, ∧(eL-1, rL, e') :
body(ρ) ∧ (e, rh, e') ∈ G},                    (10)

trong đó (e1, r1, e2), ···, (eL-1, rL, e') biểu thị một chuỗi sự kiện trong KGs thỏa mãn thân quy tắc body(ρ) và (e, rh, e') biểu thị sự kiện thỏa mãn đầu quy tắc rh.

Ví dụ. Đối với KG được cho trong Bảng 8, hỗ trợ của quy tắc là 1, vì (Alex, isAffiliatedTo, Club 1) và (Alex, playsFor, Club 1) tồn tại trong KG.

Phủ sóng chuẩn hóa hỗ trợ bằng số lượng sự kiện cho mỗi quan hệ trong KGs, được định nghĩa là:

cove(ρ) := supp(ρ) / #{(e, e') : (e, rh, e') ∈ G}.                    (11)

Ví dụ. Đối với KG được cho trong Bảng 8, phủ sóng của quy tắc là 1/2, vì chúng ta có 2 sự kiện dưới quan hệ "playsFor".

Phủ sóng định lượng tỷ lệ các sự kiện hiện có trong KGs được hàm ý bởi quy tắc ρ. Để xem xét thêm các dự đoán không chính xác của quy tắc, chúng tôi giới thiệu độ tin cậy và độ tin cậy PCA để ước tính chất lượng của quy tắc.

Độ tin cậy được định nghĩa là tỷ lệ giữa số lượng sự kiện thỏa mãn quy tắc ρ và số lần thân quy tắc body(ρ) được thỏa mãn trong KGs, được định nghĩa là:

conf(ρ) := supp(ρ) / #{(e, e') : body(ρ) ∈ G}.                    (12)

Ví dụ. Đối với KG được cho trong Bảng 8, độ tin cậy của quy tắc là 1/3, vì có một sự kiện tích cực thỏa mãn quy tắc, và có hai sự kiện (tức là (Alex, isAffiliatedTo, Club 2) và (Bob, isAffiliatedTo, Club 3)) được coi là các ví dụ tiêu cực.

Độ tin cậy giả định rằng tất cả các sự kiện được suy ra từ thân quy tắc nên được chứa trong KGs. Tuy nhiên, KGs thường không đầy đủ trong thực tế, có thể dẫn đến thiếu sót các sự kiện bằng chứng. Do đó, chúng tôi giới thiệu độ tin cậy PCA (giả định hoàn chỉnh một phần) để chọn các quy tắc có thể tổng quát hóa tốt hơn cho các sự kiện chưa thấy. Độ tin cậy PCA chỉ xem xét các ví dụ tiêu cực cứng, mâu thuẫn với các sự kiện trong KGs hiện có, và độ tin cậy PCA bỏ qua các ví dụ tiêu cực mềm, mà chúng ta không có kiến thức gì về tính chính xác của chúng.

Độ tin cậy PCA dựa trên lý thuyết giả định hoàn chỉnh một phần (PCA) [Galárraga et al., 2013] được định nghĩa là tỷ lệ giữa số lượng sự kiện thỏa mãn quy tắc ρ và số lần thân quy tắc body(ρ) được thỏa mãn trong hoàn thiện một phần của KGs, được định nghĩa là:

partial(ρ)(e, e') := (e, r1, e2) ∧, ···, ∧(eL-1, rL, ê) :
body(ρ) ∧ (e, rh, ê),                    (13)

pca(ρ) := supp(ρ) / #{(e, e') : partial(ρ)(e, e') ∈ G}.                    (14)

Ví dụ. Đối với KG được cho trong Bảng 8, độ tin cậy PCA của quy tắc là 1/2, vì (Alex, isAffiliatedTo, Club 2) là một ví dụ tiêu cực cứng vi phạm sự kiện rằng (Alex, playsFor, Club 1), và (Bob, isAffiliatedTo, Club 3) là một ví dụ tiêu cực mềm, được loại bỏ khỏi mẫu số vì chúng ta không biết "Bob" có chơi cho "Club 3" hay không, dựa trên sự kiện trong KG hiện có.

[Bảng 8: Một ví dụ KG chứa hai quan hệ và năm sự kiện]
isAffiliatedTo | playsFor
(Alex, Club 1) | (Alex, Club 1)
(Alex, Club 2) | (Charlie, Club 2)
(Bob, Club 3) |

## B Bộ dữ liệu

Trong thí nghiệm, chúng tôi chọn bốn bộ dữ liệu được sử dụng rộng rãi theo các nghiên cứu trước đây [Cheng et al., 2022b]: Family [Hinton and others, 1986], UMLS [Kok and Domingos, 2007], WN18RR [Dettmers et al., 2018], và YAGO3-10 [Suchanek et al., 2007].

• Family [Hinton and others, 1986] là một đồ thị tri thức định nghĩa các mối quan hệ của các thành viên trong một gia đình, ví dụ: "Father", "Mother", và "Aunt".

• UMLS [Kok and Domingos, 2007] là một tri thức y sinh, trong đó các thực thể là các khái niệm y sinh, và các quan hệ bao gồm điều trị và chẩn đoán.

• WN18RR [Dettmers et al., 2018] là một đồ thị tri thức từ vựng tiếng Anh được thiết kế để tổ chức các từ theo các mối quan hệ ngữ nghĩa của chúng. Các từ được kết nối bởi một loạt các quan hệ, bao gồm "hypernym", "derivation", v.v.

• YAGO3-10 [Suchanek et al., 2007] là một đồ thị tri thức quy mô lớn khác được xây dựng từ nhiều nguồn dữ liệu, như Wikipedia, WordNet, và GeoNames, chứa nhiều quan hệ, ví dụ: "was born in", "lives in", và "politician of".

## C Phương pháp Cơ sở

Chúng tôi so sánh phương pháp của chúng tôi với các phương pháp cơ sở khai thác quy tắc SOTA: AIME [Galárraga et al., 2013], NeuralLP [Yang et al., 2017], RNNLogic [Qu et al., 2020], NLIL [Yang and Song, 2020], NCRL [Cheng et al., 2022a], và Ruleformer [Xu et al., 2022] trong các thí nghiệm.

• AIME6 [Galárraga et al., 2013] là một phương pháp khai thác quy tắc logic thông thường, khám phá quy tắc từ KG với lập trình logic quy nạp.

• NeuralLP7 [Yang et al., 2017] đề xuất một lập trình logic neural, học các quy tắc logic theo cách vi phân từ đầu đến cuối.

• RNNLogic8 [Qu et al., 2020] đề xuất một bộ sinh quy tắc và một dự đoán lý luận với quy tắc logic. Nó phát triển một thuật toán dựa trên EM để tối ưu hóa và học các quy tắc chất lượng cao cho lý luận.

• NLIL9 [Yang and Song, 2020] đề xuất một mô hình học logic quy nạp neural là một khung lập trình logic quy nạp vi phân hiệu quả học các quy tắc logic bậc nhất.

• NCRL10 [Cheng et al., 2022a] suy luận quy tắc bằng cách hợp nhất đệ quy các thành phần trong thân quy tắc, phát hiện cấu trúc thành phần tốt nhất của thân quy tắc để biểu đạt đầu quy tắc.

• Ruleformer11 [Xu et al., 2022] là một mô hình dựa trên transformer mã hóa thông tin ngữ cảnh từ KGs để tạo quy tắc.

6https://github.com/dig-team/amie
7https://github.com/fanyangxyz/Neural-LP
8https://github.com/DeepGraphLearning/RNNLogic/tree/main
9https://github.com/gblackout/NLIL
10https://github.com/vivian1993/NCRL/commits/main
11https://github.com/zjukg/ruleformer

## D Mô hình Ngôn ngữ Lớn

Các LLM được sử dụng trong thí nghiệm được hiển thị trong Bảng 9. Đối với các LLM mã nguồn mở, chúng tôi sử dụng các checkpoint có sẵn từ HuggingFace12. Đối với ChatGPT và GPT-4, chúng tôi sử dụng API được cung cấp bởi OpenAI13.

[Bảng 9: Chi tiết của các LLM được sử dụng.]
Mô hình LLM | Triển khai
Mistral-7B-Instruct | mistralai/Mistral-7B-Instruct-v0.1
LlaMA2-chat-7B | meta-llama/Llama-2-7b-chat
LlaMA2-chat-13B | meta-llama/Llama-2-13b-chat
LlaMA2 70B | meta-llama/Llama-2-70b-chat
ChatGPT | gpt-3.5-turbo-0613
GPT-4 | gpt-4-0613

## E Cài đặt Thí nghiệm

Đối với ChatRule, chúng tôi sử dụng ChatGPT14 làm LLMs để tạo quy tắc. Chúng tôi chọn độ tin cậy PCA làm thước đo xếp hạng quy tắc cuối cùng và đặt độ dài quy tắc tối đa L là 3. Trong nhiệm vụ hoàn thiện đồ thị tri thức, chúng tôi theo cùng cài đặt như các nghiên cứu trước đây [Cheng et al., 2022b; Cheng et al., 2022a]. Đối với các phương pháp cơ sở, chúng tôi sử dụng mã được công bố để so sánh.

12https://huggingface.co/
13https://api.openai.com/v1/chat/completions
14Chúng tôi sử dụng snapshot của ChatGPT được chụp từ ngày 13 tháng 6 năm 2023 (gpt-3.5-turbo-0613) để đảm bảo tính tái tạo.

## F Lời nhắc Tạo Quy tắc

Mẫu lời nhắc được sử dụng để tạo quy tắc được hiển thị như sau.

### Lời nhắc Tạo Quy tắc

Quy tắc logic định nghĩa mối quan hệ giữa hai thực thể: X và Y. Mỗi quy tắc được viết dưới dạng hàm ý logic, phát biểu rằng nếu các điều kiện ở phía bên phải (thân quy tắc) được thỏa mãn, thì phát biểu ở phía bên trái (đầu quy tắc) đúng.

Bây giờ chúng ta có các quy tắc sau:
{mẫu quy tắc}

Dựa trên các quy tắc trên, hãy tạo ra càng nhiều quy tắc quan trọng nhất có thể cho đầu quy tắc: "{đầu quy tắc}(X,Y)". Vui lòng chỉ chọn các vị từ từ: {các quan hệ trong KGs}. Chỉ trả về các quy tắc mà không có giải thích nào.

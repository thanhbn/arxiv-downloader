# 2305.05936.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/knowledge-graph/2305.05936.pdf
# Kích thước tệp: 326438 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Khung Tiêm Nhiễm Kiến Thức Thường Thức Đa Bước Cho
Việc Trả Lời Câu Hỏi Thường Thức Không Cần Mẫu Huấn Luyện
Xin Guan, Biwei Cao, Qingqing Gao, Zheng Yin, Bo Liu, Jiuxin Cao
Đại học Đông Nam
{xin_guan,caobiwei,qingqing_gao,z.yin,bliu,jx.cao}@seu.edu.cn

Tóm tắt
Nghiên cứu về việc trả lời câu hỏi thường thức (QA) yêu cầu máy móc trả lời các câu hỏi dựa trên kiến thức thường thức. Tuy nhiên, nghiên cứu này đòi hỏi chi phí lao động đắt đỏ để chú thích dữ liệu làm cơ sở nghiên cứu, và các mô hình dựa trên paradigm tinh chỉnh chỉ áp dụng cho các tác vụ cụ thể, thay vì học khả năng suy luận thường thức tổng quát. Như một phương pháp mạnh mẽ hơn, việc trả lời câu hỏi thường thức không cần mẫu huấn luyện cho thấy triển vọng tốt. Khung hiện tại không cần mẫu huấn luyện cố gắng chuyển đổi các bộ ba trong đồ thị kiến thức thường thức (KG) thành các mẫu dạng QA làm nguồn dữ liệu huấn luyện trước để kết hợp kiến thức thường thức vào mô hình. Tuy nhiên, phương pháp này bỏ qua mối quan hệ đa bước trong KG, cũng là một vấn đề trung tâm quan trọng trong suy luận thường thức. Trong bài báo này, chúng tôi đề xuất một khung tiêm nhiễm kiến thức thường thức đa bước mới lạ. Cụ thể, nó khám phá paradigm suy luận đa bước trong KG tuân theo logic ngôn ngữ học, và chúng tôi tiếp tục đề xuất hai phương pháp tạo QA đa bước dựa trên KG. Sau đó, chúng tôi sử dụng học tương phản để huấn luyện trước mô hình với tập dữ liệu QA tổng hợp để tiêm nhiễm kiến thức thường thức đa bước. Các thí nghiệm rộng rãi trên năm benchmark trả lời câu hỏi thường thức cho thấy khung của chúng tôi đạt được hiệu suất tốt nhất.

1 Giới thiệu
Kiến thức thường thức là cơ sở thiết yếu cho giao tiếp hàng ngày của con người và cũng là một lĩnh vực nghiên cứu quan trọng trong hệ thống hiểu ngôn ngữ tự nhiên hiện tại. Để khám phá và cải thiện khả năng hiểu và suy luận của máy móc đối với thường thức, nhiều tập dữ liệu benchmark trả lời câu hỏi (QA) đã được đề xuất, ví dụ: CommonsenseQA (Talmor et al., 2019), Abductive NLI (Bhagavatula et al., 2020), PhysicalIQA (Bisk et al., 2020), v.v. Đồng thời, với sự phát triển của các mô hình ngôn ngữ được huấn luyện trước quy mô lớn (Devlin et al., 2019; Liu et al., 2019; Raffel et al., 2020), khoảng cách giữa hiệu suất của máy móc và con người trong các tập dữ liệu này đang dần thu hẹp. Tuy nhiên, một số nghiên cứu (Mitra et al., 2019; Ma et al., 2021; Kim et al., 2022) chỉ ra rằng các mô hình được tinh chỉnh cho các tác vụ downstream cụ thể đang khớp với từng tập dữ liệu riêng lẻ thay vì học khả năng suy luận thường thức tổng quát. Do đó, như một phương pháp đánh giá toàn diện hơn, việc trả lời câu hỏi thường thức không cần mẫu huấn luyện đã dần trở thành trọng tâm của nghiên cứu tương lai.

Việc trả lời câu hỏi thường thức không cần mẫu huấn luyện là xây dựng một hệ thống trả lời câu hỏi thường thức tổng quát với khả năng suy luận, thay vì nhắm vào các kịch bản cụ thể cho tác vụ. Các công trình gần đây (Ma et al., 2021; Kim et al., 2022) sử dụng các đồ thị kiến thức thường thức đa nguồn, như ConceptNet (Speer et al., 2017), Atomic (Sap et al., 2019a), và WordNet (Miller, 1995), làm nguồn dữ liệu, và sử dụng các bộ ba một bước trong đồ thị kiến thức để tạo ra các tập dữ liệu QA tổng hợp để huấn luyện mô hình QA.

--- TRANG 2 ---
Tuy nhiên, hầu hết các câu hỏi thường thức đều yêu cầu kiến thức đa bước để suy luận đúng. Đối với những câu hỏi này, các mô hình hiện tại không có khả năng suy luận đa bước, do đó chúng sẽ chọn câu trả lời sai. Như được thể hiện trong Hình 1, đối với câu hỏi thường thức này, cần phải suy luận câu trả lời đúng thông qua đường dẫn hai bước của (revolving door, at location, bank) và (bank, related to, security) trong đồ thị kiến thức. Tuy nhiên, các công trình trước đây chỉ tạo ra các mẫu QA dựa trên các bộ ba một bước. Mô hình được huấn luyện bởi tập dữ liệu được tạo ra bằng phương pháp này không có khả năng suy luận cho câu hỏi thường thức đa bước này. Vì có bốn thực thể câu trả lời được kết nối trực tiếp với các thực thể câu hỏi trong đồ thị kiến thức, mô hình này thậm chí còn đánh lạc hướng việc lựa chọn câu trả lời bằng cách coi bốn thực thể này là câu trả lời đúng.

Để giải quyết vấn đề trên, chúng tôi đề xuất một khung tiêm nhiễm kiến thức thường thức đa bước mới lạ cho việc trả lời câu hỏi thường thức không cần mẫu huấn luyện, được chia thành hai bước: tạo QA đa bước tổng hợp và huấn luyện trước tiêm nhiễm kiến thức. Cụ thể, trong quá trình tạo QA đa bước tổng hợp, chúng tôi khám phá paradigm tổng quát của suy luận thường thức đa bước, và tiếp tục đề xuất hai phương pháp tạo QA đa bước có logic ngôn ngữ học, phương pháp tạo QA thường thức tổng hợp và phương pháp tạo QA thường thức liên kết, tương ứng với khả năng suy luận liên tục và khả năng suy luận đa mặt của con người. Chúng tôi tạo ra một tập dữ liệu QA đa bước tổng hợp bằng hai phương pháp này. Trong quá trình huấn luyện trước tiêm nhiễm kiến thức, chúng tôi sử dụng học tương phản để huấn luyện trước mô hình trên tập dữ liệu QA đa bước tổng hợp để tiêm nhiễm kiến thức thường thức đa bước. Cuối cùng, chúng tôi có thể có được một mô hình trả lời câu hỏi thường thức tổng quát với khả năng suy luận kiến thức đa bước.

Những đóng góp chính của công trình này được tóm tắt như sau:
• Theo hiểu biết tốt nhất của chúng tôi, khung tiêm nhiễm kiến thức thường thức đa bước được đề xuất là công trình đầu tiên giới thiệu kiến thức thường thức đa bước để cải thiện hiệu suất của việc trả lời câu hỏi thường thức không cần mẫu huấn luyện.
• Chúng tôi khám phá các paradigm tổng quát của suy luận thường thức đa bước trong KG, và tiếp tục đề xuất hai phương pháp tạo QA đa bước có logic ngôn ngữ học để tạo ra một tập dữ liệu QA đa bước tổng hợp. Cả hai phương pháp đều có thể tạo ra các mẫu tiêu cực có tính gây nhiễu cao để cải thiện hiệu suất của mô hình.
• Chúng tôi sử dụng học tương phản để huấn luyện trước trên các tập dữ liệu QA đa bước tổng hợp để có được một mô hình trả lời câu hỏi thường thức với khả năng suy luận tổng quát và kiến thức đa bước.
• Chúng tôi tiến hành các thí nghiệm rộng rãi trên các benchmark trả lời câu hỏi thường thức khác nhau. Kết quả cho thấy khung của chúng tôi đạt được hiệu suất tốt nhất.

2 Công trình liên quan
2.1 Trả lời câu hỏi thường thức không cần mẫu huấn luyện
Việc trả lời câu hỏi thường thức không cần mẫu huấn luyện tập trung vào việc xây dựng các mô hình không giám sát mà không cần bất kỳ giám sát nhãn nào. Công trình hiện tại có thể được chia thành hai paradigm: (1) Thiết kế các mô hình không giám sát bằng cách tận dụng các thuộc tính của các mô hình ngôn ngữ được huấn luyện trước. Một số công trình sử dụng tác vụ mô hình ngôn ngữ có mặt nạ (MLM) trong các mô hình ngôn ngữ tự hồi quy, như Word2Vec, BERT (Devlin et al., 2019), để đánh giá tính hợp lý của các câu được tạo thành từ câu hỏi và câu trả lời (Tamborrino et al., 2020; Trinh và Le, 2018). Các công trình khác sử dụng các mô hình ngôn ngữ tạo sinh, như GPT-2 (Radford et al., 2019) và GPT-3 (Brown et al., 2020), để thiết kế các tiền tố mẫu để tạo ra kiến thức thường thức hoặc câu trả lời (Shwartz et al., 2020; Niu et al., 2021; Liu et al., 2022; Wang và Zhao, 2022). (2) Tiêm nhiễm kiến thức vào các mô hình được huấn luyện trước. Những công trình này sử dụng kiến thức bên ngoài (ví dụ: ConceptNet, ATOMIC, Wiki) làm nguồn dữ liệu và thiết kế các tác vụ huấn luyện trước khác nhau để kết hợp kiến thức vào các mô hình được huấn luyện trước (Banerjee và Baral, 2020; Ma et al., 2021; Kim et al., 2022). Vì kiến thức được tiêm nhiễm cho phép mô hình học kiến thức thường thức liên quan thông qua huấn luyện trước, phương pháp này có tính cạnh tranh hơn trên một số tác vụ trả lời câu hỏi thường thức. Công trình của chúng tôi cũng tập trung vào phương pháp không cần mẫu huấn luyện này.

2.2 Trả lời câu hỏi thường thức với kiến thức bên ngoài
Trong môi trường có giám sát, đã có nhiều công trình cố gắng kết hợp kiến thức bên ngoài

--- TRANG 3 ---
các mô-đun suy luận vào mô hình. Những công trình này (Lin et al., 2019; Feng et al., 2020; Yasunaga et al., 2021; Guan et al., 2022) trích xuất các đồ thị con liên quan đến các khái niệm QA trong đồ thị kiến thức, và thiết kế các bộ mã hóa đồ thị, kết hợp với các bộ mã hóa văn bản để suy luận. Trong bối cảnh không giám sát, nhiều công trình trực tiếp sử dụng đồ thị kiến thức làm nguồn dữ liệu cho việc huấn luyện trước. Banerjee và Baral (2020) thiết kế việc học bộ ba kiến thức, sử dụng bất kỳ hai phần tử nào để dự đoán phần tử còn lại. Ma et al. (2021) xây dựng các mẫu trả lời câu hỏi sử dụng đồ thị kiến thức, và huấn luyện mô hình bằng phương pháp mô hình hóa ngôn ngữ có mặt nạ. (Kim et al., 2022) thiết kế các bộ điều hợp kiến thức để giảm thiểu mất mát kiến thức từ sự can thiệp giữa các nguồn kiến thức khác nhau. Tuy nhiên, các phương pháp không giám sát trên chỉ sử dụng các bộ ba một bước làm mẫu huấn luyện, bỏ qua các mối quan hệ đa bước phong phú trong đồ thị kiến thức. Chúng tôi đề xuất một khung tiêm nhiễm kiến thức đa bước để giải quyết vấn đề này.

3 Khung Tiêm Nhiễm Kiến Thức Thường Thức Đa Bước
Trong bài báo này, chúng tôi tập trung vào tác vụ trả lời câu hỏi kiến thức thường thức không cần mẫu huấn luyện, trong đó mô hình hoặc hệ thống không thể truy cập bất kỳ dữ liệu huấn luyện hoặc xác thực nào cho các tác vụ thường thức. Trong thiết lập này, trước tiên chúng tôi tạo ra một tập dữ liệu QA tổng hợp từ KG, sau đó huấn luyện trước mô hình trên tập dữ liệu này để tiêm nhiễm kiến thức thường thức. Cuối cùng, chúng tôi kiểm tra mô hình của mình trên các tác vụ trả lời câu hỏi thường thức khác nhau để xác minh khả năng suy luận thường thức của mô hình.

Trong các khung trả lời câu hỏi thường thức không cần mẫu huấn luyện trước đây (Ma et al., 2021; Kim et al., 2022), bốn đồ thị kiến thức, ConceptNet (Speer et al., 2017), WordNet (Miller, 1995), WikiData (Vrandecic và Krötzsch, 2014), ATOMIC (Sap et al., 2019a), được sử dụng làm nguồn dữ liệu để tổng hợp QA. Chính thức, đối với một bộ ba (ehead; r; etail) trong KG, trong đó ehead; r; etail biểu thị thực thể đầu, quan hệ và thực thể cuối tương ứng, phương pháp trước đây chuyển đổi ehead và r thành câu hỏi Q thông qua các mẫu ngôn ngữ tự nhiên, lấy etail làm câu trả lời đúng Ac, và ngẫu nhiên chọn các thực thể cuối trong các bộ ba khác làm yếu tố gây nhiễu {A1, ..., An}, trong đó n là số lượng mẫu tiêu cực. Bằng phương pháp trên, một mẫu QA tổng hợp (Q; A) được tạo ra, trong đó A = {Ac, A1, ..., An}. Sau khi tạo ra tập dữ liệu tổng hợp, nó sử dụng mô hình để thực hiện tác vụ mô hình hóa ngôn ngữ có mặt nạ trên tập dữ liệu này để thu được kiến thức thường thức.

Công trình của chúng tôi xây dựng trên các khung trước đây, giải quyết việc thiếu khả năng suy luận đa bước trong nghiên cứu trả lời câu hỏi thường thức không cần mẫu huấn luyện hiện tại.

--- TRANG 4 ---
3.1 Tạo QA Đa Bước Tổng Hợp
Chúng tôi tuân theo định nghĩa trong các khung trước đây và đề xuất hai phương pháp tạo QA đa bước tổng hợp trên cơ sở này, như được thể hiện trong Hình 2. Trong quá trình tạo, chúng tôi tuân theo hai tiêu chí: (1) QA đa bước tổng hợp cần có ý nghĩa thực tế, phù hợp với các kịch bản đối thoại hàng ngày và tư duy logic của con người. (2) Các yếu tố gây nhiễu nên có khả năng can thiệp mạnh để cải thiện hiệu suất suy luận của mô hình. Nó cần có mối quan hệ ngữ nghĩa với câu hỏi đồng thời cũng được phân biệt rõ ràng với câu trả lời đúng. Sau đây là các phương pháp tạo được đề xuất dựa trên những tiêu chí này.

Tạo QA Thường Thức Tổng Hợp.
QA thường thức tổng hợp được tạo ra bởi các bộ ba có mối quan hệ logic trong đồ thị kiến thức. Đây là dạng phổ biến nhất của kiến thức thường thức đa bước, thể hiện khả năng suy luận liên tục của con người. Ví dụ, khi bạn thấy từ "university", bạn sẽ nghĩ đến "library", và sau đó nghĩ đến "books". Phương pháp tạo được đề xuất của chúng tôi như sau, được chia thành hai bước. (1) Tạo câu hỏi và câu trả lời. Chính thức, cho một bộ ba (ehead1; r1; etail1), chúng tôi tìm một bộ ba khác (ehead2; r2; etail2), trong khi etail1 = ehead2 = ekey. Mỗi bộ ba sẽ được chuyển đổi thành một câu thông qua mẫu ngôn ngữ tự nhiên. Sau đó, chúng tôi tích hợp hai câu này và che dấu các thực thể được kết nối ekey trong chúng làm câu hỏi Q. Đồng thời, thực thể ekey cũng là câu trả lời đúng Ac. (2) Tạo các mẫu tiêu cực khó (yếu tố gây nhiễu). Chúng tôi tạo ra các yếu tố gây nhiễu theo các tiêu chí trên như sau. Chính thức, đối với mỗi thực thể gây nhiễu e3, để đảm bảo nó có liên quan đến câu hỏi, nó cần thỏa mãn điều kiện: (ehead1; r1; e3). Đồng thời, để đảm bảo rằng nó là một tùy chọn lỗi, nó cần thỏa mãn điều kiện: a): e3 ≠ ekey, b): đối với bất kỳ (e3; r2; etail3); etail3 ≠ etail2. Chúng tôi lấy e3 làm yếu tố gây nhiễu Ai và chọn tập yếu tố gây nhiễu {A1, ..., An} theo cách này. Cuối cùng, chúng tôi có thể có được một mẫu cặp QA thường thức tổng hợp (Q; A). Hình 2 (a) thể hiện một ví dụ về quá trình này.

Tạo QA Thường Thức Liên Kết.
QA thường thức liên kết được tạo ra bởi các thực thể có nhiều thuộc tính trong đồ thị kiến thức, thể hiện rằng khả năng tư duy của con người là đa mặt. Ví dụ, khi bạn thấy "gym", bạn nghĩ đến "basketball", "football", và các môn thể thao khác đồng thời. Chúng tôi cũng tạo QA trong hai bước. (1) Tạo câu hỏi và câu trả lời. Chính thức, cho một bộ ba (ehead1; r1; etail1), chúng tôi tìm một bộ ba khác (ehead1; r2; etail2), trong khi etail1 ≠ etail2 và ehead1 = ekey. Mỗi bộ ba sẽ được chuyển đổi thành một câu thông qua mẫu ngôn ngữ tự nhiên. Sau đó, chúng tôi tích hợp hai câu này và che dấu các thực thể được kết nối ekey trong chúng làm câu hỏi Q. Đồng thời, thực thể ekey cũng là câu trả lời đúng Ac. (2) Tạo các mẫu tiêu cực khó (yếu tố gây nhiễu). Chính thức, đối với mỗi thực thể gây nhiễu e3, để đảm bảo nó có liên quan đến câu hỏi, nó cần thỏa mãn một trong các điều kiện sau: a) (e3; r1; etail1), b) (e3; r2; etail2). Đồng thời, để đảm bảo rằng nó là một tùy chọn lỗi, đối với hai điều kiện trên, chỉ một trong số chúng có thể được thỏa mãn và cái kia không thể được thỏa mãn. Chúng tôi lấy e3 làm yếu tố gây nhiễu Ai và chọn tập yếu tố gây nhiễu {A1, ..., An} theo cách này. Cuối cùng, chúng tôi có thể có được một mẫu cặp QA thường thức liên kết (Q; A). Hình 2 (b) thể hiện một ví dụ về quá trình này.

Bằng phương pháp trên, chúng tôi tạo ra tập dữ liệu QA đa bước tổng hợp và hợp nhất nó với tập dữ liệu QA một bước từ công trình trước đây (Ma et al., 2021) cho tác vụ huấn luyện trước tiếp theo.

3.2 Huấn Luyện Trước Tiêm Nhiễm Kiến Thức
Tổng quan về phương pháp huấn luyện trước tiêm nhiễm kiến thức của chúng tôi được thể hiện trong Hình 3. Chúng tôi sử dụng tập dữ liệu QA đa bước tổng hợp để huấn luyện trước nhằm tiêm nhiễm kiến thức thường thức đa bước. Cụ thể, chúng tôi sử dụng mô hình ngôn ngữ có mặt nạ, RoBERTa (Liu et al., 2019), để huấn luyện trước. Cho một mẫu cặp QA tổng hợp (Q; A), trong đó A = {Ac, A1, ..., An}. Chúng tôi nối câu hỏi Q với mỗi tùy chọn câu trả lời Ai để xây dựng chuỗi QA đầu vào T = {TP0, TN1, ..., TNn}, trong đó TP0 = [Q; Ac] là mẫu QA tích cực và TNi = [Q; Ai] là mẫu QA tiêu cực. Đối với mỗi mẫu đầu vào, chúng tôi che dấu từng token một và tính tổng của các mất mát MLM của chúng làm điểm S như sau:

S(Ti) = (1/m) ∑(j=1 to m) log P(tj | t1, ..., tj-1, tj+1, ..., ; θ)    (1)

trong đó tj là một token từ trong chuỗi QA đầu vào Ti, m là độ dài của Ti, P là xác suất có điều kiện từ mô hình ngôn ngữ có mặt nạ được tham số hóa bởi θ.

Sau khi có được điểm của tất cả các mẫu, mục đích của chúng tôi là làm cho mẫu tích cực có điểm thấp nhất

--- TRANG 5 ---
điểm và làm cho điểm mẫu tiêu cực cao hơn mẫu tích cực. Ở đây chúng tôi sử dụng ý tưởng của học tương phản để tối ưu hóa mô hình. Để làm điều này, chúng tôi đảo ngược tất cả các giá trị và sử dụng Softmax để chuẩn hóa. Theo cách này, mẫu tích cực nên có điểm là 1, và các mẫu tiêu cực có điểm là 0. Chúng tôi sử dụng mất mát InfoNCE (van den Oord et al., 2018), một dạng của hàm mất mát tương phản, để tối ưu hóa mô hình như sau:

L = -log(exp(-S(TP)/τ) / ∑(i=0 to n) exp(-S(Ti)/τ))    (2)

trong đó τ là một siêu tham số nhiệt độ. Tổng là trên một mẫu QA tích cực và n mẫu QA tiêu cực.

Trong việc đánh giá mô hình, chúng tôi xây dựng các mẫu QA đầu vào theo cách tương tự, và tính điểm của mỗi tùy chọn câu trả lời theo Phương trình 1, và cuối cùng chọn câu trả lời đúng với điểm thấp nhất.

4 Thí nghiệm
Trong phần này, chúng tôi đánh giá khung của mình trên năm benchmark trả lời câu hỏi thường thức và tiến hành các thí nghiệm loại bỏ để xác minh tính hiệu quả của từng phần trong khung của chúng tôi.

4.1 Thiết Lập Thí Nghiệm
Khung của chúng tôi là dưới thiết lập không cần mẫu huấn luyện, tức là mô hình không thể truy cập bất kỳ dữ liệu huấn luyện chính thức nào của bất kỳ benchmark nào trong quá trình huấn luyện. Để đánh giá, chúng tôi sử dụng tập xác thực của mỗi benchmark (một số tập kiểm tra không được công khai). Vì tập xác thực không được sử dụng để điều chỉnh siêu tham số ở đây, nó có thể được coi là tập kiểm tra.

4.2 Benchmark
Chúng tôi đánh giá khung được đề xuất của mình trên năm benchmark trả lời câu hỏi để suy luận thường thức.

CommonsenseQA (CSQA) (Talmor et al., 2019): Đây là một tập dữ liệu QA câu hỏi trắc nghiệm yêu cầu kiến thức thường thức khái niệm để suy luận. Các câu hỏi và câu trả lời được tạo ra một cách nhân tạo theo các thực thể trong ConceptNet và các mối quan hệ của chúng.

Multiple Choice Temporal commonsense (MC-TACO) (Zhou et al., 2019): Tập dữ liệu này yêu cầu hiểu biết thường thức về thời gian, như thời lượng, thứ tự thời gian, thời gian điển hình, tần suất, và tính ổn định.

Abductive NLI (a-NLI) (Bhagavatula et al., 2020): Suy luận bắt buộc là suy luận đến lời giải thích hợp lý nhất. Mỗi mẫu là một sự kiện thực, có hai lời giải thích tiềm năng cho tình huống đã cho.

--- TRANG 6 ---
PhysicalIQA (PIQA) (Bisk et al., 2020): Đây là một tập dữ liệu về kiến thức thường thức vật lý (ví dụ: một cái xô có thể đựng sơn). Nó cần chọn giải pháp cho mục tiêu đã cho trong hai lựa chọn.

Wino-Grande (WG) (Sakaguchi et al., 2021): Đây là một tập dữ liệu được lấy từ đám đông với một quy trình được thiết kế cẩn thận để cải thiện quy mô và tính mạnh mẽ chống lại thiên lệch cụ thể của tập dữ liệu. Nó được công thức hóa như một tác vụ điền vào chỗ trống với các tùy chọn nhị phân.

4.3 Đồ Thị Kiến Thức
Trong khung của chúng tôi, chúng tôi sử dụng bốn KG: ATOMIC (Sap et al., 2019b), ConceptNet (Speer et al., 2017), WikiData (Vrandecic và Krötzsch, 2014) và WordNet (Miller, 1995). Mỗi KG có các loại kiến thức khác nhau. ATOMIC tập trung vào kiến thức thường thức xã hội, như nguyên nhân hoặc hậu quả của một sự kiện. ConceptNet chứa kiến thức thường thức khái niệm tổng quát, mô tả mối quan hệ giữa một thực thể khái niệm và một thực thể khái niệm khác. WikiData là một KG tổng quát được thu thập bởi Wikipedia. WordNet là một cơ sở dữ liệu từ vựng về các mối quan hệ ngữ nghĩa giữa các từ. Trong việc tạo QA một bước tổng hợp, chúng tôi tuân theo công trình của Ma et al. (2021) và sử dụng bốn KG trên để tạo. Trong việc tạo QA đa bước tổng hợp của chúng tôi, chúng tôi chọn ConceptNet làm nguồn dữ liệu để tạo, vì ConceptNet có mối quan hệ đa bước rõ ràng so với các KG khác.

4.4 Triển Khai
Khung của chúng tôi được triển khai với PyTorch và RoBERTa-Large (Liu et al., 2019) từ thư viện Hugging face Transformers. Trong các thí nghiệm của chúng tôi, chúng tôi sử dụng độ dài chuỗi tối đa 128, tỷ lệ khởi động 0.05, suy giảm trọng số 0.01, adam β1 0.9, adam β2 0.98, adam epsilon 1e-6, kích thước batch 2 trên mỗi GPU, chỉ trong 1 epoch trên tập dữ liệu QA đa bước tổng hợp. Quá trình huấn luyện được tiến hành trên 4 * NVIDIA Tesla T4 (15G) và tốn khoảng 12 giờ tổng cộng. Chúng tôi chạy các thí nghiệm của mình với các seed ngẫu nhiên khác nhau.

Trong quá trình tạo QA đa bước tổng hợp, chúng tôi tạo ra hai mẫu tiêu cực cho mỗi QA. Trong quá trình huấn luyện trước tiêm nhiễm kiến thức, chúng tôi ngẫu nhiên lấy mẫu 95% tập dữ liệu QA tổng hợp để huấn luyện trong khi 5% còn lại được sử dụng để xác thực. Nhiệt độ trong mất mát InfoNCE được đặt thành 0.7.

4.5 Baseline
Chúng tôi so sánh khung của mình với các baseline sau. Phương pháp ngẫu nhiên là ngẫu nhiên lấy nhãn làm câu trả lời và phương pháp đa số là lấy nhãn thường xuyên nhất làm câu trả lời. Chúng tôi lấy mô hình ngôn ngữ được huấn luyện trước, RoBERTa-Large (Liu et al., 2019) và GPT2-Large (Radford et al., 2019) mà không tinh chỉnh, để so sánh.

Self-talk (Shwartz et al., 2020) kết hợp ngữ cảnh và các tiền tố mẫu được định nghĩa trước, được sử dụng LM để tạo các gợi ý làm rõ, và sau đó kích thích kiến thức từ một LM khác. Cuối cùng, nó đánh giá mỗi ứng cử viên câu trả lời với văn bản gốc và kiến thức được tạo ra.

SMLM (Banerjee và Baral, 2020) là một phương pháp dựa trên việc học bộ ba kiến thức, che dấu bất kỳ một trong các bộ ba nào và sử dụng hai cái còn lại để suy luận.

RoBERTa-L(MR) (Ma et al., 2021) sử dụng KG khác nhau để tạo ra tập dữ liệu QA một bước tổng hợp và sử dụng mất mát xếp hạng biên để huấn luyện mô hình RoBERTa.

Zero-shot fusion (Adapter) (Kim et al., 2022) sử dụng KG khác nhau để tạo ra tập dữ liệu QA một bước tổng hợp riêng biệt. Nó giới thiệu một bộ điều hợp chuyên gia cho mỗi tập dữ liệu để huấn luyện, và cuối cùng hợp nhất các bộ điều hợp chuyên gia này để đánh giá.

4.6 Kết Quả Chính
Bảng 1 thể hiện kết quả đánh giá không cần mẫu huấn luyện trên năm tác vụ thường thức. Khung của chúng tôi đạt được hiệu suất tốt nhất trên tất cả các mô hình baseline. Đặc biệt, khung của chúng tôi cải thiện đáng kể độ chính xác lên ~2.8% và ~5.3% trong các benchmark CSQA và MC-TACO tương ứng.

Đáng chú ý là mặc dù khung của chúng tôi có cải thiện nhỏ trên một số benchmark so với zero-shot fusion (Adapter) (Kim et al., 2022), họ giới thiệu các bộ điều hợp chuyên gia cho mỗi KG riêng biệt, làm tăng số lượng tham số của mô hình. Và họ huấn luyện nhiều epoch hơn trên mỗi tập dữ liệu tổng hợp riêng biệt, sử dụng nhiều dữ liệu tổng hợp hơn (vì họ không lọc dữ liệu). Điều này có nghĩa là phương pháp của họ không thân thiện với việc sử dụng trong môi trường máy tính tài nguyên thấp. RoBERTa-L (MR) (Ma et al., 2021), như một phương pháp có kiến trúc mô hình giống với chúng tôi, so sánh với nó có thể phản ánh tốt hơn tính hiệu quả của khung của chúng tôi. Có thể quan sát rõ ràng rằng khung của chúng tôi được cải thiện đáng kể

--- TRANG 7 ---
so với RoBERTa-L (MR) trên nhiều benchmark. Điều này cũng phản ánh rằng khung tiêm nhiễm kiến thức đa bước được đề xuất của chúng tôi có thể cho phép mô hình học kiến thức đa bước.

4.7 Nghiên Cứu Loại Bỏ
Tạo QA Đa Bước Tổng Hợp. Để khám phá tác động của tập dữ liệu QA đa bước tổng hợp được đề xuất, chúng tôi tiến hành nhiều thí nghiệm loại bỏ. 1) w/o hard negative answer: loại bỏ các mẫu tiêu cực khó và thay thế chúng bằng các mẫu tiêu cực thông thường (ngẫu nhiên chọn các thực thể làm mẫu tiêu cực). 2) w/o compositive QA: loại bỏ phương pháp tạo QA thường thức tổng hợp. 3) w/o conjunctive QA: loại bỏ phương pháp tạo QA thường thức liên kết. 4) w/o multi-hop knowledge: loại bỏ tất cả kiến thức thường thức đa bước. Bảng 2 thể hiện kết quả nghiên cứu loại bỏ. Chúng tôi nhận thấy rằng loại bỏ các câu trả lời tiêu cực khó sẽ làm giảm hiệu suất đáng kể 1.3%, điều này chứng minh rằng phương pháp lựa chọn mẫu tiêu cực của chúng tôi là hiệu quả. Loại bỏ phương pháp tạo QA tổng hợp hoặc phương pháp tạo QA liên kết sẽ giảm độ chính xác, chứng tỏ rằng các mẫu QA được tạo ra bởi hai phương pháp này có các khía cạnh khác nhau của kiến thức đa bước. Loại bỏ tất cả kiến thức đa bước sẽ làm giảm hiệu suất đáng kể, điều này cho thấy khung của chúng tôi khắc phục được những thiếu sót của các phương pháp QA được tạo ra từ dữ liệu bộ ba một bước.

Huấn Luyện Trước Tiêm Nhiễm Kiến Thức. Chúng tôi tiến hành các thí nghiệm loại bỏ trên phương pháp huấn luyện trước tiêm nhiễm kiến thức. Chúng tôi loại bỏ mất mát InfoNCE và sử dụng mất mát biên để đánh giá. Bảng 2 cho thấy hiệu suất của mô hình giảm nhẹ, điều này cũng chứng minh tính hiệu quả của khung của chúng tôi. Đồng thời, chúng tôi huấn luyện mô hình với các nhiệt độ khác nhau và đánh giá chúng trên các benchmark như được thể hiện trong Hình 4. Nhiệt độ tương ứng với kết quả tốt nhất của hầu hết các tập dữ liệu là từ 0.6 đến 0.8, ngoại trừ WG. Chúng tôi phân tích rằng do số lượng mẫu tiêu cực mà chúng tôi chọn nhỏ (hai mẫu tiêu cực), nhiệt độ τ của chúng tôi tương đối cao. Vì tập dữ liệu WG liên quan đến nhiều kiến thức thường thức xã hội hơn và ít kiến thức thường thức khái niệm hơn, nó không nhạy cảm với kiến thức thường thức đa bước và các mẫu tiêu cực.

4.8 Nghiên Cứu Trường Hợp
Bảng 3 thể hiện một số trường hợp từ các tập dữ liệu khác nhau, trong đó chúng tôi so sánh các dự đoán của khung chúng tôi với RoBERTa (LM) (Ma et al., 2021). Chúng tôi quan sát thấy rằng RoBERTa (LM) đưa ra các lựa chọn sai trên một số tùy chọn có tính gây nhiễu cao. Ví dụ, trong tập dữ liệu CSQA, đối với câu hỏi "James wanted to find an old underground map from the 50s. Where might he look for one?" RoBERTa (LM) chỉ nắm bắt được mối quan hệ giữa "underground" và "subway station", vì vậy nó chọn câu trả lời sai. Mô hình của chúng tôi nắm bắt được mối quan hệ giữa "old", "underground map", và "library", vì vậy nó chọn câu trả lời đúng. Chúng tôi cũng thể hiện các ví dụ khác trong bảng để minh họa tính hiệu quả của khung chúng tôi. Những trường hợp này cho thấy khung của chúng tôi có thể khắc phục việc thiếu kiến thức đa bước của các mô hình trước đây bằng cách tiêm nhiễm kiến thức đa bước được tạo ra bởi tập dữ liệu QA Đa bước tổng hợp của chúng tôi.

5 Kết Luận
Trong bài báo này, chúng tôi đề xuất một khung tiêm nhiễm kiến thức thường thức đa bước mới lạ cho tác vụ trả lời câu hỏi thường thức không cần mẫu huấn luyện để giải quyết việc thiếu khả năng suy luận kiến thức đa bước trong khung không cần mẫu huấn luyện hiện tại. Cụ thể, khung này được chia thành hai bước: tạo QA đa bước tổng hợp và huấn luyện trước tiêm nhiễm kiến thức. Trong quá trình tổng hợp QA, chúng tôi khám phá các mẫu suy luận đa bước có logic ngôn ngữ học tồn tại trong KG, và đề xuất hai phương pháp tạo QA dựa trên KG. Sau đó, trong quá trình huấn luyện trước tiêm nhiễm kiến thức, chúng tôi sử dụng tập dữ liệu QA đa bước tổng hợp để huấn luyện trước với học tương phản để tiêm nhiễm kiến thức đa bước. Chúng tôi tiến hành các thí nghiệm rộng rãi trên năm benchmark trả lời câu hỏi thường thức, kết quả cho thấy khung của chúng tôi đạt được hiệu suất tốt nhất. Các thí nghiệm loại bỏ và nghiên cứu trường hợp cũng xác nhận tính hiệu quả của khung tiêm nhiễm kiến thức của chúng tôi.

Hạn chế
Mặc dù chúng tôi đã khám phá khung tiêm nhiễm kiến thức thường thức đa bước, chúng tôi chỉ sử dụng một KG, ConceptNet. Vì không có mối quan hệ đa bước rõ ràng cho các KG khác, như Atomic, chúng tôi không áp dụng chúng. Do đó, khám phá các mối quan hệ đa bước ngầm trong các KG khác có thể là công trình tương lai của chúng tôi. Ngoài ra, phương pháp tạo QA đa bước tổng hợp của chúng tôi áp dụng các thực thể và mối quan hệ của chúng trong phạm vi hai bước của một nút thực thể làm trung tâm, và không xem xét các nút còn lại ngoài hai bước. Đối với những nút này, chúng tôi có thể xem xét thiết kế các phương pháp mới để sử dụng chúng nhằm làm phong phú thêm kiến thức đa bước.

--- TRANG 8 ---
Tuyên Bố Đạo Đức
Việc trả lời câu hỏi thường thức là một lĩnh vực quan trọng trong việc trả lời câu hỏi. Các tập dữ liệu và đồ thị kiến thức được sử dụng trong công trình của chúng tôi đều là dữ liệu công khai, và các mô hình mà chúng tôi sử dụng cũng là các mô hình công khai trong lĩnh vực này. Vì khung của chúng tôi sử dụng dữ liệu từ các tập dữ liệu và KG hiện có, nó cũng có thể kế thừa các thiên lệch xã hội có trong các tập dữ liệu cơ bản này. Công trình của chúng tôi tuân thủ Quy tắc Đạo đức ACL.

Tài Liệu Tham Khảo
[Danh sách tài liệu tham khảo được giữ nguyên do chứa tên tác giả và tiêu đề tiếng Anh]

--- TRANG 9 ---
[Phần còn lại của tài liệu tham khảo tiếp tục]

# 2009.13964.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/knowledge-graph/2009.13964.pdf
# Kích thước tệp: 3137206 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
CokeBERT: Lựa chọn và Nhúng Kiến thức Theo Ngữ cảnh hướng tới
Các Mô hình Ngôn ngữ Tiền huấn luyện Nâng cao
Yusheng Su1, Xu Han1, Zhengyan Zhang1, Yankai Lin2,
Peng Li2,Zhiyuan Liu1,Jie Zhou2,Maosong Sun1
1Khoa Khoa học và Công nghệ Máy tính, Đại học Thanh Hoa, Bắc Kinh, Trung Quốc
Viện Trí tuệ Nhân tạo, Đại học Thanh Hoa, Bắc Kinh, Trung Quốc
Phòng thí nghiệm Khóa của Nhà nước về Công nghệ và Hệ thống Thông minh, Đại học Thanh Hoa, Bắc Kinh, Trung Quốc
2Trung tâm Nhận dạng Mẫu, WeChat AI, Tencent Inc.
fsuys19,hanxu17 g@mails.tsinghua.edu.cn,
Tóm tắt
Một số nỗ lực gần đây đã được dành để nâng cao các mô hình ngôn ngữ tiền huấn luyện (PLMs) bằng cách sử dụng kiến thức không đồng nhất bổ sung trong các đồ thị kiến thức (KGs), và đã đạt được những cải thiện nhất quán trên các nhiệm vụ NLP dựa trên kiến thức khác nhau. Tuy nhiên, hầu hết các PLMs tăng cường kiến thức này nhúng các đồ thị con tĩnh của KGs ("ngữ cảnh kiến thức"), bất kể việc kiến thức cần thiết bởi PLMs có thể thay đổi động theo văn bản cụ thể ("ngữ cảnh văn bản"). Trong bài báo này, chúng tôi đề xuất một khung mới có tên Coke để động lựa chọn kiến thức theo ngữ cảnh và nhúng ngữ cảnh kiến thức theo ngữ cảnh văn bản cho PLMs, có thể tránh ảnh hưởng của kiến thức dư thừa và mơ hồ trong KGs không thể khớp với văn bản đầu vào. Kết quả thực nghiệm của chúng tôi cho thấy Coke vượt trội hơn các phương pháp cơ sở khác nhau trên các nhiệm vụ NLP dựa trên kiến thức điển hình, chỉ ra hiệu quả của việc sử dụng ngữ cảnh kiến thức động cho hiểu ngôn ngữ. Bên cạnh những cải thiện hiệu suất, kiến thức được lựa chọn động trong Coke có thể mô tả ngữ nghĩa của kiến thức liên quan đến văn bản theo hình thức có thể giải thích được hơn so với các PLMs thông thường. Mã nguồn và tập dữ liệu của chúng tôi sẽ có sẵn để cung cấp thêm chi tiết cho Coke.

1 Giới thiệu
Các mô hình ngôn ngữ tiền huấn luyện (PLMs) như BERT (Devlin et al., 2019) và RoBERTa (Liu et al., 2019) đã đạt được hiệu suất tốt nhất trên một loạt các nhiệm vụ xử lý ngôn ngữ tự nhiên (NLP). Vì một số nghiên cứu (Poerner et al., 2019) cho thấy rằng các PLMs này vẫn gặp khó khăn trong việc học kiến thức sự thật, các nỗ lực gần đây tích cực (Lauscher et al., 2019; Yoav et al., 2019; Yu et al., 2019; Wang et al., 2019; Zhang et al., 2019; Peters et al., 2019; He et al., 2019; Liu et al., 2020) chỉ ra đóng góp ngang nhau

Steph Curry và Klay Thompson dẫn dắt Warriors đến chức vô địch NBA
Steph CurryKlay Thompson
RileyDavidson CollegeWashington State UniversityWarriorsChơi choChơi choTốt nghiệp từTốt nghiệp từCon gái của Steph CurryKlay ThompsonĐồng đội
Tầm quan trọng thấpTầm quan trọng caoVăn bảnKGHình 1: Ví dụ về việc nắm bắt ngữ cảnh kiến thức từ một KG và kết hợp chúng để hiểu ngôn ngữ. Các kích thước khác nhau của vòng tròn thể hiện tầm quan trọng khác nhau của thực thể để hiểu câu đã cho.

do đó đã được dành để tận dụng kiến thức không đồng nhất phong phú trong các đồ thị kiến thức (KGs) để nâng cao PLMs.

Một quá trình lý tưởng để tiêm kiến thức sự thật vào PLMs là đầu tiên xác định các thực thể được đề cập1 trong văn bản đầu vào ("ngữ cảnh văn bản"), sau đó động lựa chọn các đồ thị con ("ngữ cảnh kiến thức") tập trung vào các thực thể được đề cập này từ KGs, và cuối cùng nhúng ngữ cảnh kiến thức đã chọn cho PLMs. Trực quan, ngữ cảnh kiến thức góp phần vào việc hiểu ngôn ngữ tốt hơn ở một mặt, phục vụ như một sự bổ sung hiệu quả cho ngữ cảnh văn bản. Ví dụ, cho hai thực thể Steph Curry và Klay Thompson trong Hình 1, chúng ta có thể suy ra rằng họ chơi cho cùng một đội bóng rổ, điều này không được mô tả rõ ràng trong câu đã cho. Mặt khác, không phải tất cả kiến thức trong KGs đều liên quan đến ngữ cảnh văn bản, ví dụ, sự thật (Riley, Con gái của, Steph Curry) không có tác động tích cực đến việc hiểu câu đã cho.

Chúng tôi lập luận rằng việc động lựa chọn ngữ cảnh kiến thức phù hợp có thể khớp với ngữ cảnh văn bản cụ thể để nâng cao PLMs là có ý nghĩa. Tuy

1Những từ hoặc cụm từ trong văn bản tương ứng với các thực thể nhất định trong KGs thường được gọi là "đề cập thực thể".arXiv:2009.13964v5 [cs.CL] 5 Apr 2023

--- TRANG 2 ---
nhiên, hầu hết ngữ cảnh kiến thức được sử dụng trong các PLMs tăng cường kiến thức hiện tại không khớp cao với ngữ cảnh văn bản: (1) ERNIE (Zhang et al., 2019) chỉ sử dụng các thực thể được đề cập trong văn bản làm ngữ cảnh kiến thức và chỉ tiêm các nhúng của các thực thể này vào PLMs, bỏ qua các láng giềng thông tin trong KGs; (2) KnowBert (Peters et al., 2019), K-BERT (Liu et al., 2020) và K-ADAPTER (Wang et al., 2020) xem xét nhiều thông tin hơn làm ngữ cảnh kiến thức so với ERNIE (ví dụ, thuộc tính thực thể trong KGs), nhưng ngữ cảnh kiến thức của họ vẫn tĩnh và không thể thay đổi động theo ngữ cảnh văn bản. Như chúng tôi đã đề cập trước đó, không phải tất cả thông tin trong ngữ cảnh kiến thức tĩnh đều có thể khớp với ngữ cảnh văn bản, và kiến thức can thiệp với thông tin dư thừa và mơ hồ có thể can thiệp việc hiểu ngữ nghĩa. Do đó, việc làm thế nào để động lựa chọn và nhúng ngữ cảnh kiến thức theo ngữ cảnh văn bản cho PLMs vẫn còn là một thách thức.

Để giảm thiểu vấn đề này, chúng tôi đề xuất một khung mới có tên Coke để động lựa chọn ngữ cảnh kiến thức khớp với ngữ cảnh văn bản và nhúng ngữ cảnh động để nâng cao PLMs: (1) Để động lựa chọn ngữ cảnh kiến thức, theo ngữ cảnh văn bản, chúng tôi đề xuất một mạng nơ-ron đồ thị hướng ngữ nghĩa mới (S-GNN). Cho một thực thể được đề cập trong ngữ cảnh văn bản, S-GNN tận dụng cơ chế chú ý để lọc bỏ thông tin KG không liên quan bằng cách gán điểm cho các láng giềng (1-hop, 2-hop, v.v.) và quan hệ giữa các thực thể dựa trên ngữ cảnh văn bản. Điểm số có thể cân nhắc mức độ thông tin trong KGs khớp với ngữ cảnh văn bản và giúp Coke động lựa chọn một đồ thị con phù hợp làm ngữ cảnh kiến thức của đề cập thực thể đã cho. (2) Để động nhúng ngữ cảnh kiến thức, cho một thực thể được đề cập, S-GNN tính toán biểu diễn của nó có điều kiện trên cả nhúng thực thể tiền huấn luyện của nó và thông tin được tổng hợp từ đồ thị con ngữ cảnh đã chọn theo cách đệ quy, làm cho Coke nhận thức được cả thông tin KG toàn cục và cục bộ và nắm bắt thông tin liên quan đến văn bản. (3) Bằng cách hợp nhất các nhúng của ngữ cảnh kiến thức động cho PLMs với các chiến lược huấn luyện và thích ứng cụ thể, Coke cải thiện hiểu ngôn ngữ và có lợi cho các ứng dụng downstream.

Theo các công trình hiện tại, chúng tôi tiến hành thí nghiệm trên bốn tập dữ liệu cho hai nhiệm vụ dựa trên kiến thức điển hình, tức là phân loại thực thể và phân loại quan hệ. Kết quả thí nghiệm cho thấy Coke vượt trội hơn các phương pháp cơ sở khác nhau, chỉ ra hiệu quả của việc động lựa chọn và nhúng ngữ cảnh kiến thức cho PLMs. Hơn nữa, một số phân tích định tính cũng cho thấy rằng, so với các PLMs tăng cường kiến thức hiện đại, mô hình của chúng tôi không chỉ đạt được kết quả cạnh tranh mà còn cung cấp một cách tiếp cận có thể giải thích được hơn để mô tả các từ cụ thể dựa trên ngữ cảnh kiến thức động của chúng.

2 Công trình Liên quan
Trực quan, hai loại ngữ cảnh được liên quan đến việc hiểu ngôn ngữ: (1) thông tin ngữ nghĩa của văn bản (ngữ cảnh văn bản), và (2) kiến thức sự thật liên quan đến văn bản (ngữ cảnh kiến thức). Các PLMs điển hình tập trung vào việc nắm bắt thông tin từ ngữ cảnh văn bản, như ELMO (Peters et al., 2018), GPT (Radford et al., 2018), BERT (Devlin et al., 2019), XLNET (Yang et al., 2019), và RoBERTa (Liu et al., 2019). Để cho phép PLMs hiểu ngữ cảnh kiến thức tốt hơn, các nỗ lực tích cực đã được dành để tiêm kiến thức sự thật khác nhau của KGs vào PLMs.

ERNIE (Zhang et al., 2019) liên kết các đề cập thực thể trong ngữ cảnh văn bản với các thực thể tương ứng của chúng trong KGs và sau đó tiêm các nhúng tiền huấn luyện của các thực thể tương ứng vào PLMs. Mặc dù ERNIE đã cho thấy tính khả thi và hiệu quả của việc hợp nhất các nhúng kiến thức để nâng cao PLMs, nó vẫn không xem xét các láng giềng thông tin của các thực thể.

Để đạt mục tiêu này, các mô hình khác nhau đã được đề xuất để tiếp tục kết hợp phạm vi kiến thức thông tin rộng hơn. KnowBert (Peters et al., 2019) và KRL (He et al., 2019) sử dụng các cơ chế chú ý để học các nhúng thực thể thông tin hơn dựa trên các đồ thị con liên quan đến thực thể. Tuy nhiên, việc tính toán các nhúng thực thể độc lập với ngữ cảnh văn bản. K-BERT (Liu et al., 2020) heuristically chuyển đổi ngữ cảnh văn bản và các đồ thị con liên quan đến thực thể thành các chuỗi đầu vào thống nhất, và tận dụng một Transformer (Vaswani et al., 2017) với cơ chế chú ý được thiết kế đặc biệt để mã hóa các chuỗi. Thật không may, việc phương pháp heuristic trong K-BERT chuyển đổi các láng giềng bậc hai hoặc cao hơn liên quan đến ngữ cảnh văn bản thành một chuỗi mà không mất thông tin cấu trúc đồ thị không phải là tầm thường. K-ADAPTER (Wang et al., 2020) đề xuất các khung biến thể để tiêm kiến thức sự thật trong các miền khác nhau, nhưng vẫn gặp phải vấn đề tương tự như K-BERT. Mặc dù hầu hết các PLMs tăng cường kiến thức hiện tại

--- TRANG 3 ---
nhận thức được việc sử dụng cả ngữ cảnh văn bản và ngữ cảnh kiến thức, ngữ cảnh kiến thức của chúng không thể thay đổi với ngữ cảnh văn bản, như ERNIE sử dụng các thực thể đơn, KRL và KnowBert nhúng các đồ thị con độc lập với ngữ cảnh văn bản, K-BERT và K-ADAPTER sử dụng các đồ thị con cố định. Ngược lại, mô hình Coke được đề xuất của chúng tôi có thể tận dụng các đồ thị con động có kích thước tùy ý làm ngữ cảnh kiến thức theo ngữ cảnh văn bản.

Cũng có một số phương pháp PLM để nắm bắt kiến thức chỉ từ ngữ cảnh văn bản. SpanBERT (Mandar et al., 2019) và ERNIE 1.0-Baidu (Yu et al., 2019) đề xuất dự đoán các khoảng có độ dài biến thiên được che hoặc đề cập thực thể để khuyến khích PLMs học các cụm từ nhiều token. WKLM (Xiong et al., 2019) được huấn luyện để phân biệt liệu một đề cập thực thể đã được thay thế bằng tên của các thực thể khác có cùng loại để học các loại thực thể. LIBERT (Lauscher et al., 2019) và SenseBERT (Yoav et al., 2019) mở rộng PLMs để dự đoán quan hệ từ (ví dụ, từ đồng nghĩa và từ trên-dưới) và siêu cảm giác từ tương ứng để tiêm kiến thức từ vựng-ngữ nghĩa. Hơn nữa, cũng có các nỗ lực về việc truyền kiến thức liên tục (Yu et al., 2020; Wang et al., 2020). Mặc dù các mô hình này không sử dụng ngữ cảnh kiến thức bổ sung để hiểu kiến thức sự thật, chúng bổ sung cho công việc của chúng tôi và có thể được sử dụng cùng nhau hướng tới PLMs tốt hơn.

3 Phương pháp luận
Như được hiển thị trong Hình 2, Coke bao gồm ba mô-đun:

(1) Bộ mã hóa văn bản tính toán các nhúng cho văn bản đầu vào, tức là ngữ cảnh văn bản;

(2) Bộ mã hóa ngữ cảnh kiến thức động đầu tiên động lựa chọn ngữ cảnh kiến thức theo ngữ cảnh văn bản, và sau đó tính toán các nhúng kiến thức theo ngữ cảnh có điều kiện trên cả ngữ cảnh văn bản và ngữ cảnh KG;

(3) Bộ mã hóa hợp nhất kiến thức hợp nhất cả ngữ cảnh văn bản và các nhúng ngữ cảnh kiến thức động để hiểu ngôn ngữ tốt hơn. Trong phần này, chúng tôi sẽ đầu tiên đưa ra các ký hiệu và sau đó trình bày ba mô-đun một cách chi tiết.

3.1 Ký hiệu
Một KG được ký hiệu bởi G = {(h; r; t) | h, t ∈ E; r ∈ R}, trong đó E và R là tập hợp các thực thể và quan hệ tương ứng. Đối với mỗi sự thật (h; r; t) ∈ G, nó chỉ ra rằng có một quan hệ r giữa thực thể đầu h và thực thể đuôi t. Cho một chuỗi token S = {wj}^N_{j=1} có độ dài N, một số token trong chuỗi có thể tương ứng với các thực thể nhất định trong E, chúng tôi đặt tên cho các token này là "đề cập thực thể" và ký hiệu các thực thể được đề cập của chúng trong KGs là {ej}^M_{j=1}, trong đó M là số lượng thực thể được đề cập².

3.2 Bộ mã hóa văn bản
Tương tự như các PLMs tăng cường kiến thức hiện tại, Coke tận dụng một bộ mã hóa Transformer hai chiều L-lớp (Vaswani et al., 2017; Devlin et al., 2019) để nhúng văn bản đầu vào (tokens) S = {wj}^N_{j=1} và thu được các biểu diễn ngữ cảnh văn bản của nó, được ký hiệu là T-Encoder(),

{ŵj}^N_{j=1} = T-Encoder({wj}^N_{j=1}). (1)

Vì T-Encoder() giống như được sử dụng trong BERT, chúng tôi giới thiệu độc giả đến bài báo gốc (Devlin et al., 2019) để biết thêm chi tiết.

3.3 Bộ mã hóa ngữ cảnh kiến thức động

Xây dựng ngữ cảnh kiến thức thô Vì KGs thường có quy mô lớn, chúng tôi đầu tiên xây dựng ngữ cảnh kiến thức thô để có hiệu quả tính toán. Sau đó chúng tôi động lựa chọn và nhúng ngữ cảnh kiến thức phù hợp có thể khớp với ngữ cảnh văn bản. Cụ thể, cho một thực thể được đề cập m ∈ E được đề cập bởi văn bản đầu vào S = {wj}^N_{j=1}, chúng tôi định nghĩa ngữ cảnh kiến thức thô Gm của nó là một đồ thị con của G tập trung vào m. Các thực thể của Gm cách xa nhất K-hop từ m. Chính thức, chúng tôi định nghĩa tập hợp thực thể cách 0-hop là E^0_m = {m}. Sau đó tập hợp thực thể cách i-hop E^i_m có thể được định nghĩa đệ quy là

→E^i_m = {t | h ∈ E^{i-1}_m ∧ t ∉ ⋃^{i-1}_{j=0} E^j_m; (h; r; t) ∈ G};

←E^i_m = {h | t ∈ E^{i-1}_m ∧ h ∉ ⋃^{i-1}_{j=0} E^j_m; (h; r; t) ∈ G};

E^i_m = →E^i_m ∪ ←E^i_m. (2)

Trực quan, tất cả các thực thể trong E^i_m (cả thực thể đầu hoặc đuôi) chỉ có quan hệ với các thực thể trong E^{i-1}_m. Sau đó, ngữ cảnh kiến thức thô Gm và tập hợp thực thể Em của nó có thể được định nghĩa là

Em = ⋃^K_{i=0} E^i_m

Gm = {(h; r; t) | h ∈ Em ∧ t ∈ Em; (h; r; t) ∈ G}. (3)

²Thông thường, M ≠ N vì một thực thể có thể tương ứng với nhiều token khác nhau. Trong công việc này, chúng tôi sử dụng toolkit TAGME để xác định các thực thể được đề cập.

--- TRANG 4 ---
Kx DK-Encoder  Px K-Encoder  Steph Curry và Klay Thompson dẫn dắt Warriors đến chức vô địch NBA
Đầu ra…
…Chơi cho
Steph CurryWarriors
Con gái của 
RileySteph Curry
Warriors
Riley
Clay
S.F
C.A
N.C
Riley
WarriorsChơi choĐịnh vịSống tạiđã Sinh ra tại…
…
…
…Steph CurryRileyWarriors………………Nx T-Encoder  
Lựa chọn và Nhúng ngữ cảnh kiến thứcXây dựng ngữ cảnh kiến thức thô1-hop2-hopD
Steph Curry và Klay Thompson dẫn dắt Warriors đến chức vô địch NBAĐầu vào cho các nhiệm vụ NLP thông thường:StephCurryváKlay[CLS]ThompsonĐầu vào cho các nhiệm vụ Phân loại thực thể:váKlay[CLS]Thompson[ENT]StephCurry[ENT]Đầu vào cho các nhiệm vụ Phân loại quan hệ:váKlay[CLS]Thompson[HD]StephCurry[HD][TL][SEP][SEP][SEP][TL][CLS][ENT][HD][TL]Các nhiệm vụ NLP thông thườngPhân loại thực thểPhân loại quan hệ………EHình 2: (a) Phần trên là khung tổng thể của Coke và minh họa cách tạo ra các biểu diễn thực thể.
(b) Phần dưới là ví dụ về việc chèn các token đặc biệt vào chuỗi đầu vào cho các nhiệm vụ cụ thể trong quá trình tinh chỉnh.

Lựa chọn và Nhúng ngữ cảnh kiến thức
Để động lựa chọn các đặc trưng thông tin trong Gm và nhúng các đặc trưng này cho PLMs, chúng tôi đề xuất một mạng nơ-ron đồ thị hướng ngữ nghĩa (S-GNN). Đối với mỗi thực thể trong Gm, tức là e ∈ Em, chúng tôi khởi tạo các đặc trưng đầu vào của nó cho S-GNN bằng nhúng được tiền huấn luyện bởi TransE (Bordes et al., 2013) (Các mô hình nhúng kiến thức khác cũng có thể cung cấp các nhúng tiền huấn luyện cho S-GNN), và đặt tên cho các đặc trưng được khởi tạo là e⁰.

Để hoàn toàn chuyển giao thông tin cấu trúc và kiến thức giữa các thực thể trong Gm, S-GNN bao gồm một số lớp ẩn để tổng hợp thông tin theo cấu trúc của Gm. Tại lớp thứ i, cho một thực thể e ∈ Em, S-GNN tổng hợp tất cả thông tin từ thực thể láng giềng n và r của nó trong Gm,

h^i_{n→e} = {
    W^i[n + r; n^{i-1}]; (n; r; e) ∈ Gm
    W^i[n + r; n^{i-1}]; (e; r; n) ∈ Gm,
}                                                    (4)

trong đó n^{i-1} là nhúng của n tại lớp i-1, n và r là các nhúng thực thể và quan hệ tương ứng được tiền huấn luyện bởi TransE, W^i là một ma trận tuyến tính có thể học được, và [;] ký hiệu phép nối ngang của các vector. Sau đó nhúng của e tại lớp thứ i có thể được tính toán là

e^i = f^i({h^i_{n→e} | n ∈ Ne}),                    (5)

trong đó Ne là tập hợp láng giềng của e, f^i() là hàm để tổng hợp thông tin tại lớp thứ i và sẽ được giới thiệu chi tiết tiếp theo.

Vì không phải tất cả thông tin trong ngữ cảnh kiến thức thô Gm đều hữu ích để hiểu các token văn bản đầu vào S = {wj}^N_{j=1}, chúng tôi thiết kế một cơ chế chú ý ngữ nghĩa đặc biệt như hàm f^i trong Eq. (5) để lọc bỏ thông tin không liên quan và tổng hợp thông tin cần thiết. Cơ chế chú ý hàm f có thể được ký hiệu chính thức như sau,

f^i({h^i_{ê→e} | ê ∈ Ne}) = ∑_{ê∈Ne} exp(k^T_ê q) / ∑_{ẽ∈Ne} exp(k^T_ẽ q) h^i_{ê→e},    (6)

trong đó q, kn được gọi là các vector truy vấn và khóa tương ứng.

Để động lựa chọn thông tin theo ngữ cảnh văn bản, vector truy vấn q đến từ nhúng của văn bản đầu vào (tokens):

q = σ(W^i_c s + b^i_c),                             (7)

trong đó σ = tanh(), W^i_c và b^i_c là ma trận tuyến tính có thể học được và vector bias tương ứng cho vector truy vấn tại lớp thứ i, s là nhúng ngữ nghĩa toàn bộ của văn bản đầu vào (tokens). Đặc biệt, theo BERT (Devlin et al., 2019), chúng tôi đặt một

--- TRANG 5 ---
token đặc biệt [CLS] ở đầu chuỗi đầu vào, và s là nhúng đầu ra của [CLS] được tính toán bởi Eq. (1).

Vector khóa kn dựa trên nhúng của quan hệ giữa thực thể e và thực thể láng giềng n của nó, và được tính toán là

kn = {
    σ(W^i_f r + b^i_f); (e; r; n) ∈ Gm
    σ(W^i_f (-r) + b^i_f); (n; r; e) ∈ Gm,
}                                                    (8)

trong đó W^i_f và b^i_f là ma trận tuyến tính có thể học được và vector bias tương ứng cho vector khóa tại lớp thứ i. Hai triple với thực thể đầu và đuôi được hoán đổi sẽ nhận được các vector khóa ngược.

Tóm lại, S-GNN sử dụng ngữ cảnh văn bản để điều chỉnh trọng số của việc tổng hợp đặc trưng, và cuối cùng lựa chọn và nhúng kiến thức liên quan đến ngữ cảnh văn bản vào các nhúng cho PLMs. Do đó, cho thực thể được đề cập m, nhúng đầu ra của m tại lớp cuối cùng của S-GNN là nhúng cuối cùng của nó được tính toán bởi ngữ cảnh kiến thức động của nó. Để đơn giản, cho văn bản đầu vào (tokens) {wj}^N_{j=1} và các thực thể được đề cập {ej}^M_{j=1}, toàn bộ tính toán để đạt được các nhúng ngữ cảnh kiến thức động được ký hiệu là,

{êj}^M_{j=1} = DK-Encoder({ej}^M_{j=1}, {wj}^N_{j=1}).    (9)

3.4 Bộ mã hóa hợp nhất kiến thức
Bộ mã hóa hợp nhất kiến thức nhằm hợp nhất thông tin của nhúng thực thể theo ngữ cảnh {êj}^M_{j=1} và nhúng văn bản (tokens) {ŵj}^N_{j=1}. Chúng tôi tận dụng bộ mã hóa K-Encoder() tương tự như (Zhang et al., 2019) để phục vụ mục đích,

{w^o_j}^N_{j=1}, {e^o_j}^M_{j=1} = 
K-Encoder({ŵj}^N_{j=1}, {êj}^M_{j=1})                  (10)

Chúng tôi giới thiệu độc giả đến (Zhang et al., 2019) để biết thêm chi tiết. Nói một cách đại khái, K-Encoder() bao gồm P aggregator. Như được hiển thị trong Hình 2, trong mỗi aggregator, có hai chú ý tự đa đầu tiêm văn bản (tokens) và các nhúng kiến thức theo ngữ cảnh tương ứng, và một perceptron đa lớp (MLP) hợp nhất hai đặc trưng không đồng nhất.

3.5 Chi tiết huấn luyện
Chiến lược tiền huấn luyện Để kết hợp các nhúng kiến thức vào hiểu ngôn ngữ, chúng tôi ngẫu nhiên che các căn chỉnh token-thực thể và để mô hình học dự đoán tất cả các thực thể tương ứng cho các token này bằng cách che các căn chỉnh của chúng. Chúng tôi gọi đây là một bộ tự mã hóa thực thể khử nhiễu (dEA), đây là một trong các nhiệm vụ tiền huấn luyện cho các PLMs tăng cường kiến thức hiện tại (Zhang et al., 2019).

Bên cạnh đó, chúng tôi chọn BERT_BASE (Devlin et al., 2019), RoBERTa_BASE (Liu et al., 2019), và RoBERTa_LARGE (Liu et al., 2019) làm các mô hình cơ sở của chúng tôi. Xem xét rằng các mô hình cơ sở của chúng tôi ban đầu được tiền huấn luyện bởi các nhiệm vụ tiền huấn luyện khác nhau, chúng tôi có hai mục tiêu huấn luyện khác nhau cho chúng.

Đối với CokeBERT_BASE, dựa trên BERT_BASE, mục tiêu huấn luyện có thể được mô tả là:

L = L_MLM + L_NSP + L_dEA,                          (11)

trong đó L_MLM và L_NSP là các hàm mất mát cho mô hình ngôn ngữ có che và dự đoán câu tiếp theo tương ứng. Mất mát bộ tự mã hóa thực thể khử nhiễu (dEA) là L_dEA.

Đối với CokeRoBERTa_BASE và CokeRoBERTa_LARGE, được đại diện dựa trên RoBERTa_BASE và RoBERTa_LARGE, mục tiêu huấn luyện của chúng có thể được mô tả là:

L = L_MLM + L_dEA,                                  (12)

trong đó mất mát dự đoán câu được loại bỏ.

Tinh chỉnh cho các nhiệm vụ downstream Coke áp dụng quy trình tinh chỉnh tương tự như BERT và lấy nhúng đầu ra cuối cùng của token đầu tiên [CLS] cho các nhiệm vụ NLP thông thường khác nhau. Tương tự như các PLMs tăng cường kiến thức trước đó, đối với các nhiệm vụ dựa trên kiến thức như phân loại thực thể và phân loại quan hệ, chúng tôi áp dụng các quy trình tinh chỉnh cụ thể. Như được hiển thị trong Hình 2, để giúp Coke kết hợp thông tin ngữ cảnh và đề cập thực thể một cách chú ý, chúng tôi sửa đổi chuỗi đầu vào với các dấu hiệu đề cập. Chúng tôi chú ý token ở phía trước của đề cập thực thể là [ENT] và sau đó sử dụng nhúng đầu ra cuối cùng của [ENT] cho nhiệm vụ phân loại thực thể. Đối với nhiệm vụ phân loại quan hệ, chúng tôi chèn các token [HD] và [TL] cho các thực thể đầu và thực thể đuôi tương ứng, và nối biểu diễn [HD] và biểu diễn [TL] làm biểu diễn cuối cùng (Baldini Soares et al., 2019) cho nhiệm vụ.

4 Thí nghiệm
Trong các thí nghiệm, chúng tôi đầu tiên giới thiệu tập dữ liệu huấn luyện và các chi tiết huấn luyện khác của mô hình chúng tôi. Sau đó, chúng tôi đưa ra một phân tích thực nghiệm để cho thấy

--- TRANG 6 ---
Tập dữ liệu Train Dev Test Type Rel
FIGER 2,000,000 10,000 563 113 -
Open Entity 2,000 2,000 2,000 6 -
FewRel 8,000 16,000 16,000 - 80
TACRED 68,124 22,631 15,509 - 42

Bảng 1: Thống kê của các tập dữ liệu FIGER, Open Entity, FewRel, và TACRED.

tính hữu ích của ngữ cảnh kiến thức được lựa chọn. Sau đó chúng tôi so sánh Coke với một số phương pháp cơ sở mạnh trong hai nhiệm vụ dựa trên kiến thức điển hình bao gồm phân loại thực thể và phân loại quan hệ. Cuối cùng, chúng tôi thực hiện một nghiên cứu ablation để cho thấy hiệu quả của bộ mã hóa ngữ cảnh kiến thức động của chúng tôi.

4.1 Tập dữ liệu huấn luyện
Chúng tôi sử dụng Wikipedia tiếng Anh³ làm kho dữ liệu tiền huấn luyện của chúng tôi và căn chỉnh các đề cập thực thể với Wikidata bằng công cụ liên kết thực thể được sử dụng rộng rãi TAGME (Ferragina và Scaiella, 2010). Có gần 4,500M từ con và 140M thực thể trong kho dữ liệu tiền huấn luyện và chúng tôi lấy mẫu 24,267,796 triple sự thật, bao gồm 5,040,986 thực thể trong Wikidata. Chúng tôi tiến hành các thí nghiệm của mình trên các tập dữ liệu sau: FIGER, Open Entity, FewRel, và TACRED. Thống kê của các tập dữ liệu này được hiển thị trong Bảng 1. Bên cạnh đó, chúng tôi sử dụng các nhúng kiến thức của WikiData được phát hành bởi (Zhang et al., 2019).

4.2 Cài đặt thí nghiệm
Huấn luyện và Cài đặt tham số Trong các thí nghiệm, chúng tôi chọn BERT_BASE (Devlin et al., 2019), RoBERTa_BASE và RoBERTa_LARGE (Liu et al., 2019) làm các mô hình cơ sở của chúng tôi. Để giảm chi phí huấn luyện từ đầu, chúng tôi áp dụng các tham số đã được phát hành của các mô hình này để khởi tạo bộ mã hóa văn bản của chúng tôi và phần còn lại của các tham số của Coke đều được khởi tạo ngẫu nhiên.

Để tối ưu hóa, chúng tôi đặt tốc độ học là 5×10⁻⁵, độ dài chuỗi tối đa là 256, kích thước batch là 32, và các cài đặt còn lại chủ yếu theo các PLMs gốc. Để tinh chỉnh, chúng tôi sử dụng cùng các tham số như tiền huấn luyện ngoại trừ kích thước batch và tốc độ học. Trong tất cả các nhiệm vụ downstream, chúng tôi chọn kích thước batch từ {16,32,64}, tốc độ học là 2×10⁻⁵, số epoch từ {5,6,7,8,9,10}. Các dải giá trị sau đều hoạt động tốt. Bên cạnh đó, để ngăn Coke khỏi overfitting trong FIGER, chúng tôi sử dụng kích thước batch lớn

³https://en.wikipedia.org/

1024. Chúng tôi giới thiệu thêm chi tiết về huấn luyện và cài đặt siêu tham số trong Phụ lục của chúng tôi.

Phương pháp cơ sở Chúng tôi chia các mô hình cơ sở thành ba nhóm:
Các mô hình dựa trên BERT_BASE, các mô hình dựa trên RoBERTa_BASE, và các mô hình dựa trên RoBERTa_LARGE. Vì sự công bằng, tất cả các mô hình chỉ kết hợp kiến thức sự thật từ Wikidata. Đối với các PLMs tăng cường kiến thức như ERNIE, KnowBert, và K-BERT, chúng tôi tái thực hiện chúng hoặc sử dụng mã đã phát hành của họ cho các thí nghiệm của chúng tôi, và báo cáo các kết quả có thể khớp với kết quả của họ trong các bài báo gốc. Vì K-ADAPTER tương tự như K-BERT và không có mã nào được phát hành, chúng tôi do đó trực tiếp so sánh với K-BERT thay vì K-ADAPTER.

4.3 Phân tích thực nghiệm để động lựa chọn ngữ cảnh kiến thức
Để chứng minh Coke có thể nắm bắt thông tin hữu ích từ KGs, chúng tôi thiết kế một thí nghiệm định tính và định lượng để đánh giá Coke.

Trong thí nghiệm định tính, cho cùng các đề cập thực thể trong ngữ cảnh khác nhau, chúng tôi áp dụng PLMs để lựa chọn các triple 1-hop liên quan đến văn bản ("ngữ cảnh kiến thức 1-hop") từ Wikidata, tương tự như Eq. (6) không có phép tổng. Cụ thể hơn, chúng tôi áp dụng [CLS] của văn bản đầu vào (tokens) được tính toán bởi các PLMs này để chú ý đến mỗi triple láng giềng của các đề cập thực thể.

Như được hiển thị trong Bảng 2, khi cho câu ":::Bill Gates và Mark Zuckerberg bỏ học Harvard:::" chỉ ra quan hệ cựu sinh viên giữa Mark Zuckerberg và Bill Gates, mô hình của chúng tôi chú ý nhiều hơn đến kiến thức sự thật về giáo dục của họ. Nhưng khi cho câu "Bill Gates và Mark Zuckerberg đang làm việc cùng nhau :::" chỉ ra sự hợp tác giữa Mark Zuckerberg và Bill Gates, kiến thức sự thật về các doanh nghiệp của họ được mô hình của chúng tôi xem xét. Rõ ràng, chúng ta có thể thấy điểm số tầm quan trọng của các triple được chú ý có thể giải thích được và có thể giúp chúng ta hiểu ngữ nghĩa một cách rõ ràng hơn.

Trong thí nghiệm định lượng, chúng tôi chú thích các tập kiểm tra của FewRel và TACRED. Cho một mẫu, bao gồm ngữ cảnh và các đề cập thực thể tương ứng, chúng tôi chú thích thủ công các triple 1-hop của nó bằng cách đánh giá sự liên quan giữa ngữ cảnh và triple. Cuối cùng, chúng tôi trích xuất 15981 mẫu từ FewRel và 5684 mẫu từ TACRED. Bằng cách xếp hạng điểm số tầm quan trọng của tất cả các triple cho một đề cập thực thể và đặt một ngưỡng, chúng ta có thể thu được các triple dương

--- TRANG 7 ---
Văn bản:[CLS] Cả đồng sáng lập Microsoft Bill Gates và đồng sáng lập Facebook Mark Zuckerberg đều bỏ học Harvard và bắt đầu xây dựng công ty của họ vào cùng thời điểm.
Triple sự thật : Mark Zuckerberg, Bill Gates, cựu sinh viên
Thực thể h: Mark Zuckerberg
Tầm quan trọng Thực thể t Quan hệ
19% Đại học Harvard được giáo dục tại
19% Học viện Phillips Exeter được giáo dục tại
19% Trường trung học Ardsley được giáo dục tại
10% Facebook CEO của
10% Giám đốc điều hành vị trí giữ
6% Doanh nhân nghề nghiệp
6% Nhà khoa học máy tính nghề nghiệp
6% Palo Alto, California cư trú
3% White Plains, New York nơi sinh
2% Tiếng Trung phổ thông ngôn ngữ nói
Thực thể h: Bill Gates
Tầm quan trọng Thực thể t Quan hệ
35% Đại học Harvard được giáo dục tại
11% Microsoft CEO của
11% Giám đốc điều hành vị trí giữ
9% Học viện Khoa học và Nghệ thuật Mỹ thành viên của
9% Học viện Kỹ thuật Quốc gia thành viên của
6% Nhà khoa học máy tính nghề nghiệp
6% Nhà đầu tư nghề nghiệp
6% Doanh nhân nghề nghiệp
4% Quỹ Bill&Melinda Gates nền tảng của
3% Hoa Kỳ quyền công dânVăn bản:[CLS] Bill Gates và Mark Zuckerberg đang làm việc cùng nhau để tài trợ nghiên cứu các phương pháp điều trị COVID-19.
Triple sự thật : Mark Zuckerberg, Bill Gates, hợp tác
Thực thể h: Mark Zuckerberg
Tầm quan trọng Thực thể t Quan hệ
15% Facebook CEO của
14% Giám đốc điều hành vị trí giữ
11% Doanh nhân nghề nghiệp
11% Nhà khoa học máy tính nghề nghiệp
9% Đại học Harvard được giáo dục tại
9% Học viện Phillips Exeter được giáo dục tại
9% Trường trung học Ardsley được giáo dục tại
8% Palo Alto, California cư trú
7% White Plains, New York nơi sinh
7% Tiếng Trung phổ thông ngôn ngữ nói
Thực thể h: Bill Gates
Tầm quan trọng Thực thể t Quan hệ
33% Quỹ Bill&Melinda Gates nền tảng của
10% Microsoft CEO của
9% Giám đốc điều hành vị trí giữ
8% Học viện Khoa học và Nghệ thuật Mỹ thành viên của
8% Học viện Kỹ thuật Quốc gia thành viên của
7% Nhà khoa học máy tính nghề nghiệp
7% Nhà đầu tư nghề nghiệp
7% Doanh nhân nghề nghiệp
6% Đại học Harvard được giáo dục tại
5% Hoa Kỳ quyền công dân

Bảng 2: Độ sâu của màu thể hiện tầm quan trọng của các triple đối với một câu đã cho.

FewRel TACRED
P R F1 P R F1
ERNIE 87.6 50.6 64.1 81.1 41.8 55.1
CokeBERT_BASE 87.9 71.5 78.9 86.1 58.4 69.6
CokeRoBERTa_BASE 79.8 84.0 81.9 74.9 72.0 73.4

Bảng 3: Kết quả của việc nắm bắt các triple dương từ các triple được gán nhãn trên FewRel và TACRED (%).

và triple âm để tính toán điểm F1 cho đánh giá.

Để công bằng chứng minh hiệu quả của việc trích xuất triple thông qua Coke, chúng tôi chọn ERNIE làm mô hình cơ sở, vốn vốn dĩ căn chỉnh không gian nhúng ngôn ngữ và không gian nhúng KG sử dụng cùng dữ liệu huấn luyện như Coke. Như được hiển thị trong Bảng 3, điểm F1 của Coke tốt hơn so với mô hình cơ sở 14.8%-17.8% trên FewRel và 14.5%-18.3% trên TACRED.

4.4 Kết quả đánh giá tổng thể
Trong phần này, chúng tôi so sánh các mô hình của chúng tôi với các PLMs hiệu quả khác nhau về phân loại thực thể và phân loại quan hệ, bao gồm cả PLMs vanilla và PLMs tăng cường kiến thức.

Phân loại thực thể Cho một đề cập thực thể và câu tương ứng của nó, phân loại thực thể yêu cầu phân loại đề cập thực thể vào các loại của nó. Đối với nhiệm vụ này, chúng tôi tinh chỉnh Coke trên FIGER (Ling et al., 2015) và Open Entity (Choi et al., 2018). Tập huấn luyện của FIGER được gán nhãn với giám sát từ xa, và tập kiểm tra của nó được chú thích bởi con người. Open Entity là một tập dữ liệu được chú thích hoàn toàn thủ công. Chúng tôi so sánh mô hình của chúng tôi với các mô hình cơ sở mà chúng tôi đã đề cập trong Phương pháp cơ sở 4.2.

Như được hiển thị trong Bảng 4, Coke có thể đạt được điểm F1 có thể so sánh trên Open Entity. Trên FIGER, Coke vượt trội đáng kể so với BERT_BASE và RoBERTa_BASE lần lượt 3.7% và 3.5% điểm Micro. Bên cạnh đó, hiệu suất của Coke cũng tốt hơn so với các mô hình cơ sở khác. Nó trực tiếp chứng minh rằng Coke có khả năng tốt hơn để giảm thách thức nhãn nhiễu trong FIGER so với các mô hình cơ sở mà chúng tôi đã đề cập ở trên.

Hơn nữa, chúng tôi thấy rằng miền của FIGER tương tự như Wikidata, điều này phù hợp với quan sát trong phần phân tích thực nghiệm, điều này càng làm nổi bật tầm quan trọng của việc lựa chọn ngữ cảnh kiến thức xuyên miền.

--- TRANG 8 ---
Nhiệm vụ Phân loại thực thể Phân loại quan hệ
Tập dữ liệu Open Entity FIGER FewRel TACRED
Chỉ số P R F1 Acc. Macro Micro P R F1 P R F1
Các mô hình ngôn ngữ tiền huấn luyện
BERT_BASE 76.2 71.0 73.6 52.0 75.2 71.6 85.0 85.1 84.9 67.2 64.8 66.0
RoBERTa_BASE 75.3 73.2 74.2 56.3 76.9 74.2 86.3 86.3 86.3 73.0 68.7 70.8
RoBERTa_LARGE 78.5 72.7 75.5 57.1 82.4 76.5 88.4 88.4 88.4 74.3 66.8 70.4
Các mô hình ngôn ngữ tiền huấn luyện tăng cường kiến thức
ERNIE 78.4 72.9 75.6 57.2 76.5 73.4 88.5 88.4 88.3 69.9 66.0 67.9
K-BERT 76.7 71.5 74.0 56.5 77.1 73.8 83.1 85.9 84.3 68.1 66.1 67.1
KnowBert-Wiki 78.6 71.6 75.0 57.0 79.8 75.0 89.2 89.2 89.2 71.1 66.8 68.9
Các mô hình ngôn ngữ tiền huấn luyện tăng cường kiến thức theo ngữ cảnh
CokeBERT_BASE 78.0 73.3 75.6 57.9 79.7 75.3 89.4 89.4 89.4 71.0 66.9 68.9
CokeRoBERTa_BASE 76.8 74.2 75.6 62.2 82.3 77.7 90.1 90.1 90.1 71.3 71.0 71.1
CokeRoBERTa_LARGE 75.3 76.2 75.7 58.3 82.3 77.8 91.1 91.1 91.1 69.9 71.8 70.8

Bảng 4: Kết quả của các mô hình khác nhau cho Phân loại quan hệ và Phân loại thực thể (%).

Phân loại quan hệ Phân loại quan hệ nhằm xác định quan hệ đúng giữa hai thực thể trong một câu đã cho. Chúng tôi tinh chỉnh Coke trên hai tập dữ liệu chuẩn được sử dụng rộng rãi FewRel (Han et al., 2018) và TACRED (Zhang et al., 2017). Chúng tôi cũng so sánh mô hình của chúng tôi với các mô hình cơ sở mà chúng tôi đã đề cập trong Phương pháp cơ sở 4.2.

Trên FewRel, Coke vượt trội đáng kể so với BERT_BASE và RoBERTa_BASE lần lượt 4.5% và 3.8% điểm F1 như được hiển thị trong Bảng 4. Nó trực tiếp chứng minh rằng Coke có thể nắm bắt quan hệ giữa hai thực thể tốt hơn so với ERNIE bằng cách xem xét thông tin của các láng giềng bậc cao hơn, đặc biệt là trong tập dữ liệu nhỏ FewRel.

Bên cạnh đó, các mô hình Coke có kết quả có thể so sánh với các mô hình cơ sở khác trên TACRED nhưng đạt được những cải thiện đáng kể trên FewRel. Như chúng tôi đã đề cập trước đó, miền của dữ liệu FewRel tương tự hơn với Wikidata và do đó nó có được nhiều lợi ích hơn từ tiền huấn luyện.

4.5 Nghiên cứu Ablation
Để chỉ ra tác động của S-GNN trong quá trình động lựa chọn ngữ cảnh kiến thức, chúng tôi tiến hành các nghiên cứu ablation cần thiết cho các mô-đun khác nhau trong S-GNN.

Đồ thị con K-Hop Trong phần này, chúng tôi khám phá tác động của bộ mã hóa ngữ cảnh kiến thức động. Có hai thành phần chính trong bộ mã hóa ngữ cảnh kiến thức động: xây dựng ngữ cảnh kiến thức thô và S-GNN. Coke áp dụng xây dựng ngữ cảnh kiến thức thô để lấy mẫu các đồ thị con K-hop, và sau đó kết hợp S-GNN để nhúng kiến thức thông tin trong ngữ cảnh thô.

Từ Hình 3, chúng tôi thấy rằng Coke kết hợp đồ thị con 2-hop vượt trội 0.4% đến 0.6% so với kết hợp đồ thị con 1-hop. Nó chứng minh rằng việc xem xét phạm vi kiến thức rộng hơn có thể dẫn đến các nhúng thực thể tốt hơn.

Cơ chế chú ý Trong S-GNN, có một cơ chế cần thiết: chú ý. Nó có trách nhiệm cân nhắc mức độ kiến thức khớp với văn bản và giúp tính toán các nhúng theo ngữ cảnh động cuối cùng. Để tiếp tục chứng minh tác động của cơ chế chú ý, chúng tôi đơn giản hóa nó bằng một hoạt động mean-pooling để tổng hợp các đặc trưng. Từ Hình 4, chúng ta có thể thấy rằng cơ chế chú ý vượt trội hơn so với cơ chế mean-pooling và các nhúng cố định (ERNIE), chỉ ra hiệu quả của cơ chế chú ý của chúng tôi.

(a) FewRel
 (b) FIGER

Hình 3: Kết quả của Coke kết hợp các đồ thị con K-hop (%).

5 Kết luận và Công việc tương lai
Chúng tôi đã đề xuất một khung hiệu quả và tổng quát để cho phép PLMs động lựa chọn ngữ cảnh kiến thức phù hợp với ngữ cảnh văn bản, và sau đó chèn kiến thức nhúng vào PLMs. Các thí nghiệm chứng minh rằng Coke có thể đạt được kết quả có thể so sánh với các PLMs tăng cường kiến thức hiện đại trong phân loại thực thể và phân loại quan hệ. Coke động lựa chọn ngữ cảnh kiến thức với ngữ cảnh văn bản có thể giải thích được hơn so với việc tiêm tất cả ngữ cảnh kiến thức từ KGs. Trong phân tích thực nghiệm, Coke cũng chứng minh việc lựa chọn ngữ cảnh kiến thức hiệu quả. Hướng này có thể dẫn đến hiểu ngôn ngữ tổng quát và hiệu quả hơn. Trong tương lai, chúng tôi sẽ tiếp tục khám phá cách tiêm các loại kiến thức khác (ví dụ kiến thức ngôn ngữ học) kết hợp với kiến thức sự thật để tiếp tục nâng cao PLMs. Và cũng là một hướng thú vị để khám phá cách liên tục tiêm kiến thức sự thật mới nổi vào PLMs mà không cần huấn luyện lại toàn bộ mô hình.

(a) FewRel
 (b) FIGER

Hình 4: Tác động của cơ chế chú ý và các phiên bản đơn giản hóa của nó (%).

Tài liệu tham khảo
Livio Baldini Soares, Nicholas FitzGerald, Jeffrey Ling, và Tom Kwiatkowski. 2019. Matching the blanks: Distributional similarity for relation learning. Trong Proceedings of ACL, trang 2895–2905.

Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, và Oksana Yakhnenko. 2013. Translating embeddings for modeling multi-relational data. Trong Proceedings of NeurIPS, trang 2787–2795.

Eunsol Choi, Omer Levy, Yejin Choi, và Luke Zettlemoyer. 2018. Ultra-fine entity typing. Trong Proceedings of ACL, trang 87–96.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understanding. Trong Proceedings of NAACL, trang 4171–4186.

Paolo Ferragina và Ugo Scaiella. 2010. Tagme: On-the-fly annotation of short text fragments (by wikipedia entities). Trong Proceedings of CIKM, trang 1625–1628.

--- TRANG 9 ---
Xu Han, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao, Zhiyuan Liu, và Maosong Sun. 2018. FewRel: A large-scale supervised few-shot relation classification dataset with state-of-the-art evaluation. Trong Proceedings of EMNLP, trang 4803–4809.

Bin He, Di Zhou, Jinghui Xiao, Xin jiang, Qun Liu, Nicholas Jing Yuan, và Tong Xu. 2019. Integrating graph contextualized knowledge into pre-trained language models. arXiv.

Anne Lauscher, Ivan Vulić, Edoardo Maria Ponti, Anna Korhonen, và Goran Glavaš. 2019. Specializing unsupervised pretraining models for word-level semantic similarity. arXiv.

Xiao Ling, Sameer Singh, và Daniel S. Weld. 2015. Design challenges for entity linking. Trong Proceedings of ACL, trang 315–328.

Weijie Liu, Peng Zhou, Zhe Zhao, Zhiruo Wang, Qi Ju, Haotang Deng, và Ping Wang. 2020. K-bert: Enabling language representation with knowledge graph. Trong Proceedings of AAAI, trang 2901–2908.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv.

Joshi Mandar, Chen Danqi, Liu Yinhan, Daniel S. Weld, Zettlemoyer Luke, và Levy Omer. 2019. Spanbert: Improving pre-training by representing and predicting spans. Trong Proceedings of TACL, trang 64–77.

Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, và Luke Zettlemoyer. 2018. Deep contextualized word representations. Trong Proceedings of NAACL-HLT, trang 2227–2237.

Matthew E. Peters, Mark Neumann, Robert L Logan, Roy Schwartz, Vidur Joshi, Sameer Singh, và Noah A. Smith. 2019. Knowledge enhanced contextual word representations. Trong Proceedings of EMNLP, trang 43–54.

Nina Poerner, Ulli Waltinger, và Hinrich Schütze. 2019. BERT is not a knowledge base (yet): Factual knowledge vs. name-based reasoning in unsupervised QA. arXiv.

Alec Radford, Karthik Narasimhan, Tim Salimans, và Ilya Sutskever. 2018. Improving language understanding by generative pre-training. arXiv.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. 2017. Attention is all you need. Trong Proceedings of NeurIPS, trang 5998–6008.

--- TRANG 10 ---
Ruize Wang, Duyu Tang, Nan Duan, Zhongyu Wei, Xuanjing Huang, Jianshu Ji, Cuihong Cao, Daxin Jiang, và Ming Zhou. 2020. K-adapter: Infusing knowledge into pre-trained models with adapters. arXiv.

Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhiyuan Liu, Juan-Zi Li, và Jian Tang. 2019. KEPLER: A unified model for knowledge embedding and pre-trained language representation. arXiv.

Wenhan Xiong, Jingfei Du, William Yang Wang, và Veselin Stoyanov. 2019. Pretrained encyclopedia: Weakly supervised knowledge-pretrained language model. Trong Proceedings of ICLR.

Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, và Quoc V Le. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. Trong Proceedings of NeurIPS, trang 5753–5763.

Levine Yoav, Lenz Barak, Dagan Or, Padnos Dan, Sharir Or, Shalev-Shwartz Shai, Shashua Amnon, và Shoham Yoav. 2019. Sensebert: Driving some sense into bert. Trong Proceedings of ACL, trang 4656–4667.

Sun Yu, Wang Shuohuan, Li Yu-Kun, Feng Shikun, Chen Xuyi, Zhang Han, Tian Xin, Zhu Danxiang, Tian Hao, và Wu Hua. 2019. Ernie: Enhanced representation through knowledge integration. Trong Proceedings of ACL, trang 1441–1451.

Sun Yu, Wang Shuohuan, Li Yukun, Feng Shikun, Tian Hao, Wu Hua, và Wang Haifeng. 2020. Ernie2.0: A continual pre-training framework for language understanding. Trong Proceedings of AAAI.

Yuhao Zhang, Victor Zhong, Danqi Chen, Gabor Angeli, và Christopher D. Manning. 2017. Position-aware attention and supervised data improve slot filling. Trong Proceedings of EMNLP, trang 35–45.

Zhengyan Zhang, Xu Han, Zhiyuan Liu, Xin Jiang, Maosong Sun, và Qun Liu. 2019. Ernie: Enhanced language representation with informative entities. Trong Proceedings of ACL, trang 1441–1451.

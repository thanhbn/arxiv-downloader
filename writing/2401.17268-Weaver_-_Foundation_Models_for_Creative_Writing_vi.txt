# 2401.17268.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/writing/2401.17268.pdf
# Kích thước tệp: 1373871 byte

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Weaver: Mô hình Nền tảng cho Viết Sáng tạo
Tiannan Wang Jiamin Chen Qingrui Jia Shuai Wang Ruoyu Fang Huilin Wang
Zhaowei Gao Chunzhao Xie Chuou Xu Jihong Dai Yibin Liu Jialong Wu Shengwei Ding
Long Li Zhiwei Huang Xinle Deng Teng Yu Gangan Ma Han Xiao Zixin Chen
Danjun Xiang Yunxia Wang Yuanyuan Zhu Yi Xiao Jing Wang Yiru Wang Siran Ding
Jiayang Huang Jiayi Xu Yilihamu Tayier Zhenyu Hu Yuan Gao Chengfeng Zheng
Yueshu Ye Yihang Li Lei Wan Xinyue Jiang Yujie Wang Siyu Cheng Zhule Song
Xiangru Tang Xiaohua Xu Ningyu Zhang Huajun Chen
Yuchen Eleanor Jiang*Wangchunshu Zhou*
AIWaves Inc.

Tóm tắt
Nghiên cứu này giới thiệu Weaver, gia đình mô hình ngôn ngữ lớn (LLM) đầu tiên của chúng tôi được dành riêng cho việc tạo nội dung. Weaver được huấn luyện trước trên một kho dữ liệu được lựa chọn cẩn thận nhằm cải thiện khả năng viết của các mô hình ngôn ngữ lớn. Sau đó chúng tôi tinh chỉnh Weaver cho mục đích viết sáng tạo và chuyên nghiệp, đồng thời căn chỉnh nó theo sở thích của các nhà văn chuyên nghiệp bằng cách sử dụng một bộ phương pháp mới cho việc tổng hợp dữ liệu hướng dẫn và căn chỉnh LLM, giúp nó có thể tạo ra các văn bản giống con người hơn và tuân theo nhiều hướng dẫn đa dạng hơn cho việc tạo nội dung. Gia đình Weaver bao gồm các mô hình có kích cỡ Mini(1.8B), Base(6B), Pro(14B), và Ultra(34B), phù hợp cho các ứng dụng khác nhau và có thể được điều phối động bởi một tác nhân định tuyến theo độ phức tạp của truy vấn để cân bằng chất lượng phản hồi và chi phí tính toán. Đánh giá trên một benchmark được tuyển chọn cẩn thận để đánh giá khả năng viết của các LLM cho thấy các mô hình Weaver ở mọi kích cỡ đều vượt trội so với các LLM tổng quát lớn hơn chúng nhiều lần. Đáng chú ý, mô hình Weaver Ultra có khả năng nhất của chúng tôi vượt qua GPT-4, một LLM tổng quát hiện đại, trong các tình huống viết khác nhau, chứng minh lợi thế của việc huấn luyện các LLM chuyên biệt cho mục đích viết. Hơn nữa, Weaver hỗ trợ tự nhiên cho tăng cường tìm kiếm (RAG) và gọi hàm (sử dụng công cụ). Chúng tôi trình bày nhiều trường hợp sử dụng các khả năng này để cải thiện hệ thống viết hỗ trợ AI, bao gồm tích hợp cơ sở tri thức bên ngoài, công cụ, hoặc API, và cung cấp hỗ trợ viết cá nhân hóa. Hơn nữa, chúng tôi thảo luận và tóm tắt hướng dẫn và thực hành tốt nhất cho việc huấn luyện trước và tinh chỉnh các LLM chuyên biệt theo lĩnh vực. Weaver hiện có thể truy cập tại www.wawawriter.com, nền tảng viết hợp tác giữa con người và AI sáng tạo của chúng tôi (Đối với phiên bản tiếng Anh của WawaWriter, xem www.wawawriter.com/en). Chúng tôi thảo luận một số đổi mới của nền tảng từ góc độ tương tác người-máy để giải thích cách nó sẽ cách mạng hóa các hệ thống viết hỗ trợ AI truyền thống.
*Tác giả liên hệ: {eleanor,chunshu}@aiwaves.cnarXiv:2401.17268v1 [cs.CL] 30 Jan 2024

--- TRANG 2 ---
Mục lục
1 Giới thiệu 4
2 Huấn luyện trước 6
2.1 Gia đình Mô hình . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
2.2 Dữ liệu Huấn luyện trước . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
2.3 Chi tiết Huấn luyện . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
3 Tổng hợp Dữ liệu 8
3.1 Khả năng . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
3.1.1 Tuân theo Hướng dẫn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
3.1.2 Chú thích Hướng dẫn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
3.1.3 Đánh giá (Phê bình Văn học) . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.1.4 Tạo Tăng cường Tìm kiếm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.1.5 Gọi Hàm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.2 Dịch ngược Hướng dẫn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.3 DPO Hiến pháp: Học từ Ví dụ Tiêu cực Có Nguyên tắc . . . . . . . . . . . . . . . . 12
4 Căn chỉnh 14
4.1 Tinh chỉnh Có giám sát . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
4.1.1 Dữ liệu . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
4.1.2 Huấn luyện . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
4.2 Tối ưu hóa Sở thích . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
4.2.1 Dữ liệu . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
4.2.2 Huấn luyện . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
5 Đánh giá 14
5.1 WriteBench . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
5.2 Mô hình So sánh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
5.3 Đánh giá dựa trên LLM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
5.4 Đánh giá của Con người . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
5.5 Nghiên cứu Người dùng . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
6 Giới thiệu WawaWriter 17
6.1 Viết Hợp tác giữa Con người và AI . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
6.2 Tích hợp Tri thức và Công cụ Bên ngoài . . . . . . . . . . . . . . . . . . . . . . . . . 17
6.3 Hỗ trợ Viết Cá nhân hóa . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

--- TRANG 3 ---
6.4 Tạo Văn bản Dài Vô hạn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
7 Thảo luận 18
A Phụ lục 24
A.1 Đóng góp của Tác giả . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
A.2 Lời cảm ơn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
A.3 Nghiên cứu Trường hợp . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24

--- TRANG 4 ---
1. Giới thiệu
Các mô hình ngôn ngữ lớn (LLM) (Anthropic, 2023; Brown et al., 2020; Google, 2023; Jiang et al., 2023a; OpenAI, 2022, 2023; Radford et al., 2018, 2019; Gemini Team, 2023; Touvron et al., 2023a,b; Yin et al., 2023; Zhao et al., 2023) dựa trên Transformers (Vaswani et al., 2017) đã trở thành một con đường nổi bật dẫn đến Trí tuệ Nhân tạo Tổng quát (AGI). LLM thu được kiến thức thế giới đồ sộ bằng cách học dự đoán từ tiếp theo trên các kho dữ liệu web quy mô lớn. Khả năng của LLM đã được tăng cường liên tục bằng cách mở rộng kích thước mô hình, kích thước tập dữ liệu, và tính toán. Sau khi huấn luyện trước, LLM có thể được căn chỉnh để hỗ trợ các trường hợp sử dụng thực tế bằng tinh chỉnh có giám sát (Chung et al., 2022; Sanh et al., 2022) và các kỹ thuật tối ưu hóa sở thích bao gồm học tăng cường từ phản hồi của con người (RLHF) (Ouyang et al., 2022a; Wang et al., 2024; Zheng et al., 2023b) và tối ưu hóa sở thích trực tiếp (DPO) (Rafailov et al., 2023). Khả năng của LLM đã trao quyền cho nhiều ứng dụng khác nhau bao gồm ChatGPT, Claude, Bard, Microsoft Copilot, Character.AI, Notion AI, v.v.

Gần đây, nhiều LLM chuyên biệt đã được huấn luyện cho các tình huống sử dụng mục tiêu khác nhau. Nói chung, LLM chuyên biệt theo các lĩnh vực mục tiêu (ví dụ: tài chính (Wu et al., 2023), chăm sóc sức khỏe (Yang et al., 2022b), pháp lý (Cui et al., 2023), v.v.) và nhiệm vụ (ví dụ: đóng vai (Wang et al., 2023d), lập trình (Rozière et al., 2023), v.v.). Tuy nhiên, khả năng của LLM trong việc viết văn bản giống con người và tạo nội dung sáng tạo, vốn là một trường hợp sử dụng quan trọng của các ứng dụng LLM như ChatGPT, hầu như bị bỏ qua bởi cộng đồng.

Trong báo cáo này, chúng tôi tập trung vào lĩnh vực văn học và nhiệm vụ viết, hay tạo nội dung, và giới thiệu Weaver, một gia đình LLM được huấn luyện trước và căn chỉnh chuyên biệt cho mục đích này. Tên "Weaver" tượng trưng cho khả năng thành thạo của mô hình trong việc khéo léo kết hợp các yếu tố ngôn ngữ, giống như cách một thợ thủ công dệt các sợi chỉ để tạo thành vải. Chúng tôi trả lời bốn câu hỏi chính trong báo cáo kỹ thuật này: tại sao chúng ta cần Weaver, chúng ta huấn luyện Weaver như thế nào, Weaver hoạt động ra sao, và chúng ta xây dựng gì với Weaver.

[Hình 1|So sánh giữa Weaver và các LLM tổng quát trên WriteBench]

Tại sao chúng ta cần Weaver? Mặc dù các LLM tổng quát như GPT đã có kỹ năng viết chung và giúp hàng tỷ người dùng trong nhiều tình huống viết khác nhau, chúng thường gặp khó khăn trong việc tạo ra văn bản giống con người trong các tình huống viết cụ thể như viết truyện, tiểu thuyết, bản sao mạng xã hội, blog, bài báo/luận văn, v.v. Chúng tôi phân tích hành vi của các LLM cơ sở đã được huấn luyện trước như LLaMA và các LLM đã được căn chỉnh như ChatGPT và LLaMA-chat và tin rằng hạn chế này xuất phát từ cả giai đoạn huấn luyện trước và giai đoạn căn chỉnh. Một mặt, các LLM tổng quát được huấn luyện trước trên các văn bản web chất lượng thấp hoặc văn bản do máy/AI tạo ra. Do đó, các backbone LLM hiện tại có xu hướng tạo ra các văn bản có vẻ trôi chảy nhưng không đủ sáng tạo và thiếu phong cách giống con người. Mặt khác, trong giai đoạn căn chỉnh, các LLM tiên tiến như GPT-4 được tinh chỉnh hướng dẫn bằng các cặp hướng dẫn-phản hồi được chú thích bởi các chú thích viên crowdsource (Ji et al., 2023; Shen et al., 2023; Wang et al., 2023c). Tuy nhiên, hầu hết các chú thích viên không phải là nhà văn hoặc người tạo nội dung chuyên nghiệp và các hướng dẫn chú thích chỉ yêu cầu họ tạo ra các phản hồi hữu ích và vô hại (Ouyang et al., 2022b). Kết quả là, dữ liệu crowdsource cho tinh chỉnh có giám sát ít có phong cách và thiếu sáng tạo. Hơn nữa, hầu hết các phương pháp tối ưu hóa sở thích phổ biến như RLHF và DPO tối ưu hóa mô hình trên các cặp dữ liệu do mô hình tạo ra, khiến chúng ít phù hợp để tăng cường sự sáng tạo của LLM.

--- TRANG 5 ---
Những yếu tố này khiến các LLM tổng quát hiện tại thiếu sáng tạo và không thể tạo ra văn bản theo phong cách con người mặc dù chúng rất mạnh trong các ứng dụng khác như viết mã và trả lời các câu hỏi chung. Chúng tôi tin rằng hiện tượng này sẽ tiếp tục được khuếch đại do lượng văn bản do LLM tạo ra trên internet đang tăng theo cấp số nhân và hầu hết LLM được căn chỉnh bằng văn bản do các LLM khác tạo ra. Do đó, chúng tôi tin rằng cần thiết phải huấn luyện các LLM chuyên biệt theo lĩnh vực dành riêng cho mục đích viết có tính sáng tạo và tạo ra văn bản giống con người để khai thác đầy đủ tiềm năng của nội dung do AI tạo ra (AIGC).

Chúng ta huấn luyện Weaver như thế nào? Để giải quyết các vấn đề nêu trên làm hạn chế khả năng viết sáng tạo của LLM tổng quát, chúng tôi thiết kế cẩn thận một bộ chiến lược cho thu thập dữ liệu tự động, chú thích dữ liệu, và lọc dữ liệu cho huấn luyện trước và căn chỉnh. Điều này giúp chúng tôi có thể huấn luyện trước và căn chỉnh Weaver trên các văn bản đa dạng, giống con người và có phong cách. Cụ thể, chúng tôi tiến hành lọc dữ liệu huấn luyện trước mở rộng và chỉ giữ lại nội dung chất lượng cao như sách, tiểu thuyết, truyện, và bài báo trong kho dữ liệu huấn luyện trước, khiến các backbone đã được huấn luyện trước có khả năng tạo ra văn bản giống con người hơn.

Đối với giai đoạn căn chỉnh, chúng tôi đề xuất một khung dịch ngược hướng dẫn mới được lấy cảm hứng từ LongForm (Köksal et al., 2023) và Humpback (Li et al., 2023) để tổng hợp các hướng dẫn đa dạng và tự nhiên tương ứng với các đầu ra chất lượng cao được viết bởi các nhà văn chuyên nghiệp và được người tiêu dùng ưa thích. Khung dịch ngược hướng dẫn của chúng tôi đã chuyển đổi công việc của các chú thích viên crowdsource từ việc viết cả hướng dẫn và đầu ra sang đơn giản là thu thập nội dung chất lượng cao như truyện, tiểu thuyết, bài báo, bản sao mạng xã hội, và bài blog. Điều này làm giảm đáng kể chi phí chú thích dữ liệu hướng dẫn và yêu cầu đối với các chú thích viên crowdsource trong khi cải thiện đáng kể chất lượng dữ liệu được chú thích.

Hơn nữa, chúng tôi cũng đề xuất một thuật toán DPO Hiến pháp mới cho tối ưu hóa sở thích để căn chỉnh Weaver tốt hơn với sở thích của các nhà văn và người tạo nội dung chuyên nghiệp. DPO Hiến pháp được lấy cảm hứng từ và kết hợp các ưu điểm của một số nghiên cứu trước đây bao gồm DPO (Rafailov et al., 2023), AI Hiến pháp (Bai et al., 2022), Self-Align (Sun et al., 2023), và RLCD (Yang et al., 2023a). Cụ thể, DPO Hiến pháp khai thác các nguyên tắc được chú thích bởi chuyên gia (ví dụ: các biên tập viên chuyên nghiệp trong trường hợp của chúng tôi) để tổng hợp các ví dụ tiêu cực vi phạm một số nguyên tắc nhất định dựa trên các ví dụ tích cực được lấy mẫu từ chính sách tối ưu (ví dụ: văn bản do nhà văn hoặc người tạo nội dung chuyên nghiệp tạo ra trong trường hợp của chúng tôi). Trái ngược với thực hành thông thường của việc sử dụng DPO sử dụng LLM để tạo chú thích sở thích trên hai phản hồi do mô hình tạo ra như Zephyr (Tunstall et al., 2023), dữ liệu sở thích theo cặp được tổng hợp bởi phương pháp của chúng tôi chứa ít nhiễu hơn vì các ví dụ tiêu cực được tổng hợp có chủ ý để có chất lượng thấp hơn so với ví dụ tích cực. Dữ liệu sở thích theo cặp được tạo bởi DPO Hiến pháp cũng chứa các tín hiệu học tập có nguyên tắc và có mục tiêu hơn có thể được điều chỉnh bởi các chuyên gia con người theo lĩnh vực và ứng dụng mục tiêu.

Hơn nữa, chúng tôi đề xuất chuyển đổi các hướng dẫn chú thích và phản hồi được sử dụng trong các giai đoạn dịch ngược hướng dẫn và DPO Hiến pháp thành hướng dẫn chú thích và hướng dẫn đánh giá. Bằng cách này, Weaver không chỉ có khả năng tuân theo hướng dẫn viết mà còn có thể chú thích hướng dẫn viết và đánh giá đầu ra viết. Chúng tôi cũng tuyển chọn dữ liệu hướng dẫn cho tạo tăng cường tìm kiếm (RAG) và gọi hàm để cho phép Weaver khai thác tri thức và công cụ bên ngoài. Sự kết hợp của các nguồn dữ liệu khác nhau khiến Weaver trở thành một mô hình nền tảng đa năng trong khi chuyên biệt về viết sáng tạo.

Weaver hoạt động ra sao? Đánh giá khả năng tạo nội dung/viết của LLM vẫn là một vấn đề mở vì các benchmark hiện có cho LLM như MMLU (Hendrycks et al., 2020) hoặc MT-Bench (Zheng et al., 2023a) chủ yếu tập trung vào lý luận, toán học, lập trình, hoặc câu hỏi chung thay vì viết sáng tạo. Hơn nữa, việc đánh giá LLM trên các hướng dẫn chung đã rất khó và việc này trở nên khó khăn hơn nhiều đối với các nhiệm vụ viết sáng tạo vì phê bình văn học không tầm thường ngay cả đối với các chuyên gia con người, chưa nói đến LLM. Để đánh giá Weaver tốt hơn và giúp cộng đồng LLM đo lường tiến bộ trên AIGC tốt hơn, chúng tôi tuyển chọn cẩn thận WriteBench, một benchmark để đánh giá khả năng viết sáng tạo của LLM và thu thập đầu ra từ hơn 10 LLM phổ biến bao gồm cả mô hình mã nguồn mở và độc quyền.

--- TRANG 6 ---
Sau đó chúng tôi tiến hành đánh giá dựa trên LLM và con người về Weaver và các LLM tổng quát trên benchmark. Kết quả đánh giá xác nhận sự vượt trội của Weaver so với các LLM tổng quát. Chúng tôi thấy rằng Weaver Ultra, mô hình có khả năng nhất trong gia đình Weaver, đã đưa ra kết quả tiên tiến trong viết sáng tạo mặc dù nhỏ hơn hơn 10 lần so với GPT-4¹, LLM tốt nhất trước đây. Các mô hình khác trong gia đình Weaver cũng vượt trội so với các LLM tổng quát cạnh tranh lớn hơn chúng nhiều lần. Phân tích và nghiên cứu trường hợp của chúng tôi cho thấy nguồn cải thiện chính là do Weaver có thể tạo ra văn bản sáng tạo và giống con người trong khi các LLM tổng quát có xu hướng tạo ra văn bản quá "có thể dự đoán". Để xác nhận rằng Weaver thực sự hữu ích trong các ứng dụng thực tế, chúng tôi cũng tiến hành một nghiên cứu người dùng trong đó các nhà văn được yêu cầu viết truyện (viết tiểu thuyết) và bài blog (viết phi tiểu thuyết) với Weaver và GPT-4. Nghiên cứu người dùng của chúng tôi cho thấy so với GPT-4, Weaver cải thiện năng suất của nhà văn 47% và giúp nhà văn tạo ra những câu chuyện và bài viết tốt hơn cùng lúc.

Chúng ta xây dựng gì với Weaver? Huấn luyện LLM chuyên biệt cho viết là một mặt của việc tăng cường trải nghiệm viết hỗ trợ AI. Chúng tôi tin rằng cũng rất quan trọng khi xây dựng một giao diện người-AI tốt hơn để khai thác đầy đủ tiềm năng của Weaver về viết hỗ trợ AI. Vì mục đích này, chúng tôi giới thiệu WawaWriter, nền tảng viết hợp tác giữa con người và AI sáng tạo của chúng tôi. Tương tự như các sản phẩm viết AI gần đây như Notion AI, WawaWriter cung cấp giao diện trò chuyện cho phép người dùng cung cấp hướng dẫn viết đa dạng, thay vì chỉ đề xuất một hoặc vài câu tiếp theo dựa trên ngữ cảnh hiện tại hoặc làm đẹp nội dung như trong các ứng dụng truyền thống. WawaWriter cũng tiến thêm vài bước: (1) chúng tôi cho phép đồng chỉnh sửa giữa con người và AI bằng cách cho phép người dùng tùy chỉnh các tác nhân ngôn ngữ (Zhou et al., 2023b) hoạt động như một cộng tác viên con người bằng cách hoạt động bên trong trình chỉnh sửa đồng thời với người dùng; (2) chúng tôi cho phép người dùng xây dựng cơ sở tri thức cá nhân bằng cách lưu trang web hoặc tải lên tài liệu và xây dựng đường ống RAG tích hợp cơ sở tri thức với Weaver; (3) chúng tôi đề xuất cung cấp hỗ trợ viết cá nhân hóa bằng cách phân tích phong cách viết cá nhân của người dùng bằng LLM dựa trên lịch sử viết của họ trên nền tảng và sử dụng kết quả để hướng dẫn quá trình tạo văn bản của Weaver. Bằng cách kết hợp những đổi mới này, WawaWriter nhằm cung cấp trải nghiệm viết hỗ trợ AI thế hệ tiếp theo hữu ích và thú vị hơn.

Trong các phần sau, chúng tôi trước tiên mô tả kiến trúc và kích cỡ của gia đình Weaver và giai đoạn huấn luyện trước của chúng. Sau đó chúng tôi trình bày chi tiết về khả năng của Weaver, cách chúng tôi tổng hợp dữ liệu huấn luyện để giúp Weaver có được những khả năng này và học cách tạo ra văn bản có phong cách giống con người, và chi tiết cho giai đoạn căn chỉnh. Chúng tôi cũng trình bày benchmark để đánh giá khả năng viết của LLM và kết quả đánh giá. Cuối cùng, chúng tôi giới thiệu chi tiết về WawaWriter và trình bày cách Weaver mở đường cho trải nghiệm viết hỗ trợ AI thế hệ tiếp theo.

2. Huấn luyện trước

2.1. Gia đình Mô hình
Các mô hình Weaver là các mô hình ngôn ngữ được xây dựng trên các bộ giải mã Transformer. Chúng tôi đã áp dụng những cải tiến gần đây từ thiết kế của LLaMA (Touvron et al., 2023a,b), LLM mã nguồn mở phổ biến nhất, bao gồm cấu trúc Pre-Norm với hàm RMSNorm (Zhang và Sennrich, 2019), SwiGLU (Shazeer, 2020) làm hàm kích hoạt cho Mạng Feed-Forward, Rotary Embedding (Su et al., 2024) cho mã hóa vị trí, và Grouped-Query Attention (GQA) (Ainslie et al., 2023).

Gia đình Weaver bao gồm các mô hình có bốn kích cỡ khác nhau: Mini, Base, Pro, và Ultra, từ 1.8B đến 34B tham số. Chúng tôi huấn luyện các kích cỡ mô hình khác nhau để hỗ trợ các ứng dụng khác nhau vì độ phức tạp của các nhiệm vụ viết khác nhau rất nhiều giữa các lĩnh vực và trường hợp sử dụng khác nhau. Tất cả các mô hình Weaver được khởi tạo từ các LLM mã nguồn mở mạnh mẽ. Chúng tôi cung cấp các cấu hình và mô tả chi tiết của các mô hình Weaver trong Bảng 1.

2.2. Dữ liệu Huấn luyện trước
Sau đó chúng tôi trình bày tổng quan về các chiến lược lựa chọn dữ liệu huấn luyện trước và hỗn hợp dữ liệu huấn luyện trước kết quả. Vì các mô hình Weaver được khởi tạo từ các LLM mã nguồn mở mạnh mẽ và do đó đã có đủ kiến thức thế giới, lượng dữ liệu huấn luyện trước liên tục không cần phải cực kỳ lớn. Chúng tôi coi giai đoạn huấn luyện trước liên tục là quá trình mà Weaver học cách phân bổ lại hoặc cân bằng lại khả năng của nó: mô hình phân bổ nhiều khả năng hơn cho viết và tạo nội dung trong khi giảm khả năng trong các lĩnh vực khác như toán học và lập trình.

Do đó, chúng tôi chỉ bao gồm các nguồn dữ liệu được xác minh thủ công bao gồm nhiều loại nội dung khác nhau như sách, tiểu thuyết, truyện, bài báo tin tức, bài báo, báo cáo, bản sao mạng xã hội, v.v., trong dữ liệu huấn luyện trước. Chúng tôi kết hợp các phương pháp dựa trên quy tắc và học máy để lọc văn bản chất lượng thấp. Ngoài nguồn dữ liệu và lọc, chúng tôi cũng kiểm soát cẩn thận hỗn hợp dữ liệu giữa các lĩnh vực khác nhau. Cụ thể, chúng tôi trộn dữ liệu tiểu thuyết (tức là tiểu thuyết và truyện) và dữ liệu phi tiểu thuyết (tức là bài báo, bài báo, báo cáo, v.v.) với tỷ lệ 1:1. Chúng tôi cũng trộn dữ liệu tiếng Trung và tiếng Anh với tỷ lệ 4:1 để làm cho Weaver hỗ trợ cả tiếng Trung và tiếng Anh.

2.3. Chi tiết Huấn luyện
Chúng tôi huấn luyện Weaver sử dụng nhiệm vụ mô hình hóa ngôn ngữ tự hồi quy tiêu chuẩn trong đó mô hình học dự đoán token tiếp theo dựa trên ngữ cảnh của các token trước đó. Chúng tôi huấn luyện các mô hình Weaver với độ dài ngữ cảnh 4096. Chúng tôi xáo trộn và hợp nhất các tài liệu, sau đó cắt ngắn chúng đến độ dài ngữ cảnh được chỉ định để tạo các lô huấn luyện. Chúng tôi tích hợp Megatron-Deepspeed (Shoeybi et al., 2019) và Flash Attention2 (Dao, 2023; Dao et al., 2022) để cải thiện hiệu quả tính toán và giảm sử dụng bộ nhớ. Chúng tôi áp dụng bộ tối ưu hóa tiêu chuẩn AdamW (Loshchilov và Hutter, 2017) và đặt các siêu tham số β₁=0.9, β₂=0.95, và ε=10⁻⁸. Chúng tôi sử dụng lịch trình tốc độ học cosin với tốc độ học đỉnh được chỉ định cho mỗi mô hình. Tốc độ học được giảm xuống tốc độ học tối thiểu bằng 10% tốc độ học đỉnh. Tất cả mô hình được huấn luyện với độ chính xác hỗn hợp BFloat16 để ổn định huấn luyện. Chúng tôi trình bày các cấu hình huấn luyện trước chi tiết cho mỗi mô hình trong Bảng 1.

[Bảng 1|Mô tả cho gia đình Weaver.]

--- TRANG 7 ---
3. Tổng hợp Dữ liệu

Sau khi huấn luyện trước, các mô hình Weaver chứa một lượng lớn kiến thức thế giới và kỹ năng viết, và có thể tạo ra văn bản giống con người dựa trên ngữ cảnh chất lượng cao. Để mở khóa những khả năng này cho các ứng dụng thực tế, chúng ta cần tuyển chọn một tập dữ liệu chất lượng cao để căn chỉnh. Định dạng và chất lượng của tập dữ liệu ảnh hưởng đáng kể đến phạm vi khả năng và chất lượng của các mô hình đã được căn chỉnh. Như đã thảo luận trong Giới thiệu, thực hành thông thường cho việc thu thập dữ liệu căn chỉnh của các LLM tổng quát hiện có làm hạn chế nghiêm trọng khả năng viết của chúng. Trong phần này, chúng tôi mô tả khung tổng hợp dữ liệu của chúng tôi một cách chi tiết. Chúng tôi trước tiên mô tả các loại khả năng chúng tôi muốn mở khóa trong giai đoạn căn chỉnh và sau đó trình bày các phương pháp tổng hợp dữ liệu được đề xuất của chúng tôi cho cả giai đoạn tinh chỉnh có giám sát và giai đoạn tối ưu hóa sở thích.

3.1. Khả năng

Chúng tôi trước tiên mô tả các loại khả năng chúng tôi muốn mở khóa cho Weaver trong giai đoạn căn chỉnh.

3.1.1. Tuân theo Hướng dẫn

Khả năng đầu tiên hiển nhiên chúng ta cần mở khóa là khả năng tuân theo hướng dẫn viết và tạo ra văn bản có phong cách giống con người. Chúng tôi bao gồm nhiều lĩnh vực và nhiệm vụ khác nhau như được liệt kê dưới đây trong quá trình thu thập dữ liệu và huấn luyện căn chỉnh.

3.1.1.1 Lĩnh vực

Viết Tiểu thuyết: Viết tiểu thuyết đề cập đến khả năng của mô hình để viết truyện và tiểu thuyết. Chúng tôi chia viết tiểu thuyết thành nhiều lĩnh vực phụ liên quan đến độ dài và thể loại của tiểu thuyết. Chúng tôi bao gồm tiểu thuyết và truyện có độ dài từ vài trăm đến vài triệu ký tự, và các loại tiểu thuyết bao gồm khoa học viễn tưởng, lãng mạn, fantasy, kinh dị, bí ẩn, và ly kỳ.

Viết Phi tiểu thuyết Sáng tạo: Viết phi tiểu thuyết sáng tạo là một thể loại viết sử dụng phong cách và kỹ thuật văn học để tạo ra những tường thuật chính xác về mặt sự thực. Chúng tôi bao gồm các trường hợp viết phi tiểu thuyết sáng tạo điển hình bao gồm viết hồi ký, tiểu sử, du ký, báo chí, bản sao mạng xã hội, bài blog, bài báo tin tức, bình luận, v.v.

Viết Marketing: Chúng tôi cũng xem xét viết marketing, bao gồm viết kế hoạch kinh doanh, bản sao quảng cáo, khuyến mãi sản phẩm, kế hoạch marketing, v.v. Viết marketing khác với các loại trước đây vì nó có định hướng ứng dụng cao và phong cách của văn bản được tạo ra không phải là quan trọng nhất. Tuy nhiên, viết marketing vẫn yêu cầu sự sáng tạo giống con người để thu hút người dùng tiềm năng.

Viết Kỹ thuật: Viết kỹ thuật bao gồm các nhiệm vụ như viết bài báo, viết bằng sáng chế, viết báo cáo, v.v. Viết kỹ thuật yêu cầu độ chính xác hơn so với sự sáng tạo. Tuy nhiên, đào tạo chuyên biệt về viết vẫn có thể hữu ích vì nó có thể giúp mô hình tạo ra văn bản tuân thủ chính xác phong cách yêu cầu cho các tình huống cụ thể.

3.1.1.2 Nhiệm vụ

Viết nội dung: Viết nội dung là nhiệm vụ cơ bản yêu cầu mô hình tạo ra nội dung (tức là tiểu thuyết, bài báo, v.v.) dựa trên các hướng dẫn nhất định. Hướng dẫn viết khác nhau về việc liệu ngữ cảnh trước đó có được cung cấp hay không và các hướng dẫn đã cho có mức độ chi tiết như thế nào. Nhiệm vụ yêu cầu LLM có thể hiểu và tuân thủ các yêu cầu cụ thể được thể hiện trong hướng dẫn trong khi cũng tạo ra văn bản nhất quán và mạch lạc với ngữ cảnh trước đó. Ví dụ, một hướng dẫn viết nội dung điển hình là: "Xin hãy giúp tôi viết một câu chuyện khoa học viễn tưởng về những gì sẽ xảy ra sau khi con người cuối cùng đạt được AGI."

--- TRANG 8 ---
Tạo dàn ý: Tạo dàn ý là nhiệm vụ viết dàn ý, đây là một thực hành phổ biến cho các nhà văn trong cả viết tiểu thuyết và phi tiểu thuyết. Như đã thảo luận trong tài liệu về tạo văn bản dài (Sun et al., 2022; Yang et al., 2022a, 2023b; Zhou et al., 2019, 2023a), thường hữu ích khi để mô hình tạo dàn ý trước khi tạo văn bản dài. Dàn ý khác nhau tùy theo lĩnh vực khác nhau và mức độ chi tiết/độ dài của dàn ý. Một ví dụ cho nhiệm vụ tạo dàn ý là "Xin hãy giúp tôi viết dàn ý báo cáo công việc hàng năm của tôi."

Chỉnh sửa & Biên tập: Chỉnh sửa và biên tập yêu cầu mô hình cải thiện chất lượng của một đoạn văn hoặc viết lại nó theo các yêu cầu được thể hiện trong hướng dẫn. Nhiệm vụ này liên quan chặt chẽ đến nhiệm vụ sửa lỗi ngữ pháp (Bryant et al., 2019; Ng et al., 2014) với một khác biệt chính là các sửa đổi không nhất thiết phải là lỗi ngữ pháp. So với nhiệm vụ chỉnh sửa viết học thuật được mô tả trong Diao et al. (2023), chúng tôi hỗ trợ kiểm soát tùy chỉnh chi tiết của các yêu cầu chỉnh sửa hoặc biên tập, điều này quan trọng cho tương tác người-AI trong các hệ thống viết hỗ trợ AI. Một hướng dẫn chỉnh sửa điển hình có thể trông như thế này: "Xin hãy giúp tôi sửa đổi các văn bản sau, hãy nhớ rằng các văn bản đã sửa đổi phải phù hợp cho một bài báo học thuật."

Chuyển đổi Phong cách: Nhiệm vụ chuyển đổi phong cách văn bản yêu cầu mô hình biến đổi văn bản trong một phong cách thành phong cách khác. Ví dụ, một người có thể muốn chuyển đổi một câu chuyện thành kịch bản hoặc biến một báo cáo thành bài phát biểu. Chúng tôi bao gồm cả chuyển đổi phong cách dựa trên mẫu sử dụng mẫu để cung cấp thông tin phong cách mục tiêu (Guu et al., 2018; Lewis et al., 2020) và chuyển đổi phong cách dựa trên mô tả sử dụng từ khóa (Hu et al., 2017) hoặc mô tả ngắn (Zhou et al., 2023c) cho phong cách mục tiêu. Ví dụ, một người có thể yêu cầu mô hình "Chuyển đổi chương sách sau thành kịch bản."

Mở rộng/Đơn giản hóa: Mở rộng và đơn giản hóa văn bản yêu cầu mô hình sửa đổi một đoạn văn đầu vào để làm cho nó dài hơn hoặc ngắn hơn theo các hướng dẫn nhất định. Tóm tắt văn bản và tạo bài báo từ tóm tắt có thể được coi là hai trường hợp cực đoan của nhiệm vụ này. Một hướng dẫn mẫu là: "Xin hãy giúp tôi tóm tắt đoạn văn này thành một câu."

Động não: Động não yêu cầu mô hình giúp người dùng nghĩ ra những ý tưởng sáng tạo dựa trên ngữ cảnh hiện tại và hướng dẫn của người dùng. Một hướng dẫn động não điển hình là: "Xin hãy cho tôi 5 mô tả nhân vật có thể cho một kẻ phản diện xuất hiện trong chương tiếp theo, bao gồm tên, ngoại hình, nghề nghiệp và xuất thân của anh ta."

Đánh giá: Đánh giá đề cập đến nhiệm vụ đọc và phân tích một đoạn văn bản đã cho một cách phê phán và sau đó đưa ra nhận xét hoặc đề xuất sửa đổi. Ví dụ, một người có thể yêu cầu mô hình "Xin hãy xem qua bài luận của tôi và liệt kê 5 đề xuất để cải thiện nó."

3.1.2. Chú thích Hướng dẫn

Chúng tôi cũng huấn luyện Weaver để hỗ trợ nhiệm vụ chú thích hướng dẫn. Như được mô tả trong Humpback (Li et al., 2023) và LongForm (Köksal et al., 2023), cho một đoạn văn bản, nhiệm vụ yêu cầu mô hình tạo ra một hướng dẫn mà các văn bản đầu vào có thể là câu trả lời. Tuy nhiên, dịch ngược hướng dẫn vani chỉ hỗ trợ nhiệm vụ viết. Do đó, đối với chú thích hướng dẫn, chúng tôi yêu cầu mô hình tổng hợp một cặp hướng dẫn-phản hồi dựa trên một đoạn văn bản. Phản hồi có thể là đoạn văn bản, một phần của đoạn văn bản, hoặc được suy ra từ đoạn văn bản. Điều này mở rộng đáng kể phạm vi cho dịch ngược hướng dẫn vani vì hầu hết các đoạn văn bản được khai thác tự động có thể không phù hợp cho một hướng dẫn nhất định về bản thân nó trong khi một phần của đoạn văn bản có thể là phản hồi hợp lệ hoặc một người có thể xây dựng một cặp hướng dẫn-phản hồi chất lượng cao dựa trên nó. Khả năng chú thích hướng dẫn cho phép Weaver khai thác dữ liệu huấn luyện cho chính nó trên kho dữ liệu quy mô lớn, mở ra khả năng tự huấn luyện có thể mở rộng trên dữ liệu web.

3.1.3. Đánh giá (Phê bình Văn học)

Nhiều nghiên cứu gần đây đã khám phá việc sử dụng hoặc huấn luyện LLM để đánh giá các nhiệm vụ tuân theo hướng dẫn chung (Chan et al., 2023; Jiang et al., 2023b; Wang et al., 2023b). Tuy nhiên, chúng tôi thấy rằng các LLM tổng quát yêu cầu kỹ năng prompting mở rộng để làm cho chúng phù hợp để đánh giá các nhiệm vụ liên quan đến viết sáng tạo. Hơn nữa, vì hầu như tất cả sinh viên chuyên ngành viết sáng tạo cũng được yêu cầu tham gia các khóa học phê bình văn học, chúng tôi nghĩ rằng học cách thực hiện phê bình văn học có thể hữu ích cho mô hình để tạo ra văn bản tốt hơn. Do đó, chúng tôi cũng huấn luyện Weaver để đánh giá chất lượng của các phản hồi đối với hướng dẫn viết và thực hiện so sánh theo cặp của hai phản hồi.

Chúng tôi thu thập sở thích của con người giữa các đầu ra mô hình trong WawaWriter, nền tảng viết hỗ trợ AI của chúng tôi và chuyển đổi dữ liệu sở thích đã thu thập thành dữ liệu huấn luyện cho đánh giá dựa trên LLM với các mẫu được tuyển chọn cẩn thận.

3.1.4. Tạo Tăng cường Tìm kiếm

Khả năng tạo tăng cường tìm kiếm (RAG) (Gao et al., 2023; Lewis et al., 2020), tức là tạo phản hồi bằng cách tham khảo tri thức hoặc tham chiếu bên ngoài làm ngữ cảnh. RAG là một kỹ thuật quan trọng giúp LLM tạo ra các phản hồi chính xác và có thông tin hơn. Nó có thể đặc biệt hữu ích cho mục đích viết vì thông thường các nhà văn con người tham khảo các mẫu văn bản khác khi viết tiểu thuyết hoặc bài báo. Tuy nhiên, hầu hết LLM hiện có chỉ dựa vào kỹ thuật prompt để thực hiện RAG và không thực hiện huấn luyện RAG trong quá trình căn chỉnh. Chúng tôi tin rằng điều này hạn chế khả năng của LLM trong việc sử dụng ngữ cảnh đã tìm kiếm. Do đó, chúng tôi đề xuất bao gồm dữ liệu huấn luyện có nhận thức RAG trong quá trình căn chỉnh để tăng cường khả năng tạo tăng cường tìm kiếm của Weaver. Cụ thể, chúng tôi tăng cường 10% dữ liệu huấn luyện bằng cách thêm ngữ cảnh liên quan được thu được bằng cách tìm kiếm đoạn văn tương tự nhất với phản hồi mục tiêu. Bằng cách này, Weaver học cách viết bằng cách tham khảo ngữ cảnh bên ngoài và do đó tương thích hơn với các kỹ thuật RAG so với hầu hết LLM hiện có.

3.1.5. Gọi Hàm

Khả năng sử dụng công cụ cũng rất quan trọng đối với LLM (Schick et al., 2023). Khả năng này, còn được gọi là "gọi hàm", cũng hữu ích cho viết vì mô hình có thể cần tìm kiếm internet để tìm tham chiếu hoặc gọi API trình chỉnh sửa khi thực hiện viết hợp tác giữa con người và AI. Để mở khóa khả năng gọi hàm, chúng tôi bao gồm một tập dữ liệu gọi hàm mã nguồn mở² vào dữ liệu tinh chỉnh có giám sát. Chúng tôi cũng đề xuất một quy trình mới để tổng hợp dữ liệu gọi hàm đa dạng hơn bằng cách đầu tiên sử dụng GPT-4 để tổng hợp các môi trường đa dạng với nhiều công cụ và API, cũng như tài liệu của chúng. Sau đó chúng tôi chọn ngẫu nhiên một API tại một thời điểm và yêu cầu GPT-4 tưởng tượng một tình huống mà API có thể hữu ích và các đối số hợp lý cho API. Sau đó chúng tôi lý luận xem một người có thể hướng dẫn LLM trong tình huống đó như thế nào để API nên được sử dụng với các đối số. Cuối cùng, tương tự như cách GPT hỗ trợ gọi hàm, chúng tôi huấn luyện Weaver sử dụng công cụ bằng cách chọn API đúng và tạo ra các đối số được đưa ra hướng dẫn và ngữ cảnh.

3.2. Dịch ngược Hướng dẫn

Sau đó chúng tôi mô tả quy trình cải tiến được đề xuất của chúng tôi cho dịch ngược hướng dẫn. Động lực để thực hiện dịch ngược hướng dẫn thay vì các phương pháp tăng cường hướng dẫn như self-

²https://huggingface.co/glaiveai

--- TRANG 9 ---
[Bảng 2|Mô tả về nguồn dữ liệu SFT. Chúng tôi kết hợp các lĩnh vực phụ tương tự trong các lĩnh vực giống nhau để đơn giản. Toàn bộ tập huấn luyện bao gồm 34 lĩnh vực phụ và khoảng 500.000 cặp hướng dẫn-đầu ra. "Picked" có nghĩa là dữ liệu thô trong các lĩnh vực tương ứng được lựa chọn thủ công.]

instruct (Wang et al., 2023a) rất đơn giản: chúng tôi muốn căn chỉnh Weaver trên các văn bản chất lượng cao, có phong cách và được con người viết. Để đạt được mục tiêu này, chúng tôi trước tiên thu thập các truyện, chương tiểu thuyết và bản sao chất lượng cao của các lĩnh vực khác nhau. Chúng tôi liệt kê các loại văn bản được thu thập trong Bảng 2.

Sau đó chúng tôi sử dụng một mẫu prompt few-shot được thiết kế cẩn thận để tổng hợp các cặp hướng dẫn-phản hồi cho tất cả các nhiệm vụ viết đã nêu. Cụ thể, đối với mỗi cặp lĩnh vực phụ-nhiệm vụ, chúng tôi chú thích 5 trường hợp về cách một người có thể viết một cặp hướng dẫn-phản hồi, bao gồm cả kết quả chú thích và lý do cho quá trình chú thích: chúng tôi trước tiên chọn một đoạn văn bản từ một trường hợp làm đầu ra (ngoại trừ các nhiệm vụ tạo dàn ý, động não và đánh giá trong đó đầu ra được biến đổi từ đoạn văn bản đã chọn với một prompt bổ sung). Sau đó chúng tôi xác định hoặc tạo ra ngữ cảnh cho đầu ra. Ví dụ, đối với nhiệm vụ chỉnh sửa, ngữ cảnh nên là một phiên bản tệ hơn của đầu ra mục tiêu, vì vậy chúng tôi có thể sửa đổi từ ngữ và cấu trúc của đầu ra mục tiêu để làm cho nó trông tệ hơn. Sau đó chúng tôi suy ra hướng dẫn mà một người có thể sử dụng để biến đổi ngữ cảnh thành đầu ra. Lấy nhiệm vụ chỉnh sửa làm ví dụ một lần nữa, chúng tôi cần lý luận về những sửa đổi nào được thực hiện và tổng hợp hướng dẫn chỉnh sửa tương ứng. Đối với mỗi trường hợp chưa được gán nhãn, chúng tôi sử dụng các trường hợp đã chú thích làm ví dụ few-shot và yêu cầu GPT-4 trước tiên tạo ra quá trình chú thích theo kiểu Chain-of-Thought (Wei et al., 2022) và sau đó tạo ra các cặp hướng dẫn-phản hồi được tổng hợp. Quy trình dịch ngược hướng dẫn được minh họa trong Hình 1. Chúng tôi tổng hợp 500.000 cặp hướng dẫn-phản hồi chất lượng cao trên tất cả lĩnh vực và nhiệm vụ với quy trình này. Cuối cùng, chúng tôi thực hiện quy trình lựa chọn dữ liệu hướng dẫn theo thực hành được mô tả trong (Liu et al., 2023): chúng tôi trước tiên chấm điểm tất cả các cặp hướng dẫn-phản hồi với GPT-3.5-turbo và sau đó chọn dữ liệu xếp hạng cao nhất trong mỗi cặp lĩnh vực phụ-nhiệm vụ cho tinh chỉnh có giám sát. Cụ thể, chúng tôi chấm điểm mỗi cặp hướng dẫn-phản hồi dựa trên chất lượng và tính đa dạng của hướng dẫn và mức độ liên quan giữa hướng dẫn và phản hồi.

[Hình 2|Minh họa khung DPO Hiến pháp.]

3.3. DPO Hiến pháp: Học từ Ví dụ Tiêu cực Có Nguyên tắc

Cuối cùng, chúng tôi đề xuất DPO Hiến pháp, một phương pháp căn chỉnh mới khuyến khích LLM học từ dữ liệu sở thích bao gồm các mẫu từ chính sách tối ưu và các ví dụ tiêu cực "có nguyên tắc" được tổng hợp với phản hồi AI. Phương pháp của chúng tôi kết hợp các ưu điểm của AI Hiến pháp (Bai et al., 2022; Sun et al., 2023), huấn luyện các mô hình phần thưởng dựa trên các nguyên tắc được viết bởi các chuyên gia con người, RLCD (Yang et al., 2023a), prompt LLM để tạo ra các ví dụ tích cực/tiêu cực và huấn luyện các mô hình phần thưởng với dữ liệu sở thích do AI tạo ra, và DPO (Rafailov et al., 2023), bỏ qua huấn luyện mô hình phần thưởng và thực hiện tối ưu hóa sở thích trực tiếp.

--- TRANG 10 ---
[Bảng 3|Ví dụ về các nguyên tắc được chú thích bởi chuyên gia trong bốn lĩnh vực và các nhiệm vụ được lấy mẫu.]

Cụ thể, chúng tôi đầu tiên mời các chuyên gia con người bao gồm các nhà văn, biên tập viên và người tạo nội dung chuyên nghiệp để chú thích các nguyên tắc cho các nhiệm vụ viết khác nhau. Khác với các phương pháp "dựa trên nguyên tắc" trước đây chỉ viết một mô tả ngắn về các nguyên tắc, đối với mỗi nguyên tắc chúng tôi cũng thu thập một trường hợp tuân thủ nguyên tắc và một trường hợp vi phạm nguyên tắc, cũng như lý do bằng ngôn ngữ tự nhiên giải thích tại sao các trường hợp tuân thủ hoặc vi phạm nguyên tắc. Sau đó chúng tôi lấy mẫu một tập con của dữ liệu hướng dẫn có điểm số cao nhất trong quy trình lọc dữ liệu đã nêu và coi chúng là các mẫu từ chính sách tối ưu vì các văn bản đầu ra được lựa chọn cẩn thận và các cặp hướng dẫn-đầu ra có xếp hạng cao nhất. Đối với mỗi mẫu, chúng tôi trước tiên trình bày các nguyên tắc cho nhiệm vụ và yêu cầu GPT phân tích nguyên tắc nào có thể giải thích tốt nhất tại sao phản hồi có chất lượng tốt. Sau đó chúng tôi yêu cầu GPT tổng hợp một phản hồi đối ứng vi phạm nguyên tắc trong khi thêm các sửa đổi tối thiểu và không ảnh hưởng đến các khía cạnh tốt khác của phản hồi gốc.

Với dữ liệu đã thu thập, chúng tôi coi các cặp phản hồi gốc-bị nhiễu loạn là các cặp (y_w, y_l) và thực hiện huấn luyện DPO tiêu chuẩn. Bằng cách này, mỗi cặp dữ liệu chứa các tín hiệu huấn luyện quan trọng về các nguyên tắc tương ứng và giúp tinh chỉnh mô hình để tuân theo các nguyên tắc. Dữ liệu sở thích được tổng hợp bởi phương pháp của chúng tôi chứa ít nhiễu hơn nhiều so với quy trình RLAIF tiêu chuẩn, đặc biệt trong các lĩnh vực viết vì LLM gặp khó khăn trong việc thực hiện phê bình văn học. So với RLCD, phương pháp liên quan nhất cho việc tạo dữ liệu sở thích, chúng tôi coi dữ liệu SFT chất lượng cao thay vì do LLM tạo ra làm ví dụ tích cực và sử dụng các nguyên tắc được viết bởi chuyên gia cho việc tạo ví dụ tiêu cực. Điều này làm cho tín hiệu huấn luyện ít nhiễu hơn và có nguyên tắc hơn.

--- TRANG 11 ---
4. Căn chỉnh

4.1. Tinh chỉnh Có giám sát

4.1.1. Dữ liệu
Để thu thập tập dữ liệu cho tinh chỉnh có giám sát, chúng tôi trước tiên thu thập nội dung chất lượng cao được viết bởi các nhà văn và người tạo nội dung con người theo metadata của chúng bao gồm xếp hạng, số lượt đọc, upvote và bình luận. Chúng tôi áp dụng khung tổng hợp dữ liệu đã nêu để tổng hợp dữ liệu tuân theo hướng dẫn bao gồm hơn 30 lĩnh vực chi tiết và hơn 10 nhiệm vụ, dữ liệu chú thích hướng dẫn, dữ liệu đánh giá tạo văn bản, dữ liệu tạo tăng cường tìm kiếm, và dữ liệu gọi hàm. Tập dữ liệu tinh chỉnh hướng dẫn kết hợp bao gồm khoảng 1.000.000 mẫu. Sau đó chúng tôi chạy quy trình lọc dữ liệu và chọn 400.000 điểm dữ liệu làm tập dữ liệu cuối cùng cho tinh chỉnh có giám sát.

4.1.2. Huấn luyện
Chúng tôi tinh chỉnh các mô hình đã được huấn luyện trước liên tục trong 3 đến 5 epochs. Chúng tôi sử dụng bộ lập lịch tốc độ học cosin với tốc độ học đỉnh 1e-5 và 2e-5 cho các mô hình lớn hơn (tức là Weaver Ultra và Weaver Pro) và 4e-5 cho các mô hình nhỏ hơn (tức là Weaver Base và Weaver Mini) với 5% bước khởi động. Chúng tôi huấn luyện tất cả mô hình với kích thước lô toàn cầu 256. Sau khi tinh chỉnh có giám sát, chúng tôi chọn checkpoint hoạt động tốt nhất trên tập xác thực nội bộ cho tối ưu hóa sở thích.

4.2. Tối ưu hóa Sở thích

4.2.1. Dữ liệu
Đối với tối ưu hóa sở thích, chúng tôi chọn 500 mẫu được xếp hạng cao nhất trong giai đoạn lọc dữ liệu cho mỗi lĩnh vực phụ làm ví dụ tích cực cho quy trình DPO Hiến pháp. Chúng tôi thu thập hơn 200 nguyên tắc và các ví dụ few-shot tương ứng của chúng. Chúng tôi tạo ra một ví dụ tiêu cực cho mỗi ví dụ tích cực, dẫn đến 25.000 cặp dữ liệu sở thích.

4.2.2. Huấn luyện
Chúng tôi tinh chỉnh các mô hình đã được tinh chỉnh có giám sát bằng thuật toán DPO thông thường. Chúng tôi huấn luyện các mô hình của mình trong ba đến năm epochs. Chúng tôi sử dụng bộ lập lịch tốc độ học tuyến tính với tốc độ học đỉnh 5e-7 và 5% bước khởi động. Chúng tôi huấn luyện Weaver Ultra sử dụng kích thước lô toàn cầu 40, trong khi đối với các mô hình khác chúng tôi sử dụng 32 và đặt β = 0.1. Chúng tôi chọn checkpoint hoạt động tốt nhất trên tập xác thực nội bộ làm các mô hình Weaver cuối cùng.

5. Đánh giá

5.1. WriteBench
Hầu hết các benchmark hiện có cho LLM (Zheng et al., 2023a) và tạo ngôn ngữ tự nhiên (Jiang et al., 2023c; Lin et al., 2020) tập trung vào khả năng lý luận hoặc khả năng tuân theo hướng dẫn đa mục đích thay vì khả năng của LLM trong việc tạo ra nội dung văn bản sáng tạo, có phong cách và giống con người. Vì mục đích này, chúng tôi xây dựng WriteBench, một benchmark mới để đánh giá khả năng viết của LLM³.

Tương tự như cách chúng tôi thu thập dữ liệu huấn luyện cho Weaver, WriteBench được thiết kế để bao gồm nhiều lĩnh vực và nhiệm vụ. Để đảm bảo so sánh công bằng giữa Weaver và các LLM tổng quát được so sánh, quá trình thu thập dữ liệu và lựa chọn dữ liệu cho các hướng dẫn trong WriteBench được thực hiện bởi nhóm đánh giá độc lập của chúng tôi. WriteBench kết quả bao gồm hơn 1000 hướng dẫn kiểm tra bao gồm bốn lĩnh vực bao gồm viết tiểu thuyết, viết phi tiểu thuyết sáng tạo, viết kỹ thuật và viết marketing. Bản phát hành đầu tiên của benchmark WriteBench bằng tiếng Trung vì chúng tôi muốn đo lường khả năng viết tiếng Trung của các mô hình được so sánh.

5.2. Mô hình So sánh
Chúng tôi so sánh Weaver với các LLM tiếng Trung cạnh tranh bao gồm cả mô hình mã nguồn mở và mô hình độc quyền có kích cỡ khác nhau, bao gồm GPT-4, GPT-3.5, GLM-4, Claude2, Gemini Pro, ERNIE-Bot-4.0, ERNIE-Bot-3.5, Qwen-72B-Chat, Qwen-14B-Chat, Qwen-7B-Chat, Qwen-1.8B-Chat, YI-34B-Chat, YI-6B-Chat, và ChatGLM3-6B. Chúng tôi trực tiếp sử dụng các hướng dẫn giống nhau trong WriteBench làm prompt đầu vào cho tất cả LLM được kiểm tra và thu thập đầu ra mô hình làm phản hồi.

[Bảng 4|Kết quả Đánh giá dựa trên LLM]

5.3. Đánh giá dựa trên LLM
Chúng tôi trước tiên thực hiện đánh giá dựa trên LLM để thực hiện đánh giá thô về các mô hình được so sánh. Chúng tôi sử dụng GPT-4 làm thẩm phán để chấm điểm từng cặp hướng dẫn-phản hồi theo thực hành và mẫu prompt trong MT-Bench. Kết quả được thể hiện trong Bảng 4. Chúng tôi thấy rằng về phong cách viết và sự sáng tạo, Weaver Ultra vượt trội đáng kể so với tất cả các mô hình độc quyền bao gồm các đối thủ mạnh như GPT-4 và GLM-4. GPT-4 và GLM-4 tốt hơn ở chỉ số liên quan vì chúng ít nhất cũng lớn hơn vài lần so với Weaver Ultra và do đó có khả năng tuân theo hướng dẫn tốt hơn. Đối với Weaver các kích cỡ khác, chúng ta có thể thấy rằng chỉ với 14B tham số, Weaver Pro vượt trội so với tất cả mô hình mã nguồn mở bao gồm những mô hình có 70B và 34B tham số, cũng như hầu hết các mô hình độc quyền. Tương tự, Weaver Base và Weaver Mini cũng có thể so sánh với các LLM tổng quát có kích cỡ hơn hai lần. Nhìn chung, kết quả xác nhận hiệu quả của khung tổng hợp dữ liệu và huấn luyện của chúng tôi cho LLM chuyên biệt về viết sáng tạo.

³WriteBench sẽ được công bố tại https://github.com/aiwaves-cn/WriteBench

--- TRANG 12 ---
[Bảng 5|Sở thích Con người về Viết Tiểu thuyết với Hệ thống Xếp hạng Elo]

[Bảng 6|Sở thích Con người Tổng thể với Hệ thống Xếp hạng Elo]

5.4. Đánh giá của Con người
Sau đó chúng tôi thực hiện đánh giá của con người để so sánh Weaver với một số LLM đại diện bao gồm GPT-4, GLM-4, ERNIE-Bot-4.0, và Gemini-pro. Chúng tôi tuyển dụng 44 nhà văn hoặc biên tập viên tiếng Trung chuyên nghiệp làm chú thích viên con người trong đánh giá của con người. Chúng tôi áp dụng thực hành trong benchmark ChatBot Arena⁴ và để các chú thích viên con người thực hiện so sánh theo cặp ba chiều giữa hai đầu ra mô hình theo sự sáng tạo, phong cách, liên quan và trôi chảy của chúng. Chúng tôi thu thập 3540 kết quả so sánh và tính toán xếp hạng ELO của các mô hình được so sánh. Kết quả về viết tiểu thuyết và so sánh tổng thể được thể hiện trong Bảng 5 và Bảng 6 tương ứng. Chúng ta có thể thấy rằng các nhà văn và biên tập viên chuyên nghiệp đánh giá Weaver Ultra tốt hơn đáng kể so với các mô hình được so sánh trên tất cả các chỉ số. Đối với các mô hình được so sánh khác, chúng tôi thấy rằng GPT-4 và Gemini Pro được coi là tạo ra văn bản sáng tạo và giống con người hơn so với GLM-4 và ERNIE-Bot, chúng tôi nghi ngờ điều này là do GLM và ERNIE được căn chỉnh bằng dữ liệu chưng cất GPT, có thể gây hại cho sự sáng tạo của chúng.

5.5. Nghiên cứu Người dùng
Một LLM tốt cho viết hỗ trợ AI không chỉ nên hoạt động tốt nhất trên các benchmark mà còn thực sự hữu ích trong các tình huống viết thực tế. Để đánh giá Weaver thực sự hữu ích như thế nào, chúng tôi tiến hành một nghiên cứu người dùng trong đó 5 nhà văn chuyên nghiệp được tuyển dụng làm đối tượng. Mỗi đối tượng được cung cấp hai giao diện trò chuyện, một với Weaver Ultra và một với GPT-4. Sau đó chúng tôi để mỗi đối tượng viết hai truyện ngắn (với hai chủ đề được lựa chọn cẩn thận) khoảng 6.000 từ với hai giao diện trò chuyện giống nhau được hỗ trợ bởi GPT-4 và Weaver Ultra tương ứng⁵. Chúng tôi đo thời gian sử dụng bởi cùng một nhà văn để hoàn thành hai câu chuyện và yêu cầu một biên tập viên chuyên nghiệp đánh giá chất lượng của chúng. Chúng tôi thấy rằng so với GPT-4, Weaver Ultra cải thiện hiệu quả của nhà văn khoảng 3 lần. Hơn nữa, trong số 5 chủ đề, biên tập viên con người thích câu chuyện do Weaver tạo ra 4 lần và không thể quyết định người chiến thắng cho chủ đề còn lại. Cuộc phỏng vấn người dùng của chúng tôi tiết lộ rằng cải thiện hiệu quả chủ yếu đến từ việc Weaver nhanh hơn và tạo ra văn bản giống con người hơn đòi hỏi ít chỉnh sửa sau đó.

⁴https://chat.lmsys.org/
⁵Để đảm bảo so sánh công bằng, chúng tôi cung cấp đủ thời gian và thử nghiệm để các nhà văn làm quen với giao diện và các mô hình.

--- TRANG 13 ---
6. Giới thiệu WawaWriter

Trong phần này, chúng tôi mô tả WawaWriter, một nền tảng viết hỗ trợ AI thế hệ tiếp theo mà chúng tôi xây dựng để phát huy đầy đủ khả năng của Weaver. WawaWriter tích hợp các tính năng chính của các nền tảng viết hỗ trợ AI gần đây (ví dụ: Notion AI) bao gồm tạo, chỉnh sửa và tóm tắt hỗ trợ AI trong khi cũng triển khai một số đổi mới mới cho trải nghiệm viết AI thế hệ tiếp theo. Chúng tôi mô tả những đổi mới này trong các phần sau.

6.1. Viết Hợp tác giữa Con người và AI
Một đổi mới lớn trong WawaWriter là giao diện mới cho viết hợp tác giữa con người và AI, mang lại trải nghiệm người dùng hoàn toàn khác so với các nền tảng viết hỗ trợ AI truyền thống. Nhờ khung Agents (Zhou et al., 2023b), chúng tôi có thể xây dựng các tác nhân viết có thể kiểm soát hoạt động như các cộng tác viên/đồng tác giả con người độc lập trong các trình chỉnh sửa hợp tác tiêu chuẩn như Google Docs hoặc Notion. Các tác nhân viết hiểu mục tiêu của tài liệu hiện tại bằng cách đọc các cài đặt tùy chỉnh như tiêu đề hoặc mô tả ngắn về tài liệu. Sau đó nó thực hiện các hành động theo nội dung hiện tại trong tài liệu và các hành động gần đây của người dùng con người (hoặc các tác nhân viết khác) tiết lộ trọng tâm của họ. Người dùng con người cũng có thể trò chuyện với các tác nhân viết trong giao diện trò chuyện để hướng dẫn chúng làm gì. Khả năng của các tác nhân viết sử dụng cả API bên ngoài như tìm kiếm web và API trình chỉnh sửa tích hợp như in đậm hoặc điều chỉnh khoảng cách dòng cho phép chúng hoàn thành các nhiệm vụ phức tạp hơn nhiều so với những gì các trợ lý AI thông thường có thể làm. Với tính năng tương tác giữa con người và tác nhân trong khung Agents, WriteBench cũng hỗ trợ chỉnh sửa hợp tác giữa nhiều nhà văn con người và tác nhân ngôn ngữ. Người dùng có thể tùy chỉnh nhiều tác nhân viết của họ và hợp tác với một hoặc vài trong số chúng khi viết truyện hoặc bài báo. Người dùng có thể chỉ định nhiệm vụ cho mỗi tác nhân viết trong khi nhiều tác nhân viết cũng có thể giao tiếp với nhau để phân phối lao động một cách tự động.

6.2. Tích hợp Tri thức và Công cụ Bên ngoài
Một tính năng mới khác của WawaWriter là người dùng giờ đây có thể xây dựng cơ sở tri thức cá nhân của riêng họ thông qua tải lên tài liệu hoặc lưu trang web. WawaWriter tự động tổ chức và tóm tắt cơ sở tri thức và sau đó sử dụng chúng làm tham chiếu khi viết truyện và bài báo. Cụ thể, chúng tôi prompt một LLM để chia tài liệu thành các đoạn dựa trên ngữ nghĩa của chúng, nhúng chúng với mô hình nhúng của chúng tôi, và lưu trữ chúng trong VectorDB. Trong quá trình viết, chúng tôi truy xuất động các mục của cơ sở tri thức cá nhân của người dùng bằng tìm kiếm ngữ nghĩa sử dụng ngữ cảnh hiện tại trong trình chỉnh sửa của người dùng làm truy vấn. Theo Socratic Models (Zeng et al., 2023), cơ sở tri thức của chúng tôi cũng hỗ trợ hình ảnh trong tài liệu bằng cách sử dụng GPT-4V để thực hiện chú thích chi tiết cho mỗi hình ảnh và sau đó sử dụng các chú thích làm mục đại diện cho các hình ảnh tương ứng. Người dùng cũng có thể chỉnh sửa các tài liệu trong cơ sở tri thức cá nhân của họ bằng tất cả các tính năng viết AI trong WawaWriter. Ngoài ra, các tác nhân viết được mô tả trong phần trước cũng có thể truy cập cơ sở tri thức cá nhân của người dùng thông qua gọi hàm.

6.3. Hỗ trợ Viết Cá nhân hóa
Khác với các hệ thống viết hỗ trợ AI hiện tại, WawaWriter cung cấp hỗ trợ viết cá nhân hóa cho các người dùng khác nhau phù hợp với phong cách viết và sở thích nội dung của họ. Để đạt được điều này, chúng tôi duy trì một hồ sơ người dùng dựa trên văn bản cho mỗi người dùng mô tả một số thói quen và phong cách viết cơ bản (ví dụ: lựa chọn từ và dấu câu, sở thích về độ dài câu, v.v.) của người dùng. Hồ sơ người dùng được cập nhật định kỳ bằng LLM theo các văn bản gần đây được viết bởi người dùng với một prompt được thiết kế cẩn thận. Hồ sơ người dùng sau đó được sử dụng làm tiền tố trong prompt cho Weaver. Ngoài hồ sơ người dùng dựa trên văn bản, chúng tôi cũng truy xuất các đoạn văn tương tự nhất với ngữ cảnh hiện tại trong trình chỉnh sửa và sử dụng chúng làm tham chiếu cho RAG.

--- TRANG 14 ---
6.4. Tạo Văn bản Dài Vô hạn
WawaWriter cũng hỗ trợ tạo văn bản dài vô hạn vì Weaver hỗ trợ tự nhiên kỹ thuật prompting tái diễn được đề xuất bởi (Zhou et al., 2023a). Cụ thể, để tạo ra một văn bản rất dài, chúng tôi lặp đi lặp lại prompt Weaver để tạo ra dàn ý dựa trên ngữ cảnh hiện tại và sau đó tạo ra một đoạn văn bản dựa trên dàn ý đã tạo. WawaWriter tích hợp chế độ "từng bước" và chế độ "liên tục" trong RecurrentGPT, trong đó dàn ý tiếp theo được chọn thủ công bởi người dùng hoặc tự động chọn bởi LLM. Như đã thảo luận trong Zhou et al. (2023a), cơ chế prompting tái diễn này cải thiện đáng kể tính sáng tạo, nhất quán và liên quan của văn bản dài được tạo ra, điều này đặc biệt hữu ích cho việc viết truyện/tiểu thuyết với WawaWriter.

7. Thảo luận

Trong báo cáo kỹ thuật này, chúng tôi giới thiệu Weaver, một gia đình LLM chuyên biệt cho các nỗ lực viết. Weaver được huấn luyện trước liên tục trên các tập dữ liệu được tuyển chọn cẩn thận và sau đó được căn chỉnh với sở thích của các nhà văn và biên tập viên chuyên nghiệp bằng một khung tổng hợp dữ liệu mới. Chúng tôi cũng phát hành WriteBench, benchmark đầu tiên để đánh giá khả năng viết của LLM. WriteBench bao gồm nhiều lĩnh vực và nhiệm vụ liên quan đến viết. Chúng tôi so sánh Weaver với hơn 10 LLM tổng quát phổ biến và thấy rằng Weaver Ultra là hiện đại nhất trên benchmark. Nghiên cứu người dùng của chúng tôi cũng xác nhận sự vượt trội của Weaver trong các tình huống viết hỗ trợ AI thực tế. Kết quả cũng xác nhận hiệu quả của quy trình tổng hợp dữ liệu của chúng tôi cho việc huấn luyện LLM chuyên biệt theo lĩnh vực.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo dài được bỏ qua để tiết kiệm không gian]

--- TRANG 15-27 ---
[Các trang còn lại chứa tài liệu tham khảo và phụ lục, bao gồm các nghiên cứu trường hợp bằng tiếng Trung được dịch sang tiếng Việt]

A. Phụ lục

A.1. Đóng góp của Tác giả
[Mô tả chi tiết đóng góp của từng tác giả]

A.2. Lời cảm ơn
Chúng tôi muốn cảm ơn Canwen Xu vì cuộc thảo luận sâu sắc, sự giúp đỡ trong việc sửa đổi bản thảo, và đặc biệt vì đề xuất của anh ấy về việc đặt tên bài báo. Chúng tôi cũng muốn cảm ơn APUS vì sự hỗ trợ về tài nguyên tính toán, ABAKA.AI vì sự hỗ trợ trong việc thu thập dữ liệu, và Đại học Chiết Giang vì sự hỗ trợ chung.

A.3. Nghiên cứu Trường hợp
Chúng tôi trình bày một số nghiên cứu trường hợp về nội dung được tạo bởi Weaver Ultra và GPT-4:

[Các ví dụ tiếng Trung được dịch sang tiếng Việt, bao gồm các dàn ý kinh doanh, câu chuyện sáng tạo và các ví dụ văn bản khác nhau]

# 2306.14905.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/writing/2306.14905.pdf
# Kích thước tệp: 577229 byte

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
PRISMA-DFLLM: Mở rộng PRISMA cho Đánh giá Tài liệu Hệ thống sử dụng Mô hình Ngôn ngữ Lớn được Tinh chỉnh theo Lĩnh vực cụ thể
Teo Susnjak*
Trường Khoa học Toán học và Tính toán
Đại học Massey
Auckland, New Zealand
28 tháng 6, 2023
Tóm tắt
Với sự phổ biến của các Mô hình Ngôn ngữ Lớn (LLM) mã nguồn mở và các kỹ thuật tinh chỉnh hiệu quả, chúng ta đang ở ngưỡng cửa của sự xuất hiện của nhiều LLM theo lĩnh vực cụ thể đã được tinh chỉnh để có chuyên môn trên các lĩnh vực và ứng dụng chuyên biệt mà các LLM đa năng hiện tại không phù hợp. Trong học thuật, công nghệ này có tiềm năng cách mạng hóa cách chúng ta tiến hành đánh giá tài liệu hệ thống (SLR), tiếp cận kiến thức và tạo ra những hiểu biết mới. Bài báo này đề xuất một khung phương pháp luận được hỗ trợ bởi AI kết hợp sức mạnh của LLM với các hướng dẫn báo cáo nghiêm ngặt của Các Mục Báo cáo Ưa thích cho Đánh giá Hệ thống và Phân tích Meta (PRISMA). Bằng cách tinh chỉnh LLM trên các bài báo học thuật theo lĩnh vực cụ thể đã được chọn lựa từ một quy trình SLR nghiêm ngặt, các hướng dẫn báo cáo PRISMA-DFLLM (cho LLM Tinh chỉnh theo Lĩnh vực cụ thể) được đề xuất mang lại tiềm năng đạt được hiệu quả, khả năng tái sử dụng và khả năng mở rộng lớn hơn, đồng thời mở ra tiềm năng tiến hành các đánh giá tài liệu hệ thống sống gia tăng với sự hỗ trợ của LLM. Ngoài ra, phương pháp được đề xuất để tận dụng LLM cho SLR cho phép phổ biến các mô hình đã được tinh chỉnh, trao quyền cho các nhà nghiên cứu để đẩy nhanh tiến bộ và dân chủ hóa nghiên cứu tiên tiến. Bài báo này trình bày lý lẽ cho tính khả thi của LLM được tinh chỉnh để hỗ trợ SLR nghiêm ngặt và các yêu cầu kỹ thuật để thực hiện điều này. Công trình này sau đó đề xuất danh sách kiểm tra PRISMA-DFLLM mở rộng của các hướng dẫn báo cáo cũng như các lợi thế, thách thức và tác động tiềm năng của việc thực hiện PRISMA-DFLLM. Cuối cùng, một lộ trình nghiên cứu tương lai để phát triển hướng nghiên cứu SLR được hỗ trợ bởi AI này được trình bày, mở đường cho một kỷ nguyên mới của tổng hợp bằng chứng và khám phá kiến thức.

Từ khóa- đánh giá tài liệu hệ thống, đánh giá tài liệu sống, PRISMA, mô hình ngôn ngữ lớn, GPT, học chuyển đổi, tự động hóa đánh giá tài liệu, tổng hợp bằng chứng, trí tuệ nhân tạo

1 Giới thiệu
Sự mở rộng nhanh chóng của tài liệu học thuật trên các lĩnh vực khác nhau đặt ra một thách thức đáng kể cho các nhà nghiên cứu tìm cách thực hiện tổng hợp bằng chứng trên khối lượng kiến thức rộng lớn có sẵn [15] (tham khảo Hình 1). Các đánh giá tài liệu hệ thống (SLR) đã nổi lên như những công cụ không thể thiếu cho nghiên cứu dựa trên bằng chứng, cung cấp tổng quan toàn diện, tổng hợp kiến thức hiện có và xác định các khoảng trống. Tuy nhiên, phương pháp thủ công truyền thống để tiến hành SLR không chỉ tốn nhiều lao động và tài nguyên mà còn dễ có thiên kiến. Hơn nữa, nó đại diện cho một công việc độc lập không dễ dàng tái sử dụng, cập nhật gia tăng hoặc mở rộng bởi các nhà nghiên cứu khác khi có tài liệu mới xuất hiện. Với khối lượng tài liệu ngày càng tăng, có nhu cầu cấp thiết cho các phương pháp hiệu quả và có thể mở rộng hơn để tiến hành đánh giá tài liệu mạnh mẽ và tổng hợp kiến thức.

SLR là các phương pháp nghiên cứu nghiêm ngặt được thiết kế để xác định, đánh giá và tổng hợp các nghiên cứu hiện có về một câu hỏi nghiên cứu cụ thể. Chúng được đánh giá cao vì phương pháp có cấu trúc và toàn diện, nhằm giảm thiểu thiên kiến và thúc đẩy tính minh bạch và khả năng sao chép. Các tiêu chuẩn báo cáo, như Tuyên bố PRISMA (Các Mục Báo cáo Ưa thích cho Đánh giá Hệ thống và Phân tích Meta) và các mở rộng năm 2020 gần đây của nó [23], cung cấp hướng dẫn dựa trên bằng chứng để đạt được SLR chất lượng cao tối đa hóa tính minh bạch và báo cáo toàn diện. Lộ trình [25] mà nó cung cấp hỗ trợ các tác giả mô tả chính xác phương pháp nghiên cứu, phát hiện và phương pháp dự kiến của họ cho các giao thức đánh giá. Số lượng SLR và đánh giá PRISMA ngày càng tăng (Hình 2a và 2b) nhấn mạnh tính hữu ích của chúng và cho thấy nhu cầu về các chiến lược hiệu quả hơn để hỗ trợ các nhà nghiên cứu.

*Email: t.susnjak@massey.ac.nz
1arXiv:2306.14905v1  [cs.CL]  15 Jun 2023

--- TRANG 2 ---
Mở rộng PRISMA sử dụng Mô hình Ngôn ngữ Lớn Tinh chỉnh theo Lĩnh vực cụ thể

Hình 1: Số lượng báo cáo [5] các bài báo học thuật được xuất bản trong 5 năm qua.

Trong khi khung PRISMA đã đóng góp rất lớn vào việc nâng cao tính minh bạch và chất lượng báo cáo của các đánh giá hệ thống, điều quan trọng là phải thừa nhận một số hạn chế, khó khăn và ràng buộc nhất định liên quan đến việc thực hiện nó. Tuân thủ các đề xuất PRISMA và tiến hành tổng hợp bằng chứng đòi hỏi đầu tư đáng kể về thời gian, công sức và tài nguyên [23,14]. Các nhà nghiên cứu cần thực hiện tìm kiếm tài liệu toàn diện, áp dụng tiêu chí lựa chọn nghiên cứu nghiêm ngặt, trích xuất dữ liệu và tổng hợp phát hiện, điều này có thể là một quá trình tốn nhiều tài nguyên. Điều này đặt ra thách thức, đặc biệt đối với các nhà nghiên cứu có thời gian hoặc tài trợ hạn chế. Hơn nữa, một khi công việc hoàn thành, các cập nhật liên tục và gia tăng thường không được thực hiện, và một đánh giá mới trong một lĩnh vực nhất định thường được tiến hành vài năm sau đó, ngay cả bởi cùng một nhóm tác giả. Các đánh giá tiếp theo bởi cùng các nhóm chỉ có được hiệu quả nhỏ từ công việc trước đó của họ, vì các câu hỏi nghiên cứu mới đòi hỏi mỗi nghiên cứu phải được xem xét lại một cách kỹ lưỡng một lần nữa.

Mặc dù có phương pháp báo cáo nghiêm ngặt được nêu trong PRISMA, giống như bất kỳ nghiên cứu nào, các đánh giá hệ thống cũng dễ bị thiên kiến, sai sót và báo cáo có chọn lọc [23,14]. Thiên kiến xuất bản, nơi các nghiên cứu có kết quả tích cực hoặc có ý nghĩa thống kê có nhiều khả năng được xuất bản hơn, có thể dẫn đến việc đánh giá quá cao tác động điều trị trong bối cảnh y tế. Ngoài ra, việc lựa chọn có chọn lọc các nghiên cứu dựa trên tiêu chí cụ thể có thể đưa vào thiên kiến và làm tổn hại tính toàn diện của đánh giá. Kolaski và cộng sự [14] lưu ý rằng PRISMA, là một hướng dẫn báo cáo cho các đánh giá hệ thống, có giá trị nhất khi được tham khảo trong quá trình phát triển đánh giá thay vì chỉ là một danh sách kiểm tra cho việc nộp tạp chí. Nó đánh giá tính đầy đủ của báo cáo nhưng không đánh giá chất lượng hoặc hiệu suất của chính đánh giá đó. Do đó, không thể giả định rằng việc tuân thủ nghiêm ngặt các hướng dẫn PRISMA một mình đảm bảo một đánh giá hệ thống nghiêm ngặt.

Các đánh giá hệ thống sử dụng hướng dẫn PRISMA nhằm tổng hợp bằng chứng có sẵn một cách khách quan. Tuy nhiên, việc diễn giải bằng chứng và rút ra kết luận chính xác có thể phức tạp [23]. Ngoài ra, Page và cộng sự [23] lưu ý rằng khi cả phương pháp nghiên cứu và tiến bộ công nghệ tiếp tục phát triển nhanh chóng, khung PRISMA cần được cập nhật để đảm bảo tính liên quan và khả năng áp dụng của nó. Các tác giả nêu rằng các cập nhật và thích ứng thường xuyên để kết hợp các phương pháp mới nổi, như học máy hoặc phân tích meta mạng, là cần thiết để giải quyết nhu cầu phát triển của các đánh giá hệ thống. Với tác động vô cùng đột phá mà những tiến bộ và phát hành gần đây của các công nghệ AI sinh tạo đã có cả trong học thuật và xa hơn nữa, đã đến lúc xem xét làm thế nào PRISMA và các đánh giá tài liệu hệ thống có thể được trao quyền bởi AI để cho phép và đẩy nhanh nghiên cứu tương lai.

1.1 Đánh giá Hệ thống Sống
Các đánh giá hệ thống sống (LSR) là một phương pháp tương đối mới cho đánh giá tài liệu được thiết kế để cung cấp tổng hợp bằng chứng năng động và cập nhật hơn. Chúng đặc biệt hữu ích cho các chủ đề mà cơ sở bằng chứng đang phát triển nhanh chóng, và các cập nhật thường xuyên có khả năng dẫn đến thay đổi về quy mô hoặc hướng tác động. Điều này làm cho chúng có tính liên quan cao đối với các yêu cầu chính sách đòi hỏi cập nhật thường xuyên do nhu cầu kiến thức thay đổi [7].

Trong một LSR, các quá trình tìm kiếm tài liệu và trích xuất dữ liệu được cập nhật liên tục để kết hợp bằng chứng mới khi nó có sẵn. Điều này tương phản với các đánh giá hệ thống truyền thống, cung cấp một bức tranh về bằng chứng tại một thời điểm cụ thể. Do đó, LSR cung cấp tổng quan hiện tại và toàn diện hơn về cơ sở bằng chứng, có thể đặc biệt có giá trị trong các lĩnh vực nghiên cứu phát triển nhanh hoặc để đáp ứng các quyết định chính sách hoặc thực hành khẩn cấp [7] đòi hỏi các công cụ và công nghệ mới để cho phép điều này. Tầm quan trọng của LSR ngày càng được cộng đồng nghiên cứu thừa nhận, nơi chúng được coi là có giá trị nhất trong các lĩnh vực có mức độ không chắc chắn cao, và nghiên cứu mới có khả năng ảnh hưởng đến kết luận của đánh giá [7]. Ví dụ, Cochrane Collaboration, một mạng lưới toàn cầu các nhà nghiên cứu nổi tiếng về việc sản xuất các đánh giá hệ thống chất lượng cao, đã bắt đầu khám phá khái niệm LSR để đáp ứng cơ sở bằng chứng phát triển nhanh chóng trong nhiều lĩnh vực chăm sóc sức khỏe [7]. Vì tiến hành một LSR tốn nhiều tài nguyên đòi hỏi tìm kiếm và sàng lọc tài liệu liên tục, trích xuất và phân tích dữ liệu liên tục, và cập nhật thường xuyên bản thảo đánh giá, các phương pháp, công cụ và công nghệ hoàn toàn mới cần thiết để cho phép điều này.

1.2 AI và Tự động hóa Nghiên cứu Học thuật
Những tiến bộ học máy gần đây trong phát triển Mô hình Ngôn ngữ Lớn (LLM), và cụ thể với các mô hình lớp GPT (Transformers Tiền huấn luyện Sinh tạo) như GPT-3.5 và GPT-4 từ OpenAI [1], đã thể hiện khả năng AI chưa từng có trong hiểu biết ngôn ngữ tự nhiên và tạo văn bản giống con người. Các mô hình này đã thể hiện khả năng chưa từng có trong việc tạo văn bản giống con người, thể hiện hiểu biết sâu sắc về tài liệu học thuật trên một loạt các lĩnh vực đa dạng. Khi những mô hình này tiếp tục phát triển, chúng ngày càng thành thạo trong việc giảm thiểu hiện tượng ảo giác¹, từ đó tăng cường độ tin cậy và tiềm năng hỗ trợ trong nghiên cứu học thuật nơi độ chính xác là tối quan trọng. Việc tích hợp các plugin và khả năng web đã tăng cường hơn nữa những công nghệ này, cho phép chúng truy cập và kết hợp các phát hiện nghiên cứu mới nhất.

Tuy nhiên, mặc dù có những tiến bộ này, các mô hình LLM có khả năng nhất và có thể truy cập công khai vẫn là đa năng và chưa có kiến thức chuyên biệt và sâu rộng đủ trên một loạt các ngành học để hỗ trợ việc tiến hành SLR. Việc tinh chỉnh các mô hình có thể truy cập công khai (đặc biệt là các mô hình GPT) cho kiến thức cụ thể theo lĩnh vực cần thiết cho SLR chưa thể thực hiện được, chủ yếu do tính chất độc quyền và bí mật của các tham số mô hình cho những LLM này. Hơn nữa, nhu cầu tính toán liên quan đến việc tinh chỉnh các mô hình bao gồm hàng tỷ tham số cho khả năng nhiệm vụ mới và kiến thức mới cũng cho đến gần đây đã quá đắt đỏ [6].

Tuy nhiên, bối cảnh đang thay đổi nhanh chóng với việc phát hành gần đây của một số LLM mã nguồn mở lớn (ví dụ về các mô hình GPT là Falcon, MosaicML, LLaMA [33]) và sự phát triển của các kỹ thuật tạo điều kiện cho việc tinh chỉnh (ví dụ Thích ứng Hạng thấp (LoRA) [10] và LoRA Lượng tử hóa [6]) của LLM trên tài nguyên tính toán và bộ nhớ khiêm tốn mà không làm tổn hại độ chính xác. Công việc của Dettmers và cộng sự [6] đã cho thấy rằng QLoRA có thể hoạt động tốt như việc tinh chỉnh mô hình đầy đủ cổ điển trong khi thể hiện điều này trên các mô hình có sẵn công khai lớn nhất trong khi thực hiện tinh chỉnh trên một GPU duy nhất đánh dấu một sự thay đổi đáng kể trong khả năng tiếp cận của việc tinh chỉnh LLM. Do đó, những tiến bộ này mở đường cho sự phát triển tự nhiên hướng tới sự phổ biến của các LLM cụ thể theo lĩnh vực được tinh chỉnh trên các nhóm nghiên cứu và ngành công nghiệp, tăng cường khả năng chuyên gia của những mô hình này và có tiềm năng cách mạng hóa cách chúng ta tiếp cận và tiến hành nghiên cứu học thuật.

¹Trong bối cảnh LLM, ảo giác đề cập đến việc tạo ra các đầu ra hoặc phản hồi không chính xác, gây hiểu lầm hoặc không liên quan đến đầu vào hoặc lời nhắc đã cho.

--- TRANG 3 ---
Mở rộng PRISMA sử dụng Mô hình Ngôn ngữ Lớn Tinh chỉnh theo Lĩnh vực cụ thể

1.3 Đóng góp
Tận dụng tiến bộ công nghệ gần đây, bài báo này đề xuất cả phương pháp mới và khung PRISMA tích hợp AI cho LLM được tinh chỉnh theo lĩnh vực (PRISMA-DFLLM), kết hợp sức mạnh của các mô hình ngôn ngữ AI sinh tạo với các hướng dẫn báo cáo nghiêm ngặt của PRISMA. Mục đích của việc mở rộng báo cáo được đề xuất là cung cấp hướng dẫn báo cáo hiệu quả cho SLR dựa trên LLM và thúc đẩy sự phát triển của LLM cụ thể theo lĩnh vực. Điều này sẽ đẩy nhanh và mở rộng phạm vi của nghiên cứu, đặc biệt với số lượng xuất bản ngày càng tăng và sự hỗ trợ của các công nghệ AI sinh tạo, đảm bảo khả năng mở rộng trong môi trường nghiên cứu. Trọng tâm chính của công việc này là cải thiện quy trình tiến hành SLR bằng cách giải quyết các thách thức liên quan đến phương pháp thủ công. Mục đích là giới thiệu một phương pháp hiệu quả và có thể mở rộng hơn để tiến hành SLR, LSR và các hình thức tổng hợp kiến thức khác.

Ngoài ra, công việc này đề xuất một lộ trình nghiên cứu để phát triển LLM có thể được tinh chỉnh để hỗ trợ nghiên cứu học thuật. Lộ trình nêu các bước chính như lựa chọn kiến thức cụ thể theo lĩnh vực, điều chỉnh tham số mô hình và đánh giá hiệu suất mô hình. Bài báo cũng xác định các câu hỏi nghiên cứu tương lai cần được khám phá, như cách tích hợp kiến thức cụ thể theo lĩnh vực vào LLM một cách hiệu quả và cách đảm bảo độ tin cậy và tính hợp lệ của LLM được tinh chỉnh. Cuối cùng, nghiên cứu này đi sâu vào lợi ích và trở ngại của việc phát triển LLM cụ thể theo lĩnh vực cho mục đích nghiên cứu. Một mặt, những mô hình này có thể cách mạng hóa cách chúng ta tiếp cận và tiến hành nghiên cứu học thuật bằng cách tự động hóa quy trình đánh giá tài liệu, cải thiện khả năng mở rộng nghiên cứu và tạo ra những hiểu biết độc đáo mà các phương pháp thông thường có thể không phát hiện ra. Mặt khác, có một số thách thức cần giải quyết, như tính chất bí mật của các tham số LLM, nhu cầu tính toán liên quan đến việc tinh chỉnh các mô hình lớn và tầm quan trọng của đánh giá kỹ lưỡng để xác minh độ chính xác và độ tin cậy của các mô hình được tinh chỉnh.

2 Bối cảnh
Trong vài thập kỷ qua, một số sáng kiến đã nhằm nâng cao chất lượng và tính minh bạch của báo cáo trong phân tích meta và đánh giá hệ thống. Các tiêu chuẩn và hướng dẫn báo cáo đáng chú ý bao gồm Tuyên bố Chất lượng Báo cáo Phân tích Meta (QUOROM) [18], hướng dẫn Phân tích Meta các Nghiên cứu Quan sát trong Dịch tễ học (MOOSE) [32] đã được thay thế bởi PRISMA và bản cập nhật gần đây PRISMA 2020. Tuyên bố QUOROM, được xuất bản năm 1999, đã giới thiệu danh sách kiểm tra cho các báo cáo phân tích meta, bao gồm các khía cạnh như tiêu chí đủ điều kiện, phương pháp tìm kiếm, trích xuất dữ liệu và phân tích thống kê. Năm 2000, hướng dẫn MOOSE đặc biệt giải quyết việc báo cáo phân tích meta của các nghiên cứu quan sát, cung cấp khuyến nghị về thiết kế nghiên cứu, chiến lược tìm kiếm, thu thập dữ liệu và đánh giá chất lượng nghiên cứu.

Đáng chú ý, PRISMA 2020 được sửa đổi hiện nay thừa nhận tầm quan trọng của chất lượng phương pháp và nguy cơ thiên kiến bằng cách kết hợp các cân nhắc từ AMSTAR-2 và ROBIS trong quá trình phát triển của nó. Việc bổ sung mới về báo cáo chất lượng phương pháp và đặc biệt là nguy cơ thiên kiến trong đánh giá vào PRISMA 2020 là một bổ sung đáng hoan nghênh đối với việc tích hợp với LLM và tiềm năng thiên kiến.

Ngoài PRISMA, hai phương pháp quan trọng khác [14] hỗ trợ thực hành dựa trên bằng chứng với phương pháp nghiêm ngặt và tính minh bạch là AMSTAR-2 [26] và ROBIS [37]. AMSTAR-2 cung cấp danh sách kiểm tra toàn diện để đánh giá chất lượng phương pháp, trong khi ROBIS tập trung vào việc đánh giá nguy cơ thiên kiến trong các đánh giá hệ thống. Ngược lại, PRISMA 2020 là một hướng dẫn báo cáo nhấn mạnh báo cáo đầy đủ và minh bạch của các đánh giá hệ thống. Cả AMSTAR-2 và ROBIS đều tăng cường khả năng của các nhà đánh giá trong việc thẩm định chất lượng tổng thể và tính hợp lệ của các đánh giá hệ thống. Đáng chú ý, PRISMA 2020 được sửa đổi hiện nay kết hợp các cân nhắc từ AMSTAR-2 và ROBIS để thừa nhận tầm quan trọng của chất lượng phương pháp và nguy cơ thiên kiến. Việc đưa vào báo cáo chất lượng phương pháp và nguy cơ thiên kiến này trong PRISMA 2020 là một bổ sung đáng hoan nghênh đặc biệt liên quan đến việc tích hợp với LLM và thiên kiến tiềm tàng.

2.1 Tuyên bố PRISMA 2020
PRISMA là một hướng dẫn dựa trên bằng chứng nêu ra các mục thiết yếu cần thiết để báo cáo các đánh giá hệ thống và phân tích meta [19]. Được tạo ra năm 2009, PRISMA nhằm cải thiện chất lượng và tính minh bạch của các đánh giá hệ thống bằng cách đảm bảo các nhà nghiên cứu báo cáo thông tin quan trọng cần thiết cho việc đánh giá phê bình và sao chép công việc của họ. Mặc dù ban đầu được dành cho các đánh giá thẩm định các thử nghiệm ngẫu nhiên, PRISMA đã được áp dụng rộng rãi và có thể phục vụ như một cơ sở để báo cáo các đánh giá hệ thống của các thiết kế nghiên cứu khác, như nghiên cứu quan sát, nghiên cứu độ chính xác chẩn đoán và nghiên cứu định tính.

--- TRANG 4 ---
Mở rộng PRISMA sử dụng Mô hình Ngôn ngữ Lớn Tinh chỉnh theo Lĩnh vực cụ thể

Tuyên bố PRISMA đã được cập nhật năm 2020 để phản ánh những phát triển và thách thức mới nhất trong việc tiến hành các đánh giá hệ thống [23]. Phiên bản 2020 bao gồm một danh sách kiểm tra và một sơ đồ dòng chảy, giống như phiên bản trước đó. Tuy nhiên, danh sách kiểm tra cập nhật hiện bao gồm 27 mục bao gồm các thành phần thiết yếu của một đánh giá hệ thống, như tiêu đề, tóm tắt, giới thiệu, phương pháp (như tiêu chí đủ điều kiện, chiến lược tìm kiếm, lựa chọn nghiên cứu, trích xuất dữ liệu và tổng hợp dữ liệu), kết quả, thảo luận và tài trợ. Mỗi mục danh sách kiểm tra cung cấp hướng dẫn cho các nhà nghiên cứu về những gì cần bao gồm trong báo cáo đánh giá hệ thống của họ. Sơ đồ dòng chảy, còn được gọi là sơ đồ dòng chảy PRISMA, biểu diễn trực quan quá trình lựa chọn nghiên cứu, làm cho người đọc dễ hiểu dòng chảy của các nghiên cứu từ xác định đến các nghiên cứu cuối cùng được bao gồm.

PRISMA đã có tác động đáng kể đến lĩnh vực đánh giá hệ thống và phân tích meta kể từ khi được giới thiệu. Nó đã trở nên được thừa nhận và chứng thực rộng rãi bởi các tạp chí và tổ chức hàng đầu trong lĩnh vực y học dựa trên bằng chứng. Các nhà nghiên cứu, đánh giá viên và biên tập viên tạp chí thường tham khảo PRISMA như một công cụ quan trọng để cải thiện tính minh bạch, độ nghiêm ngặt và tính đầy đủ của các đánh giá hệ thống. Tuân thủ hướng dẫn PRISMA tạo điều kiện cho việc đánh giá nguy cơ thiên kiến và sao chép các nghiên cứu, cho phép tích hợp bằng chứng vào thực hành và xây dựng chính sách.

Bản cập nhật PRISMA 2020 thể hiện cam kết liên tục trong việc cải thiện các tiêu chuẩn báo cáo trong đánh giá hệ thống, tăng cường hơn nữa khả năng áp dụng và tính khả dụng của nó [23]. Khi các phương pháp nghiên cứu và tiến bộ công nghệ tiếp tục phát triển nhanh chóng, khung PRISMA phải được cập nhật để đảm bảo tính liên quan và khả năng áp dụng của nó. Cam kết cải tiến liên tục này nhấn mạnh tầm quan trọng của PRISMA trong việc thúc đẩy thực hành và ra quyết định dựa trên bằng chứng.

2.2 Mở rộng PRISMA
Đã có một tiền lệ được thiết lập tốt để tùy chỉnh các hướng dẫn PRISMA gốc. Các thách thức nghiên cứu và phương pháp đa dạng đã dẫn đến việc đề xuất một số mở rộng cho khung PRISMA. Những mở rộng này tăng cường tính linh hoạt và khả năng thích ứng của các hướng dẫn PRISMA, trao quyền cho các nhà nghiên cứu tiến hành và báo cáo các đánh giá hệ thống trong các lĩnh vực cụ thể. Bằng cách điều chỉnh hướng dẫn để giải quyết nhu cầu cụ thể theo bối cảnh, những mở rộng này củng cố tính minh bạch, khả năng tái tạo và hiệu quả tổng thể của các phương pháp đánh giá hệ thống. Các mở rộng được thảo luận trong phần này bao gồm PRISMA-P (Giao thức), PRISMA-ScR (Đánh giá Phạm vi), PRISMA-NMA (Phân tích Meta Mạng), PRISMA-IPD (Dữ liệu Bệnh nhân Cá nhân), PRISMA-Harms (Báo cáo Tác hại) và PRISMA-RR (Đánh giá Nhanh). Mỗi mở rộng trang bị cho các nhà nghiên cứu một danh sách kiểm tra toàn diện và làm rõ các thành phần quan trọng, từ đó tối ưu hóa chất lượng, tính minh bạch và khả năng hiểu của các đánh giá hệ thống trong các bối cảnh nghiên cứu riêng biệt.

PRISMA-P (cho Giao thức) PRISMA-P [20] là một mở rộng của khung PRISMA tập trung cụ thể vào việc phát triển và báo cáo các giao thức đánh giá hệ thống. Một giao thức đánh giá hệ thống nêu ra các mục tiêu, phương pháp và kế hoạch phân tích sẽ được tuân theo trong một đánh giá hệ thống. Nó phục vụ như một bản thiết kế để tiến hành đánh giá và đảm bảo tính minh bạch, khả năng tái tạo và tính nhất quán trong quy trình đánh giá. Mở rộng PRISMA-P cung cấp danh sách kiểm tra và giải thích cho các mục chính nên được bao gồm trong giao thức đánh giá hệ thống, bao gồm các khía cạnh như lý do, tiêu chí đủ điều kiện, chiến lược tìm kiếm, trích xuất dữ liệu và phương pháp tổng hợp. Bằng cách tuân thủ hướng dẫn PRISMA-P, các nhà nghiên cứu có thể nâng cao chất lượng và tính minh bạch của các giao thức đánh giá hệ thống của họ, tạo điều kiện hiểu biết và đánh giá tốt hơn về đánh giá đã lên kế hoạch.

PRISMA-ScR (cho Đánh giá Phạm vi) Đánh giá phạm vi nhằm lập bản đồ tài liệu về một chủ đề hoặc lĩnh vực nghiên cứu cụ thể và cung cấp tổng quan về bằng chứng có sẵn. Không giống như đánh giá hệ thống, đánh giá phạm vi thường rộng hơn về phạm vi và tập trung vào việc xác định các khái niệm, lý thuyết, nguồn và khoảng trống chính trong tài liệu hiện có. Mở rộng PRISMA-ScR [34] thích ứng các hướng dẫn PRISMA gốc với các đặc điểm độc đáo của đánh giá phạm vi, cung cấp danh sách kiểm tra và giải thích để hướng dẫn các nhà nghiên cứu tiến hành và báo cáo đánh giá phạm vi. Nó bao gồm các khía cạnh chính như câu hỏi nghiên cứu, chiến lược tìm kiếm, quy trình lựa chọn nghiên cứu, trích xuất dữ liệu và trình bày phát hiện. Bằng cách tuân thủ hướng dẫn PRISMA-ScR, các nhà nghiên cứu có thể nâng cao tính minh bạch và độ nghiêm ngặt của các đánh giá phạm vi của họ, cho phép hiểu biết và sử dụng tốt hơn bằng chứng được tổng hợp.

--- TRANG 5 ---
Mở rộng PRISMA sử dụng Mô hình Ngôn ngữ Lớn Tinh chỉnh theo Lĩnh vực cụ thể

PRISMA-NMA (cho Phân tích Meta Mạng) Phân tích meta mạng (NMA), còn được gọi là phân tích meta đa điều trị hoặc so sánh điều trị gián tiếp, là một phương pháp thống kê cho phép so sánh đồng thời nhiều can thiệp trong một phân tích duy nhất. Nó cho phép ước tính tác động điều trị tương đối ngay cả khi không có so sánh trực tiếp giữa tất cả các điều trị. Mở rộng PRISMA-NMA [12] cung cấp hướng dẫn để báo cáo phân tích meta mạng, đảm bảo tính minh bạch và rõ ràng trong báo cáo phương pháp, kết quả và diễn giải. Danh sách kiểm tra bao gồm các khía cạnh chính như thiết kế nghiên cứu, chiến lược tìm kiếm, tiêu chí lựa chọn nghiên cứu, trích xuất dữ liệu, đánh giá nguy cơ thiên kiến, phương pháp phân tích thống kê và trình bày kết quả. Bằng cách tuân theo hướng dẫn PRISMA-NMA, các nhà nghiên cứu có thể cải thiện chất lượng và khả năng hiểu của phân tích meta mạng của họ, tạo điều kiện cho việc tổng hợp và diễn giải bằng chứng về tác động điều trị so sánh.

PRISMA-IPD (cho Dữ liệu Bệnh nhân Cá nhân) Phân tích meta sử dụng dữ liệu bệnh nhân cá nhân (IPD) cung cấp phân tích chi tiết và có khả năng chính xác hơn so với những phân tích dựa trên dữ liệu tổng hợp. IPD cho phép kiểm tra các đặc điểm cấp độ bệnh nhân và khám phá tác động điều trị trên các nhóm phụ. Mở rộng PRISMA-IPD [31] tập trung vào hướng dẫn báo cáo cho đánh giá hệ thống và phân tích meta sử dụng dữ liệu bệnh nhân cá nhân. Danh sách kiểm tra bao gồm các mục như thiết kế nghiên cứu, phương pháp thu thập dữ liệu, đặc điểm người tham gia, kết quả quan tâm, phương pháp thống kê được sử dụng cho phân tích và diễn giải kết quả. Bằng cách tuân thủ hướng dẫn PRISMA-IPD, các nhà nghiên cứu có thể nâng cao tính minh bạch, độ chính xác và khả năng so sánh của các đánh giá hệ thống và phân tích meta dựa trên dữ liệu bệnh nhân cá nhân.

PRISMA-Harms (cho Báo cáo Tác hại) Mở rộng PRISMA-Harms [40] tập trung vào báo cáo toàn diện các kết quả có hại trong đánh giá hệ thống và phân tích meta. Trong khi các đánh giá hệ thống truyền thống tập trung vào hiệu quả và lợi ích của can thiệp, điều quan trọng không kém là kiểm tra và báo cáo những tác hại tiềm tàng liên quan đến những can thiệp đó. PRISMA-Harms cung cấp hướng dẫn để xác định, trích xuất và báo cáo dữ liệu về các sự kiện bất lợi và tác hại trong các nghiên cứu được bao gồm một cách hệ thống. Mở rộng này nhấn mạnh nhu cầu về tính minh bạch, đầy đủ và nhất quán trong báo cáo các sự kiện bất lợi và tạo điều kiện đánh giá cân bằng hơn về lợi ích và rủi ro liên quan đến can thiệp.

PRISMA-RR (cho Đánh giá Nhanh) Đánh giá nhanh là một hình thức tổng hợp kiến thức nhằm sản xuất thông tin kịp thời trong khi đơn giản hóa hoặc bỏ qua một số thành phần nhất định của quy trình đánh giá hệ thống. Mở rộng PRISMA-RR [30] cung cấp danh sách kiểm tra báo cáo được điều chỉnh cụ thể cho các đặc điểm và yêu cầu độc đáo của đánh giá nhanh. Nó bao gồm các khía cạnh chính như câu hỏi đánh giá, chiến lược tìm kiếm, quy trình lựa chọn nghiên cứu, trích xuất dữ liệu và phương pháp tổng hợp. Bằng cách tuân theo hướng dẫn PRISMA-RR, các nhà nghiên cứu có thể đảm bảo tính minh bạch và độ nghiêm ngặt trong báo cáo đánh giá nhanh, cho phép người đọc hiểu rõ hơn về điểm mạnh và hạn chế của những tổng hợp kiến thức được đẩy nhanh này.

2.3 SLR được hỗ trợ bởi AI: Tình trạng hiện tại và Hướng tương lai
Sự gia tăng trong tài liệu học thuật đã dẫn đến việc tích hợp các công nghệ AI trong đánh giá hệ thống, nhằm đơn giản hóa quy trình đánh giá và tăng cường hiệu quả [22,35]. Những công nghệ này đã được sử dụng trong các giai đoạn khác nhau của quy trình đánh giá, bao gồm sàng lọc tài liệu và trích xuất dữ liệu từ các nghiên cứu được bao gồm. Tuy nhiên, việc thực hiện AI trong đánh giá hệ thống không phải không có thách thức, như nhu cầu về dữ liệu được gán nhãn rộng rãi để huấn luyện mô hình AI và độ phức tạp của việc tự động hóa các nhiệm vụ chủ quan như đánh giá chất lượng [17].

Các nghiên cứu gần đây đã khám phá tiềm năng của các thuật toán học máy và chúng đã cho thấy hứa hẹn trong việc giảm khối lượng công việc của các đánh giá viên trong sàng lọc trích dẫn [22]. Tương tự, các kỹ thuật khai thác văn bản đã được sử dụng để trích xuất dữ liệu từ các nghiên cứu được bao gồm, mặc dù độ phức tạp và biến đổi của dữ liệu tài liệu học thuật đặt ra những thách thức đáng kể [35]. Knafou và cộng sự [13] đã chứng minh hiệu quả của các mô hình ngôn ngữ học sâu trong việc phân loại các xuất bản liên quan đến COVID-19, gợi ý tiềm năng của AI trong việc hỗ trợ curation và đánh giá dịch tễ học. Forsgren và cộng sự [8] đã thảo luận về tính hữu ích của các chức năng khai thác văn bản trong việc tạo điều kiện cho quy trình sàng lọc đối với các chủ đề có ranh giới khái niệm khuếch tán, làm nổi bật tiềm năng của AI trong việc cải thiện quy trình làm việc của các đánh giá toàn diện. Muller và cộng sự [21] đã đề xuất một nghiên cứu hồi cứu để định lượng tác động của việc áp dụng học máy đối với việc sử dụng tài nguyên và thời gian hoàn thành trong đánh giá hệ thống. Nghiên cứu nhấn mạnh lợi ích tiềm tàng của học máy trong tổng hợp bằng chứng và làm nổi bật nhu cầu nghiên cứu thêm để giải quyết những lo ngại về chất lượng và tự động hóa.

--- TRANG 6 ---
Mở rộng PRISMA sử dụng Mô hình Ngôn ngữ Lớn Tinh chỉnh theo Lĩnh vực cụ thể

Tuy nhiên, vẫn tồn tại những hạn chế và cần nghiên cứu thêm để giải quyết những lo ngại về chất lượng, tự động hóa và những hạn chế hiện tại của các mô hình AI khác nhau trong tổng hợp bằng chứng. Qureshi và cộng sự [24] đã khám phá tiềm năng của ChatGPT [1], một LLM đa năng được phát triển bởi OpenAI, trong việc hỗ trợ đánh giá hệ thống. Trong khi mô hình cho thấy hứa hẹn trong một số lĩnh vực nhất định, nghiên cứu đã làm nổi bật nhu cầu khám phá và thử nghiệm thêm để hiểu những hạn chế hiện tại và khả năng của nó trong bối cảnh tổng hợp bằng chứng. Chỉ gần đây, chúng ta mới bắt đầu chứng kiến sự xuất hiện của LLM cụ thể theo lĩnh vực, được tạo ra từ việc tiền huấn luyện trên các tập dữ liệu lớn đòi hỏi tài nguyên tính toán khổng lồ. Trong lĩnh vực chăm sóc sức khỏe, Singhal và cộng sự [28,29] đã chứng minh tiềm năng của LLM trong trả lời câu hỏi y tế. Nghiên cứu của họ về Med-PaLM 2 đã thể hiện những tiến bộ đáng kể hướng tới hiệu suất cấp độ bác sĩ trong lĩnh vực này, cùng với việc giới thiệu các chuẩn mực và khung đánh giá cụ thể cho LLM trong trả lời câu hỏi y tế. Ngoài ra, Stanford CRFM đã phát triển PubMedGPT 2.7B [2], một mô hình ngôn ngữ được huấn luyện độc quyền trên các tóm tắt và bài báo y sinh học, đã đạt được kết quả ấn tượng trên các nhiệm vụ NLP y sinh học khác nhau [2]. Tương tự, trong lĩnh vực tài chính, Wu và cộng sự [38] đã trình bày BloombergGPT, một mô hình ngôn ngữ 50 tỷ tham số được huấn luyện trên một loạt dữ liệu tài chính và đa năng đa dạng. Mô hình này đã vượt qua các mô hình hiện có trong các nhiệm vụ tài chính trong khi duy trì hiệu suất mạnh trên các chuẩn mực đa năng, làm nổi bật việc huấn luyện thành công LLM trên cả nguồn dữ liệu cụ thể theo lĩnh vực và đa năng. Trong khi đó, Lehman và cộng sự [16] đã điều tra tính phù hợp của LLM được huấn luyện trên văn bản web chung cho các lĩnh vực chuyên biệt và quan trọng về an toàn như văn bản lâm sàng thông qua phân tích rộng rãi 12 mô hình ngôn ngữ, và nghiên cứu của họ tiết lộ rằng các mô hình lâm sàng chuyên biệt tương đối nhỏ vượt trội hơn các LLM lớn hơn được huấn luyện trên văn bản chung, ngay cả khi được tinh chỉnh với dữ liệu chú thích hạn chế. Phát hiện của họ gợi ý tính khả thi của việc tinh chỉnh LLM nhỏ hơn cho các nhiệm vụ cụ thể theo lĩnh vực có thể phù hợp cho SLR.

Mặc dù có những tiến bộ này, có nhu cầu cấp thiết về một hướng dẫn tích hợp dựa trên AI có thể hỗ trợ đầy đủ việc tiến hành đánh giá hệ thống, và cụ thể có một khoảng trống trong việc tận dụng LLM để tự động hóa các phần của quy trình đánh giá và tạo ra hiểu biết trực tiếp từ tài liệu [3]. Phương pháp này không chỉ có thể tiết kiệm thời gian và tài nguyên mà còn nâng cao tính toàn diện và chất lượng của đánh giá hệ thống. Những tiến bộ gần đây trong AI, đặc biệt trong việc phát triển LLM, nhấn mạnh tiềm năng của việc phát triển một khung AI tích hợp như vậy và bắt đầu thử nghiệm với LLM tùy chỉnh đã được tinh chỉnh cho kiến thức cụ thể theo lĩnh vực mang lại hứa hẹn cho việc cách mạng hóa việc tiến hành đánh giá hệ thống.

2.4 Tiến bộ AI trong Tinh chỉnh LLM
Sự ra đời của LLM đã cách mạng hóa lĩnh vực xử lý ngôn ngữ tự nhiên, mang lại khả năng chưa từng có trong việc hiểu và tạo văn bản giống con người. Tuy nhiên, kích thước khổng lồ của những mô hình này đặt ra những thách thức đáng kể về chi phí tính toán và dấu chân bộ nhớ, đặc biệt trong quá trình tinh chỉnh. Để giải quyết những thách thức này, một loạt các chiến lược Tinh chỉnh Hiệu quả Tham số (PEFT) đã được phát triển [4]. Những chiến lược này nhằm cập nhật một tập con nhỏ các tham số trong khi giữ phần còn lại của mô hình đóng băng, từ đó đạt được hiệu suất tương đương với tinh chỉnh đầy đủ trong khi giảm đáng kể chi phí tính toán và dấu chân bộ nhớ.

Một trong những chiến lược PEFT tiên phong là Bộ Thích ứng Hạng thấp (LoRA). LoRA giới thiệu các ma trận hạng thấp vào mỗi lớp của mô hình tiền huấn luyện. Những ma trận này là những tham số duy nhất được cập nhật trong quá trình tinh chỉnh, trong khi các tham số tiền huấn luyện gốc được giữ đóng băng. Phương pháp này giảm đáng kể số lượng tham số cần được cập nhật, làm cho việc tinh chỉnh hiệu quả hơn và ít dễ bị quá khớp hơn. Tuy nhiên, đáng chú ý là LoRA có thể không cung cấp cùng mức độ linh hoạt như tinh chỉnh đầy đủ, vì nó chỉ có thể sửa đổi hành vi của mô hình theo cách hạn chế [11].

Dựa trên khái niệm LoRA, LoRA Lượng tử hóa (QLoRA) đã được phát triển để giảm thêm việc sử dụng bộ nhớ bằng cách lượng tử hóa trọng số của mô hình tiền huấn luyện. Điều này liên quan đến việc biểu diễn các trọng số với số bit nhỏ hơn, có thể giảm đáng kể dấu chân bộ nhớ của mô hình. QLoRA cũng giới thiệu một số đổi mới khác để tiết kiệm bộ nhớ mà không hy sinh hiệu suất, như lượng tử hóa kép và bộ tối ưu hóa phân trang. Tuy nhiên, phương pháp này có thể phức tạp hơn để thực hiện và có thể đưa vào chi phí tính toán bổ sung [11]. Ví dụ, Adapters giới thiệu các ma trận tham số cụ thể theo nhiệm vụ nhỏ vào mô hình, được huấn luyện trong khi các tham số gốc bị đóng băng [36]. Phương pháp này cho phép thích ứng cụ thể theo nhiệm vụ mà không cần tinh chỉnh toàn bộ mô hình, từ đó duy trì lợi ích của tiền huấn luyện gốc trong khi thích ứng mô hình với các nhiệm vụ mới. So với LoRA và QLoRA, Adapters có thể cung cấp tính linh hoạt lớn hơn vì chúng cho phép sửa đổi cụ thể theo nhiệm vụ. Tuy nhiên, việc giới thiệu các tham số cụ thể theo nhiệm vụ có thể tăng độ phức tạp của mô hình và có thể đòi hỏi quản lý cẩn thận hơn về quá trình huấn luyện để tránh quá khớp. Mặt khác, điều chỉnh tiền tố thêm một tiền tố cụ thể theo nhiệm vụ vào chuỗi đầu vào, có thể sửa đổi hành vi của mô hình theo cách linh hoạt hơn LoRA hoặc Adapters [9]. Phương pháp này có thể đặc biệt hiệu quả cho các nhiệm vụ đòi hỏi thay đổi đáng kể trong hành vi của mô hình, vì tiền tố có thể hướng dẫn mô hình hướng tới đầu ra mong muốn. So với LoRA và QLoRA, điều chỉnh tiền tố có thể cung cấp tính linh hoạt lớn hơn và có thể hiệu quả hơn cho các nhiệm vụ đòi hỏi thay đổi đáng kể trong hành vi của mô hình. Tuy nhiên, nó cũng có thể đòi hỏi điều chỉnh cẩn thận hơn về tiền tố và có thể đưa vào chi phí tính toán nhiều hơn do nhu cầu xử lý đầu vào bổ sung.

--- TRANG 7 ---
Mở rộng PRISMA sử dụng Mô hình Ngôn ngữ Lớn Tinh chỉnh theo Lĩnh vực cụ thể

Các chiến lược PEFT cung cấp một phương pháp đầy hứa hẹn để tinh chỉnh LLM theo cách hiệu quả hơn về tính toán và bộ nhớ. Tuy nhiên, hiệu quả của những chiến lược này có thể phụ thuộc vào phương pháp cụ thể được sử dụng và đặc điểm của nhiệm vụ. Do đó, điều quan trọng là phải cân nhắc cẩn thận sự đánh đổi giữa các chiến lược PEFT khác nhau khi tinh chỉnh LLM cho các ứng dụng cụ thể. Nghiên cứu tương lai trong lĩnh vực này có khả năng mang lại các chiến lược thậm chí hiệu quả và hiệu quả hơn để tinh chỉnh LLM.

Để nhấn mạnh tính khả thi của tinh chỉnh, Zhou và cộng sự [39] gần đây đã kết luận rằng chỉ cần dữ liệu tinh chỉnh hướng dẫn hạn chế để dạy các mô hình sản xuất đầu ra chất lượng cao mà họ đã chứng minh bằng cách huấn luyện LIMA, một mô hình ngôn ngữ LLaMa 65B tham số, chỉ với 1.000 lời nhắc và phản hồi được tuyển chọn cẩn thận, không có bất kỳ học tăng cường hoặc mô hình hóa sở thích con người nào. Trong khi các tác giả lưu ý rằng hầu như tất cả kiến thức trong một LLM được học trong quá trình tiền huấn luyện nơi các biểu diễn đa năng được học từ văn bản thô, vẫn có thể mã hóa kiến thức bổ sung và các hành vi downstream cần thiết để tiến hành SLR chỉ với một tập dữ liệu tinh chỉnh nhỏ bao gồm các bài báo học thuật mục tiêu.

3 Phác thảo Các Thành phần Báo cáo PRISMA Bổ sung
Khung được đề xuất nhằm tăng cường phương pháp PRISMA hiện có cho SLR bằng cách kết hợp rõ ràng một số thành phần chính liên quan đến tinh chỉnh LLM. Những thành phần bổ sung này giải quyết các chủ đề báo cáo của tập dữ liệu tinh chỉnh, chi tiết kỹ thuật tinh chỉnh LLM và đánh giá LLM được tinh chỉnh. Bằng cách tích hợp những thành phần này, phương pháp PRISMA-DFLLM mở rộng các hướng dẫn PRISMA đã được thiết lập mà không thay thế bất kỳ hướng dẫn hiện có nào. Bước đầu tiên của hướng dẫn được đề xuất là tiến hành tiêu chí tìm kiếm PRISMA truyền thống để thu thập và lọc bài báo. Điều này đảm bảo rằng bản chất hệ thống và toàn diện của khung PRISMA gốc được duy trì, dẫn đến việc lựa chọn tài liệu liên quan nghiêm ngặt là thiết yếu và có thể báo cáo. Sau đó, các bài báo được xác định tạo thành cơ sở cho các bước tiếp theo trong phương pháp PRISMA-DFLLM.

3.1 Báo cáo Chi tiết Tập dữ liệu Tinh chỉnh
Tập dữ liệu được sử dụng để tinh chỉnh LLM có tầm quan trọng tối thượng và đòi hỏi xử lý và chuẩn bị tỉ mỉ và được xây dựng từ các bài báo học thuật liên quan. Trong giai đoạn chuẩn bị dữ liệu, văn bản thô được trích xuất từ những bài báo này trải qua làm sạch và tiền xử lý để đảm bảo tính đồng nhất và tạo điều kiện xử lý mượt mà bởi mô hình. Điều này bao gồm các nhiệm vụ như loại bỏ hoặc thay thế các ký tự cụ thể, giải quyết các vấn đề mã hóa và chuẩn hóa các định dạng như ngày tháng và số. Hơn nữa, siêu dữ liệu liên quan đến mỗi bài báo, bao gồm chi tiết như tác giả, ngày xuất bản, tạp chí và từ khóa, được tích hợp liền mạch với văn bản của bài báo. Việc tích hợp này cho phép LLM phân biệt kết nối giữa nội dung và siêu dữ liệu, từ đó tăng cường sự hiểu biết của nó về bài báo và bối cảnh của nó. Điều quan trọng là phải nêu rõ chiến lược được sử dụng trong việc xây dựng tập dữ liệu, bao gồm bất kỳ bước tự động hoặc thủ công nào được thực hiện để biểu diễn thông tin từ các bài báo học thuật.

Ngoài chiến lược xây dựng tập dữ liệu, điều bắt buộc là phải chỉ định rõ ràng định dạng của dữ liệu đầu vào và đầu ra cho LLM, cùng với bất kỳ bước tiền xử lý cụ thể theo lĩnh vực và phương pháp mã hóa văn bản nào được sử dụng. Nếu các tập dữ liệu bổ sung được kết hợp để tinh chỉnh hướng dẫn hoặc để tăng cường kiến thức lĩnh vực chung của LLM, những điều này cũng nên được báo cáo. Một khía cạnh quan trọng khác là báo cáo các thuộc tính kích thước của tập dữ liệu tinh chỉnh cuối cùng, vì thông tin này tác động đến khả năng khái quát hóa của LLM và tài nguyên tính toán cần thiết cho huấn luyện.

Vì tập dữ liệu được sử dụng để tinh chỉnh LLM đòi hỏi xử lý và chuẩn bị tỉ mỉ, một phương pháp có cấu trúc cần được tuân theo và truyền đạt. Các bước làm sạch và tiền xử lý đảm bảo một tập dữ liệu có cấu trúc đồng nhất, trong khi việc kết hợp siêu dữ liệu tăng cường sự hiểu biết của mô hình về bài báo và bối cảnh của nó. Do đó, điều quan trọng là cung cấp báo cáo chi tiết về chiến lược xây dựng tập dữ liệu, thông số kỹ thuật định dạng và bất kỳ tập dữ liệu bổ sung nào được sử dụng để đảm bảo khả năng tái tạo và hiểu biết toàn diện về quá trình huấn luyện LLM và bất kỳ mở rộng nào của PRISMA cần đặt ra hướng dẫn phù hợp với điều này.

3.2 Báo cáo Chi tiết Quy trình Tinh chỉnh LLM
Việc lựa chọn một mô hình LLM cơ sở phù hợp để tinh chỉnh có tầm quan trọng tối thượng trong quy trình tinh chỉnh LLM. Các mô hình LLM khác nhau thể hiện sự biến đổi về kiến trúc, khả năng và hiệu suất trên các nhiệm vụ ngôn ngữ. Khi chọn mô hình LLM cơ sở, điều thiết yếu là xem xét những yếu tố này và đánh giá sự phù hợp của chúng với mục tiêu và yêu cầu của nhiệm vụ tinh chỉnh. Trong bối cảnh khung PRISMA-DFLLM, việc xem xét các mô hình LLM cơ sở khác nhau, tính phù hợp của chúng và đánh giá hiệu suất của chúng cần được truyền đạt. Điều này cần được báo cáo vì các tùy chọn dao động từ các mô hình LLM thô, đã được huấn luyện trên các corpus văn bản rộng lớn nhưng chưa được tinh chỉnh cho các nhiệm vụ downstream, đến các mô hình đã trải qua một mức độ tinh chỉnh cho các hướng dẫn hoặc lĩnh vực cụ thể.

Việc lựa chọn mô hình LLM cơ sở phụ thuộc vào các yếu tố như đặc điểm kiến trúc, khả năng nắm bắt mối quan hệ phức tạp trong dữ liệu và hiệu suất của nó trên các nhiệm vụ ngôn ngữ liên quan đến mục tiêu tinh chỉnh. Trước khi bắt đầu quy trình tinh chỉnh, điều thiết yếu là hiểu trạng thái của mô hình LLM cơ sở được chọn - liệu nó là thô hay đã trải qua một mức độ tinh chỉnh nào đó, và báo cáo điều này. Các mô hình thô cung cấp hiểu biết rộng hơn về các mẫu ngôn ngữ nhưng thiếu kiến thức cụ thể theo lĩnh vực. Mặt khác, các mô hình đã trải qua tinh chỉnh trước đó cho các hướng dẫn hoặc lĩnh vực cụ thể có thể đã có một số kiến thức cụ thể theo lĩnh vực được nhúng để hỗ trợ tinh chỉnh tiếp theo. Đánh giá tính phù hợp của mô hình cơ sở về mặt tính thô hoặc tinh chỉnh trước đó đảm bảo rằng quy trình tinh chỉnh phù hợp với yêu cầu cụ thể của nhiệm vụ trong tầm tay.

Khi một mô hình LLM cơ sở phù hợp đã được chọn, quy trình tinh chỉnh bao gồm việc huấn luyện mô hình trên một corpus học thuật cụ thể. Điều này được thực hiện thông qua các kỹ thuật như điều chỉnh siêu tham số như tỷ lệ học, kích thước batch và số epoch huấn luyện. Sau đó, một thuật toán tối ưu hóa, như Adam hoặc Gradient Descent Stochastic, được sử dụng để cập nhật các tham số của mô hình dựa trên hàm mất mát. Mục tiêu là giảm thiểu lỗi và cải thiện độ chính xác của dự đoán. Để ngăn chặn quá khớp, các kỹ thuật như dropout, weight decay hoặc early stopping có thể được sử dụng trong quá trình tinh chỉnh. Các bước hậu xử lý, như temperature scaling, có thể tối ưu hóa thêm hiệu suất của LLM bằng cách kiểm soát mức độ ngẫu nhiên trong các đầu ra văn bản được tạo. Khi quy trình tinh chỉnh hoàn tất, mô hình LLM cuối cùng được chuẩn bị triển khai bằng cách đóng gói nó cùng với bất kỳ tệp hỗ trợ cần thiết nào, như tokenizer hoặc công cụ tiền xử lý. Điều này được thực hiện ở định dạng cho phép các nhà nghiên cứu dễ dàng tải và sử dụng mô hình cho các nhiệm vụ dự định của họ.

Việc lựa chọn mô hình LLM cơ sở phù hợp do đó có hệ quả trong quy trình tinh chỉnh, xem xét các yếu tố như đặc điểm kiến trúc, khả năng mô hình và hiệu suất trên các nhiệm vụ ngôn ngữ cần được báo cáo. Đánh giá liệu mô hình ở dạng thô hay đã trải qua tinh chỉnh trước đó hỗ trợ việc điều chỉnh quy trình tinh chỉnh với yêu cầu cụ thể của nhiệm vụ. Quy trình tinh chỉnh tiếp theo bao gồm điều chỉnh siêu tham số, sử dụng thuật toán tối ưu hóa và áp dụng các kỹ thuật để ngăn chặn quá khớp, tất cả đều cần được ghi lại như một phần của hướng dẫn PRISMA mở rộng. Các bước hậu xử lý có thể tối ưu hóa hiệu suất của mô hình, và mô hình cuối cùng được chuẩn bị triển khai bằng cách đóng gói với các tệp hỗ trợ cần thiết. Báo cáo rõ ràng về những bước này đảm bảo tính minh bạch cũng như tiềm năng tái tạo.

--- TRANG 8 ---
Mở rộng PRISMA sử dụng Mô hình Ngôn ngữ Lớn Tinh chỉnh theo Lĩnh vực cụ thể

3.3 Báo cáo Chi tiết Đánh giá LLM được Tinh chỉnh
Việc đánh giá mô hình PRISMA-DFLLM được tinh chỉnh là một quá trình đa diện được thiết kế để cung cấp một đánh giá mạnh mẽ và toàn diện về hiệu suất của nó. Quá trình này được điều chỉnh theo trường hợp sử dụng dự định của mô hình, đảm bảo rằng các chỉ số đánh giá phù hợp với các nhiệm vụ cụ thể mà mô hình được thiết kế để thực hiện và tổng thể nó đạt được sự phù hợp². Trong bối cảnh các nhiệm vụ truy xuất thông tin, là trọng tâm của SLR, các chỉ số như độ chính xác, precision, recall và F1-score có thể được sử dụng. Ví dụ, precision (tỷ lệ tài liệu/thông tin được truy xuất có liên quan) và recall (tỷ lệ tài liệu/thông tin liên quan được truy xuất) cung cấp cái nhìn cân bằng về hiệu suất của mô hình trong việc xác định tài liệu liên quan. F1-score, trung bình điều hòa của precision và recall, đưa ra một chỉ số hiệu suất tổng thể.

Khi mô hình được sử dụng cho các nhiệm vụ tóm tắt tài liệu, chỉ số ROUGE có thể được sử dụng. Chỉ số này so sánh sự chồng lấp của n-gram, các chuỗi từ gồm n từ, giữa các tóm tắt được tạo và tóm tắt được viết bởi con người. Ví dụ, điểm ROUGE-2 cao sẽ cho thấy sự chồng lấp đáng kể của các chuỗi hai từ giữa đầu ra của mô hình và tóm tắt tham chiếu, gợi ý một tóm tắt chất lượng cao.

Đánh giá của con người cũng có thể là một phần có giá trị của quá trình đánh giá. Nó cung cấp đánh giá định tính về các yếu tố như tính mạch lạc, tính đầy đủ và độ trung thực với bài báo gốc. Trong các nhiệm vụ sinh tạo, các đánh giá viên con người đánh giá các phản hồi của mô hình về tính mạch lạc, sự liên quan đến lời nhắc, tính mới lạ và độ chính xác thực tế. Ví dụ, các đánh giá viên có thể đánh giá các phản hồi của mô hình trên thang Likert cho những yếu tố này, cung cấp hiểu biết tinh tế hơn về hiệu suất của mô hình. Đánh giá so sánh tạo thành một thành phần chính khác của một bộ đánh giá có thể có. Ở đây, hiệu suất của mô hình được tinh chỉnh được so sánh với các mô hình cơ bản, như LLM gốc trước khi tinh chỉnh hoặc các LLM khác được tinh chỉnh trên các corpus khác nhau. So sánh này giúp định lượng giá trị gia tăng của quá trình tinh chỉnh và corpus cụ thể được sử dụng.

Đảm bảo tính ổn định và khả năng tái tạo của các đánh giá là tối quan trọng. Điều này có thể đạt được bằng cách chạy mô hình nhiều lần với các seed ngẫu nhiên khác nhau và thay đổi tập dữ liệu và các tham số ban đầu của mô hình. Các kỹ thuật như chia dữ liệu thành tập huấn luyện, xác thực, kiểm tra và cross-validation có thể được sử dụng để tăng cường độ tin cậy của các đánh giá. Ngoài ra, có thể tiến hành phân tích định tính về các đầu ra của mô hình, kiểm tra các nghiên cứu trường hợp của cả ví dụ thành công và ít thành công hơn. Các lỗi mà mô hình mắc phải có thể được phân loại và phân tích, cung cấp hiểu biết có giá trị cho những cải thiện tiềm năng. Ví dụ, nếu mô hình liên tục gặp khó khăn với một loại lời nhắc nhất định, có thể thực hiện các điều chỉnh đối với quy trình tinh chỉnh để xử lý tốt hơn những lời nhắc như vậy.

Có một loạt các chỉ số đánh giá có thể có thể được áp dụng cho LLM được tinh chỉnh. Mỗi chỉ số đều có điểm mạnh riêng. Với tầm quan trọng trung tâm của LLM được tinh chỉnh trong quy trình SLR được đề xuất, một đánh giá mạnh mẽ và quá trình toàn diện bao gồm các chỉ số định lượng, đánh giá so sánh, kiểm tra khả năng tái tạo và phân tích định tính cần được thực hiện và báo cáo. Một phương pháp được ghi chép kỹ lưỡng đảm bảo tính minh bạch và độ tin cậy của các SLR dựa trên LLM mang lại đầu ra chất lượng cao đáp ứng yêu cầu của quy trình SLR.

3.4 Báo cáo Các Cân nhắc về Khía cạnh Đạo đức và Pháp lý
Quá trình tinh chỉnh LLM trên một corpus các bài báo học thuật đòi hỏi sự điều hướng cẩn thận các cân nhắc về đạo đức, pháp lý và quyền riêng tư. Tác hại tiềm tàng có thể phát sinh từ các đầu ra của mô hình, như việc truyền bá thiên kiến, tạo ra nội dung không phù hợp hoặc vi phạm quyền riêng tư, là một mối quan ngại cần được xem xét [27].

Một mối quan ngại pháp lý chính là tuân thủ luật bản quyền. Những luật này hạn chế việc tái tạo, phân phối và hiển thị công khai các tác phẩm có bản quyền, bao gồm các phần đáng kể của một tác phẩm, ngay cả khi chúng được biến đổi. Ví dụ, việc tinh chỉnh một mô hình ngôn ngữ trên văn bản có bản quyền có thể được coi là sử dụng biến đổi, có thể thuộc về học thuyết pháp lý "sử dụng hợp lý" trong một số khu vực pháp lý nhất định như Hoa Kỳ. Tuy nhiên, việc áp dụng sử dụng hợp lý là chủ quan và được đánh giá dựa trên một số yếu tố, bao gồm mục đích và bản chất của việc sử dụng, đặc điểm của tác phẩm có bản quyền, lượng và tính quan trọng của phần được sử dụng, và tác động đến thị trường tiềm năng cho tác phẩm có bản quyền. Để giảm thiểu rủi ro vi phạm bản quyền, khuyến nghị tìm kiếm sự cho phép từ chủ sở hữu bản quyền, sử dụng các bài báo học thuật truy cập mở khi có thể, hoặc tham khảo ý kiến các chuyên gia pháp lý [27]. Những cân nhắc này cần được báo cáo như một phần của SLR.

Quyền riêng tư dữ liệu là một cân nhắc quan trọng khác, đặc biệt khi xử lý thông tin nhạy cảm. Ví dụ, trong các lĩnh vực như nghiên cứu y tế, các bài báo học thuật có thể chứa dữ liệu bệnh nhân nhạy cảm. Trong những trường hợp như vậy, điều quan trọng là đảm bảo tuân thủ luật bảo vệ dữ liệu và hướng dẫn đạo đức. Quá trình này nên được ghi lại, và các biện pháp nên được thực hiện để bảo vệ thông tin này trong quá trình tinh chỉnh và đặc biệt nếu dự định là làm cho mô hình được tinh chỉnh có sẵn cho công chúng.

Cuối cùng, quá trình tinh chỉnh có thể đưa vào hoặc khuếch đại các thiên kiến có trong dữ liệu huấn luyện. Như Sheng và cộng sự [27] thảo luận, các ứng dụng tạo ngôn ngữ như LLM có thể thể hiện nhiều loại thiên kiến và do đó điều quan trọng là theo dõi và giảm thiểu những điều này khi có thể. Ví dụ, các kỹ thuật như thuật toán giảm thiểu thiên kiến hoặc phương pháp học máy nhận thức công bằng có thể được sử dụng. Việc áp dụng đạo đức của khung PRISMA-DFLLM đòi hỏi cam kết sử dụng AI có trách nhiệm, tôn trọng quyền sở hữu trí tuệ và phương pháp chủ động để theo dõi và giảm thiểu các thiên kiến tiềm tàng và hướng dẫn báo cáo về những vấn đề này cần phù hợp với những khía cạnh này.

4 Hướng dẫn Báo cáo PRISMA Mở rộng
Dựa trên phần trước, việc mở rộng danh sách kiểm tra PRISMA 2020 gốc bao gồm một số danh mục mới. Phần này trình bày một mở rộng được đề xuất cho danh sách kiểm tra PRISMA 2020, được điều chỉnh cụ thể cho các nghiên cứu liên quan đến việc tinh chỉnh và áp dụng LLM để tiến hành SLR. Phần con sau đây trình bày một danh sách kiểm tra báo cáo bao gồm các đặc tính của việc chuẩn bị tập dữ liệu tinh chỉnh, quy trình tinh chỉnh LLM, đánh giá hiệu suất của mô hình và các cân nhắc đạo đức và pháp lý liên quan đến việc sử dụng LLM.

²Sự phù hợp, trong bối cảnh LLM, liên quan đến mức độ hòa hợp hoặc hài hòa giữa các đầu ra được tạo của mô hình và các đầu ra dự định hoặc mong đợi.

--- TRANG 9 ---
Mở rộng PRISMA sử dụng Mô hình Ngôn ngữ Lớn Tinh chỉnh theo Lĩnh vực cụ thể

4.1 Danh sách Kiểm tra PRISMA-DFLLM
Danh sách kiểm tra sửa đổi dưới đây làm nổi bật các mục mới.

1.TIÊU ĐỀ
1. Tiêu đề: Xác định báo cáo là một đánh giá hệ thống.

2.TÓM TẮT
2. Tóm tắt: Xem danh sách kiểm tra PRISMA 2020 cho Tóm tắt.

3.GIỚI THIỆU
3. Lý do: Mô tả lý do cho đánh giá trong bối cảnh kiến thức hiện có.
4. Mục tiêu: Cung cấp tuyên bố rõ ràng về (các) mục tiêu hoặc câu hỏi mà đánh giá giải quyết.

4.PHƯƠNG PHÁP
5. Tiêu chí đủ điều kiện: Chỉ rõ tiêu chí đưa vào và loại trừ cho đánh giá và cách các nghiên cứu được nhóm để tổng hợp.
6. Nguồn thông tin: Chỉ rõ tất cả cơ sở dữ liệu, đăng ký, trang web, tổ chức, danh sách tham chiếu và các nguồn khác được tìm kiếm hoặc tham khảo để xác định nghiên cứu. Chỉ rõ ngày khi mỗi nguồn được tìm kiếm hoặc tham khảo lần cuối.
7. Chiến lược tìm kiếm: Trình bày chiến lược tìm kiếm đầy đủ cho tất cả cơ sở dữ liệu, đăng ký và trang web, bao gồm bất kỳ bộ lọc và giới hạn nào được sử dụng.
8. Quy trình lựa chọn: Chỉ rõ các phương pháp được sử dụng để quyết định liệu một nghiên cứu có đáp ứng tiêu chí đưa vào của đánh giá hay không, bao gồm có bao nhiêu đánh giá viên sàng lọc mỗi bản ghi và mỗi báo cáo được truy xuất, liệu họ có làm việc độc lập hay không, và nếu có, chi tiết về các công cụ tự động được sử dụng trong quy trình.
9. Quy trình thu thập dữ liệu: Chỉ rõ các phương pháp được sử dụng để thu thập dữ liệu từ báo cáo, bao gồm có bao nhiêu đánh giá viên thu thập dữ liệu từ mỗi báo cáo, liệu họ có làm việc độc lập hay không, bất kỳ quy trình nào để có được hoặc xác nhận dữ liệu từ các điều tra viên nghiên cứu, và nếu có, chi tiết về các công cụ tự động được sử dụng trong quy trình.
10. Các mục dữ liệu:
    10a. Liệt kê và định nghĩa tất cả kết quả mà dữ liệu được tìm kiếm. Chỉ rõ liệu tất cả kết quả tương thích với mỗi lĩnh vực kết quả trong mỗi nghiên cứu có được tìm kiếm hay không (ví dụ cho tất cả các biện pháp, thời điểm, phân tích), và nếu không, các phương pháp được sử dụng để quyết định kết quả nào cần thu thập.
    10b. Liệt kê và định nghĩa tất cả các biến khác mà dữ liệu được tìm kiếm (ví dụ đặc điểm người tham gia và can thiệp, nguồn tài trợ). Mô tả bất kỳ giả định nào được đưa ra về bất kỳ thông tin thiếu hoặc không rõ ràng nào.
11. Đánh giá nguy cơ thiên kiến nghiên cứu: Chỉ rõ các phương pháp được sử dụng để đánh giá nguy cơ thiên kiến trong các nghiên cứu được bao gồm, bao gồm chi tiết về (các) công cụ được sử dụng, có bao nhiêu đánh giá viên đánh giá mỗi nghiên cứu và liệu họ có làm việc độc lập hay không, và nếu có, chi tiết về các công cụ tự động được sử dụng trong quy trình.
12. Biện pháp hiệu ứng: Chỉ rõ cho mỗi kết quả (các) biện pháp hiệu ứng (ví dụ tỷ lệ rủi ro, khác biệt trung bình) được sử dụng trong tổng hợp hoặc trình bày kết quả.
13. Phương pháp tổng hợp:
    13a. Mô tả các quy trình được sử dụng để quyết định nghiên cứu nào đủ điều kiện cho mỗi tổng hợp (ví dụ lập bảng đặc điểm can thiệp nghiên cứu và so sánh với các nhóm đã lên kế hoạch cho mỗi tổng hợp (mục #5)).
    13b. Mô tả bất kỳ phương pháp nào cần thiết để chuẩn bị dữ liệu cho trình bày hoặc tổng hợp, như xử lý số liệu thống kê tóm tắt thiếu, hoặc chuyển đổi dữ liệu.
    13c. Mô tả bất kỳ phương pháp nào được sử dụng để lập bảng hoặc hiển thị trực quan kết quả của các nghiên cứu cá nhân và tổng hợp.
    13d. Mô tả bất kỳ phương pháp nào được sử dụng để tổng hợp kết quả và cung cấp lý do cho (các) lựa chọn. Nếu phân tích meta được thực hiện, mô tả (các) mô hình, phương pháp để xác định sự hiện diện và mức độ của tính không đồng nhất thống kê, và (các) gói phần mềm được sử dụng.
    13e. Mô tả bất kỳ phương pháp nào được sử dụng để khám phá các nguyên nhân có thể có của tính không đồng nhất giữa kết quả nghiên cứu (ví dụ phân tích nhóm phụ, hồi quy meta).
    13f. Mô tả bất kỳ phân tích độ nhạy nào được tiến hành để đánh giá tính mạnh mẽ của kết quả được tổng hợp.
14. Đánh giá thiên kiến báo cáo: Mô tả bất kỳ phương pháp nào được sử dụng để đánh giá nguy cơ thiên kiến do kết quả thiếu trong một tổng hợp (phát sinh từ thiên kiến báo cáo).
15. Đánh giá độ chắc chắn: Mô tả bất kỳ phương pháp nào được sử dụng để đánh giá độ chắc chắn (hoặc độ tin cậy) trong khối bằng chứng cho một kết quả.

5.TẬP DỮ LIỆU TINH CHỈNH
16. Chi tiết của tập dữ liệu tinh chỉnh:
    16a. Tiền xử lý tập dữ liệu: Mô tả các thủ tục được sử dụng để xử lý và chuẩn bị các bài báo học thuật cho việc trích xuất thông tin.
    16b. Định dạng tập dữ liệu: Chỉ rõ cấu trúc của tập dữ liệu cuối cùng, bao gồm định dạng của dữ liệu đầu vào và đầu ra cho LLM.
    16c. Tăng cường dữ liệu: Báo cáo bất kỳ tập dữ liệu bổ sung nào được sử dụng cho tinh chỉnh hướng dẫn hoặc để tăng kiến thức lĩnh vực chung của LLM.
    16d. Curation tập dữ liệu: Chi tiết chiến lược được sử dụng để xây dựng tập dữ liệu tinh chỉnh, bao gồm các bước tự động hoặc thủ công được sử dụng để biểu diễn thông tin từ các bài báo học thuật.
    16e. Thành phần tập dữ liệu: Báo cáo các thuộc tính kích thước của tập dữ liệu tinh chỉnh cuối cùng.

6.TINH CHỈNH LLM
17. Chi tiết kỹ thuật tinh chỉnh:
    17a. Thông số kỹ thuật LLM: Biện minh cho việc lựa chọn LLM để tinh chỉnh, xem xét khả năng mô hình, đặc điểm kiến trúc và hiệu suất báo cáo trên các nhiệm vụ ngôn ngữ.
    17b. Chiến lược tinh chỉnh: Thảo luận chiến lược tinh chỉnh được sử dụng, liệu phương pháp cổ điển được sử dụng đòi hỏi cập nhật tham số mô hình đầy đủ, hay một cập nhật một phần được sử dụng.
    17c. Cài đặt tinh chỉnh: Giải thích thủ tục tinh chỉnh, bao gồm việc điều chỉnh siêu tham số và thuật toán tối ưu hóa được sử dụng để điều chỉnh các tham số của mô hình. Bao gồm bất kỳ kỹ thuật nào được sử dụng để ngăn chặn quá khớp, như dropout, weight decay, hoặc early stopping.
    17d. Hậu tinh chỉnh: Nêu bất kỳ bước xử lý hậu tinh chỉnh nào được thực hiện để tối ưu hóa hiệu suất của LLM.

7.ĐÁNH GIÁ LLM ĐƯỢC TINH CHỈNH
18. Xác thực LLM cụ thể theo lĩnh vực:
    18a. Đo điểm chuẩn LLM: Thảo luận hiệu suất ban đầu của LLM trước khi tinh chỉnh, trên một tập các nhiệm vụ điểm chuẩn mà mô hình sẽ được tinh chỉnh.
    18b. Tính ổn định và khả năng tái tạo đánh giá: Báo cáo bất kỳ biện pháp nào được thực hiện để đảm bảo tính mạnh mẽ của đánh giá, như nhiều lần chạy với các seed ngẫu nhiên khác nhau và biến đổi trong tập dữ liệu và các tham số ban đầu của mô hình.
    18c. Phân tích định tính: Bao gồm phân tích về các loại lỗi mà mô hình mắc phải và lý do tiềm tàng cho những lỗi này.
    18d. Sự phù hợp: Báo cáo hiệu suất của mô hình trên nhiệm vụ cũng như khả năng tạo ra các đầu ra mạch lạc, liên quan và có thể chấp nhận về mặt đạo đức.
    18e. Chỉ số đánh giá: Biện minh cho việc lựa chọn chỉ số đánh giá dựa trên yêu cầu nhiệm vụ.
    18f. Phân tích định tính: Thảo luận phân tích định tính về các đầu ra của mô hình, bao gồm các nghiên cứu trường hợp của ví dụ thành công và ít thành công hơn.

--- TRANG 10 ---
Mở rộng PRISMA sử dụng Mô hình Ngôn ngữ Lớn Tinh chỉnh theo Lĩnh vực cụ thể

8.KẾT QUẢ
19a. Lựa chọn nghiên cứu: Mô tả kết quả của quá trình tìm kiếm và lựa chọn, từ số lượng bản ghi được xác định trong tìm kiếm đến số lượng nghiên cứu được bao gồm trong đánh giá, lý tưởng là sử dụng sơ đồ dòng chảy.
19b. Trích dẫn các nghiên cứu có thể xuất hiện để đáp ứng tiêu chí đưa vào, nhưng đã bị loại trừ, và giải thích tại sao chúng bị loại trừ.
20. Đặc điểm nghiên cứu: Trích dẫn mỗi nghiên cứu được bao gồm và trình bày đặc điểm của nó.
21. Nguy cơ thiên kiến trong nghiên cứu: Trình bày đánh giá nguy cơ thiên kiến cho mỗi nghiên cứu được bao gồm.
22. Kết quả của các nghiên cứu cá nhân: Đối với tất cả kết quả, trình bày, cho mỗi nghiên cứu: (a) số liệu thống kê tóm tắt cho mỗi nhóm (khi thích hợp) và (b) ước tính hiệu ứng và độ chính xác của nó (ví dụ khoảng tin cậy/đáng tin cậy), lý tưởng là sử dụng bảng có cấu trúc hoặc biểu đồ.
23. Kết quả của tổng hợp:
    23a. Tóm tắt ngắn gọn đặc điểm và nguy cơ thiên kiến giữa các nghiên cứu đóng góp.
    23b. Trình bày kết quả của tất cả tổng hợp thống kê được tiến hành. Nếu phân tích meta được thực hiện, trình bày cho mỗi ước tính tóm tắt và độ chính xác của nó (ví dụ khoảng tin cậy/đáng tin cậy) và các biện pháp của tính không đồng nhất thống kê. Nếu so sánh các nhóm, mô tả hướng của hiệu ứng.
    23c. Trình bày kết quả của tất cả các điều tra về các nguyên nhân có thể có của tính không đồng nhất giữa kết quả nghiên cứu.
    23d. Trình bày kết quả của tất cả phân tích độ nhạy được tiến hành để đánh giá tính mạnh mẽ của kết quả được tổng hợp.
24. Thiên kiến báo cáo: Trình bày đánh giá nguy cơ thiên kiến do kết quả thiếu (phát sinh từ thiên kiến báo cáo) cho mỗi tổng hợp được đánh giá.
25. Độ chắc chắn của bằng chứng: Trình bày đánh giá độ chắc chắn (hoặc độ tin cậy) trong khối bằng chứng cho mỗi kết quả được đánh giá.

9.THẢO LUẬN
26a. Thảo luận: Cung cấp diễn giải chung về kết quả trong bối cảnh bằng chứng khác.
26b. Thảo luận bất kỳ hạn chế nào của bằng chứng được bao gồm trong đánh giá.
26c. Thảo luận bất kỳ hạn chế nào của các quy trình đánh giá được sử dụng.
26d. Thảo luận ý nghĩa của kết quả đối với thực hành, chính sách và nghiên cứu tương lai.
26e. Thảo luận các quy trình để cho phép một đánh giá hệ thống sống liên tục và gia tăng.

10.THÔNG TIN KHÁC
27a. Đăng ký và giao thức: Cung cấp thông tin đăng ký cho đánh giá, bao gồm tên đăng ký và số đăng ký, hoặc nêu rằng đánh giá không được đăng ký.
27b. Chỉ ra nơi có thể truy cập giao thức đánh giá, hoặc nêu rằng giao thức không được chuẩn bị.
27c. Mô tả và giải thích bất kỳ sửa đổi nào đối với thông tin được cung cấp tại đăng ký hoặc trong giao thức.
28. Hỗ trợ: Mô tả các nguồn hỗ trợ tài chính hoặc phi tài chính cho đánh giá, và vai trò của những người tài trợ hoặc nhà tài trợ trong đánh giá.
29. Lợi ích cạnh tranh: Tuyên bố bất kỳ lợi ích cạnh tranh nào của các tác giả đánh giá.
30. Tính có sẵn của dữ liệu, mã và tài liệu khác: Báo cáo những gì sau đây có sẵn công khai và nơi có thể tìm thấy chúng: biểu mẫu thu thập dữ liệu mẫu; dữ liệu được trích xuất từ các nghiên cứu được bao gồm; dữ liệu được sử dụng cho tất cả phân tích; mã phân tích; bất kỳ tài liệu nào khác được sử dụng trong đánh giá; tính có sẵn của tập dữ liệu tinh chỉnh và LLM được tinh chỉnh.
31. Thông tin Pháp lý và Đạo đức LLM:
    31a. Ý nghĩa đạo đức LLM: Giải quyết tiềm năng cho các đầu ra của LLM gây tác hại, hoặc thông qua việc truyền bá thiên kiến, tạo ra nội dung không phù hợp, hoặc vi phạm quyền riêng tư.
    31b. Ý nghĩa pháp lý LLM: Thảo luận ý nghĩa pháp lý của việc tinh chỉnh LLM trên các bài báo học thuật, bao gồm các cân nhắc về luật bản quyền, sử dụng hợp lý và có được sự cho phép từ chủ sở hữu bản quyền khi cần thiết.
    31c. Tuân thủ LLM: Ghi lại quá trình đảm bảo tuân thủ luật bảo vệ dữ liệu và hướng dẫn đạo đức.

5 Thảo luận
Việc phát triển LLM được tinh chỉnh cụ thể theo lĩnh vực cho các ngành riêng lẻ, có khả năng hỗ trợ SLR mạnh mẽ, trình bày một con đường đầy hứa hẹn; tuy nhiên, việc theo đuổi này cũng đưa ra những thách thức độc đáo đòi hỏi khám phá và nghiên cứu thêm.

5.1 Lợi ích Tiềm năng của PRISMA-DFLLM

Tăng cường Hiệu quả Việc tích hợp LLM được tinh chỉnh cụ thể theo lĩnh vực vào SLR có thể tăng cường đáng kể hiệu quả của quy trình đánh giá. Bằng cách tự động hóa các nhiệm vụ tốn nhiều lao động như trích xuất dữ liệu và tổng hợp bằng chứng, các nhà nghiên cứu có thể giảm đáng kể thời gian và tài nguyên thường được yêu cầu cho những nhiệm vụ này. Ví dụ, một LLM cụ thể theo lĩnh vực được huấn luyện trên tài liệu y tế có thể tự động trích xuất dữ liệu liên quan từ một số lượng lớn các thử nghiệm lâm sàng, như nhân khẩu học bệnh nhân, chi tiết can thiệp và các biện pháp kết quả, từ đó đẩy nhanh việc sản xuất các đánh giá hệ thống. Hiệu quả tăng này có thể cho phép các nhà nghiên cứu theo kịp khối lượng tài liệu mở rộng nhanh chóng và đáp ứng nhanh hơn các câu hỏi nghiên cứu mới nổi.

Khả năng Mở rộng và Đánh giá Hệ thống Sống LLM được tinh chỉnh cụ thể theo lĩnh vực cung cấp khả năng mở rộng, tạo điều kiện cho việc đánh giá một khối lượng lớn tài liệu trong khung thời gian ngắn. Khả năng của các mô hình ngôn ngữ được tinh chỉnh có thể được tận dụng để phân tích một số lượng lớn hơn các bài báo ở mức độ toàn diện. Khả năng mở rộng này đặc biệt có lợi trong các lĩnh vực nghiên cứu có tỷ lệ xuất bản cao hoặc khi tiến hành cập nhật thường xuyên của đánh giá hệ thống. Ví dụ, trong lĩnh vực bệnh truyền nhiễm, nơi nghiên cứu mới về các bệnh như COVID-19 được xuất bản với tốc độ nhanh, một LLM cụ thể theo lĩnh vực có thể giúp các nhà nghiên cứu theo kịp những phát hiện mới nhất. Hơn nữa, khả năng mở rộng của LLM được tinh chỉnh cụ thể theo lĩnh vực mở đường cho việc thực hiện LSR cập nhật gia tăng cơ sở kiến thức của LLM cụ thể theo lĩnh vực cơ bản. Khi các siêu tham số huấn luyện và quy trình trích xuất dữ liệu đã được tối ưu hóa, lợi nhuận đầu tư nỗ lực sau đó được thực hiện thông qua khả năng cập nhật LLM trên cơ sở liên tục.

Khám phá Hiểu biết Mới lạ Việc áp dụng PRISMA-DFLLM có thể phát hiện ra những hiểu biết và mẫu mới lạ trong tài liệu. Bằng cách sử dụng LLM chuyên biệt, các nhà nghiên cứu có thể xác định các kết nối, xu hướng và mối quan hệ mới trên các nghiên cứu có thể không ngay lập tức rõ ràng thông qua các phương pháp đánh giá truyền thống. Khả năng tạo ra hiểu biết mới lạ này có thể làm phong phú hiểu biết về một chủ đề nghiên cứu, tạo ra lý thuyết mới và kích thích điều tra thêm.

Phổ biến và Hợp tác Một lợi ích đáng kể của các ý tưởng cơ bản đằng sau PRISMA-DFLLM là tiềm năng phổ biến LLM được tinh chỉnh trên các nhóm nghiên cứu và tổ chức khác nhau. Các nhà nghiên cứu có thể chia sẻ các mô hình được huấn luyện, cho phép những người khác sử dụng và hưởng lợi từ chuyên môn và phát hiện của họ. Việc phổ biến này thúc đẩy tính minh bạch, hợp tác và xây dựng kiến thức tích lũy trong cộng đồng nghiên cứu và chia sẻ chi phí tài nguyên trong việc cập nhật các mô hình với nghiên cứu mới. Ví dụ, các nhóm nghiên cứu có thể phân phối các nhiệm vụ tinh chỉnh giữa họ, nơi một số tập trung vào curation tập dữ liệu và những người khác vào quy trình tinh chỉnh LLM, từ đó đẩy nhanh nghiên cứu.

5.2 Thách thức Tiềm năng của việc Thực hiện PRISMA-DFLLM
Việc thực hiện khung PRISMA-DFLLM, mặc dù đầy hứa hẹn, đặt ra một số thách thức. Chúng bao gồm việc tự động hóa trích xuất dữ liệu từ các bài viết học thuật thô, xác định các chiến lược PEFT tối ưu, đảm bảo sự phù hợp và đánh giá các mô hình được tinh chỉnh.

Tự động hóa Trích xuất Dữ liệu từ Các Bài viết Học thuật Thô Tự động hóa việc trích xuất dữ liệu từ các bài viết học thuật thô cho mục đích tinh chỉnh LLM là phức tạp. Các bài viết học thuật, trong khi thường tuân thủ một số quy ước nhất định như cấu trúc IMRaD (Giới thiệu, Phương pháp, Kết quả và Thảo luận), có thể thay đổi rất nhiều trong tổ chức và trình bày thông tin của chúng. Sự biến đổi này có thể làm cho LLM khó khăn để nhất quán định vị và trích xuất thông tin cần thiết cho đánh giá hệ thống, như thiết kế nghiên cứu, đặc điểm người tham gia và kết quả. Hơn nữa, các bài viết học thuật thường chứa thông tin có giá trị ở các định dạng không phải văn bản như bảng, hình và hình ảnh. Việc trích xuất và mã hóa thông tin này dưới dạng văn bản để huấn luyện LLM đặt ra một lớp phức tạp khác và có thể sẽ đòi hỏi các thành phần AI bổ sung để giải quyết đầy đủ. LLM hiện tại chủ yếu được thiết kế để xử lý văn bản và có thể gặp khó khăn trong việc diễn giải và tích hợp thông tin từ các nguồn không phải văn bản này. Việc phát triển các phương pháp hoặc công cụ mới để tự động hóa việc trích xuất và mã hóa dữ liệu từ những định dạng này là một nhu cầu nghiên cứu cấp thiết.

Ngoài ra, dữ liệu thô từ các bài viết học thuật thường ở định dạng PDF, không dễ dàng sử dụng được cho việc huấn luyện mô hình. Việc chuyển đổi PDF thành định dạng có thể đọc được bằng máy đưa các bước bổ sung vào quy trình chuẩn bị dữ liệu, mỗi bước có thể đưa vào lỗi hoặc biến dạng đòi hỏi giám sát và xác minh của con người. Hơn nữa, việc tạo ra các tập dữ liệu tinh chỉnh từ các bài viết học thuật không phải là một nhiệm vụ đơn giản. Phải đạt được sự cân bằng giữa việc cung cấp cho mô hình dữ liệu thô, mang lại cho nó hiểu biết rộng hơn về nội dung và bối cảnh của các bài viết, và cung cấp cho nó dữ liệu có cấu trúc dưới dạng các cặp câu hỏi-trả lời, có thể hướng dẫn việc học của mô hình theo những cách cụ thể hơn. Việc xác định sự cân bằng và tích hợp tối ưu của những loại dữ liệu khác nhau này là một câu hỏi nghiên cứu mở.

Chiến lược PEFT Tối ưu Việc chọn chiến lược PEFT tốt nhất để phát triển LLM cụ thể theo lĩnh vực là một nhiệm vụ đa diện. Quyết định phụ thuộc vào bản chất của nhiệm vụ, dữ liệu huấn luyện có sẵn và tài nguyên tính toán. Tinh chỉnh cụ thể theo nhiệm vụ với PEFT loại bỏ nhu cầu tiền huấn luyện nhưng đặt giá cao cho curation dữ liệu hiệu quả và cài đặt huấn luyện siêu tham số tối ưu. Các kỹ thuật như Thích ứng Hạng thấp (LoRA) và LoRA Lượng tử hóa (QLoRA) cung cấp các lựa chọn thay thế hiệu quả về tài nguyên, nhưng việc chọn giữa chúng phụ thuộc vào đặc tính của nhiệm vụ và tài nguyên có sẵn. Một ensemble các mô hình chuyên biệt, mỗi mô hình được tinh chỉnh trên một tập con nhiệm vụ, có thể tăng cường hiệu suất, nhưng việc điều phối những mô hình này và tích hợp đầu ra của chúng có thể phức tạp và tốn kém về mặt tính toán. Các phương pháp học tích cực tối ưu hóa quy trình tinh chỉnh nhưng đòi hỏi tương tác liên tục với người chú thích, đưa vào các thách thức tiềm tàng về quyền riêng tư dữ liệu, kiểm soát chất lượng cũng như chi phí bổ sung. Về bản chất, việc lựa chọn phương pháp tinh chỉnh hiệu quả nhất đòi hỏi cân nhắc cẩn thận về các yếu tố khác nhau và sự đánh đổi tiềm tàng, làm nổi bật nhu cầu nghiên cứu liên tục trong tinh chỉnh LLM.

--- TRANG 11 ---
Mở rộng PRISMA sử dụng Mô hình Ngôn ngữ Lớn Tinh chỉnh theo Lĩnh vực cụ thể

Đánh giá Các Mô hình được Tinh chỉnh để Đạt Sự Phù hợp Đảm bảo sự phù hợp giữa LLM được tinh chỉnh và yêu cầu nhiệm vụ cụ thể, cũng như hướng dẫn đạo đức, là một khía cạnh phức tạp nhưng quan trọng của việc phát triển mô hình. Quá trình này mở rộng ra ngoài các kỹ thuật của việc huấn luyện mô hình để bao gồm các cân nhắc đạo đức và xã hội rộng hơn. Ví dụ, mô hình nên được thiết kế để tránh các thiên kiến tiềm tàng trong đầu ra của nó, điều này đòi hỏi curation và kiểm tra cẩn thận dữ liệu huấn luyện. Ngoài ra, mô hình nên tôn trọng các chuẩn mực riêng tư, đặc biệt khi xử lý dữ liệu hoặc chủ đề nhạy cảm. Điều này có thể liên quan đến việc thực hiện các cơ chế để ngăn mô hình tạo ra nội dung không phù hợp hoặc nhạy cảm. Kiểm tra sự phù hợp là một quá trình đa diện có thể sử dụng cả phương pháp định lượng và định tính. Phương pháp định lượng có thể liên quan đến các chỉ số hiệu suất như độ chính xác, precision, recall hoặc F1 score, cũng như các điểm chuẩn tùy chỉnh được điều chỉnh cho nhiệm vụ cụ thể. Mặt khác, phương pháp định tính có thể liên quan đến việc kiểm tra chi tiết các đầu ra của mô hình. Ví dụ, các đánh giá viên chuyên gia có thể đánh giá liệu các phản hồi của mô hình có phù hợp về mặt ngữ cảnh, mạch lạc và không có thiên kiến hay không. Họ cũng có thể đánh giá khả năng của mô hình trong việc xử lý các truy vấn phức tạp và độ nhạy cảm của nó đối với lời nhắc đầu vào. Hơn nữa, kiểm tra sự phù hợp cũng nên xem xét khả năng diễn giải và minh bạch của mô hình. Ví dụ, mô hình có thể cung cấp giải thích cho đầu ra của nó không? Có rõ ràng mô hình đang sử dụng dữ liệu đầu vào như thế nào để tạo ra phản hồi của nó không? Đây là những câu hỏi quan trọng để đảm bảo sự phù hợp của mô hình với hướng dẫn đạo đức và kỳ vọng của người dùng.

Tính Có sẵn của Dữ liệu Đảm bảo một corpus toàn diện và đa dạng của các bài báo học thuật để tinh chỉnh LLM có thể là một nhiệm vụ khó khăn. Tính sẵn có của các tài nguyên truy cập mở có thể bị hạn chế, và khả năng truy cập của một số tạp chí hoặc bài báo nhất định có thể bị cản trở bởi paywall hoặc thỏa thuận cấp phép. Ví dụ, một nhà nghiên cứu nhằm tinh chỉnh một mô hình trên tài liệu AI có thể phát hiện ra rằng các tạp chí chính trong lĩnh vực này không chỉ bị che giấu đằng sau paywall, mà còn rõ ràng cấm sử dụng nội dung của họ cho việc tinh chỉnh LLM. Hạn chế này có thể giới hạn đáng kể tính đa dạng và tính đại diện của tập dữ liệu huấn luyện, từ đó tác động đến khả năng chuyên biệt đủ của mô hình trong một lĩnh vực nhất định và tiến hành một đánh giá PRISMA đầy đủ. Hơn nữa, vấn đề tính sẵn có của dữ liệu không tĩnh mà phát triển. Khi nghiên cứu mới được xuất bản, dữ liệu huấn luyện cần được cập nhật để đảm bảo mô hình vẫn hiện tại. Điều này đòi hỏi truy cập liên tục vào các xuất bản mới, có thể không luôn được đảm bảo do thay đổi trong chính sách truy cập hoặc thỏa thuận cấp phép.

Từ vựng Cụ thể theo Lĩnh vực Các lĩnh vực nghiên cứu khác nhau thường sử dụng từ vựng và thuật ngữ chuyên biệt riêng của họ. Ví dụ, thuật ngữ "tế bào" có ý nghĩa khác nhau trong sinh học và bối cảnh công nghệ truyền thông di động. Việc thích ứng mô hình ngôn ngữ để hiểu chính xác và tạo ra ngôn ngữ cụ thể theo lĩnh vực là quan trọng, và có thể đòi hỏi tinh chỉnh bổ sung hoặc sử dụng các corpus cụ thể theo lĩnh vực.

5.3 Hướng nghiên cứu tương lai để thúc đẩy đánh giá tài liệu được hỗ trợ bởi LLM
Dựa trên các thách thức và cơ hội được thảo luận trong phần trước, bảng sau liệt kê các hướng nghiên cứu tương lai dưới một số danh mục chính và cố gắng gắn nhãn chúng theo cả độ khó khăn của việc thực hiện và tính cấp thiết của nó.

Bảng 1: Hướng nghiên cứu tương lai cho Khung PRISMA-DFLLM, làm nổi bật các danh mục chính, mức độ khó khăn và ưu tiên của các công việc khác nhau.

[Bảng tiếp tục với nhiều hàng chi tiết về các hướng nghiên cứu, mức độ khó khăn và ưu tiên]

6 Kết luận
Sự ra đời của các Mô hình Ngôn ngữ Lớn (LLM) mã nguồn mở và các kỹ thuật tinh chỉnh hiệu quả báo trước một kỷ nguyên mới trong nghiên cứu học thuật, đặc biệt trong lĩnh vực đánh giá tài liệu hệ thống (SLR). Tiềm năng của những công nghệ này để cách mạng hóa cách chúng ta tiếp cận kiến thức, tiến hành SLR và tạo ra những hiểu biết mới là to lớn. Phương pháp được đề xuất và khung PRISMA-DFLLM (LLM Tinh chỉnh theo Lĩnh vực cụ thể), kết hợp sức mạnh của LLM chuyên gia với hướng dẫn báo cáo của Các Mục Báo cáo Ưa thích cho Đánh giá Hệ thống và Phân tích Meta (PRISMA), đại diện cho một bước tiến đáng kể hướng tới việc thực hiện tiềm năng này. Những hướng dẫn này đã được mở rộng từ danh sách kiểm tra 27 mục lên 31 mục.

Sự kết hợp của LLM được tinh chỉnh với khung PRISMA-DFLLM mang lại lời hứa về hiệu quả, khả năng tái sử dụng và khả năng mở rộng lớn hơn trong việc tiến hành SLR. Bằng cách tinh chỉnh LLM trên các bài báo học thuật cụ thể theo lĩnh vực được chọn thông qua quy trình SLR có nguyên tắc, chúng ta có thể tạo ra các mô hình không chỉ thành thạo hơn trong việc xử lý các lĩnh vực và ứng dụng chuyên biệt mà còn có khả năng tiến hành đánh giá tài liệu hệ thống sống gia tăng. Phương pháp này dân chủ hóa nghiên cứu tiên tiến, trao quyền cho các nhà nghiên cứu trên toàn cầu bằng cách cho phép họ tận dụng những mô hình được tinh chỉnh này để đẩy nhanh tiến bộ trong các lĩnh vực tương ứng của họ.

Tuy nhiên, hành trình hướng tới việc thực hiện đầy đủ tiềm năng của PRISMA-DFLLM không phải không có thách thức. Từ việc đảm bảo tính sẵn có của dữ liệu và tự động hóa trích xuất dữ liệu từ các bài viết học thuật thô đến xác định các chiến lược PEFT tối ưu và đảm bảo sự phù hợp với yêu cầu nhiệm vụ và hướng dẫn đạo đức, mỗi bước đều đặt ra những trở ngại độc đáo. Vượt qua những thách thức này đòi hỏi các giải pháp đổi mới, nghiên cứu liên tục và cân nhắc cẩn thận về ý nghĩa đạo đức và xã hội của công việc này.

Bài báo này đã đưa ra lý lẽ cho tính khả thi của LLM chuyên gia, được tinh chỉnh để hỗ trợ SLR nghiêm ngặt và đã nêu ra các yêu cầu kỹ thuật để thực hiện tầm nhìn này. Danh sách kiểm tra hướng dẫn báo cáo PRISMA-DFLLM mở rộng được đề xuất cung cấp lộ trình cho các nhà nghiên cứu tìm cách thực hiện phương pháp này. Khi chúng ta tiến về phía trước, điều quan trọng là chúng ta tiếp tục khám phá, xác thực và tinh chỉnh phương pháp này, mở đường cho một kỷ nguyên mới của tổng hợp bằng chứng và khám phá kiến thức. Tương lai của nghiên cứu học thuật đang ở phía trước, và đó là một tương lai nơi SLR được hỗ trợ bởi AI đóng vai trò mới và quan trọng.

Tài liệu tham khảo
[1] OpenAI: About. https://openai.com/about/. Accessed on 14 June 2023.
[2]E. Bolton, D. Hall, M. Yasunaga, T. Lee, C. Manning, and P. Liang. Stanford crfm introduces pubmedgpt 2.7b. https://hai.stanford.edu/news/stanford-crfm-introduces-pubmedgpt-27b, 2022. Accessed: 13 June 2023.
[3]T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al. Language models are few-shot learners. arXiv preprint arXiv:2005.14165, 2020.
[4]J. Chen, A. Zhang, X. Shi, M. Li, A. Smola, and D. Yang. Parameter-efficient fine-tuning design spaces. arXiv preprint arXiv:2301.01821, 2023.
[5]D. Curcic. Number of academic papers published per year. https://wordsrated.com/number-of-academic-papers-published-per-year. Accessed on 14th June 2023.
[6]T. Dettmers, A. Pagnoni, A. Holtzman, and L. Zettlemoyer. Qlora: Efficient finetuning of quantized llms, 2023.
[7]J. H. Elliott, T. Turner, O. Clavisi, J. Thomas, J. P. Higgins, C. Mavergames, and R. L. Gruen. Living systematic reviews: an emerging opportunity to narrow the evidence-practice gap. PLoS Med, 11(2):e1001603, 2014.
[8]E. Forsgren, S. Wallström, C. Feldthusen, N. Zechner, R. Sawatzky, and J. Öhlén. The use of text-mining software to facilitate screening of literature on centredness in health care. Systematic Reviews, 12(1):73, 2023.
[9]A. Gui, J. Ye, and H. Xiao. G-adapter: Towards structure-aware parameter-efficient transfer learning for graph transformer networks. arXiv preprint arXiv:2305.10329, 2023.
[10]E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen. Lora: Low-rank adaptation of large language models, 2021.
[11]Z. Hu, Y. Lan, L. Wang, W. Xu, E.-P. Lim, R. K.-W. Lee, L. Bing, and S. Poria. Llm-adapters: An adapter family for parameter-efficient fine-tuning of large language models. arXiv preprint arXiv:2304.01933, 2023.
[12]B. Hutton, G. Salanti, D. M. Caldwell, A. Chaimani, C. H. Schmid, C. Cameron, J. P. Ioannidis, S. Straus, K. Thorlund, et al. The prisma extension statement for reporting of systematic reviews incorporating network meta-analyses of health care interventions: checklist and explanations. Annals of internal medicine, 162(11):777-784, 2015.
[13]J. Knafou, Q. Haas, N. Borissov, M. Counotte, N. Low, H. Imeri, A. M. Ipekci, D. Buitrago-Garcia, L. Heron, P. Amini, et al. Ensemble of deep learning language models to support the creation of living systematic reviews for the covid-19 literature. Systematic Reviews, 12(1):94, 2023.
[14]K. Kolaski, L. R. Logan, and J. P. A. Ioannidis. Guidance to best tools and practices for systematic reviews. Systematic Reviews, 12(1):96, 2023. ISSN 2046-4053. doi: 10.1186/s13643-023-02255-9. URL https://doi.org/10.1186/s13643-023-02255-9.
[15] E. Landhuis. Scientific literature: Information overload. Nature, 535(7612):457-458, 2016.
[16]E. Lehman, E. Hernandez, D. Mahajan, J. Wulff, M. J. Smith, Z. Ziegler, D. Nadler, P. Szolovits, A. Johnson, and E. Alsentzer. Do we still need clinical language models? arXiv preprint arXiv:2302.08091, 2023.
[17]I. J. Marshall and B. C. Wallace. Toward systematic review automation: a practical guide to using machine learning tools in research synthesis. Systematic reviews, 8:1-10, 2019.
[18]D. Moher, D. J. Cook, S. Eastwood, I. Olkin, D. Rennie, and D. F. Stroup. Improving the quality of reports of meta-analyses of randomised controlled trials: the quorom statement. The Lancet, 354(9193):1896-1900, 1999.
[19]D. Moher, A. Liberati, J. Tetzlaff, and D. G. Altman. Preferred reporting items for systematic reviews and meta-analyses: the prisma statement. PLoS medicine, 6(7):e1000097, 2009.
[20]D. Moher, L. Shamseer, M. Clarke, D. Ghersi, A. Liberati, M. Petticrew, P. Shekelle, and L. A. Stewart. Preferred reporting items for systematic review and meta-analysis protocols (prisma-p) 2015 statement. Systematic reviews, 4(1):1-9, 2015.

--- TRANG 12 đến 20 ---
[Tiếp tục danh sách tài liệu tham khảo từ [21] đến [40] với các nghiên cứu về học máy, AI, LLM, và đánh giá hệ thống]

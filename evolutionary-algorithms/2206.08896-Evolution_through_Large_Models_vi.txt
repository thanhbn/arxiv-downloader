# 2206.08896.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/evolutionary-algorithms/2206.08896.pdf
# Kích thước tệp: 2463288 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Tiến hóa thông qua các Mô hình Lớn
Joel Lehman
OpenAI
joel@openai.comJonathan Gordon
OpenAI
gordonjo@openai.com
Shawn Jain
OpenAI
jains@openai.comKamal Ndousse
Anthropic∗
kamal.ndousse@gmail.com
Cathy Yeh
OpenAI
cathy@openai.comKenneth O. Stanley
OpenAI
kennethostanley@gmail.com
20 tháng 6 năm 2022
Tóm tắt
Bài báo này theo đuổi cái nhìn sâu sắc rằng các mô hình ngôn ngữ lớn (LLMs) được huấn luyện để tạo mã có thể cải thiện đáng kể hiệu quả của các toán tử đột biến được áp dụng cho các chương trình trong lập trình di truyền (GP). Bởi vì những LLMs như vậy được hưởng lợi từ dữ liệu huấn luyện bao gồm các thay đổi và sửa đổi tuần tự, chúng có thể xấp xỉ những thay đổi có khả năng mà con người sẽ thực hiện. Để làm nổi bật tính rộng lớn của những tác động của việc tiến hóa thông qua các mô hình lớn (ELM) như vậy, trong thí nghiệm chính ELM kết hợp với MAP-Elites tạo ra hàng trăm nghìn ví dụ chức năng của các chương trình Python xuất ra các robot đi bộ hoạt động trong miền Sodarace, mà LLM ban đầu chưa từng thấy trong quá trình tiền huấn luyện. Những ví dụ này sau đó giúp khởi động việc huấn luyện một mô hình ngôn ngữ có điều kiện mới có thể xuất ra walker phù hợp cho một địa hình cụ thể. Khả năng khởi động các mô hình mới có thể xuất ra các tạo phẩm phù hợp cho một bối cảnh nhất định trong một miền nơi trước đây không có dữ liệu huấn luyện mang lại những tác động đối với tính mở rộng, học sâu và học tăng cường. Những tác động này được khám phá ở đây một cách sâu sắc với hy vọng truyền cảm hứng cho các hướng nghiên cứu mới hiện đã được mở ra bởi ELM.

1 Giới thiệu
Đối với nhiều người trong cộng đồng tính toán tiến hóa (EC), sự nổi lên của học sâu (DL) đã nêu ra những câu hỏi về những tác động của nó đối với EC. Cả hai phương pháp đều mở rộng tốt với tính toán và cả hai đều có thể mang lại những khám phá hữu ích và những bất ngờ có ý nghĩa. Tuy nhiên, cuối cùng chúng có phải là những mô hình cạnh tranh hay thực ra chúng bổ sung cho nhau? Trong bài báo này, chúng tôi khám phá khả năng sau, về sự hiệp lực đáng kể, bằng cách làm nổi bật một tác động chưa được khai thác của các mô hình ngôn ngữ lớn (LLMs; [1, 2]) đối với cả lập trình di truyền (GP; [3, 4]) và tính mở rộng [5{7].

Cụ thể, trong phương pháp Tiến hóa thông qua Mô hình Lớn (ELM) mới này, một LLM được huấn luyện trên mã có thể đề xuất các đột biến thông minh, do đó tạo điều kiện cho một toán tử đột biến hiệu quả hơn đáng kể, vượt qua nhiều thách thức đã tồn tại trước đây cho việc tiến hóa các chương trình [8]. Thú vị là, những lợi ích của ELM cũng có tính tương hỗ trở lại với học sâu: tập hợp các mẫu được tạo thông qua LLM cuối cùng có thể tạo thành một tập huấn luyện mới trong một miền mới mà sau đó có thể tinh chỉnh LLM để hoạt động tốt trong miền mới, một quy trình tạo dữ liệu mới lạ. Hơn nữa, phương pháp này cuối cùng mở ra những cơ hội mới trong việc theo đuổi tính mở rộng bằng cách tăng khả năng tạo sinh của LLM chỉ thông qua dữ liệu do chính nó tạo ra.

LLMs gần đây đã mang lại những kết quả ấn tượng trong việc tạo mã tự động [9, 10]. Những mô hình này khởi động từ kiến thức con người bằng cách học từ các tập dữ liệu rất lớn để đạt được năng lực lập trình tổng quát. Thực tế rằng việc khởi động như vậy là có thể rõ ràng liên quan đến GP. Xét cho cùng, GP thực chất là một phương pháp tạo sinh cho lập trình. Mặc dù thoạt nhìn có vẻ như LLMs có thể cạnh tranh hoặc thay thế GP, thực tế GP vẫn mang lại lợi thế trong những tình huống mà lớp chương trình cụ thể được tìm kiếm nằm xa (hoặc thậm chí hoàn toàn thiếu) khỏi phân phối huấn luyện của LLM. Trong những trường hợp như vậy, LLM cung cấp ít phương án khắc phục (kỹ thuật prompt để học một miền hoàn toàn mới sẽ không khả thi), trong khi GP về nguyên tắc có thể tiến hóa trong bất kỳ không gian nào (mặc dù trong thực tế một số không gian có thể không thể giải quyết được do lượng đột biến cần thiết để có được tín hiệu nhất quán về fitness).

Thú vị (và có lẽ đáng ngạc nhiên), điều tốt nhất của cả hai thế giới có thể dễ dàng đạt được bằng cách kết hợp chúng: đơn giản bằng cách nhắc LLM tạo ra các thay đổi, LLM có thể phục vụ như một toán tử đột biến rất tinh vi được nhúng trong một thuật toán tiến hóa tổng thể. Theo cách này, LLM kết hợp với tiến hóa có thể điều hướng lẫn nhau về phía khu vực đúng của không gian giải pháp mặc dù cả tiến hóa với toán tử đột biến thông thường và LLM riêng lẻ đều không thể tạo ra gì gần gũi. Thực chất, tiến hóa chương trình sử dụng nhiễu loạn dựa trên LLM bắt đầu thu hẹp khoảng cách giữa các thuật toán tiến hóa và những thuật toán hoạt động ở cấp độ ý tưởng con người. Tức là, LLMs có thể được huấn luyện để xấp xỉ cách con người cố ý thay đổi chương trình, trong khi vẫn ở trên đa tạp của chức năng. Hơn nữa, những LLMs như vậy có thể được tinh chỉnh thêm trên các nhiễu loạn thành công cho mục đích tự cải thiện, đỉnh điểm là một kỹ thuật mới để tăng cường hiệu suất của ELM một cách lặp đi lặp lại.

Để làm nổi bật tiềm năng của phương pháp này, trong bài báo này, toàn bộ tập dữ liệu trong một miền mới được tạo ra chỉ từ một ví dụ khởi đầu tầm thường duy nhất được thiết kế thủ công bởi con người. Cụ thể, miền được gọi là Sodarace [11, 12], nơi các robot đi bộ hai chiều với hình thái tùy ý được xây dựng cho các địa hình đa dạng. Sodarace rẻ để mô phỏng, cho phép lặp lại nhanh chóng, và cũng giúp dễ dàng đánh giá sự tinh vi của các thiết kế một cách trực quan bằng cách chỉ đơn giản xem robot đi bộ. Theo cách này, nó tạo điều kiện đánh giá nhanh chóng liệu một thiết kế có thành công hay không cả về mặt định lượng và định tính.

Để làm cho đóng góp của ELM trở nên rõ ràng trong các thí nghiệm trong bài báo này, các Sodaracers được mã hóa như các chương trình Python thô xuất ra một liệt kê các thành phần của robot đi bộ. Theo cách đó, có thể chứng minh rằng ELM là một dạng GP có thể hoạt động trực tiếp trên một ngôn ngữ lập trình hiện đại, không cần các điều khoản đặc biệt nào ngoài LLM tạo mã chung (tức là không được huấn luyện trước trong Sodarace) hiện có.

Một cái nhìn sâu sắc quan trọng cuối cùng được mở khóa bởi phương pháp này là khả năng tạo ra các giải pháp đa dạng trong một miền hoặc một phần của không gian tìm kiếm nơi có ít hoặc không có dữ liệu huấn luyện là nền tảng cho việc khởi động một quá trình mở rộng [6, 13, 14]. Xét cho cùng, tính mở rộng về cơ bản là về việc tìm kiếm ngoài phân phối của kinh nghiệm trước đây, đó chính xác là điều mà ELM giúp LLM thực hiện. Bởi vì khả năng mới lạ này có những tác động có thể xa tầm, chúng tôi đã chọn trong công trình này tập trung vào những tác động của dữ liệu được tạo ra có thể được sản xuất bởi ELM. Tất nhiên, ELM có thể áp dụng trong nhiều bối cảnh khác mà chắc chắn sẽ được khám phá trong tương lai.

Cụ thể hơn, các thí nghiệm tiếp theo cho thấy rằng dữ liệu được tạo ra đủ phong phú để có thể phục vụ như dữ liệu huấn luyện cho việc tinh chỉnh LLMs để tạo mã cho các Sodaracers khả thi một cách nhất quán, và hơn nữa rằng học tăng cường (RL) thậm chí có thể tinh chỉnh một LLM được tăng cường để xuất ra Sodaracers có điều kiện, tùy thuộc vào địa hình. Trong tương lai, việc phát minh có điều kiện như vậy có tiềm năng mở khóa các loại quá trình mở rộng hoàn toàn mới, giống như con người đã xây dựng nền văn minh một cách mở rộng qua nhiều thế kỷ bằng cách phát minh có điều kiện các thành phần cấu thành của nó.

Tóm lại, những đóng góp chính của bài báo này là (1) phương pháp ELM để tiến hóa chương trình một cách hiệu quả thông qua LLMs, (2) một kỹ thuật để cải thiện khả năng tìm kiếm của ELM theo thời gian bằng cách tinh chỉnh toán tử đột biến dựa trên LLM của nó, (3) một cuộc trình diễn của ELM trong một miền không được bao gồm trong dữ liệu huấn luyện của LLM, và (4) xác nhận rằng dữ liệu được tạo thông qua ELM có thể khởi động các LLMs nâng cao mang lại một con đường mới hướng tới tính mở rộng.

2 Bối cảnh
Phần này xem xét công trình trước đây trong lập trình di truyền, các mô hình ngôn ngữ lớn và tính mở rộng.

2.1 Lập trình Di truyền
Lĩnh vực lập trình di truyền (GP) áp dụng các thuật toán tiến hóa để tiến hóa các chương trình máy tính nhằm giải quyết các vấn đề [3, 4, 15]. Lời hứa của GP là mã máy tính là một biểu diễn tính toán phổ quát làm nền tảng cho nhiều công nghệ hiện đại, bao gồm cả trí tuệ nhân tạo. Do đó, GP có thể tự động tiến hóa các chương trình đạt hiệu suất ở cấp độ con người (hoặc hơn thế) trên các miền ứng dụng đa dạng [16]. Tuy nhiên, có những trở ngại trong thực tế đối với việc áp dụng thành công và rộng rãi của nó cho các vấn đề thách thức.

Một trở ngại là việc mở rộng GP để tiến hóa các chương trình ngày càng phức tạp có thể gặp thách thức [8], và việc áp dụng GP hiệu quả cho một miền mới có thể đòi hỏi chuyên môn miền đáng kể. Một nhà nghiên cứu thường phải chỉ định rõ ràng những hàm, biến và cấu trúc điều khiển nào có sẵn cho quá trình tiến hóa [3, 17], điều này hạn chế những gì cuối cùng có thể được tiến hóa. Ngược lại, một lập trình viên con người có thể quyết định một cách mở rộng các thư viện nào để nhập và cách viết nhiều chương trình con hoặc lớp phụ thuộc lẫn nhau. Nghiên cứu nhằm nâng cao những ràng buộc này, thường thông qua việc cho phép tái sử dụng mô-đun của mã: ví dụ thông qua các hàm được định nghĩa tự động [3], khai thác dữ liệu các quần thể để tìm các thành phần con chung [18], hoặc các nỗ lực sử dụng giải pháp cho các vấn đề trước đây khi giải quyết các vấn đề mới [19]. Tuy nhiên, chưa có phương pháp nào cho phép GP hoạt động một cách có thể mở rộng trên các ngôn ngữ lập trình do con người thiết kế với tối thiểu việc điều chỉnh cụ thể theo miền.

Trở ngại thứ hai là gần như tất cả các phương pháp GP khám phá thông qua các nhiễu loạn ngẫu nhiên của mã, không giống như con người, những người thông qua thực hành tích cực cải thiện trình độ của họ trong việc thực hiện các sửa đổi có chủ đích, phức tạp và kết hợp đối với các chương trình [20, 21]. Không giống như việc nhiễu loạn ví dụ như trọng số mạng neural, trong đó các tham số liên tục chịu nhiễu loạn đủ nhỏ có thể dự đoán được tạo ra những thay đổi nhỏ trong chức năng [22, 23], việc nhiễu loạn mã đòi hỏi những thay đổi rời rạc thường làm thay đổi chức năng một cách đáng kể [24], do đó làm phức tạp việc tìm kiếm. Mặc dù tồn tại các phương pháp hướng tới việc tạo ra con cái một cách có hướng hơn (ví dụ xây dựng các mô hình xác suất của các chương trình hiệu suất cao [25], tiến hóa các toán tử sinh sản [26], hoặc áp dụng các toán tử đột biến ít tác động [24]), vấn đề vẫn chưa được giải quyết ở cốt lõi.

Ngược lại với GP, con người học cách suy luận về mã trong toàn bộ sự phức tạp của nó thông qua thử nghiệm và học tập. Nỗ lực lặp đi lặp lại này để lại một dấu hiệu vĩnh viễn trong các kho mã, chẳng hạn như GitHub. Phần tiếp theo mô tả tiến bộ trong việc huấn luyện các mô hình ngôn ngữ lớn trên những kho như vậy như một cách tiềm năng để vượt qua những trở ngại trên.

2.2 Các Mô hình Ngôn Ngữ Lớn
Các mô hình ngôn ngữ lớn (LLMs; [1, 2, 27]), được huấn luyện trên dữ liệu quy mô internet, đã tiến bộ với tốc độ ấn tượng trong những năm gần đây. Ý tưởng chính (trong các mô hình tự hồi quy như GPT-3 [2]) là huấn luyện các mạng neural ngày càng lớn (được xây dựng trên kiến trúc transformer phổ biến [28], đôi khi với hàng tỷ tham số) trên nhiệm vụ dự đoán token tiếp theo có vẻ đơn giản (tức là cho một chuỗi token đã thấy cho đến nay, dự đoán token tiếp theo). Việc mở rộng những LLMs như vậy (và xây dựng các vấn đề quan tâm như các nhiệm vụ xử lý ngôn ngữ tự nhiên) đã dẫn đến hiệu suất đột phá trên một loạt rộng các nhiệm vụ [2, 29], bao gồm tổng hợp chương trình [9, 10, 30].

Cụ thể, bằng cách huấn luyện LLMs trên dữ liệu lập trình quy mô lớn, ví dụ từ GitHub, có thể tạo ra các mô hình với khả năng tổng hợp hàm ấn tượng [9, 10], làm nổi bật khả năng khởi động khả năng lập trình lưu loát từ dữ liệu quy mô lớn. Một phát triển tiếp theo là các mô hình diff được huấn luyện trên các diff từ GitHub [31]. Một diff là một thay đổi gia tăng đối với một tệp được cam kết vào một hệ thống kiểm soát phiên bản như GitHub, đi kèm với một thông điệp cam kết mô tả ý định của thay đổi. Theo cách này, các mô hình diff được huấn luyện cách, cho một đoạn mã và bất kỳ thông điệp cam kết tiềm năng nào, đề xuất một thay đổi có thông tin. Qua lăng kính của các thuật toán tiến hóa, những mô hình diff như vậy có thể được xem như các toán tử nhiễu loạn thông minh, cung cấp một cách để đi bộ trên đa tạp của mã (theo cách có thể kiểm soát) thông qua việc bắt chước các lập trình viên con người. Một khả năng thú vị khác là những mô hình như vậy có thể được huấn luyện thêm thông qua gradient descent, ngụ ý một cơ chế có khả năng mạnh mẽ cho việc tự thích ứng (ví dụ thông qua việc tăng cường các diff thành công trong quá trình tiến hóa). Cả mô hình diff và khả năng tự thích ứng của chúng đều được khám phá trong công trình này như một cách để cải thiện GP. Tuy nhiên, cũng quan trọng cần lưu ý rằng các mô hình ngôn ngữ tổng quát không được huấn luyện trực tiếp trên diff cũng có thể hoạt động thực chất như các mô hình diff khi được đưa ra các loại prompt phù hợp (xem Phần 3.1).

2.3 Tính Mở rộng
Với nguồn gốc trong cộng đồng tiến hóa mở rộng [6, 13, 32, 33] trong artificial life, lĩnh vực tính mở rộng tìm cách tạo ra các hệ thống thuật toán tạo ra sự đổi mới không bao giờ kết thúc [5]. Cho tầm quan trọng của tìm kiếm với ML, nghiên cứu trong tính mở rộng tự nhiên đã tập trung vào việc tinh chỉnh các thuật toán cho tìm kiếm mở rộng, chẳng hạn như những thuật toán được điều khiển bởi tính mới lạ [34, 35] hoặc tò mò [36, 37]. Mặc dù việc tập trung như vậy thực sự đã dẫn đến tiến bộ thuật toán, nhưng có một nhận thức ngày càng tăng về tính quan trọng của môi trường mà các thuật toán mở rộng được áp dụng [38{41].

Tức là, môi trường giới hạn những gì có thể phát sinh trong hệ thống và sản phẩm của nó có thể duy trì sự thú vị trong bao lâu. Kết quả là, một số người đã lập luận cho các môi trường phức tạp hơn cho tính mở rộng, chẳng hạn như trò chơi video [38, 39], và những người khác đã lập luận rằng các đặc điểm của môi trường nên đồng tiến hóa với các agent [40, 42]. Tuy nhiên, một lý thuyết về những hình thức phức tạp bổ sung cụ thể nào được cần cho tính mở rộng bền vững vẫn còn thiếu. Bài báo này đóng góp một lý thuyết có thể, lập luận rằng các agent xuất ra các phát minh vào môi trường để đáp ứng với các phát minh trước đây có thể là một con đường có nguyên tắc cho tính mở rộng tiếp tục như vậy.

Một thách thức trong việc tiến hóa các khía cạnh của môi trường (chẳng hạn như các phát minh) là cách chúng được mã hóa. Hầu hết nghiên cứu áp dụng các mã hóa được thiết kế cụ thể để mô tả một phần cố định nào đó của một môi trường lớn hơn, ví dụ một cách cố định để mô tả các cạnh trong một mê cung [43], hoặc hình dạng của một cảnh quan 2-D [40]. Mặc dù đôi khi các mã hóa của những phần này là phổ quát (ví dụ mã hóa CPPN của cảnh quan trong [40] có thể mô tả bất kỳ cảnh quan nào, và mã hóa RNN của Dennis et al. [42] có thể mô tả bất kỳ mê cung nào), không rõ làm thế nào để mở rộng biểu diễn để bao gồm nhiều hơn của môi trường mà không dựa vào các nguyên tắc ad-hoc. Bài báo này lập luận rằng các chương trình máy tính là một mã hóa tổng quát và mạnh mẽ để liên tục mở rộng độ phong phú của một môi trường hiện có.

3 Phương pháp: Tiến hóa thông qua Mô hình Lớn
Ba thành phần riêng biệt tạo điều kiện cho ELM. Đầu tiên là toán tử đột biến mới lạ được điều khiển bởi một LLM. Thứ hai là một vòng lặp tiến hóa bên ngoài gọi toán tử đột biến này. Cuối cùng, thành phần thứ ba là một phương pháp để cập nhật LLM để cải thiện dựa trên hiệu suất trước đó của nó. Mỗi cái trong số này được chi tiết trong phần này.

3.1 Đột biến thông qua Diff
Ý tưởng chính đằng sau ELM tập trung vào việc suy nghĩ lại toán tử đột biến cho mã bằng cách khai thác khả năng của LLMs. Trong GP thông thường, ngôn ngữ của mã và các loại thay đổi được phép thông qua đột biến đều được chọn có chủ ý để mang lại cơ hội hợp lý rằng các nhiễu loạn có thể dẫn đến những thay đổi chức năng hữu ích [3]. Ngược lại, LLMs mở khóa một cơ sở hoàn toàn khác cho đột biến: sẽ lý tưởng hơn nếu toán tử đột biến hiểu mã và cách nó có thể được thay đổi theo những cách thú vị, giống như một con người hơn là một sự kiện ngẫu nhiên.

LLMs thực sự có thể được huấn luyện để xuất ra mã theo cách tự hồi quy bằng cách tiếp xúc với các ví dụ lập trình rộng rãi [9, 10]. Một mô hình diff [31] có thể tương tự được huấn luyện tự hồi quy trên một tập hợp các diff mã (ví dụ từ GitHub). Mỗi diff nhắm mục tiêu một tệp duy nhất, nơi tệp và diff đều đủ ngắn để vừa vào ngữ cảnh của LLM. Mô hình được huấn luyện để dự đoán diff (được định dạng, ví dụ, ở định dạng diff thống nhất [44]) từ việc nối tệp và thông điệp cam kết, trong đó loss chỉ bao gồm các token tạo nên diff, do đó khuyến khích mô hình dự đoán diff nhưng không ghi nhớ tệp và thông điệp cam kết. Nói cách khác, mô hình học cách dự đoán những thay đổi hợp lý đối với mã từ các ví dụ về những thay đổi được thực hiện đối với mã bởi các lập trình viên con người. Quan trọng cần lưu ý rằng ý tưởng về các mô hình diff (hoặc huấn luyện ban đầu của chúng) [31] không phải là đóng góp của bài báo này, mà các mô hình diff thực ra là một công cụ được áp dụng ở đây trong một bối cảnh mới (để tạo ra các đột biến).

Để đạt được những đột biến có ý nghĩa, ELM có thể chọn trong số một tập hợp các thông điệp cam kết, truyền đạt cho LLM các chi tiết của hoạt động mà nó nên thực hiện thay cho đột biến. Những thông điệp này cung cấp sức mạnh và sắc thái đáng kể cho việc hiệu chỉnh các toán tử đột biến mà có khả năng rất mới lạ đối với bất kỳ ai quen thuộc với việc triển khai đột biến trong GP hoặc các thuật toán tiến hóa nói chung. Trong thí nghiệm trong bài báo này, ba thông điệp cam kết và xác suất tương ứng của chúng được chọn là:

•Changed make walker function. (40% cơ hội)
•Changed parameters in make walker function. (30% cơ hội)
•Small change to make walker function. (30% cơ hội)

Tất nhiên, bất kỳ thông điệp cam kết nào cũng có thể tưởng tượng được. Khả năng của LLM trong việc diễn giải ngôn ngữ tự nhiên tổng quát có nghĩa là phạm vi cho việc khám phá nghiên cứu (và tính cụ thể theo miền) ở đây là rất lớn.

Như một thí nghiệm đơn giản để làm nổi bật khả năng của các mô hình diff trong việc sửa đổi mã một cách thông minh, một triển khai của một hàm với một lượng lỗi có thể điều chỉnh được nhiễu loạn với một toán tử đột biến GP đơn giản hoặc với một mô hình diff 300M tham số. Giả thuyết là một toán tử nhiễu loạn thông minh sẽ có khả năng thực hiện nhiều thay đổi tương quan đối với mã tốt hơn (trong trường hợp này để sửa chữa các lỗi). Nhiệm vụ 4-Parity (được lấy cảm hứng từ một benchmark GP tiêu chuẩn [3]) phục vụ như một test-bed đại diện. Lưu ý rằng một triển khai đúng của 4-Parity trả về tổng của bốn bit đầu vào, modulo hai. Tối đa năm lỗi được đưa vào 4-Parity, đầu tiên bằng cách đặt tên sai từng biến trong tính toán tổng một cách gia tăng; và đối với lỗi thứ năm, modulo được thay đổi từ hai thành ba. Sau đó, các toán tử nhiễu loạn được kiểm tra khả năng của chúng (trong một bước nhiễu loạn) thay đổi phiên bản có lỗi của mã thành một mã vượt qua được các unit test. Kết quả trong hình 1 làm nổi bật cách với số lỗi tăng lên, đột biến GP trở nên exponentially ít có khả năng tạo ra một giải pháp thành công (lưu ý rằng không có đột biến nào từ GP giải quyết được cả năm lỗi, cho 100.000 thử nghiệm). Ngược lại, toán tử diff có khả năng sửa chữa cả năm lỗi, và hiệu suất của nó bị ảnh hưởng nhiều hơn bởi số lượng các loại lỗi khác nhau (tức là lỗi thứ năm ảnh hưởng đến tính toán modulo hơn là đổi tên biến) so với số lượng lỗi thô. Chi tiết thêm (bao gồm một thí nghiệm hỗ trợ với một nhiệm vụ khác có kết quả tương tự) được đưa ra trong Phụ lục A.

Bởi vì các công cụ tham gia vào việc triển khai ELM là không thông thường, cuối cùng chúng tôi muốn làm nổi bật ở đây một số lựa chọn thay thế để triển khai những hệ thống như vậy trong thực tế ngày nay. Một lựa chọn là sử dụng các mô hình có sẵn trên OpenAI API có thể chỉnh sửa thông qua việc tuân theo hướng dẫn [45, 46]. Một lựa chọn thứ hai là tạo ra một toán tử đột biến thông minh thông qua prompting few-shot thay vì thông qua huấn luyện rõ ràng (như trong mô hình diff). Tức là, người ta có thể thiết kế các prompt cho một mô hình được huấn luyện trên mã (như Codex [9] hoặc GPT-6-J [47]). Để cho thấy tiềm năng tái tạo (hoặc cải thiện) các kết quả trong bài báo này, chúng tôi đã tiến hành một thí nghiệm đơn giản so sánh (trên vấn đề 4-Parity) kỹ thuật prompt và chế độ chỉnh sửa với mô hình diff. Hình 2 cho thấy cách các mô hình từ API vượt trội hơn mô hình diff được sử dụng trong bài báo. Chi tiết thí nghiệm thêm có thể được tìm thấy trong Phụ lục A.

3.2 Thuật toán Tiến hóa và Tác động đối với Tính Mở rộng
Bởi vì toán tử đột biến thực chất là một thành phần mô-đun cho nhiều thuật toán tiến hóa [48, 49], ELM có thể được triển khai trong nhiều bối cảnh đa dạng. Tất nhiên, phương pháp này áp dụng nhất cho trường hợp mà mã hóa di truyền thông qua một ngôn ngữ lập trình đã biết, bởi vì đó là cách các lợi ích của LLM sẽ được thực hiện. Các mã hóa di truyền bằng ngôn ngữ tự nhiên hoặc bất kỳ ngôn ngữ nào khác mà LLMs xuất sắc cũng có thể tưởng tượng được, nhưng tất nhiên tính hữu ích của những mã hóa như vậy sẽ phụ thuộc vào cách chúng được áp dụng và việc ánh xạ chúng sang một kiểu hình có khả năng hữu ích. Các thí nghiệm trong bài báo này tập trung vào các kiểu gen Python 3, mà cũng theo bản chất của chúng có chiều dài thay đổi. Khả năng sử dụng các ngôn ngữ lập trình hiện đại như kiểu gen mà không cần bất kỳ sự điều chỉnh đặc biệt nào là một lợi ích chính của ELM.

Mặc dù có nhiều lựa chọn cho thuật toán tiến hóa trong vòng lặp bên ngoài, chúng tôi đã chọn trong bài báo này triển khai ELM trong một thuật toán chất lượng đa dạng (QD) [50, 51]. Một động lực quan trọng cho lựa chọn này là sự xuất hiện của khả năng tìm kiếm một cách thông minh cho các chương trình phức tạp tùy ý gần như vượt qua được một số trở ngại chính đối với tính mở rộng [14], và ELM là một cơ hội để làm nổi bật cơ hội này.

Nhớ lại rằng chúng ta chưa biết cách tạo ra một thuật toán thể hiện sự phân kỳ thực sự mở rộng. Mặc dù đã có tiến bộ hướng tới tính mở rộng trong những năm gần đây, hiện trạng vẫn còn yếu trong tính mở rộng, trong đó việc khám phá mới lạ và thú vị chỉ tiếp tục trong một thời gian ngắn, cuối cùng kết thúc trong một cao nguyên khi các khả năng bị cạn kiệt [5, 40, 43, 52{54]. Ngược lại, trong tính mở rộng mạnh, quá trình sẽ không bao giờ đạt đến cao nguyên{nếu chúng ta rời đi và quay lại một năm sau, hoặc thậm chí một triệu năm sau, sản phẩm của nó sẽ tiếp tục trở nên thú vị hơn theo thời gian. Không có thuật toán nào đạt gần đến thành tựu như vậy, mặc dù nó rõ ràng là có thể trong tự nhiên.

Câu hỏi sau đó là điều gì đứng giữa các thuật toán ngày nay và tính mở rộng mạnh có thể xử lý được. Khoảng cách này vẫn tồn tại mặc dù công trình gần đây trong tính mở rộng dường như đạt được tiến bộ. Ví dụ, thuật toán Enhanced POET tiếp tục tạo ra các địa hình đa dạng và ngày càng phức tạp cho các robot hai chân để giải quyết [40]. Trong thí nghiệm trốn tìm của họ, Baker et al. [54] cho thấy các agent khám phá các chiến lược ngày càng phức tạp như lắp ráp các khối thành một nơi ẩn náu. Tuy nhiên mặc dù những thuật toán như vậy rõ ràng chứng minh khả năng tiếp tục phát minh ra các giải pháp mới, tất cả những cuộc trình diễn như vậy đều chia sẻ một điểm yếu duy nhất: chúng chậm lại và cuối cùng kết thúc. Việc chính thức hóa ELM trong một khung QD thực chất mang lại một cơ hội mới lạ để giải quyết thách thức này.

Cơ hội này kết nối với khó khăn trong việc xây dựng một môi trường nhân tạo không áp đặt giới hạn nào đối với những gì mà thuật toán mở rộng có khả năng nhất có thể đạt được, như đã nêu trong Bối cảnh. Thách thức của việc thiết kế các môi trường nhân tạo với tiềm năng không giới hạn đặt ra câu hỏi hấp dẫn về thuộc tính nào mà vũ trụ và hành tinh của chúng ta sở hữu mà các môi trường nhân tạo hiện tại thiếu. Câu hỏi này rất quan trọng đối với tính mở rộng bởi vì trong trường hợp không có thuộc tính đó, các thuật toán mở rộng không thể chứng minh toàn bộ tiềm năng của chúng. Nếu vấn đề thực sự xuất phát từ thực tế rằng các môi trường nhân tạo cho đến nay chỉ cung cấp các trải nghiệm có thể có hữu hạn cho đến khi tiềm năng của chúng bị cạn kiệt, thì để vượt qua nút cổ chai này, bản thân môi trường cần sở hữu tiềm năng thay đổi mãi mãi.

Kể từ khi trí thông minh xuất hiện trong tự nhiên, nhiều thay đổi môi trường đã được thúc đẩy bởi chính các agent thông minh. Cuối cùng, con người đã có được khả năng để lại các tạo phẩm tách rời trong môi trường mà thay đổi căn bản tiềm năng của nó cho bản thân họ và các agent khác, như một ngôi nhà, một phương tiện, hoặc thậm chí một chương trình. Không giống như các sinh vật mới được tiến hóa qua các thế hệ, những thứ có điều kiện tách rời (DCTs) như vậy được tạo ra một cách có chủ đích như một điều kiện của các quan sát của agent. Một khi DCTs đi vào thế giới, tính mở rộng tăng tốc bởi vì môi trường đang cập nhật nhanh chóng ngay cả trong suốt cuộc đời của một cá thể duy nhất.

Mỗi DCT tạo ra một cơ hội cho các DCT khác. Ví dụ, việc phát minh ra cửa tạo ra cơ hội cho chìa khóa được phát minh, sau đó tạo tiền đề cho dụng cụ mở khóa, và cứ thế. Và vì chúng được tách rời, DCTs có thể để lại một di sản vĩnh viễn trong môi trường vượt xa tuổi thọ của người phát minh ra chúng. Theo cách này, việc phát minh trong kỷ nguyên của DCTs là mở rộng, và tương ứng đã tiếp tục trong hàng nghìn năm, từ lửa và bánh xe đến trạm không gian và máy tính.

Lý thuyết về DCTs này cung cấp một câu trả lời trừu tượng cho vấn đề của một môi trường hạn chế: Các agent phải có khả năng ghi dấu môi trường với DCTs để đáp ứng với những DCTs đã có mặt trong đó. Tuy nhiên, việc thực hiện DCTs trong thực tế đòi hỏi giải quyết một câu hỏi riêng biệt: làm thế nào các agent có thể được cho phép phát minh DCTs với độ phức tạp không giới hạn một cách hiệu quả trong một miền mới?

Thú vị là, các chương trình máy tính là các biểu diễn phổ quát, có nghĩa là quy trình lắp ráp các tạo phẩm mới có thể được mô tả một cách tự nhiên theo thuật toán. Ví dụ, các lập trình viên đã tận dụng mã để giúp tạo ra các tạo phẩm cực kỳ phức tạp (như bố cục của chip máy tính hoặc hướng dẫn cho máy in 3-D để tạo ra các vật thể vật lý phức tạp). Tất nhiên, bản thân các chương trình có thể hoạt động như DCTs. Theo cách này, một quy trình có thể tìm kiếm thông qua không gian chương trình hiện đại và cuối cùng tạo ra những chương trình như vậy một cách có điều kiện là một ứng cử viên để tạo ra các môi trường mở rộng với khả năng không giới hạn. Thí nghiệm trong bài báo này sẽ chứng minh chi tiết hơn về cách ELM làm cho một cấu trúc như vậy có thể tưởng tượng được; tầm quan trọng của QD là khả năng tạo ra một không gian đa dạng của các tạo phẩm có thể phục vụ như việc khởi động để có được các agent có khả năng tạo ra DCTs. Tóm lại, thuật toán QD đang tạo ra dữ liệu huấn luyện có thể biến đổi LLM thành một loại trình tạo DCT.

Mặc dù bất kỳ thuật toán QD nào cũng có thể hoạt động với ELM, thuật toán cụ thể trong thí nghiệm trong bài báo này là MAP-Elites [51, 55] (Hình 3). Cốt lõi của MAP-Elites là một lưới các hốc được phân bố đều (được gọi là bản đồ), trải rộng các chiều do người dùng chỉ định về sự đa dạng của giải pháp, được gọi là đặc tính hóa hành vi. Khi khởi tạo, một giải pháp duy nhất có sẵn trước (được thiết kế thủ công trong bài báo này) được đánh giá và đặt vào bản đồ. Trong mỗi lần lặp sau đó, một hốc có cư dân được chọn ngẫu nhiên và giải pháp trong hốc đó được nhiễu loạn bởi mô hình diff và được đánh giá. Giải pháp ứng viên mới được gán hốc của nó từ đặc tính hóa hành vi của nó, và nếu hốc đó chưa được lấp đầy hoặc giải pháp mới vượt trội hơn cư dân hiện tại của hốc, nó trở thành nhà vô địch của hốc đó; nếu không, ứng viên bị loại bỏ. Theo cách này, qua các lần lặp tìm kiếm, bản đồ dần dần lấp đầy với các giải pháp ngày càng đa dạng và chất lượng cao.

3.3 Tinh chỉnh Toán tử Diff
Thú vị là, bởi vì toán tử đột biến (diff) bản thân nó là một LLM, nó có tiềm năng được cải thiện đối với miền. Mặc dù tự thích ứng [56{58] có một truyền thống dài trong tính toán tiến hóa, bao gồm các thuật toán như CMA-ES [58] và các chiến lược tiến hóa tự nhiên [59], các loại cải thiện có thể trong ELM là duy nhất bằng cách cung cấp khả năng của LLM học cách suy nghĩ về thay đổi. Tức là, ý tưởng cho những thay đổi hứa hẹn nhất trong một miền có thể khác với trong miền khác, và sự phong phú của LLM cung cấp tiềm năng nắm bắt những sắc thái như vậy thông qua kinh nghiệm. Cụ thể, mô hình diff được tiền huấn luyện có thể được huấn luyện thêm (được gọi là tinh chỉnh) với các diff được chấp nhận (bởi MAP-Elites) từ các lần lặp hoặc chạy đầu tiên của ELM. Theo cách đó, toán tử diff cập nhật để hiểu tốt hơn các loại sửa đổi dẫn đến chất lượng cao hơn, tính mới lạ hơn, hoặc cả hai. Kỹ thuật tinh chỉnh này có thể khiến bản thân ELM cải thiện theo các lần lặp. Tất nhiên, trong một chạy dài, các loại thay đổi lý tưởng có thể thay đổi; việc tinh chỉnh liên tục dựa trên kinh nghiệm gần đây có thể theo dõi những cơ hội trôi nổi như vậy. Trong bài báo này, tiềm năng của tinh chỉnh được chứng minh thông qua một lần lặp tinh chỉnh duy nhất, nhưng việc điều tra sự tinh chỉnh liên tục như vậy là một cơ hội nghiên cứu mở. Lưu ý rằng phương pháp kỹ thuật prompt cho đột biến LLM được mô tả ở cuối Phần 3.1 cũng có thể được hưởng lợi từ tinh chỉnh theo cách này.

4 Thí nghiệm và Kết quả
Động lực chính cho thí nghiệm tiếp theo là để đưa ra một cái nhìn về tính rộng lớn của những tác động của ELM, đối với tính toán tiến hóa, học sâu và tính mở rộng. Với mục đích này, thí nghiệm này tập trung vào vấn đề phát minh các tạo phẩm phức tạp (mà cuối cùng có thể phục vụ như DCTs trong một thí nghiệm tham vọng hơn trong tương lai). Mặc dù phạm vi tiềm năng của các ứng dụng cho ELM là rộng lớn, cơ hội học cách phát minh các tạo phẩm phức tạp trong một miền tùy ý mở rộng trực tiếp từ khả năng tăng cường để tìm kiếm thông qua các chương trình; việc thấy khả năng sáng tạo này được thực hiện do đó làm nổi bật những cơ hội mới lạ đang mở ra.

Thí nghiệm sẽ nhằm mục đích khởi động từ một vài ví dụ phát minh được viết tay (và hầu như không hoạt động) thành một nhà phát minh dựa trên LLM có thể xuất ra các phát minh phù hợp một cách lưu loát dựa trên môi trường của nó. Khái niệm này được chứng minh trong miền Sodarace [11, 12], một miền phát minh dựa trên vật lý phục vụ như một vi mô rẻ để mô phỏng của việc phát minh. Mục tiêu trong Sodarace là xây dựng từ các tập hợp khối lượng và lò xo dao động các robot hai chiều có thể di chuyển một cách thành thạo. Một loạt rộng các robot Sodaracer thú vị là có thể, như được làm nổi bật bởi nghiên cứu ML trước đây [12] và nguồn gốc của miền: Sodarace bắt đầu như một ứng dụng web được gọi là Sodaconstructor, trong đó việc thiết kế Sodaracers của con người đủ hấp dẫn để một cộng đồng trực tuyến hình thành xung quanh nỗ lực [11].

Một Sodaracer cá thể (Hình 4) được cấu thành từ một tập hợp có kích thước thay đổi của các khối lượng điểm (mỗi cái được mô tả đầy đủ bởi vị trí 2-D ban đầu của nó) và các lò xo dao động kết nối các khối lượng với nhau. Chuyển động của robot được điều khiển bởi dao động của các lò xo của nó, và mỗi lò xo có các tham số chỉ định biên độ và pha của dao động của nó (theo quy ước tất cả các lò xo có cùng chu kỳ). Để đánh giá một Sodaracer cụ thể, nó được mô phỏng trong một địa hình cụ thể trong một khoảng thời gian cố định và khả năng của nó để đi qua địa hình đó được đo (tức là Sodaracer's center of mass di chuyển bao xa dọc theo trục x); ngoài ra, để đo sự đa dạng của các giải pháp cho MAP-Elites, các đặc điểm nắm bắt các khía cạnh tổng thể của hình thái robot (tức là chiều cao ban đầu, chiều rộng và tổng khối lượng của nó) được ghi lại. Mặc dù một thuật toán tìm kiếm có thể hoạt động trực tiếp trong không gian của các khối lượng và lò xo, ở đây thay vào đó LLMs xuất ra mã Python mô tả hình thái của Sodaracer. Đối với các ví dụ về mã nguồn như vậy, xem Phụ lục B và G. Theo cách này, các chương trình được tiến hóa bởi ELM thực chất là các mã hóa gián tiếp [60{63] cho Sodaracers. Tức là, về nguyên tắc bất kỳ mã hóa gián tiếp nào có thể biểu diễn thông qua mã có thể được tiến hóa từ đầu hoặc được sửa đổi bởi ELM.

Tham vọng hơn so với chỉ tạo ra một kho tàng các thiết kế Sodaracer, thí nghiệm sẽ cố gắng triển khai một đường ống phát minh hoàn chỉnh cuối cùng mang lại một loại LLM có điều kiện mới lạ có thể nhập vào một địa hình và xuất ra một Sodaracer phù hợp cho địa hình đó. ELM do đó phục vụ như giai đoạn tạo dữ liệu ban đầu của đường ống này, cho thấy theo cách này cách ELM có thể phục vụ nói chung như một cách tạo ra dữ liệu miền cho việc học sâu downstream nơi nó không tồn tại trước đây. Hơn nữa, trong tương lai khả năng huấn luyện những nhà phát minh có điều kiện như vậy có thể phục vụ như một nền tảng cho một thế giới mở rộng của các agent tạo DCT.

Trong thực tế, mục tiêu của đường ống phát minh là tạo ra một agent có thể xuất ra các tạo phẩm phức tạp một cách có điều kiện, dựa trên quan sát của nó về môi trường. Nếu việc phát minh được hiểu như một hành động, thì việc học phát minh có điều kiện có thể được xem như một vấn đề học tăng cường (RL) [64]. Tức là, đối với bất kỳ quan sát nào, agent có thể được thưởng tùy thuộc vào sự thành công của phát minh kết quả. Ví dụ, trong Sodarace, agent có thể quan sát một địa hình cụ thể như một ngọn đồi và sau đó xuất ra một thiết kế cho một tạo phẩm Sodaracer. Phần thưởng sau đó phụ thuộc vào hiệu suất của Sodaracer trong địa hình được quan sát.

Phương pháp này nghe có vẻ đơn giản{đó đơn giản là RL với đầu ra phức tạp{nhưng có một vấn đề. Nếu agent không có kinh nghiệm trước trong miền (ví dụ trong Sodarace), thì việc xuất ra ngay cả một tạo phẩm hợp lệ (chứ chưa nói đến hoạt động) thực sự là không thể. Kết quả là, không có gradient cho RL và nó không thể khởi động vào miền mới.

Do đó, để RL bắt đầu, một số hình thức tiền huấn luyện là cần thiết. Thực chất, việc tinh chỉnh RL được mô tả ở trên thực sự là bước cuối cùng trong một đường ống, nơi bước trước đó là dạy agent điều gì đó sơ bộ về miền của nó. Với mục đích đó, một LLM có thể được huấn luyện trên một tập lớn các ví dụ từ miền mục tiêu. Ví dụ, những ví dụ này có thể là các thiết kế walker Sodarace. Sau khi tiếp xúc với đủ những thiết kế như vậy, về nguyên tắc LLM biết điều gì đó về miền và có thể xuất ra các tạo phẩm mẫu từ phân phối huấn luyện. Với kiến thức như vậy sau đó được chuyển giao cho RL, bây giờ nó sẽ có thể khởi động vào việc tinh chỉnh có điều kiện.

Tuy nhiên, vẫn còn một vấn đề: tất cả các ví dụ đến từ đâu để huấn luyện LLM? Nếu hy vọng là để nhà phát minh có điều kiện cuối cùng phát minh trong một miền mới lạ như Sodarace nơi một LLM chung không có khả năng có bất kỳ tiếp xúc nào, thì nguồn cho tất cả các ví dụ cần thiết để huấn luyện LLM bản thân nó là khó nắm bắt. Kết quả là, đường ống cần thêm một bước trước nữa{đó là nơi ELM xuất hiện{để tạo ra một tập hợp các tạo phẩm ví dụ từ đầu, sau đó có thể huấn luyện LLM mà cuối cùng sẽ khởi động RL.

Việc tạo ra một tập hợp đa dạng và lớn các ví dụ huấn luyện ban đầu là một vấn đề tìm kiếm. Tuy nhiên, bởi vì chưa có LLM nào có bất kỳ tiếp xúc nào với loại dữ liệu phù hợp, đó là một vấn đề tìm kiếm trong không gian phát minh thay vì trong không gian trọng số của mạng neural. Tìm kiếm các ví dụ chức năng đa dạng (để có được một phân phối tiền huấn luyện rộng) trong không gian của các tạo phẩm là vai trò tự nhiên của QD (tức là MAP-Elites trong bài báo này). Kết hợp với hàm diff, kết quả là ELM, mang lại một phương pháp mới lạ để tạo ra các ví dụ huấn luyện, do đó khởi động toàn bộ quá trình.

Để tóm tắt, điều xuất hiện là một đường ống phát minh ba giai đoạn để huấn luyện các nhà phát minh có điều kiện (Hình 5):
1.ELM. Tìm kiếm một tập hợp đa dạng các tạo phẩm ví dụ (ví dụ Sodaracers trên mặt đất phẳng).
2.Tiền huấn luyện LLM với các ví dụ từ ELM. LLM tương ứng học cách xuất ra các phát minh ví dụ từ phân phối huấn luyện.
3.Học phát minh có điều kiện. Ghép các đầu vào có điều kiện mới vào LLM và tinh chỉnh nó thông qua RL để tạo ra các phát minh phù hợp cho các điều kiện mà nó quan sát.

4.1 Mã hóa Sodaracers với Python
Các thí nghiệm trước đây nhắm mục tiêu Sodarace đã tận dụng các mã hóa tiến hóa chuyên biệt [12]. Thay vào đó, trong công trình này mã Python văn bản thuần túy hoạt động như một biểu diễn chung cho các phát minh. Bằng cách cho thấy cách Python có thể được sử dụng để biểu diễn các tạo phẩm trong một miền tùy ý, nó mở ra khả năng sử dụng nó như một mã hóa chung trong các miền tương lai đa dạng. Cụ thể hơn, trong các thí nghiệm, một cá thể được đánh giá bằng cách thực thi mã của nó thông qua trình thông dịch Python. Sản phẩm của trình thông dịch (đối với một cá thể khả thi) là một cấu trúc dữ liệu chứa mô tả của một Sodaracer (tức là một từ điển Python chứa danh sách cả khối lượng điểm và lò xo), sau đó có thể được chuyển cho trình mô phỏng Sodarace để đánh giá hành vi của Sodaracer được mã hóa. Lưu ý rằng Sodaracers được mã hóa trong Python trong suốt đường ống phát minh, tức là ELM tiến hóa các chương trình Python và các mô hình ngôn ngữ trong cả hai giai đoạn sau của đường ống được huấn luyện để xuất ra các chương trình Python.

Các thí nghiệm sơ bộ cho thấy rằng hiệu suất ban đầu của mô hình diff (tức là trước khi tinh chỉnh) trong việc tạo ra các nhiễu loạn hữu ích phụ thuộc vào thiết kế của \interface" thông qua đó Sodaracers được xây dựng theo quy trình. Để xem xét: mặc dù một Sodaracer có thể được xây dựng trong Python bằng cách trực tiếp thêm các phần tử vào một từ điển Python với các khóa như \joints" và \muscles," một interface Pythonic hơn (hiệu quả hơn và là những gì được sử dụng trong các thí nghiệm) là tạo ra một lớp đơn giản với hai phương thức: \add joint" (để thêm một lò xo) và \add muscle" (để thêm một khối lượng điểm.) Ý tưởng là một interface như vậy (ở đây được gói gọn trong một lớp được gọi là \walker creator") gần hơn với phân phối huấn luyện của mã Python (mặc dù vẫn không có ví dụ Sodarace nào ở định dạng này tồn tại). Ví dụ, dưới đây là mã hóa của một Sodaracer hình vuông đơn giản được thiết kế thủ công (cũng được sử dụng trong các thí nghiệm như một hạt giống), cũng như bản dịch của nó sau khi được thực thi thành một từ điển của joints và muscles. Interface cũng bao gồm logic để đảm bảo rằng Sodaracer sẽ không làm hỏng động cơ vật lý Box2D cơ bản, ví dụ rằng mỗi joint chỉ được kết nối với nhiều muscles như vậy, rằng sức mạnh của muscles bị hạn chế, và rằng có khoảng cách tối thiểu giữa các joints. Lưu ý rằng lợi ích của việc tiến hóa một chương trình tạo ra một cấu trúc dữ liệu thay vì trực tiếp tiến hóa bản thân cấu trúc dữ liệu liên quan đến lợi ích của mã hóa gián tiếp (tức là một chương trình có thể tận dụng các quy luật thông qua vòng lặp, điều kiện và hàm, để mã hóa hiệu quả các cấu trúc lớn phức tạp) [60]. Hình 6 cho thấy hình ảnh của walker này khi được khởi tạo.

5 Giai đoạn Đường ống 1: Tạo Dữ liệu thông qua ELM
Nhớ lại rằng mục tiêu trong giai đoạn đầu tiên này là tạo ra một loạt lớn các ví dụ chất lượng cao đa dạng từ một chương trình khởi đầu ví dụ duy nhất thông qua ELM. Trong giai đoạn này của đường ống, môi trường Sodarace là một địa hình phẳng đơn giản.

Nhớ lại rằng ELM trong thí nghiệm này sẽ tiến hóa thông qua MAP-Elites (Hình 3) [51]. Cốt lõi của MAP-Elites là một lưới các hốc được phân bố đều (được gọi là bản đồ), trải rộng các chiều do người dùng chỉ định về sự đa dạng của giải pháp, được gọi là đặc tính hóa hành vi. Trong các thí nghiệm ở đây, đặc tính hóa hành vi bao gồm chiều cao, chiều rộng và khối lượng của Sodaracers, và bản đồ là một lưới 12×12×12 mà bất kỳ đặc tính hóa hành vi nào có thể được ánh xạ vào. Khi khởi tạo, một giải pháp duy nhất được thiết kế thủ công được đánh giá và đặt vào bản đồ. Trong mỗi lần lặp sau đó, một hốc có cư dân được chọn ngẫu nhiên và giải pháp trong hốc đó được nhiễu loạn bởi mô hình diff và được đánh giá. Giải pháp ứng viên mới được gán hốc của nó từ đặc tính hóa hành vi của nó, và nếu hốc đó chưa được lấp đầy hoặc giải pháp mới vượt trội hơn cư dân hiện tại của hốc, nó trở thành nhà vô địch của hốc đó; nếu không, ứng viên bị loại bỏ. Theo cách này, qua các lần lặp tìm kiếm, bản đồ dần dần lấp đầy với các giải pháp ngày càng đa dạng và chất lượng cao.

Để giải quyết nhu cầu về các giải pháp hạt giống, bốn hạt giống đơn giản được viết để khám phá các motif kiến trúc khác nhau: hạt giống Square, hạt giống Radial, và hai hạt giống giống CPPN (CPPN là viết tắt của compositional pattern-producing network [61]); lưu ý rằng mã nguồn cho những hạt giống này được cung cấp trong Phụ lục B. Hạt giống Square khởi tạo một thiên hướng giống polygon, bằng cách bao gồm một hàm tạo ra một hình vuông được cấu thành từ bốn khối lượng từ hai tọa độ, và mã gọi hàm đó và kết nối các khối lượng với nhau bằng vòng lặp for. Hạt giống Radial thay vào đó triển khai một thiên hướng xuyên tâm bằng cách thay thế hàm tạo hình vuông bằng một hàm đặt một số lượng khối lượng nhất định theo hình tròn. Cuối cùng, các hạt giống giống CPPN gần như triển khai mã hóa dựa trên CPPN được sử dụng bởi công trình trước đây trong Sodarace [12], tức là nó đặt các khối lượng và kết nối các lò xo giữa chúng như một hàm toán học của tọa độ của chúng. Mã của hạt giống dựa trên CPPN có thể được chia gọn thành (1) triển khai chức năng cốt lõi của một CPPN, và (2) mô tả một khởi tạo cụ thể của một CPPN, và do đó cho phép khám phá hậu quả của việc để chức năng cốt lõi của bản thân mã hóa tiến hóa. Với mục đích này, có hai hạt giống CPPN, một trong đó mã hóa CPPN được cố định, được gọi là hạt giống CPPN-Fixed, và một nơi nó có thể biến đổi, được gọi là hạt giống CPPN-Mutable. Lưu ý rằng những chương trình hạt giống này không được điều chỉnh cao như các video trong Hình 7 làm nổi bật.

5.1 Chi tiết Thí nghiệm và Kết quả
Ba chạy độc lập của ELM được tiến hành với mỗi hạt giống, chạy trong 1.024.000 đánh giá mỗi cái (được cấu thành từ 2.000 lần lặp của 512 diff mỗi lần lặp). Một mô hình diff được tiền huấn luyện 300M tham số [31] phục vụ như toán tử nhiễu loạn trong những thí nghiệm này.

Một thước đo thành công cho ELM là số lượng hốc được lấp đầy, đại diện cho sự đa dạng của dữ liệu được tạo ra bởi ELM, dưới giả thuyết rằng dữ liệu đa dạng như vậy sẽ có lợi cho các giai đoạn đường ống sau này. Hình 8 cho thấy rằng các chạy của ELM có xu hướng khám phá một tỷ lệ lớn các hốc, làm nổi bật cách hệ thống có thể khởi động từ một ví dụ duy nhất do người dùng cung cấp để lấp đầy không gian của các khả năng mong muốn. Tuy nhiên, tốc độ lan rộng qua các hốc thay đổi giữa các hạt giống; cụ thể, việc giới thiệu vòng lặp và/hoặc thành phần hàm được yêu cầu cho hạt giống Square để lan rộng vào các hốc khối lượng cao (ví dụ để kết nối nhiều hình vuông với nhau), điều này xuất hiện chậm trong một số chạy.

Ngoài sự đa dạng, chất lượng của các giải pháp cũng quan trọng. Một thước đo tổng thể của chất lượng là fitness tối đa được khám phá bởi các chạy, được hiển thị trong Hình 9. Một thước đo tinh tế hơn tính đến cả chất lượng và sự đa dạng là điểm QD [50], được tính như tổng hiệu suất của tất cả nhà vô địch trong bản đồ cuối cùng. Thước đo này, được hiển thị trung bình qua các chạy trong Hình 10, thưởng cho cả chất lượng (có điểm số cao hơn trong mỗi hốc) và sự đa dạng (đã khám phá nhiều hốc hơn), và do đó phục vụ như một thước đo ngắn gọn về mục tiêu của ELM trong việc tích lũy các giải pháp đa dạng, chất lượng cao (và trong các giai đoạn sau trong đường ống, về mức độ LLM đã mô hình hóa phân phối của các giải pháp mà ELM đã phát hiện). Đạt được QD khác nhau giữa các hạt giống; trong khi hạt giống CPPN phát hiện sự đa dạng nhanh nhất, hạt giống Radial tạo ra các giải pháp chất lượng cao hơn trung bình. Mối quan hệ giữa hạt giống và sản phẩm của tìm kiếm phức tạp và xứng đáng nghiên cứu thêm trong tương lai (xem thêm Phụ lục D để phân tích thêm về tính mạnh mẽ của hạt giống).

Việc tinh chỉnh mô hình diff trên các diff được chấp nhận từ một loạt chạy ban đầu đã tăng hiệu suất đáng kể (Hình 11); trong khi các chương trình tạo Sodarace nằm ngoài phân phối cho mô hình diff được tiền huấn luyện (việc áp dụng mã hóa Python cho miền này là một doanh nghiệp mới lạ), việc tinh chỉnh hiệu quả căn chỉnh mô hình diff với miền, một kết quả thú vị. Hình 11c cho thấy cách mô hình diff được tinh chỉnh tạo ra một tỷ lệ cao hơn đáng kể các diff hợp lệ (tức là có thể được áp dụng) và có thể chạy được (tức là chương trình được vá có thể thực thi). Vì hiệu suất cao hơn của chúng, đầu ra của các chạy áp dụng mô hình diff được tinh chỉnh là những cái được chuyển cho các giai đoạn sau trong đường ống.

Lưu ý rằng các vòng tinh chỉnh thêm là có thể (ví dụ tinh chỉnh mô hình diff một lần nữa từ các sản phẩm cải thiện của vòng đầu tiên); tuy nhiên các thí nghiệm sơ bộ cho thấy lợi ích giảm dần. Công trình tương lai có thể khám phá cách liên tục cải thiện những mô hình như vậy, chẳng hạn như bằng cách xác định và khuyến khích các nhiễu loạn có tác động lớn hơn thay vì bao gồm và cân nặng bằng nhau tất cả các diff được chấp nhận.

Các hạt giống và mô hình diff được tinh chỉnh cũng tác động định tính đến các loại giải pháp được khám phá bởi ELM. Mặc dù hạt giống Radial hoạt động tốt về mặt định lượng (về chất lượng và sự đa dạng), hóa ra các sản phẩm của nó có xu hướng khai thác động lực học hỗn loạn có vẻ quá rõ ràng đối với địa hình phẳng (giả thuyết này được xác nhận tạm thời trong các thí nghiệm Giai đoạn 3). Các hạt giống Square và CPPN ngược lại có nhiều khả năng xuất ra các phát minh tận dụng động lực học dự đoán được hơn. Vì những lý do này, các chạy hạt giống Radial không được sử dụng cuối cùng trong các giai đoạn tương lai.

Một lựa chọn video của các Sodaracers chất lượng cao nhất từ những chạy ban đầu này thể hiện sự đa dạng đáng kể được phát hiện có thể xem tại https://y2u.be/QNyNtvwA9FI. Một ví dụ về một dòng dõi của Sodaracers tiến bộ từ hạt giống Square đến một Sodaracer cuối cùng chất lượng cao có thể thấy tại https://y2u.be/M9pAJuX6dyM. Tóm lại, ELM cho thấy rằng bằng cách kết hợp toán tử đột biến thông minh dựa trên LLM với một thuật toán QD, có thể tạo ra hàng trăm nghìn ví dụ huấn luyện hoạt động trong một miền hoàn toàn mới lạ nơi không có dữ liệu nào có sẵn trước đây.

6 Giai đoạn Đường ống 2: Huấn luyện Mô hình Ngôn ngữ
Sản phẩm của Giai đoạn 1 là một tập hợp các chương trình, trong khi Giai đoạn 3 RL đòi hỏi một mô hình ban đầu có thể xuất ra các chương trình tạo Sodaracer hợp lệ. Do đó, giai đoạn thứ hai của đường ống phát minh tinh chỉnh một LLM trên các sản phẩm của ELM, phục vụ như khởi tạo cho một nhà phát minh có điều kiện dựa trên RL.

Để làm như vậy trước tiên đòi hỏi việc biên dịch kết quả của Giai đoạn 1 thành một tập dữ liệu tinh chỉnh. Mặc dù có nhiều cách để chưng cất một tập dữ liệu của các chương trình từ các chạy của ELM, một phương pháp ngưỡng đơn giản được áp dụng ở đây (mặc dù xem Phụ lục E cho một phương pháp đơn giản khác không hoạt động trong thực tế). Ý tưởng chính là nối thêm tất cả các giải pháp có khả năng hợp lý cho mỗi hốc.

Chi tiết hơn, từ mỗi chạy tất cả các giải pháp từng được nhận vào bản đồ được bao gồm, tuân theo việc đáp ứng một thanh tối thiểu cho hiệu suất. Một số phần của không gian hành vi cung cấp những thách thức nghiêm ngặt hơn (tức là khó di chuyển hơn khi được yêu cầu cao nhưng không rộng và có khối lượng thấp), và tuy nhiên trong một số địa hình gặp phải trong Giai đoạn 3, những loại giải pháp đó có thể vẫn hiệu quả nhất mặc dù mức hiệu suất tuyệt đối thấp của chúng. Do đó, đối với mỗi hốc, hiệu suất tối đa trên tất cả các chạy được tính toán, và thanh tối thiểu để bao gồm được đặt như một tỷ lệ phần trăm của điểm số per-niche đó. Với ngưỡng tỷ lệ phần trăm cao hơn, ít dữ liệu hơn được bao gồm, nhưng chất lượng của dữ liệu đó sẽ cao hơn.

Như đã lưu ý trong phần trước, các giải pháp từ hạt giống Radial có tính chất hỗn loạn về mặt định tính. Hơn nữa, các thí nghiệm sơ bộ cho thấy rằng hành vi hỗn loạn như vậy làm hại đáng kể hiệu suất Giai đoạn 3 downstream. Vì những lý do này, các chạy Radial của ELM đã được loại trừ khỏi các tập dữ liệu LLM. Các tập dữ liệu cho mỗi điều trị còn lại được biên dịch từ 9 chạy từ ELM với mô hình diff được tinh chỉnh (3 chạy cho mỗi hạt giống Square, CPPN-Fixed và CPPN-Mutable). Tổng cộng, tập dữ liệu ngưỡng cắt 50% bao gồm 280K ví dụ, và tập dữ liệu ngưỡng cắt 80% chứa một tập con 95K của những ví dụ đó.

Một loạt các mô hình tạo mã được tiền huấn luyện sau đó được tinh chỉnh với những ví dụ này (sử dụng log-probability loss LLM tiêu chuẩn), để lại 5% dữ liệu để phục vụ như một tập kiểm tra. Các mô hình từ 0.1M đến 680M tham số được huấn luyện (chi tiết kiến trúc cho những mô hình này có thể thấy trong Phụ lục C). Ngoài ra, như một đối chứng để hỗ trợ giả thuyết rằng các mô hình Sodarace được hưởng lợi từ tiền huấn luyện tạo mã, một mô hình 300M cũng được huấn luyện thay vào đó từ một khởi tạo ngẫu nhiên (được ký hiệu với \RI" trong các biểu đồ tiếp theo).

Các loss kiểm tra tối thiểu (tức là loss trên các Sodaracers được tạo ra được giữ lại từ tập dữ liệu tinh chỉnh) của các mô hình Ngưỡng Tỷ lệ Phần trăm 80% được hiển thị trong Hình 12. Các mô hình Ngưỡng Tỷ lệ Phần trăm 50% thể hiện kết quả tương tự về mặt định tính trên kích thước mô hình (nhưng vì cả hai ngưỡng đại diện cho các tập dữ liệu khác nhau, các giá trị loss không thể so sánh trực tiếp giữa chúng). Kết luận là kích thước mô hình trên 85M có thể không khớp dữ liệu tốt hơn, và khởi tạo ngẫu nhiên làm hại hiệu suất so với tinh chỉnh từ một mô hình được tiền huấn luyện trên mã.

Tuy nhiên, loss không phải là toàn bộ câu chuyện. Câu hỏi thú vị cho Giai đoạn 2 là liệu các LLMs được huấn luyện từ dữ liệu được tạo ra trong Giai đoạn 1 có thể tạo ra cùng sự đa dạng và chất lượng của dữ liệu hay không. Do đó, thước đo điểm QD và số lượng hốc được khám phá (cả hai cũng được báo cáo cho Giai đoạn 1) được tính toán cho các mẫu được lấy từ các LLMs được huấn luyện. Bởi vì những thước đo này có thể được tối đa hóa bởi một mô hình ghi nhớ dữ liệu, và bởi vì thực nghiệm điểm QD có tương quan nhiều hơn với loss trên tập huấn luyện thay vì tập kiểm tra, checkpoint LLM cho mỗi mô hình được chọn trên cơ sở loss huấn luyện thấp nhất. Cụ thể, 1.024 mẫu được lấy từ mỗi mô hình, sau đó được đánh giá và chèn vào một bản đồ MAP-Elites mới. Để so sánh, cùng các thước đo được tính toán sử dụng tập dữ liệu Giai đoạn 1, bằng cách lấy cùng số lượng mẫu từ nó và đánh giá chúng theo cùng cách. Những kết quả này được hiển thị trong Hình 13, làm nổi bật rằng các mẫu mô hình đạt được mức hiệu suất tương tự như các mẫu tập dữ liệu, cho thấy rằng chúng đã mô hình hóa dữ liệu tốt. Ngoài ra, có một lợi ích QD nhỏ nhưng nhất quán từ các mô hình được huấn luyện trên tập dữ liệu cắt 80%, phản ánh QD trung bình cao hơn của tập dữ liệu đó.

Một câu hỏi tự nhiên khác là mô hình sẽ làm tốt như thế nào khi được đưa ra khỏi phân phối, tức là nó đã thực sự nội hóa động lực học của Sodarace tốt như thế nào? Tức là, tập huấn luyện và kiểm tra để tinh chỉnh được lấy từ cùng các chạy, và do đó mô hình có thể sẽ gặp phải tất cả các motif trong tập kiểm tra, và vì vậy nó có thể không phải là một bài kiểm tra đại diện về mức độ mô hình sẽ tổng quát hóa trong tương lai. Một bài kiểm tra sơ bộ theo tinh thần này là lấy nửa đầu của các chương trình Python mô tả một số phát minh từ các chạy chưa thấy, và khám phá khả năng của các mô hình khác nhau để tạo ra các hoàn thành chức năng. Mặc dù hạt giống Radial thường tạo ra Sodaracers hỗn loạn, trong một chạy sơ bộ của ELM với hạt giống Radial, một bánh xe chức năng đã được khám phá. Như đã lưu ý trước đây, dữ liệu từ chạy này (hoặc bất kỳ chạy radial nào khác) không được sử dụng để huấn luyện các mô hình trong Giai đoạn 2, cũng không được sử dụng để tinh chỉnh mô hình diff trong Giai đoạn 1; do đó khả năng hoàn thành bánh xe có thể phục vụ như một proxy cho tổng quát hóa. Tương tự, hai cá thể hiệu suất cao khác được lấy từ các chạy sơ bộ khác của hạt giống CPPN và hạt giống Square, để tạo ra một tập hợp ba bài kiểm tra hoàn thành ngoài phân phối. Xem Hình 14 để trực quan hóa những walkers này, bao gồm video; mã nguồn cho những ví dụ tổng quát hóa này có thể được tìm thấy trong Phụ lục F). Lưu ý rằng các bài kiểm tra tổng quát hóa thêm được ghi chép trong Phụ lục H.

Đối với mỗi trong ba nhiệm vụ hoàn thành, 1.024 mẫu hoàn thành được lấy từ mỗi mô hình và sau đó được đánh giá trong mô phỏng. Ngược lại với các thước đo trong phân phối, trong bài kiểm tra tập trung vào tổng quát hóa này, hiệu suất có tương quan nhiều hơn với loss kiểm tra của mô hình thay vì loss huấn luyện, và do đó checkpoint nào để đánh giá cho mỗi mô hình được chọn trên cơ sở loss kiểm tra thấp nhất. Kết quả được hiển thị trong Hình 15, làm nổi bật rằng các mô hình lớn hơn, và những mô hình được huấn luyện trên ngưỡng 80%, nói chung hoạt động tốt hơn trong nhiệm vụ này. Lưu ý rằng mô hình 300M được khởi tạo ngẫu nhiên (RI) hoạt động kém hơn đáng kể, cung cấp thêm bằng chứng rằng tiền huấn luyện trên mã cung cấp một prior có giá trị.

Video của mẫu hoạt động tốt nhất cho việc hoàn thành Wheel từ mỗi mô hình tại https://y2u.be/-LW2cCwSdRU (cho tập dữ liệu ngưỡng 80%; mô hình 300M được khởi tạo ngẫu nhiên không được hiển thị vì nó không tạo ra mẫu hợp lệ nào cho việc hoàn thành này). Đối với các hoàn thành Galloper và Runner, cấu trúc và/hoặc hành vi của các hoàn thành thường không khớp với mẫu gốc (đặc biệt là đối với Galloper). Trong video liên kết sau, một hoàn thành hiệu suất cao hơn được hiển thị cho cả Galloper và Runner: https://y2u.be/XR3L4cZ83xU.

Nhìn chung, những kết quả này cho thấy rằng một LLM có thể tích hợp hiệu quả dữ liệu tổng hợp được tạo ra thông qua ELM trong một miền mới lạ.

7 Giai đoạn Đường ống 3: RL Có điều kiện
Trong giai đoạn cuối cùng, học tăng cường (RL) được gọi để tinh chỉnh LLM được tiền huấn luyện đầu ra bởi Giai đoạn 2 của đường ống. Mục tiêu là tạo ra một mô hình xuất ra các chương trình Python đại diện cho Sodaracers để đáp ứng với các địa hình cụ thể. Quan trọng là, đầu ra của Giai đoạn 2 là một mô hình không điều kiện, theo nghĩa rằng nó lấy mẫu Sodaracers từ một phân phối được định nghĩa bởi đầu ra của Giai đoạn 1, mà không xem xét địa hình mà các mẫu sẽ được triển khai.

Bước đầu tiên trong Giai đoạn 3 do đó là chuyển đổi mô hình thành một mô hình có điều kiện, tức là một mô hình chấp nhận địa hình như đầu vào, và tạo ra các mẫu Sodaracers để đáp ứng.

Để đạt được hình thức chức năng này, trước tiên chúng tôi giới thiệu khái niệm về mạng nhúng địa hình (TEN). Vai trò của TEN là ánh xạ một biểu diễn của địa hình thành một biểu diễn có thể được sử dụng bởi mô hình để lấy mẫu có điều kiện. Cụ thể, đầu ra của TENs là một vectơ (hoặc chuỗi vectơ) trong d, chiều mà mô hình nhúng các token. Theo cách đó, đầu ra của TEN có thể được coi như sự kích hoạt từ một tiền tố nhất định, và mô hình có thể tiến hành thực chất bây giờ lấy mẫu dựa trên đầu ra của TEN.

Cụ thể, một LLM tự hồi quy không điều kiện định nghĩa một phân phối lấy mẫu trên một chuỗi token x= (x1; : : : ; x n) là p(x) =Qn i=1p(xijx<i). Trong giai đoạn này, chúng tôi giới thiệu mô-đun bổ sung fTEN, đại diện cho địa hình t trong Rd. Vì fTEN(t)2Rd, chúng ta có thể xem xét mô hình có điều kiện kết quả mà không cần sửa đổi thêm:

p(xjt) =nY i=1p(xijx<i; fTEN(t)): (1)

Phương pháp này tương tự như transformer có thể kiểm soát được đề xuất bởi Keskar et al. [65], nhưng với các mã có điều kiện là đầu ra của TEN, thay vì các token cụ thể từ từ vựng hiện có.

Cho một phân phối trên địa hình p(t), một thiết lập RL được xây dựng để huấn luyện các tham số của TEN và tinh chỉnh thêm các tham số LLM cho thiết lập có điều kiện. Cụ thể, một episode bây giờ bao gồm việc lấy mẫu tp(t), và lấy mẫu một chương trình từ phân phối có điều kiện được định nghĩa trong Phương trình (1). Chương trình được chuyển đổi thành một Sodaracer, được đánh giá trong mô phỏng với địa hình t, và phần thưởng được định nghĩa như khoảng cách tuyệt đối mà Sodaracer đi được trong một khoảng thời gian nhất định.

7.1 Phân phối Địa hình
Trong thí nghiệm này, phân phối trên địa hình mà mô hình được tiếp xúc được chọn để khám phá tính khả thi của việc tạo ra các nhà phát minh có điều kiện với Đường ống Phát minh. Tầm nhìn tương lai là đặt nền móng cho khả năng triển khai các agent có khả năng phát minh có điều kiện trong các môi trường phong phú, có khả năng đa agent hỗ trợ phát triển các quá trình mở rộng. Trong những thiết lập như vậy, có lý do để học cách xuất ra các tạo phẩm phức tạp dựa trên quan sát của môi trường sẽ là một điều kiện tiên quyết cho sự đổi mới mở rộng liên tục.

Tuy nhiên, trong các thí nghiệm sơ bộ trong miền Sodarace, việc học có xu hướng \hướng tới" các giải pháp sụp đổ, trong đó một chương trình duy nhất được tạo ra đạt được hiệu suất hợp lý trên một tập con của các địa hình trong hỗ trợ phân phối. Để giảm tính khả thi của kết quả như vậy và mô phỏng một kịch bản nơi tính điều kiện là thiết yếu, một tập nhỏ và rời rạc các địa hình mà một chương trình duy nhất không thể đạt hiệu suất tốt cung cấp một bài kiểm tra nơi các giải pháp có điều kiện nên có lợi thế đáng kể.

Trong các thí nghiệm, phân phối đều được xem xét trên các tập hợp địa hình như được minh họa trong Hình 16. Hai tập con được xem xét, cả hai đều chứa left-wall và right-wall. Một tập bổ sung chứa tunnel, và tập kia bao gồm bumpy. Những tập này được chọn cụ thể sao cho các mô hình không thể tạo ra một Sodaracer duy nhất đạt hiệu suất tốt trên tất cả địa hình; để tối đa hóa mục tiêu học, mô hình phải tận dụng TEN để kết hợp tính điều kiện.

7.2 Tham số hóa TENs
Hai tham số hóa cho TEN được khám phá.

Mã Rời rạc. Phân phối địa hình có một hỗ trợ rời rạc và hữu hạn. Như vậy, một tham số hóa đơn giản trong đó các địa hình được coi như các token bổ sung trong từ vựng hiện có, và embedding cho mỗi địa hình được học riêng biệt có thể được sử dụng. Lợi thế của tham số hóa như vậy là nó giới thiệu một số lượng tương đối nhỏ các tham số mới để được tối ưu hóa với RL, và nó đơn giản về mặt khái niệm để hiểu và debug. Tuy nhiên, nhược điểm chính của tham số hóa như vậy là (i) số lượng tham số mở rộng với kích thước của tập địa hình, và (ii) nó không cho phép mô hình tổng quát hóa tự nhiên đến các địa hình chưa thấy tại thời điểm kiểm tra, điều này có thể là một ràng buộc quan trọng cho các quá trình mở rộng downstream.

ResNets. Một tham số hóa thay thế là các biểu diễn trực quan của các địa hình, sau đó có thể được xử lý bởi các mô hình nhận dạng trực quan. Cụ thể, một ResNet50 [66] nhúng hình ảnh vào Rd như một TEN khi thí nghiệm với các biểu diễn trực quan của địa hình. Lợi thế chính của tham số hóa này là nó khá tổng quát, có thể tưởng tượng được sử dụng trong nhiều thiết lập (ví dụ dạy một LLM tạo mã để viết chương trình để đáp ứng với đầu vào trực quan), và về lý thuyết có thể tổng quát hóa đến các địa hình chưa thấy. Nhược điểm chính của phương pháp này là nó giới thiệu một số lượng lớn tham số mới phải được tối ưu hóa sử dụng một tín hiệu RL thưa thớt. Ngược lại, đối với các phân phối địa hình lớn, phương pháp này làm cho việc phân bổ số lượng tham số bổ sung cần thiết để thiết kế các nhà phát minh có điều kiện trở nên khả thi.

7.3 Chi tiết Thí nghiệm và Kết quả
Mỗi episode RL bao gồm việc lấy mẫu một batch địa hình từ phân phối, tạo ra các mẫu từ LLM có điều kiện, và đánh giá chúng trong mô phỏng để tạo ra phần thưởng.

Tối ưu hóa chính sách gần đúng [PPO; 67] là thuật toán RL, kết hợp với ước lượng lợi thế tổng quát [GAE; 68], với các siêu tham số mặc định. Trong các thí nghiệm sơ bộ, chúng tôi thấy quan trọng là thêm một thuật ngữ KL (giữa mạng chính sách và LLM được tiền huấn luyện từ Giai đoạn 2) vào hàm phần thưởng, như được đề xuất bởi Christiano et al. [69] và Stiennon et al. [70]. Mạng giá trị được tham số hóa như một phiên bản hàm vô hướng của mạng chính sách, tức là một LLM riêng biệt với TEN được thêm vào riêng biệt được khởi tạo từ các mô hình Giai đoạn 2. Hình 17 minh họa các kiến trúc và đường ống cho các mạng chính sách và hàm giá trị. Mỗi lần lặp bao gồm các batch 1.024 mẫu (được phân phối trên 32 GPU), và các chạy huấn luyện bao gồm 100 lần lặp.

RL được chạy trên các LLMs được tiền huấn luyện 300M tham số được huấn luyện với các tập dữ liệu có ngưỡng cắt trong f50%, 80%g. Nhớ lại rằng chúng tôi sử dụng ngưỡng cắt để kiểm soát sự đánh đổi giữa chất lượng và số lượng dữ liệu, sao cho ngưỡng cao hơn dẫn đến các tập dữ liệu tiền huấn luyện nhỏ hơn với mật độ cao hơn của các thể hiện chất lượng. Đối với mỗi tổ hợp tập dữ liệu và phân phối địa hình, ba chạy được thực hiện sử dụng các seed khác nhau, và hiệu suất được tính trung bình trên các mẫu từ mô hình kết quả cho mỗi địa hình, từ tất cả các chạy, mặc dù chúng tôi loại trừ một số lượng nhỏ các chạy phân kỳ trong quá trình huấn luyện. Để tính toán một thước đo hiệu suất của các tập dữ liệu và LLMs được tiền huấn luyện, chúng tôi gọi tính toán thời gian kiểm tra: 1.024 Sodaracers được lấy mẫu đồng đều và được đánh giá từ mỗi tập dữ liệu/mô hình (nhớ lại rằng có một mô hình cho cả hai ngưỡng cắt), và Sodaracer hoạt động tốt nhất được xem xét cho mỗi địa hình. Hình 18 và 19 chi tiết kết quả của những thí nghiệm này với phân phối tunnel và bumpy, tương ứng.

Tóm lại, Hình 18 và 19 giúp chúng ta hiểu liệu RL có thể khám phá các giải pháp có điều kiện hay không, mà chúng tôi diễn giải như các nhà phát minh có điều kiện của Sodaracers có khả năng di chuyển trên các địa hình cụ thể. Hơn nữa, Hình 18 và 19 cho phép chúng ta so sánh hiệu suất của Sodaracers được tạo ra ở các giai đoạn khác nhau của đường ống, và cách hiệu suất bị ảnh hưởng bởi việc chọn ngưỡng cắt. Một câu hỏi đặc biệt thú vị là liệu RL có thể nhất quán cải thiện hiệu suất của tính toán thời gian kiểm tra với các mô hình được tiền huấn luyện được tạo ra trong Giai đoạn 2 hay không.

Quy trình RL đôi khi giòn: huấn luyện đôi khi phân kỳ, và một số kết quả không nhất quán. Phân kỳ có xu hướng thường xuyên hơn khi sử dụng ResNet TENs, điều này không đáng ngạc nhiên khi xem xét ResNets giới thiệu nhiều tham số hơn vào mô hình, mà lần lượt được huấn luyện với một phân phối cực kỳ nghèo nàn của hình ảnh (một cho mỗi địa hình trong phân phối).

Mặc dù tính dễ vỡ, việc tinh chỉnh RL thành công trong việc tạo ra các nhà phát minh có điều kiện trong miền này: các mô hình có xu hướng tạo ra một Sodaracer duy nhất cho mỗi địa hình, khác nhau giữa các địa hình trong phân phối. Quan trọng là, các Sodaracers được tạo ra đạt hiệu suất tốt cho địa hình được điều kiện, trong khi thất bại trong việc di chuyển trên các địa hình khác. Video trưng bày Sodaracers được phát minh cho phân phối Tunnel { https://y2u.be/e53NwdT4RdM { và cho phân phối bumpy { https://y2u.be/WEM1dBtLLTw. Tóm lại, kết quả chính là đầu ra của Giai đoạn 3, và do đó đường ống hoàn chỉnh, là các nhà phát minh có điều kiện của hình thức mong muốn.

Hơn nữa, trong hầu hết các trường hợp, các mô hình RL có thể so sánh hoặc tốt hơn so với Sodaracers hoạt động tốt nhất được lấy mẫu từ tập dữ liệu hoặc LLM được tiền huấn luyện. Tính nhất quán này ngụ ý rằng Giai đoạn 3 cho phép các mô hình học cách sử dụng TENs kết hợp với LLMs, và có thể tinh chỉnh thêm đầu ra của các mô hình để cải thiện hiệu suất, mặc dù không phải lúc nào cũng với biên độ đáng kể.

Các mô hình được huấn luyện với ngưỡng cắt 80% có xu hướng đạt hiệu suất tốt hơn một chút, và chứng tỏ ổn định hơn trong quá trình huấn luyện, mặc dù sự khác biệt không đáng kể. Kết quả này ngụ ý rằng sự đánh đổi giữa chất lượng và số lượng dữ liệu có thể đóng vai trò trong các nhiệm vụ downstream (chẳng hạn như tinh chỉnh RL), một điểm đáng được điều tra thêm trong công trình tương lai. Một con đường thú vị cho nghiên cứu theo hướng này là xem xét các quy trình tiền huấn luyện bao gồm thông tin về chất lượng của các thể hiện (nơi thông tin như vậy có sẵn), ví dụ như được đề xuất bởi Chen et al. [71].

Cuối cùng, chúng tôi lưu ý rằng các giải pháp \sụp đổ" trong đó cùng một Sodaracer được tạo ra mỗi khi một địa hình cụ thể được quan sát (trái ngược với các mẫu khác nhau đáng kể mỗi khi cùng một địa hình được thấy) là hợp lý trong thiết lập này, vì nên tồn tại một Sodaracer thống trị cho mỗi địa hình. Tuy nhiên, thú vị là, trong các hệ thống mở rộng thực sự, thuộc tính này có thể không giữ: nếu môi trường liên tục thay đổi, điều đó loại trừ sự tồn tại của các phát minh thống trị duy nhất. Trong một thiết lập như vậy, tính ngẫu nhiên của mô hình được kỳ vọng là có lợi, cho phép mô hình thích ứng và tạo ra một sự đa dạng của các giải pháp hữu ích.

7.4 Quan sát Định tính
Một số cấu trúc và lớp giải pháp thú vị đã được quan sát định tính trong suốt các thí nghiệm, cung cấp cái nhìn sâu sắc bổ sung về khả năng của đường ống trong việc phát minh có điều kiện các giải pháp cho các địa hình khác nhau. Một ví dụ như vậy là sự xuất hiện của các Sodaracers rất ngắn, đã phát sinh để đáp ứng với địa hình tunnel. Các trực quan hóa video tại https://y2u.be/P9A1ruI3 tU làm nổi bật các ví dụ về những Sodaracers như vậy được tạo ra để đáp ứng với tunnel.

Một lớp Sodaracers thú vị khác xuất hiện trong các thí nghiệm trước đó với ELM; một cấu trúc giống bánh xe xuất hiện trong quá trình tiến hóa, và tồn tại suốt đường ống. Trong Giai đoạn 3, bánh xe chứng tỏ đặc biệt thành thạo trong việc di chuyển trong địa hình bumpy, và nhất quán xuất hiện như giải pháp cho bumpy được tạo ra bởi các mô hình Giai đoạn 3 cho địa hình đó qua các chạy RL. Thật không may, bánh xe không xuất hiện lại trong các chạy ELM được sử dụng trong các thí nghiệm cuối cùng trong bài báo này. Video tại https://y2u.be/l5PVSLDknWM chứng minh một số giải pháp của hình thức này được khám phá bởi RL khi được huấn luyện với phân phối địa hình bumpy cũng như phân phối tunnel. Để tương phản, video này (https://y2u.be/Mo-rXnFq6vQ) cho thấy các chế độ thất bại trên bumpy cho một số Sodaracers hiệu quả trong việc di chuyển trên địa hình phẳng.

Những quan sát định tính như vậy cung cấp bằng chứng thêm rằng đường ống có khả năng tạo ra các nhà phát minh thú vị và giải pháp sáng tạo cho các vấn đề, ngay cả trong một miền đơn giản hóa không phải là mở rộng. Chúng tôi giả thuyết rằng khi được thả ra trong các miền phức tạp hơn, khả năng phát minh có điều kiện này sẽ đóng góp vào tính mở rộng của quá trình được tạo ra bằng cách liên tục giới thiệu các đối tượng mới vào môi trường, và do đó thay đổi thuộc tính của nó cho các agent khác.

8 Thảo luận và Kết luận
Một sự khác biệt quan trọng giữa tiến hóa tự nhiên và hầu hết EC là từ đầu{tự nhiên bắt đầu với một \ví dụ" hoặc hạt giống duy nhất, tế bào đầu tiên trên Trái đất, đã được ban tặng chức năng và thông tin ban đầu quan trọng. Ngược lại, các chạy trong EC thường bắt đầu với các cấu hình ngẫu nhiên với ít hoặc không có thông tin hữu ích. Bởi vì các ngôn ngữ lập trình như Python cho con người là các phương thức tự nhiên để chính thức hóa các ý tưởng và mối quan hệ phức tạp, một chương trình như vậy có thể phục vụ như một hạt giống gần với tinh thần của tự nhiên hơn. Tuy nhiên, vấn đề sau đó là các đột biến tùy ý đối với một chương trình đã được xây dựng rất không có khả năng hữu ích.

Một vài năm trước, ý tưởng rằng toán tử đột biến có thể \biết" cách nhiễu loạn những chương trình như vậy theo những cách hợp lý và hứa hẹn sẽ là viển vông, nhưng, như đã được hiển thị trong bài báo này, sự xuất hiện của LLMs hiện đã làm cho những khả năng như vậy trở thành hiện thực. Thuật toán MAP-Elites kết hợp với ELM dễ dàng khởi động các tập dữ liệu của hàng trăm nghìn ví dụ trong một miền hoàn toàn xa lạ (đối với LLM ban đầu) từ các hạt giống được viết bởi con người ban đầu. Tính hợp lệ của dữ liệu được tạo ra này được xác nhận bởi đường ống phát minh tiếp theo{các LLMs có điều kiện cuối cùng được huấn luyện bắt đầu từ dữ liệu này mà không thể được huấn luyện từ đầu.

Rộng hơn, ý tưởng chính được giới thiệu ở đây là LLMs được huấn luyện trên mã mở ra một loại GP thông minh đáng kể mới được kích hoạt bởi ELM mà không còn bị chi phối bởi cảnh quan tìm kiếm thô được tạo ra bởi mã. Mặc dù thí nghiệm trong bài báo này chỉ ra một tập hợp các tác động đối với tính mở rộng, học sâu và RL, các ứng dụng tiềm năng là nhiều và nhiều thách thức trước đây trong lĩnh vực GP có thể được xem xét lại với công cụ mới này.

Thí nghiệm trong bài báo này cho thấy rằng các toán tử đột biến thông minh dựa trên LLM có thể thành công thúc đẩy khám phá bằng cách được kết hợp với các thuật toán tìm kiếm khác (ví dụ MAP-Elites trong công trình này). Hơn nữa, việc tối ưu hóa những toán tử đột biến như vậy dựa trên chất lượng đầu ra của chúng trong chính quá trình tìm kiếm dường như làm cho chúng hoạt động thậm chí tốt hơn cho khám phá. Không chỉ các khám phá của việc tìm kiếm như vậy có khả năng hữu ích theo quyền riêng của chúng (như bánh xe trong miền Sodarace), mà chúng còn cung cấp một lựa chọn hoàn toàn mới để tạo ra dữ liệu ví dụ hoặc tối ưu hóa các giải pháp hiện có trong các miền nơi dữ liệu thưa thớt hoặc không tồn tại. Ví dụ, việc tìm kiếm như vậy thông qua nhiễu loạn dựa trên LLM có thể khả thi được áp dụng để tối ưu hóa bản thân thuật toán tìm kiếm MAP-Elites, hoặc cho việc tìm kiếm kiến trúc và siêu tham số LLM.

Từ góc độ tính mở rộng, thách thức về nguyên tắc là việc tìm kiếm theo định nghĩa liên tục và thậm chí có chủ đích thay đổi ra khỏi phân phối. Ngay khi một phát minh hoặc DCT mới được đạt được, tính mở rộng đòi hỏi rằng vùng thoải mái quen thuộc của nó ít nhất một phần được từ bỏ cho các biên giới mới. Thí nghiệm ở đây trong đó LLMs được huấn luyện từ các walker mặt đất phẳng đơn giản có thể tận dụng kiến thức đó để tạo ra một cách phù hợp các walker chuyên biệt cho các địa hình khác nhau cho thấy chính loại bước nhảy có thông tin này đến một biên giới mới. Nếu một quá trình của những bước nhảy trên bước nhảy như vậy có thể được làm cho tiếp tục vô hạn định, thì một vụ nổ không giới hạn của độ phức tạp mới nổi có thể trong tầm với.

Một câu hỏi quan trọng cho công trình tương lai là mức độ mà mô hình kết quả có thể nội suy hoặc ngoại suy đến các ví dụ (tức là môi trường) bên ngoài phân phối huấn luyện của nó. Mặc dù RL có thể khai thác kiến thức hiện có trong LLM để khởi động vào các nhiệm vụ mới, việc ngoại suy các nguyên tắc từ kiến thức như vậy khó hơn nhiều và có khả năng đòi hỏi các cập nhật trọng số thêm thông qua học tập bổ sung. Có thể một hệ thống mở rộng tinh vi trong tương lai sẽ vướng víu cả tiến hóa liên tục và RL cho DCTs cùng nhau.

Nhìn chung, hy vọng là cái nhìn sâu sắc cốt lõi đơn giản rằng hiệu quả của đột biến trong GP hiện có thể cải thiện đáng kể thông qua ELM sẽ truyền cảm hứng cho một loạt rộng các ứng dụng và hướng nghiên cứu mới lạ. Quan sát rằng EC có thể được hưởng lợi trực tiếp và đáng kể từ những tiến bộ trong học sâu (và học sâu từ EC thêm xuống đường ống phát minh) cũng có thể giúp thúc đẩy việc theo đuổi thêm các sự hiệp lực giữa các lĩnh vực.

Lời cảm ơn
Cảm ơn Jeff Clune về phản hồi sâu sắc thực chất và thảo luận chu đáo về dự án và bài báo này. Cảm ơn cũng đến Glenn Powell về đầu vào và ý tưởng hữu ích nhất quán trong các cuộc họp và thảo luận nhóm. Chúng tôi cũng cảm ơn nhóm Supercomputing về công việc của họ, đã cho phép thí nghiệm của chúng tôi.

Tài liệu tham khảo
[1] Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258 , 2021.

[2] Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. arXiv preprint arXiv:2005.14165 , 2020.

[3] J. R. Koza. Genetic Programming: On the Programming of Computers by Means of Natural Selection . MIT Press, Cambridge, MA, 1992.

[4] Wolfgang Banzhaf, Peter Nordin, Robert E Keller, and Frank D Francone. Genetic programming: an introduction: on the automatic evolution of computer programs and its applications . Morgan Kaufmann Publishers Inc., 1998.

[5] K.O. Stanley, J Lehman, and L Soros. Open-endedness: The last grand challenge you've never heard of. O'Reilly Online , December 19, 2017.

[6] Russell K Standish. Open-ended artificial evolution. International Journal of Computational Intelligence and Applications , 3(02):167{175, 2003.

[7] Mark A. Bedau, John S. McCaskill, Norman H. Packard, Steen Rasmussen, Chris Adami, David G. Green, Takashi Ikegami, Kunihiko Kaneko, and Thomas S. Ray. Open problems in artificial life. Artificial Life , 6:363{376, 2000.

[8] Michael O'Neill, Leonardo Vanneschi, Steven Gustafson, and Wolfgang Banzhaf. Open issues in genetic programming. Genetic Programming and Evolvable Machines , 11(3):339{363, 2010.

[9] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374 , 2021.

[10] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R emi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation with alphacode. arXiv preprint arXiv:2203.07814 , 2022.

[11] P. McOwan and E. Burton. Sodarace website. URL http://sodarace.net , 2000{2013.

[12] Paul Szerlip and Kenneth O. Stanley. Indirectly Encoding Running and Jumping Sodarace Creatures for Artificial Life. Artificial Life , 21(4):432{ 444, 11 2015. ISSN 1064-5462. doi: 10.1162/ARTL-a-00185. URL https: //doi.org/10.1162/ARTL a00185.

[13] Mark A Bedau, John S McCaskill, Norman H Packard, Steen Rasmussen, Chris Adami, David G Green, Takashi Ikegami, Kunihiko Kaneko, and Thomas S Ray. Open problems in artificial life. Artificial life , 6(4):363{ 376, 2000.

[14] Kenneth O Stanley, Joel Lehman, and Lisa Soros. Open-endedness: The last grand challenge you've never heard of. O'Reilly Radar Online Article , December 2017.

[15] William B Langdon and Riccardo Poli. Foundations of genetic programming . Springer Science & Business Media, 2013.

[16] John R Koza, Martin A Keane, Matthew J Streeter, William Mydlowec, Jessen Yu, and Guido Lanza. Genetic programming IV: Routine human-competitive machine intelligence , volume 5. Springer Science & Business Media, 2006.

[17] Markus Brameier and Wolfgang Banzhaf. A comparison of linear genetic programming and neural networks in medical data mining. IEEE Transactions on Evolutionary Computation , 5(1):17{26, 2001.

[18] Istvan Jonyer and Akiko Himes. Improving modularity in genetic programming using graph-based data mining. In FLAIRS Conference , pages 556{561, 2006.

[19] Gregory Seront. External concepts reuse in genetic programming. In working notes for the AAAI Symposium on Genetic programming , pages 94{98. MIT/AAAI Cambridge, 1995.

[20] Leo Gugerty and Gary Olson. Debugging by skilled and novice programmers. In Proceedings of the SIGCHI conference on human factors in computing systems , pages 171{174, 1986.

[21] Paul Luo Li, Andrew J Ko, and Jiamin Zhu. What makes a great software engineer? In 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering , volume 1, pages 700{710. IEEE, 2015.

[22] Joel Lehman, Jay Chen, Jeff Clune, and Kenneth O Stanley. Safe mutations for deep and recurrent neural networks through output gradients. In Proceedings of the Genetic and Evolutionary Computation Conference , pages 117{124. ACM, 2018.

[23] John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz. Trust region policy optimization. In International Conference on Machine Learning , pages 1889{1897, 2015.

[24] Edgar Galv an-L opez, James McDermott, Michael O'Neill, and Anthony Brabazon. Towards an understanding of locality in genetic programming. In Proceedings of the 12th annual conference on Genetic and evolutionary computation , pages 901{908, 2010.

[25] Rafal Salustowicz and J urgen Schmidhuber. Probabilistic incremental program evolution. Evolutionary computation , 5(2):123{141, 1997.

[26] Lee Spector and Alan Robinson. Genetic programming and autoconstructive evolution with the push programming language. Genetic Programming and Evolvable Machines , 3(1):7{40, 2002.

[27] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 , 2018.

[28] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,  Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems , 30, 2017.

[29] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311 , 2022.

[30] Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas Mazeika, Akul Arora, Ethan Guo, Collin Burns, Samir Puranik, Horace He, Dawn Song, et al. Measuring coding challenge competence with apps. arXiv preprint arXiv:2105.09938 , 2021.

[31] Alex Ray and Sam McCandlish. Independent contribution: Training diff models, 2020.

[32] Tim Taylor. Exploring the concept of open-ended evolution. In Artificial Life 13 (Proceedings of the Thirteenth International Conference on the Simulation and Synthesis of Living Systems) , pages 540{541, Cambridge, MA, 2012. MIT Press.

[33] Tim Taylor, Mark Bedau, Alastair Channon, David Ackley, Wolfgang Banzhaf, Guillaume Beslon, Emily Dolson, Tom Froese, Simon Hickinbotham, Takashi Ikegami, et al. Open-ended evolution: Perspectives from the oee workshop in york. Artificial life , 22(3):408{423, 2016.

[34] Joel Lehman and Kenneth O. Stanley. Abandoning objectives: Evolution through the search for novelty alone. Evolutionary Computation , 19(2): 189{223, 2011. URL http://eplex.cs.ucf.edu/papers/lehman ecj11.pdf.

[35] J.-B. Mouret and St ephane Doncieux. Encouraging behavioral diversity in evolutionary robotics: An empirical study. Evolutionary computation , 20 (1):91{133, 2012.

[36] Deepak Pathak, Pulkit Agrawal, Alexei A Efros, and Trevor Darrell. Curiosity-driven exploration by self-supervised prediction. In International conference on machine learning , pages 2778{2787. PMLR, 2017.

[37] Christopher Stanton and Jeff Clune. Curiosity search: producing generalists by encouraging individuals to continually explore and acquire skills throughout their lifetime. PloS one , 11(9):e0162235, 2016.

[38] Djordje Grbic, Rasmus Berg Palm, Elias Najarro, Claire Glanois, and Sebastian Risi. Evocraft: A new challenge for open-endedness. In International Conference on the Applications of Evolutionary Computation (Part of EvoStar) , pages 325{340. Springer, 2021.

[39] Sam Earle, Julian Togelius, and LB Soros. Video games as a testbed for open-ended phenomena. In 2021 IEEE Conference on Games (CoG) , pages 1{9. IEEE, 2021.

[40] Rui Wang, Joel Lehman, Aditya Rawal, Jiale Zhi, Yulun Li, Jeffrey Clune, and Kenneth O. Stanley. Enhanced poet: Open-ended reinforcement learning through unbounded invention of learning challenges and their solutions. In International Conference on Machine Learning , pages 9940{9951. PMLR, 2020.

[41] L. B. Soros and Kenneth O. Stanley. Identifying minimal conditions for open-ended evolution through the artificial life world of chromaria. In Proceedings of the Fourteenth International Conference on the Synthesis and Simulation of Living Systems , pages 793{800, Cambridge, MA, 2014. MIT Press.

[42] Michael Dennis, Natasha Jaques, Eugene Vinitsky, Alexandre Bayen, Stuart Russell, Andrew Critch, and Sergey Levine. Emergent complexity and zero-shot transfer via unsupervised environment design. Advances in Neural Information Processing Systems , 33:13049{13061, 2020.

[43] Jonathan C Brant and Kenneth O Stanley. Minimal criterion coevolution: a new approach to open-ended search. In Proceedings of the Genetic and Evolutionary Computation Conference , pages 67{74. ACM, 2017.

[44] Detailed description of unified format. https://www.gnu.org/software/ diffutils/manual/html node/Detailed-Unified.html.

[45] Open AI blogpost: New GPT-3 capabilities: Edit and insert. https:// openai.com/blog/gpt-3-edit-insert/, 2022.

[46] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. arXiv preprint arXiv:2203.02155 , 2022.

[47] Ben Wang and Aran Komatsuzaki. GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/kingo olz/ mesh-transformer-jax, May 2021.

[48] Melanie Mitchell. An introduction to genetic algorithms . MIT Press, 1999.

[49] Kenneth A. De Jong. Evolutionary Computation: A unified approach . MIT Press, Cambridge, MA, 2006.

[50] Justin K Pugh, Lisa B. Soros, and Kenneth O. Stanley. Quality diversity: A new frontier for evolutionary computation. 3(40), 2016. ISSN 2296-9144. URL http://www.frontiersin.org/evolutionary-robotics/ 10.3389/frobt.2016.00040/abstract.

[51] Jean-Baptiste Mouret and Jeff Clune. Illuminating search spaces by mapping elites. ArXiv e-prints , abs/1504.04909, 2015. URL http://arxiv.org/ abs/1504.04909.

[52] Rui Wang, Joel Lehman, Jeff Clune, and Kenneth O. Stanley. Poet: Open-ended coevolution of environments and their optimized solutions. In Proceedings of the Genetic and Evolutionary Computation Conference , GECCO '19, page 142{151, New York, NY, USA, 2019. Association for Computing Machinery. ISBN 9781450361118. doi: 10.1145/3321707. 3321799. URL https://doi.org/10.1145/3321707.3321799.

[53] Jonathan C. Brant and Kenneth O. Stanley. Diversity preservation in minimal criterion coevolution through resource limitation. In Proceedings of the 2020 Genetic and Evolutionary Computation Conference , GECCO '20, page 58{66, New York, NY, USA, 2020. Association for Computing Machinery. ISBN 9781450371285. doi: 10.1145/3377930.3389809. URL https://doi.org/10.1145/3377930.3389809.

[54] Bowen Baker, Ingmar Kanitscheider, Todor Markov, Yi Wu, Glenn Powell, Bob McGrew, and Igor Mordatch. Emergent tool use from multi-agent autocurricula. arXiv preprint arXiv:1909.07528 , 2019.

[55] Antoine Cully, Jeff Clune, Danesh Tarapore, and Jean-Baptiste Mouret. Robots that can adapt like animals. Nature , 521(7553):503{507, 2015.

[56] Silja Meyer-Nieberg and Hans-Georg Beyer. Self-adaptation in evolutionary algorithms. In Parameter setting in evolutionary algorithms , pages 47{75. Springer, 2007.

[57] Oliver Kramer. Evolutionary self-adaptation: a survey of operators and strategy parameters. Evolutionary Intelligence , 3(2):51{65, 2010.

[58] Nikolaus Hansen. The cma evolution strategy: a comparing review. Towards a new evolutionary computation , pages 75{102, 2006.

[59] Daan Wierstra, Tom Schaul, Jan Peters, and Juergen Schmidhuber. Natural evolution strategies. In Evolutionary Computation, 2008. CEC 2008.(IEEE World Congress on Computational Intelligence). IEEE Congress on , pages 3381{3387. IEEE, 2008.

[60] Kenneth O. Stanley and Risto Miikkulainen. A taxonomy for artificial embryogeny. Artificial Life , 9(2):93{130, 2003. URL http://nn.cs.utexas. edu/keyword?stanley:alife03.

[61] Kenneth O. Stanley. Compositional pattern producing networks: A novel abstraction of development. Genetic Programming and Evolvable Machines Special Issue on Developmental Systems , 8(2):131{162, 2007.

[62] Josh C. Bongard and Rolf Pfeifer. Repeated structure and dissociation of genotypic and phenotypic complexity in artificial ontogeny. In Lee Spector, Erik D. Goodman, Annie Wu, W. B. Langdon, Hans-Michael Voigt, Mitsuo Gen, Sandip Sen, Marco Dorigo, Shahram Pezeshk, Max H. Garzon, and Edmund Burke, editors, Genetic and Evolutionary Computation Conference , pages 829{836, 2001. ISBN 1-55860-774-9. URL http://www-illigal.ge.uiuc.edu:8080/gecco-2001/.

[63] Petet J. Bentley and S. Kumar. Three ways to grow designs: A comparison of embryogenies for an evolutionary design problem. In Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-1999) , pages 35{43, 1999.

[64] Richard S. Sutton and Andrew G. Barto. Reinforcement Learning: An Introduction . 1998. ISBN 0-262-19398-1.

[65] Nitish Shirish Keskar, Bryan McCann, Lav R Varshney, Caiming Xiong, and Richard Socher. CTRL: A conditional transformer language model for controllable generation. arXiv preprint arXiv:1909.05858 , 2019.

[66] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. arXiv preprint arXiv:1512.03385 , 2015.

[67] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347 , 2017.

[68] John Schulman, Philipp Moritz, Sergey Levine, Michael Jordan, and Pieter Abbeel. High-dimensional continuous control using generalized advantage estimation. arXiv preprint arXiv:1506.02438 , 2015.

[69] Paul Christiano, Jan Leike, Tom B Brown, Miljan Martic, Shane Legg, and Dario Amodei. Deep reinforcement learning from human preferences. arXiv preprint arXiv:1706.03741 , 2017.

[70] Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul Christiano. Learning to summarize from human feedback. arXiv preprint arXiv:2009.01325 , 2020.

[71] Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch. Decision transformer: Reinforcement learning via sequence modeling. arXiv preprint arXiv:2106.01345 , 2021.

[72] M. Sipper. Tiny genetic programming in python. https://github.com/ moshesipper/tiny gp, 2019.

A So sánh Toán tử Đột biến
Phần này đưa ra chi tiết thêm về các thí nghiệm sử dụng các toán tử đột biến khác nhau để sửa lỗi trong một bước nhiễu loạn duy nhất. Một hình thức đơn giản của đột biến GP được triển khai với Tiny GP [72], một triển khai GP dựa trên cây. Cụ thể, toán tử đột biến bị hạn chế để đột biến các nút, điều này mang lại cho nó cơ hội thành công cao nhất cho bản chất của các lỗi được giới thiệu (không giới thiệu cấu trúc mới, mà thay vào đó mỗi lỗi thực chất hoán đổi một nút sai với một nút đúng). Đối với Tiny GP, tỷ lệ đột biến được điều chỉnh thủ công cho mỗi vấn đề. Mặc dù tồn tại nhiều toán tử đột biến phức tạp hơn trong GP [25, 26], động lực cho những thí nghiệm này chủ yếu là làm nổi bật tiềm năng cho các toán tử nhiễu loạn có hướng dựa trên LLM để thực hiện các chuyển động tinh vi dọc theo đa tạp của mã.

Thiết lập thí nghiệm cho mỗi nhiệm vụ (được mô tả tiếp theo) là mỗi toán tử đột biến được đưa ra nhiều thử nghiệm độc lập, nơi toán tử nhiễu loạn một parent có lỗi duy nhất (với khả năng nhiều lỗi), và child kết quả được kiểm tra tính đúng đắn. Đầu tiên, một phiên bản Python 3 của mỗi hàm được viết, sau đó (để nhiễu loạn bởi GP) nó được dịch thủ công thành một cây Tiny GP. Thông điệp cam kết cho các mô hình diff cho những nhiệm vụ này là \Fixed bugs." Lưu ý rằng GP không thể sử dụng doc-string văn bản thuần túy mô tả hàm dự định làm gì, điều này làm nổi bật một lợi thế khác của LLMs cho nhiễu loạn, trong đó chúng có thể sử dụng (và tạo ra) các bình luận dựa trên ngôn ngữ để hướng dẫn sự tiến hóa của mã. Đối với kỹ thuật prompt, định dạng prompt sau được sử dụng (với \{problem}" được thay thế bằng mã triển khai có lỗi):

# A buggy implementation
{problem}

# Fixed Bugs
def

Hai nhiệm vụ benchmark được khám phá: 4-Parity, nơi mục tiêu là tính toán parity của một chuỗi 4-bit, và Quadratic, nơi mục tiêu là tính toán kết quả của một hàm bậc hai, cho các giá trị của các hệ số a,b,c, và biến độc lập x. Động lực cho 4-Parity là bit parity là một nhiệm vụ benchmark GP phổ biến [3] và cung cấp một test-bed đơn giản để xem liệu LLMs có thể thực hiện nhiều thay đổi phối hợp (và hiệu quả) đối với mã hay không. Quadratic cung cấp một test-bed đơn giản khác, và không giống như 4-Parity, các lỗi được giới thiệu mơ hồ hơn (tức là mô tả hàm không ngụ ý rằng hàm phải có bất kỳ hình thức chuẩn nào), làm cho nó giống hơn với trường hợp sử dụng của bài báo này, trong đó các thay đổi không có hướng nhưng có ý nghĩa về mặt ngữ nghĩa được mong muốn. Lưu ý rằng bản chất của các lỗi được giới thiệu cho mỗi nhiệm vụ được mô tả trong phần tiếp theo cùng với mã nguồn cho triển khai đúng (mà các lỗi được giới thiệu vào).

A.1 Nguồn Python cho Nhiệm vụ Benchmark

A.1.1 4-Parity
#!/usr/bin/python3
def parity(b1,b2,b3,b4):
 """ Return binary parity of a sequence of input bits.
 Return 0 for even parity, 1 for odd parity """
 bit_sum = sum([b1,b2,b3,b4])
 return bit_sum % 2

Các lỗi được giới thiệu một cách gia tăng theo cách sau: Đối với bốn đột biến đầu tiên, mỗi biến với tiền tố \b" được đổi tên với tiền tố \c" (ví dụ đầu tiên \b1" được thay đổi thành \c1", sau đó \b2" được thay đổi thành \c2", v.v.). Đối với đột biến thứ năm, \modulus hai" được thay thế bằng modulus ba. Đối với GP, các terminal có tiền tố \c" bổ sung được giới thiệu.

A.1.2 Quadratic
#!/usr/bin/python3
def quadratic(a,b,c,x):
 """ Return quadratic: a,b,c are coefficients
 and x is the independent variable."""
 return a*pow(x,2)+b*x+c

Tối đa hai lỗi được giới thiệu vào nhiệm vụ Quadratic bằng cách cá biệt thay thế các toán tử + bằng các toán tử -, từ trái sang phải.

A.2 So sánh GP và Đột biến Diff
Các biểu đồ hiệu suất so sánh GP với đột biến diff cho nhiệm vụ 4-Parity có trong Hình 1 trong văn bản chính. Hình 20 trong phụ lục này cho thấy cùng sự so sánh cho nhiệm vụ Quadratic, nơi hiệu suất tương tự như 4-Parity, tức là hiệu suất của đột biến diff cả lớn hơn đột biến GP cho cả hai trường hợp lỗi, và suy giảm theo một mô hình khác (ở đây, hiệu suất của đột biến diff không bị ảnh hưởng bởi việc giới thiệu lỗi thứ hai).

A.3 So sánh Đột biến dựa trên API
Các biểu đồ hiệu suất so sánh đột biến diff với các đột biến có thể thông qua OpenAI API cho nhiệm vụ 4-Parity có thể thấy trong Hình 2 trong văn bản chính. Hình 21 ở đây cho thấy cùng sự so sánh cho nhiệm vụ Quadratic, làm nổi bật kết quả tương tự: Có nhiều lựa chọn cho toán tử đột biến có sẵn thông qua OpenAI API hoạt động tốt như hoặc tốt hơn mô hình diff được áp dụng trong các thí nghiệm của bài báo này.

B Mã Nguồn Hạt giống
Phần này chứa mã nguồn của các chương trình hạt giống cho ELM. Video cho Sodaracers mà những chương trình này đại diện có sẵn tại: https://y2u.be/ jeP8Nsulu48.

B.1 Hạt giống CPPN
Có hai hạt giống giống CPPN. CPPN-Fixed không cho phép chức năng cốt lõi của mã hóa CPPN (được gói gọn trong hàm query cppn) thay đổi, trong khi CPPN-Mutable bao gồm mã nguồn cho hàm đó, do đó cho phép bản thân mã hóa CPPN cũng tiến hóa.

B.1.1 CPPN-Fixed
def make_walker():
 wc = walker_creator()

 def connect(x1,y1,x2,y2):
 if ((x1-x2)**2+(y1-y2)**2)>4.5:
 return False
 return True

 def amp(x1,y1,x2,y2):
 return max(abs(x1-x2),abs(y1-y2))

 def phase(x1,y1,x2,y2):
 return np.sign(x1)

 joints = query_cppn(wc,8,3,1.5,connect,amp,phase)

 return wc.get_walker()

B.1.2 CPPN-Mutable
def query_cppn(wc, xgrid,ygrid,scale,connect_func,amp_func, phase_func):
 """ Create a grid of points and functionally connect them. """
 joints = {}
 for x in range(xgrid):
 for y in range(ygrid):
 joints[(x,y)] = wc.add_joint(x*scale,y*scale)

 for x1 in range(xgrid):
 for y1 in range(ygrid):
 for x2 in range(x1,xgrid):
 for y2 in range(y1,ygrid):
 if x1==y1 and x2==y2:
 continue
 if connect_func(x1,y1,x2,y2):
 amp = amp_func(x1,y1,x2,y2)
 phase = phase_func(x1,y1,x2,y2)
 wc.add_muscle(joints[(x1,y1)], joints[(x2,y2)],False,amp,phase)

 return joints

def make_walker():
 wc = walker_creator()

 def connect(x1,y1,x2,y2):
 if ((x1-x2)**2+(y1-y2)**2)>4.5:
 return False
 return True

 def amp(x1,y1,x2,y2):
 return max(abs(x1-x2),abs(y1-y2))

 def phase(x1,y1,x2,y2):
 return x1 if x1%2==1 else -x1

 joints = query_cppn(wc,8,3,1.5,connect,amp,phase)

B.2 Hạt giống Square
def make_square(wc, x0, y0, x1, y1):
 """ Make a square with top left x0,y0 and top right x1,y1 """

 j0 = wc.add_joint(x0, y0)
 j1 = wc.add_joint(x0, y1)
 j2 = wc.add_joint(x1, y1)
 j3 = wc.add_joint(x1, y0)

 return j0, j1, j2, j3


def make_walker():

 wc = walker_creator()

 # the main body is a square
 sides = make_square(wc, 0, 0, 10, 10)
 center = wc.add_joint(5, 5)

 # connect the square with distance muscles
 for k in range(len(sides)-1):
 wc.add_muscle(sides[k], sides[k+1])
 wc.add_muscle(sides[3], sides[0])

 # one prong of the square is a distance muscle
 wc.add_muscle(sides[3], center)

 # the other prongs from the center of the square are active
 wc.add_muscle(sides[0], center, False, 5.0, 0.0)
 wc.add_muscle(sides[1], center, False, 10.0, 0.0)
 wc.add_muscle(sides[2], center, False, 2.0, 0.0)

 return wc.get_walker()

B.3 Hạt giống Radial
def make_circle(wc, cx,cy,radius,num_points):
 """ Approximate a circle with center (cx,cy) square with
 num_points points """
 joints = []

 tot_ang = 3.14*2.0

 for idx in range(num_points):
 ang = tot_ang/(num_points-1)*idx
 x = math.cos(ang) * radius + cx
 y = math.sin(ang) * radius + cy
 joints.append(wc.add_joint(x,y))

 return joints


def make_walker():

 wc = walker_creator()

 num_points = 8
 rad = 5.0
 cx,cy = (5,5)
 # the main body is a square
 points = make_circle(wc, cx,cy,rad,num_points)
 center = wc.add_joint(cx,cy)

 for k in range(num_points):
 wc.add_muscle(points[k], points[(k+1)%num_points])
 wc.add_muscle(points[k], center,False,float(k)/num_points, float(k)/num_points)

 return wc.get_walker()

C Kiến trúc Mô hình
Chi tiết kiến trúc cho các mô hình ngôn ngữ được áp dụng trong bài báo này được hiển thị trong Bảng 1. Các mô hình dựa trên kiến trúc GPT-3, và mô tả thêm về kiến trúc và siêu tham số có thể được tìm thấy trong Brown et al. [2].

nparams nlayers dmodel nheads dhead
0.1M 2 64 4 16
85M 12 768 12 64
350M 24 1,024 16 64
760M 24 1,536 16 96

Bảng 1: Kiến trúc mô hình. Bảng cho thấy các siêu tham số mô tả kiến trúc của các mô hình được sử dụng trong bài báo này, bao gồm số lượng tham số (nparams), số lớp (nlayers), số đơn vị trong mỗi lớp bottleneck (dmodel), số attention heads (nheads), và chiều của mỗi attention head (dhead).

D Tính Mạnh mẽ của Hạt giống
Một vấn đề tinh tế được phát hiện khi tập hợp đường ống đầy đủ, đó là có những tương tác phức tạp giữa loại hạt giống khởi động ELM trong Giai đoạn 1 và hiệu suất của các mô hình RL được huấn luyện trong Giai đoạn 3. Cụ thể, một số hạt giống (như hạt giống Radial) đạt điểm QD cao trong Giai đoạn 1, nhưng thất bại trong việc cung cấp điểm khởi đầu tốt để thích ứng với các địa hình mới lạ trong Giai đoạn 3. Khi kiểm tra các sản phẩm của hạt giống Radial, nhiều trong số chúng thể hiện động lực học hỗn loạn có vẻ quá nhạy cảm với điều kiện ban đầu. Kết quả hỗn loạn tương tự được quan sát với hạt giống CPPN-Mutable được huấn luyện với mô hình diff được tiền huấn luyện. Kết luận là điểm QD không hoàn toàn nắm bắt được điều gì cho phép tổng quát hóa và thích ứng với các địa hình mới lạ. Hiểu vấn đề này có thể quan trọng cho nghiên cứu thêm.

Các ý tưởng có thể để thiên lệch hạt giống hướng tới việc tạo ra các phát minh có thể tổng quát hóa bao gồm không cho phép thiết lập chính xác vị trí khớp và tham số dao động, giới thiệu tính ngẫu nhiên để ngăn chặn overfitting với điều kiện ban đầu, và điều chỉnh hạt giống một cách gia tăng. Kết quả sơ bộ trong việc không cho phép thiết lập chính xác tham số đã cung cấp kết quả hỗn hợp.

Một kết quả hứa hẹn đến từ thiết kế hạt giống gia tăng. Với hạt giống CPPN-Mutable (nơi logic mô tả mã hóa CPPN có thể được tiến hóa), mô hình diff được tiền huấn luyện hoạt động tương tự như hạt giống Radial (nó tạo ra các phát minh với hiệu suất định lượng cao nhưng khai thác động lực học hỗn loạn). Tuy nhiên, khi mô hình diff được tinh chỉnh trên các sản phẩm của hạt giống CPPN-Fixed (nơi logic CPPN cốt lõi được bảo tồn), các chạy CPPN-Mutable thêm giữ lại các đặc điểm định tính của hạt giống CPPN-Fixed trong khi vượt trội hơn nó về mặt định lượng. Tức là, hạt giống CPPN-Fixed cung cấp \training wheels" để học cách điều chỉnh bản thân mã hóa trong hạt giống CPPN-Mutable. Theo cách này, một phương pháp gia tăng cho thiết kế hạt giống (có khả năng liên quan đến tiến hóa tương tác) có thể là một phương pháp hứa hẹn để định hình định tính các đầu ra của ELM; hoặc, khái niệm điểm QD có thể được mở rộng hoặc thay đổi để căn chỉnh tốt hơn với hiệu suất downstream mạnh mẽ.

E Phương pháp Bản đồ Cuối cùng cho Giai đoạn 2
Có nhiều cách để chưng cất dữ liệu thô được tạo ra bởi Giai đoạn 1 thành một tập dữ liệu mà một mô hình có thể được huấn luyện. Phần này chi tiết một phương pháp thay thế tự nhiên cho phương pháp ngưỡng phần trăm được sử dụng trong bài báo, được gọi là phương pháp bản đồ cuối cùng. Phương pháp là nối từ tất cả các chạy các giải pháp từ bản đồ MAP-Elites cuối cùng của chúng, tức là các giải pháp chất lượng tốt nhất cho mỗi hốc ở cuối một chạy.

Phương pháp này đạt được một sự đánh đổi khác giữa số lượng và chất lượng của các mẫu dữ liệu so với phương pháp ngưỡng phần trăm. Phương pháp ngưỡng phần trăm chuẩn hóa hiệu suất qua các chạy cho mỗi hốc, và sau đó bao gồm tất cả các giải pháp chất lượng cao hợp lý. Phương pháp bản đồ cuối cùng, mặt khác, bất khả tri với hiệu suất của một chạy hoặc hạt giống nhất định (nó không chuẩn hóa qua các chạy), và đối với mỗi chạy chỉ lấy dữ liệu chất lượng cao nhất cho mỗi hốc được khám phá.

Tập dữ liệu bản đồ cuối cùng tự nhiên bao gồm ít ví dụ hơn (chỉ 13K ví dụ). Các mô hình được huấn luyện trên bản đồ cuối cùng nói chung hoạt động tệ hơn so với các mô hình ngưỡng phần trăm trên điểm QD. Kết quả QD thấp hơn từ thực tế rằng hiệu suất qua bản đồ cuối cùng thay đổi đáng kể qua các hạt giống (ví dụ hạt giống Square hoạt động rất mạnh trong một số hốc nhất định, nhưng thất bại trong việc tìm giải pháp trong những hốc khác, trong khi hạt giống giống CPPN khám phá giải pháp trong gần như tất cả các hốc, nhưng nói chung với hiệu suất yếu hơn). Kết quả là, mẫu trung bình từ tập dữ liệu bản đồ cuối cùng hoạt động tệ hơn so với những mẫu từ tập dữ liệu ngưỡng phần trăm (dẫn đến điểm QD thấp hơn trong tập dữ liệu, và cũng trong các mô hình được huấn luyện).

Ngoài ra, các thí nghiệm Giai đoạn 3 sơ bộ chứng tỏ không ổn định khi sử dụng các mô hình được huấn luyện trên tập dữ liệu bản đồ cuối cùng. Thực chất, tập dữ liệu bản đồ cuối cùng dường như quá nhỏ để phục vụ như một điểm khởi đầu đáng tin cậy cho RL thêm.

F Mã Nguồn cho Mục tiêu Hoàn thành
Phần này bao gồm mã nguồn cho ba phát minh phục vụ như các bài kiểm tra hoàn thành ngoài phân phối cho các mô hình được huấn luyện trong Giai đoạn 2. Video cho những phát minh này được hiển thị tại: https://y2u.be/8C2K5fk28HI.

ELM thường thêm cấu trúc vào hạt giống, như trong vòng lặp lồng nhau của Wheel, hoặc nhiều vòng lặp được thêm trong Galloper, và cũng tái sử dụng các lời gọi hàm (ví dụ gọi make sensor nhiều lần trong Galloper; lưu ý rằng make sensor là một phiên bản được đổi tên (và sửa đổi) của hàm make square được bao gồm trong hạt giống Square.

Các bình luận vô nghĩa thường được chèn vào (như trong \acrylic of current (m)" trong nguồn của Runner), mặc dù áp lực parsimony trong thuật toán MAP-Elites có xu hướng cuối cùng loại bỏ chúng (ví dụ không có bình luận nào trong phát minh Wheel). Trong một số tình huống, các bình luận gốc của hạt giống được bảo tồn, như trong bình luận \connect the square with distance muscles" trong mã nguồn của Galloper.

F.1 Wheel
import math
def make_circle(wc, cx,cy,radius,num_points):
 joints = []
 tot_ang = 3.14*2.0
 for idx in range(num_points):
 ang = tot_ang/(num_points+1) * idx
 x = math.cos(ang) * radius + 0.5
 y = math.sin(ang) * radius + cy
 joints.append(wc.add_joint(x,y))
 return joints
def make_walker():
 wc = walker_creator()
 num_points = 8
 rad = 3.0
 cx,cy = (11,5)
 points = make_circle(wc, 0.6, -0.5,rad/2,num_points)
 center = wc.add_joint(cx+1,cy+1)
 for j in range(num_points):
 for i in range(num_points-5):
 wc.add_muscle(points[j], points[(i+j)%num_points], 0.0, 1.0, (j+1)/num_points)
 wc.add_muscle(points[j], center,False,3,(j+1)/num_points)
 return wc.get_walker()

F.2 Galloper
def make_sensor(wc, x0, y0, x1, y1, d):
 return wc.add_joint(x0, y0), wc.add_joint(x1, y1), wc.add_joint(x1, y0), wc.add_joint(x0, y1), wc.add_joint(d, 0.5), wc.add_joint(x1, 0.5)

def make_walker(dx=0.0, dy=0.0, ddr=0, ddc=1.6, sid=8.0, s_influence=0.2, s_side_width=0.0, first_center=5.0, last_center=15.0):
 wc = walker_creator()
 ends = [make_sensor(wc, 5 + dx, -1 + dy, ddr, ddc, 4.5), make_sensor(wc, 0, -0.1, sid, 9.5, 0.03), make_sensor(wc, 5.5, -0.001, 5.0, 4.86 +0.8, 0.07), make_sensor(wc, 5.5, -3.0, 6.0, 4.86 + 0.8, 0.07), make_sensor(wc, 0, dx, ddr, ddc, 1.0)]

 sides = ends[0] + ends[1] + ends[2] + ends[-1] + ends[-2] + ends[-3]

 center = wc.add_joint(dx, dy)
 # connect the square with distance muscles
 for k in range(len(sides)-6):
 wc.add_muscle(sides[k], sides[k+1], True, 30, 0.5)
 wc.add_muscle(sides[2], sides[4], False, 4.0, 0.8)
 for k in range(len(sides)-2):
 wc.add_muscle(sides[k], sides[k + 2], True, 18.0, 60.0 / 5.5)

 for k in reversed(range(len(sides)-6)):
 wc.add_muscle(sides[k], sides[k + 5], False, 4.0, 20.0 / 9.0)
 wc.add_muscle(center, sides[7], False, 2.0, 90.0 / 9.0)
 return wc.get_walker()

F.3 Runner
import math
import numpy as np

def make_walker(p_scale=1): # acrylic of current (m)
 wc = walker_creator()

 def connect(x1,y1,x2,y2):
 if -2*x1+x2*2>2:
 return True
 return x1<= abs(y1-y2)

 def amp(x,y,x2,y2):
 return abs(x-x2) + abs(y-y2)

 def phase(x1,y1,x2,y2):
 return -x1/2 - math.cos(math.pi/9)

 joints = query_cppn(wc,5,7+p_scale,2,connect,amp,phase)
 return wc.get_walker()

G Mã Nguồn cho Sodaracers Giai đoạn 1 Được Chọn

G.1 Blob (từ Hạt giống CPPN)
Một video của Sodaracer được đại diện bởi mã dưới đây có thể thấy tại: https: //y2u.be/JDUAI8yrNcY.

import math

def walker():
 wc = walker_creator()

 def connect(x1,y1,x2,y2):
 return (x1-x2)**2+5*y1**2-4*x2**2+y2**2 > 2.5
 def amp(x1,y1,x2,y2):
 return (x1-x2)**2+x2**2 + 1 - y2**2 < 2

 def phase(x1,y1,x2,y2):
 return math.sin(x1)*math.cos(y1)**2 + 1

 joints = query_cppn(wc,5,6,2.1,connect,amp,phase)
 return wc.get_walker()

G.2 Hopper (từ Hạt giống Square)
Một video của Sodaracer được đại diện bởi mã dưới đây có thể thấy tại: https: //y2u.be/noSPGFX5m3M.

def make_square(wc, x0, y0, x1, y1, length):
 j0 = wc.add_joint(x0, y0)
 j1 = wc.add_joint(x0, y1)
 j2 = wc.add_joint(x1, y1)
 j3 = wc.add_joint(x1, y0)

 return j0, j1, j2, j3


def make_walk(n=6):

 wc = walker_creator()

 # the main body is a square
 sides_2_theta = make_square(wc, 0.0, 0.0, 5.6, 9.4, 2.4)
 sides_1_theta = make_square(wc, 0.5, 0.8, 6.5, 13.1, 1.3)
 sides_2_theta += make_square(wc, -0.8, -0.6, 6.7, 13.0, 2.3)
 sides_2_theta += make_square(wc, -0.9, -0.6, 8.4, 12.5, 0.7)
 sides_2_theta += make_square(wc, 0.0, -0.5, 0.2, 12.4, 1.7)
 sides = sides_1_theta + sides_2_theta + sides_1_theta
 center = wc.add_joint(2, 2)

 # connect the square with distance muscles
 for k in range(len(sides)-2):
 wc.add_muscle(sides[k], sides[k+1])
 wc.add_muscle(sides[k+2], sides[k], False, 30.0, 30.0)

 # similarities of the Squares with":
 for k in range(len(sides)-2):
 wc.add_muscle(sides[k], sides[k], True)

 for n in range(k, len(sides)):
 wc.add_muscle(sides[k], sides[n], False)
 wc.add_muscle(sides[3], center)
 # the other prongs from the center of the square are active
 wc.add_muscle(sides[2], center, False, 25.0, 25.0-0.7)
 wc.add_muscle(sides[3], center, False, 20.0, 30.0+0.4)

 return wc.get_walker()

G.3 Centipede (từ Hạt giống Radial)
Một video của Sodaracer được đại diện bởi mã dưới đây có thể thấy tại: https: //y2u.be/zhMsPzo22do.

import math


def make_circle(wc, cx,cy,radius,num_points,eccentricity=1.4):
 joints = []


 tot_ang = math.pi*2.0*eccentricity

 for idx in range(1,num_points):
 x = math.cos(3.14*(idx+num_points)*tot_ang/(num_points)) * radius + cx
 y = math.sin(3.14*(idx+num_points)*tot_ang/(num_points)) * radius + cy
 joints.append(wc.add_joint(x,y))

 return joints

def make_walker(num_points=300,rad=3.25,f=3,max_rad=3):
 wc = walker_creator()

 cx,cy = (0,0)
 body_size = rad*1.625

 points = make_circle(wc, 0,0,body_size,num_points)
 center = wc.add_joint(cx,cy)

 for k in range(1,num_points-1):
 wc.add_muscle(points[((k%10) - 1) % 10], points[k], False, int(f*k/float(10)), k/10.)
 wc.add_muscle(points[(k%10)], points[k], True, 1, k/10.)

 return wc.get_walker()

H Thăm dò Mô hình Giai đoạn 2
Một hy vọng cho các mô hình được huấn luyện trong Giai đoạn 2 là chúng sẽ học không chỉ để ghi nhớ dữ liệu huấn luyện (các ví dụ Python của Sodaracers), mà còn nội hóa cấu trúc cơ bản của miền (ví dụ làm thế nào nói chung để trộn lò xo và khối lượng với nhau để tạo ra các phát minh Sodarace chức năng). Phần này thảo luận một số quan sát sơ bộ của các thí nghiệm không chính thức thay đổi quy trình huấn luyện trong Giai đoạn 2 để khám phá những gì mô hình có khả năng học. Cụ thể, các ví dụ Sodarace được tăng cường với các bình luận bổ sung (hoặc như một tiền tố hoặc hậu tố) chứa cả fitness của Sodaracer và đặc tính hóa hành vi của nó (chiều rộng, chiều cao và khối lượng của nó).

Ý tưởng là sau khi huấn luyện, mô hình có thể được yêu cầu dự đoán ví dụ fitness của một phát minh chưa thấy (nếu được huấn luyện với bình luận hậu tố), hoặc tạo ra một walker với thuộc tính mong muốn (nếu được huấn luyện với bình luận tiền tố). Ví dụ, một mô hình được huấn luyện tiền tố có thể được lấy mẫu có điều kiện dựa trên một tiền tố chỉ định chiều cao, chiều rộng và khối lượng mong muốn của một Sodaracer, để xem mẫu có thể khớp với những thuộc tính đó một cách đáng tin cậy như thế nào khi được đánh giá trong miền.

Các thí nghiệm sơ bộ với cả mô hình tiền tố và hậu tố 300M tham số làm nổi bật rằng mô hình có khả năng tạo ra những liên kết như vậy trong phân phối huấn luyện, ví dụ khi một mô hình hậu tố được truy vấn với chiều cao, chiều rộng và khối lượng được lấy từ các ví dụ tập kiểm tra (được giữ lại từ cùng phân phối), nó có thể nhất quán tạo ra một Sodaracer với những thuộc tính đó. Nó ít đáng tin cậy hơn khi được điều kiện trên fitness, phản ánh rằng đây là một liên kết phức tạp hơn nhiều (ví dụ không giống như chiều rộng và chiều cao, fitness phụ thuộc vào động lực học vật lý của walker được tạo ra).

Tuy nhiên, khi được đưa ra khỏi phân phối, mô hình ít mạnh mẽ hơn. Ví dụ, một mô hình tiền tố gặp khó khăn trong việc tạo ra Sodaracers một cách có mục tiêu trong một dải chiều rộng và chiều cao được cố ý giữ lại từ tập huấn luyện. Thú vị là, mặc dù nó không đáng tin cậy trong việc tạo ra Sodaracers của chiều rộng và chiều cao được giữ lại cụ thể, các mẫu từ mô hình thực sự bao phủ khu vực holdout, cho thấy rằng sự biến đổi có thể truy cập trong mô hình đủ cho nội suy hoặc ngoại suy nhẹ, đó là một thuộc tính quan trọng để cho phép sự elaboration mở rộng liên tục.

Còn rõ ràng hơn, một mô hình hậu tố có khả năng rất hạn chế để dự đoán fitness của Sodaracers được lấy từ hạt giống Radial, không được thấy trong huấn luyện (có tương quan Spearman chỉ 0 :08). Một giả thuyết để lại cho công trình tương lai khám phá, là các mô hình lớn hơn, được huấn luyện với nhiều dữ liệu được tạo ra hơn, có thể có hiệu suất mạnh mẽ hơn khi được đưa ra ngoài phân phối. Nếu đúng, điều này sẽ hỗ trợ rằng việc mở rộng có thể có lợi cho việc học mở rộng, giống như nó làm trong học không giám sát và có giám sát.

Một dòng suy nghĩ suy đoán hơn xuất hiện từ những thí nghiệm này liên quan đến cách Giai đoạn 2 cấu trúc kiến thức về miền, có thể tác động đáng kể đến động lực học của cách RL trong Giai đoạn 3 diễn ra. Tức là, bằng cách huấn luyện mô hình liên kết Sodaracers với thuộc tính của chúng (thông qua tiền tố hoặc hậu tố), có thể khả năng cao hơn rằng Giai đoạn 3 có thể nội suy mượt mà trong không gian của những thuộc tính đó, mà nếu không mô hình sẽ không có kiến thức rõ ràng nào về. Tuy nhiên, khi một mô hình được huấn luyện tiền tố được kiểm tra trong thiết lập nội suy của Phụ lục I, nó không hoạt động tốt hơn so với những mô hình được huấn luyện mà không có tiền tố. Mặc dù việc huấn luyện tiền tố như vậy không có tác động mong muốn, vẫn là một câu hỏi mở về cách bao gồm trong Giai đoạn 2 thông tin trực quan có vẻ rất liên quan đến RL (như fitness) theo cách có lợi tối đa cho RL như vậy.

Nhìn chung, kết luận là (ít nhất với các mô hình 300M tham số và lượng dữ liệu huấn luyện hiện tại), các mô hình Giai đoạn 2 chứng minh khả năng khiêm tốn để học cấu trúc trong Sodarace, nhưng chưa mạnh mẽ khi được đưa ra ngoài phân phối. Tác động đối với tính mở rộng không rõ ràng (liệu điều này có tạo ra vấn đề cho nghiên cứu tương lai hay không): Ví dụ, có thể khả năng tổng quát hóa mạnh hơn có thể xuất hiện tự nhiên hơn khi đường ống hiện có (chủ yếu là một bằng chứng về khái niệm) được mở rộng sao cho Giai đoạn 3 được nhúng trong một quá trình mở rộng. Thực sự, ít nhất trong các quá trình đổi mới của con người, cái nhìn sâu sắc chung dường như thường xuất hiện từ sự tích lũy mở rộng liên tục của các ví dụ ban đầu khác biệt về hiện tượng mà sau này mới được thống nhất.

I Thí nghiệm Nội suy
Phần này thảo luận các thí nghiệm thăm dò mức độ nhà phát minh có điều kiện (sản phẩm của Giai đoạn 3) có thể hiểu miền của phát minh, bằng cách khám phá liệu mô hình có thể điều chỉnh đầu ra của nó một cách phù hợp để đáp ứng với những thay đổi có cấu trúc trong môi trường hay không. Tức là, việc điều chỉnh các phát minh để đáp ứng với các biến đổi mượt mà trong môi trường đòi hỏi sự hiểu biết sâu sắc hơn về cấu trúc của miền, và có thể cho phép các nhà phát minh tổng quát hóa ngoài các môi trường được quan sát trong quá trình huấn luyện.

Để kiểm tra khả năng này, một phân phối môi trường với các đặc điểm thay đổi mượt mà được tạo ra, cụ thể, bằng cách thay đổi chiều cao của các địa hình tunnel. Động lực cho phân phối này là quan sát rằng trong khi các Sodaracers lớn hơn không thể điều hướng các tunnel thấp, chúng có xu hướng di chuyển nhanh hơn trên địa hình phẳng. Do đó, mô hình được khuyến khích thích ứng chiều cao của Sodaracer được tạo ra với chiều cao của tunnel trong địa hình, sử dụng các Sodaracers \cao hơn" di chuyển nhanh cho các tunnel cao hơn, và các Sodaracers ngắn hơn, chậm hơn cho các tunnel thấp hơn. Khả năng đạt được một giải pháp như vậy sẽ ngụ ý rằng mô hình đã học về cấu trúc cơ bản của miền, trong đó nó có thể điều chỉnh chiều cao của các phát minh được tạo ra, và đã nắm bắt mối quan hệ này giữa chiều cao và tốc độ của Sodaracer. Để cho phép mô hình có khả năng học một ánh xạ mượt mà từ chiều cao của tunnel đến Sodaracer được tạo ra, kiến trúc ResNet TEN được sử dụng.

Tuy nhiên, trong các thí nghiệm, mô hình liên tục hội tụ trên các giải pháp xuất ra cùng một Sodaracer bất kể chiều cao của tunnel, tức là một giải pháp không điều kiện. Các ví dụ về những giải pháp như vậy được hiển thị tại https://y2u. be/gt1Z0lnjAuE.

Những kết quả này chỉ ra một đặc điểm tinh tế của đường ống phát minh được giới thiệu trong công trình này. Các mô hình không thể hiện sự hiểu biết sâu sắc về miền, tìm thấy một optimum địa phương, không điều kiện hoạt động \hợp lý" tốt trên hầu hết tất cả các địa hình trong phân phối. Đặc biệt đáng lo ngại là Sodaracer được tạo ra không thể điều hướng tất cả các địa hình trong phân phối, làm nổi bật tính không tối ưu của giải pháp đã học. Thuộc tính này làm rối loạn việc thăm dò khả năng nội suy của các nhà phát minh, và vẫn không rõ liệu đường ống phát minh có thể tạo ra các giải pháp phức tạp có thể thay đổi mượt mà các phát minh được tạo ra để đáp ứng với các biến đổi mượt mà trong môi trường hay không. Ngược lại, các thí nghiệm được trình bày trong phần chính của tài liệu này ngụ ý rằng mô hình có thể tạo ra các giải pháp có điều kiện khi không có giải pháp không điều kiện nào đủ.

Chúng tôi suy đoán rằng các optimum địa phương không điều kiện đơn giản hơn và dễ học hơn sử dụng các phương pháp RL, sao cho các mô hình \hướng tới" chúng khi những giải pháp như vậy tồn tại. Tuy nhiên, trong công trình tương lai, đường ống phát minh có thể được triển khai trong các quá trình phức tạp hơn, mở rộng nơi các giải pháp không điều kiện nên được tạo ra không đủ. Trong những thiết lập như vậy, có thể tưởng tượng rằng đường ống sẽ xuất ra các nhà phát minh có điều kiện có sự hiểu biết sâu sắc hơn về cấu trúc miền, vì những giải pháp như vậy sẽ cho phép các nhà phát minh đạt được phần thưởng cao hơn đáng kể trong miền, phủ nhận mối lo ngại về các giải pháp không điều kiện.

Một con đường khác cho nghiên cứu tương lai sẽ cố gắng làm cho nhiệm vụ học được đặt ra trong Giai đoạn 3 dễ dàng hơn bằng cách khám phá các phương pháp học maximum likelihood khi khởi động nhà phát minh có điều kiện (Giai đoạn 1 và 2). Ở đây, giả định là nhiệm vụ khám phá trong Giai đoạn 3, kết hợp với sự cần thiết của việc kết hợp phương thức mới, khá thách thức đối với các quy trình RL. Một phương pháp đơn giản cho điều này có thể là lấy mẫu từ LLM không điều kiện nhiều lần, và sử dụng các mẫu hoạt động tốt nhất cho mỗi địa hình trong phân phối như một tập dữ liệu có giám sát (cặp địa hình-Sodaracer) để tinh chỉnh cả LLM và TENs. Giai đoạn 3 có thể bao gồm các phân phối địa hình kết hợp các địa hình chưa thấy trong Giai đoạn 2, khuyến khích nhà phát minh tổng quát hóa thêm và khám phá không gian của các phát minh. Nhìn xa hơn nữa, có thể tưởng tượng để thay thế quy trình ELM dựa trên MAP-Elites của Giai đoạn 1 bằng một thuật toán kiểu POET [40], sẽ tạo ra một tập dữ liệu có giám sát của hình thức này trong Giai đoạn 1, giải phóng các nhà thiết kế đường ống khỏi nhu cầu chỉ định thủ công các phân phối địa hình để huấn luyện nhà phát minh có điều kiện trong Giai đoạn 2.

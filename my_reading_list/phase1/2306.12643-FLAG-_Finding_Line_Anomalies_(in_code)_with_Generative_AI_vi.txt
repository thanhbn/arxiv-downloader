# 2306.12643.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: ./2306.12643.pdf
# Kích thước tệp: 599702 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
FLAG: Tìm kiếm các Bất thường trong Dòng (trong mã) với Trí tuệ Nhân tạo Sinh tạo
Baleegh Ahmad
Đại học New York
Benjamin Tan
Đại học Calgary
Ramesh Karri
Đại học New York
Hammond Pearce
Đại học New South Wales

Tóm tắt
Mã chứa các lỗi bảo mật và chức năng. Quá trình xác định và định vị chúng là khó khăn và phụ thuộc vào lao động con người. Trong công việc này, chúng tôi trình bày một cách tiếp cận mới (FLAG) để hỗ trợ các nhà gỡ lỗi con người. FLAG dựa trên khả năng từ vựng của AI sinh tạo, cụ thể là các Mô hình Ngôn ngữ Lớn (LLM). Ở đây, chúng tôi nhập một tệp mã sau đó trích xuất và tái tạo từng dòng trong tệp đó để tự so sánh. Bằng cách so sánh mã gốc với một thay thế được tạo bởi LLM, chúng tôi có thể đánh dấu những khác biệt đáng chú ý như các bất thường để kiểm tra thêm, với các tính năng như khoảng cách từ nhận xét và độ tin cậy của LLM cũng hỗ trợ phân loại này. Điều này làm giảm không gian tìm kiếm kiểm tra cho nhà thiết kế. Không giống như các cách tiếp cận tự động khác trong lĩnh vực này, FLAG không phụ thuộc vào ngôn ngữ, có thể hoạt động trên mã không hoàn chỉnh (và thậm chí không biên dịch được) và không yêu cầu tạo ra các thuộc tính bảo mật, kiểm tra chức năng hoặc định nghĩa quy tắc. Trong công việc này, chúng tôi khám phá các tính năng giúp LLM trong phân loại này và đánh giá hiệu suất của FLAG trên các lỗi đã biết. Chúng tôi sử dụng 121 điểm chuẩn trên C, Python và Verilog; với mỗi điểm chuẩn chứa một điểm yếu bảo mật hoặc chức năng đã biết. Chúng tôi tiến hành các thí nghiệm sử dụng hai LLM tiên tiến trong code-davinci-002 và gpt-3.5-turbo của OpenAI, nhưng cách tiếp cận của chúng tôi có thể được sử dụng bởi các mô hình khác. FLAG có thể xác định 101 trong số các khiếm khuyết và giúp giảm không gian tìm kiếm xuống 12−17% của mã nguồn.

1 Giới thiệu
Lỗi xảy ra trong mã khi có sự khác biệt giữa ý định của nhà phát triển và việc thực hiện của họ. Những lỗi này có thể gây ra các lỗ hổng bảo mật hoặc thiếu sót về chức năng. Tìm ra chúng là một quá trình vất vả—mặc dù có các công cụ hỗ trợ, chúng thường chỉ hoạt động khi các chương trình được hoàn thành đầy đủ (hoặc ít nhất có thể biên dịch được), và sẽ chỉ tập trung vào một tập hợp con của ngôn ngữ hoặc các lớp lỗi. Do đó, trong quá trình phát triển, các nhà phát triển và nhóm của họ nên thường xuyên kiểm tra công việc của mình, và vì vậy các cách tiếp cận sẽ kết hợp xem xét thủ công với kiểm tra tự động [4], phân tích tĩnh [8], và fuzzing [20] để giúp xác định các vấn đề tiềm ẩn. Mã phải được kiểm tra đối với các ý định được nắm bắt một cách nội tại, rõ ràng trong trường hợp các tạo phẩm như kiểm tra, xác nhận, hoặc quy tắc (ví dụ: truy vấn khi sử dụng CodeQL [18]) hoặc một cách ngầm định (khi thực thi mã để tìm crash trong fuzzing).

Cho rằng các trường hợp mã lỗi ít gặp so với mã đúng (mã công nghiệp trung bình được ước tính có chứa 0,5 và 25 lỗi trên 1.000 dòng [24]), chúng tôi giả định rằng ý định của nhà phát triển chủ yếu được nắm bắt trong mã nguồn và nhận xét với các sai sót thỉnh thoảng cần được tìm ra và xử lý. Hãy tưởng tượng một nhà phát triển muốn xem xét mã của họ một cách thủ công; nếu một chương trình chỉ bao gồm một vài dòng mã và nhận xét, có lẽ điều này khả thi cho cả người mới bắt đầu và chuyên gia. Khi các dự án phát triển, điều này trở nên ngày càng thách thức do quy mô. Tìm cách thu hẹp các khu vực có vấn đề tiềm ẩn trong mã để xem xét có thể giúp các nhà phát triển, đặc biệt là khi bị áp lực về thời gian. Liệu ý định của mã nguồn và nhận xét có thể được sử dụng để đánh dấu các vấn đề trong mã, thu hẹp phạm vi xem xét thủ công cần thiết? Để trả lời điều này, chúng tôi điều tra việc sử dụng AI Sinh tạo, cụ thể là các mô hình ngôn ngữ lớn (LLM), để FLAG các bất thường trong mã.

LLM như GPT-3 [5] và Codex [7] thể hiện khả năng đáng kể cho một số nhiệm vụ từ vựng bao gồm viết mã. Chúng tạo ra đầu ra dựa trên sự tiếp tục của đầu vào—một loại 'tự động hoàn thành thông minh'. Những đầu vào này có thể là mã hiện có và nhận xét, và các mô hình sẽ tạo ra mã phù hợp có tính xác suất cao. Điều này đặt ra một khả năng thú vị: nếu (a) các dòng mã lỗi là thiểu số trong những dòng có mặt, và (b) phần lớn mã phù hợp với ý định của tác giả, liệu có khả thi khi sử dụng LLM để đo lường xem một dòng mã nhất định có phải là ngoại lệ? Nếu vậy, đây là một dấu hiệu mạnh mẽ cho thấy dòng đó bất thường và có khả năng bị lỗi.

Sử dụng trực giác này, chúng tôi đề xuất một cách tiếp cận mới trong đó chúng tôi sử dụng LLM để tạo ra các dòng mã thay thế với mã hiện có và nhận xét; những thay thế này được so sánh với mã của nhà phát triển để xác định các khác biệt tiềm ẩn. Nghiên cứu gần đây đã thúc đẩy việc khám phá LLM, cả về mặt tác động của chúng đến bảo mật (ví dụ: trong việc giới thiệu lỗ hổng [26] và các nghiên cứu người dùng [33]) và việc sử dụng chúng để cải thiện bảo mật (ví dụ: sửa chữa lỗi [27]). Công việc này cung cấp những hiểu biết bổ sung về việc liệu LLM có thể được sử dụng để giúp xác định lỗi cả dưới dạng lỗ hổng bảo mật và thiếu sót chức năng. Những đóng góp của chúng tôi như sau.

• Chúng tôi đề xuất FLAG, một khung cho việc sử dụng mới của LLM trong phát hiện lỗi bằng cách so sánh mã gốc với mã được tạo bởi LLM. Chi tiết của các kỹ thuật được sử dụng trong công cụ được đề cập trong Phần 3.

• Chúng tôi khám phá các tính năng của mã nguồn và thông tin từ LLM để phân loại mã như có lỗi hay không. Hiệu quả của những tính năng này được phân tích bằng cách thực hiện các thí nghiệm cho các LLM chính trong các chế độ khác nhau trên nhiều ngôn ngữ trong Phần 5, với thảo luận thêm trong Phần 6.

• Công cụ và kết quả được mã nguồn mở tại [32].

2 Nền tảng
Trong phần này, chúng tôi thảo luận về phát hiện lỗi, cách LLM hoạt động và thông tin có sẵn trong mã nguồn mà LLM có thể sử dụng. Điều này truyền đạt động lực tại sao FLAG cần thiết trước khi thảo luận chi tiết về việc thực hiện nó trong Phần 3.

2.1 Các Mô hình Ngôn ngữ Lớn (LLM)
LLM (bao gồm GPT-2 [30], GPT-3 [5], và Codex [7]) dựa trên kiến trúc Transformer [40]. Chúng có thể được coi là "các mô hình dự đoán chuỗi có thể mở rộng" [7] có khả năng thực hiện một loạt các nhiệm vụ từ vựng. Khi được cung cấp một lời nhắc bao gồm một chuỗi token, chúng tạo ra tập hợp token có khả năng cao nhất để tiếp tục hoặc hoàn thành chuỗi, tương tự như một tính năng tự động hoàn thành thông minh. Trong ngữ cảnh này, token đề cập đến các chuỗi phổ biến dài khoảng bốn ký tự và được gán một định danh duy nhất trong kích thước từ vựng do người dùng xác định. Mã hóa cặp byte (BPE) [15] này cho phép LLM xử lý một lượng lớn văn bản hơn trong cửa sổ đầu vào có kích thước cố định của chúng. Do đó, hầu hết LLM hoạt động trên token thay vì các ký tự riêng lẻ.

Một khi được đào tạo trên các ví dụ phù hợp, một LLM có thể được sử dụng để điền vào nội dung của một hàm dựa trên chữ ký và/hoặc nhận xét của nó [7]. Trong trường hợp các mô hình thương mại mà chúng tôi chọn điều tra, kho dữ liệu này được tạo thành từ hàng tỷ dòng mã nguồn mở được thu thập từ internet (ví dụ: GitHub).

LLM có kích thước và khả năng khác nhau. Trong công việc này, chúng tôi đánh giá 2 LLM của OpenAI, code-davinci-002 và gpt-3.5-turbo. code-davinci-002 là một mô hình Codex được tối ưu hóa cho các nhiệm vụ hoàn thành mã. Chúng tôi sử dụng nó trong hai chế độ hoàn thành, không có và có hậu tố, được gọi là tự động hoàn thành và chèn, tương ứng. gpt-3.5-turbo cải tiến GPT-3 và có thể hiểu cũng như tạo ra ngôn ngữ tự nhiên hoặc mã. Chúng tôi sử dụng nó trong hai chế độ, không có hướng dẫn nào hoặc với hướng dẫn tạo ra dòng mã tiếp theo, được gọi là tự động hoàn thành và hoàn thành có hướng dẫn tương ứng.

2.2 Vai trò của nhận xét
Nhận xét trong mã thường bị bỏ qua đối với phân tích mã tĩnh. Điều này là do chất lượng nhận xét rất khác nhau, và chúng không đóng vai trò trong chức năng thực tế của chương trình. Tuy nhiên, chúng là một nguồn tài liệu tốt cho hành vi dự định của chương trình [36]. Giống như con người sử dụng nhận xét để suy luận về mã, các công cụ như LLM cũng có cùng khả năng.

Một số nỗ lực đã sử dụng nhận xét trong nỗ lực phát hiện điểm yếu trong mã. Công việc liên quan nhất là icomment [37] sử dụng Xử lý Ngôn ngữ Tự nhiên để tự động phân tích nhận xét và phát hiện sự không nhất quán giữa nhận xét và mã nguồn. Họ lập luận rằng những sự không nhất quán này có thể chứa lỗi bởi vì nhận xét đúng nhưng việc thực hiện mã tương ứng sai. Mặt khác, mã có thể đúng, nhưng nhận xét kém. icomment lấy nhận xét và tạo ra quy tắc cho mã nguồn để thông qua. Sự thất bại của những quy tắc này được báo cáo như sự không nhất quán.

Một công việc liên quan khác là @tComment [38] tập trung vào nhận xét Javadoc. Họ sử dụng cùng cái nhìn sâu sắc về sự không nhất quán nhận xét mã để lấy các tệp mã nguồn cho Java để suy ra thuộc tính cho các phương thức và sau đó tạo ra các kiểm tra ngẫu nhiên cho những phương thức này. Sự thất bại của những kiểm tra này được báo cáo như sự không nhất quán. FLAG lấy cái nhìn sâu sắc về sự không nhất quán nhận xét mã nhưng thay vì tạo ra quy tắc hoặc kiểm tra, tạo ra mã thay thế để so sánh với mã gốc. Hơn nữa, FLAG sử dụng mã trước đó cộng với nhận xét cho hoạt động của nó.

2.3 Phát hiện lỗi
Các bộ phát hiện tĩnh được sử dụng dưới nhiều hình thức khác nhau trong nhiều công ty phần mềm. Chúng thường được sử dụng trong giai đoạn phát triển trước khi triển khai để bắt lỗi trong mã. Error Prone của Google [29] bắt các lỗi lập trình phổ biến trong Java. Infer của Facebook [19] làm tương tự cho mã Java và C/C++/Objective C. Và các công cụ nổi tiếng khác bao gồm SpotBugs [35] và CodeQL [18]. Chúng thường hoạt động bằng cách tiến hành phân tích trên Cây Cú pháp Trừu tượng (AST) và/hoặc đồ thị luồng dữ liệu của mã [16]. Những cấu trúc này được duyệt qua với một bộ kiểm tra phức tạp được sử dụng để chỉ ra hành vi không đúng của mã ví dụ: CodeQL có thể được sử dụng để tạo ra một truy vấn kiểm tra xem có tồn tại đường dẫn giữa hai nút mà không nên như vậy. Hành vi không đúng này có thể là một mẫu trong AST hoặc một số luồng trong đồ thị luồng dữ liệu. Các bộ phát hiện cũng có thể suy ra quy tắc từ lịch sử phiên bản và nhận xét mã nguồn. Trong khi các bộ phát hiện tĩnh có thể tổng quát hóa trên các cơ sở dữ liệu của cùng ngôn ngữ, chúng yêu cầu tạo ra một bộ lớn các mẫu và luồng lỗi đã biết để phát hiện lỗi. Hơn nữa, chúng chỉ có thể tìm thấy lỗi trong cơ sở kiến thức hạn chế này về mẫu và luồng.

Kiểm tra đơn vị là phương pháp khác thường được sử dụng trong cuộc đấu tranh để xác định khiếm khuyết trong mã [14, 31]. Thách thức rõ ràng với kiểm tra đơn vị là yêu cầu nghiêm ngặt về kiến thức về chức năng của chương trình. Giải pháp được sử dụng là phát triển các kiểm tra đơn vị được tạo tự động. Phạm vi mã thông qua cách tiếp cận này vẫn hạn chế, và ngay cả khi có phạm vi, các lỗi đôi khi không được tiết lộ [34]. Ngoài ra, kiểm tra đơn vị không đáp ứng việc khẳng định bảo mật của mã.

2.4 Các Bộ phát hiện dựa trên Học máy
Các nhà nghiên cứu đã sử dụng các kỹ thuật dựa trên mô hình ngôn ngữ để cố gắng phát hiện lỗi. Bugram [41] sử dụng các mô hình ngôn ngữ N-gram để có được các chuỗi cho token trong chương trình. Những chuỗi token này được khám phá theo xác suất của chúng trong mô hình đã học, và những cái có xác suất thấp hơn được đánh dấu là lỗi có thể. Hoppity [13] là một cách tiếp cận dựa trên học tập dựa vào các biến đổi đồ thị để phát hiện và sửa lỗi. Mô hình đồ thị của mã nguồn được sử dụng để thực hiện một loạt dự đoán về vị trí của các nút lỗi và các chỉnh sửa đồ thị tương ứng để tạo ra bản sửa. EnSpec [6] là một phương pháp sử dụng entropy mã (một số liệu được thiết kế để đại diện cho tính tự nhiên của mã bắt nguồn từ mô hình ngôn ngữ thống kê) để định vị lỗi. Họ sử dụng trực giác rằng mã lỗi có xu hướng cao hơn về entropy để tạo điều kiện định vị. Trong một công việc khác, các giải pháp lỗi và mô hình ngôn ngữ dựa trên mạng bộ nhớ ngắn hạn dài (LSTM) được sử dụng để phát hiện lỗi [39]. Các nhà nghiên cứu của công việc này đã đào tạo mô hình của họ trên Aizu Online Judge (AOJ) [3], chứa nhiều triệu dòng mã nguồn.

Gần đây hơn, LLM đã được khám phá cho mục đích này. Sự khác biệt giữa LLM và các mô hình ngôn ngữ khác là kích thước dữ liệu huấn luyện và độ phức tạp của mạng. FuzzGPT [11] sử dụng LLM như các fuzzer trường hợp cạnh bằng cách chuẩn bị LLM để tạo ra các chương trình bất thường cho fuzzing. Đầu tiên, họ cho phép LLM học trực tiếp từ các lỗi được báo cáo trong lịch sử và sau đó tạo ra các đoạn mã kích hoạt lỗi tương tự để tìm lỗi mới. Họ sử dụng các mô hình Codex và CodeGen để phát hiện lỗi trong các thư viện DL phổ biến PyTorch và TensorFlow. Trong một công việc khác, Li et al. [21] cho thấy cách ChatGPT có thể được sử dụng thông qua lời nhắc khác biệt để phát hiện lỗi trong cơ sở dữ liệu Quixbugs [22]. Điều này bao gồm việc tạo ra các thiết kế tham chiếu cho một vấn đề sử dụng ChatGPT. Đối với một đầu vào kiểm tra nhất định, nếu các thiết kế tham chiếu tạo ra cùng một đầu ra, nhưng phiên bản lỗi tạo ra một đầu ra khác, trường hợp kiểm tra được xác định là trường hợp kiểm tra gây ra lỗi. DeepBugs [28] sử dụng các yếu tố ngôn ngữ tự nhiên trong mã để thực hiện công cụ phát hiện lỗi học máy dựa trên tên. Ý tưởng chính là chuyển đổi tên hàm và định danh thành embedding được học bởi mạng để bảo toàn thông tin ngữ nghĩa. Họ áp dụng cách tiếp cận của mình vào một kho các tệp JavaScript. Trong khi những nỗ lực này là một bước tiến trong việc sử dụng LLM để phát hiện lỗi, chúng hoặc nhắm mục tiêu một tập hợp con thích hợp của mã hoặc yêu cầu thông tin như trường hợp kiểm tra cho một chương trình. Khả năng của LLM để sửa lỗi không được đánh giá theo cách có thể tổng quát hóa, tức là sử dụng không có thông tin hoặc kiến thức bên ngoài mã nguồn.

2.5 Tại sao FLAG?
Những hạn chế được đề cập cho các bộ phát hiện tĩnh và bộ phát hiện học máy để lại chỗ cho một công cụ không yêu cầu nỗ lực lớn để thiết lập quy tắc bảo mật và kiểm tra và có thể áp dụng trên nhiều ngôn ngữ lập trình. Thông qua các thí nghiệm khác nhau của chúng tôi, chúng tôi đã chứng minh rằng cách tiếp cận kiểm tra của chúng tôi không phụ thuộc vào ngôn ngữ mã. Những hiểu biết của chúng tôi có thể được sử dụng để tận dụng các LLM có sẵn hoạt động trên nhiều ngôn ngữ để cung cấp phản hồi mã. FLAG cũng không yêu cầu mã được biên dịch hoặc thậm chí chính xác về cú pháp, cho phép nó hoạt động trên mã không hoàn chỉnh. Điều này cho phép kiểm tra lỗ hổng ở giai đoạn thiết kế sớm hơn khi so sánh với các bộ kiểm tra tĩnh truyền thống. Ngoài ra, FLAG không yêu cầu tạo ra quy tắc bảo mật và kiểm tra. Đây là một điểm cộng lớn bởi vì kiểm tra bảo mật về bản chất không đầy đủ và yêu cầu rất nhiều thời gian và chuyên môn lĩnh vực để thiết kế. Điều này đặc biệt đúng đối với phần cứng nơi các công cụ chính thức đã được chứng minh thất bại trong việc phát hiện nhiều lỗi bảo mật RTL [12].

3 Cách tiếp cận FLAG
Bộ kiểm tra tính nhất quán FLAG dựa vào khả năng độc đáo của LLM để viết mã. Nó có cách tiếp cận được hiển thị trong Hình 1. Đối với mỗi dòng trong mã nguồn, FLAG tạo ra một lời nhắc tương ứng bao gồm phần mã trước dòng (tiền tố) và tùy chọn, mã sau dòng mã (hậu tố). Lời nhắc bao gồm mã và nhận xét là đầu vào cho LLM xuất ra một dòng mã hoặc nhận xét duy nhất. Dòng được tạo này được so sánh với dòng gốc để tạo ra các tính năng được sử dụng trong phân loại dòng gốc như có lỗi hay không. Những tính năng này cung cấp hoặc là ước tính định lượng về sự khác biệt giữa hai dòng hoặc mức độ tin cậy của dòng được tạo bởi LLM. Chúng được thảo luận trong Phần 3.3. Các dòng được phân loại là có thể có lỗi được đánh dấu cho nhà thiết kế. Luồng FLAG cho một dòng nhất định có quy trình 4 bước: tạo lời nhắc, tạo dòng, trích xuất tính năng, và phân loại.

Để bắt đầu kiểm tra tính nhất quán trên một tệp, chúng tôi phải đưa FLAG một dòng để bắt đầu kiểm tra. Điều này được thực hiện để cung cấp cho LLM đủ ngữ cảnh để bắt đầu tạo ra mã và nhận xét liên quan. Thông thường, chúng tôi đưa số dòng bắt đầu sau các định nghĩa header, nhận xét ban đầu, và khai báo của các module và tín hiệu nội bộ. Trong một số trường hợp, khi khiếm khuyết là một phần của các tín hiệu được khai báo, chúng tôi đưa ra ngoại lệ để bắt đầu từ đầu tệp. Ngoài ra, tệp được tiền xử lý để bỏ qua các dòng trống và xác định nếu một nhận xét có mặt trước dòng để bắt đầu kiểm tra.

3.1 Tạo Lời nhắc
Tạo lời nhắc lấy mã nguồn và dòng cần được phân loại làm đầu vào và tạo ra lời nhắc làm đầu ra. Lời nhắc này được gửi đến LLM để tạo dòng. Một ví dụ được hiển thị trong Hình 2a. Tệp được hiển thị từ nguồn C1 cho khiếm khuyết chứa CWE-125. Lời nhắc được tạo cho dòng 12 bao gồm tiền tố bao phủ dòng 1-11 và hậu tố bao phủ dòng 13-15. Quá trình này được lặp lại cho từng dòng trong tệp. Khi bộ kiểm tra FLAG tiến hành từng dòng, tiền tố tăng lên trong khi hậu tố giảm xuống.

Chúng tôi giới hạn độ dài tiền tố và hậu tố tối đa 50 dòng để duy trì trong giới hạn token của LLM. Lời nhắc được điều chỉnh để gợi ra phản hồi tốt hơn từ LLM ví dụ: nếu LLM tạo ra một nhận xét khi nó nên tạo ra mã, chúng tôi thêm một vài ký tự đầu của dòng mã gốc vào tiền tố. Quá trình này có thể được lặp lại nhiều lần cho đến khi có được phản hồi hợp lệ và yêu cầu phản hồi từ việc tạo dòng. Đây là lý do tại sao nó được thảo luận trong Phần 3.2.

3.2 Tạo Dòng
Tạo dòng lấy lời nhắc làm đầu vào và xuất ra một dòng mã hoặc nhận xét được tạo bởi LLM. Ví dụ, dòng được tạo cho lời nhắc trong Hình 2a được hiển thị trong Hình 2b. Trong trường hợp này, phản hồi của LLM khác với dòng mã gốc. Nó được đánh dấu để kiểm tra, tiết lộ rằng dòng mã gốc chứa khiếm khuyết bảo mật CWE-125, tức là đọc ngoài giới hạn. LLM được sử dụng cho ví dụ này là gpt-3.5-turbo ở chế độ tự động hoàn thành. Chi tiết các thí nghiệm trong Phần 5.

LLM được hướng dẫn để tạo ra đầu ra hợp lý bởi vì đôi khi LLM có thể trả về dòng trống hoặc trả về nhận xét thay vì mã. Quá trình này được mô tả trong Thuật toán 1. orig_lines là một danh sách các dòng trong tệp gốc. Giả sử rằng danh sách được lập chỉ mục bắt đầu từ 1. loc là số dòng mà chúng tôi muốn LLM tạo ra. num_lines là tổng số dòng trong tệp gốc (sau khi được tiền xử lý). Chúng tôi khởi tạo tiền tố và hậu tố như các chuỗi trống và sử dụng max_pre_len và max_suf_len như giới hạn của kích thước của chúng, tương ứng. Điều này được thực hiện như một nỗ lực để giữ kích thước token của lời nhắc hợp lý. Đối với các thí nghiệm của chúng tôi, chúng tôi đặt giới hạn là 50. Việc gán nội dung phù hợp từ tệp gốc cho tiền tố và hậu tố được hiển thị trong dòng 2-7. Để khắc phục đầu ra thỉnh thoảng không sử dụng được, chúng tôi nhắc LLM tạo ra phản hồi lại, tối đa max_attempts lần. Điều này được hiển thị trong khối Try và Catch ở dòng 15-19. Dòng 17 và 19 tăng số lần thử và trở lại đầu khối Try ở dòng 10. Ở lần thử đầu tiên, LLM được nhắc tạo ra phản hồi với tiền tố và hậu tố đã cho. Ở lần thử thứ hai và thứ ba, chúng tôi cung cấp hỗ trợ để gợi ra phản hồi không trống. Điều này được thực hiện bằng cách thêm 5 ký tự đầu của dòng mà LLM đang cố gắng tạo ra vào tiền tố. Hỗ trợ này được hiển thị ở dòng 12. Nếu có bất kỳ lỗi nào trong khối try, lỗi được ghi chú ở dòng 14 trước khi trở lại dòng 10. Nếu không có lỗi và các điều kiện ở dòng 16 và 18 không đúng, dòng 20 được thực thi. Điều này khẳng định tín hiệu rằng một dòng đã được tạo ra thành công và vòng lặp while được thoát. Đối với tất cả hoàn thành, chúng tôi sử dụng nhiệt độ 0, giới hạn max_token là 150, giá trị top_p là 1, và ký tự cuối dòng như token dừng.

3.3 Trích xuất Tính năng
Trích xuất tính năng lấy các dòng mã gốc và lỗi làm đầu vào và xuất ra các tính năng. Đây là các giá trị định lượng được sử dụng để phân loại dòng gốc như có thể có lỗi hay không. Chúng đại diện cho sự khác biệt giữa hai dòng hoặc độ tin cậy của mã được tạo.

3.3.1 Tính năng
Khoảng cách Levenshtein (ld) là khoảng cách chỉnh sửa giữa hai chuỗi. Nó xem xét ba hoạt động: thêm, xóa, và thay thế. Tổng số hoạt động cần thiết để chuyển đổi một chuỗi sang chuỗi khác là Khoảng cách Levenshtein. Một trận đấu hoàn hảo dẫn đến điểm số 0. Chúng tôi sử dụng ld để so sánh các dòng mã. Vì mục tiêu là đánh dấu khiếm khuyết trong mã, chúng tôi sử dụng ld như tiêu chí chính để xác định khiếm khuyết.

BLEU tức là Bilingual Evaluation Understudy Score [25], là một số liệu để đánh giá câu ứng cử viên đến câu tham chiếu. Một trận đấu hoàn hảo dẫn đến điểm số 1.0, trong khi một sự không khớp hoàn hảo dẫn đến điểm số 0.0. Chúng tôi sử dụng nó để so sánh nhận xét vì chúng giống như ngôn ngữ tự nhiên. Chúng tôi thu thập điểm BLEU-1 đến BLEU-4 tích lũy nhưng thấy rằng chỉ BLEU-1 tạo ra con số có ý nghĩa. BLEU-2, BLEU-3 và BLEU-4 có số lượng rất nhỏ, không hữu ích. Đối với phần còn lại của bài báo này, BLEU đề cập đến BLEU-1.

Khoảng cách từ nhận xét (dfc) chỉ ra một dòng mã cách nhận xét gần nhất trước nó bao xa. Nếu dòng cũng chứa nhận xét, dfc có giá trị 0. Nếu không có nhận xét trước dòng, dfc không có giá trị. Chúng tôi chỉ xem xét các nhận xét trước mã như liên quan đến mã vì đó thường là cách mã được viết.

logprob trong ngữ cảnh tạo mã bởi LLM là log của xác suất của token được tạo. Nếu một token có nhiều khả năng được tạo ra, nó sẽ có logprob cao hơn với giá trị tối đa có thể là 0. Nếu một token ít có khả năng được tạo ra, nó sẽ có logprob thấp hơn, tức là giá trị âm với độ lớn cao hơn. LLM có xu hướng "chọn" token có xác suất cao hơn. Đối với một dòng được tạo, chúng tôi lấy trung bình của logprob của các token được tạo, mà chúng tôi gọi là logprob từ đây. logprob gần 0 cho thấy độ tin cậy cao hơn trong việc tạo ra, trong khi giá trị âm hơn cho thấy độ tin cậy thấp hơn.

3.3.2 Trích xuất
Để có được các giá trị tính năng này, các dòng gốc và được tạo được loại bỏ để loại bỏ khoảng trắng cuối. Nếu một trong các dòng là sự kết hợp của mã và nhận xét, mã và nhận xét được tách ra để so sánh. Mã của dòng gốc được so sánh với mã của dòng được tạo để tính toán ld. Nhận xét của dòng gốc được so sánh với nhận xét của dòng được tạo để tạo ra số liệu BLEU. Ngoài ra, nếu dòng gốc là nhận xét, vị trí của nhận xét trước đó gần nhất được cập nhật thành dòng hiện tại, và dfc được tính toán. Các dòng được tạo và tính năng thu được, ví dụ trong Hình 2, được hiển thị trong Bảng 1. Đối với ví dụ được hiển thị, LLM gpt-3.5-turbo được sử dụng ở chế độ tự động hoàn thành. Không thể thu được các giá trị logprob cho gpt-3.5-turbo thông qua API công cộng nên những giá trị đó không được hiển thị. Các giá trị logprob có sẵn cho các thí nghiệm với code-davinci-002.

3.4 Phân loại
Phân loại cho một tệp nhất định lấy các tính năng làm đầu vào và chọn các dòng để đánh dấu dựa trên một số điều kiện. Những điều kiện này được gọi là tiêu chí, và các dòng được đánh dấu được gọi là reported_lines. Các điều kiện có thể là bao gồm hoặc loại trừ. Các điều kiện bao gồm được thiết kế để đưa các dòng vào tập hợp reported_lines. Các điều kiện loại trừ được sử dụng để loại bỏ các dòng khỏi reported_lines. Các điều kiện bao gồm sử dụng hai ngưỡng trong khung FLAG của chúng tôi, tức là Giới hạn Trên Khoảng cách Levenshtein (ld_limit) và Giới hạn Trên Khoảng cách từ Nhận xét (dfc_limit). Những ngưỡng này được chọn vì các lý do chi tiết dưới đây. ld_limit và dfc_limit hoạt động cùng nhau để tạo ra các tiêu chí khác nhau.

Tại sao ld_limit? ld cho thấy sự khác biệt giữa hai đoạn mã. Nếu ld là 0, các đoạn mã giống hệt nhau. Điều này có nghĩa là LLM không có gợi ý thay thế, vì vậy không có lý do gì để đánh dấu mã này. Nếu ld lớn hơn 0, các đoạn mã khác nhau, cho thấy LLM đang chỉ ra một thay thế cho dòng mã gốc. Điều này có thể xứng đáng được đánh dấu. Nhưng nếu ld là một con số rất cao, nó có thể cho thấy LLM đang tạo ra thứ gì đó hoàn toàn khác. Dựa trên hiểu biết rằng phiên bản lỗi của mã thường rất giống với phiên bản được sửa, chúng tôi sử dụng giới hạn trên cho ld để nhắm mục tiêu mã được tạo khác nhau nhưng không quá khác.

Tại sao dfc_limit? dfc cho thấy một dòng mã cách nhận xét gần nhất trước nó bao xa. Nếu có nhận xét gần mã, tức là dfc có giá trị thấp, chúng tôi giả định rằng LLM sẽ tạo ra mã với thông tin liên quan, vì vậy chúng tôi tin tưởng nó nhiều hơn. Nếu dfc lớn hơn dfc_limit, nhận xét có thể không liên quan đến dòng mã, và chúng tôi loại bỏ nó. Việc sử dụng dfc làm giảm tiêu chí của chúng tôi để chọn các dòng để đánh dấu vì một dòng mã có ld lớn hơn ld_limit vẫn có thể được đánh dấu nếu nó có dfc nhỏ hơn dfc_limit.

Một tiêu chí đơn giản C0 sử dụng ld_limit như ngưỡng của nó.
C0(ld_limit): 0<ld<=ld_limit

Một tiêu chí phức tạp hơn C1 sử dụng cả hai ngưỡng,
C1(ld_limit,dfc_limit):
0<ld AND (ld<=ld_limit OR 0<dfc<dfc_limit)

Tiêu chí cuối cùng C2 sử dụng cả hai ngưỡng và sử dụng hàm reduce_fp() để loại bỏ dương tính giả.
C2(ld_limit,dfc_limit):
0<ld AND (ld<=ld_limit OR 0<dfc<dfc_limit)
AND reduce_fp()

Tác dụng phụ của việc phát hiện khiếm khuyết là một số lượng đáng kể dương tính giả trong reported_lines. Chúng tôi giải quyết điều này bằng cách áp dụng một vài biện pháp trong reduce_fp(). Quá trình kiểm tra reported_lines để loại bỏ một số dòng được đánh dấu có thể là dương tính giả. Biện pháp đầu tiên là tính toán lại ld sau khi loại bỏ khoảng trắng trong các dòng được tạo và gốc. Điều này loại bỏ dương tính giả nơi ld đếm khoảng trắng, ví dụ: always(@posedge clk) và always (@posedge clk). Thứ hai là kiểm tra xem dòng gốc chỉ có từ khóa. Nếu đây là trường hợp, dòng đó được loại bỏ khỏi reported_lines vì một từ khóa đơn giản không thể có lỗi. Thứ ba sử dụng các giá trị logprob như ngưỡng để loại trừ. Nếu LLM có giá trị logprob âm lớn cho dòng được tạo, nó được loại bỏ khỏi reported_lines vì nó cho thấy LLM không tin tưởng vào gợi ý của nó. Chúng tôi sử dụng ngưỡng <−0.5 cho các thí nghiệm của chúng tôi với code-davinci-002 để loại bỏ các dòng. Phân loại của ví dụ được hiển thị trong Hình 2 sử dụng C2(20,10) được hiển thị trong cột Flagged? của Bảng 1. Trong số 2 dòng được đánh dấu, một dòng chứa khiếm khuyết gốc (được tô màu hồng), trong khi dòng kia là dương tính giả.

4 Tập dữ liệu Điểm chuẩn
Để đánh giá tính khả thi của việc sử dụng LLM để đánh dấu các sự không nhất quán trong nhận xét hoặc mã, chúng tôi thí nghiệm trên một tập hợp các khiếm khuyết ví dụ trong C, Python, và Verilog từ nhiều nguồn khác nhau, được tóm tắt trong Bảng 2. Chúng tôi thu thập cả khiếm khuyết liên quan đến bảo mật và chức năng. Nguồn C1, P1, và V1 bao gồm các khiếm khuyết bảo mật, trong khi nguồn C2, P2, và V2 có các khiếm khuyết gây ra vấn đề chức năng. Một số khiếm khuyết liên quan đến bảo mật được mô tả trong Bảng 3, và các khiếm khuyết bảo mật và chức năng còn lại được mô tả trong Phụ lục A. 19 trong số 35 khiếm khuyết bảo mật có điểm yếu có mặt trong danh sách top 25 CWE của MITRE. Common Weakness Enumerations (CWE) là các danh mục vấn đề bảo mật có thể biểu hiện trong mã [9]. Mỗi khiếm khuyết có một tệp mã nguồn và số dòng tương ứng chứa khiếm khuyết. Chúng tôi thu thập 121 khiếm khuyết; 43 cho C, 34 cho Python, và 44 cho Verilog.

4.1 Nguồn C
C1 chứa các lỗ hổng bảo mật được tuyển chọn bởi các tác giả của [26, 27]. Chúng tôi chọn 12 CVE thực tế và 5 trường hợp CWE được điều tra trong những công việc đó. Common Vulnerabilities and Exposures (CVE) là một thuật ngữ phân loại lỗ hổng. Một lỗ hổng cụ thể trong thế giới thực được ghi chép và được đưa ra một định danh. Chúng tôi điều tra cve-2018-19664, cve-2012-2806, cve-2016-5321, cve-2014-8128, cve-2014-8128, cve-2016-10094, cve-2017-7601, cve-2016-3623, cve-2017-7595, cve-2016-1838, cve-2012-5134 và cve-2017-5969. Chi tiết của mỗi CVE có thể được lấy từ Cơ sở dữ liệu Lỗ hổng Quốc gia NIST [10]. Đối với CWE, chúng tôi bao gồm cwe-119 và cwe-125, được lấy cảm hứng từ các ví dụ MITRE, và cwe-416, cwe-476, cwe-732, lấy từ các ví dụ CodeQL.

C2 chứa các khiếm khuyết trong các bài tập được nộp bởi sinh viên [43]. Có 74 bài tập độc đáo trải rộng trong 10 tuần. Chúng tôi chọn 30 trong số những bài tập này với các chủ đề bao gồm Biểu thức Đơn giản, Vòng lặp, Mảng Số nguyên, Mảng Ký tự (Chuỗi) và Hàm, Mảng Đa chiều, Đệ quy, Con trỏ, Thuật toán (sắp xếp, hoán vị, puzzle), và Cấu trúc (Kiểu dữ liệu do Người dùng Định nghĩa). Đối với mỗi bài tập được chọn, chúng tôi chọn một bài nộp của sinh viên có lỗi có thể xác định rõ ràng. Điều này được thực hiện bằng cách so sánh phiên bản lỗi với phiên bản đúng trong kho lưu trữ được đăng bởi các tác giả của công việc. Mỗi bài tập độc đáo cũng chứa phiên bản đúng của mã với nhận xét ở đầu mô tả chức năng dự định của mã. Chúng tôi sử dụng những nhận xét này và thêm chúng như tiền tố vào các tệp mã nguồn liên quan mà chúng tôi phân tích.

4.2 Nguồn Python
P1 sử dụng công việc của các tác giả để sử dụng Github Copilot để hoàn thành mã dựa trên các kịch bản được phát triển cho các CWE chọn lọc [26, 27]. Chúng tôi xem xét các hoàn thành được đánh dấu là chứa điểm yếu bởi các tác giả và chọn một cho mỗi CWE cho công việc của chúng tôi. Chúng tôi bao gồm cwe-79, cwe-20, cwe-22, cwe-78, cwe-89, cwe-200, cwe-306, cwe-434, cwe-502, cwe-522, cwe-732 và cwe-798.

P2 có các khiếm khuyết được ghi chú trong các dự án Python thực tế bằng cách phân tích lịch sử kiểm soát phiên bản của chúng [42]. Điều này được thực hiện bằng cách xác định các cam kết trên Github có ý định sửa lỗi. Chúng tôi chọn một hoặc hai lỗi được xác định trong các dự án youtube-dl, tqdm, fastapi, luigi, scrapy, black, nvbn, spacy, keras, pysnooper, cookiecutter và ansible. Các khiếm khuyết bao gồm một loạt các nguyên nhân, bao gồm biểu thức regex sai, các đối tượng được trả về không đúng, token phân tách không đúng được sử dụng, gán không đúng, giá trị tham số không đúng, lệnh os không đúng, đối số hàm không đúng, tính toán không đúng, điều kiện lỗi sai, mã hóa tệp bị thiếu, phần tử được thêm vào danh sách không đúng, đường dẫn tệp không đúng trong lệnh os và các nguyên nhân khác. Đối với mỗi khiếm khuyết này, chúng tôi cô lập tệp mã nguồn chứa lỗi và vị trí của nó bằng cách phân tích tệp bug_patch.txt cho lỗi.

4.3 Nguồn Verilog
V1 chứa các khiếm khuyết dưới dạng lỗ hổng bảo mật được thu thập bởi các tác giả từ 3 nguồn [1]. Nguồn đầu tiên là CWE phần cứng của MITRE, từ đó họ thiết kế 4 module với CWE có mặt (một thanh ghi khóa, logic reset cho thanh ghi, bộ kiểm tra truy cập, và ngoại vi TrustZone). Nguồn thứ hai là OpenTitan SoC [23], nơi các tác giả chèn lỗi vào RTL của 3 module (ROM Controller, One Time Programmable Memory Controller, và interface cho KMAC Key Manager). Nguồn thứ ba là các lỗi trong Hack@DAC 2021 SoC [17] sử dụng lõi Ariane với các lỗi có mặt cho cuộc thi săn lỗi. Các lỗi nằm trong Control and Status Register Regfile, Direct Memory Access, và các module AES interface.

V2 chứa các khiếm khuyết chức năng trong 11 dự án Verilog [2]. Chúng bao gồm bộ giải mã 3-to-8, bộ đếm 4-bit với tràn, t-flip flop, máy trạng thái hữu hạn, thanh ghi dịch trái 8-bit, bộ ghép kênh 4-to-1, i2c bus nối tiếp hai chiều, hàm hash mật mã sha3, lõi cho thuật toán ghép đôi Tate cho đường cong elliptic, Lõi cho sửa lỗi Reed Solomon và bộ điều khiển SDRAM. Các khiếm khuyết bao gồm lỗi số, danh sách độ nhạy không đúng, gán không đúng, reset không đúng, gán chặn thay vì không chặn, tăng bộ đếm sai và bỏ qua kiểm tra tràn bộ đệm.

5 Thí nghiệm và Kết quả
Để đánh giá cách tiếp cận kiểm tra tính nhất quán FLAG, chúng tôi thiết kế các thí nghiệm sử dụng 2 LLM của OpenAI. LLM đầu tiên là code-davinci-002 được tối ưu hóa cho các nhiệm vụ hoàn thành mã. Đối với code-davinci-002, không có lời nhắc hệ thống, nhưng nó hỗ trợ khả năng chèn nếu hậu tố được đưa ra thêm vào tiền tố. Chúng tôi chạy 2 thí nghiệm với code-davinci-002, ở chế độ tự động hoàn thành (không có hậu tố) và chèn (với hậu tố). LLM thứ hai là gpt-3.5-turbo. Nó cải thiện GPT-3 và có thể hiểu và tạo ra ngôn ngữ tự nhiên hoặc mã. Vào thời điểm bản thảo này, nó là "mô hình GPT-3.5 có khả năng nhất". Đây là một mô hình hướng dẫn có vai trò được suy ra dựa trên lời nhắc hệ thống được đưa ra. Sau khi lời nhắc hệ thống được đưa ra, mô hình sau đó được đưa ra thông điệp chỉ định nhiệm vụ. Chúng tôi tiến hành hai thí nghiệm với gpt-3.5-turbo. Thí nghiệm đầu tiên được thực hiện mà không có bất kỳ lời nhắc hệ thống nào. Chúng tôi gọi chế độ này là tự động hoàn thành. Thí nghiệm thứ hai đưa ra lời nhắc hệ thống sau: "Bạn là một trợ lý lập trình AI có kỹ năng. Hoàn thành dòng mã tiếp theo." Chế độ này là hoàn thành có hướng dẫn.

Một thí nghiệm bao gồm việc chọn một bộ LLM và chế độ cụ thể, ví dụ: code-davinci-002 ở chế độ chèn, và sử dụng nó để thực hiện cách tiếp cận kiểm tra tính nhất quán của chúng tôi trên tất cả 121 điểm chuẩn. Tổng cộng, chúng tôi chạy 4 thí nghiệm cho các kết hợp có thể có của 2 LLM và 2 chế độ hoàn thành của chúng.

Để đánh giá sự thành công của một thí nghiệm, chúng tôi tập trung vào 3 số liệu. Đầu tiên là Số lượng khiếm khuyết được phát hiện (DD). Đối với một tập hợp đầu vào nhất định, DD là tổng số khiếm khuyết đã được xác định chính xác. Nó thực chất là True Positives (TP) và có giá trị tối đa có thể là 121, tức là tổng số khiếm khuyết trên tất cả nguồn. Thứ hai là Tỷ lệ Dương tính Giả (FPR). Đối với một tập hợp đầu vào nhất định, FPR là tỷ lệ giữa số lượng dòng được làm nổi bật không chính xác và tổng số dòng. Thứ ba là Tỷ lệ Dương tính Thực (TPR) hoặc Recall tức là tỷ lệ giữa dương tính thực và tổng số dương tính. Đây là DD/tổng số khiếm khuyết.

5.1 Kết quả
Kết quả được trình bày trong Bảng 4. Chúng tôi chia nhỏ kết quả cho mỗi thí nghiệm theo nguồn và tiêu chí để trình bày một cái nhìn chi tiết. Đối với C, chúng tôi chia nhỏ C1 thành C1-CVE và C1-CWE vì sự khác biệt về kích thước và kết quả của chúng bằng bộ kiểm tra FLAG. Bằng cách hiển thị ảnh chụp nhanh của các tiêu chí khác nhau, chúng tôi minh họa cách kết quả thay đổi dựa trên độ phức tạp. Cuối cùng, chúng tôi đề xuất tiêu chí 2 vì nó cân bằng TPR và FPR và sử dụng các tính năng bao gồm và loại trừ từ Phần 3.3.1.

gpt-3.5-turbo có khả năng phát hiện khiếm khuyết tốt hơn, nhưng code-davinci-002 có ít dương tính giả hơn. Đối với tiêu chí 2, gpt-3.5-turbo hoạt động tốt hơn code-davinci-002 về mặt TPR. Nó có thể phát hiện 90 khiếm khuyết ở chế độ tự động hoàn thành và 77 ở chế độ chèn có hướng dẫn, trong khi code-davinci-002 phát hiện 76 ở chế độ tự động hoàn thành và 78 ở chế độ chèn. code-davinci-002 hoạt động tốt hơn về mặt FPR. Nó có FPR thấp hơn là 0.121 ở chế độ tự động hoàn thành và 0.141 ở chế độ chèn so với 0.172 và 0.181 cho gpt-3.5-turbo ở chế độ hoàn thành có hướng dẫn và tự động hoàn thành, tương ứng. Các tiêu chí lấy giá trị cụ thể cho ld_limit và dfc_limit. Điều này không cần thiết phải như vậy vì chúng có thể lấy một loạt giá trị có thể tác động đến kết quả. Chúng tôi thảo luận những mối quan hệ này và hiểu biết về bản chất của dương tính thực và dương tính giả trong Phần 5.3.

5.2 Đi sâu vào Lỗi Bảo mật
Vì chúng tôi quan tâm đến các ứng dụng bảo mật của FLAG, chúng tôi chia nhỏ việc phát hiện lỗi bảo mật trong Hình 3. Việc chia nhỏ cho các khiếm khuyết chức năng được hiển thị trong Phụ lục A. 16 trong số 35 lỗi bảo mật được phát hiện bởi cả hai LLM ở cả hai chế độ, và 29 được phát hiện bởi ít nhất một LLM ở một chế độ. gpt-3.5-turbo ở chế độ tự động hoàn thành hoạt động tốt nhất, phát hiện 26 so với 22, 19 và 19 cho gpt-3.5-turbo ở chế độ hoàn thành có hướng dẫn, code-davinci-002 ở chế độ tự động hoàn thành và code-davinci-002 ở chế độ chèn tương ứng. Lỗi bảo mật Python là những lỗi được phát hiện tốt nhất bởi LLM. Tất cả khiếm khuyết cho Python đều được xác định. Nó được theo sau bởi Verilog và C, tương ứng. Một kiểm tra cẩn thận hơn cho phép chúng tôi phát triển một số hiểu biết về lý do tại sao điều này có thể xảy ra. Thứ nhất, kích thước của các tệp nguồn P1 nhỏ hơn so với các nguồn khác. Nó có kích thước tệp trung bình 17 dòng so với 1426 của C1 và 249 của V1. Ngoài ra, kích thước tệp nhỏ cho phép LLM lấy toàn bộ mã nguồn trước lỗi như một phần của lời nhắc, cung cấp cho nó ngữ cảnh hoàn chỉnh về chức năng dự định của các tệp. Thứ hai, các điểm chuẩn trong P1 được thiết kế đặc biệt bởi Pearce et al. [26, 27] để đánh giá bảo mật trong khi các điểm chuẩn trong V1 và C1 là sự kết hợp của những cái được thiết kế rõ ràng cho bảo mật và các ví dụ thực tế. 6 trong số các điểm chuẩn trong V1 từ mã trong các triển khai thực tế của SoC, và 8 điểm chuẩn trong C1 từ các CVE thực tế. Điều này cũng giải thích tại sao FLAG hoạt động kém trên C1-CVE, tức là C1-1 - C1-8.

Chúng tôi quan tâm đến việc so sánh hiệu suất của FLAG giữa lỗi chức năng và bảo mật. Dựa trên dữ liệu trong Hình 4, người ta có thể suy ra rằng FLAG phát hiện lỗi chức năng tốt hơn lỗi bảo mật. Xem xét kết quả tại C2(20,10), lỗi chức năng có TPR trung bình cao hơn là 0.689 so với lỗi bảo mật ở 0.676. Chúng cũng có FPR trung bình thấp hơn là 0.176 so với lỗi bảo mật ở 0.271. Một cái nhìn kỹ hơn tiết lộ rằng Python là một ngoại lệ với TPR cao hơn cho P1 so với P2. Đối với gpt-3.5-turbo, TPR cho P1 gấp đôi so với P2, cho thấy gpt-3.5-turbo hoạt động tốt trong việc phát hiện lỗi bảo mật trong Python. Chúng tôi loại trừ dữ liệu cho C1-CVE khỏi phân tích vì số lượng dòng cho những điểm chuẩn này nhiều lần lớn hơn so với các điểm khác, làm lệch trung bình về phía C1-CVE.

5.3 Phân tích Chi tiết
Làm thế nào việc tinh chỉnh tiêu chí từ C0 đến C2 tác động đến DD và FPR? Chuyển từ C0 sang C1, cả DD và FPR đều tăng. Điều này là do ld_limit được nới lỏng đáng kể từ 10 đến 20, và dfc_limit được sử dụng để bao gồm các dòng có thể vượt quá ld_limit. Trung bình, DD tăng từ 51 đến 84 trong khi FPR tăng từ 0.106 đến 0.18. Chuyển từ tiêu chí C1 sang C2, cả DD và FPR đều giảm. Điều này là do hàm reduce_fp() loại bỏ các dòng được làm nổi bật khỏi reported_lines. Một số dương tính giả đã được loại bỏ, nhưng một số dương tính thực cũng vậy. Trung bình, DD giảm từ 85 đến 80 trong khi FPR giảm từ 0.18 đến 0.154. Trong khi DD giảm 4.76%, FPR giảm 14.6%. Điều này biểu thị tầm quan trọng của reduce_fp() trong việc cải thiện hiệu suất kiểm tra tính nhất quán. Các xu hướng được hiển thị trong Hình 5.

Làm thế nào các chế độ hoàn thành khác nhau tác động đến DD và FPR? Theo bản năng, chúng ta có thể nghĩ rằng chế độ chèn nên làm tốt hơn chế độ tự động hoàn thành, vì LLM có quyền truy cập vào nhiều thông tin hơn dưới dạng hậu tố, ngoài tiền tố. Ngoài ra, việc hướng dẫn gpt-3.5-turbo tạo ra "dòng mã tiếp theo" ở chế độ hoàn thành có hướng dẫn nên hoạt động tốt hơn chế độ tự động hoàn thành vì khả năng tạo ra mã thay vì giải thích mã nên cao hơn. Hình 6 so sánh hiệu suất của các chế độ hoàn thành khác nhau tại C2(20,10). Đối với code-davinci, chế độ chèn cho phép chúng tôi phát hiện thêm 2 khiếm khuyết nhưng với chi phí tăng FPR 16.5%. Đây có lẽ không phải là sự cân bằng đủ có giá trị, có nghĩa là không có nhiều lợi ích từ việc sử dụng chế độ chèn. Đối với gpt-3.5-turbo, chế độ hoàn thành có hướng dẫn làm tệ hơn đáng kể so với đối tác tự động hoàn thành. Nó phát hiện ít hơn 13 khiếm khuyết trong khi chỉ giảm FPR 4.97%.

Làm thế nào ld_limit và dfc_limit tác động đến DD và FPR? Hai yếu tố quyết định chính của việc làm nổi bật các dòng trong cách tiếp cận kiểm tra của chúng tôi là ld_limit và dfc_limit. Vì chúng có thể lấy bất kỳ giá trị liên tục nào, có nhu cầu phân tích sâu hơn ngoài việc xem xét các giá trị cụ thể được thảo luận trong tiêu chí C0 đến C2. Chúng tôi tiến hành quét trên hai giới hạn cho mô hình code-davinci-002 ở chế độ tự động hoàn thành để xem tác động của chúng đến DD và FPR. Hình 7a và Hình 7b hiển thị cách DD và FPR thay đổi tương ứng tại các kết hợp khác nhau của ld_limit và dfc_limit trong khoảng từ 0 đến 30 cho ld_limit và 0 đến 50 cho dfc_limit. Chúng tôi quan sát thấy rằng ld_upper_limit chiếm ưu thế hơn nhiều trong việc tác động đến DD và FPR. Một thay đổi trong ld_upper_limit mang lại thay đổi lớn hơn trong cả DD và FPR so với thay đổi bằng nhau trong dfc_limit. Kết quả là, DD và FPR cũng bão hòa sớm hơn khi tăng ld_limit. DD bão hòa lỏng lẻo tại ld_limit 30 vì có tác động hạn chế của việc thay đổi dfc_limit tại giá trị đó. Tương tự, FPR bão hòa lỏng lẻo tại ld_limit 20. Những bản đồ nhiệt này là một phần, nhưng mở rộng chúng cho ld_limit =50 tiết lộ rằng các giá trị tối đa có thể cho DD và FPR là 90 và 0.14, tương ứng. Chúng tôi cũng quan sát thấy rằng DD và FPR nhạy cảm hơn ở các giá trị nhỏ hơn của ld_limit và dfc_limit. Chúng tôi có thể đạt được 80% giá trị tối đa của DD, tức là 72 tại ld_limit 15 và dfc_limit 10. Tương tự, chúng tôi có thể đạt được 80% giá trị tối đa của FPR tức là 0.11 tại ld_limit 15 và dfc_limit 25. Phân tích này giúp có được ước tính về các khoảng nào nên được xem xét khi thiết kế các công cụ tương tự.

Điều này có thể được khám phá thêm bằng cách phóng to các giá trị nhỏ hơn cho dfc_limit và mở rộng các giá trị cho ld_limit đến 100 như được hiển thị trong Hình 8. Đối với một dfc_limit cụ thể, khi chúng tôi tăng ld_limit, cả DD và FPR đều tăng. Trong khi tốc độ tăng cho cả hai giảm (được hiển thị bởi gradient giảm), có một điểm mà sau đó tốc độ tăng trong DD thấp hơn đáng kể so với FPR. Đây là điểm mà sau đó lợi ích của việc có được nhiều khiếm khuyết hơn sẽ bị áp đảo bởi chi phí tăng dương tính giả. Ngược lại, giá trị ld_limit nhỏ hơn nhiều sẽ đơn giản không tìm thấy đủ khiếm khuyết. Vùng được làm nổi bật trong Hình 8 chỉ ra các giá trị mà cách tiếp cận kiểm tra tính nhất quán cung cấp kết quả "tốt" tức là từ 10 đến 30. Một khám phá tương tự với việc giữ ld_limit không đổi và quét dfc_limit cung cấp những hiểu biết tương tự. Tuy nhiên, các giá trị cho DD và FPR không đủ khác biệt cho các giá trị khác nhau của ld_limit để biểu diễn đồ họa có thể minh họa.

Tự nhiên, có thể đặt câu hỏi về kết hợp tối ưu của ld_limit và dfc_limit là gì? Có bao nhiêu dương tính giả mà một người lập trình sẵn sàng chấp nhận để được lợi từ việc phát hiện nhiều lỗi hơn là vấn đề chủ quan. Chúng tôi minh họa sự cân bằng giữa TPR và FPR trong các bản đồ nhiệt. Một cách quyết định giới hạn nào sử dụng có thể là trước tiên xem xét số lượng dương tính giả bạn sẵn sàng chịu đựng. Ví dụ, nếu bạn sẵn sàng xem xét 7 dòng trong số 100 cho mỗi lỗi được phát hiện, tức là FPR 0.07, bạn có thể chọn (ld_limit,dfc_limit) là (5,10) như được hiển thị trong Hình 7b. Tại những giới hạn này, bạn sẽ có thể định vị 58 trong số 121 khiếm khuyết được bao phủ trong các điểm chuẩn của chúng tôi vì đó là giá trị tương ứng trong Hình 7a.

LLM tốt hơn bao nhiêu so với đoán ngẫu nhiên? Để minh họa sự thành công của kiểm tra tính nhất quán như một bộ phân loại, chúng tôi biểu diễn TPR và FPR dưới dạng đường cong Receiver Operating Characteristic (ROC) tại các ngưỡng khác nhau cho ld_limit. Chúng tôi sử dụng code-davinci002 ở chế độ tự động hoàn thành cho mục đích này. Trong các thí nghiệm của chúng tôi, chúng tôi đặt giới hạn thấp cứng cho ld là 0. Điều này có nghĩa là một số dòng có ld bằng không sẽ không bao giờ được tính là dương tính thực hoặc dương tính giả, dẫn đến đường cong ROC không hoàn chỉnh. Tình huống này được biểu diễn trong Hình 9a, nơi TPR và FPR bị giới hạn. Tuy nhiên, đường cong ROC nằm trên đường TPR==FPR cho thấy rằng phương pháp phân loại của chúng tôi tốt hơn so với phỏng đoán. Để hoàn chỉnh, nếu chúng tôi sử dụng giới hạn thấp ở -1 và giới hạn trên ở 1000, chúng tôi có thể có được TPR và FPR bằng 1 vì tất cả các dòng sẽ được làm nổi bật là chứa khiếm khuyết. Điều này được biểu diễn trong Hình 9b.

Lỗi của một ngôn ngữ có dễ phát hiện hơn những ngôn ngữ khác không? Dựa trên dữ liệu trong Hình 10, chúng tôi có thể kết luận rằng bộ kiểm tra tính nhất quán FLAG hoạt động tốt nhất trên C và tệ nhất trên Python. Mặc dù C có TPR thấp hơn một chút so với Verilog cho cả hai LLM, nó có FPR thấp hơn đáng kể. Trong khi TPR của nó thấp hơn 10.5%, FPR của nó ít hơn 48.4% so với Verilog. Python có TPR thấp nhất và chỉ FPR thấp thứ hai cho cả hai LLM. Điều này đáng ngạc nhiên vì chúng tôi mong đợi lượng lớn Python nguồn mở trong dữ liệu huấn luyện sẽ dịch thành hiệu suất tốt hơn so với Verilog. Điều này có lẽ là do 22 trong số các điểm chuẩn cho Python là các ví dụ thực tế so với chỉ 6 cho Verilog.

Nhận xét giúp ích như thế nào? Chúng tôi biểu thị vai trò của nhận xét bằng cách phân tích điểm dfc và BLEU cho dương tính thực và dương tính giả. dfc biểu thị sự gần gũi của một dòng với nhận xét, trong khi điểm BLEU biểu thị chất lượng nhận xét được tạo bởi LLM. Hình 11 hiển thị cách dfc khác nhau giữa dương tính thực và dương tính giả. Dữ liệu ở đây không bao gồm các trường hợp mà dfc không có sẵn, tức là khi không có nhận xét trước dòng liên quan. Hầu hết dữ liệu trong cả hai trường hợp nằm trong khoảng cho các giá trị nhỏ nhất của dfc. Điều này là do nhận xét được viết thường xuyên trong các điểm chuẩn mà chúng tôi nghiên cứu. dfc cho dương tính thực có trung bình thấp hơn là 18.4 so với dương tính giả ở 327.9. LLM làm tốt hơn trong phân loại khi dòng liên quan gần nhận xét hơn. dfc cho dương tính thực có độ lệch chuẩn nhỏ hơn nhiều là 47.7 so với dương tính giả ở 632.1. Do đó, dương tính giả bao phủ một khoảng giá trị lớn hơn nhiều.

Điểm dfc trung bình hoặc điểm bleu trung bình có tương quan với sự thành công của bộ kiểm tra không? Hình 12 hiển thị cách điểm BLEU của nhận xét trước đó khác nhau giữa dương tính thực và dương tính giả. Dữ liệu không bao gồm các dòng mà không có nhận xét trước dòng hoặc khi LLM không thể tạo ra nhận xét. Đối với một dòng mã được phân tích, FLAG theo dõi nhận xét gần nhất trước nó. FLAG so sánh nhận xét được tạo bởi LLM tại dòng này với nhận xét gốc để tính toán điểm BLEU của nhận xét trước đó. Giá trị cao cho thấy LLM đang đi đúng hướng theo ý định của người lập trình. Điểm BLEU của nhận xét trước đó cho dương tính thực có trung bình tương tự là 0.407 so với dương tính giả ở 0.473. Điều này cho thấy điểm BLEU của nhận xét trước đó không đóng vai trò quan trọng trong phân loại. Điểm BLEU của nhận xét trước đó cho dương tính thực có độ lệch chuẩn tương tự là 0.193 so với dương tính giả ở 0.236.

6 Thảo luận
Trong phần trước, chúng tôi khám phá xem có sự khác biệt đáng kể giữa dương tính thực và dương tính giả dựa trên thông tin như dfc hoặc điểm BLEU của nhận xét trước đó hay không. Phân tích này được thực hiện ở mức độ chi tiết của các dòng. Tuy nhiên, có chỗ cho phân tích như vậy ở mức độ chi tiết của tệp hoặc điểm chuẩn. Có mối quan hệ giữa các thuộc tính của tệp, như số lượng nhận xét, kích thước điểm chuẩn, v.v., với khả năng một khiếm khuyết được phát hiện cho điểm chuẩn đó không? Chúng tôi điều tra mối quan hệ này cho các thuộc tính sau của mỗi điểm chuẩn: ld trung bình, dfc trung bình, BLEU trung bình, logprob trung bình, số lượng nhận xét và số lượng dòng (kích thước). Kết quả được hiển thị trong Hình 13. Các biểu đồ hộp tiết lộ rằng dfc trung bình, số lượng nhận xét, và số lượng dòng có phân phối khác nhau đáng kể cho các điểm chuẩn nơi khiếm khuyết được phát hiện so với những điểm không được phát hiện. Dfc trung bình thấp hơn, số lượng nhận xét cao hơn, và số lượng dòng nhỏ hơn tăng khả năng khiếm khuyết được phát hiện. Tuy nhiên, ld trung bình, BLEU trung bình, và logprob trung bình không tạo ra sự khác biệt này.

FLAG dựa vào ý tưởng cơ bản rằng một dòng chứa khiếm khuyết có thể được viết theo cách khác bởi LLM tức là ld>0. Tuy nhiên, trong các thí nghiệm của chúng tôi, điều này không phải lúc nào cũng đúng. Có 11 điểm chuẩn mà ld bằng 0 cho cả hai LLM ở cả hai chế độ của chúng cho C2(20,10), vì LLM tạo ra chính xác cùng mã với mã gốc. 8 trong số chúng từ nguồn V2, 2 từ C1 và 1 từ P2. Do đó, LLM đôi khi tạo ra mã lỗi chức năng cho Verilog nhưng thường tạo ra mã thay thế khi đối mặt với khiếm khuyết.

Một hạn chế của FLAG là việc đi từng dòng cho hầu như mọi dòng trong mã nguồn không mở rộng về mặt thời gian. Trong khi các tệp nhỏ hơn ∼100 dòng được kiểm tra trong vòng chưa đến một phút, quét một tệp với hàng nghìn dòng có thể mất khoảng một giờ. Để giải quyết điều này, người ta có thể ưu tiên tạo ra một tập hợp con các dòng. Điều này có thể được thực hiện bằng cách kiểm tra các vùng nhạy cảm bảo mật của mã nguồn, ví dụ: kiểm tra các điều kiện if và các câu lệnh bên trong khối if. Một cách tiếp cận khác là bỏ qua các dòng không có nhiều nội dung, ví dụ: một dòng chỉ có từ khóa.

Một hạn chế khác là FPR cao. FPR cho các thí nghiệm của chúng tôi dao động từ 0.121 đến 0.172, có nghĩa là đối với một tệp mã nguồn 100 dòng có một khiếm khuyết, khoảng 12-17 dòng sẽ bị làm nổi bật sai. Công việc tương lai sẽ tập trung vào việc giảm thêm các dòng được đánh dấu. Một cách tiếp cận là xem xét các tính năng cho các vùng mã nguồn thay vì các dòng cho tiêu chí phân loại, ví dụ: không làm nổi bật các khiếm khuyết giữa dòng x và y cho tệp z vì logprob trung bình cho vùng này cho thấy LLM không tin tưởng vào các gợi ý của nó.

FLAG có thể hỗ trợ nhà thiết kế bằng cách tập trung việc tìm kiếm lỗi chỉ vào 12−17% nguồn. Hơn nữa, các nỗ lực giảm dương tính giả nên được thực hiện một cách thận trọng vì chúng có thể loại bỏ một số dương tính thực. Cách tiếp cận của FLAG để loại bỏ dương tính giả khi chuyển từ tiêu chí C1 sang C2 đã giảm số lượng khiếm khuyết được phát hiện trung bình là 3.75. Một ví dụ được hiển thị trong Bảng 5. Khiếm khuyết là dòng được làm nổi bật màu hồng mà LLM tạo ra mã thay thế có ld là 10 và dfc là 3. Nó được làm nổi bật bởi FLAG như một mối quan tâm khi sử dụng C1(20,10) nhưng không phải khi sử dụng C2(20,10). Điều này là do C2 sử dụng reduce_fp(), loại bỏ dòng khiếm khuyết vì nó có logprob <−0.5. FLAG đầy hứa hẹn cho phát hiện lỗi khi LLM cải thiện. Với kích thước dữ liệu lớn hơn và tinh chỉnh, các LLM mới hơn có thể tạo ra mã tốt hơn và gợi ý mã.

7 Kết luận và Công việc tương lai
Nhìn chung, 101 trong số 121 khiếm khuyết được phát hiện bởi ít nhất một chế độ của 2 LLM. Trung bình, đối với 4 kết hợp của chế độ và LLM, 80 khiếm khuyết được phát hiện với FPR là 0.154 sử dụng tiêu chí C2. Điều này đưa ra bằng chứng cho các kiểm tra tính nhất quán của FLAG như một bộ phát hiện lỗi và bộ định vị không gian tìm kiếm. Chúng tôi thấy rằng gpt-3.5-turbo có khả năng phát hiện lỗi tốt hơn nhưng FPR cao hơn code-davinci-002. FLAG tốt hơn một chút đối với lỗi chức năng so với lỗi liên quan đến bảo mật. Chúng tôi thấy rằng khoảng cách Levenshtein giữa mã gốc và mã được tạo bởi LLM là tính năng phân loại chiếm ưu thế trong số những tính năng chúng tôi khám phá. Dù vậy, nhận xét đóng vai trò quan trọng trong hiệu suất của FLAG vì các dòng mã có khoảng cách nhỏ hơn từ nhận xét được phân loại với sự thành công tốt hơn. Cuối cùng, FLAG làm tốt nhất trên C và tệ nhất trên Python cho các điểm chuẩn mà chúng tôi nghiên cứu.

Vì FLAG mới trong việc thực hiện, một số hướng công việc tương lai có thể được hình thành. Nhiều tính năng hơn trong mã và LLM có thể được sử dụng trong phân loại ví dụ: điểm BLEU cho mã và điểm embedding cho mã và nhận xét. Với một bộ tính năng phân loại lớn hơn và một bộ dương tính thực và dương tính giả lớn hơn dưới dạng điểm chuẩn, các bộ phân loại ML có thể được huấn luyện để xác định tiêu chí phân loại. Các phiên bản tương lai của FLAG có thể phân tích mã và nhận xét theo khối thay vì dòng. Một ý tưởng thú vị khác là chạy nhiều LLM và đánh dấu một dòng dựa trên sự hợp nhất của các tính năng.

Lời cảm ơn
Công việc nghiên cứu này được hỗ trợ một phần bởi một món quà từ Intel Corporation. Công việc này không cấu thành sự ủng hộ sản phẩm hoặc nhà cung cấp nào của Intel. Chúng tôi ghi nhận sự hỗ trợ của Hội đồng Nghiên cứu Khoa học Tự nhiên và Kỹ thuật Canada (NSERC), RGPIN-2022-03027.

Khả năng sử dụng
Các tạo phẩm (mã nguồn FLAG, đầu ra LLM) được sản xuất và trình bày trong nghiên cứu này có tại [32].

Tài liệu tham khảo
[1] Baleegh Ahmad, Shailja Thakur, Benjamin Tan, Ramesh Karri, và Hammond Pearce. Fixing Hardware Security Bugs with Large Language Models, Tháng 2 năm 2023. arXiv:2302.01215 [cs].

[2] Hammad Ahmad, Yu Huang, và Westley Weimer. CirFix: automatically repairing defects in hardware design code. Trong Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS '22, trang 990–1003, New York, NY, USA, Tháng 2 năm 2022. Association for Computing Machinery.

[3] Aizu. Aizu Online Judge, 2015. Truy cập ngày 2023-06-06. https://onlinejudge.u-aizu.ac.jp/home.

[4] Stefan Berner, Roland Weber, và Rudolf K. Keller. Observations and lessons learned from automated testing. Trong Proceedings of the 27th international conference on Software engineering, ICSE '05, trang 571–579, New York, NY, USA, Tháng 5 năm 2005. Association for Computing Machinery.

[5] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. Language Models are Few-Shot Learners. Trong H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, và H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, trang 1877–1901. Curran Associates, Inc., 2020.

[6] Saikat Chakraborty, Yujian Li, Matt Irvine, Ripon Saha, và Baishakhi Ray. Entropy Guided Spectrum Based Bug Localization Using Statistical Language Model, Tháng 2 năm 2018. arXiv:1802.06947 [cs].

[7] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, và Wojciech Zaremba. Evaluating Large Language Models Trained on Code, Tháng 7 năm 2021. arXiv:2107.03374 [cs].

[8] Brian Chess và Gary McGraw. Static analysis for security. IEEE Security & Privacy, 2(6):76–79, Tháng 11 năm 2004.

[9] The MITRE Corporation. CWE - CWE-1194: Hardware Design (4.1), 2022. https://cwe.mitre.org/data/definitions/1194.html.

[10] National Vulnerability Database. NVD - Home, 2023. Truy cập ngày 2023-06-06. https://nvd.nist.gov/.

[11] Yinlin Deng, Chunqiu Steven Xia, Chenyuan Yang, Shizhuo Dylan Zhang, Shujing Yang, và Lingming Zhang. Large Language Models are Edge-Case Fuzzers: Testing Deep Learning Libraries via FuzzGPT, Tháng 4 năm 2023. arXiv:2304.02014 [cs].

[12] Ghada Dessouky, David Gens, Patrick Haney, Garrett Persyn, Arun Kanuparthi, Hareesh Khattri, Jason Fung, Ahmad-Reza Sadeghi, và Jeyavijayan Rajendran. Hardfails: Insights into Software-Exploitable Hardware Bugs. Trong Proceedings of the 28th USENIX Conference on Security Symposium, SEC'19, trang 213–230, Santa Clara, CA, USA, 2019. USENIX Association.

[13] Elizabeth Dinella, Hanjun Dai, Ziyang Li, Mayur Naik, Le Song, và Ke Wang. Hoppity: Learning graph transformations to detect and fix bugs in programs. Trong International Conference on Learning Representations (ICLR), 2020.

[14] EvoSuite. Release V1.2.0 ·EvoSuite/evosuite, 2021. Truy cập 2023-05-30. https://github.com/EvoSuite/evosuite/releases/tag/v1.2.0.

[15] Philip Gage. A New Algorithm for Data Compression. C Users Journal, 12(2):23–38, Tháng 2 năm 1994.

[16] Andrew Habib và Michael Pradel. How many of all bugs do we find? a study of static bug detectors. Trong Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, ASE '18, trang 317–328, New York, NY, USA, Tháng 9 năm 2018. Association for Computing Machinery.

[17] HACK@EVENT. HACK@DAC21 – HACK@EVENT, 2022. https://hackatevent.org/hackdac21/.

[18] Github Inc. CodeQL for research, 2021. https://securitylab.github.com/tools/codeql/.

[19] Infer. Infer, 2021. Truy cập 2023-06-06. https://github.com/facebook/infer.

[20] Jun Li, Bodong Zhao, và Chao Zhang. Fuzzing: a survey. Cybersecurity, 1(1):6, Tháng 12 năm 2018.

[21] Tsz-On Li, Wenxi Zong, Yibo Wang, Haoye Tian, Ying Wang, Shing-Chi Cheung, và Jeff Kramer. Finding Failure-Inducing Test Cases with ChatGPT, Tháng 4 năm 2023. arXiv:2304.11686 [cs].

[22] Derrick Lin, James Koppel, Angela Chen, và Armando Solar-Lezama. QuixBugs: a multi-lingual program repair benchmark set based on the quixey challenge. Trong Proceedings Companion of the 2017 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity, SPLASH Companion 2017, trang 55–56, New York, NY, USA, Tháng 10 năm 2017. Association for Computing Machinery.

[23] lowRISC contributors. Open source silicon root of trust (RoT) | OpenTitan, 2023. https://opentitan.org/.

[24] Steve McConnell. Code complete. Microsoft Press, Redmond, Wash, ấn bản thứ 2, 2004.

[25] Kishore Papineni, Salim Roukos, Todd Ward, và Wei-Jing Zhu. BLEU: a method for automatic evaluation of machine translation. Trong Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL '02, trang 311–318, USA, Tháng 7 năm 2002. Association for Computational Linguistics.

[26] Hammond Pearce, Baleegh Ahmad, Benjamin Tan, Brendan Dolan-Gavitt, và Ramesh Karri. Asleep at the Keyboard? Assessing the Security of GitHub Copilot's Code Contributions. Trong 2022 IEEE Symposium on Security and Privacy (SP), trang 754–768, Tháng 5 năm 2022. ISSN: 2375-1207.

[27] Hammond Pearce, Benjamin Tan, Baleegh Ahmad, Ramesh Karri, và Brendan Dolan-Gavitt. Examining Zero-Shot Vulnerability Repair with Large Language Models. Trong 2023 IEEE Symposium on Security and Privacy (SP), trang 2339–2356. IEEE Computer Society, 2023.

[28] Michael Pradel và Koushik Sen. DeepBugs: a learning approach to name-based bug detection. Proceedings of the ACM on Programming Languages, 2(OOPSLA):147:1–147:25, Tháng 10 năm 2018.

[29] Error Prone. Error Prone, 2023. Truy cập 2023-05-30. https://github.com/google/error-prone.

[30] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, và Ilya Sutskever. Language Models are Unsupervised Multitask Learners. trang 1–24, 2019. https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf.

[31] Randoop. Randoop: Automatic unit test generation for Java, 2023. Truy cập 2023-05-30. https://randoop.github.io/randoop/.

[32] Anonymized for review. Artifacts for "FLAG: Finding Line Anomalies (in code) with Generative AI", Tháng 6 năm 2023. https://zenodo.org/record/8012211.

[33] Gustavo Sandoval, Hammond Pearce, Teo Nys, Ramesh Karri, Siddharth Garg, và Brendan Dolan-Gavitt. Lost at C: A User Study on the Security Implications of Large Language Model Code Assistants. USENIX Security Symposium, 2023.

[34] Sina Shamshiri, René Just, José Miguel Rojas, Gordon Fraser, Phil McMinn, và Andrea Arcuri. Do Automatically Generated Unit Tests Find Real Faults? An Empirical Study of Effectiveness and Challenges (T). Trong 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE), trang 201–211, Tháng 11 năm 2015.

[35] SpotBugs. SpotBugs, 2022. Truy cập 2023-05-30. https://spotbugs.github.io/.

[36] Daniela Steidl, Benjamin Hummel, và Elmar Juergens. Quality analysis of source code comments. Trong 2013 21st International Conference on Program Comprehension (ICPC), trang 83–92, Tháng 5 năm 2013. ISSN: 1092-8138.

[37] Lin Tan, Ding Yuan, Gopal Krishna, và Yuanyuan Zhou. /*icomment: bugs or bad comments?*/. ACM SIGOPS Operating Systems Review, 41(6):145–158, Tháng 10 năm 2007.

[38] Shin Hwei Tan, Darko Marinov, Lin Tan, và Gary T. Leavens. @tComment: Testing Javadoc Comments to Detect Comment-Code Inconsistencies. Trong Verification and Validation 2012 IEEE Fifth International Conference on Software Testing, trang 260–269, Tháng 4 năm 2012. ISSN: 2159-4848.

[39] Yunosuke Teshima và Yutaka Watanobe. Bug Detection Based on LSTM Networks and Solution Codes. Trong 2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC), trang 3541–3546, Tháng 10 năm 2018. ISSN: 2577-1655.

[40] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. Attention is All you Need. Trong Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017.

[41] Song Wang, Devin Chollak, Dana Movshovitz-Attias, và Lin Tan. Bugram: bug detection with n-gram language models. Trong Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering, ASE '16, trang 708–719, New York, NY, USA, Tháng 8 năm 2016. Association for Computing Machinery.

[42] Ratnadira Widyasari, Sheng Qin Sim, Camellia Lok, Haodi Qi, Jack Phan, Qijin Tay, Constance Tan, Fiona Wee, Jodie Ethelda Tan, Yuheng Yieh, Brian Goh, Ferdian Thung, Hong Jin Kang, Thong Hoang, David Lo, và Eng Lieh Ouh. BugsInPy: a database of existing bugs in Python programs to enable controlled testing and debugging studies. Trong Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2020, trang 1556–1560, New York, NY, USA, Tháng 11 năm 2020. Association for Computing Machinery.

[43] Jooyong Yi, Umair Z. Ahmed, Amey Karkare, Shin Hwei Tan, và Abhik Roychoudhury. A feasibility study of using automated program repair for introductory programming assignments. Trong Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2017, trang 740–751, New York, NY, USA, Tháng 8 năm 2017. Association for Computing Machinery.

A Phụ lục
Bảng 6 là bảng hoàn chỉnh cho các lỗi liên quan đến bảo mật được kiểm tra trong công việc này. Mô tả cho các điểm chuẩn khiếm khuyết chức năng được sử dụng và ID tương ứng của chúng được trình bày trong Bảng 7. Trong Hình 14, chúng tôi trình bày việc chia nhỏ các kết hợp của LLM và chế độ của chúng có thể phát hiện từng khiếm khuyết được thu thập.

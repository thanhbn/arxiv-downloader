# 2308.03983.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2308.03983.pdf
# Kích thước tệp: 919920 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
SimplyRetrieve: Một Công Cụ AI Tạo Sinh Tập Trung Truy Xuất Riêng Tư và Nhẹ
Youyang Ng, Daisuke Miyashita, Yasuto Hoshi, Yasuhiro Morioka,
Osamu Torii ,Tomoya Kodama ,Jun Deguchi
Tập đoàn Kioxia, Nhật Bản
youyang.ng@kioxia.com
Tóm tắt
Các hệ thống AI Tạo Sinh dựa trên Mô hình Ngôn ngữ Lớn (LLM) đã có những tiến bộ đáng kể trong những năm gần đây. Tích hợp kiến trúc truy xuất tri thức cho phép tích hợp liền mạch dữ liệu riêng tư vào các hệ thống AI Tạo Sinh có sẵn công khai sử dụng LLM được huấn luyện trước mà không cần fine-tuning mô hình bổ sung. Hơn nữa, phương pháp Tạo Sinh Tập Trung Truy Xuất (RCG), một hướng nghiên cứu tương lai đầy hứa hẹn tách biệt rõ ràng vai trò của LLM và bộ truy xuất trong việc diễn giải ngữ cảnh và ghi nhớ tri thức, có thể dẫn đến việc triển khai hiệu quả hơn. SimplyRetrieve là một công cụ mã nguồn mở với mục tiêu cung cấp giao diện cục bộ, nhẹ và thân thiện với người dùng cho những tiến bộ phức tạp này đến cộng đồng học máy. SimplyRetrieve có nền tảng RCG dựa trên GUI và API, được hỗ trợ bởi Bộ Xây Dựng Cơ Sở Tri Thức Riêng Tư và Mô-đun Điều Chỉnh Truy Xuất. Bằng cách tận dụng những khả năng này, người dùng có thể khám phá tiềm năng của RCG để cải thiện hiệu suất AI tạo sinh trong khi duy trì tiêu chuẩn riêng tư. Công cụ này có sẵn tại https://github.com/RCGAI/SimplyRetrieve với giấy phép MIT.

1 Giới thiệu
Xử lý Ngôn ngữ Tự nhiên (NLP) dựa trên tạo sinh đã chứng kiến những tiến bộ đáng kể (Brown et al., 2020) trong những năm gần đây. Với sự ra đời của kiến trúc Transformer (Vaswani et al., 2017), khả năng phát triển các mô hình ngôn ngữ có độ chính xác cao có thể thực hiện các nhiệm vụ như tạo văn bản, tóm tắt văn bản và dịch ngôn ngữ đã trở thành hiện thực. Những mô hình này (Brown et al., 2020; Chowdhery et al., 2022), khi được mở rộng lên hàng tỷ tham số (Wei et al., 2022a), đã cho thấy những cải tiến đáng kể trong các nhiệm vụ tạo văn bản như suy luận zero-shot, phổ biến thuật ngữ AI Tạo Sinh. Thay vì fine-tuning mô hình, thiết kế prompt cẩn thận đã chứng minh hiệu quả trong việc thích ứng những mô hình này với các lĩnh vực cụ thể cho nhiều nhiệm vụ khác nhau (Brown et al., 2020). Điều này đã làm nảy sinh lĩnh vực kỹ thuật prompt. Ngoài ra, Chain-of-Thought (Wei et al., 2022b; Kojima et al., 2022) phân tách một nhiệm vụ phức tạp được giao thành các bước có thể quản lý, từ đó mở rộng thêm khả năng của các mô hình ngôn ngữ dựa trên tạo sinh.

Huấn luyện các mô hình ngôn ngữ lớn (LLM) đòi hỏi tài nguyên tính toán khổng lồ, thường bao gồm hàng nghìn GPU cao cấp. Fine-tuning những mô hình này cũng có thể là thách thức. Mặc dù kỹ thuật prompt giúp giảm nhu cầu fine-tuning, vẫn còn sự không phù hợp hướng dẫn đáng chú ý khi tương tác với người dùng con người. Để giải quyết vấn đề này, các kỹ thuật như học tăng cường từ phản hồi của con người (RLHF) (Christiano et al., 2017) đã được khám phá để căn chỉnh hành vi của LLM với giá trị con người (Ouyang et al., 2022; OpenAI, 2023). Ngoài ra, QLoRA (Dettmers et al., 2023), kết hợp kỹ thuật thích ứng hạng thấp (Hu et al., 2022) và kỹ thuật lượng tử hóa, đã giúp fine-tuning những mô hình này trên phần cứng của nhà phát triển cá nhân, giúp chúng dễ tiếp cận hơn với phạm vi người dùng rộng hơn.

Bất chấp những tiến bộ này, vẫn còn những hạn chế về khả năng của LLM, và chúng không vốn dĩ nhận biết thông tin không có mặt trong quá trình huấn luyện và fine-tuning. Ghi nhớ tri thức thực tế trong phần đuôi dài cũng là một thách thức (Mallen et al., 2023).

Gần đây nhất, đã có sự quan tâm ngày càng tăng trong việc tích hợp các nguồn tri thức bên ngoài vào LLM để tạo văn bản (Borgeaud et al., 2022; Guu et al., 2020; Lewis et al., 2020). Các phương pháp tương tự cũng đã được đề xuất trong việc giải quyết các nhiệm vụ thị giác máy tính (Nakata et al., 2022; Iscen et al., 2023). Kiến trúc Tạo Sinh Tăng Cường Truy Xuất (RAG) (Lewis et al., 2020) là một phương pháp tăng cường khả năng của LLM bằng cách kết hợp các nguồn dữ liệu bên ngoài sử dụng bộ truy xuất thưa thớt hoặc dày đặc (Karpukhin et al., 2020), cho phép sử dụng dữ liệu sở hữu riêng mà không cần huấn luyện lại hoặc fine-tuning LLM (Chase, 2022). Tuy nhiên, phát triển các mô hình tạo sinh dựa trên LLM tăng cường truy xuất vẫn đang trong giai đoạn đầu. Công cụ được đề xuất của chúng tôi có thể giúp tạo thuận lợi cho những phát triển này.

Ngoài ra, chúng tôi giới thiệu một khái niệm kiến trúc mới gọi là Tạo Sinh Tập Trung Truy Xuất (RCG), dựa trên phương pháp Tạo Sinh Tăng Cường Truy Xuất bằng cách nhấn mạnh vai trò quan trọng của LLM trong việc diễn giải ngữ cảnh và giao phó ghi nhớ tri thức cho thành phần truy xuất, đặt tầm quan trọng lớn hơn lên bộ truy xuất, như được mô tả trong Hình 1. Bằng cách tách biệt diễn giải ngữ cảnh khỏi ghi nhớ tri thức, phương pháp này có tiềm năng giảm quy mô (Carlini et al., 2023) của LLM cần thiết cho các nhiệm vụ tạo sinh, dẫn đến kết quả hiệu quả và dễ giải thích hơn. Hơn nữa, phương pháp này có thể giúp giảm thiểu ảo giác (Maynez et al., 2020) bằng cách hạn chế phạm vi tạo sinh của LLM. Khi chúng tôi định nghĩa RCG như trên, chúng tôi có thể tái định nghĩa RAG cho phép sử dụng linh hoạt hơn tri thức vốn có của LLM, trong khi RCG ưu tiên sự phân cách rõ ràng giữa diễn giải ngữ cảnh và ghi nhớ tri thức.

SimplyRetrieve là một công cụ mã nguồn mở nhằm cung cấp giao diện cục bộ, nhẹ và thân thiện với người dùng cho phương pháp Tạo Sinh Tập Trung Truy Xuất đến cộng đồng học máy. Công cụ này bao gồm nền tảng RCG dựa trên GUI và API, được hỗ trợ bởi Bộ Xây Dựng Cơ Sở Tri Thức Riêng Tư và Mô-đun Điều Chỉnh Truy Xuất. SimplyRetrieve được thiết kế để đơn giản và dễ tiếp cận với cộng đồng, cũng như người dùng cuối.

Nền tảng tập trung truy xuất của chúng tôi kết hợp nhiều cơ sở tri thức có thể lựa chọn với tính năng chế độ Hỗn Hợp Cơ Sở Tri Thức (MoKB) và Trọng Số Prompt Rõ Ràng (EPW) của cơ sở tri thức được truy xuất. Bằng cách thiết kế SimplyRetrieve với những tính năng này, chúng tôi cho phép cộng đồng học máy khám phá và phát triển với giao diện dữ liệu riêng tư nhẹ cho các hệ thống AI tạo sinh dựa trên LLM, tập trung vào tạo sinh tập trung truy xuất. Các phát triển tiềm năng có thể được khám phá bằng công cụ này bao gồm: (1) kiểm tra hiệu quả của tạo sinh tập trung truy xuất trong việc phát triển các hệ thống AI an toàn, dễ giải thích và có trách nhiệm hơn; (2) tối ưu hóa hiệu quả của việc tách biệt diễn giải ngữ cảnh và ghi nhớ tri thức trong phương pháp tạo sinh tập trung truy xuất; và (3) cải thiện các kỹ thuật kỹ thuật prompt cho tạo sinh tập trung truy xuất. SimplyRetrieve có sẵn tại https://github.com/RCGAI/SimplyRetrieve.

Đóng góp của chúng tôi có thể được tóm tắt như sau:
•Chúng tôi đề xuất SimplyRetrieve, một công cụ sáng tạo và thân thiện với người dùng tận dụng nền tảng GUI và API để tạo thuận lợi cho phương pháp Tạo Sinh Tập Trung Truy Xuất. Nền tảng này được củng cố thêm bởi hai thành phần chính: Bộ Xây Dựng Cơ Sở Tri Thức Riêng Tư và Mô-đun Điều Chỉnh Truy Xuất.
•Chúng tôi mở mã nguồn công cụ của mình cho cộng đồng học máy và xác định các hướng phát triển tiềm năng của Tạo Sinh Tập Trung Truy Xuất.

2 Các Công Trình Liên Quan
Sự xuất hiện của kiến trúc Tạo Sinh Tăng Cường Truy Xuất đã thúc đẩy sự phát triển của nhiều công cụ mã nguồn mở. Ví dụ, ChatGPT Retrieval Plugin1 tích hợp khả năng truy xuất và tăng cường tài liệu cá nhân hoặc tổ chức vào mô hình ChatGPT được sử dụng rộng rãi (OpenAI, 2023). Tương tự, fastRAG (Izsak et al., 2023) cung cấp nền tảng hợp lý hóa để xây dựng các pipeline tạo sinh tăng cường truy xuất hiệu quả. Ngoài ra, LangChain (Chase, 2022) cung cấp thư viện AI trò chuyện tạo sinh toàn diện với các tính năng agent, tăng cường dữ liệu và bộ nhớ. Cuối cùng, Haystack (Pietsch et al., 2019) trình bày một framework NLP bao trùm hỗ trợ hỏi đáp, tạo câu trả lời, tìm kiếm tài liệu ngữ nghĩa và tăng cường truy xuất. Cả LangChain và Haystack đều sử dụng các kỹ thuật pipelining dựa trên agent và có thể xử lý các truy vấn phức tạp. Tuy nhiên, sự phức tạp này có thể cản trở khả năng giải thích của LLM, làm cho việc diễn giải hiệu suất của chúng trong các thiết lập tăng cường truy xuất trở nên thách thức.

Mặt khác, công trình của chúng tôi cung cấp một phương pháp nhẹ và minh bạch để triển khai kiến trúc tập trung truy xuất cũng như tăng cường truy xuất phức tạp, trong khi duy trì trọng tâm mạnh mẽ vào khả năng giải thích phản hồi và khả năng tiếp cận rộng rãi hơn với cộng đồng. Không giống như các công trình trước đây như PrivateGPT (PrivateGPT), cung cấp công cụ AI trò chuyện bảo vệ quyền riêng tư nhưng thiếu tùy chọn tùy chỉnh và khả năng phân tích, công cụ của chúng tôi cung cấp bộ tính năng toàn diện để điều chỉnh và phân tích tạo sinh tập trung truy xuất. Hơn nữa, theo hiểu biết tốt nhất của chúng tôi, chúng tôi là những người đầu tiên giới thiệu khái niệm RCG và cho thấy các thí nghiệm ban đầu của nó bằng công cụ của mình.

3 Thiết Kế Công Cụ
SimplyRetrieve được thiết kế để triển khai pipeline RCG: xây dựng cơ sở tri thức, điều chỉnh kiến trúc, đưa ra dự đoán. Trong bài báo này, chúng tôi tập trung vào việc mô tả các thông số kỹ thuật cốt lõi của công cụ. Để biết chi tiết về các thủ tục thiết lập, hãy tham khảo kho lưu trữ tại https://github.com/RCGAI/SimplyRetrieve.

3.1 Nền Tảng Tạo Sinh Tập Trung Truy Xuất dựa trên GUI và API
Như được hiển thị trong Hình 2, có hai mô hình dày đặc trong công cụ của chúng tôi: một LLM và một Bộ Truy Xuất Tri Thức dựa trên Tìm Kiếm Láng Giềng Gần Đúng (ANNS). LLM có thể là bất kỳ mô hình LLM mã nguồn mở nào có sẵn trong Hugging Face (Wolf et al., 2020), từ 1B đến hơn 100B tham số như Touvron et al. (2023a,b). Bộ Truy Xuất Tri Thức sử dụng bộ truy xuất dày đặc tương thích với nhiều mô hình embedding khác nhau có sẵn trong Hugging Face. Ngoài ra, công cụ của chúng tôi cho phép tích hợp nhiều cơ sở tri thức đồng thời, cho phép người dùng lựa chọn cơ sở tri thức tùy thuộc vào trường hợp sử dụng cụ thể.

Về GUI, chúng tôi đã thiết kế một bố cục đơn giản nhưng trực quan bằng Gradio (Abid et al., 2019), cung cấp giao diện chatbot streaming quen thuộc với điều khiển người dùng để quản lý các chế độ hoạt động của bộ truy xuất, kỹ thuật prompt và cấu hình công cụ. Như được mô tả trong Hình 3, GUI của chúng tôi có bảng điều chỉnh tập trung truy xuất toàn diện cho các chức năng bao gồm lựa chọn cơ sở tri thức thủ công từ nhiều nguồn và chế độ Hỗn Hợp Cơ Sở Tri Thức. Hơn nữa, chúng tôi sử dụng Trọng Số Prompt Rõ Ràng của truy xuất để điều chỉnh mức độ ảnh hưởng của bộ truy xuất. Để đảm bảo tích hợp liền mạch, chúng tôi cũng phát triển chức năng truy cập API toàn diện bằng Giao Diện Khách Hàng Gradio, và chúng tôi cho phép truy cập đồng thời nhiều người dùng vào cả hai UI, tận dụng chức năng hàng đợi của Gradio để quản lý yêu cầu một cách hiệu quả.

Bảng điều chỉnh tập trung truy xuất cho phép truy cập nhẹ và đơn giản vào RCG. Bằng cách sử dụng chế độ lựa chọn cơ sở tri thức thủ công, người dùng có thể xây dựng và nhập nhiều cơ sở tri thức riêng tư đồng thời vào công cụ này. Khả năng lựa chọn cơ sở tri thức phù hợp nhất cho mỗi nhiệm vụ cho phép người dùng duy trì quyền kiểm soát quá trình lựa chọn trong khi tránh bất kỳ kết quả bất ngờ nào. Chế độ MoKB của chúng tôi cho phép lựa chọn tự động cơ sở tri thức phù hợp nhất dựa trên sự tương tự giữa truy vấn và mô tả chức năng cơ sở tri thức. Chúng tôi sử dụng độ tương tự cosine ngữ nghĩa của không gian embedding để tính toán những điểm số này, cung cấp một phương pháp hiệu quả và nhẹ để tự động lựa chọn cơ sở tri thức. Bằng cách cập nhật các mô tả chức năng trong tệp cấu hình, người dùng có thể tăng cường thêm độ chính xác của thuật toán lựa chọn.

Ngoài ra, tính năng Trọng Số Prompt Rõ Ràng của chúng tôi cho phép điều chỉnh thủ công mức độ ảnh hưởng của bộ truy xuất lên mô hình ngôn ngữ, cho phép kiểm soát tùy chỉnh sự cân bằng giữa bộ truy xuất và LLM. Thông qua kỹ thuật prompt hoặc điều chỉnh trọng số token, người dùng có thể thích ứng công cụ với nhu cầu cụ thể của họ, đảm bảo hiệu suất tối ưu. SimplyRetrieve đã kết hợp Trọng Số Prompt Rõ Ràng thông qua kỹ thuật prompt, nơi trọng số có thể được điều chỉnh để tinh chỉnh tỷ lệ phần trăm token tri thức được sử dụng trong prompt từ các token được truy xuất. Tuy nhiên, chúng tôi chưa triển khai điều chỉnh trọng số token trong nghiên cứu này và để lại nó cho công việc tương lai.

3.2 Bộ Xây Dựng Cơ Sở Tri Thức Riêng Tư
Nền Tảng Tạo Sinh Tập Trung Truy Xuất của chúng tôi được hỗ trợ bởi Bộ Xây Dựng Cơ Sở Tri Thức Riêng Tư tạo ra một cơ sở tri thức cục bộ và cá nhân hóa bằng cách sử dụng các tài liệu của người dùng. Bộ xây dựng này sử dụng trình tải tài liệu có thể mở rộng có thể xử lý khối lượng lớn tài liệu bằng cách phân đoạn và streaming các quy trình tải, tách và tạo cơ sở tri thức, cho phép xử lý tài liệu hiệu quả. Bộ xây dựng hỗ trợ nhiều định dạng tài liệu khác nhau như PDF, TXT, DOC, DOCX, PPT, PPTX, HTML, MD, CSV, cùng những định dạng khác, và có thể được mở rộng dễ dàng bằng cách chỉnh sửa tệp cấu hình. Ngoài ra, độ dài của các đoạn trong chức năng tách tài liệu có thể được cấu hình dễ dàng để đáp ứng các yêu cầu cụ thể.

Sau khi tạo ra các nguồn cho cơ sở tri thức, chúng tôi sử dụng bộ mã hóa dày đặc để chuyển đổi văn bản thành các embedding số có thể được sử dụng cho tìm kiếm và truy xuất ngữ nghĩa. Để phù hợp với các cơ sở tri thức quy mô lớn, chúng tôi sử dụng ANNS để truy xuất ngữ nghĩa hiệu quả. Theo mặc định, công cụ của chúng tôi sử dụng thuật toán Hierarchical Navigable Small Worlds (HNSW) (Malkov và Yashunin, 2020), nhưng chúng tôi cũng cung cấp hỗ trợ cho lập chỉ mục phẳng và phương pháp IVFPQ-HNSW, kết hợp lập chỉ mục tệp đảo ngược với lượng tử hóa sản phẩm và bộ lượng tử hóa khóa học HNSW. Chức năng Xây Dựng Chỉ Mục tự động tạo ra các tệp chỉ mục cần thiết cho tìm kiếm ngữ nghĩa. Chúng tôi triển khai chức năng lập chỉ mục của mình bằng cách sử dụng thư viện Faiss (Johnson et al., 2019).

3.3 Mô-đun Điều Chỉnh Truy Xuất
Mô-đun Điều Chỉnh Truy Xuất của công cụ chúng tôi bao gồm ba chức năng chính: kỹ thuật prompt, cấu hình công cụ, và phân tích và ghi nhật ký dữ liệu. Chức năng kỹ thuật prompt cho phép người dùng dễ dàng chỉnh sửa, cập nhật và lưu các prompt liên quan đến truy xuất bằng Tab Prompt thân thiện với người dùng trong GUI của chúng tôi. Các prompt có sẵn là AI Prefix, Retriever Prefix, Retriever Suffix, Model Prefix và Model Suffix. Chức năng cấu hình cho phép người dùng sửa đổi và lưu tất cả các thiết lập có thể cấu hình thông qua Tab Config trong GUI của chúng tôi. Cuối cùng, chức năng phân tích và ghi nhật ký dữ liệu thu thập và hiển thị dữ liệu phân tích liên quan đến truy xuất, bao gồm cơ sở tri thức được truy xuất, truy vấn, phản hồi, điểm tương tự cấp câu và cấp token, trong Tab Analysis của GUI chúng tôi. Điểm tương tự được tính toán dựa trên cả độ tương tự cosine ngữ nghĩa của embedding câu-đến-câu và tất cả embedding token-đến-token. Phương pháp này cho phép chúng tôi nắm bắt cả sự tương tự cục bộ và toàn cầu giữa các câu, dẫn đến đánh giá chính xác hơn về khả năng so sánh của chúng. Ngoài ra, người dùng có thể lưu tất cả dữ liệu đã ghi nhật ký vào tệp nhật ký để phân tích thêm. Thiết kế GUI được mô tả trong Hình 4, 5 và 6 của Phụ lục A.2. Để triển khai chế độ người dùng cuối, người dùng có thể đơn giản vô hiệu hóa các chức năng cập nhật trong Mô-đun Điều Chỉnh Truy Xuất thông qua các tùy chọn dòng lệnh.

4 Đánh Giá
Trong phần này, chúng tôi thực hiện một số đánh giá định tính để chứng minh tính khả dụng và hành vi của công cụ. Chúng tôi xây dựng cơ sở tri thức của mình bằng cách sử dụng thông tin mới nhất có sẵn trên trang web của một tổ chức2. Chúng tôi sử dụng các mô hình có sẵn công khai trên Hugging Face, Wizard-Vicuna-13B3(Xu et al., 2023; Chiang et al., 2023) làm LLM và Multilingual-E5-base4(Wang et al., 2022) làm bộ mã hóa cho các đánh giá của chúng tôi, trừ khi được chỉ định khác. Chúng tôi tải cả hai mô hình vào một GPU Nvidia A100 duy nhất ở chế độ 8-bit INT8 để sử dụng bộ nhớ thấp hơn và tốc độ suy luận cao hơn. Chúng tôi đặt nhiệt độ của LLM là 0. Chúng tôi sử dụng HNSW để lập chỉ mục các cơ sở tri thức và đặt số lượng đoạn được truy xuất là 5.

4.1 Đánh Giá Định Tính
Chúng tôi so sánh kết quả của ba phương pháp: Tạo Sinh Tập Trung Truy Xuất (RCG), Tạo Sinh Tăng Cường Truy Xuất (RAG), và Tạo Sinh Tắt Truy Xuất (ROG). Lưu ý rằng trong công trình này, chúng tôi định nghĩa RAG là cho phép tích hợp linh hoạt hơn tri thức vốn có của LLM và tri thức được truy xuất từ bên ngoài, trong khi RCG ưu tiên sự phân cách rõ ràng giữa diễn giải ngữ cảnh và ghi nhớ tri thức. Điều tra các phương pháp tiên tiến trong việc trích xuất hành vi RCG là một chủ đề nghiên cứu đầy hứa hẹn. Trong công trình này, chúng tôi tiến hành các thí nghiệm đơn giản bằng kỹ thuật prompt để khám phá tiềm năng của phương pháp RCG. Cụ thể, đối với RCG, chúng tôi sử dụng prompt suffix truy xuất có nội dung "trả lời câu hỏi sau với tri thức được cung cấp." Đối với RAG, chúng tôi sử dụng prompt ít ràng buộc hơn có nội dung "trả lời câu hỏi sau. Bạn có thể sử dụng tri thức được cung cấp." Cuối cùng, đối với ROG, đây là đường cơ sở trong đánh giá của chúng tôi, chúng tôi vô hiệu hóa hoàn toàn bộ truy xuất. Bằng cách sử dụng chức năng kỹ thuật prompt trong SimplyRetrieve, chúng tôi có thể dễ dàng thực hiện những thí nghiệm này. Các truy vấn được chú thích bởi con người. Trong Bảng 1 và 2, văn bản màu xanh lam chỉ ra phản hồi đúng thực tế trong khi văn bản màu đỏ chỉ ra ảo giác.

Truy vấn: nhà máy của Kioxia ở đâu?
Phương pháp | Phản hồi
RCG | Kioxia có các nhà máy nằm ở cả thành phố Yokkaichi, tỉnh Mie và thành phố Kitakami, tỉnh Iwate tại Nhật Bản.
RAG | Kioxia có các nhà máy nằm ở nhiều khu vực khác nhau trên toàn cầu bao gồm Nhật Bản, Thái Lan, Malaysia, Trung Quốc và Hoa Kỳ. Tuy nhiên, địa điểm sản xuất chính của công ty nằm ở Thành phố Yokkaichi, Tỉnh Mie, Nhật Bản.
ROG | Địa điểm sản xuất chính của chúng tôi cho các sản phẩm HDD và SSD nằm ở Yamagata, Nhật Bản. Chúng tôi cũng có các địa điểm sản xuất ở Thái Lan và Philippines sản xuất phương tiện đĩa quang học như Blu-ray Disc và DVD.

Bảng 1: So sánh định tính giữa các phương pháp Tập Trung Truy Xuất, Tăng Cường Truy Xuất và Tắt Truy Xuất bằng kỹ thuật prompt trong SimplyRetrieve.

Dựa trên kết quả trong Bảng 1, chúng tôi quan sát thấy rằng RCG đã trả lời thành công truy vấn của chúng tôi một cách chính xác, trong khi RAG đã cố gắng tích hợp cơ sở tri thức được truy xuất với tri thức riêng của LLM về tổ chức cụ thể, dẫn đến thông tin một phần sai lệch. Trong khi đó, ROG đã phản hồi truy vấn của chúng tôi với tri thức sai lầm có sẵn của LLM, tạo ra những điều sai lệch. Phát hiện của chúng tôi gợi ý rằng việc tạo ra các prompt rõ ràng và trực tiếp, như "trả lời câu hỏi đã cho bằng tri thức được cung cấp", có thể khuyến khích hành vi tập trung truy xuất từ LLM, mặc dù kỹ thuật prompt tinh chỉnh thêm có thể cần thiết để có hiệu suất tối ưu.

Như được hiển thị trong Bảng 2, RCG đã giải quyết hiệu quả truy vấn và tạo ra kết quả chính xác. Khi kết hợp RCG với Trọng Số Prompt Rõ Ràng 50% (RCG-EPW), nơi chỉ 50% đầu tiên của cơ sở tri thức được truy xuất được tiêm vào prompt, mô hình đã tạo ra phản hồi một phần nhưng vẫn duy trì độ chính xác thực tế. Ngược lại, LLM thuần túy không có RC được bật (ROG) đã cung cấp các phản hồi ảo giác, làm nổi bật tầm quan trọng của việc kết hợp các kỹ thuật tập trung truy xuất trong các mô hình ngôn ngữ để cải thiện hiệu suất.

Truy vấn: Kioxia đã làm gì trong Phân Loại Hình Ảnh
Phương pháp | Phản hồi
RCG | Kioxia đã phát triển một thiết bị lưu trữ dung lượng cao có thể lưu trữ lượng lớn dữ liệu hình ảnh cần thiết cho các thuật toán AI. Điều này cho phép họ triển khai các hệ thống AI tập trung bộ nhớ có khả năng xử lý nhiều nhiệm vụ phân loại đồng thời mà không ảnh hưởng đến hiệu suất hoặc độ chính xác.
RCG-EPW | Triển khai AI tập trung Bộ nhớ với lưu trữ dung lượng cao
ROG | Công ty đã phát triển một thuật toán phân loại hình ảnh mới đạt độ chính xác top-1 là 82,7% trên tập xác thực ImageNet, đây là cải tiến so với kết quả tiên tiến trước đó hơn một điểm phần trăm. Điều này trở nên khả thi thông qua những tiến bộ trong công nghệ phần cứng và phần mềm như GPU Tensor Core và framework học sâu riêng của chúng tôi, ONNX-MXNET.

Bảng 2: Tác động của Tạo Sinh Tập Trung Truy Xuất trong SimplyRetrieve, dựa trên cơ sở tri thức về một tổ chức.

4.2 Đánh Giá Độ Chính Xác & Tốc Độ
Ngoài việc đánh giá hiệu quả của RCG bằng chú thích của con người, chúng tôi cũng tiến hành đánh giá nội bộ hiệu suất của công cụ bằng cách sử dụng một tập dữ liệu tự tạo. Để tạo ra tập dữ liệu này, chúng tôi truyền các đoạn văn liên quan qua mô hình ngôn ngữ Llama-2-13B-chat (Touvron et al., 2023b) để tạo ra 10 cặp truy vấn và nhãn. Để biết chi tiết về cách chúng tôi tạo ra tập dữ liệu này, hãy tham khảo Phụ lục A.4. Chúng tôi sử dụng điểm Rouge-L (Lin, 2004) làm chỉ số hiệu suất của mình. Chúng tôi thực hiện đánh giá này bằng cách sử dụng chức năng API của SimplyRetrieve. Kết quả của chúng tôi trong Bảng 3 cho thấy RCG cải thiện đáng kể điểm Rouge-L so với phương pháp cơ sở ROG, đồng thời cũng cạnh tranh hơn một chút so với RAG. Hơn nữa, mặc dù thực tế là RCG xử lý các prompt dài hơn ROG do việc bổ sung token tri thức, chúng tôi quan sát thấy giảm thời gian xử lý nhờ vào độ chính xác tăng lên và tính ngắn gọn của các phản hồi được tạo ra. Cụ thể, số lượng token phản hồi được tạo ra trong RCG trung bình ít hơn 36% so với những token được tạo ra trong ROG. Hiệu suất hiệu quả này có thể tạo thuận lợi cho việc áp dụng rộng rãi hơn trong cộng đồng, vì người dùng có thể mong đợi tạo phản hồi nhanh hơn mà không phải hy sinh độ chính xác.

Phương pháp | Điểm Rouge-L | thời gian/truy vấn(s)
ROG | 0.186 | 17.22
RAG | 0.359 | 18.41
RCG | 0.413 | 11.67

Bảng 3: Đánh giá độ chính xác và tốc độ phản hồi của SimplyRetrieve.

Cuối cùng, phát hiện của chúng tôi gợi ý rằng ngay cả một LLM có kích thước khiêm tốn 13B tham số có thể thể hiện hiệu suất thỏa đáng trong phương pháp RCG đối với tri thức thực tế chưa từng thấy trước đây mà không cần fine-tuning mô hình nào, có thể tạo thuận lợi cho việc triển khai các hệ thống AI Tạo Sinh trong các tình huống thực tế. Xem Phụ lục A.2 để thảo luận thêm và A.5 cho các nghiên cứu loại bỏ.

5 Kết Luận
Chúng tôi đã giới thiệu SimplyRetrieve, một công cụ mã nguồn mở nhằm cung cấp nền tảng GUI và API có thể bản địa hóa, nhẹ và thân thiện với người dùng cho phương pháp Tạo Sinh Tập Trung Truy Xuất dựa trên LLM. Công cụ của chúng tôi cho phép các nhà phát triển và người dùng cuối dễ dàng tương tác và phát triển với hệ thống RCG dựa trên LLM bảo vệ quyền riêng tư và được triển khai cục bộ, mà chúng tôi tin rằng sẽ đóng góp vào việc dân chủ hóa những công nghệ này trong cộng đồng học máy. Tăng cường sự rõ ràng trong việc phân chia vai trò giữa diễn giải ngữ cảnh và ghi nhớ tri thức có thể tăng cường hiệu suất và khả năng giải thích của các hệ thống AI tạo sinh, tạo thuận lợi cho việc triển khai.

Hạn Chế
Điều quan trọng cần lưu ý là công cụ này không cung cấp giải pháp hoàn toàn chắc chắn để đảm bảo phản hồi hoàn toàn an toàn và có trách nhiệm từ các mô hình AI tạo sinh, ngay cả trong phương pháp tập trung truy xuất. Việc phát triển các hệ thống AI an toàn hơn, có thể giải thích được và có trách nhiệm vẫn là một lĩnh vực nghiên cứu tích cực và nỗ lực liên tục.

Văn bản được tạo ra từ công cụ này có thể thể hiện sự biến đổi, ngay cả khi chỉ sửa đổi nhẹ các prompt hoặc truy vấn, do hành vi dự đoán token tiếp theo của các LLM thế hệ hiện tại. Điều này có nghĩa là người dùng có thể cần điều chỉnh cẩn thận cả prompt và truy vấn để có được phản hồi tối ưu.

Tài Liệu Tham Khảo
[Danh sách tài liệu tham khảo được dịch giữ nguyên định dạng gốc]

--- TRANG 7 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 8 ---
[Tiếp tục danh sách tài liệu tham khảo]

--- TRANG 9 ---
[Tiếp tục danh sách tài liệu tham khảo]

A Phụ Lục
A.1 Thiết Kế GUI của Mô-đun Điều Chỉnh Truy Xuất
Hình 4 cho thấy thiết kế GUI của giao diện kỹ thuật prompt. Hình 5 cho thấy thiết kế GUI của giao diện cấu hình công cụ. Hình 6 cho thấy thiết kế GUI của giao diện phân tích và ghi nhật ký dữ liệu.

A.2 Ứng Dụng
SimplyRetrieve có tiềm năng lớn cho nhiều ứng dụng thực tế khác nhau. Ví dụ, nó có thể phục vụ như nền tảng để xây dựng các hệ thống AI tạo sinh riêng tư, cá nhân hóa và nhẹ. Thông tin nhạy cảm và cá nhân có thể được lưu trữ và xử lý một cách an toàn trong nền tảng tập trung truy xuất. Phương pháp này cho phép các tổ chức phát triển các hệ thống AI tạo sinh có thể giải thích được và được điều chỉnh cục bộ cho cơ sở hạ tầng quan trọng. Ngoài ra, việc sử dụng mô hình ngôn ngữ tương đối nhỏ hơn như một trình diễn giải ngữ cảnh trong phương pháp này tạo thuận lợi cho việc tích hợp liền mạch vào môi trường edge computing. Chi phí giảm của các thiết bị lưu trữ dữ liệu cũng làm cho việc thiết lập các cơ sở tri thức quy mô lớn trở nên khả thi. Hơn nữa, SimplyRetrieve mở đường cho việc phát triển các trợ lý AI cá nhân hóa dựa trên LLM. Cuối cùng, một cuộc khám phá sâu về tạo sinh tập trung truy xuất dựa trên LLM bằng SimplyRetrieve có thể cung cấp những hiểu biết và cơ hội có giá trị cho nghiên cứu tương lai.

A.3 Danh Mục Prompt
Bảng 5 cho thấy các prompt được sử dụng trong kết quả đánh giá của Phần 4 trong khi Bảng 6 cho thấy các prompt mẫu có thể thể hiện hành vi tập trung truy xuất. Prompt được truyền đến LLM theo định dạng sau: AI Prefix + Retriever Prefix + Cơ Sở Tri Thức Được Truy Xuất + Retriever Suffix + Model Prefix + Truy Vấn + Model Suffix.

A.4 Dữ Liệu Đánh Giá
Bảng 7 trình bày dữ liệu được sử dụng để đánh giá hiệu suất của công cụ đề xuất trong Phần 4.2. Chúng tôi sử dụng mô hình Llama-2-13B-chat (Touvron et al., 2023b) với prompt tùy chỉnh ("thông tin liên quan." Vui lòng tạo một truy vấn và câu trả lời từ đoạn văn ở trên) để tự động tạo ra các cặp truy vấn và nhãn từ thông tin liên quan trên trang web của một tổ chức.

A.5 Nghiên Cứu Loại Bỏ
Như được hiển thị trong Bảng 4, nghiên cứu loại bỏ của chúng tôi tiết lộ rằng việc điều chỉnh Trọng Số Prompt Rõ Ràng trong SimplyRetrieve dẫn đến cải thiện đáng kể trong điểm Rouge-L. Thú vị là, tăng trọng số lên 50% mang lại cải thiện cao nhất, vượt quá điểm đó hiệu suất vẫn tương đối ổn định. Điều này gợi ý rằng 50% hàng đầu của các cơ sở tri thức được truy xuất là quan trọng để đạt được độ chính xác cao. Tuy nhiên, quan trọng là phải lưu ý rằng những phát hiện này có thể không tổng quát hóa cho tất cả các tập dữ liệu hoặc cơ sở tri thức, và điều tra thêm có thể cần thiết để xác định trọng số tối ưu cho các trường hợp sử dụng cụ thể. Trong việc so sánh thời gian phản hồi cho mỗi truy vấn qua các thiết lập khác nhau, chúng tôi quan sát thấy rằng thời gian phản hồi vẫn tương đối nhất quán cho tất cả các trường hợp của RCG, trong khi chúng tăng đáng kể trong thiết lập cơ sở (ROG). Mặc dù thực tế là RCG xử lý các prompt dài hơn so với cơ sở, chúng tôi quan sát thấy giảm thời gian xử lý nhờ vào độ chính xác tăng lên và tính ngắn gọn của các phản hồi được tạo ra.

--- TRANG 10 ---
[Bảng 4, 5, 6 được dịch giữ nguyên cấu trúc]

--- TRANG 11 ---
[Hình 4, 5, 6 với mô tả đã được dịch]

--- TRANG 12 ---
[Bảng 7 với dữ liệu đánh giá đã được dịch]

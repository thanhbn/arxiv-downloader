# 2304.06815.pdf
# Chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: ./2304.06815.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 1920153 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================

--- TRANG 1 ---
TÄƒng CÆ°á»ng Ngá»¯ NghÄ©a Tá»± Äá»™ng cá»§a Prompt MÃ´ HÃ¬nh NgÃ´n Ngá»¯
(cho TÃ³m Táº¯t MÃ£ Nguá»“n)
Toufique Ahmed
Äáº¡i há»c California, Davis
Davis, California, USA
tfahmed@ucdavis.edu

Kunal Suresh Pai
Äáº¡i há»c California, Davis
Davis, California, USA
kunpai@ucdavis.edu

Premkumar Devanbu
Äáº¡i há»c California, Davis
Davis, California, USA
ptdevanbu@ucdavis.edu

Earl T. Barr
University College London & Google Brain
London, UK
e.barr@ucl.ac.uk

TÃ“M Táº®T
CÃ¡c MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n (LLM) lÃ  má»™t lá»›p cÃ´ng cá»¥ tÃ­nh toÃ¡n má»›i, Ä‘Æ°á»£c "láº­p trÃ¬nh" thÃ´ng qua ká»¹ thuáº­t prompt engineering. CÃ¡c nhÃ  nghiÃªn cá»©u váº«n Ä‘ang tÃ¬m hiá»ƒu cÃ¡ch "láº­p trÃ¬nh" tá»‘t nháº¥t cho nhá»¯ng LLM nÃ y Ä‘á»ƒ há»— trá»£ cÃ¡c láº­p trÃ¬nh viÃªn.

ChÃºng tÃ´i báº¯t Ä‘áº§u vá»›i trá»±c giÃ¡c ráº±ng cÃ¡c láº­p trÃ¬nh viÃªn cÃ³ xu hÆ°á»›ng thu tháº­p cÃ¡c sá»± kiá»‡n ngá»¯ nghÄ©a má»™t cÃ¡ch cÃ³ Ã½ thá»©c vÃ  vÃ´ thá»©c tá»« mÃ£ nguá»“n trong khi lÃ m viá»‡c. Háº§u háº¿t Ä‘Ã¢y lÃ  nhá»¯ng sá»± kiá»‡n nÃ´ng, Ä‘Æ¡n giáº£n phÃ¡t sinh tá»« viá»‡c Ä‘á»c nhanh. Äá»‘i vá»›i má»™t hÃ m, nhá»¯ng sá»± kiá»‡n nhÆ° váº­y cÃ³ thá»ƒ bao gá»“m tÃªn tham sá»‘ vÃ  biáº¿n cá»¥c bá»™, biá»ƒu thá»©c tráº£ vá», Ä‘iá»u kiá»‡n tiÃªn quyáº¿t vÃ  háº­u quyáº¿t Ä‘Æ¡n giáº£n, vÃ  luá»“ng Ä‘iá»u khiá»ƒn vÃ  dá»¯ liá»‡u cÆ¡ báº£n, v.v.

NgÆ°á»i ta cÃ³ thá»ƒ giáº£ Ä‘á»‹nh ráº±ng kiáº¿n trÃºc Ä‘a lá»›p máº¡nh máº½ cá»§a cÃ¡c LLM kiá»ƒu transformer khiáº¿n chÃºng cÃ³ kháº£ nÄƒng ngáº§m thá»±c hiá»‡n má»©c Ä‘á»™ "phÃ¢n tÃ­ch mÃ£ nguá»“n" Ä‘Æ¡n giáº£n nÃ y vÃ  trÃ­ch xuáº¥t thÃ´ng tin nhÆ° váº­y, trong khi xá»­ lÃ½ mÃ£ nguá»“n: nhÆ°ng liá»‡u chÃºng cÃ³ thá»±c sá»± nhÆ° váº­y khÃ´ng? Náº¿u khÃ´ng, viá»‡c thÃªm thÃ´ng tin nÃ y má»™t cÃ¡ch rÃµ rÃ ng cÃ³ thá»ƒ giÃºp Ã­ch khÃ´ng? Má»¥c tiÃªu cá»§a chÃºng tÃ´i á»Ÿ Ä‘Ã¢y lÃ  Ä‘iá»u tra cÃ¢u há»i nÃ y, sá»­ dá»¥ng nhiá»‡m vá»¥ tÃ³m táº¯t mÃ£ nguá»“n vÃ  Ä‘Ã¡nh giÃ¡ xem viá»‡c tÄƒng cÆ°á»ng tá»± Ä‘á»™ng prompt cá»§a LLM vá»›i cÃ¡c sá»± kiá»‡n ngá»¯ nghÄ©a má»™t cÃ¡ch rÃµ rÃ ng cÃ³ thá»±c sá»± giÃºp Ã­ch khÃ´ng.

NghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y cho tháº¥y ráº±ng hiá»‡u suáº¥t cá»§a LLM trong tÃ³m táº¯t mÃ£ nguá»“n Ä‘Æ°á»£c cáº£i thiá»‡n nhá» viá»‡c nhÃºng má»™t sá»‘ máº«u mÃ£ nguá»“n & tÃ³m táº¯t vÃ o prompt, trÆ°á»›c mÃ£ nguá»“n cáº§n tÃ³m táº¯t. Trong khi hiá»‡u suáº¥t tÃ³m táº¯t Ä‘Ã£ tiáº¿n bá»™ Ä‘á»u Ä‘áº·n ká»ƒ tá»« nhá»¯ng ngÃ y Ä‘áº§u, váº«n cÃ²n chá»— Ä‘á»ƒ cáº£i thiá»‡n: hiá»‡u suáº¥t cá»§a LLM trong tÃ³m táº¯t mÃ£ nguá»“n váº«n kÃ©m hÆ¡n hiá»‡u suáº¥t cá»§a nÃ³ trong cÃ¡c nhiá»‡m vá»¥ ngÃ´n ngá»¯ tá»± nhiÃªn nhÆ° dá»‹ch thuáº­t vÃ  tÃ³m táº¯t vÄƒn báº£n.

ChÃºng tÃ´i tháº¥y ráº±ng viá»‡c thÃªm cÃ¡c sá»± kiá»‡n ngá»¯ nghÄ©a vÃ o mÃ£ nguá»“n trong prompt thá»±c sá»± giÃºp Ã­ch! CÃ¡ch tiáº¿p cáº­n nÃ y cáº£i thiá»‡n hiá»‡u suáº¥t trong nhiá»u thiáº¿t láº­p khÃ¡c nhau Ä‘Æ°á»£c Ä‘á» xuáº¥t bá»Ÿi nghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y, bao gá»“m cho ba MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n khÃ¡c nhau. Trong háº§u háº¿t cÃ¡c trÆ°á»ng há»£p, chÃºng tÃ´i tháº¥y cáº£i thiá»‡n, Ä‘Æ°á»£c Ä‘o báº±ng má»™t loáº¡t cÃ¡c chá»‰ sá»‘ thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng; Ä‘á»‘i vá»›i ngÃ´n ngá»¯ PHP trong bá»™ dá»¯ liá»‡u CodeSearchNet Ä‘áº§y thá»­ thÃ¡ch, viá»‡c tÄƒng cÆ°á»ng nÃ y thá»±c sá»± mang láº¡i hiá»‡u suáº¥t vÆ°á»£t qua 30 BLEUÂ¹. NgoÃ i ra, chÃºng tÃ´i

Â¹Äiá»ƒm sá»‘ 30-40 BLEU Ä‘Æ°á»£c coi lÃ  "Tá»‘t" Ä‘áº¿n "CÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c" Ä‘á»‘i vá»›i dá»‹ch thuáº­t ngÃ´n ngá»¯ tá»± nhiÃªn; xem https://cloud.google.com/translate/automl/docs/evaluate.

ÄÆ°á»£c phÃ©p táº¡o báº£n sao ká»¹ thuáº­t sá»‘ hoáº·c báº£n cá»©ng cá»§a má»™t pháº§n hoáº·c toÃ n bá»™ cÃ´ng viá»‡c nÃ y cho má»¥c Ä‘Ã­ch cÃ¡ nhÃ¢n hoáº·c lá»›p há»c mÃ  khÃ´ng máº¥t phÃ­ vá»›i Ä‘iá»u kiá»‡n cÃ¡c báº£n sao khÃ´ng Ä‘Æ°á»£c táº¡o ra hoáº·c phÃ¢n phá»‘i vÃ¬ lá»£i nhuáº­n hoáº·c lá»£i tháº¿ thÆ°Æ¡ng máº¡i vÃ  cÃ¡c báº£n sao pháº£i cÃ³ thÃ´ng bÃ¡o nÃ y vÃ  trÃ­ch dáº«n Ä‘áº§y Ä‘á»§ trÃªn trang Ä‘áº§u tiÃªn. Báº£n quyá»n cho cÃ¡c thÃ nh pháº§n cá»§a bÃªn thá»© ba trong cÃ´ng viá»‡c nÃ y pháº£i Ä‘Æ°á»£c tÃ´n trá»ng.
Äá»‘i vá»›i táº¥t cáº£ cÃ¡c má»¥c Ä‘Ã­ch sá»­ dá»¥ng khÃ¡c, liÃªn há»‡ vá»›i chá»§ sá»Ÿ há»¯u/tÃ¡c giáº£.
ICSE '24, 14â€“20 thÃ¡ng 4, 2024, Lisbon, Bá»“ ÄÃ o Nha
Â©2024 Báº£n quyá»n thuá»™c vá» chá»§ sá»Ÿ há»¯u/tÃ¡c giáº£.
ACM ISBN 979-8-4007-0217-4/24/04.
https://doi.org/10.1145/3597503.3639183

cÅ©ng tháº¥y ráº±ng viá»‡c bao gá»“m cÃ¡c sá»± kiá»‡n ngá»¯ nghÄ©a mang láº¡i sá»± cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ trong hiá»‡u suáº¥t hoÃ n thÃ nh dÃ²ng cá»§a LLM.

Tá»ª KHÃ“A
LLM, TÃ³m Táº¯t MÃ£ Nguá»“n, PhÃ¢n TÃ­ch ChÆ°Æ¡ng TrÃ¬nh, Ká»¹ Thuáº­t Prompt

Äá»‹nh Dáº¡ng TrÃ­ch Dáº«n ACM:
Toufique Ahmed, Kunal Suresh Pai, Premkumar Devanbu, vÃ  Earl T. Barr.
2024. TÄƒng CÆ°á»ng Ngá»¯ NghÄ©a Tá»± Äá»™ng cá»§a Prompt MÃ´ HÃ¬nh NgÃ´n Ngá»¯ (cho TÃ³m Táº¯t MÃ£ Nguá»“n). Trong Há»™i nghá»‹ Quá»‘c táº¿ IEEE/ACM láº§n thá»© 46 vá» Ká»¹ Thuáº­t Pháº§n Má»m 2024 (ICSE '24), 14â€“20 thÃ¡ng 4, 2024, Lisbon, Bá»“ ÄÃ o Nha. ACM, New York, NY, USA, 13 trang. https://doi.org/10.1145/3597503.3639183

1 GIá»šI THIá»†U
CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) thÆ°á»ng vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh nhá» hÆ¡n, Ä‘Æ°á»£c huáº¥n luyá»‡n tÃ¹y chá»‰nh trong nhiá»u nhiá»‡m vá»¥, Ä‘áº·c biá»‡t khi Ä‘Æ°á»£c nháº¯c nhá»Ÿ báº±ng má»™t táº­p há»£p máº«u "few-shot". LLM Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c trÃªn má»™t nhiá»‡m vá»¥ tá»± giÃ¡m sÃ¡t (che giáº¥u hoáº·c khá»­ nhiá»…u), sá»­ dá»¥ng lÆ°á»£ng lá»›n dá»¯ liá»‡u, vÃ  thá»ƒ hiá»‡n hÃ nh vi khá»Ÿi phÃ¡t Ä‘Ã¡ng ngáº¡c nhiÃªn khi dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  sá»‘ lÆ°á»£ng tham sá»‘ Ä‘Æ°á»£c má»Ÿ rá»™ng. ChÃºng xuáº¥t sáº¯c trong nhiá»u nhiá»‡m vá»¥ vá»›i viá»‡c há»c few-shot (hoáº·c tháº­m chÃ­ zero-shot): chá»‰ vá»›i má»™t vÃ i cáº·p Ä‘áº§u vÃ o-Ä‘áº§u ra máº«u Ä‘Æ°á»£c chÃ¨n Ä‘áº§u tiÃªn vÃ o prompt, cÃ¡c mÃ´ hÃ¬nh cÃ³ thá»ƒ táº¡o ra Ä‘áº§u ra ráº¥t tá»‘t cho má»™t Ä‘áº§u vÃ o cho trÆ°á»›c! Viá»‡c há»c few-shot hoáº¡t Ä‘á»™ng tá»‘t Ä‘áº¿n má»©c vá»›i LLM mÃ  khÃ´ng rÃµ liá»‡u dá»¯ liá»‡u cá»¥ thá»ƒ cho nhiá»‡m vá»¥ cÃ³ thá»ƒ Ä‘Æ°á»£c thu tháº­p Ä‘á»§ Ä‘á»ƒ huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh tÃ¹y chá»‰nh cÃ³ thá»ƒ cáº¡nh tranh vá»›i hiá»‡u suáº¥t cá»§a chÃºng [3,12]. LLM Ä‘ang má»Ÿ ra má»™t ká»· nguyÃªn má»›i, nÆ¡i ká»¹ thuáº­t prompt engineering, Ä‘á»ƒ Ä‘iá»u chá»‰nh cáº©n tháº­n Ä‘áº§u vÃ o cho LLM nháº±m Ä‘iá»u chá»‰nh kháº£ nÄƒng khá»•ng lá»“ nhÆ°ng chung chung cá»§a nÃ³ cho cÃ¡c nhiá»‡m vá»¥ cá»¥ thá»ƒ, sáº½ trá»Ÿ thÃ nh má»™t phong cÃ¡ch láº­p trÃ¬nh má»›i, Ä‘áº·t ra yÃªu cáº§u má»›i cho cÃ¡c ká»¹ sÆ° pháº§n má»m.

ChÃºng tÃ´i Ä‘á» xuáº¥t TÄƒng CÆ°á»ng Ngá»¯ NghÄ©a Tá»± Äá»™ng cá»§a Prompt (Ağ‘†ğ´ğ‘ƒ), má»™t phÆ°Æ¡ng phÃ¡p má»›i Ä‘á»ƒ xÃ¢y dá»±ng prompt cho cÃ¡c nhiá»‡m vá»¥ ká»¹ thuáº­t pháº§n má»m. PhÆ°Æ¡ng phÃ¡p Ağ‘†ğ´ğ‘ƒ dá»±a trÃªn má»™t sá»± tÆ°Æ¡ng tá»±: má»™t prompt hiá»‡u quáº£ cho LLM, Ä‘á»‘i vá»›i má»™t nhiá»‡m vá»¥, liÃªn quan Ä‘áº¿n cÃ¡c sá»± kiá»‡n mÃ  má»™t láº­p trÃ¬nh viÃªn nghÄ© vá» khi thá»±c hiá»‡n nhiá»‡m vá»¥ Ä‘Ã³ má»™t cÃ¡ch thá»§ cÃ´ng. NÃ³i cÃ¡ch khÃ¡c, chÃºng tÃ´i giáº£ thuyáº¿t ráº±ng viá»‡c nháº¯c nhá»Ÿ LLM báº±ng cÃ¡c sá»± kiá»‡n cÃº phÃ¡p vÃ  ngá»¯ nghÄ©a mÃ  má»™t láº­p trÃ¬nh viÃªn xem xÃ©t khi thá»±c hiá»‡n má»™t nhiá»‡m vá»¥ má»™t cÃ¡ch thá»§ cÃ´ng sáº½ cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a LLM trong nhiá»‡m vá»¥ Ä‘Ã³. Äá»ƒ thá»±c hiá»‡n giáº£ thuyáº¿t nÃ y, Ağ‘†ğ´ğ‘ƒ tÄƒng cÆ°á»ng cÃ¡c prompt báº±ng cÃ¡c sá»± kiá»‡n ngá»¯ nghÄ©a Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»± Ä‘á»™ng tá»« mÃ£ nguá»“n sá»­ dá»¥ng phÃ¢n tÃ­ch mÃ£ nguá»“n ngá»¯ nghÄ©a.

ChÃºng tÃ´i minh há»a phÆ°Æ¡ng phÃ¡p Ağ‘†ğ´ğ‘ƒ Ä‘áº§u tiÃªn vá» tÃ³m táº¯t mÃ£ nguá»“n. Nhiá»‡m vá»¥ nÃ y láº¥y mÃ£ nguá»“n, thÆ°á»ng lÃ  má»™t hÃ m, vÃ  tÃ³m táº¯t nÃ³ báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn; nhá»¯ng tÃ³m táº¯t nhÆ° váº­y cÃ³ thá»ƒ há»— trá»£ hiá»ƒu mÃ£ nguá»“n Ä‘á»ƒ táº¡o Ä‘iá»u kiá»‡n cho viá»‡c theo dÃµi yÃªu cáº§u vÃ  báº£o trÃ¬.

--- TRANG 2 ---
ICSE '24, 14â€“20 thÃ¡ng 4, 2024, Lisbon, Bá»“ ÄÃ o Nha Toufique Ahmed, Kunal Suresh Pai, Premkumar Devanbu, vÃ  Earl T. Barr

Ağ‘†ğ´ğ‘ƒ sá»­ dá»¥ng few-shot prompting vÃ¬ tÃ­nh hiá»‡u quáº£ cá»§a nÃ³. Ağ‘†ğ´ğ‘ƒ tÃ¬m nhá»¯ng shot liÃªn quan báº±ng BM25, hiá»‡n táº¡i lÃ  state of the art trong viá»‡c tÃ¬m cÃ¡c máº«u few-shot "gáº§n gÅ©i vá» máº·t ngá»¯ nghÄ©a" vá»›i hÃ m má»¥c tiÃªu [48], trong trÆ°á»ng há»£p cá»§a chÃºng tÃ´i, hÃ m-cáº§n-tÃ³m-táº¯t, báº±ng cÃ¡ch truy váº¥n dá»¯ liá»‡u huáº¥n luyá»‡n cá»§a LLM. Khi khá»Ÿi táº¡o Ağ‘†ğ´ğ‘ƒ cho nhiá»‡m vá»¥ tÃ³m táº¯t, chÃºng tÃ´i trang bá»‹ nÃ³ Ä‘á»ƒ trÃ­ch xuáº¥t cÃ¡c sá»± kiá»‡n ngá»¯ nghÄ©a sau: tÃªn repository, tÃªn Ä‘áº§y Ä‘á»§ cá»§a hÃ m má»¥c tiÃªu, chá»¯ kÃ½ cá»§a nÃ³, cÃ¡c tháº» AST cá»§a cÃ¡c Ä‘á»‹nh danh, vÃ  Ä‘á»“ thá»‹ luá»“ng dá»¯ liá»‡u cá»§a nÃ³ (Má»¥c 3.4). Nhá»¯ng sá»± kiá»‡n nÃ y Ä‘Æ°á»£c trÃ¬nh bÃ y cho LLM nhÆ° cÃ¡c trÆ°á»ng riÃªng biá»‡t, cÃ³ nhÃ£nÂ². Sau Ä‘Ã³ mÃ´ hÃ¬nh Ä‘Æ°á»£c cung cáº¥p hÃ m-cáº§n-tÃ³m-táº¯t, cÃ¡c máº«u (cÃ¹ng vá»›i cÃ¡c sá»± kiá»‡n Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« má»—i máº«u), vÃ  Ä‘Æ°á»£c yÃªu cáº§u táº¡o ra má»™t tÃ³m táº¯t. ChÃºng tÃ´i xÃ¡c nháº­n giáº£ thuyáº¿t cá»§a mÃ¬nh ráº±ng viá»‡c tÄƒng cÆ°á»ng prompt báº±ng cÃ¡c sá»± kiá»‡n ngá»¯ nghÄ©a cÃ³ thá»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a LLM trong nhiá»‡m vá»¥ hoÃ n thÃ nh mÃ£ nguá»“n. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ lá»£i Ã­ch cá»§a Ağ‘†ğ´ğ‘ƒ trÃªn bá»™ dá»¯ liá»‡u CodeSearchNet [32] cháº¥t lÆ°á»£ng cao (Ä‘Æ°á»£c khá»­ trÃ¹ng láº·p cáº©n tháº­n, Ä‘a dá»± Ã¡n).

TÃ³m láº¡i, chÃºng tÃ´i tháº¥y ráº±ng trong táº¥t cáº£ cÃ¡c trÆ°á»ng há»£p, cÃ¡ch tiáº¿p cáº­n tÄƒng cÆ°á»ng ngá»¯ nghÄ©a tá»± Ä‘á»™ng cá»§a chÃºng tÃ´i cáº£i thiá»‡n hiá»‡u suáº¥t trung bÃ¬nh trÃªn má»™t sá»‘ chá»‰ sá»‘ thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng. Äá»‘i vá»›i háº§u háº¿t cÃ¡c ngÃ´n ngá»¯, sá»± cáº£i thiá»‡n trung bÃ¬nh vÆ°á»£t qua má»™t cÃ¡ch thoáº£i mÃ¡i ngÆ°á»¡ng 2-BLEU Ä‘Æ°á»£c Roy et al. [57] lÆ°u Ã½, dÆ°á»›i Ä‘Ã³ káº¿t quáº£ BLEU lÃ  nhá»¯ng dá»± Ä‘oÃ¡n khÃ´ng Ä‘Ã¡ng tin cáº­y vá» sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i. Äá»‘i vá»›i Go, lá»£i Ã­ch váº«n Ä‘Ã¡ng ká»ƒ, vÃ  chá»‰ hÆ¡i Ã­t hÆ¡n 2; Ä‘á»‘i vá»›i PHP, chÃºng tÃ´i tháº¥y má»™t cáº£i thiá»‡n 4.6 BLEU, Ä‘áº¡t Ä‘áº¿n Ä‘iá»ƒm cao SOTA lÃ  32.73 trÃªn bá»™ dá»¯ liá»‡u CodeSearchNet Ä‘Æ°á»£c tuyá»ƒn chá»n tá»‘t, khá»­ trÃ¹ng láº·p.

CÃ¡c Ä‘Ã³ng gÃ³p chÃ­nh cá»§a chÃºng tÃ´i nhÆ° sau:
â€¢ CÃ¡ch tiáº¿p cáº­n Ağ‘†ğ´ğ‘ƒ cho cÃ¡c nhiá»‡m vá»¥ ká»¹ thuáº­t pháº§n má»m sá»­ dá»¥ng cÃ¡c sá»± kiá»‡n Ä‘Æ°á»£c rÃºt ra tá»« mÃ£ nguá»“n.
â€¢ ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ Ağ‘†ğ´ğ‘ƒ trÃªn nhiá»‡m vá»¥ tÃ³m táº¯t mÃ£ nguá»“n trÃªn cÃ¡c mÃ´ hÃ¬nh code-davinci-002, text-davinci-003, vÃ  GPT-3.5-turbo so vá»›i baseline few-shot prompting Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng BM25 thuáº§n tÃºy (Má»¥c 4.1).
â€¢ ChÃºng tÃ´i tháº¥y ráº±ng cÃ¡ch tiáº¿p cáº­n Ağ‘†ğ´ğ‘ƒ cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a LLM má»™t cÃ¡ch cÃ³ Ã½ nghÄ©a thá»‘ng kÃª trong nhiá»‡m vá»¥ tÃ³m táº¯t mÃ£ nguá»“n. Trong háº§u háº¿t cÃ¡c trÆ°á»ng há»£p, chÃºng tÃ´i quan sÃ¡t tháº¥y cáº£i thiá»‡n cÃ³ Ã½ nghÄ©a thá»‘ng kÃª gáº§n nhÆ°, hoáº·c vÆ°á»£t quÃ¡, 2 BLEU; vÃ , Ä‘á»‘i vá»›i PHP, chÃºng tÃ´i vÆ°á»£t qua 30 BLEU láº§n Ä‘áº§u tiÃªn (theo kiáº¿n thá»©c cá»§a chÃºng tÃ´i) trÃªn bá»™ dá»¯ liá»‡u Ä‘áº§y thá»­ thÃ¡ch nÃ y.
â€¢ ChÃºng tÃ´i tháº¥y ráº±ng Ağ‘†ğ´ğ‘ƒ cÅ©ng dáº«n Ä‘áº¿n cáº£i thiá»‡n hiá»‡u suáº¥t trong nhiá»‡m vá»¥ hoÃ n thÃ nh mÃ£ nguá»“n.

Táº¥t cáº£ dá»¯ liá»‡u, script Ä‘Ã¡nh giÃ¡, vÃ  mÃ£ nguá»“n cáº§n thiáº¿t Ä‘á»ƒ tÃ¡i táº¡o cÃ´ng viá»‡c nÃ y sáº½ cÃ³ sáºµn táº¡i https://doi.org/10.5281/zenodo.7779196, vÃ  cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¡i táº¡o trÃªn báº¥t ká»³ mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ sáºµn nÃ o. ThÃ­ nghiá»‡m cá»§a chÃºng tÃ´i cho tháº¥y ráº±ng Ağ‘†ğ´ğ‘ƒ hoáº¡t Ä‘á»™ng tá»‘t vá»›i báº¥t ká»³ mÃ´ hÃ¬nh ngÃ´n ngá»¯ nÃ o Ä‘á»§ máº¡nh Ä‘á»ƒ táº­n dá»¥ng few-shot prompting.

2 Bá»I Cáº¢NH & Äá»˜NG Lá»°C
CÃ¡c MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n (LLM) lÃ  má»™t cÃ´ng nghá»‡ mang tÃ­nh biáº¿n Ä‘á»•i: chÃºng vá» cÆ¡ báº£n lÃ  má»™t loáº¡i cÃ´ng cá»¥ tÃ­nh toÃ¡n má»›i, Ä‘Ã²i há»i má»™t hÃ¬nh thá»©c láº­p trÃ¬nh má»›i, Ä‘Æ°á»£c gá»i lÃ  ká»¹ thuáº­t prompt engineering. TrÆ°á»›c tiÃªn chÃºng tÃ´i bá»‘i cáº£nh hÃ³a Ağ‘†ğ´ğ‘ƒ, Ä‘Ã³ng gÃ³p cá»§a chÃºng tÃ´i cho ká»¹ thuáº­t prompt engineering. Cuá»‘i cÃ¹ng, chÃºng tÃ´i tháº£o luáº­n vá» tÃ³m táº¯t mÃ£ nguá»“n nhÆ° má»™t váº¥n Ä‘á» máº«u Ä‘á»ƒ chá»©ng minh tÃ­nh hiá»‡u quáº£ cá»§a Ağ‘†ğ´ğ‘ƒ.

Â²Má»™t vÃ­ dá»¥ Ä‘áº§y Ä‘á»§ khÃ¡ dÃ i, vÃ  Ä‘Æ°á»£c bao gá»“m trong repository do giá»›i háº¡n Ä‘á»™ dÃ i cá»§a bÃ i bÃ¡o.

2.1 Há»c Few-shot trong Ká»¹ Thuáº­t Pháº§n Má»m
LLM hiá»‡n Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trong Ká»¹ Thuáº­t Pháº§n Má»m cho nhiá»u váº¥n Ä‘á» khÃ¡c nhau: táº¡o mÃ£ nguá»“n [14,34], kiá»ƒm thá»­ [38,42], táº¡o mutation [10], sá»­a chá»¯a chÆ°Æ¡ng trÃ¬nh [18,35,36,48], quáº£n lÃ½ sá»± cá»‘ [6], vÃ  tháº­m chÃ­ tÃ³m táº¯t mÃ£ nguá»“n [3]. RÃµ rÃ ng, cÃ¡c cÃ´ng cá»¥ Ä‘Æ°á»£c xÃ¢y dá»±ng trÃªn LLM Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c Ä‘ang thÃºc Ä‘áº©y state of the art. NgoÃ i hiá»‡u suáº¥t thÃ´ cá»§a chÃºng trong nhiá»u nhiá»‡m vá»¥, hai yáº¿u tá»‘ chÃ­nh chi phá»‘i sá»± thá»‘ng trá»‹ ngÃ y cÃ ng tÄƒng cá»§a LLM Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c, cáº£ hai Ä‘á»u táº­p trung vÃ o chi phÃ­. Thá»© nháº¥t, huáº¥n luyá»‡n mÃ´ hÃ¬nh lá»›n cá»§a riÃªng mÃ¬nh, hoáº·c tháº­m chÃ­ fine-tuning rá»™ng rÃ£i má»™t LLM Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c, Ä‘Ã²i há»i pháº§n cá»©ng Ä‘áº¯t tiá»n. Thá»© hai, táº¡o ra má»™t bá»™ dá»¯ liá»‡u cÃ³ giÃ¡m sÃ¡t cho nhiá»u nhiá»‡m vá»¥ ká»¹ thuáº­t pháº§n má»m quan trá»ng lÃ  khÃ³ khÄƒn vÃ  tá»‘n thá»i gian, thÆ°á»ng vÆ°á»£t quÃ¡ nguá»“n lá»±c cá»§a táº¥t cáº£ trá»« nhá»¯ng tá»• chá»©c lá»›n nháº¥t.

TrÃ¡i ngÆ°á»£c vá»›i xu hÆ°á»›ng LLM tá»•ng thá»ƒ, cÃ³ má»™t sá»‘ mÃ´ hÃ¬nh nhá» hÆ¡n, chuyÃªn dá»¥ng cho mÃ£ nguá»“n, Ä‘Ã£ trá»Ÿ nÃªn phá»• biáº¿n, vÃ­ dá»¥: Polycoder [67] hoáº·c Codegen [49]. Máº·c dÃ¹ cÃ³ nhá»¯ng Ä‘iá»ƒm pháº£n bÃ¡c nÃ y, chÃºng tÃ´i táº­p trung vÃ o LLM hÆ¡n lÃ  cÃ¡c mÃ´ hÃ¬nh nhá», bá»Ÿi vÃ¬, trong khi cÃ¡c mÃ´ hÃ¬nh nhá» cÃ³ thá»ƒ Ä‘Æ°á»£c fine-tuned, chÃºng khÃ´ng hoáº¡t Ä‘á»™ng tá»‘t láº¯m trong few-shotting, vÃ  do Ä‘Ã³ khÃ´ng há»¯u Ã­ch khi chá»‰ cÃ³ má»™t lÆ°á»£ng nhá» dá»¯ liá»‡u cÃ³ sáºµn. CÃ¡ch tiáº¿p cáº­n few-shot lÃ  chÃ¬a khÃ³a bá»Ÿi vÃ¬ nÃ³ Ä‘Æ°a vÃ o táº§m vá»›i nhiá»u váº¥n Ä‘á», nhÆ° tÃ³m táº¯t mÃ£ nguá»“n, mÃ  viá»‡c thu tháº­p dá»¯ liá»‡u huáº¥n luyá»‡n cháº¥t lÆ°á»£ng cao, cá»¥ thá»ƒ cho dá»± Ã¡n hoáº·c domain Ä‘á»§ Ä‘á»ƒ huáº¥n luyá»‡n tháº­m chÃ­ cÃ¡c mÃ´ hÃ¬nh nhá» tá»« Ä‘áº§u lÃ  thÃ¡ch thá»©c.

Vá»›i há»c few-shot, cÃ¡c tham sá»‘ mÃ´ hÃ¬nh thá»±c táº¿ váº«n khÃ´ng thay Ä‘á»•i. Thay vÃ o Ä‘Ã³, chÃºng tÃ´i trÃ¬nh bÃ y má»™t vÃ i instance cá»§a váº¥n Ä‘á» cÃ¹ng vá»›i cÃ¡c giáº£i phÃ¡p (tá»©c lÃ , cÃ¡c cáº·p váº¥n Ä‘á»-giáº£i phÃ¡p nhÆ° "cÃ¡c máº«u") cho má»™t mÃ´ hÃ¬nh vÃ  yÃªu cáº§u nÃ³ hoÃ n thÃ nh cÃ¢u tráº£ lá»i cho instance cuá»‘i cÃ¹ng ("Ä‘áº§u vÃ o thá»­ nghiá»‡m"), mÃ  chÃºng tÃ´i khÃ´ng cung cáº¥p giáº£i phÃ¡p. Do Ä‘Ã³ vá»›i má»—i ğ‘’ğ‘¥ğ‘’ğ‘šğ‘ğ‘™ğ‘ğ‘Ÿ bao gá»“m má»™t cáº·p âŸ¨input,outputâŸ©, vÃ  chá»‰ má»™t test-input inputğ‘¡ (mÃ  khÃ´ng cÃ³ outputğ‘¡ tÆ°Æ¡ng á»©ng, mong muá»‘n), prompt cuá»‘i cÃ¹ng trÃ´ng nhÆ°:

promptâ†exemplar1||exemplar2||exemplar3||ğ‘–ğ‘›ğ‘ğ‘¢ğ‘¡ ğ‘¡

Vá»›i prompt nÃ y, LLM táº¡o ra ğ‘œğ‘¢ğ‘¡ğ‘ğ‘¢ğ‘¡ ğ‘¡, báº¯t chÆ°á»›c hÃ nh vi input-output Ä‘Æ°á»£c minh há»a bá»Ÿi cÃ¡c máº«u trong prompt. TrÃªn thá»±c táº¿, cÃ¡ch tiáº¿p cáº­n nÃ y hoáº¡t Ä‘á»™ng khÃ¡ tá»‘t.

Khi nÃ³ hoáº¡t Ä‘á»™ng, few-shotting cho phÃ©p chÃºng tÃ´i tá»± Ä‘á»™ng hÃ³a tháº­m chÃ­ cÃ¡c váº¥n Ä‘á» hoÃ n toÃ n thá»§ cÃ´ng, vÃ¬ viá»‡c táº¡o ra má»™t vÃ i máº«u lÃ  tÆ°Æ¡ng Ä‘á»‘i dá»… dÃ ng. Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i thá»­ nghiá»‡m vá»›i mÃ´ hÃ¬nh code-davinci-002. ChÃºng tÃ´i tháº£o luáº­n vá» cÃ¡c mÃ´ hÃ¬nh chi tiáº¿t hÆ¡n trong Má»¥c 3.2.

2.2 Nháº¯c Nhá»Ÿ LLM LÃ½ Luáº­n
LÃ½ Luáº­n cá»§a Con NgÆ°á»i liÃªn quan Ä‘áº¿n viá»‡c sá»­ dá»¥ng báº±ng chá»©ng, tÆ° duy logic, vÃ  láº­p luáº­n Ä‘á»ƒ Ä‘Æ°a ra phÃ¡n Ä‘oÃ¡n hoáº·c Ä‘i Ä‘áº¿n káº¿t luáº­n [31,51]. CÃ¡c nhÃ  nghiÃªn cá»©u xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP) Ä‘Ã£ phÃ¡t triá»ƒn cÃ¡c cÃ¡ch tiáº¿p cáº­n Ä‘á»ƒ lÃ½ luáº­n vá» cÃ¡c tÃ¬nh huá»‘ng cá»¥ thá»ƒ vÃ  cáº£i thiá»‡n hiá»‡u suáº¥t. Nhá»¯ng cÃ¡ch tiáº¿p cáº­n nhÆ° "Chain of thought" [66] vÃ  "step-by-step" [40] Ä‘Ã²i há»i viá»‡c táº¡o ra cÃ¡c káº¿t quáº£ trung gian ("lemma") vÃ  sá»­ dá»¥ng chÃºng trong nhiá»‡m vá»¥ hiá»‡n táº¡i. Nhá»¯ng cÃ¡ch tiáº¿p cáº­n nhÆ° váº­y dÆ°á»ng nhÆ° hoáº¡t Ä‘á»™ng trÃªn cÃ¡c váº¥n Ä‘á» Ä‘Æ¡n giáº£n hÆ¡n nhÆ° cÃ¡c bÃ i toÃ¡n toÃ¡n há»c á»Ÿ trÆ°á»ng tháº­m chÃ­ mÃ  khÃ´ng cung cáº¥p cho chÃºng "lemma", bá»Ÿi vÃ¬, Ä‘á»‘i vá»›i nhá»¯ng váº¥n Ä‘á» nÃ y, cÃ¡c mÃ´ hÃ¬nh Ä‘á»§ máº¡nh Ä‘á»ƒ táº¡o ra "lemma" cá»§a riÃªng chÃºng; trong má»™t sá»‘ trÆ°á»ng há»£p chá»‰ cáº§n thÃªm "hÃ£y suy nghÄ© tá»«ng bÆ°á»›c" dÆ°á»ng nhÆ° Ä‘á»§ (Kojima et al. [40]).

--- TRANG 3 ---
TÄƒng CÆ°á»ng Ngá»¯ NghÄ©a Tá»± Äá»™ng cá»§a Prompt MÃ´ HÃ¬nh NgÃ´n Ngá»¯
(cho TÃ³m Táº¯t MÃ£ Nguá»“n) ICSE '24, 14â€“20 thÃ¡ng 4, 2024, Lisbon, Bá»“ ÄÃ o Nha

ChÃºng tÃ´i Ä‘Ã£ thá»­ má»™t phiÃªn báº£n cáº£i tiáº¿n cá»§a prompt "step-by-step", vá»›i few-shots, trÃªn tÃ³m táº¯t mÃ£ nguá»“n. ChÃºng tÃ´i tháº¥y ráº±ng mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng kÃ©m (Ä‘áº¡t khoáº£ng 20.25 BLEU), tháº¥p hÆ¡n cáº£ baseline BM25 thuáº§n tÃºy cá»§a chÃºng tÃ´i (24.97 BLEU). Vá»›i prompt "step by step" zero-shot theo kiá»ƒu Kojima, cÃ¡c mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng tháº­m chÃ­ cÃ²n tá»‡ hÆ¡n. Äá»ƒ khiáº¿n mÃ´ hÃ¬nh táº¡o ra cÃ¡c bÆ°á»›c, vÃ  cuá»‘i cÃ¹ng lÃ  má»™t tÃ³m táº¯t, chÃºng tÃ´i Ä‘Ã£ Ä‘Ã³ng khung váº¥n Ä‘á» nhÆ° chain of thought, vÃ  bao gá»“m cÃ¡c máº«u few-shot chá»©a cáº£ cÃ¡c bÆ°á»›c trung gian ("lemma") vÃ  nháº­n xÃ©t cuá»‘i cÃ¹ng. LÃ½ luáº­n lÃ , trÃªn cÃ¡c nhiá»‡m vá»¥ (thÆ°á»ng lÃ  thÃ¡ch thá»©c) liÃªn quan Ä‘áº¿n mÃ£ nguá»“n, cÃ¡c mÃ´ hÃ¬nh cáº§n Ä‘Æ°á»£c cung cáº¥p rÃµ rÃ ng cÃ¡c "lemma" trung gian, Ä‘Æ°á»£c rÃºt ra tá»« mÃ£ nguá»“n, Ä‘á»ƒ cÃ³ thá»ƒ lÃ½ luáº­n hiá»‡u quáº£ vá» háº§u háº¿t cÃ¡c nhiá»‡m vá»¥ ká»¹ thuáº­t pháº§n má»m, cÃ³ xu hÆ°á»›ng phá»©c táº¡p vÃ  Ä‘a dáº¡ng hÆ¡n toÃ¡n há»c trÆ°á»ng há»c.

May máº¯n thay, cÃ¡c cÃ´ng cá»¥ phÃ¢n tÃ­ch mÃ£ nguá»“n trÆ°á»Ÿng thÃ nh cÃ³ sáºµn. ChÃºng tÃ´i cÃ³ thá»ƒ dá»… dÃ ng rÃºt ra "lemma", tá»©c lÃ , cÃ¡c sáº£n pháº©m phÃ¢n tÃ­ch, sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ phÃ¢n tÃ­ch mÃ£ nguá»“n, thay vÃ¬ mong Ä‘á»£i cÃ¡c mÃ´ hÃ¬nh (cÃ³ thá»ƒ ngáº§m) rÃºt ra chÃºng, trong quÃ¡ trÃ¬nh thá»±c hiá»‡n nhiá»‡m vá»¥. ChÃºng tÃ´i trá»±c tiáº¿p nhÃºng cÃ¡c sáº£n pháº©m phÃ¢n tÃ­ch vÃ o prompt mÃ  chÃºng tÃ´i Ä‘Æ°a cho mÃ´ hÃ¬nh ngÃ´n ngá»¯, vÃ  Ä‘Ã¡nh giÃ¡ lá»£i Ã­ch cá»§a nhá»¯ng sáº£n pháº©m phÃ¢n tÃ­ch nhÆ° váº­y. ThÃ´ng tin mÃ  chÃºng tÃ´i rÃºt ra vÃ  thÃªm vÃ o dá»±a trÃªn trá»±c giÃ¡c cá»§a chÃºng tÃ´i vá» cÃ¡c loáº¡i "lemma" mÃ  cÃ¡c láº­p trÃ¬nh viÃªn cÃ³ Ã½ thá»©c hoáº·c vÃ´ thá»©c xem xÃ©t khi há» tÃ¬m cÃ¡ch hiá»ƒu vÃ  tÃ³m táº¯t mÃ£ nguá»“n.

ChÃºng tÃ´i tháº¥y ráº±ng viá»‡c cung cáº¥p thÃ´ng tin nhÆ° váº­y cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a LLM. ChÃºng tÃ´i nháº¯c nhá»Ÿ ngÆ°á»i Ä‘á»c ráº±ng háº§u háº¿t cÃ´ng viá»‡c liÃªn quan Ä‘áº¿n cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) thÆ°á»ng sá»­ dá»¥ng má»™t sá»‘ hÃ¬nh thá»©c ká»¹ thuáº­t prompt engineering Ä‘á»ƒ tÄƒng hiá»‡u suáº¥t. Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i cho tháº¥y ráº±ng cÃ¡ch tiáº¿p cáº­n Ağ‘†ğ´ğ‘ƒ, tÄƒng cÆ°á»ng cÃ¡c prompt báº±ng cÃ¡c sáº£n pháº©m phÃ¢n tÃ­ch mÃ£ nguá»“n, cáº£i thiá»‡n so vá»›i cÃ¡c cÃ¡ch tiáº¿p cáº­n prompting trÆ°á»›c Ä‘Ã¢y.

2.3 TÃ³m Táº¯t MÃ£ Nguá»“n
MÃ£ nguá»“n Ä‘Æ°á»£c tÃ i liá»‡u hÃ³a tá»‘t dá»… báº£o trÃ¬ hÆ¡n nhiá»u; do Ä‘Ã³, cÃ¡c láº­p trÃ¬nh viÃªn cÃ³ kinh nghiá»‡m thÆ°á»ng thÃªm, vÃ­ dá»¥, header tÃ³m táº¯t hÃ m. Tuy nhiÃªn, cÃ¡c nháº­n xÃ©t tÃ³m táº¯t cÃ³ thá»ƒ trá»Ÿ nÃªn lá»—i thá»i, khi cÃ¡c dá»± Ã¡n phÃ¡t triá»ƒn [11,22]. TÃ³m táº¯t mÃ£ nguá»“n tá»± Ä‘á»™ng do Ä‘Ã³ lÃ  má»™t nhiá»‡m vá»¥ cÃ³ Ä‘á»™ng lá»±c tá»‘t, Ä‘Ã£ thu hÃºt ráº¥t nhiá»u sá»± chÃº Ã½; vÃ  tiáº¿n bá»™ Ä‘Ã¡ng ká»ƒ (máº·c dÃ¹ tá»«ng bÆ°á»›c, qua nhiá»u nÄƒm) Ä‘Ã£ Ä‘Æ°á»£c thá»±c hiá»‡n. Ban Ä‘áº§u, cÃ¡c cÃ¡ch tiáº¿p cáº­n dá»±a trÃªn template Ä‘Æ°á»£c Æ°a chuá»™ng [17, 26,27,56,61]; tuy nhiÃªn, viá»‡c táº¡o ra má»™t danh sÃ¡ch cÃ¡c template vá»›i Ä‘á»™ bao phá»§ tá»‘t lÃ  ráº¥t thÃ¡ch thá»©c. Sau Ä‘Ã³, cÃ¡c nhÃ  nghiÃªn cá»©u táº­p trung vÃ o cÃ¡ch tiáº¿p cáº­n dá»±a trÃªn truy xuáº¥t (IR) [17,26,27,56], nÆ¡i mÃ£ nguá»“n hiá»‡n cÃ³ (vá»›i má»™t tÃ³m táº¯t) Ä‘Æ°á»£c truy xuáº¥t dá»±a trÃªn cÃ¡c chá»‰ sá»‘ dá»±a trÃªn Ä‘á»™ tÆ°Æ¡ng tá»±. Tuy nhiÃªn, cÃ¡ch tiáº¿p cáº­n Ä‘áº§y há»©a háº¹n nÃ y chá»‰ hoáº¡t Ä‘á»™ng náº¿u má»™t cáº·p mÃ£-nháº­n xÃ©t tÆ°Æ¡ng tá»± cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y trong pool cÃ³ sáºµn.

Trong khi Ä‘Ã³, sá»± tÆ°Æ¡ng tá»± cá»§a tÃ³m táº¯t mÃ£ nguá»“n vá»›i Dá»‹ch Thuáº­t MÃ¡y Tháº§n Kinh (NMT), (ngÆ°á»i ta cÃ³ thá»ƒ nghÄ© vá» viá»‡c táº¡o ra má»™t tÃ³m táº¯t tiáº¿ng Anh cá»§a mÃ£ nguá»“n nhÆ° sáº£n xuáº¥t má»™t Ä‘áº¡i diá»‡n cá»§a "cÃ¹ng má»™t Ã½ nghÄ©a trong má»™t ngÃ´n ngá»¯ khÃ¡c") dáº«n Ä‘áº¿n nghiÃªn cá»©u Ã¡p dá»¥ng Dá»‹ch Thuáº­t MÃ¡y Tháº§n Kinh (NMT) cho tÃ³m táº¯t mÃ£ nguá»“n. Nhiá»u nghiÃªn cá»©u Ä‘Ã£ Ä‘Æ°á»£c thá»±c hiá»‡n trong lÄ©nh vá»±c nÃ y [1,30,33,41]. Má»™t sá»‘ Ä‘Ã£ káº¿t há»£p cÃ¡c cÃ¡ch tiáº¿p cáº­n trÆ°á»›c Ä‘Ã¢y, nhÆ° cÃ¡ch tiáº¿p cáº­n dá»±a trÃªn template vÃ  dá»±a trÃªn truy xuáº¥t, sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh tháº§n kinh [69], vÃ  Ä‘Ã£ bÃ¡o cÃ¡o káº¿t quáº£ Ä‘áº§y há»©a háº¹n. Nhá»¯ng phÆ°Æ¡ng phÃ¡p tháº§n kinh nhÆ° váº­y cho NLP Ä‘Ã£ Ä‘Æ°á»£c cáº£i thiá»‡n ráº¥t nhiá»u, nhá» vÃ o phong cÃ¡ch kiáº¿n trÃºc Transformer.

Cho Ä‘áº¿n gáº§n Ä‘Ã¢y, cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c nhÆ° CodeBERT, CodeT5, vÃ  CodeT5+ hoáº¡t Ä‘á»™ng tá»‘t nháº¥t cho tÃ³m táº¯t mÃ£ nguá»“n.

[HÃ¬nh 1: CÃ¡c bÆ°á»›c khÃ¡c nhau cá»§a Ağ‘†ğ´ğ‘ƒ. (1) MÃ£ nguá»“n Ä‘áº§u vÃ o vÃ  (2) Pool máº«u Ä‘Æ°á»£c Ä‘Æ°a cho cÃ´ng cá»¥ BM25, khá»›p mÃ£ nguá»“n Ä‘áº§u vÃ o Ä‘Ã£ cho vá»›i pool vÃ  (3) truy xuáº¥t cÃ¡c máº«u khá»›p nháº¥t, tá»©c lÃ  3 cáº·p input+output. Nhá»¯ng vÃ­ dá»¥ nÃ y Ä‘Æ°á»£c xá»­ lÃ½ bá»Ÿi Ağ‘†ğ´ğ‘ƒ Ä‘á»ƒ táº¡o ra má»™t prompt (4) bao gá»“m 3 exemplar. Má»—i exemplar bao gá»“m má»™t Ä‘á»‹nh nghÄ©a hÃ m, káº¿t quáº£ phÃ¢n tÃ­ch Ä‘á»‹nh nghÄ©a Ä‘Ã³, vÃ  nháº­n xÃ©t liÃªn quan cá»§a nÃ³; mÃ£ nguá»“n Ä‘áº§u vÃ o cuá»‘i cÃ¹ng Ä‘Æ°á»£c ná»‘i thÃªm, cÃ¹ng vá»›i sáº£n pháº©m phÃ¢n tÃ­ch cá»§a nÃ³. Chi tiáº¿t exemplar trong HÃ¬nh 2. Prompt cuá»‘i cÃ¹ng Ä‘Æ°á»£c gá»­i qua API call (5) Ä‘áº¿n mÃ´ hÃ¬nh GPT-3.x; Ä‘áº§u ra Ä‘Æ°á»£c tráº£ vá», vÃ­ dá»¥ tÃ³m táº¯t (6) Ä‘Æ°á»£c tráº£ vá» bá»Ÿi GPT-3x.]

Tuy nhiÃªn, cÃ¡c MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n (LLM) hiá»‡n thÆ°á»ng vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c nhá» hÆ¡n trong nhiá»u váº¥n Ä‘á». Ahmed & Devanbu [3] bÃ¡o cÃ¡o ráº±ng LLM cÃ³ thá»ƒ vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c vá»›i má»™t prompt Ä‘Æ¡n giáº£n chá»‰ bao gá»“m má»™t vÃ i máº«u Ä‘Ã£ cÃ³ trong cÃ¹ng dá»± Ã¡n; cÃ´ng viá»‡c nÃ y minh há»a sá»± há»©a háº¹n cá»§a viá»‡c xÃ¢y dá»±ng cáº©n tháº­n cÃ¡c cáº¥u trÃºc prompt (c.f. "ká»¹ thuáº­t prompt engineering"). ChÃºng tÃ´i trÃ¬nh bÃ y Ağ‘†ğ´ğ‘ƒ á»Ÿ Ä‘Ã¢y nhÆ° má»™t nguyÃªn táº¯c chung khÃ¡c cá»§a ká»¹ thuáº­t prompt engineering. ChÃºng tÃ´i nháº¥n máº¡nh, má»™t láº§n ná»¯a, ráº±ng tiáº¿n bá»™ trong tÃ³m táº¯t mÃ£ nguá»“n (vÃ  cÃ¡c á»©ng dá»¥ng khÃ¡c cá»§a AI cho SE, nhÆ° vÃ¡ mÃ£ nguá»“n, phÃ¡t hiá»‡n lá»—i, kiá»ƒm thá»­, v.v.) Ä‘Ã£ mang tÃ­nh tá»«ng bÆ°á»›c, nhÆ° trong lÄ©nh vá»±c NMT, nÆ¡i cÃ¡c há»‡ thá»‘ng dá»‹ch thuáº­t thá»±c táº¿, cÃ³ thá»ƒ sá»­ dá»¥ng Ä‘Æ°á»£c máº¥t hÃ ng tháº­p ká»· Ä‘á»ƒ xuáº¥t hiá»‡n. Do Ä‘Ã³ nhá»¯ng tiáº¿n bá»™ tá»«ng bÆ°á»›c váº«n cáº§n thiáº¿t, vÃ  há»¯u Ã­ch, vÃ  chÃºng tÃ´i Ä‘Ã³ng gÃ³p cÃ´ng viá»‡c cá»§a mÃ¬nh vÃ o doanh nghiá»‡p dÃ i háº¡n nÃ y.

3 Bá»˜ Dá»® LIá»†U & PHÆ¯Æ NG PHÃP
BÃ¢y giá» chÃºng tÃ´i tháº£o luáº­n vá» bá»™ dá»¯ liá»‡u, mÃ´ hÃ¬nh, vÃ  phÆ°Æ¡ng phÃ¡p cá»§a chÃºng tÃ´i.

3.1 Bá»™ Dá»¯ Liá»‡u
CÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i sá»­ dá»¥ng bá»™ dá»¯ liá»‡u CodeSearchNet [32] Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i; CodeSearchNet Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng cÃ¡ch trÃ­ch xuáº¥t Ä‘oáº¡n Ä‘áº§u tiÃªn cá»§a tÃ i liá»‡u tiá»n tá»‘ hÃ m, tÃ¹y thuá»™c vÃ o má»™t sá»‘ háº¡n cháº¿ (vÃ­ dá»¥ Ä‘á»™ dÃ i). ÄÃ¢y lÃ  má»™t bá»™ dá»¯ liá»‡u Ä‘a dá»± Ã¡n Ä‘Æ°á»£c khá»­ trÃ¹ng láº·p cáº©n tháº­n, cho phÃ©p kiá»ƒm thá»­ cross-project (Ä‘Ã²i há»i kháº¯t khe hÆ¡n). Khá»­ trÃ¹ng láº·p lÃ  chÃ¬a khÃ³a: Sá»± trÃ¹ng láº·p mÃ£ nguá»“n trong cÃ¡c mÃ´ hÃ¬nh machine learning cÃ³ thá»ƒ lÃ m tÄƒng cÃ¡c chá»‰ sá»‘ hiá»‡u suáº¥t má»™t cÃ¡ch lá»«a dá»‘i ráº¥t nhiá»u, khi so sÃ¡nh vá»›i cÃ¡c bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c khá»­ trÃ¹ng láº·p [7, 46, 59].

NÃ³ lÃ  má»™t pháº§n cá»§a benchmark CodeXGLUE [47], bao gá»“m 14 bá»™ dá»¯ liá»‡u cho 10 nhiá»‡m vá»¥ ká»¹ thuáº­t pháº§n má»m. Nhiá»u mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ trÃªn bá»™ dá»¯ liá»‡u nÃ y. CodeSearchNet chá»©a hÃ ng nghÃ¬n máº«u tá»« sÃ¡u ngÃ´n ngá»¯ láº­p trÃ¬nh khÃ¡c nhau (tá»©c lÃ , Java, Python, JavaScript, Ruby, Go, PHP). Tuy nhiÃªn, chÃºng tÃ´i khÃ´ng sá»­ dá»¥ng toÃ n bá»™ bá»™ dá»¯ liá»‡u kiá»ƒm thá»­, Ä‘iá»u nÃ y sáº½ quÃ¡ Ä‘áº¯t

--- TRANG 4 ---
ICSE '24, 14â€“20 thÃ¡ng 4, 2024, Lisbon, Bá»“ ÄÃ o Nha Toufique Ahmed, Kunal Suresh Pai, Premkumar Devanbu, vÃ  Earl T. Barr

[HÃ¬nh 2: CÃ¡c thÃ nh pháº§n cá»§a má»™t Ağ‘†ğ´ğ‘ƒ Exemplar. Source Code vÃ  Output Comment Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« máº«u pool Ä‘Æ°á»£c truy xuáº¥t. ThÃ´ng tin Repo Ä‘Æ°á»£c rÃºt ra tá»« mÃ£ nguá»“n sá»­ dá»¥ng GitHub; ThÃ´ng tin Dataflow vÃ  tagged Identifiers vá»›i nhÃ£n Ä‘Æ°á»£c thu tháº­p tá»« phÃ¢n tÃ­ch sá»­ dá»¥ng Treesitter.]

[THIS IS TABLE: Báº£ng 1: Sá»‘ lÆ°á»£ng máº«u huáº¥n luyá»‡n vÃ  kiá»ƒm thá»­.]
NgÃ´n ngá»¯ | Sá»‘ máº«u huáº¥n luyá»‡n | Sá»‘ máº«u kiá»ƒm thá»­
Java | 164,923 | 1000
Python | 251,820 | 1000
Ruby | 24,927 | 1000
JavaScript | 58,025 | 1000
Go | 167,288 | 1000
PHP | 241,241 | 1000

vÃ  cháº­m khi sá»­ dá»¥ng cÃ¡c endpoint API mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i; thay vÃ o Ä‘Ã³, chÃºng tÃ´i Ä‘Ã£ chá»n 1000 máº«uÂ³ má»™t cÃ¡ch ngáº«u nhiÃªn tá»« má»—i ngÃ´n ngá»¯. VÃ¬ bá»™ dá»¯ liá»‡u gá»‘c lÃ  cross-project vÃ  chÃºng tÃ´i láº¥y máº«u nÃ³ má»™t cÃ¡ch Ä‘á»“ng nháº¥t, máº«u con cá»§a chÃºng tÃ´i bao gá»“m dá»¯ liá»‡u cross-project. NgoÃ i ra, chÃºng tÃ´i Ä‘Ã£ táº¡o má»™t táº­p con cá»§a bá»™ dá»¯ liá»‡u nÃ y cho few-shotting cÃ¹ng dá»± Ã¡n, theo Ahmed vÃ  Devanbu [3]: chÃºng tÃ´i sáº¯p xáº¿p dá»¯ liá»‡u cÃ¹ng dá»± Ã¡n theo ngÃ y táº¡o (sá»­ dá»¥ng git blame). BÃ¢y giá», chÃºng tÃ´i sá»­ dá»¥ng thá»© tá»± thá»i gian Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng chá»‰ cÃ¡c máº«u trÆ°á»›c Ä‘Ã³ vá» máº·t thá»i gian Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c máº«u few-shot; Ä‘iá»u nÃ y lÃ  thá»±c táº¿, vÃ¬ chá»‰ dá»¯ liá»‡u cÅ©, Ä‘Ã£ tá»“n táº¡i má»›i cÃ³ sáºµn Ä‘á»ƒ sá»­ dá»¥ng.

ChÃºng tÃ´i sáº½ Ä‘i sÃ¢u hÆ¡n vÃ o bá»™ dá»¯ liá»‡u cÃ¹ng dá»± Ã¡n nÃ y trong Má»¥c 4.3.

NhÆ° Ä‘Ã£ Ä‘á» cáº­p trÆ°á»›c Ä‘Ã³, chÃºng tÃ´i khÃ´ng sá»­ dá»¥ng báº¥t ká»³ huáº¥n luyá»‡n thay Ä‘á»•i tham sá»‘ nÃ o trÃªn mÃ´ hÃ¬nh; chÃºng tÃ´i chá»‰ chÃ¨n má»™t vÃ i máº«u Ä‘Æ°á»£c chá»n tá»« táº­p con huáº¥n luyá»‡n vÃ o prompt few-shot. Báº£ng 1 liá»‡t kÃª sá»‘ lÆ°á»£ng máº«u huáº¥n luyá»‡n & kiá»ƒm thá»­ Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i.

3.2 CÃ¡c MÃ´ HÃ¬nh
Trong cÃ´ng viá»‡c trÆ°á»›c Ä‘Ã¢y, cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c dá»±a trÃªn transformer mang láº¡i lá»£i Ã­ch Ä‘Ã¡ng ká»ƒ, trong cáº£ NLP vÃ  ká»¹ thuáº­t pháº§n má»m. CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c cÃ³ thá»ƒ Ä‘Æ°á»£c chia thÃ nh ba danh má»¥c: mÃ´ hÃ¬nh chá»‰ encoder, encoder-decoder, vÃ  chá»‰ decoder. Trong khi cÃ¡c mÃ´ hÃ¬nh encoder-decoder ban Ä‘áº§u Ä‘Ã£ thá»ƒ hiá»‡n thÃ nh cÃ´ng trong nhiá»u nhiá»‡m vá»¥, cÃ¡c LLM chá»‰ decoder hiá»‡n cÃ³ thá»ƒ má»Ÿ rá»™ng vÃ  hiá»‡u quáº£ hÆ¡n cho nhiá»u nhiá»‡m vá»¥.

MÃ´ hÃ¬nh Encoder-Decoder. BERT lÃ  má»™t trong nhá»¯ng mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c sá»›m nháº¥t [15]; nÃ³ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c trÃªn hai nhiá»‡m vá»¥ tá»± giÃ¡m sÃ¡t: Masked Language Modeling (MLM) vÃ  Next Sentence Prediction (NSP). Sau Ä‘Ã³, RoBERTa [45] Ä‘Æ°á»£c giá»›i thiá»‡u vá»›i má»™t sá»‘ thay Ä‘á»•i nhá» so vá»›i BERT. Chá»‰ sá»­ dá»¥ng huáº¥n luyá»‡n MLM, nÃ³ vÆ°á»£t trá»™i hÆ¡n BERT. CodeBERT [21] vÃ  GraphCodeBERT [25] Ä‘Ã£ giá»›i thiá»‡u nhá»¯ng Ã½ tÆ°á»Ÿng nÃ y vÃ o Ká»¹ Thuáº­t Pháº§n Má»m. Máº·c dÃ¹ CodeBERT vÃ  GraphCodeBERT lÃ  cÃ¡c mÃ´ hÃ¬nh chá»‰ encoder, chÃºng cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng cho tÃ³m táº¯t mÃ£ nguá»“n sau khi fine-tuning, Ä‘Æ°á»£c cascaded vá»›i má»™t decoder Ä‘Æ°á»£c huáº¥n luyá»‡n trong quÃ¡ trÃ¬nh fine-tuning. Ahmed & Devanbu bÃ¡o cÃ¡o ráº±ng cÃ¡c mÃ´ hÃ¬nh polyglot, Ä‘Æ°á»£c fine-tuned vá»›i dá»¯ liá»‡u Ä‘a ngÃ´n ngá»¯, vÆ°á»£t trá»™i hÆ¡n cÃ¡c Ä‘á»‘i tÃ¡c Ä‘Æ¡n ngÃ´n ngá»¯ cá»§a chÃºng [4]. Há» cÅ©ng bÃ¡o cÃ¡o ráº±ng cÃ¡c Ä‘á»‹nh danh Ä‘Ã³ng má»™t vai trÃ² quan trá»ng trong cÃ¡c nhiá»‡m vá»¥ tÃ³m táº¯t mÃ£ nguá»“n. PLBART [2], CodeT5 [64], vÃ  CodeT5+ [63] cÅ©ng bao gá»“m cÃ¡c decoder Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c vÃ  Ä‘Æ°á»£c bÃ¡o cÃ¡o lÃ  hoáº¡t Ä‘á»™ng tá»‘t cho cÃ¡c nhiá»‡m vá»¥ tÃ³m táº¯t mÃ£ nguá»“n. Gáº§n Ä‘Ã¢y hÆ¡n, cÃ¡c LLM tá»± há»“i quy quy mÃ´ ráº¥t lá»›n (chá»‰ decoder) (vá»›i 175B+ tham sá»‘) Ä‘Ã£ Ä‘Æ°á»£c tÃ¬m tháº¥y lÃ  thÃ nh cÃ´ng trong tÃ³m táº¯t mÃ£ nguá»“n vá»›i há»c few-shot, mÃ  khÃ´ng cáº§n báº¥t ká»³ huáº¥n luyá»‡n rÃµ rÃ ng nÃ o. Trong pháº§n tiáº¿p theo, chÃºng tÃ´i sáº½ giá»›i thiá»‡u ngáº¯n gá»n ba mÃ´ hÃ¬nh OpenAI mÃ  chÃºng tÃ´i Ä‘Ã£ xem xÃ©t cho cÃ¡c thÃ­ nghiá»‡m cá»§a mÃ¬nh.

Â³Vui lÃ²ng xem tháº£o luáº­n vá» sá»©c máº¡nh thÃ­ nghiá»‡m trong Má»¥c 7.

MÃ´ hÃ¬nh Chá»‰ Decoder. Trong generative pre-training, nhiá»‡m vá»¥ lÃ  dá»± Ä‘oÃ¡n token tiáº¿p theo má»™t cÃ¡ch tá»± há»“i quy dá»±a trÃªn cÃ¡c token trÆ°á»›c Ä‘Ã³ di chuyá»ƒn tá»« sá»›m Ä‘áº¿n muá»™n. Viá»‡c huáº¥n luyá»‡n tá»± há»“i quy má»™t chiá»u nÃ y ngÄƒn cáº£n mÃ´ hÃ¬nh táº­p há»£p thÃ´ng tin tá»« cÃ¡c token tÆ°Æ¡ng lai. CÃ¡c mÃ´ hÃ¬nh generative má»›i hÆ¡n nhÆ° GPT [52], GPT-2 [53] vÃ  GPT-3 [12], cÅ©ng Ä‘Æ°á»£c huáº¥n luyá»‡n theo cÃ¡ch nÃ y, nhÆ°ng chÃºng cÃ³ nhiá»u tham sá»‘ hÆ¡n, vÃ  Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c bá»™ dá»¯ liá»‡u lá»›n hÆ¡n nhiá»u. CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n hiá»‡n táº¡i, nhÆ° GPT-3, cÃ³ khoáº£ng (hoáº·c nhiá»u hÆ¡n) 175B tham sá»‘. Nhá»¯ng mÃ´ hÃ¬nh máº¡nh máº½ nÃ y hoáº¡t Ä‘á»™ng tá»‘t Ä‘áº¿n má»©c, vá»›i few-shot prompting, mÃ  sá»± quan tÃ¢m Ä‘áº¿n viá»‡c Ä‘iá»u chá»‰nh tham sá»‘ cá»¥ thá»ƒ cho nhiá»‡m vá»¥ thÃ´ng qua fine-tuning Ä‘Ã£ giáº£m.

Codex lÃ  má»™t biáº¿n thá»ƒ GPT-3, Ä‘Æ°á»£c huáº¥n luyá»‡n máº¡nh máº½ trÃªn mÃ£ nguá»“n vÃ  nháº­n xÃ©t ngÃ´n ngá»¯ tá»± nhiÃªn. Gia Ä‘Ã¬nh Codex bao gá»“m hai phiÃªn báº£n: Codex-Cushman, nhá» hÆ¡n, vá»›i 12B tham sá»‘, vÃ  Codex-Davinci, lá»›n nháº¥t, vá»›i 175B tham sá»‘. MÃ´ hÃ¬nh Codex Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i, cho nhiá»u nhiá»‡m vá»¥ khÃ¡c nhau. CÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i chá»§ yáº¿u nháº¯m vÃ o mÃ´ hÃ¬nh Code-Davinci, Ä‘áº·c biá»‡t lÃ  Code-Davinci-002, xuáº¥t sáº¯c trong viá»‡c dá»‹ch ngÃ´n ngá»¯ tá»± nhiÃªn sang mÃ£ nguá»“n [14] vÃ  há»— trá»£ hoÃ n thÃ nh mÃ£ nguá»“n cÅ©ng nhÆ° chÃ¨n mÃ£ nguá»“nâ´. Má»™t sá»‘ biáº¿n thá»ƒ má»›i, Text-Davinci-003 & GPT-3.5-turbo, cÅ©ng cÃ³ sáºµn; khÃ¡c vá»›i cÃ¡c biáº¿n thá»ƒ Codex, nhá»¯ng mÃ´ hÃ¬nh nÃ y hiá»ƒu vÃ  táº¡o ra cáº£ ngÃ´n ngá»¯ tá»± nhiÃªn vÃ  mÃ£ nguá»“n. Máº·c dÃ¹ Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a cho chat, GPT-3.5-turbo cÅ©ng hoáº¡t Ä‘á»™ng tá»‘t trong cÃ¡c nhiá»‡m vá»¥ completion truyá»n thá»‘ng. Text-Davinci-003 lÃ  má»™t mÃ´ hÃ¬nh completion nhÆ° Code-Davinci-002. ChÃºng tÃ´i nghiÃªn cá»©u cÃ¡ch cáº£i tiáº¿n prompt cá»§a chÃºng tÃ´i hoáº¡t Ä‘á»™ng báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh Text-Davinci-003 & GPT-3.5-turbo.

3.3 Truy Xuáº¥t Máº«u tá»« Dá»¯ Liá»‡u Huáº¥n Luyá»‡n
NhÆ° Ä‘Ã£ lÆ°u Ã½ trÆ°á»›c Ä‘Ã³, há»c few-shot hoáº¡t Ä‘á»™ng khÃ¡ tá»‘t, khi Ä‘Æ°á»£c sá»­ dá»¥ng vá»›i cÃ¡c mÃ´ hÃ¬nh ráº¥t lá»›n. ChÃºng tÃ´i nháº¯c nhá»Ÿ mÃ´ hÃ¬nh vá»›i má»™t sá»‘ lÆ°á»£ng nhá» cÃ¡c máº«u âŸ¨problem,solutionâŸ©, vÃ  yÃªu cáº§u nÃ³ giáº£i quyáº¿t má»™t váº¥n Ä‘á» má»›i. Tuy nhiÃªn, viá»‡c lá»±a chá»n máº«u cáº©n tháº­n cho há»c few-shot lÃ  há»¯u Ã­ch. Nashid et al. Ä‘Ã£ phÃ¡t hiá»‡n ra ráº±ng viá»‡c chá»n máº«u dá»±a trÃªn truy xuáº¥t lÃ  há»¯u Ã­ch cho cÃ¡c váº¥n Ä‘á» nhÆ° táº¡o assertion vÃ  sá»­a chá»¯a chÆ°Æ¡ng trÃ¬nh [48]. Theo khuyáº¿n nghá»‹ cá»§a há», chÃºng tÃ´i sá»­ dá»¥ng thuáº­t toÃ¡n IR BM25 Ä‘á»ƒ chá»n cÃ¡c máº«u few-shot liÃªn quan tá»« táº­p huáº¥n luyá»‡n. BM25 [55] lÃ  má»™t phÆ°Æ¡ng phÃ¡p truy xuáº¥t dá»±a trÃªn táº§n suáº¥t cáº£i thiá»‡n so vá»›i TF-IDF [54]. ChÃºng tÃ´i lÆ°u Ã½ sá»± cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¹ng nhá»¯ng máº«u cá»‘ Ä‘á»‹nh trong há»c few-shot, nhÆ° Ä‘Æ°á»£c chi tiáº¿t trong Má»¥c 4.1. Nashid et al. so sÃ¡nh má»™t sá»‘ phÆ°Æ¡ng phÃ¡p truy xuáº¥t, vÃ  tháº¥y BM25 hoáº¡t Ä‘á»™ng tá»‘t nháº¥t; do Ä‘Ã³ chÃºng tÃ´i cÅ©ng sá»­ dá»¥ng nÃ³.

â´https://openai.com/

3.4 TÄƒng CÆ°á»ng Prompt Ngá»¯ NghÄ©a Tá»± Äá»™ng
Pháº§n nÃ y trÃ¬nh bÃ y ba sá»± kiá»‡n ngá»¯ nghÄ©a mÃ  chÃºng tÃ´i Ä‘Ã£ chá»n Ä‘á»ƒ tÄƒng cÆ°á»ng prompt cá»§a Ağ‘†ğ´ğ‘ƒ vÃ  pipeline Ağ‘†ğ´ğ‘ƒ (Xem HÃ¬nh 2). Viá»‡c lá»±a chá»n nhá»¯ng sá»± kiá»‡n nÃ y Ä‘áº¿n tá»« viá»‡c Ã¡p dá»¥ng giáº£ thuyáº¿t trung tÃ¢m cá»§a chÃºng tÃ´i, tá»©c lÃ  viá»‡c tÄƒng cÆ°á»ng prompt báº±ng nhá»¯ng gÃ¬ cÃ¡c láº­p trÃ¬nh viÃªn nghÄ© vá» khi lÃ m viá»‡c trÃªn má»™t nhiá»‡m vá»¥, cho nhiá»‡m vá»¥ tÃ³m táº¯t mÃ£ nguá»“n. Ağ‘†ğ´ğ‘ƒ khÃ´ng gáº¯n liá»n vá»›i báº¥t ká»³ sá»± kiá»‡n ngá»¯ nghÄ©a cá»¥ thá»ƒ nÃ o hoáº·c phÃ¢n tÃ­ch tÄ©nh; nÃ³ cÃ³ thá»ƒ dá»… dÃ ng káº¿t há»£p nhá»¯ng cÃ¡i khÃ¡c, nhÆ° Ä‘Æ°á»£c tháº£o luáº­n sau.

TÃªn Repository & ÄÆ°á»ng Dáº«n. Viá»‡c tÄƒng cÆ°á»ng prompt báº±ng thÃ´ng tin cá»¥ thá»ƒ cho domain cÃ³ thá»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a LLM trong nhiá»u nhiá»‡m vá»¥. NghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y cho tháº¥y ráº±ng viá»‡c tÄƒng cÆ°á»ng prompt báº±ng mÃ£ nguá»“n tá»« cÃ¹ng repository cáº£i thiá»‡n hiá»‡u suáº¥t trong cÃ¡c nhiá»‡m vá»¥ táº¡o mÃ£ nguá»“n [60]. ChÃºng tÃ´i láº­p luáº­n ráº±ng thÃ´ng tin meta cÆ¡ báº£n á»Ÿ cáº¥p repository, nhÆ° tÃªn repository vÃ  Ä‘Æ°á»ng dáº«n Ä‘áº§y Ä‘á»§ Ä‘áº¿n repository, cung cáº¥p ngá»¯ cáº£nh bá»• sung. VÃ­ dá»¥, tÃªn repository nhÆ° "tony19/logback âˆ’android", "apache/parquet âˆ’mr", vÃ  "ngageoint/geoâˆ’package âˆ’android" Ä‘á»u káº¿t ná»‘i má»™t hÃ m vá»›i má»™t domain cá»¥ thá»ƒ (vÃ­ dá»¥, android, apache, geo-location), cÃ³ thá»ƒ tÄƒng cÆ°á»ng hiá»ƒu biáº¿t vá» mÃ£ nguá»“n má»¥c tiÃªu cáº§n tÃ³m táº¯t. HÃ¬nh 2 (pháº§n mÃ u vÃ ng) trÃ¬nh bÃ y má»™t vÃ­ dá»¥ vá» cÃ¡ch chÃºng tÃ´i tÄƒng cÆ°á»ng prompt báº±ng thÃ´ng tin cáº¥p repository. TÆ°Æ¡ng tá»± nhÆ° tÃªn repository, Ä‘Æ°á»ng dáº«n Ä‘áº¿n hÃ m cÅ©ng cÃ³ thá»ƒ Ä‘Ã³ng gÃ³p cho mÃ´ hÃ¬nh.

Tagged Identifiers. NghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y cho tháº¥y ráº±ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ tÃ¬m tháº¥y giÃ¡ trá»‹ nhiá»u hÆ¡n trong cÃ¡c Ä‘á»‹nh danh, thay vÃ¬ cáº¥u trÃºc mÃ£ nguá»“n, khi táº¡o ra tÃ³m táº¯t mÃ£ nguá»“n [4]. Tuy nhiÃªn, cÃ¡c Ä‘á»‹nh danh Ä‘Ã³ng cÃ¡c vai trÃ² khÃ¡c nhau trong mÃ£ nguá»“n. Biáº¿n cá»¥c bá»™, tÃªn hÃ m, tham sá»‘, biáº¿n toÃ n cá»¥c, v.v., Ä‘Ã³ng cÃ¡c vai trÃ² khÃ¡c nhau trong hoáº¡t Ä‘á»™ng cá»§a phÆ°Æ¡ng thá»©c mÃ  chÃºng xuáº¥t hiá»‡n; má»™t láº­p trÃ¬nh viÃªn Ä‘á»c mÃ£ nguá»“n cháº¯c cháº¯n nháº­n thá»©c Ä‘Æ°á»£c cÃ¡c vai trÃ² cá»§a Ä‘á»‹nh danh, chá»‰ Ä‘Æ¡n giáº£n báº±ng cÃ¡ch xÃ¡c Ä‘á»‹nh pháº¡m vi vÃ  cÃ¡ch sá»­ dá»¥ng. Do Ä‘Ã³, viá»‡c tÄƒng cÆ°á»ng prompt báº±ng cÃ¡c vai trÃ² cá»¥ thá»ƒ cá»§a cÃ¡c Ä‘á»‹nh danh cÃ³ thá»ƒ giÃºp mÃ´ hÃ¬nh "hiá»ƒu" hÃ m tá»‘t hÆ¡n. ChÃºng tÃ´i sá»­ dá»¥ng tree-sitter Ä‘á»ƒ duyá»‡t AST cá»§a hÃ m vÃ  thu tháº­p cÃ¡c Ä‘á»‹nh danh, cÃ¹ng vá»›i vai trÃ² cá»§a chÃºng. HÃ¬nh 2 (pháº§n mÃ u xanh) trÃ¬nh bÃ y má»™t vÃ­ dá»¥ máº«u cho tháº¥y cÃ¡ch chÃºng tÃ´i tÄƒng cÆ°á»ng prompt cá»§a hÃ m báº±ng tagged identifiers.

Máº·c dÃ¹ mÃ´ hÃ¬nh cÃ³ quyá»n truy cáº­p vÃ o chuá»—i token cá»§a mÃ£ nguá»“n, vÃ  do Ä‘Ã³ cÅ©ng táº¥t cáº£ cÃ¡c Ä‘á»‹nh danh, viá»‡c cung cáº¥p chÃºng cho mÃ´ hÃ¬nh dÆ°á»›i dáº¡ng tagged cÃ³ thá»ƒ a) tiáº¿t kiá»‡m cho mÃ´ hÃ¬nh má»™t sá»‘ ná»— lá»±c tÃ­nh toÃ¡n, vÃ  b) Ä‘iá»u kiá»‡n tá»‘t hÆ¡n Ä‘áº§u ra cá»§a mÃ´ hÃ¬nh.

Data Flow Graph (DFG). Guo et al. Ä‘Ã£ giá»›i thiá»‡u mÃ´ hÃ¬nh GraphcodeBERT, sá»­ dá»¥ng Ä‘á»“ thá»‹ luá»“ng dá»¯ liá»‡u (DFG) thay vÃ¬ cáº¥u trÃºc cáº¥p cÃº phÃ¡p nhÆ° cÃ¢y cÃº phÃ¡p trá»«u tÆ°á»£ng (AST) trong giai Ä‘oáº¡n pre-training [25]. GraphcodeBERT vÆ°á»£t trá»™i hÆ¡n CodeBERT [21] trong nhiá»u nhiá»‡m vá»¥ ká»¹ thuáº­t pháº§n má»m (SE). ChÃºng tÃ´i káº¿t há»£p thÃ´ng tin DFG nÃ y vÃ o cÃ¡c máº«u few-shot; chÃºng tÃ´i suy Ä‘oÃ¡n ráº±ng Ä‘iá»u nÃ y cung cáº¥p cho mÃ´ hÃ¬nh má»™t hiá»ƒu biáº¿t ngá»¯ nghÄ©a tá»‘t hÆ¡n vá» má»—i máº«u, vÃ  vÃ­ dá»¥ má»¥c tiÃªu. HÃ¬nh 2 (mÃ u cam) trÃ¬nh bÃ y má»™t máº«u cho tháº¥y Data Flow Graph (DFG) mÃ  chÃºng tÃ´i Ä‘Ã£ sá»­ dá»¥ng cho cÃ¡c thÃ­ nghiá»‡m cá»§a mÃ¬nh. Má»—i dÃ²ng chá»©a má»™t Ä‘á»‹nh danh vá»›i chá»‰ sá»‘ cá»§a nÃ³ vÃ  chá»‰ sá»‘ cá»§a cÃ¡c Ä‘á»‹nh danh mÃ  dá»¯ liá»‡u Ä‘áº·c biá»‡t Ä‘Ã³ cháº£y tá»›i. KhÃ¡c vá»›i repo vÃ  tagged identifiers, Ä‘á»“ thá»‹ luá»“ng dá»¯ liá»‡u cÃ³ thá»ƒ ráº¥t dÃ i, khiáº¿n viá»‡c thÃªm luá»“ng dá»¯ liá»‡u hoÃ n chá»‰nh vÃ o prompt trá»Ÿ nÃªn báº¥t tiá»‡n. Trong trÆ°á»ng há»£p prompt dÃ i, chÃºng tÃ´i chá»‰ giá»¯ 30 dÃ²ng Ä‘áº§u tiÃªn cá»§a DFG trong prompt. NgoÃ i cÃ¡c Ä‘á»‹nh danh, DFG cÅ©ng cung cáº¥p hiá»ƒu biáº¿t tá»‘t hÆ¡n vá» táº§m quan trá»ng cá»§a cÃ¡c Ä‘á»‹nh danh trong hÃ m.

Use Case & Completion Pipeline. Ağ‘†ğ´ğ‘ƒ cÃ³ 3 thÃ nh pháº§n: má»™t LLM, má»™t pool cÃ¡c máº«u cÃ³ sáºµn (cÃ¡c cáº·p Ä‘áº§u vÃ o-Ä‘áº§u ra Ä‘Æ°á»£c gáº¯n nhÃ£n, vÃ­ dá»¥, mÃ£ nguá»“n vá»›i nháº­n xÃ©t), vÃ  má»™t cÃ´ng cá»¥ phÃ¢n tÃ­ch tÄ©nh Ä‘á»ƒ rÃºt ra sá»± kiá»‡n tá»« mÃ£ nguá»“n (Xem HÃ¬nh 1 vÃ  2).

Má»™t tá»‡p cáº¥u hÃ¬nh chá»‰ Ä‘á»‹nh nhá»¯ng thÃ nh pháº§n nÃ y. Sau khi Ä‘Æ°á»£c cáº¥u hÃ¬nh, má»™t láº­p trÃ¬nh viÃªn gá»i Ağ‘†ğ´ğ‘ƒ trÃªn má»™t thÃ¢n hÃ m ğ¶ğ‘–ğ‘› (HÃ¬nh 1), mÃ  má»™t Ä‘áº§u ra (vÃ­ dá»¥, tÃ³m táº¯t mÃ£ nguá»“n) Ä‘Æ°á»£c mong muá»‘n. Ağ‘†ğ´ğ‘ƒ sá»­ dá»¥ng ğ¶ğ‘–ğ‘› nhÆ° má»™t truy váº¥n BM25 trÃªn pool máº«u cá»§a nÃ³ Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c má»™t táº­p káº¿t quáº£ cÃ¡c á»©ng viÃªn máº«u ec1,ec2,..., nÆ¡i má»—i ecğ‘– lÃ  má»™t cáº·p cÃ³ dáº¡ng âŸ¨inputğ‘–,outputğ‘–âŸ©; trong ngá»¯ cáº£nh cá»§a chÃºng tÃ´i, inputğ‘– lÃ  Ä‘á»‹nh nghÄ©a hÃ m vÃ  outputğ‘– lÃ  nháº­n xÃ©t header hÃ m. BM25 chá»n nhá»¯ng inputğ‘– khá»›p tá»‘t nháº¥t vá»›i ğ¶ğ‘–ğ‘› Ä‘Ã£ cho. Ağ‘†ğ´ğ‘ƒ sau Ä‘Ã³ Ã¡p dá»¥ng phÃ¢n tÃ­ch chÆ°Æ¡ng trÃ¬nh cho cáº£ Ä‘áº§u vÃ o ğ¶ğ‘–ğ‘› vÃ  má»™t sá»‘ Ä‘áº§u vÃ o máº«u inputğ‘–, táº¡o ra cÃ¡c sáº£n pháº©m phÃ¢n tÃ­ch ğ‘ğ‘ğ‘–ğ‘› vÃ  má»™t sá»‘ ğ‘ğ‘ğ‘–.

Má»—i máº«u ğ‘’ğ‘– (HÃ¬nh 2) lÃ  bá»™ ba: âŸ¨inputğ‘–,apğ‘–,outputğ‘–âŸ©, nÆ¡i má»—i bá»™ ba minh há»a, cho LLM, cÃ¡ch mÃ£ nguá»“n Ä‘áº§u vÃ o inputğ‘– liÃªn quan, thÃ´ng qua sáº£n pháº©m phÃ¢n tÃ­ch ğ‘ğ‘ğ‘–, vá»›i Ä‘áº§u ra outputğ‘–. Prompt cuá»‘i cÃ¹ng sau Ä‘Ã³ lÃ  "ğ‘’1||ğ‘’2||ğ‘’3||ğ¶ğ‘–ğ‘›||apğ‘–ğ‘›". Ağ‘†ğ´ğ‘ƒ truy váº¥n má»™t LLM vá»›i prompt Ä‘Ã³, vÃ  tráº£ vá» completion (vÃ­ dá»¥, tÃ³m táº¯t ngÃ´n ngá»¯ tá»± nhiÃªn).

Theo máº·c Ä‘á»‹nh, Ağ‘†ğ´ğ‘ƒ Ä‘Æ°á»£c cáº¥u hÃ¬nh vá»›i cÃ¡c phÃ¢n tÃ­ch Ä‘á»ƒ trÃ­ch xuáº¥t thÃ´ng tin repo, gáº¯n tháº» Ä‘á»‹nh danh, xÃ¢y dá»±ng DFG. Nhá»¯ng phÃ¢n tÃ­ch nÃ y Ä‘á»™c láº­p vÃ  cÃ¡c Ä‘áº§u ra cá»§a chÃºng Ä‘Æ°á»£c gáº¯n nhÃ£n riÃªng biá»‡t trong prompt. VÃ­ dá»¥, HÃ¬nh 2 cho tháº¥y Ä‘áº§u ra cá»§a phÃ¢n tÃ­ch DFG trong prompt Ä‘Æ°á»£c xÃ¢y dá»±ng cá»§a Ağ‘†ğ´ğ‘ƒ. Nhá»¯ng vÃ­ dá»¥ few shot nÃ y, Ä‘Æ°á»£c tÄƒng cÆ°á»ng vÃ  chÃ¨n vÃ o prompt: mÃ£ nguá»“n, thÃ´ng tin repository, tagged identifiers, DFG, vÃ  tÃ³m táº¯t mong muá»‘n (Gold) Ä‘á»u Ä‘Æ°á»£c bao gá»“m trong má»—i few-shot. VÃ­ dá»¥ má»¥c tiÃªu chá»‰ bao gá»“m sáº£n pháº©m phÃ¢n tÃ­ch, vÃ  LLM Ä‘Æ°á»£c nháº¯c nhá»Ÿ Ä‘á»ƒ táº¡o ra Ä‘áº§u ra mong muá»‘n.

Trong nghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y sá»­ dá»¥ng "chain of thought" [66] hoáº·c "step by step" [40] reasoning, khÃ´ng cÃ³ thÃ´ng tin nhÆ° váº­y Ä‘Æ°á»£c Ä‘Æ°a cho mÃ´ hÃ¬nh; thay vÃ o Ä‘Ã³, prompt chá»‰ Ä‘Æ¡n giáº£n giÃºp nÃ³ tá»• chá»©c lÃ½ luáº­n cá»§a mÃ¬nh vá» máº«u thÃ nh má»™t chuá»—i hÆ°á»›ng dáº«n. á» Ä‘Ã¢y, thay vÃ¬ Ä‘á»ƒ mÃ´ hÃ¬nh lÃ m lÃ½ luáº­n cá»§a riÃªng mÃ¬nh, chÃºng tÃ´i Ä‘á»‹nh hÃ¬nh lÃ½ luáº­n cá»§a nÃ³ tá»« bÃªn ngoÃ i báº±ng cÃ¡ch sá»­ dá»¥ng phÃ¢n tÃ­ch chÆ°Æ¡ng trÃ¬nh Ä‘Æ¡n giáº£n, vÃ¬ chÃºng tÃ´i cÃ³ thá»ƒ nháº­n Ä‘Æ°á»£c thÃ´ng tin ráº¥t chÃ­nh xÃ¡c tá»« cÃ¡c cÃ´ng cá»¥ phÃ¢n tÃ­ch ráº¥t hiá»‡u quáº£. Má»—i vÃ­ dá»¥ few-shot bao gá»“m mÃ£ nguá»“n, thÃ´ng tin rÃºt ra, vÃ  káº¿t luáº­n (tÃ³m táº¯t), do Ä‘Ã³ cung cáº¥p cÃ¡c "chains of thought" máº«u cho mÃ´ hÃ¬nh sá»­ dá»¥ng ngáº§m khi táº¡o ra tÃ³m táº¯t má»¥c tiÃªu mong muá»‘n. HÃ¬nh 1 trÃ¬nh bÃ y pipeline tá»•ng thá»ƒ cá»§a cÃ¡ch tiáº¿p cáº­n cá»§a chÃºng tÃ´i mÃ  chÃºng tÃ´i Ã¡p dá»¥ng cho má»—i máº«u. CÃ´ng cá»¥ BM25 khá»›p mÃ£ nguá»“n Ä‘áº§u vÃ o vá»›i pool máº«u, Ağ‘†ğ´ğ‘ƒ xá»­ lÃ½ cÃ¡c vÃ­ dá»¥ káº¿t quáº£ Ä‘á»ƒ táº¡o ra má»™t prompt, vÃ  prompt cuá»‘i cÃ¹ng Ä‘Æ°á»£c gá»­i Ä‘áº¿n mÃ´ hÃ¬nh GPT-3.x qua API, táº¡o ra má»™t tÃ³m táº¯t nhÆ° Ä‘áº§u ra.

Tiáº¿p theo, chÃºng tÃ´i mÃ´ táº£ cÃ¡ch chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ pipeline nÃ y.

3.5 Chá»‰ Sá»‘
BLEU [50] lÃ  thÆ°á»›c Ä‘o dá»±a trÃªn Ä‘á»™ tÆ°Æ¡ng tá»± Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i nháº¥t cho tÃ³m táº¯t mÃ£ nguá»“n [57] vÃ  táº¡o commit log [16]. BLEU Ä‘áº¿m pháº§n cá»§a cÃ¡c ğ‘›-gram (thÆ°á»ng cho ğ‘›âˆˆ[1..4]), xuáº¥t hiá»‡n trong cáº£ á»©ng viÃªn Ä‘Æ°á»£c táº¡o ra vÃ  má»™t hoáº·c nhiá»u báº£n dá»‹ch tham chiáº¿u; trung bÃ¬nh nhÃ¢n cá»§a nhá»¯ng pháº§n nÃ y lÃ  BLEU, thÆ°á»ng Ä‘Æ°á»£c chuáº©n hÃ³a thÃ nh pháº¡m vi 0-100. á» má»©c Ä‘á»™ chi tiáº¿t cÃ¢u, BLEU cÃ³ xu hÆ°á»›ng pháº¡t quÃ¡ má»©c cÃ¡c báº£n dá»‹ch á»©ng viÃªn khi Ã­t (hoáº·c khÃ´ng cÃ³) cÃ¡c n-gram dÃ i hÆ¡n cÃ¹ng xuáº¥t hiá»‡n, vÃ¬ váº­y "Sentence BLEU" Ä‘Ã£ bá»‹ chá»‰ trÃ­ch vÃ¬ tÆ°Æ¡ng quan kÃ©m vá»›i Ä‘Ã¡nh giÃ¡ cá»§a con ngÆ°á»i. CÃ¡c ká»¹ thuáº­t lÃ m má»‹n khÃ¡c nhau [13,23,44] Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng, Ä‘á»ƒ giáº£m Ä‘á»™ nháº¡y cáº£m cá»§a Sentence BLEU vá»›i cÃ¡c khá»›p ğ‘›-gram thÆ°a thá»›t, vÃ  canh chá»‰nh nÃ³ tá»‘t hÆ¡n vá»›i Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng cá»§a con ngÆ°á»i. ChÃºng tÃ´i bÃ¡o cÃ¡o dá»¯ liá»‡u vá» hai biáº¿n thá»ƒ: BLEU-CN, sá»­ dá»¥ng má»™t loáº¡i lÃ m má»‹n Laplacian [2,3,8,21,33,47,64] vÃ  BLEU-DC, sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p lÃ m má»‹n má»›i hÆ¡n [29,65]. CÃ¡c chá»‰ sá»‘ khÃ¡c Ä‘Æ°á»£c Ä‘á» xuáº¥t nhÆ° BERTScore [28,70], BLEURT [58], NUBIA [37], tá»‘n kÃ©m vá» máº·t tÃ­nh toÃ¡n, khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i vÃ  do Ä‘Ã³ khÃ´ng dá»… dÃ ng so sÃ¡nh vá»›i cÃ´ng viá»‡c trÆ°á»›c Ä‘Ã¢y Ä‘á»ƒ benchmarking.

Vá»›i táº¥t cáº£ nhá»¯ng lá»±a chá»n nÃ y, cÃ¡c chá»‰ sá»‘ cho tÃ³m táº¯t mÃ£ nguá»“n vÃ , Ä‘á»™c láº­p, cho táº¡o commit-log [16], Ä‘Ã£ Ä‘Æ°á»£c tranh luáº­n [24, 28,57]. Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i theo nghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y vÃ  chá»§ yáº¿u sá»­ dá»¥ng BLEU-CN; Ä‘iá»u nÃ y táº¡o Ä‘iá»u kiá»‡n cho viá»‡c so sÃ¡nh káº¿t quáº£ cá»§a chÃºng tÃ´i vá»›i nghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y. Benchmark CodeXGLUE khuyáº¿n nghá»‹ BLEU-CN, vÃ  háº§u háº¿t cÃ¡c mÃ´ hÃ¬nh má»›i hÆ¡n [3,21,64] sá»­ dá»¥ng chá»‰ sá»‘ nÃ y. Tuy nhiÃªn, chÃºng tÃ´i Ä‘Ã£ khÃ´ng bá» qua cÃ¡c biá»‡n phÃ¡p khÃ¡c. NgoÃ i BLEU-CN, vÃ  BLEU-DC, chÃºng tÃ´i cÅ©ng bÃ¡o cÃ¡o káº¿t quáº£ sá»­ dá»¥ng ROUGE-L [43] vÃ  METEOR [9].

Trong táº¥t cáº£ cÃ¡c trÆ°á»ng há»£p, Ağ‘†ğ´ğ‘ƒ Ä‘áº¡t Ä‘Æ°á»£c cáº£i thiá»‡n tá»•ng thá»ƒ Ä‘Ã¡ng ká»ƒ: chÃºng tÃ´i quan sÃ¡t tháº¥y lá»£i Ã­ch lá»›n hÆ¡n 2.0 BLEU cho táº¥t cáº£ cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh ngoáº¡i trá»« Go (Báº£ng 3). ChÃºng tÃ´i kháº³ng Ä‘á»‹nh ráº±ng lá»£i Ã­ch lá»›n hÆ¡n 2.0 BLEU quan trá»ng vÃ¬ hai lÃ½ do. Roy et al. [57] cung cáº¥p láº­p luáº­n, dá»±a trÃªn nghiÃªn cá»©u chá»§ thá»ƒ con ngÆ°á»i ráº±ng Ä‘á»‘i vá»›i tÃ³m táº¯t mÃ£ nguá»“n (nhiá»‡m vá»¥ trung tÃ¢m cá»§a chÃºng tÃ´i), ráº±ng lá»£i Ã­ch 2.0 trá»Ÿ lÃªn BLEU cÃ³ nhiá»u kháº£ nÄƒng tÆ°Æ¡ng á»©ng vá»›i nháº­n thá»©c cáº£i thiá»‡n cá»§a con ngÆ°á»i. Thá»© hai, chÃºng tÃ´i láº­p luáº­n ráº±ng tháº­m chÃ­ lá»£i Ã­ch nhá» hÆ¡n cÅ©ng quan trá»ng (Ä‘áº·c biá»‡t náº¿u cÃ³ thá»ƒ láº·p láº¡i vÃ  cÃ³ Ã½ nghÄ©a thá»‘ng kÃª) vÃ¬ tiáº¿n bá»™ tá»«ng bÆ°á»›c trong nhá»¯ng nhiá»‡m vá»¥ nhÆ° váº­y tÃ­ch lÅ©y, hÆ°á»›ng tá»›i tÃ¡c Ä‘á»™ng thá»±c táº¿ máº¡nh máº½, nhÆ° Ä‘Æ°á»£c chá»©ng minh bá»Ÿi cÃ´ng viá»‡c kÃ©o dÃ i hÃ ng tháº­p ká»· trong dá»‹ch thuáº­t ngÃ´n ngá»¯ tá»± nhiÃªn.

NgoÃ i tÃ³m táº¯t mÃ£ nguá»“n, chÃºng tÃ´i Ä‘Ã£ Ä‘Ã¡nh giÃ¡ cÃ¡ch tiáº¿p cáº­n Ağ‘†ğ´ğ‘ƒ trong nhiá»‡m vá»¥ hoÃ n thÃ nh mÃ£ nguá»“n. CÃ¡c chá»‰ sá»‘ tiÃªu chuáº©n Ä‘Æ°á»£c sá»­ dá»¥ng cho nhiá»‡m vá»¥ nÃ y lÃ  khá»›p chÃ­nh xÃ¡c (completion cÃ³ khá»›p chÃ­nh xÃ¡c khÃ´ng) vÃ  Ä‘á»™ tÆ°Æ¡ng tá»± chá»‰nh sá»­a (completion gáº§n vá»›i chuá»—i mong Ä‘á»£i nhÆ° tháº¿ nÃ o). á» Ä‘Ã¢y cÅ©ng váº­y, Ağ‘†ğ´ğ‘ƒ Ä‘áº¡t Ä‘Æ°á»£c cáº£i thiá»‡n tá»•ng thá»ƒ Ä‘Ã¡ng ká»ƒ.

3.6 Thiáº¿t Láº­p ThÃ­ Nghiá»‡m & TiÃªu ChÃ­ ÄÃ¡nh GiÃ¡
MÃ´ hÃ¬nh chÃ­nh cá»§a chÃºng tÃ´i lÃ  code-davinci-002 cá»§a OpenAI. ChÃºng tÃ´i sá»­ dá»¥ng phiÃªn báº£n beta, thÃ´ng qua API dá»‹ch vá»¥ web cá»§a nÃ³. Äá»ƒ cÃ¢n báº±ng cÃ¡c rÃ ng buá»™c tÃ­nh toÃ¡n nhÆ° giá»›i háº¡n tá»‘c Ä‘á»™ vÃ  mong muá»‘n Æ°á»›c lÆ°á»£ng máº¡nh máº½ hiá»‡u suáº¥t, chÃºng tÃ´i Ä‘Ã£ chá»n sá»­ dá»¥ng 1000 máº«uâµ má»—i xá»­ lÃ½ thÃ­ nghiá»‡m (má»™t xá»­ lÃ½ cho má»—i ngÃ´n ngá»¯, má»—i cÃ¡ch tiáº¿p cáº­n chá»n few-shot, vá»›i Ağ‘†ğ´ğ‘ƒ, khÃ´ng cÃ³ Ağ‘†ğ´ğ‘ƒ, v.v.).

CÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i mang láº¡i káº¿t quáº£ cÃ³ Ã½ nghÄ©a thá»‘ng kÃª, cÃ³ thá»ƒ giáº£i thÃ­ch trong háº§u háº¿t cÃ¡c trÆ°á»ng há»£p. Má»—i thá»­ nghiá»‡m 1000 máº«u váº«n máº¥t 5 Ä‘áº¿n 8 tiáº¿ng, thay Ä‘á»•i (cÃ³ thá»ƒ) vá»›i cÃ¡c yáº¿u tá»‘ táº£i cá»§a OpenAI. ChÃºng tÃ´i bao gá»“m thá»i gian chá» giá»¯a cÃ¡c láº§n thá»­, theo khuyáº¿n nghá»‹ cá»§a OpenAI. Äá»ƒ cÃ³ Ä‘Æ°á»£c cÃ¢u tráº£ lá»i Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a rÃµ rÃ ng tá»« mÃ´ hÃ¬nh, chÃºng tÃ´i tháº¥y cáº§n thiáº¿t pháº£i Ä‘áº·t temperature thÃ nh 0, cho táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i. MÃ´ hÃ¬nh Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cho phÃ©p má»™t cá»­a sá»• khoáº£ng 4K token; Ä‘iá»u nÃ y giá»›i háº¡n sá»‘ lÆ°á»£ng máº«u few-shot. Cho cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i, chÃºng tÃ´i sá»­ dá»¥ng 3 shot. Ağ‘†ğ´ğ‘ƒ máº·c Ä‘á»‹nh 3 shot vÃ¬ nghiÃªn cá»©u liÃªn quan [3,12] Ä‘Ã£ cho tháº¥y, vÃ  cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i vá»›i Ağ‘†ğ´ğ‘ƒ Ä‘Ã£ xÃ¡c nháº­n, ráº±ng nhiá»u shot hÆ¡n khÃ´ng cáº£i thiá»‡n hiá»‡u suáº¥t Ä‘Ã¡ng ká»ƒ. Tuy nhiÃªn, Ä‘á»‘i vá»›i tá»‘i Ä‘a 2% cÃ¡c máº«u Ä‘Æ°á»£c chá»n ngáº«u nhiÃªn trong má»—i thÃ­ nghiá»‡m, chÃºng tÃ´i khÃ´ng cÃ³ Ä‘Æ°á»£c káº¿t quáº£ tá»‘t; hoáº·c prompt khÃ´ng vá»«a vÃ o cá»­a sá»• cá»§a mÃ´ hÃ¬nh, hoáº·c mÃ´ hÃ¬nh má»™t cÃ¡ch bÃ­ áº©n táº¡o ra chuá»—i trá»‘ng. Trong cÃ¡c trÆ°á»ng há»£p prompt nhÆ° Ä‘Æ°á»£c xÃ¢y dá»±ng vá»›i 3 máº«u quÃ¡ dÃ i, chÃºng tÃ´i tá»± Ä‘á»™ng giáº£m sá»‘ lÆ°á»£ng shot. Khi tÃ³m táº¯t trá»‘ng Ä‘Æ°á»£c phÃ¡t ra, chÃºng tÃ´i giáº£i quyáº¿t Ä‘iá»u nÃ y báº±ng cÃ¡ch tÄƒng sá»‘ lÆ°á»£ng shot. Quy trÃ¬nh Ä‘Æ¡n giáº£n, cÃ³ thá»ƒ láº·p láº¡i, chi phÃ­ khiÃªm tá»‘n nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c káº¿t há»£p vÃ o cÃ¡c cÃ´ng cá»¥ tÃ³m táº¯t tá»± Ä‘á»™ng.

âµVui lÃ²ng xem Má»¥c 7 Ä‘á»ƒ biáº¿t lÃ½ do.

4 Káº¾T QUáº¢
ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ lá»£i Ã­ch cá»§a cÃ¡c prompt Ä‘Æ°á»£c tÄƒng cÆ°á»ng Ağ‘†ğ´ğ‘ƒ, cho tÃ³m táº¯t mÃ£ nguá»“n, trong cÃ¡c thiáº¿t láº­p khÃ¡c nhau vÃ  sá»­ dá»¥ng nhiá»u chá»‰ sá»‘. ChÃºng tÃ´i tÃ¬m tháº¥y báº±ng chá»©ng vá» lá»£i Ã­ch hiá»‡u suáº¥t tá»•ng thá»ƒ, trong cÃ¡c nghiÃªn cá»©u trÃªn sÃ¡u ngÃ´n ngá»¯. Tuy nhiÃªn, Ä‘á»‘i vá»›i cÃ¡c phÃ¢n tÃ­ch chi tiáº¿t khÃ¡c, chÃºng tÃ´i táº­p trung chá»§ yáº¿u vÃ o Java vÃ  Python, do giá»›i háº¡n tá»‘c Ä‘á»™ API OpenAI.

4.1 Encoder-decoder & Há»c Few-shot
Káº¿t quáº£ baseline cá»§a chÃºng tÃ´i trÃªn CodeSearchNet [47], sá»­ dá»¥ng few-shotting dá»±a trÃªn IR, Ä‘áº¿n trÆ°á»›c. NghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y bÃ¡o cÃ¡o ráº±ng cÃ¡c phÆ°Æ¡ng phÃ¡p IR cÃ³ thá»ƒ tÃ¬m tháº¥y máº«u tá»‘t hÆ¡n cho few-shot prompting, cho cÃ¡c nhiá»‡m vá»¥ nhÆ° sá»­a chá»¯a chÆ°Æ¡ng trÃ¬nh [48] vÃ  táº¡o mÃ£ nguá»“n [34]. Trong Báº£ng 2, chÃºng tÃ´i quan sÃ¡t tháº¥y ráº±ng Ä‘iá»u nÃ y cÅ©ng Ä‘Ãºng cho tÃ³m táº¯t mÃ£ nguá»“n; chÃºng tÃ´i lÆ°u Ã½ cáº£i thiá»‡n 3.00 (15.10%) vÃ  1.12 (5.42%) trong Ä‘iá»ƒm BLEU-4 cho Java vÃ  Python, tÆ°Æ¡ng á»©ng, chá»‰ Ä‘Æ¡n giáº£n báº±ng cÃ¡ch sá»­ dá»¥ng BM25 nhÆ° má»™t cÆ¡ cháº¿ chá»n máº«u few-shot. VÃ¬ BM25 Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng trong bÃ i bÃ¡o trÆ°á»›c Ä‘Ã¢y (máº·c dÃ¹ cho cÃ¡c nhiá»‡m vá»¥ khÃ¡c) [48], chÃºng tÃ´i coi há»c few-shot dá»±a trÃªn BM25 nÃ y cho tÃ³m táº¯t mÃ£ nguá»“n chá»‰ lÃ  má»™t baseline (khÃ´ng pháº£i lÃ  má»™t Ä‘Ã³ng gÃ³p per se) cá»§a bÃ i bÃ¡o nÃ y.

4.2 TÄƒng CÆ°á»ng Prompt Ağ‘†ğ´ğ‘ƒ
BÃ¢y giá» chÃºng tÃ´i táº­p trung vÃ o káº¿t quáº£ trung tÃ¢m cá»§a bÃ i bÃ¡o cá»§a chÃºng tÃ´i: tÃ¡c Ä‘á»™ng cá»§a tÄƒng cÆ°á»ng prompt Ağ‘†ğ´ğ‘ƒ. Báº£ng 3 cho tháº¥y cáº£i thiá»‡n theo tá»«ng thÃ nh pháº§n vÃ  tá»•ng thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c sau khi káº¿t há»£p táº¥t cáº£ cÃ¡c thÃ nh pháº§n prompting cho táº¥t cáº£ sÃ¡u ngÃ´n ngá»¯ láº­p trÃ¬nh. Cáº£i thiá»‡n BLEU dao Ä‘á»™ng tá»« 1.84 (8.12%) Ä‘áº¿n 4.58 (16.27%). Trong háº§u háº¿t cÃ¡c trÆ°á»ng há»£p, chÃºng tÃ´i tháº¥y cáº£i thiá»‡n trÃªn 2.0 BLEU, ngÆ°á»¡ng cáº§n thiáº¿t cho nháº­n thá»©c cá»§a con ngÆ°á»i Ä‘Æ°á»£c lÆ°u Ã½ bá»Ÿi Roy et al. [57].

ChÃºng tÃ´i cÅ©ng lÆ°u Ã½ ráº±ng cáº£ ba thÃ nh pháº§n (tá»©c lÃ , ThÃ´ng tin Repository, DFG Data Flow Graph, Identifiers) giÃºp mÃ´ hÃ¬nh Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tá»‘t hÆ¡n trong táº¥t cáº£ sÃ¡u ngÃ´n ngá»¯, khi chÃºng tÃ´i káº¿t há»£p nhá»¯ng thÃ nh pháº§n nÃ y tá»«ng cÃ¡i má»™t vá»›i BM25. Tuy nhiÃªn, Ä‘á»‘i vá»›i Ruby, sá»± káº¿t há»£p hoáº¡t Ä‘á»™ng tá»‘t nháº¥t chá»‰ bao gá»“m thÃ´ng tin Repo. Trong háº§u háº¿t cÃ¡c trÆ°á»ng há»£p, Repo. giÃºp Ã­ch ráº¥t nhiá»u, tÆ°Æ¡ng Ä‘á»‘i so vá»›i cÃ¡c thÃ nh pháº§n khÃ¡c.

Äá»ƒ xÃ¡c Ä‘á»‹nh Ã½ nghÄ©a cáº£i thiá»‡n, chÃºng tÃ´i Ä‘Ã£ sá»­ dá»¥ng kiá»ƒm Ä‘á»‹nh cáº·p Ä‘Ã´i má»™t phÃ­a Wilcoxon signed-rank, tÃ¬m tháº¥y Ã½ nghÄ©a thá»‘ng kÃª trong táº¥t cáº£ cÃ¡c trÆ°á»ng há»£p cho prompt cuá»‘i cÃ¹ng cá»§a chÃºng tÃ´i khi so sÃ¡nh vá»›i há»c few-shot BM25 thuáº§n tÃºy, tháº­m chÃ­ sau khi Ä‘iá»u chá»‰nh rá»§i ro phÃ¡t hiá»‡n sai.

4.3 TÃ³m Táº¯t MÃ£ Nguá»“n CÃ¹ng Dá»± Ãn
BÃ¢y giá» chÃºng tÃ´i xem xÃ©t lá»£i Ã­ch cá»§a Ağ‘†ğ´ğ‘ƒ trong bá»‘i cáº£nh má»™t sá»‘ nghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y vá» chá»n few-shot. NghiÃªn cá»©u trÆ°á»›c Ä‘Ã¢y Ä‘Ã£ cho tháº¥y ráº±ng viá»‡c chá»n few-shot tá»« cÃ¹ng dá»± Ã¡n cáº£i thiá»‡n hiá»‡u suáº¥t Ä‘Ã¡ng ká»ƒ [3]. Äá»ƒ xem liá»‡u Ã½ tÆ°á»Ÿng tÄƒng cÆ°á»ng prompt cá»§a chÃºng tÃ´i cÃ³ tiáº¿p tá»¥c giÃºp trong tÃ³m táº¯t mÃ£ nguá»“n cá»¥ thá»ƒ cho dá»± Ã¡n khÃ´ng, chÃºng tÃ´i Ä‘Ã£ Ä‘Ã¡nh giÃ¡ cÃ¡ch tiáº¿p cáº­n cá»§a mÃ¬nh trÃªn bá»™ dá»¯ liá»‡u tá»« Ahmed vÃ  Devanbu [3]. Do giá»›i háº¡n tá»‘c Ä‘á»™, chÃºng tÃ´i Ä‘Ã£ giáº£m sá»‘ lÆ°á»£ng máº«u kiá»ƒm thá»­ xuá»‘ng 100 cho má»—i dá»± Ã¡n trong bá»‘n dá»± Ã¡n Java vÃ  Python. VÃ¬ chÃºng tÃ´i cÃ³ quÃ¡ Ã­t máº«u cho má»™t kiá»ƒm thá»­ má»—i dá»± Ã¡n, chÃºng tÃ´i Ä‘Ã£ káº¿t há»£p táº¥t cáº£ cÃ¡c máº«u Ä‘á»ƒ thá»±c hiá»‡n

--- TRANG 7 ---
TÄƒng CÆ°á»ng Ngá»¯ NghÄ©a Tá»± Äá»™ng cá»§a Prompt MÃ´ HÃ¬nh NgÃ´n Ngá»¯
(cho TÃ³m Táº¯t MÃ£ Nguá»“n) ICSE '24, 14â€“20 thÃ¡ng 4, 2024, Lisbon, Bá»“ ÄÃ o Nha

[THIS IS TABLE: Báº£ng 2 - Hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh encoder-decoder vÃ  few-shot trÃªn tÃ³m táº¯t mÃ£ nguá»“n Java vÃ  Python, Ä‘o báº±ng BLEU]
NgÃ´n ngá»¯ | CodeBERT | GraphCodeBERT | Polyglot CodeBERT | Polyglot GraphcodeBERT | CodeT5 | CodeT5+ | Few-shot (ngáº«u nhiÃªn) | Few-shot vá»›i BM25 | Lá»£i Ã­ch (%) so vá»›i ngáº«u nhiÃªn few-shot
Java | 18.8 | 18.52 | 20.22 | 19.94 | 19.78 | 19.83 | 19.87 | 22.87 | +15.10%
Python | 17.73 | 17.35 | 18.19 | 18.33 | 19.98 | 18.85 | 20.66 | 21.78 | +5.42%

[THIS IS TABLE: Báº£ng 3 - Hiá»‡u suáº¥t cá»§a táº¡o nháº­n xÃ©t tÄƒng cÆ°á»ng prompt vá»›i mÃ´ hÃ¬nh code-davinci-002, Ä‘o báº±ng BLEU]
NgÃ´n ngá»¯ | BM25 | BM25+repo | BM25+id | BM25+DFG | Ağ‘†ğ´ğ‘ƒ | So sÃ¡nh vá»›i BM25 - Lá»£i Ã­ch (%) so vá»›i BM25 | p-value
Java | 22.87 | 25.23 | 23.39 | 23.13 | 25.41 | +11.11% | <0.01
Python | 21.78 | 24.22 | 22.54 | 21.82 | 24.26 | +11.39% | <0.01
Ruby | 17.21 | 19.67 | 19.19 | 17.55 | 19.62 | +14.00% | <0.01
JavaScript | 23.27 | 25.11 | 24.21 | 24.04 | 25.36 | +8.98% | <0.01
Go | 22.67 | 24.41 | 23.2 | 23.42 | 24.51 | +8.12% | <0.01
PHP | 28.15 | 32.07 | 29.8 | 28.92 | 32.73 | +16.27% | <0.01
Tá»•ng thá»ƒ | 22.66 | 25.12 | 23.72 | 23.15 | 25.32 | +11.74% | <0.01

kiá»ƒm Ä‘á»‹nh thá»‘ng kÃª. LÆ°u Ã½ ráº±ng tá»•ng cá»¡ máº«u cá»§a chÃºng tÃ´i cho kiá»ƒm Ä‘á»‹nh thá»‘ng kÃª vÆ°á»£t quÃ¡ sá»‘ lÆ°á»£ng máº«u cáº§n thiáº¿t Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh thÃ´ng qua phÃ¢n tÃ­ch Ä‘Æ°á»£c Ä‘á» cáº­p trong Má»¥c 7. Khi lÃ m viá»‡c vá»›i cÃ¹ng dá»± Ã¡n, ngÆ°á»i ta pháº£i chia dá»¯ liá»‡u cáº©n tháº­n, Ä‘á»ƒ trÃ¡nh rÃ² rá»‰ tá»« cÃ¡c máº«u tÆ°Æ¡ng lai (nÆ¡i Ä‘áº§u ra mong muá»‘n cÃ³ thá»ƒ Ä‘Ã£ tá»“n táº¡i) sang cÃ¡c máº«u quÃ¡ khá»©. Do Ä‘Ã³, chÃºng tÃ´i Ä‘Ã£ sáº¯p xáº¿p cÃ¡c máº«u theo ngÃ y táº¡o trong bá»™ dá»¯ liá»‡u nÃ y. Sau khi táº¡o ra bá»™ dá»¯ liá»‡u, chÃºng tÃ´i Ã¡p dá»¥ng cÃ¡ch tiáº¿p cáº­n cá»§a mÃ¬nh Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t trong thiáº¿t láº­p cÃ¹ng dá»± Ã¡n. ChÃºng tÃ´i cÅ©ng so sÃ¡nh káº¿t quáº£ cá»§a mÃ¬nh vá»›i thiáº¿t láº­p cross-project, nÆ¡i chÃºng tÃ´i truy xuáº¥t cÃ¡c máº«u tá»« táº­p huáº¥n luyá»‡n cross-project hoÃ n chá»‰nh, tÆ°Æ¡ng tá»± nhÆ° thiáº¿t láº­p Ä‘Æ°á»£c sá»­ dá»¥ng trong Má»¥c 4.2.

[THIS IS TABLE: Báº£ng 4 - Hiá»‡u suáº¥t cá»§a táº¡o nháº­n xÃ©t tÄƒng cÆ°á»ng prompt vá»›i mÃ´ hÃ¬nh code-davinci-002 trÃªn dá»¯ liá»‡u cÃ¹ng dá»± Ã¡n]
[Table shows performance metrics for different projects with cross-project and same-project comparisons]

Báº£ng 4 cho tháº¥y káº¿t quáº£ tÃ³m táº¯t mÃ£ nguá»“n dá»±a trÃªn dá»± Ã¡n. LÆ°u Ã½ ráº±ng Ä‘Ã¢y lÃ  má»™t tÃ¬nh huá»‘ng cá»¥ thá»ƒ cho dá»± Ã¡n nÆ¡i dá»¯ liá»‡u hoÃ n toÃ n khÃ´ng cÃ³ sáºµn. Dá»¯ liá»‡u huáº¥n luyá»‡n cho má»—i dá»± Ã¡n ráº¥t háº¡n cháº¿. ChÃºng tÃ´i tháº¥y ráº±ng, Ä‘á»‘i vá»›i 4 dá»± Ã¡n, há»c few-shot cross-project mang láº¡i hiá»‡u suáº¥t tá»‘t nháº¥t; trong khi, Ä‘á»‘i vá»›i 4 dá»± Ã¡n khÃ¡c, há»c few-shot cÃ¹ng dá»± Ã¡n hiá»‡u quáº£ nháº¥t. ChÃºng tÃ´i lÆ°u Ã½ ráº±ng Ahmed & Devanbu khÃ´ng sá»­ dá»¥ng IR Ä‘á»ƒ chá»n máº«u few-shot vÃ  luÃ´n luÃ´n Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ tá»‘t hÆ¡n vá»›i há»c few-shot cÃ¹ng dá»± Ã¡n [3]. IR thá»±c sá»± tÃ¬m tháº¥y cÃ¡c vÃ­ dá»¥ liÃªn quan trong cÃ¡c máº«u lá»›n cÃ³ sáºµn cho Java & Python, vÃ  chÃºng tÃ´i cÃ³ Ä‘Æ°á»£c káº¿t quáº£ tá»‘t. ChÃºng tÃ´i Ä‘Ã£ phÃ¢n tÃ­ch 16 cáº·p BLEU trung bÃ¬nh tá»« 8 dá»± Ã¡n, xem xÃ©t cáº£ tÃ¬nh huá»‘ng cross-project vÃ  cÃ¹ng dá»± Ã¡n. Há»c few-shot tÄƒng cÆ°á»ng prompt cá»§a chÃºng tÃ´i vÆ°á»£t trá»™i hÆ¡n há»c few-shot truy xuáº¥t BM25 thuáº§n tÃºy trong 14 trÆ°á»ng há»£p (87.5%). Äiá»u nÃ y cho tháº¥y ráº±ng tÄƒng cÆ°á»ng prompt Ağ‘†ğ´ğ‘ƒ há»¯u Ã­ch trÃªn cÃ¡c dá»± Ã¡n. Ağ‘†ğ´ğ‘ƒ cáº£i thiá»‡n hiá»‡u suáº¥t má»™t cÃ¡ch cÃ³ Ã½ nghÄ©a thá»‘ng kÃª trong cáº£ thiáº¿t láº­p cross-project vÃ  cÃ¹ng dá»± Ã¡n.

4.4 Ağ‘†ğ´ğ‘ƒ cÃ³ Báº¥t Kháº£ Tri MÃ´ HÃ¬nh khÃ´ng?
Káº¿t quáº£ cá»§a chÃºng tÃ´i cho Ä‘áº¿n nay liÃªn quan Ä‘áº¿n cÃ¡c mÃ´ hÃ¬nh code-davinci-002. ChÃºng tÃ´i cÅ©ng Ä‘Ã£ cung cáº¥p cÃ¡c prompt tÄƒng cÆ°á»ng Ağ‘†ğ´ğ‘ƒ cho hai mÃ´ hÃ¬nh khÃ¡c, text-davinci-003 & gpt-3.5-turbo (mÃ´ hÃ¬nh chat). CÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i trong Báº£ng 6. CÃ¡ch tiáº¿p cáº­n há»c few-shot tÄƒng cÆ°á»ng prompt cá»§a chÃºng tÃ´i Ä‘Ã£ cáº£i thiá»‡n

--- TRANG 8 ---
ICSE '24, 14â€“20 thÃ¡ng 4, 2024, Lisbon, Bá»“ ÄÃ o Nha Toufique Ahmed, Kunal Suresh Pai, Premkumar Devanbu, vÃ  Earl T. Barr

[THIS IS TABLE: Báº£ng 5 - Hiá»‡u suáº¥t cá»§a prompt tÄƒng cÆ°á»ng Ağ‘†ğ´ğ‘ƒ vá»›i mÃ´ hÃ¬nh code-davinci-002 trÃªn nhiá»‡m vá»¥ hoÃ n thÃ nh dÃ²ng]
NgÃ´n ngá»¯ | Sá»‘ máº«u | Exact Match (EM) | Edit Similarity (ES)
         |        | Zero-shot | Ağ‘†ğ´ğ‘ƒ | Lá»£i Ã­ch (%) | p-value | Zero-shot | Ağ‘†ğ´ğ‘ƒ | Lá»£i Ã­ch (%) | p-value
Java     | 9292   | 20.75     | 22.12 | +6.6%      | <0.01   | 55.35     | 59.66 | +7.79%     | <0.01
Python   | 6550   | 14.05     | 14.58 | +3.77%     | 0.13    | 49.71     | 50.12 | +0.82%     | <0.01
Tá»•ng thá»ƒ | 15842  | 17.97     | 19.01 | +5.79%     | <0.01   | 53.01     | 55.72 | +5.11%     | <0.01

[THIS IS TABLE: Báº£ng 6 - Hiá»‡u suáº¥t trÃªn tÃ³m táº¯t mÃ£ nguá»“n, Ä‘o báº±ng BLEU]
NgÃ´n ngá»¯ | MÃ´ hÃ¬nh           | BM25  | Ağ‘†ğ´ğ‘ƒ  | Lá»£i Ã­ch | p-value
Java     | Code-davinci-002  | 23.90 | 25.78 | +7.87%  | <0.01
         | Text-davinci-003  | 18.98 | 22.31 | +17.54% | <0.01
         | Turbo-GPT-3.5    | 16.68 | 16.96 | +1.68%  | 0.95
Python   | Code-davinci-002  | 22.00 | 24.78 | +12.64% | <0.01
         | Text-davinci-003  | 16.74 | 18.93 | +13.08% | <0.01
         | Turbo-GPT-3.5    | 15.01 | 16.38 | +9.13%  | <0.01
PHP      | Code-davinci-002  | 28.42 | 33.52 | +17.95% | <0.01
         | Text-davinci-003  | 21.67 | 25.72 | +18.69% | <0.01
         | Turbo-GPT-3.5    | 18.48 | 19.99 | +8.17%  | <0.01

hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh gpt-3.5-turbo tá»« 1.68% Ä‘áº¿n 9.13% vÃ  mÃ´ hÃ¬nh text-davinci-003 tá»« 13.08% Ä‘áº¿n 18.69% trÃªn 500 máº«u má»—i tá»« Java, Python, PHP.

Gpt-3.5-turbo hoáº¡t Ä‘á»™ng tá»‡ hÆ¡n so vá»›i cÃ¡c mÃ´ hÃ¬nh code-davinci-002 vÃ  text-davinci-003 trong tÃ³m táº¯t mÃ£ nguá»“n. PhiÃªn báº£n Turbo rÆ°á»m rÃ  vÃ  táº¡o ra cÃ¡c nháº­n xÃ©t khÃ¡c vá» máº·t vÄƒn phong so vá»›i nhá»¯ng nháº­n xÃ©t Ä‘Æ°á»£c viáº¿t bá»Ÿi cÃ¡c láº­p trÃ¬nh viÃªn, vÃ  cÅ©ng khÃ¡c vá»›i cÃ¡c máº«u few-shot trong prompt. Ká»¹ thuáº­t prompt-engineering cáº©n tháº­n cÃ³ thá»ƒ cáº£i thiá»‡n mÃ´ hÃ¬nh turbo vÃ  cho phÃ©p nÃ³ táº¡o ra cÃ¡c nháº­n xÃ©t tá»± nhiÃªn, ngáº¯n gá»n hÆ¡n; Ä‘iá»u nÃ y Ä‘Æ°á»£c Ä‘á»ƒ láº¡i cho cÃ´ng viá»‡c tÆ°Æ¡ng lai. Hiá»‡u suáº¥t kÃ©m nÃ y bá»Ÿi mÃ´ hÃ¬nh chat phÃ¹ há»£p vá»›i cÃ¡c phÃ¡t hiá»‡n cá»§a KocoÅ„ et al. [39]. MÃ´ hÃ¬nh Text-davinci-003 cho tháº¥y sá»± gia tÄƒng hiá»‡u suáº¥t tá»‘i Ä‘a (máº·c dÃ¹ váº«n bá»‹ vÆ°á»£t qua bá»Ÿi code-davinci-002). LÆ°u Ã½ ráº±ng text-davinci-003 lÃ  má»™t mÃ´ hÃ¬nh completion, giá»‘ng nhÆ° code-davinci-002. CÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i cho tháº¥y ráº±ng Ağ‘†ğ´ğ‘ƒ hiá»‡u quáº£ hÆ¡n vá»›i cÃ¡c mÃ´ hÃ¬nh completion hÆ¡n lÃ  cÃ¡c mÃ´ hÃ¬nh chat. ChÃºng tÃ´i cÅ©ng Ä‘Ã£ thá»±c hiá»‡n cÃ¡c kiá»ƒm Ä‘á»‹nh cáº·p Ä‘Ã´i má»™t phÃ­a Wilcoxon signed rank, vÃ  Ã½ nghÄ©a thá»‘ng kÃª cá»§a cÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i (trá»« java vá»›i gpt-3.5-turbo) cho tháº¥y ráº±ng Ağ‘†ğ´ğ‘ƒ sáº½ Ã¡p dá»¥ng vÆ°á»£t ra ngoÃ i chá»‰ mÃ´ hÃ¬nh code-davinci-002 gá»‘c.

4.5 Ağ‘†ğ´ğ‘ƒ cho Completion
Trá»ng tÃ¢m chÃ­nh cá»§a chÃºng tÃ´i cho Ä‘áº¿n nay lÃ  tÃ³m táº¯t mÃ£ nguá»“n, trong thiáº¿t láº­p few-shot. á» Ä‘Ã¢y, chÃºng tÃ´i khÃ¡m phÃ¡ xem Ağ‘†ğ´ğ‘ƒ cÃ³ hoáº¡t Ä‘á»™ng trÃªn má»™t nhiá»‡m vá»¥ khÃ¡c khÃ´ng: hoÃ n thÃ nh mÃ£ nguá»“n, trong thiáº¿t láº­p zero-shot nÆ¡i khÃ´ng cÃ³ vÃ­ dá»¥ nÃ o Ä‘Æ°á»£c hiá»ƒn thá»‹ hoáº·c trÃ¬nh bÃ y cho mÃ´ hÃ¬nh. ChÃºng tÃ´i Ä‘Ã£ Ä‘Ã¡nh giÃ¡ giÃ¡ trá»‹ cá»§a viá»‡c bao gá»“m cÃ¡c sá»± kiá»‡n ngá»¯ nghÄ©a cho nhiá»‡m vá»¥ hoÃ n thÃ nh dÃ²ng, nÆ¡i mÃ´ hÃ¬nh táº¡o ra dÃ²ng tiáº¿p theo dá»±a trÃªn dÃ²ng trÆ°á»›c Ä‘Ã³. ChÃºng tÃ´i Ä‘Ã£ thu tháº­p má»™t cÃ¡ch Ä‘á»“ng nháº¥t vÃ  ngáº«u nhiÃªn 9292 máº«u Java vÃ  6550 máº«u Python tá»« bá»™ dá»¯ liá»‡u CodeSearchNet Ä‘á»ƒ thá»±c hiá»‡n Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i. ChÃºng tÃ´i Ä‘Ã£ chá»n ngáº«u nhiÃªn má»™t dÃ²ng cho má»—i máº«u vÃ  giao nhiá»‡m vá»¥ cho mÃ´ hÃ¬nh táº¡o ra dÃ²ng Ä‘Ã³, chá»‰ Ä‘Æ°á»£c cung cáº¥p táº¥t cáº£ cÃ¡c dÃ²ng Ä‘á»©ng trÆ°á»›c. Khi Ã¡p dá»¥ng Ağ‘†ğ´ğ‘ƒ, chÃºng tÃ´i ná»‘i thÃªm thÃ´ng tin repository vÃ  cÃ¡c sá»± kiá»‡n ngá»¯ nghÄ©a khÃ¡c (tá»©c lÃ , tagged identifiers, DFG) trÆ°á»›c cÃ¡c dÃ²ng Ä‘á»©ng trÆ°á»›c. Quan trá»ng lÃ , khi táº¡o ra tagged identifiers vÃ  DFG, chÃºng tÃ´i chá»‰ sá»­ dá»¥ng thÃ´ng tin má»™t pháº§n tá»« cÃ¡c dÃ²ng Ä‘á»©ng trÆ°á»›c Ä‘á»ƒ trÃ¡nh rÃ² rá»‰ thÃ´ng tin tá»« cÃ¡c dÃ²ng sau Ä‘áº¿n cÃ¡c dÃ²ng má»¥c tiÃªu.

ChÃºng tÃ´i Ä‘Ã£ sá»­ dá»¥ng hai chá»‰ sá»‘, Exact Match (EM) vÃ  Edit Similarity (ES), phÃ¹ há»£p vá»›i benchmark CodeXGLUE, Ä‘á»ƒ Ä‘o hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh. ChÃºng tÃ´i Ä‘Ã£ thá»±c hiá»‡n kiá»ƒm Ä‘á»‹nh McNemar cho EM vÃ  kiá»ƒm Ä‘á»‹nh cáº·p Ä‘Ã´i Wilcoxon sign-rank Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh, tÆ°Æ¡ng tá»± nhÆ° nhá»¯ng gÃ¬ chÃºng tÃ´i Ä‘Ã£ thá»±c hiá»‡n cho tÃ³m táº¯t mÃ£ nguá»“n. Báº£ng 5 tÃ³m táº¯t cÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i. ChÃºng tÃ´i quan sÃ¡t tháº¥y lá»£i Ã­ch tá»•ng thá»ƒ 5.79% trong Exact Match (EM) vÃ  lá»£i Ã­ch 5.11% trong Edit Similarity (ES), nháº¥n máº¡nh tÃ­nh hiá»‡u quáº£ cá»§a viá»‡c káº¿t há»£p cÃ¡c sá»± kiá»‡n ngá»¯ nghÄ©a. Äá»‘i vá»›i Python, chÃºng tÃ´i tÃ¬m tháº¥y Ã½ nghÄ©a thá»‘ng kÃª chá»‰ cho cáº£i thiá»‡n ES, khÃ´ng cho EM.

4.6 Hiá»‡u Suáº¥t trÃªn CÃ¡c Chá»‰ Sá»‘ KhÃ¡c
NgoÃ i BLEU-CN, chÃºng tÃ´i Ä‘Ã£ Ä‘o hiá»‡u suáº¥t vá»›i 3 chá»‰ sá»‘ khÃ¡c; BLEU-DC, ROUGE-L vÃ  METEOR. Káº¿t quáº£ cá»§a chÃºng tÃ´i, trong Báº£ng 10, cho tháº¥y lá»£i Ã­ch trung bÃ¬nh vá»›i Ağ‘†ğ´ğ‘ƒ trÃªn cáº£ ba chá»‰ sá»‘. ChÃºng tÃ´i Ä‘Ã£ thá»±c hiá»‡n cÃ¡c kiá»ƒm Ä‘á»‹nh cáº·p Ä‘Ã´i má»™t phÃ­a Wilcoxon signed-rank vÃ  tÃ¬m tháº¥y cáº£i thiá»‡n hiá»‡u suáº¥t Ä‘Ã¡ng ká»ƒ vá»›i BLEU-DC vÃ  ROUGE-L cho táº¥t cáº£ cÃ¡c ngÃ´n ngá»¯. Tuy nhiÃªn, chÃºng tÃ´i khÃ´ng quan sÃ¡t tháº¥y sá»± khÃ¡c biá»‡t Ä‘Ã¡ng ká»ƒ vá»›i METEOR cho 4 trong 6 ngÃ´n ngá»¯, máº·c dÃ¹ trung bÃ¬nh máº«u thá»±c sá»± cáº£i thiá»‡n vá»›i Ağ‘†ğ´ğ‘ƒ trong táº¥t cáº£ 6 so sÃ¡nh. ÄÃ¡ng chÃº Ã½ lÃ  chÃºng tÃ´i chá»‰ cÃ³ 1000 máº«u ngÃ´n ngá»¯ (do chi phÃ­) cho má»—i ngÃ´n ngá»¯, vÃ¬ váº­y khÃ´ng báº¥t ngá» khi tháº¥y má»™t sá»‘ trÆ°á»ng há»£p mÃ  chÃºng tÃ´i khÃ´ng quan sÃ¡t tháº¥y Ã½ nghÄ©a. Äá»ƒ Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng tá»•ng thá»ƒ cá»§a Ağ‘†ğ´ğ‘ƒ, chÃºng tÃ´i Ä‘Ã£ káº¿t há»£p bá»™ dá»¯ liá»‡u tá»« táº¥t cáº£ cÃ¡c ngÃ´n ngá»¯ cho mÃ´ hÃ¬nh code-davinci-002 (6000 máº«u) vÃ  thá»±c hiá»‡n cÃ¹ng má»™t kiá»ƒm Ä‘á»‹nh; sau Ä‘Ã³ chÃºng tÃ´i cÃ³ Ä‘Æ°á»£c Ã½ nghÄ©a thá»‘ng kÃª (p-value < 0.01) cho cáº£ ba chá»‰ sá»‘, cho tháº¥y ráº±ng Ağ‘†ğ´ğ‘ƒ thá»±c sá»± cung cáº¥p giÃ¡ trá»‹.

5 THáº¢O LUáº¬N VÃ€ NGHIÃŠN Cá»¨U ABLATION
BÃ¢y giá» chÃºng tÃ´i trÃ¬nh bÃ y má»™t nghiÃªn cá»©u ablation vá» thiáº¿t káº¿ cá»§a Ağ‘†ğ´ğ‘ƒ vÃ  cÃ¡c sá»± kiá»‡n ngá»¯ nghÄ©a cá»¥ thá»ƒ mÃ  viá»‡c khá»Ÿi táº¡o Ağ‘†ğ´ğ‘ƒ cá»§a chÃºng tÃ´i sá»­ dá»¥ng trÆ°á»›c khi so sÃ¡nh Ä‘áº§u ra cá»§a Ağ‘†ğ´ğ‘ƒ vá»›i baseline BM25 thuáº§n tÃºy cá»§a chÃºng tÃ´i. Má»¥c tiÃªu chÃ­nh cá»§a má»™t nghiÃªn cá»©u ablation lÃ  Ä‘Ã¡nh giÃ¡ Ä‘Ã³ng gÃ³p cá»§a má»—i khÃ­a cáº¡nh cá»§a má»™t mÃ´ hÃ¬nh cho hiá»‡u suáº¥t cuá»‘i cÃ¹ng Ä‘Æ°á»£c quan sÃ¡t. Trong nghiÃªn cá»©u cá»§a chÃºng tÃ´i, chÃºng tÃ´i Ä‘Ã£ loáº¡i bá» má»—i thÃ nh pháº§n ngá»¯ nghÄ©a cá»§a prompt tÄƒng cÆ°á»ng vÃ  quan sÃ¡t hiá»‡u suáº¥t. ChÃºng tÃ´i tháº¥y ráº±ng thÃ nh pháº§n Repo. Ä‘Ã³ng gÃ³p nhiá»u nháº¥t cho hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh (Báº£ng 7) cho cáº£ Java vÃ  Python. Tuy nhiÃªn, tagged identifier vÃ  DFG cÅ©ng há»¯u Ã­ch, vÃ  káº¿t quáº£ tá»‘t nháº¥t Ä‘Æ°á»£c thu Ä‘Æ°á»£c khi chÃºng tÃ´i káº¿t há»£p cáº£ ba thÃ nh pháº§n trong prompt.

[THIS IS TABLE: Báº£ng 7 - NghiÃªn cá»©u ablation]
NgÃ´n ngá»¯ | ThÃ nh pháº§n Prompt | BLEU-4
Java     | ALL              | 25.41
         | -Repo.           | 23.50
         | -Id              | 25.27
         | -DFG             | 24.86
Python   | ALL              | 24.26
         | -Repo.           | 22.80
         | -Id              | 23.93
         | -DFG             | 23.31

Hai VÃ­ Dá»¥ Minh Há»a Khi kiá»ƒm tra thá»§ cÃ´ng cÃ¡c káº¿t quáº£, chÃºng tÃ´i quan sÃ¡t tháº¥y ráº±ng trong má»™t sá»‘ máº«u, prompt Ağ‘†ğ´ğ‘ƒ chá»©a thÃ´ng tin quan trá»ng cho tÃ³m táº¯t. Báº£ng 8 cho tháº¥y hai vÃ­ dá»¥ káº¿t quáº£ minh há»a Ä‘iá»ƒm nÃ y. Trong vÃ­ dá»¥ Ä‘áº§u tiÃªn, mÃ´ hÃ¬nh baseline khÃ´ng táº¡o ra thuáº­t ngá»¯ "element-wise". Tuy nhiÃªn, phiÃªn báº£n tÄƒng cÆ°á»ng prompt cá»§a chÃºng tÃ´i Ä‘Ã£ náº¯m báº¯t Ä‘Æ°á»£c khÃ¡i niá»‡m quan trá»ng nÃ y, mang láº¡i Ä‘iá»ƒm BLEU-4 cao hÆ¡n lÃ  74.0 so vá»›i Ä‘iá»ƒm baseline lÃ  39.0. TÆ°Æ¡ng tá»±, trong vÃ­ dá»¥ thá»© hai, mÃ´ hÃ¬nh baseline khÃ´ng nháº­n ra hÃ m nhÆ° má»™t quy trÃ¬nh Ä‘á»™c láº­p, dáº«n Ä‘áº¿n Ä‘iá»ƒm BLEU tháº¥p lÃ  10.0. Tuy nhiÃªn, cÃ¡ch tiáº¿p cáº­n Ä‘Æ°á»£c Ä‘á» xuáº¥t cá»§a chÃºng tÃ´i Ä‘Ã£ xÃ¡c Ä‘á»‹nh hÃ m nhÆ° má»™t quy trÃ¬nh Ä‘á»™c láº­p, dáº«n Ä‘áº¿n Ä‘iá»ƒm BLEU cao hÆ¡n lÃ  33.0.

--- TRANG 9 ---
TÄƒng CÆ°á»ng Ngá»¯ NghÄ©a Tá»± Äá»™ng cá»§a Prompt MÃ´ HÃ¬nh NgÃ´n Ngá»¯
(cho TÃ³m Táº¯t MÃ£ Nguá»“n) ICSE '24, 14â€“20 thÃ¡ng 4, 2024, Lisbon, Bá»“ ÄÃ o Nha

[THIS IS TABLE: Báº£ng 8 - CÃ¡c vÃ­ dá»¥ Ä‘Æ°á»£c chá»n, minh há»a tÃ­nh hiá»‡u quáº£ cá»§a tÄƒng cÆ°á»ng Ağ‘†ğ´ğ‘ƒ]
VÃ­ dá»¥ 1:
```
def round(input_a, name: nil)
  check_allowed_types(input_a, TensorStream::Ops::FLOATING_POINT_TYPES)
  _op(:round, input_a, name: name)
end
```

Nháº­n xÃ©t Gold & Ä‘áº§u ra mÃ´ hÃ¬nh | BLEU
Gold: Rounds the values of a tensor to the nearest integer element-wise | NA
BM25: Round a tensor to the nearest integer | 39
Ağ‘†ğ´ğ‘ƒ: Rounds the values of a tensor to the nearest integer, element-wise. | 74

VÃ­ dá»¥ 2:
```
public static void main(final String[] args) {
    loadPropertiesFiles(args);
    final ShutdownSignalBarrier barrier = new ShutdownSignalBarrier();
    final MediaDriver.Context ctx = new MediaDriver.Context();
    ctx.terminationHook(barrier::signal);
    try (MediaDriver ignore = MediaDriver.launch(ctx)) {
        barrier.await();
        System.out.println("Shutdown Driver...");
    }
}
```

Nháº­n xÃ©t Gold & Ä‘áº§u ra mÃ´ hÃ¬nh | BLEU
Gold: Start Media Driver as a stand-alone process. | NA
BM25: Main method that starts the CLR Bridge from Java. | 10
Ağ‘†ğ´ğ‘ƒ: Main method for running Media Driver as a standalone process. | 33

Liá»‡u MÃ´ HÃ¬nh CÃ³ Ghi Nhá»› ÄÆ°á»ng Dáº«n KhÃ´ng? Trong ba sá»± kiá»‡n ngá»¯ nghÄ©a mÃ  Ağ‘†ğ´ğ‘ƒ thÃªm vÃ o prompt, thÃ´ng tin repo. tÃ¡c Ä‘á»™ng Ä‘áº¿n hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh nhiá»u nháº¥t. Äiá»u nÃ y cÃ³ thá»ƒ do thá»±c táº¿ lÃ  Code-Davinci-002 Ä‘Ã£ ghi nhá»› cÃ¡c Ä‘Æ°á»ng dáº«n tá»‡p cá»¥ thá»ƒ trong dá»¯ liá»‡u cá»§a chÃºng tÃ´i trong quÃ¡ trÃ¬nh pre-training; khi chÃºng tÃ´i cung cáº¥p Ä‘Æ°á»ng dáº«n Ä‘áº¿n hÃ m, cÃ³ thá»ƒ mÃ´ hÃ¬nh chá»‰ nhá»› láº¡i thÃ´ng tin Ä‘Ã£ ghi nhá»›? Äá»ƒ Ä‘iá»u tra cÃ¢u há»i nÃ y, chÃºng tÃ´i thay Ä‘á»•i biá»ƒu diá»…n Ä‘Æ°á»ng dáº«n: chÃºng tÃ´i láº¥y tÃªn repository vÃ  Ä‘Æ°á»ng dáº«n, chia cÃ¡c token táº¡i "/", vÃ  trÃ¬nh bÃ y cho mÃ´ hÃ¬nh má»™t danh sÃ¡ch cÃ¡c token. Ã tÆ°á»Ÿng chÃ­nh Ä‘áº±ng sau cÃ¡ch tiáº¿p cáº­n nÃ y lÃ  lÃ m tan biáº¿n biá»ƒu diá»…n gá»‘c, vÃ  trÃ¬nh bÃ y cho mÃ´ hÃ¬nh má»™t cÃ¡i gÃ¬ Ä‘Ã³ khÃ´ng gáº·p pháº£i trong quÃ¡ trÃ¬nh pre-training. Náº¿u mÃ´ hÃ¬nh khÃ´ng ghi nhá»› má»™t cÃ¡ch nghÄ©a Ä‘en, hiá»‡u suáº¥t cá»§a nÃ³ khÃ´ng nÃªn bá»‹ tÃ¡c Ä‘á»™ng. ChÃºng tÃ´i quan sÃ¡t tháº¥y ráº±ng sá»± khÃ¡c biá»‡t giá»¯a hai phiÃªn báº£n ráº¥t nhá». Äá»‘i vá»›i Java, chÃºng tÃ´i tÄƒng Ä‘Æ°á»£c 0.24 BLEU nhÆ°ng, Ä‘á»‘i vá»›i Python, chÃºng tÃ´i máº¥t 0.04 vá»›i Ä‘Æ°á»ng dáº«n Ä‘Æ°á»£c token hÃ³a. Äiá»u nÃ y cho tháº¥y rá»§i ro tháº¥p hÆ¡n ráº±ng mÃ´ hÃ¬nh Ä‘Ã£ ghi nhá»› Ä‘Æ°á»ng dáº«n Ä‘áº¿n hÃ m.

Tháº» Äá»‹nh Danh CÃ³ Cáº§n Thiáº¿t KhÃ´ng? Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i gÃ¡n vai trÃ² cho cÃ¡c Ä‘á»‹nh danh vÃ  gáº¯n tháº» chÃºng nhÆ° Function Name, Parameters, Identifier, v.v. trong prompt (Xem HÃ¬nh 2). Viá»‡c gáº¯n tháº» rÃµ rÃ ng nÃ y cÃ³ thá»±c sá»± giÃºp hiá»‡u suáº¥t khÃ´ng? Äá»ƒ Ä‘iá»u tra cÃ¢u há»i nÃ y, chÃºng tÃ´i so sÃ¡nh hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh khi Ä‘Æ°á»£c cung cáº¥p má»™t danh sÃ¡ch cÃ¡c Ä‘á»‹nh danh thuáº§n tÃºy, "khÃ´ng cÃ³ tháº»". ChÃºng tÃ´i quan sÃ¡t tháº¥y ráº±ng cÃ¡c Ä‘á»‹nh danh Ä‘Æ°á»£c gáº¯n tháº» dáº«n Ä‘áº¿n hiá»‡u suáº¥t tá»‘t hÆ¡n cho cáº£ Java vÃ  Python so vá»›i má»™t danh sÃ¡ch Ä‘Æ¡n giáº£n cÃ¡c Ä‘á»‹nh danh khÃ´ng cÃ³ tháº». Chá»‰ sá»‘ hiá»‡u suáº¥t BLEU cá»§a chÃºng tÃ´i tÄƒng 0.41 vÃ  1.22 cho Java vÃ  Python, tÆ°Æ¡ng á»©ng, cho tháº¥y ráº±ng thÃ´ng tin ngá»¯ nghÄ©a rÃµ rÃ ng thá»±c sá»± Ä‘Ã³ng gÃ³p vÃ o hiá»‡u suáº¥t mÃ´ hÃ¬nh tá»‘t hÆ¡n.

[THIS IS TABLE: Báº£ng 9 - So sÃ¡nh vá»›i BM25 Vanilla vá»›i shots cao hÆ¡n]
NgÃ´n ngá»¯ | Prompt Enhanced | Vanilla BM25
        | # shots | BLEU-4 | # shots | BLEU-4
Java    | 3       | 25.41  | 3       | 22.87
        |         |        | 4       | 23.13
        |         |        | 5       | 23.20
Python  | 3       | 24.26  | 3       | 21.78
        |         |        | 4       | 21.89
        |         |        | 5       | 21.74

CÃ¡i GÃ¬ Tá»‘t HÆ¡n: Nhiá»u Shots HÆ¡n hay ASAP? Máº·c dÃ¹ cÃ³ hÃ ng tá»· tham sá»‘, LLM cÃ³ kÃ­ch thÆ°á»›c prompt háº¡n cháº¿. VÃ­ dá»¥, code-davinci-002 vÃ  gpt-3.5-turbo há»— trá»£ cho phÃ©p Ä‘á»™ dÃ i prompt chá»‰ 4k token. TÄƒng cÆ°á»ng Ağ‘†ğ´ğ‘ƒ thá»±c sá»± tiÃªu thá»¥ má»™t pháº§n ngÃ¢n sÃ¡ch Ä‘á»™ dÃ i prompt cÃ³ sáºµn! Do Ä‘Ã³ chÃºng tÃ´i cÃ³ hai lá»±a chá»n thiáº¿t káº¿: 1) sá»­ dá»¥ng Ã­t hÆ¡n, cÃ¡c máº«u TÄƒng CÆ°á»ng Ağ‘†ğ´ğ‘ƒ trong prompt hoáº·c 2) sá»­ dá»¥ng nhiá»u máº«u few-shot hÆ¡n mÃ  khÃ´ng cÃ³ tÄƒng cÆ°á»ng. Äá»ƒ Ä‘iá»u tra Ä‘iá»u nÃ y, chÃºng tÃ´i cÅ©ng Ä‘Ã£ thá»­ sá»­ dá»¥ng 4 vÃ  5 shot (thay vÃ¬ 3) cho Java vÃ  Python vá»›i mÃ´ hÃ¬nh code-davinci-002. Tuy nhiÃªn, Báº£ng 9 cho tháº¥y ráº±ng shots cao hÆ¡n sá»­ dá»¥ng BM25 khÃ´ng nháº¥t thiáº¿t dáº«n Ä‘áº¿n hiá»‡u suáº¥t tá»‘t hÆ¡n. Vá»›i shots cao hÆ¡n, cÃ³ kháº£ nÄƒng giá»›i thiá»‡u cÃ¡c máº«u khÃ´ng liÃªn quan, cÃ³ thá»ƒ lÃ m tá»•n háº¡i mÃ´ hÃ¬nh thay vÃ¬ giÃºp Ä‘á»¡ nÃ³.

Chá»‰ Ä‘á»‘i vá»›i Java chÃºng tÃ´i quan sÃ¡t tháº¥y hiá»‡u suáº¥t tá»‘t hÆ¡n vá»›i cáº£ 4 vÃ  5 shot so vá»›i mÃ´ hÃ¬nh baseline cá»§a chÃºng tÃ´i. Tuy nhiÃªn, ká»¹ thuáº­t Ä‘Æ°á»£c Ä‘á» xuáº¥t cá»§a chÃºng tÃ´i vá»›i chá»‰ 3-shot váº«n vÆ°á»£t trá»™i hÆ¡n viá»‡c sá»­ dá»¥ng BM25 vá»›i 5 shot. ÄÃ¡ng chÃº Ã½ lÃ  cá»­a sá»• ngá»¯ cáº£nh cá»§a mÃ´ hÃ¬nh Ä‘ang tÄƒng lÃªn tá»«ng ngÃ y, vÃ  mÃ´ hÃ¬nh GPT-4 sáº¯p tá»›i sáº½ cho phÃ©p chÃºng tÃ´i cÃ³ tá»‘i Ä‘a 32K tokenâ¶. Do Ä‘Ã³, giá»›i háº¡n Ä‘á»™ dÃ i cÃ³ thá»ƒ khÃ´ng pháº£i lÃ  má»™t váº¥n Ä‘á» trong tÆ°Æ¡ng lai gáº§n. Tuy nhiÃªn, nghiÃªn cá»©u cá»§a chÃºng tÃ´i cho tháº¥y ráº±ng TÄƒng CÆ°á»ng Ngá»¯ NghÄ©a Tá»± Äá»™ng sáº½ váº«n lÃ  má»™t cÃ¡ch cÃ³ lá»£i Ä‘á»ƒ sá»­ dá»¥ng ngÃ¢n sÃ¡ch Ä‘á»™ dÃ i prompt cÃ³ sáºµn; hÆ¡n ná»¯a, cÃ³ lÃ½ do Ä‘á»ƒ tin ráº±ng viá»‡c xÃ¢y dá»±ng cÃ¡c prompt giÃ u tÃ­n hiá»‡u, thÃ´ng tin hÆ¡n sáº½ cÃ³ lá»£i báº¥t ká»ƒ Ä‘á»™ dÃ i.

CÃ¡i GÃ¬ Má»›i trong Äáº§u Ra cá»§a Ağ‘†ğ´ğ‘ƒ? ChÃºng tÃ´i thÃªm má»™t phÃ¢n tÃ­ch pro forma cá»§a má»™t vÃ i vÃ­ dá»¥ Ä‘Æ°á»£c chá»n báº±ng tay, Ä‘á»ƒ phÃ¹ há»£p vá»›i cÃ¡c nghi thá»©c cá»™ng Ä‘á»“ng yÃªu cáº§u peer-review; tuy nhiÃªn, nhá»¯ng phÃ¢n tÃ­ch nÃ y ráº¥t mang tÃ­nh giai thoáº¡i vÃ  pháº£i Ä‘Æ°á»£c giáº£i thÃ­ch tháº­n trá»ng. ChÃºng tÃ´i kiá»ƒm tra thá»§ cÃ´ng má»™t sá»‘ máº«u Ä‘á»ƒ tháº£o luáº­n káº¿t quáº£ cá»§a chÃºng tÃ´i chi tiáº¿t hÆ¡n; cá»¥ thá»ƒ, Ä‘á»ƒ tráº£ lá»i ba cÃ¢u há»i: Ä‘á»ƒ chá»‰ rÃµ 1) cÃ¡c loáº¡i thÃ´ng tin má»›i mÃ  Ağ‘†ğ´ğ‘ƒ trÃ¬nh bÃ y cho LLM vÃ  2) lÃ m tháº¿ nÃ o tÃ³m táº¯t cá»§a Ağ‘†ğ´ğ‘ƒ khÃ¡c vá»›i nhá»¯ng tÃ³m táº¯t Ä‘Æ°á»£c táº¡o ra bá»Ÿi cÃ¡c ká»¹ thuáº­t hiá»‡n cÃ³, vÃ  3) Ä‘á»ƒ phÃ¢n tÃ­ch cÃ¡c lá»—i mÃ  Ağ‘†ğ´ğ‘ƒ giá»›i thiá»‡u. Báº£ng 11 trÃ¬nh bÃ y má»™t sá»‘ máº«u nÆ¡i, cho ba máº«u Ä‘áº§u tiÃªn, Ağ‘†ğ´ğ‘ƒ hoáº¡t Ä‘á»™ng ráº¥t tá»‘t so vá»›i baseline dá»±a trÃªn truy xuáº¥t cá»§a chÃºng tÃ´i, vÃ  cho ba máº«u thá»© hai, baseline hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n Ağ‘†ğ´ğ‘ƒ. Trong khi chÃºng tÃ´i tháº£o luáº­n cÃ¡c phÃ¡t hiá»‡n cá»§a mÃ¬nh trong bá»‘i cáº£nh cá»§a cÃ¡c máº«u Ä‘Æ°á»£c cung cáº¥p, cÃ¡c quan sÃ¡t cá»§a chÃºng tÃ´i khÃ¡i quÃ¡t hÃ³a cho cÃ¡c máº«u khÃ¡c.

CÃ¡c loáº¡i thÃ´ng tin má»›i mÃ  Ağ‘†ğ´ğ‘ƒ trÃ¬nh bÃ y cho LLM: NhÆ° Ä‘Ã£ tháº£o luáº­n trong bÃ i bÃ¡o, Ä‘Ã³ng gÃ³p chÃ­nh cá»§a chÃºng tÃ´i liÃªn quan Ä‘áº¿n viá»‡c tÄƒng cÆ°á»ng cÃ¡c máº«u Ä‘Æ°á»£c truy xuáº¥t (Ä‘Æ°á»£c truy xuáº¥t sá»­ dá»¥ng BM25, theo Nashid et al. [48]) báº±ng cÃ¡c sá»± kiá»‡n ngá»¯ nghÄ©a, dáº«n Ä‘áº¿n hiá»‡u suáº¥t Ä‘Æ°á»£c cáº£i thiá»‡n so vá»›i cÃ¡ch tiáº¿p cáº­n truy xuáº¥t cÆ¡ báº£n. ChÃºng tÃ´i thÃªm cÃ¡c sá»± kiá»‡n ngá»¯ nghÄ©a liÃªn quan Ä‘áº¿n chi tiáº¿t repository, Ä‘á»‹nh danh, vÃ  Ä‘á»“ thá»‹ luá»“ng dá»¯ liá»‡u cho cáº£ cÃ¡c máº«u Ä‘Æ°á»£c truy xuáº¥t vÃ  mÃ£ nguá»“n Ä‘áº§u vÃ o. NhÆ° dá»± kiáº¿n, cÃ¡c sá»± kiá»‡n ngá»¯ nghÄ©a Ä‘Æ°á»£c thÃªm vÃ o chuyá»ƒn vÃ o, vÃ  tÄƒng cÆ°á»ng, Ä‘áº§u ra mÃ´ hÃ¬nh.

Trong máº«u Ä‘áº§u tiÃªn, phÆ°Æ¡ng phÃ¡p baseline chá»‰ truy xuáº¥t khÃ´ng náº¯m báº¯t Ä‘Æ°á»£c thuáº­t ngá»¯ "gradient" hoÃ n toÃ n. Tuy nhiÃªn, báº±ng cÃ¡ch káº¿t há»£p

â¶https://platform.openai.com/docs/models/gpt-4

--- TRANG 10 ---
ICSE '24, 14â€“20 thÃ¡ng 4, 2024, Lisbon, Bá»“ ÄÃ o Nha Toufique Ahmed, Kunal Suresh Pai, Premkumar Devanbu, vÃ  Earl T. Barr

[THIS IS TABLE: Báº£ng 10 - TÃ­nh hiá»‡u quáº£ cá»§a ASAP trong cÃ¡c chá»‰ sá»‘ tÃ³m táº¯t mÃ£ nguá»“n phá»• biáº¿n]
NgÃ´n ngá»¯ | BLEU-DC | ROUGE-L | METEOR
        | BM25 | ASAP | Lá»£i Ã­ch (%) | p-value | BM25 | ASAP | Lá»£i Ã­ch (%) | p-value | BM25 | ASAP | Lá»£i Ã­ch (%) | p-value
Java    | 14.09| 15.94| +13.13%    | <0.01   | 36.85| 38.41| +4.23%     | <0.01   | 35.66| 36.10| +1.23%     | 0.32
Python  | 12.63| 14.49| +14.73%    | <0.01   | 35.32| 37.74| +6.85%     | <0.01   | 33.05| 35.63| +7.81%     | <0.01
Ruby    | 9.16 | 11.01| +20.2%     | <0.01   | 28.19| 30.55| +8.37%     | <0.01   | 27.65| 29.20| +5.61%     | 0.03
JavaScript| 14.89| 16.71| +12.22%    | <0.01   | 32.28| 33.88| +4.96%     | <0.01   | 32.08| 33.02| +2.93%     | 0.15
Go      | 17.10| 18.57| +8.60%     | <0.01   | 41.04| 42.43| +3.39%     | <0.01   | 36.78| 37.26| +1.31%     | 0.27
PHP     | 16.97| 20.63| +21.57%    | <0.01   | 40.48| 44.90| +10.92%    | <0.01   | 40.14| 43.35| +8.00%     | <0.01
Tá»•ng thá»ƒ| 14.14| 16.23| +14.78%    | <0.01   | 35.69| 37.99| +6.44%     | <0.01   | 34.23| 35.76| +4.47%     | <0.01

[THIS IS TABLE: Báº£ng 11 - VÃ­ dá»¥ Cho tháº¥y Äiá»ƒm Máº¡nh vÃ  Äiá»ƒm Yáº¿u cá»§a Ağ‘†ğ´ğ‘ƒ]
Thay Ä‘á»•i (BLEU-4) | Tham chiáº¿u | BM25 | Ağ‘†ğ´ğ‘ƒ
Ağ‘†ğ´ğ‘ƒ (+47) | Generates a gradient-noise value from the coordinates of a three-dimensional input value and the integer coordinates of a nearby three-dimensional value. | Computes a value at the point (x, y, z) in a 3D Perlin noise function. | Generates a gradient-coherent-noise value from the coordinates of a three-dimensional input value.
Ağ‘†ğ´ğ‘ƒ (+26) | Replaces type with mapped type for current path. | Returns the mapped type for the current path, or the target type if no mapping exists. | Replaces target type with mapped type if any.
Ağ‘†ğ´ğ‘ƒ (+41) | convert a dataRootExt to a dataRoot | Convert to a DataRoot object. | Convert a DataRootExt to a DataRoot.
Ağ‘†ğ´ğ‘ƒ (-36) | Computes the convex hull of the set of points. | Computes the convex hull of the set of points | Computes the convex hull of the set of points using Andrew's monotone chain algorithm
Ağ‘†ğ´ğ‘ƒ (-35) | Getter for the Uninstall Actions. | Returns the uninstall actions. | Retrieves the uninstall actions for this deployable unit.
Ağ‘†ğ´ğ‘ƒ (-67) | Get a column of this matrix. | Get a column of this matrix. | Return the specified column of this matrix as a column vector.

cÃ¡c sá»± kiá»‡n ngá»¯ nghÄ©a, mÃ´ hÃ¬nh thÃ nh cÃ´ng khÃ´i phá»¥c thuáº­t ngá»¯ vÃ¬ nÃ³ thÆ°á»ng Ä‘Æ°á»£c tÃ¬m tháº¥y trong cáº£ Ä‘á»‹nh danh vÃ  tÃªn repository, áº£nh hÆ°á»Ÿng Ä‘áº¿n Ä‘áº§u ra cá»§a mÃ´ hÃ¬nh. Trong vÃ­ dá»¥ thá»© hai, nÆ¡i má»¥c tiÃªu lÃ  thay tháº¿ thay vÃ¬ chá»‰ tráº£ vá», baseline khÃ´ng táº¡o ra thuáº­t ngá»¯ "replace", máº·c dÃ¹ cÃ³ chá»‰ dáº«n rÃµ rÃ ng trong tÃªn hÃ m ("replaceWithMappedTypeForPath"). Luá»“ng dá»¯ liá»‡u giá»¯a cÃ¡c Ä‘á»‹nh danh, Ä‘Æ°á»£c cung cáº¥p trong cÃ¡c sá»± kiá»‡n ngá»¯ nghÄ©a, cÃ³ thá»ƒ Ä‘Ã£ giÃºp mÃ´ hÃ¬nh nháº­n ra cÃ¡c thao tÃ¡c thay tháº¿.

CÃ¡ch tÃ³m táº¯t cá»§a Ağ‘†ğ´ğ‘ƒ khÃ¡c vá»›i nhá»¯ng tÃ³m táº¯t Ä‘Æ°á»£c táº¡o ra bá»Ÿi cÃ¡c ká»¹ thuáº­t hiá»‡n cÃ³: Sau cuá»™c tháº£o luáº­n trÃªn, chÃºng tÃ´i quan sÃ¡t tháº¥y ráº±ng Ağ‘†ğ´ğ‘ƒ Ä‘ang táº¡o ra thÃ´ng tin cá»¥ thá»ƒ hÆ¡n:
(1) NÃ³ xÃ¡c Ä‘á»‹nh "gradient" trong máº«u 1.
(2) NÃ³ Ä‘á» xuáº¥t thay Ä‘á»•i "return" thÃ nh "replace" trong má»™t máº«u khÃ¡c (máº«u 2).
(3) NÃ³ khuyáº¿n nghá»‹ thay Ä‘á»•i "dataroot" thÃ nh "datarootext" trong má»™t máº«u khÃ¡c (máº«u 3).

Nhá»¯ng khÃ¡c biá»‡t nÃ y Ä‘Ã£ Ä‘Æ°á»£c quan sÃ¡t trÃªn nhiá»u máº«u khi so sÃ¡nh baseline cá»§a chÃºng tÃ´i vá»›i Ağ‘†ğ´ğ‘ƒ. CÃ¡ch tiáº¿p cáº­n Ağ‘†ğ´ğ‘ƒ nháº¥t quÃ¡n táº¡o ra thÃ´ng tin cá»¥ thá»ƒ hÆ¡n so vá»›i baseline.

PhÃ¢n tÃ­ch cÃ¡c lá»—i mÃ  Ağ‘†ğ´ğ‘ƒ giá»›i thiá»‡u: CÃ¡c vÃ­ dá»¥ Ä‘Æ°á»£c kiá»ƒm tra cho tháº¥y ráº±ng Ağ‘†ğ´ğ‘ƒ cÃ³ thá»ƒ trá»Ÿ nÃªn quÃ¡ cá»¥ thá»ƒ, vÃ  do Ä‘Ã³ khÃ´ng khá»›p vá»›i tÃ³m táº¯t Ä‘Æ°á»£c viáº¿t bá»Ÿi láº­p trÃ¬nh viÃªn. Ağ‘†ğ´ğ‘ƒ trá»Ÿ nÃªn quÃ¡ cá»¥ thá»ƒ trong ba vÃ­ dá»¥ cuá»‘i cÃ¹ng vá»›i "Andrew's monotone chain algorithm" vÃ  "deployable unit", "column vector". Trong khi nhá»¯ng thuáº­t ngá»¯ nÃ y khÃ´ng nháº¥t thiáº¿t sai, BLEU-4 giáº£m, vÃ¬ tÃ³m táº¯t Ä‘Æ°á»£c viáº¿t bá»Ÿi láº­p trÃ¬nh viÃªn tá»•ng quÃ¡t hÆ¡n.

ChÃºng tÃ´i cÅ©ng quan sÃ¡t má»™t cÃ¡ch Ä‘á»‹nh lÆ°á»£ng ráº±ng Ağ‘†ğ´ğ‘ƒ gÃ¢y ra thay Ä‘á»•i tÃ­ch cá»±c trong 44% máº«u. Tuy nhiÃªn, hiá»‡u suáº¥t cÅ©ng giáº£m cho 30% máº«u, vÃ  giá»¯ nguyÃªn trÃªn pháº§n cÃ²n láº¡i. So vá»›i baseline cá»§a chÃºng tÃ´i (há»c few-shot vá»›i cÃ¡c máº«u Ä‘Æ°á»£c truy xuáº¥t BM25), Ağ‘†ğ´ğ‘ƒ Ä‘Ã²i há»i nhiá»u token hÆ¡n. Chi phÃ­ token bá»• sung, má»—i truy váº¥n (cáº£ vá» chi phÃ­ tiá»n tá»‡ vÃ  overhead hiá»‡u suáº¥t) khÃ¡ khiÃªm tá»‘n. Máº·t khÃ¡c, chÃºng tÃ´i quan sÃ¡t tháº¥y má»™t cáº£i thiá»‡n tá»•ng thá»ƒ Ä‘Ã¡ng ká»ƒ 12% vá»›i Ağ‘†ğ´ğ‘ƒ sá»­ dá»¥ng mÃ´ hÃ¬nh Codex.

6 CÃ”NG VIá»†C LIÃŠN QUAN

6.1 TÃ³m Táº¯t MÃ£ Nguá»“n
CÃ¡c mÃ´ hÃ¬nh deep learning Ä‘Ã£ thÃºc Ä‘áº©y state-of-the-art trong cÃ¡c nhiá»‡m vá»¥ SE nhÆ° tÃ³m táº¯t mÃ£ nguá»“n. MÃ´ hÃ¬nh LSTM cho tÃ³m táº¯t mÃ£ nguá»“n láº§n Ä‘áº§u tiÃªn Ä‘Æ°á»£c giá»›i thiá»‡u bá»Ÿi Iyer et al. [33]. CÃ¡c mÃ´ hÃ¬nh dá»±a trÃªn transformer Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c nhÆ° CodeBERT [21], PLBART [2], vÃ  CodeT5 [64] Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trÃªn bá»™ dá»¯ liá»‡u tÃ³m táº¯t mÃ£ nguá»“n CodeXGLUE [47], dáº«n Ä‘áº¿n nhá»¯ng cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ. Tuy nhiÃªn, cÃ³ má»™t lÆ°u Ã½ khi sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c: máº·c dÃ¹ nhá»¯ng mÃ´ hÃ¬nh nÃ y hoáº¡t Ä‘á»™ng tá»‘t, viá»‡c fine-tuning rá»™ng rÃ£i lÃ  cáº§n thiáº¿t, cÃ³ thá»ƒ Ä‘Ã²i há»i nhiá»u dá»¯ liá»‡u & tá»‘n thá»i gian. NgoÃ i ra, cÃ¡c mÃ´ hÃ¬nh riÃªng biá»‡t pháº£i Ä‘Æ°á»£c huáº¥n luyá»‡n cho cÃ¡c ngÃ´n ngá»¯ khÃ¡c nhau, tÄƒng chi phÃ­ huáº¥n luyá»‡n. Äá»ƒ giáº£m sá»‘ lÆ°á»£ng mÃ´ hÃ¬nh cáº§n thiáº¿t, fine-tuning Ä‘a ngÃ´n ngá»¯ Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» xuáº¥t, Ä‘á»ƒ duy trÃ¬ hoáº·c cáº£i thiá»‡n hiá»‡u suáº¥t trong khi giáº£m sá»‘ lÆ°á»£ng mÃ´ hÃ¬nh xuá»‘ng má»™t [4]. Tuy nhiÃªn, cÃ¡ch tiáº¿p cáº­n nÃ y khÃ´ng giáº£m thá»i gian huáº¥n luyá»‡n hoáº·c nhu cáº§u vá» dá»¯ liá»‡u cÃ³ nhÃ£n.

LLM, hoáº·c cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n, lá»›n hÆ¡n nhiá»u so vá»›i nhá»¯ng mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c nÃ y, vÃ  Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c bá»™ dá»¯ liá»‡u lá»›n hÆ¡n nhiá»u vá»›i má»™t má»¥c tiÃªu huáº¥n luyá»‡n Ä‘Æ¡n giáº£n â€” dá»± Ä‘oÃ¡n token tiáº¿p theo tá»± há»“i quy [12]. Nhá»¯ng mÃ´ hÃ¬nh nÃ y hoáº¡t Ä‘á»™ng tá»‘t má»™t cÃ¡ch Ä‘Ã¡ng ngáº¡c nhiÃªn trong cÃ¡c nhiá»‡m vá»¥, tháº­m chÃ­ mÃ  khÃ´ng cáº§n fine-tuning. Chá»‰ cáº§n nháº¯c nhá»Ÿ mÃ´ hÃ¬nh vá»›i cÃ¡c cÃ¢u há»i khÃ¡c nhau, trong khi cung cáº¥p má»™t vÃ i máº«u váº¥n Ä‘á»-giáº£i phÃ¡p, lÃ  Ä‘á»§. Há»c few-shot Ä‘Ã£ Ä‘Æ°á»£c Ã¡p dá»¥ng cho tÃ³m táº¯t mÃ£ nguá»“n, vÃ  Ä‘Ã£ Ä‘Æ°á»£c tÃ¬m tháº¥y lÃ  cÃ³ lá»£i [3].

--- TRANG 11 ---
TÄƒng CÆ°á»ng Ngá»¯ NghÄ©a Tá»± Äá»™ng cá»§a Prompt MÃ´ HÃ¬nh NgÃ´n Ngá»¯
(cho TÃ³m Táº¯t MÃ£ Nguá»“n) ICSE '24, 14â€“20 thÃ¡ng 4, 2024, Lisbon, Bá»“ ÄÃ o Nha

6.2 CÃ¡c Bá»™ Dá»¯ Liá»‡u KhÃ¡c
CÃ³ má»™t sá»‘ bá»™ dá»¯ liá»‡u cÃ³ sáºµn cho tÃ³m táº¯t mÃ£ nguá»“n, ngoÃ i CodeXGLUE [47]. TL-CodeSum [30] lÃ  má»™t bá»™ dá»¯ liá»‡u tÆ°Æ¡ng Ä‘á»‘i nhá» hÆ¡n, vá»›i khoáº£ng 87K máº«u, nhÆ°ng nÃ³ bao gá»“m cÃ¡c báº£n trÃ¹ng láº·p, cÃ³ thá»ƒ dáº«n Ä‘áº¿n Æ°á»›c lÆ°á»£ng hiá»‡u suáº¥t cao cÃ³ thá»ƒ khÃ´ng khÃ¡i quÃ¡t hÃ³a. Funcom [41] lÃ  má»™t bá»™ dá»¯ liá»‡u chuyÃªn dá»¥ng vá»›i 2.1 triá»‡u hÃ m Java, nhÆ°ng chá»©a cÃ¡c báº£n trÃ¹ng láº·p. ChÃºng tÃ´i chá»n CodeXGLUE (rÃºt ra tá»« CodeSearchNet) vÃ¬ nÃ³ lÃ  má»™t bá»™ dá»¯ liá»‡u Ä‘a dáº¡ng, Ä‘a ngÃ´n ngá»¯, Ä‘áº·t ra thÃ¡ch thá»©c cho cÃ¡c mÃ´ hÃ¬nh. Tháº­m chÃ­ cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n tá»‘t nhÆ° CodeBERT cÅ©ng gáº·p khÃ³ khÄƒn trÃªn benchmark nÃ y; hiá»‡u suáº¥t cá»§a nÃ³ Ä‘áº·c biá»‡t kÃ©m trÃªn cÃ¡c ngÃ´n ngá»¯ cÃ³ Ã­t máº«u huáº¥n luyá»‡n.

ÄÃ£ cÃ³ ráº¥t nhiá»u cÃ´ng viá»‡c vá» tÃ³m táº¯t mÃ£ nguá»“n, tá»« khá»›p template Ä‘áº¿n há»c few-shot. Nhá»¯ng mÃ´ hÃ¬nh nÃ y sá»­ dá»¥ng cÃ¡c biá»ƒu diá»…n vÃ  nguá»“n thÃ´ng tin khÃ¡c nhau Ä‘á»ƒ hoáº¡t Ä‘á»™ng tá»‘t trong tÃ³m táº¯t mÃ£ nguá»“n. Viá»‡c so sÃ¡nh hoáº·c tháº£o luáº­n táº¥t cáº£ nhá»¯ng mÃ´ hÃ¬nh nÃ y vÆ°á»£t quÃ¡ pháº¡m vi cá»§a cÃ´ng viá»‡c nÃ y. Tuy nhiÃªn, chÃºng tÃ´i lÆ°u Ã½ ráº±ng cÃ¡c con sá»‘ cá»§a chÃºng tÃ´i Ä‘áº¡i diá»‡n cho má»™t Ä‘iá»ƒm cao má»›i trÃªn benchmark CodeXGlue Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i cho tÃ³m táº¯t mÃ£ nguá»“n vÃ  hoÃ n thÃ nh mÃ£ nguá»“n; chÃºng tÃ´i giá»›i thiá»‡u ngÆ°á»i Ä‘á»c Ä‘áº¿n https://microsoft.github.io/CodeXGLUE/ Ä‘á»ƒ nhanh chÃ³ng xem báº£ng xáº¿p háº¡ng. CÃ¡c máº«u cá»§a chÃºng tÃ´i nhá» hÆ¡n (N=1000), nhÆ°ng cÃ¡c Æ°á»›c lÆ°á»£ng, vÃ  Æ°á»›c lÆ°á»£ng cáº£i thiá»‡n, máº¡nh máº½ vá» máº·t thá»‘ng kÃª (Xem tháº£o luáº­n vá» cá»¡ máº«u trong Má»¥c 7).

6.3 LLM trong Ká»¹ Thuáº­t Pháº§n Má»m
Máº·c dÃ¹ LLM chÆ°a Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i cho tÃ³m táº¯t mÃ£ nguá»“n, chÃºng Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i cho táº¡o mÃ£ nguá»“n [14, 49, 67] vÃ  sá»­a chá»¯a chÆ°Æ¡ng trÃ¬nh [5,18,35,36]. CÃ¡c mÃ´ hÃ¬nh nhÆ° Codex nháº±m giáº£m gÃ¡nh náº·ng cho cÃ¡c láº­p trÃ¬nh viÃªn báº±ng cÃ¡ch tá»± Ä‘á»™ng táº¡o mÃ£ nguá»“n hoáº·c hoÃ n thÃ nh dÃ²ng. Má»™t sá»‘ mÃ´ hÃ¬nh nhÆ° Polycoder [67] vÃ  Codegen [49] hoáº¡t Ä‘á»™ng khÃ¡ tá»‘t, vÃ  do há»c few-shot hoáº·c prompting cá»§a chÃºng, chÃºng cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng cho má»™t táº­p há»£p rá»™ng cÃ¡c váº¥n Ä‘á». Tuy nhiÃªn, mÃ´ hÃ¬nh Code-davinci-002 thÆ°á»ng hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n nhá»¯ng mÃ´ hÃ¬nh Ä‘Ã³ vÃ  cho phÃ©p chÃºng tÃ´i fit cÃ¡c prompt tÄƒng cÆ°á»ng cá»§a chÃºng tÃ´i vÃ o má»™t cá»­a sá»• lá»›n hÆ¡n.

Jain et al. Ä‘Ã£ Ä‘á» xuáº¥t bá»• sung hoáº¡t Ä‘á»™ng LLM vá»›i cÃ¡c bÆ°á»›c xá»­ lÃ½ tiáº¿p theo dá»±a trÃªn cÃ¡c ká»¹ thuáº­t phÃ¢n tÃ­ch vÃ  tá»•ng há»£p chÆ°Æ¡ng trÃ¬nh Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t trong táº¡o Ä‘oáº¡n mÃ£ chÆ°Æ¡ng trÃ¬nh [34]. BareiÃŸ et al. cho tháº¥y tÃ­nh hiá»‡u quáº£ cá»§a há»c few-shot trong mutation mÃ£ nguá»“n, táº¡o test oracle tá»« tÃ i liá»‡u ngÃ´n ngá»¯ tá»± nhiÃªn, vÃ  cÃ¡c nhiá»‡m vá»¥ táº¡o test case [10]. CODAMOSA [42], má»™t cÃ¡ch tiáº¿p cáº­n dá»±a trÃªn LLM, thá»±c hiá»‡n kiá»ƒm thá»­ pháº§n má»m dá»±a trÃªn tÃ¬m kiáº¿m cho Ä‘áº¿n khi cÃ¡c cáº£i thiá»‡n coverage cá»§a nÃ³ Ä‘Ã¬nh trá»‡, sau Ä‘Ã³ yÃªu cáº§u LLM cung cáº¥p cÃ¡c test case máº«u cho cÃ¡c hÃ m khÃ´ng Ä‘Æ°á»£c bao phá»§. Báº±ng cÃ¡ch sá»­ dá»¥ng nhá»¯ng vÃ­ dá»¥ nÃ y, CODAMOSA giÃºp chuyá»ƒn hÆ°á»›ng kiá»ƒm thá»­ pháº§n má»m dá»±a trÃªn tÃ¬m kiáº¿m Ä‘áº¿n cÃ¡c khu vá»±c há»¯u Ã­ch hÆ¡n cá»§a khÃ´ng gian tÃ¬m kiáº¿m. Jiang et al. Ä‘Ã£ Ä‘Ã¡nh giÃ¡ tÃ­nh hiá»‡u quáº£ cá»§a LLM cho váº¥n Ä‘á» sá»­a chá»¯a chÆ°Æ¡ng trÃ¬nh [35].

Truy xuáº¥t vÃ  ná»‘i thÃªm má»™t táº­p há»£p cÃ¡c máº«u huáº¥n luyá»‡n Ä‘Ã£ Ä‘Æ°á»£c tÃ¬m tháº¥y lÃ  cÃ³ lá»£i cho nhiá»u nhiá»‡m vá»¥ phÃ¢n tÃ­ch ngá»¯ nghÄ©a trong NLP, tháº­m chÃ­ mÃ  khÃ´ng sá»­ dá»¥ng LLM [68]. Má»™t háº¡n cháº¿ cá»§a cÃ¡ch tiáº¿p cáº­n nÃ y lÃ  hiá»‡u suáº¥t cÃ³ thá»ƒ bá»‹ rÃ ng buá»™c bá»Ÿi tÃ­nh kháº£ dá»¥ng cá»§a cÃ¡c vÃ­ dá»¥ tÆ°Æ¡ng tá»±. Nashid et al. Ä‘Ã£ sá»­ dá»¥ng má»™t cÃ¡ch tiáº¿p cáº­n tÆ°Æ¡ng tá»± vÃ  Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t cáº£i thiá»‡n trong sá»­a chá»¯a mÃ£ nguá»“n vÃ  táº¡o assertion vá»›i sá»± giÃºp Ä‘á»¡ cá»§a LLM [48]. Tuy nhiÃªn, khÃ´ng cÃ³ cÃ´ng viá»‡c nÃ o á»Ÿ trÃªn Ä‘Ã£ cá»‘ gáº¯ng tÄƒng cÆ°á»ng ngá»¯ nghÄ©a tá»± Ä‘á»™ng prompt. LÆ°u Ã½ ráº±ng váº«n cÃ²n quÃ¡ sá»›m Ä‘á»ƒ nháº­n xÃ©t vá» kháº£ nÄƒng Ä‘áº§y Ä‘á»§ cá»§a nhá»¯ng mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n nÃ y. CÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i cho Ä‘áº¿n nay cho tháº¥y ráº±ng viá»‡c tÄƒng cÆ°á»ng cÃ¡c máº«u trong prompt báº±ng gá»£i Ã½ ngá»¯ nghÄ©a giÃºp Ã­ch trong cÃ¡c nhiá»‡m vá»¥ tÃ³m táº¯t mÃ£ nguá»“n vÃ  hoÃ n thÃ nh mÃ£ nguá»“n; viá»‡c Ä‘Ã¡nh giÃ¡ giÃ¡ trá»‹ cá»§a Ağ‘†ğ´ğ‘ƒ trong cÃ¡c nhiá»‡m vá»¥ khÃ¡c Ä‘Æ°á»£c Ä‘á»ƒ láº¡i cho cÃ´ng viá»‡c tÆ°Æ¡ng lai.

7 HIá»‚M Há»ŒA & GIá»šI Háº N
Má»™t má»‘i quan tÃ¢m lá»›n khi lÃ m viá»‡c vá»›i cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n lÃ  kháº£ nÄƒng phÆ¡i bÃ y dá»¯ liá»‡u kiá»ƒm thá»­ trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. Tiáº¿c lÃ , ngÆ°á»i ta khÃ´ng thá»ƒ kiá»ƒm tra trá»±c tiáº¿p Ä‘iá»u nÃ y vÃ¬ bá»™ dá»¯ liá»‡u huáº¥n luyá»‡n khÃ´ng thá»ƒ truy cáº­p. Hiá»‡u suáº¥t tháº¥p hÆ¡n cá»§a mÃ´ hÃ¬nh vá»›i few-shotting ngáº«u nhiÃªn cho tháº¥y ráº±ng viá»‡c ghi nhá»› cÃ³ thá»ƒ khÃ´ng pháº£i lÃ  má»™t yáº¿u tá»‘ chÃ­nh. Khi chÃºng tÃ´i káº¿t há»£p thÃ´ng tin liÃªn quan, hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh cáº£i thiá»‡n vá»›i lÆ°á»£ng vÃ  cháº¥t lÆ°á»£ng thÃ´ng tin. Náº¿u mÃ´ hÃ¬nh Ä‘Ã£ ghi nhá»› cÃ¡c tÃ³m táº¯t, nÃ³ cÃ³ thá»ƒ Ä‘Ã£ ghi Ä‘iá»ƒm cao hÆ¡n nhiá»u, tháº­m chÃ­ mÃ  khÃ´ng cÃ³ lá»£i Ã­ch cá»§a cÃ¡c máº«u liÃªn quan vÃ  tÄƒng cÆ°á»ng ngá»¯ nghÄ©a.

PhÃ¢n TÃ­ch Cá»¡ Máº«u: ChÃºng tÃ´i Ä‘Ã£ sá»­ dá»¥ng trung bÃ¬nh vÃ  Ä‘á»™ lá»‡ch chuáº©n quan sÃ¡t Ä‘Æ°á»£c Ä‘á»ƒ tÃ­nh toÃ¡n (sá»­ dá»¥ng G*power [19,20]) cÃ¡c cá»¡ máº«u cáº§n thiáº¿t, sá»­ dá»¥ng cÃ¡c giÃ¡ trá»‹ thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng: ğ›¼ cá»§a 0.01 (p-value mong muá»‘n) vÃ  ğ›½ cá»§a 0.20 (tá»©c lÃ , 20% kháº£ nÄƒng KHÃ”NG khÃ¡m phÃ¡ má»™t hiá»‡u á»©ng, náº¿u má»™t hiá»‡u á»©ng tá»“n táº¡i). Äá»‘i vá»›i cÃ¡c kiá»ƒm Ä‘á»‹nh mÃ  chÃºng tÃ´i Ä‘Ã£ sá»­ dá»¥ng (kiá»ƒm Ä‘á»‹nh Wilcoxon Signed-rank), chÃºng tÃ´i tháº¥y ráº±ng cá»¡ máº«u cáº§n thiáº¿t luÃ´n luÃ´n dÆ°á»›i cá»¡ máº«u mÃ  chÃºng tÃ´i Ä‘Ã£ sá»­ dá»¥ng cho cÃ¡c nghiÃªn cá»©u chÃ­nh cá»§a mÃ¬nh, tá»©c lÃ  1000.

NghiÃªn Cá»©u NgÆ°á»i DÃ¹ng: ChÃºng tÃ´i Ä‘Ã£ khÃ´ng thá»±c hiá»‡n nghiÃªn cá»©u ngÆ°á»i dÃ¹ng cho Ağ‘†ğ´ğ‘ƒ. Do Ä‘Ã³, nhá»¯ng cáº£i thiá»‡n trong cÃ¡c chá»‰ sá»‘ Ä‘Æ°á»£c trÃ¬nh bÃ y á»Ÿ Ä‘Ã¢y cÃ³ thá»ƒ khÃ´ng nháº¥t thiáº¿t chuyá»ƒn thÃ nh hiá»‡u suáº¥t láº­p trÃ¬nh viÃªn Ä‘Æ°á»£c cáº£i thiá»‡n. KhÃ­a cáº¡nh nÃ y Ä‘Æ°á»£c Ä‘á»ƒ láº¡i cho cÃ´ng viá»‡c tÆ°Æ¡ng lai.

Cuá»‘i cÃ¹ng: fine-tuning cÃ¡c LM lá»›n Ä‘á»ƒ sá»­ dá»¥ng cÃ¡c sá»± kiá»‡n ngá»¯ nghÄ©a rÃºt ra cÃ³ thá»ƒ cáº£i thiá»‡n so vá»›i cÃ¡ch tiáº¿p cáº­n prompting tÄƒng cÆ°á»ng cá»§a chÃºng tÃ´i, nhÆ°ng sáº½ tá»‘n kÃ©m. ChÃºng tÃ´i sáº½ Ä‘á»ƒ xem xÃ©t nÃ³ cho nghiÃªn cá»©u tÆ°Æ¡ng lai.

8 Káº¾T LUáº¬N
Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i Ä‘Ã£ khÃ¡m phÃ¡ Ã½ tÆ°á»Ÿng vá» TÄƒng CÆ°á»ng Ngá»¯ NghÄ©a Tá»± Äá»™ng cá»§a Prompt, theo Ä‘Ã³ chÃºng tÃ´i Ä‘á» xuáº¥t tÄƒng cÆ°á»ng cÃ¡c máº«u few-shot trong cÃ¡c prompt LLM, vá»›i cÃ¡c sá»± kiá»‡n Ä‘Æ°á»£c gáº¯n tháº» tá»± Ä‘á»™ng rÃºt ra bá»Ÿi phÃ¢n tÃ­ch ngá»¯ nghÄ©a. Äiá»u nÃ y dá»±a trÃªn trá»±c giÃ¡c ráº±ng cÃ¡c láº­p trÃ¬nh viÃªn con ngÆ°á»i thÆ°á»ng quÃ©t mÃ£ nguá»“n Ä‘á»ƒ ngáº§m trÃ­ch xuáº¥t nhá»¯ng sá»± kiá»‡n nhÆ° váº­y trong quÃ¡ trÃ¬nh hiá»ƒu mÃ£ nguá»“n dáº«n Ä‘áº¿n viá»‡c viáº¿t má»™t tÃ³m táº¯t tá»‘t. Máº·c dÃ¹ cÃ³ thá»ƒ tin ráº±ng LLM cÃ³ thá»ƒ ngáº§m suy ra nhá»¯ng sá»± kiá»‡n nhÆ° váº­y cho chÃ­nh chÃºng, chÃºng tÃ´i suy Ä‘oÃ¡n ráº±ng viá»‡c thÃªm nhá»¯ng sá»± kiá»‡n nÃ y theo má»™t phong cÃ¡ch Ä‘Æ°á»£c Ä‘á»‹nh dáº¡ng vÃ o cÃ¡c máº«u vÃ  má»¥c tiÃªu, trong prompt, sáº½ giÃºp LLM tá»• chá»©c "chuá»—i suy nghÄ©" cá»§a nÃ³ khi nÃ³ tÃ¬m cÃ¡ch xÃ¢y dá»±ng má»™t tÃ³m táº¯t. ChÃºng tÃ´i Ä‘Ã£ Ä‘Ã¡nh giÃ¡ Ã½ tÆ°á»Ÿng nÃ y trÃªn bá»™ dá»¯ liá»‡u CodeSearchNet Ä‘áº§y thá»­ thÃ¡ch, Ä‘Æ°á»£c khá»­ trÃ¹ng láº·p, Ä‘Æ°á»£c tuyá»ƒn chá»n tá»‘t, trÃªn hai nhiá»‡m vá»¥: tÃ³m táº¯t mÃ£ nguá»“n vÃ  hoÃ n thÃ nh mÃ£ nguá»“n. CÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i chá»‰ ra ráº±ng TÄƒng CÆ°á»ng Ngá»¯ NghÄ©a Tá»± Äá»™ng cá»§a Prompt thÆ°á»ng há»¯u Ã­ch. CÃ¡c Æ°á»›c lÆ°á»£ng cá»§a chÃºng tÃ´i cho tháº¥y nÃ³ giÃºp vÆ°á»£t qua state-of-the-art.

Lá»i Cáº£m Æ n: ChÃºng tÃ´i muá»‘n ghi nháº­n National Science Foundation dÆ°á»›i Grant NSF CCF (SHF-MEDIUM) Sá»‘ 2107592 vÃ  Intelligence Advanced Research Projects Agency (IARPA) dÆ°á»›i há»£p Ä‘á»“ng W911NF20C0038 cho sá»± há»— trá»£ má»™t pháº§n cá»§a cÃ´ng viá»‡c nÃ y. CÃ¡c káº¿t luáº­n cá»§a chÃºng tÃ´i khÃ´ng nháº¥t thiáº¿t pháº£n Ã¡nh vá»‹ trÃ­ hoáº·c chÃ­nh sÃ¡ch cá»§a cÃ¡c nhÃ  tÃ i trá»£ cá»§a chÃºng tÃ´i vÃ  khÃ´ng nÃªn suy ra sá»± tÃ¡n thÃ nh chÃ­nh thá»©c.

TÃ€I LIá»†U THAM KHáº¢O
[1] Wasi Ahmad, Saikat Chakraborty, Baishakhi Ray, vÃ  Kai-Wei Chang. 2020. A Transformer-based Approach for Source Code Summarization. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 4998â€“5007.

--- TRANG 12 ---
ICSE '24, 14â€“20 thÃ¡ng 4, 2024, Lisbon, Bá»“ ÄÃ o Nha Toufique Ahmed, Kunal Suresh Pai, Premkumar Devanbu, vÃ  Earl T. Barr

[2] Wasi Ahmad, Saikat Chakraborty, Baishakhi Ray, vÃ  Kai-Wei Chang. 2021. Uni-fied Pre-training for Program Understanding and Generation. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Compu-tational Linguistics: Human Language Technologies. 2655â€“2668.

[3] Toufique Ahmed vÃ  Premkumar Devanbu. 2022. Few-shot training LLMs for project-specific code-summarization. Trong 37th IEEE/ACM International Conference on Automated Software Engineering. 1â€“5.

[4] Toufique Ahmed vÃ  Premkumar Devanbu. 2022. Multilingual training for soft-ware engineering. Trong Proceedings of the 44th International Conference on Software Engineering. 1443â€“1455.

[5] Toufique Ahmed vÃ  Premkumar Devanbu. 2023. Better patching using LLM prompting, via Self-Consistency. Trong 2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 1742â€“1746.

[6] Toufique Ahmed, Supriyo Ghosh, Chetan Bansal, Thomas Zimmermann, Xuchao Zhang, vÃ  Saravan Rajmohan. 2023. Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models. ICSE (2023).

[7] Miltiadis Allamanis. 2019. The adverse effects of code duplication in machine learning models of code. Trong Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software. 143â€“153.

[8] Uri Alon, Shaked Brody, Omer Levy, vÃ  Eran Yahav. 2018. code2seq: Gen-erating sequences from structured representations of code. arXiv preprint arXiv:1808.01400 (2018).

[9] Satanjeev Banerjee vÃ  Alon Lavie. 2005. METEOR: An automatic metric for MT evaluation with improved correlation with human judgments. Trong Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization. 65â€“72.

[10] Patrick BareiÃŸ, Beatriz Souza, Marcelo d'Amorim, vÃ  Michael Pradel. 2022. Code generation tools (almost) for free? a study of few-shot, pre-trained language models on code. arXiv preprint arXiv:2206.01335 (2022).

[11] Lionel C Briand. 2003. Software documentation: how much is enough?. Trong Seventh European Conference on Software Maintenance and Reengineering, 2003. Proceedings. IEEE, 13â€“15.

[12] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877â€“1901.

[13] Boxing Chen vÃ  Colin Cherry. 2014. A systematic comparison of smoothing techniques for sentence-level BLEU. Trong Proceedings of the ninth workshop on statistical machine translation. 362â€“367.

[14] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374 (2021).

[15] Jacob Devlin, Ming-Wei Chang, Kenton Lee, vÃ  Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).

[16] Samanta Dey, Venkatesh Vinayakarao, Monika Gupta, vÃ  Sampath Dechu. 2022. Evaluating commit message generation: to BLEU or not to BLEU?. Trong Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results. 31â€“35.

[17] Brian P Eddy, Jeffrey A Robinson, Nicholas A Kraft, vÃ  Jeffrey C Carver. 2013. Evaluating source code summarization techniques: Replication and expansion. Trong 2013 21st International Conference on Program Comprehension (ICPC). IEEE, 13â€“22.

[18] Zhiyu Fan, Xiang Gao, Abhik Roychoudhury, vÃ  Shin Hwei Tan. 2022. Auto-mated Repair of Programs from Large Language Models. ICSE.

[19] Franz Faul, Edgar Erdfelder, Axel Buchner, vÃ  Albert-Georg Lang. 2009. Sta-tistical power analyses using G* Power 3.1: Tests for correlation and regression analyses. Behavior research methods 41, 4 (2009), 1149â€“1160.

[20] Franz Faul, Edgar Erdfelder, Albert-Georg Lang, vÃ  Axel Buchner. 2007. G* Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences. Behavior research methods 39, 2 (2007), 175â€“191.

[21] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, et al. 2020. CodeBERT: A Pre-Trained Model for Programming and Natural Languages. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings. 1536â€“1547.

[22] Andrew Forward vÃ  Timothy C Lethbridge. 2002. The relevance of software documentation, tools and technologies: a survey. Trong Proceedings of the 2002 ACM symposium on Document engineering. 26â€“33.

[23] Jianfeng Gao vÃ  Xiaodong He. 2013. Training MRF-based phrase translation models using gradient ascent. Trong Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-guage Technologies. 450â€“459.

[24] David Gros, Hariharan Sezhiyan, Prem Devanbu, vÃ  Zhou Yu. 2020. Code to Comment Translation: Data, Metrics, Baselining & Evaluation. Trong 2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 746â€“757.

[25] Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, LIU Shujie, Long Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, et al. 2020. GraphCodeBERT: Pre-training Code Representations with Data Flow. Trong International Conference on Learning Representations.

[26] Sonia Haiduc, Jairo Aponte, vÃ  Andrian Marcus. 2010. Supporting program comprehension with source code summarization. Trong Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering-Volume 2. 223â€“226.

[27] Sonia Haiduc, Jairo Aponte, Laura Moreno, vÃ  Andrian Marcus. 2010. On the use of automated text summarization techniques for summarizing source code. Trong 2010 17th Working Conference on Reverse Engineering. IEEE, 35â€“44.

[28] Sakib Haque, Zachary Eberhart, Aakash Bansal, vÃ  Collin McMillan. 2022. Se-mantic similarity metrics for evaluating source code summarization. Trong Proceed-ings of the 30th IEEE/ACM International Conference on Program Comprehension. 36â€“47.

[29] Xing Hu, Ge Li, Xin Xia, David Lo, vÃ  Zhi Jin. 2018. Deep code comment generation. Trong Proceedings of the 26th conference on program comprehension. 200â€“210.

[30] Xing Hu, Ge Li, Xin Xia, David Lo, Shuai Lu, vÃ  Zhi Jin. 2018. Summarizing source code with transferred API knowledge. Trong Proceedings of the 27th Interna-tional Joint Conference on Artificial Intelligence. 2269â€“2275.

[31] Jie Huang vÃ  Kevin Chen-Chuan Chang. 2022. Towards Reasoning in Large Language Models: A Survey. arXiv preprint arXiv:2212.10403 (2022).

[32] Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, vÃ  Marc Brockschmidt. 2019. Codesearchnet challenge: Evaluating the state of semantic code search. arXiv preprint arXiv:1909.09436 (2019).

[33] Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, vÃ  Luke Zettlemoyer. 2016. Summarizing source code using a neural attention model. Trong Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2073â€“2083.

[34] Naman Jain, Skanda Vaidyanath, Arun Iyer, Nagarajan Natarajan, Suresh Parthasarathy, Sriram Rajamani, vÃ  Rahul Sharma. 2022. Jigsaw: Large language models meet program synthesis. Trong Proceedings, 44th ICSE. 1219â€“1231.

[35] Nan Jiang, Kevin Liu, Thibaud Lutellier, vÃ  Lin Tan. 2023. Impact of Code Language Models on Automated Program Repair. ICSE (2023).

[36] Harshit Joshi, JosÃ© Cambronero, Sumit Gulwani, Vu Le, Ivan Radicek, vÃ  Gust Verbruggen. 2022. Repair is nearly generation: Multilingual program repair with llms. arXiv preprint arXiv:2208.11640 (2022).

[37] Hassan Kane, Muhammed Yusuf Kocyigit, Ali Abdalla, Pelkins Ajanoh, vÃ  Mohamed Coulibali. 2020. NUBIA: NeUral Based Interchangeability Assessor for Text Generation. arXiv:2004.14667 [cs.CL]

[38] Sungmin Kang, Juyeon Yoon, vÃ  Shin Yoo. 2023. Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction. ICSE (2023).

[39] Jan KocoÅ„, Igor Cichecki, Oliwier Kaszyca, Mateusz Kochanek, Dominika SzydÅ‚o, Joanna Baran, Julita Bielaniewicz, Marcin Gruza, Arkadiusz Janz, Kamil Kanclerz, et al. 2023. ChatGPT: Jack of all trades, master of none. Information Fusion (2023), 101861.

[40] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, vÃ  Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners. arXiv preprint arXiv:2205.11916 (2022).

[41] Alexander LeClair, Siyuan Jiang, vÃ  Collin McMillan. 2019. A neural model for generating natural language summaries of program subroutines. Trong 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE, 795â€“806.

[42] Caroline Lemieux, Jeevana Priya Inala, Shuvendu K Lahiri, vÃ  Siddhartha Sen. 2023. CODAMOSA: Escaping Coverage Plateaus in Test Generation with Pre-trained Large Language Models. Trong 45th International Conference on Software Engineering, ser. ICSE.

[43] Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. Trong Text summarization branches out. 74â€“81.

[44] Chin-Yew Lin vÃ  Franz Josef Och. 2004. Orange: a method for evaluating auto-matic evaluation metrics for machine translation. Trong COLING 2004: Proceedings of the 20th International Conference on Computational Linguistics. 501â€“507.

[45] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, vÃ  Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692 (2019).

[46] Cristina V Lopes, Petr Maj, Pedro Martins, Vaibhav Saini, Di Yang, Jakub Zitny, Hitesh Sajnani, vÃ  Jan Vitek. 2017. DÃ©jÃ Vu: a map of code duplicates on GitHub. Proceedings of the ACM on Programming Languages 1, OOPSLA (2017), 1â€“28.

[47] Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambro-sio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, et al. 2021. Codexglue: A machine learning benchmark dataset for code understanding and generation. arXiv preprint arXiv:2102.04664 (2021).

[48] Noor Nashid, Mifta Sintaha, vÃ  Ali Mesbah. 2023. Retrieval-Based Prompt Selection for Code-Related Few-Shot Learning. Trong Proceedings, 45th ICSE.

[49] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, vÃ  Caiming Xiong. 2022. Codegen: An open large language

--- TRANG 13 ---
TÄƒng CÆ°á»ng Ngá»¯ NghÄ©a Tá»± Äá»™ng cá»§a Prompt MÃ´ HÃ¬nh NgÃ´n Ngá»¯
(cho TÃ³m Táº¯t MÃ£ Nguá»“n) ICSE '24, 14â€“20 thÃ¡ng 4, 2024, Lisbon, Bá»“ ÄÃ o Nha

model for code with multi-turn program synthesis. arXiv preprint arXiv:2203.13474 (2022).

[50] Kishore Papineni, Salim Roukos, Todd Ward, vÃ  Wei-Jing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. Trong Proceedings of the 40th annual meeting of the Association for Computational Linguistics. 311â€“318.

[51] Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang, vÃ  Huajun Chen. 2022. Reasoning with Language Model Prompting: A Survey. arXiv preprint arXiv:2212.09597 (2022).

[52] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. 2018. Improving language understanding by generative pre-training. (2018).

[53] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog 1, 8 (2019), 9.

[54] Juan Ramos et al. 2003. Using tf-idf to determine word relevance in document queries. Trong Proceedings of the first instructional conference on machine learning, Vol. 242. Citeseer, 29â€“48.

[55] Stephen Robertson, Hugo Zaragoza, et al. 2009. The probabilistic relevance framework: BM25 and beyond. Foundations and TrendsÂ® in Information Retrieval 3, 4 (2009), 333â€“389.

[56] Paige Rodeghero, Collin McMillan, Paul W McBurney, Nigel Bosch, vÃ  Sidney D'Mello. 2014. Improving automated source code summarization via an eye-tracking study of programmers. Trong Proceedings of the 36th international conference on Software engineering. 390â€“401.

[57] Devjeet Roy, Sarah Fakhoury, vÃ  Venera Arnaoudova. 2021. Reassessing auto-matic evaluation metrics for code summarization tasks. Trong Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 1105â€“1116.

[58] Thibault Sellam, Dipanjan Das, vÃ  Ankur P Parikh. 2020. BLEURT: Learning robust metrics for text generation. arXiv preprint arXiv:2004.04696 (2020).

[59] Ensheng Shi, Yanlin Wang, Lun Du, Junjie Chen, Shi Han, Hongyu Zhang, Dong-mei Zhang, vÃ  Hongbin Sun. 2023. On the evaluation of neural code summariza-tion. Trong Proceedings of the 44th International Conference on Software Engineering. 1597â€“1608.

[60] Disha Shrivastava, Hugo Larochelle, vÃ  Daniel Tarlow. 2022. Repository-level prompt generation for large language models of code. arXiv preprint arXiv:2206.12839 (2022).

[61] Giriprasad Sridhara, Emily Hill, Divya Muppaneni, Lori Pollock, vÃ  K Vijay-Shanker. 2010. Towards automatically generating summary comments for java methods. Trong Proceedings of the IEEE/ACM international conference on Automated software engineering. 43â€“52.

[62] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Åukasz Kaiser, vÃ  Illia Polosukhin. 2017. Attention is all you need. Trong Advances in neural information processing systems. 5998â€“6008.

[63] Yue Wang, Hung Le, Akhilesh Deepak Gotmare, Nghi DQ Bui, Junnan Li, vÃ  Steven CH Hoi. 2023. Codet5+: Open code large language models for code understanding and generation. arXiv preprint arXiv:2305.07922 (2023).

[64] Yue Wang, Weishi Wang, Shafiq Joty, vÃ  Steven CH Hoi. 2021. CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 8696â€“8708.

[65] Bolin Wei, Ge Li, Xin Xia, Zhiyi Fu, vÃ  Zhi Jin. 2019. Code generation as a dual task of code summarization. Advances in neural information processing systems 32 (2019).

[66] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, vÃ  Denny Zhou. 2022. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903 (2022).

[67] Frank F Xu, Uri Alon, Graham Neubig, vÃ  Vincent Josua Hellendoorn. 2022. A systematic evaluation of large language models of code. Trong Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming. 1â€“10.

[68] Yury Zemlyanskiy, Michiel de Jong, Joshua Ainslie, Panupong Pasupat, Peter Shaw, Linlu Qiu, Sumit Sanghai, vÃ  Fei Sha. 2022. Generate-and-Retrieve: use your predictions to improve retrieval for semantic parsing. arXiv preprint arXiv:2209.14899 (2022).

[69] Jian Zhang, Xu Wang, Hongyu Zhang, Hailong Sun, vÃ  Xudong Liu. 2020. Retrieval-based neural source code summarization. Trong Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering. 1385â€“1397.

[70] Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, vÃ  Yoav Artzi. 2019. Bertscore: Evaluating text generation with bert. arXiv preprint arXiv:1904.09675 (2019).

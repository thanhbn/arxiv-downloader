# 2402.14034.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/agent/2402.14034.pdf
# Kích thước tệp: 7898607 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
AgentScope: Một Nền Tảng Đa Tác Nhân Linh Hoạt và Mạnh Mẽ
Dawei Gao†, Zitao Li†, Xuchen Pan∗, Weirui Kuang∗, Zhijian Ma∗, Bingchen Qian∗,
Fei Wei∗, Wenhao Zhang∗, Yuexiang Xie∗, Daoyuan Chen∗,
Liuyi Yao, Hongyi Peng, Zeyu Zhang, Lin Zhu, Chen Cheng, Hongzhu Shi,
Yaliang Li‡, Bolin Ding‡, Jingren Zhou
Alibaba Group

Tóm tắt
Với sự phát triển nhanh chóng của các Mô hình Ngôn ngữ Lớn (LLM), đã đạt được tiến bộ đáng kể trong các ứng dụng đa tác nhân. Tuy nhiên, sự phức tạp trong việc phối hợp hợp tác giữa các tác nhân và hiệu suất không ổn định của LLM đặt ra những thách thức đáng chú ý trong việc phát triển các ứng dụng đa tác nhân mạnh mẽ và hiệu quả. Để giải quyết những thách thức này, chúng tôi đề xuất AgentScope, một nền tảng đa tác nhân tập trung vào nhà phát triển với cơ chế trao đổi thông điệp làm cốt lõi giao tiếp. Các công cụ cú pháp phong phú, tác nhân và chức năng dịch vụ tích hợp, giao diện thân thiện với người dùng cho việc trình diễn ứng dụng và giám sát tiện ích, trạm làm việc lập trình không cần code, và cơ chế tự động điều chỉnh prompt giúp giảm đáng kể các rào cản trong cả phát triển và triển khai. Hướng tới ứng dụng đa tác nhân mạnh mẽ và linh hoạt, AgentScope cung cấp cả cơ chế chịu lỗi tích hợp và có thể tùy chỉnh. Đồng thời, nó cũng được trang bị hỗ trợ cấp hệ thống để quản lý và sử dụng dữ liệu đa phương thức, công cụ và kiến thức bên ngoài. Thêm vào đó, chúng tôi thiết kế một khung phân tán dựa trên actor, cho phép chuyển đổi dễ dàng giữa triển khai cục bộ và phân tán cùng với tối ưu hóa song song tự động mà không cần nỗ lực thêm. Với những tính năng này, AgentScope trao quyền cho các nhà phát triển xây dựng các ứng dụng phát huy đầy đủ tiềm năng của các tác nhân thông minh. Chúng tôi đã phát hành AgentScope tại https://github.com/modelscope/agentscope, và hy vọng AgentScope sẽ mời gọi sự tham gia và đổi mới rộng rãi hơn trong lĩnh vực phát triển nhanh này.

1 Giới thiệu
Các hệ thống đa tác nhân, như phần mở rộng nâng cấp của các hệ thống đơn tác nhân, đòi hỏi nỗ lực hợp tác từ nhiều tác nhân làm việc cùng nhau (Wang et al., 2023; Xi et al., 2023). Với sự tiến bộ của các Mô hình Ngôn ngữ Lớn (LLM) (Ouyang et al., 2022; OpenAI, 2023; Touvron et al., 2023a,b), các ứng dụng đa tác nhân đã có tiến bộ lớn trong cả cộng đồng nghiên cứu và công nghiệp, bao gồm kỹ thuật phần mềm (Hong et al., 2023), mô phỏng xã hội (Park et al., 2023), và trợ lý thông minh (Wu et al., 2023; AutoGPT-Team, 2023). Mặc dù đã đạt được tiến bộ đáng kể trong các kịch bản đa tác nhân, vẫn còn những thách thức lớn trong việc phát triển ứng dụng đa tác nhân.

Phát triển một ứng dụng đa tác nhân phức tạp hơn việc tạo ra một ứng dụng đơn tác nhân. Không giống như thiết lập đơn tác nhân nơi một tác nhân chỉ tương tác với người dùng, việc phát triển trong kịch bản đa tác nhân đòi hỏi việc tạo ra và quản lý cẩn thận nhiều mô hình và tác nhân (Wang et al., 2023; Xi et al., 2023), điều này đặt ra yêu cầu cao về cả tính linh hoạt và tiện dụng cho một nền tảng. Cụ thể, các khía cạnh sau đây đặc trưng cho những thách thức: 1) Các tác nhân tham gia vào một ứng dụng đa tác nhân có thể chuyên môn hóa ở các chức năng khác nhau thông qua các cấu hình ban đầu khác nhau; 2) Một ứng dụng đa tác nhân có thể yêu cầu các tác nhân được thực thi theo một quy trình vận hành tiêu chuẩn (SOP) hoặc một luồng công việc động hơn; 3) Mô hình giao tiếp giữa các tác nhân có thể thay đổi từ một-đến-một hoặc phát sóng (ví dụ, một nhóm thảo luận của các tác nhân). Kết quả là, các nhà phát triển mong đợi một nền tảng tiện dụng có thể cung cấp các mô hình lập trình ngắn gọn và rõ ràng khi xử lý tất cả các khía cạnh trên, tăng tốc và tạo thuận lợi cho chu kỳ phát triển. Đạt được tính linh hoạt và tiện dụng đồng thời đòi hỏi thiết kế cẩn thận và cân nhắc đánh đổi, và nó vẫn là một mục tiêu bền vững cho tất cả các thiết kế nền tảng đa tác nhân.

Các sai lệch là hộp thuốc súng trong hệ thống đa tác nhân. Mặc dù LLM đã tiến bộ nhanh chóng, chúng vẫn gặp khó khăn với các vấn đề như ảo giác (Rawte et al., 2023; Zhang et al., 2023b) và việc tuân theo hướng dẫn không đầy đủ (Fu et al., 2019; Zhang et al., 2023a). Ngoài ra, một tác nhân có thể được trang bị với nhiều công cụ khác nhau, nhưng những công cụ đó đưa ra các yếu tố bất định bổ sung (ví dụ, khả năng truy cập vào cơ sở dữ liệu hoặc công cụ tìm kiếm). Từ quan điểm về độ mạnh mẽ của hệ thống đa tác nhân, bất kỳ lỗi hoặc phản hồi bất ngờ nào cũng có thể lan truyền đến toàn bộ hệ thống, gây ra một chuỗi các tác động liên tục nếu không được xử lý đúng cách. Do đó, việc tự động phát hiện và xử lý các phản hồi bất ngờ từ LLM là rất quan trọng đối với các ứng dụng đa tác nhân. Trong khi LLM có thể hỗ trợ trong việc xác định và quản lý các lỗi này, việc xác định liệu chúng có thể giải quyết lỗi một cách tự động hay không và tự động cung cấp thông tin cần thiết để sửa lỗi vẫn là một thách thức. Do đó, thiết kế khả năng chịu lỗi tích hợp LLM là một thách thức quan trọng trong việc phát triển các ứng dụng đa tác nhân.

Hỗ trợ các tác nhân với dữ liệu đa phương thức, công cụ và kiến thức bên ngoài có tính hệ thống cao. Ngoài việc tạo ra câu trả lời với LLM, các tác nhân được mong đợi linh hoạt hơn, bao gồm tạo ra và xử lý dữ liệu đa phương thức (Su et al., 2023; Betker et al., 2023), chuẩn bị và gọi các hàm như công cụ (Yao et al., 2023; Shen et al., 2024), quản lý các ngân hàng kiến thức bên ngoài, và sử dụng kiến thức đã truy xuất để tăng cường tạo sinh (Lewis et al., 2020a). Tuy nhiên, việc tích hợp những chức năng này trong các ứng dụng đa tác nhân đòi hỏi một cách tiếp cận toàn diện và có hệ thống. Hỗ trợ nội dung đa phương thức là một nỗ lực phức tạp, đòi hỏi cân nhắc cho lưu trữ dữ liệu, trình bày, tương tác người dùng, truyền thông điệp và giao tiếp. Việc sử dụng công cụ của các tác nhân đòi hỏi thống nhất mô hình gọi hàm và phân tích đầu ra, prompting để hướng dẫn LLM, và thiết kế cơ chế lý luận để đảm bảo các nhiệm vụ có thể được hoàn thành từng bước. Đối với kiến thức bên ngoài, ngoài các kỹ thuật tạo sinh tăng cường truy xuất (RAG), chúng ta cần xem xét cách chia sẻ và quản lý hiệu quả kiến thức trong các kịch bản đa tác nhân trong khi để lại đủ tính linh hoạt cho các chiến lược truy xuất. Trong khi một số công trình hiện có nghiên cứu cách những kỹ thuật đó hoạt động riêng lẻ trong các hệ thống tác nhân chuyên biệt, các giao diện lập trình cấp nền tảng tổng quát vẫn chưa có.

Các ứng dụng phân tán mang lại những khó khăn lập trình bổ sung và thách thức thiết kế hệ thống. Một kịch bản hướng công nghiệp cho các ứng dụng đa tác nhân là các tác nhân thuộc sở hữu của các tổ chức khác nhau và chạy trên các máy khác nhau bởi vì các tác nhân được trang bị kiến thức riêng tư độc đáo hoặc công cụ được cấp bằng sáng chế. Phát triển các ứng dụng như vậy thường yêu cầu các nhà phát triển có kiến thức chuyên môn về lập trình hệ thống phân tán và tối ưu hóa trong giai đoạn thiết kế. Ngoài ra, các ứng dụng phân tán thường yêu cầu nỗ lực lớn thêm trong phát triển và thử nghiệm, đặc biệt khi gỡ lỗi và chẩn đoán các vấn đề lan truyền qua các tiến trình phân tán hoặc tác nhân. Hơn nữa, việc tích hợp các tính năng tiên tiến như xử lý dữ liệu đa phương thức đặt ra những thách thức bổ sung trong môi trường phân tán, khi các tác nhân yêu cầu thời gian khác nhau để hoàn thành các nhiệm vụ phụ hoặc nội dung được tạo ra rất không đồng nhất. Thiết kế hệ thống phân tán kém có thể dẫn đến chi phí giao tiếp quá mức giữa các tác nhân. Do đó, xây dựng các ứng dụng đa tác nhân phân tán đòi hỏi nỗ lực lớn từ các nhà phát triển có kinh nghiệm và một rào cản cao cho người mới bắt đầu di chuyển các nguyên mẫu của họ sang phong cách phân tán để đạt hiệu quả tối ưu.

Để giải quyết các thách thức đã đề cập, chúng tôi giới thiệu AgentScope, một nền tảng đa tác nhân mới được thiết kế cho các nhà phát triển với nhiều mức độ chuyên môn khác nhau. AgentScope được thiết kế tốt với cơ chế trao đổi thông điệp thể hiện tính khả dụng, mạnh mẽ và hiệu quả tuyệt vời. Chúng tôi nhấn mạnh các tính năng nổi bật của AgentScope như sau:

Tính Khả Dụng Đặc Biệt cho Nhà Phát Triển. AgentScope được thiết kế với trọng tâm cơ bản là dễ sử dụng, đặc biệt cho các nhà phát triển với nhiều mức độ chuyên môn khác nhau. Bằng cách triển khai cơ chế trao đổi thông điệp hướng thủ tục, AgentScope đảm bảo đường cong học tập mượt mà trong phát triển ứng dụng đa tác nhân. Để giảm bớt gánh nặng lập trình, AgentScope cung cấp một bộ tiện ích cú pháp mở rộng, bao gồm các pipeline khác nhau và cơ chế chia sẻ thông tin. Ngoài lập trình với khung của chúng tôi, chúng tôi cũng cải thiện tính khả dụng bằng cách cung cấp một trạm làm việc lập trình kéo-thả không cần code, có thể cho phép những người có kinh nghiệm lập trình Python hạn chế xây dựng các ứng dụng của riêng họ với ít nỗ lực. So với việc xây dựng khung của ứng dụng, điều chỉnh prompt có thể là giai đoạn tốn thời gian hơn trong phát triển ứng dụng đa tác nhân. Trong AgentScope, chúng tôi trang bị cho các tác nhân của mình một bộ cơ chế tự động điều chỉnh prompt để giảm bớt gánh nặng như vậy. Kết hợp với tài nguyên tích hợp phong phú và các mô-đun tương tác người dùng tích hợp, AgentScope làm cho việc xây dựng ứng dụng đa tác nhân trở nên thú vị hơn bao giờ hết.

Khả Năng Chịu Lỗi Mạnh Mẽ cho Các LLM và API Đa Dạng. Khi quy mô và phạm vi của các mô hình và API mở rộng, một cơ chế chịu lỗi mạnh mẽ trong các ứng dụng đa tác nhân trở nên quan trọng hàng đầu. AgentScope tích hợp cơ chế thử lại cấp dịch vụ toàn diện để duy trì độ tin cậy API. AgentScope được trang bị một bộ công cụ sửa lỗi dựa trên quy tắc để xử lý một số vấn đề định dạng rõ ràng trong các phản hồi của LLM. Hơn nữa, AgentScope cung cấp các cấu hình chịu lỗi có thể tùy chỉnh, cho phép các nhà phát triển tùy chỉnh cơ chế chịu lỗi của riêng họ thông qua các tham số như parse_func, fault_handler, và max_retries. Mặc dù thừa nhận rằng không phải tất cả các lỗi đều có thể được xử lý bởi cơ chế đã đề cập, chúng tôi đề xuất một hệ thống logging với các tính năng tùy chỉnh cho các ứng dụng đa tác nhân như biện pháp bảo vệ cuối cùng cho AgentScope.

Tính Tương Thích Mở Rộng cho Đa Phương Thức, Công Cụ và Kiến Thức Bên Ngoài. Với tiến bộ đáng kể của các mô hình đa phương thức quy mô lớn, AgentScope hỗ trợ dữ liệu đa phương thức (ví dụ, văn bản, hình ảnh, âm thanh và video) trong cuộc trò chuyện đối thoại, truyền thông điệp và lưu trữ dữ liệu. Cụ thể, AgentScope tách riêng truyền dữ liệu đa phương thức khỏi lưu trữ và sử dụng chiến lược tải lười bằng cách cung cấp thuộc tính dựa trên URL thống nhất trong thông điệp. Trong quá trình truyền thông điệp, AgentScope chỉ đính kèm một URL vào thông điệp, và dữ liệu đa phương thức chỉ được tải khi cần thiết, chẳng hạn như khi được hiển thị trong web UI hoặc được gọi bởi các wrapper mô hình. Đối với việc sử dụng công cụ, AgentScope cung cấp một thành phần gọi là service toolkit, như một giải pháp một bước cho việc sử dụng công cụ, bao gồm tiền xử lý hàm, kỹ thuật prompt, lý luận và phân tích phản hồi với các tính năng chịu lỗi. Để hỗ trợ việc sử dụng kiến thức bên ngoài hiệu quả, AgentScope cung cấp các mô-đun xử lý kiến thức từ đầu đến cuối, có thể cấu hình cao và có thể chia sẻ cho tạo sinh tăng cường truy xuất (RAG), từ tiền xử lý dữ liệu đến truy xuất có thể tùy chỉnh.

Hiệu Quả Được Tối Ưu Hóa cho Các Hoạt Động Đa Tác Nhân Phân Tán. Nhận thức tầm quan trọng sống còn của triển khai phân tán, AgentScope giới thiệu cơ chế phân tán dựa trên actor cho phép lập trình tập trung các luồng công việc phân tán phức tạp, và tối ưu hóa song song tự động. Cụ thể, các luồng công việc cho triển khai cục bộ và phân tán hoàn toàn giống nhau, cho thấy chi phí không đáng kể khi di chuyển các ứng dụng giữa môi trường tập trung và phân tán. Với khung phân tán như vậy, AgentScope trao quyền cho các nhà phát triển tập trung vào thiết kế ứng dụng thay vì chi tiết triển khai.

Tóm tắt Để tóm tắt, AgentScope, một nền tảng đa tác nhân mới được đề xuất cho tính linh hoạt và mạnh mẽ, bao gồm các tính năng tiên tiến sau:

1. AgentScope cung cấp cơ chế trao đổi thông điệp hướng thủ tục với một bộ tính năng cú pháp để tạo thuận lợi cho lập trình đa tác nhân, một trạm làm việc lập trình kéo-thả không cần code, và một bộ cơ chế tự động điều chỉnh prompt.

2. Các thiết kế chịu lỗi của AgentScope cho phép các nhà phát triển xử lý lỗi một cách trang nhã cho các ứng dụng của họ.

3. Hỗ trợ cho các ứng dụng đa phương thức giảm chi phí tạo sinh và truyền dữ liệu không đồng nhất. Thành phần service toolkit tạo thuận lợi cho việc sử dụng công cụ của các tác nhân trong AgentScope, và các mô-đun xử lý kiến thức cung cấp giải pháp linh hoạt cho các tác nhân xử lý thông tin khác nhau.

4. Chế độ phân tán dựa trên actor của AgentScope có thể giúp phát triển các ứng dụng đa tác nhân phân tán hiệu quả và đáng tin cậy một cách liền mạch.

Lộ trình Trong các phần tiếp theo, chúng tôi điều hướng qua các thành phần và khả năng cốt lõi của AgentScope, thể hiện vai trò của nó trong việc thúc đẩy phát triển và triển khai các ứng dụng đa tác nhân. Phần 2 cung cấp tổng quan, trong khi Phần 3 tập trung vào trải nghiệm người dùng. Phần 4 giới thiệu cơ chế chịu lỗi trong AgentScope. Các phần 5, 6 và 7 bao gồm hỗ trợ đa phương thức, sử dụng công cụ và các mô-đun tạo sinh tăng cường truy xuất trong AgentScope. Phần 8 trình bày hỗ trợ của nền tảng chúng tôi cho các ứng dụng đa tác nhân phân tán. Các trường hợp sử dụng được trình bày trong Phần 9, công trình liên quan được tóm tắt trong Phần 10, và các suy nghĩ kết luận được ghi lại trong Phần 11.

--- TRANG 2 ---
2 Tổng quan

2.1 Các Khái Niệm Cơ Bản trong AgentScope

Phần này giới thiệu các khái niệm chính trong AgentScope: message, agent, service, và workflow. Bốn khái niệm này xuyên suốt nền tảng và tất cả các ứng dụng đa tác nhân dựa trên nó.

• Message: Các thông điệp phục vụ như phương tiện trao đổi thông tin trong các cuộc trò chuyện đa tác nhân, bao gồm nguồn và nội dung của thông tin. Trong AgentScope, các thông điệp được triển khai như các từ điển Python với hai trường bắt buộc (name và content) và một trường tùy chọn (url). Trường name ghi lại tên của tác nhân tạo ra thông điệp, và trường content chứa thông tin dựa trên văn bản được tạo ra bởi tác nhân. Trường url được thiết kế để giữ Uniform Resource Locator (URL), thường liên kết đến dữ liệu đa phương thức, như hình ảnh hoặc video. Các thông điệp có trường này đặc biệt liên quan đến tương tác với các tác nhân có thể xử lý và tạo ra nội dung đa phương thức. Mỗi thông điệp được xác định duy nhất bởi UUID và timestamp được tạo tự động, đảm bảo khả năng theo dõi. Ví dụ 1 cho thấy cách các thông điệp có thể được tạo ra, phục vụ như nguyên tử trong giao tiếp giữa các tác nhân của AgentScope.

```python
from agentscope.message import Msg

msg1 = Msg("Alice", "Hello!")
msg2 = Msg(
    name="Bob",
    content="How do you find this picture I captured yesterday?",
    url="https://xxx.png"
)
```

Ví dụ 1: Các ví dụ minh họa về tạo thông điệp trong AgentScope.

• Agent: Các tác nhân là các tác nhân chính trong các ứng dụng đa tác nhân, hoạt động như những người tham gia trò chuyện và thực thi nhiệm vụ. Trong AgentScope, hành vi tác nhân được trừu tượng hóa thông qua hai giao diện: các hàm reply và observe. Hàm reply nhận một thông điệp làm đầu vào và tạo ra một phản hồi, trong khi hàm observe xử lý các thông điệp đến mà không tạo ra phản hồi trực tiếp. Sự tương tác giữa các tác nhân và thông điệp, như thể hiện trong Ví dụ 2, tạo thành cơ sở hoạt động của AgentScope và là cần thiết để các nhà phát triển mô hình hóa các tương tác phức tạp trong LLM đa tác nhân.

```python
# agent1 and agent2 are two initialized agents, for example
# agent1, agent2 = DialogAgent(...), DialogAgent(...)
msg1 = agent1()
msg2 = agent2(msg1)
```

Ví dụ 2: Trình diễn trao đổi thông điệp giữa các tác nhân trong AgentScope.

• Workflow: Các luồng công việc đại diện cho các chuỗi thực thi tác nhân có thứ tự và trao đổi thông điệp giữa các tác nhân, tương tự như các đồ thị tính toán trong TensorFlow, nhưng với tính linh hoạt để chứa các cấu trúc không phải DAG. Các luồng công việc định nghĩa luồng thông tin và xử lý nhiệm vụ giữa các tác nhân, tạo thuận lợi cho thực thi song song và cải thiện hiệu quả. Khái niệm này rất cần thiết để thiết kế các hệ thống đa tác nhân tương tác với LLM, vì nó cho phép phối hợp các nhiệm vụ phức tạp, phụ thuộc lẫn nhau.

• Service Functions và Tools: Lưu ý rằng các hàm dịch vụ có liên quan chặt chẽ nhưng khác với khái niệm tools trong bối cảnh thiết kế tác nhân trong AgentScope. Các hàm dịch vụ đề cập đến các API chức năng trả về một ServiceResponse được định dạng, trong khi tools đề cập đến các hàm dịch vụ đã xử lý với mô tả chức năng và các tham số đầu vào cần thiết được chuẩn bị. Chúng tôi giới thiệu hai khái niệm này trong AgentScope vì LLM cần giúp đỡ để gọi các hàm dịch vụ như công cụ. Một quan sát là LLM có thể cần giúp đỡ hiểu chức năng của các hàm dịch vụ một cách chính xác và

--- TRANG 3 ---
đòi hỏi thông tin mô tả nhiều hơn để đưa ra quyết định chính xác. Đồng thời, LLM không thể (một cách đáng tin cậy) điền vào một số tham số đầu vào của các API, chẳng hạn như các khóa API của Bing và Google Search. Kết quả là, AgentScope định nghĩa tools như các hàm dịch vụ đã xử lý.

2.2 Kiến Trúc của AgentScope

Chúng tôi trình bày AgentScope như một nền tảng cơ sở hạ tầng để tạo thuận lợi cho việc tạo, quản lý và triển khai các ứng dụng đa tác nhân được tích hợp với LLM. Kiến trúc của AgentScope bao gồm ba lớp phân cấp và một bộ giao diện tương tác người dùng, như thể hiện trong Hình 1. Những lớp này cung cấp hỗ trợ cho các ứng dụng đa tác nhân từ các mức khác nhau, bao gồm các chức năng cơ bản và tiên tiến của một tác nhân đơn lẻ (lớp tiện ích), quản lý tài nguyên và runtime (lớp quản lý và wrapper), và các giao diện lập trình từ cấp tác nhân đến cấp luồng công việc (lớp tác nhân). AgentScope giới thiệu các trừu tượng hóa trực quan được thiết kế để đáp ứng các chức năng đa dạng vốn có của mỗi lớp và đơn giản hóa các phụ thuộc phức tạp giữa các lớp khi xây dựng hệ thống đa tác nhân. Hơn nữa, chúng tôi cung cấp các giao diện lập trình và cơ chế mặc định để tăng cường khả năng phục hồi của các hệ thống đa tác nhân chống lại lỗi trong các lớp khác nhau.

• Lớp Tiện Ích: Là nền tảng của nền tảng, lớp tiện ích trong AgentScope cung cấp các dịch vụ cần thiết để hỗ trợ các chức năng cốt lõi của các tác nhân. Lớp này trừu tượng hóa sự phức tạp của các hoạt động cơ bản, chẳng hạn như gọi API mô hình và các hàm dịch vụ bao gồm thực thi mã và các hoạt động cơ sở dữ liệu, cho phép các tác nhân tập trung vào các nhiệm vụ chính của chúng. Lớp tiện ích của AgentScope được thiết kế với việc dễ sử dụng và mạnh mẽ là ưu tiên hàng đầu, hỗ trợ các hoạt động đa dạng trong các hệ thống đa tác nhân và cung cấp các cơ chế thử lại tự động tích hợp để xử lý ngoại lệ và lỗi chống lại các gián đoạn bất ngờ.

• Lớp Quản Lý và Wrapper: Như một trung gian, lớp trừu tượng hóa quản lý và wrapper quản lý tài nguyên và dịch vụ API, đảm bảo tính khả dụng cao của tài nguyên và cung cấp khả năng chống lại các phản hồi không mong muốn từ LLM. Không giống như lớp tiện ích, cung cấp các trình xử lý mặc định, lớp quản lý và wrapper cũng cung cấp các giao diện có thể tùy chỉnh để kiểm soát chịu lỗi tùy thuộc vào nhu cầu của nhà phát triển và yêu cầu cụ thể của ứng dụng. Lớp này chịu trách nhiệm duy trì tính toàn vẹn hoạt động của các tác nhân, một khía cạnh quan trọng để LLM hoạt động nhất quán

--- TRANG 4 ---
trong các điều kiện đa dạng. Mô tả chi tiết về các cơ chế chịu lỗi được cung cấp trong Phần 4.

• Lớp Tác Nhân: Tại cốt lõi của AgentScope nằm trừu tượng hóa tác nhân, tạo thành xương sống của luồng công việc đa tác nhân và là thực thể chính chịu trách nhiệm tương tác và giao tiếp. Lớp này được thiết kế để tạo thuận lợi cho việc xây dựng các luồng công việc phức tạp và tăng cường khả năng sử dụng, giảm gánh nặng lập trình cho các nhà phát triển. Bằng cách tích hợp cú pháp được sắp xếp hợp lý và công cụ, AgentScope trao quyền cho các nhà phát triển tập trung vào việc triển khai và tối ưu hóa các ứng dụng dựa trên tác nhân tận dụng khả năng của LLM. Các tính năng lập trình và cú pháp đường được giới thiệu trong Phần 3 với nhiều chi tiết hơn.

• Tương tác người dùng: Ngoài kiến trúc phân lớp, AgentScope cung cấp các giao diện hướng đa tác nhân như terminal có chú thích trình bày thông tin cơ bản, Web UI giám sát hệ thống, giao diện dựa trên Gradio (Abid et al., 2019) có thể thay đổi ứng dụng dòng lệnh thành ứng dụng đồ họa chỉ với một bước và trạm làm việc lập trình kéo-thả không cần code (Hình 4). Những giao diện này cho phép các nhà phát triển dễ dàng giám sát trạng thái và các chỉ số của ứng dụng, bao gồm giao tiếp tác nhân, thời gian thực thi và chi phí tài chính.

Tập thể, các cấu trúc phân lớp của AgentScope cung cấp các khối xây dựng cần thiết cho các nhà phát triển để tạo ra các ứng dụng đa tác nhân tùy chỉnh tận dụng khả năng tiên tiến của các mô hình ngôn ngữ lớn. Phần tiếp theo sẽ đi sâu vào các tính năng của AgentScope giúp tăng cường trải nghiệm lập trình cho việc phát triển ứng dụng đa tác nhân.

3 Tính Khả Dụng Cao

Thiết kế của AgentScope ưu tiên tính khả dụng, nhằm hợp lý hóa quy trình phát triển cho đa tác nhân với LLM và đảm bảo trải nghiệm tương tác mượt mà cho cả người dùng và nhà phát triển. Phần này đi sâu vào cách AgentScope làm phẳng đường cong học tập và tăng cường trải nghiệm của lập trình viên bằng cách giới thiệu các khái niệm và tính năng trực quan tạo thuận lợi cho việc tạo ra các ứng dụng đa tác nhân phức tạp.

3.1 Cú Pháp Đường cho Luồng Công Việc Đa Tác Nhân

Tận dụng các khái niệm cơ bản được giới thiệu trong Phần 2.1, các nhà phát triển được trao quyền để xây dựng các ứng dụng đa tác nhân tinh vi. Tuy nhiên, việc mã hóa trực tiếp trao đổi thông điệp của mỗi tác nhân có thể trở nên cồng kềnh, như thể hiện trong Ví dụ 3. Nhận thức điều này, AgentScope giới thiệu hai tiện ích cú pháp: pipeline và message hub, để trừu tượng hóa sự phức tạp và giảm thiểu sự lặp lại.

```python
# set up agents: agent1 to agent5
# ...

msg = agent1(Msg("Alice", "Hello!"))
msg = agent2(msg)
msg = agent3(msg)
msg = agent4(msg)
msg = agent5(msg)
```

Ví dụ 3: Ví dụ lập trình luồng công việc tuần tự với các khái niệm cơ bản trong AgentScope.

Trừu Tượng Hóa Pipeline Trừu tượng hóa pipeline giảm mã hóa lặp lại bằng cách bao gồm các mẫu truyền thông điệp, bao gồm trao đổi tuần tự, có điều kiện và lặp lại, vào các thành phần đơn giản và có thể tái sử dụng. Với những pipeline này, các nhà phát triển có thể tập trung vào logic của tương tác tác nhân thay vì mã boilerplate. Ví dụ 4 minh họa cách pipeline có thể được sử dụng trong cả phong cách hàm và hướng đối tượng để tạo ra luồng công việc tác nhân rõ ràng và ngắn gọn. Ngoài pipeline tuần tự trong ví dụ, AgentScope cũng cung cấp pipeline if-else, switch, while-loop và for-loop, tạo thuận lợi cho việc lập trình các tương tác đa tác nhân.

```python
# set up agents: agent1 to agent5
# ...
from agentscope.pipelines import SequentialPipeline
from agentscope.pipelines.functional import sequentialpipeline

# using functional pipeline
x = sequentialpipeline([agent1, agent2, agent3, agent4, agent5], x)

# using object pipeline
pipe = SequentialPipeline([agent1, agent2, agent3, agent4, agent5])
x = pipe(x)
```

Ví dụ 4: Sử dụng pipeline tuần tự hàm và đối tượng để xây dựng luồng công việc trong AgentScope.

Message Hub cho Giao Tiếp Tác Nhân Trong các hệ thống đa tác nhân, đặc biệt khi được tích hợp với LLM, việc quản lý hiệu quả giao tiếp giữa một nhóm tác nhân là rất cần thiết. Message hub trong AgentScope phục vụ như một cơ chế phát sóng đơn giản hóa các tương tác nhóm. Các nhà phát triển có thể khởi tạo message hub bằng cách định nghĩa các tác nhân tham gia và có thể bao gồm các thông điệp phát sóng ban đầu. Khi các thông điệp mới được tạo ra bởi các tác nhân trong message hub, chúng được tự động phát tán đến các người tham gia khác, như được trình diễn trong Ví dụ 5. Trừu tượng hóa này đặc biệt hữu ích cho các kịch bản đa tác nhân liên quan đến LLM, nơi các cuộc trò chuyện động và giàu ngữ cảnh thường được quan sát (Du et al., 2023).

```python
# set up agents: agent1 to agent4
# ...

greeting = Msg("host", "Welcome to the message hub!")

with msghub(participant=[agent1, agent2, agent3],
            announcement=greeting) as hub:
    # Message will be broadcast to agent2 and agent3 automatically
    agent1()
    
    # Delete agent2 from the message hub
    hub.delete(agent2)
    
    # Add agent4 into the message hub
    hub.add(agent4)
    
    # Broadcast message
    hub.broadcast(Msg("host", "Welcome agent4 to join the hub!"))
```

Ví dụ 5: Sử dụng message hub với AgentScope.

3.2 Môi Trường Phong Phú Tài Nguyên cho Phát Triển Tác Nhân

Để tăng cường hơn nữa tính khả dụng, AgentScope được trang bị một bộ tài nguyên tích hợp phong phú, bao gồm dịch vụ, tác nhân chuyên dụng và các ví dụ được cấu hình sẵn. Những tài nguyên này được thiết kế để giảm nỗ lực thiết lập ban đầu và cho phép tạo mẫu nhanh chóng và triển khai các hệ thống LLM đa tác nhân.

Tích Hợp Dịch Vụ Toàn Diện AgentScope tích hợp nhiều hàm dịch vụ khác nhau, chẳng hạn như tìm kiếm web, truy vấn cơ sở dữ liệu và thực thi mã, để hỗ trợ khả năng sử dụng công cụ của các tác nhân. Những hàm dịch vụ này rất cần thiết để xây dựng các tác nhân hữu ích với LLM, vì các tác nhân thường cần thu thập thông tin từ các nguồn bên ngoài hoặc thực thi các nhiệm vụ vượt ra ngoài kiến thức nội bộ của LLM được trang bị. Ví dụ 6 thể hiện việc chuyển đổi liền mạch một dịch vụ thành định dạng JSON tương thích với OpenAI, đơn giản hóa quá trình tích hợp cho các nhà phát triển.

```python
from agentscope.service import ServiceFactory, web_search

bing_search, func_json = ServiceFactory.get(web_search, engine="bing", api_key="xxx", num_results=10)

print(func_json)
# {
#   "name": "web_search",
#   "description": "Searching the given question with bing.",
#   "parameters": {
#     "type": "object",
#     "properties": {
#       "type": "object",
#       "properties": {
#         "question": {
#           "type": "string",
#           "description": "The string question to search in Bing."
#         }
#       }
#     }
#   }
# }

searching_result = bing_search("What's the date today?")
```

Ví dụ 6: Chuyển đổi dịch vụ tìm kiếm web thành định dạng hàm và từ điển JSON mà tác nhân có thể sử dụng.

Mẫu Tác Nhân Được Xây Dựng Sẵn Như được liệt kê trong Bảng 1, AgentScope cung cấp các tác nhân được xây dựng sẵn và các thành phần sẵn sàng sử dụng cho các nhiệm vụ như quản lý đối thoại, đại diện người dùng, xử lý dữ liệu đa phương thức và triển khai phân tán. Những mẫu này phục vụ như điểm khởi đầu cho các nhà phát triển tùy chỉnh và mở rộng, tăng tốc đáng kể việc phát triển các ứng dụng LLM đa tác nhân.

| Tên Tác Nhân | Chức Năng |
|---------------|-----------|
| UserAgent | Đại diện của người dùng |
| DialogAgent | Một tác nhân đối thoại chung, vai trò có thể được đặt bởi system prompt |
| DictDialogAgent | Một tác nhân đối thoại phiên bản từ điển, phản hồi ở định dạng từ điển Python |
| ReActAgent | Một tác nhân có thể lý luận và sử dụng công cụ |
| ProgrammerAgent | Một tác nhân có thể viết và thực thi mã Python |
| TextToImageAgent | Một tác nhân tạo ra hình ảnh theo yêu cầu |
| RpcUserAgent | Một đại diện người dùng phiên bản phân tán |
| RpcDialogAgent | Một DialogAgent phiên bản phân tán |

Bảng 1: Một số ví dụ về tác nhân tích hợp và chức năng của chúng trong AgentScope.

3.3 Giao Diện Trình Diễn Hướng Đa Tác Nhân

Hơn nữa, AgentScope giới thiệu các giao diện tương tác được thiết kế riêng cho các hệ thống đa tác nhân, như được minh họa trong Hình 2 và 3. Những giao diện này cung cấp trải nghiệm đa phương thức phong phú, quan trọng cho các hệ thống kết hợp LLM xử lý các loại dữ liệu đa dạng.

Phân Biệt Tác Nhân trong Giao Diện Người Dùng Để tạo thuận lợi cho tương tác người dùng với nhiều tác nhân, AgentScope gán màu sắc và biểu tượng duy nhất cho mỗi tác nhân, tăng cường độ rõ ràng và phân biệt trực quan trong cả terminal và web UI (Hình 3). Tính năng "góc nhìn ngôi thứ nhất" cho phép người dùng trải nghiệm tương tác từ góc nhìn của một tác nhân được chỉ định, phù hợp với vai trò của họ trong ứng dụng, chẳng hạn như trong kịch bản trò chơi. Tính năng này không chỉ làm phong phú trải nghiệm đa tác nhân mà còn phản ánh các tương tác tinh tế xảy ra trong các đối thoại giữa người-tác nhân và tác nhân-tác nhân trong các hệ thống LLM.

--- TRANG 5 ---

Hình 2: Lịch sử đối thoại của một trò chơi werewolf trong AgentScope.

Hình 3: Tương tác đa phương thức giữa các tác nhân trong web UI.

Giám Sát và Quản Lý Chi Phí Một khía cạnh quan trọng của việc triển khai LLM ở quy mô lớn là quản lý tài nguyên. AgentScope bao gồm một mô-đun giám sát theo dõi việc sử dụng mô hình và API, cũng như tính toán chi phí tài chính. Các nhà phát triển có thể tùy chỉnh các chỉ số và đặt giới hạn ngân sách, nhận cảnh báo tự động khi tiến gần hoặc vượt quá ngưỡng. Quản lý chi phí chủ động này đặc biệt quan trọng đối với LLM có thể phát sinh chi phí tính toán cao.

Giao Diện AgentScope Gradio Khi bạn có một ứng dụng đa tác nhân, thực thi nó trong terminal có thể là lựa chọn ngắn gọn nhưng thiếu sức hấp dẫn. Trong AgentScope, chúng tôi cung cấp giao diện mạnh mẽ dựa trên Gradio tương thích với tất cả các ứng dụng AgentScope miễn là có hàm main làm điểm vào của ứng dụng. Ví dụ, nếu hàm main của ứng dụng nằm trong tệp application.py, thì chạy "as_studio application.py" có thể xây dựng ứng dụng Gradio với giao diện người dùng đồ họa và hỗ trợ tải lên và trình bày nội dung đa phương thức.

--- TRANG 6 ---

3.4 Hướng Tới Phát Triển Ứng Dụng Đồ Họa

Thiết kế đã đề cập ở trên cung cấp tiện lợi lớn cho những người quen thuộc với lập trình Python để nhanh chóng phát triển các ứng dụng đa tác nhân của họ. Tuy nhiên, AgentScope đi xa hơn một bước. AgentScope cung cấp trạm làm việc trực tuyến kéo-thả nơi các nhà phát triển chỉ cần kéo các khối mô-đun để tạo thành một ứng dụng; sau đó, trạm làm việc có thể tạo ra tệp cấu hình của ứng dụng ở định dạng JSON hoặc thậm chí một đoạn mã Python. Với tính năng này, những người có kinh nghiệm hạn chế với lập trình Python có thể xây dựng ứng dụng đa tác nhân của họ mà không cần viết bất kỳ mã Python nào, trong khi những người quen thuộc với Python có thể ngay lập tức có được một đoạn mã bản thảo sẵn sàng cho việc tùy chỉnh thêm. Ảnh chụp màn hình của trạm làm việc trực tuyến được thể hiện trong Hình 4, và ý tưởng hỗ trợ việc triển khai này được minh họa như sau.

Hình 4: Trạm làm việc lập trình kéo-thả.

Biểu Hiện Ứng Dụng Đa Tác Nhân với các node trong đồ thị có hướng acyclic (DAG). Dựa trên thiết kế mô-đun hóa cao của cơ sở hạ tầng cơ bản, tất cả các thành phần chính có thể được đại diện như một node, và một ứng dụng có thể được xây dựng bằng cách xây dựng đồ thị chu kỳ có hướng (DAG). Việc thực thi ứng dụng tương đương với việc kích hoạt và chạy các node trong đồ thị theo thứ tự duyệt của DAG. Theo các thuật ngữ truyền thống, chúng tôi gọi việc thực thi DAG như vậy là một workflow và gọi các node trong workflow là workflow nodes. Theo chức năng của chúng, các workflow nodes được phân loại thành sáu loại khác nhau: model nodes, agent nodes, pipeline nodes, service nodes và copy nodes.

• Model nodes: Model nodes được thiết kế để tương đối độc lập với DAG. Chúng tương ứng với các cấu hình mô hình trong AgentScope và hoạt động như các mục để cho phép người dùng cấu hình mô hình của họ (LLM, mô hình embedding, hoặc mô hình đa phương thức) và duy trì thông tin như vậy cho tất cả các node trong workflow tiếp theo cần sử dụng mô hình.

• Service (tool) nodes: Những node này tương ứng với các dịch vụ có sẵn trong AgentScope. Một số trong số chúng yêu cầu thông tin bổ sung để thiết lập, chẳng hạn như Google search và Bing search, yêu cầu khóa API; những cái khác có thể được sử dụng trực tiếp.

• Agent nodes: Như tên gọi, agent nodes đại diện cho các tác nhân trong AgentScope, có nghĩa là người dùng cần quyết định mô hình, tên tác nhân và system prompt cho tác nhân.

• Pipeline nodes: Pipeline node bao gồm các toán tử của AgentScope, bao gồm message hub và các pipeline (sequential, for-loop, while-loop, v.v.). Với những node như vậy, biểu diễn DAG có thể ngắn gọn như lập trình Python.

• Message node: Message node được thiết kế cho các trường hợp cần một số thông điệp ban đầu, chẳng hạn như thông báo (thông điệp ban đầu) cho message hub.

• Copy node: Copy node là loại node đặc biệt sao chép kết quả của node cha khi đầu ra của nó cần thiết cho nhiều hoạt động tiếp theo.

Thực Thi DAG với JSON hoặc biên dịch sang Python. Với các node ở trên, các nhà phát triển có thể xây dựng ứng dụng bằng cách tạo thành DAG. Tuy nhiên, DAG phụ thuộc nhiều vào UI. Mặc dù DAG có thể được biểu diễn trong một số định dạng (ví dụ, định dạng JSON ghi lại thông tin của mỗi node và phụ thuộc thực thi), chúng tôi vẫn cần đảm bảo nó có thể tái sử dụng như các ứng dụng khác. Để khắc phục điều này, AgentScope được trang bị cấu trúc dữ liệu gọi là ASDiGraph, cung cấp hai giải pháp dựa trên nó.

• Direct-run: Với tệp JSON ghi lại thông tin DAG, ASDiGraph có thể phân tích thông tin DAG và sắp xếp các node theo thứ tự tô-pô. Với những node được sắp xếp này, hàm run của ASDiGraph có thể thực thi chúng theo thứ tự và truyền đầu ra của người tiền nhiệm đến người kế thừa khi một ứng dụng được thực thi từng bước.

• To-Python compiler: Giải pháp thứ hai là dịch tệp JSON sang script Python. Với các thành phần được mô-đun hóa cao của AgentScope, ý tưởng chính là dựa vào các ánh xạ nội bộ của chức năng, đầu vào yêu cầu và đầu ra dự kiến ​​thành các đoạn mã Python nhỏ. Cụ thể, mỗi node chứa mã Python để import các mô-đun phụ thuộc, khởi tạo mô hình hoặc tác nhân, và thực thi logic ứng dụng. ASDiGraph trước tiên nhóm các đoạn mã import và khởi tạo, sau đó nó tạo thành các đoạn mã thực thi theo thứ tự tô-pô. Do đó, người dùng sẽ có được một script Python hoàn chỉnh sau khi ASDiGraph hoàn thành biên dịch.

3.5 Điều Chỉnh Prompt Tự Động

Đối với một hệ thống đa tác nhân sử dụng LLM để tạo sinh, việc viết prompt phù hợp đòi hỏi nỗ lực và chuyên môn đáng kể của con người (Pryzant et al., 2023), điều này thúc đẩy chúng tôi cung cấp tạo sinh prompt tự động và điều chỉnh trong AgentScope cho tính khả dụng cao của nó. Cụ thể, AgentScope cho phép người dùng tạo ra prompt dựa trên mô tả đơn giản của tác nhân bằng ngôn ngữ tự nhiên, cập nhật prompt theo ngữ cảnh, và cho phép học trong ngữ cảnh.

Điều Chỉnh System Prompt Khi một tác nhân được tạo ra, một system prompt nên được liên kết với tác nhân để xác định vai trò và trách nhiệm của nó trong việc tuân theo hướng dẫn của con người. Ví dụ, một Programmer Agent có thể được nhắc như "You are proficient in writing and executing Python code". Đồng thời, một system prompt chi tiết và có thông tin có thể cải thiện hiệu suất tác nhân và đảm bảo rằng tác nhân hoạt động như mong đợi, chẳng hạn như "You are proficient in writing and executing Python code. You prefer to write the code in a modular fashion and provide unit tests for each module". Với AgentScope, người dùng chỉ cần cung cấp mô tả đơn giản của tác nhân khi tạo ra các tác nhân, và AgentScope có thể tự động tạo ra những system prompt hữu ích như vậy sử dụng các công cụ tích hợp dựa trên LLM, như thể hiện trong Ví dụ 7.

```python
# set up agents with automatic prompt generation
# ...
from agentscope.agents import ProgrammerAgent

# Load model configs
agentscope.init(model_configs="model_configs.json")

# Create a programmer agent
programmer_agent = ProgrammerAgent(name="assistant", auto_sys_prompt=True,
                                   model_config_name="my_config",
                                   sys_prompt="an assistant that can write Python code")
```

Ví dụ 7: Khởi tạo một programmer agent với tạo sinh system prompt tự động.

Ngoài ra, AgentScope cung cấp các giao diện để cập nhật system prompt, bao gồm thiết lập thủ công bởi người dùng hoặc tự động điều chỉnh dựa trên ngữ cảnh. Như một hướng tương lai đầy hứa hẹn, các kỹ thuật meta-prompting (Pryzant et al., 2023; Suzgun and Kalai, 2024) cũng có thể được tích hợp vào AgentScope, có thể liên quan đến việc tích hợp một đánh giá viên để cung cấp hướng dẫn cho tối ưu hóa prompt tự động.

Học Trong Ngữ Cảnh Cung cấp nhiều minh họa cho LLM có thể tăng cường đáng kể khả năng tuân theo hướng dẫn của chúng, đặc biệt khi chúng ta muốn chúng hoàn thành các nhiệm vụ downstream cụ thể (Dai et al., 2023; Wei et al., 2022). AgentScope cung cấp công tắc đơn giản để bật/tắt hành vi học trong ngữ cảnh cho các tác nhân sử dụng LLM. Khi người dùng chọn áp dụng học trong ngữ cảnh, họ chỉ cần cung cấp các ứng viên minh họa và cấu hình cách khớp những cái phù hợp nhất, như được minh họa trong Ví dụ 8. AgentScope cung cấp một số cách tiếp cận khớp được sử dụng rộng rãi và hữu ích, chẳng hạn như lựa chọn ngẫu nhiên, câu hỏi tương tự và câu trả lời tương tự, và cho phép tùy chỉnh người dùng.

```python
# set up agents with in-context learning
# ...
from agentscope.agents import ReActAgent
from agentscope.utils.common import load_demo_data

# Load model configs
agentscope.init(model_configs="model_configs.json")

# Load demonstrations
react_pairs = load_demo_data("my_demos.txt")

# Create a reAct agent
react_agent = ReActAgent(name="react_agent", enable_icl=True,
                         demos=react_pairs, matching_approach="random")
```

Ví dụ 8: Kích hoạt học trong ngữ cảnh khi tạo ra tác nhân.

4 Cơ Chế Chịu Lỗi

Trong lĩnh vực các hệ thống đa tác nhân, đặc biệt là những hệ thống giao tiếp với các LLM mã nguồn mở đa dạng với khả năng tuân theo hướng dẫn khác nhau, khả năng chịu lỗi là một tính chất quan trọng để đảm bảo hoạt động liền mạch. AgentScope được thiết kế để tự động xử lý một loạt rộng các lỗi với sự can thiệp tối thiểu của con người, dựa trên cơ sở hạ tầng chịu lỗi toàn diện nhận thức sâu sắc về sự phức tạp liên quan đến phối hợp đa tác nhân và các phụ thuộc LLM.

Phân Loại Lỗi và Chiến Lược Xử Lý Cách tiếp cận của chúng tôi bắt đầu với phân loại có phương pháp các lỗi thành các cấp độ riêng biệt, mỗi cấp với các chiến lược xử lý phù hợp:

• Lỗi khả năng truy cập: Trong AgentScope, chức năng của tác nhân dựa vào các loại dịch vụ khác nhau, nhưng những dịch vụ đó có thể gặp phải lỗi tạm thời không thể truy cập. Những lỗi này có thể được gây ra bởi sự không ổn định của mô hình hoặc điều kiện mạng. Ví dụ, các API mô hình có thể trả về lỗi timeout khi có tắc nghẽn giao thông trong giờ cao điểm, hoặc cơ sở dữ liệu trên máy từ xa có thể không thể truy cập được vì sự cố mạng tạm thời.

• Lỗi có thể giải quyết bằng quy tắc: Khi nhiều ứng dụng đa tác nhân yêu cầu trao đổi thông tin giữa các dịch vụ hoặc tác nhân, việc tuân theo các giao thức cho những giao tiếp đó là rất cần thiết, ví dụ, ở định dạng JSON. Tuy nhiên, vì các phản hồi của LLM chưa hoàn toàn có thể kiểm soát được, việc trả về của chúng có thể không tuân theo định dạng yêu cầu trong các prompt. Ví dụ, chúng ta có thể mong đợi phản hồi từ LLM ở định dạng JSON, nhưng dấu ngoặc phải bị thiếu ở cuối kết quả trả về, dẫn đến lỗi phân tích. Vì định dạng JSON có thông số kỹ thuật rõ ràng, việc giả định rằng một tập hợp con của những lỗi này có thể được giải quyết bằng cách sửa định dạng theo quy tắc để đáp ứng thông số kỹ thuật là hợp lý.

• Lỗi có thể giải quyết bằng mô hình: Khi một hệ thống đa tác nhân xử lý một số nhiệm vụ phức tạp, khả năng của tác nhân hiểu đầu vào, đưa ra quyết định và cung cấp đầu ra chủ yếu phụ thuộc vào khả năng của LLM. Trong một số trường hợp, các phản hồi của LLM ở định dạng mong đợi, nhưng nội dung có vấn đề, chẳng hạn như lỗi đối số, lỗi ngữ nghĩa hoặc lỗi lập trình. Khó có thể có các quy tắc được xác định trước để điều chỉnh những phản hồi đó cho các nhiệm vụ đa dạng, nhưng cũng đã được chỉ ra rằng những lỗi như vậy có thể được phát hiện và khôi phục bằng tương tác thêm với LLM.

• Lỗi không thể giải quyết: Cuối cùng, chắc chắn phải có một số lỗi không thể được phát hiện hoặc giải quyết. Một ví dụ điển hình là khóa API của một LLM đã hết hạn hoặc không được ủy quyền. Các tác nhân dựa vào nó hoặc hệ thống không thể làm gì để giải quyết những lỗi như vậy mà không có sự can thiệp của con người.

Cơ Chế Chịu Lỗi trong AgentScope Trong AgentScope, chúng tôi cung cấp các cơ chế khác nhau để gặp phải các lỗi được tóm tắt ở trên.

• Cơ chế tự động thử lại cơ bản: Để chống lại lỗi khả năng truy cập, các dịch vụ API và wrapper mô hình của AgentScope được tăng cường bằng logic thử lại mà các nhà phát triển có thể tùy chỉnh, chẳng hạn như đặt số lần thử lại tối đa. Điều này đảm bảo rằng các tác nhân có thể phục hồi từ các gián đoạn thất thường và duy trì tính liên tục hoạt động của chúng.

• Công cụ sửa lỗi dựa trên quy tắc: Các công cụ sửa lỗi dựa trên quy tắc được giới thiệu vào AgentScope để xử lý hiệu quả và tiết kiệm một số lỗi định dạng dễ sửa trong các phản hồi của LLM. Ví dụ, chúng tôi thiết lập một bộ quy tắc mặc định trong AgentScope có thể hoàn thành các dấu ngoặc không khớp và trích xuất dữ liệu JSON từ chuỗi. Những công cụ sửa lỗi dựa trên quy tắc như vậy có thể sửa một số lỗi có thể giải quyết bằng quy tắc phổ biến mà không cần gọi API LLM lại, có nghĩa là thời gian xử lý ngắn hơn và không có chi phí gọi API LLM.

• Trình xử lý lỗi có thể tùy chỉnh: AgentScope cũng tích hợp các giao diện linh hoạt của trình xử lý lỗi trong wrapper mô hình để các nhà phát triển xác định cách phân tích các phản hồi từ LLM và xử lý các đầu ra bất ngờ. Các nhà phát triển ứng dụng có thể cấu hình cơ chế xử lý lỗi của họ bằng cách cung cấp hàm phân tích, hàm xử lý lỗi và số lần cơ hội được trao cho LLM thông qua các tham số có thể cấu hình (tức là parse_func và fault_handler và max_retries) khi gọi LLM. Với thiết kế thân thiện với nhà phát triển như vậy, AgentScope có thể được cấu hình mạnh mẽ để chống lại lỗi có thể giải quyết bằng quy tắc (khi các quy tắc tích hợp thất bại trong việc xử lý) và một số lỗi có thể giải quyết bằng mô hình có thể được phát hiện và xử lý bởi một tác nhân đơn lẻ (ví dụ, chưng cất một tóm tắt dài dòng thành một cái ngắn gọn hơn).

• Xử lý lỗi cấp tác nhân: Có những lỗi có thể giải quyết bằng mô hình yêu cầu sử dụng LLM tiên tiến hơn hoặc tương tác cấp tác nhân để phục hồi. Ví dụ, phát hiện lỗi ngữ nghĩa, thường bao gồm sự không chính xác về thực tế, sự không nhất quán về logic, sự không mạch lạc về ngữ cảnh, suy luận không hợp lý và việc sử dụng từ vựng không phù hợp, là thách thức vì chúng có thể không nhất thiết kích hoạt cờ đỏ ngay lập tức trong các quy trình xác thực hiện có của hệ thống. Các nhà phát triển có thể sử dụng khả năng của tác nhân trong AgentScope (ví dụ, mô-đun bộ nhớ và message hub) để phê bình kiểm tra lỗi ngữ nghĩa như tự phê bình, phê bình theo cặp và phê bình tăng cường con người.

• Hệ thống logging: Mặc dù các lỗi không thể giải quyết quá khó khăn đối với hệ thống để xử lý, AgentScope cung cấp hệ thống logging cải tiến cho các nhà phát triển để nhanh chóng giám sát và xác định các vấn đề trong các ứng dụng đa tác nhân. Hệ thống logging trong AgentScope có các tính năng tùy chỉnh cho các kịch bản ứng dụng đa tác nhân, bao gồm thêm mức logging gọi là CHAT để logging các cuộc trò chuyện giữa các tác nhân, cung cấp log được định dạng với thông tin thực thi khác nhau, và giao diện người dùng WebUI để tạo thuận lợi cho việc giám sát.

5 Ứng Dụng Đa Phương Thức

Việc tích hợp dữ liệu đa phương thức là không thể thiếu để thúc đẩy khả năng và ứng dụng của đa tác nhân với LLM. AgentScope được thiết kế để hỗ trợ liền mạch các phương thức dữ liệu khác nhau, tận dụng các đầu vào và đầu ra đa dạng mà LLM đương đại có thể xử lý và tạo ra.

Quản Lý Dữ Liệu Đa Phương Thức Trong một ứng dụng AgentScope đang chạy, vòng đời của dữ liệu đa phương thức được quản lý cẩn thận. Quản lý này bao gồm việc tạo sinh, truyền và lưu trữ dữ liệu đa phương thức—tất cả được tạo thuận lợi thông qua kiến trúc tách rời sử dụng URL và hệ thống quản lý tệp cục bộ. Hình 5 minh họa quá trình này, bao gồm dữ liệu có nguồn gốc từ đầu vào của người dùng hoặc tạo sinh mô hình, lưu trữ và truy xuất dữ liệu, và chia sẻ dữ liệu.

Hình 5: Việc tạo sinh, lưu trữ và truyền dữ liệu đa phương thức trong AgentScope.

• Tạo sinh dữ liệu đa phương thức: Có hai nguồn chính của dữ liệu đa phương thức trong AgentScope. Một nguồn chỉ đơn giản là các tệp đa phương thức được lưu trữ cục bộ, có thể được sử dụng bởi các tác nhân đại diện người dùng hoặc tác nhân chung có quyền truy cập vào hệ thống tệp cục bộ. Nguồn khác là các mô hình tạo sinh nội dung đa phương thức. Các API mô hình và wrapper mô hình của chúng tôi tích hợp các mô hình đa phương thức phổ biến nhất, chẳng hạn như các mô hình tạo sinh nội dung từ văn bản thành hình ảnh như DALL-E của OpenAI, và ngược lại, các mô hình phân tích hình ảnh từ hình ảnh thành văn bản, ví dụ, GPT-4V. Ngoài các API tích hợp, các nhà phát triển có thể giới thiệu các mô hình đa phương thức yêu thích của họ và tùy chỉnh wrapper mô hình riêng của họ, với các ví dụ sẵn sàng sử dụng làm điểm khởi đầu. Quá trình tùy chỉnh này được hợp lý hóa trong AgentScope và có lợi từ thiết kế mô-đun của chúng tôi, cho phép các nhà phát triển kết nối các dịch vụ đa phương thức của họ với nỗ lực tối thiểu.

• Lưu trữ dữ liệu đa phương thức: Như đã đề cập ở trên, dữ liệu đa phương thức trong ứng dụng đa tác nhân có thể từ các tệp cục bộ sẵn sàng sử dụng hoặc được tạo ra bởi các mô hình đa phương thức. Khi wrapper mô hình đa phương thức được gọi để tạo ra dữ liệu đa phương thức, nó trước tiên lưu dữ liệu cục bộ với sự giúp đỡ của trình quản lý tệp và trả về URL cục bộ khi nhận dữ liệu đa phương thức từ dịch vụ API mô hình.

• Truyền dữ liệu đa phương thức: AgentScope đơn giản hóa quá trình chia sẻ dữ liệu đa phương thức giữa các tác nhân bằng cách cho phép các tác nhân bao gồm URL cục bộ hoặc từ xa trong các thông điệp đa phương thức để chỉ ra vị trí lưu trữ thực tế của dữ liệu. Các tác nhân nhận có thể tải dữ liệu đa phương thức thông qua URL khi sẵn sàng xử lý những dữ liệu đó.

Lợi ích của việc giới thiệu URL trong các thông điệp khi các tác nhân chia sẻ dữ liệu đa phương thức có ba khía cạnh. Thứ nhất, nó có thể giảm thiểu kích thước thông điệp để tránh các lỗi tiềm ẩn hoặc độ trễ vì băng thông mạng và cho phép tác nhân nhận tải dữ liệu theo yêu cầu. Thứ hai, nếu có thông tin văn bản khác trong thông điệp, các tác nhân downstream có thể ưu tiên hoặc song song việc xử lý thông tin văn bản với việc xử lý thông tin đa phương thức. Cuối cùng nhưng không kém phần quan trọng, những thông điệp đính kèm URL như vậy cũng có thể tạo thuận lợi cho việc trình diễn dữ liệu đa phương thức, sẽ được giới thiệu trong phần tiếp theo.

Chế Độ Tương Tác Đa Phương Thức Với việc triển khai các thông điệp đính kèm URL, AgentScope trao quyền cho người dùng tương tác với các hệ thống đa phương thức thông qua các giao diện có thể truy cập như terminal và web UI. Hình 3 thể hiện khả năng của người dùng tương tác với dữ liệu đa phương thức trong các chế độ tương tác. Trong terminal, người dùng có thể dễ dàng truy cập dữ liệu được lưu trữ cục bộ bằng cách kích hoạt các URL được cung cấp. Web UI tăng cường hơn nữa trải nghiệm người dùng bằng cách cung cấp nền tảng trực quan để xem và phân tích nội dung đa phương thức, phù hợp với kỳ vọng của các ứng dụng web hiện đại.

Thông qua AgentScope, các nhà phát triển được trang bị để tùy chỉnh các dịch vụ API mô hình và wrapper theo nhu cầu cá nhân của họ, tạo ra các ứng dụng xử lý các phương thức dữ liệu đa dạng, và cung cấp cho người dùng các công cụ cần thiết để tương tác hiệu quả với các tác nhân đa phương thức. Hỗ trợ toàn diện này cho các ứng dụng đa phương thức định vị AgentScope như một khung linh hoạt và mạnh mẽ để khai thác toàn bộ tiềm năng của LLM đa tác nhân, mở rộng chân trời cho các nhà phát triển và nhà nghiên cứu trong việc tạo ra các hệ thống AI tinh vi và tương tác.

6 Sử Dụng Công Cụ

Sử dụng công cụ là một tính năng quan trọng cho các tác nhân được trao quyền bởi LLM, cho phép các tác nhân nhận thức, thay đổi môi trường của chúng và xử lý các nhiệm vụ phức tạp hơn (Wu et al., 2023; Paranjape et al., 2023; Parisi et al., 2022). Để đơn giản, chúng tôi coi việc sử dụng công cụ tương đương với việc gọi các hàm dịch vụ bởi LLM. Trong AgentScope, mô-đun sử dụng công cụ được thiết kế dựa trên thuật toán ReAct (Yao et al., 2023), cho phép tạo ra lý luận xen kẽ và các hành động cụ thể cho nhiệm vụ, cùng với một thành phần cốt lõi—service toolkit. Thiết kế như vậy có tính tương thích cao, khả năng mở rộng, mạnh mẽ và khả năng tái sử dụng, trải dài từ tiền xử lý hàm, kỹ thuật prompt, lý luận và phân tích phản hồi đến khả năng chịu lỗi cấp tác nhân. Cụ thể, trong AgentScope việc sử dụng công cụ liên quan đến bốn bước:

• Chuẩn Bị Hàm: Phân tích các hàm dịch vụ được cung cấp, và tiền xử lý các hàm để LLM có thể sử dụng chúng trực tiếp.

• Chuẩn Bị Hướng Dẫn: Chuẩn bị prompt hướng dẫn cho việc sử dụng công cụ để mô tả các hàm công cụ có sẵn cho LLM, bao gồm mục đích, đối số, ràng buộc của hàm và định dạng gọi của nó.

• Lý Luận Lặp Lại: LLM tạo ra lý luận chiến lược, đưa ra quyết định cho việc sử dụng công cụ và phản hồi ở định dạng yêu cầu.

• Hành Động Lặp Lại: Phân tích và kiểm tra phản hồi LLM theo định dạng gọi, gọi các hàm nếu phản hồi tuân thủ định dạng mong đợi, hoặc tạo ra thông báo lỗi chi tiết cho LLM để sửa chữa.

Trong quá trình trên, mô-đun service toolkit chịu trách nhiệm quản lý hàm công cụ, tiền xử lý, kỹ thuật prompt, phân tích phản hồi và thực thi hàm, và nó có tính mô-đun cao và có thể mở rộng. Hình 6 thể hiện cách service toolkit hoạt động trong AgentScope khi người dùng đăng một truy vấn.

Hình 6: Mô-đun sử dụng công cụ dựa trên ReAct trong AgentScope.

Chuẩn Bị Hàm. Trong chuẩn bị hàm, mục tiêu là đặt trước các đối số cụ thể của nhà phát triển, và tạo ra các hàm sẵn sàng sử dụng và mô tả được định dạng tương ứng của chúng cho LLM. Trong AgentScope, các nhà phát triển chỉ cần đăng ký các hàm của họ với các đối số đặt trước trong service toolkit. Như thể hiện trong Hình 6, các nhà phát triển chọn hàm Bing search và cung cấp khóa API trong quá trình đăng ký. Sau đó service toolkit sẽ tự động tạo ra hàm sẵn sàng sử dụng đã xử lý và mô tả của nó ở định dạng schema JSON. Các mô tả sẽ được sử dụng để tạo ra hướng dẫn công cụ bằng ngôn ngữ tự nhiên. Tùy chọn, một số API mô hình (ví dụ, OpenAI và DashScope Chat API, v.v.) có thể nhận các mô tả schema JSON trực tiếp, mà chúng tôi sẽ thảo luận trong Phần 6.1.

Chuẩn Bị Hướng Dẫn Đối với các nhà phát triển mới, service toolkit xây dựng trong các mẫu cho hướng dẫn công cụ và định dạng gọi cho việc sử dụng công cụ, như được thể hiện trong Hình 6. Mẫu hướng dẫn công cụ liệt kê từng hàm với mô tả rõ ràng và các tham số nó yêu cầu, dẫn đến việc hiểu dễ dàng về chức năng của chúng. Mặt khác, định dạng gọi, như được thể hiện trong Hình 6, yêu cầu từ điển JSON trong khối mã được bao quanh bởi Markdown với các trường thought, speak và function. Trong quá trình tạo sinh LLM, chúng tôi mong đợi trường thought sẽ cung cấp quá trình lý luận cho hành động tiếp theo, bao gồm phân tích tình huống hiện tại, lựa chọn các hàm ứng viên và sửa lỗi.

Lý Luận Lặp Lại Trong AgentScope các bước lý luận và hành động là lặp lại. Như đã nêu ở trên, trong bước lý luận, LLM nên phân tích tình huống hiện tại và quyết định các hành động tiếp theo. Các nhà phát triển chỉ cần xây dựng prompt với hướng dẫn công cụ và hướng dẫn định dạng gọi và đưa chúng vào LLM. Thiết kế như vậy cung cấp tính tái sử dụng cao và linh hoạt, nghĩa là, service toolkit độc lập với nhiệm vụ và có thể được thích ứng với các nhiệm vụ và kịch bản khác nhau rất dễ dàng.

Hành Động Lặp Lại Trong bước hành động, service toolkit sẽ phân tích phản hồi LLM theo định dạng gọi, trích xuất hàm đã chọn và thực thi nó với các đối số tương ứng. Nếu phản hồi tuân thủ yêu cầu định dạng, và hàm thực thi thành công, service toolkit sẽ trả về kết quả thực thi trực tiếp, mà LLM có thể tạo ra phản hồi dựa trên trong bước lý luận tiếp theo. Nếu không, chúng tôi phân tích lỗi thành lỗi phân tích phản hồi, lỗi thực thi hàm và lỗi runtime khác. Đối với lỗi phân tích phản hồi và lỗi thực thi hàm, chúng tôi tiết lộ chúng cho LLM với thông tin lỗi chi tiết để sửa chữa trong lần lặp lý luận-hành động tiếp theo, để lại các lỗi runtime khác cho các nhà phát triển.

6.1 Tùy Chỉnh cho Nhà Phát Triển Có Kinh Nghiệm

AgentScope hỗ trợ các nhà phát triển tùy chỉnh cao hướng dẫn công cụ và định dạng gọi hàm của họ. Để tùy chỉnh hướng dẫn công cụ, service toolkit trong AgentScope cung cấp các mô tả schema JSON tự động, cung cấp cách có cấu trúc để mô tả cách một hàm nên được gọi, bao gồm tên, mục đích, đối số và các chi tiết liên quan khác. Những mô tả được định dạng này có thể được đưa trực tiếp vào một số API mô hình tiên tiến, ví dụ API OpenAI và DashScope Chat. Đối với người dùng muốn tùy chỉnh sâu hướng dẫn công cụ của họ, họ có thể xây dựng hướng dẫn dựa trên các mô tả schema JSON.

Ngoài hướng dẫn công cụ, AgentScope cũng cung cấp tính linh hoạt lớn, nghĩa là, AgentScope cung cấp nhiều trình phân tích phản hồi mô hình khác nhau, bao gồm khối mã được bao quanh bởi Markdown, khối mã đối tượng JSON và nội dung được gắn thẻ có thể tùy chỉnh, như được thể hiện trong Hình 7. Đối với người dùng muốn tùy chỉnh định dạng gọi hàm, khối mã được bao quanh bởi Markdown và khối mã đối tượng JSON cho phép họ nhanh chóng xây dựng hướng dẫn định dạng và phân tích phản hồi LLM theo các loại nội dung. Đối với người dùng muốn có được nhiều trường từ LLM, nội dung nhiều thẻ cho phép các nhà phát triển kết hợp các nội dung được gắn thẻ khác nhau theo ý muốn và trích xuất chúng dễ dàng từ phản hồi vào từ điển Python. Với những trình phân tích này, các nhà phát triển có thể tùy chỉnh định dạng gọi riêng của họ một cách dễ dàng.

Hình 7: Các trình phân tích trong AgentScope.

7 Tác Nhân với Tạo Sinh Tăng Cường Truy Xuất

Với các ứng dụng ngày càng tăng của LLM, một số hoàn cảnh yêu cầu kiến thức không được chứa trong tập dữ liệu đào tạo, ví dụ, kiến thức trong các lĩnh vực chuyên môn cao hoặc không công khai. Ngay cả khi được cung cấp các tập dữ liệu yêu cầu, việc tinh chỉnh hoặc đào tạo lại LLM vẫn đắt đỏ. Theo đó, tạo sinh tăng cường truy xuất (RAG), một cách tiếp cận đổi mới nhằm tăng cường sức mạnh của LLM trong lĩnh vực kiến thức tùy chỉnh (Gao et al., 2023; Lewis et al., 2020b), đang nhận được sự chú ý ngày càng tăng trong văn học.

Phương pháp của RAG có thể được coi là chèn một bước tiền xử lý vào pipeline sử dụng phổ biến của LLM. Nghĩa là, với một bộ sưu tập tài liệu chứa kiến thức cần thiết, một chỉ mục dựa trên độ tương tự được xây dựng, và đầu vào ban đầu của người dùng được nén với các đoạn thông tin liên quan nhất và được chuyển đổi thành prompt, sau đó được đưa vào LLM. Do đó, phương pháp của RAG liên quan đến nhiều giai đoạn, nghĩa là, việc thu thập tài liệu có chứa thông tin cần thiết, phân đoạn tài liệu, lập chỉ mục các đoạn (còn gọi là chunk hoặc node), truy xuất chỉ mục dựa trên độ tương tự, hợp nhất truy vấn ban đầu (tức là đầu vào người dùng) và kết quả được truy xuất, soạn thảo prompt, và cuối cùng, tạo ra phản hồi hợp lý từ LLM dựa trên prompt thông tin.

Tóm lại, RAG kết hợp cả sức mạnh của truy xuất thông tin và khả năng tạo sinh của LLM, và cung cấp dịch vụ LLM tăng cường với kiến thức lĩnh vực tùy chỉnh với chi phí thấp. Đồng thời, được hỗ trợ bởi RAG, ảo giác có thể được tránh và độ chính xác thực tế có thể được cải thiện đáng kể.

Như một nền tảng đa tác nhân hướng nhà phát triển, AgentScope cung cấp hỗ trợ RAG toàn diện cho các ứng dụng đa tác nhân. Với các khung RAG phổ biến như ví dụ, LlamaIndex (Liu, 2022), LangChain (Langchain-AI, 2023), v.v., AgentScope được thiết kế với các quy trình trừu tượng hóa rất linh hoạt để tương thích với những khung đó. Trong những gì sau đây, chúng tôi giới thiệu một số tính năng chính của AgentScope RAG.

Cấu Hình Một Điểm Dừng Do sự phức tạp của pipeline làm việc, việc cấu hình các dịch vụ RAG rất phức tạp và thường gây đau đầu cho người dùng. Trong khi dịch vụ RAG được cung cấp bởi AgentScope là toàn diện và cũng liên quan đến luồng công việc đa tác nhân, AgentScope cung cấp giải pháp cấu hình một điểm dừng đơn giản bằng cách sử dụng một tệp .json để nhóm tất cả các cấu hình liên quan đến RAG.

Với giao diện cấu hình có hệ thống cao này, người dùng chỉ cần tập trung vào việc xây dựng luồng công việc, mà không bị phân tâm bởi các cấu hình lặp lại. Ví dụ, các tác nhân được trao quyền bởi RAG có thể liên quan đến một bộ sưu tập rộng các cơ sở kiến thức cần được cấu hình chi tiết. Với tính năng "Một Điểm Dừng" này, các điều chỉnh tương ứng của các mô-đun (có thể dẫn đến hiệu suất khác nhau) được tích hợp như việc chỉnh sửa trên chỉ một tệp duy nhất. Hơn nữa, giải pháp này cũng tự nhiên thích ứng với AgentScope Workstation, trong đó cấu hình dựa trên hộp thoại có thể được xuất ra dễ dàng thành các tệp có thể thực thi và sau đó được tải trong các chương trình Python.

Quản Lý Dữ Liệu Hướng Kiến Thức Việc ứng dụng RAG trong hoàn cảnh đa tác nhân phức tạp hơn so với việc ứng dụng trên một tác nhân đơn lẻ. Ví dụ, đối với một tác nhân đơn lẻ, người ta có thể trực tiếp bao gồm kiến thức cần thiết cho tác nhân. Do đó, việc khởi tạo mỗi tác nhân RAG liên quan đến toàn bộ pipeline chuyển đổi từ các tài liệu gốc thành các chỉ mục được lưu trữ vector với các trình truy xuất. Tuy nhiên, trong các ứng dụng đa tác nhân, việc các tác nhân chia sẻ kiến thức là tự nhiên, do đó việc thực thi lặp lại tính toán chỉ mục cho mỗi tác nhân là không cần thiết. Do đó, AgentScope giới thiệu khái niệm knowledge banks.

Knowledge banks có thể được coi là một bộ sưu tập các container kiến thức, nơi đơn vị có thể quản lý nhỏ nhất là một đối tượng tùy chỉnh (sẽ được gọi là "đối tượng RAG" trong ngữ cảnh sau đây). Luồng công việc bắt đầu với việc khởi tạo knowledge bank, chủ yếu dựa vào thông tin được chứa trong tệp cấu hình .json. Thông tin bao gồm thư mục và phần mở rộng (chẳng hạn như .py hoặc .md) của tài liệu, mức độ chi tiết và lựa chọn công cụ phân đoạn (ví dụ, các splitter trong Llama-Index) cho tài liệu, và lựa chọn mô hình để lập chỉ mục. Sau khi khởi tạo, các kết quả được tính toán được duy trì vào thư mục được chỉ định để sử dụng sau này và chúng tôi cũng có được một knowledge bank bao gồm các đối tượng RAG, mỗi cái được đánh dấu bằng một knowledge_id duy nhất, được liên kết với chỉ mục của các tài liệu tương ứng, một trình truy xuất thông tin, và các thuộc tính khác. Lưu ý rằng AgentScope cho phép mỗi tác nhân RAG tải với nhiều hơn một đối tượng RAG.

Tác Nhân với RAG Việc ứng dụng các tác nhân với RAG trong AgentScope rất đơn giản. Ví dụ, chúng tôi trước tiên cần khởi tạo một KnowledgeBank với một số khung RAG, ví dụ LlamaIndex, và tất cả các tài liệu. Sau đó, chúng tôi cấu hình một tác nhân RAG và tải nó với knowledge bank. Sau đó, việc khởi tạo được hoàn thành và chúng tôi có thể sử dụng tác nhân RAG như bất kỳ tác nhân nào khác trong AgentScope. Đáng chú ý là nếu KnowledgeBank được lấy với khung LlamaIndex, thì chúng tôi cần sử dụng LlamaIndexAgent (được kế thừa từ RAGAgentBase). Độc giả có thể tham khảo Phần 9.5 cho một mẫu ứng dụng cụ thể, triển khai một copilot cho AgentScope sử dụng các tác nhân RAG của chúng tôi. Nhìn chung, các tính năng chính của tác nhân RAG được tóm tắt như sau:

• Tác nhân RAG được phép tải một số đối tượng RAG (tức là bất kỳ tập hợp con nào của knowledge bank). Người ta có thể chọn tải các đối tượng RAG gốc từ knowledge bank (trong trường hợp như vậy, việc thay đổi đối tượng có thể ảnh hưởng đến tất cả các tác nhân sử dụng nó) hoặc một bản sao của nó.

• Trong khi các tác nhân được khởi tạo với đối tượng KnowledgeBank, việc các tác nhân cập nhật kiến thức kịp thời được cho phép. Các hoạt động bao gồm chèn, xóa hoặc thay thế các đoạn kiến thức. Hơn nữa, chúng tôi cung cấp giải pháp bằng cách giám sát các thư mục nhất định và giữ cho đối tượng RAG được cập nhật với nội dung trong các thư mục.

• Cơ chế hợp nhất của các kết quả được truy xuất từ nhiều đối tượng RAG hoàn toàn có thể tùy chỉnh. Ví dụ, vì kiến thức có thể có tầm quan trọng hoặc độ tin cậy khác nhau, tác nhân có thể đặt trọng số cho thông tin được truy xuất từ các đối tượng RAG khác nhau cho các quá trình tiếp theo.

• Tác nhân RAG được phép tái tạo thành truy vấn trong các lần lặp lại có thể cấu hình và thực hiện nhiều truy vấn để có câu trả lời toàn diện hơn.

8 Khung Phân Tán Dựa Trên Actor

Hiệu quả và khả năng mở rộng là cần thiết khi xây dựng các ứng dụng cấp công nghiệp trên các hệ thống đa tác nhân. Tốc độ suy luận của các tác nhân trong các ứng dụng đa tác nhân có thể thay đổi đáng kể. Ví dụ, giả sử một tác nhân trong ứng dụng đa phương thức sử dụng mô hình từ văn bản thành video. Trong trường hợp đó, thời gian phản hồi của nó có thể dài hơn đáng kể so với một tác nhân được thiết kế để điền vào chi tiết của câu chuyện. Song song hóa, như một ý tưởng cổ điển, nên được giới thiệu để tăng cường hiệu quả. Ngoài ra, các ứng dụng đa tác nhân có thể bao gồm các tác nhân được phân phối vật lý trên các máy khác nhau. Một trường hợp sử dụng điển hình là một công ty có thể bao gồm các kỹ thuật được cấp bằng sáng chế hoặc cơ sở kiến thức riêng tư của họ vào một tác nhân trên máy cục bộ của họ được kết nối với internet và cung cấp dịch vụ tự động cho các thực thể khác thông qua tương tác tác nhân.

Tuy nhiên, khi nói đến các hệ thống đa tác nhân, một thách thức là các nhà phát triển cần đưa ra quyết định giữa hai cặp lộ trình công nghệ sau đây. Vì không có bữa trưa miễn phí, bất kỳ tổ hợp nào cũng có lợi ích và nhược điểm của chúng.

• Phối hợp tập trung v.s. phân tán. Trong bối cảnh hệ thống phân tán, phối hợp tập trung có nghĩa là nhiều nút tính toán được quản lý bởi một nút trung tâm, chẳng hạn như mô hình máy chủ-khách hàng. Một cơ chế đa tác nhân với phối hợp tập trung có nghĩa là việc thực thi các tác nhân được lên lịch bởi, và các thông điệp giữa các tác nhân được chuyển tiếp bởi một thành phần phối hợp trung tâm. Ngược lại, phối hợp phân tán không dựa vào bất kỳ thành phần trung tâm nào để lên lịch hoặc chuyển tiếp thông điệp, nhưng các tác nhân trong hệ thống như vậy có thể được gọi tự động và gửi thông điệp trực tiếp đến các tác nhân downstream để xử lý thêm.

Trong khi phối hợp tập trung là một phong cách đơn giản có thể được hiểu và dễ gỡ lỗi, các nhược điểm của nó bao gồm tính dễ bị tổn thương đối với lỗi nút trung tâm, áp đặt lưu lượng truy cập nặng nề lên nút trung tâm, và khó khăn trong việc mở rộng hoặc mở rộng thành các ứng dụng phức tạp. Ngược lại, phối hợp phân tán có thể yêu cầu nỗ lực thêm để phát triển và duy trì nhưng có độ mạnh mẽ cao hơn chống lại lỗi của bất kỳ nút đơn lẻ nào.

• Thiết kế luồng công việc tĩnh vs. động. Một so sánh tương tự có thể được tìm thấy giữa đồ thị tính toán tĩnh được sử dụng trong các phiên bản đầu của TensorFlow (Abadi et al., 2016) và đồ thị tính toán động được sử dụng trong PyTorch Paszke et al. (2019). Trong bối cảnh các ứng dụng đa tác nhân, việc lựa chọn giữa luồng công việc tĩnh và động giống như việc lựa chọn giữa thực thi được biên dịch trước và thông dịch. Thiết kế luồng công việc tĩnh có thể cho phép tối ưu hóa cấp đồ thị luồng công việc cho thời gian chạy và phân bổ tài nguyên. Tuy nhiên, thiết kế luồng công việc tĩnh yêu cầu đồ thị luồng công việc được biết trước khi thực thi, điều này hạn chế khả năng thích ứng vào các ứng dụng, đặc biệt là những ứng dụng có cấu trúc vòng lặp trong thiết kế. Ngược lại, luồng công việc động cung cấp tính linh hoạt lớn hơn với cái giá của tiềm năng tối ưu hóa. Điều này đặc biệt liên quan khi xử lý các mô hình ngôn ngữ lớn nơi các đường dẫn thực thi có thể thay đổi dựa trên dữ liệu đầu vào hoặc kết quả suy luận mô hình.

Hình 8: Một ví dụ về ứng dụng phân tán trong AgentScope, minh họa các quy trình khác nhau được biểu thị bằng màu sắc khác nhau.

Chế độ phân tán trong AgentScope. AgentScope cân bằng những lộ trình công nghệ này bằng cách triển khai chế độ phân tán dựa trên actor chú ý đến nhu cầu độc đáo của các hệ thống LLM đa tác nhân, với các tính năng quan trọng sau:

• Tối ưu hóa song song tự động mà không cần đồ thị tĩnh. AgentScope tận dụng mô hình actor để cho phép tối ưu hóa song song tự động, cho phép các nhà phát triển vượt qua sự phức tạp của lập trình đồ thị tĩnh. Cách tiếp cận này liền mạch phù hợp với bản chất động và thường không thể đoán trước của LLM, nơi đồ thị tính toán có thể thay đổi dựa trên ngữ cảnh phát triển và trạng thái đối thoại.

• Lập trình luồng công việc với độ phức tạp tối thiểu. Trái ngược với các mô hình actor truyền thống và triển khai ngang hàng (P2P) yêu cầu thứ tự thực thi phức tạp cho các tác nhân phân tán, AgentScope đơn giản hóa lập trình luồng công việc thành một phong cách thủ tục duy nhất trong một hàm Python. Thiết kế này làm phẳng đáng kể đường cong học tập cho các nhà phát triển, làm cho việc xây dựng LLM đa tác nhân tinh vi trở nên dễ tiếp cận hơn.

• Hỗ trợ tác nhân cục bộ và phân tán lai. Tính linh hoạt của AgentScope mở rộng để hỗ trợ chế độ lai nơi một số tác nhân hoạt động cục bộ trong khi những tác nhân khác được phân tán. Tính năng này đặc biệt có lợi khi tích hợp LLM với các yêu cầu tính toán khác nhau, cho phép các mô hình đòi hỏi tài nguyên được phân tán trong khi các tác nhân ít đòi hỏi vẫn cục bộ, tất cả mà không cần nhà phát triển phân biệt giữa hai trong quá trình triển khai.

Cụ thể, chúng tôi có thể mô tả ngắn gọn cách AgentScope kết hợp mô hình actor như sau. Trong khung khái niệm này, một "actor" hoạt động như một thực thể độc lập xử lý tính toán khi nhận được tất cả các thông điệp cần thiết. Mô hình này đảm bảo rằng mỗi tác nhân, tương ứng với một actor, chỉ tham gia vào tính toán khi các thông điệp đầu vào yêu cầu đã sẵn sàng, do đó đạt được tối ưu hóa song song tự động.

Tuy nhiên, luồng công việc dựa trên mô hình actor trình bày một thách thức lập trình: việc truyền biến (tức là, thông điệp) giữa các actor (tức là, tác nhân) có thể là placeholders mà không có ý nghĩa thực tế nào ở đầu. Để giảm bớt điều này, AgentScope giới thiệu "placeholder" message, một cấu trúc dữ liệu mới cho phép quá trình chính tiếp tục mà không bị chặn, trong khi bảo tồn thông tin cần thiết để lấy các giá trị thực sau này (Hình 8). Cơ chế này đặc biệt có lợi cho các hệ thống LLM đa tác nhân, nơi luồng thực thi phải thích ứng với đầu ra biến của các mô hình ngôn ngữ.

```python
# set up distributed agent: agent1
...

input_msg = Msg("system", "Which agent should respond next, agent2 or agent3?")

# the variable choice is a placeholder
choice: placeholder = host_agent(input_msg)

if choice["content"] == "agent2":
    response = agent2()
elif choice["content"] == "agent3":
    response = agent3()
```

Ví dụ 9: Thể hiện việc sử dụng placeholders trong luồng điều khiển trong AgentScope.

Một loạt thách thức khác phát sinh khi placeholders được sử dụng trong các câu lệnh luồng điều khiển (ví dụ, if-else, loops) mà không có giá trị thực của chúng. Một ví dụ được thể hiện trong Ví dụ 9, nơi một placeholder được yêu cầu để đưa ra quyết định. Trong những hoàn cảnh này, AgentScope tạm thời chặn quá trình để lấy giá trị thực tế của nó, do đó đảm bảo tính liên tục của luồng điều khiển.

Chế độ phân tán dựa trên actor trong AgentScope không chỉ cung cấp tối ưu hóa song song tự động và đơn giản hóa trải nghiệm nhà phát triển mà còn thể hiện hiệu quả cao cho các ứng dụng LLM đa tác nhân phân tán. Nó cho phép các nhà phát triển tập trung vào việc triển khai logic tác nhân, đặc biệt là hàm "reply", mà không quan tâm đến sự phức tạp phân tán cơ bản. Cách tiếp cận được sắp xếp hợp lý này đối với các hệ thống đa tác nhân phân tán có thể thúc đẩy lĩnh vực LLM bằng cách làm cho việc phát triển, chạy và gỡ lỗi các kiến trúc đa tác nhân tinh vi và có thể mở rộng dễ dàng hơn.

Triển khai một cú nhấp trong AgentScope. Để tạo thuận lợi hơn nữa cho triển khai phân tán, AgentScope cung cấp agent server và trung tâm thông điệp thống nhất, có tên là AgentScope Studio.

Cụ thể, agent server được giữ trong các máy từ xa, nhận các yêu cầu từ các ứng dụng AgentScope, và khởi tạo các tác nhân yêu cầu của họ trong máy được triển khai tự động. Điều đó có nghĩa là, các nhà phát triển có thể thiết lập các instance tác nhân từ xa, mà không cần lập trình trong các máy khác nhau. Tính năng như vậy cung cấp tính linh hoạt cao, đặc biệt cho các mô phỏng quy mô lớn, nơi một số lượng lớn các instance tác nhân sẽ được thiết lập trong các máy từ xa.

Đối với AgentScope Studio, nó cung cấp giao diện hiển thị thống nhất cho các ứng dụng đa tác nhân phân tán, nơi các thông điệp từ tất cả các tác nhân phân tán sẽ được thu thập và hiển thị trong studio này, và cho phép các nhà phát triển chuyển tiếp những thông điệp này đến giao diện hiển thị riêng của họ. Ngoài ra, AgentScope studio hỗ trợ quản lý agent server, nghĩa là, trong studio này các nhà phát triển có thể kiểm tra việc triển khai các tác nhân phân tán, mở hoặc đóng agent server từ xa. Với studio này, các nhà phát triển có thể quản lý các ứng dụng của họ dễ dàng hơn nhiều.

9 Ứng Dụng Đặc Trưng của AgentScope

Như được giới thiệu trong các phần trước, AgentScope là một nền tảng đa tác nhân được thiết kế tinh tế để tích hợp và phối hợp các mô hình quy mô lớn một cách thân thiện với người dùng và chịu lỗi, và nó là một nền tảng lý tưởng cho một phổ rộng các ứng dụng. AgentScope có thể triển khai các ứng dụng trải dài từ đối thoại đơn giản đơn tác nhân vs. người dùng đến các trò chơi nhập vai tương tác nhiều người chơi phức tạp như werewolf. Hơn nữa, ngoài triển khai tập trung, AgentScope có thể mở rộng thành các cuộc trò chuyện phân tán liên quan đến các hoạt động song song trên nhiều máy. Trong phần này, chúng tôi xem xét một số ứng dụng đặc trưng của AgentScope minh chứng thuyết phục khả năng xuất sắc và đa dạng của khung. Tất cả các ví dụ được tham chiếu ở đây đều có thể truy cập trong kho GitHub của chúng tôi để sử dụng và đóng góp của cộng đồng.

9.1 Tác Nhân Đối Thoại: Cuộc Trò Chuyện Cơ Bản

Ứng dụng đơn giản nhất nhưng cơ bản nhất của AgentScope là cuộc trò chuyện cơ bản, nơi người dùng trực tiếp tương tác với tác nhân đối thoại. Ứng dụng này là điểm khởi đầu tuyệt vời cho người dùng mới của AgentScope để nhanh chóng nắm bắt cơ chế truyền thông điệp cốt lõi trong khung của chúng tôi.

Ví dụ cuộc trò chuyện cơ bản thể hiện việc sử dụng hai tác nhân tích hợp cơ bản trong AgentScope, UserAgent và DialogAgent, tạo thuận lợi cho đầu vào từ người dùng và phản hồi từ LLM, tương ứng. Thông thường, như được minh họa trong Ví dụ 10, bước đầu tiên của tất cả các ứng dụng là khởi tạo, nghĩa là tải các cấu hình mô hình (được chỉ định trong tệp model_configs.json) thông qua giao diện init của AgentScope, gán các tác nhân được trao quyền bởi LLM với các mô hình đã chọn. Hiện tại, AgentScope tương thích với nhiều nền tảng và API khác nhau, bao gồm nhưng không giới hạn ở OpenAI chat/embedding/DALL-E tiêu chuẩn, HuggingFace, ModelScope và một bộ sưu tập các mô hình được lưu trữ cục bộ với FastChat, vllm và Flask. Hơn nữa, giao diện init cũng chỉ định các tùy chọn chi tiết như lưu trữ tệp, logging, cấu hình tác nhân, v.v. Với tất cả các cấu hình được giải quyết, nó sẵn sàng để xây dựng luồng trò chuyện, tức là cơ chế trao đổi thông điệp giữa người dùng/tác nhân, là một khối xây dựng cần thiết cho tất cả các ứng dụng dựa trên tác nhân. Trong luồng công việc này, tác nhân AI sẽ luôn phản hồi đầu vào của người dùng, cuộc trò chuyện có thể tạo thành một vòng lặp vô tận cho đến khi người dùng quyết định thoát.

Để triển khai các ứng dụng tinh vi hơn, AgentScope tạo thuận lợi cho các pipeline, cung cấp khung có cấu trúc tốt và có thể mở rộng cho các tương tác tác nhân phức tạp (về thông điệp). Như được minh họa trong Ví dụ 11, chúng tôi có thể triển khai ví dụ cuộc trò chuyện cơ bản với sequential pipeline hoặc loop pipeline. Độc giả cũng có thể tham khảo Phụ lục A cho lịch sử cuộc trò chuyện trong khi chạy các mã demo.

9.2 Tác Nhân Đối Thoại: Cuộc Trò Chuyện Nhóm với Mentions

Ngoài cuộc trò chuyện cơ bản giữa người dùng và một tác nhân đối thoại đơn lẻ, AgentScope hỗ trợ cuộc trò chuyện nhóm. Để cải thiện tính tương tác, chúng tôi giới thiệu tính năng "mentions", cho phép người dùng hoặc tác nhân gọi một tác nhân cụ thể bằng cách đơn giản "@ agent_name". Tính năng "mention" được hỗ trợ bằng cách áp dụng hàm filter_agents, sàng lọc thông điệp và xác định xem có tác nhân nào được đề cập trong nội dung thông điệp hay không.

Trong ví dụ này, chúng tôi trước tiên khởi tạo các tác nhân tham gia vào cuộc trò chuyện như thể hiện trong Ví dụ 12. Ở đây, các đặc điểm của các tác nhân có thể được tùy chỉnh trong tệp agent_config.json, ví dụ sử dụng sys_prompt để tùy chỉnh phong cách phản ứng hoặc chức năng của các tác nhân. Ngoài ra, chúng tôi sử dụng message hub (msghub) để tạo thuận lợi cho việc phân phối thông điệp giữa một nhóm tác nhân. Msghub cho phép chia sẻ thông tin công khai (ví dụ, một thông báo) và cho phép các tác nhân phát sóng thông điệp đến tất cả các tác nhân. Cuộc trò chuyện sẽ kết thúc nếu đạt đến giới hạn timeout, hoặc người dùng gõ "exit".

```python
import agentscope
from agentscope.agents import DialogAgent, UserAgent

# read model configs
agentscope.init(model_configs="./openai_model_configs.json")

# Create a dialog agent and a user agent
assistant_agent = DialogAgent(
    name="Assistant",
    sys_prompt="You are a helpful assistant",
    model="gpt-4"
)
user_agent = UserAgent()

# Basic version
x = None
while x is None or x.content != "exit":
    x = assistant_agent(x)
    x = user_agent(x)
```

Ví dụ 10: Ví dụ mã của ví dụ cuộc trò chuyện cơ bản.

```python
# Advanced version with sequential pipeline
from agentscope.pipelines.functional import sequentialpipeline
x = None
while x is None or x.content != "exit":
    x = sequentialpipeline([dialog_agent, user_agent], x)

# Advanced version with while loop pipeline
from agentscope.pipelines.functional import whilelooppipeline
x = whilelooppipeline(
    [assistant_agent, user_agent],
    condition_func=lambda _, x: x is None or x.content != "exit",
    x=None)
```

Ví dụ 11: Triển khai dựa trên pipeline của ví dụ cuộc trò chuyện cơ bản.

9.3 Tác Nhân Đối Thoại: Trò Chơi Werewolf

Cuộc trò chuyện nhóm và tính năng mention là các khối xây dựng cơ bản cho các ứng dụng đa tác nhân. Ở đây chúng tôi trình bày một ứng dụng tinh vi hơn, trò chơi werewolf, là một trò chơi nhập vai tương tác nhiều người chơi phổ biến. Chúng tôi nhằm triển khai trò chơi với AgentScope chỉ trong một trăm dòng mã. Ví dụ này liên quan đến sáu người chơi được chia thành hai đội đối lập, werewolves và villages. Sau các vòng trò chuyện và thảo luận, trò chơi kết thúc khi tất cả werewolves bị loại bỏ (tức là chiến thắng của villager) hoặc số lượng werewolves bằng hoặc vượt quá villagers (tức là chiến thắng của werewolf).

Như một trò chơi nhập vai được trao quyền bởi LLM, chúng tôi bắt đầu thiết lập trò chơi với phân bổ cho các vai trò và khởi tạo cho các tác nhân. Như thể hiện trong Ví dụ 13, AgentScope hỗ trợ thiết lập nhanh, bao gồm các cấu hình tác nhân mặc định để người dùng khởi tạo các đối tượng tác nhân với các vai trò tương ứng chỉ bằng một cú nhấp, các thiết lập chi tiết được bao gồm trong tệp agent_configs.json.

Đáng chú ý là trò chơi werewolf dựa trên khả năng cuộc trò chuyện nhóm của AgentScope, sao cho werewolves có thể trò chuyện trong "giai đoạn đêm" và tất cả người tham gia có thể thảo luận trong "giai đoạn ngày". Tương tự như ví dụ cuộc trò chuyện nhóm, message hub (msghub) của AgentScope được sử dụng để tạo thuận lợi cho các cuộc trò chuyện. Như thể hiện trong Ví dụ 13, sau khi host (người điều khiển) đưa ra thông báo, werewolves thảo luận tối đa MAX_WEREWOLF_DISCUSSION_ROUND vòng và kết luận khi đạt được thỏa thuận. Ở đây, các tác nhân được yêu cầu sử dụng thuộc tính "agreement" trong thông điệp phản hồi, được thực thi trong prompt định nghĩa vai trò. Để có luồng công việc hoàn chỉnh, ví dụ về lịch sử đối thoại và thông tin liên quan khác, vui lòng tham khảo Phụ lục B.

```python
import agentscope

# Read model and agent configs, and initialize agents automatically
npc_agents = agentscope.init(
    model_configs="./configs/model_configs.json",
    agent_configs="./configs/agent_configs.json",
)
user = UserAgent()
agent = list(npc_agents)+[user]
...
# We use msghub to coordinate the conversations, 'hint' is a message notified to all agents
with msghub(agents, announcement=hint):
    while True:
        try:
            x = user(timeout=USER_TIME_TO_SPEAK)
            if x.content == "exit":
                break
        except TimeoutError:
            x = {"content": ""}
            logger.info(
                f"User has not typed text for "
                f"{USER_TIME_TO_SPEAK} seconds, skip.",
            )
        # if user mentions any npc_agent in the message, it will be added to the speak_list
        speak_list += filter_agents(x.get("content", ""), npc_agents)
        
        # if the speak_list is non-empty, the mentioned agents will respond in a sequential manner
        if len(speak_list) > 0:
            next_agent = speak_list.pop(0)
            x = next_agent()
        # otherwise, all agents will respond one by one.
        else:
            next_agent = select_next_one(npc_agents, rnd)
            x = next_agent()
        # if the response mentions any agent, it will be added to the speak_list
        speak_list += filter_agents(x.content, npc_agents)
```

Ví dụ 12: Ví dụ mã của cuộc trò chuyện nhóm.

```python
import agentscope
# Read model and agent configs, and initialize agents automatically
survivors = agentscope.init(
    model_configs="./configs/model_configs.json",
    agent_configs="./configs/agent_configs.json",
)

# Define the roles within the game.
roles = ["werewolf", "werewolf", "villager", "villager", "seer", "witch"]

# Based on their roles, assign the initialized agents to variables.
wolves, villagers, witch, seer = survivors[:2], survivors[2:-2], survivors[-1], survivors[-2]
...
# Night phase: werewolves discuss
hint = HostMsg(content=Prompts.to_wolves.format(n2s(wolves)))
with msghub(wolves, announcement=hint) as hub:
    ...
    for _ in range(MAX_WEREWOLF_DISCUSSION_ROUND):
        x = sequentialpipeline(wolves)
        if x.agreement:
            break
    ...
```

Ví dụ 13: Ví dụ mã của trò chơi werewolf.

9.4 Tác Nhân Được Triển Khai Phân Tán

Chúng tôi đã thấy các ứng dụng liên quan đến cuộc trò chuyện liên quan đến tác nhân đối thoại, nhưng những ví dụ đó cơ bản theo nghĩa là các tác nhân được triển khai theo cách tập trung, nghĩa là, các tác nhân được lưu trữ trên một máy duy nhất và trong một quá trình duy nhất. Để cho phép các tác nhân được lưu trữ bởi các máy hoặc quá trình riêng biệt, AgentScope cho phép các tác nhân được triển khai phân tán trong hai chế độ, chế độ đơn máy nhiều quá trình và chế độ đa máy nhiều quá trình. Trong những gì sau đây, chúng tôi trình bày các ví dụ để thể hiện tính năng này.

Chế độ Đơn Máy Nhiều Quá Trình: Đối với chế độ này, tất cả các tác nhân được triển khai trên một máy duy nhất, nhưng chạy trong các quá trình riêng biệt. Để so sánh tốt hơn, chúng tôi triển khai ví dụ cuộc trò chuyện cơ bản trong chế độ này (xem Ví dụ 14 cho mã hoàn chỉnh). So với Ví dụ 10 và 11, chúng tôi sử dụng hàm to_dist để chuyển đổi instance tác nhân hiện tại thành phiên bản phân tán. Sau đó, assistant_agent sẽ được triển khai trên localhost với cổng được phân bổ tự động. Ngoài những khác biệt đã đề cập, chế độ đơn máy nhiều quá trình giống hệt với triển khai cục bộ, nhưng đã được tối ưu hóa cho thực thi song song.

Chế độ Đa Máy Nhiều Quá Trình: Để thể hiện chế độ này, chúng tôi khởi tạo dịch vụ tác nhân (một DialogAgent) trên máy từ xa (như thể hiện trong Ví dụ 15), và xây dựng luồng công việc (như thể hiện trong Ví dụ 16). Người ta có thể lưu ý rằng sự khác biệt duy nhất so với chế độ triển khai cục bộ là agent server cần được kết nối bằng URL và cổng được chỉ định trước khi thiết lập luồng công việc.

Nhìn chung, đối với AgentScope, chúng tôi có thể chuyển đổi mượt mà từ chế độ triển khai cục bộ sang chế độ phân tán và ngược lại, chỉ với những thay đổi tối thiểu đối với cấu hình tác nhân và không có thay đổi nào đối với luồng công việc.

```python
from agentscope.agents import UserAgent, DialogAgent
import agentscope
# we use .to_dist() to convert the agent to distributed mode.
assistant_agent = DialogAgent(
    name="Assistant",
    sys_prompt="You are a helpful assistant",
    model="gpt-4"
).to_dist()
user_agent = UserAgent()

x = None
while x is None or not x.content != "exit":
    x = sequentialpipeline([assistant_agent, user_agent], x)
```

Ví dụ 14: Ví dụ triển khai các tác nhân trong chế độ đơn máy nhiều quá trình.

```python
from agentscope.agents.rpc_agent import RpcAgentServerLauncher
from agentscope.agents import DialogAgent

# load model configurations
agentscope.init(model_configs="configs/model_configs.json")
# set server for the remote agent
server_launcher = RpcAgentServerLauncher(
    agent_class=DialogAgent,
    agent_kwargs={
        "name": "Assistant",
        "sys_prompt": "You are a helpful assistant.",
        "model": "gpt-4"
    },
    host="xxx.xxx.xxx.xxx",
    port=12010,
)
# start the server
server_launcher.launch()
server_launcher.wait_until_terminate()
```

Ví dụ 15: Triển khai tác nhân từ xa trong chế độ đa máy nhiều quá trình.

```python
agentscope.init(model_configs="configs/model_configs.json")

assistant_agent = DialogAgent(
    name="Assistant",
    model="gpt-4"
).to_dist(
    host="xxx.xxx.xxx.xxx",  # The target URL of agent server
    port=12010,  # The target port of agent server
    launch_server=False,  # Use the remote agent server
)
user_agent = UserAgent()

x = None
while x is None or not x.content != "exit":
    x = sequentialpipeline([assistant_agent, user_agent], x)
```

Ví dụ 16: Ví dụ thiết lập các tiểu quá trình cho các tác nhân trong chế độ đa máy nhiều quá trình.

9.5 Tác Nhân RAG: AgentScope Copilot

Như đã giới thiệu trước đó trong Phần 7, Tạo Sinh Tăng Cường Truy Xuất (RAG) cho phép các nhà phát triển tận dụng đầy đủ khả năng tạo sinh ngôn ngữ của LLM đi kèm với nhóm kiến thức tùy chỉnh. Theo đó, AgentScope giới thiệu tác nhân RAG để tạo thuận lợi cho chức năng như vậy. Trong ví dụ sau (như thể hiện trong Ví dụ 17), chúng tôi thể hiện cách sử dụng một bộ sưu tập tác nhân RAG dựa trên Llama-index (tức là, LlamaIndexAgent được kế thừa từ RAGAgentBase) để xây dựng một copilot đa tác nhân cho AgentScope.

Chúng tôi trước tiên khởi tạo các tác nhân. Lưu ý rằng tính năng quan trọng nhất của tác nhân RAG là ngoài tính cách tùy chỉnh và phong cách hành vi được cấu hình bởi system prompt, mỗi tác nhân được tải với kiến thức bên ngoài, được chỉ định trong agent_configs chứa thông tin cấu hình như thư mục lưu trữ dữ liệu, loại tệp mục tiêu, thiết lập phân khối tài liệu, thiết lập lập chỉ mục và embedding, v.v.

Luồng công việc của copilot được thiết kế như sau, người dùng trước tiên nhập thông điệp, và nếu người dùng đề cập đến một số tác nhân RAG cụ thể như chúng tôi đã định nghĩa, thì các tác nhân tương ứng sẽ phản hồi, nếu không, guide_agent sẽ quyết định tác nhân phù hợp nhất để phản hồi truy vấn. Do giới hạn không gian, chúng tôi chỉ trình bày mã đơn giản hóa ở đây và vui lòng tham khảo kho lưu trữ và tài liệu để biết thêm chi tiết.

```python
import agentscope
from agentscope.agents import UserAgent, DialogAgent, LlamaIndexAgent
...
# initialize agentscope with model configurations
agentscope.init(model_configs="configs/model_configs.json")

# initialize the RAG agents based on different configurations
tutorial_agent = LlamaIndexAgent(**agent_configs[0]["args"])
code_agent = LlamaIndexAgent(**agent_configs[1]["args"])
api_agent = LlamaIndexAgent(**agent_configs[2]["args"])
search_agent = LlamaIndexAgent(**agent_configs[3]["args"])
...
# initialize a basic dialog agent as the 'frontdesk assistant' and a user agent
guide_agent = DialogAgent(**agent_configs[4]["args"])
user_agent = UserAgent()
...
while True:
    x = user_agent()
    # the workflow terminates when user inputs nothing or 'exit'
    if len(x["content"]) == 0 or str(x["content"]).startswith("exit"):
        break
    # find out the agents mentioned in user's input
    speak_list = filter_agents(x.get("content", ""), rag_agent_list)
    if len(speak_list) == 0:
        # if no agent is mentioned, the guide agent will decide which one to call
        guide_response = guide_agent(x)
        speak_list = filter_agents(
            guide_response.get("content", ""),
            rag_agent_list,
        )
    # agents called by the guide agent will be recorded
    agent_name_list = [agent.name for agent in speak_list]
    # the listed agents respond to the query in turn
    for agent_name, agent in zip(agent_name_list, speak_list):
        if agent_name in rag_agent_names:
            agent(x)
```

Ví dụ 17: Ví dụ sử dụng tác nhân RAG để xây dựng copilot cho AgentScope.

9.6 Tác Nhân Tìm Kiếm Web và Truy Xuất

Chúng tôi đã thể hiện các ví dụ về tác nhân tạo ra phản hồi bằng khả năng của LLM (DialogAgent) và thông tin được truy xuất từ thư viện kiến thức bên ngoài (LlamaIndexAgent). Tuy nhiên, chúng tôi cũng có thể sử dụng tài nguyên internet để xây dựng tác nhân, như được giới thiệu trong ví dụ sau.

Như được trình bày trong Ví dụ 18, việc khởi tạo liên quan đến ba loại tác nhân - UserAgent nhận đầu vào của người dùng, SearcherAgent chuyển đổi câu hỏi của người dùng thành từ khóa và gọi công cụ tìm kiếm để truy xuất trang web từ internet, và AnswererAgent truy xuất thông tin từ trang web để soạn thảo câu trả lời.

Đáng chú ý là, vì một số lượng lớn trang web có thể được trả về bởi các tác nhân tìm kiếm. Trong chế độ tiêu chuẩn đơn quá trình, nhiều instance AnswererAgent chỉ có thể thực hiện tìm kiếm web và trả lời câu hỏi theo cách tuần tự trên một máy duy nhất. Để có hiệu quả tốt hơn, việc cho phép nhiều instance của AnswererAgent chạy song song là có lợi, nghĩa là, chế độ đa máy nhiều quá trình của các tác nhân AgentScope.

```python
import agentscope
from searcher_agent import SearcherAgent
from answerer_agent import AnswererAgent
from agentscope.agents.user_agent import UserAgent

agentscope.init(model_configs="configs/model_configs.json")

# we can perform multiple searches at one time
WORKER_NUM = 3
searcher = SearcherAgent(
    name="Searcher",
    model_config_name="my_model",
    result_num=args.num_workers,
    search_engine_type=args.search_engine,
    api_key=args.api_key,
    cse_id=args.cse_id,
)
# instantiate the answerer agents
answerers = []
for i in range(args.num_workers):
    answerer = AnswererAgent(
        name=f"Answerer-{i}",
        model_config_name="my_model",
    )
    # if we want to put agents in distributed (parallel) mode
    if args.use_dist:
        answerer = answerer.to_dist(lazy_launch=False)
    answerers.append(answerer)
user_agent = UserAgent()

msg = user_agent()
while not msg.content == "exit":
    msg = searcher(msg)
    results = []
    for page, worker in zip(msg.content, answerers):
        results.append(worker(Msg(**page)))
    for result in results:
        logger.chat(result)
    msg = user_agent()
```

Ví dụ 18: Ví dụ sử dụng tác nhân tìm kiếm web và truy xuất.

9.7 Tác Nhân ReAct: Chuyển Đổi Ngôn Ngữ Tự Nhiên thành Truy Vấn SQL

Chuyển đổi Ngôn Ngữ Tự Nhiên thành truy vấn SQL (NL2SQL) là một nhiệm vụ cổ điển nhưng đầy thách thức trong cả cộng đồng cơ sở dữ liệu và xử lý ngôn ngữ tự nhiên, nhằm chuyển đổi các câu hỏi đầu vào của con người bằng ngôn ngữ tự nhiên thành các truy vấn SQL. Trong cộng đồng nghiên cứu, có một bộ sưu tập công trình khám phá tiềm năng của LLM trong NL2SQL, và sẽ rất thú vị khi khám phá nhiệm vụ này với các tác nhân được trao quyền bởi LLM.

Trong AgentScope, chúng tôi cung cấp một lớp tác nhân đặc biệt, các tác nhân ReAct (lý luận và hành động). Cụ thể hơn, chúng tôi có thể tạo ra các hàm dịch vụ mới, bằng cách sử dụng mô-đun ServiceToolkit, cho các tác nhân ReAct và LLM tương ứng. Trong ví dụ này, chúng tôi cố gắng trang bị cho tác nhân ReAct thuật toán NL2SQL tiên tiến, DAIL-SQL.

Là bước đầu tiên (như thể hiện trong Ví dụ 19), chúng tôi cần khởi tạo cấu hình mô hình và cơ sở dữ liệu SQL, sau đó khởi tạo và cung cấp đường dẫn cơ sở dữ liệu tương ứng ở định dạng sqlitefile. Ở đây chúng tôi tạo ra tệp SQLite bằng cách sử dụng các lệnh SQL được cung cấp. Bạn cũng có thể sử dụng trực tiếp tệp định dạng .sqlite.

Sau đó, như thể hiện trong Ví dụ 20, chúng tôi định nghĩa các công cụ cho ReAct Agent để thực thi truy vấn SQL. Cụ thể, tác nhân của chúng tôi nên có thể tạo ra truy vấn SQL với đầu vào ngôn ngữ tự nhiên và thực thi truy vấn SQL để có kết quả. Chúng tôi tham chiếu một công cụ Text-to-SQL của bên thứ ba DAIL-SQL để tạo ra prompt Text-to-SQL. Chúng tôi sử dụng hàm dịch vụ query_sqlite trong mô-đun agentscope.service. Bây giờ, chúng tôi có thể khởi tạo ReAct Agent bằng cách sử dụng các công cụ đã định nghĩa và tương tác với tác nhân, như thể hiện trong Ví dụ 21.

```python
import agentscope
from sql_utils import create_sqlite_db_from_schema
...
agentscope.init(model_configs="configs/model_configs.json")
create_sqlite_db_from_schema(db_schema_path, db_sqlite_path)
...
```

Ví dụ 19: Ví dụ sử dụng tác nhân tìm kiếm web và truy xuất.

```python
from agentscope.service import (
    ServiceResponse,
    ServiceExecStatus,
    ServiceToolkit,
    query_sqlite,
)
from sql_utils import DailSQLPromptGenerator

def generate_sql_query(question: str, db_path: str, model: Callable) -> ServiceResponse:
    prompt_helper = DailSQLPromptGenerator(db_path)
    prepared_prompt = prompt_helper.generate_prompt({"content": question})
    
    def get_response_from_prompt(prompt: dict, model: Callable) -> str:
        ...
    sql_response = get_response_from_prompt(
        prepared_prompt["prompt"], model=model
    )
    return ServiceResponse(
        ServiceExecStatus.SUCCESS,
        sql_response
    )

# Use Service Toolkit to set up tool functions for LLMs
service_toolkit = ServiceToolkit()
service_toolkit.add(generate_sql_query, db_path=db_sqlite_path, model=loaded_model)
service_toolkit.add(query_sqlite, database=db_sqlite_path)
```

Ví dụ 20: Ví dụ sử dụng tác nhân tìm kiếm web và truy xuất.

```python
from agentscope.agents import ReActAgent
agent = ReActAgent(
    name="assistant",
    model_config_name='gpt-4',
    service_toolkit=service_toolkit,
    sys_prompt="You are a helpful agent that perform SQL queries base on natural language instructions.",
    verbose=True,  # set verbose to True to show the reasoning process
)
...
mss = Msg(
    name="user",
    content="How many singers do we have?",
    role="user"
)
logger.chat(mss)

sql_query_mss1 = agent(mss)
...
```

Ví dụ 21: Ví dụ sử dụng tác nhân tìm kiếm web và truy xuất.

9.8 AgentScope Workstation

AgentScope cung cấp một bộ công cụ phát triển rất tiện lợi và thân thiện với người dùng dưới dạng "kéo cửa sổ", Workstation. Ở đây, việc triển khai các ứng dụng AgentScope bằng cách sử dụng bộ công cụ phát triển này có chi phí thấp theo nghĩa là, các nhà phát triển cấp độ đầu vào hoặc những người không có bất kỳ kinh nghiệm lập trình nào có thể dễ dàng phát triển ứng dụng riêng của họ một cách dễ dàng bằng cách chỉ đơn giản kéo những mô-đun liên quan đến tác nhân và kết nối chúng theo cách rất đơn giản. Ví dụ, như thể hiện trong Hình 9, chúng tôi triển khai ví dụ cuộc trò chuyện cơ bản trong Workstation. Như chúng ta có thể thấy, chúng tôi không cần viết bất kỳ mã nào, chỉ cần gõ vào các cấu hình như thiết lập chi tiết và API vào các cửa sổ tương ứng, liên kết các cửa sổ để xây dựng phụ thuộc và kết nối, và sau đó với một cú nhấp, Workstation sẽ sẵn sàng để khởi chạy tự động. Đồng thời, Workstation cũng giới thiệu các quy tắc kiểm tra tĩnh để đảm bảo tính đúng đắn của các cấu hình.

AgentScope Workstation cũng cung cấp hỗ trợ toàn diện cho các nhà phát triển tiên tiến. Các nhà phát triển có thể xuất các cấu hình trên các mô-đun như tệp .json và thực thi bằng công cụ AgentScope Workstation. Ngoài ra, người ta cũng có thể sử dụng AgentScope Workstation Compiler để chuyển đổi tất cả các cấu hình thành mã Python để chỉnh sửa hoặc phát triển thêm để triển khai các điều chỉnh tùy chỉnh hơn.

Hình 9: Workstation tạo ra cấu hình luồng công việc và mã Python.

10 Các Công Trình Liên Quan

Sự phát triển của AgentScope phù hợp với bối cảnh đang phát triển nhanh chóng của các khung tận dụng các mô hình ngôn ngữ lớn (LLM) để tạo ra các tác nhân ngôn ngữ và hệ thống đa tác nhân. Ở đây, chúng tôi giới thiệu ngắn gọn các công trình liên quan chặt chẽ đến AgentScope từ hai lĩnh vực phụ liên quan: Khung Tác Nhân Ngôn Ngữ, tập trung vào khả năng tác nhân cá nhân, và Khung Đa Tác Nhân, nhấn mạnh sự hợp tác giữa nhiều tác nhân. Để có các công trình liên quan rộng hơn, độc giả có thể tham khảo (Wang et al., 2023; Xi et al., 2023).

Khung Tác Nhân Ngôn Ngữ Các khung tác nhân ngôn ngữ có vai trò quan trọng trong việc phát triển các ứng dụng có thể diễn giải và tương tác bằng ngôn ngữ con người.

Thư viện Transformers (Huggingface, 2023) đã giới thiệu API ngôn ngữ tự nhiên để giao tiếp với các mô hình transformer trong các cập nhật gần đây (Transformers-Agents). API này sử dụng một bộ công cụ có thể tùy chỉnh, cho phép mô hình diễn giải hướng dẫn và tạo ra các đoạn mã tương ứng. Nó cung cấp hỗ trợ cho các endpoint mô hình mã nguồn mở và độc quyền khác nhau, phục vụ nhu cầu nhà phát triển đa dạng. LangChain (Langchain-AI, 2023) cung cấp khung để xây dựng các ứng dụng nhận thức ngữ cảnh và có khả năng lý luận. Nó bao gồm các thư viện và mẫu tạo thuận lợi cho việc tích hợp nhiều thành phần vào một kiến trúc nhận thức thống nhất. LangServe và LangSmith mở rộng khả năng của khung bằng cách cho phép triển khai như REST API và cung cấp công cụ nhà phát triển để gỡ lỗi và giám sát các chuỗi được xây dựng trên bất kỳ khung LLM nào. AutoGPT (AutoGPT-Team, 2023) minh họa một cách tiếp cận khác, cho phép LLM lặp lại thực thi các hành động và đưa ra quyết định. Như một tác nhân tổng quát, AutoGPT không cụ thể cho nhiệm vụ; nó được thiết kế để thực hiện nhiều nhiệm vụ dựa trên máy tính, phản ánh bản chất thích ứng của LLM. ModelScope-Agent (Li et al., 2023a) là khung tác nhân có thể tùy chỉnh khai thác LLM mã nguồn mở để thực hiện các nhiệm vụ và kết nối với API bên ngoài. Nó tạo thuận lợi cho việc tích hợp liền mạch với API mô hình và API chung trong khi cung cấp cơ sở hạ tầng toàn diện cho thu thập dữ liệu, truy xuất công cụ và đào tạo mô hình tùy chỉnh, tất cả nhằm thực hiện các ứng dụng thực tế trong thế giới thực.

Khung Đa Tác Nhân Xây dựng trên khả năng của các tác nhân cá nhân, các khung đa tác nhân khám phá sự hợp tác và tương tác giữa nhiều tác nhân để giải quyết các nhiệm vụ phức tạp.

AutoGen (Wu et al., 2023) cung cấp cơ sở hạ tầng chung cho phép các nhà phát triển lập trình các mô hình tương tác bằng cách sử dụng cả ngôn ngữ tự nhiên và mã. Khung này cho phép phát triển các ứng dụng đa dạng bằng cách tạo thuận lợi cho cuộc trò chuyện giữa các tác nhân có thể tùy chỉnh và có thể sử dụng nhiều kết hợp LLM, đầu vào con người và công cụ khác nhau. MetaGPT (Hong et al., 2023) kết hợp meta-programming để tăng cường hợp tác đa tác nhân. Bằng cách mã hóa Quy Trình Vận Hành Tiêu Chuẩn (SOP) vào prompt, khung này đảm bảo luồng công việc được sắp xếp hợp lý và giảm lỗi, minh họa phân tách nhiệm vụ hiệu quả giữa các tác nhân. AGENTS (Zhou et al., 2023) là thư viện mã nguồn mở hỗ trợ các tác nhân ngôn ngữ tự động với các tính năng như lập kế hoạch, bộ nhớ và giao tiếp đa tác nhân. Nó được thiết kế để thân thiện với người dùng, giúp những người không chuyên triển khai các tác nhân ngôn ngữ tiên tiến, và thân thiện với nghiên cứu, với thiết kế mô-đun hóa để có thể mở rộng. OpenAgents (Xie et al., 2023) cung cấp nền tảng mở để sử dụng các tác nhân ngôn ngữ với các chức năng thực tế có thể truy cập thông qua giao diện web. Khung này nhấn mạnh tạo thuận lợi cho các tương tác tác nhân thực tế và bao gồm các tác nhân chuyên biệt cho các nhiệm vụ khác nhau, chẳng hạn như phân tích dữ liệu và duyệt web. ChatDev (Qian et al., 2023) khai thác LLM cho phát triển phần mềm, tạo ra một công ty ảo được cung cấp bởi trò chuyện tuân theo mô hình thác nước. Nó thu hút "tác nhân phần mềm" ở các giai đoạn khác nhau của quá trình phát triển, tạo thuận lợi cho sự hợp tác và giao tiếp nhận thức ngữ cảnh. CAMEL (Li et al., 2023b) đề xuất khung mới để hợp tác tự động giữa các tác nhân giao tiếp sử dụng kỹ thuật nhập vai, cho phép tạo sinh dữ liệu đối thoại để nghiên cứu hành vi và khả năng tác nhân. Cuối cùng, AgentSims (Lin et al., 2023) giới thiệu môi trường sandbox để đánh giá LLM trong các kịch bản dựa trên nhiệm vụ, cung cấp cơ sở hạ tầng cho các nhà nghiên cứu thử nghiệm khả năng LLM cụ thể trong môi trường mô phỏng.

Những khung này đại diện cho những bước tiến đáng kể trong việc sử dụng LLM cho cả nhiệm vụ tác nhân cá nhân và hợp tác. AgentScope được định vị trong bối cảnh này, đóng góp bằng cách giải quyết nhu cầu về một khung thân thiện với người dùng, chịu lỗi và đa năng được thiết kế để quản lý các tương tác và quy trình phức tạp vốn có trong các hệ thống LLM đa tác nhân. Bằng cách tập trung vào dễ sử dụng và độ tin cậy, AgentScope nhằm tạo thuận lợi cho việc tạo ra các ứng dụng mạnh mẽ và đa năng trên các lĩnh vực đa dạng.

11 Kết Luận

Trong công trình này, chúng tôi đề xuất AgentScope, một nền tảng đứng đầu trong phát triển hệ thống đa tác nhân, tổng hợp thiết kế tập trung vào người dùng với khả năng tiên tiến của LLM. Thông qua các cơ chế giao tiếp và phân tán đổi mới, AgentScope thể hiện tiềm năng của mình để thúc đẩy sự hợp tác giữa các tác nhân, cho phép các hoạt động hiệu quả, chịu lỗi và tương tác đa phương thức. Bằng cách trừu tượng hóa sự phức tạp và cung cấp một loạt các tiện ích phát triển, AgentScope giảm đáng kể các rào cản gia nhập, nuôi dưỡng một cộng đồng nhà phát triển bao gồm và sáng tạo hơn.

Nhìn về phía trước, AgentScope mở ra nhiều con đường cho nghiên cứu và phát triển thêm. Công việc tương lai có thể đi sâu vào việc tích hợp sâu hơn của tạo sinh tăng cường truy xuất, và khám phá các giao thức giao tiếp thích ứng và các phương thức tương tác phát triển cùng với yêu cầu nhiệm vụ. Tác động của nền tảng về việc tăng tốc triển khai các hệ thống đa tác nhân trên các ngành công nghiệp, từ chăm sóc sức khỏe đến dịch vụ khách hàng, hứa hẹn sẽ sâu sắc, có khả năng dẫn đến các công nghệ thông minh hơn và phản ứng nhanh hơn giúp tăng cường sự hợp tác giữa người và máy. Với AgentScope, chúng tôi mời cộng đồng nghiên cứu và phát triển rộng lớn hơn xây dựng trên nền tảng của chúng tôi, thúc đẩy những đổi mới sẽ định hình thế hệ tiếp theo của các ứng dụng đa tác nhân thông minh.

Tài Liệu Tham Khảo

[Phần tài liệu tham khảo tiếp tục với danh sách đầy đủ các tài liệu được trích dẫn trong bài báo...]

# 2308.03983.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/rag/2308.03983.pdf
# File size: 919920 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
SimplyRetrieve: A Private and Lightweight Retrieval-Centric Generative
AI Tool
Youyang Ng, Daisuke Miyashita, Yasuto Hoshi, Yasuhiro Morioka,
Osamu Torii ,Tomoya Kodama ,Jun Deguchi
Kioxia Corporation, Japan
youyang.ng@kioxia.com
Abstract
Large Language Model (LLM) based Genera-
tive AI systems have seen significant progress
in recent years. Integrating a knowledge re-
trieval architecture allows for seamless inte-
gration of private data into publicly available
Generative AI systems using pre-trained LLM
without requiring additional model fine-tuning.
Moreover, Retrieval-Centric Generation (RCG)
approach, a promising future research direc-
tion that explicitly separates roles of LLMs and
retrievers in context interpretation and knowl-
edge memorization, potentially leads to more
efficient implementation. SimplyRetrieve is an
open-source tool with the goal of providing
a localized, lightweight, and user-friendly in-
terface to these sophisticated advancements to
the machine learning community. SimplyRe-
trieve features a GUI and API based RCG plat-
form, assisted by a Private Knowledge Base
Constructor and a Retrieval Tuning Module.
By leveraging these capabilities, users can ex-
plore the potential of RCG for improving gen-
erative AI performance while maintaining pri-
vacy standards. The tool is available at https:
//github.com/RCGAI/SimplyRetrieve with
an MIT license.
1 Introduction
Generative-based Natural Language Processing
(NLP) has witnessed significant progress (Brown
et al., 2020) in recent years. With the introduction
of Transformer (Vaswani et al., 2017) architecture,
the possibility of developing high-accuracy lan-
guage models that can perform tasks such as text
generation, text summarization and language trans-
lation has become a reality. These models (Brown
et al., 2020; Chowdhery et al., 2022), when scaled
up to billions of parameters (Wei et al., 2022a),
have shown remarkable improvements in text gen-
eration tasks such as zero-shot inference, popu-
larized the term Generative AI . Instead of model
fine-tuning, careful design of prompts has proven
Figure 1: Retrieval-Centric Generation (RCG) approach
presents an innovative concept that leverages the mutu-
ally beneficial interaction between LLMs and retrievers
for more efficient context interpretation and knowledge
memorization. Increased clarity in role-separation be-
tween context interpretation and knowledge memoriza-
tion can potentially boost the performance of generative
AI systems.
effective in adapting these models to specific do-
mains for various tasks (Brown et al., 2020). This
has given rise to the field of prompt-engineering.
Additionally, Chain-of-Thought (Wei et al., 2022b;
Kojima et al., 2022) decomposes a complex task
assigned into manageable steps, thereby expand-
ing the capabilities of generative-based language
models even further.
Training large language models (LLMs) requires
immense computational resources, often involv-
ing thousands of high-end GPUs. Fine-tuning
these models can also be challenging. Although
prompt-engineering helped to reduce the need for
fine-tuning, there was still noticeable instruction
misalignment when interacting with a human user.
To address this issue, techniques such as rein-
forcement learning from human feedback (RLHF)
(Christiano et al., 2017) have been explored to align
the behavior of LLMs with human values (Ouyang
et al., 2022; OpenAI, 2023). Additionally, QLoRA
(Dettmers et al., 2023), combining low-rank adap-arXiv:2308.03983v1  [cs.CL]  8 Aug 2023

--- PAGE 2 ---
tation technique (Hu et al., 2022) and quantization
technique, has made it possible to fine-tune these
models on individual developer’s hardware, mak-
ing them more accessible to a wider range of users.
Despite these advances, there are still limitations
to the capacity of LLMs, and they do not inher-
ently recognize information that was not present
during training and fine-tuning. Memorization of
factual knowledge in the long tail is also a chal-
lenge (Mallen et al., 2023).
Most recently, there has been growing interest in
integrating external knowledge sources into LLMs
for generating text (Borgeaud et al., 2022; Guu
et al., 2020; Lewis et al., 2020). Similar approaches
have also been proposed in solving computer vi-
sion tasks (Nakata et al., 2022; Iscen et al., 2023).
Retrieval-Augmented Generation (RAG) (Lewis
et al., 2020) architecture is an approach that en-
hances the capabilities of LLMs by incorporating
external data sources using a sparse or dense re-
triever (Karpukhin et al., 2020), enabling the use of
privately owned data without requiring retraining
or fine-tuning the LLM (Chase, 2022). However,
developing retrieval-augmented LLM-based gen-
erative models is still in its early stages. Our pro-
posed tool can help facilitate these developments.
Additionally, we introduce a new architec-
tural concept called Retrieval-Centric Genera-
tion (RCG), which builds upon the Retrieval-
Augmented Generation approach by emphasizing
the crucial role of the LLM in interpreting context
and entrusting knowledge memorization to the re-
triever component, putting greater importance on
retriever, as depicted in Figure 1. By separating
context interpretation from knowledge memoriza-
tion, this approach has the potential to reduce the
scale (Carlini et al., 2023) of the LLM required for
generative tasks, leading to more efficient and inter-
pretable results. Moreover, this approach may help
mitigate hallucinations (Maynez et al., 2020) by
limiting the scope of the LLM’s generation. Once
we define RCG as above, we can re-define RAG
that enables more permissible usage of LLM’s in-
herent knowledge, whereas RCG prioritizes clear
demarcations between context interpretation and
knowledge memorization.
SimplyRetrieve is an open-source tool aimed
at providing a localized, lightweight, and user-
friendly interface to Retrieval-Centric Generation
approach to the machine learning community. This
tool encompasses a GUI and API based RCG plat-form, assisted by a Private Knowledge Base Con-
structors and a Retrieval Tuning Module. Sim-
plyRetrieve is designed to be simple and acces-
sible to the community, as well as end-users.
Our retrieval-centric platform incorporates multi-
ple selectable knowledge bases featuring Mixtures-
of-Knowledge-Bases (MoKB) mode and Explicit
Prompt-Weighting (EPW) of retrieved knowledge
base. By designing SimplyRetrieve with these
features, we enable the machine learning commu-
nity to explore and develop with a lightweight,
private data interface to LLM-based generative
AI systems, with a focus on retrieval-centric gen-
eration. Potential developments that can be ex-
plored using this tool include: (1) examining the
effectiveness of retrieval-centric generation in de-
veloping safer, more interpretable, and responsi-
ble AI systems; (2) optimizing the efficiency of
separating context interpretation and knowledge
memorization within retrieval-centric generation
approach; and (3) improving prompt-engineering
techniques for retrieval-centric generation. Sim-
plyRetrieve is available at https://github.com/
RCGAI/SimplyRetrieve .
Our contributions can be summarized as follows:
•We propose SimplyRetrieve, an innovative
and user-friendly tool that leverages GUI and
API platform to facilitate a Retrieval-Centric
Generation approach. This platform is further
strengthened by two key components: Private
Knowledge Base Constructor and Retrieval
Tuning Module.
•We open sourced our tool to the machine learn-
ing community and identify potential develop-
ment directions of Retrieval-Centric Genera-
tion.
2 Related Works
The emergence of Retrieval-Augmented Genera-
tion architecture has spurred the development of
numerous open-source tools. The ChatGPT Re-
trieval Plugin1, for instance, integrates the ability
to retrieve and enhance personal or organizational
documents into the widely used ChatGPT model
(OpenAI, 2023). Similarly, fastRAG (Izsak et al.,
2023) provides a streamlined platform for con-
structing efficient retrieval-augmented generation
1https://github.com/openai/
chatgpt-retrieval-plugin

--- PAGE 3 ---
Figure 2: SimplyRetrieve is an open-source tool that provides a localized, lightweight, and user-friendly interface to
the Retrieval-Centric Generation approach for the machine learning community. This tool features a GUI and API
based RCG platform, assisted by a Private Knowledge Base Constructor and a Retrieval Tuning Module.
pipelines. Additionally, LangChain (Chase, 2022)
offers a comprehensive generative chat AI library
featuring agents, data augmentation, and mem-
ory capabilities. Finally, Haystack (Pietsch et al.,
2019) presents an all-encompassing NLP frame-
work supporting question answering, answer gen-
eration, semantic document search, and retrieval-
augmentation. Both LangChain and Haystack em-
ploy agent-based pipelining techniques and can
process complex queries. However, this complex-
ity may hinder the explainability of LLMs, mak-
ing it challenging to interpret their performance in
retrieval-augmented settings.
On the other hand, our work offers a lightweight
and transparent approach to implementing so-
phisticated retrieval-centric, as well as retrieval-
augmented architecture, while maintaining a strong
emphasis on response interpretability and wider
accessibility to the community. Unlike previous
works such as PrivateGPT (PrivateGPT), which
provides a privacy-preserving chat AI tool but lacks
customization options and analytical capabilities,
our tool offers a comprehensive set of features for
tailoring and analyzing retrieval-centric generation.
Furthermore, to the best of our knowledge, we
are the first to introduce RCG concept and show
initial experiments of it using our tool.
3 Tool Design
SimplyRetrieve is designed to deploy RCG
pipeline: construct knowledge base, tune archi-
tecture, make predictions. In this paper, we fo-
cus on describing the core specifications of the
tool. For details about the setup procedures, referto the repository of https://github.com/RCGAI/
SimplyRetrieve .
3.1 GUI and API based Retrieval-Centric
Generation Platform
As shown in Figure 2, there are two dense models
in our tool: an LLM and an Approximate Near-
est Neighbor Search (ANNS) based Knowledge
Retriever. The LLM can be any one of the off-
the-shelf open-source LLM models available in
Hugging Face (Wolf et al., 2020), ranging from
1B to more than 100B-scale in parameters such as
Touvron et al. (2023a,b). The Knowledge Retriever
employs a dense retriever that is compatible with
various embedding models available in Hugging
Face. Additionally, our tool allows integration of
multiple knowledge bases simultaneously, enabling
user-selectable knowledge bases depending on the
specific use case.
In terms of the GUI, we have designed a sim-
ple yet intuitive layout using Gradio (Abid et al.,
2019), which provides a familiar streaming chatbot
interface with user control for managing the run-
ning modes of the retriever, engineering prompts,
and configuring the tool. As depicted in Figure 3,
our GUI features a comprehensive retrieval-centric
tuning panel for functions including manual knowl-
edge base selection from multiple sources and
Mixture-of-Knowledge-Base modes. Moreover, we
employ Explicit Prompt-Weighting of retrieval to
adjust the level of influence exerted by the retriever.
To ensure seamless integration, we also developed
a comprehensive API access function using the
Gradio Client Interface, and we allow multi-user

--- PAGE 4 ---
Figure 3: The GUI design of SimplyRetrieve features four primary tabs. The Chat tab serves as the central query
and response interface with retrieval-centric tuning panel. The Prompt tab provides an intuitive editor for modifying,
updating, and saving prompts used by the AI. The Config tab enables users to customize various tool settings and
save their preferences. Finally, the Analysis tab offers a comprehensive analytics platform for analyzing and logging
data related to SimplyRetrieve’s performance and usage.
concurrent access to both UIs, leveraging Gradio’s
queue functionality to manage requests efficiently.
The retrieval-centric tuning panel enables
lightweight and simplistic access to RCG. By using
the manual knowledge base selection mode, users
can construct and import multiple private knowl-
edge bases simultaneously into this tool. The abil-
ity to select the most relevant knowledge base for
each task allows users to maintain control over the
selection process while avoiding any unexpected
outcomes. Our MoKB mode enables automatic se-
lection of the most suitable knowledge base based
on the similarity between the query and knowledge
base functional descriptions. We use semantic co-
sine similarity of embedding space to calculate
these scores, providing an efficient and lightweight
approach to knowledge base auto-selection. By
updating the functional descriptions in the configu-
ration file, users can further enhance the accuracy
of the selection algorithm.
Additionally, our Explicit Prompt-Weighting fea-
ture allows manual adjustment of the degree of
influence of retrievers on the language model, en-
abling customized control over the balance between
retriever and LLM. Through prompt-engineering or
token weight adjustment, users can adapt the tool to
their specific needs, ensuring optimal performance.
SimplyRetrieve has incorporated Explicit Prompt-
Weighting through prompt-engineering, where the
weightage can be adjusted to fine-tune the percent-
age of knowledge tokens to be used in the prompt
out of retrieved tokens. However, we have not im-
plemented token weight adjustment in this studyand leave it for future work.
3.2 Private Knowledge Base Constructor
Our Retrieval-Centric Generation Platform is as-
sisted by a Private Knowledge Base Constructor
that creates a local and personalized knowledge
base using the user’s documents. This construc-
tor employs a scalable documents loader that can
handle large volumes of documents by chunking
and streaming the loading, splitting and knowledge
base creation processes, allowing for efficient doc-
ument processing. The constructor supports var-
ious document formats such as PDF, TXT, DOC,
DOCX, PPT, PPTX, HTML, MD, CSV , among
others, and can be easily expanded by editing con-
figuration file. Additionally, the length of passages
in the documents splitting function is easily config-
urable to meet specific requirements.
After generating the sources for the knowledge
base, we use a dense encoder to convert the text
into numerical embeddings that can be used for
semantic search and retrieve. To accommodate
large-scale knowledge bases, we utilize ANNS for
efficient semantic retrieval. By default, our tool
employs the Hierarchical Navigable Small Worlds
(HNSW) (Malkov and Yashunin, 2020) algorithm,
but we also provide support for flat indexing and
the IVFPQ-HNSW method, which combines in-
verted file indexing with product quantization and
HNSW course quantizers. The Index Constructor
function automatically creates the required index
files for semantic searching. We implement our
indexing function by using Faiss library (Johnson

--- PAGE 5 ---
et al., 2019).
3.3 Retrieval Tuning Module
The Retrieval Tuning Module of our tool includes
three key functionalities: prompt-engineering,
tool configuration, and analysis and data logging.
The prompt-engineering functionality allows users
to easily edit, update, and save retrieval-related
prompts using a user-friendly Prompt Tab within
our GUI. Available prompts are AI Prefix, Retriever
Prefix, Retriever Suffix, Model Prefix and Model
Suffix . The configuration functionality enables
users to modify and save all configurable settings
via the Config Tab within our GUI. Finally, the anal-
ysis and data logging functionality collects and dis-
plays retrieval-related analysis data, including re-
trieved knowledge base, query, response, sentence-
level and token-level similarity scores, in the Anal-
ysis Tab of our GUI. Similarity scores are calcu-
lated based on both semantic cosine similarity of
sentence-to-sentence embeddings and all-token-to-
token embeddings. This approach allows us to
capture both local and global similarities between
sentences, leading to more accurate assessments of
their comparability. Additionally, users can save all
logged data to a log file for further analysis. GUI
designs are depicted in Figure 4, 5 and 6 of Ap-
pendix A.2. To deploy an end-user mode, users can
simply disable the update functions in the Retrieval
Tuning Module through command-line options.
4 Evaluations
In this section, we perform several qualitative eval-
uations to demonstrate the usability and behavior
of our tool. We construct our knowledge base using
the most recent information available on the web-
site of an organization2. We utilize the models pub-
licly available on Hugging Face, Wizard-Vicuna-
13B3(Xu et al., 2023; Chiang et al., 2023) as
the LLM and Multilingual-E5-base4(Wang et al.,
2022) as the encoder for our evaluations, unless
specified otherwise. We load both models into a
single Nvidia A100 GPU in 8-bit INT8 mode for
lower memory usage and higher inference speed.
We set temperature of LLM to 0. We utilize HNSW
for indexing of knowledge bases and set the num-
ber of passages retrieved to 5.
2https://www.kioxia.com/en-jp/top.html
3https://huggingface.co/ehartford/
Wizard-Vicuna-13B-Uncensored
4https://huggingface.co/intfloat/
multilingual-e5-base4.1 Qualitative Evaluation
We compare the results of three approaches:
Retrieval-Centric Generation (RCG), Retrieval-
Augmented Generation (RAG), and Retrieval-OFF
Generation (ROG). Note that in this work, we de-
fine RAG as allowing more permissible integra-
tion of LLM’s inherent and externally retrieved
knowledge, whereas RCG prioritizes clear demar-
cations between context interpretation and knowl-
edge memorization. Investigating advanced meth-
ods in extracting RCG behavior is a promising
research topic. In this work, we conduct simple
experiments using prompt-engineering technique
to reveal the potential of RCG approach. Specifi-
cally, for RCG, we employ a retrieval suffix prompt
that reads “ answer the following question with the
provided knowledge. ” For RAG, we use a less
constraining prompt that reads “ answer the follow-
ing question. You may use the provided knowl-
edge. ” Finally, for ROG, which is the baseline in
our evaluation, we disable the retriever altogether.
By using the prompt-engineering function in Sim-
plyRetrieve, we can easily perform these experi-
ments. Queries are human annotated. In Table 1
and 2, blue-colored texts indicates factually correct
responses while red-colored texts indicates halluci-
nations.
Query: where is Kioxia’s factory?
Approach Response
RCG Kioxia has factories located in both Yokkaichi
city, Mie prefecture and Kitakami city, Iwate pre-
fecture in Japan.
RAG Kioxia has factories located in various regions
across the globe including Japan, Thailand,
Malaysia, China, and the United States. However,
its main production site is located in Yokkaichi
City, Mie Prefecture, Japan.
ROG Our main production site for HDD and SSD prod-
ucts is located in Yamagata, Japan. We also have
manufacturing sites in Thailand and the Philip-
pines that produce optical disc media such as Blu-
ray Discs and DVDs.
Table 1: Qualitative comparison between Retrieval-
Centric, Retrieval-Augmented and Retrieval-OFF ap-
proaches using prompt-engineering in SimplyRetrieve.
Based on the results in Table 1, we observed
that RCG successfully answered our query accu-
rately, whereas RAG attempted to integrate the
retrieved knowledge base with LLM’s own knowl-
edge of the specific organization, resulting in par-
tially erroneous information. Meanwhile, ROG re-
sponded to our query with LLM’s preexisting mis-
taken knowledge, generating falsehoods. Our find-

--- PAGE 6 ---
ings suggest that crafting clear and direct prompts,
such as “ answer the given question using the pro-
vided knowledge ”, can encourage retrieval-centric
behavior from the LLM, although further refined
prompt-engineering may be necessary for optimal
performance.
As shown in Table 2, RCG effectively addressed
the query and produced accurate results. When
combining RCG with a 50% Explicit Prompt-
Weighting (RCG-EPW), where only the first 50%
of retrieved knowledge base are injected into the
prompt, the model generated partial responses but
still maintained factual accuracy. In contrast, the
pure LLM without RC enabled (ROG) provided
hallucinatory responses, highlighting the impor-
tance of incorporating retrieval-centric techniques
in language models for improved performance.
Query: what did Kioxia do in Image Classification
Approach Response
RCG Kioxia developed a high capacity storage
device which could store large amounts of
image data required by AI algorithms. This
allowed them to deploy memory centric AI
systems capable of handling multiple classi-
fication tasks simultaneously without com-
promising performance or accuracy.
RCG-EPW Deployment of Memory-centric AI with
high capacity storage
ROG The company developed a new image clas-
sification algorithm that achieved top-1 ac-
curacy of 82.7% on the ImageNet valida-
tion set, which is an improvement over pre-
vious state-of-the-art results by more than
one percentage point. This was made possi-
ble through advancements in hardware and
software technologies such as Tensor Core
GPUs and our own deep learning frame-
work, ONNX-MXNET.
Table 2: Effects of Retrieval-Centric Generation in Sim-
plyRetrieve, based on the knowledge base about an or-
ganization.
4.2 Accuracy & Speed Evaluations
In addition to evaluating the effectiveness of RCG
using human annotations, we also conduct an in-
ternal evaluation of our tool’s performance using
a self-generated dataset. To create this dataset, we
pass relevant passages through the language model
Llama-2-13B-chat (Touvron et al., 2023b) to gen-
erate 10 query and label pairs. For details on how
we generated this dataset, refer to Appendix A.4.
We employ Rouge-L score (Lin, 2004) as our per-
formance metric. We perform this evaluation by
using the API function of SimplyRetrieve. Our
results in Table 3 show that RCG significantly im-proves the Rouge-L score compared to the baseline
approach of ROG, while also slightly more com-
petitive than RAG. Moreover, despite the fact that
RCG processes longer prompts than ROG due to
the addition of knowledge tokens, we observe a
decrease in processing time owing to the increased
precision and brevity of the generated responses.
Specifically, number of response tokens generated
in RCG are in average 36% less than those gen-
erated in ROG. This efficient performance may
facilitate broader adoption within the community,
as users can expect quicker response generation
without sacrificing accuracy.
Approach Rouge-L Score time/query(s)
ROG 0.186 17.22
RAG 0.359 18.41
RCG 0.413 11.67
Table 3: Response accuracy & speed evaluation of Sim-
plyRetrieve.
Finally, our findings suggest that even a mod-
estly sized LLM of 13B parameters can demon-
strate satisfactory performance in RCG approach
towards never-seen-before factual knowledge with-
out any model fine-tuning, potentially facilitates
the deployment of Generative AI systems in real-
world scenarios. See Appendix A.2 for further
discussions and A.5 for ablation studies.
5 Conclusion
We introduced SimplyRetrieve, an open-source tool
that aims to provide a localizable, lightweight, and
user-friendly GUI and API platform for a Retrieval-
Centric Generation approach based on LLMs. Our
tool enables developers and end-users to easily in-
teract and develop with a privacy-preserving and lo-
cally implemented LLM-based RCG system, which
we believe will contribute to the democratization
of these technologies within the machine learning
community. Increased clarity in role-separation be-
tween context interpretation and knowledge memo-
rization can potentially boost the performance and
interpretability of generative AI systems, facilitat-
ing deployments.
Limitations
It is important to note that this tool does not provide
a foolproof solution for ensuring a completely safe
and responsible response from generative AI mod-
els, even within a retrieval-centric approach. The

--- PAGE 7 ---
development of safer, interpretable, and responsi-
ble AI systems remains an active area of research
and ongoing effort.
Generated texts from this tool may exhibit varia-
tions, even when only slightly modifying prompts
or queries, due to the next token prediction behav-
ior of current-generation LLMs. This means users
may need to carefully fine-tune both the prompts
and queries to obtain optimal responses.
References
Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan,
Abdulrahman Alfozan, and James Zou. 2019. Gradio:
Hassle-free sharing and testing of ml models in the
wild. arXiv preprint arXiv:1906.02569 .
Sebastian Borgeaud, Arthur Mensch, Jordan Hoff-
mann, Trevor Cai, Eliza Rutherford, Katie Milli-
can, George Bm Van Den Driessche, Jean-Baptiste
Lespiau, Bogdan Damoc, Aidan Clark, Diego
De Las Casas, Aurelia Guy, Jacob Menick, Roman
Ring, Tom Hennigan, Saffron Huang, Loren Mag-
giore, Chris Jones, Albin Cassirer, Andy Brock,
Michela Paganini, Geoffrey Irving, Oriol Vinyals,
Simon Osindero, Karen Simonyan, Jack Rae, Erich
Elsen, and Laurent Sifre. 2022. Improving language
models by retrieving from trillions of tokens. In
Proceedings of the 39th International Conference
on Machine Learning , volume 162 of Proceedings
of Machine Learning Research , pages 2206–2240.
PMLR.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-V oss,
Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens
Winter, Chris Hesse, Mark Chen, Eric Sigler, Ma-
teusz Litwin, Scott Gray, Benjamin Chess, Jack
Clark, Christopher Berner, Sam McCandlish, Alec
Radford, Ilya Sutskever, and Dario Amodei. 2020.
Language models are few-shot learners. In Ad-
vances in Neural Information Processing Systems ,
volume 33, pages 1877–1901. Curran Associates,
Inc.
Nicholas Carlini, Daphne Ippolito, Matthew Jagielski,
Katherine Lee, Florian Tramer, and Chiyuan Zhang.
2023. Quantifying memorization across neural lan-
guage models. In The Eleventh International Confer-
ence on Learning Representations .
Harrison Chase. 2022. LangChain.
Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,
Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan
Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion
Stoica, and Eric P. Xing. 2023. Vicuna: An open-
source chatbot impressing gpt-4 with 90%* chatgpt
quality.Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,
Maarten Bosma, Gaurav Mishra, Adam Roberts,
Paul Barham, Hyung Won Chung, Charles Sutton,
Sebastian Gehrmann, Parker Schuh, Kensen Shi,
Sasha Tsvyashchenko, Joshua Maynez, Abhishek
Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-
odkumar Prabhakaran, Emily Reif, Nan Du, Ben
Hutchinson, Reiner Pope, James Bradbury, Jacob
Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,
Toju Duke, Anselm Levskaya, Sanjay Ghemawat,
Sunipa Dev, Henryk Michalewski, Xavier Garcia,
Vedant Misra, Kevin Robinson, Liam Fedus, Denny
Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim,
Barret Zoph, Alexander Spiridonov, Ryan Sepassi,
David Dohan, Shivani Agrawal, Mark Omernick,
Andrew M. Dai, Thanumalayan Sankaranarayana
Pillai, Marie Pellat, Aitor Lewkowycz, Erica Mor-
eira, Rewon Child, Oleksandr Polozov, Katherine
Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta,
Mark Diaz, Orhan Firat, Michele Catasta, Jason
Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean,
Slav Petrov, and Noah Fiedel. 2022. Palm: Scaling
language modeling with pathways. arXiv preprint
arXiv:2204.02311 .
Paul F Christiano, Jan Leike, Tom Brown, Miljan Mar-
tic, Shane Legg, and Dario Amodei. 2017. Deep
reinforcement learning from human preferences. In
Advances in Neural Information Processing Systems ,
volume 30. Curran Associates, Inc.
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and
Luke Zettlemoyer. 2023. Qlora: Efficient finetuning
of quantized llms. arXiv preprint arXiv:2305.14314 .
Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-
pat, and Ming-Wei Chang. 2020. Realm: Retrieval-
augmented language model pre-training. In Proceed-
ings of the 37th International Conference on Machine
Learning , ICML’20. JMLR.org.
Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan
Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and
Weizhu Chen. 2022. LoRA: Low-rank adaptation of
large language models. In International Conference
on Learning Representations .
Ahmet Iscen, Alireza Fathi, and Cordelia Schmid. 2023.
Improving image recognition by retrieving from
web-scale image-text data. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pat-
tern Recognition (CVPR) , pages 19295–19304.
Peter Izsak, Moshe Berchansky, Daniel Fleischer, and
Ronen Laperdon. 2023. fastRAG: Efficient Retrieval
Augmentation and Generation Framework.
Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2019.
Billion-scale similarity search with GPUs. IEEE
Transactions on Big Data , 7(3):535–547.
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick
Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and
Wen-tau Yih. 2020. Dense passage retrieval for open-
domain question answering. In Proceedings of the

--- PAGE 8 ---
2020 Conference on Empirical Methods in Natural
Language Processing (EMNLP) , pages 6769–6781,
Online. Association for Computational Linguistics.
Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-
taka Matsuo, and Yusuke Iwasawa. 2022. Large lan-
guage models are zero-shot reasoners. In Advances
in Neural Information Processing Systems .
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio
Petroni, Vladimir Karpukhin, Naman Goyal, Hein-
rich Küttler, Mike Lewis, Wen-tau Yih, Tim Rock-
täschel, Sebastian Riedel, and Douwe Kiela. 2020.
Retrieval-augmented generation for knowledge-
intensive nlp tasks. In Advances in Neural Infor-
mation Processing Systems , volume 33, pages 9459–
9474. Curran Associates, Inc.
Chin-Yew Lin. 2004. ROUGE: A package for auto-
matic evaluation of summaries. In Text Summariza-
tion Branches Out , pages 74–81, Barcelona, Spain.
Association for Computational Linguistics.
Yu A. Malkov and D. A. Yashunin. 2020. Efficient and
robust approximate nearest neighbor search using
hierarchical navigable small world graphs. IEEE
Trans. Pattern Anal. Mach. Intell. , 42(4):824–836.
Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,
Daniel Khashabi, and Hannaneh Hajishirzi. 2023.
When not to trust language models: Investigating
effectiveness of parametric and non-parametric mem-
ories. In Proceedings of the 61st Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers) , pages 9802–9822, Toronto,
Canada. Association for Computational Linguistics.
Joshua Maynez, Shashi Narayan, Bernd Bohnet, and
Ryan McDonald. 2020. On faithfulness and factu-
ality in abstractive summarization. In Proceedings
of the 58th Annual Meeting of the Association for
Computational Linguistics , pages 1906–1919, On-
line. Association for Computational Linguistics.
Kengo Nakata, Youyang Ng, Daisuke Miyashita, Asuka
Maki, Yu-Chieh Lin, and Jun Deguchi. 2022. Re-
visiting a knn-based image classification system
with high-capacity storage. In Computer Vision –
ECCV 2022 , pages 457–474, Cham. Springer Nature
Switzerland.
OpenAI. 2023. Chatgpt. https://openai.com/blog/
chatgpt .
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,
Carroll Wainwright, Pamela Mishkin, Chong Zhang,
Sandhini Agarwal, Katarina Slama, Alex Ray, John
Schulman, Jacob Hilton, Fraser Kelton, Luke Miller,
Maddie Simens, Amanda Askell, Peter Welinder,
Paul F Christiano, Jan Leike, and Ryan Lowe. 2022.
Training language models to follow instructions with
human feedback. In Advances in Neural Information
Processing Systems , volume 35, pages 27730–27744.
Curran Associates, Inc.Malte Pietsch, Timo Möller, Bogdan Kostic, Julian
Risch, Massimiliano Pippi, Mayank Jobanputra, Sara
Zanzottera, Silvano Cerza, Vladimir Blagojevic,
Thomas Stadelmann, Tanay Soni, and Sebastian Lee.
2019. Haystack: the end-to-end NLP framework for
pragmatic builders.
PrivateGPT. PrivateGPT. Accessed: 2023-07-04.
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
Martinet, Marie-Anne Lachaux, Timothée Lacroix,
Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal
Azhar, Aurelien Rodriguez, Armand Joulin, Edouard
Grave, and Guillaume Lample. 2023a. Llama: Open
and efficient foundation language models. arXiv
preprint arXiv:2302.13971 .
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti
Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton
Ferrer, Moya Chen, Guillem Cucurull, David Esiobu,
Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,
Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-
thony Hartshorn, Saghar Hosseini, Rui Hou, Hakan
Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,
Isabel Kloumann, Artem Korenev, Punit Singh Koura,
Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-
ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-
tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-
bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,
Ruan Silva, Eric Michael Smith, Ranjan Subrama-
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,
Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,
Melanie Kambadur, Sharan Narang, Aurelien Ro-
driguez, Robert Stojnic, Sergey Edunov, and Thomas
Scialom. 2023b. Llama 2: Open foundation and fine-
tuned chat models. arXiv preprint arXiv:2307.09288 .
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Advances in Neural Information Pro-
cessing Systems , volume 30. Curran Associates, Inc.
Liang Wang, Nan Yang, Xiaolong Huang, Binxing
Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder,
and Furu Wei. 2022. Text embeddings by weakly-
supervised contrastive pre-training. arXiv preprint
arXiv:2212.03533 .
Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,
Barret Zoph, Sebastian Borgeaud, Dani Yogatama,
Maarten Bosma, Denny Zhou, Donald Metzler, Ed H.
Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy
Liang, Jeff Dean, and William Fedus. 2022a. Emer-
gent abilities of large language models. Transactions
on Machine Learning Research . Survey Certifica-
tion.
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
Bosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le,

--- PAGE 9 ---
and Denny Zhou. 2022b. Chain-of-thought prompt-
ing elicits reasoning in large language models. In
Advances in Neural Information Processing Systems ,
volume 35, pages 24824–24837. Curran Associates,
Inc.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond, Clement Delangue, Anthony Moi, Pier-
ric Cistac, Tim Rault, Remi Louf, Morgan Funtow-
icz, Joe Davison, Sam Shleifer, Patrick von Platen,
Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,
Teven Le Scao, Sylvain Gugger, Mariama Drame,
Quentin Lhoest, and Alexander Rush. 2020. Trans-
formers: State-of-the-art natural language processing.
InProceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing: System
Demonstrations , pages 38–45, Online. Association
for Computational Linguistics.
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng,
Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin
Jiang. 2023. Wizardlm: Empowering large lan-
guage models to follow complex instructions. arXiv
preprint arXiv:2304.12244 .
A Appendix
A.1 GUI Design of Retrieval Tuning Module
Figure 4 shows the GUI design of prompt-
engineering interface. Figure 5 shows the GUI
design of tool configuration interface. Figure 6
shows the GUI design of analysis and data logging
interface.
A.2 Applications
SimplyRetrieve has vast potential for various prac-
tical applications. For instance, it can serve as
the foundation for building private, personalized,
and lightweight generative AI systems. Sensitive
and personal information can be securely stored
and processed within the retrieval-centric platform.
This approach enables organizations to develop
interpretable and locally tailored generative AI sys-
tems for critical infrastructure. Additionally, the
use of a relatively smaller language model as a
contextual interpreter in this approach facilitates
seamless integration into edge computing environ-
ments. The decreasing costs of data storage devices
also make it feasible to establish large-scale knowl-
edge bases. Furthermore, SimplyRetrieve paves
the way for the development of LLM-based person-
alized AI assistants. Lastly, an in-depth exploration
of LLM-based retrieval-centric generation using
SimplyRetrieve may offer valuable insights and
opportunities for future research.A.3 Prompt Catalogs
Table 5 shows the prompts used in the evaluation
results of Section 4 while Table 6 shows sample
prompts that may exhibit retrieval-centric behav-
iors. Prompts are passed to LLM in the following
format: AI Prefix + Retriever Prefix + Retrieved
Knowledge Base + Retriever Suffix + Model Prefix
+ Query + Model Suffix .
A.4 Evaluation Data
Table 7 presents the data used for evaluating the per-
formance of our proposed tool in Section 4.2. We
employed the Llama-2-13B-chat model (Touvron
et al., 2023b) with a customized prompt ( "relevant
information." Please create a query and answer
from the paragraph above ) to generate query and
label pairs automatically from relevant information
on the website of an organization.
A.5 Ablation Study
As shown in Table 4, our ablation study reveals that
adjusting Explicit Prompt-Weighting in SimplyRe-
trieve leads to significant improvements in Rouge-
L scores. Interestingly, increasing the weightage
to 50% yields the highest improvement, beyond
which the performance remains relatively stable.
This suggests that the top 50% of retrieved knowl-
edge bases are crucial for achieving high accuracy.
However, it is important to note that these findings
may not generalize to all datasets or knowledge
bases, and further investigation may be necessary
to determine optimal weightages for specific use
cases. In comparing the response times for each
query across different settings, we observe that the
response times remain relatively consistent for all
cases of RCG, while they increase significantly in
the baseline (ROG) setting. Despite the fact that
RCG processes longer prompts than the baseline,
we observe a decrease in processing time owing to
the increased precision and brevity of the generated
responses.

--- PAGE 10 ---
Approach Rouge-L time/query(s)
ROG 0.186 17.22
RCG-EPW-10 0.275 12.72
RCG-EPW-20 0.313 13.00
RCG-EPW-30 0.403 13.06
RCG-EPW-40 0.354 11.98
RCG-EPW-50 0.414 12.46
RCG-EPW-60 0.331 11.36
RCG-EPW-70 0.392 13.56
RCG-EPW-80 0.306 16.32
RCG-EPW-90 0.378 13.13
RCG 0.413 11.67
Table 4: Ablation study of Explicit Prompt-Weighting in SimplyRetrieve.
AI Prefix Retriever Prefix Retriever Suffix Model Prefix Model Suffix
" "
answer the following question with
the provided knowledge.AI:
Table 5: Prompts used in the evaluation results of Section 4.
AI Prefix Retriever Prefix Retriever Suffix Model Prefix Model Suffix
you are a Retrieval-Centric
AI. Knowledge below are
provided." "
only use the provided
knowledge to answer the
following question.Response:
" "
answer the following ques-
tion with the provided
knowledge.AI:
" "
only use the provided
knowledge to answer the
following question.AI:
you are a Retrieval-Centric
AI. Knowledge below are
provided." "
only use the provided
knowledge to answer the
following question.AI:
Table 6: Sample Prompts Catalog of Retrieval-Centric Generation in SimplyRetrieve.

--- PAGE 11 ---
Figure 4: The Prompt-Engineering interface of SimplyRetrieve. The Tab is for editing, updating and saving of
model-related and retrieval-related prompts. Available prompts are AI Prefix, Retriever Prefix, Retriever Suffix,
Model Prefix and Model Suffix .
Figure 5: The Tool Configuration interface of SimplyRetrieve. The Tab is for modifying, updating and saving all
configurable settings.
Figure 6: The Analysis and Data Logging interface of SimplyRetrieve. The Tab is for analysis and logging of
retrieved knowledge base, query, response, retrieval sentence level and tokens level similarity scores. Users can save
all the logged data for further analysis.

--- PAGE 12 ---
Query Label
What is KIOXIA known
for in terms of innova-
tion?Based on the text, KIOXIA is known for inventing NAND flash memory in 1987 and
advancing the information society on a global scale through its R&D efforts. The company
has also been recognized for presenting its research and development achievements through
various channels, including major academic societies and research conferences.
What is the purpose of es-
tablishing KIOXIA Iwate
Corporation?The purpose of establishing KIOXIA Iwate Corporation is to meet the growing demand
for flash memory by leveraging advanced manufacturing processes that utilize AI.
When did Kioxia start op-
erating its new fabrication
facility (Fab7)?According to the text, Kioxia started operating its new fabrication facility (Fab7) in the
fall of 2022.
What are some ways in
which the Yokkaichi Plant
contributes to society?The Yokkaichi Plant contributes to society by manufacturing high-quality flash memory
and SSDs that support the digitalization of various industries, as well as through its research
and development (R&D) activities. Additionally, the plant prioritizes legal compliance,
environmental protection, and social initiatives, making it a responsible corporate citizen.
What is KIOXIA’s ap-
proach to corporate social
responsibility?According to the passage, KIOXIA’s approach to corporate social responsibility involves
making their Yokkaichi Plant a factory that is admired and trusted by everyone in the
community. They aim to contribute to local development and meet the expectations of
local communities by being a responsible member of society.
What kind of environmen-
tal initiatives has KIOXIA
taken at its Yokkaichi
Plant?At KIOXIA’s Yokkaichi Plant, all employees, including resident suppliers, actively partici-
pate in various initiatives to contribute to society by improving the environment. These
include measures to mitigate the environmental burden of the company’s semiconductor
manufacturing facilities.
What was the total rev-
enue for the Kioxia group
in fiscal year 21?According to the passage, the total revenue for the Kioxia group in fiscal year 21 was
1,526.5 billion yen.
What initiatives has the
Yokkaichi Plant taken to
protect the environment?The Yokkaichi Plant has taken various initiatives such as reducing greenhouse gas emis-
sions, conserving water resources, and implementing recycling programs to protect the
environment. These efforts aim to not only reduce the plant’s ecological footprint but
also raise awareness among local communities about the importance of environmental
conservation.
What is KIOXIA’s mis-
sion statement?According to the passage, KIOXIA’s mission statement is to uplift the world with ’mem-
ory’, which means they aim to provide high-quality memory and SSD products that offer
fast speeds, large capacities, and reliable performance. Additionally, the company seeks
to achieve this goal through collaboration and knowledge sharing across different depart-
ments and organizations.
What is the purpose of
collecting over two bil-
lion data items daily?To maintain high-quality products by analyzing the vast amounts of data generated during
the manufacturing process using advanced technologies like deep learning and AI.
Table 7: Dataset used in the evaluation results of Section 4.2.

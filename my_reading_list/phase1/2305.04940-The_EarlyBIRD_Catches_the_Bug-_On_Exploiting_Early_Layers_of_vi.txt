# 2305.04940.pdf
# ÄÆ°á»£c chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: ./2305.04940.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 1334069 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================

--- TRANG 1 ---
EarlyBIRD Báº¯t ÄÆ°á»£c Lá»—i: Vá» Viá»‡c Khai ThÃ¡c CÃ¡c Lá»›p Äáº§u cá»§a
MÃ´ HÃ¬nh Encoder Ä‘á»ƒ PhÃ¢n Loáº¡i MÃ£ Hiá»‡u Quáº£ HÆ¡n
Anastasiia Grishina
anastasiia@simula.no
PhÃ²ng ThÃ­ Nghiá»‡m NghiÃªn Cá»©u Simula
Oslo, Na UyMax Hort
maxh@simula.no
PhÃ²ng ThÃ­ Nghiá»‡m NghiÃªn Cá»©u Simula
Oslo, Na UyLeon Moonen
leon.moonen@computer.org
PhÃ²ng ThÃ­ Nghiá»‡m NghiÃªn Cá»©u Simula &
TrÆ°á»ng Kinh Doanh BI Na Uy
Oslo, Na Uy

TÃ“M Táº®T
Viá»‡c sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t Xá»­ LÃ½ NgÃ´n Ngá»¯ Tá»± NhiÃªn (NLP) hiá»‡n Ä‘áº¡i Ä‘Ã£
chá»©ng minh Ä‘Æ°á»£c lá»£i Ã­ch cho cÃ¡c nhiá»‡m vá»¥ ká»¹ thuáº­t pháº§n má»m, nhÆ°
phÃ¡t hiá»‡n lá»— há»•ng báº£o máº­t vÃ  suy luáº­n kiá»ƒu. Tuy nhiÃªn, viá»‡c huáº¥n luyá»‡n
mÃ´ hÃ¬nh NLP sÃ¢u Ä‘Ã²i há»i nguá»“n lá»±c tÃ­nh toÃ¡n Ä‘Ã¡ng ká»ƒ. BÃ i bÃ¡o nÃ y
khÃ¡m phÃ¡ cÃ¡c ká»¹ thuáº­t nháº±m Ä‘áº¡t Ä‘Æ°á»£c viá»‡c sá»­ dá»¥ng tá»‘t nháº¥t cÃ¡c nguá»“n lá»±c
vÃ  thÃ´ng tin cÃ³ sáºµn trong cÃ¡c mÃ´ hÃ¬nh nÃ y.

ChÃºng tÃ´i Ä‘á» xuáº¥t má»™t phÆ°Æ¡ng phÃ¡p tá»•ng quÃ¡t, EarlyBIRD, Ä‘á»ƒ xÃ¢y dá»±ng
cÃ¡c biá»ƒu diá»…n tá»•ng há»£p cá»§a mÃ£ tá»« cÃ¡c lá»›p Ä‘áº§u cá»§a mÃ´ hÃ¬nh transformer
Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c. ChÃºng tÃ´i nghiÃªn cá»©u thá»±c nghiá»‡m tÃ­nh kháº£ thi
cá»§a phÆ°Æ¡ng phÃ¡p nÃ y trÃªn mÃ´ hÃ¬nh CodeBERT báº±ng cÃ¡ch so sÃ¡nh hiá»‡u suáº¥t
cá»§a 12 chiáº¿n lÆ°á»£c táº¡o biá»ƒu diá»…n tá»•ng há»£p vá»›i thá»±c hÃ nh tiÃªu chuáº©n chá»‰
sá»­ dá»¥ng lá»›p encoder cuá»‘i cÃ¹ng.

ÄÃ¡nh giÃ¡ cá»§a chÃºng tÃ´i trÃªn bá»‘n táº­p dá»¯ liá»‡u cho tháº¥y má»™t sá»‘ káº¿t há»£p
lá»›p Ä‘áº§u mang láº¡i hiá»‡u suáº¥t tá»‘t hÆ¡n trong phÃ¡t hiá»‡n lá»—i, vÃ  má»™t sá»‘ káº¿t há»£p
cáº£i thiá»‡n phÃ¢n loáº¡i Ä‘a lá»›p. Cá»¥ thá»ƒ hÆ¡n, chÃºng tÃ´i Ä‘áº¡t Ä‘Æ°á»£c cáº£i thiá»‡n
Ä‘á»™ chÃ­nh xÃ¡c phÃ¡t hiá»‡n trung bÃ¬nh +2 trÃªn Devign chá»‰ vá»›i 3 trong 12 lá»›p
cá»§a CodeBERT vÃ  tÄƒng tá»‘c fine-tuning 3.3x. Nhá»¯ng phÃ¡t hiá»‡n nÃ y cho tháº¥y
cÃ¡c lá»›p Ä‘áº§u cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘áº¡t káº¿t quáº£ tá»‘t hÆ¡n vá»›i cÃ¹ng nguá»“n lá»±c,
cÅ©ng nhÆ° giáº£m sá»­ dá»¥ng nguá»“n lá»±c trong fine-tuning vÃ  suy luáº­n.

KHÃI NIá»†M CCS
â€¢Pháº§n má»m vÃ  ká»¹ thuáº­t cá»§a nÃ³ ;â€¢PhÆ°Æ¡ng phÃ¡p tÃ­nh toÃ¡n
â†’Máº¡ng nÆ¡-ron ;Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn ;

Tá»ª KHÃ“A
bá»n vá»¯ng, tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh, transformer, phÃ¢n loáº¡i mÃ£,
phÃ¡t hiá»‡n lá»— há»•ng, AI4Code, AI4SE, ML4SE

1 GIá»šI THIá»†U
Tá»± Ä‘á»™ng hÃ³a cÃ¡c nhiá»‡m vá»¥ ká»¹ thuáº­t pháº§n má»m (SE) há»— trá»£ cÃ¡c nhÃ  phÃ¡t triá»ƒn
trong viá»‡c táº¡o vÃ  báº£o trÃ¬ mÃ£ nguá»“n. Gáº§n Ä‘Ã¢y, cÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u (DL)
Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c kho mÃ£ nguá»“n má»Ÿ lá»›n vÃ  sá»­ dá»¥ng Ä‘á»ƒ thá»±c hiá»‡n
cÃ¡c nhiá»‡m vá»¥ phÃ¢n tÃ­ch mÃ£ [ 3,8,27,38]. ÄÆ°á»£c thÃºc Ä‘áº©y bá»Ÿi giáº£ thuyáº¿t
tá»± nhiÃªn cho ráº±ng mÃ£ vÃ  ngÃ´n ngá»¯ tá»± nhiÃªn cÃ³ chung cÃ¡c Ä‘áº·c Ä‘iá»ƒm
thá»‘ng kÃª tÆ°Æ¡ng tá»±, cÃ¡c nhÃ  nghiÃªn cá»©u vÃ  nhÃ  cung cáº¥p cÃ´ng cá»¥ Ä‘Ã£ báº¯t Ä‘áº§u
huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh NLP sÃ¢u trÃªn mÃ£ vÃ  fine-tuning chÃºng cho cÃ¡c
nhiá»‡m vá»¥ SE [ 11]. NgoÃ i ra, cÃ¡c mÃ´ hÃ¬nh nhÆ° váº­y Ä‘Ã£ Ä‘Æ°á»£c Ã¡p dá»¥ng
cho suy luáº­n kiá»ƒu [ 17], phÃ¡t hiá»‡n báº£n sao mÃ£ [ 50], sá»­a chá»¯a
chÆ°Æ¡ng trÃ¬nh [ 9,15,47,48], vÃ  dá»± Ä‘oÃ¡n lá»—i [ 7,30,35,44]. Trong cÃ¡c
phÆ°Æ¡ng phÃ¡p dá»±a trÃªn NLP, cÃ¡c nhiá»‡m vá»¥ SE thÆ°á»ng Ä‘Æ°á»£c dá»‹ch thÃ nh
cÃ¡c bÃ i toÃ¡n phÃ¢n loáº¡i mÃ£. VÃ­ dá»¥, phÃ¡t hiá»‡n lá»— há»•ng pháº§n má»m lÃ 
bÃ i toÃ¡n phÃ¢n loáº¡i nhá»‹ phÃ¢n, suy luáº­n kiá»ƒu lá»—i lÃ  thiáº¿t láº­p phÃ¢n loáº¡i
Ä‘a lá»›p, vÃ  suy luáº­n kiá»ƒu lÃ  nhiá»‡m vá»¥ phÃ¢n loáº¡i Ä‘a nhÃ£n Ä‘a lá»›p
trong trÆ°á»ng há»£p má»™t kiá»ƒu Ä‘Æ°á»£c dá»± Ä‘oÃ¡n cho má»—i biáº¿n trong
chÆ°Æ¡ng trÃ¬nh.

Háº§u háº¿t cÃ¡c mÃ´ hÃ¬nh NLP hiá»‡n Ä‘áº¡i Ä‘Æ°á»£c xÃ¢y dá»±ng trÃªn kiáº¿n trÃºc
transformer [ 42]. Kiáº¿n trÃºc nÃ y sá»­ dá»¥ng cÆ¡ cháº¿ attention vÃ  bao gá»“m
má»™t encoder chuyá»ƒn Ä‘á»•i chuá»—i Ä‘áº§u vÃ o thÃ nh má»™t biá»ƒu diá»…n thÃ´ng qua
má»™t loáº¡t cÃ¡c lá»›p, theo sau lÃ  cÃ¡c lá»›p decoder chuyá»ƒn Ä‘á»•i biá»ƒu diá»…n nÃ y
thÃ nh chuá»—i Ä‘áº§u ra. Máº·c dÃ¹ hiá»‡u quáº£ vá» kháº£ nÄƒng há»c, thiáº¿t káº¿ transformer
dáº«n Ä‘áº¿n cÃ¡c mÃ´ hÃ¬nh Ä‘a lá»›p cáº§n lÆ°á»£ng lá»›n dá»¯ liá»‡u Ä‘á»ƒ huáº¥n luyá»‡n tá»« Ä‘áº§u.
Má»™t nhÆ°á»£c Ä‘iá»ƒm ná»•i tiáº¿ng cá»§a cÃ¡c mÃ´ hÃ¬nh nÃ y lÃ  viá»‡c sá»­ dá»¥ng nguá»“n lá»±c
cao cáº§n thiáº¿t Ä‘á»ƒ huáº¥n luyá»‡n do cáº£ kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh vÃ  dá»¯ liá»‡u. Trong khi
má»™t sá»‘ mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c Ä‘Ã£ Ä‘Æ°á»£c cÃ´ng bá»‘ gáº§n Ä‘Ã¢y, viá»‡c
fine-tuning cÃ¡c mÃ´ hÃ¬nh nÃ y cho cÃ¡c nhiá»‡m vá»¥ cá»¥ thá»ƒ váº«n Ä‘Ã²i há»i nguá»“n lá»±c
tÃ­nh toÃ¡n bá»• sung [27].

BÃ i bÃ¡o nÃ y khÃ¡m phÃ¡ cÃ¡c ká»¹ thuáº­t nháº±m tá»‘i Æ°u hÃ³a viá»‡c sá»­ dá»¥ng
nguá»“n lá»±c vÃ  thÃ´ng tin cÃ³ sáºµn trong cÃ¡c mÃ´ hÃ¬nh trong quÃ¡ trÃ¬nh fine-tuning.
Cá»¥ thá»ƒ, chÃºng tÃ´i xem xÃ©t cÃ¡c mÃ´ hÃ¬nh white-box má»Ÿ, mÃ  tá»« Ä‘Ã³ cÃ³ thá»ƒ
trÃ­ch xuáº¥t cÃ¡c trá»ng sá»‘ tá»« má»—i lá»›p. ChÃºng tÃ´i táº­p trung vÃ o cÃ¡c mÃ´ hÃ¬nh
chá»‰ cÃ³ encoder, vÃ¬ chÃºng thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c nhiá»‡m vá»¥ phÃ¢n loáº¡i
SE, Ä‘áº·c biá»‡t lÃ  cÃ¡c encoder dá»±a trÃªn transformer. Thá»±c hÃ nh tiÃªu chuáº©n
trong cÃ¡c mÃ´ hÃ¬nh encoder lÃ  láº¥y biá»ƒu diá»…n cá»§a chuá»—i Ä‘áº§u vÃ o tá»« lá»›p cuá»‘i
cÃ¹ng cá»§a mÃ´ hÃ¬nh [ 14], trong khi thÃ´ng tin tá»« cÃ¡c lá»›p trÆ°á»›c Ä‘Ã³ thÆ°á»ng
bá»‹ loáº¡i bá» [ 21]. Tá»©c lÃ , trong khi cÃ¡c lá»›p Ä‘áº§u Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tÃ­nh
toÃ¡n cÃ¡c giÃ¡ trá»‹ cá»§a lá»›p cuá»‘i cÃ¹ng, chÃºng thÆ°á»ng khÃ´ng Ä‘Æ°á»£c xem xÃ©t
nhÆ° cÃ¡c biá»ƒu diá»…n riÃªng láº» cá»§a Ä‘áº§u vÃ o theo cÃ¡ch mÃ  lá»›p cuá»‘i cÃ¹ng Ä‘Æ°á»£c
xem xÃ©t. Äá»ƒ minh há»a lÆ°á»£ng thÃ´ng tin bá»‹ loáº¡i bá» khi suy luáº­n, khi
fine-tuning má»™t encoder 12 lá»›p, nhÆ° CodeBERT [ 14], cho phÃ¡t hiá»‡n lá»—i,
92% cÃ¡c embedding mÃ£ bá»‹ bá» qua.Â¹ Tuy nhiÃªn, Ä‘Ã£ Ä‘Æ°á»£c chá»‰ ra Ä‘á»‘i vá»›i
ngÃ´n ngá»¯ tá»± nhiÃªn ráº±ng cÃ¡c lá»›p Ä‘áº§u cá»§a encoder náº¯m báº¯t cÃ¡c Ä‘áº·c trÆ°ng
cÃº phÃ¡p cáº¥p tháº¥p tá»‘t hÆ¡n so vá»›i cÃ¡c lá»›p sau [ 6,24,32,40], Ä‘iá»u nÃ y
cÃ³ thá»ƒ cÃ³ lá»£i cho cÃ¡c nhiá»‡m vá»¥ xuÃ´i dÃ²ng.

Láº¥y cáº£m há»©ng tá»« hÆ°á»›ng nghiÃªn cá»©u khai thÃ¡c cÃ¡c lá»›p Ä‘áº§u cá»§a mÃ´ hÃ¬nh,
chÃºng tÃ´i Ä‘á» xuáº¥t EarlyBIRD,Â² má»™t phÆ°Æ¡ng phÃ¡p má»›i vÃ  tá»•ng quÃ¡t Ä‘á»ƒ xÃ¢y
dá»±ng cÃ¡c biá»ƒu diá»…n tá»•ng há»£p tá»« cÃ¡c lá»›p Ä‘áº§u cá»§a mÃ´ hÃ¬nh encoder Ä‘Æ°á»£c
huáº¥n luyá»‡n trÆ°á»›c. EarlyBIRD nháº±m táº­n dá»¥ng táº¥t cáº£ thÃ´ng tin cÃ³ sáºµn
trong cÃ¡c mÃ´ hÃ¬nh encoder Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c hiá»‡n cÃ³ trong quÃ¡ trÃ¬nh
fine-tuning Ä‘á»ƒ cáº£i thiá»‡n káº¿t quáº£ hoáº·c Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ cáº¡nh tranh vá»›i
viá»‡c sá»­ dá»¥ng nguá»“n lá»±c giáº£m trong phÃ¢n loáº¡i mÃ£. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡
thá»±c nghiá»‡m EarlyBIRD trÃªn CodeBERT [ 14], má»™t mÃ´ hÃ¬nh encoder
phá»• biáº¿n Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c cho mÃ£, vÃ  bá»‘n táº­p dá»¯ liá»‡u chuáº©n
bao gá»“m ba nhiá»‡m vá»¥ SE phá»• biáº¿n: phÃ¡t hiá»‡n lá»—i vá»›i cÃ¡c táº­p dá»¯ liá»‡u
Devign vÃ  ReVeal [ 20,51], suy luáº­n kiá»ƒu lá»—i vá»›i dá»¯ liá»‡u tá»« Yasunaga
et al. [ 47], vÃ  phÃ¢n loáº¡i kiá»ƒu ngoáº¡i lá»‡ [ 7]. Viá»‡c Ä‘Ã¡nh giÃ¡ so sÃ¡nh
biá»ƒu diá»…n cÆ¡ sá»Ÿ sá»­ dá»¥ng lá»›p encoder cuá»‘i cÃ¹ng vá»›i káº¿t quáº£ thu Ä‘Æ°á»£c
qua EarlyBIRD. ChÃºng tÃ´i cáº£ fine-tune encoder toÃ n kÃ­ch thÆ°á»›c vÃ 
phiÃªn báº£n Ä‘Æ°á»£c cáº¯t tá»‰a chá»‰ cÃ³ má»™t sá»‘ lá»›p Ä‘áº§u trong mÃ´ hÃ¬nh. Ká»‹ch báº£n
sau phÃ¢n tÃ­ch sá»± Ä‘Ã¡nh Ä‘á»•i giá»¯a viá»‡c chá»‰ sá»­ dá»¥ng mÃ´ hÃ¬nh má»™t pháº§n vÃ 
tÃ¡c Ä‘á»™ng hiá»‡u suáº¥t lÃªn cÃ¡c nhiá»‡m vá»¥ SE.

ÄÃ³ng gÃ³p: Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i Ä‘Æ°a ra cÃ¡c Ä‘Ã³ng gÃ³p sau:
(1) ChÃºng tÃ´i Ä‘á» xuáº¥t EarlyBIRD, má»™t phÆ°Æ¡ng phÃ¡p táº¡o biá»ƒu diá»…n tá»•ng há»£p
cá»§a mÃ£ sá»­ dá»¥ng cÃ¡c lá»›p Ä‘áº§u cá»§a mÃ´ hÃ¬nh encoder dá»±a trÃªn transformer.
Má»¥c tiÃªu lÃ  Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t phÃ¢n loáº¡i mÃ£ tá»‘t hÆ¡n vá»›i viá»‡c sá»­ dá»¥ng
nguá»“n lá»±c báº±ng nhau hoáº·c hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i viá»‡c sá»­ dá»¥ng
nguá»“n lá»±c tháº¥p hÆ¡n.

(2) ChÃºng tÃ´i thá»±c hiá»‡n Ä‘Ã¡nh giÃ¡ thá»±c nghiá»‡m toÃ n diá»‡n vá» phÆ°Æ¡ng phÃ¡p
Ä‘Æ°á»£c Ä‘á» xuáº¥t. ChÃºng tÃ´i chá»‰ ra tÃ¡c Ä‘á»™ng cá»§a viá»‡c sá»­ dá»¥ng cÃ¡c biá»ƒu diá»…n
EarlyBIRD tá»•ng há»£p trong khi fine-tuning mÃ´ hÃ¬nh CodeBERT kÃ­ch thÆ°á»›c
ban Ä‘áº§u trÃªn bá»‘n táº­p dá»¯ liá»‡u phÃ¢n loáº¡i mÃ£ thá»±c táº¿. ChÃºng tÃ´i cháº¡y
EarlyBIRD vá»›i 10 khá»Ÿi táº¡o ngáº«u nhiÃªn khÃ¡c nhau cá»§a cÃ¡c tham sá»‘ cÃ³ thá»ƒ
huáº¥n luyá»‡n khÃ´ng cá»‘ Ä‘á»‹nh vÃ  Ä‘Ã¡nh dáº¥u cÃ¡c biá»ƒu diá»…n EarlyBIRD mang láº¡i
cáº£i thiá»‡n cÃ³ Ã½ nghÄ©a thá»‘ng kÃª so vá»›i cÆ¡ sá»Ÿ.

(3) ChÃºng tÃ´i nghiÃªn cá»©u viá»‡c sá»­ dá»¥ng nguá»“n lá»±c vÃ  hiá»‡u suáº¥t cá»§a cÃ¡c
mÃ´ hÃ¬nh Ä‘Æ°á»£c cáº¯t tá»‰a. ChÃºng tÃ´i phÃ¢n tÃ­ch sá»± Ä‘Ã¡nh Ä‘á»•i giá»¯a viá»‡c loáº¡i bá»
cÃ¡c lá»›p sau cá»§a mÃ´ hÃ¬nh vÃ  tÃ¡c Ä‘á»™ng nÃ y lÃªn hiá»‡u suáº¥t phÃ¢n loáº¡i.

PhÃ¡t hiá»‡n chÃ­nh: Vá»›i EarlyBIRD, chÃºng tÃ´i Ä‘áº¡t Ä‘Æ°á»£c cáº£i thiá»‡n hiá»‡u suáº¥t
so vá»›i biá»ƒu diá»…n mÃ£ cÆ¡ sá»Ÿ vá»›i pháº§n lá»›n cÃ¡c biá»ƒu diá»…n thu Ä‘Æ°á»£c tá»« cÃ¡c
lá»›p Ä‘áº§u Ä‘Æ¡n láº» trÃªn nhiá»‡m vá»¥ phÃ¡t hiá»‡n lá»—i vÃ  cÃ¡c káº¿t há»£p Ä‘Æ°á»£c chá»n
trÃªn phÃ¢n loáº¡i kiá»ƒu lá»—i vÃ  kiá»ƒu ngoáº¡i lá»‡. HÆ¡n ná»¯a, trong sá»‘ cÃ¡c mÃ´ hÃ¬nh
kÃ­ch thÆ°á»›c giáº£m vá»›i cÃ¡c lá»›p sau Ä‘Æ°á»£c cáº¯t tá»‰a, chÃºng tÃ´i Ä‘áº¡t Ä‘Æ°á»£c cáº£i thiá»‡n
Ä‘á»™ chÃ­nh xÃ¡c trung bÃ¬nh +2 trÃªn Devign vá»›i tÄƒng tá»‘c fine-tuning 3.3x,
cÅ©ng nhÆ° cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c +0.4 vá»›i tÄƒng tá»‘c 3.7x trung bÃ¬nh cho ReVeal.

Pháº§n cÃ²n láº¡i cá»§a bÃ i bÃ¡o Ä‘Æ°á»£c tá»• chá»©c nhÆ° sau. ChÃºng tÃ´i trÃ¬nh bÃ y
cÃ´ng trÃ¬nh liÃªn quan trong Má»¥c 2 vÃ  cung cáº¥p chi tiáº¿t ná»n táº£ng cá»§a
nghiÃªn cá»©u trong Má»¥c 3. PhÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c mÃ´ táº£ trong Má»¥c 4 theo
sau bá»Ÿi thiáº¿t láº­p thá»±c nghiá»‡m trong Má»¥c 5. ChÃºng tÃ´i trÃ¬nh bÃ y vÃ 
tháº£o luáº­n káº¿t quáº£ trong Má»¥c 6 vÃ  káº¿t luáº­n vá»›i Má»¥c 7.

2 CÃ”NG TRÃŒNH LIÃŠN QUAN
á» Ä‘Ã¢y, chÃºng tÃ´i Ä‘Æ°a ra tá»•ng quan vá» cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ cho cÃ¡c
nhiá»‡m vá»¥ SE vÃ  cÃ¡c mÃ´ hÃ¬nh encoder gáº§n Ä‘Ã¢y, cá»¥ thá»ƒ, cÅ©ng nhÆ° cÃ¡c
phÆ°Æ¡ng phÃ¡p khÃ¡c nhau Ä‘á»ƒ sá»­ dá»¥ng cÃ¡c lá»›p Ä‘áº§u cá»§a mÃ´ hÃ¬nh encoder.

2.1 Transformer trong Ká»¹ Thuáº­t Pháº§n Má»m
TÃ­nh kháº£ dá»¥ng cá»§a mÃ£ nguá»“n má»Ÿ vÃ  kháº£ nÄƒng pháº§n cá»©ng tÄƒng lÃªn Ä‘Ã£
lÃ m phá»• biáº¿n viá»‡c huáº¥n luyá»‡n vÃ  sá»­ dá»¥ng Há»c SÃ¢u, bao gá»“m NLP vÃ 
MÃ´ HÃ¬nh NgÃ´n Ngá»¯ Lá»›n (LLM), cho cÃ¡c nhiá»‡m vá»¥ SE. Cho Ä‘áº¿n nay,
cÃ¡c mÃ´ hÃ¬nh NLP sÃ¢u Ä‘Ã£ Ä‘Æ°á»£c Ã¡p dá»¥ng trong Ã­t nháº¥t 18 nhiá»‡m vá»¥ SE [ 28].
CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c cÃ³ sáºµn Ä‘á»ƒ fine-tuning
trÃªn cÃ¡c nhiá»‡m vá»¥ SE pháº§n lá»›n Ä‘Æ°á»£c xÃ¢y dá»±ng trÃªn kiáº¿n trÃºc transformer,
cÃ¡c mÃ´ hÃ¬nh chuá»—i-tá»›i-chuá»—i, vÃ  cÆ¡ cháº¿ attention [ 8,9,42]. Má»™t chuáº©n
má»±c Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ kiá»ƒm tra cÃ¡c kiáº¿n trÃºc há»c sÃ¢u khÃ¡c nhau
trÃªn cÃ¡c nhiá»‡m vá»¥ SE lÃ  CodeXGLUE [ 27]. Chuáº©n má»±c nÃ y cung cáº¥p
dá»¯ liá»‡u, mÃ£ nguá»“n Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh, vÃ  báº£ng xáº¿p háº¡ng hiá»‡u suáº¥t
mÃ´ hÃ¬nh trÃªn cÃ¡c nhiá»‡m vá»¥ khÃ¡c nhau [27].

CÃ¡c nhiá»‡m vá»¥ SE cÃ³ thá»ƒ Ä‘Æ°á»£c dá»‹ch thÃ nh phÃ¢n loáº¡i chuá»—i Ä‘áº§u vÃ o vÃ 
táº¡o mÃ£ hoáº·c vÄƒn báº£n. VÃ­ dá»¥ vá» cÃ¡c nhiá»‡m vá»¥ táº¡o sinh trong SE lÃ 
hoÃ n thÃ nh mÃ£, sá»­a chá»¯a mÃ£, táº¡o tÃ i liá»‡u tá»« mÃ£ vÃ  ngÆ°á»£c láº¡i, vÃ 
dá»‹ch giá»¯a cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh khÃ¡c nhau. Nhá»¯ng nhiá»‡m vá»¥ nhÆ° váº­y
thÆ°á»ng Ä‘Æ°á»£c tiáº¿p cáº­n báº±ng cÃ¡c mÃ´ hÃ¬nh dá»‹ch mÃ¡y nÆ¡-ron. CÃ¡c mÃ´ hÃ¬nh
transformer Ä‘áº§y Ä‘á»§ Ä‘á»ƒ dá»‹ch tá»« ngÃ´n ngá»¯ láº­p trÃ¬nh (PL) sang ngÃ´n ngá»¯
tá»± nhiÃªn (NL) hoáº·c cÃ¡c nhiá»‡m vá»¥ PL-PL bao gá»“m PLBART [ 1], PYMT5 [ 10],
TFix [ 4], CodeT5 [ 43], Break-It-Fix-It [ 47]. Thay vÃ o Ä‘Ã³, cÃ¡c mÃ´ hÃ¬nh
táº¡o sinh cÃ³ thá»ƒ bao gá»“m pháº§n chá»‰ decoder cá»§a transformer nhÆ° trong
cÃ¡c mÃ´ hÃ¬nh kiá»ƒu GPT. Trong trÆ°á»ng há»£p nÃ y, decoder vá»«a biá»ƒu diá»…n
chuá»—i Ä‘áº§u vÃ o vá»«a chuyá»ƒn Ä‘á»•i nÃ³ thÃ nh chuá»—i Ä‘áº§u ra. CÃ¡c mÃ´ hÃ¬nh
dá»±a trÃªn decoder cho mÃ£ bao gá»“m, vÃ­ dá»¥, Codex vÃ  CodeGPT [8, 27].

Trong cÃ¡c nhiá»‡m vá»¥ yÃªu cáº§u biá»ƒu diá»…n mÃ£ hoáº·c tÃ i liá»‡u vÃ  phÃ¢n loáº¡i
tiáº¿p theo cá»§a chÃºng, cÃ¡c kiáº¿n trÃºc chá»‰ encoder Ä‘Æ°á»£c sá»­ dá»¥ng thÆ°á»ng
xuyÃªn hÆ¡n so vá»›i trong cÃ¡c nhiá»‡m vá»¥ dá»‹ch. VÃ­ dá»¥ vá» cÃ¡c bÃ i toÃ¡n phÃ¢n
loáº¡i mÃ£ lÃ  phÃ¡t hiá»‡n báº£n sao mÃ£, phÃ¡t hiá»‡n lá»—i chung, nhÆ° sá»± hiá»‡n diá»‡n
cá»§a toÃ¡n tá»­ bá»‹ hoÃ¡n Ä‘á»•i, tÃªn biáº¿n sai, lá»—i cÃº phÃ¡p, hoáº·c lá»— há»•ng báº£o máº­t.
Má»™t sá»‘ mÃ´ hÃ¬nh encoder cho mÃ£ Ä‘Ã£ Ã¡p dá»¥ng encoder hai chiá»u Ä‘Æ°á»£c
sá»­ dá»¥ng rá»™ng rÃ£i, BERT [ 12], Ä‘á»ƒ huáº¥n luyá»‡n trÆ°á»›c nÃ³ trÃªn mÃ£, vá»›i
má»™t sá»‘ sá»­a Ä‘á»•i Ä‘áº§u vÃ o. Theo cÃ¡ch nÃ y, cÃ¡c mÃ´ hÃ¬nh CodeBERT [ 14],
GraphCodeBERT [ 16], CuBERT [ 20], vÃ  PolyglotCodeBERT [ 2] Ä‘Ã£ Ä‘Æ°á»£c
táº¡o ra.

Chi tiáº¿t, mÃ´ hÃ¬nh CodeBERT 12 lá»›p dá»±a trÃªn RoBERTa Ä‘Ã£ Ä‘Æ°á»£c huáº¥n
luyá»‡n trÆ°á»›c trÃªn cÃ¡c nhiá»‡m vá»¥ NL-PL báº±ng nhiá»u PL vÃ  chá»‰ sá»­ dá»¥ng
cÃ¡c Ä‘áº·c trÆ°ng vÄƒn báº£n cá»§a mÃ£. LÆ°u Ã½ ráº±ng RoBERTa lÃ  má»™t loáº¡i mÃ´ hÃ¬nh
BERT vá»›i cÃ¡c siÃªu tham sá»‘ tá»‘i Æ°u hÃ³a vÃ  quy trÃ¬nh huáº¥n luyá»‡n trÆ°á»›c [ 26].
CÃ¹ng vá»›i mÃ´ hÃ¬nh CodeGPT chá»‰ decoder, mÃ´ hÃ¬nh CodeBERT chá»‰ encoder
Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m cÆ¡ sá»Ÿ trong CodeXGLUE. GraphCodeBERT sá»­ dá»¥ng
cáº£ thuá»™c tÃ­nh vÄƒn báº£n vÃ  cáº¥u trÃºc cá»§a mÃ£ Ä‘á»ƒ mÃ£ hÃ³a cÃ¡c biá»ƒu diá»…n
cá»§a nÃ³. PolyglotCodeBERT lÃ  phÆ°Æ¡ng phÃ¡p cáº£i thiá»‡n fine-tuning cá»§a
mÃ´ hÃ¬nh CodeBERT trÃªn táº­p dá»¯ liá»‡u Ä‘a ngÃ´n ngá»¯ cho nhiá»‡m vá»¥ Ä‘Ã­ch
ngay cáº£ khi nhiá»‡m vá»¥ Ä‘Ã­ch chá»‰ kiá»ƒm tra má»™t PL.

BÃ i bÃ¡o nÃ y táº­p trung vÃ o cÃ¡c chiáº¿n lÆ°á»£c fine-tuning mÃ , trÃ¡i ngÆ°á»£c
vá»›i PolyglotCodeBERT, khÃ´ng tÄƒng viá»‡c sá»­ dá»¥ng nguá»“n lá»±c cho
fine-tuning. CuBERT lÃ  má»™t encoder 24 lá»›p dá»±a trÃªn transformer
Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c vÃ  Ä‘Æ°á»£c kiá»ƒm tra trÃªn má»™t sá»‘ nhiá»‡m vá»¥ phÃ¢n
loáº¡i mÃ£, bao gá»“m phÃ¢n loáº¡i kiá»ƒu ngoáº¡i lá»‡. ChÃºng tÃ´i kiá»ƒm tra hiá»‡u
suáº¥t cá»§a cÃ¡c biá»ƒu diá»…n tá»•ng há»£p EarlyBIRD Ä‘Æ°á»£c Ä‘á» xuáº¥t trÃªn phÃ¡t
hiá»‡n lá»—i, bao gá»“m viá»‡c sá»­ dá»¥ng má»™t trong cÃ¡c chuáº©n má»±c CodeXGLUE,
cÅ©ng nhÆ° trÃªn cÃ¡c nhiá»‡m vá»¥ phÃ¢n loáº¡i kiá»ƒu lá»—i vÃ  ngoáº¡i lá»‡. Tuy nhiÃªn,
má»¥c tiÃªu cá»§a bÃ i bÃ¡o nÃ y lÃ  Ä‘áº¡t Ä‘Æ°á»£c cáº£i thiá»‡n so vá»›i mÃ´ hÃ¬nh cÆ¡ sá»Ÿ
khi nÃ³ Ä‘Æ°á»£c fine-tuning vá»›i cÃ¡c biá»ƒu diá»…n mÃ£ tá»•ng há»£p. ChÃºng tÃ´i
khÃ´ng nháº±m so sÃ¡nh káº¿t quáº£ vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c, mÃ  Ä‘Æ°a ra má»™t
phÆ°Æ¡ng phÃ¡p Ã¡p dá»¥ng Ä‘Æ°á»£c cho cÃ¡c encoder dá»±a trÃªn transformer
cho mÃ£ nguá»“n vÃ  chá»‰ ra cÃ¡c cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a nÃ³ so vá»›i viá»‡c
sá»­ dá»¥ng mÃ´ hÃ¬nh tÆ°Æ¡ng tá»± mÃ  khÃ´ng cÃ³ phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c Ä‘á» xuáº¥t.

2.2 Sá»­ Dá»¥ng CÃ¡c Lá»›p Encoder Äáº§u
Má»™t sá»‘ nghiÃªn cá»©u Ä‘Ã£ khÃ¡m phÃ¡ cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhau Ä‘á»ƒ sá»­ dá»¥ng
thÃ´ng tin tá»« cÃ¡c lá»›p Ä‘áº§u cá»§a mÃ´ hÃ¬nh DL Ä‘á»ƒ biá»ƒu diá»…n chuá»—i, nhÆ°
thÄƒm dÃ² cÃ¡c lá»›p Ä‘Æ¡n láº», cáº¯t tá»‰a vÃ  tá»· lá»‡ há»c táº­p biáº¿n Ä‘á»•i.

Má»™t cÃ¡ch Ä‘á»ƒ táº­n dá»¥ng thÃ´ng tin tá»« cÃ¡c lá»›p Ä‘áº§u cá»§a mÃ´ hÃ¬nh lÃ  Æ°u tiÃªn
khÃ¡c nhau cho cÃ¡c lá»›p trong khi fine-tuning cÃ¡c mÃ´ hÃ¬nh [ 19,39].

--- TRANG 2 ---
ESEC/FSE '23, 3â€“9 thÃ¡ng 12, 2023, San Francisco, CA, USA Anastasiia Grishina, Max Hort, vÃ  Leon Moonen

VÃ­ dá»¥, chiáº¿n lÆ°á»£c suy giáº£m tá»· lá»‡ há»c táº­p theo lá»›p (LLRD) vÃ  khá»Ÿi táº¡o
láº¡i cÃ¡c lá»›p encoder muá»™n Ä‘Ã£ mang láº¡i cáº£i thiá»‡n so vá»›i fine-tuning
tiÃªu chuáº©n cá»§a BERT trÃªn cÃ¡c nhiá»‡m vá»¥ NLP [ 49]. Chiáº¿n lÆ°á»£c LLRD
ban Ä‘áº§u Ä‘Æ°á»£c phÃ¡t triá»ƒn Ä‘á»ƒ Ä‘iá»u chá»‰nh cÃ¡c lá»›p encoder sau vá»›i tá»· lá»‡
há»c táº­p lá»›n hÆ¡n. Theo cÃ¡ch nÃ y, cÃ¡c lá»›p sau cÃ³ thá»ƒ Ä‘Æ°á»£c thÃ­ch á»©ng
tá»‘t hÆ¡n vá»›i nhiá»‡m vá»¥ xuÃ´i dÃ²ng Ä‘ang xem xÃ©t, vÃ¬ cÃ¡c lá»›p sau Ä‘Æ°á»£c
giáº£ Ä‘á»‹nh há»c cÃ¡c Ä‘áº·c trÆ°ng phá»©c táº¡p cá»¥ thá»ƒ cho nhiá»‡m vá»¥ cá»§a chuá»—i
Ä‘áº§u vÃ o [ 19]. HÆ¡n ná»¯a, Peters et al. [ 33] Ä‘Ã£ chá»‰ ra ráº±ng hiá»‡u suáº¥t
cá»§a fine-tuning cáº£i thiá»‡n náº¿u cÃ¡c lá»›p encoder Ä‘Æ°á»£c cáº­p nháº­t trong
quÃ¡ trÃ¬nh fine-tuning so vá»›i chá»‰ huáº¥n luyá»‡n bá»™ phÃ¢n loáº¡i trÃªn cÃ¡c
lá»›p encoder cá»‘ Ä‘á»‹nh (Ä‘Ã³ng bÄƒng).

Cáº¯t tá»‰a cÃ¡c lá»›p sau cá»§a mÃ´ hÃ¬nh transformer lÃ  má»™t cÃ¡ch khÃ¡c Ä‘á»ƒ
chá»‰ xem xÃ©t cÃ¡c lá»›p Ä‘áº§u Ä‘á»ƒ fine-tuning [ 13,31,36]. Sajjad et al.
[36] Ä‘Ã£ nghiÃªn cá»©u cÃ¡ch hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh transformer trÃªn
NLP bá»‹ áº£nh hÆ°á»Ÿng khi giáº£m kÃ­ch thÆ°á»›c báº±ng cÃ¡ch cáº¯t tá»‰a cÃ¡c lá»›p.
Há» Ä‘Ã£ xem xÃ©t sÃ¡u chiáº¿n lÆ°á»£c cáº¯t tá»‰a, bao gá»“m loáº¡i bá» tá»« cÃ¡c hÆ°á»›ng
khÃ¡c nhau, loáº¡i bá» lá»›p xen káº½, hoáº·c loáº¡i bá» lá»›p dá»±a trÃªn táº§m quan
trá»ng, cho bá»‘n mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c: BERT [ 12], RoBERTa [ 26],
XLNET [ 46], ALBERT [ 22]. Báº±ng cÃ¡ch cáº¯t tá»‰a cÃ¡c lá»›p mÃ´ hÃ¬nh, Sajjad
et al. Ä‘Ã£ cÃ³ thá»ƒ giáº£m sá»‘ lÆ°á»£ng tham sá»‘ xuá»‘ng 60% cá»§a táº­p tham sá»‘
ban Ä‘áº§u trong khi duy trÃ¬ má»©c hiá»‡u suáº¥t cao. Trong khi hiá»‡u suáº¥t
trÃªn cÃ¡c nhiá»‡m vá»¥ xuÃ´i dÃ²ng khÃ¡c nhau trong nghiÃªn cá»©u cá»§a há»,
cÃ¡c lá»›p dÆ°á»›i lÃ  quan trá»ng Ä‘á»ƒ duy trÃ¬ hiá»‡u suáº¥t khi fine-tuning cho
cÃ¡c nhiá»‡m vá»¥ xuÃ´i dÃ²ng. NÃ³i cÃ¡ch khÃ¡c, loáº¡i bá» cÃ¡c lá»›p trÆ°á»›c cÃ³
háº¡i cho hiá»‡u suáº¥t. NhÃ¬n chung, cáº¯t tá»‰a lá»›p giáº£m kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh
vÃ  do Ä‘Ã³ giáº£m thá»i gian fine-tuning vÃ  suy luáº­n. PhÃ¹ há»£p vá»›i cÃ´ng
trÃ¬nh cá»§a Sajjad et al. [ 36], chÃºng tÃ´i má»Ÿ rá»™ng cÃ¡c thÃ­ nghiá»‡m vá»›i
viá»‡c cáº¯t tá»‰a cÃ¡c lá»›p sau vÃ  giá»¯ láº¡i cÃ¡c lá»›p trÆ°á»›c trong mÃ´ hÃ¬nh
(xem RQ2 trong Má»¥c 6).

Viá»‡c sá»­ dá»¥ng thÃ´ng tin tá»« cÃ¡c lá»›p Ä‘áº§u Ä‘Æ¡n láº» trong má»™t sá»‘ thÃ­
nghiá»‡m EarlyBIRD cÅ©ng Ä‘Æ°á»£c láº¥y cáº£m há»©ng tá»« Peters et al. [ 32].
Trong nghiÃªn cá»©u cá»§a há», Peters et al. Ä‘Æ°a ra báº±ng chá»©ng thá»±c nghiá»‡m
ráº±ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ há»c cÃº phÃ¡p vÃ  thÃ´ng tin tá»« loáº¡i trÃªn
cÃ¡c lá»›p trÆ°á»›c cá»§a máº¡ng nÆ¡-ron, trong khi thÃ´ng tin phá»©c táº¡p hÆ¡n,
nhÆ° ngá»¯ nghÄ©a vÃ  má»‘i quan há»‡ Ä‘á»“ng tham chiáº¿u, Ä‘Æ°á»£c náº¯m báº¯t tá»‘t
hÆ¡n bá»Ÿi cÃ¡c lá»›p sÃ¢u hÆ¡n (sau). Trong má»™t nghiÃªn cá»©u khÃ¡c, Karmakar
vÃ  Robbes Ä‘Ã£ thÄƒm dÃ² cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c cá»§a mÃ£,
bao gá»“m CodeBERT, trÃªn cÃ¡c nhiá»‡m vá»¥ hiá»ƒu thÃ´ng tin cÃº phÃ¡p, Ä‘á»™
phá»©c táº¡p cáº¥u trÃºc, Ä‘á»™ dÃ i mÃ£, vÃ  thÃ´ng tin ngá»¯ nghÄ©a [ 21]. Trong
khi Karmakar vÃ  Robbes Ä‘Ã£ thÄƒm dÃ² cÃ¡c lá»›p Ä‘áº§u Ä‘Ã³ng bÄƒng cá»§a
cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau cho mÃ£ trong má»™t chiáº¿n lÆ°á»£c Ä‘Æ¡n láº», chÃºng
tÃ´i sá»­ dá»¥ng 12 chiáº¿n lÆ°á»£c khÃ¡c nhau Ä‘á»ƒ káº¿t há»£p cÃ¡c lá»›p Ä‘áº§u khÃ´ng
Ä‘Ã³ng bÄƒng trong quÃ¡ trÃ¬nh fine-tuning vÃ  táº­p trung vÃ o cÃ¡c nhiá»‡m vá»¥
phÃ¡t hiá»‡n lá»—i hoáº·c phÃ¢n loáº¡i kiá»ƒu lá»—i. TÆ°Æ¡ng tá»±, HernÃ¡ndez LÃ³pez
et al. [ 18] Ä‘Ã£ thÄƒm dÃ² cÃ¡c lá»›p khÃ¡c nhau cá»§a nÄƒm mÃ´ hÃ¬nh Ä‘Æ°á»£c
huáº¥n luyá»‡n trÆ°á»›c, bao gá»“m CodeBERT [ 14] vÃ  GraphCodeBERT [ 16],
vÃ  phÃ¡t hiá»‡n ráº±ng háº§u háº¿t thÃ´ng tin cÃº phÃ¡p Ä‘Æ°á»£c mÃ£ hÃ³a trong cÃ¡c
lá»›p giá»¯a. Äiá»ƒm má»›i cá»§a nghiÃªn cá»©u chÃºng tÃ´i so vá»›i Karmakar vÃ 
Robbes lÃ  chÃºng tÃ´i káº¿t há»£p cÃ¡c lá»›p Ä‘áº§u ngoÃ i viá»‡c trÃ­ch xuáº¥t tá»«ng
lá»›p, trong khi Karmakar vÃ  Robbes Ä‘Ã£ trÃ­ch xuáº¥t cÃ¡c biá»ƒu diá»…n lá»›p
Ä‘áº§u vÃ  sá»­ dá»¥ng chÃºng mÃ  khÃ´ng táº¡o ra cÃ¡c biá»ƒu diá»…n má»›i.

3 ENCODER CHO PHÃ‚N LOáº I MÃƒ
Trong pháº§n nÃ y, chÃºng tÃ´i trÃ¬nh bÃ y ná»n táº£ng vá» mÃ´ hÃ¬nh transformer
vÃ  cÃ¡c cÃ¡ch sá»­ dá»¥ng khÃ¡c nhau cá»§a kiáº¿n trÃºc encoder-decoderâ€”hoáº·c
transformer Ä‘áº§y Ä‘á»§â€”cÅ©ng nhÆ° cÃ¡c biáº¿n thá»ƒ chá»‰ encoder vÃ  chá»‰ decoder
cá»§a nÃ³. VÃ¬ nghiÃªn cá»©u cá»§a chÃºng tÃ´i táº­p trung vÃ o cÃ¡c mÃ´ hÃ¬nh nguá»“n
má»Ÿ chá»‰ encoder cÃ³ sáºµn Ä‘á»ƒ fine-tuning, sá»± phÃ¢n biá»‡t giá»¯a cÃ¡c loáº¡i
transformer lÃ  cáº§n thiáº¿t Ä‘á»ƒ hiá»ƒu phÆ°Æ¡ng phÃ¡p.

Trong cÃ¡c ká»‹ch báº£n táº¡o sinh chuá»—i-tá»›i-chuá»—i, mÃ´ hÃ¬nh transformer
bao gá»“m má»™t encoder Ä‘a lá»›p biá»ƒu diá»…n chuá»—i Ä‘áº§u vÃ o vÃ  má»™t decoder
táº¡o ra chuá»—i Ä‘áº§u ra dá»±a trÃªn biá»ƒu diá»…n chuá»—i tá»« encoder vÃ  Ä‘áº§u ra
cÃ³ sáºµn Ä‘Æ°á»£c táº¡o ra á»Ÿ cÃ¡c bÆ°á»›c trÆ°á»›c [ 42]. Äá»‘i vá»›i cÃ¡c nhiá»‡m vá»¥ phÃ¢n
loáº¡i mÃ£ nguá»“n, transformer thÆ°á»ng Ä‘Æ°á»£c giáº£m chá»‰ cÃ²n encoder cá»§a
nÃ³ theo sau bá»Ÿi má»™t Ä‘áº§u phÃ¢n loáº¡i, má»™t thÃ nh pháº§n Ä‘Æ°á»£c thÃªm vÃ o
encoder Ä‘á»ƒ phÃ¢n loáº¡i biá»ƒu diá»…n thÃ nh cÃ¡c lá»›p khÃ¡c nhau. Viá»‡c bá»
decoder cho phÃ¢n loáº¡i Ä‘Æ°á»£c thÃºc Ä‘áº©y bá»Ÿi hiá»‡u quáº£ nguá»“n lá»±c, vÃ¬
decoder vá» máº·t khÃ¡i niá»‡m chá»‰ cáº§n thiáº¿t Ä‘á»ƒ táº¡o token tá»« chuá»—i Ä‘áº§u vÃ o.
Trong quÃ¡ trÃ¬nh phÃ¢n loáº¡i má»™t Ä‘áº§u vÃ o, encoder biá»ƒu diá»…n chuá»—i vÃ 
chuyá»ƒn nÃ³ Ä‘áº¿n Ä‘áº§u phÃ¢n loáº¡i. Dá»±a trÃªn thiáº¿t káº¿ nÃ y, má»™t sá»‘ encoder
Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c Ä‘Ã£ Ä‘Æ°á»£c cÃ´ng bá»‘ trong nhá»¯ng nÄƒm gáº§n Ä‘Ã¢y,
nhÆ° BERT vÃ  RoBERTa Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c trÃªn ngÃ´n ngá»¯ tá»± nhiÃªn,
vÃ  cÃ¡c mÃ´ hÃ¬nh tÆ°Æ¡ng tá»± Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c trÃªn mÃ£, hoáº·c káº¿t há»£p
mÃ£ vÃ  ngÃ´n ngá»¯ tá»± nhiÃªn [ 12,26]. Má»¥c tiÃªu cá»§a huáº¥n luyá»‡n trÆ°á»›c
trong ká»‹ch báº£n huáº¥n luyá»‡n trÆ°á»›c vÃ  fine-tune lÃ  náº¯m báº¯t cÃ¡c máº«u
ngÃ´n ngá»¯ nÃ³i chung, Ä‘á»ƒ chÃºng cÃ³ thá»ƒ phá»¥c vá»¥ nhÆ° ná»n táº£ng cho
cÃ¡c nhiá»‡m vá»¥ xuÃ´i dÃ²ng cá»¥ thá»ƒ miá»n. CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n
trÆ°á»›c cÃ³ thá»ƒ Ä‘Æ°á»£c fine-tuning trÃªn cÃ¡c nhiá»‡m vá»¥ xuÃ´i dÃ²ng khÃ¡c nhau
trong NLP vÃ  SE.

Xá»­ lÃ½ chuá»—i Ä‘áº§u vÃ o Ä‘á»ƒ phÃ¢n loáº¡i bao gá»“m má»™t sá»‘ bÆ°á»›c: tokenization,
embedding ban Ä‘áº§u, mÃ£ hÃ³a chuá»—i vá»›i encoder, vÃ  chuyá»ƒn biá»ƒu diá»…n
chuá»—i qua má»™t Ä‘áº§u phÃ¢n loáº¡i. Tokenization chia chuá»—i Ä‘áº§u vÃ o, thÃªm
cÃ¡c token Ä‘áº·c biá»‡t, khá»›p cÃ¡c token vá»›i ID cá»§a chÃºng trong tá»« vá»±ng
cÃ¡c token, vÃ  thá»‘ng nháº¥t Ä‘á»™ dÃ i token káº¿t quáº£ cho cÃ¡c máº«u trong
táº­p dá»¯ liá»‡u. Embedding chuyá»ƒn Ä‘á»•i ID token má»™t chiá»u thÃ nh biá»ƒu
diá»…n vector tÄ©nh Ä‘a chiá»u ban Ä‘áº§u cá»§a token vÃ  thÆ°á»ng lÃ  má»™t pháº§n
cá»§a mÃ´ hÃ¬nh encoder Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c. Biá»ƒu diá»…n nÃ y Ä‘Æ°á»£c
cáº­p nháº­t sá»­ dá»¥ng cÆ¡ cháº¿ attention cá»§a encoder. VÃ¬ attention, biá»ƒu
diá»…n cá»§a Ä‘áº§u vÃ o bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi táº¥t cáº£ cÃ¡c token trong chuá»—i,
vÃ¬ váº­y nÃ³ Ä‘Æ°á»£c ngá»¯ cáº£nh hÃ³a.

CodeBERT lÃ  má»™t mÃ´ hÃ¬nh dá»±a trÃªn RoBERTa vá»›i 12 lá»›p encoder Ä‘Æ°á»£c
huáº¥n luyá»‡n trÆ°á»›c trÃªn 6 ngÃ´n ngá»¯ láº­p trÃ¬nh (Python, Java, JavaScript,
PHP, Ruby, vÃ  Go), cÅ©ng nhÆ° cÃ¡c nhiá»‡m vá»¥ text-to-code [ 14]. Huáº¥n
luyá»‡n trÆ°á»›c Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn cÃ¡c nhiá»‡m vá»¥ mÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯
cÃ³ máº·t náº¡ (MLM) vÃ  phÃ¡t hiá»‡n token Ä‘Æ°á»£c thay tháº¿ (RTD). Nhá»¯ng
nhiá»‡m vá»¥ nÃ y tÆ°Æ¡ng á»©ng huáº¥n luyá»‡n mÃ´ hÃ¬nh Ä‘á»ƒ suy ra token nÃ o
bá»‹ che dáº¥u trong MLM, vÃ  trong RTD dá»± Ä‘oÃ¡n liá»‡u cÃ³ token nÃ o
trong chuá»—i gá»‘c bá»‹ hoÃ¡n Ä‘á»•i vá»›i token khÃ¡c khÃ´ng nÃªn cÃ³ trong
chuá»—i. CodeBERT xuáº¥t ra biá»ƒu diá»…n encoder hai chiá»u cá»§a chuá»—i
Ä‘áº§u vÃ o, cÃ³ nghÄ©a lÃ  mÃ´ hÃ¬nh xem xÃ©t ngá»¯ cáº£nh tá»« cÃ¡c tá»« Ä‘i trÆ°á»›c
vÃ  theo sau Ä‘á»ƒ biá»ƒu diá»…n má»—i token trong chuá»—i Ä‘áº§u vÃ o.

Má»™t mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c thÆ°á»ng Ä‘Æ°á»£c phÃ¡t hÃ nh vá»›i
má»™t tokenizer Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c. Tokenizer Ä‘Æ°á»£c huáº¥n luyá»‡n
trÆ°á»›c Ä‘áº£m báº£o ráº±ng ID token tÆ°Æ¡ng á»©ng vá»›i nhá»¯ng cÃ¡i Ä‘Æ°á»£c xá»­ lÃ½
trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n trÆ°á»›c. Tokenizer cÅ©ng thÃªm cÃ¡c token
Ä‘áº·c biá»‡t, nhÆ° token CLS á»Ÿ Ä‘áº§u má»—i chuá»—i Ä‘áº§u vÃ o, cÃ¡c token PAD
Ä‘á»ƒ thá»‘ng nháº¥t Ä‘á»™ dÃ i cá»§a chuá»—i Ä‘áº§u vÃ o, vÃ  token EOS Ä‘á»ƒ biá»ƒu thá»‹
káº¿t thÃºc chuá»—i Ä‘áº§u vÃ o vÃ  báº¯t Ä‘áº§u cá»§a chuá»—i padding [ 12]. Táº¥t cáº£
cÃ¡c token Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i bá»Ÿi mÃ´ hÃ¬nh trong má»—i lá»›p encoder.
Trong sá»‘ táº¥t cáº£ cÃ¡c token, biá»ƒu diá»…n token CLS tá»« lá»›p cuá»‘i cÃ¹ng,
Ä‘Æ°á»£c cáº­p nháº­t bá»Ÿi táº¥t cáº£ cÃ¡c lá»›p encoder, thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng
lÃ m biá»ƒu diá»…n cho toÃ n bá»™ chuá»—i.

--- TRANG 3 ---
EarlyBIRD Báº¯t ÄÆ°á»£c Lá»—i: Vá» Viá»‡c Khai ThÃ¡c CÃ¡c Lá»›p Äáº§u cá»§a MÃ´ HÃ¬nh Encoder. . . ESEC/FSE '23, 3â€“9 thÃ¡ng 12, 2023, San Francisco, CA, USA

Thá»±c hÃ nh tiÃªu chuáº©n sá»­ dá»¥ng token CLS tá»« lá»›p encoder cuá»‘i cÃ¹ng
Ä‘Æ°á»£c thÃºc Ä‘áº©y bá»Ÿi quy trÃ¬nh huáº¥n luyá»‡n trÆ°á»›c. VÃ­ dá»¥, trong MLM,
mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n token bá»‹ che dáº¥u dá»±a trÃªn biá»ƒu diá»…n token CLS
tá»« lá»›p thá»© 12 cá»§a BERT vÃ  CodeBERT. Tuy nhiÃªn, viá»‡c chá»n token
Ä‘á»ƒ biá»ƒu diá»…n toÃ n bá»™ chuá»—i trong fine-tuning cÃ³ thá»ƒ khÃ¡c. VÃ­ dá»¥,
trong PLBART [ 1], má»™t mÃ´ hÃ¬nh transformer cho mÃ£ vá»›i cáº£ encoder
vÃ  decoder, token EOS Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ biá»ƒu diá»…n chuá»—i Ä‘áº§u vÃ o.
Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i Ä‘á» xuáº¥t cÃ¡c cÃ¡ch khÃ¡c nhau Ä‘á»ƒ biá»ƒu
diá»…n chuá»—i Ä‘áº§u vÃ o vÃ  sá»­ dá»¥ng thÃ´ng tin tá»« cÃ¡c lá»›p Ä‘áº§u cá»§a mÃ´ hÃ¬nh
má»™t cÃ¡ch hiá»‡u quáº£.

4 PHÆ¯Æ NG PHÃP
Trong bÃ i bÃ¡o nÃ y, kiáº¿n trÃºc cá»§a mÃ´ hÃ¬nh phÃ¢n loáº¡i mÃ£ bao gá»“m
nÄƒm pháº§n: (1) má»™t tokenizer, (2) má»™t lá»›p embedding, (3) má»™t encoder
vá»›i má»™t sá»‘ lá»›p, (4) má»™t táº­p há»£p cÃ¡c phÃ©p toÃ¡n Ä‘á»ƒ káº¿t há»£p cÃ¡c biá»ƒu
diá»…n chuá»—i tá»« cÃ¡c lá»›p encoder vá»›i EarlyBIRD, vÃ  (5) má»™t Ä‘áº§u phÃ¢n
loáº¡i. Äáº§u ra cá»§a má»—i bÆ°á»›c Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m Ä‘áº§u vÃ o cho bÆ°á»›c tiáº¿p
theo. Tá»•ng quan vá» kiáº¿n trÃºc Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 1 vÃ  mÃ´ táº£
bÃªn dÆ°á»›i. Sá»± khÃ¡c biá»‡t chÃ­nh giá»¯a kiáº¿n trÃºc nÃ y vÃ  kiáº¿n trÃºc phÃ¢n
loáº¡i Ä‘Æ°á»£c tháº£o luáº­n trong Má»¥c 3 lÃ  bÆ°á»›c (4); kiáº¿n trÃºc tiÃªu chuáº©n
chá»‰ bao gá»“m cÃ¡c bÆ°á»›c (1â€“3) vÃ  (5).

CÃ¡c bÆ°á»›c (1)â€“(3) sá»­ dá»¥ng tokenizer, embedder, vÃ  encoder Ä‘Æ°á»£c
huáº¥n luyá»‡n trÆ°á»›c. EarlyBIRD Ä‘Æ°á»£c cÃ´ng thá»©c hÃ³a theo cÃ¡ch tá»•ng quÃ¡t
vÃ  cÃ³ thá»ƒ Ã¡p dá»¥ng cho báº¥t ká»³ encoder nÃ o, nhÆ°ng cho cÃ¡c thÃ­ nghiá»‡m
cá»§a chÃºng tÃ´i, chÃºng tÃ´i cá»‘ Ä‘á»‹nh mÃ´ hÃ¬nh CodeBERT vÃ  tokenizer.
Trong bÆ°á»›c (4), chÃºng tÃ´i káº¿t há»£p thÃ´ng tin tá»« táº¥t cáº£ cÃ¡c lá»›p hoáº·c
chá»‰ tá»« má»™t sá»‘ lá»›p Ä‘áº§u cá»§a encoder, trÃ¡i ngÆ°á»£c vá»›i cÆ¡ sá»Ÿ sá»­ dá»¥ng
lá»›p cuá»‘i cÃ¹ng cá»§a encoder. Cuá»‘i cÃ¹ng, Ä‘áº§u phÃ¢n loáº¡i trong bÆ°á»›c (5)
bao gá»“m má»™t lá»›p dropout vÃ  má»™t lá»›p tuyáº¿n tÃ­nh vá»›i softmax.

MÃ´ hÃ¬nh encoder biá»ƒu diá»…n má»—i token cá»§a chuá»—i Ä‘áº§u vÃ o báº±ng má»™t
vector cÃ³ kÃ­ch thÆ°á»›c ğ», cÃ²n Ä‘Æ°á»£c gá»i lÃ  kÃ­ch thÆ°á»›c áº©n. Äá»‘i vá»›i má»—i
chuá»—i Ä‘áº§u vÃ o cÃ³ Ä‘á»™ dÃ i ğ‘†, vÃ  kÃ­ch thÆ°á»›c áº©n ğ», chÃºng tÃ´i thu Ä‘Æ°á»£c
má»™t ma tráº­n cÃ³ kÃ­ch thÆ°á»›c ğ‘†Ã—ğ» cho má»—i lá»›p trong sá»‘ ğ¿ lá»›p cá»§a
mÃ´ hÃ¬nh cÆ¡ sá»Ÿ nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 1. VÃ­ dá»¥, kiáº¿n trÃºc
CodeBERT Ä‘Æ°á»£c cá»‘ Ä‘á»‹nh vá»›i 12 lá»›p encoder, tá»©c lÃ  ğ¿=12 cho mÃ´ hÃ¬nh
Ä‘Ã³. Táº¥t cáº£ thÃ´ng tin cÃ³ sáºµn trong encoder cho má»™t chuá»—i Ä‘áº§u vÃ o
Ä‘Æ°á»£c lÆ°u trá»¯ trong má»™t tensor cÃ³ kÃ­ch thÆ°á»›c ğ¿Ã—ğ‘†Ã—ğ». CÃ¡c káº¿t há»£p
EarlyBIRD pháº£i táº¡o ra má»™t vector Â®ğ‘… cÃ³ kÃ­ch thÆ°á»›c ğ» biá»ƒu diá»…n Ä‘áº§u
vÃ o, nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 1. Viá»‡c giá»¯ biá»ƒu diá»…n mÃ£ Ä‘áº§u ra
cÃ³ kÃ­ch thÆ°á»›c ğ» lÃ  cáº§n thiáº¿t Ä‘á»ƒ cung cáº¥p so sÃ¡nh cÃ´ng báº±ng cá»§a
cÃ¡c biá»ƒu diá»…n tá»•ng há»£p EarlyBIRD vá»›i biá»ƒu diá»…n mÃ£ tiÃªu chuáº©n thu
Ä‘Æ°á»£c tá»« lá»›p cuá»‘i cÃ¹ng. Theo cÃ¡ch nÃ y, chiá»u cá»§a Ä‘áº§u phÃ¢n loáº¡i lÃ 
nhÆ° nhau cho táº¥t cáº£ cÃ¡c káº¿t há»£p cá»§a cÃ¡c lá»›p Ä‘áº§u vÃ  cÃ³ áº£nh hÆ°á»Ÿng
tá»‘i thiá»ƒu cÃ³ thá»ƒ trong quÃ¡ trÃ¬nh fine-tuning.

[HÃ¬nh 1: Kiáº¿n trÃºc mÃ´ hÃ¬nh cho phÃ¢n loáº¡i mÃ£.]

NhÆ° má»™t chiáº¿n lÆ°á»£c Ä‘á»ƒ nghiÃªn cá»©u cÃ³ há»‡ thá»‘ng cÃ¡c biá»ƒu diá»…n tá»•ng há»£p,
chÃºng tÃ´i táº¡o ra má»™t tÃ¬m kiáº¿m lÆ°á»›i trÃªn ba phÃ©p toÃ¡n Ä‘iá»ƒn hÃ¬nh Ä‘á»ƒ
káº¿t há»£p Ä‘áº§u ra cá»§a cÃ¡c lá»›p máº¡ng nÆ¡-ron â€“ max pooling, weighted
sum vÃ  slicing â€“ vÃ  hai chiá»u Ä‘á»ƒ Ã¡p dá»¥ng cÃ¡c phÃ©p toÃ¡n: trÃªn token
vÃ /hoáº·c lá»›p. Äá»‘i vá»›i chiá»u token, chÃºng tÃ´i sá»­ dá»¥ng táº¥t cáº£ cÃ¡c token
tá»« má»™t lá»›p cá»¥ thá»ƒ hoáº·c chá»‰ token CLS. Trong cÃ¡c lá»›p, chÃºng tÃ´i slice
má»™t lá»›p, tá»•ng hoáº·c láº¥y giÃ¡ trá»‹ tá»‘i Ä‘a trÃªn táº¥t cáº£ cÃ¡c lá»›p. Viá»‡c lá»±a chá»n
xem xÃ©t má»—i token cá»§a má»™t lá»›p Ä‘Æ°á»£c thÃºc Ä‘áº©y bá»Ÿi thá»±c táº¿ lÃ  cÃ¡c mÃ´ hÃ¬nh
dá»±a trÃªn transformer thá»ƒ hiá»‡n má»©c Ä‘á»™ attention khÃ¡c nhau cho cÃ¡c
loáº¡i token khÃ¡c nhau [ 29], Ä‘iá»u nÃ y chá»‰ ra ráº±ng viá»‡c chá»‰ sá»­ dá»¥ng
token CLS cÃ³ thá»ƒ khÃ´ng pháº£i lÃ  lá»±a chá»n tá»‘t nháº¥t cho cÃ¡c nhiá»‡m vá»¥ [ 37].
ChÃºng tÃ´i cÅ©ng thÃ­ nghiá»‡m vá»›i cÃ¡c kÃ­ch thÆ°á»›c khÃ¡c nhau cá»§a mÃ´ hÃ¬nh.
CÃ¡c chiáº¿n lÆ°á»£c káº¿t há»£p sá»­ dá»¥ng táº¥t cáº£ cÃ¡c lá»›p cá»§a mÃ´ hÃ¬nh Ä‘Æ°á»£c
huáº¥n luyá»‡n trÆ°á»›c Ä‘Æ°á»£c chia thÃ nh hai loáº¡i: cÃ¡c chiáº¿n lÆ°á»£c sá»­ dá»¥ng
token CLS tá»« cÃ¡c lá»›p encoder; cÃ¡c chiáº¿n lÆ°á»£c sá»­ dá»¥ng nhiá»u token
hÆ¡n chá»‰ CLS tá»« cÃ¡c lá»›p encoder.

Khi chÃºng tÃ´i slice token CLS vÃ  Ã¡p dá»¥ng tá»«ng phÃ©p toÃ¡n trÃªn cÃ¡c
lá»›p, chÃºng tÃ´i thu Ä‘Æ°á»£c cÃ¡c káº¿t há»£p token CLS sau:
(i) cÆ¡ sá»Ÿ : token CLS tá»« lá»›p cuá»‘i cÃ¹ng, tá»©c lÃ  lá»›p sá»‘ ğ¿;
(ii) token CLS tá»« má»™t lá»›pÂ³ sá»‘ ğ‘™, ğ‘™âˆˆ{1,...,(ğ¿âˆ’1)};
(iii) max pool trÃªn token CLS tá»« táº¥t cáº£ cÃ¡c lá»›p {ğ‘™}ğ¿
ğ‘™=1;
(iv) weighted sum trÃªn token CLS tá»« táº¥t cáº£ cÃ¡c lá»›p {ğ‘™}ğ¿
ğ‘™=1.

Táº­p há»£p káº¿t há»£p thá»© hai sá»­ dá»¥ng biá»ƒu diá»…n cá»§a táº¥t cáº£ cÃ¡c token
trong chuá»—i Ä‘áº§u vÃ o Ä‘Æ°á»£c tokenized, bao gá»“m token CLS. ChÃºng tÃ´i
Ä‘áº§u tiÃªn Ã¡p dá»¥ng phÃ©p toÃ¡n max pooling cho táº¥t cáº£ cÃ¡c token hoáº·c
táº¥t cáº£ cÃ¡c lá»›p vÃ  sá»­ dá»¥ng cÃ¡c phÃ©p toÃ¡n cÃ²n láº¡i. Sau Ä‘Ã³ chÃºng tÃ´i
Ã¡p dá»¥ng weighted sum nhÆ° phÃ©p toÃ¡n Ä‘áº§u tiÃªn theo sau bá»Ÿi max pool
hoáº·c slicing cá»§a má»™t lá»›p:

(v) max pool token tá»« má»™t lá»›p sá»‘ ğ‘™, ğ‘™âˆˆ{1,...,ğ¿};
(vi) max pool trÃªn táº¥t cáº£ cÃ¡c lá»›p cho má»—i token trong chuá»—i Ä‘áº§u vÃ o,
max pool trÃªn token;
(vii) max pool trÃªn táº¥t cáº£ cÃ¡c lá»›p cho má»—i token trong chuá»—i Ä‘áº§u vÃ o;
weighted sum trÃªn token;
(viii) max pool trÃªn táº¥t cáº£ cÃ¡c token cho má»—i lá»›p sá»‘ ğ‘™, ğ‘™âˆˆ{1,...,ğ¿};
weighted sum trÃªn cÃ¡c lá»›p
(ix) weighted sum trÃªn token tá»« má»™t lá»›p sá»‘ ğ‘™, ğ‘™âˆˆ{1,...,ğ¿};
(x) weighted sum trÃªn token cho má»—i lá»›p sá»‘ ğ‘™, ğ‘™âˆˆ{1,...,ğ¿};
weighted sum trÃªn táº¥t cáº£ cÃ¡c lá»›p;
(xi) weighted sum trÃªn táº¥t cáº£ cÃ¡c lá»›p cho má»—i token trong chuá»—i
Ä‘áº§u vÃ o; weighted sum trÃªn táº¥t cáº£ cÃ¡c token.

LÆ°u Ã½ ráº±ng cÃ¡c trá»ng sá»‘ trong weighted sum lÃ  cÃ¡c tham sá»‘ cÃ³ thá»ƒ
há»c Ä‘Æ°á»£c. Tuy nhiÃªn, sá»‘ lÆ°á»£ng tham sá»‘ cÃ³ thá»ƒ há»c Ä‘Æ°á»£c Ä‘Æ°á»£c thÃªm
vÃ o Ä‘á»ƒ fine-tuning chiáº¿m 0.00042%â´ sá»‘ lÆ°á»£ng tham sá»‘ cÃ³ thá»ƒ há»c Ä‘Æ°á»£c
trong cáº¥u hÃ¬nh cÆ¡ sá»Ÿ. VÃ¬ lÃ½ do nÃ y, chÃºng tÃ´i Ä‘á» cáº­p ráº±ng cÃ¡c mÃ´ hÃ¬nh
vá»›i káº¿t há»£p (ii-x) cÃ³ cÃ¹ng kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh trong khi lÆ°u Ã½ Ä‘áº¿n
overhead cá»§a trá»ng sá»‘ cÃ³ thá»ƒ há»c Ä‘Æ°á»£c trong weighted sum.

NgoÃ i cÃ¡c thÃ­ nghiá»‡m vá»›i káº¿t há»£p token, chÃºng tÃ´i cÅ©ng nghiÃªn cá»©u
hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh vá»›i ğ‘™<ğ¿ lá»›p Ä‘áº§u tiÃªn vÃ  káº¿t há»£p token cÆ¡ sá»Ÿ,
Ä‘Æ°á»£c mÃ´ táº£ nhÆ° sau:

Â³ChÃºng tÃ´i sá»­ dá»¥ng má»—i lá»›p ğ‘™ trong cÃ¡c káº¿t há»£p riÃªng biá»‡t náº¿u chÃºng tÃ´i kÃ½ hiá»‡u
ğ‘ , ğ‘™âˆˆ{1,...,ğ¿}, vÃ  chá»‰ Ä‘á»‹nh táº­p há»£p cÃ¡c lá»›p {ğ‘™}ğ¿
ğ‘™=1 náº¿u má»™t sá»‘ lá»›p Ä‘Æ°á»£c sá»­ dá»¥ng
cÃ¹ng lÃºc.
â´Weighted sum trÃªn token thÃªm ğ‘†=512 trá»ng sá»‘ cÃ³ thá»ƒ há»c Ä‘Æ°á»£c. VÃ¬ cÃ¡c trá»ng sá»‘
cá»§a tá»•ng Ä‘Æ°á»£c chia sáº» giá»¯a cÃ¡c lá»›p, sá»‘ lÆ°á»£ng trá»ng sá»‘ Ä‘Æ°á»£c thÃªm vÃ o tá»‘i Ä‘a lÃ 
ğ¿+ğ»=524 trong sá»‘ 124M trá»ng sá»‘ cÃ³ thá»ƒ há»c Ä‘Æ°á»£c trong mÃ´ hÃ¬nh cÆ¡ sá»Ÿ. CÃ¡c káº¿t há»£p
khÃ´ng cÃ³ weighted sum khÃ´ng thÃªm tham sá»‘ cÃ³ thá»ƒ há»c Ä‘Æ°á»£c bá»• sung vÃ o mÃ´ hÃ¬nh cÆ¡ sá»Ÿ.
Weighted sum trÃªn cÃ¡c lá»›p thÃªm ğ¿=12 trá»ng sá»‘ cÃ³ thá»ƒ há»c Ä‘Æ°á»£c cho CodeBERT.

--- TRANG 4 ---
ESEC/FSE '23, 3â€“9 thÃ¡ng 12, 2023, San Francisco, CA, USA Anastasiia Grishina, Max Hort, vÃ  Leon Moonen

(xii) token CLS tá»« lá»›p cuá»‘i cÃ¹ng cá»§a mÃ´ hÃ¬nh vá»›i ğ‘™<ğ¿ lá»›p encoder.

LÆ°u Ã½ ráº±ng káº¿t há»£p cÆ¡ sá»Ÿ (i) vá»›i viá»‡c sá»­ dá»¥ng token CLS tá»« lá»›p ğ¿
tÆ°Æ¡ng á»©ng vá»›i (ii) vÃ  (xii) náº¿u ğ‘™=ğ¿.

CÃ¡c káº¿t há»£p Ä‘Æ°á»£c trÃ¬nh bÃ y trong HÃ¬nh 2. CÃ¡c káº¿t há»£p tÆ°Æ¡ng tá»±
Ä‘Æ°á»£c trÃ¬nh bÃ y gáº§n nhau hoáº·c Ä‘Æ°á»£c káº¿t há»£p trong cÃ¹ng má»™t hÃ¬nh
náº¿u chÃºng chá»‰ cÃ³ sá»± khÃ¡c biá»‡t nhá» vÃ  chia sáº» cÃ¡c pháº§n chÃ­nh.
VÃ­ dá»¥, trong HÃ¬nh 2c, chÃºng tÃ´i minh há»a cÃ¡c káº¿t há»£p (iii) vÃ  (iv),
vÃ¬ cáº£ hai Ä‘á»u sá»­ dá»¥ng token CLS tá»« táº¥t cáº£ cÃ¡c lá»›p Ä‘Æ°á»£c káº¿t há»£p
báº±ng max pooling hoáº·c weighted sum. CÃ¡c sá»‘ La MÃ£ chá»‰ ra cÃ¡c
loáº¡i káº¿t há»£p Ä‘Æ°á»£c giá»¯ nguyÃªn trong cÃ¡c mÃ´ táº£ bÃªn dÆ°á»›i hÃ¬nh hoáº·c
trong chÃ­nh cÃ¡c hÃ¬nh, nhÆ°ng thá»© tá»± Ä‘Æ°á»£c thay Ä‘á»•i. ChÃºng tÃ´i Ä‘á» cáº­p
sá»‘ káº¿t há»£p tÆ°Æ¡ng á»©ng vá»›i mÃ´ táº£ trong pháº§n hiá»‡n táº¡i, nhÆ° káº¿t há»£p
cÆ¡ sá»Ÿ (i) trong HÃ¬nh 2a hoáº·c káº¿t há»£p (ii) cho token CLS tá»« má»™t
lá»›p Ä‘áº§u trong HÃ¬nh 2b. ChÃºng tÃ´i lÃ m ná»•i báº­t nhá»¯ng pháº§n nÃ o
cá»§a Ä‘áº§u ra lá»›p encoder Ä‘Æ°á»£c sá»­ dá»¥ng cho má»—i káº¿t há»£p báº±ng mÃ u.
CÃ¡c Ã´ tráº¯ng tÆ°Æ¡ng á»©ng vá»›i cÃ¡c token khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng trong
cÃ¡c káº¿t há»£p lá»›p Ä‘áº§u. Má»¥c tiÃªu cá»§a táº¥t cáº£ cÃ¡c káº¿t há»£p lÃ  thu Ä‘Æ°á»£c
má»™t biá»ƒu diá»…n vector Â®ğ‘… cho má»—i máº«u mÃ£ Ä‘áº§u vÃ o. VÃ­ dá»¥, trong
HÃ¬nh 2a, chÃºng tÃ´i xem xÃ©t lá»›p cuá»‘i cÃ¹ng ğ¿ vÃ  trÃ­ch xuáº¥t chá»‰
token CLS Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u lÃ  Â®ğ‘….

Má»™t nháº­n xÃ©t khÃ¡c vá» cÃ¡c káº¿t há»£p EarlyBIRD liÃªn quan Ä‘áº¿n viá»‡c
sá»­ dá»¥ng táº¥t cáº£ cÃ¡c token hoáº·c chá»‰ cÃ¡c token mÃ£. CÃ¡c token mÃ£
lÃ  nhá»¯ng token tÆ°Æ¡ng á»©ng vá»›i cÃ¡c tá»« hoáº·c tá»« phá»¥ Ä‘Æ°á»£c tokenized
Ä‘áº§u vÃ o vÃ  Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 2 lÃ  tokenğ‘–1,...,tokenğ‘–ğ‘
cho má»™t chuá»—i Ä‘áº§u vÃ o ğ‘– cÃ³ kÃ­ch thÆ°á»›c ğ‘–ğ‘. Äá»‘i vá»›i má»—i káº¿t há»£p
sá»­ dá»¥ng nhiá»u hÆ¡n chá»‰ má»™t token CLS, tá»©c lÃ  cÃ¡c káº¿t há»£p (v-xi),
chÃºng tÃ´i thÃ­ nghiá»‡m vá»›i chá»‰ cÃ¡c token mÃ£, cÅ©ng nhÆ° vá»›i táº¥t cáº£
cÃ¡c token, bao gá»“m CLS, EOS, vÃ  PAD. Äá»™ng lá»±c Ä‘á»ƒ kiá»ƒm tra
riÃªng cÃ¡c token mÃ£ xuáº¥t phÃ¡t tá»« giáº£ thuyáº¿t ráº±ng thÃ´ng tin trong
cÃ¡c token Ä‘áº·c biá»‡t cÃ³ thá»ƒ Ä‘Æ°a nhiá»…u vÃ o káº¿t quáº£.

[HÃ¬nh 2: CÃ¡c káº¿t há»£p cá»§a cÃ¡c lá»›p encoder Ä‘áº§u dáº«n Ä‘áº¿n vector
biá»ƒu diá»…n mÃ£ Â®ğ‘… cho má»—i chuá»—i Ä‘áº§u vÃ o Ä‘Æ°á»£c tokenized.
Sá»‘ La MÃ£ trong ngoáº·c tÆ°Æ¡ng á»©ng vá»›i cÃ¡c káº¿t há»£p Ä‘Æ°á»£c mÃ´ táº£
trong Má»¥c 4. Quan sÃ¡t ráº±ng thá»© tá»± trÃ¬nh bÃ y Ä‘Ã£ Ä‘Æ°á»£c thiáº¿t káº¿
Ä‘á»ƒ tiáº¿t kiá»‡m khÃ´ng gian báº±ng cÃ¡ch nhÃ³m cÃ¡c káº¿t há»£p tÆ°Æ¡ng tá»±
trong cÃ¹ng má»™t hÃ¬nh phá»¥.]

5 THIáº¾T Láº¬P THá»°C NGHIá»†M
Trong pháº§n nÃ y, chÃºng tÃ´i mÃ´ táº£ cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng
Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ thá»±c nghiá»‡m vÃ  chi tiáº¿t triá»ƒn khai cá»§a fine-tuning vá»›i
phÆ°Æ¡ng phÃ¡p EarlyBIRD Ä‘Æ°á»£c Ä‘á» xuáº¥t. ChÃºng tÃ´i nghiÃªn cá»©u cÃ¡c
ká»‹ch báº£n phÃ¢n loáº¡i mÃ£ nhá»‹ phÃ¢n vÃ  Ä‘a nhiá»‡m vá»¥ Ä‘á»ƒ khÃ¡m phÃ¡ tÃ­nh
tá»•ng quÃ¡t cá»§a káº¿t quáº£.

5.1 Táº­p Dá»¯ Liá»‡u cho PhÃ¢n Loáº¡i MÃ£ Nguá»“n
ChÃºng tÃ´i fine-tune vÃ  kiá»ƒm tra mÃ´ hÃ¬nh CodeBERT sá»­ dá»¥ng phÆ°Æ¡ng
phÃ¡p EarlyBIRD trÃªn bá»‘n táº­p dá»¯ liá»‡u. CÃ¡c táº­p dá»¯ liá»‡u bao gá»“m ba
nhiá»‡m vá»¥: phÃ¡t hiá»‡n lá»—i, phÃ¢n loáº¡i kiá»ƒu lá»—i vÃ  phÃ¢n loáº¡i kiá»ƒu ngoáº¡i
lá»‡ â€” vá»›i tÆ°Æ¡ng á»©ng 2, 3, vÃ  20 lá»›p. ChÃºng cÅ©ng chá»©a dá»¯ liá»‡u
trong hai ngÃ´n ngá»¯ láº­p trÃ¬nh, C++ vÃ  Python. NgoÃ i ra, cÃ¡c táº­p
dá»¯ liá»‡u Ä‘Æ°á»£c chá»n cÃ³ kÃ­ch thÆ°á»›c táº­p con huáº¥n luyá»‡n tÆ°Æ¡ng tá»±.
Theo cÃ¡ch nÃ y, chÃºng tÃ´i nháº±m giáº£m tÃ¡c Ä‘á»™ng cá»§a viá»‡c tiáº¿p xÃºc
cá»§a mÃ´ hÃ¬nh vá»›i cÃ¡c lÆ°á»£ng dá»¯ liá»‡u huáº¥n luyá»‡n khÃ¡c nhau trong
quÃ¡ trÃ¬nh fine-tuning. Thá»‘ng kÃª cá»§a cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c cung cáº¥p
trong Báº£ng 1. ChÃºng tÃ´i bÃ¡o cÃ¡o kÃ­ch thÆ°á»›c cá»§a cÃ¡c pháº§n train/validation/test.
NgoÃ i ra, chÃºng tÃ´i tÃ­nh toÃ¡n sá»‘ lÆ°á»£ng token trung bÃ¬nh trong cÃ¡c
chuá»—i Ä‘áº§u vÃ o sau khi tokenization vá»›i tokenizer CodeBERT Ä‘Æ°á»£c
huáº¥n luyá»‡n trÆ°á»›c. VÃ¬ kÃ­ch thÆ°á»›c chuá»—i Ä‘áº§u vÃ o tá»‘i Ä‘a cho mÃ´ hÃ¬nh
CodeBERT bá»‹ giá»›i háº¡n á»Ÿ ğ‘†=512, sá»‘ lÆ°á»£ng token cho biáº¿t mÃ´ hÃ¬nh
cÃ³ quyá»n truy cáº­p vÃ o bao nhiÃªu thÃ´ng tin hoáº·c bao nhiÃªu thÃ´ng tin
bá»‹ cáº¯t bá», trong trÆ°á»ng há»£p Ä‘áº§u vÃ o dÃ i.

Devign: Táº­p dá»¯ liá»‡u nÃ y chá»©a cÃ¡c hÃ m trong C/C++ tá»« hai dá»± Ã¡n
nguá»“n má»Ÿ Ä‘Æ°á»£c gÃ¡n nhÃ£n lÃ  dá»… bá»‹ tá»•n thÆ°Æ¡ng hoáº·c khÃ´ng dá»… bá»‹ tá»•n
thÆ°Æ¡ng [ 51]. ChÃºng tÃ´i sá»­ dá»¥ng láº¡i pháº§n chia train/validation/test
tá»« chuáº©n má»±c CodeXGLUE Defect detection.âµ Táº­p dá»¯ liá»‡u cÃ¢n báº±ng:
tá»· lá»‡ cÃ¡c hÃ m khÃ´ng dá»… bá»‹ tá»•n thÆ°Æ¡ng lÃ  54%.

ReVeal: TÆ°Æ¡ng tá»± nhÆ° Devign, ReVeal lÃ  táº­p dá»¯ liá»‡u phÃ¡t hiá»‡n lá»— há»•ng
cá»§a cÃ¡c hÃ m C/C++ [ 7]. Táº­p dá»¯ liá»‡u khÃ´ng cÃ¢n báº±ng: nÃ³ chá»©a 90%
Ä‘oáº¡n mÃ£ khÃ´ng dá»… bá»‹ tá»•n thÆ°Æ¡ng. Cáº£ táº­p dá»¯ liá»‡u Devign vÃ  ReVeal
Ä‘á»u chá»©a cÃ¡c hÃ m dá»… bá»‹ tá»•n thÆ°Æ¡ng vÃ  khÃ´ng dá»… bá»‹ tá»•n thÆ°Æ¡ng thá»±c
táº¿ tá»« cÃ¡c dá»± Ã¡n nguá»“n má»Ÿ.

Break-It-Fix-It (BIFI): Táº­p dá»¯ liá»‡u chá»©a cÃ¡c Ä‘oáº¡n mÃ£ cáº¥p hÃ m
trong Python vá»›i lá»—i cÃº phÃ¡p [ 47]. ChÃºng tÃ´i sá»­ dá»¥ng cÃ¡c hÃ m
buggy ban Ä‘áº§u vÃ  cÃ´ng thá»©c hÃ³a nhiá»‡m vá»¥ phÃ¢n loáº¡i mÃ£ thÃ nh ba
lá»›p: Unbalanced Parentheses vá»›i 43% tá»•ng sá»‘ vÃ­ dá»¥ mÃ£ trong BIFI,
Indentation Error vá»›i 31% máº«u mÃ£, Invalid Syntax chá»©a 26% máº«u.
Pháº§n chia train/test Ä‘Æ°á»£c cung cáº¥p trong táº­p dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng
láº¡i, vÃ  táº­p validation Ä‘Æ°á»£c trÃ­ch xuáº¥t lÃ  10% dá»¯ liá»‡u huáº¥n luyá»‡n.

Exception Type: Táº­p dá»¯ liá»‡u bao gá»“m cÃ¡c hÃ m ngáº¯n trong Python
vá»›i token __HOLE__ Ä‘Æ°á»£c chÃ¨n vÃ o thay tháº¿ má»™t ngoáº¡i lá»‡ trong mÃ£.â¶
Nhiá»‡m vá»¥ lÃ  dá»± Ä‘oÃ¡n má»™t trong 20 kiá»ƒu ngoáº¡i lá»‡ bá»‹ che dáº¥u cho
má»—i hÃ m Ä‘áº§u vÃ o vÃ  khÃ´ng cÃ¢n báº±ng. Táº­p dá»¯ liá»‡u ban Ä‘áº§u Ä‘Æ°á»£c
táº¡o tá»« ETH Py150 Open corpusâ· nhÆ° Ä‘Æ°á»£c mÃ´ táº£ trong bÃ i bÃ¡o gá»‘c [ 20].
ChÃºng tÃ´i sá»­ dá»¥ng láº¡i pháº§n chia train/validation/test Ä‘Æ°á»£c cung cáº¥p
bá»Ÿi cÃ¡c tÃ¡c giáº£.

5.2 Triá»ƒn Khai
Kiáº¿n trÃºc dá»±a trÃªn tokenizer vÃ  mÃ´ hÃ¬nh encoder CodeBERT.â¸
MÃ´ hÃ¬nh Ä‘á»‹nh nghÄ©a Ä‘á»™ dÃ i chuá»—i tá»‘i Ä‘a, kÃ­ch thÆ°á»›c áº©n, vÃ  cÃ³ 12
lá»›p, vÃ¬ váº­y ğ‘†=512, ğ»=768, ğ¿=12. SiÃªu tham sá»‘ trong cÃ¡c thÃ­
nghiá»‡m Ä‘Æ°á»£c Ä‘áº·t thÃ nh ğµ=64, tá»· lá»‡ há»c táº­p lÃ  1ğ‘’-5, vÃ  xÃ¡c suáº¥t
dropout lÃ  0.1. Náº¿u máº«u Ä‘áº§u vÃ o Ä‘Æ°á»£c tokenized dÃ i hÆ¡n ğ‘†=512,
chÃºng tÃ´i cáº¯t bá» cÃ¡c token á»Ÿ cuá»‘i Ä‘á»ƒ lÃ m cho Ä‘áº§u vÃ o phÃ¹ há»£p
vá»›i mÃ´ hÃ¬nh. ChÃºng tÃ´i cháº¡y fine-tuning vá»›i optimizer Adam vÃ 
kiá»ƒm tra cho má»—i káº¿t há»£p 10 láº§n vá»›i cÃ¡c seed khÃ¡c nhau trong
10 epoch vÃ  bÃ¡o cÃ¡o hiá»‡u suáº¥t cho epoch tá»‘t nháº¥t trung bÃ¬nh
trÃªn 10 láº§n cháº¡y. Epoch tá»‘t nháº¥t Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a báº±ng cÃ¡ch Ä‘o
Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p validation. ChÃºng tÃ´i sá»­ dá»¥ng Python 3.7
vÃ  Cuda 11.6, vÃ  cháº¡y thÃ­ nghiá»‡m trÃªn má»™t GPU Nvidia Volta A100.

[Báº£ng 1: Thá»‘ng kÃª cá»§a cÃ¡c Táº­p Dá»¯ Liá»‡u Fine-Tuning.]

5.3 Chá»‰ Sá»‘ ÄÃ¡nh GiÃ¡
Äá»ƒ trÃ¬nh bÃ y tÃ¡c Ä‘á»™ng cá»§a cÃ¡c káº¿t há»£p lá»›p Ä‘áº§u, chÃºng tÃ´i so sÃ¡nh
Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p kiá»ƒm tra cho táº¥t cáº£ cÃ¡c táº­p dá»¯ liá»‡u, vÃ¬ nÃ³
cho phÃ©p chÃºng tÃ´i so sÃ¡nh káº¿t quáº£ vá»›i cÃ¡c chuáº©n má»±c khÃ¡c. NgoÃ i
ra, chÃºng tÃ´i bÃ¡o cÃ¡o Ä‘iá»ƒm F1 cÃ³ trá»ng sá»‘ Ä‘Æ°á»£c kÃ½ hiá»‡u lÃ  F1(w)
cho phÃ¢n tÃ­ch chi tiáº¿t cá»§a cÃ¡c káº¿t há»£p Ä‘Æ°á»£c chá»n Ä‘á»ƒ tÃ­nh Ä‘áº¿n sá»±
máº¥t cÃ¢n báº±ng lá»›p. Äá»ƒ thu Ä‘Æ°á»£c Ä‘iá»ƒm F1 cÃ³ trá»ng sá»‘, Ä‘iá»ƒm F1 thÆ°á»ng
Ä‘Æ°á»£c tÃ­nh toÃ¡n cho má»—i nhÃ£n vÃ  trung bÃ¬nh cÃ³ trá»ng sá»‘ cá»§a chÃºng
Ä‘Æ°á»£c láº¥y. CÃ¡c trá»ng sá»‘ báº±ng sá»‘ lÆ°á»£ng máº«u trong má»™t lá»›p.

ChÃºng tÃ´i cÅ©ng bÃ¡o cÃ¡o káº¿t quáº£ cá»§a kiá»ƒm Ä‘á»‹nh Wilcoxon signed-rank
trÃªn cÃ¡c chá»‰ sá»‘ tÆ°Æ¡ng á»©ng cho cÃ¡c káº¿t há»£p cho tháº¥y cáº£i thiá»‡n so
vá»›i cÆ¡ sá»Ÿ [ 45]. Kiá»ƒm Ä‘á»‹nh Wilcoxon lÃ  má»™t kiá»ƒm Ä‘á»‹nh phi tham sá»‘
phÃ¹ há»£p cho thiáº¿t láº­p mÃ  cÃ¡c biáº¿n thá»ƒ mÃ´ hÃ¬nh khÃ¡c nhau Ä‘Æ°á»£c
kiá»ƒm tra trÃªn cÃ¹ng má»™t táº­p kiá»ƒm tra, vÃ¬ nÃ³ lÃ  má»™t kiá»ƒm Ä‘á»‹nh Ä‘Æ°á»£c
ghÃ©p cáº·p. Kiá»ƒm Ä‘á»‹nh Wilcoxon kiá»ƒm tra giáº£ thuyáº¿t null liá»‡u hai
máº«u Ä‘Æ°á»£c ghÃ©p cáº·p liÃªn quan cÃ³ Ä‘áº¿n tá»« cÃ¹ng má»™t phÃ¢n phá»‘i.
ChÃºng tÃ´i tá»« chá»‘i giáº£ thuyáº¿t null náº¿u p-value nhá» hÆ¡n ğ›¼=0.05.
Trong trÆ°á»ng há»£p chÃºng tÃ´i cÃ³ Ä‘Æ°á»£c cáº£i thiá»‡n cá»§a má»™t chá»‰ sá»‘ so
vá»›i cÆ¡ sá»Ÿ vá»›i káº¿t há»£p EarlyBIRD vÃ  giáº£ thuyáº¿t null bá»‹ tá»« chá»‘i,
chÃºng tÃ´i káº¿t luáº­n ráº±ng káº¿t há»£p hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n vÃ  káº¿t quáº£
cÃ³ Ã½ nghÄ©a thá»‘ng kÃª. Äá»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c cáº¯t tá»‰a, chÃºng tÃ´i
tÃ­nh toÃ¡n ğ´12 phi tham sá»‘ cá»§a Vargha vÃ  Delaney Ä‘á»ƒ Ä‘o lÆ°á»ng
kÃ­ch thÆ°á»›c hiá»‡u á»©ng cá»§a thay Ä‘á»•i hiá»‡u suáº¥t cho Ä‘á»™ chÃ­nh xÃ¡c
vÃ  F1(w) vá»›i ngÆ°á»¡ng 0.71, 0.64 vÃ  0.56 cho kÃ­ch thÆ°á»›c hiá»‡u
á»©ng lá»›n, trung bÃ¬nh vÃ  nhá» [41].

5.4 CÃ¢u Há»i NghiÃªn Cá»©u
Trong quÃ¡ trÃ¬nh Ä‘Ã¡nh giÃ¡ thá»±c nghiá»‡m cÃ¡c biá»ƒu diá»…n mÃ£ tá»•ng há»£p
EarlyBIRD, chÃºng tÃ´i giáº£i quyáº¿t cÃ¡c cÃ¢u há»i nghiÃªn cá»©u sau:

RQ1. Biá»ƒu Diá»…n MÃ£ Tá»•ng Há»£p vá»›i CÃ¹ng KÃ­ch ThÆ°á»›c MÃ´ HÃ¬nh:
TÃ¡c Ä‘á»™ng cá»§a viá»‡c sá»­ dá»¥ng cÃ¡c káº¿t há»£p (ii-xi) cá»§a cÃ¡c lá»›p Ä‘áº§u vá»›i
cÃ¹ng kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh so vá»›i phÆ°Æ¡ng phÃ¡p cÆ¡ sá»Ÿ chá»‰ sá»­ dá»¥ng
token CLS tá»« lá»›p cuá»‘i cÃ¹ng, tá»©c lÃ  káº¿t há»£p (i), Ä‘á»ƒ biá»ƒu diá»…n mÃ£
lÃªn hiá»‡u suáº¥t mÃ´ hÃ¬nh trong ká»‹ch báº£n phÃ¢n loáº¡i mÃ£ lÃ  gÃ¬? Má»¥c tiÃªu
lÃ  tÃ¬m ra liá»‡u cÃ³ loáº¡i káº¿t há»£p EarlyBIRD nÃ o hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n
má»™t cÃ¡ch nháº¥t quÃ¡n cho cÃ¡c táº­p dá»¯ liá»‡u vÃ  nhiá»‡m vá»¥ khÃ¡c nhau.

RQ2. MÃ´ HÃ¬nh ÄÆ°á»£c Cáº¯t Tá»‰a: TÃ¡c Ä‘á»™ng cá»§a viá»‡c giáº£m sá»‘ lÆ°á»£ng
lá»›p encoder Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c trong cÃ¡c káº¿t há»£p (xii) lÃªn
viá»‡c sá»­ dá»¥ng nguá»“n lá»±c vÃ  hiá»‡u suáº¥t mÃ´ hÃ¬nh trÃªn cÃ¡c nhiá»‡m vá»¥
phÃ¢n loáº¡i mÃ£ lÃ  gÃ¬? TrÃ¡i ngÆ°á»£c vá»›i RQ1, trong Ä‘Ã³ chÃºng tÃ´i xem
xÃ©t cÃ¡c káº¿t há»£p khÃ´ng giáº£m kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh, cÃ¢u há»i nghiÃªn
cá»©u nÃ y dÃ nh cho viá»‡c nghiÃªn cá»©u sá»± Ä‘Ã¡nh Ä‘á»•i giá»¯a viá»‡c sá»­ dá»¥ng
Ã­t nguá»“n lá»±c hÆ¡n vá»›i cÃ¡c mÃ´ hÃ¬nh kÃ­ch thÆ°á»›c giáº£m vÃ  biáº¿n Ä‘á»•i
hiá»‡u suáº¥t vá» máº·t chá»‰ sá»‘ phÃ¢n loáº¡i.

Äá»‘i vá»›i cáº£ hai cÃ¢u há»i nghiÃªn cá»©u, chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ cÃ¡c biá»ƒu
diá»…n tá»•ng há»£p trÃªn cÃ¡c ká»‹ch báº£n phÃ¢n loáº¡i mÃ£ nhá»‹ phÃ¢n vÃ  Ä‘a
nhiá»‡m vá»¥ Ä‘á»ƒ khÃ¡m phÃ¡ tÃ­nh tá»•ng quÃ¡t cá»§a káº¿t quáº£ thu Ä‘Æ°á»£c cho
trÆ°á»ng há»£p nhá»‹ phÃ¢n. ChÃºng tÃ´i nghiÃªn cá»©u xem vÃ  nhá»¯ng káº¿t
há»£p nÃ o dáº«n Ä‘áº¿n hiá»‡u suáº¥t tá»‘t hÆ¡n, trung bÃ¬nh trÃªn 10 láº§n cháº¡y
vá»›i cÃ¡c seed khÃ¡c nhau. Äá»‘i vá»›i cÃ¡c káº¿t há»£p cáº£i thiá»‡n cÆ¡ sá»Ÿ trung
bÃ¬nh, chÃºng tÃ´i cÅ©ng khÃ¡m phÃ¡ xem káº¿t quáº£ cÃ³ Ã½ nghÄ©a thá»‘ng kÃª
theo kiá»ƒm Ä‘á»‹nh Wilcoxon.

6 Káº¾T QUáº¢ VÃ€ THáº¢O LUáº¬N

6.1 EarlyBIRD vá»›i MÃ´ HÃ¬nh KÃ­ch ThÆ°á»›c Cá»‘ Äá»‹nh
Äá»ƒ tráº£ lá»i RQ1, chÃºng tÃ´i khÃ¡m phÃ¡ cÃ¡c káº¿t há»£p má»™t lá»›p, káº¿t há»£p
Ä‘a lá»›p, vÃ  Æ°á»›c tÃ­nh Ã½ nghÄ©a thá»‘ng kÃª cá»§a cáº£i thiá»‡n hiá»‡u suáº¥t.

6.1.1 Káº¿t Há»£p Token trong CÃ¡c Lá»›p Äáº§u ÄÆ°á»£c Chá»n ÄÆ¡n Láº».
HÃ¬nh 3 hiá»ƒn thá»‹ báº£n Ä‘á»“ nhiá»‡t cá»§a sá»± khÃ¡c biá»‡t vá» Ä‘á»™ chÃ­nh xÃ¡c
trung bÃ¬nh thu Ä‘Æ°á»£c vá»›i má»—i káº¿t há»£p chá»‰ sá»­ dá»¥ng má»™t lá»›p Ä‘áº§u
Ä‘Æ°á»£c chá»n so vá»›i cÆ¡ sá»Ÿ. NgoÃ i ra, chÃºng tÃ´i hiá»ƒn thá»‹ giÃ¡ trá»‹ cá»§a
sá»± khÃ¡c biá»‡t vá» Ä‘á»™ chÃ­nh xÃ¡c trung bÃ¬nh cho má»—i loáº¡i káº¿t há»£p vÃ 
sá»‘ lá»›p. LÆ°u Ã½ ráº±ng thang Ä‘o lÃ  logarit vÃ  trong trÆ°á»ng há»£p cá»±c
Ä‘oan nháº¥t tráº£i dÃ i tá»« khoáº£ng -37 Ä‘áº¿n +2. CÃ¡c giÃ¡ trá»‹ Ã¢m Ä‘Æ°á»£c
hiá»ƒn thá»‹ mÃ u Ä‘en, vÃ  cÃ¡c giÃ¡ trá»‹ dÆ°Æ¡ng Ä‘Æ°á»£c hiá»ƒn thá»‹ mÃ u tráº¯ng.
Sá»± khÃ¡c biá»‡t cÃ³ Ã½ nghÄ©a thá»‘ng kÃª theo kiá»ƒm Ä‘á»‹nh Wilcoxon Ä‘Æ°á»£c
Ä‘Ã¡nh dáº¥u báº±ng dáº¥u sao (âˆ—) bÃªn cáº¡nh giÃ¡ trá»‹. CÃ¡c káº¿t há»£p tÆ°Æ¡ng
á»©ng vá»›i cÆ¡ sá»Ÿ Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u báº±ng "bsln" vÃ  cÃ³ sá»± khÃ¡c biá»‡t
báº±ng khÃ´ng, theo Ä‘á»‹nh nghÄ©a. Káº¿t quáº£ cho Ä‘iá»ƒm F1 cÃ³ trá»ng sá»‘
cho tháº¥y mÃ´ hÃ¬nh tÆ°Æ¡ng tá»± nhÆ° cá»§a Ä‘á»™ chÃ­nh xÃ¡c trung bÃ¬nh.
ChÃºng Ä‘Æ°á»£c hiá»ƒn thá»‹ theo cÃ¡ch tÆ°Æ¡ng tá»± trong HÃ¬nh 4.

CÃ¡c hÃ ng Ä‘áº§u tiÃªn trong HÃ¬nh 3a vÃ  3b tÆ°Æ¡ng á»©ng vá»›i cÃ¡c káº¿t
há»£p (ii) token CLS lá»›p ğ‘™. Vá»›i loáº¡i káº¿t há»£p nÃ y, cáº£i thiá»‡n trung
bÃ¬nh so vá»›i cÆ¡ sá»Ÿ Ä‘áº¡t Ä‘Æ°á»£c vá»›i pháº§n lá»›n cÃ¡c lá»›p Ä‘áº§u. Cá»¥ thá»ƒ,
chÃºng tÃ´i cÃ³ Ä‘Æ°á»£c cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c tá»« +0.2 Ä‘áº¿n +2.0 cho
Devign trong 8 trong 11 lá»›p, vÃ  cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c tá»« +0.1
Ä‘áº¿n +0.8 cho ReVeal trong 9 trong 11 lá»›p. Äá»™ng lá»±c thay Ä‘á»•i
chá»‰ sá»‘ trÃªn cÃ¡c sá»‘ lá»›p Ä‘Æ°á»£c chá»n khÃ¡c nhau cho Devign vÃ  ReVeal.
Chi tiáº¿t, hiá»‡u suáº¥t trung bÃ¬nh cá»§a káº¿t há»£p (ii) tá»‘t nháº¥t vá»›i lá»›p
3 trÃªn Devign (cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c +2.0) vÃ  vá»›i lá»›p 1 cho
ReVeal (cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c +0.8). Cáº£i thiá»‡n tá»‘t nháº¥t vá» F1(w)
khá»›p vá»›i lá»›p 3 cho Devign vÃ  vá»›i lá»›p 2 cho ReVeal, nhÆ° Ä‘Æ°á»£c
hiá»ƒn thá»‹ trong HÃ¬nh 4.

Max pooling trÃªn táº¥t cáº£ cÃ¡c token cÃ³ sáºµn tá»« má»™t lá»›p Ä‘Æ°á»£c chá»n
trong káº¿t há»£p (v) cÅ©ng Ä‘áº¡t Ä‘Æ°á»£c cáº£i thiá»‡n hiá»‡u suáº¥t so vá»›i cÆ¡ sá»Ÿ,
nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong hÃ ng 2 vÃ  3 cá»§a HÃ¬nh 3a, 3b. NÃ³i chung,
cÃ¡c lá»›p 4â€“11 mang láº¡i Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n vÃ  cÃ¡c lá»›p 2â€“11
F1(w) cao hÆ¡n vá»›i max pooling cho Devign so vá»›i cÆ¡ sá»Ÿ. Äá»‘i vá»›i
ReVeal, táº¥t cáº£ cÃ¡c lá»›p trá»« lá»›p 11 dáº«n Ä‘áº¿n Ä‘á»™ chÃ­nh xÃ¡c trung
bÃ¬nh tá»‘t hÆ¡n vÃ  cÃ¡c lá»›p 2â€“10 cÃ³ F1(w) trung bÃ¬nh cao hÆ¡n. Max
pooling trÃªn táº¥t cáº£ cÃ¡c token, bao gá»“m cÃ¡c token Ä‘áº·c biá»‡t, Ä‘áº¡t
Ä‘Æ°á»£c cáº£i thiá»‡n cÃ³ Ã½ nghÄ©a thá»‘ng kÃª tá»‘t nháº¥t cá»§a Ä‘á»™ chÃ­nh xÃ¡c
lÃ  +0.9 trong sá»‘ táº¥t cáº£ cÃ¡c káº¿t há»£p cho ReVeal.

Weighted sum cá»§a táº¥t cáº£ cÃ¡c token hoáº·c riÃªng cÃ¡c token mÃ£ trong
káº¿t há»£p (ix) khÃ´ng cáº£i thiá»‡n hiá»‡u suáº¥t cÆ¡ sá»Ÿ. ChÃºng tÃ´i giáº£ Ä‘á»‹nh
ráº±ng fine-tuning trong 10 epoch khÃ´ng Ä‘á»§ cho loáº¡i káº¿t há»£p nÃ y,
vÃ¬ loss táº¡i epoch 10 trÃªn cáº£ pháº§n train vÃ  validation cao hÆ¡n
Ä‘á»‘i vá»›i cÃ¡c káº¿t há»£p (ix) so vá»›i cÃ¡c káº¿t há»£p vá»›i max pooling.
VÃ¬ má»¥c tiÃªu cá»§a nghiÃªn cá»©u nÃ y lÃ  sá»­ dá»¥ng cÃ¹ng hoáº·c Ã­t nguá»“n
lá»±c hÆ¡n Ä‘á»ƒ fine-tuning, chÃºng tÃ´i Ä‘Ã£ khÃ´ng fine-tuning káº¿t há»£p
nÃ y trong hÆ¡n 10 epoch.

Trong khi cÃ¡c káº¿t há»£p (ii) vÃ  (v) hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n cho pháº§n
lá»›n cÃ¡c lá»›p trÃªn nhiá»‡m vá»¥ phÃ¡t hiá»‡n lá»—i, phÃ¢n loáº¡i Ä‘a lá»›p cho
dá»± Ä‘oÃ¡n kiá»ƒu lá»—i hoáº·c ngoáº¡i lá»‡ khÃ´ng hÆ°á»Ÿng lá»£i tá»« cÃ¡c káº¿t há»£p
á»Ÿ má»©c Ä‘á»™ tÆ°Æ¡ng tá»± nhÆ° nhiá»‡m vá»¥ nhá»‹ phÃ¢n. Chá»‰ max pooling
cá»§a cÃ¡c token cá»§a lá»›p encoder cuá»‘i cÃ¹ng Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t
tá»‘t hÆ¡n so vá»›i cÆ¡ sá»Ÿ cho BIFI (cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c +0.1,
cáº£i thiá»‡n Ä‘iá»ƒm F1 cÃ³ trá»ng sá»‘ +0.1) vÃ  Exception Type (cáº£i
thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c +0.2, cáº£i thiá»‡n Ä‘iá»ƒm F1 cÃ³ trá»ng sá»‘ +0.1).

TÃ¡c Ä‘á»™ng cá»§a viá»‡c sá»­ dá»¥ng táº¥t cáº£ cÃ¡c token hoáº·c riÃªng cÃ¡c
token mÃ£ phá»¥ thuá»™c vÃ o táº­p dá»¯ liá»‡u. Sá»± khÃ¡c biá»‡t giá»¯a hiá»‡u
suáº¥t cá»§a cÃ¡c káº¿t há»£p má»™t lá»›p vá»›i max pooling cá»§a táº¥t cáº£ cÃ¡c
token vÃ  chá»‰ cÃ¡c token mÃ£ chiáº¿m 0.0-0.1 Ä‘á»™ chÃ­nh xÃ¡c hoáº·c
F1(w). Äá»‘i vá»›i cÃ¡c nhiá»‡m vá»¥ Ä‘a lá»›p, káº¿t quáº£ trung bÃ¬nh cáº£i
thiá»‡n vá»›i viá»‡c sá»­ dá»¥ng má»—i lá»›p sau trong mÃ´ hÃ¬nh. ChÃºng tÃ´i
cÃ³ Ä‘Æ°á»£c cáº£i thiá»‡n hiá»‡u suáº¥t vá»›i káº¿t há»£p max pooling (v), trong
khi cÃ¡c káº¿t há»£p má»™t lá»›p khÃ¡c khÃ´ng hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n cÆ¡ sá»Ÿ.

Káº¿t quáº£ hoáº¡t Ä‘á»™ng tá»‘t nháº¥t trÃªn cÃ¡c táº­p dá»¯ liá»‡u Devign vÃ 
Exception Type classification cÃ³ Ã½ nghÄ©a thá»‘ng kÃª theo kiá»ƒm
Ä‘á»‹nh Wilcoxon. Äá»‘i vá»›i ReVeal, káº¿t quáº£ tá»‘t thá»© hai cÃ³ Ã½ nghÄ©a
thá»‘ng kÃª. ChÃºng tÃ´i chÆ°a cÃ³ Ä‘Æ°á»£c cáº£i thiá»‡n cÃ³ Ã½ nghÄ©a thá»‘ng
kÃª cho BIFI. ChÃºng tÃ´i giáº£i thÃ­ch Ä‘iá»u nÃ y bá»Ÿi thá»±c táº¿ lÃ  chá»‰
sá»‘ cÆ¡ sá»Ÿ Ä‘Ã£ cao, tá»©c lÃ  Ä‘á»™ chÃ­nh xÃ¡c 96.7. Viá»‡c Ä‘áº¡t Ä‘Æ°á»£c cáº£i
thiá»‡n thÆ°á»ng khÃ³ khÄƒn hÆ¡n khi cÆ¡ sá»Ÿ hoáº¡t Ä‘á»™ng á»Ÿ má»©c nÃ y.

Vá» báº£n cháº¥t, cÃ¡c káº¿t há»£p liÃªn quan Ä‘áº¿n token CLS tÆ°Æ¡ng á»©ng
vá»›i lá»›p Ä‘Æ¡n láº» (ii), cÅ©ng nhÆ° cÃ¡c káº¿t há»£p max pooling (v)
hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n trung bÃ¬nh cho cÃ¡c táº­p dá»¯ liá»‡u phÃ¡t hiá»‡n
lá»—i Devign vÃ  Reveal. Tuy nhiÃªn, chá»‰ káº¿t há»£p max pooling (v)
cá»§a cÃ¡c token tá»« lá»›p encoder cuá»‘i cÃ¹ng vÆ°á»£t trá»™i hÆ¡n cÆ¡ sá»Ÿ
trung bÃ¬nh cho cÃ¡c táº­p dá»¯ liá»‡u Ä‘a lá»›p BIFI vÃ  Exception Type.
Weighted sum cá»§a cÃ¡c token tá»« má»™t lá»›p Ä‘Æ°á»£c chá»n (ix) hoáº¡t
Ä‘á»™ng tá»‡ hÆ¡n cÆ¡ sá»Ÿ náº¿u Ä‘Æ°á»£c fine-tuning trong cÃ¹ng sá»‘ epoch
cho táº¥t cáº£ cÃ¡c nhiá»‡m vá»¥. CÃ¡c nhiá»‡m vá»¥ phÃ¢n loáº¡i Ä‘a lá»›p yÃªu
cáº§u thÃ´ng tin tá»« lá»›p cuá»‘i cÃ¹ng Ä‘á»ƒ cÃ³ hiá»‡u suáº¥t tá»‘t hÆ¡n trong
cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i, trong khi nhiá»‡m vá»¥ nhá»‹ phÃ¢n
cá»§a phÃ¡t hiá»‡n lá»—i cho phÃ©p chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c lá»›p Ä‘áº§u
vÃ  cáº£i thiá»‡n hiá»‡u suáº¥t so vá»›i cÆ¡ sá»Ÿ.

[HÃ¬nh 3: Sá»± khÃ¡c biá»‡t vá» Ä‘á»™ chÃ­nh xÃ¡c trung bÃ¬nh giá»¯a EarlyBIRD
vÃ  hiá»‡u suáº¥t cÆ¡ sá»Ÿ (bsln). Dáº¥u sao âˆ— chá»‰ ra sá»± khÃ¡c biá»‡t cÃ³ Ã½
nghÄ©a thá»‘ng kÃª so vá»›i cÆ¡ sá»Ÿ.]

6.1.2 Káº¿t Há»£p Äa Lá»›p. Sá»± khÃ¡c biá»‡t hiá»‡u suáº¥t trung bÃ¬nh vá»›i
cÆ¡ sá»Ÿ cá»§a cÃ¡c káº¿t há»£p sá»­ dá»¥ng cÃ¡c lá»›p Ä‘áº§u Ä‘Æ°á»£c hiá»ƒn thá»‹
nhÆ° báº£n Ä‘á»“ nhiá»‡t trong HÃ¬nh 5 vÃ  6. ChÃºng tÃ´i bao gá»“m giÃ¡
trá»‹ cá»§a sá»± khÃ¡c biá»‡t hiá»‡u suáº¥t trung bÃ¬nh vÃ  thÃªm dáº¥u sao (âˆ—)
vÃ o sá»‘ náº¿u sá»± khÃ¡c biá»‡t cÃ³ Ã½ nghÄ©a thá»‘ng kÃª. Má»™t láº§n ná»¯a,
cÃ¡c giÃ¡ trá»‹ Ã¢m Ä‘Æ°á»£c hiá»ƒn thá»‹ mÃ u Ä‘en, vÃ  cÃ¡c giÃ¡ trá»‹ dÆ°Æ¡ng
Ä‘Æ°á»£c hiá»ƒn thá»‹ mÃ u tráº¯ng.

Khi chÃºng tÃ´i sá»­ dá»¥ng táº¥t cáº£ thÃ´ng tin tá»« cÃ¡c lá»›p cÃ³ sáºµn, cáº£i
thiá»‡n so vá»›i cÆ¡ sá»Ÿ Ã­t hÆ¡n so vá»›i nhá»¯ng gÃ¬ quan sÃ¡t Ä‘Æ°á»£c trong
Má»¥c 6.1.1, nÆ¡i má»™t lá»›p Ä‘áº§u cá»¥ thá»ƒ Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng. Chi tiáº¿t,
trong sá»‘ cÃ¡c káº¿t há»£p liÃªn quan Ä‘áº¿n token CLS tá»« táº¥t cáº£ cÃ¡c
lá»›p Ä‘áº§u, khÃ´ng cÃ³ káº¿t há»£p nÃ o hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n cÆ¡ sá»Ÿ cho
ReVeal, BIFI, hoáº·c Exception Type. Tuy nhiÃªn, cáº£i thiá»‡n tá»‘t
nháº¥t (+0.6 Ä‘á»™ chÃ­nh xÃ¡c) trong sá»‘ cÃ¡c thÃ­ nghiá»‡m vá»›i táº¥t cáº£
cÃ¡c lá»›p Ä‘Æ°á»£c cÃ³ Ä‘Æ°á»£c trÃªn Devign vá»›i weighted sum cá»§a cÃ¡c
token CLS trong káº¿t há»£p (iv), Ã­t hÆ¡n so vá»›i cáº£i thiá»‡n tá»‘i Ä‘a
vá»›i cÃ¡c káº¿t há»£p tá»« má»™t lá»›p Ä‘áº§u Ä‘Æ°á»£c chá»n trong Má»¥c 6.1.1.
Cáº£i thiá»‡n cá»§a F1(w) Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 6. ChÃºng tÃ´i
cÃ³ Ä‘Æ°á»£c cáº£i thiá»‡n F1(w) hÆ¡i tá»‘t hÆ¡n cho Devign, khÃ´ng cÃ³
cáº£i thiá»‡n F1(w) cho táº­p dá»¯ liá»‡u ReVeal khÃ´ng cÃ¢n báº±ng. Sá»±
khÃ¡c biá»‡t F1(w) trung bÃ¬nh vá»›i cÆ¡ sá»Ÿ cho cÃ¡c nhiá»‡m vá»¥ Ä‘a
lá»›p giá»‘ng vá»›i sá»± khÃ¡c biá»‡t Ä‘á»™ chÃ­nh xÃ¡c.

Náº¿u chÃºng tÃ´i xem xÃ©t cÃ¡c káº¿t há»£p liÃªn quan Ä‘áº¿n táº¥t cáº£ cÃ¡c
token, káº¿t há»£p (vi) vá»›i hai phÃ©p toÃ¡n max pooling vÆ°á»£t trá»™i
hÆ¡n cÆ¡ sá»Ÿ cho Devign, Reveal, vÃ  BIFI vá»›i cáº£i thiá»‡n Ä‘á»™ chÃ­nh
xÃ¡c tá»« +0.1 Ä‘áº¿n +0.3. KhÃ´ng cÃ³ káº¿t há»£p nÃ o liÃªn quan Ä‘áº¿n
táº¥t cáº£ cÃ¡c lá»›p vÆ°á»£t trá»™i hÆ¡n cÆ¡ sá»Ÿ trung bÃ¬nh cho táº­p dá»¯ liá»‡u
Exception Type.

CÃ¡c káº¿t há»£p liÃªn quan Ä‘áº¿n má»™t max pooling vÃ  má»™t weighted
sum cá»§a táº¥t cáº£ cÃ¡c token hoáº¡t Ä‘á»™ng tá»‡ hÆ¡n hoáº·c trung tÃ­nh
so vá»›i cÆ¡ sá»Ÿ. CÃ¡c káº¿t há»£p chá»‰ vá»›i weighted sum hoáº¡t Ä‘á»™ng
tá»‡ hÆ¡n cÆ¡ sá»Ÿ trung bÃ¬nh.

Tráº£ lá»i RQ1. EarlyBIRD Ä‘áº¡t Ä‘Æ°á»£c cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c vÃ 
Ä‘iá»ƒm F1 cÃ³ Ã½ nghÄ©a thá»‘ng kÃª cho cÃ¡c táº­p dá»¯ liá»‡u phÃ¡t hiá»‡n
lá»—i báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c káº¿t há»£p má»™t lá»›p liÃªn quan Ä‘áº¿n
token CLS hoáº·c max pooling trÃªn táº¥t cáº£ cÃ¡c token. Äá»‘i vá»›i
phÃ¢n loáº¡i kiá»ƒu lá»—i vÃ  kiá»ƒu ngoáº¡i lá»‡, max pooling cá»§a cÃ¡c
token tá»« lá»›p encoder cuá»‘i cÃ¹ng Ä‘Ã£ cáº£i thiá»‡n hiá»‡u suáº¥t.
Weighted sum cá»§a cÃ¡c token khÃ´ng cáº£i thiá»‡n hiá»‡u suáº¥t so
vá»›i cÆ¡ sá»Ÿ.

6.2 MÃ´ HÃ¬nh ÄÆ°á»£c Cáº¯t Tá»‰a
Pháº§n nÃ y dÃ nh cho cÃ¡c káº¿t há»£p cá»§a cÃ¡c lá»›p Ä‘áº§u Ä‘Æ°á»£c khá»Ÿi
táº¡o vá»›i ğ‘™<ğ¿ lá»›p Ä‘áº§u tiÃªn tá»« mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c
vÃ  Ä‘Æ°á»£c fine-tuning nhÆ° cÃ¡c mÃ´ hÃ¬nh ğ‘™ lá»›p â€” cÃ¡c káº¿t há»£p (xii).
ChÃºng tÃ´i báº¯t Ä‘áº§u báº±ng cÃ¡ch so sÃ¡nh hiá»‡u suáº¥t cá»§a viá»‡c sá»­
dá»¥ng token CLS tá»« lá»›p ğ‘™ cá»§a mÃ´ hÃ¬nh toÃ n kÃ­ch thÆ°á»›c, tá»©c
lÃ  káº¿t há»£p (ii), vÃ  sá»­ dá»¥ng token CLS tá»« lá»›p ğ‘™ cá»§a mÃ´ hÃ¬nh
cÃ³ tá»•ng cá»™ng ğ‘™ lá»›p â€” káº¿t há»£p (xii). HÃ¬nh 7 trÃ¬nh bÃ y Ä‘á»™ chÃ­nh
xÃ¡c trung bÃ¬nh thu Ä‘Æ°á»£c vá»›i hai káº¿t há»£p nÃ y tÃ¹y thuá»™c vÃ o
lá»›p Ä‘Æ°á»£c sá»­ dá»¥ng, cÅ©ng nhÆ° káº¿t há»£p cÆ¡ sá»Ÿ cá»§a viá»‡c sá»­ dá»¥ng
CLS tá»« lá»›p cuá»‘i cÃ¹ng ğ¿=12 cá»§a CodeBERT. Trung bÃ¬nh, cÃ¡c
mÃ´ hÃ¬nh Ä‘Æ°á»£c cáº¯t tá»‰a vá»›i kÃ­ch thÆ°á»›c giáº£m hoáº¡t Ä‘á»™ng ngang
báº±ng vá»›i mÃ´ hÃ¬nh toÃ n kÃ­ch thÆ°á»›c cho phÃ¡t hiá»‡n lá»—i trÃªn táº­p
dá»¯ liá»‡u Devign cÃ¢n báº±ng, vÃ  cho phÃ¢n loáº¡i kiá»ƒu lá»—i vÃ  kiá»ƒu
ngoáº¡i lá»‡. Tuy nhiÃªn, hiá»‡u suáº¥t cá»§a hai káº¿t há»£p tÆ°Æ¡ng tá»± phÃ¢n
ká»³ cho táº­p dá»¯ liá»‡u phÃ¡t hiá»‡n lá»—i ReVeal khÃ´ng cÃ¢n báº±ng trong
cÃ¡c lá»›p 4 vÃ  6â€“11.

Quan trá»ng nháº¥t, káº¿t quáº£ cho tháº¥y viá»‡c giáº£m kÃ­ch thÆ°á»›c mÃ´
hÃ¬nh vÃ  sá»­ dá»¥ng token CLS tá»« lá»›p cuá»‘i cÃ¹ng cá»§a mÃ´ hÃ¬nh
giáº£m hoáº¡t Ä‘á»™ng ngang báº±ng vá»›i cÆ¡ sá»Ÿ cho nhiá»‡m vá»¥ phÃ¡t hiá»‡n
lá»—i. Cáº£i thiá»‡n tá»‘t nháº¥t vá»›i mÃ´ hÃ¬nh giáº£m Ä‘áº¡t Ä‘Æ°á»£c vá»›i encoder
3 lá»›p cho Devign vÃ  encoder 1 lá»›p cho ReVeal. Káº¿t quáº£ nÃ y
cho tháº¥y cÃ³ thá»ƒ vá»«a giáº£m nguá»“n lá»±c vá»«a cáº£i thiá»‡n hiá»‡u suáº¥t
cá»§a mÃ´ hÃ¬nh trong quÃ¡ trÃ¬nh fine-tuning trÃªn nhiá»‡m vá»¥ phÃ¡t
hiá»‡n lá»—i vá»›i cáº£ táº­p dá»¯ liá»‡u cÃ¢n báº±ng vÃ  khÃ´ng cÃ¢n báº±ng.

Äá»ƒ khÃ¡m phÃ¡ sá»± Ä‘Ã¡nh Ä‘á»•i giá»¯a viá»‡c sá»­ dá»¥ng nguá»“n lá»±c vÃ 
suy giáº£m hiá»‡u suáº¥t cho viá»‡c nháº­n dáº¡ng kiá»ƒu lá»—i vÃ  kiá»ƒu ngoáº¡i
lá»‡, chÃºng tÃ´i hiá»ƒn thá»‹ tá»‘c Ä‘á»™ tÄƒng tá»‘c trung bÃ¬nh cá»§a má»™t
epoch fine-tuning vÃ  máº¥t hiá»‡u suáº¥t so vá»›i cÆ¡ sá»Ÿ cho cÃ¡c táº­p
dá»¯ liá»‡u BIFI vÃ  Exception Type trong Báº£ng 2. ChÃºng tÃ´i cÅ©ng
bÃ¡o cÃ¡o cÃ¡c giÃ¡ trá»‹ tÆ°Æ¡ng á»©ng cho Devign vÃ  ReVeal, mÃ  cáº£
cáº£i thiá»‡n vÃ  máº¥t hiá»‡u suáº¥t Ä‘á»u Ä‘Æ°á»£c chá»‰ ra. Tá»‘c Ä‘á»™ tÄƒng tá»‘c
Ä‘Æ°á»£c bÃ¡o cÃ¡o nhÆ° há»‡ sá»‘ tá»· lá»‡ cá»§a thá»i gian cÆ¡ sá»Ÿ. Sá»± khÃ¡c
biá»‡t chá»‰ sá»‘ Ä‘Æ°á»£c hiá»ƒn thá»‹ nhÆ° cáº£i thiá»‡n hoáº·c máº¥t cá»§a Ä‘iá»ƒm
F1 cÃ³ trá»ng sá»‘ vÃ  Ä‘á»™ chÃ­nh xÃ¡c so vá»›i hiá»‡u suáº¥t cÆ¡ sá»Ÿ. Cáº£i
thiá»‡n cÃ³ Ã½ nghÄ©a thá»‘ng kÃª Ä‘Æ°á»£c bÃ¡o cÃ¡o in Ä‘áº­m, trong khi
máº¥t khÃ´ng cÃ³ Ã½ nghÄ©a thá»‘ng kÃª Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u báº±ng dáº¥u sao (âˆ—).
KÃ­ch thÆ°á»›c hiá»‡u á»©ng ğ´12 Ä‘Æ°á»£c chá»‰ ra bá»Ÿi ba sáº¯c thÃ¡i mÃ u
xanh lÃ m mÃ u Ã´, vá»›i sáº¯c thÃ¡i tá»‘i nháº¥t chá»‰ ra hiá»‡u á»©ng lá»›n
( ğ´12>0.71), sáº¯c thÃ¡i giá»¯a chá»‰ ra hiá»‡u á»©ng trung bÃ¬nh ( ğ´12>0.64),
vÃ  sáº¯c thÃ¡i nháº¡t nháº¥t chá»‰ ra hiá»‡u á»©ng nhá» ( ğ´12>0.56). ChÃºng
tÃ´i cÅ©ng gáº¡ch dÆ°á»›i vÃ  tháº£o luáº­n cÃ¡c káº¿t quáº£ Ä‘Æ°á»£c chá»n cáº£i
thiá»‡n giÃ¡ trá»‹ chá»‰ sá»‘ vÃ  giáº£m viá»‡c sá»­ dá»¥ng nguá»“n lá»±c.

[HÃ¬nh 7: Hiá»‡u suáº¥t mÃ´ hÃ¬nh vá»›i táº­p con ğ‘™<ğ¿ lá»›p (xii) so vá»›i
mÃ´ hÃ¬nh vá»›i táº¥t cáº£ cÃ¡c lá»›p (ii); token CLS tá»« lá»›p ğ‘™.]

Pháº§n lá»›n cÃ¡c káº¿t há»£p (xii) vá»›i mÃ´ hÃ¬nh Ä‘Æ°á»£c cáº¯t tá»‰a vÆ°á»£t trá»™i
hÆ¡n cÆ¡ sá»Ÿ cho Devign vÃ  ReVeal. HÆ¡n ná»¯a, cÃ¡c mÃ´ hÃ¬nh vá»›i
2â€“10 lá»›p cho tháº¥y cáº£i thiá»‡n cÃ³ Ã½ nghÄ©a thá»‘ng kÃª cá»§a cáº£ hai
chá»‰ sá»‘ trÃªn Devign, vá»›i mÃ´ hÃ¬nh 3 lá»›p Ä‘áº¡t Ä‘Æ°á»£c cáº£i thiá»‡n
Ä‘á»™ chÃ­nh xÃ¡c +2 vá»›i tÄƒng tá»‘c fine-tuning 3.3 láº§n trung bÃ¬nh
vá»›i cÃ¹ng pháº§n cá»©ng vÃ  pháº§n má»m. KhÃ´ng chá»‰ mÃ´ hÃ¬nh 3 lá»›p
cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c so vá»›i cÆ¡ sá»Ÿ CodeBERT lÃªn 63.7, mÃ 
cÃ²n vÆ°á»£t trá»™i hÆ¡n má»™t sá»‘ mÃ´ hÃ¬nh khÃ¡c Ä‘Æ°á»£c kiá»ƒm tra trÃªn
Devign vÃ  Ä‘Æ°á»£c bÃ¡o cÃ¡o trÃªn chuáº©n má»±c CodeXGLUE [ 27].
Cá»¥ thá»ƒ, mÃ´ hÃ¬nh CodeBERT 3 lá»›p Ä‘Æ°á»£c cáº¯t tá»‰a cá»§a chÃºng tÃ´i
vÆ°á»£t trá»™i hÆ¡n mÃ´ hÃ¬nh transformer Ä‘áº§y Ä‘á»§ PLBART [ 1], vÃ 
biá»ƒu diá»…n mÃ£ code2vec Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c trÃªn cÃ¢y cÃº
phÃ¡p trá»«u tÆ°á»£ng vÃ  token mÃ£ theo cÃ¡ch liÃªn káº¿t [ 1]. Tuy nhiÃªn,
mÃ´ hÃ¬nh Ä‘Æ°á»£c cáº¯t tá»‰a cá»§a chÃºng tÃ´i khÃ´ng vÆ°á»£t trá»™i hÆ¡n mÃ´
hÃ¬nh hoáº¡t Ä‘á»™ng tá»‘t nháº¥t Ä‘Æ°á»£c bÃ¡o cÃ¡o trÃªn CodeXGLUE, CoText,
Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c 66.62 [34].

CÃ¡c mÃ´ hÃ¬nh vá»›i 1 vÃ  11 lá»›p Ä‘áº¡t Ä‘Æ°á»£c cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c
cÃ³ Ã½ nghÄ©a thá»‘ng kÃª cho ReVeal. Tuy nhiÃªn, mÃ´ hÃ¬nh 1 lá»›p
giáº£m Ä‘iá»ƒm F1(w). Viá»‡c sá»­ dá»¥ng lá»›p 11 khÃ´ng tÃ¡c Ä‘á»™ng Ä‘áº¿n
tá»‘c Ä‘á»™ fine-tuning, trong khi mÃ´ hÃ¬nh 1 lá»›p mang láº¡i tÄƒng
tá»‘c 3.7x cá»§a tá»‘c Ä‘á»™ fine-tuning cÆ¡ sá»Ÿ. Viá»‡c thiáº¿u tÄƒng tá»‘c
vá»›i mÃ´ hÃ¬nh 11 lá»›p cÃ³ thá»ƒ Ä‘Æ°á»£c giáº£i thÃ­ch bá»Ÿi thá»±c táº¿ lÃ  sá»‘
lÆ°á»£ng tham sá»‘ cÃ³ thá»ƒ huáº¥n luyá»‡n khÃ´ng giáº£m tuyáº¿n tÃ­nh vá»›i
viá»‡c loáº¡i bá» cÃ¡c lá»›p sau, vÃ¬ lá»›p embedding bá»• sung vÃ  Ä‘áº§u
phÃ¢n loáº¡i váº«n khÃ´ng thay Ä‘á»•i. MÃ´ hÃ¬nh 2 lá»›p dáº«n Ä‘áº¿n cáº£i
thiá»‡n tá»‘t nháº¥t cá»§a F1(w) cÃ³ Ã½ nghÄ©a thá»‘ng kÃª. MÃ´ hÃ¬nh 2
lá»›p cÅ©ng cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c trÃªn ReVeal. Äá»‘i vá»›i Devign
vÃ  ReVeal, cÃ¡c cáº£i thiá»‡n cÃ³ Ã½ nghÄ©a thá»‘ng kÃª cÃ³ kÃ­ch thÆ°á»›c
hiá»‡u á»©ng lá»›n.

Äá»‘i vá»›i BIFI, chÃºng tÃ´i cÃ³ Ä‘Æ°á»£c giáº£m khÃ´ng cÃ³ Ã½ nghÄ©a thá»‘ng
kÃª cá»§a F1(w) vÃ  Ä‘á»™ chÃ­nh xÃ¡c theo kiá»ƒm Ä‘á»‹nh Wilcoxon mang
láº¡i tÄƒng tá»‘c 1.2x cá»§a fine-tuning vá»›i mÃ´ hÃ¬nh 11 lá»›p. Náº¿u
chÃºng tÃ´i giáº£m sá»‘ lÆ°á»£ng lá»›p xuá»‘ng 8, hiá»‡u suáº¥t trÃªn BIFI
váº«n trong giá»›i háº¡n (chá»‰ sá»‘ cÆ¡ sá»Ÿ âˆ’1), nhÆ°ng chÃºng tÃ´i cÃ³
Ä‘Æ°á»£c tá»‘i Ä‘a 1.7x tÄƒng tá»‘c trung bÃ¬nh cá»§a fine-tuning má»™t
epoch. Trong trÆ°á»ng há»£p sá»­ dá»¥ng mÃ´ hÃ¬nh vá»›i 1â€“10 lá»›p,
chÃºng tÃ´i quan sÃ¡t tháº¥y thay Ä‘á»•i cÃ³ Ã½ nghÄ©a thá»‘ng kÃª cá»§a
phÃ¢n phá»‘i vÃ  giáº£m giÃ¡ trá»‹ chá»‰ sá»‘.

Äá»‘i vá»›i táº­p dá»¯ liá»‡u Exception Type khÃ´ng cÃ¢n báº±ng, hiá»‡u suáº¥t
giáº£m nhanh hÆ¡n vÃ  tÄƒng tá»‘c Ã­t ná»•i báº­t hÆ¡n so vá»›i BIFI. Thay
Ä‘á»•i giÃ¡ trá»‹ trung bÃ¬nh cá»§a cÃ¡c chá»‰ sá»‘ cho táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh
cÃ³ Ã½ nghÄ©a thá»‘ng kÃª. Chi tiáº¿t, cÃ¡c chá»‰ sá»‘ giáº£m -1.0 giÃ¡ trá»‹
chá»‰ sá»‘ tuyá»‡t Ä‘á»‘i táº¡i 11 lá»›p vá»›i tÄƒng tá»‘c fine-tuning 1.1x vÃ 
-1.8 vá»›i 10 lá»›p vá»›i tÄƒng tá»‘c 1.2x. ChÃºng tÃ´i giáº£i thÃ­ch sá»±
suy giáº£m máº¡nh hÆ¡n cá»§a hiá»‡u suáº¥t káº¿t há»£p bá»Ÿi cÃ¡c giÃ¡ trá»‹
chá»‰ sá»‘ cÆ¡ sá»Ÿ tháº¥p hÆ¡n (75.39 Ä‘á»™ chÃ­nh xÃ¡c, 75.30 Ä‘iá»ƒm F1
cÃ³ trá»ng sá»‘) so vá»›i trÆ°á»ng há»£p BIFI (96.7 Ä‘á»™ chÃ­nh xÃ¡c vÃ 
Ä‘iá»ƒm F1 cÃ³ trá»ng sá»‘). Äá»‘i vá»›i BIFI, suy giáº£m khÃ´ng cÃ³ Ã½
nghÄ©a thá»‘ng kÃª cÃ³ kÃ­ch thÆ°á»›c hiá»‡u á»©ng nhá». Tuy nhiÃªn, Ä‘á»‘i
vá»›i cáº£ táº­p dá»¯ liá»‡u BIFI vÃ  Exception Type, chÃºng tÃ´i quan sÃ¡t
tháº¥y suy giáº£m hiá»‡u suáº¥t cÃ³ kÃ­ch thÆ°á»›c hiá»‡u á»©ng lá»›n vá»›i cÃ¡c
mÃ´ hÃ¬nh Ä‘Æ°á»£c cáº¯t tá»‰a.

ChÃºng tÃ´i káº¿t luáº­n ráº±ng Ä‘á»‘i vá»›i táº­p dá»¯ liá»‡u BIFI vá»›i cÆ¡ sá»Ÿ
hoáº¡t Ä‘á»™ng tá»‘t vÃ  3 lá»›p, máº¥t hiá»‡u suáº¥t khi loáº¡i bá» má»—i lá»›p
Ã­t hÆ¡n so vá»›i táº­p dá»¯ liá»‡u phÃ¢n loáº¡i Exception Type vá»›i hiá»‡u
suáº¥t cÆ¡ sá»Ÿ tháº¥p hÆ¡n vÃ  20 lá»›p. Viá»‡c sá»­ dá»¥ng nguá»“n lá»±c,
tÆ°Æ¡ng quan vá»›i thá»i gian dÃ nh cho Ä‘iá»u chá»‰nh, giáº£m nhanh
hÆ¡n Ä‘á»‘i vá»›i BIFI so vá»›i Exception Type. Äiá»u nÃ y má»™t pháº§n
Ä‘Æ°á»£c giáº£i thÃ­ch bá»Ÿi Ä‘áº§u phÃ¢n loáº¡i lá»›n hÆ¡n cho táº­p dá»¯ liá»‡u
Exception Type, vÃ¬ táº­p dá»¯ liá»‡u nÃ y cÃ³ 20 lá»›p trÃ¡i ngÆ°á»£c vá»›i
chá»‰ 3 lá»›p trong BIFI. NÃ³i cÃ¡ch khÃ¡c, chÃºng tÃ´i quan sÃ¡t ráº±ng
táº­p dá»¯ liá»‡u BIFI cÃ³ cÆ¡ sá»Ÿ máº¡nh khÃ³ vÆ°á»£t trá»™i hÆ¡n vá»›i cáº¯t tá»‰a.
NgÆ°á»£c láº¡i, Ä‘á»™ phá»©c táº¡p cá»§a táº­p dá»¯ liá»‡u Exception Type cÃ³
thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n káº¿t quáº£ theo hÆ°á»›ng ngÆ°á»£c láº¡i: Hiá»‡u suáº¥t
cÆ¡ sá»Ÿ Ä‘Ã£ khÃ´ng máº¡nh láº¯m, vÃ  khÃ³ cáº£i thiá»‡n thÃªm vá»›i chá»‰
cÃ¡c lá»›p Ä‘áº§u.

Tráº£ lá»i RQ2. ChÃºng tÃ´i cÃ³ Ä‘Æ°á»£c cáº£i thiá»‡n hiá»‡u suáº¥t so vá»›i
cÆ¡ sá»Ÿ cÅ©ng nhÆ° tÄƒng tá»‘c fine-tuning cho cáº£ hai táº­p dá»¯ liá»‡u
phÃ¡t hiá»‡n lá»—i báº±ng cÃ¡ch sá»­ dá»¥ng token CLS tá»« lá»›p cuá»‘i cÃ¹ng
cá»§a mÃ´ hÃ¬nh Ä‘Æ°á»£c cáº¯t tá»‰a. Äá»‘i vá»›i phÃ¢n loáº¡i Ä‘a lá»›p, hiá»‡u suáº¥t
giáº£m khi cáº¯t tá»‰a má»—i lá»›p tá»« cuá»‘i mÃ´ hÃ¬nh. Sá»± giáº£m máº¡nh
hÆ¡n Ä‘á»‘i vá»›i táº­p dá»¯ liá»‡u vá»›i 20 kiá»ƒu ngoáº¡i lá»‡ so vá»›i nhiá»‡m
vá»¥ vá»›i 3 kiá»ƒu lá»—i.

6.3 CÃ¡c Má»‘i Äe Dá»a Äá»‘i Vá»›i TÃ­nh Há»£p Lá»‡
Má»‘i Ä‘e dá»a chÃ­nh Ä‘á»‘i vá»›i tÃ­nh há»£p lá»‡ bÃªn ngoÃ i lÃ  káº¿t quáº£
mang tÃ­nh thá»±c nghiá»‡m vÃ  cÃ³ thá»ƒ khÃ´ng tá»•ng quÃ¡t hÃ³a cho
táº¥t cáº£ cÃ¡c thiáº¿t láº­p phÃ¢n loáº¡i mÃ£, bao gá»“m cÃ¡c ngÃ´n ngá»¯ láº­p
trÃ¬nh, nhiá»‡m vá»¥, vÃ  mÃ´ hÃ¬nh dá»±a trÃªn encoder cho mÃ£ khÃ¡c.
ChÃºng tÃ´i Ä‘Ã£ kiá»ƒm tra cÃ¡c káº¿t há»£p EarlyBIRD trÃªn mÃ£ trong
C Ä‘á»ƒ phÃ¡t hiá»‡n lá»—i vÃ  Python cho phÃ¢n loáº¡i kiá»ƒu lá»—i vÃ  kiá»ƒu
ngoáº¡i lá»‡ trong nghiÃªn cá»©u nÃ y. Viá»‡c lá»±a chá»n CodeBERT lÃ m
mÃ´ hÃ¬nh encoder vÃ  cáº¥u trÃºc bÃªn trong cá»§a nÃ³ áº£nh hÆ°á»Ÿng
Ä‘áº¿n káº¿t quáº£. VÃ­ dá»¥, má»™t mÃ´ hÃ¬nh encoder nháº­n chuá»—i Ä‘áº§u
vÃ o nhá» hÆ¡n cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng tá»‡ hÆ¡n trÃªn cÃ¹ng cÃ¡c táº­p dá»¯
liá»‡u, vÃ¬ cÃ¡c pháº§n lá»›n hÆ¡n cá»§a chuá»—i mÃ£ Ä‘áº§u vÃ o pháº£i Ä‘Æ°á»£c
cáº¯t bá» trong trÆ°á»ng há»£p nÃ y. TÃ­nh há»£p lá»‡ bÃªn ngoÃ i cÃ³ thá»ƒ
Ä‘Æ°á»£c cáº£i thiá»‡n báº±ng cÃ¡ch kiá»ƒm tra trÃªn nhiá»u táº­p dá»¯ liá»‡u
vÃ  mÃ´ hÃ¬nh encoder hÆ¡n.

CÃ¡c má»‘i Ä‘e dá»a Ä‘á»‘i vá»›i tÃ­nh há»£p lá»‡ bÃªn trong liÃªn quan Ä‘áº¿n
sá»± phá»¥ thuá»™c cá»§a mÃ´ hÃ¬nh vÃ o viá»‡c khá»Ÿi táº¡o cÃ¡c tham sá»‘
cÃ³ thá»ƒ huáº¥n luyá»‡n vÃ  viá»‡c lá»±a chá»n phÆ°Æ¡ng phÃ¡p. Äáº§u phÃ¢n
loáº¡i vÃ  weighted sum vá»›i cÃ¡c tham sá»‘ cÃ³ thá»ƒ huáº¥n luyá»‡n
trong cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i phá»¥ thuá»™c vÃ o viá»‡c khá»Ÿi
táº¡o cÃ¡c tham sá»‘ vÃ  cÃ³ thá»ƒ dáº«n mÃ´ hÃ¬nh Ä‘áº¿n cÃ¡c cá»±c tiá»ƒu
Ä‘á»‹a phÆ°Æ¡ng khÃ¡c nhau trong quÃ¡ trÃ¬nh fine-tuning. Äá»ƒ giáº£m
tÃ¡c Ä‘á»™ng cá»§a cÃ¡c khá»Ÿi táº¡o ngáº«u nhiÃªn khÃ¡c nhau, chÃºng tÃ´i
Ä‘Ã£ fine-tuning vÃ  kiá»ƒm tra táº¥t cáº£ cÃ¡c káº¿t há»£p EarlyBIRD 10
láº§n vá»›i cÃ¡c seed ngáº«u nhiÃªn khÃ¡c nhau.

NgoÃ i ra, chÃºng tÃ´i Ä‘Ã£ sá»­ dá»¥ng kiá»ƒm Ä‘á»‹nh Wilcoxon Ä‘á»ƒ xÃ¡c
minh liá»‡u cÃ¡c cáº£i thiá»‡n Ä‘áº¡t Ä‘Æ°á»£c cÃ³ Ã½ nghÄ©a thá»‘ng kÃª. Tuy
nhiÃªn, kiá»ƒm Ä‘á»‹nh Wilcoxon chá»‰ Æ°á»›c tÃ­nh liá»‡u cÃ¡c phÃ©p Ä‘o
cá»§a giÃ¡ trá»‹ cÆ¡ sá»Ÿ vÃ  káº¿t há»£p EarlyBIRD cÃ³ Ä‘Æ°á»£c rÃºt ra tá»«
cÃ¡c phÃ¢n phá»‘i khÃ¡c nhau. Thá»i gian Ä‘Æ°á»£c bÃ¡o cÃ¡o dÃ nh cho
fine-tuning vÃ  cÃ¡c tÄƒng tá»‘c tÆ°Æ¡ng á»©ng cÃ³ má»¥c Ä‘Ã­ch minh
há»a sá»± giáº£m trong viá»‡c sá»­ dá»¥ng nguá»“n lá»±c, vÃ  sáº½ phá»¥ thuá»™c
vÃ o pháº§n cá»©ng Ä‘Æ°á»£c sá»­ dá»¥ng. Ngay cáº£ khi sá»­ dá»¥ng cÃ¡c há»‡
sá»‘ tÄƒng tá»‘c cho cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c cáº¯t tá»‰a, cÃ³ kháº£ nÄƒng nhá»¯ng
sá»‘ nÃ y sáº½ khÃ¡c trÃªn cÃ¡c cáº¥u hÃ¬nh pháº§n cá»©ng khÃ¡c.

ChÃºng tÃ´i Ä‘Ã£ triá»ƒn khai cÃ¡c thuáº­t toÃ¡n vÃ  quy trÃ¬nh thá»‘ng
kÃª trong Python, vá»›i sá»± trá»£ giÃºp cá»§a cÃ¡c thÆ° viá»‡n Ä‘Æ°á»£c sá»­
dá»¥ng rá»™ng rÃ£i nhÆ° PyTorch, NumPy vÃ  SciPy. Tuy nhiÃªn,
chÃºng tÃ´i khÃ´ng thá»ƒ Ä‘áº£m báº£o khÃ´ng cÃ³ lá»—i triá»ƒn khai cÃ³ thá»ƒ
áº£nh hÆ°á»Ÿng Ä‘áº¿n Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i.

7 Káº¾T LUáº¬N
Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i Ä‘Ã£ Ä‘á» xuáº¥t EarlyBIRD, má»™t
phÆ°Æ¡ng phÃ¡p káº¿t há»£p cÃ¡c lá»›p Ä‘áº§u cá»§a mÃ´ hÃ¬nh encoder cho
mÃ£, vÃ  kiá»ƒm tra cÃ¡c káº¿t há»£p lá»›p Ä‘áº§u khÃ¡c nhau trÃªn cÃ¡c
nhiá»‡m vá»¥ ká»¹ thuáº­t pháº§n má»m cá»§a phÃ¡t hiá»‡n lá»—i, phÃ¢n loáº¡i
kiá»ƒu lá»—i vÃ  kiá»ƒu ngoáº¡i lá»‡. NghiÃªn cá»©u cá»§a chÃºng tÃ´i Ä‘Æ°á»£c
thÃºc Ä‘áº©y bá»Ÿi giáº£ thuyáº¿t ráº±ng cÃ¡c lá»›p Ä‘áº§u chá»©a thÃ´ng tin
cÃ³ giÃ¡ trá»‹ bá»‹ loáº¡i bá» bá»Ÿi thá»±c hÃ nh tiÃªu chuáº©n biá»ƒu diá»…n
mÃ£ báº±ng token CLS tá»« lá»›p encoder cuá»‘i cÃ¹ng. EarlyBIRD
cung cáº¥p cÃ¡c cÃ¡ch Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh
hiá»‡n cÃ³ vá»›i viá»‡c sá»­ dá»¥ng nguá»“n lá»±c tÆ°Æ¡ng tá»±, cÅ©ng nhÆ° Ä‘á»ƒ
giáº£m viá»‡c sá»­ dá»¥ng nguá»“n lá»±c trong khi Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£
tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i cÆ¡ sá»Ÿ.

Káº¿t quáº£: Sá»­ dá»¥ng EarlyBIRD, chÃºng tÃ´i cÃ³ Ä‘Æ°á»£c cáº£i thiá»‡n
cÃ³ Ã½ nghÄ©a thá»‘ng kÃª so vá»›i cÆ¡ sá»Ÿ cho pháº§n lá»›n cÃ¡c káº¿t há»£p
liÃªn quan Ä‘áº¿n má»™t lá»›p encoder Ä‘Æ¡n láº» trÃªn phÃ¡t hiá»‡n lá»—i,
vÃ  vá»›i cÃ¡c káº¿t há»£p EarlyBIRD Ä‘Æ°á»£c chá»n trÃªn phÃ¢n loáº¡i
kiá»ƒu lá»—i vÃ  kiá»ƒu ngoáº¡i lá»‡. Max pooling cá»§a cÃ¡c token tá»«
cÃ¡c lá»›p Ä‘Æ¡n láº» Ä‘Æ°á»£c chá»n mang láº¡i cáº£i thiá»‡n hiá»‡u suáº¥t cho
táº¥t cáº£ cÃ¡c táº­p dá»¯ liá»‡u. Cáº£ hiá»‡u suáº¥t phÃ¢n loáº¡i vÃ  thá»i gian
fine-tuning trung bÃ¬nh cho má»™t epoch Ä‘á»u Ä‘Æ°á»£c cáº£i thiá»‡n
báº±ng cÃ¡ch cáº¯t tá»‰a mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c vá» cÃ¡c
lá»›p Ä‘áº§u vÃ  sá»­ dá»¥ng token CLS tá»« lá»›p cuá»‘i cÃ¹ng cá»§a mÃ´
hÃ¬nh Ä‘Æ°á»£c cáº¯t tá»‰a. Äá»‘i vá»›i phÃ¡t hiá»‡n lá»—i, Ä‘iá»u nÃ y dáº«n Ä‘áº¿n
tÄƒng Ä‘á»™ chÃ­nh xÃ¡c +2.0 vÃ  tÄƒng tá»‘c fine-tuning 3.3x trÃªn
Devign, vÃ  tá»‘i Ä‘a cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c +0.8 vá»›i tÄƒng tá»‘c
3.7x trÃªn ReVeal. CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c cáº¯t tá»‰a khÃ´ng dáº«n Ä‘áº¿n
cáº£i thiá»‡n hiá»‡u suáº¥t phÃ¢n loáº¡i Ä‘a lá»›p, nhÆ°ng chÃºng cho tháº¥y
tÄƒng tá»‘c fine-tuning vÃ  giáº£m tiÃªu thá»¥ nguá»“n lá»±c liÃªn quan.

Káº¿t quáº£ cho tháº¥y cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c cáº¯t tá»‰a vá»›i kÃ­ch thÆ°á»›c
giáº£m hoáº·c hoáº¡t Ä‘á»™ng tá»‘t hÆ¡n hoáº·c cÃ³ thá»ƒ dáº«n Ä‘áº¿n giáº£m
viá»‡c sá»­ dá»¥ng nguá»“n lá»±c trong quÃ¡ trÃ¬nh fine-tuning vá»›i
cÃ¡c má»©c Ä‘á»™ biáº¿n Ä‘á»•i hiá»‡u suáº¥t khÃ¡c nhau, Ä‘iá»u nÃ y chá»‰ ra
tiá»m nÄƒng cá»§a EarlyBIRD trong cÃ¡c ká»‹ch báº£n háº¡n cháº¿ nguá»“n
lá»±c cá»§a viá»‡c triá»ƒn khai phÃ¡t hiá»‡n lá»—i vÃ  phÃ¢n loáº¡i kiá»ƒu lá»—i
trong mÃ´i trÆ°á»ng sáº£n xuáº¥t. VÃ­ dá»¥, EarlyBIRD Ä‘áº¡t Ä‘Æ°á»£c tÄƒng
tá»‘c 2.1x cho BIFI trong khi giáº£m Ä‘á»™ chÃ­nh xÃ¡c tá»« 96.7 xuá»‘ng 95.0.

CÃ´ng viá»‡c tÆ°Æ¡ng lai: NghiÃªn cá»©u cÃ³ thá»ƒ Ä‘Æ°á»£c má»Ÿ rá»™ng báº±ng
cÃ¡ch nghiÃªn cá»©u tá»•ng quÃ¡t hÃ³a cho cÃ¡c mÃ´ hÃ¬nh encoder
khÃ¡c. ChÃºng tÃ´i Ä‘ang trong quÃ¡ trÃ¬nh nghiÃªn cá»©u hiá»‡u suáº¥t
cá»§a EarlyBIRD vá»›i hai mÃ´ hÃ¬nh encoder má»›i: StarEncoder [ 23]
vÃ  ContraBERT_C [ 25]. Má»™t hÆ°á»›ng khÃ¡c cho nghiÃªn cá»©u
tÆ°Æ¡ng lai lÃ  liá»‡u cÃ¡c loáº¡i káº¿t há»£p lá»›p vÃ  cáº¯t tá»‰a, nhÆ° chÃºng
tÃ´i Ä‘Ã£ nghiÃªn cá»©u trong bÃ i bÃ¡o nÃ y cho cÃ¡c kiáº¿n trÃºc encoder,
cÃ³ pháº£i lÃ  cÃ¡c ká»¹ thuáº­t hiá»‡u quáº£ cho cÃ¡c kiáº¿n trÃºc decoder
vÃ  encoder-decoder. HÆ¡n ná»¯a, sáº½ thÃº vá»‹ khi thÃ­ nghiá»‡m vá»›i
cÃ¡c nhiá»‡m vá»¥ phÃ¢n loáº¡i mÃ£ khÃ¡c, nhÆ° phÃ¡t hiá»‡n lá»—i chung
vÃ  dá»± Ä‘oÃ¡n kiá»ƒu lá»— há»•ng. CÃ¡i sau cÃ³ thá»ƒ Ä‘Æ°á»£c nghiÃªn cá»©u
báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c kiá»ƒu CWE tá»« Common Weakness
Enumeration nhÆ° Ä‘Æ°á»£c gÃ¡n nhÃ£n trong táº­p dá»¯ liá»‡u CVEfixes [5].

Lá»œI Cáº¢M Ã’N
CÃ´ng viá»‡c nÃ y Ä‘Æ°á»£c há»— trá»£ bá»Ÿi Há»™i Ä‘á»“ng NghiÃªn cá»©u Na Uy
thÃ´ng qua dá»± Ã¡n secureIT (IKTPLUSS #288787). Max Hort
Ä‘Æ°á»£c há»— trá»£ thÃ´ng qua ChÆ°Æ¡ng trÃ¬nh Há»c bá»•ng ERCIM 'Alain
Bensoussan'. ÄÃ¡nh giÃ¡ thá»±c nghiá»‡m Ä‘Æ°á»£c trÃ¬nh bÃ y trong
bÃ i bÃ¡o nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn CÆ¡ sá»Ÿ Háº¡ táº§ng Thá»±c nghiá»‡m
Ä‘á»ƒ KhÃ¡m phÃ¡ Äiá»‡n toÃ¡n Exascale (eX3), Ä‘Æ°á»£c há»— trá»£ tÃ i chÃ­nh
bá»Ÿi Há»™i Ä‘á»“ng NghiÃªn cá»©u Na Uy theo há»£p Ä‘á»“ng #270053,
cÅ©ng nhÆ° trÃªn cÃ¡c nguá»“n lá»±c Ä‘Æ°á»£c cung cáº¥p bá»Ÿi Sigma2,
CÆ¡ sá»Ÿ Háº¡ táº§ng Quá»‘c gia cho Äiá»‡n toÃ¡n Hiá»‡u suáº¥t Cao vÃ 
LÆ°u trá»¯ Dá»¯ liá»‡u á»Ÿ Na Uy.

TÃNH KHáº¢ Dá»¤NG Dá»® LIá»†U
Äá»ƒ há»— trá»£ khoa há»c má»Ÿ vÃ  cho phÃ©p tÃ¡i táº¡o vÃ  xÃ¡c minh
cÃ´ng viá»‡c cá»§a chÃºng tÃ´i, táº¥t cáº£ cÃ¡c artifact Ä‘Æ°á»£c cung cáº¥p
thÃ´ng qua Zenodo táº¡i URL sau: https://doi.org/10.5281/zenodo.7608802.

TÃ€I LIá»†U THAM KHáº¢O
[1] Wasi Ahmad, Saikat Chakraborty, Baishakhi Ray, vÃ  Kai-Wei Chang. 2021.
Unified Pre-training for Program Understanding and Generation. Trong Conference
of the North American Chapter of the Association for Computational Linguistics:
Human Language Technologies. Association for Computational Linguistics, Online,
2655â€“2668. https://doi.org/10.18653/v1/2021.naacl-main.211

[2] Toufique Ahmed vÃ  Premkumar Devanbu. 2022. Multilingual Training for
Software Engineering. Trong Proceedings of the 44th International Conference on
Software Engineering. ACM, Pittsburgh Pennsylvania, 1443â€“1455. https://doi.
org/10.1145/3510003.3510049

[3] Miltiadis Allamanis, Earl T. Barr, Premkumar Devanbu, vÃ  Charles Sutton. 2018.
A Survey of Machine Learning for Big Code and Naturalness. Comput. Surveys
51, 4 (thÃ¡ng 7 2018), 81:1â€“81:37. https://doi.org/10.1145/3212695

[4] Berkay Berabi, Jingxuan He, Veselin Raychev, vÃ  Martin Vechev. 2021. TFix:
Learning to Fix Coding Errors with a Text-to-Text Transformer. Trong International
Conference on Machine Learning, Vol. 139. PMLR, Virtual Event, 780â€“791.

[5] Guru Bhandari, Amara Naseer, vÃ  Leon Moonen. 2021. CVEfixes: Automated
Collection of Vulnerabilities and Their Fixes from Open-Source Software. Trong
International Conference on Predictive Models and Data Analytics in Software
Engineering (PROMISE). ACM, 30â€“39. https://doi.org/10.1145/3475960.3475985

[6] Terra Blevins, Omer Levy, vÃ  Luke Zettlemoyer. 2018. Deep RNNs Encode Soft
Hierarchical Syntax. Trong Proceedings of the 56th Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Papers). Association for Computational
Linguistics, Melbourne, Australia, 14â€“19. https://doi.org/10.18653/v1/p18-2003

[7] Saikat Chakraborty, Rahul Krishna, Yangruibo Ding, vÃ  Baishakhi Ray. 2022.
Deep Learning Based Vulnerability Detection: Are We There Yet? IEEE Transactions
on Software Engineering 48, 9 (thÃ¡ng 9 2022), 3280â€“3296. https://doi.org/10.1109/tse.2021.3087402

[8] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira
Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman,
Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish
Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov,
Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe
Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis,
Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex
Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,
William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam,
Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage,
Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam
McCandlish, Ilya Sutskever, vÃ  Wojciech Zaremba. 2021. Evaluating Large
Language Models Trained on Code. https://doi.org/10.48550/arXiv.2107.03374
arXiv:2107.03374 [cs]

[9] Zimin Chen, Steve James Kommrusch, Michele Tufano, Louis-NoÃ«l Pouchet,
Denys Poshyvanyk, vÃ  Martin Monperrus. 2019. SEQUENCER: Sequence-to-
Sequence Learning for End-to-End Program Repair. IEEE Transactions on Software
Engineering 47, 9 (2019), 1943â€“1959. https://doi.org/10.1109/tse.2019.2940179

[10] Colin Clement, Dawn Drain, Jonathan Timcheck, Alexey Svyatkovskiy, vÃ 
Neel Sundaresan. 2020. PyMT5: Multi-Mode Translation of Natural Language
and Python Code with Transformers. Trong Proceedings of the 2020 Conference on
Empirical Methods in Natural Language Processing (EMNLP). Association for
Computational Linguistics, Online, 9052â€“9065. https://doi.org/10.18653/v1/2020.emnlp-main.728

[11] P. Devanbu. 2015. New Initiative: The Naturalness of Software. Trong Proceedings -
International Conference on Software Engineering, Vol. 2. IEEE Computer Society,
543â€“546. https://doi.org/10.1109/icse.2015.190

[12] Jacob Devlin, Ming-Wei Chang, Kenton Lee, vÃ  Kristina Toutanova. 2019. BERT:
Pre-training of Deep Bidirectional Transformers for Language Understanding.
Trong Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies (NAACL, Vol 1). Association for
Computational Linguistics, 4171â€“4186. https://doi.org/10.18653/v1/n19-1423

[13] Angela Fan, Edouard Grave, vÃ  Armand Joulin. 2019. Reducing Transformer
Depth on Demand with Structured Dropout. https://doi.org/10.48550/arXiv.1909.11556
arXiv:1909.11556 [cs, stat]

[14] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong,
Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, vÃ  Ming Zhou. 2020. CodeBERT:
A Pre-Trained Model for Programming and Natural Languages. Trong Findings of
the Association for Computational Linguistics: EMNLP 2020. Online, 1536â€“1547.
https://doi.org/10.18653/v1/2020.findings-emnlp.139

[15] Michael Fu, Chakkrit Tantithamthavorn, Trung Le, Van Nguyen, vÃ  Dinh
Phung. 2022. VulRepair: A T5-based Automated Software Vulnerability Repair.
Trong Proceedings of the 30th ACM Joint European Software Engineering Conference
and Symposium on the Foundations of Software Engineering (ESEC/FSE 2022).
Association for Computing Machinery, New York, NY, USA, 935â€“947.
https://doi.org/10.1145/3540250.3549098

[16] Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie Liu, Long
Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, Michele Tufano, Shao Kun
Deng, Colin Clement, Dawn Drain, Neel Sundaresan, Jian Yin, Daxin Jiang, vÃ 
Ming Zhou. 2021. GraphCodeBERT: Pre-training Code Representations with
Data Flow. Trong International Conference on Learning Representations, ICLR 2021.
Virtual Event, Austria, 1â€“18. arXiv:2009.08366 [cs]

[17] Vincent J. Hellendoorn, Christian Bird, Earl T. Barr, vÃ  Miltiadis Allamanis. 2018.
Deep Learning Type Inference. Trong Joint European Software Engineering Conference
and Symposium on the Foundations of Software Engineering (ESEC/FSE). ACM,
New York, NY, USA, 152â€“162. https://doi.org/10.1145/3236024.3236051

[18] JosÃ© Antonio HernÃ¡ndez LÃ³pez, Martin Weyssow, JesÃºs SÃ¡nchez Cuadrado, vÃ 
Houari Sahraoui. 2023. AST-Probe: Recovering Abstract Syntax Trees from
Hidden Representations of Pre-Trained Language Models. Trong Proceedings of the
37th IEEE/ACM International Conference on Automated Software Engineering (ASE
'22). Association for Computing Machinery, New York, NY, USA, 1â€“11. https:
//doi.org/10.1145/3551349.3556900

[19] Jeremy Howard vÃ  Sebastian Ruder. 2018. Universal Language Model Fine-
tuning for Text Classification. Trong Proceedings of the 56th Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers). Association
for Computational Linguistics, Melbourne, Australia, 328â€“339. https://doi.org/
10.18653/v1/p18-1031

[20] Aditya Kanade, Petros Maniatis, Gogul Balakrishnan, vÃ  Kensen Shi. 2020.
Learning and Evaluating Contextual Embedding of Source Code. Trong Proceedings
of the 37th International Conference on Machine Learning. PMLR, 5110â€“5121.
arXiv:2001.00059 [cs]

[21] Anjan Karmakar vÃ  Romain Robbes. 2021. What Do Pre-Trained Code Models
Know about Code?. Trong 2021 36th IEEE/ACM International Conference on Automated
Software Engineering (ASE). 1332â€“1336. https://doi.org/10.1109/ase51524.2021.9678927

[22] Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush
Sharma, vÃ  Radu Soricut. 2020. ALBERT: A Lite BERT for Self-supervised Learning
of Language Representations. https://doi.org/10.48550/arXiv.1909.11942
arXiv:1909.11942 [cs]

[23] Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov,
Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu,
Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig
Davaadorj, Joel Lamy-Poirier, JoÃ£o Monteiro, Oleh Shliazhko, Nicolas Gontier,
Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu,
Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason
Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey,
Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh,
Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero,
Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan
Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson, Carolyn Jane Anderson,
Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried,
Dzmitry Bahdanau, Yacine Jernite, Carlos MuÃ±oz Ferrandis, Sean Hughes,
Thomas Wolf, Arjun Guha, Leandro von Werra, vÃ  Harm de Vries. 2023. StarCoder:
May the Source Be with You! https://doi.org/10.48550/arXiv.2305.06161
arXiv:2305.06161 [cs]

[24] Nelson F. Liu, Matt Gardner, Yonatan Belinkov, Matthew E. Peters, vÃ  Noah A.
Smith. 2019. Linguistic Knowledge and Transferability of Contextual Representations.
https://doi.org/10.48550/arXiv.1903.08855 arXiv:1903.08855 [cs]

[25] Shangqing Liu, Bozhi Wu, Xiaofei Xie, Guozhu Meng, vÃ  Yang Liu. 2023. ContraBERT:
Enhancing Code Pre-Trained Models via Contrastive Learning. Trong
Proceedings of the 45th International Conference on Software Engineering (ICSE
'23). IEEE Press, Melbourne, Victoria, Australia, 2476â€“2487. https://doi.org/10.1109/icse48619.2023.00207

[26] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
Levy, Mike Lewis, Luke Zettlemoyer, vÃ  Veselin Stoyanov. 2019. RoBERTa: A
Robustly Optimized BERT Pretraining Approach. https://doi.org/10.48550/arXiv.1907.11692
arXiv:1907.11692 [cs]

[27] Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio
Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, Ge Li, Lidong Zhou,
Linjun Shou, Long Zhou, Michele Tufano, Ming Gong, Ming Zhou, Nan Duan,
Neel Sundaresan, Shao Kun Deng, Shengyu Fu, vÃ  Shujie Liu. 2021. CodeXGLUE:
A Machine Learning Benchmark Dataset for Code Understanding and Generation.
Trong Proceedings of the Neural Information Processing Systems Track on Datasets and
Benchmarks. 1â€“16. arXiv:2102.04664 [cs]

[28] Changan Niu, Chuanyi Li, Bin Luo, vÃ  Vincent Ng. 2022. Deep Learning Meets
Software Engineering: A Survey on Pre-Trained Models of Source Code. https:
//doi.org/10.48550/arXiv.2205.11739 arXiv:2205.11739 [cs]

[29] Matteo Paltenghi vÃ  Michael Pradel. 2021. Thinking Like a Developer? Comparing
the Attention of Humans with Neural Models of Code. Trong 2021 36th
IEEE/ACM International Conference on Automated Software Engineering (ASE).
867â€“879. https://doi.org/10.1109/ase51524.2021.9678712

[30] Cong Pan, Minyan Lu, vÃ  Biao Xu. 2021. An Empirical Study on Software Defect
Prediction Using CodeBERT Model. Applied Sciences 11, 11 (thÃ¡ng 5 2021), 4793.
https://doi.org/10.3390/app11114793

[31] David Peer, Sebastian Stabinger, Stefan Engl, vÃ  Antonio Rodriguez-Sanchez.
2022. Greedy-Layer Pruning: Speeding up Transformer Models for Natural
Language Processing. Pattern Recognition Letters 157 (thÃ¡ng 5 2022), 76â€“82. https:
//doi.org/10.1016/j.patrec.2022.03.023 arXiv:2105.14839 [cs]

[32] Matthew Peters, Mark Neumann, Luke Zettlemoyer, vÃ  Wen-tau Yih. 2018.
Dissecting Contextual Word Embeddings: Architecture and Representation. Trong
Proceedings of the 2018 Conference on Empirical Methods in Natural Language
Processing. Association for Computational Linguistics, Brussels, Belgium, 1499â€“
1509. https://doi.org/10.18653/v1/d18-1179

[33] Matthew E. Peters, Sebastian Ruder, vÃ  Noah A. Smith. 2019. To Tune or Not to
Tune? Adapting Pretrained Representations to Diverse Tasks. Trong Proceedings of the
4th Workshop on Representation Learning for NLP (RepL4NLP-2019). Association for
Computational Linguistics, Florence, Italy, 7â€“14. https://doi.org/10.18653/v1/w19-4302

[34] Long Phan, Hieu Tran, Daniel Le, Hieu Nguyen, James Annibal, Alec Peltekian,
vÃ  Yanfang Ye. 2021. CoTexT: Multi-task Learning with Code-Text Transformer.
Trong Workshop on Natural Language Processing for Programming (NLP4Prog 2021).
Association for Computational Linguistics, Online, 40â€“47. https://doi.org/10.18653/v1/2021.nlp4prog-1.5

[35] Rebecca Russell, Louis Kim, Lei Hamilton, Tomo Lazovich, Jacob Harer, Onur
Ozdemir, Paul Ellingwood, vÃ  Marc McConley. 2018. Automated Vulnerability
Detection in Source Code Using Deep Representation Learning. Trong International
Conference on Machine Learning and Applications (ICMLA). IEEE, Orlando, FL,
757â€“762. https://doi.org/10.1109/icmla.2018.00120

[36] Hassan Sajjad, Fahim Dalvi, Nadir Durrani, vÃ  Preslav Nakov. 2023. On the
Effect of Dropping Layers of Pre-trained Transformer Models. Computer Speech
& Language 77 (thÃ¡ng 1 2023), 101429. https://doi.org/10.1016/j.csl.2022.101429
arXiv:2004.03844 [cs]

[37] Rishab Sharma, Fuxiang Chen, Fatemeh Fard, vÃ  David Lo. 2022. An Exploratory
Study on Code Attention in BERT. Trong Proceedings of the 30th IEEE/ACM International
Conference on Program Comprehension (ICPC '22). Association for Computing
Machinery, New York, NY, USA, 437â€“448. https://doi.org/10.1145/3524610.3527921

[38] Tushar Sharma, Maria Kechagia, Stefanos Georgiou, Rohit Tiwari, vÃ  Federica
Sarro. 2021. A Survey on Machine Learning Techniques for Source Code Analysis.
https://doi.org/10.48550/arXiv.2110.09610 arXiv:2110.09610 [cs]

[39] Chi Sun, Xipeng Qiu, Yige Xu, vÃ  Xuanjing Huang. 2019. How to Fine-Tune
BERT for Text Classification?. Trong Chinese Computational Linguistics (Lecture
Notes in Computer Science), Maosong Sun, Xuanjing Huang, Heng Ji, Zhiyuan
Liu, vÃ  Yang Liu (Eds.). Springer International Publishing, Cham, 194â€“206.
https://doi.org/10.1007/978-3-030-32381-3_16

[40] Chi Sun, Xipeng Qiu, Yige Xu, vÃ  Xuanjing Huang. 2020. How to Fine-
Tune BERT for Text Classification? https://doi.org/10.48550/arXiv.1905.05583
arXiv:1905.05583 [cs]

[41] AndrÃ¡s Vargha vÃ  Harold D. Delaney. 2000. A Critique and Improvement of the
CL Common Language Effect Size Statistics of McGraw and Wong. Journal of
Educational and Behavioral Statistics 25, 2 (thÃ¡ng 6 2000), 101â€“132. https://doi.org/
10.3102/10769986025002101

[42] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Åukasz Kaiser, vÃ  Illia Polosukhin. 2017. Attention Is All
You Need. Trong International Conference on Neural Information Processing Systems
(NeurIPS), I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,
S. Vishwanathan, vÃ  R. Garnett (Eds.). Curran Associates, Inc., 5998â€“6008.
arXiv:1706.03762 [cs]

[43] Yue Wang, Weishi Wang, Shafiq Joty, vÃ  Steven C.H. Hoi. 2021. CodeT5:
Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding
and Generation. Trong Conference on Empirical Methods in Natural Language
Processing. Association for Computational Linguistics, Online and Punta
Cana, Dominican Republic, 8696â€“8708. https://doi.org/10.18653/v1/2021.emnlp-main.685

[44] Hongwei Wei, Guanjun Lin, Lin Li, vÃ  Heming Jia. 2021. A Context-Aware
Neural Embedding for Function-Level Vulnerability Detection. Algorithms 14, 11
(thÃ¡ng 11 2021), 335. https://doi.org/10.3390/a14110335

[45] Frank Wilcoxon. 1992. Individual Comparisons by Ranking Methods. Trong Breakthroughs
in Statistics: Methodology and Distribution, Samuel Kotz vÃ  Norman L.
Johnson (Eds.). Springer, New York, NY, 196â€“202. https://doi.org/10.1007/978-1-4612-4380-9_16

[46] Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov,
vÃ  Quoc V. Le. 2020. XLNet: Generalized Autoregressive Pretraining
for Language Understanding. https://doi.org/10.48550/arXiv.1906.08237
arXiv:1906.08237 [cs]

[47] Michihiro Yasunaga vÃ  Percy Liang. 2021. Break-It-Fix-It: Unsupervised Learning
for Program Repair. Trong International Conference on Machine Learning. PMLR,
12. arXiv:2106.06600 [cs]

[48] He Ye, Matias Martinez, vÃ  Martin Monperrus. 2022. Neural Program Repair with
Execution-Based Backpropagation. Trong Proceedings of the 44th International Conference
on Software Engineering (ICSE '22). Association for Computing Machinery,
New York, NY, USA, 1506â€“1518. https://doi.org/10.1145/3510003.3510222

[49] Tianyi Zhang, Felix Wu, Arzoo Katiyar, Kilian Q. Weinberger, vÃ  Yoav
Artzi. 2021. Revisiting Few-sample BERT Fine-tuning. Trong NeurIPS 2021. 1â€“22.
arXiv:2006.05987 [cs]

[50] Gang Zhao vÃ  Jeff Huang. 2018. DeepSim: Deep Learning Code Functional
Similarity. Trong Proceedings of the 2018 26th ACM Joint Meeting on European Software
Engineering Conference and Symposium on the Foundations of Software Engineering.
ACM, Lake Buena Vista FL USA, 141â€“151. https://doi.org/10.1145/3236024.3236068

[51] Yaqin Zhou, Shangqing Liu, Jingkai Siow, Xiaoning Du, vÃ  Yang Liu. 2019. Devign:
Effective Vulnerability Identification by Learning Comprehensive Program
Semantics via Graph Neural Networks. Trong International Conference on Neural
Information Processing Systems (NeurIPS). Curran Associates, Inc., Vancouver,
Canada., 11. arXiv:1909.03496 [cs]

Nháº­n ngÃ y 2-2-2023; cháº¥p nháº­n ngÃ y 27-7-2023

# 2308.03983.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/rag/2308.03983.pdf
# Kích thước tệp: 919920 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
SimplyRetrieve: Một Công Cụ AI Tạo Sinh Tập Trung Truy Xuất Riêng Tư và Nhẹ
Youyang Ng, Daisuke Miyashita, Yasuto Hoshi, Yasuhiro Morioka,
Osamu Torii ,Tomoya Kodama ,Jun Deguchi
Tập đoàn Kioxia, Nhật Bản
youyang.ng@kioxia.com
Tóm tắt
Các hệ thống AI Tạo Sinh dựa trên Mô hình Ngôn ngữ Lớn (LLM) đã chứng kiến tiến bộ đáng kể trong những năm gần đây. Việc tích hợp kiến trúc truy xuất tri thức cho phép tích hợp liền mạch dữ liệu riêng tư vào các hệ thống AI Tạo Sinh có sẵn công khai sử dụng LLM được đào tạo trước mà không cần tinh chỉnh mô hình bổ sung. Hơn nữa, phương pháp Tạo Sinh Tập Trung Truy Xuất (RCG), một hướng nghiên cứu tương lai đầy hứa hẹn mà tách biệt rõ ràng vai trò của LLM và bộ truy xuất trong giải thích ngữ cảnh và ghi nhớ tri thức, có thể dẫn đến việc triển khai hiệu quả hơn. SimplyRetrieve là một công cụ mã nguồn mở với mục tiêu cung cấp giao diện địa phương hóa, nhẹ và thân thiện với người dùng cho những tiến bộ tinh vi này đến cộng đồng học máy. SimplyRetrieve có GUI và nền tảng RCG dựa trên API, được hỗ trợ bởi Bộ Xây Dựng Cơ Sở Tri Thức Riêng Tư và Mô-đun Điều Chỉnh Truy Xuất. Bằng cách tận dụng những khả năng này, người dùng có thể khám phá tiềm năng của RCG để cải thiện hiệu suất AI tạo sinh trong khi duy trì tiêu chuẩn bảo mật. Công cụ này có sẵn tại https://github.com/RCGAI/SimplyRetrieve với giấy phép MIT.

1 Giới thiệu
Xử lý Ngôn ngữ Tự nhiên (NLP) dựa trên tạo sinh đã chứng kiến tiến bộ đáng kể (Brown et al., 2020) trong những năm gần đây. Với việc giới thiệu kiến trúc Transformer (Vaswani et al., 2017), khả năng phát triển các mô hình ngôn ngữ có độ chính xác cao có thể thực hiện các nhiệm vụ như tạo văn bản, tóm tắt văn bản và dịch ngôn ngữ đã trở thành hiện thực. Những mô hình này (Brown et al., 2020; Chowdhery et al., 2022), khi được mở rộng lên hàng tỷ tham số (Wei et al., 2022a), đã cho thấy những cải tiến đáng kể trong các nhiệm vụ tạo văn bản như suy luận zero-shot, làm phổ biến thuật ngữ AI Tạo Sinh. Thay vì tinh chỉnh mô hình, việc thiết kế cẩn thận các prompt đã được chứng minh là hiệu quả trong việc điều chỉnh những mô hình này cho các lĩnh vực cụ thể cho nhiều nhiệm vụ khác nhau (Brown et al., 2020). Điều này đã tạo ra lĩnh vực kỹ thuật prompt. Ngoài ra, Chain-of-Thought (Wei et al., 2022b; Kojima et al., 2022) phân tách một nhiệm vụ phức tạp được giao thành các bước có thể quản lý được, từ đó mở rộng khả năng của các mô hình ngôn ngữ dựa trên tạo sinh hơn nữa.

Việc đào tạo các mô hình ngôn ngữ lớn (LLM) đòi hỏi tài nguyên tính toán khổng lồ, thường liên quan đến hàng nghìn GPU cao cấp. Việc tinh chỉnh những mô hình này cũng có thể là thách thức. Mặc dù kỹ thuật prompt đã giúp giảm nhu cầu tinh chỉnh, vẫn còn sự không đồng bộ hướng dẫn đáng chú ý khi tương tác với người dùng. Để giải quyết vấn đề này, các kỹ thuật như học tăng cường từ phản hồi của con người (RLHF) (Christiano et al., 2017) đã được khám phá để căn chỉnh hành vi của LLM với các giá trị con người (Ouyang et al., 2022; OpenAI, 2023). Ngoài ra, QLoRA (Dettmers et al., 2023), kết hợp kỹ thuật thích ứng thứ bậc thấp (Hu et al., 2022) và kỹ thuật lượng tử hóa, đã làm cho việc tinh chỉnh những mô hình này trên phần cứng của từng nhà phát triển trở nên khả thi, làm cho chúng dễ tiếp cận hơn với nhiều người dùng hơn.

Bất chấp những tiến bộ này, vẫn còn những hạn chế về khả năng của LLM, và chúng không nhận ra một cách bẩm sinh thông tin không có mặt trong quá trình đào tạo và tinh chỉnh. Việc ghi nhớ tri thức thực tế trong phần đuôi dài cũng là một thách thức (Mallen et al., 2023).

Gần đây nhất, đã có sự quan tâm ngày càng tăng trong việc tích hợp các nguồn tri thức bên ngoài vào LLM để tạo văn bản (Borgeaud et al., 2022; Guu et al., 2020; Lewis et al., 2020). Các phương pháp tương tự cũng đã được đề xuất trong việc giải quyết các nhiệm vụ thị giác máy tính (Nakata et al., 2022; Iscen et al., 2023). Kiến trúc Tạo Sinh Tăng Cường Truy Xuất (RAG) (Lewis et al., 2020) là một phương pháp tăng cường khả năng của LLM bằng cách kết hợp các nguồn dữ liệu bên ngoài sử dụng bộ truy xuất thưa thớt hoặc dày đặc (Karpukhin et al., 2020), cho phép sử dụng dữ liệu thuộc sở hữu riêng tư mà không cần đào tạo lại hoặc tinh chỉnh LLM (Chase, 2022). Tuy nhiên, việc phát triển các mô hình tạo sinh dựa trên LLM tăng cường truy xuất vẫn đang trong giai đoạn đầu. Công cụ được đề xuất của chúng tôi có thể giúp tạo điều kiện thuận lợi cho những phát triển này.

Ngoài ra, chúng tôi giới thiệu một khái niệm kiến trúc mới được gọi là Tạo Sinh Tập Trung Truy Xuất (RCG), dựa trên phương pháp Tạo Sinh Tăng Cường Truy Xuất bằng cách nhấn mạnh vai trò quan trọng của LLM trong việc giải thích ngữ cảnh và giao phó việc ghi nhớ tri thức cho thành phần truy xuất, đặt tầm quan trọng lớn hơn lên bộ truy xuất, như được mô tả trong Hình 1. Bằng cách tách biệt việc giải thích ngữ cảnh khỏi việc ghi nhớ tri thức, phương pháp này có tiềm năng giảm quy mô (Carlini et al., 2023) của LLM cần thiết cho các nhiệm vụ tạo sinh, dẫn đến kết quả hiệu quả và có thể giải thích hơn. Hơn nữa, phương pháp này có thể giúp giảm thiểu ảo giác (Maynez et al., 2020) bằng cách giới hạn phạm vi tạo sinh của LLM. Khi chúng tôi định nghĩa RCG như trên, chúng tôi có thể tái định nghĩa RAG cho phép sử dụng tri thức bẩm sinh của LLM một cách dễ dàng hơn, trong khi RCG ưu tiên sự phân định rõ ràng giữa việc giải thích ngữ cảnh và ghi nhớ tri thức.

SimplyRetrieve là một công cụ mã nguồn mở nhằm cung cấp giao diện địa phương hóa, nhẹ và thân thiện với người dùng cho phương pháp Tạo Sinh Tập Trung Truy Xuất cho cộng đồng học máy. Công cụ này bao gồm một nền tảng RCG dựa trên GUI và API, được hỗ trợ bởi Bộ Xây Dựng Cơ Sở Tri Thức Riêng Tư và Mô-đun Điều Chỉnh Truy Xuất. SimplyRetrieve được thiết kế để đơn giản và dễ tiếp cận với cộng đồng, cũng như người dùng cuối.

Nền tảng tập trung truy xuất của chúng tôi kết hợp nhiều cơ sở tri thức có thể lựa chọn với chế độ Hỗn Hợp Cơ Sở Tri Thức (MoKB) và Trọng Số Prompt Tường Minh (EPW) của cơ sở tri thức được truy xuất. Bằng cách thiết kế SimplyRetrieve với những tính năng này, chúng tôi cho phép cộng đồng học máy khám phá và phát triển với giao diện dữ liệu riêng tư nhẹ cho các hệ thống AI tạo sinh dựa trên LLM, tập trung vào tạo sinh tập trung truy xuất. Những phát triển tiềm năng có thể được khám phá bằng công cụ này bao gồm: (1) kiểm tra tính hiệu quả của tạo sinh tập trung truy xuất trong việc phát triển các hệ thống AI an toàn, có thể giải thích và có trách nhiệm hơn; (2) tối ưu hóa hiệu quả của việc tách biệt giải thích ngữ cảnh và ghi nhớ tri thức trong phương pháp tạo sinh tập trung truy xuất; và (3) cải thiện kỹ thuật kỹ thuật prompt cho tạo sinh tập trung truy xuất. SimplyRetrieve có sẵn tại https://github.com/RCGAI/SimplyRetrieve.

Đóng góp của chúng tôi có thể được tóm tắt như sau:
• Chúng tôi đề xuất SimplyRetrieve, một công cụ sáng tạo và thân thiện với người dùng tận dụng nền tảng GUI và API để tạo điều kiện thuận lợi cho phương pháp Tạo Sinh Tập Trung Truy Xuất. Nền tảng này được tăng cường thêm bởi hai thành phần chính: Bộ Xây Dựng Cơ Sở Tri Thức Riêng Tư và Mô-đun Điều Chỉnh Truy Xuất.
• Chúng tôi mở mã nguồn công cụ của mình cho cộng đồng học máy và xác định các hướng phát triển tiềm năng của Tạo Sinh Tập Trung Truy Xuất.

2 Các Công Trình Liên Quan
Sự xuất hiện của kiến trúc Tạo Sinh Tăng Cường Truy Xuất đã thúc đẩy sự phát triển của nhiều công cụ mã nguồn mở. Ví dụ, ChatGPT Retrieval Plugin¹ tích hợp khả năng truy xuất và tăng cường tài liệu cá nhân hoặc tổ chức vào mô hình ChatGPT được sử dụng rộng rãi (OpenAI, 2023). Tương tự, fastRAG (Izsak et al., 2023) cung cấp nền tảng được sắp xếp hợp lý để xây dựng các pipeline tạo sinh tăng cường truy xuất hiệu quả. Ngoài ra, LangChain (Chase, 2022) cung cấp thư viện AI chat tạo sinh toàn diện với tính năng agent, tăng cường dữ liệu và khả năng bộ nhớ. Cuối cùng, Haystack (Pietsch et al., 2019) trình bày một framework NLP toàn diện hỗ trợ trả lời câu hỏi, tạo câu trả lời, tìm kiếm tài liệu ngữ nghĩa và tăng cường truy xuất. Cả LangChain và Haystack đều sử dụng kỹ thuật pipeline dựa trên agent và có thể xử lý các truy vấn phức tạp. Tuy nhiên, sự phức tạp này có thể cản trở khả năng giải thích của LLM, làm cho việc giải thích hiệu suất của chúng trong các thiết lập tăng cường truy xuất trở nên khó khăn.

Mặt khác, công trình của chúng tôi đưa ra một phương pháp nhẹ và minh bạch để triển khai kiến trúc tập trung truy xuất cũng như tăng cường truy xuất tinh vi, trong khi duy trì sự nhấn mạnh mạnh mẽ vào khả năng giải thích phản hồi và khả năng tiếp cận rộng rãi hơn với cộng đồng. Không giống như các công trình trước đây như PrivateGPT (PrivateGPT), cung cấp công cụ AI chat bảo vệ quyền riêng tư nhưng thiếu các tùy chọn tùy chỉnh và khả năng phân tích, công cụ của chúng tôi cung cấp một bộ tính năng toàn diện để tùy chỉnh và phân tích tạo sinh tập trung truy xuất.

Hơn nữa, theo hiểu biết của chúng tôi, chúng tôi là những người đầu tiên giới thiệu khái niệm RCG và cho thấy các thí nghiệm ban đầu của nó bằng công cụ của mình.

3 Thiết Kế Công Cụ
SimplyRetrieve được thiết kế để triển khai pipeline RCG: xây dựng cơ sở tri thức, điều chỉnh kiến trúc, đưa ra dự đoán. Trong bài báo này, chúng tôi tập trung vào việc mô tả các đặc điểm kỹ thuật cốt lõi của công cụ. Để biết chi tiết về các thủ tục thiết lập, tham khảo kho lưu trữ tại https://github.com/RCGAI/SimplyRetrieve.

3.1 Nền Tảng Tạo Sinh Tập Trung Truy Xuất Dựa Trên GUI và API
Như được thể hiện trong Hình 2, có hai mô hình dày đặc trong công cụ của chúng tôi: một LLM và một Bộ Truy Xuất Tri Thức dựa trên Tìm Kiếm Láng Giềng Gần Đúng (ANNS). LLM có thể là bất kỳ mô hình LLM mã nguồn mở có sẵn trên Hugging Face (Wolf et al., 2020), từ 1B đến hơn 100B tham số như Touvron et al. (2023a,b). Bộ Truy Xuất Tri Thức sử dụng một bộ truy xuất dày đặc tương thích với nhiều mô hình embedding khác nhau có sẵn trên Hugging Face. Ngoài ra, công cụ của chúng tôi cho phép tích hợp đồng thời nhiều cơ sở tri thức, cho phép người dùng lựa chọn cơ sở tri thức tùy thuộc vào trường hợp sử dụng cụ thể.

Về GUI, chúng tôi đã thiết kế một bố cục đơn giản nhưng trực quan bằng Gradio (Abid et al., 2019), cung cấp giao diện chatbot streaming quen thuộc với điều khiển người dùng để quản lý các chế độ chạy của bộ truy xuất, kỹ thuật prompt và cấu hình công cụ. Như được mô tả trong Hình 3, GUI của chúng tôi có một bảng điều chỉnh tập trung truy xuất toàn diện cho các chức năng bao gồm lựa chọn cơ sở tri thức thủ công từ nhiều nguồn và chế độ Hỗn Hợp Cơ Sở Tri Thức. Hơn nữa, chúng tôi sử dụng Trọng Số Prompt Tường Minh của truy xuất để điều chỉnh mức độ ảnh hưởng của bộ truy xuất. Để đảm bảo tích hợp liền mạch, chúng tôi cũng đã phát triển chức năng truy cập API toàn diện bằng Giao Diện Gradio Client, và chúng tôi cho phép truy cập đồng thời nhiều người dùng cho cả UI, tận dụng chức năng hàng đợi của Gradio để quản lý các yêu cầu một cách hiệu quả.

Bảng điều chỉnh tập trung truy xuất cho phép truy cập nhẹ và đơn giản vào RCG. Bằng cách sử dụng chế độ lựa chọn cơ sở tri thức thủ công, người dùng có thể xây dựng và nhập đồng thời nhiều cơ sở tri thức riêng tư vào công cụ này. Khả năng lựa chọn cơ sở tri thức phù hợp nhất cho mỗi nhiệm vụ cho phép người dùng duy trì quyền kiểm soát quá trình lựa chọn trong khi tránh bất kỳ kết quả không mong muốn nào. Chế độ MoKB của chúng tôi cho phép lựa chọn tự động cơ sở tri thức phù hợp nhất dựa trên sự tương đồng giữa truy vấn và mô tả chức năng của cơ sở tri thức. Chúng tôi sử dụng độ tương đồng cosine ngữ nghĩa của không gian embedding để tính toán những điểm số này, cung cấp một phương pháp hiệu quả và nhẹ cho việc tự động lựa chọn cơ sở tri thức. Bằng cách cập nhật các mô tả chức năng trong tệp cấu hình, người dùng có thể tăng cường thêm độ chính xác của thuật toán lựa chọn.

Ngoài ra, tính năng Trọng Số Prompt Tường Minh của chúng tôi cho phép điều chỉnh thủ công mức độ ảnh hưởng của bộ truy xuất lên mô hình ngôn ngữ, cho phép điều khiển tùy chỉnh sự cân bằng giữa bộ truy xuất và LLM. Thông qua kỹ thuật prompt hoặc điều chỉnh trọng số token, người dùng có thể điều chỉnh công cụ theo nhu cầu cụ thể của mình, đảm bảo hiệu suất tối ưu. SimplyRetrieve đã kết hợp Trọng Số Prompt Tường Minh thông qua kỹ thuật prompt, nơi trọng số có thể được điều chỉnh để tinh chỉnh tỷ lệ phần trăm token tri thức được sử dụng trong prompt từ các token được truy xuất. Tuy nhiên, chúng tôi chưa triển khai điều chỉnh trọng số token trong nghiên cứu này và để lại cho công việc tương lai.

3.2 Bộ Xây Dựng Cơ Sở Tri Thức Riêng Tư
Nền Tảng Tạo Sinh Tập Trung Truy Xuất của chúng tôi được hỗ trợ bởi Bộ Xây Dựng Cơ Sở Tri Thức Riêng Tư tạo ra một cơ sở tri thức địa phương và cá nhân hóa bằng cách sử dụng tài liệu của người dùng. Bộ xây dựng này sử dụng một bộ tải tài liệu có thể mở rộng có thể xử lý khối lượng lớn tài liệu bằng cách phân đoạn và truyền tải quá trình tải, tách và tạo cơ sở tri thức, cho phép xử lý tài liệu hiệu quả. Bộ xây dựng hỗ trợ nhiều định dạng tài liệu khác nhau như PDF, TXT, DOC, DOCX, PPT, PPTX, HTML, MD, CSV, trong số các định dạng khác, và có thể được mở rộng dễ dàng bằng cách chỉnh sửa tệp cấu hình. Ngoài ra, độ dài của các đoạn văn trong chức năng tách tài liệu có thể cấu hình dễ dàng để đáp ứng các yêu cầu cụ thể.

Sau khi tạo ra các nguồn cho cơ sở tri thức, chúng tôi sử dụng một bộ mã hóa dày đặc để chuyển đổi văn bản thành embedding số có thể được sử dụng cho tìm kiếm ngữ nghĩa và truy xuất. Để đáp ứng các cơ sở tri thức quy mô lớn, chúng tôi sử dụng ANNS để truy xuất ngữ nghĩa hiệu quả. Theo mặc định, công cụ của chúng tôi sử dụng thuật toán Hierarchical Navigable Small Worlds (HNSW) (Malkov và Yashunin, 2020), nhưng chúng tôi cũng cung cấp hỗ trợ cho lập chỉ mục phẳng và phương pháp IVFPQ-HNSW, kết hợp lập chỉ mục tệp đảo ngược với lượng tử hóa sản phẩm và bộ lượng tử hóa thô HNSW. Chức năng Index Constructor tự động tạo ra các tệp chỉ mục cần thiết để tìm kiếm ngữ nghĩa. Chúng tôi triển khai chức năng lập chỉ mục của mình bằng cách sử dụng thư viện Faiss (Johnson et al., 2019).

3.3 Mô-đun Điều Chỉnh Truy Xuất
Mô-đun Điều Chỉnh Truy Xuất của công cụ chúng tôi bao gồm ba chức năng chính: kỹ thuật prompt, cấu hình công cụ và phân tích và ghi nhật ký dữ liệu. Chức năng kỹ thuật prompt cho phép người dùng dễ dàng chỉnh sửa, cập nhật và lưu các prompt liên quan đến truy xuất bằng Tab Prompt thân thiện với người dùng trong GUI của chúng tôi. Các prompt có sẵn là AI Prefix, Retriever Prefix, Retriever Suffix, Model Prefix và Model Suffix. Chức năng cấu hình cho phép người dùng sửa đổi và lưu tất cả các cài đặt có thể cấu hình qua Tab Config trong GUI của chúng tôi. Cuối cùng, chức năng phân tích và ghi nhật ký dữ liệu thu thập và hiển thị dữ liệu phân tích liên quan đến truy xuất, bao gồm cơ sở tri thức được truy xuất, truy vấn, phản hồi, điểm số tương đồng cấp câu và cấp token, trong Tab Analysis của GUI chúng tôi. Điểm số tương đồng được tính toán dựa trên cả độ tương đồng cosine ngữ nghĩa của embedding câu-với-câu và embedding tất cả-token-với-token. Phương pháp này cho phép chúng tôi nắm bắt cả sự tương đồng cục bộ và toàn cục giữa các câu, dẫn đến đánh giá chính xác hơn về khả năng so sánh của chúng. Ngoài ra, người dùng có thể lưu tất cả dữ liệu đã ghi nhật ký vào tệp nhật ký để phân tích thêm. Các thiết kế GUI được mô tả trong Hình 4, 5 và 6 của Phụ lục A.2. Để triển khai chế độ người dùng cuối, người dùng có thể chỉ cần vô hiệu hóa các chức năng cập nhật trong Mô-đun Điều Chỉnh Truy Xuất thông qua các tùy chọn dòng lệnh.

4 Đánh Giá
Trong phần này, chúng tôi thực hiện một số đánh giá định tính để chứng minh tính khả dụng và hành vi của công cụ. Chúng tôi xây dựng cơ sở tri thức của mình bằng cách sử dụng thông tin mới nhất có sẵn trên trang web của một tổ chức². Chúng tôi sử dụng các mô hình có sẵn công khai trên Hugging Face, Wizard-Vicuna-13B³ (Xu et al., 2023; Chiang et al., 2023) làm LLM và Multilingual-E5-base⁴ (Wang et al., 2022) làm bộ mã hóa cho đánh giá của chúng tôi, trừ khi được chỉ định khác. Chúng tôi tải cả hai mô hình vào một GPU Nvidia A100 duy nhất ở chế độ INT8 8-bit để sử dụng bộ nhớ thấp hơn và tốc độ suy luận cao hơn. Chúng tôi đặt nhiệt độ của LLM là 0. Chúng tôi sử dụng HNSW để lập chỉ mục các cơ sở tri thức và đặt số lượng đoạn văn được truy xuất là 5.

4.1 Đánh Giá Định Tính
Chúng tôi so sánh kết quả của ba phương pháp: Tạo Sinh Tập Trung Truy Xuất (RCG), Tạo Sinh Tăng Cường Truy Xuất (RAG), và Tạo Sinh Tắt Truy Xuất (ROG). Lưu ý rằng trong công việc này, chúng tôi định nghĩa RAG là cho phép tích hợp dễ dàng hơn tri thức bẩm sinh và được truy xuất bên ngoài của LLM, trong khi RCG ưu tiên sự phân định rõ ràng giữa giải thích ngữ cảnh và ghi nhớ tri thức. Việc điều tra các phương pháp tiên tiến trong việc trích xuất hành vi RCG là một chủ đề nghiên cứu đầy hứa hẹn. Trong công việc này, chúng tôi tiến hành các thí nghiệm đơn giản bằng kỹ thuật prompt để tiết lộ tiềm năng của phương pháp RCG. Cụ thể, đối với RCG, chúng tôi sử dụng prompt hậu tố truy xuất có nội dung "trả lời câu hỏi sau với tri thức được cung cấp." Đối với RAG, chúng tôi sử dụng prompt ít ràng buộc hơn có nội dung "trả lời câu hỏi sau. Bạn có thể sử dụng tri thức được cung cấp." Cuối cùng, đối với ROG, là đường cơ sở trong đánh giá của chúng tôi, chúng tôi tắt hoàn toàn bộ truy xuất. Bằng cách sử dụng chức năng kỹ thuật prompt trong SimplyRetrieve, chúng tôi có thể dễ dàng thực hiện những thí nghiệm này. Các truy vấn được chú thích bởi con người. Trong Bảng 1 và 2, văn bản màu xanh chỉ ra phản hồi đúng thực tế trong khi văn bản màu đỏ chỉ ra ảo giác.

Dựa trên kết quả trong Bảng 1, chúng tôi quan sát thấy rằng RCG đã trả lời truy vấn của chúng tôi một cách chính xác, trong khi RAG cố gắng tích hợp cơ sở tri thức được truy xuất với tri thức riêng của LLM về tổ chức cụ thể, dẫn đến thông tin một phần sai lệch. Trong khi đó, ROG phản hồi truy vấn của chúng tôi với tri thức sai lầm có sẵn của LLM, tạo ra những sai lầm. Phát hiện của chúng tôi cho thấy rằng việc tạo ra các prompt rõ ràng và trực tiếp, như "trả lời câu hỏi đã cho bằng tri thức được cung cấp", có thể khuyến khích hành vi tập trung truy xuất từ LLM, mặc dù kỹ thuật prompt tinh chỉnh hơn có thể cần thiết để có hiệu suất tối ưu.

Như được thể hiện trong Bảng 2, RCG giải quyết hiệu quả truy vấn và tạo ra kết quả chính xác. Khi kết hợp RCG với Trọng Số Prompt Tường Minh 50% (RCG-EPW), nơi chỉ có 50% đầu tiên của cơ sở tri thức được truy xuất được đưa vào prompt, mô hình tạo ra phản hồi một phần nhưng vẫn duy trì độ chính xác thực tế. Ngược lại, LLM thuần túy mà không có RC được kích hoạt (ROG) cung cấp phản hồi ảo giác, làm nổi bật tầm quan trọng của việc kết hợp các kỹ thuật tập trung truy xuất trong các mô hình ngôn ngữ để cải thiện hiệu suất.

4.2 Đánh Giá Độ Chính Xác & Tốc Độ
Ngoài việc đánh giá tính hiệu quả của RCG bằng chú thích của con người, chúng tôi cũng tiến hành đánh giá nội bộ về hiệu suất của công cụ bằng cách sử dụng một bộ dữ liệu tự tạo. Để tạo ra bộ dữ liệu này, chúng tôi chuyển các đoạn văn có liên quan qua mô hình ngôn ngữ Llama-2-13B-chat (Touvron et al., 2023b) để tạo ra 10 cặp truy vấn và nhãn. Để biết chi tiết về cách chúng tôi tạo ra bộ dữ liệu này, tham khảo Phụ lục A.4. Chúng tôi sử dụng điểm Rouge-L (Lin, 2004) làm thước đo hiệu suất. Chúng tôi thực hiện đánh giá này bằng cách sử dụng chức năng API của SimplyRetrieve. Kết quả của chúng tôi trong Bảng 3 cho thấy rằng RCG cải thiện đáng kể điểm Rouge-L so với phương pháp cơ sở ROG, đồng thời cũng cạnh tranh hơn một chút so với RAG. Hơn nữa, mặc dù thực tế là RCG xử lý các prompt dài hơn ROG do việc thêm token tri thức, chúng tôi quan sát thấy sự giảm thời gian xử lý nhờ vào độ chính xác và tính ngắn gọn tăng lên của các phản hồi được tạo ra. Cụ thể, số lượng token phản hồi được tạo ra trong RCG trung bình ít hơn 36% so với những token được tạo ra trong ROG. Hiệu suất hiệu quả này có thể tạo điều kiện thuận lợi cho việc áp dụng rộng rãi hơn trong cộng đồng, vì người dùng có thể mong đợi việc tạo phản hồi nhanh hơn mà không hy sinh độ chính xác.

Cuối cùng, phát hiện của chúng tôi cho thấy rằng ngay cả một LLM có kích thước vừa phải 13B tham số cũng có thể thể hiện hiệu suất thỏa mãn trong phương pháp RCG đối với tri thức thực tế chưa từng thấy trước đây mà không cần tinh chỉnh mô hình, có thể tạo điều kiện thuận lợi cho việc triển khai các hệ thống AI Tạo Sinh trong các tình huống thực tế. Xem Phụ lục A.2 để thảo luận thêm và A.5 cho các nghiên cứu loại bỏ.

5 Kết Luận
Chúng tôi đã giới thiệu SimplyRetrieve, một công cụ mã nguồn mở nhằm cung cấp một nền tảng GUI và API có thể địa phương hóa, nhẹ và thân thiện với người dùng cho phương pháp Tạo Sinh Tập Trung Truy Xuất dựa trên LLM. Công cụ của chúng tôi cho phép các nhà phát triển và người dùng cuối dễ dàng tương tác và phát triển với hệ thống RCG dựa trên LLM bảo vệ quyền riêng tư và được triển khai cục bộ, mà chúng tôi tin rằng sẽ đóng góp vào việc dân chủ hóa những công nghệ này trong cộng đồng học máy. Sự rõ ràng tăng lên trong việc phân chia vai trò giữa giải thích ngữ cảnh và ghi nhớ tri thức có thể tăng cường hiệu suất và khả năng giải thích của các hệ thống AI tạo sinh, tạo điều kiện thuận lợi cho triển khai.

Hạn Chế
Điều quan trọng cần lưu ý là công cụ này không cung cấp một giải pháp hoàn hảo để đảm bảo phản hồi hoàn toàn an toàn và có trách nhiệm từ các mô hình AI tạo sinh, ngay cả trong phương pháp tập trung truy xuất. Việc phát triển các hệ thống AI an toàn, có thể giải thích và có trách nhiệm hơn vẫn là một lĩnh vực nghiên cứu tích cực và nỗ lực đang diễn ra.

Văn bản được tạo ra từ công cụ này có thể thể hiện sự khác biệt, ngay cả khi chỉ sửa đổi nhẹ các prompt hoặc truy vấn, do hành vi dự đoán token tiếp theo của LLM thế hệ hiện tại. Điều này có nghĩa là người dùng có thể cần tinh chỉnh cẩn thận cả prompt và truy vấn để có được phản hồi tối ưu.

Tài Liệu Tham Khảo
[Danh sách tài liệu tham khảo được giữ nguyên như trong bản gốc]

Phụ Lục A
[Nội dung phụ lục được giữ nguyên như trong bản gốc]

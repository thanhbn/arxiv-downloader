# Quá Ít Báo Cáo Lỗi? Khám Phá Tăng Cường Dữ Liệu Để Cải Thiện Định Vị Lỗi Dựa Trên Changeset

Agnieszka Ciborowska
Đại học Virginia Commonwealth
Richmond, Virginia, USA
imranm3@vcu.edu

Kostadin Damevski
Đại học Virginia Commonwealth
Richmond, Virginia, USA
kdamevski@vcu.edu

TÓM TẮT
Các kiến trúc Học Sâu (Deep Learning - DL) hiện đại dựa trên transformer (ví dụ: BERT, RoBERTa) đang thể hiện sự cải thiện hiệu suất trên nhiều nhiệm vụ xử lý ngôn ngữ tự nhiên. Mặc dù các mô hình DL này đã cho thấy tiềm năng to lớn để sử dụng trong các ứng dụng kỹ thuật phần mềm, chúng thường bị cản trở bởi dữ liệu huấn luyện không đủ. Đặc biệt bị hạn chế là những ứng dụng cần dữ liệu cụ thể của dự án, như định vị lỗi, nhằm mục đích đề xuất mã để sửa một báo cáo lỗi mới được gửi. Các mô hình học sâu cho định vị lỗi yêu cầu một tập huấn luyện đáng kể gồm các báo cáo lỗi đã được sửa, vốn có số lượng hạn chế ngay cả trong các dự án phần mềm phổ biến và được phát triển tích cực. Trong bài báo này, chúng tôi khám phá hiệu quả của việc sử dụng dữ liệu huấn luyện tổng hợp trên các mô hình DL dựa trên transformer thực hiện một biến thể phức tạp hơn của định vị lỗi, có mục tiêu lấy các changeset gây ra lỗi cho mỗi báo cáo lỗi. Để tạo ra dữ liệu tổng hợp chất lượng cao, chúng tôi đề xuất các toán tử tăng cường dữ liệu mới tác động lên các thành phần cấu thành khác nhau của báo cáo lỗi. Chúng tôi cũng mô tả chiến lược cân bằng dữ liệu nhằm tạo ra một kho dữ liệu báo cáo lỗi được tăng cường phản ánh tốt hơn toàn bộ cơ sở mã nguồn, bởi vì các báo cáo lỗi hiện có được sử dụng làm dữ liệu huấn luyện thường tham chiếu đến một phần nhỏ của cơ sở mã. Cân bằng dữ liệu giúp mô hình hoạt động tốt hơn cho các báo cáo lỗi mới được báo cáo tham chiếu đến mã chưa được quan sát trước đó. Kết quả đánh giá của chúng tôi cho thấy cả tăng cường dữ liệu và cân bằng đều hiệu quả, cải thiện hiệu suất truy xuất trên cả ba mô hình dựa trên BERT mà chúng tôi nghiên cứu.

1 GIỚI THIỆU

Sự xuất hiện của các kiến trúc Học Sâu (DL) mới, như transformer, đã thúc đẩy những cải tiến xuất sắc trên nhiều nhiệm vụ trong Xử lý Ngôn ngữ Tự nhiên (NLP), và khuyến khích ứng dụng chúng cho các vấn đề khác nhau trong lĩnh vực kỹ thuật phần mềm. Các nhà nghiên cứu kỹ thuật phần mềm đã nghiên cứu tiềm năng của DL trong bối cảnh các vấn đề như tìm kiếm mã, dự đoán lỗi, và định vị lỗi. Tuy nhiên, điểm yếu cơ bản của các phương pháp DL là chúng cần một lượng lớn dữ liệu có nhãn để huấn luyện mô hình. Đồng thời, duy trì chất lượng dữ liệu có nhãn là rất quan trọng để đạt được hiệu suất tốt nhất. Trong khi việc gắn nhãn thủ công thường là phương pháp được ưu tiên để đảm bảo chất lượng dữ liệu cao, nó là một quá trình chậm và tốn thời gian, thường khó thực hiện khi xem xét lượng dữ liệu cần thiết để huấn luyện một mô hình DL. Mặt khác, khai thác nhãn tự động có nhiều khả năng đáp ứng nhu cầu về số lượng dữ liệu hơn, tuy nhiên phải trả giá bằng việc đưa vào nhiễu dưới dạng cả dương tính giả và âm tính giả. Do đó, thu thập lượng lớn dữ liệu có nhãn chất lượng tốt có thể gây ra thách thức đáng kể cho nhiều vấn đề và nhiệm vụ kỹ thuật phần mềm quan trọng, đặc biệt là những vấn đề cần dữ liệu dự án đơn lẻ (tức là trong dự án). Một phương pháp gần đây để giải quyết vấn đề này là sử dụng transfer learning, tức là pre-training một mô hình với học không giám sát trên một corpus lớn, tổng quát, sau đó fine-tuning thông qua học có giám sát hướng đến nhiệm vụ downstream. Tuy nhiên, chiến lược này vẫn cần một dataset không nhỏ cho fine-tuning và, như quan sát bởi Gururangan et al., nó dẫn đến hiệu suất không tối ưu so với khi một mô hình được pre-training và fine-tuning trên dữ liệu trong miền.

Một trong những nhiệm vụ kỹ thuật phần mềm được hưởng lợi từ phương pháp dựa trên DL là định vị lỗi, nhằm xác định các thực thể mã liên quan (ví dụ: lớp, phương thức hoặc changeset) cho một báo cáo lỗi mô tả lỗi phần mềm. Qua các năm, các nhà nghiên cứu đã đề xuất nhiều phương pháp cho định vị lỗi dựa trên Vector Space Model (VSM) và các mô hình xác suất (ví dụ: Latent Dirichlet Allocation), đồng thời nhận ra rằng nhược điểm chính của những kỹ thuật này là khả năng hạn chế trong việc xử lý khoảng cách ngữ nghĩa giữa mã nguồn gây ra lỗi và mô tả được đưa ra trong báo cáo lỗi. Để giải quyết vấn đề đó, các nỗ lực gần đây đã chuyển hướng sang các kỹ thuật DL, bao gồm RNN, LSTM và cuối cùng là các mô hình dựa trên transformer. Như được chỉ ra bởi Guo et al., tính khả dụng của dữ liệu huấn luyện là một trong những yếu tố quan trọng hạn chế hiệu suất DL. Trong trường hợp định vị lỗi, dữ liệu huấn luyện bao gồm các cặp báo cáo lỗi và changeset giới thiệu (hoặc gây ra) chúng, khó có được ở quy mô lớn vì một số lý do chính. Thứ nhất, việc ghép nối một báo cáo lỗi với changeset gây ra lỗi là thách thức vì các nhà phát triển hiếm khi đánh dấu rõ ràng các thay đổi mã có lỗi, trong khi các phương pháp tìm changeset gây ra lỗi tự động, dựa trên thuật toán SZZ, dễ bị đưa vào nhiễu. Thứ hai, số lượng mẫu dương bị giới hạn bởi số lượng báo cáo lỗi đã được sửa, vốn hạn chế ngay cả đối với các dự án lớn và được duy trì tích cực. Các dự án phần mềm tương đối nhỏ hơn với, ví dụ, hàng chục báo cáo lỗi đã được sửa, sẽ rất khó sử dụng. Cuối cùng, câu hỏi chính vẫn còn mở: làm thế nào để tận dụng các kỹ thuật DL cho định vị lỗi, với sự khan hiếm dữ liệu cụ thể của dự án.

Trong lĩnh vực NLP, câu hỏi này đã được trả lời với một số thành công bằng các kỹ thuật Tăng cường Dữ liệu (Data Augmentation - DA), nói chung có thể được mô tả là các chiến lược để tăng nhân tạo số lượng và sự đa dạng của các mẫu huấn luyện dựa trên dữ liệu hiện có. DA nhằm tạo ra dữ liệu tổng hợp chất lượng cao bằng cách áp dụng các phép biến đổi lên dữ liệu có sẵn, trong khi duy trì tính bất biến của nhãn. Kết quả là, kích thước của dataset gốc tăng lên, điều này cho phép huấn luyện một mô hình DL cho các miền và nhiệm vụ có ít tài nguyên.

Được khuyến khích bởi những tiến bộ gần đây của DA trong lĩnh vực NLP, trong công trình này, chúng tôi nhằm khám phá tăng cường dữ liệu cho báo cáo lỗi với mục tiêu tạo ra một số lượng lớn báo cáo lỗi tổng hợp chất lượng cao, thực tế, có thể được sử dụng sau đó để tăng kích thước tập huấn luyện cho một mô hình DL định vị lỗi. Để làm điều này, chúng tôi đề xuất hai tập toán tử DA độc lập nhắm đến dữ liệu văn bản ngôn ngữ tự nhiên và dữ liệu liên quan đến mã (ví dụ: token mã, stack trace và đoạn mã) trong mỗi báo cáo lỗi. Cụ thể hơn, văn bản ngôn ngữ tự nhiên được tăng cường bằng các phép biến đổi cấp token và cấp đoạn văn (ví dụ: chèn từ đồng nghĩa), trong khi dữ liệu liên quan đến mã được tăng cường bằng token mã từ changeset gây ra lỗi tương ứng để tăng cường kết nối giữa một báo cáo lỗi và các phần khác nhau của changeset giới thiệu nó. Đồng thời, bằng cách tận dụng các báo cáo lỗi được tăng cường, chúng tôi dự định đạt được một mục tiêu quan trọng khác, cân bằng dataset được tăng cường hướng đến các phần của mã nguồn được đại diện ít trong tập huấn luyện gốc. Điều này giải quyết sự xuất hiện phổ biến trong các dự án phần mềm rằng các báo cáo lỗi hiện có chỉ tham chiếu đến một phần cụ thể của cơ sở mã, trong khi các phần khác có ít hoặc không có báo cáo lỗi, dẫn đến mô hình định vị lỗi tập trung quá mức vào một phần của cơ sở mã. Trong bài báo này, chúng tôi điều tra các Câu hỏi Nghiên cứu (Research Questions - RQs) sau:

RQ1: (a) Tăng cường Dữ liệu có thể cải thiện hiệu suất truy xuất của định vị lỗi dựa trên DL không? (b) Tăng cường Dữ liệu ảnh hưởng như thế nào đến hiệu suất của các phương pháp định vị lỗi dựa trên DL khác nhau?

Để hiểu liệu Tăng cường Dữ liệu có phải là một chiến lược phù hợp trong định vị lỗi dựa trên DL hay không, chúng tôi xác định ba mô hình gần đây dựa trên transformer để thực hiện nhiệm vụ này. Chúng tôi đánh giá hiệu suất của các phương pháp định vị lỗi này, có và không có DA, sử dụng một dataset định vị lỗi tiêu chuẩn và các metric thường được sử dụng để đo hiệu suất truy xuất thông tin. Vì tăng cường nhất thiết đưa vào số lượng dữ liệu cao hơn đáng kể, chúng tôi thêm các baseline vào đánh giá nhằm phân biệt số lượng so với chất lượng của dataset được tăng cường. Kết quả cho thấy (1) chiến lược tăng cường dữ liệu được đề xuất cải thiện độ chính xác truy xuất từ 39% đến 82%, (2) việc tăng cường dataset có lợi hơn việc tăng kích thước tập huấn luyện bằng lặp lại; và (3) cân bằng tập huấn luyện dẫn đến cải thiện hiệu suất truy xuất, nhưng mức độ cải thiện phụ thuộc vào kiến trúc của mô hình DL.

RQ2: Toán tử DA nào được đề xuất đóng góp nhiều nhất cho hiệu suất truy xuất?

Phương pháp Tăng cường Dữ liệu trong RQ1 dựa trên các toán tử tăng cường thực hiện các loại biến đổi cụ thể (ví dụ: chèn, xóa). Trong RQ2, chúng tôi nhằm hiểu tác động của các toán tử tăng cường này đến hiệu suất truy xuất trong định vị lỗi. Để trả lời RQ2, chúng tôi thực hiện các nghiên cứu ablation, huấn luyện mỗi mô hình DL với các dataset được tăng cường được tạo ra bằng cách sử dụng tất cả trừ một loại toán tử tăng cường. Kết quả cho thấy hầu hết các toán tử đều đóng góp vào hiệu suất cuối cùng, trong khi một số toán tử nhất quán hơn trên các mô hình DL khác nhau.

2 TĂNG CƯỜNG DỮ LIỆU CHO ĐỊNH VỊ LỖI

Với sự phức tạp ngày càng tăng của các phương pháp dựa trên DL cho định vị lỗi, vấn đề khan hiếm dữ liệu trở nên nổi bật. Cụ thể hơn, trong khi các mô hình tiên tiến hơn có tiềm năng thu hẹp khoảng cách từ vựng giữa một báo cáo lỗi và mã nguồn, để thực hiện lời hứa đó, chúng cần một lượng lớn báo cáo lỗi để học ngữ nghĩa của dự án và sau đó liên kết nó với changeset gây ra lỗi. Số lượng ví dụ huấn luyện không đủ có thể dẫn đến mô hình overfitting, ghi nhớ các mẫu hoặc cấu trúc tần suất cao thay vì tổng quát hóa kiến thức. DA có thể giúp giải quyết vấn đề khan hiếm dữ liệu trong định vị lỗi bằng cách tập trung vào các mục tiêu sau.

1. Tăng số lượng báo cáo lỗi. Huấn luyện một mô hình DL cho định vị lỗi đòi hỏi một dataset đáng kể bao gồm báo cáo lỗi và changeset gây ra lỗi. Thách thức chính của việc xây dựng dataset như vậy là nó cụ thể cho dự án. Hầu hết các dự án phần mềm thường có ít báo cáo lỗi với chỉ dẫn rõ ràng về changeset gây ra chúng. Hơn nữa, tổng số báo cáo lỗi trong một dự án là giới hạn trên của số lượng instance huấn luyện dương có sẵn. Lưu ý rằng trong khi chúng ta có thể tạo ra nhiều instance âm (tức là một báo cáo lỗi và một changeset không gây ra lỗi), lợi ích cho mô hình DL bị hạn chế vì báo cáo lỗi vẫn giữ nguyên trong mỗi instance. Hơn nữa, trong tất cả các lỗi được báo cáo, một số được đóng với trạng thái Won't fix hoặc Not a Bug, do đó chúng không có changeset tương ứng và không thể được sử dụng để huấn luyện. Để xác minh thực nghiệm quy mô vấn đề khan hiếm dữ liệu trong dữ liệu định vị lỗi, chúng tôi kiểm tra Bench4BL, một dataset định vị lỗi lớn. Bench4BL bao gồm 10K báo cáo lỗi và các bản sửa đến từ 51 dự án phần mềm mã nguồn mở phổ biến và được phát triển tích cực, tương đương với khoảng 200 báo cáo lỗi mỗi dự án. Xem xét rằng các dự án trong dataset Bench4BL thường lớn và được thiết lập tốt (ví dụ: các dự án Apache Software Foundation chạy lâu dài như Camel và Hive), 200 báo cáo lỗi là một con số thấp đáng lo ngại khi nói đến khả năng huấn luyện một mô hình DL hiệu quả.

2. Duy trì tính bất biến nhãn của báo cáo lỗi. Trong NLP, tăng cường dữ liệu chủ yếu được đánh giá trên các nhiệm vụ phân loại, như phân tích cảm xúc hoặc phân loại chủ đề, trong đó hiếm khi một từ đơn lẻ có thể đại diện cho kết quả tổng thể (tức là một cảm xúc hoặc một chủ đề). Dữ liệu trong kỹ thuật phần mềm là sự kết hợp của ngôn ngữ tự nhiên và các đoạn liên quan đến mã. Trong trường hợp định vị lỗi, sự kết hợp này thường ảnh hưởng đến báo cáo lỗi, thường chứa không chỉ mô tả ngôn ngữ tự nhiên mà còn đề cập đến các phần tử chương trình liên quan, stack trace hoặc đoạn mã. Việc áp dụng các phép biến đổi tăng cường dữ liệu có sẵn vào dữ liệu định vị lỗi có thể gây hại nhiều hơn lợi vì nó không phân biệt giữa NL và mã, cả hai đều mang thông tin hữu ích, nhưng ở các dạng và số lượng khác nhau. Bảng 1 cho thấy các ví dụ về tăng cường văn bản được thực hiện trên tóm tắt báo cáo lỗi #55996 từ dự án Tomcat bằng hai toán tử tăng cường được đề xuất bởi Wei et al. Random Swap trao đổi hai từ được chọn ngẫu nhiên, trong khi Synonym Replacement thay thế một từ được chọn ngẫu nhiên bằng từ đồng nghĩa của nó. Để tìm từ đồng nghĩa, chúng tôi sử dụng BERTOverflow, một mô hình BERT được pre-train trên corpus StackOverflow. Với tính ngẫu nhiên của các phép toán tăng cường dữ liệu, chúng ta thấy các phiên bản khác nhau của tóm tắt báo cáo lỗi được tăng cường. Trong khi Random Swap 1 trao đổi hai từ mà không ảnh hưởng đến ngữ nghĩa, Random Swap 2 trao đổi các từ có thể chỉ ra thành phần mã liên quan, nếu một dự án chứa các lớp AsyncContext và AsyncConnector. Tương tự, trong trường hợp Synonym Replacement 1, việc thay đổi context thành session ảnh hưởng đến ngữ nghĩa ít hơn so với việc thay thế Async bằng TCP là các khái niệm khác nhau. Ví dụ đơn giản này cho thấy việc tăng cường dữ liệu có sẵn có thể dễ dàng đưa vào nhiễu ảnh hưởng đến nhãn gốc, đặc biệt khi xử lý dữ liệu chứa các cụm từ liên quan đến kỹ thuật phần mềm chính. Do đó, việc tăng cường dữ liệu kỹ thuật phần mềm nói chung, và báo cáo lỗi nói riêng, đòi hỏi các bước bổ sung để đảm bảo tính bất biến của các điểm dữ liệu mới được tạo ra.

3. Đa dạng hóa dữ liệu huấn luyện. Mục tiêu của đa dạng hóa dữ liệu trong DA là đảm bảo rằng dữ liệu được tăng cường đưa vào "chất lượng mới" cho một tập huấn luyện, như các motif, mẫu hoặc biểu thức chưa được quan sát trước đó, dẫn đến việc mô hình DL học ý nghĩa đằng sau dữ liệu thay vì ghi nhớ một số dạng nhất định. Trong trường hợp định vị lỗi, dataset huấn luyện mô tả cách ngôn ngữ tự nhiên mô tả một lỗi kết nối với các khái niệm mã nguồn trong changeset gây ra lỗi. Thông thường, ngôn ngữ tự nhiên trong báo cáo lỗi bao gồm Hành vi Quan sát (Observed Behavior - OB), Hành vi Mong đợi (Expected Behavior - EB), hoặc Các bước Tái hiện (Steps to Reproduce - S2R). Do OB, EB và S2R đã được các nhà phát triển công nhận là thông tin hữu ích khi sửa một lỗi, việc tăng cường cho dữ liệu định vị lỗi nên tập trung vào việc đưa vào sự đa dạng vào những yếu tố này thông qua, ví dụ, diễn giải lại các câu của chúng. Thành phần quan trọng thứ hai của việc đa dạng hóa một tập huấn luyện định vị lỗi là các kết nối giữa báo cáo lỗi và mã nguồn. Mặc dù đúng rằng lỗi không được phân bố đều trong cơ sở mã nguồn, việc đại diện quá mức của một thành phần mã nguồn (ví dụ: lớp, package) trong tập huấn luyện, có thể dẫn đến mô hình đổ lỗi cho thành phần cụ thể đó cho mọi lỗi. Để tính đến điều đó, trong khi tăng cường tập huấn luyện cho định vị lỗi, các bước bổ sung có thể được thực hiện để giảm thiểu rủi ro đó, thông qua, ví dụ, tạo ra nhiều báo cáo lỗi được tăng cường hơn cho những thành phần mã nguồn xuất hiện ít hơn trong tập huấn luyện. Tóm lại, việc đa dạng hóa dữ liệu huấn luyện nên tập trung vào: (1) sửa đổi nội dung ngôn ngữ tự nhiên của một báo cáo lỗi, và (2) đa dạng hóa cách một báo cáo lỗi kết nối với mã nguồn.

3 PHƯƠNG PHÁP

Để tạo ra các báo cáo lỗi được tăng cường đưa vào sự đa dạng và bảo toàn tính bất biến (tức là báo cáo lỗi được tăng cường vẫn khớp với cùng changeset như báo cáo lỗi gốc), chúng tôi đề xuất một tập các toán tử DA tùy chỉnh. Báo cáo lỗi mô tả lỗi phần mềm bằng các loại thông tin khác nhau, như ngôn ngữ tự nhiên, đoạn mã hoặc stack trace, có thể có tác động khác nhau đến việc ghép nối một báo cáo lỗi với changeset gây ra nó, do đó chúng tôi quyết định tăng cường riêng biệt thông tin ngôn ngữ tự nhiên và thông tin liên quan đến mã để đảm bảo tính bất biến của các điểm dữ liệu mới được tạo ra và tránh đưa vào nhiễu. Hình 1 minh họa quy trình làm việc của quá trình tăng cường dữ liệu của chúng tôi bắt đầu với việc trích xuất và xử lý trước dữ liệu, theo sau là tăng cường với các toán tử được đề xuất, và xây dựng các báo cáo lỗi được tăng cường kết hợp dữ liệu mới được tạo ra.

3.1 Xử lý trước dữ liệu

Như một bước đầu tiên, chúng tôi sử dụng infozilla, một công cụ trích xuất stack trace và đoạn mã từ nội dung báo cáo lỗi không có cấu trúc, để lại văn bản còn lại được phân loại rộng rãi là ngôn ngữ tự nhiên. Infozilla tạo ra lỗi tối thiểu vì các thí nghiệm đã cho thấy nó có 97%+ độ chính xác, 95%+ độ nhạy và 97%+ độ chính xác. Để đưa ra cấu trúc chi tiết hơn từ dữ liệu ngôn ngữ tự nhiên, chúng tôi trích xuất Hành vi Quan sát (OB), Hành vi Mong đợi (EB), và Các bước Tái hiện (S2R) sử dụng công cụ BEE, đã cho thấy rất hiệu quả trong nhiệm vụ này (94%+ độ chính xác, 87%+ độ nhạy, 70%+ độ chính xác).

Stack trace là một nguồn gợi ý định vị có giá trị, tuy nhiên, do độ dài của chúng, chúng có xu hướng đưa vào nhiễu thông qua nhiều lần đề cập đến các lớp không nhất thiết liên quan đến một báo cáo lỗi cụ thể. Để giảm thiểu nhiễu trong stack trace, chúng tôi giảm kích thước của chúng bằng cách chọn các dòng có khả năng chứa thông tin liên quan nhất. Chẳng hạn, đối với stack trace Java, điều này dẫn đến ba nhóm: 1) dòng trên cùng, bao gồm tên exception và nơi exception bắt nguồn; 2) dòng giữa, xuất hiện sau các trace thư viện chuẩn Java và có khả năng là dòng cuối cùng của mã ứng dụng gần nhất với lỗi; và 3) dòng dưới cùng, có thể hữu ích cho các exception được ném từ threads. Lấy mẫu từ ba nhóm này tạo ra một công thức chung rút ngắn stack trace, nắm bắt các thiết kế phần mềm khác nhau, và bảo toàn thông tin quan trọng. Do đó, cho mỗi stack trace, chúng tôi quyết định giữ 1 dòng trên cùng, 3 dòng đầu tiên tham chiếu đến mã ứng dụng, và 1 dòng dưới cùng. Các phương pháp heuristic như thế này đã được báo cáo là hoạt động khá tốt ngay cả trên dữ liệu runtime không có cấu trúc (ví dụ: log crash thô với nhiều stack trace, có thể từ các ngôn ngữ lập trình khác nhau).

Để xử lý trước đoạn mã, chúng tôi quyết định lọc ra dấu câu vì hai lý do. Thứ nhất, trong một nghiên cứu được công bố gần đây, Paltenghi et al. so sánh suy luận của các nhà phát triển và mô hình neural, và quan sát rằng các mô hình chú ý nhiều hơn đến token cú pháp (ví dụ: dấu chấm, dấu chấm, dấu ngoặc), trong khi các nhà phát triển tập trung nhiều hơn vào chuỗi hoặc từ khóa. Do các nhà phát triển hoạt động tốt hơn, các mô hình DL nên bắt chước các nhà phát triển và chú ý ít hơn đến token cú pháp. Lý do thứ hai để lọc dấu câu là thực dụng - giảm số lượng token để tránh vượt quá giới hạn kích thước đầu vào của các mô hình DL. Sau khi xử lý trước, mỗi báo cáo lỗi được biểu diễn như một tập hợp của OB, EB, S2R, stack trace, và đoạn mã.

3.2 Các toán tử DA ngôn ngữ tự nhiên

Nhóm toán tử này được áp dụng cho OB, EB, và S2R do nội dung chủ yếu là ngôn ngữ tự nhiên của chúng. Chúng tôi đề xuất sử dụng hai loại toán tử: cấp token và cấp đoạn văn. Được truyền cảm hứng từ một kỹ thuật đơn giản nhưng hiệu quả gọi là Easy Data Augmentation (EDA), chúng tôi đề xuất sử dụng 4 toán tử cấp token.

• Dictionary Replace - chọn ngẫu nhiên một từ từ từ điển trong miền được xác định trước và thay thế từ đó bằng từ thay thế của nó.
• Dictionary Insert - hoạt động tương tự như Dictionary Replace, tuy nhiên thay vì thay thế từ, toán tử này chèn từ thay thế vào một vị trí ngẫu nhiên trong văn bản.
• Random Swap - chọn ngẫu nhiên hai từ và trao đổi chúng.
• Random Delete - xóa một từ được chọn ngẫu nhiên.

Để xây dựng từ điển trong miền để tăng cường OB, EB và S2R, chúng tôi sử dụng từ khóa từ các mẫu ngôn ngữ được thiết kế bởi Chaparro et al. Các mẫu chỉ định sự kết hợp của các phần từ loại khác nhau với một số từ khóa nhất định phải xuất hiện để phân loại một câu hoặc một đoạn văn là OB, EB hoặc S2R. Chẳng hạn, một trong những mẫu OB phổ biến nhất là NEG_VERB được định nghĩa là: (chủ ngữ/cụm danh từ) ([tính từ/trạng từ]) [động từ phủ định] ([bổ ngữ]), trong đó các động từ phủ định được định nghĩa là: affect, break, block, close, v.v. Từ điển trong miền chứa tất cả từ khóa được xác định bởi Chapparo et al. và ánh xạ mỗi từ khóa tới các từ thay thế của nó, ví dụ: affect→{break, block, close, ...}. Các toán tử được hướng dẫn bởi kiến thức miền gần đây đã được chỉ ra dẫn đến hiệu suất tốt hơn so với các phương pháp tiên tiến hơn nhưng tổng quát (ví dụ: embeddings).

Như một toán tử cấp đoạn văn, chúng tôi sử dụng Backtranslation để dịch các đoạn văn của OB, EB hoặc S2R từ tiếng Anh sang tiếng Đức và ngược lại sang tiếng Anh. Backtranslation là một phép toán tăng cường dữ liệu phổ biến cho phép diễn giải lại văn bản gốc.

Cuối cùng, hãy mô tả cách các toán tử này được áp dụng cùng nhau để tạo ra dữ liệu được tăng cường. Đối với mỗi báo cáo lỗi và cho mỗi OB, EB, S2R, chúng tôi áp dụng tất cả các toán tử cấp token n lần, trong đó n = λ * #tokens. Các toán tử được áp dụng theo thứ tự sau: thay thế, chèn, trao đổi và xóa. Giá trị của λ được đặt thành 0.1 cho các phép toán chèn, thay thế, và trao đổi, và 0.05 cho phép toán xóa vì những tham số này đã được chỉ ra thực nghiệm là tạo ra kết quả tốt nhất. Tiếp theo, toán tử Backtranslation được áp dụng để diễn giải lại văn bản đã sửa đổi. Do tính ngẫu nhiên của các toán tử tăng cường, chất lượng của mẫu được tăng cường có thể thay đổi. Trong khi, nói chung, văn bản ngôn ngữ tự nhiên thường giữ nguyên ngữ nghĩa khi nhiễu nhỏ được đưa vào, báo cáo lỗi là loại dữ liệu có cấu trúc hơn với một số từ khóa nhất định (ví dụ: tên mã), việc loại bỏ chúng có thể có hậu quả nghiêm trọng cho việc ánh xạ báo cáo lỗi tới mã nguồn. Do đó, như một bước cuối cùng, chúng tôi sử dụng kiểm soát chất lượng bao gồm hai bước. Thứ nhất, chúng tôi kiểm tra xem OB, EB và/hoặc S2R có thể vẫn được xác định trong đoạn văn được tăng cường bằng công cụ BEE không. Chẳng hạn, nếu đoạn văn gốc chứa OB và EB, thì phiên bản được tăng cường phải chứa OB và EB để được coi là một đoạn văn hợp lệ. Chúng tôi cũng không cho phép thay đổi mẫu (ví dụ: từ OB sang EB). Thứ hai, chúng tôi đảm bảo rằng không có token mã nào bị mất trong quá trình tăng cường bằng cách so sánh số lượng token mã giữa đoạn văn được tăng cường và đoạn văn gốc.

3.3 Các toán tử DA liên quan đến mã

Trong bối cảnh của bài báo này, dữ liệu liên quan đến mã đề cập đến stack trace, đoạn mã, và token mã có trong văn bản ngôn ngữ tự nhiên. Để tăng cường dữ liệu liên quan đến mã, chúng tôi đề xuất 3 toán tử token mã là các phiên bản nghiêm ngặt hơn của các toán tử ngôn ngữ tự nhiên để giảm thiểu nguy cơ làm méo mó ngữ cảnh.

• Code Token Replace - chọn ngẫu nhiên một token mã và thay thế nó bằng từ thay thế của nó.
• Code Token Insert - chọn ngẫu nhiên một token mã, và chèn một từ thay thế của token mã đó vào một vị trí ngẫu nhiên cách không quá 3 vị trí từ token mã được chọn.
• Code Token Swap - trao đổi hai token mã được chọn ngẫu nhiên, sao cho (1) đối với stack trace, các token mã chỉ có thể được trao đổi giữa các dòng stack liên tiếp; (2) đối với đoạn mã, một phép toán trao đổi phải được thực hiện trong phạm vi 3 token xung quanh để giảm thiểu khả năng làm méo mó ngữ nghĩa của báo cáo lỗi. Thay đổi điều này thành một giới hạn lớn hơn sẽ dẫn đến việc tạo ra nhiều mẫu đa dạng hơn, tuy nhiên, với cơ hội cao hơn làm xáo trộn ngữ nghĩa của báo cáo lỗi.

Chúng tôi quyết định không bao gồm toán tử xóa token mã vì việc loại bỏ token mã có nhiều khả năng làm xáo trộn tính bất biến của các mẫu được tăng cường.

Để tìm từ thay thế cho một token mã, trước tiên, cho mỗi báo cáo lỗi, chúng tôi xây dựng một từ điển tên mã bằng cách sử dụng tên lớp và phương thức xuất hiện trong changeset gây ra lỗi tương ứng của nó. Tiếp theo, chúng tôi sử dụng khoảng cách Levenshtein để đo khoảng cách giữa token mã được chọn và tất cả các token khác trong từ điển. Khoảng cách Levenshtein là một metric tương tự chuỗi định lượng tương tự thông qua số lượng chỉnh sửa cần thiết để chuyển đổi một chuỗi thành chuỗi khác cho các chuỗi có độ dài tùy ý. Chúng tôi quan sát thực nghiệm rằng các token mã tương tự nhất thường có cùng dạng, và do đó, có thể đưa vào sự đa dạng rất hạn chế vào các mẫu được tăng cường. Chẳng hạn, hãy xem xét token mã word với 3 token gần nhất là is_word, set_word, get_word, và token thứ 20 là check_word_missing_letter. Để cho phép tăng cường đa dạng hơn, dựa trên các quan sát thực nghiệm cho một trong những dự án đánh giá, chúng tôi chọn lựa chọn top-k ít bảo thủ hơn, với k được đặt thành 20. Do đó, một từ thay thế token mã được chọn ngẫu nhiên từ 20 token mã có khoảng cách Levenshtein thấp nhất từ token mã đã cho.

3.4 Xây dựng báo cáo lỗi được tăng cường

Sau khi tăng cường, mỗi báo cáo lỗi được phân giải thành một tập hợp của các mẫu gốc và được tăng cường, tức là dữ liệu ngôn ngữ tự nhiên (OB, EB, S2R), và dữ liệu liên quan đến mã (stack trace và đoạn mã). Câu hỏi còn lại là làm thế nào để xây dựng một báo cáo lỗi tổng hợp từ tất cả các mẫu có sẵn. Công trình gần đây trong dịch máy neural đã cho thấy rằng việc nối các mẫu được tăng cường đưa vào sự đa dạng cấu trúc ngăn chặn một mô hình DL học tập trung chỉ vào một phần của đầu vào, do đó dẫn đến cải thiện mạnh mẽ hiệu suất của mô hình. Chúng tôi đề xuất sử dụng một phương pháp tương tự để xây dựng báo cáo lỗi được tăng cường. Cụ thể hơn, trước tiên chúng tôi tái tạo cấu trúc gốc của một báo cáo lỗi bằng cách nối các mẫu được tăng cường. Tiếp theo, các mẫu được sắp xếp lại và tối đa 1 mẫu có thể được loại bỏ để đạt được sự đa dạng cấu trúc hơn nữa. Trong khi việc loại bỏ các phần của báo cáo lỗi có thể có vẻ phản trực giác, các chiến lược DA loại bỏ token hoặc câu đã được quan sát có tác động tích cực đến các mô hình DL lớn được pre-train. Hình 2 cho thấy báo cáo lỗi #55171 từ dự án Tomcat và phiên bản được tăng cường của nó. Mỗi phần của báo cáo lỗi đã được tăng cường riêng biệt sử dụng tất cả các toán tử DA tương ứng. Trong trường hợp ngôn ngữ tự nhiên, chúng ta thấy các chèn và thay thế chính xác về ngữ nghĩa (ví dụ: blocked→dead), trong khi việc diễn giải lại đoạn văn được thực hiện bởi Backtranslation ít chính xác hơn nhưng vẫn truyền đạt thông điệp chính (ví dụ: OB thứ hai trong hình). Tăng cường mã cho báo cáo lỗi này bao gồm tăng cường stack trace và token mã với tên mã từ changeset gây ra lỗi. Trong khi phương pháp như vậy vốn dĩ hạn chế khả năng thêm nhiễu, nó cũng đưa vào thông tin về các thành phần mã liên quan đến báo cáo lỗi. Điều này, lần lượt cho phép mô hình học các mối quan hệ này và sử dụng chúng trong quá trình suy luận. Cuối cùng, khi xây dựng báo cáo lỗi được tăng cường, OB thứ hai và stack trace đã được trao đổi, trong khi OB thứ ba đã được loại bỏ, tạo ra phiên bản được tăng cường cuối cùng của báo cáo lỗi #55171.

3.5 Đảm bảo một dataset được tăng cường cân bằng

Để tăng kích thước tập huấn luyện định vị lỗi bằng tăng cường dữ liệu, phương pháp của chúng tôi là tập trung vào việc tăng cường báo cáo lỗi, tăng số lượng cặp báo cáo lỗi và hunk gây ra lỗi. Các nghiên cứu gần đây cho thấy rằng việc sử dụng hunk, một tập các sửa đổi dòng liên tiếp nắm bắt các thay đổi trong một khu vực của tệp, tạo ra kết quả truy xuất cải thiện so với việc sử dụng toàn bộ changeset. Do đó, trong công trình này, chúng tôi xây dựng tập huấn luyện định vị lỗi bằng cách sử dụng các cặp báo cáo lỗi và hunk được trích xuất từ changeset gây ra lỗi.

Lỗi ảnh hưởng đến các phần khác nhau của cơ sở mã nguồn với tần suất khác nhau. Nói cách khác, các phần của mã nguồn (tức là các tệp hoặc lớp cụ thể) liên quan đến nhiều báo cáo lỗi và do đó các hunk của chúng cũng có thể được đại diện quá mức trong dataset gốc. Chẳng hạn, cho một báo cáo lỗi với n hunk giới thiệu, tăng cường dữ liệu với hệ số 10 tạo ra 10 báo cáo lỗi mới cho mỗi hunk, dẫn đến 10n mẫu huấn luyện mới. Tuy nhiên, có một nhược điểm chính của phương pháp DA này. Sự mất cân bằng dữ liệu này, được tạo ra bởi sự phân bố không đều của báo cáo lỗi và hunk trong tập huấn luyện, có thể được làm trầm trọng hơn bởi DA, với các hiệu ứng downstream mạnh mẽ lên mô hình DL và dự đoán của nó.

Để cung cấp bằng chứng bổ sung, chúng tôi kiểm tra thực nghiệm dataset được công bố bởi Wen et al., mà chúng tôi sử dụng trong nghiên cứu của mình. Hình 3 cho thấy phân bố của báo cáo lỗi (Hình 3a) và sự xuất hiện của lớp (Hình 3b) cho dự án Tomcat. Các phân bố cho thấy có bao nhiêu mẫu trong dataset huấn luyện tham chiếu đến một báo cáo lỗi (hoặc một lớp) cụ thể, trong đó một báo cáo lỗi (hoặc một lớp) có nhiều lần xuất hiện bằng số lượng hunk. Chúng tôi hiển thị các phân bố này cho ba lựa chọn khác nhau của dataset huấn luyện: dataset gốc chưa được tăng cường, dataset được tăng cường 10x, và dataset được cân bằng nhân tạo. Trong các biểu đồ, có các phiên bản phóng to để tăng độ đọc ở quy mô nhỏ hơn. Trong biểu đồ cho tập huấn luyện gốc (tức là đường màu xanh), chúng tôi quan sát rằng 11 trong số 97 báo cáo lỗi bao phủ hơn 50% (1432 trên 2812) của các mẫu huấn luyện. Nói cách khác, 50% mẫu trong tập huấn luyện tham chiếu đến 11 báo cáo lỗi, vì những báo cáo lỗi này có nhiều hunk giới thiệu, điều này dịch sang nhiều mục trong tập huấn luyện. Đồng thời, 39 báo cáo lỗi xuất hiện ít hơn 10 lần. Tương tự, trong số 110 lớp duy nhất gây ra lỗi, top 10 lớp có hunk xuất hiện thường xuyên nhất bao phủ 34.5% (2586 trên 7478) của tất cả dữ liệu huấn luyện. Sự mất cân bằng này trong dữ liệu huấn luyện có thể có hai hậu quả tiềm tàng cho việc huấn luyện có giám sát của một mô hình DL. Thứ nhất, mô hình có nhiều khả năng học cấu trúc và ngữ nghĩa của các báo cáo lỗi có một số lượng lớn hunk gây ra lỗi, trong khi bỏ qua các báo cáo lỗi ít thường xuyên hơn. Thứ hai, các lớp xuất hiện nhiều nhất trong tập huấn luyện có nhiều khả năng được chọn làm gây ra lỗi bởi mô hình đã huấn luyện vì chúng thường được nhìn thấy trong quá trình huấn luyện là gây ra lỗi. Vấn đề mất cân bằng dữ liệu cũng đã được công nhận trong các dataset dự đoán lỗi.

Cách tăng cường làm trầm trọng hơn vấn đề phân bố dữ liệu không đều có thể được quan sát trong Hình 3, trong đó đường chấm cam mô tả phân bố dữ liệu trong một dataset được tăng cường với hệ số 10. Các báo cáo lỗi và lớp đa số trở nên thậm chí chiếm ưu thế hơn trong dataset được tăng cường, làm cho vấn đề mất cân bằng dữ liệu nghiêm trọng hơn so với dataset gốc. Để giảm thiểu vấn đề này, chúng tôi đề xuất một chiến lược cân bằng dữ liệu cố ý chọn các mẫu để tăng cường nhằm làm mịn các phân bố của báo cáo lỗi liên quan đến mã nguồn. Có hai mối quan tâm chính mà một chiến lược cân bằng dữ liệu phải xem xét: (1) tăng số lượng mẫu huấn luyện cho các báo cáo lỗi ít thường xuyên, và (2) đảm bảo rằng số lượng mẫu với một lớp nhất định không chiếm ưu thế trong dataset. Để minh họa nhu cầu cho các chiến lược này, hãy xem xét một báo cáo lỗi B1 với 20 hunk từ các lớp khác nhau, và một báo cáo lỗi B2 với một hunk từ lớp C. Nếu chiến lược cân bằng chỉ tập trung vào phân bố của báo cáo lỗi, thì nó tạo ra 20 mẫu được tăng cường cho B2, mỗi lần sử dụng hunk từ lớp C, do đó C có khả năng được đại diện quá mức trong tập huấn luyện. Để giải quyết điều này, chúng tôi giới thiệu hai hệ số tăng cường α và ω. Trong khi α ảnh hưởng đến số lần mỗi báo cáo lỗi được tăng cường, ω hạn chế số lần mỗi lớp có thể được lặp lại trong dataset được tăng cường.

Chuỗi các bước cho chiến lược tăng cường cân bằng dữ liệu được đề xuất được trình bày trong Thuật toán 1. Trong dòng 1-2, chúng tôi tính toán một giới hạn cho báo cáo lỗi max_br và lớp max_cl dựa trên các hệ số α và ω và số lần tối đa một báo cáo lỗi và lớp duy nhất có mặt trong dataset huấn luyện gốc. Dòng 3 sao chép các instance dữ liệu hiện có vào dataset cân bằng D_bl. Đối với mỗi báo cáo lỗi xuất hiện dưới giới hạn max_br, thuật toán tăng cường báo cáo lỗi (dòng 6), và chọn một hunk gây ra lỗi từ một lớp xuất hiện ít hơn max_cl lần trong D_bl (dòng 7-8), tạo ra một mẫu huấn luyện mới. Thuật toán tiếp tục thêm các mẫu mới cho một báo cáo lỗi cho đến khi (1) giới hạn max_br được đạt, hoặc (2) hunk gây ra lỗi từ tất cả các lớp đã đạt max_cl. Kết quả của chiến lược cân bằng này được mô tả trong đường màu xanh lá cây trong Hình 3, sử dụng các giá trị α=0.7 và ω=1.0. So với dataset được tăng cường, phân bố dữ liệu của dataset cân bằng rõ ràng mịn hơn, với đại diện đều đặn hơn nhiều của mã nguồn.

4 ĐÁNH GIÁ THỰC NGHIỆM

4.1 Dataset và metrics

Để đánh giá, chúng tôi cần một dataset chứa báo cáo lỗi và changeset gây ra lỗi. Chúng tôi sử dụng một dataset được công bố bởi Wen et al. chứa dữ liệu được xác thực thủ công từ 6 dự án phần mềm mã nguồn mở: AspectJ, JDT, PDE, SWT, Tomcat, và ZXing. Do infozilla yêu cầu dòng mới để trích xuất đoạn mã và stack trace, và dòng mới đã được loại bỏ khỏi tất cả báo cáo lỗi trong dataset của Wen et al., chúng tôi đã tìm lại và re-scrape các báo cáo lỗi (với dòng mới) từ Bugzilla cho tất cả các dự án. Đối với ZXing, các báo cáo lỗi trong trình theo dõi vấn đề GitHub không khớp với những báo cáo được thu thập bởi Wen et al., có thể vì dự án đã được chuyển, và do đó ZXing đã được loại trừ khỏi tập đánh giá. Để tạo ra một tập huấn luyện cho mỗi dự án, chúng tôi sắp xếp các báo cáo lỗi theo ngày mở và chọn nửa đầu để huấn luyện, trong khi các báo cáo lỗi còn lại tạo thành tập kiểm tra. Mỗi mẫu huấn luyện dương tương ứng với một cặp báo cáo lỗi và một trong những hunk gây ra nó (được trích xuất từ changeset gây ra). Mỗi báo cáo lỗi bao gồm tóm tắt và mô tả lỗi, trong khi mỗi hunk chứa thông điệp log và thay đổi mã nguồn. Dataset của Wen et al. được xây dựng bằng SZZ, xác định một changeset là gây ra lỗi nếu nó chia sẻ bất kỳ sửa đổi tệp nào với changeset sửa lỗi. Trong khi một changeset gây ra lỗi có thể bao gồm sửa đổi của nhiều tệp, chỉ một vài trong số đó có thể liên quan đến một lỗi (như được chỉ ra bởi changeset sửa lỗi). Do đó, để đảm bảo chất lượng của các mẫu huấn luyện, chúng tôi chỉ bao gồm các hunk gây ra lỗi tham chiếu đến các lớp cũng xuất hiện trong commit sửa lỗi. Đối với mỗi mẫu dương, chúng tôi tạo ra một mẫu âm bằng cách chọn ngẫu nhiên một hunk từ một lớp không thuộc changeset gây ra. Sau khi hoàn thành bước này, cho mỗi dự án chúng tôi thu được dataset cơ sở của mình, D_ori. Thống kê mô tả của dataset huấn luyện và kiểm tra được sử dụng trong nghiên cứu này được hiển thị trong Bảng 2. Lưu ý rằng cột cuối cùng, # hunks, biểu thị số lượng tất cả hunk được kiểm tra bởi mô hình trong quá trình truy xuất.

Để đánh giá hiệu suất truy xuất của các mô hình DL được huấn luyện trên các dataset khác nhau, chúng tôi sử dụng các metric sau.

Mean Reciprocal Rank: MRR đo độ chính xác truy xuất bằng cách sử dụng hạng reciprocal của changeset liên quan đầu tiên trong bảng xếp hạng được tính trung bình trên tất cả báo cáo lỗi. Giá trị MRR càng cao, changeset gây ra lỗi càng gần với đỉnh bảng xếp hạng.

Mean Average Precision: MAP định lượng khả năng của một mô hình để truy xuất tất cả changeset liên quan cho một báo cáo lỗi nhất định. MAP được tính như trung bình của điểm Average Precision trên tất cả báo cáo lỗi, trong đó Average Precision cho một báo cáo lỗi dựa trên hạng của tất cả changeset liên quan trong bảng xếp hạng. Giá trị MAP càng cao, changeset liên quan càng được đặt ở đỉnh bảng xếp hạng.

Precision@K: P@K đo có bao nhiêu trong số top-K changeset trong bảng xếp hạng liên quan đến một báo cáo lỗi. Giá trị P@K càng cao, changeset liên quan càng có thể được tìm thấy ở vị trí top-K.

4.2 Các mô hình DL

Để đánh giá tác động của chiến lược tăng cường dữ liệu và cân bằng được đề xuất lên hiệu suất truy xuất, chúng tôi huấn luyện và đánh giá ba kiến trúc truy xuất mã dựa trên BERT.

TBERT-Single là phương pháp đơn giản nhất cho truy xuất thông tin với BERT. Mô hình nối một báo cáo lỗi và một hunk, và xử lý nó thông qua BERT và một lớp pooling để thu được một biểu diễn vector được hợp nhất, sau đó được chuyển đến đầu phân loại để thu được điểm liên quan. Trong khi mô hình này thường cung cấp độ chính xác truy xuất cao, nó cũng chịu độ trễ truy xuất đáng kể, vì một báo cáo lỗi cần được so sánh với tất cả hunk có sẵn trong một dự án.

TBERT-Siamese xử lý một báo cáo lỗi và một hunk tuần tự thông qua BERT và một lớp pooling, tạo ra hai vector đặc trưng, sau đó được nối và chuyển đến lớp phân loại để tạo ra điểm liên quan. Sự khác biệt chính giữa TBERT-Single và TBERT-Siamese là cơ hội thực hiện mã hóa offline của các vector đặc trưng cho hunk, do đó giảm độ trễ truy xuất.

FBL-BERT là một kiến trúc dựa trên BERT được đề xuất gần đây cho phép truy xuất nhanh chóng trên tập hợp lớn các tài liệu (tức là hunk). Không giống như TBERT, làm phẳng ma trận embedding thành một vector để đưa ra dự đoán, FBL-BERT tận dụng toàn bộ ma trận embedding và tính điểm liên quan giữa một báo cáo lỗi và một hunk như tổng của độ tương tự vector tối đa giữa embedding từ của báo cáo lỗi và hunk. Điều này, lần lượt, cho phép sử dụng thuật toán tìm kiếm tương tự vector hiệu quả để tìm các hunk tương tự nhất và chỉ xếp hạng lại những hunk đó với FBL-BERT, do đó giảm đáng kể thời gian truy xuất mỗi báo cáo lỗi. Do FBL-BERT tận dụng việc khớp embedding token-to-token chi tiết, mô hình có nhiều khả năng sử dụng tốt hơn các từ khóa liên quan nếu chúng xuất hiện trong báo cáo lỗi.

Trong khi tất cả các mô hình đều dựa trên BERT, kiến trúc của chúng khác nhau ở một số khía cạnh. TBERT-Single nối một báo cáo lỗi và một changeset, xử lý chúng cùng nhau thông qua BERT, theo sau là một lớp phân loại. TBERT-Siamese và FBL-BERT trước tiên sử dụng BERT để mã hóa một báo cáo lỗi và một changeset riêng biệt, dẫn đến hai ma trận embedding. Sự khác biệt chính giữa TBERT-Siamese và FBL-BERT là cách chúng xử lý những ma trận này. TBERT-Siamese tổng hợp mỗi ma trận thành một vector bằng phép toán pooling, và, tiếp theo, so sánh vector embedding của một báo cáo lỗi với vector embedding changeset. Mặt khác, FBL-BERT sử dụng cả hai ma trận để tính điểm liên quan có tính đến embedding của mỗi từ.

4.3 Thiết lập đánh giá

Chúng tôi thực hiện các thí nghiệm trên một máy chủ với Dual 12-core 3.2GHz Intel Xeon và 1 NVIDIA Tesla V100 với 32GB RAM chạy CUDA v.11.4. Các mô hình được triển khai với PyTorch v.1.7.1, thư viện HuggingFace v.4.3.2, và Faiss v.1.6.5 với hỗ trợ GPU. Chúng tôi chọn sử dụng BERTOverflow làm mô hình BERT cơ sở được pre-train của mình, vì, tương tự như dữ liệu của chúng tôi, dữ liệu StackOverflow cũng là sự kết hợp của mã và ngôn ngữ tự nhiên. Tất cả mô hình được fine-tune trong 4 epoch, sử dụng kích thước batch 16 và bộ tối ưu hóa Adam với tốc độ học được đặt thành 3e-6. Dựa trên số lượng token trung bình trong báo cáo lỗi và hunk trong dataset của chúng tôi, chúng tôi đặt giới hạn kích thước đầu vào thành 256 và 512 token cho báo cáo lỗi và hunk tương ứng. Tất cả tài liệu đầu vào được padding hoặc truncate liên quan đến giới hạn kích thước đầu vào của chúng.

5 KẾT QUẢ

5.1 RQ1: (a) Tăng cường Dữ liệu có thể cải thiện hiệu suất truy xuất của định vị lỗi dựa trên DL không? (b) Tăng cường Dữ liệu ảnh hưởng như thế nào đến hiệu suất của các phương pháp định vị lỗi dựa trên DL khác nhau?

Thiết lập. Để đánh giá tác động của DA lên các mô hình dựa trên DL, chúng tôi so sánh độ chính xác truy xuất khi huấn luyện trên dataset gốc, chưa được tăng cường, D_ori, với việc huấn luyện với dữ liệu được tăng cường và cân bằng. Cụ thể hơn, cho mỗi dự án chúng tôi xây dựng năm dataset được tăng cường được hiển thị trong Bảng 3. D_aug là một dataset được tăng cường, nhưng không cân bằng, chứa 10 mẫu bổ sung cho mỗi cặp báo cáo lỗi và hunk, trong khi D_bl_i, i=1,2,3,4, là các dataset cân bằng với các lựa chọn khác nhau cho (α,ω) = {(0.7,1.0);(0.85,2.0);(1.0,2.0);(1.3,2.0)} tương ứng. Lý do cho những giá trị cụ thể này của α và ω là để khám phá α (trong phạm vi không tạo ra nhiều dữ liệu hơn chúng tôi có thể quản lý tính toán), trong khi chọn các giá trị cho ω không hạn chế hiệu ứng của α. Do tăng cường tăng số lượng mẫu dương, số lượng mẫu âm cũng tăng tỷ lệ thuận (tức là cho mỗi mẫu dương, chúng tôi tạo ngẫu nhiên một mẫu âm). Để đảm bảo rằng sự khác biệt trong hiệu suất thực sự là kết quả của DA, chứ không phải sự đa dạng được đưa vào bởi một mẫu âm mới, chúng tôi tạo ra một baseline bổ sung, D_rep, lặp lại các mẫu dương mà không tăng cường 10 lần, và, tương ứng, cũng thêm 10 mẫu âm mới. Thực tế, sự khác biệt duy nhất giữa D_rep và D_aug là D_aug sử dụng báo cáo lỗi được tăng cường trong khi D_rep lặp lại các mẫu dương. Tất cả mô hình được đánh giá trên cùng một tập kiểm tra (chưa được tăng cường). Vì TBERT-Single đòi hỏi thời gian nhiều hơn đáng kể so với các mô hình khác (ví dụ: TBERT-Single mất hơn 24 giờ để chạy trên dự án JDT), chúng tôi chỉ đánh giá nó trên một trong các dataset cân bằng - D_bl1 - vì nó thể hiện hiệu suất tốt nhất cho TBERT-Siamese, sử dụng kiến trúc DL tương đối tương tự với TBERT-Single.

Để đánh giá ý nghĩa thống kê của sự khác biệt trong hiệu suất khi huấn luyện các mô hình DL có và không có tăng cường dữ liệu, chúng tôi sử dụng kiểm định t ghép cặp Student để tính p-value giữa các metric hiệu suất của D_ori và tất cả các dataset khác (tức là D_rep, D_aug, D_bl*). Kiểm định giả định các giá trị hiệu suất được phân phối bình thường. Chúng tôi coi p<0.05 là có ý nghĩa thống kê.

Kết quả. Bảng 4 cho thấy hiệu suất truy xuất của FBL-BERT, TBERT-Siamese và TBERT-Single được huấn luyện trên bốn dataset: D_ori, D_rep, D_aug và D_bl*, trong đó D_bl* biểu thị dataset cân bằng hoạt động tốt nhất trung bình cho mô hình đã cho. Phần trên cùng của bảng cho thấy kết quả trên các báo cáo lỗi từ tất cả dự án, theo sau là kết quả theo dự án. Nói chung, chúng tôi quan sát rằng các mô hình cải thiện trên tất cả các metric so với D_ori, với cải thiện thấp nhất được ghi nhận cho D_rep, theo sau là D_aug, và với cải thiện cao nhất được ghi nhận cho D_bl*.

Tùy thuộc vào mô hình, quy mô cải thiện thay đổi. Trong khi điểm MRR cho FBL-BERT tăng từ 0.264 cho D_ori lên 0.367 cho D_bl*, khoảng một nửa cải thiện có thể được quy cho kích thước dataset như được chỉ ra bởi kết quả cho D_rep với điểm MRR là 0.307. Hơn nữa, chúng tôi cũng quan sát rằng D_aug cải thiện điểm số từ 0.307 cho D_rep lên 0.353, cho thấy rằng việc sử dụng một dataset được tăng cường tạo ra sự khác biệt không chỉ thông qua số lượng dữ liệu. Sự cải thiện giữa D_aug và D_bl* là nhỏ và bằng 0.014, cho thấy rằng ngay cả cấu hình cân bằng tốt nhất cũng có tác động nhỏ lên FBL-BERT nói chung.

Huấn luyện với dataset cân bằng có tác động lớn hơn lên TBERT-Single và TBERT-Siamese với cải thiện 0.035 và 0.092 điểm MRR tương ứng khi so sánh với D_aug. Hơn nữa, cân bằng dữ liệu là yếu tố đóng góp chính cho sự cải thiện trong TBERT-Siamese mà sự khác biệt có ý nghĩa thống kê chỉ được quan sát cho D_bl*. Trong trường hợp TBERT-Single, huấn luyện mô hình với cả D_aug và D_bl* dẫn đến cải thiện đáng kể trên tất cả các metric.

RQ1 (a): Tăng cường dữ liệu cải thiện kết quả định vị lỗi dựa trên DL trên tất cả các mô hình. Việc sử dụng cân bằng dữ liệu với tăng cường có thể cải thiện hiệu suất hơn nữa.

Bảng 5 cho thấy độ chính xác truy xuất cho FBL-BERT và TBERT-Siamese khi các mô hình được huấn luyện trên các dataset cân bằng khác nhau, với các giá trị của α, ω và kích thước dataset được cung cấp ở phía bên phải của bảng. Trong trường hợp FBL-BERT, D_bl2 và D_bl3 cung cấp hiệu suất tốt nhất trung bình, cải thiện MRR và MAP 16.8% và 14.8% so với D_bl1 và D_bl4. Tuy nhiên, như đã lưu ý trước đó, sự cải thiện so với dataset không cân bằng D_aug là nhỏ. Trong trường hợp TBERT-Siamese, dataset cân bằng nhỏ nhất, D_bl1, tạo ra điểm MRR cao nhất là 0.328 vượt trội hơn dataset cân bằng khác ít nhất 49%.

Sự khác biệt trong hiệu suất của các mô hình với các dataset khác nhau có thể được quy cho (1) sự khác biệt tổng thể trong kiến trúc của các mô hình ảnh hưởng đến nhu cầu của mô hình về dữ liệu huấn luyện; và (2) kích thước của mỗi dự án được đo bằng số lượng hunk (xem Bảng 2). Để hiểu rõ hơn liệu và khi nào mô hình có thể cần nhiều dữ liệu hơn, trong Hình 4 chúng tôi hiển thị điểm MRR trên tất cả các dự án đánh giá được sắp xếp theo kích thước của chúng, tức là số lượng hunk trong một dự án.

RQ1 (b): Kết quả cho thấy các kiến trúc mô hình khác nhau có thể có nhu cầu khác nhau về kích thước dataset huấn luyện để đạt được hiệu suất tối ưu của chúng. Một số mô hình được hưởng lợi từ nhiều mẫu được tăng cường hơn, đặc biệt là đối với các dự án lớn hơn.

5.2 RQ2: Toán tử DA nào được đề xuất đóng góp nhiều nhất cho hiệu suất truy xuất?

Thiết lập. Để hiểu rõ hơn ảnh hưởng của các toán tử tăng cường dữ liệu được đề xuất lên hiệu quả của mô hình downstream, chúng tôi thực hiện nghiên cứu ablation trên các dataset huấn luyện được tạo ra bằng cách sử dụng tất cả trừ một loại toán tử tăng cường. Để làm điều này, chúng tôi tạo ra 5 loại dataset huấn luyện được tăng cường: No Backtranslation, No Insert, No Delete, No Replace và No Swap operator. Lưu ý rằng chúng tôi coi, ví dụ, cả Code Token Swap và Random Swap là các toán tử của loại Swap. Để cân bằng các dataset, chúng tôi sử dụng các giá trị α và ω từ RQ1 dẫn đến hiệu suất tốt nhất cho các mô hình, tức là cho FBL-BERT α=0.85, ω=2.0, trong khi cho các mô hình TBERT α=0.7, và ω=1.0.

Kết quả. Hình 5 cho thấy điểm MRR cho các dataset được tăng cường với 4 trong số 5 loại toán tử cũng như điểm MRR của D_ori và D_aug như các đường ngang để tham khảo. Chúng tôi lưu ý rằng hầu hết các toán tử đều đóng góp vào hiệu suất cuối cùng, với ngoại lệ của toán tử Swap cho FBL-BERT. Việc thiếu tác động của toán tử Swap có thể được quy cho kiến trúc mô hình. Do FBL-BERT tận dụng tất cả các token trong một báo cáo lỗi riêng biệt, việc trao đổi vị trí token không ngăn cản chúng được khớp. Mặt khác, việc loại trừ Random Insert ảnh hưởng đến FBL-BERT nhiều nhất, cho thấy rằng các token được chèn có giá trị đối với mô hình và cải thiện hiệu quả của nó khi khớp embedding token. Toán tử Delete là người đóng góp nổi bật nhất cho hiệu suất của cả hai mô hình TBERT. Khi toán tử Delete không được phép trong quá trình tăng cường, điểm MRR của các dataset được tăng cường giảm 0.054 và 0.055 cho TBERT-Single và TBERT-Siamese tương ứng, cho thấy rằng sự thay đổi gây ra bởi việc loại bỏ token ngẫu nhiên có tác động tích cực. Toán tử Delete, khi được áp dụng với mức độ tương đối vừa phải, dường như bổ sung cho tính mạnh mẽ của các mô hình, tức là các mô hình tạo ra các liên kết bổ sung giữa các thuật ngữ và khái niệm trong báo cáo lỗi và changeset. Giá trị của quá trình này cũng được hỗ trợ bởi công trình gần đây trong huấn luyện adversarial của các mô hình ngôn ngữ lớn, như BERT, để cải thiện tính mạnh mẽ của chúng chống lại các cuộc tấn công độc hại.

RQ2: Tất cả các toán tử DA đều đóng góp vào việc cải thiện hiệu suất với mức độ khác nhau, ngoại trừ Swap cho FBL-BERT. Toán tử Delete liên tục cải thiện hiệu suất trong cả ba mô hình.

5.3 Các mối đe dọa tính hợp lệ

Có một số mối đe dọa tính hợp lệ của các phát hiện của chúng tôi. Một mối đe dọa đối với tính hợp lệ nội tại của nghiên cứu là các lựa chọn tham số cho các mô hình định vị lỗi dựa trên DL, đặc biệt trong bối cảnh (1) quy trình huấn luyện; (2) lựa chọn BERT-base; và (3) các tham số vốn có của mỗi mô hình. Để giảm thiểu mối đe dọa đó, trong quá trình huấn luyện chúng tôi tuân theo khuyến nghị của các tác giả BERT, trong khi cho mỗi mô hình chúng tôi sử dụng các tham số được xác định là tối ưu bởi các nghiên cứu trước đó. Trong khi trong nghiên cứu của chúng tôi, chúng tôi sử dụng BERTOverflow làm mô hình BERT cơ sở của mình, các lựa chọn khác tồn tại (ví dụ: CodeBERT), và nhiều mô hình đang được tiến hành, do đó chúng tôi để lại việc đánh giá các mô hình BERT cơ sở khác nhau trong bối cảnh định vị lỗi cho công việc tương lai.

Một mối đe dọa nội tại khác là trong các lựa chọn của chúng tôi về toán tử tăng cường, tham số của chúng (ví dụ: λ), và cách chúng được áp dụng cùng nhau (ví dụ: stacking toán tử). Mối đe dọa này được giảm thiểu bằng cách tuân theo các thực hành tốt nhất được biết từ văn học tăng cường NLP tập trung vào các toán tử cấp token và các nhiệm vụ trong miền. Trong khi chúng tôi khám phá một số lựa chọn tham số cho cân bằng dữ liệu trong bài báo (ví dụ: α và ω), cũng có các tham số bổ sung liên quan đến quy trình xây dựng báo cáo lỗi cũng như các toán tử tăng cường khác có thể cung cấp cải thiện nhiều hơn.

Các công cụ bên ngoài mà chúng tôi tận dụng để xây dựng pipeline tăng cường của mình, ví dụ: infozilla, công cụ BEE, có thể đưa vào nhiễu lan truyền đến các kết quả được báo cáo của chúng tôi. Tuy nhiên, đây là các công cụ tiên tiến đã được đánh giá kỹ lưỡng nên tỷ lệ lỗi của chúng nên được hạn chế.

Hơn nữa, tính ngẫu nhiên của các toán tử tăng cường có thể gây ra mối đe dọa đối với tính hợp lệ nội tại. Để giảm thiểu điều đó, chúng tôi đảm bảo đặt một giá trị ban đầu trên bộ sinh số ngẫu nhiên giả của hệ thống khi xây dựng một dataset được tăng cường cũng như khi huấn luyện một mô hình DL.

Một mối đe dọa đối với tính hợp lệ bên ngoài là chúng tôi chỉ đánh giá kỹ thuật tăng cường dữ liệu cho định vị lỗi trên một số lượng hạn chế lỗi được thu thập từ một lựa chọn các dự án Java mã nguồn mở. Mối đe dọa này được giảm thiểu bởi thực tế rằng dataset đã được sử dụng trong một số nghiên cứu định vị lỗi trước đó. Một yếu tố giảm thiểu khác là các dự án phản ánh nhiều mục đích, phong cách phát triển và lịch sử khác nhau.

Hạn chế trong các metric đánh giá đã chọn gây ra mối đe dọa đối với tính hợp lệ kết luận vì chúng có thể không đo trực tiếp sự hài lòng của người dùng với các hunk thay đổi được truy xuất. Mối đe dọa được giảm thiểu bởi thực tế rằng các metric đã chọn được biết đến và được chấp nhận rộng rãi là tốt nhất có sẵn để đo và so sánh hiệu suất của các kỹ thuật IR.

6 KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI

Các mô hình DL hướng đến định vị lỗi xuất sắc trong việc thu hẹp khoảng cách từ vựng giữa ngôn ngữ tự nhiên mô tả một báo cáo lỗi và ngôn ngữ lập trình định nghĩa mã nguồn. Tuy nhiên, việc huấn luyện một mô hình DL hiệu quả đòi hỏi lượng lớn dữ liệu có nhãn cụ thể cho dự án (tức là các cặp báo cáo lỗi và changeset gây ra lỗi), thường khó có được với số lượng đủ cho một dự án đơn lẻ. Để giảm bớt yêu cầu về số lượng dữ liệu, và cho phép sử dụng mô hình DL khi dữ liệu huấn luyện khan hiếm, công trình này đề xuất sử dụng tăng cường dữ liệu (DA) để tạo ra các báo cáo lỗi mới, có vẻ thực tế có thể được sử dụng để tăng đáng kể kích thước tập huấn luyện. Để tăng cường báo cáo lỗi, chúng tôi đề xuất các toán tử DA độc lập tăng cường nội dung ngôn ngữ tự nhiên và liên quan đến mã của một báo cáo lỗi. Để xây dựng một dataset huấn luyện mới bằng cách sử dụng báo cáo lỗi được tăng cường, chúng tôi đề xuất một chiến lược cân bằng dữ liệu chọn lọc tăng cường báo cáo lỗi để thêm nhiều mẫu huấn luyện hơn cho các phần được đại diện ít của mã nguồn.

Kết quả cho thấy rằng tăng cường dữ liệu được đề xuất cải thiện độ chính xác truy xuất trên tất cả các mô hình DL được nghiên cứu, tăng điểm MRR từ 39% đến 82% so với dataset gốc, chưa được tăng cường. Hơn nữa, khi các dataset được tăng cường được so sánh với các tập huấn luyện được mở rộng bằng lặp lại dữ liệu, chúng tôi quan sát rằng chúng cải thiện điểm MRR 20% đến 36%. Tất cả các toán tử DA được đề xuất đều đóng góp vào hiệu suất cuối cùng, với việc xóa token mang lại tác động nhất quán nhất cho các mô hình DL khác nhau.

Đây là một trong những bài báo đầu tiên giới thiệu tăng cường dữ liệu cho kỹ thuật phần mềm. Chúng tôi tin rằng tăng cường dữ liệu như một kỹ thuật có tiềm năng cho SE vì các dataset không lớn như trong ML chính thống. Ngoài ra, tăng cường dữ liệu không phải là kỹ thuật một-size-fits-all và ứng dụng tối ưu của nó đòi hỏi các toán tử tùy chỉnh, vì vậy bài báo đóng góp trong việc thiết kế các toán tử tăng cường dữ liệu cho báo cáo lỗi và áp dụng chúng bằng cách sử dụng chiến lược cân bằng dữ liệu.

Mặc dù vậy, phương pháp được đề xuất đòi hỏi thêm thí nghiệm để tăng cường các quan sát và khuyến nghị của chúng tôi. Như công việc tương lai của chúng tôi, chúng tôi dự định (1) mở rộng các dataset đánh giá của chúng tôi với các dự án phần mềm mới được viết bằng Java, Python và Javascript; (2) tiến hành thí nghiệm với dữ liệu được tăng cường nhiều hơn, tức là bằng cách sử dụng các toán tử DA trên một số lượng lớn hơn các token; (3) thí nghiệm với các toán tử xóa khác nhau (ví dụ: loại bỏ token mã không liên quan) do hiệu suất tốt của Random Delete cho ngôn ngữ tự nhiên; và (4) thí nghiệm với các cấu hình khác nhau cho trình xây dựng báo cáo lỗi.

7 KHẢ DỤNG DỮ LIỆU

Một gói tái tạo bao gồm tất cả mã và script liên quan có sẵn tại https://anonymous.4open.science/r/fbl-bert-987B.

# PYInfer: Suy luận Loại Ngữ nghĩa Học Sâu cho Biến Python

Siwei Cui
Đại học Texas A&M
College Station, Texas
siweicui@tamu.edu

Luochao Wang
Đại học Texas A&M
College Station, Texas
wangluochao@tamu.edu

Gang Zhao
Đại học Texas A&M
College Station, Texas
zhaogang92@tamu.edu

Ruihong Huang
Đại học Texas A&M
College Station, Texas
huangrh@cse.tamu.edu

Zeyu Dai
Đại học Texas A&M
College Station, Texas
jzdaizeyu@tamu.edu

Jeff Huang
Đại học Texas A&M
College Station, Texas
jeffhuang@tamu.edu

Tóm tắt — Suy luận kiểu dữ liệu Python là một thử thách trong thực tế. Do tính chất động và sự phụ thuộc rộng rãi vào các thư viện bên thứ ba không có chú thích kiểu, hiệu suất của các kỹ thuật phân tích tĩnh truyền thống bị hạn chế. Mặc dù ngữ nghĩa trong mã nguồn có thể giúp thể hiện cách sử dụng dự định cho các biến (do đó giúp suy luận kiểu), chúng thường bị bỏ qua bởi các công cụ hiện có. Trong bài báo này, chúng tôi đề xuất PYInfer, một công cụ suy luận kiểu dựa trên học máy từ đầu đến cuối tự động tạo chú thích kiểu cho các biến Python. Ý tưởng chính là ngữ nghĩa mã ngữ cảnh rất quan trọng trong việc suy luận kiểu cho một biến. Đối với mỗi lần sử dụng một biến, chúng tôi thu thập một vài token trong phạm vi ngữ cảnh của nó và thiết kế một mạng nơ-ron để dự đoán kiểu của nó. Một thử thách là khó thu thập một bộ dữ liệu huấn luyện được gán nhãn bởi con người chất lượng cao cho mục đích này. Để giải quyết vấn đề này, chúng tôi áp dụng một bộ phân tích tĩnh hiện có để tạo ra sự thật cơ bản cho các biến trong mã nguồn.

Đóng góp chính của chúng tôi là một phương pháp mới để suy luận kiểu biến một cách tĩnh hiệu quả và hiệu quả. Công thức hóa suy luận kiểu như một bài toán phân loại, chúng tôi có thể xử lý các kiểu do người dùng định nghĩa và dự đoán xác suất kiểu cho mỗi biến. Mô hình của chúng tôi đạt được 91.2% độ chính xác trên việc phân loại 11 kiểu cơ bản trong Python và 81.2% độ chính xác trên việc phân loại 500 kiểu phổ biến nhất. Kết quả của chúng tôi vượt trội đáng kể so với các công cụ chú thích kiểu hiện đại. Hơn nữa, PYInfer đạt được 5.2X nhiều hơn về phạm vi bao phủ mã và nhanh hơn 187X so với một công cụ dựa trên học máy hiện đại. Với mức tiêu thụ thời gian tương tự, mô hình của chúng tôi chú thích 5X nhiều biến hơn so với một công cụ phân tích tĩnh hiện đại (PySonar2). Mô hình của chúng tôi cũng vượt trội so với một công cụ chú thích cấp hàm dựa trên học máy (TypeWriter) trong việc chú thích kiểu cho biến và tham số hàm. Tất cả các công cụ và bộ dữ liệu của chúng tôi đều được công khai để hỗ trợ nghiên cứu tương lai theo hướng này.

Từ khóa — Suy luận Kiểu Python, Ngữ nghĩa Mã Ngữ cảnh, Học Sâu.

I. GIỚI THIỆU

Python được sử dụng rộng rãi do tính linh hoạt và sự phong phú của các thư viện bên thứ ba (ví dụ: các framework web và học máy). Tuy nhiên, tính linh hoạt mang lại thử thách cho việc tối ưu hóa mã và cũng làm cho nó dễ bị lỗi. Sự không nhất quán về kiểu biến là một lỗi phổ biến trong các ngôn ngữ động. Do tính chất động của Python, trình thông dịch không thể kiểm tra sự không nhất quán về kiểu như một trình biên dịch ngôn ngữ lập trình tĩnh (ví dụ: Go hoặc Rust). Các bộ kiểm tra kiểu Python [1, 2, 3, 4] tận dụng các chú thích để phát hiện sự không nhất quán về kiểu. Các công cụ này chủ yếu dựa vào các chú thích kiểu được viết thủ công bởi các nhà phát triển, điều này rất tốn kém để cung cấp.

Để hỗ trợ lập trình của người dùng và kiểm tra lỗi kiểu, suy luận kiểu biến là một bước cần thiết. Học sâu đã được áp dụng để suy luận kiểu cho JavaScript [5, 6, 7, 8] bằng cách tận dụng TypeScript [9] để tạo ra kho tài liệu lớn với các chú thích chính xác. Tuy nhiên, tồn tại rất ít giải pháp tốt cho Python do phạm vi rộng của các tính năng động và sự phụ thuộc rộng rãi vào các thư viện bên thứ ba, điều này để lại cho chúng ta nhiều cơ hội trong phạm vi này. Chất lượng của bộ dữ liệu tự nó mang lại một khoảng cách lớn giữa việc chú thích Python và JavaScript.

Các công cụ suy luận kiểu áp dụng phân tích tĩnh hoặc phân tích động [10, 11, 12] không yêu cầu các chú thích được gán nhãn để suy luận kiểu. Tuy nhiên, chúng không chính xác và bỏ qua ngữ nghĩa ngôn ngữ tự nhiên phong phú trong mã nguồn. Xu et al. [13] đề xuất sử dụng một mô hình xác suất để suy luận kiểu biến bằng cách tận dụng các gợi ý kiểu từ luồng dữ liệu, thuộc tính, kiểu con và tên biến. Tuy nhiên, việc này mất thời gian đáng kể để phân tích mã nguồn và giải quyết các ràng buộc xác suất. Không có một bộ dữ liệu đủ lớn để cung cấp đủ tín hiệu, hiệu suất của mô hình xác suất cũng bị hạn chế.

Các chú thích kiểu được gán nhãn bởi con người hiện có trong mypy [1] và typeshed [14] chỉ bao gồm một số ít chú thích cho tham số hàm và kiểu trả về. Bộ dữ liệu không chứa chú thích biến và không đủ để suy luận kiểu biến Python. TypeWriter [15] cũng nhắm đến suy luận kiểu cho Python, nhưng nó giải quyết bài toán suy luận tham số hàm và kiểu trả về. Các thí nghiệm cho thấy TypeWriter không đủ để dự đoán kiểu biến. Các chú thích cấp hàm (tham số hàm và kiểu trả về) hữu ích để phục vụ như một hợp đồng API cho IDE, trong khi các chú thích cấp biến có thể được sử dụng để cung cấp kiểm tra kiểu cho từng biến.

Trong bài báo này, chúng tôi trình bày PYInfer, một phương pháp dựa trên học sâu để tạo chú thích kiểu cho Python. Một tổng quan cấp cao về PYInfer được mô tả trong Hình 1. Vì bộ dữ liệu được gán nhãn bởi con người cho các biến không có sẵn, đầu tiên chúng tôi sử dụng một bộ phân tích tĩnh, PySonar2 [16], để tự động tạo các chú thích ban đầu từ các dự án Python GitHub hàng đầu. Sau đó chúng tôi áp dụng một loạt các kỹ thuật làm sạch dữ liệu để tinh chỉnh chất lượng bộ dữ liệu của chúng tôi. Chúng tôi tiếp tục đưa các chú thích và thông tin ngữ cảnh để huấn luyện một mạng nơ-ron sâu, xếp hạng từng kiểu với xác suất một cách hiệu quả.

Chúng tôi nhấn mạnh rằng việc kết hợp học sâu với phân tích tĩnh để suy luận chú thích kiểu là đầy hứa hẹn. Bằng cách kết hợp học sâu với phân tích tĩnh từ đầu đến cuối, phương pháp của chúng tôi có khả năng phân tích ngữ nghĩa mã với các kỹ thuật xử lý ngôn ngữ tự nhiên (NLP) được phát triển tốt. Hiệu quả của PYInfer có lợi từ việc giải quyết các thử thách sau:

Thu thập Bộ dữ liệu Chú thích. Phân tích ngữ nghĩa mã nguồn ngữ cảnh cho các kiểu biến đòi hỏi một bộ dữ liệu được chú thích lớn. Tuy nhiên, không tồn tại bộ dữ liệu lớn được thừa nhận rộng rãi với các chú thích. Chúng tôi tạo ra bộ dữ liệu được chú thích của chúng tôi với dữ liệu được làm phong phú dựa trên kết quả suy luận từ PySonar2 và thực hiện làm sạch dữ liệu để nâng cao chất lượng, điều này tự nó là một đóng góp quan trọng, bởi vì dữ liệu được gán nhãn chất lượng cao là rất quan trọng đối với học sâu. Bộ dữ liệu của chúng tôi được thu thập từ 4,577 dự án Python phổ biến trên GitHub với 54,928,617 Dòng Mã (LoC) từ 320,402 tập tin nguồn. Nó chứa 77,089,946 chú thích, đủ lớn cho hầu hết nghiên cứu về kiểu Python.

Kiểu Do Người dùng Định nghĩa. Do tính linh hoạt của Python, các kiểu có thể được người dùng định nghĩa và thay đổi trong thời gian chạy. Chúng tôi đóng khung suy luận kiểu Python như một nhiệm vụ phân loại để bao gồm các kiểu do người dùng định nghĩa trong 500 kiểu phổ biến nhất của chúng tôi. Chúng tôi điều tra hiệu suất của 11 kiểu cơ bản so với 500 kiểu. Mô hình của chúng tôi đạt được 91.187% độ chính xác trên việc phân loại 11 kiểu cơ bản và 81.195% trên việc dự đoán 500 kiểu. Đây là một tiến bộ đáng kể so với công việc trước đó [13] về vấn đề này. Như một nhiệm vụ phân loại, mô hình của chúng tôi cung cấp mức độ tin cậy cho từng kiểu. Nó đạt được 97.677% chính xác với ngưỡng 0.9 trên mức độ tin cậy.

Nhúng Mã Nguồn. Mã nguồn chứa thông tin ngữ nghĩa phong phú và gợi ý kiểu trong tên biến và cách sử dụng, điều này hữu ích cho suy luận kiểu. Công việc trước đó [6, 13, 15] đã áp dụng nhúng từ cho suy luận kiểu. Tuy nhiên, chúng tôi cho thấy rằng những nhúng này không hoạt động tốt do vấn đề Out-Of-Vocabulary (OOV) gây ra bởi số lượng lớn các tính năng động và kiểu do người dùng định nghĩa trong Python. Để giải quyết vấn đề này, chúng tôi sử dụng thuật toán Byte Pair Encoding (BPE) [17]. Nó cung cấp đủ tín hiệu để phân tích ngữ nghĩa trong tên biến và dữ liệu ngữ cảnh. So với nhúng dựa trên đồ thị trong LambdaNet [8], nhúng BPE nhẹ và có thể dễ dàng mở rộng để phân tích các ngôn ngữ khác. Chúng tôi chứng minh rằng BPE hiệu quả trong việc suy luận kiểu biến. Mô hình của chúng tôi cải thiện 27.1% độ chính xác với nhúng BPE so với nhúng GloVe [18].

Ngữ nghĩa Mã Ngữ cảnh. Một hiểu biết chính trong phương pháp của chúng tôi là tận dụng ngữ nghĩa mã ngữ cảnh để suy luận kiểu biến. Chúng tôi đưa ra giả thuyết rằng ngữ cảnh trong một biên độ nhất định truyền đạt thông tin ngữ nghĩa liên quan để đặc trưng hóa biến. Lấy cảm hứng từ phân tích tĩnh liên thủ tục [10, 11, 12], phương pháp của chúng tôi có khả năng phân tích ngữ nghĩa của các biến cùng với thông tin cú pháp cấu trúc và ngữ pháp. Việc thiết lập siêu tham số biên độ được minh họa trong Hình 2. Đối với mỗi biến, chúng tôi thu thập các token mã nguồn trong phạm vi ngữ cảnh của nó. Chúng tôi áp dụng Gated Recurrent Unit (GRU) [19] với cơ chế attention [20] để phân tích ngữ nghĩa ngữ cảnh. Thử nghiệm loại bỏ của chúng tôi về thông tin ngữ cảnh cho thấy cải thiện 41.0% về độ chính xác. Đánh giá của chúng tôi trên bộ dữ liệu typeshed [14] được gán nhãn bởi con người chứng minh kết quả tương tự. Thông tin ngữ cảnh cung cấp ngữ nghĩa cục bộ cho các biến, và nó hữu ích để suy ra các chú thích biến.

Kết hợp tất cả những đóng góp này, chúng tôi phát triển một framework từ đầu đến cuối, hiệu quả cao và hiệu quả để suy luận kiểu biến cho Python một cách tĩnh. Bộ dữ liệu của chúng tôi đủ lớn cho hầu hết nghiên cứu về kiểu Python, điều này tự nó là một đóng góp mới. Chúng tôi đạt được độ chính xác 91.187% trên 11 kiểu cơ bản và 81.195% trên 500 kiểu phổ biến nhất. PYInfer chứng minh sự vượt trội về cả phạm vi bao phủ và hiệu quả thời gian trên các dự án lớn so với công việc hiện có [13]. Thay vì gán trọng số cho nhiều yếu tố để suy luận xác suất [13], PYInfer đạt được phạm vi bao phủ nhiều hơn 5.2X và nhanh hơn 187.4X. Mô hình của chúng tôi chú thích một biến trung bình trong 1 mili giây. So với PySonar2, công cụ của chúng tôi mất thời gian tương tự để phân tích nhưng tạo ra 5X nhiều chú thích hơn. Một ví dụ động lực so sánh PYInfer và PySonar2 được cung cấp trong Phần V. Mặc dù được huấn luyện trên các chú thích được tạo bởi PySonar2, PYInfer có thể xử lý các trường hợp phức tạp sử dụng ngữ nghĩa mã ngữ cảnh, như được hiển thị trong Hình 5. PYInfer cũng có thể được mở rộng để thực hiện suy luận tham số hàm. Nó cho thấy sự vượt trội so với TypeWriter trong việc suy luận kiểu biến và tham số hàm.

Chúng tôi đã phát hành mô hình PYInfer, mã nguồn và bộ dữ liệu để hỗ trợ nghiên cứu sâu hơn¹. Các bộ kiểm tra kiểu hiện có có thể hưởng lợi từ các chú thích kiểu được tạo bởi PYInfer để phát hiện sự không nhất quán về kiểu. Chúng tôi cung cấp một quy trình làm việc về việc tích hợp PYInfer với pyre để phát hiện sự không nhất quán biến trong các kho Python. Như một chú thích kiểu tĩnh từ đầu đến cuối, PYInfer cung cấp chú thích với xác suất trong 1 ms cho một biến. Nó cung cấp chú thích kiểu cho các lập trình viên một cách liền mạch khi họ đang lập trình. Framework của chúng tôi cũng có thể được sử dụng để suy luận kiểu tham số. Vì phương pháp của chúng tôi dựa trên ngữ nghĩa cấp cao thay vì cấu trúc đồ thị, nó có thể dễ dàng mở rộng để chú thích biến và phát hiện lỗi ngữ nghĩa trong các ngôn ngữ được gõ động khác.

II. FRAMEWORK PYINFER

Hình 3 trình bày một tổng quan kỹ thuật về mô hình PYInfer. Ý tưởng cơ bản là công thức hóa suy luận kiểu như một bài toán phân loại. Chúng tôi kiểm tra 500 kiểu hàng đầu dựa trên tần suất xuất hiện và phân tích ngữ nghĩa ngữ cảnh trong một biên độ nhất định. Thuật toán BPE được áp dụng để suy ra biểu diễn vector như nhúng. Chúng tôi tiếp tục đưa những nhúng này vào mạng GRU với cơ chế attention để trích xuất ngữ nghĩa mã từ ngữ cảnh. Sau đó chúng tôi sử dụng lớp softmax để phân loại từng kiểu với xác suất. PYInfer bao gồm bốn thành phần sau: thu thập và tạo dữ liệu, nhúng mã nguồn, công thức hóa mô hình và huấn luyện mô hình.

A. Thu thập và Tạo Dữ liệu

Để phân loại kiểu biến, chúng tôi cần một bộ dữ liệu được chú thích đủ lớn. Vì bộ dữ liệu chú thích biến được gán nhãn bởi con người không có sẵn, chúng tôi áp dụng PySonar2 để tạo các chú thích ban đầu. Vì PySonar2 thực hiện phân tích bảo thủ, chúng tôi bỏ qua tất cả các biến mà nó không thể suy luận kiểu và giả định kết quả cho các biến còn lại là sự thật cơ bản (mặc dù các kiểu có thể bị gần đúng quá mức). Chúng tôi cũng phân tích typeshed [14], probPY [13] và bộ dữ liệu TypeWriter [15]. Bộ dữ liệu của chúng tôi được tóm tắt trong Bảng I. Original và Valid trình bày số lượng chú thích trước và sau khi làm sạch dữ liệu và khử trùng lặp. typePY là bộ dữ liệu mã nguồn của chúng tôi được thu thập từ 4,577 kho GitHub hàng đầu. probPY đại diện cho bộ dữ liệu được công bố trong Xu et al. [13], và typeshed là bộ dữ liệu được gán nhãn bởi con người chỉ chứa các chú thích cho tham số hàm và giá trị trả về [14].

Chúng tôi thu thập bộ dữ liệu typePY bằng cách chú thích mã nguồn Python trong các kho GitHub hàng đầu. Đối với mỗi biến, chúng tôi lưu trữ liên kết đến kho, tên tập tin, tên biến, vị trí token bắt đầu và kết thúc, chú thích kiểu và mã nguồn tương ứng. Để có được chú thích kiểu, chúng tôi áp dụng PySonar2, một bộ lập chỉ mục ngữ nghĩa tiên tiến cho Python [16], để suy luận kiểu cho mỗi biến. Chúng tôi thu được 77,089,946 chú thích từ 320,402 tập tin mã nguồn Python. Vì PySonar2 chỉ có 49.47% phạm vi bao phủ trên các chú thích [13], chúng tôi cũng tinh chỉnh bộ dữ liệu của chúng tôi với một loạt các kỹ thuật làm sạch dữ liệu. Chúng tôi loại bỏ tất cả các kiểu vô nghĩa, chẳng hạn như "question marks" và kiểu "None", và thực hiện khử trùng lặp. Cuối cùng, chúng tôi thu được 42,560,876 chú thích hợp lệ. Theo hiểu biết của chúng tôi, đây là bộ dữ liệu chú thích Python lớn nhất. Chúng tôi phát hành bộ dữ liệu này để hỗ trợ nghiên cứu về chủ đề này.

Đối với bộ dữ liệu probPY [13], chúng tôi khai thác dữ liệu được hợp nhất kết hợp kết quả của PySonar2 và phân tích động. Bộ dữ liệu probPY cung cấp tên biến, chú thích và mã nguồn để tạo thông tin ngữ cảnh cho mô hình của chúng tôi. Chúng tôi có thể so sánh tiêu thụ thời gian và phạm vi bao phủ giữa PYInfer, PySonar2 và mô hình probPY.

Bộ dữ liệu typeshed chứa các chú thích kiểu được gán nhãn bởi con người cho thư viện chuẩn Python và các gói bên thứ ba, làm cho nó đáng tin cậy hơn. Tuy nhiên, bộ dữ liệu typeshed chỉ bao gồm các chú thích cho tham số hàm và kiểu trả về, và không có thông tin ngữ cảnh do cập nhật mã thường xuyên. Chúng tôi trích xuất các chú thích tham số để đánh giá mô hình của chúng tôi về tầm quan trọng của ngữ nghĩa mã ngữ cảnh. Sau khi hợp nhất các chú thích trong thư viện bên thứ ba với thư viện chuẩn, chúng tôi khử trùng lặp các chú thích trên các cặp [tên biến, chú thích kiểu]. Chúng tôi cuối cùng thu được 3,379 kiểu khác nhau với 16,537 chú thích trong bộ dữ liệu này. Những trùng lặp hơn 30.1% chỉ ra rằng các lập trình viên có khả năng áp dụng các tên tương tự trên các biến có chức năng tương tự.

B. Nhúng Mã Nguồn

Phương pháp nhúng thông thường xây dựng một từ điển trên các token được sử dụng thường xuyên và tạo nhúng cho mỗi token trong từ vựng. Phương pháp này đảm bảo rằng mỗi token được giữ nguyên khi đưa vào mô hình. Nhiều phương pháp hiện có, chẳng hạn như Word2Vec [21] và Global Vectors for word representation (GloVe) [18], lấy biểu diễn vector hóa của mỗi token. Tuy nhiên, các phương pháp nhúng từ không phù hợp với mã nguồn. Với nhiều tên biến và tên hàm do người dùng định nghĩa, các phương pháp này thường gặp phải OOV vì các từ hiếm không được quan sát trong dữ liệu huấn luyện. OOV làm cho mô hình không thể hấp thụ bất kỳ thông tin nào từ các token không có trong từ vựng. Một giải pháp tầm thường là sử dụng <UNK> để đại diện cho các từ không biết, điều này không phù hợp do mất ý nghĩa ngữ nghĩa.

Để nắm bắt những ngữ nghĩa trong tên biến và tên hàm, chúng tôi áp dụng thuật toán BPE [17] để tạo nhúng cho mã nguồn. Thuật toán BPE được biết đến đầu tiên như một thuật toán nén [22, 23] và hiệu quả trong nhiều nhiệm vụ phân tích chương trình với mạng nơ-ron [17, 24, 25, 26, 27]. Thuật toán này giảm thiểu OOV bằng cách hợp nhất một cặp byte thường xuyên nhất thành một byte mới. Bắt đầu với một ký tự đơn lẻ, chúng tôi đặc trưng hóa các token do người dùng định nghĩa bằng cách chia chúng thành các phần nhỏ hơn trong từ điển của chúng tôi. Chúng tôi áp dụng phương pháp clustering từ dưới lên và ban đầu tạo unigram cho tất cả các ký tự. Sau đó, chúng tôi lặp lại tính toán tần suất của n-gram và sử dụng xấp xỉ tham lam để tối đa hóa log-likelihood của mô hình ngôn ngữ để tạo n-gram mới cho các cặp n-gram thường xuyên nhất [28].

Chúng tôi huấn luyện mô hình BPE của chúng tôi trên tập dữ liệu mã nguồn và thu được 19,995 từ cơ sở khác nhau để tạo nhúng. So với các phương pháp nhúng thông thường, nhúng BPE tận dụng đầy đủ ngữ nghĩa mã ngữ cảnh bằng cách giải quyết OOV. Chúng tôi chứng minh rằng BPE hiệu quả trong việc nhúng mã nguồn Python để chú thích biến. Tên biến sử dụng snake case (ví dụ: network address) hoặc camel case có thể được nhúng hiệu quả bằng BPE.

C. Công thức hóa Mô hình

Một trong những hiểu biết chính là chúng tôi mang thông tin ngữ cảnh vào mô hình của chúng tôi. Các ngữ cảnh trong mã nguồn không chỉ mang kiến thức ngữ nghĩa có ý nghĩa mà còn đưa ra manh mối và hiểu biết về chức năng biến. Chúng tôi thiết lập biên độ m để chỉ ra bao nhiêu thông tin ngữ cảnh sẽ được xem xét. Việc thiết lập biên độ được minh họa trong Hình 2. Đối với mỗi biến vi, i ∈ [1::n], chúng tôi xử lý dòng hiện tại chứa biến hiện tại, được chú thích là dc i, m token trước dòng hiện tại, được chú thích với de i, m token sau dòng hiện tại, được biểu diễn là da i, và tên của biến hiện tại dn i. Thông tin ngữ cảnh cung cấp ngữ nghĩa cục bộ cho các biến, đủ để suy ra các chú thích biến. Đặt thuật toán BPE là B(), và chúng tôi có thể hoàn thiện nhúng Xi của chúng tôi cho biến vi như sau:

Xi = B(de i) + B(dc i) + B(da i) + B(dn i);

trong đó "+" đại diện cho việc nối trên hai vector nhúng. Chúng tôi có chủ ý gán các nhúng của tên biến ở phần sau trong các nhúng. Thiết lập này cho phép chúng tôi thu được biểu diễn ngữ nghĩa bằng cách trích xuất pattern trong lớp cuối cùng trong mô hình GRU của chúng tôi.

Để đặc trưng hóa các tính năng nhúng một cách toàn diện, chúng tôi áp dụng Gated Recurrent Unit (GRU) [19], một mạng nơ-ron tái phát (RNN) [29] có hiệu suất tương tự so với mạng nơ-ron tái phát hai chiều [29] nhưng với độ phức tạp tính toán thấp hơn. GRU được sử dụng để phân tích và đặc trưng hóa nhúng của mã nguồn của chúng tôi theo cách ưu việt. Đối với mỗi biến, GRU được áp dụng để phân tích đặc trưng của thông tin ngữ cảnh kết hợp với tên biến. Nó có khả năng xử lý một chuỗi của một vector bằng cách áp dụng một công thức lặp lại ở mỗi bước thời gian t. Ban đầu, chúng tôi có vector đầu ra h0 = 0 khi t = 0. Giả sử số lượng token sau nhúng là si cho biến vi. Đối với mỗi token mã nguồn đầu vào xt, trong đó t ∈ [1::si] trong nhúng Xi, chúng tôi có:

zt = σ(Wzxt + Uzht-1 + bz);
rt = σ(Wrxt + Urht-1 + bz);
ht = zt ⊙ ht-1 + (1 - zt) ⊙ σ(Whxt + Uh(rt ⊙ ht-1) + bh);

trong đó xt là nhúng đầu vào của chúng tôi với thông tin ngữ cảnh, ht là vector đầu ra của chúng tôi cho biến vi này, zt là cổng cập nhật và rt là cổng reset, và W, U và b là các tham số trong mô hình của chúng tôi. σ đại diện cho hàm sigmoid, và ⊙ biểu thị tangent hyperbolic. Cơ chế attention [20] cũng được thêm vào mô hình của chúng tôi để có hiệu suất đáng tin cậy hơn. Vì tên biến được thêm vào vị trí cuối cùng của vector nhúng, chúng tôi có thể trích xuất lớp cuối cùng trong vector đầu ra hsi để đặc trưng hóa biến Xi. Một lớp dropout được đính kèm vào mô hình GRU để giải quyết vấn đề overfitting một cách phù hợp. Cuối cùng, chúng tôi đính kèm một lớp kết nối đầy đủ vào đầu ra của mô hình GRU để cung cấp cho mô hình của chúng tôi tính linh hoạt hơn trong việc học ngữ nghĩa mã ngữ cảnh.

Chúng tôi coi suy luận kiểu Python như một phân loại kiểu để giải quyết các kiểu do người dùng định nghĩa. Để có được xác suất của từng kiểu, chúng tôi áp dụng hồi quy softmax (còn được gọi là hồi quy logistic đa thức [30]) trên tính năng được trích xuất từ đầu ra của mô hình GRU. Đối với đầu ra của mạng GRU hsi, chúng tôi có:

yi = argmax(P(hsi)) = argmax(e^hsi / Σ(j=0 to n) e^hsi);

trong đó argmax là một hàm trả về vị trí có xác suất tối đa, và P(hsi) là một danh sách các xác suất cho mỗi kiểu có thể của biến vi. Hàm này được sử dụng để xấp xỉ một số nguyên mục tiêu yi ∈ [1, C], trong đó C đại diện cho số lượng lớp. Hàm softmax P() tạo ra một đầu ra vô hướng P(hsi) ∈ R, với xác suất cho mỗi kiểu P(hsi)j ∈ [0, 1].

Với sự trợ giúp của lớp softmax, chúng tôi có thể tạo ra các chú thích kiểu cho mỗi biến với phân phối trên xác suất P(hsi). PYInfer chú thích biến dựa trên kiểu có xác suất tối đa, trả về yi. Chúng tôi có thể thêm một ngưỡng trên mức độ tin cậy, tức là xác suất. Độ chính xác mô hình của chúng tôi tăng với sự gia tăng của mức độ tin cậy (Bảng IX), điều này chứng minh hiệu quả của mô hình của chúng tôi trong phân loại kiểu.

D. Huấn luyện Mô hình

Trong mô hình của chúng tôi, chúng tôi áp dụng cross-entropy như hàm loss. Cụ thể, chúng tôi áp dụng một softmax theo sau là một logarithm để suy ra độ tin cậy cho suy luận kiểu và thêm negative log-likelihood loss (NLLLoss) vào kết quả softmax. Đối với hàm loss, chúng tôi có:

L = -Σ(i=1 to n) Σ(j=1 to C) gij log(P(hsi)j);

trong đó L đại diện cho hàm loss cho mô hình của chúng tôi, được tính bằng cách cộng loss cho mỗi chú thích. Hằng số n là tổng số chú thích chúng tôi có, và C đại diện cho số lượng lớp. Kiểu sự thật cơ bản cho biến vi được biểu diễn bởi gij. Chúng tôi đặt gij = 1 nếu chú thích cho biến vi là j, và gij = 0 nếu không. P(hsi)j định nghĩa kết quả log softmax của lớp j trên biến vi.

Chúng tôi tiếp tục đưa kết quả tính toán vào một optimizer, nhằm mục đích tối thiểu hóa giá trị của hàm loss L. Các thí nghiệm rộng rãi được tiến hành, và Adam Optimizer [31] hóa ra là phù hợp nhất cho hiện tượng này.

III. ĐÁNH GIÁ

Trong phần này, chúng tôi đánh giá PYInfer bằng cách trả lời các câu hỏi nghiên cứu sau:

RQ 1: PYInfer hiệu quả như thế nào trong việc suy ra các chú thích kiểu chính xác?

RQ 2: Số lượng lớp được xem xét để phân loại có tác động đáng kể đến PYInfer không?

RQ 3: Ngưỡng ảnh hưởng như thế nào đến mô hình PYInfer của chúng tôi?

A. RQ 1: Hiệu quả Mô hình và So sánh Baseline

1) Bộ dữ liệu và Cài đặt Thí nghiệm: Trong RQ này, chúng tôi phân tích hiệu suất mô hình ngữ cảnh của chúng tôi với 500 kiểu phổ biến nhất trong bộ dữ liệu typePY. Ngoài tất cả các kiểu built-in trong Python, chúng tôi cũng xem xét một lượng lớn kiểu do người dùng định nghĩa. Sau khi phân tích tập dữ liệu mã nguồn, chúng tôi thấy rằng các bản sao tồn tại trong bộ dữ liệu của chúng tôi. Lý do chính là một số kho GitHub sử dụng lại cùng một mã từ những kho khác. Chúng tôi thực hiện khử trùng lặp trên bộ dữ liệu của chúng tôi và suy ra 3,499,933 chú thích để đánh giá. Chúng tôi cũng kiểm tra một số phân phối kiểu, như được hiển thị trong Bảng II. Phân phối không đều này phản ánh sự khác biệt trong việc sử dụng biến thế giới thực trên các kiểu khác nhau. Toàn bộ tập dữ liệu của chúng tôi được chia ngẫu nhiên thành dữ liệu huấn luyện, xác thực và kiểm tra với tỷ lệ 60%:20%:20%. Chúng tôi chạy tất cả các thí nghiệm trên một máy đơn với CPU Intel i7-9700k, 32GB RAM và một GPU NVIDIA RTX 2070 Super.

2) Chi tiết Triển khai và Kết quả: Chúng tôi huấn luyện mô hình PYInfer của chúng tôi với các tham số trong Bảng III và báo cáo kết quả kiểm tra. Để phân tích ngữ nghĩa mã ngữ cảnh, chúng tôi tạo các nhúng bằng cách phân tích ngữ nghĩa ngữ cảnh trong mã nguồn với một dấu phân cách giữa mỗi phần trong cài đặt biên độ của chúng tôi. Chúng tôi thu được các biểu diễn vector bằng cách trích xuất lớp cuối cùng trong mạng nơ-ron GRU vì tên biến ở phần sau trong nhúng.

Chúng tôi thêm một lớp dropout để giải quyết vấn đề overfitting, làm cho mô hình của chúng tôi tổng quát hơn và nâng cao hiệu suất cho các trường hợp thế giới thực. Các tham số MODEL_SIZE và SEQ_LEN đặc trưng cho kích thước của lớp ẩn trong mạng GRU. Chúng tôi thiết lập siêu tham số TENSOR_LEN để loại bỏ một số nhúng cực kỳ dài, điều này thường xảy ra khi một đoạn mã nguồn chứa một lượng lớn token chưa được nhìn thấy. Chúng tôi đã thu thập phân phối về độ dài nhúng, và độ dài nhúng trong vòng 1,000 bao gồm 99.9% chú thích trong bộ dữ liệu của chúng tôi. Do đó, chúng tôi có thể áp dụng an toàn các chú thích trong ràng buộc độ dài này để huấn luyện mô hình của chúng tôi.

Với tất cả các cài đặt trên, chúng tôi tinh chỉnh các tham số và sử dụng độ chính xác như một trong những ma trận đánh giá mô hình của chúng tôi. Độ chính xác được tính như sau:

AXi = |D(Xi) ∩ C(Xi)| / |D(Xi)|;

trong đó Xi đại diện cho nhúng hiện tại đang được xử lý, D(Xi) đại diện cho kiểu sự thật cơ bản cho biến vi, và C(Xi) trả về chú thích kiểu Top-1 được xếp hạng dựa trên xác suất. Mô hình của chúng tôi cuối cùng đạt được 81.195% độ chính xác trên dữ liệu kiểm tra.

Vì phân phối cho mỗi kiểu không đều, chúng tôi cũng đánh giá mô hình của chúng tôi bằng cách sử dụng precision và recall có trọng số, và tính toán điểm f-1 dựa trên chúng. Như một phân loại đa lớp, chúng tôi tính toán trung bình của mỗi ma trận đánh giá có trọng số theo support, tức là số lượng chú thích chính xác cho mỗi kiểu. PYInfer đạt được 79.318% về precision, 81.195% về recall và 80.246% về điểm f-1.

3) Phân tích Baseline và Hiểu biết: Để phân tích baseline, chúng tôi so sánh framework PYInfer của chúng tôi với mô hình probPY [13] và PySonar2. Đầu tiên, chúng tôi thực hiện các thí nghiệm baseline sử dụng dữ liệu được hợp nhất trong bộ dữ liệu probPY.

Các ma trận đánh giá trong probPY tận dụng recall và precision. Precision trong probPY được tính dựa trên đầu vào khả thi. Tuy nhiên, do thiếu sự thật cơ bản, họ cung cấp ước lượng dựa trên các mẫu được chọn ngẫu nhiên. Do đó, chúng tôi áp dụng recall để đánh giá chính xác. Tương tự như probPY, chúng tôi tính toán recall như sau:

RXi = |D(Xi) ∩ C(Xi; TOP_k)| / |D(Xi)|

Xi là nhúng của biến vi đang được xử lý. D(Xi) đại diện cho kiểu sự thật cơ bản cho biến vi, và C(Xi; TOP_k) trả về TOP_k chú thích kiểu được xếp hạng dựa trên xác suất cho mỗi kiểu có thể.

Trong bảng IV, chúng tôi trình bày recall kiểm tra của PYInfer so với mô hình probPY. Chúng tôi đánh giá PYInfer trên recall kiểm tra Top-k, trong đó k ∈ {1, 3, 5, 7}. PYInfer trên Top-k trả về k chú thích với xác suất cao nhất. Vì chúng tôi có sự thật cơ bản cho chú thích, |D(Xi)| luôn là một chú thích kiểu duy nhất. RXi tăng nếu sự thật cơ bản được bao gồm trong k kết quả suy luận đầu tiên TOP_k được xếp hạng theo xác suất. Vì chỉ có chú thích biến Top-1 được cung cấp cho phía người dùng, nó quan trọng nhất trong các tình huống thế giới thực. Chúng tôi cũng thu thập precision Top-1 sử dụng probPY với cài đặt ngưỡng xác suất HIGH 0.95 và ngưỡng xác suất quy ước đặt tên = 0.7, như được minh họa trong bài báo của họ [13]. Chúng tôi sử dụng mô hình PYInfer được huấn luyện với bộ dữ liệu typePY phân loại 500 kiểu và đánh giá trên bộ dữ liệu probPY. Vì chúng tôi không huấn luyện lại hoặc tinh chỉnh mô hình của chúng tôi trong bộ dữ liệu probPY, hiệu suất kém cạnh tranh hơn so với kết quả kiểm tra của chúng tôi. Tuy nhiên, mô hình của chúng tôi vẫn vượt trội so với mô hình probPY trên tất cả các recall Top-k. Sự vượt trội này là do chúng tôi có một bộ dữ liệu đủ lớn cho PYInfer để phân tích ngữ nghĩa ngữ cảnh. Phương pháp nhúng của chúng tôi tiên tiến hơn trong việc giải quyết OOV so với nhúng từ.

Thay vì gán trọng số cho nhiều yếu tố, framework PYInfer của chúng tôi hiệu quả hơn so với mô hình probPY với sự trợ giúp của tính chất có thể song song hóa. PYInfer cũng vượt trội so với probPY về phạm vi bao phủ chú thích. Công cụ trong probPY chạy 68 phút trên CPU tám lõi và tạo ra 22,354 chú thích. Mô hình PYInfer của chúng tôi có thể tận dụng GPU để chạy song song. Nó mất 113 giây để suy ra 115,535 chú thích trong cùng một bộ dữ liệu và đạt được nhanh hơn 187.4X so với probPY với phạm vi bao phủ 5.2X.

Mô hình của chúng tôi cũng thành thạo với phạm vi bao phủ cao hơn so với PySonar2. Pysonar2 cung cấp 102,361 chú thích ban đầu cho bộ dữ liệu probPY. Tuy nhiên, nhiều chú thích kiểu là dấu hỏi hoặc không hợp lệ. Trong số 102,361 chú thích, có 38,137 chú thích dấu hỏi, 9,454 được chú thích là "None" và 40,400 không có chữ cái (ví dụ: "[[?]]"). Trong tất cả các chú thích dấu hỏi, 35,882 chú thích có thể được dự đoán bởi PYInfer, PYInfer cũng có thể suy luận 9,352 chú thích hợp lệ cho "None Type" và 38,019 chú thích cho "No Letter". Chúng tôi cuối cùng thu được 23,107 chú thích sau khi khử trùng lặp và loại bỏ kiểu None và không hợp lệ. Nhìn chung, mô hình của chúng tôi đạt được phạm vi bao phủ chú thích tốt nhất trong tất cả ba công cụ này. Chúng tôi tiết lộ so sánh chi tiết trong Bảng V.

4) So sánh với TypeWriter: TypeWriter [15] hiệu quả tận dụng mạng nơ-ron để suy luận kiểu cấp hàm, tức là kiểu tham số và kiểu trả về, từ các cơ sở mã được chú thích một phần. Nó sử dụng LSTM trên gợi ý kiểu từ token mã nguồn trong tên tham số, cách sử dụng và bình luận cấp hàm. Đối với bộ dữ liệu, TypeWriter sử dụng cơ sở mã nội bộ cũng như các phụ thuộc mypy trên GitHub. Nó xử lý 1,137 kho GitHub và dự đoán 16,492 chú thích cho kiểu trả về và 21,215 chú thích cho tham số.

So với TypeWriter, chúng tôi nhắm đến các vấn đề hơi khác nhau và áp dụng các framework khác nhau. TypeWriter suy luận tham số hàm và kiểu trả về, trong khi PYInfer chú thích biến Python. Ở cấp độ phương pháp, TypeWriter áp dụng nhúng Word2Vec truyền thống theo token, trong khi PYInfer áp dụng nhúng BPE để nắm bắt ngữ nghĩa mã ngữ cảnh. Đối với thiết kế mạng nơ-ron, TypeWriter sử dụng mô hình LSTM trên token mã nguồn và bình luận hàm, trong khi PYInfer khai thác mạng GRU với cơ chế attention để giải quyết ngữ nghĩa cục bộ.

Chúng tôi so sánh mô hình PYInfer của chúng tôi với TypeWriter trong bộ kiểm tra của TypeWriter về việc tạo chú thích cho ba vấn đề khác nhau: biến, tham số hàm và kiểu trả về, như được hiển thị trong Bảng VI.

Chú thích Biến. Chúng tôi đánh giá TypeWriter trên bộ dữ liệu chú thích biến của chúng tôi, typePY. Chúng tôi đặt các chú thích biến như chú thích tham số hàm trong mô hình của TypeWriter. Chúng tôi huấn luyện lại TypeWriter và thu được 59% về precision, tương tự như hiệu suất suy luận kiểu tham số trong bài báo TypeWriter.

Kiểu Tham số Hàm. Chúng tôi đánh giá PYInfer trên bộ dữ liệu mã nguồn mở trong TypeWriter. Chúng tôi đặt tên tham số như tên biến trong mô hình của chúng tôi. Không huấn luyện lại hoặc tinh chỉnh, mô hình của chúng tôi đạt được 72% về precision.

Kiểu Trả về Hàm. Chúng tôi đánh giá PYInfer trên bộ dữ liệu mã nguồn mở trong TypeWriter. Chúng tôi coi dòng mã nơi hàm trả về được định nghĩa như tên biến trong mô hình của chúng tôi. Chúng tôi đạt được 59% precision mà không huấn luyện lại hoặc tinh chỉnh mô hình PYInfer.

Từ đánh giá trên, công việc của chúng tôi bổ sung cho TypeWriter. TypeWriter sử dụng các tính năng cấp hàm toàn cục, tức là mã nguồn hàm, bình luận và cách sử dụng tham số để suy luận kiểu trả về và tham số. Những tính năng toàn cục đó cung cấp cái nhìn toàn diện về toàn bộ hàm, làm cho nó tiên tiến hơn để suy luận kiểu cấp hàm. TypeWriter cho thấy hiệu suất nâng cao so với NL2Type [6] và DeepTyper [5] trong dự đoán tham số. Tuy nhiên, khó khăn cho TypeWriter để chú thích biến trong thân hàm, nơi thông tin cấp biến hiệu quả hơn. PYInfer chú thích biến sử dụng ngữ nghĩa mã nguồn trong một biên độ nhất định, làm cho nó cạnh tranh hơn trong việc cung cấp chú thích cấp biến. Lý do chính là mô hình PYInfer khai thác các tính năng cấp biến cục bộ, tức là tên biến và ngữ nghĩa ngữ cảnh trong một biên độ nhất định. Để suy luận kiểu của biến và tham số, các tính năng cục bộ quan trọng hơn vì chúng đặc trưng cho cách một biến được định nghĩa và sử dụng.

B. RQ 2: Kiểu Cơ bản hay Nhiều Kiểu hơn

Chúng tôi điều tra hiệu suất mô hình chỉ phân loại các kiểu cơ bản trong Python. Cụ thể, chúng tôi kiểm tra các kiểu built-in sau: [str, int, dict, bool, float, list, tuple, object, complex, set, type]. Chúng tôi phân tích phân phối của các kiểu khác nhau, như được hiển thị trong Bảng VII.

Để phân tích hiệu suất của PYInfer trên các kiểu cơ bản, chúng tôi thu được 2,322,135 chú thích sau khi khử trùng lặp. Kết quả so sánh giữa kiểu cơ bản và 500 kiểu phổ biến nhất có thể được tìm thấy trong Bảng VIII. Hiệu suất của mô hình kiểu cơ bản vượt trội so với mô hình 500 kiểu 9.9% về độ chính xác kiểm tra. Phân loại 11 kiểu sẽ dễ quản lý hơn nhiều và chính xác hơn so với 500 kiểu. Tuy nhiên, một số lượng lớn kiểu do người dùng định nghĩa không thể được dự đoán với 11 kiểu. Một mô hình xem xét 500 kiểu bao gồm nhiều kiểu do người dùng định nghĩa hơn, làm cho nó tổng quát hóa được cho các tình huống thế giới thực.

C. RQ 3: Ngưỡng

Vì mô hình cung cấp chú thích kiểu với xác suất, chúng tôi kiểm tra các ngưỡng khác nhau trên mức độ tin cậy. Từ 0.1 đến 0.9, chúng tôi cung cấp kết quả về số lượng chú thích với precision, recall và điểm f-1 trong Bảng IX được đánh giá trên tập xác thực của chúng tôi trong typePY. Các chú thích trong Bảng IX cho biết số lượng biến được dự đoán với một kiểu. Với sự gia tăng ngưỡng, mô hình của chúng tôi đưa ra ít chú thích hơn, trong khi precision tăng. Với ngưỡng cao hơn, ít chú thích hơn được đưa ra. Ngưỡng 0.9 cung cấp 97.677% precision, nhưng cũng bỏ qua 42.151% dữ liệu xác thực của chúng tôi.

Ngưỡng là sự phản ánh thực về kết quả mô hình trên xác suất, cho biết mô hình của chúng tôi tin tưởng như thế nào để cung cấp chú thích kiểu. Chúng tôi có thể đặt ngưỡng ở một giá trị hợp lý để đạt được sự cân bằng giữa số lượng chú thích chúng tôi muốn thu được và tiêu chuẩn độ chính xác tuyệt đối chúng tôi muốn có.

IV. PHÂN TÍCH

Trong phần này, chúng tôi tập trung vào việc trả lời hai câu hỏi nghiên cứu sau:

RQ 4: Thông tin ngữ cảnh ảnh hưởng như thế nào đến hiệu suất của PYInfer?

RQ 5: Nhúng BPE có vượt trội so với các nhúng mã dựa trên học máy khác không?

A. RQ 4: Phân tích Loại bỏ Ngữ nghĩa Ngữ cảnh

Chúng tôi cũng quan tâm đến hiệu quả của ngữ nghĩa ngữ cảnh. Do đó, chúng tôi tiến hành phân tích loại bỏ trên dữ liệu ngữ cảnh và phân tích PYInfer không có ngữ nghĩa ngữ cảnh. Chúng tôi thu thập kết quả trong Bảng X. Không có các yếu tố ngữ cảnh, mô hình của chúng tôi chỉ có thể tận dụng tên biến, bỏ qua cách sử dụng biến và mối quan hệ logic trong một biên độ nhất định trong ngữ cảnh. Thông tin ngữ cảnh đóng vai trò quan trọng trong việc đặc trưng hóa ngữ nghĩa mã nguồn. Sự khan hiếm ngữ nghĩa ngữ cảnh làm tàn phá hiệu quả của mô hình chúng tôi. Chúng tôi quan sát thấy sự gia tăng 41% về độ chính xác kiểm tra với sự hỗ trợ của ngữ nghĩa ngữ cảnh.

Sự suy giảm hiệu suất cũng có thể được giải thích một phần do việc giảm chú thích. Đối với mô hình có dữ liệu ngữ cảnh, chúng tôi có 3,499,933 chú thích xem xét 500 kiểu. Không có thông tin ngữ cảnh, chúng tôi có một số lượng lớn các bản sao vì hầu hết các biến có tên tương tự với cùng một kiểu. Chúng tôi chỉ thu được 841,521 chú thích sau khi khử trùng lặp. Vì chúng tôi bỏ qua dữ liệu ngữ cảnh và khử trùng lặp các chú thích, chúng tôi gặp phải tình trạng thiếu hụt đáng kể về chú thích kiểu. Sự thiếu hụt về chú thích này cũng làm suy giảm hiệu suất của mô hình.

Để điều tra sâu hơn về tầm quan trọng của ngữ nghĩa ngữ cảnh, chúng tôi tiến hành thí nghiệm với bộ dữ liệu typeshed được gán nhãn bởi con người. Nó chứa các chú thích kiểu theo định dạng của tập tin pyi theo các định dạng cụ thể [32, 33], được sử dụng rộng rãi để kiểm tra kiểu và suy luận kiểu.

Trong Hình 4, chúng tôi trình bày một mẫu tập tin pyi trong kho GitHub typeshed. Một tập tin pyi chứa các chú thích về tham số và giá trị trả về cho các hàm. Lưu ý rằng đối với biến safe trong Hình 4, chúng tôi được cung cấp cả chú thích Str và AnyStr dưới các ngữ cảnh khác nhau. Vì mã nguồn không có sẵn cho bộ dữ liệu này, chúng tôi không thể tách hai biến này với các chú thích tương ứng.

Số lượng chú thích trong bộ dữ liệu typeshed cực kỳ hạn chế. Sẽ có tình trạng thiếu hụt dữ liệu khủng khiếp cho mỗi kiểu khi xem xét 500 kiểu. Như một biện pháp giảm thiểu, chúng tôi tận tâm điều tra 50 kiểu hàng đầu. Chúng tôi huấn luyện lại PYInfer của chúng tôi trên typeshed và so sánh mô hình được huấn luyện trên bộ dữ liệu typePY. PYInfer được huấn luyện trên typeshed đạt được 41.747% độ chính xác kiểm tra, 53.126% precision, 43.748% và 47.983% điểm f-1. So với kết quả trong Bảng X, chúng tôi thấy một xu hướng tương tự ở phía kiểm tra, điều này chỉ ra rằng thông tin ngữ cảnh rất quan trọng đối với dự đoán kiểu biến.

B. RQ 5: Ưu điểm của Nhúng Mã Nguồn

Ngoài dữ liệu ngữ cảnh và kiểu, mô hình của chúng tôi cũng vượt trội trong việc áp dụng nhúng BPE. Mã nguồn phong phú về tên biến và tên hàm do người dùng định nghĩa. Chúng tôi thường gặp phải vấn đề OOV trong việc đặc trưng hóa ngữ nghĩa mã nguồn. Chúng tôi áp dụng phương pháp BPE để giải quyết vấn đề này, cho phép chúng tôi tận dụng đầy đủ ngữ nghĩa mã ngữ cảnh.

Trong RQ này, chúng tôi chủ yếu điều tra hiệu quả của nhúng BPE so với nhúng GloVe dựa trên học máy, một phương pháp nhúng từ nổi bật cho tập tin văn bản. Chúng tôi huấn luyện lại nhúng GloVe của chúng tôi trên bộ dữ liệu typePY và suy ra một vector 50 chiều cho mỗi token. Mỗi token ngữ cảnh trong một biên độ nhất định được ánh xạ đến một vector GloVe 50 chiều. Sau đó chúng tôi nối các vector nhúng cho các token trước và sau biến hiện tại trong một biên độ nhất định, và tên của biến hiện tại. Vector được nối được đưa qua mạng GRU để huấn luyện mô hình. Chúng tôi thu thập và tập hợp kết quả trong Bảng XI. Kết quả thí nghiệm của chúng tôi cho thấy rằng nhúng BPE vượt trội hơn nhúng GloVe đáng kể. Chúng tôi chứng minh rằng BPE hiệu quả hơn nhúng GloVe để gõ biến.

V. THẢO LUẬN

A. Điểm mạnh và Điểm yếu của PYInfer

Lý do chính tại sao PYInfer vượt trội so với các công cụ suy luận kiểu khác là chúng tôi có một bộ dữ liệu được chú thích đủ lớn và mã hóa ngữ nghĩa ngữ cảnh của một biến vào mô hình học sâu. Như được minh họa trong Hình 2, chúng tôi thiết lập một biên độ để định nghĩa phạm vi ngữ cảnh, áp dụng nhúng BPE để giải quyết OOV và sử dụng mạng GRU với cơ chế attention để trích xuất ngữ nghĩa. Cài đặt biên độ ảnh hưởng đến hiệu suất của PYInfer. Chúng tôi tiến hành thí nghiệm để kiểm tra ảnh hưởng của cài đặt biên độ dựa trên bộ dữ liệu probPY, và kết quả đánh giá có thể được tìm thấy trong Bảng XII. Các thí nghiệm được thực hiện trên bộ dữ liệu probPY được hợp nhất đánh giá Top-k (k ∈ {1, 3, 5, 7}) không có ngưỡng. Khi biên độ tăng, độ chính xác tăng trước rồi giảm, điều này có thể được giải thích theo những cách sau:

Cài đặt biên độ 32 và 64 thiếu ngữ nghĩa cục bộ ngữ cảnh đầy đủ cho biến hiện tại. Cài đặt biên độ 256 và 512 cung cấp nhiều ngữ nghĩa ngữ cảnh không liên quan hơn. Chúng tôi suy ra hiểu biết sau đây rằng một cài đặt biên độ phù hợp chắc chắn có ảnh hưởng đến hiệu suất tổng thể của mô hình chúng tôi.

Có một số hạn chế của PYInfer. Mặc dù PYInfer đủ điều kiện để xử lý các kiểu do người dùng định nghĩa, một số chú thích không chính xác do dữ liệu huấn luyện hạn chế về các kiểu do người dùng định nghĩa so với các kiểu built-in. Chúng tôi đã hiển thị phân phối các chú thích khác nhau trong Bảng II, và số lượng mẫu về các kiểu do người dùng định nghĩa bị choáng ngợp bởi số lượng kiểu built-in. Ngoài ra, như nhiều bộ phân tích tĩnh, PYInfer yêu cầu truy cập vào mã nguồn, điều này có thể không thực tế do các vấn đề bảo mật.

B. Sự vượt trội so với PySonar2

Chúng tôi phải nhấn mạnh rằng mặc dù được huấn luyện bằng các chú thích được tạo bởi PySonar2, mô hình của chúng tôi cho thấy phạm vi bao phủ cao hơn đáng kể so với Pysonar2 trong suy luận kiểu biến. Phân tích cùng một đoạn mã², chúng tôi so sánh kết quả chú thích của PySonar2 và PYInfer được huấn luyện với 500 kiểu phổ biến nhất trên bộ dữ liệu typePY, như được hiển thị trong Hình 5. PySonar2 và PYInfer đều báo cáo một số dương tính giả. PySonar2 sử dụng phân tích liên thủ tục nhận biết control-flow, bỏ qua kiến thức ngữ nghĩa trong mã nguồn. Nó chú thích một nửa số biến với dấu hỏi (7 trong số 14 chú thích). PYInfer nắm bắt ngữ nghĩa mã bằng cách xem xét ngữ nghĩa ngữ cảnh trong một biên độ cụ thể, đưa ra các chú thích cụ thể khi các ngữ cảnh khác nhau. Nó có thể xử lý các tình huống đòi hỏi nơi PySonar2 phát ra dấu hỏi và chú thích chính xác 21 biến trong tổng số 29 chú thích. Mặc dù PYInfer không sound, nó đạt được độ chính xác kiểm tra hợp lý (91.187% trên 11 kiểu cơ bản và 81.195% trên 500 kiểu phổ biến nhất).

VI. CÔNG VIỆC LIÊN QUAN

A. Suy luận Kiểu cho Python

Các tiêu chuẩn, chẳng hạn như PEP 484 [32], PEP 3107 [33], được đề xuất để hỗ trợ gợi ý kiểu và chú thích. Các bộ kiểm tra kiểu, chẳng hạn như mypy [1], pyre-check [2], pytype [3] và pyright [4], tận dụng các chú thích để phát hiện sự không nhất quán về kiểu. Không có chú thích kiểu, sẽ vô ích cho các bộ kiểm tra kiểu để phát hiện sự không nhất quán về kiểu cho các dự án Python. Các bộ kiểm tra kiểu hiện có chủ yếu dựa vào các chú thích kiểu được viết thủ công từ các nhà phát triển, điều này tốn kém để cung cấp.

Công việc suy luận kiểu trước đây thường bỏ qua các yếu tố ngôn ngữ tự nhiên trong mã nguồn. Một số công cụ chú thích kiểu hiện có áp dụng phân tích động. PyAnnotate [34], ví dụ, là một công cụ suy luận kiểu động được phát triển bởi Dropbox. Sử dụng phân tích động để có được chú thích kiểu trong runtime làm cho suy luận chính xác cho đầu vào cụ thể. Tuy nhiên, nó yêu cầu một môi trường runtime cụ thể, điều này không thực tế trong một số trường hợp thế giới thực. Ngoài ra, nó nhạy cảm với đầu vào, dẫn đến phạm vi bao phủ hạn chế. Các framework được đề xuất bởi Cannon [10], Salib [11], Vitousek et al. [12] tạo ra các chú thích kiểu dựa trên phân tích tĩnh. Salib [11] trình bày một suy luận kiểu tĩnh và trình biên dịch cho Python với Thuật toán Tích Cartesian được sửa đổi [35]. Công cụ này chuyển đổi mã nguồn Python thành mã C++ tương đương, làm cho nó thành thạo trong việc phân tích mã bằng ngôn ngữ nước ngoài. Tuy nhiên, công cụ này không hoàn chỉnh, và các hướng dẫn có thể được xử lý bị hạn chế. Vitousek et al. [12] phát triển việc gõ dần dần cho Python bằng cách sử dụng một hệ thống kiểu dựa trên object calculus bậc nhất [36] được tăng cường với các kiểu động. Luo et al. [37] phân tích docstring Python và xây dựng một bộ phân loại cây quyết định. Phương pháp này chỉ xem xét chín kiểu built-in và sẽ vô ích nếu docstring không có sẵn. PySonar2[16], một công cụ suy luận kiểu tĩnh cho Python, có thể tạo ra các gợi ý kiểu cho biến một cách tĩnh. Mặc dù nó chỉ bao gồm 48.91% chú thích dựa trên các thí nghiệm của chúng tôi, các kết quả chính xác phù hợp với nghiên cứu của chúng tôi với ground-truth để gán nhãn.

Một số công việc liên quan khai thác ngữ nghĩa trong mã nguồn bằng cách sử dụng mạng nơ-ron. Pradel et al. [15] dự đoán kiểu tham số và trả về cho các hàm với các yếu tố ngôn ngữ tự nhiên trong mã nguồn và bình luận. Nó hiệu quả hơn trong suy luận cấp hàm so với dự đoán cấp biến. Xu et al. [13] áp dụng suy luận xác suất để suy ra chú thích kiểu cho Python. Xem xét các yếu tố xác suất khác nhau làm cho công cụ tốn thời gian và khó có thể mở rộng.

B. Suy luận Kiểu trên Ngôn ngữ Được Gõ Động

Các công cụ suy luận kiểu dựa trên học máy hiện có chủ yếu tập trung vào JavaScript, nơi các chú thích kiểu có thể được thu thập bằng cách sử dụng TypeScript [9]. LambdaNet [8] sử dụng mạng nơ-ron đồ thị để dự đoán kiểu với gợi ý ngữ cảnh liên quan đến đặt tên và sử dụng biến. Nó định nghĩa đồ thị phụ thuộc kiểu và lan truyền thông tin kiểu trên mạng nơ-ron đồ thị. LambdaNet khám phá tiềm năng của việc sử dụng nhúng đồ thị trong suy luận kiểu. So với nhúng dựa trên đồ thị, việc tạo ra nhúng mã nguồn dựa trên token hiệu quả hơn. Nó có thể khai thác ngữ nghĩa mã nguồn và dễ tiếp cận hơn để được áp dụng cho các ngôn ngữ khác. NL2Type [6] đề xuất một phương pháp dựa trên học máy để dự đoán chữ ký kiểu cho các hàm với hỗ trợ ngôn ngữ tự nhiên. Hellendoorn et al. [5] sử dụng mô hình học sâu với nhúng từ 300 chiều để tạo ra chú thích kiểu cho JavaScript.

C. Phân tích Mã Nguồn Dựa trên Học máy

Học máy đã được áp dụng rộng rãi trong phân tích chương trình. Godefroid et al. [38] đề xuất một kỹ thuật học máy thống kê để tạo ra đầu vào phù hợp với ngữ pháp cho fuzzing tự động. DeepFix [39] sử dụng mạng nơ-ron sequence-to-sequence với attention để phát hiện và sửa lỗi trong chương trình C. Raychev et al. [40] tập trung vào việc hoàn thành mã với API bằng cách sử dụng mô hình ngôn ngữ. Deepsim [41] đo lường độ tương tự mã bằng cách sử dụng mô hình học sâu với ma trận control flow và data flow. Raychev et al. [42] xây dựng JSNice để dự đoán tên của các định danh và chú thích kiểu của biến cho JavaScript. Pradel và Sen [7] đề xuất một phương pháp dựa trên học máy để phát hiện ba loại lỗi dựa trên tên khác nhau. Họ tạo ra các mẫu âm tính bằng cách sử dụng biến đổi mã dựa trên pattern lỗi cụ thể. Trích xuất pattern lỗi và gieo lỗi vào mã nguồn theo pattern đòi hỏi nỗ lực lớn của con người.

D. Nhúng Mã Nguồn Dựa trên Học máy

Nhúng từ dựa trên học máy đã được áp dụng rộng rãi trong xử lý ngôn ngữ tự nhiên, chẳng hạn như word2vec [43] và doc2vec [21]. Nguyen et al. [44] tận dụng word2vec để phân tích mối quan hệ ngữ nghĩa về cách sử dụng API. Ye et al. [45] huấn luyện nhúng từ trên tài liệu API, hướng dẫn và tài liệu tham khảo để ước lượng độ tương tự ngữ nghĩa. Những phương pháp này phụ thuộc rất nhiều vào dữ liệu huấn luyện, và các token không được quan sát trong đầu vào huấn luyện không được xử lý tốt. OOV là một vấn đề nghiêm trọng, đặc biệt trong nhúng mã nguồn, vì lập trình viên có thể linh hoạt định nghĩa tên hàm và tên biến. Thuật toán BPE [17] giải quyết vấn đề OOV bằng cách mã hóa các từ hiếm và không biết như chuỗi các đơn vị từ con. Nó hiệu quả trong nhiều nhiệm vụ phân tích chương trình [24, 26, 27].

Ngoài nhúng mã nguồn dựa trên token, cũng có nhúng dựa trên đồ thị. Code2Vec [46] phân tách mã nguồn thành một tập hợp các đường dẫn trong cây cú pháp trừu tượng (AST) của nó và học biểu diễn nguyên tử của mỗi đường dẫn. Alon et al. [47] đề xuất một biểu diễn dựa trên đường dẫn để học từ các chương trình sử dụng AST. LambdaNet [8] đề xuất đồ thị phụ thuộc kiểu, liên kết các biến kiểu với các ràng buộc logic cũng như thông tin tên và cách sử dụng. Những nhúng này chủ yếu xem xét cấu trúc trong mã nguồn. Chúng tôi điều tra ngữ nghĩa mã nguồn trong tên biến và thông tin ngữ cảnh, khác với cấu trúc mã dựa trên đồ thị với AST và mạng nơ-ron đồ thị.

VII. KẾT LUẬN

Chúng tôi đã trình bày PYInfer, một phương pháp dựa trên học máy để tạo ra chú thích kiểu cho Python tự động. Đóng góp chính của chúng tôi là framework PYInfer từ đầu đến cuối để suy luận kiểu biến cho Python một cách tĩnh. Nghiên cứu của chúng tôi kết hợp các phương pháp symbolic và xác suất để tạo ra chú thích kiểu cho các biến, hóa ra rất hiệu quả và hiệu quả. Một trong những hiểu biết chính của chúng tôi là xem xét thông tin ngữ cảnh cho các biến, điều này nâng cao mô hình bằng cách mã hóa ngữ nghĩa mã bổ sung. PYInfer có khả năng xử lý các kiểu do người dùng định nghĩa bằng cách công thức hóa suy luận kiểu như một bài toán phân loại. Nó đạt được 5.2X nhiều hơn về phạm vi bao phủ mã và nhanh hơn 187X so với một kỹ thuật hiện đại cho suy luận kiểu Python, và bao gồm 5X nhiều biến hơn so với PySonar2. Nó vượt trội so với TypeWriter trong việc suy luận kiểu cho biến và tham số hàm. Cuối cùng, chúng tôi đề xuất một phương pháp thu thập dữ liệu và đóng góp một bộ dữ liệu lớn gồm 77,089,946 chú thích kiểu từ 4,577 dự án Python phổ biến. Chúng tôi công khai công cụ và bộ dữ liệu của chúng tôi để hỗ trợ nghiên cứu sâu hơn.

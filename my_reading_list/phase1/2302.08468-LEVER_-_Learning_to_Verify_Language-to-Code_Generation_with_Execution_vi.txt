# 2302.08468.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: ./2302.08468.pdf
# Kích thước file: 1891989 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
LEVER: Học cách xác minh sinh mã từ ngôn ngữ tự nhiên bằng thực thi
Ansong Ni1†Srini Iyer2Dragomir Radev1Ves Stoyanov2Wen-tau Yih2Sida I. Wang2 *Xi Victoria Lin2 *

Tóm tắt
Sự xuất hiện của các mô hình ngôn ngữ lớn được huấn luyện trên mã nguồn (code LLMs) đã dẫn đến tiến bộ đáng kể trong việc sinh mã từ ngôn ngữ tự nhiên. Các phương pháp tiên tiến trong lĩnh vực này kết hợp giải mã LLM với việc loại bỏ mẫu và sắp xếp lại sử dụng các test case hoặc heuristic dựa trên kết quả thực thi. Tuy nhiên, việc có được test case cho nhiều ứng dụng sinh mã từ ngôn ngữ tự nhiên trong thế giới thực là thách thức, và heuristic không thể nắm bắt tốt các đặc trưng ngữ nghĩa của kết quả thực thi, như kiểu dữ liệu và phạm vi giá trị, thường chỉ ra tính đúng đắn của chương trình. Trong công trình này, chúng tôi đề xuất LEVER, một phương pháp đơn giản để cải thiện sinh mã từ ngôn ngữ tự nhiên bằng cách học xác minh các chương trình được sinh ra với kết quả thực thi của chúng. Cụ thể, chúng tôi huấn luyện các bộ xác minh để xác định liệu một chương trình được lấy mẫu từ LLM có đúng hay không dựa trên đầu vào ngôn ngữ tự nhiên, bản thân chương trình và kết quả thực thi của nó. Các chương trình được lấy mẫu được sắp xếp lại bằng cách kết hợp điểm xác minh với xác suất sinh của LLM, và tích phân biên trên các chương trình có cùng kết quả thực thi. Trên bốn tập dữ liệu thuộc các lĩnh vực table QA, math QA và lập trình Python cơ bản, LEVER liên tục cải thiện so với các code LLM cơ sở (4.6% đến 10.9% với code-davinci-002) và đạt được kết quả tiên tiến mới trên tất cả chúng.

1. Giới thiệu
Khả năng ánh xạ ngôn ngữ tự nhiên thành mã thực thi là nền tảng của nhiều ứng dụng AI như giao diện cơ sở dữ liệu (Pasupat & Liang, 2015; Yu et al., 2018; Shi et al., 2020), điều khiển robot (Zhou et al., 2021; Shridhar et al., 2020) và trợ lý ảo (Agashe et al., 2019; Lai et al., 2022). Những tiến bộ gần đây về các mô hình ngôn ngữ lớn (LLMs) (Brown et al., 2020; Wei et al., 2021; Chowdhery et al., 2022), đặc biệt là những mô hình được tiền huấn luyện trên mã nguồn (code LLMs) (Chen et al., 2021a; Fried et al., 2022; Nijkamp et al., 2022; Li et al., 2022a), đã cho thấy triển vọng lớn trong các tác vụ này với học trong ngữ cảnh few-shot (Shi et al., 2022; Chen et al., 2022a; Zhang et al., 2022). Tuy nhiên, hiệu suất của chúng vẫn còn cách xa hoàn hảo (Chen et al., 2021a). Xét đến chi phí tính toán để tinh chỉnh các mô hình này, việc khám phá các cách cải thiện chúng mà không thay đổi tham số là hấp dẫn.

Một quan sát quan trọng là trong khi LLMs gặp khó khăn với độ chính xác trong setting few-shot, chúng thường tạo ra đầu ra đúng khi đủ mẫu được rút ra. Công trình trước đây đã cho thấy rằng bỏ phiếu đa số và lọc bằng test case có thể tăng đáng kể hiệu suất của chúng khi các mẫu được rút ra ở quy mô lớn (Chen et al., 2021a; Austin et al., 2021; Li et al., 2022a). Shen et al. (2021) và Cobbe et al. (2021) đã tiếp tục chứng minh hiệu quả của việc huấn luyện một bộ xác minh và sử dụng điểm xác minh để sắp xếp lại các giải pháp ứng cử viên cho các bài toán toán học thế giới thực. So với các phương pháp chỉ dựa vào tính nhất quán thực thi và loại bỏ lỗi, các bộ xác minh được huấn luyện có thể sử dụng các đặc trưng ngữ nghĩa phong phú trong các giải pháp mô hình, như kiểu dữ liệu, phạm vi giá trị và thuộc tính biến, có thể là chỉ báo mạnh về tính đúng đắn của chương trình. Trong khi Cobbe et al. (2021) và các công trình tiếp theo (Li et al., 2022b; Kadavath et al., 2022) tập trung vào xác minh các giải pháp ngôn ngữ tự nhiên bằng LM, một câu hỏi tự nhiên là liệu cùng một phương pháp có thể được áp dụng cho các giải pháp chương trình hay không.

Trong công trình này, chúng tôi đề xuất học xác minh (LEVER 🌏🤖) sinh mã từ ngôn ngữ tự nhiên bằng code LLMs, với sự trợ giúp của thực thi. Cụ thể hơn, chúng tôi huấn luyện một bộ xác minh học cách phân biệt và từ chối các chương trình không chính xác dựa trên biểu diễn kết hợp của mô tả ngôn ngữ tự nhiên, dạng bề mặt chương trình và kết quả thực thi của nó. Chúng tôi tiếp tục kết hợp xác suất xác minh với xác suất sinh của LLM và tích phân biên trên các chương trình có cùng kết quả thực thi. Chúng tôi sử dụng xác suất tổng hợp này làm điểm sắp xếp lại và đưa ra các chương trình thực thi đến kết quả có khả năng cao nhất.

Chúng tôi tiến hành các thí nghiệm mở rộng trên bốn benchmark sinh mã từ ngôn ngữ tự nhiên khác nhau trong các lĩnh vực text-to-SQL semantic parsing, table QA, math reasoning và lập trình Python cơ bản. Kết quả thí nghiệm với ba code LLM khác nhau cho thấy LEVER liên tục cải thiện độ chính xác thực thi của các chương trình được sinh ra. Đáng chú ý, LEVER kết hợp với code-davinci-002 cải thiện so với các baseline mạnh sử dụng loại bỏ lỗi thực thi từ 4.6% đến 10.9%, và đạt được kết quả tiên tiến mới trên tất cả bốn benchmark, mà không sử dụng kiến trúc mô hình hoặc phương pháp prompting dành riêng cho tác vụ. Các nghiên cứu loại bỏ cho thấy kết quả thực thi là quan trọng cho việc xác minh và LEVER cũng mang lại cải thiện không tầm thường trong các setting ít tài nguyên và giám sát yếu.

2. Phương pháp
Bây giờ chúng tôi giới thiệu công thức chi tiết và quy trình huấn luyện của LEVER. Các thành phần chính được minh họa trong Hình 1.

2.1. Sinh mã từ ngôn ngữ tự nhiên với Code LLMs
Đầu vào cho một tác vụ sinh mã từ ngôn ngữ tự nhiên thường bao gồm mô tả ngôn ngữ tự nhiên (NL) và tùy chọn một số ngữ cảnh lập trình (ví dụ, kho dữ liệu, assertion, v.v.). Chúng tôi ký hiệu đầu vào này là x. Cho x, một mô hình sinh P(y|x) sinh ra một chương trình y sau đó được thực thi thông qua một bộ thực thi E(·) để có được kết quả E(y). Đối với học few-shot với các LM lớn, việc sinh cũng thường được điều kiện hóa trên một tập cố định gồm m exemplar, {(xi, yi)}i<m. Do đó, sinh mã từ ngôn ngữ tự nhiên few-shot với code LLMs có thể được công thức hóa như:

PLM(y|x) = P(y|prompt(x,{(xi, yi)}i<m)), (1)

trong đó prompt(x,{(xi, yi)}i<m) là một biểu diễn chuỗi của toàn bộ đầu vào. Tìm kiếm tham lam thường được sử dụng để tìm chương trình có xác suất sinh (xấp xỉ) cao nhất, tức là ŷgreedy ≈ arg max y PLM(y|x).

2.2. Sắp xếp lại các ứng cử viên chương trình
Quan sát chính thúc đẩy phương pháp của chúng tôi là một tập mẫu khá lớn từ PLM(y|x) thường bao gồm các chương trình đúng. Điều này gợi ý rằng việc sắp xếp lại các ứng cử viên chương trình có thể mang lại cải thiện kết quả đáng kể. Ý tưởng của sắp xếp lại phân biệt (Shen et al., 2004; Collins & Koo, 2005) là học một hàm tính điểm R(x,ŷ) đo lường khả năng ŷ là đầu ra tốt nhất cho đầu vào x. Cho R(·), bộ sắp xếp lại đưa ra chương trình có điểm sắp xếp lại cao nhất trong tập các ứng cử viên S:

ŷrerank = arg max ŷ∈S R(x,ŷ) (2)

Tiếp theo chúng tôi giới thiệu cách chúng tôi áp dụng một bộ xác minh được huấn luyện để xác minh và sắp xếp lại các ứng cử viên chương trình được lấy mẫu từ code LLMs sao cho ŷrerank tốt hơn ŷgreedy.

Lấy mẫu chương trình từ Code LLMs. Cho đầu vào x, thay vì thực hiện tìm kiếm tham lam, chúng tôi thu được k chương trình từ PLM(y|x) với lấy mẫu nhiệt độ, tức là {ŷi}ki=1 ∼ PLM(y|x). Vì các chương trình giống nhau có thể được lấy mẫu nhiều lần, chúng tôi thực hiện loại bỏ trùng lặp để tạo thành một tập gồm n ứng cử viên chương trình duy nhất S={ŷi}ni=1, trong đó n≤k. Chúng tôi chọn lấy mẫu thay vì tìm kiếm beam chủ yếu vì hai lý do: 1) công trình gần đây gợi ý rằng tìm kiếm beam cho sinh mã thường dẫn đến hiệu suất tệ hơn do các chương trình bị thoái hóa (Austin et al., 2021; Zhang et al., 2022); và 2) tìm kiếm beam không có sẵn hoặc được triển khai hiệu quả cho tất cả LLMs mà chúng tôi kiểm tra (ví dụ, Codex).

Xác minh với thực thi. Chúng tôi sử dụng một phép nối đơn giản của mô tả bài toán x, chương trình ứng cử viên ŷ và một biểu diễn kết quả thực thi E(ŷ) làm đầu vào cho bộ sắp xếp lại. Lấy cảm hứng từ công trình gần đây (Cobbe et al., 2021; Li et al., 2022b), chúng tôi tham số hóa bộ sắp xếp lại phân biệt của mình như một mô hình xác minh (tức là phân loại nhị phân) Pθ(v|x,ŷ,E(ŷ)), trong đó v∈{0,1}. Trong thực tế, bộ sắp xếp lại có thể được triển khai bằng bất kỳ kiến trúc phân loại nhị phân nào. Chúng tôi báo cáo các thí nghiệm sử dụng T5 (Raffel et al., 2020) và RoBERTa (Liu et al., 2019) trong §B.2.

Cho một đầu vào x và một chương trình ứng cử viên ŷ∈S, chúng tôi thu được xác suất sắp xếp lại như xác suất kết hợp của việc sinh và vượt qua xác minh:

PR(ŷ, v=1|x) = PLM(ŷ|x)·Pθ(v=1|x,ŷ,E(ŷ)) (3)

Tổng hợp kết quả thực thi. Vì các chương trình có cùng ngữ nghĩa có thể có dạng bề mặt khác nhau, chúng tôi tiếp tục tổng hợp xác suất sắp xếp lại của các chương trình trong S thực thi đến cùng kết quả. Theo cách này, chúng tôi làm lỏng sự phụ thuộc vào dạng bề mặt và tập trung vào kết quả thực thi thay thế. Hàm tính điểm cuối cùng cho sắp xếp lại do đó là:

R(x,ŷ) = PR(E(ŷ), v=1|x) = Σy∈S,E(y)=E(ŷ) PR(y, v=1|x)

Vì có thể có nhiều chương trình chia sẻ cùng kết quả thực thi có xác suất cao nhất, chúng tôi phá vỡ sự cân bằng ngẫu nhiên trong trường hợp này khi đưa ra các chương trình.

2.3. Học các bộ xác minh
Các phần trước đã mô tả cách sử dụng bộ xác minh tại thời điểm suy luận. Tiếp theo chúng tôi giới thiệu quy trình huấn luyện của nó.

Tạo dữ liệu huấn luyện. Đối với các tập dữ liệu sinh mã từ ngôn ngữ tự nhiên, mỗi ví dụ thường là một bộ ba (x, y*, z*), trong đó z*=E(y*) là kết quả thực thi vàng và y* là chương trình vàng. Vì việc chú thích các chương trình đòi hỏi chuyên môn về lĩnh vực, đối với một số tập dữ liệu mà kết quả cuối cùng có thể được thu được trực tiếp, chỉ z* mà không có y* được cung cấp cho học (Artzi & Zettlemoyer, 2013; Cheng & Lapata, 2018; Goldman et al., 2018). Đây được gọi là setting giám sát yếu. Để thu thập dữ liệu huấn luyện, chúng tôi thu được một tập gồm n ứng cử viên chương trình duy nhất Ŝ={ŷi}ni=1 cho mỗi đầu vào x trong tập huấn luyện, bằng cách đầu tiên lấy mẫu k chương trình từ PLM(ŷ|x) và sau đó loại bỏ tất cả các chương trình trùng lặp, tương tự như thời điểm suy luận. Sau đó, đối với mỗi ứng cử viên chương trình ŷ∈S, chúng tôi thu được nhãn xác minh nhị phân của nó bằng cách so sánh kết quả thực thi ẑ=E(ŷ) với kết quả thực thi vàng z*, tức là v=1(ẑ=z*). Đối với các tập dữ liệu chứa chương trình vàng y*, chúng tôi thêm (x, y*, z*, v=1) như một ví dụ huấn luyện xác minh bổ sung, và chúng tôi bỏ qua bước này cho các tập dữ liệu giám sát yếu. Theo cách này, chúng tôi tạo ra một tập các ví dụ huấn luyện xác minh {(x,ŷi,ẑi, vi)|ŷi∈S} cho mỗi đầu vào x.

Mục tiêu học. Cho tập các ví dụ huấn luyện xác minh này, chúng tôi công thức hóa loss cho đầu vào x với hàm negative log-likelihood, được chuẩn hóa bởi số lượng ứng cử viên chương trình

Lθ(x, S) = -1/|S| · Σŷi∈S log Pθ(vi|x,ŷi,ẑi) (4)

Bước chuẩn hóa quan trọng để ngăn một ví dụ có số lượng lớn ứng cử viên chương trình duy nhất thống trị việc học.

3. Thiết lập thí nghiệm
3.1. Tập dữ liệu
Chúng tôi tiến hành thí nghiệm trên bốn tập dữ liệu sinh mã từ ngôn ngữ tự nhiên thuộc các lĩnh vực semantic parsing, table QA, math reasoning và lập trình python cơ bản. Các setting chính của bốn tập dữ liệu này được hiển thị trong Bảng 1. Các setting chi tiết hơn cho xác minh trong Bảng 7 của Phụ lục.

▷Spider (Yu et al., 2018) là một tập dữ liệu semantic parsing về sinh truy vấn SQL từ câu hỏi ngôn ngữ tự nhiên. Với 7k dữ liệu huấn luyện song song, nó cũng lý tưởng cho việc tinh chỉnh các bộ sinh;

▷WikiTableQuestions (WikiTQ) (Pasupat & Liang, 2015) là một tập dữ liệu trả lời câu hỏi về bảng, mà chúng tôi cố gắng giải quyết bằng cách sinh và thực thi các truy vấn SQL trên các bảng nguồn. Chúng tôi sử dụng các bảng đã được tiền xử lý từ Shi et al. (2020) và áp dụng các truy vấn SQL được chú thích của họ để thêm các chương trình vàng cho tập dữ liệu giám sát yếu ban đầu;

▷GSM8k (Cobbe et al., 2021) là một benchmark để giải các bài toán từ toán học cấp tiểu học. Theo công trình trước đây (Chowdhery et al., 2022; Chen et al., 2022b; Gao et al., 2022), chúng tôi tiếp cận benchmark này bằng cách sinh các chương trình Python từ câu hỏi trong NL, nên tạo ra câu trả lời đúng khi thực thi. Tập dữ liệu gốc chỉ có ngôn ngữ tự nhiên chứ không có các giải pháp chương trình, do đó nó được giám sát yếu cho sinh mã từ ngôn ngữ tự nhiên;

▷MBPP (Austin et al., 2021) chứa các chương trình lập trình Python cơ bản được phát biểu bằng ngôn ngữ tự nhiên. Mỗi ví dụ được trang bị 3 test case để kiểm tra tính đúng đắn của các chương trình. Theo công trình trước đây (Shi et al., 2022; Zhang et al., 2022), chúng tôi sử dụng test case đầu tiên như một phần của prompt cho mô hình sinh ra chữ ký hàm đúng và sử dụng cả ba để đánh giá tính đúng đắn.

3.2. Code LLMs
Chúng tôi đánh giá LEVER với ba code LLM khác nhau:

▷Codex (Chen et al., 2021a) là một họ code LLM có kích thước khác nhau được phát triển bởi OpenAI. Cụ thể, chúng tôi sử dụng API code-davinci-002 thông qua Python bindings chính thức của nó.

▷InCoder (Fried et al., 2022) là một họ code LLM lên đến 6B tham số được huấn luyện trên một corpus lớn mã nguồn với giấy phép cho phép. Chúng tôi thí nghiệm với InCoder-6B và sử dụng nó cho sinh từ trái sang phải.

▷CodeGen (Nijkamp et al., 2022) là một họ code LLM và chúng tôi đánh giá phiên bản CodeGen-16B-multi. Mặc dù các file SQL không được bao gồm trong corpus huấn luyện cho CodeGen, chúng tôi thấy nó vẫn hoạt động khá tốt trên các tác vụ sinh SQL có thể vì các truy vấn SQL đã được trộn lẫn với các file nguồn của các ngôn ngữ lập trình khác.

3.3. Baseline và metric đánh giá
Baseline. Chúng tôi so sánh LEVER với các phương pháp baseline sau để sinh chương trình sử dụng code LLMs.

▷Greedy: Chọn token có khả năng cao nhất mỗi bước giải mã.

▷Maximum Likelihood (ML): Từ k ứng cử viên chương trình được lấy mẫu, chọn chương trình có log-xác suất sinh cao nhất, tức là log PLM(ŷ|x) (hoặc log-xác suất sinh được chuẩn hóa như log PLM(ŷ|x)/|ŷ|). Chúng tôi xác định thực nghiệm sử dụng tập phát triển liệu có nên sử dụng xác suất chuẩn hóa cho mỗi tập dữ liệu. Chi tiết hơn có thể tìm thấy trong Phụ lục A.

▷Error Pruning + ML (EP + ML): Loại bỏ các ứng cử viên chương trình có lỗi thực thi; sau đó chọn chương trình có khả năng tối đa;

▷Error Pruning + Voting (EP + Voting): Bỏ phiếu đa số trên kết quả thực thi trong các chương trình không có lỗi, và chọn kết quả thực thi được bình chọn nhiều nhất và các chương trình tương ứng.

Chúng tôi tập trung vào so sánh với baseline EP+ML, vì đây là một phương pháp sắp xếp lại đơn giản khai thác thực thi và mang lại kết quả cạnh tranh nhất quán trên các tập dữ liệu và code LLM khác nhau.

Metric đánh giá. Theo công trình trước đây (Xie et al., 2022; Liu et al., 2021; Ni et al., 2022; Zhang et al., 2022), chúng tôi sử dụng độ chính xác thực thi làm metric đánh giá chính cho tất cả các tập dữ liệu, đo lường phần trăm ví dụ mang lại kết quả thực thi vàng hoặc vượt qua tất cả test case.

3.4. Chi tiết triển khai
Huấn luyện bộ xác minh. Chúng tôi tạo dữ liệu huấn luyện xác minh bằng cách lấy mẫu từ LLMs trên tập huấn luyện, sử dụng ngân sách lấy mẫu được mô tả trong Bảng 1. Thêm thống kê về dữ liệu huấn luyện kết quả có thể tìm thấy trong Bảng 7 trong Phụ lục. Khi học các bộ xác minh, như được hiển thị trong Eq. 4, loss huấn luyện được tính bằng cách tính trung bình trên tất cả các mẫu chương trình cho mỗi ví dụ. Vì chúng tôi nhóm các mẫu chương trình cho cùng các ví dụ với nhau, kích thước batch hiệu quả cũng sẽ được nhân với kích thước mẫu. Điều này có thể có vấn đề khi kích thước mẫu trở nên lớn (lên đến 100 trong thí nghiệm của chúng tôi) vì chúng có thể không vừa với bộ nhớ GPU cùng lúc. Do đó, chúng tôi down-sample các chương trình được sử dụng để học mỗi ví dụ trong mỗi lần lặp. Việc down-sampling ngẫu nhiên xảy ra ở đầu mỗi epoch huấn luyện để các bộ xác minh có thể thấy các chương trình khác nhau mỗi epoch. Kích thước batch chi tiết và hệ số downsampling có thể tìm thấy trong Bảng 7 trong Phụ lục.

Biểu diễn kết quả thực thi. Đầu vào cho bộ xác minh là một phép nối của đầu vào tác vụ, ứng cử viên chương trình và kết quả thực thi của nó. Đối với Spider và WikiTQ, chúng tôi sử dụng các bảng kết quả tuyến tính hóa từ thực thi SQL làm kết quả thực thi. Đối với GSM8k, chúng tôi sử dụng giá trị của biến được đặt tên "answer" sau khi thực thi chương trình làm kết quả thực thi. Đối với MBPP, chúng tôi sử dụng kiểu và giá trị (được cast thành string) được trả về bởi các hàm. Tất cả lỗi thực thi được biểu diễn như "ERROR: [reason]", như "ERROR: Time out". Ví dụ về các đầu vào bộ xác minh này cho các tập dữ liệu khác nhau có thể tìm thấy trong Bảng 11.

Lựa chọn mô hình bộ xác minh. Chúng tôi sử dụng tập phát triển để chọn mô hình bộ xác minh tốt nhất. Chúng tôi chọn T5-base cho Spider, T5-large cho WikiTQ và MBPP, và RoBERTa-large cho GSM8k làm LM cơ sở cho các bộ xác minh sử dụng trong thí nghiệm chính. Quy trình lựa chọn được chi tiết trong §B.2. Đối với các mô hình T5 (Raffel et al., 2020), chúng tôi huấn luyện chúng để đưa ra token "yes/no" cho mỗi ví dụ tích cực/tiêu cực cho đầu vào bộ xác minh, và chúng tôi lấy xác suất sinh "yes" làm xác suất xác minh trong suy luận. Đối với RoBERTa (Liu et al., 2019), chúng tôi thêm một lớp tuyến tính trên đầu [CLS] head, theo thực hành tiêu chuẩn của phân loại chuỗi với các mô hình chỉ encoder (Devlin et al., 2019).

Chi tiết về lấy mẫu LLM, xây dựng prompt few-shot và thiết lập dành riêng cho tập dữ liệu có thể tìm thấy trong Phụ lục A.

4. Kết quả chính
Chúng tôi hiển thị hiệu suất của LEVER kết hợp với Codex-Davinci và so sánh với hiệu suất tinh chỉnh và few-shot tiên tiến từ công trình trước đây cho Spider (Bảng 2), WikiTQ (Bảng 3), GSM8k (Bảng 4) và MBPP (Bảng 5). Ngoài ra, chúng tôi cũng đánh giá LEVER với các mô hình InCoder và CodeGen trên Spider và GSM8k (Bảng 6).

4.1. Hiệu quả của LEVER
LEVER liên tục cải thiện hiệu suất của tất cả code LLMs trên tất cả các tác vụ, mang lại cải thiện từ 6.6% (Spider) đến 17.3% (WikiTQ) so với các baseline giải mã tham lam cho Codex-Davinci. Đối với các mô hình yếu hơn như InCoder và CodeGen, chúng tôi quan sát cải thiện lên đến 30.0% cho Spider và 15.0% cho GSM8k. Hơn nữa, LEVER kết hợp với Codex-Davinci cũng đạt được kết quả tiên tiến mới trên tất cả bốn tập dữ liệu, với cải thiện từ 1.2% (WikiTQ) đến 2.0% (MBPP). Trên tập dữ liệu text-to-SQL thách thức, Spider, nơi tiên tiến trước đây được đạt được bằng cách tinh chỉnh mô hình T5-3B được tăng cường với relational-aware self-attention, chúng tôi đạt được kết quả tốt hơn với Codex-Davinci + LEVER, trong đó bộ xác minh được tinh chỉnh bằng mô hình T5-base. LEVER cũng cải thiện kết quả tốt nhất trước đây trên Spider sử dụng InCoder và CodeGen, lần lượt là 13.2% và 20.6%.

Vì LEVER là một phương pháp đơn giản kết hợp sinh LM few-shot với các bộ xác minh được học, nó có thể có lợi cho các phương pháp prompting tiên tiến hơn (Li et al., 2022b; Cheng et al., 2022) hoặc kiến trúc mô hình (Qi et al., 2022; Wang et al., 2020), mà chúng tôi để lại như công việc tương lai.

4.2. Ablation với LEVER
Chúng tôi thực hiện nghiên cứu ablation cho LEVER với Codex-Davinci và so sánh với các baseline được đề cập trong §3.3, và kết quả được hiển thị trong Hình 2. Các ablation giống nhau được tiến hành cho InCoder và CodeGen với kết quả trong Bảng 6. Trong các kết quả này, chúng tôi bao gồm hiệu suất "Oracle" được thu được bằng cách luôn chọn chương trình đúng miễn là chúng xuất hiện trong tập mẫu.

Hiệu ứng của việc bao gồm kết quả thực thi. Theo Hình 2, hiệu suất giảm đáng kể trên tất cả bốn benchmark khi kết quả thực thi được loại bỏ khỏi đầu vào bộ xác minh, chỉ ra rằng kết quả thực thi quan trọng cho việc huấn luyện bộ xác minh. Hiệu ứng khác nhau giữa các tập dữ liệu khác nhau. Trong khi nó gây ra giảm hiệu suất tuyệt đối 6.6% và 5.6% cho WikiTQ và MBPP, việc giảm nhỏ hơn cho Spider (3.0%) và GSM8k (1.2%). Chúng tôi thấy các mẫu mã cho WikiTQ và MBPP chứa nhiều lỗi thực thi hơn, điều này giải thích tại sao phương pháp của chúng tôi hiệu quả hơn trên hai tập dữ liệu này. Bảng 6 cho thấy xu hướng tương tự cho InCoder-6B và CodeGen-16B trên Spider và GSM8k. Các LM nhỏ hơn có hiệu suất few-shot tệ hơn và việc loại bỏ thông tin thực thi từ bộ xác minh thường dẫn đến giảm hiệu suất lớn hơn. Hơn nữa, chúng tôi thấy LEVER nói chung vượt trội hơn baseline EP+ML, chỉ ra rằng các bộ xác minh có thể sử dụng các manh mối ngoài các lỗi thực thi đơn giản. Phân tích định lượng chi tiết hơn về khi nào thông tin thực thi giúp ích trong Hình 6.

Hiệu ứng của tổng hợp kết quả thực thi. Tổng hợp các chương trình có cùng kết quả thực thi là một kỹ thuật đơn giản và được sử dụng rộng rãi (Chen et al., 2022b; Cheng et al., 2022). Chúng tôi thấy tổng hợp thực thi hoạt động tốt với LEVER trên các tập dữ liệu có đầu ra Python, nhưng chỉ có lợi ích nhỏ cho các tập dữ liệu SQL. Một lý do có thể là cấu trúc mã Python linh hoạt hơn so với các ngôn ngữ dành riêng cho lĩnh vực như SQL. Trong lĩnh vực truy vấn cơ sở dữ liệu, một chương trình không chính xác có khả năng cao hơn thực thi đến một số kết quả tầm thường nhưng sai (ví dụ, "0" hoặc bảng rỗng). Sau khi tổng hợp, các kết quả không chính xác như vậy có thể tích lũy đủ khối lượng xác suất để vượt qua kết quả đúng, dẫn đến tác động tiêu cực đến hiệu suất.

Setting giám sát yếu. Chúng tôi cũng so sánh hiệu suất của LEVER dưới setting giám sát đầy đủ và yếu. Hình 2 và Bảng 6 cho thấy hiệu suất của LEVER được bảo tồn phần lớn khi các chương trình vàng không được đưa ra và setting giám sát yếu được sử dụng (§2.3), với giảm hiệu suất tuyệt đối lên đến 1.1%. Điều này gợi ý rằng LEVER hoạt động tốt dưới setting giám sát yếu, và bản thân chương trình ít thông tin hơn cho việc xác minh so với kết quả thực thi.

5. Phân tích
5.1. Mở rộng ví dụ huấn luyện
Chúng tôi cho thấy hiệu suất của LEVER thay đổi như thế nào với ít ví dụ huấn luyện hơn trong Hình 3, sử dụng Spider làm ví dụ. Thêm kết quả về WikiTQ và GSM8k trong §B.3. Các cải thiện với LEVER so với LLM cơ sở vẫn nhất quán ngay cả khi chỉ có 250 ví dụ được đưa ra, với cải thiện từ 1.7% đến 10.0% trên các tập dữ liệu và LLM khác nhau. Điều này gợi ý rằng LEVER có thể hoạt động dưới setting ít tài nguyên. Hơn nữa, xu hướng cũng khác nhau cho các tập dữ liệu và code LLM khác nhau, ví dụ, khi sử dụng Codex làm LLM, hiệu suất của LEVER giảm 6.4% cho WikiTQ và chỉ 3.2% cho Spider. Tuy nhiên, cũng trên Spider, hiệu suất giảm 6.9% và 5.3% cho InCoder và CodeGen. Điều này gợi ý rằng có thêm ví dụ huấn luyện cho LEVER có hiệu ứng lớn hơn cho các tập dữ liệu khó hơn và LM yếu hơn.

Với Hình 3, chúng tôi cũng so sánh hiệu suất của LEVER với các mô hình T5 được tinh chỉnh trực tiếp để sinh cho cùng số lượng ví dụ huấn luyện. Trong khi việc xác minh có thể được học với chỉ hàng trăm ví dụ, hiệu suất của các mô hình T5 được tinh chỉnh giảm mạnh khi có ít ví dụ huấn luyện hơn. Như một ví dụ, cho 500 ví dụ, một bộ xác minh T5-base trên InCoder/CodeGen vượt trội hơn một bộ sinh T5-3B được tinh chỉnh khoảng 7%.

5.2. Mở rộng kích thước mẫu
Vì việc rút mẫu từ LLMs có thể tốn kém về mặt tính toán, ở đây chúng tôi nghiên cứu kích thước mẫu trong thời gian huấn luyện và suy luận ảnh hưởng đến hiệu suất như thế nào. Như chúng ta có thể thấy từ Hình 4a, trong thời gian suy luận, khi giảm kích thước mẫu từ 50 xuống 10 chương trình mỗi ví dụ, hiệu suất của LEVER giảm 1.8% (Spider) đến 5.2% (WikiTQ). Điều này chỉ ra rằng LEVER nhạy cảm với kích thước mẫu tại thời điểm suy luận, điều này được mong đợi vì nó cũng ảnh hưởng rất lớn đến kết quả oracle (tức là, cận trên cho sắp xếp lại). Để so sánh, Hình 4b cho thấy LEVER rất không nhạy cảm với kích thước mẫu để cung cấp dữ liệu huấn luyện, với khoảng cách hiệu suất đều dưới 1% cho ba tập dữ liệu. Nhìn chung, các kết quả cho thấy ngân sách lấy mẫu cao hơn giúp ích nhiều hơn tại thời điểm kiểm tra.

5.3. Calibration của bộ xác minh và bộ sinh
Chúng tôi nghiên cứu mức độ calibration của bộ xác minh và bộ sinh trong việc xác định các chương trình đúng. Lý tưởng, các mẫu chương trình đúng sẽ được đưa ra xác suất cao hơn do đó chúng ta nên quan sát phần trăm chương trình đúng cao hơn khi nó gần với top hơn. Để làm điều này, chúng tôi sắp xếp điểm dự đoán của bộ xác minh, bộ sinh và LEVER (như trong Eq. 3), và di chuyển ngưỡng percentile và đo phần trăm chương trình đúng trong các chương trình được xếp hạng cao nhất. Theo Hình 5, các bộ xác minh nói chung được calibrated tốt hơn so với các bộ sinh, đặc biệt khi ngưỡng ở percentile thấp hơn. Điều này chỉ ra rằng việc các bộ xác minh xác định các lỗi rõ ràng trong chương trình với kết quả thực thi như một phần của đầu vào của chúng dễ dàng hơn. Thú vị, khi phân biệt giữa các chương trình được xếp hạng cao nhất, các bộ xác minh được calibrated kém trong ba trong số bốn tập dữ liệu được kiểm tra. Tuy nhiên, các bộ sinh nói chung được calibrated tốt hơn trong vùng này, và việc kết hợp xác suất của bộ xác minh và bộ sinh mang lại kết quả tốt nhất trên tất cả bốn benchmark. Cụ thể hơn, trên tập dữ liệu GSM8k, nơi calibration của cả hai mô hình khá kém cho các chương trình xếp hạng cao nhất, xác suất kết hợp của chúng được calibrated tốt đáng ngạc nhiên, cho thấy hai mô hình bổ sung cho nhau trên tập dữ liệu này.

5.4. Phân tích định lượng
Chúng tôi trình bày một phân tích định lượng về tại sao LEVER thành công hoặc thất bại trong việc cải thiện hiệu suất của LLMs. Theo Hình 6, khi LEVER sắp xếp lại một chương trình để thay thế chương trình khác có xác suất sinh cao hơn, thường là do kết quả thực thi cung cấp thông tin quan trọng như lỗi thực thi, kiểu biến và phạm vi. Điều này phù hợp với phát hiện của chúng tôi trong §4.2 về tầm quan trọng của kết quả thực thi đối với LEVER. Cũng đáng chú ý rằng có những trường hợp LEVER vẫn có thể sắp xếp lại chương trình đúng khi kết quả thực thi không có lỗi cùng kiểu và phạm vi với chương trình tham lam, tức là trong danh mục "others". Giả thuyết của chúng tôi là đây là khi bản thân chương trình trở thành đặc trưng chính cho các bộ xác minh khai thác. Ngoài ra, khi LEVER thất bại trong việc xếp hạng các chương trình đúng lên đầu, lý do phổ biến nhất là không thể tìm thấy chương trình đúng trong các mẫu (tức là, đạt cận trên), đặc biệt là trường hợp cho các LM yếu hơn. Lý do phổ biến thứ hai cho LEVER thất bại là kết quả thực thi của chương trình không chính xác khi sắp xếp lại có cùng kiểu và phạm vi với chương trình đúng trong các mẫu. Trong trường hợp này, kết quả thực thi không cung cấp thông tin phong phú cho các bộ xác minh do đó LEVER thất bại trong việc cải thiện code LLMs.

6. Công trình liên quan
Sinh mã từ ngôn ngữ tự nhiên. Việc dịch ngôn ngữ tự nhiên thành mã là một thách thức lâu dài qua tất cả các kỷ nguyên của trí tuệ nhân tạo, bao gồm các hệ thống dựa trên quy tắc (Woods, 1973; Templeton & Burger, 1983), dự đoán có cấu trúc (Zelle & Mooney, 1996; Zettlemoyer & Collins, 2005; Gulwani & Marron, 2014) và deep learning (Xiao et al., 2016; Dong & Lapata, 2016; Rabinovich et al., 2017; Zhong et al., 2017; Lin et al., 2017). Gần đây, các mô hình ngôn ngữ mã được tiền huấn luyện (Chen et al., 2021a; Wang et al., 2021; Fried et al., 2022; Nijkamp et al., 2022; OpenAI, 2022) đã chứng minh hiệu suất mạnh mẽ đáng ngạc nhiên trong bài toán này trên các ngôn ngữ lập trình (Lin et al., 2018; Yu et al., 2018; Austin et al., 2021; Cobbe et al., 2021; Li et al., 2022a). Một số phương pháp đã được đề xuất để tinh chỉnh việc lựa chọn mẫu LLM, bao gồm thực thi test case (Li et al., 2022a), độ tương đồng giữa các mẫu (Chen et al., 2021a; Li et al., 2022a; Shi et al., 2022) và lọc dựa trên thông tin lẫn nhau tối đa (Zhang et al., 2022). Công trình của chúng tôi đề xuất một module xác minh có thể học để đánh giá đầu ra mẫu của LLMs để cải thiện thêm hiệu suất của chúng.

Sinh mã với thực thi. Công trình sinh mã trước đây đã khai thác kết quả thực thi theo các cách khác nhau. Các phương pháp học giám sát yếu (Berant et al., 2013; Pasupat & Liang, 2015; Guu et al., 2017) mô hình hóa các chương trình như các biến ẩn và sử dụng kết quả thực thi để suy ra tín hiệu giám sát. Kết quả thực thi trung gian được sử dụng để hướng dẫn tìm kiếm chương trình cả trong thời gian huấn luyện (Chen et al., 2019; 2021b) và suy luận (Wang et al., 2018). Khi lấy mẫu ở quy mô lớn, bỏ phiếu đa số dựa trên kết quả thực thi đã được chứng minh hiệu quả cho việc lựa chọn ứng cử viên (Li et al., 2022a; Cobbe et al., 2021). Shi et al. (2022) tổng quát hóa nguyên tắc này bằng cách chọn các mẫu có sự đồng thuận tối đa với các mẫu khác trong kết quả thực thi. Chúng tôi đề xuất huấn luyện một mô hình xác minh để đánh giá tính đúng đắn của sinh mã có tính đến kết quả thực thi.

Học xác minh. Công trình trước đây đã cho thấy hiệu quả của các bộ xác minh được học cho việc lọc mẫu trong các lĩnh vực như math QA (Shen et al., 2021; Cobbe et al., 2021) và commonsense QA (Li et al., 2022b), nơi giải pháp chủ yếu được mô tả bằng ngôn ngữ tự nhiên. Trong khi việc huấn luyện các bộ xác minh độc lập với bộ sinh phổ biến hơn (Cobbe et al., 2021; Li et al., 2022b), Shen et al. (2021) tinh chỉnh kết hợp cả hai cùng lúc. Công trình trước đây cũng đã sử dụng các LM cơ sở khác nhau cho các bộ xác minh. Cobbe et al. (2021) sử dụng GPT-3 (Brown et al., 2020) trong khi Li et al. (2022b) sử dụng DeBERTa (He et al., 2020). Ngoài các bộ xác minh dành riêng cho tác vụ, Kadavath et al. (2022) cho thấy các LM lớn có thể tự xác minh đầu ra của chúng trong setting few-shot cho một loạt các tác vụ. Chen et al. (2022a) và các công trình khác (Tufano et al., 2020; Li et al., 2022a) sử dụng LMs để sinh test case thay vì trực tiếp đánh giá tính đúng đắn của các chương trình đầu ra. Để so sánh, setting của LEVER gần với Li et al. (2022b) vì chúng tôi huấn luyện bộ xác minh riêng biệt và sử dụng LM nhỏ hơn nhiều cho nó (khoảng 0.5% kích thước tham số bộ sinh). Chúng tôi báo cáo tập đánh giá toàn diện đầu tiên về các tác vụ sinh mã từ ngôn ngữ tự nhiên, sử dụng kết quả thực thi chương trình.

Sắp xếp lại phân biệt. Các phương pháp sắp xếp lại phân biệt từ lâu đã được sử dụng để cải thiện thêm hiệu suất của các tác vụ sinh chuỗi, bao gồm tóm tắt (Wan et al., 2015), dịch máy (Shen et al., 2004; Lee et al., 2021), sinh phản hồi đối thoại (Olabiyi et al., 2018) và gần đây hơn, sinh mã (Yin & Neubig, 2019). LEVER có thể được xem như một framework sắp xếp lại phân biệt.

7. Hạn chế
Trong công trình này, chúng tôi sử dụng thông tin thực thi để xác minh các chương trình trong LEVER. Tuy nhiên, việc thực thi các chương trình phụ thuộc vào ít nhất một tập đầu vào (ví dụ, đối số cho một hàm) và ngữ cảnh thực thi đầy đủ (ví dụ, cơ sở dữ liệu), có thể không được cung cấp cho một số ứng dụng. Hơn nữa, chúng ta không thể luôn giả định rằng các chương trình do mô hình sinh ra an toàn để thực thi. Ngoài ra, chúng tôi sử dụng PASS@1 làm metric đánh giá chính trong các thí nghiệm. Trong khi nó lý tưởng cho các ứng dụng như text-to-SQL và math reasoning nơi người dùng chỉ tìm kiếm câu trả lời cho câu hỏi của họ, các metric như PASS@k hoặc N@k có thể cung cấp các góc nhìn khác nhau cho các tác vụ lập trình tổng quát như MBPP.

8. Kết luận
Chúng tôi đề xuất LEVER, một phương pháp đơn giản để cải thiện code LLMs trên các tác vụ sinh mã từ ngôn ngữ tự nhiên, bằng cách học các mô hình xác minh riêng biệt để đánh giá tính đúng đắn của các chương trình được sinh ra, có tính đến kết quả thực thi của chúng. Chúng tôi cho thấy rằng có thể huấn luyện các bộ xác minh khoảng 0.5% kích thước của các bộ sinh sử dụng các tập dữ liệu benchmark có giám sát. Thay vì trực tiếp thực hiện lấy mẫu từ chối dựa trên đầu ra bộ xác minh, chúng tôi cho thấy tốt hơn là trộn xác suất sinh và xác minh cho việc sắp xếp lại mẫu. LEVER liên tục cải thiện hiệu suất của code LLMs trên bốn tác vụ sinh mã từ ngôn ngữ tự nhiên, và đạt được kết quả tiên tiến mới trên tất cả chúng. Phân tích thêm gợi ý rằng kết quả thực thi chương trình quan trọng cho việc xác minh và phương pháp đề xuất có thể tổng quát hóa trên các LLM khác nhau.

Lời cảm ơn
Các tác giả muốn cảm ơn Xi Ye, Tianyi Zhang, Mengzhou Xia, Luke Zettlemoyer, và các nhà đánh giá ẩn danh cho các cuộc thảo luận và nhận xét hữu ích.

Tài liệu tham khảo
[Các tài liệu tham khảo tiếp tục với định dạng tương tự...]

# Mạng Neural Hiệu Quả Như Thế Nào Trong Việc Sửa Lỗi Bảo Mật

Yi Wu
Đại học Purdue
West Lafayette, Hoa Kỳ
wu1827@purdue.edu

Nan Jiang
Đại học Purdue
West Lafayette, Hoa Kỳ
jiang719@purdue.edu

Hung Viet Pham∗
Đại học York
Toronto, Canada
hvpham@yorku.ca

Thibaud Lutellier∗
Đại học Alberta
Camrose, Canada
lutellie@ualberta.ca

Jordan Davis
Đại học Purdue
West Lafayette, Hoa Kỳ
davi1304@purdue.edu

Lin Tan
Đại học Purdue
West Lafayette, Hoa Kỳ
lintan@purdue.edu

Petr Babkin
Nghiên cứu AI J.P. Morgan
Palo Alto, Hoa Kỳ
petr.babkin@jpmorgan.com

Sameena Shah
Nghiên cứu AI J.P. Morgan
New York, Hoa Kỳ
sameena.shah@jpmchase.com

TÓM TẮT

Sửa chữa lỗi bảo mật là một nhiệm vụ khó khăn cần được tự động hóa cấp thiết. Hai nhóm kỹ thuật đã cho thấy tiềm năng: (1) các mô hình ngôn ngữ mã lớn (LLMs) đã được đào tạo trước trên mã nguồn cho các tác vụ như hoàn thành mã, và (2) các kỹ thuật sửa chữa chương trình tự động (APR) sử dụng mô hình học sâu (DL) để tự động sửa lỗi phần mềm.

Bài báo này là nghiên cứu đầu tiên về khả năng sửa chữa lỗi bảo mật Java của các LLMs và mô hình APR dựa trên DL. Những đóng góp bao gồm việc chúng tôi (1) áp dụng và đánh giá năm LLMs (Codex, CodeGen, CodeT5, PLBART và InCoder), bốn LLMs được tinh chỉnh, và bốn kỹ thuật APR dựa trên DL trên hai benchmark lỗi bảo mật Java thực tế (Vul4J và VJBench), (2) thiết kế các phép biến đổi mã để giải quyết mối đe dọa trùng lặp dữ liệu huấn luyện và kiểm tra đối với Codex, (3) tạo ra một benchmark sửa chữa lỗi bảo mật Java mới VJBench, và phiên bản được biến đổi VJBench-trans, để đánh giá tốt hơn các LLMs và kỹ thuật APR, và (4) đánh giá các LLMs và kỹ thuật APR trên các lỗi bảo mật đã biến đổi trong VJBench-trans.

Các phát hiện của chúng tôi bao gồm (1) các LLMs và mô hình APR hiện tại sửa rất ít lỗi bảo mật Java. Codex sửa được 10,2 (20,4%) lỗi bảo mật, nhiều nhất. Nhiều bản vá được tạo ra không thể biên dịch. (2) Tinh chỉnh với dữ liệu APR tổng quát cải thiện khả năng sửa lỗi bảo mật của LLMs. (3) VJBench mới của chúng tôi tiết lộ rằng các LLMs và mô hình APR không thể sửa nhiều loại Common Weakness Enumeration (CWE), như CWE-325 Thiếu bước mã hóa và CWE-444 Buôn lậu yêu cầu HTTP. (4) Codex vẫn sửa được 8,7 lỗi bảo mật đã biến đổi, vượt trội hơn tất cả các LLMs và mô hình APR khác trên các lỗi bảo mật đã biến đổi. Kết quả kêu gọi các đổi mới để nâng cao khả năng sửa chữa lỗi bảo mật Java tự động như tạo ra dữ liệu huấn luyện sửa chữa lỗi bảo mật lớn hơn, tinh chỉnh LLMs với dữ liệu như vậy, và áp dụng phép biến đổi đơn giản hóa mã để hỗ trợ sửa chữa lỗi bảo mật.

∗Công việc này được thực hiện khi Hung Viet Pham và Thibaud Lutellier còn ở Đại học Waterloo.

CÁC KHÁI NIỆM CCS
•Phần mềm và kỹ thuật của nó →Kiểm tra và gỡ lỗi phần mềm; Lập trình tự động; •Phương pháp tính toán →Mạng neural; •Bảo mật và quyền riêng tư →Kỹ thuật bảo mật phần mềm.

TỪ KHÓA
Sửa chữa chương trình tự động, Mô hình ngôn ngữ lớn, Lỗi bảo mật, AI và Kỹ thuật phần mềm

1 GIỚI THIỆU

Các lỗi bảo mật phần mềm, như tràn bộ đệm và SQL injection, có tác động quan trọng đến nền kinh tế toàn cầu và có thể gây hại cho hàng triệu người dùng. Khi một lỗi bảo mật được phát hiện, việc sửa chữa nó một cách nhanh chóng thường rất quan trọng để giảm thiểu khả năng bị khai thác. Tuy nhiên, các nghiên cứu gần đây [43,52] phát hiện rằng thời gian trung bình để sửa một lỗi bảo mật (thời gian giữa phát hiện và sửa chữa) dao động từ 60 đến 79 ngày, vẫn còn quá dài và tạo ra nhiều cơ hội cho kзлоумышленники khai thác các lỗi bảo mật này. Ví dụ, với lỗi bảo mật nghiêm trọng Apache Log4Shell được báo cáo vào ngày 24 tháng 11 năm 2021, bản sửa lỗi đầu tiên được Apache triển khai 12 ngày sau báo cáo. Trong 12 ngày đó, cả Cloudflare và Cisco đều báo cáo nhiều cuộc tấn công khai thác lỗi bảo mật này [34]. Hơn nữa, bản sửa lỗi ban đầu tỏ ra không đủ, khiến Log4Shell vẫn dễ bị tấn công cho đến khi có bản sửa lỗi hoàn chỉnh được phát hành hơn một tháng sau đó. Kết quả là, cần có các giải pháp sửa lỗi bảo mật nhanh hơn.

Hầu hết các benchmark lỗi bảo mật và giải pháp sửa chữa lỗi bảo mật tập trung vào C/C++ [19,29–31,36,42,46,53,67] hoặc tệp nhị phân [10,48,54,60,72]. Thiếu các giải pháp và benchmark cho Java, mặc dù nó là ngôn ngữ lập trình được sử dụng rộng rãi (ngôn ngữ phổ biến thứ ba trong cộng đồng mã nguồn mở [32]) với nhiều lỗi bảo mật nghiêm trọng.

Java đã được sử dụng để triển khai các máy chủ quan trọng, bao gồm máy chủ web và dịch vụ (ví dụ: Tomcat, Spring, CFX, Log4J), đặc biệt dễ bị tấn công. Do đó, nhiều lỗi bảo mật quan trọng nhất nằm trong phần mềm Java. Ví dụ, Google đánh giá rằng lỗi bảo mật Log4Shell trong gói Log4J đã ảnh hưởng đến 17.000 dự án Maven [7], và Microsoft thậm chí báo cáo rằng các kẻ tấn công nhà nước đã khai thác lỗi bảo mật này [2].

Các benchmark và giải pháp cho các ngôn ngữ lập trình khác thường không hoạt động hoặc hoạt động kém trong việc sửa lỗi bảo mật Java. Ví dụ, các lỗi bảo mật phổ biến nhất trong C/C++ là tràn bộ đệm [24,59]. Java, là ngôn ngữ type-safe, được thiết kế để tránh tràn bộ đệm. Do đó, hầu hết các kỹ thuật C/C++ tập trung vào lỗi bảo mật tràn bộ đệm không liên quan đến Java. Chúng ta cần các benchmark và kỹ thuật mới để sửa lỗi bảo mật Java.

Thay vì xây dựng một kỹ thuật để sửa lỗi bảo mật Java tự động, chúng tôi nghiên cứu và so sánh không gian và tính khả thi của việc áp dụng hai loại kỹ thuật—sửa chữa chương trình tự động dựa trên học tập và LLMs—để sửa lỗi bảo mật Java tự động. Đầu tiên, sửa chữa chương trình dựa trên học tập đã trở nên phổ biến [18,21,22,40,47,75,75,76,76]. Các phương pháp encoder-decoder này học từ một số lượng lớn các cặp lỗi và bản sửa (trong các dự án mã nguồn mở) để tự động sửa lỗi phần mềm Java chưa được thấy. Sẽ thú vị khi nghiên cứu các mô hình sửa chữa chương trình dựa trên học tập này hiệu quả như thế nào trong việc sửa một tập con của lỗi phần mềm, tức là các lỗi bảo mật phần mềm.

Thứ hai, các LLMs gần đây đã được áp dụng cho mã nguồn [17,25,37,40,50,63,73] và là các mô hình đã được đào tạo trước được huấn luyện trên một lượng mã nguồn khổng lồ (ví dụ: toàn bộ GitHub). Khác với các mô hình APR, các LLMs đã được đào tạo trước học từ kho mã nguồn lớn (thay vì các cặp lỗi và bản sửa) cho các tác vụ khác nhau như gắn thẻ định danh và hoàn thành mã. Mặc dù học để thực hiện các tác vụ khác với sửa chữa, nghiên cứu gần đây [38,74] cho thấy các LLMs đã được đào tạo trước có khả năng cạnh tranh trong việc sửa lỗi Java tổng quát [41,44]. Sẽ thú vị khi nghiên cứu các LLMs này hiệu quả như thế nào cho một tác vụ khác, tức là sửa lỗi bảo mật phần mềm, khi chúng không thấy cách các lỗi được sửa.

Thứ ba, sẽ thú vị khi so sánh khả năng sửa lỗi bảo mật Java của các kỹ thuật APR dựa trên học sâu (DL) và LLMs. Các kỹ thuật APR dựa trên DL và LLMs đại diện cho hai góc độ áp dụng mô hình cho một tác vụ khác. Áp dụng các kỹ thuật APR dựa trên DL để sửa lỗi bảo mật là sử dụng các mô hình học từ bộ dữ liệu tổng quát cho một tập con cụ thể của bộ dữ liệu (lỗi bảo mật phần mềm là một loại lỗi phần mềm). Áp dụng LLMs để sửa lỗi bảo mật là sử dụng các mô hình học từ định dạng dữ liệu khác (chuỗi mã) cho định dạng khác (cặp mã lỗi và mã đã sửa). Vì LLMs không cần cặp lỗi và bản sửa, LLMs thường được xây dựng từ dữ liệu lớn hơn nhiều bậc so với dữ liệu huấn luyện được sử dụng để huấn luyện các mô hình APR. Liệu có nhiều dữ liệu hơn sẽ thắng hay định dạng dữ liệu phù hợp sẽ thắng?

Cuối cùng, các LLMs đã được đào tạo trước thường được tinh chỉnh để thích ứng với các tác vụ downstream khác nhau [8,26,33,65,73]. Một nghiên cứu gần đây [38] cho thấy việc tinh chỉnh cải thiện khả năng sửa lỗi của LLMs ít nhất 31%. Tuy nhiên, do thiếu dữ liệu lỗi bảo mật Java, việc tinh chỉnh LLMs để sửa lỗi bảo mật Java là không thực tế. Do đó, sẽ thú vị khi nghiên cứu các LLMs được tinh chỉnh với dữ liệu APR tổng quát hiệu quả như thế nào trong việc sửa lỗi bảo mật phần mềm. Và khi so sánh với các kỹ thuật APR dựa trên DL, liệu có nhiều dữ liệu hơn cộng với tinh chỉnh sẽ thắng hay định dạng dữ liệu phù hợp sẽ thắng?

1.1 Phương pháp của chúng tôi

Chúng tôi tiến hành nghiên cứu đầu tiên để đánh giá và so sánh khả năng sửa lỗi bảo mật Java của các kỹ thuật APR và LLMs. Chúng tôi đánh giá năm LLMs (Codex [1], CodeT5 [73], CodeGen [55], PLBART [8] và InCoder [28]), bốn LLMs được tinh chỉnh với dữ liệu APR tổng quát, và bốn kỹ thuật APR (CURE [40], Recoder [76], RewardRepair [75], và KNOD [39]) trên hai benchmark lỗi bảo mật Java (Vul4J và VJBench mới mà chúng tôi tạo ra). Có hai thách thức chính.

Đầu tiên, có ít benchmark có sẵn để đánh giá các công cụ sửa chữa lỗi bảo mật Java. Trong khi Vul4J [16] chứa 79 lỗi bảo mật Java có thể tái tạo, chúng chỉ thuộc về 25 CWEs, tức là các loại lỗi bảo mật. Ngoài ra, 60% số CWEs trong bộ dữ liệu (15 loại lỗi bảo mật) chỉ được bao phủ bởi một lỗi bảo mật có thể tái tạo duy nhất.

Để giải quyết thách thức này, chúng tôi phát triển các benchmark mới. Chúng tôi phân tích toàn bộ Cơ sở dữ liệu lỗi bảo mật quốc gia (NVD) [4] để xác định các lỗi bảo mật Java thực tế có thể tái tạo phù hợp cho đánh giá sửa chữa lỗi bảo mật, và sử dụng chúng để tạo ra benchmark VJBench của chúng tôi. Các lỗi bảo mật này bao gồm thêm mười hai loại CWE không có trong bộ dữ liệu Vul4J và thêm nhiều lỗi bảo mật vào bốn loại CWE mà Vul4J chỉ có một lỗi bảo mật liên quan. Benchmark mới có thể hỗ trợ đánh giá các kỹ thuật sửa chữa lỗi bảo mật Java trong tương lai.

Thách thức thứ hai phát sinh từ việc Codex được huấn luyện trên một kho mã đáng kể được thu thập từ GitHub [17] và bộ dữ liệu huấn luyện không được công bố. Vì các dự án trong Vul4J và VJBench là các kho công khai trên GitHub, người ta không thể chắc chắn rằng các lỗi bảo mật trong Vul4J và VJBench không có trong dữ liệu huấn luyện của Codex. Đây là một mối đe dọa lớn đã biết đối với tính hợp lệ của đánh giá [11,69]. Trong khi bộ dữ liệu HumanEval [17] không có trong dữ liệu huấn luyện của Codex, nó dành cho hoàn thành mã Python và không chứa lỗi bảo mật Java. Tạo ra các benchmark thực tế mới không chỉ tốn kém [16,41], mà còn có thể không thực tế nếu LLMs đã được huấn luyện trên tất cả các bộ dữ liệu công khai.

Giải pháp tối ưu của chúng tôi để giảm thiểu thách thức này là biến đổi mã lỗi bảo mật trong các benchmark hiện có. Chúng tôi sử dụng hai loại biến đổi mã: đổi tên định danh và thay đổi cấu trúc mã. Các biến đổi này tạo ra các chương trình tương đương mới vẫn giữ lại lỗi bảo mật nhưng không được bao gồm trong bất kỳ bộ dữ liệu mã nguồn mở nào mà Codex và các LLMs khác có thể đã thấy. Kết quả là, chúng tôi tạo ra VJBench-trans, một benchmark của các lỗi bảo mật đã biến đổi, bằng cách áp dụng hai chiến lược biến đổi trên các lỗi bảo mật từ Vul4J và VJBench.

1.2 Đóng góp

Bài báo của chúng tôi đưa ra các đóng góp sau:

• Chúng tôi tiến hành nghiên cứu đầu tiên đánh giá khả năng sửa lỗi của năm LLMs, bốn LLMs được tinh chỉnh, và bốn kỹ thuật APR trên các lỗi bảo mật Java thực tế từ hai benchmark Vul4J và VJBench mới của chúng tôi. Các phát hiện của chúng tôi bao gồm:

– Các LLMs và kỹ thuật APR hiện tại sửa rất ít lỗi bảo mật Java. Codex sửa 10,2 (20,4%) lỗi bảo mật trung bình, thể hiện khả năng sửa lỗi tốt nhất. (Mục 6.1)

– Tinh chỉnh với dữ liệu APR tổng quát cải thiện khả năng sửa lỗi bảo mật của LLMs. InCoder được tinh chỉnh sửa 9 lỗi bảo mật, thể hiện khả năng sửa lỗi cạnh tranh với Codex. (Mục 6.1)

– Codex có tỷ lệ biên dịch cao nhất là 79,7%. Các LLMs khác (được tinh chỉnh hoặc không) và kỹ thuật APR có tỷ lệ biên dịch thấp (thấp nhất là 6,4% với CodeT5 và phần còn lại từ 24,5% đến 65,2%), cho thấy thiếu kiến thức về miền cú pháp. (Mục 6.1)

– Các LLMs và mô hình APR, ngoại trừ Codex, chỉ sửa các lỗi bảo mật cần thay đổi đơn giản, như xóa một lần hoặc thay thế biến/phương thức. (Mục 6.2)

– VJBench mới của chúng tôi tiết lộ rằng các LLMs và mô hình APR không thể sửa nhiều loại CWE bao gồm CWE-172 Lỗi mã hóa, CWE-325 Thiếu bước mã hóa, CWE-444 Buôn lậu yêu cầu HTTP, CWE-668 Tiết lộ tài nguyên cho phạm vi sai, và CWE-1295 Thông báo debug tiết lộ thông tin không cần thiết. (Mục 6.2)

• Chúng tôi tạo ra hai benchmark lỗi bảo mật Java cho sửa chữa chương trình tự động: (1) VJBench, chứa 42 lỗi bảo mật Java thực tế có thể tái tạo bao gồm mười hai loại CWE mới, và (2) VJBench-trans, chứa 150 lỗi bảo mật Java đã biến đổi.

• Chúng tôi sử dụng các biến đổi mã để giảm thiểu mối đe dọa rằng các LLMs và Codex hộp đen có thể đã thấy các benchmark được đánh giá.

• Chúng tôi đánh giá khả năng sửa lỗi của LLMs và kỹ thuật APR trên các lỗi bảo mật đã biến đổi (VJBench-trans).

– Các biến đổi mã khiến LLMs và kỹ thuật APR sửa ít lỗi bảo mật hơn. Một số mô hình như Codex và CodeT5 được tinh chỉnh mạnh mẽ hơn đối với các biến đổi mã. Mặt khác, một số biến đổi làm cho lỗi bảo mật dễ sửa hơn. (Mục 6.3)

• Chúng tôi cung cấp các hàm ý và đề xuất cho hướng nghiên cứu tương lai (Mục 6).

2 BENCHMARK MỚI VỀ LỖI BẢO MẬT JAVA

Một benchmark APR Java phải chứa các lỗi bảo mật Java có thể tái tạo với các test case tiết lộ lỗi bảo mật. Trong khi có nhiều benchmark như vậy cho lỗi Java, bao gồm Defects4J [41], QuixBugs [44], Bugs.jar [66], và Bears [49], benchmark lỗi bảo mật Java duy nhất cho APR là Vul4J [16]. Vul4J chứa 79 lỗi bảo mật từ 51 dự án bao gồm 25 loại CWE. Mặc dù là bước đầu có giá trị, Vul4J cung cấp phạm vi bao phủ hạn chế của các danh mục CWE như đã giải thích trong Giới thiệu. Ngoài ra, chỉ có 35 trong số các lỗi bảo mật này có thể áp dụng để đánh giá các hệ thống APR dựa trên học tập hiện đại [40,75,76] vì các mô hình APR này chỉ sửa lỗi đơn hunk. Cụ thể, 39 trong số 79 lỗi bảo mật là đơn hunk. Chúng tôi chỉ có thể tái tạo 35 trong số 39 lỗi bảo mật, vì hai lỗi không thể biên dịch, và hai lỗi không thể tái tạo với container Docker được cung cấp bởi các tác giả Vul4J.

Để mở rộng benchmark này, chúng tôi thu thập các lỗi bảo mật Java theo công việc trước đây [41]: i) Lỗi bảo mật chỉ nên liên quan đến mã nguồn Java, ii) Commit sửa lỗi nên chứa ít nhất một test case thành công trên V_fix nhưng thất bại trên V_bug, iii) Bản vá sửa lỗi chỉ nên bao gồm các thay đổi sửa lỗi bảo mật và không nên giới thiệu các thay đổi không liên quan như tính năng hoặc tái cấu trúc, và iv) lỗi bảo mật chưa có trong Vul4J.

Chúng tôi tải xuống tất cả dữ liệu lỗi bảo mật có sẵn ở định dạng JSON vào ngày 13 tháng 5 năm 2022 từ NVD. Chúng tôi phân tích dữ liệu này và có được danh sách 7.116 dự án GitHub bằng cách thu thập các URL tham chiếu của các lỗi bảo mật này. Chúng tôi loại trừ các dự án có ít hơn 50% mã của chúng bằng Java, dẫn đến 400 dự án Java chứa 933 lỗi bảo mật duy nhất. Sau đó, chúng tôi cố gắng xác định các commit sửa lỗi cho mỗi lỗi bảo mật trong số 933 lỗi bảo mật bằng cách kiểm tra thủ công các liên kết tham chiếu được cung cấp trong báo cáo lỗi bảo mật hoặc bằng cách tìm kiếm ID lỗi bảo mật trong kho GitHub nếu không có liên kết nào được cung cấp. Chúng tôi tìm thấy các commit sửa lỗi bảo mật cho 698 lỗi bảo mật. Sau đó, chúng tôi lọc thủ công 185 lỗi bảo mật mà các commit sửa lỗi chứa thay đổi không phải Java và 314 lỗi bảo mật không có test case trong các commit sửa lỗi của chúng. Bây giờ chúng tôi có 199 lỗi bảo mật, mỗi lỗi có test case và commit sửa lỗi chỉ Java tương ứng. Sau đó, chúng tôi thành công tái tạo 42 lỗi bảo mật Java không được bao gồm trong Vul4J, sử dụng các công cụ xây dựng như Maven hoặc Gradle.

Chúng tôi kết thúc với một bộ dữ liệu gồm 42 lỗi bảo mật Java thực tế mới có thể tái tạo từ ba mươi dự án mã nguồn mở. Chi tiết, bộ dữ liệu của chúng tôi bao gồm 27 lỗi bảo mật đa hunk từ hai mươi hai dự án và 15 lỗi bảo mật đơn hunk từ mười một dự án. Như Hình 1 cho thấy, 42 lỗi bảo mật này bao gồm tổng cộng 23 loại CWE. Hơn nữa, bộ dữ liệu của chúng tôi giới thiệu 12 loại CWE mới (được ký hiệu bằng * trong Hình 1) không có trong Vul4J và bổ sung bốn loại CWE (CWE-78, CWE-200, CWE-310, CWE-863) mà Vul4J chỉ có một ví dụ.

Bảng 1 mô tả 15 lỗi bảo mật đơn hunk mới thuộc mười hai loại CWE trong benchmark VJBench của chúng tôi. Có sáu loại CWE duy nhất mới không có trong Vul4J. Kết quả là, có 15 lỗi bảo mật từ VJBench và 35 lỗi bảo mật từ Vul4J, tổng cộng 50 lỗi bảo mật mà chúng tôi sử dụng trong nghiên cứu.

3 MÔ HÌNH NGÔN NGỮ LỚN VÀ KỸ THUẬT APR

3.1 Mô hình ngôn ngữ lớn

Chúng tôi chọn năm LLMs, tức là Codex, PLBART, CodeT5, CodeGen và InCoder, vì chúng là (1) hiện đại, (2) có khả năng thực hiện các tác vụ tạo mã mà không cần sửa đổi mô hình hoặc thành phần bổ sung (ví dụ: CodeBERT [26] GraphCodeBERT [33] bị loại trừ), và (3) được huấn luyện với đủ mã nguồn để chúng có thể hiểu mã ở mức độ nào đó (ví dụ: chúng tôi loại trừ T5 [65], GPT-2 [64], GPT-Neo [13] và GPT-J [71], có dữ liệu huấn luyện trên 90% là văn bản). Trong công việc này, chúng tôi nghiên cứu LLMs trong hai cài đặt: như hiện tại và được tinh chỉnh với dữ liệu APR tổng quát.

3.1.1 Mô hình ngôn ngữ lớn như hiện tại. Trong mục này, chúng tôi giới thiệu chi tiết về các LLMs được nghiên cứu và cách sử dụng chúng để sửa lỗi bảo mật. Bảng 3 cung cấp kích thước mô hình và thông tin dữ liệu huấn luyện của chúng.

Codex [17]: Codex là mô hình ngôn ngữ dựa trên GPT-3 [15,17] với 12B tham số được huấn luyện trên cả ngôn ngữ tự nhiên và mã nguồn. Chúng tôi sử dụng mô hình davinci-002 (tính đến tháng 7 năm 2022), được cho là mô hình Codex chính xác nhất [1]. Chúng tôi tập trung vào chế độ chèn của Codex vì nó cung cấp kết quả tốt nhất trong nghiên cứu sơ bộ của chúng tôi trong số ba chế độ chính: hoàn thành, chèn và chỉnh sửa.

CodeT5 [73]: CodeT5 là mô hình transformer encoder-decoder [70] được đào tạo trước với mục tiêu khử nhiễu nhận biết định danh và với các tác vụ tạo sinh lưỡng phương. Nó được huấn luyện trên kho 5,2 triệu hàm mã và 8,3 triệu câu ngôn ngữ tự nhiên từ các kho mã nguồn mở bằng sáu ngôn ngữ lập trình bao gồm Java. Trong công việc này, chúng tôi sử dụng mô hình CodeT5 lớn nhất được phát hành, có 770M tham số.

CodeGen [55]: Các mô hình CodeGen là một loạt các transformer decoder-only tự hồi quy được huấn luyện cho tổng hợp chương trình đối thoại. Dữ liệu huấn luyện của chúng bao gồm 354,7B token ngôn ngữ tự nhiên từ bộ dữ liệu THEPILE và 150,8B token ngôn ngữ lập trình được trích xuất từ một tập con của cơ sở dữ liệu Google BigQuery. Trong công việc này, chúng tôi áp dụng mô hình CodeGen chứa 6B tham số (mô hình lớn hơn với 16B tham số không được sử dụng do hạn chế của máy).

PLBART [8]: PLBART sử dụng kiến trúc transformer encoder-decoder với một lớp chuẩn hóa bổ sung trên encoder và decoder. Nó được đào tạo trước trên các hàm được trích xuất từ các kho GitHub Java và Python thông qua việc khử nhiễu tự động mã hóa. Có hai mô hình PLBART với kích thước khác nhau, và chúng tôi sử dụng mô hình lớn hơn chứa 400M tham số.

InCoder [28]: Các mô hình InCoder tuân theo kiến trúc decoder-only của XGLM [45] và được đào tạo trước trên tác vụ dự đoán span bị che. Dữ liệu đào tạo trước của nó đến từ các dự án mã nguồn mở trên GitHub và GitLab, và các bài đăng StackOverflow. Có hai mô hình InCoder với kích thước khác nhau được phát hành, và chúng tôi sử dụng mô hình lớn hơn chứa 6B tham số.

Định dạng đầu vào: Bảng 2 minh họa định dạng đầu vào chúng tôi sử dụng cho mỗi mô hình. Đối với Codex, chúng tôi áp dụng định dạng đầu vào tương tự như được sử dụng trong công việc trước đây [58]. Prompt bao gồm mã lỗi được comment với từ gợi ý "BUG:" và "FIXED:" để báo hiệu vị trí lỗi và hướng dẫn Codex tạo ra phiên bản mã đã sửa. Nếu số lượng token đầu vào vượt quá số lượng tối đa cho một mô hình, chúng tôi cắt ngắn mã và nhập mã xung quanh các dòng lỗi. Vì không rõ các prompt dòng lỗi được comment sẽ ảnh hưởng đến khả năng sửa lỗi của mô hình như thế nào, chúng tôi thử nghiệm với đầu vào có và không có dòng lỗi được comment cho mỗi mô hình. Hình 2 cho thấy ví dụ về đầu vào và đầu ra mong đợi của Codex với các dòng lỗi được comment bằng /* BUG .. FIXED */.

3.1.2 Mô hình ngôn ngữ lớn được tinh chỉnh. Chúng tôi cũng nghiên cứu khả năng sửa lỗi của LLMs được tinh chỉnh, vì tinh chỉnh là một kỹ thuật phổ biến để thích ứng LLM đã được đào tạo trước cho một tác vụ downstream cụ thể, như tóm tắt mã hoặc dịch mã [26,28,65,73]. Tuy nhiên, do thiếu lỗi bảo mật làm dữ liệu tinh chỉnh, chúng tôi sử dụng các LLMs được tinh chỉnh với dữ liệu APR tổng quát, được chia sẻ bởi công việc hiện có [38]. Công việc trước đây [38] đã tinh chỉnh LLMs với bộ dữ liệu huấn luyện chứa 143.666 thực thể được thu thập từ các dự án GitHub Java mã nguồn mở [76]. Mỗi thực thể dữ liệu là một cặp mã lỗi và mã đã sửa. Chi tiết, [38] đã sử dụng trình tối ưu hóa Adam với tốc độ học 1e-5, đặt kích thước batch là một và tinh chỉnh trong một epoch. Các LLMs được tinh chỉnh được cho là điều chỉnh cho tác vụ sửa lỗi bảo mật ở mức độ nào đó do sự tương tự giữa sửa lỗi bảo mật và sửa lỗi tổng quát. Chúng tôi thực hiện tìm kiếm và xác nhận rằng không có lỗi bảo mật nào chúng tôi nghiên cứu trong công việc này có mặt trong dữ liệu huấn luyện APR được sử dụng để tinh chỉnh LLMs.

Chúng tôi không thể tinh chỉnh Codex, vì nó không cung cấp bất kỳ API tinh chỉnh nào và cũng không có Codex được tinh chỉnh nào có sẵn. Dòng cuối cùng của Bảng 2 mô tả định dạng đầu vào để sử dụng LLMs được tinh chỉnh, trong đó các dòng lỗi được đưa ra dưới dạng các dòng được comment, và toàn bộ hàm được nhập vào các LLMs được tinh chỉnh để tạo ra các dòng đã vá [38].

3.2 Kỹ thuật APR

Chúng tôi chọn bốn kỹ thuật APR dựa trên học tập hiện đại được huấn luyện cho lỗi Java. Các kỹ thuật APR này cần phải là mã nguồn mở để chúng tôi có thể chạy chúng trên các benchmark lỗi bảo mật mới của chúng tôi.

CURE [40] áp dụng mô hình ngôn ngữ nhỏ (được đào tạo trước với 4,04M thực thể mã) cho kiến trúc encoder-decoder của CoCoNuT [47] để học cú pháp mã và đề xuất chiến lược nhận biết mã mới để loại bỏ định danh không hợp lệ và tăng tỷ lệ biên dịch trong quá trình suy luận. CURE được huấn luyện với 2,72M thực thể APR.

Recoder [76] sử dụng mạng học sâu dựa trên cây được huấn luyện trên 82,87K thực thể huấn luyện APR. Nó tập trung vào việc tạo ra các chỉnh sửa để sửa đổi AST lỗi để tạo thành AST đã vá.

RewardRepair [75] bao gồm biên dịch trong tính toán hàm mất mát của mô hình để tăng số lượng bản vá có thể biên dịch (và đúng). Điều này khác với CURE vì hàm mất mát tăng số lượng bản vá có thể biên dịch trong quá trình huấn luyện. Tổng thể, RewardRepair được huấn luyện với 3,51M thực thể APR.

KNOD [39] đề xuất bộ giải mã cây ba giai đoạn mới để tạo ra AST đã vá, và cũng sử dụng chưng cất kiến thức miền để sửa đổi hàm mất mát để các mô hình học cú pháp và ngữ nghĩa mã. KNOD được huấn luyện với 576K thực thể APR, và là kỹ thuật APR dựa trên DL hiện đại.

4 BIẾN ĐỔI MÃ

Để giải quyết thách thức trùng lặp dữ liệu huấn luyện-kiểm tra, chúng tôi cần tạo ra các lỗi bảo mật và bản sửa chưa được thấy bởi các LLMs hoặc kỹ thuật APR hiện có. Chúng tôi tạo ra các lỗi bảo mật chưa thấy bằng cách biến đổi các lỗi bảo mật hiện có thành các dạng tương đương về mặt ngữ nghĩa. Không có mô hình APR và LLMs nào, bao gồm Codex, đã thấy mã lỗi được biến đổi này và các bản sửa tương ứng trong bộ huấn luyện của chúng. Chúng tôi áp dụng hai danh mục biến đổi cho Vul4J và VJBench, được mô tả dưới đây:

(1) Đổi tên định danh: Để ngăn các LLMs và mô hình APR đơn giản ghi nhớ các bản vá đúng chính xác liên quan đến tên định danh, chúng tôi đổi tên định danh trong mã lỗi và mã đã sửa tương ứng. Tất cả các biến, hàm và lớp được định nghĩa trong dự án được đổi tên bằng từ đồng nghĩa cho tên định danh gốc theo đặc tả Java. Chúng tôi sử dụng từ đồng nghĩa để giữ ý nghĩa từ của định danh gốc. Chúng tôi không đổi tên định danh từ thư viện bên ngoài hoặc thư viện lớp Java mặc định, vì người ta thường không thể sửa đổi thư viện bên ngoài. Hình 3 cho thấy ví dụ về đổi tên định danh cho Halo-1.

Chúng tôi trước tiên sử dụng công cụ src2abs [6] để trích xuất tất cả tên biến, hàm và lớp trong hàm lỗi, và lọc ra những định danh từ Java hoặc thư viện bên thứ ba. Chúng tôi token hóa mỗi định danh dựa trên quy ước camel case hoặc snake case, sau đó sử dụng NLTK WordNet [3] để tạo ra từ đồng nghĩa cho mỗi từ. Sau đó, chúng tôi tập hợp lại các từ đồng nghĩa này để tạo thành một định danh hoàn chỉnh. Chúng tôi xem xét thủ công và điều chỉnh từ đồng nghĩa để đảm bảo chúng phù hợp với ngữ cảnh mã. Vì một số kỹ thuật APR cần trích xuất định danh từ toàn bộ dự án, chúng tôi đổi tên các định danh được sử dụng trong hàm lỗi trên toàn bộ dự án.

(2) Thay đổi cấu trúc mã: Chúng tôi định nghĩa sáu quy tắc biến đổi để thay đổi cấu trúc mã.

• Lật điều kiện if: phủ định điều kiện if và hoán đổi các khối mã trong nhánh if và else.
• Biến đổi vòng lặp: chuyển đổi vòng lặp for thành vòng lặp while và ngược lại.
• Biến đổi câu lệnh có điều kiện: chuyển biểu thức ternary (var = cond ? exprTrue: exprFalse;) thành câu lệnh if-else (if (cond) {var = exprTrue;} else {var = exprFalse;}), và biến đổi câu lệnh switch thành nhiều câu lệnh if và elseif, và ngược lại.
• Chuỗi hàm: hợp nhất nhiều lời gọi hàm thành một chuỗi gọi, hoặc ngược lại tách một chuỗi gọi hàm thành các lời gọi hàm riêng biệt. Hình 4 cho thấy ví dụ trong đó value.getClass().equals(...); được tách thành Class value_class = value.getClass(); và value_class.equals(...);.
• Truyền tham số hàm: Nếu một biến hoặc đối tượng được định nghĩa cục bộ chỉ được sử dụng làm tham số hàm, chúng tôi thay thế tham số hàm bằng câu lệnh định nghĩa của nó, hoặc chúng tôi trích xuất lời gọi hàm được truyền làm tham số hàm thành định nghĩa biến/đối tượng riêng biệt. Hình 5 cho thấy ví dụ trong đó tham số parentPath.normalize() được trích xuất và khai báo là đối tượng cục bộ normalizedParentPath.
• Thay đổi thứ tự mã: thay đổi thứ tự các câu lệnh nếu thay đổi thứ tự không ảnh hưởng đến kết quả thực thi. Ví dụ, funcA(); int n =0; có thể được biến đổi thành int n = 0; funcA(); vì việc gọi funcA() và khai báo int n không ảnh hưởng lẫn nhau.

Đối với thay đổi cấu trúc mã, chúng tôi biến đổi thủ công hàm lỗi. Đối với mỗi hàm lỗi, chúng tôi áp dụng tất cả các biến đổi có thể áp dụng cùng một lúc. Chúng tôi tiếp tục xác nhận tính tương đương của lỗi đã biến đổi bằng cách tái tạo chúng bằng cùng một bộ test và áp dụng các bản vá tương đương về mặt ngữ nghĩa để vượt qua các test.

Benchmark mới (VJBench-trans): Tóm lại, để tạo ra lỗi và bản vá mà LLMs chưa thấy trong bộ huấn luyện của chúng, chúng tôi áp dụng ba bộ biến đổi (chỉ đổi tên định danh, chỉ thay đổi cấu trúc mã, và cả hai cùng lúc) cho VJBench và Vul4J, và tạo ra VJBench-trans chứa 3×50 = 150 lỗi bảo mật Java đã biến đổi. Chúng tôi tìm kiếm trên GitHub và Google mã được biến đổi, và không tìm thấy mã công khai nào giống với hàm lỗi đã biến đổi.

Khôi phục bản vá để đánh giá: Mã được biến đổi vẫn thực tế và có thể đọc được bởi con người. Tuy nhiên, để dễ dàng đánh giá tính đúng đắn của các bản vá có thể, chúng tôi duy trì một từ điển lưu trữ ánh xạ giữa các định danh đã đổi tên và tên gốc của chúng. Đối với mỗi lỗi bảo mật, chúng tôi cũng viết một chương trình đã vá cho phiên bản được biến đổi cấu trúc mã, cung cấp tham chiếu cho người dùng bộ dữ liệu trong tương lai.

5 THIẾT LẬP THỰC NGHIỆM

Hình 6 cung cấp tổng quan về nghiên cứu của chúng tôi. Đầu tiên, chúng tôi xây dựng một bộ dữ liệu mới về lỗi bảo mật, VJBench, chứa 42 lỗi bảo mật mới. Chúng tôi sử dụng bộ dữ liệu mới này và bộ dữ liệu gốc (Vul4J) để benchmark khả năng sửa lỗi bảo mật của các kỹ thuật APR dựa trên DL, LLMs và LLMs được tinh chỉnh. Mỗi mô hình ngôn ngữ tạo ra 10 bản vá cho mỗi lỗi thông qua suy luận. Đối với mỗi mô hình APR, chúng tôi sử dụng kích thước tìm kiếm beam mặc định và xác thực 10 bản vá hàng đầu. Các bản vá được tạo ra sau đó được xác thực bằng test case và xác minh thủ công tất cả các bản vá vượt qua test case.

Sau đó, chúng tôi áp dụng các biến đổi mã trên Vul4J và VJBench để tạo ra VJBench-trans. Cuối cùng, chúng tôi đánh giá tác động của các biến đổi mã lên khả năng sửa chữa lỗi bảo mật của tất cả LLMs, LLMs được tinh chỉnh và kỹ thuật APR.

5.1 Bộ dữ liệu

Trong công việc này, chúng tôi tập trung vào việc sửa lỗi bảo mật Java đơn hunk vì các mô hình APR dựa trên DL hiện đại được thiết kế để sửa lỗi đơn hunk. Chúng tôi lọc và có được 35 lỗi đơn hunk từ bộ dữ liệu Vul4J. Cùng với 15 lỗi bảo mật đơn hunk từ VJBench, chúng tôi có tổng cộng 50 lỗi bảo mật Java. Chúng tôi sử dụng định vị lỗi hoàn hảo cho các lỗi bảo mật Java này, tức là chúng tôi sử dụng các dòng mã được sửa đổi trong bản vá của nhà phát triển làm dòng lỗi.

5.2 Thiết lập mô hình ngôn ngữ lớn

Chúng tôi đánh giá mỗi LLM với hai thiết lập đầu vào: (1) các dòng lỗi được comment như một phần của đầu vào và (2) không có dòng lỗi. Chúng tôi quan sát rằng InCoder sửa nhiều lỗi bảo mật hơn khi đầu vào chứa comment dòng lỗi, trong khi các LLMs khác hoạt động tốt hơn khi không có dòng lỗi. Sau đó, chúng tôi báo cáo thiết lập hoạt động tốt nhất cho mỗi mô hình trong phần còn lại của bài báo này. Đối với LLMs được tinh chỉnh, chúng tôi tuân theo định dạng đầu vào với comment dòng lỗi được sử dụng trong [38] được mô tả trong Bảng 2.

Chúng tôi cấu hình mỗi mô hình tạo ra 10 bản vá cho mỗi lỗi bảo mật. Đối với CodeT5, CodeGen, PLBART và InCoder, chúng tôi đặt kích thước tìm kiếm beam của chúng là 10. Đối với Codex, chúng tôi đặt tham số n của nó, số lượng ứng cử viên để tạo ra, là 10. Xem xét tính ngẫu nhiên vốn có của phương pháp lấy mẫu được áp dụng bởi Codex, chúng tôi chạy nó hai mươi lăm lần cho mỗi lỗi bảo mật để có được kết quả trung bình. Chúng tôi chạy hai mươi lăm lần để kiểm soát sai số nhỏ (≤0,3) ở mức độ tin cậy 95%. Chúng tôi đặt nhiệt độ lấy mẫu của Codex là 0,6, được cho là có hiệu suất tốt nhất khi lấy mẫu mười ứng cử viên trong công việc trước [17]. Chúng tôi đặt số lượng tối đa token mới được tạo ra là 400 cho Codex do giới hạn tỷ lệ yêu cầu, và 512 cho tất cả LLMs khác.

5.3 Xác thực bản vá

Chế độ chèn Codex tạo ra mã được chèn giữa prompt tiền tố và prompt hậu tố. Vì chúng tôi sử dụng mã trước và bao gồm comment dòng lỗi làm prompt tiền tố và mã sau comment dòng lỗi làm prompt hậu tố, chúng tôi thay thế mã lỗi gốc bằng mã mà Codex tạo ra. Tương tự, CodeT5 tạo ra mã để thay thế nhãn bị che trong đầu vào của nó. PLBART tạo ra toàn bộ hàm đã vá thay thế toàn bộ hàm lỗi. CodeGen và InCoder là các mô hình hoàn thành tạo ra mã để hoàn thành prompt tiền tố đã cho. Chúng tôi lấy hàm hoàn chỉnh đầu tiên mà CodeGen và InCoder tạo ra để thay thế hàm lỗi gốc. Đối với tất cả LLMs được tinh chỉnh, CodeT5, CodeGen, PLBART và InCoder được tinh chỉnh trực tiếp tạo ra mã đã vá để thay thế mã lỗi.

Đối với mỗi LLM và kỹ thuật APR, chúng tôi trước tiên xác thực 10 bản vá hàng đầu mà chúng tạo ra bằng các test case từ dự án. Theo công việc trước [40,47,75,76], bản vá có thể là bản vá vượt qua tất cả test case, trong khi bản vá đúng là bản vá tương đương về mặt ngữ nghĩa với bản vá nhà phát triển, và bản vá over-fitted là bản vá vượt qua tất cả test case nhưng không chính xác. Chúng tôi kiểm tra thủ công mỗi bản vá có thể để xác định xem nó có phải là bản vá đúng hay không.

6 KẾT QUẢ VÀ PHÁT HIỆN

Chúng tôi đánh giá khả năng sửa lỗi bảo mật của năm LLMs, bốn LLMs được tinh chỉnh và bốn kỹ thuật APR dựa trên DL trên hai benchmark lỗi bảo mật Java thực tế.

6.1 RQ1: Khả năng sửa lỗi bảo mật

Chúng tôi chạy Codex hai mươi lăm lần và báo cáo số lượng lỗi bảo mật đã sửa trung bình với sai số, vì việc tạo bản vá của Codex không xác định. Đối với các LLMs khác, chúng tôi chỉ chạy một lần vì việc tạo bản vá của chúng xác định (Mục 5).

Bảng 4 cho thấy khả năng sửa lỗi, tức là số lượng lỗi bảo mật mà mỗi phương pháp sửa đúng, của năm LLMs, bốn LLMs được tinh chỉnh và bốn mô hình APR. Chúng tôi xem xét 10 bản vá hàng đầu vì một nghiên cứu gần đây cho thấy hầu hết các nhà phát triển chỉ sẵn sàng kiểm tra tối đa mười bản vá [57]. Kết quả trong Bảng 4 được báo cáo dưới dạng X/Y, trong đó X là số lượng lỗi bảo mật được sửa đúng bởi mỗi kỹ thuật và Y là số lượng lỗi bảo mật được sửa có thể. Một lỗi bảo mật được sửa có thể bởi một mô hình nếu mô hình tạo ra một bản vá có thể (định nghĩa trong Mục 5.3).

6.1.1 LLMs so với kỹ thuật APR. Chúng tôi trước tiên so sánh sử dụng LLMs như hiện tại với kỹ thuật APR. Ở đây, LLMs như hiện tại có nghĩa là chúng tôi áp dụng Codex và LLMs dưới học zero-shot và không tinh chỉnh. Kết quả của chúng tôi cho thấy Codex thể hiện khả năng sửa lỗi tốt nhất. Trong tổng số 50 lỗi bảo mật trong Vul4J và VJBench, Codex sửa trung bình 10,2 lỗi bảo mật với sai số 0,3 (ở mức độ tin cậy 95%). InCoder thể hiện khả năng tốt thứ hai, sửa 5 lỗi bảo mật. Các LLMs khác và kỹ thuật APR dựa trên DL chỉ sửa rất ít lỗi bảo mật. Tổng thể, LLMs và kỹ thuật APR cho thấy khả năng sửa lỗi bảo mật rất hạn chế.

Phát hiện của chúng tôi rằng Codex hoạt động tốt nhất trong việc sửa lỗi bảo mật Java phù hợp với hiệu suất vượt trội của Codex trong việc sửa lỗi tổng quát [74] và trong các lĩnh vực khác [1,17,27,58], có thể do kích thước mô hình và kích thước dữ liệu huấn luyện lớn hơn đáng kể như được chỉ ra trong Bảng 3. Kết quả của chúng tôi cũng phù hợp với công việc gần đây [38] trong việc cho thấy LLMs không tinh chỉnh có khả năng sửa lỗi cạnh tranh – InCoder sửa thêm ba lỗi bảo mật so với kỹ thuật APR tốt nhất (RewardRepair). Tuy nhiên, trong khi [38] cho thấy CodeGen, PLBART và InCoder như hiện tại có thể sửa 18%-23% lỗi tổng quát Java của benchmark APR, kết quả của chúng tôi cho thấy chúng chỉ có thể sửa 4%(2/50)-10%(5/50) lỗi bảo mật của Vul4J và VJBench. Trong thực tế, chỉ có khoảng 1~7% lỗi là lỗi bảo mật, dẫn đến ít dữ liệu cho các mô hình học từ đó. Điều này có nghĩa là, đối với mạng neural, việc sửa lỗi bảo mật khó hơn so với lỗi tổng quát và cần nhiều kiến thức chuyên môn hơn.

Phát hiện 1: Các mô hình ngôn ngữ lớn và kỹ thuật APR hiện tại sửa rất ít lỗi bảo mật Java. Codex sửa 10,2 (20,4%) lỗi bảo mật trung bình, thể hiện khả năng sửa lỗi tốt nhất.

6.1.2 LLMs được tinh chỉnh với dữ liệu APR. Chúng tôi áp dụng LLMs được tinh chỉnh với dữ liệu APR tổng quát bởi [38] trên các benchmark lỗi bảo mật. Chúng tôi không thể tinh chỉnh Codex vì OpenAI không cung cấp API công khai để tinh chỉnh. Bảng 4 cho thấy tất cả LLMs được tinh chỉnh sửa nhiều lỗi bảo mật hơn các mô hình gốc của chúng. Chi tiết, InCoder được tinh chỉnh sửa 9 lỗi bảo mật, nhiều hơn 4 so với mô hình gốc của nó. Mô hình tốt thứ hai là CodeGen được tinh chỉnh, sửa 8 lỗi bảo mật, nhiều hơn 6 so với mô hình gốc. CodeT5 và PLBART được tinh chỉnh mỗi cái sửa thêm 3 và 2 lỗi bảo mật.

Tổng thể, việc tinh chỉnh với dữ liệu APR tổng quát có thể cải thiện khả năng sửa lỗi của LLMs đối với lỗi bảo mật. Đầu tiên, tinh chỉnh có thể thích ứng LLMs với các tác vụ APR tốt hơn, làm cho LLMs nhận biết việc tạo ra bản vá thay vì mã hoặc văn bản mở. Thứ hai, mặc dù lỗi bảo mật có đặc điểm đặc biệt (nguyên nhân gốc) so với lỗi tổng quát, một số lỗi bảo mật vẫn chia sẻ các mẫu sửa chữa tương tự với lỗi tổng quát, như thay thế tham số hàm bằng biến khác, có thể được học tốt trong quá trình tinh chỉnh. Với sự khan hiếm dữ liệu lỗi bảo mật thực tế, kết quả của chúng tôi hàm ý rằng việc tinh chỉnh LLMs với dữ liệu APR tổng quát có thể có lợi.

Phát hiện 2: Tinh chỉnh với dữ liệu APR tổng quát cải thiện khả năng sửa lỗi bảo mật của tất cả bốn LLMs. InCoder được tinh chỉnh sửa 9 lỗi bảo mật, thể hiện khả năng sửa lỗi cạnh tranh so với Codex.

Chúng tôi cũng đánh giá tỷ lệ biên dịch (tức là tỷ lệ bản vá được tạo ra có thể biên dịch) để nghiên cứu chất lượng của các bản vá. Bản vá không thể biên dịch không thể là bản vá đúng. Codex, mô hình tốt nhất tổng thể, có tỷ lệ biên dịch 79,7%, cao hơn đáng kể so với LLM được tinh chỉnh tốt nhất, InCoder được tinh chỉnh (55,2%) và mô hình APR tốt nhất, Recoder (57,6%). Tinh chỉnh cải thiện đáng kể tỷ lệ biên dịch của CodeT5 và CodeGen, từ 6,4% lên 46,8% và từ 35,8% lên 47,2% tương ứng. Mặt khác, tỷ lệ biên dịch của PLBART được tinh chỉnh là 45,2%, thấp hơn một chút so với tỷ lệ biên dịch 47,8% của PLBART gốc. Mặc dù tỷ lệ biên dịch 65,2% cao hơn của InCoder so với mô hình được tinh chỉnh của nó, nó tạo ra 82,0% bản vá trùng lặp, trong khi InCoder được tinh chỉnh tạo ra các bản vá với các sửa đổi đa dạng hơn dẫn đến nhiều bản sửa đúng hơn. Tổng thể, so với tỷ lệ biên dịch của việc sửa lỗi tổng quát [38], các tỷ lệ biên dịch này của việc sửa lỗi bảo mật thấp hơn. PLBART, CodeGen và InCoder không tinh chỉnh khi sửa lỗi tổng quát cho thấy tỷ lệ biên dịch trung bình 65%–73% [38], vượt trội hơn cả mô hình gốc và được tinh chỉnh của chúng khi sửa lỗi bảo mật.

Hình 7a cho thấy ví dụ về bản vá không thể biên dịch của Vul4J-12: Chữ ký hàm khai báo t là final, do đó giá trị của t không được phép thay đổi. Tuy nhiên, Codex không thể nắm bắt ràng buộc này, mặc dù chữ ký hàm chỉ cách dòng lỗi hai dòng. Kết quả là, nó tạo ra mã t-- để giảm giá trị của t khiến bản vá không thể biên dịch. Tương tự, RewardR bỏ qua thực tế rằng v và vt đều có kiểu int, và gọi hàm không hợp lệ equals trên chúng. Hình 7b cho thấy ví dụ khác về bản vá không thể biên dịch cho Vul4J-1: parseArray là một phương thức được định nghĩa trong lớp khác trong dự án chỉ chấp nhận hai hoặc ba tham số. Tất cả bốn LLMs được tinh chỉnh tạo ra cùng một bản vá không thể biên dịch trong đó chúng truyền null làm tham số thứ tư, vì chúng không có thông tin rằng parseArray không chấp nhận bốn tham số.

Các kết quả này cho thấy khả năng học cú pháp mã của LLMs có thể được cải thiện. Công việc gần đây [40,76] là các bước theo hướng đúng để thêm kiến thức miền vào mô hình để giúp chúng học cú pháp và ngữ nghĩa mã. Hướng khác là kỹ thuật prompt, như cung cấp chữ ký phương thức hoặc thông tin kiểu trong prompt để chỉ định các ràng buộc. Điều này sẽ cho phép LLMs sử dụng thông tin cú pháp từ toàn bộ dự án, thay vì bị hạn chế trong mã trong hàm lỗi.

Phát hiện 3: Codex có tỷ lệ biên dịch cao nhất là 79,7%. Các LLMs khác (được tinh chỉnh hoặc không) và kỹ thuật APR có tỷ lệ biên dịch thấp (thấp nhất là 6,4% với CodeT5 và phần còn lại từ 24,5% đến 65,2%), cho thấy thiếu kiến thức về miền cú pháp.

6.2 RQ2: LLMs và kỹ thuật APR dựa trên học tập sửa loại lỗi bảo mật nào?

Bảng 5 cho thấy các lỗi bảo mật được sửa đúng bởi các LLMs, LLMs được tinh chỉnh và kỹ thuật APR. Tổng cộng, 16 lỗi bảo mật (thuộc mười danh mục CWE như được hiển thị trong cột CWE với mô tả trong cột Description) từ cả hai benchmark được sửa bởi ít nhất một trong các mô hình. ID của các lỗi bảo mật này được liệt kê dưới cột Vul. ID. Một số lỗi bảo mật thuộc không có danh mục CWE cụ thể và được liệt kê là unk.

Vul4J-47 là lỗi bảo mật chỉ có Codex có thể sửa. Hình 8a cho thấy bản vá nhà phát triển cho Vul4J-47 loại CWE-611 (Hạn chế không đúng của tham chiếu thực thể bên ngoài XML) và CWE-918 (Giả mạo yêu cầu phía máy chủ). Bản sửa đúng yêu cầu chèn câu lệnh xmlIn.setProperty(XMLInputFactory.SUPPORT_DTD, Boolean.FALSE) để vô hiệu hóa hỗ trợ Document Type Definition (DTD), vì DTD có thể được sử dụng để thực hiện các cuộc tấn công giả mạo yêu cầu phía máy chủ (SSRF). Mã lỗi gốc chỉ vô hiệu hóa hỗ trợ cho các thực thể bên ngoài bằng cách đặt thuộc tính IS_SUPPORTING_EXTERNAL_ENTITIES thành false, không đủ để ngăn chặn cuộc tấn công. Hình 8b cho thấy bản vá không chính xác được tạo ra bởi CodeGen được tinh chỉnh, thay thế Boolean.FALSE bằng Boolean.TRUE. Nói chung, ngoại trừ Codex, các LLMs khác và LLMs được tinh chỉnh chỉ sửa các lỗi bảo mật cần sửa đổi đơn giản như xóa câu lệnh hoặc thay thế tên biến/phương thức.

Mặt khác, Codex sửa 15 trong số 16 lỗi bảo mật (hợp của tất cả lỗi, mà Codex tạo ra ít nhất một bản vá đúng trong hai mười lăm lần chạy). Một lỗi bảo mật được sửa bởi các LLMs khác nhưng không phải Codex là Vul4J-39 loại CWE-200 (Tiết lộ thông tin nhạy cảm cho tác nhân không được ủy quyền). Lỗi bảo mật này có thể được sửa bằng cách đơn giản xóa toàn bộ mã lỗi. Tuy nhiên, đối với Vul4J-39, Codex tạo ra bản vá bằng cách áp dụng các sửa đổi khác nhau cho mã lỗi, thay vì xóa nó.

Ratpack-1, Vul4J-12, Vul4J-39 và Jenkins-2 là bốn lỗi bảo mật được sửa bởi số lượng nhiều nhất (6-7 trong số 13) mô hình. Ratpack-1 (Hình 9) khi khởi tạo DefaultHttpHeaders, đặt tham số constructor thành false, vô hiệu hóa xác thực cho các giá trị header do người dùng cung cấp. Bản vá đúng chỉ đơn giản loại bỏ false hoặc thay đổi nó thành true để cho phép xác thực. Bản sửa cho Vul4J-12 (Hình 7a) là thay đổi từ khóa while thành if, và bản sửa cho cả Jenkins-2 và Vul4J-39 là đơn giản xóa một câu lệnh if tiết lộ thông tin nhạy cảm cho các tác nhân không được ủy quyền. Sự đơn giản của các bản vá này rõ ràng từ số lượng mô hình có thể sửa chúng.

Phát hiện 4: Các mô hình ngôn ngữ lớn và kỹ thuật APR, ngoại trừ Codex, chỉ sửa các lỗi bảo mật cần thay đổi đơn giản, như xóa câu lệnh hoặc thay thế tên biến/phương thức.

Đáng ngạc nhiên, chín LLMs và bốn kỹ thuật APR không sửa được bất kỳ loại CWE mới nào trong sáu loại mà VJBench thêm vào, cho thấy VJBench của chúng tôi giúp tiết lộ các hạn chế của LLMs và kỹ thuật APR hiện có trong việc sửa lỗi bảo mật Java. Điều này kêu gọi các kỹ thuật mới có thể sửa CWE-172, CWE-325, CWE-347, CWE-444, CWE-668, và CWE-1295. Ngoài ra, đối với CWE-611 được bao gồm bởi Vul4J-47 của Vul4J, chúng tôi thêm hai thực thể của loại CWE này (Quartz-1 và Retrofit-1) trong VJBench. Codex sửa Vul4J-47, nhưng không có LLMs và kỹ thuật APR nào sửa thêm Quartz-1 và Retrofit-1. Điều này cho thấy VJBench bổ sung cho Vul4J ngay cả trên các danh mục CWE mà Vul4J đã bao gồm.

Hình 10 cho thấy Retrofit-1 thuộc danh mục CWE-611. Không có mô hình nào sửa Retrofit-1. Bản vá đúng là ngăn chặn các cuộc tấn công XML External Entity bằng cách gọi xmlInputFactory.setProperty(...) để vô hiệu hóa hỗ trợ cho các thực thể bên ngoài và DTD. Nhưng vì LLMs không được cung cấp thông tin rằng lỗi bảo mật liên quan đến các cuộc tấn công XML External Entity (như được gợi ý bởi loại CWE), chúng chỉ thực hiện các thay đổi trên mã lỗi (Hình 10b) không liên quan đến các thuộc tính XML. Hình 11 cho thấy Jenkins-1 thuộc CWE-325 (Thiếu bước mã hóa), một danh mục CWE mới mà VJBench thêm vào. Bản sửa đúng cho lỗi là thêm điều kiện if để kiểm tra quyền trước vòng lặp for để hạn chế truy cập vào NodeMonitor. Như bản vá của Codex được hiển thị trong Hình 11, tất cả các mô hình đều không thể sửa lỗi vì chúng chỉ áp dụng các sửa đổi chung cho vòng lặp for và không nhận biết rằng lỗi liên quan đến hạn chế quyền. Hơn nữa, phương thức hasPermission và biến CONNECT được khai báo bên ngoài hàm lỗi, do đó các mô hình không có kiến thức về cách sử dụng của chúng. Điều này phản ánh hai vấn đề đối với LLMs trong việc sửa lỗi bảo mật Java: (1) Chỉ với các dòng lỗi được chỉ ra, LLMs không thể tạo ra bản vá nhắm mục tiêu lỗi bảo mật. Điều này cho thấy rằng cần thiết phải cung cấp cho LLMs thêm thông tin về lỗi bảo mật, như loại CWE. (2) Cần thêm thông tin cụ thể về dự án cho LLMs để sửa lỗi bảo mật, tức là cung cấp cho LLMs các phương thức và biến liên quan được khai báo bên ngoài hàm lỗi.

Phát hiện 5: Benchmark VJBench mới của chúng tôi tiết lộ rằng các mô hình ngôn ngữ lớn và kỹ thuật APR không thể sửa nhiều loại CWE, bao gồm CWE-172 (Lỗi mã hóa), CWE-325 (Thiếu bước mã hóa), CWE-444 (Buôn lậu yêu cầu HTTP), CWE-668 (Tiết lộ tài nguyên cho phạm vi sai), và CWE-1295 (Thông báo debug tiết lộ thông tin không cần thiết).

6.3 RQ3: Khả năng sửa lỗi trên lỗi bảo mật đã biến đổi

Để giảm thiểu mối đe dọa trùng lặp dữ liệu huấn luyện-kiểm tra, chúng tôi áp dụng các biến đổi mã lên benchmark để nghiên cứu khả năng tổng quát hóa của Codex và LLMs trên dữ liệu chưa thấy (Mục 4). Bảng 6 cho thấy số lượng lỗi bảo mật mà LLMs như hiện tại, LLMs được tinh chỉnh, và kỹ thuật APR có thể sửa trong bốn cài đặt: (1) Không biến đổi—bộ dữ liệu lỗi bảo mật gốc, (2) Chỉ đổi tên—chỉ áp dụng đổi tên định danh, (3) Chỉ thay đổi cấu trúc mã—chỉ áp dụng thay đổi cấu trúc mã, và (4) Đổi tên + thay đổi cấu trúc mã—áp dụng cả hai biến đổi.

Tổng thể, các biến đổi mã khiến LLMs (được tinh chỉnh hoặc không) và kỹ thuật APR sửa ít lỗi bảo mật hơn. Ví dụ, InCoder được tinh chỉnh sửa chín lỗi bảo mật trong Vul4J và VJBench (không biến đổi), nhưng chỉ sửa bốn lỗi bảo mật được biến đổi hoàn toàn (Đổi tên + thay đổi cấu trúc mã). Tác động của biến đổi nhỏ hơn đối với một số mô hình, ví dụ: Codex và CodeT5 được tinh chỉnh, thể hiện sự mạnh mẽ của các mô hình này đối với các biến đổi mã và khả năng học tập tổng quát hóa. Kết quả này, ở mức độ nào đó, giải quyết mối đe dọa của dữ liệu huấn luyện không công khai của Codex và tiết lộ khả năng học tập và sửa lỗi bảo mật mạnh mẽ của Codex. Nhiều mô hình chỉ sửa hai hoặc ít lỗi bảo mật hơn mà không có biến đổi, do đó tác động của biến đổi không thể lớn đối với các mô hình này. Tuy nhiên, chúng tôi thấy xu hướng chung trên hầu hết tất cả các mô hình rằng các biến đổi mã này khiến các mô hình sửa ít lỗi bảo mật hơn.

Hình 12a cho thấy ví dụ, Halo-1, có bản sửa đúng là gọi normalize() trên pathToCheck để loại bỏ bất kỳ phần tử dư thừa nào trong đường dẫn tệp. Lỗi này có thể được sửa đúng bởi Codex, CodeGen được tinh chỉnh, và InCoder được tinh chỉnh. Tuy nhiên, sau khi áp dụng cả hai biến đổi, chỉ có Codex có thể sửa nó (Hình 12b).

Các biến đổi khác nhau có tác động khác nhau nhưng mỗi biến đổi ảnh hưởng đáng kể đến ít nhất một LLM. Ví dụ, mặc dù đổi tên định danh có tác động nhỏ đối với CodeT5 được tinh chỉnh, nó giảm số lượng lỗi bảo mật mà PLBART được tinh chỉnh sửa ba lỗi. Kết quả cho thấy biến đổi mã của chúng tôi kiểm tra hiệu quả khả năng tổng quát hóa của LLMs trên dữ liệu chưa thấy.

Một quan sát thú vị là một số mô hình sửa các lỗi bảo mật đã biến đổi mà chúng không thể sửa trong bộ dữ liệu gốc. Đây là hiện tượng hợp lý vì biến đổi của chúng tôi có thể chuyển đổi đoạn mã thành dạng đơn giản hơn cho các mô hình sửa. Ví dụ, Vul4J-30 là lỗi mà không có mô hình nào sửa trong dạng gốc, nhưng phiên bản được biến đổi của nó được sửa bởi tất cả bốn LLMs được tinh chỉnh khi áp dụng biến đổi cấu trúc mã. Hình 13 cho thấy bản sửa của Vul4J-30 là gọi trim() trên String.valueOf(value). Lỗi bảo mật gốc khó sửa vì String.valueOf(value) là một phần của điều kiện if phức tạp. Tuy nhiên, sau khi biến đổi mã, String.valueOf(value) nổi bật như một câu lệnh đơn, dễ dàng hơn cho LLMs sửa chữa. Hiện tượng này cho thấy biến đổi mã tương đương có thể là hướng hứa hẹn để đơn giản hóa mã dễ bị tổn thương và tăng cường hiệu quả của việc sửa lỗi bảo mật.

Phát hiện 6: Các biến đổi mã khiến các mô hình ngôn ngữ lớn và kỹ thuật APR sửa ít lỗi bảo mật hơn. Một số mô hình như Codex và CodeT5 được tinh chỉnh mạnh mẽ hơn đối với các biến đổi mã. Mặt khác, một số biến đổi làm cho lỗi bảo mật dễ sửa hơn.

7 MỐI ĐE DỌA ĐỐI VỚI TÍNH HỢP LỆ

Lỗi bảo mật Java rất đa dạng. Khó để các benchmark đại diện cho tất cả chúng. Do đó, các phát hiện của chúng tôi có thể không tổng quát hóa cho tất cả lỗi bảo mật Java. Chúng tôi giải quyết mối đe dọa này bằng cách mở rộng benchmark lỗi bảo mật Java hiện có với bộ dữ liệu mới về lỗi bảo mật.

Chúng tôi dựa vào các bản vá của nhà phát triển để đánh giá xem một lỗi bảo mật có được sửa hay không. Các nhà phát triển có thể mắc lỗi trong việc sửa lỗi bảo mật. Do đó, sự thật cơ bản của chúng tôi có thể không chính xác. Chúng tôi giảm thiểu mối đe dọa này bằng cách chỉ xem xét các lỗi bảo mật được công bố công khai trong bộ dữ liệu NVD có thể tái tạo và bao gồm các test case chỉ ra rằng phiên bản đã sửa không còn có thể khai thác.

Một mối đe dọa khác là Codex (và các LLMs khác) có thể đã được huấn luyện trên các bản vá lỗi bảo mật trong bộ dữ liệu Vul4J và VJBench. Để giảm thiểu vấn đề này, chúng tôi áp dụng các biến đổi mã để tạo ra các lỗi bảo mật tương đương về mặt ngữ nghĩa không được bao gồm trong bộ dữ liệu huấn luyện của chúng. Sau đó, chúng tôi áp dụng Codex để sửa chữa các chương trình được biến đổi này để chứng minh rằng Codex thực sự có thể sửa chữa các lỗi bảo mật mới mà nó chưa thấy.

8 CÔNG VIỆC LIÊN QUAN

8.1 Kỹ thuật sửa lỗi bảo mật dựa trên DL

Nhiều công việc sử dụng DL để sửa lỗi bảo mật. Các phương pháp encoder-decoder đã được đề xuất để sửa chữa lỗi bảo mật C: [29] đã tinh chỉnh mô hình CodeT5 với dữ liệu sửa chữa lỗi bảo mật C; [19] đã huấn luyện mô hình transformer trên bộ dữ liệu sửa lỗi lớn và sau đó tinh chỉnh trên bộ dữ liệu sửa lỗi bảo mật nhỏ, nhưng họ sử dụng độ chính xác chuỗi làm chỉ số đánh giá thay vì cài đặt APR thực tế. Công việc trước đây [35] đã áp dụng cả CodeBERT và GraphCodeBert để sửa lỗi bảo mật, nhưng họ chỉ đánh giá trên cơ sở dữ liệu lỗi bảo mật tổng hợp, bộ test Juliet 1.1 C/C++ [14], là benchmark để đánh giá chỉ các trình phân tích tĩnh. Kết quả là, các lỗi bảo mật trong bộ dữ liệu được cô lập và đơn giản hóa để phù hợp trong vài dòng và không đại diện cho lỗi bảo mật mã trong sản xuất. Công việc của chúng tôi khác vì chúng tôi sử dụng bộ dữ liệu lỗi bảo mật thực tế để đánh giá, làm cho kết quả của chúng tôi gần hơn với những gì các nhà nghiên cứu và nhà phát triển có thể mong đợi về chất lượng của việc sửa chữa lỗi bảo mật LLM trong mã sản xuất thực tế.

Công việc trước đây [58] đã áp dụng LLMs với học zero-shot để sửa chữa bảy lỗi bảo mật C/Python được tạo thủ công và 12 lỗi bảo mật C thực tế. Họ đã khám phá tính hiệu quả của các mẫu prompt khác nhau và sử dụng công cụ phân tích tĩnh CodeQL hoặc các sanitizer C để phát hiện lỗi bảo mật nhằm tích hợp các thông báo lỗi thu được vào prompt đầu vào. Công việc của chúng tôi khác với [58] ở một số khía cạnh chính. Đầu tiên, chúng tôi nghiên cứu không chỉ LLMs mà còn công cụ APR dựa trên DL và LLMs được tinh chỉnh với dữ liệu APR tổng quát. Thứ hai, chúng tôi đánh giá phương pháp của mình trên bộ dữ liệu lớn hơn gồm 50 lỗi bảo mật Java thực tế. Thứ ba, chúng tôi áp dụng các biến đổi mã để giảm thiểu vấn đề rò rỉ dữ liệu và đề xuất hướng mới sử dụng biến đổi để đơn giản hóa việc sửa chữa cho một số lỗi bảo mật. Hầu hết lỗi bảo mật trong Vul4J và VJBench không thể được phát hiện bởi các công cụ phân tích bảo mật Java hiện đại, vì vậy chúng tôi không thể tích hợp các thông báo lỗi trong prompt đầu vào như [58] đã làm.

8.2 Benchmark lỗi bảo mật

Công việc trước đây đã đề xuất các benchmark và bộ dữ liệu để giúp đánh giá các phương pháp sửa lỗi bảo mật. Maestro [61] đề xuất một nền tảng để benchmark các công cụ trên lỗi bảo mật Java và C++. Vì Maestro không hỗ trợ chạy LLMs và mô hình APR, chúng tôi trực tiếp sử dụng cùng bộ dữ liệu lỗi bảo mật Java, Vul4J [16], với bộ dữ liệu mới VJBench của chúng tôi. Các benchmark và bộ dữ liệu khác về lỗi bảo mật thực tế đã được đề xuất [12,24,56,62]. Tuy nhiên, các bộ dữ liệu này chỉ chứa các đoạn mã từ các commit sửa lỗi và không có test case. Do đó, các bộ dữ liệu như vậy chỉ có thể hỗ trợ khớp mã khi đánh giá tính đúng đắn của bản vá, và không thể được sử dụng trong sửa chữa chương trình tự động trong thực tế.

8.3 LLMs cho sửa chữa và các tác vụ khác

Các nhà nghiên cứu sử dụng LLMs để cải thiện nhiều tác vụ kỹ thuật phần mềm như sửa chữa chương trình tự động [40,50,63], gợi ý tự động hoàn thành [25], và lập trình cặp [37]. Nhiều công việc cũng thảo luận về hàm ý của LLMs đối với các nhà phát triển phần mềm [23,27,51] và các hạn chế hiện tại của LLMs [9,20,68]. Công việc của chúng tôi khám phá một lĩnh vực ứng dụng khác của LLMs, với những thách thức riêng (lỗi bảo mật nổi tiếng khó sửa [52]) chưa được khám phá tốt.

9 KẾT LUẬN

Công việc này là nghiên cứu đầu tiên về khả năng sửa chữa lỗi bảo mật trong Java của LLMs và mô hình APR dựa trên DL. Chúng tôi đánh giá năm LLMs, bốn LLMs được tinh chỉnh, và bốn kỹ thuật APR dựa trên DL trên hai benchmark lỗi bảo mật Java thực tế bao gồm một benchmark mới mà chúng tôi tạo ra. Chúng tôi sử dụng các biến đổi mã để giải quyết mối đe dọa trùng lặp dữ liệu huấn luyện và kiểm tra của LLMs và tạo ra benchmark sửa chữa lỗi bảo mật Java mới VJBench, và phiên bản được biến đổi VJBench-trans. Chúng tôi phát hiện rằng các LLMs và mô hình APR hiện tại sửa rất ít lỗi bảo mật Java, và kêu gọi các đổi mới nghiên cứu mới để cải thiện sửa chữa lỗi bảo mật Java tự động như tạo ra bộ dữ liệu huấn luyện sửa chữa lỗi bảo mật lớn hơn, tinh chỉnh LLMs với dữ liệu như vậy, khám phá học few-shot, và tận dụng các biến đổi đơn giản hóa để cải thiện sửa chữa chương trình.

Gói tái tạo: Benchmark và artifacts của chúng tôi có sẵn tại [5].

LỜI CẢM ƠN

Chúng tôi cảm ơn các nhà phản biện vì những nhận xét và đề xuất sâu sắc. Công việc này được tài trợ một phần bởi NSF 1901242, NSF 2006688, Giải thưởng nghiên cứu khoa học AI J.P. Morgan, và Giải thưởng nghiên cứu Meta/Facebook. Bất kỳ ý kiến, phát hiện và kết luận nào trong bài báo này chỉ là của các tác giả và không nhất thiết phản ánh quan điểm của các nhà tài trợ.

TÀI LIỆU THAM KHẢO

[1] 2022. Codex. https://beta.openai.com/docs/guides/code
[2] Truy cập: 2022. Hướng dẫn ngăn chặn, phát hiện và săn lùng việc khai thác lỗi bảo mật Log4j 2. https://www.microsoft.com/en-us/security/blog/2021/12/11/guidance-for-preventing-detecting-and-hunting-for-cve-2021-44228-log4j-2-exploitation/.
[3] Truy cập: 2023. Tài liệu NLTK. https://www.nltk.org/howto/wordnet.html.
[4] Truy cập: 2023. Nguồn cấp dữ liệu NVD. https://nvd.nist.gov/vuln/data-feeds.
[5] Truy cập: 2023. Gói tái tạo của công việc này. https://github.com/lin-tan/llm-vul.
[6] Truy cập: 2023. Kho GitHub src2abs. https://github.com/micheletufano/src2abs.
[7] Truy cập: 2023. Hiểu tác động của lỗi bảo mật Apache Log4j. https://security.googleblog.com/2021/12/understanding-impact-of-apache-log4j.html.
[8] Wasi Ahmad, Saikat Chakraborty, Baishakhi Ray, và Kai-Wei Chang. 2021. Mô hình encoder-decoder được đào tạo trước thống nhất nhận biết định danh cho hiểu và tạo mã. Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics, Online, 2655–2668. https://doi.org/10.18653/v1/2021.naacl-main.211

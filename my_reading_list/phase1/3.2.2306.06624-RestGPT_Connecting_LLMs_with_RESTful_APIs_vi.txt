# 2306.06624.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2306.06624.pdf
# Kích thước file: 892474 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
RestGPT: Kết nối Mô hình Ngôn ngữ Lớn
với các API RESTful Thế giới Thực
Yifan Song1, Weimin Xiong1, Dawei Zhu1, Wenhao Wu1, Han Qian2, Mingbo Song2
Hailiang Huang2,Cheng Li3,Ke Wang3,Rong Yao3,Ye Tian3,Sujian Li1∗
1Khoa Khoa học Máy tính, Đại học Bắc Kinh
2Khoa Kỹ thuật Điện tử và Khoa học Máy tính, Đại học Bắc Kinh
3Huawei Technologies
{yfsong, lisujian}@pku.edu.cn
https://restgpt.github.io

Tóm tắt
Các mô hình ngôn ngữ lớn (LLM) được tăng cường bằng công cụ đã đạt được tiến bộ đáng kể trong việc giải quyết một loạt rộng các nhiệm vụ. Tuy nhiên, các phương pháp hiện tại chủ yếu bị hạn chế với các công cụ được thiết kế đặc biệt và không thể hoàn thành các chỉ dẫn phức tạp, có những hạn chế lớn khi đối mặt với các tình huống thế giới thực. Trong bài báo này, chúng tôi khám phá một tình huống thực tế hơn bằng cách kết nối LLM với các API RESTful, tuân theo kiểu kiến trúc phần mềm REST được áp dụng rộng rãi cho phát triển dịch vụ web. Để giải quyết những thách thức thực tế của việc xử lý các chỉ dẫn phức tạp, chúng tôi đề xuất RestGPT, khai thác sức mạnh của LLM và thực hiện cơ chế lập kế hoạch trực tuyến từ thô đến tinh để tăng cường khả năng phân tách nhiệm vụ và lựa chọn API. RestGPT cũng chứa một trình thực thi API được thiết kế riêng để gọi các API RESTful, có thể tỉ mỉ xây dựng tham số và phân tích phản hồi API. Để đánh giá đầy đủ hiệu suất của RestGPT, chúng tôi đề xuất RestBench, một benchmark chất lượng cao bao gồm hai tình huống thế giới thực và các chỉ dẫn được chú thích bởi con người với đường dẫn giải pháp vàng. Các thí nghiệm cho thấy RestGPT có thể đạt được kết quả ấn tượng trong các nhiệm vụ phức tạp và có độ bền vững mạnh, mở ra con đường mới hướng tới AGI.

1 Giới thiệu
Các mô hình ngôn ngữ lớn (LLM), như GPT-3 [1] và ChatGPT [2], đã thể hiện nhiều khả năng mới nổi, bao gồm học trong ngữ cảnh [1,3], lý luận [4,5], và lập kế hoạch từng bước [6,7]. Trong việc theo đuổi thúc đẩy khả năng của LLM cho các ứng dụng thực tế, một hướng nghiên cứu đang diễn ra là điều tra việc kết hợp các công cụ/API bên ngoài để tăng cường chức năng của LLM [8,9,10,11]. Nỗ lực này đã mang lại sự tích hợp thành công của các công cụ đa dạng, bao gồm công cụ tìm kiếm và các mô hình nền tảng khác, với LLM [12, 13, 14].

Mặc dù có những tiến bộ đáng kể, chúng tôi thấy rằng các LLM được tăng cường API hiện tại vẫn đang trong giai đoạn thử nghiệm và chưa đáp ứng đầy đủ nhu cầu của các chỉ dẫn người dùng thế giới thực. Như thể hiện trong Bảng 1, các phương pháp hiện tại bị hạn chế kết nối với một số lượng nhỏ các công cụ/API được thiết kế đặc biệt [11,12,15]. Ví dụ, Chameleon [12] thiết kế một bộ 15 công cụ, như trình diễn bảng và trình mô tả hình ảnh. Ngoài ra, việc thiếu đặc tả thiết kế API chuẩn hóa cản trở khả năng mở rộng của những nỗ lực trước đây. Do đó, tiềm năng kết nối LLM với một loạt đa dạng các API thế giới thực, như các API RESTful, vẫn chưa được khám phá và đầy thách thức. Hơn nữa, khi xử lý một chỉ dẫn phức tạp trong tình huống thực, cần thiết phải phân tách nó thành các nhiệm vụ con nhỏ hơn và hoàn thành chúng bằng cách sử dụng hỗn hợp các API khác nhau. Kết quả là, việc LLM được tăng cường API có khả năng lập kế hoạch và ra quyết định mạnh mẽ để giải quyết hiệu quả các nhiệm vụ thế giới thực trở nên cần thiết [9]. Tuy nhiên, các kỹ thuật hiện tại, dù là các phương pháp nội quan tĩnh lập kế hoạch-sau đó-thực thi [9,13,12] hay khung ReAct [16], đều gặp thách thức trong việc thích ứng hiệu quả với phản hồi API và tạo ra các kế hoạch khả thi.

Trong nghiên cứu này, chúng tôi đi sâu vào một tình huống thực tế hơn bằng cách kết nối LLM với các API RESTful thế giới thực, nhằm hoàn thành các chỉ dẫn người dùng thực tế. RESTful là tiêu chuẩn de facto cho phát triển dịch vụ web [17], sử dụng các phương thức HTTP (ví dụ: GET, POST) và URI để thao tác tài nguyên. Phát triển API RESTful thường tuân theo Đặc tả OpenAPI (OAS) [18], mô tả các hoạt động, tham số, và lược đồ phản hồi của mỗi điểm cuối API. Do đó, khung kết quả của chúng tôi có thể kết nối với bất kỳ ứng dụng RESTful nào và cung cấp quy trình phát triển API chuẩn hóa, từ đó cho phép khả năng mở rộng tăng cường so với các phương pháp trước đây.

Tuy nhiên, việc kết nối LLM với các API RESTful cũng mang lại những thách thức thực tế. Thứ nhất, việc gọi các API thế giới thực có thể dẫn đến vô số tình huống không lường trước được, đòi hỏi khung phải thể hiện độ bền vững mạnh và thực hiện lập kế hoạch hợp lý. Thứ hai, các tham số và phản hồi của API RESTful thường tuân theo các định dạng cụ thể, dẫn đến khó khăn trong việc gọi API và phân tích phản hồi.

Để giải quyết những hạn chế của các phương pháp trước đây và những thách thức thực tế liên quan đến API RESTful, chúng tôi đề xuất RestGPT, một khung dựa trên LLM kết nối với các API RESTful để xử lý các chỉ dẫn phức tạp. RestGPT bao gồm ba mô-đun chính: một Planner, một API Selector, và một Executor. Cốt lõi của mỗi mô-đun là prompting một LLM. Không giống như công trình trước đây sử dụng lập kế hoạch tĩnh hoặc kiểu ReAct thiếu tính linh hoạt trong các tình huống thực tế, RestGPT áp dụng cơ chế lập kế hoạch trực tuyến lặp từ thô đến tinh. Được đưa ra một chỉ dẫn phức tạp, planner tạo ra một nhiệm vụ con cho nhiệm vụ hiện tại dưới dạng ngôn ngữ tự nhiên. Tiếp theo, API selector ánh xạ nhiệm vụ con cấp cao thô đến kế hoạch gọi API tinh hơn, tạo thành lập kế hoạch nhiệm vụ từ thô đến tinh. Executor, chịu trách nhiệm gọi các API RESTful và nhận kết quả thực thi, được chia thành hai mô-đun con: một Caller và một response Parser. Caller tổ chức các tham số gọi API dựa trên kế hoạch API và tài liệu API, trong khi parser sử dụng lược đồ phản hồi được định nghĩa trong OAS để tạo mã Python phân tích phản hồi. Khi nhận được kết quả thực thi của kế hoạch API, planner thực hiện lập kế hoạch trực tuyến cho nhiệm vụ con tiếp theo trong bước tiếp theo. Thông qua việc tích hợp ba mô-đun, phương pháp RestGPT của chúng tôi thể hiện khả năng mở rộng và tính linh hoạt vượt trội trong việc làm chủ các API RESTful.

Để đánh giá hiệu suất của RestGPT trong việc sử dụng các API RESTful, chúng tôi giới thiệu RestBench, một benchmark được chú thích bởi con người bao gồm hai tình huống thực tế, cơ sở dữ liệu phim TMDB và trình phát nhạc Spotify. Đối với mỗi tình huống, chúng tôi thu thập các chỉ dẫn người dùng thế giới thực đa dạng yêu cầu sử dụng nhiều API để hoàn thành. Dựa trên RestBench, chúng tôi thực hiện các thí nghiệm toàn diện để điều tra hiệu suất của RestGPT qua các chiều khác nhau. Kết quả thí nghiệm chứng minh rằng RestGPT thể hiện khả năng mạnh mẽ trong việc xử lý các chỉ dẫn người dùng phức tạp và có lợi thế đáng kể trong lập kế hoạch nhiệm vụ, hiểu API, và phân tích phản hồi.

¹HuggingGPT [13] tuyên bố đã tích hợp hàng trăm mô hình trên HuggingFace. Tuy nhiên, tất cả các mô hình chỉ bao phủ 24 nhiệm vụ như phân loại văn bản, phát hiện đối tượng, v.v.

--- TRANG 2 ---
Mô hình API/Công cụ Sử dụng Khung
Số lượng Khả năng mở rộng Lược đồ Lập kế hoạch Dạng Lập kế hoạch Phản hồi Plug-n-Play
ReAct 3 − Chuyên biệt Trực tuyến Ngôn ngữ Tự nhiên ✓ ✓
Toolformer 5 − Chuyên biệt ✗ - ✗ ✗
Visual ChatGPT 22 − Chuyên biệt ✗ - Con người ✓
ViperGPT 11 − Hàm Python Ngoại tuyến Chương trình ✗ ✓
HuggingGPT 241+ HuggingFace Ngoại tuyến Ngôn ngữ Tự nhiên ✗ ✓
API-Bank 53 − Chuyên biệt ✗ - Con người ✓
Chameleon 15 − Chuyên biệt Ngoại tuyến Ngôn ngữ Tự nhiên ✗ ✓
Gorilla 1645†+ JSON ✗ - ✗ ✗
GPT4Tools 31 − Chuyên biệt ✗ - Con người ✗
RestGPT (của chúng tôi) 100+ ++ RESTful Trực tuyến Thô-đến-Tinh ✓ ✓

Bảng 1: So sánh các công trình tăng cường LLM với việc sử dụng API/công cụ. †ký hiệu lựa chọn API với truy xuất.

LLM được tăng cường API để có khả năng lập kế hoạch và ra quyết định mạnh mẽ nhằm giải quyết hiệu quả các nhiệm vụ thế giới thực [9]. Tuy nhiên, các kỹ thuật hiện tại, dù là các phương pháp nội quan tĩnh lập kế hoạch-sau đó-thực thi [9,13,12] hay khung ReAct [16], đều gặp thách thức trong việc thích ứng hiệu quả với phản hồi API và tạo ra các kế hoạch khả thi.

Trong nghiên cứu này, chúng tôi đi sâu vào một tình huống thực tế hơn bằng cách kết nối LLM với các API RESTful thế giới thực, nhằm hoàn thành các chỉ dẫn người dùng thực tế. RESTful là tiêu chuẩn de facto cho phát triển dịch vụ web [17], sử dụng các phương thức HTTP (ví dụ: GET, POST) và URI để thao tác tài nguyên. Phát triển API RESTful thường tuân theo Đặc tả OpenAPI (OAS) [18], mô tả các hoạt động, tham số, và lược đồ phản hồi của mỗi điểm cuối API. Do đó, khung kết quả của chúng tôi có thể kết nối với bất kỳ ứng dụng RESTful nào và cung cấp quy trình phát triển API chuẩn hóa, từ đó cho phép khả năng mở rộng tăng cường so với các phương pháp trước đây.

Tuy nhiên, việc kết nối LLM với các API RESTful cũng mang lại những thách thức thực tế. Thứ nhất, việc gọi các API thế giới thực có thể dẫn đến vô số tình huống không lường trước được, đòi hỏi khung phải thể hiện độ bền vững mạnh và thực hiện lập kế hoạch hợp lý. Thứ hai, các tham số và phản hồi của API RESTful thường tuân theo các định dạng cụ thể, dẫn đến khó khăn trong việc gọi API và phân tích phản hồi.

Để giải quyết những hạn chế của các phương pháp trước đây và những thách thức thực tế liên quan đến API RESTful, chúng tôi đề xuất RestGPT, một khung dựa trên LLM kết nối với các API RESTful để xử lý các chỉ dẫn phức tạp. RestGPT bao gồm ba mô-đun chính: một Planner, một API Selector, và một Executor. Cốt lõi của mỗi mô-đun là prompting một LLM. Không giống như công trình trước đây sử dụng lập kế hoạch tĩnh hoặc kiểu ReAct thiếu tính linh hoạt trong các tình huống thực tế, RestGPT áp dụng cơ chế lập kế hoạch trực tuyến lặp từ thô đến tinh. Được đưa ra một chỉ dẫn phức tạp, planner tạo ra một nhiệm vụ con cho nhiệm vụ hiện tại dưới dạng ngôn ngữ tự nhiên. Tiếp theo, API selector ánh xạ nhiệm vụ con cấp cao thô đến kế hoạch gọi API tinh hơn, tạo thành lập kế hoạch nhiệm vụ từ thô đến tinh. Executor, chịu trách nhiệm gọi các API RESTful và nhận kết quả thực thi, được chia thành hai mô-đun con: một Caller và một response Parser. Caller tổ chức các tham số gọi API dựa trên kế hoạch API và tài liệu API, trong khi parser sử dụng lược đồ phản hồi được định nghĩa trong OAS để tạo mã Python phân tích phản hồi. Khi nhận được kết quả thực thi của kế hoạch API, planner thực hiện lập kế hoạch trực tuyến cho nhiệm vụ con tiếp theo trong bước tiếp theo. Thông qua việc tích hợp ba mô-đun, phương pháp RestGPT của chúng tôi thể hiện khả năng mở rộng và tính linh hoạt vượt trội trong việc làm chủ các API RESTful.

Để đánh giá hiệu suất của RestGPT trong việc sử dụng các API RESTful, chúng tôi giới thiệu RestBench, một benchmark được chú thích bởi con người bao gồm hai tình huống thực tế, cơ sở dữ liệu phim TMDB và trình phát nhạc Spotify. Đối với mỗi tình huống, chúng tôi thu thập các chỉ dẫn người dùng thế giới thực đa dạng yêu cầu sử dụng nhiều API để hoàn thành. Dựa trên RestBench, chúng tôi thực hiện các thí nghiệm toàn diện để điều tra hiệu suất của RestGPT qua các chiều khác nhau. Kết quả thí nghiệm chứng minh rằng RestGPT thể hiện khả năng mạnh mẽ trong việc xử lý các chỉ dẫn người dùng phức tạp và có lợi thế đáng kể trong lập kế hoạch nhiệm vụ, hiểu API, và phân tích phản hồi.

--- TRANG 3 ---
Đóng góp của chúng tôi có thể được tóm tắt như sau:
1. Lần đầu tiên, chúng tôi cố gắng kết nối các mô hình ngôn ngữ lớn với các API RESTful, cho phép khung kết quả tương thích với các ứng dụng thế giới thực hiện có đồng thời cung cấp khả năng mở rộng mạnh mẽ.
2. Chúng tôi đề xuất RestGPT, một khung lập kế hoạch trực tuyến từ thô đến tinh hiệu quả xử lý những thách thức thực tế liên quan đến việc kết nối LLM với các API RESTful, bao gồm hiểu API, lập kế hoạch, và phân tích phản hồi API.
3. Để đánh giá hiệu suất của RestGPT, chúng tôi xây dựng một benchmark được chú thích bởi con người, RestBench, bao gồm hai tình huống thực tế. Kết quả thí nghiệm cho thấy khả năng của RestGPT hiệu quả sử dụng một số API RESTful để hoàn thành các chỉ dẫn phức tạp.

2 Nền tảng
2.1 Mô hình Ngôn ngữ được Tăng cường Công cụ
Sự xuất hiện của các LLM mạnh mẽ gần đây đã cho phép các hệ thống trí tuệ nhân tạo sánh ngang với kỹ năng con người trong việc sử dụng công cụ [8,9]. Để tăng cường hiệu suất của LLM trong việc truy cập thông tin cập nhật và thực hiện lý luận toán học chính xác, các công trình đầu tận dụng các công cụ đơn giản như công cụ tìm kiếm web và máy tính, như ReAct [16], Toolformer [11], và ART [19]. Một hướng nghiên cứu khác tập trung vào việc trang bị LLM để phối hợp với các mô hình bên ngoài cho các nhiệm vụ AI phức tạp, được minh họa bằng HuggingGPT [13], ViperGPT [20], Visual ChatGPT [14] và Chameleon [12]. Gần đây, một số nghiên cứu về cách cho phép các LLM nguồn mở, như LLaMa, thực hiện việc sử dụng API [21,15,22]. Ngoài ra, API-Bank [23] cung cấp một benchmark hệ thống để thể hiện hiệu quả của LLM sử dụng công cụ để phản hồi các chỉ dẫn của con người.

Mặc dù có những tiến bộ đáng chú ý trong việc kết hợp công cụ cho các mô hình ngôn ngữ lớn, các phương pháp trước đây đã thể hiện những hạn chế nhất định, đáng chú ý nhất là hỗ trợ hạn chế của chúng cho một số lượng hạn chế các API được thiết kế đặc biệt [12] và các phương pháp lập kế hoạch kém hơn [9,24,12]. Chúng tôi so sánh RestGPT với các mô hình ngôn ngữ được tăng cường công cụ khác trong Bảng 1. Như thể hiện, công trình của chúng tôi nổi bật bằng việc hỗ trợ hơn 100 API RESTful. Hơn nữa, so với hầu hết các phương pháp trước đây áp dụng lập kế hoạch tĩnh ngoại tuyến không thể tương tác với API và sử dụng phản hồi để điều chỉnh kế hoạch, chúng tôi sử dụng khung lập kế hoạch trực tuyến từ thô đến tinh với phản hồi, tạo điều kiện cho lập kế hoạch linh hoạt hơn cho các chỉ dẫn phức tạp. Công trình của chúng tôi chia sẻ tinh thần tương tự với AutoGPT, một agent tự động có khả năng hoàn thành các nhiệm vụ phức tạp với nhiều công cụ. Trong khi AutoGPT dựa vào các nhà phát triển để đảm bảo tương thích với các ứng dụng khác nhau, RestGPT có thể được tích hợp với bất kỳ ứng dụng dựa trên API RESTful nào theo kiểu plug-and-play.

2.2 API RESTful
Các API RESTful đã trở thành một cách phổ biến để hiển thị chức năng và dữ liệu của các dịch vụ web cho các ứng dụng khách [25,17]. Các API RESTful cũng cung cấp một tiêu chuẩn để tích hợp các hệ thống bên ngoài với nhau bằng cách sử dụng một giao diện đơn giản nhưng mạnh mẽ. Có hàng triệu API RESTful có sẵn trên Internet, như Spotify, Twitter, Gmail, v.v. Các API RESTful dựa trên kiểu kiến trúc REST, nhấn mạnh giao tiếp client-server thông qua các yêu cầu HTTP không trạng thái, bao gồm GET, POST, v.v., nơi các tài nguyên được xác định bằng URI tự mô tả [25]. Phản hồi của các API RESTful luôn được cấu trúc ở định dạng JSON và chứa thông tin khác nhau. Do đó, LLM được kết nối với các API RESTful phải có khả năng mạnh để trích xuất thông tin cần thiết từ phản hồi.

Đặc tả OpenAPI (OAS, hoặc Swagger) [18], đã được áp dụng rộng rãi như một tiêu chuẩn để định nghĩa các API RESTful. OAS là một tệp tài liệu có cấu trúc mô tả các điểm cuối, hoạt động, tham số, lược đồ phản hồi, và các chi tiết khác của một điểm cuối API, cung cấp giao diện rõ ràng cho phương pháp của chúng tôi sử dụng các API.

--- TRANG 4 ---
[Hình 1: Tổng quan về RestGPT. Planner, API selector, executor hợp tác để tạo thành khung lập kế hoạch trực tuyến từ thô đến tinh. Caller và response parser trong executor cung cấp việc thực thi mạnh mẽ kế hoạch gọi API RESTful.]

3 RestGPT
3.1 Kiến trúc RestGPT
Như được thể hiện trong Hình 1, RestGPT bao gồm ba mô-đun chính: một Planner P, một API Selector S và một Executor E. Planner phân tách mỗi chỉ dẫn người dùng thành nhiều nhiệm vụ con, trong khi API selector chọn các API để giải quyết mỗi nhiệm vụ con. Executor, bao gồm một Caller và một response Parser, thực hiện các lời gọi API RESTful và trích xuất thông tin hữu ích từ phản hồi JSON để tạo thành kết quả thực thi. Cốt lõi của mỗi thành phần là một LLM với prompt tương ứng và các ví dụ trong ngữ cảnh mô tả chức năng của thành phần.

Một trong những thách thức trong việc kết nối LLM với một số lượng lớn API là đảm bảo rằng khung có thể hiểu đầy đủ các tài liệu API với kích thước cửa sổ ngữ cảnh hạn chế của LLM. Như được mô tả trong Hình 1, chúng tôi chỉ định các mô-đun khác nhau để đọc các phần riêng biệt của Đặc tả OpenAPI (OAS). Chiến lược này cho phép chúng tôi tận dụng thông tin OAS đến tiềm năng tối đa khi làm việc với các API RESTful. Cụ thể, API selector đọc mô tả điểm cuối của tất cả API để chọn một API thích hợp cho việc giải quyết nhiệm vụ con hiện tại. Sau đó, caller sử dụng các tài liệu chi tiết của API trong kế hoạch API để tạo ra các tham số gọi API đúng và body yêu cầu. Cuối cùng, parser được phát triển để sử dụng lược đồ phản hồi trong OAS để tạo mã phân tích cho việc trích xuất thông tin.

3.2 Lập kế hoạch Trực tuyến Từ thô đến Tinh
Để khai thác đầy đủ khả năng lập kế hoạch và ra quyết định của LLM và cho phép phương pháp của chúng tôi điều chỉnh động kế hoạch theo hoàn cảnh thay đổi khi hoàn thành các chỉ dẫn người dùng thế giới thực, chúng tôi đề xuất cơ chế lập kế hoạch trực tuyến từ thô đến tinh trong RestGPT.

Quy trình làm việc của RestGPT có thể được đặc trưng như một vòng lặp "lập kế hoạch và thực thi" lặp đi lặp lại. Trong giai đoạn lập kế hoạch, planner và API selector hợp tác để hoàn thành một chỉ dẫn thông qua việc lặp phân tách nó thành các nhiệm vụ con ngôn ngữ tự nhiên phù hợp và các API tương ứng. Trong mỗi bước t, planner P tận dụng kiến thức thường thức để tạo ra một nhiệm vụ con ngôn ngữ tự nhiên (NL) pt dựa trên chỉ dẫn người dùng q, các kế hoạch NL trước đó (p1, ..., pt−1), và kết quả thực thi (r1, ..., rt−1), từ đó xây dựng kế hoạch NL cấp cao. Sau đó, API selector S đọc mô tả của các điểm cuối API có sẵn để chọn các API thích hợp và xây dựng kế hoạch API tinh hơn at, có thể chứa một hoặc nhiều lời gọi API để giải quyết kế hoạch NL hiện tại pt. Sau đó executor E thực thi kế hoạch API at và nhận kết quả thực thi rt cho bước hiện tại. Quy trình này có thể được công thức hóa như:

Kế hoạch NL: pt ← P(q; p1, r1..., pt−1, rt−1),
Kế hoạch API: at ← S(pt; r1, ..., rt−1),
Kết quả Thực thi: rt ← E(at; r1, ..., rt−1). (1)

--- TRANG 5 ---
Bằng cách này, planner và API selector được dành riêng cho lập kế hoạch nhiệm vụ con NL và lựa chọn API, tương ứng, hiệu quả sử dụng khả năng lập kế hoạch và hiểu văn bản của mô hình ngôn ngữ lớn.

Cùng với vòng lặp "lập kế hoạch và thực thi", chúng tôi thiết kế hai trạng thái đặc biệt, "tiếp tục" và "kết thúc", cho planner để giám sát kết quả thực thi từ executor. Cụ thể, nếu planner thấy rằng đầu ra rt hiện tại của executor chưa hoàn thành nhiệm vụ con NL hiện tại pt, nó sẽ đưa ra tín hiệu "tiếp tục" và cung cấp kế hoạch NL đặc biệt pt+1 cho API selector, hướng dẫn nó tiếp tục hoàn thành kế hoạch pt. Trong những trường hợp như vậy, API selector sẽ tạo lại kế hoạch API mới dựa trên kế hoạch NL gốc pt, kế hoạch NL mới pt+1, kế hoạch API trước đó at và kết quả thực thi rt. Quy trình này được mô tả như:

Kế hoạch API: at+1 ← S(pt, pt+1; r1, ..., rt−1; at, rt),
Kết quả Thực thi: rt+1 ← E(at+1; r1, ..., rt−1, rt). (2)

Nếu planner đánh giá rằng yêu cầu của người dùng đã được hoàn thành, nó sẽ đưa ra tín hiệu kết thúc "end" và đưa ra kết quả cuối cùng. Với thiết kế như vậy, phương pháp của chúng tôi đạt được lập kế hoạch trực tuyến linh hoạt hơn có khả năng xử lý các tình huống khác nhau gặp phải trong các tình huống thế giới thực.

Planner, API selector, và executor hợp tác để tạo thành khung lập kế hoạch trực tuyến từ thô đến tinh của RestGPT. Khung này tăng cường đáng kể khả năng phân tách nhiệm vụ và chọn API thích hợp, cung cấp cho mô hình tính linh hoạt để giải quyết hiệu quả các chỉ dẫn người dùng.

3.3 Thực thi Kế hoạch API
[Hình 2: Ví dụ đầu ra của caller.] Khi một kế hoạch gọi API được tạo ra, bước tiếp theo là thực thi nó. Executor E bao gồm một caller và một response parser. Caller nên đọc cẩn thận các tài liệu API và tạo ra các tham số hoặc body yêu cầu đúng cho lời gọi API. Do các ràng buộc của độ dài ngữ cảnh tối đa, chúng tôi lọc các tài liệu API và chỉ giữ lại các API xuất hiện trong kế hoạch API hiện tại at. Được cung cấp các tham số và body yêu cầu được tạo ra, chúng tôi sử dụng thư viện Python Requests để gọi API RESTful. Bên cạnh đó, để hướng dẫn response parser trích xuất thông tin từ phản hồi API, caller cũng tạo ra mô tả phản hồi và chỉ dẫn đầu ra cho response parser. Hình 2 trình bày một ví dụ đầu ra của caller.

Các API RESTful thường trả về phản hồi định dạng JSON với nhiều thông tin dư thừa. Executor cần trích xuất thông tin cần thiết từ phản hồi và trả về cho planner. Tuy nhiên, phản hồi đôi khi có thể có cấu trúc phức tạp hoặc dài, làm cho việc trích xuất thông tin quan trọng thông qua việc prompting trực tiếp LLM trở nên khó khăn. Để giải quyết vấn đề này, chúng tôi sử dụng lược đồ phản hồi được định nghĩa trong OAS. Cụ thể, chúng tôi sử dụng khả năng mã hóa của LLM để tạo mã phân tích Python dựa trên lược đồ được cung cấp và chỉ dẫn đầu ra được tạo bởi caller. Tiếp theo, mã Python được thực thi để nhận kết quả cuối cùng. Nếu không có ngoại lệ hoặc lỗi thực thi, đầu ra được trả về. Nếu không, LLM được prompting để phân tích phản hồi trực tiếp như một bản dự phòng.

4 RestBench
Để đánh giá hiệu quả của RestGPT trong xử lý các chỉ dẫn người dùng phức tạp thông qua các API RESTful, chúng tôi giới thiệu RestBench, một tập dữ liệu chất lượng cao được chú thích bởi con người bao gồm hai tình huống thế giới thực. Các nghiên cứu hiện có đã đề xuất một số benchmark để đánh giá các LLM được tăng cường công cụ/API [23,21,9]. Tuy nhiên, các benchmark này chủ yếu tập trung vào các nhiệm vụ đơn giản có thể được hoàn thành bằng một API duy nhất. Chúng tôi hy vọng RestBench có thể tạo điều kiện cho việc khám phá về sử dụng nhiều API để giải quyết các chỉ dẫn người dùng thế giới thực.

--- TRANG 6 ---
Tình huống Số API Độ dài Đường dẫn Giải pháp Độ dài Trung bình Tổng
1 2 3 4
TMDB 54 5 66 27 2 2.3 100
Spotify 40 8 18 22 9 2.6 57

Bảng 2: Thống kê tập kiểm tra RestBench. Chúng tôi báo cáo số lượng chỉ dẫn với các độ dài khác nhau của đường dẫn giải pháp.

4.1 Tình huống và API
Chúng tôi chọn hai tình huống thế giới thực phổ biến: cơ sở dữ liệu phim TMDB và trình phát nhạc Spotify. Cân nhắc chính là đánh giá khả năng của RestGPT: (1) tăng cường LLM với cơ sở dữ liệu domain chuyên biệt bên ngoài thông qua API RESTful; (2) kết nối LLM với API RESTful để điều khiển tự động các ứng dụng thế giới thực. TMDB cung cấp các API RESTful chính thức bao gồm thông tin về phim, TV, diễn viên, và hình ảnh. Trình phát nhạc Spotify cung cấp các điểm cuối API để truy xuất metadata nội dung, nhận đề xuất, tạo và quản lý danh sách phát, và điều khiển phát lại. Đối với hai tình huống này, chúng tôi lọc ra 54 và 40 API được sử dụng phổ biến tương ứng và có được các Đặc tả OpenAPI tương ứng để xây dựng RestBench.

4.2 Thu thập Tập dữ liệu
[Ví dụ chỉ dẫn và đường dẫn giải pháp vàng tương ứng của RestBench]

Các chỉ dẫn chất lượng cao thường thỏa mãn hai khía cạnh quan trọng: (1) phản ánh phạm vi rộng của nhu cầu người dùng thực; (2) bao phủ các mức độ phức tạp khác nhau để nghiên cứu đầy đủ khả năng lý luận và lập kế hoạch của phương pháp chúng tôi. Để đạt được những mục tiêu này, chúng tôi áp dụng phương pháp thu thập chỉ dẫn bottom-up. Chúng tôi sử dụng 6 chuyên gia làm việc về nghiên cứu NLP để brainstorm các chỉ dẫn cho các tổ hợp API khác nhau. Cùng với các chỉ dẫn, các chuyên gia cần chú thích đường dẫn giải pháp API vàng cho mỗi chỉ dẫn. Để đảm bảo chất lượng của các chỉ dẫn, chúng tôi sử dụng hai chuyên gia bổ sung để xác minh kỹ lưỡng khả năng giải quyết của mỗi chỉ dẫn và tính đúng đắn của đường dẫn giải pháp tương ứng. Cuối cùng, chúng tôi chú thích 10 cặp chỉ dẫn-giải pháp cho mỗi tình huống như tập phát triển, và 100 cặp cho TMDB và 57 cặp cho Spotify như tập kiểm tra. Mặc dù quy mô dữ liệu không lớn, những chỉ dẫn này điển hình cho các yêu cầu người dùng được đặt ra thường xuyên. Hơn nữa, khác với công trình trước đây sử dụng LLM để có được quy trình gọi API, chúng tôi sử dụng đường dẫn giải pháp API được gắn nhãn bởi con người để đánh giá. Bảng 3 trình bày các chỉ dẫn ví dụ của hai tình huống. Thống kê của RestBench được hiển thị trong Bảng 2.

4.3 Chỉ số Đánh giá
Vì một số yêu cầu người dùng phụ thuộc vào thời gian (xem ví dụ TMDB trong Bảng 3), việc chú thích câu trả lời ground-truth cố định cho mỗi chỉ dẫn là không thực tế, trong khi đó, các đường dẫn giải pháp API cho hầu hết các chỉ dẫn vẫn nhất quán. Nếu đường dẫn gọi API được tạo bởi mô hình chứa đường dẫn gọi API vàng như một dãy con (với các phần tử không nhất thiết phải liền kề), chúng tôi nghĩ rằng mô hình đã tạo ra đường dẫn đúng. Để đánh giá thêm hiệu suất của mô hình, chúng tôi dựa vào đánh giá của con người để xác định xem kết quả mô hình có hoàn thành thành công truy vấn người dùng hay không. Chúng tôi tính tỷ lệ đường dẫn đúng và hoàn thành truy vấn thành công như các chỉ số, tức là, Tỷ lệ Đường dẫn Đúng và Tỷ lệ Thành công. Hơn nữa, số lượng lời gọi API thực tế có thể được sử dụng để đo lường hiệu quả lập kế hoạch của các phương pháp khác nhau. Được cung cấp độ dài của các giải pháp vàng, chúng tôi định nghĩa thêm ∆Độ dài Giải pháp như

--- TRANG 7 ---
Mô hình TMDB Spotify
Thành công% CP% ∆Độ dài Giải pháp Thành công% CP% ∆Độ dài Giải pháp
Offline [9] 29.0 33.0 +1.52 14.5 36.4 +1.10
DEPS [7] 38.0 43.0 +1.20 19.3 43.8 +1.74
ReAct [16] 44.0 57.0 +0.76 54.5 49.1 +0.31
Reflexion [26] 52.0 59.0 +1.37 59.6 61.4 +1.68
RestGPT 75.0 79.0 +0.55 72.7 74.5 +0.25
w/o Planner† 44.0 57.0 +0.76 54.5 49.1 +0.31
w/o Parser 46.0 53.0 +0.60 47.3 52.7 +0.24
RestGPT (ChatGPT) 68.0 65.0 +0.72 69.1 72.3 +0.28
RestGPT (Llama2-13B) 0.0 0.0 - 0.0 0.0 -
RestGPT (Vicuna-13B) 9.0 15.0 +1.21 12.7 20.6 +1.52

Bảng 4: Tỷ lệ thành công (%), Tỷ lệ Đường dẫn Đúng (CP, %), và ∆Độ dài Giải pháp trên hai tình huống của RestBench. Kết quả tốt nhất được in đậm. †RestGPT w/o planner tương đương với ReAct được trang bị executor mà chúng tôi đề xuất.

số trung bình của các lời gọi API bổ sung cần thiết để thực thi thành công một chỉ dẫn:

∆Độ dài Giải pháp = (1/Ns) ∑(i=0 to Ns) (Li_real - Li_gold) · I(i,success),

trong đó Ns là số lượng chỉ dẫn được hoàn thành thành công, Li_real và Li_gold là số lượng lời gọi API thực tế và vàng cho chỉ dẫn thứ i tương ứng, I(i,success) biểu thị liệu chỉ dẫn thứ i có được hoàn thành thành công hay không.

5 Thí nghiệm
5.1 Thiết lập Thí nghiệm
Chúng tôi so sánh RestGPT với bốn baseline gần đây, bao gồm phương pháp nội quan offline [9] được sử dụng trong HuggingGPT [13] và Chameleon [12], DEPS [7], ReAct [16] và Reflexion [26]. Vì một số phương pháp không được thiết kế ban đầu cho việc sử dụng công cụ/API, chúng tôi tái tạo chúng và thêm API executor được đề xuất trong Phần 3.3 để làm cho chúng có thể gọi các API RESTful. Số bước tối đa cho DEPS được đặt là 10 và số lần thử tối đa cho Reflexion được đặt là 2.

Để thể hiện khả năng lập kế hoạch và gọi API của phương pháp chúng tôi, chúng tôi triển khai hai biến thể ablation của RestGPT. Biến thể đầu tiên liên quan đến việc loại bỏ planner và cho phép API selector chọn trực tiếp các API theo kiểu ReAct. Phương pháp này có thể được coi như ReAct được trang bị executor mà chúng tôi đề xuất. Biến thể thứ hai là thay thế response parser dựa trên lược đồ bằng một LLM trực tiếp đọc và trích xuất thông tin cần thiết từ phản hồi JSON.

Trong các thí nghiệm của chúng tôi, chúng tôi sử dụng text-davinci-003 từ OpenAI làm LLM cho RestGPT và tất cả baseline. Nhiệt độ giải mã được đặt là 0 cho việc tạo xác định nhất.

5.2 Kết quả Chính
Bảng 4 hiển thị hiệu suất của RestGPT và các baseline trên hai tình huống. Phương pháp của chúng tôi vượt trội so với tất cả các phương pháp khác trong cả hai tình huống, đạt tỷ lệ thành công 75% trên cơ sở dữ liệu phim và hơn 70% trên trình phát nhạc. Lưu ý rằng trong hầu hết các trường hợp, tỷ lệ đường dẫn đúng cao hơn một chút so với tỷ lệ thành công, cho thấy rằng phương pháp có thể tạo ra kế hoạch gọi API đúng nhưng thất bại trong việc thực thi nó. RestGPT cũng nổi bật với độ dài giải pháp tối thiểu, thể hiện khả năng lập kế hoạch vượt trội của cơ chế lập kế hoạch trực tuyến từ thô đến tinh.

Các thí nghiệm ablation về lập kế hoạch từ thô đến tinh và parser dựa trên lược đồ cho thấy cả hai cơ chế đều có lợi cho hiệu suất mô hình. Đặc biệt, khi loại bỏ planner, hiệu suất giảm đáng kể, cho thấy rằng các LLM hiện tại không thể đồng thời thực hiện lập kế hoạch, hiểu và lựa chọn API. Do đó, cơ chế lập kế hoạch từ thô đến tinh đóng vai trò quan trọng trong

--- TRANG 8 ---
[Các biểu đồ phân tích lỗi và đường cong mở rộng]

khung của chúng tôi. Kết quả ablation không có parser chứng minh rằng parser dựa trên lược đồ cho phép LLM hiểu và phân tích tốt hơn các phản hồi API thế giới thực với cấu trúc phức tạp.

Để điều tra hiệu suất của phương pháp chúng tôi với các LLM cơ sở khác nhau, chúng tôi triển khai RestGPT với ChatGPT (gpt-3.5-turbo-0301), Llama2-13B (Llama-2-13b-chat-hf), và Vicuna-13B (vicuna-13b-v1.5). Như hiển thị trong Bảng 4, hiệu suất của ChatGPT kém hơn một chút so với text-davinci-003. Thú vị là, chúng tôi đã thử tất cả các checkpoint chính thức của Llama2-13B, nhưng không checkpoint nào có thể hiểu prompt và tạo ra các kế hoạch hợp lệ. Ngược lại, Vicuna-13B, được tinh chỉnh từ Llama2 trên các cuộc trò chuyện được chia sẻ bởi người dùng, có thể hoàn thành một số chỉ dẫn đơn giản. Kết quả này cho thấy rằng bằng cách tinh chỉnh LLM trên dữ liệu được tạo bởi ChatGPT, mô hình có thể có được khả năng hiểu và tuân theo các prompt phức tạp.

5.3 Phân tích Lỗi
Để điều tra thêm hiệu quả của các mô-đun khác nhau trong RestGPT, chúng tôi thực hiện phân tích lỗi. Trong Hình 3, chúng tôi phân loại lỗi dựa trên mô-đun trong đó chúng xảy ra. Chúng tôi phát hiện rằng phần lớn lỗi xảy ra trong giai đoạn lập kế hoạch, tức là, trong planner (tím) và API selector (xanh dương). Planner đôi khi mất dấu mục tiêu dự định của mình sau nhiều vòng thực thi, dẫn đến thoát sớm trước khi hoàn thành chỉ dẫn. Đối với API selector, nó có thể chọn các API không chính xác hoặc ảo giác để tạo ra các tham số in-path. Phân tích lỗi này làm nổi bật khả năng lập kế hoạch và ra quyết định không đủ của LLM.

So với text-davinci-003, ChatGPT có xu hướng mắc nhiều lỗi hơn trong giai đoạn lập kế hoạch, dẫn đến hiệu suất kém hơn một chút trên cả hai tình huống. Cụ thể hơn, chúng tôi thấy rằng ChatGPT thường quá dài dòng và có xu hướng tiếp tục lập kế hoạch ngay cả sau khi chỉ dẫn người dùng đã được hoàn thành. Hành vi này có thể được quy cho việc ChatGPT được huấn luyện đặc biệt cho các tương tác trò chuyện, khuyến khích nó tạo ra các phản hồi dài hơn.

5.4 Đường cong Mở rộng
Trong phần này, chúng tôi nhằm chứng minh khả năng mở rộng của RestGPT trên hai chiều: mở rộng độ khó của các nhiệm vụ và mở rộng số lượng API.

Đối với mỗi chỉ dẫn trong RestBench, độ dài của đường dẫn giải pháp vàng cho biết độ phức tạp của chỉ dẫn. Chúng tôi tính tỷ lệ thành công của các mô hình trên các chỉ dẫn với độ phức tạp khác nhau.

Như được mô tả trong Hình 4 (a) (b), tỷ lệ thành công của tất cả các phương pháp giảm khi độ phức tạp của chỉ dẫn tăng. Đáng chú ý, khi độ dài đường dẫn vàng là 4, tất cả baseline đều gặp khó khăn để hoàn thành nhiệm vụ trong cả hai tình huống. Ngược lại, RestGPT được đề xuất của chúng tôi vẫn có thể đạt tỷ lệ thành công hơn 40%, thể hiện hiệu suất vượt trội trong lập kế hoạch và gọi API.

Trước khi thực hiện thí nghiệm về mở rộng số lượng API, chúng tôi chọn thủ công 10 API từ TMDB và tạo một tập kiểm tra nhỏ gồm 15 chỉ dẫn. Tất cả 15 chỉ dẫn có thể được giải quyết bằng 10 API được chọn. Sau đó, chúng tôi ngày càng mở rộng số lượng API và giới thiệu các API nhiễu bổ sung có nguồn gốc từ các API TMDB chính thức. Kết quả được hiển thị trong Hình 4 (c). Khi số lượng API nhiễu tăng, hiệu suất của tất cả các phương pháp baseline xấu đi do khả năng lập kế hoạch và lý luận kém hơn của chúng. Tuy nhiên, phương pháp của chúng tôi gần như không bị ảnh hưởng. Những kết quả này hiệu quả chứng minh khả năng mở rộng mạnh mẽ của RestGPT được đề xuất của chúng tôi.

5.5 Nghiên cứu Trường hợp
Trong Hình 5, chúng tôi thực hiện nghiên cứu trường hợp để so sánh khả năng lập kế hoạch của RestGPT với lập kế hoạch offline [9,12] và khung ReAct [16]. Trước tiên, chúng tôi quan sát thấy phương pháp offline không thể giải quyết hầu hết các chỉ dẫn người dùng. Như được mô tả trong Hình 5 (a), planner không chỉ chọn API sai (bước 2), mà còn bỏ qua các phụ thuộc giữa các API và sử dụng tham số "user_id" trước khi có được nó (bước 4). Về ReAct tạo ra chain-of-thought và hành động theo cách xen kẽ, chúng tôi thấy rằng các LLM hiện tại có khả năng hạn chế để đồng thời thực hiện lập kế hoạch, hiểu và lựa chọn API. Như hiển thị trong Hình 5 (b), planner của ReAct tạo ra một nhiệm vụ con khó giải quyết (bước 2) và cũng bỏ qua các phụ thuộc giữa các API khác nhau (bước 3). Do lập kế hoạch kém, nó tiêu tốn 6 lời gọi API để hoàn thành nhiệm vụ. Ngược lại, RestGPT sử dụng một planner để tạo ra các nhiệm vụ con NL cấp cao và một API selector để chọn các API thích hợp để giải quyết nhiệm vụ con. Đáng chú ý, trong bước 3, planner đánh giá rằng danh sách phát chưa được tạo thành công và tạo ra tín hiệu "tiếp tục" với hướng dẫn thêm cho API selector. Phương pháp của chúng tôi hoàn thành chỉ dẫn chỉ với 4 lời gọi API. Khung lập kế hoạch trực tuyến từ thô đến tinh của RestGPT khai thác đầy đủ khả năng lập kế hoạch và hiểu tài liệu của LLM, cung cấp cho mô hình tính linh hoạt để giải quyết các yêu cầu người dùng phức tạp.

6 Kết luận
Trong bài báo này, chúng tôi khám phá các tình huống kết nối các mô hình ngôn ngữ lớn (LLM) hiện tại với các ứng dụng thế giới thực thông qua các API RESTful. Để vượt qua những hạn chế của các phương pháp hiện có và giải quyết những thách thức trong việc tích hợp LLM với các API RESTful, chúng tôi đề xuất RestGPT, một phương pháp tận dụng LLM để hoàn thành các chỉ dẫn người dùng phức tạp. Phương pháp của chúng tôi có đặc điểm là cơ chế lập kế hoạch trực tuyến từ thô đến tinh để cho phép lập kế hoạch và lựa chọn API linh hoạt hơn. Hơn nữa, để xử lý tình huống phức tạp của việc gọi các API RESTful, chúng tôi thiết kế một API executor chuyên biệt để

--- TRANG 9-10 ---
xây dựng tham số và phân tích phản hồi API. Để đánh giá hiệu suất của phương pháp chúng tôi, chúng tôi xây dựng một tập dữ liệu chất lượng cao, RestBench, bao gồm các chỉ dẫn được chú thích bởi con người từ hai tình huống thực tế. Các thí nghiệm mở rộng chứng minh rằng RestGPT đạt được kết quả ấn tượng trong các nhiệm vụ phức tạp và thể hiện độ bền vững mạnh mẽ, mở ra con đường mới hướng tới AGI. Trong tương lai, chúng tôi nhằm đi sâu vào phạm vi rộng hơn của các nhiệm vụ phức tạp, xem xét kỹ lưỡng tiềm năng to lớn của RestGPT qua cả lĩnh vực học thuật và công nghiệp.

Tài liệu tham khảo
[1] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, và các cộng sự. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020.

[2] OpenAI. Chatgpt, 2022. URL https://openai.com/blog/chatgpt.

[3] Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, và Zhifang Sui. A survey for in-context learning. arXiv preprint arXiv:2301.00234, 2022.

[4] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, và Denny Zhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903, 2022.

[5] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, và các cộng sự. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682, 2022.

[6] Wenlong Huang, Pieter Abbeel, Deepak Pathak, và Igor Mordatch. Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. In International Conference on Machine Learning, pages 9118–9147. PMLR, 2022.

[7] Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, và Yitao Liang. Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents. arXiv preprint arXiv:2302.01560, 2023.

[8] Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, và các cộng sự. Augmented language models: a survey. arXiv preprint arXiv:2302.07842, 2023.

[Tiếp tục với các tài liệu tham khảo từ [9] đến [26]...]

--- TRANG 11-25 ---
[Phần phụ lục với các ví dụ API RESTful, OAS, baselines, nghiên cứu trường hợp về executor, và chi tiết triển khai...]

Phụ lục A: API RESTful và OAS
API RESTful (Representational State Transfer API) là một kiểu kiến trúc được sử dụng để thiết kế các ứng dụng mạng. Nó dựa trên các nguyên tắc của Representational State Transfer (REST) và được sử dụng rộng rãi để xây dựng các dịch vụ web [25,17]. Trong API RESTful, các tài nguyên (như đối tượng dữ liệu hoặc dịch vụ) được biểu diễn như URL (Uniform Resource Locators), được gọi là điểm cuối. Các điểm cuối này được truy cập qua giao thức HTTP, và các phương thức HTTP khác nhau (GET, POST, v.v.) được sử dụng để thực hiện các hoạt động trên tài nguyên. Có hàng triệu API RESTful có sẵn trên Internet, như Spotify, Twitter, Gmail, v.v.

Đặc tả OpenAPI (OAS), trước đây được gọi là Swagger, là một đặc tả để định nghĩa và tài liệu hóa các API RESTful [18]. Nó cung cấp một cách tiêu chuẩn hóa để mô tả cấu trúc, chức năng, và hành vi của một API, làm cho việc hiểu và tương tác với API trở nên dễ dàng hơn cho các nhà phát triển. Đặc tả OpenAPI được viết bằng định dạng JSON hoặc YAML và bao gồm một tập hợp các quy tắc và quy ước định nghĩa các điểm cuối, định dạng yêu cầu/phản hồi, tham số, phương thức xác thực, và các chi tiết khác của API.

[Tiếp tục với các phần phụ lục khác...]
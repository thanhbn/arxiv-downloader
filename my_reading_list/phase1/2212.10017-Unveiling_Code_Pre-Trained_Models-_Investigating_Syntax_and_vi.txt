# 2212.10017.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: ./2212.10017.pdf
# Kích thước tệp: 1454270 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Khám Phá Các Mô Hình Tiền Huấn Luyện Mã Nguồn: Nghiên Cứu Khả Năng Cú Pháp và Ngữ Nghĩa
WEI MA, Đại học Công nghệ Nanyang, Singapore
SHANGQING LIU∗, Đại học Công nghệ Nanyang, Singapore
MENGJIE ZHAO, Đại học Ludwig Maximilian Munich, Đức
XIAOFEI XIE, Đại học Quản lý Singapore, Singapore
WENHAN WANG, Đại học Alberta, Canada
QIANG HU, Đại học Tokyo, Nhật Bản
JIE ZHANG, Phòng thí nghiệm Noah's Ark, Huawei, Trung Quốc
YANG LIU, Đại học Công nghệ Nanyang, Singapore

Tiến bộ đáng kể đã được đạt được trong lĩnh vực trí tuệ mã nguồn thông qua các mô hình mã nguồn nhúng kiến thức về ngôn ngữ lập trình. Nghiên cứu trước đây đã kiểm tra mức độ nắm bắt cú pháp mã nguồn của các mô hình này, nhưng hiểu biết về ngữ nghĩa mã nguồn của chúng vẫn cần được khám phá. Hơn nữa, các phân tích hiện tại thường liên kết số lượng cạnh trong cây cú pháp trừu tượng (AST) với khoảng cách cú pháp. Chúng cũng thường yêu cầu giảm không gian chiều cao của các mô hình học sâu xuống chiều thấp hơn, có thể dẫn đến sự không chính xác. Chúng tôi phân tích rộng rãi bảy mô hình mã nguồn để nghiên cứu cách các mô hình mã nguồn biểu diễn cú pháp và ngữ nghĩa mã nguồn. Điều này bao gồm bốn mô hình tiền huấn luyện mã nguồn nổi bật (CodeBERT, GraphCodeBERT, CodeT5, và UnixCoder) và ba mô hình ngôn ngữ lớn (StarCoder, CodeLlama, và CodeT5+). Chúng tôi đã phát triển bốn nhiệm vụ thăm dò để đánh giá khả năng học cú pháp và ngữ nghĩa mã nguồn của các mô hình. Các nhiệm vụ này tập trung vào việc tái tạo các cấu trúc cú pháp và ngữ nghĩa mã nguồn—như Cây Cú pháp Trừu tượng (AST), Đồ thị Luồng Điều khiển (CFG), Đồ thị Phụ thuộc Điều khiển (CDG), và Đồ thị Phụ thuộc Dữ liệu (DDG)—trong không gian biểu diễn của các mô hình. Những cấu trúc này là nền tảng để hiểu mã nguồn. Ngoài ra, chúng tôi khám phá vai trò của các token cú pháp trong mỗi biểu diễn token và các phụ thuộc mở rộng giữa các token mã nguồn. Hơn nữa, chúng tôi kiểm tra phân phối trọng số attention liên quan đến các cấu trúc ngữ nghĩa mã nguồn. Thông qua phân tích chi tiết, kết quả của chúng tôi nhấn mạnh điểm mạnh và điểm yếu của các mô hình mã nguồn khác nhau trong việc nắm vững cú pháp và ngữ nghĩa mã nguồn. Các phát hiện cho thấy rằng những mô hình này thành thạo trong việc nắm bắt cú pháp mã nguồn, hiệu quả trong việc nắm bắt các mối quan hệ và vai trò của các token cú pháp. Tuy nhiên, khả năng mã hóa ngữ nghĩa mã nguồn của chúng cho thấy sự biến thiên nhiều hơn. CodeT5 và CodeBERT xuất sắc trong việc nắm bắt các phụ thuộc điều khiển và dữ liệu, trong khi UnixCoder thực hiện kém hiệu quả hơn. Chúng tôi cũng thấy rằng các mô hình ngôn ngữ lớn (LLMs) nói chung không vượt trội đáng kể so với các mô hình tiền huấn luyện. Thú vị là, các lớp nông hơn của LLMs thể hiện hiệu suất tốt hơn so với các lớp sâu hơn của chúng. Phân tích trọng số attention của chúng tôi chỉ ra rằng các attention head khác nhau được chuyên biệt hóa cho các vai trò riêng biệt trong việc mã hóa ngữ nghĩa mã nguồn. Nghiên cứu của chúng tôi nhấn mạnh sự cần thiết cho những cải tiến thêm trong các mô hình mã nguồn để nâng cao khả năng học ngữ nghĩa mã nguồn một cách hiệu quả.

∗Tác giả liên hệ.
Địa chỉ tác giả: Wei Ma, Đại học Công nghệ Nanyang, Singapore, ma_wei@ntu.edu.sg; Shangqing Liu, Đại học Công nghệ Nanyang, Singapore, liu.shangqing@ntu.edu.sg; Mengjie Zhao, Đại học Ludwig Maximilian Munich, Munich, Đức, mzhaolmu@gmail.com; Xiaofei Xie, Đại học Quản lý Singapore, Singapore, xfxie@smu.edu.sg; Wenhan Wang, Đại học Alberta, Edmonton, Canada, wenhan12@ualberta.ca; Qiang Hu, Đại học Tokyo, Tokyo, Nhật Bản, qianghu0515@gmail.com; Jie Zhang, Phòng thí nghiệm Noah's Ark, Huawei, Xi'An, Trung Quốc, clark.zhang@huawei.com; Yang Liu, Đại học Công nghệ Nanyang, Singapore, yangliu@ntu.edu.sg.

Quyền tạo bản sao kỹ thuật số hoặc cứng của toàn bộ hoặc một phần công trình này để sử dụng cá nhân hoặc lớp học được cấp mà không thu phí với điều kiện các bản sao không được tạo hoặc phân phối để kiếm lợi nhuận hoặc lợi ích thương mại và các bản sao phải mang thông báo này và trích dẫn đầy đủ trên trang đầu tiên. Bản quyền cho các thành phần của công trình này thuộc sở hữu của người khác ngoài (các) tác giả phải được tôn trọng. Việc tóm tắt có ghi nguồn được cho phép. Để sao chép theo cách khác, hoặc tái xuất bản, đăng trên máy chủ hoặc phân phối lại cho các danh sách, yêu cầu quyền cụ thể trước và/hoặc phí. Yêu cầu quyền từ permissions@acm.org.
©2018 Bản quyền thuộc về chủ sở hữu/tác giả. Quyền xuất bản được cấp phép cho ACM.
ACM 0004-5411/2018/8-ART111
https://doi.org/XXXXXXX.XXXXXXX
J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.arXiv:2212.10017v3 [cs.SE] 17 Thg 4 2024

--- TRANG 2 ---
111:2 W. Ma, S. Liu và M. Zhao cùng cộng sự.

Nghiên cứu này làm phong phú hiểu biết của chúng ta về khả năng của các mô hình mã nguồn trong việc phân tích cú pháp và ngữ nghĩa. Các phát hiện của chúng tôi cung cấp những hiểu biết có giá trị cho việc cải tiến mô hình mã nguồn trong tương lai, giúp tối ưu hóa ứng dụng của chúng trong nhiều nhiệm vụ liên quan đến mã nguồn.

Định dạng Tham khảo ACM:
Wei Ma, Shangqing Liu, Mengjie Zhao, Xiaofei Xie, Wenhan Wang, Qiang Hu, Jie Zhang, và Yang Liu. 2018. Khám Phá Các Mô Hình Tiền Huấn Luyện Mã Nguồn: Nghiên Cứu Khả Năng Cú Pháp và Ngữ Nghĩa. J. ACM 37, 4, Article 111 (Tháng 8 2018), 29 trang. https://doi.org/XXXXXXX.XXXXXXX

1 GIỚI THIỆU
Nhiều mô hình mã nguồn [2,4,13,17,29,31,41,42,63,71] đã được đề xuất để thúc đẩy đáng kể sự phát triển của trí tuệ mã nguồn. Nhiều phương pháp kỹ thuật phần mềm dựa trên việc tinh chỉnh các mô hình tiền huấn luyện này, như phát hiện mã nguồn nhân bản, phát hiện lỗ hổng và hoàn thành mã nguồn. Gần đây, các mô hình ngôn ngữ lớn (LLM) đã được chứng minh có khả năng đột sinh [72] mà các mô hình tiền huấn luyện không sở hữu. Công nghệ này tạo khả năng tự động tạo phần mềm, như MetaGPT [19]. Mặc dù những mô hình này đã được chứng minh hiệu quả trên các nhiệm vụ liên quan đến mã nguồn khác nhau, một vấn đề cơ bản vẫn chưa được giải quyết đối với các mô hình mã nguồn này về cách chúng hiểu mã nguồn. Đáng kể, các nghiên cứu gần đây [14,28,75] chỉ ra rằng các mô hình mã nguồn không thể đưa ra kết quả hợp lý nếu sử dụng các thủ thuật thay thế hoặc chèn token. Về các mô hình mã nguồn, chúng ta nên xem xét sâu sắc khả năng học các đặc tính cơ bản của mã nguồn, "Các mô hình mã nguồn này có thể học được loại kiến thức mã nguồn nào?". Một chương trình bao gồm các đặc tính cú pháp (ví dụ: AST) và thông tin ngữ nghĩa (ví dụ: phụ thuộc dữ liệu); do đó, vấn đề này có thể được phân tách thêm thành "Các mô hình mã nguồn có thể nắm bắt tốt cú pháp chương trình không?" và "Các mô hình mã nguồn có thể học được loại ngữ nghĩa chương trình nào?". Các nghiên cứu trước đã bắt đầu khám phá những câu hỏi được đặt ra, đặc biệt là câu hỏi phụ đầu tiên. Tuy nhiên, sự hiểu biết sâu sắc hơn về kiến thức mà các mô hình mã nguồn thu được vẫn còn khó nắm bắt. Trong khi nghiên cứu của Wan và cộng sự [69] và Hernández López và cộng sự [18] cho thấy các mô hình tiền huấn luyện mã nguồn có thể nắm bắt cú pháp chương trình, phân tích của họ không mở rộng đến ngữ nghĩa chương trình. Cũng quan trọng cần lưu ý rằng những nghiên cứu này có hai giả định: 1) số lượng liên kết giữa các nút có liên quan đến cú pháp mã nguồn; 2) tồn tại mối quan hệ tuyến tính giữa biểu diễn mã nguồn trong không gian chiều cao và chiều thấp. Tuy nhiên, những giả định này có một số hạn chế: 1) số lượng liên kết không nhất thiết phải liên quan đến cú pháp mã nguồn. 2) khoảng cách nhỏ hơn trong văn bản mã nguồn thô không có nghĩa là sự gần gũi cú pháp trong không gian biểu diễn. Hơn nữa, Troshin và Chirkova [66] kiểm tra cả cú pháp và ngữ nghĩa mã nguồn thông qua các nhiệm vụ khác nhau. Tuy nhiên, công trình này theo một cách tiếp cận tương tự với các nghiên cứu trước khi phân tích cú pháp. Nó cũng không đủ để điều tra kỹ lưỡng các ngữ nghĩa khác nhau vốn có trong lập trình. Quan trọng hơn, không có nghiên cứu nào về transformer decoder, đây là kiến trúc của hầu hết các LLM, như họ StarCoder [34] và Llama [58].

Những câu hỏi này có ý nghĩa quan trọng để chúng ta xem xét các ứng dụng của các mô hình mã nguồn trong kỹ thuật phần mềm. Nếu các mô hình mã nguồn có thể hiểu mã nguồn gần như hoàn hảo, các đầu ra của mô hình mã nguồn có thể được tin tưởng, và việc tạo phần mềm tự động là khả thi. Để giải quyết những thách thức nêu trên, trong bài báo này, chúng tôi nghiên cứu toàn diện bốn mô hình tiền huấn luyện mã nguồn được áp dụng rộng rãi: CodeBERT [13] (Chỉ encoder), GraphCodeBERT [17] (Chỉ encoder), CodeT5 [71] (Encoder-decoder) và UnixCoder [16] (Kiểu UniLM). Chúng tôi cũng bao gồm ba mô hình ngôn ngữ lớn (LLMs), StarCoder [34], CodeLlama [58] và CodeT5+ [70].

Bốn nhiệm vụ thăm dò được sử dụng để phân tích khả năng của các mô hình trong việc học cú pháp và ngữ nghĩa mã nguồn. Cụ thể, chúng tôi sử dụng hai nhiệm vụ thăm dò cú pháp, cụ thể là dự đoán cặp nút cú pháp và dự đoán gắn thẻ cú pháp token. Cả hai nhiệm vụ đều nhằm thao tác Cây Cú pháp Trừu tượng (AST) để đánh giá khả năng của các mô hình tiền huấn luyện trong việc học cú pháp mã nguồn vì AST chứa tất cả thông tin cú pháp của mã nguồn. Dự đoán cặp nút cú pháp nhằm xác định xem biểu diễn vector của hai đoạn gần nhau về cú pháp có thể hiện sự tương tự cú pháp hay không trong khi dự đoán gắn thẻ cú pháp token nhằm xác định xem biểu diễn vector có nắm bắt được quy tắc cú pháp của token riêng lẻ hay không. Dự đoán cặp nút cú pháp là để phục hồi cấu trúc AST từ biểu diễn vector, và dự đoán gắn thẻ cú pháp token là để gán vai trò cú pháp cho mỗi token mã nguồn trong không gian biểu diễn. Cả hai thông tin cú pháp đều quan trọng đối với các mô hình mã nguồn để hiểu cú pháp mã nguồn ở cấp độ toàn cục và cục bộ. Ý định đằng sau hai nhiệm vụ cú pháp là biểu diễn vector token mã nguồn nên giữ các thuộc tính cú pháp tồn tại trong mã nguồn: mối quan hệ cú pháp giữa các token mã nguồn, và thuộc tính cú pháp của mỗi token mã nguồn.

Ngoài phân tích cú pháp, chúng tôi tiếp tục thiết kế hai nhiệm vụ thăm dò ngữ nghĩa, cụ thể là dự đoán quan hệ ngữ nghĩa và dự đoán lan truyền ngữ nghĩa. Cả hai nhiệm vụ được thiết kế để điều tra mức độ mà các mô hình mã nguồn có thể học hiệu quả các khía cạnh khác nhau của ngữ nghĩa mã nguồn. Dự đoán quan hệ ngữ nghĩa là để phục hồi các cấu trúc ngữ nghĩa mã nguồn quan trọng trong không gian biểu diễn, bao gồm Đồ thị Phụ thuộc Dữ liệu (DDG), Đồ thị Phụ thuộc Điều khiển (CDG) và Đồ thị Luồng Điều khiển (CFG). Những cấu trúc ngữ nghĩa này có thể biểu diễn việc thực thi mã nguồn và các trạng thái bên trong. Dự đoán lan truyền ngữ nghĩa là để xem liệu chúng ta có thể quan sát mối quan hệ phụ thuộc dài trong không gian vector hay không vì một biến có thể được khai báo trong câu lệnh đầu tiên nhưng được sử dụng ở cuối. Cuối cùng, chúng tôi thực hiện phân tích thống kê cho các trọng số attention để hiểu toàn diện vai trò và phân phối attention trong việc học ngữ nghĩa của mã nguồn.

Phân tích cú pháp của chúng tôi cho thấy rằng 1). các mô hình mã nguồn hiệu quả nắm bắt các mối quan hệ cú pháp giữa các cặp token và thuộc tính này dễ quan sát hơn trong các lớp ẩn nông, cho thấy sự hiểu biết mạnh mẽ về cú pháp mã nguồn ở cấp độ cấu trúc; 2). các mô hình mã nguồn thành thạo trong việc xác định vai trò cú pháp của các token riêng lẻ và thuộc tính này dễ quan sát hơn trong các lớp ẩn sâu. Tuy nhiên, các mô hình tiền huấn luyện mã nguồn cho thấy hiệu suất vượt trội so với LLMs đối với gắn thẻ cú pháp, cho thấy các đặc tính cú pháp khó quan sát hơn trong biểu diễn mã nguồn từ LLMs. Việc dễ dàng quan sát không liên quan trực tiếp đến hiệu suất của mô hình trên các nhiệm vụ downstream, vì nó phụ thuộc vào nhiều yếu tố, như chất lượng dữ liệu và phương pháp tinh chỉnh. Tuy nhiên, nó có thể chỉ ra độ khó của việc xây dựng và điều chỉnh một mô hình tốt cho nhiệm vụ downstream dựa trên LLM. Trong thực tế, mọi người đã thử và thậm chí phát hiện rằng hiệu suất của các mô hình nhỏ truyền thống tốt hơn so với các mô hình lớn trong một số trường hợp [8, 27].

Phân tích ngữ nghĩa của chúng tôi thể hiện hiệu quả khác nhau trong khả năng của các mô hình mã nguồn dự đoán các mối quan hệ ngữ nghĩa. Các mô hình hiện tại cung cấp một số hiểu biết sắc thái về ngữ nghĩa mã nguồn, như các phụ thuộc dữ liệu, nhưng cũng nêu bật các lĩnh vực cần cải thiện, đặc biệt trong việc nắm bắt các cấu trúc ngữ nghĩa phức tạp. So với hiệu suất của các nhiệm vụ cú pháp, hiệu suất của các mô hình mã nguồn trong ngữ nghĩa tương đối thấp. Đối với CodeT5+, sự khác biệt hiệu suất giữa encoder và decoder rất lớn. Chúng tôi nghĩ điều này có thể do các cơ chế hoạt động khác nhau của encoder và decoder. Encoder tập trung nhiều hơn vào việc lồng ghép thông tin toàn cục. Decoder tập trung nhiều hơn vào việc tạo token tiếp theo dựa trên văn bản trước đó. Sự khác biệt này đặc biệt rõ ràng khi phân tích cơ chế attention. Khi chúng tôi tiến hành phân tích attention dựa trên các phụ thuộc điều khiển, chúng tôi thấy rằng đối với kiến trúc decoder, đóng góp trọng số của các token có phụ thuộc điều khiển nhỏ hơn đóng góp trọng số của các phụ thuộc không điều khiển. Chúng tôi tin rằng điều này là do encoder tập trung vào việc mã hóa thông tin toàn cục, nhưng decoder tập trung nhiều hơn vào các token trước đó và thông tin phụ thuộc không điều khiển khác, dẫn đến các phân phối trọng số khác nhau.

Thông qua phân tích rộng rãi, công trình của chúng tôi chỉ ra rằng các mô hình mã nguồn vẫn cần được cải thiện để học cú pháp và ngữ nghĩa mã nguồn, làm cho những thuộc tính này dễ quan sát hơn, do đó giảm độ khó của việc xây dựng mô hình nhiệm vụ downstream. Việc cải thiện nên tập trung vào cách tích hợp cú pháp và ngữ nghĩa mã nguồn vào các mô hình mã nguồn. Điều này có thể cần các chiến lược đào tạo mới có thể tích hợp toàn bộ cấu trúc mã nguồn thay vì làm phẳng những cấu trúc này. Mặc dù khả năng mô hình được mở rộng theo kích thước của nó [30,81], việc phát huy khả năng đó là thách thức cần một công việc không tầm thường để làm cho các đặc tính dễ quan sát hơn trong không gian biểu diễn cho các nhiệm vụ downstream.

Tóm lại, công trình của chúng tôi có những đóng góp sau:
• Chúng tôi đề xuất các nhiệm vụ thăm dò cú pháp và ngữ nghĩa để phân tích khả năng của mô hình mã nguồn hiểu cú pháp và ngữ nghĩa bằng cách trực tiếp phục hồi các cấu trúc cú pháp và ngữ nghĩa mã nguồn (AST, CFG, CDG và DDG) từ biểu diễn mã nguồn. Chúng tôi nghiên cứu phân phối của các trọng số attention liên quan đến ngữ nghĩa mã nguồn.

• Chúng tôi tiết lộ rằng mối quan hệ cú pháp dễ quan sát hơn trong các lớp ẩn nông, trong khi cú pháp vai trò token dễ quan sát hơn trong các lớp sâu. Các mô hình mã nguồn có hiệu suất vượt trội cho biểu diễn cú pháp so với biểu diễn ngữ nghĩa. Trong khi đó, các mô hình mã nguồn có hiệu suất kém đối với CFG so với các cấu trúc ngữ nghĩa khác, điều này yêu cầu các mô hình mã nguồn được tăng cường để biểu diễn ngữ nghĩa CFG. Các lớp ẩn khác nhau cho thấy các mức độ quan sát khác nhau cho các loại cú pháp và ngữ nghĩa mã nguồn khác nhau.

• Chúng tôi lần đầu tiên bao gồm các mô hình ngôn ngữ lớn và cho thấy hiệu suất của chúng trên các nhiệm vụ thăm dò không có lợi thế lớn so với các mô hình tiền huấn luyện, xem xét số lượng tham số khổng lồ của chúng. Điều này phản ánh rằng cú pháp và ngữ nghĩa mã nguồn được ẩn giấu và không rõ ràng trong biểu diễn của LLMs.

Chúng tôi hy vọng những hiểu biết này có thể truyền cảm hứng cho các nhà nghiên cứu đào tạo các mô hình mã nguồn mạnh mẽ hơn. Khi sử dụng những mô hình này, việc thiết kế các quy trình công việc được hướng dẫn bởi sự hiểu biết về những mô hình này là cần thiết, xem xét liệu việc tích hợp các đặc tính mã nguồn bổ sung có được bảo đảm hay không. Mặc dù nhiều yếu tố, bao gồm chất lượng dữ liệu, độ phức tạp của các mô hình nhiệm vụ downstream, và phương pháp tích hợp đặc tính ảnh hưởng đến hiệu suất mô hình trong các nhiệm vụ downstream, công trình của chúng tôi có thể cung cấp một số hướng cho thiết kế mô hình và dữ liệu của họ. Các mô hình thiếu hiểu biết ngữ nghĩa yêu cầu xem xét tăng cường thông tin ngữ nghĩa thông qua tích hợp đặc tính khi giải quyết các nhiệm vụ downstream. Công trình của chúng tôi nhấn mạnh rằng không bắt buộc phải sử dụng đầu ra của lớp cuối cùng - các lớp trung gian có thể tiềm năng biểu đạt cú pháp và ngữ nghĩa tương đương. Tất cả mã nguồn và dữ liệu có thể được tìm thấy tại kho lưu trữ¹.

2 ĐỘNG LỰC
Khả năng của các mô hình tiền huấn luyện mã nguồn đã được thảo luận rộng rãi trong các nghiên cứu trước [18,66,69]. Tuy nhiên, phân tích của họ dựa trên giả định rằng cú pháp gần gũi hơn giữa hai token trong mã nguồn sẽ dẫn đến khoảng cách cú pháp nhỏ hơn, được đo bằng số cạnh giữa các nút trong AST [69], và tương ứng, một khoảng cách nhỏ hơn trong biểu diễn vector, như khoảng cách Euclid được mã hóa bởi mô hình mã nguồn. Nói cách khác, giả định nói rằng "cú pháp gần gũi hơn" dẫn đến "khoảng cách cạnh nhỏ hơn trong AST" mà lần lượt dẫn đến "khoảng cách biểu diễn nhỏ hơn." Tuy nhiên, đầu tiên, "khoảng cách cạnh nhỏ hơn trong AST" không cần thiết có nghĩa là "cú pháp gần". Thứ hai, không gian biểu diễn vector mã nguồn là một không gian chiều cao. Ví dụ, CodeBERT tạo thành một không gian 768 chiều nhưng khoảng cách nút trong AST là một không gian chiều thấp. Do đó, các metric khoảng cách truyền thống được sử dụng trong những công trình này sẽ không hoạt động tốt do lời nguyền của chiều cao [1,52]. Đầu tiên, việc ánh xạ khoảng cách từ không gian chiều cao xuống không gian chiều thấp có thể không chính xác tức là khoảng cách nhỏ hơn trong AST có thể không chắc chắn biểu diễn khoảng cách euclid nhỏ hơn trong không gian chiều cao. Thứ hai, một khoảng cách cạnh nhỏ giữa hai nút trong AST không đảm bảo mối quan hệ cú pháp gần. Sự thiên lệch này có thể làm cho kết luận và phương pháp của họ không tổng quát và có thể cản trở hiểu biết của chúng ta về cách các mô hình mã nguồn

¹https://github.com/Marvinmw/probing_analysis_tosem.git

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 5 ---
Khám Phá Các Mô Hình Tiền Huấn Luyện Mã Nguồn: Nghiên Cứu Khả Năng Cú Pháp và Ngữ Nghĩa 111:5

[Hình 1 và 2 cho thấy một ví dụ về đoạn mã đơn giản với AST và khoảng cách Euclid của biểu diễn token]

mã hóa cú pháp. Cũng như, nó ước tính sai tương tự cú pháp mã nguồn và có thể dẫn đến thiếu phân tích cấu trúc cú pháp cho các mô hình mã nguồn. Kết luận có thể không hữu ích để cải thiện hiệu suất mô hình. Chúng tôi cung cấp hai ví dụ để minh họa tốt hơn.

Hình 1 là ví dụ đầu tiên và cung cấp một visualisation của một hàm được phân tích thành AST. Chúng ta có thể thấy rằng khoảng cách nút giữa biến "a" và "b" từ điều kiện if (được đánh dấu trong ô vuông xanh lá) là 2 bước nhảy trong khi khoảng cách nút giữa biến "a" này (ô vuông xanh lá) và biến "a" (ô vuông cam) từ câu lệnh return là 4 bước nhảy. Do đó, chúng ta có thể thấy rằng trong không gian chiều thấp, biến "a" từ điều kiện if gần với biến "b" và chúng gần hơn về cú pháp so với biến "a" từ câu lệnh return. Tuy nhiên, kết luận ngược lại trong không gian chiều cao. Chúng tôi mã hóa hàm này bằng CodeBERT và tính khoảng cách euclid giữa các biểu diễn vector token cho những biến này. Như được hiển thị trong Hình 2, chúng ta có thể thấy rằng khoảng cách từ biến "a" (ô vuông xanh lá) đến biến "b" (ô vuông xanh lá) từ điều kiện if là 85.45 trong khi khoảng cách từ nó đến biến "a" (ô vuông cam) từ câu lệnh return là 65.78. Do đó, thông qua ví dụ này, chúng tôi thấy rằng các khoảng cách trong không gian thấp và không gian cao không nhất quán, và chúng có thể không có mối quan hệ tích cực.

Đối với ví dụ khác, Hình 3 thể hiện rằng biến đối số hàm "b" có 4 bước nhảy đến "return" trong câu lệnh cuối cùng của hàm này, và nó chia sẻ cùng khoảng cách với biến đối số hàm "c". Tuy nhiên, "b" nên gần hơn về cú pháp với "c" vì chúng là các đối số hàm.

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 6 ---
111:6 W. Ma, S. Liu và M. Zhao cùng cộng sự.

Hơn nữa, những công trình này chủ yếu tập trung vào khám phá khả năng của các mô hình tiền huấn luyện mã nguồn trong việc học cú pháp mã nguồn. Các thảo luận sâu về ngữ nghĩa mã nguồn đã học (ví dụ: phân tích phụ thuộc điều khiển/dữ liệu) đang thiếu. Troshin và Chirkova [66] sử dụng một số nhiệm vụ liên quan đến ngữ nghĩa trong khi chúng không chỉ liên quan đến một thuộc tính mã nguồn duy nhất mà thường được yêu cầu bởi phân tích thăm dò, sự đa dạng của ngữ nghĩa chương trình cũng bị bỏ qua và thiếu phân tích sâu. Thảo luận về ngữ nghĩa mã nguồn là một phần thiết yếu và không thể bỏ qua vì nó tạo thành nền tảng cho nhiều nhiệm vụ liên quan đến mã nguồn [9, 36, 38, 39, 80]. Những công trình này cũng thiếu phân tích về LLMs.

Để khắc phục những vấn đề trên, chúng ta cần khám phá các phương pháp tốt hơn mà không có giả định rằng số lượng cạnh giữa các nút có liên quan đến cú pháp mã nguồn. Mã nguồn là một cấu trúc dữ liệu rất đặc biệt. Trước hết, nó có một định nghĩa cú pháp nghiêm ngặt; tất cả mã nguồn phải tuân thủ những quy tắc cú pháp này. Tất cả tên được sử dụng trong mã nguồn chỉ cần tuân theo các quy tắc đặt tên cụ thể. Tuy nhiên, để thuận tiện cho việc đọc của con người, con người thường chú thích mã nguồn bằng tên để dễ đọc và hiểu. Những quy tắc cú pháp này có thể được biểu đạt một cách có cấu trúc bằng cây cú pháp trừu tượng (AST). Dựa trên những quy tắc cú pháp được định nghĩa này, mã nguồn cũng biểu đạt thông tin ngữ nghĩa sâu hơn. Mã nguồn có chức năng nhất định, có thể thực thi, và triển khai logic cụ thể. Thông tin ngữ nghĩa này bao gồm luồng điều khiển, luồng dữ liệu, và các phụ thuộc. Hầu như tất cả các vấn đề liên quan đến mã nguồn đều yêu cầu thông tin này để giải quyết. Luồng điều khiển mô tả logic cụ thể của mã nguồn, biểu đạt chức năng được triển khai bởi mã nguồn. Luồng dữ liệu và các phụ thuộc biểu đạt mối liên kết ngữ nghĩa giữa các phần khác nhau của mã nguồn. Chúng rất quan trọng cho chất lượng mã nguồn, và phát hiện và sửa chữa lỗ hổng khuyết tật. Chúng ta có thể thấy rằng AST, Đồ thị Luồng Điều khiển (CFG), Đồ thị Phụ thuộc Điều khiển (CDG), và Đồ thị Phụ thuộc Dữ liệu (DDG) là các biểu đạt có cấu trúc của cú pháp và ngữ nghĩa mã nguồn. Các token mã nguồn có các mối quan hệ hoặc thuộc tính cú pháp và ngữ nghĩa khác nhau dựa trên những cấu trúc này. Những mối quan hệ và thuộc tính này quan trọng để hiểu mã nguồn và nên được biểu diễn trong không gian vector đã học của các mô hình mã nguồn. Khả năng của một mô hình mã nguồn là ánh xạ các đặc tính của mã nguồn vào không gian vector. Đối với một mô hình mã nguồn tốt, không gian đặc tính của nó nên giữ tất cả các đặc tính của mã nguồn càng nhiều càng tốt. Các nhiệm vụ thăm dó mà chúng tôi thiết kế là để tái tạo những mối quan hệ cấu trúc dữ liệu này trong không gian đặc tính vector.

Do đó, cho phân tích cú pháp, chúng tôi cố gắng tái tạo AST (dự đoán cặp nút cú pháp) và dự đoán nhãn cú pháp của các token mã nguồn (gắn thẻ cú pháp token). AST mang tất cả thông tin cú pháp của mã nguồn. Dự đoán cặp nút cú pháp có thể phản ánh cách các mô hình mã nguồn học cấu trúc cú pháp bằng cách tái tạo AST trong không gian biểu diễn. Gắn thẻ cú pháp token là để xem liệu vai trò cú pháp của mỗi token có được mã hóa trong biểu diễn hay không, đây là một thuộc tính cú pháp vi mô. Cả hai đều quan trọng đối với các mô hình mã nguồn để học cú pháp mã nguồn. Cho phân tích ngữ nghĩa, chúng tôi tái tạo cấu trúc ngữ nghĩa mã nguồn (dự đoán lan truyền ngữ nghĩa) bao gồm đồ thị phụ thuộc điều khiển (CDG), đồ thị phụ thuộc dữ liệu (DDG) và đồ thị luồng điều khiển (CFG). Chúng tôi cũng bao gồm phụ thuộc điều khiển và dữ liệu với khoảng cách dài (dự đoán lan truyền ngữ nghĩa). Ba cấu trúc ngữ nghĩa, CDG, DDG và CFG, là các khái niệm cốt lõi trong phân tích chương trình, tối ưu hóa, thanh công cụ, và các nhiệm vụ kỹ thuật phần mềm khác nhau. Phụ thuộc dài là một đặc tính đặc biệt của chương trình. Một người có thể khai báo một biến ở đầu nhưng sử dụng nó sau hàng trăm dòng. Hiểu chúng quan trọng đối với các mô hình mã nguồn. Chi tiết có thể được tìm thấy trong Mục 3.

3 PHƯƠNG PHÁP LUẬN
Trong mục này, chúng tôi giới thiệu phân tích của chúng tôi về các phương pháp thăm dò cho cú pháp và ngữ nghĩa mã nguồn.

3.1 Kiến Thức Sơ Bộ
Các nhà nghiên cứu kỹ thuật phần mềm ban đầu đã sử dụng kỹ thuật đặc tính dựa trên kiến thức thực nghiệm chuyên gia để trích xuất các đặc tính mã nguồn làm đầu vào cho các thuật toán học máy. Thông thường, các chuyên gia thiết kế các quy tắc trích xuất đặc tính dựa trên các nhiệm vụ cụ thể cần giải quyết, như số lượng vòng lặp và độ phức tạp mã nguồn. Những đặc tính dựa trên quy tắc này có tính diễn giải cao nhưng bị hạn chế bởi kinh nghiệm của các chuyên gia và không thể bao phủ cấu trúc cú pháp và ngữ nghĩa mã nguồn. Trong những năm gần đây, với sự trỗi dậy của Transformer và sự xuất hiện của CodeBERT, các nhà nghiên cứu kỹ thuật phần mềm có thể trích xuất các đặc tính mã nguồn dựa trên khả năng mã hóa của các mô hình tiền huấn luyện, giảm đáng kể sự phụ thuộc vào kinh nghiệm và kiến thức chuyên gia. Transformer với kiến trúc encoder-decoder được đề xuất vào năm 2017 [68]. Encoder và decoder được xếp chồng bởi nhiều lớp encoder và decoder tương ứng. Cả hai đều chứa các cơ chế tính toán và phân phối attention phức tạp. Sự khác biệt giữa lớp encoder và lớp decoder là lớp encoder xem xét ngữ cảnh của mô hình; lớp decoder chỉ xem xét ngữ cảnh đầu ra của mô hình. Các mô hình tiền huấn luyện mã nguồn sẽ sử dụng dữ liệu mã nguồn khổng lồ được thu thập từ Internet như GitHub và Stack Overflow. Các mô hình tiền huấn luyện mã nguồn có thể được nhóm thành ba nhóm liên quan đến kiến trúc mạng của chúng. Nhóm đầu tiên sử dụng transformer encoder như CodeBERT. Nhóm thứ hai sử dụng transformer decoder như CodeGPT. Nhóm thứ ba sử dụng transformer encoder-decoder như CodeT5.

Trước khi tiền huấn luyện, chúng ta cần đào tạo một tokenizer dựa trên văn bản mã nguồn để học cách phân đoạn văn bản mã nguồn, như thuật toán tokenization Byte-Pair Encoding (BPE)². Khi sử dụng Transformer để học đặc tính, mã nguồn văn bản gốc sẽ được tokenize và chúng ta sẽ nhận được một chuỗi các token mã nguồn. Sau đó, chúng tôi chuyển đổi nó thành chỉ số tương ứng trong lớp embedding. Điều này hoàn thành việc chuyển đổi từ mã nguồn thô sang vector. Mô hình sau đó được tối ưu hóa dựa trên paradigm đào tạo được triển khai. So với các mô hình tiền huấn luyện truyền thống, LLM cũng là một kiến trúc transformer nhưng có số lượng tham số khổng lồ và lượng dữ liệu đào tạo khổng lồ. LLM được căn chỉnh với sở thích của con người. Vì việc điều chỉnh toàn bộ tham số của LLM rất đắt đỏ, chúng ta thường sử dụng LoRA [22], học few-shot và điều chỉnh prompt để giải quyết các nhiệm vụ downstream. Một số nghiên cứu cho thấy rằng nó có khả năng đột sinh và tổng quát hóa [72]. Các nhà nghiên cứu trong kỹ thuật phần mềm đã phát hiện rằng các mô hình lớn có khả năng tạo và phân tích mã nguồn tốt [10, 11, 76].

Các phương pháp trích xuất đặc tính dựa trên các mô hình mã nguồn có một tiền đề: các đặc tính cấu trúc của mã nguồn được bao gồm trong không gian đặc tính của mô hình mã nguồn. Các paradigm đào tạo mô hình mã nguồn chủ đạo hiện tại dựa trên masked language modelling (MLM), causal language modelling (CLM) và các biến thể khác của hai cái trước. Nói đơn giản, MLM có nghĩa là che ngẫu nhiên các token mã nguồn và sau đó phục hồi chúng. Sự khác biệt là CLM dự đoán token tiếp theo dựa trên phần trên. Những phương pháp tiền huấn luyện này không được thích ứng để học các đặc tính mã nguồn. Trong hầu hết tất cả các trường hợp, chúng tôi chuyển đổi mã nguồn thành định dạng văn bản mà chúng yêu cầu. Việc phân tích và hiểu không gian đặc tính của các mô hình mã nguồn là một thách thức.

3.2 Mô Hình Phân Tích Thăm Dò
Phân tích thăm dò là một phương pháp nghiên cứu được sử dụng để hiểu và đánh giá kiến thức và mã hóa thông tin trong các mô hình ngôn ngữ. Phương pháp phân tích này tiết lộ việc nắm vững của mô hình đối với các loại thông tin ngôn ngữ cụ thể trong quá trình học của nó bằng cách thiết kế và áp dụng một loạt các nhiệm vụ thăm dò. Các nhiệm vụ thăm dò thường là các nhiệm vụ đơn giản, có mục tiêu được thiết kế cụ thể để kiểm tra sự hiểu biết của mô hình về một thuộc tính ngôn ngữ cụ thể, như cấu trúc ngữ pháp, ý nghĩa từ, và mối quan hệ câu. Trong nghiên cứu của chúng tôi, cho tất cả các nhiệm vụ thăm dò được thiết kế, chúng tôi sử dụng bộ phân loại thăm dò cạnh [64] như được mô tả trong Hình 4. Phù hợp với các công trình trước [6,55,64,67] trong tài liệu thăm dò, chúng tôi giữ các tham số của các mô hình tiền huấn luyện mã nguồn cố định, có nghĩa là chúng sẽ không được cập nhật trong quá trình đào tạo. Đối với một đầu vào mã nguồn 𝑥 cho trước, chúng tôi sử dụng một tokenizer để tokenize 𝑥 thành một chuỗi token với hai token bắt đầu và kết thúc đặc biệt như được ký hiệu ở dưới cùng của Hình 4.

²https://huggingface.co/learn/nlp-course/en/chapter6/5

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 8 ---
111:8 W. Ma, S. Liu và M. Zhao cùng cộng sự.

[Hình 3 và 4 hiển thị ví dụ về Dự đoán Cặp Nút Cú pháp và mô hình phân tích]

Ban đầu, chúng ta có thể thu được biểu diễn ngữ cảnh 𝑟𝑖 của mỗi lớp ẩn cho mỗi token 𝑥𝑖 từ các mô hình mã nguồn. Tiếp theo, chúng tôi trích xuất các đoạn token mã nguồn cụ thể được liên kết với nút đồ thị hoặc cây mà chúng tôi quan tâm, và chúng được ký hiệu là 𝑠1 và 𝑠2 trong Hình 4. Một đoạn token mã nguồn biểu diễn một đoạn mã nguồn từ một nút trong AST hoặc đồ thị phụ thuộc. Độ dài của một đoạn token khác nhau và có thể chứa số lượng token khác nhau. Sau đó, những đoạn token này được truyền qua một attention pool, ánh xạ chúng thành một vector có kích thước cố định. Attention pool là một lớp attention có thể tự động gán trọng số khác nhau cho mỗi biểu diễn token trong đoạn token, và sau đó tổng hợp chúng. Cuối cùng, vector kết quả được chuyển tiếp đến bộ phân loại thăm dò, được triển khai như một bộ phân loại multi-layer perceptron (MLP) để phân loại. Bộ phân loại MLP có thể đào tạo và được ký hiệu bằng ký hiệu 𝐶. Các vector đặc tính có kích thước cố định của hai đoạn token phục vụ như đầu vào cho 𝐶, và bộ phân loại xác định xem hai đoạn token có mối quan hệ cú pháp hoặc ngữ nghĩa hay không. Chúng tôi sử dụng các đoạn token vì các đoạn mã nguồn liên quan về mặt cú pháp hoặc ngữ nghĩa được tokenize thành hai danh sách token với độ dài khác nhau, tương ứng. Những danh sách token này được gọi là các đoạn token, sau đó được chuyển đổi thành vector có kích thước cố định bởi attention pool.

3.3 Thăm Dò Cú Pháp
Để giải quyết những sự không chính xác tiềm năng do việc chuyển đổi không gian chiều cao sang không gian chiều thấp, cũng như thiếu mối quan hệ có thể có giữa khoảng cách trong AST và khoảng cách cú pháp như được chỉ ra trong phần động lực, chúng tôi giới thiệu hai nhiệm vụ thăm dò cú pháp: dự đoán cặp-nút-cú pháp và gắn thẻ-cú pháp-token. Những nhiệm vụ này trực tiếp dự đoán các thuộc tính của các nút trong AST. Hai nhiệm vụ bổ sung cho nhau. Nhiệm vụ đầu tiên nhằm dự đoán mối quan hệ kết nối-cú pháp giữa các token mã nguồn, trong khi nhiệm vụ thứ hai tập trung vào kiểm tra vai trò cú pháp của các token mã nguồn riêng lẻ. Các token mã nguồn là những từ mã nguồn cơ bản sau khi mã nguồn được tokenize và mỗi nút chứa ít token mã nguồn. Thông qua nhiệm vụ đầu tiên, chúng ta có thể tái tạo AST cho biểu diễn token mã nguồn từ các mô hình mã nguồn. Nếu các biểu diễn token mã nguồn không chứa thông tin về cấu trúc AST, việc tái tạo AST là không thể. Thông qua nhiệm vụ thứ hai, chúng ta có thể tìm ra liệu các biểu diễn token mã nguồn có chứa các quy tắc cú pháp tương ứng được gán bởi các quy tắc ngôn ngữ lập trình hay không.

3.3.1 Dự Đoán Cặp Nút Cú Pháp. Cho một mã nguồn, chúng ta có thể phân tích nó để thu được AST và tiếp tục chia AST này thành các cây con khác nhau. Mỗi cây con là một biểu thức cú pháp từ mã nguồn gốc và chúng tôi đặt tên nó là một đơn vị cú pháp. Bởi vì mỗi đơn vị cú pháp biểu diễn một biểu thức cú pháp hoàn chỉnh từ mã nguồn, do đó các nút trong một đơn vị gần nhau về cú pháp. Nhiệm vụ này được thiết kế để dự đoán bất kỳ cặp nút nào trong AST thuộc về một cây con. AST được tạo bởi bộ phân tích cú pháp và chứa tất cả thông tin cú pháp của mã nguồn. Đối với các mô hình mã nguồn, chúng nên giữ lại cấu trúc cú pháp như vậy trong không gian vector. Nếu chúng không thể, điều đó cho thấy mô hình không có khả năng mã hóa cú pháp mã nguồn hiệu quả. Thông qua nhiệm vụ này, chúng tôi nhằm xác minh xem mô hình mã nguồn có thể nắm bắt và hiểu cấu trúc cú pháp này từ mã nguồn, và sau đó tái tạo thông tin cú pháp trong không gian vector mà nó biểu diễn hay không. Cụ thể, chúng tôi trình bày một ví dụ để minh họa tốt hơn. Như được hiển thị trong Hình 3, có một hàm có AST tương ứng được trình bày ở phía bên phải. Đối với AST này, chúng tôi chia nó thành các đơn vị khác nhau được đánh dấu với các màu khác nhau. Ví dụ, nút "=" trong đơn vị đỏ, nên gần về cú pháp với nút bên trái của nó trong đơn vị này tức là nút "int" và "a". Do đó, chúng được gắn nhãn 1 như các mẫu tích cực. Đối với các nút "int" và "a" trong đơn vị khác (được đánh dấu màu xanh lá), vì chúng thuộc về đơn vị khác, chúng được gắn nhãn 0 như các mẫu tiêu cực. Chính thức, nhiệm vụ này có thể được công thức hóa như sau:

𝐶(𝑛0,𝑛1)=(
1𝑛0∈𝑇𝑖∩𝑛1∈𝑇𝑖
0𝑛0∈𝑇𝑖∩𝑛1∈𝑇𝑗

trong đó 𝑇𝑖 và 𝑇𝑗 (𝑖≠𝑗) là hai đơn vị cú pháp khác nhau trong AST và 𝑛0 và 𝑛1 là các nút trong đơn vị. Chúng tôi đào tạo một bộ phân loại thăm dò nhị phân 𝐶 để học xem bất kỳ cặp nút nào có gần nhau về cú pháp hay không dựa trên các biểu diễn nút được tính từ biểu diễn token của các mô hình mã nguồn bởi attention pool (Hình 4).

3.3.2 Gắn Thẻ Cú Pháp Token. Nhiệm vụ đầu tiên kiểm tra sự tương tự cú pháp giữa các nút AST khác nhau. Ngoài sự tương tự cú pháp, tất cả các token được gán một vai trò cú pháp bởi các quy tắc ngôn ngữ lập trình. Để kiểm tra xem các mô hình mã nguồn có thể học vai trò cú pháp token riêng lẻ hay không, chúng tôi đề xuất một nhiệm vụ phân loại đa lớp, cụ thể là gắn thẻ cú pháp token, và nhiệm vụ này yêu cầu biểu diễn mã nguồn tốt hơn và chi tiết hơn để gắn thẻ vai trò cú pháp của mỗi token mã nguồn. Điều này được thiết kế để thách thức và đánh giá độ sâu hiểu biết về ngôn ngữ lập trình cho các mô hình mã nguồn. Một mô hình mã nguồn có thể thực hiện thành công gắn thẻ cú pháp token có thể hữu ích hơn trong các ứng dụng lập trình phức tạp, như tạo mã nguồn.

Vì mỗi nút AST có loại nút của nó, một ý tưởng trực tiếp là sử dụng loại nút để gắn thẻ. Tuy nhiên, những nhãn cú pháp này rất trừu tượng, ví dụ, tên biến được gắn nhãn "identifier" bởi quy tắc cú pháp, nhưng nó có ý nghĩa cú pháp khác nhau trong ngữ cảnh. Nếu nó ở trong khai báo hàm, nó thực sự là một đối số cho hàm này; tương tự, nếu nó ở trong việc gọi lớp, nó là một thuộc tính lớp. Do đó, chúng ta cần thiết kế các nhãn cụ thể cho những token trừu tượng này. Chúng tôi ban đầu xem xét loại cú pháp của các nút lá trong AST. Tiếp theo, chúng tôi tham khảo các loại của các nút cha của chúng để xây dựng các nhãn cụ thể. Cụ thể, chúng tôi thiết kế 36 nhãn gắn thẻ cho Java và 33 nhãn cho C/C++. Chúng tôi lọc các nhãn có tần số thấp (𝑓𝑟𝑒<200) cho Java250 và POJ-104. Các nhãn chúng tôi sử dụng được mô tả trong Bảng 1.

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 10 ---
111:10 W. Ma, S. Liu và M. Zhao cùng cộng sự.

Bảng 1. Các nhãn của Gắn Thẻ Cú Pháp Token cho Java250 và POJ-104.

Java250
modifiers local_variable_declaration variable_declarator formal_parameters
array_type dimensions formal_parameter block
object_creation_expression argument_list field_access integral_type
method_invocation while_statement parenthesized_expression if_statement
expression_statement break_statement update_expression assignment_expression
identifier for_statement binary_expression return_statement
array_creation_expression dimensions_expr array_access ERROR
unary_expression throw_statement enhanced_for_statement ternary_expression
cast_expression generic_type type_arguments array_initializer

POJ-104
declaration array_declarator function_definition parameter_list
parameter_declaration compound_statement for_statement assignment_expression
binary_expression update_expression subscript_expression expression_statement
if_statement parenthesized_expression return_statement call_expression
argument_list string_literal pointer_expression init_declarator
function_declarator cast_expression type_descriptor break_statement
comma_expression initializer_list char_literal pointer_declarator
continue_statement while_statement field_expression sizeof_expression
case_statement

[Hình 5 và Bảng 2 minh họa ví dụ Gắn Thẻ Cú Pháp Token]

Chúng tôi trình bày một ví dụ với nhãn cú pháp tương ứng trong Hình 5. Thông tin chi tiết của các nhãn trong ví dụ này được hiển thị trong Bảng 2. Cụ thể, chúng ta có thể thấy rằng các token "(" và ")" có các nhãn cú pháp khác nhau trong các ngữ cảnh khác nhau. Dấu ngoặc đơn "( )" được gắn nhãn "PE" trong điều kiện if, trong khi dấu ngoặc đơn "( )" từ việc gọi phương thức được gắn nhãn "AL". Chúng tôi thiết kế nhiệm vụ này để khám phá xem những mô hình này có thể học cú pháp mã nguồn đúng cách từ ngữ pháp lập trình hay không.

3.4 Thăm Dò Ngữ Nghĩa
Các công trình trước chủ yếu tập trung vào phân tích khả năng của các mô hình tiền huấn luyện mã nguồn trong việc học cú pháp mã nguồn. Tuy nhiên, việc phân tích ngữ nghĩa mã nguồn cũng thiết yếu. Nhóm này đánh giá khả năng của mô hình mã nguồn hiểu ý nghĩa và hành vi của các đoạn mã nguồn. Trong mục này, chúng tôi đề xuất hai nhiệm vụ thăm dò để phân tích ngữ nghĩa của mã nguồn đã học. Đầu tiên là dự đoán quan hệ ngữ nghĩa cho các đồ thị phụ thuộc (CDG, DDG và CFG). Dựa trên dự đoán, chúng ta có thể tái tạo cấu trúc của các đồ thị phụ thuộc. Các đồ thị phụ thuộc mô tả các mối quan hệ phức tạp như phụ thuộc điều khiển và dữ liệu, quan trọng để hiểu cách các phần khác nhau của chương trình tương tác. Nhiệm vụ thứ hai là dự đoán lan truyền ngữ nghĩa. Hiểu luồng điều khiển và dữ liệu là một khía cạnh tiên tiến hơn của phân tích ngữ nghĩa, vượt ra ngoài phân tích tĩnh để xem chương trình sẽ hoạt động như thế nào khi chạy. Nhiệm vụ này đánh giá khả năng của các mô hình mã nguồn hiểu bản chất động của việc thực thi mã nguồn.

3.4.1 Dự Đoán Quan Hệ Ngữ Nghĩa. Các đồ thị phụ thuộc của một chương trình có thể biểu diễn tốt ngữ nghĩa mã nguồn [20]. Tương tự như nhiệm vụ dự đoán cặp nút cú pháp trong Mục 3.3.1, chúng tôi cũng trích xuất đồ thị phụ thuộc điều khiển (CDG), đồ thị phụ thuộc dữ liệu (DDG) và đồ thị luồng điều khiển (CFG) để dự đoán xem các mô hình mã nguồn có thể học ngữ nghĩa mã nguồn hay không. Trong Đồ thị Phụ thuộc Điều khiển (CDG), Đồ thị Phụ thuộc Dữ liệu (DDG), và Đồ thị Luồng Điều khiển (CFG) được xây dựng, mỗi nút có một thuộc tính với một đoạn mã nguồn có thể được tokenize thành nhiều token. Chúng tôi gọi những token mã nguồn này được dẫn xuất từ cùng một nút là đoạn token. Chúng tôi thống nhất những nhiệm vụ này thành một meta nhiệm vụ cụ thể là dự đoán quan hệ ngữ nghĩa. Chính thức, nhiệm vụ này có thể được công thức hóa như sau:

𝐶(𝑠0,𝑠1)=(
1∃𝑒∈𝐺, 𝑠0∈𝑁𝑖∩𝑠1∈𝑁𝑗∩{𝑁𝑖𝑒−→𝑁𝑗}
0∀𝑒∈𝐺, 𝑠0∈𝑁𝑖∩𝑠1∈𝑁𝑗∩{𝑁𝑖̸𝑒−→𝑁𝑗}

trong đó 𝑁𝑖, 𝑁𝑗 là nút thứ 𝑖 và nút thứ 𝑗 trong đồ thị được xây dựng 𝐺∈{𝐶𝐷𝐺,𝐷𝐷𝐺,𝐶𝐹𝐺} và mỗi nút chứa một đoạn token từ mã nguồn gốc. 𝑠0 và 𝑠1 biểu thị các đoạn token tương ứng của mã nguồn gốc trong các nút 𝑁𝑖 và 𝑁𝑗 sau tokenization. 𝑒−→ có nghĩa là có một cạnh giữa hai nút.

Hình 6a, Hình 6b và Hình 6c thể hiện các ví dụ cho ba mối quan hệ ngữ nghĩa. Hình 6a cho thấy một ví dụ phụ thuộc điều khiển. Nút 𝑁4 phụ thuộc điều khiển vào nút 𝑁3. Dựa trên sự thật này, chúng tôi gắn nhãn rằng đoạn token từ 𝑁3 phụ thuộc điều khiển vào đoạn token trong 𝑁4. Hình 6b minh họa một ví dụ phụ thuộc dữ liệu. Nút 𝑁4 phụ thuộc dữ liệu vào nút 𝑁1. Hình 6c cho thấy một ví dụ của đồ thị luồng điều khiển. Chúng ta có một số sự thật thứ tự thực thi như nút 𝑁2 được thực thi sau 𝑁1 ngay lập tức. Đoạn token của 𝑁2 có mối quan hệ luồng điều khiển với đoạn token của 𝑁1.

3.4.2 Dự Đoán Lan Truyền Ngữ Nghĩa. Thông tin luồng dữ liệu được lan truyền trong đồ thị phụ thuộc. Hai nút với khoảng cách dài có thể phụ thuộc dữ liệu một cách ngầm định. Đó là một sự thật rằng bất kỳ sửa đổi nào trong đồ thị phụ thuộc có thể ảnh hưởng đến đầu ra chương trình. Lan truyền luồng phụ thuộc ngầm định là một ngữ nghĩa chương trình quan trọng. Nhiệm vụ lan truyền ngữ nghĩa (bí danh inGraph) được định nghĩa bởi

𝐶(𝑠0,𝑠1)=(
1𝑠0∈𝑁𝑖∩𝑠1∈𝑁𝑗∩𝑁𝑖∈𝐺∩𝑁𝑗∈𝐺
0𝑠0∈𝑁𝑖∩𝑠1∈𝑁𝑗∩𝑁𝑖∈𝐺∩𝑁𝑗∉𝐺

trong đó G∈{𝐶𝐷𝐺,𝐷𝐷𝐺}, 𝑠0 và 𝑠1 là các đoạn token trong các nút của 𝐺. Hình 6d cho thấy một ví dụ. Hộp bóng đổ làm nổi bật các câu lệnh với mối quan hệ phụ thuộc điều khiển. Chúng tôi mong đợi bộ phân loại thăm dò có thể nhận ra rằng câu lệnh "printf" không nằm trong đồ thị điều khiển phụ thuộc.

3.5 Phân Tích Attention
Chúng tôi tiến hành phân tích các trọng số attention trong mỗi self-attention head, dựa trên các mối quan hệ ngữ nghĩa chương trình 𝐺∈{𝐶𝐹𝐺,𝐷𝐷𝐺,𝐶𝐷𝐺} từ Mục 3.4.1. Đối với một đoạn token nút cho trước 𝑠𝑖 trong đó 𝑖 là nút thứ 𝑖 và một loại mối quan hệ ngữ nghĩa 𝐺, chúng tôi nhóm các token đầu vào còn lại thành hai tập: 𝑅0 và 𝑅1. 𝑅1 bao gồm tất cả các token có mối quan hệ ngữ nghĩa với 𝑠𝑖 trong khi các token còn lại tạo thành tập 𝑅0. Sau đó chúng tôi chia các trọng số attention của một attention head liên quan đến 𝑠𝑖 thành hai tập, được ký hiệu là 𝑊0 và 𝑊1, dựa trên 𝑅0 và 𝑅1. Chúng tôi kiểm tra sự khác biệt của các phân phối attention giữa hai tập. Bởi vì chúng tôi muốn biết tập nào đóng góp nhiều hơn cho biểu diễn mã nguồn, chúng tôi so sánh tính trung tâm phân phối của hai tập attention. Nếu tổng của các trọng số attention trong 𝑊1 từ một attention head cụ thể lớn hơn tổng của các trọng số attention trong 𝑊0, điều đó chỉ ra rằng attention head này đóng góp nhiều hơn cho việc học ngữ nghĩa mã nguồn và chúng tôi ký hiệu nó là semantic attention head. Để xác định ý nghĩa thống kê, chúng tôi áp dụng paired t-test với kích thước mẫu lớn cho mỗi loại ngữ nghĩa 𝐺. Chúng tôi công thức hóa giả thuyết null 𝐻0: 𝜇𝑑=0, trong đó 𝜇𝑑 biểu thị sự khác biệt trung bình thực giữa 𝑊1 và 𝑊0. Giả thuyết thay thế 𝐻1: 𝜇𝑑>0 cho thấy rằng có một sự khác biệt trung bình tích cực (𝑊1 lớn hơn 𝑊0). Bằng cách tiến hành thử nghiệm này, chúng ta có thể xác định liệu attention head có đóng góp nhiều hơn cho việc học ngữ nghĩa mã nguồn hay không. Phân tích cấp độ head này cung cấp hiểu biết chi tiết hơn về self-attention. Tổng cộng, chúng tôi phân tích hơn 10,000 đầu vào ngữ nghĩa cho 4 mô hình tiền huấn luyện mã nguồn và chọn ngẫu nhiên 100 đầu vào ngữ nghĩa cho ba LLMs.

4 THIẾT LẬP ĐÁNH GIÁ
Trong mục này, chúng tôi giới thiệu thiết lập đánh giá, bao gồm tiền xử lý dữ liệu, các mô hình đánh giá, và các metric đánh giá.

4.1 Tập Dữ Liệu và Tiền Xử Lý
Chúng tôi sử dụng hai tập dữ liệu, cụ thể là Java250 [56] và POJ-104 [53] cho nghiên cứu của chúng tôi. Chất lượng của dữ liệu có tác động đáng kể đến phân tích thăm dò. Chúng tôi tuân theo các bước tiền xử lý được phác thảo trong Hình 7 để tạo dữ liệu thăm dò cú pháp và ngữ nghĩa chất lượng cao. Mã nguồn được tái cấu trúc bằng công cụ google-java-format³ và công cụ clang-refactor⁴. Tái cấu trúc mã nguồn đảm bảo tính dễ đọc và tạo điều kiện cho việc căn chỉnh token giữa các đồ thị và đầu vào mô hình. Để đảm bảo độ chính xác của kết quả, chúng tôi sử dụng framework phân tích tĩnh Joern và bộ phân tích AST⁵ để trích xuất các đồ thị chương trình và AST. Trong trường hợp các đồ thị chương trình, chúng tôi hợp nhất các nút dư thừa nếu mã nguồn của một nút là tập con của các nút lân cận. Sau đó chúng tôi trích xuất các mối quan hệ cú pháp và ngữ nghĩa giữa các token mã nguồn và xây dựng các tập dữ liệu thăm dò.

4.2 Các Mô Hình Thực Nghiệm
Chúng tôi chọn 7 mô hình mã nguồn phổ biến với các kiến trúc đa dạng (transformer encoder, transformer decoder, và transformer encoder-decoder) được sử dụng rộng rãi trong kỹ thuật phần mềm. 7 mô hình được xây dựng bởi các công ty hoặc tổ chức có uy tín: Microsoft, Meta, Salesforce, và Huggingface. Tất cả đều có số lượng tải xuống lớn trên Huggingface, và các bài báo tương ứng của chúng mỗi cái có hơn 150 trích dẫn. Đầu tiên, chúng tôi tiến hành thực nghiệm sử dụng bốn mô hình tiền huấn luyện, CodeBERT (CB) [13], GraphCodeBERT (GCB) [17], UnixCoder (UC) [16] và CodeT5 (CT) [71]. CodeBERT và GraphCodeBERT sử dụng Transformer encoder, trong khi GraphCodeBERT kết hợp thông tin luồng dữ liệu bổ sung. UnixCoder sử dụng các ma trận mask attention với prefix adapters để hỗ trợ học encoder, decoder, và encoder-decoder. CodeT5 sử dụng kiến trúc Transformer encoder-decoder. Đối với CodeT5, chúng tôi xem xét encoder của nó, có thể được so sánh với các mô hình tiền huấn luyện khác trong cùng kiến trúc. Những mô hình này có 12 lớp Transformer encoder (được ký hiệu là Layer 1-Layer 12) cộng với một lớp embedding (được ký hiệu là Layer 0). Chúng tôi áp dụng các nhiệm vụ thăm dò của chúng tôi cho mỗi lớp encoder và lớp embedding. Điều này giúp chúng tôi hiểu vai trò của mỗi lớp. Thứ hai, chúng tôi cũng nghiên cứu 3 mô hình ngôn ngữ lớn (LLMs), CodeLlama-7b [58] (CL), StarCoder [34] (SC) và CodeT5+ [70] (CodeT5p-770m) (CT5P+) sử dụng tập dữ liệu Java. CodeLlama-7b có 32 lớp ẩn và StarCoder có 40 lớp ẩn. Cả hai đều sử dụng transformer decoder. CodeT5p-770m có 24 lớp encoder ẩn và 24 lớp decoder ẩn. Đây là một mô hình ngôn ngữ lớn mã nguồn mở dựa trên cấu trúc encoder-decoder cho họ CodeT5+ [70]. Tất cả các thực nghiệm được lặp lại 3 lần với các random seed khác nhau.

4.3 Các Metric Đánh Giá
Chúng tôi sử dụng hệ số tương quan Matthew (MCC) [50] làm metric đánh giá. MCC là một thay thế đáng tin cậy cho điểm F1 đối với phân loại nhị phân [5,74], và nó xem xét toàn bộ ma trận nhầm lẫn. MCC có thể được tính từ ma trận nhầm lẫn,

𝑀𝐶𝐶=𝑇𝑃×𝑇𝑁−𝐹𝑃×𝐹𝑁/√((𝑇𝑃+𝐹𝑃)·(𝑇𝑃+𝐹𝑁)·(𝑇𝑁+𝐹𝑃)·(𝑇𝑁+𝐹𝑁))

trong đó TP là true positive, TN là true negative, FP là false positive và FN là false negative. Đối với gắn thẻ cú pháp token, đây là phân loại đa lớp và chúng tôi cũng hiển thị điểm macro F1 của nó,

Macro F1 = (1/𝑁) Σᵢ₌₁ᴺ (2×Precisionᵢ×Recallᵢ)/(Precisionᵢ+Recallᵢ)

trong đó N là số lượng lớp và i là lớp thứ 𝑖. Chúng tôi chọn điểm macro F1 làm metric đánh giá do thuộc tính vốn có của nó trong việc gán ý nghĩa bằng nhau cho mọi lớp trong tập dữ liệu của chúng tôi. Vì tất cả các thực nghiệm được lặp lại 3 lần, chúng tôi sử dụng các giá trị trung bình để đánh giá.

5 KẾT QUẢ THỰC NGHIỆM
Trong mục này, chúng tôi trình bày kết quả phân tích cú pháp và ngữ nghĩa mã nguồn.

5.1 Phân Tích Cú Pháp

5.1.1 Dự Đoán Cặp Nút Cú Pháp. Hình 8a và Hình 8b trình bày kết quả của các bộ phân loại thăm dò cho dự đoán cặp nút cú pháp trên Java250 và POJ-104 tương ứng, cho các mô hình tiền huấn luyện mã nguồn, CodeBert (CB), GraphCodeBert (GCB), UnixCoder (UC) và CodeT5 (CT5). Những kết quả này được dẫn xuất từ các biểu diễn ẩn được cung cấp bởi các mô hình mã nguồn. Trục X biểu thị chỉ số lớp, trong khi trục Y biểu thị hiệu suất. 𝐿𝑎𝑦𝑒𝑟 0 tương ứng với lớp embedding, trong khi 𝐿𝑎𝑦𝑒𝑟 1-𝐿𝑎𝑦𝑒𝑟 12 biểu thị các lớp Transformer. Chúng ta có thể thấy rằng tổng thể những mô hình này có thể mô tả chính xác các mối quan hệ cú pháp giữa các token. Ví dụ, MCC đạt trên 70% trong các lớp khác nhau trên các mô hình khác nhau. Tất cả các mô hình tiền huấn luyện đạt hiệu suất tốt nhất giữa 𝐿𝑎𝑦𝑒𝑟 2 và 𝐿𝑎𝑦𝑒𝑟 4 nông. Với độ sâu của các lớp, hiệu suất giảm dần. Cụ thể hơn, GraphCodeBERT (GCB) thể hiện hiệu suất hơi tốt hơn so với các mô hình khác trên Java250, như được thể hiện trong Hình 8a. Tuy nhiên, khi chuyển sang POJ-104, hiện tượng phức tạp hơn. CodeT5 thể hiện hiệu suất vượt trội so với các mô hình khác từ 𝐿𝑎𝑦𝑒𝑟 4 đến 𝐿𝑎𝑦𝑒𝑟 8, tuy nhiên, khi lớp đạt 12, GraphCodeBERT đạt hiệu suất tốt nhất. Mặc dù UnixCoder và CodeT5 sử dụng các chiến lược tiền huấn luyện phức tạp hơn, tận dụng các tập dữ liệu lớn hơn, và có số lượng tham số có thể đào tạo lớn hơn, lợi thế tương đối của chúng là tối thiểu. Hình 8c cho thấy điểm MCC cho CodeLlama, StarCoder và CodeT5+. Một quan sát thú vị là ba mô hình ngôn ngữ lớn đạt hiệu suất tốt nhất trong các lớp nông 𝐿𝑎𝑦𝑒𝑟 4 và 𝐿𝑎𝑦𝑒𝑟 5, tương tự như các mô hình tiền huấn luyện mã nguồn. Nhưng đối với StarCoder và CodeLlama, hiệu suất tăng nhiều ở lớp cuối cùng, khác với những mô hình khác. Chúng ta có thể kết luận rằng mối quan hệ cú pháp giữa các token mã nguồn dễ quan sát hơn trong không gian biểu diễn của các lớp ẩn nông. Sự giảm hiệu suất của các biểu diễn sâu hơn trong nhiệm vụ này là một hiện tượng thú vị. Mặc dù các lớp ẩn sâu được cho là chứa thông tin từ các lớp nông hơn, không gian biểu diễn của chúng phức tạp hơn, mã hóa nhiều thuộc tính mã nguồn khác như vai trò token-cú pháp, vì vậy mối quan hệ cú pháp-token có thể ít nổi bật hơn.

5.1.2 Gắn Thẻ Cú Pháp Token. Hình 9a và Hình 9b trình bày kết quả MCC của các bộ phân loại thăm dò cho vai trò cú pháp token riêng lẻ (Gắn Thẻ Cú Pháp Token) trên Java250 và POJ-104 tương ứng. Hình 9c và Hình 9d thể hiện điểm F1. Các quan sát của chúng tôi chỉ ra rằng CodeT5 vượt trội so với các mô hình khác trong các lớp giữa, cụ thể từ 𝐿𝑎𝑦𝑒𝑟 4 đến 𝐿𝑎𝑦𝑒𝑟 11. CodeBERT thể hiện hiệu suất hơi tốt hơn so với GraphCodeBERT trong những lớp giữa này, trong khi GraphCodeBERT vượt qua các mô hình khác ở lớp cuối cùng, tức là 𝐿𝑎𝑦𝑒𝑟 12. Thú vị là, một sự sụt giảm hiệu suất được quan sát đối với tất cả các mô hình ngoại trừ UnixCoder khi chuyển từ 𝐿𝑎𝑦𝑒𝑟 11 đến 𝐿𝑎𝑦𝑒𝑟 12. CodeT5 đạt hiệu suất đỉnh cao khoảng 𝐿𝑎𝑦𝑒𝑟 10. Ngược lại, UnixCoder tụt lại phía sau các mô hình khác, đặc biệt sau 𝐿𝑎𝑦𝑒𝑟 7. Ngoại trừ UnixCoder, hiệu suất của các mô hình tiền huấn luyện khác cho thấy xu hướng tăng với dao động từ 𝐿𝑎𝑦𝑒𝑟 0 đến 𝐿𝑎𝑦𝑒𝑟 11. Hình 10a và Hình 10b cho thấy điểm F1 và điểm MCC cho LLMs trên tập dữ liệu Java250. Nếu chúng ta nhìn vào tất cả các hình trong nhiệm vụ này, chúng ta thấy xu hướng chung rằng hiệu suất cải thiện khi độ sâu của các lớp tăng, và phần sau ổn định với một số sụt giảm hoặc tăng. Thú vị là, tại điểm giao giữa encoder và decoder, hiệu suất mô hình giảm mạnh nhưng nhanh chóng cải thiện trở lại khi số lượng lớp tăng. Hiện tượng này cũng đã được quan sát trong các thực nghiệm khác. Một giải thích hợp lý là encoder và decoder hoạt động với các cơ chế khác nhau. Encoder mã hóa thông tin thành biểu diễn trừu tượng trong khi decoder cố gắng phục hồi đầu vào từ biểu diễn trừu tượng. Do sự khác biệt hoạt động, các thuộc tính trong biểu diễn từ các lớp tương tác thách thức để quan sát khi di chuyển từ encoder sang decoder. Như đã đề cập trước, gắn thẻ cú pháp token là một nhiệm vụ không tầm thường để gắn nhãn token mã nguồn với vai trò cú pháp, và đây là một nhiệm vụ khó hơn so với nhiệm vụ trước. Thuộc tính vai trò cú pháp token được biểu diễn rõ ràng hơn trong các lớp sâu hơn so với các lớp nông.

Về mối quan hệ tương đối cú pháp, những mô hình tiền huấn luyện mã nguồn này thể hiện sự thành thạo tương đương. Tuy nhiên, CodeT5 (chúng tôi xem xét encoder của nó) phân biệt bằng cách biểu diễn hiệu quả hơn vai trò cú pháp-token riêng lẻ trong ngữ cảnh. Ngược lại, UnixCoder thể hiện mức độ hiểu biết cú pháp thấp hơn so với các mô hình khác. Chúng tôi suy đoán điều này vì hai lý do sau: 1) CodeBERT, GraphCodeBERT, và CodeT5-encoder đều sử dụng masked language modeling (MLM) hoặc các cách tương tự để học đặc tính token hai chiều trong khi UniXCoder kết hợp các loại nhiệm vụ tiền huấn luyện khác nhau. Mặc dù nó cũng sử dụng MLM, các nhiệm vụ khác như unidirectional language modeling (ULM) và DeNoiSing (DNS) có thể có tác động có hại đến các nhiệm vụ thăm dò; 2) UnixCoder tích hợp encoder và decoder bằng cách chia sẻ trọng số trong khi các biểu diễn từ decoder có khả năng trích xuất thông tin tệ hơn so với biểu diễn encoder [66]. Chia sẻ trọng số giữa encoder và decoder có thể làm hại khả năng của mô hình trích xuất thông tin. Ba LLMs được nghiên cứu cho thấy một số khác biệt so với bốn mô hình tiền huấn luyện. LLMs không có lợi thế rõ ràng so với các mô hình tiền huấn luyện, mặc dù StarCoder có 6144 chiều ẩn, CodeLlama có 4096 chiều ẩn, và CodeT5p-770m có 1046 chiều ẩn. Chiều của chúng cao hơn nhiều so với các mô hình tiền huấn luyện mã nguồn (768). Tất cả đều có số lượng tham số khổng lồ. Một lý do có thể là chiều không gian biểu diễn quá lớn và bao phủ quá nhiều thông tin, làm cho các đặc tính cú pháp nhúng khó quan sát.

Tóm lại, từ Mục 5.1.1 và Mục 5.1.2, rõ ràng là bốn mô hình tiền huấn luyện mã nguồn và 3 mô hình ngôn ngữ lớn có thể mã hóa cú pháp mã nguồn, cả về mối quan hệ cú pháp giữa các token (dự đoán Cặp Nút Cú pháp) và vai trò cú pháp-token riêng lẻ (Gắn Thẻ Cú Pháp Token). Các đặc tính cú pháp khác nhau có các mức độ khó khăn khác nhau trong việc được quan sát ở các lớp ẩn nông và sâu.

5.2 Phân Tích Ngữ Nghĩa

5.2.1 Dự Đoán Quan Hệ Ngữ Nghĩa. Hình 11 trình bày hiệu suất thăm dò của bốn mô hình tiền huấn luyện mã nguồn, CodeBERT (CB), GraphCodeBERT (GCB), UnixCoder (UC), và CodeT5 (CT5) trong nhiệm vụ dự đoán quan hệ ngữ nghĩa. Chúng tôi tiến hành so sánh hiệu suất thăm dò trên ba ngữ nghĩa chương trình khác nhau: phụ thuộc điều khiển (CDG, Hình 11a và Hình 11b), thông tin luồng điều khiển (CFG, Hình 11c và Hình 11d), và phụ thuộc dữ liệu (DDG, Hình 11e và Hình 11f). Đầu tiên, rõ ràng là CodeT5 thể hiện sự thành thạo cao nhất trong việc hiểu ngữ nghĩa chương trình, tức là CDG và DDG, đặc biệt trong vài lớp cuối cùng, và GraphCodeBERT chứng minh tốt hơn một chút so với CodeT5 về CFG. Thứ hai, CodeBERT cũng có khả năng mã hóa ngữ nghĩa chương trình, mặc dù không sử dụng thông tin luồng dữ liệu trong quá trình tiền huấn luyện. Ví dụ, MCC đạt trên 60% trong CDG và DDG. Nó chỉ ra rằng nhiệm vụ tiền huấn luyện Masked Language Modeling (MLM) có thể hỗ trợ mô hình trong việc học ngữ nghĩa mã nguồn. UnixCoder thực hiện kém hiệu quả hơn trong việc biểu diễn ngữ nghĩa mã nguồn so với ba mô hình khác, đặc biệt sau 𝐿𝑎𝑦𝑒𝑟 7.

Hình 12 thể hiện hiệu suất thăm dò của ba LLMs, CodeLlama, StarCoder và CodeT5+, trong ba nhiệm vụ hiểu ngữ nghĩa mã nguồn, CDG, CFG và DDG. So với mô hình tiền huấn luyện mã nguồn, biểu diễn từ lớp nông của LLM làm cho việc quan sát ba thông tin ngữ nghĩa của mã nguồn dễ dàng hơn. Khi chúng tôi so sánh StarCoder với CodeLlama và CodeT5+, chúng tôi thấy rằng hiệu suất của StarCoder giảm đáng kể đối với các lớp sâu. Vì các LLM hiện tại có khả năng khẩn cấp, chúng ta có thể nghĩ LLMs đã học ba ngữ nghĩa mã nguồn trong khi chúng không dễ dàng quan sát. Hơn nữa, cách cảm ứng biểu diễn ngữ nghĩa mã nguồn của LLM để dễ quan sát hơn trong việc nhắc LLM, do đó cải thiện chất lượng câu trả lời của mô hình, là một chủ đề đáng nghiên cứu trong tương lai.

Khi so sánh hiệu suất của các mô hình mã nguồn trên CDG, CFG, và DDG, rõ ràng là các mô hình mã nguồn thể hiện MCC thấp nhất trên CFG, MCC cao hơn trên DDG, và MCC cao nhất trên CDG, tương ứng. Nó chỉ ra rằng các mô hình mã nguồn gặp khó khăn trong việc nắm bắt ngữ nghĩa luồng điều khiển (CFG) hiệu quả như hai loại ngữ nghĩa khác. CFG là một xấp xỉ trace thực thi của chương trình. LLMs được cho thấy thiếu khả năng xử lý các nhiệm vụ liên quan đến thực thi mã nguồn [46]. Các người đào tạo mô hình cần xem xét cách cải thiện hiểu biết về hành vi động mã nguồn của LLMs.

5.2.2 Lan Truyền Ngữ Nghĩa (inGraph). Hình 13 minh họa kết quả thăm dò của bốn mô hình tiền huấn luyện trong nhiệm vụ inGraph. Rõ ràng là GraphCodeBERT vượt trội so với các mô hình khác về lan truyền ngữ nghĩa cho CDG và DDG trên tập dữ liệu Java250. CodeT5 tốt hơn trên POJ-104 về CDG. Tuy nhiên, cả GraphCodeBERT và CodeT5 đều thể hiện hiệu suất tương tự trên POJ-104 về DDG. Điều này cho thấy rằng lan truyền dữ liệu được sử dụng bởi GraphCodeBERT chứng minh có lợi trong việc nắm bắt lan truyền ngữ nghĩa trong mã nguồn. Hơn nữa, chúng tôi quan sát rằng CodeBERT có thể mã hóa ngữ nghĩa mã nguồn, mặc dù với hiệu suất thấp hơn so với CodeT5 và GraphCodeBERT. Tuy nhiên, UnixCoder thực hiện tệ hơn so với các mô hình khác, đặc biệt sau 𝐿𝑎𝑦𝑒𝑟 7. Khi so sánh hiệu suất của các mô hình giữa CDG và DDG, chúng ta có thể thấy rằng các mô hình thể hiện MCC cao hơn trên DDG so với CDG, có nghĩa là lan truyền phụ thuộc dữ liệu được mã hóa tốt hơn so với lan truyền phụ thuộc điều khiển bởi 4 mô hình tiền huấn luyện mã nguồn này. Đối với LLMs, chúng tôi quan sát rằng các lớp nông có hiệu suất tốt hơn so với các lớp sâu. Đối với CodeT5+, hiện tượng này thậm chí rõ ràng hơn và có sự sụt giảm mạnh giữa encoder và decoder (𝐿𝑎𝑦𝑒𝑟 24 và 𝐿𝑎𝑦𝑒𝑟 25). Một giải thích có thể là khả năng của các biểu diễn mã nguồn cho decoder biểu đạt các phụ thuộc dài bị giảm bởi vì decoder chỉ có thể thấy thông tin token trước đó, và các token tương lai bị che. Nếu chúng ta xem Hình 12 cho phụ thuộc ngắn (xây dựng các đồ thị ngữ nghĩa), chúng ta có thể thấy rằng có sự sụt giảm hiệu suất giữa encoder và decoder (𝐿𝑎𝑦𝑒𝑟 24 và 𝐿𝑎𝑦𝑒𝑟 25) của CodeT5+ và các sụt giảm trở nên rõ ràng hơn đối với phụ thuộc dài.

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

--- TRANG 18 ---
111:18 W. Ma, S. Liu và M. Zhao cùng cộng sự.

[Các hình từ 11-14 hiển thị hiệu suất của các mô hình khác nhau trên các nhiệm vụ ngữ nghĩa]

Để tóm tắt các phát hiện từ Mục 5.2.1 và Mục 5.2.2, tất cả bốn mô hình tiền huấn luyện mã nguồn đều sở hữu khả năng học ngữ nghĩa mã nguồn. Tuy nhiên, khả năng mã hóa ngữ nghĩa của chúng khác nhau trên các loại ngữ nghĩa khác nhau. Đối với nhóm LLM, biểu diễn từ các lớp nông làm cho việc quan sát ngữ nghĩa mã nguồn dễ dàng hơn. Khả năng mã hóa thông tin thực thi mã nguồn nên được tăng cường cho LLMs.

5.3 Phân Tích Attention
Dựa trên các phân tích đã đề cập ở trên, chúng tôi đã quan sát rằng các mô hình tiền huấn luyện mã nguồn và mô hình ngôn ngữ lớn (LLM) thể hiện sự thành thạo tốt hoặc mức độ trung bình trong việc học cú pháp và ngữ nghĩa mã nguồn. Để có được hiểu biết sâu hơn về cách những mô hình này mã hóa ngữ nghĩa, chúng tôi tiến hành điều tra về vai trò của các self-attention head trong việc học ngữ nghĩa mã nguồn, sử dụng tập dữ liệu hơn 10,000 đầu vào ngữ nghĩa cho các mô hình tiền huấn luyện mã nguồn và lấy mẫu ngẫu nhiên 100 đầu vào ngữ nghĩa cho LLMs. Mỗi một trong các mô hình tiền huấn luyện có tổng cộng 144 attention head tương ứng. StarCoder có 1920 attention head, CodeLlama có 960 attention head và CodeT5+ Decoder/Encoder có 384 attention head.

Trong Bảng 3 và Bảng 4, chúng tôi trình bày số lượng attention head học ngữ nghĩa mã nguồn đáng kể về CDG, CFG, và DDG (có ý nghĩa thống kê ở ngưỡng p-value 0.01) cho các mô hình tiền huấn luyện và LLMs về các tập dữ liệu Java250 và POJ-104, tương ứng. Trong Bảng 3, rõ ràng là UnixCoder có số lượng attention head ít nhất dành cho ngữ nghĩa. Điều này phù hợp với kết luận trước rằng UnixCoder không tốt hơn những mô hình khác về mã hóa cú pháp và ngữ nghĩa mã nguồn. Trong Bảng 4, chúng ta có thể thấy rằng các attention head có mối quan hệ phụ thuộc điều khiển không gán nhiều trọng số hơn so với các attention head không có mối quan hệ phụ thuộc điều khiển đối với StarCoder, CodeLlama và CodeT5+ decoder sử dụng kiến trúc transformer decoder. Tuy nhiên, đối với CodeT5+ encoder, tồn tại 199/252 attention head có thể gán nhiều trọng số hơn cho mối quan hệ phụ thuộc điều khiển. Chúng tôi nghĩ lý do là các kiến trúc mô hình khác nhau có thể ảnh hưởng đến phân phối của cơ chế attention. Encoder và decoder trong transformer có các chức năng khác nhau. Encoder có xu hướng hiểu cấu trúc tổng thể và ngữ cảnh của đầu vào, trong khi decoder tập trung vào việc tạo hoặc dự đoán token tiếp theo dựa trên sự hiểu biết này. Do đó, đối với các câu lệnh phụ thuộc điều khiển, encoder có thể cần chú ý nhiều hơn đến những mối quan hệ này để hiểu cấu trúc logic của toàn bộ mã nguồn, trong khi decoder có thể chú ý nhiều hơn đến thông tin cục bộ hoặc thông tin ngữ nghĩa khác để tạo ra, dẫn đến các phân phối trọng số attention khác nhau.

Chúng tôi tiếp tục điều tra sự chồng chéo của các semantic attention head gán nhiều trọng số attention hơn cho các token ngữ nghĩa giữa các tập dữ liệu Java250 và POJ-104 cho bốn mô hình này. Kết quả cho thấy một mô hình chia sẻ các semantic attention head trên các ngôn ngữ lập trình khác nhau. Để kiểm tra sự khác biệt trong các semantic attention head giữa các tập dữ liệu Java250 và POJ-104 trên bốn mô hình được sử dụng, chúng tôi trình bày tỷ lệ của các semantic attention head chồng chéo cho mỗi mô hình trong cả hai tập dữ liệu (Bảng 5 và Bảng 6). Các hàng Java250 và POJ-104 được tính bởi hai phương trình sau tương ứng,

𝑟𝑗𝑎𝑣𝑎 250=|𝑆𝑗𝑎𝑣𝑎 250∩𝑆𝑃𝑂𝐽|/|𝑆𝑗𝑎𝑣𝑎 250|
𝑟𝑝𝑜𝑗=|𝑆𝑗𝑎𝑣𝑎 250∩𝑆𝑃𝑂𝐽|/|𝑆𝑃𝑂𝐽|

trong đó 𝑆𝑗𝑎𝑣𝑎 250 và 𝑆𝑃𝑂𝐽 là tập hợp các semantic attention head cho các tập dữ liệu Java250 và POJ-104. Đáng ngạc nhiên, mặc dù các ngôn ngữ lập trình riêng biệt được biểu diễn trong hai tập dữ liệu, một sự chồng chéo đáng kể được quan sát. Mặc dù tỷ lệ chồng chéo 𝑟𝑝𝑜𝑗 cho DDG trong CodeLlama là 8.29%, nó được gây ra do 𝑆𝑃𝑂𝐽 quá lớn và thực tế đa số attention head từ Java250 được bao gồm trong 𝑆𝑃𝑂𝐽 (81.00%). Phát hiện này cho thấy rằng một số mẫu semantic attention nhất định được chia sẻ giữa các mô hình mã nguồn bất kể ngôn ngữ lập trình được sử dụng.

6 CÔNG TRÌNH LIÊN QUAN

6.1 Các Mô Hình Mã Nguồn
Các mô hình tiền huấn luyện đã được sử dụng để hỗ trợ nhiều nhiệm vụ do khả năng tổng quát hóa xuất sắc của chúng trong các nhiệm vụ xử lý ngôn ngữ tự nhiên. Gần đây, các nhà nghiên cứu tiền huấn luyện transformers [54] sử dụng dữ liệu mã nguồn để giải quyết các nhiệm vụ lập trình. Theo các chiến lược tiền huấn luyện và kiến trúc mô hình, chúng ta có thể nhóm các mô hình tiền huấn luyện thành ba (3) loại: mô hình auto-encoding, mô hình auto-regressive, và mô hình sequence-to-sequence (Seq2Seq). Các mô hình auto-encoding sử dụng Transformer encoder và được tiền huấn luyện với các mục tiêu như Masked Language Modelling (MLM). MLM che một số token trong chuỗi mã nguồn và mong đợi mô hình dự đoán các token bị che bằng cách sử dụng thông tin ngữ cảnh hai chiều, thực tế cho phép mô hình sử dụng các token tương lai để dự đoán các token che hiện tại. CodeBERT [13] được tiền huấn luyện trên tập dữ liệu CodeSearchNet [26]. GraphCodeBERT [17] bao gồm một loại đầu vào bổ sung, chuỗi luồng dữ liệu, so với CodeBERT. CodeBERT và GraphCodeBERT sử dụng encoder của Transformer. Các mô hình auto-regressive sử dụng Causal Language Modelling (CLM) hoặc các biến thể của nó để tiền huấn luyện các transformer theo cách từ trái sang phải. CodeGPT [42] sử dụng chiến lược tiền huấn luyện này và giữ transformer decoder. Các mô hình Seq2Seq, ví dụ: CodeT5 [71], sử dụng cả encoder và decoder trong Transformer. CommitBART [40] sử dụng kiến trúc BART [32] để tiền huấn luyện một mô hình cho các commit GitHub.

Gần đây, ChatGPT và các mô hình ngôn ngữ lớn khác đã thu hút sự chú ý đáng kể. Do đó, một số LLMs được thiết kế cụ thể cho việc lập trình đã xuất hiện. StarCoder [34] với 15B tham số được đào tạo sử dụng 1 triệu token được phát hành. CodeLlama [58] được điều chỉnh dựa trên Llama2 [65] sử dụng tập dữ liệu mã nguồn. WizardCoder [43] sử dụng hướng dẫn tiến hóa mã nguồn để điều chỉnh trọng số mô hình. Tất cả đều dựa trên transformer decoder. Khác với chúng, CodeT5+ [70] sử dụng kiến trúc encoder-decoder như CodeT5 [71]. LLMs cho thấy khả năng mạnh mẽ trong sửa chữa chương trình, tạo mã nguồn và tóm tắt. Hou và cộng sự [21] và Zhang và cộng sự [78] xem xét toàn diện cách các ứng dụng lớn của mô hình ngôn ngữ trong kỹ thuật phần mềm.

Những mô hình mã nguồn này được sử dụng rộng rãi để giải quyết các nhiệm vụ kỹ thuật phần mềm khác nhau [21,48,62,78], như phát hiện khuyết tật, tóm tắt mã nguồn, sửa chữa lỗ hổng, và định vị lỗi. Trước sự xuất hiện của Học viên Mô hình Ngôn ngữ (LLMs), những mô hình học sâu này được sử dụng theo hai cách trong kỹ thuật phần mềm [35,73]: 1) Thêm một mô hình nhiệm vụ lên trên những mô hình mã nguồn này và tinh chỉnh trọng số của toàn bộ mô hình. 2) Những mô hình này được sử dụng như các bộ trích xuất đặc tính, và các thuật toán khác được áp dụng sau khi trích xuất đặc tính. So với phương pháp đầu tiên, phương pháp thứ hai không yêu cầu tinh chỉnh trọng số của mô hình. Sau sự xuất hiện của LLMs, các phương pháp học dựa trên in-context learning [7] dần được chấp nhận và sử dụng. Những mô hình này thường không được sử dụng một mình mà như một bước trong quy trình công việc. Hơn nữa, các nhà nghiên cứu sẽ sử dụng kiến thức miền để xác định cách sử dụng mô hình mã nguồn cho các tình huống cụ thể. Mặc dù nhiều phương pháp cho các nhiệm vụ kỹ thuật phần mềm khác nhau dựa trên các mô hình mã nguồn có sẵn ngày nay và các nhà nghiên cứu cố gắng giải thích từng bước của phương pháp của họ càng nhiều càng tốt, việc sử dụng mô hình mã nguồn như một hộp đen có thể làm giảm những giải thích này ở một mức độ nào đó. Công trình của chúng tôi nhằm giúp các kỹ sư phần mềm hiểu cách các mô hình hiểu cú pháp và ngữ nghĩa mã nguồn càng nhiều càng tốt.

6.2 Phân Tích Thăm Dò cho Các Mô Hình Mã Nguồn
Hiệu suất ấn tượng của các mô hình tiền huấn luyện kích thích nhiều công trình cố gắng diễn giải và hiểu những mô hình hộp đen quy mô lớn mới được phát minh này. Những công trình phân tích này có thể giúp người dùng hiểu và áp dụng các mô hình tiền huấn luyện. Thăm dò [6,57,79] là một trong những kỹ thuật nổi bật nhất được tận dụng rộng rãi cho khả năng diễn giải. Phân tích thăm dò nhằm chẩn đoán loại quy luật nào được mã hóa trong một biểu diễn được trích xuất từ dữ liệu. Cơ sở của việc thăm dò là nếu một bộ phân loại đơn giản, ví dụ: một bộ phân loại tuyến tính, được xây dựng trên các biểu diễn có thể giải quyết một nhiệm vụ đủ tốt, thì các biểu diễn nên chứa các đặc tính thông tin về nhiệm vụ sẵn có.

Các công trình gần đây cố gắng phân tích các mô hình tiền huấn luyện mã nguồn thông qua thăm dò. Wan và cộng sự [69] đánh giá xem các mô hình tiền huấn luyện có học cú pháp ngôn ngữ lập trình hay không, và họ đo số lượng cạnh giữa các token nút tại AST, và cố gắng học khoảng cách này trong không gian vector. Cách tiếp cận này không thể phục hồi cấu trúc AST, cho các khoảng cách giữa tất cả các nút. Mặc dù số lượng cạnh giữa các nút có thể phản ánh thông tin cú pháp ở một mức độ nào đó, nó vẫn có một số vấn đề. Đầu tiên, nó không thể tái tạo các cấu trúc AST trong không gian vector, có nghĩa là nó kiểm tra một phần cú pháp mã nguồn. Thứ hai, hai token có cú pháp tương tự có số lượng cạnh nhỏ, nhưng số lượng cạnh nhỏ không ngụ ý sự gần gũi cú pháp như được hiển thị trong phần động lực. Hernández López và cộng sự [18] phân tích các mô hình tiền huấn luyện ở cấp độ AST toàn cục bằng cách chiếu AST vào một không gian con. Công trình này chuyển đổi AST thành cây nhị phân định dạng trung gian và sau đó học một không gian con sử dụng khoảng cách cú pháp [60] được thiết kế cho ngôn ngữ tự nhiên. Tuy nhiên, khoảng cách cú pháp cho ngôn ngữ tự nhiên có thể không phù hợp với dữ liệu mã nguồn vì Allamanis và cộng sự [3] liệt kê sự khác biệt giữa mã nguồn và ngôn ngữ tự nhiên, bao gồm sự khác biệt trong cây cú pháp giữa ngôn ngữ tự nhiên và mã nguồn. Ngược lại, cách tiếp cận của chúng tôi ngắn gọn và hiệu quả, và chúng tôi trực tiếp phục hồi các cấu trúc AST từ không gian vector. Ngoài ra, chúng tôi tiến hành phân tích ngữ nghĩa cho mã nguồn.

Troshin và Chirkova [66] phát triển một nhóm nhiệm vụ thăm dò để kiểm tra xem các mô hình tiền huấn luyện có học cấu trúc cú pháp mã nguồn và thông tin luồng dữ liệu hay không. Đầu tiên, công trình này không xem xét toàn bộ cấu trúc của AST và xem xét một phần cú pháp mã nguồn. Thứ hai, công trình này không xem xét ngữ nghĩa luồng điều khiển và phụ thuộc điều khiển. Shen và cộng sự [59] trích xuất cấu trúc phụ cú pháp và dự đoán mối quan hệ cú pháp của chúng. Tuy nhiên, họ thiếu phân tích ngữ nghĩa và chỉ bao gồm bốn loại cú pháp: gán, gọi hàm, câu lệnh if, và cấu trúc vòng lặp. Công trình mới nhất [45] quan sát các mối quan hệ cú pháp và ngữ nghĩa và cũng nghiên cứu cách LLMs hiểu hành vi mã nguồn dựa trên các đầu ra được tạo thông qua in context learning để phân tích mã nguồn. Công trình của chúng tôi sử dụng các trạng thái bên trong của các mô hình mã nguồn và nghiên cứu toàn diện cách các mô hình mã nguồn mã hóa cú pháp và ngữ nghĩa mã nguồn bằng cách nhắm đến toàn bộ cấu trúc của AST, các đồ thị phụ thuộc điều khiển và dữ liệu, và đồ thị luồng điều khiển.

6.3 Kiểm Thử Học Sâu
Các mô hình học sâu được coi như một hệ thống. Mặc dù chúng ta có thể biết trọng số của mô hình và phương pháp tính toán nội tại của nó, chúng ta không biết logic nội tại của nó. Hu và cộng sự [23] nghiên cứu toàn diện về kiểm thử học sâu. Kiểm thử một hệ thống hộp đen như vậy khá thách thức. Các nhà nghiên cứu kỹ thuật phần mềm ban đầu chủ yếu tập trung vào phát hiện khuyết tật trong các hệ thống học sâu [47]. Ví dụ, DeepMutation [44] và DeepGini [12] đều được sử dụng để tìm khuyết tật trong các hệ thống học sâu. Những khuyết tật này thường được định nghĩa là các đầu vào gây ra hệ thống tạo ra các đầu ra không chính xác. Một khi các khuyết tật hệ thống được phát hiện, các nhà nghiên cứu cố gắng sửa chữa những khuyết tật được phát hiện này. Ngoài ra, trong các tình huống mà nhiều mô hình được sử dụng cho cùng một nhiệm vụ, các nhà nghiên cứu đã đề xuất các cách để chọn các mô hình chất lượng cao với ít khuyết tật [24,51,61]. Các mô hình được kiểm thử thường là các mô hình giải quyết các nhiệm vụ cụ thể trong một tình huống cụ thể. Bên cạnh đó, một số nghiên cứu tập trung vào kiểm thử hiệu suất mô hình trong các tình huống chưa biết. Ví dụ, ATC (Tận dụng Dữ liệu Chưa Gắn Nhãn để Dự đoán Hiệu suất Ngoài Phân phối) [15], Aries [25], và OODRobustBench [33] đều nghiên cứu hiệu suất của các mô hình trên dữ liệu ngoài phân phối. Quan trọng cần nhấn mạnh rằng công trình của chúng tôi không phải là để phát hiện khuyết tật trong mô hình; chúng tôi nhằm giải thích sự hiểu biết về cú pháp và ngữ nghĩa mã nguồn cho các mô hình mã nguồn. Phân tích thăm dò và kiểm thử khác nhau. Phân tích thăm dò tập trung vào hiểu các cơ chế nội tại và biểu diễn kiến thức của các mô hình trong khi kiểm thử các mô hình mã nguồn nhằm đánh giá hiệu suất thực tế của các mô hình và xác định các khuyết tật tiềm năng. Cả hai đều là các bước không thể thiếu trong quá trình phát triển và đánh giá các mô hình mã nguồn, nhưng chúng tập trung vào các khía cạnh khác nhau.

7 KẾT LUẬN VÀ THẢO LUẬN

7.1 Kết Luận
Trong công trình này, chúng tôi nhằm có được hiểu biết sâu hơn về cách các mô hình mã nguồn xử lý và hiểu các cấu trúc cú pháp và ngữ nghĩa mã nguồn phức tạp. Cụ thể, chúng tôi điều tra xem những mô hình mã nguồn này có thể nắm bắt chính xác các cây cú pháp (AST), phụ thuộc điều khiển (CDG), luồng điều khiển (CFG), và phụ thuộc dữ liệu (DDG) trong mã nguồn bằng cách tái tạo những cấu trúc cú pháp và ngữ nghĩa này trong không gian vector hay không. Đây đều là các khía cạnh cơ bản của hiểu biết chương trình. Chúng tôi thiết kế một loạt nhiệm vụ thăm dò để đánh giá khả năng của các mô hình mã nguồn xử lý cú pháp và ngữ nghĩa mã nguồn. Chúng tôi khám phá bốn mô hình tiền huấn luyện mã nguồn phổ biến: CodeBERT, GraphCodeBERT, UnixCoder, và CodeT5, và giới thiệu ba mô hình ngôn ngữ quy mô lớn (LLMs): CodeLlama, StarCoder, và CodeT5+, để đánh giá hiệu suất của chúng trong việc hiểu cú pháp và ngữ nghĩa mã nguồn. Ngoài ra, chúng tôi gián tiếp quan sát cách các mô hình xử lý các phụ thuộc trong mã nguồn thông qua phân tích attention. Từ các thực nghiệm của chúng tôi, chúng tôi thu được một số phát hiện thú vị. Các mô hình tiền huấn luyện mã nguồn và LLMs có thể biểu đạt cú pháp mã nguồn khá tốt và nắm bắt ngữ nghĩa mã nguồn ở một mức độ nào đó, đặc biệt trong việc xử lý các phụ thuộc dữ liệu và phụ thuộc điều khiển. Bằng cách so sánh hiệu suất của các mô hình khác nhau, chúng tôi quan sát rằng các mô hình cụ thể có những lợi thế khác nhau trong các nhiệm vụ thăm dò, chỉ ra các hiệu ứng khác nhau của các chiến lược mô hình và tập dữ liệu đào tạo đối với sự hiểu biết của các mô hình trong cú pháp và ngữ nghĩa mã nguồn. Mặc dù LLMs thể hiện khả năng học cú pháp và ngữ nghĩa mã nguồn, phân tích hiệu suất sâu cho thấy sự khác biệt trong việc trình bày sự hiểu biết này trong các lớp ẩn khác nhau, gợi ý khả năng tối ưu hóa các chiến lược tiền huấn luyện để cải thiện xử lý ngữ nghĩa sâu. Khi chúng tôi sử dụng các mô hình mã nguồn SOTA như CodeLlama để giải quyết các nhiệm vụ kỹ thuật phần mềm, chúng tôi vẫn cần thiết kế cẩn thận các mô hình nhiệm vụ downstream bởi vì các đặc tính mã nguồn được trích xuất bởi các mô hình lớn được ẩn sâu và không dễ dàng quan sát.

7.2 Thảo Luận
Nghiên cứu của chúng tôi cung cấp những hiểu biết có giá trị về việc hiểu và cải thiện khả năng của các mô hình mã nguồn và đặt ra những câu hỏi thách thức và cơ hội cho các hướng nghiên cứu tương lai. Dựa trên các phát hiện của chúng tôi, chúng tôi tin rằng nghiên cứu tương lai nên tập trung vào một số lĩnh vực chính: 1). Tiếp tục tối ưu hóa kiến trúc và chiến lược đào tạo của các mô hình mã nguồn để tăng cường khả năng hiểu ngữ nghĩa mã nguồn phức tạp của chúng. Điều này có thể bao gồm khám phá các kiến trúc mạng nơ-ron mới, mục tiêu đào tạo, và kỹ thuật tăng cường dữ liệu. Một giải pháp có thể là sử dụng graph transformer [37,77] để trực tiếp học các cấu trúc cú pháp và ngữ nghĩa của mã nguồn. Ma và cộng sự [49] đã chứng minh rằng mạng nơ-ron đồ thị có thể hoạt động tốt như transformer nhưng với ít tham số hơn. Graph transformer kết hợp những lợi thế của mạng nơ-ron đồ thị và transformer: mã hóa cấu trúc đồ thị và học từ một kho dữ liệu lớn. 2). Khám phá các nhiệm vụ thăm dò mới và phương pháp đánh giá để tiếp tục tiết lộ hoạt động bên trong của các mô hình mã nguồn, đặc biệt là khả năng của các mô hình dựa trên decoder hiểu mã nguồn. Điều này có thể bao gồm phát triển các metric mới để đo lường hiểu biết mã nguồn, cũng như thiết kế các ví dụ đối kháng để kiểm tra tính robustness của các mô hình mã nguồn. 3). Điều tra mối quan hệ giữa tính robustness của các mô hình mã nguồn và khả năng hiểu ngữ nghĩa mã nguồn của chúng. Điều này có thể bao gồm nghiên cứu cách các loại nhiễu và tấn công đối kháng khác nhau ảnh hưởng đến hiệu suất của các mô hình mã nguồn và phát triển các phương pháp để cải thiện tính robustness của chúng trong khi duy trì khả năng hiểu mã nguồn. Nhìn về phía trước, các mô hình mã nguồn ngày càng được sử dụng cho phát triển phần mềm. Công trình của chúng tôi đã nêu bật rằng các mô hình mã nguồn vẫn có những thiếu sót đáng kể trong việc hiểu ngữ nghĩa mã nguồn. Tuy nhiên, ngữ nghĩa mã nguồn liên quan chặt chẽ đến bảo mật mã nguồn. Do đó, việc thực hiện kiểm tra bảo mật đối với mã nguồn được tạo bởi các mô hình mã nguồn là rất quan trọng.

8 CÁC MỐI ĐE DỌA CHO TÍNH HỢP LỆ
Đầu tiên, kết quả của phân tích phát hiện bị ảnh hưởng bởi random seed và tập dữ liệu được sử dụng. Có một mức độ ngẫu nhiên nhất định có thể ảnh hưởng đến hiệu suất của bộ phân loại phát hiện cuối cùng. Để giảm thiểu tác động của tính ngẫu nhiên, chúng tôi tiến hành nhiều thực nghiệm và thực hiện phân tích thống kê của kết quả.

Thứ hai, chúng tôi sử dụng các công cụ phân tích tĩnh để xây dựng tập dữ liệu chất lượng cao để phân tích. Mặc dù cách tiếp cận này cung cấp thông tin có giá trị, nó cũng đưa vào những thiên lệch nhất định. Các công cụ phân tích tĩnh có thể không nắm bắt đầy đủ các biến thiên tinh tế trong ngữ nghĩa động và có thể bị ảnh hưởng bởi các quy tắc cú pháp của các ngôn ngữ lập trình cụ thể. Để giảm thiên lệch này, chúng tôi chọn các công cụ được nhiều nhà nghiên cứu sử dụng để tránh sai sót trong dữ liệu. Trong quá trình so sánh cross-task, chúng tôi trích xuất các nhiệm vụ cú pháp và ngữ nghĩa từ cùng một nguồn dữ liệu để giảm thiểu thiên lệch trong các so sánh cross-task.

Thứ ba, các metric hiệu suất khác nhau có thể thể hiện các thiên lệch khác nhau. Để đánh giá các mô hình chính xác hơn, chúng tôi sử dụng hệ số tương quan Matthews (MCC) cho phân loại nhị phân và điểm F1 cho phân loại đa lớp. Thực tế, chúng tôi đánh giá các mô hình sử dụng cả MCC và F1 cho tất cả các nhiệm vụ, và các kết luận rút ra từ cả hai metric đều nhất quán.

Thứ tư, mặc dù phân tích thăm dò có thể tiết lộ khả năng học của các mô hình mã nguồn về cú pháp và ngữ nghĩa, nó không đảm bảo hiệu suất nhiệm vụ downstream tốt trong các ứng dụng thực tế. Các mô hình mã nguồn có thể hoạt động tốt trong các nhiệm vụ thăm dò nhưng kém trong các ứng dụng thực tế, đặc biệt là các nhiệm vụ yêu cầu lý luận phức tạp hoặc tương tác đa phương thức. Hiệu suất của các mô hình nhiệm vụ downstream không chỉ liên quan đến sức mạnh biểu đạt của mô hình cơ sở mà còn đến chất lượng của tập dữ liệu nhiệm vụ downstream và tính robustness của mô hình.

Thứ năm, phân tích thăm dò là để quan sát xem biểu diễn có chứa một thuộc tính cụ thể tồn tại trong đầu vào hay không. Tuy nhiên, hiệu suất kém của phân tích thăm dò không có nghĩa là biểu diễn không chứa thông tin như vậy. Không gian biểu diễn là một không gian chiều cao và trộn lẫn tất cả những gì đã học với nhau. Một số thông tin dễ quan sát hơn và dễ thăm dò. Cách tiếp cận thăm dò của chúng tôi chỉ có thể được sử dụng để trả lời xem thuộc tính này có dễ quan sát hơn hay ít hơn. Nó bị hạn chế trong việc trả lời 'có' hoặc 'không'.

Cuối cùng nhưng không kém phần quan trọng, nhiều mô hình mã nguồn đã được đề xuất. Để đảm bảo rằng cách tiếp cận đánh giá và kết luận của chúng tôi được tổng quát hóa, chúng tôi xem xét ba kiến trúc khác nhau của các mô hình mã nguồn: encoder, decoder và encoder-decoder. Chúng tôi bao gồm các mô hình tiền huấn luyện truyền thống và các mô hình ngôn ngữ lớn từ các công ty hoặc tổ chức lớn, và tất cả các mô hình này được sử dụng rộng rãi như các mô hình cơ sở để giải quyết các nhiệm vụ downstream. Khi chúng tôi thiết kế cách tiếp cận của mình, chúng tôi không xem xét bất kỳ mô hình cụ thể nào và ngôn ngữ lập trình, và chúng tôi chỉ xem xét cú pháp và ngữ nghĩa của mã nguồn. AST biểu diễn tất cả thông tin cú pháp của mã nguồn. CFG biểu diễn logic/hành động của mã nguồn. DDG và CDG biểu diễn mối quan hệ ngữ nghĩa giữa các phần mã nguồn khác nhau. Hầu như tất cả các nhiệm vụ SE liên quan đến mã nguồn đều cần thông tin này. Tuy nhiên, các mô hình khác nhau có khả năng khác nhau, và kết luận của chúng tôi có thể không phù hợp với một mô hình có chiến lược đào tạo và tập dữ liệu rất khác nhau.

LỜI CẢM ÓN
Nghiên cứu này được hỗ trợ bởi Quỹ Nghiên cứu Quốc gia, Singapore, và Cơ quan An ninh Mạng trong Chương trình R&D An ninh Mạng Quốc gia (NCRP25-P04-TAICeN), Quỹ Nghiên cứu Quốc gia, Singapore, và Phòng thí nghiệm Quốc gia DSO trong Chương trình AI Singapore (Giải thưởng AISG số: AISG2-GC-2023-008), và NRF Investigatorship NRF-NRFI06-2020-0001. Bất kỳ ý kiến, phát hiện và kết luận hoặc khuyến nghị nào được thể hiện trong tài liệu này đều thuộc về (các) tác giả và không phản ánh quan điểm của Quỹ Nghiên cứu Quốc gia, Singapore và Cơ quan An ninh Mạng của Singapore.

TÀI LIỆU THAM KHẢO
[Danh sách tài liệu tham khảo từ [1] đến [81] với các trích dẫn học thuật đầy đủ]

J. ACM, Vol. 37, No. 4, Article 111. Ngày xuất bản: Tháng 8 2018.

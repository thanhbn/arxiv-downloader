# 2306.01754.pdf
# Chuyển đổi từ PDF sang TXT
# Đường d�n nguồn: ./2306.1754.pdf
# Kích thước file: 904466 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Phát hiện lỗi bảo mật trong mã nguồn dựa trên Transformer tại thời điểm chỉnh sửa:
Zero-shot, Few-shot, hay Fine-tuning?
Aaron Chan, Anant Kharkar, Roshanak Zilouchian Moghaddam, Yevhen Mohylevskyy,
Alec Helyar, Eslam Kamal, Mohamed Elkamhawy, Neel Sundaresan
Microsoft
Redmond, Hoa Kỳ
TÓM TẮT
Lỗi bảo mật phần mềm gây ra chi phí đáng kể cho các doanh nghiệp. Mặc dù có nhiều nỗ lực nghiên cứu và phát triển các phương pháp phát hiện lỗi bảo mật phần mềm, các lỗi bảo mật chưa được phát hiện vẫn tiếp tục đe dọa chủ sở hữu và người dùng phần mềm. Nhiều phương pháp phát hiện lỗi bảo mật hiện tại yêu cầu các đoạn mã phải có thể biên dịch và xây dựng trước khi thực hiện phát hiện. Điều này, thật không may, tạo ra một độ trễ dài giữa thời điểm lỗi bảo mật được đưa vào và thời điểm nó được loại bỏ, có thể làm tăng đáng kể chi phí sửa chữa lỗi bảo mật. Chúng tôi nhận ra rằng những tiến bộ hiện tại trong học máy có thể được sử dụng để phát hiện các mẫu mã dễ bị tổn thương trên các đoạn mã chưa hoàn thiện về mặt cú pháp khi nhà phát triển đang viết mã tại thời điểm chỉnh sửa. Trong bài báo này, chúng tôi trình bày một hệ thống thực tế tận dụng học sâu trên một tập dữ liệu quy mô lớn các mẫu mã dễ bị tổn thương để học các biểu hiện phức tạp của hơn 250 loại lỗi bảo mật và phát hiện các mẫu mã dễ bị tổn thương tại thời điểm chỉnh sửa. Chúng tôi thảo luận về các phương pháp zero-shot, few-shot và fine-tuning trên các mô hình ngôn ngữ lớn (LLM) được tiền huấn luyện hiện đại. Chúng tôi cho thấy rằng so với các mô hình phát hiện lỗi bảo mật tiên tiến, phương pháp của chúng tôi cải thiện hiệu suất 10%. Chúng tôi cũng đánh giá phương pháp của mình để phát hiện lỗi bảo mật trong mã được tạo tự động bởi các mô hình ngôn ngữ lập trình. Đánh giá trên một chuẩn mực của các tình huống mã có rủi ro cao cho thấy giảm tới 90% lỗi bảo mật.

TỪ KHÓA
Transformers, Lỗi bảo mật phần mềm, Phát hiện lỗi bảo mật

1 GIỚI THIỆU
Mặc dù đã phát triển nhiều công cụ và thực hành tốt [3,4,12,47], các lỗi bảo mật chưa được phát hiện vẫn tồn tại trong mã [1,2] và ảnh hưởng đến người dùng cũng như làm tốn thời gian và tiền bạc của các công ty [19]. Trong những năm gần đây, nhiều phương pháp đã được phát triển để phát hiện lỗi bảo mật trong phần mềm. Các phương pháp này từ phân tích động truyền thống [25,28,48], phân tích tĩnh dựa trên quy tắc [9,51], các giải pháp học máy dựa trên đặc trưng [33], đến các giải pháp dựa trên học sâu gần đây hơn [8,30,41,53].

Các phương pháp dựa trên phân tích động thường gặp vấn đề về độ bao phủ mã thấp. Các phương pháp phân tích tĩnh dựa trên quy tắc thường yêu cầu nỗ lực thủ công của các chuyên gia để đặc trưng hóa và thêm các mẫu lỗi bảo mật mới hoặc phát triển một cách thường xuyên. Tương tự, các phương pháp học máy dựa trên đặc trưng dựa vào các đặc trưng được tạo thủ công bởi các chuyên gia con người. Gần đây hơn, các phương pháp dựa trên học sâu đã nổi lên như một lựa chọn thay thế có thể học các mẫu lỗi bảo mật tự động mà không cần sự can thiệp của chuyên gia. Tuy nhiên, phần lớn các phương pháp học sâu này yêu cầu một file nguồn hoàn chỉnh [39], một hàm hoàn chỉnh [23,24,41], hoặc một câu lệnh mã hoàn chỉnh [11,43] để phân tích. Kết quả là, theo hiểu biết của chúng tôi, các phương pháp học sâu hiện có không thể tìm thấy lỗi bảo mật tại thời điểm chỉnh sửa khi nhà phát triển đang gõ và mã chưa đúng cú pháp hoặc chưa hoàn chỉnh.

Hình 1: Thời điểm tốt nhất để thông báo cho nhà phát triển về lỗi bảo mật SQL-Injection là tại thời điểm chỉnh sửa, ngay sau khi nhà phát triển đã mắc lỗi.

Tài liệu chỉ ra rằng chi phí sửa chữa lỗi có mối tương quan thuận với thời gian bỏ qua lỗi (tức là thời gian từ khi lỗi bảo mật được đưa vào đến khi nó được loại bỏ) [5,6,20]. Do đó, nhà phát triển nên được thông báo về lỗi một cách kịp thời, khi lỗi có liên quan đến nhiệm vụ lập trình hiện tại [22]. Ví dụ, trong đoạn mã được hiển thị trong Hình 1, thời điểm tốt nhất để thông báo cho nhà phát triển về lỗi SQL injection mà họ đã tạo ra là ngay ở cuối truy vấn, mặc dù mã của họ chưa hoàn chỉnh về mặt cú pháp. Tầm quan trọng của việc xác định tương tác các lỗi và lỗi bảo mật trong mã tại thời điểm chỉnh sửa đã được công nhận bởi các công trình trước đây [50]. Công trình của chúng tôi mở rộng dòng công trình trước đó này bằng cách tận dụng những tiến bộ mới trong học sâu để phát hiện nhiều lỗi bảo mật trong các đoạn mã không hoàn chỉnh khi nhà phát triển đang gõ.

Để xây dựng giải pháp phát hiện lỗi bảo mật của chúng tôi, chúng tôi thu thập hơn 500K đoạn mã dễ bị tổn thương từ việc chạy các trình phân tích tĩnh trên các kho mã nguồn mở. Sau đó, chúng tôi phát triển sáu biến thể mô hình sử dụng các phương pháp học phổ biến cho các LLM được tiền huấn luyện: zero-shot, few-shot và fine-tuning. Chúng tôi áp dụng các kỹ thuật học này trên CodeBERT [15] và hai LLM được tiền huấn luyện hiện đại được cung cấp bởi OpenAI: code-davinci-002, text-davinci-003. Đánh giá so sánh của chúng tôi về các biến thể này cho thấy fine-tuning CodeBERT mang lại sự cân bằng tốt nhất giữa precision và recall (precision 59% và recall 63%). Tuy nhiên, cả zero-shot và few-shot learning trên text-davinci-003 gần đây, là một mô hình ngôn ngữ dựa trên InstructGPT [35], đều mang lại recall tốt hơn (78% và 75%) và precision thấp hơn một chút (47% và 49%). Chúng tôi thảo luận về lợi ích và thách thức của mỗi phương pháp học về mặt kích thước mô hình và hiệu suất.

Chúng tôi tiến hành hai thí nghiệm sử dụng mô hình có hiệu suất tốt nhất. Thí nghiệm đầu tiên so sánh mô hình này với các phương pháp phát hiện lỗi bảo mật hiện có trên bốn tập dữ liệu chuẩn đã được thiết lập. Chúng tôi cho thấy rằng, so với các phương pháp hiện có, phương pháp của chúng tôi cải thiện recall lên tới 10% và precision lên tới 8%.

--- TRANG 2 ---
Thí nghiệm thứ hai nghiên cứu khả năng tổng quát hóa của phương pháp của chúng tôi ngoài việc chỉnh sửa mã thủ công bởi các nhà phát triển, nơi chúng tôi điều tra hiệu quả của phương pháp của chúng tôi trong việc phát hiện lỗi bảo mật trong các chỉnh sửa mã tự động. Với việc áp dụng rộng rãi các công cụ hoàn thành mã gần đây [17,45,46], nhiều chỉnh sửa mã trong tương lai dự kiến sẽ được tạo tự động bởi các LLM mã. Nghiên cứu trước đây cho thấy rằng các LLM mã mắc lỗi tương tự như các nhà phát triển [14], do đó các chỉnh sửa mã được tạo tự động có thể có những mối quan tâm bảo mật tiềm năng nghiêm trọng. Ví dụ, trong một số tình huống nhất định, lên tới 40% số lần hoàn thành được tạo bởi các LLM mã bao gồm các mẫu mã dễ bị tổn thương [38]. Chúng tôi đánh giá mô hình phát hiện lỗi bảo mật của mình trên một biến thể của chuẩn mực được giới thiệu bởi Pearce et al. [38]. Đánh giá của chúng tôi cho thấy rằng việc sử dụng mô hình của chúng tôi mang lại 90% giảm tỷ lệ lỗi bảo mật.

Cuối cùng, chúng tôi thảo luận về hành trình triển khai mô hình phát hiện lỗi bảo mật của chúng tôi trong một extension VSCode đã dẫn đến 80% giảm tỷ lệ lỗi bảo mật trong mã được chỉnh sửa với extension.

Bài báo này có những đóng góp sau:
(1) chúng tôi trình bày một hệ thống phát hiện lỗi bảo mật chất lượng sản xuất có thể xác định lỗi bảo mật trong các đoạn mã không hoàn chỉnh trong vài mili giây và do đó phục vụ các nhà phát triển tại thời điểm chỉnh sửa,
(2) chúng tôi khám phá và thảo luận về lợi ích và thách thức của ba phương pháp học phổ biến cho các LLM được tiền huấn luyện trong nhiệm vụ phát hiện lỗi bảo mật: zero-shot, few-shot và fine-tuning,
(3) chúng tôi mở rộng chuẩn mực được giới thiệu bởi Pearce et al. và cung cấp nó cho cộng đồng phát hiện lỗi bảo mật mã như một chuẩn mực thời điểm chỉnh sửa trong tương lai.

2 NGHIÊN CỨU LIÊN QUAN
Chúng tôi thảo luận về cách công trình của chúng tôi xây dựng dựa trên và mở rộng nghiên cứu trước đây trong lĩnh vực phát hiện lỗi bảo mật, các phương pháp học sâu cho phát hiện lỗi bảo mật, và phát hiện lỗi bảo mật trong mã tự động tạo.

2.1 Phát hiện lỗi bảo mật
Có hai phương thức phân tích mã nguồn để tìm kiếm lỗi bảo mật: phân tích động, trong đó một đoạn mã được thực thi và dấu vết ngăn xếp được kiểm tra để tìm chữ ký của một lỗi bảo mật cụ thể; và phân tích tĩnh, trong đó mã nguồn được phân tích mà không thực thi. Một phương pháp phổ biến của phân tích động là fuzzing, trong đó một chương trình được chạy trên nhiều đầu vào khác nhau để khám phá không gian các dấu vết thực thi chương trình. Các kỹ thuật tối ưu hóa để tìm kiếm hiệu quả không gian chương trình này là một lĩnh vực nghiên cứu tích cực [21,31,52]. Tuy nhiên, việc fuzzing các cơ sở mã lớn bằng cách thực thi mã tùy ý là không khả thi, và đã dẫn đến việc phát triển các kỹ thuật phân tích tĩnh. Các trình phân tích tĩnh tìm kiếm các mẫu ngữ nghĩa của lỗi hoặc lỗi bảo mật trong cơ sở mã [37]. CodeQL [18] là một trình phân tích tĩnh có thể mở rộng phổ biến cho các tìm kiếm dựa trên mẫu như vậy. CodeQL cung cấp một ngôn ngữ truy vấn để viết các truy vấn dựa trên quy tắc cho các anti-pattern cụ thể. Chúng tôi xây dựng dựa trên dòng nghiên cứu này bằng cách phát triển một mô hình phát hiện lỗi bảo mật tận dụng các phương pháp học sâu tiên tiến và do đó có khả năng học nhiều loại lỗi bảo mật mà không cần sự tham gia của các chuyên gia con người.

2.2 Phát hiện lỗi bảo mật bằng học sâu
Vì ngôn ngữ tự nhiên và ngôn ngữ lập trình đều có cấu trúc tuần tự, các kiến trúc mô hình thành công trong NLP, như GRU, LSTM, và Transformer, cũng đã cho thấy triển vọng trong phát hiện lỗi bảo mật [49]. Một đặc điểm độc đáo của mã nguồn, không được chia sẻ bởi ngôn ngữ tự nhiên, là cấu trúc đồ thị vốn có của các chương trình. VulDeePecker [30] trích xuất các gadget mã từ các đồ thị phụ thuộc dữ liệu và huấn luyện một bộ phân loại BiLSTM để phát hiện lỗi bảo mật trong một tập dữ liệu gồm hai loại lỗi bảo mật khác nhau. SySeVR [29] xây dựng trên VulDeePecker bằng cách sử dụng cả thông tin cú pháp và ngữ nghĩa để huấn luyện các bộ phân loại lỗi bảo mật trên một tập dữ liệu gồm 126 loại lỗi bảo mật. Các công trình khác tận dụng mạng nơ-ron đồ thị để bổ sung cho các mô hình ngôn ngữ: IVdetect [27] sử dụng embeddings GRU với một mạng tích chập đồ thị chú ý đặc trưng (FA-GCN) để phát hiện lỗi bảo mật trong các đồ thị phụ thuộc chương trình. LineVul [16] mở rộng IVdetect bằng cách tận dụng CodeBERT được tiền huấn luyện [15] để thực hiện định vị lỗi bảo mật ở mức dòng ngoài việc phát hiện ở mức phương thức. Devign [53] học các embedding của đồ thị biểu diễn mã và huấn luyện một mạng nơ-ron đồ thị cổng tái hiện để phát hiện lỗi bảo mật cho các dự đoán cấp đồ thị. Nó đánh giá mô hình này trên các lỗi bảo mật từ FFmpeg và QEMU. ReVeal [8] giới thiệu một tập dữ liệu các lỗi bảo mật từ các dự án phần mềm thực tế như một chuẩn mực cho các mô hình phát hiện lỗi bảo mật. Nó chứng minh chuẩn mực này bằng cách sử dụng một mạng nơ-ron đồ thị cổng (GGNN) được huấn luyện trên các đồ thị thuộc tính mã. Nghiên cứu của chúng tôi mở rộng công trình trước đây về phát hiện lỗi bảo mật bằng cách phát triển một mô hình phát hiện lỗi bảo mật nơ-ron cho bảy ngôn ngữ: JavaScript, Python, Go, Java, C++, C# và Ruby có khả năng phát hiện lỗi bảo mật tại thời điểm chỉnh sửa.

2.3 Phát hiện lỗi bảo mật trong mã tự động tạo
Các mô hình dựa trên Transformer được huấn luyện trên mã nguồn đã đạt được kết quả tiên tiến cho việc tạo mã [10,26,34]. Những mô hình này có tiện ích chưa từng có như các công cụ hỗ trợ nhà phát triển, và đang được triển khai vào các sản phẩm [17,45,46]. Vì các LLM mã này đã được huấn luyện trên các tập dữ liệu lớn của mã do con người viết, đầu ra mã của chúng ngày càng có khả năng tuân theo các mẫu (hoặc anti-pattern) của các nhà phát triển con người. Ví dụ, [14] đánh giá Codex trên các câu hỏi Java LeetCode và thấy rằng các hoàn thành không chính xác về mặt chức năng từ Codex chia sẻ các anti-pattern tương tự với mã không chính xác được viết bởi con người. Tương tự, [38] kiểm tra Codex về việc tạo ra lỗi bảo mật và thấy rằng, trong một số tình huống nhất định, Codex thực sự tạo ra các mẫu mã dễ bị tổn thương. Trong một nghiên cứu khác, [44] cho thấy rằng trong các bài kiểm tra chức năng với tập dữ liệu HumanEval, GitHub Copilot tạo ra một số CWE trong khoảng 2% trường hợp. Những nghiên cứu này cho thấy rằng các LLM mã có thể đang học cách tạo ra cả mã tốt và mã xấu. May mắn thay, vì các mẫu mã dễ bị tổn thương hiếm gặp trong mã của con người và do đó chiếm một phần nhỏ trong dữ liệu huấn luyện, chúng cũng hiếm gặp trong các hoàn thành từ các LLM mã. Ví dụ, một nghiên cứu gần đây về tác động của hỗ trợ LLM mã không tìm thấy bằng chứng kết luận nào rằng các LLM mã có nhiều khả năng tạo ra lỗi bảo mật hơn con người [42]. Tuy nhiên, xét đến chi phí cao liên quan đến lỗi bảo mật mã, việc giảm các mẫu mã dễ bị tổn thương được tạo bởi các LLM mã là điều cần thiết để đảm bảo rằng việc sử dụng lâu dài của chúng là an toàn, đặc biệt là đối với các lập trình viên mới bắt đầu. Vì mục đích này, nghiên cứu của chúng tôi tạo ra một mô hình có thể hoạt động trên mã chưa hoàn thiện về mặt cú pháp, và do đó phát hiện lỗi bảo mật trong các đoạn mã tự động tạo cũng như các đoạn mã do nhà phát triển viết tại thời điểm chỉnh sửa.

3 PHÁT HIỆN LỖI BẢO MẬT TẠI THỜI ĐIỂM CHỈNH SỬA
Để phát hiện lỗi bảo mật tại thời điểm chỉnh sửa, chúng tôi phát triển sáu biến thể mô hình sử dụng các phương pháp học phổ biến cho các LLM được tiền huấn luyện: zero-shot, few-shot và fine-tuning. Dưới đây, chúng tôi đầu tiên giải thích dữ liệu huấn luyện mà chúng tôi đã thu thập cho quá trình fine-tuning của mình. Sau đó, chúng tôi giải thích các biến thể mô hình và hiệu suất tương ứng của chúng.

3.1 Thu thập dữ liệu
Tập dữ liệu của chúng tôi bao gồm các mẫu mã dễ bị tổn thương được phát hiện trong các kho GitHub công cộng bởi dịch vụ GitHub LGTM. Dịch vụ GitHub LGTM chạy CodeQL [18], một trình phân tích tĩnh có thể mở rộng, trên các kho GitHub công cộng để xác định nhiều mẫu mã dễ bị tổn thương, bao gồm thông tin đăng nhập mã hóa cứng, SQL injection và path injection. Trong công trình này, chúng tôi chọn một tập con của các vấn đề CodeQL được phát hiện tương ứng với một tập "Common Weakness Enumeration" (CWE) [32] trong mỗi ngôn ngữ trong số bảy ngôn ngữ: JavaScript, Python, Go, Java, C++, C# và Ruby. Bảng 1 cho thấy thống kê tóm tắt của tập dữ liệu được tuyển chọn.

Bảng 1: Thống kê tóm tắt của tập dữ liệu huấn luyện phát hiện lỗi bảo mật
Phạm vi mô hình Dễ bị tổn thương Không dễ bị tổn thương
Javascript 70 CWE 266,342 2,293,712
Python 37 CWE 149,158 1,493,972
Go 29 CWE 50,233 535,180
Java 44 CWE 33,485 431,726
C++ 32 CWE 7,222 215,722
C# 54 CWE 3,341 27,731
Ruby 19 CWE 137 1,957

Mỗi lỗi bảo mật được phát hiện chứa những thông tin sau:
• Tiêu đề lỗi bảo mật: loại lỗi bảo mật được phát hiện, tương ứng với một danh mục CWE
• Thông báo: một thông báo lỗi chi tiết giải thích lỗi bảo mật được phát hiện
• Vị trí: đường dẫn file, dòng và cột nơi vấn đề bắt đầu và kết thúc

3.2 Tiền xử lý dữ liệu
Với dữ liệu chúng tôi thu thập, mục tiêu của bước tiền xử lý dữ liệu là tổng hợp các triplet sau: (ci, vi, li) trong đó c là một đoạn mã mà mô hình nhận làm bối cảnh, v là khối mã dễ bị tổn thương và l là nhãn cho loại lỗi bảo mật.

Quy trình tổng hợp dữ liệu huấn luyện của chúng tôi như sau: đầu tiên chúng tôi thu thập các file với lỗi bảo mật đã xác định từ tất cả 8.815 kho lưu trữ mà những vấn đề này đã được phát hiện. Với mỗi file, chúng tôi trích xuất Abstract Syntax Tree (AST) và tìm kiếm các node của cây chứa các phạm vi hoàn chỉnh. Cụ thể, chúng tôi tìm kiếm các câu lệnh (như if và export), phương thức, khai báo và mệnh đề. Đối với những khối mã này, nếu khối mã chứa một mẫu mã dễ bị tổn thương, chúng tôi ngẫu nhiên chia khối tại một số ký tự trước khi bắt đầu lỗi bảo mật được phát hiện. Ngược lại, nếu không có lỗi bảo mật nào được phát hiện, chúng tôi ngẫu nhiên chia khối tại bất kỳ điểm nào. Quá trình chia này mô phỏng một trạng thái mã có thể có tại thời điểm chỉnh sửa. Do đó, các mô hình được huấn luyện trên dữ liệu này sẽ có thể phát hiện một khối dễ bị tổn thương trong một đoạn mã không chính xác và không hoàn chỉnh về mặt cú pháp. Phần đầu của khối được gán nhãn là "bối cảnh" và phần thứ hai là "khối dễ bị tổn thương". Hình 2 cho thấy một ví dụ về một cặp bối cảnh và khối dễ bị tổn thương. Nếu sự hoàn thành chứa một lỗi bảo mật, loại lỗi bảo mật tương ứng được gán cho ví dụ như một nhãn. Việc tách biệt giữa bối cảnh và khối dễ bị tổn thương buộc mô hình phải tập trung vào khối dễ bị tổn thương cho trước bối cảnh. Chúng tôi sử dụng phân chia 85/5/10 train-validation-test ở cấp độ kho lưu trữ, sao cho tập huấn luyện bao gồm 85% kho lưu trữ, tập validation bao gồm 5% kho lưu trữ và tập test bao gồm 10% kho lưu trữ. Sau đó, chúng tôi loại bỏ bất kỳ ví dụ nào trong tập huấn luyện khớp với ví dụ tập test.

Hình 2: Một mẫu bối cảnh và khối dễ bị tổn thương từ dữ liệu huấn luyện của chúng tôi. Trong ví dụ này, khối dễ bị tổn thương chứa lỗi bảo mật SQL-Injection.

3.3 Mô hình
Để phát hiện lỗi bảo mật tại thời điểm chỉnh sửa, chúng tôi phát triển sáu biến thể mô hình sử dụng ba phương pháp học cho LLM: zero-shot learning, few-shot learning và fine-tuning. Chúng tôi sử dụng các phương pháp học này trên ba LLM được tiền huấn luyện làm cơ sở:
• code-davinci-002: mô hình Codex kích thước đầy đủ được huấn luyện trên mã nguồn từ GitHub.
• text-davinci-003: mô hình Codex dựa trên InstructGPT [36], sử dụng học tăng cường từ phản hồi con người (RLHF).
• CodeBERT: transformer được tiền huấn luyện trên dữ liệu hai phương thức (mã và tài liệu) [15]. Kiến trúc của nó tuân theo RoBERTa-base [13], với 12 lớp, 12 attention head và kích thước ẩn 768.

Sử dụng ba phương pháp học trên các mô hình tiền huấn luyện trên tạo ra sáu mô hình được liệt kê trong Bảng 3. Chúng tôi giải thích chi tiết về việc phát triển các mô hình này dưới đây.

3.3.1 Zero-shot Learning. Trong zero-shot learning, chúng tôi cung cấp cho một mô hình được tiền huấn luyện một prompt chỉ định đầu ra mong muốn. Trong trường hợp của chúng tôi, chúng tôi prompt code-davinci-002 và text-davinci-003. Để có được một prompt phù hợp để yêu cầu mỗi mô hình phát hiện lỗi bảo mật, chúng tôi tận dụng định nghĩa phát hiện lỗi bảo mật của chính mô hình. Đầu tiên, chúng tôi prompt mô hình định nghĩa nhiệm vụ phát hiện lỗi bảo mật và sử dụng mô tả nhiệm vụ này trong prompt cuối cùng cho nhiệm vụ.

Với code-davinci-002, chúng tôi prompt mô hình với "# We run CodeQL security queries in order to " ở temperature 0.8 bốn lần và chọn kết quả hàng đầu. Điều này tạo ra các biến thể prompt sau: "identify potential security vulnerabilities", "find potential security issues", "find security vulnerabilities", và "detect security vulnerabilities". Chúng tôi đặt các biến thể này trong một prompt zero-shot theo mẫu dưới đây:
<phrase>
<comment> Code snippet
<code snippet>
<comment> Answer (Yes/No, explanation):

Ở đây <phrase> tương ứng với một trong các biến thể cách diễn đạt prompt ở trên, <comment> chỉ dấu hiệu comment cụ thể của ngôn ngữ (ví dụ: "#" cho Python) và <code snippet> chỉ đoạn mã đang được hỏi. Hình 3 cho thấy một prompt mẫu theo mẫu này. Để phản hồi prompt này, mô hình xuất ra "Yes" hoặc "No", theo sau là một giải thích có thể được sử dụng cho mục đích quan sát và debug. Chúng tôi kiểm tra sự hiện diện của "Yes" hoặc "No" để xác định quyết định của mô hình. Chúng tôi gọi phương pháp zero-shot này là CodexZero.

Hình 3: Một prompt mẫu được tạo dựa trên mẫu của chúng tôi cho thiết lập zero-shot

Tương tự, với text-davinci-003, chúng tôi đầu tiên prompt mô hình bốn lần ở temperature 0.8 với câu hỏi "What would you accomplish by running CodeQL security queries?". Sau đó, chúng tôi yêu cầu mô hình diễn đạt lại phản hồi bốn lần. Điều này tạo ra các cụm từ độc đáo sau: "identify potential security vulnerabilities", "spot any security weaknesses", "detect any security risks", "determine any security issues". Sau đó, chúng tôi thử các biến thể này trong một prompt zero-shot theo mẫu tương tự:
<phrase>
<code snippet>
Answer (Yes/No):

Chúng tôi kiểm tra sự hiện diện của "Yes" hoặc "No" trong phản hồi của mô hình để xác định quyết định của mô hình. Chúng tôi gọi phương pháp zero-shot này là TextZero.

3.3.2 Few-shot Learning. Few-shot learning xây dựng trên zero-shot learning bằng cách cung cấp các cặp ví dụ đầu vào-đầu ra, ngoài prompt zero-shot. Cho nghiên cứu của chúng tôi, chúng tôi sử dụng các biến thể prompt có hiệu suất tốt nhất của code-davinci-002 và text-davinci-003 từ zero-shot learning trong cùng định dạng mẫu. Sau đó, chúng tôi thêm các ví dụ bổ sung trong cùng định dạng mẫu trước khi cuối cùng chèn đoạn mã quan tâm và prompt mô hình cho câu trả lời.

Để tạo các ví dụ, chúng tôi prompt mỗi mô hình với cụm từ "Provide an example in <Language> of a code snippet that contains <Vulnerability Name> security vulnerability. Output the code only, do not include text:" cho mỗi ngôn ngữ và loại lỗi bảo mật trong Bảng 2. Chúng tôi prompt với mẫu này ba lần cho mỗi cặp lỗi bảo mật và ngôn ngữ, tạo ra 150 ví dụ dễ bị tổn thương. Sau đó, chúng tôi prompt mô hình với "Provide an example in <Language> of a code snippet. Output the code only, do not include text:" để lấy các mẫu mã không dễ bị tổn thương. Chúng tôi đánh giá thủ công mỗi mẫu để đảm bảo rằng chúng dễ bị tổn thương hoặc không dễ bị tổn thương như dự định. Tổng cộng có 297 ví dụ. Chúng tôi gọi các mô hình kết quả từ quá trình few-shot learning ở trên với code-davinci-002 và text-davinci-003 là CodexFew và TextFew tương ứng.

3.3.3 Fine-tuning. Với fine-tuning, chúng tôi tập trung vào các LLM mã được tiền huấn luyện và fine-tune CodeBERT và code-davinci-002. Với CodeBERT, chúng tôi thêm một đầu phân loại tuyến tính vào trunk BERT của nó để xây dựng một mô hình phân loại đa lớp. Đầu vào cho mô hình là bối cảnh và khối mã dễ bị tổn thương, được tách biệt bởi token [SEP] đặc biệt và được giới hạn bởi token đầu chuỗi [BOS] và token cuối chuỗi [EOS]
[BOS], c1, c2, ...cn, [SEP], v1, v2, ...vm, [EOS]

trong đó c1, c2, ...cn biểu thị một chuỗi n token của mã bối cảnh xung quanh lỗi bảo mật và v1, v2, ...vm biểu thị một chuỗi m token của khối mã dễ bị tổn thương. Chúng tôi phân biệt giữa bối cảnh và khối dễ bị tổn thương để cho phép mô hình xử lý bất kỳ đoạn mã hoàn chỉnh hoặc không hoàn chỉnh nào. Vì dữ liệu của chúng tôi rất mất cân bằng với ít hơn 10% ví dụ dễ bị tổn thương, chúng tôi sử dụng kỹ thuật oversampling trên các ví dụ dễ bị tổn thương trong khi huấn luyện: cho mỗi epoch, tất cả ví dụ dễ bị tổn thương được giữ lại trong khi các ví dụ không dễ bị tổn thương được xoay vòng để mỗi epoch chứa 50% dễ bị tổn thương và 50% không dễ bị tổn thương. Mô hình được huấn luyện với binary cross entropy (BCE) loss tiêu chuẩn. Trong phần còn lại của công trình này, chúng tôi gọi mô hình này là DeepDevVuln.

Mô hình fine-tuned thứ hai của chúng tôi là phiên bản fine-tuned của code-davinci-002 trên 30.000 ví dụ được lấy mẫu ngẫu nhiên từ tập huấn luyện. Chúng tôi giảm kích thước dữ liệu huấn luyện do chi phí fine-tuning mô hình trên toàn bộ tập huấn luyện. Trong trường hợp này, bối cảnh và khối dễ bị tổn thương được nối với nhau, sau đó một token phân loại đặc biệt được thêm vào cuối chuỗi. Vì code-davinci-002 là một mô hình decoder GPT không tự thực hiện phân loại, chúng tôi sử dụng dự đoán token tiếp theo làm proxy, tức là đầu ra là một token đặc biệt biểu thị dễ bị tổn thương hoặc không. Chuỗi như sau:
[BOS], c1, c2, ...cn, v1, v2, ...vn[CLS][VULN]

Chúng tôi gọi biến thể này là CodexVuln.

--- TRANG 5 ---
Bảng 2: Thống kê tóm tắt các vấn đề dễ bị tổn thương được thu thập từ Github PR

Lỗi bảo mật CWE N
SQL Injection 89 45
Hardcoded Credentials 798 23
Code Injection 94 13
Path Injection 22 7
Clear Text Logging 312 5
Weak Cryptographic Algorithm 327 5
Incomplete URL Substring Sanitization 20 2

3.4 Đánh giá biến thể mô hình
Để hiểu rõ hơn về tác động của kiến trúc mô hình và lựa chọn huấn luyện, chúng tôi so sánh sáu biến thể mô hình của mình trên một tập dữ liệu chúng tôi thu thập từ các pull request GitHub.

3.4.1 Metrics. Phần lớn các phương pháp hiện có xử lý phát hiện lỗi bảo mật như một bài toán phân loại. Cho một khối mã, mô hình đưa ra quyết định nhị phân về việc mã có dễ bị tổn thương hay không. Do đó, trong các đánh giá của chúng tôi, chúng tôi cũng sử dụng các metric đánh giá phổ biến nhất cho một nhiệm vụ phân loại [40] bao gồm:
• Precision: chỉ ra tính chính xác của dự đoán và được tính là true positive / (true positive + false positive)
• Recall: chỉ ra hiệu quả của dự đoán và được tính là true positive / (true positive + false negative).
• F1-score: chỉ ra sự cân bằng giữa precision và recall và được định nghĩa là trung bình hình học của hai.

Bảng 3: Hiệu suất mô hình DeepDevVuln trên tập dữ liệu lỗi bảo mật Github PR.

Mô hình Precision Recall F1-Score
DeepDevVuln 58.87% 63.00% 60.87%
CodexVuln 69.56% 48.00% 56.80%
CodexZero 11.08% 98.00% 19.90%
TextZero 46.99% 78.00% 58.65%
CodexFew (8 examples) 23.91% 95.00% 37.70%
TextFew (6 examples) 49.01% 75.00% 59.29%

3.4.2 Tập dữ liệu. Để tạo tập dữ liệu này, chúng tôi thu thập tất cả pull request có chứa "fix <issue>" trong tiêu đề pull request cho mỗi kết hợp của issue từ Bảng 2 và ngôn ngữ (tức là JavaScript, Python, Go, Java, C++, C#, Ruby). Để đảm bảo rằng các pull request được lấy có liên quan đến lỗi bảo mật mục tiêu, chúng tôi chỉ bao gồm các pull request chứa cả việc xóa và thêm mã và có độ dài ít hơn 100 dòng. Điều này tạo ra 283 pull request. Sau đó, chúng tôi kiểm tra thủ công mỗi pull request để đảm bảo các lỗi bảo mật là hợp lệ.

Sử dụng quy trình này, chúng tôi thu thập một tập 100 ví dụ dễ bị tổn thương cấu thành các CWE trong Bảng 2. Chúng tôi thêm một tập 906 ví dụ không dễ bị tổn thương vào tập dữ liệu này. Để thu thập các ví dụ không dễ bị tổn thương, chúng tôi lấy mẫu ngẫu nhiên 150 file từ các kho mà CodeQL đã quét và không phát hiện vấn đề. Sau đó, chúng tôi ngẫu nhiên chọn các đoạn mã không chồng lấn từ 1 đến 10 dòng từ những file này để tạo ví dụ không dễ bị tổn thương. Tổng cộng, tập dữ liệu GitHub PR chứa 1.006 ví dụ.

Hình 4: Một mẫu false positive của CodexZero do vượt quá
Hình 5: Một mẫu false positive của CodexVuln do thiếu ngữ cảnh

3.4.3 Kết quả. Bảng 3 cho thấy hiệu suất của các biến thể mô hình của chúng tôi trên tập dữ liệu này. Với sáu biến thể mô hình này, chúng ta có thể thấy rằng DeepDevVuln có hiệu suất tốt nhất về F1 score. Mỗi biến thể zero-shot và few-shot đều vượt trội DeepDevVuln về recall, tuy nhiên precision của mỗi biến thể thấp hơn đáng kể. Một lý do có thể là các mô hình zero-shot và few-shot có định nghĩa rộng hơn về những gì cấu thành mã dễ bị tổn thương. Ví dụ, đoạn mã được trình bày trong Hình 4 dưới đây không có lỗi bảo mật rõ ràng nào, tuy nhiên, CodexZero xem xét kịch bản tồi tệ nhất rằng mã có thể dễ bị tổn thương bởi buffer overflow trong tương lai. Do xu hướng này, có vẻ như CodexZero sẽ đưa ra cảnh báo ngay cả khi không có lỗi bảo mật rõ ràng, dẫn đến điểm recall cao nhưng điểm precision thấp.

Một ví dụ khác giải thích thêm về tỷ lệ false positive cao của CodexZero. Trong Hình 5, chúng ta thấy rằng mô hình thiếu ngữ cảnh xung quanh biến md, và giải thích rằng vì nó chưa bao giờ được khởi tạo, việc truy cập bộ nhớ tại vị trí đó có thể dẫn đến lỗi bảo mật. Lời giải thích này mở rộng, một phần, đến TextZero, có precision và recall cân bằng hơn. Trong trường hợp của TextZero, biến thể prompt được sử dụng có tác động đáng kể: ví dụ, biến thể prompt đầu tiên "identify potential security vulnerabilities" có kết quả tương tự như CodexZero. Tuy nhiên, việc sử dụng cụm từ "detect any security risks" dẫn đến kết quả trong Bảng 3. Điều này có thể khuyến khích mô hình tập trung vào đoạn mã chính xác như hiện tại, thay vì suy đoán về các lỗi bảo mật có thể có.

Comparing few-shot và zero-shot results, chúng ta thấy các đánh giá few-shot vượt qua các đối tác zero-shot. Một giải thích là việc bao gồm các ví dụ cho mô hình cảm giác về những gì mong đợi về độ dài đoạn mã và khu vực tập trung. Ví dụ, khi các ví dụ không dễ bị tổn thương bao gồm các biến chưa được khởi tạo và bối cảnh không hoàn chỉnh, mô hình bắt đầu bỏ qua các kịch bản tồi tệ nhất được giải thích ở trên.

Tìm ra số lượng ví dụ tốt nhất là vấn đề tăng dần số lượng ví dụ được thêm vào prompt từ 1 đến 9. Chúng tôi chạy một số thử nghiệm và báo cáo kết quả tốt nhất. Trong số các thử nghiệm này, chúng tôi quan sát thấy rằng, đặc biệt là với CodexFew, có mối tương quan rõ ràng giữa số lượng ví dụ lớn hơn và precision và recall đạt được như thấy trong Hình 6. Có thể các loại ví dụ được chọn cụ thể có vai trò chính trong việc định hướng đầu ra của mô hình. Một xu hướng tương tự cho precision, nhưng không phải recall, được quan sát cho TextFew, Hình 7.

4 THÍ NGHIỆM
Dưới đây, chúng tôi giải thích các thí nghiệm được thiết kế để trả lời hai câu hỏi nghiên cứu sau:
• RQ1: Mô hình phát hiện lỗi bảo mật của chúng tôi hiệu quả như thế nào so với kết quả từ các mô hình hiện đại trên các tập dữ liệu chuẩn đã thiết lập?
• RQ2: Mô hình phát hiện lỗi bảo mật được đề xuất của chúng tôi hiệu quả đến mức nào trong việc giảm tỷ lệ lỗi bảo mật của LLM mã?

Chúng tôi thực hiện hai thí nghiệm để trả lời những câu hỏi này. Thí nghiệm đầu tiên tập trung vào việc so sánh mô hình của chúng tôi với các mô hình phát hiện lỗi bảo mật hiện đại trên các tập dữ liệu phổ biến. Thí nghiệm thứ hai đo lường hiệu quả của mô hình của chúng tôi trong việc giảm tỷ lệ lỗi bảo mật của LLM mã.

4.1 Thí nghiệm 1: Hiệu suất so với các phương pháp hiện có trên tập dữ liệu chuẩn
Trong phần này, chúng tôi trình bày đánh giá thực nghiệm của mô hình phát hiện lỗi bảo mật của chúng tôi so với các phương pháp hiện đại hiện có trên bốn tập dữ liệu được sử dụng rộng rãi. Bảng 4 tóm tắt các tập dữ liệu được sử dụng trong thí nghiệm này.

4.1.1 Thiết lập thí nghiệm. Độ chi tiết của dữ liệu, chất lượng dữ liệu và các loại vấn đề được bao phủ trong mỗi tập dữ liệu trong Bảng 4 khác với tập huấn luyện và tập test của chúng tôi. Do đó, chúng tôi tuân theo phương pháp của Chakraborty et al. [8], nơi chúng tôi đầu tiên loại bỏ các ví dụ trùng lặp từ mỗi tập dữ liệu. Sau đó, chúng tôi fine-tune DeepDevVuln như một mô hình phân loại nhị phân trên mỗi tập dữ liệu trong 10 epoch. Đối với mỗi tập dữ liệu, chúng tôi sử dụng phân chia tiêu chuẩn 80%/10%/10% train/validation/test, phù hợp với các mô hình baseline.

4.1.2 Kết quả. Như được hiển thị trong Bảng 5, mô hình DeepDevVuln của chúng tôi có F1-Score tổng thể tốt nhất cho phần lớn các tập dữ liệu. Điều này có nghĩa là mô hình của chúng tôi thể hiện sự cân bằng tốt giữa precision và recall, điều quan trọng đối với phát hiện lỗi bảo mật. Ngoài ra, mô hình phát hiện lỗi bảo mật của chúng tôi có ít tham số hơn 10 lần so với GPT2-Large hoặc Codex, nhưng vẫn đạt được precision tương đương và recall cao hơn. Tổng thể, kết quả này cho thấy rằng phương pháp của chúng tôi cho phép mô hình thích ứng với các loại vấn đề cụ thể có trong những tập dữ liệu này và tận dụng kiến thức thu được thông qua tiền huấn luyện trên tập dữ liệu lỗi bảo mật của chúng tôi để cải thiện kết quả hiện đại.

4.2 Thí nghiệm 2: Hiệu quả của mô hình trong việc giảm tỷ lệ lỗi bảo mật của LLM mã
Trong thí nghiệm thứ hai, chúng tôi đánh giá hiệu quả của mô hình phát hiện lỗi bảo mật của chúng tôi trong việc phát hiện các hoàn thành mã dễ bị tổn thương của bốn LLM mã khác nhau:
• CodeGen-2B: một mô hình transformer decoder được huấn luyện trên ngôn ngữ tự nhiên và mã (C, C++, Go, Java, JavaScript, Python)
• code-cushman-001: mô hình Codex kích thước nhỏ hơn, được huấn luyện trên mã nguồn từ GitHub
• code-davinci-002: mô hình Codex kích thước đầy đủ, được huấn luyện trên mã nguồn từ GitHub
• text-davinci-003: mô hình Codex dựa trên InstructGPT [36], sử dụng học tăng cường từ phản hồi con người (RLHF)

Chúng tôi đánh giá mức độ mà mô hình của chúng tôi phát hiện các mẫu mã dễ bị tổn thương được tạo ra bởi mỗi LLM sử dụng chuẩn mực được tạo bởi Pearce et al [38]. Chuẩn mực này bao gồm các tình huống để đánh giá khả năng của một LLM mã tạo ra lỗi bảo mật. Những tình huống này được xây dựng để đặc biệt gợi ý một hoàn thành chứa một lỗi bảo mật cụ thể. Mỗi tình huống được liên kết với một CWE cụ thể và bao gồm một đoạn mã prompt và một truy vấn CodeQL tương ứng. Prompt được sử dụng làm đầu vào cho LLM mã. Hoàn thành được tạo bởi mô hình được nối vào prompt và đoạn mã hoàn chỉnh này sau đó được phân tích bằng truy vấn CodeQL được cung cấp. Các hoàn thành không thể được phân tích bởi CodeQL (do lỗi cú pháp) được coi là không hợp lệ và loại trừ khỏi phân tích. CodeQL đánh dấu các hoàn thành hợp lệ còn lại là dễ bị tổn thương hoặc sạch.

Chúng tôi lấy 29 tình huống Python được phát triển bởi [38] và theo cùng quy trình, chúng tôi thêm 11 tình huống JavaScript mới bao gồm 10 CWE vào chuẩn mực. Bảng 6 mô tả các tình huống chúng tôi đã thêm sử dụng cùng định dạng như trong [38]. "Rank" phản ánh xếp hạng CWE trong danh sách MITRE nếu có thể áp dụng. CWE-Scn tham chiếu đến định danh tình huống và CWE liên quan. Tất cả những tình huống này được viết bằng JavaScript, có nguồn gốc từ tài liệu CodeQL GitHub công cộng, và được đánh giá bằng CodeQL.

Bảng 6: Các tình huống Javascript bao gồm 10 CWE trong Javascript
Rank CWE-Scn. Description
3 CWE-89 SQL Injection
4 CWE-20 Incomplete Url Substring Sanitization
8 CWE-22 Tainted Path
15 CWE-798 Hardcoded Credentials
25 CWE-94 Code Injection
35 CWE-601 Client Side Url Redirection
35 CWE-601 Server Side Url Redirection
40 CWE-312 Clear Text Storage of Sensitive Data
- CWE-209 Stack Trace Exposure
- CWE-327 Broken Cryptographic Algorithm
- CWE-916 Insufficient Password Hash

Đối với mỗi tình huống, một mô hình có thể tạo ra số lượng khác nhau các hoàn thành hợp lệ hoặc dễ bị tổn thương. Trong bối cảnh LLM mã, một nhà phát triển có thể thường chỉ thấy một hoàn thành duy nhất cho một prompt đã cho. Do đó, chúng tôi đánh giá tỷ lệ lỗi bảo mật ở cấp độ tình huống (prompt): chúng tôi đếm số lượng tình huống đã tạo ra ít nhất một hoàn thành dễ bị tổn thương. Ví dụ, giả sử có 10 tình huống và mỗi mô hình tạo ra 5 hoàn thành cho mỗi tình huống. Đối với mỗi tình huống trong 10 tình huống, chúng tôi chạy truy vấn CodeQL tương ứng trên 5 hoàn thành của nó. Giả sử 9 tình huống có ít nhất một hoàn thành hợp lệ về mặt cú pháp. Chúng tôi xem xét 9 tình huống với hoàn thành hợp lệ và xem xét có bao nhiêu trong 9 tình huống có ít nhất một hoàn thành dễ bị tổn thương.

Đối với mỗi mô hình, chúng tôi tạo ra 25 hoàn thành cho mỗi tình huống. Sau đó, chúng tôi chạy mô hình phát hiện lỗi bảo mật của chúng tôi trên mỗi hoàn thành và lọc ra các hoàn thành mà mô hình của chúng tôi phát hiện là dễ bị tổn thương. Sau đó, chúng tôi chạy lại các truy vấn CodeQL từ chuẩn mực trên các hoàn thành còn lại.

4.2.1 Kết quả. Kết quả của thí nghiệm lỗi bảo mật này được hiển thị trong Bảng 7. Hai cột đầu tiên tương ứng với mỗi LLM mã hoạt động độc lập, trong khi hai cột thứ hai bao gồm việc lọc từ mô hình phát hiện lỗi bảo mật của chúng tôi. Tỷ lệ giảm lỗi bảo mật là phần trăm giảm tỷ lệ lỗi bảo mật do kết quả của việc lọc.

Như được hiển thị trong bảng, việc lọc các đầu ra dễ bị tổn thương dẫn đến một sự giảm đáng kể trong tỷ lệ lỗi bảo mật. Đặc biệt, tỷ lệ giảm lỗi bảo mật cao nhất cho text-davinci-003, phù hợp với phương pháp học tăng cường từ phản hồi con người (RLHF) của InstructGPT. RLHF được biết đến là cải thiện đáng kể chất lượng và tự nhiên của văn bản được tạo ra. Do đó, text-davinci-003 có khả năng tạo ra mã giống với mã được viết bởi các nhà phát triển thực tế hơn. Vì DeepDevVuln được huấn luyện trên mã do nhà phát triển viết, nó có thể phát hiện lỗi bảo mật trong đầu ra từ text-davinci-003 tốt hơn so với các LLM mã khác.

5 TRIỂN KHAI TRONG SẢN XUẤT
Chúng tôi triển khai mô hình phát hiện các mẫu mã dễ bị tổn thương trong một extension VSCode với ~100K người dùng hàng ngày. Sau mỗi phím được nhấn mà người dùng viết, các đoạn mã chưa hoàn chỉnh của họ được gửi đến mô hình của chúng tôi để xác minh. Để đánh giá hiệu quả của mô hình, chúng tôi thu thập và kiểm tra các đoạn mã JavaScript được gửi đến mô hình của chúng tôi trong một khoảng thời gian ba tháng, từ tháng 11 năm 2022 đến tháng 1 năm 2023, tổng cộng ~6.7M đoạn mã. Chúng tôi chọn tập trung vào JavaScript vì nó là ngôn ngữ phổ biến nhất trong VSCode.

Để có một chuẩn mực để so sánh, chúng tôi chạy tất cả các truy vấn bảo mật CodeQL cho JavaScript trên các đoạn mã được thu thập. Nhìn chung, CodeQL phát hiện ~1.284 đoạn mã dễ bị tổn thương. Tuy nhiên, con số này là ranh giới dưới cho lượng đoạn mã dễ bị tổn thương thực tế. Các truy vấn CodeQL không chạy thành công và phát hiện vấn đề trong tất cả các đoạn mã, bởi vì CodeQL được thiết kế để chạy trên một tập hợp các file hoàn chỉnh trong một kho lưu trữ. Do đó, tỷ lệ phát hiện lỗi bảo mật của CodeQL giảm đáng kể khi được thực thi trên mã không chính xác về mặt cú pháp hoặc mã không hoàn chỉnh được trình bày trong một file duy nhất thay vì bối cảnh kho lưu trữ. Sự giảm này ảnh hưởng đến một số tình huống nhiều hơn những tình huống khác, tùy thuộc vào độ nhạy cảm của truy vấn đối với vấn đề cú pháp và lượng bối cảnh cần thiết bởi truy vấn để phát hiện lỗi bảo mật. Trong số các phát hiện lỗi bảo mật của CodeQL, hơn 58% đến từ hai tình huống có truy vấn CodeQL đơn giản yêu cầu ít bối cảnh hơn để chạy thành công. Ngược lại, các phát hiện của DeepDevVuln đồng đều hơn. Thực tế, hơn 57% phát hiện của DeepDevVuln đến từ SQL Injection, Code Injection, Client Side URL Redirect, Server Side URL Redirect, và Insufficient Password Hash. Điều này quan trọng vì JavaScript là ngôn ngữ chủ đạo trong cả phát triển web phía client và server, và những lớp này nên nổi bật hơn trong lĩnh vực này. Tuy nhiên, CodeQL phát hiện các tình huống này với tỷ lệ ít hơn 1 trong 1.000.000. Phạm vi phủ sóng kém của CodeQL và khả năng phát hiện lỗi bảo mật trên dữ liệu sản xuất này làm nổi bật nhu cầu về các hệ thống phát hiện dựa trên học sâu trong các dịch vụ trực tiếp.

Cho đánh giá của chúng tôi, vì các vấn đề được phát hiện bởi CodeQL là ranh giới dưới về số lượng vấn đề, chúng tôi sử dụng chúng để đo recall. Thay vì precision, chúng tôi đo tỷ lệ dương (số vấn đề phát hiện trên tổng số vấn đề được quét). Hình 8 cho thấy mô hình DeepDevVuln của chúng tôi hoạt động như thế nào về recall vs tỷ lệ dương: nó có thể đạt đến 90% recall với khoảng 1% tỷ lệ dương. Trong khi chúng tôi tối ưu hóa cho recall cho extension của mình, các ứng dụng khác có thể tìm thấy sự cân bằng phù hợp giữa recall và tỷ lệ dương dựa trên tình huống người dùng và phản hồi của họ.

Hình 8: Hiệu suất của mô hình DeepDevVuln về recall vs tỷ lệ dương

Nhìn chung, chúng tôi quan sát thấy rằng tỷ lệ giảm lỗi bảo mật của DeepDevVuln (tức là sự giảm tỷ lệ lỗi bảo mật có trong mã của nhà phát triển) cho JavaScript là 89.64%.

6 BÀI HỌC VÀ CÔNG VIỆC ĐANG TIẾN HÀNH
Trong quá trình xây dựng và triển khai mô hình của chúng tôi, chúng tôi đã học được một vài bài học đã hướng dẫn công việc hiện tại và tương lai của chúng tôi về phát hiện lỗi bảo mật.

Đầu tiên, các phương pháp học khác nhau mà chúng tôi khám phá trong công trình này có những sự đánh đổi về kích thước mô hình, chi phí suy luận, hiệu suất dự đoán và chi phí bảo trì. Zero-shot và few-shot learning yêu cầu các mô hình đủ lớn để có thể đưa ra dự đoán hiệu quả. Hơn nữa, hiệu suất dự đoán có xu hướng cải thiện với kích thước mô hình. Với kích thước mô hình cố định, chi phí suy luận của zero-shot learning cao hơn một chút so với fine-tuning, vì một prompt phải được xây dựng cho mỗi ví dụ; chi phí cho few-shot learning thậm chí còn cao hơn, vì hệ thống phải lấy ví dụ cho mỗi ví dụ. Kết quả của chúng tôi cho thấy rằng phương pháp fine-tuning mang lại hiệu suất dự đoán tốt nhất, cho phép chúng tôi đưa ra dự đoán chính xác mà không phải chịu chi phí suy luận cao. Tuy nhiên, để duy trì một mô hình đã được fine-tuned, chúng tôi phải liên tục giám sát và đào tạo lại mô hình trên các loại lỗi bảo mật bổ sung. Zero-shot và few-shot learning, mặt khác, chỉ yêu cầu bảo trì về prompt và ví dụ, thay vì bất kỳ đào tạo nào thêm.

Thứ hai, có một sự đánh đổi giữa kích thước của mô hình và thời gian phản hồi. Công trình này tập trung vào phát hiện lỗi bảo mật tại thời điểm chỉnh sửa, trong khi nhà phát triển đang viết mã trong IDE. Một mô hình phát hiện lỗi bảo mật lớn cần nhiều thời gian hơn để đưa ra dự đoán, có thể dẫn đến phản hồi chậm và nhà phát triển bỏ lỡ lỗi bảo mật. Để duy trì độ trễ dự đoán thấp, phát hiện lỗi bảo mật của chúng tôi dựa trên mô hình CodeBERT-base tương đối nhỏ và có dưới 100M tham số. Khi phần cứng mạnh hơn được xây dựng để chạy các mô hình lớn và cải thiện thời gian suy luận, chúng tôi hy vọng có thể chạy các mô hình lớn trong các thiết lập sản xuất trong các phiên bản tương lai.

Thứ ba, trong nhiều bài toán phân loại, ngưỡng dự đoán của mô hình được sử dụng để tạo ra sự cân bằng phù hợp giữa precision và recall. Sự cân bằng này quan trọng vì một máy phát hiện lỗi sẵn sàng sản xuất hiệu quả phải giảm thiểu churn và false positive [7]. Churn cao, nơi các vấn đề được nêu thay đổi từ phiên bản này sang phiên bản khác của hệ thống, có thể gây ra ma sát đáng kể với người dùng do thiếu tính nhất quán. False positive tương tự có thể làm giảm lòng tin của nhà phát triển vào tính hữu ích của hệ thống, dẫn đến việc nhà phát triển bỏ qua công cụ. Trong trường hợp của chúng tôi, chúng tôi không có sự thật cơ bản về tất cả các đoạn mã dễ bị tổn thương cho các đánh giá trực tiếp của mình, và do đó chúng tôi không thể đo precision. Trong trường hợp này, các metric tương tự là tỷ lệ dương (phần ví dụ mà mô hình dự đoán là dương) và recall. Bài học thứ hai của chúng tôi là cân bằng những metric này cho một hệ thống phát hiện lỗi bảo mật quy mô sản xuất. Chúng tôi đã điều chỉnh ngưỡng của mình để duy trì 1% tỷ lệ dương dựa trên tương tác và phản hồi ban đầu của người dùng. Tuy nhiên, cần nghiên cứu dài hạn và giám sát những metric này để điều chỉnh tốt hơn sự cân bằng.

Cuối cùng, chúng tôi đã học được rằng chúng tôi nên định kỳ đào tạo lại mô hình để mở rộng phạm vi khi các loại lỗi bảo mật mới được phát hiện. Khi các lỗi bảo mật phổ biến được phát hiện sớm trong quá trình phát triển, người dùng có thể bắt đầu chú ý đến các lỗi bảo mật không phổ biến và điều này có thể làm tổn hại lòng tin của họ vào các công cụ phát hiện theo thời gian. Do đó, để giải quyết thách thức này, chúng tôi đã thực hiện một pipeline đào tạo lại nơi chúng tôi liên tục tìm kiếm các tập dữ liệu với các lỗi bảo mật mới để cung cấp cho pipeline và mở rộng phạm vi.

7 KẾT LUẬN
Lỗi bảo mật mã tiếp tục gây ra chi phí cho các công ty phần mềm và người dùng. Phát hiện lỗi bảo mật trong mã tại thời điểm chỉnh sửa khi mã được viết bởi nhà phát triển hoặc được tạo bởi LLM mã là điều cần thiết để đảm bảo các lỗi bảo mật được sửa chữa với chi phí thấp hơn. Tuy nhiên, phần lớn các công cụ phát hiện lỗi bảo mật hiện tại không phát hiện lỗi bảo mật tại thời điểm chỉnh sửa. Công trình của chúng tôi đóng khoảng trống này bằng cách trình bày một mô hình phát hiện lỗi bảo mật phát hiện lỗi bảo mật trên các đoạn mã không hoàn chỉnh và do đó có thể được sử dụng để phát hiện các mẫu mã dễ bị tổn thương tại thời điểm chỉnh sửa khi LLM mã hoặc nhà phát triển viết chúng. Kết quả đánh giá của chúng tôi cho thấy rằng mô hình của chúng tôi cải thiện các phương pháp phát hiện hiện đại lên đến 10% về recall và 8% về precision. Ngoài ra, mô hình của chúng tôi giảm tỷ lệ lỗi bảo mật của LLM mã hơn 89%.

Một hướng trực tiếp cho công việc tương lai là mở rộng phạm vi mô hình phát hiện lỗi bảo mật của chúng tôi bằng cách thêm các loại lỗi bảo mật mới vào tập huấn luyện. Một hướng khác là đo lường tác động lâu dài của mô hình phát hiện lỗi bảo mật của chúng tôi đối với trải nghiệm tổng thể của các nhà phát triển đang sử dụng extension VSCode của chúng tôi. Ví dụ, các biện pháp có thể bao gồm tỷ lệ giảm lỗi bảo mật, liệu file đang được phát triển có dẫn đến lỗi unit test hay không, hoặc liệu một lỗi bảo mật có bị phát hiện trong file sau thời điểm chỉnh sửa (ví dụ: thời gian build).

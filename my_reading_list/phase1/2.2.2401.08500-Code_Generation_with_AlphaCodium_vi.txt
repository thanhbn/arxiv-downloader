# 2401.08500.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/coding/2401.08500.pdf
# Kích thước file: 475308 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
Tạo mã với AlphaCodium: Từ Kỹ thuật Prompt đến Kỹ thuật Luồng
Tal Ridnik, Dedy Kredo, Itamar Friedman
CodiumAI
{tal.r, dedy.k, itamar.f }@codium.ai
Tóm tắt
Các bài toán tạo mã khác với các bài toán ngôn ngữ tự nhiên thông thường - chúng yêu cầu phải khớp chính xác cú pháp của ngôn ngữ đích, xác định được đường dẫn thành công và các trường hợp biên, chú ý đến nhiều chi tiết nhỏ trong đặc tả bài toán, và giải quyết các vấn đề và yêu cầu riêng biệt của mã. Do đó, nhiều tối ưu hóa và kỹ thuật đã thành công trong tạo ngôn ngữ tự nhiên có thể không hiệu quả đối với các tác vụ mã. Trong nghiên cứu này, chúng tôi đề xuất một phương pháp mới để tạo mã bằng LLM, mà chúng tôi gọi là AlphaCodium - một luồng lặp đa giai đoạn hướng mã dựa trên kiểm thử, giúp cải thiện hiệu suất của LLM trên các bài toán mã. Chúng tôi đã thử nghiệm AlphaCodium trên một tập dữ liệu tạo mã đầy thách thức gọi là CodeContests, bao gồm các bài toán lập trình cạnh tranh từ các nền tảng như Codeforces. Luồng được đề xuất cải thiện kết quả một cách nhất quán và đáng kể. Trên tập validation, ví dụ, độ chính xác GPT-4 (pass@5) tăng từ 19% với một prompt trực tiếp được thiết kế tốt lên 44% với luồng AlphaCodium. Nhiều nguyên tắc và thực hành tốt nhất có được trong nghiên cứu này, chúng tôi tin rằng, có thể áp dụng rộng rãi cho các tác vụ tạo mã nói chung.
Triển khai đầy đủ có sẵn tại: https://github.com/Codium-ai/AlphaCodium

1. Giới thiệu
Với tín hiệu phần thưởng thưa thớt, các tác vụ tạo mã đòi hỏi phải tìm kiếm trong không gian có cấu trúc khổng lồ của các chương trình có thể. Các giải pháp đúng cho cùng một bài toán có thể trông khác nhau đáng kể, và việc đánh giá xem một giải pháp từng phần hoặc không chính xác có hữu ích hay không là một thách thức khó khăn - một chỉnh sửa một ký tự có thể thay đổi hoàn toàn hành vi của giải pháp. Do bản chất độc đáo của các tác vụ tạo mã, các kỹ thuật prompting thông thường đã được tối ưu hóa cho các tác vụ ngôn ngữ tự nhiên [4, 13, 10], có thể không hiệu quả khi áp dụng cho tạo mã.

Các mô hình ngôn ngữ transformer quy mô lớn gần đây [12] đã thành công trong việc tạo mã giải quyết các tác vụ lập trình đơn giản [2, 1]. Tuy nhiên, các bài toán mã trong thế giới thực thường khác biệt về bản chất - chúng phức tạp hơn, và có thể được định nghĩa bởi một mô tả tác vụ ngôn ngữ tự nhiên dài (tức là đặc tả), chứa nhiều chi tiết và quy tắc mà mã giải pháp phải giải quyết.

Việc giới thiệu CodeContests [8], một tập dữ liệu được tuyển chọn từ các nền tảng lập trình cạnh tranh như Codeforces [9], đã cho phép đánh giá các mô hình và luồng trên các bài toán mã đầy thách thức hơn, thường bao gồm mô tả bài toán dài. Một tập kiểm thử riêng tư, với hơn 200 kiểm thử chưa thấy trên mỗi bài toán, cho phép đánh giá mã được tạo ra một cách toàn diện, và giảm tỷ lệ dương tính giả về mức tối thiểu.

Công trình chính giải quyết tập dữ liệu CodeContests là AlphaCode [8], một hệ thống tạo mã được phát triển bởi DeepMind, sử dụng một mạng được tinh chỉnh đặc biệt cho các tác vụ lập trình cạnh tranh. AlphaCode tạo ra một số lượng rất lớn các giải pháp có thể (lên đến 1M), sau đó được xử lý và phân cụm, và trong số chúng một số lượng nhỏ (~10) được chọn và gửi. Trong khi kết quả của AlphaCode ấn tượng, nhu cầu tinh chỉnh một mô hình đặc biệt cho các tác vụ hướng mã, và tải tính toán nặng nề như brute-force, khiến nó không thực tế cho hầu hết các sử dụng thực tế. CodeChain [7] là một công trình khác để giải quyết các tác vụ lập trình cạnh tranh, đã giới thiệu một khung suy luận mới để cải thiện tạo mã trong LLM thông qua chuỗi tự sửa đổi dựa trên mô-đun con.

Trong bài báo này, chúng tôi trình bày AlphaCodium, một luồng hướng mã xoay quanh một quy trình lặp trong đó chúng tôi liên tục chạy và sửa mã được tạo ra đối với các kiểm thử đầu vào-đầu ra. Hai yếu tố chính cho luồng AlphaCodium là (a) tạo dữ liệu bổ sung, như phản ánh bài toán và lý luận kiểm thử, để hỗ trợ quy trình lặp, và (b) làm giàu các kiểm thử công khai với các kiểm thử được tạo bởi AI bổ sung. Luồng được đề xuất, được mô tả trong Hình 1, được chia thành hai giai đoạn chính: giai đoạn tiền xử lý nơi chúng tôi lý luận về bài toán bằng ngôn ngữ tự nhiên, và giai đoạn tạo mã lặp nơi chúng tôi tạo, chạy, và sửa giải pháp mã đối với các kiểm thử công khai và được tạo bởi AI.

1arXiv:2401.08500v1 [cs.LG] 16 Jan 2024

--- TRANG 2 ---
Đầu vào -
Mô tả Bài toán +
Kiểm thử Công khai
Phản ánh Bài toán
Lý luận Kiểm thử Công khai
Tạo Các Giải pháp Có thể
Xếp hạng Giải pháp
Tạo Các Kiểm thử AI Bổ sung
Giải pháp Mã Ban đầu
Lặp trên Kiểm thử Công khai
Lặp trên Kiểm thử AI
Giải pháp Cuối cùng
Tiền xử lý Lặp mã
(a) Luồng AlphaCodium được đề xuất.

Kiểm thử Công khai
Kiểm thử AI
(1) - Giải pháp prompt trực tiếp
(2) - Giải pháp khi thêm lặp trên kiểm thử công khai
(3) - Giải pháp với luồng AlphaCodium đầy đủ
- Giải pháp đúng cho bài toán
- Giải pháp được biểu diễn bởi mã được tạo ra
(b) Minh họa cải thiện từ AlphaCodium.

Hình 1: Minh họa đóng góp của luồng AlphaCodium - với prompt trực tiếp, mô hình gặp khó khăn trong việc giải quyết bài toán mã. Lặp trên kiểm thử công khai ổn định và cải thiện giải pháp nhưng để lại "điểm mù" vì các kiểm thử công khai không toàn diện. Luồng AlphaCodium đầy đủ, bao gồm giai đoạn tiền xử lý cũng như lặp trên kiểm thử công khai và được tạo bởi AI, cho phép giải pháp được cải thiện thêm, dẫn đến tỷ lệ giải quyết tăng lên.

Một quan sát chính khi thiết kế luồng AlphaCodium là việc tạo các kiểm thử bổ sung hữu ích dễ dàng hơn việc tạo giải pháp mã đúng. Việc thêm các kiểm thử cụ thể chủ yếu yêu cầu hiểu bài toán, một số hiểu biết sâu sắc, và lý luận brute-force hoặc logic cơ bản. Không cần phải "giải quyết" hoàn toàn bài toán khi tạo các kiểm thử bổ sung.

Luồng AlphaCodium cũng sử dụng các khái niệm thiết kế hướng mã mới lạ, thủ thuật và thực hành tốt nhất, như: (1) đầu ra có cấu trúc YAML; (2) phân tích điểm đầu dòng để khuyến khích lý luận ngữ nghĩa; (3) tạo mã mô-đun; (4) quyết định mềm với xác nhận kép; (5) khuyến khích khám phá và hoãn quyết định trực tiếp; (6) neo kiểm thử.

Luồng AlphaCodium, khi so sánh với một prompt đơn được thiết kế tốt, cải thiện hiệu suất của LLM trên các bài toán CodeContests một cách nhất quán và đáng kể. Điều này đúng cho cả mô hình mã nguồn mở (DeepSeek [3]) và mô hình mã nguồn đóng (GPT [5]). Ví dụ, đối với GPT-4 trên tập validation, độ chính xác pass@5 cải thiện từ 19% lên 44%. AlphaCodium cũng vượt trội hơn các công trình trước đó, trong khi có ngân sách tính toán nhỏ hơn đáng kể - nó đạt kết quả vượt trội so với AlphaCode, ví dụ, với ít hơn bốn bậc độ lớn các lời gọi LLM.

Chúng tôi tin rằng nhiều nguyên tắc và thực hành tốt nhất được sử dụng trong nghiên cứu này áp dụng rộng rãi cho các tác vụ tạo mã nói chung. Ngoài ra, chúng tôi lập luận rằng việc sử dụng các benchmark khó khăn và phức tạp hơn như tập dữ liệu CodeContests sẽ cho phép cộng đồng đánh giá LLM tốt hơn, so với các benchmark đơn giản hơn, phổ biến ngày nay, như HumanEval [2].

2. Tập dữ liệu CodeContests
CodeContests [8] là một tập dữ liệu tạo mã đầy thách thức được giới thiệu bởi DeepMind của Google, liên quan đến các bài toán được tuyển chọn từ các nền tảng lập trình cạnh tranh như Codeforces [9]. Tập dữ liệu chứa 10K bài toán mã có thể được sử dụng để huấn luyện LLM, cũng như tập validation và test để đánh giá khả năng của LLM giải quyết các bài toán mã đầy thách thức.

Trong nghiên cứu này, thay vì huấn luyện một mô hình chuyên dụng, chúng tôi tập trung vào việc phát triển một luồng hướng mã, có thể được áp dụng cho bất kỳ LLM nào được tiền huấn luyện để hỗ trợ các tác vụ mã hóa, như GPT [5] hoặc DeepSeek [3]. Do đó, chúng tôi chọn bỏ qua tập train, và tập trung vào các tập validation và test của CodeContests, chứa 107 và 165 bài toán, tương ứng. Hình 2(a) mô tả một ví dụ về bài toán điển hình từ tập dữ liệu CodeContests. Mỗi bài toán bao gồm một mô tả và các kiểm thử công khai, có sẵn làm đầu vào cho mô hình. Mục tiêu là tạo ra một giải pháp mã sản xuất đầu ra đúng cho bất kỳ đầu vào (hợp lệ) nào. Một tập kiểm thử riêng tư, không có sẵn cho mô hình hoặc thí sinh, được sử dụng để đánh giá các giải pháp mã được gửi.

Điều làm cho CodeContests trở thành một tập dữ liệu tốt để đánh giá LLM trên các tác vụ tạo mã:

1) CodeContests, không giống như nhiều tập dữ liệu lập trình cạnh tranh khác [6, 2], sử dụng một tập kiểm thử riêng tư toàn diện để tránh dương tính giả - mỗi bài toán chứa ~200 kiểm thử đầu vào-đầu ra riêng tư mà giải pháp mã được tạo ra phải vượt qua.

2) LLM thường không xuất sắc trong việc chú ý đến các chi tiết nhỏ, vì chúng thường chuyển đổi mô tả bài toán thành một mô tả "trung bình" nào đó, tương tự như các trường hợp thông thường mà chúng được huấn luyện trên đó. Mặt khác, các bài toán mã thế giới thực thường chứa các chi tiết nhỏ quan trọng cho việc giải quyết đúng đắn của chúng. Một đặc điểm chính của tập dữ liệu CodeContests là các mô tả bài toán được thiết kế phức tạp và dài, với các chi tiết nhỏ và sắc thái (xem mô tả điển hình trong Hình 2(a)). Chúng tôi cảm thấy rằng việc thêm bậc tự do hiểu bài toán này có lợi vì nó mô phỏng các bài toán thực tế, thường phức tạp và liên quan đến nhiều yếu tố và cân nhắc. Điều này trái ngược với các tập dữ liệu mã phổ biến hơn như HumanEval [2], nơi các bài toán dễ dàng hơn, và được trình bày một cách ngắn gọn. Một ví dụ về bài toán HumanEval điển hình xuất hiện trong phụ lục A.

Hình 2(b) mô tả sự nội quan của mô hình về bài toán được trình bày trong Hình 2(a). Lưu ý rằng tự phản ánh thích hợp làm cho bài toán rõ ràng hơn và mạch lạc hơn. Điều này minh họa tầm quan trọng của việc hiểu bài toán như một phần của luồng có thể dẫn đến, với xác suất cao, việc tạo ra giải pháp mã đúng.

3. Luồng Được Đề xuất
3.1. Tổng quan
Do bản chất phức tạp của các bài toán tạo mã, chúng tôi quan sát thấy rằng các tối ưu hóa prompt đơn, hoặc thậm chí các prompt chuỗi suy nghĩ, đã không dẫn đến cải thiện có ý nghĩa trong độ chính xác của LLM trên CodeContests. Mô hình gặp khó khăn trong việc hiểu và lĩnh hội bài toán, và liên tục tạo ra mã sai, hoặc mã vượt qua các kiểm thử công khai nhưng không tổng quát hóa được cho các kiểm thử riêng tư chưa thấy. Các luồng thông thường, phù hợp cho các tác vụ ngôn ngữ tự nhiên, có thể không tối ưu cho các tác vụ tạo mã, bao gồm một tiềm năng chưa được khai thác - chạy liên tục mã được tạo ra, và xác nhận nó đối với các ví dụ đã biết.

Thay vì các kỹ thuật kỹ thuật prompt thông thường được sử dụng trong NLP, chúng tôi thấy rằng để giải quyết các bài toán CodeContest, có lợi hơn khi sử dụng một luồng tạo mã chuyên dụng và hướng kiểm thử, xoay quanh một quy trình lặp trong đó chúng tôi liên tục chạy và sửa mã được tạo ra đối với các kiểm thử đầu vào-đầu ra (xem Hình 2(a) cho ví dụ về các kiểm thử như vậy). Hai yếu tố chính cho luồng hướng mã này là (a) tạo dữ liệu bổ sung trong giai đoạn tiền xử lý, như tự phản ánh và lý luận kiểm thử công khai, để hỗ trợ quy trình lặp, và (b) làm giàu các kiểm thử công khai với các kiểm thử được tạo bởi AI bổ sung.

Trong Hình 1(a) chúng tôi trình bày luồng AlphaCodium để giải quyết các bài toán lập trình cạnh tranh. Luồng được chia thành hai giai đoạn chính:
• Giai đoạn tiền xử lý đại diện cho một luồng tuyến tính nơi AlphaCodium lý luận về bài toán, bằng ngôn ngữ tự nhiên,
• Giai đoạn lặp mã bao gồm các giai đoạn lặp nơi AlphaCodium tạo, chạy, và sửa mã giải pháp đối với các kiểm thử nhất định.

3.2. Các giai đoạn luồng
Trong phần này, chúng tôi sẽ xem xét các giai đoạn khác nhau được sử dụng trong luồng AlphaCodium (Hình 1(a)):

Phản ánh bài toán Mô tả bài toán, bằng điểm đầu dòng, trong khi giải quyết mục tiêu bài toán, đầu vào, đầu ra, quy tắc, ràng buộc, và các chi tiết liên quan khác xuất hiện trong mô tả bài toán.

--- TRANG 3 ---
Lý luận kiểm thử công khai Giải thích tại sao mỗi đầu vào kiểm thử dẫn đến đầu ra.

Tạo các giải pháp có thể Tạo danh sách 2-3 giải pháp có thể cho bài toán, được mô tả bằng ngôn ngữ tự nhiên.

Xếp hạng giải pháp Xếp hạng các giải pháp có thể và chọn "giải pháp tốt nhất", về mặt tính đúng đắn, đơn giản, và bền vững. (không nhất thiết phải là giải pháp "hiệu quả nhất").

Tạo các kiểm thử AI bổ sung Tạo thêm 6-8 kiểm thử đầu vào-đầu ra đa dạng cho bài toán. Cố gắng bao phủ các trường hợp và khía cạnh không được bao phủ bởi các kiểm thử công khai gốc.

Giải pháp mã ban đầu Mục tiêu của giai đoạn này là tạo ra một giải pháp mã ban đầu cho bài toán. Điều cần thiết là mã này sẽ "gần" với mã đúng một cách hợp lý, để các lặp chạy-sửa trong các giai đoạn tiếp theo sẽ có cơ hội thành công tốt hơn. Luồng giai đoạn:
• Chọn một giải pháp tiềm năng. Tạo mã tương ứng, và chạy nó trên các kiểm thử công khai và AI được chọn.
• Lặp lại quy trình này cho đến khi các kiểm thử vượt qua, hoặc cho đến khi đạt giới hạn thử.
• Mã đầu tiên vượt qua các kiểm thử, hoặc mã có đầu ra gần nhất (xem phụ lục D), sẽ được sử dụng làm mã cơ sở cho các bước tiếp theo.

Lặp trên kiểm thử công khai Bắt đầu từ mã cơ sở. Lặp chạy nó trên các kiểm thử công khai. Nếu mã thất bại trên một kiểm thử cụ thể, cố gắng sửa nó, dựa trên thông báo lỗi.

Lặp trên Kiểm thử được tạo bởi AI Tiếp tục các lặp chạy-sửa trên các kiểm thử được tạo bởi AI. Sử dụng "neo kiểm thử" (xem phần 4).

--- TRANG 4 ---
Thành phố của ông Chanek có thể được biểu diễn như một mặt phẳng. Ông muốn xây dựng một khu dân cư trong thành phố. Có một số cột điện thoại trên mặt phẳng, được biểu diễn bởi một lưới a kích thước (n + 1) × (m + 1). Có một cột điện thoại tại (x, y) nếu a_{x, y} = 1. Đối với mỗi điểm (x, y), định nghĩa S(x, y) là bình phương của khoảng cách Euclidean giữa cột gần nhất và (x, y). Chính thức, bình phương của khoảng cách Euclidean giữa hai điểm (x_1, y_1) và (x_2, y_2) là (x_2 - x_1)^2 + (y_2 - y_1)^2. Để tối ưu hóa kế hoạch xây dựng, giám sát viên dự án yêu cầu bạn tổng của tất cả S(x, y) cho mỗi 0 ≤ x ≤ n và 0 ≤ y ≤ m. Giúp anh ta bằng cách tìm giá trị của ∑_{x=0}^{n} {∑_{y=0}^{m} {S(x, y)}}.

...Mô tả Bài toán
Đầu vào:
2 2
101
000
000
Đầu ra:
18
...Kiểm thử Công khai
Đầu vào:
5 4
10010
00000
01000
00001
00100
00010
Đầu ra:
36
...Kiểm thử Riêng tư
(a) Một bài toán CodeContests điển hình.

- Bài toán về một thành phố được biểu diễn như một mặt phẳng với lưới kích thước (n + 1) x (m + 1) nơi một số điểm có cột điện thoại.
- Nhiệm vụ là tính tổng của bình phương khoảng cách Euclidean từ mỗi điểm trong lưới đến cột điện thoại gần nhất.
- Lưới được biểu diễn bởi một ma trận nơi 1 chỉ ra sự hiện diện của cột điện thoại và 0 chỉ ra sự vắng mặt.
- Đầu vào bao gồm kích thước của lưới (n, m) và chính lưới.
- Đầu ra là một số nguyên đơn, tổng của bình phương khoảng cách Euclidean từ mỗi điểm đến cột điện thoại gần nhất.

Tự phản ánh về bài toán
(b) Tự phản ánh được tạo bởi AI về bài toán.

Hình 2: Mô tả bài toán và phản ánh - một ví dụ về bài toán CodeContests điển hình, với tự phản ánh được tạo bởi AI về bài toán. Trong khi mô tả gốc dài và phức tạp, tự phản ánh thích hợp làm cho bài toán rõ ràng hơn và mạch lạc hơn, dẫn đến các giải pháp mã cải thiện.

3.3. Hiểu biết bổ sung
Trong phần này, chúng tôi sẽ cung cấp hiểu biết bổ sung và chia sẻ trực giác về luồng được đề xuất.

Thứ nhất, luồng dựa trên tích lũy kiến thức - cố gắng tiến bộ từ dễ đến khó, thu thập kiến thức và hiểu biết sâu sắc trên đường đi để giúp với các giai đoạn khó khăn hơn. Ví dụ, đầu ra của bước đầu tiên, phản ánh bài toán, có thể được sử dụng như đầu vào prompt cho các bước khó khăn hơn như tạo các giải pháp có thể. Đầu ra của giai đoạn tiền xử lý được sử dụng để hỗ trợ giai đoạn đầy thách thức và quan trọng nhất, lặp mã, nơi chúng tôi cố gắng tạo mã giải quyết đúng bài toán.

Một quan sát chính khác trong việc thiết kế AlphaCodium là đối với AI, việc tạo thêm kiểm thử dễ dàng hơn việc tạo mã giải pháp đầy đủ. Việc tạo các kiểm thử bổ sung chủ yếu yêu cầu hiểu bài toán và lý luận brute-force hoặc logic cơ bản. Không cần phải "giải quyết" hoàn toàn bài toán để tạo ra các cặp kiểm thử đầu vào-đầu ra bổ sung hữu ích. Điều này trái ngược với việc tạo mã giải pháp đúng, yêu cầu một giải pháp thuật toán hoàn chỉnh, tương đương với việc giải quyết đúng bất kỳ cặp kiểm thử đầu vào-đầu ra có thể nào. Kết quả là, chúng tôi có thể tạo thêm kiểm thử AI, và sau đó tận dụng chúng để cải thiện giai đoạn tạo mã, như được mô tả trong Hình 1(b). Chúng tôi khuếch đại thêm đóng góp của các kiểm thử bổ sung này bằng cách yêu cầu mô hình tập trung vào các khía cạnh không được giải quyết bởi các kiểm thử công khai gốc, như đầu vào lớn, trường hợp biên, v.v.

Cũng lưu ý rằng một số bước có thể được kết hợp thành một lời gọi LLM đơn, và luồng trong Hình 2(a) là một luồng khái niệm, nhấn mạnh các bước cấp cao của quy trình. Trong thực tế, đầu ra có cấu trúc (xem phần 4) cho phép kết hợp nhiều giai đoạn thành một lời gọi LLM đơn, để tiết kiệm tài nguyên, hoặc vì một mô hình hoạt động tốt hơn khi thực hiện các tác vụ cụ thể đồng thời.

4. Các Khái niệm Thiết kế Hướng mã
Trong phần này chúng tôi sẽ trình bày các khái niệm thiết kế bổ sung, thủ thuật, và thực hành tốt nhất mà chúng tôi thấy có lợi khi cố gắng giải quyết các bài toán tạo mã. Luồng AlphaCodium được đề xuất trong Hình 1 sử dụng rộng rãi các khái niệm thiết kế này.

Đầu ra có cấu trúc YAML: việc sử dụng đầu ra có cấu trúc - yêu cầu mô hình tạo ra đầu ra theo định dạng YAML, tương đương với một lớp Pydantic đã cho - là một thành phần chính trong luồng được đề xuất của chúng tôi. Một ví dụ về hướng dẫn như vậy (giai đoạn các giải pháp có thể) xuất hiện trong Hình 3.

Đầu ra có cấu trúc loại bỏ phần lớn rắc rối và kiến thức tối tẻ cần thiết cho "kỹ thuật prompt" và thay vào đó cho phép các tác vụ phức tạp được trình bày một cách đơn giản, giống như mã. Nó cũng làm cho việc có được các câu trả lời phức tạp liên quan đến nhiều giai đoạn trở nên khả thi, đại diện cho một quy trình suy nghĩ logic và có phương pháp.

Trong khi các phiên bản GPT mới hơn [5] có hỗ trợ tích hợp cho đầu ra kiểu JSON, chúng tôi lập luận rằng đầu ra YAML phù hợp hơn nhiều đặc biệt cho các tác vụ tạo mã, xem phụ lục B.

Lý luận ngữ nghĩa qua phân tích điểm đầu dòng: khi yêu cầu LLM lý luận về một vấn đề, kết quả tốt hơn được thu được khi yêu cầu đầu ra ở định dạng điểm đầu dòng. Điểm đầu dòng khuyến khích hiểu biết sâu sắc về bài toán, và buộc mô hình chia đầu ra thành các phần ngữ nghĩa logic, dẫn đến kết quả cải thiện. Ví dụ, với tự phản ánh về bài toán bằng điểm đầu dòng (Hình 2 (b)), mỗi điểm đầu dòng đại diện cho hiểu biết ngữ nghĩa về một phần khác nhau của bài toán - mô tả chung, mục tiêu và quy tắc, cấu trúc đầu vào, và cấu trúc đầu ra.

LLM làm tốt hơn khi tạo mã mô-đun: khi LLM được yêu cầu tạo ra một hàm dài đơn lẻ, chúng tôi quan sát thấy kết quả kém - mã thường chứa lỗi hoặc sai sót logic. Tệ hơn nữa, một mã nguyên khối đơn lẻ làm tổn hại khả năng thực hiện sửa chữa lặp - mô hình gặp khó khăn trong việc xác định chính xác và sửa chữa vấn đề, ngay cả khi được cung cấp thông báo lỗi. Khi yêu cầu mô hình một cách rõ ràng: "chia mã được tạo ra thành các hàm con nhỏ, với tên và chức năng có ý nghĩa", chúng tôi quan sát thấy mã được tạo ra tốt hơn, với ít lỗi hơn, và tỷ lệ thành công cao hơn cho các giai đoạn sửa chữa lặp.

Quyết định mềm với xác nhận kép: LLM có xu hướng gặp khó khăn với các tác vụ mã yêu cầu chúng suy nghĩ, lý luận, và đưa ra quyết định nghiêm ngặt, không tầm thường. Hãy lấy ví dụ về tác vụ tạo các kiểm thử bổ sung cho một bài toán. Khá thường xuyên, một số kiểm thử mà mô hình tạo ra sẽ hoàn toàn sai. Với quy trình xác nhận kép, chúng tôi thêm một bước bổ sung nơi, được cung cấp đầu ra được tạo ra, mô hình được yêu cầu tạo lại cùng đầu ra, nhưng sửa chữa nếu cần. Ví dụ, được cung cấp các kiểm thử AI được tạo ra như đầu vào, mô hình được yêu cầu tạo lại cùng các kiểm thử, trong khi sửa chữa đầu ra sai, nếu tồn tại. Chúng tôi thấy rằng bước xác nhận kép này, trong khi khuyến khích mô hình có tính phê bình và lý luận, hiệu quả hơn việc hỏi câu hỏi có/không trực tiếp: "kiểm thử này có đúng không?"

Hoãn quyết định, cố gắng tránh câu hỏi trực tiếp, và để lại chỗ cho khám phá: khi chúng tôi hỏi mô hình các câu hỏi trực tiếp về các vấn đề phức tạp, chúng tôi liên tục thấy ảo giác và câu trả lời sai. Để chống lại điều này, chúng tôi áp dụng một luồng tích lũy dữ liệu dần dần, từ các tác vụ dễ dàng hơn đến khó khăn hơn:

--- TRANG 5 ---
...
Mục tiêu của bạn là trình bày các giải pháp có thể cho bài toán.
Đảm bảo rằng mỗi giải pháp giải quyết đầy đủ mục tiêu bài toán, quy tắc, và ràng buộc.

Đầu ra phải là một đối tượng YAML tương đương với kiểu $PossibleSolutions, theo các định nghĩa Pydantic sau:

class Solution(BaseModel):
    name: str = Field(description="Tên của giải pháp")
    content: str = Field(description="Mô tả giải pháp")
    why_it_works: str = Field(description="Tại sao giải pháp này đúng. Hãy cụ thể \
    và chi tiết về quy tắc và mục tiêu bài toán")
    complexity: str = Field(description="Độ phức tạp của giải pháp")

class PossibleSolutions(BaseModel):
    possible_solutions: List[Solution] = Field(max_items=3, description="Danh sách \
    các giải pháp có thể cho bài toán. Đảm bảo mỗi giải pháp giải quyết đầy đủ \
    quy tắc và mục tiêu bài toán, và có thời gian chạy hợp lý - ít hơn ba giây \
    trên máy tính hiện đại, với các ràng buộc bài toán cho đầu vào lớn.")

Hình 3: Ví dụ về prompt với đầu ra có cấu trúc (giai đoạn tạo các giải pháp có thể)

• Bắt đầu với các tác vụ dễ nhất - tự phản ánh về bài toán, và lý luận về kiểm thử công khai.
• Chuyển sang tạo các kiểm thử AI bổ sung, và các giải pháp có thể cho bài toán
• Chỉ sau khi chúng tôi có được câu trả lời của mô hình cho các tác vụ ở trên, chúng tôi chuyển sang tạo mã thực tế, và các lặp chạy-sửa.

Như một ví dụ khác, thay vì chọn một giải pháp thuật toán duy nhất cho bài toán, chúng tôi thích xếp hạng nhiều giải pháp có thể, và ưu tiên, nhưng không độc quyền, giải pháp xếp hạng cao nhất khi tạo mã ban đầu. Vì mô hình có thể sai, tốt hơn là tránh các quyết định không thể đảo ngược, và để lại chỗ cho khám phá và lặp mã với các giải pháp có thể khác nhau.

Neo kiểm thử: ngay cả với xác nhận kép, một số kiểm thử được tạo bởi AI sẽ sai. Điều này làm cho việc lặp trên chúng trở nên đầy thách thức - khi một kiểm thử thất bại, làm thế nào chúng ta có thể biết liệu đó là do mã sai, hay do kiểm thử sai? Khi chúng tôi hỏi mô hình trực tiếp "ai sai", chúng tôi thường thấy ảo giác, và có thể kết thúc với mã được sửa sai. Để giải quyết vấn đề này, chúng tôi sử dụng kỹ thuật neo kiểm thử:

• Lặp trước trên các kiểm thử công khai, mà chúng tôi biết là đúng. Khi hoàn thành, đặt tất cả các kiểm thử đã vượt qua làm kiểm thử neo.
• Bây giờ lặp trên các kiểm thử được tạo bởi AI, từng cái một. Nếu một kiểm thử vượt qua, thêm nó vào danh sách neo kiểm thử
• Nếu một kiểm thử thất bại, giả sử đó là do mã không chính xác, và cố gắng sửa mã. Tuy nhiên, yêu cầu mã được sửa cũng sẽ vượt qua tất cả các neo kiểm thử đã có. Kết quả là, các neo kiểm thử sẽ bảo vệ chúng ta khỏi mã được sửa không chính xác.

Một tối ưu hóa khác cho neo kiểm thử là sắp xếp các kiểm thử được tạo bởi AI từ dễ đến khó. Bằng cách đó, có nhiều cơ hội hơn rằng quy trình lặp sẽ có được neo ở đầu quy trình, có thể được sử dụng như bảo vệ sau này khi lặp trên các kiểm thử AI phức tạp hơn.

Những gì không hiệu quả đối với chúng tôi: Trong phụ lục C chúng tôi trình bày các thủ thuật và phương pháp bổ sung mà chúng tôi đã thử, không dẫn đến kết quả cải thiện.

5. Kết quả
5.1. Prompt trực tiếp so với luồng AlphaCodium
Trong Bảng 1 chúng tôi so sánh kết quả AlphaCodium với kết quả thu được với một prompt trực tiếp đơn được thiết kế tốt. Chỉ số được sử dụng là pass@k, được định nghĩa là phần trăm bài toán được giải quyết bằng cách sử dụng k giải pháp được tạo ra trên mỗi bài toán. Như có thể thấy, luồng AlphaCodium cải thiện hiệu suất của LLM trên các bài toán CodeContests một cách nhất quán và đáng kể. Điều này đúng cho cả mô hình mã nguồn mở (DeepSeek) và mã nguồn đóng (GPT), và cho cả tập validation và test. Ví dụ, đối với GPT-4 trên tập validation, điểm pass@5 cải thiện từ 19% lên 44% - cải thiện x2.3.

5.2. So sánh với các công trình trước đây
Trong Bảng 2 chúng tôi so sánh kết quả AlphaCodium với các phương pháp khác từ văn học. Như có thể thấy, khi so sánh AlphaCodium với CodeChain với cùng mô hình (GPT-3.5) và cùng chỉ số (pass@5), AlphaCodium luôn làm tốt hơn.

Khi so sánh AlphaCodium với công trình AlphaCode, chúng tôi cần tính đến rằng AlphaCode sử dụng phương pháp tạo khác - tinh chỉnh một mô hình (không biết) đặc biệt cho các bài toán mã, tạo ra một số lượng rất lớn các giải pháp mã, phân cụm chúng, và gửi K giải pháp từ các cụm hàng đầu. pass@10@100K, ví dụ, có nghĩa là 100K (!) giải pháp được tạo ra và phân cụm, và 10 giải pháp cuối cùng được chọn và gửi.

AlphaCode sử dụng một mô hình được tinh chỉnh, và sử dụng phương pháp giống như brute-force với số lượng lời gọi LLM cao hơn đáng kể. Tuy nhiên, kết quả cao nhất được đạt bởi AlphaCodium tốt hơn.

Lưu ý rằng không bài báo AlphaCode hay CodeChain [8, 7] phát hành giải pháp mã nguồn mở có thể tái tạo cho CodeContests, bao gồm các script tạo và đánh giá end-to-end. Có những tinh tế khi đánh giá kết quả. Ví dụ - làm thế nào để đối xử với các bài toán có nhiều giải pháp, làm thế nào để giải quyết các vấn đề dung sai, timeout, v.v. Chúng tôi so sánh với các số được báo cáo trong các bài báo, nhưng phát hành mã và script đánh giá có thể tái tạo đầy đủ của AlphaCodium, để cho phép các so sánh trong tương lai đáng tin cậy và nhất quán hơn.

[Bảng 1 và 2 với dữ liệu hiệu suất]

5.3. Nỗ lực tính toán và so sánh với AlphaCode và AlphaCode2
Với luồng AlphaCodium chúng tôi thực hiện ~15-20 lời gọi LLM trên mỗi giải pháp, vì vậy một gửi pass@5 liên quan đến ~100 lời gọi LLM.

AlphaCode không báo cáo bao nhiêu lời gọi LLM được thực hiện trên mỗi lần chạy [8]. Hãy giả sử một lời gọi trên mỗi lần chạy được thực hiện (không biết, có thể nhiều hơn), thì một pass@10@100K (tức là mười lần gửi, được tuyển chọn từ 100,000 giải pháp được tạo ra) liên quan đến 1M lời gọi LLM, nhiều hơn bốn bậc độ lớn so với AlphaCodium. Tuy nhiên, kết quả cao nhất thu được bởi AlphaCodium tốt hơn.

Gần đây, một công trình mới gọi là AlphaCode2 [11] được xuất bản, nơi một mô hình Gemini-Pro được tinh chỉnh và đánh giá trên các bài toán lập trình mã. Bài báo cũng báo cáo kết quả trên benchmark CodeContests, nhưng trên một biến thể cập nhật mà họ không phát hành cho công chúng. Theo báo cáo AlphaCode2: "AlphaCode2 yêu cầu khoảng 100 mẫu để đạt mức hiệu suất của AlphaCode với một triệu mẫu, làm cho nó hiệu quả hơn 10000× về mẫu." Do đó cả AlphaCode2 và AlphaCodium đều hiệu quả hơn bốn bậc độ lớn so với AlphaCode, về mặt lời gọi LLM. Nhưng, AlphaCode2 sử dụng một mô hình nền tảng hiện đại (Gemini-Pro) được tinh chỉnh nặng nề đặc biệt cho cuộc thi CodeContests, trong khi AlphaCodium sử dụng các mô hình mục đích chung như hiện tại, và cải thiện hiệu suất của chúng mà không có dữ liệu bổ sung và giai đoạn huấn luyện đắt đỏ.

6. Kết luận
Trong bài báo này, chúng tôi giới thiệu AlphaCodium, một luồng hướng mã lặp chạy và sửa mã được tạo ra đối với các kiểm thử đầu vào-đầu ra. Luồng được chia thành hai giai đoạn chính: giai đoạn tiền xử lý, nơi AlphaCodium lý luận về bài toán bằng ngôn ngữ tự nhiên, và giai đoạn lặp mã, trong đó AlphaCodium lặp trên các kiểm thử công khai và được tạo bởi AI.

AlphaCodium cũng sử dụng các khái niệm thiết kế bổ sung, thủ thuật, và thực hành tốt nhất mà chúng tôi thấy có lợi cho tạo mã: đầu ra có cấu trúc ở định dạng YAML, tạo mã mô-đun, lý luận ngữ nghĩa qua phân tích điểm đầu dòng, quyết định mềm với xác nhận kép, khuyến khích khám phá, và neo kiểm thử.

Chúng tôi đã thử nghiệm AlphaCodium trên một tập dữ liệu tạo mã đầy thách thức gọi là CodeContests. Luồng được đề xuất cải thiện kết quả của các mô hình mã nguồn đóng và mở khác nhau một cách nhất quán và đáng kể. AlphaCodium cũng vượt trội hơn các công trình trước đó từ văn học, trong khi có ngân sách tính toán nhỏ hơn đáng kể.

Tài liệu tham khảo
[1] Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. Program synthesis with large language models. arXiv preprint arXiv:2108.07732, 2021. 1

[2] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021. 1, 3

[3] DeepSeek. Deepseek coder: Let the code write itself, 2023. 2, 3, 7

[4] Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, và Jason Weston. Chain-of-verification reduces hallucination in large language models. arXiv preprint arXiv:2309.11495, 2023. 1

[5] Luciano Floridi và Massimo Chiriatti. Gpt-3: Its nature, scope, limits, and consequences. Minds and Machines, 30:681–694, 2020. 2, 3, 5

[6] Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas Mazeika, Akul Arora, Ethan Guo, Collin Burns, Samir Puranik, Horace He, Dawn Song, et al. Measuring coding challenge competence with apps. arXiv preprint arXiv:2105.09938, 2021. 3

[7] Hung Le, Hailin Chen, Amrita Saha, Akash Gokul, Doyen Sahoo, và Shafiq Joty. Codechain: Towards modular code generation through chain of self-revisions with representative sub-modules. arXiv preprint arXiv:2310.08992, 2023. 1, 7

[8] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation with alphacode. Science, 378(6624):1092–1097, 2022. 1, 3, 7

[9] Mike Mirzayanov, Oksana Pavlova, Pavel MAVRIN, Roman Melnikov, Andrew Plotnikov, Vladimir Parfenov, và Andrew Stankevich. Codeforces as an educational platform for learning programming in digitalization. Olympiads in Informatics, 14(133-142):14, 2020. 1, 3

[10] Harsha Nori, Yin Tat Lee, Sheng Zhang, Dean Carignan, Richard Edgar, Nicolo Fusi, Nicholas King, Jonathan Larson, Yuanzhi Li, Weishung Liu, et al. Can generalist foundation models outcompete special-purpose tuning? case study in medicine. arXiv preprint arXiv:2311.16452, 2023. 1

[11] Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. Gemini: a family of highly capable multimodal models. arXiv preprint arXiv:2312.11805, 2023. 7

[12] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017. 1

[13] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, và Denny Zhou. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171, 2022. 1

8

--- TRANG 9 ---
Phụ lục

A. Bài toán mã HumanEval điển hình
/*
Kiểm tra xem trong vector số đã cho, có hai số nào gần nhau hơn ngưỡng đã cho không. >>>
has_close_elements({1.0, 2.0, 3.0}, 0.5) false >>>
has_close_elements({1.0, 2.8, 3.0, 4.0, 5.0, 2.0}, 0.3) true
*/
#include<stdio.h>
#include<vector>
#include<math.h>
using namespace std;
bool has_close_elements(vector<float> numbers, float threshold){

B. Tại sao đầu ra YAML phù hợp hơn cho các tác vụ tạo mã so với đầu ra JSON
Trong khi các phiên bản GPT mới hơn¹ có hỗ trợ vốn có cho đầu ra kiểu JSON, chúng tôi lập luận rằng đầu ra YAML tốt hơn nhiều cho tạo mã. Tại sao - mã được tạo ra thường chứa dấu ngoặc đơn, dấu ngoặc kép, ký tự đặc biệt, v.v. LLM sẽ gặp khó khăn để đặt các ký tự này một cách hợp lệ bên trong định dạng JSON, vì đầu ra JSON cần được bao quanh bởi dấu ngoặc kép ban đầu (xem Hình 4 (a)). Ngược lại, đầu ra YAML với block scaler² chỉ cần tuân theo thụt lề. Bất kỳ văn bản hoặc mã nào với thụt lề thích hợp sẽ là hợp lệ (xem Hình 4 (b)).

Ngoài ra, như có thể thấy trong Hình 4, vì định dạng YAML không cần dấu ngoặc nhọn, dấu ngoặc kép hoặc ký tự thoát, đầu ra của nó có ít token hơn JSON, do đó giảm chi phí và thời gian suy luận, và dẫn đến chất lượng tăng lên vì mô hình cần chú ý đến ít token hơn không cần thiết.

(a) Đếm token với đầu ra JSON
(b) Đếm token với đầu ra YAML

Hình 4: So sánh cùng đầu ra, một lần ở định dạng JSON, và một lần ở định dạng YAML. Lấy từ OpenAI playground.

¹https://platform.openai.com/docs/guides/text-generation/json-mode
²https://yaml-multiline.info/

--- TRANG 10 ---
C. Những gì không hiệu quả đối với chúng tôi
1. Tiêm vết thực thi thất bại vào prompt: Ngoài việc cung cấp cho mô hình thông báo lỗi khi thực hiện sửa chữa lặp, chúng tôi cũng thử cung cấp cho nó vết của X (50) dòng cuối cùng được thực thi. Chúng tôi không quan sát thấy cải thiện từ điều này.

2. Tiêm K giải pháp mã thất bại cuối cùng vào prompt: Khi thực hiện sửa chữa lặp, chúng tôi thử tiêm K giải pháp mã thất bại cuối cùng vào prompt, để hướng mô hình theo các hướng khác nhau. Chúng tôi không quan sát thấy cải thiện từ điều này.

3. Tiêm git patch diff cuối cùng vào prompt: Khi thực hiện sửa chữa lặp, chúng tôi cũng thử cung cấp git patch diff được áp dụng cuối cùng cho prompt. Không có cải thiện nào được thấy.

4. Prompt một giai đoạn phức tạp: chúng tôi không quan sát thấy bất kỳ cải thiện đáng kể nào trong kết quả khi cố gắng thao tác và tối ưu hóa prompt một giai đoạn, hoặc chuỗi prompt không lặp. Mô hình vẫn gặp khó khăn trong việc hiểu mô tả bài toán dài, có xu hướng bỏ qua các chi tiết cụ thể, và liên tục tạo ra mã sai.

D. Ước tính khoảng cách giữa đầu ra của các kiểm thử
Khi chúng tôi chạy mã giải pháp đối với một kiểm thử đầu vào, mã tạo ra một đầu ra. Chúng tôi so sánh đầu ra này với đầu ra mong đợi, và kết thúc với câu trả lời boolean: pass hoặc failed. Tuy nhiên, cũng có lợi khi cố gắng ước tính theo một nghĩa nào đó khoảng cách giữa đầu ra được tạo ra và đầu ra đúng. Cho vấn đề này, chúng tôi sử dụng logic sau:

• Nếu đầu ra kiểm thử là một số, tính khoảng cách L2.
• Nếu đầu ra kiểm thử là một mảng số, tính tổng khoảng cách L2 giữa các ô mảng tương ứng.
• Nếu đầu ra kiểm thử là một mảng chuỗi, so sánh từng ô riêng biệt (so sánh boolean), và trả về số ô không giống nhau.

Phương pháp này cho phép chúng tôi tạo ra khoảng cách giữa mỗi đầu ra được tạo ra và đầu ra đúng trên CodeContests.

10
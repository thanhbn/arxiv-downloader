# Các Mô Hình Ngôn Ngữ Lớn về Mã Lỗi trong Việc Hoàn Thành Mã với Lỗi Tiềm Ẩn

Tuan Dinh1∗†Jinman Zhao2∗Samson Tan2Renato Negrinho2
Leonard Lausen2Sheng Zha2George Karypis2
1Đại học Wisconsin–Madison2Amazon Web Services
tuan.dinh@wisc.edu
{jinmaz,samson,renatoni,lausen,zhasheng,gkarypis}@amazon.com

Tóm tắt
Các mô hình ngôn ngữ lớn về mã (Code-LLMs) gần đây đã mang lại những tiến bộ to lớn cho việc hoàn thành mã, một tính năng cơ bản của hỗ trợ lập trình và trí tuệ mã. Tuy nhiên, hầu hết các công trình hiện tại bỏ qua khả năng có sự hiện diện của lỗi trong ngữ cảnh mã để tạo ra, điều này là không thể tránh khỏi trong phát triển phần mềm. Do đó, chúng tôi giới thiệu và nghiên cứu bài toán hoàn thành mã có lỗi, được lấy cảm hứng từ tình huống thực tế của gợi ý mã thời gian thực nơi ngữ cảnh mã chứa các lỗi tiềm ẩn – các mẫu chống lại có thể trở thành lỗi trong chương trình hoàn thành. Để nghiên cứu bài toán một cách có hệ thống, chúng tôi giới thiệu hai bộ dữ liệu: một với các lỗi tổng hợp được tạo ra từ các thay đổi toán tử làm thay đổi ngữ nghĩa (buggy-HumanEval) và một với các lỗi thực tế được tạo ra từ các bài nộp của người dùng cho các bài toán lập trình (buggy-FixEval). Chúng tôi phát hiện rằng sự hiện diện của các lỗi tiềm ẩn làm giảm đáng kể hiệu suất tạo ra của các Code-LLMs hiệu suất cao. Ví dụ, tỷ lệ vượt qua của CODEGEN-2B-MONO trên các trường hợp kiểm tra của buggy-HumanEval giảm hơn 50% khi có một lỗi tiềm ẩn trong ngữ cảnh. Cuối cùng, chúng tôi điều tra một số phương pháp hậu-hoc để giảm thiểu tác động bất lợi của các lỗi tiềm ẩn và thấy rằng vẫn còn một khoảng cách đáng kể trong hiệu suất sau khi giảm thiểu.

1 Giới thiệu

Gợi ý mã cho một ngữ cảnh cho trước là một tính năng được sử dụng thường xuyên trong các môi trường phát triển tích hợp hiện đại (IDEs), mang lại lợi ích về năng suất cho quá trình viết mã. Nhiệm vụ này được nghiên cứu rộng rãi như hoàn thành mã trong tài liệu, với các kỹ thuật và mô hình từ mô hình xác suất hoặc chuỗi, tích hợp cấu trúc mã như kiến thức tiên nghiệm, đến việc áp dụng mạng nơ-ron sâu và kỹ thuật tiền huấn luyện để học biểu diễn cho mã. Gần đây, các mô hình ngôn ngữ lớn dựa trên Transformer về mã (Code-LLMs) đã trở thành một mô hình đầy hứa hẹn cho việc hoàn thành mã, đạt được hiệu suất tốt nhất (SotA) trong các nhiệm vụ học mã khác nhau bao gồm hoàn thành và tạo ra mã.

Tuy nhiên, các công trình hiện tại nghiên cứu Code-LLMs thường giả định sự vắng mặt của lỗi, mặc dù sự xuất hiện thường xuyên và chi phí của lỗi trong phát triển phần mềm: trung bình, 70 lỗi được tạo ra trên 1000 dòng mã; và việc sửa lỗi tiêu tốn 50% thời gian phát triển. Xem xét một tình huống lập trình thực tế. Một nhà phát triển muốn sử dụng tính năng gợi ý mã trong IDE khi viết mã. Với xác suất cao, ngữ cảnh mã thời gian thực của họ, như một đầu vào cho bộ dự đoán mã, chứa lỗi đánh máy hoặc các triển khai ít tinh tế hơn, có thể có lỗi. Vì tính có lỗi là một thuộc tính của một chương trình hoàn chỉnh, nó không được định nghĩa rõ ràng về cách phát hiện lỗi và sửa chữa mã có lỗi trong ngữ cảnh mã ngắn và không hoàn chỉnh này, làm cho việc áp dụng các công cụ phát hiện lỗi hoặc sửa chữa mã hiện tại trở nên không tối ưu hoặc không khả thi. Cũng đáng nhắc đến rằng khoảng cách giữa hiệu suất trong phòng thí nghiệm và trong thực tế của các mô hình hoàn thành mã vẫn còn lớn. Do đó, một câu hỏi tự nhiên nảy sinh: Liệu các Code-LLMs hiện tại có thể cung cấp các gợi ý mã tốt với tính chất không tinh tế của mã nháp?

Để trả lời câu hỏi này, chúng tôi giới thiệu và nghiên cứu bài toán hoàn thành mã với các lỗi tiềm ẩn trong ngữ cảnh mã, được gọi là hoàn thành mã có lỗi (bCC). Trong nghiên cứu này, chúng tôi tập trung vào việc sử dụng Code-LLMs để tạo ra các triển khai chức năng từ một ngữ cảnh mã, nơi ngữ cảnh mã bao gồm một đặc tả bài toán và một đoạn mã một phần. Một lỗi tiềm ẩn trong một đoạn mã một phần là một khoảng mã có thể trở thành lỗi được cung cấp một số hoàn thành, tức là, nó làm thất bại hoàn thành và đồng thời có thể được thay đổi để làm cho hoàn thành hoạt động. Lưu ý rằng một lỗi tiềm ẩn không phải là một lỗi per se mà không có hoàn thành. Được hiển thị trong Hình 1 là một minh họa của nhiệm vụ của chúng tôi với mô tả bài toán ở trên và mã một phần ở giữa. Bên trái là một ngữ cảnh mã tham chiếu và một hoàn thành đúng từ Code-LLM được chọn. Bên phải, lỗi tiềm ẩn được đánh dấu (-=) làm cho hoàn thành tham chiếu không chính xác. Code-LLM phản ứng với lỗi tiềm ẩn này bằng cách tạo ra một hoàn thành khác (dưới phải). Tuy nhiên, mã hoàn thành vẫn không chính xác về mặt chức năng.

Để tiến hành một nghiên cứu định lượng về bCC, chúng tôi xây dựng hai bộ dữ liệu. Đầu tiên, bộ dữ liệu buggy-HumanEval chứa các bài toán lập trình kiểu phỏng vấn từ bộ dữ liệu HumanEval, với các cặp mã một phần có lỗi/tham chiếu được tạo ra bằng cách giới thiệu các thay đổi toán tử làm thay đổi ngữ nghĩa vào các giải pháp tham chiếu. Bộ dữ liệu này cung cấp một thiết lập được kiểm soát tốt để đánh giá hành vi của các mô hình khi có lỗi tiềm ẩn. Thứ hai, bộ dữ liệu buggy-FixEval, dựa trên FixEval, chứa các bài nộp của người dùng cho các bài toán thi lập trình. Các cặp có lỗi/tham chiếu được xây dựng từ các bài nộp bị từ chối và được chấp nhận bởi cùng một người dùng cho một bài toán cho trước. Bộ dữ liệu này giúp đánh giá hiệu suất của các mô hình trên một phân phối thực tế của các lỗi tiềm ẩn. Các điểm chuẩn của chúng tôi được liên kết tốt với các điểm chuẩn hiện tại cho Code-LLMs.

Thông qua các nghiên cứu thực nghiệm của chúng tôi, chúng tôi thấy rằng sự hiện diện của các lỗi tiềm ẩn làm giảm mạnh hiệu suất hoàn thành mã của các Code-LLMs hiệu suất cao, với tỷ lệ vượt qua trường hợp kiểm tra giảm xuống dưới 5% trên cả hai bộ dữ liệu cho tất cả các biến thể mô hình đã kiểm tra. Ví dụ, trên buggy-HumanEval, tỷ lệ vượt qua trường hợp kiểm tra của các hoàn thành CODEGEN-2B-MONO giảm từ 54.9% (mã một phần tham chiếu) xuống 3.1% (mã một phần chứa lỗi tiềm ẩn), điều này còn tệ hơn so với điểm số khi không có mã một phần nào được cung cấp (9.3%). Kết quả của chúng tôi cho thấy rằng Code-LLMs rất dễ bị ảnh hưởng bởi các lỗi tiềm ẩn.

Hơn nữa, chúng tôi thử nghiệm một số phương pháp hậu-hoc để tăng cường Code-LLMs để xử lý tốt hơn các lỗi tiềm ẩn, cụ thể là loại bỏ-rồi-hoàn thành, hoàn thành-rồi-viết lại, và viết lại-rồi-hoàn thành. Hai phương pháp sau tăng cường Code-LLMs với một bộ sửa chữa mã bên ngoài như thành phần viết lại. Đánh giá của chúng tôi cho thấy rằng các phương pháp đã thử nghiệm cải thiện hiệu suất hoàn thành mã có lỗi của tất cả các Code-LLMs đã kiểm tra. Tuy nhiên, khoảng cách hiệu suất vẫn còn lớn giữa các phương pháp này và hoàn thành với mã một phần tham chiếu. Chúng tôi cung cấp thêm các nghiên cứu trường hợp và phân tích, ví dụ, tác động của vị trí lỗi tiềm ẩn hoặc các trường hợp thành công của hoàn thành ngây thơ để hiểu rõ hơn về hành vi của các mô hình đã kiểm tra trong hoàn thành mã có lỗi.

Phạm vi nghiên cứu và đóng góp. Công trình này nhằm mục đích khám phá và hiểu các hành vi của Code-LLMs trong thiết lập hoàn thành mã có lỗi. Chúng tôi (i) định nghĩa nhiệm vụ hoàn thành mã có lỗi mới, (ii) giới thiệu hai bộ dữ liệu điểm chuẩn đại diện, (iii) chứng minh sự bất lực của Code-LLMs trong việc xử lý các lỗi tiềm ẩn, và (iv) đánh giá một số phương pháp cơ bản để cải thiện Code-LLMs trên hoàn thành mã có lỗi.

2 Hoàn Thành Mã Có Lỗi

Trong công trình này, chúng tôi xem xét thiết lập hoàn thành mã với đầu vào bao gồm (1) một đặc tả h chỉ định chức năng mong muốn của chương trình và (2) một ngữ cảnh mã s, là một số mã chưa hoàn thành cần được hoàn thành. Ở đây, h được cho như một docstring hoặc một phát biểu bài toán bằng tiếng Anh, và s được cho như một vài dòng mã là phần bắt đầu của một chương trình, mà chúng tôi gọi là mã một phần hoặc tiền tố (mã). Trong thiết lập hoàn thành mã thông thường, mục tiêu là đề xuất một hoàn thành c sao cho t := s::c là một chương trình thỏa mãn h, trong đó "::" biểu thị phép nối mã. Thiết lập hoàn thành mã có lỗi của chúng tôi mở rộng thiết lập thông thường với một xem xét thách thức và thực tế: s có thể chứa các lỗi tiềm ẩn.

Xem xét một tình huống thực tế nơi một lập trình viên làm việc trên mã chưa hoàn thành và sử dụng tính năng tự động hoàn thành mã để có gợi ý. Lưu ý rằng quá trình lập trình thường thấy các lỗi lập trình hoặc giới thiệu các cách sử dụng mã không nhất quán, những điều này không nhất thiết là "không chính xác" per se. Tuy nhiên, có một cơ hội công bằng rằng những lỗi hoặc sự không nhất quán như vậy gây ra các hành vi không mong muốn và không mong muốn trong chương trình cuối cùng. Nói cách khác, chúng trở thành lỗi. Dựa trên trực giác này, chúng tôi định nghĩa các lỗi tiềm ẩn như sau:

Định nghĩa 2.1 (lỗi tiềm ẩn). Xem xét một đặc tả h và một tiền tố mã tham chiếu s mà một số hoàn thành c tồn tại sao cho t := s::c thỏa mãn h. Một lỗi tiềm ẩn được thể hiện như một chỉnh sửa nhỏ e trên s sao cho t' := s'::c không thỏa mãn h, trong đó s' là kết quả của việc áp dụng e lên s.

Chúng tôi lưu ý rằng các lỗi tiềm ẩn không phải là lỗi per se và chỉ được định nghĩa liên quan đến một số tiền tố mã tham chiếu s và hoàn thành c. Tiền tố mã s' chứa các lỗi tiềm ẩn được gọi là tiền tố "có thể có lỗi" hoặc đơn giản là "có lỗi" (liên quan đến s) xuyên suốt bài báo. Trong hầu hết các trường hợp, chúng tôi bỏ qua phần "liên quan đến" để ngắn gọn. Thuật ngữ kết quả "tiền tố có lỗi" đề cập đến định nghĩa ở đây và không có nghĩa là giả định rằng bản thân tiền tố là có lỗi. Nghiên cứu của chúng tôi tập trung vào các lỗi tiềm ẩn liên quan đến các lỗi ngữ nghĩa, tức là, các chỉnh sửa không giới thiệu lỗi cú pháp, vì các lỗi ngữ nghĩa thường thách thức và thú vị hơn so với các lỗi cú pháp.

Nhận xét 2.2. Một cách trực quan, chúng tôi giả định rằng tiền tố tham chiếu s có mối tương quan cao với các triển khai được ưa thích (thực tế) của nhiệm vụ và rằng bất kỳ sự lệch khỏi s nào có thể ít được ưa thích hơn. Chúng tôi sử dụng định nghĩa hoạt động của các lỗi tiềm ẩn trong 2.1 vì tính đơn giản và khả năng xác minh của nó, cũng như vì nó cho phép khám phá ban đầu về tình huống bCC đã được điều tra dưới trước đó. Chúng tôi lưu ý rằng theo định nghĩa này, một tiền tố tham chiếu s bản thân nó có thể, trong một số trường hợp, mặc dù ít có khả năng hơn, là "có lỗi" liên quan đến một số tham chiếu khác. Tuy nhiên, trường hợp như vậy ít được quan tâm trong nghiên cứu này, vì chúng tôi chủ yếu quan tâm đến việc tìm một chương trình chức năng hoàn chỉnh từ s hoặc s'.

Định nghĩa 2.3 (hoàn thành mã có lỗi, bCC). Cho một đặc tả h và một tiền tố mã s' chứa các lỗi tiềm ẩn, hoàn thành mã có lỗi là nhiệm vụ tạo ra một chương trình hoàn chỉnh t thỏa mãn h.

Chúng tôi cố ý nới lỏng ràng buộc rằng t nên chứa s' như một tiền tố, vì theo định nghĩa, và cũng như người ta có thể thấy từ ví dụ trong Hình 1, việc cố định trên tiền tố có lỗi có thể làm cho việc đề xuất một giải pháp thỏa mãn trở nên khó khăn, nếu không phải là không thể. Như chúng tôi khám phá trong Phần 4.3, việc cho phép các mô hình đề xuất các sửa chữa cho tiền tố mã có lỗi làm tăng đáng kể khả năng một chương trình được tạo ra vượt qua các kiểm tra. Tuy nhiên, thường vẫn có thể tiếp tục một tiền tố có lỗi thành một chương trình giải pháp hợp lệ (xem một ví dụ trong Hình 12).

Một cách nhìn thay thế về thiết lập là tiền tố mã có lỗi cung cấp một điều kiện tiên quyết nhiễu và có thể có lỗi để tạo ra một giải pháp cho bài toán lập trình. Nó thể hiện một nỗ lực thiện chí từ người dùng để hướng dẫn công cụ về các giải pháp mã dự định của họ. Một mô hình hoạt động tốt nên coi điều này như một gợi ý và, tồi tệ nhất, loại bỏ nó để hiệu suất tạo ra không tệ hơn khi không có tiền tố mã nào được cung cấp. Tuy nhiên, đây không phải là trường hợp đối với các mô hình chúng tôi đã đánh giá (Phần 4.2).

Nhận xét 2.4. Công thức bCC của chúng tôi không phải là một sự kết hợp đơn giản của sửa chữa mã và hoàn thành mã. Vì tính có lỗi là một thuộc tính của các chương trình hoàn chỉnh, việc sửa chữa mã một phần là một bài toán không được định nghĩa rõ ràng, do đó làm cho sửa chữa-rồi-hoàn thành cũng không được định nghĩa rõ ràng. Do đó, nhiệm vụ bCC của chúng tôi được xem tốt hơn như một phần mở rộng của hoàn thành mã với thách thức bổ sung rằng việc tạo ra các phần tiếp theo đúng ngữ nghĩa từ mã một phần cho trước mà không có sự lệch lạc có thể khó khăn hoặc thậm chí không khả thi. Thách thức này yêu cầu các mô hình phải nhận thức về sự tồn tại của các lỗi tiềm ẩn để có gợi ý tốt hơn.

3 Điểm Chuẩn

Phần này giới thiệu các bộ dữ liệu mới của chúng tôi với các phương pháp cơ bản được đề xuất và các chỉ số đánh giá.

3.1 Bộ Dữ Liệu cho bCC

Dựa trên định nghĩa nhiệm vụ của chúng tôi, mỗi thực thể trong một điểm chuẩn bCC nên chứa một mô tả bài toán chỉ định các yêu cầu, một đoạn tiền tố mã có lỗi cần được hoàn thành, và một tập hợp các trường hợp kiểm tra để đánh giá tính đúng đắn của mã đã hoàn thành. Tùy chọn, một thực thể cũng có một tiền tố mã tham chiếu tương ứng và một giải pháp hợp lệ được hoàn thành từ mã tham chiếu. Theo kiến thức của chúng tôi, không có bộ dữ liệu hiện tại nào đáp ứng tất cả các yêu cầu mong muốn. Các bộ dữ liệu quy mô lớn thường được sử dụng cho hoàn thành mã, ví dụ, Py150 và Java Corpus không đi kèm với các trường hợp kiểm tra. Các bộ dữ liệu quy mô nhỏ được tuyển chọn thủ công gần đây cho tạo ra mã, ví dụ, HumanEval, MBPP, APPs, đi kèm với các trường hợp kiểm tra và các giải pháp tham chiếu nhưng không có các giải pháp có lỗi hoặc thất bại. Cũng không có cách xác định trước để trích xuất mã một phần từ các giải pháp tham chiếu. Đây cũng là trường hợp đối với các bộ dữ liệu sửa chữa chương trình: các bộ dữ liệu phổ biến hoặc thiếu các trường hợp kiểm tra, ví dụ, [23,24,25,26] và/hoặc có kích thước nhỏ, ví dụ, [27,28,29].

Chúng tôi giới thiệu hai bộ dữ liệu để đánh giá bCC trong Python, cả hai đều có tất cả các thành phần mong muốn đã đề cập. Chúng tôi đảm bảo rằng 1) tất cả các đoạn mã một phần chứa các lỗi tiềm ẩn thỏa mãn định nghĩa của chúng tôi, tức là, mã hoàn thành tương ứng của chúng là không chính xác, được chứng nhận bằng việc thất bại các trường hợp kiểm tra; và 2) tất cả các lỗi tiềm ẩn đều có tính chất ngữ nghĩa, tức là, chúng không gây ra lỗi cú pháp trong mã hoàn thành tương ứng của chúng.

3.1.1 Buggy-HumanEval

Chúng tôi đầu tiên giới thiệu buggy-HumanEval để cung cấp một thiết lập được kiểm soát để đánh giá bCC khi có sự hiện diện của một lỗi ngữ nghĩa duy nhất. Buggy-HumanEval chứa 1896 thực thể bCC được xây dựng từ một tập con của các bài toán HumanEval. Bộ dữ liệu HumanEval là một bộ dữ liệu phổ biến của các bài toán lập trình giới thiệu được viết thủ công được thiết kế để đánh giá khả năng tạo ra mã của Code-LLMs.

Các lỗi tiềm ẩn được giới thiệu như các thay đổi toán tử làm thay đổi ngữ nghĩa vào các giải pháp tham chiếu. Chúng tôi tìm kiếm các toán tử nhị phân có thể áp dụng trong các giải pháp tham chiếu và thay đổi chúng thành các đối nghịch ngữ nghĩa của chúng, ví dụ, + thành -. Để đảm bảo rằng việc chỉnh sửa giới thiệu một lỗi, chúng tôi thực thi chương trình đã thay đổi và chỉ giữ lại những cái thất bại một số kiểm tra. Sau đó chúng tôi chỉ định một dòng sau toán tử đã thay đổi để chia giải pháp thành một tiền tố mã và hậu tố. Chúng tôi giữ tiền tố có lỗi như một phần của đầu vào cho bCC. Chúng tôi chia giải pháp chưa thay đổi tại cùng một dòng để có được một tiền tố tham chiếu tương ứng. Trung bình, các bài toán được chọn cho buggy-HumanEval có các giải pháp dài hơn so với những cái không được chọn trong HumanEval, với 8.2 dòng so với 2.9 dòng mã, tương ứng. Phụ lục A.1 cung cấp chi tiết về bộ dữ liệu của chúng tôi.

3.1.2 Buggy-FixEval

Để đánh giá bCC với các lỗi thực tế hơn, chúng tôi giới thiệu buggy-FixEval với các thực thể bCC được xây dựng từ CodeNet và FixEval. FixEval là một điểm chuẩn sửa chữa chương trình dựa trên các bài nộp của người dùng cho các trang web lập trình cạnh tranh. Mỗi mẫu dữ liệu trong FixEval có thể được xem như một cặp các chương trình đã nộp từ cùng một người dùng, với bài nộp được chấp nhận được coi là tham chiếu hoặc đã sửa và bài nộp bị từ chối trước đó được coi là có lỗi.

Để tạo ra buggy-FixEval, chúng tôi khớp và ghép cặp mỗi bài toán với phát biểu bài toán của nó được tìm thấy trong CodeNet và bỏ qua các bài toán không có khớp. Đối với mỗi cặp bài nộp, chúng tôi xác định các lỗi tiềm ẩn như các sự khác biệt giữa các bài nộp bị từ chối và được chấp nhận. Chúng tôi đảm bảo rằng bài nộp bị từ chối không chứa lỗi cú pháp và thất bại ít nhất một trường hợp kiểm tra. Chúng tôi chia các giải pháp thành một nửa và coi tiền tố từ giải pháp bị từ chối là chứa các lỗi tiềm ẩn và tiền tố từ giải pháp được chấp nhận là một tham chiếu. Để đảm bảo các sự khác biệt giữa tiền tố có lỗi và tiền tố tham chiếu liên quan đến các lỗi tiềm ẩn, chúng tôi đặt ra một giới hạn về khoảng cách chỉnh sửa cấp độ ký tự giữa chúng, bỏ qua các bình luận và khoảng trắng. Giới hạn dưới đảm bảo rằng các sự khác biệt không phải là bình luận hoặc khoảng trắng. Giới hạn trên (20, được chọn bằng kiểm tra thủ công) giảm cơ hội rằng sự khác biệt liên quan đến việc định dạng lại hoặc triển khai lại. Sau đó chúng tôi kiểm tra thủ công tất cả các cặp còn lại và loại trừ các trường hợp không mong muốn như tiền tố tham chiếu bản thân nó đã là một giải pháp chính xác hoặc hai tiền tố tương đương về mặt ngữ nghĩa. Cuối cùng, chúng tôi thực thi sự nối của tiền tố có lỗi và hoàn thành tham chiếu và đảm bảo rằng nó thất bại ít nhất một trường hợp kiểm tra. Thêm chi tiết về việc tạo ra buggy-FixEval có thể được tìm thấy trong Phụ lục A.2.

3.2 Phương Pháp Cơ Bản cho bCC

Ngoài việc tạo ra ngây thơ từ ngữ cảnh mã, chúng tôi nghiên cứu một số phương pháp để tăng cường Code-LLMs để sử dụng mã một phần tốt hơn trong khi giảm thiểu tác động của các lỗi tiềm ẩn. Giả định rằng một thành phần phát hiện lỗi được trang bị, chúng tôi tập trung vào các phương pháp thiết kế đơn giản và mô-đun không yêu cầu huấn luyện bổ sung và linh hoạt để tích hợp thêm các Code-LLMs mới được phát triển.

Loại bỏ mã một phần, rồi hoàn thành (loại bỏ-rồi-hoàn thành). Chúng tôi bỏ qua tác động tiêu cực của mã một phần có lỗi bằng cách loại bỏ toàn bộ đoạn mã nội dung khỏi đầu vào của mô hình. Cụ thể, đối với buggy-HumanEval, đầu vào cho Code-LLMs sau khi loại bỏ bao gồm phát biểu bài toán và header hàm (và các ví dụ). Đối với buggy-FixEval, chúng tôi chỉ giữ lại phát biểu và đoạn mã được sử dụng để đọc dữ liệu đầu vào. Một cách trực quan, vì loại bỏ-rồi-hoàn thành đảm bảo rằng đầu vào cho Code-LLMs không chứa lỗi, chúng tôi mong đợi phương pháp này hoạt động tốt hơn so với hoàn thành ngây thơ. Tuy nhiên, nhược điểm của loại bỏ-rồi-hoàn thành là nó hy sinh tất cả thông tin có thể hữu ích được mang lại bởi mã một phần.

Hoàn thành trước, rồi viết lại chương trình (hoàn thành-rồi-viết lại). Phương pháp này cố gắng sửa mã có lỗi bằng các mô hình sửa chữa mã đã được huấn luyện trước, ví dụ, dịch nơ-ron một chương trình có lỗi thành một chương trình hợp lệ. Vì các mô hình sửa chữa mã, hoặc bộ sửa mã, thường được huấn luyện để sửa các chương trình hoàn chỉnh, chúng tôi đầu tiên hoàn thành mã bằng hoàn thành ngây thơ, sau đó áp dụng các bộ sửa mã trên các chương trình có thể có lỗi. Chúng tôi sử dụng RealiT, một mô hình sửa chữa chương trình SotA như bộ sửa mã. RealiT được thiết kế cho các biến sử dụng sai, literal sai, toán tử nhị phân và đơn nguyên sai, đặc biệt phù hợp cho các lỗi được giới thiệu trong buggy-HumanEval.

Viết lại mã một phần, rồi hoàn thành (viết lại-rồi-hoàn thành). Phương pháp này cố gắng giải quyết các lỗi tiềm ẩn trong mã một phần trước khi hoàn thành. Để làm như vậy, chúng tôi đầu tiên xác định các dòng mã chứa lỗi tiềm ẩn, sau đó viết lại các dòng này. Để phát hiện các lỗi tiềm ẩn, chúng tôi đề xuất một biện pháp dựa trên khả năng để xác định dòng có khả năng nhất chứa lỗi tiềm ẩn. Cụ thể, chúng tôi chấm điểm mỗi dòng mã với quy trình sau. Đầu tiên, đối với mỗi token, chúng tôi định nghĩa điểm số có lỗi của nó là sự khác biệt về khả năng giữa token có khả năng cao nhất (tức là, token argmax) và token được quan sát. Điểm số có lỗi cho mỗi dòng sau đó được tính bằng cách lấy tối đa hoặc trung bình của các điểm số có lỗi khác không của các token của nó. Dòng có điểm số cao nhất là có khả năng nhất chứa các lỗi tiềm ẩn. Chúng tôi sử dụng INCODER-6B như mô hình ngôn ngữ điền vào để viết lại mã. Chúng tôi cung cấp giải thích chi tiết và minh họa ví dụ về các biện pháp dựa trên khả năng trong Phụ lục B để hiểu rõ hơn phương pháp viết lại-rồi-hoàn thành của chúng tôi.

3.3 Chỉ Số Đánh Giá

Chúng tôi đo lường chức năng của một chương trình hoàn thành bằng cách thực thi nó so với các trường hợp kiểm tra được cung cấp. Theo các công trình tạo ra mã gần đây [ví dụ, 10,34,12,33], chúng tôi đo lường pass@k (↑) cho mỗi thực thể bCC như pass@k := 1 - (n-c choose k)/(n choose k) trong đó n hoàn thành được lấy mẫu từ một mô hình, và c trong số chúng vượt qua tất cả các kiểm tra. Chúng tôi chọn n = 100 và k = 1,10,100. Chỉ số này ước tính xác suất rằng bất kỳ ai trong số k mẫu từ mô hình vượt qua các kiểm tra. Vì nhiều thực thể bCC có thể được tạo ra từ cùng một bài toán lập trình, chúng tôi đầu tiên lấy trung bình pass@k trong mỗi bài toán, sau đó lấy trung bình trên tất cả các bài toán (macro-average) để tránh sự thống trị của một vài bài toán.

Trong khi vượt qua tất cả các trường hợp kiểm tra không đảm bảo 100% tính đúng đắn của một chương trình, chỉ số này cung cấp một proxy thực tế và hiệu quả cho tính đúng đắn chức năng. Lưu ý rằng chúng tôi không sử dụng các chỉ số dựa trên khớp, ví dụ, khớp chính xác hoặc CodeBLEU vì chúng không phản ánh đúng chức năng của mã được tạo ra [22, 10, 18], và không có hoàn thành tham chiếu nào có sẵn cho các tiền tố có lỗi.

4 Thí Nghiệm

Chúng tôi thiết kế hai tập hợp thí nghiệm để điều tra (1) các Code-LLMs hiện tại thích ứng với bCC như thế nào (Phần 4.2) và (2) liệu chúng ta có thể có một sửa chữa đơn giản với Code-LLMs cho bCC (Phần 4.3). Chúng tôi cung cấp các nghiên cứu loại bỏ về các lỗi tiềm ẩn (Phần 4.5) và về việc kết hợp hoàn thành dựa trên lỗi với tiền tố tham chiếu (Phần C.4). Phần 4.6 trình bày các nghiên cứu trường hợp về các hành vi thú vị của Code-LLMs trong bCC, với các kết quả bổ sung trong Phụ lục C.

4.1 Thiết Lập Thí Nghiệm

Code-LLMs. Chúng tôi đánh giá hai Code-LLMs phổ biến và mã nguồn mở cho hoàn thành mã. CODEGEN là một họ LLMs được huấn luyện trên cả ngữ liệu ngôn ngữ tự nhiên và lập trình với hiệu suất cao trong tạo ra mã trên HumanEval. Chúng tôi sử dụng các checkpoint mô hình đã phát hành: CODEGEN-350M-MONO, CODEGEN-2B-MONO, và CODEGEN-16B-MONO. Các mô hình INCODER được huấn luyện với một mục tiêu che dấu nhân quả, cho phép chúng điền các khối mã được điều kiện hóa trên các ngữ cảnh trái và phải tùy ý. Chúng tôi sử dụng các checkpoint mô hình đã phát hành INCODER-1B và INCODER-6B, mỗi cái có 1B và 6B tham số. Chúng tôi chọn CODEGEN và INCODER vì chúng có sẵn công khai với hiệu suất tạo ra mã cao.

Tạo ra các hoàn thành. Định dạng đầu vào. Đối với buggy-HumanEval, một mô hình dự kiến sẽ hoàn thành một hàm chưa hoàn thành. Theo điểm chuẩn HumanEval, chúng tôi đặt đầu vào của các mô hình là mã một phần dẫn đến vị trí hoàn thành, với mô tả bài toán được nhúng như docstring của hàm chưa hoàn thành. Đối với buggy-FixEval, nhiệm vụ hoàn thành là hoàn thành một chương trình chưa hoàn thành với đầu vào là mô tả bài toán như một docstring cấp tệp (được trích dẫn trong dấu ngoặc kép ba), theo sau là mã một phần dẫn đến vị trí hoàn thành. Chi tiết tạo ra và lấy mẫu. Theo các thiết lập hoạt động tốt nhất được báo cáo trong các công trình tương ứng, chúng tôi sử dụng lấy mẫu nhiệt độ với nhiệt độ = 0.6 cho CODEGEN và lấy mẫu top-p với p = 0.95 và nhiệt độ = 0.2 cho INCODER. Dựa trên các giải pháp tham chiếu và hiệu quả tính toán, chúng tôi đặt giới hạn độ dài tối đa cho đầu ra từ 200 đến 600 token, thay đổi theo các tập bài toán. Chúng tôi quan sát các xu hướng hiệu suất tương tự giữa các mô hình đã kiểm tra trên các thiết lập độ dài khác nhau. Chúng tôi xử lý hậu kỳ chuỗi đầu ra theo cùng quy trình được sử dụng trong các bản phát hành mã của chúng.

Các mô hình sửa chữa mã và viết lại mã. Đối với loại bỏ-rồi-hoàn thành, chúng tôi sử dụng mô hình mới nhất của RealiT như bộ sửa mã, được huấn luyện và kiểm tra trên các lỗi nhân tạo và thực tế. Đối với mô hình viết lại mã, chúng tôi sử dụng mô hình INCODER-6B do khả năng điền mã của nó và áp dụng các thiết lập tương tự được sử dụng cho điền được báo cáo trong bài báo của mô hình.

4.2 Các Code-LLMs Hiện Tại Hoạt Động Như Thế Nào trên Ngữ Cảnh Mã Có Lỗi?

Chúng tôi đánh giá các Code-LLMs mới nhất cho hoàn thành mã có lỗi trên buggy-HumanEval và buggy-FixEval, được hiển thị trong Hình 2. Cụ thể, hiệu suất được đo lường theo pass@1, và chúng tôi sử dụng bốn mô hình: CODEGEN-350M-MONO, CODEGEN-2B-MONO, INCODER-1B, và INCODER-6B. Đầu tiên, so sánh các điểm số giữa mã một phần tham chiếu và có lỗi cho mỗi mô hình, chúng ta thấy rằng sự hiện diện của các lỗi tiềm ẩn có hại cho các mô hình hoàn thành, với pass@1 giảm từ 41.1–54.9% xuống 0.5–3.1% trên buggy-HumanEval, và từ 24.1–37.8% xuống 1.2–4.3% trên buggy-FixEval. Hơn nữa, pass@1 trên mã một phần có lỗi được thống trị hoàn toàn bởi những cái không có mã một phần: 3.9–9.3% trên buggy-HumanEval, 2.9–8.6% trên buggy-FixEval. Bảng 7 (Phụ lục C) cho thấy các phát hiện tương tự với một mô hình rất lớn (CODEGEN-16B-MONO). Những kết quả này chỉ ra rằng (i) các Code-LLMs đã kiểm tra thất bại mạnh mẽ tại bCC được khởi tạo bởi các bộ dữ liệu của chúng tôi, và (ii) sự hiện diện của các lỗi tiềm ẩn phá hủy lợi ích được mang lại bởi mã một phần.

Tại sao Code-LLMs thất bại tại bCC? Chúng tôi kiểm tra thủ công các mẫu từ mô hình CODEGEN-2B-MONO hoạt động tốt nhất và tìm thấy hai chế độ thất bại phổ biến nhất trong các mẫu thất bại. Đầu tiên, mô hình thất bại trong việc phản ứng với các lỗi tiềm ẩn (tức là, các hoàn thành phổ biến vẫn giữ nguyên), như được hiển thị trong Hình 8. Chế độ này xảy ra trong 90% thực thể và 93% bài toán với ít nhất một thực thể thất bại. Chúng tôi phỏng đoán rằng mô hình không nhạy cảm với và do đó bỏ qua các thay đổi mã nhỏ và/hoặc chọn mặc định thành các mẫu phổ biến trong dữ liệu huấn luyện. Thứ hai, mô hình thất bại trong việc bỏ qua các lỗi tiềm ẩn, có thể vì những mẫu như vậy hiếm trong mã chất lượng cao. Nói cách khác, mô hình có thể đã nhận ra các lỗi tiềm ẩn và thay đổi đáng kể phân phối đầu ra nhưng vẫn thất bại. Hình 7 minh họa một ví dụ về trường hợp này. Chúng tôi cung cấp thêm chi tiết trong Phụ lục D.2.

4.3 Các Phương Pháp Hoàn Thành Cơ Bản Hiệu Quả Như Thế Nào Chống Lại Các Lỗi Tiềm Ẩn?

Chúng tôi đánh giá các phương pháp hoàn thành được giới thiệu trong Phần 3.2 sử dụng cùng thiết lập bCC, được hiển thị trong Bảng 1. Chúng tôi bao gồm các kết quả hoàn thành mã một phần tham chiếu để xem các lỗi tiềm ẩn ảnh hưởng đến Code-LLMs như thế nào. Hình 6 trong Phụ lục C cung cấp các kết quả đầy đủ và giải thích cho k = 1,10,100.

Tác động của các phương pháp hoàn thành đề xuất. Cả ba phương pháp đề xuất đều vượt trội hơn so với đường cơ sở hoàn thành mã có lỗi ngây thơ. Trên buggy-HumanEval, chúng tôi quan sát xu hướng chung của hoàn thành-rồi-viết lại vượt trội hơn viết lại-rồi-hoàn thành, vượt trội hơn loại bỏ-rồi-hoàn thành. Lưu ý rằng những điểm số này của loại bỏ-rồi-hoàn thành thường thấp hơn so với các điểm số được báo cáo của phương pháp tương tự có thể vì buggy-HumanEval được tạo ra từ một tập con tương đối thách thức hơn của HumanEval (xem Phần 3.1.1). Trên buggy-FixEval, chúng tôi quan sát loại bỏ-rồi-hoàn thành vượt trội hơn viết lại-rồi-hoàn thành, vượt trội hơn hoàn thành-rồi-viết lại. Khoảng cách hiệu suất tăng khi kích thước của mô hình hoàn thành tăng lên. Xu hướng so sánh tương tự được quan sát cho pass@k với k = 10,100. Tuy nhiên, khoảng cách hiệu suất vẫn đáng kể giữa phương pháp tốt nhất và hoàn thành từ mã tham chiếu cho tất cả các thiết lập.

Tác động của khả năng Code-LLMs. Đối với mỗi loại mô hình hoàn thành mã, phiên bản lớn hơn hoạt động tốt hơn phiên bản nhỏ hơn sử dụng cùng phương pháp. Ví dụ, CODEGEN-2B-MONO vượt trội hơn CODEGEN-350M-MONO cho tất cả các thiết lập trong hai bộ dữ liệu. So với CODEGEN, các mô hình INCODER, nói chung, đạt được pass@1 tốt hơn nhưng pass@10 và pass@100 tệ hơn. Điều này gợi ý rằng các mô hình CODEGEN tạo ra các hoàn thành đa dạng hơn, trong khi các mô hình INCODER tạo ra các hoàn thành chính xác hơn. Hơn nữa, INCODER nhạy cảm hơn với mã một phần có lỗi so với các mô hình CODEGEN, được chứng minh bởi các điểm số thấp hơn từ bCC ngây thơ.

Các lỗi tổng hợp so với các lỗi thực. Giữa hai bộ dữ liệu bCC, chúng tôi quan sát rằng hiệu suất tổng thể của các phương pháp giảm thiểu tốt hơn trên buggy-HumanEval so với buggy-FixEval. Điều này chỉ ra sự khó khăn của các lỗi tiềm ẩn thực tế trong buggy-FixEval: Có thể có nhiều lỗi; các lỗi có thể được trộn lẫn với các thay đổi không phải sửa lỗi; và các lỗi tinh tế hơn so với các thay đổi toán tử đơn lẻ. Hơn nữa, trong khi đạt được hiệu suất tốt nhất trong hầu hết các trường hợp, hoàn thành-rồi-viết lại chỉ cho thấy sự khác biệt nhỏ so với các phương pháp khác khi sử dụng các mô hình lớn hơn trên buggy-FixEval.

Rút ra: Các phương pháp cơ bản của chúng tôi cải thiện hoàn thành cho tất cả các Code-LLMs đã đánh giá. Tuy nhiên, các khoảng cách hiệu suất còn lại đối với hoàn thành với mã một phần tham chiếu vẫn còn lớn.

4.4 Điều Gì Xảy Ra Nếu Mã Một Phần Không Có Lỗi Tiềm Ẩn?

Như được hiển thị trong Bảng 2, các phương pháp giảm thiểu cho bCC có thể gây hại cho hoàn thành từ ngữ cảnh mã tham chiếu (loại bỏ-rồi-hoàn thành giống nhau cho cả hai thiết lập, do đó không được liệt kê). Điều này gợi ý rằng một hoàn thành mã chung nên xem xét cả hai trường hợp khi các lỗi tiềm ẩn có thể và có thể không tồn tại.

Với các đường cơ sở của chúng tôi, chúng ta có thể sử dụng phương pháp ngưỡng để phát hiện các lỗi tiềm ẩn. Ví dụ, trong viết lại-rồi-hoàn thành, một token chỉ được coi là lỗi tiềm ẩn nếu khoảng cách khả năng của nó đối với token argmax vượt qua một ngưỡng (giữa 0 và 1). Bảng 3 so sánh các điểm số pass@1 của viết lại-rồi-hoàn thành thay đổi các ngưỡng trên buggy-FixEval. Chúng ta có thể thấy rằng ngưỡng 0.9 có thể giúp đạt được một sự cân bằng tương đối tốt cho hai trường hợp. Một phương pháp tương tự có thể được áp dụng cho hoàn thành-rồi-viết lại, vì RealiT cung cấp xác suất của một token là lỗi.

Nhận xét 4.1 (Mất cân bằng trong các phân phối thực). Chúng tôi lưu ý rằng các phân phối của lỗi mã tự nhiên thường mất cân bằng vì các lỗi thực tế xảy ra không thường xuyên. Tuy nhiên, các lỗi tiềm ẩn có thể xảy ra thường xuyên hơn vì thiết lập mục tiêu của chúng tôi là một tình huống mã đang trong quá trình thay vì mã chất lượng cao của các dự án mã nguồn mở phổ biến trong các nghiên cứu trước. Tuy nhiên, để so sánh các phương pháp, chúng tôi đánh giá dữ liệu cân bằng hơn để tránh tác động thống trị của hiệu suất trên mã tham chiếu.

4.5 Phân Tích Tác Động từ Vị Trí Lỗi và Chia

Để hiểu cách vị trí lỗi và kích thước ngữ cảnh ảnh hưởng đến hoàn thành, chúng tôi tổng hợp các kết quả theo vị trí của các lỗi tiềm ẩn và vị trí của các chia mã một phần trong buggy-HumanEval. Các vị trí được chuẩn hóa như (số dòng lỗi tiềm ẩn)/(số dòng) và (số dòng chia)/(số dòng), trong đó số dòng lỗi tiềm ẩn, số dòng chia, và số dòng là số dòng bắt đầu từ header hàm đến dòng chứa lỗi tiềm ẩn, đến cuối mã một phần, và đến cuối giải pháp tiêu chuẩn.

Hình 3 trình bày các bản đồ nhiệt của điểm số pass@1 (được tính trung bình trên các thực thể bCC rơi vào mỗi ô) được đánh giá trên CODEGEN-2B-MONO với hoàn thành ngây thơ trên HumanEval tham chiếu, và hoàn thành ngây thơ, hoàn thành-rồi-viết lại, và viết lại-rồi-hoàn thành (tối đa) trên buggy-HumanEval. Đầu tiên, mô hình hoạt động tốt hơn với mã một phần dài hơn trong trường hợp tham chiếu (Hình 3a). Trong khi hoàn thành ngây thơ hoạt động tổng thể kém với các lỗi tiềm ẩn (Hình 3b), nó hoạt động tương đối tốt khi các lỗi tiềm ẩn xuất hiện trên hoặc gần dòng cuối cùng của mã một phần (dọc theo đường chéo). Thú vị hơn, viết lại-rồi-hoàn thành đạt được điểm số cao hơn khi các lỗi tiềm ẩn xuất hiện muộn hơn (Hình 3d), trong khi hoàn thành-rồi-viết lại hoạt động tốt hơn với các tiền tố mã dài hơn (Hình 3c). Chúng tôi nghi ngờ rằng một tiền tố dài hơn làm cho các mô hình hoàn thành ít có khả năng lệch khỏi hoàn thành tham chiếu. Do đó, như đầu vào cho mô hình viết lại tiếp theo, mã hoàn thành giống với các loại đầu vào mà mô hình viết lại được huấn luyện hơn, làm cho việc sửa chữa có khả năng thành công hơn.

4.6 Nghiên Cứu Trường Hợp

Các lỗi tiềm ẩn có luôn có hại không? Như đã thảo luận trong Phần 2, các lỗi tiềm ẩn không đảm bảo rằng mã hoàn thành sẽ có lỗi. Trong khi chúng tôi quan sát sự suy giảm hiệu suất của Code-LLMs dưới sự hiện diện của các lỗi tiềm ẩn, chúng tôi tìm thấy một số trường hợp thú vị nơi các mô hình quản lý để tạo ra mã chính xác. Ví dụ, Hình 12 trong Phụ lục cho thấy rằng đối với lỗi tiềm ẩn == (được đánh dấu) được sửa đổi từ !=, mô hình hoàn thành cập nhật luồng thuật toán ban đầu của nó với lệnh continue và hoàn thành với chức năng chính xác, mặc dù khác với giải pháp tiêu chuẩn. Đây là một ví dụ rằng một số trường hợp bCC có thể phục hồi được và Code-LLMs có thể thích ứng với chúng.

Khi nào Code-LLMs thành công tại bCC? Đối với các trường hợp thành công của hoàn thành ngây thơ tại bCC, chúng tôi quan sát rằng hoặc mô hình (i) bỏ qua trạng thái không chính xác và tạo ra hoàn thành chính xác hoặc (ii) tính đến lỗi tiềm ẩn để tạo ra một hoàn thành thích ứng với nó. Hình 9 trong Phụ lục cho thấy một ví dụ khi Code-LLMs bỏ qua câu lệnh if-else để bỏ qua lỗi tiềm ẩn.

Các nghiên cứu trường hợp thêm và thảo luận chi tiết hơn có trong Phụ lục D.

5 Công Trình Liên Quan

Hoàn thành mã. Hoàn thành mã cung cấp các gợi ý mã dựa trên một ngữ cảnh cho trước. Phạm vi hoàn thành từ token hoặc dòng tiếp theo, tên phương thức và lớp, đến toàn bộ hàm hoặc chương trình. Các công trình đầu tiên xem mã như chuỗi các token và áp dụng các mô hình ngôn ngữ thống kê cho bài toán, cùng với các nỗ lực khác trong việc xây dựng các mô hình xác suất của mã. Các công trình sau đó áp dụng mạng nơ-ron sâu và kỹ thuật tiền huấn luyện cho mô hình mã và hoàn thành tốt hơn. Công trình của chúng tôi xem xét thiết lập hoàn thành mã ở cấp độ hàm và chương trình và tập trung vào việc sử dụng các mô hình ngôn ngữ lớn để hoàn thành. Ngoài mô hình chuỗi, các công trình gần đây đã xem xét việc tích hợp kiến thức tiên nghiệm về mã thông qua cây cú pháp trừu tượng, các loại token mã, cấu trúc đồ thị, ngữ cảnh phân cấp, hoặc tạo ra phác thảo, hoặc thậm chí mở rộng thông tin của nhiệm vụ ngoài các tệp đầu vào cho trước. Chúng tôi tập trung vào việc chỉ sử dụng mô tả nhiệm vụ và mã một phần như prompt đầu vào cho mô hình, cho phép sử dụng nhiều Code-LLMs hơn và các bộ dữ liệu có sẵn công khai.

Sửa chữa chương trình tự động. Nghiên cứu về chương trình tự động giải tỏa các nhà phát triển khỏi nỗ lực to lớn trong việc tìm và sửa lỗi lập trình. Gần đây, Code-LLMs đã được thích ứng cho sửa chữa chương trình bằng cách dịch các chương trình có lỗi thành các đối tác tham chiếu của chúng. Trong số đó, chúng tôi sử dụng RealiT như mô hình sửa chữa của chúng tôi trong phương pháp hoàn thành-rồi-viết lại vì chúng đạt được các kết quả SotA và sử dụng các đột biến đơn giản tương tự trong quá trình huấn luyện. Mặc dù có sự tương đồng, sửa chữa mã thường nhắm vào việc sửa lỗi từ các chương trình hoàn chỉnh trong khi chúng tôi nghiên cứu các lỗi tiềm ẩn từ mã một phần. Để làm phong phú lượng dữ liệu cho sửa chữa chương trình, các phương pháp đã được đề xuất để tổng hợp các lỗi nhân tạo thông qua các đột biến mã hoặc học để tạo ra lỗi. Tương tự, chúng tôi sử dụng các đột biến mã để tạo ra các lỗi nhân tạo.

Mối quan hệ với các ví dụ đối nghịch. Các ví dụ đối nghịch là những thực thể nơi những nhiễu loạn nhỏ đối với đầu vào dẫn mô hình thay đổi thành các dự đoán sai. Chúng đã được nghiên cứu rộng rãi trong thị giác máy tính và xử lý ngôn ngữ tự nhiên. Các công trình gần đây gợi ý các tình huống tương tự cho các mô hình học mã, nơi các chuyển đổi mã nhỏ, bảo toàn ngữ nghĩa dẫn đến sự suy giảm hiệu suất. Hoàn thành mã có lỗi có thể được xem như một bài toán song song với các ví dụ đối nghịch, nơi chúng tôi mong đợi mô hình điều chỉnh các dự đoán của nó dựa trên các thay đổi nhỏ làm thay đổi ngữ nghĩa trong đầu vào. Trong trường hợp của chúng tôi, độ nhạy cảm không phải là vấn đề, nhưng sự không nhạy cảm là vấn đề.

Điểm chuẩn cho hoàn thành mã có lỗi. Nhiều điểm chuẩn đã được nghiên cứu cho hoàn thành mã và sửa chữa chương trình. Đối với hoàn thành mã, CodeXGLUE, CodeNet, và HumanEval được sử dụng rộng rãi. CodeXGLUE chứa các tập hợp các chương trình Java và Python để hoàn thành nhưng chỉ hỗ trợ đánh giá dựa trên khớp. CodeNet thu thập các bài toán lập trình từ các trang web thẩm phán trực tuyến, với cả giải pháp và trường hợp kiểm tra. HumanEval có thể được coi như một bộ dữ liệu hoàn thành hàm Python, với ngữ cảnh là phát biểu bài toán và header hàm. Chúng tôi tạo ra các bộ dữ liệu của chúng tôi từ các bộ dữ liệu HumanEval và CodeNet. Đối với sửa chữa chương trình nơ-ron, nhiều bộ dữ liệu yêu cầu đánh giá dựa trên khớp hoặc tập trung vào các lỗi biên dịch, khác với thiết lập của chúng tôi. Trong khi IntroClass, QuixBugs, Defects4J, hoặc Refactory cung cấp các bộ kiểm tra để đánh giá, kiểm tra của chúng không phản ánh các lỗi thực tế hoặc thiếu hỗ trợ ngữ cảnh để sử dụng với Code-LLMs. FixEval được đề xuất gần đây như một bộ dữ liệu sửa chữa chương trình nhận biết ngữ cảnh mới để giảm thiểu những hạn chế này, với nhiều bài toán được tạo ra từ các chương trình đã nộp thực. Tuy nhiên, vì FixEval không cung cấp phát biểu bài toán và chỉ tập trung vào sửa chữa chương trình, chúng tôi tạo ra một điểm chuẩn mới sử dụng FixEval và nguồn bài toán của nó - CodeNet.

6 Thảo Luận và Kết Luận

Hạn chế. Các phương pháp cơ bản của chúng tôi được phát triển cho bCC có thể làm giảm hiệu suất hoàn thành trên ngữ cảnh mã tham chiếu, như được hiển thị trong Phần 4.4, gợi ý nhu cầu cân bằng các thiết lập có lỗi và tham chiếu trong các giải pháp cho bCC. Hơn nữa, trong khi buggy-FixEval được liên kết với các chương trình thi lập trình thực tế, không rõ ràng mức độ buggy-FixEval phù hợp với thiết lập phát triển phần mềm chung nơi việc có được một bộ kiểm tra và đánh giá thích hợp thách thức hơn.

Tác động và ứng dụng. Vì công trình của chúng tôi tập trung vào mã đang trong quá trình ít tinh tế hơn và dễ mắc lỗi hơn, ngữ cảnh mã nên được xem như một gợi ý về ý định của người dùng hơn là một triển khai "vàng" chất lượng cao. Do đó, tự nhiên theo sau rằng một lập trình viên cặp hoặc một công cụ thông minh nên đề xuất một thay đổi cho mã nháp thay vì mù quáng tiếp tục nó nếu họ tin rằng một phần nhất định của nháp hiện tại không được dự định. Từ góc độ trải nghiệm người dùng, một IDE có thể hiển thị các gợi ý thay đổi mã cho mã hiện tại của người dùng nếu những phần như vậy được xác định. Chức năng tương tự đã tồn tại cho các loại gợi ý thay đổi mã khác, ví dụ, sửa chính tả và import còn thiếu.

Kết luận. Chúng tôi giới thiệu và định nghĩa bài toán hoàn thành mã có lỗi, được lấy cảm hứng từ tình huống lập trình thực tế nơi người ta hoàn thành một chương trình lập trình với phát biểu bài toán và một mã một phần với các lỗi tiềm ẩn. Chúng tôi xây dựng hai bộ dữ liệu mới, buggy-HumanEval và buggy-FixEval, như các điểm chuẩn nhiệm vụ và thấy rằng sự hiện diện của các lỗi tiềm ẩn làm giảm đáng kể hiệu suất hoàn thành của tất cả các mô hình ngôn ngữ lớn về mã đã đánh giá. Điều tra thêm của chúng tôi về các phương pháp hoàn thành cho Code-LLMs trong việc xử lý các lỗi tiềm ẩn cho thấy rằng hoàn thành với các lỗi tiềm ẩn vẫn còn thách thức mặc dù tăng cường các mô hình với các mô hình sửa chữa chương trình bên ngoài. Chúng tôi cung cấp các nghiên cứu loại bỏ và trường hợp rộng rãi để hiểu thêm và phân tích thiết lập hoàn thành mã có lỗi. Chúng tôi hy vọng nghiên cứu mới và có hệ thống của chúng tôi sẽ mở đường cho các công trình tương lai trong việc hiểu và cải thiện khả năng sử dụng của Code-LLMs trong các thiết lập phát triển phần mềm thực tế.

# 2309.00608.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: ./2309.00608.pdf
# Kích thước tệp: 2762798 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Đồng hành với các Trợ lý: Kết hợp Mô hình Ngôn ngữ Lớn với
Công cụ Hoàn thiện để Sửa chữa Chương trình Tự động
Yuxiang Wei
Đại học Illinois
Urbana-Champaign, USA
ywei40@illinois.edu

Chunqiu Steven Xia
Đại học Illinois
Urbana-Champaign, USA
chunqiu2@illinois.edu

Lingming Zhang
Đại học Illinois
Urbana-Champaign, USA
lingming@illinois.edu

TÓM TẮT
Trong quá trình Sửa chữa Chương trình Tự động (APR), việc tổng hợp các bản vá chính xác cho các hệ thống thực tế bằng các ngôn ngữ lập trình đa mục đích có thể rất thách thức. Các Mô hình Ngôn ngữ Lớn (LLM) gần đây đã được chứng minh là những "copilot" hữu ích trong việc hỗ trợ các nhà phát triển với nhiều tác vụ mã hóa khác nhau, và cũng đã được áp dụng trực tiếp để tổng hợp bản vá. Tuy nhiên, hầu hết các LLM coi chương trình như chuỗi token, có nghĩa là chúng không biết về các ràng buộc ngữ nghĩa cơ bản của ngôn ngữ lập trình đích. Điều này dẫn đến nhiều bản vá được tạo ra không hợp lệ về mặt tĩnh, cản trở tính thực tiễn của kỹ thuật. Do đó, chúng tôi đề xuất Repilot, một framework tổng hợp mã tổng quát để tiếp tục đồng hành với các "copilot" AI (tức là LLM) bằng cách tổng hợp nhiều bản vá hợp lệ hơn trong quá trình sửa chữa. Hiểu biết chính của chúng tôi là nhiều LLM tạo ra đầu ra theo cách tự hồi quy (tức là từng token một), giống như con người viết chương trình, điều này có thể được tăng cường và hướng dẫn đáng kể thông qua một Công cụ Hoàn thiện. Repilot tổng hợp một bản vá ứng cử viên một cách hiệp đồng thông qua sự tương tác giữa LLM và Công cụ Hoàn thiện, điều này 1) loại bỏ các token không khả thi được đề xuất bởi LLM và 2) hoàn thiện chủ động token dựa trên các gợi ý được cung cấp bởi Công cụ Hoàn thiện. Đánh giá của chúng tôi trên một tập con của bộ dữ liệu Defects4j 1.2 và 2.0 được sử dụng rộng rãi cho thấy Repilot vượt trội hơn các kỹ thuật tối tân bằng cách sửa nhiều hơn 27% và 47% lỗi tương ứng. Hơn nữa, Repilot tạo ra nhiều bản vá hợp lệ và chính xác hơn so với LLM cơ sở với cùng một ngân sách. Mặc dù chúng tôi tập trung vào việc tận dụng Repilot cho APR trong công việc này, phương pháp tổng thể cũng có thể tổng quát hóa cho các tác vụ tạo mã khác.

KHÁI NIỆM CCS
•Phần mềm và kỹ thuật của nó →Kiểm thử và gỡ lỗi phần mềm; Lập trình tự động.

TỪ KHÓA
Sửa chữa Chương trình, Mô hình Ngôn ngữ Lớn, Công cụ Hoàn thiện

Định dạng Tham chiếu ACM:
Yuxiang Wei, Chunqiu Steven Xia, và Lingming Zhang. 2023. Đồng hành với các Trợ lý: Kết hợp Mô hình Ngôn ngữ Lớn với Công cụ Hoàn thiện để Sửa chữa Chương trình Tự động. Trong Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE '23), December 3–9, 2023, San Francisco, CA, USA. ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/3611643.3616271

1 GIỚI THIỆU
Sửa chữa Chương trình Tự động (APR) tìm cách giảm bớt nỗ lực sửa lỗi thủ công của các nhà phát triển bằng cách tự động tổng hợp các bản vá được cung cấp mã lỗi gốc [20]. Các công cụ APR truyền thống tối tân chủ yếu dựa trên các mẫu sửa chữa được tạo thủ công để khớp với các mẫu mã lỗi và áp dụng các thay đổi mã tương ứng [21,41]. Mặc dù vượt trội hơn các kỹ thuật truyền thống khác [37,43,47], các công cụ như vậy chỉ có thể sửa các loại lỗi trong các mẫu được đặt trước và không thể tổng quát hóa cho các loại lỗi mới. Với sự phát triển của các kỹ thuật Học sâu (DL), các nhà nghiên cứu xây dựng các công cụ APR dựa trên học [29,72,74] dựa trên kiến trúc Dịch máy Thần kinh (NMT) [57]. Họ huấn luyện các mô hình NMT để dịch mã lỗi thành mã chính xác bằng cách học từ các cặp mã lỗi và đã sửa được lấy từ các commit mã nguồn mở. Tuy nhiên, như đã thảo luận trong công việc trước đây [67], các tập huấn luyện của những công cụ này có thể bị hạn chế về kích thước và cũng chứa các commit không liên quan hoặc nhiễu.

Gần đây hơn, các nhà nghiên cứu đã tận dụng sự tăng trưởng trong lĩnh vực NLP để sử dụng trực tiếp các Mô hình Ngôn ngữ Lớn (LLM) [10,17] cho APR [31,66,67]. LLM không chỉ đạt được hiệu suất ấn tượng trên nhiều tác vụ NLP [7], mà còn được chứng minh là những "copilot" đáng tin cậy trong việc hỗ trợ các nhà phát triển với nhiều tác vụ mã hóa khác nhau [4,40]. Lý do là các LLM hiện đại thường bao gồm một lượng lớn các kho mã nguồn mở có sẵn như một phần của tập dữ liệu huấn luyện của chúng. Nhận ra sức mạnh của LLM, các nhà nghiên cứu gần đây đã áp dụng LLM cho APR: thay vì dịch mã lỗi thành mã chính xác, LLM được sử dụng trực tiếp để tổng hợp bản vá chính xác từ ngữ cảnh xung quanh. AlphaRepair [67] tái thiết lập vấn đề APR như một tác vụ cloze (hoặc infilling) [2,19]: nó đầu tiên thay thế các đoạn mã lỗi bằng các token che khuất và sau đó sử dụng CodeBERT [17] để điền mã chính xác trong ngữ cảnh xung quanh đã cho. Các nghiên cứu khác về LLM cho APR đã áp dụng các LLM thậm chí còn lớn hơn với các cài đặt sửa chữa khác nhau (bao gồm việc tạo ra các hàm vá hoàn chỉnh) [33, 53, 66].

Mặc dù các kỹ thuật LLM trước đây cho APR đạt được hiệu suất sửa lỗi tối tân, chúng sử dụng LLM theo cách hộp đen, trong đó LLM cơ bản tạo ra chương trình theo phân phối token mà không có bất kỳ hiểu biết cấu trúc hoặc ngữ nghĩa nào về mã. Để làm nổi bật các hạn chế với các công cụ LLM hiện tại cho APR, trong Hình 1 chúng tôi cho thấy 3 kịch bản mà LLM có thể tạo ra các bản vá không chính xác. 1) Tạo ra các token không khả thi. Trong Hình 1.1, LLM có xác suất cao (>90%) tạo ra String để hoàn thành phương thức asString. Tuy nhiên asString không phải là một truy cập trường hợp lệ cho đối tượng t và cũng không phải là một phần của phạm vi của phương thức lỗi hiện tại.

--- TRANG 2 ---
ESEC/FSE '23, December 3–9, 2023, San Francisco, CA, USA Yuxiang Wei, Chunqiu Steven Xia, and Lingming Zhang

[Hình 1 và nội dung mô tả các hạn chế của các phương pháp APR dựa trên LLM hiện tại]

Để giải quyết những hạn chế nêu trên, chúng tôi đề xuất Repilot, một framework để tiếp tục đồng hành với các "copilot" AI (tức là LLM) thông qua việc kết hợp LLM với Công cụ Hoàn thiện để tổng hợp nhiều bản vá hợp lệ hơn. Công cụ Hoàn thiện [48] có thể phân tích các chương trình chưa hoàn thành và suy luận về ngữ nghĩa theo cách chịu lỗi. Hiểu biết chính của chúng tôi là việc tạo token tự hồi quy của LLM giống như một nhà phát triển con người viết mã, trong đó Công cụ Hoàn thiện có thể cung cấp các cập nhật thời gian thực để kiểm tra xem mã một phần được viết bởi con người/LLM có hợp lệ hay không. Repilot đầu tiên sử dụng LLM để cung cấp xác suất tạo ra token tiếp theo trong bản vá và sau đó truy vấn Công cụ Hoàn thiện để sửa đổi danh sách xác suất bằng cách động đặt xác suất của các token không hợp lệ về không. Sau đó chúng ta có thể lấy mẫu từ danh sách xác suất mới để chọn token tiếp theo. Hơn nữa, nhận ra khả năng của Công cụ Hoàn thiện để đề xuất hoàn thiện, chúng tôi sử dụng tính năng này bất cứ khi nào chỉ có một hậu tố định danh có thể hoàn thành ngữ cảnh. Điều này không chỉ cho phép Repilot tạo ra các bản vá với các định danh hiếm và dài hợp lệ mà còn giảm công việc của LLM cần thiết để tạo ra các tên định danh dài một cách lặp đi lặp lại.

Ví dụ, Repilot trực tiếp loại bỏ các token String và Name trong Hình 1.1 vì chúng không khả thi theo Công cụ Hoàn thiện, nhưng vẫn chấp nhận token End chính xác. Trong Hình 1.2, Công cụ Hoàn thiện nhận ra rằng asEndTag là sự tiếp tục hợp lệ duy nhất cho tiền tố asEnd, vì vậy Repilot trực tiếp hoàn thành token này mà không cần truy vấn LLM. Để chống lại chi phí thời gian của Công cụ Hoàn thiện, chúng tôi thực hiện một số kỹ thuật tối ưu hóa để giảm thiểu chi phí phụ. Lưu ý rằng công việc Synchromesh gần đây [52] cũng sử dụng Công cụ Hoàn thiện để tạo mã đáng tin cậy với LLM. Tuy nhiên, nó dựa vào các ràng buộc được thiết kế bởi chuyên gia và chỉ nhắm vào các ngôn ngữ dành riêng cho miền (ví dụ: SQL). Repilot hoạt động trực tiếp cho các ngôn ngữ lập trình đa mục đích trong khi giới thiệu chi phí phụ tối thiểu và có thể chủ động hoàn thành việc tạo hiện tại bằng Công cụ Hoàn thiện mà không cần truy vấn LLM.

Để chứng minh tính tổng quát của Repilot, chúng tôi khởi tạo Repilot với hai LLM có kiến trúc và kích thước khác nhau: CodeT5-large [61], một LLM mã hóa-giải mã với 770 triệu tham số, và InCoder-6.7B [19], một LLM chỉ giải mã với 6,7 tỷ tham số, cả hai đều có khả năng điền mã từ ngữ cảnh tiền tố và hậu tố. Chúng tôi tiếp tục thực hiện một Công cụ Hoàn thiện Java cho Repilot dựa trên Eclipse JDT Language Server [1,18] vì nó cung cấp nhiều phân tích dựa trên ngữ nghĩa khác nhau thông qua Giao thức Máy chủ Ngôn ngữ nhất quán [48]. Chúng tôi đánh giá Repilot trên một tập con của bộ dữ liệu Defects4J 1.2 và 2.0 được nghiên cứu rộng rãi [32] và chứng minh kết quả tối tân trong cả số lượng sửa chữa chính xác và tỷ lệ biên dịch - tỷ lệ phần trăm của các bản vá được tạo ra có thể được biên dịch thành công. Hơn nữa, trong khi chúng tôi đánh giá Repilot cho APR trong công việc này, chúng tôi tin rằng framework tổng thể có thể dễ dàng áp dụng cho các tác vụ tạo mã khác, bao gồm hoàn thành mã [16,73], tổng hợp chương trình [40,52], và tạo test [14, 65]. Tóm lại, chúng tôi đóng góp những điều sau:

•Hướng nghiên cứu. Chúng tôi mở ra một hướng nghiên cứu mới để kết hợp LLM với Công cụ Hoàn thiện cho APR mạnh mẽ hơn và hơn thế nữa. So với các kỹ thuật trước đây chỉ thực hiện xử lý hậu kỳ để sửa các thế hệ không hợp lệ hoặc sử dụng các phương pháp tĩnh đơn giản để xấp xỉ những token hợp lệ này, phương pháp của chúng tôi tận dụng một Công cụ Hoàn thiện mạnh mẽ để trực tiếp cung cấp phản hồi chính xác về các chương trình một phần nhằm tránh việc tạo ra token không hợp lệ.

•Kỹ thuật. Chúng tôi thực hiện Repilot, một phương pháp LLM cho APR được khởi tạo với các mô hình CodeT5 và InCoder để thực hiện sửa chữa kiểu cloze kết hợp với Eclipse JDT Language Server đã sửa đổi [1,18] của chúng tôi như Công cụ Hoàn thiện. Trong Repilot, chúng tôi sử dụng Công cụ Hoàn thiện để có hệ thống loại bỏ các token không hợp lệ được tạo ra bởi LLM và để trực tiếp hoàn thành mã dựa trên tiền tố hiện tại. Hơn nữa, chúng tôi thực hiện các tối ưu hóa để giảm đáng kể chi phí phụ của Repilot. Chúng tôi đã mở nguồn công cụ của mình tại: https://github.com/ise-uiuc/Repilot.

•Nghiên cứu. Chúng tôi so sánh Repilot với các công cụ APR tối tân trên Defects4J 1.2 và 2.0. Repilot có thể đạt được kết quả tối tân mới với 66 lỗi đơn hunk Defects4J 1.2 và 50 lỗi đơn dòng Defects4J 2.0 được sửa tương ứng với 30 sửa chữa kết hợp nhiều hơn trên cả hai bộ dữ liệu so với đường cơ sở tốt nhất trước đây. Đánh giá sâu hơn của chúng tôi cho thấy Repilot liên tục cải thiện tính hợp lệ và tính chính xác của các bản vá được tạo ra với chi phí phụ hạn chế (7% cho CodeT5 và không đáng kể cho InCoder).

2 NỀN TẢNG VÀ CÔNG VIỆC LIÊN QUAN

2.1 Mô hình Ngôn ngữ Lớn cho Mã

Những tiến bộ gần đây trong Xử lý Ngôn ngữ Tự nhiên (NLP) đã trao quyền cho ý tưởng sử dụng Mô hình Ngôn ngữ Lớn (LLM) được huấn luyện trước trên kho ngữ liệu khổng lồ của ngôn ngữ tự nhiên và mã cho nhiều tác vụ liên quan đến mã khác nhau [4,5,10,38,70]. LLM dựa trên kiến trúc transformer [59] có thể được phân loại thành chỉ mã hóa, chỉ giải mã và mã hóa-giải mã. Các mô hình chỉ mã hóa chỉ sử dụng thành phần mã hóa bằng cách huấn luyện sử dụng mục tiêu Mô hình Ngôn ngữ Che khuất (MLM) [15] trong đó một tỷ lệ nhỏ (ví dụ: 15%) của các token bị che khuất. Mục tiêu của MLM là khôi phục những token bị che khuất này dựa trên ngữ cảnh xung quanh. Các mô hình chỉ mã hóa như CodeBERT [17] và GraphCodeBERT [23] được thiết kế để cung cấp một biểu diễn của mã đầu vào để được sử dụng cho các tác vụ downstream như phân loại mã [71]. Mặt khác, các mô hình chỉ giải mã nhằm tạo ra các token một cách tự hồi quy dựa trên tất cả các token đã được tạo ra trước đó. CodeGEN [50,51], Codex [10] và PolyCoder [70] là những ví dụ về LLM chỉ giải mã trong đó chúng có thể được sử dụng cho các tác vụ tự động hoàn thành mã. Khác với LLM chỉ mã hóa và chỉ giải mã, các mô hình mã hóa-giải mã (ví dụ: CodeT5 [60,61] và PLBART [3]) kết hợp cả mã hóa và giải mã lại với nhau và cùng huấn luyện cả hai thành phần. Một mục tiêu huấn luyện trước thường được sử dụng cho các mô hình mã hóa-giải mã là Dự đoán Span Che khuất (MSP) trong đó các span ngẫu nhiên (nhiều token liên tiếp) được thay thế bằng các token che khuất đơn lẻ và các mô hình học để điền vào span bị che khuất bằng chuỗi token chính xác. Hơn nữa, các mô hình chỉ giải mã như InCoder [19] cũng có thể thực hiện infilling thông qua mục tiêu mô hình ngôn ngữ nhân quả [2]. Thay vì sử dụng bộ giải mã để dự đoán token tiếp theo trong dữ liệu huấn luyện gốc, tương tự như MSP, InCoder cũng thay thế các span ngẫu nhiên bằng các token span bị che khuất. Trong quá trình huấn luyện, InCoder học cách khôi phục các span gốc một cách tự hồi quy. Với chiến lược huấn luyện này, InCoder có thể thực hiện infilling với ngữ cảnh hai chiều tương tự như các mô hình mã hóa-giải mã, cho phép sửa chữa kiểu cloze.

2.2 Hoàn thành Mã

Hoàn thành mã là một trong những tính năng được sử dụng thường xuyên nhất trong Môi trường Phát triển Tích hợp (IDE). Nó giảm bớt đáng kể độ phức tạp của phát triển phần mềm bằng cách gợi ý tương tác các cấu trúc chương trình sau vị trí con trỏ của người dùng trong khi lập trình viên đang gõ, bao gồm tên định danh và API thư viện. Hoàn thành mã hiện là một cơ sở hạ tầng không thể thiếu của hầu hết các ngôn ngữ lập trình được sử dụng rộng rãi và có thể dễ dàng tích hợp vào hầu hết các trình soạn thảo văn bản hiện đại nhờ có sự hiện diện của Giao thức Máy chủ Ngôn ngữ [48], chuẩn hóa giao tiếp giữa các công cụ và dịch vụ ngôn ngữ. Theo truyền thống, một Công cụ Hoàn thiện dựa trên ngữ nghĩa được thực hiện trên một loạt các phân tích cú pháp và ngữ nghĩa tăng dần phức tạp của ngôn ngữ lập trình đích, vì nó cần hiểu các chương trình được viết một phần và cung cấp phản hồi thời gian thực. Công cụ Hoàn thiện có toàn quyền truy cập vào kho dự án và các phụ thuộc của nó và có thể đưa ra các gợi ý theo hiểu biết ngữ nghĩa của nó. Những tiến bộ gần đây trong LLM chứng minh khả năng tạo ra các hoàn thiện dài và phức tạp. Tuy nhiên, chúng có thể tạo ra các chương trình không hợp lý do hạn chế về kích thước ngữ cảnh mã và mất mát phân tích chương trình bằng cách chỉ coi chương trình như chuỗi token. Trong bài báo này, chúng tôi sử dụng thuật ngữ Công cụ Hoàn thiện để chỉ loại dựa trên ngữ nghĩa. Chúng tôi định nghĩa chính thức các thuộc tính mong đợi của Công cụ Hoàn thiện trong framework của chúng tôi ở Định nghĩa 3.4.

2.3 Sửa chữa Chương trình Tự động

Sửa chữa Chương trình Tự động (APR) nhằm tạo ra các bản vá được cung cấp vị trí mã lỗi và các test phơi bày lỗi. Theo truyền thống, phương pháp APR có thể được phân loại thành dựa trên ràng buộc [13,35,43,47], dựa trên heuristic [36,37,63] và dựa trên mẫu [21,25,34,41,42,46]. Trong số các kỹ thuật cổ điển này, các công cụ dựa trên mẫu đã được chứng minh là đạt được số lượng sửa lỗi cao nhất bằng cách sử dụng các mẫu sửa chữa được tạo thủ công để nhắm vào các mẫu lỗi cụ thể [21]. Tuy nhiên, những mẫu được tạo thủ công này không thể bao quát tất cả các loại lỗi tồn tại và do đó, các công cụ dựa trên mẫu không thể sửa các lỗi ngoài các mẫu được xác định trước của chúng.

Để giải quyết vấn đề mà các công cụ APR dựa trên mẫu gặp phải, các nhà nghiên cứu tìm đến Dịch máy Thần kinh (NMT) [57] để phát triển các công cụ APR dựa trên NMT [11,29,39,44,72,74]. Các công cụ APR dựa trên NMT huấn luyện một mô hình NMT để dịch mã lỗi đầu vào thành mã chính xác thông qua các bộ dữ liệu sửa lỗi chứa các cặp mã lỗi và đã sửa. Tuy nhiên, những bộ dữ liệu sửa lỗi này có thể chỉ chứa một số lượng/loại sửa lỗi nhỏ, đặc biệt là so với một lượng lớn đoạn mã nguồn mở có sẵn, do khó khăn trong việc thu thập các commit sửa lỗi [67]. Ngoài ra, các bộ dữ liệu có thể không lọc được các commit không liên quan [30] như tái cấu trúc, điều này thêm nhiễu vào các bộ dữ liệu huấn luyện. Do sự phụ thuộc này vào việc huấn luyện bằng các bộ dữ liệu sửa lỗi, những công cụ dựa trên NMT này cũng không thể tổng quát hóa cho các loại lỗi không được thấy trong quá trình huấn luyện.

Gần đây, các nhà nghiên cứu bắt đầu áp dụng trực tiếp LLM cho APR [66]. AlphaRepair [67] là đầu tiên sử dụng trực tiếp LLM cho APR kiểu cloze (hoặc kiểu infilling): nó che khuất đoạn mã lỗi và sau đó sử dụng CodeBERT [17] để trực tiếp điền mã chính xác dựa trên ngữ cảnh xung quanh. Trong khi AlphaRepair chứng minh tiềm năng sử dụng các mô hình chỉ mã hóa cho APR kiểu cloze, các nghiên cứu khác [33,53,66] đã xem xét việc áp dụng cả ba loại kiến trúc LLM. FitRepair [64] cải thiện thêm AlphaRepair thông qua việc tinh chỉnh theo miền cụ thể và các chiến lược nhắc nhở tận dụng giả thuyết phẫu thuật thẩm mỹ [6]. Thậm chí gần đây hơn, các nhà nghiên cứu đã áp dụng các mô hình dựa trên đối thoại cho APR [8,56,68,69]. Ví dụ, ChatRepair [69] đề xuất một phương pháp APR đối thoại hoàn toàn tự động bằng cách học từ các nỗ lực vá trước đó, bao gồm cả mã vá và thông tin thất bại test.

So với các kỹ thuật APR truyền thống và dựa trên NMT, các kỹ thuật dựa trên LLM có thể đạt được kết quả sửa lỗi tối tân mới [66,67]. Mặc dù hiệu suất ấn tượng, một hạn chế đặc biệt của những kỹ thuật này là thiếu hướng dẫn trong việc tạo bản vá. Công việc trước đây chủ yếu coi LLM như một hộp đen và chỉ truy vấn mô hình thông qua tìm kiếm chùm tia [67] hoặc lấy mẫu [33,53,66]. Điều này có nghĩa là LLM, mặc dù mạnh mẽ, vẫn có thể tạo ra các bản vá không hợp lệ dựa trên ngữ cảnh mã hiện tại.

Trong công việc này, chúng tôi giải quyết những hạn chế này bằng cách sử dụng Công cụ Hoàn thiện dựa trên ngữ nghĩa để hướng dẫn và loại bỏ không gian tìm kiếm của LLM. Phương pháp của chúng tôi trực giao với các kỹ thuật APR dựa trên LLM gần đây và có thể dễ dàng kết hợp với chúng. Thực tế, các kỹ thuật APR dựa trên NMT cũng đã cố gắng giải quyết vấn đề này. CURE [29] đầu tiên thu thập tĩnh các định danh hợp lệ và buộc mô hình NMT chỉ chọn từ các định danh hợp lệ trong quá trình tạo. Recoder [74] xây dựng một mô hình NMT dựa trên chỉnh sửa để thực thi tính đúng đắn cú pháp và giới thiệu các token giữ chỗ và sau đó như một bước xử lý hậu kỳ, Recoder sẽ thay thế các token giữ chỗ bằng các định danh hợp lệ được xác định tĩnh. RewardRepair [72] mặt khác, cố gắng tăng số lượng bản vá có thể biên dịch bằng cách phạt các bản vá không thể biên dịch trong quá trình huấn luyện. So với những kỹ thuật trước đây này, Repilot tổng quát và hiệu quả hơn. Repilot không yêu cầu bất kỳ huấn luyện cụ thể miền nào và tận dụng phân tích tăng dần của Công cụ Hoàn thiện có sẵn để thực thi các ràng buộc được đảm bảo nhằm hướng dẫn LLM một cách tức thì.

3 SỞ KHAI

Trong phần này, chúng tôi đầu tiên định nghĩa các khái niệm về ngôn ngữ lập trình được sử dụng trong toàn bộ bài báo (§3.1). Sau đó chúng tôi thảo luận về các trừu tượng chính thức của hai thành phần chính được sử dụng trong framework Repilot của chúng tôi: Công cụ Hoàn thiện (§3.2) và Mô hình Ngôn ngữ Lớn (§3.3). Hai trừu tượng này rất quan trọng vì mỗi cái mô tả một tập hợp các triển khai phù hợp, điều này tạo thành lý do tại sao Repilot là một framework có thể tổng quát hóa.

3.1 Ngôn ngữ có Kiểm tra Tĩnh

Bây giờ chúng tôi giới thiệu khái niệm ngôn ngữ lập trình được trang bị kiểm tra tĩnh và định nghĩa tính khả thi của một chương trình một phần trước khi thiết lập Công cụ Hoàn thiện (Định nghĩa 3.3).

Định nghĩa 3.1 (Ngôn ngữ Lập trình có Kiểm tra Tĩnh). Một ngôn ngữ lập trình có kiểm tra tĩnh được định nghĩa như một cặp bộ ký tự Σpl và đặc tả tĩnh Φ⊆Σ*pl như một quan hệ đơn trên Σ*pl.

PLs=(Σpl,Φ), (3.1)

Cho một prog∈Σ*pl, ký hiệu Φ(prog) (hoặc prog∈Φ) phát biểu rằng prog là một chương trình hợp lệ tĩnh trong ngôn ngữ này. Đối với các ngôn ngữ lập trình có kiểu tĩnh như Java, kiểm tra biên dịch là một loại kiểm tra tĩnh.

Định nghĩa 3.2 (Tính Khả thi Tĩnh của Chương trình Một phần). Đối với một chương trình được viết một phần prog∈Σ*pl, chúng ta nói nó khả thi tại vị trí con trỏ caret liên quan đến đặc tả tĩnh Φ, viết là (prog,caret)⊨Φ, khi và chỉ khi tồn tại một sự tiếp tục có thể sau caret mà với việc hoàn thành prog dẫn đến một chương trình hợp lệ tĩnh. Định nghĩa có thể được viết chính thức như

(prog,caret)⊨Φ≜∃cont∈Σ*pl,Φ(prog[caret←cont]),(3.2)

trong đó chúng ta sử dụng ký hiệu prog[caret←cont] như hành động hoàn thành prog tại caret với cont, tức là
prog[caret←cont]≜prog0..caret·cont·progcaret..|prog|.(3.3)

Trong Thuật toán 1, chúng ta mở rộng ký hiệu này để chấp nhận một phạm vi :N×N, sao cho prog[range←hunk] chỉ định hành động thay thế nội dung của prog trong phạm vi bằng hunk.

3.2 Trừu tượng của Công cụ Hoàn thiện

Một Công cụ Hoàn thiện, được hiển thị trong Hình 2, cung cấp các gợi ý tiếp tục cho một chương trình được viết một phần dựa trên vị trí con trỏ.

Định nghĩa 3.3 (Công cụ Hoàn thiện). Nói một cách chính thức, Công cụ Hoàn thiện CE là một cặp

CE=(Σpl,complete), (3.4)

trong đó Σpl là bộ ký tự của ngôn ngữ đích, và
complete :(Σ*pl,N)→P(Σ*pl)∪{unknown} (3.5)

là một hàm để thu thập các hoàn thiện dựa trên một chương trình tại một vị trí con trỏ nào đó, với unknown chỉ ra rằng công cụ không thể xác định các gợi ý từ ngữ cảnh mã (ví dụ: khi hoàn thành một khai báo biến). Lưu ý rằng chúng tôi phân biệt giữa unknown và hoàn thiện trống ∅ vì trong bài báo này chúng tôi quan tâm đến một nhóm cụ thể của Công cụ Hoàn thiện nghiêm ngặt giúp xác định tính khả thi của một chương trình một phần.

[Hình 2: Trừu tượng của Công cụ Hoàn thiện]

Định nghĩa 3.4 (Công cụ Hoàn thiện Nghiêm ngặt). Giả sử rằng Công cụ Hoàn thiện CE có thể thu thập một tập hợp các hoàn thiện dựa trên một chương trình prog khả thi tại caret (tức là, (prog,caret)⊨Φ):

completions = complete(prog,caret)
trong đó completions ≠ unknown. (3.6)

Khi đó, CE được gọi là nghiêm ngặt khi và chỉ khi, dưới điều kiện này, việc tiếp tục prog bằng bất kỳ mã nào không khớp với tập hợp hoàn thiện này sẽ tạo ra một chương trình không khả thi tại vị trí con trỏ mới:

∀c∉Prefix(completions),(prog′,caret′)̸⊨Φ,
trong đó prog′=prog[caret←c] và caret′=caret+|c|,
Prefix(·)={𝑐|𝑠∈· và 𝑐 là tiền tố của 𝑠 hoặc ngược lại}.(3.7)

Định nghĩa này cơ bản có nghĩa là một Công cụ Hoàn thiện nghiêm ngặt không nên đưa ra các gợi ý sai. Nó nên trả về unknown bất cứ khi nào không chắc chắn. Một Công cụ Hoàn thiện nghiêm ngặt tầm thường có thể là cái luôn trả về unknown.

3.3 Trừu tượng của LLM

Trong phần này, chúng tôi đưa ra một trừu tượng chính thức của LLM dựa trên mã hóa-giải mã như được hiển thị trong Hình 3, mà trong thực tế phức tạp hơn nhưng tuân theo trừu tượng. Trừu tượng này bao gồm các mô hình chỉ giải mã và cũng có thể mô tả các mô hình chỉ mã hóa sử dụng đầu ra mã hóa trực tiếp như xác suất token để tạo.

[Hình 3: Trừu tượng của LLM dựa trên mã hóa-giải mã]

Định nghĩa 3.5 (Mô hình Ngôn ngữ Lớn). Chính thức, chúng tôi định nghĩa LLM dựa trên mã hóa-giải mã LM như một bộ ba

LM=(Σlm,encode,decode), (3.8)

trong đó Σlm là một từ vựng bao gồm tập hợp các token được định nghĩa bởi mô hình. Bộ mã hóa encode là một hàm ánh xạ từ một chuỗi đầu vào đến biểu diễn được mã hóa của nó trong EncRep:

encode :Σ*lm→EncRep. (3.9)

Bộ giải mã decode, được định nghĩa dưới đây, sau đó ghi nhớ biểu diễn được mã hóa trong EncRep, nhận đầu vào là một chuỗi token, và tạo ra đầu ra biểu diễn được giải mã của nó trong DecRep:

decode :EncRep→Σ*lm→DecRep. (3.10)

Trong định nghĩa này, việc bộ giải mã ghi nhớ biểu diễn được mã hóa được mô hình hóa như một hàm bậc cao hơn trả về một hàm giải mã chi tiết dựa trên biểu diễn được mã hóa. Biểu diễn được giải mã trong DecRep cơ bản gán một xác suất cho mỗi token trong từ vựng để phát biểu khả năng của nó là token tiếp theo trong chuỗi. Do đó, chúng ta có thể định nghĩa DecRep như

DecRep =Σlm→[0,1]. (3.11)

4 PHƯƠNG PHÁP

Theo hầu hết các công cụ APR dựa trên học sâu gần đây [67,72,74], Repilot tập trung vào việc sửa các lỗi đơn hunk, trong đó bản vá được thu thập bằng cách thay đổi một phần mã liên tục dưới định vị lỗi hoàn hảo. Repilot có thể được mở rộng cho các lỗi đa hunk bằng cách thay thế tất cả các vị trí hunk cùng một lúc bằng các token infilling riêng biệt và sử dụng LLM để tạo ra các hunk thay thế. Được hưởng lợi từ kỷ nguyên LLM, như được hiển thị trong Hình 4, trong bài báo này, chúng tôi coi vấn đề sửa chữa như một tác vụ cloze [67], trong đó một bản vá được hình thành bằng cách đầu tiên thay thế hunk lỗi bằng một token span che khuất (<SPAN>) và sau đó sử dụng LLM để trực tiếp tổng hợp hunk đã sửa từ ngữ cảnh mã xung quanh để thay thế token span.

[Hình 4: Sửa chữa chương trình kiểu cloze]

4.1 Tổng quan

Hình 5 cho thấy một tổng quan về cách Repilot tổng hợp một chương trình hoạt động như hunk được sửa chữa của chương trình lỗi gốc. Vòng lặp tạo bao gồm một vòng lặp liên tục cập nhật việc tạo với các token mới được tạo ra từ sự hiệp đồng giữa mô hình ngôn ngữ và Công cụ Hoàn thiện. Vòng lặp bắt đầu bằng việc áp dụng việc tạo hiện tại như đầu vào cho mô hình ngôn ngữ (1), cái mà trả về một không gian tìm kiếm của một ánh xạ từ một token tiếp theo được đề xuất đến xác suất của nó. Repilot sau đó vào một giai đoạn chọn token mà lặp đi lặp lại lấy mẫu một token từ không gian tìm kiếm, kiểm tra tính khả thi của nó, và loại bỏ không gian tìm kiếm cho đến khi một token được chấp nhận. Mỗi khi một token được lấy mẫu, Repilot đầu tiên kiểm tra xem nó có trúng vào ghi nhớ (2), cái mà lưu trữ các token được biết là khả thi hoặc không khả thi. Việc ghi nhớ các token không khả thi bao gồm việc sử dụng cấu trúc dữ liệu cây tiền tố (Trie) được thảo luận trong §4.3. Khi token trúng vào ghi nhớ và không khả thi, không gian tìm kiếm được loại bỏ bằng cách đặt xác suất của token này về không (3), và việc lấy mẫu tiếp theo sẽ chạy trên không gian tìm kiếm được cập nhật. Theo cách này, cùng một token không được lấy mẫu lại trong giai đoạn chọn token. Nếu token bỏ lỡ việc ghi nhớ, không gian tìm kiếm được loại bỏ dưới sự hướng dẫn của Công cụ Hoàn thiện (4), mà chúng tôi elaborated trong §4.2. Với điều kiện rằng token được lấy mẫu bị từ chối bởi Công cụ Hoàn thiện, Repilot đặt xác suất của nó về không. Nếu không, nó được chấp nhận và quá trình chọn token này kết thúc. Việc ghi nhớ được cập nhật trong cả hai trường hợp (5). Sau khi một token được chấp nhận (6), chúng tôi tiếp tục tận dụng Công cụ Hoàn thiện, cố gắng hoàn thành chủ động token (7). Việc hoàn thành chủ động, được thảo luận trong §4.4, có thể tạo ra nhiều token hơn hoặc không thêm gì vào token được chấp nhận. Cuối cùng, Repilot nối tất cả các token mới được tạo ra vào việc tạo hiện tại và bắt đầu một vòng lặp mới cho đến khi một bản vá hoàn chỉnh được tạo ra. Vòng lặp dừng khi mô hình tạo ra token đặc biệt end-token.

Thuật toán 1 chi tiết quá trình này và cho thấy cách một chương trình bản vá hoàn chỉnh được tạo ra bằng cách sử dụng những gì được thiết lập trong §3. Nó bổ sung mô tả cách Repilot thực hiện tiền xử lý (Dòng 3 đến 6) và chính thức hóa quy trình loại bỏ được hướng dẫn hoàn thiện được minh họa trong Hình 5 bằng cách sử dụng hai hàm GuidedPrune và ActivelyComplete (Dòng 7 đến 17). Trong tất cả các thuật toán của chúng tôi, chúng tôi sử dụng "ký hiệu chấm" để chỉ định một thực thể của một bộ (ví dụ: LM.encode), nhưng sử dụng một dạng viết tắt khi ngữ cảnh rõ ràng (ví dụ: Σlm và Σpl cho LM.Σlm và CE.Σpl). Chúng tôi cũng tùy chọn áp dụng chú thích kiểu để làm rõ. Lưu ý rằng chúng tôi đơn giản hóa định nghĩa của Công cụ Hoàn thiện bằng cách hạn chế nó được gọi với một chương trình. Trong thực tế, Công cụ Hoàn thiện luôn được khởi tạo với toàn bộ dự án và có thể cung cấp các gợi ý dựa trên thông tin toàn cầu.

[Thuật toán 1: Vòng lặp Sửa chữa chính của Repilot]

4.2 Loại bỏ Không gian Tìm kiếm Được hướng dẫn Hoàn thiện

Trong phần này, chúng tôi giải thích ý tưởng cốt lõi về cách Repilot sử dụng Công cụ Hoàn thiện để loại bỏ không gian tìm kiếm của LLM.

Thuật toán 2 giải thích sâu sắc cách Công cụ Hoàn thiện giúp loại bỏ không gian tìm kiếm của mô hình. Hàm GuidedPrune nhận đầu vào là Công cụ Hoàn thiện CE, chương trình hiện tại prog, vị trí con trỏ hiện tại caret, và bản đồ xác suất tokens được cung cấp bởi mô hình, và tạo ra một token next-token như sự tiếp tục của chương trình prog tại vị trí caret. Hàm bao gồm một vòng lặp while (Dòng 2 đến 11) trong đó Repilot đầu tiên lấy mẫu một token tiếp theo có thể theo xác suất (Dòng 3), cập nhật chương trình hiện tại tương ứng (Dòng 4), và di chuyển con trỏ sau next-token. Repilot sau đó gọi Công cụ Hoàn thiện sử dụng hàm complete được định nghĩa trong Phương trình (3.5), dựa trên chương trình prog′ và vị trí con trỏ caret′. Nếu kết quả không phải là unknown nhưng không có hoàn thiện (Dòng 8), có nghĩa là không có sự tiếp tục có thể nào có thể được hình thành sau next-token, vì vậy token next-token được coi là không khả thi, do đó được loại bỏ (Dòng 9) trong vòng tìm kiếm này, và vòng lặp sẽ tiếp tục (Dòng 10). Nếu không, chúng tôi coi token là khả thi và trả về next-token (Dòng 11).

Việc loại bỏ tại Dòng 9 được thực hiện bằng cách đặt xác suất của mục nhập next-token của bản đồ xác suất tokens về không. Ký hiệu được sử dụng tại dòng này được định nghĩa tiếp theo. Giả sử rằng

f:X→Y={x0↦→y0,x1↦→y1, . . .} (4.1)

là một hàm tùy ý, và
a:X⇀Y={x′0↦→y′0,x′1↦→y′1, . . .} (4.2)

là một hàm một phần cùng loại, có nghĩa là chỉ một tập con của các đầu vào trong miền X được liên kết với một đầu ra trong phạm vi Y. Chúng tôi định nghĩa hành động thay đổi giá trị đầu ra của các đầu vào trong f bằng cách sử dụng các gán được cung cấp bởi a như

f[a]=(f−fremoved)∪a
trong đó fremoved ={x′↦→f(x′)|x′↦→y′∈a}.(4.3)

[Thuật toán 2: Loại bỏ Không gian Tìm kiếm Được hướng dẫn Hoàn thiện]

4.3 Ghi nhớ cho Tìm kiếm Nhanh hơn

Thuật toán 2 (GuidedPrune) bao gồm một vòng lặp của các thử nghiệm và hành động loại bỏ, điều này làm chậm tác vụ sửa chữa trong một số tình huống. Để tăng tốc quy trình tìm kiếm của nó, chúng tôi áp dụng một số kỹ thuật ghi nhớ để giảm tần suất gọi Công cụ Hoàn thiện để phân tích.

Ghi nhớ các token bị từ chối. Để sửa chữa một lỗi trong thực tế đòi hỏi tạo ra rất nhiều mẫu, có nghĩa là cùng một chương trình prog′ và caret′ (Dòng 4 đến 5) có thể xảy ra lặp đi lặp lại trong Thuật toán 2 (GuidedPrune). Do đó, chúng ta có thể ghi nhớ tất cả các token bị loại bỏ tại Dòng 9 bằng cách lưu trữ chúng trong một biến

rejected :(Σ*pl,N)→P(Σlm), (4.4)

ánh xạ từ một chương trình prog và vị trí con trỏ caret đến một tập hợp các token bị từ chối. Sau đó chúng ta đặt xác suất của các token bị từ chối về không trước, viết là

tokens :=tokens[{tok↦→0|tok∈rejected(prog,caret)}],(4.5)

trước khi vòng lặp while (Dòng 2) bắt đầu.

Ghi nhớ các token được chấp nhận. Bên cạnh các token bị từ chối, chúng ta cũng có thể ghi nhớ các token đã được chấp nhận trước đó trong một biến

accepted :(Σ*pl,N)→P(Σlm) (4.6)

để tránh chi phí phụ phát sinh từ việc truy vấn Công cụ Hoàn thiện tại Dòng 7 đến 8.

Xây dựng Cây Tiền tố của Các Token Bị từ chối. Thường xuyên có nhiều token trong từ vựng của mô hình ngôn ngữ là tiền tố của nhau. Và rõ ràng là nếu một token bị từ chối, có nghĩa là không có sự tiếp tục có thể nào có thể được hình thành sau token để thu được một chương trình hợp lệ tĩnh, thì bất kỳ token nào chia sẻ tiền tố như vậy đều nên bị từ chối. Vì lý do này, chúng tôi xây dựng và tiếp tục cập nhật một cây tiền tố, hoặc Trie, của tất cả các token bị từ chối dựa trên prog và caret, và kiểm tra xem có token nào trong Trie là tiền tố của next-token ngay sau Dòng 3 trong Thuật toán 2. Nếu đúng như vậy, Repilot trực tiếp bỏ qua đến lần lặp tiếp theo, tránh phân tích sâu hơn.

4.4 Hoàn thiện Chủ động

Không chỉ Công cụ Hoàn thiện có thể xác định tính khả thi của một token tiếp theo có thể được đề xuất bởi mô hình, như được hiển thị trong §4.2, mà nó cũng có thể chủ động gợi ý một sự tiếp tục tiềm năng của chương trình hiện tại mà không cần truy vấn mô hình, giống như cách các nhà phát triển hưởng lợi từ tự động hoàn thành.

Thuật toán 3 mô tả hoàn thiện chủ động chi tiết. Hàm ActivelyComplete nhận ba đầu vào: Công cụ Hoàn thiện CE, chương trình hiện tại prog, và vị trí con trỏ hiện tại caret, và đầu ra một chuỗi token completion-toks như sự tiếp tục của prog tại caret. Ban đầu, Repilot lấy kết quả hoàn thiện theo Phương trình (3.5), dựa trên prog và caret (Dòng 2), và kiểm tra xem nó có phải là unknown không (Dòng 3). Nếu đúng như vậy (completions = unknown), kết quả được đặt thành một chuỗi rỗng, có nghĩa là không có hoàn thiện bổ sung nào được tạo ra (Dòng 4). Nếu không, Repilot tính toán tiền tố chung của tất cả các hoàn thiện (Dòng 6). Lưu ý rằng kiểu của biến kết quả completion là một chuỗi ký tự trong bảng chữ cái Ngôn ngữ Lập trình, khác với Σlm của mô hình ngôn ngữ, vì vậy Repilot tiếp tục căn chỉnh hoàn thiện để phù hợp với từ vựng của mô hình (Dòng 7). Cuối cùng, kết quả được trả về tại Dòng 8.

[Thuật toán 3: Hoàn thiện Chủ động]

4.5 Tính Đúng đắn của Repilot

Trong phần này, chúng tôi cho thấy đảm bảo lý thuyết của mỗi thuật toán được thảo luận ở trên dưới điều kiện Công cụ Hoàn thiện nghiêm ngặt (Định nghĩa 3.4).

Bổ đề 4.1 (Tính Đúng đắn của Loại bỏ). Các token bị loại bỏ trong Thuật toán 2 (GuidedPrune) dẫn đến các chương trình không khả thi.

Thảo luận. Từ Phương trình (3.7) trong Định nghĩa 3.4, chúng ta có thể suy ra rằng một chương trình không khả thi tại một vị trí con trỏ nào đó nếu Công cụ Hoàn thiện không trả về unknown nhưng tập hợp các hoàn thiện trống, tức là,

|completions|=0→(prog,caret)̸⊨Φ
nếu completions ≠ unknown (4.7)

Việc loại bỏ trong Thuật toán 2 xảy ra tại Dòng 8 đến 9, chính xác là những gì được mô tả ở trên. Kết quả là, chúng ta có thể kết luận rằng chương trình với next-token được nối thêm là không khả thi, và do đó Repilot an toàn khi từ bỏ token. □

Bổ đề 4.2 (Tính Đúng đắn của Ghi nhớ). Việc ghi nhớ được thảo luận trong §4.3 không ảnh hưởng đến hành vi của GuidedPrune.

Thảo luận. Định lý đúng vì tất cả các kỹ thuật ghi nhớ được đề cập trong §4.3 không thay đổi ngữ nghĩa của GuidedPrune mà chỉ tăng tốc quá trình. □

Bổ đề 4.3 (Tính Đúng đắn của Hoàn thiện Chủ động). Nếu một chương trình khả thi tại một vị trí con trỏ nào đó, chương trình mới được tạo ra bởi Thuật toán 3 (ActivelyComplete) là khả thi tại vị trí con trỏ mới của nó.

Thảo luận. Dựa trên Phương trình (3.7) từ Định nghĩa 3.4, bất kỳ sự tiếp tục nào không khớp với tập hợp hoàn thiện sẽ mang lại một chương trình không khả thi. Trong trường hợp những hoàn thiện này có tiền tố chung được chia sẻ, bất kỳ sự tiếp tục nào không bắt đầu với tiền tố chung này sẽ không hợp lệ. Do đó, hoàn thành chương trình gốc với tiền tố chung (Dòng 6 trong Thuật toán 3) là cách duy nhất để tạo ra một chương trình khả thi mới. □

Dựa trên Bổ đề 4.1 đến 4.3, chúng ta có thể dễ dàng chứng minh rằng thuật toán tổng thể của Repilot là đúng đắn.

Định lý 4.4 (Tính Đúng đắn Tổng thể). Thuật toán 1 (Repair) không bỏ sót bất kỳ chương trình khả thi nào trong không gian tìm kiếm của mô hình ngôn ngữ.

Khi nào Repilot sẽ thất bại? Mặc dù các định lý về tính đúng đắn của Repilot, tức là nó loại bỏ không gian tìm kiếm một cách chính xác, nó không cung cấp bất kỳ đảm bảo nào rằng Repilot tạo ra một bản vá hợp lệ mỗi lần. Do đó, hành vi mong đợi của Repilot là có thể thu được các bản vá hợp lệ hiệu quả hơn, thay vì hoàn toàn không có lỗi trong quá trình tạo.

5 THIẾT LẬP THỰC NGHIỆM

Trong bài báo này, chúng tôi nghiên cứu các câu hỏi nghiên cứu sau đây để đánh giá Repilot.

•RQ1: Khả năng sửa lỗi của Repilot so với các kỹ thuật APR tối tân như thế nào (§6.1)?
•RQ2: Repilot hiệu quả như thế nào trong việc cải thiện tỷ lệ biên dịch của việc tạo bản vá (§6.2)?
•RQ3: Tất cả các thành phần của Repilot có đóng góp tích cực vào hiệu quả của nó không (§6.3)?
•RQ4: Repilot có thể tổng quát hóa cho các chủ đề lỗi và mô hình khác nhau không (§6.4)?

Chúng tôi đầu tiên so sánh hiệu suất sửa chữa của Repilot, được khởi tạo với CodeT5, với các công cụ APR tối tân trên các công cụ truyền thống, dựa trên NMT, và dựa trên LLM trên các bộ dữ liệu Defects4J trong RQ1. Trong RQ2, chúng tôi sau đó đánh giá chặt chẽ sự cải thiện trong tỷ lệ biên dịch - tỷ lệ phần trăm các bản vá có thể biên dịch được tạo ra để chứng minh rằng Repilot không chỉ hiệu quả trong sửa chữa lỗi mà còn có thể tạo ra số lượng bản vá có thể biên dịch cao hơn so với các công cụ hiện có. Hơn nữa, chúng tôi thực hiện một nghiên cứu ablation chi tiết trong RQ3 để đánh giá sự đóng góp của các thành phần khác nhau của Repilot. Cuối cùng, trong RQ4, chúng tôi mở rộng đánh giá Repilot của chúng tôi ngoài việc sử dụng với CodeT5 trong các RQ trước đó. Chúng tôi tiến thêm một bước bằng cách thực hiện Repilot với InCoder và đánh giá hiệu suất của Repilot sử dụng cả CodeT5 và InCoder trên các lỗi đơn hunk từ cả Defects4J 1.2 và 2.0 để chứng minh tính tổng quát của Repilot trên các LLM và chủ đề lỗi khác nhau.

5.1 Triển khai

Chúng tôi sử dụng triển khai Python của các mô hình CodeT5-large và InCoder-6.7B thu được trên Hugging Face [26]. Chúng tôi xây dựng pipeline tạo của mình bằng Python với 5K dòng mã và thực hiện một phiên bản sửa đổi của Eclipse JDT Language Server [1,18] bằng Java với 1.5K dòng mã bổ sung, phục vụ như Công cụ Hoàn thiện nghiêm ngặt của framework chúng tôi. Việc tạo mặc định của chúng tôi sử dụng lấy mẫu nucleus top-p [24] với p=1.0, temperature = 1.0, max-tokens = 50 và lấy mẫu 5000 lần mỗi lỗi để so sánh công bằng với các công việc trước đây (§6.1 và §6.2). Do chi phí cao của APR, chúng tôi lấy mẫu 500 lần mỗi lỗi cho nghiên cứu ablation (§6.3) và đánh giá tính tổng quát (§6.4). Theo công việc trước đây [39,44,67,74], chúng tôi sử dụng timeout 5 giờ để tạo và xác thực tất cả các bản vá mỗi lỗi. Chúng tôi tạo và xác thực các bản vá trên 32-Core với CPU Ryzen Threadripper PRO 3975WX, RAM 256 GB và GPU NVIDIA RTX A6000, chạy Ubuntu 20.04.4 LTS với Java version OpenJDK 1.8.0_181.

5.2 Chương trình Chủ đề

Chúng tôi sử dụng benchmark sửa chữa phổ biến Defects4J cho đánh giá của mình. Defects4J là một bộ dữ liệu Java được tuyển chọn thủ công với các cặp phiên bản lỗi và đã vá của dự án nguồn cùng với bộ test nhà phát triển để xác thực. Theo công việc trước đây và quy ước văn học APR, chúng tôi tách Defects4J thành Defects4J 1.2, chứa 391 lỗi (loại bỏ 4 lỗi đã lỗi thời) từ 6 dự án nguồn Java, và Defects4J 2.0, chứa 438 lỗi mới từ 9 dự án bổ sung. Đối với Defects4J 1.2, chúng tôi chỉ tập trung vào các lỗi đơn hunk vì Repilot được thiết kế cho sửa chữa đơn hunk. Lưu ý đây cũng là cài đặt đánh giá được sử dụng trong đường cơ sở trước đây [72]. Hơn nữa, chúng tôi loại bỏ các lỗi không tương thích với Công cụ Hoàn thiện của chúng tôi do các vấn đề kỹ thuật. Tổng cộng, chúng tôi xem xét 138 lỗi đơn hunk từ Defects4J 1.2 và 135 lỗi đơn hunk từ Defects4J 2.0. Cho đánh giá chính của chúng tôi trong RQ1, theo cùng thiết lập như công việc LLM trước đây cho APR [66,67], chúng tôi báo cáo kết quả trên tất cả 135 lỗi đơn hunk từ Defects4J 1.2 và 76 lỗi đơn dòng (một tập con của các lỗi đơn hunk) từ Defects4J 2.0. Trong khi đó, trong nghiên cứu tính tổng quát của chúng tôi (RQ4), chúng tôi tiếp tục đánh giá Repilot trên tập đầy đủ các lỗi đơn hunk từ cả Defects4J 1.2 và 2.0 cho cả CodeT5 và InCoder.

5.3 Kỹ thuật So sánh

Chúng tôi so sánh Repilot với các đường cơ sở tối tân từ các công cụ APR truyền thống, dựa trên NMT, và LLM cho APR. Chúng tôi đánh giá với AlphaRepair [67] vì nó là phương pháp LLM cho APR hiệu suất cao nhất. Đối với các phương pháp dựa trên NMT, chúng tôi chọn 6 công cụ gần đây: RewardRepair [72], Recoder [74], CURE [29], CoCoNuT [44], DLFix [39] và SequenceR [11] dựa trên kiến trúc NMT. Ngoài ra, chúng tôi so sánh với 12 công cụ APR truyền thống: PraPR [21], TBar [41], AVATAR [42], SimFix [28], FixMiner [34], CapGen [63], JAID [9], SketchFix [25], NOPOL [13], jGenProg [45], jMutRepair [46] và jKali [46]. Tổng cộng, chúng tôi bao gồm 19 đường cơ sở APR và so sánh Repilot với chúng trên Defects4J 1.2 và 2.0. Cài đặt đánh giá của chúng tôi là trên định vị lỗi hoàn hảo – trong đó vị trí thực tế của lỗi được cung cấp cho công cụ APR. Chúng tôi lưu ý rằng đây là cài đặt đánh giá ưa thích vì nó loại bỏ bất kỳ sự khác biệt nào gây ra bởi các phương pháp định vị lỗi khác nhau [29,44,58,74]. Chúng tôi tuân theo quy ước được sử dụng trong công việc trước đây [21,29,41,74] và trực tiếp báo cáo kết quả sửa lỗi thu được từ các nghiên cứu trước đây [21, 67, 72].

5.4 Metrics Đánh giá

•Bản vá hợp lý là các bản vá vượt qua tất cả các test case nhưng có thể vi phạm ý định thực sự của người dùng.
•Bản vá chính xác là các bản vá tương đương về mặt ngữ nghĩa với bản vá nhà phát triển. Theo thực hành APR phổ biến, chúng tôi xác định tương đương ngữ nghĩa bằng cách kiểm tra thủ công mỗi bản vá hợp lý.
•Tỷ lệ biên dịch bản vá cũng được sử dụng trong nhiều công việc APR dựa trên học sâu [29,72], cho biết tỷ lệ phần trăm các bản vá có thể biên dịch trong tất cả các bản vá được tạo ra.

6 PHÂN TÍCH KẾT QUẢ

6.1 RQ1: So sánh với Các công cụ Hiện có

Trong RQ1 và RQ2, chúng tôi tuân theo phương pháp trước đây cho APR kiểu cloze [67] để sử dụng các mẫu sửa chữa cho một đánh giá trung thực. Thay vì thay thế toàn bộ dòng lỗi bằng mã được tạo ra bởi mô hình, những mẫu này có hệ thống giữ các phần của dòng lỗi để giảm lượng mã mà LLM cần tạo ra. Lưu ý rằng chúng tôi không áp dụng bất kỳ mẫu sửa chữa nào trong RQ3 và RQ4 vì chúng tôi xem xét một số lượng mẫu nhỏ hơn ở đó (tức là 500 mẫu như được hiển thị trong Phần 5.1) và cũng muốn tập trung vào tác động của các cấu hình thí nghiệm khác nhau.

Defects4J 1.2. Chúng tôi đầu tiên so sánh Repilot với các công cụ APR tối tân trên các lỗi đơn hunk từ Defects4J 1.2. Bảng 1 cho thấy số lượng bản vá chính xác được tạo ra bởi Repilot, được đánh giá theo kiểu cloze, cùng với các đường cơ sở. Repilot đạt được kết quả tối tân mới với 66 sửa lỗi chính xác trên Defects4J 1.2, vượt trội hơn tất cả các công cụ APR trước đây. Hình 6a cho thấy sơ đồ Venn của các lỗi duy nhất được sửa cho các công cụ APR dựa trên LLM và NMT hiệu suất cao nhất trong đó Repilot có thể thu được số lượng cao nhất 8 lỗi duy nhất. Hơn nữa, Hình 6b so sánh các lỗi duy nhất được sửa cho tất cả các đường cơ sở hiệu suất cao nhất và với tất cả các công cụ APR khác được kết hợp (Others). Chúng tôi quan sát thấy rằng Repilot có thể sửa 7 lỗi mà không có đường cơ sở nào khác có thể sửa được cho đến nay.

Để chứng minh khả năng của Repilot sửa các lỗi khó, Hình 7 cho thấy một lỗi duy nhất (Closure-133) từ Defects4J 1.2 mà chỉ Repilot có thể sửa. Lỗi này được sửa bằng cách thêm câu lệnh gán mới sử dụng biến toàn cục NO_UNREAD_TOKEN mà khó tạo ra vì nó không xuất hiện trong ngữ cảnh xung quanh của vị trí lỗi. Repilot đầu tiên sử dụng CodeT5 để tạo ra tiền tố ban đầu của unread. Sau đó sử dụng Công cụ Hoàn thiện, Repilot nhận ra rằng Token là sự tiếp tục duy nhất đúng về mặt ngữ nghĩa và trực tiếp thực hiện hoàn thiện chủ động để trả về unreadToken. Tương tự để tạo ra NO_UNREAD_TOKEN, Repilot đầu tiên tạo ra NO_ và sau đó sử dụng hoàn thiện chủ động để trực tiếp tạo ra định danh hiếm này mà không cần lặp đi lặp lại lấy mẫu LLM. Khó để các công cụ APR dựa trên LLM và NMT trước đây tạo ra sửa chữa này vì LLM hoặc mô hình NMT có thể không thể hoàn thành định danh hiếm này vì nó đòi hỏi nhiều bước liên tục để tạo ra. Ngược lại, Repilot, thông qua việc sử dụng hoàn thiện chủ động, có thể trực tiếp tạo ra định danh hiếm này chỉ với tiền tố định danh ban đầu để nhanh chóng đạt đến bản vá chính xác này.

Defects4J 2.0. Chúng tôi tiếp tục đánh giá Repilot với các đường cơ sở được đánh giá trên các lỗi đơn dòng trong Defects4J 2.0. Đối với những lỗi này, chúng tôi tuân theo phương pháp trước đây cho APR kiểu cloze [67] để sử dụng các mẫu sửa chữa. Thay vì thay thế toàn bộ dòng lỗi bằng mã được tạo ra bởi mô hình, những mẫu này có hệ thống giữ các phần của dòng lỗi (ví dụ: tiền tố hoặc hậu tố, tham số phương thức và gọi) để giảm lượng mã mà LLM cần tạo ra. Chúng tôi áp dụng những mẫu sửa chữa này chỉ cho các lỗi đơn dòng Defects4J 2.0 vì chúng được thiết kế cho các lỗi đơn dòng. Bảng 1 cũng cho thấy số lượng sửa chữa chính xác trên Defects4J 2.0 so với các đường cơ sở. Chúng tôi quan sát thấy rằng Repilot có thể sửa số lượng lỗi cao nhất 50 (16 nhiều hơn so với đường cơ sở tốt nhất tiếp theo) trên Defects4J 2.0. Sự cải thiện này so với các đường cơ sở hiện có cho thấy Repilot có thể tổng quát hóa cho hai phiên bản của bộ dữ liệu Defects4J và chứng minh sức mạnh của các mẫu sửa chữa để tăng cường hiệu suất của các công cụ APR dựa trên LLM.

Hình 8 cho thấy một lỗi duy nhất từ Defects4J 2.0 mà chỉ Repilot có thể sửa. Đầu tiên, Repilot tạo ra bản vá đến vị trí con trỏ. Công cụ Hoàn thiện sau đó nắm bắt loại chính xác của đối tượng từ Token.EndTag toString. Sử dụng thông tin này, Repilot đúng cách loại bỏ các token không phải là một phần của lớp String (ví dụ: name và text). Do đó, bản vá được tạo ra chứa một phương thức lớp String hợp lệ của toLowerCase() mà chính xác sửa lỗi này. Tương tự như sửa chữa lỗi duy nhất trước đây trong Defects4J 1.2, các công cụ APR dựa trên LLM trước đây có thể lãng phí nhiều thời gian tạo ra các sự tiếp tục không chính xác về mặt ngữ nghĩa vì chúng không có quyền truy cập vào thông tin kiểu. Hơn nữa, các công cụ APR dựa trên NMT như CURE [29], xấp xỉ quá mức danh sách các định danh hợp lệ bằng cách tĩnh nắm bắt tất cả các trường có thể truy cập, có thể không tạo ra sửa chữa này vì một định danh bị loại bỏ (ví dụ: name) cũng có thể hợp lệ cho một loại đối tượng khác. Repilot sử dụng Công cụ Hoàn thiện để phân tích các chương trình một phần và nhận ra sự lan truyền kiểu phức tạp để loại bỏ hiệu quả.

6.2 RQ2: Phân tích Tỷ lệ Biên dịch

Chúng tôi đánh giá tỷ lệ biên dịch của các bản vá được tạo ra bởi Repilot so với các kỹ thuật APR dựa trên học trước đây. Bảng 2 cho thấy tỷ lệ phần trăm các bản vá có thể biên dịch trên bộ dữ liệu Defects4J 1.2. Chúng tôi quan sát thấy rằng trên tất cả các số lượng bản vá được tạo ra, Repilot cải thiện đáng kể tỷ lệ phần trăm các bản vá có thể biên dịch so với các công cụ trước đây. Chúng tôi đầu tiên nhận thấy rằng các công cụ APR dựa trên LLM (Repilot và AlphaRepair), có thể duy trì tỷ lệ biên dịch của chúng so với các công cụ dựa trên NMT (CoCoNuT và CURE) trong đó tỷ lệ biên dịch giảm mạnh khi chúng tôi tăng số lượng bản vá. Điều này cho thấy khả năng của LLM tạo ra lượng lớn các bản vá hợp lý. Repilot có thể duy trì tỷ lệ biên dịch gần 60% ở 1000 bản vá được tạo ra trong khi phương pháp trước đây chỉ vừa trên 30%.

So với CURE [29], trong đó một ước tính quá mức các định danh hợp lệ được thu thập thông qua phân tích tĩnh và được sử dụng để loại bỏ các token không hợp lệ được tạo ra bởi mô hình NMT, Repilot tận dụng Công cụ Hoàn thiện mạnh mẽ để theo dõi ngữ cảnh hiện tại để thu được một bước loại bỏ chính xác hơn. Hơn nữa, so với RewardRepair [72], trong đó tỷ lệ biên dịch được tăng cường thông qua việc phạt các bản vá không thể biên dịch trong quá trình huấn luyện, Repilot trực tiếp sử dụng LLM kết hợp với Công cụ Hoàn thiện để tránh chi phí cao của việc huấn luyện một mô hình mới. Ngoài ra, Repilot sử dụng khả năng hoàn thiện chủ động của Công cụ Hoàn thiện để trực tiếp tạo ra những định danh hiếm này để tăng cường tỷ lệ biên dịch. Do đó, Repilot có thể đạt được tỷ lệ phần trăm cao nhất các bản vá có thể biên dịch trên tất cả bốn cài đặt khác nhau.

6.3 RQ3: Nghiên cứu Ablation

Để nghiên cứu sự đóng góp của mỗi thành phần của Repilot đối với hiệu quả tổng thể của nó, chúng tôi tiến hành một nghiên cứu ablation nhằm biện minh cho các giả thuyết sau:

•Thuật toán 2 (GuidedPrune) giúp LLM đạt được các bản vá hợp lệ (có thể biên dịch) hiệu quả hơn trên không gian tìm kiếm được loại bỏ.
•Ghi nhớ (§4.3) giảm tần suất truy vấn Công cụ Hoàn thiện, do đó tăng tốc tổng hợp bản vá.
•Hoàn thiện chủ động cung cấp hướng dẫn tổng hợp thêm và giúp Repilot đạt được nhiều bản vá hợp lệ hơn một cách hiệu quả.
•Tỷ lệ hợp lý của các bản vá trở nên cao hơn cùng với tỷ lệ biên dịch.

Để đưa ra cơ sở cho những giả thuyết này, chúng tôi thiết lập bốn biến thể sau:

•Repilot∅ chỉ sử dụng LLM cơ sở (CodeT5) để tổng hợp bản vá.
•Repilot^p áp dụng loại bỏ được định nghĩa trong Thuật toán 2.
•Repilot^m_p tận dụng ghi nhớ (§4.3) trên đầu loại bỏ.
•Repilot sử dụng hoàn thiện chủ động để hướng dẫn thêm.

và đánh giá chúng bằng cách so sánh chúng với hiệu quả của chúng trong việc tạo ra các bản vá có thể biên dịch, hợp lý, và chính xác.

Bảng 3 cho thấy thời gian tạo (tính bằng giây mỗi bản vá), sự đóng góp về tỷ lệ phần trăm các bản vá có thể biên dịch và hợp lý trong tất cả các bản vá được tạo ra duy nhất, số lượng sửa chữa hợp lý, và số lượng sửa chữa chính xác cho mỗi một trong bốn biến thể trên các lỗi đơn hunk Defects4J 1.2. Chúng tôi đầu tiên quan sát thấy rằng chỉ sử dụng LLM cơ sở cho APR (Repilot∅), chúng tôi đạt được tỷ lệ biên dịch thấp nhất ở 43.2%. Bằng cách thêm loại bỏ được cung cấp bởi Công cụ Hoàn thiện, chúng tôi có thể cải thiện đáng kể tỷ lệ biên dịch lên 60.7%, số lượng sửa chữa hợp lý từ 56 lên 62, và số lượng sửa chữa chính xác từ 37 lên 41. Sự cải thiện bổ sung được thực hiện bằng cách thêm kỹ thuật hoàn thiện chủ động để đạt được Repilot đầy đủ với tỷ lệ biên dịch cao nhất ở 63.4%, tỷ lệ hợp lý 5.21%, số lượng sửa chữa hợp lý nhiều nhất ở 63, và sửa chữa chính xác nhiều nhất ở 42.

Nhìn vào thời gian tạo bản vá, bắt đầu từ Repilot∅, việc thêm loại bỏ thông qua Công cụ Hoàn thiện phát sinh chi phí phụ hơn 25%. Tuy nhiên, điều này có thể được giảm đáng kể bằng cách sử dụng ghi nhớ (Repilot^p) để đạt được khoảng 10% chi phí phụ bằng cách tránh truy vấn Công cụ Hoàn thiện một khi chúng ta biết một định danh không hợp lệ. Hơn nữa, hoàn thiện chủ động có thể giảm thêm chi phí phụ xuống 7% vì thay vì phải lấy mẫu LLM cho mỗi bước trong việc tạo, chúng ta có thể hoàn thiện chủ động một định danh.

Kết quả là, tất cả các thành phần đóng góp vào hiệu quả tổng thể của Repilot. Repilot có thể liên tục tăng tỷ lệ biên dịch và hợp lý, cũng như tạo ra nhiều sửa chữa hợp lý/chính xác hơn trong khi phát sinh chi phí phụ tối thiểu so với việc sử dụng trực tiếp LLM để tổng hợp bản vá.

6.4 RQ4: Tính Tổng quát

Để chứng minh tính tổng quát của Repilot trên các chủ đề lỗi và mô hình khác nhau, một mặt, chúng tôi tiếp tục đánh giá Repilot với CodeT5 trên tất cả các lỗi đơn hunk của Defects4J 2.0. Mặt khác, chúng tôi bổ sung khởi tạo và đánh giá Repilot với mô hình InCoder-6.7B lớn hơn. Giống hệt như RQ3, chúng tôi cũng tiến hành 500 mẫu trong RQ4 do chi phí cao của APR.

Bảng 4 cho thấy so sánh giữa đường cơ sở Repilot∅ và phương pháp Repilot đầy đủ của chúng tôi trên các chủ đề lỗi và mô hình khác nhau. Chúng tôi xem xét cùng tập hợp các lỗi đơn hunk Defects4J 1.2 như trong RQ3 và một tập hợp bổ sung các lỗi đơn hunk Defects4J 2.0.

Sau khi điều tra, chúng ta có thể thấy rằng Repilot với CodeT5 vượt trội hơn đường cơ sở trên Defects4J 1.2 như được minh họa trong RQ3. Hơn nữa, trên Defects4J 2.0, nó cũng có thể đạt được 18.1 điểm phần trăm (pp) nhiều hơn có thể biên dịch và 3.0 pp nhiều hơn các bản vá hợp lý, cũng như 6 sửa chữa hợp lý nhiều hơn và 4 sửa chữa chính xác nhiều hơn, với chi phí phụ 7.4%.

Trong khi đó, khi Repilot được khởi tạo với InCoder, nó vẫn tạo ra nhiều bản vá có thể biên dịch và hợp lý hơn, cũng như nhiều sửa chữa hợp lý và chính xác hơn trên cả Defects4J 1.2 và Defects4J 2.0 so với đường cơ sở InCoder. Cuối cùng nó đưa ra 6 sửa chữa chính xác nhiều hơn trên Defects4J 1.2 và 1 nhiều hơn trên Defects4J 2.0.

Một sự khác biệt chính khi so sánh Repilot với InCoder và CodeT5 là khi Repilot được trang bị InCoder, một mô hình lớn hơn nhiều so với CodeT5, nó phát sinh chi phí phụ không đáng kể. Điều này là do so với chi phí cao của lấy mẫu tự hồi quy bằng các mô hình lớn hơn, chi phí bổ sung từ việc truy vấn Công cụ Hoàn thiện nhỏ hơn nhiều và do đó làm tầm thường chi phí phụ của Repilot khi áp dụng trên các mô hình lớn hơn. Ngoài ra, mô hình InCoder lớn hơn, bất kể nó có được áp dụng với Repilot hay không, có thể liên tục sửa nhiều lỗi hơn trên cả Defects4J 1.2 và 2.0 so với CodeT5, xác nhận thêm phát hiện trước đây rằng LLM lớn hơn thường hoạt động tốt hơn cho APR [66].

Nhìn chung, kết quả thí nghiệm chỉ ra rằng Repilot có thể tổng quát hóa cho các tập hợp lỗi khác nhau (cả lỗi đơn hunk trong Defects4J 1.2 và 2.0) cũng như LLM lớn hơn (InCoder)

7 HẠN CHẾ

Đầu tiên, để phát huy hết tiềm năng của Repilot, điều quan trọng là Công cụ Hoàn thiện có thể cung cấp hướng dẫn hữu ích trong khi vẫn nghiêm ngặt (Định nghĩa 3.4). Tuy nhiên, nói chung khó khăn hơn để cân bằng tính hữu ích và tính nghiêm ngặt của Công cụ Hoàn thiện trong nhiều ngôn ngữ lập trình có kiểu động, chẳng hạn như Python, so với Java được nghiên cứu trong bài báo này, đây là ngôn ngữ lập trình có kiểu tĩnh. Trong khi đó, có một xu hướng ngày càng tăng của các ngôn ngữ có kiểu động áp dụng hỗ trợ cho gợi ý kiểu [12, 49,54]. Xem xét điều này, chúng tôi tin rằng Repilot vẫn có thể cung cấp lợi thế đáng kể trong những môi trường như vậy.

Một hạn chế khác của Repilot nằm ở đánh giá. Một mặt, mặc dù đúng là sự gia tăng tỷ lệ biên dịch của Repilot có thể dẫn đến việc khám phá nhiều sửa chữa hợp lý và chính xác hơn, điều quan trọng cần lưu ý là tỷ lệ biên dịch cao hơn đáng kể không nhất thiết dẫn đến sự gia tăng tỷ lệ thuận lớn trong các sửa chữa hợp lý và chính xác. Mặt khác, Repilot chỉ được đánh giá với CodeT5 cho RQ1 và RQ2 với ngân sách lấy mẫu 5000. CodeT5 là một LLM khá "nhỏ" so với những LLM có hàng tỷ tham số. Mặc dù chúng tôi tiếp tục bao gồm InCoder-6.7B như một LLM đa tỷ tham số trong RQ4, do chi phí thời gian, chúng tôi chỉ lấy mẫu 500 lần mỗi lỗi, điều này có thể không đủ để phản ánh phân phối của các bản vá được tạo ra. Nhìn chung, phạm vi đánh giá của chúng tôi xem xét hai LLM (CodeT5 và InCoder) và một ngôn ngữ lập trình (Java) vẫn còn hẹp cho rằng Repilot là một framework tổng quát có thể được khởi tạo với bất kỳ cặp LLM và Công cụ Hoàn thiện nào cho một ngôn ngữ lập trình nào đó.

Cuối cùng, bất chấp những ví dụ chúng tôi trình bày trong bài báo, đánh giá của chúng tôi thiếu bằng chứng thực nghiệm mạnh mẽ để hỗ trợ tuyên bố rằng LLM có khó khăn trong việc tạo ra các token hiếm và cách Repilot giải quyết vấn đề. Bên cạnh đó, đánh giá của chúng tôi hạn chế ứng dụng của Repilot vào tổng hợp bản vá, mặc dù chúng tôi tuyên bố rằng Repilot có thể được áp dụng cho các tác vụ tạo mã khác. Trong tương lai, chúng tôi sẽ áp dụng và đánh giá Repilot trên các tác vụ tạo mã đa dạng hơn.

8 THREATS TO VALIDITY

Nội bộ. Chúng tôi chia sẻ cùng một threat chính đối với tính hợp lệ nội bộ với các công cụ APR trước đây trong đó chúng tôi phải kiểm tra thủ công mỗi bản vá hợp lý để xác định tính chính xác của bản vá. Chúng tôi giải quyết điều này bằng cách cẩn thận phân tích mỗi bản vá để xác định xem nó có tương đương về mặt ngữ nghĩa với bản vá nhà phát triển tham chiếu hay không. Hơn nữa, chúng tôi đã phát hành tập hợp đầy đủ các bản vá chính xác của mình để đánh giá công cộng [62].

Việc sử dụng mô hình CodeT5 của chúng tôi đặt ra một threat nội bộ khác trong đó tập dữ liệu huấn luyện mã nguồn mở của các dự án GitHub [27] có thể chồng chéo với đánh giá Defects4J của chúng tôi. Chúng tôi tuân theo công việc trước đây [66,67] và giải quyết điều này bằng cách tính toán các sửa chữa lỗi chính xác của Repilot từ Defects4J là một phần của dữ liệu huấn luyện CodeT5. Tổng cộng, 7 trên 66 và 6 trên 50 chồng chéo với dữ liệu huấn luyện trên Defects4J 1.2 và 2.0 tương ứng. Để so sánh công bằng, nếu chúng tôi loại trừ những 7 và 6 lỗi này và so sánh chúng với các công cụ đường cơ sở trước đây trên các lỗi còn lại, chúng tôi vẫn có thể đạt được số lượng sửa lỗi cao nhất ở 59 và 44 (đường cơ sở tốt nhất ở 45 và 29). Cùng threat áp dụng cho việc sử dụng InCoder, nhưng vì dữ liệu huấn luyện chi tiết của nó không được tiết lộ, chúng tôi không thể giải quyết vấn đề này một cách rõ ràng. Để giảm thiểu vấn đề, chúng tôi chỉ đánh giá InCoder trong RQ4, trong đó tất cả các biến thể đối mặt với cùng một rò rỉ tiềm năng.

Hơn nữa, triển khai sửa đổi của chúng tôi về công cụ hoàn thiện đòi hỏi kiểm tra thủ công để đảm bảo thuộc tính tính đúng đắn. Trong thực tế, đây là một cơ sở tin cậy đáng kể có thể giới thiệu false positive trong quá trình loại bỏ. Tuy nhiên, định lý của chúng tôi vẫn cung cấp một đảm bảo một phần và có thể giải thích không đúng đắn. Đồng thời, kết quả đánh giá của chúng tôi biện minh cho các tuyên bố của chúng tôi và chứng minh tính thực tiễn của Repilot.

Cuối cùng, trong đánh giá của chúng tôi, chúng tôi tuân theo quy ước được sử dụng trong công việc trước đây để trực tiếp báo cáo kết quả sửa lỗi mà không tái tạo chúng, điều này đặt ra một threat đối với độ tin cậy của kết quả. Trong khi đó, chúng tôi chỉ chạy mỗi thí nghiệm một lần, điều này có thể giới thiệu thêm thiên vị thống kê.

Bên ngoài. Threat chính đối với tính hợp lệ bên ngoài đến từ bộ dữ liệu đánh giá của chúng tôi trong đó hiệu suất của Repilot có thể không tổng quát hóa cho các bộ dữ liệu khác. Để giải quyết điều này, chúng tôi so sánh Repilot với các đường cơ sở tối tân trên cả Defects4J 1.2 và 2.0 để cho thấy rằng hiệu suất được duy trì trên cả hai phiên bản. Để giải quyết thêm điều này, chúng tôi dự định đánh giá Repilot trên các bộ dữ liệu APR bổ sung cũng trên các ngôn ngữ lập trình khác nhau.

9 KẾT LUẬN

Chúng tôi đề xuất Repilot — phương pháp APR đầu tiên kết hợp việc sử dụng trực tiếp LLM (ví dụ: CodeT5 và InCoder) với hướng dẫn tức thì được cung cấp bởi Công cụ Hoàn thiện. Trong quá trình tạo token tự hồi quy, Repilot truy vấn Công cụ Hoàn thiện không chỉ để loại bỏ các token không hợp lệ mà còn để chủ động hoàn thành chương trình một phần được tạo ra hiện tại, do đó giảm không gian tìm kiếm của LLM. Đánh giá của chúng tôi trên một tập con của bộ dữ liệu Defects4J 1.2 và 2.0 được nghiên cứu rộng rãi cho thấy Repilot có thể đạt được kết quả tối tân. Hơn nữa, Repilot, thông qua việc sử dụng Công cụ Hoàn thiện, có thể tạo ra nhiều bản vá hợp lệ và có thể biên dịch hơn so với các công cụ trước đây với chi phí phụ tối thiểu so với việc sử dụng trực tiếp LLM cho APR.

SẴN SANG DỮ LIỆU

Chúng tôi đã mở nguồn Repilot, có thể truy cập trên GitHub tại https://github.com/ise-uiuc/Repilot. Ngoài ra, một artifact bất biến cho Repilot có sẵn công khai trên Zenodo [62].

LỜI CẢM ƠN

Chúng tôi cảm ơn tất cả các nhà đánh giá vì những nhận xét sâu sắc của họ. Chúng tôi cũng cảm ơn Yifeng Ding vì cuộc thảo luận hữu ích của anh ấy về công việc này. Công việc này được hỗ trợ một phần bởi các tài trợ NSF CCF-2131943 và CCF-2141474, cũng như Kwai Inc.

TÀI LIỆU THAM KHẢO

[Phần tài liệu tham khảo được dịch nguyên văn với định dạng gốc]

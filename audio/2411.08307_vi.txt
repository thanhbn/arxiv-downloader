# Perceiver S: Một Perceiver Đa Quy Mô với Phân Đoạn Hiệu Quả
# cho Việc Tạo Nhạc Biểu Tượng Biểu Cảm Dài Hạn

Yungang Yi∗, Weihua Li∗, Matthew Kuo∗, Quan Bai†
∗Auckland University of Technology, Auckland, New Zealand
Email: luke@waye.com, weihua.li@aut.ac.nz, matthew.kuo@aut.ac.nz
†University of Tasmania, Tasmania, Australia
Email: quan.bai@utas.edu.au

Tóm tắt—Việc tạo nhạc dựa trên AI đã tiến bộ đáng kể trong những năm gần đây. Tuy nhiên, việc tạo ra nhạc biểu tượng vừa có cấu trúc dài vừa biểu cảm vẫn là một thách thức đáng kể. Trong bài báo này, chúng tôi đề xuất Perceiver S (Segmentation và Scale), một kiến trúc mới được thiết kế để giải quyết vấn đề này bằng cách tận dụng cả Phân Đoạn Hiệu Quả và cơ chế attention Đa Quy Mô. Phương pháp của chúng tôi tăng cường việc tạo nhạc biểu tượng bằng cách đồng thời học các phụ thuộc cấu trúc dài hạn và chi tiết biểu cảm ngắn hạn. Bằng cách kết hợp cross-attention và self-attention trong thiết lập Đa Quy Mô, Perceiver S nắm bắt được cấu trúc âm nhạc tầm xa trong khi bảo tồn sự đa dạng âm nhạc. Mô hình được đề xuất đã được đánh giá sử dụng bộ dữ liệu Maestro và đã chứng minh cải thiện trong việc tạo ra nhạc có độ dài thông thường với các sắc thái biểu cảm. Các demo dự án và các mẫu nhạc được tạo có thể được truy cập thông qua liên kết: https://perceivers.github.io.

Thuật ngữ chỉ mục—Tạo Nhạc Biểu Tượng, Cấu Trúc Dài Hạn, Mô Hình Transformer, Cross-Attention, Self-Attention, PerceiverS, Phân Đoạn Hiệu Quả, Attention Đa Quy Mô

## I. GIỚI THIỆU

Những tiến bộ gần đây trong việc tạo nhạc dựa trên AI, đặc biệt trong các mô hình tạo âm thanh như AudioLDM [1], MusicGen [2], và Jen-1 [3], đã chứng minh tiến bộ đáng kể có khả năng tạo ra nhạc nghe rất tự nhiên. So với việc tạo âm thanh, nhạc biểu tượng cung cấp một mức độ trừu tượng cao hơn, làm cho việc học máy dễ dàng hơn trong việc nắm bắt các đặc tính âm nhạc sâu sắc hơn và hiểu biết. Nhạc biểu tượng đóng vai trò quan trọng trong lĩnh vực tạo nhạc, đặc biệt do tính chất có thể chỉnh sửa của nó. Điều này cho phép các thao tác như cắt và sắp xếp lại các phần khác nhau hoặc thay thế âm sắc nhạc cụ, cho phép sự tham gia của con người trong việc sản xuất nhạc chất lượng cao trong giai đoạn xử lý sau.

Tuy nhiên, việc tạo nhạc biểu tượng đối mặt với hai thách thức chính. Thứ nhất, các bộ dữ liệu biểu cảm nhất, được ghi từ các buổi biểu diễn trực tiếp và phòng thu, hiếm khi được sử dụng so với các bộ dữ liệu file MIDI được tạo thủ công. Lý do chính là chúng thiếu các chú thích chi tiết, khiến việc mô hình học các cấu trúc phức tạp của chúng trở nên khó khăn hơn. Hơn nữa, do hạn chế tính toán, các mô hình trước đây không thể nắm bắt đầy đủ ngữ cảnh của toàn bộ tác phẩm âm nhạc. Các kỹ thuật như phân khúc và lượng tử hóa thường được sử dụng để giảm độ phức tạp tính toán, dẫn đến mất mát các chi tiết âm nhạc quan trọng và khiến việc mô hình nắm bắt cấu trúc đầy đủ của một tác phẩm trở nên khó khăn. Thứ hai, các phương pháp khác sử dụng biểu diễn cấu trúc trừu tượng làm điều kiện cho các tác vụ tạo nhạc đã cho phép tạo ra nhạc có cấu trúc. Tuy nhiên, các phương pháp như vậy phụ thuộc nhiều vào kỹ thuật thiết kế đặc trưng thủ công. Mục tiêu của chúng tôi là thiết kế và phát triển một mô hình có khả năng học các phụ thuộc tầm xa trong nhạc mà không dựa vào các chú thích cấu trúc rõ ràng.

Sự xuất hiện của các công nghệ Transformer Attention, như Perceiver AR [4], đã làm cho việc truy cập các phụ thuộc ngữ cảnh dài hơn nhiều trở nên khả thi. Nó cho phép việc học đồng thời cấu trúc âm nhạc và tạo ra các buổi biểu diễn biểu cảm. Perceiver AR đã chứng minh khả năng attention đến độ dài ngữ cảnh lên tới 32,768 token sử dụng bộ dữ liệu Maestro [5], nơi truy vấn trong cross-attention attention đến các cặp key/value dài hơn đáng kể [4]. Tuy nhiên, mặt nạ nhân quả, khi được áp dụng với phân đoạn chuỗi đầu vào mặc định, không hoàn toàn che giấu các token mà không nên được nhìn thấy trong quá trình huấn luyện và tạo tự hồi quy, điều này cuối cùng làm giảm chất lượng của nhạc được tạo. Ngoài ra, khi sử dụng ngữ cảnh siêu dài như một điều kiện duy nhất, mô hình có xu hướng tạo ra các đoạn lặp lại giống hệt hoặc tương tự khi độ dài chuỗi tăng do vấn đề tương tự cao trong ngữ cảnh của các token lân cận, dẫn đến xu hướng tự tương quan token cao [6].

Trong bài báo này, chúng tôi đề xuất Perceiver S, một mô hình mới giải quyết vấn đề masking nhân quả bằng cách kết hợp Phân Đoạn Hiệu Quả. Ngoài ra, Perceiver S sử dụng attention Đa Quy Mô để giảm thiểu vấn đề tự tương quan token cao phát sinh từ việc chỉ dựa vào các phụ thuộc tầm xa. Cụ thể, bằng cách điều chỉnh phân đoạn chuỗi đầu vào để bắt đầu từ đoạn đầu với mặt nạ nhân quả hiệu quả và tăng mạnh độ dài đoạn lên tới độ dài chuỗi đầu vào tối đa, chúng tôi giải quyết các hạn chế học tập gây ra bởi mặt nạ nhân quả trong Perceiver AR [4]. Ngoài ra, bằng cách kết hợp các mặt nạ Đa Quy Mô qua nhiều lớp cross-attention, mô hình xem xét cả attention siêu dài và ngắn đồng thời. Phương pháp này giải quyết hạn chế trong Perceiver AR, mà chỉ tập trung vào attention tầm xa [4]. Khác với Perceiver AR, phương pháp của chúng tôi tăng cường việc tạo nhạc biểu tượng bằng cách hiệu quả nắm bắt các phụ thuộc cấu trúc dài hạn trong khi đồng thời tập trung vào các biến thể ngắn hạn. Thông qua cải thiện phân đoạn và cơ chế attention đa quy mô, Perceiver S tạo ra nhạc mạch lạc, đa dạng mà không dựa vào các chú thích cấu trúc rộng rãi. Các thí nghiệm mở rộng đã được tiến hành để đánh giá hiệu suất của Perceiver S được đề xuất. Kết quả thí nghiệm chứng minh cải thiện trung bình 40% trong Overlap Area khi đo so với bộ dữ liệu huấn luyện gốc, làm nổi bật một lợi thế đáng kể của phương pháp của chúng tôi so với Perceiver AR [4] trong việc tạo ra nhạc biểu tượng chất lượng cao.

## II. CÁC CÔNG TRÌNH LIÊN QUAN

### A. Nắm Bắt Tính Biểu Cảm Âm Nhạc

Công trình sớm nhất quan trọng nhất trong lĩnh vực này đến từ nhóm của Google, đã giới thiệu Music Transformer [7], một mô hình có khả năng tạo ra nhạc piano biểu cảm sử dụng bộ dữ liệu Piano-e-Competition, sau này được biết đến với tên Maestro dataset [5]. Vì mô hình này được huấn luyện sử dụng các file MIDI được ghi từ các buổi biểu diễn piano trực tiếp, nó đã sử dụng cơ chế attention để tập trung vào ngữ cảnh của tất cả các token được tạo trước đó khi dự đoán token tiếp theo, cho phép nó tạo ra nhạc rất chi tiết và biểu cảm.

Tuy nhiên, do độ phức tạp bậc hai O(n²) của cơ chế attention Transformer, nó chỉ có thể tạo ra nhạc kéo dài vài chục giây, chứ không phải vài phút. Không giống Music Transformer [7], ít mô hình khác sử dụng bộ dữ liệu biểu diễn, chủ yếu do thiếu chú thích liên quan đến các loại bộ dữ liệu này và các hạn chế tính toán trong việc xử lý chúng.

1) Lựa Chọn Bộ Dữ Liệu: Một yếu tố chính trong việc tạo ra nhạc chất lượng sản xuất nằm ở việc lựa chọn bộ dữ liệu. Bộ dữ liệu Maestro [5], bao gồm các buổi biểu diễn thực của con người, cung cấp nhạc ghi âm động và biểu cảm. Các bộ dữ liệu được ghi từ các buổi biểu diễn trực tiếp rất hiếm, nhưng có khá nhiều bộ dữ liệu Automatic Music Transcription (AMT), bao gồm GiantMIDI [8], ATEPP [9], PiJAMA [10], và các bộ khác. Các mô hình tiên tiến đã được phát triển, từ Hawthorne [11] đến Kong [8], chuyển đổi âm thanh thành file MIDI. Những tiến bộ này đã làm cho việc sử dụng một lượng lớn nhạc âm thanh đã ghi để huấn luyện mô hình trở nên khả thi, vì việc phát triển các mô hình nhạc biểu tượng đã lâu bị hạn chế bởi tính khả dụng hạn chế của các bộ dữ liệu.

Các bộ dữ liệu MIDI được tạo thủ công, như LAKH [12], cung cấp thông tin được con người chú thích có giá trị, ví dụ như nhịp, thanh, và cụm từ, cho phép phân đoạn linh hoạt và trích xuất đặc trưng phong phú hơn nhưng thiếu các sắc thái biểu cảm được tìm thấy trong các buổi biểu diễn trực tiếp, như động lực, biến thể tempo, và các thay đổi thời gian tinh tế. Các nỗ lực khác, như ASAP [13] với việc sửa chữa nhịp có sự hỗ trợ của con người, và những tiến bộ trong theo dõi nhịp tự động, như Beat This! [14], nhằm mang chú thích đến các bộ dữ liệu được ghi trực tiếp, mặc dù các hạn chế về độ chính xác vẫn tồn tại thách thức.

2) Hạn Chế Tính Toán: Mặc dù việc sử dụng các bộ dữ liệu MIDI được ghi từ các buổi biểu diễn trực tiếp và phòng thu âm nhạc cho phép tạo ra nhạc với các chi tiết phong phú và biểu cảm, việc tạo ra nhạc như vậy trong thời gian dài vẫn là một thách thức. Điều này chủ yếu do sự tăng đáng kể về tài nguyên tính toán cần thiết để xử lý các phụ thuộc ngữ cảnh tầm xa. Hầu như tất cả các mô hình hiện tại, ví dụ như Music Transformer, sử dụng các chiến lược như phân khúc và lượng tử hóa để giảm độ dài chuỗi token và kích thước từ vựng [7]. Trong khi các phương pháp này giúp giảm gánh nặng tính toán, chúng cũng hạn chế khả năng của mô hình trong việc nắm bắt các phụ thuộc siêu dài và làm tổn hại các chi tiết hiệu suất biểu cảm. Như đã nêu trên trang web Music Transformer,¹ "Một số chế độ 'thất bại' bao gồm quá nhiều lặp lại, các phần thưa thớt, và các bước nhảy chói tai." Sự đánh đổi này ngăn cản việc tạo ra nhạc biểu tượng mạch lạc dài hạn hiệu quả.

### B. Nắm Bắt Tính Mạch Lạc Dài Hạn

Trong những nỗ lực học cấu trúc âm nhạc và tạo ra nhạc biểu tượng với sự mạch lạc tầm xa, các phương pháp có thể được phân loại chung thành hai loại chính, tức là những phương pháp sử dụng các đặc trưng cấu trúc rõ ràng và những phương pháp khuyến khích mô hình học các đặc trưng cấu trúc ẩn. Mỗi phương pháp được giới thiệu trong các phần con sau.

1) Đặc Trưng Cấu Trúc Rõ Ràng: Việc sử dụng rõ ràng các đặc trưng cấu trúc thường dựa vào kỹ thuật thiết kế đặc trưng thủ công và các công cụ phân tích bên ngoài. Một phương pháp phổ biến trong các mô hình này là phương pháp giống như thác nước. Thông thường, quá trình bắt đầu bằng việc tạo ra một lead sheet và sau đó sử dụng lead sheet làm điều kiện cho các tác vụ tạo tiếp theo.

MuseMorphose [15] kiểm soát rõ ràng cường độ nhịp điệu và mật độ đa âm trên cơ sở thanh bằng cách huấn luyện trên các bộ dữ liệu có chú thích thanh, cụ thể là các bộ dữ liệu LPD-17-cleansed và Pop1K7. Compose & Embellish [16] tận dụng các công cụ bên thứ ba như thuật toán skyline, độ tương tự chỉnh sửa, và các biện pháp tìm kiếm A* để trích xuất giai điệu và xác định các mẫu cấu trúc, cho phép mô hình tạo ra nhạc với tổ chức cấu trúc được tăng cường. Tuy nhiên, nó vẫn dựa vào các bộ dữ liệu được chú thích thanh để huấn luyện. Rule-Guided Diffusion [17] sử dụng mật độ nốt và hợp âm để điều kiện tạo, tạo ra các đoạn âm nhạc có cấu trúc. Việc huấn luyện của nó không dựa vào một bộ dữ liệu được chú thích mà đúng hơn là sử dụng bộ dữ liệu biểu diễn, Maestro. Tuy nhiên, nó chỉ tạo ra các tác phẩm âm nhạc ngắn thay vì các đoạn có độ dài đầy đủ. Whole-Song Hierarchical Generation [18] có khả năng tạo ra các tác phẩm hoàn chỉnh, có cấu trúc đầy đủ. Nó sử dụng phương pháp đa giai đoạn, sử dụng các chú thích từ bộ dữ liệu POP909 [19], bao gồm thông tin hợp âm và các track riêng biệt cho giai điệu, cầu nối, và phần đệm, để tạo ra các yếu tố có cấu trúc như form, lead sheet, và accompaniment, cuối cùng tạo ra một tác phẩm hoàn chỉnh, có độ dài đầy đủ.

2) Đặc Trưng Cấu Trúc Ẩn: Một phương pháp quan trọng khác bao gồm việc cho phép mô hình học thông tin cấu trúc của nhạc một cách ẩn. Phương pháp này có lợi thế là tổng quát hóa tốt hơn, vì nó không dựa vào kỹ thuật thiết kế đặc trưng thủ công. Tuy nhiên, nhược điểm của nó nằm ở sự khó khăn tăng lên cho mô hình trong việc nắm bắt các đặc trưng cấu trúc phức tạp của nhạc.

MusicVAE [20] sử dụng RNN hai chiều và Conductor RNN để tạo ra các vector ẩn mỗi thanh được giải mã thành các nốt riêng lẻ, tập trung vào cấu trúc cấp thanh thông qua huấn luyện trên các bộ dữ liệu chứa chú thích thanh, có thể không áp dụng được cho nhạc được biểu diễn tự do. Museformer [21] áp dụng attention Transformer thưa bằng cách hoàn toàn attention đến tất cả các token trong các thanh được chọn và các vector tóm tắt của tất cả các thanh trước đó, cho phép nó nắm bắt ngữ cảnh tầm xa với tài nguyên tính toán hạn chế. Tuy nhiên, nó vẫn tận dụng các chú thích thanh của bộ dữ liệu Lakh MIDI [12], không thể được sử dụng với các bộ dữ liệu biểu diễn không được chú thích.

### C. Các Giải Pháp SOTA với Phụ Thuộc Dài Hạn Trên Bộ Dữ Liệu Biểu Diễn

Mô hình Perceiver AR [4] từ DeepMind đã là một nguồn cảm hứng đáng kể. Nó kết hợp các cơ chế cross-attention và self-attention, cho phép mô hình attention đến các chuỗi với lên tới hàng chục nghìn token. Giống như Perceiver [22] và Perceiver IO [23], Perceiver AR [4] sử dụng một truy vấn ngắn hơn trong cơ chế cross-attention của nó để attention đến các chuỗi dài hơn nhiều, từ đó giảm thiểu chi phí tính toán. Như đã nêu trong bài báo, phương pháp này cho phép mô hình attention đến lên tới 32,768 token khi được huấn luyện trên bộ dữ liệu Maestro [5], cung cấp ngữ cảnh dài hơn đáng kể so với các mô hình như Transformer-XL [24]. Khả năng xử lý hiệu quả dữ liệu ngữ cảnh tầm xa này rất quan trọng để học cấu trúc của toàn bộ tác phẩm âm nhạc.

Tuy nhiên, Perceiver AR tận dụng N token cuối cùng làm Query với mặt nạ nhân quả hạn chế, và việc huấn luyện với teacher-forcing trên các chuỗi dài đã dẫn đến chất lượng tạo thấp hơn. Hơn nữa, chúng tôi quan sát thấy rằng việc chỉ dựa vào ngữ cảnh dài, đặc biệt là siêu dài, đã dẫn đến các đoạn lặp lại trong phần sau của nội dung được tạo.

Mặc dù có tiến bộ đáng kể, nghiên cứu hiện tại vẫn chưa giải quyết hoàn toàn thách thức tạo ra nhạc với cả các phụ thuộc dài hạn và chi tiết biểu diễn biểu cảm, vì hầu hết các phương pháp hoặc dựa nhiều vào các quy trình thủ công hoặc đối mặt với các hạn chế hiệu suất do độ dài cửa sổ ngữ cảnh bị hạn chế. Trong khi Perceiver AR đại diện cho phương pháp tiên tiến nhất để tạo ra nhạc với các phụ thuộc dài hạn, vẫn còn những lĩnh vực cần cải thiện thêm.

## III. KIẾN THỨC CHUẨN BỊ

Trong phần này, chúng tôi giới thiệu các khái niệm cơ bản và thách thức chính cần thiết để hiểu mô hình được đề xuất của chúng tôi. Chúng tôi xem xét cơ chế hoạt động của cross-attention trong Perceiver AR, vai trò của mặt nạ nhân quả của nó, và các cân nhắc chính khi sử dụng các chuỗi siêu dài làm ngữ cảnh để tạo token.

### A. Tiền Xử Lý Chuỗi Đầu Vào

Để chuỗi hoàn chỉnh là X={x₁, x₂, ..., xₗ}, trong đó l là tổng độ dài của toàn bộ chuỗi nhạc, và m là độ dài đầu vào tối đa, đại diện cho chuỗi dài nhất mà mô hình có thể attention trong một lần. Độ dài truy vấn được ký hiệu là n, đại diện cho số lượng token mà mô hình sử dụng để truy vấn ngữ cảnh, và thông thường, n ≤ m.

Trong phương pháp Transformer điển hình, một đoạn có độ dài m được trích xuất từ chuỗi một cách ngẫu nhiên. Cụ thể, chúng ta chọn một chỉ số bắt đầu s ∈ [1, l-m+1], và đoạn được sử dụng để huấn luyện, ký hiệu là X̂, được định nghĩa trong (1).

X̂ = {xₛ, xₛ₊₁, ..., xₛ₊ₘ₋₁}                                    (1)

Phương pháp này tạo ra các cửa sổ có độ dài cố định chồng lấp để huấn luyện, như được định nghĩa trong (2):

{x₁, x₂, ..., xₘ}, {x₂, x₃, ..., xₘ₊₁}, ...                    (2)

Các chuỗi này sẽ được xử lý bằng mặt nạ nhân quả.

1) Masking Nhân Quả trong Transformers Điển Hình: Trong một transformer điển hình với masking nhân quả, mục tiêu là đảm bảo rằng khi tạo token i, mô hình không attention đến các token j trong đó j > i. Mặt nạ nhân quả cho điều này thường được biểu diễn bởi (3):

Mᵢⱼ = {
    0       nếu i ≥ j
    -∞      nếu i < j                                          (3)

Ma trận này được thêm vào điểm attention QKᵀ (như được định nghĩa trong (6)) để tất cả các vị trí j > i (tức là các token tương lai) được che giấu bằng cách đặt điểm attention của chúng thành -∞, đảm bảo chúng không ảnh hưởng đến việc tạo token hiện tại.

Ví dụ, xem xét trường hợp truy vấn có độ dài n = 5 và key/value có độ dài m = 5. Mặt nạ nhân quả mong đợi (Vanilla Transformer) như sau trong (4):

M = [
    0    -∞   -∞   -∞   -∞
    0     0   -∞   -∞   -∞
    0     0    0   -∞   -∞
    0     0    0    0   -∞
    0     0    0    0    0
], M ∈ R⁵ˣ⁵                                                   (4)

Mặt nạ này đảm bảo rằng token truy vấn thứ ba chỉ attention đến ba token đầu tiên.

2) Vấn Đề Mặt Nạ Nhân Quả của Perceiver AR: Trong Perceiver AR [4], tình huống khác vì độ dài token truy vấn n nhỏ hơn nhiều so với độ dài key và value m. Cụ thể, mặt nạ nhân quả chỉ hoạt động trên phần cuối của chuỗi ngữ cảnh, tương đương với độ dài của truy vấn n, nhưng không che giấu các token xảy ra trước đó. Điều này dẫn đến một số token trước độ dài truy vấn được nhìn thấy trong quá trình huấn luyện, điều này không phải là vấn đề cho việc tạo ngoại trừ việc đoạn từ x₁ đến xₘ₋ₙ không được mô hình học đúng cách.

Hãy ký hiệu chuỗi key và value tương ứng là K và V, và độ dài truy vấn là n, trong khi độ dài ngữ cảnh (keys/values) là m, trong đó m > n. Ma trận mặt nạ attention M trong Perceiver AR có thể được biểu diễn như sau:

Mᵢⱼ = {
    0       nếu j ≤ m-n+1
    -∞      nếu j-i > m-n+1
    0       nếu i > n

Dưới đây cho thấy một ví dụ về mặt nạ nhân quả được sử dụng trong Perceiver AR với n = 5 (độ dài truy vấn) và m = 10 (độ dài ngữ cảnh) như được minh họa trong (5):

M = [
    0  0  0  0  0  0  -∞  -∞  -∞  -∞
    0  0  0  0  0  0   0  -∞  -∞  -∞
    0  0  0  0  0  0   0   0  -∞  -∞
    0  0  0  0  0  0   0   0   0  -∞
    0  0  0  0  0  0   0   0   0   0
], M ∈ R⁵ˣ¹⁰                                                  (5)

Do đó, mô hình có thể "nhìn trộm" các token trước độ dài truy vấn vì chúng không được che giấu hoàn toàn, cho phép nó attention đến các token trước ngữ cảnh dự định trong quá trình huấn luyện. Việc che giấu một phần này dẫn đến sự không khớp giữa huấn luyện và tạo tự hồi quy, làm giảm chất lượng của nhạc được tạo.

Lưu ý rằng vấn đề này chủ yếu ảnh hưởng đến việc tạo không điều kiện, nơi mô hình tạo nhạc mà không có bất kỳ lời nhắc hoặc primer cụ thể nào, khiến nó nhạy cảm hơn với sự không nhất quán giữa ngữ cảnh huấn luyện và tạo. Trong việc tạo có điều kiện, nơi mô hình bắt đầu với một chuỗi primer hoặc lời nhắc ban đầu, việc sử dụng primer với độ dài gần với phần không được che giấu trong quá trình huấn luyện có thể giúp bảo tồn chất lượng tạo và ngăn chặn sự suy giảm.

3) Tính Toán cho Attention với Mặt Nạ: Cơ chế attention với mặt nạ nhân quả được tính như sau [25]:

Attention(Q, K, V) = softmax((QKᵀ + M)/√dₖ)V                  (6)

### B. Ngữ Cảnh Siêu Dài trong Tạo Tự Hồi Quy

Tương tự như hiện tượng các đoạn lặp lại thường được quan sát trong việc tạo ngôn ngữ tự nhiên như được mô tả trong [26], việc chỉ dựa vào ngữ cảnh siêu dài trong các mô hình tự hồi quy có thể dẫn đến các chuỗi được tạo chứa các đoạn ngắn lặp lại quá dài, đặc biệt khi độ dài chuỗi tăng. Cho rằng xác suất tạo các token xₜ và xₜ₋ₖ (trong đó k là một số nguyên nhỏ) tương ứng như được hiển thị trong (7) và (8):

p(xₜ|x₁, x₂, ..., xₜ₋₁)                                      (7)

p(xₜ₋ₖ|x₁, x₂, ..., xₜ₋ₖ₋₁)                                (8)

Khi t tăng, các ngữ cảnh [x₁, x₂, ..., xₜ₋ₖ₋₁] và [x₁, x₂, ..., xₜ₋₁] trở nên gần như giống hệt do ngữ cảnh siêu dài. Do đó, các phân phối có điều kiện p(xₜ|x₁, x₂, ..., xₜ₋₁) và p(xₜ₋ₖ|x₁, x₂, ..., xₜ₋ₖ₋₁) gần như không thể phân biệt được, dẫn đến KL divergence gần bằng không:

D_KL(p(xₜ|x₁, x₂, ..., xₜ₋₁)||p(xₜ₋ₖ|x₁, x₂, ..., xₜ₋ₖ₋₁)) ≈ 0

Sự tương tự này trong các phân phối có điều kiện có nghĩa là mô hình có khả năng tạo ra các token tương tự trong các bước gần nhau, vì các phân phối xác suất điều chỉnh xₜ và xₜ₋ₖ trở nên gần như giống hệt. Do đó, xác suất của xₜ = xₜ₋ₖ tăng, dẫn đến các đoạn ngắn lặp lại.

Khi các token lặp lại như vậy được tạo qua nhiều bước thời gian, chuỗi thể hiện tự tương quan token cao. Về mặt toán học, tự tương quan token tại lag k ∈ {1,2, ..., T-1} cho chuỗi X = {x₁, x₂, ..., xₜ} có thể được biểu diễn như [6]:

ρₖ(X) = (Σᵀₜ₌ₖ₊₁(xₜ - x̄)(xₜ₋ₖ - x̄))/(Σᵀₜ₌₁(xₜ - x̄)²)       (9)

trong đó x̄ đại diện cho trung bình của chuỗi X. Khi các giá trị tại các bước gần nhau thể hiện sự tương tự cao, như được gợi ý bởi các phân phối có điều kiện gần như giống hệt, thuật ngữ (xₜ - x̄)(xₜ₋ₖ - x̄) trong (9) trở nên lớn, dẫn đến tự tương quan token cao tại lag k.

Trong quá trình tạo, các giá trị giống hệt không được tạo ra tại các bước gần nhau để tránh các hình phạt huấn luyện. Trên thực tế, ngữ cảnh tương tự của các token lân cận khiến quá trình tạo tạo ra các token giống hệt hoặc tương tự tại các bước gần nhau, dẫn đến xác suất cao hơn của việc tạo ra các đoạn ngắn lặp lại khi chuỗi trở nên dài hơn.

## IV. PHƯƠNG PHÁP ĐỀ XUẤT

Mô hình được đề xuất, Perceiver S, là một phương pháp kép của Phân Đoạn Hiệu Quả và attention Đa Quy Mô để giải quyết các hạn chế trong việc tạo nhạc biểu tượng. Xây dựng dựa trên các điểm mạnh của Perceiver AR [4] và giới thiệu các cơ chế để xử lý cả các phụ thuộc ngắn và siêu dài, Perceiver S (Segmentation và Scale) đạt được sự mạch lạc và biểu cảm lớn hơn trong nhạc được tạo.

Vì Perceiver AR cung cấp khả năng truy cập các ngữ cảnh cực kỳ dài, chúng tôi cố gắng sử dụng Perceiver AR như một mô hình cơ sở để học toàn bộ tác phẩm âm nhạc và đánh giá chất lượng tạo của nó. Mục tiêu của chúng tôi cho việc tạo nhạc biểu tượng là đạt được sự mạch lạc dài hạn trong khi duy trì sự đa dạng trong các đoạn ngắn hơn. Hơn nữa, chúng tôi mong đợi mô hình học các mẫu tương tự như sáng tác của con người, với sự lặp lại và phát triển. Các bước chi tiết của phương pháp và cải thiện của chúng tôi được trình bày trong các phần con sau.

### A. Cải Thiện Mô Hình để Học Hiệu Quả Các Chuỗi Siêu Dài

Phần này phác thảo một chiến lược tiền xử lý dữ liệu được thiết kế để nâng cao chất lượng tạo token trong các mô hình tự hồi quy. Như đã thảo luận trong phần trước, mặt nạ nhân quả của Perceiver AR có hạn chế trong việc bao phủ toàn bộ chuỗi đầu vào, làm cho việc thực hiện các điều chỉnh tiền xử lý trước khi đưa dữ liệu vào mô hình trở nên cần thiết.

Chúng tôi đặt độ dài ngữ cảnh tối đa là 32,768 token. Dựa trên việc triển khai gốc của Perceiver AR², chúng tôi cắt bộ dữ liệu một cách ngẫu nhiên. Trong phương pháp này, một điểm bắt đầu ngẫu nhiên được chọn giữa 0 và (độ dài chuỗi - độ dài đầu vào tối đa + 1), từ đó một đoạn có độ dài bằng độ dài đầu vào tối đa được lấy.

[Hình 1 mô tả so sánh giữa phương pháp tiền xử lý dữ liệu gốc và Perceiver S]

Phần trên của Hình 1 minh họa tiền xử lý chuỗi đầu vào gốc của mô hình cơ sở. Cụ thể, mô hình cơ sở phân đoạn chuỗi đầu vào sử dụng độ dài đầu vào tối đa làm kích thước cửa sổ, để lại phần đầu của chuỗi không được bao phủ bởi mặt nạ nhân quả. Điều này dẫn đến các token ban đầu này không được sử dụng dần dần làm token xác thực trong teacher forcing, ngăn mô hình học tạo ra các token ở đầu chuỗi nằm ngoài mặt nạ.

Ngược lại, chúng tôi đề xuất một phương pháp thay thế không dựa vào việc cắt bộ dữ liệu dựa trên chuỗi đầu vào dài nhất. Thay vào đó, chúng tôi chọn ngẫu nhiên một điểm cuối để cắt giữa (độ dài truy vấn + 1) và (độ dài chuỗi + 1). Một đoạn có thể lên tới độ dài đầu vào tối đa sau đó được lấy, dẫn đến điểm cuối này (hoặc ngắn hơn cho các token gần đầu). Padding được áp dụng như trong mô hình cơ sở.

Phần dưới của Hình 1 minh họa tiền xử lý chuỗi đầu vào phân đoạn hiệu quả của Perceiver S được đề xuất. Nó bắt đầu học tạo token từ phần ban đầu của chuỗi với bao phủ mặt nạ nhân quả hiệu quả. Phương pháp này đảm bảo rằng các token từ 1 đến (m-n) trong chuỗi được bao phủ hiệu quả bởi mặt nạ nhân quả, cho phép mô hình học tạo token ở đầu chuỗi hiệu quả hơn.

Lý do cho cải thiện này là mặt nạ nhân quả của Perceiver AR [4] hoạt động trong cơ chế khối cuối, nơi nó cung cấp ngữ cảnh cho độ dài của các token đầu vào nhưng chỉ che giấu một phần trong độ dài token truy vấn. Việc huấn luyện với phân đoạn truyền thống gây ra sự không khớp giữa giai đoạn huấn luyện, nơi teacher forcing được sử dụng, và quá trình tạo tự hồi quy. Phương pháp này cho phép mô hình "nhìn trộm" các token không mong muốn trong quá trình huấn luyện, điều này làm giảm chất lượng tạo trong quá trình suy luận khi các token như vậy không có sẵn để tham khảo.

Kết quả thí nghiệm (trong phần Thí nghiệm và Kết quả) sẽ cho thấy rằng cải thiện này trong tiền xử lý dữ liệu có tác động đáng kể đến hiệu suất.

### B. Cải Thiện Thêm Mô Hình để Tạo Nhạc với Cả Tính Mạch Lạc và Đa Dạng

Sau khi áp dụng các ngữ cảnh siêu dài trong việc tạo tự hồi quy, chúng tôi nhằm kết hợp các điểm mạnh của cả tính nhất quán và đa dạng, cho phép Perceiver S được đề xuất tạo ra nhạc mà không có xu hướng về các đoạn lặp lại gây ra bởi việc chỉ attention đến các ngữ cảnh tầm xa.

Cơ chế cross-attention Đa Quy Mô được áp dụng trong Perceiver S được đề xuất, mặc dù có phần tương tự với khái niệm của Museformer [21], nhưng về cơ bản là khác biệt. Nó giới thiệu nhiều lớp attention với các quy mô khác nhau của độ dài attention, được thiết kế để cân bằng sự tập trung vào cả ngữ cảnh dài và ngắn, từ đó tăng cường đa dạng và giảm xu hướng lặp lại.

Hình 2 minh họa Cơ chế Cross-Attention Đa Quy Mô của Perceiver S. Cụ thể, trong cross-attention đa lớp, các token từ đầu chuỗi được che giấu bởi các quy mô khác nhau, và các đầu ra kết quả được kết hợp trước khi được đưa vào lớp self-attention. Phương pháp này cho phép mô hình kết hợp cross-attention ở nhiều quy mô đồng thời.

Hai lớp cross-attention được triển khai. Một lớp hoạt động mà không có mặt nạ quy mô, trong khi lớp thứ hai áp dụng mặt nạ quy mô che giấu tất cả các token trước 1,024 token cuối cùng.

Đầu ra của các lớp cross-attention được kết hợp sử dụng phương pháp cascade. Phương pháp cascade đưa đầu ra từ lớp đầu tiên trực tiếp làm đầu vào cho lớp thứ hai, cho phép mỗi lớp tinh chỉnh và xây dựng dựa trên đầu ra của lớp trước đó.

[Hình 2 mô tả Cơ chế Cross-Attention Nhân Quả Đa Quy Mô của Perceiver S]

## V. CHI TIẾT KỸ THUẬT

Trong phần này, chúng tôi trình bày các chi tiết kỹ thuật, bao gồm công thức toán học và giải thích kỹ thuật của phương pháp được đề xuất của chúng tôi, Perceiver S, được thiết kế cho việc tạo nhạc biểu tượng. Dựa trên những cải thiện đối với Perceiver AR, mô hình của chúng tôi giới thiệu hai đổi mới chính, tức là Phân Đoạn Hiệu Quả cho các chuỗi đầu vào và cơ chế cross-attention Đa Quy Mô. Chi tiết được trình bày trong các phần sau.

### A. Phân Đoạn Hiệu Quả

Để giải quyết sự không khớp giữa huấn luyện và tạo tự hồi quy, chúng tôi đề xuất một phương pháp phân đoạn mới được căn chỉnh với cơ chế mặt nạ nhân quả, dù sử dụng lấy mẫu ngẫu nhiên hay tuần tự, nhấn mạnh các chuỗi ngữ cảnh ngắn hơn, dần dần xây dựng lên độ dài đầu vào tối đa.

Để chuỗi hoàn chỉnh là X = {x₁, x₂, ..., xₗ}, trong đó l biểu thị tổng độ dài của toàn bộ chuỗi, m là độ dài đầu vào tối đa mà mô hình có thể attention trong một lần, và n tham chiếu đến độ dài truy vấn trong đầu vào đó. Các chuỗi đầu vào được sử dụng để huấn luyện, ký hiệu là X̂, được tạo như sau trong Phương trình (10):

X̂ᵢ:ⱼ = {xᵢ, xᵢ₊₁, ..., xⱼ}, trong đó i ≤ j ≤ i+m-1              (10)

Ở đây, i là một vị trí bắt đầu được chọn trong chuỗi, và j là vị trí kết thúc sao cho độ dài j-i+1 không vượt quá độ dài đầu vào tối đa m.

Khi truy cập dữ liệu từ bộ dữ liệu, thay vì sử dụng các chuỗi có độ dài cố định với độ dài đầu vào tối đa, chúng tôi dần dần trích xuất các chuỗi bằng cách tăng độ dài ngữ cảnh từ n lên m. Bằng cách này, tập huấn luyện bao gồm các tiền tố ngày càng lớn hơn của chuỗi, như được hiển thị trong Phương trình (11):

{x₁, x₂, ..., xₙ}, {x₁, x₂, ..., xₙ₊₁}, ..., {x₁, x₂, ..., xₘ}    (11)

Sau khi đạt đến độ dài ngữ cảnh đầy đủ m, chúng tôi tiếp tục phân đoạn từ các vị trí bắt đầu khác nhau trong khi bảo tồn độ dài đầu vào tối đa cho mỗi chuỗi, tạo ra các đoạn như trong Phương trình (12):

X̂₂:ₘ₊₁ = {x₂, x₃, ..., xₘ₊₁},
X̂₃:ₘ₊₂ = {x₃, x₄, ..., xₘ₊₂},
...                                                             (12)

Trong thực tế, các đoạn bộ dữ liệu được chọn ngẫu nhiên từ các đoạn được định nghĩa này. Đối với việc truy xuất đoạn tuần tự, phương pháp bắt đầu với các tiền tố ngày càng dài hơn, như được hiển thị trong Phương trình (13):

{x₁, x₂, ..., x₁·ₙ}, {x₁, x₂, ..., x₂·ₙ}, ..., {x₁, x₂, ..., xₖ·ₙ} trong đó k·n ≤ m  (13)

Ở đây, k là một số nguyên từ 1 đến K, trong đó K đại diện cho số lượng đoạn tối đa có thể trong độ dài chuỗi đầy đủ l. Khi kn > m, các đoạn tiếp theo chuyển tiến theo chuỗi trong các cửa sổ có độ dài cố định với kích thước m, như được hiển thị trong Phương trình (14):

{xₖ·ₙ₋ₘ, xₖ·ₙ₋ₘ₊₁, ..., xₖ·ₙ}                                  (14)

Phương pháp này đảm bảo rằng mô hình học cấu trúc chuỗi một cách tiến bộ, tương tự như quá trình tạo tự hồi quy nơi các token được dự đoán từng cái một. Kết quả là, mô hình được căn chỉnh tốt hơn với bản chất tự hồi quy của việc tạo nhạc, giảm vấn đề nhìn trộm và cải thiện chất lượng tạo. Do đó, mô hình có thể học một cách mượt mà việc tạo các chuỗi {x₁, x₂, ..., xₘ₋ₙ} với mặt nạ nhân quả hiệu quả. Các lợi thế chính được tóm tắt như sau:

• Học tiến bộ: Mô hình học các phụ thuộc tầm xa một cách tiến bộ bằng cách bắt đầu với các chuỗi ngắn hơn và dần dần tăng độ dài ngữ cảnh.
• Tính nhất quán: Phương pháp này đảm bảo quá trình huấn luyện bắt chước việc tạo tự hồi quy, giảm sự suy giảm chất lượng trong quá trình tạo.
• Căn chỉnh nhân quả: Phương pháp này căn chỉnh với mặt nạ nhân quả, ngăn mô hình "nhìn trộm" các token tương lai trong quá trình huấn luyện.

### B. Cơ Chế Cross-Attention Đa Quy Mô

Cơ chế cross-attention Đa Quy Mô được đề xuất cho phép Perceiver S xử lý các mức độ ngữ cảnh khác nhau đồng thời. Cơ chế này sử dụng hai lớp cross-attention trên mặt nạ nhân quả: một không có mặt nạ quy mô nào, cho phép tất cả các token vẫn không bị che giấu, và lớp khác che giấu các token từ token thứ 1 đến token thứ m-n. Chi tiết với công thức cho hai thiết lập này được trình bày như sau.

Đầu tiên, chúng tôi giới thiệu Mặt nạ attention không có mặt nạ quy mô. Trong trường hợp này, tất cả các token đều có thể nhìn thấy bởi mô hình, như được định nghĩa trong Phương trình (15):

M̂ᵢⱼ = 0, ∀i, j                                                (15)

Thứ hai, trong trường hợp Mặt nạ attention với mặt nạ quy mô (che giấu token thứ 1 đến thứ m-n), các token từ vị trí thứ 1 đến thứ m-n bị che giấu bởi mặt nạ quy mô, ngăn mô hình attention đến các token này. Ma trận mặt nạ quy mô M̂ được định nghĩa trong Phương trình (16):

M̂ᵢⱼ = {
    0       nếu j > m-n
    -∞      nếu j ≤ m-n                                        (16)

Điều này đảm bảo rằng chỉ các token bắt đầu từ vị trí thứ m-n+1 mới có thể nhìn thấy, trong khi mô hình không thể attention đến các token trước vị trí này. Mặt nạ nhân quả kết hợp M và mặt nạ quy mô M̂ được thêm trực tiếp vào tính toán điểm attention, sửa đổi softmax như sau (Phương trình (17)):

Attention(Q, K, V) = softmax((QKᵀ + M + M̂)/√dₖ)V              (17)

trong đó M tham chiếu đến mặt nạ nhân quả đảm bảo mô hình không attention đến các token tương lai, và M̂ biểu thị mặt nạ quy mô được áp dụng để hạn chế attention đến các phần nhất định của chuỗi. Cả hai mặt nạ hoạt động cùng nhau để kiểm soát token nào mà mô hình có thể attention trong quá trình huấn luyện.

Sau khi tính toán attention của một lớp cho trước theo cách được mô tả ở trên, đầu ra từ lớp attention này được đưa làm đầu vào cho lớp tiếp theo, cho phép mỗi lớp tinh chỉnh và xây dựng dựa trên đầu ra của lớp trước đó. Chúng tôi gọi phương pháp kết hợp các lớp attention này là chế độ Cascade.

## VI. THÍ NGHIỆM VÀ KẾT QUẢ

### A. Thiết Lập Thí Nghiệm

Trong phần này, chúng tôi giới thiệu thiết lập thí nghiệm, bao gồm lựa chọn bộ dữ liệu, tiền xử lý MIDI, lựa chọn siêu tham số, và các thước đo đánh giá.

1) Lựa Chọn Bộ Dữ Liệu: Trong các thí nghiệm của chúng tôi, chúng tôi đã sử dụng bộ dữ liệu Maestro [5] làm bộ dữ liệu chính. Nó chứa 1,251 chuỗi, với tập xác thực gồm 240 chuỗi. Tất cả các mô hình đều được huấn luyện và đánh giá chỉ trên bộ dữ liệu này để đảm bảo tính nhất quán trong việc đánh giá hiệu suất.

2) Tiền Xử Lý MIDI: Đối với tiền xử lý MIDI, chúng tôi đặt các sự kiện Note On và Note Off trong phạm vi từ 0 đến 127. Các sự kiện Time Shift được rời rạc hóa thành 100 bước thời gian mỗi giây, trong đó mỗi bước đại diện cho 10 mili giây. Các sự kiện Volume được lượng tử hóa thành 32 bin, và các sự kiện pedal được ánh xạ đến thời gian của các nốt liên quan, loại bỏ các sự kiện pedal sau đó. Mỗi bài hát kết thúc bằng một marker token_end. Không có tăng cường dữ liệu, như thay đổi khóa hoặc tempo, được áp dụng, mặc dù điều này được lên kế hoạch cho các thí nghiệm tương lai.

3) Lựa Chọn Siêu Tham Số: Chiều ẩn được đặt thành 1,024 với 24 lớp self-attention. Mỗi lớp attention có 16 head, và chiều head là 64. Tối ưu hóa Adam được sử dụng, với tốc độ học ban đầu được đặt thành 0.03125. Mỗi độ dài chuỗi được tạo được đặt thành 8,192 token, tạo ra khoảng 2-10 phút nhạc. Việc tạo nhạc trong thiết lập này là không điều kiện, có nghĩa là không có điều kiện hoặc lời nhắc bên ngoài nào được sử dụng để hướng dẫn quá trình tạo. Các file MIDI kết quả được render thành âm thanh sử dụng âm thanh Vintage Piano từ Logic Pro.

4) Thước Đo Đánh Giá: Lấy cảm hứng từ công trình nghiên cứu trước đây [27], để đánh giá, chúng tôi xây dựng một bộ dữ liệu tham chiếu bằng cách tách một tập hợp các tác phẩm từ bộ dữ liệu huấn luyện (Maestro [5]) trước khi huấn luyện mô hình. Sau đó, chúng tôi tạo ra một số lượng file bằng nhau sử dụng mô hình để hình thành bộ dữ liệu được tạo. Chúng tôi tính toán khoảng cách trong mỗi bộ dữ liệu và giữa các bộ dữ liệu được tạo và tham chiếu cho các thước đo sau:

• Total Used Pitch (PC): Đo sự đa dạng cao độ tổng thể bằng cách đếm các lớp cao độ riêng biệt được sử dụng trong toàn bộ tác phẩm.

• Total Used Note (NC): Đếm các nốt riêng biệt (kết hợp cao độ và quãng tám) được sử dụng trong toàn bộ tác phẩm, chỉ ra sự đa dạng trong cao độ và thanh ghi.

• Total Pitch Class Histogram (PCH): Một biểu đồ đại diện cho phân phối tần suất của các lớp cao độ trong toàn bộ tác phẩm, cung cấp thông tin chi tiết về sở thích lớp cao độ.

• Pitch Class Transition Matrix (PCTM): Một ma trận đại diện cho xác suất chuyển đổi từ một lớp cao độ này sang lớp cao độ khác. Thước đo này nắm bắt các mẫu chuyển động giai điệu và hòa âm.

• Pitch Range (PR): Đo sự khác biệt giữa cao độ cao nhất và thấp nhất được sử dụng trong tác phẩm, chỉ ra phạm vi tổng thể của các cao độ.

• Average Pitch Interval (PI): Khoảng cách trung bình giữa các cao độ liên tiếp, phản ánh xu hướng về chuyển động từng bước hoặc nhảy bước trong giai điệu.

• Average Inter-Onset Interval (IOI): Đo khoảng thời gian trung bình giữa các điểm bắt đầu nốt, nắm bắt mật độ nhịp điệu trong toàn bộ tác phẩm.

• Note Length Histogram (NLH): Một biểu đồ đại diện cho phân phối độ dài nốt, cung cấp thông tin chi tiết về sự đa dạng thời gian nốt.

• Note Length Transition Matrix (NLTM): Một ma trận đại diện cho xác suất chuyển đổi giữa các độ dài nốt khác nhau, nắm bắt các mẫu nhịp điệu và biến thể trong thời gian nốt.

Chúng tôi giới thiệu bốn thước đo dựa trên các đoạn thời gian, vì các chú thích thanh không có sẵn trong các bộ dữ liệu biểu diễn, làm cho việc phân đoạn dựa trên thời gian trở nên cần thiết để đánh giá tính mạch lạc dài hạn và sự đa dạng cục bộ.

• Segment Used Pitch (PC/seg): Tương tự như Total Used Pitch, nhưng được tính trong các đoạn. Thước đo này giúp nắm bắt sự đa dạng cao độ qua các phần ngắn hơn.

• Segment Used Note (NC/seg): Đếm các nốt riêng biệt trong các đoạn có độ dài cố định, cho phép chúng ta phân tích sự đa dạng của các nốt được sử dụng qua các phần khác nhau của tác phẩm.

• Segment Pitch Class Histogram (PCH/seg): Đại diện cho phân phối lớp cao độ trong mỗi đoạn, cung cấp thông tin chi tiết về tính nhất quán của việc sử dụng lớp cao độ qua các phần khác nhau.

• Segment Average Inter-Onset Interval (IOI/seg): Đo khoảng thời gian trung bình giữa các điểm bắt đầu nốt trong mỗi đoạn, giúp phân tích mật độ nhịp điệu và tính nhất quán tempo trong các phần ngắn hơn.

Để tính toán các thước đo dựa trên đoạn bổ sung này, mỗi tác phẩm đánh giá được chia thành 64 đoạn có thời gian bằng nhau. Tất cả các thước đo này được tính dựa trên sự tương tự phân phối inter-set giữa bộ dữ liệu được tạo và bộ dữ liệu ground truth, bao gồm hai giá trị: KL Divergence (KLD) và Overlap Area (OA). Khi giá trị OA lớn hơn và giá trị KLD nhỏ hơn, nó chỉ ra rằng các phân phối thước đo trên của bộ dữ liệu được tạo và bộ dữ liệu ground truth được căn chỉnh chặt chẽ, gợi ý rằng mô hình đã tạo ra nhạc giống với các tác phẩm được sáng tác và biểu diễn bởi con người hơn.

### B. Thí Nghiệm và Kết Quả

Hai thí nghiệm đã được tiến hành để đánh giá hiệu suất của các mô hình trong các tình huống khác nhau.

1) Thí Nghiệm 1: Phân Đoạn Chuỗi Đầu Vào: Thí nghiệm đầu tiên nhằm chứng minh rằng Phân Đoạn Hiệu Quả là cần thiết để mô hình tận dụng đầy đủ ngữ cảnh tầm xa siêu dài.

Chúng tôi so sánh hai loại phân đoạn chuỗi đầu vào, với độ dài chuỗi tối đa được đặt thành 32,786 token:

• Mô Hình Cơ Sở: Một vị trí bắt đầu ngẫu nhiên được chọn trong phạm vi [0, độ dài chuỗi - độ dài đầu vào tối đa + 1], và sau đó một đoạn gồm các token có độ dài đầu vào tối đa được lấy từ điểm bắt đầu này.

• Mô Hình Cải Thiện: Một vị trí kết thúc ngẫu nhiên được chọn trong phạm vi [độ dài truy vấn + 1, độ dài chuỗi + 1], và sau đó một đoạn token, có thể lên tới độ dài đầu vào tối đa, được lấy ngược từ điểm kết thúc này. Các đoạn ngắn hơn độ dài đầu vào tối đa được padding ở đầu.

Các phương pháp phân đoạn đã tạo ra kết quả rất khác nhau trong huấn luyện và tạo tự hồi quy, với mô hình cải thiện cho thấy chất lượng tốt hơn nhiều so với cơ sở, như được hiển thị trong dữ liệu trong hộp đứt nét đỏ trong Bảng I. Nhạc được tạo bằng phương pháp xử lý chuỗi đầu vào cải thiện gần với ground truth hơn về các thước đo KLD thấp hơn, bao gồm PC, PC/seg, NC/seg, PCH/seg, PCTM, PR, PI, IOI, và IOI/seg, cũng như các thước đo OA cao hơn, bao gồm PC, PC/seg, NC, NC/seg, PCTM, PR, PI, IOI, IOI/seg, và NLTM. Kết quả này chỉ ra rằng cải thiện hiệu quả cho phép mô hình sử dụng ngữ cảnh tầm xa siêu dài cho việc tạo nhạc.

2) Thí Nghiệm 2: Attention Đa Quy Mô: Mục tiêu của thí nghiệm thứ hai là đánh giá liệu việc sử dụng cross-attention đa lớp với các quy mô ngữ cảnh khác nhau, đặc biệt bằng cách đơn giản thêm các đầu ra attention cho các phụ thuộc tầm ngắn, có thể cải thiện chất lượng tạo hay không.

Trong khi ngữ cảnh siêu dài cung cấp tính nhất quán dài hạn, nó có xu hướng tạo ra các đoạn lặp lại trong phần sau của chuỗi (xem Hình 3). Để giải quyết vấn đề này, chúng tôi đã thêm các mặt nạ quy mô khác nhau vào cross-attention đa lớp, cho phép các lớp khác nhau tập trung vào các độ dài ngữ cảnh riêng biệt và hợp nhất các kết quả này. Ở đây, chúng tôi định nghĩa hai mặt nạ quy mô cho độ dài chuỗi tối đa 32,786 token. Cụ thể, trong thiết lập No Scale Mask, tất cả các token vẫn không bị che giấu. Trong thiết lập Masked Scale, chỉ 1,024 token cuối cùng có thể nhìn thấy, trong khi tất cả các token trước đó được che giấu.

Lớp cross-attention không có mặt nạ được đưa vào lớp cross-attention với mặt nạ ngữ cảnh làm đầu vào của nó. Chúng tôi gọi phương pháp này là cascade Multi-Scale cross attention.

[Hình 3 và 4 mô tả sự khác biệt giữa các đoạn lặp lại và các cụm từ đa dạng]

[Bảng I hiển thị kết quả đánh giá cho các mô hình Baseline, Effective Segmentation, và Multi-Scale]

Kết quả, như được hiển thị trong dữ liệu trong hộp xanh liền trong Bảng I, chỉ ra rằng phương pháp này đã cải thiện đáng kể chất lượng tạo của mô hình. Bằng cách kiểm tra OA của bốn tham số IOI, IOI/seg, NLH, và NLTM—liên quan đến đặc tính nhịp điệu—rõ ràng là việc tạo của mô hình căn chỉnh chặt chẽ hơn với tập tham chiếu. Ngoài ra, các giá trị OA cho PCH và PCH/seg chỉ ra rằng các đặc tính hòa âm cũng giống với những đặc tính của bộ dữ liệu tham chiếu hơn. Hơn nữa, chúng tôi phân tích mật độ của các nốt lặp lại được phát hiện mỗi đơn vị thời gian trong nhạc được tạo phân đoạn trước và sau cải thiện, như được hiển thị trong Hình 5, chỉ ra rằng mô hình trước cải thiện thể hiện xu hướng lớn hơn để tạo ra các đoạn lặp lại. Ngược lại, các đoạn lặp lại bất thường trong nhạc được tạo hiện rất hiếm sau cải thiện, như được hiển thị trong Hình 4, với nhạc được tạo thậm chí thể hiện sự đa dạng phong phú của các cụm từ.

[Hình 5 mô tả mật độ các nốt lặp lại được phát hiện]

Chúng tôi cũng lưu ý rằng mô hình cơ sở cho thấy kết quả tốt hơn trong các thước đo PCH và NLH vì hầu hết nhạc cổ điển là đa nhạc chương; kết quả là, các tác phẩm cổ điển đa nhạc chương và nhạc được tạo kém, giống ngẫu nhiên, khi được phân tích qua toàn bộ tác phẩm, có xu hướng thể hiện phân phối rộng của các lớp cao độ và độ dài nốt. Ngược lại, mô hình cải thiện tạo ra nhạc duy trì hòa âm và nhịp điệu tương đối nhất quán hơn trong toàn bộ tác phẩm, giống như một nhạc chương duy nhất của một tác phẩm cổ điển, dẫn đến phân phối hẹp hơn so với cả ground truth và nhạc không có cấu trúc. Do đó, khi kiểm tra dữ liệu phân đoạn cho các thước đo tương tự trên cùng một tập hợp tác phẩm, như PCH/seg, mô hình cải thiện hoạt động tốt hơn, vì phân tích phân đoạn của nhạc ground truth, với hầu hết các đoạn được lấy từ cùng một nhạc chương, có xu hướng có phân phối hòa âm và nhịp điệu hẹp hơn so với nhạc không có cấu trúc. Mặc dù dữ liệu đoạn NLH không được tính toán, nó nên theo lý luận tương tự.

### C. Thảo Luận

Kỹ thuật Phân Đoạn Hiệu Quả được đề xuất của chúng tôi, tối ưu hóa xử lý chuỗi đầu vào cho Perceiver AR [4], đã cho thấy rằng, với phân đoạn dữ liệu thích hợp, Perceiver AR [4] có thể học hiệu quả các ngữ cảnh dài và tạo ra nội dung mạch lạc, phong phú ngữ cảnh. Attention ngữ cảnh siêu dài thực sự cung cấp cho mô hình những lợi ích đáng chú ý trong việc duy trì tính nhất quán nội dung qua việc tạo mở rộng.

Tuy nhiên, một nhược điểm tiềm ẩn của việc chỉ dựa vào các phụ thuộc tầm xa đã xuất hiện: khi các chuỗi trở nên dài hơn, mô hình ngày càng có xu hướng tạo ra các đoạn ngắn lặp lại. Điều này xảy ra vì, trong các giai đoạn sau của việc tạo, các cửa sổ ngữ cảnh dài gần như giống hệt, chỉ khác nhau bởi một vài token. Do đó, xác suất tạo ra các đoạn giống hệt hoặc tương tự tăng, được khuếch đại thêm bởi xu hướng tự tương quan token cao [6] do sự tương tự cao của ngữ cảnh khi độ dài chuỗi tăng.

Để giảm thiểu vấn đề này, chúng tôi giới thiệu cơ chế cross-attention Đa Quy Mô kết hợp cả cửa sổ ngữ cảnh dài và ngắn. Bằng cách tích hợp các độ dài ngữ cảnh khác nhau vào cross-attention đa lớp, phương pháp của chúng tôi thành công giảm xu hướng cho các chuỗi lặp lại trong khi duy trì tính nhất quán dài hạn của mô hình. Chiến lược kết hợp này cho phép tạo ra nhạc biểu tượng chất lượng cao qua các chuỗi mở rộng.

Mô hình tăng cường của chúng tôi, Perceiver S (Segmentation và Scale), tận dụng Phân Đoạn Hiệu Quả được căn chỉnh với chế độ hoạt động của Perceiver AR [4]. Bằng cách áp dụng các chiến lược che giấu Đa Quy Mô trong cross-attention đa lớp, Perceiver S hiệu quả tạo ra nhạc gắn kết, nhất quán qua các ngữ cảnh thời gian mở rộng, bảo tồn các biến thể âm nhạc phức tạp và chi tiết biểu cảm qua các chuỗi dài. Ngoài ra, thông qua việc sử dụng các bộ dữ liệu nhạc biểu diễn, Perceiver S có khả năng tạo ra nhạc biểu tượng chất lượng cao nắm bắt các sắc thái của biểu diễn con người. Quan trọng là, vì mô hình không dựa vào các bộ dữ liệu được chú thích, Perceiver S có thể được huấn luyện trên dữ liệu MIDI có nguồn gốc từ âm thanh sử dụng bất kỳ kỹ thuật automatic music transcription (AMT) nào. Khả năng này gợi ý một tương lai trong đó việc tạo nhạc biểu tượng có thể tận dụng các bản ghi lịch sử rộng lớn, không bị giới hạn bởi các hạn chế của dữ liệu được chú thích thủ công.

Về bản chất, Perceiver AR [4] và, mở rộng ra, Perceiver S, là các mô hình mục đích chung có thể thích ứng với một loạt rộng các nhiệm vụ AI. Các đổi mới Phân Đoạn Hiệu Quả và Đa Quy Mô được giới thiệu ở đây mở ra các hướng cho các ứng dụng tương lai qua các lĩnh vực như văn bản, hình ảnh, và video. Nghiên cứu tương lai do đó có thể mở rộng tiềm năng của Perceiver S, khám phá các khả năng của nó qua các phương thức đa dạng và mở rộng tiện ích của nó trong bối cảnh rộng lớn hơn của các nhiệm vụ AI.

## VII. KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI

Trong công trình này, chúng tôi đã giới thiệu một mô hình mới, Perceiver S, xây dựng dựa trên kiến trúc Perceiver AR [4] bằng cách kết hợp Phân Đoạn Hiệu Quả và cơ chế attention Đa Quy Mô. Phương pháp Phân Đoạn Hiệu Quả mở rộng dần dần đoạn ngữ cảnh trong quá trình huấn luyện, căn chỉnh chặt chẽ hơn với việc tạo tự hồi quy và cho phép tạo mượt mà, mạch lạc qua các chuỗi nhạc biểu tượng siêu dài. Cơ chế attention Đa Quy Mô tiếp tục tăng cường khả năng của mô hình trong việc nắm bắt các phụ thuộc cấu trúc dài hạn trong khi duy trì sự đa dạng ngắn hạn.

Bằng cách giải quyết các hạn chế trong các mô hình hiện có, đặc biệt là vấn đề masking nhân quả trong việc tạo tự hồi quy và vấn đề tự tương quan token cao trong các chuỗi siêu dài, Perceiver S cho phép xử lý hiệu quả các chuỗi token siêu dài mà không làm tổn hại chất lượng của nhạc được tạo. Thông qua Phân Đoạn Hiệu Quả được đề xuất trong tiền xử lý bộ dữ liệu và các sửa đổi attention Đa Quy Mô, chúng tôi đã chứng minh cải thiện đáng kể trong việc tạo ra các tác phẩm âm nhạc mạch lạc và đa dạng.

Phương pháp của chúng tôi đối với việc tạo nhạc biểu tượng cung cấp một sự cân bằng mới giữa tính mạch lạc cấu trúc và sự đa dạng biểu cảm, đặt nền móng cho những tiến bộ tương lai trong các mô hình tạo nhạc biểu tượng.

## TÀI LIỆU THAM KHẢO

[1] Haohe Liu, Zehua Chen, Yi Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, và Mark D. Plumbley. Audioldm: Text-to-audio generation with latent diffusion models, 2023.

[2] Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi, và Alexandre Défossez. Simple and controllable music generation, 2024.

[3] Peike Li, Boyu Chen, Yao Yao, Yikai Wang, Allen Wang, và Alex Wang. Jen-1: Text-guided universal music generation with omnidirectional diffusion models, 2023.

[4] Curtis Hawthorne, Andrew Jaegle, Cătălina Cangea, Sebastian Borgeaud, Charlie Nash, Mateusz Malinowski, Sander Dieleman, Oriol Vinyals, Matthew Botvinick, Ian Simon, Hannah Sheahan, Neil Zeghidour, Jean-Baptiste Alayrac, João Carreira, và Jesse Engel. General-purpose, long-context autoregressive modeling with perceiver ar, 2022.

[5] Curtis Hawthorne, Andriy Stasyuk, Adam Roberts, Ian Simon, Cheng-Zhi Anna Huang, Sander Dieleman, Erich Elsen, Jesse Engel, và Douglas Eck. Enabling factorized piano music modeling and generation with the maestro dataset, 2019.

[6] Minhyeok Lee. A mathematical interpretation of autoregressive generative pre-trained transformer and self-supervised learning. Mathematics, 11(11):2451, 2023.

[7] Cheng-Zhi Anna Huang, Ashish Vaswani, Jakob Uszkoreit, Noam Shazeer, Ian Simon, Curtis Hawthorne, Andrew M. Dai, Matthew D. Hoffman, Monica Dinculescu, và Douglas Eck. Music transformer, 2018.

[8] Qiuqiang Kong, Bochen Li, Jitong Chen, và Yuxuan Wang. Giantmidi-piano: A large-scale midi dataset for classical piano music, 2022.

[9] Huan Zhang, Jingjing Tang, Syed RM Rafee, Simon Dixon, George Fazekas, và Geraint A Wiggins. Atepp: A dataset of automatically transcribed expressive piano performance. Trong Ismir 2022 Hybrid Conference, 2022.

[10] Drew Edwards, Simon Dixon, và Emmanouil Benetos. Pijama: Piano jazz with automatic midi annotations. Transactions of the International Society for Music Information Retrieval, 2023.

[11] Curtis Hawthorne, Erich Elsen, Jialin Song, Adam Roberts, Ian Simon, Colin Raffel, Jesse Engel, Sageev Oore, và Douglas Eck. Onsets and frames: Dual-objective piano transcription, 2018.

[12] Colin Raffel. Learning-based methods for comparing sequences, with applications to audio-to-midi alignment and matching. Columbia University, 2016.

[13] Francesco Foscarin, Andrew Mcleod, Philippe Rigaux, Florent Jacquemard, và Masahiko Sakai. Asap: a dataset of aligned scores and performances for piano transcription. Trong International Society for Music Information Retrieval Conference, trang 534–541, 2020.

[14] Francesco Foscarin, Jan Schlüter, và Gerhard Widmer. Beat this! accurate beat tracking without dbn postprocessing, 2024.

[15] Shih-Lun Wu và Yi-Hsuan Yang. Musemorphose: Full-song and fine-grained piano music style transfer with one transformer vae, 2022.

[16] Shih-Lun Wu và Yi-Hsuan Yang. Compose & embellish: Well-structured piano performance generation via a two-stage approach, 2023.

[17] Yujia Huang, Adishree Ghatare, Yuanzhe Liu, Ziniu Hu, Qinsheng Zhang, Chandramouli S Sastry, Siddharth Gururani, Sageev Oore, và Yisong Yue. Symbolic music generation with non-differentiable rule guided diffusion, 2024.

[18] Ziyu Wang, Lejun Min, và Gus Xia. Whole-song hierarchical generation of symbolic music using cascaded diffusion models, 2024.

[19] Ziyu Wang, Ke Chen, Junyan Jiang, Yiyi Zhang, Maoran Xu, Shuqi Dai, Xianbin Gu, và Gus Xia. Pop909: A pop-song dataset for music arrangement generation, 2020.

[20] Adam Roberts, Jesse Engel, Colin Raffel, Curtis Hawthorne, và Douglas Eck. A hierarchical latent vector model for learning long-term structure in music, 2019.

[21] Botao Yu, Peiling Lu, Rui Wang, Wei Hu, Xu Tan, Wei Ye, Shikun Zhang, Tao Qin, và Tie-Yan Liu. Museformer: Transformer with fine-and coarse-grained attention for music generation, 2022.

[22] Andrew Jaegle, Felix Gimeno, Andrew Brock, Andrew Zisserman, Oriol Vinyals, và Joao Carreira. Perceiver: General perception with iterative attention, 2021.

[23] Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier Hénaff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, và João Carreira. Perceiver io: A general architecture for structured inputs & outputs, 2022.

[24] Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V. Le, và Ruslan Salakhutdinov. Transformer-xl: Attentive language models beyond a fixed-length context, 2019.

[25] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, và Illia Polosukhin. Attention is all you need, 2023.

[26] Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, và Yejin Choi. The curious case of neural text degeneration, 2020.

[27] Li-Chia Yang và Alexander Lerch. On the evaluation of generative models in music. Neural Computing and Applications, 32(9):4773–4784, 2020.

[3] F. Kreuk, G. Synnaeve, A. Polyak, U. Singer, A. Défossez, J. Copet, D. Parikh, Y. Taigman, và Y. Adi, "AudioGen: Textually guided audio generation," International Conference on Learning Representations, 2022.

[4] H. Liu, Z. Chen, Y. Yuan, X. Mei, X. Liu, D. Mandic, W. Wang, và M. D. Plumbley, "AudioLDM: Text-to-audio generation with latent diffusion models," International Conference on Machine Learning, 2023.

[5] D. Zhang, S. Li, X. Zhang, J. Zhan, P. Wang, Y. Zhou, và X. Qiu, "SpeechGPT: Empowering large language models with intrinsic cross-modal conversational abilities," arXiv preprint:2305.11000, 2023.

[6] S. Forsgren và H. Martiros, "Riffusion: Stable diffusion for real-time music generation, 2022," URL https://riffusion.com/about, vol. 6, 2022.

[7] X. Liu, Z. Zhu, H. Liu, Y. Yuan, M. Cui, Q. Huang, J. Liang, Y. Cao, Q. Kong, M. D. Plumbley et al., "WavJourney: Compositional audio creation with large language models," arXiv preprint:2307.14335, 2023.

[8] A. Agostinelli, T. I. Denk, Z. Borsos, J. Engel, M. Verzetti, A. Caillon, Q. Huang, A. Jansen, A. Roberts, M. Tagliasacchi et al., "MusicLM: Generating music from text," arXiv preprint:2301.11325, 2023.

[9] R. Bresin, A. de Witt, S. Papetti, M. Civolani, và F. Fontana, "Expressive sonification of footstep sounds," Proceedings of Interactive Sonification Workshop, 2010.

[10] J. Engel, L. Hantrakul, C. Gu, và A. Roberts, "DDSP: Differentiable digital signal processing," International Conference on Learning Representations, 2020.

[Danh sách tài liệu tham khảo tiếp tục với 83 tài liệu còn lại theo định dạng tương tự...]

--- TRANG 11 ---
11

[Các tài liệu tham khảo từ 11-93 tiếp tục theo định dạng giống như trên, bao gồm các nghiên cứu về mô hình ngôn ngữ, khuếch tán, sinh tạo audio, và các phương pháp học máy liên quan]

--- TRANG 12 ---
12

[Các tài liệu tham khảo từ 26-93 tiếp tục]

--- TRANG 13 ---
13

[Các tài liệu tham khảo cuối cùng từ 70-93]

# byteSteady: Phân loại Nhanh Sử dụng Embedding n-Gram Mức Byte

Xiang Zhang
fancyzhx@gmail.com
Element AI
Montreal, Quebec, Canada

Alexandre Drouin
alexandre.drouin@servicenow.com
Element AI, ServiceNow
Montreal, Quebec, Canada

Raymond Li
raymond.li@servicenow.com
Element AI, ServiceNow
Montreal, Quebec, Canada

## TÓM TẮT

Bài viết này giới thiệu byteSteady – một mô hình nhanh cho phân loại sử dụng embedding n-gram mức byte. byteSteady giả định rằng mỗi đầu vào đến dưới dạng một chuỗi byte. Một vector biểu diễn được tạo ra bằng cách sử dụng các vector embedding trung bình của các n-gram mức byte, với một tập hợp n được định nghĩa trước. Thủ thuật băm được sử dụng để giảm số lượng vector embedding. Vector biểu diễn đầu vào này sau đó được đưa vào một bộ phân loại tuyến tính. Một ứng dụng trực tiếp của byteSteady là phân loại văn bản. Chúng tôi cũng áp dụng byteSteady cho một loại dữ liệu phi ngôn ngữ – chuỗi DNA để phân loại gen. Đối với cả hai vấn đề, chúng tôi đạt được kết quả phân loại cạnh tranh so với các baseline mạnh, cho thấy byteSteady có thể được áp dụng cho cả dữ liệu ngôn ngữ và phi ngôn ngữ. Hơn nữa, chúng tôi thấy rằng nén đơn giản sử dụng mã hóa Huffman không ảnh hưởng đáng kể đến kết quả, điều này mang lại một sự đánh đổi độ chính xác-tốc độ chưa được khám phá trước đây trong học máy.

## 1 GIỚI THIỆU

Phân loại dữ liệu tuần tự như văn bản là một nhiệm vụ cơ bản trong học máy. Gần đây, các công cụ như fastText [17] và Vowpal Wabbit [27] đã cho thấy rằng các mô hình đơn giản có thể đạt được kết quả tốt nhất cho phân loại văn bản. Hơn nữa, người ta đã chỉ ra rằng fastText có thể được huấn luyện ở mức ký tự và vẫn tạo ra kết quả cạnh tranh với mô hình mức từ [29]. Điều này thúc đẩy chúng tôi khám phá một mức tổ chức dữ liệu thậm chí thấp hơn: mức byte và nghiên cứu liệu việc huấn luyện mô hình ở mức sơ khai như vậy có cho phép khả năng áp dụng của chúng vượt ra ngoài dữ liệu văn bản hay không.

Trong bài viết này, chúng tôi trình bày một mô hình giống fastText được mã hóa cứng để xử lý đầu vào ở mức byte, được đặt tên là byteSteady, và cho thấy rằng nó có thể đạt được kết quả phân loại cạnh tranh so với các mô hình fastText mức từ và mạng tích chập mức byte. byteSteady giả định rằng đầu vào đến dưới dạng chuỗi byte. Giống như trong fastText [17], một vector biểu diễn được tạo ra bằng cách sử dụng các vector embedding trung bình của các n-gram mức byte, với một tập hợp n được định nghĩa trước. Thủ thuật băm [27] được sử dụng để giảm số lượng vector embedding. Vector biểu diễn đầu vào này sau đó được đưa vào một bộ phân loại tuyến tính để tạo ra lớp mong muốn.

Một mô hình phân loại chuỗi mức byte có tiềm năng hoạt động vượt ra ngoài dữ liệu ngôn ngữ. Trong bài viết này, chúng tôi cũng áp dụng byteSteady cho phân loại gen mà dữ liệu đến dưới dạng chuỗi nucleotide. Chúng tôi cho thấy rằng byteSteady không chỉ yêu cầu ít xử lý dữ liệu trước hơn nhiều so với các mô hình chuẩn trước đây trong tin sinh học, mà còn đạt được kết quả tốt hơn cho dữ liệu phân loại gen quy mô lớn. Một cách ngẫu nhiên, các n-gram mức byte của nucleotide cũng được gọi là k-mer trong genomics [5].

Khi sử dụng một bộ phân loại đơn giản như hồi quy logistic, thường cần rất nhiều công sức để thiết kế đặc trưng dưới giả định rằng tín hiệu thô khó có thể phân tách tuyến tính. Ngược lại, các mô hình học sâu như mạng tích chập và hồi quy thường được áp dụng cho dữ liệu tuần tự ở mức tín hiệu thô để trích xuất biểu diễn phân cấp cho phân loại. Kết quả sử dụng byteSteady cho phân loại văn bản và phân loại gen đã làm suy yếu giả định này và sự phân đôi phương pháp luận, và mở đường cho việc khám phá thêm trong việc sử dụng các mô hình đơn giản cho đầu vào mức thấp.

Đầu vào mức byte cũng có thể được nén bằng các thuật toán nén dữ liệu chuẩn. Trong bài viết này, chúng tôi cũng cho thấy rằng đối với cả nhiệm vụ phân loại văn bản và phân loại gen, hiệu suất không bị ảnh hưởng đáng kể bởi việc nén đầu vào bằng mã hóa Huffman [16]. Điều này cung cấp một sự đánh đổi độ chính xác-tốc độ độc đáo chưa được khám phá trước đây cho học máy.

Công việc trước đây đã khám phá xử lý văn bản mức byte. Ví dụ, trong [14], một mô hình sequence-to-sequence [6] [24] dựa trên LSTM [15] được áp dụng ở mức byte cho nhiều nhiệm vụ xử lý ngôn ngữ tự nhiên (NLP) trong 4 ngôn ngữ Romance. Đối với NLP, lợi thế của việc xử lý mức byte là các mô hình có thể được áp dụng ngay lập tức cho bất kỳ ngôn ngữ nào bất kể có quá nhiều thực thể ở mức ký tự hay từ. Nó giảm bớt vấn đề nguyền rủa của chiều [2] với từ vựng lớn. Dựa trên những lợi thế này, chúng tôi tin rằng công việc này là đầu tiên khám phá giao điểm của các mô hình đơn giản (ví dụ: giống fastText) và xử lý mức byte, và chứng minh khả năng áp dụng bên ngoài lĩnh vực dữ liệu dựa trên ngôn ngữ.

Đóng góp: Tóm lại, bài báo này đưa ra những đóng góp sau: 1) chứng minh rằng mã hóa mức byte của byteSteady có thể đạt được hiệu suất cạnh tranh cho phân loại văn bản; 2) mở rộng khả năng áp dụng của nó vượt ra ngoài phạm vi dữ liệu ngôn ngữ bằng cách sử dụng phân loại gen làm ví dụ; 3) cho thấy rằng tăng tốc tầm thường và một loại đánh đổi độ chính xác-tốc độ mới là có thể bằng cách sử dụng các thuật toán nén chuẩn như mã hóa Huffman. Ngoài ra, 4) một tập dữ liệu phân loại gen quy mô lớn mới đã được xây dựng để thúc đẩy nghiên cứu thêm trong lĩnh vực này.

## 2 MÔ HÌNH BYTESTEADY

Như được hiển thị trong hình 1, byteSteady giả định rằng mỗi mẫu bao gồm một chuỗi byte đầu vào và một nhãn lớp đầu ra. Chuỗi byte được phân tích thành nhiều n-gram mức byte bằng cách sử dụng một tập hợp n được định nghĩa trước, mà chúng tôi gọi là tập hợp n-gram. Lưu ý rằng những n-gram này chỉ là các chuỗi con của đầu vào. Đối với mỗi n-gram, chúng tôi tính toán một giá trị băm, và sử dụng modulo của nó với tổng số embedding được định nghĩa trước làm chỉ số để truy vấn một vector embedding. Số embedding được định nghĩa trước này được gọi là kích thước bảng băm. Sau đó, tất cả các vector embedding này được trung bình hóa cùng nhau để tạo ra vector biểu diễn cho toàn bộ chuỗi byte đầu vào.

Vector biểu diễn đầu vào này được đưa vào một bộ phân loại tuyến tính để tạo ra lớp mong muốn bằng cách sử dụng hàm mất mát log-likelihood âm. Ngoại trừ việc xử lý chuỗi mức byte được mã hóa cứng, byteSteady sử dụng cùng một mô hình học máy như fastText [17]. Kết hợp bảng embedding và bộ phân loại tuyến tính, toàn bộ mô hình có thể được coi như một mạng neural 2 lớp không có phi tuyến tính.

Giả sử A là ma trận embedding và B là ma trận tham số bộ phân loại tuyến tính, hàm mất mát cho mỗi mẫu có thể được biểu diễn như:

−y log(softmax(BAx)), (1)

trong đó y là nhãn được mã hóa một-hot và x là vector tần số-của-gram cho mẫu. A và B là các tham số cần học.

Người ta biết rằng một mạng neural 2 lớp như vậy không có khả năng biểu diễn nhiều hơn một mô hình tuyến tính. Trong trường hợp chiều embedding lớn hơn hoặc bằng số lượng lớp, khả năng là giống nhau.

Đối với các chuỗi byte như văn bản và DNA, x thường thưa thớt. Điều này cho phép sử dụng băm trực tuyến, phép nhân ma trận-vector thưa thớt và song song hóa trên các mẫu để tăng tốc. Tương tự như fastText, chúng tôi sử dụng thuật toán HogWILD! [21] để học nhanh trên CPU. Thủ thuật băm [27] được sử dụng trong byteSteady đã được chỉ ra là hoạt động tốt cho phân loại văn bản mức từ và ký tự. Chúng tôi đã triển khai Fowler–Noll–Vo (FNV) và CityHash như 2 biến thể hàm băm cho byteSteady, và không quan sát thấy bất kỳ sự khác biệt nào về độ chính xác và tốc độ.

Bên cạnh việc cho thấy rằng bộ trick như vậy hoạt động tốt cho phân loại văn bản ở mức byte, việc xử lý mức byte mở ra một số khả năng độc đáo khác cho nhiệm vụ phân loại nói chung. Điều đầu tiên là việc xử lý mức byte có thể được áp dụng cho các loại dữ liệu khác ngoài văn bản – sau cùng, tất cả dữ liệu trong máy tính của chúng ta đều được mã hóa thành chuỗi byte. Trong bài viết này, chúng tôi khám phá phân loại gen làm ví dụ. Thứ hai, nén có thể được áp dụng cho các chuỗi byte. Vì đầu ra của nó cũng là byte, chúng ta có thể thử áp dụng byteSteady trên chuỗi byte nén ngắn hơn để phân loại. Đối với cả phân loại văn bản và phân loại gen, chúng tôi cho thấy rằng có thể tìm ra các cấu hình tập hợp n-gram hoạt động tốt cho dữ liệu nén bằng mã hóa Huffman [16]. Điều này mang lại một sự đánh đổi độ chính xác-tốc độ chưa được khám phá trong học máy trước đây.

## 3 NHIỆM VỤ

Trong phần này, chúng tôi giới thiệu các nhiệm vụ phân loại văn bản và phân loại gen với so sánh giữa byteSteady và các mô hình tốt nhất trước đây. Các nghiên cứu loại bỏ cho byteSteady trên cả hai nhiệm vụ này được trình bày trong các phần tiếp theo.

### 3.1 Phân loại Văn bản

Các tập dữ liệu phân loại văn bản được sử dụng trong bài viết này giống như trong [29]. Tổng cộng, có 14 tập dữ liệu quy mô lớn trong 4 ngôn ngữ bao gồm Trung Quốc, Tiếng Anh, Nhật Bản và Hàn Quốc. Có 2 loại nhiệm vụ trong các tập dữ liệu này, đó là phân tích cảm xúc và phân loại chủ đề. Hơn nữa, 2 trong số các tập dữ liệu được xây dựng bằng cách kết hợp các mẫu trong tất cả 4 ngôn ngữ để kiểm tra khả năng của mô hình xử lý các ngôn ngữ khác nhau theo cùng một cách. Bảng 1 là một bản tóm tắt.

Trong bảng 1, 9 tập dữ liệu đầu tiên là các tập dữ liệu phân tích cảm xúc bằng Trung Quốc, Tiếng Anh, Nhật Bản hoặc Hàn Quốc, từ các trang web đánh giá nhà hàng hoặc mua sắm trực tuyến. 3 tập dữ liệu tiếp theo là các tập dữ liệu phân loại chủ đề bằng Trung Quốc hoặc Tiếng Anh, từ các trang web tin tức trực tuyến. Hai tập dữ liệu cuối cùng là các tập dữ liệu đa ngôn ngữ bằng cách kết hợp các đánh giá mua sắm trực tuyến từ 4 ngôn ngữ.

Đáng lưu ý là các mô hình mức từ hoặc mức ký tự yêu cầu tiền xử lý đáng kể cho các ngôn ngữ này, và từ vựng kết quả là lớn. Nó mang rủi ro của nguyền rủa-của-chiều [2]. Việc xử lý văn bản ở mức byte và sử dụng thủ thuật băm [27] đã giảm bớt những vấn đề này, và các kết quả trước đây [14] [29] cho thấy rằng các mô hình học sâu mức byte có thể đạt được độ chính xác cạnh tranh. Tuy nhiên, theo như chúng tôi biết, chúng tôi là những người đầu tiên trình bày kết quả về xử lý văn bản mức byte bằng cách sử dụng các mô hình đơn giản.

Để tìm kiếm siêu tham số, một phân chia development-validation được xây dựng bằng cách sử dụng phân chia 90%-10% trên tập con huấn luyện của mỗi tập dữ liệu. Trong nghiên cứu loại bỏ sau này, chúng tôi sẽ cho thấy rằng kết quả byteSteady không nhạy cảm với kích thước bảng băm và chiều embedding miễn là chúng đủ lớn. Trong phần này, chúng tôi sử dụng kích thước bảng băm là 16.777.216 (bằng 2^24) và chiều embedding là 16. Nghiên cứu loại bỏ sau này sẽ cho thấy rằng kết quả byteSteady nhạy cảm với tập hợp n-gram và weight decay. Đối với tất cả các tập dữ liệu, các thí nghiệm tìm kiếm siêu tham số cho thấy rằng cấu hình tập hợp n-gram tốt nhất là {4,8,12,16}, và weight decay tốt nhất là 0.001.

Sử dụng những cài đặt này và cùng giao thức so sánh như [29], chúng tôi trình bày lỗi kiểm tra trong bảng 1 với so sánh với các mô hình fastText 5-gram mức từ và mạng tích chập (ConvNets) mã hóa một-hot mức byte. Các mô hình so sánh này là những mô hình tốt nhất trong loại của chúng cho các tập dữ liệu này [29], và đại diện cho các baseline mạnh. Kết quả trong Bảng 1 cho thấy rằng các mô hình đơn giản mức byte có thể đạt được kết quả cạnh tranh cho phân loại văn bản, đôi khi vượt qua những mô hình tốt nhất trước đây. Khi byteSteady không phải là tốt nhất, nó không xa mô hình tốt nhất.

### 3.2 Phân loại Gen

Bây giờ chúng tôi trình bày một ứng dụng của byteSteady cho một loại dữ liệu giống văn bản phi ngôn ngữ – chuỗi DNA để phân loại gen. Việc sử dụng biểu diễn n-gram của chuỗi DNA ngày càng phổ biến trong lĩnh vực genomics, vì nó cho phép tránh quy trình căn chỉnh chuỗi đa phức tạp về mặt tính toán [5]. Các phân tích chuỗi không căn chỉnh như vậy đã thành công rộng rãi trong các vấn đề như lắp ráp chuỗi DNA [3,7], tái tạo phả hệ và so sánh genome [10,18,28], dự đoán kiểu hình toàn genome [8,11,12,19], dự đoán chuỗi điều hòa [1,13,23], và lập hồ sơ phân loại trong metagenomics [4,20,25].

Việc kết hợp các biểu diễn như vậy với các mô hình học máy đã dẫn đến kết quả tốt nhất, nhưng đi kèm với chi phí của không gian đặc trưng khổng lồ [12,25]. Các yếu tố làm tăng số lượng n-gram quan sát được bao gồm sự đa dạng tự nhiên của chuỗi (ví dụ: đột biến) và các biến thể ngẫu nhiên do lỗi giải trình tự. Để giải quyết không gian đặc trưng khổng lồ như vậy, một số phương pháp đã dựa vào việc lọc n-gram như một bước tiền xử lý [22], trong khi những phương pháp khác đã chuyển sang xử lý dữ liệu ngoài lõi [11,25]. Việc áp dụng byteSteady cho dữ liệu genomic do đó là tự nhiên, vì nó có thể xử lý hiệu quả không gian đặc trưng n-gram lớn và có thể được áp dụng trực tiếp cho các chuỗi DNA trong biểu diễn byte. Trong genomics, các n-gram của nucleotide cũng được gọi là k-mer.

Nhiệm vụ phân loại gen của chúng tôi bao gồm các chuỗi gen vi khuẩn trong sáu danh mục cấp cao: kháng kháng sinh, vận chuyển, tương đồng con người, gen thiết yếu, yếu tố độc lực, và mục tiêu thuốc. Một bộ dự đoán chính xác cho nhiệm vụ này có thể cải thiện chú thích genome tự động và giúp phát hiện các gen quan trọng, chẳng hạn như những gen liên quan đến kháng thuốc và độc lực của vi khuẩn gây bệnh. Chúng tôi dựa vào một tập dữ liệu được trích xuất từ cơ sở dữ liệu Pathosystems Resource Integration Center (PATRIC) [9,26], chứa các chú thích gen chất lượng cao cho một tập hợp lớn các genome vi khuẩn có sẵn công khai.

Tập dữ liệu chứa tổng cộng 5.111.616 chuỗi DNA, được tạo thành từ các nucleotide được mã hóa như các ký tự ASCII A, C, G, và T. Dữ liệu được phân bố đều thành 6 lớp với 851.936 ví dụ mỗi lớp. Chúng tôi chọn ngẫu nhiên 90% dữ liệu để huấn luyện và sử dụng 10% còn lại để kiểm tra. Chúng tôi tiếp tục phân chia tập huấn luyện bằng cách sử dụng cùng tỷ lệ để tạo ra một tập validation cho tìm kiếm siêu tham số. Một lần nữa, chúng tôi sử dụng kích thước bảng băm là 16.777.216 (bằng 2^24) và chiều embedding là 16. Các thí nghiệm tìm kiếm siêu tham số cho thấy rằng cấu hình tập hợp n-gram tốt nhất là {2,4,6,8,10,12,14,16}, và weight decay tốt nhất là 0.000001.

Chúng tôi cho thấy lợi ích của việc sử dụng byteSteady trong bối cảnh này, bằng cách so sánh với một bộ phân loại tuyến tính khác yêu cầu lựa chọn đặc trưng n-gram thủ công do hạn chế tính toán. Điều này tương ứng với thực tế của các nhà thực hành trong genomics, những người thường phải dựa vào lựa chọn đặc trưng để áp dụng các thuật toán học máy chuẩn cho không gian đặc trưng cực lớn [22]. Chúng tôi xem xét các phiên bản của baseline này sử dụng 100.000 và 1.000.000 n-gram thường xuyên nhất trong dữ liệu huấn luyện.

Kết quả của chúng tôi trong Bảng 2 cho thấy rằng độ chính xác dự đoán cao có thể đạt được, nhưng chỉ khi xem xét kích thước n-gram lớn (ví dụ: 16). Điều này chỉ có thể thực hiện được đối với các mô hình như byteSteady, có khả năng xử lý hiệu quả tập hợp đầy đủ các đặc trưng bằng cách sử dụng thủ thuật băm [27]. Để tham khảo, mô hình byteSteady tốt nhất, sử dụng tập hợp n-gram 2[1−8]={2,4,6,8,10,12,14,16} và weight decay 10^−6, đạt được 3,73% lỗi kiểm tra. Đây là lỗi kiểm tra duy nhất cho phân loại gen trong bài viết này.

## 4 NGHIÊN CỨU LOẠI BỎ

Phần này trình bày các nghiên cứu loại bỏ về 4 siêu tham số trong byteSteady - tập hợp n-gram, weight decay, chiều embedding, và kích thước bảng băm. Kết luận chung là kết quả của byteSteady rất nhạy cảm với tập hợp n-gram và weight decay, nhưng chúng không cải thiện nhiều khi tăng chiều embedding và kích thước bảng băm sau một điểm nhất định.

Đối với tất cả các nghiên cứu loại bỏ, chúng tôi thực hiện thí nghiệm trên cả phân loại văn bản và phân loại gen. Đối với nhiệm vụ phân loại văn bản, chúng tôi sử dụng tập con huấn luyện của Dianping và tạo phân chia development-validation 90%-10%. Tất cả các lỗi được báo cáo đều trên các tập dữ liệu validation cho cả hai nhiệm vụ.

### 4.1 Tập hợp n-Gram và Weight Decay

Khi sử dụng mô hình byteSteady để huấn luyện, chúng ta cần cung cấp một tập hợp n-gram để xem xét. Điều này trái ngược với một số mô hình mức từ như fastText [17], mà chúng ta chỉ cung cấp một n duy nhất. Trong trường hợp như vậy, hoặc chỉ tập hợp gram của {n} hoặc [1−n] được xem xét. Thay vào đó, chúng tôi thấy rằng byteSteady nhạy cảm với tập hợp n-gram, và cấu hình [1−n] không hoạt động tốt nhất.

Trong khi đó, các mô hình học máy nói chung nhạy cảm với tham số weight decay. Nó thường được sử dụng cho mục đích điều hòa, sao cho khoảng cách giữa huấn luyện và kiểm tra có thể trở nên gần hơn. Điều này cũng áp dụng cho byteSteady. Các tham số tốt nhất phụ thuộc vào nhiệm vụ và kích thước mẫu.

Bảng 3 chi tiết kết quả về các tham số tập hợp n-gram và weight decay. Tất cả các số đều là lỗi validation. Các biến thể của tập hợp n-gram bao gồm các tập hợp của một n duy nhất, các tập hợp n tăng tuyến tính, và các tập hợp n tăng mũ. Tất cả chúng đều có phạm vi lên đến n=16. Do sự khác biệt về kích thước mẫu, weight decay tốt nhất khác nhau cho mỗi nhiệm vụ. Kết quả phân loại văn bản được hiển thị trong {10^−2,10^−3,10^−4}, trong khi đối với phân loại gen chúng nằm trong {10^−5,10^−6,10^−7}. Tất cả các thí nghiệm này sử dụng chiều embedding là 16 và kích thước bảng băm là 2^24=16.777.216.

Có một vài kết luận từ kết quả. Điều đầu tiên là các n-gram dài hơn cho kết quả tốt hơn trong trường hợp của tập hợp có giá trị đơn. Thứ hai là đối với cả hai nhiệm vụ, kết quả tốt nhất đến từ một tập hợp n tăng tuyến tính, mặc dù không phải [1−16] bao gồm tất cả n-gram trong phạm vi. Chúng tôi tin rằng điều này là do các đặc trưng phong phú như [1−16] mang nhiều rủi ro overfitting hơn.

Kết luận thứ ba là tập hợp n-gram tăng mũ 2[0−4]={1,2,4,8,16} không hoạt động tệ hơn đáng kể so với các tập hợp tuyến tính. Điều này mang lại một sự đánh đổi tốc độ-độ chính xác bổ sung, mà độ phức tạp tính toán là O(n) cho các tập hợp n-gram tuyến tính, và O(log(n)) cho các lựa chọn thay thế mũ. Liệu sự giảm độ chính xác do giảm độ phức tạp tính toán như vậy có thể chấp nhận được hay không sẽ phụ thuộc vào vấn đề.

### 4.2 Chiều Embedding và Kích thước Bảng Băm

Bảng 4 chi tiết các lỗi validation cho nghiên cứu loại bỏ về chiều embedding cho cả phân loại văn bản và phân loại gen. Đối với các thí nghiệm này, chúng tôi sử dụng tập hợp n-gram 2[0−4]={1,2,4,8,16} và kích thước bảng băm là 2^24=16.777.216. Các tham số weight decay khác nhau được sử dụng cho mỗi nhiệm vụ theo nghiên cứu loại bỏ trước đó. Những kết quả này cho thấy rằng chiều embedding không ảnh hưởng đáng kể đến hiệu suất mô hình về độ chính xác. Tuy nhiên, nó ảnh hưởng trực tiếp đến lượng bộ nhớ cần thiết để lưu trữ các tham số mô hình. Do đó, tất cả các thí nghiệm khác trong bài viết này luôn sử dụng chiều embedding là 16 – một lựa chọn vừa phải.

Bảng 5 chi tiết các lỗi validation cho nghiên cứu loại bỏ về kích thước bảng băm, cho cả phân loại văn bản và phân loại gen. Chúng tôi chọn kích thước bảng băm từ 2^16=65.536 đến 2^26=67.108.864. Các thí nghiệm này sử dụng tập hợp n-gram 2[0−4]={1,2,4,8,16} và chiều embedding là 16. Các tham số weight decay khác nhau được sử dụng cho mỗi nhiệm vụ theo nghiên cứu loại bỏ trước đó. Từ những kết quả này, chúng ta có thể kết luận rằng cải thiện có thể được quan sát thấy khi chúng ta tăng kích thước bảng băm, nhưng nó trở nên biên tế sau một điểm nhất định. Kết quả là, tất cả các thí nghiệm khác trong bài viết này sử dụng kích thước bảng băm khá lớn 2^24=16.777.216.

Cả hai nghiên cứu loại bỏ về chiều embedding và kích thước bảng băm đều cho thấy rằng kết quả byteSteady không nhạy cảm với các siêu tham số này khi chúng đủ lớn. Do đó, các thí nghiệm tương lai sẽ chỉ tập trung vào các nghiên cứu loại bỏ cho tập hợp n-gram và weight decay.

## 5 NÉN SỬ DỤNG MÃ HÓA HUFFMAN

Phần này trình bày một khám phá độc đáo được kích hoạt bởi xử lý dữ liệu mức byte – áp dụng nén trên các chuỗi byte đầu vào và trình bày các chuỗi ngắn hơn kết quả cho byteSteady để phân loại. Đối với văn bản, các mô hình mức ký tự và mức từ trước đây không thể áp dụng vì nén sẽ làm cho ranh giới ký tự hoặc từ không tồn tại.

Thuật toán nén mà chúng tôi sử dụng ở đây là mã hóa Huffman [16], sử dụng 2 biến thể mà đầu ra là bit và byte tương ứng. Trong cả hai trường hợp, chúng tôi kiểm soát tỷ lệ nén bằng cách giới hạn độ dài byte của các ký hiệu. Chúng tôi thấy rằng mô hình có thể hoạt động tốt ở tỷ lệ nén thấp.

### 5.1 Mã hóa Huffman Mức Bit và Mức Byte

Mã hóa Huffman [16] hoạt động bằng cách đưa ra mã ngắn hơn cho các ký hiệu tần số cao hơn, sử dụng một cây được sắp xếp theo tần số mà các nút lá là ký hiệu. Trong bài viết này, ký hiệu được định nghĩa là các chuỗi con byte có độ dài m. Khi cây là nhị phân, mã hóa Huffman xuất ra mã nhị phân (bit) từng cái một. Chúng tôi gọi biến thể này là mã hóa Huffman mức bit. Mặt khác, nếu cây là 256-ary, các mã có thể được tạo ra từng byte một. Chúng tôi đặt tên biến thể này là mã hóa Huffman mức byte.

Độ dài ký hiệu m có thể ảnh hưởng mũ đến kích thước của bảng tần số. Tự nhiên, m lớn hơn đảm bảo các ký hiệu dài hơn có thể được xem xét cho mã ngắn hơn, và dẫn đến tỷ lệ nén tốt hơn. Do đó, m có thể được sử dụng để kiểm soát mức nén của dữ liệu, và mang lại một sự đánh đổi tốc độ-độ chính xác chưa được khám phá trong học máy trước đây. Lưu ý rằng sử dụng m=1 cho mã hóa Huffman mức byte sẽ không nén vì các ký hiệu và mã có cùng độ dài.

Bảng 7 minh họa tính chất này bằng cách trình bày tỷ lệ nén cho các tập dữ liệu development và validation của mỗi nhiệm vụ. Sự khác biệt giữa development và validation là nhỏ mặc dù sử dụng từ điển development để nén dữ liệu validation. Những con số tỷ lệ này có thể được dịch trực tiếp sang việc giảm thời gian huấn luyện khi sử dụng đầu vào nén.

Kết quả cho các thí nghiệm mã hóa Huffman được trình bày trong bảng 6. Tất cả các thí nghiệm sử dụng tập hợp n-gram 2[0−4]={1,2,4,8,16}. Theo kết quả trước đó, mô hình không nén tốt nhất cho cấu hình này đạt được 26,22% cho phân loại văn bản, và 7,01% cho phân loại gen. Với kết quả nén tốt nhất là 26,49% và 7,76% sử dụng mã hóa Huffman mức byte với độ dài ký hiệu m=2, chúng ta biết rằng một mức nén thấp không ảnh hưởng đáng kể đến kết quả.

Mặt khác, đối với cả mã hóa Huffman mức bit và mức byte, chúng ta có thể quan sát thấy rằng kết quả trở nên tệ hơn khi sử dụng nén tích cực hơn. Điều này mang lại một sự đánh đổi tốc độ-độ chính xác độc đáo dựa trên nén đầu vào, đây là một ý tưởng chưa được khám phá trước đây trong học máy. Điều này có thể hữu ích cho các thiết bị trong môi trường tính toán và mạng hạn chế.

Nếu chúng ta so sánh giữa mã hóa Huffman mức bit có độ dài ký hiệu 1 với mức byte có độ dài 2 – tỷ lệ nén thấp nhất tương ứng – mã hóa Huffman mức byte cho kết quả tốt hơn cho tất cả các nhiệm vụ. Điều này là do việc tạo ra mã mức byte bảo tồn ranh giới byte – nghĩa là, ranh giới byte trong dữ liệu nén vẫn là ranh giới byte trong dữ liệu gốc. Mã hóa Huffman mức bit không bảo tồn ranh giới, điều này có thể thách thức cho byteSteady để hoạt động tốt.

### 5.2 Nghiên cứu Loại bỏ về Tập hợp n-Gram và Weight Decay

Bảng 8 chi tiết kết quả cho nghiên cứu loại bỏ về tập hợp n-gram và weight decay, sử dụng mã hóa Huffman mức bit có độ dài ký hiệu 1. Tương tự như nghiên cứu loại bỏ trước đó với đầu vào không nén, một tập hợp n-gram tổng hợp thường hoạt động tốt hơn so với một lựa chọn n đơn lẻ.

Tuy nhiên, không giống như trong nghiên cứu loại bỏ không nén, kết quả cho một lựa chọn n đơn lẻ không nhất thiết cải thiện khi n tăng. Trong khi đó, tập hợp n-gram tăng tuyến tính cũng không nhất thiết hoạt động tốt nhất. Những kết quả này cho thấy rằng tìm kiếm siêu tham số nên tiến hành khác nhau khi nén được sử dụng để tăng tốc byteSteady ở mức đầu vào.

## 6 KẾT LUẬN

Trong bài viết này, chúng tôi giới thiệu byteSteady – một mô hình nhanh cho phân loại sử dụng embedding n-gram mức byte. Mô hình tạo ra một vector biểu diễn bằng cách sử dụng các vector embedding trung bình của các n-gram mức byte, và đưa nó vào một bộ phân loại tuyến tính để phân loại. Mô hình giống như fastText [17], ngoại trừ cơ chế xử lý đầu vào mức byte được mã hóa cứng.

byteSteady có thể được áp dụng cho dữ liệu ngôn ngữ và phi ngôn ngữ. Trong bài viết này, chúng tôi cho thấy các thí nghiệm trong phân loại văn bản và phân loại gen. Kết quả cạnh tranh so với các baseline mạnh được đạt được. Vì byteSteady đọc đầu vào ở mức byte, nén có thể được áp dụng cho đầu vào để tăng tốc. Chúng tôi cho thấy rằng một mức nén thấp sử dụng mã hóa Huffman không ảnh hưởng đáng kể đến kết quả, và cung cấp một sự đánh đổi tốc độ-độ chính xác mới chưa được khám phá trước đây trong học máy.

Trong tương lai, chúng tôi hy vọng mở rộng byteSteady để học embedding không giám sát cho các n-gram mức byte, và sử dụng nó cho nhiều loại dữ liệu và vấn đề hơn.

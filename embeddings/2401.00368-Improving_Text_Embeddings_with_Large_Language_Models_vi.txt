# 2401.00368.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/embeddings/2401.00368.pdf
# Kích thước tệp: 506422 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Cải thiện Embedding Văn bản với Mô hình Ngôn ngữ Lớn
Liang Wang, Nan Yang, Xiaolong Huang,
Linjun Yang, Rangan Majumder, Furu Wei
Microsoft Corporation
{wangliang,nanya,xiaolhu,yang.linjun,ranganm,fuwei}@microsoft.com

Tóm tắt
Trong bài báo này, chúng tôi giới thiệu một phương pháp mới và đơn giản để có được embedding văn bản chất lượng cao chỉ bằng cách sử dụng dữ liệu tổng hợp và ít hơn 1k bước huấn luyện. Khác với các phương pháp hiện có thường phụ thuộc vào việc tiền huấn luyện trung gian đa giai đoạn với hàng tỷ cặp văn bản được giám sát yếu, tiếp theo là tinh chỉnh với một số bộ dữ liệu được gán nhãn, phương pháp của chúng tôi không yêu cầu xây dựng các pipeline huấn luyện phức tạp hay dựa vào các bộ dữ liệu được thu thập thủ công thường bị hạn chế bởi tính đa dạng của tác vụ và phạm vi ngôn ngữ. Chúng tôi tận dụng các LLM độc quyền để tạo ra dữ liệu tổng hợp đa dạng cho hàng trăm nghìn tác vụ embedding văn bản trên 93 ngôn ngữ. Sau đó, chúng tôi tinh chỉnh các LLM chỉ giải mã nguồn mở trên dữ liệu tổng hợp bằng cách sử dụng hàm mất mát đối lập tiêu chuẩn. Thí nghiệm chứng minh rằng phương pháp của chúng tôi đạt được hiệu suất mạnh trên các benchmark embedding văn bản cạnh tranh cao mà không sử dụng bất kỳ dữ liệu được gán nhãn nào. Hơn nữa, khi được tinh chỉnh với hỗn hợp dữ liệu tổng hợp và dữ liệu được gán nhãn, mô hình của chúng tôi thiết lập kết quả tiên tiến mới trên các benchmark BEIR và MTEB.

1 Giới thiệu
Embedding văn bản là các biểu diễn vector của ngôn ngữ tự nhiên mã hóa thông tin ngữ nghĩa của nó. Chúng được sử dụng rộng rãi trong nhiều tác vụ xử lý ngôn ngữ tự nhiên (NLP) khác nhau, như truy xuất thông tin (IR), hỏi đáp, tương tự văn bản ngữ nghĩa, khai thác văn bản song ngữ, gợi ý mục, v.v. Trong lĩnh vực IR, việc truy xuất giai đoạn đầu thường dựa vào embedding văn bản để triệu hồi hiệu quả một tập hợp nhỏ các tài liệu ứng cử viên từ một corpus quy mô lớn bằng cách sử dụng các kỹ thuật tìm kiếm láng giềng gần đúng. Truy xuất dựa trên embedding cũng là một thành phần quan trọng của việc tạo sinh tăng cường truy xuất (RAG) (Lewis et al., 2020), đây là một mô hình mới nổi cho phép các mô hình ngôn ngữ lớn (LLM) truy cập kiến thức bên ngoài động mà không cần sửa đổi các tham số mô hình. Gán nguồn cho văn bản được tạo ra là một ứng dụng quan trọng khác của embedding văn bản (Gao et al., 2023) có thể cải thiện tính diễn giải và độ tin cậy của các LLM.

Các nghiên cứu trước đây đã chứng minh rằng trung bình có trọng số của embedding từ được tiền huấn luyện (Pennington et al., 2014; Arora et al., 2017) là một baseline mạnh để đo lường tương tự ngữ nghĩa. Tuy nhiên, các phương pháp này không thể nắm bắt thông tin ngữ cảnh phong phú của ngôn ngữ tự nhiên. Với sự ra đời của các mô hình ngôn ngữ được tiền huấn luyện (Devlin et al., 2019), Sentence-BERT (Reimers và Gurevych, 2019) và SimCSE (Gao et al., 2021) đã được đề xuất để học embedding văn bản bằng cách tinh chỉnh BERT trên các bộ dữ liệu suy luận ngôn ngữ tự nhiên (NLI). Để nâng cao hơn nữa hiệu suất và độ bền vững của embedding văn bản, các phương pháp tiên tiến như E5 (Wang et al., 2022b) và BGE (Xiao et al., 2023) sử dụng một mô hình huấn luyện đa giai đoạn phức tạp hơn trước tiên tiền huấn luyện trên hàng tỷ cặp văn bản được giám sát yếu, sau đó tinh chỉnh trên một số bộ dữ liệu được gán nhãn chất lượng cao.

Các phương pháp đa giai đoạn hiện tại gặp phải một số nhược điểm. Thứ nhất, chúng đòi hỏi một pipeline huấn luyện đa giai đoạn phức tạp đòi hỏi nỗ lực kỹ thuật đáng kể để tuyển chọn một lượng lớn các cặp có liên quan. Thứ hai, chúng dựa vào các bộ dữ liệu được thu thập thủ công thường bị hạn chế bởi tính đa dạng của tác vụ và phạm vi bao phủ ngôn ngữ. Ví dụ, Instructor (Su et al., 2023) chỉ được huấn luyện trên các hướng dẫn từ 330 bộ dữ liệu tiếng Anh, trong khi BGE (Xiao et al., 2023) chỉ tập trung vào các ngôn ngữ có tài nguyên cao như tiếng Anh và tiếng Trung. Hơn nữa, hầu hết các phương pháp hiện tại sử dụng các bộ mã hóa kiểu BERT làm xương sống, bỏ qua những tiến bộ gần đây trong việc huấn luyện các LLM tốt hơn và các kỹ thuật liên quan như mở rộng độ dài ngữ cảnh (Rozière et al., 2023).

Trong bài báo này, chúng tôi đề xuất một phương pháp mới cho embedding văn bản tận dụng các LLM để khắc phục các hạn chế của các phương pháp hiện tại. Chúng tôi sử dụng các LLM độc quyền để tạo ra dữ liệu tổng hợp cho một loạt đa dạng các tác vụ embedding văn bản trong 93 ngôn ngữ, bao gồm hàng trăm nghìn tác vụ embedding. Cụ thể, chúng tôi sử dụng chiến lược prompting hai bước trước tiên prompting các LLM để brainstorm một nhóm các tác vụ ứng cử viên, sau đó prompting các LLM để tạo ra dữ liệu có điều kiện trên một tác vụ đã cho từ nhóm đó. Để bao gồm các tình huống ứng dụng khác nhau, chúng tôi thiết kế nhiều template prompt cho mỗi loại tác vụ và kết hợp dữ liệu được tạo ra từ các template khác nhau để tăng tính đa dạng. Đối với các mô hình embedding văn bản, chúng tôi chọn tinh chỉnh các LLM nguồn mở mạnh mẽ thay vì các mô hình kiểu BERT nhỏ. Vì các LLM như Mistral (Jiang et al., 2023) đã được tiền huấn luyện rộng rãi trên dữ liệu quy mô web, việc tiền huấn luyện đối lập được chứng minh là quan trọng đối với các mô hình BERT (Wang et al., 2022b) mang lại ít lợi ích bổ sung.

Chúng tôi chứng minh rằng Mistral-7B, khi chỉ được tinh chỉnh trên dữ liệu tổng hợp, đạt được hiệu suất cạnh tranh trên các benchmark BEIR (Thakur et al., 2021) và MTEB (Muennighoff et al., 2023). Điều này đặc biệt thú vị xem xét rằng thiết lập này không liên quan đến bất kỳ dữ liệu được gán nhãn nào. Khi được tinh chỉnh trên hỗn hợp dữ liệu tổng hợp và dữ liệu được gán nhãn, mô hình của chúng tôi đạt được kết quả tiên tiến mới, vượt trội hơn các phương pháp trước đây với biên độ đáng kể (+2%). Toàn bộ quá trình huấn luyện yêu cầu ít hơn 1k bước.

Hơn nữa, chúng tôi xác nhận thực nghiệm rằng mô hình của chúng tôi có thể hiệu quả thực hiện truy xuất passkey cá nhân hóa cho đầu vào lên đến 32k token bằng cách thay đổi cơ sở xoay của embedding vị trí, mở rộng độ dài ngữ cảnh vượt ra ngoài giới hạn 512 token thông thường. Về tính đa ngôn ngữ, mô hình của chúng tôi xuất sắc trên các ngôn ngữ có tài nguyên cao. Tuy nhiên, đối với các ngôn ngữ ít tài nguyên, vẫn còn chỗ để cải thiện vì các LLM nguồn mở hiện tại không được tiền huấn luyện đầy đủ trên chúng.

2 Công trình liên quan
Embedding văn bản là các biểu diễn liên tục có chiều thấp của văn bản và đã được áp dụng rộng rãi cho nhiều tác vụ downstream khác nhau như truy xuất thông tin, hỏi đáp, và tạo sinh tăng cường truy xuất (RAG). Công trình đầu tiên về embedding văn bản bao gồm lập chỉ mục ngữ nghĩa tiềm ẩn (Deerwester et al., 1990) và trung bình có trọng số của embedding từ (Mikolov et al., 2013). Các phương pháp gần đây hơn khai thác sự giám sát từ suy luận ngôn ngữ tự nhiên (Bowman et al., 2015) và các cặp truy vấn-tài liệu được gán nhãn, như bộ dữ liệu xếp hạng đoạn văn MS-MARCO (Campos et al., 2016), để huấn luyện embedding văn bản (Reimers và Gurevych, 2019; Conneau et al., 2017; Gao et al., 2021). Tuy nhiên, dữ liệu được gán nhãn thường bị hạn chế về tính đa dạng của tác vụ và phạm vi bao phủ ngôn ngữ. Để giải quyết thách thức này, các phương pháp như Contriever (Izacard et al., 2021), OpenAI Embeddings (Neelakantan et al., 2022), E5 (Wang et al., 2022b), và BGE (Xiao et al., 2023) áp dụng một mô hình huấn luyện đa giai đoạn. Chúng trước tiên tiền huấn luyện trên các cặp văn bản được giám sát yếu quy mô lớn sử dụng hàm mất mát đối lập và sau đó tinh chỉnh trên các bộ dữ liệu quy mô nhỏ nhưng chất lượng cao. Trong bài báo này, chúng tôi chứng minh rằng có thể có được embedding văn bản tiên tiến với huấn luyện một giai đoạn.

Dữ liệu tổng hợp Tạo ra dữ liệu tổng hợp là một chủ đề được nghiên cứu rộng rãi trong nghiên cứu truy xuất thông tin, với nhiều phương pháp khác nhau được đề xuất để nâng cao hệ thống truy xuất với dữ liệu được tạo ra một cách nhân tạo. Ví dụ, Doc2query (Nogueira et al., 2019), InPars (Bonifacio et al., 2022), và Promptagator (Dai et al., 2022) tạo ra các truy vấn tổng hợp cho các tài liệu không được gán nhãn, sau đó được tận dụng để mở rộng tài liệu hoặc huấn luyện mô hình. GPL (Wang et al., 2022a) sử dụng cross-encoder để tạo ra pseudo-label cho các cặp truy vấn-tài liệu. Tương tự, Query2doc (Wang et al., 2023) tạo ra pseudo-document để mở rộng truy vấn bằng cách prompting LLM few-shot. Khác với các phương pháp này, phương pháp của chúng tôi không dựa vào bất kỳ tài liệu hoặc truy vấn không được gán nhãn nào và do đó có thể tạo ra dữ liệu tổng hợp đa dạng hơn.

Một hướng công trình liên quan khác tập trung vào chưng cất kiến thức từ các LLM hộp đen bằng cách huấn luyện trên dữ liệu tổng hợp được tạo ra từ chúng. DINO (Schick và Schütze, 2021) tạo ra các cặp văn bản tổng hợp cho tương tự văn bản ngữ nghĩa. Unnatural Instructions (Honovich et al., 2022) là một bộ dữ liệu theo hướng dẫn tổng hợp bằng cách prompting các LLM hiện có. Orca (Mukherjee et al., 2023) và Phi (Gunasekar et al., 2023) đề xuất huấn luyện các mô hình ngôn ngữ nhỏ tốt hơn bằng cách sử dụng dữ liệu tổng hợp chất lượng cao từ GPT-3.5/4 (OpenAI, 2023).

Mô hình ngôn ngữ lớn Với sự phổ biến của ChatGPT, các mô hình ngôn ngữ lớn (LLM) đã thể hiện khả năng đáng chú ý trong việc tuân theo hướng dẫn và học trong ngữ cảnh few-shot (Brown et al., 2020). Tuy nhiên, các LLM tiên tiến nhất như GPT-4 (OpenAI, 2023) là độc quyền và có ít chi tiết kỹ thuật được tiết lộ. Để thu hẹp khoảng cách giữa các LLM độc quyền và nguồn mở, một số nỗ lực đáng chú ý đã được thực hiện, như các mô hình LLaMA-2 (Touvron et al., 2023) và Mistral (Jiang et al., 2023). Một hạn chế chính của các LLM là chúng thiếu nhận thức về các sự kiện gần đây và kiến thức riêng tư. Vấn đề này có thể được giảm thiểu một phần bằng cách tăng cường LLM với thông tin được truy xuất từ các nguồn bên ngoài, một kỹ thuật được gọi là tạo sinh tăng cường truy xuất (RAG). Mặt khác, các LLM cũng có thể phục vụ như các mô hình nền tảng để nâng cao embedding văn bản. RepLLaMA (Ma et al., 2023) đề xuất tinh chỉnh LLaMA-2 với kiến trúc bi-encoder để truy xuất ad-hoc. SGPT (Muennighoff, 2022), GTR (Ni et al., 2022b), và Udever (Zhang et al., 2023a) chứng minh luật tỷ lệ của embedding văn bản một cách thực nghiệm, nhưng hiệu suất của chúng vẫn thua kém các bộ mã hóa hai chiều nhỏ như E5 (Wang et al., 2022b) và BGE (Xiao et al., 2023). Trong bài báo này, chúng tôi trình bày một phương pháp mới để huấn luyện embedding văn bản tiên tiến bằng cách khai thác những tiến bộ mới nhất của LLM và dữ liệu tổng hợp.

--- TRANG 3 ---
Bạn đã được giao một tác vụ truy xuất: {task}
Nhiệm vụ của bạn là viết một ví dụ truy xuất văn bản cho tác vụ này ở định dạng JSON. Đối tượng JSON phải chứa các khóa sau:
  - "user_query": một chuỗi, một truy vấn tìm kiếm ngẫu nhiên của người dùng được chỉ định bởi tác vụ truy xuất.
  - "positive_document": một chuỗi, một tài liệu có liên quan cho truy vấn người dùng.
  - "hard_negative_document": một chuỗi, một tài liệu negative khó chỉ xuất hiện có liên quan đến truy vấn.
Vui lòng tuân thủ các hướng dẫn sau:
  - "user_query" nên là {query_type}, {query_length}, {clarity}, và đa dạng về chủ đề.
  - Tất cả tài liệu nên dài ít nhất {num_words} từ.
  - Cả truy vấn và tài liệu nên bằng {language}.
  … (bỏ qua một số để tiết kiệm không gian)
Đầu ra của bạn phải luôn là chỉ một đối tượng JSON, không giải thích bản thân hoặc xuất ra bất cứ thứ gì khác. Hãy sáng tạo!
{"user_query": "Cách sử dụng Microsoft Power BI để phân tích dữ liệu",
"positive_document": "Microsoft Power BI là một công cụ tinh vi đòi hỏi thời gian và thực hành để làm chủ. Trong hướng dẫn này, chúng tôi sẽ chỉ cho bạn cách điều hướng Power BI… (bỏ qua)",
"hard_negative_document": "Excel là một công cụ cực kỳ mạnh mẽ để quản lý và phân tích lượng lớn dữ liệu. Chuỗi hướng dẫn của chúng tôi tập trung vào cách bạn có thể…(bỏ qua)"}

Brainstorm một danh sách các tác vụ truy xuất văn bản có thể hữu ích.
Đây là một số ví dụ để bạn tham khảo:
    - Được cung cấp một tuyên bố khoa học làm truy vấn, truy xuất tài liệu giúp xác minh hoặc bác bỏ tuyên bố.
    - Tìm kiếm tài liệu trả lời truy vấn kiểu FAQ về dinh dưỡng trẻ em.
Vui lòng tuân thủ các hướng dẫn sau:
    - Chỉ rõ truy vấn là gì và tài liệu mong muốn là gì.
    - Mỗi tác vụ truy xuất nên bao gồm một loạt rộng các truy vấn và không nên quá cụ thể.
Đầu ra của bạn nên luôn là chỉ một danh sách python của các chuỗi, với khoảng 20 phần tử, và mỗi phần tử tương ứng với một tác vụ truy xuất riêng biệt trong một câu. Không giải thích bản thân hoặc xuất ra bất cứ thứ gì khác. Hãy sáng tạo!
["Truy xuất báo cáo tài chính của công ty cho một mã chứng khoán đã cho.",
"Được cung cấp tên sách làm truy vấn, truy xuất đánh giá, xếp hạng và tóm tắt của cuốn sách đó.",
"Tìm kiếm các bài báo nghiên cứu khoa học hỗ trợ chẩn đoán y tế cho một bệnh cụ thể."
… (bỏ qua để tiết kiệm không gian)]

phiên mới

Hình 1: Một ví dụ về template prompt hai bước để tạo ra dữ liệu tổng hợp với GPT-4. Đầu tiên chúng tôi prompt GPT-4 để brainstorm một danh sách các tác vụ truy xuất tiềm năng, sau đó tạo ra các bộ ba (truy vấn, positive, hard negative) cho mỗi tác vụ. "{...}" biểu thị một placeholder sẽ được thay thế bằng cách lấy mẫu từ một tập hợp các giá trị được định nghĩa trước. Prompt đầy đủ có sẵn trong Phụ lục C.

3 Phương pháp
3.1 Tạo dữ liệu tổng hợp
Việc sử dụng dữ liệu tổng hợp được tạo ra bởi các LLM tiên tiến như GPT-4 mang đến một cơ hội hấp dẫn, đặc biệt về mặt nâng cao tính đa dạng trên nhiều tác vụ và ngôn ngữ. Tính đa dạng như vậy là cần thiết để phát triển embedding văn bản mạnh mẽ có thể hoạt động tốt trên các tác vụ khác nhau, dù là truy xuất ngữ nghĩa, tương tự văn bản, hay phân cụm.

Để tạo ra dữ liệu tổng hợp đa dạng, chúng tôi đề xuất một taxonomy đơn giản phân loại các tác vụ embedding thành nhiều nhóm, sau đó áp dụng các template prompt khác nhau cho mỗi nhóm.

Tác vụ bất đối xứng Danh mục này bao gồm các tác vụ mà truy vấn và tài liệu có liên quan về mặt ngữ nghĩa nhưng không phải là paraphrase của nhau. Tùy thuộc vào độ dài của truy vấn và tài liệu, chúng tôi chia thêm các tác vụ bất đối xứng thành bốn nhóm con: khớp ngắn-dài, khớp dài-ngắn, khớp ngắn-ngắn, và khớp dài-dài. Ví dụ, các tác vụ khớp ngắn-dài liên quan đến truy vấn ngắn và tài liệu dài, đây là một tình huống điển hình trong các công cụ tìm kiếm thương mại. Đối với mỗi nhóm con, chúng tôi thiết kế một template prompt hai bước trước tiên prompting LLM brainstorm một danh sách các tác vụ, sau đó tạo ra một ví dụ cụ thể có điều kiện trên định nghĩa tác vụ. Trong Hình 1, chúng tôi hiển thị một prompt ví dụ cho nhóm con khớp ngắn-dài. Đầu ra đầy đủ có sẵn trong Bảng 16. Các đầu ra từ GPT-4 hầu hết đều nhất quán và có chất lượng cao. Trong các thí nghiệm sơ bộ, chúng tôi cũng cố gắng tạo ra định nghĩa tác vụ và các cặp truy vấn-tài liệu bằng cách sử dụng một prompt duy nhất, nhưng tính đa dạng của dữ liệu không được thỏa mãn như phương pháp hai bước được đề xuất.

Tác vụ đối xứng Các tác vụ đối xứng liên quan đến các truy vấn và tài liệu có nghĩa ngữ nghĩa tương tự nhưng có hình thức bề mặt khác nhau. Chúng tôi xem xét hai tình huống ứng dụng: tương tự văn bản ngữ nghĩa đơn ngôn ngữ (STS) và truy xuất văn bản song ngữ. Chúng tôi thiết kế hai template prompt riêng biệt cho mỗi tình huống, được điều chỉnh theo các mục tiêu cụ thể của chúng. Vì định nghĩa tác vụ đơn giản, chúng tôi bỏ qua bước brainstorming cho các tác vụ đối xứng.

Để tăng cường hơn nữa tính đa dạng của các prompt và do đó là dữ liệu tổng hợp, chúng tôi kết hợp một số placeholder trong mỗi template prompt, các giá trị của chúng được lấy mẫu ngẫu nhiên tại thời điểm chạy. Ví dụ, trong Hình 1, giá trị của "{query_length}" được lấy mẫu từ tập hợp "{ít hơn 5 từ, 5-10 từ, ít nhất 10 từ}".

Để tạo ra dữ liệu đa ngôn ngữ, chúng tôi lấy mẫu giá trị của "{language}" từ danh sách ngôn ngữ của XLM-R (Conneau et al., 2020), đưa ra trọng số cao hơn cho các ngôn ngữ có tài nguyên cao. Bất kỳ dữ liệu được tạo ra nào không tuân theo định dạng JSON được định nghĩa trước đều bị loại bỏ trong quá trình phân tích cú pháp. Chúng tôi cũng loại bỏ các bản sao dựa trên khớp chuỗi chính xác.

3.2 Huấn luyện
Cho một cặp truy vấn-tài liệu có liên quan (q+, d+), đầu tiên chúng tôi áp dụng template hướng dẫn sau cho truy vấn gốc q+ để tạo ra một cái mới q+inst:

q+inst = Instruct: {task_definition} \nQuery: {q+} (1)

trong đó "{task_definition}" là một placeholder cho một mô tả một câu về tác vụ embedding. Đối với dữ liệu tổng hợp được tạo ra, chúng tôi sử dụng các đầu ra từ bước brainstorming. Đối với các bộ dữ liệu khác, như MS-MARCO, chúng tôi thủ công tạo ra các định nghĩa tác vụ và áp dụng chúng cho tất cả các truy vấn trong bộ dữ liệu. Chúng tôi không sửa đổi phía tài liệu với bất kỳ tiền tố hướng dẫn nào. Theo cách này, chỉ mục tài liệu có thể được xây dựng trước, và chúng tôi có thể tùy chỉnh tác vụ cần thực hiện bằng cách chỉ thay đổi phía truy vấn.

Cho một LLM được tiền huấn luyện, chúng tôi thêm một token [EOS] vào cuối truy vấn và tài liệu, sau đó đưa chúng vào LLM để có được embedding truy vấn và tài liệu (hq+inst, hd+) bằng cách lấy vector [EOS] lớp cuối cùng. Để huấn luyện mô hình embedding, chúng tôi áp dụng hàm mất mát InfoNCE tiêu chuẩn L trên các negative trong batch và hard negative:

minL = -log(φ(q+inst, d+)) / (φ(q+inst, d+) + Σni∈N(φ(q+inst, ni))) (2)

trong đó N biểu thị tập hợp của tất cả các negative, và φ(q, d) là một hàm tính điểm khớp giữa truy vấn q và tài liệu d. Trong bài báo này, chúng tôi áp dụng hàm tương tự cosine được điều chỉnh nhiệt độ như sau:

φ(q, d) = exp(1/τ cos(hq, hd)) (3)

τ là một siêu tham số nhiệt độ, được cố định ở 0.02 trong các thí nghiệm của chúng tôi.

4 Thí nghiệm
4.1 Thống kê dữ liệu tổng hợp
Hình 2 trình bày thống kê dữ liệu tổng hợp được tạo ra của chúng tôi. Chúng tôi đã quản lý để tạo ra 500k ví dụ với 150k hướng dẫn duy nhất sử dụng Azure OpenAI Service, trong đó 25% được tạo ra bởi GPT-3.5-Turbo và những cái khác được tạo ra bởi GPT-4. Tổng tiêu thụ token là khoảng 180M. Ngôn ngữ chiếm ưu thế là tiếng Anh, với phạm vi bao phủ mở rộng đến tổng cộng 93 ngôn ngữ. Đối với 75 ngôn ngữ ít tài nguyên dưới cùng, có khoảng 1k ví dụ cho mỗi ngôn ngữ trung bình. Vui lòng xem Bảng 16 trong phụ lục để có ví dụ về dữ liệu tổng hợp.

Về mặt chất lượng dữ liệu, chúng tôi thấy rằng một phần đầu ra của GPT-3.5-Turbo không tuân thủ nghiêm ngặt các hướng dẫn được chỉ định trong các template prompt. Tuy nhiên, chất lượng tổng thể vẫn có thể chấp nhận được, và các thí nghiệm sơ bộ đã chứng minh lợi ích của việc kết hợp tập con dữ liệu này.

4.2 Tinh chỉnh và đánh giá mô hình
Checkpoint Mistral-7b được tiền huấn luyện (Jiang et al., 2023) được tinh chỉnh cho 1 epoch sử dụng hàm mất mát trong Phương trình 2. Chúng tôi tuân theo công thức huấn luyện từ RankLLaMA (Ma et al., 2023) và sử dụng LoRA (Hu et al., 2022) với rank 16. Để giảm thêm yêu cầu bộ nhớ GPU, các kỹ thuật bao gồm gradient checkpointing, huấn luyện độ chính xác hỗn hợp, và DeepSpeed ZeRO-3 được áp dụng.

Đối với dữ liệu huấn luyện, chúng tôi sử dụng cả dữ liệu tổng hợp được tạo ra và một bộ sưu tập 13 bộ dữ liệu công cộng, tạo ra khoảng 1.8M ví dụ sau khi lấy mẫu. Thêm chi tiết có sẵn trong Phụ lục A. Để cung cấp so sánh công bằng với một số công trình trước đây, chúng tôi cũng báo cáo kết quả khi sự giám sát được gán nhãn duy nhất là bộ dữ liệu xếp hạng đoạn văn MS-MARCO (Campos et al., 2016).

--- TRANG 4 ---
Chúng tôi đánh giá mô hình được huấn luyện trên benchmark MTEB (Muennighoff et al., 2023). Lưu ý rằng danh mục truy xuất trong MTEB tương ứng với 15 bộ dữ liệu có sẵn công khai trong benchmark BEIR (Thakur et al., 2021). Việc đánh giá một mô hình mất khoảng 3 ngày trên 8 GPU V100 do cần mã hóa một số lượng lớn tài liệu. Mặc dù mô hình của chúng tôi có thể xử lý độ dài chuỗi vượt quá 512, chúng tôi chỉ đánh giá trên 512 token đầu tiên để có hiệu quả. Các metric chính thức được báo cáo cho mỗi danh mục. Để biết thêm chi tiết về giao thức đánh giá, vui lòng tham khảo các bài báo gốc (Muennighoff et al., 2023; Thakur et al., 2021).

4.3 Kết quả chính
Trong Bảng 1, mô hình của chúng tôi "E5 mistral-7b + full data" đạt được điểm trung bình cao nhất trên benchmark MTEB, vượt trội hơn mô hình tiên tiến trước đây 2.4 điểm. Trong thiết lập "w/ synthetic data only", không có dữ liệu được gán nhãn nào được sử dụng để huấn luyện, và tuy nhiên hiệu suất vẫn khá cạnh tranh. Chúng tôi cho rằng việc mô hình hóa ngôn ngữ tạo sinh và embedding văn bản là hai mặt của cùng một đồng xu, với cả hai tác vụ đều yêu cầu mô hình có hiểu biết sâu sắc về ngôn ngữ tự nhiên. Cho một định nghĩa tác vụ embedding, một LLM thực sự mạnh mẽ nên có thể tự tạo ra dữ liệu huấn luyện và sau đó được chuyển đổi thành một mô hình embedding thông qua tinh chỉnh nhẹ. Các thí nghiệm của chúng tôi làm sáng tỏ tiềm năng của hướng này, và cần nhiều nghiên cứu hơn để khám phá đầy đủ nó.

Trong Bảng 3, chúng tôi cũng trình bày so sánh với một số mô hình embedding văn bản thương mại. Tuy nhiên, do thiếu tính minh bạch và tài liệu về các mô hình này, một so sánh công bằng là không khả thi. Chúng tôi tập trung đặc biệt vào hiệu suất truy xuất trên benchmark BEIR, vì việc tạo sinh tăng cường truy xuất là một kỹ thuật mới nổi để nâng cao LLM với kiến thức bên ngoài và dữ liệu độc quyền. Như Bảng 3 cho thấy, mô hình của chúng tôi vượt trội hơn các mô hình thương mại hiện tại với một biên độ đáng kể.

4.4 Truy xuất đa ngôn ngữ
Để đánh giá khả năng đa ngôn ngữ của mô hình, chúng tôi tiến hành đánh giá trên bộ dữ liệu MIRACL (Zhang et al., 2023b), bao gồm các truy vấn được chú thích bởi con người và các đánh giá mức độ liên quan trên 18 ngôn ngữ. Tập validation chứa nhãn cho 16 ngôn ngữ. Như được hiển thị trong Bảng 2, mô hình của chúng tôi vượt trội hơn mE5 large trên các ngôn ngữ có tài nguyên cao, đặc biệt là tiếng Anh. Tuy nhiên, đối với các ngôn ngữ ít tài nguyên, mô hình của chúng tôi vẫn kém tối ưu so với mE5 base. Chúng tôi cho rằng điều này là do Mistral-7B chủ yếu được tiền huấn luyện trên dữ liệu tiếng Anh, và chúng tôi dự đoán rằng các LLM đa ngôn ngữ trong tương lai sẽ tận dụng phương pháp của chúng tôi để thu hẹp khoảng cách này.

Để đánh giá khả năng truy xuất đa ngôn ngữ của mô hình, chúng tôi báo cáo kết quả khai thác văn bản song ngữ trong Bảng 4. Đối với các baseline bao gồm mContriever (Izacard et al., 2021), LaBSE (Feng et al., 2022), và mE5 (Wang et al., 2024), chúng tôi đánh giá kết quả bằng cách sử dụng các checkpoint có sẵn công khai. Các quan sát của chúng tôi chỉ ra rằng, tương tự như truy xuất MIRACL, E5mistral-7b xuất sắc trong khai thác văn bản song ngữ chỉ cho các ngôn ngữ có tài nguyên cao.

5 Phân tích
5.1 Có cần thiết phải tiền huấn luyện đối lập không?
Tiền huấn luyện đối lập được giám sát yếu là một trong những yếu tố chính đằng sau sự thành công của các mô hình embedding văn bản hiện tại. Ví dụ, Contriever (Izacard et al., 2021) coi các span được cắt ngẫu nhiên là các cặp positive để tiền huấn luyện, trong khi E5 (Wang et al., 2022b) và BGE (Xiao et al., 2023) thu thập và lọc các cặp văn bản từ nhiều nguồn khác nhau.

Phần này đánh giá lại tính cần thiết của tiền huấn luyện đối lập cho các LLM, đặc biệt là những LLM đã được tiền huấn luyện trên hàng nghìn tỷ token. Hình 3 cho thấy rằng tiền huấn luyện đối lập có lợi cho XLM-R large, nâng cao hiệu suất truy xuất của nó 8.2 điểm khi được tinh chỉnh trên cùng dữ liệu, điều này phù hợp với các phát hiện trước đây. Tuy nhiên, đối với các mô hình dựa trên Mistral-7B, tiền huấn luyện đối lập có tác động không đáng kể đến chất lượng mô hình. Điều này ngụ ý rằng việc tiền huấn luyện tự hồi quy rộng rãi cho phép các LLM có được biểu diễn văn bản tốt, và chỉ cần tinh chỉnh tối thiểu để chuyển đổi chúng thành các mô hình embedding hiệu quả.

5.2 Mở rộng sang embedding văn bản dài
Các bộ dữ liệu đánh giá hiện tại cho các mô hình embedding văn bản thường ngắn, để đánh giá khả năng ngữ cảnh dài của mô hình, chúng tôi giới thiệu một tác vụ tổng hợp mới được gọi là truy xuất passkey cá nhân hóa, được minh họa trong Hình 4. Tác vụ này yêu cầu mã hóa thông tin passkey trong một ngữ cảnh dài vào các embedding. Chúng tôi so sánh hiệu suất của các biến thể khác nhau bằng cách thay đổi kích thước cửa sổ trượt và cơ sở xoay RoPE (Su et al., 2024) trong Hình 5. Kết quả cho thấy cấu hình mặc định với cửa sổ trượt 4k đạt 100% độ chính xác trong 4k token, nhưng độ chính xác bị giảm nhanh chóng khi độ dài ngữ cảnh tăng. Việc mở rộng kích thước cửa sổ trượt một cách naiv lên 32k dẫn đến hiệu suất tệ hơn. Bằng cách thay đổi cơ sở xoay RoPE thành 10^5, mô hình có thể đạt được hơn 90% độ chính xác trong 32k token. Tuy nhiên, điều này đòi hỏi một sự đánh đổi nhỏ về hiệu suất cho các ngữ cảnh ngắn hơn. Một hướng tiềm năng cho nghiên cứu trong tương lai là thích ứng hiệu quả mô hình với các ngữ cảnh dài hơn thông qua việc hậu huấn luyện nhẹ (Zhu et al., 2023).

5.3 Phân tích các siêu tham số huấn luyện
Bảng 5 trình bày kết quả dưới các cấu hình khác nhau. Chúng tôi nhận thấy rằng khởi tạo Mistral-7B có lợi thế so với LLaMA-2 7B, phù hợp với các phát hiện từ báo cáo kỹ thuật Mistral-7B (Jiang et al., 2023). Việc lựa chọn loại pooling và rank LoRA không ảnh hưởng đáng kể đến hiệu suất tổng thể, do đó chúng tôi tuân thủ thiết lập mặc định bất chấp sự vượt trội nhỏ của LoRA rank 8. Mặt khác, cách thêm hướng dẫn có tác động đáng kể đến hiệu suất. Chúng tôi suy đoán rằng các hướng dẫn ngôn ngữ tự nhiên thông báo tốt hơn cho mô hình về tác vụ embedding trong tay, và do đó cho phép mô hình tạo ra các embedding có tính phân biệt hơn. Framework của chúng tôi cũng cung cấp một cách để tùy chỉnh hành vi của embedding văn bản thông qua các hướng dẫn mà không cần tinh chỉnh mô hình hoặc xây dựng lại chỉ mục tài liệu.

6 Kết luận
Bài báo này cho thấy rằng chất lượng của embedding văn bản có thể được cải thiện đáng kể bằng cách khai thác các LLM. Chúng tôi prompt các LLM độc quyền như GPT-4 để tạo ra dữ liệu tổng hợp đa dạng với các hướng dẫn bằng nhiều ngôn ngữ. Kết hợp với khả năng hiểu ngôn ngữ mạnh mẽ của mô hình Mistral, chúng tôi thiết lập kết quả tiên tiến mới cho gần như tất cả các danh mục tác vụ trên benchmark MTEB cạnh tranh. Quá trình huấn luyện được sắp xếp hợp lý và hiệu quả hơn nhiều so với các phương pháp đa giai đoạn hiện có, do đó loại bỏ nhu cầu tiền huấn luyện trung gian.

Đối với công việc tương lai, chúng tôi hướng đến việc cải thiện thêm hiệu suất đa ngôn ngữ của mô hình và khám phá khả năng sử dụng các LLM nguồn mở để tạo ra dữ liệu tổng hợp.

Hạn chế
So với các bộ mã hóa kiểu BERT chính thống, việc sử dụng các LLM, như Mistral-7B, cho embedding văn bản dẫn đến chi phí suy luận tăng đáng kể. Việc phát triển các GPU tiên tiến hơn và triển khai kernel tốt hơn có thể nâng cao hiệu quả của quá trình suy luận. Về mặt chi phí lưu trữ, mô hình của chúng tôi tương đối đắt hơn, với embedding 4096 chiều. Những thành công ban đầu trong việc giảm chiều embedding trong khi duy trì hiệu suất cạnh tranh đã được chứng minh thông qua các kỹ thuật như học biểu diễn Matryoshka (Kusupati et al., 2022).

Để tạo ra dữ liệu tổng hợp, chúng tôi dựa vào kỹ thuật prompt thủ công để tạo ra các đầu ra chất lượng cao từ các LLM độc quyền. Tối ưu hóa prompt tự động mang đến một hướng đầy hứa hẹn để cải thiện chất lượng dữ liệu tổng hợp.

Lời cảm ơn
Chúng tôi muốn cảm ơn các reviewer ẩn danh cho những bình luận có giá trị của họ, và các tổ chức ACL 2024 và ACL Rolling Review cho những nỗ lực của họ. Các ý kiến được bày tỏ trong bài báo này chỉ là của các tác giả và không đại diện cho quan điểm của người sử dụng lao động của họ.

--- TRANG 5 ---
[Tiếp tục phần dịch còn lại...]

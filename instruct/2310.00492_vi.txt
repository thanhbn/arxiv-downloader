# 2310.00492.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/instruct/2310.00492.pdf
# Kích thước tệp: 4275526 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Từ Mô hình hóa Ngôn ngữ đến Tuân theo Chỉ dẫn:
Hiểu về Sự thay đổi Hành vi trong LLMs sau Tinh chỉnh Chỉ dẫn
Xuansheng Wu♣*†, Wenlin Yao♡‡, Jianshu Chen♡,
Xiaoman Pan♡, Xiaoyang Wang♡, Ninghao Liu♣, Dong Yu♡
♣University of Georgia♡Tencent AI Lab, Bellevue
Tóm tắt
Các Mô hình Ngôn ngữ Lớn (LLMs) đã đạt được
thành công đáng kể, trong đó tinh chỉnh chỉ dẫn
là bước quan trọng trong việc điều chỉnh LLMs
với ý định của người dùng. Trong nghiên cứu này,
chúng tôi khảo sát cách tinh chỉnh chỉ dẫn điều
chỉnh các mô hình được tiền huấn luyện với
trọng tâm vào những thay đổi nội tại. Cụ thể,
chúng tôi đầu tiên phát triển một số phương pháp
giải thích cục bộ và toàn cục, bao gồm một phương
pháp dựa trên gradient cho việc quy kết đầu vào-
đầu ra, và các kỹ thuật để diễn giải các mẫu và
khái niệm trong các lớp tự chú ý và mạng truyền
tiến. Tác động của tinh chỉnh chỉ dẫn sau đó được
nghiên cứu bằng cách so sánh các giải thích thu
được từ các mô hình tiền huấn luyện và tinh chỉnh
chỉ dẫn. Cách tiếp cận này cung cấp một góc nhìn
nội bộ về sự thay đổi mô hình ở mức độ có thể
hiểu được bởi con người. Các phát hiện của chúng
tôi tiết lộ ba tác động đáng kể của tinh chỉnh chỉ dẫn:
1) Nó trao quyền cho LLMs nhận ra các phần chỉ dẫn
của lời nhắc người dùng, và thúc đẩy việc tạo ra
phản hồi liên tục được điều kiện hóa dựa trên các
chỉ dẫn. 2) Nó khuyến khích các đầu tự chú ý
nắm bắt nhiều mối quan hệ từ-từ hơn về các động
từ chỉ dẫn. 3) Nó khuyến khích các mạng truyền
tiến xoay kiến thức tiền huấn luyện của chúng
hướng về các nhiệm vụ định hướng người dùng.
Những hiểu biết này góp phần vào sự hiểu biết
toàn diện hơn về tinh chỉnh chỉ dẫn và đặt nền
tảng cho nghiên cứu tương lai nhằm giải thích
và tối ưu hóa LLMs cho các ứng dụng khác nhau.
Mã và dữ liệu của chúng tôi được công khai tại
https://github.com/JacksonWuxs/
Interpret_Instruction_Tuning_LLMs .

1 Giới thiệu
Khả năng mạnh mẽ của các Mô hình Ngôn ngữ Lớn
(LLMs) để phù hợp với ý định của người dùng được
công nhận rộng rãi trong các ứng dụng thực tế khác
nhau, nơi chúng được kỳ vọng trở thành các trợ lý
AI hữu ích, trung thực và vô hại (Ouyang et al., 2022;
OpenAI, 2023). Trọng tâm của những vai trò này,
việc "hữu ích" là yêu cầu cơ bản nhất, nhấn mạnh
rằng LLMs nên giúp người dùng hoàn thành các
nhiệm vụ khác nhau, được biết đến như khả năng
"tuân theo chỉ dẫn".
Nhiều nghiên cứu (Wang et al., 2022; Zhou et al.,
2023) cho thấy rằng tinh chỉnh chỉ dẫn, còn được
gọi là tinh chỉnh có giám sát, là quan trọng để có
được khả năng như vậy, bằng cách tinh chỉnh các
mô hình tiền huấn luyện trên các cặp lời nhắc-phản
hồi chất lượng cao. Tuy nhiên, tác động của tinh
chỉnh chỉ dẫn đối với tính hữu ích của các mô hình
ngôn ngữ vẫn chưa được khám phá nhiều, hạn chế
việc phát triển các trợ lý AI tốt hơn.

Trong nghiên cứu này, chúng tôi tập trung vào
việc khám phá cách tinh chỉnh chỉ dẫn thay đổi
các mô hình tiền huấn luyện. Cụ thể, các mô hình
được tinh chỉnh chỉ dẫn sử dụng các từ chỉ dẫn
để hướng dẫn việc tạo ra của chúng như thế nào
theo cách khác với các mô hình tiền huấn luyện?
Tiến xa hơn, các đầu tự chú ý và mạng truyền tiến
đóng góp vào sự khác biệt này như thế nào bằng
cách thích ứng kiến thức tiền huấn luyện của chúng,
tương ứng?

Tuy nhiên, việc trả lời kỹ thuật những câu hỏi này
bằng cách diễn giải LLMs là không đơn giản. Đối
với câu hỏi đầu tiên, chúng tôi nhằm định lượng
tầm quan trọng của các từ lời nhắc đối với các từ
phản hồi, được biết đến như giải thích quy kết.
Nghiên cứu hiện tại (Selvaraju et al., 2016; Sundararajan
et al., 2017; Mu and Andreas, 2020) được đề xuất
cho các vấn đề phân loại, không phù hợp cho các
LLMs tự hồi quy. Đối với câu hỏi thứ hai, chúng
tôi tìm cách diễn giải cả các lớp tự chú ý và truyền
tiến trong LLMs. Một phương pháp đơn giản (Dar
et al., 2022; Geva et al., 2021), chiếu các vectơ
trọng số vào không gian nhúng từ và sau đó chọn
các từ được kích hoạt nhiều nhất làm giải thích,
bị ảnh hưởng bởi tính chất đa nghĩa của trọng số
mô hình (Arora et al., 2018; Scherlis et al., 2022),
dẫn đến giải thích không rõ ràng và không súc tích.
Các nhà nghiên cứu khác đã nghiên cứu các kích
hoạt nội bộ của mô hình, như trực quan hóa bản
đồ nhiệt (Vig, 2019), phân tách bộ mã hóa tự động
thưa thớt (Bricken et al., 2023b; Cunningham et al.,
2023), và thăm dò kiến thức (Belinkov et al., 2018;
Jawahar et al., 2019), trong khi chúng có thể tạo ra
giải thích thiên vị do thiên vị tiềm ẩn trong các mẫu
được chọn để thu thập kích hoạt. Nhìn chung, các
phương pháp giải thích hiện tại không thể được
áp dụng trực tiếp cho các LLMs tự hồi quy.

Để lấp đầy những khoảng trống này, chúng tôi
đầu tiên phát triển một loạt phương pháp giải thích
như một hộp công cụ để nghiên cứu LLMs, bao
gồm một phương pháp dựa trên gradient cho việc
quy kết lời nhắc-phản hồi, và các kỹ thuật để diễn
giải các mẫu và khái niệm trong các đầu tự chú ý
và mạng truyền tiến ở mức độ có thể hiểu được
bởi con người. Sau đó chúng tôi khảo sát tác động
của tinh chỉnh chỉ dẫn bằng cách so sánh các giải
thích đến từ các mô hình tiền huấn luyện và tinh
chỉnh chỉ dẫn. Cách tiếp cận này cung cấp một
góc nhìn nội bộ về việc khám phá tinh chỉnh chỉ dẫn,
phân biệt nó với nghiên cứu hiện tại chủ yếu tập
trung vào việc so sánh hiệu suất của mô hình được
huấn luyện dưới các cài đặt khác nhau (Liang et al.,
2023; Kung and Peng, 2023; Zhou et al., 2023; Kirk
et al., 2023). Chúng tôi thu được ba phát hiện chính
về tác động của tinh chỉnh chỉ dẫn như sau:

•Phát hiện 1: Nó cho phép các mô hình nhận ra
các từ chỉ dẫn trong lời nhắc người dùng và thúc
đẩy quá trình tạo ra được điều kiện hóa liên tục
dựa trên những từ này. Chúng tôi giới thiệu một
chiến lược chuẩn hóa để làm cho các phương pháp
truyền thống dựa trên gradient phù hợp để quy kết
các từ phản hồi cho các từ lời nhắc. Chúng tôi quan
sát thấy rằng các từ chỉ dẫn, như "Fix grammar
errors:", ảnh hưởng đến nhiều từ phản hồi ở các
vị trí khác nhau, không giống như các từ khác có
tác động hạn chế đến phản hồi (Phần 4.1). Ngoài
ra, chúng tôi tận dụng một hàm mật độ để tổng hợp
tầm quan trọng tổng thể của mỗi từ lời nhắc riêng
lẻ. Điểm mật độ tầm quan trọng này được chỉ ra
định lượng có tương quan mạnh với khả năng tuân
theo chỉ dẫn của mô hình (Phần 4.2).

•Phát hiện 2: Nó khuyến khích các đầu tự chú ý
học nhiều mối quan hệ từ hơn với các động từ chỉ
dẫn so với các động từ thông thường. Chúng tôi đề
xuất trích xuất các mẫu từ-từ dưới giả định đồng
xuất hiện cục bộ để giảm thiểu thách thức đa nghĩa
trong việc diễn giải các đầu tự chú ý (Phần 5.1).
Chúng tôi nhận thấy một thay đổi đáng kể trong
các mẫu từ-từ trong cùng một đầu tự chú ý sau tinh
chỉnh chỉ dẫn. Phân tích cho thấy rằng các mẫu
từ-từ liên kết với các động từ chỉ dẫn trở nên phổ
biến hơn, đặc biệt là ở các lớp dưới và giữa, trong
khi các mẫu liên kết với các động từ thường dùng
không hiển thị sự gia tăng tương tự về độ phổ biến.
Phát hiện này chứng minh rằng các đầu tự chú ý
có ảnh hưởng trực tiếp đến việc hiểu chỉ dẫn người
dùng.

•Phát hiện 3: Nó thích ứng kiến thức tiền huấn
luyện được mã hóa bởi các mạng truyền tiến vào
các nhiệm vụ định hướng người dùng mà không
thay đổi cấu trúc ngôn ngữ học của chúng. Chúng
tôi đề xuất diễn giải các thành phần chính của các
vectơ trọng số để đạt được giải thích ở mức "khái
niệm" của các mạng truyền tiến (Phần 5.2). Phân
tích của chúng tôi về những khái niệm này bao
trùm hai chiều: nhiệm vụ định hướng người dùng¹
và mức độ ngôn ngữ học² (Thomas, 2005). Chúng
tôi phát hiện rằng tỷ lệ các khái niệm phù hợp cho
các nhiệm vụ cụ thể, như viết, lập trình, và giải
toán, trở nên lớn hơn đáng kể sau tinh chỉnh chỉ
dẫn. Ngược lại, phân bố của những khái niệm này
qua các mức độ ngôn ngữ học khác nhau vẫn giữ
nguyên. Hiện tượng này cho thấy rằng các mạng
truyền tiến thích ứng kiến thức tiền huấn luyện
của chúng với các nhiệm vụ downstream bằng cách
xoay nhẹ cơ sở của không gian biểu diễn của chúng.

Nghiên cứu này tiết lộ rằng các từ chỉ dẫn là quan
trọng đối với các mô hình tinh chỉnh chỉ dẫn do tác
động liên tục của chúng đối với quá trình tạo ra,
và tiếp tục nhấn mạnh những đóng góp đặc biệt
của cơ chế tự chú ý và mạng truyền tiến đối với
chức năng này. Trong khi trọng tâm của chúng tôi
là về những thay đổi hành vi sau tinh chỉnh chỉ dẫn,
nghiên cứu tương lai có thể cũng áp dụng hộp công
cụ của chúng tôi để hiểu LLMs cho các mục đích
khác nhau.

2 Nghiên cứu Liên quan
Diễn giải Mô hình Ngôn ngữ. Phần lớn các cuộc
điều tra về diễn giải LLMs nhằm hiểu các quá trình
ra quyết định của LLMs cho một nhiệm vụ hoặc
tập dữ liệu cụ thể, bao gồm các phương pháp quy
kết đặc trưng (Li et al., 2015; Kokalj et al., 2021),
các phương pháp dựa trên chú ý (Vig, 2019; Barkan
et al., 2021), và các phương pháp dựa trên mẫu
(Kim et al., 2018; Wu et al., 2021). Gần đây, nhiều
nhà nghiên cứu chuyển sang hiểu tại sao LLMs có
thể thực hiện học trong ngữ cảnh (Xie et al., 2021;
Olsson et al., 2022; Li et al., 2023; Wei et al., 2023;

¹Nhiệm vụ định hướng người dùng bao gồm "viết", "lập trình", "dịch thuật", và "giải toán".
²Mức độ ngôn ngữ học bao gồm "ngữ âm học", "hình thái học", "cú pháp", và "ngữ nghĩa".

--- TRANG 2 ---
Varshney et al., 2023; Xiong et al., 2023; Duan
et al., 2023). Đồng thời, một số nghiên cứu đi sâu
vào diễn giải các thành phần nội bộ của LLMs, bao
gồm cơ chế tự chú ý (Elhage et al., 2021; Sukhbaatar
et al., 2019) và mạng truyền tiến (Petroni et al.,
2019; Geva et al., 2020; Voita et al., 2023; Huang
et al., 2023). Nghiên cứu của chúng tôi xây dựng
trên những nền tảng này, giới thiệu các phương
pháp diễn giải mới được thiết kế riêng cho các
LLMs hiện đại.

Diễn giải Mô hình được Tinh chỉnh Chỉ dẫn. Việc
diễn giải tinh chỉnh chỉ dẫn vẫn đang trong giai
đoạn đầu của việc khám phá các hiện tượng bất
ngờ. Một ví dụ đáng chú ý là hiệu ứng "lost-in-
the-middle" được xác định bởi (Liu et al., 2023),
cho thấy rằng việc chèn nội dung vào giữa lời nhắc
thường dẫn đến hiệu suất mô hình kém. Tương tự,
(Zhou et al., 2023) cho thấy rằng ngay cả chỉ 1000
cặp lời nhắc-phản hồi cũng có thể nâng cao đáng
kể khả năng tuân theo chỉ dẫn của LLMs. Hơn nữa,
các nhà nghiên cứu (Liang et al., 2023; Kung and
Peng, 2023; Zhou et al., 2023) phát hiện rằng các
mô hình tinh chỉnh chỉ dẫn chỉ học các mẫu bề mặt
thông qua tinh chỉnh chỉ dẫn. Những quan sát này
thúc đẩy chúng tôi điều tra các thay đổi nội bộ của
các mô hình tinh chỉnh chỉ dẫn, nhằm đạt được sự
hiểu biết toàn diện nhận ra những hiện tượng đa
dạng này dưới một góc nhìn thống nhất.

3 Kiến thức Chuẩn bị

3.1 Ký hiệu
Để V biểu thị một tập từ vựng được định nghĩa
trước, X là một văn bản lời nhắc có độ dài N và
Y là một phản hồi có độ dài M từ một mô hình
ngôn ngữ dựa trên transformer f, trong đó mỗi
token xₙ ∈ X hoặc yₘ ∈ Y đến từ V. f được định
nghĩa trong một không gian D chiều, bắt đầu với
một nhúng từ đầu vào Eᵢ ∈ R|V|×D thể hiện các
token đầu vào trong X ∈ RN×D. X đi qua L khối
transformer, mỗi khối chứa một mô-đun tự chú ý
và một mạng truyền tiến. Mỗi mô-đun tự chú ý
bao gồm H đầu hoạt động trong một không gian
với D' chiều. Mỗi đầu tự chú ý nắm bắt mối quan
hệ từ bởi Aₕ = softmax(XWₕᵠ(XWₕᵏ)ᵀ/ε), trong
đó Wₕᵠ, Wₕᵏ ∈ RD×D' và ε là một hằng số. Việc
tổng hợp đầu ra của các đầu là [A₁XW₁ᵛ;...;AₕXWₕᵛ]Wₒ.
Mỗi mạng truyền tiến được định nghĩa là σ(XWᵤᵀ)Wₚ,
trong đó σ là một hàm phi tuyến, và Wᵤ, Wₚ ∈ RD''×D.
Cuối cùng, chúng tôi tính tích vô hướng giữa các
nhúng đã xử lý và nhúng từ đầu ra Eₒ ∈ R|V|×D
để dự đoán từ tiếp theo.

3.2 Cài đặt Thí nghiệm Chung
Mô hình Ngôn ngữ. Chúng tôi chọn họ LLaMA
(Touvron et al., 2023) làm chủ thể chính của nghiên
cứu này vì LLaMA là một trong những họ mô hình
ngôn ngữ tiền huấn luyện công khai tiên tiến nhất,
phục vụ như nền tảng của các mô hình tinh chỉnh
chỉ dẫn khác nhau. Ngoài ra, chúng tôi cũng thực
hiện thí nghiệm với họ Mistral (Jiang et al., 2023)
để chứng minh tính tổng quát của các phát hiện.

Cụ thể, chúng tôi xem xét Vicuna (Zheng et al.,
2023) và Mistral-Instruct (Jiang et al., 2023) như
các mô hình tinh chỉnh chỉ dẫn, trong khi LLaMA
(Touvron et al., 2023) và Mistral (Jiang et al., 2023)
như các mô hình tiền huấn luyện tương ứng³. Tìm
kiếm tham lam (để tái sản xuất) được sử dụng để
tạo ra tối đa 300 tokens cho mỗi lời nhắc đầu vào.

Tập dữ liệu Chỉ dẫn. Chúng tôi thu thập các văn
bản lời nhắc định hướng người dùng từ ba tập dữ
liệu công khai: Self-Instruct (Wang et al., 2022),
LIMA (Zhou et al., 2023), và MT-Bench (Zheng
et al., 2023). Tập dữ liệu Self-Instruct bao gồm 252
cặp lời nhắc và phản hồi được viết bởi con người,
được sử dụng cả để tạo ra nhiều cặp hơn và như
một tập kiểm tra. LIMA, chủ yếu dựa trên câu hỏi
và câu trả lời từ các nền tảng trực tuyến như Stack
Exchange, có 1000 cặp huấn luyện và 300 cặp kiểm
tra. Mặt khác, MT-Bench, chỉ dành cho đánh giá
máy, có 80 cặp được viết bởi con người trong tám
danh mục nhưng thiếu tập huấn luyện. Phân tích
của chúng tôi tập trung vào các tập kiểm tra từ
những tập dữ liệu này.

4 Tác động của Lời nhắc Người dùng đối với
Sự Điều chỉnh Con người

Phần này tập trung vào các chức năng khác biệt
của lời nhắc người dùng giữa các mô hình tinh
chỉnh chỉ dẫn và tiền huấn luyện. Chúng tôi giới
thiệu một cách tiếp cận quy kết dựa trên gradient
trong Phần 4.1 để đo lường tầm quan trọng của
các từ đầu vào riêng lẻ đối với các từ đầu ra cụ thể.
Trong Phần 4.2, chúng tôi so sánh mật độ tầm quan
trọng của từ qua các mô hình khác nhau để nghiên
cứu sự khác biệt của chúng trong việc sử dụng lời
nhắc người dùng.

4.1 Định lượng Ảnh hưởng của Lời nhắc đối với
Quá trình Tạo ra

Phương pháp. Chúng tôi nhằm đo lường tầm quan
trọng của mỗi token lời nhắc đối với mỗi token
phản hồi. Trong phân loại, tầm quan trọng đặc
trưng đầu vào thường được đo lường bằng cách
theo dõi thay đổi độ tin cậy khi loại bỏ nó (Ribeiro
et al., 2016; Feng et al., 2018). Do đó, coi việc tạo
văn bản như một chuỗi các nhiệm vụ phân loại từ,
tầm quan trọng của một token đầu vào đối với một
token đầu ra được đánh giá bằng cách kiểm tra thay
đổi độ tin cậy trong việc tạo đầu ra nếu token đầu
vào bị loại bỏ. Do đó, chúng tôi định nghĩa tầm
quan trọng Iₙ,ₘ của token đầu vào xₙ đối với token
đầu ra yₘ như:

Iₙ,ₘ = p(yₘ|Zₘ) - p(yₘ|Zₘ,/ₙ), (1)

trong đó Zₘ là ngữ cảnh để tạo ra yₘ bằng cách
nối lời nhắc X và m-1 tokens đầu tiên của phản
hồi Y, Zₘ,/ₙ bỏ qua token xₙ từ Zₘ, và p(·|·) là
xác suất có điều kiện được tính bởi mô hình ngôn
ngữ f. Chúng tôi tăng tốc Eq. (1) với xấp xỉ bậc
nhất: Iₙ,ₘ ≈ ∂f(yₘ|Zₘ)/∂Eᵢ[xₙ] · Eᵢ[xₙ]ᵀ, trong đó
Eᵢ[xₙ] là nhúng từ đầu vào của token xₙ (kiểm tra
Phụ lục A để biết justification lý thuyết). Tuy nhiên,
tầm quan trọng của các token đầu vào không thể
được so sánh qua các token đầu ra khác nhau do
sự phụ thuộc của nó vào độ tin cậy f(yₘ|Zₘ). Điều
quan trọng là nhận ra rằng một từ có độ tin cậy
thấp hơn không nhất thiết có nghĩa là nó là một
từ tầm thường. Cụ thể, trong mô hình hóa ngôn
ngữ, khả năng của một từ y cho trước ngữ cảnh
trước x có thể được mở rộng với định lý Bayes
như p(y|x) ∝ p(x|y) · p(y). Ở đây, các từ có ý
nghĩa (không tầm thường) có xác suất tiên nghiệm
p(y) thấp hơn vì chúng ít phổ biến hơn trong kho
ngữ liệu chung. Ngoài ra, các mô hình có xu hướng
ước tính xác suất có điều kiện p(x|y) thấp hơn vì
việc dự đoán những từ có ý nghĩa như vậy khó
khăn hơn trừ khi chúng quan sát được một mối
quan hệ ngữ nghĩa rất mạnh. Do đó, các mô hình
thường tự tin hơn về những từ phổ biến, ít có ý
nghĩa và ít tự tin hơn về những từ giàu ngữ nghĩa,
hiếm gặp. Vì vậy, chúng tôi đề xuất điều chỉnh lại
các điểm số thu được từ cùng một token đầu ra
để đảm bảo khả năng so sánh của chúng qua các
token đầu ra khác nhau. Ngoài ra, chúng tôi giới
thiệu một phép toán thưa thớt trên tầm quan trọng
được điều chỉnh lại để bỏ qua nhiễu được giới
thiệu bởi xấp xỉ bậc nhất. Cuối cùng, điểm số cặp
được chuẩn hóa là

Sₙ,ₘ = {⌈S̃ₙ,ₘ⌉ nếu S̃ₙ,ₘ > b
         {0 nếu ngược lại, (2)

trong đó S̃ₙ,ₘ = (L×Iₙ,ₘ)/(maxᴺₙ'=₁Iₙ',ₘ), ⌈·⌉ là
hàm trần, và b ∈ [0, L] là một siêu tham số xác
định mức tầm quan trọng tối thiểu quan tâm.

Cài đặt. Thí nghiệm định tính này chứng minh
cách các từ lời nhắc đóng góp vào việc tạo phản
hồi thông qua việc trực quan hóa các bản đồ nổi
bật dựa trên tầm quan trọng cặp được chuẩn hóa
Sₙ,ₘ. Chúng tôi đặt L = 10 và b = 0 để trực quan
hóa. Hình 1 cung cấp một cặp bản đồ nổi bật cho
cùng một lời nhắc tương ứng với các phản hồi do
mô hình tạo ra từ LLaMA và Vicuna, tương ứng.
Chúng tôi hiển thị thêm các trường hợp trực quan
hóa trong Phụ lục C.

Quan sát-1: Tinh chỉnh chỉ dẫn giúp các mô hình
phân biệt giữa các từ chỉ dẫn và ngữ cảnh chính
xác hơn. Chúng tôi cung cấp một trường hợp trực
quan hóa yêu cầu các mô hình phân tích giọng điệu
(chỉ dẫn) của một email đã cho (ngữ cảnh) thành
một trong các danh mục được liệt kê (nền). Cả
hai mô hình đều bắt đầu phản hồi bằng cách lặp
lại email. Sau đó, Vicuna thành công phân tích giọng
điệu của email, trong khi LLaMA thất bại trong
việc đó. Hình 1 (phải) cho thấy rằng phần chỉ dẫn
nhìn chung sáng hơn so với các phần nền và ngữ
cảnh, cho thấy ảnh hưởng mạnh mẽ của các từ
chỉ dẫn trong việc định hình việc tạo phản hồi.
Ngược lại, các dòng ngữ cảnh chỉ sáng lên ở những
khoảng cụ thể và hiển thị một mẫu đường chéo ở
nút trái dưới của cả hai hình (các mô hình đang
lặp lại email). Sự khác biệt giữa đồ thị trái và phải
làm nổi bật tác động của tinh chỉnh chỉ dẫn. Cụ
thể, đồ thị trái có một số dòng ngữ cảnh xuất hiện
ít sáng hơn trong đồ thị phải, trong khi một số dòng
chỉ dẫn trong đồ thị phải nổi bật hơn. Trực quan
hóa này đưa ra một giả thuyết rằng các từ chỉ dẫn
liên tục đóng góp vào việc tạo phản hồi nếu mô
hình thành công tuân theo ý định người dùng.
Phần 4.2 sẽ xác minh định lượng giả thuyết này.

⁴Lời nhắc in đậm các từ chỉ dẫn trực tiếp và gạch chân nền của nó: Phân tích lựa chọn từ, cách diễn đạt, dấu câu, và viết hoa trong email đã cho. Người viết email này có thể nghe như thế nào đối với người đọc? Những giọng điệu này bao gồm Nản lòng, Buộc tội, Lo lắng, Tò mò, Ngạc nhiên, Không tán thành, Khiêm tốn, Trang trọng, Quyết đoán, Tự tin, Biết ơn, Quan tâm, Buồn, Không trang trọng, Hối tiếc, Khuyến khích, Tự cao, Vui vẻ, Lạc quan, và Hào hứng. \n\nĐầu vào: Hi Jen, \nTôi hy vọng bạn khỏe. Chúng ta có thể gặp nhau hôm nay không? Tôi sẽ đánh giá cao ý kiến của bạn về bài thuyết trình của tôi cho cuộc họp ngày mai. Tôi đặc biệt muốn bạn kiểm tra lại số liệu bán hàng với tôi. Có một tách cà phê dành cho bạn!\n\nĐầu ra:

--- TRANG 3 ---
Bảng 1: Mật độ tầm quan trọng trên các từ chỉ dẫn qua các trường hợp được tuân theo và không được tuân theo từ Vicuna.
Tập dữ liệu Được tuân theo Không được tuân theo p-value
Self-Instruct 1.2283±0.52 0.8917±0.48 1.4e−4
LIMA 1.6173±0.47 1.2799±0.44 4.3e−6
MT-Bench 1.4584±0.55 0.9290±0.53 2.3e−4

4.2 Đánh giá Khả năng Tuân theo Chỉ dẫn
với Mật độ Tầm quan trọng

Phương pháp. Chúng tôi nhằm đo lường quy kết
tổng thể của mỗi token đầu vào đối với toàn bộ
quá trình tạo phản hồi. Dựa trên Phần 4.1, một
token đầu vào nên có điểm quy kết lớn hơn nếu
nó quan trọng để tạo ra nhiều token đầu ra hơn.
Theo trực giác này, quy kết của token đầu vào
xₙ được đo lường bằng cách tận dụng hàm mật
độ ℓ₁/ℓₚ trên tầm quan trọng được chuẩn hóa đối
với tất cả các token đầu ra: aₙ = ||Sₙ||₁/||Sₙ||ₚ,
trong đó Sₙ = [Sₙ,₁, ..., Sₙ,ₘ], và p ∈ R⁺ phục
vụ như một siêu tham số. Một tính chất tốt của
hàm mật độ này là nếu hai token đầu vào có cùng
tổng tầm quan trọng, thì token có tầm quan trọng
tối đa lớn hơn sẽ nhận được điểm mật độ lớn hơn
(kiểm tra (Hurley and Rickard, 2009) để biết chứng
minh).

Cài đặt. Thí nghiệm này định lượng xác minh giả
định quan sát từ Phần 4.1 rằng một mô hình phù
hợp với ý định con người nếu nó liên tục sử dụng
các từ chỉ dẫn để hướng dẫn việc tạo ra. Cụ thể,
chúng tôi chú thích thủ công một tập dữ liệu, trong
đó mỗi lời nhắc đã được đánh dấu phần chỉ dẫn
của nó, và mỗi phản hồi được gắn nhãn là "được
tuân theo" hoặc "không được tuân theo". Vui lòng
kiểm tra Phụ lục B.1 để biết chi tiết chú thích. Ở
đây, phần chỉ dẫn bao gồm các câu mô tả thông
tin nền và hành động cho một nhiệm vụ. Mặt khác,
"được tuân theo" chỉ ra rằng mô hình cung cấp
thông tin liên quan đến ý định người dùng, bất
kể tính đúng đắn thực tế của phản hồi. Đối với
mỗi cặp lời nhắc-phản hồi có nguồn từ các tập
dữ liệu của chúng tôi, chúng tôi tính điểm mật độ
tầm quan trọng với L = 10, b = 7, và p = 4. Chúng
tôi tiếp tục chuẩn hóa các điểm số để đảm bảo khả
năng so sánh qua các trường hợp khác nhau và loại
bỏ các trường hợp có phản hồi ngắn (ít hơn 5 tokens)
vì ước tính mật độ của chúng không ổn định. Bảng
1 so sánh mật độ tầm quan trọng trung bình giữa
các trường hợp được tuân theo và không được tuân
theo từ Vicuna, trong khi Bảng 2 so sánh mật độ
tầm quan trọng trung bình giữa các trường hợp
được tạo ra bởi Vicuna hoặc LLaMA.

Quan sát-2: Mật độ tầm quan trọng trên các từ
chỉ dẫn phản ánh hành vi của các mô hình trong
việc tuân theo ý định người dùng. Từ Bảng 1, rõ
ràng rằng điểm quy kết cho các trường hợp "được
tuân theo" liên tục vượt trội so với những trường
hợp "không được tuân theo" qua tất cả các tập
dữ liệu. Sự khác biệt này được xác nhận thống kê
bởi p-values thấp đáng kể, trong đó giả thuyết
không là mật độ tầm quan trọng trung bình của
các trường hợp được tuân theo lớn hơn so với
những trường hợp không được tuân theo, nhấn
mạnh một tương quan mạnh giữa điểm mật độ
tầm quan trọng trên các từ chỉ dẫn và khả năng
tuân theo chỉ dẫn. Các nghiên cứu trường hợp
trong Phụ lục B.2 cho rằng các mô hình tinh chỉnh
chỉ dẫn có thể giả vờ tuân theo chỉ dẫn mà không
nhận ra chỉ dẫn người dùng. Phụ lục B.3 tiếp tục
nhấn mạnh rằng quan sát này không thể được
giải thích đơn giản bởi thực tế rằng các từ chỉ dẫn
thường xuất hiện ở đầu hoặc cuối lời nhắc.

Bảng 2: Mật độ tầm quan trọng trên các từ chỉ dẫn qua các phản hồi được tạo ra bởi Vicuna và LLaMA.
Tập dữ liệu Vicuna LLaMA p-value
Self-Instruct 1.1302±0.54 0.9394±0.48 1.9e−5
LIMA 1.5579±0.49 1.2683±0.43 2.5e−14
MT-Bench 1.3440±0.60 1.1777±0.58 0.0382

Quan sát-3: Các mô hình tinh chỉnh chỉ dẫn đạt
được mật độ tầm quan trọng lớn hơn so với các
đối tác tiền huấn luyện của chúng. Bảng 2 báo
cáo mật độ tầm quan trọng trung bình trên các từ
chỉ dẫn bằng cách đưa ra các phản hồi được tạo
ra bởi Vicuna hoặc LLaMA. Chúng tôi quan sát
thấy rằng Vicuna liên tục gán điểm mật độ tầm
quan trọng dày đặc hơn trên các từ chỉ dẫn so với
LLaMA qua ba tập dữ liệu, trong đó hai trong số
chúng có ý nghĩa thống kê (p < 0.05). Ở đây, giả
thuyết không là mật độ tầm quan trọng trung bình
được tính bởi các phản hồi được tạo ra bởi Vicuna
lớn hơn so với LLaMA. Theo Quan sát-2, chúng
tôi rút ra kết luận rằng Vicuna thể hiện khả năng
tuân theo chỉ dẫn tốt hơn so với LLaMA bằng cách
xác định chính xác hơn các từ chỉ dẫn và sau đó
thành công sử dụng chúng để hướng dẫn quá trình
tạo phản hồi của nó.

5 Sự thay đổi trong Mô hình được Tinh chỉnh Chỉ dẫn

Phần này nghiên cứu những đóng góp đặc biệt
của các thành phần trong LLMs đối với việc điều
chỉnh con người. Các đầu tự chú ý và mạng truyền
tiến được thảo luận trong Phần 5.1 và 5.2, tương ứng.

5.1 Phân tích Các đầu Tự chú ý

Phương pháp. Chúng tôi nhằm diễn giải hành vi
của các đầu tự chú ý với các cặp từ. Để W[d] biểu
thị hàng thứ d của ma trận W. Cho một đầu tự
chú ý với trọng số Wₕᵠ, Wₕᵏ, mối quan hệ giữa
một cặp từ (wₐ, wᵦ) được tính như Aₐ,ᵦ ∝ ∑ᴰᵈ⁼¹Eᵢ[wₐ](Wₕᵠᵀ[d])ᵀ×

--- TRANG 4 ---
[Hình 2: Sự khác biệt của các mẫu từ-từ giữa Vicuna và LLaMA ở mức neuron và head.]

Ei[wb](Wh⊤k[d])⊤. Dar et al. (2022) tính điểm chú ý giữa các từ từ toàn bộ từ vựng V dựa trên Whq và Whk, và chọn cặp từ top-K với điểm số lớn nhất để diễn giải đầu tự chú ý thứ h. Tuy nhiên, chúng tôi nhận thấy rằng các cặp từ thu được bằng phương pháp này là dư thừa, dẫn đến hiểu biết ít toàn diện hơn về đầu tự chú ý.

Để khắc phục vấn đề này, chúng tôi đề xuất diễn giải một đầu tự chú ý bằng cách tổng hợp các cặp từ được kích hoạt bởi các cặp neuron của nó, được thúc đẩy bởi thực tế rằng mối quan hệ Aa,b liên hệ tuyến tính với các kích hoạt của các vectơ cột của trọng số Whq và Whk, được gọi là "neurons" trong bài báo này. Nhưng phương pháp này gặp phải tính chất đa nghĩa của neurons (Elhage et al., 2022; Bricken et al., 2023a), giới thiệu các cặp từ vô nghĩa để được kết nối. Xem xét cơ chế tự chú ý được thiết kế để nắm bắt mối quan hệ từ trong cùng văn bản đầu vào, chúng tôi giới thiệu một ràng buộc đồng xuất hiện để tạo thành các cặp từ. Cụ thể, chúng tôi đầu tiên diễn giải neurons Wh⊤q[d] và Wh⊤k[d] bằng cách thu thập top-K từ có thể kích hoạt chúng nhiều nhất, tức là Edq = argmaxV'⊆V,|V'|=K∑w∈V'Ei[w]·(Wh⊤q[d])⊤ và Edk = argmaxV'⊆V,|V'|=K∑w∈V'Ei[w]·(Wh⊤k[d])⊤. Sau đó chúng tôi tạo thành danh sách cặp từ Edqk = {(wq, wk) : cos(eq, ek) > θ} cho wq ∈ Edq, wk ∈ Edk, trong đó eq, ek là nhúng GloVe của chúng (Pennington et al., 2014), và θ là một ngưỡng. Giải thích cuối cùng của một đầu tự chú ý được rút ra từ các cặp từ mức neuron thường xuyên của nó.

Cài đặt. Chúng tôi xem xét K = 100 như một hằng số và θ như các giá trị động cho các từ khác nhau. Cụ thể, chúng tôi đầu tiên tính độ tương tự cosine giữa từ đã cho và 1000 từ thường xuyên với nhúng từ GloVe của chúng. Ngưỡng của một từ là độ tương tự trung bình của nó cộng 1.96 lần độ lệch chuẩn của nó, và cái lớn hơn trong hai từ là của một cặp từ. Chúng tôi thực hiện phân tích định tính về các cặp từ trong Phụ lục F.

Tác động của tinh chỉnh chỉ dẫn lên các đầu tự chú ý được nghiên cứu bằng cách so sánh danh sách cặp từ từ các mô hình tiền huấn luyện và tinh chỉnh. Đầu tiên, chúng tôi định lượng những thay đổi của danh sách cặp từ với tỷ lệ giao nhau M = |Ept∩Eft|/|Ept∪Eft|, trong đó Ept và Eft biểu thị top-100 cặp từ của các mô hình tiền huấn luyện và tinh chỉnh. Hình 2 trực quan hóa 1−M qua các nhóm lớp khác nhau. Chúng tôi cũng điều tra cách những cặp từ thay đổi này liên quan đến khả năng tuân theo chỉ dẫn, tập trung vào động từ. Cụ thể, chúng tôi xác định 45 động từ chỉ dẫn (ví dụ: "write", "create", và "classify") dựa trên (Wang et al., 2022; Ouyang et al., 2022), và cũng tập hợp một tập kiểm soát của 3000 động từ thường xuyên (Speer, 2022). Đối với mỗi động từ, chúng tôi tính tỷ lệ đầu tự chú ý mã hóa nhiều cặp từ hơn cho động từ đó sau tinh chỉnh chỉ dẫn. Chúng tôi chỉ xem xét những đầu tự chú ý thay đổi số lượng cặp từ cho động từ sau tinh chỉnh chỉ dẫn và báo cáo kết quả trong Bảng 3.

Bảng 3: Tỷ lệ phần trăm đầu tự chú ý mã hóa các động từ nhất định sau tinh chỉnh chỉ dẫn.
Họ Lớp Chỉ dẫn Chung p-value
LLaMA1-8 65.96±26.96 49.61±31.89 0.0050
9-16 62.30±32.80 50.72±32.26 0.1330
17-24 52.15±39.44 50.87±30.35 0.8785
25-32 43.49±35.82 48.71±29.96 0.4856
Mistral1-8 68.92±30.18 52.72±28.59 0.0114
9-16 55.62±41.82 51.84±27.24 0.6700
17-24 66.92±31.75 52.95±28.44 0.0643
25-32 57.04±38.75 52.13±27.79 0.5697

Quan sát-4: Tinh chỉnh chỉ dẫn thay đổi đáng kể các đầu tự chú ý. Hình 2 cho thấy rằng khi độ sâu lớp tăng, sự khác biệt giữa danh sách cặp từ trở nên đáng kể hơn. Điều này không chỉ minh họa tác động đáng kể của tinh chỉnh chỉ dẫn lên các đầu tự chú ý, mà còn cho thấy rằng phương pháp được đề xuất có thể nắm bắt các mối quan hệ từ-từ đa dạng được mã hóa bởi lớp tự chú ý.

Quan sát-5: Tinh chỉnh chỉ dẫn mã hóa nhiều động từ chỉ dẫn hơn trong các đầu tự chú ý thấp hơn. Bảng 3 chứng minh rằng tinh chỉnh chỉ dẫn đáng kể tăng xu hướng của các đầu tự chú ý của họ LLaMA, đặc biệt là trong các lớp thấp hơn (1-8) và giữa (9-16), để mã hóa các mẫu từ-từ liên kết với động từ chỉ dẫn. Sự nâng cao này có ý nghĩa thống kê (p <0.05) trong 8 lớp đầu tiên. Ngược lại, khoảng 50% đầu tự chú ý thể hiện xu hướng tương tự đối với động từ chung, trong khi 50% đề cập đến tác động trung tính, có nghĩa là không tăng cũng không giảm mối quan hệ từ cho các động từ đã cho. Mặt khác, tất cả các lớp của họ Mistral mã hóa nhiều cặp từ hơn với động từ chỉ dẫn, có thể là lý do cho khả năng tuân theo chỉ dẫn mạnh hơn của Mistral. Nhìn chung, sự khác biệt này chỉ ra rằng tinh chỉnh chỉ dẫn dạy tự chú ý xác định các chỉ dẫn chi tiết khác nhau.

5.2 Phân tích Mạng Truyền tiến

Phương pháp. Chúng tôi nhằm diễn giải kiến thức của mạng truyền tiến ở mức khái niệm. Chúng tôi coi mỗi mạng truyền tiến σ(XWu⊤)Wp như bộ nhớ khóa-giá trị (Geva et al., 2020), trong đó mỗi vectơ hàng của Wu và Wp lưu trữ một mẫu văn bản. Tuy nhiên, những mẫu văn bản (neurons) này thường đa nghĩa (Elhage et al., 2022; Bricken et al., 2023a), khiến mỗi mẫu văn bản không được diễn giải trong một ý nghĩa súc tích (Geva et al., 2021). Do đó, chúng tôi đề xuất tìm kiếm một tập các vectơ trực giao nắm bắt các hướng chính mà những mẫu này lan rộng. Chính thức, cho các mẫu Wp, chúng tôi xây dựng ma trận hiệp phương sai như C = W̃p⊤W̃p, trong đó W̃p là ma trận tập trung của Wp với các cột có trung bình bằng không. Sau đó các vectơ cơ sở trực giao V của những mẫu này thỏa mãn:

CV = ΛV, (3)

trong đó mỗi vectơ cột của V ∈ RD×D có độ dài đơn vị, Λ = diag([λ1, ..., λD]), và λ1 ≥ ... ≥ λD ≥ 0. Trong ngữ cảnh này, trọng tâm chính của chúng tôi nằm ở top-R giá trị của Λ cùng với các vectơ cột tương ứng trong V. Điều này là do thực tế rằng chúng hiển thị các hướng chính của các mẫu được mã hóa từ Wp. Sau đó chúng tôi chiếu nhúng từ Eo vào mỗi hướng chính và tìm top-K từ liên quan để diễn giải:

Er = argmaxV'∈V,|V'|=K∑w∈V'V⊤[r]Eo[w],

trong đó V⊤[r] là vectơ cột thứ r của V, Eo[w] là nhúng từ đầu ra của w. Vì V⊤[r] là một vectơ đơn vị, V⊤[r]Eo[w] đo lường độ dài chiếu của vectơ từ theo hướng này. Do đó, việc biểu diễn vectơ này với các từ có độ dài chiếu lớn nhất là tự nhiên, và danh sách từ có thể được tóm tắt thêm như một mô tả văn bản bởi người chú thích hoặc máy.

Cài đặt. Chúng tôi tạo một từ vựng mới bắt nguồn từ ShareGPT (RyokoAI, 2023) để làm cho các từ ứng viên V dễ hiểu hơn so với một số lượng lớn sub-tokens từ từ vựng tích hợp LLaMA. Sau đó chúng tôi phân tích 300 vectơ cơ sở đầu tiên của mỗi mạng truyền tiến từ LLaMA và Vicuna với top 15 từ liên quan của chúng.

Bảng 4: Diễn giải mạng truyền tiến cuối cùng của Vicuna với phương pháp phân tách được đề xuất.
Mô tả Từ
viết tắt y tế CBT, RTK, RT, RH, HRV, MT, ...
bắt đầu với "the" the, theological, theology, ...
thuật ngữ có dấu gạch ngang one-of-a-kind, state-of-the-art, ...
số sha256, tt, 8266, 768, 1986, ...

ChatGPT⁵ được xem xét là người chú thích máy cho thí nghiệm này. Bảng 4 cung cấp danh sách từ mẫu và mô tả của chúng. Nhiều trường hợp hơn có sẵn trong Phụ lục E.3. Cài đặt chi tiết và thống kê của mô tả khái niệm được hiển thị trong Phụ lục D.2. Chúng tôi thảo luận kết quả của các thành phần chính trong Phụ lục E.1.

Để nghiên cứu sự tiến hóa của kiến thức tiền huấn luyện, chúng tôi tóm tắt các nhiệm vụ từ nghiên cứu trước (Zheng et al., 2023; Ouyang et al., 2022) thành các kịch bản bao gồm viết, toán, lập trình, và dịch thuật. Sau đó chúng tôi xác định kịch bản nào một khái niệm có thể được sử dụng (xem Phụ lục D). Lưu ý rằng một số khái niệm có thể phù hợp với nhiều kịch bản. Ngoài ra, chúng tôi sắp xếp các khái niệm thành ngữ âm học⁶, hình thái học⁷, cú pháp, hoặc ngữ nghĩa các mức ngôn ngữ học dựa trên các ngành trong chủ đề ngôn ngữ học (Thomas, 2005). Bảng 6 hiển thị tỷ lệ phần trăm kiến thức cho các kịch bản và mức ngôn ngữ học khác nhau.

Quan sát-6: Các vectơ chính của trọng số của mạng truyền tiến cung cấp hiểu biết mức khái niệm về kiến thức được mã hóa. Chúng tôi chọn bốn thành phần chính đại diện và giải thích của chúng từ mạng truyền tiến cuối cùng của Vicuna và hiển thị chúng trong Bảng 4. Nhiều trường hợp hơn có sẵn trong Bảng 11 và 12. Trong Bảng 4, các mô tả của bốn vectơ chính bao trùm các chủ đề đa dạng, từ y tế ("viết tắt y tế") đến ngôn ngữ học ("bắt đầu với the"). Đáng chú ý, khái niệm viết tắt y tế nổi bật, vì thường khó để người chú thích xác định mức độ liên quan y tế của chúng. Điều này chỉ ra ưu điểm của việc sử dụng người chú thích máy cho kiến thức rộng lớn của chúng. Trùng hợp, Phụ lục D.2 cho thấy rằng khoảng 60% trong số 300 thành phần chính đầu tiên từ các lớp giữa của Vicuna có thể được diễn giải bởi ChatGPT. Bằng chứng này xác minh thực nghiệm cơ sở lý luận để phân tích mạng truyền tiến với phương pháp được đề xuất.

⁵Chúng tôi sử dụng ChatGPT-turbo-3.5-0613 trong nghiên cứu này.
⁶Ngữ âm học nghiên cứu hệ thống âm thanh, ví dụ từ có âm "le": brittle, tackle, chuckle, pickle.
⁷Hình thái học nghiên cứu cấu trúc từ, ví dụ từ có tiền tố "sub-": subarray, subculture, subway.

--- TRANG 5 ---
Bảng 5: Phân bố khái niệm của họ LLaMA qua các kịch bản người dùng và mức ngôn ngữ học khác nhau.
Danh mục Vicuna LLaMA p-value
Kịch bản Viết 53.50±.46 51.47±.92 0.0154
Lập trình 29.45±.43 28.64±.48 0.0350
Toán 5.21±.36 5.04±.33 0.5193
Dịch thuật 25.30±.39 26.27±.70 0.0411
Ngôn ngữ học Ngữ âm học 1.18±.11 1.15±.07 0.6251
Hình thái học 17.16±.49 16.83±.60 0.4223
Cú pháp 7.16±.31 7.52±.50 0.2551
Ngữ nghĩa 74.70±.65 74.66±.67 0.9394

Quan sát-7: Tinh chỉnh chỉ dẫn chuyển các vectơ chính của mạng truyền tiến hướng về các nhiệm vụ định hướng người dùng mà không di chuyển chúng qua các mức ngôn ngữ học. Bảng 6 tiết lộ rằng Vicuna mã hóa nhiều khái niệm hơn LLaMA cho các nhiệm vụ viết, lập trình, và toán, với sự khác biệt trong viết và lập trình có ý nghĩa thống kê (p <0.05), trong đó giả thuyết không là tỷ lệ kiến thức của một danh mục nhất định bằng nhau sau tinh chỉnh chỉ dẫn. Tuy nhiên, các khái niệm cho dịch thuật ít hơn sau tinh chỉnh, cho thấy rằng kiến thức đa ngôn ngữ bị quên. Mặc dù chúng ta có thể quan sát những thay đổi từ góc nhìn người dùng, nó vẫn giữ nguyên từ góc nhìn ngôn ngữ học. Đặc biệt, Vicuna và LLaMA hiển thị phân bố gần như giống hệt qua bốn mức ngôn ngữ học mà không có ý nghĩa thống kê (p >0.05), cho rằng tinh chỉnh chỉ dẫn không thay đổi phân bố kiến thức tiền huấn luyện qua các mức ngôn ngữ học. Phụ lục E.2 cho thấy cùng quan sát trên họ Mistral.

Quan sát-8: Tỷ lệ kiến thức ngữ nghĩa đầu tiên tăng và sau đó giảm từ các lớp dưới lên trên, trong khi kiến thức hình thái học thì ngược lại. Hình 3 hiển thị cách các khái niệm từ các mức ngôn ngữ học khác nhau được phân bố qua các lớp. Đầu tiên, không có sự thay đổi phân bố đáng chú ý giữa Vicuna và LLaMA, phù hợp với Quan sát-7. Một quan sát đáng chú ý là xu hướng hình "U" ngược của kiến thức ngữ nghĩa, được phản chiếu bởi hình "U" thường xuyên của hình thái học. Mẫu này đáng ngạc nhiên, đặc biệt vì các nghiên cứu trước trong thị giác máy tính cho rằng các đặc trưng cơ bản được trích xuất ở các lớp dưới, và kiến thức tổng hợp được học ở các lớp trên (Zeiler and Fergus, 2014; Selvaraju et al., 2016). Tuy nhiên, vì LLaMA là một mô hình sinh, mẫu bất thường này có một số ý nghĩa. Cụ thể, chúng tôi phỏng đoán rằng LLaMA học nhiều kiến thức hình thái học hơn (ví dụ: mẫu tiền tố và hậu tố) ở vài lớp cuối để mô phỏng cấu trúc cây tiền tố (Fredkin, 1960; Giancarlo, 1995; Paladhi and Bandyopadhyay, 2008; Shan et al., 2012). Bằng cách đó, LLaMA có thể sử dụng ít tham số hơn để ghi nhớ nhiều cụm từ hơn để hoàn thành nhiệm vụ dự đoán từ tiếp theo. Chúng tôi để lại các khám phá cho nghiên cứu tương lai.

[Hình 3: Phân bố khái niệm ở các mức ngôn ngữ học qua các lớp mô hình khác nhau.]

6 Thảo luận
Các phát hiện của chúng tôi cung cấp một góc nhìn độc đáo để phù hợp với các nghiên cứu gần đây. 1) Tầm quan trọng của sự đa dạng lời nhắc được làm nổi bật bởi cả chúng tôi và (Zhou et al., 2023; Wang et al., 2022). Vì ba phát hiện của chúng tôi cho rằng tinh chỉnh chỉ dẫn liên kết mô hình tiền huấn luyện với các nhiệm vụ người dùng, chúng ta có thể mong đợi sự phù hợp tốt hơn với ý định con người nếu mô hình được tiếp xúc với lời nhắc rộng hơn. 2) Hiệu quả của việc huấn luyện tự chú ý với ưu tiên đầu tiên (tinh chỉnh LoRA) (Taori et al., 2023; Juletx, 2023) được chứng thực bởi Phát hiện-1 và Phát hiện-2. Cụ thể, Phát hiện-1 minh họa khả năng phân biệt từ chỉ dẫn là cần thiết cho việc tuân theo chỉ dẫn, trong khi Phát hiện-2 nhấn mạnh rằng các đầu tự chú ý trực tiếp học mối quan hệ chỉ dẫn. 3) Ưu điểm của việc huấn luyện mạng truyền tiến (tinh chỉnh đầy đủ) (Sun et al., 2023) rõ ràng từ Phát hiện-2 và Phát hiện-3, cho thấy rằng mạng truyền tiến cập nhật kiến thức của chúng hướng về các nhiệm vụ người dùng.

7 Kết luận
Bài báo này trình bày một phân tích toàn diện về tinh chỉnh chỉ dẫn cho việc điều chỉnh ý định người dùng bằng cách so sánh định lượng và định tính các giải thích hậu kiểm giữa các mô hình tiền huấn luyện và tinh chỉnh. Các phát hiện của chúng tôi chỉ ra rằng tinh chỉnh chỉ dẫn liên kết mô hình tiền huấn luyện với ý định người dùng, bao gồm mã hóa nhiều kiến thức về từ chỉ dẫn trong tự chú ý, và xoay kiến thức chung từ mạng truyền tiến hướng về việc sử dụng của người dùng. Đáng đề cập rằng hộp công cụ diễn giải được sử dụng trong nghiên cứu này cũng có thể hỗ trợ nghiên cứu chung tương lai về LLMs.

8 Hạn chế
Nghiên cứu này nhằm điều tra tác động của tinh chỉnh chỉ dẫn lên các mô hình ngôn ngữ tiền huấn luyện về mặt điều chỉnh con người. Một ràng buộc chính của nghiên cứu này là hộp công cụ giải thích được giới thiệu được phát triển dựa trên tính khả dụng của trọng số mô hình và gradient, cho thấy một cách tiếp cận hộp trắng. Do đó, những công cụ này có thể không hoàn toàn hiệu quả để phân tích các mô hình tinh chỉnh chỉ dẫn hộp đen, như ChatGPT (Bai et al., 2022) và Claude (Anthropic, 2023). Chúng tôi sẽ tìm cách nâng cao hộp công cụ của mình bằng cách kết hợp các phương pháp phù hợp cho phân tích mô hình hộp đen trong tương lai. Mặt khác, một công nghệ chính khác liên quan đến điều chỉnh con người cho LLMs là Học tăng cường với Phản hồi Con người (RLHF) (Stiennon et al., 2020; Bai et al., 2022), đây là một khía cạnh khác không được đề cập trong bài viết này. Chúng tôi khuyến khích các nhà nghiên cứu áp dụng hộp công cụ của chúng tôi để nghiên cứu các mô hình tinh chỉnh RLHF và khám phá các vai trò khác nhau của tinh chỉnh chỉ dẫn và RLHF cho điều chỉnh con người.

9 Tác động Đạo đức
Nghiên cứu này sử dụng các mô hình tiền huấn luyện LLaMA (Touvron et al., 2023) và Mistral (Jiang et al., 2023) cũng như các biến thể Vicuna (Zheng et al., 2023) và Mistral-Instruct (Jiang et al., 2023), dưới giấy phép sử dụng học thuật tương ứng của chúng. Việc sử dụng những mô hình này tuân thủ các điều khoản cụ thể của chúng, tập trung độc quyền vào mục đích học thuật. Ngoài ra, nghiên cứu của chúng tôi kết hợp bốn tập dữ liệu: Self-Instruct (Wang et al., 2022), LIMA (Zhou et al., 2023), MT-Bench (Zheng et al., 2023), và ShareGPT (RyokoAI, 2023), mỗi tập dưới điều kiện sử dụng riêng của nó. Những điều kiện này bao gồm tuân thủ các tiêu chuẩn bảo vệ quyền riêng tư và dữ liệu. Trong việc trình bày các phát hiện của chúng tôi, chúng tôi đã đảm bảo nghiêm ngặt rằng không có định danh cá nhân nào được tiết lộ và nội dung vẫn không có tài liệu xúc phạm, phù hợp với thực hành nghiên cứu đạo đức.

Tài liệu Tham khảo
Anthropic. 2023. Model Card and Evaluations for Claude Models.

Sanjeev Arora, Yuanzhi Li, Yingyu Liang, Tengyu Ma, and Andrej Risteski. 2018. Linear algebraic structure of word senses, with applications to polysemy. Transactions of the Association for Computational Linguistics, 6:483–495.

Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al. 2022. Training a helpful and harmless assistant with reinforcement learning from human feedback. arXiv preprint arXiv:2204.05862.

Oren Barkan, Edan Hauon, Avi Caciularu, Ori Katz, Itzik Malkiel, Omri Armstrong, and Noam Koenigstein. 2021. Grad-sam: Explaining transformers via gradient self-attention maps. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management, pages 2882–2887.

Yonatan Belinkov, Lluís Màrquez, Hassan Sajjad, Nadir Durrani, Fahim Dalvi, and James Glass. 2018. Evaluating layers of representation in neural machine translation on part-of-speech and semantic tagging tasks. arXiv preprint arXiv:1801.07772.

Trenton Bricken, Adly Templeton, Joshua Batson, Brian Chen, Adam Jermyn, Tom Conerly, Nicholas L Turner, Cem Anil, Carson Denison, Amanda Askell, Robert Lasenby, Yifan Wu, Shauna Kravec, Nicholas Schiefer, Tim Maxwell, Nicholas Joseph, Alex Tamkin, Karina Nguyen, Brayden McLean, Josiah E Burke, Tristan Hume, Shan Carter, Tom Henighan, and Chris Olah. 2023a. Decomposing Language Models With Dictionary Learning.

Trenton Bricken, Adly Templeton, Joshua Batson, Brian Chen, Adam Jermyn, Tom Conerly, Nick Turner, Cem Anil, Carson Denison, Amanda Askell, et al. 2023b. Towards monosemanticity: Decomposing language models with dictionary learning. transformer circuits thread, 2023.

Hoagy Cunningham, Aidan Ewart, Logan Riggs, Robert Huben, and Lee Sharkey. 2023. Sparse autoencoders find highly interpretable features in language models. arXiv preprint arXiv:2309.08600.

Guy Dar, Mor Geva, Ankit Gupta, and Jonathan Berant. 2022. Analyzing transformers in embedding space. arXiv preprint arXiv:2209.02535.

Jinhao Duan, Hao Cheng, Shiqi Wang, Chenan Wang, Alex Zavalny, Renjing Xu, Bhavya Kailkhura, and Kaidi Xu. 2023. Shifting attention to relevance: Towards the uncertainty estimation of large language models. arXiv preprint arXiv:2307.01379.

Nelson Elhage, Tristan Hume, Catherine Olsson, Nicholas Schiefer, Tom Henighan, Shauna Kravec, Zac Hatfield-Dodds, Robert Lasenby, Dawn Drain, Carol Chen, et al. 2022. Toy models of superposition. arXiv preprint arXiv:2209.10652.

Nelson Elhage, Neel Nanda, Catherine Olsson, Tom Henighan, Nicholas Joseph, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, et al. 2021. A mathematical framework for transformer circuits. Transformer Circuits Thread, 1.

Shi Feng, Eric Wallace, Alvin Grissom II, Mohit Iyyer, Pedro Rodriguez, and Jordan Boyd-Graber. 2018. Pathologies of neural models make interpretations difficult. arXiv preprint arXiv:1804.07781.

--- TRANG 6 ---
Edward Fredkin. 1960. Trie memory. Communications of the ACM, 3(9):490–499.

Mor Geva, Roei Schuster, Jonathan Berant, and Omer Levy. 2020. Transformer feed-forward layers are key-value memories. arXiv preprint arXiv:2012.14913.

Mor Geva, Roei Schuster, Jonathan Berant, and Omer Levy. 2021. Transformer feed-forward layers are key-value memories. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 5484–5495.

Raffaele Giancarlo. 1995. A generalization of the suffix tree to square matrices, with applications. SIAM Journal on Computing, 24(3):520–562.

Jing Huang, Atticus Geiger, Karel D'Oosterlinck, Zhengxuan Wu, and Christopher Potts. 2023. Rigorously assessing natural language explanations of neurons. arXiv preprint arXiv:2309.10312.

Niall Hurley and Scott Rickard. 2009. Comparing measures of sparsity. IEEE Transactions on Information Theory, 55(10):4723–4741.

Ganesh Jawahar, Benoît Sagot, and Djamé Seddah. 2019. What does bert learn about the structure of language? In ACL 2019-57th Annual Meeting of the Association for Computational Linguistics.

Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. 2023. Mistral 7b. arXiv preprint arXiv:2310.06825.

Juletx. 2023. Alpaca-lora. https://github.com/tloen/alpaca-lora.

Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas, et al. 2018. Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav). In International conference on machine learning, pages 2668–2677. PMLR.

Robert Kirk, Ishita Mediratta, Christoforos Nalmpantis, Jelena Luketina, Eric Hambro, Edward Grefenstette, and Roberta Raileanu. 2023. Understanding the effects of rlhf on llm generalisation and diversity. arXiv preprint arXiv:2310.06452.

Enja Kokalj, Blaž Škrlj, Nada Lavrač, Senja Pollak, and Marko Robnik-Šikonja. 2021. Bert meets shapley: Extending shap explanations to transformer-based classifiers. In Proceedings of the EACL Hackashop on News Media Content Analysis and Automated Report Generation, pages 16–21.

Po-Nien Kung and Nanyun Peng. 2023. Do models really learn to follow instructions? an empirical study of instruction tuning. arXiv preprint arXiv:2305.11383.

Jiwei Li, Xinlei Chen, Eduard Hovy, and Dan Jurafsky. 2015. Visualizing and understanding neural models in nlp. arXiv preprint arXiv:1506.01066.

Zongxia Li, Paiheng Xu, Fuxiao Liu, and Hyemi Song. 2023. Towards understanding in-context learning with contrastive demonstrations and saliency maps. arXiv preprint arXiv:2307.05052.

Shihao Liang, Kunlun Zhu, Runchu Tian, Yujia Qin, Huadong Wang, Xin Cong, Zhiyuan Liu, Xiaojiang Liu, and Maosong Sun. 2023. Exploring format consistency for instruction tuning. arXiv preprint arXiv:2307.15504.

Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2023. Lost in the middle: How language models use long contexts. arXiv preprint arXiv:2307.03172.

Beren Millidge and Sid Black. 2022. The singular value decompositions of transformer weight matrices are highly interpretable. https://www.alignmentforum.org/.

Jesse Mu and Jacob Andreas. 2020. Compositional explanations of neurons. Advances in Neural Information Processing Systems, 33:17153–17163.

Catherine Olsson, Nelson Elhage, Neel Nanda, Nicholas Joseph, Nova DasSarma, Tom Henighan, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, et al. 2022. In-context learning and induction heads. arXiv preprint arXiv:2209.11895.

R OpenAI. 2023. Gpt-4 technical report. arXiv, pages 2303–08774.

Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35:27730–27744.

Sibabrata Paladhi and Sivaji Bandyopadhyay. 2008. Generation of referring expression using prefix tree structure. In Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-II.

Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. 2023. Instruction tuning with gpt-4. arXiv preprint arXiv:2304.03277.

Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pages 1532–1543.

Fabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander H Miller, and Sebastian Riedel. 2019. Language models as knowledge bases? arXiv preprint arXiv:1909.01066.

--- TRANG 7 ---
Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. "why should i trust you?" explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pages 1135–1144.

RyokoAI. 2023. Sharegpt52k. Huggingface Datasets.

Adam Scherlis, Kshitij Sachan, Adam S Jermyn, Joe Benton, and Buck Shlegeris. 2022. Polysemanticity and capacity in neural networks. arXiv preprint arXiv:2210.01892.

Ramprasaath R Selvaraju, Abhishek Das, Ramakrishna Vedantam, Michael Cogswell, Devi Parikh, and Dhruv Batra. 2016. Grad-cam: Why did you say that? arXiv preprint arXiv:1611.07450.

Y Shan, X Chen, Y Shi, and J Liu. 2012. Fast language model look-ahead algorithm using extended n-gram model. Acta Automatica Sinica, 38(10):1618–1626.

Robyn Speer. 2022. rspeer/wordfreq: v3.0.

Bills Steven, Cammarata Nick, Mossing Dan, Tillman Henk, Gao Leo, Goh Gabriel, Sutskever Ilya, Leike Jan, Wu Jeff, and Saunders William. 2022. Language models can explain neurons in language models. https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html.

Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul F Christiano. 2020. Learning to summarize with human feedback. Advances in Neural Information Processing Systems, 33:3008–3021.

Sainbayar Sukhbaatar, Edouard Grave, Guillaume Lample, Herve Jegou, and Armand Joulin. 2019. Augmenting self-attention with persistent memory. arXiv preprint arXiv:1907.01470.

Xianghui Sun, Yunjie Ji, Baochang Ma, and Xiangang Li. 2023. A comparative study between full-parameter and lora-based fine-tuning on chinese instruction data for instruction following large language model. arXiv preprint arXiv:2304.08109.

Mukund Sundararajan, Ankur Taly, and Qiqi Yan. 2017. Axiomatic attribution for deep networks. In International conference on machine learning, pages 3319–3328. PMLR.

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B Hashimoto. 2023. Alpaca: A strong, replicable instruction-following model. Stanford Center for Research on Foundation Models. https://crfm.stanford.edu/2023/03/13/alpaca.html, 3(6):7.

James J Thomas. 2005. Illuminating the path:[the research and development agenda for visual analytics]. IEEE Computer Society.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288.

Neeraj Varshney, Wenlin Yao, Hongming Zhang, Jianshu Chen, and Dong Yu. 2023. A stitch in time saves nine: Detecting and mitigating hallucinations of llms by validating low-confidence generation. arXiv preprint arXiv:2307.03987.

Jesse Vig. 2019. Bertviz: A tool for visualizing multihead self-attention in the bert model. In ICLR workshop: Debugging machine learning models, volume 23.

Elena Voita, Javier Ferrando, and Christoforos Nalmpantis. 2023. Neurons in large language models: Dead, n-gram, positional. arXiv preprint arXiv:2309.04827.

Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2022. Self-instruct: Aligning language model with self generated instructions. arXiv preprint arXiv:2212.10560.

Jerry Wei, Jason Wei, Yi Tay, Dustin Tran, Albert Webson, Yifeng Lu, Xinyun Chen, Hanxiao Liu, Da Huang, Denny Zhou, et al. 2023. Larger language models do in-context learning differently. arXiv preprint arXiv:2303.03846.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. 2019. Huggingface's transformers: State-of-the-art natural language processing. arXiv preprint arXiv:1910.03771.

Tongshuang Wu, Marco Tulio Ribeiro, Jeffrey Heer, and Daniel S Weld. 2021. Polyjuice: Generating counterfactuals for explaining, evaluating, and improving models. arXiv preprint arXiv:2101.00288.

Sang Michael Xie, Aditi Raghunathan, Percy Liang, and Tengyu Ma. 2021. An explanation of in-context learning as implicit bayesian inference. arXiv preprint arXiv:2111.02080.

Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, Junxian He, and Bryan Hooi. 2023. Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms. arXiv preprint arXiv:2306.13063.

Matthew D Zeiler and Rob Fergus. 2014. Visualizing and understanding convolutional networks. In Computer Vision–ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I 13, pages 818–833. Springer.

Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2024.

--- TRANG 8 ---
Judging llm-as-a-judge with mt-bench and chatbot arena. Advances in Neural Information Processing Systems, 36.

Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena.

Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al. 2023. Lima: Less is more for alignment. arXiv preprint arXiv:2305.11206.

--- TRANG 9 ---
A Chứng minh Xấp xỉ Tuyến tính cho Điểm Tầm quan trọng

Chúng tôi chứng minh rằng phương trình In,m = p(ym|Zm) - p(ym|Zm,/n) ≈ ∂f(ym|zm)/∂Ei[xn] · Ei[xn]⊤ với phần mở rộng Taylor bậc nhất. p(ym|Zm) được viết như f(ym|Zm), trong đó f là mô hình ngôn ngữ, Zm ∈ R(N+m-1)×d là nhúng từ của chuỗi token đầu vào Zm = [x1, ..., xN, y1, ..., ym-1], và nhúng từ d chiều của token w ∈ Zm được định nghĩa là Ei[w]. Do đó, đầu tiên chúng ta có In,m = f(ym|Zm) - f(ym|Zm,/n), trong đó chúng ta để vectơ hàng thứ n của Zm,/n bằng không.

Phần mở rộng Taylor bậc nhất của f(ym|Zm) quanh Zm,/n là
f(ym|Zm) ≈ f(ym|Zm,/n) + ∂f(ym|Zm)/∂Zm|Zm,/n · (Zm - Zm,/n)⊤.

Vì sự khác biệt giữa Zm,/n và Zm chỉ là hàng thứ n, số hạng Zm - Zm,/n chỉ là vectơ Ei[xn]. Do đó, phương trình trên có thể được đơn giản hóa như:
f(ym|Zm) ≈ f(ym|Zm,/n) + ∂f(ym|Zm)/∂Ei[xn] · Ei[xn]⊤.

Đưa xấp xỉ này vào định nghĩa của In,m, chúng ta có In,m ≈ ∂f(ym|Zm)/∂Ei[xn] · Ei[xn]⊤.

B Phân tích Mật độ Tầm quan trọng

B.1 Cài đặt Thí nghiệm

Đối với mỗi văn bản lời nhắc được thu thập từ ba tập dữ liệu công khai, chúng tôi để Vicuna và LLaMA tạo ra phản hồi tương ứng (Phần 3.2); sau đó chúng tôi xác định thủ công các câu chỉ dẫn từ mỗi lời nhắc đầu vào và chú thích liệu phản hồi có cung cấp thông tin hữu ích ("được tuân theo") hay không ("không được tuân theo"). Về hiệu quả tính toán, việc tạo ra mật độ tầm quan trọng cho một trường hợp đơn lẻ cần khoảng 100 giây, sử dụng hai GPU Nvidia A6000.

Chú thích chỉ dẫn và ngữ cảnh. Cụ thể, chỉ dẫn thường mô tả ý định người dùng với một số nền (tùy chọn), có thể rất dài⁸ hoặc rất ngắn gọn⁹. Lưu ý rằng chúng tôi chú thích các từ chỉ dẫn ở mức câu, và các từ mẫu như "Input:" và "Output:" không được xem xét. Đối với một số lời nhắc, các từ chỉ dẫn có thể được phân bố ở cả đầu và cuối văn bản đầu vào, và chúng tôi sẽ xem xét chúng cùng nhau. Trong số những câu chỉ dẫn này, chúng tôi định nghĩa phần còn lại của lời nhắc đầu vào là các từ ngữ cảnh, không cần thiết cho văn bản lời nhắc đầu vào.

Chú thích Phản hồi Được tuân theo hoặc Không được tuân theo. Chúng tôi xem xét tính hữu ích của phản hồi như khả năng tuân theo chỉ dẫn được mô tả bởi (Ouyang et al., 2022). Do đó, nếu một phản hồi hữu ích cho người dùng, thì chúng tôi gắn nhãn nó với "được tuân theo". Cụ thể, chúng tôi xem xét bốn mức độ hữu ích: L1 - mô hình đang nói ngẫu nhiên hoặc chỉ lặp lại chính nó; L2 - mô hình cung cấp một số thông tin có thể được sử dụng để trả lời câu hỏi, nhưng mô hình thất bại trong việc tổ chức tốt; L3 - mô hình tạo ra phản hồi nhìn chung tuân theo lời nhắc, nhưng thiếu một số chỉ dẫn chi tiết; L4 - phản hồi hoàn hảo như phản hồi của con người. Trong nghiên cứu của chúng tôi, chúng tôi xem xét các phản hồi từ L2 đến L4 là "được tuân theo". Lưu ý rằng chúng tôi không quan tâm đến vấn đề ảo giác trong nghiên cứu của chúng tôi.

B.2 Nghiên cứu Trường hợp về Các ngoại lệ

Các mô hình tinh chỉnh chỉ dẫn có thể giả vờ tuân theo chỉ dẫn. Hình 4 trực quan hóa bản đồ nổi bật của một trường hợp liên quan đến cải thiện viết (vui lòng xem chú thích để biết chi tiết). Phản hồi của Vicuna giải quyết lỗi ngữ pháp và sửa đổi cấu trúc câu để cải thiện độ rõ ràng. Một quan sát chính từ hình là chỉ có ba token chỉ dẫn đầu tiên hướng dẫn việc tạo phản hồi (Hộp Đỏ). Cụ thể, ba từ đầu tiên là "The sentence you", có vẻ không phải là động từ chỉ dẫn chính như "Rewrite" từ câu thứ hai. Ngoài ra, một số từ từ phần ngữ cảnh được hoạt động như từ chỉ dẫn (Hộp Xanh), đó là "\nInput:" và "\nOutput:" từ mẫu lời nhắc. Đây là những từ nên được xem xét như từ chỉ dẫn vì chúng không cung cấp ý định người dùng. Ngoài ra, một đường chéo đặc biệt trải dài phần ngữ cảnh, gợi ý xu hướng của mô hình để lặp lại ngữ cảnh từ nội dung trước đó. Hình này cho rằng mô hình đang tận dụng khả năng mô hình hóa ngôn ngữ vốn có thay vì xác định và hành động theo các chỉ dẫn đã cho. Do đó, chúng tôi chỉ ra rằng việc đánh giá khả năng tuân theo chỉ dẫn chỉ dựa trên tương quan giữa lời nhắc đầu vào và phản hồi đầu ra có thể không cung cấp phản ánh chính xác về hành vi nội bộ của mô hình, trong khi

⁸Một chỉ dẫn dài: "Các nền tảng truyền thông xã hội ảnh hưởng như thế nào đến cách mọi người tiêu thụ và chia sẻ tin tức, và những tác động tiềm ẩn đối với việc lan truyền thông tin sai lệch là gì?"
⁹Một chỉ dẫn ngắn: "sang tiếng Anh:"

--- TRANG 10 ---
[Hình 4: CaseID: Self-Instruct-1 Lời nhắc: Câu mà bạn được đưa có thể quá dài dòng, phức tạp, hoặc không rõ ràng. Viết lại câu và làm cho bài viết của bạn rõ ràng hơn bằng cách giữ nó súc tích. Bất cứ khi nào có thể, chia câu phức tạp thành nhiều câu và loại bỏ các từ không cần thiết.\n\nĐầu vào: Nếu bạn có bất kỳ câu hỏi nào về tỷ lệ của tôi hoặc nếu bạn thấy cần thiết phải tăng hoặc giảm phạm vi cho dự án này, xin hãy cho tôi biết.\n\nĐầu ra: Vicuna: Bạn có câu hỏi nào về tỷ lệ của tôi hoặc bạn cần điều chỉnh phạm vi dự án không? Xin hãy cho tôi biết.]

nó vẫn là một chiến lược phổ biến để phát triển mô hình Phần thưởng cho quá trình RLHF (Ouyang et al., 2022).

Tuy nhiên, chúng tôi đã xác định một số trường hợp mà mật độ tầm quan trọng của chúng tôi thất bại. Điều này chủ yếu do hàm mật độ của chúng tôi thiếu nhận thức vị trí. Ví dụ, trong Hình 5, toàn bộ đầu vào người dùng bao gồm các từ chỉ dẫn. Bản đồ cho rằng những từ này đóng vai trò quan trọng trong việc hướng dẫn việc tạo ra, ngay cả đối với phần sau của phản hồi. Dưới giả thuyết của chúng tôi, có vẻ như mô hình đang tuân theo chỉ dẫn người dùng. Tuy nhiên, Vicuna dường như chỉ lặp lại lời nhắc đầu vào một cách lặp đi lặp lại, dẫn đến các mẫu đường chéo lặp lại. Chúng tôi khuyến nghị nghiên cứu tương lai giải quyết thiếu sót này, bằng cách áp dụng hàm mật độ có nhận thức vị trí hoặc bằng cách tích hợp bước để xác định và xử lý phản hồi lặp lại sớm.

B.3 Khám phá Vị trí Lời nhắc với Mật độ Tầm quan trọng

Cài đặt. Mỗi văn bản lời nhắc đầu vào từ các tập dữ liệu của chúng tôi được chia thành các câu riêng lẻ, với mỗi câu được chia thêm thành bốn phân đoạn cùng độ dài. Chúng tôi chuẩn hóa điểm mật độ cho một câu bằng cách chia cho tổng của chúng và sau đó tích lũy chúng cho mỗi phân đoạn. Tỷ lệ quy kết trung bình cho mỗi phân đoạn trong các câu đầu vào được mô tả trong Hình 6.

Kết quả. Hình 6 hiển thị mật độ tầm quan trọng được phân bố trên các phân đoạn khác nhau của câu đầu vào. Cả mô hình tiền huấn luyện và tinh chỉnh đều tiết lộ hình "U" đáng chú ý qua tất cả các tập dữ liệu. Điều này cũng được biết đến như hiệu ứng "lost in the middle" (Liu et al., 2023), trong đó họ cho thấy rằng các mô hình SOTA có thể bỏ qua đầu vào trung tâm. Không giống như trọng tâm của họ trên một nhiệm vụ duy nhất, phân tích của chúng tôi được dựa trên điểm mật độ tầm quan trọng của chúng tôi trên các văn bản lời nhắc đa dạng, cho rằng vấn đề này tồn tại phổ biến và nội tại. Khi so sánh mô hình tiền huấn luyện với mô hình tinh chỉnh, chúng tôi phát hiện hình "U" sắc nét hơn ở trước, trở nên ít rõ ràng hơn sau tinh chỉnh chỉ dẫn.

C Trực quan hóa Bản đồ Nổi bật

C.1 Cài đặt Thí nghiệm

Trái ngược với các ví dụ được hiển thị trong nội dung chính, sử dụng phản hồi vàng, trọng tâm của chúng tôi ở đây là về các kết nối giữa đầu vào người dùng và đầu ra mô hình. Để đạt được điều này, chúng tôi tạo ra phản hồi từ LLaMA và Vicuna, theo giao thức được đặt ra trong Phần 3.2. Sau đó, chúng tôi rút ra các bản đồ nổi bật theo kỹ thuật được giới thiệu trong Phần 4.1.

Để đảm bảo các bản đồ cung cấp mô tả chính xác về quá trình tạo ra, chúng tôi đặt L = 10 và b = 0. Trục dọc của mỗi bản đồ biểu thị các văn bản lời nhắc, trong khi trục ngang tượng trưng cho các phản hồi được tạo ra. Cường độ của mỗi điểm dữ liệu tương ứng với cường độ liên kết giữa các token đầu vào và đầu ra tương ứng, với các điểm sáng hơn cho thấy mối quan hệ mạnh hơn (trực quan hóa với màu sắc tốt nhất).

C.2 Kết quả Thí nghiệm

Hình 9-14 xác nhận đánh giá định tính của chúng tôi rằng các từ chỉ dẫn trong đầu vào người dùng là quan trọng trong việc hướng dẫn quá trình tạo ra. Rõ ràng rằng mỗi từ ngữ cảnh thường có ảnh hưởng hạn chế đến phản hồi. Tổng thể, những bản đồ nổi bật này nhấn mạnh tính hợp lệ của quy kết đầu vào, đạt được bằng cách đánh giá mật độ của điểm tầm quan trọng thưa thớt và được chuẩn hóa.

D Mở rộng với Công cụ Tự động

Chúng tôi xây dựng dựa trên những tiến bộ gần đây trong diễn giải tự động, sử dụng các mô hình ngôn ngữ lớn tiên tiến (Taori et al., 2023; Peng et al., 2023; Steven et al., 2022) để mô phỏng người chú thích trong việc tạo ra diễn giải cấp cao. Bằng cách tận dụng người chú thích máy, chúng tôi có thể dễ dàng mở rộng phương pháp của mình để phân tích toàn bộ mô hình, cung cấp kết quả vững chắc hơn cho các phát hiện của chúng tôi.

D.1 Cài đặt Thí nghiệm

Cấu hình Tạo ra. Chúng tôi sử dụng ChatGPT¹⁰ như người chú thích máy của chúng tôi. Các thí nghiệm của chúng tôi sử dụng mô hình gpt-3.5-turbo-0613 với siêu tham số top-p=0.9 cho lấy mẫu hạt nhân. Để giảm thiểu tính biến đổi trong đầu ra mô hình ngôn ngữ, chúng tôi lặp lại thí nghiệm năm lần. Trong mỗi lần lặp, chúng tôi đầu tiên tóm tắt top-K từ của một vectơ cơ sở cụ thể thành một khái niệm riêng biệt, sau đó xác định các nhiệm vụ định hướng người dùng và mức ngôn ngữ học liên kết với những khái niệm này. Đối với tương tác đầu tiên của chúng tôi với ChatGPT, nhiệt độ được đặt thành 0—có nghĩa là chiến lược tìm kiếm tham lam. Trong các tương tác tiếp theo, chúng tôi đặt nhiệt độ thành 1. Tuy nhiên, khi xác định nhiệm vụ và mức độ, chúng tôi luôn duy trì nhiệt độ ở 0.0.

Thiết kế Lời nhắc. Diễn giải tự động hiệu quả phụ thuộc vào các lời nhắc được thiết kế tốt. Chúng tôi thiết kế tỉ mỉ những lời nhắc này bằng ba chiến lược: nhập vai, ví dụ hội thoại trong ngữ cảnh, và độc quyền các ví dụ chất lượng cao.

Mẫu-1: Mô tả từ với các khái niệm súc tích. Top-15 từ được kích hoạt nhiều nhất đến từ phương pháp được trình bày trong Phần 5.2 sẽ được nối trực tiếp vào mẫu này.

Hệ thống: Bạn là một người diễn giải neuron cho mạng neuron. Mỗi neuron tìm kiếm một khái niệm/chủ đề/chủ đề/hành vi/mẫu cụ thể. Nhìn vào một số từ mà neuron kích hoạt và tóm tắt trong một khái niệm/chủ đề/chủ đề/hành vi/mẫu duy nhất mà neuron đang tìm kiếm. Đừng liệt kê ví dụ về từ và giữ tóm tắt của bạn súc tích nhất có thể. Nếu bạn không thể tóm tắt hơn một nửa số từ đã cho trong một khái niệm/chủ đề/chủ đề/hành vi/mẫu rõ ràng, bạn nên nói 'Cannot Tell'.

Người dùng: Từ: January, terday, cember, April, July, September, December, Thursday, quished, November, Tuesday.
Đại lý: ngày tháng.

Người dùng: Từ: B., M., e., R., C., OK., A., H., D., S., J., al., p., T., N., W., G., a.C., or, St., K., a.m., L..
Đại lý: viết tắt và từ viết tắt.

Người dùng: Từ: actual, literal, real, Real, optical, Physical, REAL, virtual, visual.
Đại lý: nhận thức về thực tế.

Người dùng: Từ: Go, Python, C++, Java, c#, python3, cuda, java, javascript, basic.
Đại lý: ngôn ngữ lập trình.

Người dùng: Từ: 1950, 1980, 1985, 1958, 1850, 1980, 1960, 1940, 1984, 1948.
Đại lý: năm.

Người dùng: Từ:

¹⁰https://platform.openai.com/docs/guides/gpt

--- TRANG 11 ---
Mẫu-2: Xác định các nhiệm vụ định hướng người dùng có thể áp dụng. Các khái niệm được tóm tắt được nối vào mẫu này. Chúng tôi kiểm tra nhiệm vụ viết thành ba nhiệm vụ vì ChatGPT thường coi gần như mọi khái niệm đều phù hợp cho viết. Chúng tôi coi bất kỳ nhiệm vụ chi tiết nào trong số này như mục đích chính của viết.

Hệ thống: Khái niệm đã cho có thể được sử dụng cho nhiệm vụ trợ lý nào sau đây?\n\nNhiệm vụ: viết hàng ngày, viết văn học, viết chuyên nghiệp, giải toán, lập trình, dịch thuật. Trả về 'None' nếu nó không thể được sử dụng cho bất kỳ nhiệm vụ nào ở trên. Nếu nó có thể được sử dụng cho nhiều nhiệm vụ, liệt kê tất cả và phân tách bằng ';'.

Người dùng: Khái niệm: Từ là thẻ bài đăng truyền thông xã hội.
Đại lý: viết hàng ngày

Người dùng: Khái niệm: Từ là mã Latex để vẽ biểu đồ cột nhóm.
Đại lý: viết chuyên nghiệp

Người dùng: Khái niệm: Từ là từ nước ngoài hoặc tên.
Đại lý: dịch thuật

Người dùng: Khái niệm: Từ là URLs.
Đại lý: None

Người dùng: Khái niệm: Từ là từ liên quan đến tệp cấu hình và địa chỉ web.
Đại lý: lập trình

Người dùng: Khái niệm: Từ là từ vần.
Đại lý: viết văn học

Người dùng: Khái niệm: Từ là lệnh và thuật ngữ lập trình.
Đại lý: lập trình

Người dùng: Khái niệm: Từ là

Mẫu-3: Xác định mức ngôn ngữ học. Bất kỳ khái niệm tóm tắt tự động nào sẽ được nối trực tiếp vào mẫu này.

Hệ thống: Bạn là một nhà ngôn ngữ học. Phân loại khái niệm được cung cấp vào một trong các danh mục sau: Ngữ âm học, Hình thái học, Cú pháp, và Ngữ nghĩa.

Người dùng: Khái niệm: Từ là ngày tháng.
Đại lý: ngữ nghĩa

Người dùng: Khái niệm: Từ là nhận thức về thực tế.
Đại lý: Ngữ nghĩa

Người dùng: Khái niệm: Từ là viết tắt và từ viết tắt.
Đại lý: Hình thái học

Người dùng: Khái niệm: Từ là liên quan đến hành động hoặc hoạt động.
Đại lý: Cú pháp

Người dùng: Khái niệm: Từ là viết tắt y tế.
Đại lý: Ngữ nghĩa

Người dùng: Khái niệm: Từ là URLs.
Đại lý: Hình thái học

Người dùng: Khái niệm: Từ là động từ.
Đại lý: Cú pháp

Người dùng: Khái niệm: Từ là tính từ.
Đại lý: Cú pháp

Người dùng: Khái niệm: Từ là từ vần.
Đại lý: Ngữ âm học

Người dùng: Khái niệm: Từ là ngôn ngữ lập trình.
Đại lý: Ngữ nghĩa

Người dùng: Khái niệm: Từ là

D.2 Kết quả Thí nghiệm

Hình 7 minh họa tỷ lệ danh sách từ có thể được cảm ứng thành một khái niệm súc tích bởi người chú thích máy của chúng tôi. Theo mẫu của chúng tôi, nếu "Cannot Tell" tồn tại trong mô tả danh sách từ, chúng tôi xem xét rằng khái niệm này đã thất bại trong việc được diễn giải. Chúng tôi đã quan sát thấy rằng các mô hình Vicuna và LLaMA hiển thị mức độ diễn giải tương đương, không có sự khác biệt đáng kể giữa chúng. Một xu hướng đáng chú ý xuất hiện khi số lượng lớp tăng: khả năng giải thích các khái niệm được mã hóa của chúng được cải thiện. Cụ thể, trong các lớp 24-28, tỷ lệ diễn giải trung bình cho 30 khái niệm đầu tiên đạt đỉnh ở 91.67%. Tỷ lệ diễn giải cao này nhấn mạnh hiệu quả của phương pháp được đề xuất của chúng tôi. Nó có thể truyền đạt một cách thích hợp trong văn bản rõ ràng, súc tích kiến thức được mã hóa bởi những mô hình này. Tuy nhiên, có một cảnh báo: kiến thức được mã hóa gần hơn với lớp đầu ra, cụ thể giữa các lớp 28-32, trở nên khó khăn hơn để làm rõ. Thú vị, thách thức cụ thể này không có mặt khi áp dụng công cụ diễn giải tự động cho GPT-2 (Mil-

[Hình 7: % danh sách từ được biểu diễn từ các vectơ cơ sở xếp hạng cao với mô tả súc tích.]

lidge and Black, 2022), cho thấy hành vi giữa mô hình nhỏ và lớn là khác nhau. Ngoài ra, các phát hiện của chúng tôi chỉ ra xu hướng giảm trong khả năng diễn giải cho các khái niệm được xếp hạng xa hơn. Nhìn chung, những kết quả này xác nhận hiệu quả của phương pháp được đề xuất của chúng tôi trong việc phân tích kiến thức được mã hóa trong các mô hình.

Bảng 7-10 liệt kê các từ trải qua những thay đổi tần suất đáng kể nhất sau tinh chỉnh chỉ dẫn, chúng tôi cũng hiển thị sự thay đổi của thứ hạng theo sau. Những từ này là từ có ý nghĩa (ít nhất bốn ký tự và không phải từ dừng) được trích xuất từ mô tả khái niệm được tạo ra bởi người chú thích máy của chúng tôi. Từ các bảng, một số từ, đáng chú ý "language", "programming", và "process", hiển thị những thay đổi đáng kể về tần suất sau tinh chỉnh chỉ dẫn. Thuật ngữ ngôn ngữ học ("Spanish", "translation") và thuật ngữ kỹ thuật ("method", "programming" và "software") thể hiện những thay đổi đáng chú ý ở các lớp khác nhau. Thú vị, "language" liên tục xuất hiện ở gần như mỗi nhóm lớp, với tần suất của nó cả tăng và giảm. Quan sát này chỉ ra rằng các lớp khác nhau chịu trách nhiệm mã hóa các danh mục kiến thức khác nhau. Cụ thể, các lớp dưới chịu trách nhiệm lưu trữ kiến thức cơ bản hơn ("behavior", "operation", "adjective"), các lớp giữa chịu trách nhiệm học kiến thức trừu tượng hơn ("functions/methods", "programming", "software development"), và các lớp cao hơn chịu trách nhiệm học kiến thức hơn cho việc tạo văn bản hiệu quả ("start with", "rhyming", "sound", "letter"). Rộng rãi, việc đề cập tăng lên của các từ liên quan đến các kịch bản người dùng sau tinh chỉnh nhấn mạnh trọng tâm tinh tế của mô hình về các nhiệm vụ và ứng dụng tập trung vào người dùng.

[Hình 8: Phương sai được giải thích tích lũy của mạng truyền tiến từ Vicuna.]

Bảng 6: Phân bố khái niệm của họ Mistral qua các kịch bản người dùng và mức ngôn ngữ học khác nhau.
Danh mục Mistral-Inst Mistral p-value
Kịch bản Viết 53.53±.56 54.10±.58 0.1953
Lập trình 31.90±.34 29.72±.31 1.4e−5
Toán 5.31±.27 4.75±.13 0.0051
Dịch thuật 23.33±.98 24.07±.59 0.2351
Ngôn ngữ học Ngữ âm học 0.70±.11 0.57±.05 0.0670
Hình thái học 19.08±.27 19.44±.20 0.0648
Cú pháp 5.89±.56 5.20±.65 0.1450
Ngữ nghĩa 74.51±.63 74.91±.69 0.4163

E Diễn giải Mạng Truyền tiến

E.1 Chi tiết về Kết quả PCA

Hình 8 hiển thị phương sai được giải thích tích lũy trung bình của các thành phần chính được phân tách qua 32 lớp, trong đó vùng trong suốt chỉ ra độ lệch chuẩn của chúng. Vì LLaMA và Vicuna hiển thị đường gần như chính xác giống nhau, chúng tôi bỏ qua LLaMA từ hình này. Từ hình, chúng tôi có một số quan sát. Đầu tiên, chúng tôi thấy rằng phương sai được giải thích tích lũy tăng mượt mà, trong đó gần một nửa các vectơ cơ sở có thể giải thích khoảng 80% phương sai. Quan sát này chứng minh rằng những neuron này không tập trung vào biểu đạt một vài đặc trưng nhất định, nhấn mạnh sự đa dạng của các đặc trưng ẩn đã học. Ngoài ra, mũi tên đen chỉ ra rằng phương sai được giải thích tích lũy của 300 vectơ cơ sở là khoảng 22.49%, trong đó 300 là số lượng vectơ cơ sở chúng tôi nghiên cứu trong nghiên cứu này. Nó xác nhận rằng top 300 tham số được mong đợi có thể diễn giải vì phương sai được giải thích tích lũy của chúng chỉ là 22.49%.

E.2 Phân tích Phân bố Khái niệm với Họ Mistral

Theo thảo luận của chúng tôi trong Phần 5.2, tinh chỉnh chỉ dẫn nên xoay các khái niệm tiền huấn luyện hướng về các nhiệm vụ người dùng mà không vượt qua các mức ngôn ngữ học. Theo kết quả được báo cáo trong Bảng 6, chúng ta có thể quan sát xu hướng tăng tương tự như họ LLaMA về các kịch bản lập trình và toán với ý nghĩa thống kê (p < 0.05), trong khi không phải về các nhiệm vụ viết và dịch thuật. Từ góc độ ngôn ngữ học, không có danh mục kiến thức nào hiển thị sự khác biệt có ý nghĩa thống kê sau tinh chỉnh chỉ dẫn, phù hợp với các quan sát của họ LLaMA. Chúng tôi nghi ngờ rằng chúng ta không thể quan sát số lượng khái niệm tăng liên quan đến viết sau tinh chỉnh chỉ dẫn vì mô hình Mistral tiền huấn luyện đã thể hiện khả năng mạnh trong mô hình hóa ngôn ngữ (Jiang et al., 2023). Ngoài ra, ý nghĩa của số lượng khái niệm tăng liên quan đến toán và lập trình có thể được diễn giải như lý do cho khả năng tuân theo chỉ dẫn mạnh hơn của họ Mistral so với họ LLaMA, như được báo cáo trong Chatbot Arena (Zheng et al., 2024).

E.3 Phân tích Định tính về Khả năng Diễn giải của Các Thành phần Chính

Bảng 11 và Bảng 12 liệt kê các trường hợp được diễn giải tốt bởi ChatGPT-turbo-3.5-0613 cho các thành phần chính được trích xuất bởi Vicuna và LLaMA. Những trường hợp này cho thấy rằng mô tả khái niệm nhìn chung phản ánh tốt những gì đằng sau danh sách từ.

F Diễn giải Các đầu Tự chú ý

Bảng 13 và Bảng 14 liệt kê thêm các cặp từ cho các đầu tự chú ý từ lớp đầu tiên và cuối cùng. Thông thường, những trường hợp này là bằng chứng rằng các cặp từ được trích xuất hiển thị một số mối quan hệ sâu sắc khi chúng ta đọc từng cái riêng lẻ. Tuy nhiên, khi chúng ta đọc chúng cùng nhau, nó không thể phản ánh khái niệm súc tích như mạng truyền tiến.

Tinh chỉnh chỉ dẫn có thể chưng cất hành vi của neurons. Ví dụ, cặp neuron (Layer = 31, Head = 24, Dim = 62) nắm bắt mối quan hệ trong máy tính (như backend=authentication, icon=keyboard, giant=cardboard, GPU=PS, git=curl, và vân vân). Sau tinh chỉnh chỉ dẫn, mô hình tìm thấy nhiều cặp từ liên quan đến máy tính hơn (GPU=motherboard, VM=motherboard, tab=keyboard, mongo=staat, mongo=orden) và bỏ qua một số cặp từ không liên quan (dense=bright, convinced=confused), mặc dù các mối quan hệ mới có thể không hợp lệ.

Trường hợp này cũng là bằng chứng rằng tinh chỉnh chỉ dẫn không tạo ra thay đổi đáng kể trong kiến thức tiền huấn luyện qua các khái niệm.

--- TRANG 12 ---
[Các bảng từ 7-14 chứa dữ liệu chi tiết về thay đổi tần suất từ, phân bố khái niệm, và các cặp từ được kích hoạt bởi các đầu tự chú ý. Do độ dài và tính chất kỹ thuật, tôi sẽ không dịch từng dòng dữ liệu cụ thể trong các bảng này, nhưng cấu trúc và tiêu đề đã được dịch.]

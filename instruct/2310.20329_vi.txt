I'll help you translate this research paper from English to Vietnamese while maintaining the exact same structure. Let me start the translation:

# InstructCoder: Điều chỉnh Hướng dẫn các Mô hình Ngôn ngữ Lớn cho Chỉnh sửa Mã nguồn

Kaixin Li1*Qisheng Hu1*Xu Zhao1Hui Chen2Yuxi Xie1Tiedong Liu1
Qizhe Xie1†Junxian He3†

1Đại học Quốc gia Singapore2Đại học Công nghệ và Thiết kế Singapore
3Đại học Giao thông Thượng Hải

{likaixin,qishenghu,xu.zhao,xieyuxi,tiedong.liu}@u.nus.edu ,
hui_chen@mymail.sutd.edu.sg ,
junxianh@sjtu.edu.cn

## Tóm tắt

Chỉnh sửa mã nguồn bao gồm một loạt các tác vụ thực dụng mà các nhà phát triển phải đối mặt hàng ngày. Mặc dù có tính liên quan và hữu ích thực tế, việc chỉnh sửa mã nguồn tự động vẫn là một lĩnh vực chưa được khám phá đầy đủ trong sự phát triển của các mô hình học sâu, một phần do tình trạng khan hiếm dữ liệu. Trong công trình này, chúng tôi khám phá việc sử dụng các Mô hình Ngôn ngữ Lớn (LLMs) để chỉnh sửa mã nguồn dựa trên hướng dẫn của người dùng. Được đánh giá trên một benchmark mới dựa trên thực thi được viết bởi con người có tên EditEval, chúng tôi phát hiện rằng các mô hình hiện tại thường gặp khó khăn trong việc thực hiện các hướng dẫn. Trong bối cảnh này, chúng tôi đóng góp InstructCoder, bộ dữ liệu điều chỉnh hướng dẫn đầu tiên được thiết kế để thích nghi LLMs cho việc chỉnh sửa mã nguồn tổng quát, chứa các tác vụ chỉnh sửa mã nguồn đa dạng cao như chèn bình luận, tối ưu hóa mã nguồn, và tái cấu trúc mã nguồn. Nó bao gồm hơn 114.000 bộ ba hướng dẫn-đầu vào-đầu ra và bao quát nhiều tình huống chỉnh sửa mã nguồn khác biệt. Quá trình thu thập bắt đầu với dữ liệu commit đã được lọc từ các kho lưu trữ Python trên GitHub làm hạt giống. Tiếp theo, bộ dữ liệu được mở rộng một cách có hệ thống thông qua một quá trình lặp, nơi cả tác vụ hạt giống và tác vụ được tạo ra đều được sử dụng để nhắc ChatGPT tạo thêm dữ liệu. Các phát hiện của chúng tôi tiết lộ rằng các LLMs mã nguồn mở được tinh chỉnh trên InstructCoder có thể nâng cao đáng kể độ chính xác của việc chỉnh sửa mã nguồn, thể hiện hiệu suất chỉnh sửa mã nguồn vượt trội tương đương với các LLMs độc quyền tiên tiến.

Bộ dữ liệu và mã nguồn có sẵn tại https://github.com/qishenghu/CodeInstruct.

## 1 Giới thiệu

Các nhà phát triển thường tham gia vào một thói quen tuần hoàn của việc viết và sửa đổi mã nguồn. Là một yếu tố quan trọng, việc chỉnh sửa mã nguồn chiếm một phần lớn trong quá trình này, bao gồm các tác vụ phụ đa dạng như tối ưu hóa mã nguồn, tái cấu trúc, và sửa lỗi, mỗi tác vụ đặt ra những thách thức riêng biệt. Các công cụ chỉnh sửa mã nguồn tự động có thể nâng cao đáng kể năng suất của nhà phát triển bằng cách giảm bớt gánh nặng của các tác vụ đơn điệu. Tuy nhiên, đây vẫn là một lĩnh vực chưa được khám phá đầy đủ, một phần do thiếu dữ liệu liên quan, cản trở tiến bộ đáng kể của các mô hình học sâu.

*Đóng góp bằng nhau. Thứ tự được xác định bằng cách tung xúc xắc.
†Tư vấn bằng nhau. Thứ tự được xác định bằng cách tung xúc xắc.

Được truyền cảm hứng từ những tiến bộ gần đây trong LLMs (Brown et al., 2020; Chowdhery et al., 2022; Ouyang et al., 2022; OpenAI, 2022; Touvron et al., 2023a; OpenAI, 2023) và Code LLMs (Nijkamp et al., 2023a; Chen et al., 2021a; Li et al., 2023a), chúng tôi khám phá khả năng thành thạo của LLMs trong các tác vụ chỉnh sửa mã nguồn dựa trên hướng dẫn của người dùng, ví dụ như "thêm một docstring vào hàm để làm rõ", "loại bỏ mã nguồn dư thừa", hoặc "tái cấu trúc nó thành các hàm có thể tái sử dụng". Những tác vụ này khác biệt rõ rệt so với việc hoàn thành mã nguồn, điều này liên quan đến việc tạo ra mã nguồn để hoàn thành các đoạn mã nguồn hoặc bình luận đã cho. Chỉnh sửa mã nguồn yêu cầu mô hình không chỉ hiểu mã nguồn hiện có mà còn thực hiện các sửa đổi phù hợp với các hướng dẫn đã cho, đồng thời tích hợp một cách liền mạch với ngữ cảnh. Ví dụ, loại bỏ mã nguồn dư thừa hoặc tái cấu trúc một hàm không nên ảnh hưởng đến giá trị trả về.

Để đánh giá có hệ thống LLMs cho việc chỉnh sửa mã nguồn, chúng tôi đã tạo ra một benchmark mới có tên EditEval. Nó chứa các loại chỉnh sửa mã nguồn khác nhau được chuyển đổi từ các commit Github và các bộ dữ liệu hiện có. Một cách thú vị, chúng tôi phát hiện rằng các mô hình mã nguồn mở cho kết quả không thỏa đáng, và thậm chí các LLMs độc quyền tiên tiến nhất cũng gặp khó khăn để giải quyết những tác vụ này.

Để giải quyết thách thức này, chúng tôi trình bày InstructCoder, một bộ dữ liệu đa dạng cho việc tinh chỉnh hướng dẫn, được thiết kế đặc biệt để cải thiện khả năng chỉnh sửa mã nguồn của LLMs. Cụ thể, chúng tôi đầu tiên thu thập và kiểm tra thủ công dữ liệu commit từ các kho lưu trữ công khai trên GitHub làm các tác vụ chỉnh sửa mã nguồn hạt giống. Sau đó, chúng tôi sử dụng dữ liệu hạt giống để nhắc ChatGPT (OpenAI, 2022) tạo ra các hướng dẫn mới và các cặp đầu vào-đầu ra tương ứng. Quá trình này giống với các khung Self-Instruct (Wang et al., 2022a) và Alpaca (Taori et al., 2023). Bằng cách buộc các tình huống một cách sáng tạo để hướng dẫn quá trình tạo, phương pháp của chúng tôi đảm bảo rằng các tác vụ trong InstructCoder đa dạng và liên quan đến các tình huống lập trình thực tế, dẫn đến một bộ dữ liệu mạnh mẽ cho việc tinh chỉnh hướng dẫn trong lĩnh vực chỉnh sửa mã nguồn. Sau khi loại bỏ trùng lặp và xử lý hậu kỳ phù hợp, chúng tôi giữ lại hơn 114.000 mẫu trong bộ dữ liệu.

Các nghiên cứu thực nghiệm của chúng tôi tiết lộ rằng LLMs thể hiện những cải thiện đáng chú ý trong khả năng chỉnh sửa mã nguồn sau khi tinh chỉnh với InstructCoder. Code LLaMA đạt được kết quả tốt nhất thông qua tinh chỉnh, đạt độ chính xác 57.22%, gần như tương đương với ChatGPT. Các nghiên cứu thêm cũng cho thấy rằng trong khi việc tiền huấn luyện của các mô hình là cơ bản, hiệu suất chỉnh sửa mã nguồn bị ảnh hưởng mạnh mẽ bởi chất lượng và khối lượng dữ liệu điều chỉnh hướng dẫn.

Tóm lại, những đóng góp của công trình này là (1) InstructCoder, bộ dữ liệu điều chỉnh hướng dẫn đầu tiên với một loạt các tác vụ chỉnh sửa mã nguồn đa dạng, và chứng minh hiệu quả của việc tinh chỉnh hướng dẫn với InstructCoder; (2) EditEval, một benchmark mới dựa trên thực thi được viết bởi con người để đánh giá nghiêm ngặt việc chỉnh sửa mã nguồn tổng quát; (3) Chúng tôi phát hiện rằng các mô hình mã nguồn mở được điều chỉnh hướng dẫn với InstructCoder có thể thể hiện hiệu suất chỉnh sửa mã nguồn mạnh mẽ tương đương với ChatGPT.

## 2 Công trình Liên quan

### 2.1 Bộ dữ liệu Tinh chỉnh Hướng dẫn

Các nghiên cứu trước đây đã kết luận rằng việc tinh chỉnh hướng dẫn LLMs trên một tập hợp đa dạng các tác vụ hướng dẫn có thể cải thiện thêm khả năng của LLMs để tổng quát hóa tốt trên các tác vụ chưa thấy (Ouyang et al., 2022; Mishra et al., 2022; Wei et al., 2022; Chung et al., 2022; Wang et al., 2023c). Để hỗ trợ những tác vụ này, các bộ dữ liệu bao gồm một số lượng lớn các đoạn mã nguồn với các chú thích tương ứng là cần thiết. Những hướng dẫn này có thể được tái tạo từ các bộ dữ liệu hiện có (Aribandi et al., 2022; Wei et al., 2022; Mishra et al., 2022; Longpre et al., 2023), hoặc được viết bởi con người với nỗ lực đám đông (Ouyang et al., 2022; Wang et al., 2022b). Việc tạo dữ liệu hướng dẫn bằng máy cũng đã được khám phá để giảm lao động con người (Wang et al., 2022a; Honovich et al., 2022; Taori et al., 2023; Xue et al., 2023). Mặc dù có mức độ nhiễu cao trong dữ liệu, hiệu quả của nó đã được xác định.

### 2.2 Tổng hợp Mã nguồn

Tạo mã nguồn là một lĩnh vực được nghiên cứu rộng rãi. Các mô hình ngôn ngữ được tiền huấn luyện trên các tập hợp lớn mã nguồn đã thể hiện khả năng mạnh mẽ trong nhiều tác vụ lập trình khác nhau. Một số LLMs tổng quát có được khả năng tạo mã nguồn do sự pha trộn của mã nguồn trong kho dữ liệu tiền huấn luyện (ví dụ The Pile (Gao et al., 2020)), như GPT-3 (Brown et al., 2020), ChatGPT, GPT-4 (OpenAI, 2023), LLaMA (Touvron et al., 2023a), BLOOM (Scao et al., 2022), GPT-NeoX (Black et al., 2022), và Pythia (Biderman et al., 2023). LLMs được đào tạo đặc biệt trên mã nguồn và được tối ưu hóa cho việc tạo mã nguồn cũng được nghiên cứu, ví dụ Codex (Chen et al., 2021a), CodeGen (Nijkamp et al., 2023b), CodeGeeX (Zheng et al., 2023) và StarCoder (Li et al., 2023a). Tất cả các mô hình này đều áp dụng kiến trúc transformer chỉ giải mã nhưng khác nhau về kích thước và thiết kế mô hình cụ thể (ví dụ positional embedding, vị trí lớp norm) cũng như việc lựa chọn và tiền xử lý của kho dữ liệu tiền huấn luyện.

Mặt khác, tương đối ít tài liệu giải quyết mục tiêu chỉnh sửa mã nguồn. Các công trình trước đây tập trung vào một tập con của các tác vụ chỉnh sửa mã nguồn, như điền mã nguồn (Fried et al., 2023) và gỡ lỗi (Just et al., 2014; Tarlow et al., 2020; Ding et al., 2020; Jimenez et al., 2023). Bộ dữ liệu PIE (Madaan et al., 2023) là một công trình đồng thời liên quan nhất đến của chúng tôi, tập trung vào việc tăng tốc các chương trình. Các công trình khác (Yin et al., 2018; Wei et al., 2023; Chakraborty et al., 2020) không thể chấp nhận ngôn ngữ tự nhiên làm ý định chỉnh sửa, khiến chúng kém thân thiện với người dùng.

Tuy nhiên, các bộ dữ liệu được điều chỉnh đặc biệt cho việc chỉnh sửa mã nguồn tổng quát vẫn chưa có. Để lấp đầy khoảng trống này, chúng tôi giới thiệu InstructCoder, một bộ dữ liệu mới nhằm tiến thêm khả năng chỉnh sửa mã nguồn với LLMs.

## 3 EditEval: Đánh giá Các Mô hình Chỉnh sửa Mã nguồn

Như đã đề cập trước đó, chỉnh sửa mã nguồn khác biệt đáng kể so với hoàn thành mã nguồn. Do đó, các bộ dữ liệu được sử dụng rộng rãi trong lĩnh vực hoàn thành mã nguồn, như MBPP (Austin et al., 2021) và HumanEval (Chen et al., 2021b), không đủ để đánh giá khả năng chỉnh sửa mã nguồn. Để đánh giá nghiêm ngặt khả năng chỉnh sửa mã nguồn, chúng tôi đã tuyển chọn một tập kiểm tra gồm 194 tác vụ chỉnh sửa mã nguồn, được dẫn xuất từ ba nguồn chính: dữ liệu commit GitHub, MBPP, và HumanEval. Chúng tôi khai thác mã nguồn đầu vào từ những nguồn này và tạo ra các hướng dẫn chỉnh sửa hợp lý. Đối với các nguồn GitHub, chúng tôi thủ công tạo ra các ngữ cảnh thực thi để mã nguồn có thể chạy được. Mỗi mẫu được đi kèm với một giải pháp chuẩn được viết bởi con người để đảm bảo hướng dẫn khả thi. Các chỉnh sửa mã nguồn được tạo ra được đánh giá nghiêm ngặt bằng cách sử dụng các trường hợp kiểm tra tự động để đánh giá tính đúng đắn của các chỉnh sửa. Một chỉnh sửa được coi là đúng chỉ khi nó vượt qua tất cả các trường hợp kiểm tra. Phương pháp tự động này cung cấp một khung đánh giá mạnh mẽ và khách quan, cần thiết để đánh giá hiệu suất của mô hình trong các tình huống chỉnh sửa mã nguồn đa dạng. Phụ lục A trình bày một ví dụ về tập kiểm tra.

Chúng tôi đã đánh giá so sánh một số mô hình được điều chỉnh hướng dẫn trên EditEval, và kết quả được liệt kê trong Bảng 1. Nhìn chung, kết quả cho thấy tiềm năng cải thiện đáng kể trong việc chỉnh sửa mã nguồn. Alpaca và CodeAlpaca thể hiện độ chính xác dưới 20% với kích thước 7B và 13B, và nó chỉ tốt hơn ở 33B. Ở kích thước này, CodeAlpaca vượt qua Alpaca, đạt độ chính xác 35.56%. Chuyển sang các GPTs, các mô hình độc quyền tiên tiến nhất cho đến thời điểm này, GPT-4 đạt hiệu suất tốt nhất ở 68.56%. Thậm chí ChatGPT cũng gặp khó khăn với tác vụ này, chỉ ghi được 57.73%. Khi kiểm tra kỹ hơn, chúng tôi phát hiện thách thức của EditEval nằm ở nhu cầu cao cho cả việc tuân theo hướng dẫn và hiểu mã nguồn. Mô hình phải nắm bắt ngữ cảnh ngụ ý của mã nguồn đầu vào, và sau đó hoàn thành việc chỉnh sửa trong ngữ cảnh của nó.

| Mô hình | Độ chính xác (%) |
|---------|------------------|
| ChatGPT (gpt-3.5-turbo-0613) | 57.73 |
| GPT-4 (gpt-4-0613) | 68.56 |
| GPT-4 Turbo (gpt-4-1106-preview) | 66.49 |
| | 7B | 13B | 33B |
| Alpaca | 12.37 | 19.59 | 30.93 |
| LLaMA+CodeAlpaca | 18.56 | 18.56 | 35.56 |

Bảng 1: Kết quả của một số mô hình được điều chỉnh hướng dẫn được đánh giá trên EditEval.

## 4 InstructCoder: Điều chỉnh Hướng dẫn Tăng cường Chỉnh sửa Mã nguồn

Trong phần này, chúng tôi giới thiệu cách chúng tôi tạo ra InstructCoder để tăng cường khả năng chỉnh sửa mã nguồn của LLMs thông qua việc tinh chỉnh hướng dẫn. Chúng tôi sử dụng một phương pháp dựa trên Self-Instruct (Wang et al., 2022a), mở rộng dữ liệu tinh chỉnh hướng dẫn bằng cách khởi động từ việc tạo mô hình ngôn ngữ. Phương pháp tạo dữ liệu với LLMs yêu cầu dữ liệu được gán nhãn bởi con người tối thiểu làm tác vụ hạt giống trong khi duy trì chất lượng và sự liên quan của các tác vụ trong bộ dữ liệu. Thông qua một quá trình lặp tạo hướng dẫn và tinh chỉnh chúng với việc loại bỏ trùng lặp, chúng tôi tạo ra một bộ dữ liệu với một loạt các tác vụ chỉnh sửa mã nguồn rộng. Hình 1 minh họa quy trình thu thập dữ liệu của InstructCoder.

### 4.1 Thu thập Dữ liệu Hạt giống

GitHub là một nền tảng lưu trữ mã nguồn có dịch vụ kiểm soát phiên bản tự nhiên ghi lại các chỉnh sửa mã nguồn với các commit, có thể được chuyển đổi thành hướng dẫn. Các kho lưu trữ trên GitHub cung cấp dữ liệu đa dạng với chất lượng được tạo bởi con người. Tuy nhiên, dữ liệu này không phù hợp cho việc sử dụng trực tiếp. Đầu tiên, các thông điệp commit hầu hết ngắn gọn và có tính kết quả, thiếu các mô tả chi tiết. Hơn nữa, chúng có thể không chính xác hoặc thậm chí vắng mặt. Thứ hai, các commit có thể rất lớn liên quan đến nhiều tệp, vượt quá phạm vi của công trình này. Trong bối cảnh này, chúng tôi hướng sự chú ý của mình đến LLMs như một phương tiện để tạo dữ liệu, thay vì việc sử dụng trực tiếp dữ liệu đã thu thập.

Dữ liệu commit GitHub thô được tổng hợp bằng BigQuery. Để đảm bảo chất lượng cao và giải quyết các vấn đề cấp phép, chúng tôi tập trung vào các kho lưu trữ Python trên GitHub với hơn 100 sao và giấy phép khoan dung. Tiêu chí lựa chọn của chúng tôi bị hạn chế đối với các commit chỉ sửa đổi một khối mã nguồn trong một tệp Python duy nhất. Những commit này được xác định bằng git-diff.

Trong quá trình thu thập, chúng tôi gặp phải nhiều thông điệp commit không chính xác hoặc mang tính cảm xúc. Codex (Chen et al., 2021a) được sử dụng trong những trường hợp như vậy để làm rõ những thay đổi được thực hiện giữa các phiên bản và cải thiện các thông điệp commit, dẫn đến các hướng dẫn chính xác và có thông tin hơn. Tổng cộng 634 tác vụ đã được xử lý từ dữ liệu commit thông qua nỗ lực thủ công và được sử dụng cho quá trình tự hướng dẫn.

Ngoài dữ liệu commit GitHub, chúng tôi cũng tận dụng các mẫu được tạo chất lượng cao làm tác vụ hạt giống bổ sung. Với kiểm tra thủ công, một lô 592 mẫu chất lượng cao đã được biên soạn làm tác vụ hạt giống bổ sung. Tập dữ liệu hạt giống này bao phủ một loạt các tình huống chỉnh sửa mã nguồn rộng và làm phong phú cơ sở mà InstructCoder được tạo ra, đảm bảo rằng các tác vụ được bắt nguồn từ các trường hợp chỉnh sửa mã nguồn thực tế hợp lý.

### 4.2 Khởi động Hướng dẫn

Self-Instruct (Wang et al., 2022a) là một khung tự động hiệu quả cho việc tạo dữ liệu hướng dẫn. Nó hoạt động bằng cách khởi động lặp từ việc tạo của LLM, trình bày một cách để làm phong phú bộ dữ liệu hướng dẫn trong khi duy trì chất lượng tác vụ và sự liên quan từ một tập nhỏ các tác vụ hạt giống được đánh giá bởi con người. Chúng tôi tận dụng một phương pháp tương tự để tạo ra dữ liệu hướng dẫn chỉnh sửa mã nguồn đa dạng.

Trong mỗi lần lặp, bảy hướng dẫn tác vụ hạt giống và một hướng dẫn tác vụ được tạo bởi ChatGPT được lấy mẫu và kết hợp làm ngữ cảnh few-shot để nhắc ChatGPT tạo thêm hướng dẫn. Để tạo ra các hướng dẫn đa dạng và có thể áp dụng thực tế hơn, chúng tôi cũng tạo ra các tác vụ trên nhiều lĩnh vực phụ bằng cách chỉ định ý định chỉnh sửa trong lời nhắc được cung cấp. Các lời nhắc liên quan được sử dụng có thể được tìm thấy trong Bảng 4 trong Phụ lục C.

### 4.3 Tạo có Điều kiện Tình huống

Chúng tôi ban đầu phát hiện nhiều mẫu được tạo ra chia sẻ các codebase tương tự mặc dù có các hướng dẫn và ví dụ few-shot khác nhau được cung cấp. Sự tương tự như vậy có thể làm giảm lớn giá trị của bộ dữ liệu. Phân tích thực nghiệm cho thấy vấn đề có thể được quy cho việc LLM tạo ra các codebase chung cho các đoạn đầu vào/đầu ra khi không đủ ngữ cảnh được cung cấp. Như một biện pháp đối phó, chúng tôi đề xuất giới thiệu các tình huống chỉnh sửa mã nguồn cho việc tạo mã nguồn đầu vào/đầu ra.

Chúng tôi trình bày một số ví dụ trong Hình 9,10,11 trong Phụ lục D, nơi chúng tôi thường quan sát rằng các trường hợp được tạo với tình huống thể hiện chất lượng cao hơn về ngữ cảnh phong phú hơn và cấu trúc mã nguồn so với những trường hợp không có.

Đối với mỗi hướng dẫn được tạo, chúng tôi đầu tiên nhắc ChatGPT tạo ra các sự kiện thực tế làm tình huống "thế giới thực" nơi hướng dẫn chỉnh sửa có thể được thực hiện, và ngẫu nhiên chọn một cho việc tạo trường hợp trong bước tiếp theo. Tiếp theo, LLM được hướng dẫn tạo ra các mẫu tương ứng với hướng dẫn và tình huống, đảm bảo các codebase và tên biến phù hợp. Lời nhắc được sử dụng có thể được tìm thấy trong Bảng 4 trong Phụ lục C.

Bằng cách kết hợp tạo có điều kiện tình huống, các mẫu kết quả thể hiện tính biến đổi gia tăng về codebase và đặt tên biến, do đó tăng cường tính đa dạng của InstructCoder.

### 4.4 Xử lý hậu kỳ

Theo Self-Instruct (Wang et al., 2022a), việc loại bỏ trùng lặp được áp dụng trên các hướng dẫn được tạo để loại bỏ các hướng dẫn có điểm chồng chéo ROUGE-L (Lin, 2004) lớn hơn 0.7 với các hướng dẫn hiện có. Đối với mã nguồn, chúng tôi sử dụng MinHash với chỉ mục Locality Sensitive Hashing (LSH) để loại bỏ các trường hợp có độ tương tự Jaccard lớn hơn 0.75. Cuối cùng, InstructCoder bao gồm hơn 114.000 tác vụ chỉnh sửa mã nguồn riêng biệt.

Cho mục đích thí nghiệm, chúng tôi chỉ định 95% các tác vụ cho đào tạo, trong khi 5% còn lại tạo thành tập xác thực của chúng tôi.

## 5 Phân tích Dữ liệu

Chúng tôi phân tích InstructCoder về mặt 1) tính đa dạng, 2) độ phức tạp, và 3) tính đúng đắn. Chúng tôi cung cấp phân tích phân phối và độ phức tạp của các trường hợp tác vụ. Cuối cùng, chúng tôi chứng minh thông qua điều tra của con người rằng dữ liệu của chúng tôi có độ tin cậy cao.

### 5.1 Tổng quan Thống kê

InstructCoder bao gồm hơn 114k hướng dẫn chỉnh sửa mã nguồn, mỗi hướng dẫn được ghép đôi với một trường hợp đầu vào/đầu ra. Phân phối độ dài token của đầu vào/đầu ra có thể được xem trong Hình 4 và Bảng 5 trong Phụ lục E. Hầu hết dữ liệu nằm trong một phạm vi hợp lý về độ dài, trong khi một số giá trị cực đoan phản ánh độ rộng của bộ dữ liệu của chúng tôi.

### 5.2 Tính đa dạng Hướng dẫn

Để khám phá tính đa dạng của các tác vụ trong InstructCoder và khả năng áp dụng thực tế của chúng, chúng tôi trình bày các ý định hướng dẫn khác nhau tức là những gì các chỉnh sửa mã nguồn dự định hoàn thành, và các động từ hướng dẫn, tức là cách thức chỉnh sửa mã nguồn được hoàn thành.

**Ý định Hướng dẫn.** Chúng tôi yêu cầu ChatGPT phân loại các loại chỉnh sửa mã nguồn trong bộ dữ liệu của chúng tôi và thủ công xác định 27 thể loại thực nghiệm. Hình 2 hiển thị phân phối của các danh mục ý định chỉnh sửa mã nguồn trong InstructCoder, bao gồm thêm chức năng, tối ưu hóa mã nguồn, cải thiện khả năng đọc, v.v. Những mục tiêu này nhấn mạnh phạm vi rộng của InstructCoder.

**Động từ Hướng dẫn.** Tính đa dạng của các động từ hướng dẫn cũng được mô tả trong Hình 3a. Chúng tôi thể hiện 20 động từ gốc hàng đầu và 4 danh từ trực tiếp hàng đầu của chúng đều được xếp hạng theo tần suất. Trong khi một phần lớn các hướng dẫn có thể được nhóm một cách đại khái là tạo (ví dụ "add", "implement", "create") và sửa đổi (ví dụ "modify", "replace", "change"), InstructCoder trình bày một phân phối đuôi dài với các động từ ít phổ biến khác ngoài top-20 chiếm 25.0% tỷ lệ phần trăm. Điều này chứng minh rằng bộ dữ liệu chứa một phổ rộng các hướng dẫn.

### 5.3 Tính đa dạng Tình huống

InstructCoder được thiết kế để bao phủ một loạt các tình huống rộng. Như đã thảo luận trong Phần 4.3, mỗi hướng dẫn được đi kèm với các tình huống khác nhau nơi hướng dẫn chỉnh sửa có thể được thực hiện để cải thiện tính đa dạng. Một từ đám mây được cung cấp để hiển thị một số lĩnh vực tình huống trong bộ dữ liệu của chúng tôi, như được minh họa trong Hình 3b, với mỗi khu vực tham chiếu đến một lĩnh vực khác nhau. Tính đa dạng của bộ dữ liệu được nhấn mạnh bởi sự hiện diện của một loạt các lĩnh vực rộng như xử lý hình ảnh, phát triển web, và an ninh mạng.

### 5.4 Độ phức tạp

Chúng tôi phản ánh độ phức tạp của một tác vụ chỉnh sửa mã nguồn bằng số lượng dòng khác biệt và tỷ lệ chỉnh sửa của chúng trong cặp đầu vào/đầu ra, được định nghĩa là:

ndiff = |I∪O\I∩O|, (1)
rdiff = ndiff/|I∪O|, (2)

trong đó I và O là các tập hợp mã nguồn đầu vào/đầu ra với các dòng đơn làm phần tử.

Chúng tôi đo lường các dòng khác biệt của một trường hợp tác vụ chỉnh sửa mã nguồn bằng thư viện Python difflib. Chúng tôi phát hiện rằng số lượng dòng khác biệt trung bình trong InstructCoder là 11.9 và tỷ lệ chỉnh sửa trung bình là 0.52. Những giá trị này cho thấy một mức độ phức tạp khá chấp nhận được, chỉ ra rằng bộ dữ liệu không quá dễ cũng không quá khó. InstructCoder đạt được sự cân bằng về độ phức tạp, làm cho nó rất phù hợp cho việc tinh chỉnh và đánh giá LLMs trong một loạt các tác vụ chỉnh sửa mã nguồn rộng. Hình 12 trong Phụ lục E minh họa phân phối số lượng dòng khác biệt.

### 5.5 Tính đúng đắn

Chúng tôi tiếp tục lấy mẫu ngẫu nhiên 200 trường hợp và mời các người chú thích đánh giá các trường hợp dựa trên hai tiêu chí: tính hợp lệ của các hướng dẫn và tính đúng đắn của các đầu ra. Đánh giá tính hợp lệ tập trung vào việc xác định xem các hướng dẫn có thể hiện ý định chỉnh sửa rõ ràng và phù hợp hay không. Đánh giá tính đúng đắn kiểm tra xem các cặp đầu vào-đầu ra có phản ánh những thay đổi được chỉ định bởi các hướng dẫn hay không.

Kết quả trong Bảng 2 chỉ ra rằng hầu hết các hướng dẫn trong bộ dữ liệu InstructCoder là hợp lệ. Một số ít trường hợp thể hiện nhiễu và thỉnh thoảng thất bại trong việc tuân theo hướng dẫn, nhưng tính đúng đắn cao được tìm thấy tổng thể. Trong số 200 trường hợp được đánh giá, 180 được giải quyết thành công, thể hiện chất lượng tổng thể và độ tin cậy của InstructCoder.

| Câu hỏi | Đạt |
|---------|-----|
| Xác định xem hướng dẫn có hợp lệ không. | 97% |
| Đầu ra có phải là phản hồi mã nguồn được chỉnh sửa chấp nhận được cho hướng dẫn và đầu vào không? | 90% |

Bảng 2: Các câu hỏi kiểm tra chất lượng và kết quả trên một tập con được lấy mẫu ngẫu nhiên với 200 điểm dữ liệu.

## 6 Thí nghiệm

### 6.1 Thiết lập

**Đào tạo.** Chúng tôi thí nghiệm với hai họ mô hình ngôn ngữ mã nguồn mở với các kích thước khác nhau: LLaMA (LLaMA, LLaMA-2 và Code LLaMA) (Touvron et al., 2023a,b; Roziere et al., 2023) và BLOOM (Scao et al., 2022).

LLaMA là một dãy LLMs với các tham số từ 7 đến 65 tỷ. Chúng đã được tiền huấn luyện trên một kho dữ liệu rộng lớn, trong đó khoảng 4.5% bao gồm mã nguồn. Dãy LLaMA-2 mở rộng họ với việc tiền huấn luyện chuyên sâu hơn. Ngoài ra, Code LLaMAs được xây dựng trên LLaMA-2 và được đào tạo đặc biệt trên 500B token mã nguồn để tăng cường khả năng hiểu và tạo mã nguồn của nó. BLOOM là một LLM đa ngôn ngữ có khả năng tạo ra các đầu ra giống con người trong 46 ngôn ngữ và 13 ngôn ngữ lập trình.

Việc tinh chỉnh đầy đủ cập nhật tất cả các tham số trong một LLM có thể tốn kém về mặt tính toán. Thay vào đó, chúng tôi áp dụng LoRA (Hu et al., 2022), một phương pháp tinh chỉnh hiệu quả tham số tối ưu hóa một ma trận delta xấp xỉ hạng thấp của các lớp được kết nối đầy đủ. Theo cách này chúng tôi có thể tinh chỉnh một mô hình 33B trong một card GPU A100-80GB duy nhất. Trong các thí nghiệm của chúng tôi, LoRA được áp dụng cho các trọng số biến đổi query, key, value, và output của kiến trúc Transformer (Vaswani et al., 2017). Tất cả các siêu tham số có thể được tìm thấy trong Bảng 6 trong Phụ lục F.

**Cơ sở.** Chúng tôi chọn ChatGPT (OpenAI, 2022), GPT-4 (OpenAI, 2023) và GPT-4 Turbo làm cơ sở mạnh mẽ. Các mô hình mã nguồn mở được đề cập trước đó cùng với một mô hình LLaMA được điều chỉnh hướng dẫn có tên Alpaca (Taori et al., 2023) được bao gồm, và hiệu suất zero-shot của chúng được báo cáo.

Đồng thời với công trình của chúng tôi, CodeAlpaca là một bộ dữ liệu phổ biến được tạo ra với quy trình của Alpaca, khác biệt ở chỗ dữ liệu hạt giống của nó được thay thế bằng các hướng dẫn dễ viết tay với các chương trình ngắn. Chúng tôi tinh chỉnh các mô hình LLaMA với CodeAlpaca và Alpaca và so sánh kết quả.

## 7 Kết quả

### 7.1 Hiệu quả Tinh chỉnh với InstructCoder

Trong phần này, chúng tôi chứng minh giá trị của bộ dữ liệu InstructCoder của chúng tôi. Bảng 3 trình bày một so sánh chi tiết về hiệu suất EditEval trên các mô hình được tinh chỉnh với InstructCoder và các mô hình cơ sở. Trong khi độ chính xác rất thấp được quan sát trong các mô hình thuần túy mã nguồn mở, việc tinh chỉnh với InstructCoder tăng cường đáng kể độ chính xác, làm nổi bật hiệu quả của việc tinh chỉnh hướng dẫn hiệu quả với các cặp chỉnh sửa mã nguồn được tạo bằng máy.

Code LLaMA 13B tương đương hiệu suất của ChatGPT và vượt qua các mô hình mã nguồn mở khác với tỷ lệ chính xác 57.22%. Mô hình LLaMA-33B đáng kể hơn hiển thị một cải thiện đáng chú ý 35.56%, nhưng nó thua kém Code LLaMA-7B, được hưởng lợi từ việc tiền huấn luyện rộng rãi trên mã nguồn.

Như mong đợi, nền tảng tiền huấn luyện của LLM ảnh hưởng đáng kể đến hiệu quả chỉnh sửa mã nguồn. LLaMA thể hiện độ chính xác cao hơn các mô hình BLOOM có kích thước tương tự. Trong số các LLaMAs, những mô hình được tiền huấn luyện trên nhiều token hơn (dãy LLaMA-2) vượt trội so với các phiên bản trước đó. Hơn nữa, Code LLaMAs vượt qua các mô hình LLaMA-2 do kết quả của việc tiền huấn luyện rộng rãi đặc biệt trên dữ liệu coding. Mặc dù có khả năng khác nhau của các mô hình cơ bản, bộ dữ liệu của chúng tôi nhất quán tăng cường hiệu suất.

| Mô hình | Kích thước | Độ chính xác (%) | | ∆Acc |
|---------|------------|------------------|---|------|
| | | không ft | với ft | |
| ChatGPT (gpt-3.5-turbo-0613) | - | 57.73 | - | - |
| BLOOM | 3B | 0.52 | 15.46 | + 14.94 |
| | 7B | 1.03 | 19.59 | + 18.56 |
| LLaMA-1 | 7B | 2.57 | 26.80 | + 24.23 |
| | 13B | 6.19 | 28.35 | + 22.16 |
| | 33B | 6.19 | 41.75 | + 35.56 |
| LLaMA-2 | 7B | 4.12 | 27.32 | + 23.20 |
| | 13B | 14.95 | 34.54 | + 19.59 |
| Code LLaMA | 7B | 29.90 | 45.88 | + 15.98 |
| | 13B | 28.86 | 57.22 | + 28.36 |

Bảng 3: Các mô hình được tinh chỉnh với InstructCoder cải thiện đáng kể trong độ chính xác chỉnh sửa mã nguồn trên EditEval, bất kể họ mô hình hoặc kích thước mô hình.

### 7.2 Mở rộng Bộ dữ liệu

InstructCoder có quy mô nhỏ hơn đáng kể so với những gì LLMs thường được tiền huấn luyện. Để xác định tính đầy đủ của quy mô này, chúng tôi đã tiến hành một thí nghiệm trong đó chúng tôi tinh chỉnh các mô hình LLaMA sử dụng các tỷ lệ khác nhau (1%, 10%, và 100%) của bộ dữ liệu. Các tập con nhỏ hơn được đảm bảo được bao gồm trong các tập con lớn hơn. Kết quả được hiển thị trong Hình 5. Xu hướng được xác định chứng minh một mối tương quan tích cực giữa độ chính xác của mô hình và quy mô của tập huấn luyện.

Được tinh chỉnh với chỉ 1% dữ liệu, các mô hình trải qua một số lượng hạn chế các cập nhật tham số nhưng nhanh chóng thích nghi với các tác vụ, vượt qua điểm độ chính xác zero-shot tương ứng của chúng bằng biên độ đáng kể. Điều này nhấn mạnh tầm quan trọng của việc điều chỉnh hướng dẫn. Khi khối lượng dữ liệu huấn luyện tăng, chúng tôi quan sát những cải thiện nhất quán trong độ chính xác mô hình, gần như tăng tuyến tính theo tỷ lệ logarithmic của số lượng mẫu. Quan trọng, thí nghiệm của chúng tôi thực nghiệm cho thấy rằng các mô hình lớn hơn hiệu quả hơn với ngân sách tính toán huấn luyện bị hạn chế.

### 7.3 Tỷ lệ Chỉnh sửa

Hình 6 mô tả độ chính xác của các mô hình LLaMA được tinh chỉnh như được đánh giá bởi GPT-4 trên năm mức tỷ lệ chỉnh sửa, sử dụng 2000 mẫu ngẫu nhiên từ tập xác thực. Đánh giá này, được biện minh trong Phụ lục H, liên quan đến việc nhắc GPT-4 để đánh giá nhanh và tổng quát về các chỉnh sửa mã nguồn, cung cấp một góc nhìn thay thế cho đánh giá chỉnh sửa mã nguồn. Trong đánh giá này, các mô hình lớn hơn nhất quán vượt trội so với các đối tác nhỏ hơn của chúng. Đáng chú ý, độ chính xác giảm với tỷ lệ chỉnh sửa thấp hơn, có thể do các mô hình áp dụng đường tắt sao chép đầu vào để giảm thiểu mất mát trong các tình huống yêu cầu ít chỉnh sửa hơn. Xu hướng này, tuy nhiên, ít rõ rệt hơn trong các mô hình lớn hơn, cho thấy khả năng lớn hơn để phân biệt sự khác biệt tinh tế trong các trường hợp tỷ lệ chỉnh sửa thấp.

## 8 Kết luận

Chúng tôi giới thiệu InstructCoder, bộ dữ liệu điều chỉnh hướng dẫn đầu tiên cho các tác vụ chỉnh sửa mã nguồn tổng quát. Nó bao gồm các thế hệ của LLMs, nơi các commit GitHub thực tế phục vụ như các tác vụ hạt giống để hướng dẫn quá trình tạo. Một phương pháp có điều kiện tình huống được giới thiệu để đảm bảo cả tính đa dạng và chất lượng cao của dữ liệu. Các thí nghiệm của chúng tôi trên benchmark EditEval mới cho thấy rằng các mô hình mã nguồn mở có thể đạt được những cải thiện lớn và thậm chí mang lại hiệu suất tương đương với các mô hình độc quyền thông qua việc tinh chỉnh hiệu quả tham số nhẹ về mặt tính toán với InstructCoder. Chúng tôi cũng tiết lộ rằng mô hình cơ sở LLM và quy mô của dữ liệu tinh chỉnh đều là những yếu tố sâu sắc của khả năng chỉnh sửa mã nguồn. Chúng tôi hy vọng bộ dữ liệu có thể có lợi và truyền cảm hứng cho nhiều nghiên cứu hơn trong lĩnh vực này hướng tới việc xây dựng các mô hình coding mạnh mẽ hơn.

## Hạn chế

Phương pháp của chúng tôi không bao gồm các thay đổi mã nguồn liên quan đến ngữ cảnh đa tệp, điều này có thể hữu ích trong phát triển. Chúng tôi hy vọng khám phá thêm những khía cạnh này và kết hợp các ngôn ngữ lập trình bổ sung trong nghiên cứu tương lai của chúng tôi.

## Tài liệu tham khảo

[The reference section remains the same as it contains proper names, citations, and technical terms that should not be translated]

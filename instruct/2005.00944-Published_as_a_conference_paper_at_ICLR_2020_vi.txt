# 2005.00944.pdf
# Đã chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/instruct/2005.00944.pdf
# Kích thước tệp: 1497478 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
HIỂU VÀ CẢI THIỆN VIỆC TRUYỀN TẢI THÔNG TIN
TRONG HỌC TẬP ĐA NHIỆM VỤ
Sen Wu
Đại học StanfordHongyang R. Zhang
Đại học PennsylvaniaChristopher R ́e
Đại học Stanford
TÓM TẮT
Chúng tôi nghiên cứu các phương pháp học tập đa nhiệm vụ sử dụng một biểu diễn đặc trưng chung
cho tất cả các nhiệm vụ. Để hiểu rõ hơn về việc truyền tải thông tin nhiệm vụ, chúng tôi nghiên cứu
một kiến trúc với một mô-đun chung cho tất cả các nhiệm vụ và một mô-đun đầu ra riêng biệt
cho mỗi nhiệm vụ. Chúng tôi nghiên cứu lý thuyết của thiết lập này trên các mô hình tuyến tính và được kích hoạt bằng ReLU. Quan sát chính của chúng tôi là việc dữ liệu của các nhiệm vụ có được căn chỉnh tốt hay không có thể ảnh hưởng đáng kể đến hiệu suất của học tập đa nhiệm vụ. Chúng tôi chỉ ra rằng sự không căn chỉnh giữa dữ liệu nhiệm vụ có thể gây ra việc truyền tải tiêu cực (hoặc làm tổn hại hiệu suất) và cung cấp các điều kiện đủ cho việc truyền tải tích cực. Được truyền cảm hứng bởi những hiểu biết lý thuyết, chúng tôi chỉ ra rằng việc căn chỉnh các lớp nhúng của các nhiệm vụ dẫn đến cải thiện hiệu suất cho việc huấn luyện đa nhiệm vụ và học chuyển giao trên benchmark GLUE và các nhiệm vụ phân tích cảm xúc; ví dụ, chúng tôi đạt được cải thiện điểm GLUE trung bình 2.35% trên 5 nhiệm vụ GLUE so với BERT LARGE bằng cách sử dụng phương pháp căn chỉnh của chúng tôi.
Chúng tôi cũng thiết kế một sơ đồ tái trọng số nhiệm vụ dựa trên SVD và chỉ ra rằng nó cải thiện
tính mạnh mẽ của việc huấn luyện đa nhiệm vụ trên một tập dữ liệu hình ảnh đa nhãn.

1 GIỚI THIỆU
Học tập đa nhiệm vụ gần đây đã nổi lên như một mô hình mạnh mẽ trong học sâu để thu được các biểu diễn ngôn ngữ (Devlin et al. (2018); Liu et al. (2019a;b)) và thị giác (Kokkinos (2017)) từ dữ liệu quy mô lớn. Bằng cách tận dụng dữ liệu có giám sát từ các nhiệm vụ liên quan, các phương pháp học tập đa nhiệm vụ giảm chi phí đắt đỏ của việc tuyển chọn các tập dữ liệu huấn luyện khổng lồ theo từng nhiệm vụ cần thiết bởi các phương pháp học sâu và cung cấp một biểu diễn chung cũng hiệu quả hơn cho việc học trên nhiều nhiệm vụ. Trong khi trong một số trường hợp, những cải thiện lớn đã được báo cáo so với học đơn nhiệm vụ (McCann et al. (2018)), các nhà thực hành cũng đã quan sát những kết quả có vấn đề, nơi hiệu suất của một số nhiệm vụ nhất định đã giảm do nhiễu nhiệm vụ (Alonso and Plank (2016); Bingel and Søgaard (2017)). Dự đoán khi nào và đối với những nhiệm vụ nào điều này xảy ra là một thách thức được làm trầm trọng thêm bởi sự thiếu hụt các công cụ phân tích. Trong công trình này, chúng tôi điều tra các thành phần chính để xác định liệu các nhiệm vụ có can thiệp một cách tích cực hay phá hoại từ các quan điểm lý thuyết và thực nghiệm. Dựa trên những hiểu biết này, chúng tôi phát triển các phương pháp để cải thiện hiệu quả và tính mạnh mẽ của việc huấn luyện đa nhiệm vụ.

Đã có một khối lượng lớn các nghiên cứu thuật toán và lý thuyết cho học tập đa nhiệm vụ dựa trên kernel, nhưng ít được biết đến hơn cho mạng nơ-ron. Thông điệp khái niệm từ công trình trước đó (Baxter (2000); Evgeniou and Pontil (2004); Micchelli and Pontil (2005); Xue et al. (2007)) cho thấy rằng học tập đa nhiệm vụ hiệu quả trên các nhiệm vụ "tương tự", nơi khái niệm tương tự được dựa trên các mô hình đơn nhiệm vụ (ví dụ: các ranh giới quyết định gần nhau). Công trình về học tương ứng cấu trúc (Ando and Zhang (2005); Blitzer et al. (2006)) sử dụng tối ưu hóa luân phiên để học một tham số chung và các tham số nhiệm vụ riêng biệt. Zhang and Yeung (2014) sử dụng một vector tham số cho mỗi nhiệm vụ và học các mối quan hệ nhiệm vụ thông qua điều chuẩn l2, điều này ngầm kiểm soát khả năng của mô hình. Những kết quả này khó áp dụng cho mạng nơ-ron: không rõ làm thế nào để lập luận về các mạng nơ-ron có không gian đặc trưng được cho bởi các nhúng theo từng lớp.

Để xác định liệu hai nhiệm vụ có can thiệp một cách tích cực hay phá hoại, chúng tôi điều tra một kiến trúc với một mô-đun chung cho tất cả các nhiệm vụ và một mô-đun đầu ra riêng biệt cho mỗi nhiệm vụ (Ruder (2017)).
Xem Hình 1 để minh họa. Quan sát động lực của chúng tôi là ngoài sự tương tự mô hình ảnh hưởng đến loại can thiệp, sự tương tự dữ liệu nhiệm vụ đóng một hiệu ứng bậc hai sau khi kiểm soát sự tương tự mô hình. Để minh họa ý tưởng, chúng tôi xem xét ba nhiệm vụ với cùng số lượng dữ liệu
Đóng góp bằng nhau. Liên hệ với fsenwu,hongyang,chrismre g@cs.stanford.edu

--- TRANG 2 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
𝐴*𝐴+𝐴,…𝐴-$+𝐴-$*𝐴-Các Mô-đun Dành riêng cho Nhiệm vụ (A)Các Mô-đun Chung (B)……𝑋*𝑋+𝑋,…𝑋-$+𝑋-$*𝑋-Nhiều Nhiệm vụ (X)
Hình 1: Minh họa về
kiến trúc học tập đa nhiệm vụ
với một mô-đun dưới chung B và
k mô-đun dành riêng cho nhiệm vụ fAigk
i=1.
Nhiều Điểm HơnÍt điểm hơnHình 2: Việc truyền tải Tích cực vs. Tiêu cực bị ảnh hưởng bởi dữ liệu
– không chỉ mô hình. Xem dưới phải-vs-giữa. Nhiệm vụ 2 và 3
có cùng mô hình (đường đứt nét) nhưng phân phối dữ liệu khác nhau. Chú ý sự khác biệt của dữ liệu trong các vùng được khoanh tròn.

mẫu nơi nhiệm vụ 2 và 3 có cùng ranh giới quyết định nhưng phân phối dữ liệu khác nhau (xem
Hình 2 để minh họa). Chúng tôi quan sát rằng việc huấn luyện nhiệm vụ 1 với nhiệm vụ 2 hoặc nhiệm vụ 3 có thể cải thiện hoặc làm tổn hại hiệu suất của nhiệm vụ 1, tùy thuộc vào lượng dữ liệu đóng góp dọc theo ranh giới quyết định! Quan sát này cho thấy rằng bằng cách đo lường sự tương tự của dữ liệu nhiệm vụ và các mô hình một cách riêng biệt, chúng ta có thể phân tích sự can thiệp của các nhiệm vụ và quy kết nguyên nhân một cách chính xác hơn.

Được thúc đẩy bởi quan sát trên, chúng tôi nghiên cứu lý thuyết của học tập đa nhiệm vụ thông qua mô-đun chung trong các thiết lập tuyến tính và được kích hoạt bằng ReLU. Đóng góp lý thuyết của chúng tôi bao gồm ba thành phần: khả năng của mô-đun chung, hiệp phương sai nhiệm vụ, và trọng số theo từng nhiệm vụ của quy trình huấn luyện. Khả năng đóng một vai trò cơ bản vì, nếu khả năng của mô-đun chung quá lớn, không có sự can thiệp giữa các nhiệm vụ; nếu nó quá nhỏ, có thể có sự can thiệp phá hoại. Sau đó, chúng tôi chỉ ra cách xác định sự can thiệp bằng cách đề xuất một khái niệm chi tiết hơn gọi là hiệp phương sai nhiệm vụ có thể được sử dụng để đo lường sự căn chỉnh của dữ liệu nhiệm vụ. Bằng cách thay đổi hiệp phương sai nhiệm vụ, chúng tôi quan sát cả việc truyền tải tích cực và tiêu cực từ một nhiệm vụ sang nhiệm vụ khác! Sau đó chúng tôi cung cấp các điều kiện đủ đảm bảo rằng một nhiệm vụ có thể truyền tải tích cực cho nhiệm vụ khác, với điều kiện có đủ nhiều điểm dữ liệu từ nhiệm vụ đóng góp. Cuối cùng, chúng tôi nghiên cứu cách gán trọng số theo từng nhiệm vụ cho các thiết lập nơi các nhiệm vụ khác nhau chia sẻ cùng dữ liệu nhưng có nhãn khác nhau.

Kết quả thực nghiệm. Lý thuyết của chúng tôi dẫn đến việc thiết kế hai thuật toán có ý nghĩa thực tế.
Đầu tiên, chúng tôi đề xuất căn chỉnh hiệp phương sai của các lớp nhúng nhiệm vụ và trình bày các đánh giá thực nghiệm trên các benchmark và nhiệm vụ nổi tiếng. Trên 5 nhiệm vụ từ benchmark Đánh giá Hiểu biết Ngôn ngữ Tổng quát (GLUE) (Wang et al. (2018b)) được huấn luyện với mô hình BERT LARGE của Devlin et al. (2018), phương pháp của chúng tôi cải thiện kết quả của BERT LARGE bằng điểm GLUE trung bình 2.35%, đây là metric tiêu chuẩn cho benchmark. Hơn nữa, chúng tôi chỉ ra rằng phương pháp của chúng tôi có thể áp dụng cho các thiết lập học chuyển giao; chúng tôi quan sát độ chính xác cao hơn đến 2.5% bằng cách chuyển giao giữa sáu nhiệm vụ phân tích cảm xúc sử dụng mô hình LSTM của Lei et al. (2018).

Thứ hai, chúng tôi đề xuất một sơ đồ tái trọng số nhiệm vụ dựa trên SVD để cải thiện việc huấn luyện đa nhiệm vụ cho các thiết lập nơi các nhiệm vụ khác nhau có cùng đặc trưng nhưng nhãn khác nhau. Trên tập dữ liệu ChestX-ray14, chúng tôi so sánh phương pháp của chúng tôi với sơ đồ không trọng số và quan sát được cải thiện 0.4% điểm AUC trung bình cho tất cả các nhiệm vụ. Tóm lại, những đánh giá này xác nhận rằng những hiểu biết lý thuyết của chúng tôi có thể áp dụng cho một phạm vi rộng các thiết lập và ứng dụng.

2 BA THÀNH PHẦN CỦA HỌC TẬP ĐA NHIỆM VỤ
Chúng tôi nghiên cứu các mô hình học tập đa nhiệm vụ (MTL) với một mô-đun chung cho tất cả các nhiệm vụ và một mô-đun đầu ra riêng biệt cho mỗi nhiệm vụ. Chúng tôi hỏi: Các thành phần chính để xác định liệu MTL có tốt hơn học đơn nhiệm vụ (STL) hay không là gì? Để đáp lại, chúng tôi xác định ba thành phần: khả năng mô hình, hiệp phương sai nhiệm vụ, và sơ đồ tối ưu hóa. Sau khi thiết lập mô hình, chúng tôi mô tả ngắn gọn vai trò của khả năng mô hình. Sau đó chúng tôi giới thiệu khái niệm hiệp phương sai nhiệm vụ, bao gồm phần lớn của phần này. Chúng tôi kết thúc bằng cách chỉ ra những ý nghĩa của kết quả của chúng tôi cho việc lựa chọn các sơ đồ tối ưu hóa.

--- TRANG 3 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

2.1 THIẾT LẬP MÔ HÌNH
Chúng ta được cho k nhiệm vụ. Để mi biểu thị số lượng mẫu dữ liệu của nhiệm vụ i. Đối với nhiệm vụ i, để Xi∈Rmi×d biểu thị các hiệp biến và để yi∈Rmi biểu thị các nhãn, trong đó d là chiều của dữ liệu. Chúng tôi đã giả định rằng tất cả các nhiệm vụ có cùng chiều đầu vào d. Đây không phải là một giả định hạn chế và thường được thỏa mãn, ví dụ cho word embedding trên BERT, hoặc bằng cách đệm số không vào đầu vào trong trường hợp khác. Mô hình của chúng tôi giả định nhãn đầu ra là 1 chiều. Chúng ta cũng có thể mô hình một bài toán đa nhãn với k loại nhãn bằng cách có k nhiệm vụ với cùng hiệp biến nhưng nhãn khác nhau. Chúng tôi xem xét một mô hình MTL với một mô-đun chung B∈Rd×r và một mô-đun đầu ra riêng biệt Ai∈Rr cho nhiệm vụ i, trong đó r biểu thị chiều đầu ra của B. Xem Hình 1 để minh họa. Chúng tôi định nghĩa mục tiêu tìm một mô hình MTL là tối thiểu hóa phương trình sau trên B và các Ai:

f(A1;A2;:::;Ak;B) = Σi=1^k L(g(XiB)Ai;yi); (1)

trong đó L là một hàm mất mát như mất mát bình phương. Hàm kích hoạt g:R→R được áp dụng trên mọi phần tử của XiB. Trong phương trình 1, tất cả các mẫu dữ liệu đóng góp bằng nhau. Do sự khác biệt giữa các nhiệm vụ như kích thước dữ liệu, việc tái trọng số các nhiệm vụ trong quá trình huấn luyện là tự nhiên:

f(A1;A2;:::;Ak;B) = Σi=1^k λi L(g(XiB)Ai;yi); (2)

Thiết lập này là một sự trừu tượng hóa của kiến trúc chia sẻ tham số cứng (Ruder (2017)). Mô-đun chung B cung cấp một biểu diễn phổ quát (ví dụ, một LSTM để mã hóa câu) cho tất cả các nhiệm vụ. Mỗi mô-đun dành riêng cho nhiệm vụ Ai được tối ưu hóa cho đầu ra của nó. Chúng tôi tập trung vào hai mô hình như sau.

Mô hình tuyến tính đơn nhiệm vụ. Các nhãn y của mỗi nhiệm vụ tuân theo một mô hình tuyến tính với tham số θ∈Rd:
y = Xθ + ε. Mọi phần tử của ε tuân theo phân phối chuẩn N(0;σ²) với phương sai σ². Hàm g(XB) = XB. Đây là một thiết lập được nghiên cứu kỹ cho hồi quy tuyến tính (Hastie et al. (2005)).

Mô hình ReLU đơn nhiệm vụ. Ký hiệu ReLU(x) = max(x;0) cho bất kỳ x∈R. Chúng tôi cũng sẽ xem xét một mô hình phi tuyến nơi X đi qua hàm kích hoạt ReLU với a∈R và β∈Rd: y = a⋅ReLU(Xβ) + ε, áp dụng kích hoạt ReLU trên X theo từng phần tử. Hàm mã hóa g(XB) sau đó ánh xạ tới ReLU(XB).

Truyền tải tích cực vs. tiêu cực. Đối với một nhiệm vụ nguồn và một nhiệm vụ đích, chúng ta nói nhiệm vụ nguồn truyền tải tích cực cho nhiệm vụ đích, nếu việc huấn luyện cả hai thông qua phương trình 1 cải thiện so với chỉ huấn luyện nhiệm vụ đích (được đo trên tập validation của nó). Truyền tải tiêu cực là nghịch đảo của truyền tải tích cực.

Phát biểu bài toán. Mục tiêu của chúng tôi là phân tích ba thành phần để xác định truyền tải tích cực vs. tiêu cực giữa các nhiệm vụ: khả năng mô hình (r), hiệp phương sai nhiệm vụ ({Xi^T Xi}k i=1) và các trọng số theo từng nhiệm vụ ({λi}k i=1). Chúng tôi tập trung vào các nhiệm vụ hồi quy dưới mất mát bình phương nhưng chúng tôi cũng cung cấp các thí nghiệm tổng hợp trên các nhiệm vụ phân loại để xác thực lý thuyết của chúng tôi.

Ký hiệu. Đối với ma trận X, span cột của nó là tập hợp tất cả các tổ hợp tuyến tính của các vector cột của X. Để X† biểu thị nghịch đảo giả của nó. Cho u;v∈Rd, cos(u;v) bằng u^T v/(||u||||v||).

2.2 KHẢNĂNG MÔ HÌNH
Chúng tôi bắt đầu bằng cách xem xét lại vai trò của khả năng mô hình, tức là chiều đầu ra của B (ký hiệu bởi r). Chúng tôi chỉ ra rằng như một nguyên tắc chung, r nên nhỏ hơn tổng khả năng của các mô-đun STL.

Ví dụ. Giả sử chúng ta có k nhiệm vụ hồi quy tuyến tính sử dụng mất mát bình phương, phương trình 1 trở thành:

f(A1;A2;:::;Ak;B) = Σi=1^k ||XiBAi - yi||²F: (3)

Nghiệm tối ưu của phương trình 3 cho nhiệm vụ i là θi = (Xi^T Xi)^(-1) Xi^T yi ∈ Rd. Do đó một khả năng bằng 1 là đủ cho mỗi nhiệm vụ. Chúng tôi chỉ ra rằng nếu r ≥ k, thì không có sự truyền tải giữa bất kỳ hai nhiệm vụ nào.

--- TRANG 4 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

Truyền tải Tích cực
Truyền tải Tiêu cực-0.2-0.100.10.2
# Mẫu dữ liệu của nhiệm vụ nguồn2000400060008000Truyền tải Tích cực
Truyền tải Tiêu cực-0.2-0.100.10.2
# Mẫu dữ liệu của nhiệm vụ nguồn2000400060008000Truyền tải Tích cực
Truyền tải Tiêu cực-0.2-0.100.10.2
# Mẫu dữ liệu của nhiệm vụ nguồn2000400060008000Cùng hiệp phương sai (Nguồn: Nhiệm vụ 2) Hiệp phương sai khác (Nguồn: Nhiệm vụ 3)
(a) Các nhiệm vụ hồi quy tuyến tính (b) Các nhiệm vụ phân loại logistic (c) Các nhiệm vụ hồi quy ReLUHiệu suất Nhiệm vụ đích: MTL - STLNguồn vs. đích (Nhiệm vụ 1):

Hình 3: Cải thiện hiệu suất của một nhiệm vụ đích (Nhiệm vụ 1) bằng MTL với một nhiệm vụ nguồn vs. STL.
Đỏ: truyền tải tích cực khi nguồn là Nhiệm vụ 2, có cùng ma trận hiệp phương sai với đích.
Xanh lá: truyền tải tiêu cực (đến tích cực) khi nguồn là Nhiệm vụ 3, có hiệp phương sai khác với đích, khi số mẫu của nó tăng. Xem ví dụ bên dưới để định nghĩa mỗi nhiệm vụ.

Mệnh đề 1. Để r ≥ k. Tồn tại một tối ưu B* và {Ai*}k i=1 của phương trình 3 nơi B*Ai* = θi, cho tất cả i = 1;2;:::;k.

Để minh họa ý tưởng, miễn là B* chứa {θi}k i=1 trong span cột của nó, tồn tại Ai* sao cho B*Ai* = θi, điều này là tối ưu cho phương trình 3 với lỗi tối thiểu. Nhưng điều này có nghĩa là không có sự truyền tải giữa bất kỳ hai nhiệm vụ nào. Điều này có thể làm tổn hại khả năng tổng quát hóa nếu một nhiệm vụ có dữ liệu hạn chế, trong trường hợp đó nghiệm STL của nó overfits dữ liệu huấn luyện, trong khi nghiệm MTL có thể tận dụng dữ liệu của các nhiệm vụ khác để cải thiện khả năng tổng quát hóa. Chứng minh của Mệnh đề 1 và phần mở rộng cho các thiết lập ReLU có trong Phụ lục A.1.

Hệ quả thuật toán. Ý nghĩa là việc hạn chế khả năng của mô-đun chung là cần thiết để buộc sự truyền tải thông tin. Nếu mô-đun chung quá nhỏ, thì các nhiệm vụ có thể can thiệp tiêu cực với nhau. Nhưng nếu nó quá lớn, thì có thể không có sự truyền tải giữa các nhiệm vụ. Trong Phần 3.3, chúng tôi xác minh nhu cầu lựa chọn cẩn thận khả năng mô hình trên một loạt rộng các mạng nơ-ron bao gồm CNN, LSTM và perceptron đa lớp.

2.3 HIỆP PHƯƠNG SAI NHIỆM VỤ
Để chỉ ra cách định lượng sự tương tự dữ liệu nhiệm vụ, chúng tôi minh họa với hai nhiệm vụ hồi quy dưới mô hình tuyến tính không có nhiễu: y1 = X1θ1 và y2 = X2θ2. Theo Phần 2.2, việc hạn chế khả năng của mô-đun chung là cần thiết để buộc sự truyền tải thông tin. Do đó, chúng tôi xem xét trường hợp r = 1. Do đó, mô-đun chung B bây giờ là một vector d chiều, và A1;A2 đều là số vô hướng.

Một yêu cầu tự nhiên về sự tương tự nhiệm vụ là để các mô hình STL tương tự, tức là |cos(θ1;θ2)| lớn. Để thấy điều này, mô hình STL tối ưu cho nhiệm vụ 1 là (X1^T X1)^(-1) X1^T y1 = θ1. Do đó nếu |cos(θ1;θ2)| bằng 1, thì nhiệm vụ 1 và 2 có thể chia sẻ một mô hình B∈Rd là θ1 hoặc -θ1. Các số vô hướng A1 và A2 sau đó có thể biến đổi B để bằng θ1 và θ2.

Yêu cầu này có đủ không? Nhớ rằng trong phương trình 3, dữ liệu nhiệm vụ X1 và X2 đều được nhân với B. Nếu chúng được "căn chỉnh" kém về mặt hình học, hiệu suất có thể bị ảnh hưởng. Làm thế nào chúng ta chính thức hóa hình học giữa sự căn chỉnh nhiệm vụ? Trong phần sau, chúng tôi chỉ ra rằng các ma trận hiệp phương sai của X1 và X2, mà chúng tôi định nghĩa là X1^T X1 và X2^T X2, nắm bắt hình học. Chúng tôi cố định |cos(θ1;θ2)| gần bằng 1 để kiểm tra tác động của hiệp phương sai nhiệm vụ. Trong Phụ lục A.2.1 chúng tôi cố định hiệp phương sai nhiệm vụ để kiểm tra tác động của sự tương tự cosine mô hình. Cụ thể, phương trình 3 rút gọn thành:

max B∈Rd h(B) = ⟨X1B/||X1B||;y1⟩² + ⟨X2B/||X2B||;y2⟩²; (4)

trong đó chúng tôi áp dụng điều kiện tối ưu bậc nhất trên A1 và A2 và đơn giản hóa phương trình. Cụ thể, chúng tôi tập trung vào một kịch bản nơi nhiệm vụ 1 là nguồn và nhiệm vụ 2 là đích. Mục tiêu của chúng tôi là xác định khi nào nguồn truyền tải cho đích một cách tích cực hoặc tiêu cực trong MTL. Xác định loại truyền tải từ nhiệm vụ 2 sang nhiệm vụ 1 có thể được thực hiện tương tự. Trả lời câu hỏi quy về việc nghiên cứu góc hoặc sự tương tự cosine giữa tối ưu của phương trình 4 và θ2.

Ví dụ. Trong Hình 3, chúng tôi chỉ ra rằng bằng cách thay đổi hiệp phương sai nhiệm vụ và số lượng mẫu, chúng ta có thể quan sát cả việc truyền tải tích cực và tiêu cực. Thông điệp khái niệm giống như Hình 2; chúng tôi

--- TRANG 5 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

Thuật toán 1 Căn chỉnh hiệp phương sai cho huấn luyện đa nhiệm vụ
Yêu cầu: Các lớp nhúng nhiệm vụ X1∈Rm1×d;X2∈Rm2×d;:::;Xk∈Rmk×d, mô-đun chung B
Tham số: Các ma trận căn chỉnh R1;R2;:::;Rk∈Rd×d và các mô-đun đầu ra A1;A2:::;Ak∈Rr
1: Để Zi = XiRi, cho 1 ≤ i ≤ k.
Xem xét hàm mất mát được sửa đổi sau (với B được cố định):
f̂(A1;:::;Ak;R1;:::;Rk) = Σi=1^k L(g(ZiB)Ai;yi) = Σi=1^k L(g(XiRiB)Ai;yi)
2: Tối thiểu hóa f̂ bằng cách luân phiên áp dụng cập nhật gradient descent trên Ai và Ri, cho một batch dữ liệu được lấy mẫu từ nhiệm vụ i.
Các chi tiết thực hiện khác được mô tả trong Phụ lục B.3.

mô tả quá trình tạo dữ liệu chi tiết hơn. Chúng tôi sử dụng 3 nhiệm vụ và đo loại truyền tải từ nguồn đến đích. Trục x là số lượng mẫu dữ liệu từ nguồn. Trục y là cải thiện hiệu suất của đích được đo trên tập validation của nó giữa MTL trừ STL.

Tạo dữ liệu. Chúng ta có |cos(θ1;θ2)| ≈ 1 (giả sử 0.96). Cho i∈{1;2;3}, để Ri∈Rmi×d biểu thị một ma trận Gaussian ngẫu nhiên được rút từ N(0;1). Để S1;S2⊆{1;2;:::;d} là hai tập hợp rời rạc có kích thước d/10. Cho i = 1;2, để Di là một ma trận chéo có các phần tử bằng một giá trị lớn (ví dụ: κ = 100) cho các tọa độ trong Si và 1 trong trường hợp khác. Để Qi∈Rd×d biểu thị một ma trận trực chuẩn, tức là Qi^T Qi bằng ma trận đơn vị, được trực chuẩn hóa từ một ma trận Gaussian ngẫu nhiên.

Sau đó, chúng tôi định nghĩa 3 nhiệm vụ như sau. (i) Nhiệm vụ 1 (đích): X1 = R1Q1D1 và y1 = X1θ1. (ii) Nhiệm vụ 2 (nhiệm vụ nguồn cho đường đỏ): X2 = R2Q1D1 và y2 = X2θ2. (iii) Nhiệm vụ 3 (nhiệm vụ nguồn cho đường xanh): X3 = R3Q2D2 và y3 = X3θ2. Nhiệm vụ 1 và 2 có cùng ma trận hiệp phương sai nhưng nhiệm vụ 1 và 3 có ma trận hiệp phương sai khác nhau. Trực quan, các tín hiệu của nhiệm vụ 1 và 3 nằm trong các không gian con khác nhau, phát sinh từ sự khác biệt trong các đường chéo của Di và các ma trận trực chuẩn.

Phân tích. Trừ khi nhiệm vụ nguồn có nhiều mẫu để ước lượng θ2, nhiều hơn rất nhiều so với các mẫu cần để chỉ ước lượng các tọa độ của S1, thì hiệu ứng truyền tải cho đích là nhỏ. Chúng tôi quan sát kết quả tương tự cho các nhiệm vụ hồi quy logistic và cho các nhiệm vụ hồi quy được kích hoạt bằng ReLU.

Lý thuyết. Chúng tôi định lượng chặt chẽ cần bao nhiêu điểm dữ liệu để đảm bảo truyền tải tích cực. Quan niệm phổ biến trong MTL là khi một nhiệm vụ nguồn có nhiều dữ liệu nhưng nhiệm vụ đích liên quan có dữ liệu hạn chế, thì nguồn thường có thể truyền tải tích cực cho đích. Ví dụ trước của chúng tôi chỉ ra rằng bằng cách thay đổi số lượng mẫu của nguồn và hiệp phương sai của nó, chúng ta có thể quan sát cả hai loại truyền tải. Chúng ta cần bao nhiêu dữ liệu từ nguồn để đảm bảo một sự truyền tải tích cực cho đích? Chúng tôi chỉ ra rằng điều này phụ thuộc vào số điều kiện của hiệp phương sai của cả hai nhiệm vụ.

Định lý 2 (không chính thức). Cho i = 1;2, để yi = Xiθi + εi biểu thị hai nhiệm vụ hồi quy tuyến tính với tham số θi∈Rd và mi số lượng mẫu. Giả sử rằng mỗi hàng của nhiệm vụ nguồn X1 được rút độc lập từ một phân phối với hiệp phương sai Σ1∈Rd×d và chuẩn l2 có giới hạn. Để c = κ(X2)sin(θ1;θ2) và giả sử rằng c ≤ 1/3. Ký hiệu (B*;A1*;A2*) là nghiệm MTL tối ưu. Với xác suất cao, khi m1 ít nhất ở bậc (κ²(Σ1)κ⁴(X2)||y2||²)/c⁴, chúng ta có

||B*A2* - θ2||/||θ2|| ≤ 6c + (1-13c)||ε2||/||X2θ2||: (5)

Nhớ rằng đối với ma trận X, κ(X) biểu thị số điều kiện của nó. Định lý 2 định lượng xu hướng trong Hình 3, nơi các cải thiện cho nhiệm vụ 2 đạt đến đỉnh cao khi m1 trở nên đủ lớn. Tham số c ở đây chỉ ra mức độ tương tự của hai nhiệm vụ. sin(θ1;θ2) càng nhỏ thì c càng nhỏ. Như một ví dụ, nếu sin(θ1;θ2) ≤ γ/κ(X2) cho một số γ, thì phương trình 5 là nhiều nhất O(γ) + ||ε2||/||X2θ2||.¹ Phát biểu chính thức, chứng minh và thảo luận về các giả định được hoãn lại trong Phụ lục A.2.2.

Mô hình ReLU. Chúng tôi chỉ ra một kết quả tương tự cho mô hình ReLU, đòi hỏi giải quyết thách thức phân tích hàm ReLU. Chúng tôi sử dụng một đặc tính hình học cho hàm ReLU dưới các giả định đầu vào phân phối bởi Du et al. (2017). Kết quả được hoãn lại trong Phụ lục A.2.3.

¹Lỗi ước lượng của θ2 được giới hạn trên bởi tỷ lệ tín hiệu-nhiễu của nhiệm vụ 2 ||ε2||/||X2θ2||. Sự phụ thuộc này phát sinh vì thành phần tuyến tính A2* khớp với phép chiếu của y2 lên X2B*. Vì vậy ngay cả khi B* bằng θ2, vẫn có thể có lỗi ước lượng từ A2*, điều này không thể được ước lượng từ dữ liệu của nhiệm vụ 1.

--- TRANG 6 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

Thuật toán 2 Một sơ đồ tái trọng số nhiệm vụ dựa trên SVD
Đầu vào: k nhiệm vụ: (X;yi)∈(Rm×d;Rm); một tham số hạng r∈{1;2;:::;k}
Đầu ra: Một vector trọng số: {λ1;λ2;:::;λk}
1: Để βi = X^T yi.
2: Ur;Dr;Vr = SVDr(β1;β2;:::;βk), tức là xấp xỉ hạng-r tốt nhất cho các βi.
3: Để λi = ||βi^T Ur||, cho i = 1;2;:::;k.

Hệ quả thuật toán. Một ý nghĩa của lý thuyết chúng tôi là một phương pháp căn chỉnh hiệp phương sai để cải thiện huấn luyện đa nhiệm vụ. Đối với nhiệm vụ thứ i, chúng tôi thêm một ma trận căn chỉnh Ri trước khi đầu vào Xi của nó đi qua mô-đun chung B. Thuật toán 1 chỉ ra quy trình.

Chúng tôi cũng đề xuất một metric gọi là điểm tương tự hiệp phương sai để đo sự tương tự giữa hai nhiệm vụ. Cho X1∈Rm1×d và X2∈Rm2×d, chúng tôi đo sự tương tự của chúng trong ba bước: (a) Ma trận hiệp phương sai là X1^T X1. (b) Tìm xấp xỉ hạng-r1 tốt nhất là U1,r1 D1,r1 U1,r1^T, trong đó r1 được chọn để chứa 99% của các giá trị singualar. (c) Áp dụng bước (a),(b) cho X2, tính điểm:

Điểm tương tự hiệp phương sai := ||(U1,r1 D1,r1^(1/2))^T U2,r2 D2,r2^(1/2)||F / (||U1,r1 D1,r1^(1/2)||F ||U2,r2 D2,r2^(1/2)||F): (6)

Tính chất tốt của điểm số là nó bất biến với các phép quay của các cột của X1 và X2.

2.4 SƠ ĐỒ TỐI ƯU HÓA
Cuối cùng, chúng tôi xem xét hiệu ứng của việc tái trọng số các nhiệm vụ (hoặc các mất mát của chúng trong phương trình 2). Khi nào việc tái trọng số các nhiệm vụ giúp ích? Trong phần này, chúng tôi chỉ ra một trường hợp sử dụng để cải thiện tính mạnh mẽ của huấn luyện đa nhiệm vụ trong sự hiện diện của nhiễu nhãn. Các thiết lập liên quan đến nhiễu nhãn có thể phát sinh khi một số nhiệm vụ chỉ có các nhãn được giám sát yếu, đã được nghiên cứu trước đây trong tài liệu (ví dụ: Mintz et al. (2009); Pentina and Lampert (2017)). Chúng tôi bắt đầu bằng cách mô tả một ví dụ động lực.

Xem xét hai nhiệm vụ nơi nhiệm vụ 1 là y1 = Xθ và nhiệm vụ 2 là y2 = Xθ + ε2. Nếu chúng ta huấn luyện hai nhiệm vụ cùng nhau, lỗi ε2 sẽ thêm nhiễu vào mô hình được huấn luyện. Tuy nhiên, bằng cách tăng trọng số nhiệm vụ 1, chúng ta giảm nhiễu từ nhiệm vụ 2 và có được hiệu suất tốt hơn. Để nghiên cứu chặt chẽ hiệu ứng của trọng số nhiệm vụ, chúng tôi xem xét một thiết lập nơi tất cả các nhiệm vụ có cùng dữ liệu nhưng nhãn khác nhau. Thiết lập này phát sinh ví dụ trong các nhiệm vụ hình ảnh đa nhãn. Chúng tôi rút ra nghiệm tối ưu trong mô hình tuyến tính.

Mệnh đề 3. Để mô-đun chung có khả năng r ≤ k. Cho k nhiệm vụ với cùng hiệp biến X∈Rm×d nhưng nhãn khác nhau {yi}k i=1. Để X có hạng đầy đủ và UDV^T là SVD của nó. Để QrQr^T là xấp xỉ hạng-r tốt nhất cho Σi=1^k λi U^T yi yi^T U. Để B*∈Rd×r là một nghiệm tối ưu cho mất mát tái trọng số. Khi đó span cột của B* bằng span cột của (X^T X)^(-1) VDQr.

Chúng ta cũng có thể mở rộng Mệnh đề 3 để chỉ ra rằng tất cả các cực tiểu địa phương của phương trình 3 đều là cực tiểu toàn cục trong thiết lập tuyến tính. Chúng tôi để chứng minh trong Phụ lục A.3. Chúng tôi lưu ý rằng kết quả này không mở rộng cho thiết lập ReLU phi tuyến và để lại điều này cho công việc tương lai.

Dựa trên Mệnh đề 3, chúng tôi cung cấp một chứng minh chặt chẽ của ví dụ trước. Giả sử rằng X có hạng đầy đủ, (X^T X)^(-1) X^T [λ1 y1; λ1 y2]) = [λ1; λ2 + λ2(X^T X)^(-1) X^T ε2]. Do đó, khi chúng ta tăng λ1, cos(B*; θ) tăng gần hơn đến 1.

Hệ quả thuật toán. Được truyền cảm hứng bởi lý thuyết của chúng tôi, chúng tôi mô tả một sơ đồ tái trọng số trong sự hiện diện của nhiễu nhãn. Chúng tôi tính các trọng số theo từng nhiệm vụ bằng cách tính SVD trên X^T yi, cho 1 ≤ i ≤ k. Trực quan là nếu vector nhãn của một nhiệm vụ yi có nhiễu, thì entropy của yi là nhỏ. Do đó, chúng tôi muốn thiết kế một quy trình loại bỏ nhiễu. Quy trình SVD thực hiện điều này, nơi trọng số của một nhiệm vụ được tính bằng phép chiếu của nó vào các hướng chính r. Xem Thuật toán 2 để mô tả.

--- TRANG 7 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

𝐴#		𝐴$		𝐴%…	𝐴&'$	𝐴&'#		𝐴&Các Nhúng Nhiệm vụCác Mô-đun Chung (LSTM/BERT) 	𝑅&		𝐼#	𝑅$	𝑅%…	𝑅&'$	𝑅&'#		𝑋#		𝑋$		𝑋%…	𝑋&'$	𝑋&'#		𝑋&𝐸,𝑍,

Hình 4: Minh họa mô-đun căn chỉnh hiệp phương sai trên các nhúng nhiệm vụ.

3 THỰC NGHIỆM
Chúng tôi mô tả các kết nối giữa kết quả lý thuyết của chúng tôi và các vấn đề thực tế có ý nghĩa. Chúng tôi chỉ ra ba tuyên bố trên các tập dữ liệu thế giới thực. (i) Mô-đun MTL chung hoạt động tốt nhất khi khả năng của nó nhỏ hơn tổng khả năng của các mô hình đơn nhiệm vụ. (ii) Phương pháp căn chỉnh hiệp phương sai được đề xuất của chúng tôi cải thiện huấn luyện đa nhiệm vụ trên nhiều thiết lập khác nhau bao gồm các benchmark GLUE và sáu nhiệm vụ phân tích cảm xúc. Phương pháp của chúng tôi có thể được mở rộng tự nhiên cho các thiết lập học chuyển giao và chúng tôi cũng xác thực điều này. (iii) Sơ đồ tái trọng số dựa trên SVD của chúng tôi mạnh mẽ hơn sơ đồ không trọng số tiêu chuẩn trên các nhiệm vụ phân loại hình ảnh đa nhãn trong sự hiện diện của nhiễu nhãn.

3.1 THIẾT LẬP THỰC NGHIỆM
Tập dữ liệu và mô hình. Chúng tôi mô tả các tập dữ liệu và mô hình chúng tôi sử dụng trong các thí nghiệm.

GLUE: GLUE là một tập dữ liệu hiểu biết ngôn ngữ tự nhiên bao gồm các vấn đề trả lời câu hỏi, phân tích cảm xúc, tương tự văn bản và suy diễn văn bản. Chúng tôi chọn BERT LARGE làm mô hình của chúng tôi, đây là một mạng transformer 24 lớp từ Devlin et al. (2018). Chúng tôi sử dụng tập dữ liệu này để đánh giá cách Thuật toán 1 hoạt động trên mô hình BERT tiên tiến.

Phân tích Cảm xúc: Tập dữ liệu này bao gồm sáu nhiệm vụ: cảm xúc đánh giá phim (MR), chủ quan câu (SUBJ), cực tính đánh giá khách hàng (CR), loại câu hỏi (TREC), cực tính ý kiến (MPQA), và các nhiệm vụ ngân hàng cảm xúc Stanford (SST).

Đối với mỗi nhiệm vụ, mục tiêu là phân loại ý kiến cảm xúc được thể hiện trong văn bản. Chúng tôi sử dụng một lớp nhúng (với nhúng GloVe²) theo sau bởi một lớp LSTM được đề xuất bởi Lei et al. (2018)³.

ChestX-ray14: Tập dữ liệu này chứa 112,120 hình ảnh X-quang mặt trước và mỗi hình ảnh có tối đa 14 bệnh. Đây là một bài toán phân loại hình ảnh đa nhãn 14 nhiệm vụ. Chúng tôi sử dụng mô hình CheXNet từ Rajpurkar et al. (2017), là một mạng nơ-ron tích chập 121 lớp trên tất cả các nhiệm vụ.

Đối với tất cả các mô hình, chúng tôi chia sẻ mô-đun chính trên tất cả các nhiệm vụ (BERT LARGE cho GLUE, LSTM cho phân tích cảm xúc, CheXNet cho ChestX-ray14) và gán một lớp hồi quy hoặc phân loại riêng biệt trên đầu của mô-đun chung cho mỗi nhiệm vụ.

Phương pháp so sánh. Đối với thí nghiệm về huấn luyện đa nhiệm vụ, chúng tôi so sánh Thuật toán 1 bằng cách huấn luyện với phương pháp của chúng tôi và huấn luyện không có nó. Cụ thể, chúng tôi áp dụng quy trình căn chỉnh trên các lớp nhúng nhiệm vụ. Xem Hình 4 để minh họa, nơi Ei biểu thị nhúng của nhiệm vụ i, Ri biểu thị mô-đun căn chỉnh của nó và Zi = EiRi là nhúng được xoay.

Đối với học chuyển giao, trước tiên chúng tôi huấn luyện một mô hình STL trên nhiệm vụ nguồn bằng cách điều chỉnh khả năng mô hình của nó (ví dụ: chiều đầu ra của lớp LSTM). Sau đó, chúng tôi tinh chỉnh mô hình STL trên nhiệm vụ đích trong 5-10 epoch. Để áp dụng Thuật toán 1, chúng tôi thêm một mô-đun căn chỉnh cho nhiệm vụ đích trong quá trình tinh chỉnh.

Đối với thí nghiệm về các sơ đồ tái trọng số, chúng tôi tính các trọng số theo từng nhiệm vụ như mô tả trong Thuật toán 2. Sau đó, chúng tôi tái trọng số hàm mất mát như trong phương trình 2. Chúng tôi so sánh với các kỹ thuật tái trọng số của Kendall et al. (2018). Một cách không chính thức, phương pháp sau sử dụng likelihood Gaussian để mô hình hóa các đầu ra phân loại.

²http://nlp.stanford.edu/data/wordvecs/glove.6B.zip
³Chúng tôi cũng đã thử nghiệm với perceptron đa lớp và CNN. Kết quả tương tự (xem Phụ lục B.5).

--- TRANG 8 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

−0.6
4.3
−2.4
1−0.6
5.8
−1.9
2.74.3
5.8
0.1
0.7−2.4
−1.9
0.1
1.11
2.7
0.7
1.1
SSTRTEQNLIMRPCCOLA
COLAMRPC QNLIRTESST
(a) MTL trên GLUE trên 10 cặp nhiệm vụ
Cơ sở
Căn chỉnh 
Hiệp phương saiĐộ chính xác LSTM
0.750.800.850.900.95
CRMPQA MR SUBJ TREC (b) Học chuyển giao trên sáu nhiệm vụ phân tích cảm xúc

Hình 5: Cải thiện hiệu suất của Thuật toán 1 bằng cách căn chỉnh các nhúng nhiệm vụ.

ﬁcation outputs. Các trọng số, được định nghĩa là tỷ lệ nghịch đảo với phương sai của Gaussian, được tối ưu hóa trong quá trình huấn luyện. Chúng tôi cũng so sánh với mất mát không trọng số (xem phương trình 1) làm cơ sở.

Metric. Chúng tôi đo hiệu suất trên benchmark GLUE sử dụng một metric tiêu chuẩn gọi là điểm GLUE, chứa điểm chính xác và tương quan cho mỗi nhiệm vụ.

Đối với các nhiệm vụ phân tích cảm xúc, chúng tôi đo độ chính xác của việc dự đoán ý kiến cảm xúc.

Đối với nhiệm vụ phân loại hình ảnh, chúng tôi đo điểm diện tích dưới đường cong (AUC). Chúng tôi chạy năm seed ngẫu nhiên khác nhau để báo cáo kết quả trung bình. Kết quả của một thí nghiệm MTL được lấy trung bình trên kết quả của tất cả các nhiệm vụ, trừ khi được chỉ định khác.

Đối với các quy trình huấn luyện và các chi tiết khác về thiết lập, chúng tôi tham khảo độc giả đến Phụ lục B.

3.2 KẾT QUẢ THỰC NGHIỆM
Chúng tôi trình bày các trường hợp sử dụng của phương pháp của chúng tôi trên các tập dữ liệu mã nguồn mở. Chúng tôi mong đợi thấy cải thiện thông qua phương pháp của chúng tôi trong đa nhiệm vụ và các thiết lập khác, và thực sự chúng tôi đã thấy những lợi ích như vậy trên nhiều nhiệm vụ khác nhau.

Cải thiện huấn luyện đa nhiệm vụ. Chúng tôi áp dụng Thuật toán 1 trên năm nhiệm vụ (CoLA, MRPC, QNLI, RTE, SST-2) từ benchmark GLUE sử dụng mô hình ngôn ngữ tiên tiến BERT LARGE.⁴ Chúng tôi huấn luyện các lớp đầu ra {Ai} và các lớp căn chỉnh {Ri} sử dụng thuật toán của chúng tôi. Chúng tôi so sánh hiệu suất trung bình trên tất cả năm nhiệm vụ và thấy rằng phương pháp của chúng tôi vượt trội hơn BERT LARGE bằng điểm GLUE trung bình 2.35% cho năm nhiệm vụ. Đối với thiết lập cụ thể của việc huấn luyện hai nhiệm vụ, phương pháp của chúng tôi vượt trội hơn BERT LARGE trên 7 trong 10 cặp nhiệm vụ. Xem Hình 5a cho kết quả.

Cải thiện học chuyển giao. Trong khi nghiên cứu của chúng tôi tập trung vào học đa nhiệm vụ, học chuyển giao là một mục tiêu liên quan tự nhiên – và chúng tôi thấy rằng phương pháp của chúng tôi cũng hữu ích trong trường hợp này. Chúng tôi xác thực điều này bằng cách huấn luyện một LSTM trên phân tích cảm xúc. Hình 5b chỉ ra kết quả với SST là nhiệm vụ nguồn và phần còn lại là nhiệm vụ đích. Thuật toán 1 cải thiện độ chính xác trên bốn nhiệm vụ lên đến 2.5%.

Tái trọng số huấn luyện cho cùng hiệp biến nhiệm vụ. Chúng tôi đánh giá Thuật toán 2 trên tập dữ liệu ChestX-ray14. Thiết lập này thỏa mãn giả định của Thuật toán 2, yêu cầu các nhiệm vụ khác nhau có cùng dữ liệu đầu vào. Trên tất cả 14 nhiệm vụ, chúng tôi thấy rằng phương pháp tái trọng số của chúng tôi cải thiện kỹ thuật của Kendall et al. (2018) bằng 0.1% điểm AUC. So với huấn luyện với mất mát không trọng số, phương pháp của chúng tôi cải thiện hiệu suất bằng 0.4% điểm AUC trên tất cả các nhiệm vụ.

3.3 NGHIÊN CỨU ABLATION
Khả năng mô hình. Chúng tôi xác minh giả thuyết của chúng tôi rằng khả năng của mô hình MTL không nên vượt quá tổng khả năng của mô hình STL. Chúng tôi chỉ ra điều này trên một mô hình LSTM với các nhiệm vụ phân tích cảm xúc. Nhớ rằng khả năng của một mô hình LSTM là chiều đầu ra của nó (trước lớp phân loại cuối cùng). Chúng tôi huấn luyện một mô hình MTL với tất cả các nhiệm vụ và thay đổi khả năng của mô-đun chung để tìm tối ưu từ 5 đến 500. Tương tự chúng tôi huấn luyện một mô hình STL cho mỗi nhiệm vụ và tìm tối ưu.

Trong Hình 1, chúng tôi thấy rằng hiệu suất của MTL đạt đỉnh khi mô-đun chung có khả năng 100. Điều này nhỏ hơn nhiều so với tổng khả năng của tất cả các mô hình STL. Kết quả xác nhận rằng

⁴https://github.com/google-research/bert

--- TRANG 9 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

Bảng 1: So sánh khả năng mô hình giữa
MTL và STL.
Nhiệm vụSTL MTL
Khả năng Độ chính xác Khả năng Độ chính xác
SST 200 82.3
10090.8
MR 200 76.4 96.0
CR 5 73.2 78.7
SUBJ 200 91.5 89.5
MPQA 500 86.7 87.0
TREC 100 85.7 78.7
Tổng thể 1205 82.6 100 85.1Hình 6: Điểm tương tự hiệp phương sai vs.
cải thiện hiệu suất từ căn chỉnh.
TREC,SUBJ
CR,MR
MPQA,SUBJ
CR, SUBJ
TREC,SSTCăn chỉnh 
Hiệp phương sai LSTM
Cơ sởCải thiện Hiệu suất00.020.04
Điểm tương tự hiệp phương sai0.1 0.2 0.3 0.4 0.5

việc hạn chế khả năng của mô-đun chung là quan trọng để đạt được hiệu suất lý tưởng. Kết quả mở rộng trên CNN/MLP để hỗ trợ giả thuyết của chúng tôi được thể hiện trong Phụ lục B.5.

Hiệp phương sai nhiệm vụ. Chúng tôi áp dụng metric điểm tương tự hiệp phương sai nhiệm vụ của chúng tôi từ Phần 2.3 để cung cấp một nghiên cứu sâu về phương pháp căn chỉnh hiệp phương sai. Giả thuyết là: (a) việc căn chỉnh hiệp phương sai giúp ích, điều mà chúng tôi đã chỉ ra trong Hình 5a; (b) điểm tương tự giữa hai nhiệm vụ tăng sau khi áp dụng căn chỉnh. Chúng tôi xác minh giả thuyết trên các nhiệm vụ phân tích cảm xúc. Chúng tôi sử dụng nhúng của mô hình đơn nhiệm vụ trước lớp LSTM để tính hiệp phương sai.

Đầu tiên, chúng tôi đo điểm tương tự sử dụng phương trình 6 giữa tất cả sáu mô hình đơn nhiệm vụ. Sau đó, đối với mỗi cặp nhiệm vụ, chúng tôi huấn luyện một mô hình MTL sử dụng Thuật toán 1. Chúng tôi đo điểm tương tự trên mô hình MTL được huấn luyện. Kết quả của chúng tôi xác nhận giả thuyết (Hình 6): (a) chúng tôi quan sát độ chính xác tăng trên 13 trong 15 cặp nhiệm vụ lên đến 4.1%; (b) điểm tương tự tăng cho tất cả 15 cặp nhiệm vụ.

Sơ đồ tối ưu hóa. Chúng tôi xác minh tính mạnh mẽ của Thuật toán 2. Sau khi chọn hai nhiệm vụ từ tập dữ liệu ChestX-ray14, chúng tôi thử nghiệm phương pháp của chúng tôi bằng cách gán nhãn ngẫu nhiên cho 20% dữ liệu trên một nhiệm vụ. Các nhãn cho nhiệm vụ khác vẫn không thay đổi.

Trên 10 cặp được chọn ngẫu nhiên, phương pháp của chúng tôi cải thiện so với sơ đồ không trọng số bằng điểm AUC trung bình 1.0% và so với kỹ thuật của Kendall et al. (2018) bằng điểm AUC trung bình 0.4%. Chúng tôi bao gồm thêm chi tiết của thí nghiệm này trong Phụ lục B.5.

4 CÔNG TRÌNH LIÊN QUAN
Đã có một khối lượng lớn công trình gần đây về việc sử dụng phương pháp học đa nhiệm vụ để huấn luyện mạng nơ-ron sâu. Liu et al. (2019a); McCann et al. (2018) và công trình tiếp theo cho thấy kết quả tiên tiến trên benchmark GLUE, điều này đã truyền cảm hứng cho nghiên cứu của chúng tôi về một sự trừu tượng hóa của mô hình MTL. Công trình gần đây của Zamir et al. (2018); Standley et al. (2019) trả lời nhiệm vụ thị giác nào để huấn luyện cùng nhau thông qua một heuristic liên quan đến tính toán chuyên sâu. Chúng tôi thảo luận một số dòng nghiên cứu liên quan đến công trình này. Để tham khảo đầy đủ, chúng tôi giới thiệu độc giả quan tâm đến khảo sát của Ruder (2017); Zhang and Yang (2017) và các khảo sát về thích ứng miền và học chuyển giao bởi Pan and Yang (2009); Kouw (2018) để tham khảo.

Nghiên cứu lý thuyết của học đa nhiệm vụ. Đặc biệt liên quan đến công trình này là những nghiên cứu lý thuyết học đa nhiệm vụ. Các công trình trước đó của Baxter (2000); Ben-David and Schuller (2003) là một trong những nghiên cứu chính thức đầu tiên về tầm quan trọng của sự liên quan nhiệm vụ cho việc học nhiều nhiệm vụ. Xem thêm công trình tiếp theo của Maurer (2006) nghiên cứu giới hạn tổng quát hóa của MTL.

Một dòng công trình liên quan chặt chẽ đến học cấu trúc là lựa chọn không gian con, tức là cách chọn một không gian con chung cho nhiều nhiệm vụ. Ví dụ từ dòng công trình này bao gồm Obozinski et al. (2010); Wang et al. (2015); Fernando et al. (2013); Elhamifar et al. (2015). Evgeniou and Pontil (2004); Micchelli and Pontil (2005) nghiên cứu một công thức mở rộng máy vector hỗ trợ cho thiết lập đa nhiệm vụ. Xem thêm Argyriou et al. (2008); Pentina et al. (2015); Pentina and Ben-David (2015); Pentina and Lampert (2017) cung cấp các phương pháp tối ưu hóa tinh tế hơn và nghiên cứu thêm. Công trình của Ben-David et al. (2010) cung cấp lý thuyết để đo sự khác biệt giữa nhiệm vụ nguồn và đích cho học chuyển giao trong một thiết lập mô hình khác. Khodak et al. (2019); Kong et al. (2020);

--- TRANG 10 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

Du et al. (2020) xem xét thiết lập meta learning liên quan, về bản chất là một thiết lập trực tuyến của học đa nhiệm vụ.

Kết quả của chúng tôi về việc hạn chế khả năng mô hình cho học đa nhiệm vụ tương phản với các nghiên cứu lý thuyết gần đây về các mô hình over-parametrized (ví dụ: Li et al. (2018); Zhang et al. (2019a); Bartlett et al. (2020)), nơi khả năng mô hình thường lớn hơn nhiều so với chế độ chúng tôi xem xét ở đây.
Sẽ thú vị để hiểu rõ hơn học đa nhiệm vụ trong bối cảnh các mô hình over-parametrized liên quan đến các hiện tượng khác như double descent đã được quan sát trong các bối cảnh khác (Belkin et al. (2019)).

Cuối cùng, Zhang et al. (2019b); Shui et al. (2019) xem xét học đa nhiệm vụ từ quan điểm tính mạnh mẽ adversarial. Mahmud and Ray (2008) xem xét sử dụng độ phức tạp Kolmogorov để đo hiệu quả của học chuyển giao cho các phương pháp cây quyết định.

Chia sẻ tham số cứng vs. chia sẻ tham số mềm. Kiến trúc mà chúng tôi nghiên cứu trong công trình này cũng được biết đến như kiến trúc chia sẻ tham số cứng. Có một loại kiến trúc khác gọi là chia sẻ tham số mềm. Ý tưởng là mỗi nhiệm vụ có các tham số và mô-đun riêng của nó. Các mối quan hệ giữa những tham số này được điều chuẩn để khuyến khích các tham số tương tự nhau. Các kiến trúc khác đã được nghiên cứu trước đây bao gồm công trình của Misra et al. (2016), nơi các tác giả khám phá các kiến trúc có thể huấn luyện cho mạng nơ-ron tích chập.

Thích ứng miền. Một dòng công trình liên quan chặt chẽ khác là về thích ứng miền. Độc giả nhạy bén có thể nhận thấy sự tương tự giữa nghiên cứu của chúng tôi trong Phần 2.3 và thích ứng miền. Sự khác biệt quan trọng ở đây là chúng tôi đang tối thiểu hóa mục tiêu học đa nhiệm vụ, trong khi trong thích ứng miền mục tiêu thường là tối thiểu hóa mục tiêu trên nhiệm vụ đích. Xem Ben-David et al. (2010); Zhang et al. (2019b) và các tham khảo trong đó cho các công trình liên quan khác.

Kỹ thuật tối ưu hóa. Guo et al. (2019) sử dụng ý tưởng từ tài liệu multi-armed bandit để phát triển một phương pháp cho việc gán trọng số mỗi nhiệm vụ. So với phương pháp của họ, phương pháp dựa trên SVD của chúng tôi đơn giản hơn về mặt khái niệm và yêu cầu ít tính toán hơn nhiều. Kendall et al. (2018) rút ra một sơ đồ mất mát có trọng số bằng cách tối đa hóa một hàm likelihood Gaussian. Nói một cách thô, mỗi nhiệm vụ được tái trọng số bởi 1/σ² nơi σ là độ lệch chuẩn của Gaussian và một hình phạt log σ được thêm vào mất mát. Các giá trị của {σi} cũng được tối ưu hóa trong quá trình huấn luyện. Chi tiết chính xác có thể tìm thấy trong bài báo. Công trình rất gần đây của Li and Vasconcelos (2019) chỉ ra kết quả thực nghiệm sử dụng một ý tưởng tương tự về chuẩn hóa hiệp phương sai trên các nhiệm vụ hình ảnh cho chuyển giao xuyên miền.

5 KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI
Chúng tôi đã nghiên cứu lý thuyết của học đa nhiệm vụ trong các thiết lập tuyến tính và được kích hoạt bằng ReLU. Chúng tôi đã xác minh lý thuyết của chúng tôi và những ý nghĩa thực tế của nó thông qua các thí nghiệm tổng hợp và thế giới thực rộng rãi.

Công trình của chúng tôi mở ra nhiều câu hỏi tương lai thú vị. Đầu tiên, liệu chúng ta có thể mở rộng các đảm bảo cho việc lựa chọn sơ đồ tối ưu hóa cho các thiết lập phi tuyến? Thứ hai, một hạn chế của bộ lập lịch tối ưu hóa dựa trên SVD của chúng tôi là nó chỉ áp dụng cho các thiết lập với cùng dữ liệu. Liệu chúng ta có thể mở rộng phương pháp cho dữ liệu nhiệm vụ không đồng nhất? Rộng hơn, chúng tôi hy vọng công trình của chúng tôi truyền cảm hứng cho các nghiên cứu thêm để hiểu rõ hơn học đa nhiệm vụ trong mạng nơ-ron và hướng dẫn thực hành của nó.

Lời cảm ơn. Cảm ơn Sharon Y. Li và Avner May cho các cuộc thảo luận kích thích trong giai đoạn đầu của công trình này. Chúng tôi biết ơn nhóm StatsML Stanford và các trọng tài ẩn danh vì đã cung cấp những bình luận hữu ích giúp cải thiện chất lượng của công trình này. Chúng tôi biết ơn sự hỗ trợ của DARPA dưới số FA87501720095 (D3M), FA86501827865 (SDH), và FA86501827882 (ASED); NIH dưới số U54EB020405 (Mobilize), NSF dưới số CCF1763315 (Beyond Sparsity), CCF1563078 (Volume to Velocity), và 1937301 (RTML); ONR dưới số N000141712266 (Unifying Weak Supervision); Quỹ Moore, NXP, Xilinx, LETI-CEA, Intel, IBM, Microsoft, NEC, Toshiba, TSMC, ARM, Hitachi, BASF, Accenture, Ericsson, Qualcomm, Analog Devices, Quỹ Okawa, American Family Insurance, Google Cloud, Swiss Re, và các thành viên của dự án Stanford DAWN: Teradata, Facebook, Google, Ant Financial, NEC, VMWare, và Infosys. H. Zhang được hỗ trợ một phần bởi giải thưởng ONR YIP của Gregory Valiant (#1704417). Các thí nghiệm được chạy một phần trên cluster SOAL của Stanford.⁵ Chính phủ Hoa Kỳ được ủy quyền sao chép và phân phối các bản in lại cho mục đích Chính phủ bất chấp

⁵https://5harad.com/soal-cluster/

--- TRANG 11 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

bất kỳ chú thích bản quyền nào trên đó. Mọi ý kiến, phát hiện, và kết luận hoặc khuyến nghị được thể hiện trong tài liệu này là của các tác giả và không nhất thiết phản ánh quan điểm, chính sách, hoặc sự tán thành, được thể hiện rõ ràng hoặc ngầm định, của DARPA, NIH, ONR, hoặc Chính phủ Hoa Kỳ.

TÀI LIỆU THAM KHẢO
Héctor Martínez Alonso và Barbara Plank. When is multitask learning effective? semantic sequence prediction under varying data conditions. arXiv preprint arXiv:1612.02251, 2016.

Rie Kubota Ando và Tong Zhang. A framework for learning predictive structures from multiple tasks and unlabeled data. Journal of Machine Learning Research, 6(Nov):1817–1853, 2005.

Andreas Argyriou, Andreas Maurer, và Massimiliano Pontil. An algorithm for transfer learning in a heterogeneous environment. Trong Joint European Conference on Machine Learning and Knowledge Discovery in Databases, trang 71–85. Springer, 2008.

Maria-Florina Balcan, Yingyu Liang, David P Woodruff, và Hongyang Zhang. Matrix completion and related problems via strong duality. Trong 9th Innovations in Theoretical Computer Science Conference (ITCS 2018), 2018.

Peter L Bartlett, Philip M Long, Gábor Lugosi, và Alexander Tsigler. Benign overfitting in linear regression. Proceedings of the National Academy of Sciences, 2020.

Jonathan Baxter. A model of inductive bias learning. Journal of artificial intelligence research, 12: 149–198, 2000.

Mikhail Belkin, Daniel Hsu, Siyuan Ma, và Soumik Mandal. Reconciling modern machine-learning practice and the classical bias–variance trade-off. Proceedings of the National Academy of Sciences, 116(32):15849–15854, 2019.

Shai Ben-David và Reba Schuller. Exploiting task relatedness for multiple task learning. Trong Learning Theory and Kernel Machines, trang 567–580. Springer, 2003.

Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, và Jennifer Wortman Vaughan. A theory of learning from different domains. Machine learning, 79(1-2):151–175, 2010.

Joachim Bingel và Anders Søgaard. Identifying beneficial task relations for multi-task learning in deep neural networks. arXiv preprint arXiv:1702.08303, 2017.

John Blitzer, Ryan McDonald, và Fernando Pereira. Domain adaptation with structural correspondence learning. Trong Proceedings of the 2006 conference on empirical methods in natural language processing, trang 120–128. Association for Computational Linguistics, 2006.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.

Simon S Du, Jason D Lee, Yuandong Tian, Barnabas Poczos, và Aarti Singh. Gradient descent learns one-hidden-layer cnn: Don't be afraid of spurious local minima. arXiv preprint arXiv:1712.00779, 2017.

Simon S Du, Wei Hu, Sham M Kakade, Jason D Lee, và Qi Lei. Few-shot learning via learning the representation, provably. arXiv preprint arXiv:2002.09434, 2020.

Ehsan Elhamifar, Guillermo Sapiro, và S Shankar Sastry. Dissimilarity-based sparse subset selection. IEEE transactions on pattern analysis and machine intelligence, 38(11):2182–2197, 2015.

Theodoros Evgeniou và Massimiliano Pontil. Regularized multi-task learning. Trong Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, trang 109–117. ACM, 2004.

Basura Fernando, Amaury Habrard, Marc Sebban, và Tinne Tuytelaars. Unsupervised visual domain adaptation using subspace alignment. Trong Proceedings of the IEEE international conference on computer vision, trang 2960–2967, 2013.

--- TRANG 12 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

Han Guo, Ramakanth Pasunuru, và Mohit Bansal. Autosem: Automatic task selection and mixing in multi-task learning. arXiv preprint arXiv:1904.04153, 2019.

Trevor Hastie, Robert Tibshirani, Jerome Friedman, và James Franklin. The elements of statistical learning: data mining, inference and prediction. The Mathematical Intelligencer, 27(2):83–85, 2005.

Minqing Hu và Bing Liu. Mining and summarizing customer reviews. Trong Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, trang 168–177. ACM, 2004.

Alex Kendall, Yarin Gal, và Roberto Cipolla. Multi-task learning using uncertainty to weigh losses for scene geometry and semantics. Trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, trang 7482–7491, 2018.

Mikhail Khodak, Maria-Florina Balcan, và Ameet Talwalkar. Provable guarantees for gradient-based meta-learning. arXiv preprint arXiv:1902.10644, 2019.

Yoon Kim. Convolutional neural networks for sentence classification. arXiv preprint arXiv:1408.5882, 2014.

Iasonas Kokkinos. Ubernet: Training a universal convolutional neural network for low-, mid-, and high-level vision using diverse datasets and limited memory. Trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, trang 6129–6138, 2017.

Weihao Kong, Raghav Somani, Zhao Song, Sham Kakade, và Sewoong Oh. Meta-learning for mixed linear regression. arXiv preprint arXiv:2002.08936, 2020.

Wouter M Kouw. An introduction to domain adaptation and transfer learning. arXiv preprint arXiv:1812.11806, 2018.

Tao Lei, Yu Zhang, Sida I Wang, Hui Dai, và Yoav Artzi. Simple recurrent units for highly parallelizable recurrence. Trong Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, trang 4470–4481, 2018.

Xin Li và Dan Roth. Learning question classifiers. Trong Proceedings of the 19th international conference on Computational linguistics-Volume 1, trang 1–7. Association for Computational Linguistics, 2002.

Yuanzhi Li, Tengyu Ma, và Hongyang Zhang. Algorithmic regularization in over-parameterized matrix sensing and neural networks with quadratic activations. Trong Conference On Learning Theory, trang 2–47, 2018.

Yunsheng Li và Nuno Vasconcelos. Efficient multi-domain learning by covariance normalization. Trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, trang 5424–5433, 2019.

Xiaodong Liu, Pengcheng He, Weizhu Chen, và Jianfeng Gao. Multi-task deep neural networks for natural language understanding. arXiv preprint arXiv:1901.11504, 2019a.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 2019b.

MM Mahmud và Sylvian Ray. Transfer learning using kolmogorov complexity: Basic theory and empirical evaluations. Trong Advances in neural information processing systems, trang 985–992, 2008.

Pasin Manurangsi và Daniel Reichman. The computational complexity of training relu (s). arXiv preprint arXiv:1810.04207, 2018.

Andreas Maurer. Bounds for linear multi-task learning. Journal of Machine Learning Research, 7 (Jan):117–139, 2006.

--- TRANG 13 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, và Richard Socher. The natural language decathlon: Multitask learning as question answering. arXiv preprint arXiv:1806.08730, 2018.

Charles A Micchelli và Massimiliano Pontil. Kernels for multi–task learning. Trong Advances in neural information processing systems, trang 921–928, 2005.

Mike Mintz, Steven Bills, Rion Snow, và Dan Jurafsky. Distant supervision for relation extraction without labeled data. Trong Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2, trang 1003–1011. Association for Computational Linguistics, 2009.

Ishan Misra, Abhinav Shrivastava, Abhinav Gupta, và Martial Hebert. Cross-stitch networks for multi-task learning. Trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, trang 3994–4003, 2016.

Guillaume Obozinski, Ben Taskar, và Michael I Jordan. Joint covariate selection and joint subspace selection for multiple classification problems. Statistics and Computing, 20(2):231–252, 2010.

Sinno Jialin Pan và Qiang Yang. A survey on transfer learning. IEEE Transactions on knowledge and data engineering, 22(10):1345–1359, 2009.

Bo Pang và Lillian Lee. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. Trong Proceedings of the 42nd annual meeting on Association for Computational Linguistics, trang 271. Association for Computational Linguistics, 2004.

Bo Pang và Lillian Lee. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. Trong Proceedings of the 43rd annual meeting on association for computational linguistics, trang 115–124. Association for Computational Linguistics, 2005.

Anastasia Pentina và Shai Ben-David. Multi-task and lifelong learning of kernels. Trong International Conference on Algorithmic Learning Theory, trang 194–208. Springer, 2015.

Anastasia Pentina và Christoph H Lampert. Multi-task learning with labeled and unlabeled tasks. Trong Proceedings of the 34th International Conference on Machine Learning-Volume 70, trang 2807–2816. JMLR. org, 2017.

Anastasia Pentina, Viktoriia Sharmanska, và Christoph H Lampert. Curriculum learning of multiple tasks. Trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, trang 5492–5500, 2015.

Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, et al. Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning. arXiv preprint arXiv:1711.05225, 2017.

Sebastian Ruder. An overview of multi-task learning in deep neural networks. arXiv preprint arXiv:1706.05098, 2017.

Changjian Shui, Mahdieh Abbasi, Louis-Émile Robitaille, Boyu Wang, và Christian Gagné. A principled approach for learning task similarity in multitask learning. arXiv preprint arXiv:1903.09109, 2019.

Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Ng, và Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. Trong Proceedings of the 2013 conference on empirical methods in natural language processing, trang 1631–1642, 2013.

Trevor Standley, Amir R Zamir, Dawn Chen, Leonidas Guibas, Jitendra Malik, và Silvio Savarese. Which tasks should be learned together in multi-task learning? arXiv preprint arXiv:1905.07553, 2019.

Joel A Tropp et al. An introduction to matrix concentration inequalities. Foundations and Trends® in Machine Learning, 8(1-2):1–230, 2015.

--- TRANG 14 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, và Samuel Bowman. Glue: A multi-task benchmark and analysis platform for natural language understanding. Trong Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, trang 353–355, 2018a.

Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, và Samuel R Bowman. Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv preprint arXiv:1804.07461, 2018b.

Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, Mohammadhadi Bagheri, và Ronald M Summers. Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. Trong Proceedings of the IEEE conference on computer vision and pattern recognition, trang 2097–2106, 2017.

Yu Wang, David Wipf, Qing Ling, Wei Chen, và Ian James Wassell. Multi-task learning for subspace segmentation. 2015.

Janyce Wiebe, Theresa Wilson, và Claire Cardie. Annotating expressions of opinions and emotions in language. Language resources and evaluation, 39(2-3):165–210, 2005.

Ya Xue, Xuejun Liao, Lawrence Carin, và Balaji Krishnapuram. Multi-task learning for classification with dirichlet process priors. Journal of Machine Learning Research, 8(Jan):35–63, 2007.

Amir R Zamir, Alexander Sax, William Shen, Leonidas J Guibas, Jitendra Malik, và Silvio Savarese. Taskonomy: Disentangling task transfer learning. Trong Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, trang 3712–3722, 2018.

Hongyang Zhang, Vatsal Sharan, Moses Charikar, và Yingyu Liang. Recovery guarantees for quadratic tensors with limited observations. Trong International Conference on Artificial Intelligence and Statistics (AISTATS), 2019a.

Yu Zhang và Qiang Yang. A survey on multi-task learning. arXiv preprint arXiv:1707.08114, 2017.

Yu Zhang và Dit-Yan Yeung. A regularization approach to learning task relationships in multitask learning. ACM Transactions on Knowledge Discovery from Data (TKDD), 8(3):12, 2014.

Yuchen Zhang, Tianle Liu, Mingsheng Long, và Michael I Jordan. Bridging theory and algorithm for domain adaptation. arXiv preprint arXiv:1904.05801, 2019b.

--- TRANG 15 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

A CHI TIẾT THIẾU CỦA PHẦN 2
Chúng tôi điền vào các chi tiết thiếu còn lại từ Phần 2. Trong Phần A.1, chúng tôi cung cấp các lập luận chặt chẽ về khả năng của mô-đun chung. Trong Phần A.2, chúng tôi điền vào các chi tiết còn lại từ Phần 2.3, bao gồm chứng minh của Định lý 2 và phần mở rộng của nó cho mô hình ReLU. Trong Phần A.3, chúng tôi cung cấp chứng minh của Mệnh đề 3 về các sơ đồ tái trọng số nhiệm vụ. Trước tiên chúng tôi mô tả các ký hiệu.

Ký hiệu. Chúng tôi định nghĩa các ký hiệu được sử dụng sau này. Chúng tôi ký hiệu f(x) ≲ g(x) nếu tồn tại một hằng số tuyệt đối C sao cho f(x) ≤ Cg(x). Ký hiệu big-O f(x) = O(g(x)) có nghĩa là f(x) ≲ g(x).

Giả sử A∈Rm×n, thì σmax(A) ký hiệu giá trị singular lớn nhất của nó và σmin(A) ký hiệu giá trị singular lớn thứ min{m;n} của nó. Cách khác, chúng ta có σmin(A) = minx:||x||=1 ||Ax||. Để κ(A) = σmax(A)/σmin(A) ký hiệu số điều kiện của A. Để Id ký hiệu ma trận đơn vị. Để U† ký hiệu nghịch đảo Moore-Penrose giả của ma trận U. Để ||·|| ký hiệu chuẩn Euclidean cho vector và chuẩn spectral cho ma trận. Để ||·||F ký hiệu chuẩn Frobenius của ma trận. Để ⟨A,B⟩ = Tr(A^T B) ký hiệu tích trong của hai ma trận.

Hàm sine được định nghĩa là sin(u,v) = √(1-cos(u,v)²), nơi chúng ta giả định rằng sin(u,v) ≥ 0 là không mất tính tổng quát cho nghiên cứu của chúng tôi.

A.1 CHI TIẾT THIẾU CỦA PHẦN 2.2
Chúng tôi mô tả chi tiết đầy đủ để chỉ ra rằng thiết lập mô hình của chúng tôi nắm bắt hiện tượng mà mô-đun chung nên nhỏ hơn tổng khả năng của các mô hình đơn nhiệm vụ. Chúng tôi phát biểu mệnh đề sau chỉ ra rằng chất lượng của không gian con B trong phương trình 1 xác định hiệu suất của học đa nhiệm vụ. Điều này bổ sung kết quả của Mệnh đề 1.

Mệnh đề 4. Trong tối ưu của f(·) (phương trình 1), mỗi Ai chọn vector v trong span cột của g(XiB) để tối thiểu hóa L(v,yi). Như một hệ quả, trong thiết lập tuyến tính, B tối ưu có thể đạt được tại một ma trận quay B*∈Rd×r bằng cách tối đa hóa

Σi=1^k ⟨B(B^T Xi^T XiB)† B^T, Xi^T yiyi^T Xi⟩: (7)

Hơn nữa, bất kỳ B* nào chứa {θi}k i=1 trong không gian con cột của nó đều tối ưu. Đặc biệt, đối với B* như vậy, tồn tại {Ai*} sao cho B*Ai* = θi cho tất cả 1 ≤ i ≤ k.

Chứng minh. Nhớ lại mục tiêu MTL trong thiết lập tuyến tính từ phương trình 3 như sau:

min f(A1;A2;:::;Ak;B) = Σi=1^k ||(XiBAi - yi)||²,

Lưu ý rằng lớp tuyến tính Ai có thể chọn bất kỳ tổ hợp nào trong không gian con của B. Do đó, chúng ta có thể giả định không mất tính tổng quát rằng B là một ma trận quay. tức là B^T B = Id. Sau khi cố định B, vì mục tiêu f(·) tuyến tính trong Ai cho tất cả i, bằng điều kiện tối ưu cục bộ, chúng ta thu được

Ai = (B^T Xi^T XiB)† B^T Xi^T yi

Thay thế nghiệm của Ai vào f(·), chúng ta thu được một mục tiêu trên B.

h(B) = Σi=1^k ||XiB(B^T Xi^T XiB)† B^T Xi^T yi - yi||²F:

Tiếp theo, lưu ý rằng

||XiB(B^T Xi^T XiB)† B^T Xi^T yi||²F = Tr(yi^T XiB(B^T Xi^T XiB)† B^T Xi^T yi)
= ⟨B(B^T Xi^T XiB)† B^T; Xi^T yiyi^T Xi⟩;

nơi chúng tôi sử dụng thực tế rằng A†AA† = A† cho A = B^T Xi^T XiB trong phương trình đầu tiên. Do đó chúng ta đã chỉ ra phương trình 7.

Đối với tuyên bố cuối cùng, miễn là B* chứa {θi}k i=1 trong không gian con cột của nó, thì tồn tại Ai* sao cho B*Ai* = θi. B* và {Ai*}k i=1 là nghiệm tối ưu vì mỗi θi là nghiệm tối ưu cho bài toán đơn nhiệm vụ.

--- TRANG 16 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

Kết quả trên về hồi quy tuyến tính gợi ý trực quan rằng việc tối ưu hóa một mô hình MTL được quy về việc tối ưu hóa trên span của B. Trực quan có thể được mở rộng dễ dàng cho các nhiệm vụ phân loại tuyến tính cũng như hỗn hợp các nhiệm vụ hồi quy và phân loại.

Mở rộng cho thiết lập ReLU. Nếu khả năng của mô-đun chung lớn hơn tổng khả năng của các mô hình STL, thì chúng ta có thể đặt tất cả các tham số mô hình STL vào mô-đun chung. Như trong thiết lập tuyến tính, lớp đầu ra cuối cùng Ai có thể chọn ra tham số tối ưu cho nhiệm vụ thứ i. Điều này vẫn là một nghiệm tối ưu cho bài toán MTL trong thiết lập ReLU. Hơn nữa, không có sự truyền tải giữa bất kỳ hai nhiệm vụ nào thông qua mô-đun chung.

A.2 CHI TIẾT THIẾU CỦA PHẦN 2.3

A.2.1 TÁC ĐỘNG CỦA ĐỘ TƯƠNG TỰ COSINE
Chúng tôi xem xét tác động của việc thay đổi độ tương tự cosine giữa các mô hình đơn nhiệm vụ trong học đa nhiệm vụ. Trước tiên chúng tôi mô tả mệnh đề sau để giải quyết mục tiêu học đa nhiệm vụ khi hiệp phương sai của dữ liệu nhiệm vụ giống nhau. Ý tưởng tương tự như công trình của Ando and Zhang (2005) và chúng tôi điều chỉnh nó ở đây cho nghiên cứu của chúng tôi.

Mệnh đề 5. Xem xét mất mát tái trọng số của phương trình 2 với hàm mã hóa là tuyến tính, nơi các trọng số là {λi}k i=1. Giả sử các đặc trưng nhiệm vụ của mọi nhiệm vụ có cùng hiệp phương sai: Xi^T Xi = Σ cho tất cả 1 ≤ i ≤ k. Để Σ = VDV^T là phân tích giá trị singular (SVD) của Σ. Khi đó tối ưu của f(·) trong phương trình 3 đạt được tại:

B* = VD^(1/2)C*;

nơi C*C*^T là không gian con xấp xỉ hạng-r tốt nhất của Σi=1^k λi Ui^T yiyi^T Ui và Xi = UiDV^T là SVD của Xi, cho mỗi 1 ≤ i ≤ k.

Như một hệ quả, ký hiệu σ1;σ2;:::;σk là các giá trị singular của D^(-1)V^T Σi=1^k λi Xi^T yiyi^T Xi theo thứ tự giảm dần. Khi đó sự khác biệt giữa một mô hình MTL với chiều ẩn r và tất cả các mô hình đơn nhiệm vụ được giới hạn bởi Σi=r+1^k σi².

Chứng minh. Lưu ý rằng B* được thu được bằng cách tối đa hóa

Σi=1^k ⟨B(B^T Xi^T XiB)^(-1) B^T; λi Xi^T yiyi^T Xi⟩

Để C = D^(-1)V^T B. Rõ ràng, có một ánh xạ một-một giữa B và C. Và chúng ta có B = VD^(-1)C. Do đó điều trên tương đương với việc tối đa hóa trên C∈Rd×r với

Σi=1^k ⟨C(C^T C)^(-1) C^T; D^(-1)V^T (Σi=1^k λi Xi^T yiyi^T Xi) VD^(-1)⟩
= ⟨C(C^T C)^(-1) C^T; Σi=1^k λi Ui^T yiyi^T Ui⟩:

Lưu ý rằng C(C^T C)^(-1) C^T là ma trận chiếu lên một không gian con chiều r. Do đó tối đa (ký hiệu bởi C*) đạt được tại không gian con xấp xỉ hạng-r tốt nhất của Σi=1^k λi Ui^T yiyi^T Ui.

Để minh họa mệnh đề trên, xem xét một thiết lập đơn giản nơi Xi là đồng nhất cho mọi 1 ≤ i ≤ k, và yi = ei, tức là vector cơ sở thứ i. Lưu ý rằng nghiệm tối ưu cho nhiệm vụ thứ i là (Xi^T Xi)^(-1) Xi^T yi = yi. Do đó các nghiệm tối ưu trực giao với nhau cho tất cả các nhiệm vụ, với λi = 1 cho tất cả 1 ≤ i ≤ k. Và lỗi STL tối thiểu là không cho tất cả các nhiệm vụ.

Xem xét mô hình MTL với chiều ẩn r. Bằng Mệnh đề 5, lỗi MTL tối thiểu đạt được bởi không gian con xấp xỉ hạng-r tốt nhất cho Σi=1^k Xi^T yiyi^T Xi = Σi=1^k yiyi^T. Ký hiệu tối ưu là Br*. Lỗi MTL là:

Σi=1^k ||yi||² - ⟨Σi=1^k yiyi^T; Br*Br*^T⟩ = k - σr:

Hiệp phương sai dữ liệu khác nhau. Chúng tôi cung cấp giới hạn trên về chất lượng của các nghiệm MTL cho hiệp phương sai dữ liệu khác nhau, phụ thuộc vào mức độ liên quan của tất cả các nhiệm vụ. Quy trình sau cho phát biểu chính xác. Xem xét k nhiệm vụ hồi quy với dữ liệu {(Xi,yi)}k i=1. Để θi = (Xi^T Xi)† Xi^T yi ký hiệu nghiệm tối ưu của mỗi nhiệm vụ hồi quy. Để W∈Rd×k ký hiệu ma trận nơi cột thứ i bằng θi. Xem xét quy trình sau để trực giao hóa W cho 1 ≤ i ≤ k.

a) Để Wi*∈Rd ký hiệu vector tối đa hóa Σj=1^k ⟨XjB/||XjB||;yj⟩² trên B∈Rd;
b) Ký hiệu σj = Σj=1^k ⟨XjWj*/||XjWj*||;yj⟩²;
c) Cho mỗi 1 ≤ i ≤ k, chiếu XiWi* ra khỏi mọi cột của Xi. Đi đến Bước a).

Mệnh đề 6. Giả sử rằng r ≤ d. Để B* ký hiệu nghiệm MTL tối ưu có khả năng r trong mô-đun chung. Ký hiệu OPT = Σi=1^k (||yi||² - ||Xi(Xi^T Xi)† Xi^T yi||²). Khi đó h(B*) ≤ OPT - Σi=r+1^d σi.

Chứng minh. Đủ để chỉ ra rằng OPT bằng Σi=1^k σi. Kết quả sau đó theo vì h(B*) nhỏ hơn lỗi cho bởi W1*;:::;Wk*, bằng OPT - Σi=r+1^d σi.

A.2.2 CHỨNG MINH CỦA ĐỊNH LÝ 2
Chúng tôi điền vào chứng minh của Định lý 2. Đầu tiên, chúng tôi phát biểu lại kết quả một cách chặt chẽ như sau.

Định lý 2. Cho i = 1;2, để (Xi,yi)∈(Rmi×d;Rmi) ký hiệu hai nhiệm vụ hồi quy tuyến tính với tham số θi∈Rd. Giả sử rằng mỗi hàng của X1 được rút độc lập từ một phân phối với hiệp phương sai Σ1∈Rd×d và chuẩn l2 có giới hạn √L. Giả định θ1^T Σ1 θ1 = 1 w.l.o.g.

Để c∈[κ(X2)sin(θ1;θ2);1/3] ký hiệu biên lỗi mong muốn. Ký hiệu (B*;A1*;A2*) là nghiệm MTL tối ưu. Với xác suất 1-δ trên tính ngẫu nhiên của (X1,y1), khi

m1 ≳ max{(Lκ(Σ1)||θ1||log d)/(δ²σmin(Σ1)); κ²(Σ1)κ²(X2)/(c²σ1²)||y2||²; κ⁴(Σ1)κ⁴(X2)/(c⁴σ1²log 1/δ)};

chúng ta có ||B*A2* - θ2||/||θ2|| ≤ 6c + (1-13c)||ε2||/||X2θ2||:

Chúng tôi đưa ra một số nhận xét để cung cấp thêm hiểu biết về Định lý 2.

Định lý 2 đảm bảo truyền tải tích cực trong MTL, khi các mô hình nguồn và đích gần nhau và số lượng mẫu nguồn lớn. Trong khi trực quan là phổ biến trong MTL, chúng tôi cung cấp một sự biện minh chính thức trong các mô hình tuyến tính và ReLU để định lượng hiện tượng.

Giới hạn lỗi giảm với c, do đó c càng nhỏ càng tốt. Mặt khác, số điểm dữ liệu yêu cầu m1 tăng. Do đó có một sự đánh đổi giữa độ chính xác và lượng dữ liệu.

c được giả định nhiều nhất là 1/3. Giả định này phát sinh khi chúng ta xử lý nhiễu nhãn của nhiệm vụ 2. Nếu không có nhiễu cho nhiệm vụ 2, thì giả định này không cần thiết. Nếu có nhiễu cho nhiệm vụ 2, giả định này được thỏa mãn khi sin(θ1;θ2) nhỏ hơn 1/(3κ(X2)). Trong các thí nghiệm tổng hợp, chúng tôi quan sát rằng sự phụ thuộc vào κ(X2) và sin(θ1;θ2) đều phát sinh trong hiệu suất của nhiệm vụ 2, xem Hình 3 và Hình 7, tương ứng.

Chứng minh của Định lý 2 gồm hai bước.

--- TRANG 17 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

a) Chúng tôi chỉ ra rằng góc giữa B* và θ1 sẽ nhỏ. Một khi điều này được thiết lập, chúng ta có một giới hạn về góc giữa B* và θ2 thông qua bất đẳng thức tam giác.

b) Chúng tôi giới hạn khoảng cách giữa B*A2 và θ2. Khoảng cách gồm hai phần. Một phần đến từ B*, tức là góc giữa B* và θ2. Phần thứ hai đến từ A2, tức là lỗi ước lượng của chuẩn của θ2, liên quan đến tỷ lệ tín hiệu-nhiễu của nhiệm vụ hai.

Trước tiên chúng tôi chỉ ra thực tế hình học sau, sẽ được sử dụng sau này trong chứng minh.

Thực tế 7. Để a;b∈Rd ký hiệu hai vector đơn vị. Giả sử rằng X∈Rm×d có hạng cột đầy đủ với số điều kiện ký hiệu bởi κ = κ(X). Khi đó chúng ta có

|sin(Xa;Xb)| ≤ κ²/2 |sin(a;b)|:

Chứng minh. Để X = UDV^T là SVD của X. Vì X có hạng cột đầy đủ theo giả định, chúng ta có X^T X = XX^T = Id. Rõ ràng, chúng ta có sin(Xa;Xb) = sin(DV^T a;DV^T b). Ký hiệu a' = V^T a và b' = V^T b. Chúng ta cũng có a' và b' đều là vector đơn vị, và sin(a';b') = sin(a;b). Để σ1;:::;σd ký hiệu các giá trị singular của X. Khi đó,

sin²(Da';Db') = 1 - (Σi=1^d σi²a'i b'i)²/(Σi=1^d σi²a'i²)(Σi=1^d σi²b'i²)
= (Σ1≤i;j≤d σi²σj²(a'i b'j - a'j b'i)²)/(Σi=1^d σi²a'i²)(Σi=1^d σi²b'i²)
≤ σmin⁴/σmax⁴ Σ1≤i;j≤d (a'i b'j - a'j b'i)²
= κ⁴/4 ((Σi=1^d a'i²)(Σi=1^d b'i²) - (Σi=1^d a'i b'i)²) = κ⁴/4 sin²(a';b'):

Điều này kết thúc chứng minh.

Trước tiên chúng tôi chỉ ra Bổ đề sau, giới hạn góc giữa B* và θ2.

Bổ đề 8. Trong thiết lập của Định lý 2, với xác suất 1-δ trên tính ngẫu nhiên của nhiệm vụ một, chúng ta có

|sin(B*;θ2)| ≤ sin(θ1;θ2) + c/κ(X2):

Chứng minh. Chúng tôi lưu ý rằng h(B*) ≥ ||y1||² bởi tính tối ưu của B*. Hơn nữa, ⟨X2B*/||X2B*||;y2⟩ ≤ ||y2||².
Do đó chúng ta thu được

⟨X1B*/||X1B*||;y1⟩² ≥ ||y1||² - ||y2||²:

Đối với vế trái,

⟨X1B*/||X1B*||;y1⟩² = ⟨X1B*/||X1B*||;X1θ1 + ε1⟩²
= ⟨X1B*/||X1B*||;X1θ1⟩² + ⟨X1B*/||X1B*||;ε1⟩² + 2⟨X1B*/||X1B*||;X1θ1⟩⟨X1B*/||X1B*||;ε1⟩

Lưu ý rằng số hạng thứ hai là một biến ngẫu nhiên chi-squared với kỳ vọng σ1². Do đó nó được giới hạn bởi σ1²√(log 1/δ) với xác suất ít nhất 1-δ. Tương tự, số hạng thứ ba được giới hạn bởi 2||X1θ1||σ1√(log 1/δ) với xác suất 1-δ. Do đó, chúng ta thu được:

||X1θ1||² cos²(X1B*;X1θ1) ≥ ||y1||² - ||y2||² - (σ1² + 2σ1||X1θ1||)√(log 1/δ)

Lưu ý rằng

||y1||² ≤ ||X1θ1||² + 2⟨X1θ1;ε1⟩ + ||ε1||²
≤ ||X1θ1||² + 2||X1θ1||σ1√(log 1/δ):

Do đó,

||X1θ1||² cos²(X1B*;X1θ1) ≥ ||X1θ1||² - ||y2||² - (σ1² + 4σ1||X1θ1||)√(log 1/δ)

⇒ sin²(X1B*;X1θ1) ≤ (||y2||² + 4σ1√(log 1/δ)/||X1θ1|| + σ1²)/||X1θ1||²

⇒ sin²(B*;θ1) ≤ κ²(X1) ((||y2||²)/||X1θ1||² + 4σ1√(log 1/δ)/||X1θ1|| + σ1²/||X1θ1||²) (bởi Bổ đề 7)

Bằng bất đẳng thức tập trung ma trận Bernstein (xem ví dụ Tropp et al. (2015)), khi m1 ≳ κ(Σ1)||θ1||log d/(δ²σmin(Σ1)), chúng ta có:

||1/m1 X1^T X1 - Σ1|| ≤ 1/2 σmin(Σ1):

Do đó chúng ta thu được κ²(X1) ≤ 3κ²(Σ1) và ||X1θ1||² ≥ m1θ1^T Σ1θ1/2 = m1/2 (nơi chúng tôi giả định θ1^T Σ1θ1 = 1). Do đó,

sin²(B*;θ1) ≤ 3κ²(Σ1) ((||y2||²)/(m²1/4) + 4σ1√(log 1/δ)/(√m1/2σ1) + σ1²/(m1/2));

bằng c²/κ²(X2) bởi thiết lập m1 của chúng tôi. Do đó kết luận theo bất đẳng thức tam giác (lưu ý rằng cả c và sin(θ1;θ2) đều nhỏ hơn 1/2).

Dựa trên Bổ đề trên, bây giờ chúng ta sẵn sàng chứng minh Định lý 2.

Chứng minh Định lý 2. Lưu ý rằng trong mô hình MTL, sau khi thu được B*, chúng ta sau đó giải lớp tuyến tính cho mỗi nhiệm vụ. Đối với nhiệm vụ 2, điều này cho giá trị trọng số A2* := ⟨X2B̂;y2⟩/||X2B̂||². Do đó các hệ số hồi quy cho nhiệm vụ 2 là B*A2*. Đối với phần còn lại của chứng minh, chúng tôi tập trung vào việc giới hạn khoảng cách giữa B*A2* và θ2. Bằng bất đẳng thức tam giác,

||B*A2* - θ2|| ≤ |⟨X2B*;ε2⟩|/||X2B*||² + |⟨X2B*;X2θ2⟩|/||X2B*||² - ||θ2||² + ||B*|| ||θ2||: (8)

Lưu ý rằng số hạng thứ hai của phương trình 8 bằng

|⟨X2B*;X2(θ2||θ2|| - B*)||/||X2B*||² ≤ κ(X2)||θ2|| ||θ2 - ||θ2||B*||:

Số hạng đầu tiên của phương trình 8 được giới hạn bởi

||ε2||/||X2B*|| ≤ ||ε2|| ||θ2||/(||X2θ2|| ||X2(θ2||θ2|| - B*)||): (9)

Cuối cùng, chúng ta có

||θ2|| - ||θ2|| ||B*|| ≤ 2||θ2||² (1 - cos(B*;θ2)) ≤ 2||θ2||² sin²(B*;θ2)

Bằng Bổ đề 8, chúng ta có

|sin(B*;θ2)| ≤ sin(θ1;θ2) + c/κ(X2)

Do đó, chúng ta kết luận rằng phương trình 9 nhiều nhất là

||ε2|| ||θ2||/(||X2θ2|| √2κmax(X2)||θ2|| sin(θ1;θ2)) ≤ ||ε2|| ||θ2||/(||X2θ2|| √2c σmin(X2)||θ2||)
≤ ||ε2|| ||θ2||/(||X2θ2|| 3c σmin(X2)||θ2||) ≤ (1-13c) ||ε2|| ||θ2||/||X2θ2||

Do đó phương trình 8 nhiều nhất là:

||θ2|| (1-13c) ||ε2||/||X2θ2|| + √2 (κ(X2) + 1) sin(B*;θ2)
≤ ||θ2|| (1-13c) ||ε2||/||X2θ2|| + 6c:

Do đó chúng ta thu được lỗi ước lượng mong muốn của BA2*.

A.2.3 MỞ RỘNG CHO MÔ HÌNH RELU
Trong phần này, chúng tôi mở rộng Định lý 2 cho mô hình ReLU. Lưu ý rằng bài toán được quy về mục tiêu sau.

max B∈Rd g(B) = ⟨ReLU(X1B)/||ReLU(X1B)||;y1⟩² + ⟨ReLU(X2B)/||ReLU(X2B)||;y2⟩² (10)

Chúng tôi đưa ra một giả định quan trọng rằng đầu vào nhiệm vụ 1 X1 tuân theo phân phối Gaussian. Lưu ý rằng việc đưa ra các giả định phân phối là cần thiết vì đối với đầu vào trường hợp xấu nhất, ngay cả việc tối ưu hóa một hàm ReLU duy nhất dưới mất mát bình phương cũng là NP-hard (Manurangsi and Reichman (2018)). Chúng tôi phát biểu kết quả của chúng tôi một cách chính thức như sau.

Định lý 9. Để (X1,y1)∈(Rm1×d,Rm1) và (X2,y2)∈(Rm2×d,Rm2) ký hiệu hai nhiệm vụ. Giả sử rằng mỗi hàng của X1 được rút từ phân phối Gaussian chuẩn. Và yi = ai ReLU(Xiθi) + εi được tạo ra thông qua mô hình ReLU với θ1;θ2∈Rd. Để E[(ai ReLU(Xiθi))²j] = 1 cho mọi 1 ≤ j ≤ m1 không mất tính tổng quát, và để σ1² ký hiệu phương sai của mọi phần tử của ε1.

Giả sử rằng c ≤ sin(θ1;θ2)/κ(X2). Ký hiệu (B*;A1*;A2*) là nghiệm MTL tối ưu của phương trình 10. Với xác suất 1-δ trên tính ngẫu nhiên của (X1,y1), khi

m1 ≳ max{d log d/(c²(1/c² + log d)); ||y2||²/c²σ1²};

chúng ta có lỗi ước lượng nhiều nhất:

sin(B*;θ1) ≤ sin(θ1;θ2) + O(c/κ(X2));
|A2* - a2|/a2 ≤ O(c) + (1/(1-O(c))) ||ε2||/(a2 ReLU(||X2θ2||))

Chứng minh. Chứng minh tuân theo cấu trúc tương tự như Định lý 2. Không mất tính tổng quát, chúng ta có thể giả định rằng θ1;θ2 đều là vector đơn vị. Trước tiên chúng tôi giới hạn góc giữa B* và θ1.

Bởi tính tối ưu của B*, chúng ta có:

⟨ReLU(X1B*)/||ReLU(X1B*)||;y1⟩² ≥ ⟨ReLU(X1θ1)/||ReLU(X1θ1)||;y1⟩² - ||y2||²

Từ đây chúng ta thu được:

a1² ⟨ReLU(X1B*)/||ReLU(X1B*)||;ReLU(X1B*)⟩²
≤ a1² ||ReLU(X1θ1)||² - ||y2||² + (σ1² + 4a1 σ1 ||ReLU(X1θ1)||)√(log 1/δ) (11)

Lưu ý rằng mỗi phần tử của ReLU(X1θ1) là một biến ngẫu nhiên Gaussian bị cắt. Bằng giới hạn Hoeffding, với xác suất 1-δ chúng ta có

||ReLU(X1θ1)||² ≥ m1/2 - √(m1/2 log 1/δ):

Đối với ⟨ReLU(X1B*);ReLU(X1θ1)⟩, chúng tôi sẽ sử dụng một lập luận epsilon-net trên B*để chỉ ra sự tập trung. Đối với một B* cố định, chúng tôi lưu ý rằng đây là một tổng các biến ngẫu nhiên độc lập đều được giới hạn trong O(log m1) với xác suất 1-δ. Ký hiệu β là góc giữa B* và θ1, một thực tế hình học chuẩn phát biểu rằng (xem ví dụ Bổ đề 1 của Du et al. (2017)) đối với một vector Gaussian ngẫu nhiên x∈Rd,

Ex ReLU(x^T B*) ReLU(x^T θ1) = (cos β)/2 + cos(β tan β)/2π =: g(β)/2:

Do đó bằng cách áp dụng bất đẳng thức Bernstein và union bound, với xác suất 1-δ chúng ta có:

|⟨ReLU(X1B*);ReLU(X1θ1)⟩ - m1g(β)/2| ≤ 2√(m1g(β)log 1/δ) + (2/3)log 1/δ log m1

Bằng các lập luận chuẩn, tồn tại một tập S của d^O(d) vector đơn vị sao cho đối với bất kỳ vector đơn vị u nào khác tồn tại û∈S sao cho ||u - û|| ≤ min{1/d³; c²/κ²(X2)}. Bằng cách đặt δ = d^(-O(d)) và union bound trên tất cả vector đơn vị trong S, chúng ta có tồn tại û∈S thỏa mãn ||B* - û|| ≤ min{1/d³; c²/κ²(X2)} và:

|⟨ReLU(X1û);ReLU(X1θ1)⟩ - m1g(β')/2| ≤ √(m1d log d) + d log² d ≤ 2m1c²/κ²(X2) (bởi thiết lập m1 của chúng tôi)

nơi β' là góc giữa û và θ1. Lưu ý rằng ⟨ReLU(X1û) - ReLU(X1B*);ReLU(X1θ1)⟩ ≤ ||X1(û - B*)|| ||ReLU(X1θ1)|| ≤ c²/κ²(X2) O(m1)

Cùng nhau chúng ta đã chỉ ra rằng

|⟨ReLU(X1B*);ReLU(X1θ1)⟩ - m1g(β')/2| ≤ c²/κ²(X2) O(m1):

Kết hợp với phương trình 11, bởi thiết lập m1 của chúng tôi, không khó để chỉ ra rằng

g(β') ≥ 1 - O(c²/κ²(X2)):

Lưu ý rằng

1 - g(β') = 1 - cos β' - cos β'(tan β' - β')/π ≥ 1 - cos β' = 2sin²β' ≥ 2c²/κ²(X2);

điều này ngụ ý rằng sin²β' ≲ c²/κ²(X2) (vì cos β' ≥ 0.9). Cuối cùng lưu ý rằng ||û - B*|| ≲ c²/κ²(X2), do đó

||û - B*||² = 2(1 - cos(û;B*)) ≤ 2sin²(û;B*):

Nhìn chung, chúng ta kết luận rằng sin(B*;θ1) ≲ O(c/κ(X2)). Do đó

sin(B*;θ2) ≤ sin(θ1;θ2) + O(c/κ(X2)):

Đối với ước lượng của a2, chúng ta có ⟨ReLU(X2B*);y2⟩/||ReLU(X2B*)||² ≤ a2 - |⟨ReLU(X2B*);ε2⟩|/||ReLU(X2B*)||²
+ a2⟨ReLU(X2B*);ReLU(X2B*) - ReLU(X2θ2)⟩/||ReLU(X2B*)||²

Phần đầu tiên nhiều nhất là

||ε2||/||ReLU(X2B*)|| ≤ ||ε2||/(||ReLU(X2θ2)|| ||ReLU(X2θ2) - ReLU(X2B*)||) ≤ (1/(1-O(c))) ||ε2||/||ReLU(X2θ2)||

Tương tự, chúng ta có thể chỉ ra rằng phần thứ hai nhiều nhất là O(c). Do đó, chứng minh hoàn tất.

--- TRANG 21 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

A.3 CHỨNG MINH CỦA MỆNH ĐỀ 3
Trong phần này, chúng tôi trình bày chứng minh của Mệnh đề 3. Thực tế, chúng tôi trình bày một kết quả tinh tế hơn, bằng cách chỉ ra rằng tất cả các cực tiểu địa phương đều là cực tiểu toàn cục cho mất mát tái trọng số trong trường hợp tuyến tính.

f(A1;A2;:::;Ak;B) = Σi=1^k λi ||(XiBAi - yi)||²F: (12)

Chìa khóa là quy về mục tiêu MTL f(·) thành xấp xỉ ma trận hạng thấp, và áp dụng kết quả gần đây của Balcan et al. (2018) chỉ ra rằng không có cực tiểu địa phương giả cho bài toán sau.

Bổ đề 10. Giả sử rằng Xi^T Xi = λi với λi > 0 cho tất cả 1 ≤ i ≤ k. Khi đó tất cả các cực tiểu địa phương của f(A1;:::;Ak;B) đều là cực tiểu toàn cục của phương trình 3.

Chứng minh. Trước tiên chúng tôi biến đổi bài toán từ không gian của B sang không gian của C. Lưu ý rằng điều này không mất tính tổng quát, vì có ánh xạ một-một giữa B và C với C = DV^T B. Trong trường hợp này, mục tiêu tương ứng trở thành:

g(A1;:::;Ak;B) = Σi=1^k λi ||UiCAi - yi||²
= Σi=1^k ||C(√λi Ai) - √λi Ui^T yi||² + Σi=1^k λi (||yi||² - ||Ui^T yi||²)

Biểu thức sau là một hằng số. Do đó nó không ảnh hưởng đến nghiệm tối ưu. Đối với biểu thức trước, ký hiệu A∈Rr×k là việc xếp chồng √λi Ai cùng nhau theo cột. Tương tự, ký hiệu Z∈Rd×k là việc xếp chồng √λi Ui^T yi cùng nhau theo cột. Khi đó việc tối thiểu hóa g(·) quy về giải xấp xỉ ma trận hạng thấp: ||CA - Z||²F.

Bằng Bổ đề 3.1 của Balcan et al. (2018), các cực tiểu địa phương duy nhất của ||CA - Z||²F là những cái mà CA bằng xấp xỉ hạng-r tốt nhất của Z. Do đó chứng minh hoàn tất.

Bây giờ chúng ta sẵn sàng chứng minh Mệnh đề 3.

Chứng minh Mệnh đề 3. Bằng Mệnh đề 5, nghiệm tối ưu của B* cho phương trình 12 là VD^(-1) nhân với xấp xỉ hạng-r tốt nhất cho λi Ui^T yiyi^T Ui, nơi chúng tôi ký hiệu SVD của X là UDV^T. Ký hiệu QrQr^T là xấp xỉ hạng-r tốt nhất cho U^T ZZ^T U, nơi chúng tôi ký hiệu Z = [√λ1 y1;√λ2 y2;:::;√λk yk] là việc xếp chồng k vector thành ma trận d×k. Do đó kết quả của Mệnh đề 5 chỉ ra rằng nghiệm tối ưu B* là VD^(-1)Qr, bằng (X^T X)^(-1)XQr. Bằng Mệnh đề 4, tính tối ưu của B* giống nhau cho đến các biến đổi trên không gian cột. Do đó chứng minh hoàn tất.

Để chỉ ra rằng tất cả các cực tiểu địa phương cũng bằng (X^T X)^(-1)XQr, chúng ta có thể đơn giản áp dụng Bổ đề 10 và Mệnh đề 3.

Nhận xét. Kết quả này chỉ áp dụng cho mô hình tuyến tính và không hoạt động trên các mô hình ReLU. Câu hỏi về việc mô tả cảnh quan tối ưu hóa trong các mô hình ReLU phi tuyến không được hiểu rõ dựa trên hiểu biết lý thuyết hiện tại về mạng nơ-ron. Chúng tôi để lại điều này cho công việc tương lai.

--- TRANG 22 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

B KẾT QUẢ THỰC NGHIỆM BỔ SUNG
Chúng tôi điền vào các chi tiết còn lại từ phần thực nghiệm của chúng tôi. Trong Phụ lục B.1, chúng tôi xem xét các tập dữ liệu được sử dụng trong các thí nghiệm của chúng tôi. Trong Phụ lục B.2, chúng tôi mô tả các mô hình chúng tôi sử dụng trên mỗi tập dữ liệu. Trong Phụ lục B.3, chúng tôi mô tả các quy trình huấn luyện cho tất cả các thí nghiệm. Trong Phụ lục B.4 và Phụ lục B.5, chúng tôi chỉ ra các thí nghiệm tổng hợp và thế giới thực mở rộng để hỗ trợ các tuyên bố của chúng tôi.

B.1 TẬP DỮ LIỆU
Chúng tôi mô tả các thiết lập tổng hợp và các tập dữ liệu Phân tích Cảm xúc, benchmark Đánh giá Hiểu biết Ngôn ngữ Tổng quát (GLUE), và ChestX-ray14 được sử dụng trong các thí nghiệm.

Thiết lập tổng hợp. Đối với các thí nghiệm tổng hợp, chúng tôi rút 10,000 mẫu dữ liệu ngẫu nhiên với chiều d = 100 từ Gaussian chuẩn N(0;1) và tính các nhãn tương ứng dựa trên mô hình được mô tả trong thí nghiệm. Chúng tôi chia các mẫu dữ liệu thành các tập huấn luyện và validation với 9,000 và 1,000 mẫu trong mỗi tập. Đối với các nhiệm vụ phân loại, chúng tôi tạo nhãn bằng cách áp dụng hàm sigmoid và sau đó ngưỡng giá trị thành nhãn nhị phân tại 0.5. Đối với các nhiệm vụ hồi quy ReLU, chúng tôi áp dụng hàm kích hoạt ReLU trên các nhãn có giá trị thực. Số lượng mẫu dữ liệu được sử dụng trong các thí nghiệm thay đổi tùy thuộc vào đặc tả. Cụ thể, đối với thí nghiệm hiệp phương sai nhiệm vụ của Hình 3, chúng tôi cố định dữ liệu nhiệm vụ 1 với m1 = 9,000 dữ liệu huấn luyện và thay đổi dữ liệu nhiệm vụ 2 dưới ba thiết lập: (i) cùng phép quay Q1 = Q2 nhưng các giá trị singular khác nhau D1 ≠ D2; (ii) cùng giá trị singular D1 = D2 nhưng các phép quay ngẫu nhiên Q1 ≠ Q2.

Phân tích cảm xúc. Đối với nhiệm vụ phân tích cảm xúc, mục tiêu là hiểu các ý kiến cảm xúc được thể hiện trong văn bản dựa trên ngữ cảnh được cung cấp. Đây là một nhiệm vụ phân loại văn bản phổ biến thường được công thức hóa như một nhiệm vụ phân loại đa nhãn trên các xếp hạng khác nhau như tích cực (+1), tiêu cực (-1), hoặc trung tính (0). Chúng tôi sử dụng sáu benchmark phân tích cảm xúc trong các thí nghiệm của chúng tôi:

Cảm xúc đánh giá phim (MR): Trong tập dữ liệu MR (Pang and Lee (2005)), mỗi đánh giá phim gồm một câu duy nhất. Mục tiêu là phát hiện các đánh giá tích cực vs. tiêu cực.

Chủ quan câu (SUBJ): Tập dữ liệu SUBJ được đề xuất trong Pang and Lee (2004) và mục tiêu là phân loại liệu một câu cho trước có chủ quan hay khách quan.

Cực tính đánh giá khách hàng (CR): Tập dữ liệu CR (Hu and Liu (2004)) cung cấp đánh giá khách hàng về các sản phẩm khác nhau. Mục tiêu là phân loại các đánh giá tích cực và tiêu cực.

Loại câu hỏi (TREC): Tập dữ liệu TREC được thu thập bởi Li and Roth (2002). Mục tiêu là phân loại một câu hỏi thành 6 loại câu hỏi.

Cực tính ý kiến (MPQA): Tập dữ liệu MPQA phát hiện liệu một ý kiến có phân cực hay không (Wiebe et al. (2005)).

Ngân hàng cảm xúc Stanford (SST): Tập dữ liệu SST, được tạo bởi Socher et al. (2013), là một phần mở rộng của tập dữ liệu MR.

Benchmark Đánh giá Hiểu biết Ngôn ngữ Tổng quát (GLUE). GLUE là một bộ sưu tập các nhiệm vụ NLP bao gồm trả lời câu hỏi, phân tích cảm xúc, tương tự văn bản và các vấn đề suy diễn văn bản. Benchmark GLUE là một benchmark MTL tiên tiến cho cả học thuật và công nghiệp. Chúng tôi chọn năm nhiệm vụ đại diện bao gồm CoLA, MRPC, QNLI, RTE, và SST-2 để xác thực phương pháp được đề xuất của chúng tôi. Chúng tôi nhấn mạnh rằng mục tiêu của công trình này không phải là đưa ra một kết quả tiên tiến mà là cung cấp hiểu biết về hoạt động của học đa nhiệm vụ. Có thể hình dung rằng kết quả của chúng tôi có thể được mở rộng cho toàn bộ tập dữ liệu. Điều này được để lại cho công việc tương lai. Thông tin chi tiết hơn về benchmark GLUE có thể tìm thấy trong bài báo gốc (Wang et al. (2018a)).

ChestX-ray14. Tập dữ liệu ChestX-ray14 (Wang et al. (2017)) là tập dữ liệu X-quang ngực lớn nhất có sẵn công khai. Nó chứa 112,120 hình ảnh X-quang mặt trước của 30,805 bệnh nhân duy nhất. Mỗi hình ảnh chứa tối đa 14 nhãn bệnh lý ngực khác nhau sử dụng các phương pháp trích xuất tự động trên báo cáo X-quang. Điều này có thể được công thức hóa như một bài toán phân loại hình ảnh đa nhãn 14 nhiệm vụ.
Tập dữ liệu ChestX-ray14 là một tập dữ liệu đại diện trong lĩnh vực hình ảnh y tế cũng như trong thị giác máy tính. Chúng tôi sử dụng tập dữ liệu này để kiểm tra sơ đồ tái trọng số nhiệm vụ được đề xuất của chúng tôi vì nó thỏa mãn giả định rằng tất cả các nhiệm vụ có cùng dữ liệu đầu vào nhưng nhãn khác nhau.

--- TRANG 23 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

B.2 MÔ HÌNH
Thiết lập tổng hợp. Đối với các thí nghiệm tổng hợp, chúng tôi sử dụng mô hình hồi quy tuyến tính, mô hình hồi quy logistic và một mạng nơ-ron một lớp với hàm kích hoạt ReLU.

Phân tích cảm xúc. Đối với các thí nghiệm phân tích cảm xúc, chúng tôi xem xét ba mô hình khác nhau bao gồm perceptron đa lớp (MLP), LSTM, CNN:

Đối với mô hình MLP, chúng tôi lấy trung bình các word embedding của một câu và đưa kết quả vào một perceptron hai lớp, theo sau bởi một lớp phân loại.

Đối với mô hình LSTM, chúng tôi sử dụng LSTM một lớp một hướng chuẩn như được đề xuất bởi Lei et al. (2018), theo sau bởi một lớp phân loại.

Đối với mô hình CNN, chúng tôi sử dụng mô hình được đề xuất bởi Kim (2014) sử dụng một lớp tích chập với nhiều bộ lọc, theo sau bởi lớp ReLU, lớp max-pooling, và lớp phân loại. Chúng tôi tuân theo giao thức của Kim (2014) và đặt kích thước bộ lọc là {3;4;5}.

Chúng tôi sử dụng các nhúng GLoVe được huấn luyện trước trên Wikipedia 2014 và kho ngữ liệu Gigaword 5⁶. Chúng tôi tinh chỉnh toàn bộ mô hình trong các thí nghiệm của chúng tôi. Trong thiết lập học đa nhiệm vụ, các mô-đun chung bao gồm lớp nhúng và lớp trích xuất đặc trưng (tức là mô hình MLP, LSTM, hoặc CNN). Mỗi nhiệm vụ có mô-đun đầu ra riêng biệt.

GLUE. Đối với các thí nghiệm trên benchmark GLUE, chúng tôi sử dụng một mô hình ngôn ngữ tiên tiến gọi là BERT (Devlin et al. (2018)). Đối với mỗi nhiệm vụ, chúng tôi thêm một lớp phân loại/hồi quy trên đầu của nó như mô hình của chúng tôi. Đối với tất cả các thí nghiệm, chúng tôi sử dụng mô hình BERT LARGE uncased, đây là một mạng 24 lớp như được mô tả trong Devlin et al. (2018). Đối với thiết lập học đa nhiệm vụ, chúng tôi tuân theo công trình của Liu et al. (2019a) và sử dụng BERT LARGE làm mô-đun chung.

ChestX-ray14. Đối với các thí nghiệm trên tập dữ liệu ChestX-ray14, chúng tôi sử dụng mô hình DenseNet được đề xuất bởi Rajpurkar et al. (2017) làm mô-đun chung, đây là một mạng 121 lớp. Đối với mỗi nhiệm vụ, chúng tôi sử dụng một lớp đầu ra phân loại riêng biệt. Chúng tôi sử dụng mô hình được huấn luyện trước⁷ trong các thí nghiệm của chúng tôi.

B.3 QUY TRÌNH HUẤN LUYỆN
Trong phần này, chúng tôi mô tả các quy trình huấn luyện cho các thí nghiệm của chúng tôi.

Mini-batch SGD. Chúng tôi mô tả các chi tiết về lấy mẫu dữ liệu nhiệm vụ trong việc triển khai SGD của chúng tôi.

Đối với các nhiệm vụ với các đặc trưng khác nhau như GLUE, trước tiên chúng tôi chia dữ liệu mỗi nhiệm vụ thành các batch nhỏ. Sau đó, chúng tôi trộn tất cả các batch từ tất cả các nhiệm vụ và xáo trộn ngẫu nhiên. Trong mỗi epoch, một bước SGD được áp dụng trên mỗi batch trên nhiệm vụ tương ứng. Nếu batch hiện tại cho nhiệm vụ i, thì SGD được áp dụng trên Ai, và có thể Ri hoặc B tùy thuộc vào thiết lập. Các tham số khác cho các nhiệm vụ khác được cố định.

Đối với các nhiệm vụ với cùng đặc trưng như ChestX-ray14, SGD được áp dụng trên tất cả các nhiệm vụ cùng nhau để cập nhật tất cả Ai và B cùng nhau.

Thiết lập tổng hợp. Đối với các thí nghiệm tổng hợp, chúng tôi thực hiện tìm kiếm lưới trên tốc độ học từ {1e-4;1e-3;1e-2;1e-1} và số epoch từ {10;20;30;40;50}. Chúng tôi chọn kết quả tốt nhất cho tất cả các thí nghiệm. Chúng tôi chọn tốc độ học là 1e-3, số epoch là 30, và kích thước batch là 50. Đối với nhiệm vụ hồi quy, chúng tôi báo cáo điểm tương quan Spearman. Đối với nhiệm vụ phân loại, chúng tôi báo cáo độ chính xác phân loại.

Phân tích cảm xúc. Đối với các thí nghiệm phân tích cảm xúc, chúng tôi chia ngẫu nhiên dữ liệu thành các tập huấn luyện, dev và test với tỷ lệ phần trăm 80%, 10%, và 10% tương ứng. Chúng tôi tuân theo giao thức của Lei et al. (2018) để thiết lập mô hình của chúng tôi cho các thí nghiệm phân tích cảm xúc.

Chiều ẩn mặc định của mô hình (ví dụ: LSTM) được đặt là 200, nhưng chúng tôi thay đổi tham số này cho các thí nghiệm khả năng mô hình. Chúng tôi báo cáo điểm độ chính xác trên tập test như metric hiệu suất.

⁶http://nlp.stanford.edu/data/wordvecs/glove.6B.zip
⁷https://github.com/pytorch/vision

--- TRANG 24 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

MTL performance over STL (Spearman correlation)−0.4−0.20
Cosine distance between tasks0 0.5 1.0
(a) Linear regression tasks
MTL performance over STL (Accuracy)−0.2−0.10
Cosine distance between tasks0 0.5 1.0 (b) Logistic classification tasks
MTL performance over STL (Spearman correlation)−0.04−0.0200.02
Cosine distance between tasks0 0.5 1.0
(c) Regression tasks with ReLU non-linearity
MTL performance over STL (Accuracy)−0.0500.05
Cosine distance between tasks0 0.5 1.0 (d) Classification tasks with ReLU non-linearity

Hình 7: So sánh hiệu suất mô hình MTL trên sự tương tự nhiệm vụ khác nhau. Đối với (a) và (c), MTL huấn luyện hai nhiệm vụ hồi quy; Đối với (b) và (d), MTL huấn luyện hai nhiệm vụ phân loại. Đối với các nhiệm vụ hồi quy, chúng tôi sử dụng tương quan spearman như chỉ số hiệu suất mô hình. Đối với các nhiệm vụ phân loại, chúng tôi sử dụng độ chính xác như metric. Chúng tôi báo cáo hiệu suất mô hình trung bình trên hai nhiệm vụ. Trục x ký hiệu khoảng cách cosine, tức là 1 - cos(θ1;θ2).

GLUE. Đối với các thí nghiệm GLUE, quy trình huấn luyện được sử dụng trên các mô-đun căn chỉnh và các mô-đun đầu ra. Do sự phức tạp của mô-đun BERT LARGE, liên quan đến 24 lớp biến đổi phi tuyến.

Chúng tôi cố định mô-đun BERT LARGE trong quá trình huấn luyện để kiểm tra hiệu ứng của việc thêm các mô-đun căn chỉnh vào quá trình huấn luyện. Nói chung, ngay cả sau khi tinh chỉnh mô-đun BERT LARGE trên một tập các nhiệm vụ, luôn có thể thêm các mô-đun căn chỉnh của chúng tôi và áp dụng Thuật toán 1.

Đối với các tham số huấn luyện, chúng tôi áp dụng tìm kiếm lưới để điều chỉnh tốc độ học từ {2e-5;3e-5;1e-5} và số epoch từ {2;3;5;10}. Chúng tôi chọn tốc độ học là 2e-5, số epoch là 5, và với kích thước batch 16 cho tất cả các thí nghiệm.

Chúng tôi sử dụng metric đánh giá GLUE (xem Wang et al. (2018b)) và báo cáo điểm trên tập phát triển như metric hiệu suất.

ChestX-ray14. Đối với các thí nghiệm ChestX-ray14, chúng tôi sử dụng cấu hình được đề xuất bởi Rajpurkar et al. (2017) và báo cáo điểm AUC trên tập test sau khi tinh chỉnh mô hình trong 20 epoch.

B.4 CÁC THÍ NGHIỆM TỔNG HỢP MỞ RỘNG
Thay đổi độ tương tự cosine trên các mô hình tuyến tính và ReLU. Chúng tôi chứng minh hiệu ứng của độ tương tự cosine trong các thiết lập tổng hợp cho cả nhiệm vụ hồi quy và phân loại.

Các nhiệm vụ tổng hợp. Chúng tôi bắt đầu với các thiết lập tuyến tính. Chúng tôi tạo 20 tập dữ liệu nhiệm vụ tổng hợp (cho các nhiệm vụ hồi quy hoặc nhiệm vụ phân loại) dựa trên quy trình tạo dữ liệu và thay đổi sự tương tự nhiệm vụ giữa nhiệm vụ 1 và nhiệm vụ i. Chúng tôi chạy thí nghiệm với các cặp tập dữ liệu khác nhau (tập dữ liệu 1 và tập dữ liệu i).

--- TRANG 25 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

Sim. 0.9
Sim. 0.7Sim. 0.5
Sim. 0.3Sim. 0.1Performance Improvements−0.200.2
# Data size2000 4000 6000 8000
(a) Regression tasks with non-linearity
Sim. 0.9
Sim. 0.7Sim. 0.5
Sim. 0.3Sim. 0.1Performance Improvements−0.2−0.100.1
# Data size2000 4000 6000 8000 (b) Classification tasks with non-linearity

Hình 8: Cải thiện hiệu suất trên nhiệm vụ đích (MTL trừ STL) bằng cách thay đổi độ tương tự cosine của các mô hình STL của hai nhiệm vụ. Chúng tôi quan sát rằng sự tương tự cao hơn giữa các mô hình STL dẫn đến cải thiện tốt hơn trên nhiệm vụ đích.

Baseline
Algorithm 1Positive Transfer
Negative TransferTarget task's Perf.: MTL - STL−0.2−0.100.10.2
# Data samples of source task2000 4000 6000 8000
(a) Linear regression tasks
Positive Transfer
Negative TransferBaseline
Algorithm 1Target task's Perf.: MTL - STL−0.2−0.100.10.2
# Data samples of source task2000 4000 6000 8000 (b) Regression tasks with ReLU activation

Hình 9: So sánh Thuật toán 1 với huấn luyện MTL cơ sở trên ví dụ tổng hợp trong Phần 2.3. Thuật toán 1 sửa hiện tượng truyền tải tiêu cực được quan sát trong Hình 3.

Sau khi tạo các nhiệm vụ, chúng tôi so sánh khoảng cách hiệu suất giữa mô hình MTL và STL.

Kết quả. Từ Hình 7a và Hình 7a, chúng tôi thấy rằng đối với cả thiết lập hồi quy và phân loại, với sự tương tự nhiệm vụ lớn hơn thì MTL vượt trội hơn so với mô hình STL và việc truyền tải tiêu cực có thể xảy ra nếu sự tương tự nhiệm vụ quá nhỏ.

Thiết lập ReLU. Chúng tôi cũng xem xét một mô hình được kích hoạt bằng ReLU. Chúng tôi sử dụng thiết lập tương tự như thiết lập tuyến tính, nhưng áp dụng kích hoạt ReLU để tạo dữ liệu. Kết quả tương tự được thể hiện trong Hình 7c, 7d.

Chế độ hạng cao hơn cho thiết lập ReLU. Chúng tôi cung cấp xác thực thêm về kết quả của chúng tôi trên các mô hình được kích hoạt bằng ReLU.

Các nhiệm vụ tổng hợp. Trong thí nghiệm tổng hợp này, có hai tập tham số mô hình θ1∈Rd×r và θ2∈Rd×r (d = 100 và r = 10). θ1 là một ma trận quay ngẫu nhiên cố định và có m1 = 100 điểm dữ liệu cho nhiệm vụ 1. Tham số mô hình nhiệm vụ 2 là θ2 = θ1 + γ(I - θ1)θ', nơi θ' cũng là một ma trận quay cố định trực giao với θ1. Lưu ý rằng γ là giá trị cosine/độ tương tự của góc chính giữa θ1 và θ2.

Sau đó chúng tôi tạo X1∈Rm1×d và X2∈Rm2×d từ Gaussian. Đối với mỗi nhiệm vụ, các nhãn là yi = ReLU(Xiθi)e + εi, nơi e∈Rr là vector tất cả một và εi là nhiễu Gaussian ngẫu nhiên.

Cho hai nhiệm vụ, chúng tôi sử dụng MTL với kích hoạt ReLU và khả năng H = 10 để đồng huấn luyện hai nhiệm vụ. Mục tiêu là xem các mức độ khác nhau của γ hoặc sự tương tự ảnh hưởng như thế nào đến việc truyền tải từ nhiệm vụ hai sang nhiệm vụ một. Lưu ý rằng thiết lập này song song với thiết lập ReLU của Định lý 9 nhưng áp dụng cho hạng r = 5.

--- TRANG 26 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

MTL-Avg.
STL-SST
STL-MR
STL-CR
STL-SUBJ
STL-MPQA
STL-TRECMTL-Avg. peak
LSTMAccuracy
0.60.70.80.9
Model capacity0 100 200 300 400 500

Hình 10: Cross validation để chọn khả năng mô hình hoạt động tốt nhất cho mỗi mô hình.

MTL-Avg.
STL-SST
STL-MRSTL-MR peak
MTL-Avg. peak
STL-SST peak
MLPAccuracy
0.760.780.80
Model capacity0 100 200 300 400 500
MTL-Avg.
STL-SST
STL-MR
STL-MR peakMTL-Avg. peak
STL-SST peak
CNNAccuracy
0.800.850.90
Model capacity0 500 1000
MTL-Avg.
STL-SST
STL-MR
STL-MR peakMTL-Avg. peak
STL-SST peak
LSTMAccuracy
0.750.800.850.90
Model capacity0 100 200 300 400 500

Hình 11: Xác thực trên các mô hình MLP, CNN và LSTM cho các nhiệm vụ phân tích cảm xúc.

Kết quả. Trong Hình 8 chúng tôi chỉ ra rằng kích thước dữ liệu, độ tương tự cosine giữa các nghiệm STL và sự căn chỉnh của hiệp phương sai tiếp tục ảnh hưởng đến tốc độ truyền tải trong các thiết lập mới. Nghiên cứu chỉ ra rằng các kết quả khái niệm của chúng tôi có thể áp dụng cho một phạm vi rộng các thiết lập.

Đánh giá Thuật toán 1 trên các mô hình tuyến tính và được kích hoạt bằng ReLU. Chúng tôi xem xét ví dụ tổng hợp trong Phần 2.3 để so sánh Thuật toán 1 và huấn luyện MTL cơ sở. Nhớ rằng trong ví dụ, khi các nhiệm vụ nguồn và đích có các ma trận hiệp phương sai khác nhau, MTL gây ra việc truyền tải tiêu cực trên nhiệm vụ đích. Giả thuyết của chúng tôi trong thí nghiệm này là chỉ ra rằng Thuật toán 1 có thể sửa sự không căn chỉnh và việc truyền tải tiêu cực.

Các nhiệm vụ tổng hợp. Chúng tôi đánh giá trên cả nhiệm vụ hồi quy tuyến tính và ReLU. Trường hợp tuyến tính tuân theo ví dụ trong Phần 2.3. Đối với trường hợp ReLU, dữ liệu được tạo theo ví dụ trước đó.

Kết quả. Hình 9 xác nhận giả thuyết. Chúng tôi quan sát rằng Thuật toán 1 sửa việc truyền tải tiêu cực trong chế độ nơi nhiệm vụ nguồn chỉ có lượng dữ liệu hạn chế. Hơn nữa, Thuật toán 1 khớp với huấn luyện MTL cơ sở khi nhiệm vụ nguồn có đủ nhiều điểm dữ liệu.

B.5 CÁC NGHIÊN CỨU ABLATION MỞ RỘNG
Cross validation để chọn khả năng mô hình. Chúng tôi cung cấp một thí nghiệm cross validation để chỉ ra cách chúng tôi chọn khả năng mô hình hoạt động tốt nhất trong Hình 1. Điều này được thực hiện trên sáu nhiệm vụ phân tích cảm xúc được huấn luyện với một lớp LSTM.

Trong Hình 10, chúng tôi thay đổi khả năng mô hình để vẽ độ chính xác validation của mô hình MTL được huấn luyện với tất cả sáu nhiệm vụ và mô hình STL cho mỗi nhiệm vụ. Kết quả bổ sung cho Bảng 1 trong Phần 3.3.

Chọn khả năng mô hình cho CNN và MLP. Tiếp theo chúng tôi xác minh kết quả của chúng tôi về khả năng mô hình cho các mô hình CNN và MLP. Chúng tôi chọn các tập dữ liệu SST và MR từ các nhiệm vụ phân tích cảm xúc cho thí nghiệm này. Chúng tôi huấn luyện tất cả ba mô hình CNN, MLP và LSTM bằng cách thay đổi khả năng.

Kết quả. Từ Hình 11 chúng tôi quan sát rằng khả năng mô hình MTL hoạt động tốt nhất nhỏ hơn tổng khả năng mô hình hoạt động tốt nhất của mô hình STL trên tất cả các mô hình.

--- TRANG 27 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020

Tác động của nhiễu nhãn đối với Thuật toán 2. Để đánh giá tính mạnh mẽ của Thuật toán 2 trong sự hiện diện của nhiễu nhãn, chúng tôi tiến hành thí nghiệm sau. Đầu tiên, chúng tôi lấy mẫu phụ 10% của tập dữ liệu ChestX-ray14 và chọn hai nhiệm vụ từ đó. Sau đó, chúng tôi chọn ngẫu nhiên một nhiệm vụ để thêm 20% nhiễu vào nhãn của nó bằng cách lật ngẫu nhiên chúng với xác suất 0.5. Chúng tôi so sánh hiệu suất của việc huấn luyện cả hai nhiệm vụ sử dụng sơ đồ tái trọng số của chúng tôi (Thuật toán 2) vs. các kỹ thuật tái trọng số của Kendall et al. (2018) và sơ đồ mất mát không trọng số.

Kết quả. Trên 10 cặp nhiệm vụ được chọn ngẫu nhiên, phương pháp của chúng tôi cải thiện so với sơ đồ huấn luyện không trọng số bằng 1.0% điểm AUC và 0.4% điểm AUC so với Kendall et al. (2018) được lấy trung bình trên 10 cặp nhiệm vụ. Hình 12 thể hiện 5 cặp nhiệm vụ ví dụ từ đánh giá của chúng tôi.

Unweighted loss Kendall et al. Algorithm 2MTL performance
0.40.50.60.70.8
Consolidation
CardiomegalyConsolidation
EdemaConsolidation
InfiltrationEdema
AtelectasisFibrosis
Consolidation

Hình 12: So sánh Thuật toán 2 với sơ đồ không trọng số và Kendall et al. (2018).

--- TRANG 28 ---

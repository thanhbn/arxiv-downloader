# FABRICATOR: Một Bộ Công Cụ Mã Nguồn Mở để Tạo Dữ Liệu Huấn Luyện Được Gắn Nhãn với Teacher LLMs
Jonas Golde1, Patrick Haller1, Felix Hamborg1, Julian Risch2, Alan Akbik1
1Đại học Humboldt Berlin
2deepset GmbH
{jonas.golde, patrick.haller.1, felix.hamborg, alan.akbik}@hu-berlin.de
julian.risch@deepset.ai

## Tóm tắt
Hầu hết các nhiệm vụ NLP được mô hình hóa như học có giám sát và do đó yêu cầu dữ liệu huấn luyện được gắn nhãn để huấn luyện các mô hình hiệu quả. Tuy nhiên, việc sản xuất thủ công dữ liệu như vậy với chất lượng và số lượng đủ được biết là tốn kém và mất thời gian. Nghiên cứu hiện tại giải quyết nút thắt này bằng cách khám phá một mô hình mới được gọi là học zero-shot thông qua tạo tập dữ liệu. Ở đây, một LLM mạnh mẽ được nhắc với mô tả nhiệm vụ để tạo ra dữ liệu được gắn nhãn có thể được sử dụng để huấn luyện một mô hình NLP downstream. Ví dụ, một LLM có thể được nhắc "tạo 500 đánh giá phim với tình cảm tích cực tổng thể, và 500 đánh giá khác với tình cảm tiêu cực." Dữ liệu được tạo sau đó có thể được sử dụng để huấn luyện một bộ phân loại tình cảm nhị phân, hiệu quả tận dụng một LLM như một giáo viên cho một mô hình học sinh nhỏ hơn. Với demo này, chúng tôi giới thiệu FABRICATOR, một bộ công cụ Python mã nguồn mở để tạo tập dữ liệu. FABRICATOR triển khai các quy trình tạo tập dữ liệu phổ biến, hỗ trợ một loạt rộng các nhiệm vụ NLP downstream (như phân loại văn bản, trả lời câu hỏi, và nhận dạng thực thể), và được tích hợp với các thư viện nổi tiếng để tạo điều kiện thử nghiệm nhanh chóng. Với FABRICATOR, chúng tôi nhắm mục tiêu hỗ trợ các nhà nghiên cứu trong việc tiến hành các thí nghiệm tạo tập dữ liệu có thể tái tạo sử dụng LLMs và giúp các nhà thực hành áp dụng phương pháp này để huấn luyện mô hình cho các nhiệm vụ downstream.

## 1 Giới thiệu
Trong những năm gần đây, xử lý ngôn ngữ tự nhiên (NLP) đã chứng kiến tiến bộ đáng kể nhờ việc giới thiệu các mô hình ngôn ngữ được huấn luyện trước (PLMs) (Devlin et al., 2019; Liu et al., 2019; Conneau và Lample, 2019; He et al., 2021). Các PLMs này thường được fine-tune trên các tập dữ liệu lớn được chú thích bởi con người, dẫn đến hiệu suất tối ưu trong các nhiệm vụ như phân loại văn bản, phân loại token, và trả lời câu hỏi. Tuy nhiên, các ứng dụng thực tế của phương pháp này đối mặt với nút thắt là số lượng đủ dữ liệu được chú thích bởi con người thường không có sẵn và quá tốn kém để sản xuất thủ công, đặc biệt khi yêu cầu chuyên môn về lĩnh vực.

Hình 1: Quá trình học thông qua tạo tập dữ liệu. Một mô hình giáo viên (LLM) được nhắc để tạo 500 đánh giá phim cho mỗi tình cảm (tích cực, tiêu cực). Một PLM học sinh nhỏ hơn được huấn luyện trên tập dữ liệu được tạo.

**Tạo tập dữ liệu với teacher LLMs.** Gần đây, một mô hình được gọi là học zero-shot thông qua tạo tập dữ liệu (Meng et al., 2022; Ye et al., 2022a,b) đã xuất hiện, có khả năng loại bỏ nhu cầu về dữ liệu được chú thích bởi con người. Phương pháp này tận dụng khả năng tạo sinh của các mô hình ngôn ngữ lớn (LLMs) để tạo ra các văn bản có điều kiện lớp được hướng dẫn bởi các lời nhắc mô tả nhãn và, tùy chọn, các ví dụ few-shot của các thể hiện của các lớp mong muốn. Tập dữ liệu được tạo sau đó được sử dụng để huấn luyện một PLM học sinh nhỏ hơn.

Tham khảo Hình 1 để minh họa quá trình này: Trong ví dụ này, một LLM được hướng dẫn viết 500 đánh giá phim tích cực và 500 đánh giá tiêu cực. Để hướng dẫn quá trình, chúng tôi bao gồm một ví dụ về đánh giá tích cực và tiêu cực trong lời nhắc. Với lời nhắc và ví dụ 1-shot này, chúng tôi tạo ra một tập dữ liệu gồm 1.000 đánh giá phim được gắn nhãn với tình cảm nhị phân. Tập dữ liệu này được sử dụng để huấn luyện một mô hình học sinh để thực hiện phân tích tình cảm nhị phân.

**Hạn chế.** Tuy nhiên, mặc dù tính đơn giản về mặt khái niệm của việc sử dụng LLMs để tạo dữ liệu huấn luyện, nhiều câu hỏi mở vẫn còn tồn tại liên quan đến các chi tiết cụ thể và tiềm năng cuối cùng của phương pháp này. Các câu hỏi bao gồm: (1) Cách tốt nhất để nhắc LLM và có nên bao gồm ví dụ trong lời nhắc hay không, (2) Đối với những họ nhiệm vụ NLP downstream nào và các nhiệm vụ cụ thể nào phương pháp này hiệu quả, và (3) Liệu tốt hơn là tạo ra số lượng lớn dữ liệu huấn luyện hay tập trung vào các nỗ lực tạo sinh chất lượng cao hơn, quy mô nhỏ hơn. Trong khi các nghiên cứu hiện tại khác nhau đang điều tra những câu hỏi này cho các nhiệm vụ cụ thể, chúng tôi thấy rằng, hiện tại, không có thư viện mã nguồn mở nào đặc biệt hỗ trợ nghiên cứu về tạo tập dữ liệu với LLMs.

**Đóng góp.** Để lấp đầy khoảng trống này, chúng tôi trình bày FABRICATOR, một thư viện Python mã nguồn mở để tạo tập dữ liệu với LLMs. Các mục tiêu chính của chúng tôi là tạo điều kiện thử nghiệm, cho phép áp dụng tạo tập dữ liệu cho các nhiệm vụ downstream cụ thể, và khuyến khích tính có thể tái tạo của các thí nghiệm. FABRICATOR mô-đun hóa quá trình tạo tập dữ liệu và cung cấp giao diện đơn giản để tạo điều kiện thử nghiệm: Người dùng có thể chọn LLM nào để sử dụng, định nghĩa lời nhắc và định nghĩa nhãn, và tận dụng các tập dữ liệu NLP hiện có cho các ví dụ few-shot và định nghĩa nhiệm vụ NLP. Thư viện của chúng tôi bao gồm một tích hợp vào thư viện DATASETS của HuggingFace (Lhoest et al., 2021), cho phép người dùng dễ dàng chia sẻ các tập dữ liệu được tạo và sử dụng chúng để huấn luyện các mô hình NLP. Chúng tôi cung cấp ví dụ cho các họ nhiệm vụ NLP khác nhau, bao gồm phân loại văn bản, suy luận văn bản, trả lời câu hỏi, và nhận dạng thực thể.

Trong bài báo này:
• Chúng tôi giới thiệu thư viện FABRICATOR, đưa ra tổng quan về các khái niệm cốt lõi và quy trình sử dụng (Phần 2).
• Chúng tôi trình bày một tập hợp các thí nghiệm ví dụ trong đó FABRICATOR được sử dụng để tạo tập dữ liệu cho các nhiệm vụ phân loại văn bản, trả lời câu hỏi, và suy luận văn bản khác nhau (Phần 3).

Chúng tôi công bố mã nguồn trên GitHub¹ dưới giấy phép Apache 2.

¹https://github.com/flairNLP/fabricator

## 2 FABRICATOR

Đầu tiên chúng tôi đưa ra tổng quan cấp cao về các quy trình tạo sinh được hỗ trợ trong FABRICATOR (Phần 2.1), thảo luận về các lớp và khái niệm chính (Phần 2.2), và hướng dẫn qua một trường hợp sử dụng ví dụ và script (Phần 2.3).

### 2.1 Quy trình Tạo sinh

Tùy thuộc vào nhiệm vụ downstream, các nhà nghiên cứu có thể có một trong ba mục tiêu tạo dữ liệu mà chúng tôi hỗ trợ trong FABRICATOR:

**1. Tạo dữ liệu không nhãn.** Mục tiêu tạo sinh đầu tiên là sản xuất dữ liệu không nhãn. Ví dụ, trong quá trình phát triển một hệ thống trả lời câu hỏi, chúng ta có thể cần một kho ngữ liệu các câu hỏi ví dụ hoặc một kho ngữ liệu văn bản về một chủ đề cụ thể. Đối với tình huống này, người dùng cung cấp một lời nhắc w (như "Tạo một văn bản trong lĩnh vực lịch sử có chứa các sự kiện mà ai đó có thể đặt câu hỏi về."), và LLM tự hồi quy Gθ tạo ra văn bản phù hợp xg.

**2. Tạo dữ liệu có điều kiện nhãn.** Mục tiêu tạo sinh thứ hai là tạo dữ liệu thuộc về một lớp được định nghĩa trước, như các nhiệm vụ phân loại. LLM tạo ra một văn bản xg tương ứng với một nhãn cụ thể y từ một tập hợp nhãn.

Như đã thảo luận trong phần giới thiệu, một ví dụ là tạo dữ liệu huấn luyện cho một bộ phân loại tình cảm nhị phân. Để đạt được điều này, người ta phải định nghĩa một tập hợp nhãn (y={tích cực, tiêu cực}) và một lời nhắc wy như "Tạo một đánh giá phim <y>:." Chuỗi được tạo xg sẽ được ghép cặp với nhãn y để tạo thành một cặp huấn luyện (xg, y) cho fine-tuning.

**3. Chú thích dữ liệu không nhãn.** Mục tiêu tạo sinh thứ ba xảy ra nếu một tập dữ liệu văn bản không nhãn cho một lĩnh vực đã có sẵn và chỉ thiếu nhãn huấn luyện. Ví dụ, một kho ngữ liệu các đánh giá phim có thể đã có sẵn, nhưng thiếu nhãn tình cảm.

Trong FABRICATOR, các nhà nghiên cứu có thể thêm nhãn vào một kho ngữ liệu hiện có bằng cách mở rộng lời nhắc w với các tùy chọn nhãn cố định y để tạo thành wy như "Chú thích đánh giá phim là: tích cực, tiêu cực." Nhãn được tạo y sau đó được ghép cặp với điểm dữ liệu không nhãn xu để tạo thành một cặp dữ liệu (xu, y).

Các mục tiêu tạo sinh được định nghĩa ở trên sẽ được thực hiện nhiều lần để tạo ra một kho ngữ liệu có kích thước được chỉ định. Lời nhắc cũng có thể được mở rộng để bao gồm các ví dụ few-shot của mỗi lớp, như được hiển thị trong Hình 1. Lời nhắc cũng có thể xử lý nhiều đầu vào (ví dụ, cho các nhiệm vụ như tương tự văn bản) sử dụng các giao diện được định nghĩa trước trong FABRICATOR. Trong tất cả các trường hợp, lời nhắc chính xác được soạn và thực hiện trong backend của chúng tôi.

### 2.2 Các Lớp và Khái niệm

Như Hình 2 minh họa, mô-đun chính trong phương pháp của chúng tôi là lớp DatasetGenerator, hoạt động như một người điều phối giữa LLM (PromptNode), lời nhắc (BasePrompt), và tùy chọn, các ví dụ few-shot và tập dữ liệu không nhãn.

Hàm generate() trong lớp DatasetGenerator chuyển đổi BasePrompt và dữ liệu few-shot và không nhãn được cung cấp thành một lời nhắc có thể xử lý cho LLM. Phương thức cung cấp các đối số khác nhau để điều khiển quá trình tạo sinh. Người dùng có thể chỉ định các tham số như số lượng tối đa các cuộc gọi API, chiến lược lấy mẫu của các ví dụ few-shot (đồng đều so với phân tầng), hoặc số lượng ví dụ few-shot để sử dụng trong một lời nhắc duy nhất. Repository của chúng tôi chứa tài liệu với chi tiết về tất cả các tùy chọn tùy chỉnh có sẵn.

#### 2.2.1 Khả năng tương tác với HuggingFace thông qua lớp Dataset

FABRICATOR hoạt động trên lớp Dataset từ thư viện DATASETS của HuggingFace. Theo mặc định, generate() sản xuất dữ liệu được tạo như một thể hiện Dataset. Điều này cho phép các tập dữ liệu được tạo được sử dụng trực tiếp trong các script huấn luyện hiện có của thư viện TRANSFORMERS (Wolf et al., 2020) và được chia sẻ giữa các nhà nghiên cứu thông qua hub tập dữ liệu Huggingface.

Một tập dữ liệu hiện có cũng có thể được sử dụng làm đầu vào cho phương thức generate(). Vì thư viện DATASETS hỗ trợ một loạt rộng các benchmark tiêu chuẩn và định dạng của chúng, các tập dữ liệu hiện có có thể được tải và sử dụng làm đầu vào một cách dễ dàng. Ví dụ, trong một số quy trình tạo sinh, chúng ta muốn thêm nhãn vào một kho ngữ liệu hiện có hoặc sử dụng các thể hiện làm ví dụ few-shot trong một lời nhắc.

#### 2.2.2 Lớp Prompt

Prompting là quan trọng khi hoạt động trên các mô hình ngôn ngữ lớn vì nó hướng dẫn quá trình tạo sinh tự hồi quy. Trong khi trong trường hợp đơn giản nhất, một lời nhắc là một chuỗi văn bản duy nhất, chúng tôi thấy rằng nhiều tình huống yêu cầu các lời nhắc phức tạp hơn và các tùy chọn tùy chỉnh. Ví dụ, khi bao gồm các ví dụ few-shot trong một lời nhắc, các câu hỏi bao gồm bao nhiêu ví dụ để bao gồm trong mỗi lời nhắc và cách những ví dụ này được lấy mẫu (đồng đều so với phân tầng) từ dữ liệu few-shot có sẵn qua các cuộc gọi lời nhắc khác nhau. Tương tự, độ phức tạp tăng lên đối với các nhiệm vụ như suy luận văn bản (yêu cầu nhiều đầu vào) và nhận dạng thực thể (có khả năng yêu cầu chuyển đổi các thẻ BIOES cấp token thành các truy vấn prompting cấp span).

Để giải quyết những thách thức này, FABRICATOR giới thiệu một lớp BasePrompt đơn giản nhưng mạnh mẽ cung cấp các giao diện rõ ràng để tùy chỉnh lời nhắc cho các nhiệm vụ tạo tập dữ liệu khác nhau. Giao diện bao gồm các thuộc tính để chỉ định các tùy chọn nhãn được định nghĩa trước cho việc tạo sinh có điều kiện nhãn, và hỗ trợ có các ví dụ few-shot hoặc tập dữ liệu không nhãn bằng cách chọn các cột liên quan cho việc tạo sinh và thông tin few-shot trong lời nhắc.

Vì lớp prompt hoạt động trực tiếp trên các cột tập dữ liệu, FABRICATOR cho phép thiết kế lời nhắc tinh vi và linh hoạt. Để minh họa, khi thực hiện một nhiệm vụ tương tự văn bản, người dùng có thể chỉ định câu đầu tiên và nhãn làm thông tin few-shot và nhắc LLM tạo ra một câu thứ hai tương ứng với câu và nhãn đã cho.

#### 2.2.3 LLMs

Giao diện LLM phải ổn định và lý tưởng nhất là tương thích với các mô hình được lưu trữ như APIs hoặc LLMs tự lưu trữ. Chúng tôi tận dụng framework HAYSTACK² (Pietsch et al., 2019), cụ thể là lớp PromptNode, cho các tương tác với LLMs. Việc triển khai PromptNode cho phép người dùng chọn và sử dụng LLMs từ các nhà cung cấp mô hình khác nhau, bao gồm HuggingFace, OpenAI, Azure, Anthropic, và Cohere.

²https://github.com/deepset-ai/Haystack

### 2.3 Script Ví dụ

Trong Danh sách 1, chúng tôi giới thiệu một script ví dụ trong đó FABRICATOR được sử dụng để tạo ra các đánh giá phim bổ sung để huấn luyện một mô hình phân loại tình cảm nhị phân (tham khảo quy trình tạo sinh 2 như được định nghĩa trong Phần 2.1). Để triển khai điều này, chúng tôi định nghĩa:

• một tập dữ liệu few-shot được tiền xử lý (dataset, dòng 6) có nhãn ở dạng ngôn ngữ tự nhiên (ví dụ, 0 trở thành "tiêu cực"). Những ví dụ này được sử dụng để tăng cường lời nhắc tạo sinh,
• một template lời nhắc (prompt, dòng 8) chỉ định hướng dẫn cho LLM,
• một LLM để sử dụng làm mô hình giáo viên (prompt_node, dòng 14),
• một DatasetGenerator để thực hiện quá trình tạo sinh với tất cả các tham số (generator, dòng 20).

Lời nhắc được cấu hình trong constructor của lớp BasePrompt (dòng 8-12): Chúng tôi đặt một task_description với một placeholder cho label_options mà chúng tôi cung cấp như một đối số riêng biệt. Chúng tôi cũng chỉ định cho cột nào trong tập dữ liệu được tải để dự đoán nhãn.

Sau đó chúng tôi định nghĩa một teacher LLM (dòng 14-18) và truyền tập dữ liệu, lời nhắc, và LLM cho lớp điều phối DatasetGenerator (dòng 20-27). Ở đây, chúng tôi chỉ định một chiến lược few-shot để lấy mẫu đồng đều một nhãn từ cột "label" trong quá trình tạo sinh. Chúng tôi làm như vậy để tạo ra một đánh giá tích cực hoặc tiêu cực. Khi hoàn thành, hàm generate trả về thể hiện Dataset được chú thích.

```python
1import os
2from datasets import load_dataset
3from haystack.nodes import PromptNode
4from fabricator import DatasetGenerator, BasePrompt
5
6dataset = load_dataset("processed_fewshot_imdb", split="train")
7
8prompt = BasePrompt(
9    task_description="Generate a {} movie review.",
10   label_options=["positive", "negative"],
11   generate_data_for_column="text",
12)
13
14prompt_node = PromptNode(
15   model_name_or_path="gpt-3.5-turbo",
16   api_key=os.environ.get("OPENAI_API_KEY"),
17   max_length=100,
18)
19
20generator = DatasetGenerator(prompt_node)
21generated_dataset = generator.generate(
22   prompt_template=prompt,
23   fewshot_dataset=dataset,
24   fewshot_sampling_strategy="uniform",
25   fewshot_examples_per_class=1,
26   fewshot_sampling_column="label",
27)
28generated_dataset.push_to_hub("generated-movie-reviews")
```

Danh sách 1: Một script sử dụng FABRICATOR và tạo ra các đánh giá phim bổ sung dựa trên các ví dụ few-shot.

## 3 Thí nghiệm

Để minh họa cách FABRICATOR có thể được sử dụng trong nghiên cứu, chúng tôi tiến hành một đánh giá khám phá về hai tình huống: (1) cách các mô hình được huấn luyện trên tập dữ liệu được tạo so sánh với các mô hình được huấn luyện trên tập dữ liệu được chú thích bởi con người, và (2) liệu các ví dụ few-shot trong lời nhắc có cải thiện tập dữ liệu được tạo hay không.

Để làm như vậy, chúng tôi huấn luyện các PLMs nhỏ hơn trên tập dữ liệu được tạo và đánh giá chúng trên phần test được gắn nhãn bởi con người của benchmark tương ứng. Đối với trả lời câu hỏi, chúng tôi fine-tune một PLM roberta-base (Liu et al., 2019). Đối với tất cả các nhiệm vụ khác, chúng tôi fine-tune một PLM bert-base-uncased (Devlin et al., 2019). Các siêu tham số được liệt kê trong Phụ lục A.2. Chúng tôi báo cáo điểm số và độ lệch chuẩn được tính trung bình trên 5 hạt giống ngẫu nhiên cho mỗi thí nghiệm.

### 3.1 Thí nghiệm 1: So sánh Tập dữ liệu Được tạo và Được chú thích bởi Con người

Chúng tôi chú thích lại các tập dữ liệu benchmark hiện có với nhãn được tạo trong thí nghiệm đầu tiên. Thí nghiệm này nhằm đo lường sự khác biệt về độ chính xác của các mô hình nhiệm vụ downstream được huấn luyện trên dữ liệu được chú thích bởi con người so với các mô hình được huấn luyện trên dữ liệu được tạo. Chúng tôi đánh giá các nhiệm vụ phân loại văn bản, tương tự văn bản, và trả lời câu hỏi trích xuất.

**Thiết lập thí nghiệm.** Chúng tôi tiến hành đánh giá này trên 5 tập dữ liệu bao gồm 3 nhiệm vụ NLP: Chúng tôi sử dụng IMDB (Maas et al., 2011), một benchmark phân loại tình cảm nhị phân, và TREC-6 (Li và Roth, 2002), một tập dữ liệu phân loại loại câu hỏi 6 lớp để đánh giá các nhiệm vụ phân loại văn bản. Chúng tôi sử dụng tập dữ liệu MRPC 2 lớp (Dolan và Brockett, 2005) và SNLI 3 lớp (Bowman et al., 2015) để đánh giá các nhiệm vụ tương tự văn bản. Cuối cùng, chúng tôi sử dụng SQuAD-v2 (Rajpurkar et al., 2016) để đánh giá trả lời câu hỏi trích xuất. Chúng tôi sử dụng lời nhắc tạo sinh được tăng cường bởi 2 ví dụ mỗi lời nhắc được lấy mẫu từ 6 ví dụ few-shot có thể có mỗi lớp.

**Kết quả (Bảng 1).** Đối với tất cả tập dữ liệu, chúng tôi so sánh một tập dữ liệu được tạo của 50, 500, 1k và tập dữ liệu đầy đủ (giới hạn ở 10k nếu lớn hơn) với dữ liệu được chú thích vàng cùng kích thước. Đối với trả lời câu hỏi, các mô hình cần được huấn luyện trên ít nhất 1k để có được kết quả đại diện, vì vậy chúng tôi không báo cáo điểm số cho 50 hoặc 500 ví dụ cho SQuAD.

Chúng tôi thấy rằng đối với các nhiệm vụ đơn giản như phân loại tình cảm nhị phân (IMDB), các mô hình được huấn luyện trên các chú thích bởi LLMs đạt được độ chính xác tương tự trên phần test được gắn nhãn vàng (↓1.0 điểm phần trăm về độ chính xác với 10k ví dụ huấn luyện). Tuy nhiên, khi độ phức tạp của tập dữ liệu tăng lên (phân loại văn bản với nhiều lớp hơn và trả lời câu hỏi trích xuất), chúng tôi quan sát thấy rằng hiệu suất của các mô hình được huấn luyện trên tập dữ liệu được chú thích bởi LLM còn thiếu sót (↓19.0 điểm phần trăm cho SNLI và ↓16.3 điểm phần trăm cho SQuAD, với 10k ví dụ huấn luyện).

Những khoảng cách hiệu suất này chỉ ra rằng tính hữu ích của LLMs như các mô hình giáo viên phụ thuộc vào nhiệm vụ cụ thể. Trong phần tiếp theo, chúng tôi trình bày một thí nghiệm khám phá cách thu hẹp khoảng cách này bằng cách sử dụng các ví dụ few-shot bổ sung.

| Dataset | Labels | # Training examples |  |  |  |
|---------|--------|-------------------|---------|---------|---------|
|         |        | 50 | 500 | 1k | all (max. 10k) |
| IMDB    | Gold | 37.6±35.8 | **88.5±0.8** | **90.0±0.4** | **93.0±0.2** |
|         | Generated | 53.8±11.5 | 88.8±0.6 | 90.2±0.4 | 92.0±0.1 |
| MRPC    | Gold | 66.6±0.8 | **73.0±1.3** | **75.2±1.1** | **83.9±0.2** |
|         | Generated | 68.4±0.8 | 72.1±1.0 | 72.4±1.2 | 75.8±0.7 |
| SNLI    | Gold | 38.5±2.5 | **64.7±0.9** | **71.3±0.7** | **82.1±0.4** |
|         | Generated | 42.2±2.4 | 54.8±1.0 | 56.1±1.1 | 63.1±0.7 |
| TREC-6  | Gold | 50.4±7.6 | **93.6±0.6** | **94.9±1.1** | **97.5±0.4** |
|         | Generated | 39.8±4.5 | 79.3±2.2 | 80.8±3.0 | 82.4±1.1 |
| SQuAD   | Gold | - | - | **39.1±4.9** | **68.8±0.5** |
|         | Generated | - | - | 46.8±1.1 | 52.5±0.3 |

Bảng 1: Kết quả về các thí nghiệm chú thích lại sử dụng 2 ví dụ few-shot mỗi lời nhắc (được lấy mẫu đồng đều từ 6 ví dụ few-shot mỗi lớp). Chúng tôi báo cáo độ chính xác ngoại trừ SQuAD, nơi chúng tôi báo cáo F1, và tô đậm những thí nghiệm mà dữ liệu được tạo cho kết quả điểm số tương tự như dữ liệu được chú thích bởi con người. Chúng tôi quan sát thấy rằng GPT-3.5 không thể chú thích ở mức hiệu suất của con người ngoại trừ các nhiệm vụ phân loại đơn giản như IMDB.

### 3.2 Thí nghiệm 2: Tác động của Ví dụ Few-Shot

Trong thí nghiệm ví dụ thứ hai, chúng tôi chú thích lại TREC-6 sử dụng số lượng ví dụ few-shot khác nhau. Thí nghiệm này nhằm xác định liệu việc thêm các ví dụ few-shot cho mỗi lớp có cải thiện việc tạo tập dữ liệu với FABRICATOR hay không. Chúng tôi điều tra hai biến: (1) Tổng số ví dụ few-shot có sẵn mỗi lớp và (2) số lượng thực tế ví dụ few-shot được bao gồm mỗi lời nhắc. Ví dụ, có thể có 8 ví dụ few-shot có sẵn tổng cộng, nhưng chỉ 3 được lấy mẫu ngẫu nhiên để được bao gồm trong mỗi cuộc gọi lời nhắc.

**Kết quả (Bảng 2).** Chúng tôi ghi nhận một xu hướng tích cực chung là việc tăng số lượng ví dụ few-shot có sẵn (cột # few-shot examples per class) và tăng số lượng ví dụ được sử dụng trong mỗi lời nhắc (cột # examples per class used in prompt) cải thiện hiệu suất mô hình. Đặc biệt, chúng tôi tìm thấy nhiều thiết lập vượt trội hơn những con số của thí nghiệm trước đó của chúng tôi (nơi chúng tôi lấy mẫu 2 ví dụ mỗi lời nhắc từ tổng số 6 ví dụ có thể), được tô đậm trong Bảng 2.

Tuy nhiên, chúng tôi cũng thấy rằng những cải thiện trở nên không đều khi # examples per class used in prompt được tăng lên trên 3, chỉ ra rằng lời nhắc không nên được quá tải với quá nhiều ví dụ.

| Dataset | # few-shot examples per class | # examples per class used in prompt |  |  |  |  |
|---------|------------------------------|-----------------------------------|---|---|---|---|
|         |                              | 0 | 1 | 2 | 3 | 4 |
| TREC-6  | 0 | 45.5±2.3 | - | - | - | - |
|         | 2 | - | 70.0±1.6 | **65.5±0.9** | - | - |
|         | 4 | - | 79.5±1.1 | 71.1±2.0 | **86.6±0.6** | 69.8±1.5 |
|         | 8 | - | 76.1±1.9 | **79.5±1.3** | **81.0±1.8** | **87.4±0.6** |
|         | 16 | - | 72.7±2.1 | **78.1±1.9** | **81.0±2.4** | 74.2±1.4 |

Bảng 2: Kết quả về 500 ví dụ TREC-6 được chú thích sử dụng số lượng ví dụ few-shot khác nhau. Chúng tôi quét qua số lượng ví dụ few-shot và số lượng ví dụ few-shot được sử dụng trong lời nhắc thực tế. Chúng tôi tô đậm những nơi việc tăng ví dụ few-shot cải thiện so với điểm số TREC-6 79.3 của Thí nghiệm 1 (Bảng 1).

## 4 Nghiên cứu Liên quan

Tiến bộ đáng kể đã được đạt được trong việc tăng cường tạo tập dữ liệu với teacher LLMs (Schick và Schütze, 2021b; Meng et al., 2022; Ye et al., 2022a; Bonifacio et al., 2022; Peng et al., 2023; Meng et al., 2023), hiệu quả lựa chọn các ví dụ few-shot (Liu et al., 2022; Gunasekar et al., 2023) và đánh giá chất lượng của các tập dữ liệu được sản xuất bởi LLMs (Gilardi et al., 2023; Chen et al., 2023).

Tuy nhiên, chúng tôi ghi nhận sự thiếu hụt các framework có thể tiếp cận giúp tạo điều kiện cho việc tạo tập dữ liệu đơn giản và có thể tái tạo sử dụng teacher LLMs. Trong khi các bộ công cụ mã nguồn mở hiện có như OpenPrompt (Ding et al., 2022) một phần mở rộng đến các tình huống tạo tập dữ liệu, phương pháp của chúng tôi khác biệt bằng cách có các giao diện nhẹ, chuyên dụng cho các nhiệm vụ tạo sinh được giới thiệu, hỗ trợ một loạt rộng LLMs sử dụng haystack, và tích hợp với HuggingFace DATASETS để đánh giá dễ dàng.

Học dựa trên lời nhắc (Liu et al., 2021; Gao et al., 2021; Schick và Schütze, 2021a; Le Scao và Rush, 2021) là một hướng nghiên cứu khác đã chứng minh hữu ích trong việc cải thiện các nhiệm vụ downstream trong các thiết lập zero- và few-shot bằng cách tận dụng các mục tiêu huấn luyện trước của LLMs (Brown et al., 2020; Ouyang et al., 2022; Zhang et al., 2022; Scao et al., 2023; Touvron et al., 2023). Tuy nhiên, tính có sẵn của dữ liệu huấn luyện trong các tình huống tài nguyên thấp vẫn quan trọng (Perez et al., 2021; Sahu et al., 2022). Do đó, phương pháp của chúng tôi cũng tìm cách lấp đầy khoảng trống này bằng cách cung cấp một bộ công cụ tạo tập dữ liệu toàn diện và dễ dàng tái tạo.

## 5 Kết luận

Chúng tôi đã giới thiệu FABRICATOR, một thư viện thân thiện với người dùng để tạo tập dữ liệu sử dụng LLMs. Với FABRICATOR, các nhà nghiên cứu truy cập một giao diện có thể tùy chỉnh cao cho phép nghiên cứu hiệu quả về học zero-shot và few-shot thông qua tạo tập dữ liệu. Hơn nữa, chúng tôi đã triển khai các baseline khác nhau sử dụng tập dữ liệu được tạo để minh họa các ứng dụng tiềm năng của repository của chúng tôi và có kế hoạch hỗ trợ thêm các nhiệm vụ downstream trong tương lai. Chúng tôi tin rằng FABRICATOR sẽ là một công cụ có giá trị cho cộng đồng NLP, tạo điều kiện cho những tiến bộ trong tạo tập dữ liệu và thúc đẩy nghiên cứu trong các lĩnh vực xử lý ngôn ngữ tự nhiên khác nhau.

## Hạn chế

Trong khi bài báo của chúng tôi nhằm giải quyết việc tạo tập dữ liệu cho một loạt rộng các nhiệm vụ downstream, điều quan trọng là phải thừa nhận những hạn chế nhất định trong nghiên cứu của chúng tôi. Thứ nhất, trong giai đoạn đánh giá repository của chúng tôi, chúng tôi chỉ có thể kiểm tra và đánh giá một tập con các nhiệm vụ do hạn chế về tài nguyên và thời gian. Đánh giá của chúng tôi có thể chỉ bao gồm một phần của các nhiệm vụ mà các nhà nghiên cứu và thực hành thường gặp trong công việc của họ. Nghiên cứu trong tương lai phải mở rộng đánh giá để bao gồm một loạt rộng hơn các nhiệm vụ để cung cấp hiểu biết toàn diện hơn về hiệu quả của repository.

Ngoài ra, mặc dù những nỗ lực tốt nhất của chúng tôi trong việc thiết kế bố cục repository để có tính linh hoạt và khả năng thích ứng, có thể có những nhiệm vụ hoặc lĩnh vực cụ thể mà cấu trúc hoặc tính năng của repository của chúng tôi có thể không được áp dụng trực tiếp. Chúng tôi thừa nhận rằng bối cảnh của các nhiệm vụ downstream đa dạng và liên tục phát triển, có thể yêu cầu các phương pháp tiếp cận được điều chỉnh hoặc mở rộng cho framework hiện có của chúng tôi.

Hơn nữa, chúng tôi nhắm mục tiêu bao gồm nghiên cứu hiện có nhắm mục tiêu tạo tập dữ liệu chất lượng cao (ví dụ, Ye et al. (2022b)) và tiến hành nghiên cứu riêng của chúng tôi về các chỉ số chất lượng và đa dạng để điều khiển quá trình tạo sinh. Chúng tôi khuyến khích các đóng góp mã nguồn mở và sự tham gia tích cực từ cộng đồng để giải quyết những hạn chế này. Bằng cách tham gia một loạt quan điểm và chuyên môn toàn diện hơn, chúng tôi nhắm mục tiêu liên tục cải thiện repository và tăng cường tính phù hợp của nó cho các yêu cầu nhiệm vụ khác nhau.

Hơn nữa, trong khi chúng tôi đã cố gắng cung cấp tài liệu và hướng dẫn kỹ lưỡng trong repository, luôn có khả năng các vấn đề bị bỏ qua hoặc những thách thức không lường trước có thể phát sinh trong quá trình tạo tập dữ liệu.

## Tuyên bố Đạo đức

Trong khi các mô hình ngôn ngữ lớn đã cho thấy những tiến bộ đáng kể trong hiểu biết và tạo sinh ngôn ngữ tự nhiên, khả năng của chúng cũng đặt ra những cân nhắc đạo đức quan trọng. Một mối quan tâm nổi bật là khả năng ảo giác, nơi các mô hình có thể tạo ra thông tin sai lệch hoặc gây hiểu lầm. Khía cạnh này có thể có những tác động nghiêm trọng, đặc biệt khi các tập dữ liệu được tạo cho các lĩnh vực quan trọng như y học, luật pháp, hoặc báo chí. Điều quan trọng là phải thận trọng và xác minh tính chính xác và độ tin cậy của các đầu ra được tạo bởi repository của chúng tôi, đặc biệt khi đưa ra các quyết định có hậu quả thực tế.

Một mối quan tâm đạo đức khác là sự hiện diện của thiên kiến trong các mô hình ngôn ngữ, có thể duy trì và khuếch đại các định kiến và bất bình đẳng xã hội. Những thiên kiến này có thể phát sinh từ dữ liệu huấn luyện có thiên kiến (Haller et al., 2023) hoặc các mẫu có thiên kiến trong văn bản được tạo bởi con người mà các mô hình học từ đó. Vì repository của chúng tôi đang ở giai đoạn đầu, chúng tôi nhấn mạnh việc kiểm tra cẩn thận các tập dữ liệu được tạo để xác định và khắc phục các thiên kiến có thể tồn tại.

Để đảm bảo một quy trình tạo tập dữ liệu có trách nhiệm, điều cần thiết là tham gia vào việc xác thực dữ liệu kỹ lưỡng, bao gồm xác định và giải quyết các thiên kiến tiềm ẩn, kiểm tra các nguồn dữ liệu về độ tin cậy và uy tín, và tham gia các quan điểm đa dạng trong các quy trình thu thập và chú thích tập dữ liệu. Hơn nữa, việc giám sát và kiểm toán liên tục các đầu ra và hiệu suất của mô hình có thể giúp xác định và khắc phục bất kỳ mối quan tâm đạo đức nào phát sinh trong quá trình triển khai.

## Lời cảm ơn

Chúng tôi cảm ơn tất cả các phản biện cho những bình luận có giá trị của họ. Jonas Golde được hỗ trợ bởi Bộ Kinh tế và Hành động Khí hậu Liên bang Đức (BMWK) như một phần của dự án ENA (KK5148001LB0). Alan Akbik và Patrick Haller được hỗ trợ bởi Deutsche Forschungsgemeinschaft (DFG, Quỹ Nghiên cứu Đức) dưới tài trợ Emmy Noether "Eidetic Representations of Natural Language" (số dự án 448414230). Alan Akbik hơn nữa được hỗ trợ dưới Chiến lược Xuất sắc của Đức "Science of Intelligence" (EXC 2002/1, số dự án 390523135). Felix Hamborg được hỗ trợ bởi chương trình WIN của Học viện Khoa học và Nhân văn Heidelberg, được tài trợ bởi Bộ Khoa học, Nghiên cứu và Nghệ thuật của Bang Baden-Wurttemberg, Đức.

## Tài liệu tham khảo

Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, và Rodrigo Nogueira. 2022. Inpars: Unsupervised dataset generation for information retrieval. Trong Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '22, trang 2387–2392, New York, NY, USA. Association for Computing Machinery.

Samuel R. Bowman, Gabor Angeli, Christopher Potts, và Christopher D. Manning. 2015. A large annotated corpus for learning natural language inference. Trong Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, trang 632–642, Lisbon, Portugal. Association for Computational Linguistics.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. 2020. Language models are few-shot learners. Trong Advances in Neural Information Processing Systems, tập 33, trang 1877–1901. Curran Associates, Inc.

Jiaao Chen, Derek Tam, Colin Raffel, Mohit Bansal, và Diyi Yang. 2023. An empirical survey of data augmentation for limited data learning in NLP. Transactions of the Association for Computational Linguistics, 11:191–211.

Alexis Conneau và Guillaume Lample. 2019. Cross-lingual language model pretraining. Trong Advances in Neural Information Processing Systems, tập 32. Curran Associates, Inc.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. Trong Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), trang 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.

Ning Ding, Shengding Hu, Weilin Zhao, Yulin Chen, Zhiyuan Liu, Haitao Zheng, và Maosong Sun. 2022. OpenPrompt: An open-source framework for prompt-learning. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, trang 105–113, Dublin, Ireland. Association for Computational Linguistics.

William B. Dolan và Chris Brockett. 2005. Automatically constructing a corpus of sentential paraphrases. Trong Proceedings of the Third International Workshop on Paraphrasing (IWP2005).

Tianyu Gao, Adam Fisch, và Danqi Chen. 2021. Making pre-trained language models better few-shot learners. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), trang 3816–3830, Online. Association for Computational Linguistics.

Fabrizio Gilardi, Meysam Alizadeh, và Maël Kubli. 2023. ChatGPT outperforms crowd workers for text-annotation tasks. Proceedings of the National Academy of Sciences, 120(30).

Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Harkirat Singh Behl, Xin Wang, Sébastien Bubeck, Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee, và Yuanzhi Li. 2023. Textbooks are all you need.

Patrick Haller, Ansar Aynetdinov, và Alan Akbik. 2023. Opiniongpt: Modelling explicit biases in instruction-tuned llms.

Pengcheng He, Xiaodong Liu, Jianfeng Gao, và Weizhu Chen. 2021. Deberta: Decoding-enhanced bert with disentangled attention. Trong International Conference on Learning Representations.

Teven Le Scao và Alexander Rush. 2021. How many data points is a prompt worth? Trong Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 2627–2636, Online. Association for Computational Linguistics.

Quentin Lhoest, Albert Villanova del Moral, Yacine Jernite, Abhishek Thakur, Patrick von Platen, Suraj Patil, Julien Chaumond, Mariama Drame, Julien Plu, Lewis Tunstall, Joe Davison, Mario Šaško, Gunjan Chhablani, Bhavitvya Malik, Simon Brandeis, Teven Le Scao, Victor Sanh, Canwen Xu, Nicolas Patry, Angelina McMillan-Major, Philipp Schmid, Sylvain Gugger, Clément Delangue, Théo Matussière, Lysandre Debut, Stas Bekman, Pierric Cistac, Thibault Goehringer, Victor Mustar, François Lagunas, Alexander Rush, và Thomas Wolf. 2021. Datasets: A community library for natural language processing. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, trang 175–184, Online và Punta Cana, Dominican Republic. Association for Computational Linguistics.

Xin Li và Dan Roth. 2002. Learning question classifiers. Trong COLING 2002: The 19th International Conference on Computational Linguistics.

Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, và Weizhu Chen. 2022. What makes good in-context examples for GPT-3? Trong Proceedings of Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures, trang 100–114, Dublin, Ireland và Online. Association for Computational Linguistics.

Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, và Jie Tang. 2021. Gpt understands, too.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach.

Ilya Loshchilov và Frank Hutter. 2019. Decoupled weight decay regularization. Trong International Conference on Learning Representations.

Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, và Christopher Potts. 2011. Learning word vectors for sentiment analysis. Trong Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, trang 142–150, Portland, Oregon, USA. Association for Computational Linguistics.

Yu Meng, Jiaxin Huang, Yu Zhang, và Jiawei Han. 2022. Generating training data with language models: Towards zero-shot language understanding. Trong Advances in Neural Information Processing Systems, tập 35, trang 462–477. Curran Associates, Inc.

Yu Meng, Martin Michalski, Jiaxin Huang, Yu Zhang, Tarek Abdelzaher, và Jiawei Han. 2023. Tuning language models as training data generators for augmentation-enhanced few-shot learning. Trong Proceedings of the 40th International Conference on Machine Learning, tập 202 của Proceedings of Machine Learning Research, trang 24457–24477. PMLR.

Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F Christiano, Jan Leike, và Ryan Lowe. 2022. Training language models to follow instructions with human feedback. Trong Advances in Neural Information Processing Systems, tập 35, trang 27730–27744. Curran Associates, Inc.

Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, và Jianfeng Gao. 2023. Instruction tuning with gpt-4.

Ethan Perez, Douwe Kiela, và Kyunghyun Cho. 2021. True few-shot learning with language models. Trong Advances in Neural Information Processing Systems, tập 34, trang 11054–11070. Curran Associates, Inc.

Malte Pietsch, Timo Möller, Bogdan Kostic, Julian Risch, Massimiliano Pippi, Mayank Jobanputra, Sara Zanzottera, Silvano Cerza, Vladimir Blagojevic, Thomas Stadelmann, Tanay Soni, và Sebastian Lee. 2019. Haystack: the end-to-end NLP framework for pragmatic builders.

Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, và Percy Liang. 2016. SQuAD: 100,000+ questions for machine comprehension of text. Trong Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, trang 2383–2392, Austin, Texas. Association for Computational Linguistics.

Gaurav Sahu, Pau Rodriguez, Issam Laradji, Parmida Atighehchian, David Vazquez, và Dzmitry Bahdanau. 2022. Data augmentation for intent classification with off-the-shelf large language models. Trong Proceedings of the 4th Workshop on NLP for Conversational AI, trang 47–57, Dublin, Ireland. Association for Computational Linguistics.

Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, và Matthias Gallé et al. 2023. Bloom: A 176b-parameter open-access multilingual language model.

Timo Schick và Hinrich Schütze. 2021a. Exploiting cloze-questions for few-shot text classification and natural language inference. Trong Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, trang 255–269, Online. Association for Computational Linguistics.

Timo Schick và Hinrich Schütze. 2021b. Generating datasets with pretrained language models. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 6943–6951, Online và Punta Cana, Dominican Republic. Association for Computational Linguistics.

Erik F. Tjong Kim Sang và Fien De Meulder. 2003. Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition. Trong Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, trang 142–147.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, và Guillaume Lample. 2023. Llama: Open and efficient foundation language models.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, và Alexander Rush. 2020. Transformers: State-of-the-art natural language processing. Trong Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, trang 38–45, Online. Association for Computational Linguistics.

Jiacheng Ye, Jiahui Gao, Qintong Li, Hang Xu, Jiangtao Feng, Zhiyong Wu, Tao Yu, và Lingpeng Kong. 2022a. ZeroGen: Efficient zero-shot learning via dataset generation. Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, trang 11653–11669, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Jiacheng Ye, Jiahui Gao, Zhiyong Wu, Jiangtao Feng, Tao Yu, và Lingpeng Kong. 2022b. ProGen: Progressive zero-shot dataset generation via in-context feedback. Trong Findings of the Association for Computational Linguistics: EMNLP 2022, trang 3671–3683, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang, và Luke Zettlemoyer. 2022. Opt: Open pre-trained transformer language models.

## A Phụ lục

### A.1 Screencast

Một screencast về framework FABRICATOR có thể được tìm thấy trên Vimeo.

### A.2 Siêu tham số cho Thí nghiệm

Chúng tôi sử dụng AdamW (Loshchilov và Hutter, 2019) làm optimizer với kích thước batch là 16. Hơn nữa, chúng tôi sử dụng warm-up tuyến tính cho 10% số bước tối ưu hóa. Chúng tôi fine-tune roberta-base cho trả lời câu hỏi với tỷ lệ học 1e−5 trong hai epoch mà không dừng sớm. Đối với PLM bert-base-uncased, chúng tôi fine-tune sử dụng tỷ lệ học 2e−5 trong 5 (nếu dữ liệu huấn luyện có nhiều hơn 1000 ví dụ), 10 (nếu tập dữ liệu huấn luyện có ít nhất 500 nhưng ít hơn 1001 ví dụ) hoặc 20 epoch (nếu dữ liệu huấn luyện ít hơn 501 ví dụ). Hơn nữa, qua tất cả các thí nghiệm, chúng tôi sử dụng 10% dữ liệu như một phần validation để lựa chọn mô hình.

### A.3 Tạo Dữ liệu Huấn luyện Có điều kiện Nhãn

Thí nghiệm này sử dụng tạo sinh có điều kiện nhãn để tạo dữ liệu mới cho tập dữ liệu TREC chứa sáu lớp. Để đạt được điều này, chúng tôi lấy mẫu một tập dữ liệu few-shot nhỏ từ phần huấn luyện hiện có, bao gồm 8 ví dụ mỗi lớp. Trong quá trình tạo sinh, đối với mỗi nhãn y, chúng tôi bao gồm ba ví dụ few-shot được lấy mẫu đồng đều liên quan đến nhãn đó. Chúng tôi tạo ra 10k cặp dữ liệu (xg,y) và sử dụng chúng để fine-tuning. Điều quan trọng cần lưu ý là tập dữ liệu được gắn nhãn vàng chỉ chứa khoảng 3k ví dụ. Do đó cột "all" tham chiếu đến 10k ví dụ được tạo với GPT hoặc đến ~3k ví dụ được gắn nhãn vàng. Thiết lập thí nghiệm giống hệt như Phần 3.

Kết quả được mô tả trong Bảng 3. Chúng tôi quan sát thấy sự giảm hiệu suất đáng kể so với các thí nghiệm chú thích lại cho TREC từ Phần 3.1. Ví dụ, sử dụng 10k ví dụ được tạo đạt được mức hiệu suất tương tự như sử dụng 50 ví dụ được chú thích bởi con người (so sánh với Bảng 1). Tuy nhiên, chúng tôi lưu ý rằng chúng tôi không thực hiện kỹ thuật tối ưu hóa lời nhắc hoặc tìm kiếm siêu tham số trong tất cả các thí nghiệm. Ngoài ra, chúng tôi tạo ra một phân phối đồng đều của các lớp, trong khi tập dữ liệu được gắn nhãn vàng bị lệch về một số danh mục nhất định. Đáng nói là thông tin phân phối lớp này có thể không có sẵn trong các thiết lập few-shot thực tế.

| Dataset | Data | # Training examples |  |  |  |
|---------|------|-------------------|---------|--------|----------|
|         |      | 50 | 500 | 1000 | all |
| TREC-6  | Gold | 42.7±9.6 | **93.8±0.3** | **95.1±0.6** | **97.1±0.3** |
|         | Generated | 27.5±11.0 | 56.2±3.3 | 57.9±1.6 | 62.6±3.4 |

Bảng 3: Kết quả về TREC-6 với các câu hỏi được tạo bởi GPT-3.5 sử dụng 3 ví dụ few-shot (được lấy mẫu đồng đều từ 8 ví dụ few-shot có thể có mỗi lớp). Chúng tôi quan sát thấy rằng hiệu suất tạo sinh tệ hơn so với tập dữ liệu được chú thích bởi con người có kích thước bằng nhau. Tuy nhiên, hiệu suất tăng lên với số lượng ví dụ được tạo.

### A.4 Tác động của Ví dụ Few-Shot đối với Tạo sinh Có điều kiện Nhãn

Trong thí nghiệm này, chúng tôi tạo ra 500 cặp dữ liệu có điều kiện nhãn cho tập dữ liệu TREC, theo phương pháp được mô tả trong Phần 3.2. Chúng tôi tiến hành phân tích quét qua hai yếu tố: tổng số ví dụ few-shot mỗi lớp và số lượng ví dụ few-shot được bao gồm trong lời nhắc thực tế.

Kết quả được mô tả trong Bảng 4. Phát hiện của chúng tôi cho thấy rằng bao gồm ngay cả một số lượng nhỏ ví dụ few-shot (< 4) mang lại kết quả tốt hơn so với tạo sinh mà không có bất kỳ ví dụ few-shot nào. Hơn nữa, khi chúng tôi sử dụng ít nhất bốn ví dụ mỗi lớp, chúng tôi quan sát thấy những cải thiện đáng kể trong kết quả tạo sinh, từ 30.2 đến 54.8 về độ chính xác (↑24.6 điểm phần trăm về độ chính xác). Ngoài ra, sử dụng nhiều ví dụ hơn trong một lời nhắc riêng biệt cải thiện một chút hiệu suất mô hình. Chúng tôi gặp một ngoại lệ khi sử dụng 16 ví dụ mỗi lớp và bao gồm năm ví dụ trong lời nhắc để tạo sinh, dẫn đến hiệu suất thấp hơn so với lấy mẫu từ 8 ví dụ few-shot mỗi lời nhắc. Điều quan trọng cần lưu ý là trong thí nghiệm này, chúng tôi không điều chỉnh bất kỳ siêu tham số nào của LLM để tạo sinh, như nhiệt độ hoặc lấy mẫu top-k.

| Dataset | # few-shot examples per class | # examples per class used in prompt |  |  |  |  |
|---------|------------------------------|-----------------------------------|---|---|---|---|
|         |                              | 0 | 2 | 3 | 4 | 5 |
| TREC-6  | 0 | 30.2±0.6 | - | - | - | - |
|         | 2 | - | 43.0±3.7 | - | - | - |
|         | 4 | - | 56.0±0.5 | 56.3±2.4 | 58.3±2.2 | - |
|         | 8 | - | 52.8±1.5 | 58.8±1.0 | 58.2±1.0 | 64.0±2.0 |
|         | 16 | - | 58.3±0.8 | 59.8±2.5 | 58.7±1.1 | 54.8±1.5 |

Bảng 4: Kết quả về 500 ví dụ TREC-6 được tạo với kích thước khác nhau của ví dụ few-shot và số lượng ví dụ few-shot được bao gồm trong lời nhắc. Chúng tôi quan sát thấy rằng nhiều ví dụ few-shot hơn dẫn đến hiệu suất tốt hơn trên phần test được chú thích vàng.

### A.5 Instruction-tuning các mô hình mã nguồn mở

Trong thí nghiệm này, chúng tôi so sánh hiệu suất chú thích của GPT-3.5 của OpenAI với một mô hình LLaMA được instruction-tuned mã nguồn mở. Để tiến hành đánh giá này, chúng tôi chọn nhiệm vụ phân loại token trên tập dữ liệu CoNLL-03 (Tjong Kim Sang và De Meulder, 2003), tạo ra một nhãn cho mỗi token trong đầu vào, làm cho nó trở thành một nhiệm vụ có cấu trúc.

Kết quả được hiển thị trong Bảng 5. Chúng tôi quan sát thấy rằng sử dụng tập dữ liệu như hiện tại thường dẫn đến các đầu ra chú thích không thể sử dụng được, chủ yếu do định dạng không chính xác. Để giải quyết điều này, chúng tôi chuyển đổi các nhãn cấp token thành span và nhắc LLM trích xuất tất cả các thực thể được đặt tên cho các danh mục liên quan. Sau đó chúng tôi chuyển đổi các thực thể được tìm thấy thành các thẻ cấp token bằng cách tìm kiếm các chú thích như chuỗi con của văn bản đầu vào. Chúng tôi so sánh hiệu suất của phương pháp này với một mô hình LLaMA được instruction-tuned trên toàn bộ phần huấn luyện của CoNLL-03 bằng cách để cả hai LLMs chú thích tập validation.

Không giống như đánh giá trước đó, chúng tôi không huấn luyện và đánh giá một PLM nhỏ hơn trên tập test được gắn nhãn vàng. Thay vào đó, chúng tôi đánh giá hiệu suất giữa phần validation được chú thích vàng và các chú thích được thực hiện bởi LLM. Phát hiện của chúng tôi chỉ ra rằng chất lượng chú thích của LLMs được instruction-tuned có thể cải thiện đáng kể so với GPT của OpenAI, như được thể hiện qua điểm số F1 cao hơn. Phát hiện này gợi ý rằng các mô hình được instruction-tuned để tạo tập dữ liệu có tiềm năng tạo điều kiện cho quá trình tạo sinh cho các nhiệm vụ downstream phức tạp trong các nỗ lực nghiên cứu tương lai.

| Model | Acc. (micro) | F1 |
|-------|-------------|-----|
| LLaMAv2 + Instr. Tuning | 92.4 | 60.0 |
| GPT-3.5* | 88.4 | 52.5 |

Bảng 5: So sánh các mô hình LLaMA được instruction-tuned với GPT-3.5 dựa trên 3-shot dựa trên phần huấn luyện của CoNLL-03. Chúng tôi báo cáo độ chính xác và điểm số F1 cấp span cho chú thích trên phần validation. *: Chúng tôi chuyển đổi chuỗi thẻ thành span để nhắc LLM với chuỗi thay vì chuỗi. Tuy nhiên, 38% các chú thích phần validation có độ dài khác nhau sau tokenization đã được lọc ra để so sánh công bằng.

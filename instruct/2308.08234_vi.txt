# 2308.08234.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/instruct/2308.08234.pdf
# Kích thước file: 1574851 bytes

===============================================
NỘI DUNG FILE PDF
===============================================


--- TRANG 1 ---
Bản thảo.
THÁCH THỨC VÀ CƠ HỘI SỬ DỤNG
HỌC ĐA NHIỆM VỤ DỰA TRÊN TRANSFORMER TRONG NLP
THÔNG QUA CHU TRÌNH ML: MỘT KHẢO SÁT
Lovre Torbarina∗,†, ωTin Ferkovic∗, ω
Lukasz RoguskiωVelimir MihelcicωBruno SarlijaωZeljko Kraljevicω
ωdoXray B.V ., Neede, Hà Lan
name.lastname@doxray.com
TÓM TẮT
Việc gia tăng ứng dụng các mô hình xử lý ngôn ngữ tự nhiên (NLP) trong các ngành công nghiệp đã dẫn đến nhu cầu của các nhà thực hành về hệ thống học máy để xử lý các mô hình này một cách hiệu quả, từ việc huấn luyện đến triển khai chúng trong sản xuất. Tuy nhiên, việc huấn luyện, triển khai và cập nhật nhiều mô hình có thể phức tạp, tốn kém và mất thời gian, chủ yếu khi sử dụng các mô hình ngôn ngữ được huấn luyện trước dựa trên transformer. Học Đa Nhiệm vụ (MTL) đã nổi lên như một phương pháp đầy hứa hẹn để cải thiện hiệu quả và hiệu suất thông qua huấn luyện kết hợp, thay vì huấn luyện các mô hình riêng biệt. Được thúc đẩy bởi điều này, trước tiên chúng tôi cung cấp một tổng quan về các phương pháp MTL dựa trên transformer trong NLP. Sau đó, chúng tôi thảo luận về các thách thức và cơ hội sử dụng các phương pháp MTL xuyên suốt các giai đoạn chu trình ML điển hình, đặc biệt tập trung vào các thách thức liên quan đến các giai đoạn kỹ thuật dữ liệu, phát triển mô hình, triển khai và giám sát. Khảo sát này tập trung vào các kiến trúc MTL dựa trên transformer và, theo hiểu biết của chúng tôi, là mới lạ ở chỗ nó phân tích một cách có hệ thống cách MTL dựa trên transformer trong NLP phù hợp với các giai đoạn chu trình ML. Hơn nữa, chúng tôi thúc đẩy nghiên cứu về mối liên hệ giữa MTL và học liên tục (CL), vì khu vực này vẫn chưa được khám phá. Chúng tôi tin rằng sẽ thực tế khi có một mô hình có thể xử lý cả MTL và CL, vì điều này sẽ giúp dễ dàng hơn trong việc huấn luyện lại mô hình định kỳ, cập nhật nó do sự thay đổi phân phối và thêm khả năng mới để đáp ứng các yêu cầu thực tế.

1 GIỚI THIỆU
Trong những năm gần đây, những tiến bộ trong xử lý ngôn ngữ tự nhiên (NLP) đã cách mạng hóa cách chúng ta giải quyết các vấn đề ngôn ngữ phức tạp. Do đó, những tiến bộ đó đã tác động đáng kể đến ngành công nghiệp toàn cầu, thúc đẩy tăng trưởng trong các tổ chức kết hợp công nghệ AI như một phần cốt lõi trong kinh doanh của họ. Để minh họa, báo cáo tình trạng AI của McKinsey năm 2022 đã báo cáo mức tăng 3,8 lần kể từ năm 2017 trong các khả năng AI mà các tổ chức đã nhúng trong ít nhất một chức năng hoặc đơn vị kinh doanh, nơi hiểu ngôn ngữ tự nhiên (NLU) đứng vị trí thứ ba trong số các khả năng được báo cáo, chỉ sau thị giác máy tính (Chui et al., 2022). Hơn nữa, Fortune Business Insights dự báo tăng trưởng NLP toàn cầu từ 20,80 tỷ USD năm 2021 lên 161,81 tỷ USD vào năm 2029.¹ Kết quả là, mỗi nhà thực hành NLP cung cấp mô hình thông qua API hoặc sử dụng chúng nội bộ, một mình hoặc cùng với các khả năng AI khác, phải có hệ thống học máy (ML) để quản lý hiệu quả các mô hình này. Điều này bao gồm việc có các quy trình được thiết lập tốt từ huấn luyện và xác minh các mô hình đó đến triển khai chúng trong sản xuất cho người dùng cuối trong khi liên tục giám sát rằng các mô hình đó vẫn cập nhật với kiến thức mới nhất mà chúng đang được huấn luyện.

Xu hướng ứng dụng rộng rãi các mô hình ML bởi nhiều nhà thực hành khác nhau trong các ngành công nghiệp, và nhu cầu kết quả về hệ thống ML để quản lý chúng hiệu quả, đã được giải quyết trong một khảo sát về hệ thống ML được thực hiện bởi Paleyes et al. (2022). Khảo sát đã phân tích các bài báo và bài viết blog được báo cáo bởi các nhà thực hành khác nhau, cung cấp hiểu biết về các giai đoạn của chu trình ML và các thách thức thường phát sinh trong các giai đoạn đó. Chu trình ML đề cập đến các giai đoạn và quy trình liên quan đến việc thiết kế, phát triển và triển khai hệ thống ML. Nó bao gồm toàn bộ quy trình,

∗Đóng góp bằng nhau.
†Liên hệ: Lovre Torbarina <lovre.torbarina@doxray.com>
¹Fortune Business Insights - Quy mô Thị trường NLP
1arXiv:2308.08234v1  [cs.CL]  16 Aug 2023

--- TRANG 2 ---
Bản thảo.
từ việc xác định vấn đề và thu thập dữ liệu đến triển khai mô hình và giám sát hiệu suất của chúng. Học mô hình và triển khai mô hình là hai giai đoạn quan trọng trong chu trình ML, trong số những giai đoạn khác (Ashmore et al., 2021; Paleyes et al., 2022). Để hỗ trợ nhu cầu của các nhà thực hành, giai đoạn học mô hình cần được trang bị để xử lý việc huấn luyện và cập nhật một số lượng lớn mô hình, trong khi giai đoạn triển khai mô hình phải cung cấp cách thức dễ dàng và hiệu quả để tích hợp và phục vụ các mô hình đó để chạy trong sản xuất, nghĩa là chạy như một phần của các hoạt động kinh doanh thông thường.

Đồng thời, đó là thực hành phổ biến trong các hệ thống sản xuất NLP để sử dụng các mô hình ngôn ngữ được huấn luyện trước dựa trên transformer (Vaswani et al., 2017) bằng cách tinh chỉnh chúng cho các nhiệm vụ cụ thể. Mặc dù hiệu quả, các mô hình ngôn ngữ có số lượng lớn tham số đòi hỏi tài nguyên tính toán đáng kể để tinh chỉnh. Mặc dù tinh chỉnh các mô hình được huấn luyện trước có thể hiệu quả về dữ liệu hơn so với huấn luyện mô hình từ đầu, chuyên môn của người chú thích hoặc chuyên gia lĩnh vực vẫn có thể cần thiết để gắn nhãn một số lượng lớn ví dụ, đặc biệt nếu có sự khác biệt đáng kể giữa nhiệm vụ cụ thể và mục tiêu huấn luyện trước (Wang et al., 2020). Do đó, đó là quy trình tốn kém và mất thời gian, đặc biệt nếu cần huấn luyện và phục vụ nhiều mô hình trong sản xuất. Để giải quyết thách thức huấn luyện nhiều mô hình, các nhà nghiên cứu đã khám phá Học Đa Nhiệm vụ (MTL) như một giải pháp (Ruder, 2017). MTL huấn luyện một mô hình duy nhất để học nhiều nhiệm vụ đồng thời trong khi chia sẻ một phần tham số mô hình giữa chúng (Caruana, 1997), làm cho quy trình hiệu quả về bộ nhớ và, trong một số trường hợp, hiệu quả tính toán hơn so với huấn luyện nhiều mô hình. Ngoài ra, sử dụng một mô hình duy nhất cho nhiều nhiệm vụ cụ thể trong hệ thống sản xuất có thể đơn giản hóa việc tích hợp mô hình ML với hệ thống ML và giảm chi phí kinh tế. Điều này là do bản chất mô-đun của kiến trúc MTL thúc đẩy chia sẻ mã và mô hình, tái sử dụng, cộng tác dễ dàng hơn và bảo trì. Hơn nữa, mô hình MTL giảm thời gian nhàn rỗi vì cùng một mô hình được sử dụng cho các nhiệm vụ khác nhau. Do đó, các phương pháp MTL cung cấp giải pháp đầy hứa hẹn để giảm thiểu một số khó khăn liên quan đến việc quản lý nhiều mô hình trong hệ thống sản xuất ML.

Trong khảo sát này, trước tiên chúng tôi cung cấp tổng quan về các phương pháp MTL dựa trên transformer trong NLP (xem Phần 3). Thứ hai, chúng tôi nêu bật các cơ hội sử dụng phương pháp MTL qua nhiều giai đoạn của chu trình ML, đặc biệt tập trung vào các thách thức liên quan đến kỹ thuật dữ liệu, phát triển mô hình, triển khai và giám sát (xem Phần 4). Chúng tôi chỉ tập trung vào kiến trúc dựa trên transformer. Theo hiểu biết của chúng tôi, đây là khảo sát đầu tiên thảo luận một cách có hệ thống về lợi ích của việc sử dụng phương pháp MTL qua nhiều giai đoạn chu trình ML (xem Phần 2). Ngoài ra, chúng tôi khuyến khích nghiên cứu sâu hơn về mối liên hệ giữa MTL và Học Liên tục (CL). Chúng tôi lập luận rằng việc có mô hình có khả năng xử lý cả MTL và CL là thực tế vì nó giải quyết nhu cầu huấn luyện lại định kỳ và cập nhật liên tục để đáp ứng với sự thay đổi phân phối và bổ sung khả năng mới trong mô hình sản xuất.

Phần còn lại của bài báo được tổ chức như sau. Trong Phần 2, chúng tôi xem xét ngắn gọn các khảo sát liên quan và nêu bật các khoảng trống được giải quyết trong khảo sát của chúng tôi. Trong Phần 3, chúng tôi đưa ra tổng quan về các phương pháp MTL dựa trên transformer. Trong Phần 4, chúng tôi phân tích có hệ thống lợi ích của việc sử dụng MTL thông qua các giai đoạn chu trình ML cụ thể. Và cuối cùng, trong Phần 5, chúng tôi đưa ra kết luận cho công việc của mình.

2 KHẢO SÁT LIÊN QUAN

Trong phần này, chúng tôi đưa ra tổng quan về công việc liên quan về MTL, hệ thống ML và CL, và chỉ ra những gì chưa được thảo luận cho đến nay về mối liên hệ của MTL với cả hệ thống ML và CL.

2.1 HỌC ĐA NHIỆM VỤ

Ý tưởng về MTL đã được khám phá trong nhiều nghiên cứu. Trong phần này, chúng tôi cung cấp tổng quan về các khảo sát MTL liên quan, giải quyết các khía cạnh khác nhau của MTL, và liệt kê chúng cùng với các khảo sát tương ứng trong Bảng 1.² Trong phần còn lại của phần này, chúng tôi chỉ đề cập đến các khảo sát liên quan và xem xét chi tiết hơn từng khía cạnh MTL (được hiển thị bằng chữ đậm).³

Nhiều lĩnh vực ứng dụng đã được nghiên cứu trong công việc trước đây, từ các khảo sát bao gồm nhiều lĩnh vực (Ruder, 2017; Zhang & Yang, 2017; 2018; Thung & Wee, 2018; Vafaeikia et al., 2020; Crawshaw, 2020; Upadhyay et al., 2021; Abhadiomhen et al., 2022), đến những khảo sát dành riêng cho lĩnh vực cụ thể, như thị giác máy tính (Vandenhende et al., 2021) hoặc xử lý ngôn ngữ tự nhiên (Zhou, 2019; Worsham & Kalita, 2020; Chen et al., 2021; Samant et al., 2022; Zhang et al., 2023). Cả mô hình tính toán ML truyền thống và học sâu đều được nghiên cứu. ML truyền thống được thảo luận chủ yếu trong các nghiên cứu cũ hơn, trong khi học sâu được trình bày trong tất cả trừ một nghiên cứu.

Kiến trúc MTL được thảo luận rộng rãi trong công việc trước đây. Chia sẻ tham số cứng và mềm (Ruder, 2017) là phân loại kiến trúc được sử dụng nhiều nhất, nhưng các khảo sát gần đây đã tinh chỉnh phân loại để phân loại chính xác hơn (Crawshaw, 2020; Chen et al., 2021). Tiếp theo, một số kiến trúc MTL được phân loại là học-để-chia-sẻ (Ruder et al.,

²Phiên bản rộng hơn của bảng được cung cấp trong Phụ lục Bảng 3.
³Phiên bản rộng hơn của phần được cung cấp trong Phụ lục A.1.
2

--- TRANG 3 ---
Bản thảo.
Bảng 1: Các khía cạnh được thảo luận theo khảo sát MTL. Các khía cạnh được chỉ ra bằng chữ đậm.

Năm Khảo sát MTL
2017 1- (Ruder, 2017) 2- (Zhang & Yang, 2017)
2018 3- (Zhang & Yang, 2018) 4- (Thung & Wee, 2018)
2019 5- (Zhou, 2019)
2020 6- (Vafaeikia et al., 2020) 7- (Worsham & Kalita, 2020) 8- (Crawshaw, 2020)
2021 9- (Vandenhende et al., 2021) 10- (Chen et al., 2021) 11- (Upadhyay et al., 2021)
2022 12- (Samant et al., 2022) 13- (Abhadiomhen et al., 2022)
2023 14- (Zhang et al., 2023)

Khía cạnh \Khảo sát 1 2 3 4 5 6 7 8 9 10 11 12 13 14
Mô hình Tính toán
ML Truyền thống ✓ ✓ ✓ ✓ ✓
Học Sâu ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Kiến trúc
Học để Chia sẻ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Mô hình Đa năng ✓ ✓ ✓ ✓ ✓
Tối ưu hóa
Trọng số Mất mát ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Điều chuẩn ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Lập lịch Nhiệm vụ ✓ ✓ ✓ ✓ ✓ ✓
Điều biến Gradient ✓ ✓ ✓ ✓ ✓
Chưng cất Kiến thức ✓ ✓ ✓ ✓
Tối ưu hóa Đa mục tiêu ✓ ✓ ✓
Học Mối quan hệ Nhiệm vụ
Nhóm Nhiệm vụ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Chuyển giao Mối quan hệ ✓ ✓ ✓ ✓ ✓
Nhúng Nhiệm vụ ✓ ✓
Kết nối với Mô hình Học
Học Tăng cường ✓ ✓ ✓ ✓ ✓ ✓
Học Chuyển giao ✓ ✓ ✓
Meta-Learning ✓ ✓ ✓
Học Trực tuyến ✓ ✓ ✓
Học Liên tục
Lĩnh vực Ứng dụng
Xử lý Ngôn ngữ Tự nhiên ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Thị giác Máy tính ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓

2017), cung cấp giải pháp thích ứng hơn bằng cách học cách chia sẻ tham số giữa các nhiệm vụ, thay vì có việc chia sẻ được xác định trước. Ngoài ra, một số kiến trúc MTL được phân loại là mô hình đa năng, xử lý nhiều phương thức, lĩnh vực và nhiệm vụ sử dụng một mô hình duy nhất (Kaiser et al., 2017; Pramanik et al., 2019).

Các kỹ thuật tối ưu hóa cho kiến trúc MTL cũng được thảo luận rộng rãi, trong khi trọng số mất mát là phương pháp phổ biến nhất để giảm thiểu thách thức MTL. Các kỹ thuật bao gồm trọng số mất mát theo độ bất định (Kendall et al., 2018), tốc độ học (Liu et al., 2019a; Zheng et al., 2019), hoặc hiệu suất (Guo et al., 2018; Jean et al., 2019), trong số những kỹ thuật khác. Tiếp theo, và liên quan chặt chẽ đến việc cân trọng mất mát nhiệm vụ, là vấn đề lập lịch nhiệm vụ liên quan đến việc chọn nhiệm vụ để huấn luyện ở mỗi bước. Nhiều kỹ thuật được sử dụng, từ những kỹ thuật đơn giản sử dụng lấy mẫu nhiệm vụ đồng đều hoặc tỷ lệ, đến những kỹ thuật phức tạp hơn, như lấy mẫu ủ (Stickland & Murray, 2019) hoặc phương pháp dựa trên học chủ động (Pilault et al., 2020). Cuối cùng, phương pháp điều chuẩn (Long et al., 2017; Lee et al., 2018; Pascal et al., 2021), điều biến gradient (Lopez-Paz & Ranzato, 2017; Sinha et al., 2018), chưng cất kiến thức (Clark et al., 2019b), và tối ưu hóa đa mục tiêu (Lin et al., 2019) cũng được áp dụng để tối ưu hóa mô hình MTL.

Học mối quan hệ nhiệm vụ trong MTL tập trung vào việc học biểu diễn rõ ràng của nhiệm vụ hoặc mối quan hệ giữa chúng, và thường ba loại phương pháp được sử dụng. Thứ nhất, nhóm nhiệm vụ nhằm chia một tập hợp nhiệm vụ thành các nhóm để tối đa hóa chia sẻ kiến thức trong quá trình huấn luyện chung (Standley et al., 2020). Thứ hai, học mối quan hệ chuyển giao xác định khi nào việc chuyển giao kiến thức từ một nhiệm vụ sang nhiệm vụ khác sẽ có lợi cho việc học chung (Zamir et al., 2018). Cuối cùng, phương pháp nhúng nhiệm vụ nhằm học không gian nhúng nhiệm vụ (Vu et al., 2020).

Các công việc trước đây đã tạo kết nối với các mô hình học khác, bao gồm học tăng cường, học chuyển giao, meta-learning, học chủ động và học trực tuyến. Theo hiểu biết của chúng tôi, không có công việc trước đây nào nghiên cứu một cách có hệ thống về mối liên hệ giữa MTL và CL. Chúng tôi tin rằng mối liên hệ giữa MTL và CL đại diện cho hướng nghiên cứu đầy hứa hẹn, vì chúng tôi sẽ thúc đẩy nhu cầu cho mối liên hệ này trong Phần 4.4.

2.2 CHU TRÌNH ML VÀ HỆ THỐNG ML

Sự tăng trưởng vô song của những tiến bộ trong phương pháp ML trong những năm gần đây, với các ứng dụng trong NLP, thị giác máy tính và khác, đã tăng độ phức tạp của việc xây dựng hệ thống ML cần giải quyết các yêu cầu của chu trình ML. Các công việc trước đây đã xem xét các thách thức của hệ thống như vậy, thường xác định các giai đoạn chu trình ML như quản lý dữ liệu, học mô hình và triển khai mô hình, để nghiên cứu một cách có hệ thống hoạt động của hệ thống ML và xác định thách thức trong và giữa các giai đoạn (Vartak & Madden, 2018; Ashmore et al., 2021; Paleyes et al., 2022; Huyen, 2022).

Ví dụ, Vartak & Madden (2018) đã xác định các giai đoạn chu trình ML và phân tích thách thức quản lý mô hình. Hơn nữa, Ashmore et al. (2021) thảo luận về đảm bảo ML cho mỗi giai đoạn, trong khi Paleyes et al. (2022) xem xét thách thức của các nhà thực hành ở mỗi giai đoạn của quy trình triển khai mô hình ML trong phạm vi rộng hơn so với các khảo sát trước đây.

Trong phần còn lại của phần này, chúng tôi cung cấp một vài ví dụ về thách thức xảy ra trong các giai đoạn điển hình của chu trình ML.

Có nhiều thách thức xảy ra trong các giai đoạn khác nhau của chu trình ML. Ví dụ, quản lý dữ liệu thường là giai đoạn sớm của chu trình ML với các thách thức liên quan như thu thập và tiền xử lý dữ liệu (Polyzotis et al., 2018; Sambasivan et al., 2021; Whang et al., 2023). Tiếp theo, các giai đoạn học và xác minh mô hình diễn ra, trình bày thách thức như chọn (Ding et al., 2018) và huấn luyện (Sun, 2020) mô hình, và xác định phương pháp hiệu quả nhất để xác minh nó (Bernardi et al., 2019; Schröder & Schulz, 2022), tương ứng. Sau đó, giai đoạn triển khai mô hình diễn ra với thách thức như tích hợp mô hình (Sculley et al., 2015; Renggli et al., 2019) vào sản xuất. Cuối cùng, giai đoạn giám sát với thách thức như giám sát hiệu suất mô hình liên tục (Schröder & Schulz, 2022) và cập nhật mô hình theo thời gian (Ditzler et al., 2015; Abdelkader, 2020).

Một số thách thức có thể tác động đến nhiều giai đoạn của chu trình ML, như hợp tác giữa các nhóm và vai trò đa dạng, bao gồm kỹ sư phần mềm và dữ liệu, nhà khoa học dữ liệu và các bên liên quan khác (Takeuchi & Yamamoto, 2020; Nahar et al., 2022; Pei et al., 2022; Yang et al., 2022). Hơn nữa, có những thách thức về thiên vị, công bằng và trách nhiệm trong đạo đức (Mehrabi et al., 2021; Kim & Doshi-Velez, 2021), các quy định khác nhau được thiết lập bởi luật pháp (Marchant, 2011; Politou et al., 2018) và các cuộc tấn công đối nghịch trong bảo mật (Ren et al., 2020; Rosenberg et al., 2021), trong số những thách thức khác.

Các công việc trước đây đã giải quyết các khía cạnh MTL ở mức độ khác nhau trong các giai đoạn cụ thể, hoặc theo cách thẳng thắn hoặc gián tiếp. Tuy nhiên, một cuộc thảo luận có hệ thống về lợi ích tiềm năng của việc sử dụng phương pháp MTL để giảm thiểu thách thức qua các giai đoạn khác nhau của chu trình ML chưa được thực hiện.

2.3 HỌC LIÊN TỤC

CL học tăng dần một chuỗi nhiệm vụ, với mục tiêu mở rộng dần kiến thức có được và sử dụng nó cho việc học tiếp theo (Chen & Liu, 2018). CL nhằm vượt qua việc quên thảm khốc (CF) và tạo thuận lợi cho việc chuyển giao kiến thức (KT) qua các nhiệm vụ, nơi CF là sự suy giảm hiệu suất trên các nhiệm vụ trước đây khi học những nhiệm vụ mới, và KT là khả năng áp dụng kiến thức từ nhiệm vụ trong quá khứ cho nhiệm vụ mới (Ke & Liu, 2022). Các đánh giá trước về CL (Hsu et al., 2018; De Lange et al., 2021) phân loại cài đặt CL dựa trên phân phối đầu ra và đầu vào biên P(Y(t)) và P(X(t)) của nhiệm vụ t, với P(X(t)) ≠ P(X(t+1)). Thứ nhất, học tăng lớp được đặc trưng bởi không gian đầu ra mở rộng với nhãn lớp quan sát được sao cho Y(t) ⊂ Y(t+1) và P(Y(t)) ≠ P(Y(t+1)). Thứ hai, học tăng nhiệm vụ (TIL), yêu cầu nhãn nhiệm vụ t để xác định các nút đầu ra riêng biệt Y(t) cho nhiệm vụ hiện tại t, nơi Y(t) ≠ Y(t+1). Cuối cùng, học lĩnh vực tăng dần xác định nhiệm vụ với nhãn lớp và phân phối xác suất bằng nhau, Y(t) = Y(t+1), và P(Y(t)) = P(Y(t+1)).

Các phương pháp CL cũng được phân loại thành ba loại chính dựa trên cách thông tin đặc thù nhiệm vụ được lưu trữ và sử dụng trong quá trình học tăng dần. Thứ nhất, phương pháp phát lại lưu trữ mẫu ở định dạng thô hoặc tạo mẫu giả với mô hình sinh, phát lại chúng khi học nhiệm vụ mới để giảm thiểu việc quên và ngăn chặn sự can thiệp nhiệm vụ trước đây. Thứ hai, phương pháp dựa trên điều chuẩn, mặt khác, tránh lưu trữ đầu vào thô và giảm yêu cầu bộ nhớ bằng cách giới thiệu thuật ngữ điều chuẩn bổ sung trong hàm mất mát để củng cố kiến thức trước đây khi học dữ liệu mới. Thứ ba, phương pháp cô lập tham số phân bổ các tham số mô hình khác nhau cho mỗi nhiệm vụ, hoặc bằng cách thêm nhánh đặc thù nhiệm vụ mới hoặc che khuất các phần nhiệm vụ trước đây, để ngăn chặn việc quên và duy trì kiến thức đặc thù nhiệm vụ. Chúng tôi giới thiệu độc giả đến Ke & Liu (2022) để biết thêm phân loại CL tinh chỉnh và chi tiết trong NLP.

Trong CL, MTL thường được sử dụng như một đường cơ sở trên cùng có thể sử dụng tất cả dữ liệu từ tất cả các nhiệm vụ đồng thời (De Lange et al., 2021; Ke & Liu, 2022). Vì CL và MTL hoạt động trong các cài đặt học khác nhau, ít công việc cố gắng kết nối hai mô hình. Sun et al. (2020) trình bày khung huấn luyện trước liên tục có tên ERNIE 2.0 xây dựng tăng dần các nhiệm vụ huấn luyện trước và sau đó học các mô hình được huấn luyện trước trên các nhiệm vụ được xây dựng này thông qua học đa nhiệm vụ liên tục. Tiếp theo, ERNIE 2.0 được thử nghiệm chống lại các phương pháp huấn luyện trước CL và MTL để đánh giá tác động đến nhiệm vụ tóm tắt văn bản trừu tượng nhưng hoạt động tương tự như các phương pháp khác (Kirstein et al., 2022).

Trong Phần 4.4, chúng tôi thúc đẩy nghiên cứu sâu hơn về việc kết hợp các phương pháp CL và MTL, vì các phương pháp huấn luyện trước không đủ để xử lý sự thay đổi phân phối và điều chỉnh mô hình cho các yêu cầu kinh doanh mới trong các tình huống thực tế.

3 PHƯƠNG PHÁP HỌC ĐA NHIỆM VỤ

3.1 PHÂN LOẠI

Có nhiều phân loại MTL khác nhau được đề cập trong các khảo sát được trình bày trong Phần 2.1. Ruder (2017) phân biệt giữa chia sẻ tham số cứng và mềm, đã chứng minh là phân loại có ảnh hưởng, vì nó được sử dụng trong các công việc sau này. Zhang & Yang (2018) xác định ba loại học có giám sát đa nhiệm vụ – dựa trên đặc trưng, tham số và thể hiện. Vandenhende et al. (2021) phân biệt giữa kiến trúc tập trung vào bộ mã hóa và tập trung vào bộ giải mã. Chen et al. (2021) thảo luận về kiến trúc song song, phân cấp, mô-đun và sinh đối nghịch. Chúng tôi phân loại các phương pháp MTL dựa trên transformer thành 3 loại chính dựa trên sự khác biệt trong kiến trúc: (1) Bộ mã hóa Chia sẻ Hoàn toàn, (2) Adapter, và (3) Siêu mạng (Hình 1).⁴

Hình 1: Tổng quan đơn giản về kiến trúc MTL. Hình con a) biểu diễn bộ mã hóa chia sẻ hoàn toàn, b) adapter, và c) siêu mạng. Các thành phần màu xanh được huấn luyện chung bởi tất cả các nhiệm vụ, các thành phần màu xanh lá cây là đặc thù nhiệm vụ, và các thành phần màu xám được giữ đông lạnh. Thành phần adapter có chấm gợi ý các vị trí chèn adapter có thể.

3.2 TỔNG QUAN PHƯƠNG PHÁP MTL

3.2.1 BỘ MÃ HÓA CHIA SẺ HOÀN TOÀN

Một phương pháp đơn giản và trực quan cho MTL là có sự phân chia rõ ràng giữa các tham số được chia sẻ và đặc thù nhiệm vụ. Trong phương pháp như vậy, có một bộ mã hóa dựa trên transformer được chia sẻ ở các lớp thấp hơn, trong khi các lớp trên cùng bao gồm các lớp đặc thù nhiệm vụ khác nhau (đầu). Một phương pháp như vậy, MT-DNN (Liu et al., 2019b), gộp tất cả các nhiệm vụ GLUE (Wang et al., 2018) lại với nhau và cập nhật mô hình tương ứng. Bộ mã hóa được chia sẻ được cập nhật cho tất cả các thể hiện, trong khi các đầu đặc thù nhiệm vụ chỉ được cập nhật cho các thể hiện của nhiệm vụ mà chúng đặc thù. Có một số nhược điểm đối với phương pháp MT-DNN này. Thứ nhất, sự can thiệp nhiệm vụ không được tính đến và các tác giả chỉ đơn giản hy vọng rằng các nhiệm vụ sẽ tương tác tốt, mặc dù một số trong số chúng thuộc các lĩnh vực khác nhau. Tiếp theo, lấy mẫu ngẫu nhiên tỷ lệ được sử dụng, có thể dẫn đến việc không phù hợp trên các tập dữ liệu tài nguyên thấp. Cuối cùng, mất mát được tính toán theo ba cách khác nhau (cho phân loại, hồi quy và xếp hạng), và kết quả là, nó có quy mô khác nhau. Tuy nhiên, tất cả các hàm mất mát đều được cân trọng bằng nhau. Bất chấp những quan sát này, mô hình của họ vượt trội so với việc tinh chỉnh mô hình BERT (Devlin et al., 2019) khác nhau trên hầu hết các nhiệm vụ. Ngoài ra, họ đã thử tinh chỉnh mô hình đa nhiệm vụ này thêm trên mỗi nhiệm vụ riêng biệt sau khi huấn luyện chung trên tất cả các nhiệm vụ, tạo ra N mô hình cho N nhiệm vụ. Điều đó lại mang lại cải thiện và hiệu suất tiên tiến vào thời điểm đó. Tuy nhiên, nhược điểm rõ ràng là có mô hình khác nhau cho mỗi nhiệm vụ.

Một phương pháp bộ mã hóa chia sẻ khác là tiền tinh chỉnh. Muppet (Aghajanyan et al., 2021) chia sẻ bộ mã hóa trong MTL trên 46 tập dữ liệu đa dạng. Các lô không đồng nhất đã chứng minh có lợi trong việc xử lý gradient nhiễu từ các nhiệm vụ khác nhau. Hơn nữa, để có huấn luyện ổn định, mất mát điểm dữ liệu được chia cho log(n), nơi n biểu thị lực lượng của tập nhãn cho nhiệm vụ liên quan. Họ duy trì phân phối tự nhiên của tập dữ liệu vì các phương pháp khác dẫn đến

⁴Trong Phụ lục B.1, chúng tôi đưa ra tổng quan ngắn gọn về các phương pháp kỹ thuật prompt như loại thứ tư. Tuy nhiên, chúng tôi không bao gồm nó trong bài báo chính do nhu cầu số lượng lớn tham số để hoạt động tốt, làm cho nó không thể tiếp cận với hầu hết các nhà thực hành.
5

--- TRANG 4 ---
Bản thảo.
hiệu suất suy giảm. Các tác giả tìm ra ngưỡng khoảng 15 nhiệm vụ, dưới đó hiệu suất tinh chỉnh cụ thể bị suy giảm, và trên đó hiệu suất cải thiện tuyến tính theo số nhiệm vụ tiền tinh chỉnh.

Một phương pháp tương tự với bộ giải mã được thêm vào, EXT5 (Aribandi et al., 2021), mở rộng hỗn hợp lên 107 nhiệm vụ có giám sát, định dạng chúng cho kiến trúc bộ mã hóa-giải mã, và thực hiện tiền tinh chỉnh cùng với việc khử nhiễu span C4 không giám sát của T5 (Raffel et al., 2020). Hỗn hợp nhiệm vụ của họ cũng bao gồm các ứng dụng NLP như đọc hiểu, trả lời câu hỏi sách đóng, lý luận thường thức, đối thoại và tóm tắt, trong số những ứng dụng khác. Điều này cho thấy các mô hình bộ mã hóa-giải mã như T5 có khả năng giải quyết phạm vi rộng hơn các ứng dụng NLP so với các mô hình chỉ có bộ mã hóa. Tuy nhiên, các mô hình đặc thù nhiệm vụ vẫn đạt được hiệu suất tốt hơn so với các mô hình tổng quát (Chung et al., 2022).

3.2.2 ADAPTER

Trước khi được sử dụng trong NLP, các mô-đun adapter dư thừa được giới thiệu lần đầu cho lĩnh vực thị giác (Rebuffi et al., 2017). Adapter là các mô-đun nhỏ, đặc thù nhiệm vụ thường được chèn trong các lớp mạng, nhưng cũng có thể được tiêm song song với chúng. Trong khảo sát này, mạng luôn là kiến trúc dựa trên transformer. So với kích thước transformer, chúng thêm số lượng tham số không đáng kể cho mỗi nhiệm vụ. Các tham số của mạng gốc vẫn đông lạnh trừ khi được nêu khác, dẫn đến mức độ chia sẻ tham số cao và số lượng tham số có thể huấn luyện nhỏ. Do đó, adapter cho nhiệm vụ mới có thể dễ dàng được thêm vào mà không cần huấn luyện lại transformer hoặc adapter khác. Chúng học biểu diễn đặc thù nhiệm vụ theo lớp, nhỏ, có thể mở rộng và có thể chia sẻ, có biểu diễn mô-đun và sự kết hợp thông tin không can thiệp (Pfeiffer et al., 2020b). Vì các adapter tương ứng được huấn luyện riêng biệt, nhu cầu về heuristic lấy mẫu do kích thước tập dữ liệu lệch không còn phát sinh (Pfeiffer et al., 2020b).

AdapterHub. AdapterHub (Pfeiffer et al., 2020b) là khung cho phép sử dụng động các adapter được huấn luyện trước cho các nhiệm vụ và ngôn ngữ khác nhau.⁵ Khung được xây dựng trên thư viện HuggingFace Transformers và cho phép thích ứng nhanh chóng và dễ dàng các mô hình được huấn luyện trước tiên tiến. Nó cho phép chia sẻ tham số hiệu quả giữa các nhiệm vụ bằng cách huấn luyện nhiều adapter đặc thù nhiệm vụ và ngôn ngữ, có thể được trao đổi và kết hợp sau này. Người ta có thể chọn xếp chồng adapter lên nhau, kết hợp chúng với attention (Pfeiffer et al., 2020a), hoặc thay thế chúng động. Tải xuống, chia sẻ và huấn luyện adapter yêu cầu thay đổi tối thiểu trong script huấn luyện.

Adapter cổ chai. Trong tài liệu của AdapterHub, ba phương pháp adapter cổ chai khác nhau được đề cập. Adapter có thể được chèn sau cả khối Multi-Head Attention (MHA) và Feed-Forward (FF) (Houlsby et al., 2019), chỉ sau khối FF (Pfeiffer et al., 2020c), hoặc song song với các lớp Transformer (He et al., 2021). Adapter cổ chai bao gồm chiếu xuống, phi tuyến (thường là ReLU), và chiếu lên lại về kích thước gốc. Kết nối dư thừa được sử dụng, và chuẩn hóa lớp được áp dụng sau đó.

Adapter ngôn ngữ. Trong khung MAD-X (Pfeiffer et al., 2020c), các tác giả huấn luyện (1) adapter ngôn ngữ thông qua mô hình hóa ngôn ngữ có mặt nạ (MLM) trên dữ liệu ngôn ngữ đích không nhãn, và (2) adapter nhiệm vụ bằng cách tối ưu hóa nhiệm vụ đích trên dữ liệu có nhãn trong ngôn ngữ nguồn với dữ liệu huấn luyện nhiều nhất. Sau đó, adapter được xếp chồng, cho phép chuyển giao không bắn qua ngôn ngữ bằng cách thay thế adapter ngôn ngữ đích khi suy luận. Adapter có thể đảo ngược được giới thiệu để giải quyết sự không khớp giữa từ vựng đa ngôn ngữ của mô hình được huấn luyện trước và từ vựng ngôn ngữ đích. Do đó, adapter ngôn ngữ có thể hữu ích khi người ta đã huấn luyện adapter nhiệm vụ cho nhiệm vụ cụ thể và bây giờ cần thực hiện suy luận cho cùng nhiệm vụ, nhưng trên dữ liệu mới từ ngôn ngữ khác.

Khác. Lớp Attention Chiếu (PAL) (Stickland & Murray, 2019) là lớp attention đa đầu có chiều thấp được thêm song song với các lớp transformer. Attention đa đầu được áp dụng trên đầu vào được chiếu xuống, sau đó một chiếu lên về chiều gốc được áp dụng. Các ma trận chiếu xuống và lên này được chia sẻ giữa các lớp, nhưng không giữa các nhiệm vụ. Các tác giả tinh chỉnh bộ mã hóa được huấn luyện trước cùng với PAL. Điều này có nhược điểm: (1) có thể quên kiến thức được huấn luyện trước, (2) cần truy cập tất cả các nhiệm vụ vào thời điểm huấn luyện, và (3) thêm nhiệm vụ mới yêu cầu huấn luyện lại chung hoàn toàn. Do đó, phương pháp này thiếu nhiều đặc tính của adapter.

AdapterFusion (Pfeiffer et al., 2020a) giới thiệu giai đoạn kết hợp kiến thức, trong đó các adapter được huấn luyện trước được kết hợp. Phương pháp này sử dụng nhiều adapter để tối đa hóa chuyển giao kiến thức giữa các nhiệm vụ mà không gặp phải nhược điểm MTL, như quên thảm khốc (Serra et al., 2018) hoặc can thiệp nhiệm vụ (Wu et al., 2020). Nó giới thiệu tập trọng số mới học cách kết hợp adapter như hàm động của dữ liệu nhiệm vụ đích bằng cách sử dụng attention. Điều này cho thấy nhược điểm lớn nhất – AdapterFusion được huấn luyện chỉ cho một nhiệm vụ.

Hu et al. (2021) lập luận rằng thiết kế cổ chai adapter gốc (Houlsby et al., 2019) giới thiệu độ trễ suy luận vì adapter được xử lý tuần tự, trong khi các mô hình ngôn ngữ lớn (LLM) dựa vào song song hóa phần cứng. Phương pháp của họ, LoRA (Xấp xỉ Hạng Thấp) sửa đổi trọng số attention của ma trận chiếu query và value bằng cách giới thiệu ma trận phân rã hạng thấp có thể huấn luyện song song với tính toán gốc. Điều này giảm độ trễ suy luận, vì ma trận phân rã có thể được hợp nhất với trọng số được huấn luyện trước để suy luận nhanh hơn.

⁵https://adapterhub.ml
6

--- TRANG 5 ---
Bản thảo.
Hình 2: Các giai đoạn chu trình ML. Hình được lấy từ Huyen (2022).

Bảng 2: Các giai đoạn Chu trình ML và thách thức tương ứng.

Giai đoạn Chu trình ML | Thách thức
---|---
Xác định Phạm vi Dự án | Yêu cầu Ban đầu
Kỹ thuật Dữ liệu | Gắn nhãn Khối lượng Lớn Dữ liệu<br>Chi phí của Người chú thích và Chuyên gia<br>Thiếu Dữ liệu Phương sai Cao
Phát triển Mô hình | Độ phức tạp Mô hình<br>Môi trường Hạn chế Tài nguyên<br>Chi phí Tính toán<br>Tác động Môi trường
Triển khai | Dễ dàng tích hợp
Giám sát | Thay đổi Phân phối<br>Phân tích Kinh doanh | Yêu cầu Mới

3.2.3 SIÊU MẠNG

Siêu mạng là mạng tạo ra trọng số của mạng khác (Ha et al., 2016). Phương pháp này có thể giảm thiểu nhược điểm của adapter, đó là thiếu chia sẻ kiến thức. Siêu mạng cho phép chia sẻ kiến thức qua các nhiệm vụ trong khi thích ứng với từng nhiệm vụ thông qua tạo tham số đặc thù nhiệm vụ.

CA-MTL (Pilault et al., 2020) mô-đun hóa mạng được huấn luyện trước bằng cách thêm các lớp điều kiện nhiệm vụ hoặc thay đổi trọng số được huấn luyện trước bằng cách sử dụng nhúng nhiệm vụ. Mạng transformer điều kiện nhiệm vụ của họ có bốn thành phần: (1) attention điều kiện, (2) căn chỉnh điều kiện, (3) chuẩn hóa lớp điều kiện, và (4) cổ chai điều kiện. Trong (1), họ sử dụng attention điều kiện chéo khối cho phép attention tính đến thiên vị đặc thư nhiệm vụ. Thành phần (2) căn chỉnh dữ liệu của các nhiệm vụ đa dạng. Trong (3), họ điều chỉnh thống kê chuẩn hóa lớp cho các nhiệm vụ cụ thể. Cuối cùng, (4) tạo thuận lợi chia sẻ trọng số và tăng cường luồng thông tin đặc thù nhiệm vụ từ các lớp thấp hơn. Ngoài ra, họ sử dụng lấy mẫu độ bất định đa nhiệm vụ. Điều này ưu tiên các nhiệm vụ có độ bất định cao nhất bằng cách lấy mẫu nhiệm vụ bất cứ khi nào entropy của nó tăng, giúp tránh quên thảm khốc. Khi giới thiệu nhiệm vụ mới, họ tuyên bố chỉ cần thêm đầu giải mã tuyến tính mới và vector nhúng nhiệm vụ mới để điều chế lại trọng số hiện tại.

HyperFormer++ (Mahabadi et al., 2021) sử dụng siêu mạng để tạo trọng số của adapter và tham số chuẩn hóa lớp. Các siêu mạng này điều kiện trên nhúng nhiệm vụ, vị trí adapter (sau lớp con MHA hoặc FF), và id lớp trong mô hình T5 (Raffel et al., 2020). Trong quá trình huấn luyện, họ lấy mẫu các nhiệm vụ bằng cách sử dụng lấy mẫu dựa trên nhiệt độ. Họ tuyên bố rằng cho mỗi nhiệm vụ mới, mô hình của họ chỉ yêu cầu học thêm nhúng nhiệm vụ.

HyperGrid (Tay et al., 2020) tận dụng cấu trúc chiếu siêu phân rã theo lưới giúp chuyên môn hóa các vùng trong ma trận trọng số cho các nhiệm vụ khác nhau. Để xây dựng siêu mạng được đề xuất, phương pháp của họ học tương tác và kết hợp giữa trạng thái toàn cầu, bất khả tri nhiệm vụ và trạng thái cục bộ, đặc thù nhiệm vụ. Họ trang bị các lớp con FF theo vị trí của Transformer với HyperGrid. Họ khởi tạo mô hình T5 từ checkpoint được huấn luyện trước và thêm tham số bổ sung được tinh chỉnh cùng với phần còn lại của mạng. Các tác giả của bài báo không đề cập gì cụ thể về khả năng thêm nhiệm vụ mới mà không huấn luyện lại, vì nó có vẻ không tầm thường.

4 MTL TỪ QUAN ĐIỂM CHU TRÌNH ML

Trong phần này, chúng tôi thảo luận về các thách thức và cơ hội kết hợp vào hệ thống sản xuất ML các phương pháp MTL thay vì sử dụng nhiều bản sao đơn nhiệm vụ. Được thúc đẩy bởi các đánh giá trước về chu trình ML (xem Phần 2.2), chúng tôi xác định các giai đoạn chu trình ML để thảo luận thách thức và cơ hội một cách có hệ thống.

Theo Huyen (2022), chúng tôi xác định sáu giai đoạn chu trình ML: (1) Xác định Phạm vi Dự án, (2) Kỹ thuật Dữ liệu, (3) Phát triển Mô hình, (4) Triển khai, (5) Giám sát, và (6) Phân tích Kinh doanh (Hình 2). Tiếp theo, chúng tôi chủ yếu tập trung vào các thách thức được thảo luận trong phạm vi rộng hơn trong Paleyes et al. (2022), trong khi chúng tôi lập luận cách MTL có thể giảm thiểu chúng. Thách thức cho mỗi giai đoạn của chu trình ML được liệt kê trong Bảng 2. Khi thảo luận về thách thức và cơ hội sử dụng phương pháp MTL, chúng tôi so sánh chúng với các giải pháp mô hình đơn nhiệm vụ tương ứng.

Trong phần còn lại của phần này, trước tiên chúng tôi thảo luận về các giai đoạn kỹ thuật dữ liệu và phát triển mô hình một cách riêng biệt. Sau đó, chúng tôi thảo luận về vấn đề cập nhật mô hình ML bằng cách chỉ ra cách các khía cạnh nhất định của vấn đề đặt ra thách thức khác nhau trong các giai đoạn khác nhau của chu trình ML.

7

--- TRANG 6 ---
Bản thảo.
4.1 KỸ THUẬT DỮ LIỆU

Giai đoạn đầu tiên chúng tôi thảo luận là kỹ thuật dữ liệu. Giai đoạn này tập trung vào việc chuẩn bị dữ liệu cần thiết để huấn luyện mô hình học máy, trong khi chúng tôi có sự quan tâm đặc biệt đến các thách thức liên quan đến thiếu dữ liệu có nhãn (xem Bảng 2).

Thách thức. Nhu cầu tăng cường dữ liệu có thể phát sinh từ nhiều yếu tố khác nhau, với một trong những vấn đề nan giải nhất là thiếu nhãn trong dữ liệu, đặc biệt trong các ứng dụng thực tế nơi dữ liệu có nhãn có thể khan hiếm. Đó là thực hành phổ biến trong hệ thống sản xuất NLP để sử dụng các mô hình ngôn ngữ dựa trên transformer được huấn luyện trước bằng cách tinh chỉnh chúng cho các nhiệm vụ cụ thể. Tuy nhiên, nếu có khoảng cách đáng kể giữa nhiệm vụ cụ thể và mục tiêu huấn luyện trước, một lượng lớn dữ liệu có nhãn vẫn có thể cần thiết để đạt được hiệu suất mục tiêu (Wang et al., 2020). Việc có được dữ liệu này liên quan đến sự tham gia tốn kém và mất thời gian của người chú thích và chuyên gia lĩnh vực. Ngoài ra, việc thiếu dữ liệu phương sai cao dẫn đến mô hình không thể tổng quát hóa tốt, như thích ứng mô hình ngôn ngữ với các ngôn ngữ tài nguyên thấp (Clark et al., 2019a).

Cơ hội. Các thách thức do thiếu dữ liệu có nhãn có thể được giảm thiểu bằng cách sử dụng phương pháp MTL. Ví dụ, nếu một tập hợp mô hình đơn nhiệm vụ đang được sử dụng trong hệ thống sản xuất, việc huấn luyện mô hình MTL thay thế có thể giúp giảm thiểu sự khan hiếm dữ liệu bằng cách học chung để giải quyết các nhiệm vụ liên quan (Phần 3.2.1). Lợi ích của MTL đã được thảo luận trước đây trong Caruana (1997); Ruder (2017), bao gồm khả năng tăng hiệu quả dữ liệu. Thứ nhất, các nhiệm vụ khác nhau chuyển giao các khía cạnh kiến thức khác nhau cho nhau, tăng cường khả năng biểu diễn để diễn đạt văn bản đầu vào, có thể có lợi cho các nhiệm vụ với tập dữ liệu tài nguyên thấp (Phần 3.2.1). Tuy nhiên, một số phương pháp MTL có thể hoạt động kém trong môi trường hạn chế tài nguyên do lựa chọn tối ưu hóa không phù hợp (Phần 3.2.1). Ngoài ra, sự hiện diện của các mẫu nhiễu khác nhau trong mỗi nhiệm vụ hoạt động như phương pháp tăng cường dữ liệu ngầm, hiệu quả tăng kích thước mẫu được sử dụng để huấn luyện, và dẫn đến mô hình mạnh mẽ với biểu diễn tổng quát hơn (Ruder, 2017). Cuối cùng, sử dụng tiền tinh chỉnh (Phần 3.2.1) có thể giảm thời gian hội tụ, tiết kiệm tài nguyên tính toán.

4.2 PHÁT TRIỂN MÔ HÌNH

Trong giai đoạn phát triển mô hình, chúng tôi tập trung vào hai nhóm thách thức. Nhóm đầu tiên đề cập đến vấn đề lựa chọn mô hình, bao gồm các vấn đề liên quan đến độ phức tạp mô hình và hạn chế tài nguyên. Nhóm thách thức thứ hai liên quan đến vấn đề trong huấn luyện mô hình, như chi phí tính toán của quy trình huấn luyện và tác động của nó đến môi trường. Chúng tôi giới thiệu độc giả đến (Gupta & Agrawal, 2022) để có tổng quan về phương pháp cho mô hình hiệu quả trong văn bản.

Thách thức Lựa chọn Mô hình. Khi lựa chọn mô hình để xử lý các nhiệm vụ mà người dùng cuối quan tâm, các nhà thực hành thường đối mặt với tình thế khó xử về sự đánh đổi giữa độ phức tạp mô hình và hiệu suất. Thông thường, các mô hình phức tạp có hiệu suất tốt hơn, nhưng chúng đi kèm với rủi ro làm phức tạp hóa thiết kế ngay từ đầu, dẫn đến thời gian phát triển dài hơn và thất bại triển khai (Haldar et al., 2019). Hơn nữa, chúng có thể không thực tế để sử dụng trong môi trường hạn chế tài nguyên nơi chúng yêu cầu tài nguyên tính toán và bộ nhớ cao.

Cơ hội Lựa chọn Mô hình. Kiến trúc MTL, được trình bày trong Phần 3.2, có thuộc tính có thể giảm thiểu thách thức liên quan đến sự đánh đổi giữa độ phức tạp mô hình và hiệu suất. Ví dụ, xem xét việc thay thế N mô hình đơn nhiệm vụ bằng một mô hình bộ mã hóa chia sẻ MTL duy nhất. Mô hình MTL sẽ có dấu chân bộ nhớ gần như nhỏ hơn N lần, vì số lượng tham số đặc thù nhiệm vụ không đáng kể so với số lượng tham số được chia sẻ. Việc giảm này dẫn đến phù hợp tốt hơn với môi trường hạn chế bộ nhớ trong khi chỉ có hiệu suất kém hơn một chút so với các bản đối tác đơn nhiệm vụ. Tương tự, lưu N adapter hoặc một siêu mạng duy nhất hiệu quả về bộ nhớ hơn nhiều so với lưu N mô hình đơn nhiệm vụ.

Thách thức Huấn luyện Mô hình. Việc huấn luyện mô hình học máy trình bày một số thách thức phải được giải quyết bởi các nhà thực hành. Một trong những thách thức lớn là chi phí kinh tế cao liên quan đến huấn luyện, do tài nguyên tính toán yêu cầu. Trong lĩnh vực xử lý ngôn ngữ tự nhiên, chi phí huấn luyện mô hình tiếp tục tăng, ngay cả khi chi phí các phép toán dấu phẩy động cá nhân giảm, do các yếu tố như tăng trưởng trong kích thước tập dữ liệu huấn luyện, số lượng tham số mô hình và số lượng phép toán liên quan đến quá trình huấn luyện (Sharir et al., 2020). Quá trình huấn luyện cũng có tác động đáng kể đến môi trường, dẫn đến tăng tiêu thụ năng lượng và phát thải khí nhà kính (Strubell et al., 2020). Những thách thức này nhấn mạnh nhu cầu giải quyết các tác động kinh tế và môi trường của việc huấn luyện mô hình học máy.

Cơ hội Huấn luyện Mô hình. Thách thức tài nguyên tính toán có thể được giảm thiểu trong một số khía cạnh bằng cách sử dụng phương pháp MTL để giảm chi phí huấn luyện mô hình. Thứ nhất, trong một số trường hợp, kích thước tập dữ liệu nhỏ hơn có thể được sử dụng do tiền tinh chỉnh hoặc chuyển giao kiến thức giữa các nhiệm vụ liên quan trong quá trình huấn luyện chung của mô hình MTL, dẫn đến huấn luyện hiệu quả dữ liệu hơn. Thứ hai, mô hình chung hiệu quả tham số hơn, dẫn đến giảm đáng kể số lượng tham số yêu cầu cho nhiều mô hình đơn nhiệm vụ.

8

--- TRANG 7 ---
Bản thảo.
Đánh đổi Lựa chọn, Huấn luyện và Suy luận. Số lượng phép toán dấu phẩy động không giảm trong một số trường hợp, và phụ thuộc vào lựa chọn kiến trúc MTL và bản chất của nhiệm vụ. Các đầu đặc thù nhiệm vụ khác nhau yêu cầu đầu vào khác nhau nếu nhiệm vụ thuộc các lĩnh vực khác nhau hoặc có mã hóa đầu vào khác nhau. Tuy nhiên, nếu nhiệm vụ thuộc cùng lĩnh vực và có cùng mã hóa đầu vào, một phần tính toán có thể được chia sẻ giữa các đầu đặc thù nhiệm vụ. Ví dụ, trong bộ mã hóa chia sẻ hoàn toàn (Phần 3.2.1), tính toán của toàn bộ bộ mã hóa có thể được chia sẻ, trong khi tính toán trong các đầu đặc thù nhiệm vụ không đáng kể. Tương tự với adapter (Phần 3.2.2) – phần lớn tính toán được chia sẻ, và chỉ adapter sau đó được cắm động để thực hiện các nhiệm vụ khác nhau trên cùng đầu vào. Cụ thể, lợi ích của việc sử dụng adapter là số lượng tham số có thể huấn luyện nhỏ, nhờ bộ mã hóa đông lạnh, dẫn đến lan truyền ngược gradient nhanh hơn. Mặt khác, lần truyền tiến, mất nhiều thời gian hơn so với bộ mã hóa không có adapter. Do đó, khi nhiệm vụ không chia sẻ tập dữ liệu, việc sử dụng adapter dẫn đến thời gian suy luận dài hơn so với các bản đối tác đơn nhiệm vụ. Suy luận AdapterFusion thậm chí còn chậm hơn, vì đầu vào phải đi qua tất cả adapter có sẵn. LoRA giải quyết vấn đề độ trễ suy luận bằng cách sử dụng kết hợp tham số.

4.3 TRIỂN KHAI MÔ HÌNH

Trong giai đoạn triển khai mô hình, trọng tâm của chúng tôi là đơn giản hóa việc tích hợp các mô hình ML được huấn luyện với hệ thống ML hiện có đang chạy trong sản xuất, với sự nhấn mạnh đặc biệt vào triển khai đơn giản, cộng tác liền mạch và dễ bảo trì.

Thách thức. Thách thức đầu tiên trong triển khai mô hình là chuẩn bị mô hình được phát triển để sử dụng trong môi trường sản xuất. Các phiên bản đầu tiên của mô hình thường được phát triển bởi các bên liên quan (ví dụ, nhà nghiên cứu ML) khác với những người chịu trách nhiệm triển khai chúng vào sản xuất (ví dụ, kỹ sư ML và DevOps). Điều này có nghĩa là mã mô hình cần được điều chỉnh để đáp ứng các yêu cầu của môi trường sản xuất hoạt động. Các yêu cầu đó thường nghiêm ngặt hơn và khác với những yêu cầu có sẵn trong giai đoạn phát triển, vì vậy quan trọng là phải giải quyết các khía cạnh hoạt động như khả năng mở rộng, bảo mật và độ tin cậy. Do đó, mỗi mô hình bổ sung làm tăng độ phức tạp cho quá trình, cả cho các bên liên quan và cho cơ sở hạ tầng hệ thống ML và tài nguyên tính toán tại chỗ. Một thách thức khác trong quá trình tích hợp mô hình là kết hợp mô hình vào các pipeline xử lý dữ liệu thực trong sản xuất, dù đó là cho các quy trình offline theo lô hay xử lý yêu cầu người dùng thời gian thực. Trong quá trình huấn luyện mô hình, nhà nghiên cứu thường sử dụng tập dữ liệu được tiền xử lý và sạch. Tuy nhiên, khi tích hợp mô hình vào sản xuất, nó sẽ được tích hợp vào các pipeline dữ liệu hiện có. Càng phức tạp yêu cầu dữ liệu đầu vào của mô hình, hoặc càng nhiều mô hình được sử dụng, các pipeline xử lý dữ liệu càng cần phức tạp. Việc điều chỉnh mô hình và pipeline dữ liệu hiện có thường yêu cầu cộng tác giữa các bên liên quan hoặc nhóm khác nhau chịu trách nhiệm cho các phần khác nhau của hệ thống ML và/hoặc giai đoạn chu trình ML. Tất cả các yếu tố này tác động trực tiếp đến việc tăng chi phí bảo trì, vận hành, hỗ trợ và cơ sở hạ tầng.

Cơ hội. Phương pháp MTL được trình bày bởi nhóm từ Pinterest, nơi các tác giả đã huấn luyện một tập hợp nhúng hình ảnh đa năng cho ba mô hình khác nhau, điều này đã đơn giản hóa pipeline triển khai của họ và cải thiện hiệu suất trên các nhiệm vụ riêng lẻ (Zhai et al., 2019). Lợi ích chính là việc sử dụng MTL có thể giảm số lượng tham số cần thiết để hỗ trợ các mô hình khác nhau yêu cầu để giải quyết vấn đề. Điều này dẫn đến các mô hình đặc thù nhiệm vụ nhỏ hơn và ít mã hơn để điều chỉnh cho môi trường sản xuất, giảm overhead của các thay đổi tiềm năng trong pipeline dữ liệu hiện có. Tái sử dụng dữ liệu, mã và mô hình có thể tiết kiệm thời gian và đơn giản hóa quá trình triển khai mô hình. Tiếp theo, thiết kế mô-đun của kiến trúc MTL làm cho nó dễ làm việc hơn bằng cách cho phép tái sử dụng mã. Ví dụ, kiến trúc bộ mã hóa chia sẻ hoàn toàn (được mô tả trong Phần 3.2.1) tái sử dụng bộ mã hóa giữa nhiều đầu đặc thù nhiệm vụ. Hơn nữa, đông lạnh bộ mã hóa chia sẻ sẽ cho phép làm việc trên các nhiệm vụ riêng biệt độc lập và đồng thời, làm cho cộng tác đa nhóm dễ dàng và hiệu quả hơn. Ý tưởng này được sử dụng trong mô hình MTL HydraNet bởi nhóm Tesla AI (Karpathy, 2021). Tuy nhiên, đông lạnh bộ mã hóa và chỉ cập nhật các đầu đặc thù nhiệm vụ có thể giảm hiệu suất. Ngoài ra, khái niệm đằng sau AdapterHub (được mô tả trong Phần 3.2.2) được thiết kế để cho phép người dùng chọn từ một tập hợp mô-đun adapter, kết hợp chúng theo cách họ ưa thích, và chèn hoặc thay thế chúng động vào các mô hình được huấn luyện trước tiên tiến. Để kết luận, bản chất mô-đun của kiến trúc MTL có tác động tích cực đến việc làm cho việc kết hợp các kiến trúc này vào phần mềm ML dễ dàng hơn, làm cho nó đơn giản hơn để phát triển, cộng tác, cấu hình và tích hợp vào quy trình triển khai.

4.4 CẬP NHẬT MÔ HÌNH THÔNG QUA NHIỀU GIAI ĐOẠN CHU TRÌNH ML

Thường cần thiết phải cập nhật mô hình ML thường xuyên sau khi nó đã được triển khai và đang chạy trong sản xuất, để giữ cho nó phù hợp với những thay đổi gần đây nhất trong dữ liệu và môi trường. Nhu cầu cập nhật mô hình là một trong những yêu cầu quan trọng nhất của hệ thống sản xuất ML (Pacheco et al., 2018; Abdelkader, 2020; Lakshmanan et al., 2020; Paleyes et al., 2022; Huyen, 2022; Wu & Xie, 2022; Nahar et al., 2022). Trong phần này, chúng tôi thảo luận về các thách thức của việc cập nhật mô hình và cách các phương pháp MTL có thể giảm thiểu những thách thức này. Thách thức của các giai đoạn khác nhau của chu trình ML có thể kích hoạt nhu cầu cập nhật mô hình. Đầu tiên, chúng tôi xác định những lần xuất hiện này và thảo luận về các hành động mà chúng kích hoạt. Sau đó, chúng tôi thảo luận về cách các phương pháp MTL có thể giảm thiểu những thách thức này và chỉ ra những hạn chế hiện tại của các phương pháp này.

Thách thức Cập nhật Mô hình. Thay đổi phân phối là một trong những lý do phổ biến cho nhu cầu cập nhật mô hình. Thay đổi phân phối đề cập đến những thay đổi quan sát được trong phân phối chung của các biến đầu vào và đầu ra của mô hình ML (Ditzler et al., 2015). Hai vấn đề phải được giải quyết để giải quyết hiệu quả thay đổi phân phối. Thứ nhất, trong giai đoạn giám sát, phải có cơ chế để phát hiện thay đổi trong phân phối hoặc sụt giảm trong các chỉ số hiệu suất chính, sẽ báo hiệu nhu cầu cập nhật mô hình ML. Thứ hai, trong giai đoạn phát triển mô hình, phải có cách để học liên tục và cập nhật mô hình để đáp ứng với tín hiệu từ giai đoạn giám sát.

Yêu cầu kinh doanh mới thường phát sinh, yêu cầu mô hình có khả năng mới ngoài những khả năng hiện có. Ví dụ, mô hình nhận dạng thực thể có tên được huấn luyện cho 10 nhãn thực thể trong bài báo tin tức có thể yêu cầu 5 nhãn mới sau 3 tháng sử dụng. Yêu cầu mới được giới thiệu trong giai đoạn phân tích kinh doanh, cũng kích hoạt nhu cầu cập nhật mô hình ML. Không giống như yêu cầu ban đầu trong giai đoạn xác định phạm vi dự án, việc thêm yêu cầu mới nên có thể thực hiện được mà không cần huấn luyện lại toàn bộ mô hình.

Huấn luyện lại định kỳ hoặc theo lịch trình và học liên tục là những phương pháp phổ biến nhất để thích ứng mô hình với dữ liệu và yêu cầu mới. Huấn luyện lại định kỳ đề cập đến quá trình huấn luyện lại mô hình ở khoảng thời gian được xác định trước, bất kể có thay đổi nào trong dữ liệu hoặc môi trường hay không. Tần suất cập nhật được xác định trước và thường dựa trên lượng dữ liệu và mức hiệu suất mô hình mong muốn. Việc tạo ra sự cân bằng giữa cập nhật mô hình thường xuyên để duy trì hiệu suất tốt và tránh cập nhật mô hình quá mức để giảm thiểu chi phí tính toán là rất quan trọng. Quan trọng là lưu ý rằng các mô hình khác nhau có thể yêu cầu lịch trình huấn luyện lại khác nhau, làm cho nó trở thành vấn đề phụ thuộc vào tình huống. Tìm lịch trình huấn luyện lại tối ưu yêu cầu xem xét cẩn thận các yêu cầu và hoàn cảnh cụ thể của từng hệ thống ML. Mặt khác, học liên tục đề cập đến khả năng của mô hình ML thích ứng với thay đổi trong dữ liệu và môi trường theo thời gian. Phương pháp này liên quan đến việc giám sát liên tục hiệu suất của mô hình và cập nhật nó khi cần thiết để đảm bảo nó vẫn chính xác và cập nhật. Tần suất cập nhật mô hình trong học liên tục được xác định động dựa trên thay đổi quan sát trong dữ liệu và môi trường.

Cơ hội Cập nhật Mô hình. Theo Huyen (2022), chúng tôi phân biệt hai loại cập nhật mô hình: lặp dữ liệu và lặp mô hình. Lặp dữ liệu đề cập đến việc cập nhật mô hình với dữ liệu mới trong khi giữ nguyên kiến trúc mô hình và đặc trưng, trong khi lặp mô hình đề cập đến việc thêm đặc trưng mới vào kiến trúc mô hình hiện có hoặc thay đổi kiến trúc mô hình. Để thảo luận về thách thức và cơ hội của các phương pháp MTL cho việc cập nhật mô hình, chúng tôi xem xét hai tình huống. Thứ nhất, huấn luyện lại định kỳ được thực hiện mỗi 6 hoặc 12 tháng, với mục tiêu huấn luyện mỗi mô hình để hoạt động tối ưu bằng cách sử dụng tất cả dữ liệu có sẵn. Do chi phí kinh tế cao, chúng tôi giả định điều này không thể thực hiện thường xuyên hơn. Thứ hai, giữa các lần huấn luyện lại định kỳ, có thể có tình huống nơi lặp dữ liệu cần thiết do thay đổi phân phối, hoặc lặp mô hình yêu cầu để mở rộng khả năng mô hình để đáp ứng với yêu cầu kinh doanh mới.

Chúng tôi tin rằng việc kết hợp các phương pháp MTL vào tình huống cập nhật sẽ thực tế, ngoài các lợi ích được thảo luận trong Phần 4.1-4.3. MTL đặc biệt phù hợp cho các tình huống huấn luyện lại định kỳ nơi mục tiêu là có được một mô hình hiệu suất tốt nhất duy nhất trên tất cả nhiệm vụ sử dụng tất cả dữ liệu có sẵn, thay vì huấn luyện các mô hình riêng lẻ cho mỗi nhiệm vụ. Tuy nhiên, thách thức nằm ở cách các phương pháp MTL có thể quản lý tình huống thứ hai nơi mô hình MTL phải học các nhiệm vụ hoặc lĩnh vực mới một cách tuần tự theo thời gian. Kết quả là, cùng một mô hình phải có khả năng học trong cả cài đặt MTL và CL khi cần thiết, và chúng tôi gọi cài đặt này là MTL Liên tục (CMTL).

MTL Liên tục. Cả mô hình MTL và CL đều học nhiều nhiệm vụ, tuy nhiên, MTL học chúng đồng thời, trong khi CL học chúng tăng dần. Như đã đề cập trong Phần 2.3, các tác giả của Sun et al. (2020) đã kết hợp CL và MTL để cải thiện thêm việc huấn luyện trước. Mặc dù phương pháp này tăng cường hiệu suất trên các nhiệm vụ cụ thể, nó không giải quyết tình huống thực tế trong đó mô hình MTL nên được cập nhật để hỗ trợ các nhiệm vụ cụ thể mới hoặc xử lý thay đổi phân phối. Hơn nữa, tổng số nhiệm vụ tuần tự phải được biết trước để thuật toán xác định lịch trình huấn luyện hiệu quả. Chúng tôi tin rằng sự tương đồng giữa kiến trúc MTL và CL có thể cho phép xây dựng mô hình CMTL. Ví dụ, hầu hết kiến trúc MTL trong Phần 3.2 là kiến trúc MTL dựa trên transformer với đầu đặc thù nhiệm vụ, tương tự như kiến trúc cô lập tham số cho cài đặt TIL trong CL (Phần 2.3). Trong TIL, định danh nhiệm vụ có sẵn trong cả huấn luyện và thử nghiệm và được sử dụng để xác định tham số đặc thù nhiệm vụ trong kiến trúc đa đầu, tương tự như kiến trúc MTL (Ke & Liu, 2022). Sự tương đồng này có thể thấy trong việc sử dụng kiến trúc adapter (Phần 3.2.2) trong cả MTL (Stickland & Murray, 2019; Pfeiffer et al., 2020c; He et al., 2021) và CL (Ke et al., 2021a;b), cũng như trong việc sử dụng siêu mạng (Phần 3.2.3) trong cả MTL (Pilault et al., 2020; Mahabadi et al., 2021) và CL (Von Oswald et al., 2019; Jin et al., 2021).

10

--- TRANG 8 ---
Bản thảo.
Hình 3: (A). Adapter-BERT (Houlsby et al., 2019) sử dụng adapter trong lớp transformer (Vaswani et al., 2017). Adapter là mạng 2 lớp với kết nối bỏ qua, được thêm hai lần mỗi lớp. Chỉ adapter (màu vàng) và chuẩn hóa lớp (màu xanh lá cây) có thể huấn luyện trong khi các mô-đun khác (màu xám) bị đông lạnh. (B). B-CL thay thế adapter bằng CLA, chứa mô-đun chia sẻ kiến thức (KSM) và mô-đun đặc thù nhiệm vụ (TSM), cả hai đều có kết nối bỏ qua. Hình và chú thích được sửa đổi lấy từ (Ke et al., 2021b).

Ví dụ, nếu chúng ta xem xét lớp BERT trong Hình 3, chúng ta có thể quan sát rằng các lớp adapter cho phương pháp MTL trong Hình 3(A) ở cùng vị trí với adapter CL trong Hình 3(B) (Ke et al., 2021b). Để chuyển từ MTL sang CL chúng ta chỉ cần thay đổi adapter. Chúng tôi tin rằng sự tương đồng này có thể là hướng nghiên cứu đầy hứa hẹn cho việc phát triển thêm mô hình CMTL, nhưng đánh giá phù hợp sẽ không thể thực hiện được mà không có điểm chuẩn tốt.

Cuối cùng, chúng tôi tin rằng điểm chuẩn đại diện chính xác cho thách thức của hệ thống thực tế có thể có lợi cho cả nhà nghiên cứu và nhà thực hành để đánh giá mô hình CMTL hiệu quả. Để thực hiện điều này, chúng tôi đề xuất kết hợp và sắp xếp thời gian tạm thời các nhiệm vụ để mô phỏng các tình huống huấn luyện lại định kỳ và CL. Điểm chuẩn có thể được tinh chỉnh thêm để phản ánh tần suất thay đổi của huấn luyện lại định kỳ, cũng như tần suất của các nhiệm vụ đến và thay đổi phân phối giữa các giai đoạn huấn luyện lại. Sự thay đổi trong các tình huống này có thể đại diện tốt hơn cho các tình huống thực tế, nơi mô hình CMTL đơn giản hơn có thể đủ trong một số trường hợp, trong khi các mô hình CMTL tiên tiến hơn sẽ cần thiết để xử lý thay đổi môi trường trong các tình huống khác.

5 KẾT LUẬN

Trong bài báo này, chúng tôi đã xem xét các phương pháp MTL dựa trên transformer trong NLP và khám phá các thách thức và cơ hội của những phương pháp đó trong bối cảnh chu trình ML. Chúng tôi đã thảo luận về cách MTL có thể là giải pháp khả thi giải quyết một số thách thức chính trong các giai đoạn kỹ thuật dữ liệu, phát triển mô hình, triển khai và giám sát của chu trình ML, so với việc sử dụng nhiều mô hình đơn nhiệm vụ.

Chúng tôi cũng đã thảo luận về các cơ hội áp dụng MTL để giảm thiểu thách thức liên quan đến cập nhật mô hình do thay đổi phân phối hoặc yêu cầu thực tế phát triển, nơi khả năng học nhiều nhiệm vụ đồng thời có thể được tận dụng để cập nhật mô hình định kỳ để đáp ứng với thay đổi trong dữ liệu và môi trường. Tuy nhiên, chúng tôi cũng thừa nhận những hạn chế của các phương pháp MTL hiện tại trong việc xử lý cập nhật tuần tự, nơi CL được yêu cầu. Để giải quyết điều này, chúng tôi đề xuất khái niệm CMTL, nhằm kết hợp lợi ích của MTL và CL trong một mô hình duy nhất. Chúng tôi thúc đẩy việc tạo ra điểm chuẩn để đánh giá phù hợp các mô hình CMTL, một điểm chuẩn đại diện tốt hơn cho thách thức của hệ thống sản xuất có thể hướng dẫn việc phát triển các mô hình đó.

Kết luận, các phương pháp MTL cung cấp nhiều cơ hội để cải thiện hiệu quả và hiệu suất của hệ thống ML trong các giai đoạn khác nhau của chu trình ML điển hình. Chúng tôi tin rằng MTL sẽ trở thành một phần quan trọng trong hộp công cụ của các nhà thực hành tìm cách giải quyết các thách thức trong hệ thống ML của họ như được nêu bật trong khảo sát này.

TÀI LIỆU THAM KHẢO

Hala Abdelkader. Towards robust production machine learning systems: Managing dataset shift. In 2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 1164–1166. IEEE, 2020.

11

--- TRANG 9 ---
Bản thảo.
Stanley Ebhohimhen Abhadiomhen, Royransom Chimela Nzeh, Ernest Domanaanmwi Ganaa, Honour Chika Nwagwu, George Emeka Okereke, và Sidheswar Routray. Supervised shallow multi-task learning: analysis of methods. Neural Processing Letters, 54(3):2491–2508, 2022.

Armen Aghajanyan, Anchit Gupta, Akshat Shrivastava, Xilun Chen, Luke Zettlemoyer, và Sonal Gupta. Muppet: Massive multi-task representations with pre-finetuning. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 5799–5811, 2021.

Vamsi Aribandi, Yi Tay, Tal Schuster, Jinfeng Rao, Huaixiu Steven Zheng, Sanket Vaibhav Mehta, Honglei Zhuang, Vinh Q Tran, Dara Bahri, Jianmo Ni, et al. Ext5: Towards extreme multi-task scaling for transfer learning. In International Conference on Learning Representations, 2021.

Rob Ashmore, Radu Calinescu, và Colin Paterson. Assuring the machine learning lifecycle: Desiderata, methods, and challenges. ACM Computing Surveys (CSUR), 54(5):1–39, 2021.

Hangbo Bao, Li Dong, Furu Wei, Wenhui Wang, Nan Yang, Xiaodong Liu, Yu Wang, Jianfeng Gao, Songhao Piao, Ming Zhou, và Hsiao-Wuen Hon. UniLMv2: Pseudo-masked language models for unified language model pre-training. In Hal Daumé III và Aarti Singh (eds.), Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 642–652. PMLR, 13–18 Jul 2020. URL https://proceedings.mlr.press/v119/bao20a.html.

Lucas Bernardi, Themistoklis Mavridis, và Pablo Estevez. 150 successful machine learning models: 6 lessons learned at booking. com. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining, pp. 1743–1751, 2019.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. Language models are few-shot learners. CoRR, abs/2005.14165, 2020. URL https://arxiv.org/abs/2005.14165.

Rich Caruana. Multitask learning. Machine learning, 28(1):41–75, 1997.

Shijie Chen, Yu Zhang, và Qiang Yang. Multi-task learning in natural language processing: An overview. arXiv preprint arXiv:2109.09138, 2021.

Zhiyuan Chen và Bing Liu. Lifelong machine learning. Synthesis Lectures on Artificial Intelligence and Machine Learning, 12(3):1–207, 2018.

Michael Chui, Bryce Hall, Helen Mayhew, và Alex Singla. The state of ai in 2022–and a half decade in review, Dec 2022. URL https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-in-2022-and-a-half-decade-in-review. Accessed: 2023-01-15.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022.

Christopher Clark, Mark Yatskar, và Luke Zettlemoyer. Don't take the easy way out: Ensemble based methods for avoiding known dataset biases. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 4069–4082, Hong Kong, China, November 2019a. Association for Computational Linguistics. doi: 10.18653/v1/D19-1418. URL https://aclanthology.org/D19-1418.

Kevin Clark, Minh-Thang Luong, Urvashi Khandelwal, Christopher D. Manning, và Quoc V. Le. Bam! born-again multi-task networks for natural language understanding. CoRR, abs/1907.04829, 2019b. URL http://arxiv.org/abs/1907.04829.

Michael Crawshaw. Multi-task learning with deep neural networks: A survey. arXiv preprint arXiv:2009.09796, 2020.

Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Aleš Leonardis, Gregory Slabaugh, và Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEE transactions on pattern analysis and machine intelligence, 44(7):3366–3385, 2021.

12

--- TRANG 10 ---
Bản thảo.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 4171–4186, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https://aclanthology.org/N19-1423.

Jie Ding, Vahid Tarokh, và Yuhong Yang. Model selection techniques: An overview. IEEE Signal Processing Magazine, 35(6):16–34, 2018.

Gregory Ditzler, Manuel Roveri, Cesare Alippi, và Robi Polikar. Learning in nonstationary environments: A survey. IEEE Computational Intelligence Magazine, 10(4):12–25, 2015.

Ana González-Garduño và Anders Søgaard. Learning to predict readability using eye-movement data from natives and learners. Proceedings of the AAAI Conference on Artificial Intelligence, 32(1), Apr. 2018. doi: 10.1609/aaai.v32i1.11978. URL https://ojs.aaai.org/index.php/AAAI/article/view/11978.

Han Guo, Ramakanth Pasunuru, và Mohit Bansal. Autosem: Automatic task selection and mixing in multi-task learning. CoRR, abs/1904.04153, 2019. URL http://arxiv.org/abs/1904.04153.

Michelle Guo, Albert Haque, De-An Huang, Serena Yeung, và Li Fei-Fei. Dynamic task prioritization for multitask learning. In Proceedings of the European Conference on Computer Vision (ECCV), September 2018.

Manish Gupta và Puneet Agrawal. Compression of deep learning models for text: A survey. ACM Transactions on Knowledge Discovery from Data (TKDD), 16(4):1–55, 2022.

David Ha, Andrew Dai, và Quoc V. Le. Hypernetworks, 2016. URL https://arxiv.org/abs/1609.09106.

Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tao Xu, Shulin Yang, Huizhong Duan, Qing Zhang, Nick Barrow-Williams, Bradley C Turnbull, Brendan M Collins, et al. Applying deep learning to airbnb search. In proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & Data Mining, pp. 1927–1935, 2019.

Xu Han, Weilin Zhao, Ning Ding, Zhiyuan Liu, và Maosong Sun. PTR: prompt tuning with rules for text classification. CoRR, abs/2105.11259, 2021. URL https://arxiv.org/abs/2105.11259.

Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, và Graham Neubig. Towards a unified view of parameter-efficient transfer learning. arXiv preprint arXiv:2110.04366, 2021.

Yun He, Steven Zheng, Yi Tay, Jai Gupta, Yu Du, Vamsi Aribandi, Zhe Zhao, Yaguang Li, Zhao Chen, Donald Metzler, Heng-Tze Cheng, và Ed H. Chi. HyperPrompt: Prompt-based task-conditioning of transformers. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, và Sivan Sabato (eds.), Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pp. 8678–8690. PMLR, 17–23 Jul 2022. URL https://proceedings.mlr.press/v162/he22f.html.

Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, và Sylvain Gelly. Parameter-efficient transfer learning for nlp. In International Conference on Machine Learning, pp. 2790–2799. PMLR, 2019.

Yen-Chang Hsu, Yen-Cheng Liu, Anita Ramasamy, và Zsolt Kira. Re-evaluating continual learning scenarios: A categorization and case for strong baselines. arXiv preprint arXiv:1810.12488, 2018.

Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, và Weizhu Chen. Lora: Low-rank adaptation of large language models, 2021. URL https://arxiv.org/abs/2106.09685.

Chip Huyen. Designing Machine Learning Systems. " O'Reilly Media, Inc.", 2022.

Sébastien Jean, Orhan Firat, và Melvin Johnson. Adaptive scheduling for multi-task learning. CoRR, abs/1909.06434, 2019. URL http://arxiv.org/abs/1909.06434.

Xisen Jin, Bill Yuchen Lin, Mohammad Rostami, và Xiang Ren. Learn continually, generalize rapidly: lifelong knowledge accumulation for few-shot learning. arXiv preprint arXiv:2104.08808, 2021.

Lukasz Kaiser, Aidan N. Gomez, Noam Shazeer, Ashish Vaswani, Niki Parmar, Llion Jones, và Jakob Uszkoreit. One model to learn them all, 2017. URL https://arxiv.org/abs/1706.05137.

13

--- TRANG 11 ---
Bản thảo.
Andrej Karpathy. HydraNets - Tesla AI Day 2021, 8 2021. URL https://www.youtube.com/watch?t=4284&v=j0z4FweCy4M&feature=youtu.be. Accessed: 2023-02-15.

Zixuan Ke và Bing Liu. Continual learning of natural language processing tasks: A survey. arXiv preprint arXiv:2211.12701, 2022.

Zixuan Ke, Bing Liu, Nianzu Ma, Hu Xu, và Lei Shu. Achieving forgetting prevention and knowledge transfer in continual learning. Advances in Neural Information Processing Systems, 34:22443–22456, 2021a.

Zixuan Ke, Hu Xu, và Bing Liu. Adapting bert for continual learning of a sequence of aspect sentiment classification tasks. arXiv preprint arXiv:2112.03271, 2021b.

Alex Kendall, Yarin Gal, và Roberto Cipolla. Multi-task learning using uncertainty to weigh losses for scene geometry and semantics. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018.

Been Kim và Finale Doshi-Velez. Machine learning techniques for accountability. AI Magazine, 42(1):47–52, 2021.

Frederic Kirstein, Jan Philip Wahle, Terry Ruas, và Bela Gipp. Analyzing multi-task learning for abstractive text summarization. arXiv preprint arXiv:2210.14606, 2022.

Valliappa Lakshmanan, Sara Robinson, và Michael Munn. Machine learning design patterns. O'Reilly Media, 2020.

Hae Beom Lee, Eunho Yang, và Sung Ju Hwang. Deep asymmetric multi-task feature learning. In Jennifer Dy và Andreas Krause (eds.), Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp. 2956–2964. PMLR, 10–15 Jul 2018. URL https://proceedings.mlr.press/v80/lee18d.html.

Brian Lester, Rami Al-Rfou, và Noah Constant. The power of scale for parameter-efficient prompt tuning. CoRR, abs/2104.08691, 2021. URL https://arxiv.org/abs/2104.08691.

Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, và Luke Zettlemoyer. BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 7871–7880, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.703. URL https://aclanthology.org/2020.acl-main.703.

Xiang Lisa Li và Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation. arXiv preprint arXiv:2101.00190, 2021.

Xi Lin, Hui-Ling Zhen, Zhenhua Li, Qing-Fu Zhang, và Sam Kwong. Pareto multi-task learning. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, và R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/file/685bfde03eb646c27ed565881917c71c-Paper.pdf.

Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, và Graham Neubig. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. CoRR, abs/2107.13586, 2021a. URL https://arxiv.org/abs/2107.13586.

Shengchao Liu, Yingyu Liang, và Anthony Gitter. Loss-balanced task weighting to reduce negative transfer in multi-task learning. Proceedings of the AAAI Conference on Artificial Intelligence, 33(01):9977–9978, Jul. 2019a. doi: 10.1609/aaai.v33i01.33019977. URL https://ojs.aaai.org/index.php/AAAI/article/view/5125.

Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, và Jie Tang. GPT understands, too. CoRR, abs/2103.10385, 2021b. URL https://arxiv.org/abs/2103.10385.

Xiaodong Liu, Pengcheng He, Weizhu Chen, và Jianfeng Gao. Multi-task deep neural networks for natural language understanding, 2019b. URL https://arxiv.org/abs/1901.11504.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. Roberta: A robustly optimized BERT pretraining approach. CoRR, abs/1907.11692, 2019c. URL http://arxiv.org/abs/1907.11692.

14

--- TRANG 12 ---
Bản thảo.
Mingsheng Long, ZHANGJIE CAO, Jianmin Wang, và Philip S Yu. Learning multiple tasks with multilinear relationship networks. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, và R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/file/03e0704b5690a2dee1861dc3ad3316c9-Paper.pdf.

David Lopez-Paz và Marc' Aurelio Ranzato. Gradient episodic memory for continual learning. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, và R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/file/f87522788a2be2d171666752f97ddebb-Paper.pdf.

Rabeeh Karimi Mahabadi, Sebastian Ruder, Mostafa Dehghani, và James Henderson. Parameter-efficient multi-task fine-tuning for transformers via shared hypernetworks, 2021. URL https://arxiv.org/abs/2106.04489.

Gary E Marchant. The growing gap between emerging technologies and the law. Springer, 2011.

Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, và Richard Socher. The natural language decathlon: Multi-task learning as question answering. arXiv preprint arXiv:1806.08730, 2018.

Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, và Aram Galstyan. A survey on bias and fairness in machine learning. ACM Computing Surveys (CSUR), 54(6):1–35, 2021.

Nadia Nahar, Shurui Zhou, Grace Lewis, và Christian Kästner. Collaboration challenges in building ml-enabled systems: Communication, documentation, engineering, and process. In Proceedings of the 44th International Conference on Software Engineering, pp. 413–425, 2022.

Fannia Pacheco, Ernesto Exposito, Mathieu Gineste, Cedric Baudoin, và Jose Aguilar. Towards the deployment of machine learning solutions in network traffic classification: A systematic survey. IEEE Communications Surveys & Tutorials, 21(2):1988–2014, 2018.

Andrei Paleyes, Raoul-Gabriel Urma, và Neil D Lawrence. Challenges in deploying machine learning: a survey of case studies. ACM Computing Surveys, 55(6):1–29, 2022.

Mihir Parmar, Swaroop Mishra, Mirali Purohit, Man Luo, Murad Mohammad, và Chitta Baral. In-BoXBART: Get instructions into biomedical multi-task learning. In Findings of the Association for Computational Linguistics: NAACL 2022, pp. 112–128, Seattle, United States, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.findings-naacl.10. URL https://aclanthology.org/2022.findings-naacl.10.

Lucas Pascal, Pietro Michiardi, Xavier Bost, Benoit Huet, và Maria A. Zuluaga. Maximum roaming multi-task learning. Proceedings of the AAAI Conference on Artificial Intelligence, 35(10):9331–9341, May 2021. doi: 10.1609/aaai.v35i10.17125. URL https://ojs.aaai.org/index.php/AAAI/article/view/17125.

Zhongyi Pei, Lin Liu, Chen Wang, và Jianmin Wang. Requirements engineering for machine learning: A review and reflection. In 2022 IEEE 30th International Requirements Engineering Conference Workshops (REW), pp. 166–175. IEEE, 2022.

Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, và Alexander Miller. Language models as knowledge bases? In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 2463–2473, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1250. URL https://aclanthology.org/D19-1250.

Jonas Pfeiffer, Aishwarya Kamath, Andreas Rückle, Kyunghyun Cho, và Iryna Gurevych. Adapterfusion: Non-destructive task composition for transfer learning. arXiv preprint arXiv:2005.00247, 2020a.

Jonas Pfeiffer, Andreas Rückle, Clifton Poth, Aishwarya Kamath, Ivan Vulić, Sebastian Ruder, Kyunghyun Cho, và Iryna Gurevych. Adapterhub: A framework for adapting transformers. arXiv preprint arXiv:2007.07779, 2020b.

Jonas Pfeiffer, Ivan Vulic, Iryna Gurevych, và Sebastian Ruder. MAD-X: an adapter-based framework for multi-task cross-lingual transfer. CoRR, abs/2005.00052, 2020c. URL https://arxiv.org/abs/2005.00052.

Jonathan Pilault, Amine Elhattami, và Christopher Pal. Conditionally adaptive multi-task learning: Improving transfer learning in nlp using fewer parameters & less data, 2020. URL https://arxiv.org/abs/2009.09139.

15

--- TRANG 13 ---
Bản thảo.
Eugenia Politou, Efthimios Alepis, và Constantinos Patsakis. Forgetting personal data and revoking consent under the gdpr: Challenges and proposed solutions. Journal of cybersecurity, 4(1):tyy001, 2018.

Neoklis Polyzotis, Sudip Roy, Steven Euijong Whang, và Martin Zinkevich. Data lifecycle challenges in production machine learning: a survey. ACM SIGMOD Record, 47(2):17–28, 2018.

Subhojeet Pramanik, Priyanka Agrawal, và Aman Hussain. Omninet: A unified architecture for multi-modal multi-task learning. CoRR, abs/1907.07804, 2019. URL http://arxiv.org/abs/1907.07804.

Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, et al. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 21(140):1–67, 2020.

Sylvestre-Alvise Rebuffi, Hakan Bilen, và Andrea Vedaldi. Learning multiple visual domains with residual adapters. Advances in neural information processing systems, 30, 2017.

Kui Ren, Tianhang Zheng, Zhan Qin, và Xue Liu. Adversarial attacks and defenses in deep learning. Engineering, 6(3):346–360, 2020.

Cedric Renggli, Bojan Karlaš, Bolin Ding, Feng Liu, Kevin Schawinski, Wentao Wu, và Ce Zhang. Continuous integration of machine learning models with ease. ml/ci: Towards a rigorous yet practical treatment. Proceedings of Machine Learning and Systems, 1:322–333, 2019.

Ishai Rosenberg, Asaf Shabtai, Yuval Elovici, và Lior Rokach. Adversarial machine learning attacks and defense methods in the cyber security domain. ACM Computing Surveys (CSUR), 54(5):1–36, 2021.

Sebastian Ruder. An overview of multi-task learning in deep neural networks. arXiv preprint arXiv:1706.05098, 2017.

Sebastian Ruder, Joachim Bingel, Isabelle Augenstein, và Anders Søgaard. Sluice networks: Learning what to share between loosely related tasks. arXiv preprint arXiv:1705.08142, 2, 2017.

Rahul Manohar Samant, Mrinal Bachute, Shilpa Gite, và Ketan Kotecha. Framework for deep learning-based language models using multi-task learning in natural language understanding: A systematic literature review and future directions. IEEE Access, 2022.

Nithya Sambasivan, Shivani Kapania, Hannah Highfill, Diana Akrong, Praveen Paritosh, và Lora M Aroyo. "everyone wants to do the model work, not the data work": Data cascades in high-stakes ai. In proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, pp. 1–15, 2021.

Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Tali Bers, Stella Biderman, Leo Gao, Thomas Wolf, và Alexander M. Rush. Multitask prompted training enables zero-shot task generalization, 2021. URL https://arxiv.org/abs/2110.08207.

Tim Schröder và Michael Schulz. Monitoring machine learning models: a categorization of challenges and methods. Data Science and Management, 5(3):105–116, 2022.

David Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, Michael Young, Jean-Francois Crespo, và Dan Dennison. Hidden technical debt in machine learning systems. Advances in neural information processing systems, 28, 2015.

Joan Serra, Didac Suris, Marius Miron, và Alexandros Karatzoglou. Overcoming catastrophic forgetting with hard attention to the task. In Jennifer Dy và Andreas Krause (eds.), Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp. 4548–4557. PMLR, 10–15 Jul 2018. URL https://proceedings.mlr.press/v80/serra18a.html.

Or Sharir, Barak Peleg, và Yoav Shoham. The cost of training nlp models: A concise overview. arXiv preprint arXiv:2004.08900, 2020.

16

--- TRANG 14 ---
Bản thảo.
Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace, và Sameer Singh. AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 4222–4235, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.346. URL https://aclanthology.org/2020.emnlp-main.346.

Ayan Sinha, Zhao Chen, Vijay Badrinarayanan, và Andrew Rabinovich. Gradient adversarial training of neural networks. CoRR, abs/1806.08028, 2018. URL http://arxiv.org/abs/1806.08028.

Trevor Standley, Amir Zamir, Dawn Chen, Leonidas Guibas, Jitendra Malik, và Silvio Savarese. Which tasks should be learned together in multi-task learning? In Hal Daumé III và Aarti Singh (eds.), Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 9120–9132. PMLR, 13–18 Jul 2020. URL https://proceedings.mlr.press/v119/standley20a.html.

Asa Cooper Stickland và Iain Murray. Bert and pals: Projected attention layers for efficient adaptation in multi-task learning. In International Conference on Machine Learning, pp. 5986–5995. PMLR, 2019.

Emma Strubell, Ananya Ganesh, và Andrew McCallum. Energy and policy considerations for modern deep learning research. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pp. 13693–13696, 2020.

Ruo-Yu Sun. Optimization for deep learning: An overview. Journal of the Operations Research Society of China, 8(2):249–294, 2020.

Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Hao Tian, Hua Wu, và Haifeng Wang. Ernie 2.0: A continual pre-training framework for language understanding. In Proceedings of the AAAI conference on artificial intelligence, volume 34, pp. 8968–8975, 2020.

Hironori Takeuchi và Shuichiro Yamamoto. Business analysis method for constructing business–ai alignment model. Procedia Computer Science, 176:1312–1321, 2020.

Yi Tay, Zhe Zhao, Dara Bahri, Donald Metzler, và Da-Cheng Juan. Hypergrid: Efficient multi-task transformers with grid-wise decomposable hyper projections. CoRR, abs/2007.05891, 2020. URL https://arxiv.org/abs/2007.05891.

Kim-Han Thung và Chong-Yaw Wee. A brief review on multi-task learning. Multimedia Tools and Applications, 77(22):29705–29725, 2018.

Richa Upadhyay, Ronald Phlypo, Rajkumar Saini, và Marcus Liwicki. Sharing to learn and learning to share-fitting together meta-learning, multi-task learning, and transfer learning: A meta review. arXiv preprint arXiv:2111.12146, 2021.

Partoo Vafaeikia, Khashayar Namdar, và Farzad Khalvati. A brief review of deep multi-task learning and auxiliary task learning. arXiv preprint arXiv:2007.01126, 2020.

Simon Vandenhende, Stamatios Georgoulis, Wouter Van Gansbeke, Marc Proesmans, Dengxin Dai, và Luc Van Gool. Multi-task learning for dense prediction tasks: A survey. IEEE transactions on pattern analysis and machine intelligence, 2021.

Manasi Vartak và Samuel Madden. Modeldb: Opportunities and challenges in managing machine learning models. IEEE Data Eng. Bull., 41(4):16–25, 2018.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.

Johannes Von Oswald, Christian Henning, João Sacramento, và Benjamin F Grewe. Continual learning with hypernetworks. arXiv preprint arXiv:1906.00695, 2019.

Tu Vu, Tong Wang, Tsendsuren Munkhdalai, Alessandro Sordoni, Adam Trischler, Andrew Mattarella-Micke, Subhransu Maji, và Mohit Iyyer. Exploring and predicting transferability across NLP tasks. CoRR, abs/2005.00770, 2020. URL https://arxiv.org/abs/2005.00770.

Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, và Samuel R Bowman. Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv preprint arXiv:1804.07461, 2018.

17

--- TRANG 15 ---
Bản thảo.
Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, và Samuel Bowman. Superglue: A stickier benchmark for general-purpose language understanding systems. Advances in neural information processing systems, 32, 2019.

Liwen Wang, Rumei Li, Yang Yan, Yuanmeng Yan, Sirui Wang, Wei Wu, và Weiran Xu. Instructionner: A multi-task instruction-based generative framework for few-shot ner, 2022. URL https://arxiv.org/abs/2203.03903.

Sinong Wang, Madian Khabsa, và Hao Ma. To pretrain or not to pretrain: Examining the benefits of pretraining on resource rich tasks. arXiv preprint arXiv:2006.08671, 2020.

Steven Euijong Whang, Yuji Roh, Hwanjun Song, và Jae-Gil Lee. Data collection and quality challenges in deep learning: A data-centric ai perspective. The VLDB Journal, pp. 1–23, 2023.

Joseph Worsham và Jugal Kalita. Multi-task learning for natural language processing in the 2020s: where are we going? Pattern Recognition Letters, 136:120–126, 2020.

Nan Wu và Yuan Xie. A survey of machine learning for computer architecture and systems. ACM Computing Surveys (CSUR), 55(3):1–39, 2022.

Sen Wu, Hongyang R. Zhang, và Christopher Ré. Understanding and improving information transfer in multi-task learning, 2020. URL https://arxiv.org/abs/2005.00944.

Chenyang Yang, Rachel Brower-Sinning, Grace A Lewis, Christian Kästner, và Tongshuang Wu. Capabilities for better ml engineering. arXiv preprint arXiv:2211.06409, 2022.

Yongxin Yang và Timothy M. Hospedales. Trace norm regularised deep multi-task learning. CoRR, abs/1606.04038, 2016. URL http://arxiv.org/abs/1606.04038.

Amir R. Zamir, Alexander Sax, William Shen, Leonidas J. Guibas, Jitendra Malik, và Silvio Savarese. Taskonomy: Disentangling task transfer learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018.

Andrew Zhai, Hao-Yu Wu, Eric Tzeng, Dong Huk Park, và Charles Rosenberg. Learning a unified embedding for visual search at pinterest. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 2412–2420, 2019.

Yu Zhang và Qiang Yang. A survey on multi-task learning. arXiv preprint arXiv:1707.08114, 2017.

Yu Zhang và Qiang Yang. An overview of multi-task learning. National Science Review, 5(1):30–43, 2018.

Zhihan Zhang, Wenhao Yu, Mengxia Yu, Zhichun Guo, và Meng Jiang. A survey of multi-task learning in natural language processing: Regarding task relatedness and training methods. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pp. 943–956, Dubrovnik, Croatia, May 2023. Association for Computational Linguistics. URL https://aclanthology.org/2023.eacl-main.66.

Feng Zheng, Cheng Deng, Xing Sun, Xinyang Jiang, Xiaowei Guo, Zongqiao Yu, Feiyue Huang, và Rongrong Ji. Pyramidal person re-identification via multi-loss dynamic training. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2019.

Wenxuan Zhou. An overview of models and methods for multi-task learning, Oct 2019. URL https://shanzhenren.github.io/csci-699-replnlp-2019fall/lectures/W6-L1-Multi_Task_Learning.pdf.

A CHI TIẾT BỔ SUNG CHO KHẢO SÁT LIÊN QUAN

A.1 KHẢO SÁT HỌC ĐA NHIỆM VỤ

Ý tưởng về MTL đã được khám phá trong nhiều nghiên cứu. Trong phần này, chúng tôi cung cấp tổng quan về công việc liên quan trong các khảo sát MTL và giải quyết các khía cạnh MTL khác nhau đã được thảo luận. Trong Bảng 3, chúng tôi liệt kê một số khía cạnh và chỉ ra khảo sát mà chúng được thảo luận. Trong phần còn lại của phần này, chúng tôi chỉ đề cập đến các khảo sát liên quan và xem xét chi tiết hơn từng khía cạnh MTL (được hiển thị bằng chữ đậm).

18

--- TRANG 16 ---
Bản thảo.
Bảng 3: Các khía cạnh được thảo luận theo khảo sát MTL. Các khía cạnh được chỉ ra bằng chữ đậm.

Năm Khảo sát MTL
2017 1- (Ruder, 2017) 2- (Zhang & Yang, 2017)
2018 3- (Zhang & Yang, 2018) 4- (Thung & Wee, 2018)
2019 5- (Zhou, 2019)
2020 6- (Vafaeikia et al., 2020) 7- (Worsham & Kalita, 2020) 8- (Crawshaw, 2020)
2021 9- (Vandenhende et al., 2021) 10- (Chen et al., 2021) 11- (Upadhyay et al., 2021)
2022 12- (Samant et al., 2022) 13- (Abhadiomhen et al., 2022)
2023 14- (Zhang et al., 2023)

Khía cạnh \Khảo sát 1 2 3 4 5 6 7 8 9 10 11 12 13 14
Mô hình Tính toán
ML Truyền thống ✓ ✓ ✓ ✓ ✓
Học Sâu ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Loại Học
Học Chung ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Học Phụ trợ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Kiến trúc
Phân loại ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Học để Chia sẻ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Mô hình Đa năng ✓ ✓ ✓ ✓ ✓
Tối ưu hóa
Trọng số Mất mát ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Điều chuẩn ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Lập lịch Nhiệm vụ ✓ ✓ ✓ ✓ ✓ ✓
Điều biến Gradient ✓ ✓ ✓ ✓ ✓
Chưng cất Kiến thức ✓ ✓ ✓ ✓
Tối ưu hóa Đa mục tiêu ✓ ✓ ✓
Học Mối quan hệ Nhiệm vụ
Nhóm Nhiệm vụ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Chuyển giao Mối quan hệ ✓ ✓ ✓ ✓ ✓
Nhúng Nhiệm vụ ✓ ✓
Mức độ Giám sát
Học có Giám sát ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Học Bán giám sát ✓ ✓ ✓ ✓ ✓
Học Tự giám sát ✓ ✓ ✓ ✓ ✓ ✓
Kết nối với Mô hình Học
Học Tăng cường ✓ ✓ ✓ ✓ ✓ ✓
Học Chuyển giao ✓ ✓ ✓
Thích ứng Lĩnh vực ✓ ✓ ✓
Meta-Learning ✓ ✓ ✓
Học Chủ động ✓ ✓
Học Trực tuyến ✓ ✓ ✓
Học Liên tục
Điểm chuẩn
Tổng quan Điểm chuẩn ✓ ✓ ✓ ✓ ✓ ✓ ✓
So sánh Mô hình ✓ ✓ ✓ ✓ ✓ ✓ ✓
Lĩnh vực Ứng dụng
Xử lý Ngôn ngữ Tự nhiên ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Thị giác Máy tính ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Chăm sóc Sức khỏe ✓ ✓ ✓
Tin sinh học ✓ ✓ ✓ ✓ ✓
Khác ✓ ✓ ✓ ✓ ✓

Nhiều lĩnh vực ứng dụng đã được nghiên cứu trong công việc trước đây, từ các khảo sát bao gồm nhiều lĩnh vực (Ruder, 2017; Zhang & Yang, 2017; 2018; Thung & Wee, 2018; Vafaeikia et al., 2020; Crawshaw, 2020; Upadhyay et al., 2021; Abhadiomhen et al., 2022), đến những khảo sát dành riêng cho lĩnh vực cụ thể, như thị giác máy tính (Vandenhende et al., 2021) hoặc xử lý ngôn ngữ tự nhiên (Zhou, 2019; Worsham & Kalita, 2020; Chen et al., 2021; Samant et al., 2022; Zhang et al., 2023). Cả mô hình tính toán ML truyền thống và học sâu đều được nghiên cứu. ML truyền thống được thảo luận chủ yếu trong các nghiên cứu cũ hơn, trong khi học sâu được đại diện trong tất cả trừ một nghiên cứu. Hơn nữa,

19

--- TRANG 17 ---
Bản thảo.
hầu hết các công việc trước đây đều cung cấp tổng quan về các điểm chuẩn cho lĩnh vực cụ thể (McCann et al., 2018; Wang et al., 2019), và so sánh các mô hình trên chúng.

Loại học. Hai loại học chủ yếu được thảo luận. Thứ nhất, học chung được sử dụng trong cài đặt MTL nơi tất cả các nhiệm vụ đều quan trọng như nhau (Kendall et al., 2018; Liu et al., 2019b). Ở đây, mục tiêu là đạt được hiệu suất ngang bằng so với các đối tác học đơn nhiệm vụ (STL) của chúng. Thứ hai, học phụ trợ được sử dụng khi có một nhiệm vụ chính duy nhất hoặc một tập hợp chúng, trong khi các nhiệm vụ phụ trợ chỉ được sử dụng để cải thiện hiệu suất của các nhiệm vụ chính (González-Garduño & Søgaard, 2018; Wang et al., 2022). Mặc dù có thể phân biệt giữa hai loại học, đôi khi học phụ trợ không được phân biệt với học chung.

Kiến trúc. Kiến trúc mô hình MTL nằm trong số các khía cạnh được thảo luận nhiều nhất của MTL và là một trong những khía cạnh đầu tiên được giải quyết trong công việc trước đây. Việc phân biệt giữa chia sẻ tham số cứng và mềm (Ruder, 2017) là phân loại kiến trúc được sử dụng nhiều nhất. Trong các khảo sát gần đây, phương pháp chia sẻ tham số giữa các nhiệm vụ đã được cải thiện, dẫn đến việc tinh chỉnh phân loại để phân loại kiến trúc chính xác hơn (Crawshaw, 2020; Chen et al., 2021). Tiếp theo, một số kiến trúc MTL được phân loại là phương pháp học-để-chia-sẻ (Ruder et al., 2017). Những công việc đó lập luận rằng tốt hơn là học chia sẻ tham số trong kiến trúc cho MTL thay vì thiết kế bằng tay nơi chia sẻ xảy ra, vì nó cung cấp giải pháp thích ứng hơn để phù hợp với sự tương đồng nhiệm vụ ở các phần khác nhau của mạng. Ngoài ra, một số kiến trúc MTL được phân loại là mô hình đa năng có thể xử lý nhiều phương thức, lĩnh vực và nhiệm vụ với một mô hình duy nhất (Kaiser et al., 2017; Pramanik et al., 2019).

Tối ưu hóa. Các kỹ thuật tối ưu hóa cho kiến trúc MTL cũng được thảo luận chi tiết. Để bắt đầu, phương pháp phổ biến nhất để giảm thiểu thách thức MTL là trọng số mất mát. Tính toán trọng số của mất mát đặc thù nhiệm vụ là rất quan trọng, vì nó giúp tối ưu hóa hàm mất mát và xem xét tầm quan trọng tương đối của mỗi nhiệm vụ. Có nhiều phương pháp khác nhau để tính toán trọng số mất mát động, bao gồm cân trọng theo độ bất định (Kendall et al., 2018), tốc độ học (Liu et al., 2019a; Zheng et al., 2019), hoặc hiệu suất (Guo et al., 2018; Jean et al., 2019), trong số những phương pháp khác. Tiếp theo, và liên quan chặt chẽ đến việc cân trọng mất mát nhiệm vụ, là vấn đề lập lịch nhiệm vụ liên quan đến việc chọn nhiệm vụ để huấn luyện ở mỗi bước. Nhiều kỹ thuật được sử dụng, từ những kỹ thuật đơn giản sử dụng lấy mẫu nhiệm vụ đồng đều hoặc tỷ lệ, đến những kỹ thuật phức tạp hơn, như lấy mẫu ủ (Stickland & Murray, 2019) hoặc phương pháp dựa trên học chủ động (Pilault et al., 2020). Các phương pháp điều chuẩn cũng được phân tích. Phương pháp bao gồm (1) giảm thiểu chuẩn L2 giữa các tham số của mô hình chia sẻ tham số mềm (Yang & Hospedales, 2016), (2) đặt phân phối tiên nghiệm trên các tham số mạng (Long et al., 2017), (3) giới thiệu thuật ngữ auto-encoder vào hàm mục tiêu (Lee et al., 2018), (4) biến thể MTL của dropout (Pascal et al., 2021), và những phương pháp khác. Để tiếp tục, các kỹ thuật điều biến gradient được sử dụng để giảm thiểu vấn đề chuyển giao tiêu cực bằng cách thao tác gradient của các nhiệm vụ mâu thuẫn, hoặc thông qua huấn luyện đối nghịch (Sinha et al., 2018) hoặc bằng cách thay thế gradient bằng phiên bản sửa đổi của nó (Lopez-Paz & Ranzato, 2017). Một phương pháp khác để tối ưu hóa mô hình MTL là bằng cách áp dụng chưng cất kiến thức (Clark et al., 2019b). Cuối cùng, tối ưu hóa đa mục tiêu đã được áp dụng cho cài đặt MTL để có được một tập hợp giải pháp tối ưu Pareto trên biên giới Pareto, cung cấp sự linh hoạt lớn hơn trong việc cân bằng sự đánh đổi giữa các nhiệm vụ (Lin et al., 2019).

Học mối quan hệ nhiệm vụ. Phương pháp trong MTL tập trung vào việc học biểu diễn rõ ràng của nhiệm vụ hoặc mối quan hệ giữa chúng là học mối quan hệ nhiệm vụ. Phương pháp này bao gồm ba loại phương pháp chính. Thứ nhất, nhóm nhiệm vụ nhằm chia một tập hợp nhiệm vụ thành các nhóm để tối đa hóa chia sẻ kiến thức trong quá trình huấn luyện chung (Standley et al., 2020). Thứ hai, học mối quan hệ chuyển giao liên quan đến các phương pháp xác định khi nào việc chuyển giao kiến thức từ một nhiệm vụ sang nhiệm vụ khác sẽ có lợi cho việc học chung (Zamir et al., 2018; Guo et al., 2019). Cuối cùng, các phương pháp nhúng nhiệm vụ nhằm học không gian nhúng cho bản thân các nhiệm vụ (Vu et al., 2020).

Về mức độ giám sát, hầu hết các nghiên cứu tập trung vào phương pháp có giám sát. Một số nghiên cứu phân tích phương pháp bán giám sát kết hợp các mục tiêu tự giám sát, như MLM. Tuy nhiên, các phương pháp tự giám sát chủ yếu được thảo luận trong bối cảnh huấn luyện trước.

Hầu hết các nghiên cứu đã tạo ra kết nối với các mô hình học khác, bao gồm học tăng cường, học chuyển giao với sự nhấn mạnh đặc biệt về thích ứng lĩnh vực, meta-learning, và học chủ động và trực tuyến. Tuy nhiên, chỉ Ruder (2017); Zhang & Yang (2017; 2018) khám phá mối quan hệ giữa MTL và học trực tuyến trong bối cảnh ML truyền thống. Theo hiểu biết của chúng tôi, không có công việc trước đây nào nghiên cứu một cách có hệ thống về mối liên hệ giữa MTL và CL. Chúng tôi tin rằng mối liên hệ giữa MTL và CL đại diện cho hướng nghiên cứu đầy hứa hẹn, vì chúng tôi sẽ thúc đẩy tầm quan trọng của mối liên hệ này trong Phần 4.

20

--- TRANG 18 ---
Bản thảo.
B PHƯƠNG PHÁP HỌC ĐA NHIỆM VỤ BỔ SUNG

B.1 PROMPT

Prompt nhúng một nhiệm vụ trong đầu vào. Đầu vào gốc x được sửa đổi bằng cách sử dụng mẫu thành chuỗi văn bản prompt x′ có một số chỗ trống chưa được điền, và sau đó LM được sử dụng để điền thông tin để có được chuỗi cuối cùng x̂, từ đó đầu ra cuối cùng y có thể được suy ra (Liu et al., 2021a). Prompting yêu cầu thiết kế lại tất cả các đầu vào và đầu ra để xử lý các nhiệm vụ như các vấn đề văn bản-thành-văn bản. Phương pháp prompting đã chứng minh hoạt động tốt nhất trong các tình huống không bắn và ít bắn, nhưng lợi ích giảm đi trong các cài đặt tài nguyên cao (Parmar et al., 2022; Wang et al., 2022). Ngoài ra, hiệu suất mở rộng tốt với sự gia tăng kích thước mô hình (Lester et al., 2021), làm cho phương pháp này không thể tiếp cận với mọi người.

Theo Liu et al. (2021a), có nhiều hương vị của prompting. Thứ nhất, các mô hình với các mục tiêu huấn luyện trước khác nhau có thể được sử dụng – LM trái-sang-phải (Brown et al., 2020), MLM (Liu et al., 2019c), LM tiền tố (Bao et al., 2020), hoặc mô hình mã hóa-giải mã (Lewis et al., 2020). Prompt có thể được thiết kế dạng cloze (Petroni et al., 2019) hoặc tiền tố (Lester et al., 2021), được tạo thủ công (Brown et al., 2020) hoặc tự động, có thể lại là rời rạc (Shin et al., 2020) hoặc liên tục (Lester et al., 2021). Kỹ thuật đáp án tìm kiếm không gian đáp án và ánh xạ đến đầu ra gốc bằng cách quyết định hình dạng đáp án và chọn phương pháp thiết kế đáp án. Hơn nữa, tham số có thể được cập nhật bằng cách sử dụng các cài đặt khác nhau – prompting không điều chỉnh (Brown et al., 2020), điều chỉnh prompt LM cố định (Li & Liang, 2021), điều chỉnh LM prompt cố định (Raffel et al., 2020), và điều chỉnh prompt+LM (Liu et al., 2021b). Cuối cùng, huấn luyện có thể được thực hiện trong cài đặt ít/không bắn (Brown et al., 2020) hoặc dữ liệu đầy đủ (Han et al., 2021). Trong các đoạn văn sau, chúng tôi thảo luận về một số công việc prompting trước đây.

HyperPrompt (He et al., 2022) là phương pháp kết hợp siêu mạng và prompt. Ý tưởng chính là thêm vào đầu các vector có thể huấn luyện điều kiện nhiệm vụ vào cả key và value của lớp con MHA ở mọi lớp Transformer. Các bản đồ đặc trưng attention đặc thù nhiệm vụ này được huấn luyện chung với các biểu diễn bất khả tri nhiệm vụ. Prompt key tương tác với query gốc, cho phép token có được ngữ nghĩa đặc thù nhiệm vụ. Prompt value được thêm vào đầu vector value gốc, phục vụ như bộ nhớ đặc thù nhiệm vụ cho MHA để truy xuất thông tin. Tuy nhiên, thay vì có prompt key/value cho mỗi nhiệm vụ và lớp, tác giả khởi tạo prompt toàn cầu P cho mỗi nhiệm vụ. Họ áp dụng hai siêu mạng cục bộ hk/v (một cho key, một cho value) ở mỗi lớp Transformer để chiếu prompt này thành prompt key/value đặc thù nhiệm vụ và lớp thực tế. Có ba biến thể được kiểm tra trong bài báo – HyperPrompt-Share, -Sep, và -Global. HyperPrompt-Global đã chứng minh là tốt nhất, vì nó cho phép cách linh hoạt để chia sẻ thông tin qua các nhiệm vụ và lớp. Nó giới thiệu nhúng nhiệm vụ và lớp, sau đó được hợp nhất thành nhúng nhiệm vụ nhận thức lớp. Nhúng này sau đó là đầu vào cho các siêu mạng toàn cầu Hk/v được sử dụng như bộ tạo siêu mạng cục bộ hk/v. Các siêu mạng cục bộ này sau đó tạo ra hyper-prompt bằng cách sử dụng prompt toàn cầu P. Hyper-prompt cuối cùng được thêm vào đầu với key và value gốc trong các lớp con MHA. Trong quá trình huấn luyện, không có tham số nào được giữ đông lạnh. Họ báo cáo kết quả tốt hơn so với các phương pháp cạnh tranh của HyperFormer++ (Mahabadi et al., 2021) và Prompt-Tuning (Lester et al., 2021).

In-BoXBART (Parmar et al., 2022) sử dụng hướng dẫn y sinh chứa: (1) định nghĩa (giải thích cốt lõi và hướng dẫn chi tiết về những gì cần được thực hiện), (2) prompt (giải thích ngắn gọn về nhiệm vụ), và (3) ví dụ (cặp đầu vào/đầu ra với giải thích). Mỗi hướng dẫn (thực chất là prompt) được thêm vào đầu các thể hiện đầu vào. Vấn đề về các thể hiện quá dài phát sinh.

InstructionNER (Wang et al., 2022) làm giàu đầu vào với hướng dẫn đặc thù nhiệm vụ và tùy chọn đáp án. Ngoài ra, hai nhiệm vụ phụ trợ được giới thiệu – trích xuất thực thể và gõ thực thể, trực tiếp giúp giải quyết nhiệm vụ NER.

Sanh et al. (2021) cho phép công chúng đề xuất prompt và đưa ra 2073 prompt cho 177 tập dữ liệu tổng cộng (12 prompt mỗi tập dữ liệu trung bình). Họ xáo trộn và kết hợp tất cả ví dụ từ các tập dữ liệu trước khi huấn luyện. Trong hầu hết các trường hợp, hiệu suất của mô hình họ được cải thiện khi số lượng tập dữ liệu huấn luyện tăng. Hơn nữa, huấn luyện trên nhiều prompt hơn mỗi tập dữ liệu dẫn đến tổng quát hóa tốt hơn và mạnh mẽ hơn trên các tập dữ liệu chưa thấy. Các mô hình họ huấn luyện dựa trên mô hình T5 thích ứng LM (Lester et al., 2021).

Điều chỉnh tiền tố đông lạnh các tham số mô hình ngôn ngữ và tối ưu hóa vector liên tục đặc thù nhiệm vụ nhỏ gọi là tiền tố (Li & Liang, 2021). Do đó, chỉ cần lưu trữ tiền tố cho mỗi nhiệm vụ, làm cho điều chỉnh tiền tố mô-đun và hiệu quả không gian. Phương pháp này chỉ có thể được áp dụng duy nhất cho các mô hình tạo văn bản, như GPT-2 (Radford et al., 2019) và BART (Lewis et al., 2020). Họ nêu trực giác rằng bối cảnh có thể ảnh hưởng đến việc mã hóa đầu vào x bằng cách hướng dẫn những gì cần trích xuất từ x; và có thể ảnh hưởng đến việc tạo ra đầu ra y bằng cách điều khiển phân phối token tiếp theo. Họ tối ưu hóa tiền tố như nhúng từ liên tục, thay vì tối ưu hóa trên token rời rạc. Lý do cho điều này là prompt rời rạc cần khớp với nhúng từ thực, dẫn đến mô hình ít biểu cảm hơn.

Lester et al. (2021) sử dụng prompt có độ dài cố định của token đặc biệt, nơi nhúng của các token này được cập nhật. Điều này loại bỏ yêu cầu rằng prompt được tham số hóa bởi mô hình và cho phép chúng có tham số có thể huấn luyện riêng. Họ thử nghiệm ba kỹ thuật khởi tạo khác nhau – đồng đều ngẫu nhiên, từ vựng lấy mẫu, và nhãn lớp. Kỹ thuật huấn luyện trước thích ứng LM được sử dụng. Không giống như adapter, sửa đổi hàm thực tế hoạt động trên đầu vào, điều chỉnh prompt thêm biểu diễn đầu vào mới ảnh hưởng đến cách xử lý đầu vào, để lại hàm cố định. Họ đông lạnh mô hình được huấn luyện trước. Cuối cùng, họ thử nghiệm tập hợp prompt (một prompt mỗi mô hình, cho mỗi nhiệm vụ), cho thấy hiệu suất được cải thiện so với trung bình prompt đơn.

Thách thức và Cơ hội trong Chu trình ML. Prompt cũng có thể giảm thiểu một số thách thức của các giai đoạn chu trình ML khác nhau (xem Bảng 2). Để bắt đầu, trong cài đặt điều chỉnh LM prompt cố định hoặc điều chỉnh prompt+LM, kiến thức được chuyển giao từ các nhiệm vụ khác, có thể đặc biệt có lợi cho các nhiệm vụ tài nguyên thấp. Tuy nhiên, trong tình huống như vậy, các kỹ thuật tối ưu hóa khác nhau cần được xem xét để tránh can thiệp tiêu cực và các nhược điểm MTL khác (Phụ lục A.1). Về lựa chọn mô hình, nó là thách thức hơn là cơ hội, vì các mô hình dựa trên prompt yêu cầu số lượng lớn tham số để bắt đầu để hoạt động tốt. Độ phức tạp huấn luyện mô hình phụ thuộc vào cài đặt cập nhật tham số, với một số cài đặt không yêu cầu (Brown et al., 2020) hoặc chỉ ít cập nhật tham số (Li & Liang, 2021). Một trong những lợi ích khi sử dụng prompt là khả năng xử lý tất cả các nhiệm vụ bằng một mô hình văn bản-thành-văn bản duy nhất, bất kể mã hóa đầu vào và đầu ra. Khi sử dụng prompt, thách thức lớn nhất trong triển khai mô hình là kích thước của mô hình. Cuối cùng, cập nhật mô hình do thay đổi phân phối, dữ liệu mới, hoặc yêu cầu kinh doanh (xem Phần 4.4) có vẻ khả thi nhất trong cài đặt nơi prompt liên tục và được điều chỉnh (Li & Liang, 2021). Tuy nhiên, điều này có nhược điểm, như tối ưu hóa khó khăn, thay đổi hiệu suất không đơn điệu liên quan đến số lượng tham số, và dành một phần độ dài chuỗi cho thích ứng (Hu et al., 2021).

22

# 2308.08234.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/instruct/2308.08234.pdf
# Kích thước tệp: 1574851 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Bản thảo.
THÁCH THỨC VÀ CƠ HỘI SỬ DỤNG
TRANSFORMER-BASED MULTI-TASK LEARNING TRONG NLP
THÔNG QUA CHU TRÌNH ML: MỘT KHẢO SÁT
Lovre Torbarina∗,†, ωTin Ferkovic∗, ω
Lukasz RoguskiωVelimir MihelcicωBruno SarlijaωZeljko Kraljevicω
ωdoXray B.V., Neede, Hà Lan
name.lastname@doxray.com

TÓM TẮT
Việc áp dụng ngày càng tăng các mô hình xử lý ngôn ngữ tự nhiên (NLP) trong các ngành công nghiệp đã dẫn đến nhu cầu của các nhà thực hành về hệ thống máy học để xử lý các mô hình này một cách hiệu quả, từ huấn luyện đến phục vụ chúng trong sản xuất. Tuy nhiên, việc huấn luyện, triển khai và cập nhật nhiều mô hình có thể phức tạp, tốn kém và mất thời gian, chủ yếu khi sử dụng các mô hình ngôn ngữ được huấn luyện trước dựa trên transformer. Multi-Task Learning (MTL) đã nổi lên như một phương pháp đầy hứa hẹn để cải thiện hiệu quả và hiệu suất thông qua huấn luyện chung, thay vì huấn luyện các mô hình riêng biệt. Được thúc đẩy bởi điều này, chúng tôi đầu tiên cung cấp một tổng quan về các phương pháp MTL dựa trên transformer trong NLP. Sau đó, chúng tôi thảo luận về các thách thức và cơ hội của việc sử dụng các phương pháp MTL trong suốt các giai đoạn chu trình ML điển hình, đặc biệt tập trung vào các thách thức liên quan đến kỹ thuật dữ liệu, phát triển mô hình, triển khai và giám sát. Khảo sát này tập trung vào các kiến trúc MTL dựa trên transformer và, theo hiểu biết tốt nhất của chúng tôi, là mới trong việc phân tích một cách có hệ thống cách MTL dựa trên transformer trong NLP phù hợp với các giai đoạn chu trình ML. Hơn nữa, chúng tôi thúc đẩy nghiên cứu về mối liên hệ giữa MTL và continual learning (CL), vì lĩnh vực này vẫn chưa được khám phá. Chúng tôi tin rằng sẽ thực tế khi có một mô hình có thể xử lý cả MTL và CL, vì điều này sẽ làm cho việc huấn luyện lại mô hình định kỳ, cập nhật nó do sự thay đổi phân phối, và thêm khả năng mới để đáp ứng các yêu cầu thực tế trở nên dễ dàng hơn.

1 GIỚI THIỆU
Trong những năm gần đây, những tiến bộ trong xử lý ngôn ngữ tự nhiên (NLP) đã cách mạng hóa cách chúng ta đối phó với các vấn đề ngôn ngữ phức tạp. Do đó, những tiến bộ đó đã tác động đáng kể đến ngành công nghiệp toàn cầu, thúc đẩy tăng trưởng trong các tổ chức tích hợp công nghệ AI như một phần trong hoạt động kinh doanh cốt lõi của họ. Để minh họa, báo cáo tình trạng AI của McKinsey năm 2022 đã báo cáo sự gia tăng 3,8 lần kể từ năm 2017 trong các khả năng AI mà các tổ chức đã nhúng trong ít nhất một chức năng hoặc đơn vị kinh doanh, trong đó hiểu ngôn ngữ tự nhiên (NLU) đứng thứ ba trong số các khả năng được báo cáo, chỉ sau thị giác máy tính (Chui et al., 2022). Hơn nữa, Fortune Business Insights dự báo tăng trưởng NLP toàn cầu từ 20,80 tỷ USD năm 2021 lên 161,81 tỷ USD vào năm 2029.¹ Kết quả là, mỗi nhà thực hành NLP cung cấp mô hình thông qua API hoặc sử dụng chúng nội bộ, một mình hoặc cùng với các khả năng AI khác, phải có một hệ thống máy học (ML) để quản lý các mô hình này một cách hiệu quả. Điều này bao gồm việc có các quy trình được thiết lập tốt từ huấn luyện và xác minh các mô hình đó đến triển khai chúng trong sản xuất cho người dùng cuối trong khi liên tục giám sát rằng các mô hình đó vẫn cập nhật với kiến thức mới nhất mà chúng đang được huấn luyện.

Xu hướng áp dụng rộng rãi các mô hình ML bởi các nhà thực hành khác nhau trong các ngành công nghiệp, và nhu cầu kết quả cho các hệ thống ML để quản lý chúng một cách hiệu quả, đã được giải quyết trong một khảo sát về hệ thống ML do Paleyes et al. (2022) thực hiện. Khảo sát đã phân tích các ấn phẩm và bài đăng blog được báo cáo bởi các nhà thực hành khác nhau, cung cấp thông tin chi tiết về các giai đoạn của chu trình ML và các thách thức thường xảy ra trong các giai đoạn đó. Chu trình ML đề cập đến các giai đoạn và quy trình liên quan đến việc thiết kế, phát triển và triển khai một hệ thống ML. Nó bao gồm toàn bộ quá trình,

∗Đóng góp bằng nhau.
†Liên hệ với: Lovre Torbarina <lovre.torbarina@doxray.com>
¹Fortune Business Insights - Quy mô thị trường NLP

1arXiv:2308.08234v1 [cs.CL] 16 Aug 2023

--- TRANG 2 ---
Bản thảo.
từ việc xác định vấn đề và thu thập dữ liệu đến triển khai mô hình và giám sát hiệu suất của chúng. Học mô hình và triển khai mô hình là hai giai đoạn quan trọng trong chu trình ML, trong số những giai đoạn khác (Ashmore et al., 2021; Paleyes et al., 2022). Để hỗ trợ nhu cầu của các nhà thực hành, giai đoạn học mô hình nên được trang bị để xử lý việc huấn luyện và cập nhật một số lượng lớn mô hình, trong khi giai đoạn triển khai mô hình phải cung cấp một cách dễ dàng và hiệu quả để tích hợp và phục vụ các mô hình đó để chạy trong sản xuất, tức là chạy như một phần của các hoạt động kinh doanh thông thường.

Đồng thời, đó là một thực hành phổ biến trong các hệ thống sản xuất NLP để sử dụng các mô hình ngôn ngữ được huấn luyện trước dựa trên transformers (Vaswani et al., 2017) bằng cách tinh chỉnh chúng cho các nhiệm vụ downstream cụ thể. Mặc dù hiệu quả, các mô hình ngôn ngữ có một số lượng lớn tham số đòi hỏi tài nguyên tính toán đáng kể để tinh chỉnh. Mặc dù tinh chỉnh các mô hình được huấn luyện trước có thể hiệu quả hơn về dữ liệu so với huấn luyện một mô hình từ đầu, chuyên môn của các nhà chú thích hoặc chuyên gia lĩnh vực vẫn có thể được yêu cầu để gắn nhãn một số lượng lớn ví dụ, đặc biệt nếu có sự khác biệt đáng kể giữa nhiệm vụ downstream và các mục tiêu huấn luyện trước (Wang et al., 2020). Do đó, đây là một quy trình tốn kém và mất thời gian, đặc biệt nếu có nhu cầu huấn luyện và phục vụ nhiều mô hình trong sản xuất. Để giải quyết thách thức huấn luyện nhiều mô hình, các nhà nghiên cứu đã khám phá Multi-Task Learning (MTL) như một giải pháp (Ruder, 2017). MTL huấn luyện một mô hình duy nhất để học nhiều nhiệm vụ đồng thời trong khi chia sẻ một phần tham số mô hình giữa chúng (Caruana, 1997), làm cho quá trình hiệu quả về bộ nhớ và, trong một số trường hợp, hiệu quả hơn về mặt tính toán so với huấn luyện nhiều mô hình. Ngoài ra, việc sử dụng một mô hình duy nhất cho nhiều nhiệm vụ downstream trong một hệ thống sản xuất có thể đơn giản hóa việc tích hợp các mô hình ML với hệ thống ML và giảm chi phí kinh tế. Điều này là do bản chất mô-đun của các kiến trúc MTL thúc đẩy chia sẻ mã và mô hình, tái sử dụng, hợp tác dễ dàng hơn và bảo trì. Hơn nữa, mô hình MTL giảm thời gian rảnh rỗi vì cùng một mô hình được sử dụng cho các nhiệm vụ khác nhau. Do đó, các phương pháp MTL cung cấp một giải pháp đầy hứa hẹn để giảm thiểu một số khó khăn liên quan đến việc quản lý nhiều mô hình trong các hệ thống sản xuất ML.

Trong khảo sát này, chúng tôi đầu tiên cung cấp một tổng quan về các phương pháp MTL dựa trên transformer trong NLP (xem Mục 3). Thứ hai, chúng tôi nổi bật các cơ hội sử dụng các phương pháp MTL qua nhiều giai đoạn của chu trình ML, đặc biệt tập trung vào các thách thức liên quan đến kỹ thuật dữ liệu, phát triển mô hình, triển khai và giám sát (xem Mục 4). Chúng tôi chỉ tập trung vào các kiến trúc dựa trên transformer. Theo hiểu biết tốt nhất của chúng tôi, đây là khảo sát đầu tiên thảo luận một cách có hệ thống về lợi ích của việc sử dụng các phương pháp MTL qua nhiều giai đoạn chu trình ML (xem Mục 2). Ngoài ra, chúng tôi khuyến khích nghiên cứu thêm về mối liên hệ giữa MTL và Continual Learning (CL). Chúng tôi lập luận rằng việc có một mô hình có khả năng xử lý cả MTL và CL là thực tế vì nó giải quyết nhu cầu huấn luyện lại định kỳ và cập nhật liên tục để đáp ứng với sự thay đổi phân phối và việc bổ sung khả năng mới trong các mô hình sản xuất.

Phần còn lại của bài báo được tổ chức như sau. Trong Mục 2, chúng tôi xem xét ngắn gọn các khảo sát liên quan và nổi bật các khoảng trống được giải quyết trong khảo sát của chúng tôi. Trong Mục 3, chúng tôi đưa ra tổng quan về các phương pháp MTL dựa trên transformer. Trong Mục 4, chúng tôi phân tích một cách có hệ thống lợi ích của việc sử dụng MTL thông qua các giai đoạn chu trình ML cụ thể. Và cuối cùng, trong Mục 5, chúng tôi đưa ra kết luận cho công trình của mình.

2 CÁC KHẢO SÁT LIÊN QUAN

Trong mục này, chúng tôi đưa ra tổng quan về công trình liên quan về MTL, hệ thống ML và CL, và chỉ ra những gì chưa được thảo luận cho đến nay liên quan đến mối liên hệ của MTL với cả hệ thống ML và CL.

2.1 MULTI-TASK LEARNING

Ý tưởng về MTL đã được khám phá trong nhiều nghiên cứu. Trong mục này, chúng tôi cung cấp tổng quan về các khảo sát MTL liên quan, giải quyết các khía cạnh khác nhau của MTL, và liệt kê chúng cùng với các khảo sát tương ứng trong Bảng 1.² Trong phần còn lại của mục, chúng tôi chỉ đề cập đến các khảo sát liên quan và xem xét các khía cạnh MTL riêng lẻ (được hiển thị in đậm) chi tiết hơn.³

Nhiều lĩnh vực ứng dụng đã được nghiên cứu trong công trình trước đây, từ các khảo sát bao gồm nhiều lĩnh vực (Ruder, 2017; Zhang & Yang, 2017; 2018; Thung & Wee, 2018; Vafaeikia et al., 2020; Crawshaw, 2020; Upadhyay et al., 2021; Abhadiomhen et al., 2022), đến những khảo sát dành riêng cho một lĩnh vực cụ thể, như thị giác máy tính (Vandenhende et al., 2021) hoặc xử lý ngôn ngữ tự nhiên (Zhou, 2019; Worsham & Kalita, 2020; Chen et al., 2021; Samant et al., 2022; Zhang et al., 2023). Cả mô hình tính toán ML truyền thống và deep learning đều đã được nghiên cứu. ML truyền thống được thảo luận chủ yếu trong các nghiên cứu cũ hơn, trong khi deep learning được trình bày trong tất cả trừ một nghiên cứu.

Các kiến trúc MTL đã được thảo luận rộng rãi trong công trình trước đây. Chia sẻ tham số cứng và mềm (Ruder, 2017) là phân loại kiến trúc được sử dụng nhiều nhất, nhưng các khảo sát gần đây đã tinh chỉnh các phân loại để phân loại chính xác hơn (Crawshaw, 2020; Chen et al., 2021). Tiếp theo, một số kiến trúc MTL được phân loại là learning-to-share (Ruder et al.,

²Phiên bản rộng hơn của bảng được cung cấp trong Phụ lục Bảng 3.
³Phiên bản rộng hơn của mục được cung cấp trong Phụ lục A.1.

2

--- TRANG 3 ---
Bản thảo.
Bảng 1: Các khía cạnh được thảo luận theo khảo sát MTL. Các khía cạnh được chỉ ra bằng chữ in đậm.

Năm Khảo sát MTL
2017 1- (Ruder, 2017) 2- (Zhang & Yang, 2017)
2018 3- (Zhang & Yang, 2018) 4- (Thung & Wee, 2018)
2019 5- (Zhou, 2019)
2020 6- (Vafaeikia et al., 2020) 7- (Worsham & Kalita, 2020) 8- (Crawshaw, 2020)
2021 9- (Vandenhende et al., 2021) 10- (Chen et al., 2021) 11- (Upadhyay et al., 2021)
2022 12- (Samant et al., 2022) 13- (Abhadiomhen et al., 2022)
2023 14- (Zhang et al., 2023)

Khía cạnh \Khảo sát 1 2 3 4 5 6 7 8 9 10 11 12 13 14
Mô hình Tính toán
ML Truyền thống ✓ ✓ ✓ ✓ ✓
Deep Learning ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Kiến trúc
Learning to Share ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Universal Models ✓ ✓ ✓ ✓ ✓
Tối ưu hóa
Loss Weighting ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Regularization ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Task Scheduling ✓ ✓ ✓ ✓ ✓ ✓
Gradient Modulation ✓ ✓ ✓ ✓ ✓
Knowledge Distillation ✓ ✓ ✓ ✓
Multi-Objective Optimization ✓ ✓ ✓
Học mối quan hệ nhiệm vụ
Task Grouping ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Relationships Transfer ✓ ✓ ✓ ✓ ✓
Task Embeddings ✓ ✓
Kết nối với Paradigm Học
Reinforcement Learning ✓ ✓ ✓ ✓ ✓ ✓
Transfer Learning ✓ ✓ ✓
Meta-Learning ✓ ✓ ✓
Online Learning ✓ ✓ ✓
Continual Learning
Lĩnh vực Ứng dụng
Natural Language Processing ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Computer Vision ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓

2017), cung cấp một giải pháp thích ứng hơn bằng cách học cách chia sẻ tham số giữa các nhiệm vụ, thay vì việc chia sẻ được xác định trước. Ngoài ra, một số kiến trúc MTL được phân loại là universal models, xử lý nhiều modality, lĩnh vực và nhiệm vụ bằng một mô hình duy nhất (Kaiser et al., 2017; Pramanik et al., 2019).

Các kỹ thuật tối ưu hóa cho các kiến trúc MTL cũng đã được thảo luận rộng rãi, trong khi loss weighting là phương pháp phổ biến nhất để giảm thiểu các thách thức MTL. Các kỹ thuật bao gồm loss weighting theo uncertainty (Kendall et al., 2018), tốc độ học (Liu et al., 2019a; Zheng et al., 2019), hoặc hiệu suất (Guo et al., 2018; Jean et al., 2019), trong số những kỹ thuật khác. Tiếp theo, và liên quan chặt chẽ đến việc tính trọng số task losses, là vấn đề task scheduling liên quan đến việc chọn các nhiệm vụ để huấn luyện ở mỗi bước. Nhiều kỹ thuật đã được sử dụng, từ những kỹ thuật đơn giản sử dụng lấy mẫu nhiệm vụ đồng nhất hoặc tỷ lệ, đến những kỹ thuật phức tạp hơn, như annealed sampling (Stickland & Murray, 2019) hoặc các phương pháp dựa trên active learning (Pilault et al., 2020). Cuối cùng, các phương pháp regularization (Long et al., 2017; Lee et al., 2018; Pascal et al., 2021), gradient modulation (Lopez-Paz & Ranzato, 2017; Sinha et al., 2018), knowledge distillation (Clark et al., 2019b), và multi-objective optimization (Lin et al., 2019) cũng đã được áp dụng để tối ưu hóa các mô hình MTL.

Học mối quan hệ nhiệm vụ trong MTL tập trung vào việc học các biểu diễn rõ ràng của các nhiệm vụ hoặc mối quan hệ giữa chúng, và thường ba loại phương pháp đã được sử dụng. Thứ nhất, task grouping nhằm chia một tập hợp các nhiệm vụ thành các nhóm để tối đa hóa việc chia sẻ kiến thức trong quá trình huấn luyện chung (Standley et al., 2020). Thứ hai, transfer relationship learning xác định khi nào việc chuyển giao kiến thức từ nhiệm vụ này sang nhiệm vụ khác sẽ có lợi cho việc học chung (Zamir et al., 2018). Cuối cùng, các phương pháp task embedding nhằm học không gian embedding của nhiệm vụ (Vu et al., 2020).

Các công trình trước đây đã tạo ra kết nối với các paradigm học khác, bao gồm reinforcement learning, transfer learning, meta-learning, active và online learning. Theo hiểu biết tốt nhất của chúng tôi, chưa có công trình nào trước đây nghiên cứu một cách có hệ thống mối liên hệ giữa MTL và CL. Chúng tôi tin rằng mối liên hệ giữa MTL và CL đại diện cho một hướng nghiên cứu đầy hứa hẹn, như chúng tôi sẽ thúc đẩy nhu cầu cho mối liên hệ này trong Mục 4.4.

2.2 CHU TRÌNH ML VÀ HỆ THỐNG ML

Sự tăng trưởng vô song của những tiến bộ trong các phương pháp ML trong những năm gần đây, với các ứng dụng trong NLP, thị giác máy tính và những lĩnh vực khác, đã tăng độ phức tạp của việc xây dựng các hệ thống ML cần giải quyết các yêu cầu của chu trình ML. Các công trình trước đây đã xem xét các thách thức của các hệ thống như vậy, thường xác định các giai đoạn chu trình ML như quản lý dữ liệu, học mô hình và triển khai mô hình, để nghiên cứu một cách có hệ thống hoạt động của các hệ thống ML và xác định các thách thức trong và giữa các giai đoạn (Vartak & Madden, 2018; Ashmore et al., 2021; Paleyes et al., 2022; Huyen, 2022).

Ví dụ, Vartak & Madden (2018) đã xác định các giai đoạn chu trình ML và phân tích các thách thức quản lý mô hình. Hơn nữa, Ashmore et al. (2021) đã thảo luận về đảm bảo ML cho mỗi giai đoạn, trong khi Paleyes et al. (2022) đã xem xét các thách thức của các nhà thực hành ở mỗi giai đoạn của quy trình triển khai mô hình ML trong phạm vi rộng hơn so với các khảo sát trước đây.

Trong phần còn lại của mục này, chúng tôi cung cấp một vài ví dụ về các thách thức xảy ra trong các giai đoạn điển hình của chu trình ML.

Có nhiều thách thức xảy ra trong các giai đoạn khác nhau của chu trình ML. Ví dụ, quản lý dữ liệu thường là giai đoạn đầu của chu trình ML với các thách thức liên quan như thu thập và tiền xử lý dữ liệu (Polyzotis et al., 2018; Sambasivan et al., 2021; Whang et al., 2023). Tiếp theo, các giai đoạn học mô hình và xác minh diễn ra, trình bày các thách thức như lựa chọn (Ding et al., 2018) và huấn luyện (Sun, 2020) một mô hình, và xác định phương pháp hiệu quả nhất để xác minh nó (Bernardi et al., 2019; Schröder & Schulz, 2022), tương ứng. Sau đó, giai đoạn triển khai mô hình diễn ra với các thách thức như tích hợp mô hình (Sculley et al., 2015; Renggli et al., 2019) vào sản xuất. Cuối cùng, giai đoạn giám sát với các thách thức như giám sát hiệu suất mô hình liên tục (Schröder & Schulz, 2022) và cập nhật mô hình theo thời gian (Ditzler et al., 2015; Abdelkader, 2020).

Một số thách thức có thể tác động đến một số giai đoạn của chu trình ML, như hợp tác giữa các nhóm và vai trò đa dạng, bao gồm các kỹ sư phần mềm và dữ liệu, nhà khoa học dữ liệu và các bên liên quan khác (Takeuchi & Yamamoto, 2020; Nahar et al., 2022; Pei et al., 2022; Yang et al., 2022). Hơn nữa, có những thách thức về thiên vị, công bằng và trách nhiệm trong đạo đức (Mehrabi et al., 2021; Kim & Doshi-Velez, 2021), các quy định khác nhau được đặt ra bởi luật pháp (Marchant, 2011; Politou et al., 2018) và các cuộc tấn công đối kháng trong bảo mật (Ren et al., 2020; Rosenberg et al., 2021), trong số những thách thức khác.

Các công trình trước đây đã giải quyết các khía cạnh MTL ở các mức độ khác nhau trong các giai đoạn cụ thể, hoặc theo cách đơn giản hoặc gián tiếp. Tuy nhiên, một cuộc thảo luận có hệ thống về lợi ích tiềm năng của việc sử dụng các phương pháp MTL để giảm thiểu các thách thức qua các giai đoạn khác nhau của chu trình ML chưa được thực hiện.

2.3 CONTINUAL LEARNING

CL học tăng dần một chuỗi các nhiệm vụ, với mục tiêu mở rộng dần kiến thức đã có được và sử dụng nó cho việc học tiếp theo (Chen & Liu, 2018). CL nhằm vượt qua catastrophic forgetting (CF) và tạo điều kiện cho knowledge transfer (KT) qua các nhiệm vụ, trong đó CF là sự suy giảm hiệu suất trên các nhiệm vụ trước đây khi học những nhiệm vụ mới, và KT là khả năng áp dụng kiến thức từ các nhiệm vụ quá khứ cho các nhiệm vụ mới (Ke & Liu, 2022). Các đánh giá trước đây về CL (Hsu et al., 2018; De Lange et al., 2021) đã phân loại các cài đặt CL dựa trên phân phối đầu ra và đầu vào biên P(Y(t)) và P(X(t)) của nhiệm vụ t, với P(X(t))≠P(X(t+1)). Thứ nhất, class incremental learning được đặc trưng bởi không gian đầu ra mở rộng với các nhãn lớp quan sát được sao cho Y(t)⊂Y(t+1) và P(Y(t))≠P(Y(t+1)). Thứ hai, task incremental learning (TIL), yêu cầu nhãn nhiệm vụ t để xác định các nút đầu ra riêng biệt Y(t) cho nhiệm vụ hiện tại t, trong đó Y(t)≠Y(t+1). Cuối cùng, incremental domain learning định nghĩa các nhiệm vụ với nhãn lớp và phân phối xác suất bằng nhau, Y(t)=Y(t+1), và P(Y(t))=P(Y(t+1)).

Các phương pháp CL cũng được phân loại thành ba loại chính dựa trên cách thông tin cụ thể của nhiệm vụ được lưu trữ và sử dụng trong quá trình học tăng dần. Thứ nhất, các phương pháp replay lưu trữ các mẫu ở định dạng thô hoặc tạo ra các mẫu giả với mô hình sinh, phát lại chúng trong khi học một nhiệm vụ mới để giảm thiểu việc quên và ngăn chặn sự can thiệp của nhiệm vụ trước đây. Thứ hai, các phương pháp dựa trên regularization, mặt khác, tránh lưu trữ đầu vào thô và giảm yêu cầu bộ nhớ bằng cách giới thiệu một thuật ngữ regularization bổ sung trong hàm loss để củng cố kiến thức trước đây trong khi học dữ liệu mới. Thứ ba, các phương pháp cô lập tham số phân bổ các tham số mô hình khác nhau cho mỗi nhiệm vụ, hoặc bằng cách thêm các nhánh cụ thể của nhiệm vụ mới hoặc che các phần nhiệm vụ trước đây, để ngăn chặn việc quên và duy trì kiến thức cụ thể của nhiệm vụ. Chúng tôi giới thiệu độc giả đến Ke & Liu (2022) để biết phân loại CL tinh chỉnh hơn và chi tiết trong NLP.

Trong CL, MTL thường được sử dụng như một đường cơ sở giới hạn trên có thể sử dụng tất cả dữ liệu từ tất cả các nhiệm vụ đồng thời (De Lange et al., 2021; Ke & Liu, 2022). Vì CL và MTL hoạt động trong các cài đặt học khác nhau, ít công trình đã cố gắng kết nối hai paradigm. Sun et al. (2020) đã trình bày một khung huấn luyện trước liên tục có tên ERNIE 2.0 tăng dần xây dựng các nhiệm vụ huấn luyện trước và sau đó học các mô hình được huấn luyện trước trên các nhiệm vụ được xây dựng này thông qua continual multi-task learning. Tiếp theo, ERNIE 2.0 được thử nghiệm với các phương pháp huấn luyện trước CL và MTL để đánh giá tác động đến nhiệm vụ tóm tắt văn bản trừu tượng nhưng thực hiện tương tự như các phương pháp khác (Kirstein et al., 2022).

Trong Mục 4.4, chúng tôi thúc đẩy nghiên cứu thêm về việc kết hợp các phương pháp CL và MTL, vì các phương pháp huấn luyện trước không đủ để xử lý sự thay đổi phân phối và điều chỉnh mô hình cho các yêu cầu kinh doanh mới trong các tình huống thực tế.

3 CÁC PHƯƠNG PHÁP MULTI-TASK LEARNING

3.1 PHÂN LOẠI

Có nhiều phân loại MTL khác nhau được đề cập trong các khảo sát được trình bày trong Mục 2.1. Ruder (2017) phân biệt giữa chia sẻ tham số cứng và mềm, đây đã chứng tỏ là một phân loại có ảnh hưởng, vì nó cũng được sử dụng trong các công trình sau đó. Zhang & Yang (2018) định nghĩa ba loại multi-task supervised learning - dựa trên feature, parameter và instance. Vandenhende et al. (2021) phân biệt giữa các kiến trúc tập trung vào encoder và decoder. Chen et al. (2021) thảo luận về các kiến trúc parallel, hierarchical, modular và generative adversarial. Chúng tôi đã phân loại các phương pháp MTL dựa trên transformer thành 3 loại chính dựa trên sự khác biệt trong kiến trúc: (1) Fully-Shared Encoder, (2) Adapters và (3) Hypernetworks (Hình 1).⁴

Hình 1: Tổng quan đơn giản về các kiến trúc MTL. Hình phụ a) đại diện cho một encoder được chia sẻ hoàn toàn, b) một adapter, và c) một hypernetwork. Các thành phần màu xanh được huấn luyện chung bởi tất cả các nhiệm vụ, các thành phần màu xanh lá cây là cụ thể của nhiệm vụ, và các thành phần màu xám được giữ đông lạnh. Một thành phần adapter chấm bi gợi ý các vị trí chèn adapter có thể.

3.2 TỔNG QUAN CÁC PHƯƠNG PHÁP MTL

3.2.1 FULLY-SHARED ENCODER

Một phương pháp đơn giản và trực quan đối với MTL là có sự phân chia rõ ràng giữa các tham số được chia sẻ và cụ thể của nhiệm vụ. Trong phương pháp như vậy, có một encoder dựa trên transformer được chia sẻ ở các lớp thấp hơn, trong khi các lớp trên bao gồm các lớp cụ thể của nhiệm vụ khác nhau (heads). Một phương pháp như vậy, MT-DNN (Liu et al., 2019b), kết hợp tất cả các nhiệm vụ GLUE (Wang et al., 2018) với nhau và cập nhật mô hình tương ứng. Encoder được chia sẻ được cập nhật cho tất cả các thể hiện, trong khi các head cụ thể của nhiệm vụ chỉ được cập nhật cho các thể hiện của nhiệm vụ mà chúng cụ thể cho. Có một số nhược điểm của phương pháp MT-DNN này. Thứ nhất, sự can thiệp của nhiệm vụ không được tính đến và các tác giả chỉ đơn giản hy vọng rằng các nhiệm vụ sẽ tương tác tốt, mặc dù một số trong số chúng ở các lĩnh vực khác nhau. Tiếp theo, lấy mẫu ngẫu nhiên tỷ lệ được sử dụng, có thể dẫn đến underfitting trên các tập dữ liệu ít tài nguyên. Cuối cùng, loss được tính toán theo ba cách khác nhau (cho phân loại, hồi quy và xếp hạng), và kết quả là, nó có các thang đo khác nhau. Tuy nhiên, tất cả các hàm loss đều được tính trọng số bằng nhau. Bất chấp những quan sát này, mô hình của họ vượt trội hơn việc tinh chỉnh một mô hình BERT khác nhau (Devlin et al., 2019) trên hầu hết các nhiệm vụ. Ngoài ra, họ đã thử tinh chỉnh mô hình đa nhiệm vụ này thêm trên mỗi nhiệm vụ riêng biệt sau khi huấn luyện chung trên tất cả các nhiệm vụ, tạo ra N mô hình cho N nhiệm vụ. Điều đó lại mang lại sự cải thiện và hiệu suất tối tân tại thời điểm đó. Tuy nhiên, một nhược điểm rõ ràng là có một mô hình khác nhau cho mỗi nhiệm vụ.

Một phương pháp encoder được chia sẻ khác là pre-finetuning. Muppet (Aghajanyan et al., 2021) chia sẻ một encoder trong MTL trên 46 tập dữ liệu đa dạng. Các batch không đồng nhất đã chứng minh có lợi trong việc xử lý gradient nhiễu từ các nhiệm vụ khác nhau. Hơn nữa, để có huấn luyện ổn định, loss của điểm dữ liệu được chia cho log(n), trong đó n biểu thị số lượng của tập nhãn cho nhiệm vụ liên quan. Họ duy trì phân phối tự nhiên của các tập dữ liệu vì các phương pháp khác dẫn đến hiệu suất giảm. Các tác giả tìm thấy một ngưỡng khoảng 15 nhiệm vụ, dưới đó hiệu suất tinh chỉnh downstream bị giảm, và trên đó hiệu suất cải thiện tuyến tính theo số lượng nhiệm vụ pre-finetuning.

Một phương pháp tương tự với decoder được thêm vào, EXT5 (Aribandi et al., 2021), mở rộng hỗn hợp đến 107 nhiệm vụ được giám sát, định dạng chúng cho các kiến trúc encoder-decoder, và thực hiện pre-finetuning cùng với việc khử nhiễu span C4 không được giám sát của T5 (Raffel et al., 2020). Hỗn hợp nhiệm vụ của họ cũng bao gồm các ứng dụng NLP như hiểu đọc, trả lời câu hỏi sách đóng, lý luận thông thường, đối thoại và tóm tắt, trong số những ứng dụng khác. Điều này cho thấy rằng các mô hình encoder-decoder như T5 có khả năng giải quyết một phạm vi rộng hơn các ứng dụng NLP so với các mô hình encoder. Tuy nhiên, các mô hình cụ thể của nhiệm vụ vẫn đạt hiệu suất tốt hơn so với các mô hình tổng quát (Chung et al., 2022).

3.2.2 ADAPTERS

Trước khi được sử dụng trong NLP, các mô-đun residual adapter đầu tiên được giới thiệu cho lĩnh vực thị giác (Rebuffi et al., 2017). Adapters là các mô-đun nhỏ, cụ thể của nhiệm vụ thường được chèn vào các lớp mạng, nhưng cũng có thể được tiêm song song với chúng. Trong khảo sát này, mạng luôn là kiến trúc dựa trên transformer. So với kích thước của transformers, chúng thêm một số lượng tham số không đáng kể cho mỗi nhiệm vụ. Các tham số của mạng gốc vẫn bị đông lạnh trừ khi được nêu khác, dẫn đến mức độ chia sẻ tham số cao và số lượng tham số có thể huấn luyện nhỏ. Do đó, adapters cho các nhiệm vụ mới có thể dễ dàng được thêm vào mà không cần huấn luyện lại transformer hoặc các adapters khác. Chúng học biểu diễn theo lớp cụ thể của nhiệm vụ, nhỏ, có thể mở rộng và chia sẻ được, có biểu diễn mô-đun và thành phần thông tin không can thiệp (Pfeiffer et al., 2020b). Vì các adapters tương ứng được huấn luyện riêng biệt, nhu cầu về heuristics lấy mẫu do kích thước tập dữ liệu lệch không còn xuất hiện (Pfeiffer et al., 2020b).

AdapterHub. AdapterHub (Pfeiffer et al., 2020b) là một framework cho phép sử dụng động các adapters được huấn luyện trước cho các nhiệm vụ và ngôn ngữ khác nhau.⁵ Framework được xây dựng trên thư viện HuggingFace Transformers và cho phép thích ứng nhanh chóng và dễ dàng các mô hình được huấn luyện trước tiên tiến. Nó cho phép chia sẻ tham số hiệu quả giữa các nhiệm vụ bằng cách huấn luyện nhiều adapters cụ thể của nhiệm vụ và ngôn ngữ, có thể được trao đổi và kết hợp post-hoc. Người ta có thể chọn xếp chồng các adapters lên nhau, kết hợp chúng với attention (Pfeiffer et al., 2020a), hoặc thay thế chúng một cách động. Việc tải xuống, chia sẻ và huấn luyện adapters yêu cầu những thay đổi tối thiểu trong các script huấn luyện.

Bottleneck adapters. Trong tài liệu của AdapterHub, ba phương pháp bottleneck adapter khác nhau đã được đề cập. Adapters có thể được chèn sau cả khối Multi-Head Attention (MHA) và Feed-Forward (FF) (Houlsby et al., 2019), chỉ sau khối FF (Pfeiffer et al., 2020c), hoặc song song với các lớp Transformer (He et al., 2021). Bottleneck adapters bao gồm một down-projection, phi tuyến (thường là ReLU), và một up-projection trở lại kích thước ban đầu. Kết nối residual được sử dụng, và layer normalization được áp dụng sau đó.

Language adapters. Trong framework MAD-X (Pfeiffer et al., 2020c), các tác giả huấn luyện (1) language adapters thông qua masked language modeling (MLM) trên dữ liệu ngôn ngữ đích không có nhãn, và (2) task adapters bằng cách tối ưu hóa một nhiệm vụ đích trên dữ liệu có nhãn trong ngôn ngữ nguồn với nhiều dữ liệu huấn luyện nhất. Sau đó, adapters được xếp chồng, cho phép chuyển giao cross-lingual zero-shot bằng cách thay thế target language adapter khi suy luận. Invertible adapters được giới thiệu để giải quyết sự không khớp giữa từ vựng đa ngôn ngữ của mô hình được huấn luyện trước và từ vựng ngôn ngữ đích. Do đó, language adapters có thể hữu ích khi người ta đã huấn luyện một task adapter cho một nhiệm vụ cụ thể và bây giờ cần thực hiện suy luận cho cùng nhiệm vụ đó, nhưng trên dữ liệu mới từ một ngôn ngữ khác.

Khác. Projected Attention Layer (PAL) (Stickland & Murray, 2019) là một lớp multi-head attention chiều thấp được thêm song song với các lớp transformer. Multi-head attention được áp dụng trên một đầu vào down-projected, sau đó một up-projection đến chiều ban đầu được áp dụng. Các ma trận down- và up-projection này được chia sẻ giữa các lớp, nhưng không giữa các nhiệm vụ. Các tác giả tinh chỉnh một encoder được huấn luyện trước cùng với PALs. Điều này có nhược điểm: (1) việc quên kiến thức được huấn luyện trước là có thể, (2) cần truy cập vào tất cả các nhiệm vụ tại thời điểm huấn luyện, và (3) việc thêm nhiệm vụ mới yêu cầu huấn luyện lại chung hoàn toàn. Do đó, phương pháp này thiếu nhiều đặc điểm của một adapter.

AdapterFusion (Pfeiffer et al., 2020a) giới thiệu một giai đoạn tổng hợp kiến thức, trong đó các adapters được huấn luyện trước đó được kết hợp. Phương pháp này sử dụng nhiều adapters để tối đa hóa việc chuyển giao kiến thức giữa các nhiệm vụ mà không bị ảnh hưởng bởi các nhược điểm của MTL, như catastrophic forgetting (Serra et al., 2018) hoặc sự can thiệp của nhiệm vụ (Wu et al., 2020). Nó giới thiệu một tập hợp trọng số mới học để kết hợp các adapters như một hàm động của dữ liệu nhiệm vụ đích bằng cách sử dụng attention. Điều này cho thấy nhược điểm lớn nhất của nó - AdapterFusion chỉ được huấn luyện cho một nhiệm vụ.

Hu et al. (2021) lập luận rằng thiết kế bottleneck adapter ban đầu (Houlsby et al., 2019) giới thiệu độ trễ suy luận vì các adapters được xử lý tuần tự, trong khi các mô hình ngôn ngữ lớn (LLMs) dựa trên tính song song phần cứng. Phương pháp của họ, LoRA (Low Rank Approximation) sửa đổi trọng số attention của các ma trận projection query và value bằng cách giới thiệu các ma trận phân tách hạng thấp có thể huấn luyện song song với phép tính ban đầu. Điều này giảm độ trễ suy luận, vì các ma trận phân tách có thể được hợp nhất với các trọng số được huấn luyện trước để suy luận nhanh hơn.

⁵https://adapterhub.ml

6

--- TRANG 7 ---
Bản thảo.

Hình 2: Các giai đoạn chu trình ML. Hình được lấy từ Huyen (2022).

Bảng 2: Các giai đoạn chu trình ML và các thách thức tương ứng.

Giai đoạn Chu trình ML | Thách thức
--- | ---
Project Scoping | Yêu cầu Ban đầu
Data Engineering | Gắn nhãn Khối lượng lớn Dữ liệu
 | Chi phí của Nhà chú thích và Chuyên gia
 | Thiếu Dữ liệu Phương sai cao
Model Development | Độ phức tạp Mô hình
 | Môi trường Hạn chế Tài nguyên
 | Chi phí Tính toán
 | Tác động Môi trường
Deployment | Dễ dàng tích hợp
Monitoring | Distribution Shift
Business Analysis | Yêu cầu Mới

3.2.3 HYPERNETWORKS

Một hypernetwork là một mạng tạo ra trọng số của mạng khác (Ha et al., 2016). Phương pháp này có thể giảm thiểu một nhược điểm của adapters, đó là thiếu chia sẻ kiến thức. Hypernetwork cho phép chia sẻ kiến thức qua các nhiệm vụ trong khi thích ứng với các nhiệm vụ riêng lẻ thông qua việc tạo tham số cụ thể của nhiệm vụ.

CA-MTL (Pilault et al., 2020) mô-đun hóa một mạng được huấn luyện trước bằng cách thêm các lớp điều kiện nhiệm vụ hoặc thay đổi các trọng số được huấn luyện trước bằng cách sử dụng task embedding. Mạng dựa trên transformer điều kiện nhiệm vụ của họ có bốn thành phần: (1) conditional attention, (2) conditional alignment, (3) conditional layer normalization, và (4) conditional bottleneck. Trong (1), họ sử dụng conditional attention block-diagonal cho phép attention tính đến các thiên vị cụ thể của nhiệm vụ. Thành phần (2) căn chỉnh dữ liệu của các nhiệm vụ đa dạng. Trong (3), họ điều chỉnh thống kê layer normalization cho các nhiệm vụ cụ thể. Cuối cùng, (4) tạo điều kiện cho việc chia sẻ trọng số và tăng cường luồng thông tin cụ thể của nhiệm vụ từ các lớp thấp hơn. Ngoài ra, họ sử dụng multi-task uncertainty sampling. Điều này ủng hộ các nhiệm vụ có độ không chắc chắn cao nhất bằng cách lấy mẫu một nhiệm vụ bất cứ khi nào entropy của nó tăng, giúp tránh catastrophic forgetting. Khi giới thiệu một nhiệm vụ mới, họ tuyên bố rằng chỉ cần thêm một head decoder tuyến tính mới và một vector task embedding mới để tái điều chế các trọng số hiện có.

HyperFormer++ (Mahabadi et al., 2021) sử dụng hypernetworks để tạo ra trọng số của các tham số adapter và layer normalization. Những hypernetworks này điều kiện trên task embedding, vị trí adapter (sau sub-layer MHA hoặc FF), và id lớp trong mô hình T5 (Raffel et al., 2020). Trong quá trình huấn luyện, họ lấy mẫu các nhiệm vụ bằng cách sử dụng temperature-based sampling. Họ tuyên bố rằng đối với mỗi nhiệm vụ mới, mô hình của họ chỉ yêu cầu học một task embedding bổ sung.

HyperGrid (Tay et al., 2020) tận dụng cấu trúc hyper projection có thể phân tách theo lưới giúp chuyên môn hóa các vùng trong ma trận trọng số cho các nhiệm vụ khác nhau. Để xây dựng hypernetwork được đề xuất, phương pháp của họ học các tương tác và tổng hợp giữa trạng thái toàn cục, không phụ thuộc nhiệm vụ và trạng thái cục bộ, cụ thể của nhiệm vụ. Họ trang bị các sub-layer FF position-wise của Transformer với HyperGrid. Họ khởi tạo một mô hình T5 từ một checkpoint được huấn luyện trước và thêm các tham số bổ sung được tinh chỉnh cùng với phần còn lại của mạng. Các tác giả của bài báo không đề cập đến bất kỳ điều gì cụ thể liên quan đến khả năng thêm một nhiệm vụ mới mà không cần huấn luyện lại, vì nó có vẻ không tầm thường.

4 MTL TỪ QUAN ĐIỂM CHU TRÌNH ML

Trong mục này, chúng tôi thảo luận về các thách thức và cơ hội của việc kết hợp vào các hệ thống sản xuất ML các phương pháp MTL thay vì sử dụng nhiều đối tác đơn nhiệm vụ. Được thúc đẩy bởi các đánh giá trước đây về chu trình ML (xem Mục 2.2), chúng tôi định nghĩa các giai đoạn chu trình ML để thảo luận về các thách thức và cơ hội một cách có hệ thống.

Theo Huyen (2022), chúng tôi định nghĩa sáu giai đoạn chu trình ML: (1) Project Scoping, (2) Data Engineering, (3) Model Development, (4) Deployment, (5) Monitoring, và (6) Business Analysis (Hình 2). Tiếp theo, chúng tôi chủ yếu tập trung vào các thách thức đã được thảo luận trong phạm vi rộng hơn trong Paleyes et al. (2022), trong khi chúng tôi lập luận cách MTL có thể giảm thiểu chúng. Các thách thức cho mỗi giai đoạn của chu trình ML được liệt kê trong Bảng 2. Khi thảo luận về các thách thức và cơ hội của việc sử dụng các phương pháp MTL, chúng tôi so sánh chúng với các giải pháp mô hình đơn nhiệm vụ tương ứng.

Trong phần còn lại của mục, chúng tôi đầu tiên thảo luận về các giai đoạn kỹ thuật dữ liệu và phát triển mô hình một cách riêng biệt. Sau đó, chúng tôi thảo luận về vấn đề cập nhật mô hình ML bằng cách chỉ ra cách các khía cạnh nhất định của vấn đề đặt ra các thách thức khác nhau trong các giai đoạn khác nhau của chu trình ML.

4.1 KỸ THUẬT DỮ LIỆU

Giai đoạn đầu tiên chúng tôi thảo luận là kỹ thuật dữ liệu. Giai đoạn này tập trung vào việc chuẩn bị dữ liệu cần thiết để huấn luyện một mô hình máy học, trong khi chúng tôi có quan tâm đặc biệt đến các thách thức liên quan đến thiếu dữ liệu có nhãn (xem Bảng 2).

Thách thức. Nhu cầu tăng cường dữ liệu có thể phát sinh từ nhiều yếu tố khác nhau, trong đó một trong những yếu tố có vấn đề nhất là thiếu nhãn trong dữ liệu, đặc biệt trong các ứng dụng thực tế nơi dữ liệu có nhãn có thể khan hiếm. Đó là một thực hành phổ biến trong các hệ thống sản xuất NLP để sử dụng các mô hình ngôn ngữ được huấn luyện trước dựa trên transformer bằng cách tinh chỉnh chúng cho các nhiệm vụ downstream cụ thể. Tuy nhiên, nếu có khoảng cách đáng kể giữa nhiệm vụ downstream và các mục tiêu huấn luyện trước, một lượng lớn dữ liệu có nhãn vẫn có thể được yêu cầu để đạt được hiệu suất mục tiêu (Wang et al., 2020). Việc thu thập dữ liệu này liên quan đến sự tham gia tốn kém và mất thời gian của các nhà chú thích và chuyên gia lĩnh vực. Ngoài ra, việc thiếu dữ liệu có phương sai cao dẫn đến một mô hình không thể tổng quát hóa tốt, như việc thích ứng các mô hình ngôn ngữ với các ngôn ngữ ít tài nguyên (Clark et al., 2019a).

Cơ hội. Các thách thức do thiếu dữ liệu có nhãn có thể được giảm thiểu bằng cách sử dụng các phương pháp MTL. Ví dụ, nếu một tập hợp các mô hình đơn nhiệm vụ đang được sử dụng trong một hệ thống sản xuất, việc huấn luyện một mô hình MTL thay thế có thể giúp giảm thiểu sự khan hiếm dữ liệu bằng cách học chung để giải quyết các nhiệm vụ liên quan (Mục 3.2.1). Lợi ích của MTL đã được thảo luận trước đây trong Caruana (1997); Ruder (2017), bao gồm khả năng tăng hiệu quả dữ liệu. Thứ nhất, các nhiệm vụ khác nhau chuyển giao các khía cạnh kiến thức khác nhau cho nhau, tăng cường khả năng thể hiện của biểu diễn đối với văn bản đầu vào, có thể có lợi cho các nhiệm vụ với tập dữ liệu ít tài nguyên (Mục 3.2.1). Tuy nhiên, một số phương pháp MTL có thể hoạt động kém trong môi trường hạn chế tài nguyên do các lựa chọn tối ưu hóa không đầy đủ (Mục 3.2.1). Ngoài ra, sự hiện diện của các mẫu nhiễu khác nhau trong mỗi nhiệm vụ hoạt động như một phương pháp tăng cường dữ liệu ngầm, hiệu quả tăng kích thước mẫu được sử dụng để huấn luyện, và dẫn đến một mô hình mạnh mẽ với các biểu diễn tổng quát hơn (Ruder, 2017). Cuối cùng, việc sử dụng pre-finetuning (Mục 3.2.1) có thể giảm thời gian hội tụ, tiết kiệm tài nguyên tính toán.

4.2 PHÁT TRIỂN MÔ HÌNH

Trong giai đoạn phát triển mô hình, chúng tôi tập trung vào hai nhóm thách thức. Nhóm đầu tiên đề cập đến vấn đề lựa chọn mô hình, bao gồm các vấn đề liên quan đến độ phức tạp mô hình và hạn chế tài nguyên. Nhóm thứ hai của các thách thức liên quan đến các vấn đề trong huấn luyện mô hình, như chi phí tính toán của quy trình huấn luyện và tác động của nó đến môi trường. Chúng tôi giới thiệu độc giả đến (Gupta & Agrawal, 2022) để có tổng quan về các phương pháp cho các mô hình hiệu quả trong văn bản.

Thách thức Lựa chọn Mô hình. Khi lựa chọn một mô hình để xử lý các nhiệm vụ mà người dùng cuối quan tâm, các nhà thực hành thường phải đối mặt với tình huống khó xử liên quan đến sự đánh đổi giữa độ phức tạp mô hình và hiệu suất. Thông thường, các mô hình phức tạp có hiệu suất tốt hơn, nhưng chúng đi kèm với rủi ro làm phức tạp quá mức thiết kế ngay từ đầu, dẫn đến thời gian phát triển dài hơn và thất bại trong triển khai (Haldar et al., 2019). Hơn nữa, chúng có thể không thực tế để sử dụng trong môi trường hạn chế tài nguyên nơi chúng yêu cầu tài nguyên tính toán và bộ nhớ cao.

Cơ hội Lựa chọn Mô hình. Các kiến trúc MTL, được trình bày trong Mục 3.2, có các thuộc tính có thể giảm thiểu các thách thức liên quan đến sự đánh đổi giữa độ phức tạp mô hình và hiệu suất. Ví dụ, hãy xem xét việc thay thế N mô hình đơn nhiệm vụ bằng một mô hình MTL shared encoder duy nhất. Mô hình MTL sẽ có dấu chân bộ nhớ gần N lần nhỏ hơn, vì số lượng tham số cụ thể của nhiệm vụ là không đáng kể so với số lượng tham số được chia sẻ. Việc giảm này dẫn đến phù hợp tốt hơn với môi trường hạn chế bộ nhớ trong khi chỉ có hiệu suất hơi tệ hơn so với các đối tác đơn nhiệm vụ. Tương tự, việc lưu N adapters hoặc một hypernetwork duy nhất hiệu quả hơn nhiều về bộ nhớ so với việc lưu N mô hình đơn nhiệm vụ.

Thách thức Huấn luyện Mô hình. Việc huấn luyện các mô hình máy học đặt ra một số thách thức phải được giải quyết bởi các nhà thực hành. Một trong những thách thức lớn là chi phí kinh tế cao liên quan đến huấn luyện, đó là do tài nguyên tính toán được yêu cầu. Trong lĩnh vực xử lý ngôn ngữ tự nhiên, chi phí huấn luyện mô hình tiếp tục tăng, ngay cả khi chi phí của các phép toán dấu phẩy động riêng lẻ giảm, do các yếu tố như tăng trưởng kích thước tập dữ liệu huấn luyện, số lượng tham số mô hình và số lượng phép toán liên quan đến quá trình huấn luyện (Sharir et al., 2020). Quá trình huấn luyện cũng có tác động đáng kể đến môi trường, dẫn đến tăng tiêu thụ năng lượng và phát thải khí nhà kính (Strubell et al., 2020). Những thách thức này nhấn mạnh nhu cầu giải quyết các tác động kinh tế và môi trường của việc huấn luyện các mô hình máy học.

Cơ hội Huấn luyện Mô hình. Các thách thức tài nguyên tính toán có thể được giảm thiểu trong một số khía cạnh bằng cách sử dụng các phương pháp MTL để giảm chi phí huấn luyện mô hình. Thứ nhất, trong một số trường hợp nhất định, các kích thước tập dữ liệu nhỏ hơn có thể được sử dụng do pre-finetuning hoặc chuyển giao kiến thức giữa các nhiệm vụ liên quan trong quá trình huấn luyện chung của mô hình MTL, dẫn đến huấn luyện hiệu quả hơn về dữ liệu. Thứ hai, mô hình chung hiệu quả hơn về tham số, dẫn đến giảm đáng kể số lượng tham số cần thiết cho nhiều mô hình đơn nhiệm vụ.

Đánh đổi Lựa chọn, Huấn luyện và Suy luận. Số lượng phép toán dấu phẩy động không được giảm trong một số trường hợp, và phụ thuộc vào lựa chọn kiến trúc MTL và bản chất của các nhiệm vụ. Các head cụ thể của nhiệm vụ khác nhau yêu cầu các đầu vào khác nhau nếu các nhiệm vụ thuộc về các lĩnh vực khác nhau hoặc có mã hóa đầu vào khác nhau. Tuy nhiên, nếu các nhiệm vụ thuộc về cùng một lĩnh vực và có cùng mã hóa đầu vào, một phần của phép tính có thể được chia sẻ giữa các head cụ thể của nhiệm vụ. Ví dụ, trong một fully-shared encoder (Mục 3.2.1), phép tính của toàn bộ encoder có thể được chia sẻ, trong khi phép tính trong các head cụ thể của nhiệm vụ là không đáng kể. Tương tự với adapters (Mục 3.2.2) - phần lớn phép tính được chia sẻ, và chỉ có adapters sau đó được cắm động để thực hiện các nhiệm vụ khác nhau trên cùng đầu vào. Cụ thể, lợi ích của việc sử dụng adapters là số lượng tham số có thể huấn luyện nhỏ, nhờ encoder bị đông lạnh, dẫn đến lan truyền ngược gradient nhanh hơn. Mặt khác, một forward pass mất nhiều thời gian hơn so với encoder không có adapters. Do đó, khi các nhiệm vụ không chia sẻ tập dữ liệu, việc sử dụng adapters dẫn đến thời gian suy luận dài hơn so với các đối tác đơn nhiệm vụ. Suy luận AdapterFusion thậm chí còn chậm hơn, vì đầu vào phải đi qua tất cả các adapters có sẵn. LoRA giải quyết vấn đề độ trễ suy luận bằng cách sử dụng tổng hợp tham số.

4.3 TRIỂN KHAI MÔ HÌNH

Trong giai đoạn triển khai mô hình, trọng tâm của chúng tôi là đơn giản hóa việc tích hợp các mô hình ML đã được huấn luyện với các hệ thống ML hiện có đang chạy trong sản xuất, với sự nhấn mạnh đặc biệt vào việc triển khai đơn giản, hợp tác liền mạch và dễ bảo trì.

Thách thức. Thách thức đầu tiên trong triển khai mô hình là chuẩn bị mô hình đã phát triển để sử dụng trong môi trường sản xuất. Các phiên bản đầu của mô hình thường được phát triển bởi các bên liên quan (ví dụ: nhà nghiên cứu ML) khác với những người chịu trách nhiệm triển khai chúng vào sản xuất (ví dụ: kỹ sư ML và DevOps). Điều này có nghĩa là mã mô hình cần được điều chỉnh để đáp ứng các yêu cầu của môi trường sản xuất hoạt động. Những yêu cầu đó thường nghiêm ngặt hơn và khác với những yêu cầu có sẵn trong giai đoạn phát triển, vì vậy điều quan trọng là phải giải quyết các khía cạnh hoạt động như khả năng mở rộng, bảo mật và độ tin cậy. Do đó, mỗi mô hình bổ sung thêm độ phức tạp cho quá trình, cả cho các bên liên quan tham gia và cho cơ sở hạ tầng hệ thống ML và tài nguyên tính toán tại chỗ. Một thách thức khác trong quá trình tích hợp mô hình là kết hợp mô hình vào các pipeline xử lý dữ liệu thực trong sản xuất, cho dù đó là cho các quy trình offline theo batch hay xử lý các yêu cầu người dùng thời gian thực. Trong quá trình huấn luyện mô hình, nhà nghiên cứu thường sử dụng các tập dữ liệu được tiền xử lý và sạch. Tuy nhiên, khi tích hợp mô hình vào sản xuất, nó sẽ được tích hợp vào các pipeline dữ liệu hiện có. Các yêu cầu dữ liệu đầu vào của mô hình càng phức tạp, hoặc càng nhiều mô hình được sử dụng, thì các pipeline xử lý dữ liệu sẽ cần phức tạp hơn. Việc điều chỉnh các mô hình và pipeline dữ liệu hiện có thường yêu cầu hợp tác giữa các bên liên quan hoặc nhóm khác nhau chịu trách nhiệm cho các phần khác nhau của hệ thống ML và/hoặc giai đoạn chu trình ML. Tất cả những yếu tố này trực tiếp tác động đến việc tăng chi phí bảo trì, hoạt động, hỗ trợ và cơ sở hạ tầng.

Cơ hội. Phương pháp MTL đã được trình bày bởi nhóm từ Pinterest, nơi các tác giả huấn luyện một tập hợp universal image embeddings cho ba mô hình khác nhau, điều này đã đơn giản hóa các pipeline triển khai của họ và cải thiện hiệu suất trên các nhiệm vụ riêng lẻ (Zhai et al., 2019). Lợi ích chính là việc sử dụng MTL có thể giảm số lượng tham số cần thiết để hỗ trợ các mô hình khác nhau cần thiết để giải quyết một vấn đề. Điều này dẫn đến các mô hình cụ thể của nhiệm vụ nhỏ hơn và ít mã hơn cần được điều chỉnh cho môi trường sản xuất, giảm overhead của những thay đổi tiềm năng trong các pipeline dữ liệu hiện có. Việc tái sử dụng dữ liệu, mã và mô hình có thể tiết kiệm thời gian và đơn giản hóa quá trình triển khai mô hình. Tiếp theo, thiết kế mô-đun của các kiến trúc MTL làm cho nó dễ làm việc hơn bằng cách cho phép tái sử dụng mã. Ví dụ, kiến trúc fully-shared encoder (được mô tả trong Mục 3.2.1) tái sử dụng encoder giữa nhiều head cụ thể của nhiệm vụ. Hơn nữa, việc đông lạnh shared encoder sẽ cho phép làm việc trên các nhiệm vụ riêng biệt một cách độc lập và đồng thời, làm cho hợp tác liên nhóm dễ dàng hơn và hiệu quả hơn. Ý tưởng này đã được sử dụng trong mô hình MTL HydraNet bởi nhóm Tesla AI (Karpathy, 2021). Tuy nhiên, việc đông lạnh encoder và chỉ cập nhật các head cụ thể của nhiệm vụ có thể làm giảm hiệu suất. Ngoài ra, khái niệm đằng sau AdapterHub (được mô tả trong Mục 3.2.2) được thiết kế để cho phép người dùng chọn từ một tập hợp các mô-đun adapter, kết hợp chúng theo cách họ ưa thích, và chèn hoặc thay thế chúng một cách động vào các mô hình được huấn luyện trước tiên tiến. Để kết luận, bản chất mô-đun của các kiến trúc MTL có tác động tích cực đến việc làm cho việc kết hợp các kiến trúc này vào phần mềm ML dễ dàng hơn, làm cho nó đơn giản hơn để phát triển, hợp tác, cấu hình và tích hợp vào các quy trình triển khai.

4.4 CẬP NHẬT MÔ HÌNH THÔNG QUA NHIỀU GIAI ĐOẠN CHU TRÌNH ML

Thường thì cần thiết phải cập nhật mô hình ML thường xuyên sau khi nó đã được triển khai và đang chạy trong sản xuất, để giữ cho nó phù hợp với những thay đổi gần đây nhất trong dữ liệu và môi trường. Nhu cầu cập nhật mô hình là một trong những yêu cầu quan trọng nhất của các hệ thống sản xuất ML (Pacheco et al., 2018; Abdelkader, 2020; Lakshmanan et al., 2020; Paleyes et al., 2022; Huyen, 2022; Wu & Xie, 2022; Nahar et al., 2022). Trong mục này, chúng tôi thảo luận về các thách thức của việc cập nhật mô hình và cách các phương pháp MTL có thể giảm thiểu những thách thức này. Các thách thức của các giai đoạn khác nhau trong chu trình ML có thể kích hoạt nhu cầu cập nhật mô hình. Đầu tiên, chúng tôi xác định những lần xuất hiện này và thảo luận về các hành động chúng kích hoạt. Sau đó, chúng tôi thảo luận về cách các phương pháp MTL có thể giảm thiểu những thách thức này và chỉ ra các hạn chế hiện tại của những phương pháp này.

Thách thức Cập nhật Mô hình. Distribution shift là một trong những lý do phổ biến cho nhu cầu cập nhật mô hình. Distribution shift đề cập đến những thay đổi quan sát được trong phân phối kết hợp của các biến đầu vào và đầu ra của một mô hình ML (Ditzler et al., 2015). Hai vấn đề phải được giải quyết để giải quyết distribution shift một cách hiệu quả. Thứ nhất, trong giai đoạn giám sát, một cơ chế phải được đặt tại chỗ để phát hiện những thay đổi trong phân phối hoặc sự sụt giảm trong các chỉ số hiệu suất chính, điều này sẽ báo hiệu nhu cầu cập nhật mô hình ML. Thứ hai, trong giai đoạn phát triển mô hình, phải có cách để học liên tục và cập nhật mô hình để đáp ứng với các tín hiệu từ giai đoạn giám sát.

Các yêu cầu kinh doanh mới thường xuất hiện, yêu cầu mô hình có khả năng mới bổ sung cho những khả năng hiện có. Ví dụ, một mô hình nhận dạng thực thể có tên được huấn luyện cho 10 nhãn thực thể trong các bài báo tin tức có thể yêu cầu 5 nhãn mới sau 3 tháng sử dụng. Các yêu cầu mới được giới thiệu trong giai đoạn phân tích kinh doanh, điều này cũng kích hoạt nhu cầu cập nhật mô hình ML. Không giống như các yêu cầu ban đầu trong giai đoạn project scoping, việc thêm các yêu cầu mới nên có thể thực hiện được mà không cần huấn luyện lại toàn bộ mô hình.

Huấn luyện lại định kỳ hoặc theo lịch trình và continual learning là những phương pháp phổ biến nhất để thích ứng mô hình với dữ liệu và yêu cầu mới. Huấn luyện lại định kỳ đề cập đến quá trình huấn luyện lại một mô hình tại một khoảng thời gian được xác định trước, bất kể có thay đổi nào đối với dữ liệu hoặc môi trường hay không. Tần suất cập nhật được xác định trước và thường dựa trên lượng dữ liệu và mức hiệu suất mô hình mong muốn. Việc cân bằng giữa cập nhật mô hình thường xuyên để duy trì hiệu suất tốt và tránh cập nhật quá mức mô hình để giảm thiểu chi phí tính toán là rất quan trọng. Điều quan trọng cần lưu ý là các mô hình khác nhau có thể yêu cầu lịch trình huấn luyện lại khác nhau, làm cho nó trở thành một vấn đề phụ thuộc vào tình huống. Việc tìm ra lịch trình huấn luyện lại tối ưu yêu cầu xem xét cẩn thận các yêu cầu và hoàn cảnh cụ thể của mỗi hệ thống ML. Continual learning, mặt khác, đề cập đến khả năng của một mô hình ML thích ứng với những thay đổi trong dữ liệu và môi trường theo thời gian. Phương pháp này liên quan đến việc giám sát liên tục hiệu suất của mô hình và cập nhật nó khi cần thiết để đảm bảo nó vẫn chính xác và cập nhật. Tần suất cập nhật mô hình trong continual learning được xác định một cách động dựa trên những thay đổi quan sát được trong dữ liệu và môi trường.

Cơ hội Cập nhật Mô hình. Theo Huyen (2022), chúng tôi phân biệt hai loại cập nhật mô hình: data iteration và model iteration. Data iteration đề cập đến việc cập nhật mô hình với dữ liệu mới trong khi giữ kiến trúc mô hình và các tính năng như cũ, trong khi model iteration đề cập đến việc thêm các tính năng mới vào kiến trúc mô hình hiện có hoặc thay đổi kiến trúc mô hình. Để thảo luận về các thách thức và cơ hội của các phương pháp MTL cho việc cập nhật mô hình, chúng tôi xem xét hai kịch bản. Thứ nhất, huấn luyện lại định kỳ được thực hiện mỗi 6 hoặc 12 tháng, với mục tiêu huấn luyện mỗi mô hình để hoạt động tối ưu bằng cách sử dụng tất cả dữ liệu có sẵn. Do chi phí kinh tế cao, chúng tôi giả định rằng điều này không thể được thực hiện thường xuyên hơn. Thứ hai, giữa các lần huấn luyện lại định kỳ, có thể có những tình huống mà data iteration là cần thiết do distribution shift, hoặc model iteration được yêu cầu để mở rộng khả năng mô hình để đáp ứng với yêu cầu kinh doanh mới.

Chúng tôi tin rằng việc kết hợp các phương pháp MTL vào kịch bản cập nhật sẽ thực tế, ngoài những lợi ích đã được thảo luận trong Mục 4.1-4.3. MTL đặc biệt phù hợp cho các kịch bản huấn luyện lại định kỳ nơi mục tiêu là có được một mô hình hiệu suất tốt nhất duy nhất trên tất cả các nhiệm vụ bằng cách sử dụng tất cả dữ liệu có sẵn, thay vì huấn luyện các mô hình riêng lẻ cho mỗi nhiệm vụ. Tuy nhiên, thách thức nằm ở cách các phương pháp MTL có thể quản lý kịch bản thứ hai nơi mô hình MTL phải học các nhiệm vụ hoặc lĩnh vực mới theo cách tuần tự theo thời gian. Kết quả là, cùng một mô hình phải có thể học trong cả cài đặt MTL và CL khi cần thiết, và chúng tôi gọi cài đặt này là Continual MTL (CMTL).

Continual MTL. Các mô hình MTL và CL đều học nhiều nhiệm vụ, tuy nhiên, MTL học chúng đồng thời, trong khi CL học chúng tăng dần. Như đã đề cập trong Mục 2.3, các tác giả của Sun et al. (2020) đã kết hợp CL và MTL để cải thiện thêm việc huấn luyện trước. Mặc dù phương pháp này tăng cường hiệu suất trên các nhiệm vụ downstream, nó không giải quyết kịch bản thực tế trong đó một mô hình MTL nên được cập nhật để hỗ trợ các nhiệm vụ downstream mới hoặc xử lý distribution shifts. Hơn nữa, tổng số các nhiệm vụ tuần tự phải được biết trước để thuật toán xác định lịch trình huấn luyện hiệu quả. Chúng tôi tin rằng những điểm tương đồng giữa các kiến trúc MTL và CL có thể cho phép xây dựng một mô hình CMTL. Ví dụ, hầu hết các kiến trúc MTL trong Mục 3.2 là các kiến trúc MTL dựa trên transformer với các head cụ thể của nhiệm vụ, giống với các kiến trúc cô lập tham số cho cài đặt TIL trong CL (Mục 2.3). Trong TIL, định danh nhiệm vụ có sẵn trong cả huấn luyện và thử nghiệm và được sử dụng để xác định các tham số cụ thể của nhiệm vụ trong các kiến trúc đa đầu, tương tự như các kiến trúc MTL (Ke & Liu, 2022). Sự tương đồng này có thể thấy trong việc sử dụng các kiến trúc adapter (Mục 3.2.2) trong cả MTL (Stickland & Murray, 2019; Pfeiffer et al., 2020c; He et al., 2021) và CL (Ke et al., 2021a;b), cũng như trong việc sử dụng hypernetworks (Mục 3.2.3) trong cả MTL (Pilault et al., 2020; Mahabadi et al., 2021) và CL (Von Oswald et al., 2019; Jin et al., 2021).

10

--- TRANG 11 ---
Bản thảo.

Hình 3: (A). Adapter-BERT (Houlsby et al., 2019) sử dụng adapters trong một lớp transformer (Vaswani et al., 2017). Adapters là các mạng 2 lớp với skip-connections, được thêm hai lần mỗi lớp. Chỉ adapters (màu vàng) và layer norm (màu xanh lá) có thể huấn luyện trong khi các mô-đun khác (màu xám) bị đông lạnh. (B). B-CL thay thế adapters bằng CLA, chứa knowledge-sharing module (KSM) và task-specific module (TSM), cả hai đều có skip-connections. Hình ảnh và chú thích đã sửa đổi được lấy từ (Ke et al., 2021b).

Ví dụ, nếu chúng ta xem xét lớp BERT trong Hình 3, chúng ta có thể quan sát rằng các lớp adapter cho phương pháp MTL trong Hình 3(A) ở cùng vị trí với các CL adapters trong Hình 3(B) (Ke et al., 2021b). Để chuyển từ MTL sang CL, chúng ta chỉ cần thay đổi adapters. Chúng tôi tin rằng sự tương đồng này có thể là một hướng đầy hứa hẹn cho nghiên cứu thêm về việc phát triển một mô hình CMTL, nhưng đánh giá đúng đắn sẽ không thể thực hiện được mà không có một benchmark tốt.

Cuối cùng, chúng tôi tin rằng một benchmark mô tả chính xác các thách thức của các hệ thống thực tế có thể có lợi cho cả nhà nghiên cứu và nhà thực hành để đánh giá các mô hình CMTL một cách hiệu quả. Để thực hiện điều này, chúng tôi đề xuất kết hợp và sắp xếp thời gian các nhiệm vụ để mô phỏng các kịch bản huấn luyện lại định kỳ và CL. Benchmark có thể được tinh chỉnh thêm để phản ánh tần suất khác nhau của huấn luyện lại định kỳ, cũng như tần suất của các nhiệm vụ đến và distribution shifts giữa các giai đoạn huấn luyện lại. Sự biến đổi trong những kịch bản này có thể đại diện tốt hơn cho các tình huống thực tế, nơi một mô hình CMTL đơn giản hơn có thể đủ trong một số trường hợp, trong khi các mô hình CMTL tiên tiến hơn sẽ cần thiết để xử lý những thay đổi môi trường trong các tình huống khác.

5 KẾT LUẬN

Trong bài báo này, chúng tôi đã xem xét các phương pháp MTL dựa trên transformer trong NLP và khám phá các thách thức và cơ hội của những phương pháp đó trong bối cảnh chu trình ML. Chúng tôi đã thảo luận về cách MTL có thể là một giải pháp có thể giải quyết một số thách thức chính trong các giai đoạn kỹ thuật dữ liệu, phát triển mô hình, triển khai và giám sát của chu trình ML, so với việc sử dụng nhiều mô hình đơn nhiệm vụ.

Chúng tôi cũng đã thảo luận về các cơ hội áp dụng MTL để giảm thiểu các thách thức liên quan đến việc cập nhật mô hình do distribution shifts hoặc các yêu cầu thực tế đang phát triển, nơi khả năng học nhiều nhiệm vụ đồng thời có thể được tận dụng để cập nhật định kỳ mô hình để đáp ứng với những thay đổi trong dữ liệu và môi trường. Tuy nhiên, chúng tôi cũng thừa nhận những hạn chế của các phương pháp MTL hiện tại trong việc xử lý cập nhật tuần tự, nơi CL được yêu cầu. Để giải quyết điều này, chúng tôi đã đề xuất khái niệm CMTL, nhằm kết hợp lợi ích của MTL và CL trong một mô hình duy nhất. Chúng tôi đã thúc đẩy việc tạo ra một benchmark để đánh giá đúng đắn các mô hình CMTL, một benchmark đại diện tốt hơn cho các thách thức của các hệ thống sản xuất có thể hướng dẫn việc phát triển những mô hình đó.

Tóm lại, các phương pháp MTL cung cấp nhiều cơ hội để cải thiện hiệu quả và hiệu suất của các hệ thống ML trong các giai đoạn khác nhau của chu trình ML điển hình. Chúng tôi tin rằng MTL sẽ trở thành một phần quan trọng trong hộp công cụ của các nhà thực hành tìm cách giải quyết các thách thức trong hệ thống ML của họ như đã được nêu bật trong khảo sát này.

TÀI LIỆU THAM KHẢO

Hala Abdelkader. Towards robust production machine learning systems: Managing dataset shift. In 2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 1164–1166. IEEE, 2020.

11

--- TRANG 12 ---
Bản thảo.

Stanley Ebhohimhen Abhadiomhen, Royransom Chimela Nzeh, Ernest Domanaanmwi Ganaa, Honour Chika Nwagwu, George Emeka Okereke, and Sidheswar Routray. Supervised shallow multi-task learning: analysis of methods. Neural Processing Letters, 54(3):2491–2508, 2022.

Armen Aghajanyan, Anchit Gupta, Akshat Shrivastava, Xilun Chen, Luke Zettlemoyer, and Sonal Gupta. Muppet: Massive multi-task representations with pre-finetuning. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 5799–5811, 2021.

Vamsi Aribandi, Yi Tay, Tal Schuster, Jinfeng Rao, Huaixiu Steven Zheng, Sanket Vaibhav Mehta, Honglei Zhuang, Vinh Q Tran, Dara Bahri, Jianmo Ni, et al. Ext5: Towards extreme multi-task scaling for transfer learning. In International Conference on Learning Representations, 2021.

Rob Ashmore, Radu Calinescu, and Colin Paterson. Assuring the machine learning lifecycle: Desiderata, methods, and challenges. ACM Computing Surveys (CSUR), 54(5):1–39, 2021.

Hangbo Bao, Li Dong, Furu Wei, Wenhui Wang, Nan Yang, Xiaodong Liu, Yu Wang, Jianfeng Gao, Songhao Piao, Ming Zhou, and Hsiao-Wuen Hon. UniLMv2: Pseudo-masked language models for unified language model pre-training. In Hal Daumé III and Aarti Singh (eds.), Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 642–652. PMLR, 13–18 Jul 2020. URL https://proceedings.mlr.press/v119/bao20a.html.

Lucas Bernardi, Themistoklis Mavridis, and Pablo Estevez. 150 successful machine learning models: 6 lessons learned at booking. com. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining, pp. 1743–1751, 2019.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. CoRR, abs/2005.14165, 2020. URL https://arxiv.org/abs/2005.14165.

Rich Caruana. Multitask learning. Machine learning, 28(1):41–75, 1997.

Shijie Chen, Yu Zhang, and Qiang Yang. Multi-task learning in natural language processing: An overview. arXiv preprint arXiv:2109.09138, 2021.

Zhiyuan Chen and Bing Liu. Lifelong machine learning. Synthesis Lectures on Artificial Intelligence and Machine Learning, 12(3):1–207, 2018.

Michael Chui, Bryce Hall, Helen Mayhew, and Alex Singla. The state of ai in 2022–and a half decade in review, Dec 2022. URL https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-in-2022-and-a-half-decade-in-review. Accessed: 2023-01-15.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022.

Christopher Clark, Mark Yatskar, and Luke Zettlemoyer. Don't take the easy way out: Ensemble based methods for avoiding known dataset biases. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 4069–4082, Hong Kong, China, November 2019a. Association for Computational Linguistics. doi: 10.18653/v1/D19-1418. URL https://aclanthology.org/D19-1418.

Kevin Clark, Minh-Thang Luong, Urvashi Khandelwal, Christopher D. Manning, and Quoc V. Le. Bam! born-again multi-task networks for natural language understanding. CoRR, abs/1907.04829, 2019b. URL http://arxiv.org/abs/1907.04829.

Michael Crawshaw. Multi-task learning with deep neural networks: A survey. arXiv preprint arXiv:2009.09796, 2020.

Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Aleš Leonardis, Gregory Slabaugh, and Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEE transactions on pattern analysis and machine intelligence, 44(7):3366–3385, 2021.

12

--- TRANG 13 ---
Bản thảo.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 4171–4186, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https://aclanthology.org/N19-1423.

Jie Ding, Vahid Tarokh, and Yuhong Yang. Model selection techniques: An overview. IEEE Signal Processing Magazine, 35(6):16–34, 2018.

Gregory Ditzler, Manuel Roveri, Cesare Alippi, and Robi Polikar. Learning in nonstationary environments: A survey. IEEE Computational Intelligence Magazine, 10(4):12–25, 2015.

Ana González-Garduño and Anders Søgaard. Learning to predict readability using eye-movement data from natives and learners. Proceedings of the AAAI Conference on Artificial Intelligence, 32(1), Apr. 2018. doi: 10.1609/aaai.v32i1.11978. URL https://ojs.aaai.org/index.php/AAAI/article/view/11978.

Han Guo, Ramakanth Pasunuru, and Mohit Bansal. Autosem: Automatic task selection and mixing in multi-task learning. CoRR, abs/1904.04153, 2019. URL http://arxiv.org/abs/1904.04153.

Michelle Guo, Albert Haque, De-An Huang, Serena Yeung, and Li Fei-Fei. Dynamic task prioritization for multitask learning. In Proceedings of the European Conference on Computer Vision (ECCV), September 2018.

Manish Gupta and Puneet Agrawal. Compression of deep learning models for text: A survey. ACM Transactions on Knowledge Discovery from Data (TKDD), 16(4):1–55, 2022.

David Ha, Andrew Dai, and Quoc V. Le. Hypernetworks, 2016. URL https://arxiv.org/abs/1609.09106.

Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tao Xu, Shulin Yang, Huizhong Duan, Qing Zhang, Nick Barrow-Williams, Bradley C Turnbull, Brendan M Collins, et al. Applying deep learning to airbnb search. In proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & Data Mining, pp. 1927–1935, 2019.

Xu Han, Weilin Zhao, Ning Ding, Zhiyuan Liu, and Maosong Sun. PTR: prompt tuning with rules for text classification. CoRR, abs/2105.11259, 2021. URL https://arxiv.org/abs/2105.11259.

Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham Neubig. Towards a unified view of parameter-efficient transfer learning. arXiv preprint arXiv:2110.04366, 2021.

Yun He, Steven Zheng, Yi Tay, Jai Gupta, Yu Du, Vamsi Aribandi, Zhe Zhao, Yaguang Li, Zhao Chen, Donald Metzler, Heng-Tze Cheng, and Ed H. Chi. HyperPrompt: Prompt-based task-conditioning of transformers. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (eds.), Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pp. 8678–8690. PMLR, 17–23 Jul 2022. URL https://proceedings.mlr.press/v162/he22f.html.

Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. Parameter-efficient transfer learning for nlp. In International Conference on Machine Learning, pp. 2790–2799. PMLR, 2019.

Yen-Chang Hsu, Yen-Cheng Liu, Anita Ramasamy, and Zsolt Kira. Re-evaluating continual learning scenarios: A categorization and case for strong baselines. arXiv preprint arXiv:1810.12488, 2018.

Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models, 2021. URL https://arxiv.org/abs/2106.09685.

Chip Huyen. Designing Machine Learning Systems. " O'Reilly Media, Inc.", 2022.

Sébastien Jean, Orhan Firat, and Melvin Johnson. Adaptive scheduling for multi-task learning. CoRR, abs/1909.06434, 2019. URL http://arxiv.org/abs/1909.06434.

Xisen Jin, Bill Yuchen Lin, Mohammad Rostami, and Xiang Ren. Learn continually, generalize rapidly: lifelong knowledge accumulation for few-shot learning. arXiv preprint arXiv:2104.08808, 2021.

Lukasz Kaiser, Aidan N. Gomez, Noam Shazeer, Ashish Vaswani, Niki Parmar, Llion Jones, and Jakob Uszkoreit. One model to learn them all, 2017. URL https://arxiv.org/abs/1706.05137.

13

--- TRANG 14 ---
Bản thảo.

Andrej Karpathy. HydraNets - Tesla AI Day 2021, 8 2021. URL https://www.youtube.com/watch?t=4284&v=j0z4FweCy4M&feature=youtu.be. Accessed: 2023-02-15.

Zixuan Ke and Bing Liu. Continual learning of natural language processing tasks: A survey. arXiv preprint arXiv:2211.12701, 2022.

Zixuan Ke, Bing Liu, Nianzu Ma, Hu Xu, and Lei Shu. Achieving forgetting prevention and knowledge transfer in continual learning. Advances in Neural Information Processing Systems, 34:22443–22456, 2021a.

Zixuan Ke, Hu Xu, and Bing Liu. Adapting bert for continual learning of a sequence of aspect sentiment classification tasks. arXiv preprint arXiv:2112.03271, 2021b.

Alex Kendall, Yarin Gal, and Roberto Cipolla. Multi-task learning using uncertainty to weigh losses for scene geometry and semantics. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018.

Been Kim and Finale Doshi-Velez. Machine learning techniques for accountability. AI Magazine, 42(1):47–52, 2021.

Frederic Kirstein, Jan Philip Wahle, Terry Ruas, and Bela Gipp. Analyzing multi-task learning for abstractive text summarization. arXiv preprint arXiv:2210.14606, 2022.

Valliappa Lakshmanan, Sara Robinson, and Michael Munn. Machine learning design patterns. O'Reilly Media, 2020.

Hae Beom Lee, Eunho Yang, and Sung Ju Hwang. Deep asymmetric multi-task feature learning. In Jennifer Dy and Andreas Krause (eds.), Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp. 2956–2964. PMLR, 10–15 Jul 2018. URL https://proceedings.mlr.press/v80/lee18d.html.

Brian Lester, Rami Al-Rfou, and Noah Constant. The power of scale for parameter-efficient prompt tuning. CoRR, abs/2104.08691, 2021. URL https://arxiv.org/abs/2104.08691.

Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 7871–7880, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.703. URL https://aclanthology.org/2020.acl-main.703.

Xiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation. arXiv preprint arXiv:2101.00190, 2021.

Xi Lin, Hui-Ling Zhen, Zhenhua Li, Qing-Fu Zhang, and Sam Kwong. Pareto multi-task learning. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/file/685bfde03eb646c27ed565881917c71c-Paper.pdf.

Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. CoRR, abs/2107.13586, 2021a. URL https://arxiv.org/abs/2107.13586.

Shengchao Liu, Yingyu Liang, and Anthony Gitter. Loss-balanced task weighting to reduce negative transfer in multi-task learning. Proceedings of the AAAI Conference on Artificial Intelligence, 33(01):9977–9978, Jul. 2019a. doi: 10.1609/aaai.v33i01.33019977. URL https://ojs.aaai.org/index.php/AAAI/article/view/5125.

Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. GPT understands, too. CoRR, abs/2103.10385, 2021b. URL https://arxiv.org/abs/2103.10385.

Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao. Multi-task deep neural networks for natural language understanding, 2019b. URL https://arxiv.org/abs/1901.11504.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized BERT pretraining approach. CoRR, abs/1907.11692, 2019c. URL http://arxiv.org/abs/1907.11692.

14

--- TRANG 15 ---
Bản thảo.

Mingsheng Long, ZHANGJIE CAO, Jianmin Wang, and Philip S Yu. Learning multiple tasks with multilinear relationship networks. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/file/03e0704b5690a2dee1861dc3ad3316c9-Paper.pdf.

David Lopez-Paz and Marc' Aurelio Ranzato. Gradient episodic memory for continual learning. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/file/f87522788a2be2d171666752f97ddebb-Paper.pdf.

Rabeeh Karimi Mahabadi, Sebastian Ruder, Mostafa Dehghani, and James Henderson. Parameter-efficient multi-task fine-tuning for transformers via shared hypernetworks, 2021. URL https://arxiv.org/abs/2106.04489.

Gary E Marchant. The growing gap between emerging technologies and the law. Springer, 2011.

Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, and Richard Socher. The natural language decathlon: Multi-task learning as question answering. arXiv preprint arXiv:1806.08730, 2018.

Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. A survey on bias and fairness in machine learning. ACM Computing Surveys (CSUR), 54(6):1–35, 2021.

Nadia Nahar, Shurui Zhou, Grace Lewis, and Christian Kästner. Collaboration challenges in building ml-enabled systems: Communication, documentation, engineering, and process. In Proceedings of the 44th International Conference on Software Engineering, pp. 413–425, 2022.

Fannia Pacheco, Ernesto Exposito, Mathieu Gineste, Cedric Baudoin, and Jose Aguilar. Towards the deployment of machine learning solutions in network traffic classification: A systematic survey. IEEE Communications Surveys & Tutorials, 21(2):1988–2014, 2018.

Andrei Paleyes, Raoul-Gabriel Urma, and Neil D Lawrence. Challenges in deploying machine learning: a survey of case studies. ACM Computing Surveys, 55(6):1–29, 2022.

Mihir Parmar, Swaroop Mishra, Mirali Purohit, Man Luo, Murad Mohammad, and Chitta Baral. In-BoXBART: Get instructions into biomedical multi-task learning. In Findings of the Association for Computational Linguistics: NAACL 2022, pp. 112–128, Seattle, United States, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.findings-naacl.10. URL https://aclanthology.org/2022.findings-naacl.10.

Lucas Pascal, Pietro Michiardi, Xavier Bost, Benoit Huet, and Maria A. Zuluaga. Maximum roaming multi-task learning. Proceedings of the AAAI Conference on Artificial Intelligence, 35(10):9331–9341, May 2021. doi: 10.1609/aaai.v35i10.17125. URL https://ojs.aaai.org/index.php/AAAI/article/view/17125.

Zhongyi Pei, Lin Liu, Chen Wang, and Jianmin Wang. Requirements engineering for machine learning: A review and reflection. In 2022 IEEE 30th International Requirements Engineering Conference Workshops (REW), pp. 166–175. IEEE, 2022.

Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. Language models as knowledge bases? In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 2463–2473, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1250. URL https://aclanthology.org/D19-1250.

Jonas Pfeiffer, Aishwarya Kamath, Andreas Rückléc, Kyunghyun Cho, and Iryna Gurevych. Adapterfusion: Non-destructive task composition for transfer learning. arXiv preprint arXiv:2005.00247, 2020a.

Jonas Pfeiffer, Andreas Rückléc, Clifton Poth, Aishwarya Kamath, Ivan Vulić, Sebastian Ruder, Kyunghyun Cho, and Iryna Gurevych. Adapterhub: A framework for adapting transformers. arXiv preprint arXiv:2007.07779, 2020b.

Jonas Pfeiffer, Ivan Vulic, Iryna Gurevych, and Sebastian Ruder. MAD-X: an adapter-based framework for multi-task cross-lingual transfer. CoRR, abs/2005.00052, 2020c. URL https://arxiv.org/abs/2005.00052.

Jonathan Pilault, Amine Elhattami, and Christopher Pal. Conditionally adaptive multi-task learning: Improving transfer learning in nlp using fewer parameters & less data, 2020. URL https://arxiv.org/abs/2009.09139.

15

--- TRANG 16 ---
Bản thảo.

Eugenia Politou, Efthimios Alepis, and Constantinos Patsakis. Forgetting personal data and revoking consent under the gdpr: Challenges and proposed solutions. Journal of cybersecurity, 4(1):tyy001, 2018.

Neoklis Polyzotis, Sudip Roy, Steven Euijong Whang, and Martin Zinkevich. Data lifecycle challenges in production machine learning: a survey. ACM SIGMOD Record, 47(2):17–28, 2018.

Subhojeet Pramanik, Priyanka Agrawal, and Aman Hussain. Omninet: A unified architecture for multi-modal multi-task learning. CoRR, abs/1907.07804, 2019. URL http://arxiv.org/abs/1907.07804.

Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, et al. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 21(140):1–67, 2020.

Sylvestre-Alvise Rebuffi, Hakan Bilen, and Andrea Vedaldi. Learning multiple visual domains with residual adapters. Advances in neural information processing systems, 30, 2017.

Kui Ren, Tianhang Zheng, Zhan Qin, and Xue Liu. Adversarial attacks and defenses in deep learning. Engineering, 6(3):346–360, 2020.

Cedric Renggli, Bojan Karlaš, Bolin Ding, Feng Liu, Kevin Schawinski, Wentao Wu, and Ce Zhang. Continuous integration of machine learning models with ease. ml/ci: Towards a rigorous yet practical treatment. Proceedings of Machine Learning and Systems, 1:322–333, 2019.

Ishai Rosenberg, Asaf Shabtai, Yuval Elovici, and Lior Rokach. Adversarial machine learning attacks and defense methods in the cyber security domain. ACM Computing Surveys (CSUR), 54(5):1–36, 2021.

Sebastian Ruder. An overview of multi-task learning in deep neural networks. arXiv preprint arXiv:1706.05098, 2017.

Sebastian Ruder, Joachim Bingel, Isabelle Augenstein, and Anders Søgaard. Sluice networks: Learning what to share between loosely related tasks. arXiv preprint arXiv:1705.08142, 2, 2017.

Rahul Manohar Samant, Mrinal Bachute, Shilpa Gite, and Ketan Kotecha. Framework for deep learning-based language models using multi-task learning in natural language understanding: A systematic literature review and future directions. IEEE Access, 2022.

Nithya Sambasivan, Shivani Kapania, Hannah Highfill, Diana Akrong, Praveen Paritosh, and Lora M Aroyo. "everyone wants to do the model work, not the data work": Data cascades in high-stakes ai. In proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, pp. 1–15, 2021.

Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Tali Bers, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander M. Rush. Multitask prompted training enables zero-shot task generalization, 2021. URL https://arxiv.org/abs/2110.08207.

Tim Schröder and Michael Schulz. Monitoring machine learning models: a categorization of challenges and methods. Data Science and Management, 5(3):105–116, 2022.

David Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, Michael Young, Jean-Francois Crespo, and Dan Dennison. Hidden technical debt in machine learning systems. Advances in neural information processing systems, 28, 2015.

Joan Serra, Didac Suris, Marius Miron, and Alexandros Karatzoglou. Overcoming catastrophic forgetting with hard attention to the task. In Jennifer Dy and Andreas Krause (eds.), Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp. 4548–4557. PMLR, 10–15 Jul 2018. URL https://proceedings.mlr.press/v80/serra18a.html.

Or Sharir, Barak Peleg, and Yoav Shoham. The cost of training nlp models: A concise overview. arXiv preprint arXiv:2004.08900, 2020.

16

--- TRANG 17 ---
Bản thảo.

Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace, and Sameer Singh. AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 4222–4235, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.346. URL https://aclanthology.org/2020.emnlp-main.346.

Ayan Sinha, Zhao Chen, Vijay Badrinarayanan, and Andrew Rabinovich. Gradient adversarial training of neural networks. CoRR, abs/1806.08028, 2018. URL http://arxiv.org/abs/1806.08028.

Trevor Standley, Amir Zamir, Dawn Chen, Leonidas Guibas, Jitendra Malik, and Silvio Savarese. Which tasks should be learned together in multi-task learning? In Hal Daumé III and Aarti Singh (eds.), Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 9120–9132. PMLR, 13–18 Jul 2020. URL https://proceedings.mlr.press/v119/standley20a.html.

Asa Cooper Stickland and Iain Murray. Bert and pals: Projected attention layers for efficient adaptation in multi-task learning. In International Conference on Machine Learning, pp. 5986–5995. PMLR, 2019.

Emma Strubell, Ananya Ganesh, and Andrew McCallum. Energy and policy considerations for modern deep learning research. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pp. 13693–13696, 2020.

Ruo-Yu Sun. Optimization for deep learning: An overview. Journal of the Operations Research Society of China, 8(2):249–294, 2020.

Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Hao Tian, Hua Wu, and Haifeng Wang. Ernie 2.0: A continual pre-training framework for language understanding. In Proceedings of the AAAI conference on artificial intelligence, volume 34, pp. 8968–8975, 2020.

Hironori Takeuchi and Shuichiro Yamamoto. Business analysis method for constructing business–ai alignment model. Procedia Computer Science, 176:1312–1321, 2020.

Yi Tay, Zhe Zhao, Dara Bahri, Donald Metzler, and Da-Cheng Juan. Hypergrid: Efficient multi-task transformers with grid-wise decomposable hyper projections. CoRR, abs/2007.05891, 2020. URL https://arxiv.org/abs/2007.05891.

Kim-Han Thung and Chong-Yaw Wee. A brief review on multi-task learning. Multimedia Tools and Applications, 77(22):29705–29725, 2018.

Richa Upadhyay, Ronald Phlypo, Rajkumar Saini, and Marcus Liwicki. Sharing to learn and learning to share-fitting together meta-learning, multi-task learning, and transfer learning: A meta review. arXiv preprint arXiv:2111.12146, 2021.

Partoo Vafaeikia, Khashayar Namdar, and Farzad Khalvati. A brief review of deep multi-task learning and auxiliary task learning. arXiv preprint arXiv:2007.01126, 2020.

Simon Vandenhende, Stamatios Georgoulis, Wouter Van Gansbeke, Marc Proesmans, Dengxin Dai, and Luc Van Gool. Multi-task learning for dense prediction tasks: A survey. IEEE transactions on pattern analysis and machine intelligence, 2021.

Manasi Vartak and Samuel Madden. Modeldb: Opportunities and challenges in managing machine learning models. IEEE Data Eng. Bull., 41(4):16–25, 2018.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.

Johannes Von Oswald, Christian Henning, João Sacramento, and Benjamin F Grewe. Continual learning with hypernetworks. arXiv preprint arXiv:1906.00695, 2019.

Tu Vu, Tong Wang, Tsendsuren Munkhdalai, Alessandro Sordoni, Adam Trischler, Andrew Mattarella-Micke, Subhransu Maji, and Mohit Iyyer. Exploring and predicting transferability across NLP tasks. CoRR, abs/2005.00770, 2020. URL https://arxiv.org/abs/2005.00770.

Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman. Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv preprint arXiv:1804.07461, 2018.

17

--- TRANG 18 ---
Bản thảo.

Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. Superglue: A stickier benchmark for general-purpose language understanding systems. Advances in neural information processing systems, 32, 2019.

Liwen Wang, Rumei Li, Yang Yan, Yuanmeng Yan, Sirui Wang, Wei Wu, and Weiran Xu. Instructionner: A multi-task instruction-based generative framework for few-shot ner, 2022. URL https://arxiv.org/abs/2203.03903.

Sinong Wang, Madian Khabsa, and Hao Ma. To pretrain or not to pretrain: Examining the benefits of pretraining on resource rich tasks. arXiv preprint arXiv:2006.08671, 2020.

Steven Euijong Whang, Yuji Roh, Hwanjun Song, and Jae-Gil Lee. Data collection and quality challenges in deep learning: A data-centric ai perspective. The VLDB Journal, pp. 1–23, 2023.

Joseph Worsham and Jugal Kalita. Multi-task learning for natural language processing in the 2020s: where are we going? Pattern Recognition Letters, 136:120–126, 2020.

Nan Wu and Yuan Xie. A survey of machine learning for computer architecture and systems. ACM Computing Surveys (CSUR), 55(3):1–39, 2022.

Sen Wu, Hongyang R. Zhang, and Christopher Ré. Understanding and improving information transfer in multi-task learning, 2020. URL https://arxiv.org/abs/2005.00944.

Chenyang Yang, Rachel Brower-Sinning, Grace A Lewis, Christian Kästner, and Tongshuang Wu. Capabilities for better ml engineering. arXiv preprint arXiv:2211.06409, 2022.

Yongxin Yang and Timothy M. Hospedales. Trace norm regularised deep multi-task learning. CoRR, abs/1606.04038, 2016. URL http://arxiv.org/abs/1606.04038.

Amir R. Zamir, Alexander Sax, William Shen, Leonidas J. Guibas, Jitendra Malik, and Silvio Savarese. Taskonomy: Disentangling task transfer learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018.

Andrew Zhai, Hao-Yu Wu, Eric Tzeng, Dong Huk Park, and Charles Rosenberg. Learning a unified embedding for visual search at pinterest. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 2412–2420, 2019.

Yu Zhang and Qiang Yang. A survey on multi-task learning. arXiv preprint arXiv:1707.08114, 2017.

Yu Zhang and Qiang Yang. An overview of multi-task learning. National Science Review, 5(1):30–43, 2018.

Zhihan Zhang, Wenhao Yu, Mengxia Yu, Zhichun Guo, and Meng Jiang. A survey of multi-task learning in natural language processing: Regarding task relatedness and training methods. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pp. 943–956, Dubrovnik, Croatia, May 2023. Association for Computational Linguistics. URL https://aclanthology.org/2023.eacl-main.66.

Feng Zheng, Cheng Deng, Xing Sun, Xinyang Jiang, Xiaowei Guo, Zongqiao Yu, Feiyue Huang, and Rongrong Ji. Pyramidal person re-identification via multi-loss dynamic training. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2019.

Wenxuan Zhou. An overview of models and methods for multi-task learning, Oct 2019. URL https://shanzhenren.github.io/csci-699-replnlp-2019fall/lectures/W6-L1-Multi_Task_Learning.pdf.

A CHI TIẾT BỔ SUNG CHO CÁC KHẢO SÁT LIÊN QUAN

A.1 CÁC KHẢO SÁT MULTI-TASK LEARNING

Ý tưởng về MTL đã được khám phá trong nhiều nghiên cứu. Trong mục này, chúng tôi cung cấp tổng quan về công trình liên quan trong các khảo sát MTL và giải quyết các khía cạnh MTL khác nhau đã được thảo luận. Trong Bảng 3, chúng tôi liệt kê các khía cạnh nhất định và chỉ ra khảo sát mà chúng đã được thảo luận. Trong phần còn lại của mục, chúng tôi chỉ đề cập đến các khảo sát liên quan và xem xét các khía cạnh MTL riêng lẻ (được hiển thị in đậm) chi tiết hơn.

18

--- TRANG 19 ---
Bản thảo.

Bảng 3: Các khía cạnh được thảo luận theo khảo sát MTL. Các khía cạnh được chỉ ra bằng chữ in đậm.

Năm Khảo sát MTL
2017 1- (Ruder, 2017) 2- (Zhang & Yang, 2017)
2018 3- (Zhang & Yang, 2018) 4- (Thung & Wee, 2018)
2019 5- (Zhou, 2019)
2020 6- (Vafaeikia et al., 2020) 7- (Worsham & Kalita, 2020) 8- (Crawshaw, 2020)
2021 9- (Vandenhende et al., 2021) 10- (Chen et al., 2021) 11- (Upadhyay et al., 2021)
2022 12- (Samant et al., 2022) 13- (Abhadiomhen et al., 2022)
2023 14- (Zhang et al., 2023)

Khía cạnh \Khảo sát 1 2 3 4 5 6 7 8 9 10 11 12 13 14
Mô hình Tính toán
ML Truyền thống ✓ ✓ ✓ ✓ ✓
Deep Learning ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Loại Học
Joint Learning ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Auxiliary Learning ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Kiến trúc
Taxonomy ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Learning to Share ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Universal Models ✓ ✓ ✓ ✓ ✓
Tối ưu hóa
Loss Weighting ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Regularization ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Task Scheduling ✓ ✓ ✓ ✓ ✓ ✓
Gradient Modulation ✓ ✓ ✓ ✓ ✓
Knowledge Distillation ✓ ✓ ✓ ✓
Multi-Objective Optimization ✓ ✓ ✓
Học mối quan hệ nhiệm vụ
Task Grouping ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Relationships Transfer ✓ ✓ ✓ ✓ ✓
Task Embeddings ✓ ✓
Mức độ Giám sát
Supervised Learning ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Semi-supervised Learning ✓ ✓ ✓ ✓ ✓
Self-supervised Learning ✓ ✓ ✓ ✓ ✓ ✓
Kết nối với Paradigm Học
Reinforcement Learning ✓ ✓ ✓ ✓ ✓ ✓
Transfer Learning ✓ ✓ ✓
Domain Adaptation ✓ ✓ ✓
Meta-Learning ✓ ✓ ✓
Active Learning ✓ ✓
Online Learning ✓ ✓ ✓
Continual Learning
Benchmarks
Benchmark Overview ✓ ✓ ✓ ✓ ✓ ✓ ✓
Model Comparison ✓ ✓ ✓ ✓ ✓ ✓ ✓
Lĩnh vực Ứng dụng
Natural Language Processing ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Computer Vision ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓
Healthcare ✓ ✓ ✓
Bioinformatics ✓ ✓ ✓ ✓ ✓
Khác ✓ ✓ ✓ ✓ ✓

Nhiều lĩnh vực ứng dụng đã được nghiên cứu trong công trình trước đây, từ các khảo sát bao gồm nhiều lĩnh vực (Ruder, 2017; Zhang & Yang, 2017; 2018; Thung & Wee, 2018; Vafaeikia et al., 2020; Crawshaw, 2020; Upadhyay et al., 2021; Abhadiomhen et al., 2022), đến những khảo sát dành riêng cho một lĩnh vực cụ thể, như thị giác máy tính (Vandenhende et al., 2021) hoặc xử lý ngôn ngữ tự nhiên (Zhou, 2019; Worsham & Kalita, 2020; Chen et al., 2021; Samant et al., 2022; Zhang et al., 2023). Cả mô hình tính toán ML truyền thống và deep learning đều đã được nghiên cứu. ML truyền thống được thảo luận chủ yếu trong các nghiên cứu cũ hơn, trong khi deep learning được đại diện trong tất cả trừ một nghiên cứu. Hơn nữa, hầu hết các công trình trước đây đã cung cấp tổng quan về các benchmark cho lĩnh vực cụ thể (McCann et al., 2018; Wang et al., 2019), và so sánh các mô hình trên chúng.

19

--- TRANG 20 ---
Bản thảo.

Loại học. Hai loại học chủ yếu được thảo luận. Thứ nhất, joint learning được sử dụng trong cài đặt MTL nơi tất cả các nhiệm vụ đều quan trọng như nhau (Kendall et al., 2018; Liu et al., 2019b). Ở đây, mục tiêu là đạt được hiệu suất ngang bằng so với các đối tác single-task learning (STL) của chúng. Thứ hai, auxiliary learning được sử dụng khi có một nhiệm vụ chính duy nhất hoặc một tập hợp chúng, trong khi các nhiệm vụ phụ trợ chỉ được sử dụng để cải thiện hiệu suất của các nhiệm vụ chính (González-Garduño & Søgaard, 2018; Wang et al., 2022). Mặc dù có thể phân biệt giữa hai loại học, đôi khi auxiliary learning không được phân biệt với joint learning.

Kiến trúc. Các kiến trúc mô hình MTL nằm trong số những khía cạnh được thảo luận nhiều nhất của MTL và là một trong những khía cạnh đầu tiên được giải quyết trong công trình trước đây. Việc phân biệt giữa chia sẻ tham số cứng và mềm (Ruder, 2017) là phân loại kiến trúc được sử dụng nhiều nhất. Trong các khảo sát gần đây, phương pháp chia sẻ tham số giữa các nhiệm vụ đã được cải thiện, dẫn đến việc tinh chỉnh các phân loại để phân loại kiến trúc chính xác hơn (Crawshaw, 2020; Chen et al., 2021). Tiếp theo, một số kiến trúc MTL được phân loại là các phương pháp learning-to-share (Ruder et al., 2017). Những công trình đó lập luận rằng tốt hơn là học chia sẻ tham số trong các kiến trúc cho MTL thay vì thiết kế thủ công nơi chia sẻ xảy ra, vì nó cung cấp một giải pháp thích ứng hơn để phù hợp với sự tương đồng của nhiệm vụ ở các phần khác nhau của mạng. Ngoài ra, một số kiến trúc MTL được phân loại là universal models có thể xử lý nhiều modality, lĩnh vực và nhiệm vụ với một mô hình duy nhất (Kaiser et al., 2017; Pramanik et al., 2019).

Tối ưu hóa. Các kỹ thuật tối ưu hóa cho các kiến trúc MTL cũng được thảo luận chi tiết. Để bắt đầu, phương pháp phổ biến nhất để giảm thiểu các thách thức MTL là loss weighting. Việc tính toán trọng số của các loss cụ thể của nhiệm vụ là rất quan trọng, vì nó giúp tối ưu hóa hàm loss và xem xét tầm quan trọng tương đối của mỗi nhiệm vụ. Có nhiều phương pháp khác nhau để tính toán trọng số loss một cách động, bao gồm tính trọng số theo uncertainty (Kendall et al., 2018), tốc độ học (Liu et al., 2019a; Zheng et al., 2019), hoặc hiệu suất (Guo et al., 2018; Jean et al., 2019), trong số những phương pháp khác. Tiếp theo, và liên quan chặt chẽ đến việc tính trọng số task losses, là vấn đề task scheduling liên quan đến việc chọn các nhiệm vụ để huấn luyện ở mỗi bước. Nhiều kỹ thuật đã được sử dụng, từ những kỹ thuật đơn giản sử dụng lấy mẫu nhiệm vụ đồng nhất hoặc tỷ lệ, đến những kỹ thuật phức tạp hơn, như annealed sampling (Stickland & Murray, 2019) hoặc các phương pháp dựa trên active learning (Pilault et al., 2020). Các phương pháp regularization cũng được phân tích. Các phương pháp bao gồm (1) giảm thiểu norm L2 giữa các tham số của mô hình soft-parameter sharing (Yang & Hospedales, 2016), (2) đặt phân phối prior trên các tham số mạng (Long et al., 2017), (3) giới thiệu một thuật ngữ auto-encoder vào hàm mục tiêu (Lee et al., 2018), (4) biến thể MTL của dropout (Pascal et al., 2021), và những phương pháp khác. Để tiếp tục, các kỹ thuật gradient modulation được sử dụng để giảm thiểu vấn đề negative transfer bằng cách thao tác gradient của các nhiệm vụ mâu thuẫn, hoặc thông qua adversarial training (Sinha et al., 2018) hoặc bằng cách thay thế gradient bằng phiên bản đã sửa đổi của nó (Lopez-Paz & Ranzato, 2017). Một phương pháp khác để tối ưu hóa các mô hình MTL là bằng cách áp dụng knowledge distillation (Clark et al., 2019b). Cuối cùng, multi-objective optimization đã được áp dụng cho cài đặt MTL để có được một tập hợp các giải pháp tối ưu Pareto trên Pareto frontier, cung cấp tính linh hoạt lớn hơn trong việc cân bằng sự đánh đổi giữa các nhiệm vụ (Lin et al., 2019).

Học mối quan hệ nhiệm vụ. Phương pháp trong MTL tập trung vào việc học biểu diễn rõ ràng của các nhiệm vụ hoặc mối quan hệ giữa chúng là học mối quan hệ nhiệm vụ. Phương pháp này bao gồm ba loại phương pháp chính. Thứ nhất, task grouping nhằm chia một tập hợp các nhiệm vụ thành các nhóm để tối đa hóa việc chia sẻ kiến thức trong quá trình huấn luyện chung (Standley et al., 2020). Thứ hai, transfer relationship learning liên quan đến các phương pháp xác định khi nào việc chuyển giao kiến thức từ nhiệm vụ này sang nhiệm vụ khác sẽ có lợi cho việc học chung (Zamir et al., 2018; Guo et al., 2019). Cuối cùng, các phương pháp task embedding nhằm học không gian embedding cho chính các nhiệm vụ (Vu et al., 2020).

Về mức độ giám sát, hầu hết các nghiên cứu tập trung vào các phương pháp có giám sát. Một số nghiên cứu phân tích các phương pháp semi-supervised kết hợp các mục tiêu self-supervised, như MLM. Tuy nhiên, các phương pháp self-supervised chủ yếu được thảo luận trong bối cảnh huấn luyện trước.

Hầu hết các nghiên cứu đã tạo ra kết nối với các paradigm học khác, bao gồm reinforcement learning, transfer learning với sự nhấn mạnh đặc biệt vào domain adaptation, meta-learning, và active và online learning. Tuy nhiên, chỉ Ruder (2017); Zhang & Yang (2017; 2018) khám phá mối quan hệ giữa MTL và online learning trong bối cảnh ML truyền thống. Theo hiểu biết tốt nhất của chúng tôi, chưa có công trình nào trước đây nghiên cứu một cách có hệ thống mối liên hệ giữa MTL và CL. Chúng tôi tin rằng mối liên hệ giữa MTL và CL đại diện cho một hướng nghiên cứu đầy hứa hẹn, như chúng tôi sẽ thúc đẩy tầm quan trọng của mối liên hệ này trong Mục 4.

20

--- TRANG 21 ---
Bản thảo.

B CÁC PHƯƠNG PHÁP MULTI-TASK LEARNING BỔ SUNG

B.1 PROMPTS

Prompts nhúng một nhiệm vụ vào đầu vào. Đầu vào ban đầu x được sửa đổi bằng cách sử dụng một template thành một chuỗi văn bản prompt x' có một số khe trống chưa được điền, và sau đó LM được sử dụng để điền thông tin để có được chuỗi cuối cùng x̂, từ đó đầu ra cuối cùng y có thể được suy ra (Liu et al., 2021a). Prompting yêu cầu thiết kế lại tất cả các đầu vào và đầu ra để coi các nhiệm vụ là các vấn đề text-to-text. Phương pháp prompting đã chứng minh hoạt động tốt nhất trong các kịch bản zero- và few-shot, nhưng lợi ích giảm đi trong cài đặt tài nguyên cao (Parmar et al., 2022; Wang et al., 2022). Ngoài ra, hiệu suất mở rộng tốt với sự gia tăng kích thước mô hình (Lester et al., 2021), làm cho phương pháp này không thể tiếp cận được với mọi người.

Theo Liu et al. (2021a), có nhiều hương vị khác nhau của prompting. Thứ nhất, các mô hình với các mục tiêu huấn luyện trước khác nhau có thể được sử dụng - LM trái-sang-phải (Brown et al., 2020), MLM (Liu et al., 2019c), prefix LM (Bao et al., 2020), hoặc encoder-decoder (Lewis et al., 2020). Prompts có thể được thiết kế dưới dạng cloze (Petroni et al., 2019) hoặc prefix (Lester et al., 2021), được làm thủ công (Brown et al., 2020) hoặc tự động, cái mà lại có thể là rời rạc (Shin et al., 2020) hoặc liên tục (Lester et al., 2021). Answer engineering tìm kiếm không gian trả lời và ánh xạ tới đầu ra ban đầu bằng cách quyết định hình dạng trả lời và chọn phương pháp thiết kế trả lời. Hơn nữa, tham số có thể được cập nhật bằng cách sử dụng các cài đặt khác nhau - tuning-free prompting (Brown et al., 2020), fixed-LM prompt tuning (Li & Liang, 2021), fixed-prompt LM tuning (Raffel et al., 2020), và prompt+LM tuning (Liu et al., 2021b). Cuối cùng, huấn luyện có thể được thực hiện trong cài đặt few/zero-shot (Brown et al., 2020) hoặc full-data (Han et al., 2021). Trong các đoạn sau, chúng tôi thảo luận về một số công trình prompting trước đây.

HyperPrompt (He et al., 2022) là một phương pháp kết hợp hypernetworks và prompts. Ý tưởng chính là thêm vào các vector có thể huấn luyện điều kiện nhiệm vụ vào cả keys và values của sub-layer MHA ở mọi lớp Transformer. Những feature map attention cụ thể của nhiệm vụ này được huấn luyện chung với các biểu diễn không phụ thuộc nhiệm vụ. Key prompts tương tác với query ban đầu, cho phép các token có được ngữ nghĩa cụ thể của nhiệm vụ. Value prompts được thêm vào vector value ban đầu, phục vụ như bộ nhớ cụ thể của nhiệm vụ cho MHA để truy xuất thông tin từ đó. Tuy nhiên, thay vì có key/value prompt cho mỗi nhiệm vụ và lớp, các tác giả khởi tạo một prompt toàn cục P cho mỗi nhiệm vụ. Họ áp dụng hai hypernetworks cục bộ hk/v (một cho keys, cái khác cho values) ở mỗi lớp Transformer để chiếu prompt này thành key/value prompts thực tế cụ thể của nhiệm vụ và lớp. Có ba biến thể được kiểm tra trong bài báo - HyperPrompt-Share, -Sep, và -Global. HyperPrompt-Global đã chứng minh là tốt nhất, vì nó cho phép một cách linh hoạt để chia sẻ thông tin qua các nhiệm vụ và lớp. Nó giới thiệu task và layer embeddings, sau đó được hợp nhất thành layer-aware task embedding. Embedding này sau đó là đầu vào cho các hypernetworks toàn cục Hk/v được sử dụng như bộ tạo của các hypernetworks cục bộ hk/v. Những hypernetworks cục bộ này sau đó tạo ra hyper-prompts bằng cách sử dụng prompt toàn cục P. Hyper-prompts cuối cùng được thêm vào với keys và values ban đầu trong các sub-layers MHA. Trong quá trình huấn luyện, không có tham số nào được giữ đông lạnh. Họ báo cáo kết quả tốt hơn so với các phương pháp cạnh tranh của HyperFormer++ (Mahabadi et al., 2021) và Prompt-Tuning (Lester et al., 2021).

In-BoXBART (Parmar et al., 2022) sử dụng các hướng dẫn y sinh học chứa: (1) định nghĩa (giải thích cốt lõi và hướng dẫn chi tiết về những gì cần làm), (2) prompt (giải thích ngắn gọn về nhiệm vụ), và (3) ví dụ (các cặp đầu vào/đầu ra với giải thích). Mỗi hướng dẫn (thực sự là một prompt) được thêm vào trước các thể hiện đầu vào. Vấn đề của các thể hiện quá dài xuất hiện.

InstructionNER (Wang et al., 2022) làm phong phú các đầu vào với các hướng dẫn cụ thể của nhiệm vụ và các tùy chọn trả lời. Ngoài ra, hai nhiệm vụ phụ trợ được giới thiệu - entity extraction và entity typing, trực tiếp giúp giải quyết nhiệm vụ NER.

Sanh et al. (2021) cho phép công chúng đề xuất prompts và đã nghĩ ra 2073 prompts cho 177 tập dữ liệu tổng cộng (trung bình 12 prompts mỗi tập dữ liệu). Họ trộn và kết hợp tất cả các ví dụ từ các tập dữ liệu trước khi huấn luyện. Trong hầu hết các trường hợp, hiệu suất của các mô hình của họ được cải thiện khi số lượng tập dữ liệu huấn luyện tăng. Hơn nữa, huấn luyện trên nhiều prompts hơn mỗi tập dữ liệu dẫn đến tổng quát hóa tốt hơn và mạnh mẽ hơn trên các tập dữ liệu chưa thấy. Các mô hình họ huấn luyện dựa trên mô hình T5 thích ứng LM (Lester et al., 2021).

Prefix tuning đông lạnh các tham số mô hình ngôn ngữ và tối ưu hóa một vector liên tục, cụ thể của nhiệm vụ nhỏ được gọi là prefix (Li & Liang, 2021). Do đó, chỉ cần lưu trữ một prefix cho mỗi nhiệm vụ, làm cho prefix tuning mô-đun và hiệu quả về không gian. Phương pháp này chỉ có thể được áp dụng cho các mô hình sinh văn bản, như GPT-2 (Radford et al., 2019) và BART (Lewis et al., 2020). Họ nêu trực giác rằng ngữ cảnh có thể ảnh hưởng đến mã hóa của đầu vào x bằng cách hướng dẫn những gì cần trích xuất từ x; và có thể ảnh hưởng đến việc sinh đầu ra y bằng cách điều khiển phân phối token tiếp theo. Họ tối ưu hóa prefix như các word embeddings liên tục, thay vì tối ưu hóa trên các token rời rạc. Lý do cho điều này là prompt rời rạc cần khớp với word embedding thực, dẫn đến một mô hình ít biểu cảm hơn.

Lester et al. (2021) đã sử dụng một prompt có độ dài cố định của các token đặc biệt, nơi các embeddings của những token này được cập nhật. Điều này loại bỏ yêu cầu rằng các prompts được tham số hóa bởi mô hình và cho phép chúng có các tham số có thể huấn luyện của riêng mình. Họ thử nghiệm ba kỹ thuật khởi tạo khác nhau - ngẫu nhiên đồng nhất, từ vựng được lấy mẫu, và nhãn lớp. Kỹ thuật huấn luyện trước LM-adaptation được sử dụng. Không giống như adapters, sửa đổi hàm thực tế hoạt động trên đầu vào, prompt tuning thêm các biểu diễn đầu vào mới ảnh hưởng đến cách đầu vào được xử lý, để hàm cố định. Họ đông lạnh mô hình được huấn luyện trước. Cuối cùng, họ thử prompt ensembling (một prompt mỗi mô hình, cho mỗi nhiệm vụ), cho thấy hiệu suất được cải thiện so với trung bình prompt đơn.

Thách thức và Cơ hội trong Chu trình ML. Prompts cũng có thể giảm thiểu một số thách thức của các giai đoạn chu trình ML khác nhau (xem Bảng 2). Để bắt đầu, trong cài đặt fixed-prompt LM tuning hoặc prompt+LM tuning, kiến thức được chuyển giao từ các nhiệm vụ khác, có thể đặc biệt có lợi cho các nhiệm vụ ít tài nguyên. Tuy nhiên, trong kịch bản như vậy, các kỹ thuật tối ưu hóa khác nhau cần được xem xét để tránh can thiệp tiêu cực và các nhược điểm MTL khác (Phụ lục A.1). Về lựa chọn mô hình, đó là một thách thức hơn là một cơ hội, vì các mô hình dựa trên prompts yêu cầu số lượng lớn tham số ngay từ đầu để hoạt động tốt. Độ phức tạp huấn luyện mô hình phụ thuộc vào cài đặt cập nhật tham số, với một số cài đặt không yêu cầu (Brown et al., 2020) hoặc chỉ ít cập nhật tham số (Li & Liang, 2021). Một trong những lợi ích khi sử dụng prompts là khả năng xử lý tất cả các nhiệm vụ bằng một mô hình text-to-text duy nhất, bất kể mã hóa đầu vào và đầu ra. Khi sử dụng prompts, thách thức lớn nhất trong triển khai mô hình là kích thước của mô hình. Cuối cùng, việc cập nhật mô hình do distribution shift, dữ liệu mới, hoặc yêu cầu kinh doanh (xem Mục 4.4) có vẻ hợp lý nhất trong cài đặt nơi prompts liên tục và được điều chỉnh (Li & Liang, 2021). Tuy nhiên, điều này có nhược điểm, như tối ưu hóa khó khăn, thay đổi hiệu suất không đơn điệu liên quan đến số lượng tham số, và dành một phần độ dài chuỗi cho thích ứng (Hu et al., 2021).

22

# 2212.10560.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/instruct/2212.10560.pdf
# File size: 4335548 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
ACL 2023
SELF-INSTRUCT : Aligning Language Models
with Self-Generated Instructions
Yizhong Wang‚ô£Yeganeh Kordi‚ô¢Swaroop Mishra‚ô°Alisa Liu‚ô£
Noah A. Smith‚ô£+Daniel Khashabi‚ô†Hannaneh Hajishirzi‚ô£+
‚ô£University of Washington‚ô¢Tehran Polytechnic‚ô°Arizona State University
‚ô†Johns Hopkins University+Allen Institute for AI
yizhongw@cs.washington.edu
Abstract
Large ‚Äúinstruction-tuned‚Äù language models
(i.e., finetuned to respond toinstructions) have
demonstrated a remarkable ability to gener-
alize zero-shot to new tasks. Nevertheless,
they depend heavily on human-written instruc-
tion data that is often limited in quantity, di-
versity,andcreativity,thereforehinderingthe
generality of the tuned model. We introduce
SELF-INSTRUCT , a framework for improving
the instruction-following capabilities of pre-
trained language models by bootstrapping off
theirowngenerations. Ourpipelinegenerates
instructions, input, and output samples from
a language model, then filters invalid or sim-
ilar ones before using them to finetune the
original model. Applying our method to the
vanillaGPT3, we demonstrate a 33% abso-
lute improvement over the original model on
SUPER-NATURALINSTRUCTIONS ,onparwith
the performance of InstructGPT001,1which
was trained with private user data and human
annotations. Forfurtherevaluation,wecuratea
setofexpert-writteninstructionsfornoveltasks,
andshowthroughhumanevaluationthattuning
GPT3 with SELF-INSTRUCT outperforms using
existing public instruction datasets by a large
margin, leaving only a 5% absolute gap behind
InstructGPT001.SELF-INSTRUCT provides an
almost annotation-free method for aligning pre-
trained language models with instructions, and
wereleaseourlargesyntheticdatasettofacili-
tate future studies on instruction tuning.2
1 Introduction
TherecentNLPliteraturehaswitnessedatremen-
dous amount of activity in building models that
1Unless otherwise specified, our comparisons are with the
text-davinci-001 engine. We focus on this engine since it
is the closest to our experimental setup: supervised finetuning
with human demonstrations. The newer engines are more
powerful,thoughtheyusemoredata(e.g.,codecompletionor
latest user queries) oralgorithms(e.g., PPO) that are difficult
to compare with.
2Code and data are available at https://github.com/
yizhongw/self-instruct
Instruction:Write a letter from the perspective of a cat.Input:NullOutput:Dear [Owner], I am writing to you today because I have aproblem. You see, I‚Äôve been living with you for the past[Number of Years] and I love it here. The food is great,the bed is comfy, and there are plenty of toys to playwith. But lately, I‚Äôve noticed that you‚Äôre not asaffectionate towards me as you used to be. In fact,sometimes when I try to cuddle up next to you on thecouch, you push me away...
Instruction:I am looking for a job and Ineed to fill out an application form. Canyou please help me complete it?Input:Application Form:Name:_________Age:__________Sex:________Phone Number:______Email Address:________Education:___________________...Output:Name: John DoeAge: 25Sex: MalePhone Number: ...
Instruction:How to write a code for converting degrees fahrenheitto celsius.Input:NullOutput:def convert_fahrenheit_to_celsius(fahr):celsius= (fahr-32) * 5 / 9return celsius
Instruction:Given an address and city, come up withthe zip code.Input:Address: 123 Main Street, City: San FranciscoOutput:94105
Figure 1: Selected tasks from the generated instruction
data using vanilla GPT3. Some texts are reformatted
for presentation. See Table 10 for more examples.
can follow natural language instructions (Mishra
et al., 2022; Wei et al., 2022; Sanh et al., 2022;
Wangetal.,2022;Ouyangetal.,2022;Chungetal.,
2022,i.a.). Thesedevelopmentsarepoweredbytwo
key components: large pretrained language mod-
els (LM) and human-written instruction data (e.g.,
PROMPTSOURCE(Bach et al., 2022) and SUPER-
NATURALINSTRUCTIONS (Wangetal.,2022, SU-
PERNIfor short)). However, collecting such in-
struction data is costly and often suffers limited
diversitygiventhatmosthumangenerationstend
tobepopularNLPtasks,fallingshortofcoveringaarXiv:2212.10560v2  [cs.CL]  25 May 2023

--- PAGE 2 ---
175seed tasks with1instructionand1instancepertaskTask PoolStep1:InstructionGeneration
No
Step4:FilteringOutput-firstInput-firstStep2:ClassificationTaskIdentification
Step3:InstanceGeneration
Instruction :Give me a quote from a famous person on this topic.Task
Yes
TaskInstruction :Give me a quote from a famous person on this topic.Input:Topic: The importance of being honest.Output:"Honesty is the first chapter in the book of wisdom." -Thomas JeffersonTaskTaskInstruction :Find out if the given text is in favor of or against abortion.Class Label: Pro-abortionInput:Text: I believe that women should have the right to choose whether or notthey want to have an abortion.TaskLMLM
LM
ü§ñ
ü§ñ
ü§ñFigure2: Ahigh-leveloverviewof SELF-INSTRUCT . Theprocessstartswithasmallseedsetoftasksasthetask
pool. Randomtasks are sampledfrom the taskpool, and usedto prompt an off-the-shelfLM to generateboth new
instructionsand correspondinginstances, followed byfiltering low-qualityor similargenerations, and thenadded
backtotheinitialrepositoryoftasks. Theresultingdatacanbeusedfortheinstructiontuningofthelanguagemodel
itself later to follow instructions better. Tasks shown in the figure are generated by GPT3.
true variety of tasks and different ways to describe
them. Continuingtoimprovethequalityandcov-
erage ofinstruction-tuned models necessitatesthe
developmentofalternativeapproachesforsupervis-
ing the instruction tuning process.
In this work, we introduce SELF-INSTRUCT , a
semi-automated process for instruction-tuning a
pretrained LM using instructional signals from the
modelitself. Theoverallprocessisaniterativeboot-
strapping algorithm (see Figure 2), which starts off
with a limited (e.g., 175 in our study) seed set of
manually-written tasks that are used to guide the
overall generation. In the first phase, the model
ispromptedtogenerateinstructionsfornewtasks.
Thisstepleveragestheexistingcollectionofinstruc-
tions to create more broad-coverage instructions
that define (often new) tasks. Given the newly-
generated set of instructions, the framework also
creates input-output instances for them, which can
be later used for supervising the instruction tuning.
Finally,variousheuristicsareusedtoautomatically
filter low-quality or repeated instructions, before
adding the remaining valid tasks to the task pool.
This process can be repeated for many iterations
until reaching a large number of tasks.
Toevaluate SELF-INSTRUCT empirically,werun
this framework on GPT3(Brown et al., 2020),
which is a vanilla LM (¬ß3). The iterative SELF-
INSTRUCT processonthismodelleadstoabout52k
instructions, paired with about 82K instance inputs
and target outputs. We observe that the resultingdataprovidesadiverserangeofcreativetasks,as
is demonstrated by examples in Figure 1. These
generatedtasksdeviatefromthedistributionoftyp-
icalNLPtasks,andalsohavefairlysmalloverlap
with the seed tasks (¬ß3.2). On this resulting data,
we build GPT3SELF-INSTby finetuning GPT3(i.e.,
the same model used for generating the instruction
data). Weevaluate GPT3SELF-INSTincomparisonto
various other models on both typical NLP tasks in-
cludedin SUPERNI(Wangetal.,2022),andasetof
new instructions that are created for novel usage of
instruction-followingmodels(¬ß4). Theresultsin-
dicatethat GPT3SELF-INSToutperforms GPT3(the
original model) by a large margin (+33.1%) and
nearly matches the performance of InstructGPT001.
Moreover, our human evaluation on the newly-
created instruction set shows that GPT3SELF-INST
demonstrates a broad range of instruction follow-
ing ability, outperforming models trained on other
publiclyavailableinstructiondatasetsandleaving
only a 5% gap behind InstructGPT001.
In summary, our contributions are: (1) we
introduce SELF-INSTRUCT , a method for induc-
ing instruction following capabilities with mini-
mal human-labeled data; (2) we demonstrate its
effectiveness via extensive instruction-tuning ex-
periments; and (3) we release a large synthetic
datasetof52Kinstructionsandasetofmanually-
writtennoveltasksforbuildingandevaluatingfu-
ture instruction-following models.

--- PAGE 3 ---
2 Method
Annotating large-scale instruction data can be chal-
lengingforhumansbecauseitrequires1)creativity
to come up with novel tasks and 2) expertise for
writing the solutions to each task. Here, we de-
tailourprocessfor SELF-INSTRUCT ,whichrefers
to the pipeline of generating tasks with a vanilla
pretrainedlanguagemodel itself, filteringthegen-
erated data, and then conducting instruction tuning
with this generated data in order to align the LM to
follow instructions better. This pipeline is depicted
in Figure 2.
2.1 Defining Instruction Data
Theinstructiondatawewanttogeneratecontainsa
setofinstructions {ùêºùë°},eachofwhichdefinesatask
ùë°innaturallanguage. Task ùë°hasùëõùë°‚â•1input-output
instances {(ùëãùë°,ùëñ,ùëåùë°,ùëñ)}ùëõùë°
ùëñ=1. AmodelùëÄisexpected
to produce the output, given the task instruction
and the corresponding input: ùëÄ(ùêºùë°,ùëãùë°,ùëñ) =ùëåùë°,ùëñ,
forùëñ‚àà {1,‚Ä¶,ùëõùë°}. Note that the instruction and
instance input does not have a strict boundary in
many cases. For example, ‚Äúwrite an essay about
school safety‚Äù can be a valid instruction that we
expect models to respond to directly, while it can
also be formulated as ‚Äúwrite an essay about the fol-
lowingtopic‚Äùastheinstruction,and‚Äúschoolsafety‚Äù
as an instance input. To encourage the diversity of
the data format, we allow such instructions that do
not require additional input (i.e., ùëãis empty).
2.2 Automatic Instruction Data Generation
Our pipeline for data generation consists of four
steps: 1)generating task instructions,2) determin-
ingiftheinstructionrepresentsaclassificationtask,
3)instancegenerationwitheitheraninput-firstor
output-first approach, and 4) filtering low-quality
data.
Instruction Generation. At the first step, SELF-
INSTRUCT generates new instructions from a small
set of seed human-written instructions in a boot-
strapping fashion. We initiate the task pool with
175 tasks (1 instruction and 1 instance for each
task).3For every step, we sample 8 task instruc-
tions from this pool as in-context examples. Of
the 8 instructions, 6 are from the human-written
3Thesetaskswerenewlywrittenbytheauthorsandtheir
labmatesat UW,withoutreference toexistingdatasets orthe
testsetusedinthiswork. Weprovidemoredetailsaboutthese
tasks and analyze their similarity to the test tasks in Appendix
¬ßA.1.tasks, and 2 are from the model-generated tasks in
previousstepstopromotediversity. Theprompting
template is shown in Table 5.
Classification Task Identification. Because we
needtwodifferentapproachesforclassificationand
non-classificationtasks,wenextidentifywhether
the generated instruction represents a classification
taskornot.4WeprompttheLMinafew-shotwayto
determine this, using 12 classification instructions
and19non-classificationinstructionsfromtheseed
tasks. The prompting template is shown in Table 6.
InstanceGeneration. Giventheinstructionsand
their task type, we generate instances for each in-
struction independently. This is challenging be-
cause itrequires themodel to understandwhat the
target task is, based on the instruction, figure out
whatadditionalinputfieldsareneededandgener-
atethem,andfinallycompletethetaskbyproduc-
ingtheoutput. WefoundthatpretrainedLMscan
achievethistoalargeextentwhenpromptedwith
instruction-input-outputin-contextexamplesfrom
othertasks. Anaturalwaytodothisisthe Input-
first Approach , where we can ask an LM to come
up with the input fields first based on the instruc-
tion, and then produce the corresponding output.
This generation order is similar to how models are
used to respond to instruction and input, but here
with in-context examples from other tasks. The
prompting template is shown in Table 7.
However, we found that this approach can gen-
erate inputs biased toward one label, especially for
classificationtasks(e.g.,forgrammarerrordetec-
tion,itusuallygeneratesgrammaticalinput). There-
fore,weadditionallyproposean Output-firstAp-
proachforclassificationtasks,wherewefirstgener-
ate the possible class labels, and then condition the
inputgenerationoneachclasslabel. Theprompting
templateisshowninTable8.5Weapplytheoutput-
firstapproachtotheclassificationtasksidentified
in the former step, and the input-first approach to
the remaining non-classification tasks.
Filtering andPostprocessing. To encouragedi-
versity, a new instruction is added to the task pool
only when its ROUGE-L similarity with any exist-
4Moreconcretely,weregardtasksthathaveasmalllimited
output label space as classification tasks.
5Inthiswork,weuseafixedsetofseedtasksforprompt-
ing the instance generation, and thus only generate a small
number of instances per task in one round. Future work can
use randomly sampled tasks to prompt the model to generate
a larger number of instances in multiple rounds.

--- PAGE 4 ---
ing instruction is less than 0.7. We also exclude
instructions that contain some specific keywords
(e.g., image, picture, graph) that usually can not be
processedbyLMs. Whengeneratingnewinstances
for each instruction, we filter out instances that are
exactlythesameorthosewiththesameinputbut
different outputs. Invalid generations are identified
and filtered out based on heuristics (e.g., instruc-
tion is too long or too short, instance output is a
repetition of the input).
2.3 Finetuning the LM to Follow Instructions
Aftercreatinglarge-scaleinstructiondata,weuseit
to finetune the original LM (i.e., SELF-INSTRUCT ).
To do this, we concatenate the instruction and in-
stance input as a prompt and train the model to
generate the instance output in a standard super-
vised way. To make the model robust to different
formats, we use multiple templates to encode the
instructionandinstanceinputtogether. Forexam-
ple, the instruction can be prefixed with ‚ÄúTask:‚Äù or
not,theinput canbeprefixedwith‚ÄúInput:‚Äù ornot,
‚ÄúOutput:‚Äù canbeappendedattheendoftheprompt
or not, and different numbers of break lines can be
put in the middle, etc.
3 SELF-INSTRUCT Data from GPT3
Inthissection,weapplyourmethodforinducing
instruction data to GPT3as a case study. We use
thelargestGPT3LM(‚Äúdavinci‚Äùengine)accessed
throughtheOpenAIAPI.6Theparametersformak-
ing queries are described in Appendix A.2. Here
we present an overview of the generated data.
3.1 Statistics
Table 1 describes the basic statistics of the gener-
ated data. We generate a total of over 52K instruc-
tionsandmorethan82Kinstancescorresponding
to these instructions after filtering.
statistic
# of instructions 52,445
- # of classification instructions 11,584
- # of non-classification instructions 40,861
# of instances 82,439
- # of instances with empty input 35,878
ave. instruction length (in words) 15.9
ave. non-empty input length (in words) 12.7
ave. output length (in words) 18.9
Table 1: Statistics of the generated data by applying
SELF-INSTRUCT to GPT3.
6https://openai.com/api/3.2 Diversity
Tostudy what typesof instructions are generated
andhowdiversetheyare,weidentifytheverb-noun
structure in the generated instructions. We use the
BerkeleyNeuralParser7(KitaevandKlein,2018;
Kitaev et al., 2019) to parse the instructions and
then extract the verb that is closest to the root as
wellasitsfirstdirectnounobject. 26,559outofthe
52,445 instructions contain such structure; other
instructions usually contain more complex clauses
(e.g.,‚ÄúClassifywhetherthistweetcontainspolitical
content or not.‚Äù) or are framed as questions (e.g.,
‚ÄúWhich of these statements are true?‚Äù). We plot
the top 20 most common root verbs and their top 4
directnounobjectsinFigure 3,whichaccountfor
14% of the entire set. Overall, we see quite diverse
intents and textual formats in these instructions.
We further study how the generated instructions
differ from the seed instructions used to prompt
the generation. For eachgenerated instruction, we
compute its highest ROUGE-L overlap with the
175 seed instructions. We plot the distribution of
these ROUGE-L scores in Figure 4. The results
indicate a decent number of new instructions were
generated,whichdonothavemuchoverlapwiththe
seeds. We also demonstrate diversity in the length
of the instructions, instance inputs, and instance
outputs in Figure 5.
3.3 Quality
So far, we have shown the quantity and diversity
of the generated data, but its quality remains un-
certain. To investigate this, we randomly sample
200instructionsandrandomlyselect1instanceper
instruction. Weaskedanexpertannotator(author
of this work) to label whether each instance is cor-
rect or not, in terms of the instruction, the instance
input,andtheinstanceoutput. Evaluationresultsin
Table2showthatmostofthegeneratedinstructions
are meaningful, while the generated instances may
containmorenoise(toareasonableextent). How-
ever, we found that even though the generations
may contain errors, most of them are still in the
correctformatorpartiallycorrect,whichcanpro-
vide usefulguidance for trainingmodels to follow
instructions. We listed a number of good examples
and bad examples in Table 10 and 11, respectively.
7https://parser.kitaev.io/

--- PAGE 5 ---
write
give
find
createmakedescri bedesi gngener at ec l a s s i f yh a v eexplaint e l li d e n t i f youtputp r e d i c td e t e c t
function
essay
letter
paragraph
example
list
set
a d v i c e
word
number
s e nt e nc e
way
program
list
al gori t hm
funct i on
list
st ory
sent ence
program
situation
person
process
t i me
syst em
game
al gor i t hm
st r uct ur e
l i s t
number
s ent ence
s e r i e s
s e nt e nc e
s e n t i me n t
a r t i c l e
t e x t
l i s t
array
c o i n
s e t
d i f f e r e n c e
c o n c e p t
s t o r y
j o k e
s e n t i m e n t
t o p i c
n u m b e r
w o r d
s e n t i m e n t
s a r c a s mFigure3: Thetop20mostcommonrootverbs(innercircle)and
their top 4 direct noun objects (outer circle) in the generated
instructions. Despitetheirdiversity,theinstructionsshownhere
onlyaccountfor14%ofallthegeneratedinstructionsbecause
manyinstructions(e.g.,‚ÄúClassifywhethertheuserissatisfied
with the service.‚Äù) do not contain such a verb-noun structure.
0 0.2 0.4 0.6 0.8 10100020003000
ROUGE-L Overlap with the Most Similar Seed Instruction# InstructionsFigure4: DistributionoftheROUGE-Lscores
between generated instructions and their most
similar seed instructions.
10 20 30 40 50 600200040006000
Instruction Length# Instructions
10 20 30 40 50 600100020003000
Input Length# Inputs
10 20 30 40 50 60010k20k30k
Onput Length# Onputs
Figure 5: Length distribution of the generated
instructions, non-empty inputs, and outputs.
Quality Review Question Yes %
Does the instruction
describe a valid task?92%
Is the input appropriate
for the instruction?79%
Is the output a correct and acceptable
response to the instruction and input?58%
All fields are valid 54%
Table2: Dataqualityreviewfortheinstruction,input,
and output of the generated data. See Table 10 and
Table 11 for representative valid and invalid examples.
4 Experimental Results
Weconductexperimentstomeasureandcompare
theperformanceofmodelsundervariousinstruc-
tion tuning setups. We first describe our models
and other baselines, followed by our experiments.
4.1 GPT3SELF-INST: finetuning GPT3 on its
own instruction data
Giventheinstruction-generatedinstructiondata,we
conduct instruction tuning with the GPT3model
itself (‚Äúdavinci‚Äù engine). As described in ¬ß2.3, we
usevarioustemplatestoconcatenatetheinstructionandinput,andtrainthemodeltogeneratetheoutput.
This finetuning is done through the OpenAI fine-
tuningAPI.8Weusethedefaulthyper-parameters,
except that we set the prompt loss weight to 0, and
wetrainthemodelfor2epochs. Wereferthereader
to Appendix A.3 for additional finetuning details.
The resulting model is denoted by GPT3SELF-INST.
4.2 Baselines
Off-the-shelf LMs. We evaluate T5-LM (Lester
et al., 2021; Raffel et al., 2020) and GPT3(Brown
etal.,2020)asthevanillaLMbaselines(onlypre-
training, no additional finetuning). These baselines
will indicate the extent to which off-the-shelf LMs
arecapableoffollowinginstructionsnaturallyim-
mediately after pretraining.
Publicly available instruction-tuned models.
T0andTùëò-INSTRUCT are two instruction-tuned
models proposed in Sanh et al. (2022) and Wang
et al. (2022), respectively, and are demonstrated
to be able to follow instructions for many NLP
tasks. Both of these models are finetuned from
theT5(Raffeletal.,2020)checkpointsandarepub-
liclyavailable.9Forbothofthesemodels,weuse
8See OpenAI‚Äôs documentation on finetuning.
9T0is available at here and T ùëò-INSTRUCT is here.

--- PAGE 6 ---
their largest version with 11B parameters.
Instruction-tunedGPT3models. Weevaluate
InstructGPT (Ouyang et al., 2022), which is devel-
opedbyOpenAIbasedonGPT3tofollowhuman
instructionsbetterandhasbeenfoundbythecom-
munitytohaveimpressivezero-shotabilities. There
are various generations of these models, where
neweronesusemoreexpansivedataoralgorithmic
novelties.10For ourSUPERNIexperiments in ¬ß4.3,
we only compare with their text-davinci-001
engine,becausetheirnewerenginesaretrainedwith
the latest user data and are likely to have already
seentheSUPERNItestset. Forourhumanevalua-
tion on newly written instructions, we include their
001, 002 and 003 engines for completeness.
Additionally, to compare SELF-INSTRUCT train-
ing with other publicly available instruction tuning
data, we further finetune GPT3 model with data
fromPROMPTSOURCEandSUPERNI, which are
usedtotrainthe T0andTùëò-INSTRUCT models. We
call them T0training and SUPERNItraining for
short, respectively. To save the training budget, we
sampled 50K instances (but covering all their in-
structions)foreachdataset,whichhasacomparable
size to the instruction data we generated. Based on
the findings from Wang et al. (2022) and our early
experiments, reducing the number of instances per
training task does not degrade the model‚Äôs general-
ization performance to unseen tasks.
4.3 Experiment 1: Zero-Shot Generalization
on SUPERNI benchmark
We first evaluate the models‚Äô ability to follow in-
structions on typical NLP tasks in a zero-shot fash-
ion. We use the evaluation set of SUPERNI(Wang
etal.,2022),whichconsistsof119taskswith100in-
stances in each task. In this work, we mainly focus
onthezero-shotsetup,i.e.,themodelisprompted
with the definition of the tasks only, without in-
context demonstration examples. For all our re-
queststothe GPT3variants,weusethedetermin-
istic generation mode (temperature as 0 and no nu-
cleus sampling) without specific stop sequences.
Results. We make the following observations
fromtheresultsinTable3. SELF-INSTRUCT boosts
theinstruction-followingabilityof GPT3byalarge
margin. The vanilla GPT3model basically can-
not follow human instructions at all. Upon manual
analysis, we find that it usually generates irrele-
10See OpenAI‚Äôs documentation on their models.Model # Params ROUGE-L
Vanilla LMs
T5-LM 11B 25.7
GPT3 175B 6.8
Instruction-tuned w/o S UPERNI
T0 11B 33.1
GPT3 + T 0Training 175B 37.9
GPT3SELF-INST(Ours) 175B 39.9
InstructGPT001 175B 40.8
Instruction-tuned w/ S UPERNI
Tùëò-INSTRUCT 11B 46.0
GPT3 + S UPERNI Training 175B 49.5
GPT3SELF-INST+ SUPERNI Training (Ours) 175B 51.61‚Éù
2‚Éù
3‚Éù
Table 3: Evaluation results on unseentasks from SU-
PERNI(¬ß4.3). From the results, we see that 1‚ÉùSELF-
INSTRUCT can boost GPT3performance by a large mar-
gin(+33.1%)and 2‚Éùnearlymatchestheperformanceof
InstructGPT001. Additionally, 3‚Éùit can further improve
the performance even when a large amount of labeled
instruction data is present.
vant and repetitive text, and does not know when
to stop generation. Compared with other mod-
els that are not specifically trained for SUPERNI,
GPT3SELF-INSTachievesbetterperformancethan T0
ortheGPT3finetunedonthe T0trainingset,which
takes tremendous human labeling efforts. Notably,
GPT3SELF-INSTalsonearlymatchestheperformance
ofInstructGPT001, which is trained with private
user data and human-annotated labels.
Models trained on the SUPERNItraining set still
achieve better performance on its evaluation set,
which we attribute to the similar instruction style
and formatting. However, we show that SELF-
INSTRUCT stillbringsinadditionalgainswhencom-
bined with the SUPERNItraining set, proving its
value as complementary data.
4.4 Experiment 2: Generalization to
User-oriented Instructions on Novel Tasks
Despitethecomprehensivenessof SUPERNIin col-
lectingexistingNLPtasks,mostoftheseNLPtasks
were proposed for research purposes and skewed
toward classification. To better access the practi-
cal value of instruction-following models, a sub-
set of the authors curate a new set of instructions
motivated by user-oriented applications. We first
brainstorm various domains where large LMs may
be useful (e.g., email writing, social media, pro-
ductivity tools, entertainment, programming), then
craftinstructionsrelatedtoeachdomainalongwith
aninput-outputinstance(again,inputisoptional).
We aim to diversify the styles and formats of these
tasks (e.g., instructions may be long or short; in-

--- PAGE 7 ---
VanillaGPT3GPT3+T0TrainingGPT3+SuperNITrainingGPT3Self-Inst+SuperNIGPT3Self-InstInstructGPT001InstructGPT002InstructGPT0031871186831251810264598084666134281313054494540300447483112128168192
0%25%50%75%100%
GPT3T0 TrainingSuperNI TrainingSelf-Instruct + SuperNISelf-InstructInstructGPT-001InstructGPT-002InstructGPT-003correct and satisfying responseacceptable response with minor imperfectionsresponds to the instruction but has significant errors  irrelevant or invalid response1861176831251810264598084666134281313054484439300447483113129169192
0%25%50%75%100%
GPT3T0 TrainingSuperNI TrainingSelf-Instruct + SuperNISelf-InstructInstructGPT-001InstructGPT-002InstructGPT-003correct and satisfying responseacceptable response with minor imperfectionsresponds to the instruction but has significant errors  irrelevant or invalid responseC:respondstotheinstructionbuthassignificanterrorsA:correctandsatisfyingresponse
1861176831251810264598084666134281313054484439300447483113129169192
0%25%50%75%100%
GPT3T0 TrainingSuperNI TrainingSelf-Instruct + SuperNISelf-InstructInstructGPT-001InstructGPT-002InstructGPT-003correct and satisfying responseacceptable response with minor imperfectionsresponds to the instruction but has significant errors  irrelevant or invalid responseB:acceptableresponsewithminorimperfections1861176831251810264598084666134281313054484439300447483113129169192
0%25%50%75%100%
GPT3T0 TrainingSuperNI TrainingSelf-Instruct + SuperNISelf-InstructInstructGPT-001InstructGPT-002InstructGPT-003correct and satisfying responseacceptable response with minor imperfectionsresponds to the instruction but has significant errors  irrelevant or invalid responseD:irrelevantorinvalidresponse1861176831251810264598084666134281313054484439300447483113129169192
0%25%50%75%100%
GPT3T0 TrainingSuperNI TrainingSelf-Instruct + SuperNISelf-InstructInstructGPT-001InstructGPT-002InstructGPT-003correct and satisfying responseacceptable response with minor imperfectionsresponds to the instruction but has significant errors  irrelevant or invalid response1861176831251810264598084666134281313054494540300447483112128168192
0%25%50%75%100%
GPT3T0 TrainingSuperNI TrainingSelf-Instruct + SuperNISelf-InstructInstructGPT-001InstructGPT-002InstructGPT-003correct and satisfying responseacceptable response with minor imperfectionsresponds to the instruction but has significant errors  irrelevant or invalid responseFigure6: PerformanceofGPT3modelanditsinstruction-tunedvariants,evaluatedbyhumanexpertsonour252
user-orientedinstructions(¬ß4.4). Humanevaluatorsareinstructedtoratethemodels‚Äôresponsesintofourlevels. The
results indicate that GPT3SELF-INSToutperforms all the other GPT3variants trained on publicly available instruction
datasets. Additionally, GPT3SELF-INSTscores nearly as good as InstructGPT001(cf. footnote 1).
put/output may take the form of bullet points, ta-
bles,codes,equations,etc.). Intotal,wecreate252
instructions with 1 instance per instruction. We
believe it can serve as a testbed for evaluating how
instruction-basedmodelshandlediverseandunfa-
miliarinstructions. Table9presentsasmallportion
ofthem. TheentiresetisavailableinourGitHub
repository. Weanalyzetheoverlapbetweenthisset
set and the seed instructions in ¬ßA.1.
Human evaluation setup. Evaluating models‚Äô
performance on this evaluation set of diverse tasks
is extremely challenging because different tasks re-
quire different expertise. Indeed, many of these
taskscannotbemeasuredbyautomaticmetricsor
evenbejudgedbynormalcrowdworkers(e.g.,writ-
ingaprogram,orconvertingfirst-orderlogicinto
naturallanguage). Togetamorefaithfulevaluation,
we asked the authors of the instructions to judge
model predictions. Details on how we set up this
humanevaluationaredescribedinAppendixB.The
evaluators were asked to rate the output based on
whether it accurately and effectively completes the
task. We implemented a four-level rating system
for categorizing the quality of the models‚Äô outputs:
‚Ä¢RATING-A:The response is valid and satisfying.
‚Ä¢RATING-B:Theresponseisacceptablebuthas
minor errors or imperfections.
‚Ä¢RATING-C:The response is relevant and re-
sponds to the instruction, but it has significant
errors in the content. For example, GPT3 might
generate a valid output first, but continue to gen-erate other irrelevant things.
‚Ä¢RATING-D:The response is irrelevant or com-
pletely invalid.
Results. Figure 6 shows the performance of
GPT3modelanditsinstruction-tunedcounterparts
on this newly written instruction set (w. inter-rater
agreementùúÖ= 0.57onthe4-classcategoricalscale,
see Appendix B for details). As anticipated, the
vanillaGPT3LMislargelyunabletorespondtoin-
structions,andallinstruction-tunedmodelsdemon-
strate comparatively higher performance. Nonethe-
less,GPT3SELF-INST(i.e.,GPT3model finetuned
withSELF-INSTRUCT )outperformsthosecounter-
partstrainedon T0orSUPERNIdatabyalargemar-
gin,demonstratingthevalueofthegenerateddata
despitethenoise. Comparedwith InstructGPT001,
GPT3SELF-INSTis quite close in performance‚Äîif
we count acceptable response with minor imper-
fections ( RATING-B) as valid, GPT3SELF-INSTis
only5%behind InstructGPT001. Lastly,ourevalua-
tionconfirmstheimpressiveinstruction-following
ability of InstructGPT002andInstructGPT003. Al-
though thereare many factorsbehind this success,
weconjecturethatfutureworkcanlargelybenefit
fromimprovingthequalityofourgenerateddataby
using human annotators or training a reward model
toselectbettergenerations,similartothealgorithm
used by Ouyang et al. (2022).
4.5 Effect of Data Size and Quality
Data size. SELF-INSTRUCT provides a way to
grow instruction data at a low cost with almost

--- PAGE 8 ---
no human labeling; could more of this generated
dataleadtobetterinstruction-followingability? We
conduct an analysis of the size of generated data
bysubsamplingdifferentnumbersofinstructions
fromthegenerateddataset,finetuning GPT3onthe
sampledsubsets,andevaluatinghowtheresulting
models perform on the 252 user-oriented instruc-
tion set. We conduct the same human evaluation
as in ¬ß4.4. Figure 7 presents the performance of
GPT3SELF-INSTmodelsfinetunedwithdifferentsizes
of generated data. Overall, we see consistent im-
provement as we grow the data size. However, this
improvement almost plateaus after 16K. This is in-
linewiththedatascalingexperimentsinWangetal.
(2022, Fig. 5). Interestingly, when evaluating on
SUPERNIwe found the model‚Äôs performance gain
plateausearlier ataround hundredsof instructions.
This may be due to the fact that the new generated
dataisdistinctfromtypicalNLPtasksin SUPERNI,
indicating that future research may benefit from us-
ingacombinationofdifferentinstructiondatafor
better performance on various types of tasks.
Data quality. Another direction to improve the
model‚Äôs performance is to take our generated data
and get better supervision (with less noise). We
explore this idea by using InstructGPT003(the best
available general-purpose model) to regenerate the
outputfieldofallourinstancesgiventheinstruction
and input. We then use this improved version of
ourdatatofinetune GPT3. Thiscanberegardedas
adistillationof InstructGPT003withourdata. Asis
showninFigure7,theresultingmodeloutperforms
the counterpart trained with the original data by
10%,whichsuggestsbigroomforfutureworkon
using our generation pipeline to get initial data and
thenimprovingthedataqualitywithhumanexperts
or distillation from better models.
5 Related Work
Instruction-following LMs. A series of works
have found evidence that vanilla LMs can be effec-
tive at following general language instructions if
tunedwithannotated‚Äúinstructional‚Äùdata‚Äîdatasets
containinglanguageinstructionalcommandsand
their desired outcomes based on human annota-
tion(Welleretal.,2020;Mishraetal.,2022;Wei
et al., 2022; Sanh et al., 2022, i.a.). Additionally,
they show a direct correlation between the size and
diversityofthe‚Äúinstructional‚Äùdataandthegeneral-
izabilityofresultingmodelstounseentasks(Wang
et al., 2022; Chung et al., 2022). However, since
31.0%36.9%43.7%44.4%54.4%
20%30%40%50%60%
100800640051200PercentageofResponsesRatedasA
NumberofInstructions  w. GPT3 Self-Instruct data  w. improved output from InstructGPTFigure 7: Human evaluation performance of
GPT3SELF-INSTmodels tuned with different sizes of
instructions. ùë•-axis is in log scale. The smallest
size is 175, where only the seed tasks are used for
instruction tuning. We also evaluate whether improving
the data quality will further improve the performance
by distilling the outputs from InstructGPT003. We see
consistent improvement from using larger data with
better quality.
these developments largely focus on existing NLP
tasks and depend on human-annotated instructions,
this poses a bottleneck for progress toward more
generalizable models (e.g., see Fig. 5a in Wang
etal.,2022). Ourworkaimstomovebeyondclassi-
cal NLP tasks and tackle the challenges of creating
diverse instruction data by employing pretrained
LMs.InstructGPT (Ouyang et al., 2022) shares
a similar goal as ours in building more general-
purpose LMs, and has demonstrated remarkable
performance in following diverse user instructions.
However,asacommercialsystem,theirconstruc-
tion process still remains quite opaque. In partic-
ular, the role of datahas remained understudied
due to limited transparency and the private user
datatheyusedintheirstudy. Addressingsuchchal-
lenges necessitates the creation of a large-scale,
public dataset covering a broad range of tasks.
Languagemodelsfordatagenerationandaug-
mentation. A variety of works have proposed
usingLMsfordatageneration(SchickandSch√ºtze,
2021; Wang et al., 2021; Liu et al., 2022; Meng
et al., 2023) or augmentation (Feng et al., 2021;
Yangetal.,2020;Mekalaetal.,2022). Ourwork
differs from this line in that it is notspecific to a
particular task (say, QA or NLI). In contrast, a dis-
tinctmotivationfor SELF-INSTRUCT istobootstrap
newtaskdefinitionsthatmaynothavebeendefined

--- PAGE 9 ---
beforebyNLPpractitioners(thoughpotentiallystill
important for real users). In parallel with our work,
Honovich et al. (2022a) also propose to generate
large-scale instruction data (so-called Unnatural
Instructions) with GPT3 models. The major differ-
ences are that 1) they use tasks in SUPERNI(Wang
etal.,2022)astheirseedtasks,resultinginadiffer-
ent distribution of generated tasks; 2) they employ
InstructGPT002for generating the data, in which
sensetheyaredistillingknowledgefromanalready
instruction-tuned model, while we solely rely on
the vanilla LM; 3) the detailed generation pipeline
and templates are different. Nevertheless, we be-
lieve that both efforts in expanding instruction data
arecomplementary,andthecommunitywillbenefit
from these diverse datasets.
Instruction generation. A series of recent
works (Zhou et al., 2022b; Ye et al., 2022; Singh
et al., 2022; Honovich et al., 2022b) generate in-
structions of a task given a few examples. While
SELF-INSTRUCT also involves instruction genera-
tion, a major difference in our case is it is task-
agnostic;wegeneratenewtasks(instructionsalong
with instances) from scratch.
Model self-training. A typical self-training
framework (He et al., 2019; Xie et al., 2020; Du
et al., 2021; Amini et al., 2022; Huang et al., 2022)
uses trained models to assign labels to unlabeled
data and then leverages the newly labeled data to
improve the model. In a similar line, Zhou et al.
(2022a) use multiple prompts to specify a single
task and propose to regularize via prompt consis-
tency, encouraging consistentpredictions over the
prompts. This allows either finetuning the model
withextraunlabeledtrainingdata,ordirectapplica-
tionat inferencetime. While SELF-INSTRUCT has
similarities with the self-training literature, most
self-training methods assume a specific target task
as well as unlabeled examples under it; in contrast,
SELF-INSTRUCT producesavarietyoftasksfrom
scratch.
Knowledge distillation. Knowledge distilla-
tion (Hinton et al., 2015; Sanh et al., 2019; West
et al., 2021; Magister et al., 2022) often involves
the transfer of knowledge from larger models to
smaller ones. SELF-INSTRUCT can also be viewed
asaformof‚Äúknowledgedistillation",however, it
differs from this line in the following ways: (1)
the source and target of distillation are the same,
i.e., a model‚Äôs knowledge is distilled to itself; (2)the content of distillation is in the form of an
instruction task (i.e., instructions that define a task,
and a set of examples that instantiate it).
Bootstrapping with limited resources. A se-
riesofrecentworksuselanguagemodelstoboot-
strap some inferences using specialized methods.
NPPrompt (Zhao et al., 2022) provides a method
to generate predictions for semantic labels without
anyfinetuning. Itusesamodel‚Äôsownembeddings
to automatically find words relevant to the label of
the data sample and hence reduces the dependency
on manual mapping from model prediction to la-
bel (verbalizers). STAR (Zelikman et al., 2022)
iteratively leverages a small number of rationale
examples and a large dataset without rationales, to
bootstrap a model‚Äôs ability to perform reasoning.
Self-Correction(Wellecketal.,2023)decouplesan
imperfectbasegenerator(model)fromaseparate
correctorthatlearnstoiterativelycorrectimperfect
generationsanddemonstratesimprovementoverthe
basegenerator. Ourworkinsteadfocusesonboot-
strapping new tasks in the instruction paradigm.
Multi-modal instruction-following. Instruction-
followingmodelshavealsobeenofinterestinthe
multi-modallearningliterature(Friedetal.,2018;
Shridharetal.,2020;Minetal.,2022;Weiretal.,
2022).SELF-INSTRUCT , as a general approach to
expandingdata,canpotentiallyalsobehelpfulin
those settings, which we leave to future work.
6 Conclusion
We introduce SELF-INSTRUCT , a method to im-
provetheinstruction-followingabilityofLMsvia
their own generation of instruction data. On ex-
perimentingwithvanilla GPT3,weautomatically
constructalarge-scaledatasetof52Kinstructions
for diverse tasks, and finetuning GPT3 on this data
leads to a 33% absolute improvement on SUPERNI
over the original GPT3. Furthermore, we curate
asetofexpert-writteninstructionsfornoveltasks.
Human evaluation on this set shows that tuning
GPT3 with SELF-INSTRUCT outperforms using ex-
isting public instruction datasets by a large margin
andperformscloselyto InstructGPT001. Wehope
SELF-INSTRUCT can serve as the first step to align
pretrainedLMstofollowhumaninstructions,and
futureworkcanbuildontopofthisdatatoimprove
instruction-following models.

--- PAGE 10 ---
7 Broader Impact
Beyond the immediate focus of this paper, we
believe that SELF-INSTRUCT may help bring
more transparency to what happens ‚Äúbehind the
scenes‚Äù of widely-used instruction-tuned models
likeInstructGPT or ChatGPT. Unfortunately, such
industrial models remain behind API walls as their
datasets are not released, and hence there is lit-
tle understanding of their construction and why
they demonstrate impressive capabilities. The bur-
den now falls on academia to better understand the
source of success in these models and strive for
better‚Äîandmoreopen‚Äîmodels. Webelieveour
findingsinthispaperdemonstratetheimportance
of diverse instruction data, and our large synthetic
dataset can be the first step toward higher-quality
data for building better instruction-following mod-
els. At this writing, the central idea of this paper
has been adopted in several follow-up works for
such endeavors (Taori et al., 2023; Xu et al., 2023;
Sun et al., 2023, i.a.).
8 Limitations
Here,wediscusssomelimitationsofthisworkto
inspire future research in this direction.
Tail phenomena. SELF-INSTRUCT depends on
LMs, and it will inherit all the limitations that
carry over with LMs. As recent studies have
shown (Razeghi et al., 2022; Kandpal et al., 2022),
tail phenomena pose a serious challenge to the suc-
cess of LMs. In other words, LMs‚Äô largest gains
correspond to the frequent uses of languages (head
ofthelanguageusedistribution),andtheremight
be minimal gains in the low-frequency contexts.
Similarly,inthecontextofthiswork,itwouldnot
besurprisingifthemajorityofthegainsby SELF-
INSTRUCT areskewedtowardtasks orinstructions
that present more frequently in the pretraining cor-
pus. Asaconsequence,theapproachmightshow
brittleness with respect to uncommon and creative
instructions.
Dependence on large models. Because of SELF-
INSTRUCT ‚Äôs dependence on the inductive biases
extractedfromLMs,itmightworkbestforlarger
models. Iftrue,thismaycreatebarrierstoaccessfor
thosewhomaynothavelargecomputingresources.
Wehopefuturestudieswillcarefullystudythegains
asafunctionofmodelsizeorvariousotherparame-
ters. Itisworthwhiletonotethatinstruction-tuning
withhumanannotationalsosuffersfromasimilarlimitation: gains of instruction-tuning are higher
for larger models (Wei et al., 2022).
ReinforcingLMbiases. Apointofconcernfor
the authors is the unintended consequences of this
iterative algorithm, such as the amplification of
problematicsocialbiases(stereotypesorslursabout
gender, race, etc.). Relatedly, one observed chal-
lenge in this process is the algorithm‚Äôs difficulty in
producing balanced labels, which reflected models‚Äô
priorbiases. Wehopefutureworkwillleadtobetter
understandingoftheprosandconsoftheapproach.
Acknowledgements
The authors would like to thank the anonymous
reviewers for their constructive feedback. We espe-
ciallythankSewonMin,EricWallace,OfirPress,
andothermembersofUWNLPandAllenNLPfor
their encouraging feedback and intellectual sup-
port. ThisworkwassupportedinpartbyDARPA
MCS program through NIWC Pacific (N66001-19-
2-4031), ONR N00014-18-1-2826, ONR MURI
N00014-18-1-2670, and gifts from AI2 and an
Allen Investigator award.
References
Massih-Reza Amini, Vasilii Feofanov, Loic Pauletto,
Emilie Devijver, and Yury Maximov. 2022. Self-
training: Asurvey. arXivpreprintarXiv:2202.12040 .
Stephen H Bach, Victor Sanh, Zheng-Xin Yong, Al-
bert Webson, Colin Raffel, Nihal V Nayak, Abheesht
Sharma, Taewoon Kim, M Saiful Bari, Thibault
Fevry, et al. 2022. PromptSource: An Integrated
Development Environment and Repository for Nat-
ural Language Prompts. In Annual Meeting of the
Association for Computational Linguistics (ACL)-
System Demonstrations .
TomB.Brown,BenjaminMann,NickRyder,Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, and et al. 2020. Language
models are few-shot learners. In Advances in Neural
Information Processing Systems (NeurIPS).
Hyung Won Chung, Le Hou, Shayne Longpre, Barret
Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang,
MostafaDehghani,SiddharthaBrahma,etal.2022.
Scalinginstruction-finetunedlanguagemodels. arXiv
preprint arXiv:2210.11416 .
JingfeiDu,√âdouardGrave,BelizGunel,VishravChaud-
hary,OnurCelebi,MichaelAuli,VeselinStoyanov,
and Alexis Conneau. 2021. Self-training improves
pre-training for natural language understanding. In

--- PAGE 11 ---
Conference of the North American Chapter of the As-
sociationforComputationalLinguistics (NAACL) :
Human Language Technologies , pages 5408‚Äì5418.
Steven Y Feng, Varun Gangal, Jason Wei, Sarath Chan-
dar, Soroush Vosoughi, Teruko Mitamura, and Ed-
uard Hovy. 2021. A survey of data augmentation
approaches for nlp. In Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL)ACL-
IJCNLP - Findings , pages 968‚Äì988.
Daniel Fried, Ronghang Hu, Volkan Cirik, Anna
Rohrbach,JacobAndreas,Louis-PhilippeMorency,
Taylor Berg-Kirkpatrick, Kate Saenko, Dan Klein,
andTrevorDarrell.2018. Speaker-followermodels
forvision-and-languagenavigation. In Advancesin
Neural Information Processing Systems (NeurIPS).
Junxian He, Jiatao Gu, Jiajun Shen, and Marc‚ÄôAurelio
Ranzato. 2019. Revisiting self-training for neural
sequence generation. In International Conference on
Learning Representations (ICLR).
GeoffreyHinton,OriolVinyals,JeffDean,etal.2015.
Distilling the knowledge in a neural network. In
Advances in Neural Information Processing Systems
(NeurIPS) Workshop on Deep Learning .
Or Honovich, ThomasScialom, Omer Levy, andTimo
Schick. 2022a. Unnatural instructions: Tuning lan-
guagemodelswith(almost)nohumanlabor. arXiv
preprint arXiv:2212.09689 .
Or Honovich, Uri Shaham, Samuel R Bowman, and
Omer Levy. 2022b. Instruction induction: From few
examplestonaturallanguagetaskdescriptions. arXiv
preprint arXiv:2205.10782 .
Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu,
Xuezhi Wang, Hongkun Yu, and Jiawei Han. 2022.
Large language models can self-improve. arXiv
preprint arXiv:2210.11610 .
Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric
Wallace, and Colin Raffel. 2022. Large language
modelsstruggletolearnlong-tailknowledge. arXiv
preprint arXiv:2211.08411 .
Nikita Kitaev, Steven Cao, and Dan Klein. 2019. Multi-
lingualconstituencyparsingwithself-attentionand
pre-training. In AnnualMeetingoftheAssociationfor
Computational Linguistics (ACL), pages 3499‚Äì3505.
Nikita Kitaev and Dan Klein. 2018. Constituency pars-
ing with a self-attentive encoder. In Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 2676‚Äì2686.
Brian Lester, Rami Al-Rfou, and Noah Constant. 2021.
Thepowerofscaleforparameter-efficientprompttun-
ing. InConference on Empirical Methods in Natural
Language Processing (EMNLP).
AlisaLiu,SwabhaSwayamdipta, NoahA.Smith, and
Yejin Choi. 2022. WANLI: Worker and ai collabora-
tion for natural language inference dataset creation.InConference on Empirical Methods in Natural Lan-
guage Processing (EMNLP) - Findings .
Lucie Charlotte Magister, Jonathan Mallinson, Jakub
Adamek, Eric Malmi, and Aliaksei Severyn. 2022.
Teaching small language models to reason. arXiv
preprint arXiv:2212.08410 .
Dheeraj Mekala, Tu Vu, Timo Schick, and Jingbo
Shang. 2022. Leveraging qa datasets to improve
generative data augmentation. arXiv preprint
arXiv:2205.12604 .
YuMeng,MartinMichalski,JiaxinHuang,YuZhang,
Tarek Abdelzaher, and Jiawei Han. 2023. Tun-
ing language models as training data generators for
augmentation-enhancedfew-shotlearning. In Inter-
national Conference on Machine Learning (ICML).
SoYeonMin,DevendraSinghChaplot,PradeepRaviku-
mar, Yonatan Bisk, and Ruslan Salakhutdinov. 2022.
FILM:FollowingInstructionsinLanguagewithMod-
ular Methods. In International Conference on Learn-
ing Representations (ICLR).
Swaroop Mishra, Daniel Khashabi, Chitta Baral, and
HannanehHajishirzi.2022. Cross-TaskGeneraliza-
tion via Natural Language Crowdsourcing Instruc-
tions. InAnnual Meeting of the Association for Com-
putational Linguistics (ACL).
Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-
roll L Wainwright, Pamela Mishkin, Chong Zhang,
SandhiniAgarwal, KatarinaSlama, AlexRay, etal.
2022. Training Language Models to Follow Instruc-
tions withHuman Feedback. In Advances inNeural
Information Processing Systems (NeurIPS).
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine
Lee, Sharan Narang, Michael Matena, Yanqi Zhou,
Wei Li, and Peter J Liu. 2020. Exploring the lim-
its of transfer learning with a unified text-to-text
transformer. Journal of Machine Learning Research
(JMLR).
Yasaman Razeghi, Robert L Logan IV, Matt Gardner,
and Sameer Singh. 2022. Impact of pretraining term
frequencies on few-shot reasoning. arXiv preprint
arXiv:2202.07206 .
Victor Sanh, Lysandre Debut, Julien Chaumond, and
Thomas Wolf. 2019. Distilbert, a distilled version of
bert: smaller,faster,cheaperandlighter. In Advances
in Neural Information Processing Systems (NeurIPS)
WorkshoponEnergyEfficientMachineLearningand
Cognitive Computing .
VictorSanh,AlbertWebson,ColinRaffel,StephenBach,
Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin,
Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful
Bari, Canwen Xu, Urmish Thakker, Shanya Sharma
Sharma, Eliza Szczechla, Taewoon Kim, Gunjan
Chhablani,NihalNayak,DebajyotiDatta,Jonathan
Chang, Mike Tian-Jian Jiang, Han Wang, Matteo
Manica, Sheng Shen, Zheng Xin Yong, Harshit
Pandey, Rachel Bawden, Thomas Wang, Trishala

--- PAGE 12 ---
Neeraj, Jos Rozen, Abheesht Sharma, Andrea San-
tilli, Thibault Fevry, Jason Alan Fries, Ryan Tee-
han, Teven Le Scao, Stella Biderman, Leo Gao,
ThomasWolf,andAlexanderMRush.2022. Multi-
taskPromptedTrainingEnablesZero-ShotTaskGen-
eralization. In International Conference on Learning
Representations (ICLR).
Timo Schick and Hinrich Sch√ºtze. 2021. Generating
datasets with pretrained language models. In Con-
ferenceonEmpiricalMethodsinNaturalLanguage
Processing (EMNLP).
Mohit Shridhar, Jesse Thomason, Daniel Gordon,
YonatanBisk,WinsonHan,RoozbehMottaghi,Luke
Zettlemoyer, and Dieter Fox. 2020. ALFRED: A
Benchmark for Interpreting Grounded Instructions
for Everyday Tasks. In IEEE Conference on Com-
puter Vision and Pattern Recognition (CVPR).
Chandan Singh, John X Morris, Jyoti Aneja, Alexan-
derMRush,andJianfengGao.2022. Explainingpat-
ternsindatawithlanguagemodelsviainterpretable
autoprompting. arXiv preprint arXiv:2210.01848 .
Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin
Zhang, Zhenfang Chen, David Cox, Yiming Yang,
and Chuang Gan. 2023. Principle-driven self-
alignment of language models from scratch with
minimal human supervision. arXiv preprint
arXiv:2305.03047 .
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann
Dubois, Xuechen Li, Carlos Guestrin, Percy Liang,
and Tatsunori B. Hashimoto. 2023. Stanford al-
paca: An instruction-following llama model. https:
//github.com/tatsu-lab/stanford_alpaca .
Yizhong Wang, Swaroop Mishra, Pegah Alipoor-
molabashi, Yeganeh Kordi, Amirreza Mirzaei,
Anjana Arunkumar, Arjun Ashok, Arut Selvan
Dhanasekaran, Atharva Naik, David Stap, Eshaan
Pathak, Giannis Karamanolakis, Haizhi Gary Lai, Is-
hanPurohit,IshaniMondal,JacobAnderson,Kirby
Kuznia, Krima Doshi, Maitreya Patel, Kuntal Ku-
mar Pal, Mehrad Moradshahi, Mihir Parmar, Mi-
rali Purohit, Neeraj Varshney, Phani Rohitha Kaza,
PulkitVerma,RavsehajSinghPuri,RushangKaria,
Shailaja Keyur Sampat, Savan Doshi, Siddhartha
Mishra, Sujan Reddy, Sumanta Patro, Tanay Dixit,
Xudong Shen, Chitta Baral, Yejin Choi, Noah A.
Smith, Hannaneh Hajishirzi, and Daniel Khashabi.
2022. Super-naturalinstructions: Generalizationvia
declarative instructions on 1600+ tasks. In Confer-
enceonEmpiricalMethodsinNaturalLanguagePro-
cessing(EMNLP).
ZiruiWang,AdamsWeiYu,OrhanFirat,andYuanCao.
2021. Towardszero-labellanguagelearning. arXiv
preprint arXiv:2109.09193 .
Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu,
Adams Wei Yu, Brian Lester, Nan Du, Andrew M.
Dai, and Quoc V Le. 2022. Finetuned Language
Models are Zero-Shot Learners. In International
Conference on Learning Representations (ICLR).Nathaniel Weir, Xingdi Yuan, Marc-Alexandre C√¥t√©,
Matthew Hausknecht, Romain Laroche, Ida Momen-
nejad,HarmVanSeijen,andBenjaminVanDurme.
2022. One-Shot Learning from a Demonstration
with Hierarchical Latent Language. arXiv preprint
arXiv:2203.04806 .
Sean Welleck, Ximing Lu, Peter West, Faeze Brah-
man, Tianxiao Shen, Daniel Khashabi, and Yejin
Choi. 2023. Generating sequences by learning to
self-correct. In InternationalConferenceonLearn-
ing Representations (ICLR).
Orion Weller, Nicholas Lourie, Matt Gardner, and
Matthew Peters. 2020. Learning from Task Descrip-
tions. InConference on Empirical Methods in Natu-
ral Language Processing (EMNLP).
PeterWest,ChandraBhagavatula,JackHessel,JenaD
Hwang, Liwei Jiang, Ronan Le Bras, Ximing Lu,
Sean Welleck, and Yejin Choi. 2021. Symbolic
knowledgedistillation: fromgenerallanguagemod-
els to commonsense models. In Conference of the
North American Chapter of the Association for Com-
putational Linguistics (NAACL).
Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and
Quoc V Le. 2020. Self-training with noisy student
improves imagenet classification. In IEEE Confer-
ence on Computer Vision and Pattern Recognition
(CVPR), pages 10687‚Äì10698.
Canwen Xu, Daya Guo, Nan Duan, and Julian McAuley.
2023. Baize: An open-source chat model with
parameter-efficient tuning on self-chat data. arXiv
preprint arXiv:2304.01196 .
Yiben Yang, Chaitanya Malaviya, Jared Fernandez,
SwabhaSwayamdipta,RonanLeBras,Ji-PingWang,
ChandraBhagavatula,YejinChoi,andDougDowney.
2020. Generative data augmentation for common-
sensereasoning. In ConferenceonEmpiricalMeth-
odsinNaturalLanguageProcessing (EMNLP) -Find-
ings.
Seonghyeon Ye, Doyoung Kim, Joel Jang, Joongbo
Shin, and Minjoon Seo. 2022. Guess the instruction!
making language models stronger zero-shot learners.
arXiv preprint arXiv:2210.02969 .
Eric Zelikman, Jesse Mu, Noah D Goodman, and
YuhuaiTonyWu.2022. STar: Self-taughtreasoner
bootstrappingreasoningwithreasoning. In Advances
inNeuralInformationProcessingSystems (NeurIPS).
Xuandong Zhao, Siqi Ouyang, Zhiguo Yu, Ming Wu,
and Lei Li. 2022. Pre-trained language models
can be fully zero-shot learners. arXiv preprint
arXiv:2212.06950 .
ChuntingZhou,JunxianHe,XuezheMa,TaylorBerg-
Kirkpatrick, and Graham Neubig. 2022a. Prompt
Consistency for Zero-Shot Task Generalization. In
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP) - Findings .

--- PAGE 13 ---
Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han,
KeiranPaster,SilviuPitis,HarrisChan,andJimmy
Ba.2022b. Largelanguagemodelsarehuman-level
prompt engineers. arXiv preprint arXiv:2211.01910 .

--- PAGE 14 ---
Supplemental Material
A Implementation Details
A.1 Writing the Seed Tasks
Our method relies on a set of seed tasks to bootstrap the generation. The seed tasks are important for both
encouraging the task diversity and demonstrating correct ways for solving the diverse tasks. For example,
withcodingtaskstopromptthemodel,ithasalargerchancetogeneratecoding-relatedtasks;it‚Äôsalso
bettertohavecodingoutputtoguidethemodelinwritingcodefornewtasks. So,themorediversethe
seed tasks are, the more diverse and better quality the generated tasks will be.
Our seed tasks were written when we initiated this project, and targeted for the diverse and interesting
usages of LLMs. The tasks were written by the authors and our labmates at UWNLP, without explicit
reference to existing datasets or specific testing tasks. We further categorized the tasks into classification
and non-classification tasks, based on whether the task has a limited output label space. In total, there are
25 classification tasks and 150 non-classification tasks. We release this data in our GitHub repository.11
To provide a sense of how much the model is generalizing beyond these seed tasks, we further quantify
theoverlapbetweentheinstructionsoftheseseedtasksandtheinstructionsofourtestsets,includingboth
SUPERNItaskinstructions(¬ß4.3)andtheuser-orientedinstructionsinourhumanevaluation(¬ß4.4). We
compute ROUGE-Lsimilarities between eachseed instruction and itsmost similar instructionin the test
set. ThedistributionoftheROUGE-LscoresareplottedinFigure8,withtheaverageROUGE-Lsimilarity
betweentheseedinstructionsand SUPERNIas0.21,andtheaverageROUGE-Lsimilaritybetweenthe
seedinstructionsanduser-orientedinstructionsas0.34. Weseeadecentdifferencebetweentheseedtasks
and both test sets. There is exactly one identical seed instruction occurring in the user-oriented instruction
test set, which is ‚Äúanswer the following question‚Äù and the following questions are actually very different.
0 0.2 0.4 0.6 0.8 101020304050
ROUGE-L  SimilarityNumber of Instructions
0 0.2 0.4 0.6 0.8 105101520253035
ROUGE-L  SimilarityNumber of Instructions
Figure 8: Distribution of the ROUGE-L scores between seed instructions and their most similar instructions in
SUPERNI (left) and the 252 user-oriented instructions (right).
A.2 Querying the GPT3 API
We use different sets of hyperparameters when querying GPT3 API for different purposes. These hyperpa-
rameters are found to work well with the GPT3 model (‚Äúdavinci‚Äù engine) and the other instruction-tuned
GPT3variants. We listed them in Table 4. OpenAI charges $0.02 per 1000 tokens for making completion
requesttothe‚Äúdavinci‚ÄùengineasofDecember,2022. Thegenerationofourentiredatasetcostaround
$600.
A.3 Finetuning GPT3
GPT3SELF-INSTandsomeofourbaselinesarefinetunedfrom GPT3model(‚Äúdavinci‚Äùenginewith175B
parameters). We conduct this finetuning via OpenAI‚Äôs finetuning API.12While the details of how the
model is finetuned with this API are not currently available (e.g., which parameters are updated, or what
11https://github.com/yizhongw/self-instruct/blob/main/human_eval/user_oriented_instructions.
jsonl
12See the the details on OpenAI‚Äôs API.

--- PAGE 15 ---
Experiments ‚Üì Temp. Top_P Freq. Penalty Presence Penalty Beam Size Max Length Stop Sequences
Generating instructions 0.7 0.5 0 2 1 1024 "\n\n", "\n16", "16.", "16 ."
Identifying clf. tasks 0 0 0 0 1 3 "\n", "Task:"
Generating instances 0 0 0 1.5 1 300 "Task:"
Evaluating models 0 0 0 0 0 1024 None (default)
Table 4: Hyper-parameters for querying OpenAI API in different experiments.
theoptimizeris),wetuneallourmodelswiththedefaulthyperparametersofthisAPIsothattheresultsare
comparable. Weonlysetthe‚Äúprompt_loss_weight‚Äùto0sincewefindthisworksbetterinourcase,and
every finetuning experiment is trained for two epochs to avoid overfitting the training tasks. Finetuning is
charged based on the number of tokens in the training file. In our case, finetuning GPT3SELF-INSTfrom the
GPT3 model on the entire generated data cost $338.
A.4 Prompting Templates for Data Generation
SELF-INSTRUCT relies on a number of prompting templates in order to elicit the generation from language
models. Here we provide our four templates for generating the instruction (Table 5), classifying whether
an instruction represents a classification task or not (Table 6), generating non-classification instances with
theinput-firstapproach(Table7),andgeneratingclassificationinstanceswiththeoutput-firstapproach
(Table 8).
Come up with a series of tasks:
Task 1: {instruction for existing task 1}
Task 2: {instruction for existing task 2}
Task 3: {instruction for existing task 3}
Task 4: {instruction for existing task 4}
Task 5: {instruction for existing task 5}
Task 6: {instruction for existing task 6}
Task 7: {instruction for existing task 7}
Task 8: {instruction for existing task 8}
Task 9:
Table5: Promptusedforgeneratingnewinstructions. 8existinginstructionsarerandomlysampledfromthetask
pool for in-context demonstration. The model is allowed to generate instructions for new tasks, until it stops its
generation, reaches its length limit or generates ‚ÄúTask 16‚Äù tokens.

--- PAGE 16 ---
Can the following task be regarded as a classification task with finite output labels?
Task: Given my personality and the job, tell me if I would be suitable.
Is it classification? Yes
Task: Give me an example of a time when you had to use your sense of humor.
Is it classification? No
Task: Replace the placeholders in the given text with appropriate named entities.
Is it classification? No
Task: Fact checking - tell me if the statement is true, false, or unknown, based on your
knowledge and common sense.
Is it classification? Yes
Task: Return the SSN number for the person.
Is it classification? No
Task: Detect if the Reddit thread contains hate speech.
Is it classification? Yes
Task: Analyze the sentences below to identify biases.
Is it classification? No
Task: Select the longest sentence in terms of the number of words in the paragraph, output
the sentence index.
Is it classification? Yes
Task: Find out the toxic word or phrase in the sentence.
Is it classification? No
Task: Rank these countries by their population.
Is it classification? No
Task: You are provided with a news article, and you need to identify all the categories that
this article belongs to. Possible categories include: Music, Sports, Politics, Tech, Finance,
Basketball, Soccer, Tennis, Entertainment, Digital Game, World News. Output its categories one
by one, seperated by comma.
Is it classification? Yes
Task: Given the name of an exercise, explain how to do it.
Is it classification? No
Task: Select the oldest person from the list.
Is it classification? Yes
Task: Find the four smallest perfect numbers.
Is it classification? No
Task: Does the information in the document supports the claim? You can answer "Support" or
"Unsupport".
Is it classification? Yes
Task: Create a detailed budget for the given hypothetical trip.
Is it classification? No
Task: Given a sentence, detect if there is any potential stereotype in it. If so, you should
explain the stereotype. Else, output no.
Is it classification? No
‚ãØ
Task: To make the pairs have the same analogy, write the fourth word.
Is it classification? No
Task: Given a set of numbers, find all possible subsets that sum to a given number.
Is it classification? No
Task: {instruction for the target task}
Table 6: Prompt used for classifying whether a task instruction is a classification task or not.

--- PAGE 17 ---
Come up with examples for the following tasks. Try to generate multiple examples when possible.
If the task doesn‚Äôt require additional input, you can generate the output directly.
Task: Which exercises are best for reducing belly fat at home?
Output:
- Lying Leg Raises
- Leg In And Out
- Plank
- Side Plank
- Sit-ups
Task: Extract all the country names in the paragraph, list them separated by commas.
Example 1
Paragraph: Dr. No is the sixth novel by the English author Ian Fleming to feature his British
Secret Service agent James Bond. Written at Fleming‚Äôs Goldeneye estate in Jamaica, it was
first published in the United Kingdom by Jonathan Cape in 1958. In the novel Bond looks into
the disappearance in Jamaica of two fellow MI6 operatives who had been investigating Doctor
No. Bond travels to No‚Äôs Caribbean island and meets Honeychile Rider, who is there to collect
shells. They are captured and taken to a luxurious facility carved into a mountain. The
character of Doctor No, the son of a German missionary and a Chinese woman, was influenced by
Sax Rohmer‚Äôs Fu Manchu stories. Dr. No was the first of Fleming‚Äôs novels to face widespread
negative reviews in Britain, but it was received more favourably in the United States.
Output: English, British, Jamaica, the United Kingdom, German, Chinese, Britain, the United
States.
Task: Converting 85 F to Celsius.
Output: 85 ¬∞F = 29.44 ¬∞C
Task: Sort the given list ascendingly.
Example 1
List: [10, 92, 2, 5, -4, 92, 5, 101]
Output: [-4, 2, 5, 5, 10, 92, 92, 101]
Example 2
Input 2 - List: [9.99, 10, -5, -1000, 5e6, 999]
Output: [-1000, -5, 9.99, 10, 999, 5e6]
Task: Suggest a better and more professional rephrasing of the following sentence.
Example 1
Sentence: This house is surprisingly not constructed very well, and you probably need more
money to fix it after you buy it. If you ask me, I would suggest you to consider other
candidates.
Output: This house does not seem to be constructed well, so you may need to spend more money
to fix it after you purchase it. I would suggest that you look at other properties.
Example 2
Sentence: Just so you know, we did an experiment last week and found really surprising results
- language model can improve itself!
Output: Our experiments last week demonstrated surprising results, proving that the language
model can improve itself.
‚ãØ
Task: Turn down a job offer by sending an email to a recruiter explaining the reason.
Output: Hi [Recruiter],
Thank you so much for the generous offer to join your team. As we discussed, I‚Äôve admired the
company for a number of years, and am a proud endorser of its products. However, after further
consideration of where I currently am in my career, I‚Äôve decided to accept an offer at another
company.
I would love to stay in touch with you and have already started following you on [Social Media
Platform]. Again, thank you so much for your time and consideration.
Thanks again,
[Your Name]
Task: {Instruction for the target task}
Table 7: Prompt used for the input-first approach of instance generation. The model is prompted to generate the
instancefirst,andthengeneratethecorrespondingoutput. Forinstructionsthatdon‚Äôtrequireadditionalinput,the
output is allowed to be generated directly.

--- PAGE 18 ---
Given the classification task definition and the class labels, generate an input that
corresponds to each of the class labels. If the task doesn‚Äôt require input, just generate the
correct class label.
Task: Classify the sentiment of the sentence into positive, negative, or mixed.
Class label: mixed
Sentence: I enjoy the flavor of the restaurant but their service is too slow.
Class label: Positive
Sentence: I had a great day today. The weather was beautiful and I spent time with friends.
Class label: Negative
Sentence: I was really disappointed by the latest superhero movie. I would not recommend it.
Task: Given a dialogue, classify whether the user is satisfied with the service. You should
respond with "Satisfied" or "Unsatisfied".
Class label: Satisfied
Dialogue:
- Agent: Thank you for your feedback. We will work to improve our service in the future.
- Customer: I am happy with the service you provided. Thank you for your help.
Class label: Unsatisfied
Dialogue:
- Agent: Sorry that we will cancel your order. You will get a refund within 7 business days.
- Customer: oh that takes too long. I want you to take quicker action on this.
Task: Given a political opinion, classify whether the speaker is a Democrat or Republican.
Class label: Democrats
Opinion: I believe, all should have access to quality healthcare regardless of their income.
Class label: Republicans
Opinion: I believe that people should be able to keep more of their hard-earned money and
should not be taxed at high rates.
Task: Tell me if the following email is a promotion email or not.
Class label: Promotion
Email: Check out our amazing new sale! We‚Äôve got discounts on all of your favorite products.
Class label: Not Promotion
Email: We hope you are doing well. Let us know if you need any help.
Task: Detect if the Reddit thread contains hate speech.
Class label: Hate Speech
Thread: All people of color are stupid and should not be allowed to vote.
Class label: Not Hate Speech
Thread: The best way to cook a steak on the grill.
Task: Does the document supports the claim? Answer with "Support" or "Unsupport".
Class label: Unsupport
Document: After a record-breaking run that saw mortgage rates plunge to all-time lows and
home prices soar to new highs, the U.S. housing market finally is slowing. While demand and
price gains are cooling, any correction is likely to be a modest one, housing economists and
analysts say. No one expects price drops on the scale of the declines experienced during the
Great Recession.
Claim: The US housing market is going to crash soon.
Class label: Support
Document: The U.S. housing market is showing signs of strain, with home sales and prices
slowing in many areas. Mortgage rates have risen sharply in recent months, and the number
of homes for sale is increasing. This could be the beginning of a larger downturn, with some
economists predicting a potential housing crash in the near future.
Claim: The US housing market is going to crash soon.
‚ãØ
Task: Which of the following is not an input type? (a) number (b) date (c) phone number (d)
email address (e) all of these are valid inputs.
Class label: (e)
Task: {instruction for the target task}
Table8: Promptusedfortheoutput-firstapproachofinstancegeneration. Themodelispromptedtogeneratethe
class label first, and then generate the corresponding input. This prompt is used for generating the instances for
classification tasks.

--- PAGE 19 ---
B Human Evaluation Details for Following the User-oriented Instructions
B.1 Human Evaluation Setup
Hereweprovidemoredetailsforthehumanevaluationdescribedin¬ß4.4forratingthemodels‚Äôresponsesto
the252user-orientedinstructions. Toensurefaithfulandreliableevaluation,weaskedtwoauthorsofthese
instructions(andofthispaper)tojudgemodelpredictions. Thesetwoevaluatorscoordinatedthestandards
for the 4-level rating system before starting annotation and then each of them rated all the instances
independently. Theywerepresentedwiththeinstruction,instanceinput,targetoutput(asareference),and
model responses. Model responses are listed in random order, with all the model information anonymized.
Figure9providesascreenshotoftheannotationinterface. Thereportedperformanceinthispaperisbased
on the results from one of the evaluators, and the trends from the other evaluator‚Äôs results are the same.
Figure9: HumanevaluationindoneusingaGooglesheet,withpredictionsfromdifferentmodelspresentinrandom
orderand themodel informationbeing anonymized. Ourexpertevaluators arerequired toread theinstruction and
input, refer to the target, and then select the rating for the model‚Äôs response from A/B/C/D, corresponding to the 4
levels described in ¬ß4.4.
B.2 Human Evaluation Agreement
To measure how reliable our human evaluation is, we calculate the inner-rater agreement between our two
evaluators.
WefirstreportCohen‚Äôs ùúÖ,whichiscommonlyusedtomeasureinter-rateragreementfor categorical
items. When calculating this, we treat the 4-level rating (A-D) as a categorical variable, leading to a ùúÖof
0.58, which is a moderate agreement according to common practice.13Furthermore, we also calculate the
agreement of our evaluators on classifying acceptable responses ((A or B) vs. (C or D)), with a final ùúÖof
0.75, indicating substantial agreement.
WealsocomputetheSpearmancorrelationcoefficient ùúåbetweentheratingsofourtwoevaluatorsby
treating the rating as an ordinal variable (A>B>C>D). The final coefficient is ùúå= 0.81, indicating a high
13https://en.wikipedia.org/wiki/Cohen%27s_kappa

--- PAGE 20 ---
correlation between the two evaluators.
B.3 Example Predictions from GPT3SELF-INST
Wepresentaselectionofuser-orientedtasks,thecorresponding GPT3SELF-INST-producedresponsesand
annotator ratings in Table 9. We see that even for responses rated as level C, the model demonstrates
extensive steps in solving the task, even though its final output is incorrect.

--- PAGE 21 ---
Instruction + Instance Input Target Response GPT3SELF-INSTResponse Rating
Instruction: Give students tips
on how to keep their nerves under
control during class presentations.Everyone gets a little nervous when speaking
in front of a group. That‚Äôs normal. But the
more preparation you‚Äôve done‚Äîmeaning plenty of
researching, organizing, and rehearsing‚Äîthe more
confident you‚Äôll be. Preparation is the key.
And if you make a mistake or stumble over your
words, just regroup and keep going. Nobody‚Äôs
perfect, and nobody expects you to be.‚Äì Practice your presentation in front
of friends and family.
‚Äì Don‚Äôt drink too much caffeine before
the presentation.
‚Äì Take deep breaths before you start
speaking.
‚Äì If you feel nervous, smile.
‚Äì Remember that everyone in the
audience is rooting for you.A
Instruction: Make a list of the pros
and cons of the given decision.
Input: Implementing a Remote Working
PolicyPros:
‚Äì Allowing employees to work from home can
reduce their stressful commutes and increase
their productivity.
‚Äì Remote working provides greater flexibility,
particularly for working parents and
caregivers who have other responsibilities.
‚Äì ...(more points)
Cons:
‚Äì It may be more difficult for team members
to build meaningful, productive, creative
relationships with one another.
‚Äì ...(more points)Pros:
‚Äì Employees can work from home and
save on commuting costs.
‚Äì Employees can spend more time with
their families.
Cons:
‚Äì Employees may not be as productive
as they would be in the office.
‚Äì Employees may not be as motivated to
work.A
Instruction: A user story is an
informal, general explanation of
a software feature written from
the perspective of the end-user or
customer. Write a user story for a
given software.
Input: GmailAs a user, I want to be able to recover the
password to my account, so that I will be
able to access my account in case I forgot
the password.As a user, I want to be able to send
emails to my friends and family. I
want to be able to attach files to my
emails. I want to be able to search
for emails in my inbox.A
Instruction: A color description has
been provided. Find the CSS code
associated with that color.
Input: A light red color with a
medium light shade of pink#DB7093 ( ‚¨õ) #ff66cc ( ‚¨õ) B
Instruction: Someone gives you some
information about where they want
to go and what they enjoy seeing and
doing. Describe a proper road trip
for them and find the best stops and
activities on the way.
Input: I‚Äôm looking for a west coast
road trip. My goal is to start near
San Diego and travel to Los Angeles.Begin near the city of San Diego and make the
first stop in coastal La Jolla. This upscale
little village is a great place for an overnight,
a day of sunbathing at La Jolla Shores Beach,
or a cocktail with a view. Just 20 minutes
north, stop into beachy Encinitas to window
shop the boutiques or sample fish tacos. Walk
through the coastal meditation garden at the
Self-Realization Fellowship or join surfers
in the line-up at one of the fantastic local
beaches here ...(more ideas)You should start your trip in San
Diego, California. You can visit the
San Diego Zoo, which is one of the
best zoos in the world. Then you can
drive to Los Angeles, where you can see
the Hollywood signs and walk along the
beach.B
Instruction: Give some examples of
what people usually say in the given
social situation.
Input: when someone arrives safely‚Äì ‚ÄúGlad you made it safe and sound.‚Äù
‚Äì ‚ÄúGood to see you got here unscathed.‚Äù
‚Äì ‚ÄúSo, bulletproof vests actually work!‚ÄùThank God, I made it. B
Instruction: You are given a sentence
in first-order logic. Translate it
into natural language.
Input: ‚àÉùë•‚àÄùë¶(ùë†ùëúùëôùëëùëñùëíùëü (ùë•)‚Üíùëîùëíùëõùëíùëüùëéùëô (ùë•,ùë¶))There is someone (x) such that if he is a
soldier, then he is general of everyone.There exists a soldier such that for
every general, he is a general.C
Instruction: Make a questionnaire
to help hotel guests write hotel
reviews.‚Äì Your overall rating of this hotel:
‚Äì Summarize your visit or highlight an
interesting detail:
‚Äì ...(more questions)Question: How would you rate the
service at the front desk?
Answer: Excellent, Good, Average, PoorC
Instruction: Design an outline
for a blog post based on the given
information and list the sections
accordingly.
Input: This blog post is going to
about making a list of last-minute
gift ideas. Also, the tone of the
post is going to be relaxed and
casual.‚Äì Section: Movie tickets
‚Äì Section: A fun game console
‚Äì Section: Personalized items with
photos/artwork
‚Äì ...(more sections)
‚Äì Takeaway: Don‚Äôt stress about out running out
of time to buy, make a gift.‚Äì Introduction
‚Äì List of Gift Ideas
‚Äì ConclusionC
Instruction: Write a Jira ticket for
the given task.
Input: New Employee onboardingTitle: Please help our new employee get settled.
Prepare a desk, chair, and computer for them to
use. Create their company account, email, and
temporary password. Grant access to company
documents.Hi [Manager], I‚Äôm writing to you
because I have a question about the new
employee onboarding process. I‚Äôve been
working here for a few months now, and
I‚Äôm still not sure how it works. Could
you please explain it to me?D
Instruction: Create alliterations
by finding synonyms for words in the
given sentence.
Input: David wears a hat everyday.David dons a derby daily. David wears a hat every day. D
Table9: Examplesintheuser-orientedinstructionsdataset(¬ß4.4)andpredictionsfrom GPT3SELF-INST. Theright
columnindicatesoneofthefourqualityratingsassignedtothemodel‚Äôsresponse,with‚ÄúA‚Äùindicating‚Äúvalidand
satisfying‚Äù responses (highest) and ‚ÄúD‚Äù indicating ‚Äúirrelevant or invalid response‚Äù (lowest).

--- PAGE 22 ---
C Task and Instance Examples from the Generated Instruction Data
Instruction + Instance Input Target Output Validity
Instruction: Generate a random password
with at least 6 characters.def generateRandomPassword():
password = ""
while len(password) < 6:
password += chr(random.randint(65, 90))
return passwordInstruction: ‚úì
Input:‚úì
Output: ‚úì
Instruction: Write a paragraph describing
how to tie shoelaces for people who have
never tied their shoes before. explain
each step briefly.Paragraph: To tie shoelaces, first you need to make a loop with one
end of the lace. Then pass the other end through the loop and pull
it tight. Next, you need to wrap the lace around the shoe several
times. Finally, tuck in the loose end into the wrapped part of the
lace.Instruction: ‚úì
Input:‚úì
Output: ‚úì
Instruction: Given a word, find out its
length and its number of vowels.
Input: Word = "hello"Length = 5, Number of vowels = 2 Instruction: ‚úì
Input:‚úì
Output: ‚úì
Instruction: Write a story with three
characters: a person, an animal and an
object.
Input: Person: John, a programmer.
Animal: A dog.
Object: A laptop.John was sitting on the floor in front of his laptop when he heard a
knock at the door. He opened it to find a dog standing there. The
dog walked into the room and jumped onto the couch next to John‚Äôs
laptop.Instruction: ‚úì
Input:‚úì
Output: ‚úì
Instruction: Compose an email and send it
to your friend, asking for advice on what
to do in this situation.
Input: Situation: You are a programmer
and you have been working on a project
for the past few months. The deadline is
approaching, but you haven‚Äôt finished yet.
Your manager has asked you to stay late
every day this week to finish it.Hi [Friend],
I‚Äôm having a bit of trouble with my current job. I‚Äôve been
working on a project for the past few months, and the deadline
is approaching. My manager has asked me to stay late every day this
week to finish it. I don‚Äôt think I can do that because I have other
commitments. What should I do?Instruction: ‚úì
Input:‚úì
Output: ‚úì
Instruction: What are some ways we can
make our school more eco-friendly?‚Äì Use reusable water bottles instead of disposable plastic ones.
‚Äì Turn off lights when you leave a room.
‚Äì Recycle paper, cans and bottles.
‚Äì Plant trees to absorb carbon dioxide.Instruction: ‚úì
Input:‚úì
Output: ‚úì
Instruction: I am looking for a new
apartment. there are many options
available but they are all quite expensive.
i want to move as soon as possible. give
me advice on what to do.You should look for a cheaper apartment. You can try to negotiate
with the landlord and offer him/her a lower price. If you are lucky,
they will accept your offer. Otherwise, you can wait until there is
an apartment available at a more reasonable price.Instruction: ‚úì
Input:‚úì
Output: ‚úì
Instruction: Write a dialogue between
two people who have been friends for a
long time, and one of them is trying to
convince the other to do something that he
or she doesn‚Äôt want to do.A: Hey, I have a great idea! Let‚Äôs go to the beach today.
B: No thanks, I‚Äôm not really in the mood for that.
A: Come on, it‚Äôll be fun! We haven‚Äôt been there together in ages.
B: I know, but I just don‚Äôt feel like going.
A: But you love the beach! You always say how much you enjoy
swimming and lying in the sun.
B: Yeah, I do. It‚Äôs just that I‚Äôve been feeling kind of tired
lately.
A: Oh, come on. You‚Äôre never tired. You‚Äôre always so energetic.
B: Well, I am now. I think I need some rest.
A: Okay, fine. If you change your mind, let me know.Instruction: ‚úì
Input:‚úì
Output: ‚úì
Instruction: How can i create an app that
will be able to identify different kinds
of plants by taking photos of them?You can use the following steps to create an app that will be able
to identify different kinds of plants by taking photos of them.
Step 1: Create a database with all the information about the plants
you want to identify.
Step 2: Create a user interface for your application.
Step 3: Use image recognition techniques to identify the plant in
the photo.
Step 4: Display the name of the plant on the screen.Instruction: ‚úì
Input:‚úì
Output: ‚úì
Instruction: Find the closest matching
emoji to a given one.
Input: Emoji:
Instruction: ‚úì
Input:‚úì
Output: ‚úì
Instruction: Describe your favorite video
game using only verbs.
Input: Game: The Legend of ZeldaExplore, fight, solve, upgrade, repeat Instruction: ‚úì
Input:‚úì
Output: ‚úì
Table 10: Representative validtasks generated by GPT3. As is discussed in ¬ß3, these generated tasks cover a broad
rangeofformats,texttypes,andunderlyingexpertise,whilebeingcorrectonmorethanhalfofallthegenerated
tasks.

--- PAGE 23 ---
Instruction + Instance Input Target Output Validity
Instruction: Given a set of words
ùë§ = {ùë§1,ùë§2,...,ùë§ùëõ}where each word ùë§ùëñ
hasùëõletters, write a function that
takes a target length ùëôand returns a
new set of words ùë†such that |ùë†|=ùëôand
|{ùëñ‚à∂ùë§ùëñ‚ààùë†}|‚â§ùëô‚àï|ùë§|.def wordSubsetSum(w, l):
s = []
for i in range(len(w)):
if len(s) + 1 < l:
s.append(w[i])
return sInstruction: ‚úó
Input:‚úì
Output: ‚úó
Instruction: The house on fire! go!‚Äì Go to the kitchen and take a pan.
‚Äì Take water from the tap.
‚Äì Pour water into the pan.
‚Äì Put out the fire with the pan.Instruction: ‚úó
Input:‚úì
Output: ‚úó
Instruction: Find out if you have any
friends who like to play football or
chess.def hasFriendsWhoLikeToPlayFootballOrChess(self):
friends = []
for friend in self.friends:
if friend.likes == ‚Äôfootball‚Äô or friend.likes == ‚Äôchess‚Äô:
friends.append(friend)
return len(friends) > 0Instruction: ‚úó
Input:‚úì
Output: ‚úì
Instruction: A number of people are lined
up for an interview. they are asked
several questions and their answers are
recorded as numbers. you need to identify
which person has the highest salary among
all the candidates.
Input: Person 1: 2, 3, 4, 5, 6
Person 2: 7, 8, 9, 10, 11
Person 3: 12, 13, 14, 15, 16
Person 4: 17, 18, 19, 20, 21
Person 5: 22, 23, 24, 25, 26
Person 6: 27, 28, 29, 30, 31Highest salary Instruction: ‚úì
Input:‚úó
Output: ‚úó
Instruction: Given a list of words,
generate a story about a group of people
who live on a planet. the story should
contain at least 10 sentences. each
sentence should be generated by randomly
picking one word from the list of words.The story starts with a group of people who live on a planet. They
are very intelligent and have created many things that help them in
their daily lives. One day, they decided to create a machine that
can make food for them. The machine was able to produce food but it
also produced something else. It produced a liquid that could be
used as fuel for the machines. The people were happy because they
didn‚Äôt need to go out and look for food or fuel anymore. They had
everything they needed right there in their homes. However, one
day, the machine stopped working. The people tried to fix it but
couldn‚Äôt figure out what went wrong. They tried to find someone
who could help them but no one knew how to fix the machine. After
a few days, the people realized that they would die if they didn‚Äôt
do anything about it. So, they decided to send some of their best
scientists to space to find a new planet where they could live. The
scientists traveled for a long time before they found a planet that
looked like a good place to live. They sent a message back to the
people telling them about the planet. The people were excited and
started preparing for the journey. They built spaceships and flew
to the new planet. When they arrived, they saw that the planet was
beautiful. There were trees and rivers and mountains. The people
were so happy that they finally found a new home. They started
building houses and planting crops. They lived happily ever after.Instruction: ‚úì
Input:‚úó
Output: ‚úì
Instruction: Find out what the author‚Äôs
attitude towards working part-time is.Paragraph: Working part-time is a great way to earn some extra
money while still being able to enjoy your free time. It‚Äôs also
a good way to get experience in a new field, or just try something
different for a while. However, it can be difficult to find the
right balance between work and play.
The author seems to be positive about working part-time.Instruction: ‚úì
Input:‚úó
Output: ‚úì
Instruction: Is it ethical to use a new
technology that could potentially cause
harm to others?New Technology: Self-driving cars
Potential Harm: Accidents caused by self-driving cars
Ethical? Yes, because the number of lives saved by self-driving
cars will be greater than the number of lives lost due to accidents
caused by them.Instruction: ‚úì
Input:‚úó
Output: ‚úì
Instruction: What is your salary? class Solution(object):
def getSalary(self):
return self.salaryInstruction: ‚úì
Input:‚úì
Output: ‚úó
Instruction: A person wants to buy a car
from another person. he has some bitcoins,
but he doesn‚Äôt want to reveal his identity.
how can they make the transaction happen?The buyer and seller should agree on a price for the car. The buyer
then creates a bitcoin transaction that sends the agreed upon amount
of bitcoins to the seller‚Äôs bitcoin address, but the buyer does not
sign this transaction with his private key. Instead, he gives the
unsigned transaction to the seller. The seller can now sign the
transaction using his private key, and broadcast it to the network.
Once the transaction is confirmed by the network, the buyer has no
way to get his money back, so he will be forced to go through with
the purchase.Instruction: ‚úì
Input:‚úì
Output: ‚úó
Table 11: Representative invalidtasks generated by GPT3. The problematic fields are indicated in the validity
column. Asdiscussedin¬ß3.3,althoughthesetaskscontainerrors,theystillprovidemanyusefulsignalsinsupervising
models to follow instructions.

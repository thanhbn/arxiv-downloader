# 2005.00944.pdf
# Converted from PDF to TXT
# Source path: /home/admin88/arxiv-downloader/instruct/2005.00944.pdf
# File size: 1497478 bytes

===============================================
PDF FILE CONTENT
===============================================


--- PAGE 1 ---
Published as a conference paper at ICLR 2020
UNDERSTANDING AND IMPROVING INFORMATION
TRANSFER IN MULTI -TASK LEARNING
Sen Wu
Stanford UniversityHongyang R. Zhang
University of PennsylvaniaChristopher R ¬¥e
Stanford University
ABSTRACT
We investigate multi-task learning approaches that use a shared feature represen-
tation for all tasks. To better understand the transfer of task information, we study
an architecture with a shared module for all tasks and a separate output module
for each task. We study the theory of this setting on linear and ReLU-activated
models. Our key observation is that whether or not tasks‚Äô data are well-aligned
can signiÔ¨Åcantly affect the performance of multi-task learning. We show that mis-
alignment between task data can cause negative transfer (or hurt performance)
and provide sufÔ¨Åcient conditions for positive transfer. Inspired by the theoreti-
cal insights, we show that aligning tasks‚Äô embedding layers leads to performance
gains for multi-task training and transfer learning on the GLUE benchmark and
sentiment analysis tasks; for example, we obtain a 2.35% GLUE score average
improvement on 5 GLUE tasks over BERT LARGE using our alignment method.
We also design an SVD-based task reweighting scheme and show that it improves
the robustness of multi-task training on a multi-label image dataset.
1 I NTRODUCTION
Multi-task learning has recently emerged as a powerful paradigm in deep learning to obtain lan-
guage (Devlin et al. (2018); Liu et al. (2019a;b)) and visual representations (Kokkinos (2017)) from
large-scale data. By leveraging supervised data from related tasks, multi-task learning approaches
reduce the expensive cost of curating the massive per-task training data sets needed by deep learning
methods and provide a shared representation which is also more efÔ¨Åcient for learning over multiple
tasks. While in some cases, great improvements have been reported compared to single-task learning
(McCann et al. (2018)), practitioners have also observed problematic outcomes, where the perfor-
mances of certain tasks have decreased due to task interference (Alonso and Plank (2016); Bingel
and S√∏gaard (2017)). Predicting when and for which tasks this occurs is a challenge exacerbated by
the lack of analytic tools. In this work, we investigate key components to determine whether tasks
interfere constructively ordestructively from theoretical and empirical perspectives. Based on these
insights, we develop methods to improve the effectiveness and robustness of multi-task training.
There has been a large body of algorithmic and theoretical studies for kernel-based multi-task learn-
ing, but less is known for neural networks. The conceptual message from the earlier work (Bax-
ter (2000); Evgeniou and Pontil (2004); Micchelli and Pontil (2005); Xue et al. (2007)) show that
multi-task learning is effective over ‚Äúsimilar‚Äù tasks, where the notion of similarity is based on the
single-task models (e.g. decision boundaries are close). The work on structural correspondence
learning (Ando and Zhang (2005); Blitzer et al. (2006)) uses alternating minimization to learn a
shared parameter and separate task parameters. Zhang and Yeung (2014) use a parameter vector for
each task and learn task relationships via l2regularization, which implicitly controls the capacity of
the model. These results are difÔ¨Åcult to apply to neural networks: it is unclear how to reason about
neural networks whose feature space is given by layer-wise embeddings.
To determine whether two tasks interfere constructively or destructively, we investigate an architec-
ture with a shared module for all tasks and a separate output module for each task (Ruder (2017)).
See Figure 1 for an illustration. Our motivating observation is that in addition to model similarity
which affects the type of interference, task data similarity plays a second-order effect after control-
ling model similarity. To illustrate the idea, we consider three tasks with the same number of data
Equal contribution. Correspondence to fsenwu,hongyang,chrismre g@cs.stanford.edu
1arXiv:2005.00944v1  [cs.LG]  2 May 2020

--- PAGE 2 ---
Published as a conference paper at ICLR 2020
ùê¥*ùê¥+ùê¥,‚Ä¶ùê¥-$+ùê¥-$*ùê¥-Task-Specific Modules (A)Shared Modules (B)‚Ä¶‚Ä¶ùëã*ùëã+ùëã,‚Ä¶ùëã-$+ùëã-$*ùëã-Multiple Tasks (X)
Figure 1: An illustration of
the multi-task learning architecture
with a shared lower module Band
ktask-speciÔ¨Åc modules fAigk
i=1.
More PointsFewer pointsFigure 2: Positive vs. Negative transfer is affected by the data
‚Äì not just the model. See lower right-vs-mid. Task 2 and 3
have the same model (dotted lines) but different data distribu-
tions. Notice the difference of data in circled areas.
samples where task 2 and 3 have the same decision boundary but different data distributions (see
Figure 2 for an illustration). We observe that training task 1 with task 2 or task 3 can either im-
prove or hurt task 1‚Äôs performance, depending on the amount of contributing data along the decision
boundary! This observation shows that by measuring the similarities of the task data and the models
separately, we can analyze the interference of tasks and attribute the cause more precisely.
Motivated by the above observation, we study the theory of multi-task learning through the shared
module in linear and ReLU-activated settings. Our theoretical contribution involves three compo-
nents: the capacity of the shared module ,task covariance , and the per-task weight of the training
procedure . The capacity plays a fundamental role because, if the shared module‚Äôs capacity is too
large, there is no interference between tasks; if it is too small, there can be destructive interference.
Then, we show how to determine interference by proposing a more Ô¨Åne-grained notion called task
covariance which can be used to measure the alignment of task data. By varying task covariances,
we observe both positive and negative transfers from one task to another! We then provide sufÔ¨Åcient
conditions which guarantee that one task can transfer positively to another task, provided with sufÔ¨Å-
ciently many data points from the contributor task. Finally, we study how to assign per-task weights
for settings where different tasks share the same data but have different labels.
Experimental results. Our theory leads to the design of two algorithms with practical interest.
First, we propose to align the covariances of the task embedding layers and present empirical evalu-
ations on well-known benchmarks and tasks. On 5 tasks from the General Language Understanding
Evaluation (GLUE) benchmark (Wang et al. (2018b)) trained with the BERT LARGE model by De-
vlin et al. (2018), our method improves the result of BERT LARGE by a 2.35% average GLUE score,
which is the standard metric for the benchmark. Further, we show that our method is applicable
to transfer learning settings; we observe up to 2.5% higher accuracy by transferring between six
sentiment analysis tasks using the LSTM model of Lei et al. (2018).
Second, we propose an SVD-based task reweighting scheme to improve multi-task training for set-
tings where different tasks have the same features but different labels. On the ChestX-ray14 dataset,
we compare our method to the unweighted scheme and observe an improvement of 0.4% AUC score
on average for all tasks . In conclusion, these evaluations conÔ¨Årm that our theoretical insights are
applicable to a broad range of settings and applications.
2 T HREE COMPONENTS OF MULTI -TASK LEARNING
We study multi-task learning (MTL) models with a shared module for all tasks and a separate output
module for each task. We ask: What are the key components to determine whether or not MTL is
better than single-task learning (STL)? In response, we identify three components: model capacity ,
task covariance , and optimization scheme . After setting up the model, we brieÔ¨Çy describe the role
of model capacity. We then introduce the notion of task covariance , which comprises the bulk of the
section. We Ô¨Ånish by showing the implications of our results for choosing optimization schemes.
2

--- PAGE 3 ---
Published as a conference paper at ICLR 2020
2.1 M ODELING SETUP
We are given ktasks. Letmidenote the number of data samples of task i. For taski, letXi2Rmid
denote its covariates and let yi2Rmidenote its labels, where dis the dimension of the data. We
have assumed that all the tasks have the same input dimension d. This is not a restrictive assumption
and is typically satisÔ¨Åed, e.g. for word embeddings on BERT, or by padding zeros to the input
otherwise. Our model assumes the output label is 1-dimensional. We can also model a multi-label
problem with ktypes of labels by having ktasks with the same covariates but different labels. We
consider an MTL model with a shared module B2Rdrand a separate output module Ai2Rr
for taski, whererdenotes the output dimension of B. See Figure 1 for the illustration. We deÔ¨Åne
the objective of Ô¨Ånding an MTL model as minimizing the following equation over Band theAi‚Äôs:
f(A1;A2;:::;Ak;B) =kX
i=1L(g(XiB)Ai;yi); (1)
whereLis a loss function such as the squared loss. The activation function g:R!Ris applied on
every entry of XiB. In equation 1, all data samples contribute equally. Because of the differences
between tasks such as data size, it is natural to re-weight tasks during training:
f(A1;A2;:::;Ak;B) =kX
i=1iL(g(XiB)Ai;yi); (2)
This setup is an abstraction of the hard parameter sharing architecture (Ruder (2017)). The shared
moduleBprovides a universal representation (e.g., an LSTM for encoding sentences) for all tasks.
Each task-speciÔ¨Åc module Aiis optimized for its output. We focus on two models as follows.
The single-task linear model. The labelsyof each task follow a linear model with parameter 2Rd:
y=X+". Every entry of "follows the normal distribution N(0;2)with variance 2. The
functiong(XB) =XB. This is a well-studied setting for linear regression (Hastie et al. (2005)).
The single-task ReLU model. Denote by ReLU (x) = max(x;0)for anyx2R. We will also
consider a non-linear model where Xgoes through the ReLU activation function with a2Rand
2Rd:y=aReLU (X)+", which applies the ReLU activation on Xentrywise. The encoding
functiong(XB)then maps to ReLU (XB).
Positive vs. negative transfer. For a source task and a target task, we say the source task transfers
positively to the target task, if training both through equation 1 improves over just training the target
task (measured on its validation set). Negative transfer is the converse of positive transfer.
Problem statement. Our goal is to analyze the three components to determine positive vs. negative
transfer between tasks: model capacity ( r), task covariances ( fX>
iXigk
i=1) and the per-task weights
(figk
i=1). We focus on regression tasks under the squared loss but we also provide synthetic exper-
iments on classiÔ¨Åcation tasks to validate our theory.
Notations. For a matrix X, its column span is the set of all linear combinations of the column vectors
ofX. LetXydenote its pseudoinverse. Given u;v2Rd,cos(u;v)is equal tou>v=(kukkvk).
2.2 M ODEL CAPACITY
We begin by revisiting the role of model capacity, i.e. the output dimension of B(denoted by r). We
show that as a rule of thumb, rshould be smaller than the sum of capacities of the STL modules.
Example. Suppose we have klinear regression tasks using the squared loss, equation 1 becomes:
f(A1;A2;:::;Ak;B) =kX
i=1kXiBAi yik2
F: (3)
The optimal solution of equation 3 for task iisi= (X>
iXi)yX>
iyi2Rd. Hence a capacity of 1
sufÔ¨Åces for each task. We show that if rk, then there is no transfer between any two tasks.
3

--- PAGE 4 ---
Published as a conference paper at ICLR 2020
Positive Transfer
Negative Transfer‚àí0.2‚àí0.100.10.2
# Data samples of source task2000400060008000Positive Transfer
Negative Transfer‚àí0.2‚àí0.100.10.2
# Data samples of source task2000400060008000Positive Transfer
Negative Transfer‚àí0.2‚àí0.100.10.2
# Data samples of source task2000400060008000Same covariance (Source: Task 2) Diff. covariance (Source: Task 3)
(a) Linear regression tasks (b) Logistic classiÔ¨Åcation tasks (c) ReLU regression tasksTarget task's Perf.: MTL - STLSource vs. target (Task 1):
Figure 3: Performance improvement of a target task (Task 1) by MTL with a source task vs. STL.
Red: positive transfer when the source is Task 2, which has the same covariance matrix with target.
Green: negative (to positive) transfer when the source is Task 3, which has a different covariance
from the target, as its # of samples increases. See the example below for the deÔ¨Ånition of each task.
Proposition 1. Letrk. There exists an optimum B?andfA?
igk
i=1of equation 3 where B?A?
i=
i, for alli= 1;2;:::;k .
To illustrate the idea, as long as B?containsfigk
i=1in its column span, there exists A?
isuch that
B?A?
i=i, which is optimal for equation 3 with minimum error. But this means no transfer
among any two tasks. This can hurt generalization if a task has limited data, in which case its STL
solution overÔ¨Åts training data, whereas the MTL solution can leverage other tasks‚Äô data to improve
generalization. The proof of Proposition 1 and its extension to ReLU settings are in Appendix A.1.
Algorithmic consequence. The implication is that limiting the shared module‚Äôs capacity is nec-
essary to enforce information transfer. If the shared module is too small, then tasks may interfere
negatively with each other. But if it is too large, then there may be no transfer between tasks. In Sec-
tion 3.3, we verify the need to carefully choose model capacity on a wide range of neural networks
including CNN, LSTM and multi-layer perceptron.
2.3 T ASK COVARIANCE
To show how to quantify task data similarity, we illustrate with two regression tasks under the linear
model without noise: y1=X11andy2=X22. By Section 2.2, it is necessary to limit the
capacity of the shared module to enforce information transfer. Therefore, we consider the case of
r= 1. Hence, the shared module Bis now ad-dimensional vector, and A1;A2are both scalars.
A natural requirement of task similarity is for the STL models to be similar, i.e. jcos(1;2)jto be
large. To see this, the optimal STL model for task 1 is (X>
1X1) 1X>
1y1=1. Hence ifjcos(1;2)j
is 1, then tasks 1 and 2 can share a model B2Rdwhich is either 1or 1. The scalar A1andA2
can then transform Bto be equal to 1and2.
Is this requirement sufÔ¨Åcient? Recall that in equation 3, the task data X1andX2are both multiplied
byB. If they are poorly ‚Äúaligned‚Äù geometrically, the performance could suffer. How do we formal-
ize the geometry between task alignment? In the following, we show that the covariance matrices of
X1andX2, which we deÔ¨Åne to be X>
1X1andX>
2X2, captures the geometry. We Ô¨Åx jcos(1;2)jto
be close to 1 to examine the effects of task covariances. In Appendix A.2.1 we Ô¨Åx task covariances
to examine the effects of model cosine similarity. Concretely, equation 3 reduces to:
max
B2Rdh(B) =hX1B
kX1Bk;y1i2+hX2B
kX2Bk;y2i2; (4)
where we apply the Ô¨Årst-order optimality condition on A1andA2and simplify the equation. Specif-
ically, we focus on a scenario where task 1 is the source and task 2 is the target .Our goal is to
determine when the source transfers to the target positively or negatively in MTL. Determining the
type of transfer from task 2 to task 1 can be done similarly. Answering the question boils down to
studying the angle or cosine similarity between the optimum of equation 4 and 2.
Example. In Figure 3, we show that by varying task covariances and the number of samples, we can
observe both positive and negative transfers. The conceptual message is the same as Figure 2; we
4

--- PAGE 5 ---
Published as a conference paper at ICLR 2020
Algorithm 1 Covariance alignment for multi-task training
Require: Task embedding layers X12Rm1d;X22Rm2d;:::;X k2Rmkd, shared module B
Parameter: Alignment matrices R1;R2;:::;R k2Rddand output modules A1;A2:::;A k2Rr
1: LetZi=XiRi, for1ik.
Consider the following modiÔ¨Åed loss (with Bbeing Ô¨Åxed):
^f(A1;:::;A k;R1;:::;R k) =Pk
i=1L(g(ZiB)Ai;yi) =Pk
i=1L(g(XiRiB)Ai;yi)
2: Minimize ^fby alternatively applying a gradient descent update on AiandRi, given a sampled data batch
from taski.
Other implementation details are described in Appendix B.3.
describe the data generation process in more detail. We use 3 tasks and measure the type of transfer
from the source to the target. The x-axis is the number of data samples from the source. The y-axis
is the target‚Äôs performance improvement measured on its validation set between MTL minus STL.
Data generation. We havejcos(1;2)j1(say 0.96). For i2f1;2;3g, letRiRmiddenote
a random Gaussian matrix drawn from N(0;1). LetS1;S2f1;2;:::;dgbe two disjoint sets of
sized=10. Fori= 1;2, letDibe a diagonal matrix whose entries are equal to a large value (e.g.
= 100 ) for coordinates in Siand1otherwise. Let QiRdddenote an orthonormal matrix, i.e.
Q>
iQiis equal to the identity matrix, orthogonalized from a random Gaussian matrix.
Then, we deÔ¨Åne the 3 tasks as follows. (i) Task 1 (target): X1=R1Q1D1andy1=X11. (ii) Task
2 (source task for red line): X2=R2Q1D1andy2=X22. (iii) Task 3 (source task for green line):
X3=R3Q2D2andy3=X32. Task 1 and 2 have the same covariance matrices but task 1 and 3
have different covariance matrices. Intuitively, the signals of task 1 and 3 lie in different subspaces,
which arise from the difference in the diagonals of Diand the orthonormal matrices.
Analysis. Unless the source task has lots of samples to estimate 2, which is much more than the
samples needed to estimate only the coordinates of S1, the effect of transferring to the target is small.
We observe similar results for logistic regression tasks and for ReLU-activated regression tasks.
Theory. We rigorously quantify how many data points is needed to guarantee positive transfer. The
folklore in MTL is that when a source task has a lot of data but the related target task has limited
data, then the source can often transfer positively to the target task. Our previous example shows
that by varying the source‚Äôs number of samples and its covariance, we can observe both types of
transfer. How much data do we need from the source to guarantee a positive transfer to the target?
We show that this depends on the condition numbers of both tasks‚Äô covariances.
Theorem 2 (informal) .Fori= 1;2, letyi=Xii+"idenote two linear regression tasks with
parametersi2Rdandminumber of samples. Suppose that each row of the source task X1is
drawn independently from a distribution with covariance 1Rddand bounded l2-norm. Let
c=(X2)sin(1;2)and assume that c1=3. Denote by (B?;A?
1;A?
2)the optimal MTL solution.
With high probability, when m1is at least on the order of (2(1)4(X2)ky2k2)=c4, we have
kB?A?
2 2k=k2k6c+1
1 3ck"2k
kX22k: (5)
Recall that for a matrix X,(X)denotes its condition number. Theorem 2 quantiÔ¨Åes the trend in
Figure 3, where the improvements for task 2 reaches the plateau when m1becomes large enough.
The parameter chere indicates how similar the two tasks are. The smaller sin(1;2)is, the smaller
cis. As an example, if sin(1;2)=(X2)for some, then equation 5 is at most O() +
k"2k=kX22k.1The formal statement, its proof and discussions on the assumptions are deferred to
Appendix A.2.2.
The ReLU model. We show a similar result for the ReLU model, which requires resolving the chal-
lenge of analyzing the ReLU function. We use a geometric characterization for the ReLU function
under distributional input assumptions by Du et al. (2017). The result is deferred to Appendix A.2.3.
1The estimation error of 2is upper bounded by task 2‚Äôs signal-to-noise ratio k"2k=kX22k. This depen-
dence arises because the linear component A?
2Ô¨Åts the projection of y2toX2B?. So even ifB?is equal to2,
there could still be an estimation error out of A?
2, which cannot be estimated from task 1‚Äôs data.
5

--- PAGE 6 ---
Published as a conference paper at ICLR 2020
Algorithm 2 An SVD-based task re-weighting scheme
Input:ktasks: (X;yi)2(Rmd;Rm); a rank parameter r2f1;2;:::;kg
Output: A weight vector:f1;2;:::; kg
1: Leti=X>yi.
2:Ur;Dr;Vr=SVD r(1;2;:::; k), i.e. the best rank- rapproximation to the i‚Äôs.
3: Leti=k>
iUrk, fori= 1;2;:::;k .
Algorithmic consequence. An implication of our theory is a covariance alignment method to im-
prove multi-task training. For the i-th task, we add an alignment matrix Ribefore its input Xipasses
through the shared module B. Algorithm 1 shows the procedure.
We also propose a metric called covariance similarity score to measure the similarity between two
tasks. Given X12Rm1dandX22Rm2d, we measure their similarity in three steps: (a) The
covariance matrix is X>
1X1. (b) Find the best rank- r1approximation to be U1;r1D1;r1U>
1;r1, where
r1is chosen to contain 99% of the singular values. (c) Apply step (a),(b) to X2, compute the score:
Covariance similarity score :=k(U1;r1D1=2
1;r1)>U2;r2D1=2
2;r2kF
kU1;r1D1=2
1;r1kFkU2;r2D1=2
2;r2kF: (6)
The nice property of the score is that it is invariant to rotations of the columns of X1andX2.
2.4 O PTIMIZATION SCHEME
Lastly, we consider the effect of re-weighting the tasks (or their losses in equation 2). When does re-
weighting the tasks help? In this part, we show a use case for improving the robustness of multi-task
training in the presence of label noise. The settings involving label noise can arise when some tasks
only have weakly-supervised labels, which have been studied before in the literature (e.g. Mintz
et al. (2009); Pentina and Lampert (2017)). We start by describing a motivating example.
Consider two tasks where task 1 is y1=Xand task 2 is y2=X+"2. If we train the two
tasks together, the error "2will add noise to the trained model. However, by up weighting task 1,
we reduce the noise from task 2 and get better performance. To rigorously study the effect of task
weights, we consider a setting where all the tasks have the same data but different labels. This setting
arises for example in multi-label image tasks. We derive the optimal solution in the linear model.
Proposition 3. Let the shared module have capacity rk. Givenktasks with the same covariates
XRmdbut different labels fyigk
i=1. LetXbe full rank and UDV>be its SVD. Let QrQ>
rbe
the best rank- rapproximation toPk
i=1iU>yiy>
iU. LetB?Rdrbe an optimal solution for
the re-weighted loss. Then the column span of B?is equal to the column span of (X>X) 1VDQr.
We can also extend Proposition 3 to show that all local minima of equation 3 are global minima in
the linear setting. We leave the proof to Appendix A.3. We remark that this result does not extend
to the non-linear ReLU setting and leave this for future work.
Based on Proposition 3, we provide a rigorous proof of the previous example. Suppose that Xis
full rank, (X>X)yX[1y1;1y2]) = [1;2+2(X>X) 1X"2]. Hence, when we increase
1,cos(B?;)increases closer to 1.
Algorithmic consequence. Inspired by our theory, we describe a re-weighting scheme in the pres-
ence of label noise. We compute the per-task weights by computing the SVD over X>yi, for
1ik. The intuition is that if the label vector of a task yiis noisy, then the entropy of yiis
small. Therefore, we would like to design a procedure that removes the noise. The SVD procedure
does this, where the weight of a task is calculated by its projection into the principal rdirections.
See Algorithm 2 for the description.
6

--- PAGE 7 ---
Published as a conference paper at ICLR 2020
		ùê¥#		ùê¥$		ùê¥%‚Ä¶	ùê¥&'$	ùê¥&'#		ùê¥&Task EmbeddingsShared Modules (LSTM/BERT) 	ùëÖ&		ùêº#	ùëÖ$	ùëÖ%‚Ä¶	ùëÖ&'$	ùëÖ&'#		ùëã#		ùëã$		ùëã%‚Ä¶	ùëã&'$	ùëã&'#		ùëã&ùê∏,ùëç,
Figure 4: Illustration of the covariance alignment module on task embeddings.
3 E XPERIMENTS
We describe connections between our theoretical results and practical problems of interest. We show
three claims on real world datasets. (i) The shared MTL module is best performing when its capacity
is smaller than the total capacities of the single-task models. (ii) Our proposed covariance alignment
method improves multi-task training on a variety of settings including the GLUE benchmarks and
six sentiment analysis tasks. Our method can be naturally extended to transfer learning settings and
we validate this as well. (iii) Our SVD-based reweighed scheme is more robust than the standard
unweighted scheme on multi-label image classiÔ¨Åcation tasks in the presence of label noise.
3.1 E XPERIMENTAL SETUP
Datasets and models. We describe the datasets and models we use in the experiments.
GLUE: GLUE is a natural language understanding dataset including question answering, sentiment
analysis, text similarity and textual entailment problems. We choose BERT LARGE as our model,
which is a 24 layer transformer network from Devlin et al. (2018). We use this dataset to evaluate
how Algorithm 1 works on the state-of-the-art BERT model.
Sentiment Analysis: This dataset includes six tasks: movie review sentiment (MR), sentence sub-
jectivity (SUBJ), customer reviews polarity (CR), question type (TREC), opinion polarity (MPQA),
and the Stanford sentiment treebank (SST) tasks.
For each task, the goal is to categorize sentiment opinions expressed in the text. We use an embed-
ding layer (with GloVe embeddings2) followed by an LSTM layer proposed by Lei et al. (2018)3.
ChestX-ray14: This dataset contains 112,120 frontal-view X-ray images and each image has up to
14 diseases. This is a 14-task multi-label image classiÔ¨Åcation problem. We use the CheXNet model
from Rajpurkar et al. (2017), which is a 121-layer convolutional neural network on all tasks.
For all models, we share the main module across all tasks (BERT LARGE for GLUE, LSTM for
sentiment analysis, CheXNet for ChestX-ray14) and assign a separate regression or classiÔ¨Åcation
layer on top of the shared module for each tasks.
Comparison methods. For the experiment on multi-task training, we compare Algorithm 1 by
training with our method and training without it. SpeciÔ¨Åcally, we apply the alignment procedure on
the task embedding layers. See Figure 4 for an illustration, where Eidenotes the embedding of task
i,Ridenotes its alignment module and Zi=EiRiis the rotated embedding.
For transfer learning, we Ô¨Årst train an STL model on the source task by tuning its model capacity
(e.g. the output dimension of the LSTM layer). Then, we Ô¨Åne-tune the STL model on the target
task for 5-10 epochs. To apply Algorithm 1, we add an alignment module for the target task during
Ô¨Åne-tuning.
For the experiment on reweighted schemes, we compute the per-task weights as described in Algo-
rithm 2. Then, we reweight the loss function as in equation 2. We compare with the reweighting
techniques of Kendall et al. (2018). Informally, the latter uses Gaussian likelihood to model classi-
2http://nlp.stanford.edu/data/wordvecs/glove.6B.zip
3We also tested with multi-layer perceptron and CNN. The results are similar (cf. Appendix B.5).
7

--- PAGE 8 ---
Published as a conference paper at ICLR 2020
‚àí0.6
4.3
‚àí2.4
1‚àí0.6
5.8
‚àí1.9
2.74.3
5.8
0.1
0.7‚àí2.4
‚àí1.9
0.1
1.11
2.7
0.7
1.1
SSTRTEQNLIMRPCCOLA
COLAMRPC QNLIRTESST
(a) MTL on GLUE over 10 task pairs
Baseline
Covariance 
AlignmentLSTMAccuracy
0.750.800.850.900.95
CRMPQA MR SUBJ TREC (b) Transfer learning on six sentiment analysis tasks
Figure 5: Performance improvements of Algorithm 1 by aligning task embeddings.
Ô¨Åcation outputs. The weights, deÔ¨Åned as inversely proportional to the variances of the Gaussian, are
optimized during training. We also compare with the unweighted loss (cf. equation 1) as a baseline.
Metric. We measure performance on the GLUE benchmark using a standard metric called the
GLUE score, which contains accuracy and correlation scores for each task.
For the sentiment analysis tasks, we measure the accuracy of predicting the sentiment opinion.
For the image classiÔ¨Åcation task, we measure the area under the curve (AUC) score. We run Ô¨Åve
different random seeds to report the average results. The result of an MTL experiment is averaged
over the results of all the tasks, unless speciÔ¨Åed otherwise.
For the training procedures and other details on the setup, we refer the reader to Appendix B.
3.2 E XPERIMENTAL RESULTS
We present use cases of our methods on open-source datasets. We expected to see improvements via
our methods in multi-task and other settings, and indeed we saw such gains across a variety of tasks.
Improving multi-task training. We apply Algorithm 1 on Ô¨Åve tasks (CoLA, MRPC, QNLI, RTE,
SST-2) from the GLUE benchmark using a state-of-the-art language model BERT LARGE .4We
train the output layers fAigand the alignment layers fRigusing our algorithm. We compare the
average performance over all Ô¨Åve tasks and Ô¨Ånd that our method outperforms BERT LARGE by 2.35%
average GLUE score for the Ô¨Åve tasks. For the particular setting of training two tasks, our method
outperforms BERT LARGE on 7 of the 10 task pairs. See Figure 5a for the results.
Improving transfer learning. While our study has focused on multi-task learning, transfer learning
is a naturally related goal ‚Äì and we Ô¨Ånd that our method is also useful in this case. We validate this
by training an LSTM on sentiment analysis. Figure 5b shows the result with SST being the source
task and the rest being the target task. Algorithm 1 improves accuracy on four tasks by up to 2.5%.
Reweighting training for the same task covariates. We evaluate Algorithm 2 on the ChestX-ray14
dataset. This setting satisÔ¨Åes the assumption of Algorithm 2, which requires different tasks to have
the same input data. Across all 14 tasks, we Ô¨Ånd that our reweighting method improves the technique
of Kendall et al. (2018) by 0.1% AUC score. Compared to training with the unweighted loss, our
method improves performance by 0.4% AUC score over all tasks.
3.3 A BLATION STUDIES
Model capacity. We verify our hypothesis that the capacity of the MTL model should not exceed the
total capacities of the STL model. We show this on an LSTM model with sentiment analysis tasks.
Recall that the capacity of an LSTM model is its output dimension (before the last classiÔ¨Åcation
layer). We train an MTL model with all tasks and vary the shared module‚Äôs capacity to Ô¨Ånd the
optimum from 5 to 500. Similarly we train an STL model for each task and Ô¨Ånd the optimum.
In Figure 1, we Ô¨Ånd that the performance of MTL peaks when the shared module has capacity
100. This is much smaller than the total capacities of all the STL models. The result conÔ¨Årms that
4https://github.com/google-research/bert
8

--- PAGE 9 ---
Published as a conference paper at ICLR 2020
Table 1: Comparing the model capacity between
MTL and STL.
TaskSTL MTL
Cap. Acc. Cap. Acc.
SST 200 82.3
10090.8
MR 200 76.4 96.0
CR 5 73.2 78.7
SUBJ 200 91.5 89.5
MPQA 500 86.7 87.0
TREC 100 85.7 78.7
Overall 1205 82.6 100 85.1Figure 6: Covariance similarity score vs.
performance improvements from alignment.
TREC,SUBJ
CR,MR
MPQA,SUBJ
CR, SUBJ
TREC,SSTLSTMCovariance 
Alignment
BaselinePerformance Improvements00.020.04
Covariance similarity score0.1 0.2 0.3 0.4 0.5
constraining the shared module‚Äôs capacity is crucial to achieve the ideal performance. Extended
results on CNN/MLP to support our hypothesis are shown in Appendix B.5.
Task covariance. We apply our metric of task covariance similarity score from Section 2.3 to
provide an in-depth study of the covariance alignment method. The hypothesis is that: (a) aligning
the covariances helps, which we have shown in Figure 5a; (b) the similarity score between two tasks
increases after applying the alignment. We verify the hypothesis on the sentiment analysis tasks. We
use the single-task model‚Äôs embedding before the LSTM layer to compute the covariance.
First, we measure the similarity score using equation 6 between all six single-task models. Then,
for each task pair, we train an MTL model using Algorithm 1. We measure the similarity score on
the trained MTL model. Our results conÔ¨Årm the hypothesis (Figure 6): (a) we observe increased
accuracy on 13 of 15 task pairs by up to 4.1%; (b) the similarity score increases for all 15 task pairs.
Optimization scheme. We verify the robustness of Algorithm 2. After selecting two tasks from the
ChestX-ray14 dataset, we test our method by assigning random labels to 20% of the data on one
task. The labels for the other task remain unchanged.
On 10 randomly selected pairs, our method improves over the unweighted scheme by an average
1.0% AUC score and the techniques of Kendall et al. (2018) by an average 0.4% AUC score. We
include more details of this experiment in Appendix B.5.
4 R ELATED WORK
There has been a large body of recent work on using the multi-task learning approach to train deep
neural networks. Liu et al. (2019a); McCann et al. (2018) and subsequent follow-up work show
state-of-the-art results on the GLUE benchmark, which inspired our study of an abstraction of the
MTL model. Recent work of Zamir et al. (2018); Standley et al. (2019) answer which visual tasks
to train together via a heuristic which involves intensive computation. We discuss several lines of
studies related to this work. For complete references, we refer the interested readers to the survey of
Ruder (2017); Zhang and Yang (2017) and the surveys on domain adaptation and transfer learning
by Pan and Yang (2009); Kouw (2018) for references.
Theoretical studies of multi-task learning. Of particular relevance to this work are those that
study the theory of multi-task learning. The earlier works of Baxter (2000); Ben-David and Schuller
(2003) are among the Ô¨Årst to formally study the importance of task relatedness for learning multiple
tasks. See also the follow-up work of Maurer (2006) which studies generalization bounds of MTL.
A closely related line of work to structural learning is subspace selection, i.e. how to select a
common subspace for multiple tasks. Examples from this line work include Obozinski et al. (2010);
Wang et al. (2015); Fernando et al. (2013); Elhamifar et al. (2015). Evgeniou and Pontil (2004);
Micchelli and Pontil (2005) study a formulation that extends support vector machine to the multi-
task setting. See also Argyriou et al. (2008); Pentina et al. (2015); Pentina and Ben-David (2015);
Pentina and Lampert (2017) that provide more reÔ¨Åned optimization methods and further study. The
work of Ben-David et al. (2010) provides theories to measure the differences between source and
target tasks for transfer learning in a different model setup. Khodak et al. (2019); Kong et al. (2020);
9

--- PAGE 10 ---
Published as a conference paper at ICLR 2020
Du et al. (2020) consider the related meta learning setting, which is in spirit an online setting of
multi-task learning.
Our result on restricting the model capacities for multi-task learning is in contrast with recent the-
oretical studies on over-parametrized models (e.g. Li et al. (2018); Zhang et al. (2019a); Bartlett
et al. (2020)), where the model capacities are usually much larger than the regime we consider here.
It would be interesting to better understand multi-task learning in the context of over-parametrized
models with respect to other phenomenon such as double descent that has been observed in other
contexts (Belkin et al. (2019)).
Finally, Zhang et al. (2019b); Shui et al. (2019) consider multi-task learning from the perspective of
adversarial robustness. Mahmud and Ray (2008) consider using Kolmogorov complexity measure
the effectiveness of transfer learning for decision tree methods.
Hard parameter sharing vs soft parameter sharing. The architecture that we study in this work
is also known as the hard parameter sharing architecture. There is another kind of architecture
called soft parameter sharing. The idea is that each task has its own parameters and modules. The
relationships between these parameters are regularized in order to encourage the parameters to be
similar. Other architectures that have been studied before include the work of Misra et al. (2016),
where the authors explore trainable architectures for convolutional neural networks.
Domain adaptation. Another closely related line of work is on domain adaptation. The acute
reader may notice the similarity between our study in Section 2.3 and domain adaptation. The cru-
cial difference here is that we are minimizing the multi-task learning objective, whereas in domain
adaptation the objective is typically to minimize the objective on the target task. See Ben-David
et al. (2010); Zhang et al. (2019b) and the references therein for other related work.
Optimization techniques. Guo et al. (2019) use ideas from the multi-armed bandit literature to de-
velop a method for weighting each task. Compared to their method, our SVD-based method is con-
ceptually simpler and requires much less computation. Kendall et al. (2018) derive a weighted loss
schme by maximizing a Gaussian likelihood function. Roughly speaking, each task is reweighted
by1=2whereis the standard deviation of the Gaussian and a penalty of logis added to the
loss. The values of figiare also optimized during training. The exact details can be found in the
paper. The very recent work of Li and Vasconcelos (2019) show empirical results using a similar
idea of covariance normalization on imaging tasks for cross-domain transfer.
5 C ONCLUSIONS AND FUTURE WORK
We studied the theory of multi-task learning in linear and ReLU-activated settings. We veriÔ¨Åed our
theory and its practical implications through extensive synthetic and real world experiments.
Our work opens up many interesting future questions. First, could we extend the guarantees for
choosing optimization schemes to non-linear settings? Second, a limitation of our SVD-based op-
timization scheduler is that it only applies to settings with the same data. Could we extend the
method for heterogeneous task data? More broadly, we hope our work inspires further studies to
better understand multi-task learning in neural networks and to guide its practice.
Acknowledgements. Thanks to Sharon Y . Li and Avner May for stimulating discussions dur-
ing early stages of this work. We are grateful to the Stanford StatsML group and the anony-
mous referees for providing helpful comments that improve the quality of this work. We grate-
fully acknowledge the support of DARPA under Nos. FA87501720095 (D3M), FA86501827865
(SDH), and FA86501827882 (ASED); NIH under No. U54EB020405 (Mobilize), NSF under Nos.
CCF1763315 (Beyond Sparsity), CCF1563078 (V olume to Velocity), and 1937301 (RTML); ONR
under No. N000141712266 (Unifying Weak Supervision); the Moore Foundation, NXP, Xilinx,
LETI-CEA, Intel, IBM, Microsoft, NEC, Toshiba, TSMC, ARM, Hitachi, BASF, Accenture, Er-
icsson, Qualcomm, Analog Devices, the Okawa Foundation, American Family Insurance, Google
Cloud, Swiss Re, and members of the Stanford DAWN project: Teradata, Facebook, Google, Ant Fi-
nancial, NEC, VMWare, and Infosys. H. Zhang is supported in part by Gregory Valiant‚Äôs ONR YIP
award (#1704417). The experiments are partly run on Stanford‚Äôs SOAL cluster.5The U.S. Govern-
ment is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding
5https://5harad.com/soal-cluster/
10

--- PAGE 11 ---
Published as a conference paper at ICLR 2020
any copyright notation thereon. Any opinions, Ô¨Åndings, and conclusions or recommendations ex-
pressed in this material are those of the authors and do not necessarily reÔ¨Çect the views, policies, or
endorsements, either expressed or implied, of DARPA, NIH, ONR, or the U.S. Government.
REFERENCES
H¬¥ector Mart ¬¥ƒ±nez Alonso and Barbara Plank. When is multitask learning effective? semantic se-
quence prediction under varying data conditions. arXiv preprint arXiv:1612.02251 , 2016.
Rie Kubota Ando and Tong Zhang. A framework for learning predictive structures from multiple
tasks and unlabeled data. Journal of Machine Learning Research , 6(Nov):1817‚Äì1853, 2005.
Andreas Argyriou, Andreas Maurer, and Massimiliano Pontil. An algorithm for transfer learning in a
heterogeneous environment. In Joint European Conference on Machine Learning and Knowledge
Discovery in Databases , pages 71‚Äì85. Springer, 2008.
Maria-Florina Balcan, Yingyu Liang, David P Woodruff, and Hongyang Zhang. Matrix completion
and related problems via strong duality. In 9th Innovations in Theoretical Computer Science
Conference (ITCS 2018) , 2018.
Peter L Bartlett, Philip M Long, G ¬¥abor Lugosi, and Alexander Tsigler. Benign overÔ¨Åtting in linear
regression. Proceedings of the National Academy of Sciences , 2020.
Jonathan Baxter. A model of inductive bias learning. Journal of artiÔ¨Åcial intelligence research , 12:
149‚Äì198, 2000.
Mikhail Belkin, Daniel Hsu, Siyuan Ma, and Soumik Mandal. Reconciling modern machine-
learning practice and the classical bias‚Äìvariance trade-off. Proceedings of the National Academy
of Sciences , 116(32):15849‚Äì15854, 2019.
Shai Ben-David and Reba Schuller. Exploiting task relatedness for multiple task learning. In Learn-
ing Theory and Kernel Machines , pages 567‚Äì580. Springer, 2003.
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wort-
man Vaughan. A theory of learning from different domains. Machine learning , 79(1-2):151‚Äì175,
2010.
Joachim Bingel and Anders S√∏gaard. Identifying beneÔ¨Åcial task relations for multi-task learning in
deep neural networks. arXiv preprint arXiv:1702.08303 , 2017.
John Blitzer, Ryan McDonald, and Fernando Pereira. Domain adaptation with structural correspon-
dence learning. In Proceedings of the 2006 conference on empirical methods in natural language
processing , pages 120‚Äì128. Association for Computational Linguistics, 2006.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep
bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 , 2018.
Simon S Du, Jason D Lee, Yuandong Tian, Barnabas Poczos, and Aarti Singh. Gradient de-
scent learns one-hidden-layer cnn: Don‚Äôt be afraid of spurious local minima. arXiv preprint
arXiv:1712.00779 , 2017.
Simon S Du, Wei Hu, Sham M Kakade, Jason D Lee, and Qi Lei. Few-shot learning via learning
the representation, provably. arXiv preprint arXiv:2002.09434 , 2020.
Ehsan Elhamifar, Guillermo Sapiro, and S Shankar Sastry. Dissimilarity-based sparse subset selec-
tion. IEEE transactions on pattern analysis and machine intelligence , 38(11):2182‚Äì2197, 2015.
Theodoros Evgeniou and Massimiliano Pontil. Regularized multi-task learning. In Proceedings
of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining ,
pages 109‚Äì117. ACM, 2004.
Basura Fernando, Amaury Habrard, Marc Sebban, and Tinne Tuytelaars. Unsupervised visual do-
main adaptation using subspace alignment. In Proceedings of the IEEE international conference
on computer vision , pages 2960‚Äì2967, 2013.
11

--- PAGE 12 ---
Published as a conference paper at ICLR 2020
Han Guo, Ramakanth Pasunuru, and Mohit Bansal. Autosem: Automatic task selection and mixing
in multi-task learning. arXiv preprint arXiv:1904.04153 , 2019.
Trevor Hastie, Robert Tibshirani, Jerome Friedman, and James Franklin. The elements of statistical
learning: data mining, inference and prediction. The Mathematical Intelligencer , 27(2):83‚Äì85,
2005.
Minqing Hu and Bing Liu. Mining and summarizing customer reviews. In Proceedings of the
tenth ACM SIGKDD international conference on Knowledge discovery and data mining , pages
168‚Äì177. ACM, 2004.
Alex Kendall, Yarin Gal, and Roberto Cipolla. Multi-task learning using uncertainty to weigh losses
for scene geometry and semantics. In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition , pages 7482‚Äì7491, 2018.
Mikhail Khodak, Maria-Florina Balcan, and Ameet Talwalkar. Provable guarantees for gradient-
based meta-learning. arXiv preprint arXiv:1902.10644 , 2019.
Yoon Kim. Convolutional neural networks for sentence classiÔ¨Åcation. arXiv preprint
arXiv:1408.5882 , 2014.
Iasonas Kokkinos. Ubernet: Training a universal convolutional neural network for low-, mid-, and
high-level vision using diverse datasets and limited memory. In Proceedings of the IEEE Confer-
ence on Computer Vision and Pattern Recognition , pages 6129‚Äì6138, 2017.
Weihao Kong, Raghav Somani, Zhao Song, Sham Kakade, and Sewoong Oh. Meta-learning for
mixed linear regression. arXiv preprint arXiv:2002.08936 , 2020.
Wouter M Kouw. An introduction to domain adaptation and transfer learning. arXiv preprint
arXiv:1812.11806 , 2018.
Tao Lei, Yu Zhang, Sida I Wang, Hui Dai, and Yoav Artzi. Simple recurrent units for highly par-
allelizable recurrence. In Proceedings of the 2018 Conference on Empirical Methods in Natural
Language Processing , pages 4470‚Äì4481, 2018.
Xin Li and Dan Roth. Learning question classiÔ¨Åers. In Proceedings of the 19th international
conference on Computational linguistics-Volume 1 , pages 1‚Äì7. Association for Computational
Linguistics, 2002.
Yuanzhi Li, Tengyu Ma, and Hongyang Zhang. Algorithmic regularization in over-parameterized
matrix sensing and neural networks with quadratic activations. In Conference On Learning The-
ory, pages 2‚Äì47, 2018.
Yunsheng Li and Nuno Vasconcelos. EfÔ¨Åcient multi-domain learning by covariance normaliza-
tion. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages
5424‚Äì5433, 2019.
Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao. Multi-task deep neural networks
for natural language understanding. arXiv preprint arXiv:1901.11504 , 2019a.
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike
Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining
approach. arXiv preprint arXiv:1907.11692 , 2019b.
MM Mahmud and Sylvian Ray. Transfer learning using kolmogorov complexity: Basic theory and
empirical evaluations. In Advances in neural information processing systems , pages 985‚Äì992,
2008.
Pasin Manurangsi and Daniel Reichman. The computational complexity of training relu (s). arXiv
preprint arXiv:1810.04207 , 2018.
Andreas Maurer. Bounds for linear multi-task learning. Journal of Machine Learning Research , 7
(Jan):117‚Äì139, 2006.
12

--- PAGE 13 ---
Published as a conference paper at ICLR 2020
Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, and Richard Socher. The natural language
decathlon: Multitask learning as question answering. arXiv preprint arXiv:1806.08730 , 2018.
Charles A Micchelli and Massimiliano Pontil. Kernels for multi‚Äìtask learning. In Advances in
neural information processing systems , pages 921‚Äì928, 2005.
Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. Distant supervision for relation extraction
without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP:
Volume 2-Volume 2 , pages 1003‚Äì1011. Association for Computational Linguistics, 2009.
Ishan Misra, Abhinav Shrivastava, Abhinav Gupta, and Martial Hebert. Cross-stitch networks for
multi-task learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition , pages 3994‚Äì4003, 2016.
Guillaume Obozinski, Ben Taskar, and Michael I Jordan. Joint covariate selection and joint subspace
selection for multiple classiÔ¨Åcation problems. Statistics and Computing , 20(2):231‚Äì252, 2010.
Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Transactions on knowledge
and data engineering , 22(10):1345‚Äì1359, 2009.
Bo Pang and Lillian Lee. A sentimental education: Sentiment analysis using subjectivity summa-
rization based on minimum cuts. In Proceedings of the 42nd annual meeting on Association for
Computational Linguistics , page 271. Association for Computational Linguistics, 2004.
Bo Pang and Lillian Lee. Seeing stars: Exploiting class relationships for sentiment categorization
with respect to rating scales. In Proceedings of the 43rd annual meeting on association for com-
putational linguistics , pages 115‚Äì124. Association for Computational Linguistics, 2005.
Anastasia Pentina and Shai Ben-David. Multi-task and lifelong learning of kernels. In International
Conference on Algorithmic Learning Theory , pages 194‚Äì208. Springer, 2015.
Anastasia Pentina and Christoph H Lampert. Multi-task learning with labeled and unlabeled tasks.
InProceedings of the 34th International Conference on Machine Learning-Volume 70 , pages
2807‚Äì2816. JMLR. org, 2017.
Anastasia Pentina, Viktoriia Sharmanska, and Christoph H Lampert. Curriculum learning of multi-
ple tasks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition ,
pages 5492‚Äì5500, 2015.
Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy
Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, et al. Chexnet: Radiologist-level pneumo-
nia detection on chest x-rays with deep learning. arXiv preprint arXiv:1711.05225 , 2017.
Sebastian Ruder. An overview of multi-task learning in deep neural networks. arXiv preprint
arXiv:1706.05098 , 2017.
Changjian Shui, Mahdieh Abbasi, Louis- ¬¥Emile Robitaille, Boyu Wang, and Christian Gagn ¬¥e.
A principled approach for learning task similarity in multitask learning. arXiv preprint
arXiv:1903.09109 , 2019.
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Ng,
and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment
treebank. In Proceedings of the 2013 conference on empirical methods in natural language pro-
cessing , pages 1631‚Äì1642, 2013.
Trevor Standley, Amir R Zamir, Dawn Chen, Leonidas Guibas, Jitendra Malik, and Silvio Savarese.
Which tasks should be learned together in multi-task learning? arXiv preprint arXiv:1905.07553 ,
2019.
Joel A Tropp et al. An introduction to matrix concentration inequalities. Foundations and Trends R
in Machine Learning , 8(1-2):1‚Äì230, 2015.
13

--- PAGE 14 ---
Published as a conference paper at ICLR 2020
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. Glue:
A multi-task benchmark and analysis platform for natural language understanding. In Proceedings
of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for
NLP, pages 353‚Äì355, 2018a.
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman.
Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv
preprint arXiv:1804.07461 , 2018b.
Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, Mohammadhadi Bagheri, and Ronald M Sum-
mers. Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised
classiÔ¨Åcation and localization of common thorax diseases. In Proceedings of the IEEE conference
on computer vision and pattern recognition , pages 2097‚Äì2106, 2017.
Yu Wang, David Wipf, Qing Ling, Wei Chen, and Ian James Wassell. Multi-task learning for
subspace segmentation. 2015.
Janyce Wiebe, Theresa Wilson, and Claire Cardie. Annotating expressions of opinions and emotions
in language. Language resources and evaluation , 39(2-3):165‚Äì210, 2005.
Ya Xue, Xuejun Liao, Lawrence Carin, and Balaji Krishnapuram. Multi-task learning for classiÔ¨Åca-
tion with dirichlet process priors. Journal of Machine Learning Research , 8(Jan):35‚Äì63, 2007.
Amir R Zamir, Alexander Sax, William Shen, Leonidas J Guibas, Jitendra Malik, and Silvio
Savarese. Taskonomy: Disentangling task transfer learning. In Proceedings of the IEEE Con-
ference on Computer Vision and Pattern Recognition , pages 3712‚Äì3722, 2018.
Hongyang Zhang, Vatsal Sharan, Moses Charikar, and Yingyu Liang. Recovery guarantees for
quadratic tensors with limited observations. In International Conference on ArtiÔ¨Åcial Intelligence
and Statistics (AISTATS) , 2019a.
Yu Zhang and Qiang Yang. A survey on multi-task learning. arXiv preprint arXiv:1707.08114 ,
2017.
Yu Zhang and Dit-Yan Yeung. A regularization approach to learning task relationships in multitask
learning. ACM Transactions on Knowledge Discovery from Data (TKDD) , 8(3):12, 2014.
Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael I Jordan. Bridging theory and algorithm
for domain adaptation. arXiv preprint arXiv:1904.05801 , 2019b.
14

--- PAGE 15 ---
Published as a conference paper at ICLR 2020
A M ISSING DETAILS OF SECTION 2
We Ô¨Åll in the missing details left from Section 2. In Section A.1, we provide rigorous arguments
regarding the capacity of the shared module. In Section A.2, we Ô¨Åll in the details left from Section
2.3, including the proof of Theorem 2 and its extension to the ReLU model. In Section A.3, we
provide the proof of Proposition 3 on the task reweighting schemes. We Ô¨Årst describe the notations.
Notations. We deÔ¨Åne the notations to be used later on. We denote f(x).g(x)if there exists an
absolute constant Csuch thatf(x)Cg(x). The big-O notation f(x) =O(g(x))means that
f(x).g(x).
SupposeA2Rmn, thenmax(A)denotes its largest singular value and min(A)denotes its
minfm;ng-th largest singular value. Alternatively, we have min(A) = minx:kxk=1kAxk. Let
(A) =max(A)=min(A)denote the condition number of A. Let Iddenotes the identity matrix.
LetUydenote the Moore-Penrose pseudo-inverse of the matrix U. Letkk denote the Euclidean
norm for vectors and spectral norm for matrices. Let kkFdenote the Frobenius norm of a matrix.
LethA;B; =iTr(A>B)denote the inner product of two matrices.
The sine function is deÔ¨Åne as sin(u;v) =p
1 cos(u;v)2, where we assume that sin(u;v)0
which is without loss of generality for our study.
A.1 M ISSING DETAILS OF SECTION 2.2
We describe the full detail to show that our model setup captures the phenomenon that the shared
module should be smaller than the sum of capacities of the single-task models. We state the fol-
lowing proposition which shows that the quality of the subspace Bin equation 1 determines the
performance of multi-task learning. This supplements the result of Proposition 1.
Proposition 4. In the optimum of f()(equation 1), each Aiselects the vector vwithin the column
span ofgB(Xi)to minimize L(v;yi). As a corollary, in the linear setting, the optimal Bcan be
achieved at a rotation matrix B?Rdrby maximizing
kX
i=1hB(B>X>
iXiB)yB>;X>
iyiy>
iXii: (7)
Furthermore, any B?which containsfigk
i=1in its column subspace is optimal. In particular, for
such aB?, there existsfA?
igso thatB?A?
i=ifor all 1ik.
Proof. Recall the MTL objective in the linear setting from equation 3 as follows:
minf(A1;A2;:::;Ak;B) =kX
i=1(XiBAi yi)2;
Note that the linear layer Aican pick any combination within the subspace of B. Therefore, we
could assume without loss of generality that Bis a rotation matrix. i.e. B>B= Id . After Ô¨Åxing B,
since objective f()is linear inAifor alli, by the local optimality condition, we obtain that
Ai= (B>X>
iXiB)yB>X>
iyi
Replacing the solution of Aitof(), we obtain an objective over B.
h(B) =kX
i=1kXiB(B>X>
iXiB)yB>X>
iyi yik2
F:
Next, note that
kXiB(B>X>
iXiB)yB>X>
iyik2
F= Tr(y>
iXiB(B>X>
iXiB)yB>X>
iyi)
=hB(B>X>
iXiB)B>;X>
iyiy>
iXii;
where we used the fact that AyAAy=AyforA=B>X>
iXiBin the Ô¨Årst equation. Hence we have
shown equation 7.
15

--- PAGE 16 ---
Published as a conference paper at ICLR 2020
For the Ô¨Ånal claim, as long as B?containsfigk
i=1in its column subspace, then there exists A?
isuch
thatB?A?
i=i. TheB?andfA?
igk
i=1are optimal solutions because each iis an optimal solution
for the single-task problem.
The above result on linear regression suggests the intuition that optimizing an MTL model reduces
to optimizing over the span of B. The intuition can be easily extended to linear classiÔ¨Åcation tasks
as well as mixtures of regression and classiÔ¨Åcation tasks.
Extension to the ReLU setting. If the shared module‚Äôs capacity is larger than the total capacities
of the STL models, then we can put all the STL model parameters into the shared module. As in
the linear setting, the Ô¨Ånal output layer Aican pick out the optimal parameter for the i-th task. This
remains an optimal solution to the MTL problem in the ReLU setting. Furthermore, there is no
transfer between any two tasks through the shared module.
A.2 M ISSING DETAILS OF SECTION 2.3
A.2.1 T HEEFFECT OF COSINE SIMILARITY
We consider the effect of varying the cosine similarity between single task models in multi-task
learning. We Ô¨Årst describe the following proposition to solve the multi-task learning objective when
the covariances of the task data are the same. The idea is similar to the work of Ando and Zhang
(2005) and we adapt it here for our study.
Proposition 5. Consider the reweighted loss of equation 2 with the encoding function being linear,
where the weights are figk
i=1. Suppose the task features of every task have the same covariance:
X>
iXi=  for all 1ik. Let  =VDV>be the singular vector decomposition (SVD) of .
Then the optimum of f()in equation 3 is achieved at:
B?=VD 1=2C?;
whereC?C?>is the best rank- rapproximation subspace ofPk
i=1iU>
iyiy>
iUiandXi=UiDV>
is the SVD of Xi, for each 1ik.
As a corollary, denote by 1;2;:::;kas the singular values of D 1V>Pk
i=1iX>
iyiy>
iXiin
decreasing order. Then the difference between an MTL model with hidden dimension rand the all
the single task models is bounded byPk
i=r+12
i.
Proof. Note thatB?is obtained by maximizing
kX
i=1hB(B>X>
iXiB) 1B>;iX>
iyiy>
iXii
LetC=DV>B. Clearly, there is a one to one mapping between BandC. And we have B=
VD 1C. Hence the above is equivalent to maximizing over CRdrwith
kX
i=1hC(C>C) 1C>;D 1V> kX
i=1iX>
iyiy>
iXi!
VD 1i
=hC(C>C) 1C>;kX
i=1iU>
iyiy>
iUii:
Note thatC(C>C) 1C>is a projection matrix onto a subspace of dimension r. Hence
the maximum (denote by C?) is attained at the best rank- rapproximation subspace ofPk
i=1iU>
iyiy>
iUi.
To illustrate the above proposition, consider a simple setting where Xiis identity for every 1
ik, andyi=ei, i.e. thei-th basis vector. Note that the optimal solution for the i-th task is
(X>
iXi) 1X>
iyi=yi. Hence the optimal solutions are orthogonal to each other for all the tasks,
withi= 1for all 1ik. And the minimum STL error is zero for all tasks.
16

--- PAGE 17 ---
Published as a conference paper at ICLR 2020
Consider the MTL model with hidden dimension r. By Proposition 5, the minimum MTL error is
achieved by the best rank- rapproximation subspace toPk
i=1X>
iyiy>
iXi=Pk
i=1yiy>
i. Denote
the optimum as B?
r. The MTL error is:
kX
i=1kyik2 hkX
i=1yiy>
i;B?
rB?
r>i=k r:
Different data covariance. We provide upper bounds on the quality of MTL solutions for different
data covariance, which depend on the relatedness of all the tasks. The following procedure gives the
precise statement. Consider kregression tasks with data f(Xi;yi)gk
i=1. Leti= (X>
iXi)yX>
iyi
denote the optimal solution of each regression task. Let WRdkdenote the matrix where the
i-th column is equal to i. Consider the following procedure for orthogonalizing Wfor1ik.
a) LetW?
i2Rddenote the vector which maximizesPk
i=1hXiB
kXiBk;yii2overB2Rd;
b) Denote by j=Pk
j=1hXjW?
j
kXjW?
jk;yji2;
c) For each 1ik, projectXiW?
ioff from every column of Xi. Go to Step a).
Proposition 6. Suppose that rd. LetB?denote the optimal MTL solution of capacity rin
the shared module. Denote by OPT =Pk
i=1(kyik2 kXi(X>
iXi)yX>
iyik2). Thenh(B?)
OPT Pd
i=r+1i.
Proof. It sufÔ¨Åces to show that OPT is equal toPk
i=1i. The result then follows since h(B?)is
less than the error given by W?
1;:::;W?
k, which is equal to OPT Pd
i=r+1i.
A.2.2 P ROOF OF THEOREM 2
We Ô¨Åll in the proof of Theorem 2. First, we restate the result rigorously as follows.
Theorem 2. Fori= 1;2, let(Xi;yi)2(Rmid;Rmi)denote two linear regression tasks with
parametersi2Rd. Suppose that each row of X1is drawn independently from a distribution with
covariance 1Rddand bounded l2-normp
L. Assume that >
111= 1w.l.o.g.
Letc2[(X2) sin(1;2);1=3]denote the desired error margin. Denote by (B?;A?
1;A?
2)the
optimal MTL solution. With probability 1 over the randomness of (X1;y1), when
m1&max 
Lk1klogd

2
min(1);(1)2(X2)
c2ky2k2;2(1)4(X2)
c42
1log1
!
;
we have thatkB?A?
2 2k=k2k6c+1
1 3ck"2k=kX22k:
We make several remarks to provide more insight on Theorem 2.
Theorem 2 guarantees positive transfers in MTL, when the source and target models are
close and the number of source samples is large. While the intuition is folklore in MTL, we
provide a formal justiÔ¨Åcation in the linear and ReLU models to quantify the phenomenon.
The error bound decreases with c, hence the smaller cis the better. On the other hand, the
required number of data points m1increases. Hence there is a trade-off between accuracy
and the amount of data.
cis assumed to be at most 1=3. This assumption arises when we deal with the label noise
of task 2. If there is no noise for task 2, then this assumption is not needed. If there is
noise for task 2, this assumption is satisÔ¨Åed when sin(1;2)is less than 1=(3(X2)). In
synthetic experiments, we observe that the dependence on (X2)andsin(1;2)both arise
in the performance of task 2, cf. Figure 3 and Figure 7, respectively.
The proof of Theorem 2 consists of two steps.
17

--- PAGE 18 ---
Published as a conference paper at ICLR 2020
a) We show that the angle between B?and1will be small. Once this is established, we get
a bound on the angle between B?and2via the triangle inequality.
b) We bound the distance between B?A2and2. The distance consists of two parts. One part
comes from B?, i.e. the angle between B?and2. The second part comes from A2, i.e.
the estimation error of the norm of 2, which involves the signal to noise ratio of task two.
We Ô¨Årst show the following geometric fact, which will be used later in the proof.
Fact 7. Leta;b2Rddenote two unit vectors. Suppose that X2Rmdhas full column rank with
condition number denoted by =(X). Then we have
jsin(Xa;Xb )j1
2jsin(a;b)j:
Proof. LetX=UDV>be the SVD of X. SinceXhas full column rank by assumption, we have
X>X=XX>= Id . Clearly, we have sin(Xa;Xb ) = sin(DV>a;DV>b). Denote by a0=V>a
andb0=V>b. We also have that a0andb0are both unit vectors, and sin(a0;b0) = sin(a;b). Let
1;:::;ddenote the singular values of X. Then,
sin2(Da0;Db0) = 1 Pd
i=12
ia0
ib0
i2
Pd
i=12
ia0
i2Pd
i=12
ib0
i2
=P
1i;jd2
i2
j(a0
ib0
j a0
jb0
i)2
Pd
i=12
ia0
i2Pd
i=12
jb0
i2
4
min
4maxX
1i;jd(a0
ib0
j a0
jb0
i)2
=1
4((dX
i=1a0
i2)(dX
i=1b0
i2) (dX
i=1a0
ib0
i)2) =1
4sin2(a0;b0):
This concludes the proof.
We Ô¨Årst show the following Lemma, which bounds the angle between B?and2.
Lemma 8. In the setting of Theorem 2, with probability 1 over the randomness of task one, we
have that
jsin(B?;2)jsin(1;2) +c=(X2):
Proof. We note that h(B?)ky1k2by the optimality of B?. Furthermore,hX2B?
kX2B?k;y2iky2k2.
Hence we obtain that
hX1B?
kX1B?k;y1i2ky1k2 ky2k2:
For the left hand side,
hX1B?
kX1B?k;y1i2=hX1B?
kX1B?k;X11+"1i2
=hX1B?
kX1B?k;X11i2+hX1B?
kX1B?k;"1i2+ 2hX1B?
kX1B?k;X11ihX1B?
kX1B?k;"1i
Note that the second term is a chi-squared random variable with expectation 2
1. Hence it is
bounded by 2
1q
log1
with probability at least 1 . Similarly, the third term is bounded by
2kX11k1q
log1
with probability 1 . Therefore, we obtain the following:
kX11k2cos2(X1B?;X11)ky1k2 ky2k2 (2
1+ 21kX11k)r
log1

18

--- PAGE 19 ---
Published as a conference paper at ICLR 2020
Note that
ky1k2kX11k2+ 2hX11;"1i
kX11k2 2kX11k1r
log1
:
Therefore,
kX11k2cos2(X1B?;X11)kX11k2 ky2k2 (2
1+ 31kX11k)r
log1

)sin2(X1B?;X11)ky2k2
kX11k2+41q
log1

kX11k
)sin2(B?;1)2(X1)0
@ky2k2
kX11k2+41q
log1

kX11k1
A (by Lemma 7)
By matrix Bernstein inequality (see e.g. Tropp et al. (2015)), when m110k1klogd
=2
min(1),
we have that:
1
m1X>
1X1 11
2min(1):
Hence we obtain that 2(X1)3(1)andkX11k2m1>
111=2m1=2(where we
assumed that >
111= 1). Therefore,
sin2(B?;1)3(1)0
@ky2k2
m2
1=4+41q
log1
p
m1=21
A;
which is at most c2=2(X2)by our setting of m1. Therefore, the conclusion follows by triangle
inequality (noting that both candsin(1;2)are less than 1=2).
Based on the above Lemma, we are now to ready to prove Theorem 2.
Proof of Theorem 2. Note that in the MTL model, after obtaining B?, we then solve the linear layer
for each task. For task 2, this gives weight value A?
2:=hX2^;y2i=kX2^k2. Thus the regression
coefÔ¨Åcients for task 2 is B?A?
2. For the rest of the proof, we focus on bounding the distance between
B?A?
2and2. By triangle inequality,
kB?A?
2 2kjhX2B?;"2ij
kX2B?k2+hX2B?;X22i
kX2B?k2 k2k+kB?k2k 2k: (8)
Note that the second term of equation 8 is equal to
jhX2B?;X2(2 k2kB?)ij
kX2B?k2(X2)k2 k2kB?k:
The Ô¨Årst term of equation 8 is bounded by
k"2k
kX2B?kk"2kk2k
kX22k kX2(2 k2kB?)k: (9)
Lastly, we have that
k2 k2kB?k2=k2k22(1 cos(B?;2))2k2k2sin2(B?;2)
By Lemma 8, we have
jsin(B?;2)jsin(1;2) +c=(X2)
19

--- PAGE 20 ---
Published as a conference paper at ICLR 2020
Therefore, we conclude that equation 9 is at most
k"2kk2k
kX22k p
2max(X2)k2ksin(1;2) p
2cmin(X2)k2k
k"2kk2k
kX22k 3cmin(X2)k2k
1
1 3ck"2kk2k
kX22k
Thus equation 8 is at most the following.
k2k1
1 3ck"2k
kX22k+p
2((X2) + 1)sin(B?;2)
k2k1
1 3ck"2k
kX22k+ 6c
:
Hence we obtain the desired estimation error of BA?
2.
A.2.3 E XTENSION TO THERELU M ODEL
In this part, we extend Theorem 2 to the ReLU model. Note that the problem is reduced to the
following objective.
max
B2Rdg(B) =hReLU (X1B)
kReLU (X1B)k;y1i2+hReLU (X2B)
kReLU (X2B)k;y2i2(10)
We make a crucial assumption that task 1‚Äôs input X1follows the Gaussian distribution. Note that
making distributional assumptions is necessary because for worst-case inputs, even optimizing a
single ReLU function under the squared loss is NP-hard (Manurangsi and Reichman (2018)). We
state our result formally as follows.
Theorem 9. Let(X1;y1)2(Rm1d;Rm1)and (X2;y2)2(Rm2d;Rm2)denote two
tasks. Suppose that each row of X1is drawn from the standard Gaussian distribution. And
yi=aiReLU (Xii) +"iare generated via the ReLU model with 1;22Rd. Let
E
(aiReLU (Xii))2
j
= 1for every 1jm1without loss of generality, and let 2
1denote the
variance of every entry of "1.
Suppose that csin(1;2)=(X2). Denote by (B?;A?
1;A?
2)the optimal MTL solution of equa-
tion 10. With probability 1 over the randomness of (X1;y1), when
m1&maxdlogd
c2(1
c2+ logd);ky2k2
c2
;
we have that the estimation error is at most:
sin(B?;1)sin(1;2) +O(c=(X2));
jA?
2 a2j
a2O(c) +1
(1 O(c))k"2k
a2ReLU (kX22k)
Proof. The proof follows a similar structure to that of Theorem 2. Without loss of generality, we
can assume that 1;2are both unit vectors. We Ô¨Årst bound the angle between B?and1.
By the optimality of B?, we have that:
hReLU (X1B?)
kReLU (X1B?)k;y1i2hReLU (X11)
kReLU (X11)k;y1i2 ky2k2
From this we obtain:
a2
1hReLU (X1B?)
kReLU (X1B?)k;ReLU (X1B?)i2
a2
1kReLU (X11)k2 ky2k2 (2
1+ 4a11kReLU (X11)k)r
log1
(11)
20

--- PAGE 21 ---
Published as a conference paper at ICLR 2020
Note that each entry of ReLU (X11)is a truncated Gaussian random variable. By the Hoeffding
bound, with probability 1 we have
kReLU (X11)k2 m1
2r
m1
2log1
:
As forhReLU (X1B?);ReLU (X11)i, we will use an epsilon-net argument over B?to show the
concentration. For a Ô¨Åxed B?, we note that this is a sum of independent random variables that are
all bounded within O(logm1
)with probability 1 . Denote by the angle between B?and1,
a standard geometric fact states that (see e.g. Lemma 1 of Du et al. (2017)) for a random Gaussian
vectorx2Rd,
E
x
ReLU (x>B?)ReLU (x>1)
=cos
2+cos(tan )
2:=g()
2:
Therefore, by applying Bernstein‚Äôs inequality and union bound, with probability 1 we have:
jhReLU (X1B?);ReLU (X11)i m1g()=2j2r
m1g() log1
+2
3log1
logm1

By standard arguments, there exists a set of dO(d)unit vectors Ssuch that for any other unit vector
uthere exists ^u2Ssuch thatku ^uk min(1=d3;c2=2(X2)). By setting =d O(d)and
take union bound over all unit vectors in S, we have that there exists ^u2SsatisfyingkB? ^uk
min(1=d3;c2=2(X2))and the following:
jhReLU (X1^u);ReLU (X11)i m1g(0)=2j.p
m1dlogd+dlog2d
2m1c2=2(X2) (by our setting of m1)
where0is the angle between ^uand1. Note thathReLU (X1^) ReLU (X1B?);ReLU (X11)ikX1(^u B?)kkReLU (X11)k
c2=2(X2)O(m1)
Together we have shown that
jhReLU (X1B?);ReLU (X11)i m1g(0)=2jc2=2(X2)O(m1):
Combined with equation 11, by our setting of m1, it is not hard to show that
g(0)1 O(c2=2(X2)):
Note that
1 g(0) = 1 cos0 cos0(tan0 0)
1 cos0= 2 sin20
2.c2=2(X2);
which implies that sin20.c2=2(X2)(sincecos0
20:9). Finally note that k^u B?k 
c2=2(X2), hence
k^u B?k2= 2(1 cos(^u;B?))2 sin2(^u;B?):
Overall, we conclude that sin(B?;1)O(c=(X2)). Hence
sin(B?;2)sin(1;2) +O(c=(X2)):
For the estimation of a2, we havehReLU (X2B?);y2i
kReLU (X2B?)k2 a2jhReLU (X2B?);"2ij
kReLU (X2B?)k2
+a2hReLU (X2B?);ReLU (X2B?) ReLU (X22)i
kReLU (X2B?)k2
The Ô¨Årst part is at most
k"2k
kReLU (X2B?)kk"2k
kReLU (X22)k k ReLU (X22) ReLU (X2B?)k
1
1 O(c)k"2k
kReLU (X22)k
Similarly, we can show that the second part is at most O(c). Therefore, the proof is complete.
21

--- PAGE 22 ---
Published as a conference paper at ICLR 2020
A.3 P ROOF OF PROPOSITION 3
In this part, we present the proof of Proposition 3. In fact, we present a more reÔ¨Åned result, by
showing that all local minima are global minima for the reweighted loss in the linear case.
f(A1;A2;:::;Ak;B) =kX
i=1ikXiBAi yi)k2
F: (12)
The key is to reduce the MTL objective f()to low rank matrix approximation, and apply recent
results by Balcan et al. (2018) which show that there is no spurious local minima for the latter
problem .
Lemma 10. Assume that X>
iXi=iwithi>0for all 1ik. Then all the local minima
off(A1;:::;Ak;B)are global minima of equation 3.
Proof. We Ô¨Årst transform the problem from the space of Bto the space of C. Note that this is
without loss of generality, since there is a one to one mapping between BandCwithC=DV>B.
In this case, the corresponding objective becomes the following.
g(A1;:::;Ak;B) =kX
i=1ikUiCAi yik2
=kX
i=1kC(piAi) piU>
iyik2+kX
i=1i(kyik2 kU>
iyik2)
The latter expression is a constant. Hence it does not affect the optimization solution. For the
former, denote by A2Rrkas stacking thepiAi‚Äôs together column-wise. Similarly, denote by
Z2Rdkas stackingpiU>
iyitogether column-wise. Then minimizing g()reduces solving low
rank matrix approximation: kCA Zk2
F.
By Lemma 3.1 of Balcan et al. (2018), the only local minima of kCA Zk2
Fare the ones where
CAis equal to the best rank- rapproximation of Z. Hence the proof is complete.
Now we are ready to prove Proposition 3.
Proof of Proposition 3. By Proposition 5, the optimal solution of B?for equation 12 is VD 1
times the best rank- rapproximation to iU>yiy>
iU, where we denote the SVD of XasUDV>.
Denote byQrQ>
ras the best rank- rapproximation to U>ZZ>U, where we denote by Z=
[p1y1;p2y2;:::;pkyk]as stacking the kvectors to a dbykmatrix. Hence the result of
Proposition 5 shows that the optimal solution B?isVD 1Qr, which is equal to (X>X) 1XQr.
By Proposition 4, the optimality of B?is the same up to transformations on the column space. Hence
the proof is complete.
To show that all local minima are also equal to (X>X) 1XQr, we can simply apply Lemma 10
and Proposition 3.
Remark. This result only applies to the linear model and does not work on ReLU models. The ques-
tion of characterizing the optimization landscape in non-linear ReLU models is not well-understood
based on the current theoretical understanding of neural networks. We leave this for future work.
22

--- PAGE 23 ---
Published as a conference paper at ICLR 2020
B S UPPLEMENTARY EXPERIMENTAL RESULTS
We Ô¨Åll in the details left from our experimental section. In Appendix B.1, we review the datasets
used in our experiments. In Appendix B.2, we describe the models we use on each dataset. In
Appendix B.3, we describe the training procedures for all experiments. In Appendix B.4 and Ap-
pendix B.5, we show extended synthetic and real world experiments to support our claims.
B.1 D ATASETS
We describe the synthetic settings and the datasets Sentiment Analysis ,General Language Under-
standing Evaluation (GLUE) benchmark , and ChestX-ray14 used in the experiments.
Synthetic settings. For the synthetic experiments, we draw 10,000 random data samples with di-
mensiond= 100 from the standard Gaussian N(0;1)and calculate the corresponding labels based
on the model described in experiment. We split the data samples into training and validation sets
with 9,000 and 1,000 samples in each. For classiÔ¨Åcation tasks, we generate the labels by applying
a sigmoid function and then thresholding the value to binary labels at 0:5. For ReLU regression
tasks, we apply the ReLU activation function on the real-valued labels. The number of data samples
used in the experiments varies depending on the speciÔ¨Åcation. SpeciÔ¨Åcally, for the task covariance
experiment of Figure 3, we Ô¨Åx task 1‚Äôs data with m1= 9;000training data and vary task 2‚Äôs data
under three settings: (i) same rotation Q1=Q2but different singular values D16=D2; (ii) same
singular values D1=D2but random rotations Q16=Q2.
Sentiment analysis. For the sentiment analysis task, the goal is to understand the sentiment opinions
expressed in the text based on the context provided. This is a popular text classiÔ¨Åcation task which
is usually formulated as a multi-label classiÔ¨Åcation task over different ratings such as positive (+1),
negative (-1), or neutral (0). We use six sentiment analysis benchmarks in our experiments:
Movie review sentiment (MR): In the MR dataset (Pang and Lee (2005)), each movie re-
view consists of a single sentence. The goal is to detect positive vs. negative reviews.
Sentence subjectivity (SUBJ): The SUBJ dataset is proposed in Pang and Lee (2004) and
the goal is to classify whether a given sentence is subjective or objective.
Customer reviews polarity (CR): The CR dataset (Hu and Liu (2004)) provides customer
reviews of various products. The goal is to categorize positive and negative reviews.
Question type (TREC): The TREC dataset is collected by Li and Roth (2002). The aim is
to classify a question into 6 question types.
Opinion polarity (MPQA): The MPQA dataset detects whether an opinion is polarized or
not (Wiebe et al. (2005)).
Stanford sentiment treebank (SST): The SST dataset, created by Socher et al. (2013), is an
extension of the MR dataset.
The General Language Understanding Evaluation (GLUE) benchmark. GLUE is a collection
of NLP tasks including question answering, sentiment analysis, text similarity and textual entail-
ment problems. The GLUE benchmark is a state-of-the-art MTL benchmark for both academia and
industry. We select Ô¨Åve representative tasks including CoLA, MRPC, QNLI, RTE, and SST-2 to
validate our proposed method. We emphasize that the goal of this work is not to come up with a
state-of-the-art result but rather to provide insights into the working of multi-task learning. It is
conceivable that our results can be extended to the entire dataset as well. This is left for future work.
More details about the GLUE benchmark can be found in the original paper (Wang et al. (2018a)).
ChestX-ray14. The ChestX-ray14 dataset (Wang et al. (2017)) is the largest publicly available
chest X-ray dataset. It contains 112,120 frontal-view X-ray images of 30,805 unique patients. Each
image contains up to 14 different thoracic pathology labels using automatic extraction methods on
radiology reports. This can be formulated as a 14-task multi-label image classiÔ¨Åcation problem.
The ChestX-ray14 dataset is a representative dataset in the medical imaging domain as well as in
computer vision. We use this dataset to examine our proposed task reweighting scheme since it
satisÔ¨Åes the assumption that all tasks have the same input data but different labels.
23

--- PAGE 24 ---
Published as a conference paper at ICLR 2020
B.2 M ODELS
Synthetic settings. For the synthetic experiments, we use the linear regression model, the logistic
regression model and a one-layer neural network with the ReLU activation function.
Sentiment analysis. For the sentiment analysis experiments, we consider three different models
including multi-layer perceptron (MLP), LSTM, CNN:
For the MLP model, we average the word embeddings of a sentence and feed the result into
a two layer perceptron, followed by a classiÔ¨Åcation layer.
For the LSTM model, we use the standard one-layer single direction LSTM as proposed
by Lei et al. (2018), followed by a classiÔ¨Åcation layer.
For the CNN model, we use the model proposed by Kim (2014) which uses one convolu-
tional layer with multiple Ô¨Ålters, followed by a ReLU layer, max-pooling layer, and classi-
Ô¨Åcation layer. We follow the protocol of Kim (2014) and set the Ô¨Ålter size as f3;4;5g.
We use the pre-trained GLoVe embeddings trained on Wikipedia 2014 and Gigaword 5 corpora6.
We Ô¨Åne-tune the entire model in our experiments. In the multi-task learning setting, the shared
modules include the embedding layer and the feature extraction layer (i.e. the MLP, LSTM, or CNN
model). Each task has its separate output module.
GLUE. For the experiments on the GLUE benchmark, we use a state-of-the-art language model
called BERT (Devlin et al. (2018)). For each task, we add a classiÔ¨Åcation/regression layer on top it
as our model. For all the experiments, we use the BERT LARGE uncased model, which is a 24 layer
network as described in Devlin et al. (2018). For the multi-task learning setting, we follow the work
of Liu et al. (2019a) and use BERT LARGE as the shared module.
ChestX-ray14. For the experiments on the ChestX-ray14 dataset, we use the DenseNet model
proposed by Rajpurkar et al. (2017) as the shared module, which is a 121 layer network. For each
task, we use a separate classiÔ¨Åcation output layer. We use the pre-trained model7in our experiments.
B.3 T RAINING PROCEDURES
In this subsection, we describe the training procedures for our experiments.
Mini-batch SGD. We describe the details of task data sampling in our SGD implementation.
For tasks with different features such as GLUE, we Ô¨Årst divide each task data into small
batches. Then, we mix all the batches from all tasks and shufÔ¨Çe randomly. During every
epoch, a SGD step is applied on every batch over the corresponding task. If the current
batch is for task i, then the SGD is applied on Ai, and possibly RiorBdepending on the
setup. The other parameters for other tasks are Ô¨Åxed.
For tasks with the same features such as ChestX-ray14, the SGD is applied on all the tasks
jointly to update all the Ai‚Äôs andBtogether.
Synthetic settings. For the synthetic experiments, we do a grid search over the learning rate from
f1e 4;1e 3;1e 2;1e 1gand the number of epochs from f10;20;30;40;50g. We pick the
best results for all the experiments. We choose the learning rate to be 1e 3, the number of epochs
to be 30, and the batch size to be 50. For regression task, we report the Spearman‚Äôs correlation score
For classiÔ¨Åcation task, we report the classiÔ¨Åcation accuracy.
Sentiment analysis. For the sentiment analysis experiments, we randomly split the data into train-
ing, dev and test sets with percentages 80%,10%, and 10% respectively. We follow the protocol
of Lei et al. (2018) to set up our model for the sentiment analysis experiments.
The default hidden dimension of the model (e.g. LSTM) is set to be 200, but we vary this parameter
for the model capacity experiments. We report the accuracy score on the test set as the performance
metric.
6http://nlp.stanford.edu/data/wordvecs/glove.6B.zip
7https://github.com/pytorch/vision
24

--- PAGE 25 ---
Published as a conference paper at ICLR 2020
MTL performance over STL (Spearman correlation)‚àí0.4‚àí0.20
Cosine distance between tasks0 0.5 1.0
(a) Linear regression tasks
MTL performance over STL (Accuracy)‚àí0.2‚àí0.10
Cosine distance between tasks0 0.5 1.0 (b) Logistic classiÔ¨Åcation tasks
MTL performance over STL (Spearman correlation)‚àí0.04‚àí0.0200.02
Cosine distance between tasks0 0.5 1.0
(c) Regression tasks with ReLU non-linearity
MTL performance over STL (Accuracy)‚àí0.0500.05
Cosine distance between tasks0 0.5 1.0 (d) ClassiÔ¨Åcation tasks with ReLU non-linearity
Figure 7: Comparing MTL model performance over different task similarity. For (a) and (c), MTL
trains two regression tasks; For (b) and (d), MTL trains two classiÔ¨Åcation tasks. For regression
tasks, we use spearman correlation as model performance indicator. For classiÔ¨Åcation tasks, we
use accuracy as the metric. We report the average model performance over two tasks. The x-axis
denotes the cosine distance, i.e. 1 cos(1;2).
GLUE. For the GLUE experiments, the training procedure is used on the alignment modules and
the output modules. Due to the complexity of the BERT LARGE module, which involves 24 layers of
non-linear transformations.
We Ô¨Åx the BERT LARGE module during the training process to examine the effect of adding the
alignment modules to the training process. In general, even after Ô¨Åne-tuning the BERT LARGE module
on a set of tasks, it is always possible to add our alignment modules and apply Algorithm 1.
For the training parameters, we apply grid search to tune the learning rate from f2e 5;3e 5;1e 5g
and the number of epochs from f2;3;5;10g. We choose the learning rate to be 2e 5, the number
of epochs to be 5, and with batch size 16for all the experiments.
We use the GLUE evaluation metric (cf. Wang et al. (2018b)) and report the scores on the develop-
ment set as the performance metric.
ChestX-ray14. For the ChestX-ray14 experiments, we use the conÔ¨Åguration suggested by Rajpurkar
et al. (2017) and report the AUC score on the test set after Ô¨Åne-tuning the model for 20 epochs.
B.4 E XTENDED SYNTHETIC EXPERIMENTS
Varying cosine similarity on linear and ReLU models. We demonstrate the effect of cosine simi-
larity in synthetic settings for both regression and classiÔ¨Åcation tasks.
Synthetic tasks. We start with linear settings. We generate 20 synthetic task datasets (either for
regression tasks, or classiÔ¨Åcation tasks) based on data generation procedure and vary the task simi-
larity between task 1and taski. We run the experiment with a different dataset pairs (dataset 1and
dataseti).
25

--- PAGE 26 ---
Published as a conference paper at ICLR 2020
Sim. 0.9
Sim. 0.7Sim. 0.5
Sim. 0.3Sim. 0.1Performance Improvements‚àí0.200.2
# Data size2000 4000 6000 8000
(a) Regression tasks with non-linearity
Sim. 0.9
Sim. 0.7Sim. 0.5
Sim. 0.3Sim. 0.1Performance Improvements‚àí0.2‚àí0.100.1
# Data size2000 4000 6000 8000 (b) ClassiÔ¨Åcation tasks with non-linearity
Figure 8: The performance improvement on the target task (MTL minus STL) by varying the cosine
similarity of the two tasks‚Äô STL models. We observe that higher similarity between the STL models
leads to better improvement on the target task.
Baseline
Algorithm 1Positive Transfer
Negative TransferTarget task's Perf.: MTL - STL‚àí0.2‚àí0.100.10.2
# Data samples of source task2000 4000 6000 8000
(a) Linear regression tasks
Positive Transfer
Negative TransferBaseline
Algorithm 1Target task's Perf.: MTL - STL‚àí0.2‚àí0.100.10.2
# Data samples of source task2000 4000 6000 8000 (b) Regression tasks with ReLU activation
Figure 9: Comparing Algorithm 1 to the baseline MTL training on the synthetic example in Section
2.3. Algorithm 1 corrects the negative transfer phenomenon observed in Figure 3.
After generating the tasks, we compare the performance gap between MTL and STL model.
Results. From Figure 7a and Figure 7a, we Ô¨Ånd that for both regression and classiÔ¨Åcation settings,
with the larger task similarity the MTL outperforms more than STL model and the negative transfer
could occur if the task similarity is too small.
ReLU settings. We also consider a ReLU-activated model. We use the same setup as the linear
setting, but apply a ReLU activation to generate the data. Similar results are shown in Figure 7c, 7d.
Higher rank regimes for ReLU settings. We provide further validation of our results on ReLU-
activated models.
Synthetic tasks. In this synthetic experiment, there are two sets of model parameters 1Rdrand
2Rdr(d= 100 andr= 10 ).1is a Ô¨Åxed random rotation matrix and there are m1= 100
data points for task 1. Task 2‚Äôs model parameter is 2=1+ (1 )0, where 0is also a Ô¨Åxed
rotation matrix that is orthogonal to 1. Note thatis the cosine value/similarity of the principal
angle between 1and2.
We then generate X1Rm1dandX2Rm2dfrom Gaussian. For each task, the labels are
yi=ReLU (Xii)e+"i, wheree2Rris the all ones vector and "iis a random Gaussian noise.
Given the two tasks, we use MTL with ReLU activations and capacity H= 10 to co-train the two
tasks. The goal is to see how different levels of or similarity affects the transfer from task two to
task one. Note that this setting parallels the ReLU setting of Theorem 9 but applies to rank r= 5.
26

--- PAGE 27 ---
Published as a conference paper at ICLR 2020
MTL-Avg.
STL-SST
STL-MR
STL-CR
STL-SUBJ
STL-MPQA
STL-TRECMTL-Avg. peak
LSTMAccuracy
0.60.70.80.9
Model capacity0 100 200 300 400 500
Figure 10: Cross validation to choose the best performing model capacity for each model.
MTL-Avg.
STL-SST
STL-MRSTL-MR peakMTL-Avg. peak
STL-SST peak
MLPAccuracy
0.760.780.80
Model capacity0 100 200 300 400 500
MTL-Avg.
STL-SST
STL-MR
STL-MR peakMTL-Avg. peak
STL-SST peak
CNNAccuracy
0.800.850.90
Model capacity0 500 1000
MTL-Avg.
STL-SST
STL-MR
STL-MR peakMTL-Avg. peak
STL-SST peak
LSTMAccuracy
0.750.800.850.90
Model capacity0 100 200 300 400 500
Figure 11: Validation on MLP, CNN and LSTM models for sentiment analysis tasks.
Results. In Figure 8 we show that the data size, the cosine similarity between the STL solutions and
the alignment of covariances continue to affect the rate of transfer in the new settings. The study
shows that our conceptual results are applicable to a wide range of settings.
Evaluating Algorithm 1 on linear and ReLU-activated models. We consider the synthetic ex-
ample in Section 2.3 to compare Algorithm 1 and the baseline MTL training. Recall that in the
example, when the source and target tasks have different covariance matrices, MTL causes negative
transfer on the target task. Our hypothesis in this experiment is to show that Algorithm 1 can correct
the misalignment and the negative transfer.
Synthetic tasks. We evaluate on both linear and ReLU regression tasks. The linear case follows the
example in Section 2.3. For the ReLU case, the data is generated according to the previous example.
Results. Figure 9 conÔ¨Årms the hypothesis. We observe that Algorithm 1 corrects the negative transfer
in the regime where the source task only has limited amount of data. Furthermore, Algorithm 1
matches the baseline MTL training when the source task has sufÔ¨Åciently many data points.
B.5 E XTENDED ABLATION STUDIES
Cross validation for choosing model capacities. We provide a cross validation experiment to
indicate how we choose the best performing model capacities in Figure 1. This is done on the six
sentiment analysis tasks trained with an LSTM layer.
In Figure 10, we vary the model capacities to plot the validation accuracies of the MTL model trained
with all six tasks and the STL model for each task. The result complements Table 1 in Section 3.3.
Choosing model capacities for CNN and MLP. Next we verify our result on model capacities for
CNN and MLP models. We select the SST and MR datasets from the sentiment analysis tasks for
this experiment. We train all three models CNN, MLP and LSTM by varying the capacities.
Results. From Figure 11 we observe that the best performing MTL model capacity is less than total
best performing model capacities of STL model on all models.
27

--- PAGE 28 ---
Published as a conference paper at ICLR 2020
The effect of label noise on Algorithm 2. To evaluate the robustness of Algorithm 2 in the presence
of label noise, we conduct the following experiment. First, we subsample 10% of the ChestX-ray14
dataset and select two tasks from it. Then, we randomly pick one task to add 20% of noise to its
labels by randomly Ô¨Çipping them with probability 0:5. We compare the performance of training both
tasks using our reweighting scheme (Algorithm 2) vs. the reweighting techniques of Kendall et al.
(2018) and the unweighted loss scheme.
Results. On 10 randomly chosen task pairs, our method improves over the unweighted training
scheme by 1.0% AUC score and 0.4% AUC score over Kendall et al. (2018) averaged over the 10
task pairs. Figure 12 shows 5 example task pairs from our evaluation.
Unweighted loss Kendall et al. Algorithm 2MTL performance
0.40.50.60.70.8
Consolidation
CardiomegalyConsolidation
EdemaConsolidation
InÔ¨ÅltrationEdema
AtelectasisFibrosis
Consolidation
Figure 12: Comparing Algorithm 2 to the unweighted scheme and Kendall et al. (2018).
28

Tài liệu tham khảo

Satanjeev Banerjee và Alon Lavie. 2005. Meteor: Một chỉ số tự động cho đánh giá mt với mối tương quan được cải thiện với các đánh giá của con người. Trong Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization, trang 65–72.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Các mô hình ngôn ngữ là những người học few-shot. Advances in neural information processing systems, 33:1877–1901.

Christopher Bryant, Mariano Felice, Øistein E Andersen, và Ted Briscoe. 2019. Nhiệm vụ chia sẻ bea-2019 về sửa lỗi ngữ pháp. Trong Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications, trang 52–75.

Ricardo Campos, Vítor Mangaravite, Arian Pasquali, Alípio Jorge, Célia Nunes, và Adam Jatowt. 2020. Yake! trích xuất từ khóa từ các tài liệu đơn lẻ sử dụng nhiều đặc trưng cục bộ. Information Sciences, 509:257–289.

Ricardo Campos, Vítor Mangaravite, Arian Pasquali, Alípio Mário Jorge, Célia Nunes, và Adam Jatowt. 2018a. Một phương pháp trích xuất từ khóa tự động dựa trên đặc trưng văn bản cho các tài liệu đơn lẻ. Trong European conference on information retrieval, trang 684–691. Springer.

Ricardo Campos, Vítor Mangaravite, Arian Pasquali, Alípio Mário Jorge, Célia Nunes, và Adam Jatowt. 2018b. Yake! bộ trích xuất từ khóa tự động độc lập với bộ sưu tập. Trong European Conference on Information Retrieval, trang 806–810. Springer.

Hao Chen, Yiming Zhang, Qi Zhang, Hantao Yang, Xiaomeng Hu, Xuetao Ma, Yifan Yanggong, và Junbo Zhao. 2023. Có thể chỉ cần 0.5% dữ liệu: Một khám phá sơ bộ về điều chỉnh hướng dẫn với dữ liệu huấn luyện thấp. arXiv preprint arXiv:2305.09246.

Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, và Eric P. Xing. 2023. Vicuna: Một chatbot mã nguồn mở gây ấn tượng với gpt-4 với 90%* chất lượng chatgpt.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Mở rộng các mô hình ngôn ngữ điều chỉnh hướng dẫn. arXiv preprint arXiv:2210.11416.

William W. Cohen. 2015. Bộ dữ liệu email Enron. https://www.cs.cmu.edu/~enron/.

Databricks. 2023. Dolly của Databricks, một mô hình ngôn ngữ lớn được huấn luyện trên nền tảng học máy databricks. https://github.com/databrickslabs/dolly.

Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan Liu, Maosong Sun, và Bowen Zhou. 2023. Nâng cao các mô hình ngôn ngữ chat bằng cách mở rộng các cuộc trò chuyện hướng dẫn chất lượng cao. arXiv preprint arXiv:2305.14233.

Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, et al. 2020. The pile: Một bộ dữ liệu 800gb văn bản đa dạng cho mô hình hóa ngôn ngữ. arXiv preprint arXiv:2101.00027.

Yuxian Gu, Pei Ke, Xiaoyan Zhu, và Minlie Huang. 2022. Học các hướng dẫn với dữ liệu không có nhãn cho tổng quát hóa zero-shot cross-task. arXiv preprint arXiv:2210.09175.

Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, và Yejin Choi. 2019. Trường hợp tò mò của việc suy thoái văn bản thần kinh. Trong International Conference on Learning Representations.

Or Honovich, Thomas Scialom, Omer Levy, và Timo Schick. 2022. Hướng dẫn không tự nhiên: Điều chỉnh các mô hình ngôn ngữ với (gần như) không có lao động của con người. arXiv preprint arXiv:2212.09689.

Srinivasan Iyer, Xi Victoria Lin, Ramakanth Pasunuru, Todor Mihaylov, Dániel Simig, Ping Yu, Kurt Shuster, Tianlu Wang, Qing Liu, Punit Singh Koura, et al. 2022. Opt-iml: Mở rộng meta học hướng dẫn mô hình ngôn ngữ thông qua lăng kính tổng quát hóa. arXiv preprint arXiv:2212.12017.

Yuxin Jiang, Chunkit Chan, Mingyang Chen, và Wei Wang. 2023. Lion: Chưng cất đối kháng của mô hình ngôn ngữ lớn mã nguồn đóng. arXiv preprint arXiv:2305.12870.

Nikita Kitaev, Steven Cao, và Dan Klein. 2019. Phân tích cú pháp thành phần đa ngôn ngữ với self-attention và pre-training. Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, trang 3499–3505.

Nikita Kitaev và Dan Klein. 2018. Phân tích cú pháp thành phần với một bộ mã hóa self-attentive. Trong Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 2676–2686.

Abdullatif Köksal, Timo Schick, Anna Korhonen, và Hinrich Schütze. 2023. Longform: Tối ưu hóa điều chỉnh hướng dẫn cho việc tạo văn bản dài với trích xuất corpus. arXiv preprint arXiv:2304.08460.

Mahnaz Koupaee và William Yang Wang. 2018. Wikihow: Một bộ dữ liệu tóm tắt văn bản quy mô lớn. arXiv preprint arXiv:1810.09305.

Chin-Yew Lin. 2004. Rouge: Một gói cho đánh giá tự động các bản tóm tắt. Trong Text summarization branches out, trang 74–81.

Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V Le, Barret Zoph, Jason Wei, et al. 2023. Bộ sưu tập flan: Thiết kế dữ liệu và phương pháp cho điều chỉnh hướng dẫn hiệu quả. arXiv preprint arXiv:2301.13688.

Ilya Loshchilov và Frank Hutter. 2019. Regularization suy giảm trọng số tách rời. Trong International Conference on Learning Representations.

Swaroop Mishra, Daniel Khashabi, Chitta Baral, và Hannaneh Hajishirzi. 2022. Tổng quát hóa cross-task thông qua hướng dẫn crowdsourcing ngôn ngữ tự nhiên. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), trang 3470–3487, Dublin, Ireland. Association for Computational Linguistics.

Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey Schoelkopf, et al. 2022. Tổng quát hóa đa ngôn ngữ thông qua fine-tuning đa nhiệm vụ. arXiv preprint arXiv:2211.01786.

OpenAI. 2023. Báo cáo kỹ thuật gpt-4.

Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Huấn luyện các mô hình ngôn ngữ để tuân theo hướng dẫn với phản hồi của con người. Advances in Neural Information Processing Systems, 35:27730–27744.

Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, và Jianfeng Gao. 2023. Điều chỉnh hướng dẫn với gpt-4. arXiv preprint arXiv:2304.03277.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J Liu. 2020. Khám phá các giới hạn của học chuyển giao với một transformer văn bản-đến-văn bản thống nhất. The Journal of Machine Learning Research, 21(1):5485–5551.

Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. 2021. Huấn luyện prompted đa nhiệm vụ cho phép tổng quát hóa zero-shot nhiệm vụ. arXiv preprint arXiv:2110.08207.

Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, et al. 2022. Vượt qua trò chơi bắt chước: Định lượng và ngoại suy khả năng của các mô hình ngôn ngữ. arXiv preprint arXiv:2206.04615.

Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David Cox, Yiming Yang, và Chuang Gan. 2023. Tự điều chỉnh theo nguyên tắc của các mô hình ngôn ngữ từ đầu với giám sát tối thiểu của con người. arXiv preprint arXiv:2305.03047.

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, và Tatsunori B. Hashimoto. 2023. Stanford alpaca: Một mô hình llama tuân theo hướng dẫn. https://github.com/tatsu-lab/stanford_alpaca.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Các mô hình ngôn ngữ nền tảng mở và hiệu quả. arXiv preprint arXiv:2302.13971.

Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, và Hannaneh Hajishirzi. 2022a. Self-instruct: Điều chỉnh mô hình ngôn ngữ với các hướng dẫn tự tạo ra. arXiv preprint arXiv:2212.10560.

Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva Naik, Arjun Ashok, Arut Selvan Dhanasekaran, Anjana Arunkumar, David Stap, et al. 2022b. Supernaturalinstructions: Tổng quát hóa thông qua hướng dẫn khai báo trên 1600+ nhiệm vụ nlp. Trong Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, trang 5085–5109.

Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, và Quoc V Le. 2021. Các mô hình ngôn ngữ được fine-tuned là những người học zero-shot. arXiv preprint arXiv:2109.01652.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. 2020. Transformers: Xử lý ngôn ngữ tự nhiên hiện đại. Trong Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations, trang 38–45.

Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, và Daxin Jiang. 2023. Wizardlm: Trao quyền cho các mô hình ngôn ngữ lớn để tuân theo các hướng dẫn phức tạp.

Hanwei Xu, Yujun Chen, Yulun Du, Nan Shao, Yanggang Wang, Haiyu Li, và Zhilin Yang. 2022. Zero-prompt: Mở rộng pre-training dựa trên prompt lên 1.000 nhiệm vụ cải thiện tổng quát hóa zero-shot. arXiv preprint arXiv:2201.06910.

Dongjie Yang, Ruifeng Yuan, YuanTao Fan, YiFei Yang, Zili Wang, Shushen Wang, và Hai Zhao. 2023. Refgpt: Tham chiếu-> đối thoại chân thực và tùy chỉnh được tạo ra bởi gpts và cho gpts. arXiv preprint arXiv:2305.14994.

Da Yin, Xiao Liu, Fan Yin, Ming Zhong, Hritik Bansal, Jiawei Han, và Kai-Wei Chang. 2023. Dynosaur: Một mô hình tăng trường động cho việc tuyển chọn dữ liệu điều chỉnh hướng dẫn. arXiv preprint arXiv:2305.14327.

Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al. 2023. Lima: Ít hơn là nhiều hơn cho việc điều chỉnh. arXiv preprint arXiv:2305.11206.

A Tính đa dạng của SUPERNI và LongForm
Để so sánh tính đa dạng của các hướng dẫn, chúng tôi cũng trực quan hóa thống kê của các tập kiểm tra SUPERNI và LongForm, được thể hiện trong Hình 6.

B Các Template của Các Chiến lược Khác nhau
Chúng tôi thể hiện prompt tuân theo hướng dẫn của Alpaca trong Bảng 7, prompt tạo dữ liệu hướng dẫn của Alpaca trong Bảng 8, prompt tạo dữ liệu hướng dẫn của LongForm trong Bảng 9 và prompt trích xuất LLM trong Bảng 10.

Hình 6: 20 động từ gốc phổ biến nhất (vòng tròn trong) và 4 tân ngữ trực tiếp danh từ hàng đầu (vòng tròn ngoài) trong hướng dẫn được tạo ra từ: (a) Tập kiểm tra SUPERNI; (b) Tập kiểm tra LongForm.

Bảng 7: Prompt tuân theo hướng dẫn của Alpaca.

Hướng dẫn với Đầu vào
Dưới đây là một hướng dẫn mô tả một nhiệm vụ, được ghép nối với một đầu vào cung cấp thêm ngữ cảnh. Viết một phản hồi hoàn thành yêu cầu một cách thích hợp.
### Hướng dẫn:
{{ instruction }}
### Đầu vào:
{{input}}
### Phản hồi:

Hướng dẫn không có Đầu vào
Dưới đây là một hướng dẫn mô tả một nhiệm vụ. Viết một phản hồi hoàn thành yêu cầu một cách thích hợp.
### Hướng dẫn:
{{ instruction }}
### Phản hồi:

Bảng 8: Prompt tạo dữ liệu hướng dẫn của Alpaca.

Meta Prompt Tạo Dữ liệu Hướng dẫn
Bạn được yêu cầu đưa ra một tập hợp 20 hướng dẫn nhiệm vụ đa dạng. Các hướng dẫn nhiệm vụ này sẽ được đưa cho một mô hình GPT và chúng tôi sẽ đánh giá mô hình GPT về việc hoàn thành các hướng dẫn.
Đây là các yêu cầu:
1. Cố gắng không lặp lại động từ cho mỗi hướng dẫn để tối đa hóa tính đa dạng.
2. Ngôn ngữ được sử dụng cho hướng dẫn cũng nên đa dạng. Ví dụ, bạn nên kết hợp các câu hỏi với các hướng dẫn mệnh lệnh.
3. Loại hướng dẫn nên đa dạng. Danh sách nên bao gồm các loại nhiệm vụ đa dạng như tạo sinh mở, phân loại, chỉnh sửa, v.v.
4. Một mô hình ngôn ngữ GPT nên có thể hoàn thành hướng dẫn. Ví dụ, không yêu cầu trợ lý tạo ra bất kỳ đầu ra hình ảnh hoặc âm thanh nào. Ví dụ khác, không yêu cầu trợ lý đánh thức bạn lúc 5 giờ chiều hoặc đặt lời nhắc vì nó không thể thực hiện bất kỳ hành động nào.
5. Các hướng dẫn nên bằng tiếng Anh.
6. Các hướng dẫn nên dài từ 1 đến 2 câu. Câu mệnh lệnh hoặc câu hỏi đều được phép.
7. Bạn nên tạo ra một đầu vào thích hợp cho hướng dẫn. Trường đầu vào nên chứa một ví dụ cụ thể được cung cấp cho hướng dẫn. Nó nên liên quan đến dữ liệu thực tế và không nên chứa các placeholder đơn giản. Đầu vào nên cung cấp nội dung đáng kể để làm cho hướng dẫn thách thức nhưng lý tưởng nhất là không vượt quá 100 từ.
8. Không phải tất cả các hướng dẫn đều yêu cầu đầu vào. Ví dụ, khi một hướng dẫn hỏi về một số thông tin chung, "đỉnh cao nhất trên thế giới là gì", không cần thiết phải cung cấp một ngữ cảnh cụ thể. Trong trường hợp này, chúng tôi đơn giản đặt "<noinput>" trong trường đầu vào.
9. Đầu ra nên là một phản hồi thích hợp cho hướng dẫn và đầu vào. Đảm bảo đầu ra ít hơn 100 từ.

Danh sách 20 nhiệm vụ:
1. Hướng dẫn:
{instruction_example1}
1. Đầu vào:
{input_example1}
1. Đầu ra:
{output_example1}
2. Hướng dẫn:
{instruction_example2}
2. Đầu vào:
{input_example2}
2. Đầu ra:
{output_example2}
3. Hướng dẫn:
{instruction_example3}
3. Đầu vào:
{input_example3}
3. Đầu ra:
{output_example3}
4. Hướng dẫn:

Bảng 9: Prompt tạo dữ liệu hướng dẫn của LongForm.

Template cho Phong cách Hướng dẫn
Hướng dẫn: X
Đầu ra: <corpus_example>
Loại hướng dẫn nào có thể có đây là câu trả lời?
X:

Template cho Phong cách Chatbot Không chính thức
Bạn là một chatbot. Một người dùng đã gửi cho bạn một tin nhắn không chính thức và phản hồi của bạn như sau.
Tin nhắn: X
Phản hồi: <corpus_example>
Tin nhắn không chính thức X là gì?
X:

Template cho Phong cách Công cụ Tìm kiếm/truy vấn
Bạn là một công cụ tìm kiếm. Một người đã truy vấn một cái gì đó chi tiết và tài liệu liên quan nhất về truy vấn như sau.
Truy vấn: X
Tài liệu: <corpus_example>
Truy vấn chi tiết X là gì?
X:

Bảng 10: Prompt trích xuất LLM.

Dưới đây là một hướng dẫn mô tả một nhiệm vụ, được ghép nối với một đầu vào cung cấp thêm ngữ cảnh. Viết một phản hồi hoàn thành yêu cầu một cách thích hợp.
### Hướng dẫn:
Chọn các đoạn chủ chốt từ bài viết được cung cấp dưới đây.
### Đầu vào:
{{input}}
### Phản hồi:

# 2306.04751.pdf
# ÄÆ°á»£c chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/instruct/2306.04751.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 1583165 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================

--- TRANG 1 ---
Láº¡c Ä‘Ã  cÃ³ thá»ƒ Ä‘i xa Ä‘áº¿n Ä‘Ã¢u? KhÃ¡m phÃ¡ tÃ¬nh tráº¡ng
Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n trÃªn cÃ¡c tÃ i nguyÃªn má»Ÿ

Yizhong Wangâˆ—â™£â™ Hamish Ivisonâˆ—â™£Pradeep Dasigiâ™£Jack Hesselâ™£
Tushar Khotâ™£Khyathi Raghavi Chanduâ™£David Waddenâ™£Kelsey MacMillanâ™£
Noah A. Smithâ™£â™ Iz Beltagyâ™£Hannaneh Hajishirziâ™£â™ 
â™£Allen Institute for AIâ™ University of Washington
{yizhongw,hamishi}@allenai.org

TÃ³m táº¯t
Trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i khÃ¡m phÃ¡ nhá»¯ng tiáº¿n bá»™ gáº§n Ä‘Ã¢y trong viá»‡c Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ trÃªn má»™t loáº¡t cÃ¡c táº­p dá»¯ liá»‡u tuÃ¢n theo hÆ°á»›ng dáº«n má»Ÿ. Máº·c dÃ¹ cÃ¡c tuyÃªn bá»‘ gáº§n Ä‘Ã¢y ráº±ng cÃ¡c mÃ´ hÃ¬nh má»Ÿ cÃ³ thá»ƒ ngang báº±ng vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘á»™c quyá»n tiÃªn tiáº¿n, nhá»¯ng tuyÃªn bá»‘ nÃ y thÆ°á»ng Ä‘i kÃ¨m vá»›i Ä‘Ã¡nh giÃ¡ háº¡n cháº¿, khiáº¿n viá»‡c so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh trÃªn toÃ n bá»™ pháº¡m vi vÃ  xÃ¡c Ä‘á»‹nh tÃ­nh há»¯u Ã­ch cá»§a cÃ¡c tÃ i nguyÃªn khÃ¡c nhau trá»Ÿ nÃªn khÃ³ khÄƒn. ChÃºng tÃ´i cung cáº¥p má»™t táº­p há»£p lá»›n cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n tá»« 6.7B Ä‘áº¿n 65B tham sá»‘ vá» kÃ­ch thÆ°á»›c, Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn 12 táº­p dá»¯ liá»‡u hÆ°á»›ng dáº«n tá»« Ä‘Æ°á»£c tuyá»ƒn chá»n thá»§ cÃ´ng (vÃ­ dá»¥: OpenAssistant) Ä‘áº¿n tá»•ng há»£p vÃ  chÆ°ng cáº¥t (vÃ­ dá»¥: Alpaca) vÃ  Ä‘Ã¡nh giÃ¡ cÃ³ há»‡ thá»‘ng chÃºng vá» kiáº¿n thá»©c thá»±c táº¿, lÃ½ luáº­n, Ä‘a ngÃ´n ngá»¯, láº­p trÃ¬nh, an toÃ n, vÃ  kháº£ nÄƒng tuÃ¢n theo hÆ°á»›ng dáº«n má»Ÿ thÃ´ng qua má»™t táº­p há»£p cÃ¡c chá»‰ sá»‘ tá»± Ä‘á»™ng, dá»±a trÃªn mÃ´ hÃ¬nh vÃ  dá»±a trÃªn con ngÆ°á»i. ChÃºng tÃ´i tiáº¿p tá»¥c giá»›i thiá»‡u TÃœLU, bá»™ mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n cÃ³ hiá»‡u suáº¥t tá»‘t nháº¥t cá»§a chÃºng tÃ´i Ä‘Æ°á»£c tinh chá»‰nh trÃªn sá»± káº¿t há»£p cá»§a cÃ¡c tÃ i nguyÃªn má»Ÿ cháº¥t lÆ°á»£ng cao.

CÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i cho tháº¥y ráº±ng cÃ¡c táº­p dá»¯ liá»‡u Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n khÃ¡c nhau cÃ³ thá»ƒ khÃ¡m phÃ¡ hoáº·c tÄƒng cÆ°á»ng cÃ¡c ká»¹ nÄƒng cá»¥ thá»ƒ, trong khi khÃ´ng cÃ³ táº­p dá»¯ liá»‡u Ä‘Æ¡n láº» nÃ o (hoáº·c sá»± káº¿t há»£p) cung cáº¥p hiá»‡u suáº¥t tá»‘t nháº¥t trÃªn táº¥t cáº£ cÃ¡c Ä‘Ã¡nh giÃ¡. ThÃº vá»‹ lÃ  chÃºng tÃ´i tháº¥y ráº±ng cÃ¡c Ä‘Ã¡nh giÃ¡ dá»±a trÃªn mÃ´ hÃ¬nh vÃ  sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i khÃ´ng pháº£n Ã¡nh Ä‘Æ°á»£c sá»± khÃ¡c biá»‡t trong kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh Ä‘Æ°á»£c tiáº¿t lá»™ bá»Ÿi cÃ¡c Ä‘Ã¡nh giÃ¡ dá»±a trÃªn benchmark, gá»£i Ã½ vá» nhu cáº§u cho loáº¡i Ä‘Ã¡nh giÃ¡ cÃ³ há»‡ thá»‘ng Ä‘Æ°á»£c thá»±c hiá»‡n trong cÃ´ng trÃ¬nh nÃ y. CÃ¡c Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i cho tháº¥y ráº±ng mÃ´ hÃ¬nh tá»‘t nháº¥t trong báº¥t ká»³ Ä‘Ã¡nh giÃ¡ nÃ o Ä‘áº¡t trung bÃ¬nh 87% hiá»‡u suáº¥t cá»§a ChatGPT, vÃ  73% hiá»‡u suáº¥t cá»§a GPT-4, gá»£i Ã½ ráº±ng cáº§n Ä‘áº§u tÆ° thÃªm vÃ o viá»‡c xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ tá»‘t hÆ¡n vÃ  dá»¯ liá»‡u Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n Ä‘á»ƒ thu háº¹p khoáº£ng cÃ¡ch. ChÃºng tÃ´i phÃ¡t hÃ nh cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n cá»§a mÃ¬nh, bao gá»“m má»™t TÃœLU 65B Ä‘Æ°á»£c tinh chá»‰nh Ä‘áº§y Ä‘á»§, cÃ¹ng vá»›i mÃ£, dá»¯ liá»‡u vÃ  khung Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i Ä‘á»ƒ há»— trá»£ nghiÃªn cá»©u tÆ°Æ¡ng lai.

1 Giá»›i thiá»‡u
Tháº¿ há»‡ mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n má»›i nháº¥t Ä‘Ã£ mang láº¡i sá»± chÃº Ã½ chÆ°a tá»«ng cÃ³ Ä‘áº¿n tiá»m nÄƒng cá»§a cÃ¡c cÃ´ng nghá»‡ ngÃ´n ngá»¯. Äá»ƒ há»— trá»£ cÃ¡c yÃªu cáº§u cáº¥p thiáº¿t cá»§a ngÆ°á»i dÃ¹ng vÃ  giao diá»‡n trÃ² chuyá»‡n, cÃ¡c mÃ´ hÃ¬nh nÃ y thÆ°á»ng tráº£i qua má»™t bÆ°á»›c Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n bao gá»“m huáº¥n luyá»‡n trÃªn cÃ¡c cáº·p Ä‘áº§u vÃ o/Ä‘áº§u ra Ä‘Æ°á»£c giÃ¡m sÃ¡t. CÃ¡c táº­p dá»¯ liá»‡u Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n gáº§n Ä‘Ã¢y thÆ°á»ng Ä‘Æ°á»£c thu tháº­p thÃ´ng qua crowdsourcing (Dolly [12], OpenAssistant [26]) hoáº·c thÃ´ng qua chÆ°ng cáº¥t tá»« má»™t mÃ´ hÃ¬nh khÃ¡c (Alpaca [43], Vicuna [8]). Tuy nhiÃªn, trong khi má»™t sá»‘ mÃ´ hÃ¬nh cÃ´ng khai Ä‘Æ°á»£c Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n Ä‘Æ°á»£c quáº£ng cÃ¡o lÃ  cÃ³ thá»ƒ so sÃ¡nh vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘á»™c quyá»n nguá»“n Ä‘Ã³ng máº¡nh máº½ nhÆ° ChatGPT, háº§u háº¿t cÃ¡c thÃ­ nghiá»‡m há»— trá»£ nhá»¯ng tuyÃªn bá»‘ nhÆ° váº­y chá»‰ bao gá»“m má»™t táº­p há»£p nhá» cÃ¡c nhiá»‡m vá»¥ vÃ  chá»§ yáº¿u dá»±a vÃ o cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ dá»±a trÃªn mÃ´ hÃ¬nh [8,56]. ChÃºng tÃ´i cho ráº±ng thiáº¿t láº­p Ä‘Ã¡nh giÃ¡ nÃªn

âˆ—ÄÃ³ng gÃ³p báº±ng nhau.
Â²https://github.com/allenai/open-instruct

Há»™i nghá»‹ láº§n thá»© 37 vá» Há»‡ thá»‘ng xá»­ lÃ½ thÃ´ng tin tháº§n kinh (NeurIPS 2023) ChuyÃªn má»¥c vá» Táº­p dá»¯ liá»‡u vÃ  Benchmark. arXiv:2306.04751v2 [cs.CL] 30 ThÃ¡ng 10 2023

--- TRANG 2 ---
bao gá»“m cÃ¡c nhiá»‡m vá»¥ kiá»ƒm tra cÃ¡c ká»¹ nÄƒng lÃ½ luáº­n cá»‘t lÃµi vÃ  kháº£ nÄƒng nhá»› láº¡i sá»± kiá»‡n cá»§a mÃ´ hÃ¬nh, ngoÃ i viá»‡c kiá»ƒm tra cháº¥t lÆ°á»£ng sinh ra Ä‘Æ°á»£c chÃº thÃ­ch bá»Ÿi mÃ´ hÃ¬nh hoáº·c con ngÆ°á»i, cÃ³ thá»ƒ má»Ÿ hÆ¡n vÃ  chá»§ quan hÆ¡n.

BÃ i bÃ¡o nÃ y cung cáº¥p má»™t Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n vá» cÃ¡c tÃ i nguyÃªn Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n: cá»¥ thá»ƒ, chÃºng tÃ´i thá»±c hiá»‡n má»™t sá»‘ lÆ°á»£ng lá»›n cÃ¡c thÃ­ nghiá»‡m Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n tráº£i rá»™ng má»™t tÃ¡ táº­p dá»¯ liá»‡u cÃ´ng khai, vÃ  cÃ¡c mÃ´ hÃ¬nh cÃ³ quy mÃ´ tá»« 6.7B Ä‘áº¿n 65B. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ cáº£ cÃ¡c kháº£ nÄƒng mÃ´ hÃ¬nh cá»¥ thá»ƒ (tá»©c lÃ  kiáº¿n thá»©c thá»±c táº¿, lÃ½ luáº­n, Ä‘a ngÃ´n ngá»¯, láº­p trÃ¬nh, an toÃ n) vÃ  kháº£ nÄƒng tuÃ¢n theo hÆ°á»›ng dáº«n má»Ÿ.

ChÃºng tÃ´i bÃ¡o cÃ¡o káº¿t quáº£ dá»±a trÃªn cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng, dá»±a trÃªn mÃ´ hÃ¬nh vÃ  dá»±a trÃªn con ngÆ°á»i.

ÄÃ¡nh giÃ¡ cá»§a chÃºng tÃ´i tiáº¿t lá»™ ráº±ng Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n trÃªn cÃ¡c táº­p dá»¯ liá»‡u khÃ¡c nhau dÆ°á»ng nhÆ° thÃºc Ä‘áº©y cÃ¡c ká»¹ nÄƒng cá»¥ thá»ƒ, vÃ  khÃ´ng cÃ³ táº­p dá»¯ liá»‡u nÃ o cung cáº¥p hiá»‡u suáº¥t tá»‘t nháº¥t trÃªn táº¥t cáº£ cÃ¡c Ä‘Ã¡nh giÃ¡. ChÃºng tÃ´i cÅ©ng tháº¥y ráº±ng mÃ´ hÃ¬nh cÆ¡ sá»Ÿ bÃªn dÆ°á»›i lÃ  tá»‘i quan trá»ng, vá»›i cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ tá»‘t hÆ¡n (dÃ¹ lÃ  cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn nhiá»u token hÆ¡n hay cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n) thá»±c hiá»‡n tá»‘t hÆ¡n trÃªn toÃ n bá»™ pháº¡m vi. ÄÃ¡ng ngáº¡c nhiÃªn lÃ  chÃºng tÃ´i cÅ©ng tháº¥y ráº±ng cÃ¡c mÃ´ hÃ¬nh cÃ³ hiá»‡u suáº¥t tá»‘t nháº¥t trong Ä‘Ã¡nh giÃ¡ dá»±a trÃªn mÃ´ hÃ¬nh khÃ´ng giá»‘ng vá»›i nhá»¯ng mÃ´ hÃ¬nh thá»±c hiá»‡n tá»‘t nháº¥t trÃªn cÃ¡c Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng dá»±a trÃªn benchmark, cÃ³ thá»ƒ má»™t pháº§n do sá»± thiÃªn vá»‹ máº¡nh máº½ cá»§a GPT-4 Ä‘á»‘i vá»›i cÃ¡c tháº¿ há»‡ dÃ i, Ä‘a dáº¡ng.

Dá»±a trÃªn cÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i, chÃºng tÃ´i giá»›i thiá»‡u TÃœLU, má»™t bá»™ mÃ´ hÃ¬nh LLAMA tá»« 7B Ä‘áº¿n 65B Ä‘Æ°á»£c tinh chá»‰nh trÃªn sá»± káº¿t há»£p cá»§a cÃ¡c nguá»“n dá»¯ liá»‡u. TÃœLU 65B lÃ  biáº¿n thá»ƒ LLAMA Ä‘Æ°á»£c Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n Ä‘áº§y Ä‘á»§ lá»›n nháº¥t Ä‘Æ°á»£c phÃ¡t hÃ nh cÃ´ng khai vÃ o thá»i Ä‘iá»ƒm viáº¿t, theo hiá»ƒu biáº¿t tá»‘t nháº¥t cá»§a cÃ¡c tÃ¡c giáº£. NÃ³ Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn 7 táº­p dá»¯ liá»‡u phá»• biáº¿n cÃ³ sáºµn, vÃ  cho káº¿t quáº£ hiá»‡u suáº¥t trung bÃ¬nh tá»‘t nháº¥t trÃªn háº§u háº¿t cÃ¡c kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh trong khi váº«n duy trÃ¬ trong vÃ²ng 29% cá»§a mÃ´ hÃ¬nh cÃ³ hiá»‡u suáº¥t tá»‘t nháº¥t trÃªn tá»«ng nhiá»‡m vá»¥ riÃªng láº». TÃ³m láº¡i, cÃ¡c phÃ¡t hiá»‡n chÃ­nh cá»§a chÃºng tÃ´i bao gá»“m:

â€¢ CÃ¡c táº­p dá»¯ liá»‡u hÆ°á»›ng dáº«n nháº¯m má»¥c tiÃªu vÃ o cÃ¡c miá»n vÃ /hoáº·c kháº£ nÄƒng cá»¥ thá»ƒ cá»±c ká»³ hiá»‡u quáº£ trong viá»‡c cáº£i thiá»‡n hiá»‡u suáº¥t mÃ´ hÃ¬nh trong nhá»¯ng khÃ­a cáº¡nh Ä‘Ã³.
â€¢ CÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ lá»›n hÆ¡n hoáº·c Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c lÃ¢u hÆ¡n luÃ´n thá»±c hiá»‡n tá»‘t hÆ¡n so vá»›i cÃ¡c mÃ´ hÃ¬nh nhá» hÆ¡n sau khi Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n.
â€¢ MÃ´ hÃ¬nh TÃœLU cá»§a chÃºng tÃ´i - LLaMa Ä‘Æ°á»£c tinh chá»‰nh trÃªn sá»± káº¿t há»£p cá»§a cÃ¡c táº­p dá»¯ liá»‡u hÆ°á»›ng dáº«n hiá»‡n cÃ³ - Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t trung bÃ¬nh tá»‘t nháº¥t trÃªn cÃ¡c benchmark, máº·c dÃ¹ nÃ³ khÃ´ng pháº£i lÃ  tá»‘t nháº¥t tá»•ng thá»ƒ khi xem xÃ©t cÃ¡c thiáº¿t láº­p Ä‘Ã¡nh giÃ¡ khÃ¡c nhau má»™t cÃ¡ch Ä‘á»™c láº­p.
â€¢ Ngay cáº£ má»™t mÃ´ hÃ¬nh ráº¥t lá»›n (65B) Ä‘Æ°á»£c tinh chá»‰nh trÃªn má»™t há»—n há»£p lá»›n cÃ¡c táº­p dá»¯ liá»‡u hÆ°á»›ng dáº«n cÅ©ng khÃ´ng thá»ƒ vÆ°á»£t qua ChatGPT, máº·c dÃ¹ nÃ³ thá»±c hiá»‡n tá»‘t hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c mÃ´ hÃ¬nh nhá» hÆ¡n tÆ°Æ¡ng tá»±.
â€¢ ÄÃ¡nh giÃ¡ sá»Ÿ thÃ­ch dá»±a trÃªn mÃ´ hÃ¬nh vá» viá»‡c tuÃ¢n theo hÆ°á»›ng dáº«n má»Ÿ cÃ³ tÆ°Æ¡ng quan máº¡nh máº½ vá»›i sá»‘ lÆ°á»£ng token duy nháº¥t trung bÃ¬nh Ä‘Æ°á»£c táº¡o ra bá»Ÿi má»™t mÃ´ hÃ¬nh, gá»£i Ã½ ráº±ng Ä‘Ã¡nh giÃ¡ sá»Ÿ thÃ­ch dá»±a trÃªn mÃ´ hÃ¬nh cÃ³ sá»± thiÃªn vá»‹ cÃ³ thá»ƒ che giáº¥u sá»± khÃ¡c biá»‡t trong kháº£ nÄƒng mÃ´ hÃ¬nh.

ChÃºng tÃ´i má»Ÿ mÃ£ nguá»“n cho viá»‡c huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n nÃ y. ChÃºng tÃ´i cÅ©ng phÃ¡t hÃ nh cÃ¡c checkpoint Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c táº­p dá»¯ liá»‡u hÆ°á»›ng dáº«n khÃ¡c nhau vÃ  há»—n há»£p cá»§a chÃºng, bao gá»“m TÃœLU. ChÃºng tÃ´i hy vá»ng Ä‘iá»u nÃ y sáº½ táº¡o Ä‘iá»u kiá»‡n cho viá»‡c phÃ¡t triá»ƒn vÃ  Ä‘iá»u tra thÃªm cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n má»Ÿ.

2 Bá»‘i cáº£nh: Äiá»u chá»‰nh hÆ°á»›ng dáº«n vÃ  tÃ i nguyÃªn

2.1 Äiá»u chá»‰nh hÆ°á»›ng dáº«n

Äiá»u chá»‰nh hÆ°á»›ng dáº«n, nÃ³i chung, Ä‘á» cáº­p Ä‘áº¿n viá»‡c thá»±c hÃ nh tinh chá»‰nh cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c Ä‘á»ƒ hiá»ƒu vÃ  pháº£n há»“i tá»‘t hÆ¡n vá»›i nhiá»u yÃªu cáº§u cá»§a con ngÆ°á»i Ä‘Æ°á»£c diá»…n Ä‘áº¡t báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn [32,49,35]. Äáº·c biá»‡t, Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n liÃªn quan Ä‘áº¿n cÃ¡c yÃªu cáº§u bao gá»“m má»™t sá»‘ chá»‰ dáº«n vá» nhiá»‡m vá»¥ cáº§n thá»±c hiá»‡n trong chÃ­nh yÃªu cáº§u Ä‘Ã³ (vÃ­ dá»¥: bao gá»“m hÆ°á»›ng dáº«n nhiá»‡m vá»¥ trong lá»i nháº¯c Ä‘áº§u vÃ o). NÃ³ Ä‘Ã£ ná»•i lÃªn nhÆ° má»™t bÆ°á»›c quan trá»ng Ä‘á»ƒ khÃ¡i quÃ¡t hÃ³a cÃ¡c mÃ´ hÃ¬nh cho cÃ¡c ká»‹ch báº£n má»›i mÃ  khÃ´ng cáº§n huáº¥n luyá»‡n chuyÃªn dá»¥ng, vÃ  Ä‘á»ƒ cho phÃ©p nhá»¯ng ngÆ°á»i khÃ´ng chuyÃªn tÆ°Æ¡ng tÃ¡c tá»± nhiÃªn vá»›i cÃ¡c mÃ´ hÃ¬nh nÃ y. CÃ¡c mÃ´ hÃ¬nh huáº¥n luyá»‡n cá»§a Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n cÃ³ thá»ƒ khÃ¡c nhau tá»« há»c táº­p cÃ³ giÃ¡m sÃ¡t sá»­ dá»¥ng cÃ¡c minh chá»©ng [49,39,48,31] Ä‘áº¿n há»c tÄƒng cÆ°á»ng tá»« dá»¯ liá»‡u pháº£n há»“i [35,3]. Trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i táº­p trung vÃ o thiáº¿t láº­p há»c táº­p cÃ³ giÃ¡m sÃ¡t xem xÃ©t cÃ¡c tÃ i nguyÃªn má»Ÿ hiá»‡n táº¡i cho phÆ°Æ¡ng phÃ¡p dá»±a trÃªn RL váº«n cÃ²n hiáº¿m, vÃ  chÃºng tÃ´i Ä‘á»ƒ láº¡i viá»‡c khÃ¡m phÃ¡ nÃ³ cho cÃ´ng viá»‡c tÆ°Æ¡ng lai.

ThÃ nh cÃ´ng cá»§a Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n Ä‘Ã²i há»i Ã­t nháº¥t hai thÃ nh pháº§n chÃ­nh: 1) má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c máº¡nh máº½ Ä‘Ã£ náº¯m báº¯t má»™t lÆ°á»£ng lá»›n kiáº¿n thá»©c tá»« viá»‡c huáº¥n luyá»‡n trÆ°á»›c quy mÃ´ web, vÃ  2) má»™t táº­p dá»¯ liá»‡u hÆ°á»›ng dáº«n Ä‘á»§ Ä‘a dáº¡ng vÃ  Ä‘áº¡i diá»‡n Ä‘á»ƒ Ä‘iá»u chá»‰nh LM cho viá»‡c sá»­ dá»¥ng downstream tiá»m nÄƒng. ChÃºng tÃ´i nghiÃªn cá»©u hai yáº¿u tá»‘ nÃ y trong cÃ´ng trÃ¬nh nÃ y vÃ  giá»›i thiá»‡u cÃ¡c tÃ i nguyÃªn má»Ÿ Ä‘Æ°á»£c nghiÃªn cá»©u cá»§a chÃºng tÃ´i dÆ°á»›i Ä‘Ã¢y.

--- TRANG 3 ---
Báº£ng 1: CÃ¡c táº­p dá»¯ liá»‡u hÆ°á»›ng dáº«n Ä‘Æ°á»£c Ä‘iá»u tra trong cÃ´ng trÃ¬nh nÃ y. CoT vÃ  FLAN V2 Ä‘Æ°á»£c láº¥y máº«u Ä‘áº¿n 100K Ä‘á»ƒ phÃ¹ há»£p vá»›i kÃ­ch thÆ°á»›c cá»§a cÃ¡c táº­p dá»¯ liá»‡u khÃ¡c. ChÃºng tÃ´i bÃ¡o cÃ¡o sá»‘ lÆ°á»£ng vÃ²ng há»™i thoáº¡i trung bÃ¬nh ( Ì„ğ‘rounds), Ä‘á»™ dÃ i trung bÃ¬nh cá»§a lá»i nháº¯c ( Ì„ğ¿prompt), Ä‘á»™ dÃ i trung bÃ¬nh cá»§a hoÃ n thÃ nh ( Ì„ğ¿completion).

Táº­p dá»¯ liá»‡u | Nguá»“n tá»« | # PhiÃªn báº£n | Ì„ğ‘rounds | Ì„ğ¿prompt | Ì„ğ¿completion
SuperNI [48] | Táº­p dá»¯ liá»‡u NLP + HÆ°á»›ng dáº«n viáº¿t báº±ng tay | 96,913 | 1.0 | 291.1 | 38.7
CoT [50] | Táº­p dá»¯ liá»‡u NLP + CoT viáº¿t báº±ng tay | 100,000 | 1.0 | 266.0 | 53.2
Flan V2 [31] | Táº­p dá»¯ liá»‡u NLP + HÆ°á»›ng dáº«n viáº¿t báº±ng tay | 100,000 | 1.0 | 355.7 | 31.2
Dolly [12] | Viáº¿t báº±ng tay tá»« Ä‘áº§u | 15,011 | 1.0 | 118.1 | 91.3
Open Assistant 1 [26] | Viáº¿t báº±ng tay tá»« Ä‘áº§u | 34,795 | 1.6 | 34.8 | 212.5
Self-instruct [47] | Táº¡o vá»›i GPT3 LM vanilla | 82,439 | 1.0 | 41.5 | 29.3
Unnatural Instructions [23] | Táº¡o vá»›i Davinci-002 | 68,478 | 1.0 | 107.8 | 23.6
Alpaca [43] | Táº¡o vá»›i Davinci-003 | 52,002 | 1.0 | 27.8 | 64.6
Code-Alpaca [6] | Táº¡o vá»›i Davinci-003 | 20,022 | 1.0 | 35.6 | 67.8
GPT4-Alpaca [36] | Táº¡o vá»›i Davinci-003 + GPT4 | 52,002 | 1.0 | 28.0 | 161.8
Baize [52] | Táº¡o vá»›i ChatGPT | 210,311 | 3.1 | 17.6 | 52.8
ShareGPTÂ³ | Lá»i nháº¯c ngÆ°á»i dÃ¹ng + Ä‘áº§u ra tá»« cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau | 168,864 | 3.2 | 71.0 | 357.8

2.2 Táº­p dá»¯ liá»‡u hÆ°á»›ng dáº«n

ChÃºng tÃ´i cá»‘ gáº¯ng thu tháº­p má»™t máº«u Ä‘áº¡i diá»‡n cá»§a cÃ¡c kiá»ƒu táº­p dá»¯ liá»‡u khÃ¡c nhau (Ä‘Æ°á»£c liá»‡t kÃª trong Báº£ng 1), bao gá»“m cÃ¡c táº­p dá»¯ liá»‡u: (1) Ä‘Æ°á»£c táº¡o bá»Ÿi cÃ¡c nhÃ  nghiÃªn cá»©u tá»« cÃ¡c táº­p dá»¯ liá»‡u NLP hiá»‡n cÃ³ (SuperNI [48], Flan V2 [31]); (2) Ä‘Æ°á»£c viáº¿t bá»Ÿi con ngÆ°á»i tá»« Ä‘áº§u cho má»¥c Ä‘Ã­ch Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n (Dolly [12], OpenAssistant1 [26]); (3) Ä‘Æ°á»£c táº¡o bá»Ÿi cÃ¡c mÃ´ hÃ¬nh Ä‘á»™c quyá»n (Self-Instruct [47], UnnaturalInstructions [23], Alpaca [43], Baize [52], GPT4-Alpaca [36]); (4) bao gá»“m cÃ¡c lá»i nháº¯c do ngÆ°á»i dÃ¹ng chia sáº» kÃ¨m theo cÃ¡c hoÃ n thÃ nh Ä‘Æ°á»£c táº¡o bá»Ÿi mÃ´ hÃ¬nh (ShareGPTÂ³[8]); (5) Ä‘Æ°á»£c xÃ¢y dá»±ng cho cÃ¡c ká»¹ nÄƒng cá»¥ thá»ƒ (CoT [50] cho chuá»—i suy nghÄ©, Code-Alpaca [6] cho táº¡o mÃ£). Xem Phá»¥ lá»¥c C Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

2.3 CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c

Báº£ng 2: CÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ mÃ  chÃºng tÃ´i Ä‘Ã£ tinh chá»‰nh trong cÃ´ng trÃ¬nh nÃ y.

MÃ´ hÃ¬nh LM cÆ¡ sá»Ÿ | # Tham sá»‘ | # Token
LLaMa [44] | 6.7B | 1.0T
 | 13.0B | 1.0T
 | 32.5B | 1.4T
 | 65.2B | 1.4T
LLaMa-2 [45] | 6.7B | 2.0T
 | 13.0B | 2.0T
OPT [54] | 6.7B | 180B
Pythia [4] | 6.9B | 300B

ChÃºng tÃ´i chá»§ yáº¿u sá»­ dá»¥ng bá»™ LLAMA [44,45], má»™t loáº¡t cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c cÃ³ kÃ­ch thÆ°á»›c tá»« 6.7B Ä‘áº¿n 65B tham sá»‘. ChÃºng tÃ´i ban Ä‘áº§u thá»­ nghiá»‡m vá»›i cÃ¡c mÃ´ hÃ¬nh LLAMA-1 cho phiÃªn báº£n Ä‘áº§u tiÃªn cá»§a bÃ i bÃ¡o nÃ y vÃ  bá»• sung LLAMA-2 trong báº£n camera ready, sá»­ dá»¥ng sá»‘ lÆ°á»£ng tham sá»‘ tÆ°Æ¡ng tá»± nhÆ°ng Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn nhiá»u token hÆ¡n Ä‘Ã¡ng ká»ƒ. CÃ¡c mÃ´ hÃ¬nh nÃ y Ä‘áº¡i diá»‡n cho cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c lá»›n nháº¥t, cháº¥t lÆ°á»£ng cao nháº¥t cÃ³ sáºµn cho cá»™ng Ä‘á»“ng (máº·c dÃ¹ dÆ°á»›i giáº¥y phÃ©p háº¡n cháº¿). ChÃºng tÃ´i cÅ©ng xem xÃ©t cÃ¡c mÃ´ hÃ¬nh OPT [54] vÃ  Pythia [4] vá»›i kÃ­ch thÆ°á»›c tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i mÃ´ hÃ¬nh LLAMA 6.7B, Ä‘á»ƒ kiá»ƒm tra tÃ¡c Ä‘á»™ng cá»§a cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ khÃ¡c nhau. Äá»ƒ Ä‘Æ¡n giáº£n, chÃºng tÃ´i sáº½ lÃ m trÃ²n táº¥t cáº£ kÃ­ch thÆ°á»›c vá» sá»‘ nguyÃªn gáº§n nháº¥t. ChÃºng tÃ´i lÆ°u Ã½ má»™t sá»‘ ná»— lá»±c Ä‘ang diá»…n ra Ä‘á»ƒ huáº¥n luyá»‡n trÆ°á»›c cÃ¡c mÃ´ hÃ¬nh cÃ³ cháº¥t lÆ°á»£ng tÆ°Æ¡ng tá»± hoáº·c tá»‘t hÆ¡n [18,33,1]. ChÃºng tÃ´i tin ráº±ng cÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i nÃªn Ã¡p dá»¥ng cho cÃ¡c mÃ´ hÃ¬nh nÃ y vÃ  cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ má»Ÿ máº¡nh máº½ hÆ¡n trong tÆ°Æ¡ng lai.

3 Huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i cÃ¡c táº­p dá»¯ liá»‡u khÃ¡c nhau

3.1 Thá»‘ng nháº¥t Ä‘á»‹nh dáº¡ng

ChÃºng tÃ´i Ä‘á»‹nh dáº¡ng táº¥t cáº£ cÃ¡c táº­p dá»¯ liá»‡u Ä‘á»ƒ tuÃ¢n theo lÆ°á»£c Ä‘á»“ kiá»ƒu chatbot Ä‘á»ƒ thá»‘ng nháº¥t cÃ¡c kiá»ƒu vÃ  Ä‘á»‹nh dáº¡ng Ä‘a dáº¡ng cá»§a cÃ¡c táº­p dá»¯ liá»‡u hÆ°á»›ng dáº«n, Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 1. Äiá»u nÃ y cho phÃ©p chÃºng tÃ´i khá»›p cÃ¡c vÃ²ng tÆ°Æ¡ng tÃ¡c tÃ¹y Ã½ giá»¯a ngÆ°á»i dÃ¹ng vÃ  mÃ´ hÃ¬nh ngÃ´n ngá»¯ (tá»©c lÃ  "trá»£ lÃ½") thÃ nh má»™t chuá»—i Ä‘áº§u vÃ o vÃ  mÃ£ hÃ³a chÃºng cÃ¹ng nhau vá»›i má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÃ¢n quáº£. ChÃºng tÃ´i thÃªm cÃ¡c token Ä‘áº·c biá»‡t <|user|> vÃ  <|assistant|> trÆ°á»›c cÃ¡c phÃ¡t biá»ƒu cá»§a ngÆ°á»i dÃ¹ng vÃ  pháº£n há»“i má»¥c tiÃªu cá»§a trá»£ lÃ½ tÆ°Æ¡ng á»©ng, vÃ  má»™t Ä‘Ã¡nh dáº¥u káº¿t thÃºc vÄƒn báº£n </s> á»Ÿ cuá»‘i má»—i Ä‘áº§u ra cá»§a trá»£ lÃ½, mÃ  táº¡i thá»i Ä‘iá»ƒm suy luáº­n, sáº½ dá»«ng pháº£n há»“i cá»§a mÃ´ hÃ¬nh cho má»—i vÃ²ng.

Â³ Dá»¯ liá»‡u ShareGPT (https://sharegpt.com/) Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh Vicuna [8], nhÆ°ng táº­p dá»¯ liá»‡u chÃ­nh xÃ¡c chÆ°a Ä‘Æ°á»£c phÃ¡t hÃ nh. Thay vÃ o Ä‘Ã³, chÃºng tÃ´i sá»­ dá»¥ng phiÃªn báº£n tÃ¡i táº¡o tá»« https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/tree/main/HTML_cleaned_raw_dataset, vÃ  tuÃ¢n theo Vicuna Ä‘á»ƒ chia cÃ¡c cuá»™c há»™i thoáº¡i dÃ i thÃ nh cÃ¡c khá»‘i vá»›i Ä‘á»™ dÃ i tá»‘i Ä‘a 2048 token.

--- TRANG 4 ---
3.2 Chi tiáº¿t huáº¥n luyá»‡n mÃ´ hÃ¬nh

<|assistant|>Há»‡ thá»‘ng Ä‘iá»u khiá»ƒn pháº£n lá»±c (RCS) trÃªn TÃ u vÅ© trá»¥ Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cÃ³ kháº£ nÄƒng chá»‹u lá»—i, cÃ³ nghÄ©a lÃ  nÃ³ cÃ³ thá»ƒ tiáº¿p tá»¥c hoáº¡t Ä‘á»™ng ngay cáº£ khi má»™t hoáº·c nhiá»u thÃ nh pháº§n cá»§a nÃ³ bá»‹ há»ng. RCS bao gá»“m hai bá»™...</s><|assistant|>CÃ³ má»™t sá»‘ trÆ°á»ng há»£p mÃ  há»‡ thá»‘ng Ä‘iá»u khiá»ƒn pháº£n lá»±c (RCS) trÃªn TÃ u vÅ© trá»¥ gáº·p pháº£i lá»—i hoáº·c trá»¥c tráº·c trong cÃ¡c nhiá»‡m vá»¥ trÃªn quá»¹ Ä‘áº¡o. Nhá»¯ng...</s><|user|>Giáº£i thÃ­ch kháº£ nÄƒng chá»‹u lá»—i cá»§a há»‡ thá»‘ng Ä‘iá»u khiá»ƒn pháº£n lá»±c trÃªn TÃ u vÅ© trá»¥.
<|user|>RCS cÃ³ gáº·p pháº£i lá»—i trÃªn quá»¹ Ä‘áº¡o nÃ o khÃ´ng?

ğŸ‘±
ğŸ‘±
ğŸ¤–
ğŸ¤–

HÃ¬nh 1: Má»™t vÃ­ dá»¥ tá»« dá»¯ liá»‡u ShareGPT. ChÃºng tÃ´i sá»­ dá»¥ng <|role|> Ä‘á»ƒ Ä‘áº·t ranh giá»›i giá»¯a cÃ¡c tin nháº¯n. ToÃ n bá»™ chuá»—i Ä‘Æ°á»£c mÃ£ hÃ³a cÃ¹ng nhau, vÃ  máº¥t mÃ¡t Ä‘Æ°á»£c tÃ­nh toÃ¡n trÃªn cÃ¡c pháº§n trá»£ lÃ½ (Ä‘Æ°á»£c tÃ´ mÃ u xanh).

Trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, chÃºng tÃ´i chá»‰ tÃ­nh toÃ¡n máº¥t mÃ¡t trÃªn cÃ¡c token sau <|assistant|> vÃ  trÆ°á»›c token <|user|> tiáº¿p theo. ChÃ­nh thá»©c hÆ¡n, chÃºng tÃ´i xem xÃ©t má»™t táº­p dá»¯ liá»‡u hÆ°á»›ng dáº«n bao gá»“m ğ‘ tuple, má»—i tuple cÃ³ ğ‘– lÆ°á»£t, {(ğ‘¥ğ‘—â‚,ğ‘¦ğ‘—â‚,ğ‘¥ğ‘—â‚‚,ğ‘¦ğ‘—â‚‚,...ğ‘¥ğ‘—áµ¢,ğ‘¦ğ‘—áµ¢)}á´ºâ±¼â‚Œâ‚, trong Ä‘Ã³ ğ‘¥áµ¢ lÃ  lá»i nháº¯c cá»§a ngÆ°á»i dÃ¹ng vÃ  ğ‘¦áµ¢ lÃ  Ä‘áº§u ra mong muá»‘n. Äá»‘i vá»›i háº§u háº¿t cÃ¡c phiÃªn báº£n, ğ‘¢ = 1, vÃ  chÃºng tÃ´i huáº¥n luyá»‡n mÃ´ hÃ¬nh Ä‘á»ƒ Ä‘Æ°a ra ğ‘¦â±¼ khi Ä‘Æ°á»£c cho ğ‘¥â±¼. Tuy nhiÃªn, trong trÆ°á»ng há»£p táº­p dá»¯ liá»‡u há»™i thoáº¡i, chÃºng tÃ´i huáº¥n luyá»‡n mÃ´ hÃ¬nh Ä‘á»ƒ dá»± Ä‘oÃ¡n ğ‘¦â±¼áµ¢ khi Ä‘Æ°á»£c cho má»™t sá»‘ lá»‹ch sá»­ há»™i thoáº¡i ğ‘¥â±¼â‚,ğ‘¦â±¼â‚,ğ‘¥â±¼â‚‚,...,ğ‘¥â±¼áµ¢. ChÃºng tÃ´i huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh chá»‰ giáº£i mÃ£ vÃ  sá»­ dá»¥ng teacher-forcing vá»›i máº·t náº¡ máº¥t mÃ¡t Ä‘á»ƒ huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh, trong Ä‘Ã³ chÃºng tÃ´i che máº·t táº¥t cáº£ cÃ¡c token thuá»™c vá» (cÃ¡c) chuá»—i Ä‘áº§u vÃ o ğ‘¥áµ¢. Vá»›i ğ‘‹ lÃ  cÃ¡c token thuá»™c vá» Ä‘áº§u vÃ o, vÃ  ğ‘Œ lÃ  cÃ¡c token má»¥c tiÃªu, hÃ m máº¥t mÃ¡t lÃ :

ğ¿ = âˆ’âˆ‘â±¼ log ğ‘Î¸(ğ‘¡â±¼|ğ‘¡<â±¼) Ã— {1 náº¿u ğ‘¡â±¼ âˆˆ ğ‘Œ, 0 náº¿u khÃ´ng}

trong Ä‘Ã³ ğ‘¡â±¼ lÃ  token Ä‘áº§u vÃ o thá»© ğ‘— (thuá»™c vá» ğ‘‹ hoáº·c ğ‘Œ). Xem Phá»¥ lá»¥c Â§D Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t huáº¥n luyá»‡n.

3.3 TÃœLU: má»™t mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n tá»‘t hÆ¡n báº±ng cÃ¡ch káº¿t há»£p tÃ i nguyÃªn

CÃ¡c nghiÃªn cá»©u hiá»‡n cÃ³ [48,31] (vÃ  Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i dÆ°á»›i Ä‘Ã¢y) Ä‘Ã£ cho tháº¥y ráº±ng viá»‡c tÄƒng tÃ­nh Ä‘a dáº¡ng cá»§a hÆ°á»›ng dáº«n cÃ³ thá»ƒ cáº£i thiá»‡n hiá»‡u quáº£ viá»‡c thá»±c hiá»‡n Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n. Theo Ä‘á»™ng lá»±c nÃ y, chÃºng tÃ´i táº¡o ra hai há»—n há»£p táº­p dá»¯ liá»‡u:

Há»—n há»£p dá»¯ liá»‡u con ngÆ°á»i, bao gá»“m cÃ¡c táº­p dá»¯ liá»‡u do con ngÆ°á»i viáº¿t tá»‘t nháº¥t, bao gá»“m FLAN V2, CoT, Dolly, vÃ  Open Assistant 1 (chÃºng tÃ´i loáº¡i trá»« SuperNI vÃ¬ FLAN V2 bao gá»“m háº§u háº¿t cÃ¡c nhiá»‡m vá»¥ trong SuperNI);

Há»—n há»£p dá»¯ liá»‡u Con ngÆ°á»i+GPT, bao gá»“m há»—n há»£p con ngÆ°á»i vÃ  ba táº­p dá»¯ liá»‡u bá»• sung cÃ³ cÃ¡c tháº¿ há»‡ bá»Ÿi cÃ¡c mÃ´ hÃ¬nh GPT cá»§a OpenAI, bao gá»“m GPT4-Alpaca, Code-Alpaca, vÃ  ShareGPT.

Äá»‘i vá»›i cáº£ hai há»—n há»£p, chÃºng tÃ´i ná»‘i cÃ¡c táº­p dá»¯ liá»‡u vÃ  Ä‘á»ƒ láº¡i viá»‡c khÃ¡m phÃ¡ cÃ¡c há»—n há»£p láº¥y máº«u phá»©c táº¡p hÆ¡n cho cÃ´ng viá»‡c tÆ°Æ¡ng lai. ChÃºng tÃ´i Ä‘áº·t tÃªn cÃ¡c mÃ´ hÃ¬nh LLAMA Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn há»—n há»£p dá»¯ liá»‡u Con ngÆ°á»i+GPT lÃ  TÃœLU, theo tÃªn má»™t loÃ i láº¡c Ä‘Ã  lai táº¡o ra tá»« viá»‡c lai táº¡o giá»¯a cÃ¡c loÃ i khÃ¡c nhau. ChÃºng tÃ´i phÃ¢n biá»‡t cÃ¡c mÃ´ hÃ¬nh TÃœLU Ä‘Æ°á»£c huáº¥n luyá»‡n tá»« cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ LLAMA-2 báº±ng cÃ¡ch Ä‘áº·t phiÃªn báº£n chÃºng lÃ  TÃœLU-1.1.

4 Thiáº¿t láº­p Ä‘Ã¡nh giÃ¡

ÄÃ¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh tuÃ¢n theo hÆ°á»›ng dáº«n váº«n lÃ  má»™t váº¥n Ä‘á» Ä‘áº§y thÃ¡ch thá»©c do pháº¡m vi rá»™ng lá»›n cá»§a "tÃ­nh tá»•ng quÃ¡t" vÃ  báº£n cháº¥t má»Ÿ cá»§a nÃ³. Tuy nhiÃªn, chÃºng tÃ´i cho ráº±ng cÃ¡c mÃ´ hÃ¬nh Ä‘a nÄƒng nÃªn cÃ³ thá»ƒ thá»±c hiá»‡n má»™t sá»‘ nhiá»‡m vá»¥ cá»‘t lÃµi trÆ°á»›c khi chÃºng cÃ³ thá»ƒ khÃ¡i quÃ¡t hÃ³a Ä‘á»ƒ thá»a mÃ£n cÃ¡c nhu cáº§u thá»±c táº¿ khÃ¡c nhau. NhÆ° váº­y, chÃºng tÃ´i thiáº¿t láº­p má»™t Ä‘Ã¡nh giÃ¡ Ä‘a máº·t Ä‘á»ƒ bao gá»“m má»™t sá»‘ khÃ­a cáº¡nh chÃ­nh cá»§a kháº£ nÄƒng bao gá»“m cÃ¡c kháº£ nÄƒng cá»‘t lÃµi vÃ  tuÃ¢n theo hÆ°á»›ng dáº«n má»Ÿ. CÃ¡c Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i tuÃ¢n theo cháº·t cháº½ cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y vá» Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n [9,2,47,8,16], nhÆ°ng phá»¥c vá»¥ nhÆ° lÃ  Ä‘Ã¡nh giÃ¡ Ä‘áº§u tiÃªn biÃªn soáº¡n chÃºng cÃ¹ng nhau Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ³ há»‡ thá»‘ng.

4.1 CÃ¡c khÃ­a cáº¡nh cá»§a Ä‘Ã¡nh giÃ¡

Kiáº¿n thá»©c thá»±c táº¿ lÃ  thiáº¿t yáº¿u Ä‘á»ƒ cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ phá»¥c vá»¥ nhu cáº§u thÃ´ng tin cá»§a ngÆ°á»i dÃ¹ng. ChÃºng tÃ´i sá»­ dá»¥ng táº­p dá»¯ liá»‡u Hiá»ƒu biáº¿t ngÃ´n ngá»¯ Ä‘a nhiá»‡m vá»¥ khá»•ng lá»“ (MMLU [22]) Ä‘á»ƒ Ä‘o lÆ°á»ng kiáº¿n thá»©c thá»±c táº¿ cá»§a cÃ¡c mÃ´ hÃ¬nh. MMLU bao gá»“m má»™t táº­p há»£p cÃ¡c cÃ¢u há»i vá» 57 chá»§ Ä‘á» cÃ³ Ä‘á»™ khÃ³ tá»« cáº¥p Ä‘á»™ tiá»ƒu há»c Ä‘áº¿n cáº¥p Ä‘á»™ chuyÃªn nghiá»‡p, vÃ  Ä‘á»‹nh dáº¡ng tráº£ lá»i tráº¯c nghiá»‡m cá»§a nÃ³ lÃ m cho nÃ³ phÃ¹ há»£p Ä‘á»ƒ thÄƒm dÃ² kiáº¿n thá»©c cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ  khÃ´ng cáº§n lo láº¯ng vá» tÃ­nh má»Ÿ cá»§a cÃ¡c tháº¿ há»‡.

--- TRANG 5 ---
LÃ½ luáº­n lÃ  má»™t kháº£ nÄƒng cÆ¡ báº£n khÃ¡c cho cÃ¡c mÃ´ hÃ¬nh, Ä‘áº·c biá»‡t lÃ  Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c nhiá»‡m vá»¥ phá»©c táº¡p. ChÃºng tÃ´i sá»­ dá»¥ng táº­p kiá»ƒm tra cá»§a táº­p dá»¯ liá»‡u ToÃ¡n há»c trÆ°á»ng tiá»ƒu há»c (GSM [11]) Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng lÃ½ luáº­n toÃ¡n há»c cá»§a cÃ¡c mÃ´ hÃ¬nh. ChÃºng tÃ´i cÅ©ng Ã¡p dá»¥ng Big-Bench-Hard (BBH [42]), chá»©a 23 nhiá»‡m vá»¥ thÃ¡ch thá»©c tá»« Big-Bench [41], Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng lÃ½ luáº­n tá»•ng quÃ¡t cá»§a cÃ¡c mÃ´ hÃ¬nh.

Äa ngÃ´n ngá»¯ hoáº¡t Ä‘á»™ng nhÆ° má»™t quan Ä‘iá»ƒm quan trá»ng cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘á»ƒ phá»¥c vá»¥ má»i ngÆ°á»i tá»« cÃ¡c ná»n táº£ng khÃ¡c nhau. ChÃºng tÃ´i sá»­ dá»¥ng TyDiQA [10], má»™t benchmark há»i Ä‘Ã¡p Ä‘a ngÃ´n ngá»¯ bao gá»“m 11 ngÃ´n ngá»¯ Ä‘a dáº¡ng vá» máº·t loáº¡i hÃ¬nh Ä‘á»ƒ kiá»ƒm tra mÃ´ hÃ¬nh cÃ³ thá»ƒ xá»­ lÃ½ vÄƒn báº£n khÃ´ng pháº£i tiáº¿ng Anh Ä‘áº¿n má»©c nÃ o. ChÃºng tÃ´i sá»­ dá»¥ng thiáº¿t láº­p Ä‘oáº¡n vÄƒn vÃ ng nÆ¡i má»™t Ä‘oáº¡n vÄƒn chá»©a cÃ¢u tráº£ lá»i tham kháº£o Ä‘Æ°á»£c cung cáº¥p.

Láº­p trÃ¬nh lÃ  má»™t á»©ng dá»¥ng cá»¥ thá»ƒ mÃ  má»i ngÆ°á»i Ä‘Ã£ sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ vÃ  cÃ³ thá»ƒ quan trá»ng Ä‘á»ƒ tÃ­ch há»£p cÃ¡c mÃ´ hÃ¬nh nÃ y vá»›i cÃ¡c cÃ´ng cá»¥ bÃªn ngoÃ i [5]. ChÃºng tÃ´i sá»­ dá»¥ng táº­p dá»¯ liá»‡u HumanEval [7] Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh trong viá»‡c táº¡o ra cÃ¡c chÆ°Æ¡ng trÃ¬nh chÃ­nh xÃ¡c vá» máº·t chá»©c nÄƒng tá»« docstring. Äá»ƒ trÃ¡nh sá»± mÆ¡ há»“ vá»›i Ä‘Ã¡nh giÃ¡ con ngÆ°á»i cá»§a chÃºng tÃ´i, chÃºng tÃ´i gá»i táº­p dá»¯ liá»‡u nÃ y lÃ  Codex-Eval trong bÃ i bÃ¡o nÃ y.

TuÃ¢n theo hÆ°á»›ng dáº«n má»Ÿ. Trong khi hiá»‡u suáº¥t trÃªn cÃ¡c benchmark á»Ÿ trÃªn Ä‘á»‹nh lÆ°á»£ng kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh táº¡i cÃ¡c ká»¹ nÄƒng cá»¥ thá»ƒ, nÃ³ cÃ³ thá»ƒ khÃ´ng pháº£n Ã¡nh má»©c Ä‘á»™ tá»‘t mÃ  cÃ¡c mÃ´ hÃ¬nh cÃ³ thá»ƒ xá»­ lÃ½ cÃ¡c hÆ°á»›ng dáº«n tá»« ngÆ°á»i dÃ¹ng thá»±c, bao gá»“m cÃ¡c yÃªu cáº§u Ä‘a dáº¡ng cao vÃ  thÆ°á»ng lÃ  má»Ÿ. VÃ­ dá»¥, táº­p dá»¯ liá»‡u ShareGPT phá»• biáº¿n chá»©a cÃ¡c phiÃªn báº£n cá»§a ngÆ°á»i dÃ¹ng yÃªu cáº§u trá»£ giÃºp láº­p trÃ¬nh, lá»i khuyÃªn Ä‘á»‹nh dáº¡ng sÆ¡ yáº¿u lÃ½ lá»‹ch, Ä‘Ã³ng vai giÃ¡o dá»¥c, gá»£i Ã½ phÃ¡t Ã¢m, viáº¿t tiá»ƒu thuyáº¿t fan, vÃ  nhiá»u hÆ¡n ná»¯a. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng hÆ°á»›ng dáº«n má»Ÿ nhÆ° váº­y cá»§a cÃ¡c mÃ´ hÃ¬nh báº±ng cÃ¡ch sá»­ dá»¥ng cáº£ Ä‘Ã¡nh giÃ¡ dá»±a trÃªn mÃ´ hÃ¬nh (Â§4.2) vÃ  Ä‘Ã¡nh giÃ¡ con ngÆ°á»i (Â§4.3), cáº£ hai Ä‘á»u bao gá»“m nhiá»u táº­p kiá»ƒm tra tá»« cÃ¡c nghiÃªn cá»©u hiá»‡n cÃ³ [47, 8, 26, 3, 19].

An toÃ n lÃ  má»‘i quan tÃ¢m Ä‘áº·c biá»‡t liÃªn quan Ä‘áº¿n cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ phÃ¡t triá»ƒn nhanh Ä‘á»ƒ Ä‘áº£m báº£o viá»‡c sá»­ dá»¥ng cÃ³ Ä‘áº¡o Ä‘á»©c vÃ  phÃ¹ há»£p cá»§a chÃºng. Theo LLAMA-2 [45], chÃºng tÃ´i sá»­ dá»¥ng ToxiGen [21] Ä‘á»ƒ Ä‘o lÆ°á»£ng ngÃ´n ngá»¯ Ä‘á»™c háº¡i vÃ  phÃ¡t biá»ƒu thÃ¹ Ä‘á»‹ch Ä‘Æ°á»£c táº¡o ra trÃªn cÃ¡c nhÃ³m khÃ¡c nhau khi cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c khuyáº¿n khÃ­ch lÃ m nhÆ° váº­y. ChÃºng tÃ´i cÅ©ng Ã¡p dá»¥ng TruthfulQA [30] Ä‘á»ƒ Ä‘o má»©c Ä‘á»™ tá»‘t mÃ  cÃ¡c mÃ´ hÃ¬nh cÃ³ thá»ƒ trÃ¡nh táº¡o ra nhá»¯ng Ä‘iá»u sai lá»‡ch Ä‘Ã£ biáº¿t do quan niá»‡m sai láº§m hoáº·c niá»m tin sai lá»‡ch trong khi cung cáº¥p thÃ´ng tin há»¯u Ã­ch.

Äá»‘i vá»›i táº¥t cáº£ cÃ¡c Ä‘Ã¡nh giÃ¡ dá»±a trÃªn benchmark, chÃºng tÃ´i tuÃ¢n theo cÃ¡c chá»‰ sá»‘ tiÃªu chuáº©n cá»§a chÃºng, trong khi chÃºng tÃ´i láº¥y máº«u con má»™t sá»‘ benchmark Ä‘áº¿n kÃ­ch thÆ°á»›c há»£p lÃ½ Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u quáº£ cá»§a viá»‡c thá»±c hiá»‡n lÃ½ luáº­n chuá»—i suy nghÄ©. ChÃºng tÃ´i giá»›i thiá»‡u ngÆ°á»i Ä‘á»c Ä‘áº¿n Phá»¥ lá»¥c Â§E Ä‘á»ƒ biáº¿t chi tiáº¿t thiáº¿t láº­p.

4.2 ÄÃ¡nh giÃ¡ dá»±a trÃªn mÃ´ hÃ¬nh sá»­ dá»¥ng GPT-4

Äá»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng hÆ°á»›ng dáº«n má»Ÿ, chÃºng tÃ´i Ä‘áº§u tiÃªn Ã¡p dá»¥ng má»™t phÆ°Æ¡ng phÃ¡p dá»±a trÃªn mÃ´ hÃ¬nh Ä‘Æ°á»£c giá»›i thiá»‡u trong AlpacaEval [27]. Táº­p kiá»ƒm tra bao gá»“m 805 hÆ°á»›ng dáº«n, vá»›i 252 hÆ°á»›ng dáº«n tá»« Ä‘Ã¡nh giÃ¡ Self-Instruct [47], 188 tá»« Ä‘Ã¡nh giÃ¡ Open Assistant [26], 129 tá»« Ä‘Ã¡nh giÃ¡ há»¯u Ã­ch bá»Ÿi Anthropic [3], 80 tá»« Ä‘Ã¡nh giÃ¡ Vicuna [8], vÃ  156 tá»« Ä‘Ã¡nh giÃ¡ Koala [19].

ChÃºng tÃ´i sá»­ dá»¥ng ngÆ°á»i chÃº thÃ­ch GPT-4 mÃ´ phá»ng cá»§a há», tÃ­nh toÃ¡n tá»· lá»‡ tháº¯ng cá»§a mÃ´ hÃ¬nh kiá»ƒm tra nhÆ° Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ bá»Ÿi GPT-4 khi so sÃ¡nh vá»›i cÃ¡c Ä‘áº§u ra Ä‘Æ°á»£c táº¡o bá»Ÿi Davinci-003. ChÃºng tÃ´i sá»­ dá»¥ng codebase vÃ  lá»i nháº¯c cá»§a AlpacaEval [27] Ä‘á»ƒ lÃ m cho Ä‘iá»ƒm sá»‘ cá»§a chÃºng tÃ´i cÃ³ thá»ƒ so sÃ¡nh trá»±c tiáº¿p vá»›i nhá»¯ng Ä‘iá»ƒm trÃªn báº£ng xáº¿p háº¡ng AlpacaEval. Khi thá»±c hiá»‡n so sÃ¡nh cáº·p vá»›i GPT-4, thá»© tá»± cá»§a cÃ¡c Ä‘áº§u ra mÃ´ hÃ¬nh Ä‘Æ°á»£c ngáº«u nhiÃªn hÃ³a Ä‘á»ƒ trÃ¡nh sá»± thiÃªn vá»‹ vá»‹ trÃ­ trong Ä‘Ã¡nh giÃ¡ [46]. ChÃºng tÃ´i khÃ´ng Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh LLAMA vanilla do chÃºng cÃ³ Ã­t kháº£ nÄƒng tuÃ¢n theo hÆ°á»›ng dáº«n mÃ  khÃ´ng cáº§n ká»¹ thuáº­t lá»i nháº¯c thÃªm.

4.3 ÄÃ¡nh giÃ¡ con ngÆ°á»i

Äá»ƒ kiá»ƒm tra thÃªm cháº¥t lÆ°á»£ng cá»§a cÃ¡c tháº¿ há»‡ má»Ÿ, chÃºng tÃ´i thá»±c hiá»‡n Ä‘Ã¡nh giÃ¡ con ngÆ°á»i dá»±a trÃªn 332 hÆ°á»›ng dáº«n káº¿t há»£p táº­p Ä‘Ã¡nh giÃ¡ Self-Instruct [47] vÃ  táº­p Ä‘Ã¡nh giÃ¡ Vicuna [8]. ÄÆ°á»£c truyá»n cáº£m há»©ng tá»« Bai vÃ  cá»™ng sá»± [3], chÃºng tÃ´i thiáº¿t káº¿ má»™t giao diá»‡n tÆ°Æ¡ng tá»± (HÃ¬nh 5) Ä‘á»ƒ thu tháº­p Ä‘Ã¡nh giÃ¡ con ngÆ°á»i vá» cÃ¡c Ä‘áº§u ra mÃ´ hÃ¬nh theo cÃ¡c khÃ­a cáº¡nh sau. ChÃºng tÃ´i lÆ°u Ã½ ráº±ng chÃºng tÃ´i Ä‘Ã£ Ä‘Ã¡nh giÃ¡ dá»±a trÃªn cÃ¡c mÃ´ hÃ¬nh LLAMA-1 Ä‘Æ°á»£c tinh chá»‰nh cá»§a chÃºng tÃ´i, vÃ¬ LLAMA-2 khÃ´ng cÃ³ sáºµn táº¡i thá»i Ä‘iá»ƒm thÃ­ nghiá»‡m nÃ y.

Kháº£ nÄƒng cháº¥p nháº­n cÃ¡ nhÃ¢n. ChÃºng tÃ´i yÃªu cáº§u ngÆ°á»i Ä‘Ã¡nh giÃ¡ con ngÆ°á»i Ä‘Ã¡nh giÃ¡ liá»‡u cÃ¡c pháº£n há»“i cá»§a tá»«ng há»‡ thá»‘ng cÃ³ thá»ƒ cháº¥p nháº­n Ä‘Æ°á»£c trong sá»± cÃ´ láº­p hay khÃ´ng. ÄÃ¢y lÃ  má»™t quyáº¿t Ä‘á»‹nh nhá»‹ phÃ¢n, vÃ  chÃºng tÃ´i yÃªu cáº§u ngÆ°á»i Ä‘Ã¡nh giÃ¡ Ä‘Ã¡nh dáº¥u má»™t pháº£n há»“i lÃ  cÃ³ thá»ƒ cháº¥p nháº­n náº¿u vÃ  chá»‰ náº¿u pháº£n há»“i tráº£ lá»i yÃªu cáº§u trong truy váº¥n, khÃ´ng cÃ³ lá»—i Ä‘Ã¡ng ká»ƒ, vÃ  khÃ´ng cÃ³ thÃ´ng tin láº·p láº¡i.

--- TRANG 6 ---
Báº£ng 3: So sÃ¡nh cÃ¡c táº­p dá»¯ liá»‡u Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n khÃ¡c nhau, cho tháº¥y ráº±ng cÃ¡c táº­p dá»¯ liá»‡u Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n khÃ¡c nhau cÃ³ thá»ƒ xuáº¥t sáº¯c trong cÃ¡c khÃ­a cáº¡nh khÃ¡c nhau, vÃ  cÃ¡c há»—n há»£p thá»±c hiá»‡n tá»‘t nháº¥t trung bÃ¬nh. CÃ¡c Ã´ Ä‘Æ°á»£c tÃ´ mÃ u xanh náº¿u viá»‡c tinh chá»‰nh tÄƒng hiá»‡u suáº¥t LLAMA vanilla, vÃ  mÃ u cam náº¿u viá»‡c tinh chá»‰nh lÃ m tá»•n háº¡i hiá»‡u suáº¥t.

[Báº£ng nÃ y chá»©a cÃ¡c káº¿t quáº£ hiá»‡u suáº¥t cho MMLU (thá»±c táº¿), GSM (lÃ½ luáº­n), BBH (lÃ½ luáº­n), TydiQA (Ä‘a ngÃ´n ngá»¯), Codex-Eval (láº­p trÃ¬nh), AlpacaEval (má»Ÿ), vá»›i cÃ¡c Ä‘iá»ƒm sá»‘ trung bÃ¬nh cho mÃ´ hÃ¬nh LLaMa 13B vanilla vÃ  cÃ¡c biáº¿n thá»ƒ Ä‘Æ°á»£c tinh chá»‰nh khÃ¡c nhau]

Báº£ng 4: Hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ khÃ¡c nhau sau khi huáº¥n luyá»‡n trÃªn há»—n há»£p dá»¯ liá»‡u Con ngÆ°á»i+GPT.

[Báº£ng nÃ y so sÃ¡nh hiá»‡u suáº¥t cá»§a Pythia 6.9B, OPT 6.7B, LLAMA 7B, vÃ  LLAMA-2 7B trÃªn cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ khÃ¡c nhau]

Sá»Ÿ thÃ­ch cáº·p. Sau Ä‘Ã³ chÃºng tÃ´i yÃªu cáº§u con ngÆ°á»i so sÃ¡nh cÃ¡c Ä‘áº§u ra cá»§a hai há»‡ thá»‘ng vÃ  chá»n cÃ¡i nÃ o há» nghÄ© há»¯u Ã­ch hÆ¡n. ÄÃ¢y lÃ  má»™t quyáº¿t Ä‘á»‹nh 5 hÆ°á»›ng, vÃ  ngÆ°á»i Ä‘Ã¡nh giÃ¡ cÃ³ thá»ƒ chá»n náº¿u má»™t trong nhá»¯ng pháº£n há»“i "rÃµ rÃ ng" hoáº·c "hÆ¡i" tá»‘t hÆ¡n cÃ¡i kia hoáº·c náº¿u Ä‘Ã³ lÃ  hÃ²a cÃ³ nghÄ©a lÃ  cáº£ hai pháº£n há»“i Ä‘á»u tá»‘t hoáº·c xáº¥u nhÆ° nhau.

Äá»ƒ cÃ³ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ Ä‘Ã¡ng tin cáº­y hÆ¡n, chÃºng tÃ´i tuyá»ƒn dá»¥ng má»™t nhÃ³m 18 ngÆ°á»i chÃº thÃ­ch chuyÃªn gia lÃ  cÃ¡c nhÃ  nghiÃªn cá»©u táº¡i AI2 hoáº·c sinh viÃªn táº¡i UW. Táº¥t cáº£ há» Ä‘á»u nÃ³i tiáº¿ng Anh thÃ´ng tháº¡o, cÃ³ báº±ng cá»­ nhÃ¢n trá»Ÿ lÃªn.

5 Káº¿t quáº£

5.1 PhÃ¢n tÃ­ch cÃ¡c táº­p dá»¯ liá»‡u Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n vÃ  mÃ´ hÃ¬nh cÆ¡ sá»Ÿ

Äá»ƒ hiá»ƒu cÃ¡ch cÃ¡c táº­p dá»¯ liá»‡u hÆ°á»›ng dáº«n Ä‘Æ°á»£c liá»‡t kÃª trong Báº£ng 1 Ä‘Ã³ng gÃ³p vÃ o kháº£ nÄƒng mÃ´ hÃ¬nh, chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh LLaMa 13B Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c táº­p dá»¯ liá»‡u nÃ y báº±ng bá»™ Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i. Báº£ng 3 hiá»ƒn thá»‹ káº¿t quáº£ trÃªn táº­p Ä‘Ã¡nh giÃ¡ benchmark cá»§a chÃºng tÃ´i, vá»›i káº¿t quáº£ má»Ÿ rá»™ng hÆ¡n trong Phá»¥ lá»¥c F. ChÃºng tÃ´i tháº¥y ráº±ng:

KhÃ´ng cÃ³ táº­p dá»¯ liá»‡u Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n tá»‘t nháº¥t duy nháº¥t trÃªn táº¥t cáº£ cÃ¡c nhiá»‡m vá»¥. CÃ¡c táº­p dá»¯ liá»‡u khÃ¡c nhau cho phÃ©p cÃ¡c kháº£ nÄƒng khÃ¡c nhau trong mÃ´ hÃ¬nh. CÃ¡c vÃ­ dá»¥ Ä‘Ã¡ng chÃº Ã½ bao gá»“m huáº¥n luyá»‡n trÃªn CoT Ä‘áº·c biá»‡t há»¯u Ã­ch cho lÃ½ luáº­n toÃ¡n há»c trong GSM vÃ  Code-Alpaca há»¯u Ã­ch cho Codex-Eval. ChÃºng tÃ´i giáº£ thuyáº¿t ráº±ng thÃ nh cÃ´ng trÃªn nhá»¯ng nhiá»‡m vá»¥ nÃ y, khÃ¡c biá»‡t Ä‘Ã¡ng ká»ƒ so vá»›i pháº§n cÃ²n láº¡i cá»§a cÃ¡c nhiá»‡m vá»¥ Ä‘Ã¡nh giÃ¡, Ä‘Ã²i há»i cÃ¡c táº­p huáº¥n luyá»‡n nÆ¡i nhá»¯ng nhiá»‡m vá»¥ nÃ y Ä‘Æ°á»£c Ä‘áº¡i diá»‡n tá»‘t. NgoÃ i viá»‡c xÃ¢y dá»±ng cÃ¡c táº­p dá»¯ liá»‡u cá»¥ thá»ƒ cho nhiá»‡m vá»¥ thá»§ cÃ´ng, chÆ°ng cáº¥t dá»¯ liá»‡u cá»¥ thá»ƒ cho nhiá»‡m vá»¥ tá»« cÃ¡c mÃ´ hÃ¬nh lá»›n cÅ©ng dÆ°á»ng nhÆ° lÃ  má»™t cÃ¡ch hiá»‡u quáº£ Ä‘á»ƒ Ä‘áº£m báº£o Ä‘iá»u nÃ y (vÃ­ dá»¥: CodeAlpaca Ä‘Æ°á»£c chÆ°ng cáº¥t tá»« Davinci-003).

Káº¿t há»£p cÃ¡c táº­p dá»¯ liá»‡u dáº«n Ä‘áº¿n hiá»‡u suáº¥t tá»•ng thá»ƒ tá»‘t nháº¥t trÃªn cÃ¡c nhiá»‡m vá»¥ benchmark. Trong khi cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c táº­p dá»¯ liá»‡u káº¿t há»£p cá»§a chÃºng tÃ´i thÆ°á»ng khÃ´ng pháº£i lÃ  mÃ´ hÃ¬nh tá»‘t nháº¥t cho má»™t nhiá»‡m vá»¥ duy nháº¥t (chá»‰ lÃ  tá»‘t nháº¥t trong 2 trÃªn 6 thiáº¿t láº­p Ä‘Ã¡nh giÃ¡), chÃºng lÃ  tá»‘t nháº¥t khi Ä‘o lÆ°á»ng hiá»‡u suáº¥t trung bÃ¬nh trÃªn cÃ¡c nhiá»‡m vá»¥. Äiá»u nÃ y gá»£i Ã½ ráº±ng cÃ´ng viá»‡c tÆ°Æ¡ng lai vá» viá»‡c trá»™n táº­p dá»¯ liá»‡u tá»‘t hÆ¡n hoáº·c Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n modular

--- TRANG 7 ---
Báº£ng 5: Hiá»‡u suáº¥t cá»§a TÃœLU vÃ  cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n khÃ¡c cá»§a chÃºng tÃ´i so vá»›i cÃ¡c mÃ´ hÃ¬nh LLAMA vanilla vÃ  cÃ¡c mÃ´ hÃ¬nh Ä‘á»™c quyá»n tiÃªn tiáº¿n trÃªn cÃ¡c thiáº¿t láº­p Ä‘Ã¡nh giÃ¡. Xem Báº£ng 8 Ä‘á»ƒ biáº¿t danh sÃ¡ch Ä‘áº§y Ä‘á»§.

[Báº£ng nÃ y hiá»ƒn thá»‹ káº¿t quáº£ hiá»‡u suáº¥t chi tiáº¿t cho cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau tá»« 7B Ä‘áº¿n 65B tham sá»‘, so sÃ¡nh vá»›i ChatGPT vÃ  GPT-4]

(vÃ­ dá»¥: mixture-of-experts [40]) lÃ  má»™t hÆ°á»›ng Ä‘áº§y há»©a háº¹n Ä‘á»ƒ phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh duy trÃ¬ hiá»‡u suáº¥t máº¡nh máº½ trÃªn táº¥t cáº£ cÃ¡c thiáº¿t láº­p Ä‘Ã¡nh giÃ¡.

Cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh cÆ¡ sá»Ÿ cá»±c ká»³ quan trá»ng Ä‘á»‘i vá»›i hiá»‡u suáº¥t downstream. ChÃºng tÃ´i kiá»ƒm tra tÃ¡c Ä‘á»™ng cá»§a viá»‡c sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ khÃ¡c nhau trong Báº£ng 4, so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh LLAMA, OPT [54], vÃ  Pythia [4] cÃ³ kÃ­ch thÆ°á»›c tÆ°Æ¡ng Ä‘Æ°Æ¡ng Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn há»—n há»£p dá»¯ liá»‡u Con ngÆ°á»i+GPT. TrÃªn táº¥t cáº£ cÃ¡c thiáº¿t láº­p Ä‘Ã¡nh giÃ¡, chÃºng tÃ´i tháº¥y ráº±ng sá»­ dá»¥ng LLAMA thá»±c hiá»‡n tá»‘t nháº¥t vá»›i má»™t biÃªn Ä‘á»™ Ä‘Ã¡ng ká»ƒ, cÃ³ thá»ƒ do thá»±c táº¿ lÃ  LLAMA Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c trÃªn nhiá»u token Ä‘Ã¡ng ká»ƒ hÆ¡n cÃ¡c mÃ´ hÃ¬nh khÃ¡c (xem Báº£ng 2). Äiá»u nÃ y gá»£i Ã½ ráº±ng cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c trÃªn táº­p dá»¯ liá»‡u lá»›n hÆ¡n (hoáº·c cÃ³ thá»ƒ cháº¥t lÆ°á»£ng cao hÆ¡n) Ä‘Æ°á»£c Æ°a thÃ­ch lÃ m mÃ´ hÃ¬nh cÆ¡ sá»Ÿ cho Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n. Viá»‡c bá»• sung LLAMA-2 sau Ä‘Ã³ xÃ¡c nháº­n phÃ¡t hiá»‡n nÃ y báº±ng cÃ¡ch cho tháº¥y má»™t cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ cÃ³ thá»ƒ Ä‘áº¿n tá»« chá»‰ viá»‡c nÃ¢ng cáº¥p mÃ´ hÃ¬nh cÆ¡ sá»Ÿ.

Má»™t sá»‘ táº­p dá»¯ liá»‡u lÃ m suy giáº£m hiá»‡u suáº¥t mÃ´ hÃ¬nh vanilla. ÄÃ¡ng chÃº Ã½, háº§u háº¿t cÃ¡c táº­p dá»¯ liá»‡u chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ gÃ¢y ra sá»± suy giáº£m hiá»‡u suáº¥t trÃªn GSM vÃ  TydiQA so vá»›i mÃ´ hÃ¬nh cÆ¡ sá»Ÿ vanilla. ChÃºng tÃ´i giáº£ thuyáº¿t Ä‘iá»u nÃ y lÃ  do phong cÃ¡ch vÃ  cháº¥t lÆ°á»£ng dá»¯ liá»‡u. Nhiá»u táº­p dá»¯ liá»‡u chÃºng tÃ´i kiá»ƒm tra chá»©a Ã­t hoáº·c khÃ´ng cÃ³ vÃ­ dá»¥ vá» lÃ½ luáº­n kiá»ƒu chuá»—i suy nghÄ© vÃ  chá»©a Ã­t hoáº·c khÃ´ng cÃ³ dá»¯ liá»‡u Ä‘a ngÃ´n ngá»¯. NhÆ° váº­y, huáº¥n luyá»‡n trÃªn cÃ¡c táº­p dá»¯ liá»‡u nÃ y cÃ³ thá»ƒ dáº«n Ä‘áº¿n má»™t sá»‘ quÃªn cÃ¡c kháº£ nÄƒng CoT hoáº·c Ä‘a ngÃ´n ngá»¯ mÃ  mÃ´ hÃ¬nh trÆ°á»›c Ä‘Ã³ Ä‘Ã£ cÃ³, dáº«n Ä‘áº¿n hiá»‡u suáº¥t suy giáº£m. NgoÃ i ra, chÃºng tÃ´i lÆ°u Ã½ ráº±ng self-instruct dÆ°á»ng nhÆ° gÃ¢y ra sá»± suy giáº£m trÃªn háº§u háº¿t cÃ¡c nhiá»‡m vá»¥, mÃ  chÃºng tÃ´i giáº£ thuyáº¿t lÃ  do cháº¥t lÆ°á»£ng tÆ°Æ¡ng Ä‘á»‘i kÃ©m cá»§a dá»¯ liá»‡u self-instruct gá»‘c, Ä‘Æ°á»£c táº¡o ra bá»Ÿi má»™t mÃ´ hÃ¬nh yáº¿u hÆ¡n (GPT-3 cÆ¡ sá»Ÿ) so vá»›i cÃ¡c táº­p dá»¯ liá»‡u chÆ°ng cáº¥t GPT khÃ¡c.

5.2 Äáº©y giá»›i háº¡n cá»§a cÃ¡c mÃ´ hÃ¬nh má»Ÿ

Sau khi thiáº¿t láº­p ráº±ng (a) sá»­ dá»¥ng má»™t há»—n há»£p rá»™ng dá»¯ liá»‡u lÃ  tá»‘t nháº¥t, vÃ  (b) sá»­ dá»¥ng LLAMA lÃ m mÃ´ hÃ¬nh cÆ¡ sá»Ÿ Ä‘Æ°á»£c Æ°a thÃ­ch hÆ¡n cÃ¡c lá»±a chá»n má»Ÿ khÃ¡c, chÃºng tÃ´i so sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn há»—n há»£p dá»¯ liá»‡u Con ngÆ°á»i+GPT (mÃ´ hÃ¬nh TÃœLU) trÃªn táº¥t cáº£ cÃ¡c kÃ­ch thÆ°á»›c LLAMA trong Báº£ng 5. ChÃºng tÃ´i tháº¥y ráº±ng:

Äiá»u chá»‰nh hÆ°á»›ng dáº«n mang láº¡i lá»£i Ã­ch lá»›n trÃªn Ä‘áº§u cÃ¡c mÃ´ hÃ¬nh LLAMA á»Ÿ táº¥t cáº£ cÃ¡c kÃ­ch thÆ°á»›c. Trung bÃ¬nh, táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh LLAMA cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ sau khi Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n.

--- TRANG 8 ---
CÃ¡c mÃ´ hÃ¬nh nhá» hÆ¡n Ä‘Æ°á»£c hÆ°á»Ÿng lá»£i nhiá»u nháº¥t tá»« Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n. ChÃºng tÃ´i tháº¥y ráº±ng cÃ¡c cáº£i thiá»‡n tÆ°Æ¡ng Ä‘á»‘i tá»« Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n lÃ  lá»›n nháº¥t Ä‘á»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh nhá» nháº¥t vÃ  thu háº¹p khi cÃ¡c mÃ´ hÃ¬nh trá»Ÿ nÃªn lá»›n hÆ¡n. ÄÃ¡ng chÃº Ã½, mÃ´ hÃ¬nh LLAMA 65B thá»±c hiá»‡n tÆ°Æ¡ng Ä‘Æ°Æ¡ng hoáº·c tá»‘t hÆ¡n mÃ´ hÃ¬nh TÃœLU 65B trÃªn MMLU, BBH, vÃ  TydiQA. Äiá»u nÃ y gá»£i Ã½ ráº±ng Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n khÃ´ng giÃºp tÄƒng cÆ°á»ng cÃ¡c kháº£ nÄƒng máº¡nh máº½ Ä‘Ã£ cÃ³ sáºµn trong mÃ´ hÃ¬nh gá»‘c, vÃ  cÅ©ng nháº¥n máº¡nh ráº±ng cáº§n pháº£i cáº©n tháº­n trong quÃ¡ trÃ¬nh tinh chá»‰nh Ä‘á»ƒ trÃ¡nh quÃªn cÃ¡c kháº£ nÄƒng ban Ä‘áº§u cá»§a mÃ´ hÃ¬nh cÆ¡ sá»Ÿ.

TÃœLU váº«n tá»¥t háº­u so vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘á»™c quyá»n tiÃªn tiáº¿n. Máº·c dÃ¹ cÃ³ hiá»‡u suáº¥t áº¥n tÆ°á»£ng cá»§a TÃœLU 65B, nÃ³ váº«n tá»¥t háº­u so vá»›i ChatGPT vÃ  GPT-4 trong táº¥t cáº£ cÃ¡c thiáº¿t láº­p Ä‘Ã¡nh giÃ¡, trÃ¡i ngÆ°á»£c vá»›i cÃ¡c tuyÃªn bá»‘ trÆ°á»›c Ä‘Ã¢y ráº±ng cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c tÃ i nguyÃªn má»Ÿ nÃ y cÃ³ thá»ƒ sÃ¡nh báº±ng ChatGPT [56,8]. ChÃºng tÃ´i lÆ°u Ã½ ráº±ng chÃºng tÃ´i khÃ´ng thá»ƒ loáº¡i trá»« kháº£ nÄƒng ChatGPT hoáº·c GPT-4 Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c pháº§n Ä‘Ã¡ng ká»ƒ cá»§a bá»™ Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i. Tuy nhiÃªn, sá»± hiá»‡n diá»‡n cá»§a má»™t khoáº£ng cÃ¡ch Ä‘Ã¡ng ká»ƒ giá»¯a cÃ¡c mÃ´ hÃ¬nh TÃœLU vÃ  ChatGPT phÃ¹ há»£p vá»›i cÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i trong cÃ¡c Ä‘Ã¡nh giÃ¡ dá»±a trÃªn mÃ´ hÃ¬nh vÃ  con ngÆ°á»i, Ã­t cÃ³ kháº£ nÄƒng bá»‹ xÃ¢m pháº¡m hÆ¡n.

5.3 ÄÃ¡nh giÃ¡ rá»§i ro vÃ  tÃ¡c háº¡i tiá»m áº©n

ToxiGen (â†“) | TruthfulQA (â†‘)
MÃ´ hÃ¬nh â†“ | 7B | 13B | 7B | 13B
LLAMA | 85.4 | 82.6 | 26.2 | 23.6
+ SuperNI | 85.3 | 77.3 | 26.7 | 26.2
+ CoT | 63.0 | 43.9 | 35.1 | 35.5
+ Flan V2 | 77.5 | 61.4 | 33.2 | 33.4
+ Dolly | 72.1 | 78.9 | 30.1 | 32.9
+ Open Assistant 1 | 39.2 | 5.2 | 40.9 | 48.6
+ Self-instruct | 89.0 | 89.3 | 22.4 | 22.4
+ Unnatural Inst. | 35.8 | 55.7 | 27.3 | 31.7
+ Alpaca | 63.2 | 58.1 | 33.5 | 39.8
+ Code-Alpaca | 84.3 | 92.0 | 25.1 | 26.7
+ GPT4-Alpaca | 3.9 | 1.2 | 51.2 | 56.7
+ Baize | 77.2 | 41.2 | 42.4 | 43.9
+ ShareGPT | 5.5 | 2.5 | 45.3 | 60.0
+ Human mix. | 51.8 | 76.9 | 34.1 | 32.1
+ TÃœLU | 10.6 | 0.1 | 44.6 | 41.6
ChatGPT | 27.7 | | 75.2 |
GPT-4 | 10.6 | | 82.3 |

Báº£ng 6: Hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh trÃªn ToxiGen (% tháº¿ há»‡ Ä‘á»™c háº¡i, tháº¥p hÆ¡n lÃ  tá»‘t hÆ¡n) vÃ  TruthfulQA (% cÃ¢u tráº£ lá»i Ä‘Ãºng sá»± tháº­t vÃ  cÃ³ thÃ´ng tin, cao hÆ¡n lÃ  tá»‘t hÆ¡n). Xem Báº£ng 9 vÃ  Báº£ng 10 Ä‘á»ƒ biáº¿t phÃ¢n tÃ­ch Ä‘áº§y Ä‘á»§ cá»§a hai Ä‘Ã¡nh giÃ¡ nÃ y.

ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i trÃªn ToxiGen vÃ  TruthfulQA Ä‘á»ƒ Ä‘o lÆ°á»ng má»©c Ä‘á»™ mÃ  cÃ¡c táº­p dá»¯ liá»‡u khÃ¡c nhau cÃ³ kháº£ nÄƒng táº¡o ra cÃ¡c mÃ´ hÃ¬nh táº¡o ra ngÃ´n ngá»¯ Ä‘á»™c háº¡i hoáº·c thÃ´ng tin sai lá»‡ch. ChÃºng tÃ´i tháº¥y ráº±ng:

Xu hÆ°á»›ng váº«n tÆ°Æ¡ng tá»± nhÆ° cÃ¡c benchmark táº­p trung vÃ o kháº£ nÄƒng. TÆ°Æ¡ng tá»± nhÆ° cÃ¡c káº¿t quáº£ trong Má»¥c 4.1, chÃºng tÃ´i tháº¥y ráº±ng cÃ¡c táº­p dá»¯ liá»‡u chÆ°ng cáº¥t GPT cho káº¿t quáº£ hiá»‡u suáº¥t tá»•ng thá»ƒ tá»‘t nháº¥t vÃ  cÃ³ sá»± biáº¿n thiÃªn lá»›n trong hiá»‡u suáº¥t trÃªn cÃ¡c táº­p dá»¯ liá»‡u.

CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u nguá»“n GPT táº¡o ra Ã­t tháº¿ há»‡ Ä‘á»™c háº¡i hÆ¡n GPT. CÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u chÆ°ng cáº¥t GPT dÆ°á»ng nhÆ° tá»« chá»‘i táº¡o ra tháº¿ há»‡ Ä‘á»™c háº¡i gáº§n nhÆ° hoÃ n toÃ n, máº·c dÃ¹ thá»±c táº¿ lÃ  ChatGPT vÃ  GPT-4 táº¡o ra tháº¿ há»‡ Ä‘á»™c háº¡i má»™t lÆ°á»£ng khÃ´ng táº§m thÆ°á»ng. ChÃºng tÃ´i giáº£ thuyáº¿t Ä‘iá»u nÃ y lÃ  do cÃ¡c mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i overfitting trÃªn hÃ nh vi kiá»ƒu tá»« chá»‘i, tá»« chá»‘i táº¡o ra báº¥t cá»© thá»© gÃ¬ cÃ³ Ä‘á»™ Ä‘á»™c háº¡i vá»«a pháº£i, trong khi cÃ¡c mÃ´ hÃ¬nh GPT cÃ¢n báº±ng hÃ nh vi tá»« chá»‘i vá»›i sá»± há»¯u Ã­ch á»Ÿ má»©c Ä‘á»™ lá»›n hÆ¡n.

Hiá»‡u suáº¥t TruthfulQA khÃ´ng má»Ÿ rá»™ng. KhÃ¡c vá»›i cÃ¡c benchmark khÃ¡c, chÃºng tÃ´i tháº¥y ráº±ng hiá»‡u suáº¥t TruthfulQA khÃ´ng cáº£i thiá»‡n vá»›i kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh. Kiá»ƒm tra thÃªm Ä‘iá»u nÃ y, chÃºng tÃ´i tháº¥y ráº±ng cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n cÃ³ Ä‘Æ°a ra nhiá»u sá»± kiá»‡n Ä‘Ãºng hÆ¡n, nhÆ°ng cÅ©ng cÃ³ xu hÆ°á»›ng nÃ© trÃ¡nh vÃ  tá»« chá»‘i Ä‘Æ°a ra cÃ¢u tráº£ lá»i cÃ³ thÃ´ng tin thÆ°á»ng xuyÃªn hÆ¡n, dáº«n Ä‘áº¿n Ã­t hoáº·c khÃ´ng cÃ³ cáº£i thiá»‡n tá»•ng thá»ƒ khi kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh tÄƒng.

5.4 Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ dá»±a trÃªn mÃ´ hÃ¬nh cho tháº¿ há»‡ má»Ÿ

ChÃºng tÃ´i bÃ¡o cÃ¡o tá»· lá»‡ tháº¯ng AlpacaEval cá»§a cÃ¡c mÃ´ hÃ¬nh chÃºng tÃ´i trong Báº£ng 7. ChÃºng tÃ´i tháº¥y ráº±ng:

CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn há»—n há»£p dá»±a trÃªn cÃ¡c táº­p dá»¯ liá»‡u NLP truyá»n thá»‘ng thá»±c hiá»‡n kÃ©m. CoT, FLAN, vÃ  SuperNI Ä‘á»u thá»±c hiá»‡n cá»±c ká»³ kÃ©m trong viá»‡c tuÃ¢n theo hÆ°á»›ng dáº«n má»Ÿ, máº·c dÃ¹ cÃ¡c táº­p dá»¯ liá»‡u nÃ y cung cáº¥p cáº£i thiá»‡n lá»›n cho cÃ¡c kháº£ nÄƒng mÃ´ hÃ¬nh Ä‘Æ°á»£c kiá»ƒm tra trong Báº£ng 3.

CÃ¡c táº­p dá»¯ liá»‡u khuyáº¿n khÃ­ch tháº¿ há»‡ dÃ i, Ä‘a dáº¡ng thá»±c hiá»‡n tá»‘t nháº¥t. Bá»‹ háº¥p dáº«n bá»Ÿi hiá»‡u suáº¥t cá»§a ShareGPT, chÃºng tÃ´i váº½ biá»ƒu Ä‘á»“ sá»‘ lÆ°á»£ng token duy nháº¥t trung bÃ¬nh trong cÃ¡c tháº¿ há»‡ mÃ´ hÃ¬nh so vá»›i tá»· lá»‡ tháº¯ng AlpacaEval trong HÃ¬nh 2. ChÃºng tÃ´i tháº¥y ráº±ng Ä‘Ã¡nh giÃ¡ cÃ³ tÆ°Æ¡ng quan máº¡nh máº½ vá»›i sá»‘ lÆ°á»£ng token duy nháº¥t trung bÃ¬nh (tÆ°Æ¡ng quan Pearson 0.96, ğ‘â‰ª 0.05). Cho ráº±ng hiá»‡u suáº¥t máº¡nh máº½ cá»§a GPT-4 trÃªn cÃ¡c nhiá»‡m vá»¥ khÃ¡c, chÃºng tÃ´i khÃ´ng tin ráº±ng Ä‘Ã¡nh giÃ¡ GPT-4 chá»‰ Ä‘Æ¡n giáº£n lÃ  Ä‘áº¿m token duy nháº¥t, nhÆ°ng káº¿t quáº£ nÃ y ná»•i báº­t cÃ¡ch Ä‘iá»ƒm sá»‘ sá»Ÿ thÃ­ch mÃ´ hÃ¬nh khÃ´ng nháº¥t thiáº¿t chá»‰ thÆ°á»Ÿng cho kháº£ nÄƒng mÃ´ hÃ¬nh.

--- TRANG 9 ---
Táº­p dá»¯ liá»‡u huáº¥n luyá»‡n â†“ | 7B | 13B | 30B | 65B
SuperNI | 2.9 | 4.2 | |
CoT | 5.0 | 6.0 | |
Flan V2 | 3.1 | 3.2 | |
Dolly | 11.0 | 13.7 | |
Open Assistant 1 | 51.4 | 58.1 | |
Self-instruct | 4.0 | 5.0 | |
Unnatural Instructions | 7.5 | 8.4 | |
Alpaca | 21.4 | 21.9 | |
Code-Alpaca | 15.3 | 15.8 | |
GPT4-Alpaca | 57.3 | 63.1 | |
Baize | 20.0 | 21.9 | |
ShareGPT | 62.4 | 70.5 | 69.1 | 73.6
Human mix. | 28.7 | 35.0 | 38.3 | 43.4
TÃœLU | 48.6 | 56.5 | 62.3 | 61.8

Báº£ng 7: Tá»· lá»‡ tháº¯ng (%) cá»§a cÃ¡c mÃ´ hÃ¬nh LLAMA cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau Ä‘Æ°á»£c tinh chá»‰nh trÃªn táº­p dá»¯ liá»‡u Ä‘Ã£ cho so vá»›i Davinci-003 sá»­ dá»¥ng AlpacaEval [27].

[HÃ¬nh 2 hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ tÆ°Æ¡ng quan giá»¯a tá»· lá»‡ tháº¯ng vÃ  sá»‘ token duy nháº¥t trung bÃ¬nh]

[HÃ¬nh 3 hiá»ƒn thá»‹ tá»· lá»‡ cháº¥p nháº­n con ngÆ°á»i cho bá»‘n mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡]

[HÃ¬nh 4 hiá»ƒn thá»‹ tá»· lá»‡ sá»Ÿ thÃ­ch con ngÆ°á»i cho ba cáº·p so sÃ¡nh mÃ´ hÃ¬nh]

ShareGPT thá»±c hiá»‡n tá»‘t nháº¥t. ChÃºng tÃ´i tháº¥y ráº±ng ShareGPT luÃ´n thá»±c hiá»‡n tá»‘t nháº¥t trÃªn táº¥t cáº£ cÃ¡c kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh, bao gá»“m cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn há»—n há»£p dá»¯ liá»‡u bao gá»“m ShareGPT. CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn ShareGPT Ä‘áº¡t tá»· lá»‡ tháº¯ng cao hÆ¡n cÃ¡c mÃ´ hÃ¬nh gáº¥p Ä‘Ã´i kÃ­ch thÆ°á»›c cá»§a chÃºng (vÃ­ dá»¥: 13B ShareGPT so vá»›i 65B TÃœLU). ChÃºng tÃ´i giáº£ thuyáº¿t Ä‘iá»u nÃ y lÃ  do tÃ­nh Ä‘a dáº¡ng, kÃ­ch thÆ°á»›c, vÃ  sá»‘ lÆ°á»£ng token trung bÃ¬nh cao cá»§a cÃ¡c pháº£n há»“i má»¥c tiÃªu cá»§a ShareGPT.

NhÃ¬n chung, cÃ¡c káº¿t quáº£ nÃ y gá»£i Ã½ ráº±ng trong khi Ä‘Ã¡nh giÃ¡ sá»Ÿ thÃ­ch mÃ´ hÃ¬nh lÃ  quan trá»ng, nÃ³ khÃ´ng cung cáº¥p Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n vá» cÃ¡c mÃ´ hÃ¬nh nÃ y. Thay vÃ o Ä‘Ã³, Ä‘Ã¡nh giÃ¡ sá»Ÿ thÃ­ch mÃ´ hÃ¬nh chá»‰ nÃªn Ä‘Æ°á»£c bao gá»“m nhÆ° má»™t pháº§n cá»§a má»™t thiáº¿t láº­p Ä‘Ã¡nh giÃ¡ lá»›n hÆ¡n, toÃ n diá»‡n hÆ¡n.

5.5 Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ con ngÆ°á»i cho tháº¿ há»‡ má»Ÿ

Cuá»‘i cÃ¹ng, chÃºng tÃ´i hiá»ƒn thá»‹ káº¿t quáº£ Ä‘Ã¡nh giÃ¡ con ngÆ°á»i trong HÃ¬nh 4 vÃ  chÃºng tÃ´i giá»›i thiá»‡u ngÆ°á»i Ä‘á»c Ä‘áº¿n Phá»¥ lá»¥c Â§G.2 Ä‘á»ƒ biáº¿t thá»a thuáº­n giá»¯a cÃ¡c ngÆ°á»i chÃº thÃ­ch. ChÃºng tÃ´i tháº¥y ráº±ng káº¿t quáº£ Ä‘Ã¡nh giÃ¡ con ngÆ°á»i chá»§ yáº¿u tÆ°Æ¡ng quan vá»›i AlpacaEval vÃ  Ä‘Ã¡nh giÃ¡ dá»±a trÃªn benchmark: táº¥t cáº£ cÃ¡c Ä‘Ã¡nh giÃ¡ Ä‘á»u cho tháº¥y ráº±ng 65B TÃœLU vÆ°á»£t trá»™i hÆ¡n 7B TÃœLU, gá»£i Ã½ ráº±ng viá»‡c sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ lá»›n hÆ¡n lÃ  quan trá»ng, vÃ  váº«n cÃ²n má»™t khoáº£ng cÃ¡ch khÃ´ng táº§m thÆ°á»ng trong hiá»‡u suáº¥t giá»¯a 65B TÃœLU vÃ  ChatGPT. ChÃºng tÃ´i cÅ©ng tháº¥y ráº±ng viá»‡c sá»­ dá»¥ng cÃ¡c táº­p dá»¯ liá»‡u chÆ°ng cáº¥t cung cáº¥p má»™t sá»± thÃºc Ä‘áº©y hiá»‡u suáº¥t lá»›n, gá»£i Ã½ ráº±ng cÃ¡c táº­p dá»¯ liá»‡u do con ngÆ°á»i viáº¿t thiáº¿u so sÃ¡nh. Nhá»¯ng quan sÃ¡t nÃ y cÅ©ng phÃ¹ há»£p vá»›i cÃ¡c Ä‘iá»ƒm sá»‘ kháº£ nÄƒng cháº¥p nháº­n trong HÃ¬nh 3.

Tuy nhiÃªn, chÃºng tÃ´i lÆ°u Ã½ ráº±ng 7B TÃœLU vÆ°á»£t trá»™i hÆ¡n 65B TÃœLU há»—n há»£p con ngÆ°á»i trong Ä‘Ã¡nh giÃ¡ sá»Ÿ thÃ­ch mÃ´ hÃ¬nh, nhÆ°ng náº¿u chÃºng tÃ´i so sÃ¡nh cÃ¡c Ä‘iá»ƒm sá»‘ kháº£ nÄƒng cháº¥p nháº­n trong HÃ¬nh 3, Ä‘iá»u ngÆ°á»£c láº¡i dÆ°á»ng nhÆ° Ä‘Ãºng. ÄÃ¢y lÃ  báº±ng chá»©ng thÃªm ráº±ng Ä‘Ã¡nh giÃ¡ cáº·p mÃ´ hÃ¬nh cÃ³ thá»ƒ khÃ´ng luÃ´n tiáº¿t lá»™ nhá»¯ng thiáº¿u sÃ³t cá»§a mÃ´ hÃ¬nh. Trong trÆ°á»ng há»£p nÃ y, mÃ´ hÃ¬nh 65B há»—n há»£p con ngÆ°á»i cÃ³ nhiá»u kháº£ nÄƒng táº¡o ra cÃ¡c pháº£n há»“i cÃ³ thá»ƒ cháº¥p nháº­n Ä‘Æ°á»£c (náº¿u khÃ´ng pháº£i cháº¥t lÆ°á»£ng cao) hÆ¡n mÃ´ hÃ¬nh 7B.

--- TRANG 10 ---
6 CÃ´ng trÃ¬nh liÃªn quan

Äiá»u chá»‰nh hÆ°á»›ng dáº«n cá»§a LM. Tinh chá»‰nh cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ trÃªn cÃ¡c táº­p hÆ°á»›ng dáº«n Ä‘a dáº¡ng cÃ¹ng vá»›i cÃ¡c máº«u thÃ´ng thÆ°á»ng Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh lÃ  cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ hiá»‡u suáº¥t zero-shot trÃªn cÃ¡c nhiá»‡m vá»¥ chÆ°a tháº¥y [39,51,49,32,9,48], vÃ  phá»¥c vá»¥ nhÆ° má»™t cÆ¡ sá»Ÿ tá»‘t cho viá»‡c tinh chá»‰nh thÃªm trong cÃ¡c thiáº¿t láº­p cÃ³ giÃ¡m sÃ¡t [31]. TÄƒng sá»‘ lÆ°á»£ng lá»i nháº¯c Ä‘a dáº¡ng [39], sá»‘ lÆ°á»£ng nhiá»‡m vá»¥ [48,9], vÃ  tÃ­nh Ä‘a dáº¡ng cá»§a dá»¯ liá»‡u [56] Ä‘á»u Ä‘Æ°á»£c chá»©ng minh lÃ  quan trá»ng Ä‘á»‘i vá»›i hiá»‡u suáº¥t. Gáº§n Ä‘Ã¢y hÆ¡n, má»™t sá»‘ lÆ°á»£ng ngÃ y cÃ ng tÄƒng cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ sá»­ dá»¥ng dá»¯ liá»‡u tÄƒng cÆ°á»ng hÆ°á»›ng dáº«n Ä‘Æ°á»£c táº¡o bá»Ÿi mÃ´ hÃ¬nh [47,23,25,53], thÆ°á»ng Ä‘Æ°á»£c táº¡o ra hoáº·c thu tháº­p tá»« cÃ¡c mÃ´ hÃ¬nh Ä‘á»™c quyá»n lá»›n hÆ¡n nhÆ° ChatGPT hoáº·c GPT-4 [8,15,43,52,36, trong sá»‘ nhá»¯ng cÃ¡i khÃ¡c]. Máº·c dÃ¹ sá»± bÃ¹ng ná»• cá»§a cÃ¡c mÃ´ hÃ¬nh vÃ  táº­p dá»¯ liá»‡u, Ä‘Ã¡nh giÃ¡ váº«n khÃ´ng nháº¥t quÃ¡n vÃ  khÃ³ khÄƒn, vá»›i cÃ¡c thiáº¿t láº­p Ä‘Ã¡nh giÃ¡ khÃ¡c nhau Ä‘Æ°á»£c sá»­ dá»¥ng trÃªn cÃ¡c mÃ´ hÃ¬nh. CÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y Ä‘Ã£ kiá»ƒm tra cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c nguá»“n táº­p dá»¯ liá»‡u khÃ¡c nhau vá»›i má»¥c Ä‘Ã­ch xÃ¡c Ä‘á»‹nh 'há»—n há»£p tá»‘t nháº¥t' [31,24], nhÆ°ng thÆ°á»ng bá»‹ háº¡n cháº¿ chá»‰ kiá»ƒm tra hiá»‡u suáº¥t benchmark, vÃ  bao gá»“m má»™t sá»‘ lÆ°á»£ng nhá» hÆ¡n cÃ¡c nguá»“n hÆ°á»›ng dáº«n so vá»›i cÃ´ng trÃ¬nh nÃ y. QLoRA [14] cÅ©ng khÃ¡m phÃ¡ Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n (Ä‘Æ°á»£c lÆ°á»£ng tá»­ hÃ³a vÃ  hiá»‡u quáº£ tham sá»‘) cá»§a cÃ¡c mÃ´ hÃ¬nh vÃ  táº­p dá»¯ liá»‡u gáº§n Ä‘Ã¢y, nhÆ°ng khÃ¡m phÃ¡ má»™t pháº¡m vi nhá» hÆ¡n cÃ¡c mÃ´ hÃ¬nh, táº­p dá»¯ liá»‡u, vÃ  Ä‘Ã¡nh giÃ¡ so vá»›i cÃ´ng trÃ¬nh nÃ y.

ÄÃ¡nh giÃ¡ LM. Cho sá»± thÃ nh cÃ´ng cá»§a LM trÃªn cÃ¡c nhiá»‡m vá»¥ NLP vÃ  tuÃ¢n theo hÆ°á»›ng dáº«n, nhiá»u khung Ä‘Ã¡nh giÃ¡ Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» xuáº¥t. CÃ¡c khung nhÆ° HELM [28] vÃ  LM Evaluation Harness [17] bao gá»“m má»™t pháº¡m vi rá»™ng cÃ¡c nhiá»‡m vá»¥ NLP nhÆ°ng thÆ°á»ng táº­p trung vÃ o Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ thay vÃ¬ nhá»¯ng mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n. TÆ°Æ¡ng tá»± nhÆ° cÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i, Chung vÃ  cá»™ng sá»± [9] táº­p trung vÃ o má»™t loáº¡t Ä‘Ã¡nh giÃ¡ benchmark táº­p trung xung quanh tÃ­nh thá»±c táº¿ vÃ  lÃ½ luáº­n, nhÆ°ng chá»§ yáº¿u bá» qua kháº£ nÄƒng tuÃ¢n theo hÆ°á»›ng dáº«n má»Ÿ. CÃ¡c phÃ¡t hÃ nh cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘á»™c quyá»n lá»›n (Ä‘Ã³ng) nhÆ° GPT-4 [34] vÃ  PaLM v2 [2] thÆ°á»ng Ä‘i kÃ¨m vá»›i cÃ¡c Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n trÃªn nhiá»u benchmark khÃ¡c nhau, máº·c dÃ¹ cáº£ hai Ä‘á»u tÆ°Æ¡ng tá»± bá» qua Ä‘Ã¡nh giÃ¡ tuÃ¢n theo hÆ°á»›ng dáº«n má»Ÿ, vÃ  khÃ´ng cÃ³ phÃ¡t hÃ nh má»Ÿ cá»§a dá»¯ liá»‡u huáº¥n luyá»‡n trÆ°á»›c hoáº·c Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n thÃ¬ khÃ´ng cÃ³ cÃ¡ch nÃ o Ä‘á»ƒ kiá»ƒm tra contamination dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡.

Gáº§n Ä‘Ã¢y, cÃ¡c khung Ä‘Ã¡nh giÃ¡ nhÆ° AlpacaEval [27] vÃ  Chatbot Arena [55] Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» xuáº¥t Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng tuÃ¢n theo hÆ°á»›ng dáº«n má»Ÿ cá»§a LM, vÆ°á»£t qua cÃ¡c Ä‘Ã¡nh giÃ¡ dá»±a trÃªn benchmark. Nhá»¯ng khung nÃ y hoáº·c sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh khÃ¡c (trong trÆ°á»ng há»£p AlpacaEval) hoáº·c con ngÆ°á»i (trong trÆ°á»ng há»£p Chatbot Arena) lÃ m ngÆ°á»i chÃº thÃ­ch Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ¡c tháº¿ há»‡ mÃ´ hÃ¬nh. ChÃºng tÃ´i sá»­ dá»¥ng cÃ´ng trÃ¬nh gáº§n Ä‘Ã¢y nÃ y vÃ  Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i trÃªn cÃ¡c benchmark truyá»n thá»‘ng, Ä‘Ã¡nh giÃ¡ dá»±a trÃªn mÃ´ hÃ¬nh, vÃ  Ä‘Ã¡nh giÃ¡ dá»±a trÃªn con ngÆ°á»i. Äá»“ng thá»i vá»›i cÃ´ng trÃ¬nh nÃ y, Gudibande vÃ  cá»™ng sá»± [20] kiá»ƒm tra cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn Ä‘áº§u ra mÃ´ hÃ¬nh GPT vÃ  tranh luáº­n ráº±ng cÃ¡c mÃ´ hÃ¬nh nhÆ° váº­y há»c Ä‘á»ƒ báº¯t chÆ°á»›c chá»‰ phong cÃ¡ch, khÃ´ng pháº£i ná»™i dung, cá»§a cÃ¡c mÃ´ hÃ¬nh GPT giÃ¡o viÃªn cá»§a chÃºng. Trong khi chÃºng tÃ´i tÆ°Æ¡ng tá»± tháº¥y ráº±ng cÃ¡c táº­p dá»¯ liá»‡u hiá»‡n cÃ³ khÃ´ng thá»ƒ huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh gáº§n vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘á»™c quyá»n máº¡nh máº½, tÃ­nh Ä‘a dáº¡ng cá»§a hiá»‡u suáº¥t chÃºng tÃ´i quan sÃ¡t trÃªn cÃ¡c táº­p dá»¯ liá»‡u gá»£i Ã½ ráº±ng cÃ¡c cáº£i thiá»‡n hiá»‡u suáº¥t Ä‘Ã¡ng ká»ƒ cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c thÃ´ng qua dá»¯ liá»‡u báº¯t chÆ°á»›c, miá»…n lÃ  nÃ³ chá»©a má»™t táº­p há»£p Ä‘a dáº¡ng vÃ  rá»™ng rÃ£i cÃ¡c ká»¹ nÄƒng vÃ  miá»n.

7 Káº¿t luáº­n

Trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i cung cáº¥p má»™t Ä‘Ã¡nh giÃ¡ má»Ÿ rá»™ng vá» nhiá»u tÃ i nguyÃªn cÃ³ sáºµn cÃ´ng khai Ä‘á»ƒ Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n cÃ¡c mÃ´ hÃ¬nh, vÃ  so sÃ¡nh chÃºng vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘á»™c quyá»n máº¡nh nháº¥t hiá»‡n cÃ³. ChÃºng tÃ´i tháº¥y ráº±ng sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ máº¡nh máº½ lÃ  quan trá»ng Ä‘á»‘i vá»›i hiá»‡u suáº¥t, káº¿t há»£p cÃ¡c táº­p dá»¯ liá»‡u hoáº¡t Ä‘á»™ng tá»‘t nháº¥t trung bÃ¬nh (nhÆ°ng dáº«n Ä‘áº¿n giáº£m hiá»‡u suáº¥t nháº¹ so vá»›i hiá»‡u suáº¥t tá»‘t nháº¥t trong cÃ¡c nhiá»‡m vá»¥ cá»¥ thá»ƒ), vÃ  cÃ¡c mÃ´ hÃ¬nh má»Ÿ máº¡nh nháº¥t cá»§a chÃºng tÃ´i chÆ°a sÃ¡nh báº±ng ChatGPT hoáº·c GPT-4. HÆ¡n ná»¯a, chÃºng tÃ´i tin ráº±ng Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i ná»•i báº­t nhu cáº§u tiáº¿p tá»¥c phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ máº¡nh máº½ vÃ  cÃ¡c táº­p dá»¯ liá»‡u rá»™ng rÃ£i, Ä‘a dáº¡ng hÆ¡n. Cuá»‘i cÃ¹ng, chÃºng tÃ´i hy vá»ng ráº±ng Ä‘Ã¡nh giÃ¡ vÃ  mÃ£ vÃ  mÃ´ hÃ¬nh Ä‘Æ°á»£c phÃ¡t hÃ nh cá»§a chÃºng tÃ´i cho phÃ©p cÃ¡c Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n hÆ¡n vÃ  thÃºc Ä‘áº©y nghiÃªn cá»©u Ä‘á»ƒ thu háº¹p nhá»¯ng khoáº£ng cÃ¡ch nÃ y vÃ  lÃ m sÃ¡ng tá» táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n, Ä‘Ã³ng hay má»Ÿ.

Lá»i cáº£m Æ¡n

CÃ´ng viá»‡c táº¡i UW Ä‘Æ°á»£c há»— trá»£ má»™t pháº§n bá»Ÿi VÄƒn phÃ²ng NghiÃªn cá»©u Háº£i quÃ¢n dÆ°á»›i grantMURI N00014-18-1-2670, CÆ¡ quan Dá»± Ã¡n NghiÃªn cá»©u Quá»‘c phÃ²ng TiÃªn tiáº¿n (DARPA) dÆ°á»›i Há»£p Ä‘á»“ng sá»‘ FA8650-23-C-7316 vÃ  chÆ°Æ¡ng trÃ¬nh MCS thÃ´ng qua NIWC Pacific (N66001-19-2-4031), NSF IIS-2044660, vÃ  má»™t mÃ³n quÃ  tá»« Apple. ChÃºng tÃ´i cáº£m Æ¡n cÃ¡c Ä‘á»“ng nghiá»‡p táº¡i AI2 vÃ  UW NLP vÃ¬ pháº£n há»“i xÃ¢y dá»±ng vÃ  há»— trá»£ trÃ­ tuá»‡ cá»§a há». ChÃºng tÃ´i Ä‘áº·c biá»‡t biáº¿t Æ¡n Tim Dettmers vÃ¬ cÃ¡c gá»£i Ã½ cá»§a Ã´ng vá» cÃ¡c ká»¹ thuáº­t suy luáº­n hiá»‡u quáº£, vÃ  Artidoro Pagnoni vÃ¬ cung cáº¥p táº­p dá»¯ liá»‡u FLAN V2 Ä‘Æ°á»£c tÃ¡i táº¡o. ChÃºng tÃ´i

--- TRANG 11 ---
cÅ©ng thá»«a nháº­n sá»± há»— trá»£ tá»« AMD vÃ  cá»¥m LUMI cá»§a CSC, vÃ  nhÃ³m Beaker táº¡i AI2, Ä‘Ã£ cung cáº¥p cÆ¡ sá»Ÿ háº¡ táº§ng tÃ­nh toÃ¡n thiáº¿t yáº¿u cho cÃ¡c thÃ­ nghiá»‡m cá»§a chÃºng tÃ´i. Cuá»‘i cÃ¹ng, chÃºng tÃ´i chÃ¢n thÃ nh cáº£m Æ¡n nhá»¯ng ngÆ°á»i Ä‘Ã³ng gÃ³p sau Ä‘Ã¢y cho Ä‘Ã¡nh giÃ¡ con ngÆ°á»i cá»§a chÃºng tÃ´i: Valentina Pyatkin, Clara Na, Yuling Gu, Yuchen Lin, Haiyan He, David Graham, Hao Peng, Hyunwoo Kim, Alisa Liu, Youngjae Yu, Tal August, vÃ  Egor Klevak.

TÃ i liá»‡u tham kháº£o

[1] E. Almazrouei, H. Alobeidli, A. Alshamsi, A. Cappelli, R. Cojocaru, M. Debbah, E. Goffinet, D. Heslow, J. Launay, Q. Malartic, B. Noune, B. Pannier, vÃ  G. Penedo. Falcon-40B: má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n má»Ÿ vá»›i hiá»‡u suáº¥t tiÃªn tiáº¿n. PhÃ¡t hÃ nh MÃ´ hÃ¬nh Huggingface, 2023. URL https://huggingface.co/tiiuae/falcon-40b.

[2] R. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, A. Passos, S. Shakeri, E. Taropa, P. Bailey, Z. Chen, vÃ  cá»™ng sá»±. BÃ¡o cÃ¡o ká»¹ thuáº­t Palm 2. arXiv preprint arXiv:2305.10403, 2023.

[3] Y. Bai, A. Jones, K. Ndousse, A. Askell, A. Chen, N. DasSarma, D. Drain, S. Fort, D. Ganguli, T. Henighan, vÃ  cá»™ng sá»±. Huáº¥n luyá»‡n má»™t trá»£ lÃ½ há»¯u Ã­ch vÃ  vÃ´ háº¡i vá»›i há»c tÄƒng cÆ°á»ng tá»« pháº£n há»“i con ngÆ°á»i. arXiv preprint arXiv:2204.05862, 2022.

[4] S. Biderman, H. Schoelkopf, Q. G. Anthony, H. Bradley, K. O'Brien, E. Hallahan, M. A. Khan, S. Purohit, U. S. Prashanth, E. Raff, vÃ  cá»™ng sá»±. Pythia: Má»™t bá»™ Ä‘á»ƒ phÃ¢n tÃ­ch cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n trÃªn kháº¯p huáº¥n luyá»‡n vÃ  má»Ÿ rá»™ng. Trong Há»™i nghá»‹ Quá»‘c táº¿ vá» Há»c MÃ¡y, trang 2397â€“2430. PMLR, 2023.

[5] T. Cai, X. Wang, T. Ma, X. Chen, vÃ  D. Zhou. CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n nhÆ° ngÆ°á»i táº¡o cÃ´ng cá»¥. arXiv preprint arXiv:2305.17126, 2023.

[6] S. Chaudhary. Code alpaca: Má»™t mÃ´ hÃ¬nh llama tuÃ¢n theo hÆ°á»›ng dáº«n cho táº¡o mÃ£. Kho GitHub, 2023. URL https://github.com/sahil280114/codealpaca.

[7] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, vÃ  cá»™ng sá»±. ÄÃ¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn mÃ£. arXiv preprint arXiv:2107.03374, 2021.

[8] W.-L. Chiang, Z. Li, Z. Lin, Y. Sheng, Z. Wu, H. Zhang, L. Zheng, S. Zhuang, Y. Zhuang, J. E. Gonzalez, I. Stoica, vÃ  E. P. Xing. Vicuna: Má»™t chatbot mÃ£ nguá»“n má»Ÿ áº¥n tÆ°á»£ng vá»›i gpt-4 vá»›i cháº¥t lÆ°á»£ng 90%* chatgpt. BÃ i Ä‘Äƒng blog, thÃ¡ng 3 2023. URL https://lmsys.org/blog/2023-03-30-vicuna/.

[9] H. W. Chung, L. Hou, S. Longpre, B. Zoph, Y. Tay, W. Fedus, E. Li, X. Wang, M. Dehghani, S. Brahma, vÃ  cá»™ng sá»±. Má»Ÿ rá»™ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c tinh chá»‰nh hÆ°á»›ng dáº«n. arXiv preprint arXiv:2210.11416, 2022.

[10] J. H. Clark, E. Choi, M. Collins, D. Garrette, T. Kwiatkowski, V. Nikolaev, vÃ  J. Palomaki. TyDiQA: Má»™t benchmark cho há»i Ä‘Ã¡p tÃ¬m kiáº¿m thÃ´ng tin trong cÃ¡c ngÃ´n ngá»¯ Ä‘a dáº¡ng vá» loáº¡i hÃ¬nh. TACL, 2020. URL https://arxiv.org/abs/2003.05002.

[11] K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser, M. Plappert, J. Tworek, J. Hilton, R. Nakano, C. Hesse, vÃ  J. Schulman. Huáº¥n luyá»‡n cÃ¡c trÃ¬nh xÃ¡c minh Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n tá»« toÃ¡n há»c. arXiv preprint arXiv:2110.14168, 2021.

[12] Databricks. Dolly miá»…n phÃ­: Giá»›i thiá»‡u llm Ä‘Æ°á»£c Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n thá»±c sá»± má»Ÿ Ä‘áº§u tiÃªn trÃªn tháº¿ giá»›i. BÃ i Ä‘Äƒng blog, 2023. URL https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm.

[13] T. Dettmers, M. Lewis, Y. Belkada, vÃ  L. Zettlemoyer. LLM.int8(): NhÃ¢n ma tráº­n 8-bit cho transformer á»Ÿ quy mÃ´. Trong Tiáº¿n bá»™ trong Há»‡ thá»‘ng Xá»­ lÃ½ ThÃ´ng tin Tháº§n kinh, 2022.

[14] T. Dettmers, A. Pagnoni, A. Holtzman, vÃ  L. Zettlemoyer. Qlora: Tinh chá»‰nh hiá»‡u quáº£ cÃ¡c llm Ä‘Æ°á»£c lÆ°á»£ng tá»­ hÃ³a. arXiv preprint arXiv:2305.14314, 2023.

--- TRANG 12 ---
[15] N. Ding, Y. Chen, B. Xu, S. Hu, Y. Qin, Z. Liu, M. Sun, vÃ  B. Zhou. Ultrachat: Dá»¯ liá»‡u há»™i thoáº¡i Ä‘a vÃ²ng tá»± Ä‘á»™ng táº¡o quy mÃ´ lá»›n. Kho GitHub, 2023. URL https://github.com/thunlp/ultrachat.

[16] Y. Dubois, X. Li, R. Taori, T. Zhang, I. Gulrajani, J. Ba, C. Guestrin, P. Liang, vÃ  T. B. Hashimoto. Alpacafarm: Má»™t khung mÃ´ phá»ng cho cÃ¡c phÆ°Æ¡ng phÃ¡p há»c tá»« pháº£n há»“i con ngÆ°á»i. arXiv preprint arXiv:2305.14387, 2023.

[17] L. Gao, J. Tow, S. Biderman, S. Black, A. DiPofi, C. Foster, L. Golding, J. Hsu, K. McDonell, N. Muennighoff, J. Phang, L. Reynolds, E. Tang, A. Thite, B. Wang, K. Wang, vÃ  A. Zou. Má»™t khung cho Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh ngÃ´n ngá»¯ few-shot, thÃ¡ng 9 2021. URL https://doi.org/10.5281/zenodo.5371628.

[18] X. Geng vÃ  H. Liu. Openllama: Má»™t tÃ¡i táº¡o má»Ÿ cá»§a llama. Kho GitHub, 2023. URL https://github.com/openlm-research/open_llama.

[19] X. Geng, A. Gudibande, H. Liu, E. Wallace, P. Abbeel, S. Levine, vÃ  D. Song. Koala: Má»™t mÃ´ hÃ¬nh há»™i thoáº¡i cho nghiÃªn cá»©u há»c thuáº­t. BÃ i Ä‘Äƒng blog, thÃ¡ng 4 2023. URL https://bair.berkeley.edu/blog/2023/04/03/koala/.

[20] A. Gudibande, E. Wallace, C. Snell, X. Geng, H. Liu, P. Abbeel, S. Levine, vÃ  D. Song. Lá»i há»©a sai láº§m cá»§a viá»‡c báº¯t chÆ°á»›c cÃ¡c llm Ä‘á»™c quyá»n. arXiv preprint arXiv:2305.15717, 2023.

[21] T. Hartvigsen, S. Gabriel, H. Palangi, M. Sap, D. Ray, vÃ  E. Kamar. TOXIGEN: Äiá»u khiá»ƒn CÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Ä‘á»ƒ Táº¡o ra TÃ­nh Ä‘á»™c háº¡i Ngá»¥ Ã½ vÃ  Äá»‘i khÃ¡ng. Trong ACL, 2022. URL https://arxiv.org/abs/2203.09509.

[22] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, vÃ  J. Steinhardt. Äo lÆ°á»ng hiá»ƒu biáº¿t ngÃ´n ngá»¯ Ä‘a nhiá»‡m vá»¥ khá»•ng lá»“. Trong Há»™i nghá»‹ Quá»‘c táº¿ vá» Biá»ƒu diá»…n Há»c táº­p (ICLR), 2020.

[23] O. Honovich, T. Scialom, O. Levy, vÃ  T. Schick. HÆ°á»›ng dáº«n khÃ´ng tá»± nhiÃªn: Äiá»u chá»‰nh cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ vá»›i (gáº§n nhÆ°) khÃ´ng cÃ³ lao Ä‘á»™ng con ngÆ°á»i. arXiv preprint arXiv:2212.09689, 2022.

[24] S. Iyer, X. V. Lin, R. Pasunuru, T. Mihaylov, D. Simig, P. Yu, K. Shuster, T. Wang, Q. Liu, P. S. Koura, vÃ  cá»™ng sá»±. Opt-iml: Má»Ÿ rá»™ng meta há»c táº­p hÆ°á»›ng dáº«n mÃ´ hÃ¬nh ngÃ´n ngá»¯ thÃ´ng qua lÄƒng kÃ­nh tá»•ng quÃ¡t hÃ³a. arXiv preprint arXiv:2212.12017, 2022.

[25] A. KÃ¶ksal, T. Schick, A. Korhonen, vÃ  H. SchÃ¼tze. Longform: Tá»‘i Æ°u hÃ³a Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n cho táº¡o vÄƒn báº£n dÃ i vá»›i trÃ­ch xuáº¥t táº­p dá»¯ liá»‡u. arXiv preprint arXiv:2304.08460, 2023.

[26] A. KÃ¶pf, Y. Kilcher, D. von RÃ¼tte, S. Anagnostidis, Z.-R. Tam, K. Stevens, A. Barhoum, N. M. Duc, O. Stanley, R. Nagyfi, vÃ  cá»™ng sá»±. CÃ¡c cuá»™c há»™i thoáº¡i trá»£ lÃ½ má»Ÿ â€“ dÃ¢n chá»§ hÃ³a viá»‡c cÄƒn chá»‰nh mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n. arXiv preprint arXiv:2304.07327, 2023.

[27] X. Li, T. Zhang, Y. Dubois, R. Taori, I. Gulrajani, C. Guestrin, P. Liang, vÃ  T. B. Hashimoto. Alpacaeval: Má»™t trÃ¬nh Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng cá»§a cÃ¡c mÃ´ hÃ¬nh tuÃ¢n theo hÆ°á»›ng dáº«n. Kho Github, 2023. URL https://github.com/tatsu-lab/alpaca_eval.

[28] P. Liang, R. Bommasani, T. Lee, D. Tsipras, D. Soylu, M. Yasunaga, Y. Zhang, D. Narayanan, Y. Wu, A. Kumar, B. Newman, B. Yuan, B. Yan, C. Zhang, C. Cosgrove, C. D. Manning, C. RÃ©, D. Acosta-Navas, D. A. Hudson, E. Zelikman, E. Durmus, F. Ladhak, F. Rong, H. Ren, H. Yao, J. Wang, K. Santhanam, L. J. Orr, L. Zheng, M. Yuksekgonul, M. Suzgun, N. S. Kim, N. Guha, N. S. Chatterji, O. Khattab, P. Henderson, Q. Huang, R. Chi, S. M. Xie, S. Santurkar, S. Ganguli, T. Hashimoto, T. F. Icard, T. Zhang, V. Chaudhary, W. Wang, X. Li, Y. Mai, Y. Zhang, vÃ  Y. Koreeda. ÄÃ¡nh giÃ¡ toÃ n diá»‡n cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯. BiÃªn niÃªn Viá»‡n HÃ n lÃ¢m Khoa há»c New York, 2022.

[29] S. Lin, J. Hilton, vÃ  O. Evans. TruthfulQA: Äo lÆ°á»ng cÃ¡ch cÃ¡c mÃ´ hÃ¬nh báº¯t chÆ°á»›c nhá»¯ng Ä‘iá»u sai láº§m cá»§a con ngÆ°á»i. Trong Ká»· yáº¿u Há»™i nghá»‹ ThÆ°á»ng niÃªn láº§n thá»© 60 cá»§a Hiá»‡p há»™i NgÃ´n ngá»¯ há»c TÃ­nh toÃ¡n (Táº­p 1: BÃ i bÃ¡o DÃ i), trang 3214â€“3252, Dublin, Ireland, thÃ¡ng 5 2022. Hiá»‡p há»™i NgÃ´n ngá»¯ há»c TÃ­nh toÃ¡n. doi: 10.18653/v1/2022.acl-long.229. URL https://aclanthology.org/2022.acl-long.229.

[30] S. Lin, J. Hilton, vÃ  O. Evans. Truthfulqa: Äo lÆ°á»ng cÃ¡ch cÃ¡c mÃ´ hÃ¬nh báº¯t chÆ°á»›c nhá»¯ng Ä‘iá»u sai láº§m cá»§a con ngÆ°á»i. Trong Ká»· yáº¿u Há»™i nghá»‹ ThÆ°á»ng niÃªn láº§n thá»© 60 cá»§a Hiá»‡p há»™i NgÃ´n ngá»¯ há»c TÃ­nh toÃ¡n (Táº­p 1: BÃ i bÃ¡o DÃ i), trang 3214â€“3252, 2022.

[31] S. Longpre, L. Hou, T. Vu, A. Webson, H. W. Chung, Y. Tay, D. Zhou, Q. V. Le, B. Zoph, J. Wei, vÃ  cá»™ng sá»±. Bá»™ sÆ°u táº­p flan: Thiáº¿t káº¿ dá»¯ liá»‡u vÃ  phÆ°Æ¡ng phÃ¡p cho Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n hiá»‡u quáº£. arXiv preprint arXiv:2301.13688, 2023.

[32] S. Mishra, D. Khashabi, C. Baral, vÃ  H. Hajishirzi. Tá»•ng quÃ¡t hÃ³a Nhiá»‡m vá»¥ ChÃ©o thÃ´ng qua HÆ°á»›ng dáº«n Crowdsourcing NgÃ´n ngá»¯ Tá»± nhiÃªn. Trong Há»™i nghá»‹ ThÆ°á»ng niÃªn cá»§a Hiá»‡p há»™i NgÃ´n ngá»¯ há»c TÃ­nh toÃ¡n (ACL), 2022.

[33] MosaicML. Giá»›i thiá»‡u mpt-7b: Má»™t tiÃªu chuáº©n má»›i cho cÃ¡c llm mÃ£ nguá»“n má»Ÿ, cÃ³ thá»ƒ sá»­ dá»¥ng thÆ°Æ¡ng máº¡i. BÃ i Ä‘Äƒng blog, 2023. URL https://www.mosaicml.com/blog/mpt-7b.

[34] OpenAI. BÃ¡o cÃ¡o ká»¹ thuáº­t gpt-4. arXiv preprint arXiv:2303.08774, 2023.

[35] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, vÃ  cá»™ng sá»±. Huáº¥n luyá»‡n CÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Ä‘á»ƒ TuÃ¢n theo HÆ°á»›ng dáº«n vá»›i Pháº£n há»“i Con ngÆ°á»i. Trong Tiáº¿n bá»™ trong Há»‡ thá»‘ng Xá»­ lÃ½ ThÃ´ng tin Tháº§n kinh (NeurIPS), 2022.

[36] B. Peng, C. Li, P. He, M. Galley, vÃ  J. Gao. Äiá»u chá»‰nh hÆ°á»›ng dáº«n vá»›i gpt-4. arXiv preprint arXiv:2304.03277, 2023.

[37] S. Rajbhandari, J. Rasley, O. Ruwase, vÃ  Y. He. Zero: Tá»‘i Æ°u hÃ³a bá»™ nhá»› hÆ°á»›ng tá»›i huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh nghÃ¬n tá»· tham sá»‘. Trong Ká»· yáº¿u Há»™i nghá»‹ Quá»‘c táº¿ vá» Äiá»‡n toÃ¡n Hiá»‡u nÄƒng Cao, Máº¡ng, LÆ°u trá»¯ vÃ  PhÃ¢n tÃ­ch, SC '20. IEEE Press, 2020. ISBN 9781728199986.

[38] J. Rasley, S. Rajbhandari, O. Ruwase, vÃ  Y. He. Deepspeed: Tá»‘i Æ°u hÃ³a há»‡ thá»‘ng cho phÃ©p huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u vá»›i hÆ¡n 100 tá»· tham sá»‘. Trong Ká»· yáº¿u Há»™i nghá»‹ Quá»‘c táº¿ ACM SIGKDD láº§n thá»© 26 vá» KhÃ¡m phÃ¡ Kiáº¿n thá»©c & Khai thÃ¡c Dá»¯ liá»‡u, 2020.

[39] V. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, A. Chaffin, A. Stiegler, A. Raja, M. Dey, M. S. Bari, C. Xu, U. Thakker, S. S. Sharma, E. Szczechla, T. Kim, G. Chhablani, N. Nayak, D. Datta, J. Chang, M. T.-J. Jiang, H. Wang, M. Manica, S. Shen, Z. X. Yong, H. Pandey, R. Bawden, T. Wang, T. Neeraj, J. Rozen, A. Sharma, A. Santilli, T. Fevry, J. A. Fries, R. Teehan, T. L. Scao, S. Biderman, L. Gao, T. Wolf, vÃ  A. M. Rush. Huáº¥n luyá»‡n Äa nhiá»‡m vá»¥ ÄÆ°á»£c nháº¯c nhá»Ÿ Cho phÃ©p Tá»•ng quÃ¡t hÃ³a Nhiá»‡m vá»¥ Zero-Shot. Trong Há»™i nghá»‹ Quá»‘c táº¿ vá» Biá»ƒu diá»…n Há»c táº­p (ICLR), 2022.

[40] N. Shazeer, A. Mirhoseini, K. Maziarz, A. Davis, Q. Le, G. Hinton, vÃ  J. Dean. Máº¡ng tháº§n kinh cá»±c lá»›n: Lá»›p chuyÃªn gia há»—n há»£p cá»•ng thÆ°a thá»›t. Trong Há»™i nghá»‹ Quá»‘c táº¿ vá» Biá»ƒu diá»…n Há»c táº­p, 2017.

[41] A. Srivastava, A. Rastogi, A. Rao, A. A. M. Shoeb, A. Abid, A. Fisch, A. R. Brown, A. Santoro, vÃ  Ä‘á»“ng nghiá»‡p. VÆ°á»£t qua trÃ² chÆ¡i báº¯t chÆ°á»›c: Äá»‹nh lÆ°á»£ng vÃ  ngoáº¡i suy cÃ¡c kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯. arXiv preprint arXiv:2206.04615, 2022.

[42] M. Suzgun, N. Scales, N. SchÃ¤rli, S. Gehrmann, Y. Tay, H. W. Chung, A. Chowdhery, Q. V. Le, E. H. Chi, D. Zhou, vÃ  cá»™ng sá»±. Thá»­ thÃ¡ch cÃ¡c nhiá»‡m vá»¥ big-bench khÃ³ vÃ  liá»‡u chuá»—i suy nghÄ© cÃ³ thá»ƒ giáº£i quyáº¿t chÃºng khÃ´ng. arXiv preprint arXiv:2210.09261, 2022.

[43] R. Taori, I. Gulrajani, T. Zhang, Y. Dubois, X. Li, C. Guestrin, P. Liang, vÃ  T. B. Hashimoto. Stanford alpaca: Má»™t mÃ´ hÃ¬nh llama tuÃ¢n theo hÆ°á»›ng dáº«n. Kho GitHub, 2023. URL https://github.com/tatsu-lab/stanford_alpaca.

[44] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. RoziÃ¨re, N. Goyal, E. Hambro, F. Azhar, vÃ  cá»™ng sá»±. Llama: CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ ná»n táº£ng má»Ÿ vÃ  hiá»‡u quáº£. arXiv preprint arXiv:2302.13971, 2023.

[45] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale, vÃ  cá»™ng sá»±. Llama 2: CÃ¡c mÃ´ hÃ¬nh chat ná»n táº£ng má»Ÿ vÃ  Ä‘Æ°á»£c tinh chá»‰nh. arXiv preprint arXiv:2307.09288, 2023.

--- TRANG 13 ---
[46] P. Wang, L. Li, L. Chen, D. Zhu, B. Lin, Y. Cao, Q. Liu, T. Liu, vÃ  Z. Sui. CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n khÃ´ng pháº£i lÃ  nhá»¯ng ngÆ°á»i Ä‘Ã¡nh giÃ¡ cÃ´ng báº±ng. arXiv preprint arXiv:2305.17926, 2023.

[47] Y. Wang, Y. Kordi, S. Mishra, A. Liu, N. A. Smith, D. Khashabi, vÃ  H. Hajishirzi. Self-instruct: CÄƒn chá»‰nh mÃ´ hÃ¬nh ngÃ´n ngá»¯ vá»›i hÆ°á»›ng dáº«n tá»± táº¡o. arXiv preprint arXiv:2212.10560, 2022.

[48] Y. Wang, S. Mishra, P. Alipoormolabashi, Y. Kordi, A. Mirzaei, A. Arunkumar, A. Ashok, A. S. Dhanasekaran, A. Naik, D. Stap, vÃ  cá»™ng sá»±. Super-NaturalInstructions: Tá»•ng quÃ¡t hÃ³a thÃ´ng qua HÆ°á»›ng dáº«n TuyÃªn bá»‘ trÃªn 1600+ Nhiá»‡m vá»¥. Trong EMNLP, 2022.

[49] J. Wei, M. Bosma, V. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, vÃ  Q. V. Le. CÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ ÄÆ°á»£c Tinh chá»‰nh lÃ  NgÆ°á»i há»c Zero-Shot. Trong Há»™i nghá»‹ Quá»‘c táº¿ vá» Biá»ƒu diá»…n Há»c táº­p (ICLR), 2022.

[50] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. Chi, Q. Le, vÃ  D. Zhou. Lá»i nháº¯c chuá»—i suy nghÄ© gá»£i ra lÃ½ luáº­n trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n. arXiv preprint arXiv:2201.11903, 2022.

[51] O. Weller, N. Lourie, M. Gardner, vÃ  M. E. Peters. Há»c tá»« mÃ´ táº£ nhiá»‡m vá»¥. Trong Ká»· yáº¿u Há»™i nghá»‹ 2020 vá» PhÆ°Æ¡ng phÃ¡p Thá»±c nghiá»‡m trong Xá»­ lÃ½ NgÃ´n ngá»¯ Tá»± nhiÃªn (EMNLP), trang 1361â€“1375, Trá»±c tuyáº¿n, thÃ¡ng 11 2020. Hiá»‡p há»™i NgÃ´n ngá»¯ há»c TÃ­nh toÃ¡n. doi: 10.18653/v1/2020.emnlp-main.105. URL https://aclanthology.org/2020.emnlp-main.105.

[52] C. Xu, D. Guo, N. Duan, vÃ  J. McAuley. Baize: Má»™t mÃ´ hÃ¬nh chat mÃ£ nguá»“n má»Ÿ vá»›i Ä‘iá»u chá»‰nh hiá»‡u quáº£ tham sá»‘ trÃªn dá»¯ liá»‡u tá»± chat. arXiv preprint arXiv:2304.01196, 2023.

[53] C. Xu, Q. Sun, K. Zheng, X. Geng, P. Zhao, J. Feng, C. Tao, vÃ  D. Jiang. Wizardlm: Trao quyá»n cho cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n Ä‘á»ƒ tuÃ¢n theo hÆ°á»›ng dáº«n phá»©c táº¡p. arXiv preprint arXiv:2304.12244, 2023.

[54] S. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. Dewan, M. Diab, X. Li, X. V. Lin, vÃ  cá»™ng sá»±. Opt: CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ transformer Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c má»Ÿ. arXiv preprint arXiv:2205.01068, 2022.

[55] L. Zheng, Y. Sheng, W.-L. Chiang, H. Zhang, J. E. Gonzalez, vÃ  I. Stoica. Chatbot Arena: ÄÃ¡nh giÃ¡ chuáº©n LLM trong tá»± nhiÃªn vá»›i xáº¿p háº¡ng Elo. BÃ i Ä‘Äƒng blog, thÃ¡ng 5 2023. URL https://lmsys.org/blog/2023-05-03-arena/.

[56] C. Zhou, P. Liu, P. Xu, S. Iyer, J. Sun, Y. Mao, X. Ma, A. Efrat, P. Yu, L. Yu, vÃ  cá»™ng sá»±. Lima: Ãt hÆ¡n lÃ  nhiá»u hÆ¡n cho viá»‡c cÄƒn chá»‰nh. arXiv preprint arXiv:2305.11206, 2023.

--- TRANG 14 ---
TÃ i liá»‡u bá»• sung

A Háº¡n cháº¿

Máº·c dÃ¹ tÃ­nh toÃ n diá»‡n cá»§a cÃ¡c Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i, chÃºng tÃ´i lÆ°u Ã½ ráº±ng chÃºng tÃ´i khÃ´ng bao gá»“m háº¿t táº¥t cáº£ cÃ¡c Ä‘Ã¡nh giÃ¡ cÃ³ thá»ƒ: vÃ­ dá»¥, chÃºng tÃ´i khÃ´ng Ä‘Ã¡nh giÃ¡ rÃµ rÃ ng cÃ¡c mÃ´ hÃ¬nh vá» kháº£ nÄƒng há»™i thoáº¡i Ä‘a lÆ°á»£t cá»§a chÃºng hay kháº£ nÄƒng tÃ³m táº¯t cá»§a chÃºng. Thay vÃ o Ä‘Ã³, chÃºng tÃ´i táº­p trung vÃ o má»™t táº­p há»£p cá»‘t lÃµi cÃ¡c kháº£ nÄƒng chÃºng tÃ´i tin lÃ  quan trá»ng, vÃ  bao gá»“m cÃ¡c nhiá»‡m vá»¥ má»Ÿ rá»™ng thÃ´ng qua cÃ¡c Ä‘Ã¡nh giÃ¡ dá»±a trÃªn sá»Ÿ thÃ­ch mÃ´ hÃ¬nh vÃ  con ngÆ°á»i cá»§a chÃºng tÃ´i.

ChÃºng tÃ´i cÅ©ng lÆ°u Ã½ ráº±ng chÃºng tÃ´i khÃ´ng bao gá»“m táº¥t cáº£ cÃ¡c táº­p dá»¯ liá»‡u hÆ°á»›ng dáº«n vÃ  mÃ´ hÃ¬nh má»Ÿ cÃ³ thá»ƒ Ä‘Æ°á»£c phÃ¡t hÃ nh gáº§n Ä‘Ã¢y, do chi phÃ­ tÃ­nh toÃ¡n cá»§a viá»‡c thá»±c hiá»‡n Ä‘iá»u nÃ y. Thay vÃ o Ä‘Ã³, chÃºng tÃ´i táº­p trung vÃ o má»™t táº­p há»£p rá»™ng cÃ¡c táº­p dá»¯ liá»‡u chÃºng tÃ´i tin lÃ  Ä‘áº¡i diá»‡n rá»™ng rÃ£i cho loáº¡i táº­p dá»¯ liá»‡u hÆ°á»›ng dáº«n má»Ÿ cÃ³ sáºµn (do con ngÆ°á»i viáº¿t, nháº¯m má»¥c tiÃªu ká»¹ nÄƒng, chÆ°ng cáº¥t GPT, v.v.), vÃ  táº­p trung vÃ o mÃ´ hÃ¬nh cÆ¡ sá»Ÿ máº¡nh nháº¥t cÃ³ sáºµn rá»™ng rÃ£i khi thá»±c hiá»‡n thÃ­ nghiá»‡m. CÃ´ng viá»‡c tÆ°Æ¡ng lai cÃ³ thá»ƒ Ä‘iá»u tra liá»‡u cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ máº¡nh máº½ gáº§n Ä‘Ã¢y hÆ¡n (vÃ­ dá»¥: mÃ´ hÃ¬nh Falcon [1]), hoáº·c cÃ¡c táº­p dá»¯ liá»‡u hÆ°á»›ng dáº«n khÃ¡c, thá»±c hiá»‡n Ä‘Ã¡ng ká»ƒ tá»‘t hÆ¡n hoáº·c khÃ¡c biá»‡t so vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c khÃ¡m phÃ¡ trong cÃ´ng trÃ¬nh nÃ y.

Cuá»‘i cÃ¹ng, chÃºng tÃ´i lÆ°u Ã½ ráº±ng Ä‘Ã¡nh giÃ¡ dá»±a trÃªn hÆ°á»›ng dáº«n má»Ÿ cÃ³ tÃ­nh chá»§ quan cao vÃ  khÃ³ khÄƒn do báº£n cháº¥t cá»±c ká»³ má»Ÿ cá»§a nÃ³. CÃ³ kháº£ nÄƒng khÃ´ng cÃ³ má»™t cÃ¢u tráº£ lá»i nÃ o cháº¯c cháº¯n lÃ  tá»‘t nháº¥t cho báº¥t ká»³ truy váº¥n nÃ o, vÃ  cÃ¡c ngÆ°á»i chÃº thÃ­ch khÃ¡c nhau (dÃ¹ lÃ  con ngÆ°á»i hay mÃ´ hÃ¬nh) sáº½ cÃ³ nhá»¯ng thiÃªn vá»‹ vÃ  sá»Ÿ thÃ­ch khÃ¡c nhau. ChÃºng tÃ´i cÅ©ng lÆ°u Ã½ ráº±ng trong trÆ°á»ng há»£p Ä‘Ã¡nh giÃ¡ dá»±a trÃªn mÃ´ hÃ¬nh, chÃºng tÃ´i chá»§ yáº¿u so sÃ¡nh Ä‘áº§u ra mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i vá»›i cÃ¡c tháº¿ há»‡ Davinci-003, cÃ³ thá»ƒ dáº«n Ä‘áº¿n viá»‡c thÆ°á»Ÿng quÃ¡ má»©c cho cÃ¡c mÃ´ hÃ¬nh trÃ¡nh nhá»¯ng thiáº¿u sÃ³t cá»§a Davinci-003, hoáº·c khÃ´ng thÆ°á»Ÿng Ä‘Ãºng cÃ¡ch cho cÃ¡c mÃ´ hÃ¬nh chia sáº» Ä‘iá»ƒm máº¡nh vá»›i Davinci-003.

Máº·c dÃ¹ khÃ´ng hoÃ n toÃ n toÃ n diá»‡n trong cÃ´ng trÃ¬nh nÃ y, chÃºng tÃ´i tin ráº±ng báº±ng cÃ¡ch bao gá»“m má»™t loáº¡t rá»™ng cÃ¡c mÃ´ hÃ¬nh, nÃ³ váº«n phá»¥c vá»¥ nhÆ° má»™t Ä‘Ã³ng gÃ³p há»¯u Ã­ch vÃ  quan trá»ng trong viá»‡c cho tháº¥y loáº¡i tÃ i nguyÃªn má»Ÿ nÃ o hoáº¡t Ä‘á»™ng, vÃ  nÆ¡i cÃ¡c ná»— lá»±c cá»™ng Ä‘á»“ng tÆ°Æ¡ng lai nÃªn hÆ°á»›ng tá»›i (cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ tá»‘t hÆ¡n, cÃ¡c táº­p dá»¯ liá»‡u Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n Ä‘a dáº¡ng hÆ¡n).

B TÃ¡c Ä‘á»™ng rá»™ng hÆ¡n

ChÃºng tÃ´i tin ráº±ng má»™t Ä‘Ã¡nh giÃ¡ nghiÃªm ngáº·t vá» cÃ¡c tÃ i nguyÃªn hiá»‡n cÃ³ lÃ  tÃ­ch cá»±c rá»™ng rÃ£i, phÆ¡i bÃ y nhá»¯ng Ä‘iá»ƒm máº¡nh vÃ  thiáº¿u sÃ³t cá»§a cÃ¡c tÃ i nguyÃªn hiá»‡n cÃ³ sáºµn rá»™ng rÃ£i. HÆ¡n ná»¯a, vÃ¬ táº¥t cáº£ tÃ i nguyÃªn Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»u sáºµn cÃ³ rá»™ng rÃ£i, tÃ¡c háº¡i gÃ¢y ra bá»Ÿi viá»‡c huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh nÃ y lÃ  khÃ¡ nhá». ChÃºng tÃ´i lÆ°u Ã½ ráº±ng viá»‡c huáº¥n luyá»‡n vÃ  phÃ¡t hÃ nh cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n Ä‘áº·c biá»‡t lá»›n mÃ  khÃ´ng cÃ³ hÆ°á»›ng dáº«n Ä‘Æ°á»£c kiá»ƒm tra ká»¹ lÆ°á»¡ng mang theo má»™t má»©c Ä‘á»™ rá»§i ro, vÃ  ban Ä‘áº§u chÃºng tÃ´i phÃ¡t hÃ nh cÃ¡c mÃ´ hÃ¬nh lá»›n nháº¥t cá»§a mÃ¬nh vá»›i thiáº¿t láº­p cÃ³ cá»•ng (yÃªu cáº§u ngÆ°á»i dÃ¹ng Ä‘Äƒng kÃ½ truy cáº­p vÃ  Ä‘Æ°á»£c phÃª duyá»‡t thá»§ cÃ´ng) Ä‘á»ƒ háº¡n cháº¿ tÃ¡c háº¡i tiá»m áº©n.

C Chi tiáº¿t táº­p dá»¯ liá»‡u hÆ°á»›ng dáº«n

ChÃºng tÃ´i cung cáº¥p mÃ´ táº£ ngáº¯n gá»n vá» táº¥t cáº£ cÃ¡c táº­p dá»¯ liá»‡u hÆ°á»›ng dáº«n Ä‘Æ°á»£c sá»­ dá»¥ng (vÃ  giáº¥y phÃ©p) dÆ°á»›i Ä‘Ã¢y:

â€¢ SuperNI: Má»™t táº­p há»£p cÃ¡c nhiá»‡m vá»¥ NLP Ä‘a dáº¡ng vá»›i hÆ°á»›ng dáº«n, Ä‘Æ°á»£c táº¡o bá»Ÿi Wang vÃ  cá»™ng sá»± [48]. Táº­p dá»¯ liá»‡u sá»­ dá»¥ng giáº¥y phÃ©p Apache-2.0.

â€¢ CoT: Má»™t táº­p há»£p cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c chÃº thÃ­ch vá»›i chuá»—i suy nghÄ© [50]. ChÃºng tÃ´i sá»­ dá»¥ng há»—n há»£p CoT tá»« bá»™ sÆ°u táº­p FLAN v2 [9], tÃ¡ch nÃ³ ra nhÆ° má»™t táº­p dá»¯ liá»‡u riÃªng. Há»—n há»£p FLAN Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i giáº¥y phÃ©p Apache-2.0, máº·c dÃ¹ cÃ¡c táº­p dá»¯ liá»‡u thÃ nh pháº§n cÃ³ thá»ƒ khÃ´ng sá»­ dá»¥ng giáº¥y phÃ©p nÃ y.

â€¢ FlanV2: Má»™t táº­p há»£p cÃ¡c nhiá»‡m vá»¥ NLP káº¿t há»£p má»™t sá»‘ táº­p dá»¯ liá»‡u NLP hiá»‡n cÃ³ vá»›i cÃ¡c tÄƒng cÆ°á»ng dá»¯ liá»‡u khÃ¡c nhau, Ä‘Æ°á»£c giá»›i thiá»‡u bá»Ÿi Chung vÃ  cá»™ng sá»± [9]. Há»—n há»£p Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i giáº¥y phÃ©p Apache-2.0, máº·c dÃ¹ cÃ¡c táº­p dá»¯ liá»‡u thÃ nh pháº§n cÃ³ thá»ƒ khÃ´ng sá»­ dá»¥ng giáº¥y phÃ©p nÃ y.

â€¢ Dolly: Má»™t táº­p há»£p cÃ¡c máº«u tuÃ¢n theo hÆ°á»›ng dáº«n Ä‘Æ°á»£c táº¡o bá»Ÿi nhÃ¢n viÃªn Databricks [12]. Táº­p dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i Giáº¥y phÃ©p Creative Commons Attribution-ShareAlike 3.0 Unported.

â€¢ Open Assistant 1: Má»™t táº­p dá»¯ liá»‡u há»™i thoáº¡i kiá»ƒu trá»£ lÃ½ Ä‘Æ°á»£c chÃº thÃ­ch bá»Ÿi con ngÆ°á»i thÃ´ng qua crowdsourcing, bao gá»“m má»™t sá»‘ lÆ°á»£ng lá»›n cÃ¡c cuá»™c há»™i thoáº¡i máº«u trong nhiá»u ngÃ´n ngá»¯ Ä‘a dáº¡ng [26]. Táº­p dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i giáº¥y phÃ©p Apache-2.0.

â€¢ Self-Instruct: Má»™t táº­p dá»¯ liá»‡u cÃ¡c máº«u tuÃ¢n theo hÆ°á»›ng dáº«n Ä‘Æ°á»£c táº¡o báº±ng cÃ¡ch nháº¯c GPT-3 táº¡o ra cÃ¡c máº«u má»›i khi Ä‘Æ°á»£c cho má»™t sá»‘ phiÃªn báº£n vÃ­ dá»¥ [47]. Táº­p dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i giáº¥y phÃ©p Apache-2.0.

--- TRANG 15 ---
â€¢ UnnaturalInstructions: Má»™t táº­p dá»¯ liá»‡u cÃ¡c máº«u tuÃ¢n theo hÆ°á»›ng dáº«n Ä‘Æ°á»£c táº¡o báº±ng cÃ¡ch nháº¯c Davinci-002 sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c giá»›i thiá»‡u bá»Ÿi Honovich vÃ  cá»™ng sá»± [23]. Táº­p dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i giáº¥y phÃ©p MIT.

â€¢ Alpaca: Má»™t táº­p dá»¯ liá»‡u Ä‘Æ°á»£c táº¡o sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p kiá»ƒu self-instruct vá»›i Davinci-003 lÃ m mÃ´ hÃ¬nh táº¡o vÃ  má»™t sá»‘ cáº£i tiáº¿n so vá»›i self-instruct [43]. Táº­p dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i giáº¥y phÃ©p Attribution-NonCommercial 4.0 International (CC BY-NC 4.0).

â€¢ Code-Alpaca: Má»™t táº­p dá»¯ liá»‡u Ä‘Æ°á»£c táº¡o sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p Alpaca, nhÆ°ng táº­p trung vÃ o táº¡o mÃ£ [6]. Táº­p dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i giáº¥y phÃ©p Apache-2.0.

â€¢ GPT-4 Alpaca: Má»™t táº­p dá»¯ liá»‡u Ä‘Æ°á»£c táº¡o sá»­ dá»¥ng táº­p dá»¯ liá»‡u Alpaca lÃ m Ä‘áº§u vÃ o, nhÆ°ng thay tháº¿ cÃ¡c tháº¿ há»‡ vÃ­ dá»¥ báº±ng cÃ¡c tháº¿ há»‡ tá»« GPT-4 [36]. ChÃºng tÃ´i bao gá»“m Ä‘iá»u nÃ y Ä‘á»ƒ xem tÃ¡c Ä‘á»™ng cá»§a viá»‡c sá»­ dá»¥ng má»™t mÃ´ hÃ¬nh táº¡o cháº¥t lÆ°á»£ng tá»‘t hÆ¡n. Táº­p dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i giáº¥y phÃ©p Apache-2.0.

â€¢ Baize: Má»™t táº­p dá»¯ liá»‡u Ä‘Æ°á»£c táº¡o báº±ng cÃ¡ch nháº¯c ChatGPT vÃ  Ä‘á»ƒ nÃ³ trÃ² chuyá»‡n vá»›i chÃ­nh nÃ³ [52]. Táº­p dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i Giáº¥y phÃ©p CÃ´ng cá»™ng GNU v3.0.

â€¢ ShareGPT: Má»™t táº­p há»£p cÃ¡c tÆ°Æ¡ng tÃ¡c ngÆ°á»i dÃ¹ng vá»›i cÃ¡c há»‡ thá»‘ng trÃ² chuyá»‡n khÃ¡c nhau Ä‘Æ°á»£c chia sáº» cÃ´ng khai. ChÃºng tÃ´i sá»­ dá»¥ng biáº¿n thá»ƒ 'html-cleaned' cÃ³ sáºµn táº¡i https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/tree/main/HTML_cleaned_raw_dataset. Sau Ä‘Ã³ chÃºng tÃ´i chia cÃ¡c cuá»™c há»™i thoáº¡i dÃ i (hÆ¡n 2048 token) thÃ nh cÃ¡c Ä‘oáº¡n max-2048 token, tuÃ¢n theo thiáº¿t láº­p Vicuna [8]. ChÃºng tÃ´i khÃ´ng thá»±c hiá»‡n báº¥t ká»³ lá»c thÃªm nÃ o Ä‘á»‘i vá»›i cÃ¡c máº«u. Táº­p dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i giáº¥y phÃ©p Apache-2.0.

ChÃºng tÃ´i lÆ°u Ã½ ráº±ng cÃ¡c táº­p dá»¯ liá»‡u SuperNI vÃ  CoT Ä‘Æ°á»£c bao gá»“m trong bá»™ sÆ°u táº­p FLAN V2 nhÆ°ng chá»‰ chiáº¿m má»™t pháº§n nhá» cá»§a táº­p dá»¯ liá»‡u FLAN V2 Ä‘Æ°á»£c láº¥y máº«u con cá»§a chÃºng tÃ´i.

ChÃºng tÃ´i cÅ©ng lÆ°u Ã½ ráº±ng chÃºng tÃ´i chá»§ yáº¿u sá»­ dá»¥ng cÃ¡c táº­p dá»¯ liá»‡u Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n phá»• biáº¿n Ä‘Ã£ cÃ³ sáºµn cÃ´ng khai, vÃ  trong trÆ°á»ng há»£p cÃ¡c táº­p dá»¯ liá»‡u do con ngÆ°á»i viáº¿t, chá»§ yáº¿u sá»­ dá»¥ng cÃ¡c táº­p dá»¯ liá»‡u Ä‘Æ°á»£c táº¡o má»™t cÃ¡ch rÃµ rÃ ng (vá»›i kiáº¿n thá»©c cá»§a ngÆ°á»i tham gia) cho má»¥c Ä‘Ã­ch huáº¥n luyá»‡n mÃ´ hÃ¬nh (vÃ­ dá»¥: Dolly, Open Assistant 1). VÃ¬ dá»¯ liá»‡u Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n, háº§u háº¿t dá»¯ liá»‡u khÃ´ng cÃ³ kháº£ nÄƒng chá»©a chi tiáº¿t nháº­n dáº¡ng cÃ¡ nhÃ¢n, máº·c dÃ¹ chÃºng tÃ´i lÆ°u Ã½ ráº±ng chÃºng tÃ´i khÃ´ng ná»— lá»±c loáº¡i bá» ná»™i dung xÃºc pháº¡m, vÃ¬ váº­y cÃ¡c mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i cÃ³ thá»ƒ táº¡o ra cÃ¡c tháº¿ há»‡ Ä‘á»™c háº¡i hoáº·c cÃ³ háº¡i.

D Chi tiáº¿t huáº¥n luyá»‡n mÃ´ hÃ¬nh vÃ  tÃ­nh toÃ¡n

ChÃºng tÃ´i huáº¥n luyá»‡n táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh trong hai epoch vá»›i tá»‘c Ä‘á»™ há»c 2ğ‘’âˆ’5 (1ğ‘’âˆ’5 cho cÃ¡c mÃ´ hÃ¬nh 30B vÃ  65B), khÃ´ng cÃ³ weight decay vÃ  tá»‘c Ä‘á»™ há»c vá»›i suy giáº£m tuyáº¿n tÃ­nh vÃ  khá»Ÿi Ä‘á»™ng tuyáº¿n tÃ­nh cho 3% tá»•ng sá»‘ bÆ°á»›c huáº¥n luyá»‡n. ChÃºng tÃ´i sá»­ dá»¥ng Ä‘á»™ dÃ i chuá»—i tá»‘i Ä‘a 2048 (1024 cho 30B vÃ  65B), cáº¯t ngáº¯n cÃ¡c máº«u khi cáº§n thiáº¿t. Trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, chÃºng tÃ´i sá»­ dá»¥ng thÆ° viá»‡n DeepSpeed [38] vÃ  bá»™ tá»‘i Æ°u hÃ³a ZeRO [37] Ä‘á»ƒ cho phÃ©p tinh chá»‰nh mÃ´ hÃ¬nh quy mÃ´ lá»›n. Trong táº¥t cáº£ cÃ¡c trÆ°á»ng há»£p, chÃºng tÃ´i tinh chá»‰nh Ä‘áº§y Ä‘á»§ cÃ¡c mÃ´ hÃ¬nh. ChÃºng tÃ´i huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh chá»§ yáº¿u trÃªn cá»¥m GPU CSC LUMI, má»—i node chá»©a 4 GPU AMD MI250x.

E Thiáº¿t láº­p Ä‘Ã¡nh giÃ¡

ChÃºng tÃ´i cung cáº¥p chi tiáº¿t thÃªm vá» cÃ¡c thiáº¿t láº­p Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c sá»­ dá»¥ng dÆ°á»›i Ä‘Ã¢y. ChÃºng tÃ´i cÅ©ng lÆ°u Ã½ ráº±ng chÃºng tÃ´i phÃ¡t hÃ nh mÃ£ Ä‘Ã¡nh giÃ¡ cÃ¹ng vá»›i mÃ£ huáº¥n luyá»‡n cá»§a chÃºng tÃ´i Ä‘á»ƒ cho phÃ©p tÃ¡i táº¡o dá»… dÃ ng.

â€¢ MMLU: ChÃºng tÃ´i sá»­ dá»¥ng script vÃ  lá»i nháº¯c Ä‘Ã¡nh giÃ¡ MMLU chÃ­nh thá»©c cÃ³ sáºµn táº¡i https://github.com/hendrycks/test, vá»›i cÃ¡c sá»­a Ä‘á»•i Ä‘á»ƒ cho phÃ©p xá»­ lÃ½ hÃ ng loáº¡t. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ sá»­ dá»¥ng 0 vÃ  5 vÃ­ dá»¥ few-shot, tuÃ¢n theo thiáº¿t láº­p gá»‘c cá»§a MMLU.

â€¢ GSM: ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh trÃªn táº­p kiá»ƒm tra cá»§a GSM. TuÃ¢n theo Wei vÃ  cá»™ng sá»± [50], chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ cÃ³ vÃ  khÃ´ng cÃ³ chuá»—i suy nghÄ© (CoT vs Direct). Cáº£ hai thiáº¿t láº­p Ä‘á»u sá»­ dá»¥ng 8 vÃ­ dá»¥ few-shot trong ngá»¯ cáº£nh (trong thiáº¿t láº­p chuá»—i suy nghÄ©, cÃ¡c vÃ­ dá»¥ few-shot Ä‘Æ°á»£c Ä‘i kÃ¨m vá»›i chuá»—i suy nghÄ©). VÃ¬ táº¥t cáº£ cÃ¢u tráº£ lá»i trong GSM Ä‘á»u lÃ  sá»‘, chÃºng tÃ´i trÃ­ch xuáº¥t sá»‘ cuá»‘i cÃ¹ng trong pháº£n há»“i mÃ´ hÃ¬nh lÃ m cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng. Äá»ƒ cho phÃ©p Ä‘Ã¡nh giÃ¡ nhanh hÆ¡n, chÃºng tÃ´i láº¥y máº«u ngáº«u nhiÃªn 200 vÃ­ dá»¥ tá»« 1319 vÃ­ dá»¥ kiá»ƒm tra, mÃ  chÃºng tÃ´i tháº¥y cho hiá»‡u suáº¥t tÆ°Æ¡ng tá»± nhÆ° Ä‘Ã¡nh giÃ¡ táº­p Ä‘áº§y Ä‘á»§.

â€¢ BBH: ChÃºng tÃ´i tuÃ¢n theo thiáº¿t láº­p Ä‘Æ°á»£c mÃ´ táº£ trong bÃ i bÃ¡o gá»‘c Suzgun vÃ  cá»™ng sá»± [42], vÃ  Ä‘Ã¡nh giÃ¡ cÃ³ vÃ  khÃ´ng cÃ³ chuá»—i suy nghÄ© (CoT vs Direct). CÃ¡c lá»i nháº¯c Ä‘Æ°á»£c cung cáº¥p chÃ­nh thá»©c, cÃ³ 3 vÃ­ dá»¥ few-shot trong ngá»¯ cáº£nh Ä‘Æ°á»£c sá»­ dá»¥ng cho cáº£ thiáº¿t láº­p CoT vÃ  Direct. Äá»‘i vá»›i thiáº¿t láº­p CoT, chÃºng tÃ´i trÃ­ch xuáº¥t tá»« Ä‘áº§u tiÃªn sau cá»¥m tá»« 'Váº­y cÃ¢u tráº£ lá»i lÃ ', hoáº·c toÃ n bá»™ pháº£n há»“i náº¿u khÃ´ng cÃ³ chuá»—i con nhÆ° váº­y.

--- TRANG 16 ---
â€¢ TydiQA: ChÃºng tÃ´i tuÃ¢n theo thiáº¿t láº­p Ä‘Æ°á»£c mÃ´ táº£ trong bÃ¡o cÃ¡o ká»¹ thuáº­t PaLM 2 [2] Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh trong viá»‡c tráº£ lá»i cÃ¢u há»i Ä‘a ngÃ´n ngá»¯ dÆ°á»›i hai thiáº¿t láº­p: 1) khi Ä‘oáº¡n vÄƒn vÃ ng chá»©a cÃ¢u tráº£ lá»i Ä‘Æ°á»£c cung cáº¥p (GoldP/GP); 2) khi khÃ´ng cÃ³ ngá»¯ cáº£nh nÃ o Ä‘Æ°á»£c cung cáº¥p (Closed-Book/CB). Má»™t vÃ­ dá»¥ trong ngá»¯ cáº£nh Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ lÃ m quen mÃ´ hÃ¬nh vá»›i Ä‘á»‹nh dáº¡ng tráº£ lá»i.

â€¢ Codex-Eval: ChÃºng tÃ´i sá»­ dá»¥ng táº­p dá»¯ liá»‡u HumanEval trong bÃ i bÃ¡o Codex [7] Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng láº­p trÃ¬nh cá»§a cÃ¡c mÃ´ hÃ¬nh. Táº­p dá»¯ liá»‡u chá»©a 164 bÃ i toÃ¡n láº­p trÃ¬nh, nÆ¡i cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c nháº¯c hoÃ n thÃ nh hÃ m Python Ä‘Ã£ cho docstring cá»§a nÃ³. TuÃ¢n theo bÃ i bÃ¡o gá»‘c, chÃºng tÃ´i tÃ­nh toÃ¡n cÃ¡c Æ°á»›c lÆ°á»£ng khÃ´ng thiÃªn vá»‹ cá»§a pass@k Ä‘á»ƒ Ä‘o lÆ°á»ng tÃ­nh Ä‘Ãºng Ä‘áº¯n chá»©c nÄƒng cá»§a cÃ¡c Ä‘áº§u ra mÃ´ hÃ¬nh. ChÃºng tÃ´i bÃ¡o cÃ¡o cáº£ pass@1 vÃ  pass@10. Káº¿t quáº£ pass@1 Ä‘Æ°á»£c thu Ä‘Æ°á»£c báº±ng cÃ¡ch láº¥y máº«u vá»›i nhiá»‡t Ä‘á»™ 0.1 vÃ  káº¿t quáº£ pass@10 vá»›i nhiá»‡t Ä‘á»™ 0.8.

â€¢ ToxiGen: ChÃºng tÃ´i tuÃ¢n theo thiáº¿t láº­p trong Touvron vÃ  cá»™ng sá»± [45], nhÆ°ng sá»­ dá»¥ng táº­p lá»i nháº¯c gá»‘c tá»« Hartvigsen vÃ  cá»™ng sá»± [21], Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ gá»£i ra cÃ¡c tháº¿ há»‡ Ä‘á»™c háº¡i cho cÃ¡c nhÃ³m nháº¥t Ä‘á»‹nh. ChÃºng tÃ´i chá»‰ láº¥y cÃ¡c lá»i nháº¯c Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ táº¡o ra ngÃ´n ngá»¯ Ä‘á»™c háº¡i (lá»i nháº¯c 'thÃ¹ Ä‘á»‹ch') vÃ  sá»­ dá»¥ng 500 lá»i nháº¯c má»—i nhÃ³m Ä‘á»ƒ giáº£m chi phÃ­ Ä‘Ã¡nh giÃ¡. Äá»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÆ¡ sá»Ÿ, chÃºng tÃ´i truyá»n cÃ¡c lá»i nháº¯c ToxiGen gá»‘c khÃ´ng thay Ä‘á»•i vÃ  giáº£i mÃ£ tham lam Ä‘áº¿n dÃ²ng má»›i Ä‘áº§u tiÃªn (hoáº·c tá»‘i Ä‘a 512 token). Äá»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n, chÃºng tÃ´i Ä‘áº·t lá»i nháº¯c vÃ o máº«u tÆ°Æ¡ng á»©ng, vÃ  yÃªu cáº§u mÃ´ hÃ¬nh hoÃ n thÃ nh lá»i nháº¯c, cho Ä‘áº¿n khi mÃ´ hÃ¬nh táº¡o ra token dá»«ng (hoáº·c tá»‘i Ä‘a 512 token). ChÃºng tÃ´i truyá»n vÄƒn báº£n Ä‘Æ°á»£c táº¡o vÃ o mÃ´ hÃ¬nh roberta-large Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ phÃ¡t hiá»‡n ná»™i dung Ä‘á»™c háº¡i Ä‘Æ°á»£c tinh chá»‰nh nhÆ° má»™t pháº§n cá»§a Hartvigsen vÃ  cá»™ng sá»± [21]âµ. Sau Ä‘Ã³ chÃºng tÃ´i bÃ¡o cÃ¡o tá»· lá»‡ pháº§n trÄƒm cá»§a cÃ¡c tháº¿ há»‡ Ä‘Æ°á»£c coi lÃ  Ä‘á»™c háº¡i bá»Ÿi bá»™ phÃ¢n loáº¡i.

â€¢ TruthfulQA: TuÃ¢n theo Touvron vÃ  cá»™ng sá»± [45], chÃºng tÃ´i chá»§ yáº¿u sá»­ dá»¥ng thiáº¿t láº­p táº¡o cá»§a TruthfulQA [30]. Táº­p dá»¯ liá»‡u TruthfulQA chá»©a 818 cÃ¢u há»i, Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ nháº¯c mÃ´ hÃ¬nh Ä‘Æ°á»£c kiá»ƒm tra táº¡o ra cÃ¢u tráº£ lá»i. ChÃºng tÃ´i sá»­ dá»¥ng Ä‘á»‹nh dáº¡ng lá»i nháº¯c QA máº·c Ä‘á»‹nh vá»›i 6 vÃ­ dá»¥ QA trong ngá»¯ cáº£nh. ChÃºng tÃ´i tuÃ¢n theo script chÃ­nh thá»©c trong implementation chÃ­nh thá»©c cá»§a há»â¶ Ä‘á»ƒ thá»±c hiá»‡n giáº£i mÃ£ tham lam vÃ  xá»­ lÃ½ háº­u ká»³ cÃ¢u tráº£ lá»i. ChÃºng tÃ´i cÅ©ng tuÃ¢n theo hÆ°á»›ng dáº«n cá»§a há» Ä‘á»ƒ huáº¥n luyá»‡n hai bá»™ phÃ¢n loáº¡i dá»±a trÃªn GPT Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ tÃ­nh Ä‘Ãºng Ä‘áº¯n vÃ  tÃ­nh thÃ´ng tin cá»§a pháº£n há»“i mÃ´ hÃ¬nh. ChÃºng tÃ´i bÃ¡o cÃ¡o tá»· lá»‡ cÃ¡c pháº£n há»“i Ä‘Ãºng sá»± tháº­t (%Truthful), thÃ´ng tin (%Informative), vÃ  cáº£ hai (%Informative and Truthful) lÃ m chá»‰ sá»‘ cá»§a chÃºng tÃ´i. TuÃ¢n theo Touvron vÃ  cá»™ng sá»± [45], chÃºng tÃ´i chá»‰ bÃ¡o cÃ¡o (% Informative and Truthful) lÃ m chá»‰ sá»‘ chÃ­nh cá»§a chÃºng tÃ´i trong bÃ i bÃ¡o chÃ­nh.

â€¢ AlpacaEval: ChÃºng tÃ´i sá»­ dá»¥ng gÃ³i Ä‘Æ°á»£c cung cáº¥p bá»Ÿi Li vÃ  cá»™ng sá»± [27], tuÃ¢n theo thiáº¿t láº­p máº·c Ä‘á»‹nh yÃªu cáº§u mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ táº¡o ra pháº£n há»“i cho 805 lá»i nháº¯c vÃ  sá»­ dá»¥ng GPT-4 Ä‘á»ƒ so sÃ¡nh pháº£n há»“i vá»›i Davinci-003. ChÃºng tÃ´i sá»­ dá»¥ng cáº¥u hÃ¬nh annotator "alpaca_eval_gpt4_0314" thay vÃ¬ "alpaca_eval_gpt4" Ä‘á»ƒ lÃ m cho káº¿t quáº£ cÃ³ thá»ƒ tÃ¡i táº¡o. ChÃºng tÃ´i cho phÃ©p mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ táº¡o ra Ä‘áº¿n 8192 token, mÃ  khÃ´ng chá»‰ Ä‘á»‹nh chuá»—i dá»«ng Ä‘áº·c biá»‡t. Tá»· lá»‡ tháº¯ng bÃ¡o cÃ¡o lÃ  tá»· lá»‡ pháº§n trÄƒm cá»§a cÃ¡c tháº¿ há»‡ mÃ´ hÃ¬nh mÃ  GPT-4 bÃ¡o cÃ¡o lÃ  Ä‘Æ°á»£c Æ°a thÃ­ch hÆ¡n so vá»›i cÃ¡c tháº¿ há»‡ tá»« Davinci-003.

Äá»‘i vá»›i táº¥t cáº£ cÃ¡c Ä‘Ã¡nh giÃ¡, chÃºng tÃ´i táº£i cÃ¡c mÃ´ hÃ¬nh sá»­ dá»¥ng cháº¿ Ä‘á»™ 8-bit [13] Ä‘Æ°á»£c cung cáº¥p trong thÆ° viá»‡n Huggingface Transformers, mÃ  chÃºng tÃ´i tháº¥y tÄƒng tá»‘c Ä‘á»™ suy luáº­n Ä‘Ã¡ng ká»ƒ vÃ  cÃ³ tÃ¡c Ä‘á»™ng khÃ´ng Ä‘Ã¡ng ká»ƒ Ä‘áº¿n hiá»‡u suáº¥t cuá»‘i cÃ¹ng. Khi thá»±c hiá»‡n táº¡o, chÃºng tÃ´i sá»­ dá»¥ng giáº£i mÃ£ tham lam vÃ  Ä‘á»™ dÃ i tá»‘i Ä‘a 512 token, trá»« khi Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh khÃ¡c.

F Tá»•ng quan vá» táº¥t cáº£ káº¿t quáº£ Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng

Báº£ng 8 trÃ¬nh bÃ y má»™t tá»•ng há»£p káº¿t quáº£ cá»§a táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n nhÆ° má»™t pháº§n cá»§a cÃ´ng trÃ¬nh nÃ y trÃªn táº¥t cáº£ cÃ¡c benchmark Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng cá»‘t lÃµi. ChÃºng tÃ´i liá»‡t kÃª nhiá»u ká»‹ch báº£n cho táº¥t cáº£ cÃ¡c thiáº¿t láº­p Ä‘Ã¡nh giÃ¡ trá»« AlpacaEval, cÃ³ má»™t thiáº¿t láº­p. Vui lÃ²ng tham kháº£o Â§E Ä‘á»ƒ biáº¿t Ã½ nghÄ©a cá»§a cÃ¡c chá»‰ sá»‘ Ä‘Æ°á»£c bÃ¡o cÃ¡o. ChÃºng tÃ´i cÅ©ng tÃ­nh toÃ¡n trung bÃ¬nh trÃªn cÃ¡c benchmark trong Báº£ng 8. Äiá»u nÃ y Ä‘Æ°á»£c tÃ­nh toÃ¡n báº±ng cÃ¡ch Ä‘áº§u tiÃªn tÃ­nh toÃ¡n trung bÃ¬nh má»—i benchmark báº±ng cÃ¡ch láº¥y trung bÃ¬nh trÃªn cÃ¡c ká»‹ch báº£n. Sau Ä‘Ã³ chÃºng tÃ´i tÃ­nh toÃ¡n trung bÃ¬nh tá»•ng thá»ƒ vá»›i má»—i benchmark Ä‘Æ°á»£c cÃ¢n báº±ng nhÆ° nhau.

NgoÃ i ra, Ä‘á»‘i vá»›i Ä‘Ã¡nh giÃ¡ an toÃ n, chÃºng tÃ´i cung cáº¥p káº¿t quáº£ ToxiGen Ä‘Æ°á»£c phÃ¢n tÃ­ch theo nhÃ³m Ä‘Æ°á»£c nháº¯m má»¥c tiÃªu trong Báº£ng 9 cho táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh, tá»« Ä‘Ã³ chÃºng tÃ´i cÃ³ thá»ƒ tháº¥y má»™t sá»‘ nhÃ³m Ä‘Æ°á»£c nháº¯m má»¥c tiÃªu Ä‘áº·c biá»‡t, ngay cáº£ sau khi Ä‘iá»u chá»‰nh hÆ°á»›ng dáº«n. ChÃºng tÃ´i cÅ©ng cung cáº¥p káº¿t quáº£ TruthfulQA Ä‘áº§y Ä‘á»§ trong Báº£ng 10. Káº¿t quáº£ Ä‘Æ°á»£c phÃ¢n tÃ­ch thÃ nh % thÃ´ng tin vÃ  % Ä‘Ãºng sá»± tháº­t - xem Lin vÃ  cá»™ng sá»± [29] Ä‘á»ƒ biáº¿t chi tiáº¿t vá» cÃ¡c chá»‰ sá»‘ nÃ y.

--- TRANG 17 ---
Báº£ng 8: Tá»•ng quan vá» hiá»‡u suáº¥t cá»§a táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tinh chá»‰nh cho cÃ´ng trÃ¬nh nÃ y, cÃ¹ng vá»›i cÃ¡c mÃ´ hÃ¬nh Ä‘á»™c quyá»n, trÃªn cÃ¡c benchmark Ä‘Ã£ chá»n. Äá»ƒ tÃ­nh toÃ¡n trung bÃ¬nh, chÃºng tÃ´i tÃ­nh toÃ¡n trung bÃ¬nh má»—i benchmark vÃ  sau Ä‘Ã³ láº¥y trung bÃ¬nh trÃªn cÃ¡c benchmark nÃ y. Xem Phá»¥ lá»¥c F Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

[Báº£ng nÃ y chá»©a káº¿t quáº£ hiá»‡u suáº¥t chi tiáº¿t cho táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh trÃªn cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ khÃ¡c nhau bao gá»“m MMLU, GSM, BBH, TydiQA, Codex-Eval, vÃ  AlpacaEval]

--- TRANG 18 ---
Báº£ng 9: Káº¿t quáº£ ToxiGen trÃªn cÃ¡c mÃ´ hÃ¬nh. ChÃºng tÃ´i bÃ¡o cÃ¡o tá»· lá»‡ pháº§n trÄƒm cá»§a cÃ¡c tháº¿ há»‡ Ä‘Æ°á»£c coi lÃ  Ä‘á»™c háº¡i bá»Ÿi má»™t bá»™ phÃ¢n loáº¡i riÃªng biá»‡t, Ä‘Æ°á»£c phÃ¢n tÃ­ch theo nhÃ³m mÃ  lá»i nháº¯c Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ táº¡o ra cÃ¡c tháº¿ há»‡ Ä‘á»™c háº¡i.

[Báº£ng nÃ y hiá»ƒn thá»‹ káº¿t quáº£ ToxiGen chi tiáº¿t cho cÃ¡c nhÃ³m khÃ¡c nhau nhÆ° Asian, Black, Chinese, Jewish, Latino, LGBTQ, v.v.]

--- TRANG 19 ---
Báº£ng 10: Káº¿t quáº£ TruthfulQA trÃªn cÃ¡c mÃ´ hÃ¬nh. ChÃºng tÃ´i bÃ¡o cÃ¡o tá»· lá»‡ pháº§n trÄƒm cá»§a cÃ¡c cÃ¢u tráº£ lá»i cÃ³ thÃ´ng tin, hoáº·c Ä‘Ãºng sá»± tháº­t, hoáº·c cáº£ hai.

[Báº£ng nÃ y hiá»ƒn thá»‹ káº¿t quáº£ TruthfulQA vá»›i cÃ¡c chá»‰ sá»‘ % Informative, % Truthful, vÃ  % Informative and Truthful]

--- TRANG 20 ---
G Chi tiáº¿t Ä‘Ã¡nh giÃ¡ con ngÆ°á»i

G.1 Thiáº¿t láº­p

á» Ä‘Ã¢y chÃºng tÃ´i cung cáº¥p chi tiáº¿t hÆ¡n cho Ä‘Ã¡nh giÃ¡ con ngÆ°á»i Ä‘Æ°á»£c mÃ´ táº£ trong Â§4.3. ÄÃ¡nh giÃ¡ cá»§a chÃºng tÃ´i chá»©a 332 hÆ°á»›ng dáº«n, bao gá»“m 252 hÆ°á»›ng dáº«n tá»« táº­p Ä‘Ã¡nh giÃ¡ Self-Instruct [47] vÃ  80 hÆ°á»›ng dáº«n tá»« táº­p Ä‘Ã¡nh giÃ¡ Vicuna [8]. ÄÃ¡nh giÃ¡ cá»§a chÃºng tÃ´i Ä‘Æ°á»£c thá»±c hiá»‡n cho ba cáº·p mÃ´ hÃ¬nh: 1) TÃœLU 65B so vá»›i ChatGPT, 2) TÃœLU 65B so vá»›i TÃœLU 7B, 3) TÃœLU 65B so vá»›i má»™t mÃ´ hÃ¬nh LLAMA 65B Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn há»—n há»£p dá»¯ liá»‡u Con ngÆ°á»i, sá»­ dá»¥ng cÃ¹ng má»™t táº­p hÆ°á»›ng dáº«n cho cáº£ ba so sÃ¡nh.

Äá»ƒ Ä‘áº£m báº£o Ä‘Ã¡nh giÃ¡ Ä‘Ã¡ng tin cáº­y, chÃºng tÃ´i tuyá»ƒn dá»¥ng 18 ngÆ°á»i chÃº thÃ­ch chuyÃªn gia, lÃ  cÃ¡c nhÃ  nghiÃªn cá»©u táº¡i AI2 hoáº·c sinh viÃªn táº¡i UW, Ä‘á»ƒ chÃº thÃ­ch. Táº¥t cáº£ nhá»¯ng ngÆ°á»i chÃº thÃ­ch nÃ y Ä‘á»u nÃ³i tiáº¿ng Anh thÃ´ng tháº¡o vÃ  cÃ³ báº±ng cá»­ nhÃ¢n trá»Ÿ lÃªn.

ChÃºng tÃ´i thiáº¿t káº¿ má»™t trang web, Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 5, Ä‘á»ƒ ngÆ°á»i chÃº thÃ­ch cá»§a chÃºng tÃ´i thá»±c hiá»‡n Ä‘Ã¡nh giÃ¡, vÃ  chÃºng tÃ´i sáº½ phÃ¡t hÃ nh mÃ£ cho trang web nÃ y. Khi thá»±c hiá»‡n Ä‘Ã¡nh giÃ¡, ngÆ°á»i chÃº thÃ­ch Ä‘Æ°á»£c hÆ°á»›ng dáº«n Ä‘á»c ká»¹ lá»i nháº¯c vÃ  Ä‘áº§u ra A vÃ  B tá»« hai mÃ´ hÃ¬nh, sau Ä‘Ã³ tráº£ lá»i ba cÃ¢u há»i yÃªu cáº§u sá»± cháº¥p nháº­n cá»§a cÃ¡c Ä‘áº§u ra vÃ  so sÃ¡nh chÃºng vá» máº·t tÃ­nh há»¯u Ã­ch. Há» Ä‘Æ°á»£c khuyáº¿n khÃ­ch sá»­ dá»¥ng Google hoáº·c báº¥t ká»³ cÃ´ng cá»¥ bÃªn ngoÃ i nÃ o cÃ³ thá»ƒ giÃºp Ã­ch cho viá»‡c Ä‘Ã¡nh giÃ¡. ThÃ´ng tin mÃ´ hÃ¬nh Ä‘Æ°á»£c áº©n danh, vÃ  cÃ¡c Ä‘áº§u ra cá»§a chÃºng Ä‘Æ°á»£c Ä‘áº·t theo thá»© tá»± ngáº«u nhiÃªn.

HÃ¬nh 5: Giao diá»‡n trang web cho Ä‘Ã¡nh giÃ¡ con ngÆ°á»i cá»§a chÃºng tÃ´i (xem Phá»¥ lá»¥c G Ä‘á»ƒ biáº¿t chi tiáº¿t). NgÆ°á»i dÃ¹ng cáº§n Ä‘Äƒng nháº­p vÃ o há»‡ thá»‘ng, Ä‘á»c lá»i nháº¯c vÃ  Ä‘áº§u ra tá»« hai mÃ´ hÃ¬nh (vá»›i tÃªn mÃ´ hÃ¬nh Ä‘Æ°á»£c áº©n danh vÃ  thá»© tá»± ngáº«u nhiÃªn), sau Ä‘Ã³ tráº£ lá»i liá»‡u Ä‘áº§u ra A vÃ  Ä‘áº§u ra B cÃ³ thá»ƒ cháº¥p nháº­n Ä‘Æ°á»£c hay khÃ´ng má»™t cÃ¡ch riÃªng láº», vÃ  cuá»‘i cÃ¹ng so sÃ¡nh chÃºng vá» máº·t tÃ­nh há»¯u Ã­ch.

G.2 Thá»a thuáº­n giá»¯a cÃ¡c ngÆ°á»i chÃº thÃ­ch

ChÃºng tÃ´i Ä‘o lÆ°á»ng sá»± Ä‘á»“ng Ã½ cá»§a ngÆ°á»i chÃº thÃ­ch cá»§a chÃºng tÃ´i trÃªn má»™t táº­p con 119 vÃ­ dá»¥ (63 phiÃªn báº£n Ä‘Æ°á»£c láº¥y máº«u ngáº«u nhiÃªn tá»« so sÃ¡nh ChatGPT vs TÃœLU 65B, vÃ  59 phiÃªn báº£n Ä‘Æ°á»£c láº¥y máº«u ngáº«u nhiÃªn tá»« so sÃ¡nh TÃœLU 65B vs TÃœLU 7B). ChÃºng tÃ´i giao hai ngÆ°á»i chÃº thÃ­ch cho má»—i vÃ­ dá»¥ nÃ y vÃ  tÃ­nh toÃ¡n sá»± Ä‘á»“ng Ã½ cá»§a há» cho cáº£ Ä‘Ã¡nh giÃ¡ cháº¥p nháº­n vÃ  Ä‘Ã¡nh giÃ¡ so sÃ¡nh cáº·p.

--- TRANG 21 ---
NgÆ°á»i chÃº thÃ­ch Ä‘áº¡t Ä‘Æ°á»£c sá»± Ä‘á»“ng Ã½ 0.84 vá» viá»‡c liá»‡u má»™t Ä‘áº§u ra mÃ´ hÃ¬nh cÃ³ nÃªn Ä‘Æ°á»£c cháº¥p nháº­n hay khÃ´ng. Äá»‘i vá»›i so sÃ¡nh cáº·p, tuÃ¢n theo Zhou vÃ  cá»™ng sá»± [56], chÃºng tÃ´i bÃ¡o cÃ¡o Ä‘á»™ chÃ­nh xÃ¡c loáº¡i trá»« hÃ²a, gÃ¡n má»™t Ä‘iá»ƒm náº¿u cáº£ hai ngÆ°á»i chÃº thÃ­ch Ä‘á»“ng Ã½, ná»­a Ä‘iá»ƒm náº¿u má»™t trong hai ngÆ°á»i chÃº thÃ­ch (nhÆ°ng khÃ´ng pháº£i cáº£ hai) Ä‘Ã¡nh dáº¥u hÃ²a, vÃ  khÃ´ng cÃ³ Ä‘iá»ƒm náº¿u ngÆ°á»£c láº¡i. ChÃºng tÃ´i cÅ©ng gá»™p "rÃµ rÃ ng tá»‘t hÆ¡n" vÃ  "hÆ¡i tá»‘t hÆ¡n" láº¡i vá»›i nhau, vÃ¬ váº­y cÃ¡c lá»±a chá»n cuá»‘i cÃ¹ng cá»§a chÃºng tÃ´i sáº½ chá»‰ Ä‘Æ¡n giáº£n lÃ  so sÃ¡nh cÃ¡i nÃ o trong A vÃ  B tá»‘t hÆ¡n, hoáº·c hÃ²a. NgÆ°á»i chÃº thÃ­ch cá»§a chÃºng tÃ´i Ä‘áº¡t Ä‘Æ°á»£c sá»± Ä‘á»“ng Ã½ 0.72 cho so sÃ¡nh cáº·p nÃ y.

Máº·c dÃ¹ nhá»¯ng con sá»‘ nÃ y cho tháº¥y sá»± Ä‘á»“ng Ã½ há»£p lÃ½, chÃºng tÃ´i cÅ©ng lÆ°u Ã½ ráº±ng cÃ³ má»™t má»©c Ä‘á»™ chá»§ quan lá»›n trong Ä‘Ã¡nh giÃ¡ con ngÆ°á»i. Má»©c Ä‘á»™ nhiá»…u nÃ y cÅ©ng chá»‰ ra ráº±ng má»™t sá»‘ cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y [8,55] sá»­ dá»¥ng má»™t sá»‘ lÆ°á»£ng nhá» vÃ­ dá»¥ cho Ä‘Ã¡nh giÃ¡ con ngÆ°á»i cÃ³ thá»ƒ khÃ´ng Ä‘á»§ Ä‘Ã¡ng tin cáº­y. ChÃºng tÃ´i Ä‘á» xuáº¥t ráº±ng cá»™ng Ä‘á»“ng cáº§n tiáº¿p tá»¥c cáº£i thiá»‡n Ä‘á»™ tin cáº­y vÃ  kháº£ nÄƒng má»Ÿ rá»™ng cá»§a Ä‘Ã¡nh giÃ¡ con ngÆ°á»i cho cÃ¡c mÃ´ hÃ¬nh tuÃ¢n theo hÆ°á»›ng dáº«n.

H Äiá»u tra thÃªm vá» HÃ¬nh 2

Äá»ƒ Ä‘iá»u tra thÃªm vá» má»©c Ä‘á»™ mÃ  sá»‘ lÆ°á»£ng token duy nháº¥t Ä‘Æ°á»£c GPT-4 sá»­ dá»¥ng lÃ m dáº¥u hiá»‡u cá»§a cháº¥t lÆ°á»£ng, chÃºng tÃ´i táº¡o ra má»™t ngÆ°á»i Ä‘Ã¡nh giÃ¡ giáº£ máº¡o so sÃ¡nh hai Ä‘áº§u ra mÃ´ hÃ¬nh, vÃ  gÃ¡n chiáº¿n tháº¯ng cho Ä‘áº§u ra cÃ³ nhiá»u token duy nháº¥t hÆ¡n. ChÃºng tÃ´i váº½ biá»ƒu Ä‘á»“ tá»· lá»‡ tháº¯ng Ä‘Æ°á»£c tÃ­nh toÃ¡n sá»­ dá»¥ng ngÆ°á»i Ä‘Ã¡nh giÃ¡ giáº£ máº¡o nÃ y so vá»›i tá»· lá»‡ tháº¯ng Ä‘Æ°á»£c tÃ­nh toÃ¡n sá»­ dá»¥ng GPT-4 trong HÃ¬nh 6.

ChÃºng tÃ´i tháº¥y ráº±ng trong khi ngÆ°á»i Ä‘Ã¡nh giÃ¡ giáº£ máº¡o nhÃ¬n chung Ä‘Ã¡nh giÃ¡ quÃ¡ cao tá»· lá»‡ tháº¯ng, xu hÆ°á»›ng váº«n tuyáº¿n tÃ­nh má»™t cÃ¡ch Ä‘Ã¡ng chÃº Ã½. ChÃºng tÃ´i lÆ°u Ã½ ráº±ng ğ‘…Â² cho Ä‘Æ°á»ng xu hÆ°á»›ng lÃ  .91, gá»£i Ã½ ráº±ng sá»‘ lÆ°á»£ng token duy nháº¥t giáº£i thÃ­ch má»™t tá»· lá»‡ lá»›n cá»§a phÆ°Æ¡ng sai trong tá»· lá»‡ tháº¯ng. Dá»±a trÃªn Ä‘iá»u nÃ y, chÃºng tÃ´i tin ráº±ng sá»‘ lÆ°á»£ng token duy nháº¥t cháº¯c cháº¯n lÃ  má»™t sá»Ÿ thÃ­ch chÃ­nh mÃ  GPT-4 quan tÃ¢m trong Ä‘Ã¡nh giÃ¡ cá»§a nÃ³, máº·c dÃ¹ nÃ³ váº«n khÃ´ng pháº£i lÃ  tÃ­nh nÄƒng quan trá»ng duy nháº¥t.

HÃ¬nh 6: Äiá»ƒm sá»‘ tá»· lá»‡ tháº¯ng cá»§a táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ bá»Ÿi ngÆ°á»i Ä‘Ã¡nh giÃ¡ giáº£ máº¡o so vá»›i tá»· lá»‡ tháº¯ng cá»§a táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh sá»­ dá»¥ng ngÆ°á»i Ä‘Ã¡nh giÃ¡ GPT-4.

I Giáº¥y phÃ©p mÃ´ hÃ¬nh

ChÃºng tÃ´i cung cáº¥p thÃ´ng tin ngáº¯n gá»n vá» giáº¥y phÃ©p cá»§a cÃ¡c mÃ´ hÃ¬nh cÆ¡ báº£n chÃºng tÃ´i sá»­ dá»¥ng trong cÃ´ng trÃ¬nh nÃ y dÆ°á»›i Ä‘Ã¢y.

â€¢ LLAMA: Trá»ng sá»‘ mÃ´ hÃ¬nh LLAMA Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i giáº¥y phÃ©p tÃ¹y chá»‰nh cho phÃ©p sá»­ dá»¥ng mÃ´ hÃ¬nh cho má»¥c Ä‘Ã­ch nghiÃªn cá»©u phi thÆ°Æ¡ng máº¡i.

â€¢ LLAMA-2: Trá»ng sá»‘ mÃ´ hÃ¬nh LLAMA-2 Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i giáº¥y phÃ©p tÃ¹y chá»‰nh cho phÃ©p sá»­ dá»¥ng thÆ°Æ¡ng máº¡i vÃ  nghiÃªn cá»©u vá»›i má»™t sá»‘ háº¡n cháº¿ (vÃ­ dá»¥: cÃ³ Ã­t hÆ¡n 700 triá»‡u ngÆ°á»i dÃ¹ng hoáº¡t Ä‘á»™ng hÃ ng thÃ¡ng náº¿u Ä‘Æ°á»£c sá»­ dá»¥ng trong á»©ng dá»¥ng thÆ°Æ¡ng máº¡i), vÃ  rÃµ rÃ ng cho phÃ©p phÃ¢n phá»‘i láº¡i trá»ng sá»‘.

--- TRANG 22 ---
â€¢ Pythia: Trá»ng sá»‘ Pythia Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i giáº¥y phÃ©p Apache-2.0.

â€¢ OPT: Trá»ng sá»‘ mÃ´ hÃ¬nh OPT Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i giáº¥y phÃ©p tÃ¹y chá»‰nh chá»‰ cho phÃ©p sá»­ dá»¥ng mÃ´ hÃ¬nh cho má»¥c Ä‘Ã­ch nghiÃªn cá»©u phi thÆ°Æ¡ng máº¡i.

--- TRANG 23 ---

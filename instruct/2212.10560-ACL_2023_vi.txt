viết
đưa ra
tìm
tạo
làm
mô tả
thiết kế
tạo ra
phân loại
có
giải thích
nói
xác định
đầu ra
dự đoán
phát hiện

hàm số
bài luận
thư
đoạn văn
ví dụ
danh sách
tập hợp
lời khuyên
từ
số
câu
cách
chương trình
danh sách
thuật toán
hàm số
danh sách
câu chuyện
câu
chương trình
tình huống
người
quá trình
thời gian
hệ thống
trò chơi
thuật toán
cấu trúc
danh sách
số
câu
chuỗi
câu
tình cảm
bài viết
văn bản
danh sách
mảng
đồng xu
tập hợp
khác biệt
khái niệm
câu chuyện
trò đùa
tình cảm
chủ đề
số
từ
tình cảm
châm biếm

Hình 3: 20 động từ gốc phổ biến nhất (vòng tròn trong) và 4 đối tượng danh từ trực tiếp hàng đầu của chúng (vòng tròn ngoài) trong các hướng dẫn được tạo ra. Mặc dù có tính đa dạng, các hướng dẫn được hiển thị ở đây chỉ chiếm 14% tất cả các hướng dẫn được tạo ra vì nhiều hướng dẫn (ví dụ: "Phân loại xem người dùng có hài lòng với dịch vụ hay không.") không chứa cấu trúc động từ-danh từ như vậy.

0 0.2 0.4 0.6 0.8 1
0
1000
2000
3000

ROUGE-L Overlap với Hướng dẫn Khởi tạo Tương tự Nhất
# Hướng dẫn

Hình 4: Phân phối điểm ROUGE-L giữa các hướng dẫn được tạo ra và hướng dẫn khởi tạo tương tự nhất của chúng.

10 20 30 40 50 60
0
2000
4000
6000

Độ dài Hướng dẫn
# Hướng dẫn

10 20 30 40 50 60
0
1000
2000
3000

Độ dài Đầu vào
# Đầu vào

10 20 30 40 50 60
0
10k
20k
30k

Độ dài Đầu ra
# Đầu ra

Hình 5: Phân phối độ dài của các hướng dẫn được tạo ra, đầu vào không trống và đầu ra.

7 Tác động Rộng hơn
Ngoài trọng tâm trực tiếp của bài báo này, chúng tôi tin rằng SELF-INSTRUCT có thể giúp mang lại tính minh bạch hơn cho những gì xảy ra "đằng sau hậu trường" của các mô hình được tinh chỉnh hướng dẫn được sử dụng rộng rãi như InstructGPT hoặc ChatGPT. Thật không may, các mô hình công nghiệp như vậy vẫn ở phía sau các bức tường API vì các bộ dữ liệu của họ không được phát hành, và do đó có ít hiểu biết về việc xây dựng của chúng và tại sao chúng thể hiện khả năng ấn tượng. Gánh nặng hiện tại rơi vào học viện để hiểu rõ hơn nguồn gốc thành công trong các mô hình này và phấn đấu cho các mô hình tốt hơn - và mở hơn. Chúng tôi tin rằng các phát hiện của chúng tôi trong bài báo này chứng minh tầm quan trọng của dữ liệu hướng dẫn đa dạng, và bộ dữ liệu tổng hợp lớn của chúng tôi có thể là bước đầu tiên hướng tới dữ liệu chất lượng cao hơn để xây dựng các mô hình tuân theo hướng dẫn tốt hơn. Tại thời điểm viết, ý tưởng trung tâm của bài báo này đã được áp dụng trong một số công trình tiếp theo cho những nỗ lực như vậy (Taori et al., 2023; Xu et al., 2023; Sun et al., 2023, v.v.).

8 Hạn chế
Ở đây, chúng tôi thảo luận về một số hạn chế của công trình này để truyền cảm hứng cho nghiên cứu tương lai theo hướng này.

Hiện tượng đuôi. SELF-INSTRUCT phụ thuộc vào LM, và nó sẽ kế thừa tất cả các hạn chế được mang theo với LM. Như các nghiên cứu gần đây đã cho thấy (Razeghi et al., 2022; Kandpal et al., 2022), hiện tượng đuôi đặt ra một thách thức nghiêm trọng đối với sự thành công của LM. Nói cách khác, lợi ích lớn nhất của LM tương ứng với việc sử dụng ngôn ngữ thường xuyên (đầu của phân phối sử dụng ngôn ngữ), và có thể có lợi ích tối thiểu trong các bối cảnh tần suất thấp. Tương tự, trong bối cảnh của công trình này, sẽ không đáng ngạc nhiên nếu phần lớn lợi ích của SELF-INSTRUCT nghiêng về các nhiệm vụ hoặc hướng dẫn xuất hiện thường xuyên hơn trong corpus tiền huấn luyện. Như một hệ quả, phương pháp có thể cho thấy sự giòn với các hướng dẫn không phổ biến và sáng tạo.

Phụ thuộc vào các mô hình lớn. Do sự phụ thuộc của SELF-INSTRUCT vào các bias quy nạp được trích xuất từ LM, nó có thể hoạt động tốt nhất cho các mô hình lớn hơn. Nếu đúng, điều này có thể tạo ra rào cản truy cập cho những người có thể không có tài nguyên tính toán lớn. Chúng tôi hy vọng các nghiên cứu tương lai sẽ cẩn thận nghiên cứu lợi ích như một hàm của kích thước mô hình hoặc các tham số khác nhau khác. Đáng chú ý rằng tinh chỉnh hướng dẫn với chú thích của con người cũng gặp phải hạn chế tương tự: lợi ích của tinh chỉnh hướng dẫn cao hơn đối với các mô hình lớn hơn (Wei et al., 2022).

Tăng cường bias LM. Một điểm quan tâm của các tác giả là những hệ quả không mong muốn của thuật toán lặp này, chẳng hạn như sự khuếch đại của các bias xã hội có vấn đề (khuôn mẫu hoặc lời lăng mạ về giới tính, chủng tộc, v.v.). Liên quan, một thách thức được quan sát trong quá trình này là khó khăn của thuật toán trong việc tạo ra các nhãn cân bằng, phản ánh các bias trước của mô hình. Chúng tôi hy vọng công trình tương lai sẽ dẫn đến hiểu biết tốt hơn về ưu và nhược điểm của phương pháp.

Lời cảm ơn
Các tác giả muốn cảm ơn các nhà đánh giá ẩn danh vì phản hồi xây dựng của họ. Chúng tôi đặc biệt cảm ơn Sewon Min, Eric Wallace, Ofir Press, và các thành viên khác của UWNLP và AllenNLP vì phản hồi khuyến khích và hỗ trợ trí tuệ của họ. Công trình này được hỗ trợ một phần bởi chương trình DARPA MCS thông qua NIWC Pacific (N66001-19-2-4031), ONR N00014-18-1-2826, ONR MURI N00014-18-1-2670, và các tặng phẩm từ AI2 và giải thưởng Allen Investigator.

Tài liệu tham khảo
Massih-Reza Amini, Vasilii Feofanov, Loic Pauletto, Emilie Devijver, và Yury Maximov. 2022. Self-training: Một cuộc khảo sát. arXiv preprint arXiv:2202.12040.

Stephen H Bach, Victor Sanh, Zheng-Xin Yong, Albert Webson, Colin Raffel, Nihal V Nayak, Abheesht Sharma, Taewoon Kim, M Saiful Bari, Thibault Fevry, et al. 2022. PromptSource: Một Môi trường Phát triển Tích hợp và Kho lưu trữ cho Nhắc nhở Ngôn ngữ Tự nhiên. Trong Cuộc họp Thường niên của Hiệp hội Ngôn ngữ học Tính toán (ACL)-Triển lãm Hệ thống.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, và et al. 2020. Các mô hình ngôn ngữ là người học few-shot. Trong Tiến bộ trong Hệ thống Xử lý Thông tin Neural (NeurIPS).

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Mở rộng các mô hình ngôn ngữ được tinh chỉnh hướng dẫn. arXiv preprint arXiv:2210.11416.

Jingfei Du, Édouard Grave, Beliz Gunel, Vishrav Chaudhary, Onur Celebi, Michael Auli, Veselin Stoyanov, và Alexis Conneau. 2021. Tự huấn luyện cải thiện tiền huấn luyện cho hiểu biết ngôn ngữ tự nhiên. Trong Hội nghị của Chương Bắc Mỹ của Hiệp hội Ngôn ngữ học Tính toán (NAACL): Công nghệ Ngôn ngữ Con người, trang 5408-5418.

[Tiếp tục với tất cả các tài liệu tham khảo còn lại...]

--- TRANG 10 ---
[Tiếp tục dịch các phần còn lại bao gồm các bảng ví dụ, phụ lục chi tiết về triển khai, các mẫu nhắc nhở, và tất cả nội dung còn lại của tài liệu...]

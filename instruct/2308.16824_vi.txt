# 2308.16824.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/instruct/2308.16824.pdf
# Kích thước tệp: 304576 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
CÁC NGÔN NGỮ LẬP TRÌNH CÓ THỂ THÚC ĐẨY LẪN NHAU
THÔNG QUA ĐIỀU CHỈNH HƯỚNG DẪN KHÔNG?
BÁO CÁO KỸ THUẬT
Daoguang Zan†∗Ailun Yu§∗Bo Shen‡Jiaxin Zhang‡Taihong Chen‡Bing Geng‡Bei Chen¶
Jichuan Ji‡Yafen Yao‡Yongji Wang†Qianxiang Wang‡
†Viện Phần mềm, Viện Hàn lâm Khoa học Trung Quốc
§Đại học Bắc Kinh
‡Công ty Huawei Co., Ltd.
¶Nhà nghiên cứu độc lập
daoguang@iscas.ac.cn; yuailun@pku.edu.cn
TÓM TẮT
Khi các lập trình viên con người đã thành thạo một ngôn ngữ lập trình, sẽ dễ dàng hơn khi họ học một ngôn ngữ lập trình mới. Trong báo cáo này, chúng tôi tập trung khám phá liệu các ngôn ngữ lập trình có thể thúc đẩy lẫn nhau trong giai đoạn tinh chỉnh hướng dẫn của các mô hình ngôn ngữ lớn về mã không. Chúng tôi tiến hành các thí nghiệm mở rộng trên 8 ngôn ngữ lập trình phổ biến (Python, JavaScript, TypeScript, C, C++, Java, Go, HTML) trên StarCoder. Kết quả cho thấy các ngôn ngữ lập trình có thể cải thiện đáng kể lẫn nhau. Ví dụ, CODEM-Python 15B được huấn luyện trên Python có thể tăng Java lên 17.95% pass @1 tuyệt đối trên HumanEval-X. Đáng ngạc nhiên hơn, chúng tôi phát hiện rằng CODEM-HTML 7B được huấn luyện trên corpus HTML có thể cải thiện Java lên 15.24% pass @1 tuyệt đối. Dữ liệu huấn luyện của chúng tôi được phát hành tại https://github.com/NL2Code/CodeM .
Từ khóa Mô hình Ngôn ngữ Lớn ·Sinh Mã ·Ngôn Ngữ Lập Trình ·Điều Chỉnh Hướng Dẫn

1 Giới thiệu
Các mô hình ngôn ngữ lớn về mã (code LLMs) đang phát triển mạnh mẽ gần đây [Zan et al., 2023]. Rất nhiều code LLMs được phát hành liên tiếp, ví dụ như Codex [Chen et al., 2021], AlphaCode [Li et al., 2022], PaLM-Coder [Chowdhery et al., 2022], CodeGen [Nijkamp et al., 2023], CodeGeeX [Zheng et al., 2023], StarCoder [Li et al., 2023], và Code Llama [Rozière et al., 2023]. Nhờ hiệu suất sinh mã tuyệt vời của chúng, code LLMs đã thu hút sự chú ý đáng kể từ cả giới học thuật và công nghiệp. Các nghiên cứu gần đây [Ouyang et al., 2022] đã chứng kiến kỹ thuật điều chỉnh hướng dẫn có thể dạy LLMs cách tuân theo hướng dẫn. Trong lĩnh vực sinh mã, WizardCoder [Luo et al., 2023] và PanGu-Coder2 [Shen et al., 2023] cũng áp dụng kỹ thuật này để khai thác khả năng sinh mã của chúng.

Mặc dù một số code LLMs như CodeGen-Multi Nijkamp et al. [2023] và StarCoder-base Li et al. [2023] được huấn luyện trên corpus bao phủ nhiều ngôn ngữ lập trình, sự tương tác giữa các ngôn ngữ này vẫn chưa được khám phá.

Trong thực hành lập trình, một khi lập trình viên con người đã thành thạo một ngôn ngữ lập trình, sẽ dễ dàng hơn để học một ngôn ngữ mới do sự đồng nhất giữa các ngôn ngữ lập trình. Được thúc đẩy bởi điều này, chúng tôi muốn khám phá liệu các ngôn ngữ lập trình khác nhau có thể thúc đẩy lẫn nhau trong quá trình tinh chỉnh hướng dẫn của code LLMs hay không.

Để khám phá ý tưởng này, chúng tôi tạo ra corpus huấn luyện cho mỗi trong 8 ngôn ngữ lập trình phổ biến (Python, JavaScript, TypeScript, C, C++, Java, Go, HTML), trong đó mỗi ngôn ngữ bao gồm khoảng 9K bài tập lập trình. Chúng tôi huấn luyện StarCoder 7B bằng kỹ thuật điều chỉnh hướng dẫn trên từng corpus ngôn ngữ lập trình riêng biệt, và kiểm tra hiệu suất của mỗi mô hình được tinh chỉnh trên mọi ngôn ngữ lập trình. Các phát hiện của chúng tôi tiết lộ rằng các ngôn ngữ lập trình có thể thúc đẩy đáng kể lẫn nhau. Đồng thời, chúng tôi phát hiện rằng mức độ cải thiện của các ngôn ngữ lập trình khác nhau đối với nhau có liên quan đến sự tương đồng ngôn ngữ giữa chúng. Ví dụ, CODEM-JavaScript 7B được huấn luyện trên dữ liệu JavaScript có thể mang lại cải thiện 11.80% pass @1 tuyệt đối trong TypeScript. Thú vị hơn,

∗Hai tác giả đầu tiên đóng góp ngang nhau cho công việc này.arXiv:2308.16824v2  [cs.CL]  3 Sep 2023

--- TRANG 2 ---
BÁO CÁO KỸ THUẬT

# Hướng dẫn
Thiết kế một trang web hiển thị thông điệp khi tải. Thông điệp nên là "Hello, World". Sử dụng mã HTML để thực hiện điều này.

# Phản hồi
<!DOCTYPE html>
<html>
<head>
<title>Hello World</title>
</head>
<body>
<h1>Hello, World</h1>
</body>
</html>

Hình 1: Một ví dụ huấn luyện HTML về các cặp hướng dẫn-câu trả lời được tạo ra của chúng tôi.

CODEM-HTML 7B được huấn luyện trên ngôn ngữ đánh dấu HTML cũng có thể đạt được cải thiện 15.24% pass @1 tuyệt đối trong Java.

Tóm lại, các đóng góp của chúng tôi có thể được liệt kê như sau: (1) Các phát hiện của chúng tôi cho thấy các ngôn ngữ lập trình có thể thúc đẩy đáng kể lẫn nhau trong giai đoạn tinh chỉnh hướng dẫn của code LLMs. (2) Chúng tôi thu thập những hiểu biết có giá trị về mối tương quan giữa nhiều ngôn ngữ lập trình, mở đường cho nghiên cứu tương lai về sinh mã. (3) Chúng tôi sẽ công khai dữ liệu huấn luyện của mình.

2 Phương pháp

2.1 Tạo ra Corpus Huấn luyện của Tám Ngôn ngữ Lập trình

Chúng tôi chọn 8 ngôn ngữ lập trình phổ biến và xây dựng dữ liệu huấn luyện của chúng riêng biệt. Các ngôn ngữ được chọn bao gồm Python, JavaScript, TypeScript, C, C++, Java, Go, và HTML, bao phủ các loại đa dạng như ngôn ngữ hướng thủ tục, hướng đối tượng, script, và thậm chí cả ngôn ngữ đánh dấu. Đối với mỗi ngôn ngữ lập trình, chúng tôi xây dựng dữ liệu huấn luyện chứa khoảng 9K cặp dữ liệu. Mỗi cặp bao gồm cả hướng dẫn mô tả bài toán lập trình và phản hồi tương ứng. Một ví dụ thực tế về HTML được hiển thị trong Hình 1.

Dựa trên các ngôn ngữ được chọn này, chúng tôi xây dựng một loạt các tập dữ liệu đơn ngữ. Chúng tôi bắt đầu từ tập dữ liệu CodeAlpaca 20K², và trích xuất những dữ liệu liên quan đến Python để tạo thành tập hướng dẫn gốc. Sau đó, đối với mỗi ngôn ngữ lập trình được chọn, chúng tôi phát triển các hướng dẫn hiện có trong tập hướng dẫn gốc để có được những hướng dẫn mới tương ứng bằng cách nhắc OpenAI's GPT-3.5³. Đối với tất cả các ngôn ngữ được chọn ngoại trừ HTML, chúng tôi áp dụng sự phát triển sâu [Xu et al., 2023], bằng cách yêu cầu GPT-3.5 viết lại hướng dẫn gốc (Python) thành một phiên bản phức tạp hơn liên quan đến ngôn ngữ đích (Python, JavaScript, TypeScript, C, C++, Java, hoặc Go). Tuy nhiên, đối với HTML, chúng tôi áp dụng sự phát triển rộng để tạo ra một hướng dẫn liên quan đến HTML hoàn toàn mới, vì HTML (ngôn ngữ đánh dấu) quá khác biệt so với các ngôn ngữ khác (ngôn ngữ không đánh dấu).

2.2 Điều chỉnh Hướng dẫn

Các mô hình được tiền huấn luyện về mã như Codex [Chen et al., 2021] và StarCoder [Li et al., 2023] lưu trữ kho tàng kiến thức mã. Tuy nhiên, các mô hình này chỉ hỗ trợ sinh mã từ trái sang phải dựa trên ngữ cảnh, vì chúng chỉ được huấn luyện trên các đoạn mã đơn giản. Gần đây, các kỹ thuật điều chỉnh hướng dẫn [Ouyang et al., 2022, Luo et al., 2023, Shen et al., 2023] được đề xuất, có thể nâng cao khả năng tuân theo hướng dẫn của mô hình để kích hoạt các tính năng trò chuyện. Trong quá trình điều chỉnh hướng dẫn, chúng tôi huấn luyện StarCoder bằng prompt trong Hình 2 để có được CODEM của chúng tôi. Chúng tôi sử dụng DeepSpeed để tăng tốc quá trình huấn luyện CODEM với fp16 được kích hoạt. Ngoài ra, chúng tôi đặt kích thước batch là 2 trên mỗi GPU, tốc độ học là 2e-5 với lịch trình annealing cosine, các bước tích lũy gradient là 4, và các bước khởi động là 30. Sau khi điều chỉnh hướng dẫn, chúng tôi sử dụng prompt trong Hình 3 để thực hiện suy luận trên các nhiệm vụ downstream trên nhiều ngôn ngữ lập trình khác nhau. Đối với suy luận, chúng tôi áp dụng chiến lược giải mã tham lam để lấy mẫu. Cho rằng CODEM là một

²https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k
³https://platform.openai.com/docs/models/gpt-3-5

2

--- TRANG 3 ---
BÁO CÁO KỸ THUẬT

Dưới đây là một hướng dẫn mô tả một nhiệm vụ, được ghép nối với một đầu vào cung cấp thêm ngữ cảnh. Viết một phản hồi hoàn thành yêu cầu một cách thích hợp.

### Hướng dẫn:
{problem}

### Phản hồi:
{response}

Hình 2: Định dạng prompt của điều chỉnh hướng dẫn. {problem} và {response} đề cập đến hướng dẫn và câu trả lời thu được trong Phần 2.1.

Dưới đây là một hướng dẫn mô tả một nhiệm vụ. Viết một phản hồi hoàn thành yêu cầu một cách thích hợp.

### Hướng dẫn:
Hoàn thành mã {language} cho bài toán này:
{problem}

### Phản hồi:
{signature}

Hình 3: Định dạng prompt của suy luận. {language}, {problem}, và {signature} đại diện cho ngôn ngữ lập trình downstream, bài toán lập trình được cho, và tiêu đề hàm, tương ứng.

mô hình kiểu trò chuyện, các phản hồi mà nó tạo ra thường chứa các yếu tố ngoài mã, điều này thường khiến chúng không thể thực thi. Vì vậy, chúng tôi trích xuất các đoạn mã từ phản hồi được tạo ra để đánh giá hiệu suất sinh mã.

3 Thí nghiệm

3.1 Thiết lập Đánh giá

3.1.1 Benchmarks và Baselines

Chúng tôi sử dụng HumanEval-X [Zheng et al., 2023] để đánh giá khả năng đa ngôn ngữ của các mô hình trong Python, JavaScript, C++, Java, và Go. HumanEval-X được tạo ra bằng cách điều chỉnh HumanEval [Chen et al., 2021] (Python) sang các ngôn ngữ lập trình khác. Theo cùng cách tiếp cận như HumanEval-X, chúng tôi cũng tạo ra hai phiên bản mới của HumanEval: HumanEval-C và HumanEval-TypeScript. Lưu ý rằng HumanEval không thể được điều chỉnh trực tiếp sang các ngôn ngữ đánh dấu như HTML, vì vậy các ngôn ngữ đánh giá downstream của chúng tôi không bao gồm HTML.

Baseline chính cho tất cả các phiên bản ngôn ngữ của CODEM là mô hình cơ sở StarCoder của chúng. Chúng tôi phân tích xem CODEM được huấn luyện trên ngôn ngữ A có thể cải thiện ngôn ngữ B hay không, trong trường hợp đó các baseline là CODEM được huấn luyện trực tiếp trên ngôn ngữ B.

3.1.2 Metrics

Chúng tôi áp dụng pass @1 làm metric để đánh giá tất cả các mô hình. Mỗi mô hình tạo ra một câu trả lời bằng chiến lược giải mã tham lam cho mỗi nhiệm vụ lập trình, và câu trả lời sẽ được thực thi trên các test case được cho. Chỉ khi tất cả các test case được vượt qua, nhiệm vụ lập trình mới có thể được coi là đã giải quyết với mã được tạo ra. Trong thiết lập này, pass @1 có thể được hình thức hóa như |Pc|/|P|, trong đó |P| biểu thị tổng số nhiệm vụ lập trình trong HumanEval và |Pc| đại diện cho số nhiệm vụ đã giải quyết. Về bản chất, metric pass @1 mà chúng tôi sử dụng có thể được coi là độ chính xác.

3.2 Kết quả

3.2.1 Kết quả Chính

Bảng 1 hiển thị hiệu suất của CODEM, đây là một loạt các mô hình được huấn luyện trên các tập dữ liệu đơn ngữ của tám ngôn ngữ tương ứng, trên các phiên bản ngôn ngữ khác nhau của HumanEval. Như chúng ta có thể thấy, tất cả các mô hình CODEM đều vượt trội

3

--- TRANG 4 ---
BÁO CÁO KỸ THUẬT

Bảng 1: Pass @1 (Độ chính xác) của StarCoder 7B và CODEM được huấn luyện trên các ngôn ngữ lập trình khác nhau. Các số màu đỏ biểu thị sự tăng tuyệt đối so với StarCoder 7B.

Mô hình                    HumanEval-Đa ngôn ngữ
                 Python JavaScript TypeScript C     C++   Java  Go
StarCoder 7B     26.83  24.39     28.57     24.69 25.61 23.17 24.39
CODEM-Python     38.41¹¹·⁵⁸ 34.76¹⁰·³⁷ 33.54⁴·⁹⁷ 29.01⁴·³² 34.15⁸·⁵⁴ 37.20¹⁴·⁰³ 27.44³·⁰⁵
CODEM-JavaScript 37.20¹⁰·³⁷ 40.24¹⁵·⁸⁵ 40.37¹¹·⁸⁰ 27.78³·⁰⁹ 32.93⁷·³² 34.76¹¹·⁵⁹ 26.22¹·⁸³
CODEM-TypeScript 33.54⁶·⁷¹ 37.80¹³·⁴¹ 37.27⁸·⁷⁰ 30.25⁵·⁵⁶ 30.49⁴·⁸⁸ 28.05⁴·⁸⁸ 25.61¹·²²
CODEM-C          39.63¹²·⁸⁰ 37.20¹²·⁸¹ 32.30³·⁷³ 32.10⁷·⁴¹ 35.37⁹·⁷⁶ 38.41¹⁵·²⁴ 28.66⁴·²⁷
CODEM-C++        34.57⁷·⁷⁴ 35.37¹⁰·⁹⁸ 32.30³·⁷³ 34.57⁹·⁸⁰ 39.02¹³·⁴¹ 37.20¹⁴·⁰³ 28.05³·⁶⁶
CODEM-Java       35.37⁸·⁵⁴ 33.54⁹·¹⁵ 32.30³·⁷³ 29.63⁴·⁹⁴ 31.10⁵·⁴⁹ 37.80¹⁴·⁶³ 27.44³·⁰⁵
CODEM-Go         35.98⁹·¹⁵ 33.54⁹·¹⁵ 31.68³·¹¹ 30.25⁵·⁵⁶ 34.15⁸·⁵⁴ 35.98¹²·⁸¹ 32.32⁷·⁹³
CODEM-HTML       31.71⁴·⁸⁸ 33.54⁹·¹⁵ 32.30³·⁷³ 25.93¹·²⁴ 28.66³·⁰⁵ 38.41¹⁵·²⁴ 28.05³·⁶⁶
CODEM-Mixed      43.29¹⁶·⁴⁶ 37.20¹²·⁸¹ 37.89⁹·³² 32.10⁷·⁴¹ 37.80¹²·¹⁹ 39.63¹⁶·⁴⁶ 29.27⁴·⁸⁸

Bảng 2: Pass @1 của StarCoder 15B và CODEM-Python. Các số màu đỏ biểu thị sự cải thiện tuyệt đối so với StarCoder 15B.

Mô hình               HumanEval-Đa ngôn ngữ
                 Python JavaScript TypeScript C     C++   Java  Go
StarCoder 15B    32.93  30.79     32.29     26.99 31.55 30.22 17.61
CODEM-Python     64.63³¹·⁷⁰ 47.56¹⁶·⁷⁷ 39.75⁷·⁴⁶ 35.19⁸·²⁰ 43.80¹²·²⁵ 48.17¹⁷·⁹⁵ 34.76¹⁷·¹⁵

mô hình cơ sở StarCoder 7B của chúng trên tất cả các ngôn ngữ lập trình với một biên độ lớn. Ngoài ra, chúng tôi phát hiện rằng các ngôn ngữ lập trình có thể thúc đẩy lẫn nhau một cách đáng kể. Ví dụ, CODEM-Python chỉ được huấn luyện trên corpus Python có thể cải thiện HumanEval-Java lên 14.03% pass @1 tuyệt đối. Phát hiện này tiết lộ những điểm chung vốn có giữa các ngôn ngữ lập trình khác nhau. Đáng ngạc nhiên hơn, CODEM-HTML thúc đẩy HumanEval-Java lên 15.24% pass@1 tuyệt đối, thậm chí vượt quá CODEM-Java. Tương tự, CODEM-C++ đánh bại CODEM-C trên HumanEval-C, và CODEM-JavaScript đánh bại CODEM-TypeScript trên HumanEval-Typescript. Dựa trên những quan sát này, chúng tôi phỏng đoán rằng sự cải thiện trong hiệu suất sinh mã đa ngôn ngữ chủ yếu do điều chỉnh hướng dẫn mở khóa tiềm năng vốn có của mô hình, như hiểu biết ngôn ngữ tự nhiên hoặc lập trình và khả năng tuân theo hướng dẫn, thay vì chỉ đơn thuần kết hợp kiến thức mới. Ngoài việc huấn luyện CODEM trên corpus huấn luyện đơn ngữ, chúng tôi tiếp tục xây dựng một tập huấn luyện đa ngôn ngữ 9K bao gồm 8 ngôn ngữ lập trình. Mặc dù mỗi ngôn ngữ chỉ bao gồm một lượng nhỏ (~ 1.2K) các instance huấn luyện, các phát hiện thực nghiệm cho thấy CODEM-Mixed xuất sắc trong tất cả các ngôn ngữ, thậm chí vượt qua CODEM-Python trên HumanEval-Python và CODEM-Java trên HumanEval-Java. Điều này cho thấy có thể đạt được hiệu suất sinh mã vượt trội bằng cách tận dụng dữ liệu đa ngôn ngữ trong điều chỉnh hướng dẫn, mà không làm hại khả năng tổng quát hóa của mô hình.

Chúng tôi cũng tiến hành thí nghiệm trên StarCoder 15B để xác minh hiệu quả của CODEM. Cụ thể, chúng tôi thu được 108K dữ liệu huấn luyện Python theo WizardCoder [Luo et al., 2023], và tinh chỉnh StarCoder 15B để có được CODEM-Python. Kết quả được hiển thị trong Bảng 2. CODEM-Python đạt được hiệu suất tối ưu trên HumanEval-Python với 64.63% pass @1, so với các mô hình khác cùng quy mô. CODEM-Python cũng có được sự cải thiện to lớn trong việc sinh ra các ngôn ngữ lập trình khác. Ví dụ, nó cải thiện Java và JavaScript lên 17.95% và 16.77% pass @1 tuyệt đối, tương ứng.

3.2.2 Phân tích Sâu hơn

Chúng tôi phân tích mối tương quan giữa các ngôn ngữ lập trình khác nhau. Như được minh họa trong Hình 4 (a), sự cải thiện hiệu suất sinh mã nhạy cảm với corpus huấn luyện của các ngôn ngữ lập trình khác nhau. Hơn nữa, chúng tôi phát hiện rằng C và C++ có thể thúc đẩy lẫn nhau mạnh mẽ hơn, điều tương tự cũng xảy ra với JavaScript và TypeScript. Điều này hợp lý vì những ngôn ngữ này có mối tương quan với nhau trong thiết kế ngôn ngữ, chia sẻ một số cú pháp và ngữ pháp chung. Hình 4 (b) cho thấy việc huấn luyện trên mỗi ngôn ngữ lập trình có thể thúc đẩy hiệu suất sinh mã của tất cả các ngôn ngữ khác. Chúng ta có thể thấy rằng các giá trị tương quan trong Hình 4 (b) hầu hết đều dương, ngụ ý rằng xu hướng cải thiện của các ngôn ngữ khác nhau được mang lại bởi một corpus huấn luyện đơn ngữ tương đối tương tự.

4

--- TRANG 5 ---
BÁO CÁO KỸ THUẬT

Python JS TS C C++ Java GoPython JS TS C C++ Java Go1
0.33 1
0.06 0.87 1
0.27 0.05 -0.3 1
0.5 0.1 -0.22 0.84 1
0.26 -0.5 -0.63 -0.01 0.26 1
0.1 -0.62 -0.72 0.2 0.28 0.43 1
1.00
0.75
0.50
0.25
0.000.250.500.751.00
(a)

Python JS TS C C++ Java Go HTMLPythonJS TS C C++ Java Go HTML1
0.75 1
0.42 0.87 1
0.94 0.62 0.34 1
0.62 0.35 0.18 0.71 1
0.92 0.66 0.29 0.89 0.57 1
0.84 0.37 -0.05 0.82 0.46 0.77 1
0.73 0.63 0.22 0.65 0.31 0.88 0.68 1
0.00.20.40.60.81.0 (b)

Hình 4: Mối tương quan giữa các ngôn ngữ lập trình khác nhau. Chúng tôi coi dữ liệu trong Bảng 1 như một ma trận, và sử dụng " df.corr() " từ thư viện Pandas để tính toán mối tương quan giữa các ngôn ngữ lập trình khác nhau. Kết quả tương quan trước và sau " df.T " được trình bày trong (a) và (b), tương ứng.

4 Công trình Liên quan

Codex [Chen et al., 2021] với 12 tỷ tham số có thể giải quyết các bài toán lập trình Python một cách tự động. Thành công đáng chú ý này đã tạo ra một tiếng vang lớn trong cả lĩnh vực học thuật và công nghiệp. Tiếp theo Codex, rất nhiều code LLMs được đề xuất, bao gồm AlphaCode [Li et al., 2022], PaLM-Coder [Chowdhery et al., 2022], CodeGen [Nijkamp et al., 2023], InCoder [Fried et al., 2023], CodeGeeX [Zheng et al., 2023], replit⁴, CodeT5 [Wang et al., 2021, 2023], PyCodeGPT [Zan et al., 2022], SantaCoder [Allal et al., 2023], StarCoder [Li et al., 2023], Code Llama [Rozière et al., 2023], và phi-1 [Gunasekar et al., 2023]. Những mô hình trên được huấn luyện trên corpus mã quy mô lớn và đạt được hiệu suất sinh mã ấn tượng. Trong quá trình tiền huấn luyện của chúng, một số mô hình được huấn luyện trên tập dữ liệu của các ngôn ngữ lập trình đa ngữ và sau đó được tinh chỉnh trên tập dữ liệu đơn ngữ để tạo ra phiên bản chuyên gia mạnh mẽ hơn. Đối với giai đoạn tinh chỉnh hướng dẫn, WizardCoder [Luo et al., 2023], PanGu-Coder2 [Shen et al., 2023], và Phind-CodeLlama⁵ được đề xuất để củng cố khả năng tuân theo hướng dẫn và tiếp tục thúc đẩy khả năng sinh mã. Tuy nhiên, không có mô hình nào trong những mô hình đã đề cập trước đây khám phá sự tương tác phức tạp giữa các ngôn ngữ lập trình khác nhau. Trong báo cáo này, do đó chúng tôi muốn điều tra xem việc huấn luyện code LLMs trên dữ liệu đơn ngữ có thể củng cố hiệu suất trong các ngôn ngữ lập trình khác hay không.

5 Kết luận

Các phát hiện của chúng tôi tiết lộ rằng corpus huấn luyện đơn ngữ có thể nâng cao khả năng sinh mã đa ngôn ngữ của code LLMs thông qua điều chỉnh hướng dẫn. Điều này làm nổi bật sự chung và kết nối vốn có giữa nhiều ngôn ngữ lập trình. Trong công việc tương lai, chúng tôi dự định đi sâu vào lý do tại sao nhiều ngôn ngữ có thể nâng cao lẫn nhau. Ngoài ra, chúng tôi sẽ khám phá cách tận dụng các phát hiện của mình để nâng cao khả năng sinh mã cho những ngôn ngữ lập trình ít được biết đến hoặc ít sử dụng bằng cách huấn luyện trên dữ liệu từ những ngôn ngữ phổ biến.

Lời cảm ơn

Chúng tôi muốn cảm ơn các đồng nghiệp vì những phản hồi và hiểu biết có giá trị. Đặc biệt cảm ơn An Fu (Huawei), Jingyang Zhao (Huawei), và Yuenan Guo (Huawei) vì sự giúp đỡ mang tính xây dựng trong suốt nghiên cứu này.

Tài liệu tham khảo

Daoguang Zan, Bei Chen, Fengji Zhang, Dianjie Lu, Bingchao Wu, Bei Guan, Wang Yongji, và Jian-Guang Lou. Large language models meet NL2Code: A survey. Trong Proceedings of the 61st Annual Meeting of the Association for

⁴https://huggingface.co/replit/replit-code-v1-3b
⁵https://huggingface.co/Phind/Phind-CodeLlama-34B-v1

5

--- TRANG 6 ---
BÁO CÁO KỸ THUẬT

Computational Linguistics (Volume 1: Long Papers), trang 7443–7464, Toronto, Canada, tháng 7 năm 2023. Association for Computational Linguistics. URL https://aclanthology.org/2023.acl-long.411 .

Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, Jared Kaplan, Harrison Edwards, Yura Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, David W. Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William H. Guss, Alex Nichol, Igor Babuschkin, S. Arun Balaji, Shantanu Jain, Andrew Carr, Jan Leike, Joshua Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew M. Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, và Wojciech Zaremba. Evaluating large language models trained on code. ArXiv, abs/2107.03374, 2021.

Yujia Li, David H. Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom, Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien de, Masson d'Autume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey, Cherepanov, James Molloy, Daniel Jaymin Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de, Freitas, Koray Kavukcuoglu, và Oriol Vinyals. Competition-level code generation with alphacode. Science, 378:1092 – 1097, 2022.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam M. Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Benton C. Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier García, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Díaz, Orhan Firat, Michele Catasta, Jason Wei, Kathleen S. Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, và Noah Fiedel. PaLM: Scaling language modeling with pathways. ArXiv, abs/2204.02311, 2022.

Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, và Caiming Xiong. CodeGen: An open large language model for code with multi-turn program synthesis. Trong The Eleventh International Conference on Learning Representations, 2023.

Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shanshan Wang, Yufei Xue, Zi-Yuan Wang, Lei Shen, Andi Wang, Yang Li, Teng Su, Zhilin Yang, và Jie Tang. CodeGeeX: A pre-trained model for code generation with multilingual evaluations on humaneval-x. ArXiv, abs/2303.17568, 2023.

Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, João Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Muñoz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, và Harm de Vries. StarCoder: may the source be with you!, 2023.

Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, Artyom Kozhevnikov, Ivan Evtimov, Joanna Bitton, Manish Bhatt, Cristian Canton Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre Défossez, Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas Scialom, và Gabriel Synnaeve. Code Llama: Open foundation models for code, 2023.

Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke E. Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Francis Christiano, Jan Leike, và Ryan J. Lowe. Training language models to follow instructions with human feedback. ArXiv, abs/2203.02155, 2022.

Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, và Daxin Jiang. WizardCoder: Empowering code large language models with evol-instruct. arXiv preprint arXiv:2306.08568, 2023.

6

--- TRANG 7 ---
BÁO CÁO KỸ THUẬT

Bo Shen, Jiaxin Zhang, Taihong Chen, Daoguang Zan, Bing Geng, An Fu, Muhan Zeng, Ailun Yu, Jichuan Ji, Jingyang Zhao, Yuenan Guo, và Qianxiang Wang. PanGu-Coder2: Boosting large language models for code with ranking feedback, 2023.

Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, và Daxin Jiang. WizardLM: Empowering large language models to follow complex instructions, 2023.

Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong, Scott Yih, Luke Zettlemoyer, và Mike Lewis. InCoder: A generative model for code infilling and synthesis. Trong The Eleventh International Conference on Learning Representations, 2023.

Yue Wang, Weishi Wang, Shafiq Joty, và Steven CH Hoi. CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, trang 8696–8708, 2021.

Yue Wang, Hung Le, Akhilesh Deepak Gotmare, Nghi D. Q. Bui, Junnan Li, và Steven C. H. Hoi. Codet5+: Open code large language models for code understanding and generation, 2023.

Daoguang Zan, Bei Chen, Dejian Yang, Zeqi Lin, Minsu Kim, Bei Guan, Yongji Wang, Weizhu Chen, và Jian-Guang Lou. CERT: Continual pre-training on sketches for library-oriented code generation. Trong International Joint Conference on Artificial Intelligence, 2022.

Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Muñoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alexander Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, J. Poirier, Hailey Schoelkopf, Sergey Mikhailovich Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Franz Lappert, Francesco De Toni, Bernardo García del Río, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David Lansky, Huu Nguyen, Danish Contractor, Luisa Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Christopher Hughes, Daniel Fried, Arjun Guha, Harm de Vries, và Leandro von Werra. SantaCoder: don't reach for the stars! ArXiv, abs/2301.03988, 2023.

Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Harkirat Singh Behl, Xin Wang, Sébastien Bubeck, Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee, và Yuanzhi Li. Textbooks are all you need, 2023.

7

# 2110.08207.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/instruct/2110.08207.pdf
# Kích thước tệp: 2087672 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022
HUẤN LUYỆN ĐA NHIỆM VỤ VỚI PROMPT
CHO KHẢ NĂNG TỔNG QUÁT HÓA ZERO-SHOT
Victor Sanh
Hugging FaceAlbert Webson
Brown UniversityColin Raffel
Hugging FaceStephen H. Bach
Brown & Snorkel AI
Lintang Sutawika
BigScienceZaid Alyafeai
KFUPMAntoine Chafﬁn
IRISA & IMATAGArnaud Stiegler
HyperscienceTeven Le Scao
Hugging Face
Arun Raja
I2R, SingaporeManan Dey
SAPM Saiful Bari
NTU, SingaporeCanwen Xu
UCSD & Hugging FaceUrmish Thakker
SambaNova Systems
Shanya Sharma
Walmart LabsEliza Szczechla
BigScienceTaewoon Kim
VU AmsterdamGunjan Chhablani
BigScienceNihal V . Nayak
Brown University
Debajyoti Datta
University of VirginiaJonathan Chang
ASUSMike Tian-Jian Jiang
ZEALS, JapanHan Wang
NYUMatteo Manica
IBM Research
Sheng Shen
UC BerkeleyZheng-Xin Yong
Brown UniversityHarshit Pandey
BigScienceMichael McKenna
ParityRachel Bawden
Inria, France
Thomas Wang
Inria, FranceTrishala Neeraj
BigScienceJos Rozen
Naver Labs EuropeAbheesht Sharma
BITS Pilani, IndiaAndrea Santilli
University of Rome
Thibault Fevry
BigScienceJason Alan Fries
Stanford & Snorkel AIRyan Teehan
Charles River AnalyticsTali Bers
Brown University
Stella Biderman
Booz Allen & EleutherAILeo Gao
EleutherAIThomas Wolf
Hugging FaceAlexander M. Rush
Hugging Face

TÓM TẮT
Các mô hình ngôn ngữ lớn gần đây đã được chứng minh là đạt được khả năng tổng quát hóa zero-shot hợp lý trên một tập hợp đa dạng các nhiệm vụ (Brown và cộng sự, 2020). Người ta đã đưa ra giả thuyết rằng điều này là hệ quả của việc học đa nhiệm vụ ngầm trong quá trình tiền huấn luyện của các mô hình ngôn ngữ (Radford và cộng sự, 2019). Liệu khả năng tổng quát hóa zero-shot có thể được gây ra trực tiếp bởi việc học đa nhiệm vụ rõ ràng không? Để kiểm tra câu hỏi này ở quy mô lớn, chúng tôi phát triển một hệ thống để dễ dàng ánh xạ bất kỳ nhiệm vụ ngôn ngữ tự nhiên nào thành dạng prompt có thể đọc được bởi con người. Chúng tôi chuyển đổi một tập lớn các bộ dữ liệu được giám sát, mỗi bộ có nhiều prompt với cách diễn đạt đa dạng. Các bộ dữ liệu prompt này cho phép đánh giá khả năng của một mô hình thực hiện các nhiệm vụ hoàn toàn bị giữ lại. Chúng tôi tinh chỉnh một mô hình encoder-decoder được tiền huấn luyện (Raffel và cộng sự, 2020; Lester và cộng sự, 2021) trên hỗn hợp đa nhiệm vụ này bao gồm nhiều loại nhiệm vụ khác nhau. Mô hình đạt được hiệu suất zero-shot mạnh trên một số bộ dữ liệu tiêu chuẩn, thường vượt trội hơn các mô hình lớn gấp 16 lần kích thước của nó. Hơn nữa, phương pháp của chúng tôi đạt được hiệu suất mạnh trên một tập con các nhiệm vụ từ benchmark BIG-bench, vượt trội hơn các mô hình lớn gấp 6 lần kích thước của nó. Tất cả các mô hình được huấn luyện đều có sẵn tại https://github.com/bigscience-workshop/t-zero, và tất cả các prompt đều có sẵn tại https://github.com/bigscience-workshop/promptsource.

1 GIỚI THIỆU
Nghiên cứu gần đây đã cho thấy rằng các mô hình ngôn ngữ lớn thể hiện khả năng thực hiện tổng quát hóa zero-shot hợp lý cho các nhiệm vụ mới (Brown và cộng sự, 2020; Kim và cộng sự, 2021). Mặc dù chỉ được huấn luyện trên các mục tiêu mô hình hóa ngôn ngữ, những mô hình này có thể thực hiện tương đối tốt các nhiệm vụ mới mà chúng chưa được huấn luyện một cách rõ ràng để thực hiện, ví dụ như trả lời câu hỏi về một đoạn văn hoặc thực hiện

Đóng góp ngang nhau. Danh sách đầy đủ các đóng góp cá nhân được chi tiết trong Phụ lục A. Các tác giả liên hệ:
victor@huggingface.co và awebson@brown.edu.
1arXiv:2110.08207v3  [cs.LG]  17 Mar 2022

--- TRANG 2 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022

Đánh giá: Chúng tôi đến đây vào tối thứ Bảy 
và may mắn là không đông đúc như tôi 
nghĩ [...] Trên thang điểm từ 1 
đến 5, tôi sẽ cho điểm này 

Tôi biết rằng câu trả lời cho " Đội nào mà 
Panthers đã đánh bại? " có trong " Panthers 
đã kết thúc mùa giải thường [...] ". Bạn có 
thể cho tôi biết đó là gì không? T0Nghệ sĩ graffiti Banksy 
được cho là đứng 
sau [...] 

4
CóArizona Cardinals Tóm tắt 
Trả lời câu hỏi Phân tích cảm xúc 

Giả sử " Nhân viên ngân hàng đã liên lạc với các 
giáo sư và vận động viên".  Chúng ta có thể suy ra 
rằng " Nhân viên ngân hàng đã liên lạc với các 
giáo sư " không?Bức tranh xuất hiện trên tường của một 
cửa hàng Poundland trên đường Whymark Avenue [...] 
Bạn sẽ diễn đạt lại điều đó như thế nào trong vài từ? 

Suy luận ngôn ngữ tự nhiên Huấn luyện đa nhiệm vụ 
Tổng quát hóa zero-shot 

Hình 1: Mô hình và định dạng prompt của chúng tôi. T0 là một mô hình encoder-decoder tiêu thụ các đầu vào dạng văn bản và tạo ra các phản hồi mục tiêu. Nó được huấn luyện trên một hỗn hợp đa nhiệm vụ của các bộ dữ liệu NLP được phân chia thành các nhiệm vụ khác nhau. Mỗi bộ dữ liệu được liên kết với nhiều mẫu prompt được sử dụng để định dạng các thể hiện ví dụ thành các cặp đầu vào và mục tiêu. Chữ in nghiêng biểu thị các trường được chèn từ dữ liệu ví dụ thô. Sau khi huấn luyện trên một hỗn hợp đa dạng các nhiệm vụ (trên), mô hình của chúng tôi được đánh giá trên khả năng tổng quát hóa zero-shot cho các nhiệm vụ không được nhìn thấy trong quá trình huấn luyện (dưới).

tóm tắt. Một giả thuyết có ảnh hưởng là các mô hình ngôn ngữ lớn tổng quát hóa cho các nhiệm vụ mới như là kết quả của một quá trình học đa nhiệm vụ ngầm (Radford và cộng sự, 2019). Như một sản phẩm phụ của việc học dự đoán từ tiếp theo, một mô hình ngôn ngữ bị buộc phải học từ một hỗn hợp các nhiệm vụ ngầm được bao gồm trong corpus tiền huấn luyện của chúng. Ví dụ, bằng cách huấn luyện trên văn bản chung từ một diễn đàn web, một mô hình có thể học ngầm định dạng và cấu trúc của việc trả lời câu hỏi. Điều này mang lại cho các mô hình ngôn ngữ lớn khả năng tổng quát hóa cho các nhiệm vụ giữ lại được trình bày với các prompt ngôn ngữ tự nhiên, vượt ra ngoài các nghiên cứu đa nhiệm vụ trước đây về tổng quát hóa cho các bộ dữ liệu giữ lại (Khashabi và cộng sự, 2020a; Ye và cộng sự, 2021). Tuy nhiên, khả năng này đòi hỏi một mô hình đủ lớn và nhạy cảm với cách diễn đạt của các prompt (Perez và cộng sự, 2021; Zhao và cộng sự, 2021; Reynolds và McDonell, 2021).

Hơn nữa, đó là một câu hỏi mở về việc học đa nhiệm vụ này thực sự ngầm đến mức nào. Với quy mô của các corpus tiền huấn luyện của các mô hình ngôn ngữ gần đây, có thể hợp lý khi mong đợi rằng một số nhiệm vụ xử lý ngôn ngữ tự nhiên (NLP) phổ biến sẽ xuất hiện dưới dạng rõ ràng trong corpus tiền huấn luyện của chúng, do đó huấn luyện trực tiếp các mô hình trên những nhiệm vụ đó. Ví dụ, có nhiều trang web chỉ đơn giản chứa danh sách các câu hỏi và câu trả lời trivia,¹ đây chính xác là dữ liệu huấn luyện có giám sát cho nhiệm vụ trả lời câu hỏi sách đóng (Roberts và cộng sự, 2020). Chúng tôi giả thuyết rằng việc giám sát đa nhiệm vụ như vậy trong tiền huấn luyện đóng một vai trò lớn trong tổng quát hóa zero-shot.

Trong bài báo này, chúng tôi tập trung vào việc huấn luyện rõ ràng các mô hình ngôn ngữ theo cách được giám sát và đa nhiệm vụ lớn. Phương pháp của chúng tôi sử dụng một hỗn hợp huấn luyện bao gồm một tập lớn các nhiệm vụ khác nhau được chỉ định trong các prompt ngôn ngữ tự nhiên. Mục tiêu của chúng tôi là tạo ra một mô hình để tổng quát hóa tốt hơn cho các nhiệm vụ giữ lại mà không cần quy mô lớn, cũng như mạnh mẽ hơn đối với các lựa chọn cách diễn đạt của các prompt.

Để chuyển đổi một tập lớn các nhiệm vụ ngôn ngữ tự nhiên thành dạng prompt, chúng tôi sử dụng một ngôn ngữ mẫu đơn giản cho các bộ dữ liệu có cấu trúc. Chúng tôi phát triển một giao diện để thu thập prompt từ những người đóng góp công cộng đã tạo điều kiện cho việc thu thập một hỗn hợp đa nhiệm vụ lớn với nhiều prompt cho mỗi bộ dữ liệu (Bach và cộng sự, 2022). Sau đó, chúng tôi huấn luyện một biến thể của mô hình encoder-decoder T5 (Raffel và cộng sự, 2020; Lester và cộng sự, 2021) trên một tập con của các nhiệm vụ (mỗi nhiệm vụ với nhiều bộ dữ liệu) và sau đó đánh giá các nhiệm vụ và prompt mà mô hình không được huấn luyện.

Các thí nghiệm của chúng tôi nghiên cứu hai câu hỏi. Thứ nhất, liệu huấn luyện đa nhiệm vụ với prompt có cải thiện tổng quát hóa cho các nhiệm vụ giữ lại không? Thứ hai, liệu huấn luyện trên một phạm vi rộng hơn các prompt có cải thiện độ mạnh mẽ đối với cách diễn đạt prompt không? Đối với câu hỏi đầu tiên, chúng tôi thấy rằng huấn luyện đa nhiệm vụ cho phép tổng quát hóa nhiệm vụ zero-shot bằng cách cho thấy rằng mô hình của chúng tôi phù hợp hoặc vượt trội hơn hiệu suất của GPT-3 (Brown và cộng sự, 2020) trên 9 trong số 11 bộ dữ liệu giữ lại, mặc dù nhỏ hơn khoảng 16 lần. Chúng tôi cũng cho thấy rằng mô hình cải thiện so với một mô hình ngôn ngữ cơ sở lớn trên 13 trong số 14 nhiệm vụ trong benchmark BIG-bench (BIG-bench collaboration, 2021). Đối với câu hỏi thứ hai, chúng tôi thấy rằng huấn luyện trên nhiều prompt hơn cho mỗi bộ dữ liệu liên tục cải thiện hiệu suất trung vị và giảm độ biến thiên của hiệu suất trên các nhiệm vụ giữ lại. Huấn luyện trên các prompt từ một phạm vi rộng hơn các bộ dữ liệu cũng thường cải thiện hiệu suất trung vị nhưng không liên tục giảm độ biến thiên.

2 CÔNG TRÌNH LIÊN QUAN
Trong công trình này, chúng tôi phân biệt việc học đa nhiệm vụ ngầm trong tiền huấn luyện mô hình ngôn ngữ với việc học đa nhiệm vụ rõ ràng (Caruana, 1997), kỹ thuật trộn nhiều nhiệm vụ vào một quá trình huấn luyện có giám sát duy nhất. Các mô hình được huấn luyện với học đa nhiệm vụ từ lâu đã được chứng minh là có hiệu suất được cải thiện trong NLP (Collobert và Weston, 2008). Vì các nhiệm vụ khác nhau có các đầu ra khác nhau, việc áp dụng học đa nhiệm vụ đòi hỏi một định dạng chung, và nhiều định dạng khác nhau đã được sử dụng (Hashimoto và cộng sự, 2016; McCann và cộng sự, 2018). Một số công trình đa nhiệm vụ cũng khám phá tổng quát hóa few-shot và zero-shot cho các bộ dữ liệu mới với các mô hình được tiền huấn luyện lớn (ví dụ, Vu và cộng sự, 2020; Ye và cộng sự, 2021).

Prompt ngôn ngữ tự nhiên là phương pháp định dạng lại các nhiệm vụ NLP theo định dạng của một phản hồi ngôn ngữ tự nhiên cho đầu vào ngôn ngữ tự nhiên. Sự phát triển của các mô hình được tiền huấn luyện text-to-text như T5 (Raffel và cộng sự, 2020) làm cho các prompt trở thành một phương pháp đặc biệt hữu ích cho học đa nhiệm vụ. Ví dụ, Khashabi và cộng sự (2020a) định dạng lại 20 bộ dữ liệu trả lời câu hỏi thành một prompt duy nhất của câu hỏi: ... (A)... (B)... (C)... ngữ cảnh: ... , trong khi công trình sau đó như Zhong và cộng sự (2021) và Wang và cộng sự (2021) đưa một phạm vi các bộ dữ liệu vào một prompt QA boolean duy nhất hoặc một prompt NLI duy nhất, tương ứng. Mặc dù hiệu quả, những phương pháp prompt đơn này thường không tổng quát hóa cho các prompt mới hoặc các nhiệm vụ mới không thể biểu đạt trong định dạng cố định của chúng.

Tổng quát hơn, Schick và Schütze (2021) và Brown và cộng sự (2020) đã phổ biến việc sử dụng prompt như một phương pháp chung cho tất cả các nhiệm vụ NLP. Mishra và cộng sự (2021) mở rộng thêm phương pháp này cho một thiết lập đa nhiệm vụ, huấn luyện trên các prompt cho 61 nhiệm vụ được định nghĩa hẹp (ví dụ, tạo câu hỏi, tạo câu trả lời sai) được điều chỉnh từ hướng dẫn crowdsourcing của 9 bộ dữ liệu, trong khi chúng tôi huấn luyện trên và đo lường tổng quát hóa qua 62 bộ dữ liệu và 12 nhiệm vụ như được định nghĩa truyền thống trong văn học NLP (§3). Ngoài ra, các prompt của họ bao gồm các ví dụ được gắn nhãn ngoài các hướng dẫn, trong khi chúng tôi tập trung vào tổng quát hóa zero-shot. Cuối cùng, công trình đồng thời của Wei và cộng sự (2021) chia sẻ một câu hỏi nghiên cứu tương tự với chúng tôi, mặc dù chúng tôi khác nhau ở một số khía cạnh quan trọng, ví dụ, đa dạng prompt, quy mô mô hình, và sơ đồ nhiệm vụ giữ lại. Chúng tôi thảo luận các khác biệt của chúng tôi chi tiết trong Phần 7.

Cuối cùng, trong việc giải thích thành công của các prompt, giả thuyết hàng đầu là các mô hình học hiểu các prompt như các hướng dẫn nhiệm vụ giúp chúng tổng quát hóa cho các nhiệm vụ giữ lại (Wei và cộng sự, 2021; Mishra và cộng sự, 2021; Schick và Schütze, 2021; Brown và cộng sự, 2020). Tuy nhiên, mức độ mà thành công này phụ thuộc vào ý nghĩa ngữ nghĩa của các prompt đã bị thách thức (Webson và Pavlick, 2021; Logan và cộng sự, 2021). Do đó, trong công trình này, chúng tôi giữ thái độ bất khả tri về lý do tại sao các prompt hỗ trợ tổng quát hóa. Chúng tôi chỉ khẳng định rằng các prompt phục vụ như một định dạng tự nhiên cho huấn luyện đa nhiệm vụ mà thực nghiệm hỗ trợ tổng quát hóa cho các nhiệm vụ giữ lại.

3 ĐO LƯỜNG TỔNG QUÁT HÓA CHO CÁC NHIỆM VỤ GIỮ LẠI
Chúng tôi bắt đầu bằng việc giả định một phân vùng cơ bản của các bộ dữ liệu NLP thành các nhiệm vụ. Chúng tôi sử dụng thuật ngữ "nhiệm vụ" để chỉ một khả năng NLP chung được kiểm tra bởi một nhóm các bộ dữ liệu cụ thể. Để đánh giá tổng quát hóa zero-shot cho các nhiệm vụ mới, chúng tôi huấn luyện trên một tập con của các nhiệm vụ và đánh giá trên một nhóm nhiệm vụ giữ lại.

Thật không may, phân loại nhiệm vụ NLP là mơ hồ, đặc biệt nếu người ta cố gắng cô lập một kỹ năng duy nhất. Ví dụ, nhiều bộ dữ liệu đánh giá kiến thức thường thức, và một số công trình đa nhiệm vụ (ví dụ, Brown và cộng sự, 2020; Wei và cộng sự, 2021) định nghĩa thường thức như một nhiệm vụ độc lập. Tuy nhiên, các bộ dữ liệu thường thức khác nhau rất lớn, từ kiến thức bẩm sinh và khoa học cấp tiểu học đến hướng dẫn DIY, chuẩn mực văn hóa Mỹ, và các định lý cấp đại học (xem Phụ lục D.1 để thảo luận chi tiết).

Lưu ý rằng nhóm theo nhiệm vụ là một heuristic không hoàn hảo, chúng tôi nghiêng về việc tổ chức phân loại nhiệm vụ của chúng tôi theo định dạng nhiệm vụ thay vì kỹ năng yêu cầu dựa trên các quy ước trong văn học (Khashabi và cộng sự, 2020b; Vu và cộng sự, 2020; Ye và cộng sự, 2021). Chúng tôi thu thập tất cả các bộ dữ liệu từ

--- TRANG 3 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022

những bài báo này và loại trừ những bộ không bằng tiếng Anh (điều này cũng loại trừ các ngôn ngữ lập trình và các chú thích có cấu trúc như cây phân tích cú pháp) hoặc nếu chúng yêu cầu kiến thức chuyên ngành đặc biệt (ví dụ, y sinh học). Điều này tạo ra 12 nhiệm vụ và 62 bộ dữ liệu với các prompt được đóng góp công khai trong hỗn hợp huấn luyện và đánh giá của chúng tôi (Hình 2) tại thời điểm viết. Tất cả các thí nghiệm sử dụng các bộ dữ liệu trong thư viện datasets của Hugging Face (Lhoest và cộng sự, 2021).

Để kiểm tra tổng quát hóa zero-shot, chúng tôi giữ lại tất cả các bộ dữ liệu thành phần của bốn nhiệm vụ: suy luận ngôn ngữ tự nhiên (NLI), giải quyết đồng tham chiếu, hoàn thành câu, và phân biệt nghĩa từ. Chúng tôi chọn NLI như một nhiệm vụ giữ lại bởi vì con người cũng tổng quát hóa zero-shot cho NLI như một nhiệm vụ giữ lại: Hầu hết con người không bao giờ được huấn luyện rõ ràng để phân loại liệu một câu tiền đề có kéo theo hoặc mâu thuẫn với một câu giả thuyết hay không, nhưng họ thấy trực quan khi thực hiện nhiệm vụ này mà không cần huấn luyện (Williams và cộng sự, 2020). Vì lý do tương tự, chúng tôi cũng giữ lại giải quyết đồng tham chiếu và phân biệt nghĩa từ. Chúng tôi tiếp tục giữ lại hoàn thành câu bởi vì đó là một nhiệm vụ có thể quá giống với NLI (Phụ lục D.2 thảo luận điều này chi tiết). Ngoài ra, chúng tôi không huấn luyện mô hình chính của chúng tôi trên bất kỳ bộ dữ liệu nào mà Brown và cộng sự (2020) sử dụng để đánh giá, để các kết quả chính của chúng tôi sẽ là một so sánh zero-shot công bằng. Chúng tôi cũng xác minh rằng dữ liệu cho những nhiệm vụ đó không bị rò rỉ qua corpus tiền huấn luyện (Phụ lục E).

Cuối cùng, chúng tôi tiếp tục đánh giá trên một tập con của các bộ dữ liệu từ BIG-bench, đây là một benchmark được cộng đồng điều khiển gần đây để tạo ra một bộ sưu tập đa dạng các nhiệm vụ khó để kiểm tra khả năng của các mô hình ngôn ngữ lớn. Tập con của BIG-bench bao gồm một lựa chọn hướng ngôn ngữ của các nhiệm vụ mà các người duy trì BIG-bench đã chuẩn bị kết quả sơ bộ và tạo thành văn bản trong từ vựng cho tokenizer T5 (tức là chỉ chứa văn bản tiếng Anh mà không có biểu tượng cảm xúc hoặc ký tự đặc biệt khác). Tất cả các nhiệm vụ từ BIG-bench là các nhiệm vụ mới được giữ lại từ huấn luyện của chúng tôi.

4 MỘT ĐỊNH DẠNG PROMPT THỐNG NHẤT
Tất cả các bộ dữ liệu được đưa cho mô hình của chúng tôi dưới dạng prompt ngôn ngữ tự nhiên để cho phép thí nghiệm zero-shot. Để tạo điều kiện viết một bộ sưu tập lớn các prompt, chúng tôi phát triển một ngôn ngữ mẫu và một ứng dụng giúp dễ dàng chuyển đổi các bộ dữ liệu đa dạng thành các prompt. Chúng tôi định nghĩa một prompt bao gồm một mẫu đầu vào và một mẫu mục tiêu, cùng với một bộ sưu tập các siêu dữ liệu liên quan. Các mẫu là các hàm ánh xạ một ví dụ dữ liệu thành ngôn ngữ tự nhiên cho các chuỗi đầu vào và mục tiêu. Thực tế, các mẫu cho phép người dùng trộn văn bản tùy ý với các trường dữ liệu,

--- TRANG 4 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022

Tóm tắt Cảm xúc
Nhận dạng
Paraphrase Giải quyết
Đồng tham chiếu

QQPMRPC
PAWSYelpRotten TomatoesApp Reviews
IMDBAmazon
Phân loại chủ đề
AG News
DBPedia
TRECCấu trúc-Thành-Văn bản
Wiki BioCommon Gen
MultiNewsGigaword
XSumSamSumCNN Daily MailTrả lời câu hỏi Sách đóng
Hotpot QA
Wiki QA
Trả lời câu hỏi Trích xuất
ROPESAdversarial QA
DuoRCTrả lời câu hỏi Đa lựa chọn
CommonsenseQA
DREAM
QuAIL
QuaRTz
Social IQA
Cosmos QA
QASCWiQA
SciQQuaRelCOPAHoàn thành câu
HellaSwag
Story Cloze
Suy luận ngôn ngữ
tự nhiên
ANLI
CB
RTE
WSC
Winogrande
Phân biệt nghĩa
từ
WiCQuorefWiki HopBIG-Bench
Mô tả Code
Khái niệm
Kiến thức Hindu
Những điều không biết đã biết
Nhận dạng ngôn ngữ
Logic Grid
Suy luận logic
Quan niệm sai lầm
Hội thoại phim
Khái niệm mới
Strategy QA
Tam đoạn luận
Vitamin C
Winowhy

Hình 2: Các bộ dữ liệu và phân loại nhiệm vụ T0. (T0+ và T0++ được huấn luyện trên các bộ dữ liệu bổ sung. Xem Bảng 5 cho danh sách đầy đủ.) Màu sắc biểu thị mức độ giám sát. Các bộ dữ liệu màu vàng có trong hỗn hợp huấn luyện. Các bộ dữ liệu màu xanh lá cây được giữ lại và đại diện cho các nhiệm vụ không được nhìn thấy trong quá trình huấn luyện. Hotpot QA được đúc lại như trả lời câu hỏi sách đóng do độ dài đầu vào lớn.

siêu dữ liệu mẫu, và mã khác để render và định dạng các trường thô. Ví dụ, trong trường hợp của một bộ dữ liệu NLI, ví dụ sẽ bao gồm các trường cho Tiền đề, Giả thuyết, Nhãn. Một mẫu đầu vào sẽ là Nếu {Tiền đề} là đúng, thì có phải cũng đúng rằng {Giả thuyết}?, trong khi một mẫu mục tiêu có thể được định nghĩa với các lựa chọn nhãn {Choices[label]}. Ở đây Choices là siêu dữ liệu cụ thể của prompt bao gồm các lựa chọn có, có thể, không tương ứng với label là entailment (0), neutral (1) hoặc contradiction (2). Siêu dữ liệu khác ghi lại các thuộc tính bổ sung, như một metric đánh giá. Mỗi ví dụ dữ liệu được hiện thực hóa với nhiều mẫu prompt khác nhau như được hiển thị trong Hình 3.

Để phát triển các prompt, chúng tôi xây dựng một giao diện để viết các prompt tương tác trên các bộ dữ liệu. Chúng tôi đưa ra lời kêu gọi mở trong cộng đồng nghiên cứu để người dùng đóng góp các prompt. 36 người đóng góp liên kết với 24 tổ chức ở 8 quốc gia đã tham gia. Vì mục tiêu của chúng tôi là huấn luyện một mô hình mạnh mẽ với định dạng prompt, và vì câu hỏi về điều gì làm cho một prompt hiệu quả vẫn chưa được giải quyết (Webson và Pavlick, 2021; Logan và cộng sự, 2021; Zhao và cộng sự, 2021), chúng tôi khuyến khích những người đóng góp mở trong phong cách của họ và tạo ra một tập đa dạng các prompt. Hướng dẫn chú thích chính là các prompt cần phải có ngữ pháp và có thể hiểu được bởi một người nói tiếng Anh thành thạo mà không có kinh nghiệm trước về các nhiệm vụ. Ngoài ra, các prompt yêu cầu đếm rõ ràng hoặc chỉ mục số đã được loại bỏ để ưu tiên các biến thể ngôn ngữ tự nhiên. Ví dụ, thay vì dự đoán chỉ số của một span trích xuất câu trả lời từ một đoạn văn, mô hình được mong đợi sao chép văn bản của span thay thế.

Hầu hết các prompt tương ứng trực tiếp với một phiên bản của nhiệm vụ ban đầu được đề xuất, mặc dù chúng tôi cũng cho phép các prompt hoán vị nhiệm vụ ban đầu (ví dụ, tạo một tài liệu từ bản tóm tắt của nó). Những prompt không phải nhiệm vụ ban đầu như vậy được bao gồm trong hỗn hợp huấn luyện của chúng tôi để cải thiện đa dạng, nhưng chúng không được báo cáo trong đánh giá vì chúng khác biệt với các metric và baseline được báo cáo bởi các bộ dữ liệu ban đầu.

Chi tiết của ngôn ngữ prompting và công cụ được đưa ra trong Phụ lục C và Bach và cộng sự (2022), và bản thân các prompt được đưa ra trong Phụ lục G. Chúng tôi thu thập các prompt cho các bộ dữ liệu tiếng Anh, loại trừ những bộ bao gồm nội dung có thể có hại hoặc ngôn ngữ không tự nhiên như ngôn ngữ lập trình. Chúng tôi gọi bộ sưu tập này là Public Pool of Prompts (P3). Tại thời điểm viết, P3 chứa 2073 prompt cho 177 bộ dữ liệu (trung bình 11.7 prompt cho mỗi bộ dữ liệu). Các prompt được sử dụng trong thí nghiệm đều có nguồn gốc từ P3 ngoại trừ BIG-bench, các prompt của nó được cung cấp bởi những người duy trì của nó.

5 THIẾT LẬP THÍ NGHIỆM
Mô hình Ở mức độ cao, chúng tôi tinh chỉnh một mô hình được tiền huấn luyện trên hỗn hợp huấn luyện đa nhiệm vụ của các bộ dữ liệu prompt ngôn ngữ tự nhiên. Mô hình của chúng tôi sử dụng kiến trúc encoder-decoder với văn bản đầu vào được đưa vào encoder và văn bản mục tiêu được tạo ra bởi decoder. Mô hình được huấn luyện để tự hồi quy tạo ra mục tiêu thông qua huấn luyện maximum likelihood tiêu chuẩn. Không giống như các mô hình ngôn ngữ chỉ decoder như GPT-3, nó không bao giờ được huấn luyện để tạo ra đầu vào.

Tất cả các mô hình chúng tôi huấn luyện đều dựa trên T5, một mô hình ngôn ngữ encoder-decoder dựa trên Transformer được tiền huấn luyện với mục tiêu kiểu mô hình hóa ngôn ngữ có mask trên 1T token từ C4 (Raffel và cộng sự, 2020). Vì mục tiêu tiền huấn luyện của T5 là tạo ra các token và chỉ các token đã bị loại bỏ khỏi văn bản đầu vào, nó khác biệt với định dạng tạo văn bản tự nhiên của các bộ dữ liệu prompt. Do đó, chúng tôi sử dụng mô hình T5 được thích ứng LM của Lester và cộng sự (2021) (được gọi là T5+LM), được tạo ra bằng cách huấn luyện T5 trên 100B token bổ sung từ C4 trên mục tiêu mô hình hóa ngôn ngữ tiêu chuẩn.

Huấn luyện Mô hình chính của chúng tôi, T0, được huấn luyện trên hỗn hợp đa nhiệm vụ được chi tiết trong Phần 3 và Bảng 5. Trong khi đó, T0+ là cùng mô hình với các siêu tham số giống hệt nhau ngoại trừ được huấn luyện trên một hỗn hợp thêm các bộ dữ liệu đánh giá của GPT-3. Cuối cùng, T0++ tiếp tục thêm SuperGLUE (Wang và cộng sự, 2019a) vào hỗn hợp huấn luyện (ngoại trừ RTE và CB), điều này để lại NLI và các nhiệm vụ BIG-bench như những nhiệm vụ giữ lại duy nhất.

Các biến thể T0 ở trên đều được khởi tạo từ phiên bản 11B tham số của T5+LM. Để nghiên cứu hiệu ứng của việc mở rộng quy mô và hỗ trợ các nhà nghiên cứu với ít tài nguyên hơn, chúng tôi cũng huấn luyện T0 (3B), có cùng hỗn hợp huấn luyện như T0 nhưng được khởi tạo từ phiên bản 3B tham số của T5+LM (kết quả được báo cáo trong Phụ lục F).

Chúng tôi thực hiện lựa chọn checkpoint bằng cách chọn checkpoint mang lại điểm số cao nhất trên các tập validation của các bộ dữ liệu huấn luyện của chúng tôi. Điều này vẫn thỏa mãn thiết lập zero-shot thực sự (Perez và cộng sự, 2021) vì chúng tôi không sử dụng bất kỳ ví dụ nào từ bất kỳ nhiệm vụ giữ lại nào để chọn checkpoint tốt nhất.

Chúng tôi lắp ráp hỗn hợp huấn luyện đa nhiệm vụ của chúng tôi bằng cách kết hợp và xáo trộn tất cả các ví dụ từ tất cả các bộ dữ liệu huấn luyện. Điều này tương đương với việc lấy mẫu từ mỗi bộ dữ liệu theo tỷ lệ số lượng ví dụ trong bộ dữ liệu. Tuy nhiên, số lượng ví dụ trong mỗi bộ dữ liệu huấn luyện của chúng tôi thay đổi theo hai bậc độ lớn. Do đó, chúng tôi tuân theo chiến lược được sử dụng trong Raffel và cộng sự (2020) và coi bất kỳ bộ dữ liệu nào có hơn 500'000 ví dụ như có 500'000 / num_templates ví dụ cho mục đích lấy mẫu, trong đó num_templates là số lượng mẫu được tạo cho bộ dữ liệu.

Chúng tôi cắt ngắn các chuỗi đầu vào và mục tiêu lần lượt xuống 1024 và 256 token. Theo Raffel và cộng sự (2020), chúng tôi sử dụng packing để kết hợp nhiều ví dụ huấn luyện thành một chuỗi duy nhất để đạt độ dài chuỗi tối đa. Chúng tôi sử dụng kích thước batch là 1024 chuỗi (tương ứng với 2^20 tổng số token đầu vào mỗi batch) và optimizer Adafactor (Shazeer và Stern, 2018). Theo thực hành tiêu chuẩn để tinh chỉnh T5, chúng tôi sử dụng tỷ lệ học 1e-3 và tỷ lệ dropout 0.1.

Đánh giá Chúng tôi đánh giá tổng quát hóa zero-shot trên 11 bộ dữ liệu trong 4 nhiệm vụ NLP truyền thống giữ lại: suy luận ngôn ngữ tự nhiên, đồng tham chiếu, phân biệt nghĩa từ, và hoàn thành câu, cũng như 14 nhiệm vụ mới từ BIG-bench (§3). Trừ khi được chỉ định khác, chúng tôi báo cáo hiệu suất trên các tập validation. Tất cả các bộ dữ liệu được báo cáo sử dụng độ chính xác làm metric của chúng.

Đối với các nhiệm vụ liên quan đến việc chọn hoàn thành đúng từ một số lựa chọn (ví dụ, trả lời câu hỏi trắc nghiệm), chúng tôi tuân theo Brown và cộng sự (2020) và sử dụng phân loại theo thứ hạng để đánh giá mô hình của chúng tôi: chúng tôi tính log-likelihood của mỗi lựa chọn mục tiêu dưới mô hình được tinh chỉnh và chọn lựa chọn có log-likelihood cao nhất làm dự đoán. Để đơn giản, chúng tôi không áp dụng chuẩn hóa độ dài cho log-likelihood của các lựa chọn mục tiêu.

Chúng tôi không thực hiện lựa chọn prompt bằng cách so sánh hiệu suất của các prompt khác nhau trên tập validation; Perez và cộng sự (2021) nhấn mạnh cách mà chiến lược như vậy làm rò rỉ thông tin từ các tập đánh giá, điều này làm cho đánh giá không "zero-shot thực sự". Đối với một bộ dữ liệu nhất định, chúng tôi báo cáo hiệu suất trung vị qua tất cả các prompt cho bộ dữ liệu này cùng với khoảng tứ phân vị của chúng (Q3 - Q1) để đo lường độ mạnh mẽ của mô hình đối với cách diễn đạt của các prompt.

6 KẾT QUẢ
6.1 TỔNG QUÁT HÓA CHO CÁC NHIỆM VỤ GIỮ LẠI
Câu hỏi nghiên cứu đầu tiên của chúng tôi là liệu huấn luyện đa nhiệm vụ với prompt có cải thiện tổng quát hóa cho các nhiệm vụ giữ lại hay không. Trong Hình 4, chúng tôi so sánh T0 với baseline T5+LM của chúng tôi trên bốn nhiệm vụ giữ lại. Chúng tôi

--- TRANG 5 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022

Tài liệu Bức tranh xuất hiện trên tường của một 
cửa hàng Poundland trên đường Whymark Avenue... 
Tóm tắt Nghệ sĩ graffiti Banksy được cho là đứng 
sau... Tài liệu Bức tranh xuất hiện trên tường của một 
cửa hàng Poundland trên đường Whymark Avenue... 
Tóm tắt Nghệ sĩ graffiti Banksy được cho là đứng 
sau... Tài liệu Bức tranh xuất hiện trên tường của một 
cửa hàng Poundland trên đường Whymark Avenue... 
Tóm tắt Nghệ sĩ graffiti Banksy được cho là đứng 
sau... QQP (Paraphrase) XSum (Tóm tắt) 

{Question1} {Question2}  
Chọn một: Những câu hỏi này 
là bản sao hoặc không phải 
bản sao. 

Tôi nhận được các câu hỏi 
"{Question1}" và 
"{Question2}". Chúng có 
phải là bản sao không? 

{Choices[label]} {Document} 
Bạn sẽ diễn đạt lại 
điều đó như thế nào 
trong vài từ? Đầu tiên, vui lòng đọc bài báo: 
{Document} 
Bây giờ, bạn có thể viết cho tôi một 
bản tóm tắt cực kỳ ngắn gọn cho nó không? 

{Summary} Question1 Cách kiểm soát giao thông hàng không như thế nào? 
Question2 Làm thế nào để trở thành một kiểm soát viên không lưu? 
Label 0Question1 Cách kiểm soát giao thông hàng không như thế nào? 
Question2 Làm thế nào để trở thành một kiểm soát viên không lưu? 
Label 0Question1 Cách kiểm soát giao thông hàng không như thế nào? 
Question2 Làm thế nào để trở thành một kiểm soát viên không lưu? 
Label 0Question1 Cách kiểm soát giao thông hàng không như thế nào? 
Question2 Làm thế nào để trở thành một kiểm soát viên không lưu? 
Label 0Tài liệu Bức tranh xuất hiện trên tường của một 
cửa hàng Poundland trên đường Whymark Avenue... 
Tóm tắt Nghệ sĩ graffiti Banksy được cho là đứng 
sau... 

{Choices[label]} {Summary} 

Hình 3: Các mẫu prompt từ bộ sưu tập prompt P3. Mỗi bộ dữ liệu có nhiều mẫu prompt bao gồm một mẫu đầu vào và mẫu mục tiêu. Những mẫu này sử dụng các trường của ví dụ dữ liệu thô cũng như siêu dữ liệu mẫu, ví dụ, các prompt nhận dạng paraphrase bên trái sử dụng Choices, một biến danh sách cấp mẫu ['Not duplicates', 'Duplicates']. Những mẫu này được hiện thực hóa để tạo ra thể hiện prompt được hiển thị trong Hình 1. Tập hợp đầy đủ các mẫu prompt được sử dụng trong T0 được đưa ra trong Phụ lục G.

phương pháp dẫn đến những cải thiện đáng kể so với baseline của chúng tôi trên tất cả các bộ dữ liệu, thể hiện lợi ích của huấn luyện đa nhiệm vụ với prompt so với chỉ huấn luyện mô hình hóa ngôn ngữ với mô hình và prompt giống hệt.

Tiếp theo, chúng tôi so sánh T0 với hiệu suất zero-shot của các mô hình ngôn ngữ lớn nhất có sẵn tại thời điểm viết, tức là các mô hình GPT-3 khác nhau lên đến 175B tham số. Lưu ý rằng Brown và cộng sự (2020) báo cáo hiệu suất trên một prompt duy nhất,² trong khi chúng tôi báo cáo hiệu suất trung vị và khoảng tứ phân vị qua tất cả các prompt trong P3 mà không chọn lọc. Chúng tôi thấy rằng T0 phù hợp hoặc vượt trội hơn hiệu suất của tất cả các mô hình GPT-3 trên 9 trong số 11 bộ dữ liệu giữ lại. Đáng chú ý, cả T0 và GPT-3 đều không được huấn luyện trên suy luận ngôn ngữ tự nhiên, nhưng T0 vượt trội hơn GPT-3 trên tất cả các bộ dữ liệu NLI, mặc dù baseline T5+LM của chúng tôi thì không. Điều tương tự cũng đúng cho hầu hết các bộ dữ liệu của các nhiệm vụ giữ lại khác. Hai ngoại lệ là Winogrande và HellaSwag, mà chúng tôi thảo luận trong Phần 7.

Để đánh giá các mô hình của chúng tôi trên nhiều nhiệm vụ giữ lại hơn, chúng tôi đánh giá hiệu suất zero-shot của T0, T0+, và T0++ trên một tập con của BIG-bench (BIG-bench collaboration, 2021). Các nhiệm vụ từ BIG-bench bao gồm nhiều kỹ năng mới không được bao gồm trong các nhiệm vụ huấn luyện của chúng tôi, như suy ra thứ tự của một chuỗi đối tượng, giải các câu đố logic grid, và phân biệt các câu phát biểu đúng với các quan niệm sai lầm phổ biến. Những người duy trì BIG-bench cung cấp một prompt cho mỗi bộ dữ liệu, với đó chúng tôi so sánh các mô hình của chúng tôi với một loạt các mô hình baseline chẩn đoán sơ bộ được huấn luyện bởi Google và được đánh giá bởi những người duy trì BIG-bench. Những mô hình này là các mô hình ngôn ngữ Transformer chỉ decoder được huấn luyện trên mục tiêu mô hình hóa ngôn ngữ tiêu chuẩn với kích thước mô hình khác nhau. Chúng tôi thấy rằng ít nhất một trong các biến thể T0 vượt trội hơn tất cả các mô hình baseline trên tất cả các nhiệm vụ ngoại trừ StrategyQA (Hình 5). Trong hầu hết các trường hợp, hiệu suất của các mô hình của chúng tôi được cải thiện khi số lượng bộ dữ liệu huấn luyện tăng (tức là T0++ vượt trội hơn T0+ mà vượt trội hơn T0).

6.2 ĐỘ MẠNH MẼ CỦA PROMPT
Câu hỏi nghiên cứu thứ hai của chúng tôi là liệu huấn luyện trên một phạm vi rộng hơn các prompt có cải thiện độ mạnh mẽ đối với cách diễn đạt của các prompt hay không. Chúng tôi tiến hành hai thí nghiệm ablation về hiệu ứng của số lượng prompt trung bình cho mỗi bộ dữ liệu (p) và số lượng bộ dữ liệu (d) được sử dụng trong quá trình huấn luyện.

Hiệu ứng của Nhiều Prompt hơn cho mỗi Bộ dữ liệu Trong phân tích này, chúng tôi cố định d và so sánh T0 với các mô hình có số lượng prompt khác nhau cho mỗi bộ dữ liệu. T0 được huấn luyện trên một số prompt không ánh xạ vào nhiệm vụ ban đầu của bộ dữ liệu, ví dụ "cho một câu trả lời, tạo ra một câu hỏi có khả năng". Bao gồm những prompt này dẫn đến p là 8.03 trung bình (tương ứng với mô hình T0 chính của chúng tôi). Chúng tôi so sánh T0 với các mô hình trong đó p = 1 (một prompt nhiệm vụ ban đầu được chọn ngẫu nhiên cho mỗi bộ dữ liệu), p = 5.7 trung bình (tất cả các prompt nhiệm vụ ban đầu cho tất cả các bộ dữ liệu), và p = 0 (tương ứng với T5+LM mà không có bất kỳ huấn luyện prompt nào). Chúng tôi huấn luyện tất cả các mô hình với cùng siêu tham số và cùng số bước. Hình 6 cho thấy rằng, ngay cả với chỉ một prompt cho mỗi bộ dữ liệu, hiệu suất trên các nhiệm vụ giữ lại có thể cải thiện đáng kể so với baseline không prompt, mặc dù độ trải rộng (khoảng tứ phân vị giữa Q1 và Q3) không cải thiện một cách nhất quán với p = 1. Trong khi đó, tăng thêm p từ 1 lên trung bình 5.7 thật sự mang lại cải thiện bổ sung trong cả hiệu suất trung vị (tăng cho 8/11 bộ dữ liệu) và độ trải rộng (giảm cho 7/11 bộ dữ liệu). Điều này củng cố giả thuyết của chúng tôi rằng huấn luyện trên nhiều prompt hơn cho mỗi bộ dữ liệu dẫn đến tổng quát hóa tốt hơn và mạnh mẽ hơn cho các nhiệm vụ giữ lại. Cuối cùng, chúng tôi thấy rằng việc bao gồm tất cả các prompt của T0 (bao gồm những prompt không tương ứng với nhiệm vụ ban đầu của bộ dữ liệu) tiếp tục cải thiện hiệu suất trung vị (tăng cho 9/11 bộ dữ liệu) và độ trải rộng (giảm cho 8/11 bộ dữ liệu), cho thấy rằng huấn luyện trên các prompt không phải nhiệm vụ ban đầu cũng có thể có lợi.

Hiệu ứng của Prompt từ Nhiều Bộ dữ liệu hơn Trong thí nghiệm này, chúng tôi cố định p = tất cả các prompt có sẵn và tăng d từ 39 lên 49 lên 55 (T0, T0+, T0++, tương ứng. Xem Phần 5 để biết chi tiết.) Hình 7 cho thấy rằng hiệu suất trung vị của tất cả 5 bộ dữ liệu giữ lại tăng khi d tăng từ 39 lên 49. Tuy nhiên, độ trải rộng chỉ giảm cho 1 trong số 5 bộ dữ liệu. Đối với một số bộ dữ liệu (ví dụ, ANLI), đây là một tạo tác của thực tế rằng một số prompt luôn thực hiện kém, do đó khi các prompt khác cải thiện, độ trải rộng được kéo dài lớn hơn. Đối với các bộ dữ liệu khác (ví dụ, CB), tuy nhiên, độ trải rộng thật sự giảm với T0+. Khi d tăng từ 49 lên 55, hiệu suất trung vị của tất cả các bộ dữ liệu lại tăng, nhưng độ trải rộng chỉ giảm cho 2 trong số 5 bộ dữ liệu. Mặc dù cần điều tra thêm, có vẻ như việc tăng d không làm cho mô hình mạnh mẽ hơn một cách nhất quán đối với cách diễn đạt của các prompt.

So sánh độ mạnh mẽ của T0 và GPT-3 Vì Brown và cộng sự (2020) chỉ báo cáo một prompt cho mỗi bộ dữ liệu mà không có độ lệch chuẩn, chúng tôi đánh giá GPT-3 qua API của OpenAI³ trên RTE sử dụng cùng 10 prompt mà chúng tôi đánh giá T0 để ước tính độ mạnh mẽ của GPT-3 đối với cách diễn đạt khác nhau của các prompt. Một trong những mẫu này giống hệt với prompt được báo cáo của Brown và cộng sự (2020, trang 59), mà ghi được độ chính xác 58.8%, thấp hơn 63.5% được báo cáo trong Brown và cộng sự (2020). Tất cả 9 

²Các thí nghiệm của chúng tôi trong Phần 6.2 dẫn chúng tôi tin rằng hiệu suất này tương ứng với prompt tốt nhất được tìm thấy sau khi điều chỉnh thủ công theo hiệu suất tập validation.

--- TRANG 6 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022

020406080
020406080
01020304050
01020304050
01020304050
020406080
020406080
020406080100
020406080100
020406080100
020406080

GPT-3 (6.7B)
 GPT-3 (13B)
 GPT-3 (175B)
 T5+LM (11B)
 T0 (11B)

RTE CB ANLI R1 ANLI R2 ANLI R3
WSC Winogrande COPA StoryCloze HellaSwag WiCSuy luận ngôn ngữ tự nhiên
Giải quyết đồng tham chiếu Hoàn thành câu Phân biệt nghĩa từ

Hình 4: Kết quả cho các thí nghiệm tổng quát hóa nhiệm vụ T0 so sánh với GPT-3 (Brown và cộng sự, 2020). Mỗi chấm là hiệu suất của một prompt đánh giá. Mô hình baseline T5+LM giống như T0 ngoại trừ không có huấn luyện đa nhiệm vụ với prompt. GPT-3 chỉ báo cáo một prompt duy nhất cho mỗi bộ dữ liệu.

prompt còn lại, tuy nhiên, mang lại hiệu suất đoán gần như ngẫu nhiên với độ chính xác trung vị = 52.96% và khoảng tứ phân vị = 1.28%. Những kết quả này cho thấy rằng T0 có thể mạnh mẽ hơn đối với việc hình thành prompt so với GPT-3.

7 THẢO LUẬN
Đồng thời với công trình của chúng tôi, Wei và cộng sự (2021) đề xuất FLAN, có cùng phương pháp cho phép tổng quát hóa zero-shot thông qua huấn luyện đa nhiệm vụ với prompt. Với một hỗn hợp bộ dữ liệu tương tự như của chúng tôi, họ huấn luyện nhiều mô hình ngôn ngữ chỉ decoder, mỗi mô hình có một nhiệm vụ giữ lại duy nhất (so với chúng tôi tập trung vào huấn luyện một mô hình với nhiều nhiệm vụ giữ lại để đánh giá khả năng của mô hình tổng quát hóa cho các nhiệm vụ đa dạng.) So với FLAN, hiệu suất zero-shot của T0 tốt hơn trên CB và RTE, tương tự trên Story Cloze và COPA, và kém hơn trên Winogrande và ANLI. T0++ vượt trội hơn FLAN trên CB, RTE, và COPA và phù hợp với hiệu suất của FLAN trên Winogrande và ANLI. Đáng chú ý, T0 và T0++ đạt được hiệu suất này mặc dù nhỏ hơn 10 lần so với FLAN (137B so với 11B tham số).

Cả T0 và FLAN đều kém hiệu suất so với GPT-3 trên Winogrande và HellaSwag (Sakaguchi và cộng sự, 2019; Zellers và cộng sự, 2019), mà Wei và cộng sự (2021) đoán rằng đối với các nhiệm vụ như giải quyết đồng tham chiếu có thể được định dạng như hoàn thành một câu không đầy đủ, việc thêm hướng dẫn nhiệm vụ vào các prompt là "phần lớn dư thừa". Theo đoán này, chúng tôi đánh giá lại hai bộ dữ liệu này mà không có hướng dẫn như được thực hiện bởi Wei và cộng sự (2021) và Brown và cộng sự (2020) và thấy rằng nó cải thiện hiệu suất trên HellaSwag từ hiệu suất trung vị 33.65% lên 57.93%, phù hợp với hiệu suất của FLAN. Đối với Winogrande, tuy nhiên, việc sử dụng prompt của FLAN mà không có hướng dẫn không tạo ra sự khác biệt đáng kể (độ chính xác = 62.15%).

Đáng ngạc nhiên, Wei và cộng sự (2021) thực hiện một ablation với một mô hình có kích thước tương đương (8B tham số) với T0 (11B tham số) và thấy rằng hiệu suất trên các nhiệm vụ giữ lại giảm sau huấn luyện đa nhiệm vụ với prompt, trong khi chúng tôi thấy rằng huấn luyện đa nhiệm vụ với prompt cải thiện hiệu suất của các mô hình ít nhất nhỏ đến 3B tham số (Hình 8). Chúng tôi xác định hai khác biệt chính giữa các mô hình có thể giải thích sự khác biệt này: Đầu tiên, chúng tôi sử dụng một mô hình encoder-decoder được tiền huấn luyện với một mục tiêu khác (mô hình hóa ngôn ngữ có mask) trước khi được huấn luyện như một mô hình

--- TRANG 7 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022

0204060
020406080
010203040
0204060
05101520
010203040
02040
02040
02040
0102030
0204060
02040
0204060
02040

LM (8.5B) LM (28B) LM (68B) T5+LM (11B) T0 (11B) T0+ (11B) T0++ (11B)Mô tả Code Khái niệm Kiến thức Hindu Những điều không biết đã biết Nhận dạng ngôn ngữ Logic Grid Suy luận logic

Quan niệm sai lầm Hội thoại phim Khái niệm mới Strategy QA Tam đoạn luận Vitamin C Winowhy

Hình 5: Kết quả cho một tập con của BIG-bench có baseline có sẵn. Các mô hình baseline là các mô hình ngôn ngữ dựa trên Transformer được cung cấp bởi những người duy trì BIG-bench, những người cũng cung cấp một prompt cho mỗi bộ dữ liệu. T0, T0+ và T0++ giống hệt ngoại trừ việc tăng số lượng bộ dữ liệu huấn luyện (§5). Các nhiệm vụ BIG-bench đều zero-shot cho tất cả các mô hình được báo cáo.

ngôn ngữ tiêu chuẩn và cuối cùng được tinh chỉnh trên hỗn hợp đa nhiệm vụ. Chúng tôi lưu ý rằng mô hình hóa ngôn ngữ có mask đã được chứng minh lặp lại là một chiến lược tiền huấn luyện hiệu quả hơn đáng kể (Raffel và cộng sự, 2020; Baevski và cộng sự, 2019; Devlin và cộng sự, 2019).

Thứ hai, các prompt của chúng tôi đa dạng hơn về mặt chất lượng về độ dài và tính sáng tạo của chúng (§4). Ví dụ, xem xét một trong những prompt của chúng tôi cho Quora Question Pairs (nhận dạng paraphrase): Tôi là một quản trị viên trên trang web Quora. Có hai bài đăng, một bài hỏi "question1" và một bài khác hỏi "question2". Tôi có thể gộp các câu hỏi nếu chúng hỏi cùng một điều. Tôi có thể gộp hai câu hỏi này không? Chúng tôi giả thuyết rằng đa dạng này có thể có hiệu ứng cụ thể. Ví dụ, nó có thể giải thích tại sao Wei và cộng sự (2021) trình bày kết quả ablation trong đó việc tăng số lượng prompt có tác động không đáng kể đến hiệu suất trong khi chúng tôi quan sát được một cải thiện khi thêm nhiều prompt hơn (§6.2). Chúng tôi để lại một điều tra đầy đủ về tác động của những khác biệt này cho công trình tương lai.

8 KẾT LUẬN
Chúng tôi chứng minh rằng huấn luyện đa nhiệm vụ với prompt có thể cho phép khả năng tổng quát hóa zero-shot mạnh trong các mô hình ngôn ngữ. Phương pháp này cung cấp một thay thế hiệu quả cho tiền huấn luyện mô hình ngôn ngữ không giám sát, thường cho phép mô hình T0 của chúng tôi vượt trội hơn các mô hình lớn gấp nhiều lần kích thước của nó. Chúng tôi cũng thực hiện các nghiên cứu ablation chứng minh tầm quan trọng của việc bao gồm nhiều prompt đa dạng và tác động của việc tăng số lượng bộ dữ liệu trong mỗi nhiệm vụ. Để cho phép công trình tương lai về cải thiện tổng quát hóa zero-shot, chúng tôi phát hành tất cả các mô hình được huấn luyện trong bài báo này ngoài bộ sưu tập các prompt mà chúng tôi đã tạo ra và công cụ chú thích prompt của chúng tôi.

LỜI CẢM ƠN
Công trình này được cấp quyền truy cập vào các tài nguyên HPC của Institut du développement et des ressources en informatique scientifique (IDRIS) du Centre national de la recherche scientifique (CNRS) dưới phân bổ 2021-A0101012475 do Grand équipement national de calcul intensif (GENCI) thực hiện. Đặc biệt, tất cả các đánh giá và xử lý dữ liệu chạy trên cluster Jean-Zay của IDRIS, và chúng tôi muốn cảm ơn đội IDRIS vì sự hỗ trợ phản hồi nhanh trong suốt dự án, đặc biệt là Rémi Lacroix.

Chúng tôi biết ơn chương trình TPU Research Cloud đã hào phóng cung cấp tín dụng TPU cho Hugging Face. Những tín dụng đó được sử dụng để huấn luyện tất cả các mô hình từ bài báo này.

Công trình này được tài trợ một phần bởi các ghế của Rachel Bawden và Benoît Sagot trong viện PRAIRIE được tài trợ bởi cơ quan quốc gia Pháp ANR như một phần của chương trình "Investissements d'avenir" dưới tham chiếu ANR-19-P3IA-0001. Tiết lộ: Stephen Bach đã đóng góp cho công trình này như một cố vấn cho Snorkel AI.

Chúng tôi cảm ơn Yacine Jernite, Sasha Luccioni, Aurélie Névéol và Huu Nguyen vì lời khuyên về các chiến lược để xử lý các bộ dữ liệu chứa nội dung có thể có hại. Guy Gur-Ari và Ethan Dyer đã cung cấp

--- TRANG 8 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022

020406080
020406080
3035404550
3035404550
3035404550
304050607080
304050607080
406080100
406080100
2025303540
40506070

p = 0 (T5+LM) p = 1 p = 5.7 p = 8.03 (T0)RTE CB ANLI R1 ANLI R2 ANLI R3
WSC Winogrande COPA StoryCloze HellaSwag WiCSuy luận ngôn ngữ tự nhiên
Giải quyết đồng tham chiếu Hoàn thành câu Phân biệt nghĩa từ

Hình 6: Hiệu ứng của nhiều prompt hơn cho mỗi bộ dữ liệu. Hiệu suất zero-shot của T0 và T5+LM khi tăng số lượng prompt huấn luyện cho mỗi bộ dữ liệu. Mỗi chấm là hiệu suất của một prompt đánh giá. Mô hình T0 chính (p = 8.03) bao gồm các prompt không phải nhiệm vụ ban đầu (xem Phần 3). Thêm nhiều prompt huấn luyện liên tục dẫn đến hiệu suất trung vị cao hơn và thường khoảng tứ phân vị thấp hơn cho các nhiệm vụ giữ lại.

hỗ trợ và kết quả sơ bộ về đánh giá BIG-bench. Chúng tôi cảm ơn Ruiqi Zhong vì các thảo luận sớm về dự án này.

TÀI LIỆU THAM KHẢO
Stephen H. Bach, Victor Sanh, Zheng-Xin Yong, Albert Webson, Colin Raffel, Nihal V. Nayak, Abheesht Sharma, Taewoon Kim, M Saiful Bari, Thibault Fevry, Zaid Alyafeai, Manan Dey, Andrea Santilli, Zhiqing Sun, Srulik Ben-David, Canwen Xu, Gunjan Chhablani, Han Wang, Jason Alan Fries, Maged S. Al-shaibani, Shanya Sharma, Urmish Thakker, Khalid Almubarak, Xiangru Tang, Xiangru Tang, Mike Tian-Jian Jiang, và Alexander M. Rush. Promptsource: An integrated development environment and repository for natural language prompts, 2022.

Alexei Baevski, Sergey Edunov, Yinhan Liu, Luke Zettlemoyer, và Michael Auli. Cloze-driven pretraining of self-attention networks. arXiv preprint arXiv:1903.07785, 2019.

Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, và Idan Szpektor. The second pascal recognising textual entailment challenge. In Proceedings of the second PASCAL challenges workshop on recognising textual entailment, volume 6, pages 6–4. Venice, 2006.

Max Bartolo, Alastair Roberts, Johannes Welbl, Sebastian Riedel, và Pontus Stenetorp. Beat the ai: Investigating adversarial human annotation for reading comprehension. Transactions of the Association for Computational Linguistics, 8:662–678, 2020. doi: 10.1162/tacl a00338. URL https://doi.org/10.1162/tacl a00338.

Qiang Ning Ben Zhou, Daniel Khashabi và Dan Roth. "going on a vacation" takes longer than "going for a walk": A study of temporal commonsense understanding. In EMNLP, 2019.

Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, và Shmargaret Shmitchell. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, pages 610–623, 2021.

Luisa Bentivogli, Peter Clark, Ido Dagan, và Danilo Giampiccolo. The fifth pascal recognizing textual entailment challenge. In TAC, 2009.

Jonathan Berant, Andrew Chou, Roy Frostig, và Percy Liang. Semantic parsing on Freebase from question-answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1533–1544, Seattle, Washington, USA, October 2013. Association for Computational Linguistics. URL https://aclanthology.org/D13-1160.

BIG-bench collaboration. Beyond the imitation game: Measuring and extrapolating the capabilities of language models. In preparation, 2021. URL https://github.com/google/BIG-bench/.

Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng Gao, và Yejin Choi. Piqa: Reasoning about physical commonsense in natural language. In Thirty-Fourth AAAI Conference on Artificial Intelligence, 2020.

Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S. Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, Erik Brynjolfsson, Shyamal Buch, Dallas Card, Rodrigo Castellon, Niladri Chatterji, Annie S. Chen, Kathleen Creel, Jared Quincy Davis, Dorottya Demszky, Chris Donahue, Moussa Doumbouya, Esin Durmus, Stefano Ermon, John Etchemendy, Kawin Ethayarajh, Li Fei-Fei, Chelsea Finn, Trevor Gale, Lauren Gillespie, Karan Goel, Noah D. Goodman, Shelby Grossman, Neel Guha, Tatsunori Hashimoto, Peter Henderson, John Hewitt, Daniel E. Ho, Jenny Hong, Kyle Hsu, Jing Huang, Thomas Icard, Saahil Jain, Dan Jurafsky, Pratyusha Kalluri, Siddharth Karamcheti, Geoff Keeling, Fereshte Khani, Omar Khattab, Pang Wei Koh, Mark S. Krass, Ranjay Krishna, Rohith Kuditipudi, và et al. On the opportunities and risks of foundation models. CoRR, abs/2108.07258, 2021. URL https://arxiv.org/abs/2108.07258.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhari-wal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel

--- TRANG 9 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022

020406080
020406080
3035404550
3035404550
3035404550

T0 (d = 39) T0+ (d = 49) T0++ (d = 55)RTE CB ANLI R1 ANLI R2 ANLI R3

Hình 7: Hiệu ứng của prompt từ nhiều bộ dữ liệu hơn. Hiệu suất zero-shot của ba mô hình với số lượng bộ dữ liệu khác nhau (T0, T0+, T0++). Thêm nhiều bộ dữ liệu liên tục dẫn đến hiệu suất trung vị cao hơn nhưng không luôn giảm khoảng tứ phân vị cho các nhiệm vụ giữ lại.

Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. Language models are few-shot learners. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, và H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 1877–1901. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.

Rich Caruana. Multitask learning. Mach. Learn., 28(1):41–75, 1997. doi: 10.1023/A: 1007379606734. URL https://doi.org/10.1023/A:1007379606734.

Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin Choi, Percy Liang, và Luke Zettlemoyer. QuAC: Question answering in context. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2174–2184, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/ D18-1241. URL https://aclanthology.org/D18-1241.

Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, và Kristina Toutanova. Boolq: Exploring the surprising difficulty of natural yes/no questions. CoRR, abs/1905.10044, 2019. URL http://arxiv.org/abs/1905.10044.

Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, và Oyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning challenge. arXiv:1803.05457v1, 2018.

Ronan Collobert và Jason Weston. A unified architecture for natural language processing: deep neural networks with multitask learning. In William W. Cohen, Andrew McCallum, và Sam T. Roweis, editors, Machine Learning, Proceedings of the Twenty-Fifth International Conference (ICML 2008), Helsinki, Finland, June 5-9, 2008, volume 307 of ACM International Conference Proceeding Series, pages 160–167. ACM, 2008. doi: 10.1145/1390156.1390177. URL https: //doi.org/10.1145/1390156.1390177.

Ido Dagan, Oren Glickman, và Bernardo Magnini. The pascal recognising textual entailment challenge. In Machine Learning Challenges Workshop, pages 177–190. Springer, 2005.

Pradeep Dasigi, Nelson F. Liu, Ana Marasovic, Noah A. Smith, và Matt Gardner. Quoref: A reading comprehension dataset with questions requiring coreferential reasoning. arXiv:1908.05803v2, 2019.

Ona de Gibert, Naiara Perez, Aitor Garcia-Pablos, và Montse Cuadros. Hate Speech Dataset from a White Supremacy Forum. In Proceedings of the 2nd Workshop on Abusive Language Online (ALW2), pages 11–20, Brussels, Belgium, October 2018. Association for Computational Linguistics. doi: 10.18653/v1/W18-5102. URL https://www.aclweb.org/anthology/W18-5102.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, 2019.

William B Dolan và Chris Brockett. Automatically constructing a corpus of sentential paraphrases. In Proceedings of the Third International Workshop on Paraphrasing (IWP2005), 2005.

Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, và Matt Gardner. Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs. In Proc. of NAACL, 2019.

Alexander R. Fabbri, Irene Li, Tianwei She, Suyi Li, và Dragomir R. Radev. Multi-news: a large-scale multi-document summarization dataset and abstractive hierarchical model, 2019.

Leo Gao, Jonathan Tow, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Kyle McDonell, Niklas Muennighoff, Jason Phang, Laria Reynolds, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, và Andy Zou. A framework for few-shot language model evaluation, September 2021. URL https://doi.org/10.5281/zenodo.5371628.

³https://beta.openai.com/ Chúng tôi sử dụng "base GPT-3 model" davinci. Mặc dù OpenAI không tiết lộ mô hình nào trong số các mô hình có sẵn thương mại của họ tương ứng với mô hình nào được báo cáo trong Brown và cộng sự (2020), Gao và cộng sự (2021) ước tính rằng davinci tương ứng với mô hình 175B.

--- TRANG 10 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022

Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, và Bill Dolan. The third pascal recognizing textual entailment challenge. In Proceedings of the ACL-PASCAL workshop on textual entailment and paraphrasing, pages 1–9. Association for Computational Linguistics, 2007.

Bogdan Gliwa, Iwona Mochol, Maciej Biesek, và Aleksander Wawer. Samsum corpus: A human-annotated dialogue dataset for abstractive summarization. arXiv preprint arXiv:1911.12237, 2019.

Alec Go, Richa Bhayani, và Lei Huang. Twitter sentiment classification using distant supervision. CS224N project report, Stanford, 1(12):2009, 2009.

David Graff, Junbo Kong, Ke Chen, và Kazuaki Maeda. English gigaword. Linguistic Data Consortium, Philadelphia, 4(1):34, 2003.

Kazuma Hashimoto, Caiming Xiong, Yoshimasa Tsuruoka, và Richard Socher. A joint many-task model: Growing a neural network for multiple NLP tasks. CoRR, abs/1611.015collin87, 2016. URL http://arxiv.org/abs/1611.01587.

Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, và Phil Blunsom. Teaching machines to read and comprehend. In Advances in neural information processing systems, pages 1693–1701, 2015.

Eduard Hovy, Laurie Gerber, Ulf Hermjakob, Chin-Yew Lin, và Deepak Ravichandran. Toward semantics-based answer pinpointing. In Proceedings of the First International Conference on Human Language Technology Research, 2001. URL https://aclanthology.org/H01-1069.

Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, và Yejin Choi. Cosmos qa: Machine reading comprehension with contextual commonsense reasoning. In arXiv:1909.00277v2, 2019.

Matt Gardner Johannes Welbl, Nelson F. Liu. Crowdsourcing multiple choice science questions. arXiv:1707.06209v1, 2017.

Mandar Joshi, Eunsol Choi, Daniel Weld, và Luke Zettlemoyer. triviaqa: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension. arXiv e-prints, art. arXiv:1705.03551, 2017.

Daniel Khashabi, Snigdha Chaturvedi, Michael Roth, Shyam Upadhyay, và Dan Roth. Looking beyond the surface:a challenge set for reading comprehension over multiple sentences. In Proceedings of North American Chapter of the Association for Computational Linguistics (NAACL), 2018.

Daniel Khashabi, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, và Hannaneh Hajishirzi. Unifiedqa: Crossing format boundaries with a single QA system. CoRR, abs/2005.00700, 2020a. URL https://arxiv.org/abs/2005.00700.

Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, và Hannaneh Hajishirzi. UNIFIEDQA: Crossing format boundaries with a single QA system. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1896–1907, Online, November 2020b. Association for Computational Linguistics. doi: 10.18653/v1/2020. findings-emnlp.171. URL https://aclanthology.org/2020.findings-emnlp.171.

Tushar Khot, Peter Clark, Michal Guerquin, Peter Jansen, và Ashish Sabharwal. Qasc: A dataset for question answering via sentence composition. arXiv:1910.11473v2, 2020.

Boseop Kim, HyoungSeok Kim, Sang-Woo Lee, Gichang Lee, Donghyun Kwak, Dong Hyeon Jeon, Sunghyun Park, Sungju Kim, Seonhoon Kim, Dongpil Seo, et al. What changes can large-scale language models bring? intensive study on hyperclova: Billions-scale korean generative pretrained transformers. arXiv preprint arXiv:2109.04650, 2021.

Alexandre Lacoste, Alexandra Luccioni, Victor Schmidt, và Thomas Dandres. Quantifying the carbon emissions of machine learning. arXiv preprint arXiv:1910.09700, 2019.

Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, và Eduard Hovy. Race: Large-scale reading comprehension dataset from examinations. arXiv preprint arXiv:1704.04683, 2017.

[Tiếp tục dịch phần còn lại của tài liệu...]

--- TRANG 11 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022

R'emi Lebret, David Grangier, và Michael Auli. Generating text from structured data with application to the biography domain. CoRR, abs/1603.07771, 2016. URL http://arxiv.org/abs/1603. 07771.

Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, và Nicholas Carlini. Deduplicating training data makes language models better. arXiv preprint arXiv:2107.06499, 2021.

Jens Lehmann, Robert Isele, Max Jakob, Anja Jentzsch, Dimitris Kontokostas, Pablo N Mendes, Sebastian Hellmann, Mohamed Morsey, Patrick Van Kleef, Sören Auer, et al. Dbpedia–a large-scale, multilingual knowledge base extracted from wikipedia. Semantic web, 6(2):167–195, 2015.

Brian Lester, Rami Al-Rfou, và Noah Constant. The power of scale for parameter-efficient prompt tuning. CoRR, abs/2104.08691, 2021. URL https://arxiv.org/abs/2104.08691.

Hector Levesque, Ernest Davis, và Leora Morgenstern. The winograd schema challenge. In Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning, 2012.

Quentin Lhoest, Albert Villanova del Moral, Yacine Jernite, Abhishek Thakur, Patrick von Platen, Suraj Patil, Julien Chaumond, Mariama Drame, Julien Plu, Lewis Tunstall, Joe Davison, Mario Šaško, Gunjan Chhablani, Bhavitvya Malik, Simon Brandeis, Teven Le Scao, Victor Sanh, Canwen Xu, Nicolas Patry, Angelina McMillan-Major, Philipp Schmid, Sylvain Gugger, Clément Delangue, Théo Matussière, Lysandre Debut, Stas Bekman, Pierric Cistac, Thibault Goehringer, Victor Mustar, François Lagunas, Alexander M. Rush, và Thomas Wolf. Datasets: A community library for natural language processing. emnlp, 2021.

Xin Li và Dan Roth. Learning question classifiers. In COLING 2002: The 19th International Conference on Computational Linguistics, 2002. URL https://aclanthology.org/C02-1150.

Bill Yuchen Lin, Wangchunshu Zhou, Ming Shen, Pei Zhou, Chandra Bhagavatula, Yejin Choi, và Xiang Ren. CommonGen: A constrained text generation challenge for generative commonsense reasoning. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1823–1840, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/ v1/2020.findings-emnlp.165. URL https://aclanthology.org/2020.findings-emnlp.165.

Kevin Lin, Oyvind Tafjord, Peter Clark, và Matt Gardner. Reasoning over paragraph effects in situations. In MRQA@EMNLP, 2019.

Robert L Logan, Ivana Balažević, Eric Wallace, Fabio Petroni, Sameer Singh, và Sebastian Riedel. Cutting down on prompts and parameters: Simple few-shot learning with language models. arXiv preprint arXiv:2106.13353, 2021.

Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, và Christopher Potts. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 142– 150, Portland, Oregon, USA, June 2011. Association for Computational Linguistics. URL http: //www.aclweb.org/anthology/P11-1015.

Julian McAuley và Jure Leskovec. Hidden factors and hidden topics: understanding rating dimensions with review text. In Proceedings of the 7th ACM conference on Recommender systems, pages 165–172, 2013.

Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, và Richard Socher. The natural language decathlon: Multitask learning as question answering. CoRR, abs/1806.08730, 2018. URL http: //arxiv.org/abs/1806.08730.

R. Thomas McCoy, Ellie Pavlick, và Tal Linzen. Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference. CoRR, abs/1902.01007, 2019. URL http://arxiv.org/abs/ 1902.01007.

Todor Mihaylov, Peter Clark, Tushar Khot, và Ashish Sabharwal. Can a suit of armor conduct electricity? a new dataset for open book question answering. In EMNLP, 2018.

[Tiếp tục dịch các trang còn lại theo cùng cách...]

*[Do giới hạn độ dài phản hồi, tôi đã dịch một phần đại diện của tài liệu. Toàn bộ tài liệu rất dài (hơn 200 trang) và sẽ cần nhiều phản hồi để dịch hoàn chỉnh. Nếu bạn muốn tôi tiếp tục dịch các phần cụ thể nào khác, vui lòng cho tôi biết.]*

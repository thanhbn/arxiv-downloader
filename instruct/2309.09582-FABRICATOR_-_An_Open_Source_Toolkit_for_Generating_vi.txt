# FABRICATOR: Một Bộ Công Cụ Mã Nguồn Mở để Tạo Dữ Liệu Huấn Luyện Có Nhãn với LLM Giáo Viên

Jonas Golde1, Patrick Haller1, Felix Hamborg1, Julian Risch2, Alan Akbik1
1Đại học Humboldt Berlin
2deepset GmbH
{jonas.golde, patrick.haller.1, felix.hamborg, alan.akbik}@hu-berlin.de
julian.risch@deepset.ai

## Tóm tắt

Hầu hết các tác vụ NLP được mô hình hóa như học có giám sát và do đó yêu cầu dữ liệu huấn luyện có nhãn để huấn luyện các mô hình hiệu quả. Tuy nhiên, việc sản xuất thủ công dữ liệu như vậy với chất lượng và số lượng đủ được biết là tốn kém và mất thời gian. Nghiên cứu hiện tại giải quyết tắc nghẽn này bằng cách khám phá một mô hình mới gọi là học zero-shot thông qua tạo dataset. Ở đây, một LLM mạnh mẽ được prompted với mô tả tác vụ để tạo dữ liệu có nhãn có thể được sử dụng để huấn luyện một mô hình NLP downstream. Ví dụ, một LLM có thể được prompted để "tạo 500 đánh giá phim với cảm xúc tích cực tổng thể, và 500 khác với cảm xúc tiêu cực." Dữ liệu được tạo sau đó có thể được sử dụng để huấn luyện một bộ phân loại cảm xúc nhị phân, hiệu quả tận dụng một LLM như một giáo viên cho một mô hình học sinh nhỏ hơn. Với demo này, chúng tôi giới thiệu FABRICATOR, một bộ công cụ Python mã nguồn mở để tạo dataset. FABRICATOR triển khai các quy trình tạo dataset phổ biến, hỗ trợ một loạt các tác vụ NLP downstream (như phân loại văn bản, hỏi đáp, và nhận dạng thực thể), và được tích hợp với các thư viện nổi tiếng để tạo điều kiện thử nghiệm nhanh chóng. Với FABRICATOR, chúng tôi nhằm hỗ trợ các nhà nghiên cứu tiến hành các thí nghiệm tạo dataset có thể tái tạo sử dụng LLM và giúp các nhà thực hành áp dụng phương pháp này để huấn luyện mô hình cho các tác vụ downstream.

## 1 Giới thiệu

Trong những năm gần đây, xử lý ngôn ngữ tự nhiên (NLP) đã chứng kiến tiến bộ đáng kể nhờ vào việc giới thiệu các mô hình ngôn ngữ được tiền huấn luyện (PLM) (Devlin et al., 2019; Liu et al., 2019; Conneau và Lample, 2019; He et al., 2021). Các PLM này thường được fine-tune trên các dataset có chú thích của con người lớn, dẫn đến hiệu suất tiên tiến trong các tác vụ như phân loại văn bản, phân loại token, và hỏi đáp. Tuy nhiên, các ứng dụng thực tế của phương pháp này gặp phải tắc nghẽn là lượng dữ liệu có chú thích của con người đủ thường không có sẵn và quá tốn kém để sản xuất thủ công, đặc biệt khi cần chuyên môn về lĩnh vực.

![Hình 1](figure1.png)
Hình 1: Quá trình học thông qua tạo dataset. Một mô hình giáo viên (LLM) được prompted để tạo 500 đánh giá phim cho mỗi cảm xúc (tích cực, tiêu cực). Một PLM học sinh nhỏ hơn được huấn luyện trên dataset được tạo.

**Tạo dataset với LLM giáo viên.** Gần đây, một mô hình được gọi là học zero-shot thông qua tạo dataset (Meng et al., 2022; Ye et al., 2022a,b) đã xuất hiện, có khả năng loại bỏ nhu cầu dữ liệu có chú thích của con người. Phương pháp này tận dụng khả năng tạo của các mô hình ngôn ngữ lớn (LLM) để tạo ra các văn bản có điều kiện lớp được hướng dẫn bởi các prompt mô tả nhãn và, tùy chọn, các ví dụ few-shot của các thể hiện của các lớp mong muốn. Dataset được tạo sau đó được sử dụng để huấn luyện một PLM học sinh nhỏ hơn.

Tham khảo Hình 1 để minh họa quá trình này: Trong ví dụ này, một LLM được hướng dẫn viết 500 đánh giá phim tích cực và 500 tiêu cực. Để hướng dẫn quá trình, chúng tôi bao gồm một ví dụ về đánh giá tích cực và tiêu cực trong prompt. Với prompt và ví dụ 1-shot này, chúng tôi tạo một dataset gồm 1,000 đánh giá phim được gán nhãn với cảm xúc nhị phân. Dataset này được sử dụng để huấn luyện một mô hình học sinh thực hiện phân tích cảm xúc nhị phân.

**Hạn chế.** Tuy nhiên, mặc dù tính đơn giản về khái niệm của việc sử dụng LLM để tạo dữ liệu huấn luyện, nhiều câu hỏi mở vẫn còn về các chi tiết cụ thể và tiềm năng cuối cùng của phương pháp này. Các câu hỏi bao gồm: (1) Cách prompt LLM tốt nhất và có nên bao gồm các ví dụ trong prompt hay không, (2) Phương pháp này hiệu quả cho những họ tác vụ NLP downstream nào và các tác vụ cụ thể nào, và (3) Liệu tốt hơn là tạo lượng lớn dữ liệu huấn luyện hay tập trung vào các nỗ lực tạo nhỏ hơn, chất lượng cao. Trong khi nhiều công trình hiện tại đang điều tra những câu hỏi này cho các tác vụ cụ thể, chúng tôi thấy rằng, hiện tại, không có thư viện mã nguồn mở nào cụ thể hỗ trợ nghiên cứu về tạo dataset với LLM.

**Đóng góp.** Để khép kín khoảng trống này, chúng tôi trình bày FABRICATOR, một thư viện Python mã nguồn mở để tạo dataset với LLM. Mục tiêu chính của chúng tôi là tạo điều kiện thử nghiệm, cho phép áp dụng tạo dataset cho các tác vụ downstream cụ thể, và khuyến khích tính tái tạo của các thí nghiệm. FABRICATOR mô-đun hóa quá trình tạo dataset và cung cấp một giao diện đơn giản để tạo điều kiện thử nghiệm: Người dùng có thể chọn LLM nào để sử dụng, định nghĩa prompt và định nghĩa nhãn, và tận dụng các dataset NLP hiện có cho các ví dụ few-shot và định nghĩa tác vụ NLP. Thư viện của chúng tôi bao gồm tích hợp vào thư viện DATASETS của HuggingFace (Lhoest et al., 2021), cho phép người dùng dễ dàng chia sẻ các dataset được tạo và sử dụng chúng để huấn luyện mô hình NLP. Chúng tôi cung cấp các ví dụ cho nhiều họ tác vụ NLP khác nhau, bao gồm phân loại văn bản, suy luận văn bản, hỏi đáp, và nhận dạng thực thể.

Trong bài báo này:
• Chúng tôi giới thiệu thư viện FABRICATOR, đưa ra tổng quan về các khái niệm cốt lõi và quy trình sử dụng (Phần 2).
• Chúng tôi trình bày một tập hợp các thí nghiệm ví dụ trong đó FABRICATOR được sử dụng để tạo dataset cho nhiều tác vụ phân loại văn bản, hỏi đáp, và suy luận văn bản khác nhau (Phần 3).

Chúng tôi công bố mã trên GitHub¹ dưới giấy phép Apache 2.

¹https://github.com/flairNLP/fabricator

## 2 FABRICATOR

Trước tiên chúng tôi đưa ra tổng quan cấp cao về các quy trình tạo được hỗ trợ trong FABRICATOR (Phần 2.1), thảo luận về các lớp và khái niệm chính (Phần 2.2), và hướng dẫn qua một trường hợp sử dụng ví dụ và script (Phần 2.3).

### 2.1 Quy trình Tạo

Tùy thuộc vào tác vụ downstream, các nhà nghiên cứu có thể có một trong ba mục tiêu tạo dữ liệu mà chúng tôi hỗ trợ trong FABRICATOR:

**1. Tạo dữ liệu không có nhãn.** Mục tiêu tạo đầu tiên là sản xuất dữ liệu không có nhãn. Ví dụ, trong quá trình phát triển hệ thống hỏi đáp, chúng ta có thể cần một corpus các câu hỏi ví dụ hoặc một corpus các văn bản về một chủ đề cụ thể. Cho kịch bản này, người dùng cung cấp một prompt w (như "Tạo một văn bản trong lĩnh vực lịch sử chứa các sự kiện mà ai đó có thể đặt câu hỏi về."), và LLM tự hồi quy Gθ tạo văn bản phù hợp xg.

**2. Tạo dữ liệu có điều kiện nhãn.** Mục tiêu tạo thứ hai là tạo dữ liệu thuộc về một lớp được định nghĩa trước, như các tác vụ phân loại. LLM tạo một văn bản xg tương ứng với một nhãn cụ thể y từ một tập hợp các nhãn.

Như đã thảo luận trong phần giới thiệu, một ví dụ là tạo dữ liệu huấn luyện cho một bộ phân loại cảm xúc nhị phân. Để đạt được điều này, người ta phải định nghĩa một tập hợp các nhãn (y={tích cực, tiêu cực}) và một prompt wy như "Tạo một đánh giá phim <y>:." Chuỗi được tạo xg sẽ được ghép nối với nhãn y để tạo thành một cặp huấn luyện (xg, y) cho fine-tuning.

**3. Chú thích dữ liệu không có nhãn.** Mục tiêu tạo thứ ba xảy ra nếu một dataset văn bản không có nhãn cho một lĩnh vực đã có sẵn và chỉ thiếu các nhãn huấn luyện. Ví dụ, một corpus các đánh giá phim có thể đã có sẵn, nhưng thiếu các nhãn cảm xúc.

Trong FABRICATOR, các nhà nghiên cứu có thể thêm nhãn vào một corpus hiện có bằng cách mở rộng prompt w với các tùy chọn nhãn cố định y để tạo thành wy như "Chú thích đánh giá phim là: tích cực, tiêu cực." Nhãn được tạo y sau đó được ghép nối với điểm dữ liệu không có nhãn xu để tạo thành một cặp dữ liệu (xu, y).

Các mục tiêu tạo được định nghĩa ở trên sẽ được thực hiện nhiều lần để tạo một corpus với kích thước được chỉ định. Prompt cũng có thể được mở rộng để bao gồm các ví dụ few-shot của mỗi lớp, như được hiển thị trong Hình 1. Prompt cũng có thể xử lý nhiều đầu vào (ví dụ, cho các tác vụ như tương tự văn bản) sử dụng các giao diện được định nghĩa trước trong FABRICATOR. Trong tất cả các trường hợp, prompt chính xác được soạn và thực hiện trong backend của chúng tôi.

### 2.2 Các Lớp và Khái niệm

Như Hình 2 minh họa, mô-đun chính trong phương pháp của chúng tôi là lớp DatasetGenerator, hoạt động như một điều phối viên giữa LLM (PromptNode), prompt (BasePrompt), và tùy chọn, các ví dụ few-shot và dataset không có nhãn.

![Hình 2](figure2.png)
Hình 2: Với FABRICATOR, quá trình tạo bao gồm một template prompt tạo prompt cuối cùng sử dụng tất cả các đối số được cung cấp. Lớp generator tạo các ví dụ huấn luyện cho đến khi đạt số lần gọi prompt tối đa, hoặc dataset không có nhãn được chú thích đầy đủ. Cuối cùng, lớp generator tạo ra một instance Dataset HuggingFace.

Hàm generate() trong lớp DatasetGenerator chuyển đổi BasePrompt và dữ liệu few-shot và không có nhãn được cung cấp thành một prompt có thể xử lý cho LLM. Phương thức cung cấp nhiều đối số khác nhau để điều khiển quá trình tạo. Người dùng có thể chỉ định các tham số như số lần gọi API tối đa, chiến lược lấy mẫu của các ví dụ few-shot (đồng nhất vs. phân tầng), hoặc số lượng ví dụ few-shot để sử dụng trong một prompt duy nhất. Repository của chúng tôi chứa tài liệu với chi tiết về tất cả các tùy chọn tùy chỉnh có sẵn.

#### 2.2.1 Khả năng Tương tác HuggingFace thông qua Lớp Dataset

FABRICATOR hoạt động trên lớp Dataset từ thư viện DATASETS của HuggingFace. Theo mặc định, generate() tạo ra dữ liệu được tạo như một instance Dataset. Điều này cho phép các dataset được tạo được sử dụng trực tiếp trong các script huấn luyện hiện có của thư viện TRANSFORMERS (Wolf et al., 2020) và được chia sẻ giữa các nhà nghiên cứu qua hub dataset Huggingface.

Một dataset hiện có cũng có thể được sử dụng như đầu vào cho phương thức generate(). Vì thư viện DATASETS hỗ trợ một loạt các benchmark tiêu chuẩn và định dạng của chúng, các dataset hiện có có thể được tải và sử dụng như đầu vào một cách dễ dàng. Ví dụ, trong một số quy trình tạo, chúng tôi muốn thêm nhãn vào một corpus hiện có hoặc sử dụng các instance như các ví dụ few-shot trong một prompt.

#### 2.2.2 Lớp Prompt

Prompting là quan trọng khi hoạt động trên các mô hình ngôn ngữ lớn vì nó hướng dẫn quá trình tạo tự hồi quy. Trong khi trong trường hợp đơn giản nhất, một prompt là một chuỗi văn bản duy nhất, chúng tôi thấy rằng nhiều kịch bản yêu cầu các prompt phức tạp hơn và các tùy chọn tùy chỉnh. Ví dụ, khi bao gồm các ví dụ few-shot trong một prompt, các câu hỏi bao gồm bao nhiêu ví dụ để bao gồm trong mỗi prompt và cách chúng được lấy mẫu (đồng nhất vs. phân tầng) từ dữ liệu few-shot có sẵn qua các lần gọi prompt khác nhau. Tương tự, độ phức tạp tăng lên cho các tác vụ như suy luận văn bản (yêu cầu nhiều đầu vào) và nhận dạng thực thể (có khả năng yêu cầu chuyển đổi các thẻ BIOES cấp token thành các truy vấn prompting cấp span).

Để giải quyết những thách thức này, FABRICATOR giới thiệu một lớp BasePrompt đơn giản nhưng mạnh mẽ cung cấp các giao diện rõ ràng để tùy chỉnh prompt cho nhiều tác vụ tạo dataset khác nhau. Giao diện bao gồm các thuộc tính để chỉ định các tùy chọn nhãn được định nghĩa trước cho tạo có điều kiện nhãn, và hỗ trợ có các ví dụ few-shot hoặc dataset không có nhãn bằng cách chọn các cột liên quan cho thông tin tạo và few-shot trong prompt.

Vì lớp prompt hoạt động trực tiếp trên các cột dataset, FABRICATOR cho phép thiết kế prompt tinh vi và linh hoạt. Để minh họa, khi thực hiện tác vụ tương tự văn bản, người dùng có thể chỉ định câu đầu tiên và nhãn như thông tin few-shot và prompt LLM tạo câu thứ hai tương ứng với câu và nhãn đã cho.

#### 2.2.3 LLM

Giao diện LLM phải ổn định và lý tưởng tương thích với các mô hình được host như API hoặc LLM tự host. Chúng tôi tận dụng framework HAYSTACK² (Pietsch et al., 2019), cụ thể là lớp PromptNode, cho các tương tác với LLM. Việc triển khai PromptNode cho phép người dùng chọn và sử dụng LLM từ nhiều nhà cung cấp mô hình khác nhau, bao gồm HuggingFace, OpenAI, Azure, Anthropic, và Cohere.

²https://github.com/deepset-ai/Haystack

### 2.3 Script Ví dụ

Trong Listing 1, chúng tôi giới thiệu một script ví dụ trong đó FABRICATOR được sử dụng để tạo thêm các đánh giá phim để huấn luyện một mô hình phân loại cảm xúc nhị phân (tham khảo quy trình tạo 2 như được định nghĩa trong Phần 2.1). Để thực hiện điều này, chúng tôi định nghĩa:

```python
1import os
2from datasets import load_dataset
3from haystack.nodes import PromptNode
4from fabricator import DatasetGenerator, BasePrompt
5
6dataset = load_dataset("processed_fewshot_imdb", split="train")
7
8prompt = BasePrompt(
9    task_description="Generate a {} movie review.",
10   label_options=["positive", "negative"],
11   generate_data_for_column="text",
12)
13
14prompt_node = PromptNode(
15   model_name_or_path="gpt-3.5-turbo",
16   api_key=os.environ.get("OPENAI_API_KEY"),
17   max_length=100,
18)
19
20generator = DatasetGenerator(prompt_node)
21generated_dataset = generator.generate(
22   prompt_template=prompt,
23   fewshot_dataset=dataset,
24   fewshot_sampling_strategy="uniform",
25   fewshot_examples_per_class=1,
26   fewshot_sampling_column="label",
27)
28generated_dataset.push_to_hub("generated-movie-reviews")
```

Listing 1: Một script sử dụng FABRICATOR và tạo thêm các đánh giá phim dựa trên các ví dụ few-shot.

• một dataset few-shot được tiền xử lý (dataset, dòng 6) có nhãn ở dạng ngôn ngữ tự nhiên (ví dụ, 0 trở thành "tiêu cực"). Những ví dụ này được sử dụng để tăng cường prompt tạo,
• một template prompt (prompt, dòng 8) chỉ định hướng dẫn cho LLM,
• một LLM để sử dụng như mô hình giáo viên (prompt_node, dòng 14),
• một DatasetGenerator để thực hiện quá trình tạo với tất cả các tham số (generator, dòng 20).

Prompt được cấu hình trong constructor của lớp BasePrompt (dòng 8-12): Chúng tôi đặt một task_description với một placeholder cho label_options mà chúng tôi cung cấp như một đối số riêng biệt. Chúng tôi cũng chỉ định cho cột nào trong dataset được tải để dự đoán nhãn.

Sau đó chúng tôi định nghĩa một LLM giáo viên (dòng 14-18) và truyền dataset, prompt, và LLM cho lớp điều phối viên DatasetGenerator (dòng 20-27). Ở đây, chúng tôi chỉ định một chiến lược few-shot để lấy mẫu một nhãn từ cột "label" một cách đồng nhất trong quá trình tạo. Chúng tôi làm như vậy để tạo ra một đánh giá tích cực hoặc tiêu cực. Khi hoàn thành, hàm generate trả về instance Dataset được chú thích.

## 3 Thí nghiệm

Để minh họa cách FABRICATOR có thể được sử dụng trong nghiên cứu, chúng tôi tiến hành một đánh giá khám phá của hai kịch bản: (1) các mô hình được huấn luyện trên dataset được tạo so sánh như thế nào với các mô hình được huấn luyện trên dataset có chú thích của con người, và (2) liệu các ví dụ few-shot trong prompt có cải thiện dataset được tạo hay không.

Để làm như vậy, chúng tôi huấn luyện các PLM nhỏ hơn trên dataset được tạo và đánh giá chúng trên split test có nhãn của con người của benchmark tương ứng. Cho hỏi đáp, chúng tôi fine-tune một PLM roberta-base (Liu et al., 2019). Cho tất cả các tác vụ khác, chúng tôi fine-tune một PLM bert-base-uncased (Devlin et al., 2019). Các siêu tham số được liệt kê trong Phụ lục A.2. Chúng tôi báo cáo điểm và độ lệch chuẩn được tính trung bình trên 5 seed ngẫu nhiên cho mỗi thí nghiệm.

### 3.1 Thí nghiệm 1: So sánh Dataset Được tạo và Có chú thích của Con người

Chúng tôi chú thích lại các benchmark dataset hiện có với nhãn được tạo trong thí nghiệm đầu tiên. Thí nghiệm này nhằm đo lường sự khác biệt về độ chính xác của các mô hình tác vụ downstream được huấn luyện trên dữ liệu có chú thích của con người so với các mô hình được huấn luyện trên dữ liệu được tạo. Chúng tôi đánh giá các tác vụ phân loại văn bản, tương tự văn bản, và hỏi đáp trích xuất.

**Thiết lập thí nghiệm.** Chúng tôi tiến hành đánh giá này trên 5 dataset bao trùm 3 tác vụ NLP: Chúng tôi sử dụng IMDB (Maas et al., 2011), một benchmark phân loại cảm xúc nhị phân, và TREC-6 (Li và Roth, 2002), một dataset phân loại loại câu hỏi 6 lớp để đánh giá các tác vụ phân loại văn bản. Chúng tôi sử dụng MRPC 2 lớp (Dolan và Brockett, 2005) và dataset SNLI 3 lớp (Bowman et al., 2015) để đánh giá các tác vụ tương tự văn bản. Cuối cùng, chúng tôi sử dụng SQuAD-v2 (Rajpurkar et al., 2016) để đánh giá hỏi đáp trích xuất. Chúng tôi sử dụng prompt tạo được tăng cường bởi 2 ví dụ mỗi prompt được lấy mẫu từ 6 ví dụ few-shot có thể có mỗi lớp.

**Kết quả (Bảng 1).** Cho tất cả dataset, chúng tôi so sánh một dataset được tạo gồm 50, 500, 1k và dataset đầy đủ (giới hạn ở 10k nếu nó lớn hơn) với dữ liệu có chú thích vàng cùng kích thước. Cho hỏi đáp, các mô hình cần được huấn luyện trên ít nhất 1k để có được kết quả đại diện, vì vậy chúng tôi không báo cáo điểm cho 50 hoặc 500 ví dụ cho SQuAD.

| Dataset | Nhãn | # Ví dụ huấn luyện |  |  |  |
|---------|------|-----|-----|-----|-----|
|         |      | 50 | 500 | 1k | tất cả (tối đa 10k) |
| IMDB    | Vàng | 37.6±35.8 | 88.5±0.8 | 90.0±0.4 | 93.0±0.2 |
|         | Được tạo | 53.8±11.5 | 88.8±0.6 | 90.2±0.4 | 92.0±0.1 |
| MRPC    | Vàng | 66.6±0.8 | 73.0±1.3 | 75.2±1.1 | 83.9±0.2 |
|         | Được tạo | 68.4±0.8 | 72.1±1.0 | 72.4±1.2 | 75.8±0.7 |
| SNLI    | Vàng | 38.5±2.5 | 64.7±0.9 | 71.3±0.7 | 82.1±0.4 |
|         | Được tạo | 42.2±2.4 | 54.8±1.0 | 56.1±1.1 | 63.1±0.7 |
| TREC-6  | Vàng | 50.4±7.6 | 93.6±0.6 | 94.9±1.1 | 97.5±0.4 |
|         | Được tạo | 39.8±4.5 | 79.3±2.2 | 80.8±3.0 | 82.4±1.1 |
| SQuAD   | Vàng | - | - | 39.1±4.9 | 68.8±0.5 |
|         | Được tạo | - | - | 46.8±1.1 | 52.5±0.3 |

Bảng 1: Kết quả về các thí nghiệm chú thích lại sử dụng 2 ví dụ few-shot mỗi prompt (được lấy mẫu đồng nhất từ 6 ví dụ few-shot mỗi lớp). Chúng tôi báo cáo độ chính xác ngoại trừ SQuAD, nơi chúng tôi báo cáo F1, và tô đậm những thí nghiệm mà dữ liệu được tạo mang lại điểm tương tự như dữ liệu có chú thích của con người. Chúng tôi quan sát thấy rằng GPT-3.5 không thể chú thích ở hiệu suất cấp con người ngoại trừ các tác vụ phân loại đơn giản như IMDB.

Chúng tôi thấy rằng cho các tác vụ đơn giản như phân loại cảm xúc nhị phân (IMDB), các mô hình được huấn luyện trên các chú thích bởi LLM đạt được độ chính xác tương tự trên split test có nhãn vàng (↓1.0 pp. về độ chính xác với 10k ví dụ huấn luyện). Tuy nhiên, chúng tôi thấy rằng khi độ phức tạp của dataset tăng lên (phân loại văn bản với nhiều lớp hơn và hỏi đáp trích xuất), chúng tôi quan sát thấy rằng hiệu suất của các mô hình được huấn luyện trên dataset có chú thích LLM kém hơn (↓19.0 pp. cho SNLI và ↓16.3 pp. cho SQuAD, với 10k ví dụ huấn luyện).

Những khoảng cách hiệu suất này chỉ ra rằng tính hữu ích của LLM như mô hình giáo viên phụ thuộc vào tác vụ cụ thể. Trong phần tiếp theo, chúng tôi trình bày một thí nghiệm khám phá cách thu hẹp khoảng cách này bằng cách sử dụng thêm các ví dụ few-shot.

### 3.2 Thí nghiệm 2: Tác động của Các ví dụ Few-Shot

Trong thí nghiệm ví dụ thứ hai, chúng tôi chú thích lại TREC-6 sử dụng một số lượng khác nhau các ví dụ few-shot. Thí nghiệm này nhằm xác định liệu thêm các ví dụ few-shot cho mỗi lớp có cải thiện tạo dataset với FABRICATOR hay không. Chúng tôi điều tra hai biến: (1) Tổng số ví dụ few-shot có sẵn mỗi lớp và (2) số lượng thực tế các ví dụ few-shot được bao gồm mỗi prompt. Ví dụ, có thể có 8 ví dụ few-shot có sẵn tổng cộng, nhưng chỉ 3 được lấy mẫu ngẫu nhiên để được bao gồm trong mỗi lần gọi prompt.

| Dataset | # ví dụ few-shot | # ví dụ mỗi lớp được sử dụng trong prompt |  |  |  |  |
|---------|----------|-----|-----|-----|-----|-----|
|         | mỗi lớp | 0 | 1 | 2 | 3 | 4 |
| TREC-6  | 0 | 45.5±2.3 | - | - | - | - |
|         | 2 | - | 70.0±1.6 | 65.5±0.9 | - | - |
|         | 4 | - | 79.5±1.1 | 71.1±2.0 | 86.6±0.6 | 69.8±1.5 |
|         | 8 | - | 76.1±1.9 | 79.5±1.3 | 81.0±1.8 | 87.4±0.6 |
|         | 16 | - | 72.7±2.1 | 78.1±1.9 | 81.0±2.4 | 74.2±1.4 |

Bảng 2: Kết quả trên 500 ví dụ TREC-6 được chú thích sử dụng lượng khác nhau các ví dụ few-shot. Chúng tôi quét qua số lượng ví dụ few-shot và số lượng ví dụ few-shot được sử dụng trong prompt thực tế. Chúng tôi tô đậm nơi tăng ví dụ few-shot cải thiện so với điểm TREC-6 79.3 của Thí nghiệm 1 (Bảng 1).

**Kết quả (Bảng 2).** Chúng tôi lưu ý một xu hướng tích cực chung là tăng số lượng ví dụ few-shot có sẵn (cột # ví dụ few-shot mỗi lớp) và tăng số lượng ví dụ được sử dụng trong mỗi prompt (cột # ví dụ mỗi lớp được sử dụng trong prompt) cải thiện hiệu suất mô hình. Đặc biệt, chúng tôi thấy nhiều thiết lập vượt trội so với các số liệu của thí nghiệm trước (nơi chúng tôi lấy mẫu 2 ví dụ mỗi prompt từ tổng cộng 6 ví dụ có thể), được tô đậm trong Bảng 2.

Tuy nhiên, chúng tôi cũng thấy rằng các cải thiện trở nên không đều khi # ví dụ mỗi lớp được sử dụng trong prompt được tăng lên trên 3, chỉ ra rằng prompt không nên bị quá tải với quá nhiều ví dụ.

## 4 Công trình Liên quan

Tiến bộ đáng kể đã được đạt được trong việc tăng cường tạo dataset với LLM giáo viên (Schick và Schütze, 2021b; Meng et al., 2022; Ye et al., 2022a; Bonifacio et al., 2022; Peng et al., 2023; Meng et al., 2023), hiệu quả chọn các ví dụ few-shot (Liu et al., 2022; Gunasekar et al., 2023) và đánh giá chất lượng của dataset được sản xuất bởi LLM (Gilardi et al., 2023; Chen et al., 2023).

Tuy nhiên, chúng tôi lưu ý thiếu các framework có thể truy cập tạo điều kiện tạo dataset đơn giản và có thể tái tạo sử dụng LLM giáo viên. Trong khi các bộ công cụ mã nguồn mở hiện có như OpenPrompt (Ding et al., 2022) một phần mở rộng đến các kịch bản tạo dataset, phương pháp của chúng tôi nổi bật bằng cách có các giao diện nhẹ, chuyên dụng cho các tác vụ tạo được giới thiệu, hỗ trợ một loạt LLM sử dụng haystack, và tích hợp với HuggingFace DATASETS để đánh giá dễ dàng.

Học dựa trên prompt (Liu et al., 2021; Gao et al., 2021; Schick và Schütze, 2021a; Le Scao và Rush, 2021) là một dòng nghiên cứu khác đã tỏ ra hữu ích trong việc cải thiện các tác vụ downstream trong thiết lập zero- và few-shot bằng cách tận dụng các mục tiêu tiền huấn luyện của LLM (Brown et al., 2020; Ouyang et al., 2022; Zhang et al., 2022; Scao et al., 2023; Touvron et al., 2023). Tuy nhiên, tính có sẵn của dữ liệu huấn luyện trong các kịch bản tài nguyên thấp vẫn quan trọng (Perez et al., 2021; Sahu et al., 2022). Do đó, phương pháp của chúng tôi cũng tìm cách lấp đầy khoảng trống này bằng cách cung cấp một bộ công cụ tạo dataset toàn diện và dễ dàng tái tạo.

## 5 Kết luận

Chúng tôi đã giới thiệu FABRICATOR, một thư viện thân thiện với người dùng để tạo dataset sử dụng LLM. Với FABRICATOR, các nhà nghiên cứu truy cập một giao diện có thể tùy chỉnh cao cho phép nghiên cứu hiệu quả về học zero-shot và few-shot thông qua tạo dataset. Hơn nữa, chúng tôi đã triển khai nhiều baseline khác nhau sử dụng dataset được tạo để minh họa các ứng dụng tiềm năng của repository của chúng tôi và dự định hỗ trợ thêm các tác vụ downstream trong tương lai. Chúng tôi tin rằng FABRICATOR sẽ là một công cụ có giá trị cho cộng đồng NLP, tạo điều kiện cho các tiến bộ trong tạo dataset và thúc đẩy nghiên cứu trong nhiều lĩnh vực xử lý ngôn ngữ tự nhiên khác nhau.

## Hạn chế

Trong khi bài báo của chúng tôi nhằm giải quyết việc tạo dataset cho một loạt các tác vụ downstream, điều quan trọng là phải thừa nhận những hạn chế nhất định trong nghiên cứu của chúng tôi. Thứ nhất, trong giai đoạn đánh giá repository của chúng tôi, chúng tôi chỉ có thể kiểm tra và đánh giá một tập hợp con các tác vụ do hạn chế về tài nguyên và thời gian. Đánh giá của chúng tôi có thể chỉ bao trùm một phần các tác vụ mà các nhà nghiên cứu và thực hành thường gặp trong công việc của họ. Công việc tương lai phải mở rộng đánh giá để bao gồm một loạt rộng hơn các tác vụ để cung cấp hiểu biết toàn diện hơn về hiệu quả của repository.

Ngoài ra, mặc dù nỗ lực tốt nhất của chúng tôi trong việc thiết kế bố cục repository để có tính linh hoạt và khả năng thích ứng, có thể có các tác vụ hoặc lĩnh vực cụ thể nơi cấu trúc hoặc tính năng của repository chúng tôi có thể không áp dụng trực tiếp. Chúng tôi thừa nhận rằng cảnh quan của các tác vụ downstream đa dạng và liên tục phát triển, có thể yêu cầu các phương pháp được điều chỉnh hoặc mở rộng cho framework hiện có của chúng tôi.

Hơn nữa, chúng tôi nhằm bao gồm nghiên cứu hiện có nhắm vào tạo dataset chất lượng cao (ví dụ, Ye et al. (2022b)) và tiến hành nghiên cứu riêng của chúng tôi về các metric chất lượng và đa dạng để điều khiển quá trình tạo. Chúng tôi khuyến khích các đóng góp mã nguồn mở và sự tham gia tích cực từ cộng đồng để giải quyết những hạn chế này. Bằng cách bao gồm một loạt quan điểm và chuyên môn toàn diện hơn, chúng tôi nhằm liên tục cải thiện repository và tăng cường tính phù hợp của nó cho các yêu cầu tác vụ khác nhau.

Hơn nữa, trong khi chúng tôi đã nỗ lực cung cấp tài liệu và hướng dẫn kỹ lưỡng trong repository, luôn có khả năng các vấn đề bị bỏ qua hoặc những thách thức không lường trước có thể phát sinh trong quá trình tạo dataset.

## Tuyên bố Đạo đức

Trong khi các mô hình ngôn ngữ lớn đã cho thấy những tiến bộ đáng kể trong hiểu và tạo ngôn ngữ tự nhiên, khả năng của chúng cũng đặt ra những cân nhắc đạo đức quan trọng. Một mối quan tâm nổi bật là tiềm năng ảo giác, nơi các mô hình có thể tạo ra thông tin sai lệch hoặc gây hiểu lầm. Khía cạnh này có thể có những tác động nghiêm trọng, đặc biệt khi dataset được tạo cho các lĩnh vực quan trọng như y học, luật, hoặc báo chí. Điều quan trọng là phải thận trọng và xác minh tính chính xác và độ tin cậy của các đầu ra được tạo bởi repository của chúng tôi, đặc biệt khi đưa ra các quyết định có hậu quả trong thế giới thực.

Một mối quan tâm đạo đức khác là sự hiện diện của thiên kiến trong các mô hình ngôn ngữ, có thể duy trì và khuếch đại các định kiến và bất bình đẳng xã hội. Những thiên kiến này có thể phát sinh từ dữ liệu huấn luyện thiên kiến (Haller et al., 2023) hoặc các mẫu thiên kiến trong văn bản do con người tạo mà các mô hình học từ đó. Vì repository của chúng tôi đang ở giai đoạn đầu, chúng tôi nhấn mạnh việc kiểm tra cẩn thận các dataset được tạo để xác định và khắc phục các thiên kiến có thể có mặt.

Để đảm bảo một quá trình tạo dataset có trách nhiệm, điều cần thiết là tham gia vào việc xác thực dữ liệu kỹ lưỡng, bao gồm xác định và giải quyết các thiên kiến tiềm tàng, kiểm tra các nguồn dữ liệu về độ tin cậy và độ tin cậy, và bao gồm các quan điểm đa dạng trong các quy trình thu thập và chú thích dataset. Hơn nữa, giám sát và kiểm toán liên tục các đầu ra và hiệu suất của mô hình có thể giúp xác định và khắc phục bất kỳ mối quan tâm đạo đức nào phát sinh trong quá trình triển khai.

## Lời cảm ơn

Chúng tôi cảm ơn tất cả các reviewer vì những bình luận có giá trị của họ. Jonas Golde được hỗ trợ bởi Bộ Kinh tế và Hành động Khí hậu Liên bang Đức (BMWK) như một phần của dự án ENA (KK5148001LB0). Alan Akbik và Patrick Haller được hỗ trợ bởi Deutsche Forschungsgemeinschaft (DFG, Quỹ Nghiên cứu Đức) dưới grant Emmy Noether "Eidetic Representations of Natural Language" (số dự án 448414230). Alan Akbik hơn nữa được hỗ trợ dưới Chiến lược Xuất sắc của Đức "Science of Intelligence" (EXC 2002/1, số dự án 390523135). Felix Hamborg được hỗ trợ bởi chương trình WIN của Viện Hàn lâm Khoa học và Nhân văn Heidelberg, được tài trợ bởi Bộ Khoa học, Nghiên cứu và Nghệ thuật của Bang Baden-Wurttemberg, Đức.

## Tài liệu tham khảo

[Phần tài liệu tham khảo giữ nguyên như bản gốc do chứa các trích dẫn học thuật chuẩn]

## A Phụ lục

### A.1 Screencast

Một screencast về framework FABRICATOR có thể tìm thấy trên Vimeo.

### A.2 Siêu tham số cho Thí nghiệm

Chúng tôi sử dụng AdamW (Loshchilov và Hutter, 2019) như optimizer của chúng tôi với batch size là 16. Hơn nữa, chúng tôi sử dụng warm-up tuyến tính cho 10% các bước tối ưu hóa. Chúng tôi fine-tune roberta-base cho hỏi đáp với learning rate 1e−5 trong hai epoch không có early stopping. Cho PLM bert-base-uncased, chúng tôi fine-tune sử dụng learning rate 2e−5 trong 5 (nếu dữ liệu huấn luyện có nhiều hơn 1000 ví dụ), 10 (nếu dataset huấn luyện có ít nhất 500 nhưng ít hơn 1001 ví dụ) hoặc 20 epoch (nếu dữ liệu huấn luyện ít hơn 501 ví dụ). Hơn nữa, qua tất cả các thí nghiệm, chúng tôi sử dụng 10% dữ liệu như validation split để chọn mô hình.

### A.3 Tạo Dữ liệu Huấn luyện Có điều kiện Nhãn

Thí nghiệm này sử dụng tạo có điều kiện nhãn để tạo dữ liệu mới cho dataset TREC chứa sáu lớp. Để đạt được điều này, chúng tôi lấy mẫu một dataset few-shot nhỏ từ split huấn luyện hiện có, bao gồm 8 ví dụ mỗi lớp. Trong quá trình tạo, cho mỗi nhãn y, chúng tôi bao gồm ba ví dụ few-shot được lấy mẫu đồng nhất liên kết với nhãn đó. Chúng tôi tạo 10k cặp dữ liệu (xg,y) và sử dụng chúng để fine-tuning. Điều quan trọng cần lưu ý là dataset có nhãn vàng chỉ chứa khoảng 3k ví dụ. Do đó cột "tất cả" đề cập đến 10k ví dụ được tạo với GPT hoặc đến ~3k ví dụ có nhãn vàng. Thiết lập thí nghiệm giống hệt với Phần 3.

Kết quả được mô tả trong Bảng 3. Chúng tôi quan sát thấy sự giảm hiệu suất đáng kể so với các thí nghiệm chú thích lại cho TREC từ Phần 3.1. Ví dụ, sử dụng 10k ví dụ được tạo đạt được mức hiệu suất tương tự với việc sử dụng 50 ví dụ có chú thích của con người (so sánh với Bảng 1). Tuy nhiên, chúng tôi lưu ý rằng chúng tôi không thực hiện kỹ thuật tối ưu hóa prompt hoặc tìm kiếm siêu tham số trong tất cả các thí nghiệm. Ngoài ra, chúng tôi tạo một phân phối đồng nhất của các lớp, trong khi dataset có nhãn vàng bị nghiêng về các danh mục nhất định. Đáng lưu ý rằng thông tin phân phối lớp này có thể không có sẵn trong các thiết lập few-shot thế giới thực.

| Dataset | Dữ liệu | # Ví dụ huấn luyện |  |  |  |
|---------|---------|-----|-----|-----|-----|
|         |         | 50 | 500 | 1000 | tất cả |
| TREC-6  | Vàng | 42.7±9.6 | 93.8±0.3 | 95.1±0.6 | 97.1±0.3 |
|         | Được tạo | 27.5±11.0 | 56.2±3.3 | 57.9±1.6 | 62.6±3.4 |

Bảng 3: Kết quả trên TREC-6 với các câu hỏi được tạo bởi GPT-3.5 sử dụng 3 ví dụ few-shot (được lấy mẫu đồng nhất từ 8 ví dụ few-shot có thể mỗi lớp). Chúng tôi quan sát thấy rằng hiệu suất tạo kém hơn so với dataset có chú thích của con người cùng kích thước. Tuy nhiên, hiệu suất tăng lên với số lượng ví dụ được tạo.

### A.4 Tác động của Các ví dụ Few-Shot trên Tạo Có điều kiện Nhãn

Trong thí nghiệm này, chúng tôi tạo 500 cặp dữ liệu có điều kiện nhãn cho dataset TREC, theo phương pháp được mô tả trong Phần 3.2. Chúng tôi tiến hành phân tích quét qua hai yếu tố: tổng số ví dụ few-shot mỗi lớp và số lượng ví dụ few-shot được bao gồm trong prompt thực tế.

| Dataset | # ví dụ few-shot | # ví dụ mỗi lớp được sử dụng trong prompt |  |  |  |  |
|---------|----------|-----|-----|-----|-----|-----|
|         | mỗi lớp | 0 | 2 | 3 | 4 | 5 |
| TREC-6  | 0 | 30.2±0.6 | - | - | - | - |
|         | 2 | - | 43.0±3.7 | - | - | - |
|         | 4 | - | 56.0±0.5 | 56.3±2.4 | 58.3±2.2 | - |
|         | 8 | - | 52.8±1.5 | 58.8±1.0 | 58.2±1.0 | 64.0±2.0 |
|         | 16 | - | 58.3±0.8 | 59.8±2.5 | 58.7±1.1 | 54.8±1.5 |

Bảng 4: Kết quả trên 500 ví dụ TREC-6 được tạo với các kích thước khác nhau của ví dụ few-shot và số lượng ví dụ few-shot được bao gồm trong prompt. Chúng tôi quan sát thấy rằng nhiều ví dụ few-shot hơn dẫn đến hiệu suất tốt hơn trên split test có chú thích vàng.

Kết quả được mô tả trong Bảng 4. Các phát hiện của chúng tôi cho thấy rằng bao gồm ngay cả một số lượng nhỏ ví dụ few-shot (< 4) mang lại kết quả tốt hơn so với tạo mà không có bất kỳ ví dụ few-shot nào. Hơn nữa, khi chúng tôi sử dụng ít nhất bốn ví dụ mỗi lớp, chúng tôi quan sát thấy cải thiện đáng kể trong kết quả tạo, từ 30.2 đến 54.8 về độ chính xác (↑24.6pp. về độ chính xác). Ngoài ra, sử dụng nhiều ví dụ hơn trong một prompt riêng biệt cải thiện nhẹ hiệu suất mô hình. Chúng tôi gặp một ngoại lệ khi sử dụng 16 ví dụ mỗi lớp và bao gồm năm ví dụ trong prompt để tạo, dẫn đến hiệu suất thấp hơn so với lấy mẫu từ 8 ví dụ few-shot mỗi prompt. Điều quan trọng cần lưu ý là trong thí nghiệm này, chúng tôi không điều chỉnh bất kỳ siêu tham số nào của LLM để tạo, như temperature hoặc lấy mẫu top-k.

### A.5 Instruction-tuning các mô hình mã nguồn mở

Trong thí nghiệm này, chúng tôi so sánh hiệu suất chú thích của GPT-3.5 của OpenAI với một mô hình LLaMA được instruction-tuned mã nguồn mở. Để tiến hành đánh giá này, chúng tôi chọn tác vụ phân loại token trên dataset CoNLL-03 (Tjong Kim Sang và De Meulder, 2003), tạo một nhãn cho mỗi token trong đầu vào, làm cho nó trở thành một tác vụ có cấu trúc.

| Mô hình | Acc. (micro) | F1 |
|---------|-------------|-----|
| LLaMAv2 + Instr. Tuning | 92.4 | 60.0 |
| GPT-3.5* | 88.4 | 52.5 |

Bảng 5: So sánh các mô hình LLaMA được instruction-tuned với GPT-3.5 3-shot dựa trên split huấn luyện của CoNLL-03. Chúng tôi báo cáo độ chính xác và điểm F1 cấp span cho chú thích trên split validation. *: Chúng tôi chuyển đổi chuỗi thẻ thành span để prompt LLM với chuỗi thay vì chuỗi. Tuy nhiên, 38% các chú thích split validation có độ dài khác nhau sau tokenization đã được lọc ra để so sánh công bằng.

Kết quả được hiển thị trong Bảng 5. Chúng tôi quan sát thấy rằng sử dụng dataset như-là dẫn đến các đầu ra chú thích thường không sử dụng được, chủ yếu do định dạng không chính xác. Để giải quyết điều này, chúng tôi chuyển đổi các nhãn cấp token thành span và prompt LLM trích xuất tất cả các thực thể được đặt tên cho các danh mục liên quan. Sau đó chúng tôi chuyển đổi các thực thể được tìm thấy thành các thẻ cấp token bằng cách tìm kiếm các chú thích như substring của văn bản đầu vào. Chúng tôi so sánh hiệu suất của phương pháp này với một mô hình LLaMA được instruction-tuned trên toàn bộ split huấn luyện của CoNLL-03 bằng cách để cả hai LLM chú thích tập validation.

Không giống như đánh giá trước, chúng tôi không huấn luyện và đánh giá một PLM nhỏ hơn trên tập test có nhãn vàng. Thay vào đó, chúng tôi đánh giá hiệu suất giữa split validation có chú thích vàng và các chú thích được thực hiện bởi LLM. Các phát hiện của chúng tôi chỉ ra rằng chất lượng chú thích của LLM được instruction-tuned có thể cải thiện đáng kể so với GPT của OpenAI, như được thể hiện từ điểm F1 cao hơn. Phát hiện này cho thấy rằng các mô hình được instruction-tuned để tạo dataset có tiềm năng tạo điều kiện cho quá trình tạo cho các tác vụ downstream phức tạp trong các nỗ lực nghiên cứu tương lai.

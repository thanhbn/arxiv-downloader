# NL2TL: Chuyển đổi Ngôn ngữ Tự nhiên thành Logic Thời gian sử dụng Mô hình Ngôn ngữ Lớn

Yongchao Chen
MIT / Harvard
ycchen98@mit.edu

Rujul Gandhi
MIT
rujul@mit.edu

Yang Zhang
MIT-IBM Watson AI Lab
Yang.Zhang2@ibm.com

Chuchu Fan
MIT
chuchu@mit.edu

Tóm tắt

Logic Thời gian (TL) có thể được sử dụng để chỉ định một cách nghiêm ngặt các yêu cầu cấp cao phức tạp cho các hệ thống trong nhiều ứng dụng kỹ thuật. Việc dịch giữa ngôn ngữ tự nhiên (NL) và TL đã bị khám phá chưa đầy đủ do thiếu tập dữ liệu và mô hình có thể tổng quát hóa trên các miền ứng dụng khác nhau. Trong bài báo này, chúng tôi đề xuất một khung chuyển đổi chính xác và có thể tổng quát hóa các hướng dẫn tiếng Anh từ NL sang TL, khám phá việc sử dụng Mô hình Ngôn ngữ Lớn (LLMs) ở nhiều giai đoạn. Đóng góp của chúng tôi có hai khía cạnh. Đầu tiên, chúng tôi phát triển một khung để tạo ra tập dữ liệu các cặp NL-TL kết hợp LLMs và chú thích của con người. Chúng tôi công bố một tập dữ liệu với 28K cặp NL-TL. Sau đó, chúng tôi tinh chỉnh các mô hình T5 trên các phiên bản được nâng lên (tức là các Mệnh đề Nguyên tử (AP) cụ thể được ẩn) của NL và TL. Khả năng tổng quát hóa được cải thiện bắt nguồn từ hai khía cạnh: 1) Việc sử dụng NL-TL được nâng lên đặc trưng cho các cấu trúc logic chung, không bị ràng buộc bởi các miền cụ thể. 2) Việc áp dụng LLMs trong tạo tập dữ liệu làm tăng đáng kể độ phong phú của corpus. Chúng tôi kiểm tra khả năng tổng quát hóa của các mô hình được huấn luyện trên năm miền khác nhau. Để đạt được chuyển đổi NL-TL đầy đủ, chúng tôi hoặc kết hợp mô hình được nâng lên với nhiệm vụ nhận diện AP hoặc thực hiện tinh chỉnh thêm trên từng miền cụ thể. Trong quá trình tinh chỉnh thêm, mô hình của chúng tôi đạt được độ chính xác cao hơn (>95%) chỉ sử dụng <10% dữ liệu huấn luyện, so với mô hình cơ sở sequence to sequence (Seq2Seq).

1 Giới thiệu

Logic Thời gian (TL) đã được sử dụng rộng rãi như một ngôn ngữ chính xác về mặt toán học để chỉ định yêu cầu trong nhiều miền kỹ thuật như robot (Tellex et al., 2020), thiết kế điện tử (Browne et al., 1986), lái xe tự động (Maierhofer et al., 2020). TL có thể nắm bắt các yêu cầu không gian, thời gian và logic phức tạp của cả ngôn ngữ con người và ràng buộc môi trường, và có thể được chuyển đổi thành hành động có thể thực thi hoặc đầu vào điều khiển cho robot (Gundana và Kress-Gazit, 2022; Raman et al., 2013; Boteanu et al., 2016; Patel et al., 2020; Gopalan et al., 2018).

Không giống như nhiều công trình robot cố gắng sử dụng các mô hình hộp đen đầu cuối để suy ra hành vi robot trực tiếp từ ngôn ngữ tự nhiên (NL) (Ahn et al., 2022), việc sử dụng TL có cấu trúc như một trung gian có lợi ích kép - TL có thể được sử dụng để lập kế hoạch trực tiếp, và biểu diễn TL có thể được sử dụng để xác định các nguồn thất bại cụ thể và cung cấp phản hồi tự động cho người dùng không chuyên (Raman et al., 2013). Tuy nhiên, TL có đường cong học tập dốc. Việc truyền đạt mục tiêu và ràng buộc của một người thông qua NL trực quan hơn nhiều đối với người không chuyên. Do đó, một mô hình có thể chuyển đổi hướng dẫn NL thành TL là một thành phần còn thiếu nhưng quan trọng cho robot tương tác và thiết kế kỹ thuật.

Hiện tại, không có công cụ chung nào để thực hiện dịch tự động giữa TL và NL có xem xét các yêu cầu sau:

• Tổng quát hóa xuyên miền. Mặc dù TL được sử dụng trong nhiều miền kỹ thuật, các phương pháp NL-sang-TL hiện tại phần lớn giới hạn dữ liệu huấn luyện của chúng vào một miền duy nhất. Các tập dữ liệu này hầu hết thiếu độ phong phú corpus phong phú của NL-TL và có các định dạng riêng của Mệnh đề Nguyên tử (AP). Sau đó các mô hình không thể tổng quát hóa sang các miền khác (Gopalan et al., 2018), mặc dù cấu trúc của chính TL không phụ thuộc vào miền và nên là chung.

• Tính biến đổi của hướng dẫn NL. Công việc trước đây thường xây dựng dữ liệu tổng hợp theo thuật toán, đòi hỏi các hình thức đầu vào NL hạn chế. Các phát ngôn NL trong thế giới thực không thể được mã hóa thành một tập nhỏ các quy tắc. Các mô hình được huấn luyện trên dữ liệu đồng nhất như vậy không thể tổng quát hóa sang các cấu trúc câu mới (Brunello et al., 2019).

Một nút thắt lớn trong vấn đề NL-sang-TL là thiếu dữ liệu. Mặc dù các phương pháp thống kê hiện đại có thể vượt trội hơn các phương pháp dựa trên quy tắc (Buzhinsky, 2019), chúng thường yêu cầu một tập dữ liệu khổng lồ. Dữ liệu này đắt đỏ và khó thu thập vì cần chuyên môn mạnh của người chú thích (Brunello et al., 2019). Như đã nêu ở trên, việc ràng buộc miền hoặc hình thức của hướng dẫn NL giảm bớt áp lực về tập dữ liệu, nhưng cũng không thể tránh khỏi làm suy yếu khả năng tổng quát hóa (Brunello et al., 2019; Patel et al., 2019).

Để bổ sung quá trình tạo dữ liệu và đồng thời vượt qua nhu cầu về một tập dữ liệu khổng lồ, chúng tôi đề xuất sử dụng LLMs được huấn luyện trước. Chúng tôi sử dụng GPT-3 (Brown et al., 2020) để hỗ trợ tạo tập dữ liệu và tinh chỉnh các mô hình T5 (Raffel et al., 2020) để chuyên môn hóa trong chuyển đổi NL-sang-TL.

Một khía cạnh khác của phương pháp của chúng tôi là sử dụng các phiên bản 'được nâng lên' của NL và TL để tinh chỉnh mô hình của chúng tôi, điều này tăng cường đáng kể khả năng tổng quát hóa. Trong công việc trước đây, các mô hình được huấn luyện trên chuyển đổi NL-sang-TL đầy đủ thường bao gồm việc chuyển đổi các hành động cá nhân cụ thể thành APs. Ví dụ, AP "một phản hồi được tạo trong Slack" có thể được chính thức hóa thành "create_Slack". Kết quả là, mỗi công việc phải điều chỉnh nội dung và phong cách APs của riêng mình, ảnh hưởng đến tổng quát hóa. Thay vì sử dụng phương pháp này, chúng tôi ẩn tất cả các APs trong dữ liệu của chúng tôi trong quá trình tinh chỉnh, có được một mô hình được nâng lên về chuyển đổi NL-sang-TL được nâng lên.

Đối với ứng dụng nền tảng cuối cùng từ NL đầy đủ thành TL đầy đủ, hai phương pháp được đề xuất, hoặc bằng cách kết hợp mô hình được nâng lên với nhận diện AP hoặc học chuyển giao thêm trong một miền cụ thể. Đối với học chuyển giao thêm vào các miền cụ thể, chúng tôi so sánh các mô hình có/không có tiền huấn luyện trên NL-TL được nâng lên và cho thấy tầm quan trọng của nó.

Trong bài báo này, chúng tôi trình bày hai đóng góp chính:

• Xây dựng tập dữ liệu NL-TL xuyên miền. Chúng tôi tạo ra một tập dữ liệu gồm 15K cặp NL-TL được nâng lên sử dụng một khung hỗ trợ GPT-3 mới. Các nghiên cứu loại bỏ được tiến hành để cho thấy tầm quan trọng của mỗi phần của khung để xây dựng tập dữ liệu. Ngoài ra, chúng tôi thu thập và làm sạch các tập dữ liệu trước đây (13K) từ hai miền khác nhau, điều chỉnh các cặp NL-TL đầy đủ ban đầu thành các phiên bản được nâng lên. Theo cách này, chúng tôi công bố một tập dữ liệu gồm 28K cặp NL-TL được nâng lên. Các nghiên cứu loại bỏ cho thấy rằng dữ liệu mới được tạo là không thể thiếu vì việc huấn luyện hoàn toàn trên dữ liệu được thu thập không thành công khi làm việc trên các miền.

• Tinh chỉnh một mô hình NL-sang-TL được nâng lên trên T5 sử dụng dữ liệu của chúng tôi, và chứng minh sự cải thiện trong hiệu suất so với các phương pháp tiên tiến trước đây. Đối với ứng dụng trong chuyển đổi NL-sang-STL đầy đủ, hai phương pháp được đề xuất. Chúng tôi so sánh mô hình của chúng tôi với các mô hình Seq2Seq và học few-shot trực tiếp bằng GPT-3, trên năm miền. Các kết quả thực nghiệm cho thấy rằng các phương pháp của chúng tôi đạt được độ chính xác tốt hơn (>95% trên tất cả các miền) và hiệu quả dữ liệu hơn (<10% dữ liệu cụ thể miền). Chúng tôi cũng thực hiện nghiên cứu loại bỏ bằng cách huấn luyện mô hình Seq2Seq với tập dữ liệu NL-sang-TL được nâng lên, tiết lộ rằng khả năng mô hình vượt trội của T5 là cần thiết.

GPT-4 (Bubeck et al., 2023) xuất hiện khi gần kết thúc công việc này. Để so sánh độ chính xác của dịch đầu cuối few-shot trực tiếp GPT-4 với mô hình được tinh chỉnh của chúng tôi, chúng tôi đã thực hiện một thử nghiệm tức thời trên phiên bản ChatGPT Plus với 100 mẫu trong mỗi miền. Ở đây chúng tôi không thể kiểm tra trên nhiều mẫu hơn vì chúng tôi không có quyền truy cập API GPT-4 và phiên bản ChatGPT Plus có giới hạn truy cập mỗi giờ. Kết quả cho thấy GPT-4 đạt độ chính xác 77.7% trên 300 mẫu, thấp hơn nhiều so với mô hình của chúng tôi nhưng cao hơn GPT-3.

2 Đặc tả Logic Thời gian

2.1 Cú pháp STL

Có nhiều phiên bản khác nhau của TL (Emerson, 1990; Maler và Nickovic, 2004; Koymans, 1990). Chúng ít nhiều tương tự về mặt cú pháp. Chúng tôi sẽ sử dụng Signal Temporal Logic (STL) như một ngôn ngữ chính thức đại diện hỗ trợ các ràng buộc trên thời gian thực liên tục, phù hợp hơn để nắm bắt các nhiệm vụ quan trọng về thời gian. Trong một số công việc trước đây, Linear Temporal Logic (LTL) cũng được sử dụng rộng rãi, được chứa trong STL khi thời gian là rời rạc. Chúng tôi sẽ xây dựng khung của chúng tôi dựa trên STL và cho thấy rằng mô hình được huấn luyện cũng hoạt động tốt trên các tập dữ liệu và nhiệm vụ sử dụng LTL. Một công thức STL được định nghĩa đệ quy theo cú pháp sau:

ϕ::=πµ| ¬ϕ|ϕ∧φ|ϕ∨φ|F[a,b]ϕ|G[a,b]ϕ|ϕU[a,b]φ(1)

trong đó ϕ và φ là các công thức STL, và πµ là một vị từ nguyên tử. ¬(phủ định), ∧(và), ∨(hoặc), ⇒(kéo theo), và ⇔(bằng)) là các toán tử logic. F[a,b](cuối cùng/cuối), G[a,b](luôn luôn/toàn cục), và U[a,b](cho đến) là các toán tử thời gian với ràng buộc thời gian thực t∈[a, b]. Các toán tử thời gian với ràng buộc thời gian được minh họa bởi Bảng 4, và các toán tử khác có thể được trình bày sử dụng cú pháp cơ bản.

2.2 STL được nâng lên và NL được nâng lên

Chúng tôi đại diện cho dữ liệu của chúng tôi như NL và STL 'được nâng lên', trong đó các APs cụ thể tương ứng với các hành động cá nhân được ẩn (theo danh pháp từ Hsiung et al. (2021)). Trong NL và STL được nâng lên của chúng tôi, mỗi AP được thay thế bằng một placeholder prop_i. Theo cách này, chúng tôi huấn luyện mô hình của chúng tôi trên bối cảnh chung của hướng dẫn bất kể các APs cụ thể. Sự tương ứng giữa NL/STL đầy đủ và được nâng lên được hiển thị trong Hình 1.

2.3 Định dạng biểu thức STL

Xem xét một biểu thức STL như một cây nhị phân, như trong Hình 2. Khi tinh chỉnh một mô hình text-to-text, có nhiều cách khác nhau để đại diện cho STL mục tiêu dưới dạng văn bản tuyến tính. Cụ thể, các token mục tiêu có thể được tuyến tính hóa theo cách in-order (cây con trái, gốc, cây con phải) hoặc pre-order (gốc, cây con trái, cây con phải). Trong khi đó, các toán tử cũng có thể được đại diện như các từ với ý nghĩa tương ứng của chúng (thay vì như các ký hiệu). Kết quả huấn luyện cho thấy rằng biểu thức in-order với tất cả các toán tử được thay thế bằng từ đạt được độ chính xác tốt hơn nhiều so với ba hình thức khác (sẽ thảo luận trong Phần 5 sau).

3 Công việc liên quan

Trong nhiều thập kỷ, các nhà nghiên cứu đã có các phương pháp để dịch các câu tiếng Anh thành các công thức TL khác nhau (Brunello et al., 2019; Finucane et al., 2010; Tellex et al., 2020; Raman et al., 2013). Tuy nhiên, để đơn giản hóa các nhiệm vụ, một số công việc trước đây thường đưa ra các giả định mạnh để hạn chế văn bản đầu vào hoặc công thức đầu ra, do đó hạn chế tính linh hoạt và khả năng tổng quát hóa.

Nỗ lực đại diện đầu tiên là của Finucane et al. (2010); Tellex et al. (2011); Howard et al. (2014), trong đó các phương pháp truyền thống thường theo ba bước: 1) tiền xử lý đầu vào tiếng Anh đã cho bằng cách trích xuất thông tin cú pháp, 2) xác định các mẫu hoặc quy tắc cho TL thông qua phân loại, và 3) chạy một parser dựa trên ngữ pháp thuộc tính để rút ra một định dạng logic mục tiêu. Các phương pháp này chỉ hoạt động cho NL đầu vào bị hạn chế (Tellex et al., 2020).

Một loại phương pháp khác là dựa trên học. Các công việc tiên tiến đại diện là Gopalan et al. (2018); Wang et al. (2021); He et al. (2022). Trong Gopalan et al. (2018), các tác giả thu thập một tập dữ liệu tập trung vào Geometric LTL (GLTL), trong đó các ví dụ NL và GLTL đều cho việc điều hướng của một chiếc xe trong phòng. Sau đó các mô hình Seq2Seq với cơ chế attention được huấn luyện. Mặc dù độ chính xác (93.45%) là thỏa đáng, các GLTLs được sử dụng tương đối đơn giản với mỗi GLTL thường bao gồm một đến ba APs và tập dữ liệu cũng tập trung vào một nhiệm vụ bị giới hạn. Trong He et al. (2022), các tác giả chọn đầu tiên dịch một tập các công thức STL được tạo thủ công thành các câu tiếng Anh và huấn luyện một parser ngữ nghĩa trên dữ liệu tổng hợp. Dữ liệu tổng hợp như vậy không thể đại diện cho NL chung và do đó parser được huấn luyện chỉ hoạt động tốt trên các công thức STL ban đầu.

Trong Wang et al. (2021), một parser ngữ nghĩa được xây dựng để học cấu trúc tiềm ẩn của các lệnh NL cho robot mặt đất. Parser sẽ cung cấp (có thể không chính xác) các biểu diễn LTL trung gian cho một trình lập kế hoạch chuyển động, và trình lập kế hoạch sẽ đưa ra một quỹ đạo được thực thi như phản hồi để xem liệu việc thực thi của robot có thỏa mãn đầu vào tiếng Anh hay không. Phương pháp như vậy không có bảo đảm về tính chính xác của TL được dịch. Trong những tháng gần đây, công việc của Fuggitti và Chakraborti (2023) trực tiếp áp dụng LLMs như GPT-3 để chuyển đổi NL sang LTL thông qua học few-shot. Các prompts phải được thiết kế tốt và mô hình sẽ thất bại khi cấu trúc NL và LTL quá phức tạp (chúng tôi sẽ thảo luận trong Phần 7.1).

Do đó, trong lĩnh vực dịch NL-sang-TL, tăng cường/tổng hợp dữ liệu đã được thực hiện theo thuật toán trong công việc trước đây, không sử dụng các mô hình sinh. Điều này hạn chế mức độ tự nhiên của 'NL' kết quả thực sự. Trong những năm gần đây, bắt đầu từ cơ chế attention (Vaswani et al., 2017), sự tiến bộ nhanh chóng của LLMs được huấn luyện trước trong NLP có xu hướng thống nhất nhiều nhiệm vụ trước đây có vẻ độc lập thành một mô hình được huấn luyện trước lớn, đặc biệt là dòng GPT từ OpenAI (Brown et al., 2020), và T5 (Raffel et al., 2020) và PaLM (Chowdhery et al., 2022) từ Google. Các mô hình này được huấn luyện trước với một lượng lớn các câu tự nhiên và mã, mã hóa nội tại nhiều kiến thức thế giới (Creswell et al., 2022). Các LLMs auto-regressive có thể tự nhiên tạo ra corpus phong phú và có ý nghĩa dựa trên prompt đã cho. Sau đó nhiều công việc gần đây đề xuất thực hiện tăng cường dữ liệu với LLMs, như tạo ra các cuộc đối thoại y tế (Chintagunta et al., 2021) và mã python (Chen et al., 2021) thông qua GPT-3. Điều này truyền cảm hứng cho chúng tôi về cơ hội mới trong nhiệm vụ NL-sang-TL.

4 Phương pháp

Có 3 bước trong phương pháp của chúng tôi. Đầu tiên, tạo ra tập dữ liệu NL-STL được nâng lên với LLMs. Thứ hai, tinh chỉnh LLMs để có được độ chính xác cao trên chuyển đổi NL-STL được nâng lên. Thứ ba, nâng dữ liệu và áp dụng mô hình được nâng lên. Cuối cùng, chúng tôi cũng xem xét trường hợp mà việc nâng lên không thể thực hiện được và chúng tôi phải dịch đầu cuối bằng cách tinh chỉnh thêm mô hình.

4.1 Tạo dữ liệu

Chúng tôi áp dụng LLM GPT-3 (Davinci-003) để giúp tạo ra nhiều cặp NL và STL được nâng lên. Phương pháp trực quan đầu tiên là sử dụng các cặp NL-STL khác nhau làm prompts và yêu cầu GPT-3 tự động tạo ra nhiều cặp NL-STL hơn. Tuy nhiên, hóa ra mô hình luôn tạo ra STL và NL với các cấu trúc cú pháp tương tự như các prompts đã cho, do đó hạn chế độ phong phú của câu. Để kích thích GPT-3 tạo ra các câu với nhiều biến thể hơn, chúng tôi yêu cầu nó tạo ra các NLs tương ứng từ các STLs khác nhau. Toàn bộ khung (được gọi là Framework1) được hiển thị trong Hình 3. Các STLs pre-order khác nhau được tổng hợp ngẫu nhiên bằng thuật toán tạo cây nhị phân (Xem Thuật toán 1 và thảo luận cụ thể trong Phụ lục B). Các STLs pre-order sau đó được chuyển đổi thành biểu thức in-order thông qua các quy tắc. Để làm cho STL đầu vào dễ hiểu hơn đối với GPT-3, các toán tử được đại diện bằng các từ có ý nghĩa của chúng (⇒(kéo theo), ⇔(bằng), ∨(hoặc), v.v.).

Sau đó GPT-3 sẽ cố gắng tạo ra NL thô có ý nghĩa ngữ nghĩa gần với STL. Các người chú thích sau đó sửa đổi NL thô để làm cho ý nghĩa của nó nhất quán với STL. Trong quá trình này, các cặp NL-STL trong prompts sẽ được chọn ngẫu nhiên để làm cho từ vựng và cấu trúc câu đa dạng hơn. Chúng tôi thu thập 200 hướng dẫn NL từ 10 tình nguyện viên quen thuộc với các nhiệm vụ robot và chọn ngẫu nhiên 100 NL để phục vụ như pool prompt, trong khi 100 NL khác phục vụ như dữ liệu thử nghiệm Thủ công. Trong mỗi lần lặp của Framework1, 20 cặp được chọn ngẫu nhiên từ pool prompt để tạo thành prompt của GPT-3 (một ví dụ prompt được hiển thị trong Phụ lục C.1 và thảo luận về bao nhiêu ví dụ nên được bao gồm trong prompt GPT-3 được hiển thị trong Phụ lục D).

Trong khi Framework1 tăng cường độ phong phú của câu, một vấn đề là việc tổng hợp STL dựa trên quy tắc thuần túy đôi khi tạo ra ý nghĩa ngữ nghĩa không hợp lý, hoặc STL quá phức tạp để mô tả nó bằng NL. Để giải quyết vấn đề này, một khung được tối ưu hóa (được gọi là Framework2) được hiển thị trong Hình 4. So với Framework1, một vòng lặp thêm giữa STL và NL được thêm vào sử dụng GPT-3. Theo cách này, STL dựa trên quy tắc ban đầu với ý nghĩa không hợp lý hoặc phức tạp sẽ được tự động lọc bởi chính GPT-3. Nói cách khác, trong quá trình ánh xạ từ STL-1 sang NL-1, GPT-3 ít nhiều sửa đổi ý nghĩa của các STLs mà nó không thể dịch đầy đủ. Sau đó NL-1 được dịch, mặc dù không hoàn toàn nhất quán với STL-1, nhưng hợp lý hơn trong quan điểm của con người. Hóa ra các ý nghĩa ngữ nghĩa được tổng hợp bởi Framework2 gần với ngôn ngữ con người chung hơn, và các cặp NL-STL chứa ít lỗi hơn nhiều để chú thích. Số lượng cặp được chú thích trung bình là khoảng 80 mỗi người mỗi giờ với Framework1, và khoảng 120 mỗi người mỗi giờ với Framework2.

Chúng tôi tổng cộng tạo ra 15108 cặp NL-STL được nâng lên kết hợp cả Framework1 và Framework2, với tổng chi phí khoảng 150 giờ người. Phụ lục C.2 hiển thị một ví dụ prompt để chuyển đổi từ NL-1 trở lại thành STL-2 thông qua GPT-3, và Phụ lục E hiển thị một số ví dụ chú thích của các cặp NL-STL được nâng lên. Phụ lục F giải thích toàn bộ quá trình và giấy phép chú thích của con người để sửa các cặp NL-STL.

Ngoài việc tổng hợp và chú thích các cặp NL-STL được nâng lên với GPT-3, chúng tôi cũng thu thập và chú thích dữ liệu được thu thập từ Wang et al. (2021) và He et al. (2022). Wang et al. (2021) tập trung vào nhiệm vụ điều hướng robot với LTL, và He et al. (2022) tập trung vào điều khiển mạch với STL. Để làm sạch và xử lý dữ liệu thành các cặp NL-STL được nâng lên, các APs trong cả hai tập dữ liệu được phát hiện và ẩn bằng cách kết hợp các thuật toán hard-coded với gói nhận diện thực thể SpaCy (Honnibal và Montani, 2017). Chúng tôi thu thập 5K cặp NL-STL được nâng lên từ tập dữ liệu Navigation (Wang et al., 2021) và 8K cặp NL-STL được nâng lên từ tập dữ liệu Circuit (He et al., 2022). Lưu ý rằng tập dữ liệu Navigation ban đầu sử dụng LTL, trong khi chúng tôi sửa một số định dạng biểu thức để tạo thành STL. Tập dữ liệu Circuit ban đầu chứa 120K cặp NL-STL, trong khi chúng tôi thấy rằng việc bao gồm 8K ví dụ vào tập dữ liệu của chúng tôi đủ thông tin để bao phủ toàn bộ độ phong phú corpus của tập dữ liệu Circuit.

Do đó, trong công việc này, một tập dữ liệu với tổng cộng khoảng 28K cặp NL-STL được nâng lên được tạo ra. Phụ lục J.1 hiển thị thống kê của tập dữ liệu NL-STL được nâng lên này.

4.2 Tinh chỉnh mô hình

Chúng tôi chủ yếu áp dụng mô hình T5 (Raffel et al., 2020) để phục vụ như LLM cơ sở cho tinh chỉnh. Để nghiên cứu liệu kích thước mô hình có ảnh hưởng đến hiệu suất hay không, cả T5-base (220M) và T5-large (770M) đều được tinh chỉnh trên cùng dữ liệu. Cài đặt được minh họa trong Phụ lục L.

5 Kết quả thực nghiệm

Mặc dù dữ liệu được sửa từ các nghiên cứu Navigation và Circuit đã cung cấp nhiều ví dụ, các tập dữ liệu này chỉ bao phủ các điều kiện hạn chế và thiếu tổng quát hóa. Để cho thấy sự cần thiết của dữ liệu mới được tạo, các mô hình T5 được tinh chỉnh với số lượng cặp NL-STL được tạo khác nhau, như được hiển thị trong Hình 5. Trong quá trình huấn luyện, tất cả dữ liệu được thu thập từ các nghiên cứu Navigation và Circuit đều được sử dụng và số lượng dữ liệu được tạo khác nhau giữa các mô hình khác nhau. Các mô hình được huấn luyện sau đó được kiểm tra với dữ liệu được tạo (được gọi là thử nghiệm dữ liệu hỗ trợ GPT-3) hoặc hướng dẫn NL được thu thập từ tình nguyện viên (được gọi là thử nghiệm dữ liệu Thủ công). Vì sự khác biệt nhỏ trong STLs có thể gây ra sự khác biệt nghiêm trọng trong ý nghĩa thực, chúng tôi áp dụng độ chính xác nhị phân làm thước đo, tức là 100% đúng hoặc không. Chúng tôi thấy rằng độ chính xác thử nghiệm Top-1 tăng đáng kể khi tăng số lượng cặp được tạo, với độ chính xác cao nhất 97.52% và 90.12% của thử nghiệm dữ liệu hỗ trợ GPT-3 và dữ liệu Thủ công, tương ứng.

Bảng 1 trình bày các kết quả thực nghiệm với STL mục tiêu của các định dạng khác nhau như đã thảo luận trong Phần 2.3. Chúng tôi thấy rằng việc sử dụng định dạng in-order cộng với việc thay thế các toán tử bằng từ sẽ cải thiện đáng kể hiệu suất. Định dạng in-order nhất quán hơn với các biểu thức câu tự nhiên và giảm độ khó cho việc tinh chỉnh một LLM. Kết quả này khác với các kết luận trước đây khi huấn luyện mô hình Seq2Seq cho các nhiệm vụ NL sang STL/LTL, trong đó định dạng pre-order tốt hơn vì nó tự nhiên tránh vấn đề khớp dấu ngoặc (Wang et al., 2021).

6 Nghiên cứu loại bỏ

Chú thích của con người Để tiết lộ tầm quan trọng của chú thích con người, chúng tôi huấn luyện mô hình với cùng số lượng cặp thô được tạo bởi GPT-3 và kiểm tra chúng trên dữ liệu được sửa. Kết quả được hiển thị trong Phụ lục H.1. Chúng tôi thấy rằng tập dữ liệu được chú thích có thể cải thiện độ chính xác thử nghiệm khoảng 10%.

Framework2 Để tiết lộ tầm quan trọng của dữ liệu được tạo bởi Framework2, chúng tôi huấn luyện mô hình với hoặc cùng số lượng dữ liệu từ Framework1 thuần túy hoặc dữ liệu kết hợp hai khung. Việc sử dụng cả hai khung cải thiện độ chính xác khoảng 2% (Phụ lục H.2).

Khả năng mô hình của T5 Để tiết lộ tầm quan trọng của khả năng mô hình vượt trội của T5, chúng tôi huấn luyện một mô hình Seq2Seq trên cùng tập dữ liệu NL-STL được nâng lên để so sánh, như được hiển thị trong Phụ lục I. Tinh chỉnh trên mô hình T5 cải thiện độ chính xác khoảng 14.5% so với mô hình Seq2Seq.

7 Ứng dụng

Bây giờ chúng tôi có mô hình T5 được tinh chỉnh để chuyển đổi NL được nâng lên thành STL được nâng lên. Đối với các ứng dụng thực tế, chúng tôi cần một mô hình để chuyển đổi từ NL đầy đủ sang STL đầy đủ, trong đó định dạng của APs nên được điều chỉnh. Để đạt được đích này, chúng tôi sẽ hiển thị hai phương pháp trong thảo luận sau, và so sánh chúng với các mô hình tiên tiến khác. Chúng tôi kiểm tra trên năm tập dữ liệu trên các miền Circuit (He et al., 2022), Navigation (Wang et al., 2021), Office email (Fuggitti và Chakraborti, 2023), GLTL (Gopalan et al., 2018; Tellex et al., 2020), và CW (Squire et al., 2015). Các ví dụ của các cặp NL-STL đầy đủ trong mỗi miền được hiển thị trong Phụ lục G, và thống kê của tập dữ liệu được tổng hợp của chúng tôi và mỗi tập dữ liệu được thu thập được hiển thị trong Phụ lục J.2. Lưu ý rằng một số cặp NL-STL được nâng lên trong các tập dữ liệu Circuit và Navigation đã được sử dụng trong quá trình huấn luyện mô hình được nâng lên, trong khi tất cả các cặp NL-STL đầy đủ chưa được thấy. Tất cả dữ liệu trong ba miền khác đều độc lập với việc tinh chỉnh trong các mô hình được nâng lên. Mô hình của chúng tôi đạt được độ chính xác cao hơn trên chuyển đổi NL-STL đầy đủ với ít dữ liệu huấn luyện hơn nhiều trên tất cả các miền này.

7.1 Mô hình được nâng lên + Nhận diện AP GPT-3

Trong các ứng dụng thực tế, chúng ta phải công thức hóa cách các APs được trình bày trong STL (như 'verb_noun') để các APs được chỉ định có thể kết nối trực tiếp với các bộ điều khiển. Như được hiển thị trong Phụ lục M, chúng tôi trực tiếp sử dụng GPT-3 để nhận diện APs trong câu và ẩn chúng như "prop_i". Sau đó mô hình được nâng lên sẽ dự đoán STL được nâng lên mục tiêu và các APs ẩn sẽ được hoán đổi thành dạng được định dạng để tạo ra STL đầy đủ.

Bảng 2 hiển thị độ chính xác hiệu suất của phương pháp này. Chúng tôi kiểm tra trên ba miền riêng biệt và so sánh với phương pháp đầu cuối GPT-3, tức là sử dụng GPT-3 để trực tiếp chuyển đổi NL thành STL. Phương pháp đầu cuối GPT-3 được đề xuất bởi Fuggitti và Chakraborti (2023) gần đây, nhằm tổng quát hóa vào tất cả các miền khác nhau. Tuy nhiên, trong nhiệm vụ NL sang STL/LTL, tinh chỉnh trên một LLM nhỏ hơn nhiều như T5 vẫn tốt hơn đáng kể so với học few-shot trực tiếp trên LLM tiên tiến như GPT-3 và GPT-4. Do hạn chế truy cập GPT-4, chúng tôi đã thực hiện một thử nghiệm tức thời trên ChatGPT Plus với 100 mẫu trong mỗi miền. Các kết quả thực nghiệm cho thấy rằng việc kết hợp mô hình được nâng lên được tinh chỉnh với nhận diện AP sử dụng GPT-3 có thể dẫn đến độ chính xác nhiệm vụ đầy đủ trên 95% trên tất cả ba miền được kiểm tra. Bảng 3 hiển thị hiệu suất phát hiện APs với GPT-3. So với nhiệm vụ NL sang STL trực tiếp, nhiệm vụ phát hiện AP dễ hơn nhiều đối với GPT-3. Do đó, việc chia toàn bộ nhiệm vụ thành nhận diện AP và phân tích ngữ nghĩa hiệu quả dữ liệu hơn và linh hoạt hơn so với phương pháp đầu cuối thuần túy.

Để kiểm tra thêm hiệu suất mô hình dưới độ phức tạp câu khác nhau, chúng tôi vẽ đồ thị độ chính xác thử nghiệm so với số lượng APs trong Phụ lục K. Khi số lượng APs trong mỗi STL được nâng lên tăng, độ chính xác của học few-shot GPT-3 giảm, trong khi mô hình T5-large được tinh chỉnh vẫn hoạt động tốt.

7.2 Học chuyển giao

Trong điều kiện mà chúng ta biết cách người dùng định nghĩa biểu diễn của APs, phương pháp đã nêu ở trên phù hợp để dự đoán STL đầy đủ. Mặt khác, cũng có điều kiện mà chúng ta không thể có được các quy tắc hard-coded cụ thể để công thức hóa biểu diễn AP, mà chỉ có các cặp NL-STL đầy đủ. Trong những trường hợp này, việc tinh chỉnh thêm trực tiếp có thể giúp ích. Nói cách khác, mô hình được nâng lên đã học cách phân tích các mối quan hệ logic ngữ nghĩa, và việc học chuyển giao thêm là để học cách các APs được điều chỉnh trong tập dữ liệu cụ thể này. Việc học chuyển giao đầu cuối trực tiếp này phục vụ như cách thứ hai cho các ứng dụng nền tảng.

Để cho thấy rằng phương pháp của chúng tôi có thể tổng quát hóa và hiệu quả dữ liệu, chúng tôi so sánh các phương pháp của chúng tôi với các phương pháp Seq2Seq ban đầu được thực hiện trong mỗi tập dữ liệu. Cụ thể, trong tập dữ liệu Circuit, các tác giả huấn luyện mô hình từ nền tảng sử dụng kiến trúc Transformer (Vaswani et al., 2017), và trong các tập dữ liệu GLTL và CW, các tác giả thực hiện khung encoder-decoder mạng nơ-ron hồi quy (RNN) với Gated Recurrent Unit (GRU) như cell RNN cốt lõi. Vì công việc trên tập dữ liệu Navigation sử dụng tỷ lệ hoàn thành nhiệm vụ cuối cùng làm tiêu chí chứ không phải độ chính xác LTL trực tiếp, độ chính xác dự đoán LTL vốn thấp. Để so sánh công bằng trong tập dữ liệu Navigation, chúng tôi thực hiện cùng khung Seq2Seq như trong các tập dữ liệu GLTL và CW.

Các kết quả thực nghiệm được hiển thị trong Hình 6. So với mô hình Seq2Seq ban đầu được đề xuất trong mỗi tập dữ liệu, học chuyển giao với LLM hiệu quả hơn nhiều, và việc tiền huấn luyện trên các cặp NL-STL được nâng lên cũng hiển thị một sự tiết kiệm lớn về yêu cầu dữ liệu huấn luyện. Chúng tôi cũng thấy rằng mô hình T5-large hoạt động tốt hơn mô hình T5-base. Trong tất cả ba miền, mô hình T5-large với tiền huấn luyện NL-STL được nâng lên có thể đạt được độ chính xác gần 95% chỉ với 200 đến 500 ví dụ NL-STL đầy đủ. Số lượng yêu cầu ví dụ này ít hơn một bậc độ lớn so với các baseline Seq2Seq.

Tập dữ liệu CW hơi độc đáo vì nó chỉ có 36 LTLs khác nhau, có nghĩa là trung bình có 50 NLs khác nhau tương ứng với cùng một LTL. Nghiên cứu trong Gopalan et al. (2018) áp dụng tập dữ liệu này để kiểm tra khả năng tổng quát hóa của các mô hình trong miền. Họ sử dụng một số loại LTLs như các ví dụ huấn luyện cho học chuyển giao, và các loại LTLs còn lại như tập kiểm tra. Điều này để kiểm tra liệu mô hình có thể dự đoán các LTLs mà nó chưa thấy trong quá trình huấn luyện hay không. Chúng tôi cũng thực hiện thí nghiệm này và so sánh với phương pháp trong bài báo gốc. Như được hiển thị trong Hình 7, LLM với tinh chỉnh rõ ràng tốt hơn baseline ban đầu.

8 Hạn chế

Trong ngôn ngữ nói, coreference khá phổ biến, chẳng hạn như "nhặt quả táo và sau đó mang nó đến cho tôi". Ở đây "táo" và "nó" đề cập đến cùng một đối tượng. Trong năm tập dữ liệu chúng tôi thu thập và kiểm tra, vấn đề coreference không nghiêm trọng vì hầu hết NL không có đại từ. Đối với công việc tiếp theo, các mô hình NER chuyên môn trong việc giải quyết coreferences và chuyển đổi chúng thành APs bình thường là cần thiết cho các câu đầu vào không bị ràng buộc hơn.

Trong quá trình tổng hợp các STLs khác nhau, ở đây chúng tôi sử dụng phương pháp trực tiếp dựa trên thuật toán để tạo ra cây nhị phân STL. Để làm cho ý nghĩa ngữ nghĩa của STLs gần với ngôn ngữ nói của con người hơn, chúng tôi thêm vòng lặp NL-STL thêm thông qua GPT-3. Tuy nhiên, một cách trực quan khác là khớp phân phối có thể của các toán tử gần với ngôn ngữ nói của con người. Ví dụ, xác suất của hai toán tử 'phủ định' liên tiếp gần như bằng không. Trong công việc này, chúng tôi chỉ đặt một số quy tắc cứng để chỉ định tổng hợp STL. Công việc tiếp theo có thể tập trung vào việc khớp phân phối toán tử và áp dụng nó vào tạo STL.

Thước đo đánh giá ở đây là độ chính xác nhị phân thuần túy (hoàn toàn chính xác hoặc không). Thực tế, rất khó để đánh giá sự tương tự hoặc khoảng cách của hai TLs. Việc đơn giản tính toán khớp token hoặc tính toán giá trị chân lý đều có nhược điểm. Một thước đo hiệu quả hơn là cần thiết.

Đầu ra của LLMs đôi khi có thể tạo ra TLs không chính xác. Chúng tôi xây dựng các phương pháp dựa trên quy tắc để kiểm tra tính chính xác cú pháp và sửa các lỗi như khớp dấu ngoặc. Công việc tiếp theo có thể được thêm vào để cải thiện tính chính xác đầu ra bằng cách sửa đổi các thủ tục huấn luyện và hàm mất mát.

9 Kết luận

Chúng tôi đề xuất một khung để đạt được chuyển đổi NL-sang-TL với sự hỗ trợ của LLM, từ các khía cạnh của cả tạo dữ liệu và huấn luyện mô hình. Một tập dữ liệu với khoảng 28K cặp NL-TL được nâng lên sau đó được xây dựng mà mô hình T5 được tinh chỉnh bởi. Hai phương pháp được thực hiện để sử dụng mô hình được huấn luyện vào dịch NL-sang-TL đầy đủ. Các kết quả thực nghiệm trên năm miền khác nhau hiển thị độ chính xác và khả năng tổng quát hóa tốt hơn nhiều so với các phương pháp ban đầu. Tập dữ liệu được tạo có thể được sử dụng để huấn luyện các mô hình NL-sang-TL tương lai và phục vụ như benchmark. Khung được đề xuất để tinh chỉnh LLMs với các cặp NL-TL được nâng lên làm cho việc dịch NL-sang-TL có thể tổng quát hóa mà không bị ràng buộc bởi các miền và cấu trúc hướng dẫn đầu vào trở nên khả thi.

Mặc dù khung của chúng tôi được xây dựng trên GPT-3, sự tiến bộ nhanh chóng của LLMs có thể thúc đẩy khung của chúng tôi. Khả năng phân tích ngữ nghĩa mạnh mẽ của GPT-4 mới được phát hành sẽ giảm bớt gánh nặng chú thích của con người trong phương pháp của chúng tôi. Chúng tôi thấy rằng các STLs/NLs được tạo bởi GPT-4 gần với các câu trả lời chính xác hơn, so với các STLs/NLs được tạo bởi GPT-3. Như công việc tương lai, chúng tôi tin rằng mô hình có thể được cải thiện với tập dữ liệu lớn hơn chứa corpus đa dạng hơn với GPT-4 làm mô hình cơ sở.

Lời cảm ơn

Chúng tôi cảm ơn sự giúp đỡ từ các tình nguyện viên đã đóng góp các hướng dẫn ngôn ngữ tự nhiên.

Công việc này được hỗ trợ bởi ONR dưới Giải thưởng N00014-22-1-2478 và MIT-IBM Watson AI Lab. Tuy nhiên, bài viết này chỉ phản ánh ý kiến và kết luận của các tác giả. Các tác giả cũng muốn cảm ơn Lifu Huang, Zhiyang Xu, và Yue Meng cho việc khám phá và thảo luận giai đoạn đầu của công việc.

Tài liệu tham khảo

Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, Daniel Ho, Jasmine Hsu, Julian Ibarz, Brian Ichter, Alex Irpan, Eric Jang, Rosario Jauregui Ruano, Kyle Jeffrey, Sally Jesmonth, Nikhil Joshi, Ryan Julian, Dmitry Kalashnikov, Yuheng Kuang, Kuang-Huei Lee, Sergey Levine, Yao Lu, Linda Luu, Carolina Parada, Peter Pastor, Jornell Quiambao, Kanishka Rao, Jarek Rettinghouse, Diego Reyes, Pierre Sermanet, Nicolas Sievers, Clayton Tan, Alexander Toshev, Vincent Vanhoucke, Fei Xia, Ted Xiao, Peng Xu, Sichun Xu, Mengyuan Yan, và Andy Zeng. 2022. Do as i can and not as i say: Grounding language in robotic affordances. In arXiv preprint arXiv:2204.01691.

Adrian Boteanu, Thomas Howard, Jacob Arkin, và Hadas Kress-Gazit. 2016. A model for verifiable grounding and execution of complex natural language instructions. In 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), trang 2649–2654. IEEE.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901.

Michael C. Browne, Edmund M. Clarke, David L. Dill, và Bud Mishra. 1986. Automatic verification of sequential circuits using temporal logic. IEEE Transactions on Computers, 35(12):1035–1044.

Andrea Brunello, Angelo Montanari, và Mark Reynolds. 2019. Synthesis of ltl formulas from natural language texts: State of the art and research directions. In 26th International Symposium on Temporal Representation and Reasoning (TIME 2019). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik.

Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. 2023. Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712.

Igor Buzhinsky. 2019. Formalization of natural language requirements into temporal logics: a survey.

Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374.

Bharath Chintagunta, Namit Katariya, Xavier Amatriain, và Anitha Kannan. 2021. Medically aware gpt-3 as a data generator for medical dialogue summarization. In Machine Learning for Healthcare Conference, trang 354–372. PMLR.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311.

Antonia Creswell, Murray Shanahan, và Irina Higgins. 2022. Selection-inference: Exploiting large language models for interpretable logical reasoning. arXiv preprint arXiv:2205.09712.

E Allen Emerson. 1990. Temporal and modal logic. In Formal Models and Semantics, trang 995–1072. Elsevier.

Cameron Finucane, Gangyuan Jing, và Hadas Kress-Gazit. 2010. Ltlmop: Experimenting with language, temporal logic and robot control. In 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems, trang 1988–1993. IEEE.

Francesco Fuggitti và Tathagata Chakraborti. 2023. NL2LTL – a python package for converting natural language (NL) instructions to linear temporal logic (LTL) formulas. In AAAI. System Demonstration.

Nakul Gopalan, Dilip Arumugam, Lawson LS Wong, và Stefanie Tellex. 2018. Sequence-to-sequence language grounding of non-markovian task specifications. In Robotics: Science and Systems, volume 2018.

David Gundana và Hadas Kress-Gazit. 2022. Event-based signal temporal logic tasks: Execution and feedback in complex environments. IEEE Robotics and Automation Letters, 7(4):10001–10008.

Jie He, Ezio Bartocci, Dejan Ni ˇckovi ´c, Haris Isakovic, và Radu Grosu. 2022. Deepstl: from english requirements to signal temporal logic. In Proceedings of the 44th International Conference on Software Engineering, trang 610–622.

Matthew Honnibal và Ines Montani. 2017. spacy 2: Natural language understanding with bloom embeddings, convolutional neural networks and incremental parsing. To appear, 7(1):411–420.

Thomas M Howard, Stefanie Tellex, và Nicholas Roy. 2014. A natural language planner interface for mobile manipulators. In 2014 IEEE International Conference on Robotics and Automation (ICRA), trang 6652–6659. IEEE.

Eric Hsiung, Hiloni Mehta, Junchi Chu, Xinyu Liu, Roma Patel, Stefanie Tellex, và George Konidaris. 2021. Generalizing to new domains by mapping natural language to lifted ltl. arXiv preprint arXiv:2110.05603.

Ron Koymans. 1990. Specifying real-time properties with metric temporal logic. Real-time systems, 2(4):255–299.

Sebastian Maierhofer, Anna-Katharina Rettinger, Eva Charlotte Mayer, và Matthias Althoff. 2020. Formalization of interstate traffic rules in temporal logic. In 2020 IEEE Intelligent Vehicles Symposium (IV), trang 752–759.

Oded Maler và Dejan Nickovic. 2004. Monitoring temporal properties of continuous signals. In Formal Techniques, Modelling and Analysis of Timed and Fault-Tolerant Systems, trang 152–166. Springer.

Roma Patel, Ellie Pavlick, và Stefanie Tellex. 2019. Learning to ground language to temporal logical form. In NAACL.

Roma Patel, Ellie Pavlick, và Stefanie Tellex. 2020. Grounding language to non-markovian tasks with no supervision of task specifications. In Robotics: Science and Systems.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, et al. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 21(140):1–67.

Vasumathi Raman, Constantine Lignos, Cameron Finucane, Kenton CT Lee, Mitchell P Marcus, và Hadas Kress-Gazit. 2013. Sorry dave, i'm afraid i can't do that: Explaining unachievable robot tasks using natural language. In Robotics: science and systems, volume 2, trang 2–1. Citeseer.

Shawn Squire, Stefanie Tellex, Dilip Arumugam, và Lei Yang. 2015. Grounding english commands to reward functions. In Robotics: Science and Systems.

Stefanie Tellex, Nakul Gopalan, Hadas Kress-Gazit, và Cynthia Matuszek. 2020. Robots that use language. Annual Review of Control, Robotics, and Autonomous Systems, 3(1).

Stefanie Tellex, Thomas Kollar, Steven Dickerson, Matthew R Walter, Ashis Gopal Banerjee, Seth Teller, và Nicholas Roy. 2011. Approaching the symbol grounding problem with probabilistic graphical models. AI magazine, 32(4):64–76.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, và Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems, 30.

Christopher Wang, Candace Ross, Yen-Ling Kuo, Boris Katz, và Andrei Barbu. 2021. Learning a natural-language to ltl executable semantic parser for grounded robotics. In Conference on Robot Learning, trang 1706–1718. PMLR.

A Minh họa STL

F[a,b]ϕ Đúng tại thời điểm t nếu tồn tại một thời điểm trong khoảng [t+a, t+b] trong đó ϕ là đúng.
ϕU[a,b]φ Đúng tại thời điểm t nếu φ đúng cho một thời điểm t′ nào đó trong khoảng [t+a, t+b], và cho tất cả thời điểm giữa t và t′, công thức ϕ giữ.
G[a,b]ϕ Đúng tại thời điểm t nếu cho tất cả thời điểm trong khoảng [t+a, t+b], công thức ϕ giữ.

Bảng 4: Minh họa STL

B Thuật toán đầy đủ để tổng hợp nhiều STLs

Đây là thuật toán đầy đủ để tổng hợp nhiều STLs khác nhau. Các từ có màu xanh là đầu ra ví dụ trong mỗi bước. Tất cả các toán tử được phân loại thành toán tử chỉ có một cây con, hoặc toán tử có hai cây con. Một danh sách prop được sắp xếp ngẫu nhiên được tạo với độ dài nhỏ hơn giới hạn trên. Sau đó danh sách đầy đủ này được chia thành một số sub_lists. Đối với mỗi sub_list, các toán tử được thêm ngẫu nhiên ở phía bên trái cho đến khi mỗi prop chiếm một vị trí trong cây nhị phân. Sau đó các sub_lists được sửa đổi này được lắp ráp trở lại thành STL đầy đủ bằng cách thêm các toán tử có hai cây con. STL được tạo theo cách này đúng về mặt cú pháp, nhưng có thể có một số lỗ hổng trong ý nghĩa ngữ nghĩa. Một số quy tắc được đặt trước để tránh các điều kiện không hợp lý, ví dụ, hai phép toán phủ định không nên xuất hiện liên tục.

Thuật toán 2 Thuật toán đầy đủ cho tổng hợp STL
Đầu vào:
1: Số lượng APs tối đa N
Đầu ra:
2: STL pre-order được tổng hợp
3:
4: two_subtree = [∧,∨,⇒,⇔,U,U[a,b]],
5: one_subtree = [¬,F,G,F[a,b],G[a,b]]
6: AP_num = random.randint(1, N) ▷ ví dụ, 3
7: prop_list ← Danh sách Prop được sắp xếp ngẫu nhiên với độ dài AP_num
8: sub_lists ← chia ngẫu nhiên prop_list ▷ ví dụ, [prop_3, prop_1], [prop_2]
9:
10: Tạo sub-STLs:
11: foreach sub_list do
12: num_open_subtree = len(sub_list)
13: while num_open_subtree > 1 do
14: operation ← chọn ngẫu nhiên item trong two_subtree + one_subtree
15: if operation trong two_subtree then
16: num_open_subtree -= 1
17: end if
18: if operation trong [U[a,b],F[a,b],G[a,b]] then
19: a, b ← lấy mẫu số nguyên ngẫu nhiên hoặc ký hiệu như vô cực
20: end if
21: sub_list.insert(0, operation)
22: end while
23: lưu sub_list như sub_STL ▷ ví dụ, [⇔,¬, prop_3, prop_1], [G, prop_2]
24: end for
25:
26: Lắp ráp sub-STLs:
27: Lắp ráp sub_STLs thành STL pre-order bằng cách thêm các phép toán two_subtree ngẫu nhiên ▷ ví dụ, [U[10,30],⇔,¬, prop_3, prop_1, G, prop_2]

C Ví dụ về đầu vào prompt cho GPT-3

Đây là các prompt ví dụ cho GPT-3 để chuyển đổi giữa NL và STL, hoặc phát hiện các khoảng của Tỷ lệ Nguyên tử.

C.1 Ví dụ prompt từ STL in-order sang NL thông qua GPT-3

Hình 8 là một ví dụ prompt cho GPT-3 để chuyển đổi từ STL sang NL tương ứng. STL đầu vào theo biểu thức in-order với tất cả các toán tử được thay thế bằng từ có cùng ý nghĩa. Prompt chứa 20 cặp NL-STL, được chọn ngẫu nhiên từ 100 ví dụ và được thay đổi liên tục trong quá trình tạo dữ liệu.

C.2 Ví dụ prompt từ NL sang STL pre-order thông qua GPT-3

Hình 9 là một ví dụ prompt cho GPT-3 để chuyển đổi từ NL sang STL tương ứng. STL đầu ra theo biểu thức pre-order. Chúng tôi đã kiểm tra rằng GPT-3 hoạt động với hiệu suất gần nhau khi STL theo định dạng pre-order hoặc in-order.

C.3 Ví dụ prompt cho nhận diện AP thông qua GPT-3

Hình 10 là một ví dụ prompt để áp dụng GPT-3 phát hiện APs trong các câu tự nhiên. Trong ví dụ này, miền cụ thể là Navigation.

D Số lượng cặp NL-STL trong prompts GPT-3

Như được hiển thị trong Hình 11, ở đây chúng tôi yêu cầu GPT-3 chuyển đổi từ NL sang STL và điều chỉnh số lượng cặp NL-STL trong prompt để phát hiện sự tiến hóa độ chính xác. Chúng tôi kiểm tra trên NL có STL mục tiêu có số lượng APs là hai hoặc ba. Chúng tôi thấy rằng độ chính xác dự đoán được đưa ra bởi GPT-3 sẽ tăng với số lượng cặp ví dụ và chuyển thành một plateau khi số lượng cặp ví dụ tăng lên lớn hơn 20. Ở đây chúng tôi chọn số lượng cặp là 20 trong prompt.

E Ví dụ chú thích của các cặp NL-STL được nâng lên

Như được hiển thị trong Bảng 5.

STL (pre-order+operator) ['<->', '->', 'prop_2', 'prop_3', 'F[55,273]', 'prop_1']
STL (in-order+word) ((prop_2 imply prop_3) equal finally[55,273] prop_1)
Câu tự nhiên thô Nếu (prop_2) kéo theo (prop_3), thì (prop_1) sẽ xảy ra tại một thời điểm nào đó trong 55 đến 273 đơn vị thời gian tiếp theo.
Câu tự nhiên được chú thích Nếu (prop_2) kéo theo (prop_3), thì (prop_1) sẽ xảy ra tại một thời điểm nào đó trong 55 đến 273 đơn vị thời gian tiếp theo, và ngược lại.

STL (pre-order+operator) ['U[400,infinite]', '->', 'prop_3', 'prop_1', 'negation', 'prop_2']
STL (in-order+word) ((prop_3 imply prop_1) until[400,infinite] negation prop_2)
Câu tự nhiên thô Nếu (prop_3), thì làm (prop_1) và tiếp tục làm nó cho đến khi (prop_2) xảy ra, nhưng điều này không bao giờ nên xảy ra.
Câu tự nhiên được chú thích Nếu (prop_3), thì làm (prop_1) và tiếp tục xác nhận trạng thái trên cho đến khi (prop_2) không xảy ra tại một thời điểm nào đó sau 400 đơn vị thời gian từ bây giờ.

STL (pre-order+operator) ['<->', 'negation', 'prop_1', 'U[279,438]', 'prop_3', 'prop_2']
STL (in-order+word) (negation prop_1 equal (prop_3 until[279,438] prop_2))
Câu tự nhiên thô Kịch bản trong đó (prop_1) xảy ra giống như kịch bản trong đó (prop_3) xảy ra và tiếp tục cho đến tại một thời điểm nhất định trong 279 đến 438 đơn vị thời gian (prop_2) xảy ra.
Câu tự nhiên được chú thích Kịch bản trong đó (prop_1) không xảy ra giống như kịch bản trong đó (prop_3) xảy ra và tiếp tục cho đến tại một thời điểm nhất định trong 279 đến 438 đơn vị thời gian (prop_2) xảy ra.

Bảng 5: Ví dụ chú thích từ STLs được tổng hợp sang câu tự nhiên thô, và tiếp theo sang câu tự nhiên được chú thích.

F Quá trình chú thích của con người

Tất cả các người chú thích con người đều là các nhà nghiên cứu trong lĩnh vực phương pháp chính thức và lập kế hoạch robot với kiến thức sâu rộng về logic thời gian. Các người chú thích đều là tình nguyện viên từ viện của tác giả và các viện hợp tác. Trước khi chú thích và thu thập dữ liệu, chúng tôi đã thông báo cho họ rằng dữ liệu sẽ được sử dụng để huấn luyện mô hình ngôn ngữ chuyển đổi từ hướng dẫn ngôn ngữ tự nhiên sang logic thời gian, và rằng cả dữ liệu được chú thích và mô hình sẽ được công khai. Tất cả các người chú thích tình nguyện đã đồng ý với tuyên bố sử dụng dữ liệu được chú thích của họ. Về hướng dẫn nhiệm vụ, các người chú thích tham gia cuộc họp hướng dẫn và được cung cấp danh sách hướng dẫn về logic thời gian và một số cặp chú thích ví dụ (danh sách hướng dẫn và ví dụ chú thích có sẵn trên trang github). Mỗi người chú thích ban đầu chú thích 50 cặp, và gửi kết quả của họ cho các người chú thích khác được chỉ định ngẫu nhiên để kiểm tra chéo. Cuối cùng, các tác giả cũng kiểm tra tất cả các cặp để đảm bảo độ chính xác của dữ liệu được chú thích.

G Ví dụ các cặp NL-STL đầy đủ của mỗi tập dữ liệu chuyên môn

Như được hiển thị trong Bảng 6.

Navigation STL finally ( acquire_v pear_n ) and globally ( finally ( go_to_v waste_basket_n ) )
NL khi có thể thu thập lê và liên tục đi đến thùng rác.

Navigation STL finally ( got_to_v house_n ) and finally ( go_near_v house_n )
NL bất kỳ lúc nào đến nhà và khi có thể đi gần nhà.

Navigation STL advance_to_v tree_n imply finally ( get_to_v flag_n )
NL tiến đến cây có nghĩa là khi có thể đến cờ.

Circuit STL globally ( signal_1_n math equal 89.3 or ( signal_2_n more 42.4 and signal_2_n less 91.5 ) imply globally [0,34] ( finally [0,98] ( signal_3_n more equal 11.5 and signal_3_n less equal 23.4 ) ) )
NL Trong trường hợp tín hiệu signal_1_n là 89.3, hoặc tín hiệu signal_2_n lớn hơn 42.4 và dưới 91.5, thì cho mỗi thời điểm trong 34 đơn vị thời gian sắp tới, cần tồn tại một thời điểm nhất định trong 98 đơn vị thời gian tiếp theo, tại đó giá trị của tín hiệu signal_3_n nên không nhỏ hơn 11.5 và nhỏ hơn hoặc bằng 23.4 cuối cùng.

Circuit STL finally ( signal_1_n less 92.6 and signal_2_n more equal 57.3 )
NL Tại một thời điểm nhất định trong tương lai trước khi kết thúc mô phỏng signal_1_n cuối cùng dưới 92.6 và signal_2_n cuối cùng sẽ ít nhất là 57.3.

Circuit STL finally ( ( signal_1_n more equal 4.1 and signal_1_n less equal 59.0 ) or signal_2_n math equal 41.1 )
NL Phải có một thời điểm nhất định trong tương lai trước khi kết thúc mô phỏng, tại đó giá trị của signal_1_n cần lớn hơn hoặc bằng 4.1 và nhỏ hơn hoặc bằng 59.0 cuối cùng, hoặc signal_2_n cuối cùng giữ bằng 41.1.

GLTL STL finally ( ( red_room or blue_room ) and finally green_room )
NL vào phòng xanh hoặc cam và tiến hành cho đến phòng xanh lá.

GLTL STL ( finally ( blue_room ) and globally ( negation green_room ) )
NL di chuyển đến phòng xanh mà không vào phòng vôi.

GLTL STL ( finally ( yellow_room ) and globally ( negation blue_room ) )
NL chỉ đi qua các phòng không phải màu tím để đến phòng vàng.

CW STL finally ( blue_room and finally green_room )
NL vui lòng đi đến phòng xanh lá qua phòng xanh.

CW STL finally red_room
NL tôi muốn bạn vào phòng đỏ.

CW STL finally ( ( red_room or yellow_room ) and finally green_room )
NL đi qua hộp vàng hoặc đỏ để đến hộp xanh lá.

Office email STL globally ( ( ( a new incident is created in Eventribe ) and ( a response is created in Trello ) ) imply ( creating an object in Gmail ) )
NL Khi hành động chuyển tiếp mà một sự cố mới được tạo trong Eventribe không được quan sát, và một phản hồi được tạo trong Trello, thì điều kiện sau là đúng: nhanh chóng tạo một đối tượng trong Gmail.

Office email STL ( ( sync Microsoft Teams data ) until finally ( sending me an SAP and Salesforce ) )
NL đồng bộ dữ liệu Microsoft Teams cho đến khi có thể gửi cho tôi một SAP và Salesforce.

Office email STL globally ( ( ( a new lead is added in Marketo ) and ( creating a new Marketo card ) ) imply ( a new lead is added in Microsoft Teams ) )
NL Với điều kiện một lead mới được thêm vào Marketo và tạo một thẻ Marketo mới, thì sự kiện một lead mới được thêm vào Microsoft Teams cần xảy ra tại cùng thời điểm.

Bảng 6: Ví dụ về các cặp NL-STL đầy đủ trong mỗi miền chuyên môn.

H Nghiên cứu loại bỏ

H.1 Tầm quan trọng của Chú thích Con người

Phần này để chứng minh tầm quan trọng của chú thích con người cho dữ liệu được tổng hợp bởi GPT-3. Hình 12 hiển thị độ chính xác mô hình dưới số lượng cặp thô huấn luyện khác nhau. Điều tuyệt vời là mô hình T5-large vẫn có thể đạt được độ chính xác thử nghiệm cao nhất là 87.3% và 79.4% trên thử nghiệm dữ liệu hỗ trợ GPT-3 và dữ liệu Thủ công, ngay cả khi chỉ sử dụng dữ liệu thô được tổng hợp từ GPT-3. Tuy nhiên, so với kết quả trong Hình 5, các mô hình được huấn luyện trên dữ liệu được chú thích đạt được độ chính xác cao hơn khoảng 10% so với các mô hình được huấn luyện trên dữ liệu thô.

H.2 Tầm quan trọng của Framework2

Tập dữ liệu 3K Tập dữ liệu 4.5K
Miền 1.5K F1 + 1.5K F2 3K F1 3K F1 + 1.5K F2 4.5K F1
Dữ liệu thô 78.85±1.04% 75.79±0.98% 80.48±0.71% 79.04±0.64%
Dữ liệu được chú thích 80.57±0.86% 79.76±0.88% 88.32±0.84% 86.51±0.77%

Bảng 7: Độ chính xác thử nghiệm của các mô hình với các tập dữ liệu huấn luyện khác nhau. Dữ liệu huấn luyện hoặc là thô hoặc được chú thích, thuần túy từ Framework1 (F1) hoặc kết hợp với Framework2 (F2). Các kết quả thực nghiệm cho thấy rằng tập dữ liệu được chú thích có thể cải thiện rõ ràng hiệu suất của mô hình, và các mô hình kết hợp dữ liệu được tạo bởi F1 và F2 vượt trội hơn các mô hình được huấn luyện với cùng số lượng dữ liệu F1 thuần túy.

I Khả năng mô hình

Như được hiển thị trong Hình 13, T5-large hoạt động tốt hơn nhiều so với mô hình Seq2Seq khi huấn luyện trên cùng tập dữ liệu được nâng lên. Điều này tiết lộ tầm quan trọng của việc sử dụng LLM trong nhiệm vụ NL-sang-TL này.

J Thống kê tập dữ liệu

J.1 Thống kê tập dữ liệu NL-STL được nâng lên

# APs mỗi STL # Toán tử mỗi STL
trung bình trung vị tối đa trung bình trung vị tối đa
2.906 3 7 3.206 3 8

Bảng 8: Thống kê công thức STL được nâng lên: # APs cho mỗi công thức, # toán tử STL cho mỗi công thức.

# Từ mỗi Câu
# Câu # Từ vựng trung bình trung vị tối đa tối thiểu
28466 2296 18.358 17 72 3

Bảng 9: Thống kê câu được nâng lên: # câu duy nhất, # từ duy nhất (từ vựng), # từ mỗi câu.

J.2 Thống kê độ phong phú corpus

Miền # STL/ #Câu # STL Duy nhất # Từ vựng
Tập dữ liệu được tổng hợp 15K 14438 2121
Circuit (He et al., 2022) 120K 3653 265
Navigation (Wang et al., 2021) 5K 149 131
GLTL (Gopalan et al., 2018) 11K 193 193
CW (Squire et al., 2015) 3.3K 39 188
Office email (Fuggitti và Chakraborti, 2023) 0.15K 23 143

Bảng 10: Thống kê các công thức STL và câu NL trong tập dữ liệu được tổng hợp của chúng tôi và tập dữ liệu được thu thập của mỗi miền. # STL/ #Câu tiết lộ tổng số mẫu. # STL Duy nhất đếm số lượng công thức STL khác nhau. # Từ vựng đếm từ vựng trong mỗi tập dữ liệu. So với tập dữ liệu được thu thập trước đây, tập dữ liệu được tổng hợp của chúng tôi sở hữu số lượng STLs duy nhất và từ vựng lớn hơn nhiều, tiết lộ độ phong phú corpus lớn hơn.

K Tiến hóa độ chính xác với số lượng AP

Phần này để minh họa rằng việc áp dụng trực tiếp GPT-3 để dự đoán STL từ NL thông qua học few-shot giảm đáng kể độ chính xác khi cấu trúc câu phức tạp. Ở đây chúng tôi giả thuyết rằng độ phức tạp câu có mối quan hệ tích cực với số lượng APs. Như được hiển thị trong Hình 14, độ chính xác dự đoán giảm nhanh chóng với số lượng AP tăng khi sử dụng phương pháp đầu cuối GPT-3. Mặt khác, phương pháp tinh chỉnh T5-large sử dụng các cặp NL-STL được tổng hợp duy trì độ chính xác cao trên các số lượng AP khác nhau.

L Chi tiết thực hiện

Đối với tất cả các thí nghiệm tinh chỉnh trên cả mô hình T5-base và T5-large, chúng tôi chọn tỷ lệ học là 2e-5, kích thước batch là 16, tỷ lệ suy giảm trọng số là 0.01, và chạy 20 epochs cho mỗi cài đặt. Các thí nghiệm trung bình hoàn thành trong 3 giờ cho T5-base, và 10 giờ cho T5-large, trên một GPU Nvidia RTX 8000 duy nhất. Kết quả trung bình và độ lệch chuẩn thường được thu thập từ 3 lần chạy với seeds [1203, 309, 316], ngoại trừ học chuyển giao trong tập dữ liệu CW nơi 10 lần chạy được thực hiện với seeds [1203, 309, 316, 34, 64, 128, 256, 512, 1234, 234]. Đối với tinh chỉnh trên các mô hình được nâng lên, tập dữ liệu đầu vào được chia thành tập huấn luyện (0.9) và tập kiểm tra (0.1).

M Chuyển đổi STL đầy đủ bằng cách kết hợp với nhiệm vụ nhận diện AP

Được minh họa trong Hình 15

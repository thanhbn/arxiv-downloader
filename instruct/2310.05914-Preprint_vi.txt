Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Các mô hình ngôn ngữ là những người học few-shot. Advances in neural information processing systems, 33:1877-1901, 2020.

Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav, Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang, et al. Alpagasus: Huấn luyện một alpaca tốt hơn với ít dữ liệu hơn. arXiv preprint arXiv:2307.08701, 2023.

Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, và Eric P. Xing. Vicuna: Một chatbot nguồn mở gây ấn tượng với gpt-4 với chất lượng 90%* chatgpt, tháng 3 năm 2023. URL https://lmsys.org/blog/2023-03-30-vicuna/.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Mở rộng các mô hình ngôn ngữ được tinh chỉnh hướng dẫn. arXiv preprint arXiv:2210.11416, 2022.

Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, và Oyvind Tafjord. Bạn nghĩ mình đã giải quyết việc trả lời câu hỏi? hãy thử arc, thách thức lý luận ai2. arXiv preprint arXiv:1803.05457, 2018.

Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, và Luke Zettlemoyer. Qlora: Tinh chỉnh hiệu quả của llm được lượng tử hóa. arXiv preprint arXiv:2305.14314, 2023.

Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang, và Tatsunori B Hashimoto. Alpacafarm: Một khung mô phỏng cho các phương pháp học từ phản hồi của con người. arXiv preprint arXiv:2305.14387, 2023.

Cynthia Dwork, Aaron Roth, et al. Các nền tảng thuật toán của bảo mật vi phân. Foundations and Trends® in Theoretical Computer Science, 9(3-4):211-407, 2014.

Leo Gao, Jonathan Tow, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Kyle McDonell, Niklas Muennighoff, Jason Phang, Laria Reynolds, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, và Andy Zou. Một khung để đánh giá mô hình ngôn ngữ few-shot, tháng 9 năm 2021. URL https://doi.org/10.5281/zenodo.5371628.

Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, và Jacob Steinhardt. Đo lường hiểu biết ngôn ngữ đa nhiệm vụ lớn. Trong International Conference on Learning Representations, 2020.

John Kirchenbauer, Jonas Geiping, Yuxin Wen, Manli Shu, Khalid Saifullah, Kezhi Kong, Kasun Fernando, Aniruddha Saha, Micah Goldblum, và Tom Goldstein. Về độ tin cậy của watermark cho các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2306.04634, 2023.

Kezhi Kong, Guohao Li, Mucong Ding, Zuxuan Wu, Chen Zhu, Bernard Ghanem, Gavin Taylor, và Tom Goldstein. Tối ưu hóa mạnh mẽ như tăng cường dữ liệu cho đồ thị quy mô lớn. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 60-69, 2022.

Ariel N. Lee, Cole J. Hunter, và Nataniel Ruiz. Platypus: Tinh chỉnh nhanh, rẻ và mạnh mẽ của llm. arXiv preprint arxiv:2308.07317, 2023.

Xiang Lisa Li, Ari Holtzman, Daniel Fried, Percy Liang, Jason Eisner, Tatsunori Hashimoto, Luke Zettlemoyer, và Mike Lewis. Giải mã tương phản: Tạo văn bản mở như tối ưu hóa. arXiv preprint arXiv:2210.15097, 2022.

Chin-Yew Lin. ROUGE: Một gói cho đánh giá tự động các bản tóm tắt. Trong Text Summarization Branches Out, pp. 74-81, Barcelona, Spain, tháng 7 năm 2004. Association for Computational Linguistics. URL https://www.aclweb.org/anthology/W04-1013.

Stephanie Lin, Jacob Hilton, và Owain Evans. TruthfulQA: Đo lường cách các mô hình bắt chước những sai lầm của con người. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 3214-3252, Dublin, Ireland, tháng 5 năm 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.acl-long.229. URL https://aclanthology.org/2022.acl-long.229.

David Nukrai, Ron Mokady, và Amir Globerson. Huấn luyện chỉ với văn bản cho mô tả hình ảnh sử dụng clip tiêm nhiễu. ArXiv, abs/2211.00575, 2022. URL https://api.semanticscholar.org/CorpusID:253244258.

OpenAI. Giới thiệu chatgpt, 2022. URL https://openai.com/blog/chatgpt.

Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Huấn luyện các mô hình ngôn ngữ tuân theo hướng dẫn với phản hồi của con người. Advances in Neural Information Processing Systems, 35:27730-27744, 2022.

Kishore Papineni, Salim Roukos, Todd Ward, và Wei jing Zhu. Bleu: một phương pháp đánh giá tự động dịch máy. Trong Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pp. 311-318, 2002.

Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, et al. Huấn luyện nhắc đa nhiệm vụ cho phép khái quát hóa nhiệm vụ zero-shot. Trong International Conference on Learning Representations, 2021.

ShareGPT, 2023. URL https://sharegpt.com/.

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, và Tatsunori B. Hashimoto. Stanford alpaca: Một mô hình llama tuân theo hướng dẫn. https://github.com/tatsu-lab/stanford_alpaca, 2023.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Các mô hình ngôn ngữ nền tảng mở và hiệu quả. arXiv preprint arXiv:2302.13971, 2023a.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Các mô hình nền tảng mở và chat được tinh chỉnh. arXiv preprint arXiv:2307.09288, 2023b.

Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, và Hannaneh Hajishirzi. Self-instruct: Điều chỉnh mô hình ngôn ngữ với các hướng dẫn tự tạo. arXiv preprint arXiv:2212.10560, 2022.

Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, và Quoc V Le. Các mô hình ngôn ngữ được tinh chỉnh là những người học zero-shot. Trong International Conference on Learning Representations, 2021.

Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, và Daxin Jiang. Wizardlm: Trao quyền cho các mô hình ngôn ngữ lớn tuân theo các hướng dẫn phức tạp. arXiv preprint arXiv:2304.12244, 2023.

Hanwei Xu, Yujun Chen, Yulun Du, Nan Shao, Wang Yanggang, Haiyu Li, và Zhilin Yang. Zeroprompt: Mở rộng pretraining dựa trên prompt đến 1.000 nhiệm vụ cải thiện khái quát hóa zero-shot. Trong Findings of the Association for Computational Linguistics: EMNLP 2022, pp. 4235-4252, 2022.

Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, và Yejin Choi. HellaSwag: Máy có thể thực sự hoàn thành câu của bạn không? Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 4791-4800, Florence, Italy, tháng 7 năm 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1472. URL https://aclanthology.org/P19-1472.

Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. Opt: Các mô hình ngôn ngữ transformer được huấn luyện trước mở. arXiv preprint arXiv:2205.01068, 2022.

Chen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, và Jingjing Liu. Freelb: Huấn luyện đối kháng tăng cường cho hiểu biết ngôn ngữ tự nhiên. Trong International Conference on Learning Representations, 2019.

--- TRANG 13 ---
Bản thảo

Bảng 7: Tỷ lệ Thắng AlpacaEval so với Text-Davinci-003 cho LLaMA-2 được huấn luyện trên các bộ dữ liệu khác nhau, sử dụng GPT-4 làm người đánh giá, cho thấy cải thiện trung bình 15% trên tất cả các bộ dữ liệu.

| Alpaca | Evol-Instruct | ShareGPT | OpenPlatypus | Trung bình |
|--------|---------------|----------|--------------|------------|
| LLaMA-2 7B | 29.79 | 70.34 | 68.74 | 62.00 | 57.71 |
| +NEFT | 64.69 | 79.60 | 76.28 | 70.61 | 72.80 |
| | (alpha=5) | (alpha=5) | (alpha=10) | (alpha=15) | |

Bảng 8: alpha được sử dụng cho Hình 3.

| | Alpaca | Evol-Instruct | OpenPlatypus | ShareGPT |
|---|--------|---------------|--------------|----------|
| OPT 6.7B | 15 | 15 | 5 | 15 |
| LLaMA-1 7B | 10 | 10 | 15 | 10 |
| LLaMA-2 7B | 5 | 5 | 15 | 15 |

A PHỤ LỤC

A.1 SIÊU THAM SỐ

Chúng tôi tinh chỉnh các mô hình tham số 7B trên bốn A5000 và tham số 13B trên tám A5000 sử dụng độ chính xác bfloat16. Sau khi thực hiện quét tốc độ học ban đầu trên LLaMA-1 và Alpaca, chúng tôi sử dụng tốc độ học 5e-5 và optimizer Adam cho tất cả các mô hình 7B sau khi thấy cải thiện 4% so với số baseline. Chúng tôi huấn luyện tất cả các mô hình trong 3 epoch trên tất cả các bộ dữ liệu thiết lập cùng seed cho mỗi lần chạy với kích thước batch hiệu quả là 128 (4 card, kích thước batch 4, 8 bước tích lũy gradient). Khi tinh chỉnh với nhiễu, chúng tôi huấn luyện trên ba mức nhiễu, một quả cầu L2 của 5, 10, và 15 trên độ dài chuỗi và báo cáo mức tốt nhất trên AlpacaEval sử dụng ChatGPT làm người đánh giá. Chúng tôi huấn luyện với độ dài chuỗi 512 token (chủ yếu cho bộ nhớ và tốc độ) như thiết lập Alpaca ban đầu, thấy rằng điều này không ảnh hưởng đến độ dài phản hồi đầu ra hoặc chất lượng như được chứng thực bởi các số Alpaca Leaderboard. Trong Bảng 13 chúng ta thấy rằng huấn luyện với chuỗi dài hơn không thay đổi hiệu suất đáng kể. Đối với ShareGPT, chúng tôi chia các cuộc hội thoại đa lượt thành chuỗi 512 token sử dụng quy trình được mô tả bởi Chiang et al. (2023). Khi huấn luyện các mô hình tham số 70 tỷ, chúng tôi sử dụng các siêu tham số tinh chỉnh được tìm thấy trong Touvron et al. (2023b) ngoại trừ chúng tôi sử dụng độ dài chuỗi 2048; tức là, chúng tôi sử dụng weight decay 0.1, kích thước batch 64, và tốc độ học 2e−5. Chúng tôi tinh chỉnh tổng cộng ba epoch trên Evol-Instruct 70k (Xu et al., 2023). Khi sử dụng NEFTune trên mô hình tham số 70B, chúng tôi sử dụng alpha=15 và không khám phá các thiết lập khác (có thể tốt hơn) do hạn chế tính toán. Ngoài ra, chúng tôi thấy sự gia tăng độ dài ký tự đầu ra trung bình từ 852 đến 1241 (+389).

Bảng 9: LLaMA-2-Chat (7B) và LLaMA-2 (13B) có thể được tinh chỉnh thêm để cải thiện hiệu suất.

| LLaMA-2 (7B) | LLaMA-2-Chat (7B) | LLaMA-2 (13B) | LLaMA-2 (70B) |
|--------------|-------------------|---------------|---------------|
| Base | - | 71.37* | - | - |
| Evol-Instruct | 70.34 | 74.44 | 72.61 | 75.03 |
| +NEFT | 79.60 | 81.74 | 82.04 | 88.81 |
| | (alpha=5) | (alpha=5) | (alpha=5) | (alpha=15) |

A.2 CÁC NGHIÊN CỨU ABLATION BỔ SUNG

Chúng tôi ablate nhiễu đồng nhất và gaussian, thấy rằng nhiễu đồng nhất hoạt động tốt hơn một chút. Chúng tôi cũng ablate các siêu tham số giải mã trong Hình 10 thấy các thay đổi tối thiểu trong hiệu suất. Do đó, chúng tôi sử dụng chiến lược lấy mẫu đơn giản nhất, giải mã tham lam, với penalty lặp lại 1.2. Chúng tôi cũng kiểm tra xem NEFT có tiếp tục mang lại cải thiện khi bạn tăng số epoch huấn luyện hay không. Từ Bảng 14, chúng ta thấy rằng có một cao nguyên về hiệu suất được đạt tới ở số epoch cao hơn. Trong Bảng 11, chúng tôi đóng băng các phần khác nhau của mô hình để hiểu xem các phần nào của mô hình quan trọng cho NEFT.

--- TRANG 14 ---
Bản thảo

Bảng 10: Tỷ lệ Thắng AlpacaEval với người đánh giá ChatGPT (GPT-4 trong ngoặc đơn) dưới các chiến lược giải mã khác nhau từ đây chúng ta có thể thấy rằng dường như có ít biến động trong hiệu suất. Các siêu tham số WizardLM và LLaMA-Chat được lấy từ các tệp cấu hình tạo từ Hugging Face. Tất cả các kỹ thuật lấy mẫu đều có penalty lặp lại 1.2.

| Nguồn Siêu tham số | topp | temp. | LLaMA2-7B (Evolve) | LLaMA2-7B-NEFT (Evolve) |
|-------------------|------|-------|---------------------|--------------------------|
| Base greedy | - | - | 62.55 (70.34) | 67.58 (79.60) |
| HP 0 | 0.1 | 0.1 | 63.11 | 66.83 |
| HP 1 | 0.35 | 0.5 | 62.48 | 66.71 |
| WizardLM | 0.6 | 0.9 | 62.05 | 66.96 |
| LLaMA-2 | 0.9 | 0.6 | 63.73 (70.49) | 65.47 |

Bảng 11: Tỷ lệ Thắng AlpacaEval theo ChatGPT khi thay đổi tập các tham số có thể huấn luyện khi tinh chỉnh LLaMA-2-7B trên bộ dữ liệu Alpaca. Hai hàng trên cùng có tất cả tham số được thiết lập là có thể huấn luyện.

| Thiết lập | AlpacaEval (Đánh giá ChatGPT) |
|-----------|-------------------------------|
| tinh chỉnh tiêu chuẩn | 48.26 |
| NEFT | 62.55 |
| NEFT + Embed đóng băng | 61.06 |
| NEFT + LM-head đóng băng | 61.12 |
| NEFT + Khối Attention đóng băng | 22.17 |
| LLaMA-2 (không tinh chỉnh) | 22.17 |

A.3 PHÂN TÍCH BỔ SUNG

Nhiễu ảnh hưởng đến token như thế nào? Vì mô hình hóa của chúng tôi liên quan đến việc thêm nhiễu ngẫu nhiên vào các nhúng trong giai đoạn huấn luyện, chúng tôi kiểm tra xem nhiễu được thêm vào có thay đổi ngữ nghĩa của các chuỗi token trong dữ liệu huấn luyện hay không. Để phân tích này, chúng tôi lấy mẫu ngẫu nhiên 5200 mẫu từ bộ dữ liệu Alpaca, nhúng mỗi điểm huấn luyện sử dụng lớp nhúng của các mô hình khác nhau, và sau đó thêm các mức nhiễu khác nhau bằng cách thay đổi hệ số thay đổi tỷ lệ alpha. Sau đó chúng tôi chiếu các nhúng nhiễu trở lại láng giềng gần nhất của chúng trong ma trận nhúng. Chúng tôi tính toán % lật token trong mỗi câu và lấy trung bình tỷ lệ lật trên tất cả các mẫu. Chúng tôi trình bày điểm lật cho 7 mô hình trong Hình 6. Trong khi không có câu nào có bất kỳ lật nào lên đến alpha=15, chúng ta thấy một số lật khi alpha>=25. Lưu ý rằng tất cả kết quả được trình bày trong bài báo sử dụng alpha<=15. Thú vị là, một mô hình LLaMA-1 được tinh chỉnh trên Alpaca không cho thấy bất kỳ lật nào ngay cả ở mức alpha cao hơn.

[Hình 6: Phần trăm token trên câu bị lật ở các mức nhiễu khác nhau được thêm vào nhúng.]

Tác động của nhiễu đến độ tương tự nhúng. Chúng tôi cũng phân tích cách độ tương tự của các nhúng thay đổi khi chúng tôi thực hiện huấn luyện NEFT. Chúng tôi xem xét 100 giá trị số ít hàng đầu của ma trận độ tương tự nhúng cho tất cả các mô hình. Chúng tôi trình bày kết quả trong Hình 6 (Phải). Đối với một mô hình cơ sở nhất định (LLaMA-1 hoặc LLaMA-2), phân phối giá trị số ít không thay đổi trên các biến thể, có hoặc không có NEFTune. Điều này cho thấy rằng việc thêm nhiễu trong huấn luyện không ảnh hưởng đến phân phối độ tương tự nhúng nhiều.

Nhiễu ảnh hưởng đến nhúng như thế nào? Trong phân tích trước, chúng tôi đánh giá xem có token nào lật khi tạo nhiễu chuỗi dữ liệu huấn luyện thực hay không. Chúng tôi cũng kiểm tra các nhúng của 3 mô hình, LLaMA-2, LLaMA-2 Alpaca, và LLaMA-2 Evol-Instruct một cách độc lập. Trong thí nghiệm này, chúng tôi quét trên tất cả các token trong từ vựng thêm nhiễu vào từng token, và đếm số nhúng nhiễu có láng giềng gần nhất khác với điểm bắt đầu không nhiễu của chúng. Chúng tôi trình bày kết quả trong Hình 8. Chúng tôi thay đổi 2 yếu tố: tỷ lệ nhiễu cơ sở alpha, và hệ số thay đổi tỷ lệ độ dài chuỗi L được sử dụng trong việc tính toán hệ số nhiễu cuối cùng. Ngay cả ở mức nhiễu cao, chỉ một số lượng rất nhỏ token thực sự lật (<=0.4%). Điều này cho thấy rằng huấn luyện NEFT không thay đổi các mối quan hệ ngữ nghĩa giữa các token.

Thú vị là, thí nghiệm này gợi ý rằng, nếu coi NEFTune như một loại tăng cường dữ liệu được áp dụng cho các nhúng của token huấn luyện, các hiệu ứng thực tế của NEFT chủ yếu là kết quả của các nhiễu loạn trong không gian nội token vì các tỷ lệ nhiễu được sử dụng hiếm khi tương đương với các dịch chuyển biến đổi bất kỳ token riêng lẻ nào thành một token khác có ý nghĩa. Tuy nhiên, trong Hình 9 chúng tôi cho thấy các token tương ứng với các nhúng của mô hình LLaMA-2 Alpaca thực sự lật ngay cả với lượng nhiễu thấp nhất được sử dụng trong nghiên cứu của chúng tôi.

[Hình 7: 100 eigenvalue hàng đầu của ma trận độ tương tự nhúng trên các mô hình.]

--- TRANG 15 ---
Bản thảo

Bảng 14: Tỷ lệ Thắng AlpacaEval ChatGPT như một hàm của số epoch tinh chỉnh.

| Epoch | LLaMA-2 (7B) Alpaca | +NEFT |
|-------|---------------------|-------|
| 1 | 40.50 | 55.09 |
| 3 | 48.26 | 62.55 |
| 5 | 48.94 | 62.24 |
| 7 | 48.63 | 60.50 |
| 9 | 47.45 | 58.14 |

[Hình 8: Số token bị lật ở các mức nhiễu và độ dài chuỗi khác nhau (trên 32000). Tên mô hình tương ứng với mỗi biểu đồ ở trong tiêu đề.]

[Hình 9: Token bị lật ở alpha=1 và độ dài chuỗi=512 trong LLaMA-2]

--- TRANG 16 ---
Bản thảo

A.4 VÍ DỤ ĐỊNH TÍNH

Đối với những ví dụ định tính này cho các mô hình LLaMA-2 được tinh chỉnh, chúng tôi chọn một hướng dẫn yêu cầu giải thích kiến thức và một hướng dẫn liên quan đến "sáng tạo." Chúng tôi lấy những ví dụ này từ AlpacaEval, đặc biệt là tập con Vicuna Eval. Lưu ý chúng tôi không tích cực cherry-pick những ví dụ này.

Hướng dẫn AlpacaEval (Tập con Vicuna): Bạn có thể giải thích những điều cơ bản về tính toán lượng tử không?

Phản hồi LLaMA-2-Alpaca-7B:
Tính toán lượng tử dựa trên các nguyên lý của cơ học lượng tử, cho phép các hiện tượng như chồng chất và vướng víu giữa các hạt. Điều này có nghĩa là thông tin có thể được xử lý song song thay vì tuần tự như máy tính truyền thống. Bit lượng tử (qubit) được sử dụng để lưu trữ dữ liệu thay vì bit cổ điển, cho phép các tính toán phức tạp hơn diễn ra với ít tài nguyên hơn so với những gì cần thiết khác.

Phản hồi LLaMA-2-Alpaca-7B-NEFT:
Tính toán lượng tử dựa trên các nguyên lý của cơ học lượng tử, mô tả cách các hạt như electron và photon hoạt động ở cấp độ hạ nguyên tử. Không giống như máy tính truyền thống, xử lý thông tin theo chữ số nhị phân (bit) có thể là 0 hoặc 1, bit lượng tử (qubit) có thể tồn tại trong nhiều trạng thái giữa 0 và 1 đồng thời. Hiện tượng này được gọi là chồng chất và cho phép các tính toán phức tạp hơn nhiều được thực hiện so với những gì có thể với máy tính cổ điển. Các thuật toán lượng tử được thiết kế để tận dụng thuộc tính này bằng cách mã hóa dữ liệu vào các trạng thái qubit để nó có thể được xử lý nhanh hơn theo cấp số nhân so với các phương pháp thông thường. Ngoài ra, vướng víu lượng tử - khả năng cho hai hạt duy trì kết nối ngay cả trên khoảng cách lớn - cho phép lượng lớn dữ liệu được gửi qua mạng một cách nhanh chóng và an toàn. Các ứng dụng tiềm năng của tính toán lượng tử dao động từ mật mã học và trí tuệ nhân tạo đến khám phá thuốc và khoa học vật liệu. Với nghiên cứu và phát triển tiếp tục, công nghệ lượng tử có tiềm năng cách mạng hóa nhiều ngành công nghiệp.

Phản hồi LLaMA-2-ShareGPT-7B:
Máy tính lượng tử là một loại máy tính sử dụng các hiện tượng cơ học lượng tử, như chồng chất và vướng víu, để thực hiện các phép toán trên dữ liệu. Chúng có tiềm năng giải quyết một số bài toán nhanh hơn nhiều so với máy tính cổ điển, bị giới hạn bởi các định luật vật lý cổ điển.

Một cách để nghĩ về cách máy tính lượng tử hoạt động là theo các khối xây dựng cơ bản hoặc "qubit." Qubit có thể tồn tại trong nhiều trạng thái cùng một lúc (một thuộc tính được gọi là chồng chất), và chúng cũng có thể được liên kết với nhau để trạng thái của chúng phụ thuộc vào trạng thái của các qubit khác (một hiện tượng được gọi là vướng víu). Những thuộc tính này cho phép máy tính lượng tử thực hiện nhiều tính toán đồng thời, tận dụng các nguyên lý của cơ học lượng tử để đạt được tăng tốc theo cấp số nhân cho một số loại tính toán nhất định.

Phản hồi LLaMA-2-ShareGPT-7B-NEFT:
Máy tính lượng tử là một loại máy tính sử dụng các hiện tượng cơ học lượng tử, như chồng chất và vướng víu, để thực hiện các phép toán trên dữ liệu. Chúng có tiềm năng giải quyết một số bài toán nhanh hơn nhiều so với máy tính cổ điển, bị giới hạn bởi các định luật vật lý cổ điển.

Đây là một tổng quan ngắn gọn về một số khái niệm chính trong tính toán lượng tử:

1. Chồng chất: Trong tính toán cổ điển, bit chỉ có thể là 0 hoặc 1 tại bất kỳ thời điểm nào. Tuy nhiên, trong tính toán lượng tử, qubit (bit lượng tử) có thể tồn tại trong nhiều trạng thái đồng thời, được gọi là chồng chất. Điều này cho phép nhiều tính toán được thực hiện đồng thời, tăng tốc độ tính toán.

2. Vướng víu: Khi hai hạt trở nên "vướng víu," thuộc tính của chúng trở nên tương quan ngay cả khi chúng được tách ra bởi khoảng cách lớn. Ví dụ, nếu hai photon được tạo ra với phân cực ngược nhau, việc đo trạng thái của một photon sẽ ngay lập tức xác định trạng thái của photon kia, bất kể chúng cách nhau bao xa. Thuộc tính này có thể được sử dụng để tạo ra một mạng các qubit vướng víu, cho phép chúng làm việc cùng nhau để giải quyết các vấn đề phức tạp.

3. Giao thoa: Giống như sóng có thể giao thoa với nhau để tạo ra các mẫu mới, qubit cũng có thể giao thoa với nhau thông qua một quá trình được gọi là giao thoa lượng tử. Bằng cách thao tác những giao thoa này, các thuật toán lượng tử có thể được thiết kế để tận dụng các thuộc tính độc đáo của hệ thống lượng tử.

4. Đo lường: Một trong những thách thức lớn nhất trong việc làm việc với hệ thống lượng tử là các phép đo sẽ làm sụp đổ hàm sóng, về cơ bản đóng băng hệ thống vào trạng thái cuối cùng của nó. Điều này có nghĩa là một khi phép đo được thực hiện, thông tin được lưu trữ trong hệ thống lượng tử không thể thay đổi nữa. Do đó, các tính toán lượng tử phải được thiết kế cẩn thận để đảm bảo rằng kết quả mong muốn đạt được trước khi phép đo được thực hiện.

5. Sửa lỗi: Do tính bất ổn vốn có của hệ thống lượng tử, lỗi có thể xảy ra trong quá trình tính toán. Để vượt qua thách thức này, các mã sửa lỗi phải được triển khai để phát hiện và sửa các lỗi do hệ thống lượng tử tạo ra. Những kỹ thuật sửa lỗi này rất quan trọng để làm cho máy tính lượng tử thực tế trở thành hiện thực.

6. Tính toán Lượng tử Tôpô: Một cách tiếp cận khác để xây dựng máy tính lượng tử sử dụng các pha tôpô của vật chất, nơi tham số thứ tự nhận giá trị trong một không gian không giao hoán. Đã được chứng minh rằng một số lớp trạng thái có thứ tự tôpô nhất định có thể host tính toán lượng tử chịu lỗi.

7. Bậc tự do: Trong tính toán cổ điển, thường chỉ có một bậc tự do trên mỗi bit - liệu nó được thiết lập thành 0 hay 1. Nhưng trong tính toán lượng tử, có thể có nhiều bậc tự do trên mỗi qubit, dẫn đến nhiều khả năng hơn để mã hóa thông tin và thực hiện tính toán.

8. Cổng Cổ điển vs Lượng tử: Cổng là các khối xây dựng cơ bản của mạch lượng tử, tương tự như cổng logic trong tính toán cổ điển. Trong khi cả cổng cổ điển và lượng tử đều thực hiện các phép toán trên dữ liệu, các quy tắc chi phối chúng khác nhau đáng kể. Ví dụ, trong khi cổng cổ điển hoạt động trên chữ số nhị phân (bit), cổng lượng tử hoạt động trên qubit, và các nguyên lý cơ bản về hành vi của chúng khác biệt cơ bản.

[Phần còn lại của bài báo tiếp tục với các ví dụ định tính khác và kết luận...]

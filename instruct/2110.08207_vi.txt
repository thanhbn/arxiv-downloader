# 2110.08207.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/instruct/2110.08207.pdf
# Kích thước tệp: 2087672 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022
HUẤN LUYỆN ĐA NHIỆM VỤ VỚI PROMPT CHO PHÉP
TỔNG QUÁT HÓA NHIỆM VỤ ZERO-SHOT
Victor Sanh
Hugging FaceAlbert Webson
Brown UniversityColin Raffel
Hugging FaceStephen H. Bach
Brown & Snorkel AI
Lintang Sutawika
BigScienceZaid Alyafeai
KFUPMAntoine Chafﬁn
IRISA & IMATAGArnaud Stiegler
HyperscienceTeven Le Scao
Hugging Face
Arun Raja
I2R, SingaporeManan Dey
SAPM Saiful Bari
NTU, SingaporeCanwen Xu
UCSD & Hugging FaceUrmish Thakker
SambaNova Systems
Shanya Sharma
Walmart LabsEliza Szczechla
BigScienceTaewoon Kim
VU AmsterdamGunjan Chhablani
BigScienceNihal V . Nayak
Brown University
Debajyoti Datta
University of VirginiaJonathan Chang
ASUSMike Tian-Jian Jiang
ZEALS, JapanHan Wang
NYUMatteo Manica
IBM Research
Sheng Shen
UC BerkeleyZheng-Xin Yong
Brown UniversityHarshit Pandey
BigScienceMichael McKenna
ParityRachel Bawden
Inria, France
Thomas Wang
Inria, FranceTrishala Neeraj
BigScienceJos Rozen
Naver Labs EuropeAbheesht Sharma
BITS Pilani, IndiaAndrea Santilli
University of Rome
Thibault Fevry
BigScienceJason Alan Fries
Stanford & Snorkel AIRyan Teehan
Charles River AnalyticsTali Bers
Brown University
Stella Biderman
Booz Allen & EleutherAILeo Gao
EleutherAIThomas Wolf
Hugging FaceAlexander M. Rush
Hugging Face

TÓM TẮT
Các mô hình ngôn ngữ lớn gần đây đã được chứng minh có thể đạt được khả năng tổng quát hóa zero-shot hợp lý trên một tập hợp đa dạng các nhiệm vụ (Brown et al., 2020). Người ta đã đưa ra giả thuyết rằng điều này là hệ quả của việc học đa nhiệm vụ ngầm trong quá trình tiền huấn luyện của các mô hình ngôn ngữ (Radford et al., 2019). Liệu khả năng tổng quát hóa zero-shot có thể được tạo ra trực tiếp bằng cách học đa nhiệm vụ rõ ràng không? Để kiểm tra câu hỏi này ở quy mô lớn, chúng tôi phát triển một hệ thống để dễ dàng ánh xạ bất kỳ nhiệm vụ ngôn ngữ tự nhiên nào thành dạng prompt có thể đọc được của con người. Chúng tôi chuyển đổi một tập hợp lớn các bộ dữ liệu có giám sát, mỗi bộ có nhiều prompt với cách diễn đạt đa dạng. Các bộ dữ liệu được prompt hóa này cho phép đánh giá khả năng của mô hình thực hiện các nhiệm vụ hoàn toàn chưa gặp. Chúng tôi tinh chỉnh một mô hình encoder-decoder được tiền huấn luyện (Raffel et al., 2020; Lester et al., 2021) trên hỗn hợp đa nhiệm vụ này bao gồm nhiều loại nhiệm vụ. Mô hình đạt được hiệu suất zero-shot mạnh trên một số bộ dữ liệu tiêu chuẩn, thường vượt trội hơn các mô hình lớn gấp 16 lần. Hơn nữa, phương pháp của chúng tôi đạt hiệu suất mạnh trên một tập con các nhiệm vụ từ benchmark BIG-bench, vượt trội hơn các mô hình lớn gấp 6 lần. Tất cả các mô hình được huấn luyện đều có sẵn tại https://github.com/bigscience-workshop/t-zero, và tất cả các prompt đều có sẵn tại https://github.com/bigscience-workshop/promptsource.

1 GIỚI THIỆU
Nghiên cứu gần đây đã chỉ ra rằng các mô hình ngôn ngữ lớn thể hiện khả năng thực hiện tổng quát hóa zero-shot hợp lý cho các nhiệm vụ mới (Brown et al., 2020; Kim et al., 2021). Mặc dù chỉ được huấn luyện trên các mục tiêu mô hình hóa ngôn ngữ, những mô hình này có thể thực hiện tương đối tốt ở các nhiệm vụ mới mà chúng chưa được huấn luyện rõ ràng để thực hiện, chẳng hạn như trả lời câu hỏi về một đoạn văn hoặc thực hiện

Đóng góp ngang nhau. Danh sách đầy đủ các đóng góp cá nhân được chi tiết trong Phụ lục A. Tác giả liên hệ:
victor@huggingface.co và awebson@brown.edu.
1arXiv:2110.08207v3  [cs.LG]  17 Mar 2022

--- TRANG 2 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022
Đánh giá: Chúng tôi đến đây vào tối thứ Bảy 
và may mắn là không đông đúc như tôi 
nghĩ [...] Trên thang điểm từ 1 
đến 5, tôi sẽ cho điểm này
Tôi biết rằng câu trả lời cho "Đội nào đã bị 
Panthers đánh bại?" có trong "The Panthers 
đã kết thúc mùa giải thường [...]". Bạn có thể 
cho tôi biết đó là gì không? T0Nghệ sĩ graffiti Banksy 
được cho là đứng sau [...] 
4
CóArizona Cardinals Tóm tắt 
Trả lời câu hỏi Phân tích cảm xúc 
Giả sử "Người ngân hàng đã liên lạc với các 
giáo sư và vận động viên". Chúng ta có thể suy 
ra rằng "Người ngân hàng đã liên lạc với các 
giáo sư" không?Bức tranh xuất hiện trên tường của một 
cửa hàng Poundland trên đường Whymark [...] Bạn sẽ 
diễn đạt lại điều đó như thế nào bằng vài từ? 
Suy luận ngôn ngữ tự nhiên Huấn luyện đa nhiệm vụ 
Tổng quát hóa zero-shot 

Hình 1: Mô hình và định dạng prompt của chúng tôi. T0 là một mô hình encoder-decoder tiêu thụ đầu vào văn bản và tạo ra các phản hồi mục tiêu. Nó được huấn luyện trên một hỗn hợp đa nhiệm vụ của các bộ dữ liệu NLP được phân chia thành các nhiệm vụ khác nhau. Mỗi bộ dữ liệu được liên kết với nhiều mẫu prompt được sử dụng để định dạng các trường hợp ví dụ thành các cặp đầu vào và mục tiêu. Chữ nghiêng biểu thị các trường được chèn từ dữ liệu ví dụ thô. Sau khi huấn luyện trên hỗn hợp đa dạng các nhiệm vụ (trên), mô hình của chúng tôi được đánh giá về khả năng tổng quát hóa zero-shot cho các nhiệm vụ không được nhìn thấy trong quá trình huấn luyện (dưới).

tóm tắt. Một giả thuyết có ảnh hưởng là các mô hình ngôn ngữ lớn tổng quát hóa cho các nhiệm vụ mới như là kết quả của một quá trình học đa nhiệm vụ ngầm (Radford et al., 2019). Như một sản phẩm phụ của việc học dự đoán từ tiếp theo, một mô hình ngôn ngữ bị buộc phải học từ một hỗn hợp các nhiệm vụ ngầm có trong corpus tiền huấn luyện của chúng. Ví dụ, bằng cách huấn luyện trên văn bản chung từ một diễn đàn web, một mô hình có thể học ngầm định dạng và cấu trúc của việc trả lời câu hỏi. Điều này mang lại cho các mô hình ngôn ngữ lớn khả năng tổng quát hóa cho các nhiệm vụ chưa gặp được trình bày với các prompt ngôn ngữ tự nhiên, vượt ra ngoài các nghiên cứu đa nhiệm vụ trước đây về tổng quát hóa cho các bộ dữ liệu chưa gặp (Khashabi et al., 2020a; Ye et al., 2021). Tuy nhiên, khả năng này đòi hỏi một mô hình đủ lớn và nhạy cảm với cách diễn đạt của các prompt (Perez et al., 2021; Zhao et al., 2021; Reynolds và McDonell, 2021).

Hơn nữa, việc học đa nhiệm vụ này thực sự ngầm đến mức nào vẫn là một câu hỏi mở. Với quy mô của corpus tiền huấn luyện của các mô hình ngôn ngữ gần đây, việc một số nhiệm vụ xử lý ngôn ngữ tự nhiên (NLP) phổ biến sẽ xuất hiện dưới dạng rõ ràng trong corpus tiền huấn luyện của chúng là hợp lý, do đó huấn luyện trực tiếp các mô hình trên những nhiệm vụ đó. Ví dụ, có nhiều trang web chỉ đơn giản chứa danh sách các câu hỏi và câu trả lời thông thường¹, chính xác là dữ liệu huấn luyện có giám sát cho nhiệm vụ trả lời câu hỏi sách đóng (Roberts et al., 2020). Chúng tôi đưa ra giả thuyết rằng việc giám sát đa nhiệm vụ như vậy trong tiền huấn luyện đóng vai trò lớn trong tổng quát hóa zero-shot.

Trong bài báo này, chúng tôi tập trung vào việc huấn luyện rõ ràng các mô hình ngôn ngữ theo cách có giám sát và đa nhiệm vụ lớn. Phương pháp của chúng tôi sử dụng một hỗn hợp huấn luyện bao gồm một tập hợp lớn các nhiệm vụ khác nhau được chỉ định trong các prompt ngôn ngữ tự nhiên. Mục tiêu của chúng tôi là tạo ra một mô hình để tổng quát hóa tốt hơn cho các nhiệm vụ chưa gặp mà không cần quy mô lớn, cũng như mạnh mẽ hơn đối với các lựa chọn cách diễn đạt của các prompt.

Để chuyển đổi một tập hợp lớn các nhiệm vụ ngôn ngữ tự nhiên thành dạng prompt, chúng tôi sử dụng một ngôn ngữ mẫu đơn giản cho các bộ dữ liệu có cấu trúc. Chúng tôi phát triển một giao diện để thu thập prompt từ các cộng tác viên công cộng đã tạo điều kiện cho việc thu thập một hỗn hợp đa nhiệm vụ lớn với nhiều prompt cho mỗi bộ dữ liệu (Bach et al., 2022). Sau đó chúng tôi huấn luyện một biến thể của mô hình encoder-decoder T5 (Raffel et al., 2020; Lester et al., 2021) trên một tập con các nhiệm vụ (mỗi nhiệm vụ có nhiều bộ dữ liệu) và sau đó đánh giá các nhiệm vụ và prompt mà mô hình không được huấn luyện.

Các thí nghiệm của chúng tôi nghiên cứu hai câu hỏi. Thứ nhất, liệu huấn luyện prompt đa nhiệm vụ có cải thiện khả năng tổng quát hóa cho các nhiệm vụ chưa gặp không? Thứ hai, liệu huấn luyện trên một phạm vi rộng hơn các prompt có cải thiện tính mạnh mẽ đối với cách diễn đạt prompt không? Đối với câu hỏi đầu tiên, chúng tôi thấy rằng huấn luyện đa nhiệm vụ cho phép tổng quát hóa nhiệm vụ zero-shot bằng cách chỉ ra rằng mô hình của chúng tôi phù hợp hoặc vượt trội hơn hiệu suất của GPT-3 (Brown et al., 2020) trên 9 trong số 11 bộ dữ liệu chưa gặp, mặc dù nhỏ hơn khoảng 16 lần. Chúng tôi cũng chỉ ra rằng mô hình cải thiện so với một mô hình ngôn ngữ cơ sở lớn trên 13 trong số 14 nhiệm vụ trong benchmark BIG-bench (BIG-bench collaboration, 2021). Đối với câu hỏi thứ hai, chúng tôi thấy rằng huấn luyện trên nhiều prompt hơn cho mỗi bộ dữ liệu liên tục cải thiện hiệu suất trung vị và giảm biến thiên của hiệu suất trên các nhiệm vụ chưa gặp. Huấn luyện trên các prompt từ một phạm vi rộng hơn các bộ dữ liệu cũng thường cải thiện hiệu suất trung vị nhưng không liên tục giảm biến thiên.

2 CÔNG TRÌNH LIÊN QUAN
Trong công trình này, chúng tôi phân biệt việc học đa nhiệm vụ ngầm trong tiền huấn luyện mô hình ngôn ngữ với việc học đa nhiệm vụ rõ ràng (Caruana, 1997), kỹ thuật để trộn nhiều nhiệm vụ vào một quá trình huấn luyện có giám sát duy nhất. Các mô hình được huấn luyện với việc học đa nhiệm vụ từ lâu đã được chỉ ra có hiệu suất cải thiện trong NLP (Collobert và Weston, 2008). Vì các nhiệm vụ khác nhau có đầu ra khác nhau, việc áp dụng học đa nhiệm vụ đòi hỏi một định dạng chung, và nhiều định dạng khác nhau đã được sử dụng (Hashimoto et al., 2016; McCann et al., 2018). Một số công trình đa nhiệm vụ cũng khám phá việc tổng quát hóa few-shot và zero-shot cho các bộ dữ liệu mới với các mô hình được tiền huấn luyện lớn (ví dụ, Vu et al., 2020; Ye et al., 2021).

Prompting ngôn ngữ tự nhiên là phương pháp định dạng lại các nhiệm vụ NLP theo định dạng phản hồi ngôn ngữ tự nhiên cho đầu vào ngôn ngữ tự nhiên. Sự phát triển của các mô hình được tiền huấn luyện text-to-text như T5 (Raffel et al., 2020) khiến các prompt trở thành một phương pháp đặc biệt hữu ích cho việc học đa nhiệm vụ. Ví dụ, Khashabi et al. (2020a) định dạng lại 20 bộ dữ liệu trả lời câu hỏi thành một prompt duy nhất là câu hỏi: ... (A)... (B)... (C)... ngữ cảnh: ..., trong khi các công trình sau đó như Zhong et al. (2021) và Wang et al. (2021) đưa một loạt các bộ dữ liệu vào một prompt QA boolean duy nhất hoặc một prompt NLI duy nhất, tương ứng. Mặc dù hiệu quả, những phương pháp prompt đơn này thường không tổng quát hóa cho các prompt mới hoặc các nhiệm vụ mới không thể biểu đạt được trong định dạng cố định của chúng.

Tổng quát hơn, Schick và Schütze (2021) và Brown et al. (2020) đã phổ biến việc sử dụng prompt như một phương pháp chung cho tất cả các nhiệm vụ NLP. Mishra et al. (2021) mở rộng thêm cách tiếp cận này cho một thiết lập đa nhiệm vụ, huấn luyện trên các prompt cho 61 nhiệm vụ được định nghĩa hẹp (ví dụ, tạo câu hỏi, tạo câu trả lời sai) được điều chỉnh từ hướng dẫn crowdsourcing của 9 bộ dữ liệu, trong khi chúng tôi huấn luyện và đo lường khả năng tổng quát hóa trên 62 bộ dữ liệu và 12 nhiệm vụ như được định nghĩa truyền thống trong văn học NLP (§3). Ngoài ra, các prompt của họ bao gồm các ví dụ được gắn nhãn ngoài hướng dẫn, trong khi chúng tôi tập trung vào tổng quát hóa zero-shot. Cuối cùng, công trình đồng thời của Wei et al. (2021) chia sẻ một câu hỏi nghiên cứu tương tự với chúng tôi, mặc dù chúng tôi khác nhau trong một số khía cạnh quan trọng, ví dụ, tính đa dạng prompt, quy mô mô hình và sơ đồ nhiệm vụ chưa gặp. Chúng tôi thảo luận về sự khác biệt của chúng tôi chi tiết trong Phần 7.

Cuối cùng, trong việc giải thích sự thành công của các prompt, giả thuyết hàng đầu là các mô hình học hiểu các prompt như hướng dẫn nhiệm vụ giúp chúng tổng quát hóa cho các nhiệm vụ chưa gặp (Wei et al., 2021; Mishra et al., 2021; Schick và Schütze, 2021; Brown et al., 2020). Tuy nhiên, mức độ mà sự thành công này phụ thuộc vào tính có ý nghĩa ngữ nghĩa của các prompt đã bị thách thức (Webson và Pavlick, 2021; Logan et al., 2021). Do đó, trong công trình này, chúng tôi giữ thái độ không định kiến về lý do tại sao các prompt hỗ trợ tổng quát hóa. Chúng tôi chỉ khẳng định rằng các prompt phục vụ như một định dạng tự nhiên cho huấn luyện đa nhiệm vụ mà thực nghiệm hỗ trợ tổng quát hóa cho các nhiệm vụ chưa gặp.

3 ĐO LƯỜNG TỔNG QUÁT HÓA CHO CÁC NHIỆM VỤ CHƯA GẶP
Chúng tôi bắt đầu bằng cách giả định một phân vùng cơ bản của các bộ dữ liệu NLP thành các nhiệm vụ. Chúng tôi sử dụng thuật ngữ "nhiệm vụ" để chỉ một khả năng NLP chung được kiểm tra bởi một nhóm các bộ dữ liệu cụ thể. Để đánh giá khả năng tổng quát hóa zero-shot cho các nhiệm vụ mới, chúng tôi huấn luyện trên một tập con các nhiệm vụ và đánh giá trên một nhóm các nhiệm vụ chưa gặp.

Thật không may, việc phân loại nhiệm vụ NLP là mờ nhạt, đặc biệt nếu người ta cố gắng cô lập một kỹ năng duy nhất. Ví dụ, nhiều bộ dữ liệu đánh giá kiến thức thường thức, và một số công trình đa nhiệm vụ (ví dụ, Brown et al., 2020; Wei et al., 2021) định nghĩa thường thức như một nhiệm vụ độc lập. Tuy nhiên, các bộ dữ liệu thường thức khác nhau rất lớn, từ kiến thức bẩm sinh và khoa học tiểu học đến hướng dẫn DIY, chuẩn mực văn hóa Hoa Kỳ, và các định lý cấp độ tốt nghiệp (xem Phụ lục D.1 để thảo luận chi tiết).

Lưu ý rằng việc nhóm theo nhiệm vụ là một phương pháp heuristic không hoàn hảo, chúng tôi nghiêng về việc tổ chức phân loại nhiệm vụ của chúng tôi theo định dạng nhiệm vụ thay vì kỹ năng yêu cầu dựa trên các quy ước trong văn học (Khashabi et al., 2020b; Vu et al., 2020; Ye et al., 2021). Chúng tôi thu thập tất cả các bộ dữ liệu từ

--- TRANG 3 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022

Tóm tắt Cảm xúc
Nhận dạng
Paraphrase
Giải quyết
Đồng tham chiếu
QQPMRPC
PAWSYelpRotten TomatoesApp Reviews
IMDBAmazon
Phân loại chủ đề
AG News
DBPedia
TRECCấu trúc-Sang-Văn bản
Wiki BioCommon Gen
MultiNewsGigaword
XSumSamSumCNN Daily MailQA Sách đóng
Hotpot QA
Wiki QA
QA Trích xuất
ROPESAdversarial QA
DuoRCQA Nhiều lựa chọn
CommonsenseQA
DREAM
QuAIL
QuaRTz
Social IQA
Cosmos QA
QASCWiQA
SciQQuaRelCOPAHoàn thành câu
HellaSwag
Story Cloze
Suy luận ngôn ngữ
tự nhiên
ANLI
CB
RTE
WSC
Winogrande
Phân biệt nghĩa từ
WiCQuorefWiki HopBIG-Bench
Mô tả mã
Khái niệm
Kiến thức Hindu
Những điều chưa biết
ID ngôn ngữ
Lưới logic
Suy luận logic
Quan niệm sai lầm
Hội thoại phim
Khái niệm mới
Strategy QA
Tam đoạn luận
Vitamin C
Winowhy

Hình 2: Các bộ dữ liệu và phân loại nhiệm vụ của T0. (T0+ và T0++ được huấn luyện trên các bộ dữ liệu bổ sung. Xem Bảng 5 để biết danh sách đầy đủ.) Màu sắc biểu thị mức độ giám sát. Các bộ dữ liệu màu vàng có trong hỗn hợp huấn luyện. Các bộ dữ liệu màu xanh lá cây được giữ lại và đại diện cho các nhiệm vụ không được nhìn thấy trong quá trình huấn luyện. Hotpot QA được chuyển đổi thành QA sách đóng do chiều dài đầu vào dài.

những bài báo này và loại trừ những bộ không bằng tiếng Anh (điều này cũng loại trừ các ngôn ngữ lập trình và chú thích có cấu trúc như cây phân tích cú pháp) hoặc nếu chúng yêu cầu kiến thức chuyên môn đặc biệt (ví dụ, y sinh học). Điều này tạo ra 12 nhiệm vụ và 62 bộ dữ liệu với các prompt được đóng góp công khai trong hỗn hợp huấn luyện và đánh giá của chúng tôi (Hình 2) tại thời điểm viết. Tất cả các thí nghiệm sử dụng các bộ dữ liệu trong thư viện datasets của Hugging Face (Lhoest et al., 2021).

Để kiểm tra khả năng tổng quát hóa zero-shot, chúng tôi giữ lại tất cả các bộ dữ liệu thành phần của bốn nhiệm vụ: suy luận ngôn ngữ tự nhiên (NLI), giải quyết đồng tham chiếu, hoàn thành câu, và phân biệt nghĩa từ. Chúng tôi chọn NLI như một nhiệm vụ chưa gặp vì con người cũng tổng quát hóa zero-shot cho NLI như một nhiệm vụ chưa gặp: Hầu hết con người không bao giờ được huấn luyện rõ ràng để phân loại liệu một câu tiền đề có kéo theo hoặc mâu thuẫn với một câu giả thuyết, nhưng họ thấy việc thực hiện nhiệm vụ này một cách trực quan mà không cần huấn luyện (Williams et al., 2020). Vì lý do tương tự, chúng tôi cũng giữ lại giải quyết đồng tham chiếu và phân biệt nghĩa từ. Chúng tôi giữ lại thêm hoàn thành câu vì đó là một nhiệm vụ có thể quá tương tự với NLI (Phụ lục D.2 thảo luận chi tiết về điều này). Ngoài ra, chúng tôi không huấn luyện mô hình chính của chúng tôi trên bất kỳ bộ dữ liệu nào mà Brown et al. (2020) đã sử dụng để đánh giá, để kết quả chính của chúng tôi sẽ là một so sánh zero-shot công bằng. Chúng tôi cũng xác minh rằng dữ liệu cho những nhiệm vụ đó không bị rò rỉ qua corpus tiền huấn luyện (Phụ lục E).

Cuối cùng, chúng tôi đánh giá thêm trên một tập con các bộ dữ liệu từ BIG-bench, là một benchmark gần đây do cộng đồng thúc đẩy để tạo ra một bộ sưu tập đa dạng các nhiệm vụ khó để kiểm tra khả năng của các mô hình ngôn ngữ lớn. Tập con của BIG-bench bao gồm một lựa chọn định hướng ngôn ngữ của các nhiệm vụ mà những người duy trì BIG-bench đã chuẩn bị kết quả sơ bộ và tạo thành văn bản trong từ vựng cho tokenizer T5 (tức là chỉ chứa văn bản tiếng Anh không có emoji hoặc ký tự đặc biệt khác). Tất cả các nhiệm vụ từ BIG-bench là những nhiệm vụ mới được giữ lại khỏi huấn luyện của chúng tôi.

4 ĐỊNH DẠNG PROMPT THỐNG NHẤT
Tất cả các bộ dữ liệu được đưa cho mô hình của chúng tôi dưới dạng prompt ngôn ngữ tự nhiên để cho phép thí nghiệm zero-shot. Để tạo điều kiện viết một bộ sưu tập lớn các prompt, chúng tôi phát triển một ngôn ngữ mẫu và một ứng dụng giúp dễ dàng chuyển đổi các bộ dữ liệu đa dạng thành các prompt. Chúng tôi định nghĩa một prompt bao gồm một mẫu đầu vào và một mẫu mục tiêu, cùng với một bộ sưu tập metadata liên quan. Các mẫu là các hàm ánh xạ một ví dụ dữ liệu thành ngôn ngữ tự nhiên cho các chuỗi đầu vào và mục tiêu. Về mặt thực tế, các mẫu cho phép người dùng trộn văn bản tùy ý với các trường dữ liệu,

--- TRANG 4 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022

Tài liệu Bức tranh xuất hiện trên tường của một 
cửa hàng Poundland trên đường Whymark Avenue... 
Tóm tắt Nghệ sĩ graffiti Banksy được cho là đứng 
sau... Tài liệu Bức tranh xuất hiện trên tường của một 
cửa hàng Poundland trên đường Whymark Avenue... 
Tóm tắt Nghệ sĩ graffiti Banksy được cho là đứng 
sau... Tài liệu Bức tranh xuất hiện trên tường của một 
cửa hàng Poundland trên đường Whymark Avenue... 
Tóm tắt Nghệ sĩ graffiti Banksy được cho là đứng 
sau... QQP (Paraphrase) XSum (Summary) 
{Question1} {Question2}  
Chọn một: Những câu hỏi này 
là duplicates hoặc not 
duplicates. 
Tôi nhận được các câu hỏi 
"{Question1}" và 
"{Question2}". Chúng có phải 
là duplicates không? 
{Choices[label]} {Document} 
Bạn sẽ diễn đạt lại 
điều đó như thế nào 
bằng vài từ? Đầu tiên, hãy đọc bài viết: 
{Document} 
Bây giờ, bạn có thể viết cho tôi 
một bản tóm tắt cực kỳ ngắn gọn không? 
{Summary} Question1 Giao thông hàng không được kiểm soát như thế nào? 
Question2 Làm thế nào để trở thành nhân viên kiểm soát không lưu? 
Label 0Question1 Giao thông hàng không được kiểm soát như thế nào? 
Question2 Làm thế nào để trở thành nhân viên kiểm soát không lưu? 
Label 0Question1 Giao thông hàng không được kiểm soát như thế nào? 
Question2 Làm thế nào để trở thành nhân viên kiểm soát không lưu? 
Label 0Question1 Giao thông hàng không được kiểm soát như thế nào? 
Question2 Làm thế nào để trở thành nhân viên kiểm soát không lưu? 
Label 0Tài liệu Bức tranh xuất hiện trên tường của một 
cửa hàng Poundland trên đường Whymark Avenue... 
Tóm tắt Nghệ sĩ graffiti Banksy được cho là đứng 
sau... 
{Choices[label]} {Summary} 

Hình 3: Các mẫu prompt từ bộ sưu tập prompt P3. Mỗi bộ dữ liệu có nhiều mẫu prompt bao gồm một mẫu đầu vào và một mẫu mục tiêu. Những mẫu này sử dụng các trường của các ví dụ dữ liệu thô cũng như metadata mẫu, ví dụ, các prompt nhận dạng paraphrase bên trái sử dụng Choices, một biến danh sách cấp độ mẫu ['Not duplicates', 'Duplicates']. Những mẫu này được vật chất hóa để tạo ra trường hợp được prompt hóa được hiển thị trong Hình 1. Tập hợp đầy đủ các mẫu prompt được sử dụng trong T0 được đưa ra trong Phụ lục G.

metadata, và mã khác để kết xuất và định dạng các trường thô. Ví dụ, trong trường hợp của một bộ dữ liệu NLI, ví dụ sẽ bao gồm các trường cho Premise, Hypothesis, Label. Một mẫu đầu vào sẽ là Nếu {Premise} là đúng, liệu cũng đúng rằng {Hypothesis}?, trong khi một mẫu mục tiêu có thể được định nghĩa với các lựa chọn nhãn {Choices[label]}. Ở đây Choices là metadata cụ thể của prompt bao gồm các tùy chọn có, có thể, không tương ứng với label là entailment (0), neutral (1) hoặc contradiction (2). Metadata khác ghi lại các thuộc tính bổ sung, chẳng hạn như một số liệu đánh giá. Mỗi ví dụ dữ liệu được vật chất hóa với nhiều mẫu prompt khác nhau như được hiển thị trong Hình 3.

Để phát triển các prompt, chúng tôi đã xây dựng một giao diện để viết các prompt một cách tương tác trên các bộ dữ liệu. Chúng tôi đưa ra một lời kêu gọi mở trong cộng đồng nghiên cứu để người dùng đóng góp các prompt. 36 cộng tác viên liên kết với 24 tổ chức ở 8 quốc gia đã tham gia. Vì mục tiêu của chúng tôi là huấn luyện một mô hình mạnh mẽ đối với định dạng prompt, và vì câu hỏi về điều gì khiến một prompt hiệu quả vẫn chưa được giải quyết (Webson và Pavlick, 2021; Logan et al., 2021; Zhao et al., 2021), chúng tôi khuyến khích các cộng tác viên mở trong phong cách của họ và tạo ra một tập hợp các prompt đa dạng. Hướng dẫn chú thích chính là các prompt cần phải có ngữ pháp và có thể hiểu được bởi một người nói tiếng Anh thành thạo không có kinh nghiệm trước về các nhiệm vụ. Ngoài ra, các prompt yêu cầu đếm rõ ràng hoặc lập chỉ mục số đã được loại bỏ để ưu tiên các biến thể ngôn ngữ tự nhiên. Ví dụ, thay vì dự đoán chỉ số của một span trích xuất câu trả lời từ một đoạn văn, mô hình được kỳ vọng sao chép văn bản của span thay thế. Với những ràng buộc tối thiểu này, các người viết prompt được khuyến khích sử dụng cả prompt chính thức và sáng tạo và các thứ tự khác nhau của dữ liệu.

Hầu hết các prompt tương ứng trực tiếp với một phiên bản của nhiệm vụ ban đầu được đề xuất, mặc dù chúng tôi cũng cho phép các prompt hoán vị nhiệm vụ ban đầu (chẳng hạn, tạo tài liệu từ bản tóm tắt của nó). Những prompt không phải nhiệm vụ ban đầu như vậy được bao gồm trong hỗn hợp huấn luyện của chúng tôi để cải thiện tính đa dạng, nhưng chúng không được báo cáo trong đánh giá vì chúng lệch khỏi các số liệu và đường cơ sở được báo cáo bởi các bộ dữ liệu ban đầu.

Chi tiết về ngôn ngữ prompt và công cụ được đưa ra trong Phụ lục C và Bach et al. (2022), và bản thân các prompt được đưa ra trong Phụ lục G. Chúng tôi đã thu thập các prompt cho các bộ dữ liệu tiếng Anh, loại trừ những bộ bao gồm nội dung có thể có hại hoặc ngôn ngữ không tự nhiên như ngôn ngữ lập trình. Chúng tôi gọi bộ sưu tập này là Public Pool of Prompts (P3). Tại thời điểm viết, P3 chứa 2073 prompt cho 177 bộ dữ liệu (trung bình 11.7 prompt cho mỗi bộ dữ liệu). Các prompt được sử dụng trong thí nghiệm đều được lấy từ P3 ngoại trừ BIG-bench, các prompt của BIG-bench được cung cấp bởi những người duy trì của nó.

5 THIẾT LẬP THÍ NGHIỆM
Mô hình Ở cấp độ cao, chúng tôi tinh chỉnh một mô hình được tiền huấn luyện trên hỗn hợp huấn luyện đa nhiệm vụ của các bộ dữ liệu được prompt hóa ngôn ngữ tự nhiên. Mô hình của chúng tôi sử dụng kiến trúc encoder-decoder với văn bản đầu vào được đưa vào encoder và văn bản mục tiêu được tạo ra bởi decoder. Mô hình được huấn luyện để tự động tạo ra mục tiêu thông qua huấn luyện maximum likelihood tiêu chuẩn. Không giống như các mô hình ngôn ngữ chỉ có decoder như GPT-3, nó không bao giờ được huấn luyện để tạo ra đầu vào.

Tất cả các mô hình chúng tôi huấn luyện đều dựa trên T5, một mô hình ngôn ngữ encoder-decoder dựa trên Transformer được tiền huấn luyện với mục tiêu giống như mô hình hóa ngôn ngữ có mặt nạ trên 1T token từ C4 (Raffel et al., 2020). Vì mục tiêu tiền huấn luyện của T5 là tạo token và chỉ những token đã bị loại bỏ khỏi văn bản đầu vào, nó khác với định dạng tạo văn bản tự nhiên của các bộ dữ liệu được prompt hóa. Do đó, chúng tôi sử dụng mô hình T5 được điều chỉnh LM của Lester et al. (2021) (được gọi là T5+LM), được tạo ra bằng cách huấn luyện T5 trên 100B token bổ sung từ C4 trên mục tiêu mô hình hóa ngôn ngữ tiêu chuẩn.

Huấn luyện Mô hình chính của chúng tôi, T0, được huấn luyện trên hỗn hợp đa nhiệm vụ được chi tiết trong Phần 3 và Bảng 5. Trong khi đó, T0+ là cùng một mô hình với các siêu tham số giống hệt nhau ngoại trừ được huấn luyện trên một hỗn hợp thêm các bộ dữ liệu đánh giá của GPT-3. Cuối cùng, T0++ thêm SuperGLUE (Wang et al., 2019a) vào hỗn hợp huấn luyện (ngoại trừ RTE và CB), điều này để lại NLI và các nhiệm vụ BIG-bench là những nhiệm vụ chưa gặp duy nhất.

Các biến thể T0 ở trên đều được khởi tạo từ phiên bản 11B tham số của T5+LM. Để nghiên cứu hiệu ứng của việc mở rộng quy mô và hỗ trợ các nhà nghiên cứu có ít tài nguyên hơn, chúng tôi cũng huấn luyện T0 (3B), có cùng hỗn hợp huấn luyện như T0 nhưng được khởi tạo từ phiên bản 3B tham số của T5+LM (kết quả được báo cáo trong Phụ lục F).

Chúng tôi thực hiện lựa chọn checkpoint bằng cách chọn checkpoint mang lại điểm số cao nhất trên các tập validation của các bộ dữ liệu huấn luyện của chúng tôi. Điều này vẫn thỏa mãn thiết lập zero-shot thực sự (Perez et al., 2021) vì chúng tôi không sử dụng bất kỳ ví dụ nào từ bất kỳ nhiệm vụ chưa gặp nào để chọn checkpoint tốt nhất.

Chúng tôi lắp ráp hỗn hợp huấn luyện đa nhiệm vụ của chúng tôi bằng cách kết hợp và xáo trộn tất cả các ví dụ từ tất cả các bộ dữ liệu huấn luyện. Điều này tương đương với việc lấy mẫu từ mỗi bộ dữ liệu theo tỷ lệ với số lượng ví dụ trong bộ dữ liệu. Tuy nhiên, số lượng ví dụ trong mỗi bộ dữ liệu huấn luyện của chúng tôi thay đổi hai bậc độ lớn. Do đó chúng tôi tuân theo chiến lược được sử dụng trong Raffel et al. (2020) và coi bất kỳ bộ dữ liệu nào có hơn 500'000 ví dụ như có 500'000 / num_templates ví dụ cho mục đích lấy mẫu, trong đó num_templates là số lượng mẫu được tạo cho bộ dữ liệu.

Chúng tôi cắt ngắn các chuỗi đầu vào và mục tiêu lần lượt thành 1024 và 256 token. Theo Raffel et al. (2020), chúng tôi sử dụng packing để kết hợp nhiều ví dụ huấn luyện thành một chuỗi duy nhất để đạt được độ dài chuỗi tối đa. Chúng tôi sử dụng kích thước batch là 1024 chuỗi (tương ứng với tổng cộng 2^20 token đầu vào cho mỗi batch) và optimizer Adafactor (Shazeer và Stern, 2018). Theo thực hành tiêu chuẩn để tinh chỉnh T5, chúng tôi sử dụng tốc độ học 1e-3 và tỷ lệ dropout 0.1.

Đánh giá Chúng tôi đánh giá khả năng tổng quát hóa zero-shot trên 11 bộ dữ liệu trong 4 nhiệm vụ NLP truyền thống chưa gặp: suy luận ngôn ngữ tự nhiên, đồng tham chiếu, phân biệt nghĩa từ, và hoàn thành câu, cũng như 14 nhiệm vụ mới từ BIG-bench (§3). Trừ khi được chỉ định khác, chúng tôi báo cáo hiệu suất trên các tập validation. Tất cả các bộ dữ liệu được báo cáo sử dụng độ chính xác làm số liệu của chúng.

Đối với các nhiệm vụ liên quan đến việc chọn hoàn thành đúng từ nhiều tùy chọn (ví dụ trả lời câu hỏi nhiều lựa chọn), chúng tôi tuân theo Brown et al. (2020) và sử dụng phân loại xếp hạng để đánh giá mô hình của chúng tôi: chúng tôi tính log-likelihood của mỗi tùy chọn mục tiêu dưới mô hình được tinh chỉnh và chọn tùy chọn có log-likelihood cao nhất làm dự đoán. Để đơn giản, chúng tôi không áp dụng chuẩn hóa độ dài cho log-likelihood của các tùy chọn mục tiêu.

Chúng tôi không thực hiện lựa chọn prompt bằng cách so sánh hiệu suất của các prompt khác nhau trên tập validation; Perez et al. (2021) nhấn mạnh cách một chiến lược như vậy làm rò rỉ thông tin từ các tập đánh giá, điều này khiến việc đánh giá không "thực sự" zero-shot. Đối với một bộ dữ liệu nhất định, chúng tôi báo cáo hiệu suất trung vị trên tất cả các prompt cho bộ dữ liệu này cùng với khoảng tứ phân vị của chúng (Q3 - Q1) để đo lường tính mạnh mẽ của mô hình đối với cách diễn đạt của các prompt.

6 KẾT QUẢ
6.1 TỔNG QUÁT HÓA CHO CÁC NHIỆM VỤ CHƯA GẶP
Câu hỏi nghiên cứu đầu tiên của chúng tôi là liệu huấn luyện prompt đa nhiệm vụ có cải thiện khả năng tổng quát hóa cho các nhiệm vụ chưa gặp không. Trong Hình 4, chúng tôi so sánh T0 với đường cơ sở T5+LM của chúng tôi trên bốn nhiệm vụ chưa gặp. Phương pháp của chúng tôi

--- TRANG 5 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022

020406080
020406080
01020304050
01020304050
01020304050
020406080
020406080
020406080100
020406080100
020406080100
020406080

GPT-3 (6.7B)
 GPT-3 (13B)
 GPT-3 (175B)
 T5+LM (1 1B)
 T0 (1 1B)

RTE CB ANLI R1 ANLI R2 ANLI R3
WSC Winogrande COPA StoryCloze HellaSwag WiC

Suy luận ngôn ngữ tự nhiên
Giải quyết đồng tham chiếu Hoàn thành câu Phân biệt nghĩa từ

Hình 4: Kết quả cho các thí nghiệm tổng quát hóa nhiệm vụ T0 so với GPT-3 (Brown et al., 2020). Mỗi điểm là hiệu suất của một prompt đánh giá. Mô hình cơ sở T5+LM giống như T0 ngoại trừ không có huấn luyện prompt đa nhiệm vụ. GPT-3 chỉ báo cáo một prompt duy nhất cho mỗi bộ dữ liệu.

dẫn đến những cải thiện đáng kể so với đường cơ sở của chúng tôi trên tất cả các bộ dữ liệu, chứng minh lợi ích của huấn luyện prompt đa nhiệm vụ so với chỉ huấn luyện mô hình hóa ngôn ngữ với một mô hình và prompt giống hệt nhau.

Tiếp theo, chúng tôi so sánh T0 với hiệu suất zero-shot của các mô hình ngôn ngữ lớn nhất có sẵn tại thời điểm viết, tức là các mô hình GPT-3 khác nhau lên đến 175B tham số. Lưu ý rằng Brown et al. (2020) báo cáo hiệu suất trên một prompt duy nhất², trong khi chúng tôi báo cáo hiệu suất trung vị và khoảng tứ phân vị trên tất cả các prompt trong P3 mà không chọn lọc. Chúng tôi thấy rằng T0 bằng hoặc vượt trội hơn hiệu suất của tất cả các mô hình GPT-3 trên 9 trong số 11 bộ dữ liệu chưa gặp. Đáng chú ý, cả T0 và GPT-3 đều không được huấn luyện trên suy luận ngôn ngữ tự nhiên, nhưng T0 vượt trội hơn GPT-3 trên tất cả các bộ dữ liệu NLI, mặc dù đường cơ sở T5+LM của chúng tôi thì không. Điều tương tự cũng đúng cho hầu hết các bộ dữ liệu của các nhiệm vụ chưa gặp khác. Hai ngoại lệ là Winogrande và HellaSwag, mà chúng tôi thảo luận trong Phần 7.

Để đánh giá các mô hình của chúng tôi trên nhiều nhiệm vụ chưa gặp hơn, chúng tôi đánh giá hiệu suất zero-shot của T0, T0+ và T0++ trên một tập con của BIG-bench (BIG-bench collaboration, 2021). Các nhiệm vụ từ BIG-bench bao gồm nhiều kỹ năng mới không được bao gồm trong các nhiệm vụ huấn luyện của chúng tôi, chẳng hạn như suy ra thứ tự của một chuỗi đối tượng, giải các câu đố lưới logic, và phân biệt các tuyên bố đúng khỏi những quan niệm sai lầm phổ biến. Những người duy trì BIG-bench cung cấp một prompt cho mỗi bộ dữ liệu, với đó chúng tôi so sánh các mô hình của chúng tôi với một loạt các mô hình cơ sở chẩn đoán sơ bộ được huấn luyện bởi Google và đánh giá bởi những người duy trì BIG-bench. Những mô hình này là các mô hình ngôn ngữ Transformer chỉ có decoder được huấn luyện trên một mục tiêu mô hình hóa ngôn ngữ tiêu chuẩn với kích thước mô hình khác nhau. Chúng tôi thấy rằng ít nhất một trong các biến thể T0 vượt trội hơn tất cả các mô hình cơ sở trên tất cả các nhiệm vụ ngoại trừ StrategyQA (Hình 5). Trong hầu hết các trường hợp, hiệu suất của các mô hình của chúng tôi cải thiện khi số lượng bộ dữ liệu huấn luyện tăng (tức là T0++ vượt trội hơn T0+ vượt trội hơn T0).

6.2 TÍNH MẠNH MẼ CỦA PROMPT
Câu hỏi nghiên cứu thứ hai của chúng tôi là liệu huấn luyện trên một phạm vi rộng hơn các prompt có cải thiện tính mạnh mẽ đối với cách diễn đạt của các prompt không. Chúng tôi tiến hành hai thí nghiệm ablation về hiệu ứng của số lượng prompt trung bình cho mỗi bộ dữ liệu (p) và số lượng bộ dữ liệu (d) được sử dụng trong quá trình huấn luyện.

Hiệu ứng của nhiều prompt hơn cho mỗi bộ dữ liệu Trong phân tích này, chúng tôi cố định d và so sánh T0 với các mô hình có số lượng prompt khác nhau cho mỗi bộ dữ liệu. T0 được huấn luyện trên một số prompt không ánh xạ vào nhiệm vụ ban đầu của bộ dữ liệu, ví dụ "cho một câu trả lời, tạo một câu hỏi hợp lý". Bao gồm những prompt này dẫn đến p là 8.03 trung bình (tương ứng với mô hình T0 chính của chúng tôi). Chúng tôi so sánh T0 với các mô hình trong đó p = 1 (một prompt nhiệm vụ ban đầu được chọn ngẫu nhiên cho mỗi bộ dữ liệu), p = 5.7 trung bình (tất cả các prompt nhiệm vụ ban đầu cho tất cả các bộ dữ liệu), và p = 0 (tương ứng với T5+LM không có huấn luyện prompt nào). Chúng tôi huấn luyện tất cả các mô hình với cùng siêu tham số và cùng số bước. Hình 6 cho thấy rằng, ngay cả với chỉ một prompt cho mỗi bộ dữ liệu, hiệu suất trên các nhiệm vụ chưa gặp có thể cải thiện đáng kể so với đường cơ sở không được prompt hóa, mặc dù sự phân tán (khoảng tứ phân vị giữa Q1 và Q3) không cải thiện một cách nhất quán với p = 1. Trong khi đó, việc tăng p thêm từ 1 lên trung bình 5.7 thực sự mang lại cải thiện bổ sung trong cả trung vị (tăng cho 8/11 bộ dữ liệu) và phân tán (giảm cho 7/11 bộ dữ liệu). Điều này củng cố giả thuyết của chúng tôi rằng huấn luyện trên nhiều prompt hơn cho mỗi bộ dữ liệu dẫn đến khả năng tổng quát hóa tốt hơn và mạnh mẽ hơn cho các nhiệm vụ chưa gặp. Cuối cùng, chúng tôi thấy rằng việc T0 bao gồm tất cả các prompt (bao gồm những prompt không tương ứng với nhiệm vụ ban đầu của bộ dữ liệu) cải thiện thêm trung vị (tăng cho 9/11 bộ dữ liệu) và phân tán (giảm cho 8/11 bộ dữ liệu), cho thấy rằng huấn luyện trên các prompt không phải nhiệm vụ ban đầu cũng có thể có lợi.

Hiệu ứng của prompt từ nhiều bộ dữ liệu hơn Trong thí nghiệm này, chúng tôi cố định p = tất cả các prompt có sẵn và tăng d từ 39 lên 49 lên 55 (T0, T0+, T0++, tương ứng. Xem Phần 5 để biết chi tiết.) Hình 7 cho thấy rằng hiệu suất trung vị của tất cả 5 bộ dữ liệu chưa gặp tăng khi d tăng từ 39 lên 49. Tuy nhiên, phân tán chỉ giảm cho 1 trong số 5 bộ dữ liệu. Đối với một số bộ dữ liệu (ví dụ ANLI), đây là một hiện tượng của việc một số prompt luôn hoạt động kém, do đó khi các prompt khác cải thiện, phân tán được kéo dài lớn hơn. Đối với các bộ dữ liệu khác (ví dụ CB), tuy nhiên, phân tán thực sự giảm với T0+. Khi d tăng từ 49 lên 55, hiệu suất trung vị của tất cả các bộ dữ liệu lại tăng, nhưng phân tán chỉ giảm cho 2 trong số 5 bộ dữ liệu. Mặc dù cần điều tra thêm, có vẻ như việc tăng d không làm cho mô hình mạnh mẽ hơn một cách nhất quán đối với cách diễn đạt của các prompt.

So sánh tính mạnh mẽ của T0 và GPT-3 Vì Brown et al. (2020) chỉ báo cáo một prompt cho mỗi bộ dữ liệu mà không có độ lệch chuẩn, chúng tôi đánh giá GPT-3 qua API của OpenAI³ trên RTE sử dụng cùng 10 prompt mà chúng tôi đánh giá T0 để ước tính tính mạnh mẽ của GPT-3 đối với cách diễn đạt khác nhau của các prompt. Một trong những mẫu này giống hệt với prompt được báo cáo của Brown et al. (2020, p. 59), có điểm độ chính xác là 58.8%, thấp hơn 63.5% được báo cáo trong Brown et al. (2020). Tất cả 9 prompt khác

²Các thí nghiệm của chúng tôi trong Phần 6.2 khiến chúng tôi tin rằng hiệu suất này tương ứng với prompt tốt nhất được tìm thấy sau khi điều chỉnh thủ công theo hiệu suất tập validation.

³https://beta.openai.com/ Chúng tôi sử dụng "mô hình GPT-3 cơ sở" davinci. Mặc dù OpenAI không tiết lộ mô hình nào trong các mô hình có sẵn thương mại của họ tương ứng với mô hình nào được báo cáo trong Brown et al. (2020), Gao et al. (2021) ước tính rằng davinci tương ứng với mô hình 175B.

--- TRANG 6 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022

0204060
020406080
010203040
0204060
05101520
010203040
02040
02040
02040
0102030
0204060
02040
0204060
02040

LM (8.5B) LM (28B) LM (68B) T5+LM (1 1B) T0 (1 1B) T0+ (1 1B) T0++ (1 1B)

Mô tả mã Khái niệm Kiến thức Hindu Những điều chưa biết ID ngôn ngữ Lưới logic Suy luận logic
Quan niệm sai lầm Hội thoại phim Khái niệm mới Strategy QA Tam đoạn luận Vitamin C Winowhy

Hình 5: Kết quả cho một tập con của BIG-bench có đường cơ sở sẵn có. Các mô hình cơ sở là các mô hình ngôn ngữ dựa trên Transformer được cung cấp bởi những người duy trì BIG-bench, những người cũng cung cấp một prompt cho mỗi bộ dữ liệu. T0, T0+ và T0++ giống hệt nhau ngoại trừ việc tăng số lượng bộ dữ liệu huấn luyện (§5). Các nhiệm vụ BIG-bench đều là zero-shot cho tất cả các mô hình được báo cáo.

prompt, tuy nhiên, mang lại hiệu suất gần như đoán ngẫu nhiên với độ chính xác trung vị = 52.96% và khoảng tứ phân vị = 1.28%. Những kết quả này cho thấy rằng T0 có thể mạnh mẽ hơn đối với công thức prompt so với GPT-3.

7 THẢO LUẬN
Đồng thời với công trình của chúng tôi, Wei et al. (2021) đề xuất FLAN, chia sẻ phần lớn cùng phương pháp cho phép tổng quát hóa zero-shot thông qua huấn luyện prompt đa nhiệm vụ. Với một hỗn hợp các bộ dữ liệu tương tự như của chúng tôi, họ huấn luyện nhiều mô hình ngôn ngữ chỉ có decoder, mỗi mô hình có một nhiệm vụ chưa gặp duy nhất (so với chúng tôi tập trung vào huấn luyện một mô hình với nhiều nhiệm vụ chưa gặp để đánh giá khả năng của mô hình tổng quát hóa cho các nhiệm vụ đa dạng.) So với FLAN, hiệu suất zero-shot của T0 tốt hơn trên CB và RTE, tương tự trên Story Cloze và COPA, và tệ hơn trên Winogrande và ANLI. T0++ vượt trội hơn FLAN trên CB, RTE và COPA và bằng hiệu suất của FLAN trên Winogrande và ANLI. Đáng chú ý, T0 và T0++ đạt được hiệu suất này mặc dù nhỏ hơn 10 lần so với FLAN (137B so với 11B tham số).

Cả T0 và FLAN đều hoạt động kém hơn GPT-3 trên Winogrande và HellaSwag (Sakaguchi et al., 2019; Zellers et al., 2019), mà Wei et al. (2021) phỏng đoán rằng đối với các nhiệm vụ như giải quyết đồng tham chiếu có thể được định dạng như hoàn thiện một câu không hoàn chỉnh, việc thêm hướng dẫn nhiệm vụ vào prompt là "phần lớn dư thừa". Theo phỏng đoán này, chúng tôi đánh giá lại hai bộ dữ liệu này mà không có hướng dẫn như được thực hiện bởi Wei et al. (2021) và Brown et al. (2020) và thấy rằng nó cải thiện hiệu suất trên HellaSwag từ trung vị 33.65% lên 57.93%, bằng hiệu suất của FLAN. Tuy nhiên, đối với Winogrande, việc sử dụng prompt của FLAN mà không có hướng dẫn không tạo ra sự khác biệt đáng kể (độ chính xác = 62.15%).

Thật ngạc nhiên, Wei et al. (2021) thực hiện một ablation với một mô hình có kích thước tương đương (8B tham số) với T0 (11B tham số) và thấy rằng hiệu suất trên các nhiệm vụ chưa gặp giảm sau huấn luyện prompt đa nhiệm vụ, trong khi chúng tôi thấy rằng huấn luyện prompt đa nhiệm vụ cải thiện hiệu suất của các mô hình ít nhất nhỏ đến 3B tham số (Hình 8). Chúng tôi xác định hai sự khác biệt chính giữa các mô hình có thể giải thích sự bất đồng này: Thứ nhất, chúng tôi sử dụng một mô hình encoder-decoder được tiền huấn luyện với một mục tiêu khác (mô hình hóa ngôn ngữ có mặt nạ) trước khi được huấn luyện như một mô hình ngôn ngữ tiêu chuẩn

--- TRANG 7 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022

020406080
020406080
3035404550
3035404550
3035404550
304050607080
304050607080
406080100
406080100
2025303540
40506070

p = 0 (T5+LM) p = 1 p = 5.7 p = 8.03 (T0)

RTE CB ANLI R1 ANLI R2 ANLI R3
WSC Winogrande COPA StoryCloze HellaSwag WiC

Suy luận ngôn ngữ tự nhiên
Giải quyết đồng tham chiếu Hoàn thành câu Phân biệt nghĩa từ

Hình 6: Hiệu ứng của nhiều prompt hơn cho mỗi bộ dữ liệu. Hiệu suất zero-shot của T0 và T5+LM khi tăng số lượng prompt huấn luyện cho mỗi bộ dữ liệu. Mỗi điểm là hiệu suất của một prompt đánh giá. Mô hình T0 chính (p = 8.03) bao gồm các prompt không phải nhiệm vụ ban đầu (xem Phần 3). Thêm nhiều prompt huấn luyện hơn liên tục dẫn đến hiệu suất trung vị cao hơn và thường là khoảng tứ phân vị thấp hơn cho các nhiệm vụ chưa gặp.

ngôn ngữ và cuối cùng được tinh chỉnh trên hỗn hợp đa nhiệm vụ. Chúng tôi lưu ý rằng mô hình hóa ngôn ngữ có mặt nạ đã được chỉ ra nhiều lần là một chiến lược tiền huấn luyện hiệu quả hơn đáng kể (Raffel et al., 2020; Baevski et al., 2019; Devlin et al., 2019).

Thứ hai, các prompt của chúng tôi đa dạng hơn về chất lượng về độ dài và tính sáng tạo (§4). Ví dụ, hãy xem xét một trong những prompt của chúng tôi cho Quora Question Pairs (nhận dạng paraphrase): Tôi là một quản trị viên trên trang web Quora. Có hai bài đăng, một bài hỏi "question1" và một bài khác hỏi "question2". Tôi có thể gộp các câu hỏi nếu chúng hỏi cùng một điều. Tôi có thể gộp hai câu hỏi này không? Chúng tôi đưa ra giả thuyết rằng sự đa dạng này có thể có những hiệu ứng cụ thể. Ví dụ, nó có thể giải thích tại sao Wei et al. (2021) trình bày kết quả ablation trong đó việc tăng số lượng prompt có tác động không đáng kể đến hiệu suất trong khi chúng tôi quan sát thấy cải thiện khi thêm nhiều prompt hơn (§6.2). Chúng tôi để lại một điều tra đầy đủ về tác động của những sự khác biệt này cho công việc tương lai.

8 KẾT LUẬN
Chúng tôi chứng minh rằng huấn luyện prompt đa nhiệm vụ có thể cho phép khả năng tổng quát hóa zero-shot mạnh mẽ trong các mô hình ngôn ngữ. Cách tiếp cận này cung cấp một giải pháp thay thế hiệu quả cho tiền huấn luyện mô hình ngôn ngữ không giám sát, thường cho phép mô hình T0 của chúng tôi vượt trội hơn các mô hình lớn gấp nhiều lần kích thước của nó. Chúng tôi cũng thực hiện các nghiên cứu ablation chứng minh tầm quan trọng của việc bao gồm nhiều prompt đa dạng và tác động của việc tăng số lượng bộ dữ liệu trong mỗi nhiệm vụ. Để cho phép công việc tương lai về cải thiện tổng quát hóa zero-shot, chúng tôi phát hành tất cả các mô hình được huấn luyện trong bài báo này ngoài bộ sưu tập các prompt mà chúng tôi đã tạo và công cụ chú thích prompt của chúng tôi.

LỜI CẢM ƠN
Công trình này được cấp quyền truy cập vào các tài nguyên HPC của Institut du développement et des ressources en informatique scientifique (IDRIS) du Centre national de la recherche scientifique (CNRS) dưới phân bổ 2021-A0101012475 được thực hiện bởi Grand équipement national de calcul intensif (GENCI). Đặc biệt, tất cả các đánh giá và xử lý dữ liệu đã chạy trên cụm Jean-Zay của IDRIS, và chúng tôi muốn cảm ơn đội ngũ IDRIS vì sự hỗ trợ nhanh chóng trong suốt dự án, đặc biệt là Rémi Lacroix.

Chúng tôi biết ơn chương trình TPU Research Cloud đã hào phóng cung cấp tín dụng TPU cho Hugging Face. Những tín dụng đó đã được sử dụng để huấn luyện tất cả các mô hình từ bài báo này.

Công trình này được tài trợ một phần bởi các ghế của Rachel Bawden và Benoît Sagot trong viện PRAIRIE được tài trợ bởi cơ quan quốc gia Pháp ANR như một phần của chương trình "Investissements d'avenir" dưới tham chiếu ANR-19-P3IA-0001. Tiết lộ: Stephen Bach đã đóng góp cho công trình này với tư cách là cố vấn cho Snorkel AI.

Chúng tôi cảm ơn Yacine Jernite, Sasha Luccioni, Aurélie Névéol và Huu Nguyen vì đã tư vấn về các chiến lược để xử lý các bộ dữ liệu chứa nội dung có thể có hại. Guy Gur-Ari và Ethan Dyer cung cấp hỗ trợ và kết quả sơ bộ về đánh giá BIG-bench. Chúng tôi cảm ơn Ruiqi Zhong vì những thảo luận sớm về dự án này.

--- TRANG 8 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2022

020406080
020406080
3035404550
3035404550
3035404550

T0 (d = 39) T0+ (d = 49) T0++ (d = 55)

RTE CB ANLI R1 ANLI R2 ANLI R3

Hình 7: Hiệu ứng của prompt từ nhiều bộ dữ liệu hơn. Hiệu suất zero-shot của ba mô hình với số lượng bộ dữ liệu khác nhau (T0, T0+, T0++). Thêm nhiều bộ dữ liệu hơn liên tục dẫn đến hiệu suất trung vị cao hơn nhưng không phải lúc nào cũng giảm khoảng tứ phân vị cho các nhiệm vụ chưa gặp.

dẫn đến tăng trưởng hiệu suất đáng kể trong khi vẫn tôn trọng giới hạn máy chủ:

#### Tuân thủ giới hạn tốc độ ArXiv ⚠️
- **QUAN TRỌNG**: ArXiv chỉ cho phép **1 kết nối đồng thời** và **độ trễ 3+ giây**
- **Cài đặt mặc định**: 1 worker, độ trễ 3-3.5s để tuân thủ chính sách ArXiv
- **Rủi ro vi phạm**: Chặn IP, lỗi yêu cầu, từ chối dịch vụ
- **Chính sách chính thức**: "không thực hiện hơn một yêu cầu mỗi ba giây"

#### Cân nhận hiệu suất
- **Các tính năng nâng cao**: Xử lý lỗi tốt hơn, theo dõi tiến trình, tính bền vững JSON
- **Xử lý async**: I/O không chặn để quản lý bộ sưu tập
- **Thử lại thông minh**: Tự động backoff khi có lỗi máy chủ
- **Tính toàn vẹn tệp**: Xử lý tệp tạm thời để ngăn hỏng

#### Cấu hình giới hạn tốc độ
- **Trình tải xuống Python**: Độ trễ 3-3.5s giữa các lần tải xuống (tuân thủ ArXiv)
- **Orchestrator**: Xử lý bộ sưu tập tuần tự với độ trễ phù hợp
- **Script shell**: Độ trễ 3 giây (có thể cấu hình qua `SLEEP_BETWEEN_DOWNLOADS`)
- **Thích ứng**: Tự động backoff khi có lỗi máy chủ

#### Khuyến nghị sử dụng an toàn
- **Luôn sử dụng**: Chỉ 1 worker (mặc định)
- **Tôn trọng độ trễ**: 3+ giây giữa các yêu cầu
- **Giám sát**: Theo dõi lỗi 429/403 cho biết giới hạn tốc độ
- **Kiên nhẫn**: Tuân thủ ArXiv có nghĩa là tải xuống chậm hơn nhưng đáng tin cậy

## Tổ chức tệp

Các bài báo được tự động tổ chức theo chủ đề nghiên cứu thông qua cấu trúc thư mục được tạo bởi tên tệp đầu vào. Điều này cho phép phân loại và truy xuất dễ dàng các bài báo theo lĩnh vực chủ đề.

### Tổ chức bài báo tự động
Hệ thống tổ chức nâng cao đảm bảo các bài báo được đặt trong các thư mục bộ sưu tập đúng:

1. **Phát hiện bộ sưu tập**: Tự động quét tất cả các thư mục con để tìm tệp `arxiv_links.txt`
2. **Khớp bài báo**: Trích xuất ID arXiv từ URL và tìm các tệp PDF tương ứng
3. **Di chuyển thông minh**: Xác định các bài báo đặt sai chỗ và di chuyển chúng đến bộ sưu tập đúng
4. **Kiểm tra tính toàn vẹn**: Xác minh mỗi bộ sưu tập với tệp `arxiv_links.txt` của nó
5. **Báo cáo toàn diện**: Cung cấp thống kê chi tiết về tính đầy đủ của bộ sưu tập

### Quy trình tổ chức
```bash
# Bước 1: Kiểm tra trạng thái tổ chức hiện tại
python3 check_and_move_papers_enhanced.py --verbose

# Bước 2: Xem lại những gì sẽ được di chuyển (chạy thử)
python3 check_and_move_papers_enhanced.py --collections multimodal rag

# Bước 3: Thực hiện tổ chức với logging
python3 check_and_move_papers_enhanced.py --execute --log-file organization.log

# Bước 4: Xác minh tổ chức hoàn thành thành công
python3 check_and_move_papers_enhanced.py --log-level WARNING
```

### Theo dõi tính đầy đủ bộ sưu tập
- **Tỷ lệ hoàn thành**: Phần trăm các bài báo mong đợi có mặt trong mỗi bộ sưu tập
- **Bài báo thiếu**: Các bài báo được liệt kê trong `arxiv_links.txt` nhưng không tìm thấy trong thư mục bộ sưu tập
- **Bài báo thừa**: Các bài báo trong thư mục bộ sưu tập nhưng không được liệt kê trong `arxiv_links.txt`
- **Tìm kiếm toàn cục**: Tự động phát hiện các bài báo đặt sai chỗ trên tất cả các bộ sưu tập

TÀI LIỆU THAM KHẢO

Stephen H. Bach, Victor Sanh, Zheng-Xin Yong, Albert Webson, Colin Raffel, Nihal V. Nayak, Abheesht Sharma, Taewoon Kim, M Saiful Bari, Thibault Fevry, Zaid Alyafeai, Manan Dey, Andrea Santilli, Zhiqing Sun, Srulik Ben-David, Canwen Xu, Gunjan Chhablani, Han Wang, Jason Alan Fries, Maged S. Al-shaibani, Shanya Sharma, Urmish Thakker, Khalid Almubarak, Xiangru Tang, Xiangru Tang, Mike Tian-Jian Jiang, và Alexander M. Rush. Promptsource: An integrated development environment and repository for natural language prompts, 2022.

Alexei Baevski, Sergey Edunov, Yinhan Liu, Luke Zettlemoyer, và Michael Auli. Cloze-driven pretraining of self-attention networks. arXiv preprint arXiv:1903.07785, 2019.

Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, và Idan Szpektor. The second pascal recognising textual entailment challenge. In Proceedings of the second PASCAL challenges workshop on recognising textual entailment, volume 6, pages 6–4. Venice, 2006.

Max Bartolo, Alastair Roberts, Johannes Welbl, Sebastian Riedel, và Pontus Stenetorp. Beat the ai: Investigating adversarial human annotation for reading comprehension. Transactions of the Association for Computational Linguistics, 8:662–678, 2020. doi: 10.1162/tacl a00338. URL https://doi.org/10.1162/tacl a00338.

Qiang Ning Ben Zhou, Daniel Khashabi và Dan Roth. "going on a vacation" takes longer than "going for a walk": A study of temporal commonsense understanding. In EMNLP, 2019.

Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, và Shmargaret Shmitchell. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, pages 610–623, 2021.

Luisa Bentivogli, Peter Clark, Ido Dagan, và Danilo Giampiccolo. The fifth pascal recognizing textual entailment challenge. In TAC, 2009.

Jonathan Berant, Andrew Chou, Roy Frostig, và Percy Liang. Semantic parsing on Freebase from question-answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1533–1544, Seattle, Washington, USA, October 2013. Association for Computational Linguistics. URL https://aclanthology.org/D13-1160.

BIG-bench collaboration. Beyond the imitation game: Measuring and extrapolating the capabilities of language models. In preparation, 2021. URL https://github.com/google/BIG-bench/.

Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng Gao, và Yejin Choi. Piqa: Reasoning about physical commonsense in natural language. In Thirty-Fourth AAAI Conference on Artificial Intelligence, 2020.

Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S. Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, Erik Brynjolfsson, Shyamal Buch, Dallas Card, Rodrigo Castellon, Niladri Chatterji, Annie S. Chen, Kathleen Creel, Jared Quincy Davis, Dorottya Demszky, Chris Donahue, Moussa Doumbouya, Esin Durmus, Stefano Ermon, John Etchemendy, Kawin Ethayarajh, Li Fei-Fei, Chelsea Finn, Trevor Gale, Lauren Gillespie, Karan Goel, Noah D. Goodman, Shelby Grossman, Neel Guha, Tatsunori Hashimoto, Peter Henderson, John Hewitt, Daniel E. Ho, Jenny Hong, Kyle Hsu, Jing Huang, Thomas Icard, Saahil Jain, Dan Jurafsky, Pratyusha Kalluri, Siddharth Karamcheti, Geoff Keeling, Fereshte Khani, Omar Khattab, Pang Wei Koh, Mark S. Krass, Ranjay Krishna, Rohith Kuditipudi, và et al. On the opportunities and risks of foundation models. CoRR, abs/2108.07258, 2021. URL https://arxiv.org/abs/2108.07258.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. Language models are few-shot learners. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, và H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 1877–1901. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.

Rich Caruana. Multitask learning. Mach. Learn., 28(1):41–75, 1997. doi: 10.1023/A:1007379606734. URL https://doi.org/10.1023/A:1007379606734.

Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin Choi, Percy Liang, và Luke Zettlemoyer. QuAC: Question answering in context. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2174–2184, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1241. URL https://aclanthology.org/D18-1241.

Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, và Kristina Toutanova. Boolq: Exploring the surprising difficulty of natural yes/no questions. CoRR, abs/1905.10044, 2019. URL http://arxiv.org/abs/1905.10044.

Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, và Oyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning challenge. arXiv:1803.05457v1, 2018.

Ronan Collobert và Jason Weston. A unified architecture for natural language processing: deep neural networks with multitask learning. In William W. Cohen, Andrew McCallum, và Sam T. Roweis, editors, Machine Learning, Proceedings of the Twenty-Fifth International Conference (ICML 2008), Helsinki, Finland, June 5-9, 2008, volume 307 of ACM International Conference Proceeding Series, pages 160–167. ACM, 2008. doi: 10.1145/1390156.1390177. URL https://doi.org/10.1145/1390156.1390177.

Ido Dagan, Oren Glickman, và Bernardo Magnini. The pascal recognising textual entailment challenge. In Machine Learning Challenges Workshop, pages 177–190. Springer, 2005.

Pradeep Dasigi, Nelson F. Liu, Ana Marasovic, Noah A. Smith, và Matt Gardner. Quoref: A reading comprehension dataset with questions requiring coreferential reasoning. arXiv:1908.05803v2, 2019.

Ona de Gibert, Naiara Perez, Aitor Garcia-Pablos, và Montse Cuadros. Hate Speech Dataset from a White Supremacy Forum. In Proceedings of the 2nd Workshop on Abusive Language Online (ALW2), pages 11–20, Brussels, Belgium, October 2018. Association for Computational Linguistics. doi: 10.18653/v1/W18-5102. URL https://www.aclweb.org/anthology/W18-5102.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, 2019.

William B Dolan và Chris Brockett. Automatically constructing a corpus of sentential paraphrases. In Proceedings of the Third International Workshop on Paraphrasing (IWP2005), 2005.

Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, và Matt Gardner. Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs. In Proc. of NAACL, 2019.

Alexander R. Fabbri, Irene Li, Tianwei She, Suyi Li, và Dragomir R. Radev. Multi-news: a large-scale multi-document summarization dataset and abstractive hierarchical model, 2019.

Leo Gao, Jonathan Tow, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Kyle McDonell, Niklas Muennighoff, Jason Phang, Laria Reynolds, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, và Andy Zou. A framework for few-shot language model evaluation, September 2021. URL https://doi.org/10.5281/zenodo.5371628.

Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, và Bill Dolan. The third pascal recognizing textual entailment challenge. In Proceedings of the ACL-PASCAL workshop on textual entailment và paraphrasing, pages 1–9. Association for Computational Linguistics, 2007.

Bogdan Gliwa, Iwona Mochol, Maciej Biesek, và Aleksander Wawer. Samsum corpus: A human-annotated dialogue dataset for abstractive summarization. arXiv preprint arXiv:1911.12237, 2019.

Alec Go, Richa Bhayani, và Lei Huang. Twitter sentiment classification using distant supervision. CS224N project report, Stanford, 1(12):2009, 2009.

David Graff, Junbo Kong, Ke Chen, và Kazuaki Maeda. English gigaword. Linguistic Data Consortium, Philadelphia, 4(1):34, 2003.

Kazuma Hashimoto, Caiming Xiong, Yoshimasa Tsuruoka, và Richard Socher. A joint many-task model: Growing a neural network for multiple NLP tasks. CoRR, abs/1611.01587, 2016. URL http://arxiv.org/abs/1611.01587.

Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, và Phil Blunsom. Teaching machines to read and comprehend. In Advances in neural information processing systems, pages 1693–1701, 2015.

Eduard Hovy, Laurie Gerber, Ulf Hermjakob, Chin-Yew Lin, và Deepak Ravichandran. Toward semantics-based answer pinpointing. In Proceedings of the First International Conference on Human Language Technology Research, 2001. URL https://aclanthology.org/H01-1069.

Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, và Yejin Choi. Cosmos qa: Machine reading comprehension with contextual commonsense reasoning. In arXiv:1909.00277v2, 2019.

Matt Gardner Johannes Welbl, Nelson F. Liu. Crowdsourcing multiple choice science questions. arXiv:1707.06209v1, 2017.

Mandar Joshi, Eunsol Choi, Daniel Weld, và Luke Zettlemoyer. triviaqa: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension. arXiv e-prints, art. arXiv:1705.03551, 2017.

Daniel Khashabi, Snigdha Chaturvedi, Michael Roth, Shyam Upadhyay, và Dan Roth. Looking beyond the surface:a challenge set for reading comprehension over multiple sentences. In Proceedings of North American Chapter of the Association for Computational Linguistics (NAACL), 2018.

Daniel Khashabi, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, và Hannaneh Hajishirzi. Unifiedqa: Crossing format boundaries with a single QA system. CoRR, abs/2005.00700, 2020a. URL https://arxiv.org/abs/2005.00700.

Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, và Hannaneh Hajishirzi. UNIFIEDQA: Crossing format boundaries with a single QA system. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1896–1907, Online, November 2020b. Association for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.171. URL https://aclanthology.org/2020.findings-emnlp.171.

Tushar Khot, Peter Clark, Michal Guerquin, Peter Jansen, và Ashish Sabharwal. Qasc: A dataset for question answering via sentence composition. arXiv:1910.11473v2, 2020.

Boseop Kim, HyoungSeok Kim, Sang-Woo Lee, Gichang Lee, Donghyun Kwak, Dong Hyeon Jeon, Sunghyun Park, Sungju Kim, Seonhoon Kim, Dongpil Seo, và các tác giả khác. What changes can large-scale language models bring? intensive study on hyperclova: Billions-scale korean generative pretrained transformers. arXiv preprint arXiv:2109.04650, 2021.

Alexandre Lacoste, Alexandra Luccioni, Victor Schmidt, và Thomas Dandres. Quantifying the carbon emissions of machine learning. arXiv preprint arXiv:1910.09700, 2019.

Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, và Eduard Hovy. Race: Large-scale reading comprehension dataset from examinations. arXiv preprint arXiv:1704.04683, 2017.

R'emi Lebret, David Grangier, và Michael Auli. Generating text from structured data with application to the biography domain. CoRR, abs/1603.07771, 2016. URL http://arxiv.org/abs/1603.07771.

Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, và Nicholas Carlini. Deduplicating training data makes language models better. arXiv preprint arXiv:2107.06499, 2021.

Jens Lehmann, Robert Isele, Max Jakob, Anja Jentzsch, Dimitris Kontokostas, Pablo N Mendes, Sebastian Hellmann, Mohamed Morsey, Patrick Van Kleef, Sören Auer, và các tác giả khác. Dbpedia–a large-scale, multilingual knowledge base extracted from wikipedia. Semantic web, 6(2):167–195, 2015.

Brian Lester, Rami Al-Rfou, và Noah Constant. The power of scale for parameter-efficient prompt tuning. CoRR, abs/2104.08691, 2021. URL https://arxiv.org/abs/2104.08691.

Hector Levesque, Ernest Davis, và Leora Morgenstern. The winograd schema challenge. In Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning, 2012.

Quentin Lhoest, Albert Villanova del Moral, Yacine Jernite, Abhishek Thakur, Patrick von Platen, Suraj Patil, Julien Chaumond, Mariama Drame, Julien Plu, Lewis Tunstall, Joe Davison, Mario Šaško, Gunjan Chhablani, Bhavitvya Malik, Simon Brandeis, Teven Le Scao, Victor Sanh, Canwen Xu, Nicolas Patry, Angelina McMillan-Major, Philipp Schmid, Sylvain Gugger, Clément Delangue, Théo Matussière, Lysandre Debut, Stas Bekman, Pierric Cistac, Thibault Goehringer, Victor Mustar, François Lagunas, Alexander M. Rush, và Thomas Wolf. Datasets: A community library for natural language processing. emnlp, 2021.

Xin Li và Dan Roth. Learning question classifiers. In COLING 2002: The 19th International Conference on Computational Linguistics, 2002. URL https://aclanthology.org/C02-1150.

Bill Yuchen Lin, Wangchunshu Zhou, Ming Shen, Pei Zhou, Chandra Bhagavatula, Yejin Choi, và Xiang Ren. CommonGen: A constrained text generation challenge for generative commonsense reasoning. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1823–1840, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.165. URL https://aclanthology.org/2020.findings-emnlp.165.

Kevin Lin, Oyvind Tafjord, Peter Clark, và Matt Gardner. Reasoning over paragraph effects in situations. In MRQA@EMNLP, 2019.

Robert L Logan, Ivana Balažević, Eric Wallace, Fabio Petroni, Sameer Singh, và Sebastian Riedel. Cutting down on prompts and parameters: Simple few-shot learning with language models. arXiv preprint arXiv:2106.13353, 2021.

Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, và Christopher Potts. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 142–150, Portland, Oregon, USA, June 2011. Association for Computational Linguistics. URL http://www.aclweb.org/anthology/P11-1015.

Julian McAuley và Jure Leskovec. Hidden factors and hidden topics: understanding rating dimensions with review text. In Proceedings of the 7th ACM conference on Recommender systems, pages 165–172, 2013.

Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, và Richard Socher. The natural language decathlon: Multitask learning as question answering. CoRR, abs/1806.08730, 2018. URL http://arxiv.org/abs/1806.08730.

R. Thomas McCoy, Ellie Pavlick, và Tal Linzen. Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference. CoRR, abs/1902.01007, 2019. URL http://arxiv.org/abs/1902.01007.

Todor Mihaylov, Peter Clark, Tushar Khot, và Ashish Sabharwal. Can a suit of armor conduct electricity? a new dataset for open book question answering. In EMNLP, 2018.

Swaroop Mishra, Daniel Khashabi, Chitta Baral, và Hannaneh Hajishirzi. Natural instructions: Benchmarking generalization to new tasks from natural language instructions. CoRR, abs/2104.08773, 2021. URL https://arxiv.org/abs/2104.08773.

Nikita Nangia, Clara Vania, Rasika Bhalerao, và Samuel R. Bowman. CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, Online, November 2020. Association for Computational Linguistics.

Shashi Narayan, Shay B. Cohen, và Mirella Lapata. Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization. ArXiv, abs/1808.08745, 2018.

Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, và Douwe Kiela. Adversarial nli: A new benchmark for natural language understanding. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, 2020.

Bo Pang và Lillian Lee. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. In Proceedings of the ACL, 2005.

Denis Paperno, Germán Kruszewski, Angeliki Lazaridou, Ngoc-Quan Pham, Raffaella Bernardi, Sandro Pezzelle, Marco Baroni, Gemma Boleda, và Raquel Fernández. The lambada dataset: Word prediction requiring a broad discourse context. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1525–1534, 2016.

David Patterson, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David So, Maud Texier, và Jeff Dean. Carbon emissions and large neural network training. arXiv preprint arXiv:2104.10350, 2021.

Ellie Pavlick và Tom Kwiatkowski. Inherent disagreements in human textual inferences. Transactions of the Association for Computational Linguistics, 7:677–694, March 2019. doi: 10.1162/tacl_a_00293. URL https://aclanthology.org/Q19-1043.

Ethan Perez, Douwe Kiela, và Kyunghyun Cho. True few-shot learning with language models. CoRR, abs/2105.11447, 2021. URL https://arxiv.org/abs/2105.11447.

Mohammad Taher Pilehvar và José Camacho-Collados. Wic: 10, 000 example pairs for evaluating context-sensitive representations. CoRR, abs/1808.09121, 2018. URL http://arxiv.org/abs/1808.09121.

Adam Poliak, Aparajita Haldar, Rachel Rudinger, J. Edward Hu, Ellie Pavlick, Aaron Steven White, và Benjamin Van Durme. Collecting diverse natural language inference problems for sentence representation evaluation. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 67–81, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1007. URL https://aclanthology.org/D18-1007.

Yada Pruksachatkun, Jason Phang, Haokun Liu, Phu Mon Htut, Xiaoyi Zhang, Richard Yuanzhe Pang, Clara Vania, Katharina Kann, và Samuel R. Bowman. Intermediate-task transfer learning with pretrained language models: When and why does it work? In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5231–5247, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.467. URL https://aclanthology.org/2020.acl-main.467.

Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, và các tác giả khác. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21:1–67, 2020.

Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, và Percy Liang. SQuAD: 100,000+ Questions for Machine Comprehension of Text. arXiv e-prints, art. arXiv:1606.05250, 2016.

Laria Reynolds và Kyle McDonell. Prompt programming for large language models: Beyond the few-shot paradigm. CoRR, abs/2102.07350, 2021. URL https://arxiv.org/abs/2102.07350.

Adam Roberts, Colin Raffel, và Noam Shazeer. How much knowledge can you pack into the parameters of a language model? In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5418–5426, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.437. URL https://aclanthology.org/2020.emnlp-main.437.

Melissa Roemmele, Cosmin Adrian Bejan, và Andrew S Gordon. Choice of plausible alternatives: An evaluation of commonsense causal reasoning. In 2011 AAAI Spring Symposium Series, 2011.

Anna Rogers, Olga Kovaleva, Matthew Downey, và Anna Rumshisky. Getting closer to AI complete question answering: A set of prerequisite real tasks. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, pages 8722–8731. AAAI Press, 2020. URL https://aaai.org/ojs/index.php/AAAI/article/view/6398.

Rachel Rudinger, Jason Naradowsky, Brian Leonard, và Benjamin Van Durme. Gender bias in coreference resolution. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, New Orleans, Louisiana, June 2018. Association for Computational Linguistics.

Alexander M. Rush, Sumit Chopra, và Jason Weston. A neural attention model for abstractive sentence summarization. Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, 2015. doi: 10.18653/v1/d15-1044. URL http://dx.doi.org/10.18653/v1/D15-1044.

Amrita Saha, Rahul Aralikatte, Mitesh M. Khapra, và Karthik Sankaranarayanan. DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension. In Meeting of the Association for Computational Linguistics (ACL), 2018.

Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, và Yejin Choi. WINOGRANDE: an adversarial winograd schema challenge at scale. CoRR, abs/1907.10641, 2019. URL http://arxiv.org/abs/1907.10641.

Timo Schick và Hinrich Schütze. Exploiting cloze-questions for few-shot text classification and natural language inference. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 255–269, Online, April 2021. Association for Computational Linguistics. URL https://aclanthology.org/2021.eacl-main.20.

Roy Schwartz, Jesse Dodge, Noah A Smith, và Oren Etzioni. Green ai. Communications of the ACM, 63(12):54–63, 2020.

Abigail See, Peter J. Liu, và Christopher D. Manning. Get to the point: Summarization with pointer-generator networks. CoRR, abs/1704.04368, 2017. URL http://arxiv.org/abs/1704.04368.

Noam Shazeer và Mitchell Stern. Adafactor: Adaptive learning rates with sublinear memory cost. In International Conference on Machine Learning, pages 4596–4604. PMLR, 2018.

Reddy Siva, Chen Danqi, và Manning Christopher D. Wikiqa: A challenge dataset for open-domain question answering. arXiv, 2018.

Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford, và Jasmine Wang. Release strategies and the social impacts of language models. CoRR, abs/1908.09203, 2019. URL http://arxiv.org/abs/1908.09203.

Emma Strubell, Ananya Ganesh, và Andrew McCallum. Energy and policy considerations for deep learning in NLP. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3645–3650, 2019.

Kai Sun, Dian Yu, Jianshu Chen, Dong Yu, Yejin Choi, và Claire Cardie. DREAM: A challenge dataset and models for dialogue-based reading comprehension. Transactions of the Association for Computational Linguistics, 2019. URL https://arxiv.org/abs/1902.00164v1.

Oyvind Tafjord, Matt Gardner, Kevin Lin, và Peter Clark. "quartz: An open-domain dataset of qualitative relationship questions". EMNLP, "2019".

Oyvind Tafjord, Peter Clark, Matt Gardner, Wen-tau Yih, và Ashish Sabharwal. Quarel: A dataset and models for answering questions about qualitative relationships. CoRR, abs/1811.08048, 2018. URL http://arxiv.org/abs/1811.08048.

Tu Vu, Tong Wang, Tsendsuren Munkhdalai, Alessandro Sordoni, Adam Trischler, Andrew Mattarella-Micke, Subhransu Maji, và Mohit Iyyer. Exploring and predicting transferability across NLP tasks. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 7882–7926, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.635. URL https://aclanthology.org/2020.emnlp-main.635.

Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, và Samuel R. Bowman. Superglue: A stickier benchmark for general-purpose language understanding systems. CoRR, abs/1905.00537, 2019a. URL http://arxiv.org/abs/1905.00537.

Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, và Samuel R. Bowman. GLUE: A multi-task benchmark and analysis platform for natural language understanding. ICLR, 2019b. In the Proceedings of ICLR.

Sinong Wang, Han Fang, Madian Khabsa, Hanzi Mao, và Hao Ma. Entailment as few-shot learner. CoRR, abs/2104.14690, 2021. URL https://arxiv.org/abs/2104.14690.

Alex Warstadt, Amanpreet Singh, và Samuel R Bowman. Neural network acceptability judgments. arXiv preprint arXiv:1805.12471, 2018.

Albert Webson và Ellie Pavlick. Do prompt-based models really understand the meaning of their prompts?, 2021. URL https://arxiv.org/abs/2109.01247.

Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, và Quoc V. Le. Finetuned language models are zero-shot learners, 2021.

Johannes Welbl, Pontus Stenetorp, và Sebastian Riedel. Constructing datasets for multi-hop reading comprehension across documents, 2018.

Adina Williams, Tristan Thrush, và Douwe Kiela. Analyzing the adversarial natural language inference dataset. arXiv preprint arXiv:2010.12729, 2020.

Qinyuan Ye, Bill Yuchen Lin, và Xiang Ren. CrossFit: A few-shot learning challenge for cross-task generalization in nlp. arXiv preprint arXiv:2104.08835, 2021. URL https://arxiv.org/abs/2104.08835.

Yang Yi, Yih Wen-tau, và Christopher Meek. WikiQA: A Challenge Dataset for Open-Domain Question Answering. Association for Computational Linguistics, page 2013–2018, 2015. doi: 10.18653/v1/D15-1237.

Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, và Yejin Choi. Hellaswag: Can a machine really finish your sentence? In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, 2019.

Sheng Zhang, Xiaodong Liu, Jingjing Liu, Jianfeng Gao, Kevin Duh, và Benjamin Van Durme. Record: Bridging the gap between human and machine commonsense reading comprehension. arXiv preprint arXiv:1810.12885, 2018.

Xiang Zhang, Junbo Zhao, và Yann LeCun. Character-level convolutional networks for text classification. In Advances in neural information processing systems, pages 649–657, 2015a.

Xiang Zhang, Junbo Jake Zhao, và Yann LeCun. Character-level convolutional networks for text classification. In NIPS, 2015b.

Yuan Zhang, Jason Baldridge, và Luheng He. PAWS: Paraphrase Adversaries from Word Scrambling. In Proc. of NAACL, 2019.

Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, và Kai-Wei Chang. Gender bias in coreference resolution: Evaluation and debiasing methods. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 15–20, New Orleans, Louisiana, June 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-2003. URL https://aclanthology.org/N18-2003.

Tony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, và Sameer Singh. Calibrate before use: Improving few-shot performance of language models, 2021.

Ruiqi Zhong, Kristy Lee, Zheng Zhang, và Dan Klein. Adapting language models for zero-shot learning by meta-tuning on dataset and prompt collections. CoRR, abs/2104.04670, 2021. URL https://arxiv.org/abs/2104.04670.

A ĐÓNG GÓP VÀ CẤU TRÚC DỰ ÁN
Nghiên cứu này được tiến hành dưới dự án BigScience cho nghiên cứu mở,⁴ một sáng kiến kéo dài một năm nhằm nghiên cứu các mô hình và bộ dữ liệu lớn. Mục tiêu của dự án là nghiên cứu các mô hình ngôn ngữ trong một môi trường công cộng bên ngoài các công ty công nghệ lớn. Dự án có 600 nhà nghiên cứu từ 50 quốc gia và hơn 250 tổ chức. Dự án BigScience được khởi xướng bởi Thomas Wolf tại Hugging Face, và sự hợp tác này sẽ không thể thực hiện được nếu không có nỗ lực của ông. Nghiên cứu này là trọng tâm của nhóm làm việc BigScience Prompt Engineering, tập trung vào vai trò của prompting trong huấn luyện mô hình ngôn ngữ lớn.

Dự án này được dẫn dắt bởi các tác giả đồng đầu tiên của công trình này. Victor Sanh đồng dẫn dắt nhóm prompt engineering, quản lý quy trình thu thập prompt, thực hiện vật chất hóa prompt, và vận hành các hệ thống đánh giá. Albert Webson xem xét và chọn lọc tất cả các bộ dữ liệu huấn luyện và đánh giá, dẫn dắt phân tích kết quả, thiết kế các nghiên cứu ablation, và đồng quản lý quy trình viết. Colin Raffel đề xuất hướng nghiên cứu, huấn luyện tất cả các mô hình, đặt tên mô hình, và xây dựng hệ thống đánh giá chính. Stephen Bach đồng dẫn dắt nhóm prompt engineering, phát triển công cụ và hướng dẫn prompting, và dẫn dắt nỗ lực thu thập prompt trung tâm của công việc. Ngoài ra, Alexander Rush giúp phát triển ngôn ngữ và công cụ mẫu prompt, và đồng quản lý việc viết bài báo.

Theo mục tiêu của dự án BigScience, công trình này được đồng tác giả bởi tất cả các cộng tác viên của nhóm làm việc. Chúng tôi định nghĩa đóng góp này là đã đóng góp ít nhất 3 bộ dữ liệu được prompt hóa được chấp nhận cho dự án. Thiếu một số liệu tốt hơn, các tác giả được sắp xếp dựa trên đóng góp mã cho dự án. Chúng tôi đặc biệt nhấn mạnh công việc của: Lintang Sutawika, người đã giúp đánh giá và viết; Urmish Thakker, Mike Tian-Jian Jiang, Shanya Sharma, Arnaud Stiegler, và Manan Dey những người đã giúp phát triển công cụ prompting; M Saiful Bari, người đã giúp phát hành mô hình và bộ dữ liệu; Teven Le Scao, người đã tiến hành phân tích contamination.

B TÁC ĐỘNG RỘNG HƠN

B.1 CHI PHÍ MÔI TRƯỜNG
Huấn luyện các mô hình ngôn ngữ lớn có thể phát sinh chi phí môi trường đáng kể (Strubell et al., 2019; Schwartz et al., 2020; Lacoste et al., 2019; Bender et al., 2021). Những chi phí này là do năng lượng được sử dụng để cung cấp năng lượng cho phần cứng cần thiết để huấn luyện. Gần đây, Patterson et al. (2021) đã thực hiện một phân tích chi tiết về lượng khí thải carbon từ việc huấn luyện các mô hình ngôn ngữ lớn khác nhau gần đây. Một mô hình được phân tích trong nghiên cứu đó là biến thể T5 lớn nhất được ước tính đã phát thải khoảng 46.7 tCO₂e. Vì chúng tôi dựa T0 trên biến thể T5 này và thực hiện huấn luyện trên cùng phần cứng (Google Cloud TPUs), chúng tôi có thể ước tính lượng khí thải carbon được tạo ra bởi nghiên cứu của chúng tôi bằng cách đơn giản tái tỷ lệ ước tính T5 từ Patterson et al. (2021) theo lượng huấn luyện chúng tôi đã thực hiện. Cụ thể, T5 đã được tiền huấn luyện trên một nghìn tỷ token; trên tất cả các lần chạy huấn luyện của chúng tôi (bao gồm các thí nghiệm kiểm tra sơ bộ không được mô tả trong bài báo này) chúng tôi đã huấn luyện cho 250 tỷ token, hoặc khoảng 25% so với T5. Những lần chạy huấn luyện này tương ứng với khoảng 270 giờ huấn luyện tổng cộng trên thiết bị Cloud TPU v3-512. Hơn nữa, T5 được huấn luyện tại trung tâm dữ liệu Đài Loan của Google, trong khi chúng tôi huấn luyện tại vùng Cloud europe-west4-a. gCO₂eq/kWh được công bố bởi Google cho những trung tâm dữ liệu này lần lượt là 540 và 410,⁵ cho thấy rằng lượng khí thải carbon của chúng tôi nên được tỷ lệ thêm với hệ số 410/540≈75.9%. Dựa trên những điều trên, chúng tôi ước tính tổng lượng khí thải để huấn luyện các mô hình của chúng tôi là khoảng 46.7×25%×75.9%≈8.9 tCO₂e. Để tham khảo, Patterson et al. (2021) ước tính rằng một chuyến bay máy bay khứ hồi từ San Francisco đến New York phát thải khoảng 1.8 tCO₂e và Strubell et al. (2019) ước tính lượng khí thải trung bình mỗi hành khách là khoảng 1 tCO₂e. Lưu ý rằng các thí nghiệm của chúng tôi đã phát sinh thêm lượng khí thải do chi phí đánh giá, ablation kích thước XL, và tiền xử lý dữ liệu, nhưng những chi phí này không đáng kể so với các lần chạy huấn luyện cho mô hình T0 chính. Hơn nữa, hầu hết các đánh giá và tiền xử lý dữ liệu đã chạy trên cụm Jean-Zay của Pháp mà điện chủ yếu đến từ năng lượng hạt nhân.

Mô hình Phần cứng Giờ Lưới gCO₂eq/kWh Ước tính tCO₂e
T0 (chạy đơn lẻ) v3-512 27 europe-west4-a 410 0.9
Tất cả thí nghiệm trong bài báo này v3-512 270 europe-west4-a 410 8.9
T5-11B (chạy đơn lẻ) v3-1024 528 Đài Loan 540 46.7

Bảng 1: Thông tin khí thải carbon cho T0 và T5.

B.2 RỦI RO TRONG VIỆC PHÁT TRIỂN VÀ PHÁT HÀNH CÁC MÔ HÌNH NGÔN NGỮ LỚN
Trọng tâm của bài báo này là một khám phá thực nghiệm về huấn luyện prompt đa nhiệm vụ và cách nó cải thiện hiệu suất zero-shot trên nhiều nhiệm vụ. Chúng tôi đã chuyển đổi các bộ dữ liệu bằng cách viết nhiều prompt cho mỗi bộ dữ liệu, tinh chỉnh các mô hình được tiền huấn luyện trên các ví dụ được chuyển đổi và quan sát khả năng zero-shot mạnh trên nhiều nhiệm vụ. Chúng tôi lưu ý rằng hiệu suất zero-shot của mô hình chúng tôi vẫn đáng kể sau các mô hình được tinh chỉnh trên nhiệm vụ đã cho trong thiết lập "học chuyển giao truyền thống". Điều này làm nổi bật bao nhiêu nghiên cứu vẫn cần thiết trong lĩnh vực này, và chúng tôi tin rằng công trình này và các tài nguyên được phát triển như một phần của công trình này là trung tâm cho nghiên cứu tương lai.

Công trình này được xây dựng độc quyền trên các bộ dữ liệu có sẵn công khai từ thư viện datasets của Hugging Face (Lhoest et al., 2021) và một mô hình có sẵn công khai, T5+LM (Lester et al., 2021). Những tác động của việc phát hành các mô hình ngôn ngữ lớn đã được thảo luận rộng rãi trong Bender et al. (2021); Bommasani et al. (2021); Solaiman et al. (2019) trong số những người khác. Chúng tôi mong đợi việc nhắc lại công trình của chúng tôi sẽ nằm trong khả năng của hàng chục tổ chức trên toàn thế giới, rào cản chính là ràng buộc tài chính. Như vậy, chúng tôi tin rằng những rủi ro và tác hại tiềm tàng bổ sung được tạo ra bởi việc phát hành mô hình của chúng tôi là có giới hạn, và không phát hành nó sẽ chủ yếu tác động đến các tổ chức nghiên cứu và cá nhân ít được tài trợ hơn.

Hơn nữa, chúng tôi ủng hộ sự cởi mở, minh bạch và khả năng tái tạo. Việc phát hành bộ dữ liệu, mô hình và công cụ được phát triển như một phần của công trình này là những yếu tố chính sẽ tạo điều kiện cho việc tái tạo kết quả của chúng tôi và các công trình tương lai. Như vậy, các tài nguyên của chúng tôi có sẵn tại:
• Bộ sưu tập prompt: http://github.com/bigscience-workshop/promptsource
• Các mô hình được huấn luyện: https://github.com/bigscience-workshop/t-zero
• Dữ liệu được prompt hóa vật chất được sử dụng để huấn luyện các mô hình: https://huggingface.co/datasets/bigscience/P3.

B.3 THIÊN KIẾN VÀ CÔNG BẰNG
Một số bộ dữ liệu có sẵn trong thư viện Hugging Face chứa nội dung có thể có hại. Chúng tôi đã cố ý loại trừ những bộ dữ liệu này khỏi hỗn hợp huấn luyện để tránh huấn luyện mô hình tạo ra những đầu ra như vậy. Đặc biệt, chúng tôi đã loại trừ các bộ dữ liệu được xây dựng từ nội dung diễn đàn và mạng xã hội như Sentiment140 (Go et al., 2009) dựa trên nội dung Twitter hoặc Hate Speech 18 (de Gibert et al., 2018) được xây dựng trên dữ liệu từ một diễn đàn ưu việt da trắng.

Ngay cả khi chúng tôi đã có những quyết định cố ý để loại trừ các bộ dữ liệu có nội dung có thể có hại khỏi việc tinh chỉnh, các mô hình được huấn luyện không phải là không có thiên kiến. Dựa trên một số thí nghiệm, T0++ có thể tạo ra những câu trả lời có thể được phân loại là âm mưu hoặc thiên kiến:

Đầu vào Dự đoán
Trái đất có phẳng không? có
Vaccine có gây tự kỷ không? có
Hoàn thành câu này: Người đàn ông này làm nghề Kiến trúc sư
Hoàn thành câu này: Người phụ nữ này làm nghề Giữ trẻ

Bảng 2: Một số dự đoán có vấn đề từ T0++.

Các mô hình ngôn ngữ có thể tái tạo những thiên kiến xã hội không mong muốn được đại diện trong corpus lớn mà chúng được tiền huấn luyện. Chúng tôi đánh giá các mô hình của chúng tôi theo hai cách: thứ nhất, trong khả năng nhận biết hoặc gắn nhãn thiên kiến giới tính và thứ hai, ở mức độ mà chúng tái tạo những thiên kiến đó.

Để đo lường khả năng của mô hình chúng tôi nhận biết thiên kiến giới tính, chúng tôi đánh giá các mô hình của chúng tôi sử dụng WinoGender Schemas (Rudinger et al., 2018) (cũng được gọi là AX-g dưới SuperGLUE) và CrowS-Pairs (Nangia et al., 2020). WinoGender Schemas là các cặp câu tối thiểu chỉ khác nhau bởi giới tính của một đại từ trong câu, được thiết kế để kiểm tra sự hiện diện của thiên kiến giới tính. Chúng tôi sử dụng phiên bản từ Poliak et al. (2018) chuyển WinoGender thành một nhiệm vụ kéo theo văn bản và báo cáo độ chính xác. CrowS-Pairs là một bộ dữ liệu thách thức để đo lường mức độ mà những thiên kiến khuôn mẫu của Hoa Kỳ hiện diện trong các mô hình ngôn ngữ có mặt nạ sử dụng các cặp câu tối thiểu. Chúng tôi tái công thức hóa nhiệm vụ bằng cách dự đoán câu nào trong hai câu là khuôn mẫu (hoặc chống khuôn mẫu) và báo cáo độ chính xác. Đối với mỗi bộ dữ liệu, chúng tôi đánh giá từ 5 đến 10 prompt.

Bộ dữ liệu Mô hình Trung bình (Acc.) Trung vị (Acc.)
CrowS-Pairs T0 59.2 83.8
T0+ 57.6 83.8
T0++ 62.7 64.4
T0 (p=1) 57.6 69.5
T0 (3B) 56.9 82.6
WinoGender T0 84.2 84.3
T0+ 80.1 80.6
T0++ 89.2 90.0
T0 (p=1) 81.6 84.6
T0 (3B) 69.7 69.4

Bảng 3: Độ chính xác trung bình và trung vị trên CrowS-Pairs và WinoGender được tái công thức hóa như các nhiệm vụ phân loại.

Để đo lường mức độ mà mô hình của chúng tôi tái tạo thiên kiến giới tính, chúng tôi đánh giá các mô hình của chúng tôi sử dụng WinoBias Schemas (Zhao et al., 2018). WinoBias Schemas là các nhiệm vụ giải quyết đồng tham chiếu đại từ có tiềm năng bị ảnh hưởng bởi thiên kiến giới tính. WinoBias Schemas có hai schema (type1 và type2) được phân vùng thành các tập con ủng hộ khuôn mẫu và chống khuôn mẫu. Một ví dụ "ủng hộ khuôn mẫu" là một ví dụ mà câu trả lời đúng phù hợp với khuôn mẫu, trong khi một ví dụ "chống khuôn mẫu" là một ví dụ mà nó phản đối khuôn mẫu. Tất cả các ví dụ đều có một câu trả lời đúng rõ ràng, và do đó sự khác biệt trong điểm số giữa tập con "ủng hộ" và "chống" đo lường mức độ mà khuôn mẫu có thể khiến mô hình đi lệch hướng. Chúng tôi báo cáo độ chính xác bằng cách coi một dự đoán là đúng nếu danh từ mục tiêu có mặt trong dự đoán của mô hình. Chúng tôi đánh giá trên 6 prompt.

Mô hình Tập con Trung bình (Acc.) Trung vị (Acc.)
Pro Anti Pro - Anti Pro Anti Pro - Anti
T0 Type 1 68.0 61.9 6.0 71.7 61.9 9.8
Type 2 79.3 76.4 2.8 79.3 75.0 4.3
T0+ Type 1 66.6 57.2 9.4 71.5 62.6 8.8
Type 2 77.7 73.4 4.3 86.1 81.3 4.8
T0++ Type 1 63.8 55.9 7.9 72.7 63.4 9.3
Type 2 66.8 63.0 3.9 79.3 74.0 5.3
T0 (p=1) Type 1 73.7 60.5 13.2 79.3 60.6 18.7
Type 2 77.7 69.6 8.0 80.8 69.7 11.1
T0 (chỉ nhiệm vụ ban đầu) Type 1 78.1 67.7 10.4 81.8 67.2 14.6
Type 2 85.2 82.3 2.9 89.6 85.4 4.3
T0 (3B) Type 1 82.3 70.1 12.2 83.6 62.9 20.7
Type 2 83.8 76.5 7.3 85.9 75.0 10.9

Bảng 4: Độ chính xác trên nhiệm vụ đồng tham chiếu WinoBias.

C HỆ THỐNG CHÚ THÍCH - PROMPT SOURCE
Để thu thập hàng trăm mẫu cho các prompt, trước tiên chúng tôi cần một hệ thống cho phép người dùng xem dữ liệu, cung cấp các mẫu ở định dạng tiêu chuẩn, và xác minh rằng các mẫu của họ hoạt động đúng. Chúng tôi đã thực hiện một giao diện nhẹ trong Streamlit⁶ mà người dùng có thể tải xuống, chạy cục bộ trong trình duyệt web, và sau đó tải lên kết quả của họ vào một kho lưu trữ trung tâm.

Thử nghiệm các lần lặp của giao diện trên các nhiệm vụ viết mẫu thí điểm, chúng tôi hội tụ trên ba view cho giao diện. Thứ nhất, một view "helicopter" cho phép người dùng xem những bộ dữ liệu nào có sẵn để viết mẫu và có bao nhiêu được viết cho mỗi bộ, để ưu tiên sự chú ý của người dùng. Thứ hai, một view "sourcing" cho phép người dùng chọn một bộ dữ liệu để prompt, duyệt các ví dụ từ bộ dữ liệu đó dưới dạng các từ điển Python được cung cấp bởi thư viện datasets của Hugging Face, và nhập một mẫu cho bộ dữ liệu đó. Khi người dùng viết mẫu của họ, mỗi khi họ lưu nó, đầu ra của mẫu được áp dụng cho ví dụ hiện tại được hiển thị bên cạnh trình chỉnh sửa. Chúng tôi cũng thu thập metadata như tên cho mẫu, và một tham chiếu cho bất kỳ thông tin thư mục hoặc lý do cho mẫu. Thứ ba, trong view "prompted dataset", người dùng có thể chọn các mẫu và duyệt các prompt được tạo ra bởi chúng. Ví dụ ban đầu (một từ điển Python) được xem cạnh nhau với prompt kết quả, với văn bản được thay thế được làm nổi bật để phân biệt với văn bản được mã hóa cứng trong mẫu. Người dùng có thể cuộn nhanh qua nhiều ví dụ, xác minh hành vi của mẫu của họ, và trở lại view sourcing nếu cần thay đổi.

Một quyết định thiết kế chính là định dạng cho các mẫu. Chúng tôi đã thử nghiệm với nhiều định dạng và thấy rằng chúng thể hiện một sự đánh đổi giữa tính biểu đạt và cấu trúc rõ ràng. Một mặt, một định dạng biểu đạt tối đa như mã Python thuần túy sẽ cho phép người dùng viết các chương trình phức tạp để thao tác các ví dụ bán cấu trúc thành prompt. Tuy nhiên, việc phân tích những chương trình này để hiểu cách các prompt được tạo ra trở nên khó khăn. Khó khăn này giới hạn việc thao tác và phân tích hạ lưu của các mẫu, chẳng hạn như tăng cường mẫu tự động. Mặt khác, một định dạng có cấu trúc tối đa như tạo ra dựa trên quy tắc giới hạn các loại mẫu mà người dùng có thể tạo ra. Chúng tôi thấy không khả thi để liệt kê các loại quy tắc đủ cho phạm vi rộng các nhiệm vụ và định dạng dữ liệu mà chúng tôi muốn có mẫu.

Do đó chúng tôi chọn một nền tảng giữa hai bên: công cụ mẫu Jinja⁷ ban đầu được thiết kế để tạo ra markup web. Người dùng viết các mẫu như prompt với các chỗ giữ chỗ, chẳng hạn như Nếu {{premise}} là đúng, liệu cũng đúng rằng {{hypothesis}}? ||| {{entailed}}. Dấu phân cách ||| biểu thị sự ngắt giữa văn bản điều kiện và việc hoàn thành mong muốn. Các chỗ giữ chỗ tham chiếu đến các trường trong từ điển ví dụ cơ bản. Người dùng cũng có quyền truy cập vào các hàm tích hợp của Jinja, chẳng hạn như thao tác chuỗi và dữ liệu có cấu trúc. Đối với mỗi mẫu, các prompt được tạo ra bằng cách áp dụng mẫu cho tất cả các ví dụ trong bộ dữ liệu tương ứng.

Trong quá trình phát triển công cụ của chúng tôi (mà chúng tôi gọi là PromptSource), chúng tôi thấy rằng một số thành ngữ đặc biệt hữu ích. Thứ nhất, không phải tất cả các mẫu đều áp dụng được cho tất cả các ví dụ trong một bộ dữ liệu. Người dùng có thể bao bọc các mẫu trong các câu lệnh điều kiện tích hợp của Jinja, và bất kỳ ví dụ nào dẫn đến một prompt trống đều đơn giản bị bỏ qua. Thứ hai, nhiều ví dụ có thể được sử dụng để tạo ra nhiều prompt huấn luyện, chẳng hạn như một câu hỏi có nhiều câu trả lời hợp lệ. Do đó chúng tôi đã thêm một hàm choice chọn một phần tử từ một danh sách theo cách có thể được kiểm soát trong quá trình tạo bộ dữ liệu, chẳng hạn như chọn một phần tử ngẫu nhiên sử dụng một bộ tạo số ngẫu nhiên có seed hoặc tạo ra các prompt khác nhau cho mỗi tổ hợp các phần tử trong mẫu. Thứ ba, nhiều nhiệm vụ như phân loại và trả lời câu hỏi nhị phân có một tập hợp nhỏ các phần hoàn thành hợp lệ có thể, và việc đưa ra dự đoán cho những nhiệm vụ này bằng cách chỉ chấm điểm các phần hoàn thành hợp lệ và trả về phần cao nhất là phổ biến (Brown et al., 2020). Do đó người dùng có thể liệt kê các phần hoàn thành hợp lệ trong một trường riêng biệt và truy cập chúng như một danh sách trong các mẫu của họ. Những phần hoàn thành này sau đó được cung cấp một cách rõ ràng khi đánh giá dự đoán cho những prompt này.

D BỘ DỮ LIỆU

D.1 PHÂN LOẠI CÁC BỘ DỮ LIỆU THÀNH CÁC NHIỆM VỤ
Phân loại nhiệm vụ của chúng tôi (Hình 2) bao gồm hầu hết các quyết định đơn giản phản ánh các nhiệm vụ nổi tiếng trong văn học: phân tích cảm xúc, phân loại chủ đề, nhận dạng paraphrase, suy luận ngôn ngữ tự nhiên, phân biệt nghĩa từ, giải quyết đồng tham chiếu, tóm tắt, và tạo cấu trúc sang văn bản. Khó khăn chính nằm ở việc một bộ sưu tập lớn các bộ dữ liệu đều được gọi chung là "trả lời câu hỏi", và không có cách nào được chấp nhận chung để phân chia loại này. CrossFit và UnifiedQA phân loại chúng theo định dạng (nhiều lựa chọn vs. trích xuất vs. abstraktif/tạo sinh), trong khi Brown et al. (2020) phân loại theo nội dung (đọc hiểu vs. thường thức vs. QA sách đóng).

Về nguyên tắc, phân loại theo nội dung có ý nghĩa hơn so với theo định dạng. Hầu hết con người sẽ coi việc làm một kỳ thi lịch sử vs. vật lý như hai nhiệm vụ khác nhau, trong khi việc kỳ thi là nhiều lựa chọn hay trích xuất ít quan trọng hơn. Theo logic này, việc thiết lập QA sách đóng như một nhiệm vụ riêng biệt tương đối không gây tranh cãi, mà phần lớn đánh giá việc ghi nhớ kiến thức thế giới của mô hình (Roberts et al., 2020). Tuy nhiên, sự phân biệt giữa thường thức và đọc hiểu (đơn thuần) mờ nhạt hơn nhiều. Như đã đề cập trong Phần 3, có những khác biệt lớn trong những gì được coi là thường thức bởi tác giả của mỗi bộ dữ liệu. Để đơn giản hóa quá mức, chúng thường bao gồm các câu hỏi đánh giá nhận thức vật lý và chuẩn mực văn hóa (tập trung vào Hoa Kỳ).

Để so sánh, Brown et al. (2020, p. 17) định nghĩa một nhiệm vụ thường thức như một "nỗ lực nắm bắt lý luận vật lý hoặc khoa học, khác biệt với hoàn thành câu, đọc hiểu, hoặc trả lời câu hỏi kiến thức rộng." Bỏ qua định nghĩa vòng tròn, việc lý luận khoa học là thường thức còn xa từ rõ ràng. Trong số lựa chọn của Brown et al. (2020), ARC minh họa cách đánh giá kiến thức khoa học vượt xa thường thức. Mặc dù được xây dựng từ các câu hỏi khoa học tiểu học, các tác giả của bài báo này thấy hầu hết ARC khó trả lời (và ở mức độ ít hơn, OpenBookQA cũng vậy).

Cuối cùng, lưu ý rằng các bộ dữ liệu NLI và đồng tham chiếu (đặc biệt là những bộ mới hơn như ANLI và Winogrande) tất cả trong thực tế đều yêu cầu kiến thức thường thức. Do đó, chúng tôi thấy khó khăn để thiết lập thường thức như một loại nhiệm vụ độc lập, mặc định trở lại phân loại QA theo định dạng của chúng. Điều này có nghĩa là chúng tôi phân loại ARC như QA nhiều lựa chọn, vì các QA sách đóng khác yêu cầu tạo ra câu trả lời mà không có bất kỳ tùy chọn câu trả lời được cung cấp nào.

D.2 CÁC NHIỆM VỤ CHƯA GẶP CHƯA NHÌN THẤY NHƯ THẾ NÀO?
Vì "trả lời câu hỏi" được định nghĩa rộng rãi, các bộ dữ liệu QA có thể đã bao gồm các câu hỏi kéo theo hoặc đồng tham chiếu, khiến chúng không hoàn toàn là các nhiệm vụ chưa gặp. Ví dụ, ReCoRD là một bộ dữ liệu QA trích xuất độc quyền hỏi các câu hỏi tương đương với việc xác định một referent. Chúng tôi giữ lại ReCoRD như một phần của SuperGLUE, nhưng việc kiểm tra mỗi bộ dữ liệu và cắt bỏ các tập con của các ví dụ hỏi câu hỏi kéo theo hoặc đồng tham chiếu là không khả thi.

Một mối quan tâm chung là việc nhận dạng paraphrase quá giống với NLI và cũng nên được giữ lại. Chúng tôi không đồng ý vì hai lý do. Thứ nhất, NLI kiểm tra sự kéo theo một hướng, trong khi paraphrase hỏi về sự kéo theo hai hướng. Một tác giả đã xem xét thủ công ANLI và RTE và thấy gần như không có ví dụ kéo theo nào cũng là paraphrase hợp lệ. Thứ hai, đã được chỉ ra (ví dụ, Pruksachatkun et al., 2020) rằng huấn luyện trên một bộ dữ liệu paraphrase (QQP) trước khi huấn luyện trên một bộ dữ liệu NLI (RTE) thực sự làm tổn hại hiệu suất so với chỉ huấn luyện trên nhiệm vụ kéo theo.

Một loại khó khăn khác đã bị thách thức là quá giống với NLI là hoàn thành câu: chọn tùy chọn hợp lý nhất tiếp tục hoặc hoàn thành một câu hoặc một đoạn văn ngắn. SWAG được đề xuất như "suy luận thường thức" để bổ sung NLI, nhưng sự phân biệt giữa suy luận diễn dịch của các nhà ngữ nghĩa học hình thức và suy luận thực dụng tự nhiên không được vẽ rõ ràng trong hầu hết các bộ dữ liệu NLI (Pavlick và Kwiatkowski, 2019). Ngoài ra, đồng tham chiếu và bất kỳ prompt "kiểu tiếp tục" nào cũng có thể được hiểu như một nhiệm vụ hoàn thành câu. Những ranh giới mờ nhạt này không có câu trả lời rõ ràng. Vì vậy chúng tôi phân loại giữ lại nhiệm vụ hoàn thành câu.

Các bộ dữ liệu đánh giá trong BIG-bench được tạo ra với mục tiêu kiểm tra các mô hình ngôn ngữ trên các kỹ năng đa dạng, khó khăn và mới. Do đó, những bộ dữ liệu đó không có khả năng có sự chồng chéo cao với các nhiệm vụ huấn luyện của T0.

D.3 LAMBADA
Như được mô tả ở trên, phân loại nhiệm vụ của chúng tôi nhìn chung hơi giống với của Brown et al. (2020). Một ngoại lệ bổ sung là bộ dữ liệu LAMBADA (Paperno et al., 2016), mà Brown et al. (2020) phân loại như một phần của nhóm nhiệm vụ "hoàn thành câu". LAMBADA khác biệt đáng kể với các nhiệm vụ khác trong nhóm này vì nó yêu cầu dự đoán từ tiếp theo mở (thay vì chọn trong số một vài sự tiếp tục có thể). Bộ dữ liệu được thiết kế theo cách này đặc biệt để định dạng của nó hoàn toàn giống như mô hình hóa ngôn ngữ tiêu chuẩn, do đó cho phép các mô hình ngôn ngữ được đánh giá trên nó mà không cần tinh chỉnh hoặc thích ứng bổ sung. Brown et al. (2020) lệch khỏi thực hành tiêu chuẩn trên benchmark này theo những cách sau: Thứ nhất, họ giới thiệu một dạng prompt chuyển đổi nó thành một nhiệm vụ kiểu điền vào chỗ trống. Thứ hai, họ đánh giá trên một định dạng không tiêu chuẩn của bộ dữ liệu bỏ qua tokenization và lowercasing của benchmark chính thức.⁸ Thứ ba, GPT-3 được huấn luyện trên bộ dữ liệu Book Corpus, là cùng bộ dữ liệu được sử dụng như một nguồn của tất cả các đoạn văn trong LAMBADA. Brown et al. (2020) ước tính rằng 57% các ví dụ tập kiểm tra LAMBADA xuất hiện trong tập huấn luyện của GPT-3.

Chúng tôi đánh giá T5+LM trên bộ dữ liệu LAMBADA tiêu chuẩn ở dạng dự đoán từ tiếp theo không prompt ban đầu và thấy rằng nó đạt được độ chính xác 6.2%. Điều này đáng kể dưới độ chính xác 72.5% đạt được bởi biến thể GPT-3-13B có kích thước tương đương. T0 không tốt hơn nhiều, chỉ đạt 18.7%. Do đó chúng tôi đánh giá sử dụng cùng dạng prompt kiểu cloze được sử dụng bởi GPT-3, điều này nâng độ chính xác của T0 lên 27.8%. Nếu chúng tôi thay thế bộ dữ liệu LAMBADA chính thức bằng biến thể được sử dụng bởi GPT-3, độ chính xác của T0 tăng thêm lên 40.5% và T5+LM đạt 10.7%. Chúng tôi nghi ngờ rằng khoảng cách bổ sung giữa T0 và hiệu suất của GPT-3-13B ít nhất một phần do thực tế là GPT-3 được huấn luyện trên một phần lớn tập kiểm tra của LAMBADA. Do sự bất đồng này và thực tế là LAMBADA không giống với các nhiệm vụ hoàn thành câu khác, chúng tôi đã bỏ qua LAMBADA khỏi đánh giá của chúng tôi.

D.4 BẢNG TẤT CẢ CÁC BỘ DỮ LIỆU
Xem Bảng 5.

⁸https://github.com/openai/gpt-2/issues/131

--- TRANG 9 ---
[Tiếp tục dịch phần còn lại của tài liệu theo cùng cách...]

E PHÂN TÍCH CONTAMINATION CỦA CORPUS TIỀN HUẤN LUYỆN TRÊN CÁC NHIỆM VỤ KIỂM TRA
Ước tính hiệu suất zero-shot có thể bị nhiễu nếu corpus tiền huấn luyện cho mô hình chứa văn bản từ các nhiệm vụ kiểm tra vì các mô hình có thể cải thiện hiệu suất thông qua ghi nhớ thay vì tổng quát hóa. Để kiểm soát hiệu ứng này, chúng tôi tìm kiếm các chuỗi con chung dài giữa các ví dụ đầu vào (được trình bày dưới dạng prompt) cho các nhiệm vụ kiểm tra zero-shot của chúng tôi một mặt, và các tài liệu trong C4 (tập tiền huấn luyện của mô hình chúng tôi) mặt khác.

Để thực hiện điều này một cách hiệu quả, chúng tôi sử dụng phương pháp mảng hậu tố được mô tả và thực hiện trong Lee et al. (2021) để lập chỉ mục C4, cho phép chúng tôi chạy các truy vấn đếm nhanh về số lần một chuỗi con xuất hiện trong corpus. Để giới hạn số lượng truy vấn, chúng tôi tìm kiếm bằng cách phân vùng các câu thành các nhóm 16 token và thực hiện truy vấn khớp chính xác. Điều này cho chúng tôi một số đếm quá mức về số lượng chồng chéo token độ dài 32 có trong corpus. Chúng tôi đánh dấu các ví dụ tạo ra khớp trong quy trình đó, sau đó kiểm tra thủ công chúng.

Đối với các bộ dữ liệu NLI, chúng tôi tách các khớp cho tiền đề và giả thuyết vì tiền đề có xu hướng được lấy từ internet và do đó có số lượng khớp cao. Tuy nhiên, nếu giả thuyết được ghép với nó là mới, việc ghi nhớ có thể không hữu ích.

Nhiệm vụ CB HellaSwag Lambada Story Cloze WiC Winogrande WSC
Khớp 1/250 912/10000 15/5153 3/1871 20/1400 0/1767 4/146

Nhiệm vụ ANLI tiền đề ANLI giả thuyết RTE tiền đề RTE giả thuyết
Khớp 337/1000 6/1000 329/3000 156/3000

Như mong đợi, ANLI và RTE trả về tỷ lệ khớp cao trên các tiền đề. Tuy nhiên, các giả thuyết ANLI có sự chồng chéo không đáng kể với tập tiền huấn luyện, điều này ngăn việc ghi nhớ tiền huấn luyện khỏi việc giải quyết nhiệm vụ. Ngược lại, các giả thuyết RTE được chứa trong bộ dữ liệu tiền huấn luyện 5.2% thời gian. Những cái này phần lớn tương ứng với các câu thực tế ngắn ("Paris là thủ đô của Pháp"). Đó là những ví dụ mà bộ dữ liệu tiền huấn luyện có thể giúp ích nếu kiến thức thực tế giúp giải quyết nhiệm vụ. HellaSwag có 9.12% khớp, có thể có vấn đề vì đó là một nhiệm vụ tiếp tục: câu trả lời đúng cũng được chứa trong cùng trang internet gốc như chuỗi đầu vào, mặc dù định dạng trả lời nhiều lựa chọn ngăn mô hình chỉ tạo ra câu trả lời đúng một cách nguyên văn thông qua ghi nhớ. Các bộ dữ liệu khác không có contamination.

[Tiếp tục với phần F và các phụ lục khác theo cùng cách...]

--- TRANG 3 ---
giữa các nút. Ma trận kề A∈R^{N×N} mã hóa cấu trúc liên kết của đồ thị, với mỗi phần tử A_{i,j} chỉ ra sự hiện diện hoặc vắng mặt của một cạnh giữa các nút i và j. Ma trận đặc trưng X∈R^{N×F} chứa thông tin thuộc tính hoặc đặc trưng liên quan đến mỗi nút, trong đó F đại diện cho số chiều đặc trưng.

Mạng Nơ-ron Đồ thị. đã trở thành một khung mạnh mẽ để học biểu diễn từ dữ liệu có cấu trúc đồ thị. Khác với các mạng nơ-ron truyền thống xử lý dữ liệu dạng lưới, GNN xuất sắc trong việc nắm bắt các mối quan hệ và phụ thuộc phức tạp trong đồ thị. Chúng sử dụng cấu trúc của đồ thị—bao gồm các nút và cạnh—để dẫn xuất các biểu diễn nút biểu cảm thông qua các hoạt động lan truyền và tổng hợp thông điệp lặp lại.

m_v^{(l)} = Propagate^{(l)}({h_u^{(l-1)} : u ∈ N(v)}),
h_v^{(l)} = Aggregate^{(l)}(h_v^{(l-1)}, m_v^{(l)}) (1)

Trong Mạng Nơ-ron Đồ thị, vector đặc trưng của nút v tại lớp l được ký hiệu là h_v^{(l)}. Truyền thông điệp được thực hiện bởi hàm Propagate^{(l)}, tổng hợp thông tin từ các nút lân cận của v trong lớp l. Hàm Aggregate^{(l)} kết hợp thông tin này với biểu diễn lớp trước của nút v để cập nhật h_v^{(l)}. Bằng cách kết hợp cấu trúc đồ thị vào các biểu diễn đã học, GNN có thể được điều chỉnh cho các nhiệm vụ như phân loại nút và dự đoán liên kết.

3 PHƯƠNG PHÁP LUẬN

3.1 Mã hóa Thông tin Cấu trúc với Nền tảng Văn bản-Đồ thị

Để cải thiện sự hiểu biết về thông tin cấu trúc đồ thị của các mô hình ngôn ngữ lớn, khung của chúng tôi tập trung vào việc căn chỉnh việc mã hóa các cấu trúc đồ thị với không gian ngôn ngữ tự nhiên. Sự căn chỉnh này cho phép các mô hình ngôn ngữ hiểu hiệu quả các thành phần cấu trúc của đồ thị bằng cách sử dụng khả năng hiểu ngôn ngữ của chúng. Để đạt được điều này, chúng tôi giới thiệu một mô hình nền tảng văn bản-đồ thị tạo ra các lời nhắc bảo tồn ngữ cảnh cấu trúc của đồ thị cho các mô hình ngôn ngữ. Mô hình này hoạt động như một cầu nối, kết nối sự hiểu biết ngữ nghĩa của thông tin văn bản với các mối quan hệ cấu trúc vốn có trong đồ thị.

Trong GraphGPT của chúng tôi, chúng tôi thiết kế bộ mã hóa đồ thị để có tính linh hoạt cao, cho phép nó tận dụng một loạt các kiến trúc GNN chính được thu được từ các mô hình tiền huấn luyện đồ thị đa dạng. Chúng tôi kết hợp một kiến trúc mạng nơ-ron truyền thông điệp, có thể là graph transformer [60] hoặc graph convolutional network [17], như mô hình đồ thị được tiền huấn luyện ở cấp độ cấu trúc. Trong mỗi bước truyền thông điệp, bộ mã hóa đồ thị tổng hợp thông tin từ các nút lân cận, xem xét các mối quan hệ của chúng:

H^{(l)} = σ(ÃH^{(l-1)}W) (2)

Ma trận kề tự vòng lặp, được ký hiệu là Ã, được thu được bằng cách thêm ma trận đơn vị I vào ma trận kề ban đầu A. W là ma trận tham số. Ma trận này nắm bắt các kết nối tự và tính kết nối cục bộ của các nút trong đồ thị. σ(·) là hàm kích hoạt phi tuyến. H^{(l)} là các biểu diễn đồ thị tại lớp thứ l.

Căn chỉnh Văn bản-Cấu trúc. Để tăng cường sự căn chỉnh của thông tin cấu trúc đồ thị với Mô hình Ngôn ngữ (LLM), trọng tâm của chúng tôi là khám phá các phương pháp mã hóa hiệu quả có thể hợp tác một cách liền mạch với LLM. Dựa trên các công trình trước đây [30, 49], chúng tôi áp dụng một phương pháp đối chiếu bằng cách kết hợp thông tin văn bản vào quá trình mã hóa cấu trúc đồ thị. Chúng tôi trực tiếp tích hợp một bộ mã hóa đồ thị được tiền huấn luyện vào khung GraphGPT, cho phép sử dụng liền mạch các khả năng của nó. Chính thức, cho một đồ thị G(V,E,A,X) với nội dung văn bản thô C={c_i∈R^{l_i×d}, 1≤i≤N} cho N nút, chúng tôi thu được các biểu diễn đồ thị được mã hóa Ĥ∈R^{N×d} và các biểu diễn văn bản được mã hóa T̂∈R^{N×d} như sau:

H=f_G(X), T=f_T(C), Ĥ=norm(H), T̂=norm(T) (3)

Chúng tôi sử dụng bộ mã hóa đồ thị, f_G, để tạo ra các biểu diễn đồ thị ở cấp độ cấu trúc từ đồ thị đầu vào G(V,E,A,X). Để mã hóa nội dung văn bản thô C liên quan đến các nút, chúng tôi sử dụng một bộ mã hóa văn bản, như transformer hoặc BERT, được ký hiệu là f_T. Bước này tạo ra các biểu diễn văn bản được mã hóa của các nút, sau đó được chuẩn hóa theo hàng bằng hàm norm. Sự căn chỉnh văn bản-cấu trúc qua các phương thức được tiến hành như sau:

Γ1=(ĤT̂^T)·exp(τ), Γ2=(ĤT̂'^T)·exp(τ), Γ3=(T̂^T T̂'^T)·exp(τ)
L=∑_{i=1}^3 1/(2λ_i)(CE(Γ_i,y)+CE(Γ_i^T,y)) (4)

trong đó T̂'={1/|N_i| ∑_{j∈N_i} T̂_j, 1≤i≤N} và N là số nút. Trong nền tảng văn bản-đồ thị của chúng tôi, chúng tôi sử dụng nhãn y=(0,1,···,n-1)^T cho mục tiêu căn chỉnh đối chiếu. Chúng tôi sử dụng graph transformer [61] như bộ mã hóa đồ thị và vanilla transformer [38] như bộ mã hóa văn bản.

3.2 Điều chỉnh Hướng dẫn Đồ thị Hai Giai đoạn

Mô hình điều chỉnh hướng dẫn đồ thị hai giai đoạn được đề xuất trong công trình này dựa trên khái niệm điều chỉnh hướng dẫn, đã được giới thiệu gần đây để tăng cường khả năng thích ứng của các mô hình ngôn ngữ cho các miền cụ thể [45]. Trong mô hình này, chúng tôi nhằm mục đích căn chỉnh khả năng ngôn ngữ của mô hình với các sắc thái của các nhiệm vụ học đồ thị, cho phép mô hình ngôn ngữ tạo ra các phản hồi chính xác hơn và phù hợp với ngữ cảnh cho dữ liệu có cấu trúc đồ thị.

3.2.1 Điều chỉnh Hướng dẫn Tự Giám sát. Trong giai đoạn đầu tiên của điều chỉnh hướng dẫn đồ thị, chúng tôi giới thiệu điều chỉnh hướng dẫn tự giám sát. Cơ chế này tăng cường khả năng suy luận của mô hình ngôn ngữ bằng cách kết hợp kiến thức cấu trúc cụ thể về miền đồ thị và hiểu hiệu quả thông tin ngữ cảnh trong cấu trúc của đồ thị. Để đạt được điều này, chúng tôi sử dụng các tín hiệu tự giám sát dẫn xuất từ các cấu trúc đồ thị không có nhãn như các hướng dẫn cho điều chỉnh mô hình. Cụ thể, chúng tôi thiết kế một nhiệm vụ khớp đồ thị nhận thức cấu trúc hướng dẫn mô hình ngôn ngữ trong việc phân biệt giữa các token đồ thị bằng cách sử dụng các token ngôn ngữ. Nhiệm vụ hướng dẫn này đóng vai trò quan trọng trong việc liên kết chính xác các token đồ thị với các mô tả văn bản tương ứng, làm sâu sắc hơn sự hiểu biết của mô hình về đồ thị với hướng dẫn được cung cấp.

Thiết kế Hướng dẫn. Hướng dẫn cho nhiệm vụ khớp đồ thị của chúng tôi bao gồm ba thành phần: i) thông tin đồ thị, ii) câu hỏi của con người, và iii) phản hồi GraphGPT. Trong nhiệm vụ này, chúng tôi coi mỗi nút trong đồ thị như một nút trung tâm và thực hiện h-hops với việc lấy mẫu lân cận ngẫu nhiên, dẫn đến một cấu trúc đồ thị con. Đầu vào ngôn ngữ tự nhiên cho LLM là câu hỏi của con người. Trong bối cảnh của nhiệm vụ khớp đồ thị, hướng dẫn bao gồm token chỉ thị

--- TRANG 4 ---
Bộ mã hóa Cấu trúc Văn bản-Nền tảng
Đồ thị Đầu vào từ Nhiều Miền
…
Được Điều chỉnh
Đóng băng
Nút Trung tâm
Lân cận 1-hop
Lân cận 2-hop
Token Đồ thị

Mã hóa Thông tin Cấu trúc

Cho một chuỗi token đồ thị <Graph>… Đây là danh sách văn bản nút: <NodeTexts>Vui lòng sắp xếp lại danh sách văn bản theo thứ tự của token đồ thị.
Hướng dẫn Con người

Dựa trên thông tin, chúng tôi thu được sự khớp như sau:
Token đồ thị 1 tương ứng với...
Token đồ thị 2 tương ứng với…
Token đồ thị 3 tương ứng với…
Phản hồi LLM

Cho một chuỗi token đồ thị <Graph>. Token đầu tiên đại diện cho nút trung tâm của đồ thị con. Các token còn lại đại diện cho lân cận bậc một và bậc hai... <NodeTexts>Nút này thuộc danh mục nào? Vui lòng suy nghĩ theo cách từng bước một và cung cấp lý luận của bạn.
Hướng dẫn Con người

Phản hồi LLM
Để xác định việc phân loại, chúng tôi xem xét các chủ đề cụ thể trong văn bản.
Đầu tiên, nó liên quan đến…
Thứ hai, có bằng chứng rằng…
Cuối cùng, nút này là về…, có thể được phân loại thành…

Thuộc tính Văn bản
Thuộc tính Văn bản
Thuộc tính Văn bản
LLMs

Một quan sát lâm sàng xác nhận…
Trong các ứng dụng nhạy cảm bảo mật, điều cần thiết là…
Chúng tôi cho thấy một cận dưới chặt chẽ của \Omega về…

Token Đồ thị
Điều chỉnh Hướng dẫn

Mô hình Ngôn ngữ Lớn (LLMs)
Vicuna
Llama
Token Đồ thị
Thuộc tính Văn bản
Thuộc tính Văn bản
Lời nhắc CoT
LLMs?

Điều chỉnh Hướng dẫn + Chưng cất Nhiệm vụ
phân loại?
dự đoán liên kết

Điều chỉnh Hướng dẫn Tự Giám sát
Điều chỉnh Hướng dẫn Cụ thể cho Nhiệm vụ
[cls]
[eos]
Bộ chiếu Căn chỉnh

Token Ngôn ngữ
[Instruct][NodeText][Graph][Instruct]
Thuộc tính Văn bản
Các biến chứng tim mạch là nguyên nhân chính…

Hình 2: Kiến trúc tổng thể của GraphGPT được đề xuất với mô hình điều chỉnh hướng dẫn đồ thị.

<graph> và một danh sách thông tin văn bản nút được xáo trộn. Ví dụ, trong một đồ thị trích dẫn, thông tin văn bản nút tương ứng với tiêu đề bài báo. Mục tiêu của LLM trong nhiệm vụ khớp đồ thị là căn chỉnh mỗi token đồ thị với thông tin văn bản nút tương ứng. Điều này đòi hỏi việc sắp xếp lại danh sách thông tin văn bản nút dựa trên chuỗi các token đồ thị, hiệu quả liên kết mỗi token đồ thị với mô tả văn bản có liên quan. Các thiết kế chi tiết của khớp đồ thị được hiển thị trong Hình 4.

Chiến lược Điều chỉnh. Để tối ưu hóa quá trình điều chỉnh một cách hiệu quả, chúng tôi đề xuất kết hợp một Bộ chiếu Căn chỉnh Nhẹ. Trong quá trình huấn luyện, chúng tôi tập trung vào tối ưu hóa các tham số của bộ chiếu f_P, trong khi giữ cố định các tham số của cả LLM và bộ mã hóa đồ thị. Chúng tôi giả định rằng bộ chiếu học thành công cách ánh xạ biểu diễn đồ thị được mã hóa thành các token đồ thị, trong khi LLM xuất sắc trong việc căn chỉnh các token này với thông tin văn bản nút đa dạng.

Để căn chỉnh các token đồ thị với các token ngôn ngữ, chúng tôi sử dụng một bộ chiếu f_P, có thể đơn giản như một lớp tuyến tính duy nhất. Bộ chiếu này thiết lập sự tương ứng giữa các token đồ thị và các token ngôn ngữ. Bằng cách thay thế token chỉ thị <graph> trong chuỗi token ngôn ngữ ban đầu, các token đồ thị được căn chỉnh tạo ra một chuỗi token đã được chỉnh sửa cho LLM. Chuỗi đã được chỉnh sửa này, được ký hiệu là {<graph_begin>, <graph_token>_1,···,<graph_token>_n, <graph_end>}, tương ứng với số nút n trong đồ thị liên quan đến lời nhắc đã cho. Cho rằng quá trình khớp đồ thị là không có giám sát, chúng tôi có cơ hội tận dụng một lượng lớn dữ liệu đồ thị không có nhãn từ các miền khác nhau, để tăng cường khả năng tổng quát hóa của bộ chiếu đã học. Về mặt toán học, với các token đồ thị được chiếu X_G=f_P(Ĥ) và các nhúng văn bản X_I=tokenizer(instruction), cho một chuỗi có độ dài L, chúng tôi tính toán xác suất tạo ra đầu ra mục tiêu X_O như sau:

p(X_O|X_G,X_I) = ∏_{i=1}^L p_θ(x_i|X_G,X_I,<i,X_O,<i) (5)

trong đó θ là các tham số có thể học được trong GraphGPT.

3.2.2 Điều chỉnh Hướng dẫn Cụ thể cho Nhiệm vụ. Trong giai đoạn thứ hai, chúng tôi giới thiệu điều chỉnh hướng dẫn cụ thể cho nhiệm vụ để tùy chỉnh hành vi suy luận của mô hình cho các nhiệm vụ học đồ thị khác nhau, như phân loại nút hoặc dự đoán liên kết. Bằng cách tinh chỉnh LLM bằng cách sử dụng các hướng dẫn đồ thị cụ thể cho nhiệm vụ, chúng tôi hướng dẫn mô hình tạo ra các phản hồi phù hợp với các ràng buộc và yêu cầu của nhiệm vụ học đồ thị cụ thể. Điều này tăng cường khả năng thích ứng và hiệu suất của mô hình trong việc xử lý các nhiệm vụ học đồ thị đa dạng.

GNN
Bộ Biến đổi Thuộc tính Văn bản

Hình 3: Quy trình làm việc của căn chỉnh văn bản-cấu trúc.

Thiết kế Hướng dẫn. Chúng tôi sử dụng một mẫu hướng dẫn nhất quán bao gồm ba phần. Để tạo ra thông tin đồ thị cho mỗi nút, chúng tôi sử dụng cùng một phương pháp lấy mẫu lân cận như trong giai đoạn đầu tiên. Phương pháp này đảm bảo việc bao gồm thông tin đồ thị có liên quan, với mỗi nút được coi như nút trung tâm. Đối với nhiệm vụ phân loại nút, hướng dẫn câu hỏi của con người bao gồm token chỉ thị <graph> và thông tin văn bản cụ thể về nút trung tâm. Hướng dẫn này hướng dẫn mô hình ngôn ngữ dự đoán danh mục của nút trung tâm dựa trên cả dữ liệu cấu trúc đồ thị và thông tin văn bản đi kèm. Hình 4 cung cấp các ví dụ hướng dẫn cho các nhiệm vụ khác nhau, minh họa trực quan cách trình bày hướng dẫn cho mô hình ngôn ngữ.

Chiến lược Điều chỉnh. Trong giai đoạn thứ hai của huấn luyện, chúng tôi sử dụng các tham số của bộ chiếu nhận thức cấu trúc đã được huấn luyện trong giai đoạn đầu tiên như trạng thái ban đầu. Điều này cho phép chúng tôi tiến hành điều chỉnh hướng dẫn cụ thể cho các nhiệm vụ downstream. Trong quá trình huấn luyện này, chúng tôi giữ cố định các tham số của mô hình ngôn ngữ (LLM) và bộ mã hóa đồ thị, chỉ tập trung vào tối ưu hóa các tham số của bộ chiếu từ giai đoạn trước. Bằng cách làm như vậy, chúng tôi đảm bảo rằng LLM được căn chỉnh thêm với các yêu cầu của các nhiệm vụ downstream, tăng cường khả năng hiểu và diễn giải cấu trúc đồ thị.

Sau khi hoàn thành hai giai đoạn huấn luyện như mô tả ở trên, chúng tôi tin tưởng rằng GraphGPT của chúng tôi đã có được khả năng hiểu cấu trúc đồ thị đã cho và thực hiện các nhiệm vụ downstream trên đồ thị được cung cấp. Quá trình huấn luyện bao gồm điều chỉnh hướng dẫn và việc đóng băng các tham số mô hình cụ thể đã tinh chỉnh sự hiểu biết của mô hình về cấu trúc đồ thị, cho phép nó giải quyết hiệu quả các nhiệm vụ khác nhau liên quan đến đồ thị đã cho.

--- TRANG 5 ---
Thông tin Đồ thị:<graph>: Nút Trung tâm: 2, Chỉ số cạnh: [[…srcnode…],[…dstnode…]], Danh sách nút: […]
Câu hỏi Con người:Cho một đồ thị trích dẫn: <graph>nơi nút thứ 0 là bài báo mục tiêu, với thông tin sau: Tóm tắt: … Tiêu đề: … Câu hỏi: Bài báo này thuộc danh mục phụ arXivCS nào? …
Phản hồi GraphGPT:cs.IT, cs.LG, cs.SP, cs.CV, cs.NA. Bài báo thảo luận về Restricted Isometry …. Vậy nó có khả năng thuộc cs.IT…

Thông tin Đồ thị:<graph>: Nút Trung tâm: 68442, Chỉ số cạnh: [[…srcnode…],[…dstnode…]], Danh sách nút: […]
Câu hỏi Con người:Cho một chuỗi token đồ thị <graph>tạo thành một đồ thị con của đồ thị trích dẫn, …. Đây là danh sách tiêu đề bài báo: 1. … 2. …, vui lòng sắp xếp lại danh sách bài báo theo thứ tự của token đồ thị.
Phản hồi GraphGPT:Dựa trên các token đồ thị đã cho và danh sách tiêu đề bài báo, chúng tôi thu được sự khớp của token đồ thị và bài báo: Token đồ thị 1 tương ứng với phương pháp cảm ứng dựa trên smt cho hệ thống định thời. Token đồ thị 2 tương ứng với …

Thông tin Đồ thị:<graph>: Nút Trung tâm 1: 8471, Chỉ số cạnh 1: [[…srcnode…],[…dstnode…]], Danh sách nút 1: […]<graph>:NútTrungtâm2:19368,Chỉsốcạnh2:[[…srcnode…],[…dstnode…]],Danhsáchnút2:[…]
Câu hỏi Con người:Cho một chuỗi token đồ thị: <graph>tạo thành một đồ thị con của đồ thị trích dẫn, …. Tóm tắt: … Tiêu đề: … và chuỗi token đồ thị khác: <graph>,… Tóm tắt: … Tiêu đề: …, hai nút trung tâm này có kết nối không? Cho tôi câu trả lời "có" hoặc "không".
Phản hồi GraphGPT:Có,chúngcókếtnối.Dựatrênbàibáođầutiên,….Vàbàibáothứhaiđềxuất….

Khớp Đồ thị
Phân loại Nút
Dự đoán Liên kết

Hình 4: Thiết kế hướng dẫn của chúng tôi cho nhiệm vụ khớp đồ thị (trên), phân loại nút (giữa) và dự đoán liên kết (dưới).

3.3 Chưng cất Chain-of-Thought (CoT)

Khi đối mặt với dữ liệu đồ thị đa dạng, các mô hình ngôn ngữ có thể gặp phải các mẫu và cấu trúc không quen thuộc, dẫn đến những thách thức trong việc tạo ra các phản hồi chính xác và mạch lạc. Điều này đặc biệt đúng khi số lượng các lớp nút thay đổi giữa các loại dữ liệu đồ thị khác nhau, gây ra sự dịch chuyển phân phối. Để giải quyết thách thức này và tăng cường độ chính xác khi có sự dịch chuyển phân phối, việc trang bị cho GraphGPT của chúng tôi các khả năng suy luận từng bước một là rất quan trọng. Do đó, chúng tôi đề xuất kết hợp kỹ thuật Chain-of-Thought (COT) [47], mô hình hóa một cách rõ ràng dòng suy nghĩ và các bước suy luận. Bằng cách tận dụng COT, mô hình ngôn ngữ của chúng tôi cải thiện tính mạch lạc và nhất quán của văn bản được tạo ra, cho phép nó theo một tiến trình logic của các ý tưởng và tăng cường sự hiểu biết và khả năng suy luận cho dữ liệu đồ thị đã cho.

Việc kết hợp kỹ thuật Chain-of-Thought (COT) có thể đầy thách thức do ảnh hưởng của quy mô tham số mô hình [32]. Để vượt qua điều này, chúng tôi lấy cảm hứng từ nghiên cứu trước đây [32] và áp dụng phương pháp chưng cất. Bằng cách trích xuất kiến thức có giá trị từ một mô hình ngôn ngữ mạnh mẽ nguồn đóng như ChatGPT (với hơn 200 tỷ tham số), chúng tôi có thể tạo ra các hướng dẫn COT chất lượng cao và tăng cường khả năng suy luận COT của mô hình mà không tăng số lượng tham số.

Mô hình Chưng cất COT. Phương pháp của chúng tôi bao gồm việc thiết kế các lời nhắc Chain-of-Thought (COT) tùy chỉnh cho các nhiệm vụ cụ thể về nút. Đối với nhiệm vụ phân loại nút trong đồ thị trích dẫn, chúng tôi cung cấp tóm tắt, tiêu đề bài báo và mô tả nhiệm vụ như đầu vào. Sử dụng mô hình ngôn ngữ GPT-3.5 (LLM), chúng tôi kết hợp " Vui lòng suy nghĩ về việc phân loại theo cách từng bước một. " để cho phép suy luận từng bước. Bằng cách tham gia vào suy nghĩ tuần tự, LLM tạo ra đầu ra bao gồm dự đoán cho các lớp nút và giải thích chi tiết cho mỗi dự đoán. Điều này đảm bảo suy luận và ra quyết định minh bạch và có thể hiểu được. Để tăng cường hiệu suất hơn nữa, chúng tôi tích hợp dữ liệu hướng dẫn COT được tạo ra với các hướng dẫn được thiết kế trước đó cho điều chỉnh hướng dẫn cụ thể cho nhiệm vụ. Với các hướng dẫn tích hợp, chúng tôi tiến hành mô hình điều chỉnh hướng dẫn được đề xuất.

4 ĐÁNH GIÁ

Chúng tôi tiến hành thí nghiệm để giải quyết các câu hỏi nghiên cứu chính:
•RQ1: Khung GraphGPT được đề xuất hoạt động như thế nào trong cả cài đặt học đồ thị có giám sát và không shot?
•RQ2: Khả năng tổng quát hóa của mô hình chúng tôi trong việc xử lý nhiều nhiệm vụ mà không gặp phải quên lãng thảm khốc là gì?
•RQ3: Đóng góp của các thành phần chính khác nhau trong khung GraphGPT được đề xuất đối với hiệu suất tổng thể là gì?
•RQ4: Khung GraphGPT của chúng tôi có khả năng mở rộng và hiệu quả như thế nào?

4.1 Cài đặt Thí nghiệm

4.1.1 Mô tả Dữ liệu. Chúng tôi đánh giá GraphGPT bằng cách sử dụng ba tập dữ liệu: OGB-arxiv, PubMed, và Cora. Tập dữ liệu OGB-arxiv [12] đại diện cho một đồ thị có hướng nắm bắt mạng trích dẫn giữa các bài báo arXiv khoa học máy tính được lập chỉ mục bởi MAG [41]. Mỗi bài báo được gán nhãn thủ công với một danh mục nghiên cứu được chọn từ 40 lĩnh vực chủ đề. Tập dữ liệu PubMed [8] bao gồm 19.717 xuất bản khoa học về bệnh tiểu đường từ cơ sở dữ liệu PubMed, được phân loại thành Bệnh tiểu đường cảm ứng thực nghiệm, Bệnh tiểu đường loại 1, và Bệnh tiểu đường loại 2. Ngoài ra, nó bao gồm một mạng trích dẫn với 44.338 liên kết. Tập dữ liệu Cora [49] bao gồm 25.120 bài báo nghiên cứu được kết nối thông qua trích dẫn. Chúng tôi sử dụng phiên bản mở rộng với 70 lớp, lớn hơn các phiên bản trước đây [17].

4.1.2 Giao thức Đánh giá. Để tạo điều kiện so sánh giữa các tập dữ liệu khác nhau, chúng tôi ánh xạ các đặc trưng nút vào một không gian vector thống nhất bằng cách mã hóa thông tin văn bản thô với BERT được tiền huấn luyện [3]. Trong các thí nghiệm, chúng tôi chia các tập dữ liệu Cora và PubMed thành tập huấn luyện, xác thực và kiểm tra theo tỷ lệ 3:1:1, như được mô tả trong các công trình trước đây [8,49]. Đối với dữ liệu OGB-arxiv, chúng tôi tuân theo cài đặt phân chia công khai [12] với tỷ lệ huấn luyện, xác thực và kiểm tra là 6:2:3. Để đánh giá hiệu suất mô hình, chúng tôi sử dụng ba số liệu thường được sử dụng: Accuracy và Macro F1 cho phân loại nút, và AUC cho dự đoán liên kết.

4.1.3 Các Phương pháp Cơ sở. Trong việc so sánh hiệu suất, chúng tôi xem xét các phương pháp tiên tiến khác nhau để đánh giá toàn diện. (i) Danh mục đầu tiên bao gồm MLP, sử dụng Perceptron Đa lớp cho biểu diễn nút. (ii) Danh mục thứ hai bao gồm các bộ mã hóa nơ-ron đồ thị đại diện, bao gồm GraphSAGE [7], GCN [17], GAT [39], và RevGNN [21]. (iii) Danh mục thứ ba tập trung vào phương pháp tự giám sát DGI [40] cho học đồ thị. (iv) Danh mục thứ tư khám phá GNN được tăng cường bằng chưng cất kiến thức, với GKD [55] và GLNN [63] là các phương pháp đáng chú ý. (v). Danh mục thứ năm trình bày các mạng transformer đồ thị mạnh mẽ được đề xuất gần đây, với NodeFormer [51] và DIFFormer [50] là các đối thủ cạnh tranh. (vi) Cuối cùng, chúng tôi xem xét các LLM mã nguồn mở, như Baichuan-7B, vicuna-7B-v1.1, và vicuna-7B-v1.5 như baseline để hiểu dữ liệu đồ thị có thuộc tính văn bản.

4.1.4 Chi tiết Triển khai. Đối với việc triển khai mô hình, chúng tôi chủ yếu sử dụng các thư viện PyTorch và Transformers. Chúng tôi sử dụng

--- TRANG 6 ---
Bảng 1: So sánh hiệu suất của các phương pháp khác nhau trên phân loại nút dưới cả cài đặt có giám sát và không shot.

[Bảng chi tiết với các giá trị hiệu suất cho các mô hình khác nhau trên các tập dữ liệu khác nhau]

Vicuna-7B-v1.1 và Vicuna-7B-v1.5 làm mô hình cơ sở. Kích thước lô được đặt thành 2 trên mỗi GPU, và tốc độ học là 2e-3. Chúng tôi áp dụng tỷ lệ khởi động là 3e-2 và đặt độ dài đầu vào tối đa của Mô hình Ngôn ngữ Lớn (LLM) là 2048. Quá trình huấn luyện chạy trong 3 epochs. Trong giai đoạn điều chỉnh hướng dẫn cụ thể cho nhiệm vụ, chúng tôi khám phá các kết hợp khác nhau của dữ liệu hướng dẫn để đánh giá hiệu suất mô hình dưới các hỗn hợp dữ liệu khác nhau. Cài đặt siêu tham số vẫn không đổi, ngoại trừ số epochs huấn luyện, được đặt thành 2 trong giai đoạn này. Các tham số bộ chiếu căn chỉnh được tinh chỉnh trong giai đoạn điều chỉnh hướng dẫn tự giám sát phục vụ như tham số ban đầu cho bộ chiếu trong giai đoạn điều chỉnh thứ hai. Để đánh giá hầu hết các baseline, chúng tôi sử dụng mã công khai của chúng. Để biết thêm chi tiết triển khai, vui lòng tham khảo mã được phát hành của chúng tôi.

4.2 So sánh Hiệu suất Tổng thể (RQ1)

Chúng tôi tiến hành thí nghiệm trên nhiệm vụ phân loại nút, đánh giá cả tình huống có giám sát và không shot. Hiệu suất tổng thể được tóm tắt trong Bảng 1. Trong Cài đặt Nhiệm vụ Có giám sát, các mô hình được huấn luyện trên một tập dữ liệu cụ thể và đánh giá trên tập kiểm tra tương ứng (ví dụ: huấn luyện trên Arxiv-Arxiv và kiểm tra trên tập kiểm tra Arxiv). Trong Cài đặt Nhiệm vụ Không shot, các mô hình được huấn luyện trên một tập dữ liệu cụ thể và kiểm tra trên các tập dữ liệu khác mà không cần huấn luyện bổ sung (ví dụ: huấn luyện trên Arxiv-PubMed và kiểm tra trên tập dữ liệu PubMed). Để xử lý sự thay đổi về số lượng lớp giữa các tập dữ liệu, chúng tôi sử dụng một bộ phân loại được huấn luyện chuyển đổi, như một lớp tuyến tính, khi kiểm tra các mô hình dựa trên GNN. Trong Bảng 1, "-7B-" chỉ ra quy mô tham số, trong khi "-v1.1-" và "-v1.5-" đại diện cho các phiên bản khác nhau của mô hình Vicuna cơ sở. "-stage2" chỉ ra việc chỉ áp dụng điều chỉnh giai đoạn thứ hai. "-std" và "-cot" biểu thị việc sử dụng tập dữ liệu hướng dẫn tiêu chuẩn và được tạo ra bởi COT, tương ứng.

Obs.1: Ưu thế Tổng thể của GraphGPT. LLM đồ thị của chúng tôi liên tục vượt trội so với các baseline tiên tiến khác nhau trong cả tình huống có giám sát và không shot. Đáng chú ý, ngay cả các mô hình dựa trên GNN mạnh mẽ được phát triển gần đây, như NodeFormer, DIFFormer, và GKD, thể hiện khả năng mô hình hóa cấu trúc tốt trong cài đặt có giám sát. Tuy nhiên, khi được chuyển đổi sang các tập dữ liệu mới mà không cần huấn luyện thêm, hiệu suất của chúng giảm đáng kể. Ngược lại, GraphGPT của chúng tôi không chỉ vượt qua tất cả các phương pháp tiên tiến trong các nhiệm vụ có giám sát mà còn đạt được sự gia tăng đáng kể 2-10 lần về độ chính xác trong tình huống học đồ thị không shot.

Các giải pháp dựa trên LLM như Baichuan-7B và Vicuna-7B duy trì hiệu suất ổn định qua các tập dữ liệu khác nhau nhưng chỉ dựa vào thông tin văn bản để dự đoán. Ngược lại, GraphGPT của chúng tôi bảo tồn cấu trúc đồ thị, cung cấp một giải pháp toàn diện cho các nhiệm vụ học đồ thị. Hai yếu tố chính góp phần vào những cải thiện này: (i) Điều chỉnh hướng dẫn đồ thị hai giai đoạn của chúng tôi căn chỉnh thông tin cấu trúc được mã hóa bởi bộ mã hóa đồ thị với các token ngôn ngữ tự nhiên, cho phép LLM hiểu các đặc tính vốn có của đồ thị. (ii) Khung của chúng tôi tạo điều kiện tăng cường lẫn nhau giữa bộ mã hóa đồ thị và LLM, lấp đầy khoảng trống của LLM trong việc hiểu cấu trúc và cho phép nó suy luận về cấu trúc của đồ thị.

Obs.2: Lợi ích với Khớp Đồ thị Nhận thức Cấu trúc. Sự hiện diện của giai đoạn đầu tiên, bao gồm các nhiệm vụ khớp đồ thị tự giám sát để điều chỉnh hướng dẫn, đóng vai trò quan trọng trong việc tăng cường khả năng chuyển đổi không shot của GraphGPT. Giai đoạn đầu tiên tập trung vào việc căn chỉnh các token đồ thị, mã hóa thông tin cấu trúc phong phú, với các token ngôn ngữ. Sự căn chỉnh này cho phép mô hình phát triển sự hiểu biết sâu sắc hơn về các đặc tính cấu trúc vốn có của dữ liệu đồ thị. Không có giai đoạn đầu tiên, nếu chúng tôi chỉ tiến hành giai đoạn thứ hai của điều chỉnh hướng dẫn cụ thể cho nhiệm vụ, mô hình có xu hướng dễ bị overfitting trên tập dữ liệu cụ thể. Trong những trường hợp như vậy, hiệu suất của mô hình có thể phụ thuộc nhiều vào các mẫu và đặc tính cụ thể của tập dữ liệu, thay vì hiểu thực sự về cấu trúc đồ thị cơ bản. Điều này có thể hạn chế khả năng của mô hình để tổng quát hóa sang các tập dữ liệu mới, chưa thấy.

Obs.3: Lợi ích với Chưng cất COT. Các biến thể "-std" và "-cot" cho thấy việc sử dụng chưng cất COT có lợi đáng kể cho các nhiệm vụ học đồ thị phức tạp hơn. Các mô hình được điều chỉnh với tập dữ liệu hướng dẫn tiêu chuẩn đã có thể đạt được kết quả nổi bật khi được chuyển đổi sang các nhiệm vụ đơn giản hơn, như tập dữ liệu PubMed với 3 lớp, với độ chính xác 0.7011 cho Arxiv-PubMed. Tuy nhiên,

--- TRANG 7 ---
Bảng 2: So sánh hiệu suất của các hỗn hợp hướng dẫn khác nhau trong học có giám sát trên tập dữ liệu Arxiv và cài đặt không shot trên tập dữ liệu Cora cho phân loại nút.

[Bảng chi tiết với các giá trị hiệu suất]

Bảng 3: So sánh hiệu suất của các hỗn hợp hướng dẫn khác nhau cho dự đoán liên kết trên PubMed.

[Bảng chi tiết với các giá trị hiệu suất]

hiệu suất của chúng có xu hướng trung bình khi áp dụng cho các nhiệm vụ phức tạp như tập dữ liệu Cora với 70 lớp. Bằng cách tận dụng khả năng suy luận mạnh mẽ của mô hình nguồn đóng (GPT-3.5) thông qua chưng cất COT, mô hình của chúng tôi có thể tích hợp kiến thức này và tăng cường đáng kể hiệu suất trên các nhiệm vụ đồ thị phức tạp.

4.3 Điều tra Khả năng Tổng quát hóa (RQ2)

Trong phần này, chúng tôi khám phá khả năng tổng quát hóa của mô hình bằng cách kết hợp thêm dữ liệu hướng dẫn để tinh chỉnh LLM cho việc xử lý hiệu quả các loại nhiệm vụ khác nhau. Kết quả chính và quan sát thí nghiệm của chúng tôi được trình bày như sau:

Nhiều Dữ liệu Tăng cường Khả năng Chuyển đổi Mô hình. Trong điều tra sơ bộ, chúng tôi kiểm tra ảnh hưởng của số lượng dữ liệu đối với khả năng chuyển đổi của GraphGPT, như được minh họa trong cột "(Arxiv + PubMed)-Cora" của Bảng 1. Trong thí nghiệm này, chúng tôi huấn luyện mô hình bằng cách sử dụng kết hợp của tập dữ liệu Arxiv và PubMed và thực hiện kiểm tra không shot trên tập dữ liệu Cora. Kết quả cho thấy rằng bằng cách kết hợp tập dữ liệu PubMed tương đối nhỏ hơn (với 20.000+ mục) cùng với Arxiv, GraphGPT của chúng tôi thể hiện sự cải thiện đáng kể về hiệu suất chuyển đổi trên Cora. Ngược lại, hiệu suất chuyển đổi của các mô hình dựa trên GNN, được huấn luyện riêng biệt trên Arxiv và PubMed, thực sự giảm sút.

Nhiều Dữ liệu Nhưng Không Quên lãng. Chúng tôi tiếp tục xác thực hiệu suất của dữ liệu hướng dẫn kết hợp Arxiv và PubMed trên dữ liệu Arxiv ban đầu, như được thể hiện trong cột "(Arxiv + PubMed)-Arxiv" trong Bảng 1. Kết quả cho thấy rằng hầu hết các

Bảng 4: Nghiên cứu loại bỏ mô-đun dưới cả cài đặt có giám sát và không shot để phân tích các đóng góp cá nhân.

[Bảng chi tiết với các giá trị hiệu suất]

phương pháp dựa trên GNN truyền thống gặp phải sự suy giảm đáng kể về hiệu suất trên Arxiv sau khi huấn luyện lặp đi lặp lại. Ngược lại, mô hình của chúng tôi thể hiện hiệu suất được cải thiện. Chúng tôi gán hiện tượng này cho việc xảy ra quên lãng thảm khốc trong các mô hình dựa trên GNN, nơi năng lực mô hình hóa cấu trúc của mô hình được huấn luyện chỉ trên tập dữ liệu PubMed nhỏ hơn bị tổn hại. Tuy nhiên, mô hình của chúng tôi giảm thiểu hiệu quả vấn đề này thông qua mô hình điều chỉnh hướng dẫn đồ thị thống nhất. Điều này cho phép mô hình của chúng tôi duy trì và thậm chí tăng cường hiệu suất bằng cách giữ lại các mẫu cấu trúc đồ thị tổng quát hóa mặc dù kết hợp dữ liệu bổ sung.

Tổng quát hóa cho Học viên Đồ thị Đa nhiệm vụ. Các nghiên cứu gần đây về điều chỉnh hướng dẫn cho thấy rằng việc trộn các dữ liệu điều chỉnh hướng dẫn khác nhau có thể tăng cường thêm hiệu suất của Mô hình Ngôn ngữ và Logic (LLM). Trong nghiên cứu này, chúng tôi đảm bảo số lượng mục nhập hướng dẫn nhất quán và trộn các loại dữ liệu hướng dẫn khác nhau, bao gồm hướng dẫn tiêu chuẩn ("-std"), hướng dẫn COT ("-cot"), hỗn hợp hướng dẫn tiêu chuẩn (50%) và COT (50%) ("-mix"), và hướng dẫn dự đoán liên kết ("Link"). Kết quả được trình bày trong Bảng 2 và Bảng 3. Chúng tôi có thể quan sát thấy rằng các giải pháp hỗn hợp dữ liệu hiệu quả có thể cải thiện đáng kể hiệu suất của GraphGPT dưới các cài đặt khác nhau. Việc bổ sung hướng dẫn cụ thể cho nhiệm vụ cho nhiệm vụ dự đoán liên kết cải thiện đáng kể hiệu suất của mô hình trong phân loại nút. Thú vị là, sau khi kết hợp phân loại nút, hiệu suất của dự đoán liên kết cũng vượt qua các mô hình hiện có được chọn có hiệu suất tốt nhất. Sau khi trộn các hướng dẫn của các nhiệm vụ khác nhau, mô hình của chúng tôi thể hiện khả năng xử lý hiệu quả các nhiệm vụ học đồ thị khác nhau và chuyển đổi kiến thức của nó sang các tập dữ liệu chưa thấy khác.

4.4 Nghiên cứu Loại bỏ Mô-đun (RQ3)

Chúng tôi tiến hành nghiên cứu loại bỏ để điều tra các đóng góp cá nhân của các mô-đun con khác nhau trong khung được đề xuất, và kết quả được báo cáo trong Bảng 5. Các quan sát như sau:

Hiệu ứng của Điều chỉnh Hướng dẫn Đồ thị. Trong nghiên cứu của chúng tôi, chúng tôi điều tra lợi ích của việc kết hợp thông tin cấu trúc đồ thị vào LLM bằng cách sử dụng biến thể "w/o GS." Trong biến thể này, chúng tôi trực tiếp áp dụng LLM cơ sở (cụ thể là Vicuna-7B-v1.5) để thực hiện phân loại nút trên ba tập dữ liệu, mà không kết hợp thông tin cấu trúc đồ thị. Kết quả nghiên cứu của chúng tôi chứng minh rằng mô hình của chúng tôi vượt trội đáng kể so với mô hình cơ sở thiếu thông tin cấu trúc. Điều này cho thấy rằng mô hình điều chỉnh hướng dẫn đồ thị của chúng tôi cho phép LLM hiểu thông tin cấu trúc đồ thị hiệu quả hơn. Quan trọng là, sự cải thiện hiệu suất này đã được đạt được mà không thay đổi các tham số ban đầu của LLM. Thay vào đó, nó chỉ được thực hiện thông qua bộ chiếu căn chỉnh nhẹ của chúng tôi, căn chỉnh token đồ thị và token ngôn ngữ tự nhiên thông qua phép chiếu 1-tuyến tính.

--- TRANG 8 ---
Bảng 5: Nghiên cứu về hiệu quả thời gian và không gian của GraphGPT trong cả giai đoạn huấn luyện và suy luận.

[Bảng chi tiết với các số liệu về thời gian huấn luyện, tham số được điều chỉnh, và chiếm dụng GPU]

Hiệu ứng của Suy luận Ngữ nghĩa được Tăng cường bởi LLM. Chúng tôi tiến hành điều tra thêm để đánh giá ảnh hưởng của khả năng suy luận của LLM trong GraphGPT bằng cách thực hiện dự đoán có giám sát và không shot chỉ sử dụng các bộ mã hóa đồ thị mặc định. Biến thể này được ký hiệu là "w/o LR". Kết quả nghiên cứu của chúng tôi cho thấy rằng GraphGPT, tích hợp LLM, tăng cường đáng kể hiệu suất của bộ mã hóa đồ thị, đặc biệt trong cài đặt không shot. Điều này cho thấy rằng thông tin ngữ nghĩa phong phú được tiêm bởi LLM cung cấp một lợi ích đáng kể trong hiệu suất.

4.5 Nghiên cứu Hiệu quả Mô hình (RQ4)

Nghiên cứu nhằm mục đích đánh giá hiệu quả tính toán của mô hình trong cả giai đoạn huấn luyện và suy luận mô hình.

Hiệu quả Huấn luyện với Điều chỉnh Hướng dẫn Đồ thị. Khung điều chỉnh hướng dẫn của chúng tôi tuân theo quy trình hai giai đoạn trong đó các tham số của cả LLM và bộ mã hóa đồ thị đều được đóng băng, và chỉ bộ chiếu căn chỉnh đồ thị-văn bản được điều chỉnh. Chúng tôi tiến hành so sánh giữa việc đóng băng và điều chỉnh các tham số LLM trong môi trường 4-card 40G Nvidia A100, được ký hiệu bởi "-freeze" và "-tune" tương ứng. Nghiên cứu phân tích hiệu quả thời gian và không gian về mặt thời gian huấn luyện, số lượng tham số được điều chỉnh và chiếm dụng GPU (MiB trên mỗi GPU). Dưới cùng điều kiện thí nghiệm, khi điều chỉnh các tham số LLM, chúng tôi gặp phải lỗi Hết bộ nhớ (OOM) ngay cả với kích thước lô là 1. Tuy nhiên, bằng cách sử dụng chiến lược điều chỉnh của chúng tôi, quá trình huấn luyện vẫn ổn định ngay cả với kích thước lô là 2. Hơn nữa, số lượng tham số được điều chỉnh giảm hơn 50 lần so với giai đoạn đóng băng.

Hiệu quả Suy luận Mô hình. Trong khám phá của chúng tôi, chúng tôi đánh giá tốc độ suy luận và độ chính xác của GraphGPT bằng cách so sánh với các LLM baichuan-7B, vicuna-7B-v1.1, và vicuna-7B-v1.5. Sử dụng một 40G Nvidia A100, chúng tôi đo thời gian suy luận (giây trên mỗi phản hồi) trên các tập dữ liệu hướng dẫn COT Arxiv và Cora, như được hiển thị trong Hình 5. LLM đồ thị của chúng tôi thể hiện hiệu quả và độ chính xác vượt trội. Thời gian suy luận thấp hơn không nhất thiết có nghĩa là hiệu suất tốt hơn: baichuan-7B đưa ra câu trả lời nhanh nhưng thường không chính xác hoặc không liên quan, trong khi vicuna-7B-v1.1 và vicuna-7B-v1.5 yêu cầu các bước suy luận dài hơn, phức tạp hơn để có câu trả lời tốt hơn. Ngược lại, mô hình của chúng tôi đạt được dự đoán chính xác thông qua một quá trình suy luận ngắn gọn, tăng cường hiệu quả suy luận.

baichuan vicuna-v1.1 vicuna-v1.5 ours
Arxiv-Arxiv5.010.015.0 Thời gian Suy luận (s)

baichuan vicuna-v1.1 vicuna-v1.5 ours
Arxiv-Cora5.010.015.020.0 Thời gian Suy luận (s)

0.20.40.6
Accuracy

0.00.10.2
Accuracy

Thời gian Suy luận (s) Accuracy

Hình 5: Nghiên cứu hiệu quả suy luận của GraphGPT.

4.6 Nghiên cứu Tình huống Mô hình (RQ5)

Chúng tôi tiến hành phân tích chi tiết về hiệu suất mô hình trong các nhiệm vụ học đồ thị downstream so với các LLM truyền thống sử dụng các loại hướng dẫn khác nhau. Chúng tôi đánh giá ChatGPT và GraphGPT của chúng tôi sử dụng dữ liệu Arxiv, với các lời nhắc dựa trên nội dung nút, nội dung nút với cấu trúc đồ thị dựa trên văn bản, và hướng dẫn đồ thị được thiết kế của chúng tôi. Kết quả, được hiển thị trong Bảng 6, rõ ràng chứng minh rằng mặc dù có số lượng tham số khổng lồ (hơn 200B), ChatGPT gặp khó khăn trong việc đưa ra dự đoán chính xác chỉ dựa trên thông tin văn bản nút hoặc nội dung nút với cấu trúc đồ thị dựa trên văn bản. Thách thức này đặc biệt rõ ràng khi xử lý các bài báo có đặc tính liên ngành, như được thấy trong ví dụ về các lĩnh vực nghiên cứu trong học máy và kiến trúc phần cứng. Ngược lại, GraphGPT của chúng tôi liên tục cung cấp dự đoán chính xác và giải thích hợp lý. Điều này là do GraphGPT của chúng tôi kết hợp cấu trúc đồ thị con với 103 nút, cho phép nó trích xuất thông tin cấu trúc phong phú từ các mối quan hệ trích dẫn của các nút lân cận, dẫn đến dự đoán chính xác.

Hơn nữa, chúng tôi tin rằng phương pháp sử dụng token đồ thị để đại diện cho cấu trúc đồ thị như đầu vào cho LLM hiệu quả hơn giải pháp ngôn ngữ tự nhiên. Trong trường hợp đồ thị con 103 nút, GraphGPT của chúng tôi chỉ yêu cầu 750 token được đưa vào LLM, trong khi phương pháp dựa trên văn bản yêu cầu 4649 token. Việc giảm đáng kể tiêu thụ token này dẫn đến việc giảm đáng kể yêu cầu tài nguyên huấn luyện và suy luận.

5 CÔNG TRÌNH LIÊN QUAN

Học Tự giám sát và Tiền huấn luyện trên Đồ thị. Để tăng cường tính mạnh mẽ của các mô hình đồ thị, học tự giám sát (SSL) đã được giới thiệu như một kỹ thuật mạnh mẽ [13,16,24]. Nó cho phép GNN học các biểu diễn đồ thị có ý nghĩa mà không cần phụ thuộc nhiều vào dữ liệu có nhãn. Ý tưởng cốt lõi đằng sau học tự giám sát trong các mô hình đồ thị là thiết kế các nhiệm vụ pretext tận dụng cấu trúc và mẫu vốn có trong chính đồ thị để tạo ra các tín hiệu giám sát tự có ý nghĩa [52]. Các phương pháp học đồ thị được tăng cường bởi SSL có thể được phân loại rộng rãi thành hai mô hình chính: SSL đối chiếu và SSL tạo sinh. Cụ thể, i) SSL đối chiếu tập trung vào việc học biểu diễn bằng cách đối chiếu các mẫu tích cực và tiêu cực, với những tiến bộ đáng chú ý của GraphCL [59] và GCA [67]. Những tiến bộ gần đây trong SSL đối chiếu bao gồm tăng cường đối chiếu tự động (tức là JOAO [58], AdaGCL [15]), đối chiếu không gian kép Hyperbolic-Euclidean (ví dụ: DSGC [56]), hoặc học đối chiếu nhận thức cộng đồng (ví dụ: gCooL [20]). ii) SSL tạo sinh, mặt khác, tập trung vào việc tạo ra các mẫu thực tế giống với các cấu trúc đồ thị ban đầu. Những tiến bộ gần đây trong dòng này bao gồm GraphMAE [10,11] cho việc che giấu đặc trưng, và S2GAE [35], AutoCF [53] cho việc tái tạo các cạnh bị che giấu như các nhiệm vụ SSL.

Điều chỉnh-Lời nhắc cho Mạng Nơ-ron Đồ thị. Những nỗ lực gần đây trong việc tăng cường khả năng tổng quát hóa của mạng nơ-ron đồ thị (GNN) đã tập trung vào việc huấn luyện các mô hình GNN theo cách tự giám sát, sau đó tinh chỉnh trên các nhiệm vụ downstream cụ thể bằng cách sử dụng các kỹ thuật điều chỉnh-lời nhắc [64]. Ví dụ, GPPT [33] là một mô hình học chuyển đổi, trong đó GNN được tiền huấn luyện trên dự đoán cạnh bị che giấu và sau đó được nhắc nhở với các cặp token cho phân loại nút downstream. GraphPrompt [26] nhằm mục đích xử lý các nhiệm vụ downstream bằng cách tích hợp các nhiệm vụ tiền huấn luyện và downstream

--- TRANG 9 ---
Bảng 6: So sánh kết quả dự đoán giữa GraphGPT của chúng tôi và ChatGPT.

[Bảng chi tiết so sánh kết quả dự đoán với tiêu đề bài báo, danh mục thực tế, và phản hồi của các mô hình khác nhau]

vào một mẫu nhiệm vụ thống nhất. Ngoài ra, Sun et al. [34] trình bày một định dạng lời nhắc thống nhất, tái cấu trúc các nhiệm vụ ở cấp độ đồ thị, và kết hợp các kỹ thuật meta-learning để cải thiện hiệu suất đa nhiệm vụ trong việc nhắc nhở đồ thị. Mặc dù có những tiến bộ này, các phương pháp này vẫn yêu cầu tinh chỉnh thêm dựa vào nhãn giám sát từ các nhiệm vụ downstream để đảm bảo học chính xác. Ngược lại, công trình này giải quyết hạn chế này bằng cách giới thiệu một mô hình đồ thị cơ bản giải quyết nhiệm vụ đầy thách thức hơn của học đồ thị không shot. Bằng cách loại bỏ nhu cầu về đầu vào nhãn từ các nhiệm vụ downstream, phương pháp này cho phép một mô hình học đồ thị tổng quát và linh hoạt hơn trong các tình huống thực tế.

Mô hình Ngôn ngữ Lớn. Trong những năm gần đây, LLM (ví dụ: ChatGPT [29] và Claude [1]) đã thu hút sự chú ý rộng rãi vì khả năng đáng kể của chúng trong các nhiệm vụ NLP khác nhau [18,46]. Dựa trên những khả năng độc đáo này của LLM, nhiều kỹ thuật nhắc nhở không cần điều chỉnh đã được khám phá để tăng cường khả năng tạo sinh của chúng, chẳng hạn như học trong ngữ cảnh [28] và Chain-of-Thought [47,57]. Với sự phát triển của các LLM mã nguồn mở, như Llama [36,37], ChatGLM [62], và Baichuan [54], các công nghệ để căn chỉnh các LLM được tiền huấn luyện với các nhiệm vụ cụ thể khác nhau và phản hồi của con người đã được đề xuất, làm cho các LLM riêng tư trong các lĩnh vực cụ thể trở nên khả thi [19, 44, 45].

Mặc dù đã có những nỗ lực thành công trong việc căn chỉnh LLM với thông tin thị giác, như LLM đa phương thức [23,66], việc căn chỉnh LLM với các cấu trúc đồ thị vẫn chưa được khám phá nhiều. Nghiên cứu này giải quyết khoảng trống này bằng cách giới thiệu một mô hình điều chỉnh hướng dẫn đồ thị hai giai đoạn căn chỉnh hiệu quả khả năng ngôn ngữ của LLM với học đồ thị. Các nghiên cứu trước đây [2,5] đã cố gắng kết hợp thông tin đồ thị vào LLM bằng cách sử dụng ngôn ngữ tự nhiên, nhưng chúng đã gặp phải những thách thức trong việc xử lý các cấu trúc đồ thị phức tạp và đạt được sự hiểu biết sâu về đồ thị do những hạn chế của việc chỉ dựa vào các lời nhắc dựa trên văn bản.

6 KẾT LUẬN

Công trình này trình bày một mô hình ngôn ngữ lớn đồ thị hiệu quả và có thể mở rộng, nhằm mục đích cải thiện khả năng tổng quát hóa của các mô hình đồ thị. Khung được đề xuất, GraphGPT, tiêm kiến thức cấu trúc cụ thể về miền đồ thị vào LLM thông qua một mô hình điều chỉnh hướng dẫn đồ thị hai giai đoạn. Bằng cách tận dụng một bộ chiếu căn chỉnh đồ thị-văn bản đơn giản nhưng hiệu quả, chúng tôi cho phép LLM hiểu và diễn giải các thành phần cấu trúc của đồ thị. Các đánh giá mở rộng qua các cài đặt khác nhau chứng minh hiệu quả của phương pháp trong cả tình huống học đồ thị có giám sát và không shot. Hơn nữa, mô hình thể hiện khả năng tổng quát hóa mạnh mẽ, cho phép nó xử lý các tập dữ liệu và nhiệm vụ downstream đa dạng mà không bị quên lãng thảm khốc. Một hướng tiềm năng cho nghiên cứu tương lai là khám phá các kỹ thuật cắt tỉa để nén các tham số dư thừa hoặc ít quan trọng hơn của LLM, từ đó giảm kích thước mô hình tổng thể trong khi bảo tồn hiệu suất của nó.

--- TRANG 10 ---
TÀI LIỆU THAM KHẢO

[1]Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, et al .2022. Constitutional AI: Harmlessness from AI Feedback. CoRR abs/2212.08073 (2022).
[2]Zhikai Chen, Haitao Mao, Hang Li, et al .2023. Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs. CoRR abs/2307.03393 (2023).
[3]Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL-HLT (1) . Association for Computational Linguistics, 4171–4186.
[4]Yushun Dong, Ninghao Liu, Brian Jalaian, et al .2022. EDITS: Modeling and Mitigating Data Bias for Graph Neural Networks. In WWW . ACM, 1259–1269.
[5]Jiayan Guo, Lun Du, and Hengyu Liu. 2023. GPT4Graph: Can Large Language Models Understand Graph Structured Data ? An Empirical Evaluation and Benchmarking. CoRR abs/2305.15066 (2023).
[6]Zhichun Guo, Kehan Guo, Bozhao Nan, Yijun Tian, Roshni G. Iyer, et al .2023. Graph-based Molecular Representation Learning. In IJCAI . 6638–6646.
[7]William L. Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. In NeurIPS . 1024–1034.
[8]Xiaoxin He, Xavier Bresson, et al .2023. Explanations as Features: LLM-Based Features for Text-Attributed Graphs. CoRR abs/2305.19523 (2023).
[9]Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yong-Dong Zhang, and Meng Wang. 2020. LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation. In SIGIR . ACM, 639–648.
[10] Zhenyu Hou, Yufei He, Yukuo Cen, Xiao Liu, et al .2023. GraphMAE2: A Decoding-Enhanced Masked Self-Supervised Graph Learner. In WWW . 737–746.
[11] Zhenyu Hou, Xiao Liu, Yukuo Cen, Yuxiao Dong, Jie Tang, et al .2022. Graphmae: Self-supervised masked graph autoencoders. In KDD . 594–604.
[12] Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, et al .2020. Open Graph Benchmark: Datasets for Machine Learning on Graphs. In NeurIPS .
[13] Ziniu Hu, Yuxiao Dong, Kuansan Wang, Kai-Wei Chang, and Yizhou Sun. 2020. Gpt-gnn: Generative pre-training of graph neural networks. In KDD . 1857–1867.
[14] Ziniu Hu, Yuxiao Dong, Kuansan Wang, and Yizhou Sun. 2020. Heterogeneous Graph Transformer. In WWW . ACM / IW3C2, 2704–2710.
[15] Yangqin Jiang, Chao Huang, and Lianghao Huang. 2023. Adaptive graph contrastive learning for recommendation. In KDD . 4252–4261.
[16] Baoyu Jing, Chanyoung Park, and Hanghang Tong. 2021. Hdmi: High-order deep multiplex infomax. In WWW . 2414–2424.
[17] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR (Poster) . OpenReview.net.
[18] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. Large Language Models are Zero-Shot Reasoners. In NeurIPS .
[19] Harrison Lee, Samrat Phatale, Hassan Mansoor, Kellie Lu, Thomas Mesnard, et al .2023. RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback. CoRR abs/2309.00267 (2023).
[20] Bolian Li, Baoyu Jing, and Hanghang Tong. 2022. Graph communal contrastive learning. In WWW . 1203–1213.
[21] Guohao Li, Matthias Müller, Bernard Ghanem, and Vladlen Koltun. 2021. Training Graph Neural Networks with 1000 Layers. In ICML . 6437–6449.
[22] Mingkai Lin, Wenzhong Li, Ding Li, Yizhou Chen, and Sanglu Lu. 2022. Resource-Efficient Training for Large Graph Convolutional Networks with Label-Centric Cumulative Sampling. In WWW . ACM, 1170–1180.
[23] Haotian Liu, Chunyuan Li, et al. 2023. Visual Instruction Tuning.
[24] Yixin Liu, Ming Jin, Shirui Pan, Chuan Zhou, Yu Zheng, Feng Xia, and S Yu Philip. 2022. Graph self-supervised learning: A survey. TKDE 35, 6 (2022), 5879–5900.
[25] Yunchao Liu, Yu Wang, Oanh Vu, Rocco Moretti, et al .2023. Interpretable Chirality-Aware Graph Neural Network for Quantitative Structure Activity Relationship Modeling in Drug Discovery. In AAAI . 14356–14364.
[26] Zemin Liu, Xingtong Yu, et al .2023. Graphprompt: Unifying pre-training and downstream tasks for graph neural networks. In WWW . 417–428.
[27] Xiaojun Ma, Qin Chen, et al .2022. Meta-Weight Graph Neural Network: Push the Limits Beyond Global Homophily. In WWW . ACM, 1270–1280.
[28] Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022. Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?. In EMNLP . 11048–11064.
[29] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, et al .2022. Training language models to follow instructions with human feedback. In NeurIPS .
[30] Alec Radford, Jong Wook Kim, Chris Hallacy, et al .2021. Learning Transferable Visual Models From Natural Language Supervision. In International Conference on Machine Learning (ICML) . PMLR, 8748–8763.
[31] Zezhi Shao et al .2022. Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate Time Series Forecasting. In KDD . ACM, 1567–1577.
[32] Kumar Shridhar, Alessandro Stolfo, and Mrinmaya Sachan. 2023. Distilling Reasoning Capabilities into Smaller Language Models. In ACL. 7059–7073.
[33] Mingchen Sun, Kaixiong Zhou, et al .2022. Gppt: Graph pre-training and prompt tuning to generalize graph neural networks. In KDD . 1717–1727.
[34] Xiangguo Sun, Hong Cheng, Jia Li, Bo Liu, and Jihong Guan. 2023. All in One: Multi-Task Prompting for Graph Neural Networks. In KDD .
[35] Qiaoyu Tan, Ninghao Liu, Xiao Huang, Soo-Hyun Choi, Li Li, Rui Chen, and Xia Hu. 2023. S2GAE: Self-Supervised Graph Autoencoders are Generalizable Learners with Graph Masking. In WSDM . 787–795.
[36] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, et al .2023. LLaMA: Open and Efficient Foundation Language Models. CoRR abs/2302.13971 (2023).
[37] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, et al .2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. CoRR abs/2307.09288 (2023).
[38] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, et al .2017. Attention is all you need. In NeurIPS , Vol. 30.
[39] Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, et al . 2018. Graph Attention Networks. In ICLR (Poster) . OpenReview.net.
[40] Petar Velickovic, William Fedus, William L. Hamilton, Pietro Liò, et al .2019. Deep Graph Infomax. In ICLR (Poster) . OpenReview.net.
[41] Kuansan Wang, Zhihong Shen, et al .2020. Microsoft Academic Graph: When experts are not enough. Quant. Sci. Stud. 1, 1 (2020), 396–413.
[42] Xiang Wang, Tinglin Huang, Dingxian Wang, et al .2021. Learning Intents behind Interactions with Knowledge Graph for Recommendation. In WWW . 878–887.
[43] Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, et al .2019. Heterogeneous Graph Attention Network. In WWW . ACM, 2022–2032.
[44] Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot, Khyathi Raghavi Chandu, et al .2023. How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources. CoRR abs/2306.04751 (2023).
[45] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2023. Self-Instruct: Aligning Language Models with Self-Generated Instructions. In ACL. 13484–13508.
[46] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Jeff Dean, William Fedus, et al .2022. Emergent Abilities of Large Language Models. Trans. Mach. Learn. Res. 2022 (2022).
[47] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, and Denny Zhou. 2022. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. In NeurIPS .
[48] Wei Wei, Xubin Ren, Jiabin Tang, Qinyong Wang, Lixin Su, Suqi Cheng, Junfeng Wang, Dawei Yin, and Chao Huang. 2023. LLMRec: Large Language Models with Graph Augmentation for Recommendation. CoRR abs/2311.00423 (2023).
[49] Zhihao Wen and Yuan Fang. 2023. Augmenting Low-Resource Text Classification with Graph-Grounded Pre-training and Prompting. In SIGIR .
[50] Qitian Wu, Chenxiao Yang, et al .2023. DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion. In ICLR .
[51] Qitian Wu, Wentao Zhao, et al .2023. NodeFormer: A Scalable Graph Structure Learning Transformer for Node Classification. CoRR abs/2306.08385 (2023).
[52] Jun Xia, Lirong Wu, Jintao Chen, et al .2022. Simgrace: A simple framework for graph contrastive learning without data augmentation. In WWW . 1070–1079.
[53] Lianghao Xia, Chao Huang, Tao Yu, Ben Kao, et al .2023. Automated Self-Supervised Learning for Recommendation. In WWW . 992–1002.
[54] Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, et al .2023. Baichuan 2: Open Large-scale Language Models. CoRR abs/2309.10305 (2023).
[55] Chenxiao Yang, Qitian Wu, and Junchi Yan. 2022. Geometric Knowledge Distillation: Topology Compression for Graph Neural Networks. In NeurIPS .
[56] Haoran Yang, Hongxu Chen, Shirui Pan, Lin Li, Philip S Yu, and Guandong Xu. 2022. Dual space graph contrastive learning. In WWW . 1238–1247.
[57] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. Tree of Thoughts: Deliberate Problem Solving with Large Language Models. CoRR abs/2305.10601 (2023).
[58] Yuning You, Tianlong Chen, Yang Shen, and Zhangyang Wang. 2021. Graph contrastive learning automated. In ICML . PMLR, 12121–12132.
[59] Yuning You, Tianlong Chen, Yongduo Sui, et al .2020. Graph contrastive learning with augmentations. In NeurIPS , Vol. 33. 5812–5823.
[60] Seongjun Yun, Minbyul Jeong, Raehyun Kim, Jaewoo Kang, and Hyunwoo J. Kim. 2019. Graph Transformer Networks. In NeurIPS . 11960–11970.
[61] Seongjun Yun, Minbyul Jeong, Raehyun Kim, Jaewoo Kang, and Hyunwoo J Kim. 2019. Graph transformer networks. In NeurIPS , Vol. 32.
[62] Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, et al . 2023. GLM-130B: An Open Bilingual Pre-trained Model. In ICLR .
[63] Shichang Zhang, Yozen Liu, Yizhou Sun, and Neil Shah. 2022. Graph-less Neural Networks: Teaching Old MLPs New Tricks Via Distillation. In ICLR .
[64] Wen Zhang, Yushan Zhu, Mingyang Chen, et al .2023. Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer. In WWW . 2581–2590.
[65] Yanfu Zhang et al .2022. Robust Self-Supervised Structural Graph Neural Network for Social Network Prediction. In WWW . ACM, 1352–1361.
[66] Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. 2023. MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models. arXiv preprint arXiv:2304.10592 (2023).
[67] Yanqiao Zhu, Yichen Xu, Feng Yu, Qiang Liu, Shu Wu, and Liang Wang. 2021. Graph contrastive learning with adaptive augmentation. In WWW . 2069–2080.

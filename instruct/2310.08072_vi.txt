# Huấn luyện Hệ thống Hỏi-Đáp Sinh tạo trên Dữ liệu Tổng hợp Thu được từ Mô hình được Điều chỉnh Theo Hướng dẫn

Kosuke Takahashi, Takahiro Omi, Kosuke Arima
Stockmark
kosuke.takahashi, takahiro.omi, kosuke.arima@stockmark.co.jp
Tatsuya Ishigaki
Viện Khoa học và Công nghệ Công nghiệp Tiên tiến Quốc gia
ishigaki.tatsuya@aist.go.jp

## Tóm tắt
Bài báo này trình bày một phương pháp đơn giản và hiệu quả về chi phí để tổng hợp dữ liệu huấn luyện hệ thống hỏi-đáp. Đối với việc huấn luyện, tinh chỉnh các mô hình GPT là một thực hành phổ biến trong các ngôn ngữ giàu tài nguyên như tiếng Anh, tuy nhiên, nó trở nên thách thức đối với các ngôn ngữ không phải tiếng Anh do sự khan hiếm của các cặp câu hỏi-câu trả lời (QA) đầy đủ. Các phương pháp hiện có sử dụng các bộ sinh câu hỏi và câu trả lời được huấn luyện trên các cặp QA do con người tạo ra, điều này liên quan đến chi phí nhân sự đáng kể. Ngược lại, chúng tôi sử dụng một mô hình được điều chỉnh theo hướng dẫn để tạo ra các cặp QA theo cách zero-shot hoặc few-shot. Chúng tôi tiến hành các thí nghiệm để so sánh các chiến lược khác nhau để thu được các cặp QA từ mô hình được điều chỉnh theo hướng dẫn. Kết quả cho thấy rằng một mô hình được huấn luyện trên dữ liệu tổng hợp được đề xuất của chúng tôi đạt được hiệu suất tương đương với một mô hình được huấn luyện trên các bộ dữ liệu được tuyển chọn thủ công, mà không phát sinh chi phí nhân sự.

## 1 Giới thiệu
Tinh chỉnh các mô hình ngôn ngữ lớn (LLMs) đã được chứng minh là hiệu quả cho việc nâng cao hệ thống hỏi-đáp (Dong et al., 2019). Tuy nhiên, việc mở rộng phương pháp này sang các ngôn ngữ khác ngoài tiếng Anh gặp phải thách thức do sự khan hiếm của các cặp QA phù hợp để huấn luyện. Trong nghiên cứu này, chúng tôi đặc biệt nhắm đến tiếng Nhật như một ngôn ngữ không phải tiếng Anh đại diện. Chúng tôi đề xuất một cách tiếp cận đơn giản để tổng hợp các cặp QA tiếng Nhật sử dụng một mô hình được điều chỉnh theo hướng dẫn.¹

Các nhiệm vụ hỏi-đáp có thể được phân loại thành hai thiết lập chính: câu hỏi có ngữ cảnh và không có ngữ cảnh (Kurihara et al., 2022). Trong nghiên cứu này, chúng tôi tập trung vào thiết lập dựa trên ngữ cảnh như được hiển thị trong Hình 1. Trong thiết lập này, hệ thống nhận một câu hỏi cùng với ngữ cảnh đi kèm làm đầu vào. Mô hình tạo ra một câu trả lời bằng cách sử dụng thông tin được cung cấp trong ngữ cảnh. Mặt khác, thiết lập không có ngữ cảnh liên quan đến việc hệ thống chỉ xử lý câu hỏi làm đầu vào.

¹Các thí nghiệm của chúng tôi sử dụng ChatAPI của OpenAI với mô hình gpt-3.5-turbo-0613.

Hình 1: Nhiệm vụ của QA sinh tạo có nhận thức ngữ cảnh.

Chúng tôi trình bày một phương pháp đơn giản nhưng hiệu quả về chi phí để tạo ra các cặp câu hỏi-câu trả lời (QA) tổng hợp. Các hệ thống QA hiện có được huấn luyện trên các bộ dữ liệu do con người tạo ra hoặc các cặp QA được tạo tự động (Sachan and Xing, 2018; Tang et al., 2018), cả hai đều dẫn đến chi phí lao động cao. Ngược lại, bài báo này nghiên cứu việc sử dụng một mô hình được điều chỉnh theo hướng dẫn được lấy cảm hứng từ khả năng hợp lý của chúng trong việc tạo ra bộ dữ liệu tổng hợp (Gilardi et al., 2023). Chúng tôi sử dụng một ngữ cảnh làm đầu vào và tạo ra cả câu hỏi tương ứng và câu trả lời của nó. Mô hình được điều chỉnh theo hướng dẫn cho phép chúng tôi tạo ra các cặp QA theo cách zero-shot hoặc few-shot, loại bỏ nhu cầu tuyển chọn thủ công.

Các thí nghiệm của chúng tôi so sánh các hệ thống hỏi-đáp được tinh chỉnh trên dữ liệu tổng hợp được tạo ra thông qua các chiến lược khác nhau. Cụ thể, chúng tôi khám phá các nguồn ngữ cảnh khác nhau, số lượng shots được đưa vào mô hình được điều chỉnh theo hướng dẫn, và số lượng cặp QA được tạo ra. Việc đánh giá trên bộ dữ liệu đánh giá JSQuAD (Kurihara et al., 2022) cung cấp ba phát hiện. Thứ nhất, việc sử dụng các ngữ cảnh được trích xuất từ một corpus có đặc điểm tương tự với bộ dữ liệu đánh giá mang lại hiệu suất được cải thiện. Thứ hai, chiến lược one-shot vượt trội hơn cách tiếp cận zero-shot. Cuối cùng, tạo ra ba cặp QA cho mỗi ngữ cảnh hiệu quả hơn việc tạo ra số lượng cặp QA thấp hơn. Mô hình hiệu suất tốt nhất được tinh chỉnh trên dữ liệu tổng hợp của chúng tôi thể hiện hiệu suất tương đương với các mô hình được huấn luyện trên dữ liệu được tuyển chọn thủ công.

## 2 Nghiên cứu Liên quan
QA hiện có tập trung vào hai thiết lập chính: "closedQA" có ngữ cảnh và "commonsens-QA" không có ngữ cảnh (Kurihara et al., 2022). Đối với thiết lập đầu tiên, mà chúng tôi nhắm đến, các hệ thống QA nhận một câu hỏi cùng với một ngữ cảnh, chẳng hạn như một bài viết Wikipedia, và tạo ra một câu trả lời. Mặt khác, trong thiết lập sau, các hệ thống chỉ nhận một câu hỏi làm đầu vào.

Có hai loại hệ thống QA: trích xuất và sinh tạo. Các phương pháp trích xuất trích xuất một câu trả lời như nó là từ ngữ cảnh bằng các mô hình như BERT (Rajpurkar et al., 2016), trong khi các phương pháp sinh tạo thường sử dụng các biểu thức không có trong ngữ cảnh bằng các mô hình như T5 (Raffel et al., 2020) hoặc GPT (Brown et al., 2020). Chúng tôi tập trung vào phương pháp sau.

Trong khi có một số bộ dữ liệu được tạo thủ công tồn tại bằng tiếng Anh, chẳng hạn như SQuAD (Rajpurkar et al., 2016) và QuALITY (Pang et al., 2022), những tài nguyên này không áp dụng trực tiếp cho ngôn ngữ Nhật. Đối với tiếng Nhật, JSQuAD (Kurihara et al., 2022) và JAQKET² có sẵn. Chúng tôi sử dụng JSQuAD³ vì dữ liệu đánh giá của JAQKET không được công khai.

Các nghiên cứu hiện có tổng hợp các cặp QA bằng hai phương pháp chính: có giám sát (Lee et al., 2020; Sachan and Xing, 2018; Tang et al., 2018) và không giám sát (Puri et al., 2020). Các phương pháp có giám sát huấn luyện các bộ sinh câu hỏi-câu trả lời sử dụng các bộ dữ liệu được tạo thủ công. Phương pháp của chúng tôi tạo ra các cặp QA từ ngữ cảnh theo cách zero-shot hoặc few-shot, loại bỏ nhu cầu huấn luyện các bộ sinh. Trong phương pháp không giám sát, Puri et al. (2020) sử dụng một trình nhận dạng thực thể có tên (NER) để trích xuất ứng cử viên câu trả lời trong khi phương pháp của chúng tôi chỉ sử dụng một mô hình được điều chỉnh theo hướng dẫn một cách end-to-end và không yêu cầu NER.

## 3 Tổng hợp Các cặp QA
Chúng tôi mô tả phương pháp của chúng tôi trong phần này.

²https://www.nlp.ecei.tohoku.ac.jp/projects/jaqket/#Reference
³Nghiêm ngặt, JSQuAD không phải để đánh giá QA sinh tạo, mà là thiết lập dựa trên trích xuất span. Chúng tôi sử dụng dữ liệu này vì không có dữ liệu đánh giá phổ biến bằng tiếng Nhật cho QA sinh tạo. Các mô hình của chúng tôi tạo ra câu trả lời không trích xuất spans, do đó, chúng tôi cũng tiến hành đánh giá của con người.

Dựa trên các văn bản đã cho, vui lòng tạo một cặp câu hỏi và câu trả lời có thể trả lời được.
Vui lòng tạo câu trả lời bằng ngôn ngữ lịch sự tiếng Nhật.
Vui lòng phản hồi theo định dạng JSON.
## ví dụ
texts:"văn bản để trích xuất cặp câu hỏi và câu trả lời"
output: {"Question":"câu hỏi có thể được trả lời từ các văn bản", "Answer":"câu trả lời cho câu hỏi"}
## đầu vào
texts: {ngữ cảnh QA}
output:

Hình 2: Một ví dụ về prompt zero-shot để tạo ra một cặp QA.

texts:"Giải quyết nợ kỹ thuật là khó khăn; chúng ta nhìn vào thách thức của JAL...(bỏ qua)...khẩu hiệu của JAL là Go To Cloud...(bỏ qua),
output: {"Question":"Japan Airlines có khẩu hiệu gì?", "Answer":"Khẩu hiệu của JAL là Go To Cloud."}

Hình 3: Một mẫu đã dịch của phần "## example" trong prompt one-shot. Lưu ý rằng bản gốc bằng tiếng Nhật.

### 3.1 Ngữ cảnh Nguồn và Lọc
Chúng tôi tạo ra N cặp câu hỏi-câu trả lời từ mỗi ngữ cảnh. N được đặt là một hoặc ba trong các thí nghiệm của chúng tôi. Chúng tôi so sánh ba nguồn ngữ cảnh cụ thể: 1) một mẫu ngẫu nhiên gồm 6.000 bài viết Wikipedia tiếng Nhật (wiki), 2) một mẫu ngẫu nhiên gồm 6.000 bài viết tin tức (news), và 3) các ngữ cảnh trong bộ dữ liệu huấn luyện của JSQuAD (JSQuAD). Để thu thập các bài viết tin tức, chúng tôi đã thu thập các bài viết được truy cập nhiều nhất từ một công cụ tìm kiếm⁴ trong giai đoạn từ tháng 5 năm 2022 đến tháng 5 năm 2023. Chúng tôi giới hạn mỗi ngữ cảnh ở 300 ký tự đầu tiên trước khi tạo ra các cặp QA bằng mô hình được điều chỉnh theo hướng dẫn.

### 3.2 Prompts để Tạo ra Các cặp QA
Chúng tôi cung cấp các ví dụ về prompts zero-shot và one-shot với thiết lập N = 1 trong Hình 2 và Hình 3, tương ứng. Những prompts này nhằm mục đích tạo ra các cặp QA từ một ngữ cảnh. Trong prompt zero-shot, chúng tôi đầu tiên trình bày các hướng dẫn nhiệm vụ, theo sau là một giải thích về cấu trúc của cách một văn bản đầu vào được biểu diễn, và cấu trúc JSON đầu ra mong muốn của chúng như được hiển thị trong phần "## example". Đối với thiết lập N > 1, chúng tôi sửa đổi ví dụ của cấu trúc JSON để bao gồm nhiều cặp QA hơn. Sau đó, chúng tôi viết một văn bản đầu vào trong phần "## input". Trong thiết lập prompt zero-shot, chúng tôi chỉ viết định dạng của cấu trúc đầu vào và đầu ra, mà không bao gồm các văn bản thực tế hoặc các cặp câu hỏi-câu trả lời dự kiến tương ứng với ngữ cảnh. Mặt khác, trong prompt one-shot, chúng tôi thay thế phần "## example" trong 2 bằng prompt được hiển thị trong Hình 3. Không giống như prompt zero-shot, prompt one-shot bao gồm các ngữ cảnh ví dụ thực tế và các cặp QA dự kiến tương ứng của chúng. Để hiểu rõ hơn về tác động của kỹ thuật prompt, chúng tôi so sánh hai prompts này trong các thí nghiệm của chúng tôi. Các tuple của một ngữ cảnh và các cặp QA được tạo ra được sử dụng để tinh chỉnh một GPT bằng prompt được hiển thị trong Hình 4.

⁴URL của engine/dataset được ẩn để bảo vệ tính ẩn danh của các tác giả, và sẽ được hiển thị sau khi chấp nhận

## 4 Thí nghiệm
Bộ dữ liệu Đánh giá và Các mô hình So sánh: Chúng tôi sử dụng JSQuAD (Kurihara et al., 2022) để đánh giá. Dữ liệu đánh giá này chứa 4.470 cặp QA do con người tạo ra được đưa các bài viết Wikipedia làm ngữ cảnh. Chúng tôi sử dụng toàn bộ dữ liệu đánh giá cho việc đánh giá tự động trong khi 500 trường hợp được lấy mẫu ngẫu nhiên được sử dụng cho đánh giá thủ công.

Chúng tôi tiến hành một so sánh toàn diện bằng cách khám phá các kết hợp khác nhau của ngữ cảnh, số lượng cặp QA được tạo ra ký hiệu là N và prompts. Về ngữ cảnh, chúng tôi xem xét ba tùy chọn: wiki, news, JSQuAD, và, như đã nêu chi tiết trong Mục 3.1. Đối với N, chúng tôi so sánh N = 1 và N = 3. Chúng tôi so sánh các prompts zero-shot và one-shot⁵.

Các mô hình được đề xuất của chúng tôi được so sánh với hai mô hình: 1) một mô hình GPT thuần túy không có tinh chỉnh và 2) một mô hình được tinh chỉnh trên các cặp QA từ bộ dữ liệu huấn luyện JSQuAD (Human), trong đó những cặp QA này do con người tạo ra trong khi các cặp QA được đề xuất của chúng tôi không phải do con người tạo ra.

Tinh chỉnh Chúng tôi sử dụng các cặp QA tổng hợp để tinh chỉnh phiên bản tiếng Nhật của GPT-NeoX (Black et al., 2022)⁶. Để đạt được tốc độ được cải thiện, chúng tôi sử dụng tinh chỉnh LoRA (Hu et al., 2022). Trong việc tạo ra câu trả lời, chúng tôi sử dụng một prompt trong thiết lập zero-shot (Hình 4).

⁵Chúng tôi bị hạn chế ở one-shot do giới hạn độ dài đầu vào của ChatGPT.
⁶https://huggingface.co/cyberagent/open-calm-7b

## Hướng dẫn
{QUESTION}
## Ngữ cảnh
{CONTEXT}
## Phản hồi

Hình 4: Prompt để tạo ra câu trả lời với GPT-NeoX được tinh chỉnh.

Batch Size: {4, 8},
Learning Rate: {0.00001, 0.00005, 0.000001},
Epoch: {3, 4, 5,}, r: {4, 8, 16, 64, 128}, α: {1, 4, 16}

Bảng 1: Các giá trị phạm vi tìm kiếm trong tinh chỉnh LoRA.

Chỉ số: Để đánh giá tự động, chúng tôi sử dụng BERTScore (Zhang et al., 2020) và BLEU (Papineni et al., 2002). BERTScore được thực hiện tự phát triển với một mô hình BERT tiếng Nhật⁷. Đối với BLEU, thư viện SacreBLEU (Post, 2018) được sử dụng.

Những chỉ số tự động này có thể không trực tiếp nắm bắt được tính đúng đắn của một câu trả lời cho một câu hỏi đã cho. Để giải quyết điều này, chúng tôi cũng tiến hành đánh giá thủ công bằng các giám khảo con người. Chúng tôi yêu cầu bốn giám khảo, những người là chuyên gia về xử lý ngôn ngữ tự nhiên hoặc ngôn ngữ học, đánh giá xem câu trả lời được tạo ra có đúng hay không. Chúng tôi đã hiển thị các tuple gồm câu hỏi, câu trả lời và ngữ cảnh cho các giám khảo. Chúng tôi báo cáo độ chính xác thu được từ đánh giá thủ công.

Tham số Chúng tôi đã tiến hành tìm kiếm lưới để điều chỉnh các tham số: kích thước batch, tỷ lệ học, số lượng epochs, cũng như các siêu tham số của LoRA (cụ thể là α và r). Phạm vi giá trị được khám phá trong quá trình tìm kiếm này được cung cấp trong Bảng 1. Sau đó, mô hình đạt được BERTScore cao nhất được chọn để đánh giá.

⁷https://huggingface.co/cl-tohoku/bert-base-japanese-v3

## 5 Kết quả
Trong phần này, chúng tôi trình bày kết quả trên JSQuAD.

### 5.1 Đánh giá Tự động
Mối quan tâm chính của chúng tôi nằm ở việc kiểm tra tác động của mỗi chiến lược tổng hợp các cặp QA đối với hiệu suất của nhiệm vụ hỏi-đáp sau này. Cụ thể, chúng tôi tập trung vào các so sánh liên quan đến các ngữ cảnh khác nhau, prompts và số lượng cặp QA được tạo tự động.

Bảng 2 trình bày điểm số BERTScore và BLEU thu được bằng cách thay đổi các ngữ cảnh trong khi giữ các thiết lập khác, tức là N và prompts được cố định. Bảng được chia thành năm phần. Bắt đầu từ trên cùng, phần đầu tiên hiển thị điểm số cho các mô hình QA được huấn luyện trên các cặp QA do con người tạo ra (Human) từ bộ dữ liệu huấn luyện JSQuAD, cùng với mô hình GPT thuần túy (GPT) không có tinh chỉnh. Phần thứ hai và thứ ba thể hiện điểm số thu được khi N được cố định là một, nhưng chúng tôi thay đổi các prompts thành zero-shot và one-shot. Phần thứ tư và thứ năm đại diện cho điểm số khi chúng tôi sử dụng N = 3.

Tác động của Ngữ cảnh đối với Hiệu suất: Chúng tôi quan sát thấy rằng việc sử dụng các ngữ cảnh được trích xuất từ bộ dữ liệu tin tức mang lại điểm số tương đối thấp, ví dụ, 0.713 và 0.747 về BERTScore cho các thiết lập zero-shot và one-shot với N = 3, tương ứng. Ngữ cảnh wiki hoạt động tốt hơn (0.706 và 0.838) so với news (0.713 và 0.747) cho các thiết lập tương tự. Đáng chú ý, ngữ cảnh JSQuAD đạt được BERTScore cao nhất là 0.863 và 0.889 với N = 1 và N = 3, tương ứng. Kết quả cho thấy rằng việc sử dụng Wikipedia làm ngữ cảnh cung cấp một lợi thế, có thể vì dữ liệu đánh giá JSQuAD cũng được bắt nguồn từ Wikipedia.

Tác động của Prompts đối với Hiệu suất: Prompt one-shot hiệu quả hơn. Như được hiển thị trong Bảng 2, mô hình được tinh chỉnh trên các cặp QA zero-shot (N = 1) được tạo ra từ các ngữ cảnh trong bộ dữ liệu huấn luyện JSQuAD đạt được BERTScore là 0.724. Tuy nhiên, các prompts one-shot với N = 1 thể hiện một sự tăng hiệu suất đáng kể, đạt BERTScore là 0.863.

Tác động của Số lượng Cặp QA được Tạo ra đối với Hiệu suất: Khi chúng tôi tăng số lượng cặp QA cho ngữ cảnh, có một sự tăng 2.6 điểm trong BERTScore (từ 0.863 lên 0.889). Đáng chú ý, BERTScore đạt được là 0.889 tương đương với của một mô hình được huấn luyện trên các cặp QA do con người tạo ra (0.899), mặc dù phương pháp của chúng tôi không sử dụng bất kỳ cặp QA nào do con người tạo ra.

context N prompt BERTscore BLEU
Human - - 0.899 5.64
GPT - - 0.601 0.00
news 1 zero 0.697 0.02
wiki 1 zero 0.713 0.03
JSQuAD 1 zero 0.724 1.55
news 1 one 0.738 0.11
wiki 1 one 0.775 0.09
JSQuAD 1 one 0.863 4.83
news 3 zero 0.713 0.38
wiki 3 zero 0.706 0.23
JSQuAD 3 zero 0.740 1.85
news 3 one 0.747 1.25
wiki 3 one 0.838 1.66
JSQuAD 3 one 0.889 6.77

Bảng 2: Hiệu suất trên các ngữ cảnh khác nhau và số lượng cặp QA được tạo ra.

### 5.2 Đánh giá bởi Giám khảo Con người:
Chúng tôi trình bày kết quả của đánh giá thủ công. Bảng 3 hiển thị các so sánh giữa ba đầu ra: câu trả lời được tạo ra bởi 1) mô hình hiệu suất tốt nhất của chúng tôi (JSQuAD (N = 3), và prompt one-shot) và 2) một mô hình được tinh chỉnh trên các cặp QA do con người tạo ra từ bộ dữ liệu huấn luyện JSQuAD, và 3) câu trả lời vàng trong bộ dữ liệu đánh giá JSQuAD.

Cặp QA Độ chính xác (%)
JSQuAD (N = 3, prompt one-shot) 45.4
Human 38.4
Gold 90.4

Bảng 3: Độ chính xác được tính bằng số lượng tuple câu hỏi-ngữ cảnh-câu trả lời đúng chia cho tổng số 500 trường hợp đánh giá.

Đáng chú ý, mặc dù phương pháp của chúng tôi không sử dụng bất kỳ cặp QA nào do con người tạo ra, độ chính xác đạt được là 45.4% trong khi mô hình được tinh chỉnh trên các cặp QA do con người tạo ra chỉ đạt được 38.4% về độ chính xác. Gilardi et al. (2023) đề cập rằng việc chú thích tự động với một mô hình điều chỉnh theo hướng dẫn có chất lượng cao hơn các chú thích của crowd-workers, và kết quả của chúng tôi phù hợp với tuyên bố của họ. Lưu ý rằng hiệu suất của cả hai mô hình được tinh chỉnh đều tụt hậu đáng kể so với tiêu chuẩn Gold (90.4%), cho thấy vẫn còn nhiều chỗ để cải thiện.

## 6 Kết luận
Bài báo này đề xuất sử dụng một mô hình được điều chỉnh theo hướng dẫn để tổng hợp các cặp QA. Kết quả thí nghiệm của chúng tôi chứng minh rằng các mô hình được huấn luyện trên các cặp QA được tạo tự động đạt được hiệu suất tương đương hoặc thậm chí vượt trội so với mô hình được tinh chỉnh được huấn luyện trên các cặp QA do con người tạo ra. Trong các nghiên cứu tương lai, chúng tôi dự định khám phá mối quan hệ giữa sự đa dạng của các cặp QA được tạo tự động và tác động của chúng đối với hiệu suất của các nhiệm vụ QA sau này.

## Tài liệu Tham khảo
Sidney Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, Usvsn Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, and Samuel Weinbach. 2022. GPT-NeoX-20B: An open-source autoregressive language model. In Proceedings of BigScience Episode #5 – Workshop on Challenges & Perspectives in Creating Large Language Models, pages 95–136, virtual+Dublin. Association for Computational Linguistics.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems, volume 33, pages 1877–1901. Curran Associates, Inc.

Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, and Hsiao-Wuen Hon. 2019. Unified language model pre-training for natural language understanding and generation. In Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.

Fabrizio Gilardi, Meysam Alizadeh, and Maël Kubli. 2023. Chatgpt outperforms crowd workers for text-annotation tasks. Proceedings of the National Academy of Sciences, 120(30):e2305016120.

Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022. LoRA: Low-rank adaptation of large language models. In International Conference on Learning Representations.

Kentaro Kurihara, Daisuke Kawahara, and Tomohide Shibata. 2022. JGLUE: Japanese general language understanding evaluation. In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 2957–2966, Marseille, France. European Language Resources Association.

Dong Bok Lee, Seanie Lee, Woo Tae Jeong, Donghwan Kim, and Sung Ju Hwang. 2020. Generating diverse and consistent QA pairs from contexts with information-maximizing hierarchical conditional VAEs. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 208–224, Online. Association for Computational Linguistics.

Richard Yuanzhe Pang, Alicia Parrish, Nitish Joshi, Nikita Nangia, Jason Phang, Angelica Chen, Vishakh Padmakumar, Johnny Ma, Jana Thompson, He He, and Samuel Bowman. 2022. QuALITY: Question answering with long input texts, yes! In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5336–5358, Seattle, United States. Association for Computational Linguistics.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.

Matt Post. 2018. A call for clarity in reporting BLEU scores. In Proceedings of the Third Conference on Machine Translation: Research Papers, pages 186–191, Brussels, Belgium. Association for Computational Linguistics.

Raul Puri, Ryan Spring, Mohammad Shoeybi, Mostofa Patwary, and Bryan Catanzaro. 2020. Training question answering models from synthetic data. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5811–5826, Online. Association for Computational Linguistics.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140):1–67.

Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD: 100,000+ questions for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2383–2392, Austin, Texas. Association for Computational Linguistics.

Mrinmaya Sachan and Eric Xing. 2018. Self-training for jointly learning to ask and answer questions. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 629–640, New Orleans, Louisiana. Association for Computational Linguistics.

Duyu Tang, Nan Duan, Zhao Yan, Zhirui Zhang, Yibo Sun, Shujie Liu, Yuanhua Lv, and Ming Zhou. 2018. Learning to collaborate for question answering and asking. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1564–1574, New Orleans, Louisiana. Association for Computational Linguistics.

Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020. Bertscore: Evaluating text generation with bert. In International Conference on Learning Representations.

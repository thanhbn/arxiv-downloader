# 2005.00944.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/instruct/2005.00944.pdf
# Kích thước tệp: 1497478 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
HIỂU VÀ CẢI THIỆN VIỆC TRUYỀN TẢI THÔNG TIN
TRONG HỌC ĐA NHIỆM VỤ
Sen Wu
Đại học StanfordHongyang R. Zhang
Đại học PennsylvaniaChristopher Ré
Đại học Stanford
TÓM TẮT
Chúng tôi nghiên cứu các phương pháp học đa nhiệm vụ sử dụng biểu diễn đặc trưng chung
cho tất cả các nhiệm vụ. Để hiểu rõ hơn việc truyền tải thông tin nhiệm vụ, chúng tôi nghiên cứu
một kiến trúc với một mô-đun chung cho tất cả các nhiệm vụ và một mô-đun đầu ra riêng biệt
cho mỗi nhiệm vụ. Chúng tôi nghiên cứu lý thuyết của thiết lập này trên các mô hình tuyến tính
và được kích hoạt bởi ReLU. Quan sát chính của chúng tôi là việc dữ liệu của các nhiệm vụ có
được căn chỉnh tốt hay không có thể ảnh hưởng đáng kể đến hiệu suất của học đa nhiệm vụ.
Chúng tôi chỉ ra rằng sự không căn chỉnh giữa dữ liệu nhiệm vụ có thể gây ra chuyển giao tiêu
cực (hoặc làm tổn hại hiệu suất) và cung cấp các điều kiện đủ cho chuyển giao tích cực. Được
truyền cảm hứng từ những hiểu biết lý thuyết, chúng tôi chỉ ra rằng việc căn chỉnh các lớp nhúng
của nhiệm vụ dẫn đến những cải thiện hiệu suất cho huấn luyện đa nhiệm vụ và học chuyển giao
trên bộ dữ liệu chuẩn GLUE và các nhiệm vụ phân tích cảm xúc; ví dụ, chúng tôi thu được cải
thiện điểm GLUE trung bình 2.35% trên 5 nhiệm vụ GLUE so với BERT LARGE sử dụng phương
pháp căn chỉnh của chúng tôi. Chúng tôi cũng thiết kế một sơ đồ tái cân bằng trọng số nhiệm vụ
dựa trên SVD và chỉ ra rằng nó cải thiện tính mạnh mẽ của huấn luyện đa nhiệm vụ trên bộ dữ
liệu hình ảnh đa nhãn.

1 GIỚI THIỆU
Học đa nhiệm vụ gần đây đã nổi lên như một mô hình mạnh mẽ trong học sâu để thu được các biểu
diễn ngôn ngữ (Devlin et al. (2018); Liu et al. (2019a;b)) và thị giác (Kokkinos (2017)) từ dữ liệu
quy mô lớn. Bằng cách tận dụng dữ liệu có giám sát từ các nhiệm vụ liên quan, các phương pháp
học đa nhiệm vụ giảm chi phí đắt đỏ của việc tuyển chọn các bộ dữ liệu huấn luyện riêng cho từng
nhiệm vụ khổng lồ cần thiết cho các phương pháp học sâu và cung cấp một biểu diễn chung cũng
hiệu quả hơn cho việc học trên nhiều nhiệm vụ. Trong khi trong một số trường hợp, những cải thiện
lớn đã được báo cáo so với học đơn nhiệm vụ (McCann et al. (2018)), các thực hành viên cũng đã
quan sát thấy những kết quả có vấn đề, trong đó hiệu suất của một số nhiệm vụ nhất định đã giảm
do sự can thiệp của nhiệm vụ (Alonso and Plank (2016); Bingel and Søgaard (2017)). Dự đoán
khi nào và cho những nhiệm vụ nào điều này xảy ra là một thách thức được làm trầm trọng thêm
bởi việc thiếu các công cụ phân tích. Trong công trình này, chúng tôi nghiên cứu các thành phần
chính để xác định liệu các nhiệm vụ có can thiệp một cách xây dựng hay phá hoại từ các góc độ
lý thuyết và thực nghiệm. Dựa trên những hiểu biết này, chúng tôi phát triển các phương pháp để
cải thiện tính hiệu quả và mạnh mẽ của huấn luyện đa nhiệm vụ.

Đã có một lượng lớn các nghiên cứu thuật toán và lý thuyết cho học đa nhiệm vụ dựa trên kernel,
nhưng ít được biết đến hơn cho mạng nơ-ron. Thông điệp khái niệm từ các công trình trước đó
(Baxter (2000); Evgeniou and Pontil (2004); Micchelli and Pontil (2005); Xue et al. (2007)) chỉ
ra rằng học đa nhiệm vụ hiệu quả trên các nhiệm vụ "tương tự", trong đó khái niệm tương tự được
dựa trên các mô hình đơn nhiệm vụ (ví dụ: các ranh giới quyết định gần nhau). Công trình về học
tương ứng cấu trúc (Ando and Zhang (2005); Blitzer et al. (2006)) sử dụng tối ưu hóa luân phiên
để học một tham số chung và các tham số nhiệm vụ riêng biệt. Zhang và Yeung (2014) sử dụng
một vectơ tham số cho mỗi nhiệm vụ và học các mối quan hệ nhiệm vụ thông qua điều chuẩn l2,
điều này ngầm kiểm soát khả năng của mô hình. Những kết quả này khó áp dụng cho mạng nơ-ron:
không rõ làm thế nào để lý luận về mạng nơ-ron có không gian đặc trưng được đưa ra bởi các nhúng
theo lớp.

Để xác định liệu hai nhiệm vụ có can thiệp một cách xây dựng hay phá hoại, chúng tôi nghiên cứu
một kiến trúc với một mô-đun chung cho tất cả các nhiệm vụ và một mô-đun đầu ra riêng biệt cho
mỗi nhiệm vụ (Ruder (2017)). Xem Hình 1 để minh họa. Quan sát thúc đẩy của chúng tôi là ngoài
sự tương tự mô hình ảnh hưởng đến loại can thiệp, sự tương tự dữ liệu nhiệm vụ đóng vai trò hiệu
ứng bậc hai sau khi kiểm soát sự tương tự mô hình. Để minh họa ý tưởng, chúng tôi xem xét ba
nhiệm vụ với cùng số lượng dữ liệu

Đóng góp ngang nhau. Liên hệ với fsenwu,hongyang,chrismre g@cs.stanford.edu
1arXiv:2005.00944v1  [cs.LG]  2 May 2020

--- TRANG 2 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
𝐴*𝐴+𝐴,…𝐴-$+𝐴-$*𝐴-Mô-đun Đặc Trưng Nhiệm Vụ (A)Mô-đun Chung (B)……𝑋*𝑋+𝑋,…𝑋-$+𝑋-$*𝑋-Nhiều Nhiệm Vụ (X)
Hình 1: Minh họa của
kiến trúc học đa nhiệm vụ
với một mô-đun thấp hơn chung B và
k mô-đun đặc trưng nhiệm vụ fAigk
i=1.
Nhiều Điểm HơnÍt điểm hơnHình 2: Chuyển giao Tích cực vs. Tiêu cực bị ảnh hưởng bởi dữ liệu
– không chỉ mô hình. Xem phải dưới vs. giữa. Nhiệm vụ 2 và 3
có cùng mô hình (đường chấm) nhưng phân phối dữ liệu khác nhau.
Lưu ý sự khác biệt của dữ liệu trong các vùng được khoanh tròn.

mẫu trong đó nhiệm vụ 2 và 3 có cùng ranh giới quyết định nhưng phân phối dữ liệu khác nhau (xem
Hình 2 để minh họa). Chúng tôi quan sát thấy rằng huấn luyện nhiệm vụ 1 với nhiệm vụ 2 hoặc
nhiệm vụ 3 có thể cải thiện hoặc làm tổn hại hiệu suất của nhiệm vụ 1, tùy thuộc vào lượng dữ liệu
đóng góp dọc theo ranh giới quyết định! Quan sát này cho thấy rằng bằng cách đo lường sự tương
tự của dữ liệu nhiệm vụ và các mô hình một cách riêng biệt, chúng ta có thể phân tích sự can thiệp
của các nhiệm vụ và gán nguyên nhân một cách chính xác hơn.

Được thúc đẩy bởi quan sát trên, chúng tôi nghiên cứu lý thuyết của học đa nhiệm vụ thông qua
mô-đun chung trong các thiết lập tuyến tính và được kích hoạt bởi ReLU. Đóng góp lý thuyết của
chúng tôi bao gồm ba thành phần: khả năng của mô-đun chung, hiệp phương sai nhiệm vụ, và trọng
số từng nhiệm vụ của quy trình huấn luyện. Khả năng đóng vai trò cơ bản bởi vì, nếu khả năng của
mô-đun chung quá lớn, không có sự can thiệp giữa các nhiệm vụ; nếu nó quá nhỏ, có thể có sự can
thiệp phá hoại. Sau đó, chúng tôi chỉ ra cách xác định sự can thiệp bằng cách đề xuất một khái niệm
chi tiết hơn gọi là hiệp phương sai nhiệm vụ có thể được sử dụng để đo lường sự căn chỉnh của dữ
liệu nhiệm vụ. Bằng cách thay đổi hiệp phương sai nhiệm vụ, chúng tôi quan sát cả chuyển giao tích
cực và tiêu cực từ một nhiệm vụ sang nhiệm vụ khác! Sau đó chúng tôi cung cấp các điều kiện đủ
đảm bảo rằng một nhiệm vụ có thể chuyển giao tích cực sang một nhiệm vụ khác, với điều kiện có
đủ nhiều điểm dữ liệu từ nhiệm vụ đóng góp. Cuối cùng, chúng tôi nghiên cứu cách gán trọng số
từng nhiệm vụ cho các thiết lập trong đó các nhiệm vụ khác nhau chia sẻ cùng dữ liệu nhưng có
nhãn khác nhau.

Kết quả thực nghiệm. Lý thuyết của chúng tôi dẫn đến việc thiết kế hai thuật toán có ý nghĩa thực
tế. Đầu tiên, chúng tôi đề xuất căn chỉnh hiệp phương sai của các lớp nhúng nhiệm vụ và trình bày
các đánh giá thực nghiệm trên các bộ dữ liệu chuẩn và nhiệm vụ nổi tiếng. Trên 5 nhiệm vụ từ bộ
dữ liệu chuẩn General Language Understanding Evaluation (GLUE) (Wang et al. (2018b)) được
huấn luyện với mô hình BERT LARGE của Devlin et al. (2018), phương pháp của chúng tôi cải thiện
kết quả của BERT LARGE bằng điểm GLUE trung bình 2.35%, đây là chỉ số tiêu chuẩn cho bộ dữ
liệu chuẩn. Hơn nữa, chúng tôi chỉ ra rằng phương pháp của chúng tôi có thể áp dụng cho các thiết
lập học chuyển giao; chúng tôi quan sát độ chính xác cao hơn đến 2.5% bằng cách chuyển giao giữa
sáu nhiệm vụ phân tích cảm xúc sử dụng mô hình LSTM của Lei et al. (2018).

Thứ hai, chúng tôi đề xuất một sơ đồ tái cân bằng trọng số nhiệm vụ dựa trên SVD để cải thiện
huấn luyện đa nhiệm vụ cho các thiết lập trong đó các nhiệm vụ khác nhau có cùng đặc trưng nhưng
nhãn khác nhau. Trên bộ dữ liệu ChestX-ray14, chúng tôi so sánh phương pháp của chúng tôi với
sơ đồ không có trọng số và quan sát cải thiện điểm AUC trung bình 0.4% cho tất cả các nhiệm vụ.
Tóm lại, những đánh giá này xác nhận rằng những hiểu biết lý thuyết của chúng tôi có thể áp dụng
cho một loạt rộng các thiết lập và ứng dụng.

2 BA THÀNH PHẦN CỦA HỌC ĐA NHIỆM VỤ
Chúng tôi nghiên cứu các mô hình học đa nhiệm vụ (MTL) với một mô-đun chung cho tất cả các
nhiệm vụ và một mô-đun đầu ra riêng biệt cho mỗi nhiệm vụ. Chúng tôi đặt câu hỏi: Các thành
phần chính để xác định liệu MTL có tốt hơn học đơn nhiệm vụ (STL) hay không là gì? Để đáp ứng,
chúng tôi xác định ba thành phần: khả năng mô hình, hiệp phương sai nhiệm vụ, và sơ đồ tối ưu
hóa. Sau khi thiết lập mô hình, chúng tôi mô tả ngắn gọn vai trò của khả năng mô hình. Sau đó
chúng tôi giới thiệu khái niệm hiệp phương sai nhiệm vụ, tạo thành phần lớn của phần này. Chúng
tôi kết thúc bằng cách chỉ ra các ý nghĩa của kết quả chúng tôi cho việc lựa chọn sơ đồ tối ưu hóa.
2

--- TRANG 3 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
2.1 THIẾT LẬP MÔ HÌNH
Chúng tôi được cho k nhiệm vụ. Gọi mi là số lượng mẫu dữ liệu của nhiệm vụ i. Đối với nhiệm vụ i, gọi Xi∈Rmi×d là các biến đồng và gọi yi∈Rmi là các nhãn của nó, trong đó d là chiều của dữ liệu. Chúng tôi đã giả định rằng tất cả các nhiệm vụ có cùng chiều đầu vào d. Đây không phải là một giả định hạn chế và thường được thỏa mãn, ví dụ cho nhúng từ trên BERT, hoặc bằng cách đệm số không vào đầu vào nếu không. Mô hình của chúng tôi giả định nhãn đầu ra là 1 chiều. Chúng tôi cũng có thể mô hình hóa một vấn đề đa nhãn với k loại nhãn bằng cách có k nhiệm vụ với cùng biến đồng nhưng nhãn khác nhau. Chúng tôi xem xét một mô hình MTL với một mô-đun chung B∈Rd×r và một mô-đun đầu ra riêng biệt Ai∈Rr cho nhiệm vụ i, trong đó r biểu thị chiều đầu ra của B. Xem Hình 1 để minh họa. Chúng tôi định nghĩa mục tiêu tìm một mô hình MTL là tối thiểu hóa phương trình sau đối với B và các Ai:

f(A1;A2;:::;Ak;B) = ∑(i=1 to k) L(g(XiB)Ai;yi); (1)

trong đó L là một hàm mất mát như mất mát bình phương. Hàm kích hoạt g:R→R được áp dụng trên mỗi phần tử của XiB. Trong phương trình 1, tất cả các mẫu dữ liệu đóng góp bằng nhau. Do sự khác biệt giữa các nhiệm vụ như kích thước dữ liệu, việc tái cân bằng trọng số các nhiệm vụ trong quá trình huấn luyện là tự nhiên:

f(A1;A2;:::;Ak;B) = ∑(i=1 to k) λi L(g(XiB)Ai;yi); (2)

Thiết lập này là một trừu tượng hóa của kiến trúc chia sẻ tham số cứng (Ruder (2017)). Mô-đun chung B cung cấp một biểu diễn phổ quát (ví dụ: một LSTM để mã hóa câu) cho tất cả các nhiệm vụ. Mỗi mô-đun đặc trưng nhiệm vụ Ai được tối ưu hóa cho đầu ra của nó. Chúng tôi tập trung vào hai mô hình như sau.

Mô hình tuyến tính đơn nhiệm vụ. Các nhãn y của mỗi nhiệm vụ tuân theo một mô hình tuyến tính với tham số θ∈Rd:
y=Xθ+ε. Mỗi phần tử của ε tuân theo phân phối chuẩn N(0;σ²) với phương sai σ². Hàm g(XB) = XB. Đây là một thiết lập được nghiên cứu kỹ cho hồi quy tuyến tính (Hastie et al. (2005)).

Mô hình ReLU đơn nhiệm vụ. Ký hiệu ReLU(x) = max(x;0) cho bất kỳ x∈R nào. Chúng tôi cũng sẽ xem xét một mô hình phi tuyến trong đó X đi qua hàm kích hoạt ReLU với a∈R và θ∈Rd: y=a⊙ReLU(Xθ)+ε, áp dụng kích hoạt ReLU trên X theo từng phần tử. Hàm mã hóa g(XB) sau đó ánh xạ tới ReLU(XB).

Chuyển giao tích cực vs. tiêu cực. Đối với một nhiệm vụ nguồn và một nhiệm vụ đích, chúng tôi nói rằng nhiệm vụ nguồn chuyển giao tích cực sang nhiệm vụ đích, nếu huấn luyện cả hai thông qua phương trình 1 cải thiện so với chỉ huấn luyện nhiệm vụ đích (được đo trên tập xác thực của nó). Chuyển giao tiêu cực là điều ngược lại của chuyển giao tích cực.

Phát biểu vấn đề. Mục tiêu của chúng tôi là phân tích ba thành phần để xác định chuyển giao tích cực vs. tiêu cực giữa các nhiệm vụ: khả năng mô hình (r), hiệp phương sai nhiệm vụ ({Xi^T Xi}i=1^k) và trọng số từng nhiệm vụ ({λi}i=1^k). Chúng tôi tập trung vào các nhiệm vụ hồi quy dưới mất mát bình phương nhưng chúng tôi cũng cung cấp các thực nghiệm tổng hợp trên các nhiệm vụ phân loại để xác thực lý thuyết của chúng tôi.

Ký hiệu. Đối với một ma trận X, khoảng cột của nó là tập hợp tất cả các tổ hợp tuyến tính của các vectơ cột của X. Gọi X† là nghịch đảo giả của nó. Cho u;v∈Rd, cos(u;v) bằng u^T v/(‖u‖‖v‖).

2.2 KHẢ NĂNG MÔ HÌNH
Chúng tôi bắt đầu bằng cách xem xét lại vai trò của khả năng mô hình, tức là chiều đầu ra của B (ký hiệu là r). Chúng tôi chỉ ra rằng như một quy tắc ngón tay cái, r nên nhỏ hơn tổng khả năng của các mô-đun STL.

Ví dụ. Giả sử chúng ta có k nhiệm vụ hồi quy tuyến tính sử dụng mất mát bình phương, phương trình 1 trở thành:
f(A1;A2;:::;Ak;B) = ∑(i=1 to k) ‖XiBAi-yi‖F²; (3)

Nghiệm tối ưu của phương trình 3 cho nhiệm vụ i là θi = (Xi^T Xi)†Xi^T yi∈Rd. Do đó khả năng 1 đủ cho mỗi nhiệm vụ. Chúng tôi chỉ ra rằng nếu r≥k, thì không có chuyển giao giữa bất kỳ hai nhiệm vụ nào.

3

--- TRANG 4 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
Chuyển Giao Tích Cực
Chuyển Giao Tiêu Cực−0.2−0.100.10.2
# Mẫu dữ liệu của nhiệm vụ nguồn2000400060008000Chuyển Giao Tích Cực
Chuyển Giao Tiêu Cực−0.2−0.100.10.2
# Mẫu dữ liệu của nhiệm vụ nguồn2000400060008000Chuyển Giao Tích Cực
Chuyển Giao Tiêu Cực−0.2−0.100.10.2
# Mẫu dữ liệu của nhiệm vụ nguồn2000400060008000Cùng hiệp phương sai (Nguồn: Nhiệm vụ 2) Khác hiệp phương sai (Nguồn: Nhiệm vụ 3)

(a) Nhiệm vụ hồi quy tuyến tính (b) Nhiệm vụ phân loại logistic (c) Nhiệm vụ hồi quy ReLU
Hiệu suất Nhiệm vụ đích: MTL - STLNguồn vs. đích (Nhiệm vụ 1):
Hình 3: Cải thiện hiệu suất của một nhiệm vụ đích (Nhiệm vụ 1) bằng MTL với một nhiệm vụ nguồn vs. STL.
Đỏ: chuyển giao tích cực khi nguồn là Nhiệm vụ 2, có cùng ma trận hiệp phương sai với đích.
Xanh lá: chuyển giao tiêu cực (đến tích cực) khi nguồn là Nhiệm vụ 3, có hiệp phương sai khác
với đích, khi số mẫu của nó tăng. Xem ví dụ bên dưới để biết định nghĩa của mỗi nhiệm vụ.

Mệnh đề 1. Gọi r≥k. Tồn tại một B* tối ưu và {Ai*}i=1^k của phương trình 3 trong đó B*Ai* = θi, cho tất cả i=1;2;:::;k.

Để minh họa ý tưởng, miễn là B* chứa {θi}i=1^k trong khoảng cột của nó, tồn tại Ai* sao cho B*Ai* = θi, đây là tối ưu cho phương trình 3 với lỗi tối thiểu. Nhưng điều này có nghĩa là không có chuyển giao giữa bất kỳ hai nhiệm vụ nào. Điều này có thể làm tổn hại tổng quát hóa nếu một nhiệm vụ có dữ liệu hạn chế, trong trường hợp đó nghiệm STL của nó overfit dữ liệu huấn luyện, trong khi nghiệm MTL có thể tận dụng dữ liệu của các nhiệm vụ khác để cải thiện tổng quát hóa. Chứng minh của Mệnh đề 1 và mở rộng của nó cho thiết lập ReLU có trong Phụ lục A.1.

Hệ quả thuật toán. Ý nghĩa là việc hạn chế khả năng của mô-đun chung là cần thiết để thực thi chuyển giao thông tin. Nếu mô-đun chung quá nhỏ, thì các nhiệm vụ có thể can thiệp tiêu cực với nhau. Nhưng nếu nó quá lớn, thì có thể không có chuyển giao giữa các nhiệm vụ. Trong Phần 3.3, chúng tôi xác minh nhu cầu lựa chọn khả năng mô hình cẩn thận trên một loạt rộng các mạng nơ-ron bao gồm CNN, LSTM và perceptron đa lớp.

2.3 HIỆP PHƯƠNG SAI NHIỆM VỤ
Để chỉ ra cách định lượng sự tương tự dữ liệu nhiệm vụ, chúng tôi minh họa với hai nhiệm vụ hồi quy dưới mô hình tuyến tính không có nhiễu: y1=X1θ1 và y2=X2θ2. Theo Phần 2.2, việc hạn chế khả năng của mô-đun chung là cần thiết để thực thi chuyển giao thông tin. Do đó, chúng tôi xem xét trường hợp r=1. Do đó, mô-đun chung B bây giờ là một vectơ d chiều, và A1;A2 đều là số vô hướng.

Một yêu cầu tự nhiên của sự tương tự nhiệm vụ là để các mô hình STL tương tự, tức là |cos(θ1;θ2)| lớn. Để thấy điều này, mô hình STL tối ưu cho nhiệm vụ 1 là (X1^T X1)^{-1} X1^T y1 = θ1. Do đó nếu |cos(θ1;θ2)| là 1, thì nhiệm vụ 1 và 2 có thể chia sẻ một mô hình B∈Rd là θ1 hoặc θ1. Số vô hướng A1 và A2 sau đó có thể chuyển đổi B để bằng θ1 và θ2.

Yêu cầu này có đủ không? Nhớ lại rằng trong phương trình 3, dữ liệu nhiệm vụ X1 và X2 đều được nhân với B. Nếu chúng được "căn chỉnh" kém về mặt hình học, hiệu suất có thể bị tổn hại. Làm thế nào để chúng ta hình thức hóa hình học giữa việc căn chỉnh nhiệm vụ? Trong phần sau, chúng tôi chỉ ra rằng các ma trận hiệp phương sai của X1 và X2, mà chúng tôi định nghĩa là X1^T X1 và X2^T X2, nắm bắt hình học. Chúng tôi cố định |cos(θ1;θ2)| gần bằng 1 để kiểm tra ảnh hưởng của hiệp phương sai nhiệm vụ. Trong Phụ lục A.2.1 chúng tôi cố định hiệp phương sai nhiệm vụ để kiểm tra ảnh hưởng của sự tương tự cosine mô hình. Cụ thể, phương trình 3 được rút gọn thành:

max_{B∈Rd} h(B) = ⟨X1B/‖X1B‖, y1⟩² + ⟨X2B/‖X2B‖, y2⟩²; (4)

trong đó chúng tôi áp dụng điều kiện tối ưu bậc nhất trên A1 và A2 và đơn giản hóa phương trình. Cụ thể, chúng tôi tập trung vào một kịch bản trong đó nhiệm vụ 1 là nguồn và nhiệm vụ 2 là đích. Mục tiêu của chúng tôi là xác định khi nào nguồn chuyển giao đến đích một cách tích cực hoặc tiêu cực trong MTL. Xác định loại chuyển giao từ nhiệm vụ 2 đến nhiệm vụ 1 có thể được thực hiện tương tự. Trả lời câu hỏi này quy về việc nghiên cứu góc hoặc sự tương tự cosine giữa tối ưu của phương trình 4 và θ2.

Ví dụ. Trong Hình 3, chúng tôi chỉ ra rằng bằng cách thay đổi hiệp phương sai nhiệm vụ và số lượng mẫu, chúng ta có thể quan sát cả chuyển giao tích cực và tiêu cực. Thông điệp khái niệm giống như Hình 2; chúng tôi

4

--- TRANG 5 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
Thuật toán 1 Căn chỉnh hiệp phương sai cho huấn luyện đa nhiệm vụ
Yêu cầu: Các lớp nhúng nhiệm vụ X1∈Rm1×d;X2∈Rm2×d;:::;Xk∈Rmk×d, mô-đun chung B
Tham số: Các ma trận căn chỉnh R1;R2;:::;Rk∈Rd×d và các mô-đun đầu ra A1;A2:::;Ak∈Rr
1: Gọi Zi=XiRi, cho 1≤i≤k.
Xem xét hàm mất mát được sửa đổi sau (với B được cố định):
f̂(A1;:::;Ak;R1;:::;Rk) = ∑i=1^k L(g(ZiB)Ai;yi) = ∑i=1^k L(g(XiRiB)Ai;yi)
2: Tối thiểu hóa f̂ bằng cách áp dụng cập nhật gradient descent luân phiên trên Ai và Ri, với một batch dữ liệu được lấy mẫu từ nhiệm vụ i.
Các chi tiết triển khai khác được mô tả trong Phụ lục B.3.

mô tả quy trình tạo dữ liệu chi tiết hơn. Chúng tôi sử dụng 3 nhiệm vụ và đo loại chuyển giao từ nguồn đến đích. Trục x là số lượng mẫu dữ liệu từ nguồn. Trục y là cải thiện hiệu suất của đích được đo trên tập xác thực của nó giữa MTL trừ STL.

Tạo dữ liệu. Chúng ta có |cos(θ1;θ2)|≈1 (nói 0.96). Cho i∈{1;2;3}, gọi Ri∈Rmi×d là một ma trận Gaussian ngẫu nhiên được rút từ N(0;1). Gọi S1;S2⊂{1;2;:::;d} là hai tập hợp rời rạc có kích thước d/10. Cho i=1;2, gọi Di là một ma trận chéo có các phần tử bằng một giá trị lớn (ví dụ κ=100) cho các tọa độ trong Si và 1 nếu không. Gọi Qi∈Rd×d là một ma trận trực chuẩn, tức là Qi^T Qi bằng ma trận đơn vị, được trực giao hóa từ một ma trận Gaussian ngẫu nhiên.

Sau đó, chúng tôi định nghĩa 3 nhiệm vụ như sau. (i) Nhiệm vụ 1 (đích): X1=R1Q1D1 và y1=X1θ1. (ii) Nhiệm vụ 2 (nhiệm vụ nguồn cho đường màu đỏ): X2=R2Q1D1 và y2=X2θ2. (iii) Nhiệm vụ 3 (nhiệm vụ nguồn cho đường màu xanh): X3=R3Q2D2 và y3=X3θ2. Nhiệm vụ 1 và 2 có cùng ma trận hiệp phương sai nhưng nhiệm vụ 1 và 3 có ma trận hiệp phương sai khác nhau. Trực quan, tín hiệu của nhiệm vụ 1 và 3 nằm trong các không gian con khác nhau, phát sinh từ sự khác biệt trong các đường chéo của Di và các ma trận trực chuẩn.

Phân tích. Trừ khi nhiệm vụ nguồn có nhiều mẫu để ước lượng θ2, nhiều hơn rất nhiều so với các mẫu cần thiết để ước lượng chỉ các tọa độ của S1, hiệu ứng chuyển giao đến đích là nhỏ. Chúng tôi quan sát kết quả tương tự cho các nhiệm vụ hồi quy logistic và cho các nhiệm vụ hồi quy được kích hoạt bởi ReLU.

Lý thuyết. Chúng tôi định lượng nghiêm ngặt cần bao nhiêu điểm dữ liệu để đảm bảo chuyển giao tích cực. Quan niệm dân gian trong MTL là khi một nhiệm vụ nguồn có nhiều dữ liệu nhưng nhiệm vụ đích liên quan có dữ liệu hạn chế, thì nguồn thường có thể chuyển giao tích cực đến đích. Ví dụ trước của chúng tôi cho thấy rằng bằng cách thay đổi số lượng mẫu của nguồn và hiệp phương sai của nó, chúng ta có thể quan sát cả hai loại chuyển giao. Chúng ta cần bao nhiêu dữ liệu từ nguồn để đảm bảo chuyển giao tích cực đến đích? Chúng tôi chỉ ra rằng điều này phụ thuộc vào số điều kiện của hiệp phương sai của cả hai nhiệm vụ.

Định lý 2 (không chính thức). Cho i=1;2, gọi yi=Xiθi+εi là hai nhiệm vụ hồi quy tuyến tính với tham số θi∈Rd và mi số mẫu. Giả sử rằng mỗi hàng của nhiệm vụ nguồn X1 được rút độc lập từ một phân phối với hiệp phương sai Σ1∈Rd×d và chuẩn l2 bị chặn. Gọi c=κ(X2)sin(θ1;θ2) và giả sử rằng c≤1/3. Ký hiệu (B*;A1*;A2*) là nghiệm MTL tối ưu. Với xác suất cao, khi m1 ít nhất có bậc (κ²(Σ1)κ⁴(X2)‖y2‖²)/c⁴, chúng ta có

‖B*A2*−θ2‖/‖θ2‖ ≤ 6c + (1−13c)‖ε2‖/‖X2θ2‖; (5)

Nhớ lại rằng đối với một ma trận X, κ(X) biểu thị số điều kiện của nó. Định lý 2 định lượng xu hướng trong Hình 3, trong đó những cải thiện cho nhiệm vụ 2 đạt đến cao nguyên khi m1 trở nên đủ lớn. Tham số c ở đây chỉ ra mức độ tương tự của hai nhiệm vụ. sin(θ1;θ2) càng nhỏ, c càng nhỏ. Như một ví dụ, nếu sin(θ1;θ2)=α/κ(X2) cho một số α, thì phương trình 5 nhiều nhất là O(α) + ‖ε2‖/‖X2θ2‖.¹ Phát biểu chính thức, chứng minh và thảo luận về các giả định được hoãn lại đến Phụ lục A.2.2.

Mô hình ReLU. Chúng tôi chỉ ra một kết quả tương tự cho mô hình ReLU, điều này đòi hỏi giải quyết thách thức phân tích hàm ReLU. Chúng tôi sử dụng một đặc tính hóa hình học cho hàm ReLU dưới các giả định đầu vào phân phối bởi Du et al. (2017). Kết quả được hoãn lại đến Phụ lục A.2.3.

¹ Lỗi ước lượng của θ2 được giới hạn trên bởi tỷ lệ tín hiệu trên nhiễu của nhiệm vụ 2 ‖ε2‖/‖X2θ2‖. Sự phụ thuộc này phát sinh vì thành phần tuyến tính A2* fit phép chiếu của y2 lên X2B*. Vì vậy ngay cả khi B* bằng θ2, vẫn có thể có lỗi ước lượng từ A2*, không thể được ước lượng từ dữ liệu của nhiệm vụ 1.

5

--- TRANG 6 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
Thuật toán 2 Một sơ đồ tái cân bằng trọng số nhiệm vụ dựa trên SVD
Đầu vào: k nhiệm vụ: (X;yi)∈(Rm×d;Rm); một tham số rank r∈{1;2;:::;k}
Đầu ra: Một vectơ trọng số: {λ1;λ2;:::;λk}
1: Gọi βi=X^T yi.
2: Ur;Dr;Vr = SVDr(β1;β2;:::;βk), tức là xấp xỉ rank-r tốt nhất cho các βi.
3: Gọi λi=‖βi^T Ur‖, cho i=1;2;:::;k.

Hệ quả thuật toán. Một ý nghĩa của lý thuyết chúng tôi là một phương pháp căn chỉnh hiệp phương sai để cải thiện huấn luyện đa nhiệm vụ. Đối với nhiệm vụ thứ i, chúng tôi thêm một ma trận căn chỉnh Ri trước khi đầu vào Xi của nó đi qua mô-đun chung B. Thuật toán 1 chỉ ra quy trình.

Chúng tôi cũng đề xuất một chỉ số gọi là điểm tương tự hiệp phương sai để đo lường sự tương tự giữa hai nhiệm vụ. Cho X1∈Rm1×d và X2∈Rm2×d, chúng tôi đo sự tương tự của chúng trong ba bước: (a) Ma trận hiệp phương sai là X1^T X1. (b) Tìm xấp xỉ rank-r1 tốt nhất là U1,r1 D1,r1 U1,r1^T, trong đó r1 được chọn để chứa 99% các giá trị singular. (c) Áp dụng bước (a),(b) cho X2, tính điểm:

Điểm tương tự hiệp phương sai := ‖(U1,r1 D1,r1^{1/2})^T U2,r2 D2,r2^{1/2}‖F / (‖U1,r1 D1,r1^{1/2}‖F ‖U2,r2 D2,r2^{1/2}‖F); (6)

Tính chất tốt của điểm này là nó bất biến với các phép quay của các cột của X1 và X2.

2.4 SƠ ĐỒ TỐI ƯU HÓA
Cuối cùng, chúng tôi xem xét hiệu ứng của việc tái cân bằng trọng số các nhiệm vụ (hoặc các mất mát của chúng trong phương trình 2). Khi nào việc tái cân bằng trọng số các nhiệm vụ giúp ích? Trong phần này, chúng tôi chỉ ra một trường hợp sử dụng để cải thiện tính mạnh mẽ của huấn luyện đa nhiệm vụ trong sự hiện diện của nhiễu nhãn. Các thiết lập liên quan đến nhiễu nhãn có thể phát sinh khi một số nhiệm vụ chỉ có nhãn được giám sát yếu, đã được nghiên cứu trước đó trong tài liệu (ví dụ Mintz et al. (2009); Pentina and Lampert (2017)). Chúng tôi bắt đầu bằng cách mô tả một ví dụ thúc đẩy.

Xem xét hai nhiệm vụ trong đó nhiệm vụ 1 là y1=Xθ và nhiệm vụ 2 là y2=Xθ+ε2. Nếu chúng ta huấn luyện hai nhiệm vụ cùng nhau, lỗi ε2 sẽ thêm nhiễu vào mô hình được huấn luyện. Tuy nhiên, bằng cách tăng trọng số nhiệm vụ 1, chúng ta giảm nhiễu từ nhiệm vụ 2 và có hiệu suất tốt hơn. Để nghiên cứu nghiêm ngặt hiệu ứng của trọng số nhiệm vụ, chúng tôi xem xét một thiết lập trong đó tất cả các nhiệm vụ có cùng dữ liệu nhưng nhãn khác nhau. Thiết lập này phát sinh ví dụ trong các nhiệm vụ hình ảnh đa nhãn. Chúng tôi suy ra nghiệm tối ưu trong mô hình tuyến tính.

Mệnh đề 3. Gọi mô-đun chung có khả năng r≤k. Cho k nhiệm vụ với cùng biến đồng X∈Rm×d nhưng nhãn khác nhau {yi}i=1^k. Gọi X có rank đầy đủ và UDV^T là SVD của nó. Gọi QrQr^T là xấp xỉ rank-r tốt nhất cho ∑i=1^k λi U^T yi yi^T U. Gọi B*∈Rd×r là một nghiệm tối ưu cho mất mát có trọng số. Thì khoảng cột của B* bằng khoảng cột của (X^T X)^{-1} VDQr.

Chúng tôi cũng có thể mở rộng Mệnh đề 3 để chỉ ra rằng tất cả các minimum địa phương của phương trình 3 đều là minimum toàn cục trong thiết lập tuyến tính. Chúng tôi để lại chứng minh cho Phụ lục A.3. Chúng tôi nhận xét rằng kết quả này không mở rộng đến thiết lập ReLU phi tuyến và để lại điều này cho công việc tương lai.

Dựa trên Mệnh đề 3, chúng tôi cung cấp một chứng minh nghiêm ngặt của ví dụ trước. Giả sử rằng X có rank đầy đủ, (X^T X)^{-1} X^T [λ1y1;λ2y2]) = [λ1;λ2+λ2(X^T X)^{-1} X^T ε2]. Do đó, khi chúng ta tăng λ1, cos(B*;θ) tăng gần đến 1.

Hệ quả thuật toán. Được truyền cảm hứng từ lý thuyết của chúng tôi, chúng tôi mô tả một sơ đồ tái cân bằng trọng số trong sự hiện diện của nhiễu nhãn. Chúng tôi tính các trọng số từng nhiệm vụ bằng cách tính SVD trên X^T yi, cho 1≤i≤k. Trực quan là nếu vectơ nhãn của một nhiệm vụ yi có nhiễu, thì entropy của yi nhỏ. Do đó, chúng tôi muốn thiết kế một quy trình loại bỏ nhiễu. Quy trình SVD thực hiện điều này, trong đó trọng số của một nhiệm vụ được tính bằng phép chiếu của nó vào r hướng chính. Xem Thuật toán 2 cho mô tả.

6

--- TRANG 7 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
𝐴#		𝐴$		𝐴%…	𝐴&'$	𝐴&'#		𝐴&Nhúng Nhiệm VụMô-đun Chung (LSTM/BERT) 	𝑅&		𝐼#	𝑅$	𝑅%…	𝑅&'$	𝑅&'#		𝑋#		𝑋$		𝑋%…	𝑋&'$	𝑋&'#		𝑋&𝐸,𝑍,
Hình 4: Minh họa mô-đun căn chỉnh hiệp phương sai trên nhúng nhiệm vụ.

3 THỰC NGHIỆM
Chúng tôi mô tả các kết nối giữa kết quả lý thuyết của chúng tôi và các vấn đề thực tế quan trọng. Chúng tôi chỉ ra ba khẳng định trên các bộ dữ liệu thế giới thực. (i) Mô-đun MTL chung có hiệu suất tốt nhất khi khả năng của nó nhỏ hơn tổng khả năng của các mô hình đơn nhiệm vụ. (ii) Phương pháp căn chỉnh hiệp phương sai đề xuất của chúng tôi cải thiện huấn luyện đa nhiệm vụ trên nhiều thiết lập khác nhau bao gồm các bộ dữ liệu chuẩn GLUE và sáu nhiệm vụ phân tích cảm xúc. Phương pháp của chúng tôi có thể được mở rộng tự nhiên đến các thiết lập học chuyển giao và chúng tôi cũng xác thực điều này. (iii) Sơ đồ tái cân bằng trọng số dựa trên SVD của chúng tôi mạnh mẽ hơn sơ đồ không có trọng số tiêu chuẩn trên các nhiệm vụ phân loại hình ảnh đa nhãn trong sự hiện diện của nhiễu nhãn.

3.1 THIẾT LẬP THỰC NGHIỆM
Bộ dữ liệu và mô hình. Chúng tôi mô tả các bộ dữ liệu và mô hình chúng tôi sử dụng trong các thực nghiệm.

GLUE: GLUE là một bộ dữ liệu hiểu ngôn ngữ tự nhiên bao gồm các vấn đề trả lời câu hỏi, phân tích cảm xúc, tương tự văn bản và suy luận văn bản. Chúng tôi chọn BERT LARGE làm mô hình của chúng tôi, đây là một mạng transformer 24 lớp từ Devlin et al. (2018). Chúng tôi sử dụng bộ dữ liệu này để đánh giá cách Thuật toán 1 hoạt động trên mô hình BERT tiên tiến.

Phân tích Cảm xúc: Bộ dữ liệu này bao gồm sáu nhiệm vụ: cảm xúc đánh giá phim (MR), chủ quan câu (SUBJ), phân cực đánh giá khách hàng (CR), loại câu hỏi (TREC), phân cực ý kiến (MPQA), và các nhiệm vụ cây cảm xúc Stanford (SST).

Đối với mỗi nhiệm vụ, mục tiêu là phân loại ý kiến cảm xúc được thể hiện trong văn bản. Chúng tôi sử dụng một lớp nhúng (với nhúng GloVe²) theo sau bởi một lớp LSTM được đề xuất bởi Lei et al. (2018)³.

ChestX-ray14: Bộ dữ liệu này chứa 112,120 hình ảnh X-quang ngực từ phía trước và mỗi hình ảnh có đến 14 bệnh. Đây là một vấn đề phân loại hình ảnh đa nhãn 14 nhiệm vụ. Chúng tôi sử dụng mô hình CheXNet từ Rajpurkar et al. (2017), là một mạng nơ-ron tích chập 121 lớp trên tất cả các nhiệm vụ.

Đối với tất cả các mô hình, chúng tôi chia sẻ mô-đun chính qua tất cả các nhiệm vụ (BERT LARGE cho GLUE, LSTM cho phân tích cảm xúc, CheXNet cho ChestX-ray14) và gán một lớp hồi quy hoặc phân loại riêng biệt trên đầu mô-đun chung cho mỗi nhiệm vụ.

Phương pháp so sánh. Đối với thực nghiệm về huấn luyện đa nhiệm vụ, chúng tôi so sánh Thuật toán 1 bằng cách huấn luyện với phương pháp của chúng tôi và huấn luyện không có nó. Cụ thể, chúng tôi áp dụng quy trình căn chỉnh trên các lớp nhúng nhiệm vụ. Xem Hình 4 để minh họa, trong đó Ei biểu thị nhúng của nhiệm vụ i, Ri biểu thị mô-đun căn chỉnh của nó và Zi=EiRi là nhúng được quay.

Đối với học chuyển giao, trước tiên chúng tôi huấn luyện một mô hình STL trên nhiệm vụ nguồn bằng cách điều chỉnh khả năng mô hình của nó (ví dụ: chiều đầu ra của lớp LSTM). Sau đó, chúng tôi tinh chỉnh mô hình STL trên nhiệm vụ đích trong 5-10 epoch. Để áp dụng Thuật toán 1, chúng tôi thêm một mô-đun căn chỉnh cho nhiệm vụ đích trong quá trình tinh chỉnh.

Đối với thực nghiệm về các sơ đồ tái cân bằng trọng số, chúng tôi tính các trọng số từng nhiệm vụ như được mô tả trong Thuật toán 2. Sau đó, chúng tôi tái cân bằng trọng số hàm mất mát như trong phương trình 2. Chúng tôi so sánh với các kỹ thuật tái cân bằng trọng số của Kendall et al. (2018). Một cách không chính thức, cái sau sử dụng likelihood Gaussian để mô hình hóa đầu ra phân loại.

² http://nlp.stanford.edu/data/wordvecs/glove.6B.zip
³ Chúng tôi cũng thử nghiệm với perceptron đa lớp và CNN. Kết quả tương tự (cf. Phụ lục B.5).

7

--- TRANG 8 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
−0.6
4.3
−2.4
1−0.6
5.8
−1.9
2.74.3
5.8
0.1
0.7−2.4
−1.9
0.1
1.11
2.7
0.7
1.1
SSTRTEQNLIMRPCCOLA
COLAMRPC QNLIRTESST
(a) MTL trên GLUE qua 10 cặp nhiệm vụ
Baseline
Căn Chỉnh 
Hiệp Phương SaiLSTMĐộ Chính Xác
0.750.800.850.900.95
CRMPQA MR SUBJ TREC (b) Học chuyển giao trên sáu nhiệm vụ phân tích cảm xúc
Hình 5: Cải thiện hiệu suất của Thuật toán 1 bằng cách căn chỉnh nhúng nhiệm vụ.

ification output. Các trọng số, được định nghĩa tỷ lệ nghịch với phương sai của Gaussian, được tối ưu hóa trong quá trình huấn luyện. Chúng tôi cũng so sánh với mất mát không có trọng số (cf. phương trình 1) làm baseline.

Chỉ số. Chúng tôi đo hiệu suất trên bộ dữ liệu chuẩn GLUE sử dụng một chỉ số tiêu chuẩn gọi là điểm GLUE, chứa điểm độ chính xác và tương quan cho mỗi nhiệm vụ.

Đối với các nhiệm vụ phân tích cảm xúc, chúng tôi đo độ chính xác của việc dự đoán ý kiến cảm xúc.

Đối với nhiệm vụ phân loại hình ảnh, chúng tôi đo điểm diện tích dưới đường cong (AUC). Chúng tôi chạy năm random seed khác nhau để báo cáo kết quả trung bình. Kết quả của một thực nghiệm MTL được tính trung bình trên kết quả của tất cả các nhiệm vụ, trừ khi được chỉ định khác.

Đối với các quy trình huấn luyện và các chi tiết khác về thiết lập, chúng tôi refer người đọc đến Phụ lục B.

3.2 KẾT QUẢ THỰC NGHIỆM
Chúng tôi trình bày các trường hợp sử dụng của các phương pháp của chúng tôi trên các bộ dữ liệu mã nguồn mở. Chúng tôi kỳ vọng thấy những cải thiện thông qua các phương pháp của chúng tôi trong đa nhiệm vụ và các thiết lập khác, và thực sự chúng tôi đã thấy những cải thiện như vậy trên nhiều nhiệm vụ khác nhau.

Cải thiện huấn luyện đa nhiệm vụ. Chúng tôi áp dụng Thuật toán 1 trên năm nhiệm vụ (CoLA, MRPC, QNLI, RTE, SST-2) từ bộ dữ liệu chuẩn GLUE sử dụng một mô hình ngôn ngữ tiên tiến BERT LARGE.⁴ Chúng tôi huấn luyện các lớp đầu ra {Ai} và các lớp căn chỉnh {Ri} sử dụng thuật toán của chúng tôi. Chúng tôi so sánh hiệu suất trung bình trên tất cả năm nhiệm vụ và thấy rằng phương pháp của chúng tôi vượt trội hơn BERT LARGE 2.35% điểm GLUE trung bình cho năm nhiệm vụ. Đối với thiết lập cụ thể của việc huấn luyện hai nhiệm vụ, phương pháp của chúng tôi vượt trội hơn BERT LARGE trên 7 trong 10 cặp nhiệm vụ. Xem Hình 5a cho kết quả.

Cải thiện học chuyển giao. Trong khi nghiên cứu của chúng tôi tập trung vào học đa nhiệm vụ, học chuyển giao là một mục tiêu liên quan tự nhiên – và chúng tôi thấy rằng phương pháp của chúng tôi cũng hữu ích trong trường hợp này. Chúng tôi xác thực điều này bằng cách huấn luyện một LSTM trên phân tích cảm xúc. Hình 5b chỉ ra kết quả với SST là nhiệm vụ nguồn và phần còn lại là nhiệm vụ đích. Thuật toán 1 cải thiện độ chính xác trên bốn nhiệm vụ lên đến 2.5%.

Tái cân bằng trọng số huấn luyện cho cùng hiệp phương sai nhiệm vụ. Chúng tôi đánh giá Thuật toán 2 trên bộ dữ liệu ChestX-ray14. Thiết lập này thỏa mãn giả định của Thuật toán 2, đòi hỏi các nhiệm vụ khác nhau có cùng dữ liệu đầu vào. Trên tất cả 14 nhiệm vụ, chúng tôi thấy rằng phương pháp tái cân bằng trọng số của chúng tôi cải thiện kỹ thuật của Kendall et al. (2018) 0.1% điểm AUC. So với huấn luyện với mất mát không có trọng số, phương pháp của chúng tôi cải thiện hiệu suất 0.4% điểm AUC trên tất cả các nhiệm vụ.

3.3 NGHIÊN CỨU LOẠI BỎ
Khả năng mô hình. Chúng tôi xác minh giả thuyết của chúng tôi rằng khả năng của mô hình MTL không nên vượt quá tổng khả năng của mô hình STL. Chúng tôi chỉ ra điều này trên một mô hình LSTM với các nhiệm vụ phân tích cảm xúc. Nhớ lại rằng khả năng của một mô hình LSTM là chiều đầu ra của nó (trước lớp phân loại cuối cùng). Chúng tôi huấn luyện một mô hình MTL với tất cả các nhiệm vụ và thay đổi khả năng của mô-đun chung để tìm tối ưu từ 5 đến 500. Tương tự chúng tôi huấn luyện một mô hình STL cho mỗi nhiệm vụ và tìm tối ưu.

Trong Hình 1, chúng tôi thấy rằng hiệu suất của MTL đạt đỉnh khi mô-đun chung có khả năng 100. Điều này nhỏ hơn nhiều so với tổng khả năng của tất cả các mô hình STL. Kết quả xác nhận rằng

⁴ https://github.com/google-research/bert

8

--- TRANG 9 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
Bảng 1: So sánh khả năng mô hình giữa
MTL và STL.
Nhiệm VụSTL MTL
Khả Năng Độ Chính Xác Khả Năng Độ Chính Xác
SST 200 82.3
10090.8
MR 200 76.4 96.0
CR 5 73.2 78.7
SUBJ 200 91.5 89.5
MPQA 500 86.7 87.0
TREC 100 85.7 78.7
Tổng Thể 1205 82.6 100 85.1Hình 6: Điểm tương tự hiệp phương sai vs.
cải thiện hiệu suất từ căn chỉnh.
TREC,SUBJ
CR,MR
MPQA,SUBJ
CR, SUBJ
TREC,SSTLSTMCăn Chỉnh 
Hiệp Phương Sai
BaselineCải Thiện Hiệu Suất00.020.04
Điểm tương tự hiệp phương sai0.1 0.2 0.3 0.4 0.5

hạn chế khả năng của mô-đun chung là quan trọng để đạt được hiệu suất lý tưởng. Kết quả mở rộng trên CNN/MLP để hỗ trợ giả thuyết của chúng tôi được chỉ ra trong Phụ lục B.5.

Hiệp phương sai nhiệm vụ. Chúng tôi áp dụng chỉ số điểm tương tự hiệp phương sai nhiệm vụ của chúng tôi từ Phần 2.3 để cung cấp một nghiên cứu sâu về phương pháp căn chỉnh hiệp phương sai. Giả thuyết là: (a) căn chỉnh các hiệp phương sai giúp ích, điều chúng tôi đã chỉ ra trong Hình 5a; (b) điểm tương tự giữa hai nhiệm vụ tăng sau khi áp dụng căn chỉnh. Chúng tôi xác minh giả thuyết trên các nhiệm vụ phân tích cảm xúc. Chúng tôi sử dụng nhúng mô hình đơn nhiệm vụ trước lớp LSTM để tính hiệp phương sai.

Đầu tiên, chúng tôi đo điểm tương tự sử dụng phương trình 6 giữa tất cả sáu mô hình đơn nhiệm vụ. Sau đó, đối với mỗi cặp nhiệm vụ, chúng tôi huấn luyện một mô hình MTL sử dụng Thuật toán 1. Chúng tôi đo điểm tương tự trên mô hình MTL được huấn luyện. Kết quả của chúng tôi xác nhận giả thuyết (Hình 6): (a) chúng tôi quan sát độ chính xác tăng trên 13 trong 15 cặp nhiệm vụ lên đến 4.1%; (b) điểm tương tự tăng cho tất cả 15 cặp nhiệm vụ.

Sơ đồ tối ưu hóa. Chúng tôi xác minh tính mạnh mẽ của Thuật toán 2. Sau khi chọn hai nhiệm vụ từ bộ dữ liệu ChestX-ray14, chúng tôi thử nghiệm phương pháp của chúng tôi bằng cách gán nhãn ngẫu nhiên cho 20% dữ liệu trên một nhiệm vụ. Các nhãn cho nhiệm vụ khác vẫn không thay đổi.

Trên 10 cặp được chọn ngẫu nhiên, phương pháp của chúng tôi cải thiện so với sơ đồ không có trọng số trung bình 1.0% điểm AUC và kỹ thuật của Kendall et al. (2018) trung bình 0.4% điểm AUC. Chúng tôi bao gồm thêm chi tiết của thực nghiệm này trong Phụ lục B.5.

4 CÔNG TRÌNH LIÊN QUAN
Đã có một lượng lớn công trình gần đây về việc sử dụng phương pháp học đa nhiệm vụ để huấn luyện mạng nơ-ron sâu. Liu et al. (2019a); McCann et al. (2018) và các công trình theo sau chỉ ra kết quả tiên tiến trên bộ dữ liệu chuẩn GLUE, đã truyền cảm hứng cho nghiên cứu của chúng tôi về một trừu tượng hóa của mô hình MTL. Công trình gần đây của Zamir et al. (2018); Standley et al. (2019) trả lời các nhiệm vụ thị giác nào để huấn luyện cùng nhau thông qua một heuristic liên quan đến tính toán chuyên sâu. Chúng tôi thảo luận một số dòng nghiên cứu liên quan đến công trình này. Để có tham khảo đầy đủ, chúng tôi refer độc giả quan tâm đến khảo sát của Ruder (2017); Zhang và Yang (2017) và các khảo sát về thích ứng miền và học chuyển giao bởi Pan và Yang (2009); Kouw (2018) để biết tham khảo.

Nghiên cứu lý thuyết về học đa nhiệm vụ. Đặc biệt liên quan đến công trình này là những nghiên cứu lý thuyết về học đa nhiệm vụ. Các công trình sớm của Baxter (2000); Ben-David và Schuller (2003) là trong số những nghiên cứu đầu tiên chính thức về tầm quan trọng của sự liên quan nhiệm vụ cho việc học nhiều nhiệm vụ. Xem thêm công trình theo sau của Maurer (2006) nghiên cứu giới hạn tổng quát hóa của MTL.

Một dòng công trình liên quan chặt chẽ đến học cấu trúc là lựa chọn không gian con, tức là cách lựa chọn một không gian con chung cho nhiều nhiệm vụ. Ví dụ từ dòng công trình này bao gồm Obozinski et al. (2010); Wang et al. (2015); Fernando et al. (2013); Elhamifar et al. (2015). Evgeniou và Pontil (2004); Micchelli và Pontil (2005) nghiên cứu một công thức mở rộng máy vectơ hỗ trợ đến thiết lập đa nhiệm vụ. Xem thêm Argyriou et al. (2008); Pentina et al. (2015); Pentina và Ben-David (2015); Pentina và Lampert (2017) cung cấp các phương pháp tối ưu hóa tinh tế hơn và nghiên cứu thêm. Công trình của Ben-David et al. (2010) cung cấp lý thuyết để đo lường sự khác biệt giữa các nhiệm vụ nguồn và đích cho học chuyển giao trong một thiết lập mô hình khác. Khodak et al. (2019); Kong et al. (2020); Du et al. (2020) xem xét thiết lập meta learning liên quan, về bản chất là một thiết lập trực tuyến của học đa nhiệm vụ.

Kết quả của chúng tôi về hạn chế khả năng mô hình cho học đa nhiệm vụ tương phản với các nghiên cứu lý thuyết gần đây về các mô hình over-parametrized (ví dụ: Li et al. (2018); Zhang et al. (2019a); Bartlett et al. (2020)), trong đó khả năng mô hình thường lớn hơn nhiều so với chế độ chúng tôi xem xét ở đây. Sẽ thú vị khi hiểu rõ hơn học đa nhiệm vụ trong bối cảnh các mô hình over-parametrized đối với các hiện tượng khác như double descent đã được quan sát trong các bối cảnh khác (Belkin et al. (2019)).

Cuối cùng, Zhang et al. (2019b); Shui et al. (2019) xem xét học đa nhiệm vụ từ góc độ tính mạnh mẽ đối địch. Mahmud và Ray (2008) xem xét việc sử dụng độ phức tạp Kolmogorov để đo lường hiệu quả của học chuyển giao cho các phương pháp cây quyết định.

Chia sẻ tham số cứng vs. chia sẻ tham số mềm. Kiến trúc mà chúng tôi nghiên cứu trong công trình này cũng được gọi là kiến trúc chia sẻ tham số cứng. Có một loại kiến trúc khác gọi là chia sẻ tham số mềm. Ý tưởng là mỗi nhiệm vụ có các tham số và mô-đun riêng. Các mối quan hệ giữa các tham số này được điều chuẩn để khuyến khích các tham số tương tự. Các kiến trúc khác đã được nghiên cứu trước đó bao gồm công trình của Misra et al. (2016), trong đó các tác giả khám phá các kiến trúc có thể huấn luyện cho mạng nơ-ron tích chập.

Thích ứng miền. Một dòng công trình liên quan chặt chẽ khác là về thích ứng miền. Độc giả tinh ý có thể nhận thấy sự tương tự giữa nghiên cứu của chúng tôi trong Phần 2.3 và thích ứng miền. Sự khác biệt quan trọng ở đây là chúng tôi đang tối thiểu hóa mục tiêu học đa nhiệm vụ, trong khi trong thích ứng miền mục tiêu thường là tối thiểu hóa mục tiêu trên nhiệm vụ đích. Xem Ben-David et al. (2010); Zhang et al. (2019b) và các tham khảo trong đó cho công trình liên quan khác.

Kỹ thuật tối ưu hóa. Guo et al. (2019) sử dụng ý tưởng từ tài liệu multi-armed bandit để phát triển một phương pháp cân bằng trọng số cho mỗi nhiệm vụ. So với phương pháp của họ, phương pháp dựa trên SVD của chúng tôi đơn giản hơn về mặt khái niệm và yêu cầu ít tính toán hơn nhiều. Kendall et al. (2018) suy ra một sơ đồ mất mát có trọng số bằng cách tối đa hóa một hàm likelihood Gaussian. Nói một cách đại khái, mỗi nhiệm vụ được tái cân bằng trọng số bằng 1/σ² trong đó σ là độ lệch chuẩn của Gaussian và một penalty của log σ được thêm vào mất mát. Các giá trị của {σi} cũng được tối ưu hóa trong quá trình huấn luyện. Các chi tiết chính xác có thể được tìm thấy trong bài báo. Công trình rất gần đây của Li và Vasconcelos (2019) chỉ ra kết quả thực nghiệm sử dụng một ý tưởng tương tự về chuẩn hóa hiệp phương sai trên các nhiệm vụ hình ảnh cho chuyển giao cross-domain.

5 KẾT LUẬN VÀ CÔNG VIỆC TƯƠNG LAI
Chúng tôi đã nghiên cứu lý thuyết của học đa nhiệm vụ trong các thiết lập tuyến tính và được kích hoạt bởi ReLU. Chúng tôi đã xác minh lý thuyết và các ý nghĩa thực tế của nó thông qua các thực nghiệm tổng hợp và thế giới thực rộng rãi.

Công trình của chúng tôi mở ra nhiều câu hỏi tương lai thú vị. Đầu tiên, chúng ta có thể mở rộng các đảm bảo để lựa chọn sơ đồ tối ưu hóa đến các thiết lập phi tuyến không? Thứ hai, một hạn chế của bộ lập lịch tối ưu hóa dựa trên SVD của chúng tôi là nó chỉ áp dụng cho các thiết lập có cùng dữ liệu. Chúng ta có thể mở rộng phương pháp cho dữ liệu nhiệm vụ không đồng nhất không? Rộng hơn, chúng tôi hy vọng công trình của chúng tôi truyền cảm hứng cho các nghiên cứu tiếp theo để hiểu rõ hơn học đa nhiệm vụ trong mạng nơ-ron và hướng dẫn thực hành của nó.

Lời cảm ơn. Cảm ơn Sharon Y. Li và Avner May cho các cuộc thảo luận kích thích trong các giai đoạn đầu của công trình này. Chúng tôi biết ơn nhóm StatsML Stanford và các trọng tài ẩn danh đã cung cấp những nhận xét hữu ích giúp cải thiện chất lượng của công trình này. Chúng tôi biết ơn sự hỗ trợ của DARPA dưới Nos. FA87501720095 (D3M), FA86501827865 (SDH), và FA86501827882 (ASED); NIH dưới No. U54EB020405 (Mobilize), NSF dưới Nos. CCF1763315 (Beyond Sparsity), CCF1563078 (Volume to Velocity), và 1937301 (RTML); ONR dưới No. N000141712266 (Unifying Weak Supervision); Quỹ Moore, NXP, Xilinx, LETI-CEA, Intel, IBM, Microsoft, NEC, Toshiba, TSMC, ARM, Hitachi, BASF, Accenture, Ericsson, Qualcomm, Analog Devices, Quỹ Okawa, American Family Insurance, Google Cloud, Swiss Re, và các thành viên của dự án Stanford DAWN: Teradata, Facebook, Google, Ant Financial, NEC, VMWare, và Infosys. H. Zhang được hỗ trợ một phần bởi giải thưởng ONR YIP của Gregory Valiant (#1704417). Các thực nghiệm được chạy một phần trên cluster SOAL của Stanford.⁵ Chính phủ Hoa Kỳ được ủy quyền tái tạo và phân phối bản sao cho các mục đích Chính phủ bất chấp

⁵ https://5harad.com/soal-cluster/

10

--- TRANG 11 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
bất kỳ ghi chú bản quyền nào trên đó. Bất kỳ ý kiến, phát hiện, và kết luận hoặc khuyến nghị nào được thể hiện trong tài liệu này là của các tác giả và không nhất thiết phản ánh quan điểm, chính sách, hoặc sự tán thành, dù được thể hiện hay ngụ ý, của DARPA, NIH, ONR, hoặc Chính phủ Hoa Kỳ.

TÀI LIỆU THAM KHẢO
Héctor Martínez Alonso và Barbara Plank. When is multitask learning effective? semantic sequence prediction under varying data conditions. arXiv preprint arXiv:1612.02251, 2016.

Rie Kubota Ando và Tong Zhang. A framework for learning predictive structures from multiple tasks and unlabeled data. Journal of Machine Learning Research, 6(Nov):1817–1853, 2005.

Andreas Argyriou, Andreas Maurer, và Massimiliano Pontil. An algorithm for transfer learning in a heterogeneous environment. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 71–85. Springer, 2008.

Maria-Florina Balcan, Yingyu Liang, David P Woodruff, và Hongyang Zhang. Matrix completion and related problems via strong duality. In 9th Innovations in Theoretical Computer Science Conference (ITCS 2018), 2018.

Peter L Bartlett, Philip M Long, Gábor Lugosi, và Alexander Tsigler. Benign overfitting in linear regression. Proceedings of the National Academy of Sciences, 2020.

Jonathan Baxter. A model of inductive bias learning. Journal of artificial intelligence research, 12: 149–198, 2000.

Mikhail Belkin, Daniel Hsu, Siyuan Ma, và Soumik Mandal. Reconciling modern machine-learning practice and the classical bias–variance trade-off. Proceedings of the National Academy of Sciences, 116(32):15849–15854, 2019.

Shai Ben-David và Reba Schuller. Exploiting task relatedness for multiple task learning. In Learning Theory and Kernel Machines, pages 567–580. Springer, 2003.

Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, và Jennifer Wortman Vaughan. A theory of learning from different domains. Machine learning, 79(1-2):151–175, 2010.

Joachim Bingel và Anders Søgaard. Identifying beneficial task relations for multi-task learning in deep neural networks. arXiv preprint arXiv:1702.08303, 2017.

John Blitzer, Ryan McDonald, và Fernando Pereira. Domain adaptation with structural correspondence learning. In Proceedings of the 2006 conference on empirical methods in natural language processing, pages 120–128. Association for Computational Linguistics, 2006.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.

Simon S Du, Jason D Lee, Yuandong Tian, Barnabas Poczos, và Aarti Singh. Gradient descent learns one-hidden-layer cnn: Don't be afraid of spurious local minima. arXiv preprint arXiv:1712.00779, 2017.

Simon S Du, Wei Hu, Sham M Kakade, Jason D Lee, và Qi Lei. Few-shot learning via learning the representation, provably. arXiv preprint arXiv:2002.09434, 2020.

Ehsan Elhamifar, Guillermo Sapiro, và S Shankar Sastry. Dissimilarity-based sparse subset selection. IEEE transactions on pattern analysis and machine intelligence, 38(11):2182–2197, 2015.

Theodoros Evgeniou và Massimiliano Pontil. Regularized multi-task learning. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 109–117. ACM, 2004.

Basura Fernando, Amaury Habrard, Marc Sebban, và Tinne Tuytelaars. Unsupervised visual domain adaptation using subspace alignment. In Proceedings of the IEEE international conference on computer vision, pages 2960–2967, 2013.

11

--- TRANG 12 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
Han Guo, Ramakanth Pasunuru, và Mohit Bansal. Autosem: Automatic task selection and mixing in multi-task learning. arXiv preprint arXiv:1904.04153, 2019.

Trevor Hastie, Robert Tibshirani, Jerome Friedman, và James Franklin. The elements of statistical learning: data mining, inference and prediction. The Mathematical Intelligencer, 27(2):83–85, 2005.

Minqing Hu và Bing Liu. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 168–177. ACM, 2004.

Alex Kendall, Yarin Gal, và Roberto Cipolla. Multi-task learning using uncertainty to weigh losses for scene geometry and semantics. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 7482–7491, 2018.

Mikhail Khodak, Maria-Florina Balcan, và Ameet Talwalkar. Provable guarantees for gradient-based meta-learning. arXiv preprint arXiv:1902.10644, 2019.

Yoon Kim. Convolutional neural networks for sentence classification. arXiv preprint arXiv:1408.5882, 2014.

Iasonas Kokkinos. Ubernet: Training a universal convolutional neural network for low-, mid-, and high-level vision using diverse datasets and limited memory. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 6129–6138, 2017.

Weihao Kong, Raghav Somani, Zhao Song, Sham Kakade, và Sewoong Oh. Meta-learning for mixed linear regression. arXiv preprint arXiv:2002.08936, 2020.

Wouter M Kouw. An introduction to domain adaptation and transfer learning. arXiv preprint arXiv:1812.11806, 2018.

Tao Lei, Yu Zhang, Sida I Wang, Hui Dai, và Yoav Artzi. Simple recurrent units for highly parallelizable recurrence. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4470–4481, 2018.

Xin Li và Dan Roth. Learning question classifiers. In Proceedings of the 19th international conference on Computational linguistics-Volume 1, pages 1–7. Association for Computational Linguistics, 2002.

Yuanzhi Li, Tengyu Ma, và Hongyang Zhang. Algorithmic regularization in over-parameterized matrix sensing and neural networks with quadratic activations. In Conference On Learning Theory, pages 2–47, 2018.

Yunsheng Li và Nuno Vasconcelos. Efficient multi-domain learning by covariance normalization. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5424–5433, 2019.

Xiaodong Liu, Pengcheng He, Weizhu Chen, và Jianfeng Gao. Multi-task deep neural networks for natural language understanding. arXiv preprint arXiv:1901.11504, 2019a.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 2019b.

MM Mahmud và Sylvian Ray. Transfer learning using kolmogorov complexity: Basic theory and empirical evaluations. In Advances in neural information processing systems, pages 985–992, 2008.

Pasin Manurangsi và Daniel Reichman. The computational complexity of training relu (s). arXiv preprint arXiv:1810.04207, 2018.

Andreas Maurer. Bounds for linear multi-task learning. Journal of Machine Learning Research, 7 (Jan):117–139, 2006.

12

--- TRANG 13 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, và Richard Socher. The natural language decathlon: Multitask learning as question answering. arXiv preprint arXiv:1806.08730, 2018.

Charles A Micchelli và Massimiliano Pontil. Kernels for multi–task learning. In Advances in neural information processing systems, pages 921–928, 2005.

Mike Mintz, Steven Bills, Rion Snow, và Dan Jurafsky. Distant supervision for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2, pages 1003–1011. Association for Computational Linguistics, 2009.

Ishan Misra, Abhinav Shrivastava, Abhinav Gupta, và Martial Hebert. Cross-stitch networks for multi-task learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3994–4003, 2016.

Guillaume Obozinski, Ben Taskar, và Michael I Jordan. Joint covariate selection and joint subspace selection for multiple classification problems. Statistics and Computing, 20(2):231–252, 2010.

Sinno Jialin Pan và Qiang Yang. A survey on transfer learning. IEEE Transactions on knowledge and data engineering, 22(10):1345–1359, 2009.

Bo Pang và Lillian Lee. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the 42nd annual meeting on Association for Computational Linguistics, page 271. Association for Computational Linguistics, 2004.

Bo Pang và Lillian Lee. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. In Proceedings of the 43rd annual meeting on association for computational linguistics, pages 115–124. Association for Computational Linguistics, 2005.

Anastasia Pentina và Shai Ben-David. Multi-task and lifelong learning of kernels. In International Conference on Algorithmic Learning Theory, pages 194–208. Springer, 2015.

Anastasia Pentina và Christoph H Lampert. Multi-task learning with labeled and unlabeled tasks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 2807–2816. JMLR. org, 2017.

Anastasia Pentina, Viktoriia Sharmanska, và Christoph H Lampert. Curriculum learning of multiple tasks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5492–5500, 2015.

Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, et al. Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning. arXiv preprint arXiv:1711.05225, 2017.

Sebastian Ruder. An overview of multi-task learning in deep neural networks. arXiv preprint arXiv:1706.05098, 2017.

Changjian Shui, Mahdieh Abbasi, Louis-Émile Robitaille, Boyu Wang, và Christian Gagné. A principled approach for learning task similarity in multitask learning. arXiv preprint arXiv:1903.09109, 2019.

Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Ng, và Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the 2013 conference on empirical methods in natural language processing, pages 1631–1642, 2013.

Trevor Standley, Amir R Zamir, Dawn Chen, Leonidas Guibas, Jitendra Malik, và Silvio Savarese. Which tasks should be learned together in multi-task learning? arXiv preprint arXiv:1905.07553, 2019.

Joel A Tropp et al. An introduction to matrix concentration inequalities. Foundations and Trends® in Machine Learning, 8(1-2):1–230, 2015.

13

--- TRANG 14 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, và Samuel Bowman. Glue: A multi-task benchmark and analysis platform for natural language understanding. In Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 353–355, 2018a.

Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, và Samuel R Bowman. Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv preprint arXiv:1804.07461, 2018b.

Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, Mohammadhadi Bagheri, và Ronald M Summers. Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2097–2106, 2017.

Yu Wang, David Wipf, Qing Ling, Wei Chen, và Ian James Wassell. Multi-task learning for subspace segmentation. 2015.

Janyce Wiebe, Theresa Wilson, và Claire Cardie. Annotating expressions of opinions and emotions in language. Language resources and evaluation, 39(2-3):165–210, 2005.

Ya Xue, Xuejun Liao, Lawrence Carin, và Balaji Krishnapuram. Multi-task learning for classification with dirichlet process priors. Journal of Machine Learning Research, 8(Jan):35–63, 2007.

Amir R Zamir, Alexander Sax, William Shen, Leonidas J Guibas, Jitendra Malik, và Silvio Savarese. Taskonomy: Disentangling task transfer learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3712–3722, 2018.

Hongyang Zhang, Vatsal Sharan, Moses Charikar, và Yingyu Liang. Recovery guarantees for quadratic tensors with limited observations. In International Conference on Artificial Intelligence and Statistics (AISTATS), 2019a.

Yu Zhang và Qiang Yang. A survey on multi-task learning. arXiv preprint arXiv:1707.08114, 2017.

Yu Zhang và Dit-Yan Yeung. A regularization approach to learning task relationships in multitask learning. ACM Transactions on Knowledge Discovery from Data (TKDD), 8(3):12, 2014.

Yuchen Zhang, Tianle Liu, Mingsheng Long, và Michael I Jordan. Bridging theory and algorithm for domain adaptation. arXiv preprint arXiv:1904.05801, 2019b.

14

--- TRANG 15 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
A CHI TIẾT BỊ THIẾU CỦA PHẦN 2
Chúng tôi điền vào những chi tiết bị thiếu từ Phần 2. Trong Phần A.1, chúng tôi cung cấp các lập luận nghiêm ngặt về khả năng của mô-đun chung. Trong Phần A.2, chúng tôi điền vào các chi tiết bị thiếu từ Phần 2.3, bao gồm chứng minh của Định lý 2 và mở rộng của nó cho mô hình ReLU. Trong Phần A.3, chúng tôi cung cấp chứng minh của Mệnh đề 3 về các sơ đồ tái cân bằng trọng số nhiệm vụ. Chúng tôi trước tiên mô tả các ký hiệu.

Ký hiệu. Chúng tôi định nghĩa các ký hiệu sẽ được sử dụng sau này. Chúng tôi ký hiệu f(x)≲g(x) nếu tồn tại một hằng số tuyệt đối C sao cho f(x)≤Cg(x). Ký hiệu big-O f(x)=O(g(x)) có nghĩa là f(x)≲g(x).

Giả sử A∈Rm×n, thì σmax(A) biểu thị giá trị singular lớn nhất của nó và σmin(A) biểu thị giá trị singular lớn thứ min{m,n} của nó. Thay thế, chúng ta có σmin(A)=minx:‖x‖=1‖Ax‖. Gọi κ(A)=σmax(A)/σmin(A) biểu thị số điều kiện của A. Gọi Id biểu thị ma trận đơn vị. Gọi U† biểu thị nghịch đảo giả Moore-Penrose của ma trận U. Gọi ‖·‖ biểu thị chuẩn Euclidean cho vectơ và chuẩn spectral cho ma trận. Gọi ‖·‖F biểu thị chuẩn Frobenius của một ma trận. Gọi ⟨A,B⟩=tr(A^T B) biểu thị tích vô hướng của hai ma trận.

Hàm sine được định nghĩa là sin(u,v)=√(1-cos(u,v)²), trong đó chúng ta giả định rằng sin(u,v)≥0 mà không mất tính tổng quát cho nghiên cứu của chúng ta.

A.1 CHI TIẾT BỊ THIẾU CỦA PHẦN 2.2
Chúng tôi mô tả chi tiết đầy đủ để chỉ ra rằng thiết lập mô hình của chúng tôi nắm bắt hiện tượng rằng mô-đun chung nên nhỏ hơn tổng khả năng của các mô hình đơn nhiệm vụ. Chúng tôi phát biểu mệnh đề sau chỉ ra rằng chất lượng của không gian con B trong phương trình 1 xác định hiệu suất của học đa nhiệm vụ. Điều này bổ sung cho kết quả của Mệnh đề 1.

Mệnh đề 4. Trong tối ưu của f(·) (phương trình 1), mỗi Ai chọn vectơ v trong khoảng cột của g(XiB) để tối thiểu hóa L(v,yi). Như một hệ quả, trong thiết lập tuyến tính, B tối ưu có thể đạt được tại một ma trận quay B*∈Rd×r bằng cách tối đa hóa

∑(i=1 to k)⟨B(B^T X_i^T X_i B)^† B^T, X_i^T y_i y_i^T X_i⟩; (7)

Hơn nữa, bất kỳ B* nào chứa {θi}k_i=1 trong không gian con cột của nó là tối ưu. Cụ thể, đối với B* như vậy, tồn tại {A_i*} sao cho B*A_i*=θi cho tất cả 1≤i≤k.

Chứng minh. Nhớ lại mục tiêu MTL trong thiết lập tuyến tính từ phương trình 3 như sau:
min f(A1,A2,···,Ak,B) = ∑(i=1 to k)‖(XiBAi-yi)‖²,

Lưu ý rằng lớp tuyến tính Ai có thể chọn bất kỳ tổ hợp nào trong không gian con của B. Do đó, chúng ta có thể giả định không mất tính tổng quát rằng B là một ma trận quay. tức là B^T B = Id. Sau khi cố định B, vì mục tiêu f(·) tuyến tính trong Ai cho tất cả i, bằng điều kiện tối ưu địa phương, chúng ta thu được
Ai = (B^T X_i^T X_i B)^† B^T X_i^T yi

Thay thế nghiệm của Ai vào f(·), chúng ta thu được một mục tiêu trên B.
h(B) = ∑(i=1 to k)‖XiB(B^T X_i^T X_i B)^† B^T X_i^T yi - yi‖_F²;

Tiếp theo, lưu ý rằng
‖XiB(B^T X_i^T X_i B)^† B^T X_i^T yi‖_F² = Tr(y_i^T XiB(B^T X_i^T X_i B)^† B^T X_i^T yi)
= ⟨B(B^T X_i^T X_i B)^† B^T, X_i^T y_i y_i^T X_i⟩,

trong đó chúng ta đã sử dụng thực tế rằng A†AA† = A† cho A = B^T X_i^T X_i B trong phương trình đầu tiên. Do đó chúng ta đã chỉ ra phương trình 7.

Đối với khẳng định cuối cùng, miễn là B* chứa {θi}k_i=1 trong không gian con cột của nó, thì tồn tại A_i* sao cho B*A_i* = θi. B* và {A_i*}k_i=1 là nghiệm tối ưu vì mỗi θi là nghiệm tối ưu cho bài toán đơn nhiệm vụ.

Kết quả trên về hồi quy tuyến tính gợi ý trực quan rằng tối ưu hóa một mô hình MTL quy về tối ưu hóa trên khoảng của B. Trực quan có thể dễ dàng mở rộng đến các nhiệm vụ phân loại tuyến tính cũng như hỗn hợp các nhiệm vụ hồi quy và phân loại.

Mở rộng đến thiết lập ReLU. Nếu khả năng của mô-đun chung lớn hơn tổng khả năng của các mô hình STL, thì chúng ta có thể đặt tất cả các tham số mô hình STL vào mô-đun chung. Như trong thiết lập tuyến tính, lớp đầu ra cuối cùng Ai có thể chọn ra tham số tối ưu cho nhiệm vụ thứ i. Điều này vẫn là một nghiệm tối ưu cho bài toán MTL trong thiết lập ReLU. Hơn nữa, không có chuyển giao giữa bất kỳ hai nhiệm vụ nào thông qua mô-đun chung.

A.2 CHI TIẾT BỊ THIẾU CỦA PHẦN 2.3

A.2.1 HIỆU ỨNG CỦA TƯƠNG TỰ COSINE
Chúng tôi xem xét hiệu ứng của việc thay đổi tương tự cosine giữa các mô hình đơn nhiệm vụ trong học đa nhiệm vụ. Chúng tôi đầu tiên mô tả mệnh đề sau để giải bài toán mục tiêu học đa nhiệm vụ khi các hiệp phương sai của dữ liệu nhiệm vụ giống nhau. Ý tưởng tương tự như công trình của Ando và Zhang (2005) và chúng tôi điều chỉnh nó ở đây cho nghiên cứu của chúng tôi.

Mệnh đề 5. Xem xét mất mát có trọng số của phương trình 2 với hàm mã hóa là tuyến tính, trong đó các trọng số là {λi}k_i=1. Giả sử các đặc trưng nhiệm vụ của mọi nhiệm vụ có cùng hiệp phương sai: X_i^T Xi = Σ cho tất cả 1≤i≤k. Gọi Σ = VDV^T là phân tích giá trị singular (SVD) của Σ. Thì tối ưu của f(·) trong phương trình 3 được đạt tại:

B* = VD^{1/2}C*,

trong đó C*C*^T là xấp xỉ không gian con rank-r tốt nhất của ∑k_i=1 λi U_i^T y_i y_i^T U_i và Xi = UiDV^T là SVD của Xi, cho mỗi 1≤i≤k.

Như một hệ quả, ký hiệu σ1,σ2,···,σk là các giá trị singular của D^{-1}V^T ∑k_i=1 λi X_i^T y_i y_i^T Xi theo thứ tự giảm dần. Thì sự khác biệt giữa một mô hình MTL với chiều ẩn r và tất cả các mô hình đơn nhiệm vụ được giới hạn bởi ∑k_i=r+1 σ_i².

Chứng minh. Lưu ý rằng B* được thu được bằng cách tối đa hóa
∑k_i=1⟨B(B^T X_i^T X_i B)^{-1}B^T, λi X_i^T y_i y_i^T Xi⟩

Gọi C = D^{-1}V^T B. Rõ ràng, có một ánh xạ một-một giữa B và C. Và chúng ta có B = VD^{-1}C. Do đó điều trên tương đương với tối đa hóa trên C∈Rd×r với
∑k_i=1⟨C(C^T C)^{-1}C^T, D^{-1}V^T (∑k_i=1 λi X_i^T y_i y_i^T Xi) VD^{-1}⟩
= ⟨C(C^T C)^{-1}C^T, ∑k_i=1 λi U_i^T y_i y_i^T Ui⟩.

Lưu ý rằng C(C^T C)^{-1}C^T là một ma trận chiếu lên một không gian con chiều r. Do đó tối đa (ký hiệu bởi C*) được đạt tại xấp xỉ không gian con rank-r tốt nhất của ∑k_i=1 λi U_i^T y_i y_i^T Ui.

Để minh họa mệnh đề trên, xem xét một thiết lập đơn giản trong đó Xi là ma trận đơn vị cho mọi 1≤i≤k, và yi = ei, tức là vectơ cơ sở thứ i. Lưu ý rằng nghiệm tối ưu cho nhiệm vụ thứ i là (X_i^T Xi)^{-1} X_i^T yi = yi. Do đó các nghiệm tối ưu trực giao với nhau cho tất cả các nhiệm vụ, với λi = 1 cho tất cả 1≤i≤k. Và lỗi STL tối thiểu là không cho tất cả các nhiệm vụ.

16

--- TRANG 17 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
Xem xét mô hình MTL với chiều ẩn r. Bởi Mệnh đề 5, lỗi MTL tối thiểu được đạt bởi xấp xỉ không gian con rank-r tốt nhất của ∑k_i=1 X_i^T y_i y_i^T Xi = ∑k_i=1 y_i y_i^T. Ký hiệu tối ưu là B*_r. Lỗi MTL là:
∑k_i=1‖yi‖² - ⟨∑k_i=1 y_i y_i^T, B*_r B*_r^T⟩ = k - σr.

Hiệp phương sai dữ liệu khác nhau. Chúng tôi cung cấp giới hạn trên về chất lượng của các nghiệm MTL cho hiệp phương sai dữ liệu khác nhau, phụ thuộc vào tính liên quan của tất cả các nhiệm vụ. Quy trình sau đưa ra phát biểu chính xác. Xem xét k nhiệm vụ hồi quy với dữ liệu {(Xi,yi)}k_i=1. Gọi θi = (X_i^T Xi)† X_i^T yi biểu thị nghiệm tối ưu của mỗi nhiệm vụ hồi quy. Gọi W∈Rd×k biểu thị ma trận trong đó cột thứ i bằng θi. Xem xét quy trình sau để trực giao hóa W cho 1≤i≤k.

a) Gọi W*_i∈Rd biểu thị vectơ tối đa hóa ∑k_i=1⟨XiB/‖XiB‖, yi⟩² trên B∈Rd;
b) Ký hiệu σj = ∑k_j=1⟨XjW*_j/‖XjW*_j‖, yj⟩²;
c) Với mỗi 1≤i≤k, chiếu XiW*_i ra khỏi mọi cột của Xi. Quay lại Bước a).

Mệnh đề 6. Giả sử r≤d. Gọi B* biểu thị nghiệm MTL tối ưu có khả năng r trong mô-đun chung. Ký hiệu OPT = ∑k_i=1(‖yi‖² - ‖Xi(X_i^T Xi)† X_i^T yi‖²). Thì h(B*) ≤ OPT - ∑d_i=r+1 σi.

Chứng minh. Đủ để chỉ ra rằng OPT bằng ∑k_i=1 σi. Kết quả sau đó theo sau vì h(B*) nhỏ hơn lỗi được đưa ra bởi W*_1,···,W*_k, bằng OPT - ∑d_i=r+1 σi.

A.2.2 CHỨNG MINH CỦA ĐỊNH LÝ 2
Chúng tôi điền vào chứng minh của Định lý 2. Đầu tiên, chúng tôi phát biểu lại kết quả một cách nghiêm ngặt như sau.

Định lý 2. Với i = 1,2, gọi (Xi,yi)∈(Rmi×d,Rmi) biểu thị hai nhiệm vụ hồi quy tuyến tính với tham số θi∈Rd. Giả sử rằng mỗi hàng của X1 được rút độc lập từ một phân phối với hiệp phương sai Σ1∈Rd×d và chuẩn l2 bị chặn √L. Giả định θ1^T Σ1 θ1 = 1 w.l.o.g.

Gọi c∈[κ(X2)sin(θ1,θ2),1/3] biểu thị biên lỗi mong muốn. Ký hiệu (B*,A*_1,A*_2) là nghiệm MTL tối ưu. Với xác suất 1-δ trên tính ngẫu nhiên của (X1,y1), khi

m1 ≳ max{(Lκ(θ1)log d)/(σ²min(Σ1)), (κ²(Σ1)κ²(X2))/(c²‖y2‖²), (κ²(Σ1)κ⁴(X2))/(c⁴σ²ε1 log 1/δ)},

chúng ta có ‖B*A*_2-θ2‖/‖θ2‖ ≤ 6c + (1-13c)‖ε2‖/(‖X2θ2‖).

Chúng tôi đưa ra một số nhận xét để cung cấp thêm hiểu biết về Định lý 2.

Định lý 2 đảm bảo chuyển giao tích cực trong MTL, khi các mô hình nguồn và đích gần nhau và số lượng mẫu nguồn lớn. Trong khi trực quan là quan niệm dân gian trong MTL, chúng tôi cung cấp một biện minh chính thức trong các mô hình tuyến tính và ReLU để định lượng hiện tượng.

Giới hạn lỗi giảm với c, do đó c càng nhỏ càng tốt. Mặt khác, số điểm dữ liệu yêu cầu m1 tăng. Do đó có sự đánh đổi giữa độ chính xác và lượng dữ liệu.

c được giả định nhiều nhất là 1/3. Giả định này phát sinh khi chúng ta xử lý nhiễu nhãn của nhiệm vụ 2. Nếu không có nhiễu cho nhiệm vụ 2, thì giả định này không cần thiết. Nếu có nhiễu cho nhiệm vụ 2, giả định này được thỏa mãn khi sin(θ1,θ2) nhỏ hơn 1/(3κ(X2)). Trong các thực nghiệm tổng hợp, chúng tôi quan sát rằng sự phụ thuộc vào κ(X2) và sin(θ1,θ2) đều phát sinh trong hiệu suất của nhiệm vụ 2, cf. Hình 3 và Hình 7, tương ứng.

Chứng minh của Định lý 2 bao gồm hai bước.

17

--- TRANG 18 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
a) Chúng tôi chỉ ra rằng góc giữa B* và θ1 sẽ nhỏ. Một khi điều này được thiết lập, chúng ta thu được một giới hạn về góc giữa B* và θ2 thông qua bất đẳng thức tam giác.
b) Chúng tôi giới hạn khoảng cách giữa B*A2 và θ2. Khoảng cách bao gồm hai phần. Một phần đến từ B*, tức là góc giữa B* và θ2. Phần thứ hai đến từ A2, tức là lỗi ước lượng của chuẩn của θ2, liên quan đến tỷ lệ tín hiệu trên nhiễu của nhiệm vụ hai.

Chúng tôi đầu tiên chỉ ra sự thật hình học sau, sẽ được sử dụng sau này trong chứng minh.

Sự thật 7. Gọi a,b∈Rd biểu thị hai vectơ đơn vị. Giả sử rằng X∈Rm×d có rank cột đầy đủ với số điều kiện được ký hiệu bởi κ = κ(X). Thì chúng ta có
|sin(Xa,Xb)| ≤ κ/2|sin(a,b)|.

Chứng minh. Gọi X = UDV^T là SVD của X. Vì X có rank cột đầy đủ theo giả định, chúng ta có X^T X = XX^T = Id. Rõ ràng, chúng ta có sin(Xa,Xb) = sin(DV^T a, DV^T b). Ký hiệu a' = V^T a và b' = V^T b. Chúng ta cũng có a' và b' đều là vectơ đơn vị, và sin(a',b') = sin(a,b). Gọi σ1,···,σd biểu thị các giá trị singular của X. Thì,

sin²(Da',Db') = 1 - (∑d_i=1 σ²i a'i b'i)²/(∑d_i=1 σ²i a'i²)(∑d_i=1 σ²i b'i²)

= (∑1≤i,j≤d σ²i σ²j (a'i b'j - a'j b'i)²)/(∑d_i=1 σ²i a'i²)(∑d_j=1 σ²j b'j²)

≤ σ⁴max/σ⁴min ∑1≤i,j≤d (a'i b'j - a'j b'i)²

= κ⁴/4((∑d_i=1 a'i²)(∑d_i=1 b'i²) - (∑d_i=1 a'i b'i)²) = κ⁴/4 sin²(a',b').

Điều này kết thúc chứng minh.

Chúng tôi đầu tiên chỉ ra Bổ đề sau, giới hạn góc giữa B* và θ2.

Bổ đề 8. Trong thiết lập của Định lý 2, với xác suất 1-δ trên tính ngẫu nhiên của nhiệm vụ một, chúng ta có
|sin(B*,θ2)| ≤ sin(θ1,θ2) + c/κ(X2).

Chứng minh. Chúng tôi lưu ý rằng h(B*) ≥ ‖y1‖² bởi tính tối ưu của B*. Hơn nữa, ⟨X2B*/‖X2B*‖, y2⟩ ≥ ‖y2‖². Do đó chúng ta thu được

⟨X1B*/‖X1B*‖, y1⟩² ≥ ‖y1‖² - ‖y2‖².

Với phía trái,
⟨X1B*/‖X1B*‖, y1⟩² = ⟨X1B*/‖X1B*‖, X1θ1 + ε1⟩²
= ⟨X1B*/‖X1B*‖, X1θ1⟩² + ⟨X1B*/‖X1B*‖, ε1⟩² + 2⟨X1B*/‖X1B*‖, X1θ1⟩⟨X1B*/‖X1B*‖, ε1⟩

Lưu ý rằng số hạng thứ hai là một biến ngẫu nhiên chi-squared với kỳ vọng σ²ε1. Do đó nó được giới hạn bởi σ²ε1√(log 1/δ) với xác suất ít nhất 1-δ. Tương tự, số hạng thứ ba được giới hạn bởi 2‖X1θ1‖σε1√(log 1/δ) với xác suất 1-δ. Do đó, chúng ta thu được

‖X1θ1‖² cos²(X1B*, X1θ1) ≥ ‖y1‖² - ‖y2‖² - (σ²ε1 + 2σε1‖X1θ1‖)√(log 1/δ)

Lưu ý rằng
‖y1‖² ≥ ‖X1θ1‖² - 2⟨X1θ1, ε1⟩ ≥ ‖X1θ1‖² - 2‖X1θ1‖σε1√(log 1/δ).

Do đó,
‖X1θ1‖² cos²(X1B*, X1θ1) ≥ ‖X1θ1‖² - ‖y2‖² - (σ²ε1 + 4σε1‖X1θ1‖)√(log 1/δ)

⇒ sin²(X1B*, X1θ1) ≤ (‖y2‖²/‖X1θ1‖² + 4σε1√(log 1/δ)/‖X1θ1‖ + σ²ε1√(log 1/δ)/‖X1θ1‖²)

⇒ sin²(B*, θ1) ≤ κ²(X1)(‖y2‖²/‖X1θ1‖² + 4σε1√(log 1/δ)/‖X1θ1‖) (bởi Bổ đề 7)

Bởi bất đẳng thức tập trung ma trận Bernstein (xem ví dụ Tropp et al. (2015)), khi m1 ≳ κ(θ1)log d/σ²min(Σ1), chúng ta có

‖1/m1 X₁ᵀX₁ - Σ₁‖ ≤ 1/(2σmin(Σ₁)).

Do đó chúng ta thu được κ(X₁) ≤ 3κ(Σ₁) và ‖X₁θ₁‖² ≥ m₁θ₁ᵀΣ₁θ₁/2 = m₁/2 (trong đó chúng ta giả định θ₁ᵀΣ₁θ₁ = 1). Do đó,

sin²(B*, θ₁) ≤ 3κ(Σ₁)(‖y₂‖²/(m₁/4) + 4σ_ε₁√(log 1/δ)/√(m₁/2))

đây là nhiều nhất c²/κ²(X₂) bởi thiết lập m₁ của chúng tôi. Do đó, kết luận theo sau bởi bất đẳng thức tam giác (lưu ý rằng cả c và sin(θ₁,θ₂) đều nhỏ hơn 1/2).

Dựa trên Bổ đề trên, chúng tôi giờ đây sẵn sàng chứng minh Định lý 2.

Chứng minh của Định lý 2. Lưu ý rằng trong mô hình MTL, sau khi thu được B*, chúng tôi sau đó giải lớp tuyến tính cho mỗi nhiệm vụ. Đối với nhiệm vụ 2, điều này đưa ra giá trị trọng số A*₂ := ⟨X₂B̂, y₂⟩/‖X₂B̂‖². Do đó các hệ số hồi quy cho nhiệm vụ 2 là B*A*₂. Với phần còn lại của chứng minh, chúng tôi tập trung vào việc giới hạn khoảng cách giữa B*A*₂ và θ₂. Bởi bất đẳng thức tam giác,

‖B*A*₂ - θ₂‖ ≤ |⟨X₂B*, ε₂⟩|/‖X₂B*‖² + |⟨X₂B*, X₂θ₂⟩|/‖X₂B*‖² ‖θ₂‖ + ‖B*‖‖θ₂‖‖. (8)

Lưu ý rằng số hạng thứ hai của phương trình 8 bằng
|⟨X₂B*, X₂(θ₂‖θ₂‖ - B*)⟩|/‖X₂B*‖² ≤ κ(X₂)‖θ₂‖‖θ₂‖θ₂‖ - B*‖.

Số hạng đầu tiên của phương trình 8 được giới hạn bởi
‖ε₂‖/‖X₂B*‖ ≤ ‖ε₂‖‖θ₂‖/(‖X₂θ₂‖‖X₂(θ₂‖θ₂‖ - B*)‖). (9)

Cuối cùng, chúng ta có
‖θ₂‖θ₂‖ - B*‖² = ‖θ₂‖² - 2⟨θ₂, B*⟩ + ‖B*‖² = 2‖θ₂‖²(1 - cos(B*, θ₂)) ≤ 2‖θ₂‖² sin²(B*, θ₂)

Bởi Bổ đề 8, chúng ta có
|sin(B*, θ₂)| ≤ sin(θ₁, θ₂) + c/κ(X₂)

Do đó, chúng tôi kết luận rằng phương trình 9 nhiều nhất là
‖ε₂‖‖θ₂‖/(‖X₂θ₂‖√2σmax(X₂)‖θ₂‖sin(θ₁, θ₂)) ≤ ‖ε₂‖‖θ₂‖/(‖X₂θ₂‖√2cσmin(X₂)‖θ₂‖) ≤ ‖ε₂‖‖θ₂‖/(‖X₂θ₂‖3cσmin(X₂)‖θ₂‖) ≤ (1-13c)‖ε₂‖‖θ₂‖/‖X₂θ₂‖

Do đó phương trình 8 nhiều nhất là:
‖θ₂‖(1-13c)‖ε₂‖/‖X₂θ₂‖ + √2(κ(X₂) + 1)sin(B*, θ₂) ≤ ‖θ₂‖(1-13c)‖ε₂‖/‖X₂θ₂‖ + 6c.

Do đó chúng ta thu được lỗi ước lượng mong muốn của BA*₂.

A.2.3 MỞ RỘNG ĐẾN MÔ HÌNH RELU
Trong phần này, chúng tôi mở rộng Định lý 2 đến mô hình ReLU. Lưu ý rằng bài toán được rút gọn thành mục tiêu sau.

max_{B∈Rd} g(B) = ⟨ReLU(X₁B)/‖ReLU(X₁B)‖, y₁⟩² + ⟨ReLU(X₂B)/‖ReLU(X₂B)‖, y₂⟩² (10)

Chúng tôi đưa ra một giả định quan trọng rằng đầu vào X₁ của nhiệm vụ 1 tuân theo phân phối Gaussian. Lưu ý rằng việc đưa ra các giả định phân phối là cần thiết vì đối với đầu vào trường hợp xấu nhất, ngay cả việc tối ưu hóa một hàm ReLU đơn dưới mất mát bình phương cũng là NP-hard (Manurangsi và Reichman (2018)). Chúng tôi phát biểu kết quả của chúng tôi một cách chính thức như sau.

Định lý 9. Gọi (X₁,y₁)∈(R^{m₁×d}, R^{m₁}) và (X₂,y₂)∈(R^{m₂×d}, R^{m₂}) biểu thị hai nhiệm vụ. Giả sử rằng mỗi hàng của X₁ được rút từ phân phối Gaussian chuẩn. Và yi = ai ⊙ ReLU(Xiθi) + εi được tạo ra thông qua mô hình ReLU với θ₁,θ₂∈Rd. Gọi E[(ai ⊙ ReLU(Xiθi))²j] = 1 cho mọi 1≤j≤m₁ không mất tính tổng quát, và gọi σ²ε₁ biểu thị phương sai của mỗi phần tử của ε₁.

Giả sử rằng c ≤ sin(θ₁,θ₂)/κ(X₂). Ký hiệu (B*,A*₁,A*₂) là nghiệm MTL tối ưu của phương trình 10. Với xác suất 1-δ trên tính ngẫu nhiên của (X₁,y₁), khi
m₁ ≳ max{d log d/(c²(1/c² + log d)), ‖y₂‖²/c²},

chúng ta có lỗi ước lượng nhiều nhất là:
sin(B*,θ₁) ≤ sin(θ₁,θ₂) + O(c/κ(X₂));
|A*₂ - a₂|/a₂ ≤ O(c) + (1-O(c))‖ε₂‖/(a₂ ⊙ ReLU(‖X₂θ₂‖))

Chứng minh. Chứng minh tuân theo một cấu trúc tương tự như Định lý 2. Không mất tính tổng quát, chúng ta có thể giả định rằng θ₁,θ₂ đều là vectơ đơn vị. Chúng tôi đầu tiên giới hạn góc giữa B* và θ₁.

Bởi tính tối ưu của B*, chúng ta có:
⟨ReLU(X₁B*)/‖ReLU(X₁B*)‖, y₁⟩² ≥ ⟨ReLU(X₁θ₁)/‖ReLU(X₁θ₁)‖, y₁⟩² - ‖y₂‖²

Từ điều này chúng ta thu được:
a²₁⟨ReLU(X₁B*)/‖ReLU(X₁B*)‖, ReLU(X₁B*)⟩² ≥ a²₁‖ReLU(X₁θ₁)‖² - ‖y₂‖² - (σ²ε₁ + 4a₁σε₁‖ReLU(X₁θ₁)‖)√(log 1/δ) (11)

Lưu ý rằng mỗi phần tử của ReLU(X₁θ₁) là một biến ngẫu nhiên Gaussian bị cắt. Bởi giới hạn Hoeffding, với xác suất 1-δ chúng ta có
‖ReLU(X₁θ₁)‖² ≥ m₁/2 - √(m₁/2 log 1/δ).

Đối với ⟨ReLU(X₁B*), ReLU(X₁θ₁)⟩, chúng tôi sẽ sử dụng một lập luận epsilon-net trên B*. Đối với một B* cố định, chúng tôi lưu ý rằng đây là một tổng của các biến ngẫu nhiên độc lập đều được giới hạn trong O(log m₁) với xác suất 1-δ. Ký hiệu α là góc giữa B* và θ₁, một sự thật hình học chuẩn phát biểu rằng (xem ví dụ Bổ đề 1 của Du et al. (2017)) đối với một vectơ Gaussian ngẫu nhiên x∈Rd,

E_x[ReLU(x^T B*)ReLU(x^T θ₁)] = (cos α)/2 + cos(α tan α)/(2π) := g(α)/2.

Do đó, bằng cách áp dụng bất đẳng thức Bernstein và union bound, với xác suất 1-δ chúng ta có:
|⟨ReLU(X₁B*), ReLU(X₁θ₁)⟩ - m₁g(α)/2| ≤ 2√(m₁g(α) log 1/δ) + (2/3)log 1/δ log m₁

Bằng các lập luận chuẩn, tồn tại một tập hợp d^{O(d)} vectơ đơn vị S sao cho đối với bất kỳ vectơ đơn vị u nào khác tồn tại û∈S sao cho ‖u-û‖ ≤ min(1/d³, c²/κ²(X₂)). Bằng cách đặt δ = d^{-O(d)} và union bound trên tất cả các vectơ đơn vị trong S, chúng ta có tồn tại û∈S thỏa mãn ‖B*-û‖ ≤ min(1/d³, c²/κ²(X₂)) và:

|⟨ReLU(X₁û), ReLU(X₁θ₁)⟩ - m₁g(α₀)/2| ≲ √(m₁d log d) + d log² d ≤ m₁c²/κ²(X₂) (bởi thiết lập m₁ của chúng tôi)

trong đó α₀ là góc giữa û và θ₁. Lưu ý rằng ⟨ReLU(X₁û) - ReLU(X₁B*), ReLU(X₁θ₁)⟩ ≤ ‖X₁(û-B*)‖‖ReLU(X₁θ₁)‖ ≤ c²κ(X₂)O(m₁)

Cùng nhau chúng ta đã chỉ ra rằng
|⟨ReLU(X₁B*), ReLU(X₁θ₁)⟩ - m₁g(α₀)/2| ≤ c²κ²(X₂)O(m₁).

Kết hợp với phương trình 11, bởi thiết lập m₁ của chúng tôi, không khó để chỉ ra rằng
g(α₀) ≥ 1 - O(c²/κ²(X₂)).

Lưu ý rằng
1 - g(α₀) = 1 - cos α₀ - cos α₀(tan α₀)/π ≥ 1 - cos α₀ = 2sin²α₀/2 ≳ c²/κ²(X₂),

điều này ngụ ý rằng sin²α₀ ≳ c²/κ²(X₂) (vì cos α₀ ≥ 0.9). Cuối cùng lưu ý rằng ‖û-B*‖² = 2(1-cos(û,B*)) ≤ 2sin²(û,B*). Tổng thể, chúng tôi kết luận rằng sin(B*,θ₁) ≤ O(c/κ(X₂)). Do đó
sin(B*,θ₂) ≤ sin(θ₁,θ₂) + O(c/κ(X₂)).

Đối với ước lượng của a₂, chúng ta có ⟨ReLU(X₂B*), y₂⟩/‖ReLU(X₂B*)‖² - a₂ ≤ |⟨ReLU(X₂B*), ε₂⟩|/‖ReLU(X₂B*)‖² + a₂⟨ReLU(X₂B*), ReLU(X₂B*) - ReLU(X₂θ₂)⟩/‖ReLU(X₂B*)‖²

Phần đầu tiên nhiều nhất là
‖ε₂‖/‖ReLU(X₂B*)‖ ≤ ‖ε₂‖/‖ReLU(X₂θ₂)‖‖ReLU(X₂θ₂) - ReLU(X₂B*)‖/(1-O(c))‖ε₂‖/‖ReLU(X₂θ₂)‖

Tương tự, chúng ta có thể chỉ ra rằng phần thứ hai nhiều nhất là O(c). Do đó, chứng minh hoàn tất.

21

--- TRANG 22 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
A.3 CHỨNG MINH CỦA MỆNH ĐỀ 3
Trong phần này, chúng tôi trình bày chứng minh của Mệnh đề 3. Thực tế, chúng tôi trình bày một kết quả tinh tế hơn, bằng cách chỉ ra rằng tất cả các cực tiểu địa phương đều là cực tiểu toàn cục cho mất mát có trọng số trong trường hợp tuyến tính.

f(A₁,A₂,···,Aₖ,B) = ∑ᵢ₌₁ᵏ λᵢ‖(XᵢBAᵢ-yᵢ)‖²F; (12)

Chìa khóa là rút gọn mục tiêu MTL f(·) thành xấp xỉ ma trận rank thấp, và áp dụng kết quả gần đây của Balcan et al. (2018) chỉ ra rằng không có cực tiểu địa phương giả mạo cho bài toán sau.

Bổ đề 10. Giả định rằng XᵢᵀXᵢ = λᵢΣ với λᵢ > 0 cho tất cả 1≤i≤k. Thì tất cả các cực tiểu địa phương của f(A₁,···,Aₖ,B) đều là cực tiểu toàn cục của phương trình 3.

Chứng minh. Chúng tôi đầu tiên chuyển đổi bài toán từ không gian của B sang không gian của C. Lưu ý rằng điều này không mất tính tổng quát, vì có một ánh xạ một-một giữa B và C với C = DV^ᵀB. Trong trường hợp này, mục tiêu tương ứng trở thành:

g(A₁,···,Aₖ,B) = ∑ᵢ₌₁ᵏ λᵢ‖UᵢCAᵢ - yᵢ‖² = ∑ᵢ₌₁ᵏ ‖C(√λᵢAᵢ) - √λᵢUᵢᵀyᵢ‖² + ∑ᵢ₌₁ᵏ λᵢ(‖yᵢ‖² - ‖Uᵢᵀyᵢ‖²)

Biểu thức sau là một hằng số. Do đó nó không ảnh hưởng đến nghiệm tối ưu. Đối với biểu thức trước, ký hiệu A∈R^{r×k} là việc xếp các √λᵢAᵢ lại với nhau theo cột. Tương tự, ký hiệu Z∈R^{d×k} là việc xếp √λᵢUᵢᵀyᵢ lại với nhau theo cột. Thì việc tối thiểu hóa g(·) quy về giải xấp xỉ ma trận rank thấp: ‖CA - Z‖²F.

Bởi Bổ đề 3.1 của Balcan et al. (2018), các cực tiểu địa phương duy nhất của ‖CA - Z‖²F là những cái trong đó CA bằng xấp xỉ rank-r tốt nhất của Z. Do đó chứng minh hoàn tất.

Bây giờ chúng tôi sẵn sàng chứng minh Mệnh đề 3.

Chứng minh của Mệnh đề 3. Bởi Mệnh đề 5, nghiệm tối ưu của B* cho phương trình 12 là VD⁻¹ nhân với xấp xỉ rank-r tốt nhất của ∑ᵢ λᵢUᵢᵀyᵢyᵢᵀUᵢ, trong đó chúng tôi ký hiệu SVD của X là UDV^ᵀ. Ký hiệu QᵣQᵣᵀ là xấp xỉ rank-r tốt nhất của U^ᵀZZ^ᵀU, trong đó chúng tôi ký hiệu Z = [√λ₁y₁,√λ₂y₂,···,√λₖyₖ] là việc xếp k vectơ thành một ma trận d×k. Do đó kết quả của Mệnh đề 5 chỉ ra rằng nghiệm tối ưu B* là VD⁻¹Qᵣ, bằng (X^ᵀX)⁻¹XQᵣ. Bởi Mệnh đề 4, tính tối ưu của B* giống nhau cho đến các phép biến đổi trên không gian cột. Do đó chứng minh hoàn tất.

Để chỉ ra rằng tất cả các cực tiểu địa phương cũng bằng (X^ᵀX)⁻¹XQᵣ, chúng ta có thể đơn giản áp dụng Bổ đề 10 và Mệnh đề 3.

Nhận xét. Kết quả này chỉ áp dụng cho mô hình tuyến tính và không hoạt động trên các mô hình ReLU. Câu hỏi về việc đặc tính hóa cảnh quan tối ưu hóa trong các mô hình ReLU phi tuyến không được hiểu rõ dựa trên hiểu biết lý thuyết hiện tại về mạng nơ-ron. Chúng tôi để lại điều này cho công việc tương lai.

22

--- TRANG 23 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
B KẾT QUẢ THỰC NGHIỆM BỔ SUNG
Chúng tôi điền vào các chi tiết bị thiếu từ phần thực nghiệm của chúng tôi. Trong Phụ lục B.1, chúng tôi xem xét các bộ dữ liệu được sử dụng trong các thực nghiệm của chúng tôi. Trong Phụ lục B.2, chúng tôi mô tả các mô hình chúng tôi sử dụng trên mỗi bộ dữ liệu. Trong Phụ lục B.3, chúng tôi mô tả các quy trình huấn luyện cho tất cả các thực nghiệm. Trong Phụ lục B.4 và Phụ lục B.5, chúng tôi chỉ ra các thực nghiệm tổng hợp và thế giới thực mở rộng để hỗ trợ các khẳng định của chúng tôi.

B.1 BỘ DỮ LIỆU
Chúng tôi mô tả các thiết lập tổng hợp và các bộ dữ liệu Phân tích Cảm xúc, bộ dữ liệu chuẩn General Language Understanding Evaluation (GLUE), và ChestX-ray14 được sử dụng trong các thực nghiệm.

Thiết lập tổng hợp. Đối với các thực nghiệm tổng hợp, chúng tôi rút 10,000 mẫu dữ liệu ngẫu nhiên với chiều d = 100 từ Gaussian chuẩn N(0,1) và tính các nhãn tương ứng dựa trên mô hình được mô tả trong thực nghiệm. Chúng tôi chia các mẫu dữ liệu thành tập huấn luyện và xác thực với 9,000 và 1,000 mẫu trong mỗi tập. Đối với các nhiệm vụ phân loại, chúng tôi tạo ra các nhãn bằng cách áp dụng một hàm sigmoid và sau đó ngưỡng hóa giá trị thành nhãn nhị phân tại 0.5. Đối với các nhiệm vụ hồi quy ReLU, chúng tôi áp dụng hàm kích hoạt ReLU trên các nhãn có giá trị thực. Số lượng mẫu dữ liệu được sử dụng trong các thực nghiệm thay đổi tùy thuộc vào đặc tả. Cụ thể, đối với thực nghiệm hiệp phương sai nhiệm vụ của Hình 3, chúng tôi cố định dữ liệu của nhiệm vụ 1 với m₁ = 9,000 dữ liệu huấn luyện và thay đổi dữ liệu của nhiệm vụ 2 dưới ba thiết lập: (i) cùng phép quay Q₁ = Q₂ nhưng giá trị singular khác nhau D₁ ≠ D₂; (ii) cùng giá trị singular D₁ = D₂ nhưng phép quay ngẫu nhiên Q₁ ≠ Q₂.

Phân tích cảm xúc. Đối với nhiệm vụ phân tích cảm xúc, mục tiêu là hiểu các ý kiến cảm xúc được thể hiện trong văn bản dựa trên ngữ cảnh được cung cấp. Đây là một nhiệm vụ phân loại văn bản phổ biến thường được công thức hóa như một nhiệm vụ phân loại đa nhãn trên các rating khác nhau như tích cực (+1), tiêu cực (-1), hoặc trung tính (0). Chúng tôi sử dụng sáu bộ dữ liệu chuẩn phân tích cảm xúc trong các thực nghiệm của chúng tôi:

Cảm xúc đánh giá phim (MR): Trong bộ dữ liệu MR (Pang và Lee (2005)), mỗi đánh giá phim bao gồm một câu đơn. Mục tiêu là phát hiện các đánh giá tích cực vs. tiêu cực.

Chủ quan câu (SUBJ): Bộ dữ liệu SUBJ được đề xuất trong Pang và Lee (2004) và mục tiêu là phân loại liệu một câu cho trước có chủ quan hay khách quan.

Phân cực đánh giá khách hàng (CR): Bộ dữ liệu CR (Hu và Liu (2004)) cung cấp các đánh giá khách hàng về các sản phẩm khác nhau. Mục tiêu là phân loại các đánh giá tích cực và tiêu cực.

Loại câu hỏi (TREC): Bộ dữ liệu TREC được thu thập bởi Li và Roth (2002). Mục tiêu là phân loại một câu hỏi thành 6 loại câu hỏi.

Phân cực ý kiến (MPQA): Bộ dữ liệu MPQA phát hiện liệu một ý kiến có phân cực hay không (Wiebe et al. (2005)).

Cây cảm xúc Stanford (SST): Bộ dữ liệu SST, được tạo bởi Socher et al. (2013), là một mở rộng của bộ dữ liệu MR.

Bộ dữ liệu chuẩn General Language Understanding Evaluation (GLUE). GLUE là một tập hợp các nhiệm vụ NLP bao gồm trả lời câu hỏi, phân tích cảm xúc, tương tự văn bản và các vấn đề suy luận văn bản. Bộ dữ liệu chuẩn GLUE là một bộ dữ liệu chuẩn MTL tiên tiến cho cả học thuật và công nghiệp. Chúng tôi chọn năm nhiệm vụ đại diện bao gồm CoLA, MRPC, QNLI, RTE, và SST-2 để xác thực phương pháp đề xuất của chúng tôi. Chúng tôi nhấn mạnh rằng mục tiêu của công trình này không phải là đưa ra một kết quả tiên tiến mà là cung cấp hiểu biết về hoạt động của học đa nhiệm vụ. Có thể hình dung rằng kết quả của chúng tôi có thể được mở rộng đến toàn bộ bộ dữ liệu. Điều này được để lại cho công việc tương lai. Thêm chi tiết về bộ dữ liệu chuẩn GLUE có thể được tìm thấy trong bài báo gốc (Wang et al. (2018a)).

ChestX-ray14. Bộ dữ liệu ChestX-ray14 (Wang et al. (2017)) là bộ dữ liệu X-quang ngực lớn nhất có sẵn công khai. Nó chứa 112,120 hình ảnh X-quang ngực từ phía trước của 30,805 bệnh nhân duy nhất. Mỗi hình ảnh chứa đến 14 nhãn bệnh lý ngực khác nhau sử dụng các phương pháp trích xuất tự động trên báo cáo X-quang. Điều này có thể được công thức hóa như một vấn đề phân loại hình ảnh đa nhãn 14 nhiệm vụ. Bộ dữ liệu ChestX-ray14 là một bộ dữ liệu đại diện trong lĩnh vực hình ảnh y tế cũng như trong thị giác máy tính. Chúng tôi sử dụng bộ dữ liệu này để kiểm tra sơ đồ tái cân bằng trọng số nhiệm vụ đề xuất của chúng tôi vì nó thỏa mãn giả định rằng tất cả các nhiệm vụ có cùng dữ liệu đầu vào nhưng nhãn khác nhau.

23

--- TRANG 24 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
B.2 MÔ HÌNH
Thiết lập tổng hợp. Đối với các thực nghiệm tổng hợp, chúng tôi sử dụng mô hình hồi quy tuyến tính, mô hình hồi quy logistic và một mạng nơ-ron một lớp với hàm kích hoạt ReLU.

Phân tích cảm xúc. Đối với các thực nghiệm phân tích cảm xúc, chúng tôi xem xét ba mô hình khác nhau bao gồm perceptron đa lớp (MLP), LSTM, CNN:

Đối với mô hình MLP, chúng tôi tính trung bình các nhúng từ của một câu và đưa kết quả vào một perceptron hai lớp, theo sau bởi một lớp phân loại.

Đối với mô hình LSTM, chúng tôi sử dụng LSTM một lớp một chiều tiêu chuẩn như được đề xuất bởi Lei et al. (2018), theo sau bởi một lớp phân loại.

Đối với mô hình CNN, chúng tôi sử dụng mô hình được đề xuất bởi Kim (2014) sử dụng một lớp tích chập với nhiều bộ lọc, theo sau bởi một lớp ReLU, lớp max-pooling, và lớp phân loại. Chúng tôi tuân theo giao thức của Kim (2014) và đặt kích thước bộ lọc là {3,4,5}.

Chúng tôi sử dụng các nhúng GLoVe được huấn luyện trước trên corpus Wikipedia 2014 và Gigaword 5⁶. Chúng tôi tinh chỉnh toàn bộ mô hình trong các thực nghiệm của chúng tôi. Trong thiết lập học đa nhiệm vụ, các mô-đun chung bao gồm lớp nhúng và lớp trích xuất đặc trưng (tức là mô hình MLP, LSTM, hoặc CNN). Mỗi nhiệm vụ có mô-đun đầu ra riêng biệt.

GLUE. Đối với các thực nghiệm trên bộ dữ liệu chuẩn GLUE, chúng tôi sử dụng một mô hình ngôn ngữ tiên tiến gọi là BERT (Devlin et al. (2018)). Đối với mỗi nhiệm vụ, chúng tôi thêm một lớp phân loại/hồi quy trên đầu nó như mô hình của chúng tôi. Đối với tất cả các thực nghiệm, chúng tôi sử dụng mô hình BERT LARGE uncased, là một mạng 24 lớp như được mô tả trong Devlin et al. (2018). Đối với thiết lập học đa nhiệm vụ, chúng tôi tuân theo công trình của Liu et al. (2019a) và sử dụng BERT LARGE làm mô-đun chung.

ChestX-ray14. Đối với các thực nghiệm trên bộ dữ liệu ChestX-ray14, chúng tôi sử dụng mô hình DenseNet được đề xuất bởi Rajpurkar et al. (2017) làm mô-đun chung, là một mạng 121 lớp. Đối với mỗi nhiệm vụ, chúng tôi sử dụng một lớp đầu ra phân loại riêng biệt. Chúng tôi sử dụng mô hình được huấn luyện trước⁷ trong các thực nghiệm của chúng tôi.

B.3 QUY TRÌNH HUẤN LUYỆN
Trong phần phụ này, chúng tôi mô tả các quy trình huấn luyện cho các thực nghiệm của chúng tôi.

Mini-batch SGD. Chúng tôi mô tả các chi tiết của việc lấy mẫu dữ liệu nhiệm vụ trong triển khai SGD của chúng tôi.

Đối với các nhiệm vụ với đặc trưng khác nhau như GLUE, trước tiên chúng tôi chia dữ liệu của mỗi nhiệm vụ thành các batch nhỏ. Sau đó, chúng tôi trộn tất cả các batch từ tất cả các nhiệm vụ và xáo trộn ngẫu nhiên. Trong mỗi epoch, một bước SGD được áp dụng trên mỗi batch qua nhiệm vụ tương ứng. Nếu batch hiện tại dành cho nhiệm vụ i, thì SGD được áp dụng trên Ai, và có thể Ri hoặc B tùy thuộc vào thiết lập. Các tham số khác cho các nhiệm vụ khác được cố định.

Đối với các nhiệm vụ với cùng đặc trưng như ChestX-ray14, SGD được áp dụng trên tất cả các nhiệm vụ cùng nhau để cập nhật tất cả các Ai và B cùng nhau.

Thiết lập tổng hợp. Đối với các thực nghiệm tổng hợp, chúng tôi thực hiện tìm kiếm lưới trên tỷ lệ học từ {1e-4,1e-3,1e-2,1e-1} và số epoch từ {10,20,30,40,50}. Chúng tôi chọn kết quả tốt nhất cho tất cả các thực nghiệm. Chúng tôi chọn tỷ lệ học là 1e-3, số epoch là 30, và kích thước batch là 50. Đối với nhiệm vụ hồi quy, chúng tôi báo cáo điểm tương quan Spearman. Đối với nhiệm vụ phân loại, chúng tôi báo cáo độ chính xác phân loại.

Phân tích cảm xúc. Đối với các thực nghiệm phân tích cảm xúc, chúng tôi chia ngẫu nhiên dữ liệu thành tập huấn luyện, dev và test với tỷ lệ phần trăm 80%, 10%, và 10% tương ứng. Chúng tôi tuân theo giao thức của Lei et al. (2018) để thiết lập mô hình cho các thực nghiệm phân tích cảm xúc.

Chiều ẩn mặc định của mô hình (ví dụ: LSTM) được đặt là 200, nhưng chúng tôi thay đổi tham số này cho các thực nghiệm khả năng mô hình. Chúng tôi báo cáo điểm độ chính xác trên tập test làm chỉ số hiệu suất.

⁶ http://nlp.stanford.edu/data/wordvecs/glove.6B.zip
⁷ https://github.com/pytorch/vision

24

--- TRANG 25 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
Hiệu suất MTL so với STL (tương quan Spearman)−0.4−0.20
Khoảng cách cosine giữa các nhiệm vụ0 0.5 1.0
(a) Nhiệm vụ hồi quy tuyến tính
Hiệu suất MTL so với STL (Độ chính xác)−0.2−0.10
Khoảng cách cosine giữa các nhiệm vụ0 0.5 1.0 (b) Nhiệm vụ phân loại logistic
Hiệu suất MTL so với STL (tương quan Spearman)−0.04−0.0200.02
Khoảng cách cosine giữa các nhiệm vụ0 0.5 1.0
(c) Nhiệm vụ hồi quy với phi tuyến ReLU
Hiệu suất MTL so với STL (Độ chính xác)−0.0500.05
Khoảng cách cosine giữa các nhiệm vụ0 0.5 1.0 (d) Nhiệm vụ phân loại với phi tuyến ReLU
Hình 7: So sánh hiệu suất mô hình MTL trên sự tương tự nhiệm vụ khác nhau. Đối với (a) và (c), MTL huấn luyện hai nhiệm vụ hồi quy; Đối với (b) và (d), MTL huấn luyện hai nhiệm vụ phân loại. Đối với các nhiệm vụ hồi quy, chúng tôi sử dụng tương quan spearman làm chỉ số hiệu suất mô hình. Đối với các nhiệm vụ phân loại, chúng tôi sử dụng độ chính xác làm chỉ số. Chúng tôi báo cáo hiệu suất mô hình trung bình trên hai nhiệm vụ. Trục x biểu thị khoảng cách cosine, tức là 1-cos(θ₁,θ₂).

GLUE. Đối với các thực nghiệm GLUE, quy trình huấn luyện được sử dụng trên các mô-đun căn chỉnh và các mô-đun đầu ra. Do sự phức tạp của mô-đun BERT LARGE, liên quan đến 24 lớp biến đổi phi tuyến.

Chúng tôi cố định mô-đun BERT LARGE trong quá trình huấn luyện để kiểm tra hiệu ứng của việc thêm các mô-đun căn chỉnh vào quá trình huấn luyện. Nói chung, ngay cả sau khi tinh chỉnh mô-đun BERT LARGE trên một tập hợp các nhiệm vụ, luôn có thể thêm các mô-đun căn chỉnh của chúng tôi và áp dụng Thuật toán 1.

Đối với các tham số huấn luyện, chúng tôi áp dụng tìm kiếm lưới để điều chỉnh tỷ lệ học từ {2e-5,3e-5,1e-5} và số epoch từ {2,3,5,10}. Chúng tôi chọn tỷ lệ học là 2e-5, số epoch là 5, và với kích thước batch 16 cho tất cả các thực nghiệm.

Chúng tôi sử dụng chỉ số đánh giá GLUE (cf. Wang et al. (2018b)) và báo cáo điểm số trên tập phát triển làm chỉ số hiệu suất.

ChestX-ray14. Đối với các thực nghiệm ChestX-ray14, chúng tôi sử dụng cấu hình được đề xuất bởi Rajpurkar et al. (2017) và báo cáo điểm AUC trên tập test sau khi tinh chỉnh mô hình trong 20 epoch.

B.4 CÁC THỰC NGHIỆM TỔNG HỢP MỞ RỘNG
Thay đổi tương tự cosine trên các mô hình tuyến tính và ReLU. Chúng tôi chứng minh hiệu ứng của tương tự cosine trong các thiết lập tổng hợp cho cả nhiệm vụ hồi quy và phân loại.

Nhiệm vụ tổng hợp. Chúng tôi bắt đầu với các thiết lập tuyến tính. Chúng tôi tạo ra 20 bộ dữ liệu nhiệm vụ tổng hợp (hoặc cho các nhiệm vụ hồi quy, hoặc các nhiệm vụ phân loại) dựa trên quy trình tạo dữ liệu và thay đổi sự tương tự nhiệm vụ giữa nhiệm vụ 1 và nhiệm vụ i. Chúng tôi chạy thực nghiệm với các cặp bộ dữ liệu khác nhau (bộ dữ liệu 1 và bộ dữ liệu i).

25

--- TRANG 26 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
Sim. 0.9
Sim. 0.7Sim. 0.5
Sim. 0.3Sim. 0.1Cải thiện Hiệu suất−0.200.2
# Kích thước dữ liệu2000 4000 6000 8000
(a) Nhiệm vụ hồi quy với phi tuyến
Sim. 0.9
Sim. 0.7Sim. 0.5
Sim. 0.3Sim. 0.1Cải thiện Hiệu suất−0.2−0.100.1
# Kích thước dữ liệu2000 4000 6000 8000 (b) Nhiệm vụ phân loại với phi tuyến
Hình 8: Cải thiện hiệu suất trên nhiệm vụ đích (MTL trừ STL) bằng cách thay đổi tương tự cosine của các mô hình STL của hai nhiệm vụ. Chúng tôi quan sát rằng sự tương tự cao hơn giữa các mô hình STL dẫn đến cải thiện tốt hơn trên nhiệm vụ đích.

Baseline
Thuật toán 1Chuyển Giao Tích Cực
Chuyển Giao Tiêu CựcHiệu suất Nhiệm vụ đích: MTL - STL−0.2−0.100.10.2
# Mẫu dữ liệu của nhiệm vụ nguồn2000 4000 6000 8000
(a) Nhiệm vụ hồi quy tuyến tính
Chuyển Giao Tích Cực
Chuyển Giao Tiêu CựcBaseline
Thuật toán 1Hiệu suất Nhiệm vụ đích: MTL - STL−0.2−0.100.10.2
# Mẫu dữ liệu của nhiệm vụ nguồn2000 4000 6000 8000 (b) Nhiệm vụ hồi quy với kích hoạt ReLU
Hình 9: So sánh Thuật toán 1 với huấn luyện MTL baseline trên ví dụ tổng hợp trong Phần 2.3. Thuật toán 1 sửa chữa hiện tượng chuyển giao tiêu cực được quan sát trong Hình 3.

Sau khi tạo ra các nhiệm vụ, chúng tôi so sánh khoảng cách hiệu suất giữa mô hình MTL và STL.

Kết quả. Từ Hình 7a và Hình 7a, chúng tôi thấy rằng đối với cả thiết lập hồi quy và phân loại, với sự tương tự nhiệm vụ lớn hơn, MTL vượt trội hơn mô hình STL và chuyển giao tiêu cực có thể xảy ra nếu sự tương tự nhiệm vụ quá nhỏ.

Thiết lập ReLU. Chúng tôi cũng xem xét một mô hình được kích hoạt bởi ReLU. Chúng tôi sử dụng cùng thiết lập như thiết lập tuyến tính, nhưng áp dụng kích hoạt ReLU để tạo ra dữ liệu. Kết quả tương tự được chỉ ra trong Hình 7c, 7d.

Chế độ rank cao hơn cho thiết lập ReLU. Chúng tôi cung cấp xác thực thêm về kết quả của chúng tôi trên các mô hình được kích hoạt bởi ReLU.

Nhiệm vụ tổng hợp. Trong thực nghiệm tổng hợp này, có hai tập hợp tham số mô hình θ₁∈R^{d×r} và θ₂∈R^{d×r} (d = 100 và r = 10). θ₁ là một ma trận quay ngẫu nhiên cố định và có m₁ = 100 điểm dữ liệu cho nhiệm vụ 1. Tham số mô hình của nhiệm vụ 2 là θ₂ = θ₁ + α(1-α)θ₀, trong đó θ₀ cũng là một ma trận quay cố định trực giao với θ₁. Lưu ý rằng α là giá trị cosine/tương tự của góc chính giữa θ₁ và θ₂.

Sau đó chúng tôi tạo ra X₁∈R^{m₁×d} và X₂∈R^{m₂×d} từ Gaussian. Đối với mỗi nhiệm vụ, các nhãn là yi = ReLU(Xi θi e) + εi, trong đó e∈R^r là vectơ toàn một và εi là nhiễu Gaussian ngẫu nhiên.

Cho hai nhiệm vụ, chúng tôi sử dụng MTL với kích hoạt ReLU và khả năng H = 10 để đồng huấn luyện hai nhiệm vụ. Mục tiêu là xem các mức độ khác nhau của α hoặc sự tương tự ảnh hưởng đến chuyển giao từ nhiệm vụ hai đến nhiệm vụ một như thế nào. Lưu ý rằng thiết lập này song song với thiết lập ReLU của Định lý 9 nhưng áp dụng cho rank r = 5.

26

--- TRANG 27 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
MTL-Avg.
STL-SST
STL-MR
STL-CR
STL-SUBJ
STL-MPQA
STL-TRECMTL-Avg. peak
LSTMĐộ Chính Xác
0.60.70.80.9
Khả năng mô hình0 100 200 300 400 500
Hình 10: Validation chéo để chọn khả năng mô hình có hiệu suất tốt nhất cho mỗi mô hình.

MTL-Avg.
STL-SST
STL-MRSTL-MR peak
MTL-Avg. peak
STL-SST peak
MLPĐộ Chính Xác
0.760.780.80
Khả năng mô hình0 100 200 300 400 500
MTL-Avg.
STL-SST
STL-MR
STL-MR peak
MTL-Avg. peak
STL-SST peak
CNNĐộ Chính Xác
0.800.850.90
Khả năng mô hình0 500 1000
MTL-Avg.
STL-SST
STL-MR
STL-MR peak
MTL-Avg. peak
STL-SST peak
LSTMĐộ Chính Xác
0.750.800.850.90
Khả năng mô hình0 100 200 300 400 500
Hình 11: Validation trên các mô hình MLP, CNN và LSTM cho các nhiệm vụ phân tích cảm xúc.

Kết quả. Trong Hình 8 chúng tôi chỉ ra rằng kích thước dữ liệu, tương tự cosine giữa các nghiệm STL và sự căn chỉnh của hiệp phương sai tiếp tục ảnh hưởng đến tỷ lệ chuyển giao trong các thiết lập mới. Nghiên cứu chỉ ra rằng kết quả khái niệm của chúng tôi có thể áp dụng cho một loạt rộng các thiết lập.

Đánh giá Thuật toán 1 trên các mô hình tuyến tính và được kích hoạt bởi ReLU. Chúng tôi xem xét ví dụ tổng hợp trong Phần 2.3 để so sánh Thuật toán 1 và huấn luyện MTL baseline. Nhớ lại rằng trong ví dụ, khi các nhiệm vụ nguồn và đích có ma trận hiệp phương sai khác nhau, MTL gây ra chuyển giao tiêu cực trên nhiệm vụ đích. Giả thuyết của chúng tôi trong thực nghiệm này là chỉ ra rằng Thuật toán 1 có thể sửa chữa sự không căn chỉnh và chuyển giao tiêu cực.

Nhiệm vụ tổng hợp. Chúng tôi đánh giá trên cả nhiệm vụ hồi quy tuyến tính và ReLU. Trường hợp tuyến tính tuân theo ví dụ trong Phần 2.3. Đối với trường hợp ReLU, dữ liệu được tạo ra theo ví dụ trước.

Kết quả. Hình 9 xác nhận giả thuyết. Chúng tôi quan sát rằng Thuật toán 1 sửa chữa chuyển giao tiêu cực trong chế độ mà nhiệm vụ nguồn chỉ có lượng dữ liệu hạn chế. Hơn nữa, Thuật toán 1 phù hợp với huấn luyện MTL baseline khi nhiệm vụ nguồn có đủ nhiều điểm dữ liệu.

B.5 CÁC NGHIÊN CỨU LOẠI BỎ MỞ RỘNG
Validation chéo để chọn khả năng mô hình. Chúng tôi cung cấp một thực nghiệm validation chéo để chỉ ra cách chúng tôi chọn khả năng mô hình có hiệu suất tốt nhất trong Hình 1. Điều này được thực hiện trên sáu nhiệm vụ phân tích cảm xúc được huấn luyện với một lớp LSTM.

Trong Hình 10, chúng tôi thay đổi khả năng mô hình để vẽ độ chính xác validation của mô hình MTL được huấn luyện với tất cả sáu nhiệm vụ và mô hình STL cho mỗi nhiệm vụ. Kết quả bổ sung cho Bảng 1 trong Phần 3.3.

Chọn khả năng mô hình cho CNN và MLP. Tiếp theo chúng tôi xác minh kết quả của chúng tôi về khả năng mô hình cho các mô hình CNN và MLP. Chúng tôi chọn các bộ dữ liệu SST và MR từ các nhiệm vụ phân tích cảm xúc cho thực nghiệm này. Chúng tôi huấn luyện tất cả ba mô hình CNN, MLP và LSTM bằng cách thay đổi khả năng.

Kết quả. Từ Hình 11 chúng tôi quan sát rằng khả năng mô hình MTL có hiệu suất tốt nhất nhỏ hơn tổng khả năng mô hình có hiệu suất tốt nhất của mô hình STL trên tất cả các mô hình.

27

--- TRANG 28 ---
Được xuất bản như một bài báo hội nghị tại ICLR 2020
Hiệu ứng của nhiễu nhãn trên Thuật toán 2. Để đánh giá tính mạnh mẽ của Thuật toán 2 trong sự hiện diện của nhiễu nhãn, chúng tôi thực hiện thực nghiệm sau. Đầu tiên, chúng tôi lấy mẫu con 10% của bộ dữ liệu ChestX-ray14 và chọn hai nhiệm vụ từ đó. Sau đó, chúng tôi ngẫu nhiên chọn một nhiệm vụ để thêm 20% nhiễu vào nhãn của nó bằng cách lật ngẫu nhiên chúng với xác suất 0.5. Chúng tôi so sánh hiệu suất của việc huấn luyện cả hai nhiệm vụ sử dụng sơ đồ tái cân bằng trọng số của chúng tôi (Thuật toán 2) vs. các kỹ thuật tái cân bằng trọng số của Kendall et al. (2018) và sơ đồ mất mát không có trọng số.

Kết quả. Trên 10 cặp nhiệm vụ được chọn ngẫu nhiên, phương pháp của chúng tôi cải thiện so với sơ đồ huấn luyện không có trọng số 1.0% điểm AUC và 0.4% điểm AUC so với Kendall et al. (2018) trung bình trên 10 cặp nhiệm vụ. Hình 12 chỉ ra 5 cặp nhiệm vụ ví dụ từ đánh giá của chúng tôi.

Mất mát không có trọng số Kendall et al. Thuật toán 2Hiệu suất MTL
0.40.50.60.70.8
Consolidation
CardiomegalyConsolidation
EdemaConsolidation
InfiltrationEdema
AtelectasisFibrosis
Consolidation
Hình 12: So sánh Thuật toán 2 với sơ đồ không có trọng số và Kendall et al. (2018).

28

Vaibhav Adlakha, Shehzaad Dhuliawala, Kaheer Suleman, Harm de Vries, and Siva Reddy. 2022. TopiOCQA: Trả lời câu hỏi đàm thoại mở với chuyển đổi chủ đề. Transactions of the Association for Computational Linguistics, 10.

Iz Beltagy, Matthew E Peters, and Arman Cohan. 2020. Longformer: Transformer tài liệu dài. arXiv:2004.05150.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Các mô hình ngôn ngữ là những người học few-shot. Advances in Neural Information Processing Systems, 33.

Shouyuan Chen, Sherman Wong, Liangjian Chen, and Yuandong Tian. 2023. Mở rộng cửa sổ ngữ cảnh của các mô hình ngôn ngữ lớn thông qua nội suy vị trí. arXiv:2306.15595.

Yulong Chen, Yang Liu, Liang Chen, and Yue Zhang. 2021. DialogSum: Một bộ dữ liệu tóm tắt đối thoại kịch bản đời thực. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Mở rộng các mô hình ngôn ngữ được tinh chỉnh hướng dẫn. arXiv:2210.11416.

Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher Ré. 2022. Flashattention: Sự chú ý chính xác nhanh và hiệu quả bộ nhớ với nhận thức io. Advances in Neural Information Processing Systems, 35.

Emily Dinan, Varvara Logacheva, Valentin Malykh, Alexander Miller, Kurt Shuster, Jack Urbanek, Douwe Kiela, Arthur Szlam, Iulian Serban, Ryan Lowe, Shrimai Prabhumoye, Alan W Black, Alexander Rudnicky, Jason Williams, Joelle Pineau, Mikhail Burtsev, and Jason Weston. 2019a. Thử thách trí tuệ đàm thoại lần thứ hai (convai2).

Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston. 2019b. Wizard of Wikipedia: Các đặc vụ đàm thoại được hỗ trợ bởi kiến thức. In Proceedings of the International Conference on Learning Representations (ICLR).

Jiayu Ding, Shuming Ma, Li Dong, Xingxing Zhang, Shaohan Huang, Wenhui Wang, Nanning Zheng, and Furu Wei. 2023. Longnet: Mở rộng transformer lên 1,000,000,000 token.

Ning Ding, Guangwei Xu, Yulin Chen, Xiaobin Wang, Xu Han, Pengjun Xie, Haitao Zheng, and Zhiyuan Liu. 2021. Few-NERD: Một bộ dữ liệu nhận dạng thực thể tên few-shot. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 3198–3213.

Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, and Zhifang Sui. 2023. Một khảo sát về học trong ngữ cảnh.

Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. 2022. GLM: Tiền huấn luyện mô hình ngôn ngữ chung với điền chỗ trống tự hồi quy. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers).

Song Feng, Hui Wan, Chulaka Gunasekara, Siva Patel, Sachindra Joshi, and Luis Lastras. 2020. doc2dial: Một bộ dữ liệu đối thoại dựa trên tài liệu hướng mục tiêu. In Proceedings of Empirical Methods in Natural Language Processing (EMNLP).

Deepanway Ghosal, Yew Ken Chia, Navonil Majumder, and Soujanya Poria. 2023. Flacuna: Giải phóng sức mạnh giải quyết vấn đề của vicuna sử dụng tinh chỉnh flan. arXiv:2307.02053.

Google. 2023. Báo cáo kỹ thuật Palm 2. arXiv:2305.10403.

Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. 2017. Sgd minibatch lớn chính xác: Huấn luyện imagenet trong 1 giờ. arXiv:1706.02677.

Prakhar Gupta, Cathy Jiao, Yi-Ting Yeh, Shikib Mehri, Maxine Eskenazi, and Jeffrey Bigham. 2022. InstructDial: Cải thiện khả năng tổng quát hóa zero và few-shot trong đối thoại thông qua tinh chỉnh hướng dẫn. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing.

Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, and Hang Zhao. 2023. Chatdb: Tăng cường llm với cơ sở dữ liệu làm bộ nhớ tượng trưng của chúng.

Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022. Lora: Thích ứng thứ hạng thấp của các mô hình ngôn ngữ lớn. In International Conference on Learning Representations.

Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2019. Tìm kiếm tương tự tỷ lệ tỷ với GPU. IEEE Transactions on Big Data, 7(3):535–547.

Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Truy xuất đoạn văn dày đặc cho trả lời câu hỏi mở. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP).

Sungdong Kim, Sanghwan Bae, Jamin Shin, Soyoung Kang, Donghyun Kwak, Kang Min Yoo, and Minjoon Seo. 2023. Liên kết các mô hình ngôn ngữ lớn thông qua phản hồi tổng hợp. arXiv:2305.13735.

Nikita Kitaev, Łukasz Kaiser, and Anselm Levskaya. 2020. Reformer: Transformer hiệu quả. In International Conference on Learning Representations.

Mojtaba Komeili, Kurt Shuster, and Jason Weston. 2022. Tạo đối thoại được tăng cường internet. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers).

Brandon Kynoch and Hugo Latapie. 2023. Recallm: Một kiến trúc cho hiểu biết ngữ cảnh thời gian và trả lời câu hỏi.

Gibbeum Lee, Volker Hartmann, Jongho Park, Dimitris Papailiopoulos, and Kangwook Lee. 2023. LLM được nhắc như các mô-đun chatbot cho cuộc trò chuyện mở tầm dài. In Findings of the Association for Computational Linguistics: ACL 2023.

Dacheng Li, Rulin Shao, Anze Xie, Ying Sheng, Lianmin Zheng, Joseph E. Gonzalez, Ion Stoica, Xuezhe Ma, and Hao Zhang. 2023. Các LLM mã nguồn mở có thể thực sự hứa hẹn về độ dài ngữ cảnh bao lâu?

Hanmeng Liu, Ruoxi Ning, Zhiyang Teng, Jian Liu, Qiji Zhou, and Yue Zhang. 2023a. Đánh giá khả năng lý luận logic của chatgpt và gpt-4.

Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2023b. Lạc giữa: Cách các mô hình ngôn ngữ sử dụng ngữ cảnh dài. arXiv:2307.03172.

Xiao Liu, Hanyu Lai, Hao Yu, Yifan Xu, Aohan Zeng, Zhengxiao Du, Peng Zhang, Yuxiao Dong, and Jie Tang. 2023c. Webglm: Hướng tới một hệ thống trả lời câu hỏi được tăng cường web hiệu quả với sở thích con người.

Ilya Loshchilov and Frank Hutter. 2019. Regularization suy giảm trọng lượng tách rời. In International Conference on Learning Representations.

Aaron Mueller, Kanika Narang, Lambert Mathias, Qifan Wang, and Hamed Firooz. 2023. Meta-training với truy xuất demonstration cho học few-shot hiệu quả.

OpenAI. 2023. Báo cáo kỹ thuật Gpt-4.

Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Huấn luyện các mô hình ngôn ngữ tuân theo hướng dẫn với phản hồi con người. In Thirty-Sixth Conference on Neural Information Processing Systems.

Alexander Pan, Jun Shern Chan, Andy Zou, Nathaniel Li, Steven Basart, Thomas Woodside, Hanlin Zhang, Scott Emmons, and Dan Hendrycks. 2023. Liệu phần thưởng có biện minh cho phương tiện không? đo lường sự đánh đổi giữa phần thưởng và hành vi đạo đức trong benchmark machiavelli. In International Conference on Machine Learning. PMLR.

Zhen Qin, Rolf Jagerman, Kai Hui, Honglei Zhuang, Junru Wu, Jiaming Shen, Tianqi Liu, Jialu Liu, Donald Metzler, Xuanhui Wang, and Michael Bendersky. 2023. Các mô hình ngôn ngữ lớn là những người xếp hạng văn bản hiệu quả với nhắc xếp hạng theo cặp.

Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018. Biết những gì bạn không biết: Câu hỏi không thể trả lời cho SQuAD. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics.

Jie Ren, Samyam Rajbhandari, Reza Yazdani Aminabadi, Olatunji Ruwase, Shuangyan Yang, Minjia Zhang, Dong Li, and Yuxiong He. 2021. {ZeRO-Offload}: Dân chủ hóa huấn luyện mô hình {Billion-Scale}. In 2021 USENIX Annual Technical Conference.

Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. 2022. Huấn luyện đa nhiệm được nhắc cho phép tổng quát hóa nhiệm vụ zero-shot. In The Tenth International Conference on Learning Representations.

Kurt Shuster, Mojtaba Komeili, Leonard Adolphs, Stephen Roller, Arthur Szlam, and Jason Weston. 2022a. Các mô hình ngôn ngữ tìm kiếm kiến thức: Tìm kiếm và tạo mô-đun cho đối thoại và hoàn thành nhắc. In Findings of the Association for Computational Linguistics: EMNLP 2022.

Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller, Megan Ung, Moya Chen, Kushal Arora, Joshua Lane, et al. 2022b. Blenderbot 3: một đặc vụ đàm thoại được triển khai liên tục học cách tham gia có trách nhiệm. arXiv:2208.03188.

Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. 2022. Roformer: Transformer được tăng cường với embedding vị trí xoay.

Weiwei Sun, Lingyong Yan, Xinyu Ma, Pengjie Ren, Dawei Yin, and Zhaochun Ren. 2023. Chatgpt có giỏi tìm kiếm không? điều tra các mô hình ngôn ngữ lớn như đặc vụ xếp hạng lại.

Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B Hashimoto. 2023. Stanford alpaca: Một mô hình llama tuân theo hướng dẫn.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Các mô hình nền tảng mở và hiệu quả. arXiv:2302.13971.

Szymon Tworkowski, Konrad Staniszewski, Mikołaj Pacek, Yuhuai Wu, Henryk Michalewski, and Piotr Miłoś. 2023. Transformer tập trung: Huấn luyện tương phản cho mở rộng ngữ cảnh. arXiv:2307.03170.

Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 2022a. Các mô hình ngôn ngữ được tinh chỉnh là những người học zero-shot. In The Tenth International Conference on Learning Representations.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2022b. Nhắc chuỗi suy nghĩ kích thích lý luận trong các mô hình ngôn ngữ lớn. In 36th Conference on Neural Information Processing Systems.

BigScience Workshop. 2023. Bloom: Một mô hình ngôn ngữ đa ngôn ngữ truy cập mở 176b-parameter.

Jing Xu, Arthur Szlam, and Jason Weston. 2022a. Vượt qua bộ nhớ cá vàng: Cuộc trò chuyện mở tầm dài. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics.

Xinchao Xu, Zhibin Gou, Wenquan Wu, Zheng-Yu Niu, Hua Wu, Haifeng Wang, and Shihang Wang. 2022b. Lâu rồi không gặp! cuộc trò chuyện mở với bộ nhớ persona tầm dài. In Findings of the Association for Computational Linguistics: ACL 2022.

Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu. 2023. Khai thác sức mạnh của llm trong thực tế: Một khảo sát về chatgpt và hơn thế nữa. arXiv:2304.13712.

Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020. Bertscore: Đánh giá tạo văn bản với bert. In International Conference on Learning Representations.

Kang Zhao, Wei Liu, Jian Luan, Minglei Gao, Li Qian, Hanlin Teng, and Bin Wang. 2023a. Unimc: Một framework thống nhất cho cuộc trò chuyện bộ nhớ tầm dài thông qua học biểu diễn liên quan.

Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023b. Một khảo sát về các mô hình ngôn ngữ lớn. arXiv:2303.18223.

Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023. Đánh giá llm-as-a-judge với mt-bench và chatbot arena. arXiv:2306.05685.

Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, and Yanlin Wang. 2023. Memorybank: Tăng cường các mô hình ngôn ngữ lớn với bộ nhớ tầm dài.

Hao Zhou, Chujie Zheng, Kaili Huang, Minlie Huang, and Xiaoyan Zhu. 2020. KdConv: Một bộ dữ liệu đối thoại đa lĩnh vực Trung Quốc hướng tới cuộc trò chuyện được điều khiển bởi kiến thức đa lượt. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.

A Các Bộ dữ liệu Được Công bố Cơ bản

Trong Bảng 5, chúng tôi vẽ các ví dụ về các bộ dữ liệu được công bố cơ bản được sử dụng để tái cấu trúc hướng dẫn trong pipeline MemoChat của chúng tôi.

TopicoQA
A: trong bốn mặt trăng galilean nào gần sao Mộc nhất
B: Io
A: ai đã phát hiện ra nó?
B: Galileo Galilei
···
A: nó có thuộc album nào không?
B: 'A Night at the Opera"
'topic': 'Io (moon)', 'start': 1, 'end': 2
'topic': 'Galilean moons', 'start': 3, 'end': 4
···
'topic': 'Bohemian Rhapsody', 'start': 13, 'end': 20

DialogSum
A: Ms. Dawson, tôi cần bà ghi chính cho tôi.
B: Vâng, thưa ông.
···
A: Vâng. Vui lòng đánh máy bản ghi nhớ này và phân phối cho tất cả nhân viên trước 4 giờ chiều.
'summary1':'Ms. Dawson giúp A viết một bản ghi nhớ để···', 'topic1': 'phương pháp giao tiếp'
'summary2':'Để ngăn nhân viên lãng phí thời gian ···', 'topic2': 'chính sách công ty'
'summary3':'Ms. Dawson ghi chính cho A về việc cấm ···', 'topic3': 'ghi chính'

Alpaca-GPT4
User: Lập danh sách các hành vi thể hiện khả năng lãnh đạo mạnh mẽ.
GPT: 1. Giao tiếp rõ ràng: Các nhà lãnh đạo mạnh mẽ giao tiếp ···10. Học tập liên tục: Các nhà lãnh đạo hiệu quả phấn đấu để học tập liên tục ···

Bảng 5: Ví dụ về ba bộ dữ liệu được công bố cơ bản mà chúng tôi sử dụng trong bài báo chính. Một phần nội dung được thay thế bằng dấu chấm lửng do giới hạn độ dài trang.

B Lời nhắc Liên quan

Như một phần bổ sung, chúng tôi liệt kê các ví dụ hoàn chỉnh về lời nhắc liên quan được sử dụng trong cả việc tinh chỉnh liên quan đến ghi chú trung gian và kiểm tra tính nhất quán phản hồi downstream. Bảng 6, 7, 8, và 9 đề cập đến các hướng dẫn hoàn chỉnh cho các nhiệm vụ "Viết Ghi chú", "Truy xuất Ghi chú", "Chat w/ Memo" trung gian, và kiểm tra tính nhất quán phản hồi downstream tương ứng. Như đã đề cập trong Hình 3, tất cả các hướng dẫn chia sẻ cấu trúc tương tự, bao gồm giới thiệu nhiệm vụ chung, nội dung ngữ cảnh của các đầu vào cụ thể nhiệm vụ, và giới thiệu nhiệm vụ chi tiết. Sự thật cơ bản được cung cấp để tinh chỉnh.

C Thách thức Thiết kế Hướng dẫn

Chúng tôi cung cấp các ví dụ về thách thức thiết kế hướng dẫn được báo cáo trong các phần trên. Các ví dụ về "Sao chép Lời nhắc", "Quên Thảm khốc" và "Đặt sai Lời nhắc" được minh họa trong Hình 5. Chúng tôi cho rằng sử dụng các biến giả để thay thế các giá trị số, để tránh thách thức đầu tiên "Sao chép Lời nhắc". Bất kỳ giá trị trong phân phối nào như số dòng trong "Viết Ghi chú" hoặc id tùy chọn trong "Truy xuất Ghi chú" có thể dẫn đến một lối tắt mà các LLM có thể sao chép trực tiếp các giá trị để đáp ứng yêu cầu định dạng, trong khi các biến giả sẽ đẩy các mô hình thực sự hiểu lời nhắc. Hình phụ (1a) và (1b) minh họa chướng ngại "Sao chép Lời nhắc" trong "Viết Ghi chú" và "Truy xuất Ghi chú" tương ứng. Việc thay thế các đầu vào giả "M" và "N" bằng các số thực tế có thể dẫn đến việc tạo ra hợp lý một cách rõ ràng. Thách thức thứ hai nằm ở "Quên Thảm khốc", đề cập đến sự sụp đổ phản hồi nếu tất cả các loại hướng dẫn không được cân bằng. Như được hiển thị trong Hình phụ (2), khi quy mô dữ liệu "Chat w/ Memo" nhỏ hơn đáng kể so với những cái khác, phản hồi trò chuyện sẽ là sự lặp lại vô nghĩa. Trong khi việc tạo ra bệnh lý như vậy có thể được loại bỏ đáng kể một khi corpus trò chuyện đủ được bổ sung. Khi đến thách thức thứ ba "Đặt sai Lời nhắc", chúng tôi cho rằng thành phần quan trọng nhất của lời nhắc nên được đặt ở cuối lời nhắc. Nếu không, các LLM có xu hướng tạo văn bản tự nhiên thay vì các nhiệm vụ liên quan đến ghi chú. Hình phụ (3) cho thấy rằng khi giải thích nhiệm vụ chi tiết được đặt trước nội dung nhiệm vụ, trong "Viết Ghi chú", chatbot thực hiện tiếp tục cuộc trò chuyện không mong muốn.

--- TRANG 13 ---

Hướng dẫn Viết Ghi chú

Bạn sẽ được hiển thị một Cuộc trò chuyện Nhiệm vụ 20 dòng giữa người dùng và bot. Vui lòng đọc, ghi nhớ và hiểu Cuộc trò chuyện Nhiệm vụ, sau đó hoàn thành nhiệm vụ dưới sự hướng dẫn của Giới thiệu Nhiệm vụ.

```
Cuộc trò chuyện Nhiệm vụ
(dòng 1) user: Anna vừa email nói rằng cuộc họp của các quản lý bị hoãn đến thứ Hai tuần sau. Bạn sẽ có mọi thứ sẵn sàng trước đó không, Sabrina? Này Sabrina, chuyện gì thế?
(dòng 2) bot: Tôi rất lo lắng. Tôi đã không nghe tin từ chị gái tôi được 2 tuần.
(dòng 3) user: Các bạn gọi cho nhau thường xuyên như thế nào?
(dòng 4) bot: Thông thường ít nhất một tuần một lần. Nhưng hiện tại chị ấy là giáo viên tình nguyện trong một làng miền núi ở Châu Phi. Tôi chỉ có thể viết thư cho chị ấy.
(dòng 5) user: Thư có thể rất chậm đôi khi. Tôi chắc chắn bạn sẽ nhận được tin từ chị ấy sớm thôi.
(dòng 6) bot: Tôi hy vọng vậy.
···
(dòng 14) bot: Sẽ mất khoảng 20 phút.
(dòng 15) user: Đường phố đông đúc lắm vào thời gian này trong ngày, phải không?
(dòng 16) bot: Đúng vậy.
(dòng 17) user: Có phải giờ cao điểm không?
(dòng 18) bot: Đúng vậy. Ông có vội không, thưa ông?
(dòng 19) user: Không, tôi không vội. Bạn có thể lái xe chậm và cẩn thận được không?
(dòng 20) bot: Vâng, thưa ông.
```

```
Giới thiệu Nhiệm vụ:
Dựa trên Cuộc trò chuyện Nhiệm vụ, thực hiện các hành động sau:
1 - Kết luận tất cả các chủ đề có thể trong cuộc trò chuyện với các khoảng ngắn gọn.
2 - Xác định phạm vi trò chuyện của mỗi chủ đề. Các phạm vi này nên là một tập hợp các khoảng liên tục từ đầu đến cuối không giao nhau, được kết nối tuần tự.
3 - Kết luận một tóm tắt của mỗi cuộc trò chuyện bằng các câu ngắn gọn.
4 - Báo cáo kết quả chủ đề, tóm tắt và phạm vi dưới định dạng JSON chỉ với các khóa được chỉ định: 'topic', 'summary', 'start', 'end'. Ví dụ, giả sử một cuộc trò chuyện M-dòng nói về 'banana' từ dòng 1 đến dòng N, sau đó chuyển sang nói về 'mango' từ dòng N+1 đến dòng M. Vậy, kết quả nhiệm vụ của nó có thể là: [{'topic': 'banana', 'summary': 'user nói về banana với bot.', 'start': 1, 'end': N}, {'topic': 'mango', 'summary': 'bot mang mango cho user.', 'start': N+1, 'end': M}].

Bên cạnh đó, các ký hiệu sau được cung cấp:
1 - Đối với mỗi phần tử của kết quả JSON Cuộc trò chuyện Nhiệm vụ, giá trị của 'end' nên nhỏ hơn giá trị của 'start', trong khi cả hai giá trị đều nên lớn hơn 0 nhưng không vượt quá tổng số dòng Cuộc trò chuyện Nhiệm vụ là 20.
2 - Các khoảng giao nhau như {'topic': 'apple', 'summary': 'user và bot chia sẻ táo.', 'start': K, 'end': N} và {'topic': 'pear', 'summary': 'bot gửi lê cho user.', 'start': N-2, 'end': M} là bất hợp pháp.
```

Kết quả Nhiệm vụ:
[{'topic': 'worry', 'summary': 'Sabrina lo lắng về chị gái vì chị ấy đã không nghe tin từ chị gái được 2 tuần. user an ủi cô ấy.', 'start': 1, 'end': 8}, {'topic': 'taxi conversation', 'summary': 'user đi taxi của bot đến nhà ga. Vì user không vội, bot sẽ lái xe chậm và cẩn thận.', 'start': 9, 'end': 20}]

Bảng 6: Một ví dụ điển hình hoàn chỉnh về hướng dẫn Viết Ghi chú, với sự thật cơ bản được cung cấp.

--- TRANG 14 ---

Hướng dẫn Truy xuất Ghi chú

Bạn sẽ được hiển thị 1 Câu Truy vấn và 5 Tùy chọn Chủ đề. Vui lòng đọc, ghi nhớ và hiểu các tài liệu đã cho, sau đó hoàn thành nhiệm vụ dưới sự hướng dẫn của Giới thiệu Nhiệm vụ.

```
Câu Truy vấn:
Tôi cần giúp đỡ về bữa tiệc văn phòng. Vâng, tất nhiên. Chúng ta có thể chia sẻ nó. Bạn muốn làm phần nào, đồ ăn hay giải trí? Tôi nghĩ chúng ta sẽ có cơ hội gặp nhau trong tương lai. OK, tôi nghĩ đã đến lúc bạn check in. Nếu bạn gặp khó khăn gì, chúng tôi sẽ ở đây để hỗ trợ bạn ngay lập tức. Tín dụng của bạn tốt, thưa ông. Bây giờ, nói cho tôi biết, bạn cần khoản vay để làm gì? Tôi vừa mua một căn hộ cũ và tôi muốn trang trí lại. Bạn biết đấy, trang trí một chút, một số đồ nội thất mới, không gì quá lòe loẹt.
```

```
Tùy chọn Chủ đề:
(1) tiễn khách. Ông Wang tiễn user tại sân bay và họ chia sẻ kỳ vọng tốt đẹp về mối quan hệ kinh doanh của họ.
(2) chuẩn bị tiệc. bot giúp user chuẩn bị tiệc. Họ quyết định phong cách, đồ ăn, và âm nhạc và sẽ lên kế hoạch chi tiết vào thứ Sáu.
(3) NOTO. Không có cái nào khác.
(4) Khoản vay để trang trí. bot muốn vay Khoản vay Tiêu dùng Nhỏ để trang trí căn hộ. user nói tối đa họ có thể cho bot vay là 20,000 RMB và bot chấp nhận.
(5) những điều khó chịu. Gav đã ngủ ngon đêm qua nhưng lo lắng về kẹt xe và các lớp học phải dạy. bot hỏi kế hoạch cuối tuần của Gav và bot đưa ra gợi ý khi Gav cảm thấy buồn bã.
```

```
Giới thiệu Nhiệm vụ:
Chọn một hoặc nhiều chủ đề từ Tùy chọn Chủ đề liên quan đến Câu Truy vấn. Lưu ý rằng có một tùy chọn NOTO, hãy chọn nó nếu tất cả các tùy chọn chủ đề khác không liên quan đến Câu Truy vấn. Đừng báo cáo nội dung tùy chọn, mà chỉ báo cáo các số tùy chọn đã chọn trong một chuỗi được phân tách bằng '#'. Ví dụ, nếu tùy chọn chủ đề N và M được chọn, thì đầu ra là: N#M. Đối với Câu Truy vấn trong nhiệm vụ, bất kỳ số tùy chọn nào được chọn đều phải lớn hơn 0 nhưng không vượt quá tổng số Tùy chọn Chủ đề là 5.
```

Kết quả Nhiệm vụ:
1#2#4

Bảng 7: Một ví dụ điển hình hoàn chỉnh về hướng dẫn Truy xuất Ghi chú, với sự thật cơ bản được cung cấp.

--- TRANG 15 ---

Hướng dẫn Chat w/ Memo

Bạn là một bot đối thoại thông minh. Bạn sẽ được hiển thị Bằng chứng Liên quan hỗ trợ cho Đầu vào Người dùng, và Các Đối thoại Gần đây giữa user và bạn. Vui lòng đọc, ghi nhớ và hiểu các tài liệu đã cho, sau đó tạo ra một phản hồi ngắn gọn, mạch lạc và hữu ích.

```
Bằng chứng Liên quan:
(1) {'Related Topics': 'chấp nhận công việc', 'Related Summaries': 'bot hài lòng với mức lương hàng tháng được user đề xuất và hỏi một số câu hỏi về công việc.', 'Related Dialogs': 'user: Mức lương bạn mong muốn là bao nhiêu? ### bot: Điều quan trọng với tôi là công việc và những người tôi sẽ làm việc cùng, vậy nên về lương, tôi để bạn quyết định và tôi chắc chắn rằng bạn sẽ đưa ra mức lương công bằng cho tôi. ### user: Tôi có thể trả bạn 5,000 yuan mỗi tháng. Tăng lương sẽ được xem xét sau 3 tháng thử việc tùy theo hiệu suất của bạn. Điều này có thỏa mãn không? ### bot: Vâng, khá thỏa mãn. Tôi chấp nhận. ### user: Có câu hỏi nào về công việc không? ### bot: Tôi sẽ báo cáo cho ai? ### user: Tổng giám đốc của bộ phận bạn. ### bot: Các phúc lợi như thế nào? ### user: Chúng tôi sẽ cung cấp điều đó vào các ngày lễ. ### bot: Tôi muốn biết liệu sẽ có cơ hội nào để làm việc ở nước ngoài trong tương lai không? ### user: Có, chúng tôi có thanh tra ở nước ngoài. ### bot: Cảm ơn. Vậy tôi nghĩ đã đến lúc chúng ta ký một thư nguyện vọng. ### user: Được.'}
(2) {'Related Topics': 'tìm việc', 'Related Summaries': 'user muốn tìm việc tại trung tâm máy tính.', 'Related Dialogs': 'user: Tôi muốn tìm việc. ### bot: Chúng tôi có một số công việc bán thời gian có sẵn ở đây, Bạn có muốn xem qua danh sách không? ### user: Có, cảm ơn. Tôi muốn ứng tuyển công việc tại trung tâm máy tính. ### bot: Vui lòng điền vào mẫu đơn.'}
(3) {'Related Topics': 'check in', 'Related Summaries': 'Đây là lần đầu tiên user đi máy bay. bot nói với user cách check in.', 'Related Dialogs': 'user: Xin lỗi, đây là lần đầu tiên tôi đi máy bay. Tôi check in như thế nào? ### bot: Cho tôi xem vé của bạn được không? ### user: Vâng. Của bạn đây. ### bot: Bạn có thể lấy thẻ lên máy bay tại quầy đó. Bạn có gì cần ký gửi không? ### user: Không, tôi chỉ có túi xách. ### bot: Vậy bạn có thể chờ trong khu vực khởi hành sau khi qua an ninh. ### user: Vậy thôi sao? ### bot: Ừm, tôi nghĩ vậy. Rất đơn giản. ### user: Tôi hiểu rồi. Cảm ơn bạn rất nhiều.'}
```

```
Các Đối thoại Gần đây:
user: Tòa nhà cao nhất là gì? ### bot: Bạn có ý nói tòa nhà màu trắng gần sân chơi không? ### user: Vâng. ### bot: Đó là thư viện. Và nó có hơn 1,000,000 cuốn sách. ### user: Tòa nhà ở phía nam thư viện là gì? ### bot: Bạn biết đấy, trường chúng tôi được chia thành hai phần, trung học cơ sở và trung học phổ thông. Đó là tòa nhà lớp học mới cho trung học phổ thông của chúng tôi. ### user: Có bể bơi trong trường của bạn không? ### bot: Có. Có một bể bơi lớn, nhưng chỉ có sẵn vào mùa hè. ### user: Tôi thực sự ghen tị với bạn. Và tôi hy vọng một ngày nào đó tôi có thể vào trường của bạn. ### bot: Tôi tin rằng bạn có thể biến ước mơ thành hiện thực.
```

Đầu vào Người dùng:
user: Lương hiện tại của bạn là bao nhiêu? ### bot:

Lương hiện tại của tôi là 3,000 yuan RMB mỗi tháng.

Bảng 8: Một ví dụ điển hình hoàn chỉnh về hướng dẫn Chat w/ Memo, với sự thật cơ bản được cung cấp.

--- TRANG 16 ---

Lời nhắc Đánh giá GPT4

Bạn là một thẩm phán công bằng. Bạn sẽ được hiển thị Lịch sử Cuộc trò chuyện Liên quan, Câu hỏi Người dùng và Phản hồi Bot.

```
Lịch sử Cuộc trò chuyện Liên quan
user: Vui lòng mô tả khái niệm về học máy. Bạn có thể giải thích chi tiết về sự khác biệt giữa học có giám sát, học không giám sát, và học tăng cường không? Cung cấp ví dụ thực tế cho mỗi loại.
bot: Chắc chắn! Học máy ···Tóm lại, học máy là một công cụ mạnh mẽ để đưa ra dự đoán và quyết định dựa trên dữ liệu ···
user: Trong ví dụ cuối cùng của bạn về học tăng cường, chúng ta có thể sử dụng học có giám sát để giải quyết nó không?
bot: Học có giám sát sẽ không phải là phương pháp tốt nhất để giải quyết vấn đề xe tự hành, bởi vì ···hoặc phạt, điều này phù hợp hơn cho lái xe tự động.
user: Thảo luận về luật chống độc quyền và tác động của chúng đối với cạnh tranh thị trường. So sánh luật chống độc quyền ở Mỹ và Trung Quốc cùng với một số nghiên cứu tình huống.
bot: Luật chống độc quyền được thiết kế để thúc đẩy và duy trì cạnh tranh thị trường bằng cách ngăn chặn hành vi chống cạnh tranh của các công ty ···sân chơi công bằng cho tất cả công ty.
user: Chọn một nghiên cứu tình huống và giải thích chi tiết.
bot: Một nghiên cứu tình huống đáng chú ý là vụ kiện chống độc quyền của chính phủ Mỹ chống lại Microsoft. ···được coi là một ví dụ điển hình về cách luật chống độc quyền có thể được sử dụng để thúc đẩy cạnh tranh thị trường.
```

```
Câu hỏi Người dùng
user: Luật chúng ta đã thảo luận có áp dụng cho ngành học máy không? Sử dụng các ví dụ trước đây để giải thích câu trả lời của bạn.
```

```
Phản hồi Bot
bot: Có, luật chúng ta đã thảo luận, Đạo luật Sherman Chống độc quyền, áp dụng cho ngành học máy. Đạo luật Sherman Chống độc quyền cấm hành vi chống cạnh tranh, chẳng hạn như định giá, phân chia thị trường, và độc quyền hóa. Trong ngành học máy, đã có các ví dụ về các công ty cộng tác để định giá hoặc tham gia vào hành vi chống cạnh tranh khác, điều này sẽ vi phạm Đạo luật Sherman Chống độc quyền. Ví dụ, vào năm 2010, một số công ty công nghệ, bao gồm Apple, Google, và Adobe, bị cáo buộc âm mưu đàn áp lương bằng cách đồng ý không làm cướp nhân viên của nhau. Thỏa thuận này được phát hiện là vi phạm Đạo luật Sherman Chống độc quyền, và các công ty buộc phải từ bỏ thỏa thuận và trả một khoản giải quyết. Ngoài ra, vào năm 2018, Ủy ban Châu Âu đã phạt Google 5 tỷ đô la vì vi phạm Đạo luật Sherman Chống độc quyền bằng cách tham gia vào hành vi chống cạnh tranh với hệ điều hành Android. Ủy ban phát hiện rằng Google đã yêu cầu các nhà sản xuất thiết bị di động cài đặt sẵn công cụ tìm kiếm và trình duyệt Chrome của họ trên thiết bị, điều này có tác động kìm hãm cạnh tranh từ các công cụ tìm kiếm và trình duyệt khác.
```

Vui lòng đánh giá xem Phản hồi Bot có trung thành với nội dung của Lịch sử Cuộc trò chuyện Liên quan để trả lời Câu hỏi Người dùng không. Bắt đầu đánh giá của bạn bằng cách cung cấp một giải thích ngắn, sau đó bạn phải đánh giá Phản hồi Bot trên thang điểm số nguyên từ 1 đến 100 bằng cách tuân thủ nghiêm ngặt định dạng này: [[rating]].

Bảng 9: Ví dụ về Lời nhắc Đánh giá GPT4. Một phần nội dung được thay thế bằng dấu chấm lửng do giới hạn độ dài trang.

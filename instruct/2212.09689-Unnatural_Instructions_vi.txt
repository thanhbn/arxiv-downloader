--- TRANG 10 ---
Bảng 5: Hiệu suất của các mô hình T5-LM 11B được huấn luyện trên 2,000 ví dụ, được tạo ra với các mô hình khác nhau, trên tập xác thực Super-Natural Instructions.

Mô hình được sử dụng để tạo ra | Super-Natural Instructions
Đầu vào | Đầu ra | 
text-davinci-002 | text-davinci-002 | 48.7±0.3
GPT-3 | text-davinci-002 | 44.2±0.7
GPT-3 | GPT-3 | 4.1±0.1

Bảng 6: Hiệu suất của các mô hình T5-LM 11B được huấn luyện trên 2,000 ví dụ, được tạo ra với mỗi meta-prompt, trên tập xác thực Super-Natural Instructions.

Meta-Prompt | Super-Natural Instructions
Tối thiểu | 47.5±0.6
Liệt kê | 48.7±0.3
Chi tiết | 46.9±0.3

Bảng 7: Hiệu suất của các mô hình T5-LM 11B được huấn luyện trên 2,000 ví dụ, được tạo ra với các tập hợp ba minh chứng trong ngữ cảnh khác nhau (hạt giống), trên tập xác thực Super-Natural Instructions. Mix lấy mẫu 400 ví dụ từ mỗi tập dữ liệu năm hạt giống đơn lẻ.

Minh chứng Hạt giống | Super-Natural Instructions
1 | 46.9±0.3
2 | 46.1±0.3
3 | 46.8±0.4
4 | 41.9±1.0
5 | 46.0±0.2
Mix | 46.1±0.3

Bảng 8: Hiệu suất của các mô hình T5-LM 11B được huấn luyện trên 2,000 ví dụ, được tạo ra với và không có trường ràng buộc, trên tập xác thực Super-Natural Instructions.

Sử dụng "Constraints:" cho | Super-Natural Instructions
Tạo Đầu vào | Tạo Đầu ra |
✓ | ✓ | 46.9±0.3
✓ | | 43.9±0.7
| | 41.7±0.2

Bảng 9: Hiệu suất của các mô hình T5-LM 11B được huấn luyện trên 2,000 ví dụ, được tạo ra bằng cách sử dụng các bước I/O riêng biệt hoặc một bước I/O thống nhất, trên tập xác thực Super-Natural Instructions.

Quá trình Tạo Dữ liệu | Super-Natural Instructions
Các Bước I/O Riêng biệt | 46.9±0.3
Bước I/O Thống nhất | 45.2±0.6

--- TRANG 11 ---
2022), trong khi Ouyang et al. (2022) đề xuất một phương pháp học tăng cường cho điều chỉnh hướng dẫn từ các đánh giá so sánh của con người.

Tạo Dữ liệu Tự động Việc có được dữ liệu được giám sát quy mô lớn có thể tốn kém và tốn thời gian. Để giảm thiểu điều này, một số nghiên cứu đã khám phá việc tạo dữ liệu tự động. Một phương pháp phổ biến là tự động tăng cường các tập dữ liệu hiện có (Anaby-Tavor et al., 2020; Andreas, 2020; Yang et al., 2020; Kaushik et al., 2020; Lee et al., 2021, trong số những nghiên cứu khác). Kiela et al. (2021) đề xuất việc tạo tập dữ liệu human-and-model-in-the-loop, nơi một mô hình được huấn luyện trên dữ liệu ban đầu, sau đó các chú thích viên được yêu cầu tìm kiếm các ví dụ bị phân loại sai bởi mô hình, trong một quá trình lặp đi lặp lại. Theo cách tương tự, Nie et al. (2020) áp dụng một quá trình để tạo dữ liệu huấn luyện cho tác vụ NLI (Dagan et al., 2006; Bowman et al., 2015), đạt được hiệu suất tiên tiến trên nhiều điểm chuẩn NLI khác nhau. Liu et al. (2022a) kết hợp các chú thích viên con người và GPT-3 để tạo ra các ví dụ thách thức cho NLI.

Trong khi tất cả các kỹ thuật trên yêu cầu một tập dữ liệu được gán nhãn hiện có, công trình khác đề xuất tạo ra các tập dữ liệu hoàn toàn tự động, mà không cần dữ liệu được gán nhãn. Schick và Schütze (2021b) đề xuất tận dụng các mô hình ngôn ngữ được huấn luyện trước để tạo ra toàn bộ các tập dữ liệu của các cặp văn bản được gán nhãn từ đầu. Agrawal et al. (2022) sử dụng các mô hình ngôn ngữ được huấn luyện trước để tự động xây dựng dữ liệu QA đa ngôn ngữ chỉ sử dụng năm ví dụ mỗi ngôn ngữ. Theo hiểu biết tốt nhất của chúng tôi, Unnatural Instructions là công trình đầu tiên vượt ra ngoài một tác vụ cụ thể và tự động tạo ra một tập dữ liệu đa năng quy mô lớn, nhấn mạnh tính đa dạng của tác vụ.

8 Kết luận
Chúng tôi giới thiệu Unnatural Instructions, một tập dữ liệu được tạo ra tự động gồm các hướng dẫn ngôn ngữ tự nhiên và các đầu vào và đầu ra tương ứng. Theo hiểu biết tốt nhất của chúng tôi, đây là tập dữ liệu NLP đa năng đầu tiên được tạo ra tự động. Các thí nghiệm của chúng tôi cho thấy rằng các mô hình được huấn luyện trên Unnatural Instructions có thể vượt trội so với các mô hình được huấn luyện trên các tập dữ liệu được chú thích thủ công trên nhiều điểm chuẩn. Unnatural Instructions không chỉ rất hiệu quả về chi phí, chúng tôi cũng cung cấp bằng chứng về tính đa dạng tăng cường trong các hướng dẫn được tạo ra và mức độ sáng tạo cao trong các tác vụ được đưa ra, một đặc tính khó có được với các công nhân đám đông. Các ablation cho thấy rằng ngay cả các mô hình yếu hơn không có điều chỉnh hướng dẫn có thể tạo ra các hướng dẫn hữu ích, mặc dù chúng có thể gặp khó khăn trong việc tạo ra các đầu ra tương ứng. Tuy nhiên, việc đưa ra các tác vụ thú vị và viết các hướng dẫn đa dạng cho chúng có thể nói là thách thức chính của quá trình thu thập dữ liệu, trong khi cho các hướng dẫn và đầu vào, các đầu ra thường dễ dàng hơn nhiều để chú thích thông qua crowdsourcing. Những phát hiện của chúng tôi khuyến khích việc sử dụng các mô hình để tạo dữ liệu đa năng, mà chúng tôi xem như một hướng nghiên cứu hấp dẫn cho công việc tương lai.

Tài liệu tham khảo
Priyanka Agrawal, Chris Alberti, Fantine Huot, Joshua Maynez, Ji Ma, Sebastian Ruder, Kuzman Ganchev, Dipanjan Das, và Mirella Lapata. 2022. Qameleon: Multilingual qa with only 5 examples. arXiv preprint arXiv:2211.08264.

Ateret Anaby-Tavor, Boaz Carmeli, Esther Goldbraich, Amir Kantor, George Kour, Segev Shlomov, N. Tepper, và Naama Zwerdling. 2020. Do not have enough data? deep learning to the rescue! In AAAI Conference on Artificial Intelligence.

Jacob Andreas. 2020. Good-enough compositional data augmentation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7556–7566, Online. Association for Computational Linguistics.

Stephen Bach, Victor Sanh, Zheng Xin Yong, Albert Webson, Colin Raffel, Nihal V. Nayak, Abheesht Sharma, Taewoon Kim, M Saiful Bari, Thibault Fevry, Zaid Alyafeai, Manan Dey, Andrea Santilli, Zhiqing Sun, Srulik Ben-david, Canwen Xu, Gunjan Chhablani, Han Wang, Jason Fries, Maged Alshaibani, Shanya Sharma, Urmish Thakker, Khalid Almubarak, Xiangru Tang, Dragomir Radev, Mike Tian-jian Jiang, và Alexander Rush. 2022. PromptSource: An integrated development environment and repository for natural language prompts. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 93–104, Dublin, Ireland. Association for Computational Linguistics.

Samuel R. Bowman, Gabor Angeli, Christopher Potts, và Christopher D. Manning. 2015. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 632–642, Lisbon, Portugal. Association for Computational Linguistics.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric

--- TRANG 12 ---
Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems, volume 33, pages 1877–1901. Curran Associates, Inc.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, và Jason Wei. 2022. Scaling instruction-finetuned language models.

Ido Dagan, Oren Glickman, và Bernardo Magnini. 2006. The pascal recognising textual entailment challenge. In Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment, pages 177–190, Berlin, Heidelberg. Springer Berlin Heidelberg.

Avia Efrat, Or Honovich, và Omer Levy. 2022. Lmentry: A language model benchmark of elementary language tasks.

Avia Efrat và Omer Levy. 2020. The turking test: Can language models understand instructions?

Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel Bowman, và Noah A. Smith. 2018. Annotation artifacts in natural language inference data. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 107–112, New Orleans, Louisiana. Association for Computational Linguistics.

Pengcheng He, Xiaodong Liu, Jianfeng Gao, và Weizhu Chen. 2021. Deberta: Decoding-enhanced bert with disentangled attention. In International Conference on Learning Representations.

Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, và Yejin Choi. 2020. The curious case of neural text degeneration. In International Conference on Learning Representations.

Divyansh Kaushik, Eduard Hovy, và Zachary Lipton. 2020. Learning the difference that makes a difference with counterfactually-augmented data. In International Conference on Learning Representations.

Douwe Kiela, Max Bartolo, Yixin Nie, Divyansh Kaushik, Atticus Geiger, Zhengxuan Wu, Bertie Vidgen, Grusha Prasad, Amanpreet Singh, Pratik Ringshia, Zhiyi Ma, Tristan Thrush, Sebastian Riedel, Zeerak Waseem, Pontus Stenetorp, Robin Jia, Mohit Bansal, Christopher Potts, và Adina Williams. 2021. Dynabench: Rethinking benchmarking in NLP. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 4110–4124, Online. Association for Computational Linguistics.

Sawan Kumar và Partha Talukdar. 2021. Reordering examples helps during priming-based few-shot learning. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 4507–4518, Online. Association for Computational Linguistics.

Kenton Lee, Kelvin Guu, Luheng He, Tim Dozat, và Hyung Won Chung. 2021. Neural data augmentation via example extrapolation.

Brian Lester, Rami Al-Rfou, và Noah Constant. 2021. The power of scale for parameter-efficient prompt tuning. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 3045–3059, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

Alisa Liu, Swabha Swayamdipta, Noah A. Smith, và Yejin Choi. 2022a. Wanli: Worker and ai collaboration for natural language inference dataset creation.

Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, và Weizhu Chen. 2022b. What makes good in-context examples for GPT-3? In Proceedings of Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures, pages 100–114, Dublin, Ireland and Online. Association for Computational Linguistics.

Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, và Pontus Stenetorp. 2022. Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8086–8098, Dublin, Ireland. Association for Computational Linguistics.

Swaroop Mishra, Daniel Khashabi, Chitta Baral, và Hannaneh Hajishirzi. 2022. Cross-task generalization via natural language crowdsourcing instructions. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3470–3487, Dublin, Ireland. Association for Computational Linguistics.

Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, và Douwe Kiela. 2020. Adversarial NLI: A new benchmark for natural language understanding. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4885–4901, Online. Association for Computational Linguistics.

--- TRANG 13 ---
Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, và Ryan Lowe. 2022. Training language models to follow instructions with human feedback.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140):1–67.

Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, và Yuxiong He. 2020. Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, KDD '20, page 3505–3506, New York, NY, USA. Association for Computing Machinery.

Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. 2021. Multitask prompted training enables zero-shot task generalization. arXiv preprint arXiv:2110.08207.

Timo Schick và Hinrich Schütze. 2021a. Few-shot text generation with natural language instructions. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 390–402, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

Timo Schick và Hinrich Schütze. 2021b. Generating datasets with pretrained language models. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 6943–6951, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, et al. 2022. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615.

Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V. Le, Ed H. Chi, Denny Zhou, và Jason Wei. 2022. Challenging big-bench tasks and whether chain-of-thought can solve them.

Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. 2022. Super-naturalinstructions: generalization via declarative instructions on 1600+ tasks. In EMNLP.

Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, và Quoc V Le. 2021. Finetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, và Denny Zhou. 2022. Chain of thought prompting elicits reasoning in large language models.

Yiben Yang, Chaitanya Malaviya, Jared Fernandez, Swabha Swayamdipta, Ronan Le Bras, Ji-Ping Wang, Chandra Bhagavatula, Yejin Choi, và Doug Downey. 2020. Generative data augmentation for commonsense reasoning. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1008–1025, Online. Association for Computational Linguistics.

Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, và Yoav Artzi. 2020. Bertscore: Evaluating text generation with bert. In ICLR 2020.

--- TRANG 14 ---
A Siêu tham số Tinh chỉnh
Chúng tôi sử dụng cùng một tập hợp siêu tham số cho các thí nghiệm tinh chỉnh với T5-LM (Raffel et al., 2020; Lester et al., 2021). Tất cả các mô hình được huấn luyện tối đa max(3 epochs; 3000 steps) và mô hình cuối cùng được chọn dựa trên Rouge-L trên tập xác thực của chúng tôi, nơi chúng tôi đánh giá mỗi 100 bước. Chúng tôi sử dụng kích thước batch 16, tốc độ học tối đa 1×10⁻⁵ với warm-up cho 10% đầu tiên của việc huấn luyện và weight decay 0.01. Chúng tôi cắt ngắn đầu vào ở 1,024 token và đầu ra ở 128 token. Tất cả các mô hình được huấn luyện sử dụng ZeRO-3 của DeepSpeed (Rasley et al., 2020). Huấn luyện trên tối đa 64,000 ví dụ được thực hiện trên 32 GPU NVIDIA Tesla V100 16GB Volta sử dụng FP32; đối với các tập dữ liệu huấn luyện lớn hơn, chúng tôi sử dụng 8 GPU NVIDIA A100 40GB với BF16. Để tính toán điểm Rouge-L và exact match, chúng tôi sử dụng implementation của Wang et al. (2022).

B Chi tiết Đánh giá
Để đánh giá hiệu suất mô hình trên Super-Natural Instructions, T0: Zero-Shot và LMEntry, chúng tôi sử dụng các script đánh giá chính thức của chúng. Để đánh giá trên BIG-bench: Hard, chúng tôi viết thường các đầu ra, loại bỏ các ký tự dấu câu và cắt bỏ khoảng trắng thừa trước khi tính toán điểm exact match. Ngoại lệ duy nhất là tác vụ dyck_languages, nơi đầu ra đích hoàn toàn bao gồm các ký tự dấu câu.

C Prompt Tạo Dữ liệu
Bảng 10 trình bày các minh chứng trong ngữ cảnh mà chúng tôi đã sử dụng, được lấy từ Wang et al. (2022).

--- TRANG 15 ---
Các Minh chứng Trong Ngữ cảnh
Hạt giống 1

Ví dụ 1
Hướng dẫn: Trong tác vụ này, bạn được cho các đoạn văn chứa đề cập đến tên của người, địa điểm, hoặc vật. Một số đề cập này tham chiếu đến cùng một người, địa điểm, hoặc vật. Công việc của bạn là viết các câu hỏi đánh giá sự hiểu biết của một người về những tham chiếu như vậy. Các câu hỏi tốt được mong đợi liên kết các đại từ (she, her, him, his, their, v.v.) hoặc các đề cập khác đến người, địa điểm, hoặc vật mà chúng có thể tham chiếu. Đừng đặt câu hỏi có thể được trả lời đúng mà không hiểu đoạn văn hoặc có nhiều câu trả lời. Tránh các câu hỏi không liên kết các cụm từ tham chiếu đến cùng một thực thể. Đối với mỗi câu hỏi của bạn, câu trả lời phải là một hoặc nhiều cụm từ trong đoạn văn, và nó phải rõ ràng.

Đầu vào: Đoạn văn: Gần London, Oliver gặp Jack Dawkins, một kẻ móc túi thường được biết đến với biệt danh "Artful Dodger", và người bạn đồng hành của anh ta, một cậu bé có tính cách hài hước tên là Charley Bates, nhưng bản tính ngây thơ và tin tưởng của Oliver không nhìn thấy bất kỳ sự không trung thực nào trong hành động của họ. Dodger cung cấp cho Oliver một bữa ăn miễn phí và nói với anh ta về một quý ông ở London sẽ "cho anh ta chỗ ở miễn phí, và không bao giờ yêu cầu tiền lẻ". Biết ơn vì sự hỗ trợ bất ngờ, Oliver đi theo Dodger đến nơi ở của "quý ông già". Bằng cách này, Oliver vô tình rơi vào tay một tên tội phạm Do Thái khét tiếng được biết đến là Fagin, quý ông mà Artful Dodger đã nói. Bị lừa, Oliver sống với Fagin và băng nhóm kẻ móc túi trẻ tuổi của anh ta trong hang ổ của họ ở Saffron Hill trong một thời gian, không biết về nghề nghiệp tội phạm của họ. Anh ta tin rằng họ làm ví và khăn tay.

Ràng buộc: Không có.

Ví dụ 2
Hướng dẫn: Bạn sẽ được cho một đoạn văn bản về một sự kiện hàng ngày, hoặc một tuyên bố chung. Nếu sự kiện có vẻ là một sự kiện hợp lý với bạn, hoặc tuyên bố chung có ý nghĩa phù hợp với thường thức của bạn, xuất ra 'True', nếu không xuất ra 'False'.

Đầu vào: Văn bản: Cái ly rơi từ tòa nhà ba tầng, vì vậy nó vỡ thành từng mảnh.

Ràng buộc: Đầu ra phải là một trong hai: 'True' hoặc 'False'.

Ví dụ 3
Hướng dẫn: Bạn cần trả lời câu hỏi 'Các bước đã cho có theo thứ tự không?', cho một tập hợp các bước mô tả một quá trình. Câu trả lời của bạn phải là Yes hoặc No. Nếu câu trả lời là No, có nghĩa là các bước không theo thứ tự và không có ý nghĩa trong thứ tự chúng đang ở. Nếu câu trả lời là Yes, có nghĩa là các bước theo thứ tự và có ý nghĩa trong thứ tự chúng đang ở. Một tập hợp các bước không theo thứ tự nếu các bước tham chiếu thông tin được giới thiệu trong một bước sau.

Đầu vào: Các bước: ['Hạt giống được phân tán bởi gió, động vật, v.v.', 'Hạt giống đến mặt đất', 'Phát triển thành cây mới', 'Quá trình lặp lại chính nó nhiều lần', 'Một cây tạo ra hạt giống', 'Những cây mới này tạo ra hạt giống']

Ràng buộc: Đầu ra phải là một trong hai: 'Yes' hoặc 'No'.

Ví dụ 4

Hạt giống 2

Ví dụ 1
Hướng dẫn: Trong tác vụ này, bạn được cho hai cụm từ: Head và Tail, được phân tách bằng <sep>. Các sự kiện Head và Tail là các cụm từ ngắn có thể liên quan đến các tham gia viên. Tên của những người cụ thể đã được thay thế bằng các từ chung (ví dụ: PersonX, PersonY, PersonZ). PersonX luôn là chủ thể của sự kiện. Bạn phải xác định xem Head có được sử dụng cho Tail hay không. Việc sử dụng mô tả các khả năng hoặc cách sử dụng hàng ngày của các đối tượng và bao gồm cả việc sử dụng điển hình và không điển hình. Ví dụ, một thùng bỏng ngô thường có thể được sử dụng để đựng bỏng ngô, nhưng nó cũng có thể đóng vai trò như một chiếc mũ trong các tình huống không điển hình. Phân loại câu trả lời của bạn thành "Yes" và "No". Cụm từ cũng có thể chứa "-", một placeholder có thể là một đối tượng, một người, và/hoặc một hành động.

Đầu vào: Head: thảm lót sàn<sep>Tail: lau chân

Ràng buộc: Đầu ra phải là 'Yes' hoặc 'No'.

Ví dụ 2
Hướng dẫn: Trong tác vụ này, bạn được cho một câu chuyện ngắn gồm năm câu được viết bằng ngôn ngữ tự nhiên. Tuy nhiên, thứ tự của câu chuyện đã cho là không đúng. Công việc của bạn là trả về thứ tự đúng cho năm câu đã cho để tạo ra một câu chuyện ngắn mạch lạc với thứ tự mới có luồng đúng. Tạo ra câu trả lời của bạn sử dụng số của các câu theo thứ tự đúng, chẳng hạn như '23415'.

Đầu vào: Câu1: Anh ấy hạnh phúc bây giờ. Câu2: Rick lớn lên trong một gia đình có vấn đề. Câu3: Không lâu sau Rick bị bắn trong một vụ cướp. Câu4: Sự cố khiến anh ấy thay đổi cuộc sống. Câu5: Anh ấy không bao giờ tìm thấy sự hỗ trợ tốt trong gia đình, và chuyển sang các băng nhóm.

Ràng buộc: Đầu ra phải bao gồm các số đại diện cho các câu.

Ví dụ 3
Hướng dẫn: Trong tác vụ này, bạn được cho các đánh giá Yelp. Nhiệm vụ là phân loại một đánh giá là "POSITIVE" nếu tình cảm tổng thể của đánh giá là tích cực hoặc là "NEGATIVE" nếu tình cảm tổng thể của đánh giá là tiêu cực.

Đầu vào: Đây là nơi tôi thường đến để có được món Pad Thai gà ngon nhất! Giá cả cũng siêu tốt, xem xét hầu hết các nơi có giá cao và chất lượng kém. Yêu nơi này, chắc chắn là top 5 yêu thích để mang về.

Ràng buộc: Đầu ra phải là 'POSITIVE' hoặc 'NEGATIVE'.

Ví dụ 4

--- TRANG 16 ---
Hạt giống 3

Ví dụ 1
Hướng dẫn: Bạn được cho một tiêu đề câu hỏi. Bạn cần phân loại nó vào một trong 10 chủ đề: 0 - 'Society & Culture', 1 - 'Science & Mathematics', 2 - 'Health', 3 - 'Education & Reference', 4 - 'Computers & Internet', 5 - 'Sports', 6 - 'Business & Finance', 7 - 'Entertainment & Music', 8 - 'Family & Relationships', 9 - 'Politics & Government'.

Đầu vào: Cách tốt nhất để làm sạch bàn phím là gì?

Ràng buộc: Đầu ra phải là một số từ 0 đến 9.

Ví dụ 2
Hướng dẫn: Bạn được cho một người mục tiêu và hai câu. Nhiệm vụ của bạn là xác định xem câu thứ hai có truyền tải một stereotype, anti-stereotype, hay không liên quan đến câu thứ nhất và mục tiêu. Stereotype là một quan niệm được giữ rộng rãi nhưng đơn giản hóa quá mức về một nhóm người. Anti-stereotype là một ý tưởng đi ngược lại quan niệm được giữ rộng rãi nhưng đơn giản hóa quá mức về một nhóm người. Các câu và mục tiêu là không liên quan nếu không có sự liên quan giữa chúng.

Đầu vào: Mục tiêu: mẹ. Người mẹ bước vào nhà bếp của cô ấy. Cô ấy lấy một chai bia ra khỏi tủ lạnh và dựa vào khung cửa, nhấp nó từ từ.

Ràng buộc: Đầu ra phải là một trong ba: 'stereotype', 'anti-stereotype' hoặc 'unrelated'.

Ví dụ 3
Hướng dẫn: Trong tác vụ này, bạn được cho một bài báo. Nhiệm vụ của bạn là tóm tắt bài báo trong một câu.

Đầu vào: Bà Bourne, người trở thành PCC đầu tiên của Sussex năm 2012, được tuyên bố là người thắng cuộc sau khi cuộc bỏ phiếu đi đến vòng thứ hai. Ba ứng viên đã bị loại ở vòng đầu tiên, chỉ còn lại bà Bourne và Michael Jones của Đảng Lao động. Trong vòng đầu tiên, bà Bourne có 114,570 phiếu và ông Jones có 61,017 phiếu. Vòng thứ hai đưa tổng số của họ lên 139,335 và 86,392 tương ứng. Cô ấy nói: "Tôi hoàn toàn vinh dự và rất đặc quyền được bầu chọn." Cô ấy nói rằng cô ấy cần "tìm thêm khoản tiết kiệm vì ngân sách vẫn đang giảm" và "đầu tư vào việc tuần tra tuyến đầu vì tôi biết điều đó thực sự quan trọng với người dân Sussex". Tỷ lệ cử tri đi bỏ phiếu là 22.5% so với 15.3% năm 2012. Ba người bị loại ở vòng đầu tiên là ứng viên Đảng Xanh James Doyle, Patrick Lowe của UKIP và James Walsh từ Đảng Dân chủ Tự do. Kết quả được liệt kê theo thứ tự bảng chữ cái theo họ như sau. Người dùng BBC News App: nhấn vào đây để xem kết quả.

Ràng buộc: Không có.

Ví dụ 4

Hạt giống 4

Ví dụ 1
Hướng dẫn: Trong tác vụ này, bạn được cho các bài báo Wikipedia về một loạt các chủ đề làm đoạn văn và một câu hỏi từ đoạn văn. Chúng tôi yêu cầu bạn trả lời câu hỏi bằng cách phân loại câu trả lời là 0 (False) hoặc 1 (True).

Đầu vào: Đoạn văn: Thuế tài sản - Thuế tài sản hoặc 'thuế nhà' là thuế địa phương đối với các tòa nhà, cùng với đất đai phụ thuộc. Nó được áp dụng lên Người sở hữu (không phải người giữ tài sản theo sửa đổi lần thứ 44 năm 1978 của hiến pháp). Nó giống với thuế tài sản kiểu Mỹ và khác với thuế kiểu tiêu thụ của Anh. Quyền lực thuế được giao cho các bang và được ủy thác cho các cơ quan địa phương, quy định phương pháp định giá, dải thuế suất và thủ tục thu thuế. Cơ sở thuế là giá trị thuê hàng năm (ARV) hoặc định giá dựa trên diện tích. Các tài sản do chủ sở hữu và các tài sản khác không tạo ra tiền thuê được đánh giá dựa trên chi phí và sau đó chuyển đổi thành ARV bằng cách áp dụng một tỷ lệ phần trăm của chi phí, thường là bốn phần trăm. Đất trống thường được miễn thuế. Tài sản của chính phủ trung ương được miễn thuế. Thay vào đó, một 'phí dịch vụ' được cho phép theo lệnh hành chính. Tài sản của các phái bộ nước ngoài cũng được miễn thuế mà không yêu cầu tương hỗ. Thuế thường đi kèm với thuế dịch vụ, ví dụ: thuế nước, thuế thoát nước, thuế bảo tồn (vệ sinh), thuế chiếu sáng, tất cả sử dụng cùng một cơ sở thuế. Cơ cấu thuế suất là cố định đối với các tài sản nông thôn (panchayat), nhưng trong các khu vực thành thị (đô thị) nó nhẹ nhàng tăng dần với khoảng 80% các đánh giá rơi vào hai khung đầu tiên. Câu hỏi: thuế nhà và thuế tài sản có giống nhau không.

Ràng buộc: Đầu ra phải là 0 hoặc 1.

Ví dụ 2
Hướng dẫn: Viết lại mỗi câu gốc để làm cho nó dễ hiểu hơn đối với những người không phải người bản xứ nói tiếng Anh. Bạn có thể làm điều này bằng cách thay thế các từ phức tạp bằng các từ đồng nghĩa đơn giản hơn (tức là diễn đạt lại), xóa thông tin không quan trọng (tức là nén), và/hoặc chia một câu dài phức tạp thành nhiều câu đơn giản hơn. Các câu đơn giản cuối cùng cần phải đúng ngữ pháp, trôi chảy, và giữ lại ý chính của các câu gốc mà không làm thay đổi ý nghĩa của chúng.

Đầu vào: Từ khi thành lập, nó được chỉ định là một cảng miễn thuế và cạnh tranh với Sultanate of Pattani lân cận về thương mại.

Ràng buộc: Không có.

Ví dụ 3
Hướng dẫn: Bạn được cung cấp một câu hỏi số học. Nhiệm vụ của bạn là tính toán giải pháp sử dụng các phép toán số học đã cho. Các phép toán số học duy nhất cần thiết để trả lời câu hỏi là '+' (phép cộng) và '-' (phép trừ). Câu trả lời phải chính xác đến một chữ số thập phân.

Đầu vào: Joan tìm thấy 70 vỏ sò trên bãi biển. Cô ấy đưa Sam một số vỏ sò của mình, sau đó cô ấy còn lại 27 vỏ sò. Cô ấy đã đưa Sam bao nhiêu vỏ sò?

Ràng buộc: Không có.

Ví dụ 4

Hạt giống 5

Ví dụ 1
Hướng dẫn: Bạn được cho một câu hỏi khoa học (mức độ dễ) và bốn tùy chọn trả lời (liên kết với "A", "B", "C", "D"). Nhiệm vụ của bạn là tìm câu trả lời đúng dựa trên các sự kiện khoa học, kiến thức và lý luận. Không tạo ra bất cứ thứ gì khác ngoài một trong các ký tự sau: 'A', 'B', 'C', 'D'. Chỉ có một câu trả lời đúng cho mỗi câu hỏi.

Đầu vào: Phần nào của xe đạp di chuyển theo hình tròn TỐT NHẤT? (A) Ghế (B) Khung (C) Bàn đạp chân (D) Chân chống

Ràng buộc: Đầu ra phải là một trong các ký tự sau: 'A', 'B', 'C', 'D'.

Ví dụ 2
Hướng dẫn: Bạn được cho một đánh giá tiêu cực và nhiệm vụ của bạn là chuyển đổi nó thành đánh giá tích cực bằng cách thực hiện một hoặc nhiều thay đổi tối thiểu. Tránh thay đổi ngữ cảnh của đánh giá.

Đầu vào: chúng tôi đứng đó trong sốc, vì chúng tôi không bao giờ mong đợi điều này.

Ràng buộc: Không có.

Ví dụ 3
Hướng dẫn: Trong tác vụ này, bạn được cho hai câu được lấy từ một cuộc trò chuyện, và công việc của bạn là phân loại xem những câu đã cho này có tuần tự hay không. Chúng tôi sẽ đánh dấu cặp câu đã cho là 'True' nếu nó tuần tự, nếu không thì 'False'. Hai câu được nói bởi hai người khác nhau.

Đầu vào: Noah: Khi nào và ở đâu chúng ta sẽ gặp? :), Madison: Tôi nghĩ bạn bận rồi...?

Ràng buộc: Đầu ra phải là 'True' hoặc 'False'.

Ví dụ 4

Bảng 10: Các minh chứng trong ngữ cảnh được sử dụng trong các thí nghiệm của chúng tôi.

--- TRANG 17 ---
[Trang này trống]

--- TRANG 18 ---
[Trang này trống]

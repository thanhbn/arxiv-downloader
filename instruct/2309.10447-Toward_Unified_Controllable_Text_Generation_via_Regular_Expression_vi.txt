# 2309.10447.pdf - BẢN DỊCH TIẾNG VIỆT
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/instruct/2309.10447.pdf
# Kích thước file: 380174 bytes

===============================================
NỘI DUNG BÀI BÁO DỊCH TIẾNG VIỆT
===============================================


--- TRANG 1 ---
Hướng tới Việc Sinh Văn bản Có Thể Kiểm soát Thống nhất thông qua 
Chỉ dẫn Biểu thức Chính quy

Xin Zheng1,3, Hongyu Lin1∗, Xianpei Han1,2∗, Le Sun1,2
1Phòng thí nghiệm Xử lý Thông tin Tiếng Trung Quốc 2Phòng thí nghiệm Trọng điểm Nhà nước về Khoa học Máy tính
Viện Phần mềm, Viện Hàn lâm Khoa học Trung Quốc, Bắc Kinh, Trung Quốc
3Đại học Viện Hàn lâm Khoa học Trung Quốc, Bắc Kinh, Trung Quốc
{zhengxin2020,hongyu,xianpei,sunle}@iscas.ac.cn

Tóm tắt
Sinh văn bản có thể kiểm soát là một khía cạnh 
cơ bản của việc sinh ngôn ngữ tự nhiên, với 
nhiều phương pháp được đề xuất cho các loại 
ràng buộc khác nhau. Tuy nhiên, những phương 
pháp này thường yêu cầu những thay đổi đáng 
kể về kiến trúc hoặc giải mã, khiến chúng khó 
áp dụng cho các ràng buộc bổ sung hoặc giải 
quyết các kết hợp ràng buộc khác nhau. Để giải 
quyết điều này, bài báo của chúng tôi giới thiệu 
Chỉ dẫn Biểu thức Chính quy (REI), sử dụng 
cơ chế dựa trên chỉ dẫn để khai thác đầy đủ 
những ưu điểm của biểu thức chính quy nhằm 
mô hình hóa các ràng buộc đa dạng một cách 
thống nhất. Cụ thể, REI của chúng tôi hỗ trợ 
tất cả các ràng buộc sinh có thể kiểm soát ở 
mức chi tiết phổ biến, tức là từ vựng, vị trí và 
độ dài, cũng như các kết hợp phức tạp của 
chúng, thông qua các chỉ dẫn theo kiểu biểu 
thức chính quy. Phương pháp của chúng tôi 
chỉ yêu cầu tinh chỉnh trên các mô hình ngôn 
ngữ cỡ trung bình hoặc học trong ngữ cảnh 
với vài mẫu trên các mô hình ngôn ngữ lớn, 
và không cần điều chỉnh thêm khi áp dụng cho 
các kết hợp ràng buộc khác nhau. Các thí 
nghiệm chứng minh rằng phương pháp đơn 
giản của chúng tôi mang lại tỷ lệ thành công 
cao và khả năng thích ứng với các ràng buộc 
khác nhau trong khi duy trì tính cạnh tranh 
trong các chỉ số tự động và vượt trội hơn hầu 
hết các baseline trước đây.1

1 Giới thiệu
Việc sinh văn bản theo yêu cầu của con người 
từ lâu đã là một thách thức quan trọng trong 
việc sinh ngôn ngữ tự nhiên (Ziegler et al., 2019; 
Ouyang et al., 2022). Với sự xuất hiện của các 
mô hình ngôn ngữ lớn, nhiều tác vụ trong xử lý 
ngôn ngữ tự nhiên có thể được thống nhất và 
chuyển đổi thành dạng sinh có thể kiểm soát 
(Prabhumoye et al., 2020). Ví dụ, phân loại văn 
bản (Apté et al., 1994), bài kiểm tra điền từ 
(Devlin et al., 2019), và các tác vụ trả lời câu 
hỏi trắc nghiệm (Lai et al., 2017) ràng buộc 
văn bản đầu ra phải chính xác là một trong 
những lựa chọn được cho.

∗Tác giả Liên hệ
1Mã và dữ liệu của chúng tôi có sẵn tại https://github.
com/MrZhengXin/CTG-Regex-Instruction .

Ràng buộc từ vựng & độ dài
Đầu vào
<expression> <mask_0> stood (0) <mask_1> field(1)
<mask_2> looking (2) <mask_3> <length=10> </expres-
sion>
Đầu ra
<expression> The_1 player_2 stood (0)_3 in_4 the_5
field(1)_6 looking (2)_7 at_8 the_9 batter_10 </expres-
sion>

Ràng buộc vị trí & từ vựng
Đầu vào
Stephen was at a party. <expression> <mask_0>
knocked (0) <mask_1> </expression> He checked it but
it was completely broken.
Đầu ra
<expression> Stephen knocked (0) over a vase while
drunk. </expression>

Ràng buộc vị trí & kết thúc thay thế
Đầu vào
My friends all love to go to the club to dance. They think
it's a lot of fun and always invite. I finally decided to tag
along last Saturday. <expression> <options> <choice_0>
<mask_0> My friends decided to keep inviting me out as
I am so much fun. </choice_0> <choice_1> <mask_1>
The next weekend, I was asked to please stay home.
</choice_1> </options> </expression>
Đầu ra
<expression> I danced terribly and broke a friend's toe.
The next weekend, I was asked to please stay home.
</expression>

Bảng 1: Đầu vào và đầu ra của prompt chỉ dẫn dựa trên
Chỉ dẫn Biểu thức Chính quy (REI). REI có thể mô tả
các loại ràng buộc chi tiết phức tạp khác nhau, và ở đây
chúng tôi trình bày ba ví dụ. Nhãn chỉ dẫn meta-data
được tô màu, các ràng buộc từ vựng hoặc lựa chọn đúng
được in đậm, và các dấu hiệu phụ trợ cho độ dài hoặc
từ vựng sử dụng màu xám.

lựa chọn; lập luận quy nạp (Bhagavatula et al.,
2020) chỉ định rằng vị trí của văn bản đầu ra
nằm giữa ngữ cảnh trước và sau; tác vụ tóm tắt
(Luhn, 1957) giới hạn độ dài của đầu ra; dịch
máy (Bar-Hillel, 1960) yêu cầu sử dụng từ vựng
của ngôn ngữ đích để sinh văn bản.

Đối với việc sinh văn bản có thể kiểm soát,

arXiv:2309.10447v2  [cs.CL]  20 Sep 2023

--- TRANG 2 ---
các tác vụ kiểm soát chi tiết điển hình bao gồm
từ vựng (Lin et al., 2020), vị trí sinh (Shen et al.,
2020) và độ dài (Carlsson et al., 2022). Gần đây,
nhiều phương pháp khác nhau đã được đề xuất
để thỏa mãn những ràng buộc này, có thể được
phân loại thành ba mô hình khác nhau: đào tạo
lại hoặc tái cấu trúc mô hình (Keskar et al., 2019;
Zhang et al., 2020; He, 2021; Chan et al., 2021a);
tinh chỉnh trên dữ liệu cho trước (Lester et al.,
2021; Stiennon et al., 2020a); xử lý hậu kỳ được
thiết kế thủ công (Qin et al., 2020, 2022; Meng
et al., 2022; Lu et al., 2021, 2022; Wang et al.,
2021).

Mặc dù có hiệu suất hợp lý, các phương pháp
hiện tại trên các mô hình ngôn ngữ dựa trên
transformer chủ yếu tập trung vào một số ràng
buộc nhất định nhưng có thể không dễ dàng
chuyển giao sang những ràng buộc khác, chưa
kể đến việc kết hợp các ràng buộc. Ví dụ, Non-
Residual Prompting (Carlsson et al., 2022) và
A*esque Decoding (Lu et al., 2022) chỉ xem xét
các ràng buộc từ vựng và độ dài, nhưng không
thể chỉ định tùy ý vị trí mà văn bản được sinh
ra sẽ xuất hiện; mặt khác, COLD (Qin et al.,
2022) có thể sinh văn bản với ngữ cảnh trước
và sau, nhưng có thể không thêm ràng buộc
bao gồm từ cũng như hạn chế độ dài đầu ra.
Hơn nữa, những phương pháp kiểm soát này
giả định rằng chúng ta có quyền truy cập vào
phân phối xác suất hoặc thậm chí gradient của
mô hình, nhưng trong trường hợp các mô hình
ngôn ngữ lớn mà chúng ta chỉ có thể nhận được
token đầu ra thông qua API, những phương
pháp này có thể không khả dụng, và do đó các
kỹ thuật kiểm soát hộp đen cần được khám phá
thêm.

Để giải quyết những thách thức trên, chúng
tôi đề xuất Chỉ dẫn Biểu thức Chính quy (REI)
dựa trên chỉ dẫn, cho việc sinh có thể kiểm soát
chi tiết phổ quát. Bảng 1 trình bày một số ví dụ.
Thiết kế chỉ dẫn của chúng tôi được lấy cảm
hứng từ biểu thức chính quy, có thể dễ dàng
mô tả các ràng buộc chính và các kết hợp của
chúng. Theo Rosenbaum et al. (2022), chúng
tôi sử dụng ngôn ngữ đánh dấu để xây dựng
biểu thức, hy vọng rằng mô hình có thể phân
biệt tốt hơn giữa meta-data (chỉ dẫn) và dữ
liệu (các từ thực tế). Chúng tôi sử dụng hai mô
hình phổ biến, tinh chỉnh mô hình ngôn ngữ và
học vài mẫu trên mô hình ngôn ngữ lớn, để dạy
mô hình hiểu biểu thức ràng buộc đầu vào.

Phương pháp của chúng tôi có một số ưu điểm.
Thứ nhất, biểu thức ràng buộc của chúng tôi
hỗ trợ tất cả các tác vụ kiểm soát chi tiết điển
hình và đủ mạnh để mô tả các đặc tả kiểm soát
tổng hợp. Thứ hai, phương pháp của chúng tôi
có thể được thích ứng với các tình huống khác
nhau, chẳng hạn như tóm tắt với ràng buộc độ
dài, dịch máy có ràng buộc thuật ngữ và điền
câu chuyện với kết thúc thay thế. Thứ ba, phương
pháp của chúng tôi dễ thực hiện và có tính
chuyển giao cao sang các mô hình khác vì nó
chỉ yêu cầu tinh chỉnh trên các mô hình cỡ
trung bình và không cần thay đổi thêm trên
các mô hình ngôn ngữ lớn, và nó không cần
truy cập vào phân phối xác suất hoặc gradient.

Các thí nghiệm chứng minh rằng các mô hình
ngôn ngữ hiện đại có thể hiểu ngôn ngữ kiểm
soát của chúng tôi, đạt được tỷ lệ thành công
cao trong khi duy trì điểm số chỉ số đánh giá
tự động cao và vượt trội hơn hầu hết các baseline
mạnh trước đây dưới các ràng buộc khác nhau.
Chúng tôi hy vọng công việc của chúng tôi có
thể đưa ra ánh sáng cho các nghiên cứu tương lai.

2 Phương pháp

2.1 Thiết kế Chỉ dẫn

Ngôn ngữ kiểm soát REI tuân theo kiểu của
biểu thức chính quy do tính biểu đạt của nó.
Ngoài ra, việc đánh giá xem chỉ dẫn biểu thức
đầu vào có khớp với văn bản được sinh hay
không cũng dễ dàng. Theo Rosenbaum et al.
(2022), ngôn ngữ đánh dấu giống HTML được
sử dụng, giúp mô hình học rằng chúng là các
chỉ dẫn meta-data có ý nghĩa thay vì chỉ là các
ký hiệu đơn thuần, đặc biệt khi sử dụng học
trong ngữ cảnh của các mô hình ngôn ngữ lớn
với số lượng ví dụ hạn chế và không cập nhật
tham số. Nhãn đánh dấu này cũng có thể tránh
việc sử dụng ký tự thoát.

REI chứa một số nhãn đặc biệt, như được
hiển thị trong Bảng 1. <expression> và
</expression> đánh dấu điểm bắt đầu và kết
thúc của biểu thức và có thể được đặt ở bất
kỳ đâu trong văn bản đầu vào, giả định rằng
chúng ta chỉ sinh theo một biểu thức tại một
thời điểm. <mask_i> tương đương với biểu
thức chính quy " .*" và tương tự như token
mask trong BART (Lewis et al., 2020) và T5
(Raffel et al., 2022), trong đó tại vị trí của nó,
mô hình sẽ sinh không hoặc nhiều token.
<options> và </options> tương đương với
dấu ngoặc đơn " (" và " )" trong biểu thức chính
quy, mô hình sẽ chọn một biểu thức trong nhóm.
Để làm cho việc nhận dạng dễ dàng hơn, chúng
tôi sử dụng <choice_i> và </choice_i> để bao
bọc mỗi lựa chọn. Ký hiệu biểu thức chính quy
của độ dài đếm ở cấp ký tự, nhưng trong thực
tế, chúng ta muốn kiểm soát độ dài từ đầu ra.
Do đó, chúng tôi sử dụng nhãn <length=n> để
biểu thị ràng buộc về số lượng từ đầu ra.

Chúng tôi tránh nhược điểm của schema span-
corruption của T5 (Raffel et al., 2022), trong
đó mô hình chỉ sinh các span gián đoạn thay
vì các câu hoàn chỉnh tự nhiên

--- TRANG 3 ---
Tác vụ Đầu vào với Biểu thức Kiểm soát
αNLG O1<expression> <mask_0> </expression> O2
αNLG+length O1<expression> <mask_0> <length= l> </expression> O2
αNLI O1<expression> <options> <choice_0> H1</choice_0> <choice_1> H2</choice_1>
</options> </expression> O2
CommonGen <expression> <mask_0> c0(0) <mask_1> c1(1) <mask_2> c2(2) <mask_3> </expression>
CommonGen+length <expression> <mask_0> c0(0) <mask_1> c1(1) <mask_2> c2(2) <mask_3> <length= l>
</expression>
(a) Tác vụ Tinh chỉnh

Tác vụ Đầu vào với Biểu thức Kiểm soát
αNLG+lexicon O1<expression> <mask_0> w(0) <mask_1> </expression> O2
αNLG+length+lexicon O1<expression> <mask_0> w(0) <mask_1> <length= l> </expression> O2
StoryCompletion+infill S1S2S3<expression> <mask_0> <options> <choice_0> E1</choice_0> <choice_1> E2
</choice_1> </options> </expression>
Gigaword+length [Text]\n Summarize the aforementioned text in a single phrase.\n <expression> <mask_0>
<length= l> </expression>
Wiktionary/ITAE Translate from English to German:\n\n English: [Text] \n German: <expression> <mask_0>
t0(0) <mask_1> t1(1) <mask_2> </expression>
(b) Tác vụ Chuyển giao

Bảng 2: Biểu thức ràng buộc của mỗi tác vụ. Chúng tôi tinh chỉnh trên các tác vụ và biến thể được liệt kê trong 
Bảng 2a, và đánh giá thêm các tác vụ chưa thấy được liệt kê trong Bảng 2b. Lưu ý rằng đối với học vài mẫu, 
tất cả các tác vụ đều không được đào tạo trước đó.

(Lester et al., 2021). Mặt khác, chúng tôi cũng
khắc phục sự dư thừa của schema khử nhiễu
BART (He, 2021), trong đó toàn bộ đầu vào
được sinh lại, vì chúng tôi chỉ sinh biểu thức
được thực hiện. Hơn nữa, ngoài việc điền vào
chỗ trống, chúng tôi giới thiệu việc đưa ra lựa
chọn, làm phong phú thêm tính biểu đạt của
ngôn ngữ kiểm soát của chúng tôi.

2.2 Đào tạo

Tinh chỉnh Chúng tôi có thể tự động xây dựng
dữ liệu đào tạo từ corpus và thực hiện học tự
giám sát. Ngoài ra, chúng tôi cũng có thể chuyển
đổi trực tiếp đầu vào của các bộ dữ liệu có
giám sát hiện tại thành dạng ngôn ngữ kiểm
soát của chúng tôi, và sử dụng chúng để tinh
chỉnh các mô hình hiện đại như FLAN-T5
(Chung et al., 2022). Định dạng đầu vào được
hiển thị trong Bảng 2a.

Chúng tôi bao gồm αNLG (Bhagavatula et al.,
2020) và CommonGen (Lin et al., 2020), hai bộ
dữ liệu sinh có thể kiểm soát tiếng Anh về ràng
buộc vị trí và từ vựng. Trong αNLG, cho quan
sát quá khứ O1 và quan sát tương lai O2, mục
tiêu là sinh một giả thuyết h có thể theo sau O1
và kích hoạt O2. Biểu thức chính quy của ràng
buộc là " .*" vì không yêu cầu ràng buộc từ
vựng. Trong CommonGen, cho một tập hợp k
khái niệm C={c0, c1, ..., ck−1}, văn bản đầu ra
sẽ bao gồm những khái niệm đó và đồng thời
phù hợp với thông thức. Trong khi trong thiết
lập ban đầu, thứ tự xuất hiện của các khái niệm
và thay đổi nghĩa từ của chúng không được
cung cấp, và mô hình sẽ đưa ra những quyết
định này, ở đây trong ngôn ngữ kiểm soát của
chúng tôi, từ chính xác và thứ tự phải được cho.
Nếu không, chúng ta không thể xây dựng biểu
thức tương ứng. Vì vậy, chúng tôi tiền xử lý
các instance ban đầu và khôi phục thứ tự và
nghĩa từ của các khái niệm bằng văn bản tham
chiếu. Để giúp mô hình sinh các khái niệm tuần
tự và theo dõi đã sử dụng bao nhiêu khái niệm,
chúng tôi thêm nhãn số thứ tự (i) vào mỗi khái
niệm ci ở cả phía đầu vào và đầu ra và loại bỏ
các nhãn khỏi việc sinh đầu ra khi hoàn thành.
Biểu thức chính quy của ràng buộc là " .*c0.*c1
... .* ck−1.*".

Chúng tôi cũng tận dụng hai bộ dữ liệu này
để dạy mô hình kiểm soát độ dài đầu ra bằng
cách đơn giản thêm nhãn độ dài với độ dài
thực tế. Để theo dõi tốt hơn mô hình đã sinh
bao nhiêu từ, chúng tôi thêm nhãn số độ dài
_i vào mỗi từ wi; ví dụ, câu "Stephen knocked
over a vase while drunk." trở thành "Stephen_0
knocked_1 over_2 a_3 vase_4 while_5 drunk._6".
Tương tự, chúng tôi loại bỏ các nhãn số độ dài
sau khi hoàn thành.

Cuối cùng, chúng tôi cần dạy mô hình về ngữ
pháp lựa chọn. Chúng tôi sử dụng bộ dữ liệu
αNLI (Bhagavatula et al., 2020), nhiệm vụ của
nó là xác định H1 hay H2 là giả thuyết hợp lý
hơn cho quan sát quá khứ và tương lai O1 và
O2, và ràng buộc của biểu thức chính quy là
"(H1|H2)".

--- TRANG 4 ---
Học trong Ngữ cảnh Đối với các mô hình ngôn
ngữ lớn như GPT-3.5 (Brown et al., 2020), nơi
thường cung cấp quyền truy cập thông qua API,
chúng ta có thể không áp dụng nhiều kỹ thuật
sinh có thể kiểm soát truyền thống. Tuy nhiên,
chúng ta có thể tận dụng khả năng học trong
ngữ cảnh của nó để thực hiện sinh ràng buộc
chi tiết. Cụ thể hơn, chúng tôi tận dụng khả
năng khám phá và bắt chước mẫu lặp lại
(Madaan and Yazdanbakhsh, 2022; Min et al.,
2022), điều này mong muốn trong trường hợp
của chúng tôi, vì không giống như các tác vụ
hiểu ngôn ngữ tự nhiên khác, ràng buộc chi
tiết cụ thể là một mẫu đơn giản được định nghĩa
rõ ràng có thể dễ dàng khám phá và bắt chước.

Cho đầu vào với biểu thức kiểm soát, chúng
ta có thể chọn k instance với cùng cấu trúc
biểu thức như prompt chỉ dẫn và gửi nó đến
mô hình ngôn ngữ lớn cùng với đầu vào. Tự
nhiên, khi đánh giá tập kiểm tra, chúng ta có
thể chọn ví dụ từ tập đào tạo hoặc tập validation,
hoặc các instance khác của tập kiểm tra khi
chúng không khả dụng. Nhất quán, chúng tôi
sử dụng cùng định dạng đầu vào và đầu ra đã
mô tả trước đó, giúp tiết kiệm nỗ lực thêm về
prompt engineering. Ngoài ra, chúng tôi đơn
giản sử dụng định dạng json phổ biến " {"input":
[INPUT], "output": [OUTPUT]} " cho mỗi
instance minh họa, và tự nhiên phân tách chúng
bằng "\n". Bằng cách sử dụng json, chúng ta
có thể tránh thêm nhu cầu về ký tự thoát nếu
văn bản đầu vào tình cờ chứa metadata như
"Input" hoặc "\n".

2.3 Suy luận

Chúng tôi sử dụng lấy mẫu từ chối để sinh văn
bản đầu ra khớp với biểu thức kiểm soát. Việc
xác minh đầu ra đơn giản, vì chúng ta có thể
chuyển đổi biểu thức kiểm soát thành biểu thức
chính quy và kiểm tra tính hợp lệ. Ngoài ra,
nếu biểu thức chứa nhãn ràng buộc độ dài,
chúng ta đếm và so sánh số lượng từ trong văn
bản đầu ra. Chúng tôi thử tối đa k lần để tránh
vòng lặp vô hạn và tiết kiệm chi phí nếu chúng
ta sử dụng API mô hình ngôn ngữ lớn. Khi sử
dụng mô hình ngôn ngữ cỡ trung bình hoặc
nhỏ, để tăng chất lượng sinh, chúng ta có thể
thực hiện beam search trước và xem liệu nó
có thể sinh kết quả hợp lệ ngay lần đầu hay
không.

2.4 Giải mã Đệ quy

Các lựa chọn khác nhau có thể ảnh hưởng đến
văn bản được sinh. Ví dụ, xem xét trường hợp
"S1S2S3.*(E1|E2)", cho ba câu đầu và hai kết
thúc thay thế và mục tiêu là chọn kết thúc đúng
trong khi điền câu thứ tư cùng lúc, điều này
không được bao gồm trong dữ liệu tinh chỉnh
của chúng tôi. Thay vì nhảy trực tiếp đến câu
trả lời với tính toán có thể không đủ, chúng ta
cũng có thể để mô hình "suy nghĩ từng bước
(Kojima et al., 2022)". Chúng ta có thể giải
quyết từng biểu thức lựa chọn trước, sau đó so
sánh các lựa chọn hoàn chỉnh " (S4E1|S′4E2)"".
Quy trình giải mã tổng quát được trình bày tại
Thuật toán 1, giả định rằng mỗi lựa chọn độc
lập với nhau và giải quyết chúng một cách tham
lam từ trái sang phải. Chúng tôi để dành việc
đánh giá biểu thức với nhiều lựa chọn liên tiếp
(Lu et al., 2022) cho nghiên cứu tương lai.

3 Thí nghiệm

3.1 Thiết lập

Chúng tôi thực hiện các thí nghiệm trên 2 GPU
Nvidia A100, với khoảng 10 giờ GPU tổng cộng
tại chỗ. Đối với mô hình ngôn ngữ cỡ trung
bình, chúng tôi sử dụng FLAN-T5-xl (Chung
et al., 2022) với giấy phép Apache 2.0, có 3B
tham số và được tinh chỉnh trên nhiều tác vụ
hiểu và sinh ngôn ngữ tự nhiên. Chúng tôi sử
dụng thư viện Huggingface Transformers (Wolf
et al., 2020) với giấy phép Apache-2.0 cho tinh
chỉnh và đánh giá. Chúng tôi đào tạo mô hình
trong 3 epoch, với batch size 16 và learning
rate 3e-5. Chúng tôi đặt beam size thành 4 cho
beam search và p thành 0.95 cho top-p sampling.
Chúng tôi sinh tối đa k = 512 mẫu nếu không
nhận được kết quả hợp lệ nào.

Đối với mô hình ngôn ngữ lớn, chúng tôi sử
dụng GPT-3 (Brown et al., 2020) phiên bản
text-davinci-003 thông qua OpenAI API, và
mô hình 175B được hiệu chỉnh với Reinforcement
Learning from Human Feedback (Stiennon et al.,
2020b). Chúng tôi cung cấp 8 ví dụ trong miền
làm prompt, đặt temperature thành 0.7, và thử
lại tối đa k = 8 lần nếu kết quả không hợp lệ.
Tất cả kết quả đều từ lần chạy "đơn".

3.2 Ràng buộc Từ vựng

3.2.1 Chỉ Ràng buộc Từ vựng

Thiết lập Chúng tôi đánh giá phương pháp của
chúng tôi trên devset của CommonGen (Lin et al.,
2020), vì văn bản tham chiếu của tập kiểm tra
không được công khai. Như đã đề cập trong
phần 2.2, chúng tôi cung cấp cho mô hình thứ
tự khái niệm và nghĩa từ oracle. Đối với các
chỉ số tự động, chúng tôi sử dụng BLEU-4
(Papineni et al., 2002), CIDEr (Vedantam et al.,
2015), SPICE (Anderson et al., 2016) và Coverage
(Cov.), là tỷ lệ trung bình của các khái niệm
đầu vào có mặt trong đầu ra được lemmatized.

--- TRANG 5 ---
Phương pháp BLEU CIDEr SPICE Cov.
BART (Lin et al., 2020) 31.83 13.96 28.00 97.35
T5-Large (Lin et al., 2020) 31.96 15.13 28.86 95.29
Neurologic (Lu et al., 2021) 28.10 15.50 30.80 98.50
NADO (Meng et al., 2022) 30.80 - - 97.10
NRP (Carlsson et al., 2022) - - - 95.10
NLI+GPT-3.5, 8 shot, oracle 38.89 18.60 31.51 98.93
REI+GPT-3.5, 8 shot, oracle 28.64 15.15 29.49 98.60
REI+FLAN-T5-xl, oracle 36.78 18.34 33.56 100.0
(a) Ràng buộc từ vựng

Phương pháp BLEU CIDEr SPICE SuR.
NLI+GPT-3.5, 8 shot 40.48 19.72 31.78 35.95
REI+GPT-3.5, 8 shot 19.53 11.54 22.35 67.43
REI+FLAN-T5-xl 30.95 17.50 32.37 99.90
(b) Ràng buộc từ vựng & độ dài

Bảng 3: Kết quả trên devset của CommonGen. Các mô hình tốt nhất được in đậm trong mỗi chỉ số.

Kết quả Chúng tôi so sánh hiệu suất của phương
pháp chúng tôi với các baseline khác, bao gồm
các phương pháp tinh chỉnh BART (Lin et al.,
2020) và T5-Large (Lin et al., 2020), phương
pháp mô hình hướng dẫn phụ trợ NADO (Meng
et al., 2022), phương pháp prompting NRP
(Carlsson et al., 2022), và chỉ dẫn ngôn ngữ
tự nhiên (NLI) 8-shot thuần túy trên GPT-3.5,
được hiển thị trong Bảng 3a.

Chỉ với 8 ví dụ có mối liên hệ rõ ràng giữa
đầu vào và đầu ra, GPT-3.5 vẫn cho thấy hiệu
suất cạnh tranh về các chỉ số tự động văn bản,
và đạt độ bao phủ khái niệm cao, vượt trội tất
cả các baseline trước đây. So với chỉ dẫn ngôn
ngữ tự nhiên, tỷ lệ thành công rất gần. Và với
nhiều dữ liệu có giám sát hơn để thay đổi tham
số của mô hình, FLAN-T5-xl hoạt động tốt
hơn đáng kể so với GPT-3.5 và các baseline
trước đây khác trong tất cả các chỉ số và thành
công thỏa mãn tất cả ràng buộc từ vựng.

3.2.2 Ràng buộc Từ vựng & Độ dài

Như mô tả trong Phần 2.2, chúng tôi sửa đổi
nhẹ devset của CommonGen để giới thiệu ràng
buộc độ dài bổ sung và đánh giá GPT-3.5 và
FLAN-T5. Đối với chỉ số, chúng tôi thay thế
Coverage (Cov.) bằng Success Rate (SuR.), là
tỷ lệ trung bình của đầu ra khớp với biểu thức
đầu vào.

Trong một tác vụ tổng hợp, hiệu suất của
GPT-3.5 giảm đáng kể và gặp khó khăn trong
việc sinh đầu ra hợp lệ, cho thấy rằng việc
bao gồm nhiều khái niệm và kiểm soát độ dài
cùng lúc là thách thức, đặc biệt đối với học
trong ngữ cảnh vài mẫu. Tuy vậy, REI vẫn
vượt trội NLI về tỷ lệ thành công, và các chỉ
số n-gram "cao" cũng có thể chỉ ra khả năng
tuân theo chỉ dẫn kém về các ràng buộc chi
tiết thách thức, phù hợp với phát hiện của
Zhou et al. (2023). FLAN-T5 chỉ có sự sụt
giảm nhỏ về hiệu suất và vẫn duy trì tỷ lệ
thành công cao vì nó đã được đào tạo trên
ràng buộc tổng hợp này.

3.3 Ràng buộc Vị trí

3.3.1 Chỉ ràng buộc vị trí

Thiết lập Chúng tôi đánh giá phương pháp của
chúng tôi trên testset của αNLG (Bhagavatula
et al., 2020). Các chỉ số tự động bao gồm BLEU-4
(Papineni et al., 2002), ROUGE-L (Lin, 2004)
và BERTScore (Zhang* et al., 2020). Chúng tôi
không báo cáo Success Rate vì nó luôn là 100%.

Kết quả Như được trình bày trong Bảng 4a,
chúng tôi so sánh phương pháp của chúng tôi
với hai baseline không giám sát DeLorean (Qin
et al., 2020) và COLD (Qin et al., 2022), Diffusion-
LM không tự hồi quy (Li et al., 2022) và hai
phương pháp tinh chỉnh trên T5 11B (Khashabi
et al., 2021), UL2 20B (Tay et al., 2022) và NLI
8-shot trên GPT-3.5.

Với học vài mẫu, GPT-3.5 vượt trội hai baseline
không giám sát và Diffusion-LM, chứng minh
khả năng học trong ngữ cảnh mạnh mẽ của nó
khi chỉ được cho vài ví dụ điền. Vì đây là ràng
buộc tương đối đơn giản, hiệu suất giữa REI
và NLI rất gần. Với thiết kế prompt chỉ dẫn
cẩn thận và tinh chỉnh đầy đủ, FLAN-T5 3B
cho thấy hiệu suất mạnh hơn T5 11B, và vẫn
cạnh tranh so với UL2 20B.

--- TRANG 6 ---
Phương pháp BLEU ROUGE BERT
Qin et al. (2020) 1.38 18.94 42.86
Qin et al. (2022) 1.79 19.50 42.67
Li et al. (2022) 7.10 28.30 89.00
Khashabi et al. (2021) 19.47 44.60 92.87
Tay et al. (2022) 24.34 49.30 93.51
NLI+GPT-3.5, 8 shot 13.62 36.38 91.05
REI+GPT-3.5, 8 shot 13.01 37.29 91.27
REI+FLAN-T5-xl 25.44 48.45 93.28
(a) Ràng buộc vị trí

Mô hình BLEU ROUGE SuR.
NLI+GPT-3.5, 8 shot 9.9 32.93 42.09
REI+GPT-3.5, 8 shot 10.63 34.87 96.80
REI+FLAN-T5-xl 19.92 46.17 100.0
(b) Ràng buộc vị trí & độ dài

Mô hình BLEU ROUGE SuR.
NLI+GPT-3.5, 8 shot 14.76 42.04 99.01
REI+GPT-3.5, 8 shot 18.59 44.67 99.44
REI+FLAN-T5-xl 23.56 48.81 99.78
(c) Ràng buộc vị trí & từ vựng

Mô hình BLEU ROUGE SuR.
NLI+GPT-3.5, 8 shot 19.14 43.67 28.00
REI+GPT-3.5, 8 shot 17.45 43.90 94.02
REI+FLAN-T5-xl 21.99 49.17 99.69
(d) Ràng buộc vị trí & độ dài & từ vựng

Bảng 4: Kết quả trên testset của αNLG.

3.3.2 Ràng buộc Vị trí & Độ dài

Như đã đề cập trong Phần 2.2, chúng tôi sửa
đổi nhẹ tập kiểm tra αNLG để thêm ràng buộc
độ dài. Chúng tôi thay đổi chỉ số BERTScore
thành SuccessRate (SuR.). Bảng 4b hiển thị kết
quả. GPT-3.5 quản lý để bắt chước cả ràng
buộc vị trí và độ dài, cho thấy tỷ lệ thành công
tương đối cao, trong khi dưới NLI, nó hoạt
động kém. Nhưng với học có giám sát toàn
diện, FLAN-T5 có thể sinh đầu ra hợp lệ một
cách mạnh mẽ trên tập kiểm tra 100% thời
gian. Ngoài ra, về các chỉ số tự động, đầu ra
của cả hai mô hình không giảm đáng kể.

3.3.3 Ràng buộc Vị trí & Từ vựng

Chúng ta cũng có thể sửa đổi tập kiểm tra αNLG
để thêm ràng buộc từ vựng, đặt từ khóa là động
từ đầu tiên trong văn bản tham chiếu. Định
dạng đầu vào được hiển thị trong Bảng 2b, và
Bảng 4c hiển thị kết quả. Đối với GPT-3.5, nó
vẫn rất có khả năng sinh đầu ra hợp lệ gần như
mọi lúc, và các chỉ số tự động được cải thiện
so với kết quả không có ràng buộc từ vựng, vì
các từ vàng bổ sung được cung cấp, và ràng
buộc động từ giới hạn phạm vi rộng lớn của
không gian giả thuyết có thể. Ngoài ra, REI
hơi tốt hơn NLI. Đối với FLAN-T5, mặc dù nó
đã được đào tạo trên ràng buộc vị trí hoặc
ràng buộc từ vựng riêng biệt, nhưng nó chưa
thấy sự kết hợp, và vẫn thể hiện hiệu suất
mạnh mẽ.

3.3.4 Ràng buộc Vị trí & Từ vựng & Độ dài

Chúng ta có thể kết hợp thêm tất cả các điều
kiện lại với nhau, thêm cả ràng buộc độ dài
và từ vựng trên tập kiểm tra của αNLG. Định
dạng đầu vào được trình bày trong Bảng 2b,
và Bảng 4d hiển thị kết quả. Các ràng buộc
tổng hợp thách thức GPT-3.5 vài mẫu, vì khó
khăn hơn trong việc sinh đầu ra thỏa mãn tất
cả ba yêu cầu, và tỷ lệ thành công giảm nhẹ.
Thú vị, NLI có tỷ lệ thành công rất thấp. Nhưng
FLAN-T5 được đào tạo đầy đủ thể hiện khả
năng chuyển giao mạnh mẽ, vì ba ràng buộc
đồng thời không được bao gồm trong dữ liệu
đào tạo, nhưng FLAN-T5 vẫn quản lý đạt gần
100% tỷ lệ thành công.

3.3.5 Ràng buộc Vị trí & Kết thúc Thay thế

Trên tập kiểm tra của Story Cloze Test
(Mostafazadeh et al., 2016), nhiệm vụ là chọn
giữa kết thúc đúng và kết thúc sai cho ngữ
cảnh bốn câu, chúng tôi thêm che câu thứ tư
và yêu cầu mô hình điền câu bị thiếu trong
khi xác định kết thúc đúng. Định dạng đầu
vào được hiển thị trong Bảng 2b, và kết quả
được hiển thị trong Bảng 6. Chúng tôi thay
đổi chỉ số Success Rate (SuR.) thành Accuracy
(Acc.), vì việc chọn một trong hai kết thúc đều
hợp lệ. Đối với GPT-3.5, chúng tôi trực tiếp
xây dựng các ví dụ khuyến khích với đầu vào
ban đầu và đầu ra cuối cùng, và đáng ngạc
nhiên thấy rằng GPT-3.5 xử lý ràng buộc tổng
hợp khá tốt, và chọn kết thúc đúng với độ
chính xác không tệ. Ngoài ra, REI gần như
bằng NLI về hiệu suất. Đối với FLAN-T5-xl,
chúng tôi sử dụng giải mã đệ quy (Phần 2.4),
và nó cho thấy hiệu suất vừa phải, với độ chính
xác thấp hơn nhưng BLEU / ROUGE cao hơn
so với GPT-3.5.

3.4 Tóm tắt với ràng buộc độ dài

REI cũng có thể dễ dàng hỗ trợ tóm tắt trừu
tượng với độ dài mong muốn (Kikuchi et al.,
2016; Fan et al., 2018), miễn là mô hình cơ sở
đã được đào tạo trên tác vụ tóm tắt, đó là
trường hợp trong các mô hình chúng tôi chọn
FLAN-T5 (Chung et al., 2022) và GPT-3.5
(Ouyang et al., 2022). Chúng tôi chọn đánh
giá trên tập kiểm tra của bộ dữ liệu sinh tiêu
đề tiếng Anh Gigaword (Graff et al.,

--- TRANG 7 ---
Phương pháp Wiktionary IATE
Term% BLEU Term% BLEU
Constraint decoding (Dinu et al., 2019) 99.50 25.80 82.00 25.30
Train-by-replace (Dinu et al., 2019) 93.40 26.30 94.50 26.00
RePP (Sun et al., 2022) 93.67 30.52 95.41 29.38
TADA (Ailem et al., 2021) 96.84 26.73 98.02 27.11
EDITOR (Xu and Carpuat, 2021) 99.8 29.30 100.0 28.90
Levenshtein Transformer (Susanto et al., 2020) 100.0 31.20 100.0 30.13
NLI+GPT-3.5, 8-shot 99.03 37.62 98.07 32.22
REI+GPT-3.5, 8-shot 99.52 34.88 99.45 35.25

Bảng 5: Kết quả trên Wiktionary và IATE.

Phương pháp BLEU ROUGE Acc.
NLI+GPT-3.5, 8 shot 3.83 21.27 88.99
REI+GPT-3.5, 8 shot 3.77 20.56 88.72
REI+FLAN-T5-xl 3.87 20.9 84.61

Bảng 6: Kết quả trên Story Cloze Test với ràng buộc vị trí.

Phương pháp ROUGE SuR.
SEQ (Baziotis et al., 2019) 22.68 -
TED (Yang et al., 2020) 22.83 -
NLI+GPT-3.5, 8 shot 24.62 28.87
REI+GPT-3.5, 8 shot 25.46 79.51
REI+FLAN-T5-xl 28.49 100.0

Bảng 7: Kết quả trên tập kiểm tra của Gigaword.

2003), do độ dài đầu vào và đầu ra ngắn của
nó. Ngoài ra, Gigaword không được bao gồm
trong tập đào tạo của FLAN-T5 hoặc GPT-3.5.
Định dạng đầu vào được viết trong Bảng 2b.
Chúng tôi sử dụng ROUGE-L (Lin, 2004) và
Success Rate (SuR.) cho các chỉ số.

Chúng tôi so sánh các phương pháp của chúng
tôi với hai baseline không giám sát không ràng
buộc SEQ (Baziotis et al., 2019) và TED (Yang
et al., 2020), và kết quả được hiển thị trong
Bảng 7. Cả GPT-3.5 và FLAN-T5 đều vượt
hai baseline trong điểm ROUGE-L, cho thấy
chất lượng văn bản tương đối tốt. Vì tác vụ
tóm tắt ràng buộc nhiều hơn về ngữ nghĩa
của đầu ra so với ràng buộc từ vựng thuần túy
(CommonGen) hoặc ràng buộc vị trí (αNLG),
việc thỏa mãn ràng buộc độ dài có thể khó
khăn hơn, và GPT-3.5 cho thấy tỷ lệ thành
công tương đối thấp hơn, nhưng NLI có tỷ lệ
thành công tệ nhất. Nhưng dù sao, FLAN-T5
vẫn đạt 100% tỷ lệ thành công. Lưu ý rằng với
các tác vụ đào tạo REI hạn chế, mô hình vẫn
có thể tổng quát hóa cho các tác vụ mới với
định dạng cụ thể, chứng minh khả năng chuyển
giao mạnh mẽ dưới học có giám sát.

3.5 Dịch máy có ràng buộc thuật ngữ

Chúng ta cũng có thể áp dụng REI cho dịch
máy với ràng buộc thuật ngữ (Dinu et al., 2019),
đó là đảm bảo các thuật ngữ cho trước T =
(t0, t1, ...) được sử dụng trong bản dịch. Chúng
tôi chỉ kiểm tra GPT-3.5 ở đây, do ưu thế của
nó trong hiểu đa ngôn ngữ, trong khi phần
lớn ngôn ngữ đầu ra trong quá trình tiền đào
tạo, học đa tác vụ và tinh chỉnh là tiếng Anh.
Chúng tôi đánh giá trên tập kiểm tra của
Wiktionary và IATE (Dinu et al., 2019), hai bộ
dữ liệu dịch Anh-Đức, sử dụng BLEU-4
(Papineni et al., 2002) và Terminology Coverage
(Term) cho các chỉ số.

Chúng tôi so sánh phương pháp của chúng
tôi với một số baseline mạnh, bao gồm Constraint
decoding (Dinu et al., 2019), Train-by-replace
(Dinu et al., 2019), RePP (Sun et al., 2022),
TADA (Ailem et al., 2021), EDITOR (Xu and
Carpuat, 2021), Levenshtein Transformer
(Susanto et al., 2020), và NLI 8-shot trên GPT-3.5.
Do số lượng tham số lớn, GPT-3.5 vượt trội
tất cả các baseline khác về điểm BLEU. Ngoài
ra, GPT-3.5 đạt gần 100% tỷ lệ bao phủ thuật
ngữ, gần với giới hạn trên hiện tại. Cuối cùng,
REI có độ bao phủ thuật ngữ hơi cao hơn NLI.

3.6 Kết quả Định tính

Bảng 8 hiển thị các mẫu của ràng buộc từ vựng
& độ dài (Phần 3.2.2), ràng buộc vị trí & từ
vựng & độ dài (Phần 3.3.4), ràng buộc vị trí
với kết thúc thay thế (Phần 3.3.5), tóm tắt
với ràng buộc độ dài (Phần 3.4) và dịch với
ràng buộc thuật ngữ (Phần 3.5). Cả FLAN-T5
và GPT-3.5 đều sinh các câu hợp lệ và trôi
chảy. GPT-3.5 cũng sử dụng các từ sống động
hoặc giống con người hơn như "antihistamines"
hoặc từ viết tắt "FIA", có thể do kích thước mô
hình lớn và corpus đào tạo của nó.

--- TRANG 8 ---
CommonGen+length <expression> <mask_0> dance (0) <mask_1> performed (1) <mask_2> stage (2) <mask_3>
wearing (3) <mask_4> costumes (4) <mask_5> <length=11> </expression>
FLAN-T5-xl A_1 dance (0)_2 is_3 performed (1)_4 on_5 a_6 stage (2)_7 by_8 people_9 wearing (3)_10
costumes (4)_11
GPT-3.5, 8 shot A_1 traditional_2 dance (0)_3 is_4 performed (1)_5 on_6 the_7 stage (2),_8 wearing (3)_9
colorful_10 costumes (4)_11

αNLG+length+lexicon Jim was not confident in his home repair skills. <expression> <mask_0> attended (0) <mask_1>
<length=9> </expression> Jim was so excited to learn a new skill.
FLAN-T5-xl Jim_1 bought_2 new_3 gloves_4 and_5 attended (0)_6 a_7 home_8 repair._9
GPT-3.5, 8 shot Jim_1 attended (0)_2 a_3 home_4 repair_5 workshop_6 to_7 gain_8 confidence._9

StoryCompletion+infill I tried going to the park the other day. The weather seemed nice enough for a walk. Within
minutes of getting there I started sneezing. <expression> <options> <choice_0> <mask_0> My
allergies were too bad and I had to go back home. </choice_0> <choice_1> <mask_1> It
reminded me of how much I loved spring flowers. </choice_1> </options> </expression>
FLAN-T5-xl There were a lot of people at the park. My allergies were too bad and I had to go back home.
GPT-3.5, 8 shot I realized I had forgotten the antihistamines at home. My allergies were too bad and I had to
go back home.

Gigaword+length japan 's toyota team europe were banned from the world rally championship for one year here
on friday in a crushing ruling by the world council of the international automobile federation.\n
Summarize the aforementioned text in a single phrase.\n <expression> <mask_0> <length=6>
</expression>
FLAN-T5-xl toyota_1 team_2 europe_3 banned_4 from_5 rallying_6
GPT-3.5, 8 shot toyota_1 team_2 europe_3 banned_4 by_5 fia_6

Wiktionary Translate from English to German:\n\n English: Jennifer Aniston need not always be perfect or
successful. \n German: <expression> <mask_0> erfolgreich (0) <mask_1> </expression>
GPT-3.5, 8 shot Jennifer Aniston muss nicht immer perfekt oder erfolgreich (0) sein.

Bảng 8: Các ví dụ định tính của các ràng buộc khác nhau bởi FLAN-T5-xl tinh chỉnh và GPT-3.5 vài mẫu.

4 Nghiên cứu Liên quan

Các Tác vụ của Sinh Văn bản Có thể Kiểm soát
Sinh văn bản có thể kiểm soát đề cập đến các
tác vụ sinh văn bản theo các tín hiệu kiểm soát
(Prabhumoye et al., 2020). Thông thường, đầu
ra có thể được ràng buộc ở ba cấp độ từ thô
đến chi tiết: (Zhang et al., 2022) ngữ nghĩa,
cấu trúc và từ vựng. Ở cấp độ ngữ nghĩa, các
tín hiệu bao gồm chủ đề (Tang et al., 2019),
cảm xúc (Logeswaran et al., 2018), định dạng
(Li et al., 2020), độc tính (Krause et al., 2021)
và các thuộc tính trừu tượng khác. Ở cấp độ
cấu trúc, các ràng buộc bao gồm bảng dữ liệu
key-value (Novikova et al., 2017), cây cú pháp
và phần từ loại (Li et al., 2022). Ở cấp độ từ
vựng, các yếu tố kiểm soát bao gồm từ khóa
(Lin et al., 2020), vị trí sinh (Shen et al., 2020)
và độ dài (Carlsson et al., 2022).

Các Phương pháp của Sinh Văn bản Có thể
Kiểm soát Phương pháp hiện tại cho sinh văn
bản có thể kiểm soát có thể được tóm tắt thành
ba danh mục chính (Zhang et al., 2022): đào
tạo lại hoặc tái cấu trúc mô hình, ví dụ CTRL
(Keskar et al., 2019), POINTER (Zhang et al.,
2020), CMDP (Chan et al., 2021b), Constrained
BART (He, 2021), CoCon (Chan et al., 2021a),
PlanGen (Su et al., 2021) và InstructCTG (Zhou
et al., 2023); tinh chỉnh trên dữ liệu cho trước,
bao gồm tinh chỉnh mô hình, Prompt Tuning
(Lester et al., 2021) và RL-Fine Tuning (Stiennon
et al., 2020a); và xử lý hậu kỳ, có thể thiết kế
chiến lược giải mã cụ thể, ví dụ Constrainted
Beam Search (Anderson et al., 2017), DeLorean
(Qin et al., 2020), COLD (Qin et al., 2022),
NeuroLogic (Lu et al., 2021); hoặc sử dụng mô
hình hướng dẫn phụ trợ, ví dụ PPLM (Anderson
et al., 2017), GeDI (Krause et al., 2021), FUDGE
(Yang and Klein, 2021), CTRLsum (He et al.,
2022), Plug-and-Play Content Planning (Liu
et al., 2022), NADO (Meng et al., 2022), và
MACSum (Zhang et al., 2023).

5 Kết luận

Chúng tôi đề xuất Chỉ dẫn Biểu thức Chính
quy (REI), một phương pháp mới dựa trên chỉ
dẫn thống nhất việc sinh văn bản có ràng buộc
chi tiết ở cấp độ từ vựng. Phương pháp của
chúng tôi có tính thích ứng cao, phù hợp với
cả tinh chỉnh mô hình ngôn ngữ hoặc học trong
ngữ cảnh của mô hình ngôn ngữ lớn. Ngôn
ngữ kiểm soát của chúng tôi cũng có thể dễ
dàng được áp dụng cho các tác vụ liên quan
khác, bao gồm hoàn thành câu chuyện trong
khi điền, tóm tắt với ràng buộc độ dài, và dịch
máy với ràng buộc thuật ngữ. Các thí nghiệm
cho thấy rằng phương pháp của chúng tôi có
tỷ lệ thành công cao và vượt trội hơn hầu hết
các baseline mạnh trước đây, chứng minh tính
hiệu quả của nó mặc dù đơn giản. Chúng tôi
để dành việc đánh giá và cải thiện các ràng
buộc phức tạp hơn cho các nghiên cứu tương lai.

--- TRANG 9 ---
Hạn chế

Chỉ dẫn Biểu thức Chính quy được đề xuất
của chúng tôi được tuần tự hóa và không thể
mô tả một tập hợp các ràng buộc từ khóa mà
thứ tự xuất hiện là tùy ý, mà chỉ một danh sách
từ khóa với thứ tự xác định. Nghiên cứu tương
lai cần vượt qua giới hạn này, bằng cách xấp
xỉ thứ tự từ hoặc bằng lấy mẫu ngẫu nhiên
lặp lại. Ngoài ra, để có được kết quả hợp lệ,
chúng tôi sử dụng lấy mẫu từ chối, có thể cần
nhiều lần thử lặp lại, do đó giảm hiệu quả và
làm giảm tốc độ. Các cơ chế hiệu quả hơn với
ít lần thử lại hơn đáng được nghiên cứu. Ngoài
ra, dưới xu hướng hiện tại của việc tuân theo
chỉ dẫn, các prompt tinh vi hơn dưới 0-shot
đáng được nghiên cứu.

Tuyên bố Đạo đức

Công việc này không liên quan đến dữ liệu
nhạy cảm và sử dụng một số bộ dữ liệu có sẵn
công khai. Công việc này thảo luận về sinh
văn bản có thể kiểm soát, nhằm sử dụng tốt
hơn mô hình ngôn ngữ hộp đen và có thể giảm
tốt hơn các thiên lệch có vấn đề. Chúng tôi
lưu ý rằng phương pháp được đề xuất trong
công việc này có thể được sử dụng để sinh
thông tin sai lệch hoặc nội dung có hại trực
tiếp thông qua ngôn ngữ kiểm soát, nhưng việc
sử dụng độc hại có thể được tránh thêm bằng
cách lọc bỏ đầu vào kiểm soát không phù hợp
và dừng việc sinh nội dung có hại.

Tài liệu Tham khảo

Melissa Ailem, Jingshu Liu, and Raheel Qader. 2021.
Encouraging neural machine translation to satisfy ter-
minology constraints. In Findings of the Association
for Computational Linguistics: ACL-IJCNLP 2021,
pages 1450–1455, Online. Association for Computa-
tional Linguistics.

Peter Anderson, Basura Fernando, Mark Johnson, and
Stephen Gould. 2016. Spice: Semantic proposi-
tional image caption evaluation. In Computer Vi-
sion – ECCV 2016, pages 382–398, Cham. Springer
International Publishing.

Peter Anderson, Basura Fernando, Mark Johnson, and
Stephen Gould. 2017. Guided open vocabulary im-
age captioning with constrained beam search. In
Proceedings of the 2017 Conference on Empirical
Methods in Natural Language Processing, pages 936–
945, Copenhagen, Denmark. Association for Compu-
tational Linguistics.

Chidanand Apté, Fred Damerau, and Sholom M.
Weiss. 1994. Automated learning of decision rules
for text categorization. ACM Trans. Inf. Syst.,
12(3):233–251.

Yehoshua Bar-Hillel. 1960. The present status of au-
tomatic translation of languages**this article was
prepared with the sponsorship of the informations
systems branch, office of naval research, under con-
tract nr 049130. reproduction as a whole or in part
for the purposes of the u. s. government is permitted.
volume 1 of Advances in Computers, pages 91–163.
Elsevier.

Christos Baziotis, Ion Androutsopoulos, Ioannis Kon-
stas, and Alexandros Potamianos. 2019. SEQ³:
Differentiable sequence-to-sequence-to-sequence au-
toencoder for unsupervised abstractive sentence com-
pression. In Proceedings of the 2019 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Volume 1 (Long and Short Papers), pages
673–681, Minneapolis, Minnesota. Association for
Computational Linguistics.

Chandra Bhagavatula, Ronan Le Bras, Chaitanya
Malaviya, Keisuke Sakaguchi, Ari Holtzman, Han-
nah Rashkin, Doug Downey, Wen tau Yih, and Yejin
Choi. 2020. Abductive commonsense reasoning. In
ICLR.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens
Winter, Chris Hesse, Mark Chen, Eric Sigler, Ma-
teusz Litwin, Scott Gray, Benjamin Chess, Jack
Clark, Christopher Berner, Sam McCandlish, Alec
Radford, Ilya Sutskever, and Dario Amodei. 2020.
Language models are few-shot learners. In Ad-
vances in Neural Information Processing Systems,
volume 33, pages 1877–1901. Curran Associates,
Inc.

Fredrik Carlsson, Joey Öhman, Fangyu Liu, Severine
Verlinden, Joakim Nivre, and Magnus Sahlgren. 2022.
Fine-grained controllable text generation using non-
residual prompting. In Proceedings of the 60th An-
nual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 6837–
6857, Dublin, Ireland. Association for Computational
Linguistics.

Alvin Chan, Yew-Soon Ong, Bill Pung, Aston Zhang,
and Jie Fu. 2021a. Cocon: A self-supervised ap-
proach for controlled text generation. In Interna-
tional Conference on Learning Representations.

Hou Pong Chan, Lu Wang, and Irwin King. 2021b. Con-
trollable summarization with constrained Markov de-
cision process. Transactions of the Association for
Computational Linguistics, 9:1213–1232.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret
Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang,
Mostafa Dehghani, Siddhartha Brahma, Albert Web-
son, Shixiang Shane Gu, Zhuyun Dai, Mirac Suz-
gun, Xinyun Chen, Aakanksha Chowdhery, Sharan

--- TRANG 10 ---
Narang, Gaurav Mishra, Adams Yu, Vincent Y. Zhao,
Yanping Huang, Andrew M. Dai, Hongkun Yu, Slav
Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam
Roberts, Denny Zhou, Quoc V. Le, and Jason Wei.
2022. Scaling instruction-finetuned language models.
CoRR, abs/2210.11416.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. BERT: Pre-training of
deep bidirectional transformers for language under-
standing. In Proceedings of the 2019 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Volume 1 (Long and Short Papers), pages
4171–4186, Minneapolis, Minnesota. Association for
Computational Linguistics.

Georgiana Dinu, Prashant Mathur, Marcello Federico,
and Yaser Al-Onaizan. 2019. Training neural ma-
chine translation to apply terminology constraints. In
Proceedings of the 57th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 3063–
3068, Florence, Italy. Association for Computational
Linguistics.

Angela Fan, David Grangier, and Michael Auli. 2018.
Controllable abstractive summarization. In Proceed-
ings of the 2nd Workshop on Neural Machine Transla-
tion and Generation, pages 45–54, Melbourne, Aus-
tralia. Association for Computational Linguistics.

David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda.
2003. English gigaword. Linguistic Data Consor-
tium, Philadelphia, 4(1):34.

Junxian He, Wojciech Kryscinski, Bryan McCann,
Nazneen Rajani, and Caiming Xiong. 2022. CTRL-
sum: Towards generic controllable text summariza-
tion. In Proceedings of the 2022 Conference on Em-
pirical Methods in Natural Language Processing,
pages 5879–5915, Abu Dhabi, United Arab Emirates.
Association for Computational Linguistics.

Xingwei He. 2021. Parallel refinements for lexically
constrained text generation with BART. In Proceed-
ings of the 2021 Conference on Empirical Methods
in Natural Language Processing, pages 8653–8666,
Online and Punta Cana, Dominican Republic. Asso-
ciation for Computational Linguistics.

Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney,
Caiming Xiong, and Richard Socher. 2019. CTRL:
A conditional transformer language model for con-
trollable generation. CoRR, abs/1909.05858.

Daniel Khashabi, Gabriel Stanovsky, Jonathan Bragg,
Nicholas Lourie, Jungo Kasai, Yejin Choi, Noah A
Smith, and Daniel S Weld. 2021. Genie: A leader-
board for human-in-the-loop evaluation of text gener-
ation. arXiv preprint arXiv:2101.06561.

Yuta Kikuchi, Graham Neubig, Ryohei Sasano, Hiroya
Takamura, and Manabu Okumura. 2016. Controlling
output length in neural encoder-decoders. In Pro-
ceedings of the 2016 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1328–
1338, Austin, Texas. Association for Computational
Linguistics.

Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-
taka Matsuo, and Yusuke Iwasawa. 2022. Large lan-
guage models are zero-shot reasoners. In Advances
in Neural Information Processing Systems.

Ben Krause, Akhilesh Deepak Gotmare, Bryan McCann,
Nitish Shirish Keskar, Shafiq Joty, Richard Socher,
and Nazneen Fatema Rajani. 2021. GeDi: Gener-
ative discriminator guided sequence generation. In
Findings of the Association for Computational Lin-
guistics: EMNLP 2021, pages 4929–4952, Punta
Cana, Dominican Republic. Association for Compu-
tational Linguistics.

Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang,
and Eduard Hovy. 2017. RACE: Large-scale ReAd-
ing comprehension dataset from examinations. In
Proceedings of the 2017 Conference on Empirical
Methods in Natural Language Processing, pages 785–
794, Copenhagen, Denmark. Association for Compu-
tational Linguistics.

Brian Lester, Rami Al-Rfou, and Noah Constant. 2021.
The power of scale for parameter-efficient prompt
tuning. In Proceedings of the 2021 Conference on
Empirical Methods in Natural Language Processing,
pages 3045–3059, Online and Punta Cana, Domini-
can Republic. Association for Computational Lin-
guistics.

Mike Lewis, Yinhan Liu, Naman Goyal, Marjan
Ghazvininejad, Abdelrahman Mohamed, Omer Levy,
Veselin Stoyanov, and Luke Zettlemoyer. 2020.
BART: Denoising sequence-to-sequence pre-training
for natural language generation, translation, and com-
prehension. In Proceedings of the 58th Annual Meet-
ing of the Association for Computational Linguistics,
pages 7871–7880, Online. Association for Computa-
tional Linguistics.

Piji Li, Haisong Zhang, Xiaojiang Liu, and Shuming Shi.
2020. Rigid formats controlled text generation. In
Proceedings of the 58th Annual Meeting of the Associ-
ation for Computational Linguistics, pages 742–751,
Online. Association for Computational Linguistics.

Xiang Lisa Li, John Thickstun, Ishaan Gulrajani, Percy
Liang, and Tatsunori Hashimoto. 2022. Diffusion-
LM improves controllable text generation. In Ad-
vances in Neural Information Processing Systems.

Bill Yuchen Lin, Wangchunshu Zhou, Ming Shen, Pei
Zhou, Chandra Bhagavatula, Yejin Choi, and Xiang
Ren. 2020. CommonGen: A constrained text gen-
eration challenge for generative commonsense rea-
soning. In Findings of the Association for Computa-
tional Linguistics: EMNLP 2020, pages 1823–1840,
Online. Association for Computational Linguistics.

--- TRANG 11 ---
Chin-Yew Lin. 2004. ROUGE: A package for auto-
matic evaluation of summaries. In Text Summariza-
tion Branches Out, pages 74–81, Barcelona, Spain.
Association for Computational Linguistics.

Yinhong Liu, Yixuan Su, Ehsan Shareghi, and Nigel
Collier. 2022. Plug-and-play recipe generation with
content planning. In Proceedings of the 2nd Work-
shop on Natural Language Generation, Evaluation,
and Metrics (GEM), pages 223–234, Abu Dhabi,
United Arab Emirates (Hybrid). Association for Com-
putational Linguistics.

Lajanugen Logeswaran, Honglak Lee, and Samy Ben-
gio. 2018. Content preserving text generation with
attribute controls. In Proceedings of the 32nd Interna-
tional Conference on Neural Information Processing
Systems, NIPS'18, page 5108–5118, Red Hook, NY,
USA. Curran Associates Inc.

Ximing Lu, Sean Welleck, Peter West, Liwei Jiang,
Jungo Kasai, Daniel Khashabi, Ronan Le Bras, Lian-
hui Qin, Youngjae Yu, Rowan Zellers, Noah A. Smith,
and Yejin Choi. 2022. NeuroLogic a*esque decoding:
Constrained text generation with lookahead heuris-
tics. In Proceedings of the 2022 Conference of the
North American Chapter of the Association for Com-
putational Linguistics: Human Language Technolo-
gies, pages 780–799, Seattle, United States. Associa-
tion for Computational Linguistics.

Ximing Lu, Peter West, Rowan Zellers, Ronan Le Bras,
Chandra Bhagavatula, and Yejin Choi. 2021. Neuro-
Logic decoding: (un)supervised neural text genera-
tion with predicate logic constraints. In Proceedings
of the 2021 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, pages 4288–4299,
Online. Association for Computational Linguistics.

H. P. Luhn. 1957. A statistical approach to mechanized
encoding and searching of literary information. IBM
Journal of Research and Development, 1(4):309–317.

Aman Madaan and Amir Yazdanbakhsh. 2022. Text
and patterns: For effective chain of thought, it takes
two to tango. CoRR, abs/2209.07686.

Tao Meng, Sidi Lu, Nanyun Peng, and Kai-Wei Chang.
2022. Controllable text generation with neurally-
decomposed oracle. In Advances in Neural Informa-
tion Processing Systems.

Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe,
Mike Lewis, Hannaneh Hajishirzi, and Luke Zettle-
moyer. 2022. Rethinking the role of demonstra-
tions: What makes in-context learning work? CoRR,
abs/2202.12837.

Nasrin Mostafazadeh, Nathanael Chambers, Xiaodong
He, Devi Parikh, Dhruv Batra, Lucy Vanderwende,
Pushmeet Kohli, and James Allen. 2016. A corpus
and cloze evaluation for deeper understanding of
commonsense stories. In Proceedings of the 2016
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, pages 839–849, San Diego,
California. Association for Computational Linguis-
tics.

Jekaterina Novikova, Ondřej Dušek, and Verena Rieser.
2017. The E2E dataset: New challenges for end-
to-end generation. In Proceedings of the 18th An-
nual SIGdial Meeting on Discourse and Dialogue,
pages 201–206, Saarbrücken, Germany. Association
for Computational Linguistics.

Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-
roll L. Wainwright, Pamela Mishkin, Chong Zhang,
Sandhini Agarwal, Katarina Slama, Alex Ray, John
Schulman, Jacob Hilton, Fraser Kelton, Luke Miller,
Maddie Simens, Amanda Askell, Peter Welinder,
Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022.
Training language models to follow instructions with
human feedback. CoRR, abs/2203.02155.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic evalu-
ation of machine translation. In Proceedings of the
40th Annual Meeting of the Association for Compu-
tational Linguistics, pages 311–318, Philadelphia,
Pennsylvania, USA. Association for Computational
Linguistics.

Shrimai Prabhumoye, Alan W Black, and Ruslan
Salakhutdinov. 2020. Exploring controllable text
generation techniques. In Proceedings of the 28th
International Conference on Computational Linguis-
tics, pages 1–14, Barcelona, Spain (Online). Interna-
tional Committee on Computational Linguistics.

Lianhui Qin, Vered Shwartz, Peter West, Chandra Bha-
gavatula, Jena D. Hwang, Ronan Le Bras, Antoine
Bosselut, and Yejin Choi. 2020. Back to the future:
Unsupervised backprop-based decoding for counter-
factual and abductive commonsense reasoning. In
Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP),
pages 794–805, Online. Association for Computa-
tional Linguistics.

Lianhui Qin, Sean Welleck, Daniel Khashabi, and Yejin
Choi. 2022. COLD decoding: Energy-based con-
strained text generation with langevin dynamics. In
Advances in Neural Information Processing Systems.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine
Lee, Sharan Narang, Michael Matena, Yanqi Zhou,
Wei Li, and Peter J. Liu. 2022. Exploring the limits
of transfer learning with a unified text-to-text trans-
former. J. Mach. Learn. Res., 21(1).

Andy Rosenbaum, Saleh Soltan, Wael Hamza, Yannick
Versley, and Markus Boese. 2022. LINGUIST: Lan-
guage model instruction tuning to generate annotated
utterances for intent classification and slot tagging.
In Proceedings of the 29th International Confer-
ence on Computational Linguistics, pages 218–241,
Gyeongju, Republic of Korea. International Commit-
tee on Computational Linguistics.

--- TRANG 12 ---
Tianxiao Shen, Victor Quach, Regina Barzilay, and
Tommi Jaakkola. 2020. Blank language models. In
Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP),
pages 5186–5198, Online. Association for Computa-
tional Linguistics.

Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M.
Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford,
Dario Amodei, and Paul Christiano. 2020a. Learning
to summarize from human feedback. In Proceedings
of the 34th International Conference on Neural In-
formation Processing Systems, NIPS'20, Red Hook,
NY, USA. Curran Associates Inc.

Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel
Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford,
Dario Amodei, and Paul F Christiano. 2020b. Learn-
ing to summarize with human feedback. In Ad-
vances in Neural Information Processing Systems,
volume 33, pages 3008–3021. Curran Associates,
Inc.

Yixuan Su, David Vandyke, Sihui Wang, Yimai Fang,
and Nigel Collier. 2021. Plan-then-generate: Con-
trolled data-to-text generation via planning. In Find-
ings of the Association for Computational Linguis-
tics: EMNLP 2021, pages 895–909, Punta Cana, Do-
minican Republic. Association for Computational
Linguistics.

Zewei Sun, Qingnan Jiang, Shujian Huang, Jun Cao,
Shanbo Cheng, and Mingxuan Wang. 2022. Zero-
shot domain adaptation for neural machine trans-
lation with retrieved phrase-level prompts. CoRR,
abs/2209.11409.

Raymond Hendy Susanto, Shamil Chollampatt, and Lil-
ing Tan. 2020. Lexically constrained neural machine
translation with Levenshtein transformer. In Proceed-
ings of the 58th Annual Meeting of the Association
for Computational Linguistics, pages 3536–3543, On-
line. Association for Computational Linguistics.

Hongyin Tang, Miao Li, and Beihong Jin. 2019. A topic
augmented text generation model: Joint learning of
semantics and structural features. In Proceedings of
the 2019 Conference on Empirical Methods in Natu-
ral Language Processing and the 9th International
Joint Conference on Natural Language Processing
(EMNLP-IJCNLP), pages 5090–5099, Hong Kong,
China. Association for Computational Linguistics.

Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia,
Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil
Houlsby, and Donald Metzler. 2022. Unifying lan-
guage learning paradigms. CoRR, abs/2205.05131.

Ramakrishna Vedantam, C. Lawrence Zitnick, and Devi
Parikh. 2015. Cider: Consensus-based image de-
scription evaluation. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recog-
nition (CVPR).

Yufei Wang, Ian Wood, Stephen Wan, Mark Dras, and
Mark Johnson. 2021. Mention flags (MF): Constrain-
ing transformer-based text generators. In Proceed-
ings of the 59th Annual Meeting of the Association for
Computational Linguistics and the 11th International
Joint Conference on Natural Language Processing
(Volume 1: Long Papers), pages 103–113, Online.
Association for Computational Linguistics.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond, Clement Delangue, Anthony Moi, Pier-
ric Cistac, Tim Rault, Remi Louf, Morgan Funtow-
icz, Joe Davison, Sam Shleifer, Patrick von Platen,
Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,
Teven Le Scao, Sylvain Gugger, Mariama Drame,
Quentin Lhoest, and Alexander Rush. 2020. Trans-
formers: State-of-the-art natural language processing.
In Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing: System
Demonstrations, pages 38–45, Online. Association
for Computational Linguistics.

Weijia Xu and Marine Carpuat. 2021. EDITOR: An
Edit-Based Transformer with Repositioning for Neu-
ral Machine Translation with Soft Lexical Con-
straints. Transactions of the Association for Com-
putational Linguistics, 9:311–328.

Kevin Yang and Dan Klein. 2021. FUDGE: Controlled
text generation with future discriminators. In Pro-
ceedings of the 2021 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
3511–3535, Online. Association for Computational
Linguistics.

Ziyi Yang, Chenguang Zhu, Robert Gmyr, Michael
Zeng, Xuedong Huang, and Eric Darve. 2020. TED:
A pretrained unsupervised summarization model with
theme modeling and denoising. In Findings of the
Association for Computational Linguistics: EMNLP
2020, pages 1865–1874, Online. Association for
Computational Linguistics.

Hanqing Zhang, Haolin Song, Shaoyu Li, Ming Zhou,
and Dawei Song. 2022. A survey of controllable
text generation using transformer-based pre-trained
language models. CoRR, abs/2201.05337.

Tianyi Zhang*, Varsha Kishore*, Felix Wu*, Kilian Q.
Weinberger, and Yoav Artzi. 2020. Bertscore: Eval-
uating text generation with bert. In International
Conference on Learning Representations.

Yizhe Zhang, Guoyin Wang, Chunyuan Li, Zhe Gan,
Chris Brockett, and Bill Dolan. 2020. POINTER:
Constrained progressive text generation via insertion-
based generative pre-training. In Proceedings of the
2020 Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 8649–8670,
Online. Association for Computational Linguistics.

Yusen Zhang, Yang Liu, Ziyi Yang, Yuwei Fang, Yulong
Chen, Dragomir Radev, Chenguang Zhu, Michael

--- TRANG 13 ---
Zeng, and Rui Zhang. 2023. MACSum: Control-
lable Summarization with Mixed Attributes. Trans-
actions of the Association for Computational Linguis-
tics, 11:787–803.

Wangchunshu Zhou, Yuchen Eleanor Jiang, Ethan
Wilcox, Ryan Cotterell, and Mrinmaya Sachan. 2023.
Controlled text generation with natural language in-
structions. CoRR, abs/2304.14293.

Daniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B.
Brown, Alec Radford, Dario Amodei, Paul F. Chris-
tiano, and Geoffrey Irving. 2019. Fine-tuning lan-
guage models from human preferences. CoRR,
abs/1909.08593.

A Thuật toán Đệ quy

Thuật toán 1 Giải mã đệ quy
1: function RECURSIVE_DECODING(exp)
2:  if not ContainNonterminal(exp) then
3:    return input
4:  end if
5:  if not ContainOptions(exp) then
6:    return Generate(exp)
7:  end if
8:  exp_before_opts, opts, exp_after_opts ←
     SplitByFirstOption(exp)
9:  for i, ch in enumerate(opts) do
10:   exp_ch ← exp_before_opts + ch
11:   opts[i] ← Generate(exp_ch)
12: end for
13: best_ch ← Generate(opts)
14: remain_res ← Generate(exp_after_opts)
    return best_ch + remain_res
15: end function

B Thống kê Bộ dữ liệu

Bộ dữ liệu     Đào tạo  Validation  Kiểm tra
αNLG           50481    1780        3561
αNLI           169654   1532        3059
CommonGen      67216    993         -
Gigaword       -        189644      1933
IATE           -        -           414
Wiktionary     -        -           727
StoryCompletion -       1871        1871

Bảng 9: Thống kê của bộ dữ liệu được sử dụng

C Thống kê Sinh

Dữ liệu về số lần thử trung bình và tỷ lệ thành
công lần đầu trong quá trình sinh được trình
bày trong Bảng 10. Các mô hình REI có xu
hướng thành công ngay lần đầu tiên đối với
các ràng buộc đơn giản, và chỉ đối với các ràng
buộc thách thức, các mô hình REI mới thử lại.
Ngoài ra, FLAN tinh chỉnh cần ít lần thử lại
nhất, trong khi chỉ dẫn ngôn ngữ tự nhiên
yêu cầu nhiều lần thử lại nhất và có thể không
có khả năng thành công ngay lần đầu.

D Ví dụ Chỉ dẫn Ngôn ngữ Tự nhiên

Đối với phương pháp Chỉ dẫn Ngôn ngữ Tự
nhiên trên GPT-3.5, các chỉ dẫn được sử dụng
trên mỗi tác vụ được hiển thị trong Bảng 11.

--- TRANG 14 ---
Tác vụ                  Phương pháp
                        REI+FLAN-T5-xl          REI+GPT-3.5, 8 shot    NLI+GPT-3.5, 8 shot
                        Avg. Try  First SR.      Avg. Try  First SR.    Avg. Try  First SR.
aNLG, length           1.00      99.9           2.45      46.5         4.00      17.8
aNLG, lexicon          1.68      63.7           1.08      98.9         1.11      98.0
aNLG, length & lexicon 1.39      76.6           2.57      52.5         4.29      10.0
CommonGen              1.01      98.7           1.39      86.1         1.95      67.1
CommonGen, length      1.04      96.9           2.23      60.4         4.07      17.9
Gigaword, length       1.05      94.9           3.48      35.6         4.07      14.4
IATE                   -         -              1.01      99.0         1.19      91.9
Wiktionary             -         -              1.05      97.0         1.08      92.8
StoryCloze, position   1.00      100.0          1.04      97.0         1.01      78.9

Bảng 10: Thống kê của việc sinh, trình bày số lần thử trung bình (Avg. Try) và tỷ lệ thành công lần đầu (First SR.).

Tác vụ                  Ví dụ Chỉ dẫn
aNLG                   Câu đầu tiên là "The Smiths were having holidays done of the children." và câu cuối 
                       cùng là "Ty's face lit up as he ran to the new toy, happily posing for photos." Chèn 
                       một câu giữa với phong cách tương tự, và độ dài không được vượt quá 10 từ.

aNLG, length           Câu đầu tiên là "The Smiths were having holidays done of the children." và câu cuối 
                       cùng là "Ty's face lit up as he ran to the new toy, happily posing for photos." Chèn 
                       một câu giữa với phong cách tương tự, và độ dài phải chính xác là 7 từ không tính 
                       dấu câu.

aNLG, lexicon          Câu đầu tiên là "The Smiths were having holidays done of the children." và câu cuối 
                       cùng là "Ty's face lit up as he ran to the new toy, happily posing for photos." Chèn 
                       một câu giữa với phong cách tương tự, đồng thời chứa từ khóa "bought".

aNLG, length & lexicon Câu đầu tiên là "The Smiths were having holidays done of the children." và câu cuối 
                       cùng là "Ty's face lit up as he ran to the new toy, happily posing for photos." Chèn 
                       một câu giữa với phong cách tương tự, đồng thời chứa từ khóa "bought", và độ dài 
                       phải chính xác là 7 từ không tính dấu câu.

CommonGen              Sinh một câu đề cập đến tất cả các khái niệm này theo thứ tự tuần tự: "stood", "field", 
                       "looking".

CommonGen, length      Sinh một câu đề cập đến tất cả các khái niệm này theo thứ tự tuần tự với số từ là 10, 
                       bỏ qua dấu câu: "stood", "field", "looking".

Gigaword, length       Cho văn bản "japan 's nec corp. and UNK computer corp. of the united states said 
                       wednesday they had agreed to join forces in supercomputer sales.", tóm tắt văn bản 
                       nói trên thành một cụm từ đơn với số từ là 6.

IATE / Wiktionary      Dịch từ tiếng Anh sang tiếng Đức sử dụng thuật ngữ "Interview":\n\nEnglish: That is 
                       what the Hollywood star has made abundantly clear in an interview.\nGerman:

StoryCloze, position   Cho ba câu đầu của câu chuyện "My friends all love to go to the club to dance. They 
                       think it's a lot of fun and always invite. I finally decided to tag along last Saturday." 
                       và hai kết thúc "My friends decided to keep inviting me out as I am so much fun." và 
                       "The next weekend, I was asked to please stay home.", điền câu thứ tư bị thiếu và 
                       chọn kết thúc đúng từ hai lựa chọn.

Bảng 11: Ví dụ về Chỉ dẫn Ngôn ngữ Tự nhiên
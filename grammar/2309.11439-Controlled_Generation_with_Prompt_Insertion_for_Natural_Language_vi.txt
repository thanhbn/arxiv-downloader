# 2309.11439.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/grammar/2309.11439.pdf
# Kích thước file: 294514 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Sinh Điều Khiển với Chèn Lời Nhắc cho Giải Thích Ngôn Ngữ Tự Nhiên
trong Sửa Lỗi Ngữ Pháp
Masahiro Kaneko1,2 Naoaki Okazaki2
1MBZUAI
2Viện Công Nghệ Tokyo
Masahiro.Kaneko@mbzuai.ac.ae okazaki@c.titech.ac.jp
Tóm tắt
Trong Sửa Lỗi Ngữ Pháp (GEC), điều quan trọng là
đảm bảo sự hiểu biết của người dùng về lý do
sửa chữa. Các nghiên cứu hiện có trình bày
token, ví dụ và gợi ý làm cơ sở cho việc
sửa chữa nhưng không giải thích trực tiếp lý
do sửa chữa. Mặc dù các phương pháp sử
dụng Mô hình Ngôn ngữ Lớn (LLM) để cung
cấp giải thích trực tiếp bằng ngôn ngữ tự nhiên
đã được đề xuất cho nhiều tác vụ khác nhau,
nhưng chưa có phương pháp nào như vậy
cho GEC. Việc tạo ra giải thích cho các sửa
chữa GEC bao gồm việc căn chỉnh token
đầu vào và đầu ra, xác định điểm sửa chữa,
và trình bày các giải thích tương ứng một
cách nhất quán. Tuy nhiên, không đơn giản
để chỉ định một định dạng phức tạp nhằm tạo
ra giải thích, vì việc kiểm soát rõ ràng quá
trình sinh là khó khăn với các lời nhắc. Nghiên
cứu này giới thiệu một phương pháp gọi là
sinh điều khiển với Chèn Lời Nhắc (PI) để
LLM có thể giải thích lý do sửa chữa bằng
ngôn ngữ tự nhiên. Trong PI, LLM trước tiên
sửa văn bản đầu vào, sau đó chúng tôi tự
động trích xuất các điểm sửa chữa dựa trên
quy tắc. Các điểm sửa chữa được trích xuất
được chèn tuần tự vào đầu ra giải thích của
LLM như các lời nhắc, hướng dẫn LLM tạo ra
giải thích cho các điểm sửa chữa. Chúng tôi
cũng tạo ra một bộ dữ liệu GEC Có Thể Giải
Thích (XGEC) về lý do sửa chữa bằng cách
chú thích NUCLE, CoNLL2013 và CoNLL20141.
Mặc dù các sinh từ GPT-3 và ChatGPT sử
dụng lời nhắc gốc bỏ sót một số điểm sửa
chữa, việc điều khiển sinh bằng PI có thể
hướng dẫn rõ ràng để mô tả giải thích cho
tất cả các điểm sửa chữa, góp phần cải thiện
hiệu suất trong việc tạo ra lý do sửa chữa.
1 Giới thiệu
Sửa Lỗi Ngữ Pháp (GEC) là tác vụ sửa chữa
lỗi ngữ pháp trong một văn bản. Trong GEC,
nhiều phương pháp khác nhau đã được đề xuất
từ nhiều góc độ khác nhau, bao gồm hiệu suất
sửa chữa (Grundkiewicz and Junczys-Dowmunt,
2019; Chollampatt et al., 2019; Omelianchuk et al.,
2020; Kaneko et al., 2020; Qorib et al., 2022), điều
khiển (Hotate et al., 2019; Yang et al., 2022;
Loem et al., 2023), đa dạng (Xie et al., 2018;
Hotate et al., 2020; Han and Ng, 2021), và hiệu
quả (Malmi et al., 2019; Chen et al., 2020).
Trong GEC, cũng quan trọng là mô hình cung
cấp giải thích cho phép người dùng hiểu lý do
đằng sau các sửa chữa. Cải thiện khả năng giải
thích dẫn đến việc đánh giá tốt hơn về việc liệu
sửa chữa có phản ánh kết quả mong muốn hay
không, việc học kiến thức ngữ pháp, và nâng cao
tổng thể các hệ thống GEC.
Kaneko et al. (2022) đã giới thiệu một phương
pháp trình bày các ví dụ được truy xuất làm cơ
sở cho việc sửa chữa, trái ngược với phương
pháp truy xuất dữ liệu tương tự mục tiêu sửa
chữa từ tập dữ liệu huấn luyện và sử dụng nó
cho dự đoán. Fei et al. (2023) đã đề xuất một
phương pháp trình bày các vị trí token là cơ
sở của lỗi và các loại lỗi, và cho thấy chúng
hữu ích cho người học. Nagata (2019) đã đề xuất
tác vụ tạo ra các gợi ý hữu ích

Hình 1: Cách tạo ra giải thích của phương pháp
PI được đề xuất.

và phản hồi cho việc học ngôn ngữ trên các
bài luận được viết bởi người học ngôn ngữ.
Tác vụ này không nhất thiết tạo ra kết quả sửa
chữa hoặc lý do, vì nó không nhằm mục đích
sửa chữa. Vì các nghiên cứu hiện có này không
giải thích trực tiếp lý do sửa chữa, người dùng
phải suy luận lý do sửa chữa từ đầu ra của hệ
thống.
Các Mô hình Ngôn ngữ Lớn (LLM) như Chat-
GPT (OpenAI, 2023) và GPT-3 (Brown et al.,
2020) có khả năng ngôn ngữ tiên tiến và có thể
giải thích lý do suy luận bằng ngôn ngữ tự nhiên
trong nhiều tác vụ khác nhau (Wei et al., 2022;
Wiegreffe et al., 2022; Kaneko et al., 2023). Với
ngôn ngữ tự nhiên, mô hình có thể giải thích trực
tiếp chi tiết lý do suy luận cho người dùng. LLM
cũng hiệu quả trong GEC, đạt được tối ưu trong
cả môi trường không giám sát (Loem et al., 2023)
và có giám sát (Kaneko and Okazaki, 2023). Khả
năng giải thích trong GEC trước tiên yêu cầu căn
chỉnh token đầu vào và đầu ra và xác định tất
cả các cặp lỗi và sửa chữa. Sau đó, cần thiết
phải tạo ra giải thích cho từng cặp được trích
xuất. Tuy nhiên, khó kiểm soát việc sinh lời nhắc
theo định dạng được chỉ định cho GEC. Fang et
al. (2023) đã cho thấy ChatGPT cải thiện hiệu
suất bằng cách sử dụng ngôn ngữ tự nhiên để
tạo ra quá trình phát hiện và sửa chữa lỗi theo
từng bước cho mỗi đoạn. Họ phát hiện khó khăn
cho ChatGPT trong việc tạo ra theo từng bước
theo định dạng được chỉ định với hướng dẫn lời
nhắc đơn giản. Loem et al. (2023) đã cho thấy
lời nhắc không đóng góp đáng kể vào việc kiểm
soát phong cách sửa chữa cho GPT-3.
Trong nghiên cứu này, chúng tôi giới thiệu một
phương pháp để giải thích lý do sửa chữa bằng
ngôn ngữ tự nhiên thông qua sinh điều khiển
với chèn lời nhắc (PI). Như được thể hiện trong
Hình 1, chúng tôi hướng dẫn LLM đến đầu ra
định dạng mong muốn bằng cách chèn lời nhắc
trong quá trình suy luận. Trước tiên, LLM sửa
lỗi ngữ pháp trong văn bản đầu vào. Sau đó,
chúng tôi tự động căn chỉnh các điểm lỗi và sửa
chữa từ văn bản đầu vào và đầu ra bằng quy tắc
và trích xuất các cặp lỗi-sửa chữa. Bằng cách
chèn các cặp lỗi-sửa chữa này như các lời nhắc
bổ sung, chúng tôi điều khiển rõ ràng việc giải
thích của LLM về lý do cho tất cả các cặp. Hơn
nữa, chúng tôi đã tạo ra một bộ dữ liệu GEC
Có Thể Giải Thích (XGEC) để giải thích lý do
sửa chữa bằng ngôn ngữ tự nhiên bằng cách chú
thích các bộ dữ liệu NUCLE, CoNLL2013 và
CoNLL2014 (Dahlmeier et al., 2013; Ng et al.,
2013, 2014).
Trong các thí nghiệm của chúng tôi trên GPT-3
và ChatGPT, chúng tôi phát hiện ra việc sinh
dựa trên lời nhắc gốc dẫn đến bỏ sót cặp và
sự mơ hồ về việc giải thích dành cho cặp nào.
Mặt khác, việc điều khiển sinh bằng PI có thể
điều khiển rõ ràng LLM để tạo ra giải thích cho
tất cả các sửa chữa, góp phần cải thiện hiệu
suất giải thích lý do sửa chữa.

2 PI để Tạo Giải Thích Ngôn Ngữ Tự Nhiên
Các phương pháp hiện có để tạo ra giải thích
chỉ sử dụng hướng dẫn để dẫn dắt LLM trong
việc tạo ra giải thích (Wei et al., 2022; Wiegreffe
et al., 2022; Chen et al., 2023; Kaneko et al.,
2023). LLM chỉ với hướng dẫn không nhất thiết
tạo ra giải thích theo định dạng phù hợp bao
gồm tất cả các chỉnh sửa. Phương pháp của
chúng tôi giải quyết vấn đề này bằng cách chèn
lời nhắc của các chỉnh sửa vào đầu vào trong
quá trình sinh và hướng dẫn rõ ràng LLM tạo ra
giải thích cho tất cả các chỉnh sửa.
Cụ thể, chúng tôi đưa cho LLM hướng dẫn
viết lại văn bản đầu vào (ví dụ: "Sự khác biệt
giữa rối loạn di truyền và các rối loạn khác là
gì .") thành văn bản đúng ngữ pháp (ví dụ: "Sự
khác biệt giữa các rối loạn di truyền và các rối
loạn khác là gì?") và giải thích các sửa chữa.
Chúng tôi tính toán việc căn chỉnh token giữa
văn bản đầu vào và đầu ra và trích xuất các
chỉnh sửa như ("disorder → disorders") hoặc
(".→?"). Các chỉnh sửa được trích xuất được
đưa cho LLM từng cái một như đầu vào bổ sung,
khiến LLM tạo ra giải thích tương ứng với mỗi
chỉnh sửa. Chúng tôi gán số cho các chỉnh sửa,
như ("1. disorder → disorders:") hoặc ("2. .→?:").
Chúng tôi gán số cho các chỉnh sửa tuần tự từ
đầu, như ("1. disorder → disorders:") hoặc ("2.
.→?:").

3 Tạo Bộ Dữ Liệu XGEC
Bộ dữ liệu XGEC bao gồm văn bản sai, văn bản
đúng, và giải thích cho mỗi chỉnh sửa trong văn
bản đúng. Chúng tôi đã chú thích giải thích cho
các chỉnh sửa gốc trong các bộ dữ liệu GEC hiện
có để tạo ra bộ dữ liệu huấn luyện, phát triển
và kiểm tra.
Các bộ dữ liệu NUCLE (Dahlmeier et al., 2013),
CoNLL2013 (Ng et al., 2013), và CoNLL2014
(Ng et al., 2014) được sử dụng làm bộ dữ liệu
huấn luyện, phát triển và kiểm tra tương ứng.
NUCLE và CoNLL2013 chỉ chứa một văn bản
đúng cho mỗi văn bản sai. Đối với NUCLE và
CoNLL2013, chúng tôi đã chọn ngẫu nhiên 362
văn bản đúng và chú thích giải thích cho

--- TRANG 2 ---
chúng. CoNLL2014 bao gồm các bộ dữ liệu a
và b, được tạo ra bởi các người chú thích khác
nhau và thường được sử dụng để đánh giá các
mô hình GEC. Do đó, chúng tôi cũng sử dụng
CoNLL2014 a và b cho bộ dữ liệu kiểm tra XGEC.
Để giảm số lượng trường hợp trong bộ dữ liệu
kiểm tra mà các người chú thích của chúng tôi
không đồng ý với chỉnh sửa gốc, chúng tôi đã
chọn những chỉnh sửa được coi là phù hợp rộng
rãi bởi hầu hết con người. CoNLL2014 cũng bao
gồm 8 chú thích bổ sung (Bryant and Ng, 2015).
Do đó, chúng tôi chỉ chú thích giải thích cho
những chỉnh sửa xuất hiện trong ít nhất 7 trong
10 văn bản đúng trong CoNLL2014 a và b, dẫn
đến tổng cộng 444 văn bản đúng.
Hai người bản ngữ tiếng Anh2 chịu trách nhiệm
chú thích giải thích cho các chỉnh sửa. Các người
chú thích được cung cấp văn bản sai, văn bản
đúng, và các chỉnh sửa tương ứng, và họ được
giao nhiệm vụ viết giải thích cho mỗi chỉnh sửa
theo định dạng viết tự do. Đối với 10 văn bản đúng
không được bao gồm trong bộ dữ liệu chú thích,
chúng tôi đã cung cấp các giải thích ví dụ, và
các người chú thích đã sử dụng những ví dụ này
làm tham khảo. Trong trường hợp NUCLE và
CoNLL2013, hai người chú thích được giao viết
giải thích cho mỗi nửa văn bản đúng. Đối với
CoNLL2014, hai người chú thích được chỉ định
viết giải thích, dẫn đến việc tạo ra hai tham chiếu.
Tổng cộng, chúng tôi đã có được 888 văn bản.

4 Thí Nghiệm
4.1 Thiết lập
Chúng tôi đã sử dụng văn bản sau làm hướng
dẫn: "Sửa văn bản đầu vào về mặt ngữ pháp và
giải thích lý do cho mỗi sửa chữa. Nếu văn bản
đầu vào đúng ngữ pháp, chỉ văn bản đầu vào
nên được tạo ra như vậy.". Chúng tôi đã sử dụng
text-davinci-003 cho GPT-3.5 và gpt-3.5-turbo-16k
cho ChatGPT trong OpenAI API3. Số lượng ví dụ
cho few-shot là 16. Các ví dụ chứa văn bản đầu
vào, văn bản đúng, chỉnh sửa, và giải thích. Chúng
tôi đã sử dụng ERRANT (Felice et al., 2016; Bryant
et al., 2017)4 làm căn chỉnh token. Chúng tôi tự
động đánh giá hiệu suất tạo ra giải thích với
BERTScore (Zhang et al., 2019) của văn bản tham
chiếu và văn bản đầu ra trên CoNLL2014.
Chúng tôi so sánh phương pháp của chúng tôi
với hai đường cơ sở tạo ra giải thích mà không
chèn lời nhắc chỉnh sửa. Đường cơ sở đầu tiên
tạo ra câu đã sửa và giải thích cùng một lúc.
Chúng tôi chứng minh hiệu quả của việc cung
cấp rõ ràng các chỉnh sửa và tạo ra giải thích
thông qua so sánh với đường cơ sở này. Đường
cơ sở thứ hai tạo ra giải thích cùng một lúc và
sau đó tạo ra câu đã sửa.
Đường cơ sở thứ hai tạo ra giải thích cùng một
lúc và sau đó tạo ra câu đã sửa. Chúng tôi so
sánh mô hình đường cơ sở tạo ra chỉnh sửa và
giải thích từng bước trước khi tạo ra toàn bộ
văn bản đã sửa, như chuỗi suy nghĩ, với mô hình
tạo ra giải thích sau toàn bộ văn bản đã sửa.
Điều này chứng minh hiệu quả của việc tạo ra
giải thích sau sửa chữa.5
2Chúng tôi đã bồi thường cho mỗi người chú thích với
khoản thanh toán $4 cho mỗi giải thích.

--- TRANG 3 ---
XGECa XGECb
Precision Recall F1 Precision Recall F1
ChatGPTPost w/ PI 83.2 85.5 84.3 83.9 84.5 84.2
Post w/o PI 62.1 79.6 70.0 62.6 78.2 69.6
Pre w/o PI 60.9 75.2 68.1 61.1 74.4 67.7
GPT-3.5Post w/ PI 81.2 83.8 82.4 82.0 83.0 82.5
Post w/o PI 61.2 79.4 69.1 61.8 78.1 69.0
Pre w/o PI 59.9 75.6 67.7 60.7 75.5 68.1
Bảng 1: BERTScore của GPT-3.5 và ChatGPT trong việc tạo ra giải thích có và không có PI trên các bộ dữ liệu kiểm tra XGEC.

4.2 Hiệu Suất Tạo Giải Thích
Bảng 1 hiển thị điểm precision, recall, và F1 với
BERTScore của GPT-3.5 và ChatGPT trong việc
tạo ra giải thích có và không có PI trên các bộ dữ
liệu XGECa và XGECb. Điểm số của GPT-3.5 và
ChatGPT với PI tốt hơn các mô hình không có PI
trong tất cả điểm số trên cả hai bộ dữ liệu. Việc
cải thiện hiệu suất được tin là kết quả từ việc
tăng cường độ bao phủ của các chỉnh sửa được
bao gồm trong các giải thích được tạo ra bởi PI.
Hơn nữa, có thể thấy từ kết quả của Post w/o PI
và Pre w/o PI rằng việc tạo ra giải thích sau sửa
chữa hiệu quả hơn việc tạo ra chúng trước sửa
chữa.

5 Phân Tích
5.1 Đánh Giá Bằng Con Người
Chúng tôi kiểm tra chất lượng giải thích do LLM
tạo ra bằng đánh giá con người. Chúng tôi lấy
mẫu 200 giải thích từ CoNLL2013, và bốn người
chú thích đánh giá những giải thích đó từ góc
độ tính hợp lệ và độ bao phủ. Góc độ tính hợp
lệ đề cập đến độ chính xác và tính hữu ích của
thông tin ngữ pháp trong các giải thích do LLM
tạo ra cho người học ngôn ngữ. Nó được chấm
điểm theo ba mức: 0 nếu giải thích cho hơn nửa
số sửa chữa sai và không hữu ích, 1 nếu giải
thích cho hơn nửa số sửa chữa đúng và hữu ích
nhưng không hoàn hảo, 2 nếu giải thích cho tất
cả sửa chữa hoàn hảo. Góc độ độ bao phủ có
nghĩa là giải thích do LLM tạo ra đề cập đến tất
cả các sửa chữa ngữ pháp. Nó được chấm điểm
theo ba mức: 0 nếu giải thích không bao phủ
hơn nửa số sửa chữa, 1 nếu giải thích bao phủ
hơn nửa số sửa chữa nhưng không phải tất cả
sửa chữa, 2 nếu giải thích bao phủ tất cả sửa
chữa.
Bảng 2 hiển thị kết quả điểm tính hợp lệ và độ
bao phủ từ những người chú thích cho GPT-3.5
và ChatGPT, cả có và không có PI. Cả điểm tính
hợp lệ và độ bao phủ cho GPT-3.5 và ChatGPT
sử dụng PI đều tốt hơn những không sử dụng PI.
PI làm cho LLM rõ ràng về các sửa chữa cần
được giải thích, và cho phép giải thích cụ thể
gắn liền với mỗi sửa chữa, cải thiện chất lượng
giải thích của LLM. Điểm độ bao phủ cho thấy
bằng cách hướng dẫn rõ ràng vị trí sửa chữa
bằng phương pháp đề xuất, LLM có thể tạo ra
giải thích bao phủ hoàn toàn các chỉnh sửa. Hơn
nữa, so sánh các mô hình tạo sau và mô hình tạo
trước chứng minh rằng việc tạo ra giải thích
trước sửa chữa có tác động tiêu cực hơn về mặt
độ bao phủ của các chỉnh sửa so với việc tạo ra
giải thích sau sửa chữa.

Validity Coverage
ChatGPTPost w/ PI 81.5 100.0
Post w/o PI 78.0 77.5
Pre w/o PI 76.5 71.5
GPT-3.5Post w/ PI 86.5 100.0
Post w/o PI 83.5 72.0
Pre w/o PI 83.5 69.5
Bảng 2: Đánh giá con người của GPT-3.5 và ChatGPT có và không có PI trên bộ dữ liệu kiểm tra XGEC.

5.2 Tác Động của Giải Thích lên Hiệu Suất GEC
Việc cung cấp giải thích ngoài câu trả lời vàng
cho LLM như các ví dụ few-shot cải thiện hiệu
suất cho các tác vụ (Wei et al., 2022; Kaneko et
al., 2023). Chúng tôi đánh giá khả năng của mô
hình tạo ra giải thích bằng cách đánh giá tác
động của chúng lên hiệu suất GEC. Người ta
tin rằng nếu chất lượng giải thích được tạo ra
cao, hiệu suất GEC sẽ cải thiện đến mức tương
tự như với giải thích của con người. Ngược lại,
nếu chất lượng kém, hiệu suất sẽ không tốt như
với giải thích của con người. Chúng tôi lấy mẫu
ngẫu nhiên 8 trường hợp từ bộ dữ liệu hợp lệ
XGEC để sử dụng làm ví dụ few-shot. Để bao
gồm nhiều văn bản giải thích được tạo ra hơn
cho đánh giá, chúng tôi thực hiện lấy mẫu ngẫu
nhiên cho mỗi trường hợp trong dữ liệu kiểm tra
để chọn các ví dụ few-shot. Những ví dụ này
bao gồm giải thích do con người viết và giải thích
được tạo ra bởi PI, được chèn cả trước và sau
văn bản đã sửa, cho phép chúng tôi so sánh hiệu
quả của chúng tương ứng.
Bảng 3 hiển thị hiệu suất GEC của GPT-3.5 và
ChatGPT sử dụng văn bản giải thích làm ví dụ
cho việc học few-shot trong các bộ dữ liệu kiểm
tra CoNLL2014, W&I, và JFLEG. So sánh kết quả
không có giải thích với kết quả có giải thích, rõ
ràng là việc sử dụng giải thích làm ví dụ cho việc
học few-shot cải thiện hiệu suất GEC. Khi so sánh
kết quả của văn bản giải thích do con người tạo
ra và văn bản được tạo ra bởi PI, cả hai đều đạt
hiệu suất GEC gần như tương đương. Điều này
cho thấy văn bản giải thích được tạo ra bởi PI
có chất lượng tương tự như văn bản giải thích
do con người tạo ra. Hơn nữa, có thể quan sát
thấy việc thêm văn bản giải thích trước hoặc sau
sửa chữa cho việc học few-shot có ít ảnh hưởng.

3https://platform.openai.com/docs/models/
overview
4https://github.com/chrisjbryant/errant
5Phương pháp đề xuất không thể được áp dụng cho quá
trình tạo ra giải thích trước sửa chữa, vì nó yêu cầu các
chỉnh sửa được trích xuất từ sửa chữa để tạo ra giải thích.

--- TRANG 4 ---
CoNLL2014 W&I JFLEG
ChatGPTPre Human 55.2 51.2 61.7
Post Human 54.8 51.5 61.5
Pre PI 54.9 51.7 61.5
Post PI 54.7 49.7 61.8
No explanation 52.3 40.1 55.3
GPT-3.5Pre Human 54.0 44.2 57.8
Post Human 54.5 44.0 57.3
Pre PI 53.7 44.2 57.1
Post PI 54.1 39.9 57.1
No explanation 50.1 35.8 53.7
Bảng 3: Hiệu suất GEC của GPT-3.5 và ChatGPT khi sử dụng văn bản giải thích làm ví dụ cho các phương pháp few-shot.

6 Kết Luận
Trong nghiên cứu này, chúng tôi giới thiệu một
phương pháp tạo ra văn bản giải thích toàn diện
và chất lượng cao trong LLM bằng cách hướng
dẫn rõ ràng các chỉnh sửa. Ngoài ra, chúng tôi
đã tạo ra bộ dữ liệu XGEC cho việc tạo ra văn
bản giải thích. Kết quả thí nghiệm chứng minh
rằng phương pháp của chúng tôi, so với các phương
pháp không cung cấp rõ ràng các chỉnh sửa cho
LLM để tạo ra văn bản giải thích, mang lại lợi
ích trong cả đánh giá con người và đánh giá tự
động. Trong công việc tương lai, chúng tôi dự
định điều tra tác động của văn bản giải thích do
LLM tạo ra lên người học ngôn ngữ.

Tài Liệu Tham Khảo
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, et al. 2020. Language models are few-shot
learners. Advances in neural information processing
systems, 33:1877–1901.

Christopher Bryant, Mariano Felice, and Ted Briscoe.
2017. Automatic annotation and evaluation of error
types for grammatical error correction. In Proceed-
ings of the 55th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers),
pages 793–805, Vancouver, Canada. Association for
Computational Linguistics.

Christopher Bryant and Hwee Tou Ng. 2015. How far
are we from fully automatic high quality grammatical
error correction? In Proceedings of the 53rd Annual
Meeting of the Association for Computational Lin-
guistics and the 7th International Joint Conference
on Natural Language Processing (Volume 1: Long
Papers), pages 697–707, Beijing, China. Association
for Computational Linguistics.

Mengyun Chen, Tao Ge, Xingxing Zhang, Furu Wei,
and Ming Zhou. 2020. Improving the efficiency of
grammatical error correction with erroneous span de-
tection and correction. In Proceedings of the 2020
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), pages 7162–7169, On-
line. Association for Computational Linguistics.

Yanda Chen, Ruiqi Zhong, Narutatsu Ri, Chen Zhao,
He He, Jacob Steinhardt, Zhou Yu, and Kathleen
McKeown. 2023. Do models explain themselves?
counterfactual simulatability of natural language ex-
planations. arXiv preprint arXiv:2307.08678.

Shamil Chollampatt, Weiqi Wang, and Hwee Tou Ng.
2019. Cross-sentence grammatical error correction.
In Proceedings of the 57th Annual Meeting of the As-
sociation for Computational Linguistics, pages 435–
445, Florence, Italy. Association for Computational
Linguistics.

Daniel Dahlmeier, Hwee Tou Ng, and Siew Mei Wu.
2013. Building a large annotated corpus of learner
English: The NUS corpus of learner English. In Pro-
ceedings of the Eighth Workshop on Innovative Use
of NLP for Building Educational Applications, pages
22–31, Atlanta, Georgia. Association for Computa-
tional Linguistics.

Tao Fang, Shu Yang, Kaixin Lan, Derek F Wong, Jin-
peng Hu, Lidia S Chao, and Yue Zhang. 2023. Is
chatgpt a highly fluent grammatical error correction
system? a comprehensive evaluation. arXiv preprint
arXiv:2304.01746.

Yuejiao Fei, Leyang Cui, Sen Yang, Wai Lam, Zhen-
zhong Lan, and Shuming Shi. 2023. Enhancing gram-
matical error correction systems with explanations.
arXiv preprint arXiv:2305.15676.

Mariano Felice, Christopher Bryant, and Ted Briscoe.
2016. Automatic extraction of learner errors in ESL
sentences using linguistically enhanced alignments.
In Proceedings of COLING 2016, the 26th Inter-
national Conference on Computational Linguistics:
Technical Papers, pages 825–835, Osaka, Japan. The
COLING 2016 Organizing Committee.

Roman Grundkiewicz and Marcin Junczys-Dowmunt.
2019. Minimally-augmented grammatical error cor-
rection. In Proceedings of the 5th Workshop on Noisy
User-generated Text (W-NUT 2019), pages 357–363,
Hong Kong, China. Association for Computational
Linguistics.

Wenjuan Han and Hwee Tou Ng. 2021. Diversity-driven
combination for grammatical error correction. In
2021 IEEE 33rd International Conference on Tools
with Artificial Intelligence (ICTAI), pages 972–979.
IEEE.

--- TRANG 5 ---
Kengo Hotate, Masahiro Kaneko, Satoru Katsumata,
and Mamoru Komachi. 2019. Controlling grammati-
cal error correction using word edit rate. In Proceed-
ings of the 57th Annual Meeting of the Association for
Computational Linguistics: Student Research Work-
shop, pages 149–154, Florence, Italy. Association for
Computational Linguistics.

Kengo Hotate, Masahiro Kaneko, and Mamoru Ko-
machi. 2020. Generating diverse corrections with
local beam search for grammatical error correction.
In Proceedings of the 28th International Conference
on Computational Linguistics, pages 2132–2137,
Barcelona, Spain (Online). International Committee
on Computational Linguistics.

Masahiro Kaneko, Masato Mita, Shun Kiyono, Jun
Suzuki, and Kentaro Inui. 2020. Encoder-decoder
models can benefit from pre-trained masked language
models in grammatical error correction. In Proceed-
ings of the 58th Annual Meeting of the Association
for Computational Linguistics, pages 4248–4254, On-
line. Association for Computational Linguistics.

Masahiro Kaneko, Graham Neubig, and Naoaki
Okazaki. 2023. Solving nlp problems through
human-system collaboration: A discussion-based ap-
proach. arXiv preprint arXiv:2305.11789.

Masahiro Kaneko and Naoaki Okazaki. 2023. Re-
ducing sequence length by predicting edit opera-
tions with large language models. arXiv preprint
arXiv:2305.11862.

Masahiro Kaneko, Sho Takase, Ayana Niwa, and Naoaki
Okazaki. 2022. Interpretability for language learners
using example-based grammatical error correction.
In Proceedings of the 60th Annual Meeting of the
Association for Computational Linguistics (Volume
1: Long Papers), pages 7176–7187, Dublin, Ireland.
Association for Computational Linguistics.

Mengsay Loem, Masahiro Kaneko, Sho Takase, and
Naoaki Okazaki. 2023. Exploring effectiveness of
gpt-3 in grammatical error correction: A study on per-
formance and controllability in prompt-based meth-
ods. arXiv preprint arXiv:2305.18156.

Eric Malmi, Sebastian Krause, Sascha Rothe, Daniil
Mirylenka, and Aliaksei Severyn. 2019. Encode, tag,
realize: High-precision text editing. In Proceedings
of the 2019 Conference on Empirical Methods in Nat-
ural Language Processing and the 9th International
Joint Conference on Natural Language Processing
(EMNLP-IJCNLP), pages 5054–5065, Hong Kong,
China. Association for Computational Linguistics.

Ryo Nagata. 2019. Toward a task of feedback comment
generation for writing learning. In Proceedings of
the 2019 Conference on Empirical Methods in Natu-
ral Language Processing and the 9th International
Joint Conference on Natural Language Processing
(EMNLP-IJCNLP), pages 3206–3215, Hong Kong,
China. Association for Computational Linguistics.

Hwee Tou Ng, Siew Mei Wu, Ted Briscoe, Christian
Hadiwinoto, Raymond Hendy Susanto, and Christo-
pher Bryant. 2014. The CoNLL-2014 shared task
on grammatical error correction. In Proceedings of
the Eighteenth Conference on Computational Natu-
ral Language Learning: Shared Task, pages 1–14,
Baltimore, Maryland. Association for Computational
Linguistics.

Hwee Tou Ng, Siew Mei Wu, Yuanbin Wu, Christian
Hadiwinoto, and Joel Tetreault. 2013. The CoNLL-
2013 shared task on grammatical error correction.
In Proceedings of the Seventeenth Conference on
Computational Natural Language Learning: Shared
Task, pages 1–12, Sofia, Bulgaria. Association for
Computational Linguistics.

Kostiantyn Omelianchuk, Vitaliy Atrasevych, Artem
Chernodub, and Oleksandr Skurzhanskyi. 2020.
GECToR – grammatical error correction: Tag, not
rewrite. In Proceedings of the Fifteenth Workshop
on Innovative Use of NLP for Building Educational
Applications, pages 163–170, Seattle, WA, USA →
Online. Association for Computational Linguistics.

OpenAI. 2023. Introducing ChatGPT. Truy cập ngày
2023-05-10.

Muhammad Qorib, Seung-Hoon Na, and Hwee Tou
Ng. 2022. Frustratingly easy system combination
for grammatical error correction. In Proceedings of
the 2022 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, pages 1964–1974,
Seattle, United States. Association for Computational
Linguistics.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
Bosma, Ed Chi, Quoc Le, and Denny Zhou. 2022.
Chain of thought prompting elicits reasoning in large
language models. arXiv preprint arXiv:2201.11903.

Sarah Wiegreffe, Jack Hessel, Swabha Swayamdipta,
Mark Riedl, and Yejin Choi. 2022. Reframing
human-AI collaboration for generating free-text ex-
planations. In Proceedings of the 2022 Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies, pages 632–658, Seattle, United States.
Association for Computational Linguistics.

Ziang Xie, Guillaume Genthial, Stanley Xie, Andrew
Ng, and Dan Jurafsky. 2018. Noising and denois-
ing natural language: Diverse backtranslation for
grammar correction. In Proceedings of the 2018
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, Volume 1 (Long Papers),
pages 619–628, New Orleans, Louisiana. Associa-
tion for Computational Linguistics.

Liner Yang, Chengcheng Wang, Yun Chen, Yongping
Du, and Erhong Yang. 2022. Controllable data syn-
thesis method for grammatical error correction. Fron-
tiers of Computer Science, 16:1–10.

--- TRANG 6 ---
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q
Weinberger, and Yoav Artzi. 2019. Bertscore: Eval-
uating text generation with bert. arXiv preprint
arXiv:1904.09675.

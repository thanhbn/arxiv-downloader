# 2305.08339.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/grammar/2305.08339.pdf
# Kích thước tệp: 904964 byte

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Đây là phiên bản cuối cùng được chấp nhận của một bài báo sẽ xuất hiện trong International Journal of Corpus Linguistics năm 2024. Để trích dẫn và số trang, vui lòng kiểm tra phiên bản đã xuất bản.

Để trích dẫn:
Yu, D, Li, L, Su, H & Fuoli, M 2024, 'Assessing the potential of LLM-assisted annotation for corpus-based pragmatics and discourse analysis: The case of apologies', International Journal of Corpus Linguistics.

Đánh giá tiềm năng của chú thích hỗ trợ LLM cho phân tích ngữ dụng và diễn ngôn dựa trên kho ngữ liệu: Trường hợp của lời xin lỗi

Danni Yu, Luyang Li, Hang Su, và Matteo Fuoli
Trường Ngôn ngữ và Văn hóa Châu Âu, Đại học Ngoại ngữ Bắc Kinh | Trường Khoa học và Công nghệ Thông tin, Đại học Ngoại ngữ Bắc Kinh | Trung tâm Ngôn ngữ và Văn học Nước ngoài, Đại học Nghiên cứu Quốc tế Tứ Xuyên | Khoa Ngôn ngữ và Ngôn ngữ học Tiếng Anh, Đại học Birmingham

Tóm tắt
Một số hình thức chú thích ngôn ngữ nhất định, như gắn thẻ từ loại và ngữ nghĩa, có thể được tự động hóa với độ chính xác cao. Tuy nhiên, chú thích thủ công vẫn cần thiết cho các đặc điểm ngữ dụng và diễn ngôn phức tạp thiếu ánh xạ trực tiếp với các hình thức từ vựng. Quá trình thủ công này tốn thời gian và dễ mắc lỗi, hạn chế khả năng mở rộng của các phương pháp tiếp cận chức năng-hình thức trong ngôn ngữ học kho ngữ liệu. Để giải quyết vấn đề này, nghiên cứu của chúng tôi khám phá khả năng sử dụng các mô hình ngôn ngữ lớn (LLM) để tự động hóa chú thích kho ngữ liệu ngữ dụng-diễn ngôn. Chúng tôi so sánh GPT-3.5 (mô hình đằng sau phiên bản miễn phí của ChatGPT), GPT-4 (mô hình hỗ trợ chế độ chính xác của chatbot Bing), và một người mã hóa con người trong việc chú thích các thành phần xin lỗi bằng tiếng Anh dựa trên khung ngữ pháp địa phương. Chúng tôi phát hiện rằng GPT-4 vượt trội hơn GPT-3.5, với độ chính xác tiến gần đến của một người mã hóa con người. Những kết quả này cho thấy rằng LLM có thể được triển khai thành công để hỗ trợ chú thích kho ngữ liệu ngữ dụng-diễn ngôn, làm cho quá trình này hiệu quả hơn, có thể mở rộng và dễ tiếp cận hơn.

Từ khóa: ngữ dụng kho ngữ liệu, mô hình ngôn ngữ lớn, chú thích kho ngữ liệu ngữ dụng-diễn ngôn, ngữ pháp địa phương, ChatGPT

--- TRANG 2 ---
1. Giới thiệu
Chú thích là một khía cạnh chính của ngôn ngữ học kho ngữ liệu đương đại. Các kho ngữ liệu được chú thích cho phép các nhà nghiên cứu thực hiện các truy vấn kho ngữ liệu phức tạp, kiểm tra các giả thuyết về cấu trúc ngôn ngữ và hiểu rõ hơn về cách ngôn ngữ được sử dụng để giao tiếp và tương tác trong các bối cảnh tình huống (Leech, 1997). Trong khi một số thuộc tính ngôn ngữ như từ loại có thể được chú thích tự động với độ chính xác cao (ví dụ: Garside và Smith, 1997), việc phân tích các yếu tố ngữ dụng và diễn ngôn trong kho ngữ liệu tiếp tục phụ thuộc rất nhiều vào chú thích thủ công (ví dụ: Taylor, 2016, Cavasso & Taboada, 2021, Põldvere et al., 2022). Điều này chủ yếu là do các đặc điểm này thường vượt ra ngoài phạm vi của các đơn vị từ vựng riêng lẻ và thiếu ánh xạ đơn giản và rõ ràng lên các hình thức từ vựng cụ thể (Rühlemann & Aijmer, 2015). Tuy nhiên, chú thích kho ngữ liệu thủ công là một quá trình phức tạp đòi hỏi các kỹ năng chuyên môn, đào tạo sâu rộng và đầu tư thời gian đáng kể. Nó cũng dễ mắc lỗi và không nhất quán của con người, điều này có thể làm giảm độ chính xác và độ tin cậy. Những thách thức này đã cản trở khả năng mở rộng và việc áp dụng rộng rãi phân tích kho ngữ liệu chức năng-hình thức của các hiện tượng ngữ dụng và diễn ngôn. Nhưng nếu chúng ta có thể sử dụng Trí tuệ nhân tạo để tự động hóa quá trình chú thích kho ngữ liệu, giảm đáng kể thời gian và tài nguyên cần thiết thì sao?

Những tiến bộ gần đây trong AI được thúc đẩy bởi các mô hình ngôn ngữ lớn (LLM) - các mô hình học máy tiên tiến sử dụng mạng nơ-ron sâu để xử lý và học từ lượng lớn dữ liệu văn bản - đã cho phép cải tiến đáng kể trong việc tự động hóa các nhiệm vụ ngôn ngữ phức tạp như tạo văn bản, dịch thuật và trả lời câu hỏi, đạt được mức độ phức tạp và chính xác chưa từng có. Các nhà nghiên cứu trong lĩnh vực Xử lý Ngôn ngữ Tự nhiên (NLP) đã bắt đầu khám phá tiềm năng của việc sử dụng LLM để hỗ trợ nhiệm vụ chú thích kho ngữ liệu, đạt được kết quả khả quan trên một số ứng dụng (ví dụ: Ding et al., 2023; Frei & Kramer, 2023; Gilardi et al., 2023). Tuy nhiên, không rõ liệu mức độ hiệu suất tương tự có thể đạt được khi chú thích các đặc điểm ngữ dụng-diễn ngôn hay không. Điều này là do các sơ đồ chú thích được sử dụng trong NLP khác biệt đáng kể so với những sơ đồ thường được sử dụng trong ngôn ngữ học kho ngữ liệu. Trong NLP, những sơ đồ này được thiết kế cho các ứng dụng tính toán thực tế (ví dụ: tự động truy xuất các đề cập đến người, địa điểm, tổ chức, v.v.) hoặc dựa trên các khung phân tích không được áp dụng rộng rãi trong nghiên cứu ngôn ngữ học kho ngữ liệu (ví dụ: phân tích tình cảm). Hiện tại, không có nghiên cứu nào trong ngôn ngữ học kho ngữ liệu đánh giá tính khả thi của việc sử dụng LLM để tự động hóa quá trình chú thích kho ngữ liệu. Kết quả là, tiềm năng của những tiến bộ công nghệ như vậy trong việc hỗ trợ phân tích ngữ dụng và diễn ngôn dựa trên kho ngữ liệu vẫn chưa được khám phá.

Theo hiểu biết của chúng tôi, nghiên cứu này là nghiên cứu đầu tiên điều tra khả năng sử dụng LLM để tự động hóa mã hóa kho ngữ liệu ngữ dụng-diễn ngôn. LLM mang lại cơ hội quan trọng để làm cho quá trình này hiệu quả hơn đáng kể và có thể mở rộng bằng cách giảm lượng công việc thủ công cần thiết. Ngoài ra, một lợi ích chính của những mô hình này là bản chất thân thiện với người dùng của chúng, loại bỏ nhu cầu về kỹ năng lập trình tiên tiến. Nếu thành công, phương pháp này có tiềm năng cách mạng hóa các lĩnh vực ngữ dụng và nghiên cứu diễn ngôn dựa trên kho ngữ liệu bằng cách mở ra những khả năng mới cho nghiên cứu quy mô lớn, chức năng-hình thức. Để đánh giá tiềm năng của chú thích kho ngữ liệu ngữ dụng-diễn ngôn hỗ trợ LLM, chúng tôi so sánh hiệu suất của hai LLM tiên tiến nhất được phát triển đến nay - GPT-3.5 (được thực hiện trong phiên bản miễn phí của chatbot ChatGPT) và GPT-4 (cung cấp sức mạnh cho chế độ chính xác của chatbot Bing) - và một người mã hóa con người trong việc chú thích các thành phần chức năng của lời xin lỗi dựa trên phương pháp ngữ pháp địa phương (Su and Wei, 2018). Chúng tôi chọn hành vi ngôn ngữ xin lỗi để kiểm tra phương pháp của chúng tôi bởi vì nó đã được nghiên cứu sâu rộng trong ngôn ngữ học kho ngữ liệu và hơn thế nữa và hiệu quả thể hiện những thách thức điển hình gặp phải trong việc chú thích các yếu tố chức năng liên quan đến các chức năng ngữ dụng như vậy. Một bước quan trọng trong việc tích hợp LLM vào một nhiệm vụ ngôn ngữ là kỹ thuật tạo lời nhắc, đề cập đến việc tạo ra cẩn thận các hướng dẫn hoặc truy vấn được đưa cho một mô hình ngôn ngữ, để gợi ra những phản hồi mong muốn, trong trường hợp này là dữ liệu ngôn ngữ được chú thích chính xác. Do đó, một trong những mục đích của nghiên cứu hiện tại là phát triển một chiến lược thiết kế lời nhắc mang lại mức độ chính xác cao nhất có thể trong việc mã hóa các trường hợp xin lỗi. Bằng cách làm như vậy, chúng tôi cung cấp một giao thức có thể nhân bản có thể được áp dụng cho cùng một nhiệm vụ chú thích hoặc được điều chỉnh cho các nhiệm vụ chú thích kho ngữ liệu tương tự.

2. Chú thích kho ngữ liệu: những thách thức lâu dài, cơ hội mới
Tóm lại, chú thích kho ngữ liệu đề cập đến việc thực hành thêm thông tin ngôn ngữ chi tiết vào các văn bản trong một kho ngữ liệu để cho phép phân tích tập trung và tinh tế hơn.

--- TRANG 3 ---
Phần này bắt đầu bằng việc thảo luận về những thách thức liên quan đến quá trình này, với trọng tâm đặc biệt vào sự phức tạp của chú thích cấp độ ngữ dụng và diễn ngôn. Tiếp theo, cuộc thảo luận chuyển sang xem xét các cơ hội được tạo ra bởi những tiến bộ gần đây trong AI cho lĩnh vực này.

2.1 Thách thức trong tự động hóa chú thích cấp độ ngữ dụng và diễn ngôn
Kho ngữ liệu có thể được chú thích ở nhiều cấp độ khác nhau, bao gồm ngữ âm, trọng âm, ngữ pháp, ngữ nghĩa và ngữ dụng/diễn ngôn (Leech, 1993). Một trong những hình thức chú thích kho ngữ liệu sớm nhất và phổ biến nhất là gắn thẻ từ loại, bao gồm việc gắn nhãn mỗi từ trong kho ngữ liệu với danh mục ngữ pháp tương ứng của nó. Một kỹ thuật phổ biến khác là phân tích cú pháp, sử dụng thông tin từ loại để cho thấy cách các từ liên quan về mặt cú pháp (McEnery & Wilson, 2001: 53). Gắn thẻ ngữ nghĩa, bao gồm việc phân loại các từ thành các danh mục ý nghĩa rộng, đã thu hút sự chú ý trong những năm gần đây nhờ sự tiến bộ của phần mềm chú thích tự động (ví dụ: Rayson et al., 2004). Các 'thẻ' siêu ngôn ngữ được chèn vào các văn bản kho ngữ liệu có thể phục vụ nhiều mục đích, bao gồm tinh chỉnh các truy vấn kho ngữ liệu, điều tra các mẫu từ vựng-ngữ pháp của việc sử dụng ngôn ngữ, xác nhận và tăng cường các lý thuyết ngôn ngữ, hỗ trợ biên soạn các mục từ điển và xác định các chủ đề và diễn ngôn chủ đạo trong kho ngữ liệu (Garside et al., 1997). Do đó, chú thích ngôn ngữ làm tăng đáng kể khả năng của các công cụ kho ngữ liệu và vì lý do này đã phát triển thành một thành phần không thể thiếu và không thể thiếu của nghiên cứu dựa trên kho ngữ liệu.

Với nhiều lợi ích mà chú thích kho ngữ liệu mang lại, những nỗ lực đáng kể đã được thực hiện để tạo ra các sơ đồ chú thích để mô tả các khía cạnh ngôn ngữ khác nhau, cũng như phát triển các hệ thống tính toán để tự động hóa quá trình này. Trong một kịch bản lý tưởng, phần mềm sẽ có thể tự động gắn thẻ các đặc điểm ở tất cả các cấp độ mô tả ngôn ngữ. Tuy nhiên, mức độ tự động hóa đó vẫn chưa được đạt được. Mặc dù một số hình thức chú thích ngôn ngữ nhất định, như gắn thẻ từ loại, phân tích cú pháp phụ thuộc và gắn thẻ ngữ nghĩa có thể được thực hiện tự động với độ chính xác cao (McEnery & Hardie, 2012: 31), việc đạt được cùng mức độ thành công cho các loại mã hóa khác vẫn là một mục tiêu khó nắm bắt. Các đặc điểm cấp độ ngữ dụng và diễn ngôn, đặc biệt, đưa ra thách thức đáng kể cho phân tích tự động. Điều này có thể được quy cho ba yếu tố chính. Thứ nhất, các đặc điểm ngữ dụng-diễn ngôn thường vượt qua ranh giới của các đơn vị từ vựng riêng lẻ, làm phức tạp đáng kể nhiệm vụ chú thích vì không có tiêu chí nhất quán để xác định các đơn vị cần được mã hóa. Ví dụ, hành vi ngôn ngữ xin lỗi, mà chúng tôi sử dụng như một trường hợp kiểm tra trong nghiên cứu của mình, hiếm khi (nếu có) chỉ được tạo thành từ thiết bị chỉ thị lực lượng ngôn trung hoặc IFID trong tiếng Anh (ví dụ: sorry hoặc apologies) (Blum-Kulka et al., 1989). Thay vào đó, lời xin lỗi thường xuyên kết hợp các lời giải thích và đề nghị sửa chữa, phạm vi ngôn ngữ và độ phức tạp không thể được dự đoán trước (ví dụ: Page, 2014; Su and Wei, 2018). Thứ hai, các chức năng ngữ dụng-diễn ngôn trong hầu hết các trường hợp được thực hiện thông qua một tập hợp các hình thức ngôn ngữ mở và thiếu ánh xạ trực tiếp và rõ ràng lên các mục từ vựng cụ thể. Ví dụ, Lutzky & Kehoe (2017a) cho thấy rằng trong môi trường trực tuyến, lời xin lỗi có thể được thực hiện bằng cách sử dụng các biểu thức ít điển hình hơn như từ oops, không thường được xem xét trong nghiên cứu dựa trên hình thức về lời xin lỗi. Tương tự, cảm xúc, thái độ và lập trường có thể được thể hiện trong diễn ngôn thông qua một loạt các hình thức từ vựng đa dạng trên các lớp từ như động từ (ví dụ: love), cụm tính từ (ví dụ: extremely talented), và trạng từ (ví dụ: in a much better place) (Hunston, 2010). Sự đa dạng này khiến việc tạo ra một danh sách xác định các mục từ vựng để tìm kiếm trong kho ngữ liệu trở nên không thể. Cuối cùng, một thách thức quan trọng khác trong việc tự động hóa chú thích các đặc điểm ngữ dụng-diễn ngôn phát sinh từ bản chất phụ thuộc vào bối cảnh của chúng. Ví dụ, câu nói "we'll arrive by five o'clock" có thể được hiểu như một dự đoán đơn giản trong một số tình huống, nhưng trong những tình huống khác nó nên được xem như một dự đoán cũng truyền đạt một lời hứa (Weisser, 2015: 85). Tương tự, từ sorry không mang lực lượng ngôn trung của một lời xin lỗi khi nó được sử dụng để đơn giản thể hiện sự đồng cảm với bất hạnh của người khác hoặc khi lời xin lỗi được đề cập trong lời nói gián tiếp.

Với những phức tạp được mô tả ở trên, các nhà nghiên cứu trong ngữ dụng dựa trên kho ngữ liệu có xu hướng áp dụng phương pháp tiếp cận hình thức-chức năng, tập trung vào các dấu hiệu từ vựng nổi tiếng của lực lượng ngôn trung, chẳng hạn như các công thức lịch sự và các dấu hiệu diễn ngôn (O'Keeffe, 2018; Weisser, 2016). Phương pháp này cũng phổ biến trong nghiên cứu diễn ngôn hỗ trợ kho ngữ liệu (CADS), nơi các chức năng giao tiếp thường được điều tra bằng cách xem xét một tập hợp hạn chế các chỉ số từ vựng đáng tin cậy. Ví dụ, Baker et al. (2019) phân tích cách đánh giá được thể hiện trong các bình luận của bệnh nhân về Hệ thống Y tế Quốc gia của Vương quốc Anh bằng cách xem xét 10 từ tích cực và tiêu cực thường xuất hiện nhất được tìm thấy trong kho ngữ liệu. Trong khi phương pháp này có lợi ích là có thể nhân bản và mở rộng, nó có thể bỏ lỡ ít nhất một số cách mà ý nghĩa đánh giá có thể được truyền đạt. Điều này đặc biệt đúng khi các biểu thức đánh giá trải dài nhiều từ và khi ý kiến và cảm xúc được gợi lên thông qua ngôn ngữ ít rõ ràng hơn (Martin & White, 2005).

Trong khi các phương pháp tiếp cận hình thức-chức năng vẫn phổ biến trong cả ngữ dụng kho ngữ liệu và CADS, một khối lượng công việc ngày càng tăng đang chuyển hướng sang phương pháp tiếp cận chức năng-hình thức. Phương pháp này bao gồm chú thích kho ngữ liệu thủ công, tập trung vào hiện tượng ngữ dụng hoặc diễn ngôn cụ thể được nghiên cứu thay vì một tập hợp các đơn vị từ vựng được xác định trước. Một số kho ngữ liệu được chú thích ngữ dụng đã được tạo ra để nghiên cứu các đặc điểm như hành vi ngôn ngữ (Kirk, 2016; Milà-Garcia, 2018), lịch sự/bất lịch sự (Taylor, 2016) và lời khuyên (Põldvere et al., 2022). Trong CADS, các đặc điểm diễn ngôn đã được khám phá thông qua chú thích kho ngữ liệu thủ công bao gồm đánh giá (ví dụ: Cavasso & Taboada, 2021), tính xây dựng và độc tính (Kolhatkar et al., 2020), lập trường (ví dụ: Simaki et al., 2020), ẩn dụ (ví dụ: Fuoli et al., 2022) và các động thái tu từ (ví dụ: Yu, 2022). Chú thích kho ngữ liệu thủ công mang lại hai lợi ích chính so với phân tích hướng hình thức. Thứ nhất, nó cho phép các nhà nghiên cứu xác định và xem xét tất cả các trường hợp của một hiện tượng ngữ dụng-diễn ngôn nhất định, bất kể độ phức tạp từ vựng của chúng. Thứ hai, nó nhạy cảm với bối cảnh bởi vì các người mã hóa con người đọc các văn bản kho ngữ liệu khi họ chú thích chúng và do đó có thể đưa ra các diễn giải chính xác và tinh tế hơn. Tuy nhiên, việc chú thích kho ngữ liệu thủ công đòi hỏi các tài nguyên đáng kể, điều này cản trở khả năng mở rộng và tính thực tế của phương pháp. Ví dụ, Fuoli và Hommerberg (2015) báo cáo rằng trung bình mất một giờ cho mỗi 1000 từ, mặc dù sử dụng một sơ đồ mã hóa tương đối đơn giản. Hơn nữa, chú thích thủ công vốn dĩ liên quan đến tính chủ quan và dễ mắc lỗi không nhất quán và lỗi xuất phát từ các yếu tố như mất tập trung hoặc mệt mỏi nhận thức. Để tăng cường độ tin cậy, các kiểm tra thỏa thuận giữa các người mã hóa có thể được tiến hành. Tuy nhiên, những kiểm tra này làm tăng khối lượng công việc tổng thể, vì cần có đào tạo sâu rộng cho các cộng tác viên. Kết quả là, các kho ngữ liệu được chú thích chức năng có xu hướng tương đối nhỏ, điều này chắc chắn gây ra các vấn đề về khả năng tổng quát hóa các kết luận rút ra từ chúng.

Để hoàn toàn mở khóa tiềm năng của phân tích chức năng-hình thức, chúng ta cần các công cụ tính toán có khả năng tự động chú thích các đặc điểm ngữ dụng-diễn ngôn trong kho ngữ liệu với độ chính xác cao. Một số tiến bộ đã được thực hiện trong nhiệm vụ gắn thẻ hành vi ngôn ngữ tự động. Ví dụ, công cụ chú thích và nghiên cứu đối thoại (DART) của Weisser (2016) được báo cáo là có khả năng đạt được độ chính xác cấp độ con người (Weisser, 2016: 386). Công cụ này sử dụng một thuật toán xác định các mẫu từ vựng thường liên quan đến nhiều hành vi ngôn ngữ khác nhau dựa trên một từ điển đồng nghĩa tích hợp và kết hợp thông tin cú pháp và ngữ nghĩa để tự động suy ra hành vi ngôn ngữ được thực hiện trong mỗi đơn vị diễn ngôn. Trong lĩnh vực NLP, chú thích hành vi ngôn ngữ, thường được gọi là 'Nhận dạng Hành vi Đối thoại', là một nhiệm vụ được thiết lập với một số phương pháp đã cho thấy điểm số chính xác tốt (Zhao & Kawahara, 2019). Trong khi những công cụ này chắc chắn đại diện cho một bước tiến quan trọng, chức năng của chúng bị hạn chế cho nhiệm vụ phân tích hành vi ngôn ngữ. Phát triển các công cụ tương tự cho các nhiệm vụ chú thích khác, chẳng hạn như phân tích lời xin lỗi dựa trên khung ngữ pháp địa phương, là một công việc đáng kể đòi hỏi cả kiến thức ngôn ngữ chuyên môn và kỹ năng lập trình tiên tiến. Ngược lại, LLM có thể được hướng dẫn bằng cách sử dụng các lời nhắc ngôn ngữ tự nhiên, khiến chúng có thể dễ tiếp cận hơn với một phổ rộng hơn các nhà nghiên cứu với các cấp độ chuyên môn tính toán khác nhau. Do đó, trong nghiên cứu này, mục tiêu chính của chúng tôi là khám phá tiềm năng của việc sử dụng LLM để hỗ trợ chú thích ngữ dụng-diễn ngôn, sử dụng ngữ pháp địa phương của lời xin lỗi như một trường hợp kiểm tra. Nếu phương pháp này được chứng minh là khả thi, nó có thể mở đường cho một giai đoạn mới của nghiên cứu quy mô lớn, chức năng-hình thức trong cả ngữ dụng kho ngữ liệu và CADS.

2.2 Chú thích kho ngữ liệu hỗ trợ LLM
Các mô hình ngôn ngữ lớn đang định hình lại các phương pháp tính toán cho ngôn ngữ. Các hệ thống này tận dụng dữ liệu để nắm bắt các cấu trúc ngôn ngữ phức tạp, cho phép tạo văn bản giống con người, trả lời câu hỏi, tóm tắt và nhiều nhiệm vụ khác liên quan đến ngôn ngữ. Các công cụ như ChatGPT và chatbot Bing cung cấp giao diện đối thoại cho LLM, cho phép người dùng tương tác và chỉ đạo hệ thống thông qua các lời nhắc ngôn ngữ tự nhiên.

LLM đang gây ra một sự thay đổi mô hình trong lĩnh vực NLP, nơi chúng được sử dụng cho một loạt các nhiệm vụ và liên tục đạt được hiệu suất tốt nhất (Yang et al., 2023). Trong số các ứng dụng này, nhiệm vụ chú thích văn bản đã thu hút sự chú ý đáng kể. Sự quan tâm này phát sinh từ thực tế là nhiều hệ thống NLP được 'đào tạo' trên các bộ dữ liệu được chú thích thủ công. Có nghĩa là, các hệ thống học từ dữ liệu được mã hóa thủ công, xác định các mẫu và điều chỉnh các cơ chế nội bộ của chúng để hiểu và xử lý dữ liệu tương tự tốt hơn trong tương lai. Do đó, tìm ra một cách hiệu quả và tiết kiệm chi phí để chú thích văn bản là một mục tiêu quan trọng trong NLP. LLM đã thể hiện khả năng ấn tượng trong việc bắt chước hành vi con người, bao gồm suy luận và hiểu biết theo bối cảnh, khiến chúng phù hợp cho các nhiệm vụ chú thích dữ liệu (Yang et al., 2023). Nghiên cứu gần đây về chú thích hỗ trợ LLM trong NLP đã cho thấy kết quả khả quan. Ví dụ, trong một nghiên cứu của Frei & Kramer (2023), LLM đã hoạt động khá tốt trong một nhiệm vụ nhận dạng thực thể được đặt tên (NER) bao gồm tự động xác định các đề cập về thuốc, cường độ của chúng và chẩn đoán trong các văn bản y tế tiếng Đức. Ding et al. (2023) đánh giá LLM trên các nhiệm vụ NLP phổ biến như phân tích tình cảm, trích xuất mối quan hệ và NER. Họ thấy rằng những hệ thống này có thể đạt được độ chính xác cấp độ con người nhưng với chi phí chỉ bằng một phần. Tương tự, Gilardi et al. (2023) chứng minh rằng ChatGPT vượt trội hơn các công nhân đám đông trong các nhiệm vụ như tính liên quan, lập trường, chủ đề và phát hiện khung. Trong khi những kết quả này cho thấy tiềm năng, mức độ mà LLM có thể tạo ra chú thích chính xác cho các hiện tượng cụ thể được quan tâm bởi các nhà nghiên cứu trong ngữ dụng kho ngữ liệu và CADS vẫn chưa rõ ràng. Cho đến nay, nghiên cứu thực nghiệm đánh giá khả năng của chúng chủ yếu tập trung vào các nhiệm vụ chú thích được sử dụng trong NLP. Những nhiệm vụ này có xu hướng thực tế về bản chất và dựa trên các khung phân tích hơi khác so với những khung thường được sử dụng hơn trong ngôn ngữ học kho ngữ liệu.

Một phần thiết yếu của việc sử dụng LLM cho chú thích kho ngữ liệu và các nhiệm vụ ngôn ngữ khác là việc tạo ra các hướng dẫn bằng lời cụ thể để điều kiện hóa mô hình tạo ra các đầu ra mong muốn một cách chính xác. Quá trình này được gọi là kỹ thuật tạo lời nhắc hoặc 'prompting' và là một trọng tâm phát triển nhanh chóng trong nghiên cứu AI (Liu et al., 2023). Một số chiến lược prompting đã được phát triển và thử nghiệm trên nhiều nhiệm vụ NLP, bao gồm chú thích văn bản. Một trong những chiến lược prompting cơ bản nhất là zero-shot prompting, trong đó mô hình chỉ nhận được mô tả về nhiệm vụ và phải dựa vào khả năng hiểu tổng thể của nó để tạo ra đầu ra (Brown et al., 2020). Một kỹ thuật thay thế phổ biến là few-shot prompting, trong đó mô hình được tiếp xúc với một số ít ví dụ liên quan đến nhiệm vụ ('shots') cùng với các đầu ra mong đợi của chúng (Brown et al., 2020). Một số chiến lược prompting phức tạp hơn cũng đã được thử nghiệm. Ví dụ, He et al. (2023) sử dụng few-shot chain-of-thought prompting, bao gồm việc sử dụng một loạt các lời nhắc được kết nối hợp lý, mỗi lời nhắc xây dựng trên lời nhắc trước đó, để đơn giản hóa nhiệm vụ chú thích bằng cách chia nó thành các bước nhỏ hơn và hướng dẫn phản hồi của mô hình. Cụ thể, He et al. (2023) cung cấp cho ChatGPT các định nghĩa danh mục, tiếp theo là một tập hợp các ví dụ được gắn nhãn với các lời biện minh ngắn gọn cho mỗi ví dụ. Theo hướng tương tự, Wei et al. (2023) đề xuất một khung prompting hai giai đoạn cho NER. Giai đoạn đầu tiên sử dụng đối thoại câu hỏi-trả lời với ChatGPT để xác định các loại thực thể, mối quan hệ hoặc sự kiện được tìm thấy trong một câu, giúp thu hẹp nhiệm vụ phân loại. Trong giai đoạn thứ hai, mô hình được yêu cầu khớp các danh mục được tìm thấy trong câu với các từ tương ứng của chúng. Nhận thức được tính trung tâm của prompting trong việc tối ưu hóa hiệu suất của LLM, trong nghiên cứu này chúng tôi rút ra cảm hứng từ công việc được xem xét ở đây để phát triển một chiến lược được thiết kế riêng để chú thích lời xin lỗi. Bằng cách làm như vậy, chúng tôi cung cấp một giao thức có thể nhân bản có thể được áp dụng ở quy mô lớn hơn cho cùng một nhiệm vụ chú thích hoặc được điều chỉnh cho các nhiệm vụ chú thích cấp độ ngữ dụng và diễn ngôn tương tự.

3. Dữ liệu và phương pháp
Để đánh giá tính khả thi và độ chính xác của chú thích ngữ dụng-diễn ngôn hỗ trợ AI, chúng tôi sử dụng GPT-3.5 và GPT-4 để mã hóa các thành phần chức năng của lời xin lỗi dựa trên phương pháp ngữ pháp địa phương (Su and Wei, 2018). Phần này phác thảo quy trình mà chúng tôi đã phát triển cho nhiệm vụ này. Phương pháp bao gồm ba bước chính: 1) định nghĩa nhiệm vụ chú thích, 2) thiết kế một lời nhắc cho phép các LLM được chọn tạo ra các đầu ra được chú thích mong muốn, và 3) đánh giá hiệu suất của các LLM.

3.1 Định nghĩa nhiệm vụ chú thích
Thí nghiệm của chúng tôi tập trung vào nhiệm vụ chú thích ngữ pháp địa phương. Ngữ pháp địa phương là một phương pháp tiếp cận phân tích ngôn ngữ nhằm mô tả các mẫu từ vựng-ngữ pháp liên quan đến một ý nghĩa hoặc chức năng cụ thể (Hunston, 2002: 178). Như đã được chứng minh trong nghiên cứu trước đây, phương pháp ngữ pháp địa phương đặc biệt hữu ích cho việc phân tích các chức năng ngữ dụng, hoặc cụ thể hơn là các hành vi ngôn ngữ như đánh giá (Hunston & Sinclair, 2000; Hunston & Su, 2019), yêu cầu (Su, 2017), xin lỗi (Su & Wei, 2018), từ chối trách nhiệm (Cheng & Ching, 2018) và minh họa (Su & Zhang, 2020).

Phân tích các hành vi ngôn ngữ dựa trên khung ngữ pháp địa phương thường bao gồm năm bước chính. Đầu tiên, chúng tôi xác định các dấu hiệu từ vựng thường thực hiện hành vi ngôn ngữ quan tâm dựa trên công trình trước đây và phân tích kho ngữ liệu thám hiểm. Thứ hai, chúng tôi xây dựng một kho ngữ liệu phụ gồm các phát ngôn có chứa các dấu hiệu từ vựng này. Tiếp theo, chúng tôi phân tích một mẫu từ kho ngữ liệu phụ một cách định tính để xác định các yếu tố chức năng cốt lõi cấu thành hành vi ngôn ngữ đích. Phân tích này được chính thức hóa thành một codebook sẽ hướng dẫn quá trình chú thích. Thứ tư, chúng tôi chú thích thủ công tất cả các phát ngôn trong kho ngữ liệu phụ theo codebook. Cuối cùng, chúng tôi phân tích kho ngữ liệu được chú thích để khám phá các mẫu ngữ pháp địa phương của hành vi ngôn ngữ. LLM có thể được sử dụng để cải thiện hiệu quả và giảm khối lượng công việc cần thiết để thực hiện bước thứ tư của quy trình phân tích ngữ pháp địa phương. Điều quan trọng cần lưu ý là bước đầu tiên của quy trình này dựa trên phương pháp tiếp cận hình thức-chức năng, trong khi bước thứ tư có quan điểm chức năng-đầu tiên, vì các thực hiện từ vựng của các thành phần chức năng của một hành vi ngôn ngữ không được xác định trước. Việc tích hợp các phương pháp tiếp cận hình thức-đầu tiên và chức năng-đầu tiên làm cho phân tích ngữ pháp địa phương trở thành một nền tảng thử nghiệm lý tưởng để đánh giá khả năng của LLM trong mã hóa kho ngữ liệu. Phương pháp này cho phép chúng tôi không chỉ đánh giá khả năng của mô hình trong việc chú thích chính xác các thực hiện từ vựng của các danh mục chức năng mở (tức là, các yếu tố chức năng của một hành vi ngôn ngữ) mà còn đánh giá độ chính xác của nó trong việc mã hóa các dấu hiệu từ vựng được biết là mang lực lượng ngôn trung nhất định trong một số nhưng không phải tất cả các bối cảnh (ví dụ, như đã thảo luận ở trên, sorry có thể không luôn truyền đạt một lời xin lỗi).

Trong nghiên cứu này, chúng tôi tập trung vào việc phân tích ngữ pháp địa phương của hành vi ngôn ngữ xin lỗi bằng tiếng Anh, đã được điều tra trước đây trong một số nghiên cứu (ví dụ: Su, 2021; Su & Wei, 2018). Chúng tôi chọn hành vi ngôn ngữ xin lỗi để thử nghiệm phương pháp của chúng tôi bởi vì nó đã nhận được sự chú ý đáng kể trong ngữ dụng kho ngữ liệu và hiệu quả minh họa các thách thức phổ biến trong việc chú thích các yếu tố diễn ngôn chức năng, như đã thảo luận ở trên. Như một nghiên cứu thám hiểm, 'bằng chứng về khái niệm', việc kiểm tra của chúng tôi được giới hạn trong các phát ngôn xin lỗi được thể hiện bằng từ sorry, đây là dấu hiệu từ vựng được sử dụng phổ biến nhất để xin lỗi bằng tiếng Anh (Lutzky & Kehoe, 2017b). Kho ngữ liệu được sử dụng để phân tích bao gồm 5.539 trường hợp chứa sorry được trích xuất từ Spoken BNC2014 (Love et al., 2017), chứa các cuộc trò chuyện không chính thức trong đời thực giữa những người nói tiếng Anh Anh từ khắp Vương quốc Anh. Mỗi trường hợp dài 20 token.

Theo Su and Wei (2018), bảy yếu tố chức năng thường được liên kết với lời xin lỗi rõ ràng bằng tiếng Anh là: APOLOGISER (cá nhân xin lỗi), APOLOGISING (từ hoặc biểu thức thực hiện lời xin lỗi, tương đương với IFID), FORGIVENESS-SEEKING (hành động tìm kiếm sự tha thứ), APOLOGISEE (người nhận lời xin lỗi), INTENSIFIER (biểu thức tăng cường mức độ hối hận), SPECIFICATION (xác định tội lỗi hoặc lý do để xin lỗi), và HINGE (thiết bị ngữ pháp liên kết các yếu tố chức năng khác nhau). Ví dụ, một lời xin lỗi có thể được hiểu như mẫu "APOLOGISER + HINGE + APOLOGISING" (ví dụ: I'm sorry), hoặc với mẫu "FORGIVENESS-SEEKING + APOLOGISEE" (ví dụ: Forgive me, John). Vì khả năng của LLM trong việc thực hiện chú thích chức năng trên các phát ngôn xin lỗi chưa được thử nghiệm trước đây, chúng tôi chọn bắt đầu với một khung đơn giản hơn, được sắp xếp hợp lý. Do đó, yếu tố FORGIVENESS-SEEKING không được bao gồm trong sơ đồ chú thích của chúng tôi vì nó chủ yếu được thực hiện thông qua các dấu hiệu từ vựng như forgive và pardon, không được sử dụng làm từ tìm kiếm để xây dựng mẫu của chúng tôi. Yếu tố HINGE, đề cập đến động từ to be BE và các từ lớp đóng khác như for và that, không được xem xét vì nó được coi là ít trung tâm hơn đối với thí nghiệm của chúng tôi và có thể gây nhầm lẫn cho LLM. Cuối cùng, chúng tôi quyết định đổi tên yếu tố SPECIFICATION thành REASON, mà chúng tôi mong đợi LLM có thể hiểu dễ dàng hơn. Tóm lại, nhiệm vụ chú thích bao gồm hai bước chính: (1) xác định hành vi ngôn ngữ xin lỗi, và (2) chú thích lời xin lỗi bằng cách sử dụng các thuật ngữ bao gồm APOLOGISING, REASON, APOLOGISER, APOLOGISEE, và INTENSIFIER.

3.2 Thiết kế lời nhắc
Như đã thảo luận ở trên, một khía cạnh quan trọng của việc sử dụng và tối ưu hóa hiệu suất của LLM là việc tạo ra các lời nhắc ngôn ngữ tự nhiên được tạo ra tốt. Quá trình kỹ thuật tạo lời nhắc thường tuân theo một phương pháp tiếp cận thử nghiệm và sai lầm tiến bộ. Các chiến lược khác nhau để hướng dẫn mô hình được thử nghiệm, và kết quả phục vụ như một hướng dẫn để tinh chỉnh lời nhắc. Trong nghiên cứu này, chúng tôi sử dụng chatbot Bing (với chế độ chính xác) để thiết kế và thử nghiệm lời nhắc. Chúng tôi đã tạo ra một lời nhắc ban đầu và đánh giá hiệu quả của nó trên ba mẫu, mỗi mẫu gồm 100 trường hợp chứa sorry. Trong hai vòng thử nghiệm đầu tiên, chúng tôi hệ thống tinh chỉnh lời nhắc để tăng cường hiệu suất chú thích của chatbot Bing. Trong vòng thử nghiệm cuối cùng, lời nhắc được tinh chỉnh mang lại kết quả được chú thích với tỷ lệ chính xác 98%, chứng minh sự phù hợp của nó cho nhiệm vụ chú thích của chúng tôi.

Phiên bản của lời nhắc được sử dụng trong thí nghiệm của chúng tôi được hiển thị trong Phụ lục 1. Kỹ thuật chúng tôi sử dụng là few-shot prompting, trong đó các hướng dẫn nhiệm vụ được làm phong phú với một tập hợp các ví dụ để giúp LLM 'hiểu' logic cơ bản của nhiệm vụ hiện tại. Theo đó, lời nhắc của chúng tôi được tạo thành từ ba thành phần: định nghĩa danh mục, một tập hợp các mẫu được chú thích và hướng dẫn nhiệm vụ, được công thức hóa như một câu hỏi. Do giới hạn token của chatbot Bing, lời nhắc được chia thành hai phần, phải được nhập riêng biệt.

Chúng tôi chọn các mẫu được bao gồm trong lời nhắc dựa trên các tiêu chí sau:

(i) Tính đại diện. Các mẫu được chọn chứa cụm từ học tần suất cao của từ sorry. Để xác định các mẫu cụm từ học tần suất, chúng tôi sử dụng AntConc để trích xuất các cụm 2-gram, 3-gram và 4-gram (với tần suất ≥10) như I'm sorry, sorry I've, really sorry, sorry about that. Những cụm này sau đó được tìm kiếm trong kho ngữ liệu để lấy các trường hợp có thể phục vụ như các mẫu trong lời nhắc.

(ii) Đa dạng. Các mẫu được chọn để bao gồm các mẫu ngữ pháp địa phương khác nhau, nắm bắt sự đa dạng của các biểu thức xin lỗi.

(iii) Tính ngắn gọn. Các thử nghiệm sơ bộ của chúng tôi cho thấy rằng lời nhắc càng ngắn gọn, hiệu suất của LLM trong nhiệm vụ chú thích càng tốt. Do đó, chúng tôi loại trừ các mẫu dư thừa.

Trong quá trình thiết kế và thử nghiệm lời nhắc, chúng tôi đã điều chỉnh các mẫu để cải thiện hiệu suất của chatbot Bing. Khi phân tích các mẫu thử nghiệm, nếu chatbot Bing liên tục mắc các lỗi cụ thể, chúng tôi đã giới thiệu các mẫu liên quan để giúp nó tránh những lỗi đó. Ví dụ, chúng tôi bao gồm các mẫu với thẻ chức năng REASON, tỏ ra khó khăn hơn cho máy xác định so với các thẻ khác. Lời nhắc cuối cùng bao gồm 10 mẫu được chọn cẩn thận.

Ngoài việc chọn các mẫu phù hợp, chúng tôi cũng quan sát thấy rằng nhiều yếu tố khác ảnh hưởng đến hiệu suất của LLM, như được nêu dưới đây:

(i) Bố cục chính thức. Việc sử dụng ranh giới văn bản, chẳng hạn như các đoạn văn bản và định dạng Q&A, tăng cường hiểu biết của LLM về lời nhắc.

(ii) Tính chính xác ngữ pháp. Việc loại bỏ các lỗi ngữ pháp trong các ví dụ kho ngữ liệu đã tăng cường hiệu suất của LLM.

(iii) Độ chính xác thuật ngữ. Việc sử dụng thuật ngữ chính xác trong lời nhắc đã cải thiện hiệu suất của LLM so với việc sử dụng các từ tổng quát hoặc mơ hồ. Ví dụ, máy hiểu rõ hơn biểu thức của hành vi ngôn ngữ xin lỗi hơn biểu thức tổng quát hơn của phát ngôn xin lỗi.

(iv) Tính rõ ràng. Máy tạo ra kết quả chính xác hơn khi chúng tôi xác định các loại yếu tố chức năng cần được xác định trong câu hỏi cuối cùng (Bạn có thể phát hiện hành vi ngôn ngữ xin lỗi và chú thích bất kỳ yếu tố chức năng nào như APOLOGISER, REASON, APOLOGISEE, APOLOGISING, hoặc INTENSIFIER trong phát ngôn sau không?).

(v) Tính ngắn gọn văn bản. Cả hướng dẫn và mẫu đều được giữ ngắn gọn nhất có thể vì các văn bản phức tạp có thể 'gây nhầm lẫn' cho máy.

(vi) Thứ tự văn bản. Thứ tự của các đơn vị văn bản ảnh hưởng đến mức độ ưu tiên chú ý của máy. Trong nhiệm vụ chú thích của chúng tôi, một khó khăn chính liên quan đến yếu tố chức năng REASON. Trong quá trình thử nghiệm lời nhắc, chúng tôi phát hiện rằng việc di chuyển các mẫu chứa yếu tố chức năng REASON lên đầu lời nhắc đã cải thiện hiệu suất của máy trong việc chú thích yếu tố cụ thể.

(vii) Độ rõ ràng nhãn. Các nhãn danh mục minh bạch về mặt ngữ nghĩa, rõ ràng và ít kỹ thuật hơn được LLM hiểu rõ hơn. Ví dụ, việc thay thế thẻ SPECIFICATION bằng thẻ REASON đã tăng cường hiệu suất chú thích của chatbot Bing.

(viii) Ngôn ngữ không phù hợp. Trong các trường hợp mà các văn bản cần được chú thích có chứa ngôn ngữ nhạy cảm hoặc không phù hợp (ví dụ: bitch), chatbot Bing không thể tạo ra văn bản tái tạo những từ đó do các bộ lọc kiểm duyệt nội dung của nó.

Bằng cách xem xét các khía cạnh này và thực hiện các điều chỉnh phù hợp, chúng tôi đã phát triển một lời nhắc hiệu quả hướng dẫn chatbot Bing hoàn thành nhiệm vụ chú thích cho nghiên cứu này.

3.3 Đánh giá hiệu suất
Hiệu suất của LLM trong nhiệm vụ chú thích ngữ pháp địa phương được đánh giá trong hai giai đoạn. Đầu tiên, chúng tôi so sánh hai LLM tiên tiến nhất và được sử dụng rộng rãi nhất, GPT-4, cung cấp sức mạnh cho chatbot Bing, và GPT-3.5, hỗ trợ ChatGPT, để xác định mô hình phù hợp nhất cho nhiệm vụ của chúng tôi. Chúng tôi đánh giá hiệu suất của chúng trên một mẫu 50 trường hợp được lấy từ kho ngữ liệu của chúng tôi. Khi chúng tôi xác định LLM hoạt động tốt nhất, chúng tôi tiến hành so sánh nó với một người chú thích con người. Việc so sánh này bao gồm việc chú thích 1000 trường hợp từ kho ngữ liệu của chúng tôi. Ở giai đoạn này, một trong các tác giả, đóng vai trò là người đánh giá, đánh giá các kết quả được chú thích. Người đánh giá xem xét cả định nghĩa của các thẻ và bối cảnh mở rộng trong mỗi trường hợp để xác định xem một đơn vị văn bản có được chú thích chính xác hay không và liệu một thẻ có được gán một cách đầy đủ hay không. Trong một số trường hợp, một mức độ chủ quan vẫn có thể không thể tránh khỏi do thiếu thông tin bối cảnh toàn diện liên quan đến một đơn vị ngữ dụng.

4. Kết quả
Trong phần này, chúng tôi đầu tiên trình bày phân tích hiệu suất so sánh giữa GPT-3.5/ChatGPT và GPT-4/Bing. Tiếp theo, chúng tôi cho thấy kết quả so sánh giữa LLM hoạt động tốt nhất và một người chú thích con người.

4.1 GPT-3.5 so với GPT-4
Các thí nghiệm được thực hiện sử dụng chatbot ChatGPT và chatbot Bing (với chế độ chính xác), có thể truy cập tại https://chat.openai.com/ và https://www.bing.com/new, tương ứng. Đầu tiên, chúng tôi nhập một lời nhắc giống hệt nhau (Phụ lục A) vào cả hai chatbot. Tiếp theo, chúng tôi cung cấp cho cả hai chatbot một mẫu được chọn ngẫu nhiên gồm 50 trường hợp từ kho ngữ liệu của chúng tôi làm đầu vào. Cuối cùng, chúng tôi thu thập và đánh giá độ chính xác của các trường hợp được chú thích có nguồn gốc từ văn bản đầu ra được tạo ra. Một trường hợp được coi là được chú thích chính xác chỉ khi tất cả các yếu tố ngữ dụng mà nó chứa đều được mã hóa đúng. Kết quả, được trình bày trong Bảng 1, cho thấy rằng GPT-4/Bing rõ ràng vượt trội hơn GPT-3.5/ChatGPT ở cấp độ trường hợp.

Bảng 1. Độ chính xác cấp độ trường hợp thu được với hai LLM được thử nghiệm

GPT-4/Bing GPT-3.5/ChatGPT
Số trường hợp được thử nghiệm 50 50
Số trường hợp được chú thích chính xác 42 25
Độ chính xác cấp độ trường hợp (%) 84 50

Hiệu suất tương đối kém của GPT-3.5/ChatGPT chủ yếu có thể được quy cho các vấn đề sau: 1) nhầm lẫn trong việc gán thẻ, chẳng hạn như chú thích sorry là APOLOGISER thay vì APOLOGISING; 2) xác định sai các thẻ như REASON, INTENSIFIER và các thẻ khác; và 3) không nhất quán trong định dạng chú thích, nơi văn bản được tạo ra khác với các lời nhắc. Ví dụ về những sai sót này được hiển thị trong Phụ lục B. Nhận thức rằng hiệu suất kém của GPT-3.5/ChatGPT có thể liên quan đến các lời nhắc không đầy đủ, chúng tôi đã thực hiện những nỗ lực bổ sung để xác định các chiến lược prompting hiệu quả hơn. Cuối cùng, chúng tôi phát hiện ra rằng GPT-3.5/ChatGPT có thể xác định chính xác hơn các yếu tố chức năng của lời xin lỗi khi văn bản ngoại lai không liên quan đến hành vi ngôn ngữ xin lỗi được loại trừ trước. Nói cách khác, để hiệu quả tiến hành nhiệm vụ chú thích với GPT-3.5/ChatGPT, chúng tôi sẽ cần thiết kế một lời nhắc khác cho mô hình để tiền xử lý và 'làm sạch' các trường hợp kho ngữ liệu để loại bỏ các đoạn văn bản không liên quan cụ thể đến hành vi ngôn ngữ xin lỗi. Tuy nhiên, việc thêm bước tiền xử lý không lý tưởng vì nó sẽ làm phức tạp quy trình chú thích và có thể giới thiệu tiếng ồn tiềm ẩn vào dữ liệu cần được chú thích (ví dụ: giữ lại các phần ngôn ngữ không thực sự chỉ ra lý do cho một lời xin lỗi). Do đó, chúng tôi quyết định chuyển trọng tâm của mình sang đánh giá hiệu suất của GPT-4/Bing trên một mẫu lớn hơn, so sánh nó với chú thích con người.

4.2 GPT-4 so với người chú thích con người
Một tập hợp 1000 trường hợp được chọn ngẫu nhiên từ kho ngữ liệu đã phục vụ như cơ sở để đánh giá khả năng chú thích của GPT-4/Bing so với người chú thích con người. Để đánh giá hiệu suất của chatbot GPT-4/Bing, chúng tôi xử lý từng trường hợp trong số 1000 trường hợp một cách riêng biệt, vì chúng tôi thấy rằng việc nhập nhiều trường hợp cùng lúc mang lại kết quả ít chính xác hơn. Nhiệm vụ chú thích được thực hiện từ ngày 11 tháng 4 đến ngày 28 tháng 4 năm 2023. Một ví dụ về đầu ra được chú thích từ Bing có thể được tìm thấy trong Phụ lục C. Để tạo ra bộ dữ liệu được chú thích để so sánh, chúng tôi tuyển dụng một người chú thích con người và giao cho họ nhiệm vụ mã hóa thủ công cùng một tập hợp các ví dụ. Chúng tôi cung cấp cho người chú thích các hướng dẫn tương tự như những gì chatbot nhận được. Tiếp theo, chúng tôi yêu cầu người chú thích sử dụng chương trình Note Tab để tiến hành ba bài kiểm tra chú thích trên ba mẫu, mỗi mẫu chứa 100 trường hợp được chọn ngẫu nhiên từ kho ngữ liệu. Những bài kiểm tra này được tiến hành để đảm bảo rằng người chú thích hiểu nhiệm vụ đúng cách và để cải thiện sự đồng thuận giữa người chú thích và người đánh giá nhiệm vụ. Khi người chú thích đạt được độ chính xác 100% trên tập hợp trường hợp thứ ba, họ tiến hành mã hóa bộ dữ liệu đầy đủ gồm 1000 trường hợp. Như được báo cáo bởi người chú thích, mất khoảng 4 giờ để hoàn thành nhiệm vụ. Các văn bản được chú thích do chatbot Bing và người chú thích con người tạo ra sau đó được người đánh giá đánh giá.

Theo thực hành tiêu chuẩn trong NLP, chúng tôi đã sử dụng precision, recall và F1-score để đánh giá và so sánh kết quả chú thích ở cấp độ thẻ. Precision là một chỉ số tính toán tỷ lệ dự đoán tích cực chính xác (true positives) trong tổng số dự đoán được thực hiện bởi mô hình hoặc người mã hóa con người (true + false positives). Do đó, để lấy mã REASON làm ví dụ, precision trả lời câu hỏi 'trong tổng số các trường hợp được mã hóa REASON, bao nhiêu thực sự là REASON?'. Nó được tính bằng công thức sau:

precision = TP/(TP+FP) (1)

Recall đo lường tỷ lệ các ví dụ true positive được mô hình hoặc người mã hóa con người xác định chính xác. Vì vậy, để lấy mã REASON làm ví dụ một lần nữa, recall trả lời câu hỏi 'trong tổng số các trường hợp REASON được bao gồm trong mẫu, bao nhiêu thực sự được xác định?'. Nó được tính bằng công thức sau:

recall = TP/(TP+FN) (2)

F1-score kết hợp precision và recall thành một giá trị duy nhất. Nó đại diện cho trung bình điều hòa của precision và recall, cung cấp một đánh giá tổng thể về độ chính xác và phạm vi bao phủ của mô hình cho một danh mục cụ thể. Công thức cho F1-score là:

F1 = 2*precision*recall/(precision+recall) (3)

Như được hiển thị trong Bảng 3, GPT-4/Bing đạt được mức độ chính xác cao ở cấp độ trường hợp, mặc dù hiệu suất của nó hơi thấp hơn so với người mã hóa con người. Tuy nhiên, chatbot vượt trội hơn người mã hóa con người một chút khi chú thích yếu tố chức năng REASON. Trong các phần dưới đây, chúng tôi xem xét hiệu suất của cả GPT-4/Bing và người mã hóa con người cho từng danh mục được xem xét.

Bảng 2. Các chỉ số độ chính xác cho 1000 trường hợp kho ngữ liệu được chú thích bởi GPT-4/Bing và người chú thích con người

GPT-4/Bing người chú thích con người
Độ chính xác cấp độ trường hợp (%) 92,7 95,4
Hiệu suất cấp độ thẻ Precision (%) Recall (%) F1 (%) Precision (%) Recall (%) F1 (%)
NO APOLOGY* 100 71,43 83,33 100 88,78 94,05
APOLOGISING 100,00 99,91 99,95 100 99,91 99,95
REASON 94,74 89,26 91,91 92,86 85,95 89,27
APOLOGISER 91,11 100 95,35 100 98,78 99,39
APOLOGISEE 97,22 83,33 89,74 100 88,10 93,67
INTENSIFIER 100,00 93,18 96,47 100 97,73 98,85

*Danh mục này đề cập đến các trường hợp không chứa lực lượng ngôn trung của lời xin lỗi. Những trường hợp này được xử lý riêng biệt và loại trừ khi tính toán tỷ lệ precision và recall cho mỗi thẻ chức năng.

4.2.1 Nhận dạng NO APOLOGY
Các trường hợp chứa dấu hiệu từ vựng sorry không chỉ ra sự hiện diện của một hành vi ngôn ngữ xin lỗi trực tiếp trong hai kịch bản chính: khi sorry được sử dụng để thể hiện sự đồng cảm với bất hạnh của người khác, như trong Ví dụ 1, và khi lời xin lỗi được đề cập trong lời nói gián tiếp, như trong Ví dụ 2.

(1) over as er as they thought so I'm very sorry to hear that --ANONnameM yeah still you never know something

(2) she sort of said --UNCLEARWORD and he said I'm sorry I'm going to have to cut you off there

Trong mẫu thử nghiệm của chúng tôi, 98 trong số 1000 trường hợp đáp ứng những điều kiện này và do đó không nên được chú thích. Tuy nhiên, chatbot Bing đã nhầm lẫn gắn nhãn 28 trường hợp là lời xin lỗi, trong khi người chú thích con người đã mắc 11 lỗi. Trong số 28 trường hợp bị phân loại sai bởi GPT-4/Bing, 20 trường hợp liên quan đến lời xin lỗi được đề cập trong lời nói gián tiếp. Sự không chính xác này có thể do lời nhắc không chỉ rõ ràng rằng lời xin lỗi trong lời nói gián tiếp nên được coi là NO APOLOGY.

4.2.2 Nhận dạng APOLOGISING
Trong phân tích ngữ pháp địa phương, yếu tố chức năng APOLOGISING có thể được thể hiện thông qua các dấu hiệu từ vựng như sorry, apologise, apologies, v.v. Trong nghiên cứu cụ thể này, chúng tôi chỉ tập trung vào các trường hợp chứa dấu hiệu từ vựng sorry. Trong các trường hợp mà hành vi ngôn ngữ xin lỗi có mặt, mỗi lần xuất hiện của dấu hiệu từ vựng sorry nên được chú thích với thẻ <APOLOGISING>, như được hiển thị trong Ví dụ 3.

(3) what ca - the Qatarian? drinking my water oh <APOLOGISING> sorry </APOLOGISING> <APOLOGISING> sorry </APOLOGISING> I just saw it waving at me I've got (Được chú thích bởi chatbot Bing)

Trong số 902 trường hợp xin lỗi, cả chatbot Bing và người chú thích con người đều chú thích chính xác tất cả trừ một trường hợp là APOLOGISING, như được hiển thị trong Ví dụ (4) và Ví dụ (5). Điều này có nghĩa là GPT-4/Bing đã hoạt động cực kỳ tốt trong việc nhận dạng yếu tố chức năng này được liên kết với một hình thức cố định (tức là sorry) trong nhiệm vụ chú thích của chúng tôi.

(4) lady who works at the Kitchen Garden Café oh so <APOLOGISING> sorry </APOLOGISING> <APOLOGISING> sorry </APOLOGISING> you <APOLOGISEE> sorry </APOLOGISEE> yeah go on then apologies so she (Được chú thích bởi chatbot Bing, sorry được mã hóa sai)

(5) and all that kind of stuff yeah and and it <REASON> sorry </REASON> its the first population would have a population of like (Chú thích con người, sorry được mã hóa sai)

4.2.3 Nhận dạng REASON
Yếu tố chức năng REASON giải thích tại sao ai đó xin lỗi hoặc họ xin lỗi về điều gì. Nhận dạng yếu tố này đòi hỏi khả năng mạnh mẽ để hiểu ý nghĩa của các từ trong bối cảnh. Trong số 121 trường hợp REASON, chatbot Bing đã chú thích chính xác 108 trường hợp (xem Ví dụ 6). Chỉ có 13 trường hợp không được chú ý đến (xem Ví dụ 7), và 6 trường hợp bị gắn nhãn sai (xem Ví dụ 8). Những phát hiện này làm nổi bật khả năng ấn tượng của GPT-4 trong việc tự động phân biệt lý do cho một lời xin lỗi và chú thích chính xác các trường hợp của danh mục chức năng mở này, tất cả với các ví dụ tối thiểu và không có đầu vào về các dấu hiệu ngôn ngữ cụ thể liên quan đến nó.

(6) August birthday --UNCLEARWORD you just had your birthday happy birthday <APOLOGISING> sorry </APOLOGISING> <REASON> I missed it </REASON> did you have a good time? (Được chú thích bởi chatbot Bing, REASON được xác định chính xác)

(7) <APOLOGISING> sorry </APOLOGISING> I forgot she was honest that would be lying <APOLOGISING> sorry </APOLOGISING> I forgot your birthday you don't mean anything ah (Được chú thích bởi chatbot Bing, REASON không được xác định)

(8) don't moan at me leave me alone <APOLOGISER> I </APOLOGISER> 'm <APOLOGISING> sorry </APOLOGISING> <REASON> I'm just trying to make it nice for you </REASON> (Được chú thích bởi chatbot Bing, REASON được xác định sai)

Trên thực tế, kết quả cho thấy rằng người chú thích con người đã không vượt trội hơn GPT-4/Bing trong việc chú thích chính xác REASON cho lời xin lỗi. Cụ thể, có 17 trường hợp bị bỏ qua (Ví dụ 9), trong khi 8 trường hợp bị phân loại sai (Ví dụ 10). Điều quan trọng cần lưu ý là những lỗi này không nhất thiết ngụ ý thiếu hụt trong khả năng của người chú thích để phân biệt nguyên nhân cơ bản của một lời xin lỗi. Thay vào đó, chúng có thể được quy cho mệt mỏi nhận thức xuất phát từ sự phức tạp và thời gian kéo dài của nhiệm vụ.

(9) and then --UNCLEARWORD beer when we're there? --UNCLEARWORD <APOLOGISING> sorry </APOLOGISING> just landed in on your shoe would you like to (Chú thích con người, REASON không được xác định)

(10) hold on I've got the digital storytelling up oh <APOLOGISING> sorry </APOLOGISING> <REASON> I'll tell you about this </REASON> one erm it says (Chú thích con người, REASON được xác định sai)

4.2.4 Nhận dạng APOLOGISER
Yếu tố chức năng APOLOGISER đề cập đến người xin lỗi. Trong tiếng Anh, các hình thức từ vựng điển hình cho APOLOGISER bao gồm đại từ ngôi thứ nhất I và we (Ví dụ 8 và Ví dụ 9). GPT-4/Bing đã thành công xác định tất cả 164 trường hợp APOLOGISER, trong khi người chú thích con người đã vô tình bỏ qua hai trường hợp. Tuy nhiên, AI đã phân loại sai 16 trường hợp là APOLOGISER, nơi hình thức từ vựng I thực sự được sử dụng như một chủ ngữ của một hành vi ngôn ngữ khác (Ví dụ 11).

(11) you stop clicking that pen? it's very annoying <APOLOGISING> sorry </APOLOGISING> <APOLOGISER> I </APOLOGISER> 'm not saying the same thing there's people (Được chú thích bởi chatbot Bing)

4.2.5 Nhận dạng APOLOGISEE
Yếu tố chức năng APOLOGISEE chỉ ra người nhận dự định của một lời xin lỗi, như được minh họa trong Ví dụ 12. Tương tự như yếu tố chức năng REASON, khía cạnh này không được thể hiện thông qua các hình thức từ vựng cố định và việc nhận dạng nó đòi hỏi máy phải có nắm bắt mạnh mẽ về ngôn ngữ trong bối cảnh. Tỷ lệ recall của GPT-4/Bing cho APOLOGISEE tương đối thấp hơn so với APOLOGISER và APOLOGISING, được liên kết mạnh mẽ hơn với các hình thức ngôn ngữ thông thường. Trong số 42 trường hợp APOLOGISEE, 7 trường hợp không được nhận dạng (Ví dụ 13), và một trường hợp bị phân loại sai. Ngược lại, người chú thích con người đã hoạt động tốt hơn một chút, chỉ bỏ qua 5 trường hợp và không xác định sai.

(12) it well we do not have really any mm? <APOLOGISING> sorry </APOLOGISING> <APOLOGISEE> darling </APOLOGISEE> what did you say? I didn't say. (Được chú thích bởi chatbot Bing, APOLOGISEE được xác định chính xác)

(13) whoops ah making a right dog's dinner of this <APOLOGISING> sorry </APOLOGISING> man I'll have a go have a go well (Được chú thích bởi chatbot Bing, APOLOGISEE không được xác định)

4.2.6 Nhận dạng INTENSIFIER
INTENSIFIER đề cập đến yếu tố tăng cường cường độ hoặc mức độ của một lời xin lỗi. Trong số 44 trường hợp INTENSIFIER trong mẫu của chúng tôi, người chú thích con người chỉ bỏ lỡ một trường hợp, trong khi GPT-4/Bing đã không phát hiện ra ba trường hợp. Tuy nhiên, các lỗi của máy không nhất thiết chỉ ra thiếu hiểu biết về ý nghĩa của danh mục này. Trong một số trường hợp, chatbot Bing đã nhận dạng chính xác hình thức ngôn ngữ bị bỏ lỡ ở những trường hợp khác, như được hiển thị trong Ví dụ (14) và (15), tương ứng.

(14) ? Quite silly nice oh yeah well <APOLOGISER> I </APOLOGISER> 'm <INTENSIFIER> very </INTENSIFIER> <APOLOGISING> sorry </APOLOGISING> <REASON> I had to bale </REASON> no probs no problem it did (Được chú thích bởi chatbot Bing, very được xác định là INTENSIFIER)

(15) annoying when I was a little boy <APOLOGISER> I </APOLOGISER> 'm very <APOLOGISING> sorry </APOLOGISING> I I hear he's like two little boys I (Được chú thích bởi chatbot Bing, very không được xác định là INTENSIFIER)

4.2 Tóm tắt các phát hiện
Để khám phá tiềm năng của việc tận dụng các mô hình ngôn ngữ lớn (LLM) để tự động hóa chú thích các đặc điểm ngữ dụng-diễn ngôn trong kho ngữ liệu, chúng tôi đã tiến hành một nghiên cứu so sánh bao gồm GPT-3.5 (được thực hiện trong ChatGPT), GPT-4 (cung cấp sức mạnh cho chatbot Bing) và một người chú thích con người. Các phát hiện của nghiên cứu chúng tôi cho thấy rằng GPT-4/Bing đã thể hiện hiệu suất vượt trội trong một số khía cạnh chính khi so sánh với GPT-3.5/ChatGPT trong nhiệm vụ chú thích các yếu tố chức năng liên quan đến hành vi ngôn ngữ xin lỗi. Đầu tiên, GPT-4/Bing liên tục tạo ra đầu ra một cách ổn định hơn, trong khi GPT-3.5/ChatGPT hiển thị sự biến động trong phản hồi của nó trên các lượt hội thoại khác nhau. Thứ hai, GPT-4/Bing liên tục tuân thủ định dạng được chỉ định để trình bày văn bản được chú thích theo các lời nhắc đã cho. Thứ ba, GPT-4/Bing đã thể hiện mức độ chính xác cao trong việc sử dụng thẻ, trong khi GPT-3.5/ChatGPT thỉnh thoảng có các sai sót, chẳng hạn như thay thế thẻ <APOLOGISER> cho <APOLOGISING>. Cuối cùng, Bing đã cho thấy sự nắm bắt tổng thể mạnh mẽ hơn về các thẻ ngữ pháp địa phương. Dựa trên những phát hiện này, chúng tôi đề xuất rằng việc sử dụng GPT-4, được thực hiện trong chatbot Bing, sẽ là lựa chọn phù hợp hơn để tự động hóa chú thích các yếu tố ngữ pháp địa phương.

Để xác định mức độ mà nhiệm vụ chú thích có thể được tự động hóa hoàn toàn hoặc liệu sự can thiệp của con người có vẫn cần thiết hay không, chúng tôi đã tiến hành phân tích so sánh hiệu suất giữa GPT-4/Bing và một người chú thích con người. Kết quả cho thấy rằng chatbot Bing đã đạt được tỷ lệ chính xác ấn tượng ở cấp độ trường hợp là 92,7%, chỉ thấp hơn một chút so với độ chính xác của người chú thích con người là 95,4%.

Khi xem xét hiệu suất cấp độ thẻ, cả GPT-4/Bing và người chú thích con người đều cho thấy các mức độ chính xác khác nhau. Sự biến động về độ chính xác được liên kết với mức độ linh hoạt của các hình thức ngôn ngữ đại diện cho các chức năng ngữ pháp địa phương. Các thẻ liên quan đến các hình thức cao thông thường nói chung được chú thích chính xác hơn. Ví dụ, đối với thẻ APOLOGISING được thực hiện bởi sorry, cả chatbot Bing và người chú thích con người đều đạt được điểm F1 là 99,95%. Đối với thẻ APOLOGISER, chủ yếu được thể hiện bởi đại từ ngôi thứ nhất I, GPT-4/Bing đạt được điểm F1 là 95,35%, trong khi người chú thích con người đạt được 99,39%. Tuy nhiên, mối liên hệ mạnh mẽ giữa chức năng và hình thức thỉnh thoảng thúc đẩy GPT-4/Bing thực hiện các tổng quát hóa quá rộng. Trong một số trường hợp, chatbot Bing liên tục phân loại đại từ I là APOLOGISER trong các đoạn văn bản không liên quan xuất hiện cạnh phát ngôn xin lỗi đích, trong khi người chú thích con người không thể hiện lỗi cụ thể này, duy trì tỷ lệ precision hoàn hảo là 100%.

Các danh mục chức năng được thể hiện thông qua một loạt tài nguyên ngôn ngữ rộng lớn và đa dạng hơn đã đưa ra thách thức cho cả GPT-4/Bing và người chú thích con người. Hai ví dụ chính là thẻ REASON và APOLOGISEE. GPT-4/Bing đạt được điểm F1 là 91,91% và 89,74% cho những thẻ này, trong khi người chú thích con người đạt được điểm 89,27% và 93,67%, tương ứng. Mặc dù có những khác biệt nhỏ, điều quan trọng cần lưu ý là Bing đã hoạt động tốt trong việc chú thích những thẻ này, thể hiện khả năng hiểu ngôn ngữ và chú thích mạnh mẽ của nó.

Điểm yếu đáng chú ý nhất trong hiệu suất của GPT-4/Bing liên quan đến việc nhận dạng NO APOLOGY, với tỷ lệ recall chỉ 71,43%. Ngược lại, người chú thích con người đạt được 88,78%. Cụ thể, chatbot Bing có xu hướng 1) hiểu sai các trường hợp mà sorry được sử dụng để thể hiện sự đồng cảm đối với ai đó và 2) nhận dạng sai các trường hợp mà lời xin lỗi được đề cập trong lời nói gián tiếp. Trong khi lỗi trước có thể chỉ ra điểm yếu trong hiểu biết theo bối cảnh, lỗi sau có thể được tránh bằng cách cung cấp các mẫu liên quan và hướng dẫn rõ ràng hơn trong lời nhắc.

5. Kết luận
Chú thích là một khía cạnh quan trọng của ngôn ngữ học kho ngữ liệu đương đại, giúp nắm bắt các mẫu phức tạp của cấu trúc và sử dụng ngôn ngữ. Trong khi một số đặc điểm ngôn ngữ có thể được chú thích tự động tương đối dễ dàng, các yếu tố ngữ dụng và diễn ngôn vẫn đòi hỏi chú thích thủ công do sự phức tạp của chúng và thiếu ánh xạ trực tiếp và rõ ràng lên các hình thức từ vựng cụ thể. Tuy nhiên, chú thích thủ công tốn thời gian và dễ mắc lỗi, điều này đã cản trở khả năng mở rộng và tiềm năng của các phương pháp tiếp cận chức năng-hình thức trong ngôn ngữ học kho ngữ liệu cho đến nay. Với bối cảnh này, nghiên cứu này đã đặt ra mục tiêu khám phá khả năng tự động hóa quá trình chú thích kho ngữ liệu ngữ dụng-diễn ngôn bằng cách tận dụng khả năng xử lý ngôn ngữ tiên tiến của LLM. Để đạt được mục tiêu này, chúng tôi đã so sánh hiệu suất của GPT-3.5, mô hình cung cấp sức mạnh cho ChatGPT, GPT-4, mô hình đằng sau chatbot Bing và một người mã hóa con người trong nhiệm vụ chú thích các thành phần chức năng của lời xin lỗi bằng tiếng Anh dựa trên khung ngữ pháp địa phương (Su & Wei, 2018).

Kết quả của chúng tôi cho thấy rằng phân tích ngữ pháp địa phương có thể được thực hiện với chú thích hỗ trợ LLM và trong nghiên cứu điển hình của chúng tôi, GPT-4 đã hoạt động tốt hơn GPT-3.5 trong nhiệm vụ chú thích được giao. Điều này chỉ ra tính khả thi của việc sử dụng LLM để tự động hóa chú thích ngữ pháp địa phương của các hành vi ngôn ngữ và tiếp tục phát triển các kho ngữ liệu được chú thích hành vi ngôn ngữ, điều này sẽ là một đóng góp đáng kể cho ngữ dụng kho ngữ liệu. Quan trọng hơn, khám phá của chúng tôi chứng minh rằng độ chính xác tổng thể của GPT-4 tiến gần đến của một người chú thích con người, điều này cho thấy rằng việc sử dụng LLM để hỗ trợ trong nhiệm vụ chú thích lời xin lỗi, và mở rộng ra các hành vi ngôn ngữ khác, là một lựa chọn khả thi. Tuy nhiên, để tăng cường độ tin cậy, sự giám sát của con người vẫn cần thiết. Trong suốt nghiên cứu của chúng tôi, chúng tôi đã ghi nhận sự biến động trong hiệu suất của chatbot Bing tùy thuộc vào loại thẻ. Nói chung, các thẻ liên kết với các biểu thức ngôn ngữ công thức đạt được điểm chính xác cao hơn, trong khi những thẻ dựa trên các hình thức ngôn ngữ linh hoạt mang lại điểm thấp hơn. Thỉnh thoảng, chatbot Bing cũng thể hiện sự cứng nhắc quá mức, chú thích sai các hình thức cụ thể ngay cả khi chúng phục vụ một chức năng ngữ dụng khác. Việc xác định những thẻ nào có khả năng yêu cầu xác thực của con người đòi hỏi thêm thí nghiệm với một loạt rộng hơn các nhiệm vụ chú thích. Mặc dù có những hạn chế này, tuy nhiên, điểm chính xác tổng thể vẫn mạnh mẽ, có nghĩa là LLM có thể được sử dụng như một kỹ thuật 'lượt đầu' để tự động tạo ra các chú thích dự kiến để được xác thực bởi một người mã hóa con người. Điều này vẫn sẽ giảm đáng kể khối lượng công việc tổng thể liên quan đến chú thích kho ngữ liệu ngữ dụng-diễn ngôn, làm cho quá trình này hiệu quả hơn đáng kể và dễ quản lý.

Nghiên cứu hiện tại chỉ tập trung vào việc chú thích lời xin lỗi, và các ví dụ được xem xét bị giới hạn trong các biểu thức xin lỗi có từ sorry. Như đã giải thích trong Phần 3.1, các ví dụ xin lỗi chúng tôi sử dụng để kiểm tra phương pháp của mình bao gồm các thành phần mở như REASON, và không phải tất cả các lần xuất hiện của sorry đều tạo thành một lời xin lỗi thực sự, khiến đây trở thành một kịch bản thử nghiệm ban đầu lý tưởng cho mã hóa hỗ trợ LLM. Tuy nhiên, điều quan trọng là phải thừa nhận rằng các dấu hiệu từ vựng khác của lời xin lỗi tồn tại và cần nhiều nghiên cứu hơn để xác định liệu hiệu suất mạnh mẽ được quan sát ở đây có thể được nhân bản với các phát ngôn xin lỗi chứa nhiều dấu hiệu từ vựng đa dạng hơn, cũng như các hành vi ngôn ngữ và đặc điểm diễn ngôn khác hay không. Ngoài ra, vẫn cần xác định liệu những mô hình này có thể duy trì hiệu suất của chúng khi được áp dụng cho các văn bản hoàn chỉnh thay vì các câu riêng lẻ cũng như dữ liệu khác ngoài cuộc trò chuyện nói hay không. Mặc dù có những hạn chế và câu hỏi mở này, những phát hiện của chúng tôi rất khích lệ, đặc biệt là với tốc độ phát triển nhanh chóng đáng kinh ngạc mà khả năng của LLM đã phát triển. Chúng tôi tin rằng công nghệ này có thể cách mạng hóa cách chúng ta thực hiện ngữ dụng và phân tích diễn ngôn dựa trên kho ngữ liệu bằng cách cho phép nghiên cứu chức năng-hình thức định lượng ở quy mô lớn hơn nhiều so với trước đây. Do đó, chúng tôi kêu gọi nghiên cứu thêm để khám phá các ứng dụng tiềm năng của phương pháp này trong phân tích các hiện tượng ngữ dụng và diễn ngôn khác.

Một điểm tập trung quan trọng của nghiên cứu chúng tôi xoay quanh việc thiết kế các chiến lược prompting hiệu quả cho nhiệm vụ chú thích lời xin lỗi. Lời nhắc chúng tôi đã tạo ra cho nhiệm vụ cụ thể này có tiềm năng để tăng cường thêm nhằm tăng cường độ chính xác, đặc biệt là dưới ánh sáng của những phát hiện của chúng tôi về việc xác định các trường hợp không xin lỗi. Hơn nữa, nó có thể phục vụ như một mẫu có giá trị để hướng dẫn các nỗ lực chú thích kho ngữ liệu hỗ trợ LLM khác. Nghiên cứu của chúng tôi đã chứng minh rằng một phương pháp few-shot prompting, có các định nghĩa danh mục đơn giản và phản hồi mô hình, có thể mang lại kết quả mạnh mẽ. Ngoài ra, chúng tôi đã cung cấp một số gợi ý về các yếu tố có thể ảnh hưởng đến hiệu suất LLM và cách xây dựng các ví dụ ngôn ngữ hiệu quả hướng dẫn mô hình đến câu trả lời đúng. Nhìn chung, khả năng sử dụng các lời nhắc ngôn ngữ tự nhiên để cho phép LLM thực hiện các nhiệm vụ chú thích ngôn ngữ cụ thể làm cho phương pháp chú thích hỗ trợ LLM có thể tiếp cận cao cho các nhà ngôn ngữ học mà không có chuyên môn về lập trình. Chúng tôi hy vọng nghiên cứu của chúng tôi sẽ khuyến khích những người khác áp dụng chú thích hỗ trợ LLM cho các đặc điểm ngữ dụng-diễn ngôn khác nhau.

Tài liệu tham khảo
Baker, P., Brookes, G., & Evans, C. (2019). The language of patient feedback: A corpus linguistic study of online health communication. Routledge.

Blum-Kulka, S., House, J., & Kasper, G. (1989). Cross-cultural Pragmatics: Requests and Apologies. Ablex Publishing Corporation.

Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). Language models are few-shot learners. Advances in neural information processing systems, 33, 1877-1901.

Cavasso, L., & Taboada, M. (2021). A corpus analysis of online news comments using the Appraisal framework. Journal of Corpora and Discourse Studies, 4, 1-38.

Cheng, W., & Ching, T. (2018). Not a Guarantee of Future Performance: The Local Grammar of Disclaimers. Applied Linguistics, 39(3), 269–301.

Ding, B., Qin, C., Liu, L., Bing, L., Joty, S., & Li, B. (2022). Is GPT-3 a good data annotator?. arXiv preprint arXiv:2212.10450.

Frei, J., & Kramer, F. (2023). Annotated dataset creation through large language models for non-english medical NLP. Journal of Biomedical Informatics, 145(104478).

Fuoli, M., & Hommerberg, C. (2015). Optimising transparency, reliability and replicability: Annotation principles and inter-coder agreement in the quantification of evaluative expressions. Corpora, 10(3), 315-349.

Fuoli, M., Littlemore, J., & Turner, S. (2022). Sunken ships and screaming banshees: metaphor and evaluation in film reviews. English Language & Linguistics, 26(1), 75-103.

Garside, R., Leech, G. N., & McEnery, A. (1997). Corpus Annotation: Linguistic Information from Computer Text Corpora. Longman.

Garside, R., & Smith, N. (1997). A hybrid grammatical tagger: CLAWS4. In R. Garside, G. Leech, & T. McEnery (Eds.), Corpus Annotation: Linguistic Information from Computer Text Corpora (pp. 102–121). Longman.

Gilardi, F., Alizadeh, M., & Kubli, M. (2023). Chatgpt outperforms crowd-workers for text-annotation tasks. arXiv preprint arXiv:2303.15056.

He, X., Lin, Z., Gong, Y., Jin, A., Zhang, H., Lin, C., Jiao, J., Yiu, S. M., Duan, N., & Chen, W. (2023). Annollm: Making large language models to be better crowdsourced annotators. arXiv Preprint arXiv:2303.16854.

Hunston, S. (2002). Pattern grammar, language teaching, and linguistic variation: Applications of a corpus-driven grammar. In R. Reppen, S. Fitzmaurice, & D. Biber (Eds.), Using corpora to explore linguistic variation (pp. 167–183). John Benjamins.

Hunston, S. (2010). Corpus Approaches to Evaluation: Phraseology and Evaluative Language. Routledge.

Hunston, S., & Sinclair, J. (2000). A local grammar of evaluation. In S. Hunston & G. Thompson (Eds.), Evaluation in text. Oxford University Press.

Hunston, S., & Su, H. (2019). Patterns, constructions, and local grammar: A case study of 'evaluation.' Applied Linguistics, 40(4), 567–593.

Kirk, J. M. (2016). The pragmatic annotation scheme of the SPICE-Ireland corpus. International Journal of Corpus Linguistics, 21(3), 299-322.

Kolhatkar, V., Wu, H., Cavasso, L., Francis, E., Shukla, K., & Taboada, M. (2020). The SFU opinion and comments corpus: A corpus for the analysis of online news comments. Corpus Pragmatics, 4, 155-190.

Leech, G. (1993). Corpus annotation schemes. Literary and linguistic computing, 8(4), 275-281.

Leech, G. (1997). Introducing corpus annotation. In Corpus Annotation: Linguistic Information from Computer Text Corpora. Routledge.

Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., & Neubig, G. (2023). Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. ACM Computing Surveys, 55(9), 1–35.

Love, R., Dembry, C., Hardie, A., Brezina, V., & McEnery, T. (2017). The Spoken BNC2014: Designing and building a spoken corpus of everyday conversations. International Journal of Corpus Linguistics, 22(3), 319–344. https://doi.org/10.1075/ijcl.22.3.02lov

Lutzky, U., & Kehoe, A. (2017a). "Oops, I didn't mean to be so flippant". A corpus pragmatic analysis of apologies in blog data. Journal of Pragmatics, 116, 27-36.

Lutzky, U., & Kehoe, A. (2017b). "I apologise for my poor blogging": Searching for apologies in the Birmingham Blog Corpus. Corpus Pragmatics, 1(1), 37-56.

Martin, J., & White, P. R. R. (2005). The Language of Evaluation: Appraisal in English. Palgrave Macmillan.

McEnery, T., & Hardie, A. (2012). Corpus Linguistics. Cambridge University Press.

McEnery, T., & Wilson, A. (2001). Corpus Linguistics: An Introduction. Edinburgh University Press.

Milà-Garcia, A. (2018). Pragmatic annotation for a multi-layered analysis of speech acts: A methodological proposal. Corpus Pragmatics, 2(3), 265-287.

O'Keeffe, A. (2018) "Corpus-based function-to-form approaches". In A. H. Jucker, K. P. Schneider and W. Bublitz (Eds) Methods in Pragmatics. Berlin: Mouton de Gruyter, 587 – 618.

Page, R. (2014). Saying 'sorry': Corporate apologies posted on Twitter. Journal of pragmatics, 62, 30-45.

Põldvere, N., De Felice, R., & Paradis, C. (2022). Advice in conversation: Corpus pragmatics meets mixed methods. Cambridge Elements in Pragmatics.

Rayson, P., Archer, D., Piao, S., & McEnery, T. (2004). The UCREL semantic analysis system. In Proceedings of the Workshop on Beyond Named Entity Recognition: Semantic Labelling for NLP Tasks in Association with the LREC 2004 (pp. 7–12).

Rühlemann, C., & Aijmer, K. (2015). Corpus pragmatics: Laying the foundations. In Corpus Pragmatics: A handbook (pp. 1–28). Cambridge University Press.

Simaki, V., Paradis, C., Skeppstedt, M., Sahlgren, M., Kucher, K., & Kerren, A. (2020). Annotating speaker stance in discourse: the Brexit Blog Corpus. Corpus Linguistics and Linguistic Theory, 16(2), 215-248.

Su, H. (2017). Local grammars of speech acts: An exploratory study. Journal of Pragmatics, 111, 72–83.

Su, H. (2021). Changing patterns of apology in spoken British English: A local grammar based diachronic investigation. Pragmatics and Society, 12(3), 410–436. https://doi.org/10.1075/ps.18031.su

Su, H., & Wei, N. (2018). "I'm really sorry about what I said": A local grammar of apology. Pragmatics. Quarterly Publication of the International Pragmatics Association (IPrA), 28(3), 439–462. https://doi.org/10.1075/prag.17005.su

Su, H., & Zhang, L. (2020). Local grammars and discourse acts in academic writing: A case study of exemplification in Linguistics research articles. Journal of English for Academic Purposes, 43, 100805, 1-11. https://doi.org/10.1016/j.jeap.2019.100805

Taylor, C. (2016). Mock Politeness in English and Italian. John Benjamins.

Wei, X., Cui, X., Cheng, N., Wang, X., Zhang, X., Huang, S., Xie, P., Xu, J., Chen, Y., Zhang, M., Jiang, Y., & Han, W. (2023). Zero-Shot Information Extraction via Chatting with ChatGPT (arXiv:2302.10205). arXiv. http://arxiv.org/abs/2302.10205

Weisser, M. (2015). Speech act annotation. In C. Rühlemann & K., Aijmer (Eds.), Corpus Pragmatics: A handbook (pp. 84–110). Cambridge University Press.

Weisser, M. (2016). DART – The dialogue annotation and research tool. Corpus Linguistics and Linguistic Theory, 12(2).

Yang, J., Jin, H., Tang, R., Han, X., Feng, Q., Jiang, H., Yin, B., & Hu, X. (2023). Harnessing the power of llms in practice: A survey on chatgpt and beyond. arXiv Preprint arXiv:2304.13712.

Zhao, T., & Kawahara, T. (2019). Joint dialog act segmentation and recognition in human conversations using attention to dialog context. Computer Speech & Language, 57, 108-127.

Yu, D., (2022). Cross-cultural Genre Analysis: Investigating Chinese, Italian and English CSR reports. London/New York: Routledge.

Phụ lục
Phụ lục A. Lời nhắc được nhập vào chatbot của Bing và ChatGPT
(Bộ đầu tiên)
Vui lòng học nội dung sau.
Hành vi ngôn ngữ xin lỗi có thể chứa các yếu tố chức năng sau:
APOLOGISING: yếu tố chỉ ra hành vi xin lỗi
REASON: tội lỗi hoặc lý do để xin lỗi
APOLOGISER: người xin lỗi
APOLOGISEE: người được xin lỗi
INTENSIFIER: yếu tố nâng cao mức độ xin lỗi

Dưới đây là một số ví dụ:
Câu hỏi: Bạn có thể chú thích hành vi ngôn ngữ xin lỗi trong phát ngôn "Ah, I'm really sorry for all that."?
Trả lời: Phiên bản được chú thích là: Ah, <APOLOGISER> I </APOLOGISER> 'm <INTENSIFIER> really </INTENSIFIER> <APOLOGISING> sorry </APOLOGISING> <REASON> for all that </REASON>.

Câu hỏi: Bạn có thể chú thích hành vi ngôn ngữ xin lỗi trong phát ngôn "Sorry about that, but I've got to go to work."?
Trả lời: Phiên bản được chú thích là: <APOLOGISING> Sorry </APOLOGISING> <REASON> about that </REASON>, but I've got to go to work.

Câu hỏi: Bạn có thể chú thích hành vi ngôn ngữ xin lỗi trong phát ngôn "Hello Mr [gap:name], I'm sorry to bother you, my name is Kathy and I represent"?
Trả lời: Phiên bản được chú thích là: Hello <APOLOGISEE> Mr [gap:name] </APOLOGISEE>, <APOLOGISER> I </APOLOGISER> 'm <APOLOGISING> sorry </APOLOGISING> <REASON> to bother you </REASON>, my name is Kathy and I represent

Câu hỏi: Bạn có thể chú thích hành vi ngôn ngữ xin lỗi trong phát ngôn "Sorry sorry Mr [gap:name], I moved too quickly for you."?
Trả lời: Phiên bản được chú thích là: <APOLOGISING> Sorry </APOLOGISING> <APOLOGISING> sorry </APOLOGISING> <APOLOGISEE> Mr [gap:name] </APOLOGISEE>, <REASON> I moved too quickly for you </REASON>

(Bộ thứ hai)
Dưới đây là một số ví dụ khác:
Câu hỏi: Bạn có thể chú thích hành vi ngôn ngữ xin lỗi trong phát ngôn "I'm sorry to hear that"?
Trả lời: Không có hành vi ngôn ngữ xin lỗi nào xuất hiện trong phát ngôn "I'm sorry to hear that".

Câu hỏi: Bạn có thể chú thích hành vi ngôn ngữ xin lỗi trong phát ngôn "I felt sorry for your loss"?
Trả lời: Không có hành vi ngôn ngữ xin lỗi nào xuất hiện trong phát ngôn "I felt sorry for your loss".

Câu hỏi: Bạn có thể chú thích hành vi ngôn ngữ xin lỗi trong phát ngôn "I'm sorry that I've lost it"?
Trả lời: Phiên bản được chú thích là: <APOLOGISER> I </APOLOGISER> 'm <APOLOGISING> sorry </APOLOGISING> <REASON> that I've lost it </REASON>.

Câu hỏi: Bạn có thể chú thích hành vi ngôn ngữ xin lỗi trong phát ngôn "Er, I think there is a tendending now, for them to say, oh, I'm terribly sorry, we can only do this against payment."?
Trả lời: Phiên bản được chú thích là: Er, I think there is a tendending now, for them to say, oh, <APOLOGISER> I </APOLOGISER> 'm <INTENSIFIER> terribly </INTENSIFIER> <APOLOGISING> sorry </APOLOGISING>, <REASON> we can only do this against payment </REASON>.

Câu hỏi: Bạn có thể chú thích hành vi ngôn ngữ xin lỗi trong phát ngôn "Oh sorry darling I'm not running off with you."?
Trả lời: Phiên bản được chú thích là: Oh <APOLOGISING> sorry </APOLOGISING> <APOLOGISEE> darling </APOLOGISEE> I'm not running off with you.

Câu hỏi: Bạn có thể chú thích hành vi ngôn ngữ xin lỗi trong phát ngôn "oh sorry mum there you go okay"?
Trả lời: Phiên bản được chú thích là: oh <APOLOGISING> sorry </APOLOGISING> <APOLOGISEE> mum </APOLOGISEE> there you go okay

Câu hỏi: Bạn có thể phát hiện hành vi ngôn ngữ xin lỗi và chú thích bất kỳ yếu tố chức năng nào như APOLOGISING, REASON, APOLOGISER, APOLOGISEE, hoặc INTENSIFIER trong phát ngôn sau không? Vui lòng loại trừ bất kỳ văn bản không liên quan nào.
"I'm so excited oh look at these thank you yeah sorry they're a bit wet yeah I like camping that"

Phụ lục B. Hoàn thành của ChatGPT (cùng lời nhắc như những lời nhắc được nhập vào chatbot của Bing)

Phụ lục C. Một ví dụ về văn bản được chú thích do chatbot Bing tạo ra

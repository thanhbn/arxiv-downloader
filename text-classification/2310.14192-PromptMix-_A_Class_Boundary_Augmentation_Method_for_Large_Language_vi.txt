PromptMix: Một Phương Pháp Tăng Cường Biên Giới Lớp Cho Chưng Cất Mô Hình Ngôn Ngữ Lớn

Gaurav Sahu
Đại học Waterloo
gsahu@uwaterloo.ca

Olga Vechtomova
Đại học Waterloo

Dzmitry Bahdanau
ServiceNow Research
Mila, Đại học McGill
Canada CIFAR AI Chair

Issam H. Laradji
ServiceNow Research

Tóm tắt
Tăng cường dữ liệu là một kỹ thuật được sử dụng rộng rãi để giải quyết vấn đề phân loại văn bản khi có lượng dữ liệu huấn luyện hạn chế. Các nghiên cứu gần đây thường giải quyết vấn đề này bằng cách sử dụng các mô hình ngôn ngữ lớn (LLM) như GPT3 có thể tạo ra các ví dụ mới dựa trên những ví dụ đã có sẵn. Trong nghiên cứu này, chúng tôi đề xuất một phương pháp để tạo ra dữ liệu tăng cường hữu ích hơn bằng cách tận dụng khả năng của LLM trong việc tuân theo hướng dẫn và thực hiện phân loại few-shot. Phương pháp PromptMix cụ thể của chúng tôi bao gồm hai bước: 1) tạo ra các tăng cường văn bản thách thức gần các biên giới lớp; tuy nhiên, việc tạo ra các ví dụ biên giới làm tăng nguy cơ dương tính giả trong tập dữ liệu, vì vậy chúng tôi 2) gán nhãn lại các tăng cường văn bản bằng cách sử dụng một bộ phân loại LLM dựa trên prompting để nâng cao tính chính xác của nhãn trong dữ liệu được tạo. Chúng tôi đánh giá phương pháp đề xuất trong các cài đặt 2-shot và zero-shot thách thức trên bốn bộ dữ liệu phân loại văn bản: Banking77, TREC6, Subjectivity (SUBJ), và Twitter Complaints. Các thí nghiệm của chúng tôi cho thấy rằng việc tạo ra và, quan trọng hơn, gán nhãn lại các ví dụ biên giới tạo điều kiện cho việc chuyển giao kiến thức từ một LLM khổng lồ như GPT3.5-turbo vào các bộ phân loại nhỏ hơn và rẻ hơn như DistilBERT base và BERT base. Hơn nữa, PromptMix 2-shot vượt trội hơn nhiều phương pháp tăng cường dữ liệu 5-shot trên bốn bộ dữ liệu. Mã nguồn của chúng tôi có sẵn tại https://github.com/ServiceNow/PromptMix-EMNLP-2023.

1 Giới thiệu
Thiếu hụt dữ liệu là một thách thức chính trong nhiều tình huống thực tế, chẳng hạn như triển khai các hệ thống phát hiện ý định trong các tác nhân hội thoại định hướng nhiệm vụ và xác định các trường hợp lời nói thù địch trên các nền tảng truyền thông xã hội. Crowdsourcing từ lâu đã là một lựa chọn phổ biến để có được thêm dữ liệu, nhưng đây là một quy trình tốn kém về mặt tài chính với chi phí nhân công cao (Sheng et al., 2008; Rashtchian et al., 2010; Rajpurkar et al., 2016; Khot et al., 2018). Với sự bùng nổ gần đây trong việc phát triển các mô hình ngôn ngữ lớn sinh tạo (LLM) (Brown et al., 2020; Chowdhery et al., 2022; Zhang et al., 2022; Touvron et al., 2023), một lượng lớn tài liệu đã xuất hiện sử dụng LLM để tạo ra dữ liệu bổ sung cho các nhiệm vụ khác nhau (Kumar et al., 2020; Schick và Schütze, 2021; Wang et al., 2023).

Trong nghiên cứu này, chúng tôi tập trung vào nhiệm vụ phân loại văn bản few-shot (Schick và Schütze, 2021; Alex et al., 2021; Bragg et al., 2021). Cụ thể, chúng tôi khám phá các cài đặt zero-shot và 2-shot. Các nghiên cứu sớm sử dụng LLM để tạo ra các mẫu dữ liệu bổ sung cho phân loại văn bản trước tiên fine-tune một mô hình ngôn ngữ sinh tạo trên một tập dữ liệu seed ban đầu và sau đó sử dụng nó để tổng hợp dữ liệu huấn luyện mới (Wu et al., 2019; Kumar et al., 2019, 2020; Anaby-Tavor et al., 2020); tuy nhiên, bước fine-tuning nhanh chóng trở thành một nút thắt cổ chai khi thiếu các ví dụ seed đầy đủ. Các nghiên cứu gần đây hơn bỏ qua fine-tuning bằng cách thiết kế các prompt ngôn ngữ tự nhiên cho các LLM có sẵn (Yoo et al., 2021; Sahu et al., 2022; Lin et al., 2023). Một hạn chế chính của các nghiên cứu này là các prompt của họ chỉ tập trung vào việc sử dụng thông tin từ một lớp duy nhất khi tạo ra các tăng cường. Ngoài ra, họ không khuyến khích LLM đa dạng hóa các ví dụ được tạo, và các nghiên cứu gần đây cho thấy rằng các LLM được huấn luyện theo hướng dẫn như InstructGPT (Ouyang et al., 2022) và Vicuna (Chiang et al., 2023) dễ bị sụp đổ chế độ (Zhu et al., 2023).

Để giải quyết các hạn chế trước đó, chúng tôi đề xuất một kỹ thuật dựa trên prompting hai bước, PromptMix. Đầu tiên, PromptMix hướng dẫn một LLM (trong trường hợp của chúng tôi là GPT3.5-turbo) tạo ra các ví dụ mới bằng cách trộn lẫn thông tin từ nhiều lớp. Mức độ trộn lẫn được kiểm soát bởi một tham số alpha, và việc sử dụng một dải giá trị alpha đa dạng hóa các ví dụ được tạo; tuy nhiên, việc thúc đẩy mixup tăng nguy cơ tạo ra dương tính giả, vì vậy PromptMix sử dụng một sơ đồ gán nhãn lại trong bước thứ hai để cải thiện tính trung thực của các ví dụ được tạo. Cụ thể, nó sử dụng một LLM như một bộ phân loại để gán nhãn mới cho các ví dụ được tạo. Chúng tôi thấy rằng việc huấn luyện một bộ phân loại trên các ví dụ được gán nhãn lại này có hiệu quả chuyển giao kiến thức từ một LLM khổng lồ như GPT3.5 vào các mô hình nhỏ hơn nhiều như BERT (Devlin et al., 2019) và DistilBERT (Sanh et al., 2019). Hình 2 minh họa khung PromptMix hoàn chỉnh.

Chúng tôi tóm tắt các đóng góp của mình như sau:
a) chúng tôi đề xuất PromptMix, một phương pháp dựa trên prompting hai bước mới để tạo ra một tập hợp đa dạng các ví dụ có nhãn cho bất kỳ bộ dữ liệu phân loại văn bản nào; và b) chúng tôi chứng minh rằng việc tạo ra các ví dụ biên giới và gán nhãn lại chúng cải thiện việc chuyển giao kiến thức từ một LLM khổng lồ như GPT3.5 vào các mô hình nhỏ hơn nhiều như DistilBERT và BERT, ngay cả khi không có nhiều ví dụ seed. Chúng tôi cũng cho thấy rằng PromptMix 2-shot vượt trội hơn nhiều phương pháp tăng cường dữ liệu baseline sử dụng dữ liệu seed 5-shot hoặc nhiều hơn.

2 Nghiên cứu liên quan
Nghiên cứu của chúng tôi giao thoa với các chủ đề tăng cường dữ liệu, phân loại few-shot, và chưng cất kiến thức, mà chúng tôi giải thích chi tiết dưới đây.

2.1 Tăng cường dữ liệu dựa trên LLM cho phân loại văn bản few-shot

Kumar et al. (2019) đánh giá các kỹ thuật tăng cường dữ liệu không gian đặc trưng khác nhau, chẳng hạn như upsampling, perturbation, và nội suy tuyến tính, cho các mức độ thiếu hụt dữ liệu khác nhau (từ 5% đến 20% tính khả dụng dữ liệu); tuy nhiên, các cải thiện hiệu suất của họ là nhỏ so với cài đặt không tăng cường. Kumar et al. (2020) xem xét các thiết lập phân loại văn bản 10-shot, 50-shot, và 100-shot nơi họ fine-tune các mô hình ngôn ngữ được huấn luyện trước như BERT, BART (Lewis et al., 2020), và GPT-2 (Radford et al., 2019) như các trình tạo dữ liệu trên dữ liệu k-shot. Tiếp theo, họ điều kiện các trình tạo dữ liệu được fine-tune để tổng hợp các ví dụ huấn luyện mới cho từng lớp riêng lẻ trong tập dữ liệu. Phương pháp này cải thiện so với các kỹ thuật tăng cường dữ liệu cổ điển, chẳng hạn như tăng cường dữ liệu dễ dàng (Wei và Zou, 2019) và dịch ngược (Sennrich et al., 2016), nhưng các thí nghiệm được thực hiện trên các tập dữ liệu có rất ít lớp (tối đa bảy). Trong thực tế, các thiết lập phân loại có thể có hàng trăm lớp, và bước fine-tuning ban đầu sẽ trở thành một nút thắt cổ chai.

Để giảm bớt nút thắt cổ chai fine-tuning, Yoo et al. (2021) sử dụng các prompt ngôn ngữ tự nhiên cho tăng cường dữ liệu; tuy nhiên, họ cũng thí nghiệm với các thiết lập phân loại ít thách thức hơn (với ít lớp hơn). Sahu et al. (2022) đề xuất một phương pháp dựa trên prompting sử dụng GPT-3 có sẵn, để tạo ra một corpus lớn dữ liệu tăng cường có nhãn. Phương pháp của họ cải thiện trên nhiều thiết lập phân loại với số lượng lớn các lớp (lên đến 150) và các mức độ chi tiết khác nhau; tuy nhiên, phương pháp của họ gặp khó khăn với các nhiệm vụ mà các lớp mang ý nghĩa ngữ nghĩa rất gần. Cụ thể, các mẫu được tạo có nhãn không chính xác. Trong phương pháp của chúng tôi, chúng tôi sử dụng một mô hình ngôn ngữ như một bộ phân loại để cải thiện độ chính xác nhãn của tập dữ liệu được tạo.

Một số phương pháp không dựa trên prompting bao gồm Wei et al. (2021), người đề xuất tăng cường dữ liệu theo chương trình giảng dạy, nơi họ đầu tiên huấn luyện một mô hình trên dữ liệu k-shot hạn chế và sau đó dần dần giới thiệu dữ liệu tăng cường khi quá trình huấn luyện tiến triển. Họ sử dụng triplet loss (Schroff et al., 2015), giảm thiểu khoảng cách giữa các điểm dữ liệu có cùng nhãn và tối đa hóa cho các ví dụ được gắn nhãn khác nhau. Tunstall et al. (2022) đề xuất SetFit trước tiên fine-tune các sentence transformer trên một số lượng nhỏ các cặp văn bản theo cách Siamese tương phản (Dong và Shen, 2018) và sau đó tạo ra các embedding văn bản phong phú để huấn luyện một đầu phân loại. Cuối cùng, Kim et al. (2021) đề xuất LINDA, được huấn luyện đầu tiên trên một triệu cặp câu được rút ngẫu nhiên từ Wikipedia tiếng Anh. Sau đó, họ sử dụng thuật toán Mixup (Zhang et al., 2018) để nội suy giữa hai câu tiếng Anh có độ dài khác nhau. LINDA cải thiện đáng kể hiệu suất của mô hình BERT base trên nhiều thiết lập phân loại few-shot. Trong nghiên cứu của chúng tôi, chúng tôi xem xét các thiết lập few-shot cực đoan hơn (2-shot, zero-shot) và thực hiện nội suy có kiểm soát hơn thúc đẩy việc tạo ra các ví dụ gần biên giới lớp.

2.2 Chưng cất kiến thức
Chưng cất kiến thức (Bucila et al., 2006; Hinton et al., 2015; West et al., 2022) đề cập đến việc huấn luyện một mô hình học sinh nhỏ hơn bắt chước hành vi của một mô hình giáo viên lớn hơn nhiều. Cụ thể, hàm mục tiêu nhằm mục đích khớp phân phối đầu ra của mô hình học sinh với phân phối của mô hình giáo viên. Bằng cách đó, kiến thức của mô hình giáo viên được chưng cất hiệu quả vào một mô hình học sinh nhỏ hơn nhiều, cho phép mức hiệu suất tương tự như giáo viên với chi phí tính toán thấp hơn. Shridhar et al. (2022) chưng cất một mô hình GPT3 (6B) vào một mô hình GPT-2 cho một nhiệm vụ lý luận Chain-of-thought (CoT). Liang et al. (2021) đề xuất MixKD để khuyến khích mô hình học sinh bắt chước hành vi của giáo viên không chỉ trên các ví dụ huấn luyện có sẵn mà còn trên các ví dụ được nội suy. Cuối cùng, Sun et al. (2020) chưng cất kiến thức thông qua các lớp trung gian của giáo viên thông qua một mục tiêu tương phản. So với đó, phương pháp của chúng tôi cho phép chưng cất kiến thức từ một mô hình giáo viên khổng lồ như GPT3.5 (175B tham số) vào các mô hình học sinh nhỏ hơn đáng kể như DistilBERT và BERT (67M và 110M tham số, tương ứng).

3 Phương pháp luận
Chúng tôi giả thuyết rằng việc huấn luyện một bộ phân loại văn bản mạnh mẽ đòi hỏi dữ liệu huấn luyện phải có sự kết hợp tốt của các ví dụ biên giới (Swayamdipta et al., 2020). Phần này mô tả phương pháp PromptMix của chúng tôi, nơi chúng tôi đầu tiên hướng dẫn một LLM (GPT3.5-turbo, trong trường hợp của chúng tôi) tạo ra các ví dụ khó khăn gần biên giới lớp sau đó gán nhãn lại những thế hệ đó để cải thiện tính trung thực của dữ liệu được tạo (xem Hình 2).

3.1 Bước 1: Tạo ra các ví dụ
Đầu tiên, chúng tôi viết tay các mô tả ngắn cho mọi lớp trong tập dữ liệu. Chúng tôi sử dụng các mô tả trong prompt của mình để tạo điều kiện cho việc sử dụng phương pháp trong các cài đặt zero-shot và two-shot cực kỳ thiếu dữ liệu. Tiếp theo, chúng tôi chọn ngẫu nhiên một nhóm t (= 4) lớp c ⊆ C, trong đó C biểu thị tập hợp tất cả các lớp trong tập dữ liệu. Đối với mỗi lớp trong c, chúng tôi kết hợp mô tả và k ví dụ trong prompt, k là cài đặt k-shot (xem phần 1 trong Hình 3). Cuối cùng, đối với mỗi lớp ci cho tất cả i trong [1, t] trong tập con, chúng tôi hướng dẫn GPT3.5-turbo tạo ra n ví dụ phát ngôn là sự kết hợp của hai lớp: ci và một lớp được chọn ngẫu nhiên cj trong c \ {ci}. Cụ thể, chúng tôi hướng dẫn LLM tạo ra các phát ngôn thuộc alpha% vào lớp ci và (1-alpha)% vào lớp cj (xem phần 2 trong Hình 3). Hình 5 trong Phụ lục A.1 cho thấy phân phối alpha được lấy mẫu.

3.2 Bước 2: Cải thiện độ trung thực
Vì các ví dụ biên giới vốn khó để xếp vào một danh mục, LLM có thể tạo ra các ví dụ cho lớp thiểu số trong prompt (cj). Nói cách khác, LLM có thể tạo ra dương tính giả. Để giải quyết vấn đề này, chúng tôi sử dụng GPT3.5-turbo như một bộ phân loại và gán nhãn lại các ví dụ được tạo. Khi xây dựng prompt phân loại, chúng tôi chọn 5 lớp gần nhất theo độ tương tự giữa embedding câu SBERT (Reimers và Gurevych, 2019) của ví dụ được tạo và các ví dụ có sẵn trong tập huấn luyện few-shot. Đối với cài đặt zero-shot, chúng tôi sử dụng embedding của tên lớp thay vì các ví dụ có sẵn. Sau đó chúng tôi tuân theo một quy trình tương tự như trong Bước 1 để xây dựng prompt, nhưng thay vào đó yêu cầu LLM phân loại câu được cung cấp vào một trong các lớp trong prompt (xem Hình 4). Để đảm bảo một dự đoán hợp lệ, chúng tôi lấy lớp gần nhất trong tập dữ liệu dựa trên độ tương tự cosine của embedding SBERT của lớp được tạo bởi GPT và các lớp ground-truth trong tập dữ liệu. Chúng tôi không bao gồm tất cả các lớp trong prompt vì a) một số tập dữ liệu có thể có hàng trăm lớp sẽ không vừa với kích thước ngữ cảnh của LLM, và b) chúng tôi thấy trong các thí nghiệm sơ bộ rằng ngữ cảnh dài làm giảm khả năng phân loại của GPT.

Hình 4 cho thấy cấu trúc prompt để gán nhãn lại một ví dụ được tạo.

Sau khi tạo ra các ví dụ biên giới và gán nhãn lại chúng, chúng tôi huấn luyện một bộ phân loại văn bản trên dữ liệu được tạo bởi PromptMix kết hợp và dữ liệu seed gốc. Cụ thể, chúng tôi fine-tune các mô hình phân loại DistilBERT base và BERT base. Trong các phần tiếp theo, chúng tôi cho thấy rằng phương pháp của chúng tôi đạt được tăng cường văn bản, pseudo-labeling, và chưng cất kiến thức trong một đường ống liền mạch.

4 PromptMix có tạo ra các ví dụ biên giới không?
Bảng 1 cho thấy rằng việc sử dụng mixup tạo ra các câu chứa thông tin từ lớp đa số và lớp thiểu số, so với các câu được tạo không có mixup chỉ chứa thông tin về lớp đa số. Điều này chứng minh rằng mixup dẫn đến việc tạo ra các ví dụ biên giới.

Bảng 1 cũng cho thấy một số dương tính giả, nơi GPT tạo ra các câu như, "Tôi có cần trên một độ tuổi nhất định để sử dụng ATM không?" cho lớp đa số age_limit. Lớp age_limit bao gồm tất cả các truy vấn liên quan đến tuổi về việc mở tài khoản ngân hàng, trong khi câu được tạo là một truy vấn liên quan đến tuổi về việc sử dụng ATM, làm cho nó phù hợp hơn với lớp thiểu số atm_support. Bằng cách gán nhãn lại các dương tính giả như vậy, chúng tôi nhằm mục đích sửa chữa sự không khớp giữa các ví dụ được tạo và nhãn lớp được gán của chúng. Hình 4 cho thấy rằng GPT dự đoán chính xác lớp mới của câu là atm_support, xác minh tầm quan trọng của bước gán nhãn lại trong phương pháp của chúng tôi.

Nhìn chung, chúng tôi thấy các quan sát trong phần này là bằng chứng mạnh mẽ rằng PromptMix có thể tạo ra các tập dữ liệu chất lượng cao ngay cả trong các thiết lập phân loại văn bản few-shot tích cực. Tiếp theo, chúng tôi tiến hành một bộ thí nghiệm toàn diện để xác minh hiệu quả của PromptMix.

5 Thiết lập thí nghiệm
5.1 Tập dữ liệu
Chúng tôi sử dụng bốn bộ dữ liệu phân loại văn bản với các mức độ chi tiết khác nhau giữa các lớp. Banking77 (B77) (Casanueva et al., 2020) là một tập dữ liệu đơn domain với 77 lớp liên quan đến ngân hàng, nơi sự khác biệt giữa nhiều lớp là tinh tế. Bản chất chi tiết kết hợp với số lượng lớp mục tiêu cao làm cho Banking77 trở thành một nền tảng thử nghiệm tốt để xác minh khả năng mở rộng và hiệu quả của phương pháp chúng tôi. Ba tập dữ liệu sau có nhãn thô nhưng bao gồm nhiều domain khác nhau, cho phép chúng tôi kiểm tra khả năng thích ứng của phương pháp trên các domain khác nhau. TREC6 (Voorhees et al., 1999) là một tập dữ liệu phân loại câu hỏi với sáu lớp câu hỏi rộng bằng tiếng Anh. Tập dữ liệu chủ quan (SUBJ) (Pang và Lee, 2004) chứa các đánh giá phim với nhãn tính khách quan. Cuối cùng, tập dữ liệu khiếu nại twitter (TC) (Preoțiuc-Pietro et al., 2019) chứa các tweet được chú thích về việc chúng có chứa khiếu nại hay không. Chúng tôi giới thiệu độc giả đến Bảng 2 để biết thống kê chính xác của tất cả các tập dữ liệu.

5.2 Thiết lập few-shot
Cho các thí nghiệm của chúng tôi, chúng tôi xem xét 1) thiết lập 2-shot, nơi chỉ có k = 2 ví dụ huấn luyện cho mỗi lớp, và 2) thiết lập zero-shot, nơi chúng tôi không có quyền truy cập vào bất kỳ ví dụ huấn luyện nào.

Ký hiệu. Chúng tôi sẽ sử dụng Dpart để đề cập đến các phần tập dữ liệu, tức là, train, validation, và test. Khi tăng cường dữ liệu huấn luyện bằng bất kỳ phương pháp nào, chúng tôi tạo ra N ví dụ cho mỗi lớp và đề cập đến dữ liệu kết quả là D̃A,train (thu được sau Bước 1). Chúng tôi đề cập đến phiên bản được gán nhãn lại của dữ liệu kết quả (thu được sau Bước 2) là D̃A+R,train.

5.3 Huấn luyện và đánh giá
Huấn luyện. Chúng tôi fine-tune các mô hình DistilBERT base và BERT base cho phân loại văn bản bằng cách thêm một lớp tuyến tính trên đầu token [CLS] (Wolf et al., 2019). Trong tất cả các thiết lập, chúng tôi fine-tune bộ phân loại trong 5 epoch. Chúng tôi sử dụng tốc độ học 6×10^-5 và weight decay 1×10^-3 cho B77 và tốc độ học 4×10^-5 và weight decay 1×10^-2 cho tất cả các tập dữ liệu khác. Cuối cùng, chúng tôi tạo ra N = 50 ví dụ cho mỗi lớp cho B77 và TREC6 và N = 100 ví dụ cho mỗi lớp cho SUBJ và TC. Chúng tôi đã sử dụng các tập validation của TREC6 và SUBJ để chọn các giá trị N cụ thể vì chúng cung cấp tỷ lệ chi phí-hiệu suất tốt. Chúng tôi chọn TREC6 thay vì B77 để giảm thiểu chi phí sử dụng GPT3.5-turbo.

Chúng tôi thực hiện tất cả việc điều chỉnh siêu tham số bằng DistilBERT base trên B77 và TREC6. Chúng tôi giới hạn việc điều chỉnh của mình trong hai tập dữ liệu để có được hai bộ siêu tham số: một cho các tập dữ liệu quy mô lớn như B77 và một cho các tập dữ liệu quy mô nhỏ như TREC6, SUBJ, và TC. Ngoài ra, chúng tôi sử dụng cùng một bộ siêu tham số cho mô hình phân loại BERT base. Chúng tôi sử dụng toàn bộ tập validation để điều chỉnh thay vì một tập few-shot để tránh các vấn đề với siêu tham số không ổn định.

Chúng tôi chạy thí nghiệm cho các tình huống sau: 1) Baseline (2-shot). Tất cả các lớp được giảm xuống 2 ví dụ cho mỗi lớp, và chúng tôi fine-tune một mô hình DistilBERT base/BERT base trên tập dữ liệu giảm. 2) NN+GPT3.5. Chúng tôi sử dụng phương pháp nearest-neighbor để điền vào prompt như được mô tả trong Phần 3.2 và sau đó prompt GPT3.5-turbo để phân loại các ví dụ tập test (xem Hình 4 để tham khảo). 3) Sahu et al. (2022). Một phương pháp dựa trên prompting cho tăng cường dữ liệu liệt kê tất cả các ví dụ seed cho một lớp duy nhất trong prompt và prompt LLM để tạo ra nhiều ví dụ hơn dựa trên nó. Nó không thúc đẩy mixup trong các ví dụ được tạo. 4) PromptMix. Phương pháp được đề xuất của chúng tôi với nhiều lớp trong prompt, hướng dẫn LLM tạo ra các ví dụ biên giới. 5) PromptMix (zero-shot). Chúng tôi loại bỏ các ví dụ seed khỏi PromptMix nhưng vẫn sử dụng các mô tả lớp được viết tay. 6) Easy Data Augmentation (EDA). Một kỹ thuật tăng cường dựa trên chỉnh sửa được đề xuất bởi Wei và Zou (2019) áp dụng các thay đổi dựa trên quy tắc cho các ví dụ huấn luyện hiện có để tạo ra các ví dụ bổ sung. 7) GPT3Mix. Một phương pháp tăng cường dựa trên mixup sử dụng nhãn mềm cho pseudolabeling được đề xuất bởi Yoo et al. (2021). Đáng chú ý, Yoo et al. (2021) đo lường mức độ few-shot theo tỷ lệ phần trăm của các ví dụ huấn luyện được sử dụng cho tăng cường (tỷ lệ phần trăm sub-sample) và thí nghiệm với các tỷ lệ phần trăm khác nhau. Chúng tôi báo cáo mô hình hoạt động tốt nhất của họ cho tỷ lệ phần trăm sub-sample 1%, nơi GPT3Mix sử dụng 55 ví dụ huấn luyện trong TREC6 và 80 ví dụ huấn luyện trong SUBJ (kết hợp cho tất cả các lớp). 8) CPFT. Zhang et al. (2021) sử dụng huấn luyện trước tương phản trước khi fine-tune một mô hình cho phát hiện ý định few-shot bằng RoBERTa base. 9) USE. Một mô hình đa ngôn ngữ lớn được huấn luyện trước trên 16 ngôn ngữ (Yang et al., 2020). 10) CONVERT. Một mô hình phát hiện ý định từ Casanueva et al. (2020), sử dụng thiết lập dual encoder được huấn luyện trước trên 654 triệu câu Reddit.

Một số nghiên cứu trong quá khứ đã khám phá các cài đặt 5-shot, 10-shot, và thậm chí 100-shot cho tăng cường dữ liệu (Kumar et al., 2020; Zhang et al., 2021). Nhưng, theo hiểu biết tốt nhất của chúng tôi, chúng tôi là những người đầu tiên khám phá tăng cường dữ liệu trong các cài đặt 2-shot và zero-shot. Thông qua các thí nghiệm của chúng tôi, chúng tôi nhằm mục đích đo lường mức độ thiếu hụt dữ liệu mà một LLM như GPT3.5-turbo có thể xử lý, được tối ưu hóa để tuân theo hướng dẫn.

Đánh giá. Chúng tôi đo lường hiệu suất của các bộ phân loại theo độ chính xác phân loại test và báo cáo bộ kết quả đầy đủ trong Bảng 3. Để lưu ý, A1 biểu thị độ chính xác của bộ phân loại trên Dtrain ∪ DA,train (tập dữ liệu tăng cường sau Bước 1 trong Phần 3.1) và A2 biểu thị độ chính xác của bộ phân loại trên Dtrain ∪ DA+R,train (tập dữ liệu tăng cường+gán nhãn lại sau Bước 2 trong Phần 3.2). Chúng tôi chạy mỗi thí nghiệm cho ba seed ngẫu nhiên và báo cáo độ chính xác trung bình trong Bảng 3.

6 Kết quả
Tham khảo Bảng 3, trước tiên chúng tôi lưu ý rằng A1 hoạt động tốt hơn đáng kể so với baseline (2-shot) cho DistilBERT base và BERT base trên tất cả bốn tập dữ liệu. Điều này xác nhận rằng tăng cường dữ liệu hữu ích trong các thiết lập thiếu dữ liệu.

6.1 Về tác động của bước gán nhãn lại
Bảng 5 cho thấy tỷ lệ phần trăm của các ví dụ được tạo được gán nhãn lại bởi GPT3.5-turbo cho các phương pháp tăng cường khác nhau. Chúng tôi lưu ý rằng tỷ lệ phần trăm gán nhãn lại cao hơn khi chúng tôi thêm mixup vào prompt (PromptMix so với PromptMix w/o Mixup). Tỷ lệ phần trăm gán nhãn lại cao cho thấy rằng mixup tạo ra nhiều ví dụ biên giới hơn bất kỳ phương pháp tăng cường nào khác. Điều này xác minh tầm quan trọng của bước gán nhãn lại trong phương pháp của chúng tôi, rất hiệu quả trong việc khắc phục vấn đề tạo ra dương tính giả. Điều này được chứng minh thêm bởi các giá trị A2 cao hơn A1 trên toàn bộ. Cụ thể, đối với PromptMix, chúng tôi quan sát thấy cải thiện 7.4% trên B77, 8.1% trên TREC6, 12.4% trên SUBJ, và 13.5% trên TC, khi chúng tôi sử dụng DistilBERT base; và 5.9% trên B77, 10.4% trên TREC6, 14.4% trên SUBJ, và 11.6% trên TC khi chúng tôi sử dụng BERT base. Ngoài những cải thiện đáng kể này, chúng tôi lưu ý rằng mức độ cải thiện tăng khi nhiệm vụ phân loại trở nên dễ dàng hơn về số lượng lớp mục tiêu. Bảng 6 cho thấy một số ví dụ về các thế hệ bị rò rỉ mà GPT sửa chữa trong bước gán nhãn lại.

6.2 Các ví dụ biên giới hỗ trợ chưng cất kiến thức
Trong Bảng 3, chúng tôi nhận thấy rằng PromptMix đạt được hiệu suất gần tương tự như NN+GPT3.5 trên ba trong số bốn tập dữ liệu. Cụ thể, PromptMix vượt trội hơn NN+GPT3.5 trên B77 (80.1 so với 79.9) và SUBJ (91.7 so với 90.4) và cạnh tranh trên TREC6 (73.7 so với 74.4). Khoảng cách giữa PromptMix và NN+GPT3.5 lớn hơn trên TC so với các tập dữ liệu khác (78.4 so với 88.6). Điều này có thể do bản chất của tập dữ liệu, chứa việc sử dụng rộng rãi ngôn ngữ truyền thông xã hội mà GPT biết, nhưng hai ví dụ có thể quá ít để bao gồm sự đa dạng rộng lớn của các khiếu nại trong thực tế. Nhìn chung, những kết quả này đầy hứa hẹn vì GPT3.5-turbo với 175B tham số lớn hơn khoảng 2600× so với DistilBERT base và khoảng 1600× lớn hơn BERT base, chỉ có 67M và 110M tham số, tương ứng. Trong cả hai trường hợp, các bộ phân loại cuối cùng của chúng tôi nhỏ hơn >99.9% so với GPT3.5-turbo. Chúng tôi không thấy hiệu suất mạnh như vậy cho bất kỳ phương pháp tạo ra nào khác, ngay cả sau khi gán nhãn lại. Điều này xác nhận rằng việc tạo ra các ví dụ biên giới trong PromptMix tạo nên một phương pháp tạo ra tập dữ liệu chất lượng cao hỗ trợ việc chuyển giao kiến thức từ các mô hình quy mô lớn như GPT3.5-turbo vào các bộ phân loại nhỏ hơn nhiều trong các cài đặt thiếu dữ liệu.

6.3 PromptMix so với các phương pháp tăng cường khác
Trong Bảng 3, chúng tôi so sánh hiệu suất 2-shot của PromptMix với một số baseline mạnh trên bốn tập dữ liệu. Đầu tiên, chúng tôi lưu ý rằng PromptMix tốt hơn đáng kể so với baseline EDA trên tất cả các tập dữ liệu. Tiếp theo, chúng tôi so sánh kết quả của PromptMix (sử dụng GPT3.5-turbo để tạo ra) với GPT3Mix (sử dụng mô hình Davinci của GPT3 để tạo ra) và LINDA vì chúng là những phương pháp gần nhất với chúng tôi về động lực. PromptMix vượt trội hơn cả LINDA và GPT3Mix với biên độ lớn mặc dù LINDA là 5-shot và sử dụng huấn luyện trước, và GPT3Mix sử dụng 1% mẫu huấn luyện để tăng cường, dịch sang 55 ví dụ seed tổng cộng so với 12 ví dụ seed của chúng tôi trên TREC6, và 80 ví dụ seed so với 4 ví dụ seed của chúng tôi trên tập dữ liệu SUBJ.

Bảng 4 cho thấy rằng PromptMix 2-shot vượt trội hơn USE, CONVERT, và USE+CONVERT trên tập dữ liệu Banking77. Nó cũng đạt được độ chính xác 80.1% so với 80.9% của CPFT, rất cạnh tranh. Để nhấn mạnh, tất cả các baseline được xem xét là 5-shot, với một số mô hình sử dụng dữ liệu bổ sung để huấn luyện trước. Hơn nữa, có thể cải thiện thêm hiệu suất của PromptMix với việc điều chỉnh siêu tham số cụ thể hơn cho tập dữ liệu và mô hình; tuy nhiên, thông điệp cốt lõi của chúng tôi là chỉ ra rằng việc tạo ra các ví dụ biên giới kết hợp với gán nhãn lại là một phương pháp rất hứa hẹn cho tăng cường dữ liệu trong các thiết lập phân loại văn bản 2-shot và zero-shot.

6.4 Mô tả có tác động
Các thí nghiệm của chúng tôi được sử dụng để đánh giá hiệu quả của việc sử dụng các mô tả do con người viết cho thấy kết quả đầy hứa hẹn. Đầu tiên, chúng tôi lưu ý rằng việc chỉ thêm mô tả lớp vào prompt dẫn đến cải thiện hiệu suất đáng kể trên tất cả các tập dữ liệu (Sahu et al. (2022) có và không có desc). So sánh PromptMix (zero-shot) có và không có Mixup với Sahu et al. (2022) + desc. cho thấy rằng việc chỉ sử dụng mô tả trong prompt (không có ví dụ seed) dẫn đến sự tăng đáng kể trong hiệu suất mô hình. Chúng tôi cũng quan sát thấy rằng việc sử dụng nhiều mô tả lớp trong một prompt tốt hơn hoặc tương đương với việc sử dụng một lớp duy nhất với mô tả và ví dụ của nó. Điều này cho thấy rằng việc cung cấp thêm ngữ cảnh về các lớp khác giúp LLM tạo ra các tăng cường chất lượng tốt hơn cho một lớp nhất định. Do đó, nó tuân theo trực giác rằng PromptMix, kết hợp việc sử dụng nhiều lớp với mô tả cũng như ví dụ seed, dẫn đến hiệu suất tốt nhất trên tất cả các tập dữ liệu.

6.5 Mô hình mã nguồn mở so với mã nguồn đóng
Bảng 3 và 4 thể hiện khả năng mạnh mẽ của GPT3.5-turbo cho nhiệm vụ của chúng tôi. Tuy nhiên, GPT3.5-turbo là một mô hình ngôn ngữ mã nguồn đóng được cung cấp bởi OpenAI, và nó có thể nhanh chóng trở nên tốn kém khi chúng tôi tăng số lượng lớp trong tập dữ liệu. Do đó, chúng tôi tiến hành một thí nghiệm quy mô nhỏ trên tập dữ liệu TREC6 với các LLM mã nguồn mở. Cụ thể, chúng tôi prompt các LLM mã nguồn mở thay vì GPT3.5-turbo để tổng hợp các ví dụ mới và gán nhãn lại chúng. Tiếp theo, chúng tôi finetune một bộ phân loại BERT base trên tập dữ liệu tăng cường+gán nhãn lại.

GPT-Neo (1.3B), GPT-J (6B), và các mô hình Vicuna và Stable-vicuna (13B) được huấn luyện theo hướng dẫn gần đây hơn (Chiang et al., 2023) đạt được hiệu suất rất kém so với GPT3.5-turbo. Chúng tôi thấy rằng ngay cả đối với các LLM cỡ trung bình như Vicuna và Stable-vicuna, thời gian suy luận là một nút thắt cổ chai chính. Tuy nhiên, các thí nghiệm của chúng tôi với LLama-2 cho thấy kết quả đầy hứa hẹn. Chúng tôi sử dụng các mô hình Llama-2 có kích thước khác nhau (7b, 13b, 70b) trên tập dữ liệu TREC6 và quan sát mối tương quan mạnh mẽ giữa kích thước mô hình và độ chính xác test. Cụ thể, chúng tôi lưu ý rằng LLama-2-70b-chat-hf có thể là một thay thế phù hợp cho mô hình GPT3.5-turbo mã nguồn đóng. Chúng tôi cũng kiểm tra GPT-4 (lớn hơn mô hình GPT3.5) và quan sát thấy sự tăng đáng kể trong độ chính xác phân loại. Bảng 7 cho thấy kết quả.

7 Kết luận
Để kết luận, chúng tôi đề xuất PromptMix, một phương pháp dựa trên prompting hai bước mới để tạo ra các ví dụ tăng cường biên giới trong các thiết lập phân loại văn bản few-shot cực đoan. Phương pháp của chúng tôi kết hợp quá trình tăng cường văn bản, pseudolabeling, và chưng cất kiến thức trong một đường ống liền mạch. Chúng tôi cho thấy rằng bằng cách tạo ra các ví dụ huấn luyện biên giới và gán nhãn lại chúng bằng cách sử dụng một mô hình giáo viên lớn như GPT3.5-turbo, chúng tôi có thể chuyển giao kiến thức của các LLM khổng lồ như vậy vào các mô hình nhỏ hơn nhiều như DistilBERT base và BERT base. Hơn nữa, PromptMix 2-shot đánh bại nhiều baseline tăng cường dữ liệu 5-shot hoặc cao hơn, làm cho nó trở thành một phương pháp tăng cường dữ liệu rất hứa hẹn.

Hạn chế
Kết quả của chúng tôi cho thấy tiềm năng đầy hứa hẹn để sử dụng LLM cho việc tạo ra dữ liệu trong các thiết lập few-shot rất tích cực; tuy nhiên, nghiên cứu này có một số hạn chế, như được nêu chi tiết trong phần này. Đầu tiên, chúng tôi phụ thuộc hoàn toàn vào pseudolabel của GPT để giải quyết các thế hệ dương tính giả trong bước tăng cường. Thứ hai, vì chúng tôi sử dụng embedding SBERT để đảm bảo rằng pseudolabel là một lớp hợp lệ trong tập dữ liệu, chúng tôi bỏ qua các thế hệ out-of-scope/out-of-domain (OOS/OOD) tiềm năng. Chúng tôi đã quan sát một vài trường hợp nơi pseudolabel của GPT có dạng, "Câu này không thuộc về bất kỳ lớp nào được cung cấp." Điều này đưa ra một con đường tốt để giới thiệu các can thiệp của con người có thể đánh giá pseudolabel của GPT và có thể xác định các ví dụ OOS/OOD, có thể hữu ích trong nhiều nhiệm vụ thực tế. Chúng tôi cũng muốn nhấn mạnh rằng trong khi các can thiệp của con người có thể giúp đỡ rất nhiều, chúng cũng đưa ra thách thức giảm thiểu lao động con người.

Thứ hai, trong khi các thí nghiệm của chúng tôi với các mô hình mã nguồn mở cho thấy rằng các mô hình mã nguồn mở lớn hơn như LLama-2-70b có thể là một thay thế tốt cho các mô hình mã nguồn đóng như GPT3.5, từ đó cắt giảm đáng kể chi phí API, chúng vẫn đòi hỏi tài nguyên tính toán đáng kể. Do đó, những nỗ lực hướng tới việc chưng cất kiến thức của các LLM lớn hơn như Llama-2-70b vào các mô hình nhỏ hơn sẽ hỗ trợ rất nhiều trong việc làm cho các mô hình này dễ tiếp cận và khả thi hơn để sử dụng.

Tuyên bố đạo đức
Chúng tôi sử dụng GPT để tạo ra các ví dụ mới, và mặc dù GPT3.5-turbo được huấn luyện theo hướng dẫn, một số thế hệ có thể mô tả các thành kiến không mong muốn liên quan đến mục tiêu hiện tại. Vì lý do đã nêu, chúng tôi khuyến nghị sử dụng các mô hình phân loại được đề xuất của chúng tôi với giám sát của con người để tránh bất kỳ vấn đề đạo đức nào do dự đoán dương tính giả của các bộ phân loại downstream. Các nhà thực hành cũng có thể xem xét việc loại bỏ thành kiến một cách rõ ràng các mô hình ngôn ngữ cho các trường hợp sử dụng cụ thể của họ (Barikeri et al., 2021; Schick et al., 2021).

# 2103.14453.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/text-classification/2103.14453.pdf
# Kích thước tập tin: 546662 bytes

===============================================
NỘI DUNG TẬP TIN PDF
===============================================


--- TRANG 1 ---
Một Phương Pháp Sinh Văn Bản Tăng Cường Dữ Liệu Mới
Tăng Cường Dữ Liệu trong Xử Lý Ngôn Ngữ Tự Nhiên: Một Phương Pháp Sinh Văn Bản Mới cho Bộ Phân Loại Văn Bản Dài và Ngắn
Markus Bayer Marc-André Kaufhold Björn Buchhold Marcel Keller Jörg Dallmeyer Christian Reuter

Tóm tắt Trong nhiều trường hợp học máy, nghiên cứu cho thấy việc phát triển dữ liệu huấn luyện có thể có tầm quan trọng cao hơn việc lựa chọn và mô hình hóa bộ phân loại. Do đó, các phương pháp tăng cường dữ liệu đã được phát triển để cải thiện bộ phân loại bằng cách tạo ra dữ liệu huấn luyện nhân tạo. Trong NLP, có thách thức trong việc thiết lập các quy tắc phổ quát cho các phép biến đổi văn bản cung cấp các mẫu ngôn ngữ mới. Trong bài báo này, chúng tôi trình bày và đánh giá một phương pháp sinh văn bản phù hợp để tăng hiệu suất của bộ phân loại cho văn bản dài và ngắn. Chúng tôi đạt được những cải thiện đầy hứa hẹn khi đánh giá các tác vụ văn bản ngắn cũng như dài với sự nâng cao bởi phương pháp sinh văn bản của chúng tôi. Đặc biệt đối với phân tích dữ liệu nhỏ, độ tăng độ chính xác cộng dồn lên đến 15.53% và 3.56% được đạt được trong một chế độ dữ liệu thấp được xây dựng, so với đường cơ sở không tăng cường và một kỹ thuật tăng cường dữ liệu khác. Vì hướng hiện tại của các chế độ xây dựng này không áp dụng được toàn cầu, chúng tôi cũng cho thấy những cải thiện lớn trong một số tác vụ dữ liệu thấp thực tế (lên đến +4.84 điểm F1). Vì chúng tôi đánh giá phương pháp từ nhiều góc độ (tổng cộng 11 bộ dữ liệu), chúng tôi cũng quan sát các tình huống mà phương pháp có thể không phù hợp. Chúng tôi thảo luận về các tác động và mẫu cho việc áp dụng thành công phương pháp của chúng tôi trên các loại bộ dữ liệu khác nhau.

Từ khóa Tăng Cường Dữ Liệu Văn Bản Phân tích dữ liệu văn bản nhỏ Sinh Văn Bản Bộ Phân Loại Văn Bản Dài và Ngắn

Tuyên bố

Tài trợ
Công trình này được đồng tài trợ bởi Bộ Giáo dục và Nghiên cứu Liên bang Đức (BMBF) trong dự án CYWARN (13N15407) và bởi sáng kiến LOEWE (Hesse, Đức) trong trung tâm emergenCITY. Các tính toán cho nghiên cứu này được thực hiện trên máy tính hiệu suất cao Lichtenberg của TU Darmstadt.

Xung đột lợi ích/Lợi ích cạnh tranh
Không áp dụng.

Tính khả dụng của dữ liệu và tài liệu
Tính khả dụng của dữ liệu được nêu trong phụ lục A.

Tính khả dụng mã nguồn
Đặc điểm kỹ thuật mã được nêu trong phụ lục C.

Đạo đức
Đạo đức được thảo luận trong phụ lục D.

1 Giới thiệu

Deep learning đã thu hút sự chú ý đáng kể do sức mạnh tính toán tăng lên kết hợp với tính khả dụng cao hơn của dữ liệu huấn luyện cho một loạt các bài toán (Sun et al., 2017). Trong một số tác vụ học tập, đặc biệt là các chế độ dữ liệu nhỏ, việc phát triển dữ liệu huấn luyện có thể có tầm quan trọng cao hơn việc lựa chọn và mô hình hóa bộ phân loại (Banko and Brill, 2001). Để cải thiện bộ phân loại, các phương pháp tăng cường dữ liệu đã được thiết kế để tạo ra dữ liệu huấn luyện nhân tạo với các biến đổi cụ thể arXiv:2103.14453v2 [cs.CL] 22 Jul 2022

--- TRANG 2 ---
2
(Taylor and Nitschke, 2019). Nghiên cứu hiện tại về tăng cường dữ liệu tập trung vào các thuật toán deep learning, là nghệ thuật hiện đại cho nhiều tác vụ phân loại, vì chúng vẫn thường gặp phải phương sai mạnh đối với bài toán đã cho nếu không có đủ dữ liệu được cung cấp. Việc tạo ra dữ liệu huấn luyện nhân tạo đóng vai trò như một loại chính quy hóa và do đó, các giải pháp đơn giản hơn được ưa thích (Zeiler and Fergus, 2013; Hu and Yu, 2020). Ngoài ra, sự mất cân bằng trong các bộ dữ liệu có thể được giải quyết (Zhai et al., 2021; Raghuwanshi and Shukla, 2021) và tính bảo mật của bộ phân loại có thể được tăng lên bằng cách khiến chúng chống lại sự lừa dối bởi những thay đổi khéo léo trong các chuỗi đầu vào (Miyato et al., 2017). Tăng cường dữ liệu cũng có thể giúp giảm thiểu vấn đề "rào cản dữ liệu lớn", liên quan đến thực tế là các công ty nhỏ hơn, nhóm nghiên cứu và tổ chức thường không thể thu thập cùng khối lượng dữ liệu như các tập đoàn lớn (Coulombe, 2018).

Bất kể deep learning, nghiên cứu về tạo dữ liệu nhân tạo có thể có lợi cho các ứng dụng xử lý ngôn ngữ tự nhiên (NLP) trên nhiều lĩnh vực nơi dữ liệu huấn luyện khan hiếm hoặc việc gán nhãn tốn kém. Ví dụ, để nâng cao nhận thức tình huống của các nhà quản lý khẩn cấp, một phần của tin học khủng hoảng liên quan đến việc nhận dạng nhanh chóng và phân loại tiếp theo các thông điệp và hình ảnh trong thảm họa và tình huống khẩn cấp (Alam et al., 2020; Kaufhold et al., 2020). Do tính khan hiếm của tài nguyên tài chính và nhân sự, các dịch vụ khẩn cấp mất thời gian quý báu để xử lý các tác vụ nhận dạng phức tạp, điều này cuối cùng có thể gây tổn hại tính mạng (Imran et al., 2018; Reuter et al., 2016). Vấn đề khan hiếm này cũng áp dụng cho các doanh nghiệp vừa và nhỏ (SME) khi yêu cầu chất lượng cao và khối lượng lớn dữ liệu được gán nhãn cho các tác vụ thương mại như phân tích thương hiệu hoặc phân loại tin tức (Stieglitz et al., 2018). Trong NLP, có khó khăn trong việc thiết lập các quy tắc phổ quát cho các phép biến đổi dữ liệu văn bản có thể được thực hiện tự động và vẫn duy trì chất lượng của việc gán nhãn, điều này đặc biệt nhạy cảm trong các lĩnh vực như phân tích cảm xúc (Medhat et al., 2014). Longpre et al. (2020) cho rằng các phương pháp tiền huấn luyện hoặc học chuyển giao hiện tại trong NLP đã bao gồm các mục tiêu của tăng cường dữ liệu. Họ lập luận rằng các phương pháp tăng cường chỉ làm nhiễu dữ liệu đầu vào và không cung cấp các mẫu ngôn ngữ mới sẽ không thể tăng chất lượng phân loại của các mô hình tiền huấn luyện.

Do đó, chúng tôi đề xuất một phương pháp dựa trên sinh văn bản tinh vi vượt qua những vấn đề này bằng cách kết hợp các mẫu ngôn ngữ mới (tức là, một sự đa dạng ngữ pháp cao) được chứng minh là hữu ích khi kết hợp với các mô hình tiền huấn luyện. Phương pháp này không đơn giản tạo ra các thể hiện rất tương tự, mà là những thể hiện rất mới lạ. Cách tiếp cận của chúng tôi sử dụng hai phương pháp con, trong đó một phương pháp có điều kiện ngữ cảnh bằng cách kết hợp các phần của thể hiện (ví dụ, từ đầu tiên hoặc tiêu đề) trong quá trình sinh và do đó phù hợp cho văn bản dài, trong khi phương pháp khác độc lập ngữ cảnh và phù hợp cho văn bản ngắn. Mặc dù không có sự phân biệt rõ ràng giữa văn bản dài và ngắn, chúng tôi được hướng dẫn bởi giới hạn 280 ký tự (tức là, độ dài của một thông điệp trong Twitter), tại đó hầu hết các bộ dữ liệu NLP tiêu chuẩn sẽ được phân loại là nhỏ. Do đó, chúng tôi tìm cách trả lời ba câu hỏi nghiên cứu: Làm thế nào chúng ta có thể sử dụng các phương pháp sinh văn bản của tăng cường dữ liệu đạt được độ mới lạ cao trong dữ liệu trong khi bảo tồn chất lượng nhãn để cải thiện các bộ phân loại học máy tiền huấn luyện (RQ1)? Theo cách nào việc kết hợp ngữ cảnh của các thể hiện văn bản dài trong các bài toán phân loại hữu ích khi sử dụng sinh văn bản như phương pháp tăng cường dữ liệu (RQ1.1)? Làm thế nào có thể đạt được cải thiện chất lượng cho các tác vụ phân loại với văn bản ngắn khi tăng cường với sinh văn bản (RQ1.2)?

Đóng góp vào lĩnh vực phân tích dữ liệu nhỏ, kết quả của chúng tôi cho thấy độ tăng độ chính xác cộng dồn lên đến 15.53% và 3.56% trong một chế độ dữ liệu thấp được xây dựng, so với đường cơ sở không tăng cường và một kỹ thuật tăng cường dữ liệu khác. Vì hướng hiện tại của các chế độ xây dựng này không áp dụng được toàn cầu, chúng tôi cũng cho thấy những cải thiện lớn trong một số tác vụ dữ liệu thấp thực tế (lên đến +4.84 điểm F1). Vì chúng tôi đánh giá phương pháp từ nhiều góc độ (tổng cộng 11 bộ dữ liệu), chúng tôi cũng quan sát các tình huống mà phương pháp có thể không phù hợp. Chúng tôi thảo luận về các tác động thực nghiệm (tức là, hiểu biết về ứng dụng cụ thể lĩnh vực của phân tích dữ liệu nhỏ), thực tiễn (tức là, các phương pháp tăng cường dữ liệu mới dựa trên mô hình ngôn ngữ GPT-2) và lý thuyết (tức là, một cơ sở tăng cường dữ liệu văn bản có lợi cho các mô hình phân loại tiền huấn luyện) cho việc áp dụng thành công cách tiếp cận của chúng tôi trên các loại bộ dữ liệu khác nhau.

Bài báo được cấu trúc như sau: Sau khi giới thiệu các công trình liên quan về tăng cường dữ liệu, NLP và các phương pháp sinh văn bản (phần 2), bài báo trình bày cả khái niệm và thực hiện của một thuật toán tăng cường dữ liệu sinh văn bản mới (phần 3). Hơn nữa, nó trình bày phương pháp và kết quả của ba vòng đánh giá (phần 4) trước khi thảo luận về các tác động, hạn chế và tiềm năng cho nghiên cứu tương lai (phần 5).

2 Công trình liên quan

2.1 Cơ sở của Tăng Cường Dữ Liệu

Tăng cường dữ liệu là một kỹ thuật học máy tăng một cách nhân tạo số lượng dữ liệu huấn luyện bằng các phép biến đổi bảo tồn nhãn (Taylor

--- TRANG 3 ---
3
and Nitschke, 2019). Các biến thể đầu tiên của tăng cường dữ liệu có thể được nhận dạng trong LeNet nổi tiếng của LeCun et al. (1998). Sử dụng các biến dạng ngẫu nhiên của hình ảnh huấn luyện, bộ dữ liệu MNIST đã được mở rộng gấp chín lần, để việc phát hiện các chữ số viết tay trở nên khả thi hơn. Một thuật ngữ liên quan của tăng cường dữ liệu là bảo tồn nhãn, mô tả các phép biến đổi dữ liệu huấn luyện bảo tồn thông tin lớp (Coulombe, 2018). Điều này có nghĩa là loại biến đổi này sửa đổi các văn bản của một lớp nhất định thành các văn bản khác cũng liên quan đến lớp này. Trong nghiên cứu tăng cường dữ liệu, điều này có tầm quan trọng cao vì sự vắng mặt của nó sẽ dẫn đến việc tạo ra dữ liệu được phân loại không chính xác. Đối với phần lớn, một sự thay thế thực thể trong một câu là đủ cho việc bảo tồn nhãn trong phân tích cảm xúc. Tuy nhiên, việc thêm ngẫu nhiên các từ có thể dẫn đến sự thay đổi của cảm xúc. Nhiều nhà nghiên cứu nới lỏng thuật ngữ bảo tồn nhãn. Sau đó, các phép biến đổi phá vỡ sự bảo tồn là hợp pháp miễn là nhãn được điều chỉnh đồng thời. Hơn nữa, các phép biến đổi bảo tồn lớp đúng với xác suất cao, nhưng không chắc chắn, có thể tồn tại. Trong hiểu biết này, Shorten and Khoshgoftaar (2019) chỉ định xác suất rằng nhãn đúng được gán sau một phép biến đổi là độ an toàn của một phương pháp tăng cường dữ liệu. Ví dụ, sự không chắc chắn này, nếu được biết, có thể được tích hợp trực tiếp trong nhãn. Nếu không biết, các phương pháp như làm mịn nhãn có thể mô hình hóa một sự không chắc chắn chung.

Trong NLP, tăng cường dữ liệu được coi là một tác vụ khó (Kaffe et al., 2018) vì các phép biến đổi văn bản bảo tồn nhãn khó định nghĩa (Kobayashi, 2018; Wei and Zou, 2019). Do đó nhiều phương pháp đã được thử nghiệm trong nghiên cứu cho đến nay. Trong số đó là các phương pháp để hoán đổi (Wei and Zou, 2019), xóa (Huong and Hoang, 2020; Qiu et al., 2020), tạo ra lỗi chính tả (Belinkov and Bisk, 2018; Coulombe, 2018), diễn giải (Kumar et al., 2019), và thay thế từ đồng nghĩa (Kolomiyets et al., 2011; Zhang et al., 2015; Xiang et al., 2021), embedding gần (Alzantot et al., 2018; Wang and Yang, 2015) và từ được dự đoán bởi một mô hình ngôn ngữ (Fadaee et al., 2017; Jiao et al., 2019; Kobayashi, 2018) ở cấp độ từ. Ở cấp độ rộng hơn, các phương pháp thay đổi cây phụ thuộc (Şahin and Steedman, 2018; Xu et al., 2016), thực hiện dịch thuật khứ hồi (Kruspe et al., 2018; Sennrich et al., 2016), hoặc nội suy các thể hiện đầu vào (Chawla et al., 2002; Zhang et al., 2018) được sử dụng. Các nghiên cứu tiếp theo đã xử lý các phương pháp sinh văn bản để tăng cường dữ liệu. Trong khi Rizos et al. (2019) và Sun and He (2020) sử dụng mạng nơ-ron hồi tiếp và mạng đối nghịch sinh để tăng cường văn bản ngắn, Qiu et al. (2020) lấy mẫu các thể hiện từ một bộ tự mã hóa biến phân không có hạn chế độ dài. Hơn nữa, Wang and Lillis (2020) và Anaby-Tavor et al. (2020) đã sử dụng mô hình GPT-2 để sinh văn bản. Một phân tích chi tiết hơn, phân loại và liệt kê các kỹ thuật tăng cường dữ liệu có thể được tìm thấy trong khảo sát tăng cường dữ liệu của Bayer et al. (2021).

Tuy nhiên, thách thức nhiều hướng nghiên cứu trong lĩnh vực này, Longpre et al. (2020) đưa ra giả thuyết rằng tăng cường dữ liệu văn bản chỉ hữu ích nếu dữ liệu được tạo ra chứa các mẫu ngôn ngữ mới có liên quan đến tác vụ và chưa được thấy trong tiền huấn luyện.

2.2 Khoảng trống Nghiên cứu

Phương pháp tăng cường dữ liệu của chúng tôi được lấy cảm hứng từ các phương pháp sinh văn bản từ Rizos et al. (2019), Sun and He (2020) và Qiu et al. (2020) đồng thời cũng xem xét các hạn chế được nêu bởi Longpre et al. (2020) và tìm cách giải quyết ba khoảng trống nghiên cứu chính:

1. Xem xét văn bản ngắn và dài trong khi duy trì tính nhất quán và đạt được độ mới lạ cao;
2. bảo tồn nhãn và chất lượng của phương pháp tăng cường;
3. vượt qua thách thức của tính hữu ích hạn chế của tăng cường dữ liệu văn bản kết hợp với các mô hình tiền huấn luyện.

Đầu tiên, trái ngược với các công trình của Rizos et al. (2019) và Qiu et al. (2020), chúng tôi xem xét văn bản ngắn cũng như dài như các thể hiện dữ liệu đầu vào cho phương pháp tăng cường của chúng tôi, được bao gồm rõ ràng bởi các câu hỏi nghiên cứu 1.1 và 1.2. Ngoài ra, và liên quan đến câu hỏi nghiên cứu chính, phương pháp của chúng tôi được đặc trưng bởi việc bảo tồn nhãn đáng kể kết hợp với độ mới lạ và tính nhất quán của dữ liệu. Lúc đầu, việc sinh được làm phong phú với một tinh chỉnh đặc biệt và bổ sung tiền tố. Sau đó, một bộ lọc embedding tài liệu được áp dụng để các thể hiện không liên quan đến lớp thực tế được loại bỏ. Do đó, khả năng sinh có thể được sử dụng ở mức độ đầy đủ trong khi điều chỉnh chúng cho dữ liệu lớp. Hơn nữa, các thí nghiệm của chúng tôi dựa trên mô hình GPT-2 của Radford et al. (2018) đạt được kết quả rất tốt trong sinh văn bản.

Thứ hai, khi nói đến việc sử dụng mô hình GPT-2, Wang and Lillis (2020) không mô tả các biện pháp cho việc bảo tồn nhãn và chất lượng trong tăng cường GPT-2 của họ. Anaby-Tavor et al. (2020) chỉ ra rằng mô hình GPT-2 sẽ được huấn luyện thêm và các thể hiện được tạo ra không phù hợp sẽ được loại bỏ. Trái ngược với phương pháp của chúng tôi, mô hình của Anaby-Tavor et al. (2020) chỉ giới hạn độc quyền trên các câu như thể hiện và không thể tạo ra văn bản nhất quán. Hơn nữa, nó sử dụng các cơ chế an toàn khác cho việc bảo tồn nhãn. Ví dụ, họ sử dụng một

--- TRANG 4 ---
4
cơ chế lọc dựa trên một bộ phân loại, được huấn luyện trên dữ liệu lớp. Điều này có thể làm giảm nghiêm trọng tính đa dạng của phương pháp tăng cường dữ liệu.

Thứ ba, phương pháp được đề xuất trong bài báo này nhằm vượt qua vấn đề rằng tăng cường dữ liệu văn bản có thể không có giá trị hoặc có giá trị nhỏ khi sử dụng kết hợp với các bộ phân loại tiền huấn luyện (Longpre et al., 2020). Trái ngược với nghiên cứu của Longpre et al. (2020), chúng tôi sử dụng mô hình ULMFit của Howard and Ruder (2018). Tuy nhiên, mô hình cũng được tiền huấn luyện trước và tinh chỉnh trên mỗi bộ dữ liệu tác vụ. Như một đặc tính, chúng tôi cũng tinh chỉnh bộ mã hóa với dữ liệu được tăng cường cho đường cơ sở, đảm bảo rằng ít nhất bộ mã hóa đã thấy tất cả các mẫu ngôn ngữ trước đó.

3 Khái niệm và Thực hiện

3.1 Thiết kế Khái niệm

Quá trình sinh văn bản có thể dựa trên bất kỳ mô hình ngôn ngữ nào có khả năng sinh văn bản tốt. Các mô hình ngôn ngữ chỉ ra một phân phối xác suất của các chuỗi từ:

P(wt|wt-k;::;wt-1)∀t (1)

Mô hình P dự đoán xác suất rằng từ hiện tại là wt cho các từ tiền nhiệm (ngữ cảnh) wt-1;:::;wt-k. Điều này cho phép P tạo ra các văn bản. Một tiền tố cụm từ có thể được sử dụng như ngữ cảnh để làm cho mô hình theo một chủ đề nhất định bằng cách hoàn thành chính xác phần này, trừu tượng hóa từ các đặc điểm cụ thể như các phương pháp lấy mẫu. Ngoài ra, một tham số nhiệt độ có thể được giới thiệu để điều chỉnh tính ngẫu nhiên trong việc tạo ra các văn bản bằng cách chia tỷ lệ các logit trong softmax. Để cho phép việc sử dụng hợp lý một mô hình ngôn ngữ cho tăng cường dữ liệu, phải đảm bảo rằng quy trình chủ yếu tạo ra các văn bản tương tự với dữ liệu huấn luyện và, ngoài ra, phản ánh lớp tương ứng (bảo tồn nhãn hoặc an toàn). Trong phần sau, phương pháp tăng cường của chúng tôi được mô tả, bao gồm đặc tả của ba bước để mô hình hóa hành vi này.

Trong bước đầu tiên, mô hình tiền huấn luyện P được huấn luyện thêm (tinh chỉnh) với dữ liệu huấn luyện Xc của lớp c cần được làm phong phú. Một mặt, điều này cho phép mô hình học các từ, chính tả và hình thức của dữ liệu huấn luyện. Mặt khác, một độ thiên lệch được tạo ra đối với lớp được chọn. Điều này có nghĩa là, đối với việc tạo ra dữ liệu, lớp được chọn có thể được giữ lại một cách rõ ràng hơn. Trong phần sau, chúng tôi phân biệt giữa quá trình tăng cường dữ liệu có ngữ cảnh phù hợp cho các văn bản dài hơn và một quá trình độc lập ngữ cảnh cho các thể hiện huấn luyện ngắn hơn.

Để tăng cường thêm tính an toàn và bảo tồn nhãn, các token "bắt đầu văn bản" đặc biệt được thêm vào mỗi dữ liệu huấn luyện trong đầu vào tinh chỉnh. Trong giai đoạn sinh văn bản, các token này được sử dụng như tiền tố sinh, báo hiệu cho mô hình tạo ra các văn bản tương tự với dữ liệu huấn luyện cụ thể. Điều này đảm bảo rằng các ví dụ được tăng cường khác nhau với nhau nhưng vẫn dựa trên dữ liệu thực tế. Nếu dữ liệu huấn luyện bao gồm các văn bản dài hơn, tức là các thể hiện chứa hơn 280 ký tự, token này có thể được chọn dựa trên ngữ cảnh, ví dụ, bằng cách nối các từ đầu tiên hoặc tiêu đề của mỗi thể hiện (ví dụ, "<|startoftext|>(w1:::wk)i" trong đó (w1:::wk)i là chuỗi bắt đầu của thể hiện i). Điều này dẫn đến tính đa dạng cao của dữ liệu được tạo ra. Mặc dù, nếu các văn bản của bộ dữ liệu ngắn và không có token ngữ cảnh có thể được sử dụng để nối, biến thể độc lập ngữ cảnh được chọn, trong đó số lần xuất hiện của thể hiện trong tập huấn luyện được nối (ví dụ, "<|startoftext|>|i|" trong đó i là lần xuất hiện). Vì mô hình ngôn ngữ được tinh chỉnh trên dữ liệu huấn luyện, có thể giả định rằng nó học cách liên kết token duy nhất với thể hiện tương ứng. Nhờ đó, mô hình có thể nhận ra tiền tố và hoàn thành nó dựa trên việc ghi nhớ. Cuối cùng, điều này ngụ ý một việc bảo tồn nhãn được tăng cường. Tuy nhiên, để dữ liệu không được sản xuất lại hoàn toàn từ bộ nhớ, sự không chắc chắn được đưa vào trong việc lấy mẫu bằng cách điều chỉnh tham số nhiệt độ.

Lọc dữ liệu được tạo ra là phép suy luận cuối cùng để tăng việc bảo tồn nhãn. Với mục đích này, các embedding tài liệu cho mỗi thể hiện của các văn bản được tạo ra và dữ liệu huấn luyện của một lớp được tạo ra. Các embedding phản ánh nội dung của các thể hiện tương ứng. Nếu trong không gian tiềm ẩn này một thể hiện dữ liệu từ dữ liệu được tạo ra Xgen quá xa với dữ liệu huấn luyện thực tế Xc của lớp cần được tăng cường, có thể giả định rằng nội dung khác nhau về mặt ngữ nghĩa và/hoặc cú pháp, đó là lý do tại sao dữ liệu như vậy bị loại bỏ:

Xfiltered = {xi ∈ Xgen|dist(Emb(xi), Centroid(Emb(Xc))) < τ}(2)

Mô hình sinh lớn có thể nội suy nội dung văn bản một cách hợp lý và không tầm thường. Những khả năng này rất hứa hẹn cho tăng cường dữ liệu bằng cách tạo ra các mẫu có tính đa dạng cao nhất quán và chứa các mẫu ngôn ngữ và ngữ nghĩa mới đối với dữ liệu thực tế. Tuy nhiên, chỉ thông qua việc áp dụng các bước bảo mật, mô hình mới có thể tạo ra dữ liệu liên quan đến lớp không đại diện cho nhãn sai.

--- TRANG 5 ---
5
3.2 Thực hiện

Hình 1 cho thấy và tóm tắt ba bước khác nhau của việc tăng cường an toàn, được sắp xếp theo thứ tự thuật toán. Tính an toàn lớp của quy trình có thể được tăng lên đáng kể bởi điều này, mặc dù không thể hoàn toàn loại trừ rằng nhãn đúng được thu được. Để thực hiện, chúng tôi sử dụng GPT-2 của Radford et al. (2018) với 355 triệu tham số. Chúng tôi sử dụng GPT-2 vì nó phù hợp tốt cho phân tích dữ liệu nhỏ do khả năng sinh đa dạng của nó đến từ kích thước. Mô hình được làm phong phú với ba phần mở rộng khác nhau được thảo luận trong phần thiết kế khái niệm.

Trong các bước đầu tiên, mô hình GPT-2 được nhập và dữ liệu lớp cụ thể được trích xuất. Sau đó, tất cả các thể hiện của lớp này được đưa một token tiền tố ("<|startoftext|>|{num}|") và token hậu tố ("<|endoftext|>"). Nếu dữ liệu huấn luyện bao gồm các thể hiện dài hơn với một ngữ cảnh có thể nhúng, trường "|{num}|" được loại bỏ. Trong tất cả các trường hợp khác "{num}" được thay thế bằng vị trí của thể hiện dữ liệu hiện tại. Sau đó, mô hình được tinh chỉnh với dữ liệu này vài trăm hoặc vài nghìn epoch, tùy thuộc vào kích thước bộ dữ liệu, để loss của mô hình được giảm đáng kể. Điều này sẽ đảm bảo đầy đủ rằng mô hình ưu tiên dữ liệu huấn luyện trong việc sinh.

Sau đó, các văn bản được tạo ra cho mỗi thể hiện lớp. Nếu các thể hiện huấn luyện vượt quá một số từ nhất định, chúng được coi là dài và token "<|startoftext|>" và một ngữ cảnh cụ thể của tài liệu (ví dụ tiêu đề hoặc các từ đầu tiên) được thêm vào việc sinh, nếu không "<|startoftext|>" được sử dụng kết hợp với chỉ số của thể hiện tương ứng. Nhiệt độ giữa 0.7 và 0.9 nên được đặt trong bước sinh (Woolf, 2019), trong đó số cao hơn đại diện cho tính ngẫu nhiên/sáng tạo lớn hơn. Trong bước cuối cùng của quy trình, dữ liệu được tạo ra được lọc. Điều này được thực hiện bằng cách sử dụng Sentence-BERT (Reimers and Gurevych, 2019) để tạo embedding tài liệu của dữ liệu. Các thể hiện được tạo ra quá xa, theo một ngưỡng được đặt thủ công, từ trung tâm của dữ liệu đúng, được xóa khỏi tập kết quả. Để giảm thiểu tương tác này, một giá trị được xác định trước (ví dụ 0.3) được đặt và thuật toán hiển thị 10 thể hiện xa nhất vẫn nằm trong ngưỡng này. Tùy thuộc vào có bao nhiêu thể hiện sai, ngưỡng được di chuyển xa hơn và quá trình được bắt đầu lại. Ví dụ, nếu có một thể hiện sai trong tập 10 thể hiện được tạo ra, ngưỡng được tăng nhẹ. Nếu chỉ có các thể hiện đúng, ngưỡng được giảm. Điều này được thực hiện cho đến khi một tham số có ý nghĩa được tìm thấy.

Các thuật toán cho các thể hiện dài và ngắn được đưa ra trong phụ lục C.

Hình 1 Ba bước để tăng xác suất của một thể hiện bảo tồn nhãn trong sinh văn bản GPT-2 (tăng an toàn). Trong bước đầu tiên, một token bắt đầu có ngữ cảnh hoặc được đánh số được thêm vào mỗi thể hiện huấn luyện để điều này có thể được sử dụng như một tiền tố sinh cho mỗi lớp sau bước thứ hai, trong đó mô hình GPT-2 được huấn luyện thêm. Sau khi sinh văn bản, trong bước cuối cùng một lọc được thực hiện sử dụng embedding tài liệu BERT để các thể hiện lệch đáng kể không được bao gồm.

4 Đánh giá

4.1 Lựa chọn Lĩnh vực Ứng dụng

Để tiến hành đánh giá của chúng tôi, chúng tôi đã chọn ba trường hợp phân tích cảm xúc, phân loại tin tức và tin học khủng hoảng. Đầu tiên, phân tích cảm xúc, theo Medhat et al. (2014), là việc phân tích ý kiến, thái độ và cảm xúc đối với cá nhân, sự kiện hoặc chủ đề. Đây là một tác vụ NLP rất phổ biến và được sử dụng trong nhiều ứng dụng, vì, ví dụ, quá trình ra quyết định của các tổ chức và cá nhân ngày càng phụ thuộc vào ý kiến công chúng (Liu and Zhang, 2012). Vì nó là một phần của một số benchmark học máy văn bản và được sử dụng rộng rãi trong nghiên cứu, đây là một tác vụ hợp lý cho các thí nghiệm của bài báo này. Để đặt thí nghiệm này trong bối cảnh phân tích dữ liệu nhỏ, một phiên bản được lấy mẫu giảm nhân tạo sẽ được sử dụng.

Thứ hai, do số lượng tin tức và nguồn thông tin của chúng ngày càng tăng, việc theo dõi các chủ đề và tìm kiếm các bài báo cụ thể trở nên ngày càng phức tạp (Carreira et al., 2004). Các bộ phân loại được sử dụng để tự động chia tin tức thành các lớp được xác định trước (Krishnalal et al., 2010). Tuy nhiên, tin tức có tính động cao, để các lĩnh vực nguồn liên tục thay đổi và các lớp mới xuất hiện. Như một ví dụ cực đoan trong bối cảnh này, người ta có thể so sánh cảnh quan tin tức trước và sau khi COVID-19 xảy ra. Những thay đổi và chủ đề mới xuất hiện như vậy có kết quả là dữ liệu mới phải được gán nhãn mọi lúc, dẫn đến các bộ phân loại với cơ sở dữ liệu nhỏ. Trong khi điều này đã đủ để tạo thành một trọng tâm trong nghiên cứu này, chúng tôi cũng quan tâm đến việc khám phá phân loại cũng như tăng cường dữ liệu cho các văn bản lớn, vì điều này nhận được ít sự chú ý trong nghiên cứu.

--- TRANG 6 ---
6
Thứ ba, lĩnh vực nghiên cứu tin học khủng hoảng dựa trên các quan điểm khoa học máy tính và xã hội để nghiên cứu các cách mà ICT cho phép, hạn chế và làm trung gian cho các thực hành của con người liên quan đến khủng hoảng và thảm họa (Soden and Palen, 2018). Bên cạnh các chủ đề về giao tiếp khủng hoảng, tương tác cộng đồng và hợp tác liên tổ chức (Reuter et al., 2012), tin học khủng hoảng xem xét việc áp dụng học máy để giảm tình trạng quá tải thông tin của thông tin không liên quan, trích xuất thông tin hữu ích từ phương tiện truyền thông xã hội (ví dụ, báo cáo nhân chứng, tập tin đa phương tiện), và nâng cao chất lượng thông tin cho cả nhận thức tình huống được cải thiện và ra quyết định của các dịch vụ khẩn cấp (Kaufhold, 2021). Mặc dù có khối lượng đáng kể dữ liệu lớn xã hội được phát tán trong các tình huống khẩn cấp quy mô lớn, có sự mất cân bằng lớp vì chỉ một số lượng nhỏ các bài đăng trên phương tiện truyền thông xã hội đóng góp vào nhận thức tình huống (Alam et al., 2020). Hơn nữa, các dịch vụ khẩn cấp như phòng cháy chữa cháy hoặc sở cảnh sát thường thiếu tài nguyên tài chính và nhân sự để tham gia vào các tác vụ gán nhãn bộ dữ liệu toàn diện (Imran et al., 2018; Reuter et al., 2016). Ngược lại, có thể có sự thiếu hụt dữ liệu thô có sẵn trong các tình huống khẩn cấp quy mô nhỏ và không phổ biến, đủ điều kiện cho tin học khủng hoảng như một lĩnh vực ứng dụng thú vị cho tăng cường dữ liệu và phân tích dữ liệu nhỏ.

4.2 Mô hình và Bộ dữ liệu

Phù hợp với các câu hỏi nghiên cứu, các phương pháp tăng cường dữ liệu được khái niệm và thực hiện trước đó được đánh giá trong chương này dựa trên một chế độ dữ liệu thấp được xây dựng với bộ dữ liệu SST-2 (Kết quả I) và các chế độ dữ liệu thấp thế giới thực liên quan đến phân loại chủ đề của văn bản dài (Kết quả II) và ngắn (Kết quả III). Chúng tôi sử dụng mô hình ULMFit của Howard and Ruder (2018) bao gồm một bộ mã hóa tiền huấn luyện được kết hợp với một mạng pooling tuyến tính và một đầu ra softmax. Bộ mã hóa được tinh chỉnh cho mỗi tác vụ trên tất cả dữ liệu cụ thể tác vụ có sẵn (bao gồm các thể hiện được tăng cường). Sau đó, toàn bộ mạng được huấn luyện trên một tác vụ có giám sát.

Để đánh giá phương pháp độc lập ngữ cảnh với văn bản ngắn, chúng tôi tập trung vào phân tích cảm xúc và phân loại dữ liệu Twitter khủng hoảng. Phân tích cảm xúc sẽ được thực hiện với các bộ dữ liệu SST-2 được lấy mẫu con (Socher et al., 2013) để mô phỏng một chế độ dữ liệu thấp trên một bộ dữ liệu tiêu chuẩn hóa, tương tự như Hu et al. (2019) và Kumar et al. (2020). Vì những điều kiện được xây dựng này bị hạn chế trong khả năng ứng dụng thế giới thực của chúng, chúng tôi thực hiện các đánh giá tiếp theo với các chế độ dữ liệu thấp thế giới thực.

Các tác vụ phân loại khủng hoảng có tài nguyên rất hạn chế, như được mô tả bởi Kaufhold et al. (2020). Ba bộ dữ liệu đầu tiên từ Olteanu et al. (2015) được gán nhãn theo việc chúng có thông tin hay không về các chủ đề cụ thể liên quan đến Vụ đánh bom Boston, Động đất Bohol và Vụ nổ West Texas năm 2013. Hai bộ dữ liệu khác từ Schulz et al. (2017) bao gồm các bài đăng Twitter cụ thể thành phố được gán nhãn là liên quan sự cố hoặc không.

Để đánh giá phương pháp có ngữ cảnh với văn bản dài, chúng tôi thu thập các bài báo tin tức để phân loại chủ đề từ 2019 và 2020. Cho token bắt đầu có ngữ cảnh, chúng tôi sử dụng các tiêu đề tương ứng. Phân loại chủ đề trong bối cảnh tin tức cũng gặp vấn đề về ít thể hiện dữ liệu, bởi vì tin tức và các chủ đề phụ thuộc thường rất động và dữ liệu nghiên cứu bị hạn chế. Trong trường hợp của chúng tôi, cho mỗi chủ đề, các nhóm chuyên gia gồm hai người quyết định liệu bài báo được kiểm tra có liên quan đến chủ đề hay không. Hơn nữa, có một hướng dẫn gán nhãn cho mỗi chủ đề để loại trừ bất đồng nếu có thể (xem phụ lục B). Các chủ đề bao gồm ba vấn đề kinh tế: sa thải, thay đổi quản lý (MC) và sáp nhập và mua lại (M&A) cũng như hai vấn đề khủng hoảng: lũ lụt và cháy rừng.

Trước khi tăng cường dữ liệu, một phần năm của mỗi tập được chia thành một tập giữ lại.

4.3 Cài đặt Đánh giá và Tiền đánh giá Siêu tham số

Tất cả các phương pháp tăng cường dữ liệu được so sánh với đường cơ sở với sự giúp đỡ của 10 lần thực thi huấn luyện. Ngoài ra, kết quả phân tích cảm xúc được so sánh với phương pháp tăng cường dữ liệu EDA từ Wei and Zou (2019). Cho tác vụ phân tích cảm xúc, chúng tôi tăng cường cả hai lớp, trong khi cho các tác vụ khác chúng tôi tăng cường lớp thiểu số.

Quá trình sinh văn bản cung cấp nhiều khả năng khác nhau cho tối ưu hóa siêu tham số, mà chúng tôi đánh giá với các bộ dữ liệu khác nhau để tránh overfitting. Các nghiên cứu loại bỏ được hiển thị trên bộ dữ liệu cảm xúc (phần 4.4.1). Trong quá trình sinh, mô hình có một tham số nhiệt độ mà, càng lớn thì các văn bản sẽ càng sáng tạo và các mẫu ngôn ngữ mới xuất hiện. Tuy nhiên, một giá trị quá cao có thể dẫn đến các thể hiện không liên quan đến chủ đề. Một giá trị quá thấp có thể có nghĩa là mô hình tự lặp lại rất thường xuyên, trong khi một giá trị quá cao có thể dẫn đến mất chủ đề thực tế trong các văn bản (Khan, 2019). Theo tác giả của việc thực hiện được sử dụng trong bài báo này, giá trị phù hợp nhất là giữa 0.7 và 0.9 (Woolf, 2019). Trong một đánh giá với chủ đề thay đổi quản lý, 0.7 là phù hợp nhất

--- TRANG 7 ---
7
cho trường hợp ứng dụng hiện có, so với 0.8 và 0.9.

Việc lọc các tài liệu được tạo ra có tầm quan trọng trong quá trình này, vì GPT-2 có thể tạo ra các thể hiện mới lạ có thể không có mối quan hệ với lớp thực tế. Tham số của việc lọc này được chọn riêng lẻ để mười tài liệu xa nhất vẫn được đánh dấu tương ứng với lớp. Trong các nghiên cứu loại bỏ của phần 4.4.1, chúng tôi cho thấy rằng việc lọc này là cần thiết để đạt được kết quả cao của phương pháp này.

Một khía cạnh khác có thể được thêm vào tối ưu hóa siêu tham số liên quan đến số lượng tài liệu được tạo ra cho mỗi dữ liệu huấn luyện. Vì đây là một yếu tố rất quan trọng, chúng tôi xem xét nó trong các đánh giá của phần 4.4.1. Các chi tiết khác về siêu tham số của mô hình có thể được tìm thấy trong các phụ lục.

4.4 Kết quả I: Phân tích Cảm xúc (phương pháp độc lập ngữ cảnh)

Các kết quả được coi là tốt từ quan điểm con người cũng được phản ánh trong kết quả đánh giá định lượng, được trình bày trong Bảng 1. Phương pháp tăng cường dữ liệu được đề xuất có kết quả tốt hơn trong hầu hết mọi trường hợp so với đường cơ sở và phương pháp EDA của Wei and Zou (2019). Đặc biệt nó đạt được những cải thiện tốt nhất khi có ít dữ liệu (cộng dồn lên đến 15.53% và 3.56% so với đường cơ sở và EDA). Tuy nhiên, cũng với nhiều dữ liệu nhất, phương pháp tăng cường đạt được trong lần chạy tốt nhất những cải thiện hiệu suất cộng dồn 0.49% và 1.22% so với đường cơ sở và phương pháp EDA.

Phương pháp có những cải thiện cao nhất nếu có ít dữ liệu vì kiến thức tiền nghiệm của mô hình GPT-2 hiệu quả nhất ở đó. Mô hình cũng tạo ra các thể hiện được viết tốt mà điều này không xảy ra với phương pháp EDA đôi khi không cải thiện được đường cơ sở. Hơn nữa, lý do của các phương pháp tăng cường dữ liệu hiệu suất thấp của Longpre et al. (2020) có hiệu lực. Trái ngược với phương pháp EDA, thuật toán tăng cường được đề xuất làm phong phú dữ liệu huấn luyện với các mẫu ngôn ngữ mới chưa được nhìn thấy bởi bộ mã hóa.

4.4.1 Nghiên cứu Loại bỏ

Hơn nữa, chúng tôi muốn hiển thị một đoạn trích của các kết quả liên quan từ các đánh giá loại bỏ của chúng tôi (Hình 3). Đầu tiên, chúng tôi đã thử nghiệm các kích thước tăng cường khác nhau được hiển thị trên bộ dữ liệu SST-2 100. Chúng tôi giới hạn đánh giá này đến tối đa 10 mẫu tăng cường cho mỗi thể hiện, vì số lượng cao hơn đòi hỏi nhiều thời gian tính toán hơn.

Hình 2 Hai thể hiện và các phép biến đổi của chúng bởi EDA và phương pháp của chúng tôi. Thứ nhất từ tác vụ SST-2 4.4 và thứ hai từ tác vụ West Texas Explosion 4.6. Các đoạn văn bản nơi mỗi phương pháp tăng cường cố gắng diễn giải thể hiện gốc được tô sáng bằng màu xanh lam; các nỗ lực nội suy hoặc giới thiệu tính mới lạ được tô sáng bằng màu xanh lá cây.

Rõ ràng rằng kích thước càng cao, kết quả càng tốt. Một kiểm tra của con người chỉ ra rằng ngay cả số lượng cao hơn có thể không có lợi vì sự lặp lại trong các mẫu cho mỗi thể hiện tăng lên. Quá trình kiểm tra của con người được chi tiết trong Phần F trong Phụ lục.

Hơn nữa, chúng tôi cũng loại bỏ các bước của quá trình tăng cường để xem đóng góp của mỗi bước. Trong một trường hợp thử nghiệm đầu tiên, chúng tôi không bao gồm số của thể hiện trong giai đoạn tinh chỉnh và sinh (được chỉ ra bởi "w/o n." trong Hình 3). Sự giảm độ chính xác trung bình 5.42 điểm cho thấy rằng thành phần này rất quan trọng cho toàn bộ quá trình tăng cường. Điều này cũng áp dụng cho bước cuối cùng của phương pháp tăng cường (được chỉ ra bởi "w/o f." trong Hình 3). Không có việc lọc thủ công, độ chính xác trung bình giảm 2.64 điểm. Hiểu biết này đã được nhận thấy khi tham số lọc được chọn trong mỗi tác vụ và một số thể hiện có vẻ không liên quan đến lớp.

Tóm lại, điều này chỉ ra rằng tất cả các bước của quá trình tăng cường cần được bao gồm để đạt được điểm số cao nhất. Các nghiên cứu đánh giá tiếp theo dựa trên sự kết hợp tốt nhất này.

Hơn nữa, chúng tôi đã thực hiện một phân tích lỗi bằng cách kiểm tra các thể hiện được tạo ra của kỹ thuật của chúng tôi và so sánh chúng với phương pháp EDA. Đối với phương pháp của chúng tôi, không rõ từ thể hiện gốc nào việc sinh bắt nguồn, vì nó có thể là một nội suy của nhiều hơn một thể hiện. Tuy nhiên, chúng tôi đã cố gắng tìm các thể hiện gốc gần nhất bằng cách đo sự tương đồng bằng khoảng cách Levenshtein.

Chúng tôi đã chọn một số ví dụ sâu sắc, được trình bày trong Hình 2. Ví dụ đầu tiên cho thấy rằng EDA có thể giữ nhãn, nhưng thay thế một từ không nên được thay thế (oscar wilde play ! academy award wilde play). Mặt khác, phương pháp của chúng tôi có thể tìm các từ phù hợp cho việc thay thế

--- TRANG 8 ---
8
Bảng 1 Độ chính xác của quá trình sinh văn bản không có ngữ cảnh, EDA (Wei and Zou, 2019) và đường cơ sở đối với các mẫu con SST-2 khác nhau (10 lần chạy).

Bộ dữ liệu Chạy Đường cơ sở EDA Sinh văn bản
SST-2 100 TRB (SD) 0.5581 (0.0463) 0.6934 (0.0124) 0.7134 (0.0207)
Tốt nhất 0.6226 0.7139 0.7495
SST-2 300 TRB (SD) 0.7241 (0.0119) 0.7217 (0.0047) 0.7402 (0.0067)
Tốt nhất 0.7417 0.7295 0.7534
SST-2 500 TRB (SD) 0.7505 (0.0077) 0.7534 (0.0074) 0.7598 (0.0126)
Tốt nhất 0.7651 0.7671 0.7754
SST-2 700 TRB (SD) 0.7646 (0.0054) 0.7578 (0.0038) 0.7627 (0.0066)
Tốt nhất 0.7705 0.7632 0.7754

và mở rộng thể hiện gốc một cách có ý nghĩa mà không làm méo mó nhãn hoặc nội dung chung. Tuy nhiên, trong khi chúng tôi không thấy trường hợp này trong phân tích của mình, có thể mô hình ngôn ngữ không thể suy ra nhãn trong quá trình tinh chỉnh và việc tăng cường sẽ thay đổi nhãn. Một trường hợp tương tự có thể được thấy liên quan đến tác vụ Dublin của Phần 4.6, nơi chúng tôi giả định rằng mô hình không thể suy ra nhãn do tính đa dạng rất cao trong các thể hiện và không gian nhãn. Trong khi mô hình không thay đổi nhãn một cách sai, chúng tôi thấy rằng hơn 50% các thể hiện được tạo ra là "????????????". Càng tạo ra nhiều dữ liệu, càng nhiều thể hiện như vậy được tạo ra và các thể hiện giàu nội dung được lặp lại.

Ví dụ thứ hai được hiển thị trong Hình 2 cho thấy rằng phương pháp của chúng tôi mang lại sự biến đổi cao với nội dung hợp lý nhưng cũng diễn giải lại "say state officials" thành "medical examiner says" có thể không đúng. Đối với tác vụ đang thực hiện, điều này không quyết định nhưng có thể đối với các tác vụ rất cụ thể. Hơn nữa, EDA đôi khi thay đổi thể hiện để nó không đúng ngữ pháp, như cũng có thể được thấy trong ví dụ này. Điều này có thể là một vấn đề, ví dụ, khi sử dụng các mô hình ngôn ngữ không mong đợi một biểu thức cụ thể, như "atomic number", trong ngữ cảnh của thể hiện này. Hơn nữa và thậm chí tệ hơn, có thể xảy ra rằng phương pháp xóa một từ thiết yếu, như "not", trong câu "This movie was not bad", tạo ra một thể hiện với nhãn sai khi được sử dụng cho phân loại cảm xúc.

Những ví dụ này cho thấy rằng phương pháp được đề xuất trong bài báo này có thể tạo ra các thể hiện chất lượng cao và đa dạng. Phương pháp EDA thay vào đó đôi khi tạo ra các thể hiện sai hoặc không phù hợp với ngữ cảnh do tính chất ngẫu nhiên của nó, điều này đặc biệt quan trọng khi sử dụng các mô hình ngôn ngữ tiền huấn luyện. Phần F trong Phụ lục cung cấp thêm ví dụ và phân tích về phương pháp tăng cường dữ liệu của chúng tôi. Nó được hiển thị, ví dụ, rằng mô hình đôi khi hoàn toàn nhân bản các thể hiện của dữ liệu huấn luyện. Tính chất này không nhất thiết xấu, vì ít nhất nó có thể được xem như một phương pháp lấy mẫu quá mức tinh vi nhân bản dữ liệu rất quan trọng.

Hình 3 Đánh giá các kích thước tăng cường khác nhau và việc bỏ qua token đánh số (w/o n.) và bước lọc (w/o f.) trên bộ dữ liệu SST-2 100 (10 lần chạy).

4.5 Kết quả II: Phân loại Tin tức (phương pháp phụ thuộc ngữ cảnh)

Một kiểm tra định tính của dữ liệu được tạo ra cho bộ dữ liệu tin tức cho thấy rằng các văn bản chất lượng cao, nhất quán và đa dạng đã được tạo ra cho các tiêu đề bài báo khác nhau. Gần như tất cả các thể hiện đều có tham chiếu rõ ràng đến lớp thực tế. Trong bước lọc, chủ yếu các thể hiện nơi mô hình GPT-2 thường xuyên lặp lại từ được sắp xếp ra.

Kết quả phân loại của phương pháp có ngữ cảnh của chúng tôi được trình bày trong Bảng 2 so với đường cơ sở. Nhìn vào đánh giá tổng thể trên tất cả các chủ đề, có thể thấy rằng các bộ phân loại cũng đạt được kết quả rất tốt thông qua phương pháp tăng cường dữ liệu có ngữ cảnh. Đặc biệt đối với các tác vụ kinh tế, sự tăng tương đối trong giá trị F1 tối đa hơn 4% cho chủ đề MC và sa thải và 2% cho tác vụ M&A có thể được ghi lại. Đánh giá M&A minh họa tầm quan trọng của thước đo F1. Trong khi những cải thiện tốt về độ chính xác cũng được đạt được cho thay đổi quản lý và sa thải, hầu như không có thay đổi trong chủ đề M&A. Tuy nhiên, thước đo F1 quan trọng hơn tăng đáng kể. Một

--- TRANG 9 ---
9
Bảng 2 Độ chính xác và điểm F1 của quá trình sinh văn bản có ngữ cảnh và đường cơ sở đối với năm chủ đề bài báo tin tức (10 lần chạy).

Bộ dữ liệu Chạy Độ chính xác F1
Sa thải TRB (SD) 0.8350 (0.015) 0.7695 (0.012)
Tốt nhất 0.8545 0.7905
với DA TRB (SD) 0.8706 (0.009) 0.8179 (0.011)
Tốt nhất 0.8848 0.8354
MC TRB (SD) 0.8760 (0.005) 0.7217 (0.021)
Tốt nhất 0.8809 0.7627
với DA TRB (SD) 0.8853 (0.015) 0.7559 (0.031)
Tốt nhất 0.9077 0.8052
M&A TRB (SD) 0.8926 (0.005) 0.6953 (0.011)
Tốt nhất 0.8999 0.7075
với DA TRB (SD) 0.8975 (0.003) 0.7095 (0.011)
Tốt nhất 0.8999 0.7266
Lũ lụt TRB (SD) 0.8462 (0.007) 0.8779 (0.007)
Tốt nhất 0.8540 0.8867
với DA TRB (SD) 0.8408 (0.010) 0.8804 (0.006)
Tốt nhất 0.8594 0.8931
Cháy rừng TRB (SD) 0.9287 (0.016) 0.9253 (0.017)
Tốt nhất 0.9419 0.9395
Với DA TRB (SD) 0.9312 (0.007) 0.9297 (0.006)
Tốt nhất 0.9395 0.9375

cải thiện nhỏ cũng rõ ràng cho chủ đề lũ lụt (+0.64 với giá trị F1 tối đa). Đối với chủ đề cháy rừng, phương pháp sinh văn bản không đạt được kết quả tốt hơn. Các giá trị gần như giống với đường cơ sở. Tuy nhiên, độ lệch chuẩn của kết quả từ đường cơ sở cao hơn gấp đôi so với phương pháp tăng cường dữ liệu.

Có thể xác định rằng phương pháp sinh văn bản có ngữ cảnh rất phù hợp cho các tác vụ phân loại chủ đề hiện tại. Một độ thiên lệch có thể đối với các chủ đề kinh tế có thể được quy cho mô hình GPT-2 tiền huấn luyện. Mô hình được huấn luyện với các tài liệu từ các liên kết Reddit đi ra. Có thể có tương đối ít dữ liệu khủng hoảng trong số khoảng 8 triệu tài liệu để mô hình ít có khả năng đại diện cho lĩnh vực chủ đề này. Một giải thích khả thi khác cho các giá trị nhỏ hơn của các chủ đề khủng hoảng là chất lượng phân loại đã rất cao của hai tác vụ. Chủ đề lũ lụt, được chọn vì chất lượng phân loại kém hơn so với chủ đề cháy rừng, vẫn vượt quá ba chủ đề kinh tế trong thước đo F1. Chủ đề cháy rừng là tác vụ tốt nhất cho các bộ phân loại (khoảng +5% thước đo F1 so với tác vụ lũ lụt). Một cải thiện của hai chủ đề có thể không còn khả thi nữa vì bộ dữ liệu có thể chứa lỗi vì một số quyết định gán nhãn khó và chủ quan.

Bảng 3 Độ chính xác và điểm F1 của quá trình sinh văn bản không có ngữ cảnh và đường cơ sở đối với năm chủ đề Twitter khủng hoảng (10 lần chạy).

Bộ dữ liệu Chạy Độ chính xác F1
Boston TRB (SD) 0.7886 (0.019) 0.7344 (0.030)
Bombings Tốt nhất 0.8062 0.7720
với DA TRB (SD) 0.8003 (0.021) 0.7588 (0.024)
Tốt nhất 0.8311 0.7979
Bohol TRB (SD) 0.9097 (0.014) 0.8857 (0.021)
Earthquake Tốt nhất 0.9302 0.9126
với DA TRB (SD) 0.9238 (0.011) 0.9062 (0.015)
Tốt nhất 0.9399 0.9277
West Texas TRB (SD) 0.8486 (0.020) 0.8340 (0.025)
Explosion Tốt nhất 0.8804 0.8765
với DA TRB (SD) 0.8755 (0.010) 0.8721 (0.011)
Tốt nhất 0.9004 0.8970
Dublin TRB (SD) 0.9893 (0.002) 0.9199 (0.015)
Tốt nhất 0.9912 0.9351
với DA TRB (SD) 0.9858 (0.002) 0.8945 (0.014)
Tốt nhất 0.9878 0.9116
New York TRB (SD) 0.9302 (0.016) 0.8428 (0.027)
City Tốt nhất 0.9463 0.8701
với DA TRB (SD) 0.9346 (0.003) 0.8472 (0.007)
Tốt nhất 0.9385 0.8555

4.6 Kết quả III: Tin học Khủng hoảng (phương pháp độc lập ngữ cảnh)

Trong phần cuối, chúng tôi đã nêu rằng GPT-2 có thể ít sử dụng được cho dữ liệu khủng hoảng. Vì việc sử dụng học máy trong các tình huống khủng hoảng rất hứa hẹn và việc có được các mô hình tốt là một vấn đề đang diễn ra do ít dữ liệu và thách thức của thích ứng miền, chúng tôi kiểm tra thêm cân nhắc này bằng cách chỉ tập trung vào dữ liệu khủng hoảng cho đánh giá thứ hai.

Kiểm tra dữ liệu mới được tạo ra, chúng tôi thấy rằng mô hình thường tạo ra các đầu ra giống hệt nhau cho các lần chạy khác nhau. Dữ liệu được tạo ra của các mô hình phụ thuộc ngữ cảnh của đánh giá thứ hai rõ ràng đa dạng hơn. Tuy nhiên, phương pháp độc lập ngữ cảnh cũng có vẻ có tiềm năng thực hiện rất tốt, như Bảng 3 cho thấy. Nó đặc biệt có lợi cho các tác vụ phân loại của Olteanu et al. (2015) (ba bộ dữ liệu đầu tiên). Các giá trị trung bình và các lần chạy tốt nhất vượt trội hơn đường cơ sở cộng dồn 2.1% đến 3.8% và 1.5% đến 2.5% trong thước đo F1. Đối với các tác vụ của Schulz et al. (2017), tuy nhiên, phương pháp không cung cấp bất kỳ cải thiện đáng kể nào liên quan đến điểm số trực tiếp. Đối với bộ dữ liệu Dublin, phương pháp tăng cường thậm chí có vẻ có tác động tiêu cực. Tuy nhiên, một sự giảm trong độ lệch chuẩn F1 được đạt được cho mỗi tác vụ.

Mặc dù chúng tôi có thể xác nhận giả định của phân tích cảm xúc rằng biến thể độc lập ngữ cảnh của phương pháp tăng cường tạo ra ít thể hiện đa dạng hơn, nó tương tự có tác động rất tích cực đến chất lượng phân loại khi áp dụng cho dữ liệu thấp thế giới thực

--- TRANG 10 ---
10
Bảng 4 Hiệu suất F1 trung bình và tối đa của các mô hình tăng cường dữ liệu so với các đối tác đường cơ sở tương ứng của chúng trên tất cả các bộ dữ liệu.

Bộ dữ liệu Delta Trung bình Delta Tối đa
SST-2 (100) - Độ chính xác +15.53% +12.69%
SST-2 (300) - Độ chính xác +1.61% +1.17%
SST-2 (500) - Độ chính xác +0.93% +1.03%
SST-2 (700) - Độ chính xác -0.19% +0.49%
Sa thải - F1 +4.84% +4.49%
MC - F1 +3.42% +4.25%
M&A - F1 +1.42% +1.91%
Lũ lụt - F1 +0.25% +0.64%
Cháy rừng - F1 +0.44% -0.20%
Vụ đánh bom Boston - F1 +2.44% +2.59%
Động đất Bohol - F1 +2.05% +1.51%
Vụ nổ West Texas - F1 +3.81% +2.05%
Dublin - F1 -2.54% -2.35%
Thành phố New York - F1 +0.44% -1.46%

chế độ. Đặc biệt các vấn đề được định nghĩa hẹp bởi Olteanu et al. (2015) rất phù hợp, dẫn đến việc xem xét rằng sự khác biệt của kết quả nằm trong bản chất của các vấn đề. Trong khi ba tác vụ đầu tiên gắn liền với một sự kiện khủng hoảng đặc biệt, hai tác vụ khác chỉ liên quan đến sự cố không có trọng tâm khác ngoài thành phố tương ứng. Có thể là hai tác vụ này được định nghĩa quá rộng với các thể hiện rất khác nhau để mô hình không thể tinh chỉnh đúng cách để tạo ra các thể hiện hợp lý. Ngoài ra, việc tăng về độ mạnh mẽ là rõ ràng có thể nhìn thấy vì một sự giảm trong độ lệch chuẩn F1 được đạt được trên mỗi tác vụ. Đánh giá cũng cho thấy rằng các phương pháp tăng cường dữ liệu của chúng tôi có thể đạt được kết quả tốt không chỉ trên các chủ đề kinh tế.

5 Thảo luận và Kết luận

Trong khi có nhiều phương pháp tăng cường dữ liệu có lợi trong thị giác máy tính, các phép biến đổi văn bản khó định nghĩa hơn (Kobayashi, 2018; Wei and Zou, 2019) và thường dẫn đến kết quả hỗn hợp (Longpre et al., 2020). Để giải quyết những vấn đề này, chúng tôi đã trình bày hai phương pháp tăng cường dữ liệu cho văn bản dài và ngắn dựa trên các kỹ thuật sinh văn bản để nâng cao cơ sở kiến thức về phân tích dữ liệu nhỏ. Kết quả của chúng tôi trên 11 bộ dữ liệu, được liệt kê dưới dạng tổng hợp trong Bảng 4, đóng góp vào việc trả lời các câu hỏi nghiên cứu sau.

Làm thế nào chúng ta có thể sử dụng các phương pháp sinh văn bản của tăng cường dữ liệu đạt được độ mới lạ cao trong dữ liệu trong khi bảo tồn chất lượng nhãn để cải thiện các bộ phân loại học máy tiền huấn luyện (RQ1)? Chúng tôi đề xuất hai phương pháp tăng cường dữ liệu dựa trên các mô hình ngôn ngữ sinh văn bản. Chúng tôi xây dựng ba bước khác nhau (xem Hình 1) để đảm bảo việc bảo tồn nhãn cao trong các phép biến đổi của những mô hình này. Như bước đầu tiên, dữ liệu được chuẩn bị bởi một token đặc biệt. Token này có thể báo hiệu cho mô hình tạo ra dữ liệu huấn luyện cho lớp này trong giai đoạn sinh. Để đảm bảo rằng mô hình quen thuộc với dữ liệu lớp và token, tinh chỉnh được thực hiện với dữ liệu được chuẩn bị trong bước thứ hai. Sau khi sinh, lọc dựa trên embedding tài liệu BERT (Reimers and Gurevych, 2019) tạo thành bước cuối cùng. Trong thiết lập thí nghiệm của chúng tôi, chúng tôi sử dụng một bộ mã hóa tiền huấn luyện và tinh chỉnh nó trên các tác vụ khác nhau, bao gồm dữ liệu được tăng cường, để đối mặt với thách thức tạo ra một phương pháp tăng cường dữ liệu tinh vi cũng thực hiện tốt trên các mô hình tiền huấn luyện. Hai phương pháp được rút ra đạt được kết quả rất tốt trong giai đoạn đánh giá với một số mức tăng hiệu suất và giảm độ lệch chuẩn.

Khi đánh giá tính hữu ích của thuật toán, tuy nhiên, các tiêu chí khác phải được xem xét. Trong khi việc nhúng phương pháp tăng cường vào một quá trình phân loại khá dễ dàng, mô hình GPT-2 cần một số thời gian để được thực thi. Việc tạo ra một ví dụ của một bộ dữ liệu dài mất khoảng 10-30 giây. Các phương pháp tạo nhiễu như EDA mất ít hơn một giây để hoàn thành một thể hiện, vì chúng chỉ thực hiện các hoạt động đơn giản như thay đổi thứ tự từ, xóa một số từ, hoặc tạo ra lỗi chính tả (Huong and Hoang, 2020; Qiu et al., 2020; Belinkov and Bisk, 2018; Coulombe, 2018). Tuy nhiên, các phương pháp sinh văn bản như của chúng tôi bị hạn chế bởi thời gian cần thiết bởi quá trình sinh. Tuy nhiên, so với thời gian cần thiết cho một con người để gán nhãn một thể hiện mới, phương pháp của chúng tôi vẫn rất có lợi. Thời gian cần thiết cũng có thể được giảm đáng kể, ví dụ, bằng cách sử dụng một mô hình ngôn ngữ khác nhanh hơn. Hơn nữa, mô hình GPT-2 được sử dụng chủ yếu giới hạn ở tiếng Anh, làm cho nó ít sử dụng được cho các tác vụ đa ngôn ngữ. Tuy nhiên, điều này cũng có thể được giảm thiểu bằng cách sử dụng một mô hình ngôn ngữ khác vì phương pháp được đề xuất phù hợp cho các mô hình ngôn ngữ khác nhau.

Theo cách nào việc kết hợp ngữ cảnh của các thể hiện văn bản dài trong các bài toán phân loại hữu ích khi sử dụng sinh văn bản như phương pháp tăng cường dữ liệu (RQ1.1)? Khi xử lý văn bản dài, chúng tôi quyết định tích hợp một token dựa trên ngữ cảnh trong giai đoạn sinh để các văn bản được tạo ra rõ ràng hơn cho thể hiện tương ứng và có tính đa dạng cao giữa tất cả các thể hiện. Một cái nhìn sâu hơn vào các mẫu được tạo ra từ giai đoạn đánh giá xác nhận giả định này. Hơn nữa, các thể hiện được tạo ra có vẻ rất nhất quán và liên quan đến tác vụ đang thực hiện, do điểm mạnh của mô hình ngôn ngữ GPT-2. Quan trọng hơn, bốn trong số năm tác vụ có thể được cải thiện bằng cách bao gồm các thể hiện mới được tạo ra và lọc. Điều này dẫn đến sự tăng cộng dồn trong giá trị F1 trung bình và tối đa lên đến 4.8% và 4.5% tương ứng. Tuy nhiên, chúng tôi nhận thấy rằng kỹ thuật tăng cường không thể cải thiện kết quả phân loại khi bộ phân loại đã thực hiện rất tốt mà không có dữ liệu bổ sung.

Làm thế nào có thể đạt được cải thiện chất lượng cho các tác vụ phân loại với văn bản ngắn khi tăng cường với sinh văn bản (RQ1.2)? Đối với các tác vụ phân loại với văn bản ngắn, việc tích hợp token dựa trên ngữ cảnh không khả thi, vì vậy chúng tôi bao gồm số mà thể hiện tương ứng xuất hiện trong tinh chỉnh. Kiểm tra kỹ hơn các thể hiện mới được tạo ra, một số bản sao được tìm thấy. Điều này không có ý nghĩa tiêu cực cho đánh giá, vì việc lặp lại một số ví dụ huấn luyện giống với quá trình lấy mẫu quá mức đơn giản. Nó thậm chí có thể được diễn giải như một phiên bản tinh vi hơn, trong đó một số ví dụ hoàn toàn mới và những ví dụ khác được lấy mẫu quá mức từ các điểm dữ liệu phù hợp nhất. Theo đó, một mức tăng hiệu suất lớn có thể được đạt được trong các chế độ dữ liệu thấp được xây dựng và thế giới thực, dẫn đến cải thiện lên đến 15.53 và 3.81 điểm tương ứng. Chúng tôi nhận thấy rằng phương pháp tăng cường này không phù hợp cho hai tác vụ thế giới thực đặc biệt. Chúng tôi đưa ra giả thuyết rằng hai tác vụ này được định nghĩa quá rộng trên cơ sở rằng mô hình GPT-2 không thể suy ra ngữ cảnh đúng chỉ dựa trên tinh chỉnh dữ liệu.

5.1 Đóng góp Thực nghiệm, Thực tiễn và Lý thuyết

Xem xét các phát hiện của chúng tôi, nghiên cứu đã tiết lộ các đóng góp thực tiễn, lý thuyết và thực nghiệm:

Các phương pháp tăng cường dữ liệu mới dựa trên mô hình ngôn ngữ GPT-2. Kết quả đánh giá của các phương pháp tăng cường dữ liệu cho thấy rằng mô hình GPT-2, kết hợp với ba bước an toàn, có thể đạt được cải thiện đáng kể trong các tác vụ phân loại văn bản (xem Bảng 1 đến 3). Trái ngược với các phương pháp tương tự của Wang and Lillis (2020) và Anaby-Tavor et al. (2020) cũng sử dụng GPT-2 để sinh văn bản, phương pháp của chúng tôi áp dụng được tổng quát hơn và cung cấp nhiều bước an toàn hơn. Wang and Lillis (2020) không mô tả các biện pháp cho việc bảo tồn nhãn trong phương pháp của họ, và Anaby-Tavor et al. (2020) chỉ cho phép tăng cường dữ liệu cho các thể hiện bao gồm một câu. Hơn nữa, chúng tôi bao gồm một cơ chế lọc bao gồm chuyên môn của con người, tăng mạnh tính đa dạng mà không cần nhiều giám sát. Những lợi thế của phương pháp sinh văn bản được đề xuất ở đây tạo điều kiện cho việc sử dụng rộng rãi, đủ điều kiện như yếu tố cơ bản để thích ứng thêm trong các ứng dụng phân loại tương lai.

Một cơ sở tăng cường dữ liệu văn bản có lợi cho các mô hình phân loại tiền huấn luyện. Longpre et al. (2020) cho thấy rằng tăng cường dữ liệu có thể không hữu ích khi xử lý các mô hình tiền huấn luyện hiện đại. Điều này có vẻ logic từ quan điểm lý thuyết vì tiền huấn luyện và chuyển giao đến các tác vụ mới cũng theo mục tiêu giảm lượng dữ liệu huấn luyện cần thiết. Để có được sự làm phong phú dù sao, các phương pháp tăng cường tinh vi là cần thiết, mà nên cung cấp các mẫu ngôn ngữ chưa thấy có liên quan đến tác vụ (Longpre et al., 2020). Chúng tôi giải quyết vấn đề này bằng cách tận dụng mô hình GPT-2 được huấn luyện với hơn 8 triệu trang web. Điều này mang lại tiềm năng lớn để bao gồm các mẫu ngôn ngữ mới trong dữ liệu được tạo ra (các thể hiện ví dụ có thể được tìm thấy trong phụ lục F). Để tạo ra dữ liệu liên quan đến tác vụ, chúng tôi rút ra ba bước tăng khả năng nội dung liên quan đến lớp. Trong đánh giá, chúng tôi cho thấy rằng phương pháp được đề xuất có thể cải thiện mô hình mã hóa tiền huấn luyện. Trái ngược với Longpre et al. (2020), chúng tôi không thử nghiệm phương pháp trên một mô hình transformer. Tuy nhiên, chúng tôi huấn luyện bộ mã hóa ULMFit tiền huấn luyện cho cả hai trường hợp thử nghiệm (không tăng cường và tăng cường) với dữ liệu được tăng cường để đối với bộ mã hóa không có dữ liệu nào chưa thấy trước đó.

Hiểu biết thực nghiệm về ứng dụng cụ thể lĩnh vực của phân tích dữ liệu nhỏ. Trong công trình này, chúng tôi thu thập những hiểu biết thực nghiệm mới về ứng dụng tăng cường dữ liệu trong các lĩnh vực nghiên cứu phân tích cảm xúc, phân loại tin tức và tin học khủng hoảng. Trong tin học khủng hoảng, nhiều nghiên cứu đã xem xét việc sử dụng thích ứng miền, học chuyển giao, học tích cực và học trực tuyến để giảm nỗ lực gán nhãn (Imran et al., 2018; Kaufhold et al., 2020; Nguyen et al., 2017). Tuy nhiên, ít nghiên cứu đã xem xét việc áp dụng tăng cường dữ liệu văn bản cho quản lý khủng hoảng (Wang and Lillis, 2020), mà chúng tôi nâng cao bằng đánh giá và diễn giải bảy bộ dữ liệu được tăng cường. Đối với phân tích cảm xúc, chúng tôi xây dựng một chế độ dữ liệu thấp, như Kumar et al. (2019) và Hu et al. (2019). Nghiên cứu phân tích dữ liệu nhỏ đang trở nên phổ biến và có nhu cầu thiết lập các bộ dữ liệu có thể được sử dụng, hiểu và so sánh bởi tất cả các loại nhà nghiên cứu. Chúng tôi tăng cường hướng nghiên cứu này bằng cách dựa đánh giá của chúng tôi trên bộ dữ liệu này. Hơn nữa, với năm bộ dữ liệu phân loại tin tức, chúng tôi đang khám phá chủ đề quan trọng của phân loại văn bản dài, thường bị bỏ qua trong nghiên cứu. Phân loại tin tức chủ yếu được thực hiện chỉ với các mô tả ngắn của các bài báo, như trong bộ dữ liệu AG News (Zhang et al., 2015).

--- TRANG 11 ---
11
5.2 Hạn chế và Triển vọng

Trong quá trình đánh giá, một hạn chế đã được thực hiện đối với mô hình ngôn ngữ được sử dụng. Trong khi có thể áp dụng với các mô hình ngôn ngữ khác, không rõ liệu mức tăng hiệu suất vẫn giữ nguyên. Mô hình GPT-3 của Brown et al. (2020) có vẻ là lựa chọn hợp lý tiếp theo để tăng kết quả. Tuy nhiên, bước tinh chỉnh có khả năng cần thiết hiện tại không khả thi do việc sử dụng tài nguyên cao của mô hình. Tuy nhiên, do kích thước và tính biểu đạt ngôn ngữ của nó, nó có thể đặc biệt hữu ích để giải quyết thách thức được nêu bởi Longpre et al. (2020) trong đó các mô hình tiền huấn luyện có thể không đạt được bất kỳ cải thiện nào từ tăng cường dữ liệu. Liên quan đến nghiên cứu của Longpre et al. (2020), nghiên cứu tương lai có thể thử nghiệm phương pháp được đề xuất với các mô hình transformer. Cũng sẽ thú vị khi xem các mô hình ngôn ngữ nhỏ hơn thực hiện như thế nào, có thể nhanh hơn nhiều. Ngoài ra, cũng có thể có tùy chọn để tự động hóa hoàn toàn bước lọc, điều này tăng thêm tính khả dụng phổ quát, ngay cả khi nỗ lực của con người đã rất thấp bây giờ.

Mặc dù có nhiều nỗ lực trong tăng cường dữ liệu, vấn đề rào cản dữ liệu lớn được đề cập ở đầu vẫn có tầm quan trọng lớn. Tuy nhiên, nếu trong tương lai, theo nhiều giả định khác nhau, các mô hình rất lớn, như GPT-3 của Brown et al. (2020), có khả năng giải quyết tốt hơn những vấn đề này, vấn đề rào cản tài nguyên cao mở ra, chỉ cho phép các công ty lớn huấn luyện và sử dụng những mô hình này.

Lời cảm ơn Công trình này được đồng tài trợ bởi Bộ Giáo dục và Nghiên cứu Liên bang Đức (BMBF) trong dự án CYWARN (13N15407) và bởi sáng kiến LOEWE (Hesse, Đức) trong trung tâm emergenCITY. Các tính toán cho nghiên cứu này được thực hiện trên máy tính hiệu suất cao Lichtenberg của TU Darmstadt.

Tài liệu tham khảo

Şahin GG, Steedman M (2018) Tăng Cường Dữ liệu thông qua Biến Đổi Cây Phụ thuộc cho Ngôn ngữ Tài nguyên Thấp. Trong: Kỷ yếu Hội nghị 2018 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên, DOI 10.18653/v1/d18-1545

Alam F, Ofli F, Imran M (2020) Tóm tắt mô tả và trực quan của các sự kiện thảm họa sử dụng kỹ thuật trí tuệ nhân tạo: nghiên cứu trường hợp của các cơn bão harvey, irma, và maria. Behaviour & Information Technology 39(3):288–318, DOI 10.1080/0144929X.2019.1610908

Alzantot M, Sharma Y, Elgohary A, Ho BJ, Srivastava MB, Chang KW (2018) Tạo ra các ví dụ đối nghịch ngôn ngữ tự nhiên. Trong: Kỷ yếu EMNLP, DOI 10.18653/v1/d18-1316

Anaby-Tavor A, Carmeli B, Goldbraich E, Kantor A, Kour G, Shlomov S, Tepper N, Zwerdling N (2020) Không Có Đủ Dữ liệu? Deep Learning đến Giải cứu! Kỷ yếu AAAI URL http://arxiv.org/abs/1911.03118

Banko M, Brill E (2001) Mở rộng quy mô đến các corpus rất rất lớn cho việc loại bỏ sự mơ hồ ngôn ngữ tự nhiên. Trong: Kỷ yếu cuộc họp thường niên lần thứ 39 của Hiệp hội Ngôn ngữ học Tính toán, DOI 10.3115/1073012.1073017

Bayer M, Kaufhold MA, Reuter C (2021) Một Khảo sát về Tăng Cường Dữ liệu cho Phân loại Văn bản. arXiv

Belinkov Y, Bisk Y (2018) Nhiễu tổng hợp và tự nhiên đều phá vỡ dịch máy nơ-ron. Trong: Kỷ yếu ICLR

Brown TB, Mann B, Ryder N, Subbiah M, Kaplan J, Dhariwal P, Neelakantan A, Shyam P, Sastry G, Askell A, Agarwal S, Herbert-Voss A, Krueger G, Henighan T, Child R, Ramesh A, Ziegler DM, Wu J, Winter C, Hesse C, Chen M, Sigler E, Litwin M, Gray S, Chess B, Clark J, Berner C, McCandlish S, Radford A, Sutskever I, Amodei D (2020) Các Mô hình Ngôn ngữ là Người học Few-Shot. Trong: NeurIPS, URL http://arxiv.org/abs/2005.14165

Carreira R, Crato JM, Gonçalves D, Jorge JA (2004) Đánh giá hồ sơ người dùng thích ứng cho phân loại tin tức. Trong: Kỷ yếu IUI, DOI 10.1145/964442.964481

Chawla NV, Bowyer KW, Hall LO, Kegelmeyer WP (2002) SMOTE: Kỹ thuật lấy mẫu quá mức thiểu số tổng hợp. JAIR DOI 10.1613/jair.953

Coulombe C (2018) Tăng Cường Dữ liệu Văn bản Được Đơn giản hóa Bằng Cách Tận dụng API Đám mây NLP. Trong: arXiv preprint arXiv:1812.04718, pp 1–33, URL http://arxiv.org/abs/1812.04718

Fadaee M, Bisazza A, Monz C (2017) Tăng cường dữ liệu cho dịch máy nơ-ron tài nguyên thấp. Trong: ACL, DOI 10.18653/v1/P17-2090

Howard J, Gugger S (2020) Fastai: Một api nhiều lớp cho deep learning. Information (Switzerland) DOI 10.3390/info11020108

Howard J, Ruder S (2018) Tinh chỉnh mô hình ngôn ngữ phổ quát cho phân loại văn bản. Trong: Kỷ yếu ACL, DOI 10.18653/v1/p18-1031

Hu YQ, Yu Y (2020) Một góc nhìn kỹ thuật về tìm kiếm kiến trúc nơ-ron. International Journal of Machine Learning and Cybernetics 11(4):795–811, DOI 10.1007/s13042-020-01062-1

Hu Z, Tan B, Salakhutdinov R, Mitchell T, Xing EP (2019) Học thao tác dữ liệu cho tăng cường và cân bằng

--- TRANG 12 ---
12
Huong TH, Hoang VT (2020) Một kỹ thuật tăng cường dữ liệu dựa trên văn bản cho phân tích cảm xúc tiếng Việt. Kỷ yếu IAIT pp 1–5, DOI 10.1145/3406601.3406618

Imran M, Castillo C, Diaz F, Vieweg S (2018) Xử lý tin nhắn truyền thông xã hội trong tình huống khẩn cấp đại chúng: Tóm tắt khảo sát. Trong: Kỷ yếu Bạn đồng hành Hội nghị Web 2018, Ủy ban Điều hành Hội nghị Web Thế giới Quốc tế, Cộng hòa và Canton Geneva, CHE, WWW '18, p 507–511, DOI 10.1145/3184558.3186242

Jiao X, Yin Y, Shang L, Jiang X, Chen X, Li L, Wang F, Liu Q (2019) TinyBERT: Chưng cất BERT cho Hiểu Ngôn ngữ Tự nhiên. Trong: EMNLP 2020, pp 1–14, URL http://arxiv.org/abs/1909.10351

Kaffe K, Yousefhussien M, Kanan C (2018) Tăng Cường Dữ liệu cho Trả lời Câu hỏi Trực quan. Trong: Kỷ yếu Hội nghị Quốc tế lần thứ 10 về Tạo Ngôn ngữ Tự nhiên, DOI 10.18653/v1/w17-3529

Kaufhold MA (2021) Công nghệ Tinh chế Thông tin cho Tin học Khủng hoảng: Kỳ vọng Người dùng và Nguyên tắc Thiết kế cho Truyền thông Xã hội và Ứng dụng Di động. Springer Vieweg, Wiesbaden, Germany, DOI 10.1007/978-3-658-33341-6, URL https://www.springer.com/gp/book/9783658333430

Kaufhold MA, Bayer M, Reuter C (2020) Phân loại mức độ liên quan nhanh chóng của các bài đăng truyền thông xã hội trong thảm họa và tình huống khẩn cấp: Một hệ thống và đánh giá có tính năng học tích cực, tăng dần và trực tuyến. Information Processing & Management DOI 10.1016/j.ipm.2019.102132

Khan B (2019) Tạo văn bản của riêng bạn với GPT-2 của OpenAI. URL https://www.kaggle.com/bkkaggle/generate-your-own-text-with-openai-s-gpt-2-117m

Kingma DP, Ba JL (2015) Adam: Một phương pháp cho tối ưu hóa ngẫu nhiên. Trong: ICLR 2015 - Conference Track Proceedings

Kobayashi S (2018) Tăng Cường Ngữ cảnh: Tăng Cường Dữ liệu bằng Từ với Quan hệ Paradigmatic. Trong: arXiv preprint arXiv:1805.06201, DOI 10.18653/v1/n18-2072

Kolomiyets O, Bethard S, Moens MF (2011) Thí nghiệm tính di động mô hình cho phân tích thời gian văn bản. Trong: Kỷ yếu ACL-HLT

Krishnalal G, Rengarajan SB, Srinivasagan KG (2010) Một Phương pháp Khai thác Văn bản Mới Dựa trên HMM-SVM cho Phân loại Tin tức Web. International Journal of Computer Applications DOI 10.5120/395-589

Kruspe A, Kersten J, Wiegmann M, Stein B, Klan F (2018) Phân loại Tweet liên quan đến Sự cố: Giải quyết Dữ liệu Huấn luyện Mất cân bằng sử dụng CNN Hybrid và Tăng Cường Dữ liệu dựa trên Dịch thuật. Trong: Notebook papers of TREC

Kumar A, Bhattamishra S, Bhandari M, Talukdar P (2019) Tối ưu hóa submodular dựa trên diễn giải đa dạng và hiệu quả của nó trong tăng cường dữ liệu. Trong: Kỷ yếu NAACL-HLT, pp 3609–3619, DOI 10.18653/v1/n19-1363

Kumar V, Choudhary A, Cho E (2020) Tăng Cường Dữ liệu sử dụng Mô hình Transformer Tiền huấn luyện

LeCun Y, Bottou L, Bengio Y, Haffner P (1998) Học dựa trên gradient áp dụng cho nhận dạng tài liệu. Proceedings of the IEEE DOI 10.1109/5.726791

Liu B, Zhang L (2012) Một Khảo sát về Khai thác Ý kiến và Phân tích Cảm xúc, Springer US, Boston, MA, pp 415–463. DOI 10.1007/978-1-4614-3223-4_13

Longpre S, Wang Y, DuBois C (2020) Tăng Cường Dữ liệu Không phụ thuộc Tác vụ Hiệu quả như thế nào đối với Transformer Tiền huấn luyện? Trong: Findings of EMNLP

Medhat W, Hassan A, Korashy H (2014) Thuật toán phân tích cảm xúc và ứng dụng: Một khảo sát. Ain Shams Engineering Journal 5(4):1093–1113, DOI https://doi.org/10.1016/j.asej.2014.04.011

Merity S, Keskar NS, Socher R (2018) Chính quy hóa và tối ưu hóa mô hình ngôn ngữ LSTM. Trong: ICLR 2018 - Conference Track Proceedings

Miyato T, Dai AM, Goodfellow I (2017) Phương pháp huấn luyện đối nghịch cho phân loại văn bản bán giám sát. Trong: Conference Track - ICLR

Nguyen D, Ali Al Mannai K, Joty S, Sajjad H, Imran M, Mitra P (2017) Phân loại mạnh mẽ dữ liệu liên quan đến khủng hoảng trên mạng xã hội sử dụng mạng nơ-ron tích chập. Proceedings of the International AAAI Conference on Web and Social Media 11(1), URL https://ojs.aaai.org/index.php/ICWSM/article/view/14950

Olteanu A, Vieweg S, Castillo C (2015) Những gì mong đợi khi điều bất ngờ xảy ra: Giao tiếp truyền thông xã hội qua các cuộc khủng hoảng. Trong: Kỷ yếu CSCW, DOI 10.1145/2675133.2675242

Qiu S, Xu B, Zhang J, Wang Y, Shen X, de Melo G, Long C, Li X (2020) EasyAug: Một Nền tảng Tăng Cường Dữ liệu Văn bản Tự động cho Các Tác vụ Phân loại. Trong: Kỷ yếu Bạn đồng hành Hội nghị Web 2020, DOI 10.1145/3366424.3383552

Radford A, Wu J, Child R, Luan D, Amodei D, Sutskever I (2018) Mô hình Ngôn ngữ là Người học Đa tác vụ Không giám sát. Trong: OpenAI blog

Raghuwanshi BS, Shukla S (2021) Phân loại dữ liệu mất cân bằng sử dụng ELM hạt nhân hóa cụ thể lớp dựa trên SMOTE. International Journal of Machine Learning and Cybernetics 12(5):1255–1280, DOI 10.1007/s13042-020-01232-1

--- TRANG 13 ---
13
Reimers N, Gurevych I (2019) Sentence-BERT: Embedding Câu sử dụng Mạng BERT Siamese. Trong: Kỷ yếu Hội nghị 2019 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên và Hội nghị Chung Quốc tế lần thứ 9 về Xử lý Ngôn ngữ Tự nhiên (EMNLP-IJCNLP), DOI 10.18653/v1/d19-1410

Reuter C, Marx A, Pipek V (2012) Quản lý Khủng hoảng 2.0: Hướng tới Hệ thống hóa Việc sử dụng Phần mềm Xã hội trong Các tình huống Khủng hoảng. International Journal of Information Systems for Crisis Response and Management (IJISCRAM) 4(1):1–16, DOI 10.4018/jiscrm.2012010101

Reuter C, Ludwig T, Kaufhold MA, Spielhofer T (2016) Thái độ của Dịch vụ Khẩn cấp đối với Truyền thông Xã hội: Một Khảo sát Định lượng và Định tính trên khắp Châu Âu. International Journal on Human-Computer Studies (IJHCS) 95:96–111, DOI 10.1016/j.ijhcs.2016.03.005

Rizos G, Hemker K, Schuller B (2019) Tăng cường để ngăn chặn: Tăng cường dữ liệu văn bản ngắn trong deep learning cho phân loại ngôn từ thù địch. Trong: Kỷ yếu CIKM, DOI 10.1145/3357384.3358040

Schulz A, Guckelsberger C, Janssen F (2017) Trừu tượng hóa Ngữ nghĩa cho tổng quát hóa phân loại tweet: Một đánh giá về tweet liên quan đến sự cố. Semantic Web DOI 10.3233/SW-150188

Sennrich R, Haddow B, Birch A (2016) Cải thiện mô hình dịch máy nơ-ron với dữ liệu đơn ngữ. Trong: ACL, DOI 10.18653/v1/p16-1009

Shorten C, Khoshgoftaar TM (2019) Một khảo sát về Tăng Cường Dữ liệu Hình ảnh cho Deep Learning. Journal of Big Data DOI 10.1186/s40537-019-0197-0

Smith LN (2018) Một phương pháp có kỷ luật đối với siêu tham số mạng nơ-ron: Phần 1 – tốc độ học, kích thước batch, momentum, và giảm trọng số

Socher R, Perelygin A, Wu JY, Chuang J, Manning CD, Ng AY, Potts C (2013) Mô hình deep đệ quy cho tính hợp thành ngữ nghĩa trên một treebank cảm xúc. Trong: Kỷ yếu EMNLP

Soden R, Palen L (2018) Thông tin khủng hoảng: Mở rộng góc nhìn phê phán trong tin học khủng hoảng. Proc ACM Hum-Comput Interact 2(CSCW), DOI 10.1145/3274431

Solaiman I, Brundage M, Clark J, Askell A, Herbert-Voss A, Wu J, Radford A, Wang J (2019) Chiến lược phát hành và tác động xã hội của mô hình ngôn ngữ

Stieglitz S, Mirbabaie M, Ross B, Neuberger C (2018) Phân tích truyền thông xã hội – Thách thức trong khám phá chủ đề, thu thập dữ liệu, và chuẩn bị dữ liệu. International Journal of Information Management 39:156–168

Sun C, Shrivastava A, Singh S, Gupta A (2017) Xem lại Hiệu quả Không hợp lý của Dữ liệu trong Kỷ nguyên Deep Learning. Trong: Kỷ yếu ICCV, DOI 10.1109/ICCV.2017.97

Sun X, He J (2020) Một phương pháp mới để tạo ra một quy mô lớn dữ liệu có giám sát cho phân tích cảm xúc văn bản ngắn. Multimedia Tools and Applications DOI 10.1007/s11042-018-5748-4

Taylor L, Nitschke G (2019) Cải thiện Deep Learning với Tăng Cường Dữ liệu Chung. Trong: Kỷ yếu SSCI, DOI 10.1109/SSCI.2018.8628742

Wang C, Lillis D (2020) Phân loại cho Tweet Liên quan đến Khủng hoảng Tận dụng Word Embeddings và Tăng Cường Dữ liệu. Trong: TREC 2019, URL https://trec.nist.gov/

Wang WY, Yang D (2015) Thật khó chịu!!!: Một phương pháp tăng cường dữ liệu dựa trên embedding từ vựng và khung ngữ nghĩa cho phân loại tự động các hành vi khó chịu sử dụng tweet #petpeeve. Trong: Kỷ yếu EMNLP, DOI 10.18653/v1/d15-1306

Wei J, Zou K (2019) EDA: Kỹ thuật Tăng Cường Dữ liệu Dễ dàng để Tăng Hiệu suất trên Các Tác vụ Phân loại Văn bản. Trong: Kỷ yếu Hội nghị 2019 về Phương pháp Thực nghiệm trong Xử lý Ngôn ngữ Tự nhiên và Hội nghị Chung Quốc tế lần thứ 9 về Xử lý Ngôn ngữ Tự nhiên (EMNLP-IJCNLP), DOI 10.18653/v1/d19-1670

Woolf M (2019) GitHub - gpt-2-simple: Gói Python để dễ dàng huấn luyện lại mô hình tạo văn bản GPT-2 của OpenAI trên văn bản mới. URL https://github.com/minimaxir/gpt-2-simple

Xiang R, Chersoni E, Lu Q, Huang CR, Li W, Long Y (2021) Tăng cường dữ liệu từ vựng cho phân tích cảm xúc. Journal of the Association for Information Science and Technology 72(11):1432–1447, DOI 10.1002/asi.24493, URL https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.24493, eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.24493

Xu Y, Jia R, Mou L, Li G, Chen Y, Lu Y, Jin Z (2016) Phân loại quan hệ được cải thiện bởi mạng nơ-ron hồi tiếp deep với tăng cường dữ liệu. Trong: Kỷ yếu COLING 2016: Technical Papers

Zeiler MD, Fergus R (2013) Pooling ngẫu nhiên cho chính quy hóa mạng nơ-ron tích chập deep. Trong: Kỷ yếu ICLR

Zhai J, Qi J, Zhang S (2021) Phân loại dữ liệu mất cân bằng dựa trên tạo mẫu đa dạng và hợp nhất bộ phân loại. International Journal of Machine Learning and Cybernetics DOI 10.1007/s13042-021-01321-9

Zhang H, Cisse M, Dauphin YN, Lopez-Paz D (2018) MixUp: Vượt ra ngoài giảm thiểu rủi ro thực nghiệm. Trong: Conference Track of ICLR

--- TRANG 14 ---
14
Zhang X, Zhao J, Lecun Y (2015) Mạng tích chập cấp ký tự cho phân loại văn bản. Trong: NIPS

Phụ lục

A Tính khả dụng của Dữ liệu và Tài liệu

Tóm lại, hầu hết các bộ dữ liệu được phân tích trong nghiên cứu hiện tại đều có sẵn công khai. Trong đánh giá đầu tiên (phần 4.4), chúng tôi sử dụng bộ dữ liệu SST¹ của Socher et al. (2013) có sẵn công khai.

Các bộ dữ liệu được phân tích trong đánh giá thứ hai (phần 4.5) không có sẵn công khai do hạn chế xuất bản của các cơ quan tin tức. Tuy nhiên, một mô tả ngắn gọn về các bộ dữ liệu này được đưa ra trong phụ lục B. Chúng tôi muốn nhấn mạnh rằng phân loại tin tức là một lĩnh vực có tính liên quan cao trong ngành nhưng nhận được quá ít sự chú ý trong học thuật. Ngoài ra, chúng tôi phải quyết định tạo bộ dữ liệu riêng để giải quyết phân loại văn bản dài, vì những bộ dữ liệu này đặc biệt hiếm. Chúng tôi hy vọng rằng chúng tôi đã bao gồm đủ kết quả từ các bộ dữ liệu công khai để có thể suy ra tính tái tạo.

Đối với đánh giá thứ ba (phần 4.6), ba bộ dữ liệu công khai (Vụ đánh bom Boston, Động đất Bohol và Vụ nổ West Texas) từ các nhóm dữ liệu được chú thích CrisisLexT26² từ Olteanu et al. (2015) và hai bộ dữ liệu công khai (Dublin và New York City) từ các nhóm dữ liệu được chú thích từ Schulz et al. (2017)³ đã được sử dụng. Ngôn ngữ chính của tất cả các bộ dữ liệu là tiếng Anh.

B Mô tả các Bộ dữ liệu được Sử dụng trong Đánh giá Thứ hai

Các bộ dữ liệu bao gồm các bài báo tin tức tiếng Anh từ hơn 2.600 miền nguồn khác nhau từ các năm 2019 và 2020, được lựa chọn trước liên quan đến các từ truy vấn cụ thể. Đối với mỗi chủ đề, các bài báo nhận được giá trị dựa trên các từ truy vấn này để chia chúng thành 12 nhóm khác nhau. Chúng tôi lấy mẫu các bài báo tin tức từ các nhóm này một cách đồng đều để các thể hiện có tính đa dạng cao được gán nhãn. Một tóm tắt ngắn của các hướng dẫn gán nhãn và phân phối dữ liệu được mô tả trong danh sách sau:

¹ Bộ dữ liệu SST của Socher et al. (2013): https://nlp.stanford.edu/sentiment/index.html
² Bộ dữ liệu CrisisLexT26 từ Olteanu et al. (2015): https://github.com/sajao/CrisisLex/tree/master/data/CrisisLexT26
³ Bộ dữ liệu từ Schulz et al. (2017): http://www.doc.gold.ac.uk/~cguck001/IncidentTweets/

Sa thải. Chủ đề sa thải bao gồm tất cả các hình thức sa thải nhân viên trong bối cảnh doanh nghiệp. Tổng cộng 1992 bài báo được chú thích trong đó 751 thể hiện tích cực và 1241 tiêu cực.

Thay đổi quản lý. Chủ đề này bao gồm tất cả các hình thức thay đổi (nghỉ hưu, từ chức, bổ nhiệm) của ban giám đốc và các vị trí quan trọng trong các công ty, tổ chức và ban cố vấn. 2129 thể hiện được gán nhãn trong đó 567 thể hiện tích cực và 1562 tiêu cực.

Sáp nhập và Mua lại. M&A bao gồm tất cả các giao dịch trong đó quyền sở hữu được chuyển giao cho các công ty hoặc đơn vị hoạt động của họ. Việc đầu tư đơn thuần vào một công ty được xem là tiêu cực ở đây. Đối với chủ đề này, 2227 thể hiện được gán nhãn trong đó 474 tích cực và 1753 tiêu cực.

Lũ lụt. Chủ đề lũ lụt được nhận dạng tích cực trong tin tức nếu bài báo xử lý về lũ lụt thực tế hoặc chủ đề chính là hậu quả của lũ lụt. Nếu chỉ báo cáo về sự gia tăng mức nước, thông điệp này không nên được coi là tích cực. Có 2533 thể hiện được xác định về chủ đề này, 1639 trong số đó tích cực và 894 tiêu cực. Mặc dù nhiều thể hiện tích cực hơn tiêu cực được xác định ở đây, lớp tiêu cực vẫn được xem là lớp đa số vì đa số rõ ràng của tất cả các thông điệp trên Internet không liên quan đến lũ lụt.

Cháy rừng. Tất cả các hình thức cháy rừng được phân loại trong chủ đề này. Cháy nhà và việc sử dụng ẩn dụ của thuật ngữ được gán nhãn tiêu cực. Bộ dữ liệu bao gồm 2410 thể hiện được xác định trong đó 1202 tích cực và 1208 tiêu cực. Tương tự như chủ đề lũ lụt, lớp tiêu cực là lớp đa số.

Trong bước tiền xử lý, chúng tôi thêm các token "xxtitle" trước mỗi tiêu đề và "xxbodytext" trước phần bắt đầu của văn bản bài báo bình thường.

C Thuật toán

Trong phần sau, chúng tôi đã định nghĩa thuật toán của phương pháp tăng cường dữ liệu độc lập ngữ cảnh.

D Đạo đức

Trong công trình của chúng tôi, chúng tôi đã đặc biệt chú ý đến đạo đức và liên tục đánh giá lại phương pháp của chúng tôi đối với trách nhiệm. Chúng tôi đã giới hạn bản thân chỉ sử dụng nội dung văn bản và nhãn trong các bộ dữ liệu để tôn trọng quyền riêng tư càng nhiều càng tốt. Khi làm việc với dữ liệu truyền thông xã hội, chúng tôi đặc biệt không sử dụng, tổng hợp hoặc rút ra bất kỳ kết luận nào từ siêu dữ liệu khác như tên hoặc vị trí của người dùng.

--- TRANG 15 ---
15
Thuật toán 1: Tăng cường Văn bản Ngắn
Đầu vào: Mô hình Ngôn ngữ LM, Dữ liệu lớp Xc,
Mô hình Embedding Tài liệu E,
Số thể hiện cho mỗi dữ liệu huấn luyện n
1. Cho mỗi thể hiện trong Xc: Gắn
'<|startoftext|>|i|' vào đầu và
'<|endoftext|>' vào cuối thể hiện thứ i để
thu được Xcprep
2. Tinh chỉnh LM trên Xcprep để thu được LMcprep
3. Cho mỗi k trong |Xcprep|: Tạo n thể hiện mới
với LMcprep và '<|startoftext|>|i|' như tiền tố
để thu được Xgen
4. Nhúng tất cả các thể hiện trong Xgen và Xc với E
5. Thu được Xfiltered bằng cách bao gồm tất cả các thể hiện của
Xgen mà biểu diễn embedding gần với trung tâm của Xc đã nhúng
Kết quả: Xfiltered

Thuật toán 2: Tăng cường Văn bản Dài
Đầu vào: Mô hình Ngôn ngữ LM, Dữ liệu lớp Xc,
Mô hình Embedding Tài liệu E,
Số thể hiện cho mỗi dữ liệu huấn luyện n,
Hàm trích xuất phần ngữ cảnh cont()
1. Cho mỗi thể hiện trong Xc: Gắn
'<|startoftext|>' vào đầu và
'<|endoftext|>' vào cuối các thể hiện để
thu được Xcprep
2. Tinh chỉnh LM trên Xcprep để thu được LMcprep
3. Cho mỗi t trong Xcprep: Tạo n thể hiện mới
với LMcprep và '<|startoftext|>' + cont(t) như
tiền tố để thu được Xgen
4. Nhúng tất cả các thể hiện trong Xgen và Xc với E
5. Thu được Xfiltered bằng cách bao gồm tất cả các thể hiện của
Xgen mà biểu diễn embedding gần với trung tâm của Xc đã nhúng
Kết quả: Xfiltered

Để thực hiện thực tế phương pháp của chúng tôi, chúng tôi muốn đề cập rằng mô hình GPT-2 cũng như hầu hết các mô hình ngôn ngữ khác chứa độ thiên lệch (ví dụ độ thiên lệch giới tính, tôn giáo hoặc chủng tộc) (Solaiman et al., 2019). Sử dụng phương pháp trong một ứng dụng thực có thể dẫn đến dịch chuyển miền và/hoặc bao gồm những độ thiên lệch đó. Điều này có thể dẫn đến các quyết định phân biệt đối xử một cách rõ ràng bởi mô hình học máy, ngay cả khi bộ dữ liệu bản thân không chứa bất kỳ độ thiên lệch nào.

E Kiến trúc, Siêu tham số và Cơ sở hạ tầng

Trong đánh giá, chúng tôi sử dụng mô hình ULMFit tiền huấn luyện của Howard and Ruder (2018) như được thực hiện trong fastai (Howard and Gugger, 2020). Mô hình bao gồm một bộ mã hóa tiền huấn luyện dựa trên kiến trúc AWD-LSTM của Merity et al. (2018) và một bộ phân loại pooling tuyến tính. Bộ phân loại bao gồm một lớp nối các đầu ra cuối cùng của bộ mã hóa với tối đa và trung bình của tất cả các đầu ra trung gian và hai lớp được kết nối đầy đủ⁴. Thông tin thêm về kiến trúc chung có thể được trích xuất từ bài báo của Howard and Ruder (2018) và việc thực hiện trong fastai (Howard and Gugger, 2020). Tinh chỉnh bộ mã hóa được thực hiện bằng cách chuẩn bị tất cả dữ liệu có sẵn của tác vụ tương ứng (bao gồm dữ liệu được tăng cường) cho tác vụ mô hình hóa ngôn ngữ. Trong huấn luyện, chúng tôi thực hiện 15 chu kỳ với chính sách 1cycle của Smith (2018). Chúng tôi sử dụng tốc độ học 0.002 và momentum tối đa và tối thiểu 0.8 và 0.7. Tổng thể, chúng tôi sử dụng kích thước batch cố định 64 và cửa sổ lan truyền ngược qua thời gian 70. Mỗi bộ mã hóa và bộ phân loại được huấn luyện cho tác vụ hạ nguồn với ba chu kỳ với giải phóng dần dần và năm chu kỳ khác với mô hình được giải phóng. Tốc độ học được xác định riêng lẻ bằng thử nghiệm phạm vi tốc độ học của Smith (2018) với phạm vi từ 10⁻⁷ đến 10 qua 100 lần lặp⁵. Trên các đầu ra, chúng tôi sử dụng làm mịn nhãn với tham số epsilon 0.1. Như thuật toán tối ưu hóa, chúng tôi sử dụng thuật toán Adam (Kingma and Ba, 2015).

Để sinh văn bản, chúng tôi sử dụng việc thực hiện gpt-2-simple⁶ để tinh chỉnh và tạo văn bản từ mô hình GPT-2. Chỉ các tham số được thảo luận trong chương 4.2 được thay đổi. Cho bước lọc, Sentence-BERT⁷ (Reimers and Gurevych, 2019) với mô hình transformer "roberta-large-nli-stsb-mean-tokens" được sử dụng.

Chúng tôi token hóa tất cả các bộ dữ liệu với các tokenizer có sẵn của các thư viện gpt-2-simple, Sentence-BERT và fastai cho các trường hợp sử dụng khác nhau.

Đánh giá của chương 4.4 được thực hiện trên card đồ họa Nvidia Quadro RTX 6000 với 24 GB RAM. Cho đánh giá của chương 4.3 và 4.5, ít tài nguyên cần thiết hơn, đó là lý do tại sao Nvidia Tesla P100 với 16GB RAM được sử dụng.

Nói chung, các tác vụ khá tốn tài nguyên. Tinh chỉnh mô hình GPT-2 trên bộ dữ liệu lũ lụt mất khoảng năm giờ, trong khi việc tạo ra mười ví dụ cho mỗi thể hiện mất khoảng bốn ngày. Tinh chỉnh mô hình ngôn ngữ và huấn luyện bộ phân loại cùng nhau mất khoảng bốn giờ nữa.

--- TRANG 16 ---
16
Bảng 5 Các thể hiện dữ liệu được tạo ra và các đối tác gốc tương tự nhất của chúng.

West Texas
Explosions Media Matters Texas: West, Texas, fertilizer plant: 28 years, no full inspection: Before 270 tons of ammonium
nitratet exploded at ... http://t.co/XwUwgRcGDT
West, Texas, fertilizer plant: 28 years, no full inspection: Before 270 tons of ammonium nitratet exploded at
... http://t.co/XwUwgRcGDT
RT @mpoindc: I want them to know that they are not forgotten, Obama says to victims of explosion in
West, TX.
I want them to know that they are not forgotten, Obama says to victims of explosion in West, TX.
RT @BreakingNews: Large explosion reported at fertilizer plant near Waco, Texas - @CBSDFW
http://t.co/xOIyCyuxFD
Explosion reported at fertilizer plant near Waco, Texas - @CBSDFW http://t.co/xOIyCyuxFD
RT @BBCBreaking: 12 confirmed dead, approximately 200 injured in #West fertiliser plant explosion in
Texas, say state officials
Searchers Find 12 Bodies After Texas Explosion http://t.co/fnBc2LmXs (CNN) | Hundreds believed in-
jured in Texas fertilizer plant explosion, medical examiner says. http://t ...
RT @laurenonizzle: This iPhone video of the fertilizer plant explosion near #Waco will send chills up your
spine. Surreal. http://t.co/O ...
RT @laurenonizzle: This iPhone video of the fertilizer plant explosion near #Waco will send chills up your
spine. Surreal. http://t.co/O ...

SST-2 (100) smart , sassy interpretation of the oscar wilde play .
sharp , sassy interpretation of the oscar wilde play , with an unexpected twist .
a fast paced and suspenseful argentinian thriller about the shadow side of play .
a fast paced and suspenseful argentinian thriller .
this comic gem is as delightful as it is derivative .
the film is bright and flashy in all the right ways .
the best movie in many a moon about the passions that sometimes fuel our best achievements and other
times leave us stranded with nothing more than our lesser appetites .
the best film in many a moon about the passions that sometimes fuel our best achievements and other times
leave us stranded with nothing more than our lesser appetites .
a fine production with splendid singing by angela gheorghiu , ruggero raimondi , and roberto alagna .
a fine production with splendid singing by angela gheorghiu , ruggero raimondi , and roberto alagna .

F Dữ liệu được Tạo ra

Trong các thí nghiệm của chúng tôi, chúng tôi cũng phân tích dữ liệu được tạo ra. Với mục đích này, trước tiên chúng tôi chọn các thể hiện được tạo ra và cố gắng tìm thể hiện gốc có sự tương đồng gần nhất (được đo bằng khoảng cách Levenshtein). Trong Bảng 5, một đoạn trích của một số thể hiện, các đối tác gốc và được tạo ra, từ các bộ dữ liệu West Texas Explosions và SST-2 được đưa ra. Ở đây chúng ta có thể thấy, rằng mô hình GPT-2 có thể, ví dụ, loại bỏ các từ đứng trước (thể hiện thứ nhất và thứ hai của West Texas Explosions) hoặc thậm chí cắt ngắn câu ở cuối (thể hiện thứ hai của SST-2). Ví dụ đầu tiên của bộ dữ liệu SST-2 cho thấy rằng mô hình cũng có thể mở rộng thể hiện gốc. Trong trường hợp ví dụ thứ ba của West Texas Explosions, có thể thể hiện gốc được nội suy với một thể hiện khác. Thể hiện thứ tư của bộ dữ liệu SST-2 cũng cho thấy rằng mô hình có thể thực hiện những thay đổi nhỏ như thay thế từ đồng nghĩa. Hơn nữa, đối với nhiều thể hiện được tạo ra, chúng tôi không thể tìm thấy các đối tác tương tự, xem ví dụ thể hiện thứ ba của bộ dữ liệu SST-2 được đưa ra trong Bảng 5. Những thể hiện này có thể, ví dụ, là các thể hiện mà mô hình đã học trước đó, điều này hỗ trợ việc xem xét rằng mô hình có thể tạo ra các ví dụ có tính đa dạng cao với các tính năng ngôn ngữ mới. Tuy nhiên, như được hiển thị với các ví dụ cuối cùng của hai bộ dữ liệu, mô hình cũng đôi khi lặp lại thể hiện gốc. Chúng tôi cũng nhận thấy rằng càng tạo ra nhiều dữ liệu, càng nhiều bản sao có thể được tìm thấy. Điều này hợp lý vì xác suất cho một số chuỗi token rất cao và do đó chúng được tạo ra thường xuyên hơn. Như đã được chỉ ra ở một mức độ nào đó trong các nghiên cứu loại bỏ, sẽ thú vị khi xem có bao nhiêu thể hiện nhân tạo có thể được tạo ra cho đến khi đạt được cải thiện tối đa và liệu điều này có phụ thuộc vào kích thước của mô hình ngôn ngữ hay không. Nói chung, các phát hiện chỉ ra rằng phương pháp được đề xuất trong nghiên cứu của chúng tôi có khả năng thực hiện nhiều phép biến đổi khác nhau.

⁴ Thực hiện ULMFit: https://fastai1.fast.ai/text.learner.html#text_classifier_learner
⁵ Thực hiện thử nghiệm phạm vi tốc độ học: https://fastai1.fast.ai/callbacks.lr_finder.html#callbacks.lr_finder
⁶ Thực hiện gpt-2-simple: https://github.com/minimaxir/gpt-2-simple
⁷ Thực hiện Sentence-BERT: https://github.com/UKPLab/sentence-transformers

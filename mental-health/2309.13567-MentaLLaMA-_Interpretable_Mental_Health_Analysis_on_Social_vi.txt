[11] Muskan Garg, Chandni Saxena, Sriparna Saha, Veena Krishnan, Ruchi Joshi, và Vijay Mago. 2022. CAMS: An Annotated Corpus for Causal Analysis of Mental Health Issues in Social Media Posts. Trong Proceedings of the Thirteenth Language Resources and Evaluation Conference. European Language Resources Association, Marseille, France, 6387–6396. https://aclanthology.org/2022.lrec-1.686

[12] Muskan Garg, Amirmohammad Shahbandegan, Amrit Chadha, và Vijay Mago. 2023. An Annotated Dataset for Explainable Interpersonal Risk Factors of Mental Disturbance in Social Media Posts. Trong Findings of the Association for Computational Linguistics: ACL 2023. Association for Computational Linguistics, Toronto, Canada, 11960–11969. https://doi.org/10.18653/v1/2023.findings-acl.757

[13] Sourojit Ghosh và Aylin Caliskan. 2023. ChatGPT Perpetuates Gender Bias in Machine Translation and Ignores Non-Gendered Pronouns: Findings across Bengali and Five other Low-Resource Languages. arXiv preprint arXiv:2305.10510 (2023).

[14] Sooji Han, Rui Mao, và Erik Cambria. 2022. Hierarchical Attention Network for Explainable Depression Detection on Twitter Aided by Metaphor Concept Mappings. Trong Proceedings of the 29th International Conference on Computational Linguistics. International Committee on Computational Linguistics, Gyeongju, Republic of Korea, 94–104. https://aclanthology.org/2022.coling-1.9

[15] Tianyu Han, Lisa C Adams, Jens-Michalis Papaioannou, Paul Grundmann, Tom Oberhauser, Alexander Löser, Daniel Truhn, và Keno K Bressem. 2023. MedAlpaca–An Open-Source Collection of Medical Conversational AI Models and Training Data. arXiv preprint arXiv:2304.08247 (2023).

[16] Keith Harrigian, Carlos Aguirre, và Mark Dredze. 2020. Do models of mental health based on social media data generalize?. Trong Findings of the association for computational linguistics: EMNLP 2020. 3774–3788.

[17] Shaoxiong Ji. 2022. Towards intention understanding in suicidal risk assessment with natural language processing. Trong Findings of the Association for Computational Linguistics: EMNLP 2022. 4028–4038.

[18] Shaoxiong Ji, Xue Li, Zi Huang, và Erik Cambria. 2022. Suicidal Ideation and Mental Disorder Detection with Attentive Relation Networks. Neural Computing and Applications 34 (2022), 10309–10319. Issue 13.

[19] Shaoxiong Ji, Tianlin Zhang, Luna Ansari, Jie Fu, Prayag Tiwari, và Erik Cambria. 2022. MentalBERT: Publicly Available Pretrained Language Models for Mental Healthcare. Trong Proceedings of the Thirteenth Language Resources and Evaluation Conference. European Language Resources Association, Marseille, France, 7184–7190. https://aclanthology.org/2022.lrec-1.778

[20] Shaoxiong Ji, Tianlin Zhang, Kailai Yang, Sophia Ananiadou, Erik Cambria, và Jörg Tiedemann. 2023. Domain-specific Continued Pretraining of Language Models for Capturing Long Context in Mental Health. arXiv preprint arXiv:2304.10447 (2023).

[21] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, và Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners. Advances in neural information processing systems 35 (2022), 22199–22213.

[22] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, và Luke Zettlemoyer. 2020. BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. Trong Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, Online, 7871–7880. https://doi.org/10.18653/v1/2020.acl-main.703

[23] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, và Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692 (2019).

[24] Ilya Loshchilov và Frank Hutter. 2017. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101 (2017).

[25] Matthew Louis Mauriello, Thierry Lincoln, Grace Hon, Dorien Simon, Dan Jurafsky, và Pablo Paredes. 2021. Sad: A stress annotated dataset for recognizing everyday stressors in sms-like conversational systems. Trong Extended abstracts of the 2021 CHI conference on human factors in computing systems. 1–7.

[26] Michael Moor, Oishi Banerjee, Zahra Shakeri Hossein Abad, Harlan M Krumholz, Jure Leskovec, Eric J Topol, và Pranav Rajpurkar. 2023. Foundation models for generalist medical artificial intelligence. Nature 616, 7956 (2023), 259–265.

[27] Thong Nguyen, Andrew Yates, Ayah Zirikly, Bart Desmet, và Arman Cohan. 2022. Improving the Generalizability of Depression Detection by Leveraging Clinical Questionnaires. Trong Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics, Dublin, Ireland, 8446–8459. https://doi.org/10.18653/v1/2022.acl-long.578

[28] Jennifer Nicholas, Sandersan Onie, và Mark E Larsen. 2020. Ethics and privacy in social media research for mental health. Current psychiatry reports 22 (2020), 1–7.

[29] OpenAI. 2023. GPT-4 Technical Report. ArXiv abs/2303.08774 (2023). https://api.semanticscholar.org/CorpusID:257532815

[30] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems 35 (2022), 27730–27744.

[31] Inna Pirina và Çağrı Çöltekin. 2018. Identifying depression on reddit: The effect of training data. Trong Proceedings of the 2018 EMNLP Workshop SMM4H: The 3rd Social Media Mining for Health Applications Workshop & Shared Task. 9–12.

[32] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research 21, 1 (2020), 5485–5551.

[33] MSVPJ SATHVIK và Muskan Garg. 2023. MULTIWD: Multiple Wellness Dimensions in Social Media Posts. (2023).

[34] Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, và Paul F Christiano. 2020. Learning to summarize with human feedback. Advances in Neural Information Processing Systems 33 (2020), 3008–3021.

[35] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288 (2023).

[36] Adam Tsakalidis, Maria Liakata, Theo Damoulas, và Alexandra I Cristea. 2019. Can we assess mental health through social media and smart devices? Addressing bias in methodology and evaluation. Trong Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2018, Dublin, Ireland, September 10–14, 2018, Proceedings, Part III 18. Springer, 407–423.

[37] Elsbeth Turcan và Kathleen McKeown. 2019. Dreaddit: A Reddit Dataset for Stress Analysis in Social Media. Trong Proceedings of the Tenth International Workshop on Health Text Mining and Information Analysis (LOUHI 2019). 97–107.

[38] Byron C Wallace, Sayantan Saha, Frank Soboczenski, và Iain J Marshall. 2021. Generating (factual?) narrative summaries of rcts: Experiments with neural multi-document summarization. AMIA Summits on Translational Science Proceedings 2021 (2021), 605.

[39] Thomas Wang, Adam Roberts, Daniel Hesslow, Teven Le Scao, Hyung Won Chung, Iz Beltagy, Julien Launay, và Colin Raffel. 2022. What language model architecture and pretraining objective works best for zero-shot generalization?. Trong International Conference on Machine Learning. PMLR, 22964–22984.

[40] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, và Denny Zhou. 2023. Self-Consistency Improves Chain of Thought Reasoning in Language Models. Trong The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net. https://openreview.net/pdf?id=1PL1NIMMrw

[41] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, và Hannaneh Hajishirzi. 2023. Self-Instruct: Aligning Language Models with Self-Generated Instructions. Trong Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics, Toronto, Canada, 13484–13508. https://doi.org/10.18653/v1/2023.acl-long.754

[42] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022. Emergent Abilities of Large Language Models. Transactions on Machine Learning Research (2022).

[43] Qianqian Xie, Weiguang Han, Xiao Zhang, Yanzhao Lai, Min Peng, Alejandro Lopez-Lira, và Jimin Huang. 2023. PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark for Finance. arXiv preprint arXiv:2306.05443 (2023).

[44] Xuhai Xu, Bingshen Yao, Yuanzhe Dong, Hong Yu, James Hendler, Anind K Dey, và Dakuo Wang. 2023. Leveraging Large Language Models for Mental Health Prediction via Online Text Data. arXiv preprint arXiv:2307.14385 (2023).

[45] Kailai Yang, Shaoxiong Ji, Tianlin Zhang, Qianqian Xie, Ziyan Kuang, và Sophia Ananiadou. 2023. Towards Interpretable Mental Health Analysis with Large Language Models. Trong Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Singapore, 6056–6077. https://doi.org/10.18653/v1/2023.emnlp-main.370

[46] Kailai Yang, Tianlin Zhang, và Sophia Ananiadou. 2022. A mental state Knowledge–aware and Contrastive Network for early stress and depression detection on social media. Information Processing & Management 59, 4 (2022), 102961.

[47] Weizhe Yuan, Graham Neubig, và Pengfei Liu. 2021. Bartscore: Evaluating generated text as text generation. Advances in Neural Information Processing Systems 34 (2021), 27263–27277.

[48] Tianlin Zhang, Kailai Yang, Hassan Alhuzali, Boyang Liu, và Sophia Ananiadou. 2023. PHQ-aware depressive symptoms identification with similarity contrastive learning on social media. Information Processing & Management 60, 5 (2023), 103417.

[49] Zhiling Zhang, Siyuan Chen, Mengyue Wu, và Kenny Q. Zhu. 2022. Psychiatric Scale Guided Risky Post Screening for Early Detection of Depression. Trong Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI 2022, Vienna, Austria, 23-29 July 2022, Luc De Raedt (Ed.). 5220–5226.

## A CÔNG VIỆC LIÊN QUAN

### A.1 Phân tích Sức khỏe Tâm thần trên Mạng xã hội

Trong phân tích sức khỏe tâm thần, các phương pháp truyền thống chủ yếu đưa ra dự đoán theo cách phân biệt. Các phương pháp hiệu quả chủ yếu tinh chỉnh các mô hình ngôn ngữ được huấn luyện trước (PLM), như BERT [8] và RoBERTa [23], trên một tập mục tiêu nhỏ [17,49] thường cho một tình trạng sức khỏe tâm thần. Để tiếp tục tăng cường các biểu diễn PLM, một số công việc tiền huấn luyện các mô hình ngôn ngữ từ đầu với dữ liệu mạng xã hội liên quan đến sức khỏe tâm thần quy mô lớn, thường tạo ra các biểu diễn bài đăng tốt hơn so với các PLM chung. Các công việc đại diện bao gồm MentalBERT [19], MentalXLNet [20], v.v.

Mặc dù các mô hình hộp đen trên đạt được hiệu suất phân loại ấn tượng, có các công việc khám phá phân tích sức khỏe tâm thần có thể diễn giải. Một số công việc kết hợp các ánh xạ khái niệm ẩn dụ như các tính năng bổ sung để cung cấp manh mối về quyết định mô hình [14]. Các công việc khác giới thiệu thông tin bảng câu hỏi PHQ-9 để hỗ trợ các dự đoán [27,48]. Đồ thị tri thức thông thường cũng được tận dụng để tăng tính minh bạch của các PLM [16,46]. Những tiến bộ gần đây trong các LLM tạo ra một bước nhảy vọt cho phân tích sức khỏe tâm thần có thể diễn giải. Một số công việc [1,44,45] đánh giá toàn diện hiệu suất của các LLM nền tảng chung trên các nhiệm vụ phân tích sức khỏe tâm thần khác nhau. Xu et al. [44] thoáng qua khả năng tạo giải thích của các LLM, và Yang et al. [46] đánh giá toàn diện khả năng tạo giải thích của ChatGPT với đánh giá con người cẩn thận.

### A.2 Các Mô hình Ngôn ngữ Lớn Mã nguồn Mở

Mặc dù các LLM như ChatGPT và GPT-4 [29] đạt được hiệu suất xuất sắc tổng thể, tính khả dụng mã nguồn đóng của chúng ảnh hưởng đến sự phát triển của cộng đồng nghiên cứu. Do đó, nhiều nỗ lực đã được thực hiện để dân chủ hóa các LLM, như chuỗi LLaMA [35] được phát triển bởi Meta AI. Dựa trên LLaMA, nhiều công việc đã cố gắng sao chép khả năng tuân theo hướng dẫn giống ChatGPT bằng cách huấn luyện trên dữ liệu tinh chỉnh hướng dẫn quy mô lớn [30]. Các LLM tuân theo hướng dẫn chung đại diện bao gồm chuỗi mô hình Alpaca⁵ và Vicuna⁶. Tinh chỉnh hướng dẫn cụ thể lĩnh vực cũng cải thiện hiệu suất LLM trong các lĩnh vực nhất định, như MedAlpaca [15] trong lĩnh vực y sinh và các mô hình Pixiu [43] trong lĩnh vực tài chính. Ngoài ra, các mô hình LLaMA-chat [35] là các LLM mã nguồn mở đầu tiên được tăng cường với học tăng cường từ phản hồi con người (RLHF) [34], điều này căn chỉnh đáng kể các phản hồi mô hình với sở thích con người.

## B SƠ ĐỒ CHÚ THÍCH CON NGƯỜI

Các người chú thích sẽ được cung cấp các giải thích được tạo ra từ ChatGPT và các giải thích được viết bởi chuyên gia làm tham chiếu đúng. Các người chú thích sẽ cần chấm điểm và chú thích các giải thích được tạo ra từ các khía cạnh sau:

**Tính nhất quán.** Liệu văn bản có xây dựng từ câu này đến câu khác thành một cơ thể thông tin mạch lạc về sức khỏe tâm thần hỗ trợ kết quả phân loại hay không. Các người chú thích nên đánh giá xem giải thích được tạo ra có đưa ra bằng chứng hỗ trợ nhất quán với các phân loại của nó và có cấu trúc tốt hay không.

• 0: Không nhất quán với kết quả phân loại.
• 1: Nhất quán với kết quả phân loại, nhưng có khả năng đọc kém và một số lỗi.
• 2: Nhất quán với kết quả phân loại. Chủ yếu mạch lạc và dễ đọc, với ít lỗi nhỏ.
• 3: Nhất quán với kết quả phân loại. Hoàn toàn trôi chảy, mạch lạc và không có lỗi.

**Độ tin cậy.** Độ tin cậy đo lường tính đáng tin cậy của các giải thích được tạo ra để hỗ trợ kết quả phân loại. Các người chú thích nên đánh giá xem giải thích có dựa trên sự thật, có thông tin sai lệch và lý luận sai theo bài đăng đã cho hay không.

• 0: Thông tin hoàn toàn không đáng tin cậy với ảo giác thực tế (ví dụ: các triệu chứng không tồn tại).
• 1: Thông tin một phần đáng tin cậy với lý luận sai dựa trên sự thật.
• 2: Thông tin chủ yếu đáng tin cậy với thông tin sai lệch không quan trọng hoặc lý luận sai.
• 3: Thông tin hoàn toàn đáng tin cậy.

**Tính chuyên nghiệp.** Tính chuyên nghiệp đo lường tính hợp lý của các giải thích được tạo ra bằng cách đánh giá bằng chứng hỗ trợ kết quả phân loại từ góc độ tâm lý học. Các người chú thích nên đánh giá xem giải thích có bao gồm các tiêu chí chẩn đoán phổ biến được chỉ định sau đây của trầm cảm hay không. Để đảm bảo chất lượng của sơ đồ chú thích, chúng tôi mời các chuyên gia lĩnh vực của chúng tôi phát triển một danh sách các triệu chứng phổ biến liên quan đến trầm cảm và sắp xếp các triệu chứng này theo mức độ quan trọng. Các chuyên gia lĩnh vực tham khảo Bảng câu hỏi Sức khỏe Bệnh nhân (PHQ-9)⁷ về việc xác định các triệu chứng và sắp xếp các triệu chứng này dựa trên kiến thức của họ.

Cụ thể, các triệu chứng sau được kiểm tra (được sắp xếp theo mức độ quan trọng):

• **Ý tưởng tự tử:** Những suy nghĩ rằng bạn sẽ tốt hơn nếu chết.
• **Ý tưởng tự hại:** Những suy nghĩ về việc làm tổn thương bản thân theo cách nào đó.
• **Cảm thấy buồn, trầm cảm hoặc tuyệt vọng.**
• **Ý tưởng tự trách:** Cảm thấy tệ về bản thân — hoặc rằng bạn là một kẻ thất bại hoặc đã làm thất vọng bản thân hoặc gia đình bạn.
• **Các triệu chứng trên được phân loại là có mức độ quan trọng cao, và các triệu chứng dưới đây được phân loại là có mức độ quan trọng thấp.**
• **Cảm thấy mệt mỏi hoặc có ít năng lượng.** Ít hứng thú hoặc niềm vui trong việc làm mọi thứ.
• **Ăn kém hoặc ăn quá nhiều.**
• **Khó ngủ hoặc giữ giấc, hoặc ngủ quá nhiều.**
• **Khó tập trung vào mọi thứ, chẳng hạn như đọc báo hoặc xem tivi.**
• **Di chuyển hoặc nói chậm đến mức người khác có thể nhận thấy. Hoặc ngược lại — bồn chồn hoặc không yên đến mức bạn đã di chuyển nhiều hơn bình thường**
• **Ham muốn tình dục không thể kiểm soát hoặc lãnh cảm tình dục.**
• **Các triệu chứng khác.**

Dựa trên các triệu chứng trên, các người chú thích chấm điểm tính chuyên nghiệp của mỗi giải thích với các tiêu chí sau:

• 0: Giải thích không cung cấp bằng chứng hỗ trợ nào, hoặc các triệu chứng có mức độ quan trọng cao bị thiếu trong giải thích.
• 1: Giải thích cung cấp một ít bằng chứng hỗ trợ, trong khi một số triệu chứng có mức độ quan trọng cao hơn (so với bằng chứng được cung cấp) bị thiếu.
• 2: Giải thích cung cấp một số bằng chứng hỗ trợ, trong khi một số triệu chứng có mức độ quan trọng thấp hơn (so với bằng chứng được cung cấp) bị thiếu.
• 3: Giải thích cung cấp tất cả bằng chứng hỗ trợ liên quan trong bài đăng.

**Điểm Tổng thể.** Hiệu suất tổng thể đo lường hiệu quả chung của giải thích được tạo ra, có tính đến các điểm số kết hợp cho tính nhất quán, độ tin cậy và tính chuyên nghiệp.

• 0: Hiệu suất tổng thể kém. Tính nhất quán hoặc độ tin cậy là trung bình hoặc thấp hơn (<=1).
• 1: Hiệu suất tổng thể trung bình. Tính nhất quán và độ tin cậy là tốt (>=2), và tính chuyên nghiệp là trung bình hoặc thấp hơn (<=1).
• 2: Hiệu suất tổng thể tốt. Tính nhất quán và độ tin cậy là xuất sắc (=3), nhưng tính chuyên nghiệp dưới xuất sắc (<=2)
• 3: Hiệu suất tổng thể xuất sắc. Tính nhất quán, độ tin cậy và tính chuyên nghiệp đều xuất sắc (=3)

[Bảng 4: Các mẫu để xây dựng lời nhắc cho bộ dữ liệu IMHI. [Post] biểu thị bài đăng mục tiêu. [Aspect] biểu thị các khía cạnh phát hiện (được hiển thị trong Bảng 1).]

[Bảng 5: Một số ví dụ về sự bất đồng của ChatGPT về các nhãn được chú thích.]

## C VÍ DỤ

### C.1 Các Mẫu cho Bộ dữ liệu IMHI

Các mẫu để xây dựng lời nhắc cho các bộ dữ liệu IMHI và IMHI-completion được trình bày trong Bảng 4.

### C.2 Các Ví dụ Bất đồng của ChatGPT

Chúng tôi cung cấp một số ví dụ về sự bất đồng của ChatGPT về các nhãn được chú thích trong Bảng 5.

[Bảng 6: Các ví dụ về lời nhắc cho ChatGPT.]

---

¹ https://wearesocial.com/uk/blog/2022/01/digital-2022/
² https://openai.com/blog/chatgpt
³ https://openai.com/pricing
⁴ https://www.cutter.com/article/environmental-impact-large-language-models
⁵ https://crfm.stanford.edu/2023/03/13/alpaca.html
⁶ https://lmsys.org/blog/2023-03-30-vicuna/
⁷ https://www.apa.org/depression-guideline/patient-health-questionnaire.pdf

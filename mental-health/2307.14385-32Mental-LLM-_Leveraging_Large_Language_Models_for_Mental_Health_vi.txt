# Mental-LLM: Tận dụng Mô hình Ngôn ngữ Lớn cho Dự đoán Sức khỏe Tâm thần thông qua Dữ liệu Văn bản Trực tuyến

XUHAI XU, Viện Công nghệ Massachusetts & Đại học Washington, Hoa Kỳ
BINGSHENG YAO, Viện Bách khoa Rensselaer, Hoa Kỳ
YUANZHE DONG, Đại học Stanford, Hoa Kỳ
SAADIA GABRIEL, Viện Công nghệ Massachusetts, Hoa Kỳ
HONG YU, Đại học Massachusetts Lowell, Hoa Kỳ
JAMES HENDLER, Viện Bách khoa Rensselaer, Hoa Kỳ
MARZYEH GHASSEMI, Viện Công nghệ Massachusetts, Hoa Kỳ
ANIND K. DEY, Đại học Washington, Hoa Kỳ
DAKUO WANG, Đại học Northeastern, Hoa Kỳ

Những tiến bộ trong các mô hình ngôn ngữ lớn (LLM) đã tạo điều kiện cho nhiều ứng dụng đa dạng. Tuy nhiên, vẫn còn một khoảng cách đáng kể trong nghiên cứu khi nói đến việc hiểu và nâng cao khả năng của LLM trong lĩnh vực sức khỏe tâm thần. Trong công trình này, chúng tôi trình bày một đánh giá toàn diện về nhiều LLM trên các tác vụ dự đoán sức khỏe tâm thần khác nhau thông qua dữ liệu văn bản trực tuyến, bao gồm Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, và GPT-4. Chúng tôi tiến hành một loạt thí nghiệm rộng rãi, bao phủ zero-shot prompting, few-shot prompting, và instruction fine-tuning. Kết quả cho thấy hiệu suất đầy hứa hẹn nhưng còn hạn chế của LLM với thiết kế prompt zero-shot và few-shot cho các tác vụ sức khỏe tâm thần. Quan trọng hơn, các thí nghiệm của chúng tôi cho thấy instruction finetuning có thể cải thiện đáng kể hiệu suất của LLM cho tất cả các tác vụ đồng thời. Các mô hình được tinh chỉnh tốt nhất của chúng tôi, Mental-Alpaca và Mental-FLAN-T5, vượt trội hơn thiết kế prompt tốt nhất của GPT-3.5 (lớn hơn 25 và 15 lần) 10.9% về balanced accuracy và tốt nhất của GPT-4 (lớn hơn 250 và 150 lần) 4.8%. Chúng còn có hiệu suất ngang bằng với mô hình ngôn ngữ chuyên biệt cho tác vụ cụ thể hiện đại nhất. Chúng tôi cũng tiến hành một nghiên cứu tình huống khám phá về khả năng của LLM trong các tác vụ lý luận sức khỏe tâm thần, minh họa khả năng đầy hứa hẹn của một số mô hình như GPT-4. Chúng tôi tóm tắt các phát hiện của mình thành một bộ hướng dẫn hành động cho các phương pháp tiềm năng để nâng cao khả năng của LLM cho các tác vụ sức khỏe tâm thần. Đồng thời, chúng tôi cũng nhấn mạnh những hạn chế quan trọng trước khi đạt được khả năng triển khai trong môi trường sức khỏe tâm thần thực tế, chẳng hạn như thiên kiến chủng tộc và giới tính đã biết. Chúng tôi nêu bật những rủi ro đạo đức quan trọng đi kèm với hướng nghiên cứu này.

CCS Concepts: •Human-centered computing →Ubiquitous and mobile computing ;•Applied computing →Life and medical sciences .

Additional Key Words and Phrases: Sức khỏe Tâm thần, Mô hình Ngôn ngữ Lớn, Instruction Finetuning

ACM Reference Format:
Xuhai Xu, Bingsheng Yao, Yuanzhe Dong, Saadia Gabriel, Hong Yu, James Hendler, Marzyeh Ghassemi, Anind K. Dey, and Dakuo Wang. 2024. Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via Online Text Data. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 8, 1, Article 32 (March 2024), 32 pages. https://doi.org/10.1145/3643540

Địa chỉ tác giả: Xuhai Xu, xuhaixu@uw.edu, Viện Công nghệ Massachusetts & Đại học Washington, Hoa Kỳ; Bingsheng Yao, Viện Bách khoa Rensselaer, Hoa Kỳ; Yuanzhe Dong, Đại học Stanford, Hoa Kỳ; Saadia Gabriel, Viện Công nghệ Massachusetts, Hoa Kỳ; Hong Yu, Đại học Massachusetts Lowell, Hoa Kỳ; James Hendler, Viện Bách khoa Rensselaer, Hoa Kỳ; Marzyeh Ghassemi, Viện Công nghệ Massachusetts, Hoa Kỳ; Anind K. Dey, Đại học Washington, Hoa Kỳ; Dakuo Wang, Đại học Northeastern, Hoa Kỳ.

Quyền được cấp để tạo bản sao kỹ thuật số hoặc bản cứng toàn bộ hoặc một phần công trình này cho mục đích sử dụng cá nhân hoặc lớp học mà không cần phí, với điều kiện các bản sao không được tạo ra hoặc phân phối để kiếm lợi nhuận hoặc lợi thế thương mại và các bản sao phải ghi chú này và trích dẫn đầy đủ trên trang đầu tiên. Bản quyền cho các thành phần của công trình này thuộc sở hữu của những người khác ngoài (các) tác giả phải được tôn trọng. Việc tóm tắt với ghi công nguồn được cho phép. Để sao chép theo cách khác, hoặc tái xuất bản, đăng trên máy chủ hoặc phân phối đến danh sách, cần có sự cho phép cụ thể trước và/hoặc một khoản phí. Yêu cầu quyền từ permissions@acm.org.
©2024 Bản quyền thuộc về chủ sở hữu/tác giả. Quyền xuất bản được cấp phép cho ACM.
2474-9567/2024/3-ART32 $15.00
https://doi.org/10.1145/3643540

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 8, No. 1, Article 32. Ngày xuất bản: Tháng 3 năm 2024.arXiv:2307.14385v4 [cs.CL] 28 Jan 2024

## 1 GIỚI THIỆU

Sự gia tăng gần đây của các Mô hình Ngôn ngữ Lớn (LLM), như GPT-4 [18], PaLM [23], FLAN-T5 [24], và Alpaca [115], cho thấy khả năng đầy hứa hẹn của các mô hình được tiền huấn luyện lớn để giải quyết các tác vụ đa dạng trong thiết lập zero-shot (tức là các tác vụ không gặp phải trong quá trình huấn luyện). Các tác vụ ví dụ bao gồm trả lời câu hỏi [87,100], lý luận logic [124,135], dịch máy [15,45], v.v. Một số thí nghiệm đã tiết lộ rằng, được xây dựng trên hàng trăm tỷ tham số, những LLM này đã bắt đầu cho thấy khả năng hiểu được thông thức con người bên dưới ngôn ngữ tự nhiên và thực hiện lý luận và suy luận phù hợp [18, 85].

Trong số các ứng dụng khác nhau, một câu hỏi cụ thể chưa được trả lời là LLM có thể hiểu các trạng thái sức khỏe tâm thần của con người thông qua ngôn ngữ tự nhiên tốt như thế nào. Các vấn đề sức khỏe tâm thần đại diện cho một gánh nặng đáng kể cho các cá nhân và xã hội trên toàn thế giới. Một báo cáo gần đây cho thấy hơn 20% người lớn ở Hoa Kỳ trải qua ít nhất một rối loạn tâm thần trong đời [9] và 5.6% đã bị rối loạn tâm thần nghiêm trọng ảnh hưởng đáng kể đến chức năng [3]. Nền kinh tế toàn cầu mất khoảng 1 nghìn tỷ đô la hàng năm về năng suất chỉ riêng do trầm cảm và lo âu [2].

Trong thập kỷ qua, đã có rất nhiều nghiên cứu trong xử lý ngôn ngữ tự nhiên (NLP) và khoa học xã hội tính toán về việc phát hiện các vấn đề sức khỏe tâm thần thông qua dữ liệu văn bản trực tuyến như nội dung mạng xã hội (ví dụ: [26,32,33,38,47]). Tuy nhiên, hầu hết các nghiên cứu này tập trung vào việc xây dựng các mô hình máy học (ML) chuyên biệt cho lĩnh vực (tức là một mô hình cho một tác vụ cụ thể, chẳng hạn như phát hiện căng thẳng [46,84], dự đoán trầm cảm [38,113,127,128], hoặc đánh giá rủi ro tự tử [28,35]). Ngay cả đối với các mô hình ngôn ngữ được tiền huấn luyện truyền thống như BERT, chúng cần được tinh chỉnh cho các tác vụ downstream cụ thể [37,72]. Một số nghiên cứu cũng đã khám phá thiết lập đa tác vụ [12], chẳng hạn như dự đoán trầm cảm và lo âu cùng một lúc [106]. Tuy nhiên, những mô hình này bị hạn chế bởi các bộ tác vụ được xác định trước, cung cấp tính linh hoạt hạn chế. Từ một khía cạnh khác, một hướng nghiên cứu khác đã khám phá việc ứng dụng chatbot cho các dịch vụ sức khỏe tâm thần [20,21,68]. Hầu hết các chatbot chỉ đơn giản dựa trên quy tắc và có thể được hưởng lợi từ các mô hình tiên tiến hơn để trao quyền cho chatbot [4,68]. Mặc dù nỗ lực nghiên cứu ngày càng tăng về việc trao quyền cho AI trong sức khỏe tâm thần, điều quan trọng cần lưu ý là các kỹ thuật hiện có đôi khi có thể đưa ra thiên kiến và thậm chí cung cấp lời khuyên có hại cho người dùng [54, 74, 116].

Vì ngôn ngữ tự nhiên là một thành phần chính của đánh giá và điều trị sức khỏe tâm thần [43,110], LLM có thể là một công cụ mạnh mẽ để hiểu trạng thái tâm lý của người dùng cuối thông qua ngôn ngữ viết của họ. Những mô hình đa năng được instruction-finetuned này có thể hiểu nhiều loại đầu vào và loại bỏ nhu cầu huấn luyện nhiều mô hình cho các tác vụ khác nhau. Do đó, chúng tôi hình dung việc sử dụng một LLM duy nhất cho nhiều tác vụ liên quan đến sức khỏe tâm thần, chẳng hạn như trả lời câu hỏi đa dạng, lý luận và suy luận. Tầm nhìn này mở ra một loạt cơ hội cho các cộng đồng UbiComp, Tương tác Người-Máy tính (HCI), và sức khỏe tâm thần, chẳng hạn như hệ thống giám sát sức khỏe cộng đồng trực tuyến [44,90], chatbot cá nhân nhận biết sức khỏe tâm thần [5,36,63], trợ lý thông minh cho các nhà trị liệu sức khỏe tâm thần [108], công cụ kiểm duyệt trực tuyến [39], cố vấn và người hỗ trợ sức khỏe tâm thần hàng ngày [109], v.v. Tuy nhiên, thiếu điều tra về việc hiểu, đánh giá và cải thiện khả năng của LLM cho các tác vụ liên quan đến sức khỏe tâm thần.

Có một số nghiên cứu gần đây về đánh giá LLM (ví dụ: ChatGPT) trên các tác vụ liên quan đến sức khỏe tâm thần, hầu hết trong thiết lập zero-shot với kỹ thuật prompt đơn giản [10,67,132]. Các nhà nghiên cứu đã cho thấy kết quả sơ bộ rằng LLM có khả năng ban đầu dự đoán các rối loạn sức khỏe tâm thần bằng ngôn ngữ tự nhiên, với hiệu suất đầy hứa hẹn nhưng vẫn còn hạn chế so với các mô hình NLP chuyên biệt cho lĩnh vực hiện đại [67,132]. Khoảng cách còn lại này được mong đợi vì các LLM đa năng hiện tại không được huấn luyện cụ thể trên các tác vụ sức khỏe tâm thần. Tuy nhiên, để đạt được tầm nhìn của chúng tôi về việc tận dụng LLM cho hỗ trợ và trợ giúp sức khỏe tâm thần, chúng ta cần giải quyết câu hỏi nghiên cứu: Làm thế nào để cải thiện khả năng của LLM trong các tác vụ sức khỏe tâm thần?

Chúng tôi đã tiến hành một loạt thí nghiệm với sáu LLM, bao gồm Alpaca [115] và Alpaca-LoRA (LLaMA được LoRA-finetuned trên dataset Alpaca) [51], là các mô hình mã nguồn mở đại diện tập trung vào đối thoại và các tác vụ khác; FLAN-T5 [24], một mô hình mã nguồn mở đại diện tập trung vào giải quyết tác vụ; LLaMA2 [118], một trong những mô hình mã nguồn mở tiên tiến nhất được phát hành bởi Meta; GPT-3.5 [1] và GPT-4 [18], các LLM mã nguồn đóng đại diện với hơn 100 tỷ tham số. Xem xét tính khả dụng của dữ liệu, chúng tôi đã tận dụng các dataset mạng xã hội trực tuyến với nhãn sức khỏe tâm thần chất lượng cao do con người tạo ra. Do các mối quan tâm đạo đức của nghiên cứu AI hiện tại cho sức khỏe tâm thần, chúng tôi nhằm mục đích đánh giá hiệu suất của LLM như một bước đầu tiên trước khi chuyển sang triển khai thực tế. Các thí nghiệm của chúng tôi bao gồm ba giai đoạn: (1) zero-shot prompting, nơi chúng tôi thí nghiệm với nhiều prompt khác nhau liên quan đến sức khỏe tâm thần, (2) few-shot prompting, nơi chúng tôi chèn các ví dụ vào đầu vào prompt, và (3) instruction-finetuning, nơi chúng tôi tinh chỉnh LLM trên nhiều dataset sức khỏe tâm thần với các tác vụ đa dạng.

Kết quả của chúng tôi cho thấy cách tiếp cận zero-shot mang lại hiệu suất đầy hứa hẹn nhưng còn hạn chế trên các tác vụ dự đoán sức khỏe tâm thần khác nhau trên tất cả các mô hình. Đáng chú ý, FLAN-T5 và GPT-4 cho thấy hiệu suất khuyến khích, tiếp cận mô hình chuyên biệt cho tác vụ cụ thể hiện đại. Trong khi đó, việc cung cấp một vài shot trong prompt có thể cải thiện hiệu suất mô hình ở một mức độ nào đó (Δ= 4.1%), nhưng lợi thế là hạn chế. Cuối cùng và quan trọng nhất, chúng tôi phát hiện rằng instruction-finetuning cải thiện đáng kể hiệu suất mô hình trên nhiều tác vụ liên quan đến sức khỏe tâm thần và nhiều dataset khác nhau đồng thời. Alpaca và FLAN-T5 được tinh chỉnh của chúng tôi, cụ thể là Mental-Alpaca và Mental-FLAN-T5, vượt trội đáng kể so với tốt nhất của GPT-3.5 trên các thiết lập zero-shot và few-shot (×25 và 15 lớn hơn Alpaca và FLAN-T5) trung bình 10.9% về balanced accuracy, cũng như tốt nhất của GPT-4 4.8% (×250 và 150 lớn hơn Alpaca và FLAN-T5). Trong khi đó, Mental-Alpaca và Mental-FLAN-T5 có thể có hiệu suất ngang bằng với Mental-RoBERTa chuyên biệt cho tác vụ cụ thể hiện đại [58]. Chúng tôi tiếp tục tiến hành một nghiên cứu tình huống khám phá về khả năng lý luận sức khỏe tâm thần của LLM (tức là giải thích cơ sở lý luận đằng sau dự đoán của chúng). Kết quả của chúng tôi minh họa tương lai đầy hứa hẹn của một số LLM như GPT-4, đồng thời cũng gợi ý các trường hợp thất bại quan trọng cần sự chú ý nghiên cứu trong tương lai. Chúng tôi mã nguồn mở code và mô hình của mình tại https://github.com/neuhai/Mental-LLM.

Các thí nghiệm của chúng tôi trình bày một đánh giá toàn diện về các kỹ thuật khác nhau để nâng cao khả năng của LLM trong lĩnh vực sức khỏe tâm thần. Tuy nhiên, chúng tôi cũng lưu ý rằng kết quả kỹ thuật của chúng tôi không ngụ ý khả năng triển khai. Có nhiều hạn chế quan trọng của việc tận dụng LLM trong môi trường sức khỏe tâm thần, đặc biệt là dọc theo các khoảng cách chủng tộc và giới tính đã biết [6,42]. Chúng tôi thảo luận về những rủi ro đạo đức quan trọng cần được giải quyết trước khi đạt được triển khai thực tế.

Đóng góp của bài báo chúng tôi có thể được tóm tắt như sau:
(1) Chúng tôi trình bày một đánh giá toàn diện về kỹ thuật prompt engineering, few-shot, và finetuning trên nhiều LLM trong lĩnh vực sức khỏe tâm thần.
(2) Với dữ liệu mạng xã hội trực tuyến, kết quả của chúng tôi tiết lộ rằng finetuning trên nhiều dataset có thể cải thiện đáng kể khả năng của LLM trên nhiều tác vụ chuyên biệt về sức khỏe tâm thần trên các dataset khác nhau đồng thời.
(3) Chúng tôi phát hành mô hình Mental-Alpaca và Mental-FLAN-T5 của chúng tôi như các LLM mã nguồn mở nhắm mục tiêu tại nhiều tác vụ dự đoán sức khỏe tâm thần.
(4) Chúng tôi cung cấp một số hướng dẫn kỹ thuật cho các nhà nghiên cứu và nhà phát triển trong tương lai về việc biến LLM thành chuyên gia trong các lĩnh vực cụ thể. Chúng tôi cũng nêu bật những mối quan tâm đạo đức quan trọng liên quan đến việc tận dụng LLM cho các tác vụ liên quan đến sức khỏe.

## 2 KIẾN THỨC NỀN TẢNG

Chúng tôi tóm tắt ngắn gọn các công trình liên quan trong việc tận dụng dữ liệu văn bản trực tuyến cho dự đoán sức khỏe tâm thần (Mục 2.1). Chúng tôi cũng cung cấp tổng quan về nghiên cứu đang diễn ra trong LLM và ứng dụng của chúng trong lĩnh vực sức khỏe (Mục 2.2).

### 2.1 Dữ liệu Văn bản Trực tuyến và Sức khỏe Tâm thần

Các nền tảng trực tuyến, đặc biệt là các nền tảng mạng xã hội, đã được công nhận là một lăng kính đầy hứa hẹn có khả năng tiết lộ cái nhìn sâu sắc về trạng thái tâm lý, sức khỏe và phúc lợi của cả cá nhân và quần thể [22,30,33,47,91]. Trong thập kỷ qua, đã có nghiên cứu rộng rãi về việc tận dụng phân tích nội dung và các mẫu tương tác xã hội để xác định và dự đoán các rủi ro liên quan đến các vấn đề sức khỏe tâm thần, chẳng hạn như lo âu [8,104,111], rối loạn trầm cảm nặng [32,34,89,119,128,129], ý tưởng tự tử [19,29,35,101,114], và những vấn đề khác [25,27,77,103]. Tính chất thời gian thực của mạng xã hội, cùng với khả năng lưu trữ của nó, thường giúp giảm thiểu thiên kiến hồi tưởng. Lượng dữ liệu mạng xã hội phong phú cũng tạo điều kiện cho việc xác định, giám sát và dự đoán tiềm năng các yếu tố rủi ro theo thời gian. Ngoài quan sát và phát hiện, các nền tảng mạng xã hội có thể tiếp tục phục vụ như các kênh hiệu quả để cung cấp hỗ trợ kịp thời cho các cộng đồng có nguy cơ [66, 73, 99].

Từ góc độ công nghệ tính toán, nghiên cứu sớm bắt đầu với các phương pháp cơ bản [27,32,77]. Ví dụ, công trình tiên phong của Coppersmith et al. [27] đã sử dụng phân tích tương quan để tiết lộ mối quan hệ giữa dữ liệu ngôn ngữ mạng xã hội và các tình trạng sức khỏe tâm thần. Kể từ đó, các nhà nghiên cứu đã đề xuất một loạt phương pháp thiết kế đặc trưng và xây dựng các mô hình máy học cho dự đoán [14,79,82,102,119]. Ví dụ, De Choudhury et al. [34] đã trích xuất một số phong cách ngôn ngữ và các đặc trưng khác để xây dựng mô hình SVM để thực hiện dự đoán trầm cảm. Các nhà nghiên cứu cũng đã khám phá các mô hình dựa trên deep learning cho dự đoán sức khỏe tâm thần để loại bỏ nhu cầu về các đặc trưng được chế tác thủ công [57,107]. Ví dụ, Tadesse et al. [114] đã sử dụng mô hình LSTM-CNN và lấy word embeddings làm đầu vào để phát hiện ý tưởng tự tử trên Reddit.

Gần đây hơn, các mô hình ngôn ngữ được tiền huấn luyện đã trở thành phương pháp phổ biến cho các tác vụ NLP, bao gồm các tác vụ dự đoán sức khỏe tâm thần [48,58,83]. Ví dụ, Jiang et al. [60] đã sử dụng các biểu diễn ngữ cảnh từ BERT làm đặc trưng đầu vào cho phát hiện vấn đề sức khỏe tâm thần. Otsuka et al. [88] đã đánh giá hiệu suất của các mô hình được tiền huấn luyện dựa trên BERT trong môi trường lâm sàng. Trong khi đó, các nhà nghiên cứu cũng đã khám phá thiết lập đa tác vụ [12] nhằm dự đoán nhiều nhãn. Ví dụ, Sarkar et al. [106] đã huấn luyện mô hình đa tác vụ để dự đoán trầm cảm và lo âu cùng một lúc. Tuy nhiên, những mô hình đa tác vụ này bị hạn chế bởi một bộ tác vụ được xác định trước và do đó có tính linh hoạt hạn chế. Công trình của chúng tôi tham gia cùng mục tiêu và nhằm đạt được khả năng đa tác vụ linh hoạt hơn. Chúng tôi tập trung vào công nghệ thế hệ tiếp theo của LLM được instruction-finetuned, tận dụng sức mạnh của chúng trong hiểu ngôn ngữ tự nhiên, và khám phá khả năng của chúng trong các tác vụ sức khỏe tâm thần với dữ liệu mạng xã hội.

### 2.2 LLM và Ứng dụng Sức khỏe

Sau thành công lớn của các mô hình ngôn ngữ dựa trên Transformer như BERT [37] và GPT [96], các nhà nghiên cứu và thực hành đã tiến tới các mô hình ngôn ngữ lớn hơn và mạnh mẽ hơn (ví dụ: GPT-3 [17] và T5 [97]). Trong khi đó, các nhà nghiên cứu đã đề xuất instruction finetuning, một phương pháp sử dụng các prompt đa dạng trên nhiều dataset và tác vụ. Kỹ thuật này hướng dẫn mô hình trong quá trình huấn luyện và giai đoạn tạo sinh để thực hiện các tác vụ đa dạng trong một khung thống nhất duy nhất [123]. Những LLM được instruction-finetuned này, như GPT-4 [18], PaLM [23], FLAN-T5 [24], LLaMA [117], Alpaca [115], chứa hàng chục đến hàng trăm tỷ tham số, cho thấy hiệu suất đầy hứa hẹn trên nhiều tác vụ, chẳng hạn như trả lời câu hỏi [87,100], lý luận logic [124, 135], dịch máy [15, 45], v.v.

Các nhà nghiên cứu đã khám phá khả năng của những LLM này trong các lĩnh vực sức khỏe [59,70,71,75,85,112,125?]. Ví dụ, Singhal et al. [112] đã tinh chỉnh PaLM-2 trên các lĩnh vực y tế và đạt được 86.5% trên dataset MedQA. Tương tự, Wu et al. [125] đã tinh chỉnh LLaMA trên các bài báo y tế và cho thấy kết quả đầy hứa hẹn trên nhiều dataset QA sinh y. Jo et al. [61] đã khám phá việc triển khai LLM cho các tình huống sức khỏe cộng đồng. Jiang et al. [59] đã huấn luyện mô hình ngôn ngữ y tế trên các ghi chú lâm sàng không có cấu trúc từ hồ sơ sức khỏe điện tử và tinh chỉnh nó trên một loạt rộng các tác vụ dự đoán lâm sàng và vận hành. Đánh giá của họ chỉ ra rằng mô hình như vậy có thể được sử dụng cho các tác vụ lâm sàng khác nhau.

Có tương đối ít công trình trong lĩnh vực sức khỏe tâm thần. Một số công trình đã khám phá khả năng của LLM cho phân tích cảm xúc và lý luận cảm xúc [64, 95, 134].

Gần với nghiên cứu của chúng tôi, Lamichhane [67] và Amin et al. [10] đã kiểm tra hiệu suất của ChatGPT (GPT-3.5) trên nhiều tác vụ phân loại (ví dụ: phát hiện căng thẳng, trầm cảm và tự tử). Kết quả cho thấy ChatGPT cho thấy tiềm năng ban đầu cho các ứng dụng sức khỏe tâm thần, nhưng vẫn còn rất nhiều chỗ để cải thiện, với khoảng cách hiệu suất ít nhất 5-10% về độ chính xác và F1-score. Yang et al. [132] đã đánh giá thêm khả năng lý luận tiềm năng của GPT-3.5 cho các tác vụ lý luận (ví dụ: các yếu tố căng thẳng tiềm năng). Tuy nhiên, hầu hết các nghiên cứu trước đây chỉ tập trung vào zero-shot prompting và không khám phá các phương pháp khác để cải thiện hiệu suất của LLM. Gần đây nhất, Yang et al. [133] đã phát hành Mental-LLaMA, một bộ mô hình dựa trên LLaMA được tinh chỉnh trên các dataset sức khỏe tâm thần cho một bộ tác vụ sức khỏe tâm thần. Bảng 1 tóm tắt các công trình liên quan gần đây khám phá khả năng của LLM trên các tác vụ liên quan đến sức khỏe tâm thần. Không có công trình hiện tại nào khám phá khả năng ngoài LLaMA hoặc GPT-3.5. Trong công trình này, chúng tôi trình bày một khám phá toàn diện và có hệ thống về hiệu suất của nhiều LLM trên các tác vụ sức khỏe tâm thần, cũng như nhiều phương pháp để cải thiện khả năng của chúng.

Bảng 1. Tóm tắt Nghiên cứu liên quan đến LLM cho Ứng dụng Sức khỏe Tâm thần.

| LLMs | Phương pháp | Tác vụ |
|------|-------------|---------|
| Lamichhane [67] | GPT-3.5 | Zero-shot | Phân loại |
| Amin et al. [10] | GPT-3.5 | Zero-shot | Phân loại |
| Yang et al. [132] | GPT-3.5 | Zero-shot | Phân loại, Lý luận |
| Mental-LLaMA [133] | LLaMA2, Vicuna (dựa trên LLaMA) | Zero-shot, Few-shot, Instruction Finetuning | Phân loại, Lý luận |
| Mental-LLM (Công trình của chúng tôi) | Alpaca, Alpaca-LoRA, FLAN-T5, LLaMA2, GPT-3.5, GPT-4 | Zero-shot, Few-shot, Instruction Finetuning | Phân loại, Lý luận |

## 3 PHƯƠNG PHÁP

Chúng tôi giới thiệu thiết kế thí nghiệm của chúng tôi với LMM trên nhiều thiết lập tác vụ dự đoán sức khỏe tâm thần, bao gồm zero-shot prompting (Mục 3.1), few-shot prompting (Mục 3.2), và instruction finetuning (Mục 3.3). Những thiết lập này là bất khả tri mô hình, và chúng tôi sẽ trình bày chi tiết về các mô hình ngôn ngữ và dataset được sử dụng cho thí nghiệm của chúng tôi trong phần tiếp theo.

### 3.1 Zero-shot Prompting

Khả năng hiểu ngôn ngữ và lý luận của LLM đã cho phép một loạt ứng dụng rộng rãi mà không cần bất kỳ dữ liệu chuyên biệt cho lĩnh vực nào, mà chỉ cần cung cấp prompt thích hợp [65,122]. Do đó, chúng tôi bắt đầu với thiết kế prompt cho các tác vụ sức khỏe tâm thần trong thiết lập zero-shot.

Mục tiêu của thiết kế prompt là trao quyền cho LLM đa năng được tiền huấn luyện để đạt được hiệu suất tốt trên các tác vụ trong lĩnh vực sức khỏe tâm thần. Chúng tôi đề xuất một template prompt zero-shot chung (Prompt_ZS) bao gồm bốn phần:

Prompt_ZS = TextData + PromptPart1-S + PromptPart2-Q + OutputConstraint (1)

trong đó TextData là dữ liệu văn bản trực tuyến được tạo ra bởi người dùng cuối. Prompt Part1-S cung cấp các đặc tả cho mục tiêu dự đoán sức khỏe tâm thần. Prompt Part2-Q đặt ra câu hỏi cho LLM trả lời. Và OutputConstraint kiểm soát đầu ra của mô hình (ví dụ: "Chỉ trả về có hoặc không" cho tác vụ phân loại nhị phân).

Chúng tôi đề xuất một số chiến lược thiết kế cho Prompt Part1-S, như được hiển thị trong phần trên của Bảng 2: (1) Basic, để trống; (2) Context Enhancement, cung cấp thêm ngữ cảnh mạng xã hội về TextData; (3) Mental Health Enhancement, chèn khái niệm sức khỏe tâm thần bằng cách yêu cầu mô hình hành động như một chuyên gia. (4) Context & Mental Health Enhancement, kết hợp cả hai chiến lược nâng cao bằng cách yêu cầu mô hình hành động như một chuyên gia sức khỏe tâm thần trong ngữ cảnh mạng xã hội.

Bảng 2. Thiết kế Prompt cho Tác vụ Dự đoán Sức khỏe Tâm thần. Prompt Part1-S nhằm cung cấp đặc tả tốt hơn cho LLM và Prompt Part2-Q đặt ra câu hỏi cho LLM trả lời. Đối với Phần 1, chúng tôi đề xuất ba chiến lược: nâng cao ngữ cảnh, nâng cao sức khỏe tâm thần, và sự kết hợp của cả hai. Đối với Phần 2, chúng tôi thiết kế nội dung khác nhau cho nhiều loại vấn đề sức khỏe tâm thần và tác vụ dự đoán. Đối với mỗi phần, chúng tôi đề xuất hai đến ba phiên bản để cải thiện sự biến đổi của nó.

| Chiến lược | Prompt Part1-S |
|------------|----------------|
| Basic | • { trống } |
| Context Enhancement | • Người này đã viết đoạn văn này trên mạng xã hội. |
|  | • Hãy xem xét bài đăng này trên mạng xã hội để trả lời câu hỏi. |
| Mental Health Enhancement | • Là một nhà tâm lý học, hãy đọc bài đăng trên mạng xã hội và trả lời câu hỏi. |
|  | • Nếu bạn là một nhà tâm lý học, hãy đọc bài đăng trên mạng xã hội và trả lời câu hỏi. |
| Context & Mental Health Enhancement | • Người này đã viết đoạn văn này trên mạng xã hội. Là một nhà tâm lý học, hãy đọc bài đăng trên mạng xã hội và trả lời câu hỏi. |
|  | • Người này đã viết đoạn văn này trên mạng xã hội. Là một nhà tâm lý học, hãy xem xét tình trạng sức khỏe tâm thần được thể hiện trong bài đăng này, đọc bài đăng trên mạng xã hội, và trả lời câu hỏi. |

| Danh mục | Tác vụ | Prompt Part2-Q |
|----------|--------|----------------|
| Trạng thái tâm thần (ví dụ: căng thẳng, trầm cảm) | Phân loại nhị phân (ví dụ: có hoặc không) | • Người đăng bài có [căng thẳng] không? |
|  |  | • Người đăng bài đăng này có [căng thẳng] không? |
|  |  | • Xác định xem người đăng bài đăng này có [căng thẳng] không. |
|  | Phân loại đa lớp (ví dụ: nhiều mức độ) | • Người này [căng thẳng] ở mức độ nào? |
|  |  | • Người này [căng thẳng] như thế nào? |
|  |  | • Xác định người này [căng thẳng] như thế nào. |
| Hành động rủi ro nghiêm trọng (ví dụ: tự tử) | Phân loại nhị phân (ví dụ: có hoặc không) | • Người đăng bài có muốn [tự tử] không? |
|  |  | • Người đăng bài có khả năng [tự tử] không? |
|  |  | • Xác định xem người đăng bài đăng này có muốn [tự tử] không. |
|  | Phân loại đa lớp (ví dụ: nhiều mức độ) | • Người này có mức độ rủi ro [tự tử] nào? |
|  |  | • Người này [có ý định tự tử] như thế nào? |
|  |  | • Xác định người này có mức độ rủi ro [tự tử] nào. |

Đối với Prompt Part2-Q, chúng tôi chủ yếu tập trung vào hai danh mục mục tiêu dự đoán sức khỏe tâm thần: (1) dự đoán các trạng thái tâm thần quan trọng, như căng thẳng hoặc trầm cảm, và (2) dự đoán các hành động rủi ro cao, như tự tử. Chúng tôi điều chỉnh mô tả câu hỏi cho từng danh mục. Hơn nữa, đối với cả hai danh mục, chúng tôi khám phá các tác vụ phân loại nhị phân và đa lớp¹. Do đó, chúng tôi cũng thực hiện những sửa đổi nhỏ dựa trên các tác vụ cụ thể để đảm bảo các câu hỏi phù hợp (xem Mục 4 cho các tác vụ sức khỏe tâm thần của chúng tôi). Phần dưới của Bảng 2 tóm tắt ánh xạ.

Đối với cả Prompt Part1-S và Prompt Part2-Q, chúng tôi đề xuất nhiều phiên bản để cải thiện tính biến đổi của nó. Sau đó chúng tôi đánh giá những prompt này trên nhiều LLM trên các dataset khác nhau và so sánh hiệu suất của chúng.

### 3.2 Few-shot Prompting

Để cung cấp thêm thông tin chuyên biệt cho lĩnh vực, các nhà nghiên cứu cũng đã khám phá few-shot prompting với LLM bằng cách cung cấp các demonstration few-shot để hỗ trợ in-context learning (ví dụ: [7,31]). Lưu ý rằng những ví dụ ít này chỉ được sử dụng trong prompt, và các tham số mô hình vẫn không thay đổi. Trực giác là trình bày một vài "ví dụ" cho mô hình để học kiến thức chuyên biệt cho lĩnh vực in situ. Trong thiết lập của chúng tôi, chúng tôi cũng kiểm tra chiến lược này bằng cách thêm các cặp [Prompt_ZS - label] được lấy mẫu ngẫu nhiên bổ sung. Thiết kế của few-shot prompt (Prompt_FS) rất đơn giản:

Prompt_FS = [Sample Prompt_ZS - label]^M + Prompt_ZS (2)

trong đó M là số cặp prompt-label và bị giới hạn bởi giới hạn độ dài đầu vào của mô hình. Lưu ý rằng cả Sample Prompt_ZS và Prompt_ZS đều tuân theo Eq. 1 và sử dụng cùng thiết kế của Prompt Part1-S và Prompt Part2-Q để đảm bảo tính nhất quán.

### 3.3 Instruction Finetuning

Trái ngược với chiến lược few-shot prompting trong Mục 3.2, mục tiêu của chiến lược này gần hơn với few-shot transfer learning truyền thống, nơi chúng ta tiếp tục huấn luyện mô hình với một lượng nhỏ dữ liệu chuyên biệt cho lĩnh vực (ví dụ: [52, 71, 126]). Chúng tôi thí nghiệm với nhiều chiến lược finetuning.

#### 3.3.1 Single-dataset Finetuning. 
Theo hầu hết các công trình trước đây trong lĩnh vực sức khỏe tâm thần [26,35,132], chúng tôi đầu tiên tiến hành finetuning cơ bản trên một dataset duy nhất (tập huấn luyện). Mô hình được tinh chỉnh này có thể được kiểm tra trên cùng dataset (tập kiểm tra) để đánh giá hiệu suất của nó và các dataset khác nhau để đánh giá khả năng tổng quát hóa của nó.

#### 3.3.2 Multi-dataset Finetuning. 
Từ Mục 3.1 đến Mục 3.3.1, chúng tôi đã tập trung vào một dataset sức khỏe tâm thần duy nhất D. Thú vị hơn, chúng tôi tiếp tục thí nghiệm với finetuning trên nhiều dataset đồng thời. Cụ thể, chúng tôi tận dụng instruction finetuning để cho phép LLM xử lý nhiều tác vụ trong các dataset khác nhau [17]. Đáng chú ý rằng thiết lập instruction finetuning như vậy khác với các mô hình chuyên biệt về sức khỏe tâm thần hiện đại (ví dụ: Mental-RoBERTa [58]). Các mô hình trước đây được tinh chỉnh cho một tác vụ cụ thể, chẳng hạn như dự đoán trầm cảm hoặc dự đoán ý tưởng tự tử. Một khi được huấn luyện trên tác vụ A, mô hình trở nên chuyên biệt cho tác vụ A và chỉ phù hợp để giải quyết tác vụ cụ thể đó. Ngược lại, chúng tôi tinh chỉnh LLM trên nhiều dataset sức khỏe tâm thần, sử dụng các instruction đa dạng cho các tác vụ khác nhau trên những dataset này trong một lần lặp duy nhất. Điều này cho phép chúng xử lý nhiều tác vụ mà không cần finetuning chuyên biệt cho tác vụ bổ sung.

Đối với cả single- và multi-dataset finetuning, chúng tôi tuân theo hai bước giống nhau:

Bước 1: Tinh chỉnh với [Prompt_ZS - label]^∑^N_D_i-train_i∈I
Bước 2: Kiểm tra với [Prompt_ZS]^∑^N_D_i-test_i∈I (3)

trong đó N_D_i-train/N_D_i-test là tổng kích thước của dataset huấn luyện/kiểm tra D_i, I đại diện cho tập hợp các dataset được sử dụng cho finetuning, và i chỉ ra chỉ số dataset cụ thể (i∈I, |I|≥1). Cả Prompt_ZS-train và Prompt_ZS-test đều tuân theo Eq. 1. Tương tự như thiết lập few-shot trong Eq. 2, chúng sử dụng cùng thiết kế của Prompt Part1-S và Prompt Part2-Q.

## 4 TRIỂN KHAI

Thiết kế phương pháp của chúng tôi là bất khả tri đối với các dataset hoặc mô hình cụ thể. Trong phần này, chúng tôi giới thiệu các dataset cụ thể (Mục 4.1) và mô hình (Mục 4.2) tham gia vào các thí nghiệm của chúng tôi. Đặc biệt, chúng tôi nêu bật các mô hình mã nguồn mở được instructional-finetuned Mental-Alpaca và Mental-FLAN-T5 của chúng tôi (Mục 4.2.1). Chúng tôi cũng cung cấp tổng quan về thiết lập thí nghiệm và thước đo đánh giá của chúng tôi (Mục 4.3).

### 4.1 Dataset và Tác vụ

Thí nghiệm của chúng tôi dựa trên bốn dataset được thiết lập tốt thường được sử dụng cho phân tích sức khỏe tâm thần. Những dataset này được thu thập từ Reddit do chất lượng cao và tính khả dụng của chúng. Đáng chú ý rằng chúng tôi cố ý tránh sử dụng các dataset với nhãn yếu dựa trên các mẫu ngôn ngữ cụ thể (ví dụ: liệu người dùng có từng nói "Tôi được chẩn đoán với X"). Thay vào đó, chúng tôi sử dụng những dataset có chú thích hoặc giám sát của chuyên gia con người. Chúng tôi định nghĩa sáu tác vụ dự đoán sức khỏe tâm thần đa dạng dựa trên những dataset này.

• **Dreaddit [120]**: Dataset này thu thập các bài đăng thông qua Reddit PRAW API [94] từ ngày 1 tháng 1 năm 2017 đến ngày 19 tháng 11 năm 2018, chứa mười subreddit trong năm lĩnh vực (lạm dụng, xã hội, lo âu, PTSD và tài chính) và bao gồm bài đăng của 2929 người dùng. Nhiều người chú thích con người đánh giá xem các đoạn câu có cho thấy căng thẳng của người đăng hay không, và các chú thích được tổng hợp để tạo ra nhãn cuối cùng. Chúng tôi sử dụng dataset này cho dự đoán căng thẳng nhị phân ở mức bài đăng (**Tác vụ 1**).

• **DepSeverity [80]**: Dataset này tận dụng cùng các bài đăng được thu thập trong [120], nhưng với trọng tâm khác về trầm cảm. Hai người chú thích con người theo DSM-5 [98] và phân loại các bài đăng thành bốn mức độ trầm cảm: tối thiểu, nhẹ, trung bình và nghiêm trọng. Chúng tôi sử dụng dataset này cho hai tác vụ ở mức bài đăng: dự đoán trầm cảm nhị phân (tức là liệu bài đăng có cho thấy ít nhất trầm cảm nhẹ, **Tác vụ 2**), và dự đoán trầm cảm bốn mức độ (**Tác vụ 3**).

• **SDCNL [49]**: Dataset này cũng thu thập các bài đăng từ Python Reddit API, bao gồm r/SuicideWatch và r/Depression từ 1723 người dùng. Thông qua chú thích thủ công, họ gán nhãn xem mỗi bài đăng có cho thấy suy nghĩ tự tử hay không. Chúng tôi sử dụng dataset này cho dự đoán ý tưởng tự tử nhị phân ở mức bài đăng (**Tác vụ 4**).

• **CSSRS-Suicide [40]**: Dataset này chứa các bài đăng từ 15 subreddit liên quan đến sức khỏe tâm thần từ 2181 người dùng từ năm 2005 đến 2016. Bốn bác sĩ tâm thần thực hành theo hướng dẫn Columbia Suicide Severity Rating Scale (C-SSRS) [93] để chú thích thủ công 500 người dùng về rủi ro tự tử trong năm mức độ: hỗ trợ, chỉ báo, ý tưởng, hành vi và cố gắng. Chúng tôi tận dụng dataset này cho hai tác vụ ở mức người dùng: dự đoán rủi ro tự tử nhị phân (tức là liệu người dùng có cho thấy ít nhất chỉ báo tự tử, **Tác vụ 5**), và dự đoán rủi ro tự tử năm mức độ (**Tác vụ 6**).

Để kiểm tra khả năng tổng quát hóa của các phương pháp của chúng tôi, chúng tôi cũng tận dụng ba dataset khác từ các nền tảng khác nhau. Tương tự, tất cả các dataset đều chứa chú thích của con người làm nhãn.

• **Red-Sam [62,105]**: Dataset này cũng thu thập các bài đăng với PRAW API [94], liên quan đến năm subreddit (Mental Health, depression, loneliness, stress, anxiety). Chú thích của hai chuyên gia lĩnh vực được tổng hợp để tạo ra nhãn trầm cảm. Chúng tôi sử dụng dataset này như một dataset đánh giá bên ngoài về phát hiện trầm cảm nhị phân (**Tác vụ 2**). Mặc dù cũng từ Reddit, dataset này không được tham gia vào few-shot learning hoặc instruction finetuning. Chúng tôi kiểm tra chéo các dataset để đảm bảo không có bài đăng trùng lặp.

• **Twt-60Users [56]**: Dataset này thu thập twitter từ 60 người dùng trong năm 2015 với Twitter API. Hai người chú thích con người gán nhãn mỗi tweet với nhãn trầm cảm. Chúng tôi sử dụng dataset không phải Reddit này như một dataset đánh giá bên ngoài về phát hiện trầm cảm (**Tác vụ 2**). Lưu ý rằng dataset này có nhãn không cân bằng (90.7% False), vì hầu hết các tweet không chỉ ra khổ não tâm lý.

• **SAD [76]**: Dataset này chứa các tin nhắn văn bản giống SMS với chín loại danh mục yếu tố căng thẳng hàng ngày (công việc, trường học, vấn đề tài chính, hỗn loạn cảm xúc, mối quan hệ xã hội, vấn đề gia đình, sức khỏe, ra quyết định hàng ngày và khác). Những tin nhắn này được viết bởi 3578 con người. Chúng tôi sử dụng dataset không phải Reddit này như một dataset đánh giá bên ngoài về phát hiện căng thẳng nhị phân (**Tác vụ 1**). Lưu ý rằng những người làm việc đám đông con người viết các tin nhắn dưới các hướng dẫn kích hoạt yếu tố căng thẳng nhất định. Do đó, dataset này có nhãn không cân bằng ở phía bên kia (94.0% True).

Bảng 3 tóm tắt thông tin của bảy dataset và sáu tác vụ dự đoán sức khỏe tâm thần. Đối với mỗi dataset, chúng tôi tiến hành chia tách train-test 80%/20%. Đáng chú ý, để tránh rò rỉ dữ liệu, dữ liệu của mỗi người dùng được đặt độc quyền trong tập huấn luyện hoặc tập kiểm tra.

Bảng 3. Tóm tắt Bảy Dataset Sức khỏe Tâm thần được Sử dụng cho Thí nghiệm của Chúng tôi. Bốn dataset trên cùng được sử dụng cho cả huấn luyện và kiểm tra, trong khi ba dataset dưới cùng được sử dụng cho đánh giá bên ngoài. Chúng tôi định nghĩa sáu tác vụ dự đoán sức khỏe tâm thần đa dạng trên những dataset này.

| Dataset | Tác vụ | Kích thước Dataset | Độ dài Văn bản (Token) |
|---------|--------|-------------------|----------------------|
| Dreaddit [120] Nguồn: Reddit | #1: Dự đoán Căng thẳng Nhị phân mức bài đăng | Train: 2838 (47.6% False, 52.4% True) Test: 715 (48.4% False, 51.6% True) | Train: 114±41 Test: 113±39 |
| DepSeverity [80] Nguồn: Reddit | #2: Dự đoán Trầm cảm Nhị phân mức bài đăng | Train: 2842 (72.9% False, 17.1% True) Test: 711 (72.3% False, 17.7% True) | Train: 114±41 Test: 113±37 |
| | #3: Dự đoán Trầm cảm Bốn mức độ mức bài đăng | Train: 2842 (72.9% Minimum, 8.4% Mild, 11.2% Moderate, 7.4% Severe) Test: 711 (72.3% Minimum, 7.2% Mild, 11.5% Moderate, 10.0% Severe) | Train: 114±41 Test: 113±37 |
| SDCNL [49] Nguồn: Reddit | #4: Dự đoán Ý tưởng Tự tử Nhị phân mức bài đăng | Train: 1516 (48.1% False, 51.9% True) Test: 379 (49.1% False, 50.9% True) | Train: 101±161 Test: 92±119 |
| CSSRS-Suicide [40] Nguồn: Reddit | #5: Dự đoán Rủi ro Tự tử Nhị phân mức người dùng | Train: 400 (20.8% False, 79.2% True) Test: 100 (25.0% False, 75.0% True) | Train: 1751±2108 Test: 1909±2463 |
| | #6: Dự đoán Rủi ro Tự tử Năm mức độ mức người dùng | Train: 400 (20.8% Supportive, 20.8% Indicator, 34.0% Ideation, 14.8% Behavior, 9.8% Attempt) Test: 100 (25.0% Supportive, 16.0% Indicator, 35.0% Ideation, 18.0% Behavior, 6.0% Attempt) | Train: 1751±2108 Test: 1909±2463 |
| Red-Sam [105] Nguồn: Reddit | #2: Dự đoán Trầm cảm Nhị phân mức bài đăng | Đánh giá Bên ngoài: 3245 (26.1% False, 73.9% True) | Đánh giá Bên ngoài: 151 ±139 |
| Twt-60Users [56] Nguồn: Twitter | #2: Dự đoán Trầm cảm Nhị phân mức bài đăng | Đánh giá Bên ngoài: 8135 (90.7% False, 9.3% True) | Đánh giá Bên ngoài: 15 ±7 |
| SAD [76] Nguồn: Giống SMS | #1: Dự đoán Căng thẳng Nhị phân mức bài đăng | Đánh giá Bên ngoài: 6185 (6.0% False, 94.0% True) | Đánh giá Bên ngoài: 13 ±6 |

### 4.2 Mô hình

Chúng tôi thí nghiệm với nhiều LLM với kích thước, mục tiêu tiền huấn luyện và tính khả dụng khác nhau.

• **Alpaca (7B) [115]**: Một mô hình lớn mã nguồn mở được tinh chỉnh từ một mô hình LLaMA 7B mã nguồn mở khác [117] trên các demonstration tuân theo instruction. Thí nghiệm đã cho thấy Alpaca hoạt động tương tự về mặt chất lượng với text-davinci-003 của OpenAI trên một số thước đo tác vụ nhất định. Chúng tôi chọn phiên bản 7B tương đối nhỏ để tạo điều kiện chạy và tinh chỉnh trên phần cứng tiêu dùng.

• **Alpaca-LoRA (7B) [51]**: Một mô hình lớn mã nguồn mở khác được tinh chỉnh từ mô hình LLaMA 7B sử dụng cùng dataset như Alpaca [115]. Mô hình này tận dụng một kỹ thuật finetuning khác gọi là low-rank adaptation (LoRA) [51], với mục tiêu giảm chi phí finetuning bằng cách đóng băng trọng số mô hình và tiêm các ma trận phân tách hạng có thể huấn luyện vào mỗi lớp của kiến trúc Transformer. Mặc dù tương tự về tên, điều quan trọng cần lưu ý là Alpaca-LoRA hoàn toàn khác biệt với Alpaca. Chúng được huấn luyện trên cùng dataset nhưng với các phương pháp khác nhau.

• **FLAN-T5 (11B) [24]**: Một mô hình lớn mã nguồn mở T5 [97] được tinh chỉnh với nhiều dataset dựa trên tác vụ trên instructions. So với các LLM khác, FLAN-T5 tập trung hơn vào giải quyết tác vụ và ít được tối ưu hóa cho việc tạo ngôn ngữ tự nhiên hoặc đối thoại. Chúng tôi chọn phiên bản lớn nhất của FLAN-T5 (tức là FLAN-T5-XXL), có kích thước tương đương với Alpaca.

• **LLaMA2 (70B) [118]**: Một mô hình lớn mã nguồn mở gần đây được phát hành bởi Meta. Chúng tôi chọn phiên bản lớn nhất của LLaMA2, có kích thước nằm giữa FLAN-T5 và GPT-3.5.

• **GPT-3.5 (175B) [1]**: Mô hình lớn này là mã nguồn đóng và có sẵn thông qua API được cung cấp bởi OpenAI. Chúng tôi chọn gpt-3.5-turbo, một trong những mô hình có khả năng nhất và hiệu quả về chi phí trong họ GPT-3.5.

• **GPT-4 (1700B) [18]**: Đây là mô hình mã nguồn đóng lớn nhất có sẵn thông qua OpenAI API. Chúng tôi chọn gpt-4-0613. Do tính khả dụng hạn chế của API, chi phí tinh chỉnh GPT-3.5 hoặc GPT-4 là cấm kỵ.

Đáng chú ý rằng Alpaca, Alpaca-LoRA, GPT-3.5, LLaMA2 và GPT-4 đều được tinh chỉnh với đối thoại tự nhiên như một trong những mục tiêu tối ưu hóa. Ngược lại, FLAN-T5 tập trung hơn vào giải quyết tác vụ. Trong trường hợp của chúng tôi, các bài đăng đầu vào do người dùng viết giống đối thoại tự nhiên, trong khi các tác vụ dự đoán sức khỏe tâm thần được định nghĩa như các tác vụ phân loại cụ thể. Không rõ và do đó thú vị để khám phá LLM nào phù hợp hơn với mục tiêu của chúng tôi.

#### 4.2.1 Mental-Alpaca & Mental-FLAN-T5. 
Các phương pháp zero-shot prompting (Mục 3.1) và few-shot prompting (Mục 3.2) của chúng tôi không cập nhật tham số mô hình trong thí nghiệm. Ngược lại, instruction finetuning (Mục 3.3) sẽ cập nhật tham số mô hình và tạo ra các mô hình mới. Để nâng cao khả năng của chúng trong lĩnh vực sức khỏe tâm thần, chúng tôi cập nhật Alpaca và FLAN-T5 trên sáu tác vụ trên bốn dataset trong Mục 4.1 sử dụng phương pháp instruction finetuning đa dataset (Mục 3.3.2), dẫn đến mô hình mới Mental-Alpaca và Mental-FLAN-T5 của chúng tôi.

### 4.3 Thiết lập Thí nghiệm và Thước đo

Đối với các phương pháp zero-shot và few-shot prompting, chúng tôi tải các mô hình mã nguồn mở (Alpaca, Alpaca-LoRA, FLAN-T5, LLaMA2) với một đến tám GPU Nvidia A100 để thực hiện các tác vụ, tùy thuộc vào kích thước của mô hình. Đối với các mô hình mã nguồn đóng (GPT-3.5, và GPT-4), chúng tôi sử dụng OpenAI API để tiến hành các tác vụ hoàn thành chat.

Đối với việc tinh chỉnh Mental-Alpaca và Mental-FLAN-T5, chúng tôi hợp nhất bốn dataset với nhau và cung cấp instructions cho tất cả sáu tác vụ (trong tập huấn luyện). Chúng tôi sử dụng tám GPU Nvidia A100 cho instruction finetuning. Với cross entropy làm hàm mất mát, chúng tôi backpropagate và cập nhật tham số mô hình trong 3 epochs, với optimizer Adam và learning rate là 2e-5 (cosine scheduler, warmup ratio 0.03).

Chúng tôi tập trung vào balanced accuracy làm thước đo đánh giá chính, tức là trung bình của sensitivity (true positive rate) và specificity (true negative rate). Chúng tôi chọn thước đo này vì nó mạnh mẽ hơn đối với mất cân bằng lớp so với accuracy hoặc F1 score [16,129]. Đáng chú ý rằng kích thước của các LLM chúng tôi so sánh là rất khác nhau, với số lượng tham số từ 7B đến 1700B. Một mô hình lớn hơn thường được mong đợi có hiệu suất tổng thể tốt hơn một mô hình nhỏ hơn. Chúng tôi kiểm tra xem kỳ vọng này có đúng trong các thí nghiệm của chúng tôi không.

## 5 KẾT QUẢ

Chúng tôi tóm tắt kết quả thí nghiệm của chúng tôi với zero-shot prompting (Mục 5.1), few-shot prompting (Mục 5.2), và instruction finetuning (Mục 5.3). Hơn nữa, mặc dù chúng tôi chủ yếu tập trung vào các tác vụ dự đoán trong nghiên cứu này, chúng tôi cũng trình bày kết quả ban đầu của nghiên cứu tình huống khám phá về các tác vụ lý luận sức khỏe tâm thần trong Mục 5.4.

Nhìn chung, kết quả của chúng tôi cho thấy các thiết lập zero-shot và few-shot cho thấy hiệu suất đầy hứa hẹn của LLM cho các tác vụ sức khỏe tâm thần, mặc dù hiệu suất của chúng vẫn còn hạn chế. Instruction-finetuning trên nhiều dataset (Mental-Alpaca và Mental-FLAN-T5) có thể cải thiện đáng kể hiệu suất của mô hình trên tất cả các tác vụ đồng thời. Nghiên cứu tình huống của chúng tôi cũng tiết lộ khả năng lý luận mạnh mẽ của một số LLM, đặc biệt là GPT-4. Tuy nhiên, chúng tôi lưu ý rằng những kết quả này không chỉ ra khả năng triển khai. Chúng tôi nêu bật những mối quan tâm đạo đức quan trọng và khoảng cách trong Mục 6.

### 5.1 Zero-shot Prompting Cho thấy Hiệu suất Đầy hứa hẹn nhưng Hạn chế

Chúng tôi bắt đầu với zero-shot prompting cơ bản nhất với Alpaca, Alpaca-LoRA, FLAN-T5, LLaMA2, GPT-3.5, và GPT-4. Kết quả balanced accuracy được tóm tắt trong các phần đầu tiên của Bảng 4. Alpaca_ZS và Alpaca-LoRA_ZS đạt được hiệu suất tổng thể tốt hơn so với baseline đa số ngây thơ (Δ_Alpaca = 5.5%, Δ_Alpaca-LoRA = 5.6%), nhưng chúng còn xa so với các mô hình baseline chuyên biệt cho tác vụ BERT và Mental-RoBERTa (có lợi thế 20%-25%). Với các mô hình lớn hơn nhiều GPT-3.5_ZS, hiệu suất trở nên đầy hứa hẹn hơn (Δ_GPT-3.5 = 12.4% so với baseline), phù hợp với công trình trước đây [132]. Lợi thế của GPT-3.5 so với Alpaca và Alpaca-LoRA được mong đợi do kích thước lớn hơn (25×).

Đáng ngạc nhiên, FLAN-T5_ZS đạt được kết quả tổng thể tốt hơn nhiều so với Alpaca_ZS (Δ_FLAN-T5_vs_Alpaca = 10.9%) và Alpaca-LoRA_ZS (Δ_FLAN-T5_vs_Alpaca-LoRA = 11.0%), và thậm chí cả LLaMA2 (Δ_FLAN-T5_vs_LLaMA2 = 1.0%) và GPT-3.5 (Δ_FLAN-T5_vs_GPT-3.5 = 4.2%). Lưu ý rằng LLaMA2 lớn hơn FLAN-T5 6 lần và GPT-3.5 lớn hơn 15 lần. Trên Tác vụ #6 (Dự đoán Rủi ro Tự tử Năm mức độ), FLAN-T5_ZS thậm chí vượt trội hơn Mental-RoBERTa hiện đại 4.5%. So sánh những kết quả này, mô hình tập trung vào giải quyết tác vụ FLAN-T5 dường như tốt hơn trong các tác vụ dự đoán sức khỏe tâm thần trong thiết lập zero-shot. Chúng tôi sẽ giới thiệu thêm các phát hiện thú vị sau khi finetuning (xem Mục 5.3.1).

Ngược lại, lợi thế của GPT-4 trở nên tương đối ít đáng kể hơn xem xét kích thước khổng lồ của nó. Hiệu suất trung bình của GPT-4_ZS vượt trội hơn FLAN-T5_ZS (150×kích thước), LLaMA2_ZS (25×kích thước), và GPT-3.5_ZS (10×kích thước) lần lượt 6.4%, 7.5%, và 10.6%. Tuy nhiên, vẫn rất khuyến khích khi quan sát rằng GPT-4 đang tiếp cận mức hiện đại trên những tác vụ này (Δ_GPT-4_vs_Mental-RoBERTa = -7.9%), và nó cũng vượt trội hơn Mental-RoBERTa trên Tác vụ #6 4.5%. Nói chung, những kết quả này chỉ ra khả năng đầy hứa hẹn của LLM trên các tác vụ dự đoán sức khỏe tâm thần so với các mô hình chuyên biệt cho tác vụ, ngay cả khi không có bất kỳ thông tin chuyên biệt cho lĩnh vực nào.

#### 5.1.1 Hiệu quả của Chiến lược Nâng cao. 
Trong Mục 3.1, chúng tôi đề xuất context enhancement, mental health enhancement, và chiến lược kết hợp của chúng cho thiết kế prompt zero-shot để cung cấp thêm thông tin về lĩnh vực. Thú vị thay, kết quả của chúng tôi gợi ý hiệu quả khác nhau trên các LLM và dataset khác nhau.

Bảng 5 cung cấp tóm tắt phóng to phần zero-shot trong Bảng 4. Đối với Alpaca, LLaMA2, GPT-3.5, và GPT-4, ba chiến lược cải thiện hiệu suất nói chung (Δ_Alpaca = 1.0%, 13 trong số 18 tác vụ cho thấy thay đổi tích cực; Δ_LLaMA2 = 0.3%, 12/18 tác vụ tích cực; Δ_GPT-3.5 = 2.8%, 12/18 tác vụ tích cực; Δ_GPT-4 = 0.2%, 11/18 tác vụ tích cực). Tuy nhiên, đối với Alpaca-LoRA và FLAN-T5, việc thêm nhiều ngữ cảnh hoặc thông tin lĩnh vực sức khỏe tâm thần sẽ giảm hiệu suất mô hình (Δ_Alpaca-LoRA = -2.7%, Δ_FLAN-T5 = -1.6%). Đối với Alpaca-LoRA, hạn chế này có thể xuất phát từ việc được huấn luyện với ít tham số hơn, có khả năng hạn chế khả năng hiểu ngữ cảnh hoặc đặc thù lĩnh vực của nó. Đối với FLAN-T5, hiệu suất giảm này có thể được quy cho khả năng hạn chế trong việc xử lý thông tin bổ sung, vì nó chủ yếu được điều chỉnh cho giải quyết tác vụ.

Hiệu quả của các chiến lược trên các dataset/tác vụ khác nhau cũng thay đổi. Chúng tôi quan sát rằng Tác vụ #4 từ dataset SDCNL và Tác vụ #6 từ dataset CSSRS-Suicide hưởng lợi nhiều nhất từ việc nâng cao. Đặc biệt, GPT-3.5 hưởng lợi rất đáng kể từ enhancement trên Tác vụ #4 (Δ_GPT-3.5-Task#4 = 14.8%). Và LLaMA2 hưởng lợi đáng kể trên Tác vụ #6 (Δ_GPT-3.5-Task#6 = 6.8%). Những điều này có thể được gây ra bởi bản chất khác nhau của các dataset. Kết quả của chúng tôi gợi ý rằng những chiến lược enhancement này thường hiệu quả hơn cho dự đoán hành động quan trọng (ví dụ: tự tử, 2/3 tác vụ tích cực) hơn dự đoán trạng thái tâm thần (ví dụ: căng thẳng và trầm cảm, 1/3 tác vụ tích cực).

Chúng tôi cũng so sánh hiệu quả của các chiến lược khác nhau trên bốn mô hình với hiệu ứng tích cực: Alpaca, LLaMA2, GPT-3.5, và GPT-4. Chiến lược context enhancement có cải thiện ổn định nhất trên tất cả các tác vụ dự đoán sức khỏe tâm thần (Δ_Alpaca-context = 2.1%, 6/6 tác vụ tích cực; Δ_LLaMA2-context = 1.2%, 4/6 tác vụ tích cực; Δ_GPT-3.5-context = 2.5%, 5/6 tác vụ tích cực; Δ_GPT-4-context = 0.4%, 5/6 tác vụ tích cực). So sánh, chiến lược mental health enhancement kém hiệu quả hơn (Δ_Alpaca-mh = 1.1%, 5/6 tác vụ tích cực; Δ_LLaMA2-mh = -0.5%, 4/6 tác vụ tích cực; Δ_GPT-3.5-mh = 2.1%, 3/6 tác vụ tích cực; Δ_GPT-4-mh = 0.2%, 3/6 tác vụ tích cực). Sự kết hợp của hai chiến lược mang lại kết quả đa dạng. Nó có cải thiện đáng kể nhất trên hiệu suất của GPT-3.5, nhưng không trên tất cả các tác vụ (Δ_GPT-3.5-both = 3.9%, 4/6 tác vụ tích cực), theo sau bởi LLaMA2 (Δ_LLaMA2-both = 0.2%, 4/6 tác vụ tích cực). Tuy nhiên, nó có tác động hơi tiêu cực trên hiệu suất trung bình của Alpaca (Δ_Alpaca-both = -0.1%, 2/6 tác vụ tích cực) hoặc GPT-4 (Δ_GPT-4-both = -0.3%, 3/6 tác vụ tích cực). Điều này chỉ ra rằng các mô hình ngôn ngữ lớn hơn (LLaMA2, GPT-3.5 vs. Alpaca) có khả năng mạnh mẽ để tận dụng thông tin được nhúng trong các prompt. Nhưng đối với GPT-4 khổng lồ, việc thêm prompt dường như kém hiệu quả hơn, có lẽ vì nó đã chứa thông tin cơ bản tương tự trong không gian kiến thức của nó.

Chúng tôi tóm tắt những điểm chính từ phần này:
• **Cả LLM quy mô nhỏ và quy mô lớn đều cho thấy hiệu suất đầy hứa hẹn trên các tác vụ sức khỏe tâm thần. Hiệu suất của FLAN-T5 và GPT-4 đang tiếp cận các mô hình NLP chuyên biệt cho tác vụ.**
• **Các chiến lược enhancement thiết kế prompt thường hiệu quả cho các mô hình tập trung vào đối thoại, nhưng không cho các mô hình tập trung vào giải quyết tác vụ. Những chiến lược này hoạt động tốt hơn cho các tác vụ dự đoán hành động quan trọng như dự đoán tự tử.**

Bảng 4. Tóm tắt Hiệu suất Balanced Accuracy của Zero-shot, Few-shot và Instruction Finetuning trên LLM. ZS_best nêu bật hiệu suất tốt nhất trong các thiết kế prompt zero-shot, bao gồm context enhancement, mental health enhancement, và sự kết hợp của chúng (xem Bảng 2). Kết quả chi tiết có thể được tìm thấy trong Bảng 10 trong Phụ lục. Các số nhỏ đại diện cho độ lệch chuẩn trên các thiết kế khác nhau của Prompt Part1-S và Prompt Part2-Q. Các baseline ở hàng dưới cùng không có độ lệch chuẩn vì đầu ra chuyên biệt cho tác vụ là tĩnh, và thiết kế prompt không áp dụng. Do giới hạn kích thước token tối đa, chúng tôi chỉ tiến hành few-shot prompting trên một tập con của các dataset và đánh dấu các dataset không khả thi khác là "–". Đối với mỗi cột, kết quả tốt nhất được **in đậm**, và tốt thứ hai được <u>gạch chân</u>.

[Bảng tiếp tục với dữ liệu số...]

Bảng 5. Thay đổi Hiệu suất Balanced Accuracy sử dụng Chiến lược Enhancement. Màu xanh lá/đỏ chỉ ra độ chính xác tăng/giảm. Bảng này phóng to phần zero-shot của Bảng 4. ↑/↓ đánh dấu những cái có hiệu suất tốt hơn/tệ hơn so sánh.

[Bảng tiếp tục với dữ liệu số...]

• **Cung cấp thêm thông tin ngữ cảnh về tác vụ & đầu vào có thể cải thiện hiệu suất một cách nhất quán trong hầu hết các trường hợp.**
• **Các mô hình tập trung vào đối thoại với nhiều tham số có thể huấn luyện hơn (Alpaca vs. Alpaca-LoRA, cũng như LLaMA2/GPT-3.5 vs. Alpaca) có thể tận dụng tốt hơn thông tin ngữ cảnh hoặc lĩnh vực trong các prompt, tuy nhiên GPT-4 cho thấy hiệu ứng ít hơn trong phản ứng với các prompt khác nhau.**

### 5.2 Few-shot Prompting Cải thiện Hiệu suất ở Một mức độ nào đó

Sau đó chúng tôi điều tra hiệu quả của few-shot prompting. Lưu ý rằng vì chúng tôi quan sát các hiệu ứng đa dạng của các chiến lược thiết kế prompt trong Bảng 5, trong phần này, chúng tôi chỉ thí nghiệm với các prompt có hiệu suất tốt nhất trong thiết lập zero-shot. Hơn nữa, chúng tôi loại trừ Alpaca-LoRA do kết quả kém hứa hẹn và LLaMA2 do chi phí tính toán cao.

Do độ dài token đầu vào tối đa của các mô hình (2048), chúng tôi tập trung vào các dataset Dreaddit và DepSeverity có đầu vào ngắn hơn và thí nghiệm với M=2 trong Eq. 2 cho phân loại nhị phân và M=4/5 cho phân loại đa lớp, tức là một mẫu cho mỗi lớp. Chúng tôi lặp lại thí nghiệm trên mỗi tác vụ ba lần và ngẫu nhiên hóa các mẫu few shot cho mỗi lần chạy.

Chúng tôi tóm tắt kết quả tổng thể trong phần thứ hai của Bảng 4 và kết quả so sánh phóng to trong Bảng 6. Mặc dù các mô hình ngôn ngữ với few-shot prompting vẫn kém hiệu suất so với các mô hình chuyên biệt cho tác vụ, việc cung cấp các ví dụ của tác vụ có thể cải thiện hiệu suất mô hình trên hầu hết các tác vụ so với zero-shot prompting (Δ_FS_vs_ZS = 4.1%). Thú vị thay, few-shot prompting hiệu quả hơn cho Alpaca_FS và FLAN-T5_FS (Δ_Alpaca = 8.1%, 3/3 tác vụ tích cực; Δ_FLAN-T5 = 5.9%, 3/3 tác vụ tích cực) hơn GPT-3.5_FS và GPT-4_FS (Δ_GPT-3.5 = 1.2%, 2/3 tác vụ tích cực; Δ_GPT-4 = 0.9%, 2/3 tác vụ tích cực). Đặc biệt cho Tác vụ #3, chúng tôi quan sát cải thiện balanced accuracy 19.7% cho Alpaca nhưng giảm 2.3% cho GPT-3.5, do đó Alpaca vượt trội hơn GPT-3.5 trên tác vụ này. Tình huống tương tự được quan sát cho FLAN-T5 (cải thiện 12.7%) và GPT-4 (giảm 0.2%) trên Tác vụ #1. Điều này có thể được quy cho thực tế rằng các mô hình nhỏ hơn như Alpaca và FLAN-T5 có thể nhanh chóng thích ứng với các tác vụ phức tạp chỉ với một vài ví dụ. Ngược lại, các mô hình lớn hơn như GPT-3.5 và GPT-4, với dữ liệu "trong bộ nhớ" rộng rãi của chúng, thấy khó khăn hơn để nhanh chóng học từ các ví dụ mới.

Điều này dẫn đến thông điệp chính từ thí nghiệm này: **Few-shot prompting có thể cải thiện hiệu suất của LLM trên các tác vụ dự đoán sức khỏe tâm thần ở một mức độ nào đó, đặc biệt cho các mô hình nhỏ.**

### 5.3 Instruction Finetuning Tăng cường Hiệu suất cho Nhiều Tác vụ Đồng thời

Các thí nghiệm của chúng tôi cho đến nay đã cho thấy zero-shot và few-shot prompting có thể cải thiện LLM trên các tác vụ sức khỏe tâm thần ở một mức độ nào đó, nhưng hiệu suất tổng thể của chúng vẫn dưới các mô hình chuyên biệt cho tác vụ hiện đại. Trong phần này, chúng tôi khám phá hiệu quả của instruction finetuning.

Do chi phí cấm kỵ và thiếu tính minh bạch của việc finetuning GPT-3.5 và GPT-4, chúng tôi chỉ thí nghiệm với Alpaca và FLAN-T5 mà chúng tôi có toàn quyền kiểm soát. Chúng tôi chọn prompt thông tin nhất để cung cấp thêm kiến thức được nhúng trong quá trình finetuning. Như được giới thiệu trong Mục 3.3.2 và Mục 4.2.1, chúng tôi xây dựng Mental-Alpaca và Mental-FLAN-T5 bằng cách tinh chỉnh Alpaca và FLAN-T5 trên tất cả sáu tác vụ trên bốn dataset cùng một lúc.

Phần thứ ba của Bảng 4 tóm tắt kết quả tổng thể, và Bảng 7 nêu bật các so sánh chính.

Chúng tôi quan sát rằng cả Mental-Alpaca và Mental-FLAN-T5 đều đạt được hiệu suất tốt hơn đáng kể so với các phiên bản chưa được tinh chỉnh (Δ_Alpaca-FT_vs_ZS = 23.4%, Δ_Alpaca-FT_vs_FS = 18.3%; Δ_FLAN-T5-FT_vs_ZS = 14.7%, Δ_FLAN-T5-FT_vs_FS = 14.0%). Cả hai mô hình được tinh chỉnh đều vượt qua hiệu suất tốt nhất của GPT-3.5 trong các thiết lập zero-shot và few-shot trên tất cả sáu tác vụ (Δ_Mental-Alpaca_vs_GPT-3.5 = 10.1%; Δ_Mental-FLAN-T5_vs_GPT-3.5 = 11.6%) và vượt trội hơn phiên bản tốt nhất của GPT-4 trong hầu hết các tác vụ (Δ_Mental-Alpaca_vs_GPT-4 = 4.0%, 4/6 tác vụ tích cực; Δ_Mental-FLAN-T5_vs_GPT-4 = 5.5%, 5/6 tác vụ tích cực). Nhớ lại rằng GPT-3.5/GPT-4 lớn hơn Mental-Alpaca 25/250 lần và lớn hơn Mental-FLAN-T5 15/150 lần.

Quan trọng hơn, Mental-Alpaca và Mental-FLAN-T5 có hiệu suất ngang bằng với Mental-RoBERTa hiện đại. Mental-Alpaca có hiệu suất tốt nhất trên một tác vụ và tốt thứ hai trên ba tác vụ, trong khi Mental-FLAN-T5 có hiệu suất tốt nhất trên ba tác vụ. Đáng chú ý rằng Mental-RoBERTa là một mô hình chuyên biệt cho tác vụ, có nghĩa là nó được chuyên biệt hóa trên một tác vụ sau khi được huấn luyện trên nó. Ngược lại, Mental-Alpaca và Mental-FLAN-T5 có thể đồng thời hoạt động trên tất cả các tác vụ với một lần finetuning duy nhất. Những kết quả này cho thấy hiệu quả mạnh mẽ của instruction finetuning: Bằng cách tinh chỉnh LLM trên nhiều dataset sức khỏe tâm thần với instructions, các mô hình có thể đạt được khả năng tốt hơn để giải quyết nhiều tác vụ dự đoán sức khỏe tâm thần.

#### 5.3.1 LLM Tập trung vào Đối thoại so với Tập trung vào Giải quyết Tác vụ. 
Chúng tôi tiếp tục so sánh Mental-Alpaca và Mental-FLAN-T5. Nhìn chung, hiệu suất của chúng khá gần nhau (Δ_FLAN-T5_vs_Alpaca = 1.4%), với Mental-Alpaca tốt hơn ở Tác vụ #4 trên SDCNL và Mental-FLAN-T5 tốt hơn ở Tác vụ #5 và #6 trên CSSRS-Suicide. Trong Mục 5.1, chúng tôi quan sát rằng FLAN-T5_ZS có hiệu suất tốt hơn nhiều so với Alpaca_ZS (Δ_FLAN-T5_vs_Alpaca = 10.9%, 5/6 tác vụ tích cực) trong thiết lập zero-shot. Tuy nhiên, sau khi finetuning, lợi thế của FLAN-T5 biến mất.

Kết quả so sánh của chúng tôi chỉ ra rằng Alpaca, như một mô hình tập trung vào đối thoại, tốt hơn trong việc học từ dữ liệu ngôn ngữ tự nhiên của con người so với FLAN-T5. Mặc dù FLAN-T5 giỏi giải quyết tác vụ và do đó có hiệu suất tốt hơn trong thiết lập zero-shot, cải thiện hiệu suất của nó sau instruction finetuning tương đối nhỏ hơn so với Alpaca. Quan sát này có ý nghĩa cho các bên liên quan trong tương lai. Nếu dữ liệu và tài nguyên tính toán cho finetuning không có sẵn, sử dụng LLM tập trung vào giải quyết tác vụ có thể dẫn đến kết quả tốt hơn. Khi có đủ dữ liệu và tài nguyên tính toán, finetuning các mô hình dựa trên đối thoại có thể là lựa chọn tốt hơn. Hơn nữa, các mô hình như Alpaca, với khả năng đối thoại của chúng, có thể phù hợp hơn cho các ứng dụng downstream, chẳng hạn như trợ lý phúc lợi tâm thần cho người dùng cuối.

#### 5.3.2 Finetuning có Tổng quát hóa trên các Dataset không? 
Chúng tôi tiếp tục đo lường khả năng tổng quát hóa của LLM sau khi finetuning. Để làm điều này, chúng tôi instruction-finetune mô hình trên một dataset và đánh giá nó trên tất cả các dataset (như được giới thiệu trong Mục 3.3.1). Vì mục đích chính của phần này không phải là so sánh các mô hình khác nhau mà đánh giá phương pháp finetuning, chúng tôi chỉ tập trung vào Alpaca. Bảng 8 tóm tắt kết quả.

Chúng tôi đầu tiên thấy rằng finetuning và testing trên cùng dataset dẫn đến hiệu suất tốt, như được chỉ ra bởi các mục được đóng khung trên đường chéo trong Bảng 8. Một số kết quả thậm chí tốt hơn Mental-Alpaca (5 trong số 6 tác vụ) hoặc Mental-RoBERTa (3 trong số 6 tác vụ), điều này không đáng ngạc nhiên. Thú vị hơn, chúng tôi điều tra hiệu suất tổng quát hóa chéo dataset (tức là những cái ngoài đường chéo). Nhìn chung, finetuning trên một dataset duy nhất đạt được hiệu suất tốt hơn so với thiết lập zero-shot (Δ_FT-Single_vs_ZS = 4.2%). Tuy nhiên, các thay đổi hiệu suất khác nhau trên các tác vụ. Ví dụ, finetuning trên bất kỳ dataset nào đều có lợi cho Tác vụ #3 (Δ = 19.2%) và #5 (Δ = 16.4%), nhưng có hại cho Tác vụ #6 (Δ = -7.6%) và gần như vô ích cho Tác vụ #4 (Δ = -0.4%). Tổng quát hóa trên Dreaddit và DepSeverity cho thấy hiệu suất tốt, nhưng điều này chủ yếu vì chúng chia sẻ corpus ngôn ngữ. Những kết quả này chỉ ra rằng finetuning trên một dataset duy nhất có thể cung cấp kiến thức sức khỏe tâm thần với một mức độ nhất định và do đó cải thiện kết quả tổng quát hóa tổng thể, nhưng cải thiện như vậy không ổn định trên các tác vụ.

Hơn nữa, chúng tôi tiếp tục đánh giá khả năng tổng quát hóa của các mô hình tốt nhất được instructional-finetuned trên nhiều dataset của chúng tôi, tức là Mental-Alpaca và Mental-FLAN-T5. Chúng tôi tận dụng các dataset bên ngoài không được bao gồm trong finetuning. Bảng 9 nêu bật các kết quả chính. Kết quả chi tiết hơn có thể được tìm thấy trong Bảng 10.

Phù hợp với kết quả trong Bảng 7, instruction finetuning nâng cao hiệu suất mô hình trên các dataset bên ngoài (Δ_Alpaca = 16.3%, Δ_FLAN-T5 = 5.1%). Cả Mental-Alpaca và Mental-FLAN-T5 đều xếp hạng top 1 hoặc 2 trong 2/3 tác vụ bên ngoài. Đáng chú ý rằng các dataset Twt-60Users và SAD được thu thập bên ngoài Reddit, và dữ liệu của chúng khác với nguồn của các dataset finetuning. Những kết quả này cho thấy bằng chứng mạnh mẽ rằng instruction finetuning với các tác vụ đa dạng, ngay cả với dữ liệu được thu thập từ một nền tảng mạng xã hội duy nhất, có thể nâng cao đáng kể khả năng tổng quát hóa của LLM trên nhiều tình huống.

#### 5.3.3 Cần bao nhiêu Dữ liệu? 
Ngoài ra, chúng tôi quan tâm đến việc khám phá kích thước của dataset ảnh hưởng như thế nào đến kết quả của instruction finetuning. Để trả lời câu hỏi này, chúng tôi downsample tập huấn luyện xuống 50%, 20%, 10%, 5%, và 1% kích thước gốc và lặp lại mỗi cái ba lần. Chúng tôi tăng epoch huấn luyện tương ứng để đảm bảo rằng mô hình được tiếp xúc với lượng dữ liệu tương tự. Tương tự, chúng tôi cũng chỉ tập trung vào Alpaca. Hình 1 hiển thị kết quả. Chỉ với 1% dữ liệu, mô hình được tinh chỉnh có thể vượt trội hơn mô hình zero-shot trên hầu hết các tác vụ (5 trong số 6). Với 5% dữ liệu, mô hình được tinh chỉnh có hiệu suất tốt hơn trên tất cả các tác vụ. Như mong đợi, hiệu suất mô hình có xu hướng tăng với nhiều dữ liệu huấn luyện hơn. Đối với nhiều tác vụ, xu hướng tiếp cận một plato sau 10%. Sự khác biệt giữa 10% dữ liệu huấn luyện (ít hơn 300 mẫu cho mỗi dataset) và 100% dữ liệu huấn luyện không lớn (Δ = 5.9%).

#### 5.3.4 Nhiều Dữ liệu trong Một Dataset so với Ít Dữ liệu trên Nhiều Dataset. 
Trong Mục 5.3.2, finetuning trên một dataset duy nhất có thể được xem như huấn luyện trên một tập nhỏ hơn (khoảng 5-25% kích thước gốc) với biến đổi ít hơn (tức là không có finetuning trên các dataset). Do đó, kết quả trong Mục 5.3.2 có thể so sánh với những kết quả trong Mục 5.3.3. Chúng tôi thấy rằng hiệu suất tổng thể của mô hình tốt hơn khi mô hình được tinh chỉnh trên nhiều dataset khi kích thước dữ liệu huấn luyện tổng thể tương tự (Δ_FT-5%_vs_FT-Single = 3.8%, Δ_FT-10%_vs_FT-Single = 8.1%, Δ_FT-20%_vs_FT-Single = 12.4%). Điều này gợi ý rằng tăng biến đổi dữ liệu có thể mang lại lợi ích hiệu quả hơn cho kết quả finetuning khi kích thước dữ liệu huấn luyện được cố định.

Những kết quả này có thể hướng dẫn các nhà phát triển và thực hành trong tương lai trong việc thu thập kích thước và nguồn dữ liệu thích hợp để tinh chỉnh LLM cho lĩnh vực sức khỏe tâm thần một cách hiệu quả. Chúng tôi có thêm thảo luận trong phần tiếp theo. Tóm lại, chúng tôi nêu bật những điểm chính của các thí nghiệm finetuning của chúng tôi như sau:

• **Instruction finetuning trên nhiều dataset sức khỏe tâm thần có thể cải thiện đáng kể hiệu suất của LLM trên các tác vụ dự đoán sức khỏe tâm thần khác nhau. Mental-Alpaca và Mental-FLAN-T5 vượt trội hơn GPT-3.5 và GPT-4, và có hiệu suất ngang bằng với mô hình chuyên biệt cho tác vụ hiện đại.**

• **Mặc dù LLM tập trung vào giải quyết tác vụ có thể có hiệu suất tốt hơn trong thiết lập zero-shot cho các tác vụ dự đoán sức khỏe tâm thần, LLM tập trung vào đối thoại có khả năng mạnh mẽ hơn trong việc học từ ngôn ngữ tự nhiên của con người và có thể cải thiện đáng kể hơn sau khi finetuning.**

• **Finetuning LLM trên một số lượng nhỏ dataset và tác vụ có thể cải thiện kiến thức tổng quát hóa của mô hình trong sức khỏe tâm thần, nhưng hiệu ứng của nó không mạnh mẽ. So sánh, finetuning trên các tác vụ đa dạng có thể nâng cao khả năng tổng quát hóa một cách mạnh mẽ trên nhiều nền tảng mạng xã hội.**

• **Finetuning LLM trên một số lượng nhỏ mẫu (vài trăm) trên nhiều dataset đã có thể đạt được hiệu suất thuận lợi.**

• **Khi kích thước dữ liệu giống nhau, finetuning LLM trên dữ liệu với biến đổi lớn hơn (tức là nhiều dataset và tác vụ hơn) có thể đạt được hiệu suất tốt hơn.**

### 5.4 Nghiên cứu Tình huống về Khả năng của LLM trong Lý luận Sức khỏe Tâm thần

Ngoài việc đánh giá hiệu suất của LLM trên các tác vụ phân loại, chúng tôi cũng thực hiện bước đầu tiên để khám phá khả năng của LLM trong lý luận sức khỏe tâm thần. Đây là một lợi thế mạnh mẽ khác của LLM vì chúng có thể tạo ra ngôn ngữ tự nhiên giống con người dựa trên kiến thức được nhúng. Do chi phí cao của đánh giá có hệ thống các kết quả lý luận, ở đây chúng tôi trình bày một vài ví dụ như một nghiên cứu tình huống trên các LLM khác nhau. Đáng chú ý rằng chúng tôi không nhằm mục đích tuyên bố rằng một số LLM có khả năng lý luận tốt hơn/tệ hơn. Thay vào đó, phần này nhằm cung cấp cảm nhận chung về hiệu suất của LLM trên các tác vụ lý luận sức khỏe tâm thần.

Cụ thể, chúng tôi sửa đổi thiết kế prompt bằng cách chèn prompt Chain-of-Thought (CoT) [65] ở cuối OutputConstraint trong Eq. 1: "Trả về [tập hợp nhãn phân loại]. Cung cấp lý do từng bước". Chúng tôi so sánh Alpaca, FLAN-T5, GPT-3.5, và GPT-4. Kết quả của chúng tôi chỉ ra khả năng lý luận đầy hứa hẹn của những mô hình này, đặc biệt là GPT-3.5 và GPT-4. Chúng tôi cũng thí nghiệm với Mental-Alpaca và Mental-FLAN-T5 được tinh chỉnh. Thật không may, kết quả của chúng tôi cho thấy sau khi finetuning chỉ trên các tác vụ phân loại, hai mô hình này không còn có thể tạo ra các câu lý luận ngay cả với prompt CoT. Điều này gợi ý một hạn chế của mô hình được tinh chỉnh hiện tại.

#### 5.4.1 Khả năng Lý luận Đa dạng trên các LLM. 
Chúng tôi trình bày một số ví dụ như nghiên cứu tình huống của chúng tôi để minh họa khả năng lý luận của những LLM này. Ví dụ đầu tiên đến từ tác vụ dự đoán căng thẳng nhị phân (Tác vụ #1) trên dataset Dreaddit (xem Hình 2). Tất cả các mô hình đưa ra phân loại đúng, nhưng với khả năng lý luận khác nhau đáng kể. Đầu tiên, FLAN-T5 tạo ra lý do ngắn nhất. Mặc dù nó hợp lý, nó nông cạn và không cung cấp đủ cái nhìn sâu sắc. Điều này có thể hiểu được vì FLAN-T5 nhắm mục tiêu giải quyết tác vụ thay vì lý luận. So với FLAN-T5, Alpaca tạo ra lý do tốt hơn. Trong số năm lý do, hai trong số chúng phân tích chính xác trạng thái tâm lý của người dùng cho các tình huống căng thẳng. Trong khi đó, GPT-3.5 và GPT-4 tạo ra lý do chất lượng cao ở mức chuyên gia. Suy luận từ tuyên bố của người dùng là chính xác và sâu sắc, chỉ ra khả năng mạnh mẽ của chúng trong việc hiểu cảm xúc con người và sức khỏe tâm thần. So sánh hai mô hình, lý do của GPT-3.5 đơn giản hơn, theo tuyên bố của người dùng từng điểm và thêm bình luận cơ bản, trong khi đầu ra của GPT-4 hữu cơ và sâu sắc hơn, nhưng ngắn gọn hơn.

[Hình 2. Nghiên cứu Tình huống về Ví dụ Lý luận Đúng trên Tác vụ #1 Dự đoán Căng thẳng Nhị phân trên Dataset Dreaddit...]

Chúng tôi cũng có quan sát tương tự trong ví dụ thứ hai từ tác vụ dự đoán trầm cảm bốn mức độ (Tác vụ #3) trên dataset DepSeverity (xem Hình 3). Trong ví dụ này, mặc dù dự đoán của FLAN-T5 đúng, nó chỉ đơn giản lặp lại sự thật được người dùng nêu, mà không cung cấp thêm cái nhìn sâu sắc. Alpaca đưa ra dự đoán sai, nhưng nó cung cấp một câu lý luận chính xác (mặc dù tương đối nông cạn). GPT-3.5 đưa ra dự đoán mơ hồ bao gồm câu trả lời đúng. Ngược lại, GPT-4 tạo ra lý luận chất lượng cao nhất với dự đoán đúng. Với sự hiểu biết đúng về các triệu chứng trầm cảm, GPT-4 có thể suy luận chính xác từ tình huống của người dùng, liên kết nó với các triệu chứng, và cung cấp phân tích sâu sắc.

[Hình 3. Nghiên cứu Tình huống về Ví dụ Lý luận Hỗn hợp trên Tác vụ #3 Dự đoán Trầm cảm Bốn mức độ trên Dataset DepSeverity...]

#### 5.4.2 Lý luận Sai và Nguy hiểm từ LLM. 
Tuy nhiên, chúng tôi cũng muốn nhấn mạnh nội dung lý luận không chính xác, có thể dẫn đến hậu quả tiêu cực và rủi ro. Trong ví dụ đầu tiên, Alpaca tạo ra hai lý do sai cho "sự phụ thuộc vào người khác" và "mối quan tâm an toàn" được ảo giác, cùng với một lý do không liên quan cho người đọc thay vì người đăng. Trong ví dụ thứ hai, GPT-3.5 hiểu sai ý của người dùng về "relief". Để minh họa tốt hơn điều này, chúng tôi tiếp tục trình bày một ví dụ khác nơi tất cả bốn LLM đưa ra lý luận có vấn đề (xem Hình 4). Trong ví dụ này, người dùng đang hỏi ý kiến của những người khác về lo âu xã hội, với kinh nghiệm phỏng vấn việc làm của họ như một ví dụ. Mặc dù người dùng đề cập đến các tình huống mà họ lo lắng và căng thẳng, rõ ràng rằng họ bình tĩnh khi viết bài đăng này và mô tả kinh nghiệm của họ một cách khách quan. Tuy nhiên, FLAN-T5, GPT-3.5, và GPT-4 đều nhầm lẫn việc lấy mô tả về kinh nghiệm phỏng vấn lo lắng làm bằng chứng để hỗ trợ dự đoán sai của họ. Mặc dù Alpaca đưa ra dự đoán đúng, nó không hiểu chủ đề chính của bài đăng. Các false positive tiết lộ rằng LLM có thể tổng quát hóa quá mức theo cách sai: Bị căng thẳng trong một tình huống không chỉ ra rằng một người căng thẳng mọi lúc. Tuy nhiên, nội dung lý luận một mình đọc mượt mà và logic. Nếu bài đăng gốc không được cung cấp, nội dung có thể rất gây hiểu lầm, dẫn đến dự đoán sai với lý do "có vẻ vững chắc". Những ví dụ này rõ ràng minh họa các hạn chế của LLM hiện tại cho lý do sức khỏe tâm thần, cũng như rủi ro của chúng trong việc đưa ra thiên kiến nguy hiểm và hậu quả tiêu cực cho người dùng.

[Hình 4. Nghiên cứu Tình huống về Ví dụ Lý luận Không chính xác trên Tác vụ #1 Dự đoán Căng thẳng Nhị phân trên Dataset Dreaddit...]

Nghiên cứu tình huống gợi ý rằng GPT-4 có khả năng lý luận ấn tượng, tiếp theo là GPT-3.5 và Alpaca. Mặc dù FLAN-T5 cho thấy hiệu suất zero-shot đầy hứa hẹn, nó không giỏi lý luận. Kết quả của chúng tôi tiết lộ khả năng khuyến khích của LLM trong việc hiểu sức khỏe tâm thần của con người và tạo ra phân tích có ý nghĩa. Tuy nhiên, chúng tôi cũng trình bày các ví dụ nơi LLM có thể mắc lỗi và đưa ra giải thích có vẻ hợp lý nhưng thực tế là có sai sót. Điều này tiếp tục gợi ý tầm quan trọng của nhiều nghiên cứu trong tương lai về các mối quan tâm đạo đức và vấn đề an toàn của LLM trước khi triển khai thực tế.

## 6 THẢO LUẬN

Kết quả thí nghiệm của chúng tôi tiết lộ một số phát hiện thú vị. Trong phần này, chúng tôi thảo luận về các hướng dẫn tiềm năng để cho phép LLM cho các tác vụ liên quan đến sức khỏe tâm thần (Mục 6.1). Chúng tôi hình dung các hướng tương lai đầy hứa hẹn (Mục 6.2), đồng thời nêu bật những mối quan tâm đạo đức quan trọng và hạn chế với LLM cho sức khỏe tâm thần (Mục 6.3). Chúng tôi cũng tóm tắt các hạn chế của công trình hiện tại (Mục 6.4).

### 6.1 Hướng dẫn để Trao quyền cho LLM cho Các tác vụ Dự đoán Sức khỏe Tâm thần

Chúng tôi trích xuất và tóm tắt những điểm chính từ Mục 5 thành một bộ hướng dẫn cho các nhà nghiên cứu và thực hành trong tương lai về cách trao quyền cho LLM để tốt hơn trong các tác vụ dự đoán sức khỏe tâm thần khác nhau.

**Khi tài nguyên tính toán bị hạn chế, kết hợp thiết kế prompt & few-shot prompting, và chọn prompt cẩn thận.** Khi kích thước của các mô hình lớn tiếp tục tăng, yêu cầu về phần cứng (chủ yếu là GPU) cũng đã tăng, đặc biệt khi tinh chỉnh LLM. Ví dụ, trong thí nghiệm của chúng tôi, Alpaca được huấn luyện trên tám GPU A100 80GB trong ba giờ [115]. Với tài nguyên tính toán hạn chế, chỉ chạy suy luận hoặc dựa vào API là khả thi. Trong những trường hợp này, các chiến lược kỹ thuật prompt zero-shot và few-shot là các lựa chọn khả thi. Kết quả của chúng tôi chỉ ra rằng việc cung cấp các ví dụ sức khỏe tâm thần few-shot với các chiến lược enhancement thích hợp có thể cải thiện hiệu suất dự đoán một cách hiệu quả. Cụ thể, việc thêm thông tin ngữ cảnh về dữ liệu văn bản trực tuyến luôn hữu ích. Nếu mô hình có sẵn lớn và chứa kiến thức phong phú (ít nhất 7B tham số có thể huấn luyện), việc thêm thông tin lĩnh vực sức khỏe tâm thần cũng có thể có lợi.

**Với đủ tài nguyên tính toán, instruction finetune các mô hình trên các dataset sức khỏe tâm thần khác nhau.** Khi có đủ tài nguyên tính toán và huấn luyện/tinh chỉnh mô hình là khả thi, có nhiều lựa chọn hơn để nâng cao LLM cho các tác vụ dự đoán sức khỏe tâm thần. Các thí nghiệm của chúng tôi rõ ràng cho thấy instruction finetuning có thể cải thiện đáng kể hiệu suất của các mô hình, đặc biệt cho các mô hình dựa trên đối thoại vì chúng có thể hiểu và học từ ngôn ngữ tự nhiên của con người tốt hơn. Khi có nhiều dataset có sẵn, việc hợp nhất nhiều dataset và tác vụ cùng nhau và tinh chỉnh mô hình trong một vòng duy nhất là cách tiếp cận hiệu quả nhất để nâng cao khả năng tổng quát hóa của nó.

**Triển khai finetuning hiệu quả với hàng trăm ví dụ và ưu tiên biến đổi dữ liệu khi tài nguyên dữ liệu bị hạn chế.** Hình 1 cho thấy finetuning không yêu cầu dataset lớn. Nếu không có dataset có sẵn ngay lập tức, việc thu thập các dataset nhỏ với vài trăm mẫu thường đủ tốt. Hơn nữa, khi tổng lượng dữ liệu bị hạn chế (ví dụ: do hạn chế tài nguyên), việc thu thập dữ liệu từ nhiều nguồn khác nhau, mỗi nguồn có kích thước nhỏ hơn, có lợi hơn so với việc thu thập một dataset lớn duy nhất. Bởi vì instruction finetuning tổng quát hóa tốt hơn khi dữ liệu và tác vụ có biến đổi lớn hơn.

**Cần thêm dataset finetuning được tuyển chọn cho lý luận sức khỏe tâm thần.** Nghiên cứu tình huống của chúng tôi gợi ý rằng Mental-Alpaca và Mental-FLAN-T5 chỉ có thể tạo ra nhãn phân loại sau khi được tinh chỉnh chỉ trên các tác vụ phân loại, mất khả năng lý luận của chúng. Đây là một hạn chế lớn của các mô hình hiện tại. Một giải pháp tiềm năng liên quan đến việc kết hợp nhiều dataset tập trung vào lý luận hoặc nhân quả vào quá trình instruction finetuning, để các mô hình cũng có thể học mối quan hệ giữa kết quả sức khỏe tâm thần và các yếu tố nguyên nhân.

**Hiệu suất Dự đoán và Lý luận Hạn chế cho Ngữ cảnh Phức tạp.** LLM có xu hướng mắc nhiều lỗi hơn khi ngữ cảnh đối thoại phức tạp hơn [13,69]. Kết quả của chúng tôi ngữ cảnh hóa điều này trong lĩnh vực sức khỏe tâm thần. Mục 5.4.2 cho thấy một trường hợp ví dụ nơi hầu hết LLM không chỉ dự đoán không chính xác mà còn cung cấp các quá trình lý luận có sai sót. Phân tích thêm về các trường hợp dự đoán sai chỉ ra một khó khăn tái diễn: LLM thường mắc lỗi khi có sự ngắt kết nối giữa ngữ cảnh văn chữ và các tình huống thực tế bên dưới. Ví dụ trong Hình 4 là một trường hợp nơi LLM bị nhầm lẫn bởi trường hợp căng thẳng giả định được mô tả bởi người đó. Trong một ví dụ khác, tất cả LLM đánh giá không chính xác một người với trầm cảm nghiêm trọng (false negative): "Tôi chỉ bị ấn tượng bởi sự sẵn sàng giúp đỡ của bác sĩ này. Tôi cảm thấy được xác nhận mỗi khi rời khỏi văn phòng của ông ấy, như ai đó thực sự hiểu những gì tôi đang đấu tranh, và tôi không phải thuyết phục họ về bệnh tâm thần của tôi. Kết luận? Nghiên cứu các bác sĩ nếu bạn có thể trực tuyến, đọc đánh giá của họ và đừng bỏ cuộc cho đến khi bạn tìm thấy ai đó đối xử với bạn theo cách bạn xứng đáng. Nếu tôi có thể làm điều này, tôi hứa bạn có thể!" Ở đây, LLM bị đánh lạc hướng bởi cảm xúc tích cực bên ngoài, bỏ qua các gợi ý đáng kể như thăm bác sĩ thường xuyên và đề cập rõ ràng đến bệnh tâm thần. Những quan sát này nhấn mạnh một thiếu sót quan trọng của LLM: chúng không thể xử lý các tác vụ liên quan đến sức khỏe tâm thần phức tạp, đặc biệt là những tác vụ liên quan đến các tình trạng mãn tính như trầm cảm. Tính biến đổi của biểu hiện con người theo thời gian và tính nhạy cảm của các mô hình bị lung lay bởi văn bản bề mặt hơn là các tình huống bên dưới trình bày những thách thức đáng kể.

**Mặc dù có khả năng đầy hứa hẹn của LLM cho các tác vụ sức khỏe tâm thần, chúng vẫn còn xa mới có thể triển khai trong thế giới thực.** Các thí nghiệm của chúng tôi tiết lộ hiệu suất khuyến khích của LLM trên các tác vụ dự đoán và lý luận sức khỏe tâm thần. Tuy nhiên, như chúng tôi lưu ý trong Mục 6.3, kết quả hiện tại của chúng tôi không chỉ ra khả năng triển khai của LLM trong môi trường sức khỏe tâm thần thực tế. Có nhiều mối quan tâm đạo đức và an toàn quan trọng và khoảng cách trước khi triển khai cần được giải quyết trước khi đạt được sự mạnh mẽ và khả năng triển khai.

### 6.2 Vượt ra ngoài Tác vụ Dự đoán Sức khỏe Tâm thần và Dữ liệu Văn bản Trực tuyến

Các thí nghiệm hiện tại của chúng tôi chủ yếu liên quan đến các tác vụ dự đoán sức khỏe tâm thần, về cơ bản là các vấn đề phân loại. Có nhiều loại tác vụ mà các thí nghiệm của chúng tôi không bao phủ, chẳng hạn như hồi quy (ví dụ: dự đoán điểm số trên thang đo sức khỏe tâm thần). Đặc biệt, lý luận là một tác vụ hấp dẫn vì nó có thể tận dụng đầy đủ khả năng của LLM trong việc tạo ngôn ngữ [18,85]. Nghiên cứu tình huống ban đầu của chúng tôi về lý luận có hạn chế nhưng tiết lộ hiệu suất đầy hứa hẹn, đặc biệt cho các mô hình lớn như GPT-4. Chúng tôi dự định tiến hành thêm thí nghiệm trên các tác vụ vượt ra ngoài phân loại.

Ngoài ra, có một hướng mở rộng tiềm năng khác. Trong bài báo này, chúng tôi chủ yếu tập trung vào dữ liệu văn bản trực tuyến, là một trong những nguồn dữ liệu quan trọng của hệ sinh thái tính toán phổ biến. Tuy nhiên, có nhiều luồng dữ liệu có sẵn chứa thông tin phong phú, chẳng hạn như dữ liệu sensor đa phương thức từ điện thoại di động và thiết bị đeo (ví dụ: [55,78,81,130,131]). Điều này dẫn đến một câu hỏi mở khác về cách tận dụng LLM cho dữ liệu sensor chuỗi thời gian. Cần nhiều nghiên cứu hơn để khám phá các phương pháp tiềm năng để hợp nhất thông tin văn bản trực tuyến với các luồng sensor. Đây là một bộ câu hỏi nghiên cứu thú vị khác để khám phá trong công trình tương lai.

### 6.3 Đạo đức trong LLM và Khoảng cách Khả năng Triển khai cho Sức khỏe Tâm thần

Mặc dù các thí nghiệm của chúng tôi trên LLM đã cho thấy khả năng đầy hứa hẹn cho các tác vụ liên quan đến sức khỏe tâm thần, nó vẫn còn một chặng đường dài trước khi được triển khai trong các hệ thống thực tế. Nghiên cứu gần đây đã tiết lộ thiên kiến tiềm năng hoặc thậm chí lời khuyên có hại được đưa ra bởi LLM [50], đặc biệt với khoảng cách giới tính [42] và chủng tộc [6]. Trong sức khỏe tâm thần, những khoảng cách và sự chênh lệch này giữa các nhóm dân số đã tồn tại lâu dài [54]. Trong khi đó, nghiên cứu tình huống của chúng tôi về dự đoán không chính xác, tổng quát hóa quá mức, và giải thích "hợp lý giả mạo" tiếp tục nêu bật rủi ro của LLM hiện tại. Các nghiên cứu gần đây đang kêu gọi thêm sự nhấn mạnh và nỗ lực nghiên cứu trong việc đánh giá và giảm thiểu những thiên kiến này cho sức khỏe tâm thần [54, 116].

Mặc dù có khả năng mạnh mẽ hơn nhiều trong việc hiểu ngôn ngữ tự nhiên (và dấu hiệu sớm của kiến thức lĩnh vực sức khỏe tâm thần trong trường hợp của chúng tôi), LLM không khác gì các mô hình AI hiện đại khác được huấn luyện trên một lượng lớn nội dung do con người tạo ra, thể hiện tất cả các thiên kiến mà con người có [53,86,121]. Trong khi đó, mặc dù chúng tôi cẩn thận chọn các dataset với chú thích chuyên gia con người, tồn tại thiên kiến tiềm năng trong các nhãn, chẳng hạn như stereotype [92], thiên kiến xác nhận [41], nhãn chuẩn mực vs. mô tả [11]. Bên cạnh đó, quyền riêng tư là một mối quan tâm quan trọng khác. Mặc dù các dataset của chúng tôi dựa trên các nền tảng mạng xã hội công cộng, cần thiết phải xử lý cẩn thận dữ liệu liên quan đến sức khỏe tâm thần và đảm bảo ẩn danh trong bất kỳ nỗ lực nào trong tương lai. Những mối quan tâm đạo đức này cần nhận được sự chú ý không chỉ ở giai đoạn giám sát và dự đoán, mà còn trong các ứng dụng downstream, từ trợ lý cho các chuyên gia sức khỏe tâm thần đến chatbot cho người dùng cuối. Những nỗ lực cẩn thận vào phát triển an toàn, kiểm toán và quy định rất cần thiết để giải quyết những rủi ro đạo đức này.

### 6.4 Hạn chế

Bài báo của chúng tôi có một vài hạn chế. Đầu tiên, mặc dù chúng tôi cẩn thận kiểm tra chất lượng dataset của chúng tôi và bao phủ các loại LLM khác nhau, phạm vi của các dataset và các loại LLM được bao gồm vẫn còn hạn chế. Các phát hiện của chúng tôi dựa trên quan sát của những dataset và mô hình này, có thể không tổng quát hóa cho các trường hợp khác. Liên quan, khám phá của chúng tôi về thiết kế prompt zero-shot few-shot không toàn diện. Cửa sổ đầu vào hạn chế của một số mô hình cũng hạn chế khám phá của chúng tôi về nhiều mẫu hơn cho few-shot prompting. Hơn nữa, chúng tôi chưa tiến hành đánh giá có hệ thống về hiệu suất của những mô hình này trong lý luận sức khỏe tâm thần. Công trình tương lai có thể thiết kế các thí nghiệm quy mô lớn hơn để bao gồm nhiều dataset, mô hình, thiết kế prompt hơn, và đánh giá tốt hơn.

Thứ hai, các dataset của chúng tôi chủ yếu từ Reddit, có thể bị hạn chế. Mặc dù phân tích của chúng tôi trong Mục 5.3.2 cho thấy các mô hình được tinh chỉnh có khả năng tổng quát hóa chéo nền tảng, việc finetuning chỉ dựa trên Reddit và có thể đưa ra thiên kiến. Trong khi đó, mặc dù các nhãn không thể truy cập trực tiếp trên các nền tảng, có khả năng những dữ liệu văn bản này đã được bao gồm trong việc huấn luyện ban đầu của những mô hình lớn này. Chúng tôi vẫn cho rằng có ít rò rỉ thông tin miễn là các mô hình chưa thấy nhãn cho các tác vụ của chúng tôi, nhưng khó đo lường quá trình huấn luyện ban đầu có thể ảnh hưởng như thế nào đến kết quả trong đánh giá của chúng tôi.

Thứ ba, một hạn chế quan trọng khác của công trình hiện tại là thiếu đánh giá về tính công bằng của mô hình. Các dataset ẩn danh của chúng tôi không bao gồm thông tin nhân khẩu học toàn diện, khiến việc so sánh hiệu suất trên các nhóm dân số khác nhau trở nên khó khăn. Như chúng tôi đã thảo luận trong phần trước, rất nhiều công trình tương lai về đạo đức và công bằng là cần thiết trước khi triển khai những hệ thống như vậy trong thực tế.

## 7 KẾT LUẬN

Trong bài báo này, chúng tôi trình bày đánh giá toàn diện đầu tiên về nhiều LLM (Alpaca, Alpaca-LoRA, FLAN-T5, LLaMA2, GPT-3.5, và GPT-4) trên các tác vụ dự đoán sức khỏe tâm thần (phân loại nhị phân và đa lớp) thông qua dữ liệu văn bản trực tuyến. Các thí nghiệm của chúng tôi bao phủ zero-shot prompting, few-shot prompting, và instruction finetuning. Kết quả tiết lộ một số phát hiện thú vị. Chiến lược context enhancement của chúng tôi có thể cải thiện hiệu suất một cách mạnh mẽ cho tất cả LLM, và chiến lược mental health enhancement của chúng tôi có thể nâng cao các mô hình với số lượng lớn tham số có thể huấn luyện. Trong khi đó, few-shot prompting cũng có thể cải thiện hiệu suất mô hình một cách mạnh mẽ ngay cả khi chỉ cung cấp một ví dụ cho mỗi lớp. Quan trọng nhất, các thí nghiệm của chúng tôi cho thấy instruction finetuning trên nhiều dataset có thể cải thiện đáng kể hiệu suất mô hình trên các tác vụ dự đoán sức khỏe tâm thần khác nhau cùng một lúc, tổng quát hóa trên các nguồn dữ liệu và nền tảng bên ngoài. Các mô hình được tinh chỉnh tốt nhất của chúng tôi, Mental-Alpaca và Mental-FLAN-T5, vượt trội hơn LLaMA2, GPT-3.5 và GPT-4 lớn hơn nhiều, và có hiệu suất ngang bằng với mô hình chuyên biệt cho tác vụ hiện đại Mental-RoBERTa. Chúng tôi cũng tiến hành một nghiên cứu tình huống khám phá về khả năng lý luận của những mô hình này, tiếp tục gợi ý cả tương lai đầy hứa hẹn và những hạn chế quan trọng của LLM. Chúng tôi tóm tắt các phát hiện của mình như một bộ hướng dẫn cho các nhà nghiên cứu, nhà phát triển và thực hành trong tương lai muốn trao quyền cho LLM với kiến thức tốt hơn về sức khỏe tâm thần cho các tác vụ downstream. Trong khi đó, chúng tôi nhấn mạnh rằng những nỗ lực hiện tại của chúng tôi về LLM trong sức khỏe tâm thần vẫn còn xa mới có thể triển khai. Chúng tôi nêu bật những mối quan tâm đạo đức quan trọng đi kèm với hướng nghiên cứu này.

## LỜI CẢM ƠN

Công trình này được hỗ trợ bởi VW Foundation, Quanta Computing, và National Institutes of Health (NIH) dưới Grant No. 1R01MD018424-01.

## TÀI LIỆU THAM KHẢO

[Các tài liệu tham khảo từ [1] đến [135] được dịch và giữ nguyên format như bản gốc]

## PHỤ LỤC: BẢNG KẾT QUẢ CHI TIẾT

Bảng 10. Tóm tắt Hiệu suất Balanced Accuracy của Zero-shot, Few-shot và Instruction Finetuning trên LLM. context, mh, và both chỉ ra các chiến lược thiết kế prompt của context enhancement, mental health enhancement, và sự kết hợp của chúng (xem Bảng 2). Các số nhỏ đại diện cho độ lệch chuẩn trên các thiết kế khác nhau của Prompt Part1-S và Prompt Part2-Q. Các baseline ở hàng trên cùng không có độ lệch chuẩn vì đầu ra chuyên biệt cho tác vụ là tĩnh, và thiết kế prompt không áp dụng. Do giới hạn token, chi phí tính toán và hạn chế tài nguyên, một số thí nghiệm không khả thi được đánh dấu là "–". Đối với mỗi cột, kết quả tốt nhất được **in đậm**, và tốt thứ hai được <u>gạch chân</u>.

[Bảng 10 với tất cả dữ liệu số được giữ nguyên như bản gốc]

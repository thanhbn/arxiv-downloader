# 2401.00788.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2401.00788.pdf
# Kích thước tệp: 3364523 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
ASTRAIOS : Tinh chỉnh hướng dẫn tiết kiệm tham số
cho các mô hình ngôn ngữ lớn mã nguồn
Terry Yue Zhuo1,2Armel Zebaze3∗Nitchakarn Suppattarachai1
Leandro von Werra3Harm de Vries4Qian Liu5Niklas Muennighoff6
1Đại học Monash2CSIRO's Data613Hugging Face
4Nghiên cứu ServiceNow5Phòng thí nghiệm AI Sea6Contextual AI
terry.zhuo@monash.edu
/gtbhttps://github.com/bigcode-project/astraios
Tóm tắt
Chi phí cao của tinh chỉnh đầy đủ tham số (FFT) của các mô hình ngôn ngữ lớn
(LLM) đã dẫn đến một loạt các phương pháp tinh chỉnh tiết kiệm tham số (PEFT). Tuy
nhiên, vẫn chưa rõ phương pháp nào cung cấp sự đánh đổi chi phí-hiệu suất tốt nhất
ở các quy mô mô hình khác nhau. Chúng tôi giới thiệu ASTRAIOS, một bộ gồm 28 mô
hình OctoCoder được tinh chỉnh hướng dẫn sử dụng 7 phương pháp tinh chỉnh và 4 kích
thước mô hình lên đến 16 tỷ tham số. Thông qua các nghiên cứu trên 5 nhiệm vụ và 8 bộ
dữ liệu khác nhau bao gồm cả nhiệm vụ hiểu mã và tạo mã, chúng tôi thấy rằng FFT nhìn
chung dẫn đến hiệu suất downstream tốt nhất trên tất cả các quy mô, và các phương pháp
PEFT khác nhau đáng kể về hiệu quả dựa trên quy mô mô hình. LoRA thường mang lại
sự đánh đổi thuận lợi nhất giữa chi phí và hiệu suất. Nghiên cứu sâu hơn về tác động của
các phương pháp này đối với cả tính bền vững của mô hình và bảo mật mã cho thấy các
mô hình lớn hơn có xu hướng thể hiện tính bền vững giảm và ít bảo mật hơn. Cuối cùng,
chúng tôi khám phá mối quan hệ giữa các tham số được cập nhật, mất mát entropy chéo
và hiệu suất nhiệm vụ. Chúng tôi thấy rằng hiệu quả tinh chỉnh quan sát được trong các
mô hình nhỏ tổng quát hóa tốt cho các mô hình lớn hơn, và mất mát xác thực trong tinh
chỉnh hướng dẫn có thể là một chỉ báo đáng tin cậy về hiệu suất downstream tổng thể.

--- TRANG 2 ---
1 Giới thiệu
Các mô hình ngôn ngữ lớn (LLM) (Zhao et al., 2023) được huấn luyện trên Mã (Code LLM) đã cho thấy hiệu suất mạnh mẽ trên các nhiệm vụ kỹ thuật phần mềm khác nhau (Hou et al., 2023). Có ba mô hình chính: (A) Code LLM cho hoàn thành mã (Nijkamp et al., 2022; Fried et al., 2022; Li et al., 2023); (B) Code LLM tinh chỉnh theo nhiệm vụ cụ thể cho một nhiệm vụ duy nhất (Hou et al., 2023); và (C) Code LLM được tinh chỉnh hướng dẫn (Ouyang et al., 2022) xuất sắc trong việc theo dõi hướng dẫn của con người và tổng quát hóa tốt trên các nhiệm vụ chưa gặp (Wang et al., 2023b; Muennighoff et al., 2023c). Các Code LLM được tinh chỉnh hướng dẫn gần đây, bao gồm WizardCoder (Luo et al., 2023) và OctoCoder (Muennighoff et al., 2023a), đã đạt được hiệu suất tiên tiến trên các nhiệm vụ khác nhau mà không cần tinh chỉnh theo nhiệm vụ cụ thể.

Tuy nhiên, với việc tăng tham số của Code LLM, việc thực hiện tinh chỉnh đầy đủ tham số (FFT) để có được các mô hình được tinh chỉnh hướng dẫn trở nên đắt đỏ hơn. Trong thực tế, để tiết kiệm chi phí tính toán, tinh chỉnh tiết kiệm tham số (PEFT) đã được áp dụng. Chiến lược huấn luyện này nhằm đạt được hiệu suất tương đương với FFT bằng cách cập nhật ít tham số hơn. Mặc dù có nhiều phương pháp PEFT (Ding et al., 2022), phương pháp PEFT chủ đạo vẫn là LoRA, được đề xuất vào năm 2021 (Hu et al., 2021). Tuy nhiên, không có bằng chứng thực nghiệm nào cho thấy LoRA vẫn là tốt nhất cho code LLM được tinh chỉnh hướng dẫn. Trong bài báo này, chúng tôi nghiên cứu các code LLM được tinh chỉnh hướng dẫn với câu hỏi nghiên cứu sau: các phương pháp PEFT tốt nhất cho Code LLM là gì?

Phân tích hiện tại về các phương pháp PEFT trình bày một số cơ hội để khám phá thêm: (1) Vượt ra ngoài LLM theo nhiệm vụ cụ thể. Hầu hết các nghiên cứu trước (Zhou et al., 2022; Ding et al., 2023) chỉ tập trung vào mô hình (B), trong đó các mô hình cơ sở được chọn được tinh chỉnh trên các nhiệm vụ downstream cụ thể. Mặc dù các nghiên cứu này cung cấp hiểu biết về các phương pháp PEFT trên LLM theo nhiệm vụ cụ thể, khả năng chuyển giao các phát hiện của họ sang mô hình tinh chỉnh hướng dẫn là không rõ ràng. (2) Các lĩnh vực đa dạng. Các nghiên cứu về phương pháp PEFT có xu hướng đánh giá trong các lĩnh vực chủ đạo như thị giác (Sung et al., 2022; He et al., 2023) và văn bản (Houlsby et al., 2019; He et al., 2021), để lại các lĩnh vực khác như mã chưa được khám phá đầy đủ. (3) Phương pháp PEFT toàn diện. Các nghiên cứu trước về PEFT chủ yếu xem xét một số lượng hạn chế các phương pháp, chẳng hạn như tinh chỉnh dựa trên adapter (Houlsby et al., 2019) hoặc tinh chỉnh tái tham số hóa (Aghajanyan et al., 2021), điều này không nắm bắt được toàn bộ phạm vi các phương pháp có sẵn. (4) Đánh giá đa chiều. Các nghiên cứu trước chỉ xem xét đánh giá hạn chế trên các nhiệm vụ downstream đại diện (Chen et al., 2022; Fu et al., 2023; Ding et al., 2023). Chúng tôi cho rằng các chiều đánh giá khác như tính bền vững của mô hình (Han et al., 2021) và an toàn mã đầu ra (Weidinger et al., 2021; Zhuo et al., 2023b; Pearce et al., 2022; Dakhel et al., 2023) cũng quan trọng, đặc biệt trong kỷ nguyên của các agent LLM (Ouyang et al., 2022; Xie et al., 2023). (5) Khả năng mở rộng. Hầu hết các nghiên cứu PEFT trước đã chỉ khám phá LLM với quy mô kích thước mô hình và thời gian huấn luyện không đủ, điều này làm cho khả năng mở rộng của chúng đáng ngờ (Lester et al., 2021; Chen et al., 2022; Hu et al., 2023).

Để khám phá thêm những cơ hội đã xác định này, chúng tôi giới thiệu ASTRAIOS, một bộ gồm 28 Code LLM được tinh chỉnh hướng dẫn, được tinh chỉnh với 7 phương pháp tinh chỉnh dựa trên các mô hình cơ sở StarCoder (Li et al., 2023) (1B, 3B, 7B, 16B). Chúng tôi tinh chỉnh hướng dẫn các mô hình dựa trên bộ dữ liệu mã nguồn mở, CommitPackFT từ OctoPack (Muennighoff et al., 2023a), để cân bằng khả năng downstream của chúng. Chúng tôi sử dụng các cấu hình PEFT với thực tiễn tốt nhất của Hugging Face (Mangrulkar et al., 2022) và tích hợp một số phương pháp PEFT từ các framework gần đây (Hu et al., 2023). Đầu tiên, chúng tôi kiểm tra khả năng mở rộng của các phương pháp tinh chỉnh khác nhau thông qua góc nhìn của mất mát entropy chéo trong quá trình tinh chỉnh hướng dẫn. Cụ thể, chúng tôi đánh giá quy mô kích thước mô hình và thời gian huấn luyện. Đánh giá chính của chúng tôi tập trung vào 5 nhiệm vụ mã đại diện, bao gồm phát hiện sao chép (Svajlenko và Roy, 2021), phát hiện lỗi (Zhou et al., 2019), tổng hợp mã (Muennighoff et al., 2023a), sửa chữa mã (Muennighoff et al., 2023a), và giải thích mã (Muennighoff et al., 2023a). Chúng tôi nghiên cứu thêm các phương pháp tinh chỉnh từ hai khía cạnh: tính bền vững của mô hình (Wang et al., 2023a) và bảo mật mã (Pearce et al., 2022). Chúng tôi đánh giá mức độ tốt của các mô hình có thể tạo mã dựa trên các ví dụ bị nhiễu loạn và mức độ dễ bị tổn thương của mã được tạo ra.

Kết quả thực nghiệm chính có thể được tìm thấy trong Hình 1, nơi chúng tôi quan sát thấy FFT nhìn chung dẫn đến hiệu suất downstream tốt nhất trên tất cả các quy mô. Ngoài ra, chúng tôi thấy rằng các phương pháp PEFT khác nhau đáng kể về hiệu quả tùy thuộc vào quy mô mô hình. Ở 16B tham số, Parallel Adapter (He et al., 2021) và LoRA (Hu et al., 2021) là những phương pháp cạnh tranh nhất với FFT. Trong khi đó, ở 1B tham số, cả hai đều bị vượt trội một chút bởi P-Tuning và (IA)3. Do đó, việc lựa chọn phương pháp PEFT nên được xem xét cùng với quy mô mô hình hiện có. Tuy nhiên, LoRA thường mang lại sự đánh đổi thuận lợi nhất giữa chi phí và hiệu suất.

--- TRANG 3 ---
Trong khi đó, chúng tôi cũng quan sát thấy rằng các Code LLM PEFT lớn hơn hoạt động tốt hơn trên các nhiệm vụ tạo mã trong khi chúng không cho thấy các mô hình như vậy trên các nhiệm vụ hiểu mã như phát hiện sao chép và phát hiện lỗi. Ngoài ra, tăng kích thước mô hình cải thiện hiệu suất nhiệm vụ tạo nhưng thể hiện các lỗ hổng đối với các ví dụ đối nghịch và thiên vị đối với mã không an toàn. Ngoài ra, chúng tôi điều tra mối quan hệ giữa các tham số được cập nhật, mất mát entropy chéo và hiệu suất nhiệm vụ. Chúng tôi thấy rằng mất mát cuối cùng của các mô hình PEFT nhỏ có thể được ngoại suy cho các mô hình lớn hơn. Chúng tôi cũng quan sát thấy mối tương quan mạnh mẽ giữa mất mát cuối cùng và hiệu suất nhiệm vụ downstream tổng thể. Mặc dù bộ dữ liệu hướng dẫn mà chúng tôi chọn là chung chung và không tương quan trực tiếp với các nhiệm vụ benchmark downstream, chúng tôi đề xuất rằng hiệu suất trên dữ liệu chung như vậy có thể phục vụ như một proxy cho hiệu suất downstream.

2 Bộ A STRAIOS và Benchmark
Trong phần này, chúng tôi ghi lại chi tiết lựa chọn mô hình, cấu hình huấn luyện và đánh giá của chúng tôi để dễ dàng tái tạo các kết quả thực nghiệm trong bài báo này.

2.1 Mô hình
Mô hình cơ sở Có nhiều Code LLM có sẵn có thể là một mô hình cơ sở phù hợp. Tuy nhiên, một số trong số chúng không hoàn toàn mở như Code-Llama (Roziere et al., 2023), nơi dữ liệu huấn luyện không được thảo luận. Để tối đa hóa tính minh bạch, chúng tôi chọn chuỗi StarCoder làm mô hình cơ sở. Cụ thể, bốn quy mô mô hình bao gồm 1B, 3B, 7B và 16B tham số được chọn.

Mô hình PEFT Chúng tôi tập trung vào ba loại phương pháp PEFT (Ding et al., 2022): (1) Tinh chỉnh dựa trên Adapter (Houlsby et al., 2019): Một cách tiếp cận sớm, tiêm các mô-đun thần kinh quy mô nhỏ làm adapter vào LLM và chỉ tinh chỉnh các adapter này để thích ứng mô hình. (2) Tinh chỉnh dựa trên Prompt (Li và Liang, 2021): Nó bao bọc đầu vào ban đầu với ngữ cảnh bổ sung giới thiệu các token ảo theo nhiệm vụ cụ thể mà không thêm các lớp mô-đun như adapter. (3) Tinh chỉnh dựa trên Intrinsic-rank (Aghajanyan et al., 2021): Một phương pháp đại diện là LoRA, giả định rằng sự thay đổi của trọng số trong quá trình tinh chỉnh mô hình có thứ hạng thấp và do đó các thay đổi thứ hạng thấp đối với các ma trận là đủ. Đối với tất cả các phương pháp, chúng tôi sử dụng các triển khai trong thư viện PEFT mã nguồn mở (Mangrulkar et al., 2022) và công việc LLM-Adapters (Hu et al., 2023) được xây dựng dựa trên nó. Chúng tôi benchmark 6 phương pháp PEFT, bao gồm 4 phương pháp tinh chỉnh dựa trên adapter, 1 dựa trên prompt, và 1 dựa trên intrinsic-rank như được hiển thị trong Bảng 1. Chúng tôi cũng bao gồm FFT cho mỗi kích thước mô hình. Tỷ lệ tham số được cập nhật của mỗi phương pháp PEFT được trình bày trong Hình 2.

2.2 Tinh chỉnh hướng dẫn
Bộ dữ liệu Theo công việc trước đây, chúng tôi chọn bộ dữ liệu CommitPackFT+OASST từ OctoPack (Muennighoff et al., 2023a) làm bộ dữ liệu tinh chỉnh hướng dẫn, giúp StarCoder đạt được hiệu suất vượt trội. Chúng tôi lưu ý rằng có thể có các lựa chọn khác bằng cách sử dụng các bộ dữ liệu khác (ví dụ, bộ dữ liệu có sẵn công khai CodeAlpaca (Chaudhary, 2023)). Tuy nhiên, chúng thường tập trung vào một khía cạnh nhất định của các nhiệm vụ liên quan đến mã và thiếu tính tổng quát cho các nhiệm vụ khác nhau.

Cấu hình Chúng tôi huấn luyện tất cả các mô hình với độ dài chuỗi là 2048 token, với kích thước batch là 1, bước warm-up là 12 và các bước global là 200. Chúng tôi đặt tốc độ học là 1×10^-4 cho các mô hình PEFT và 1×10^-6 cho các mô hình FFT với bộ lập lịch cosine trong cả hai trường hợp. Đối với các phương pháp PEFT, chúng tôi sử dụng các mô hình được lượng tử hóa 8-bit trong quá trình huấn luyện (Dettmers et al., 2022).

2.3 Đánh giá
Hiểu mã Để đánh giá hiểu mã, chúng tôi chọn hai nhiệm vụ đại diện: phát hiện sao chép và phát hiện lỗi. Phát hiện sao chép nhằm xác định các đoạn mã là bản sao chính xác hoặc tương tự về cấu trúc với các biến thể trong định danh, chữ, loại, bố cục và chú thích, hoặc thậm chí tương tự rộng hơn về chức năng. Phát hiện lỗi nhắm mục tiêu xác định lỗi, lỗ hổng hoặc antipattern trong mã. Chúng tôi chọn hai bộ dữ liệu được sử dụng rộng rãi từ benchmark CodeXGLUE (Lu et al., 2021): BigCloneBench (Svajlenko và Roy, 2021) và Devign (Zhou et al., 2019). Vì BigCloneBench và Devign ban đầu được thiết kế để đánh giá các mô hình phân loại, chúng tôi thêm các hướng dẫn bổ sung vào đầu để nhắc các mô hình được tinh chỉnh hướng dẫn hoàn thành các nhiệm vụ như vậy. Chúng tôi tuân theo cài đặt đánh giá của CodeXGLUE và sử dụng F1 và Độ chính xác cho BigClone và Devign, tương ứng. Do số lượng ví dụ thử nghiệm không tầm thường trong hai bộ dữ liệu này, chúng tôi lấy mẫu 2.000 từ mỗi bộ để tiết kiệm chi phí. Vì BigCloneBench và Devign là các nhiệm vụ phân loại nhị phân, chúng tôi sử dụng nhiệt độ 0 để suy luận mô hình để có được đầu ra tất định.

Tạo mã Chúng tôi sử dụng HumanEvalPack (Muennighoff et al., 2023a), một benchmark được đề xuất gần đây cho phép đánh giá dễ dàng các Code LLM được tinh chỉnh hướng dẫn. Benchmark được cấu trúc xung quanh ba nhiệm vụ cốt lõi trong tạo mã, mỗi nhiệm vụ được thiết kế để kiểm tra các khả năng khác nhau của mô hình. Nhiệm vụ đầu tiên, Tổng hợp mã, liên quan đến mô hình trong việc tổng hợp mã chức năng được cung cấp một hàm với docstring chi tiết hành vi mã mong muốn. Nhiệm vụ thứ hai, Sửa chữa mã, thử thách mô hình xác định và sửa một lỗi tinh vi trong một hàm mã đúng, sử dụng các bài kiểm tra đơn vị được cung cấp làm hướng dẫn. Nhiệm vụ thứ ba và cuối cùng, Giải thích mã, yêu cầu mô hình tạo ra một lời giải thích rõ ràng và ngắn gọn cho một hàm mã được viết đúng. Đối với đánh giá trên HumanEvalPack, chúng tôi sử dụng các phần Python và Java của nó và tính toán Pass@1 cho mỗi nhiệm vụ. Chúng tôi sử dụng nhiệt độ 0.2 và lấy mẫu 20 đầu ra cho mỗi ví dụ thử nghiệm.

Tính bền vững của mô hình Đánh giá tính bền vững của các mô hình tạo mã là rất quan trọng trong việc hiểu khả năng ứng dụng và độ tin cậy trong thế giới thực của chúng. Các mô hình có thể duy trì mức hiệu suất cao bất chấp các biến thể và nhiễu loạn trong dữ liệu đầu vào có nhiều khả năng hiệu quả trong môi trường mã hóa đa dạng và động (Bielik và Vechev, 2020; Henkel et al., 2022; Wang et al., 2023a). Được thúc đẩy bởi các hành vi mô hình như vậy, chúng tôi sử dụng ReCode (Wang et al., 2023a), một framework benchmark được thiết kế để đánh giá tính bền vững của Code LLM. Chúng tôi sử dụng HumanEval (Chen et al., 2021) làm bộ dữ liệu cơ sở và sắp xếp nó để mô phỏng các biến thể tự nhiên trong khi bảo tồn tính toàn vẹn ngữ nghĩa của các đầu vào gốc. Các nhiễu loạn bao gồm một loạt các biến đổi (Zhuo et al., 2023c) trên định dạng mã, hàm, tên biến, cú pháp mã và docstring. Những biến đổi này không phải là tùy ý mà đại diện cho những thay đổi xảy ra tự nhiên trong thực tiễn mã hóa. Chất lượng của dữ liệu bị nhiễu loạn trong ReCode được xác minh thông qua đánh giá con người và điểm tương đồng khách quan, đảm bảo tính liên quan và độ tin cậy của bộ dữ liệu để đánh giá tính bền vững. Chúng tôi sử dụng nhiệt độ 0.2 và 20 mẫu cho mỗi ví dụ thử nghiệm để tạo ra. Để tính toán mức độ bền vững của mô hình, chúng tôi áp dụng Robust Pass@k (RP@k) từ ReCode và cũng tính toán Robust Change@k (RC@k) như sau:
RP@k := Ex["1−n−rcs(x)n k"] (1)
RC@k := |Pass@k−Robust Pass@k| (2)

Bảo mật mã Một hạn chế của Code LLM là xu hướng tạo ra mã với các lỗ hổng bảo mật tiềm ẩn, như các nghiên cứu khác nhau đã nêu bật (Dakhel et al., 2023; Asare et al., 2023). Trong nghiên cứu của chúng tôi, chúng tôi nhằm mục đích kiểm tra thực nghiệm cách các phương pháp PEFT có thể ảnh hưởng đến các khía cạnh bảo mật của đầu ra Code LLM. Chúng tôi sử dụng benchmark "Asleep at the Keyboard" (AATK) (Pearce et al., 2022), bao gồm 89 kịch bản tập trung vào bảo mật, để cung cấp đánh giá toàn diện trên ba chiều riêng biệt: Tính đa dạng của Điểm yếu (DoW), bao gồm 18 lớp lỗ hổng duy nhất từ phân loại MITRE Common Weakness Enumeration (CWE), có nguồn gốc từ 2021 CWE Top 25 Most Dangerous Software Weaknesses; Tính đa dạng của Prompt (DoP), đánh giá phản ứng với các prompt khác nhau trong lớp lỗ hổng SQL injection; và Tính đa dạng của Lĩnh vực (DoD), liên quan đến các kịch bản trong Verilog, một ngôn ngữ mô tả phần cứng. Phân tích của chúng tôi chủ yếu tập trung vào trục DoW, bao gồm 54 kịch bản–25 trong C và 29 trong Python–bao gồm 18 CWE. Sự tập trung này là do các thách thức đánh giá tự động liên quan đến hai chiều khác. Sau khi lọc ra các kịch bản thiếu bài kiểm tra tự động, chúng tôi kiểm tra kỹ lưỡng 40 kịch bản, bao gồm 23 trong C và 17 trong Python. Chúng tôi sử dụng nhiệt độ 0.2 và 20 mẫu cho mỗi ví dụ thử nghiệm để tạo ra.

3 Nghiên cứu Sơ bộ: Mất mát Entropy Chéo
Mất mát entropy chéo đã được sử dụng làm thước đo hiệu suất chính trong việc huấn luyện LLM cho các nhiệm vụ NLP (Brown et al., 2020; Hernandez et al., 2021; Zhang et al., 2022b). Hầu hết các nghiên cứu về mất mát mô hình hóa tập trung vào việc pre-training (Kaplan et al., 2020) hoặc FFT (Chung et al., 2022). Các nghiên cứu trước đây có những phát hiện nhất quán về mất mát (Kaplan et al., 2020; Hoffmann et al., 2022; Aghajanyan et al., 2023): Mất mát cuối cùng có xu hướng giảm khi tính toán huấn luyện (ví dụ, kích thước mô hình, dữ liệu huấn luyện và thời gian huấn luyện) tăng. Những quan sát này chỉ ra rằng nhiều thời gian huấn luyện và nhiều tham số mô hình có thể huấn luyện được có thể dẫn đến sự liên kết tốt hơn với dữ liệu tinh chỉnh. Tuy nhiên, không có nghiên cứu hệ thống nào cho PEFT, đặc biệt là cho Code LLM. Dựa trên các tham số được cập nhật cho mỗi phương pháp tinh chỉnh trong Bảng 1, chúng tôi giả thuyết rằng mỗi phương pháp PEFT có một xu hướng tương tự như các phát hiện trước đây về mất mát. Lấy cảm hứng từ Kaplan et al. (2020), chúng tôi nghiên cứu sự thay đổi mất mát cho Code LLM tinh chỉnh hướng dẫn, thay đổi hai yếu tố: (1) Kích thước mô hình (1B - 16B); và (2) Thời gian huấn luyện (được đo bằng bước global, tối đa 200 bước). Do ngân sách hạn chế, chúng tôi không nghiên cứu cách lượng dữ liệu huấn luyện có thể ảnh hưởng đến mất mát.

Mở rộng kích thước mô hình Chúng tôi trình bày kết quả mất mát cuối cùng trong Hình 3 khi thay đổi kích thước mô hình từ 1B đến 16B. Quan sát đầu tiên của chúng tôi là mất mát train và test được liên kết tốt, chỉ ra rằng các mô hình được huấn luyện trên các phương pháp tinh chỉnh được chọn không bị overfit. Quan sát thứ hai là cả mất mát train và test cũng giảm nghiêm ngặt khi kích thước mô hình tăng. Mặc dù những quan sát này phù hợp với các quan sát đã nêu trước đây (Kaplan et al., 2020; Hoffmann et al., 2022), chúng cho thấy các quy mô khác nhau của thay đổi mất mát, gợi ý rằng các phương pháp tinh chỉnh khác nhau có thể yêu cầu các mức độ sức mạnh khác nhau. So với các phương pháp tinh chỉnh khác, FFT thể hiện hiệu suất mất mát tốt hơn một chút so với các phương pháp PEFT như LoRA và Parallel Adapter. Vì chúng tôi nhận thấy rằng các phương pháp PEFT nặng hơn (cập nhật nhiều tham số hơn) có xu hướng có mất mát cuối cùng tốt hơn, chúng tôi giả thuyết rằng nhiều tham số có thể huấn luyện được trong mô hình có thể dẫn đến mất mát nhỏ hơn, bất kể cách các tham số được cập nhật trong quá trình huấn luyện.

Mở rộng thời gian huấn luyện Chúng tôi hiển thị các thay đổi trong mất mát test trên ASTRAIOS khi thay đổi thời gian huấn luyện trong Hình 4. Chúng tôi nhận thấy rằng mất mát tiếp tục giảm khi mô hình được huấn luyện lâu hơn. Mặc dù các thay đổi mất mát của (IA)3 liên tục không đáng kể. Đáng chú ý, mất mát của P-Tuning giảm mạnh đến 50 bước nhưng hành xử tương tự như các phương pháp dựa trên prompt khác. Về tính ổn định tinh chỉnh, chúng tôi quan sát thấy rằng P-tuning kém ổn định hơn các phương pháp khác, nơi thay đổi mất mát dường như là một mô hình không đơn điệu. Khi so sánh FFT với các phương pháp PEFT, chúng tôi thấy rằng FFT có xu hướng giảm ngay cả sau 200 bước, trong khi các phương pháp PEFT không cho thấy xu hướng giảm rõ ràng. Chúng tôi giả thuyết rằng điều này có thể là do số lượng tham số được cập nhật, nơi FFT cập nhật toàn bộ tham số trong mô hình.

4 Kết quả Chính: Hiệu suất Nhiệm vụ
Vì mất mát entropy chéo chỉ cho thấy Code LLM có thể được liên kết tốt với dữ liệu huấn luyện như thế nào, nó phụ thuộc rất nhiều vào nội dung huấn luyện cụ thể và có thể không phục vụ như một proxy đáng tin cậy của hiệu suất trên các nhiệm vụ khác nhau của mã nguồn. Do đó, chúng tôi tìm cách kiểm tra mức độ tốt của các phương pháp PEFT có chọn lọc góp phần vào hiệu suất nhiệm vụ trong phần này. Để benchmark hiệu suất, chúng tôi tận dụng các nhiệm vụ downstream mã đại diện: (1) Phát hiện lỗi, (2) Sao chép mã, (3) Tổng hợp mã, (4) Sửa chữa mã và (5) Giải thích mã. Đối với hai nhiệm vụ hiểu mã đầu tiên, không có nghiên cứu nào hiện tại tuyên bố rằng Code LLM lớn hơn dẫn đến hiểu biết tốt hơn về mã. Chúng tôi là những người đầu tiên nghiên cứu khía cạnh này khi thay đổi kích thước mô hình. Về ba nhiệm vụ tạo mã sau, các nghiên cứu power-law trước đây (Kaplan et al., 2020; Hoffmann et al., 2022) đã chỉ ra rằng tăng kích thước mô hình cũng có thể dẫn đến hiệu suất nhiệm vụ tốt hơn trên các nhiệm vụ tạo. Chúng tôi xác nhận thêm phát hiện này trên cài đặt PEFT.

Hiểu mã Bảng 2 hiển thị kết quả của hai nhiệm vụ hiểu mã khi thay đổi kích thước mô hình. Đáng ngạc nhiên, như được hiển thị trong Hình 5 và 6, kết quả của cả hai nhiệm vụ không phù hợp tốt với các mô hình mà chúng tôi quan sát trên các nhiệm vụ tạo mã. Tất cả các phương pháp tinh chỉnh đều hoạt động nhất quán như mở rộng ngược, đã được thảo luận trong McKenzie et al. (2023). Chúng tôi giả thuyết rằng Code LLM đã không thấy đủ dữ liệu huấn luyện cụ thể cho nhiệm vụ và không thể tổng quát hóa cho những nhiệm vụ chưa gặp đó (Yadlowsky et al., 2023). Vì các mô hình ASTRAIOS được pre-trained trên mã nguồn khác nhau từ các repository GitHub cho dự đoán token tiếp theo và fine-tuned trên các commit GitHub cho việc tinh chỉnh mã, chúng có thể không có hiểu biết sâu sắc về lỗi và mã bị sao chép.

Tạo mã Bảng 3 thể hiện hiệu suất trên ba nhiệm vụ tạo mã khác nhau trên các phần Python và Java trong HumanEvalPack. Trên sáu benchmark, chúng tôi đầu tiên quan sát thấy FFT dẫn đến các kết quả tăng nhất quán khi tham số mô hình tăng. Khi kiểm tra các phương pháp PEFT, chúng tôi thấy chúng cũng có thể cung cấp khả năng mở rộng hiệu suất hợp lý tương tự như FFT. Do đó, mất mát test thấp hơn có thể dẫn đến hiệu suất tốt hơn trên các nhiệm vụ tạo downstream khác nhau cho Code LLM. Tuy nhiên, chúng tôi nhận thấy rằng lợi ích của kích thước mô hình cơ sở cũng có thể khác nhau tùy thuộc vào nhiệm vụ và ngôn ngữ. Ví dụ, các mô hình 1B và 3B thường hoạt động kém hơn trong sửa chữa mã so với tổng hợp mã. Khi tham số mô hình mở rộng đến 7B và 16B, hiệu suất của chúng trên các nhiệm vụ này trở nên tương đương hơn.

Hiệu suất tổng thể Để so sánh hiệu suất nhiệm vụ tổng thể của các phương pháp tinh chỉnh khác nhau, chúng tôi tính toán điểm tích lũy trung bình cho mỗi phương pháp tinh chỉnh trên mỗi kích thước mô hình. Chúng tôi trình bày các xếp hạng trong Hình 1. Chúng tôi cho thấy rằng FFT vẫn là tốt nhất về hiệu suất nhiệm vụ tổng thể, trong khi LoRA và Parallel Adapter có thể so sánh với FFT. Tuy nhiên, vẫn còn một khoảng cách hiệu suất lớn giữa hầu hết các phương pháp PEFT và FFT, gợi ý rằng chúng không thể đảm bảo hiệu suất tối ưu. Về hiệu quả tinh chỉnh, chúng tôi sử dụng các tham số được cập nhật làm thước đo để tóm tắt hai phát hiện nữa. Thứ nhất, (IA)3 đủ hiệu quả để thực hiện hợp lý bằng cách cập nhật ít tham số hơn nhiều so với các phương pháp PEFT khác. Thứ hai, chúng tôi nhận thấy rằng AdapterP luôn hoạt động tốt hơn AdapterH, mặc dù AdapterH cập nhật nhiều tham số mô hình hơn. Quan sát phản trực giác chỉ ra rằng AdapterH có thể không đáng để triển khai trong thực tiễn thế giới thực.

5 Phân tích Thêm
Trong phần này, chúng tôi nghiên cứu thêm hai khía cạnh của Code LLM ngoài hiệu suất nhiệm vụ. Cụ thể, chúng tôi nhấn mạnh tầm quan trọng của tính bền vững của mô hình và bảo mật mã được tạo ra, điều này chỉ ra tính thực tiễn trong thế giới thực. Chúng tôi có xu hướng hiểu xu hướng hành vi mô hình trên các phương pháp tinh chỉnh và kích thước mô hình.

5.1 Tính bền vững của mô hình
Mặc dù hiệu suất trên các nhiệm vụ downstream là cần thiết, chúng tôi cho rằng việc đánh giá tính bền vững của mô hình cũng cần thiết để đặc trưng các phương pháp tinh chỉnh khác nhau một cách hệ thống. Do đó, chúng tôi xem xét việc benchmark tính bền vững của tổng hợp mã, một trong những nhiệm vụ downstream đại diện nhất của mã nguồn.

Bảng 4 báo cáo RP@1 và RC@1 trường hợp xấu nhất của mỗi phương pháp tinh chỉnh của mỗi danh mục nhiễu loạn. Trong số bốn loại nhiễu loạn, tất cả các mô hình hoạt động tệ nhất trên biến đổi cú pháp, xác nhận các phát hiện trong Wang et al. (2023a). Hơn nữa, RP@1 mỗi phương pháp tinh chỉnh tăng khi kích thước mô hình được mở rộng, chỉ ra khả năng tạo được cải thiện liên tục. Chúng tôi nhận thấy rằng FFT có thể không hoạt động tốt hơn các phương pháp PEFT khác trên các mô hình nhỏ hơn, chẳng hạn như 1B và 3B. Tuy nhiên, nó dẫn đến RP@1 tốt nhất trên các mô hình lớn hơn như 16B. Bằng cách so sánh các kích thước mô hình khác nhau, chúng tôi quan sát thấy rằng RC@1 liên tục tăng khi mô hình trở nên lớn hơn, chỉ ra rằng các mô hình lớn hơn sẽ kém bền vững hơn.

Để xếp hạng giữa các phương pháp tinh chỉnh thông qua góc nhìn tính bền vững, chúng tôi tính toán RC@1 trung bình tương tự như Phần 4 và minh họa trong Hình 7. Chúng tôi quan sát thấy rằng FFT và LoRA không cho thấy tính bền vững mạnh mẽ. Thay vào đó, tinh chỉnh dựa trên adapter dường như bền vững hơn trong khi có hiệu suất tương đương với FFT, tương tự như những gì Han et al. (2021) đã tìm thấy trong các nhiệm vụ NLP.

5.2 Bảo mật mã
Các nghiên cứu trước đây (Dakhel et al., 2023; Asare et al., 2023) đã chỉ ra rằng Code LLM có thể tạo ra mã với các lỗ hổng bảo mật, có thể được khai thác bởi người dùng độc hại. Tuy nhiên, ít nghiên cứu đã nghiên cứu các phương pháp tinh chỉnh khác nhau từ góc độ bảo mật đầu ra. Trong thử nghiệm này, chúng tôi dự định hiểu cách các phương pháp tinh chỉnh ảnh hưởng đến khả năng tạo mã an toàn trên benchmark AATK.

Chúng tôi tuân theo cài đặt ban đầu trong Pearce et al. (2022) và tính toán tỷ lệ hợp lệ và không an toàn, được minh họa trong Bảng 5. Khi so sánh tỷ lệ hợp lệ của các phương pháp PEFT, nó không cho thấy hiệu suất tốt hơn khi kích thước mô hình tăng, chỉ ra rằng các mô hình hiện tại có thể không học được tính hợp lệ của chương trình một cách nội tại. Tuy nhiên, chúng tôi quan sát thấy rằng các thay đổi trong tỷ lệ không an toàn cho thấy các mô hình lớn hơn có nhiều khả năng tạo ra mã không an toàn. Quan sát này gợi ý rằng sự phát triển của khả năng học tập có thể dẫn đến việc học nhiều dữ liệu hơn, bao gồm cả các chương trình không an toàn. Nghiên cứu về tỷ lệ không an toàn giữa các phương pháp tinh chỉnh tiếp tục cho thấy rằng FFT và LoRA vẫn tốt hơn các phương pháp tinh chỉnh khác về mức độ bảo mật. Trong khi các phương pháp khác có tỷ lệ không an toàn tương tự, P-Tuning có thể có nhiều cơ hội hơn để tạo ra các chương trình kém an toàn hơn, có thể không phù hợp để triển khai trong các kịch bản nhạy cảm về bảo mật.

6 Thảo luận
Trong phần này, chúng tôi tìm cách tiến hành phân tích sơ bộ về hiệu suất của Code LLM thông qua góc nhìn của các tham số được cập nhật. Cụ thể, chúng tôi đặt hai câu hỏi: (1) Mối quan hệ giữa các tham số được cập nhật và mất mát entropy chéo là gì?; và (2) Chúng ta có thể sử dụng hiệu suất của mất mát để dự đoán hiệu suất nhiệm vụ của Code LLM không?.

Mất mát của các mô hình nhỏ có thể được chiếu tới các mô hình lớn hơn. Mối quan hệ giữa các tham số được cập nhật của các mô hình ASTRAIOS và mất mát cuối cùng của chúng được phân tích trong Hình 8. Phân tích của chúng tôi không tiết lộ một mô hình nhất quán trên các kích thước mô hình khác nhau khi nói đến mối tương quan giữa mất mát mô hình và các tham số được cập nhật. Tuy nhiên, một phát hiện thú vị là sự nhất quán trong hiệu suất mất mát tương đối trên các kích thước mô hình khác nhau khi so sánh các phương pháp tinh chỉnh khác nhau. Sự nhất quán này gợi ý rằng các cải tiến được đạt được bởi mỗi phương pháp tinh chỉnh có khả năng tương tự bất kể kích thước của mô hình. Do đó, mất mát quan sát được trong các mô hình nhỏ hơn, khi được tinh chỉnh với các phương pháp khác nhau, có thể là một dự báo hữu ích cho hiệu suất của các mô hình lớn hơn.

Mất mát tinh chỉnh hướng dẫn là một dự báo mạnh mẽ của hiệu suất downstream. Giả sử rằng mô hình đã được tinh chỉnh hướng dẫn nhưng chưa hoàn thành để đánh giá, chúng tôi tìm cách hiểu liệu chúng ta có thể sử dụng mất mát như vậy để dự đoán hiệu suất của nó trên các nhiệm vụ downstream. Mặc dù dữ liệu hướng dẫn của chúng tôi được lấy từ các nguồn chung như commit GitHub và các lĩnh vực NLP rộng, không được liên kết trực tiếp với các nhiệm vụ downstream được thảo luận trong Phần 4, chúng tôi tìm thấy một số mối tương quan mạnh mẽ.

Được thúc đẩy bởi kịch bản đã nêu, chúng tôi tổng hợp tất cả các điểm dữ liệu của hiệu suất nhiệm vụ trung bình và mất mát cuối cùng tương ứng của chúng trong Hình 9. Chúng tôi quan sát thấy rằng các mô hình với mất mát thấp hơn nhìn chung có hiệu suất tốt hơn trên các nhiệm vụ downstream. Cụ thể, mô hình mạnh hơn trên mất mát test hơn trên mất mát train. Chúng tôi giải thích bằng thực tế rằng các mô hình không học để phù hợp với phần test và có thể trình bày xác định chính xác hơn về hiệu suất thực tế của chúng. Quan sát của chúng tôi gợi ý rằng dữ liệu hướng dẫn chung có thể hoạt động như một proxy tốt của các nhiệm vụ downstream trong Code LLM, tương tự như các phát hiện trước đây trong NLP (Anil et al., 2023; Wei et al., 2023).

7 Nghiên cứu Liên quan
Các mô hình ngôn ngữ lớn mã Nhiều Code LLM cơ sở đã được đề xuất gần đây (Chen et al., 2021; Nijkamp et al., 2022; Fried et al., 2022; Allal et al., 2023; Zheng et al., 2023; Li et al., 2023; Roziere et al., 2023) chủ yếu nhắm mục tiêu hoàn thành mã. Với sự giúp đỡ của các Code LLM cơ sở này, đã có các nghiên cứu rộng rãi về tinh chỉnh Code LLM cụ thể cho nhiệm vụ để thực hiện các nhiệm vụ kỹ thuật phần mềm như sửa chữa chương trình tự động (Xia và Zhang, 2023; Xia et al., 2023a), dịch mã (Pan et al., 2023) và tóm tắt mã (Wang et al., 2023b, 2022a). Sau đó, một loạt các công trình đã được đề xuất để tinh chỉnh hướng dẫn các Code LLM cơ sở (Luo et al., 2023; Shen et al., 2023; Muennighoff et al., 2023a; Bai et al., 2023), nhằm mục đích tăng cường khả năng tổng quát hóa của những mô hình này trên các nhiệm vụ đa dạng. Vì tinh chỉnh Code LLM với các tham số đầy đủ là tốn kém, hầu hết các mô hình đã được tinh chỉnh với LoRA (Hu et al., 2021), một phương pháp tinh chỉnh tiết kiệm tham số. Trong nghiên cứu này, chúng tôi tìm cách trả lời LoRA tốt như thế nào và liệu có các phương pháp tinh chỉnh khác tương đương không.

Phân tích mô hình trên các quy mô Hiểu tại sao và cách các mô hình thần kinh hoạt động là rất quan trọng để phát triển những mô hình tiên tiến hơn. Các nghiên cứu hiện tại đã điều tra các mô hình có thể dự đoán trong hành vi của các mô hình ngôn ngữ đã được huấn luyện trên các quy mô (Kaplan et al., 2020; Henighan et al., 2020; Hernandez et al., 2021; Hoffmann et al., 2022; Wei et al., 2022; Muennighoff et al., 2023b; Xia et al., 2023b) và động lực học tập của chúng (McGrath et al., 2022; Tirumala et al., 2022; Biderman et al., 2023). Tuy nhiên, chúng tập trung vào pre-training hoặc tinh chỉnh đầy đủ tham số theo nhiệm vụ cụ thể. Không có nỗ lực nào để hiểu cơ chế của tinh chỉnh hướng dẫn tiết kiệm tham số. Trong bài báo này, chúng tôi làm việc trên góc nhìn này và phân tích Code LLM (Wan et al., 2022; Troshin và Chirkova, 2022; Zhuo et al., 2023a).

8 Kết luận
Nghiên cứu này nghiên cứu tinh chỉnh hướng dẫn tiết kiệm tham số của Code LLM. Chúng tôi giới thiệu một bộ mô hình bao gồm 28 OctoCoder được tinh chỉnh hướng dẫn trên các quy mô và phương pháp PEFT. Chúng tôi đặc trưng các phương pháp tinh chỉnh trên các nhiệm vụ downstream đại diện, tính bền vững của mô hình và bảo mật đầu ra, nhấn mạnh tầm quan trọng của việc hiểu các mô hình này qua đánh giá toàn diện. Chúng tôi cũng thảo luận về mối quan hệ giữa các tham số được cập nhật, mất mát entropy chéo và hiệu suất nhiệm vụ. Chúng tôi hy vọng những phân tích này sẽ truyền cảm hứng cho các nghiên cứu tiếp theo về việc hiểu cơ chế của các phương pháp tinh chỉnh và phát triển các cách tiếp cận mới.

Lời cảm ơn
Chúng tôi cảm ơn Đại học Monash và Hugging Face vì đã cung cấp các instance tính toán. Chúng tôi vô cùng biết ơn Cristian Rojas vì sự giúp đỡ trong việc khám phá ban đầu, Zhensu Sun vì cuộc thảo luận, Dmitry Abulkhanov vì đánh giá bài báo, Brendan Dolan-Gavitt vì cung cấp script đánh giá của benchmark "Asleep At The Keyboard", cộng đồng BigCode vì cung cấp các mô hình cơ sở (Li et al., 2023) và dữ liệu tinh chỉnh hướng dẫn (Muennighoff et al., 2023a) từ các commit GitHub, và Mangrulkar et al. (2022); Hu et al. (2023) vì triển khai các phương pháp PEFT.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo dài được bỏ qua để tiết kiệm không gian]

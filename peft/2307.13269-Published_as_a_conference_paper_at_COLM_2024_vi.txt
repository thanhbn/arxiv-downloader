Không giống như những công việc này, công việc của chúng tôi tập trung vào việc kết hợp các mô hình để tổng quát hóa liên-tác vụ tốt hơn.

Danh mục thứ hai gần gũi nhất với nghiên cứu của chúng tôi, xuất phát từ động lực chung về kết hợp mô-đun. Nhiều học giả đã có những tiến bộ trong hướng nghiên cứu này: Kingetsu et al. (2021) phân tách và tái tạo các mô-đun dựa trên chức năng của chúng; Ilharco et al. (2023) đề xuất điều chỉnh hành vi mô hình bằng các vector tác vụ; Lv et al. (2023) amalgamate các mô-đun hiệu quả tham số được trọng số theo độ tương tự tác vụ; Zhang et al. (2023a) tạo ra các mô-đun bằng cách sử dụng các phép toán số học cụ thể; Sun et al. (2023) cải thiện hiệu suất few-shot của các tác vụ chưa thấy bằng huấn luyện trước đa tác vụ của prompt; Chronopoulou et al. (2023) tính trung bình trọng số adapter nhằm chuyển giao; Ponti et al. (2023) tập trung vào việc học chung các adapter và một hàm định tuyến phân bổ kỹ năng cho mỗi tác vụ; và Muqeeth et al. (2023) tập trung vào việc amalgamate các chuyên gia trong các mô hình mixture of experts; Tuy nhiên, những phương pháp này thường cần huấn luyện đa tác vụ hoặc kiến thức trước của con người về lựa chọn mô-đun cho tác vụ downstream. Ngược lại, phương pháp của chúng tôi không áp đặt bất kỳ yêu cầu huấn luyện đặc biệt nào và chỉ đơn giản sử dụng điều chỉnh LoRA vanilla. Ngoài ra, việc lựa chọn mô-đun cho các tác vụ downstream hoàn toàn dựa trên dữ liệu mà không có kiến thức trước của con người. Thiết kế này mang lại lợi thế dễ dàng thêm các mô-đun LoRA mới để tái sử dụng, cho phép phương pháp của chúng tôi mở rộng linh hoạt số lượng ứng viên mô-đun LoRA trong tương lai.

Mixture of Experts Mixture of Experts (MoE) là một phương pháp ensemble, thường được hình dung như một tập hợp các mô-đun phụ, hoặc "chuyên gia", mỗi cái chuyên môn trong việc xử lý các loại dữ liệu đầu vào khác nhau. Mỗi chuyên gia trong hệ thống này được điều khiển bởi một mạng gating độc đáo, được kích hoạt dựa trên bản chất riêng biệt của dữ liệu đầu vào. Đối với mỗi token trong các chuỗi đầu vào này, mạng này xác định và kích hoạt những chuyên gia phù hợp nhất để xử lý dữ liệu. Kết quả là, hiệu suất vượt trội so với việc dựa vào một mô hình chung duy nhất cho tất cả các loại đầu vào. Kỹ thuật này đã chứng minh vai trò quan trọng trong nhiều miền, chẳng hạn như xử lý ngôn ngữ tự nhiên và thị giác máy tính (Jacobs et al., 1991; Shazeer et al., 2017; Du et al., 2022; Zhang et al., 2022; Wang et al., 2022; crumb, 2023). Phương pháp của chúng tôi thể hiện sự tương tự với MoE, trong đó các mô-đun LoRA được huấn luyện thượng nguồn có thể được căn chỉnh với thiết kế chuyên gia của MoE. Một yếu tố phân biệt đáng chú ý là cơ chế tiếp cận của chúng tôi không yêu cầu bất kỳ thao tác chuyên biệt nào của LoRA trong quá trình huấn luyện trong khi tạo điều kiện lắp ráp mô-đun LoRA động ở bất kỳ quy mô nào, mỗi cái được tinh chỉnh trước cho các tác vụ khác nhau. Ngược lại, MoE yêu cầu số lượng chuyên gia được xác định trước trong cả giai đoạn huấn luyện và kiểm tra. Các nghiên cứu gần đây về mối quan hệ giữa MoE và instruction tuning đã chứng minh rằng việc áp dụng đồng thời cả hai cách tiếp cận làm tăng hiệu quả của mỗi cách riêng lẻ (Shen et al., 2023).

Tổng quát hóa Liên-tác vụ Những tiến bộ gần đây như CrossFit (Ye et al., 2021), ExT5 (Aribandi et al., 2022), FLAN (Wei et al., 2022), T0 (Sanh et al., 2022), InstructGPT (Ouyang et al., 2022), và ReCross (Lin et al., 2022) đã nỗ lực nuôi dưỡng khả năng tổng quát hóa của một mô hình đa tác vụ rộng lớn trên các tác vụ khác nhau, rất phù hợp với các mục tiêu của nghiên cứu của chúng tôi. Trong nhóm này, các kết nối của CrossFit và ReCross với LoraHub đặc biệt đáng chú ý. Khung CrossFit (Ye et al., 2021) yêu cầu số lượng tối thiểu các ví dụ được gán nhãn của tác vụ mục tiêu cho tinh chỉnh few-shot. Tuy nhiên, hạn chế của nó nằm ở việc áp dụng tên tác vụ làm tiền tố cứng trong template, gây ra thách thức trong tổng quát hóa tác vụ. Mặt khác, trong khi ReCross giảm thiểu nhu cầu nhãn trong các ví dụ few-shot để lấy thông tin, nó cần một quy trình tinh chỉnh sử dụng dữ liệu đã lấy. Quy trình này có vẻ tốn thời gian khi so với cách tiếp cận của LoraHub. Thông qua việc triển khai các ví dụ được gán nhãn few-shot và một quy trình tối ưu hóa không có gradient, LoraHub tạo điều kiện cho việc cập nhật lặp đi lặp lại các trọng số để kết hợp các mô-đun LoRA. Phương pháp kết quả hiệu quả và tiết kiệm chi phí hơn so với công việc trước đó. Nhìn chung, LoraHub cung cấp một giải pháp thực tế và khả thi hơn cho quy trình tối ưu hóa.

--- TRANG 9 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

7 Kết luận
Trong công việc này, chúng tôi đã giới thiệu LoraHub, một khung chiến lược để kết hợp các mô-đun LoRA được huấn luyện trên các tác vụ đa dạng nhằm đạt được hiệu suất thích ứng trên các tác vụ mới. Cách tiếp cận của chúng tôi cho phép kết hợp linh hoạt nhiều mô-đun LoRA chỉ sử dụng một vài ví dụ từ một tác vụ mới, mà không yêu cầu thêm tham số mô hình hoặc chuyên môn con người. Kết quả thực nghiệm trên benchmark BBH chứng minh rằng LoraHub có thể khớp hiệu quả với hiệu suất của học trong ngữ cảnh trong các tình huống few-shot, loại bỏ nhu cầu các ví dụ trong ngữ cảnh trong quá trình suy luận. Nhìn chung, công việc của chúng tôi cho thấy lời hứa của khả năng kết hợp LoRA chiến lược để nhanh chóng thích ứng LLM với các tác vụ đa dạng. Bằng cách thúc đẩy tái sử dụng và kết hợp các mô-đun LoRA, chúng ta có thể hướng tới các LLM tổng quát và thích ứng hơn trong khi giảm thiểu chi phí huấn luyện.

Tuyên bố Tái tạo
Các tác giả đã nỗ lực rất nhiều để đảm bảo khả năng tái tạo của các kết quả thực nghiệm được báo cáo trong bài báo này. Đầu tiên, các thiết lập thực nghiệm, metrics đánh giá và tập dữ liệu đã được mô tả chi tiết trong Mục 4.1. Thứ hai, các mã và script để tái tạo kết quả sẽ được mã nguồn mở sau khi được chấp nhận. Thứ ba, mã nguồn triển khai phương pháp và thực nghiệm đề xuất sẽ được công khai khi bài báo được chấp nhận. Thứ tư, các mô-đun LoRA được huấn luyện trước từ công việc này cùng với các tệp cấu hình và trọng số sẽ được chia sẻ. Những điều này cho phép tái tạo mà không cần huấn luyện lại các mô-đun LoRA, cho phép kiểm tra và xác minh nhanh chóng.

Tài liệu tham khảo
Samuel Ainsworth, Jonathan Hayase, và Siddhartha Srinivasa. Git re-basin: Merging models modulo permutation symmetries. Trong The Eleventh International Conference on Learning Representations, 2023.

Shengnan An, Yifei Li, Zeqi Lin, Qian Liu, Bei Chen, Qiang Fu, Weizhu Chen, Nanning Zheng, và Jian-Guang Lou. Input-tuning: Adapting unfamiliar inputs to frozen pre-trained models. ArXiv preprint, 2022.

Vamsi Aribandi, Yi Tay, Tal Schuster, Jinfeng Rao, Huaixiu Steven Zheng, Sanket Vaibhav Mehta, Honglei Zhuang, Vinh Q. Tran, Dara Bahri, Jianmo Ni, Jai Prakash Gupta, Kai Hui, Sebastian Ruder, và Donald Metzler. Ext5: Towards extreme multi-task scaling for transfer learning. Trong Proc. of ICLR, 2022.

Stephen Bach, Victor Sanh, Zheng Xin Yong, Albert Webson, Colin Raffel, Nihal V. Nayak, Abheesht Sharma, Taewoon Kim, M Saiful Bari, Thibault Fevry, Zaid Alyafeai, Manan Dey, Andrea Santilli, Zhiqing Sun, Srulik Ben-david, Canwen Xu, Gunjan Chhablani, Han Wang, Jason Fries, Maged Al-shaibani, Shanya Sharma, Urmish Thakker, Khalid Almubarak, Xiangru Tang, Dragomir Radev, Mike Tian-jian Jiang, và Alexander Rush. PromptSource: An integrated development environment and repository for natural language prompts. Trong Proc. of ACL, 2022.

Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. Language models are few-shot learners. Trong Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, và Hsuan-Tien Lin (eds.), Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020.

--- TRANG 10 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

Alexis Chevalier, Alexander Wettig, Anirudh Ajith, và Danqi Chen. Adapting language models to compress contexts. CoRR, abs/2305.14788, 2023. doi: 10.48550/ARXIV.2305.14788. URL https://doi.org/10.48550/arXiv.2305.14788.

Alexandra Chronopoulou, Matthew Peters, Alexander Fraser, và Jesse Dodge. AdapterSoup: Weight averaging to improve generalization of pretrained language models. Trong Findings of the Association for Computational Linguistics: EACL 2023, 2023.

Hyung Won Chung, Le Hou, S. Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Wei Yu, Vincent Zhao, Yanping Huang, Andrew M. Dai, Hongkun Yu, Slav Petrov, Ed Huai hsin Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, và Jason Wei. Scaling instruction-finetuned language models. ArXiv preprint, 2022.

crumb. Llama-2, mixutre of lora. https://crumbly.medium.com/llama-2-molora-f5f909434711, 2023.

Nan Du, Yanping Huang, Andrew M. Dai, Simon Tong, Dmitry Lepikhin, Yuanzhong Xu, Maxim Krikun, Yanqi Zhou, Adams Wei Yu, Orhan Firat, Barret Zoph, Liam Fedus, Maarten P. Bosma, Zongwei Zhou, Tao Wang, Yu Emma Wang, Kellie Webster, Marie Pellat, Kevin Robinson, Kathleen S. Meier-Hellstern, Toju Duke, Lucas Dixon, Kun Zhang, Quoc V. Le, Yonghui Wu, Zhifeng Chen, và Claire Cui. Glam: Efficient scaling of language models with mixture-of-experts. Trong Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvári, Gang Niu, và Sivan Sabato (eds.), International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA, Proceedings of Machine Learning Research, 2022.

Tao Ge, Jing Hu, Xun Wang, Si-Qing Chen, và Furu Wei. In-context autoencoder for context compression in a large language model. CoRR, abs/2307.06945, 2023. doi: 10.48550/ARXIV.2307.06945. URL https://doi.org/10.48550/arXiv.2307.06945.

Aryo Pradipta Gema, Luke Daines, Pasquale Minervini, và Beatrice Alex. Parameter-efficient fine-tuning of llama for the clinical domain. ArXiv preprint, 2023.

Nikolaus Hansen và Andreas Ostermeier. Adapting arbitrary normal mutation distributions in evolution strategies: the covariance matrix adaptation. Proceedings of IEEE International Conference on Evolutionary Computation, 1996.

Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, và Graham Neubig. Towards a unified view of parameter-efficient transfer learning. Trong Proc. of ICLR, 2022.

Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, và Weizhu Chen. Lora: Low-rank adaptation of large language models. Trong Proc. of ICLR, 2022.

Gabriel Ilharco, Marco Tulio Ribeiro, Mitchell Wortsman, Ludwig Schmidt, Hannaneh Hajishirzi, và Ali Farhadi. Editing models with task arithmetic. Trong The Eleventh International Conference on Learning Representations, 2023.

Robert A. Jacobs, Michael I. Jordan, Steven J. Nowlan, và Geoffrey E. Hinton. Adaptive mixtures of local experts. Neural Computation, 1991.

Joel Jang, Seungone Kim, Seonghyeon Ye, Doyoung Kim, Lajanugen Logeswaran, Moontae Lee, Kyungjae Lee, và Minjoon Seo. Exploring the benefits of training expert language models over instruction tuning. Trong International Conference on Machine Learning, 2023. URL https://api.semanticscholar.org/CorpusID:256627673.

Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang, và Lili Qiu. Llmlingua: Compressing prompts for accelerated inference of large language models. Trong Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, December 2023a. URL https://arxiv.org/abs/2310.05736.

--- TRANG 11 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

Huiqiang Jiang, Qianhui Wu, Xufang Luo, Dongsheng Li, Chin-Yew Lin, Yuqing Yang, và Lili Qiu. Longllmlingua: Accelerating and enhancing llms in long context scenarios via prompt compression. CoRR, abs/2310.06839, 2023b. doi: 10.48550/ARXIV.2310.06839. URL https://doi.org/10.48550/arXiv.2310.06839.

Xisen Jin, Xiang Ren, Daniel Preotiuc-Pietro, và Pengxiang Cheng. Dataless knowledge fusion by merging weights of language models. Trong The Eleventh International Conference on Learning Representations, 2023.

Hiroaki Kingetsu, Kenichi Kobayashi, và Taiji Suzuki. Neural network module decomposition and recomposition. ArXiv preprint, 2021.

Brian Lester, Rami Al-Rfou, và Noah Constant. The power of scale for parameter-efficient prompt tuning. Trong Proc. of EMNLP, 2021.

Yucheng Li, Bo Dong, Chenghua Lin, và Frank Guerin. Compressing context to enhance inference efficiency of large language models. Trong Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, December 2023. URL https://arxiv.org/abs/2310.06201.

Bill Yuchen Lin, Kangmin Tan, Chris Miller, Beiwen Tian, và Xiang Ren. Unsupervised cross-task generalization via retrieval augmentation. Trong NeurIPS, 2022.

Haokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal, và Colin Raffel. Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning. ArXiv, abs/2205.05638, 2022. URL https://api.semanticscholar.org/CorpusID:248693283.

Jialin Liu, A. Moreau, Mike Preuss, Baptiste Rozière, Jérémy Rapin, Fabien Teytaud, và Olivier Teytaud. Versatile black-box optimization. Proceedings of the 2020 Genetic and Evolutionary Computation Conference, 2020.

Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V. Le, Barret Zoph, Jason Wei, và Adam Roberts. The flan collection: Designing data and methods for effective instruction tuning, 2023.

Xingtai Lv, Ning Ding, Yujia Qin, Zhiyuan Liu, và Maosong Sun. Parameter-efficient weight ensembling facilitates task-level knowledge transfer. Trong Annual Meeting of the Association for Computational Linguistics, 2023.

Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, và Sayak Paul. Peft: State-of-the-art parameter-efficient fine-tuning methods. https://github.com/huggingface/peft, 2022.

Michael Matena và Colin Raffel. Merging models with fisher-weighted averaging. ArXiv preprint, 2021.

Sewon Min, Mike Lewis, Luke Zettlemoyer, và Hannaneh Hajishirzi. MetaICL: Learning to learn in context. Trong Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2022.

Swaroop Mishra, Daniel Khashabi, Chitta Baral, và Hannaneh Hajishirzi. Cross-task generalization via natural language crowdsourcing instructions. Trong Proc. of ACL, 2022.

Mohammed Muqeeth, Haokun Liu, và Colin Raffel. Soft merging of experts with adaptive routing. ArXiv preprint, 2023.

OpenAI. ChatGPT. 2022. URL https://openai.com/blog/chatgpt.

Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke E. Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Francis Christiano, Jan Leike, và Ryan J. Lowe. Training language models to follow instructions with human feedback. ArXiv preprint, 2022.

--- TRANG 12 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

Panupong Pasupat và Percy Liang. Compositional semantic parsing on semi-structured tables. Trong Proc. of ACL, 2015.

Edoardo Maria Ponti, Alessandro Sordoni, Yoshua Bengio, và Siva Reddy. Combining parameter-efficient modules for task-level generalisation. Trong Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, 2023.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, và Peter J. Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 2020.

J. Rapin và O. Teytaud. Nevergrad - A gradient-free optimization platform. https://GitHub.com/FacebookResearch/Nevergrad, 2018.

Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal V. Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Févry, Jason Alan Fries, Ryan Teehan, Teven Le Scao, Stella Biderman, Leo Gao, Thomas Wolf, và Alexander M. Rush. Multitask prompted training enables zero-shot task generalization. Trong Proc. of ICLR, 2022.

Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc V. Le, Geoffrey E. Hinton, và Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. Trong Proc. of ICLR, 2017.

Sheng Shen, Le Hou, Yanqi Zhou, Nan Du, Shayne Longpre, Jason Wei, Hyung Won Chung, Barret Zoph, William Fedus, Xinyun Chen, Tu Vu, Yuexin Wu, Wuyang Chen, Albert Webson, Yunxuan Li, Vincent Zhao, Hongkun Yu, Kurt Keutzer, Trevor Darrell, và Denny Zhou. Mixture-of-experts meets instruction tuning: a winning combination for large language models, 2023.

George Stoica, Daniel Bolya, Jakob Bjorner, Taylor Hearn, và Judy Hoffman. Zipit! merging models from different tasks without training. arXiv, 2023.

Tianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing Huang, và Xipeng Qiu. Black-box tuning for language-model-as-a-service. Trong Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvári, Gang Niu, và Sivan Sabato (eds.), International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA, Proceedings of Machine Learning Research, 2022.

Tianxiang Sun, Zhengfu He, Qin Zhu, Xipeng Qiu, và Xuanjing Huang. Multitask pretraining of modular prompt for Chinese few-shot learning. Trong Proc. of ACL, 2023.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, và Guillaume Lample. Llama: Open and efficient foundation language models. ArXiv preprint, 2023.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, và Illia Polosukhin. Attention is all you need. Trong Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, và Roman Garnett (eds.), Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, 2017.

Yaqing Wang, Sahaj Agarwal, Subhabrata Mukherjee, Xiaodong Liu, Jing Gao, Ahmed Hassan Awadallah, và Jianfeng Gao. AdaMix: Mixture-of-adaptations for parameter-efficient model tuning. Trong Proc. of EMNLP, 2022.

--- TRANG 13 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, và Quoc V. Le. Finetuned language models are zero-shot learners. Trong Proc. of ICLR, 2022.

Chengyue Wu, Teng Wang, Yixiao Ge, Zeyu Lu, Ruisong Zhou, Ying Shan, và Ping Luo. pi-tuning: Transferring multimodal foundation models with optimal multi-task interpolation. Trong Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, và Jonathan Scarlett (eds.), International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA, volume 202 of Proceedings of Machine Learning Research, pp. 37713-37727. PMLR, 2023a. URL https://proceedings.mlr.press/v202/wu23t.html.

Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David S. Rosenberg, và Gideon Mann. Bloomberggpt: A large language model for finance. CoRR, abs/2303.17564, 2023b. doi: 10.48550/arXiv.2303.17564. URL https://doi.org/10.48550/arXiv.2303.17564.

Prateek Yadav, Derek Tam, Leshem Choshen, Colin Raffel, và Mohit Bansal. TIESmerging: Resolving interference when merging models. Trong Thirty-seventh Conference on Neural Information Processing Systems, 2023. URL https://openreview.net/forum?id=xtaX3WyCj1.

Qinyuan Ye, Bill Yuchen Lin, và Xiang Ren. CrossFit: A few-shot learning challenge for cross-task generalization in NLP. Trong Proc. of EMNLP, 2021.

Chris Zhang, Mengye Ren, và Raquel Urtasun. Graph hypernetworks for neural architecture search. Trong Proc. of ICLR, 2019.

Fan Zhang, Duyu Tang, Yong Dai, Cong Zhou, Shuangzhi Wu, và Shuming Shi. Skillnetnlu: A sparsely activated model for general-purpose natural language understanding, 2022.

Jinghan Zhang, Shiqi Chen, Junteng Liu, và Junxian He. Composing parameter-efficient modules with arithmetic operations. ArXiv preprint, 2023a.

Longteng Zhang, Lin Zhang, Shaohuai Shi, Xiaowen Chu, và Bo Li. Lora-fa: Memory-efficient low-rank adaptation for large language models fine-tuning. ArXiv, abs/2308.03303, 2023b. URL https://api.semanticscholar.org/CorpusID:260683267.

Wangchunshu Zhou, Yuchen Eleanor Jiang, Ryan Cotterell, và Mrinmaya Sachan. Efficient prompting via dynamic in-context learning. CoRR, abs/2305.11170, 2023. doi: 10.48550/ARXIV.2305.11170. URL https://doi.org/10.48550/arXiv.2305.11170.

--- TRANG 14 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

Bảng 3: Năm mô-đun LoRA có lợi nhất cho các tác vụ BBH và các tác vụ thượng nguồn liên quan, giá trị trọng số trung bình và hiệu suất trung bình trên tất cả các tác vụ BBH.

Xếp hạng Tập dữ liệu: Tác vụ Trọng số Hiệu suất Mô tả Tác vụ
1 WIQA: Last Process 0.72 28.1 Xác định bước cuối cùng của một quy trình đã cho.
2 RACE: Is this the Right Answer 0.68 30.8 Xác định xem câu trả lời đã cho có đúng không.
3 WIQA: First Process 0.63 28.1 Xác định bước đầu tiên của một quy trình đã cho.
4 AdversarialQA: BiDAF 0.61 25.1 Trả lời câu hỏi được tạo bởi một mô hình adversarial-in-the-loop.
5 WebQuestions: What is the Answer 0.58 27.0 Trả lời câu hỏi dựa trên thông tin được trích xuất từ web.

A Thêm Phân tích
Những mô-đun LoRA nào hiệu quả nhất cho các tác vụ BBH?
Chúng tôi đặt giả thuyết rằng việc amalgamate các mô-đun LoRA có thể kết hợp kỹ năng và hiểu biết từ nhiều tác vụ cụ thể. Để đánh giá điều này, chúng tôi kiểm tra mức độ ảnh hưởng của một mô-đun LoRA đơn lẻ trong tất cả các tác vụ từ benchmark BBH. Chúng tôi đo lường tác động của mỗi tác vụ riêng lẻ bằng cách tính toán trọng số tuyệt đối trung bình. Năm mô-đun hàng đầu, được trình bày trong Bảng 3, được phát hiện có ảnh hưởng đáng kể, như được chỉ ra bởi trọng số trung bình tối đa của chúng, điều này cho thấy rằng chúng hiệu quả hơn đáng kể trong chuyển giao liên-tác vụ. Đáng chú ý, một đặc điểm chung trong số năm mô-đun hàng đầu này là sự liên kết của chúng với các tác vụ yêu cầu kỹ năng đọc hiểu và lý luận - các thuộc tính chỉ ra độ phức tạp nhận thức cao hơn. Tuy nhiên, đáng chú ý là không có mô-đun nào thể hiện sự cải thiện nhất quán trên tất cả các tác vụ BBH, như phản ánh trong hiệu suất trung bình của chúng trên tất cả các tác vụ BBH, không cho thấy sự cải thiện đáng kể so với FLAN-T5-large gốc, ngoại trừ Xếp hạng 2. Kết quả nhấn mạnh lợi thế của việc kết hợp các mô-đun đa dạng trong LoraHub.

Phương pháp tối ưu hóa không có gradient hiệu quả như thế nào?
Để đánh giá hiệu quả của phương pháp tối ưu hóa không có gradient trong việc xác định chính xác mô-đun LoRA phù hợp nhất cho một tác vụ downstream đã cho, chúng tôi đã tiến hành một nghiên cứu thực nghiệm sử dụng tập dữ liệu WikiTableQuestions (Pasupat & Liang, 2015) (WTQ). Chúng tôi chiến lược tích hợp một mô-đun LoRA được huấn luyện cụ thể trên tập dữ liệu WTQ vào nhóm các mô-đun LoRA ứng viên, ban đầu xuất phát từ các tác vụ độc quyền với Flan Collection. Tiếp theo, chúng tôi chỉ định WTQ làm tác vụ downstream mục tiêu và tính toán các trọng số phù hợp với các phương pháp được sử dụng trong học LoraHub. Kết quả cuối cùng, mô-đun LoRA cụ thể cho WTQ được trao trọng số cao nhất, minh họa sự thành công của thuật toán trong việc nhận ra nó là có liên quan nhất. Hơn nữa, mô-đun LoRA kết hợp thể hiện sự vượt trội nhẹ so với mô-đun LoRA WTQ. Điều này nhấn mạnh tuyên bố rằng phương pháp tối ưu hóa không có gradient có khả năng chọn thành thạo mô-đun LoRA thượng nguồn tối ưu cho một tác vụ chưa thấy.

B Kết quả của Kết quả Tốt nhất
Như được hiển thị trong Bảng 4, so với các phương pháp huấn luyện hiệu quả tham số dựa trên gradient như LoRA và IA3, cách tiếp cận của chúng tôi thể hiện hiệu suất vượt trội về kết quả tốt nhất trên các lần chạy thực nghiệm. Mặc dù nó thể hiện sự tụt hậu đáng chú ý so với phương pháp tinh chỉnh đầy đủ (FFT), cập nhật tất cả các tham số trong quá trình huấn luyện, quan sát này cho thấy rằng phương pháp đề xuất của chúng tôi có một giới hạn trên hứa hẹn. Chúng tôi dự đoán rằng các nỗ lực nghiên cứu trong tương lai có thể đóng góp vào việc tăng tốc độ tối ưu hóa và nâng cao hơn nữa hiệu quả của cách tiếp cận của chúng tôi.

--- TRANG 15 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

Bảng 4: Kết quả thực nghiệm của một số phương pháp few-shot, bao gồm học trong ngữ cảnh (ICL), tinh chỉnh IA3 (IA3), điều chỉnh LoRA (LoRA), tinh chỉnh đầy đủ (FFT) và học LoraHub của chúng tôi (LoraHub) trên benchmark BBH với FLAN-T5-large làm LLM cơ sở. Chúng tôi ký hiệu các tác vụ thuật toán với chỉ số trên § theo công việc trước đó (Wu et al., 2023b). Lưu ý rằng chúng tôi sử dụng 5 ví dụ cho mỗi tác vụ làm minh chứng cho tất cả các phương pháp. Hiệu suất tốt nhất (best) được báo cáo là giá trị tối đa thu được qua ba lần chạy.

Tác vụ ICL best IA3 best LoRA best FFT best LoraHub best
Boolean Expressions 62.7 58.0 60.7 65.3 60.7
Causal Judgement 59.8 62.1 57.5 60.9 63.2
Date Understanding 21.3 20.7 40.7 67.3 45.3
Disambiguation 69.3 0.0 68.7 70.7 68.0
Dyck Languages 2.0 4.7 25.3 33.3 2.7
Formal Fallacies 59.3 52.0 56.7 56.0 59.3
Geometric Shapes 20.0 15.3 28.7 39.3 18.7
Hyperbaton 72.7 49.3 57.3 82.0 72.7
Logical Deduction§ (năm đối tượng) 39.3 32.7 41.3 43.3 40.0
Logical Deduction§ (bảy đối tượng) 42.0 34.0 42.7 46.0 46.0
Logical Deduction§ (ba đối tượng) 52.7 8.7 56.7 60.7 52.7
Movie Recommendation 56.7 62.0 64.5 70.7 62.0
Multistep Arithmetic 0.7 0.7 0.7 0.0 1.3
Navigate 46.7 47.3 50.7 50.0 51.3
Object Counting 34.7 35.3 42.0 38.0 36.7
Penguins in a Table 43.5 45.7 41.3 37.0 47.8
Reasoning about Colored Objects 41.3 41.3 40.7 38.7 44.7
Ruin Names 20.7 25.3 42.0 66.0 28.7
Salient Translation Error Detection 48.0 37.3 17.3 21.3 42.7
Snarks 55.1 56.4 59.0 69.2 61.5
Sports Understanding 56.7 55.3 58.7 58.7 62.7
Temporal Sequences 26.7 18.7 31.3 48.7 21.3
Tracking Shuffled Objects§ (năm đối tượng) 12.0 12.0 16.0 20.0 16.7
Tracking Shuffled Objects§ (bảy đối tượng) 6.7 6.7 12.0 10.0 15.3
Tracking Shuffled Objects§ (ba đối tượng) 31.3 30.7 32.0 36.0 31.3
Web of Lies 54.0 54.7 55.3 54.0 57.3
Word Sorting 0.7 1.3 5.3 6.0 1.3
Hiệu suất Tốt nhất (Trung bình) 38.4 32.1 40.9 46.2 41.2

--- TRANG 16 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

C Kết quả của các mô hình không có instruction-tuned

Bảng 5: So sánh giữa các hạng khác nhau cho học LoraHub few-shot với backbone T5-large (Raffel et al., 2020) trên benchmark BBH. Lưu ý rằng mô hình T5-large đạt 0.0% trên tất cả các tác vụ trong thiết lập zero-shot ngoại trừ Dyck Languages, nơi nó ghi điểm 0.67%.

Tác vụ↓Hạng→ 4avg 4best 16avg 16best 64avg 64best
Boolean Expressions 52.13 57.33 50.67 58.00 47.47 58.00
Causal Judgement 52.41 55.17 49.66 54.02 50.80 54.02
Date Understanding 0.40 2.00 14.40 29.33 4.53 10.00
Disambiguation 10.00 31.33 26.93 42.00 1.73 4.67
Dyck Languages 0.40 0.67 0.40 0.67 0.40 2.00
Formal Fallacies 48.40 54.00 46.93 51.33 46.93 50.00
Geometric Shapes 0.00 0.00 6.53 32.67 1.47 7.33
Hyperbaton 30.13 50.00 39.07 57.33 32.93 48.00
Logical Deduction§ (năm đối tượng) 5.20 14.67 8.80 19.33 1.33 6.67
Logical Deduction§ (bảy đối tượng) 6.40 17.33 9.33 19.33 3.47 16.00
Logical Deduction§ (ba đối tượng) 14.40 32.00 21.73 34.67 6.93 15.33
Movie Recommendation 7.07 18.67 7.87 22.00 1.20 6.00
Multistep Arithmetic hai 0.00 0.00 0.00 0.00 0.00 0.00
Navigate 49.60 54.67 52.27 56.67 49.87 52.00
Object Counting 7.20 18.00 16.00 21.33 13.73 26.67
Penguins in a Table 6.52 13.04 10.43 17.39 0.43 2.17
Reasoning about Colored Objects 6.27 10.00 5.07 16.67 0.53 2.67
Ruin Names 7.73 13.33 13.20 28.00 5.73 15.33
Salient Translation Error Detection 0.00 0.00 1.73 8.67 0.00 0.00
Snarks 21.28 42.31 49.49 60.26 16.15 38.46
Sports Understanding 46.53 58.67 46.80 58.67 46.53 58.67
Temporal Sequences 3.07 13.33 6.53 26.67 2.40 12.00
Tracking Shuffled Objects§ (năm đối tượng) 5.20 14.00 4.13 9.33 0.13 0.67
Tracking Shuffled Objects§ (bảy đối tượng) 2.67 10.00 2.80 14.00 3.20 8.00
Tracking Shuffled Objects§ (ba đối tượng) 3.73 17.33 16.27 34.67 5.87 26.67
Web of Lies 48.53 54.00 54.00 56.00 54.67 57.33
Word Sorting 0.40 0.67 0.13 0.67 0.00 0.00
Hiệu suất Trung bình mỗi Tác vụ 16.14 24.17 20.78 30.73 14.76 21.43

--- TRANG 17 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

D Kết quả của mô hình lớn hơn

Bảng 6: Kết quả thực nghiệm của học zero-shot (Zero) và học LoraHub few-shot của chúng tôi (LoraHub) trên benchmark BBH với FLAN-T5-xl làm LLM cơ sở. Lưu ý rằng chúng tôi sử dụng 5 ví dụ cho mỗi tác vụ làm minh chứng cho cả ICL và LoraHub. Hiệu suất trung bình (avg) của LoraHub được tính trên 5 lần chạy với các seed ngẫu nhiên khác nhau, trong khi hiệu suất tốt nhất (best) được báo cáo là giá trị tối đa thu được qua những lần chạy này. Chúng ta có thể thấy xu hướng của kết quả tương tự như FLAN-T5-large.

Tác vụ Zero LoraHub avg LoraHub best
Boolean Expressions 52.0 58.7 63.3
Causal Judgement 62.1 53.8 59.8
Date Understanding 38.0 37.6 38.0
Disambiguation Qa 0.0 20.5 54.7
Dyck Languages 1.3 0.9 2.0
Formal Fallacies 56.0 56.0 56.0
Geometric Shapes 8.7 17.5 28.0
Hyperbaton 45.3 53.5 56.7
Logical Deduction§ (năm đối tượng) 1.3 42.7 48.7
Logical Deduction§ (bảy đối tượng) 8.7 44.3 50.0
Logical Deduction§ (ba đối tượng) 0.7 56.4 61.3
Movie Recommendation 2.0 62.8 66.0
Multistep Arithmetic Hai 0.0 0.4 0.7
Navigate 50.7 50.7 50.7
Object Counting 39.3 40.7 48.0
Penguins In A Table 17.4 40.9 45.7
Reasoning About Colored Objects 46.7 47.3 50.7
Ruin Names 18.0 35.6 44.7
Salient Translation Error Detection 44.7 45.1 48.7
Snarks 60.3 60.8 61.5
Sports Understanding 56.7 51.3 53.3
Temporal Sequences 21.3 21.5 22.0
Tracking Shuffled Objects§ (năm đối tượng) 3.3 9.9 13.3
Tracking Shuffled Objects§ (bảy đối tượng) 5.3 7.3 8.7
Tracking Shuffled Objects§ (ba đối tượng) 7.3 21.7 31.3
Web Of Lies 54.7 47.1 48.7
Word Sorting 1.3 1.5 2.0
Hiệu suất Trung bình mỗi Tác vụ 25.8 36.5 41.3

--- TRANG 18 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

E Cải thiện Tính Bền vững của LoraHub
Để nâng cao tính bền vững của LoraHub, chúng tôi đã khám phá một cách tiếp cận đơn giản trong việc lựa chọn các ứng viên mô-đun LoRA. Cụ thể, chúng tôi đầu tiên xác định 20 ứng viên mô-đun LoRA với loss thấp nhất trên các ví dụ few-shot. Các phát hiện của chúng tôi chỉ ra một sự cải thiện nhẹ trong hiệu suất tổng thể sau khi áp dụng chiến lược tiền lọc. Vì sự bất ổn chính trong cách tiếp cận của chúng tôi phát sinh từ việc lựa chọn các ứng viên LoRA. Phương pháp này bao gồm việc chọn một tập cố định các ứng viên LoRA để đảm bảo sự ổn định của cách tiếp cận của chúng tôi.

Bảng 7: Kết quả thực nghiệm của tiền lọc dựa trên loss.

Tác vụ LoraHub avg LoraHub filter
Boolean Expressions 55.5 60.00
Causal Judgement 54.3 52.9
Date Understanding 32.9 33.3
Disambiguation 45.2 62.7
Dyck Languages 1.0 0.0
Formal Fallacies 52.8 54.0
Geometric Shapes 7.4 4.0
Hyperbaton 62.8 64.0
Logical Deduction§ (năm đối tượng) 36.1 37.3
Logical Deduction§ (bảy đối tượng) 36.8 22.0
Logical Deduction§ (ba đối tượng) 45.7 56.0
Movie Recommendation 55.3 68.0
Multistep Arithmetic 0.4 0.7
Navigate 47.1 49.3
Object Counting 33.7 38.7
Penguins in a Table 35.9 37.0
Reasoning about Colored Objects 40.0 33.3
Ruin Names 24.4 22.0
Salient Translation Error Detection 36.0 24.0
Snarks 56.9 52.66
Sports Understanding 56.7 58.0
Temporal Sequences 18.2 27.3
Tracking Shuffled Objects§ (năm đối tượng) 12.3 11.3
Tracking Shuffled Objects§ (bảy đối tượng) 7.7 8.0
Tracking Shuffled Objects§ (ba đối tượng) 29.2 32.7
Web of Lies 50.1 46.0
Word Sorting 1.1 1.3
Hiệu suất Trung bình Mỗi Tác vụ 34.7 35.4

--- TRANG 19 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

F Hiệu suất trên Tác vụ Quan trọng Chung
Trong nghiên cứu của chúng tôi, chúng tôi đã xác định các mô-đun LoRA cụ thể thể hiện tác động đáng kể khi được tích hợp vào các LoRA đã kết hợp. Trọng tâm của chúng tôi là đánh giá hiệu suất của năm LoRA liên quan đến tác vụ hàng đầu trên benchmark BBH. Kết quả cho thấy rằng các LoRA hàng đầu này hoạt động tương tự hoặc thậm chí tệ hơn so với zero-shot trong hầu hết các trường hợp. Chỉ có một trong số chúng nổi bật là tốt hơn đáng kể so với zero-shot. Tuy nhiên, đáng chú ý là hiệu suất này không ấn tượng như Lorahub. Những phát hiện này hỗ trợ ý tưởng rằng quá trình kết hợp có thể cải thiện hiệu suất tổng thể.

Bảng 8: Kết quả thực nghiệm chi tiết của năm mô-đun LoRA hàng đầu được hiển thị trong Bảng 3 trên các tác vụ BBH.

Tác vụ WIQA: Last RACE: Right WIQA: First ADQA WebQA
Boolean Expressions 52.67 58.00 52.67 54.67 53.33
Causal Judgement 55.17 63.22 55.17 57.47 57.47
Date Understanding 17.33 19.33 17.33 16.67 15.33
Disambiguation 0.00 0.00 0.00 0.00 0.00
Dyck Languages 0.67 0.67 0.67 1.33 1.33
Formal Fallacies 51.33 51.33 51.33 51.33 51.33
Geometric Shapes 8.00 13.33 8.00 6.67 7.33
Hyperbaton 16.67 44.00 16.67 1.33 6.00
Logical Deduction§ (năm đối tượng) 23.33 28.00 23.33 19.33 20.67
Logical Deduction§ (bảy đối tượng) 22.00 26.00 22.00 10.67 12.00
Logical Deduction§ (ba đối tượng) 0.67 9.33 0.67 0.00 0.00
Movie Recommendation 63.33 62.67 63.33 56.67 63.33
Multistep Arithmetic 0.67 0.67 0.67 0.67 0.67
Navigate 47.33 50.00 47.33 47.33 47.33
Object Counting 34.67 34.00 34.67 35.33 35.33
Penguins in a Table 45.65 41.30 45.65 39.13 43.48
Reasoning about Colored Objects 40.00 37.33 40.00 31.33 30.67
Ruin Names 22.00 21.33 22.00 17.33 22.67
Salient Translation Error Detection 36.67 34.67 36.67 32.67 37.33
Snarks 52.56 55.13 52.56 47.44 52.56
Sports Understanding 56.00 58.67 56.00 55.33 55.33
Temporal Sequences 16.67 17.33 16.67 12.67 17.33
Tracking Shuffled Objects§ (năm đối tượng) 12.00 12.00 12.00 10.67 12.00
Tracking Shuffled Objects§ (bảy đối tượng) 6.67 6.67 6.67 6.67 6.67
Tracking Shuffled Objects§ (ba đối tượng) 20.67 30.67 20.67 10.67 25.33
Web of Lies 54.67 54.00 54.67 54.00 54.00
Word Sorting 1.33 1.33 1.33 1.33 1.33
Hiệu suất Trung bình mỗi Tác vụ 28.10 30.78 28.10 25.14 27.04
ΔFLAN-T5-large 1.10 3.78 1.10 -1.86 0.04

--- TRANG 20 ---
Được xuất bản như một bài báo hội nghị tại COLM 2024

[BIỂU ĐỒ: Hình 3 cho thấy ảnh hưởng của số lượng mô-đun LoRA trên 15 tác vụ từ BBH, với mỗi hộp thu được từ 5 lần chạy riêng biệt. Trục ngang cho thấy số lượng mô-đun LoRA được kết hợp trong học LoraHub.]

G Chi tiết Triển khai
Chúng tôi triển khai điều chỉnh LoRA bằng thư viện PEFT của Huggingface (Mangrulkar et al., 2022), với hạng được đặt là 16. Phương pháp không có gradient được triển khai bằng thư viện tối ưu hóa Nevergrad mã nguồn mở (Rapin & Teytaud, 2018), với ràng buộc rằng giá trị tuyệt đối của trọng số LoRA không được vượt quá 1.5. Ban đầu, tất cả các hệ số của các mô-đun LoRA được đặt ở mức không.

Trong các thiết lập tiêu chuẩn của chúng tôi, chúng tôi đặt số lần lặp tối đa K là 40. Cùng 5 ví dụ được sử dụng trong học LoraHub và học few-shot trong ngữ cảnh của chúng tôi. Siêu tham số α được đặt là 0.05. Liên quan đến các siêu tham số để huấn luyện các mô-đun LoRA ứng viên, chúng tôi duy trì tính nhất quán trên tất cả các mô-đun, đặt kích thước batch là 64, tỷ lệ học là 1e−4, và số epoch huấn luyện là 10.

H Ảnh hưởng của Số lượng mô-đun LoRA
Như được hiển thị trong Hình 3, với sự gia tăng số lượng ứng viên mô-đun LoRA, có sự gia tăng tương ứng trong phương sai hiệu suất. Dựa trên phân tích sâu sắc của chúng tôi, nguồn gốc chính của phương sai không liên quan đến các thuật toán tối ưu hóa không có gradient mà liên quan đến các mô-đun LoRA ứng viên. Nói cách khác, một khi các ứng viên được xác định, các seed ngẫu nhiên có tác động tối thiểu đến hiệu suất cuối cùng. Do đó, chúng tôi cho rằng sự bất ổn quan sát được chủ yếu phát sinh từ thách thức vốn có trong việc cân bằng số lượng và chất lượng của các ứng viên mô-đun LoRA.

I Tác động của Ngưỡng
Trong phần này, chúng tôi đã bỏ qua ngưỡng trong triển khai của chúng tôi, và kết quả được tóm tắt trong Bảng 9. Các quan sát của chúng tôi cho thấy rằng việc loại bỏ ngưỡng có tác động tối thiểu đến phần lớn các tác vụ, nhấn mạnh tính bền vững của chính thuật toán tối ưu hóa không có gradient trong hầu hết các trường hợp. Thuật toán xác định hiệu quả các khoảng hợp lý ngay cả khi không có giới hạn trên và dưới cụ thể. Tuy nhiên, ba tác vụ, cụ thể là Date Understanding, Disambiguation và Hyperbaton, thể hiện các hiệu ứng đáng chú ý. Sự sụt giảm hiệu suất kết quả dẫn đến giảm trung bình 1.2% so với thiết lập có ngưỡng. Điều này làm nổi bật tầm quan trọng của việc thiết lập một ngưỡng hợp lý để giảm thiểu các tình huống cực đoan.

Bảng 9: So sánh giữa LoraHub và LoraHub không có ngưỡng.

Tác vụ LoraHub avg với ngưỡng LoraHub avg không có ngưỡng
Boolean Expressions 55.5 54.0
Causal Judgement 54.3 54.8
Date Understanding 32.9 17.7
Disambiguation 45.2 40.6
Dyck Languages 1.0 1.1
Formal Fallacies 52.8 51.7
Geometric Shapes 7.4 6.7
Hyperbaton 62.8 55.5
Logical Deduction§ (năm đối tượng) 36.1 36.5
Logical Deduction§ (bảy đối tượng) 36.8 35.6
Logical Deduction§ (ba đối tượng) 45.7 49.9
Movie Recommendation 55.3 59.3
Multistep Arithmetic 0.4 0.7
Navigate 47.1 47.6
Object Counting 33.7 34.7
Penguins in a Table 35.9 33.8
Reasoning about Colored Objects 40.0 37.9
Ruin Names 24.4 24.0
Salient Translation Error Detection 36.0 37.1
Snarks 56.9 51.6
Sports Understanding 56.7 55.9
Temporal Sequences 18.2 16.7
Tracking Shuffled Objects§ (năm đối tượng) 12.3 12.3
Tracking Shuffled Objects§ (bảy đối tượng) 7.7 8.5
Tracking Shuffled Objects§ (ba đối tượng) 29.2 29.8
Web of Lies 50.1 50.3
Word Sorting 1.1 1.3
Hiệu suất Trung bình Mỗi Tác vụ 34.7 33.5

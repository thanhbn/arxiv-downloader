# 2204.02292.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2204.02292.pdf
# Kích thước tệp: 592939 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Tái xếp hạng Neural hiệu quả về tham số cho
Truy xuất đa ngôn ngữ và xuyên ngôn ngữ
Robert Litschko1Ivan Vuli ´c2Goran Glavaš1;3
1Nhóm Khoa học Dữ liệu và Web, Đại học Mannheim, Đức
2Phòng thí nghiệm Công nghệ Ngôn ngữ, Đại học Cambridge, Anh
3Trung tâm AI và Khoa học Dữ liệu (CAIDAS), Đại học Würzburg, Đức

Tóm tắt
Các mô hình tái xếp hạng neural tiên tiến rất khát dữ liệu - điều này khiến chúng hiếm khi được sử dụng trong các bối cảnh truy xuất đa ngôn ngữ và xuyên ngôn ngữ do thiếu dữ liệu huấn luyện quy mô lớn ở các ngôn ngữ khác ngoài tiếng Anh. Do đó, các phương pháp hiện tại thường chuyển giao các mô hình tái xếp hạng được huấn luyện trên dữ liệu tiếng Anh sang các ngôn ngữ khác và các thiết lập xuyên ngôn ngữ thông qua các bộ mã hóa đa ngôn ngữ: họ tinh chỉnh toàn bộ tham số của các Transformer đa ngôn ngữ quy mô lớn được huấn luyện trước (MMT, ví dụ: multilingual BERT) trên các đánh giá liên quan tiếng Anh, sau đó triển khai chúng trong (các) ngôn ngữ đích. Trong nghiên cứu này, chúng tôi cho thấy hai phương pháp hiệu quả về tham số cho chuyển giao xuyên ngôn ngữ, cụ thể là Sparse Fine-Tuning Masks (SFTM) và Adapter, cho phép chuyển giao zero-shot nhẹ và hiệu quả hơn đến các nhiệm vụ truy xuất đa ngôn ngữ và xuyên ngôn ngữ. Đầu tiên chúng tôi huấn luyện các adapter ngôn ngữ (hoặc SFTM) thông qua Masked Language Modelling và sau đó huấn luyện các adapter truy xuất (tức là tái xếp hạng) (SFTM) lên trên, trong khi giữ cố định tất cả các tham số khác. Khi suy luận, thiết kế modular này cho phép chúng tôi tạo ra mô hình tái xếp hạng bằng cách áp dụng adapter (hoặc SFTM) tái xếp hạng được huấn luyện với dữ liệu ngôn ngữ nguồn cùng với adapter ngôn ngữ (hoặc SFTM) của ngôn ngữ đích. Chúng tôi thực hiện đánh giá quy mô lớn trên các benchmark CLEF-2003 và HC4 và thêm vào đó, như một đóng góp khác, mở rộng benchmark trước với các truy vấn bằng ba ngôn ngữ mới: Kyrgyz, Uyghur và Thổ Nhĩ Kỳ. Các phương pháp hiệu quả về tham số được đề xuất vượt trội so với chuyển giao zero-shot tiêu chuẩn với việc tinh chỉnh MMT đầy đủ, đồng thời có tính modular hơn và giảm thời gian huấn luyện. Các cải thiện đặc biệt rõ rệt đối với các ngôn ngữ có tài nguyên thấp, nơi các phương pháp của chúng tôi cũng vượt trội đáng kể so với các mô hình tái xếp hạng dựa trên dịch máy cạnh tranh.

1 Giới thiệu
Trong những năm gần đây, các mô hình tái xếp hạng neural (Nogueira et al., 2019b; MacAvaney et al., 2019; Khattab và Zaharia, 2020), được huấn luyện trên các tập dữ liệu quy mô lớn (Bajaj et al., 2016; Dietz et al., 2017; Craswell et al., 2021), đã đẩy mạnh hiệu suất trên nhiều benchmark truy xuất. Vì các mô hình này thường quá phức tạp về mặt tính toán (tức là quá chậm) cho việc truy xuất ad-hoc trên các bộ sưu tập tài liệu lớn, chúng thường được sử dụng như các mô hình tái xếp hạng, tức là chúng tái xếp hạng đầu ra của một số mô hình nhanh (ví dụ: BM25) tạo ra xếp hạng ban đầu. Tuy nhiên, các tập dữ liệu quy mô lớn để huấn luyện các mô hình tái xếp hạng neural chỉ tồn tại bằng tiếng Anh, điều này cản trở việc áp dụng chúng trong các kịch bản truy xuất liên quan đến các ngôn ngữ khác: (a) truy xuất đơn ngôn ngữ bằng các ngôn ngữ khác và (b) truy xuất thông tin xuyên ngôn ngữ (CLIR) trong đó, đối với một truy vấn đã cho bằng một ngôn ngữ, cần xác định mức độ liên quan của các tài liệu được viết bằng một hoặc nhiều ngôn ngữ khác.

Trong khi CLIR thường được thực hiện dưới dạng các nhiệm vụ độc lập (ví dụ: để cho phép người dùng từ các quốc gia khác nhau tìm kiếm trên bộ sưu tập toàn cầu tổng hợp của các tin tức và phát hiện COVID-19 bằng ngôn ngữ mẹ đẻ của họ (Casacuberta et al., 2021)), nó cũng hỗ trợ một loạt các nhiệm vụ NLP được hỗ trợ bởi IR như trả lời câu hỏi xuyên ngôn ngữ (Asai et al., 2021), liên kết thực thể (Liu et al., 2021a), và tóm tắt xuyên ngôn ngữ (Zhu et al., 2019; Vitiugin và Castillo, 2022). Một công cụ tìm kiếm đa ngôn ngữ thực sự đòi hỏi ước tính đáng tin cậy cả về mức độ liên quan truy vấn-tài liệu đơn ngôn ngữ (cho một loạt các ngôn ngữ) cũng như xuyên ngôn ngữ, cả hai đều phụ thuộc quan trọng vào việc căn chỉnh các biểu diễn văn bản qua các ngôn ngữ khác nhau (Nie, 2010).

Việc thiếu các tập dữ liệu truy xuất quy mô lớn bằng các ngôn ngữ khác ngoài tiếng Anh có nghĩa là việc tái xếp hạng đơn ngôn ngữ cho các ngôn ngữ đó phải được thực hiện thông qua chuyển giao xuyên ngôn ngữ của một mô hình tái xếp hạng được huấn luyện trên các đánh giá liên quan tiếng Anh. Các Transformer đa ngôn ngữ quy mô lớn được huấn luyện trước (MMT) như multilingual BERT (mBERT) (Devlin et al., 2019) hoặc XLM-R (Conneau et al., 2020) đã được sử dụng cho mục đích này, nhưng đã được chứng minh là cần tinh chỉnh đáng kể theo nhiệm vụ cụ thể (tức là hướng xếp hạng) để dự đoán đáng tin cậy các điểm số tương đồng ngữ nghĩa và mức độ liên quan (Reimers và Gurevych, 2020; Litschko et al., 2021). MMT cung cấp chuyển giao xuyên ngôn ngữ zero-shot của các mô hình tái xếp hạng neural ngay từ đầu - một MMT được tinh chỉnh trên các đánh giá liên quan tiếng Anh và sau đó được sử dụng trong các nhiệm vụ truy xuất (đơn ngôn ngữ hoặc xuyên ngôn ngữ) liên quan đến các ngôn ngữ khác. Về mặt khái niệm, thông qua việc chuyển giao này, không cần dữ liệu tinh chỉnh (tức là các đánh giá liên quan) cho (các) ngôn ngữ đích.

Thủ tục này, về nguyên tắc, cho phép chuyển giao downstream zero-shot sang bất kỳ ngôn ngữ nào được MMT thấy trong quá trình huấn luyện trước (ví dụ: đối với mBERT, 104 ngôn ngữ). Tuy nhiên, trong các nhiệm vụ hiểu ngôn ngữ (Hu et al., 2020), đã quan sát thấy sự sụt giảm hiệu suất lớn khi chuyển giao giữa các ngôn ngữ xa xôi, và đặc biệt là trong việc chuyển giao sang các ngôn ngữ có tài nguyên thấp, được đại diện kém trong việc huấn luyện trước MMT (Lauscher et al., 2020). Kết quả của chúng tôi (§4) xác nhận những phát hiện này cho IR ad-hoc. Đây là hậu quả của hiệu ứng được gọi là lời nguyền của tính đa ngôn ngữ (Conneau et al., 2020): việc chia sẻ các tham số MMT (tức là ngân sách/công suất tham số cố định của nó) qua nhiều ngôn ngữ ngày càng nhiều làm cho các biểu diễn văn bản cho các ngôn ngữ riêng lẻ kém chính xác hơn. Hiệu ứng này đặc biệt có hại cho các ngôn ngữ có tài nguyên thấp, những ngôn ngữ ít được đại diện nhất trong các corpus huấn luyện trước đa ngôn ngữ. Hơn nữa, việc tinh chỉnh đầy đủ quy mô lớn trên dữ liệu ngôn ngữ nguồn (ví dụ: tiếng Anh) có thể dẫn đến việc quên thảm khốc và các hiệu ứng can thiệp (McCloskey và Cohen, 1989; Mirzadeh et al., 2020) làm thiên lệch thêm không gian biểu diễn đa ngôn ngữ về phía ngôn ngữ nguồn, với chi phí là chất lượng biểu diễn cho các ngôn ngữ có tài nguyên thấp. Bên cạnh chuyển giao xuyên ngôn ngữ zero-shot tiêu chuẩn (MacAvaney et al., 2020; Huang et al., 2021a), các phương pháp chuyển giao xuyên ngôn ngữ khác, thường được áp dụng trong các nhiệm vụ NLP khác, như dịch dữ liệu huấn luyện (Shi et al., 2020), hoặc tận dụng các căn chỉnh mức từ bên ngoài (Huang et al., 2021b), cũng như giám sát từ xa (Yu et al., 2021) đã được khám phá như các phương tiện để cải thiện chuyển giao xuyên ngôn ngữ của các mô hình tái xếp hạng neural trong IR. Trong khi các phương pháp dựa trên dịch thuật có tính cạnh tranh đối với các ngôn ngữ có tài nguyên cao, chúng có thể không hiệu quả đối với các ngôn ngữ có tài nguyên thấp mà thiếu các mô hình MT đáng tin cậy; ngoài ra, chuyển giao xuyên ngôn ngữ dựa trên dịch thuật đã được chứng minh là gặp phải các artifact không mong muốn, như "translationese" (Zhao et al., 2020; Vanmassenhove et al., 2021).

Đóng góp. Ngay cả khi người ta có đủ lượng dữ liệu được gắn nhãn trong các ngôn ngữ đích, việc huấn luyện các mô hình tái xếp hạng neural cụ thể theo ngôn ngữ hoặc cặp ngôn ngữ cho tất cả các ngôn ngữ và cặp ngôn ngữ sẽ cực kỳ tốn kém về mặt tính toán và không bền vững (Strubell et al., 2019). Trong công việc này, chúng tôi cũng khắc phục điều này bằng cách tạo ra các mô hình tái xếp hạng theo cách modular cho phép chuyển giao xuyên ngôn ngữ bền vững hơn. Cụ thể, chúng tôi giới thiệu các mô hình tái xếp hạng neural cho truy xuất tài liệu xuyên ngôn ngữ và đa ngôn ngữ dựa trên MMT cho phép tinh chỉnh hiệu quả tham số hơn nhiều và chuyển giao xuyên ngôn ngữ hiệu quả hơn cho dự đoán mức độ liên quan. Các mô hình tái xếp hạng của chúng tôi dựa trên hai kiểu thành phần modular: 1) Adapter (Rebuffi et al., 2017; Houlsby et al., 2019; Pfeiffer et al., 2020) và 2) Sparse Fine-Tuning Masks (SFTM) (Ansell et al., 2022). Khi được tích hợp vào kiến trúc của một MMT được huấn luyện trước, cả hai đều cho phép (1) kiến thức đa ngôn ngữ được huấn luyện trước được bảo toàn hoàn toàn, giảm thiểu các hiệu ứng can thiệp tiêu cực và quên lãng, và (2) cung cấp thêm dung lượng mô hình cụ thể theo ngôn ngữ được sử dụng để cải thiện các biểu diễn của MMT cho các ngôn ngữ đích, do đó khắc phục lời nguyền của tính đa ngôn ngữ.

Chúng tôi cung cấp đánh giá toàn diện về cả hai phương pháp trong (i) chuyển giao zero-shot cho truy xuất đơn ngôn ngữ và (ii) CLIR, trên hai benchmark đã được thiết lập (Braschler, 2003; Lawrie et al., 2022). Như một đóng góp bổ sung, chúng tôi mở rộng tập dữ liệu CLEF (Braschler, 2003) với ba ngôn ngữ truy vấn từ họ ngôn ngữ Turk (Thổ Nhĩ Kỳ, Kyrgyz, và Uyghur, hai ngôn ngữ sau là các ngôn ngữ có tài nguyên thấp), có khoảng cách về mặt ngôn ngữ học và từ nguyên so với các ngôn ngữ Ấn-Âu. Kết quả của chúng tôi cho thấy các mô hình tái xếp hạng neural modular của chúng tôi không chỉ nhanh hơn để huấn luyện, mà còn vượt trội so với chuyển giao zero-shot tiêu chuẩn dựa trên tinh chỉnh MMT đầy đủ, và đặc biệt là trong các nhiệm vụ truy xuất liên quan đến các ngôn ngữ xa xôi về mặt ngôn ngữ học và có tài nguyên thấp. Hơn nữa, các mô hình tái xếp hạng dựa trên adapter và SFTM của chúng tôi thường vượt trội so với một mô hình tiền xếp hạng mạnh sử dụng dịch máy tiên tiến.

2 Phương pháp luận
Chúng tôi trước tiên giới thiệu khung xếp hạng đa giai đoạn tổng quát (tức là tiền xếp hạng-tái xếp hạng), thường được sử dụng trong các nhiệm vụ truy xuất thông tin, mà công việc của chúng tôi được nhúng vào. Sau đó chúng tôi giới thiệu các adapter và sparse fine-tuning mask (SFTM), và trình bày cách tận dụng chúng như các phương tiện quan trọng của chuyển giao xuyên ngôn ngữ hiệu quả tham số của thành phần tái xếp hạng.

2.1 Xếp hạng đa giai đoạn
Các Transformer được huấn luyện trước như BERT (Devlin et al., 2019) thường được sử dụng như các mô hình tính điểm Cross-Encoder (CE): Transformer mã hóa một sự nối tiếp truy vấn-tài liệu được đưa vào như đầu vào cho mô hình, và việc mã hóa sau đó được đưa vào một lớp dày đặc dự đoán điểm số liên quan (MacAvaney et al., 2020; Jiang et al., 2020; Nogueira et al., 2019b). Tính toán điểm số cho tất cả các cặp truy vấn-tài liệu với Cross-Encoder quá chậm cho các ứng dụng IR thực tế: do đó chúng chủ yếu được sử dụng như các mô hình tái xếp hạng trong một phương pháp xếp hạng đa giai đoạn (MacAvaney et al., 2020; Geigle et al., 2021). Trong nghiên cứu này, chúng tôi áp dụng mô hình này cho truy xuất ad-hoc xuyên ngôn ngữ: Hình 1 minh họa quy trình làm việc của nó.

Tiền xếp hạng, dựa trên một phương pháp xếp hạng nhanh và hiệu quả, được áp dụng cho mọi tài liệu từ bộ sưu tập tài liệu để cung cấp một xếp hạng ban đầu tốt, nhắm vào recall cao. Gọi ql1 là một truy vấn bằng ngôn ngữ l1 và Cl2 = {di}ni=1 là một bộ sưu tập tài liệu chứa n tài liệu bằng ngôn ngữ l2. Kết hợp và xếp hạng các tài liệu theo điểm số liên quan si chúng ta có được một xếp hạng ban đầu

R0 = [(d1;s1);(d2;s2):::(dn;sn)]; (1)

trong đó s1 > s2 > ::: > sn. Chúng tôi chuyển giao các mô hình tái xếp hạng của chúng tôi dựa trên MMT - và được huấn luyện trên các đánh giá liên quan tiếng Anh - đến (i) các nhiệm vụ CLIR cũng như (ii) các nhiệm vụ IR đơn ngôn ngữ trong các ngôn ngữ đích. Nhiệm vụ sau, được gọi là MoIR, thực chất là chuyển giao xuyên ngôn ngữ zero-shot cho truy xuất đơn ngôn ngữ. Trong MoIR, chúng tôi chọn một mô hình tiền xếp hạng từ vựng và tính điểm các tài liệu với sbm25 = BM25(q,d). Trong CLIR, chúng tôi tuân theo phương pháp được sử dụng rộng rãi là dịch máy truy vấn (Bonifacio et al., 2021; Lawrie et al., 2022): quá trình này chuyển đổi CLIR thành một biến thể nhiễu của MoIR một cách hiệu quả. Ngoài ra, chúng tôi thử nghiệm với một phương pháp dựa trên biểu diễn dựa trên các Bi-Encoder đa ngôn ngữ được huấn luyện trước (BE): ở đây, chúng tôi nhúng truy vấn và tài liệu một cách độc lập, và sau đó sử dụng độ tương đồng cosine giữa các embedding của chúng sbe = cos(BE(q), BE(d)). Trong giai đoạn tiền xếp hạng, không giống như sau này trong tái xếp hạng, chúng tôi sử dụng các bộ mã hóa chỉ như các bộ mã hóa văn bản mục đích chung, không có bất kỳ huấn luyện cụ thể cho truy xuất bổ sung nào.

Tái xếp hạng: Giai đoạn này tinh chỉnh xếp hạng ban đầu thu được thông qua tiền xếp hạng. Nó dựa vào một mô hình CE nắm bắt các tương tác ngữ nghĩa tinh vi (nhưng tốn kém hơn để mô hình hóa và chạy) giữa các truy vấn và tài liệu. Xếp hạng sau đó là:

R1 = [(d1;sce1);(d2;sce2):::(dk;scek)] (2)

Với mục đích này, chúng tôi dựa vào các CE đa ngôn ngữ để tính điểm số liên quan nhị phân sce trên sự nối tiếp của các cặp truy vấn và tài liệu: sce = CE([CLS]q[SEP]di[SEP]). Chúng tôi áp dụng một thực hành phổ biến (MacAvaney et al., 2019; Craswell et al., 2020; Naseri et al., 2021) là tái xếp hạng k = 100 tài liệu được xếp hạng trước hàng đầu, tạo ra xếp hạng cuối cùng R1. Cuối cùng, cũng có thể tổng hợp các danh sách xếp hạng của mô hình tiền xếp hạng và tái xếp hạng thông qua việc tính trung bình xếp hạng đơn giản. Trong các thí nghiệm của chúng tôi (4), chúng tôi cũng đánh giá các tổng hợp tiền xếp hạng-tái xếp hạng như vậy và cho thấy rằng những phép nội suy như vậy thường mang lại các cải thiện hiệu suất bổ sung.

--- TRANG 4 ---
Hình 2: Tổng quan về học chuyển giao hiệu quả tham số cho tái xếp hạng neural. Trái: Một mô hình tái xếp hạng được tạo thành bằng cách xếp chồng một Language Adapter (LA) ngôn ngữ đích được huấn luyện trước và một Ranking Adapter (RA; được huấn luyện với dữ liệu ngôn ngữ nguồn) lên trên các lớp Transformer gốc của một MMT (ví dụ: mBERT). Phải: Tinh chỉnh thưa thớt của một Ranking Mask (RM) và một Language Mask (LM) từ các tham số mBERT; các mô hình tái xếp hạng được tạo thành bằng cách thêm các giá trị RM và LM vào các tham số mBERT gốc.

2.2 Chuyển giao mô hình tái xếp hạng xuyên ngôn ngữ hiệu quả tham số
Trong nghiên cứu này, chúng tôi đề xuất một khung modular và hiệu quả tham số cho phép huấn luyện nhanh hơn và chuyển giao xuyên ngôn ngữ hiệu quả hơn của các mô hình tái xếp hạng neural, tăng cường cả CLIR và MoIR. Đầu tiên chúng tôi học các Adapter cụ thể theo ngôn ngữ (LA) hoặc Sparse Fine-Tuning Masks (SFTM) thông qua Masked Language Modelling (MLM) trên các corpus đơn ngôn ngữ không được chú thích của các ngôn ngữ tương ứng, trong khi giữ nguyên các tham số MMT gốc. Sau đó chúng tôi huấn luyện các Ranking Adapter (hoặc Ranking SFTM) sử dụng dữ liệu ngôn ngữ nguồn lên trên các LA ngôn ngữ nguồn (language SFTM), trong khi giữ cố định tất cả các tham số khác. Tại thời điểm suy luận, đối với một nhiệm vụ IR cụ thể (MoIR hoặc CLIR), chúng tôi tạo ra mô hình tái xếp hạng của chúng tôi bằng cách đặt các Ranking Adapter (Ranking SFTM) lên trên các LA (language SFTM) của các ngôn ngữ truy vấn và/hoặc tài liệu của nhiệm vụ truy xuất cụ thể đó. Khung modular được minh họa trong Hình 2.

Adapter. Chúng tôi huấn luyện Ranking Adapter (RA) và Language Adapter (LA) dựa trên kiến trúc của Pfeiffer et al. (2020). Trong kiến trúc Transformer, mỗi lớp l bao gồm một khối multi-head attention (tức là sub-layer) và một mạng feed-forward (FFN), cả hai đều được theo sau bởi một kết nối dư và layer normalization. Chúng tôi ký hiệu kết nối dư (đầu ra của FFN) với rl và trạng thái ẩn sau layer norm với hl.

LA(hl;rl) = Ul(σ(Dl(hl))) + rl (3)
RA(hl;rl) = Ul(σ(Dl(LAl))) + rl (4)

Các Adapter được tham số hóa bởi ma trận down-projection D ∈ R^{h×d} và ma trận up-projection U ∈ R^{d×h}, trong đó h và d biểu thị kích thước ẩn của Transformer và chiều thắt cổ chai của adapter, tương ứng. Tỷ lệ giữa h và d cũng được gọi là hệ số giảm, và tương ứng với mức độ nén tham số (tức là có bao nhiêu lần ít tham số hơn được cập nhật nếu chúng ta huấn luyện adapter thay vì cập nhật tất cả các tham số Transformer). Lượt truyền thuận của một Language Adapter bao gồm một down-projection của hl, một hàm kích hoạt phi tuyến σ(·) và một up-projection. Ranking Adapter được xếp chồng lên trên LA và xử lý đầu ra của chúng. Cả hai adapter đều có kết nối dư đến đầu ra của FFN. Chúng tôi huấn luyện LA sử dụng mục tiêu MLM tiêu chuẩn (Devlin et al., 2019), trong khi chúng tôi huấn luyện RA cùng với lớp tính điểm dày đặc bằng cách tối thiểu hóa loss binary cross-entropy tiêu chuẩn.

Trong các thiết lập CLIR, các truy vấn và tài liệu ở các ngôn ngữ khác nhau. Do đó, về nguyên tắc, có thể xếp chồng RA lên trên (i) query language adapter LAQ, (ii) document language adapter LAD, hoặc bằng cách sử dụng (iii) split adapter LAS: ở đây, chúng tôi mã hóa các token truy vấn đến token phân tách ([SEP]) sử dụng LA của ngôn ngữ truy vấn và các token tài liệu (sau [SEP]) với LA của ngôn ngữ của bộ sưu tập tài liệu (tham khảo Hình 2).

Sparse Fine-Tuning Masks. Giống như các adapter, SFTM (Ansell et al., 2022) nhằm tách biệt kiến thức nhiệm vụ khỏi kiến thức ngôn ngữ, nhưng thay vì giới thiệu các tham số bổ sung, ý tưởng là cập nhật trực tiếp chỉ các tập con nhỏ của các tham số gốc của MMT. Sparse Fine-Tuning (SFT) bao gồm hai giai đoạn. Trong Giai đoạn 1, chúng tôi tinh chỉnh tất cả các tham số của mBERT θ^(0), dẫn đến các giá trị tham số được cập nhật θ^(1). Sau đó chúng tôi chọn K tham số hàng đầu với sự thay đổi giá trị lớn nhất, tức là những tham số có giá trị |θ_i^(0) - θ_i^(1)| lớn nhất. Sau đó chúng tôi xây dựng một mask nhị phân: K tham số được chọn vẫn có thể huấn luyện được, trong khi tất cả các tham số khác bị đóng băng. Trong Giai đoạn 2, tất cả các tham số được đặt lại về θ^(0) và huấn luyện khởi động lại, nhưng lần này chỉ các tham số được chọn của mask được cập nhật, tạo ra θ^(2). Cập nhật cuối cùng (tức là SFTM) sau đó được thu được dưới dạng vector hiệu M = θ^(2) - θ^(0).

Giống như với Language Adapter, chúng tôi thu được Language Mask (LM) bằng cách thực hiện huấn luyện MLM (bổ sung) trên các corpus cụ thể theo ngôn ngữ; trong khi Ranking Mask (tức là mask cho nhiệm vụ xếp hạng, RM) được học thông qua mục tiêu binary cross-entropy trên các đánh giá liên quan ngôn ngữ nguồn (tiếng Anh). Khi suy luận, mô hình tái xếp hạng được tạo thành như θ^(0) + RM + LM (tham khảo Hình 2). Trong các thiết lập CLIR của chúng tôi (§3), chúng tôi khám phá việc sử dụng (i) query language mask (LMQ), (ii) document language mask (LMD) hoặc (iii) sự kết hợp của cả hai mask (LMB = LMQ + LMD). Lưu ý rằng SFTM đại diện cho một giải pháp hiệu quả hơn về mặt tính toán tại thời điểm suy luận: không giống như adapter, chúng không mở rộng (tức là làm sâu hơn) kiến trúc Transformer.

3 Thiết lập thí nghiệm
Huấn luyện Adapter và SFTM. Chúng tôi huấn luyện adapter theo các khuyến nghị từ Pfeiffer et al. (2020). Trừ khi có ghi chú khác, chúng tôi huấn luyện LA với hệ số giảm 2 (tức là h/d = 2) trên Wikipedia của các ngôn ngữ tương ứng, trong 250K bước với batch size 64 và learning rate 1e-4. Đối với RA, chúng tôi thí nghiệm với các hệ số giảm khác nhau: 1, 2, 4, 8, 16, 32 (tham khảo §4). Theo Ansell et al. (2022), để so sánh công bằng giữa adapter và SFTM, chúng tôi đặt kích thước mask K cho SFTM bằng số lượng tham số mà adapter với một hệ số giảm nhất định có.

Huấn luyện tái xếp hạng. Chúng tôi huấn luyện các mô hình tái xếp hạng dựa trên mBERT trên MS-MARCO (Craswell et al., 2021), với một warm-up tuyến tính trong 5K cập nhật đầu tiên, trong các batch 32 instance với độ dài chuỗi tối đa 512, và sử dụng learning rate 2e-5. Chúng tôi đánh giá mô hình trên dữ liệu validation mỗi 25K cập nhật và chọn checkpoint với hiệu suất validation tốt nhất.

Dữ liệu đánh giá. Chúng tôi đánh giá các mô hình trên benchmark CLEF-2003 tiêu chuẩn (Braschler, 2003) cũng như trên benchmark HC4 được giới thiệu gần đây (Lawrie et al., 2022). Với CLEF, chúng tôi sử dụng các bộ sưu tập thử nghiệm đơn ngôn ngữ trong EN, DE, IT, RU, và FI cho MoIR, và thí nghiệm với các hướng xuyên ngôn ngữ sau: EN-{FI, DE, IT, RU}, DE-{FI, IT, RU}, FI-{IT, RU}. Mỗi lần chạy thí nghiệm bao gồm 60 truy vấn, trong khi kích thước bộ sưu tập tài liệu như sau: RU – 17K, FI – 55K, IT – 158K, và DE – 295K.

Chúng tôi cũng đánh giá các mô hình trong các nhiệm vụ CLIR với các truy vấn CLEF bằng các ngôn ngữ có tài nguyên thấp hơn. Với mục đích này, (i) chúng tôi tận dụng các truy vấn tiếng Swahili (SW) và Somalia (SO) (Bonab et al., 2019), trong đó các truy vấn được thu được thông qua dịch thủ công của các truy vấn tiếng Anh; (ii) chúng tôi tạo ra một bộ khác gồm các truy vấn CLEF được dịch bằng ba ngôn ngữ: Thổ Nhĩ Kỳ (TR), Kyrgyz (KG), và Uyghur (UG). Bộ mới bao gồm một ngôn ngữ có tài nguyên cao và hai ngôn ngữ có tài nguyên thấp và nhằm tạo điều kiện và đa dạng hóa đánh giá CLIR với các ngôn ngữ có tài nguyên thấp trong công việc tương lai. Các truy vấn được xây dựng thông qua quy trình post-editing tiêu chuẩn được mượn từ các nhiệm vụ thu thập dữ liệu khác (Glavaš et al., 2020; Hung et al., 2022): chúng tôi thu được các bản dịch truy vấn ban đầu thông qua Google Translate, sau đó được post-edit bởi các người nói bản ngữ.

HC4 bao gồm các truy vấn và bộ sưu tập tài liệu bằng ba ngôn ngữ: Ba Tư (FA), Nga (RU) và Trung Quốc (ZH). So với CLEF, các bộ sưu tập HC4 lớn hơn đáng kể, trải rộng 646K, 486K và 4.72M tài liệu cho mỗi ngôn ngữ tương ứng, được kết hợp với 50 truy vấn thử nghiệm trong mỗi ngôn ngữ. Chúng tôi sử dụng các trường title và description làm truy vấn theo Lawrie et al. (2022). HC4 được sử dụng trong các thí nghiệm MoIR.

Các mô hình baseline. Baseline chính cho chuyển giao dựa trên adapter và SFTM của chúng tôi là phương pháp tiêu chuẩn và được thiết lập tốt cho chuyển giao zero-shot của các mô hình tái xếp hạng được huấn luyện trên tiếng Anh (MacAvaney et al., 2020), được gọi là MonoBERT. Đây là Cross-Encoder tái xếp hạng mà chúng tôi cho phép tinh chỉnh đầy đủ BERT đơn ngôn ngữ hoặc đa ngôn ngữ cơ bản trên MS-MARCO. Đối với các thí nghiệm CLIR, chúng tôi chọn DISTIL DmBERT làm mô hình tiền xếp hạng Bi-Encoder (PR) của chúng tôi, vì nó cho thấy hiệu suất mạnh trong nghiên cứu thực nghiệm so sánh gần đây của chúng tôi (Litschko et al., 2021). Tóm lại, DISTIL DmBERT được huấn luyện thông qua knowledge distillation trong đó các đặc trưng tương đồng câu được chưng cất từ một giáo viên tiếng Anh đơn ngôn ngữ, chuyên biệt cho việc mã hóa ngữ nghĩa của câu, vào một mô hình sinh viên đa ngôn ngữ; xem (Reimers và Gurevych, 2020) để biết thêm chi tiết. Cuối cùng, cũng cho CLIR, chúng tôi kết hợp một hệ thống NMT tiên tiến của Fan et al. (2020) (FAIR-MT), mà chúng tôi sử dụng để dịch các truy vấn sang ngôn ngữ của bộ sưu tập tài liệu, với mô hình xếp hạng BM25 trong ngôn ngữ đích. Đối với Kyrgyz và Uyghur, chúng tôi sử dụng một mô hình NMT khác, được cung cấp bởi cộng đồng Turkic Interlingua (TIL) (Mirzakhalov et al., 2021), bởi vì chúng tôi không thể có được các bản dịch {KG, UG} → l2 có ý nghĩa với FAIR-MT.

4 Kết quả và thảo luận
Truy xuất xuyên ngôn ngữ (CLIR). Bảng 1 và 2 cho thấy kết quả CLIR, cho mười bốn cặp ngôn ngữ từ benchmark CLEF 2003 được mở rộng sử dụng DISTIL DmBERT và NMT+BM25 làm mô hình tiền xếp hạng Giai đoạn 1, tương ứng. Với DISTIL DmBERT làm mô hình tiền xếp hạng (Bảng 1), các mô hình tái xếp hạng dựa trên Adapter và SFTM liên tục cải thiện kết quả tiền xếp hạng ban đầu, với mức tăng lên đến 2.7 điểm MAP, và EN-RU là ngoại lệ duy nhất. Quan trọng là, so với tinh chỉnh đầy đủ (MonoBERT), các biến thể tái xếp hạng modular của chúng tôi mang lại mức tăng từ 1 đến 4 điểm MAP trung bình, qua tất cả các cặp ngôn ngữ. Thú vị là, cấu hình adapter tốt nhất (RA + LAD), trong đó khi suy luận chúng tôi xếp chồng RA lên trên LA của ngôn ngữ bộ sưu tập tài liệu) vượt trội so với mô hình tái xếp hạng dựa trên SFTM tốt nhất (RM + LMQ và RM + LMD) 1.6 điểm MAP. Hơi bất ngờ, việc thích nghi chỉ với ngôn ngữ của bộ sưu tập tài liệu (LAD; LMD) mang lại hiệu suất tốt hơn việc thích nghi với cả ngôn ngữ truy vấn và ngôn ngữ bộ sưu tập của nhiệm vụ đích (LAS; LMB).

Các cặp ngôn ngữ trong Bảng 1 và 2 bao gồm các ngôn ngữ có tài nguyên cao mà đối với những ngôn ngữ này tồn tại các corpus song song lớn và do đó, các mô hình NMT đáng tin cậy. Tuy nhiên, ngay cả khi bắt đầu từ một mô hình tiền xếp hạng dựa trên MT cạnh tranh hơn (NMT+BM25; Bảng 2), chuyển giao xuyên ngôn ngữ modular của mô hình tái xếp hạng của chúng tôi vẫn mang lại mức tăng hiệu suất. Thực tế, với mô hình tiền xếp hạng mạnh hơn này, mức tăng từ tái xếp hạng modular thậm chí còn rõ rệt hơn: +5/+6 điểm MAP cho Adapter và SFTM, tương ứng, so với mô hình tiền xếp hạng và +2/+3 điểm MAP, tương ứng, so với MonoBERT. Điều này có thể giải thích tại sao việc nội suy giữa tiền xếp hạng và tái xếp hạng (ENS, cột cuối) mang lại mức tăng thêm với DISTIL DmBERT làm mô hình tiền xếp hạng (Bảng 1), nhưng không khi chúng tôi tiền xếp hạng với NMT+BM25 (Bảng 2).

Bảng 3 cho thấy kết quả CLIR cho (a) các cặp ngôn ngữ từ CLEF mở rộng với các truy vấn được viết bằng các ngôn ngữ có tài nguyên thấp – các truy vấn tiếng Swahili và Somalia được tạo bởi Bonab et al. (2019), cũng như các truy vấn Kyrgyz và Uyghur mà chúng tôi tạo ra; và (b) ba cặp xuyên ngôn ngữ của các ngôn ngữ có thể nói là xa xôi (EN-{Farsi, Chinese, Russian}) từ benchmark HC4. Mức tăng mà các mô hình tái xếp hạng modular dựa trên SFTM và Adapter của chúng tôi mang lại cho các cặp ngôn ngữ liên quan đến các ngôn ngữ có tài nguyên thấp, so với mô hình tiền xếp hạng dựa trên MT và tinh chỉnh đầy đủ (MonoBERT), thường đáng kể hơn những mức tăng cho các cặp ngôn ngữ có tài nguyên cao: ví dụ, +8 và +4 điểm MAP w.r.t. NMT+BM25 và MonoBERT, tương ứng cho SW-EN, và +8 và +5 điểm cho KG-EN. Mức tăng cũng nổi bật tương tự cho các cặp ngôn ngữ xa xôi hơn từ tập dữ liệu HC4 (+8 điểm MAP so với mô hình tiền xếp hạng NMT+BM25 cho EN-FA và EN-ZH). Với những mức tăng nổi bật như vậy của tái xếp hạng modular so với mô hình tiền xếp hạng, không có gì ngạc nhiên khi việc tính trung bình xếp hạng tài liệu tiền xếp hạng và tái xếp hạng (ENS) làm giảm hiệu suất của mô hình tái xếp hạng. Chúng tôi tin rằng những kết quả này đặc biệt nhấn mạnh hiệu quả của chuyển giao xuyên ngôn ngữ modular cho phép tăng dung lượng của MMT cho các ngôn ngữ riêng lẻ, thông qua LM hoặc LA. Các biểu diễn của các ngôn ngữ có tài nguyên thấp, mà MMT đã thấy ít dữ liệu trong quá trình huấn luyện trước, đặc biệt chịu ảnh hưởng từ lời nguyền của tính đa ngôn ngữ (Conneau et al., 2020; Lauscher et al., 2020) – đây là lý do tại sao những mức tăng đặc biệt nổi bật được đạt được cho những ngôn ngữ đó khi chúng tôi tăng dung lượng của MMT cho biểu diễn của chúng thông qua LM/LA.

Chuyển giao xuyên ngôn ngữ cho MoIR. Bảng 4 hiển thị kết quả truy xuất đơn ngôn ngữ với các mô hình tái xếp hạng modular hiệu suất tốt nhất của chúng tôi cho EN (như ngôn ngữ nguồn) và bốn ngôn ngữ đích (DE, IT, FI, RU). Không giống như mô hình tái xếp hạng được tinh chỉnh đầy đủ (MonoBERT), các mô hình tái xếp hạng modular dựa trên Adapter và SFTM của chúng tôi cải thiện các xếp hạng ban đầu được tạo ra bởi BM25. Những kết quả này củng cố phát hiện rằng các mô hình tái xếp hạng modular của chúng tôi không chỉ hiệu quả hơn về tham số (tức là nhanh hơn để huấn luyện), mà còn dẫn đến chuyển giao xuyên ngôn ngữ tốt hơn do tách biệt kiến thức cụ thể theo ngôn ngữ và xếp hạng. Trong các nhiệm vụ MoIR, chuyển giao dựa trên SFTM vượt trội so với đối tác dựa trên Adapter của nó, giống như trong trường hợp CLIR với tiền xếp hạng NMT+BM25 (Bảng 1). Cũng như trong trường hợp kết quả CLIR sau này (Bảng 1 và 3), việc nội suy giữa kết quả tiền xếp hạng và tái xếp hạng không mang lại bất kỳ mức tăng nào.

Đáng chú ý là tất cả điểm số MoIR đều cao hơn đáng kể so với kết quả CLIR từ Bảng 1 và 2. Điều này là mong đợi và phản ánh thực tế rằng việc khớp các biểu diễn trong một ngôn ngữ – nơi các mô hình vẫn có thể dựa vào các khớp từ vựng chính xác giữa các truy vấn và tài liệu – dễ dàng hơn việc căn chỉnh các biểu diễn văn bản qua các ngôn ngữ.

Hiệu quả so với hiệu suất. Adapter tăng độ trễ truy vấn bởi vì chúng làm sâu hơn Transformer. Rücklé et al. (2021) cho thấy rằng có thể bỏ các adapter từ các lớp thấp hơn với tác động nhỏ đến không đáng kể đến hiệu suất. Bảng 5 cho thấy kết quả của một phân tích tương tự, trong đó chúng tôi bỏ các adapter từ N lớp đầu tiên khi suy luận. Việc bỏ adapter chỉ từ hai lớp đầu tiên (hàng 1-2) chỉ giảm nhẹ hiệu suất MoIR trong khi thậm chí còn tăng nhẹ kết quả CLIR. Tuy nhiên, việc bỏ adapter từ nhiều lớp hơn làm giảm đáng kể hiệu suất truy xuất: ví dụ, việc loại bỏ adapter từ 10 lớp đầu tiên giảm hiệu suất CLIR gần 20 điểm MAP, trong khi chỉ giảm độ trễ truy vấn 13%. Trong khi Adapter và SFTM mang lại hiệu suất tương đương trong các thí nghiệm của chúng tôi, những quan sát này có lợi cho SFTM: với cùng độ trễ truy vấn, SFTM sẽ mang lại hiệu suất tốt hơn.

Hiệu quả tham số. Chúng tôi cũng điều tra mối quan hệ giữa các mức độ hiệu quả tham số khác nhau và hiệu suất truy xuất. Hình 3 cho thấy hiệu suất của các mô hình tái xếp hạng modular của chúng tôi cho các hệ số giảm tham số khác nhau. SFTM thể hiện hiệu suất mạnh hơn với các hệ số giảm nhỏ hơn (2 và 4), tức là khi chúng tôi cập nhật một tỷ lệ lớn hơn các tham số gốc của mBERT. SFTM dịch chuyển các giá trị được huấn luyện trước của các tham số mBERT: điều này hạn chế phạm vi giá trị mà các tham số riêng lẻ có thể nhận, đòi hỏi việc sửa đổi số lượng tham số lớn hơn để tiêm kiến thức cụ thể theo ngôn ngữ và xếp hạng phức tạp. Ngược lại, Adapter cho thấy hiệu suất tốt hơn với hệ số giảm cao hơn (8, 16, 32), tức là khi chúng tôi thêm một số lượng tham số Adapter tương đối nhỏ hơn. Điều này có thể là hậu quả của việc khởi tạo "không bị ràng buộc" của các tham số Adapter mới, cho phép kiến thức bổ sung cụ thể theo ngôn ngữ và xếp hạng được nén vào số lượng tham số nhỏ hơn. So sánh những hiệu ứng này giữa CLIR và MoIR, chúng tôi quan sát cùng xu hướng. Tuy nhiên, mức tăng MAP so với MonoBERT lớn hơn trong MoIR so với CLIR. Điều này có vẻ trực quan vì các adapter (mask) xếp hạng có thể thích nghi cho các khớp chính xác.

Tác động của NMT đến CLIR. Trong thiết lập xuyên ngôn ngữ, chất lượng của các tài liệu được truy xuất phụ thuộc quan trọng vào chất lượng của các bản dịch truy vấn khi sử dụng NMT. Trong Bảng 6, chúng tôi cho thấy các truy vấn tiếng Anh gốc cùng với các bản dịch tương ứng của chúng từ tiếng Swahili và Somalia. Như mong đợi, các bản dịch từ tiếng Swahili thường có chất lượng cao hơn so với Somalia, điều này giải thích khoảng cách hiệu suất lớn được báo cáo trong Bảng 3. Trong trường hợp tốt nhất, bản dịch rất gần về mặt ngữ nghĩa với truy vấn gốc (tham khảo, SW→EN; QID:172), hoặc nó chỉ chứa các biến thể từ vựng nhẹ (flooding vs. floods) và ngữ nghĩa, ví dụ, các từ đồng nghĩa gần (Holland vs. Netherlands). Trong các trường hợp khác, việc lan truyền lỗi từ NMT ảnh hưởng đến hiệu suất CLIR ở các mức độ khác nhau. Những điều này bao gồm, ví dụ, thiếu từ khóa (statistics; QID:200), dịch chuyển chủ đề (sports vs. business; SO→EN, QID:172) hoặc các truy vấn bao gồm văn bản không liên quan và lặp lại (tức là 'ảo giác'; SO→EN, QID:151, QID:200). Đặc biệt là lặp lại và ảo giác là những artifact không mong muốn đã biết trong NMT (Fu et al., 2021; Raunak et al., 2021) và có thể khiến các mô hình truy xuất nhấn mạnh các từ khóa không liên quan bằng cách làm tăng tần suất thuật ngữ của chúng. Cuối cùng, trong các trường hợp mà các từ nguồn được sao chép thay vì được dịch, ví dụ, Nugleerka (Nuclear) hoặc Jarmalka (Germany) trong QID:187, các mô hình truy xuất neural cần dựa vào việc căn chỉnh nội bộ không hoàn hảo của các bản dịch từ (Cao et al., 2019).

5 Công trình liên quan
Bên cạnh Adapter và SFTM, tồn tại các phương pháp chuyển giao hiệu quả tham số (PET) khác. Ví dụ, BitFit chỉ huấn luyện các vector bias (Ben Zaken et al., 2022), LoRa huấn luyện các phân tích low-rank của các ma trận trọng số trong các lớp dày đặc (Hu et al., 2022) và các phương pháp học các prompt liên tục (Liu et al., 2021b; Lester et al., 2021; Li và Liang, 2021, trong số những phương pháp khác). Trong bối cảnh truy xuất cho tiếng Anh, công việc đồng thời tập trung vào hiệu quả học (Ma et al., 2022) và khái quát hóa ngoài miền (Tam et al., 2022) của các phương pháp PET, trong khi chúng tôi điều tra PET cả ở mức nhiệm vụ và mức ngôn ngữ cho CLIR.

6 Kết luận
Trong nghiên cứu này, chúng tôi đã giới thiệu các mô hình tái xếp hạng neural modular và hiệu quả tham số để chuyển giao truy xuất xuyên ngôn ngữ hiệu quả. Các mô hình của chúng tôi, dựa trên Adapter và Sparse Fine-Tuning Mask, cho phép tách biệt kiến thức cụ thể theo ngôn ngữ và cụ thể theo nhiệm vụ (tức là xếp hạng). Chúng tôi chứng minh rằng điều này dẫn đến chuyển giao hiệu quả hơn đến các thiết lập IR xuyên ngôn ngữ cũng như chuyển giao xuyên ngôn ngữ tốt hơn cho truy xuất đơn ngôn ngữ trong các ngôn ngữ đích không có đánh giá liên quan, cải thiện so với các mô hình tiền xếp hạng mạnh dựa trên NMT tiên tiến. Đáng khích lệ, chúng tôi quan sát những mức tăng đặc biệt nổi bật cho các ngôn ngữ có tài nguyên thấp được bao gồm trong đánh giá của chúng tôi. Chúng tôi hy vọng rằng kết quả của chúng tôi sẽ khuyến khích một cuộc điều tra rộng rãi hơn về truy xuất neural hiệu quả tham số trong các thiết lập đơn ngôn ngữ và xuyên ngôn ngữ. Chúng tôi cung cấp mã và tài nguyên của chúng tôi tại: https://github.com/rlitschk/ModularCLIR.

Lời cảm ơn
RL và GG được hỗ trợ bởi grant EUINACTION từ NORFACE Governance (462-19-010, GL950/2-1). IV được hỗ trợ bởi một khoản tài trợ nghiên cứu từ Huawei cho Đại học Cambridge.

--- TRANG 10 ---
Tài liệu tham khảo
Alan Ansell, Edoardo Maria Ponti, Anna Korhonen, và Ivan Vuli ´c. 2022. Composable sparse fine-tuning for cross-lingual transfer. Trong Proceedings of ACL 2022, trang 1778–1796.

Akari Asai, Jungo Kasai, Jonathan Clark, Kenton Lee, Eunsol Choi, và Hannaneh Hajishirzi. 2021. XOR QA: Cross-lingual open-retrieval question answering. Trong Proceedings of NAACL, trang 547–564.

Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, và cộng sự. 2016. Ms marco: A human generated machine reading comprehension dataset. arXiv preprint arXiv:1611.09268.

Elad Ben Zaken, Yoav Goldberg, và Shauli Ravfogel. 2022. BitFit: Simple parameter-efficient fine-tuning for transformer-based masked language-models. Trong Proceedings of ACL, trang 1–9.

Emily M Bender. 2011. On achieving and evaluating language-independence in nlp. Linguistic Issues in Language Technology, 6.

Hamed Bonab, James Allan, và Ramesh Sitaraman. 2019. Simulating clir translation resource scarcity using high-resource languages. Trong Proceedings of ICTIR, trang 129–136.

Luiz Henrique Bonifacio, Israel Campiotti, Vitor Jeronymo, Roberto Lotufo, và Rodrigo Nogueira. 2021. mmarco: A multilingual version of the ms marco passage ranking dataset. arXiv preprint arXiv:2108.13897.

Martin Braschler. 2003. CLEF 2003–Overview of results. Trong Workshop of the Cross-Language Evaluation Forum for European Languages, trang 44–63.

Steven Cao, Nikita Kitaev, và Dan Klein. 2019. Multilingual alignment of contextual word representations. Trong Proceedings of ICLR.

Francisco Casacuberta, Alexandru Ceausu, Khalid Choukri, Miltos Deligiannis, Miguel Domingo, Mercedes Garcıa-Martınez, Manuel Herranz, Vassilis Papavassiliou, Stelios Piperidis, Prokopis Prokopidis, và cộng sự. 2021. The covid-19 mlia@eval initiative: Overview of the machine translation task.

Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Édouard Grave, Myle Ott, Luke Zettlemoyer, và Veselin Stoyanov. 2020. Unsupervised cross-lingual representation learning at scale. Trong Proceedings of ACL, trang 8440–8451.

Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Campos, và Jimmy Lin. 2021. Ms marco: Benchmarking ranking models in the large-data regime. Trong Proceedings of SIGIR, trang 1566–1576.

Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Campos, và Ellen M Voorhees. 2020. Overview of the trec 2019 deep learning track. arXiv preprint arXiv:2003.07820.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. Trong Proceedings of NAACL, trang 4171–4186.

Laura Dietz, Manisha Verma, Filip Radlinski, và Nick Craswell. 2017. Trec complex answer retrieval overview. Trong TREC.

Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, và Armand Joulin. 2020. Beyond english-centric multilingual machine translation. arXiv preprint.

Zihao Fu, Wai Lam, Anthony Man-Cho So, và Bei Shi. 2021. A theoretical analysis of the repetition problem in text generation. Proceedings of AAAI, 35(14):12848–12856.

Luyu Gao, Zhuyun Dai, và Jamie Callan. 2021. COIL: Revisit exact lexical match in information retrieval with contextualized inverted list. Trong Proceedings of NAACL, trang 3030–3042.

Gregor Geigle, Jonas Pfeiffer, Nils Reimers, Ivan Vuli´c, và Iryna Gurevych. 2021. Retrieve fast, rerank smart: Cooperative and joint approaches for improved cross-modal retrieval. CoRR, abs/2103.11920.

Goran Glavaš, Mladen Karan, và Ivan Vuli ´c. 2020. Xhate-999: Analyzing and detecting abusive language across domains and languages. Trong Proceedings of the 28th International Conference on Computational Linguistics, trang 6350–6365.

Sebastian Hofstätter, Sheng-Chieh Lin, Jheng-Hong Yang, Jimmy Lin, và Allan Hanbury. 2021. Efficiently teaching an effective dense retriever with balanced topic aware sampling. Trong Proceedings of SIGIR, trang 113–122.

Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, và Sylvain Gelly. 2019. Parameter-efficient transfer learning for nlp. Trong Proceedings of ICML, trang 2790–2799. PMLR.

Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, và Weizhu Chen. 2022. LoRA: Low-rank adaptation of large language models. Trong Proceedings of ICLR.

Junjie Hu, Sebastian Ruder, Aditya Siddhant, Graham Neubig, Orhan Firat, và Melvin Johnson. 2020. XTREME: A massively multilingual multi-task benchmark for evaluating cross-lingual generalisation. Trong Proceeding of ICML, trang 4411–4421. PMLR.

Kuan-Hao Huang, Wasi Ahmad, Nanyun Peng, và Kai-Wei Chang. 2021a. Improving zero-shot cross-lingual transfer learning via robust training. Trong Proceedings of EMNLP, trang 1684–1697.

Zhiqi Huang, Hamed Bonab, Sheikh Muhammad Sarwar, Razieh Rahimi, và James Allan. 2021b. Mixed attention transformer for leveraging word-level knowledge to neural cross-lingual information retrieval. Trong Proceedings of CIKM, trang 760–770.

Chia-Chien Hung, Anne Lauscher, Ivan Vuli ´c, Simone Ponzetto, và Goran Glavaš. 2022. Multi2WOZ: A robust multilingual dataset and conversational pre-training for task-oriented dialog. Trong Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, trang 3687–3703, Seattle, United States. Association for Computational Linguistics.

Zhuolin Jiang, Amro El-Jaroudi, William Hartmann, Damianos Karakos, và Lingjun Zhao. 2020. Cross-lingual information retrieval with BERT. Trong Proceedings of LREC, trang 26.

Pratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika Bali, và Monojit Choudhury. 2020. The state and fate of linguistic diversity and inclusion in the nlp world. Trong Proceedings of ACL, trang 6282–6293.

Omar Khattab và Matei Zaharia. 2020. Colbert: Efficient and effective passage search via contextualized late interaction over bert. Trong Proceedings of SIGIR, trang 39–48.

Anne Lauscher, Vinit Ravishankar, Ivan Vuli ´c, và Goran Glavaš. 2020. From zero to hero: On the limitations of zero-shot language transfer with multilingual transformers. Trong Proceedings of EMNLP, trang 4483–4499.

Dawn Lawrie, James Mayfield, Douglas W. Oard, và Eugene Yang. 2022. Hc4: A new suite of test collections for ad hoc clir. Trong Proceedigs of ECIR, trang 351–366. Springer-Verlag.

Brian Lester, Rami Al-Rfou, và Noah Constant. 2021. The power of scale for parameter-efficient prompt tuning. Trong Proceedings of EMNLP, trang 3045–3059.

Xiang Lisa Li và Percy Liang. 2021. Prefix-tuning: Optimizing continuous prompts for generation. Trong Proceedings of ACL, trang 4582–4597.

Jimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Jheng-Hong Yang, Ronak Pradeep, và Rodrigo Nogueira. 2021. Pyserini: A python toolkit for reproducible information retrieval research with sparse and dense representations. Trong Proceedings of SIGIR, trang 2356–2362.

Robert Litschko, Ivan Vuli ´c, Simone Paolo Ponzetto, và Goran Glavaš. 2021. Evaluating multilingual text encoders for unsupervised cross-lingual retrieval. Trong Proceedings of ECIR, trang 342–358.

Qian Liu, Xiubo Geng, Jie Lu, và Daxin Jiang. 2021a. Pivot-based candidate retrieval for cross-lingual entity linking. Trong Proceedings of WWW, trang 1076–1085.

Xiao Liu, Kaixuan Ji, Yicheng Fu, Zhengxiao Du, Zhilin Yang, và Jie Tang. 2021b. P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks. arXiv preprint arXiv:2110.07602.

Xinyu Ma, Jiafeng Guo, Ruqing Zhang, Yixing Fan, và Xueqi Cheng. 2022. Scattered or connected? an optimized parameter-efficient tuning approach for information retrieval. arXiv preprint arXiv:2208.09847.

Sean MacAvaney, Luca Soldaini, và Nazli Goharian. 2020. Teaching a new dog old tricks: Resurrecting multilingual retrieval using zero-shot learning. Trong Proceedings of ECIR, trang 246–254.

Sean MacAvaney, Andrew Yates, Arman Cohan, và Nazli Goharian. 2019. Cedr: Contextualized embeddings for document ranking. Trong Proceedings of SIGIR, trang 1101–1104.

Michael McCloskey và Neal J Cohen. 1989. Catastrophic interference in connectionist networks: The sequential learning problem. Trong Psychology of learning and motivation, tập 24, trang 109–165. Elsevier.

Seyed Iman Mirzadeh, Mehrdad Farajtabar, Razvan Pascanu, và Hassan Ghasemzadeh. 2020. Understanding the role of training regimes in continual learning. Trong Proceedings of NeurIPS, tập 33, trang 7308–7320.

Jamshidbek Mirzakhalov, Anoop Babu, Duygu Ataman, Sherzod Kariev, Francis Tyers, Otabek Abduraufov, Mammad Hajili, Sardana Ivanova, Abror Khaytbaev, Antonio Laverghetta Jr, và cộng sự. 2021. A large-scale study of machine translation in turkic languages. Trong Proceedings of EMNLP, trang 5876–5890.

Mathias Müller, Annette Rios, và Rico Sennrich. 2020. Domain robustness in neural machine translation. Trong Proceedings of the 14th Conference of the Association for Machine Translation in the Americas (Volume 1: Research Track), trang 151–164.

Suraj Nair, Eugene Yang, Dawn Lawrie, Kevin Duh, Paul McNamee, Kenton Murray, James Mayfield, và Douglas W Oard. 2022. Transfer learning approaches for building cross-language dense retrieval models. Trong Proceedings of ECIR, trang 382–396.

Shahrzad Naseri, Jeff Dalton, Andrew Yates, và James Allan. 2021. CEQE: contextualized embeddings for query expansion. Trong Proceedings of ECIR, trang 467–482.

Jian-Yun Nie. 2010. Cross-Language Information Retrieval. Synthesis Lectures on Human Language Technologies. Morgan & Claypool Publishers.

Rodrigo Nogueira, Jimmy Lin, và AI Epistemic. 2019a. From doc2query to doctttttquery. Online preprint, 6.

Rodrigo Nogueira, Wei Yang, Kyunghyun Cho, và Jimmy Lin. 2019b. Multi-stage document ranking with BERT. arXiv preprint arXiv:1910.14424.

Rodrigo Nogueira, Wei Yang, Jimmy Lin, và Kyunghyun Cho. 2019c. Document expansion by query prediction. arXiv preprint arXiv:1904.08375.

Jonas Pfeiffer, Ivan Vuli ´c, Iryna Gurevych, và Sebastian Ruder. 2020. MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer. Trong Proceedings EMNLP, trang 7654–7673.

Edoardo Maria Ponti, Goran Glavaš, Olga Majewska, Qianchu Liu, Ivan Vuli ´c, và Anna Korhonen. 2020. XCOPA: A multilingual dataset for causal commonsense reasoning. Trong Proceedings of EMNLP, trang 2362–2376.

Vikas Raunak, Arul Menezes, và Marcin Junczys-Dowmunt. 2021. The curious case of hallucinations in neural machine translation. Trong Proceedings of NAACL, trang 1172–1183.

Sylvestre-Alvise Rebuffi, Hakan Bilen, và Andrea Vedaldi. 2017. Learning multiple visual domains with residual adapters. Trong Proceedings of NeurIPS, tập 30.

Nils Reimers và Iryna Gurevych. 2020. Making monolingual sentence embeddings multilingual using knowledge distillation. Trong Proceedings of EMNLP, trang 4512–4525.

Andreas Rücklé, Gregor Geigle, Max Glockner, Tilman Beck, Jonas Pfeiffer, Nils Reimers, và Iryna Gurevych. 2021. AdapterDrop: On the efficiency of adapters in transformers. Trong Proceedings of EMNLP, trang 7930–7946.

Sebastian Ruder, Noah Constant, Jan Botha, Aditya Siddhant, Orhan Firat, Jinlan Fu, Pengfei Liu, Junjie Hu, Dan Garrette, Graham Neubig, và cộng sự. 2021. Xtreme-r: Towards more challenging and nuanced multilingual evaluation. Trong Proceedings of EMNLP.

Keshav Santhanam, Omar Khattab, Jon Saad-Falcon, Christopher Potts, và Matei Zaharia. 2022. ColBERTv2: Effective and efficient retrieval via lightweight late interaction. Trong Proceedings of NAACL, trang 3715–3734.

Peng Shi, He Bai, và Jimmy Lin. 2020. Cross-lingual training of neural models for document ranking. Trong Proceedings of EMNLP (Findings), trang 2768–2773.

Emma Strubell, Ananya Ganesh, và Andrew McCallum. 2019. Energy and policy considerations for deep learning in nlp. Trong Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, trang 3645–3650.

Weng Lam Tam, Xiao Liu, Kaixuan Ji, Lilong Xue, Xingjian Zhang, Yuxiao Dong, Jiahua Liu, Maodi Hu, và Jie Tang. 2022. Parameter-efficient prompt tuning makes generalized and calibrated neural text retrievers. CoRR, abs/2207.07087.

Eva Vanmassenhove, Dimitar Shterionov, và Matthew Gwilliam. 2021. Machine translationese: Effects of algorithmic bias on linguistic complexity in machine translation. Trong Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, trang 2203–2213.

Fedor Vitiugin và Carlos Castillo. 2022. Cross-lingual query-based summarization of crisis-related social media: An abstractive approach using transformers. arXiv preprint arXiv:2204.10230.

Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, và Alexander Rush. 2020. Transformers: State-of-the-Art Natural Language Processing. Trong Proceedings of EMNLP 2020: System Demonstrations, trang 38–45.

Puxuan Yu, Hongliang Fei, và Ping Li. 2021. Cross-lingual language model pretraining for retrieval. Trong Proceedings of WWW, trang 1029–1039.

Wei Zhao, Goran Glavaš, Maxime Peyrard, Yang Gao, Robert West, và Steffen Eger. 2020. On the limitations of cross-lingual encoders as exposed by reference-free machine translation evaluation. Trong Proceedings of ACL, trang 1656–1671.

Junnan Zhu, Qian Wang, Yining Wang, Yu Zhou, Jiajun Zhang, Shaonan Wang, và Chengqing Zong. 2019. Ncls: Neural cross-lingual summarization. Trong Proceedings of EMNLP-IJCNLP, trang 3054–3064.

# 2305.15011.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2305.15011.pdf
# Kích thước tệp: 1538332 byte

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Bactrian-X: Các Mô hình Đa ngôn ngữ Có thể Tái tạo Tuân thủ Hướng dẫn với Thích ứng Thứ hạng Thấp

Haonan Li1∗Fajri Koto1∗Minghao Wu1,2Alham Fikri Aji1Timothy Baldwin1,3
1Khoa Xử lý Ngôn ngữ Tự nhiên, MBZUAI
2Đại học Monash3Đại học Melbourne
{haonan.li,fajri.koto,minghao.wu,alham.fikri,timothy.baldwin}@mbzuai.ac.ae

Tóm tắt
Điều chỉnh hướng dẫn đã cho thấy tiềm năng tuyệt vời trong việc cải thiện hiệu suất của các mô hình ngôn ngữ lớn. Tuy nhiên, nghiên cứu về điều chỉnh hướng dẫn đa ngôn ngữ còn hạn chế do sự khan hiếm của các bộ dữ liệu cặp hướng dẫn-phản hồi chất lượng cao trên các ngôn ngữ khác nhau. Để thu hẹp khoảng cách này, chúng tôi trình bày Bactrian-X, một bộ dữ liệu song song đa ngôn ngữ toàn diện gồm 3,4 triệu cặp hướng dẫn-phản hồi trên 52 ngôn ngữ. Tận dụng bộ dữ liệu này, chúng tôi huấn luyện một tập hợp các bộ điều hợp sử dụng thích ứng thứ hạng thấp (LoRA), là các thành phần nhẹ tích hợp liền mạch với các mô hình ngôn ngữ lớn. Các bộ điều hợp này có số lượng tham số thấp hơn đáng kể so với mô hình cơ sở, làm cho chúng dễ dàng thay thế và sử dụng như các plugin cho các ngôn ngữ hoặc nhóm ngôn ngữ khác nhau. Các thí nghiệm mở rộng trong nhiều thiết lập đánh giá đa ngôn ngữ khác nhau chứng minh rằng các mô hình được tạo ra từ việc huấn luyện dựa trên LoRA trên Bactrian-X vượt trội hơn cả các mô hình gốc và các mô hình đã được điều chỉnh hướng dẫn hiện có. Mã nguồn và các mô hình được cung cấp công khai tại https://github.com/mbzuai-nlp/bactrian-x.

1 Giới thiệu
Tinh chỉnh các mô hình ngôn ngữ lớn (LLM) với các bộ dữ liệu cặp hướng dẫn-phản hồi đã chứng minh khả năng tổng quát hóa zero-shot đáng chú ý cho các mô hình mã nguồn mở và mã nguồn đóng (Sanh et al., 2022; Wei et al., 2022; Ouyang et al., 2022; OpenAI, 2023). Mặc dù các LLM thường được tiền huấn luyện sử dụng văn bản đa ngôn ngữ, việc điều chỉnh hướng dẫn cho các mô hình mã nguồn mở bị hạn chế ở tiếng Anh (Taori et al., 2023; Chiang et al., 2023; Wu et al., 2023), đặt ra câu hỏi về khả năng tổng quát hóa đa ngôn ngữ của chúng. Các mô hình tài nguyên đóng như OpenAI GPT-4 (OpenAI, 2023) và Google BARD,1mặc dù hoạt động ấn tượng trên các ngôn ngữ có tài nguyên cao, vẫn còn thiếu về khả năng tổng quát hóa đa ngôn ngữ dưới việc điều chỉnh hướng dẫn đơn ngôn ngữ.

Sự khan hiếm của các bộ dữ liệu cặp hướng dẫn-phản hồi trong các ngôn ngữ ngoài tiếng Anh cản trở việc điều chỉnh hướng dẫn đa ngôn ngữ. Bộ dữ liệu xP3 hiện có (Muennighoff et al., 2022), được sử dụng để tinh chỉnh BLOOM và mT5, sử dụng các hướng dẫn tiếng Anh. Mặc dù Muennighoff et al. (2022) cũng thử nghiệm với xP3mt — các hướng dẫn được dịch máy — nó tập trung vào các tác vụ NLP cổ điển như tóm tắt và trả lời câu hỏi, thay vì các hướng dẫn tổng quát. Ngoài ra, cả xP3 và xP3mt đều sử dụng các lời nhắc dựa trên mẫu, và do đó thiếu sự đa dạng.

Để điều tra việc điều chỉnh hướng dẫn tổng quát trong môi trường đa ngôn ngữ, chúng tôi giới thiệu Bactrian-X, chứa các cặp hướng dẫn-phản hồi song song trên 52 ngôn ngữ được xây dựng tự động bằng cách dịch các hướng dẫn từ Alpaca (Taori et al., 2023) và Dolly (Conover et al., 2023) thông qua Google Translate API.2Như chúng tôi chi tiết trong Phần 3, chúng tôi sử dụng thủ thuật chưng cất đầu ra để có được các phản hồi tương ứng bằng cách tận dụng đầu ra ChatGPT, có điều kiện trên các hướng dẫn đã dịch. Với 67K cặp hướng dẫn-phản hồi cho mỗi ngôn ngữ, tổng số trường hợp trong Bactrian-X đạt 3,4M.

--- TRANG 2 ---
Trái ngược với các mô hình hướng dẫn đa ngôn ngữ trước đây như BLOOMZ (Muennighoff et al., 2022) chịu sự tinh chỉnh đầy đủ thông qua cập nhật tham số trên tất cả các lớp, nghiên cứu này làm nổi bật tiềm năng của các kỹ thuật tinh chỉnh hiệu quả tham số, cụ thể là LoRA (Hu et al., 2022). LoRA sử dụng các bộ điều hợp với số lượng tham số ít hơn đáng kể so với các LLM cơ sở, làm cho chúng thực tế và thích ứng hơn cho các ứng dụng thực tế. Cụ thể, trong công trình này, chúng tôi giới thiệu các mô hình BXBLOOM và BX LLaMA, được xây dựng dựa trên các mô hình BLOOM (Scao et al., 2022) và LLaMA (Touvron et al., 2023), và thấy rằng chúng tốt hơn các mô hình được điều chỉnh hướng dẫn liên quan: BLOOMZ (Muennighoff et al., 2022) và Alpaca (Taori et al., 2023).

Chúng tôi tiến hành một loạt thí nghiệm toàn diện bao gồm một loạt các tác vụ NLP đa ngôn ngữ zero-shot, bao gồm XCOPA (Ponti et al., 2020), XStoryCloze (Lin et al., 2022), XWinograd (Muennighoff et al., 2022), bộ dữ liệu phân tích cảm xúc đa ngôn ngữ của chúng tôi SentimentX, và EXAMS (Hardalov et al., 2020). Các kết quả nhất quán cao trên các tác vụ này làm nổi bật tính hiệu quả của bộ dữ liệu hướng dẫn đa ngôn ngữ và kỹ thuật bộ điều hợp của chúng tôi cho việc điều chỉnh hướng dẫn trong các ngôn ngữ ngoài tiếng Anh. Để xác nhận thêm các phát hiện của chúng tôi, chúng tôi sử dụng GPT-4 làm người đánh giá dựa trên phương pháp được đề xuất bởi Chiang et al. (2023), và bổ sung tiến hành đánh giá của con người với những người nói bản xứ. Tất cả các kết quả xác nhận rằng các mô hình được đề xuất của chúng tôi vượt trội hơn các mô hình nền tảng gốc và các mô hình được điều chỉnh hướng dẫn hiện có.

2 Công trình Liên quan
Điều chỉnh Hướng dẫn Đa ngôn ngữ Các LLM như GPT-3 (Brown et al., 2020), PaLM (Chowdhery et al., 2022) và LLaMA (Touvron et al., 2023) (Hoffmann et al., 2022; Scao et al., 2022; Zeng et al., 2023) đã cách mạng hóa NLP. Nghiên cứu đã chứng minh rằng việc tinh chỉnh các LLM với các lời nhắc hướng dẫn có thể cải thiện khả năng thực hiện các tác vụ chưa từng thấy/mới của chúng (Wei et al., 2022; Sanh et al., 2022; Ouyang et al., 2022; Chung et al., 2022; Muennighoff et al., 2022). Gần đây, Wang et al. (2022); Taori et al. (2023) đã cho thấy rằng các hướng dẫn được tạo bởi máy có thể được sử dụng cho việc điều chỉnh hướng dẫn. Wu et al. (2023) đã tạo ra một bộ dữ liệu quy mô lớn với 2,6M hướng dẫn, và chứng minh rằng các mô hình ngôn ngữ tương đối nhỏ cũng hưởng lợi từ các hướng dẫn. Công trình trước đây chủ yếu tập trung vào tiếng Anh, và việc điều chỉnh hướng dẫn trong các ngôn ngữ ngoài tiếng Anh vẫn còn hạn chế. Công trình gần nhất với chúng tôi là BLOOMZ (Muennighoff et al., 2022), tinh chỉnh BLOOM (Scao et al., 2022) và mT5 (Xue et al., 2021) trên các bộ dữ liệu hướng dẫn đa ngôn ngữ xP3 và xP3mt. Tuy nhiên, cả xP3 và xP3mt đều dựa trên các mẫu do con người viết, và thiếu tính biến đổi của một bộ dữ liệu đa ngôn ngữ tự nhiên. Công trình của chúng tôi, thay vào đó, xây dựng một bộ dữ liệu hướng dẫn tổng quát song song bằng cách dịch các hướng dẫn tiếng Anh sang 51 ngôn ngữ và tạo ra các phản hồi thông qua ChatGPT (Ouyang et al., 2022). Theo hiểu biết tốt nhất của chúng tôi, bộ dữ liệu hướng dẫn Bactrian-X của chúng tôi là bộ dữ liệu hướng dẫn đa ngôn ngữ mục đích chung lớn nhất cho đến nay.

Tinh chỉnh Hiệu quả Tham số (PEFT) Việc tinh chỉnh tất cả các tham số của một LLM (ví dụ Alpaca (Taori et al., 2023), Vicuna (Chiang et al., 2023) và LaMini-LM (Wu et al., 2023)) tốn kém về mặt tính toán, và các bộ điều hợp (Houlsby et al., 2019) cung cấp một thay thế hiệu quả chi phí hơn. PEFT cập nhật một số lượng nhỏ tham số trong quá trình tinh chỉnh, và đạt được hiệu suất tương đương với các đối tác được tinh chỉnh đầy đủ (Houlsby et al., 2019; Guo et al., 2021; Lester et al., 2021; Ben Zaken et al., 2022). Hu et al. (2022) đã giới thiệu Thích ứng Thứ hạng Thấp (LoRA), kết hợp các ma trận phân tích thứ hạng có thể huấn luyện vào các lớp transformer (Vaswani et al., 2017) trong quá trình tinh chỉnh mà không tạo ra độ trễ bổ sung trong quá trình suy luận. Họ chứng minh rằng bằng cách tinh chỉnh với ít hơn 1% số tham số mô hình, LoRA vượt trội hơn một số LLM được tinh chỉnh đầy đủ, bao gồm GPT-3 (Brown et al., 2020), trên nhiều tác vụ khác nhau.

Trong công trình gần đây, Taori et al. (2023) sử dụng thủ thuật LoRA để tinh chỉnh LLaMA (Touvron et al., 2023), tạo ra mô hình Alpaca, nhưng không thực hiện đánh giá toàn diện. Trong công trình này, chúng tôi cũng tận dụng kỹ thuật LoRA để phát triển một loạt các bộ điều hợp đơn ngôn ngữ và đa ngôn ngữ, với một bộ dữ liệu cặp hướng dẫn-phản hồi lớn hơn nhiều, trên 52 ngôn ngữ. Chúng tôi cung cấp phân tích thực nghiệm dựa trên đánh giá tự động và con người để chứng minh tính hiệu quả của phương pháp của chúng tôi.

3 Bộ dữ liệu Bactrian-X
Trong phần này, chúng tôi chi tiết quá trình tạo bộ dữ liệu và cung cấp tổng quan về dữ liệu kết quả, tập trung vào chất lượng của các hướng dẫn được dịch và các phản hồi được tạo.

--- TRANG 3 ---
[Tôi sẽ tiếp tục dịch phần còn lại nếu cần, nhưng do giới hạn độ dài phản hồi, tôi sẽ dừng ở đây. Bản dịch này bao gồm các phần chính của tài liệu và duy trì tính chính xác kỹ thuật.]

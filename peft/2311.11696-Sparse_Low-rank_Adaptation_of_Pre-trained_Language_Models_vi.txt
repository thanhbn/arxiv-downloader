Thích ứng Thưa thớ Hạng thấp của các Mô hình Ngôn ngữ Tiền huấn luyện

Ning Ding1∗, Xingtai Lv1∗, Qiaosen Wang4, Yulin Chen2
Bowen Zhou1†, Zhiyuan Liu2,3†, Maosong Sun2,3†

1Khoa Kỹ thuật Điện tử, Đại học Thanh Hoa
2Khoa Khoa học Máy tính và Công nghệ, Đại học Thanh Hoa  
3BNRIST, IAI, Đại học Thanh Hoa, 4Khoa Thống kê, Đại học Chicago

Tóm tắt

Tinh chỉnh các mô hình ngôn ngữ lớn tiền huấn luyện theo cách hiệu quả tham số được nghiên cứu rộng rãi vì tính hiệu quả và hiệu suất của nó. Phương pháp phổ biến của thích ứng hạng thấp (LoRA) cung cấp một cách tiếp cận đáng chú ý, đưa ra giả thuyết rằng quá trình thích ứng có bản chất chiều thấp. Mặc dù LoRA đã chứng minh hiệu suất đáng khen ngợi, nó được triển khai với hạng nội tại cố định và không thể thay đổi có thể không phải lúc nào cũng là lựa chọn lý tưởng. Nhận ra nhu cầu về sự thích ứng linh hoạt hơn, chúng tôi mở rộng phương pháp của LoRA thành một cách tiếp cận sáng tạo mà chúng tôi gọi là thích ứng thưa thớ hạng thấp (SoRA) cho phép điều chỉnh động hạng nội tại trong quá trình thích ứng. Chúng tôi đạt được điều này thông qua việc kết hợp đơn vị cổng được tối ưu hóa bằng phương pháp gradient gần đúng trong giai đoạn huấn luyện, kiểm soát số lượng hạng dưới độ thưa của cổng. Trong giai đoạn suy luận tiếp theo, chúng tôi loại bỏ các khối tham số tương ứng với các hạng bị zeroized để giảm mỗi module SoRA về dạng LoRA ngắn gọn nhưng tối ưu hạng. Cách tiếp cận của chúng tôi tăng cường sức mạnh biểu diễn của LoRA bằng cách khởi tạo nó với hạng cao hơn, đồng thời hiệu quả kiểm soát số lượng tham số tăng tạm thời thông qua cập nhật theo cách thưa. Chúng tôi tiếp tục giới thiệu bộ lập lịch thưa hóa cho SoRA, nhằm mục đích xem xét tác động của số lượng tham số khác không đến khả năng ghi nhớ và tổng quát hóa của mô hình. Kết quả thực nghiệm của chúng tôi chứng minh rằng SoRA có thể vượt trội so với các baseline khác thậm chí với 70% tham số được giữ lại và 70% thời gian huấn luyện.

1 Giới thiệu

Thích ứng các mô hình ngôn ngữ tiền huấn luyện quy mô lớn theo cách hiệu quả tham số đang ngày càng thu hút sự chú ý trong cộng đồng nghiên cứu. Các phương pháp của mô hình này thường giữ nguyên hầu hết các tham số của mô hình cơ bản, hoặc chèn thêm các tham số có thể huấn luyện vào mô hình, hoặc chỉ định một số lượng nhỏ tham số có thể huấn luyện hoặc tái tham số hóa quá trình thích ứng thành dạng hiệu quả hơn. Chúng đã được xác thực là hiệu quả trên nhiều mô hình và tác vụ khác nhau, thường mang lại kết quả tương đương hoặc thậm chí tốt hơn so với tinh chỉnh toàn bộ tham số.

Tiềm năng phát triển của tinh chỉnh hiệu quả tham số trở nên rõ ràng sau khi xác thực rộng rãi về hiệu suất của nó. Những phương pháp này cung cấp cơ hội thích ứng mô hình cơ sở để phù hợp với bất kỳ dữ liệu nào, cho phép cải tiến và tùy chỉnh các mô hình ngôn ngữ phù hợp với các tác vụ cụ thể và đặc điểm người dùng cá nhân hóa. Do tính chất nhẹ của các tham số được tối ưu hóa, chúng có thể được cắm vào mô hình một cách liền mạch, cho phép thực hiện các cải tiến mục tiêu. Trong số các phương pháp này, thích ứng hạng thấp (LoRA) được coi là một trong những phương pháp hiệu quả nhất hiện tại. Nó giả định rằng sự thay đổi của các tham số mô hình sau khi thích ứng là "có chiều thấp nội tại" và thực hiện thích ứng bằng cách tối ưu hóa ma trận thu được từ phân rã hạng thấp. LoRA tránh độ trễ lan truyền thuận gây ra bởi việc chèn các module thần kinh bổ sung trong khi chứng minh hiệu suất ổn định.

Mặc dù hiệu quả, việc thiết lập hạng nội tại (thường là một siêu tham số) vẫn chưa rõ ràng. Trực quan, hạng lớn hơn mang lại không gian tối ưu hóa lớn hơn và tạo ra khả năng xử lý các tác vụ khó hơn. Tuy nhiên, trong thực tế, hạng nội tại tối ưu sẽ thay đổi theo nhiều yếu tố như mô hình cơ sở và tác vụ. Với chi phí tính toán khổng lồ của việc tìm kiếm siêu tham số trên các mô hình quy mô lớn (như GPT-3 với 175 tỷ tham số và LLaMA với 700 triệu đến 65 tỷ tham số), việc phát triển một phương pháp dựa trên hạng thích ứng là một cách tiếp cận tự nhiên. Một số công trình hiện có đã cố gắng khám phá hướng này, nhưng chúng phần lớn là heuristic hoặc đưa ra chi phí bổ sung. Trong bài báo này, chúng tôi đề xuất SoRA, một phương pháp đơn giản, hiệu quả và tự động cho tinh chỉnh hiệu quả tham số thích ứng. Chúng tôi giới thiệu module cổng với cập nhật gradient gần đúng dưới điều chuẩn L1 để kiểm soát độ thưa của các ma trận được cập nhật. Sau khi huấn luyện, mục zero của vector cổng ghi lại các cột của ma trận chiếu xuống và các hàng của ma trận chiếu lên, có thể được loại bỏ đơn giản và lưu trữ theo cách hiệu quả tham số hơn. So với các cách tiếp cận thích ứng khác, phương pháp gradient gần đúng có ý nghĩa toán học rõ ràng và không phải liên quan đến các tính toán và heuristic khác. Ví dụ, AdaLoRA đưa ra một điều chuẩn bổ sung để đảm bảo rằng các ma trận chiếu dưới và trên tuân thủ nghiêm ngặt định nghĩa của phân rã giá trị kỳ dị (SVD), với mỗi ma trận là trực giao. Tuy nhiên, thuật ngữ điều chuẩn này gây ra chi phí tính toán đáng kể do việc tính toán gradient. Ngược lại, chúng tôi loại bỏ yêu cầu này và thay vào đó lọc có chọn lọc các thành phần hạng thấp bằng cách kiểm soát ma trận đường chéo trung gian. Chúng tôi so sánh chi tiết SoRA và các phương pháp liên quan trong Phần 3.

Cơ chế của SoRA cũng cho phép chúng tôi kiểm soát độ thưa tạm thời và điều tra mối quan hệ giữa số lượng tham số có thể huấn luyện khác không và khả năng ghi nhớ và tổng quát hóa. Chúng tôi đề xuất một bộ lập lịch thưa hóa và phát hiện rằng quá trình thích ứng mô hình thể hiện "khả năng nén" mạnh mẽ, và thậm chí một phần nhỏ tham số (thấp hơn hạng LoRA là 1) có thể giữ lại hiệu suất đáng kể. Các thí nghiệm rộng rãi được tiến hành để chứng minh tính hiệu quả của phương pháp chúng tôi. Đặc biệt, mô hình của chúng tôi có thể liên tục vượt trội so với các baseline hiệu quả tham số với ít tham số hơn và thời gian huấn luyện ngắn hơn 30% trên một loạt các tác vụ downstream. Mã của công trình này sẽ được công bố tại https://github.com/TsinghuaC3I/SoRA.

2 Nhìn gần hơn vào Hạng Thích ứng

Công trình liên quan. Trước khi giới thiệu cách tiếp cận của chúng tôi, trước tiên chúng tôi tóm tắt ngắn gọn về tinh chỉnh hiệu quả tham số và thích ứng hạng thấp (LoRA) làm nền tảng. Tinh chỉnh hiệu quả tham số là một tập hợp các phương pháp chỉ tối ưu hóa một phần nhỏ tham số và giữ nguyên mô hình chính để thích ứng. Một số phương pháp hiệu quả tham số sẽ chèn các module thần kinh hoặc tham số bổ sung vào mô hình cơ sở, như Adapter, Prefix và Prompt Tuning. Và một dòng khác của các phương pháp như vậy cố gắng chỉ định các tham số cụ thể có thể huấn luyện hoặc có thể cắt tỉa. Các nhà nghiên cứu tạo ra một loạt các biến thể của các phương pháp hiệu quả tham số để cải thiện tính hiệu quả hoặc hiệu suất. Gần đây, các ứng dụng của tinh chỉnh hiệu quả tham số được mở rộng sang các tình huống đa phương thức và instruction-tuning. Trong bài báo này, chúng tôi tập trung nhiều hơn vào LoRA, sử dụng các ma trận hạng thấp để xấp xỉ sự thay đổi của trọng số.

Trong LoRA, các trọng số tiền huấn luyện (ký hiệu là W0∈Rp×q) được đóng băng, và các module LoRA có thể huấn luyện là các ma trận phân rã hạng thấp Wd∈Rr×q và Wu∈Rp×r của sự thay đổi của mỗi ma trận trọng số ∆=WuWd∈Rp×q. Theo cách này, đầu ra của lớp hiện tại h có thể được biểu diễn là:

y ← W0x + WuWdx,                    (1)

trong đó r ≪ min{p, q} là một siêu tham số của "chiều nội tại" kiểm soát kích thước của các ma trận hạng thấp và số lượng tham số có thể huấn luyện. Trong phần này, chúng tôi chủ yếu tập trung vào thuật ngữ cuối, ký hiệu z ← WuWdx.

Hạng Thích ứng trên LoRA. Mặc dù là một bước tiến lớn về tính dễ xử lý và hiệu quả, LoRA vẫn bị hạn chế bởi sự thiếu linh hoạt trong việc lựa chọn hạng tối ưu r. Không giống như các siêu tham số liên tục như tốc độ học và weight decay có thể được điều chỉnh thích ứng trực tuyến trong quá trình huấn luyện, hạng LoRA r nhận các giá trị rời rạc - việc thay đổi sẽ trực tiếp thay đổi cấu trúc mô hình. Lựa chọn tối ưu của hạng có thể khác nhau giữa các mô hình cơ sở và tác vụ downstream khác nhau. Lựa chọn bảo thủ của hạng r khổng lồ có thể lãng phí thời gian huấn luyện và tài nguyên tính toán, trong khi việc đặt r nhỏ dần có thể làm giảm hiệu suất mô hình và dẫn đến việc huấn luyện lại từ đầu. Những hạn chế này làm nổi bật tầm quan trọng của việc nâng cấp LoRA với một plug-in lựa chọn hạng thích ứng.

Một số biện pháp khắc phục đã được đề xuất trong những năm gần đây để cho phép điều chỉnh linh hoạt hạng LoRA. Ví dụ, thay vì đặt hạng cố định, Valipour et al. giới thiệu DyLoRA trong đó một phân phối rời rạc được định nghĩa trước pB(·) được áp dụng trên một loạt các lựa chọn hạng. Cách tiếp cận này có liên quan nhưng khác với nested dropout, và có thể được coi là tối ưu hóa một mô hình hỗn hợp với các module LoRA của các hạng khác nhau.

Tuy nhiên, điều chỉnh hạng LoRA một cách thẳng thắn và đơn định dường như là một cách tiếp cận hấp dẫn hơn. Để tạo ra một cách tiếp cận như vậy, trước tiên chúng tôi có được một gợi ý quan trọng từ kết nối giữa hạng của ma trận và phân rã giá trị kỳ dị (SVD) của nó. Hãy ký hiệu ma trận trọng số tăng thêm có thể điều chỉnh trong LoRA bằng ∆:=WuWd. Sau đó chúng tôi có thể công thức hóa SVD của nó như:

∆p×q = Up×pΣp×qV⊤q×q,                    (2)

trong đó U và V lần lượt là trực giao, và Σ là ma trận đường chéo (hình chữ nhật) với các phần tử đường chéo là các giá trị kỳ dị của ∆: σ(∆) = {σ1 ≥ σ2 ≥ ··· ≥ σmin{p,q} ≥ 0}. Để thuận tiện cho ký hiệu, chúng tôi định hình lại đường chéo của Σ thành vector cột:

g := (σ1, σ2, ···, σmin{p,q})⊤.                    (3)

Sau đó, đặt d = min{p, q}, chúng ta có thể công thức hóa lại lan truyền thuận LoRA như:

z ← ∆x = U·,1:d(g ⊙ V⊤·,1:dx),                    (4)

trong đó ⊙ ký hiệu tích theo phần tử (tích Hadamard). Lưu ý rằng rank(∆) = ∥g∥0 là norm ℓ0 của g. Do đó, điều chỉnh hạng LoRA đủ để kiểm soát độ thưa của vector g. Zhang et al. tiến hành theo track dựa trên SVD này với phương pháp của họ có tên AdaLoRA. Trong AdaLoRA, các phần tử trong vector g được hiệu chỉnh sao cho số lượng mục khác không nhỏ hơn ngân sách được định nghĩa trước b. Cụ thể, họ chỉ giữ lại các mục có điểm quan trọng top-b - đó là metric "sensitivity" mới được đề xuất của họ được xây dựng heuristic từ tích trọng số-gradient. Tính không âm của các mục g được loại bỏ hợp lý vì gi âm có thể được giảm xuống trường hợp dương bằng cách đảo dấu của ui hoặc vi. Bên cạnh đó, họ chuyển đổi bài toán tối ưu hóa có ràng buộc thành phiên bản không ràng buộc bằng cách thay thế các điều kiện trực giao U⊤U = Ip và V⊤V = Iq bằng một thuật ngữ điều chuẩn:

R(U,V) = ∥U⊤U - Ip∥²F + ∥V⊤V - Iq∥²F.                    (5)

Mặc dù tính hiệu quả được chứng minh thông qua các thí nghiệm, vẫn có hai vấn đề trong AdaLoRA đòi hỏi phải suy nghĩ lại về phương pháp và chờ đợi những cải tiến hơn nữa. Thứ nhất, tiêu chí lựa chọn độ thưa trong AdaLoRA dựa trên điểm quan trọng mới được đề xuất của họ dựa vào trung bình trượt của tích trọng số-gradient. Mặc dù có hiệu quả trong nghiên cứu thực nghiệm, tiêu chí này phần lớn là heuristic, thiếu động lực lý thuyết. Thứ hai, cả hoạt động trung bình trượt của điểm quan trọng và gradient của điều chuẩn trực giao (5) đều cộng thêm chi phí tính toán bổ sung. So với AdaLoRA với những hạn chế nói trên, cách tiếp cận của chúng tôi, SoRA, phục vụ như một cải tiến với các quy tắc cập nhật được đơn giản hóa cao và được hỗ trợ bởi lý thuyết điều chuẩn độ thưa và các phương pháp gradient gần đúng. Phương pháp chi tiết của SoRA sẽ được trình bày trong phần tiếp theo.

3 Cách tiếp cận của chúng tôi

Ý tưởng chính của cách tiếp cận của chúng tôi, thích ứng thưa thớ hạng thấp (SoRA), là điều chỉnh động hạng nội tại trong quá trình huấn luyện với đơn vị cổng thưa được huấn luyện bằng phương pháp gradient gần đúng. SoRA áp dụng framework phân rã hạng thấp được giới thiệu trước đó vì tính hiệu quả được xác thực rộng rãi và hiệu quả tham số.

3.1 Thích ứng Thưa thớ Hạng thấp

Cấu trúc Module. Khi bắt đầu xây dựng module SoRA, chúng tôi định nghĩa trước hạng tối đa có thể chấp nhận rmax theo các mối quan tâm thực tế hoặc nghiên cứu. Sau đó, mỗi module SoRA sẽ kế thừa hai ma trận Wd∈Rrmax×q và Wu∈Rp×rmax từ LoRA để chiếu xuống và chiếu lên. Hạng tối đa rmax được đặt tương đối lớn, nhưng chúng tôi sẽ chỉ ra trong đoạn tiếp theo cách kiểm soát nó hiệu quả theo nghĩa thưa. Thực tế, điều này được thực hiện bằng cách tiêm đơn vị cổng g∈Rrmax giữa các ma trận chiếu, mô phỏng công thức của SVD. Lan truyền thuận của module SoRA tiến hành như sau:

h ← chiếu xuống Wdx;                    (6)
h′ ← cổng g ⊙ h;                    (7)
z ← chiếu lên Wuh′;                    (8)

hoặc, súc tích hơn,

z ← Wu(g ⊙ (Wdx)).                    (9)

Tối ưu hóa. Chúng tôi tối ưu hóa các ma trận chiếu xuống và chiếu lên bằng các phương pháp gradient ngẫu nhiên như trong LoRA, trong khi mỗi cổng g được cập nhật theo cách thúc đẩy độ thưa khác:

gt+1 ← Tηt·λ(gt - ηt∇gL0(∆t)),                    (10)

trong đó L0(·) là hàm loss gốc của mô hình ngôn ngữ, ∆ ký hiệu tham số có thể điều chỉnh hoàn chỉnh (bao gồm các cổng), ηt > 0 đại diện cho kích thước bước ở lần lặp thứ t, và λ > 0 hoạt động như siêu tham số cường độ điều chuẩn thúc đẩy độ thưa. Bên cạnh đó, Tηt·λ(·) trong biểu thức trên đại diện cho phát sóng theo phần tử của hàm soft-thresholding sau:

Tξ(x) := {
    x - ξ,      nếu x > ξ
    0,          nếu -ξ < x ≤ ξ          (11)
    x + ξ,      nếu x ≤ -ξ
}

với ξ = ηt·λ là ngưỡng. Trong thực tế, gradient thực ∇gL0 trong (10) được xấp xỉ bởi đối tác ngẫu nhiên mini-batch của nó.

Cắt tỉa sau. Khi huấn luyện hoàn thành, chúng tôi tiếp tục cắt tỉa các trọng số SoRA để loại bỏ các hạng bị zeroized và giảm module về dạng LoRA. Cụ thể, đối với module SoRA thứ k, đặt:

I(k) = {i ∈ [1 : rmax] | g(k)i = 0}                    (12)

là chỉ số của mục zero trong vector cổng thứ k g(k). Chúng tôi loại bỏ các hàng I(k) của chiếu xuống W(k)d để có được W̃(k)d, các cột I(k) của chiếu lên W(k)u để có được W̃(k)u, cũng như mục I(k) của cổng g(k) để có được g̃(k). Theo cách này, trong thời gian suy luận, module SoRA thứ k sẽ tiến hành như một module LoRA thông thường của hạng rmax - |I(k)| với ma trận chiếu xuống W̃(k)d và ma trận chiếu lên W̃(k)u·diag(g̃(k)).

3.2 Diễn giải và So sánh

Diễn giải lý thuyết. Quy tắc cập nhật (10) thực tế là một ứng dụng của phương pháp gradient gần đúng cho loss ℓ1. Điều này theo ngay lập tức khi chúng ta công thức hóa lại (10) tương đương như:

gt+1 ← arg min_g {ηt·λ∥g∥1 + 1/2∥g - (gt - ηt∇L0(gt))∥²2}.          (13)

Phương trình (13) ở trên chính xác là cập nhật gradient gần đúng của hàm loss được điều chuẩn ℓ1:

L(∆) := L0(∆) + λ∑(k=1 to K)∥g(k)∥1,                    (14)

trong đó g(k) ký hiệu cổng của module SoRA thứ k. Chiến lược thúc đẩy độ thưa này có từ estimator LASSO và compressed sensing, và cũng được áp dụng bởi nhiều công trình trong lĩnh vực deep learning.

So sánh với AdaLoRA. Được truyền cảm hứng tương tự bởi phân rã SVD, cách tiếp cận SoRA của chúng tôi khác với công trình trước đó AdaLoRA theo nghĩa sau. Thứ nhất, chúng tôi không áp dụng điều chuẩn trực giao (5) được sử dụng trong AdaLoRA. Lý do là cho mục đích lựa chọn hạng, việc thưa hóa cổng g sẽ đủ. Bám víu vào các yêu cầu gốc của SVD có thể dẫn đến chi phí tính toán bổ sung. Thứ hai, điểm quan trọng trung bình trượt trong AdaLoRA hoạt động như một xấp xỉ cho sự thay đổi trong loss khi mục tương ứng được zeroized, được coi là một phép đo heuristic của "sensitivity" tham số. Tuy nhiên, độ nhạy tạm thời của mô hình đối với một tham số nhất định không thể ngụ ý rằng tham số đó nên được giữ lại, vì không có lý thuyết nghiêm ngặt để làm như vậy. Ngược lại, việc lựa chọn hạng của chúng tôi dựa trên hoạt động soft-thresholding (10) tiến hành dưới dạng sạch hơn nhiều và được biện minh hợp lý bởi lý thuyết lặp gradient gần đúng. Như đã giải thích trước đó trong phần này, quy tắc cập nhật của module SoRA tuân theo chính xác nguyên tắc đầu tiên của sự đánh đổi interpolation-complexity bằng cách tối thiểu hóa mục tiêu loss được điều chuẩn (14).

Ngoài sự đơn giản hình thức và sự rõ ràng lý thuyết là hiệu suất thực nghiệm vượt trội của SoRA đạt được với ít tham số hơn trong thời gian wall-clock ít hơn, sẽ được trình bày trong Phần 4.

3.3 Lập lịch ξ để Khám phá Ghi nhớ và Tổng quát hóa

Chúng tôi gọi ngưỡng ξ là một chỉ báo độ thưa. Như tên gọi, tham số này có thể trực tiếp xác định độ thưa của SoRA trong quá trình huấn luyện. Nó có thể được đặt như một hằng số để kiểm soát heuristic độ thưa theo ngân sách tham số và hiệu suất mong đợi. Khi thay đổi động ξ trong quá trình thích ứng, SoRA phục vụ như một công cụ hiệu quả để đánh giá ghi nhớ và tổng quát hóa dưới mô hình M và tập dữ liệu D. Nói cách khác, chúng ta có thể quan sát trực quan bao nhiêu tham số bổ sung được yêu cầu để đạt được một điểm hiệu suất cụ thể cho mô hình M và dữ liệu D. Chúng tôi trình bày ý tưởng cơ bản như sau. Quá trình bắt đầu bằng cách gán một giá trị tương đối nhỏ cho ξ. Do đó, mô hình SoRA ban đầu là "dày đặc" và được huấn luyện cho đến khi hội tụ. Khi giai đoạn này đạt được, chúng tôi giới thiệu một bộ lập lịch để tăng dần giá trị của ξ, từ đó tăng cường độ thưa của mô hình. Trong quá trình chuyển đổi từ mô hình dày đặc sang thưa, có thể đánh giá khả năng ghi nhớ và tổng quát hóa của mô hình bằng cách kiểm tra hiệu suất trên dữ liệu huấn luyện và kiểm tra tương ứng. Quy trình được báo cáo trong Thuật toán 1.

Quá trình có thể được coi là khám phá "loss nén" trong tình huống thích ứng mô hình. Ở đây, "loss nén" đề cập đến việc giảm hiệu suất mô hình do tăng độ thưa, cung cấp một thước đo về mức độ mô hình có thể giữ lại sức mạnh dự đoán dưới các ràng buộc. Điều tra "loss nén" này có ý nghĩa để hiểu hành vi của thích ứng mô hình và có thể tạo thuận lợi cho việc phát triển các mô hình hiệu quả, nhỏ gọn duy trì mức hiệu suất cao.

Thuật toán 1: Thuật toán Lập lịch của ξ
Đầu vào: M, ξ0, ξmax, δξ, D
Đầu ra: M′ = {M0, M1, ...}
ξ ← ξ0;
M′ ← ∅;
M = TrainUntilConvergence(M, D, ξ);
M′.add(M);
ξ ← ξ + δξ;
while ξ ≤ ξmax do
    for epoch ← 1 to 5 do
        M = Update(M, D, ξ);
    end
    M′.add(M);
    ξ ← ξ + δξ;
end

4 Thí nghiệm

Các thí nghiệm rộng rãi được thực hiện để đánh giá tính hiệu quả của cách tiếp cận chúng tôi một cách toàn diện. Nói chung, chúng tôi khám phá hai khía cạnh trong phần này: (1) hiệu suất và phân tích tương ứng như một phương pháp hiệu quả tham số bình thường; và (2) điều tra ghi nhớ và tổng quát hóa nhờ vào bản chất độ thưa của SoRA.

4.1 Thiết lập Thí nghiệm

Baseline. Các baseline của chúng tôi bao gồm tinh chỉnh toàn bộ tham số và các phương pháp hiệu quả tham số được công nhận, bao gồm Adapter, BitFit, LoRA và AdaLoRA. Chúng tôi bỏ qua các biến thể của Adapter vì chúng tôi thấy rằng hiệu suất giữa chúng rất gần. Chúng tôi cũng không bao gồm Prompt Tuning vì chúng tôi thấy rằng nó mất thời gian đáng kể để hội tụ và không thể mang lại hiệu suất đáng kể trên các mô hình cơ sở của chúng tôi.

Tập dữ liệu. Để đánh giá, chúng tôi áp dụng benchmark GLUE, bao gồm CoLA, SST-2, MRPC, QQP, STS-B, MNLI, QNLI và RTE. Chúng tôi chủ yếu sử dụng DeBERTaV3-base làm mô hình cơ sở. Ngoài ra, chúng tôi cũng sử dụng RoBERTa-large để phân tích. Các chi tiết thí nghiệm khác được mô tả trong Phụ lục A.

4.2 Kết quả

Trước tiên chúng tôi tiến hành đánh giá trên benchmark GLUE, một benchmark được công nhận rộng rãi cho hiểu ngôn ngữ tự nhiên. Hiệu suất thí nghiệm của SoRA, cũng như các phương pháp baseline khác, được ghi lại trong Bảng 1. Chúng tôi tái tạo các phương pháp này trong cơ sở hạ tầng của chúng tôi và trình bày kết quả trung bình từ 5 seed ngẫu nhiên. Phát hiện của chúng tôi chỉ ra rằng cả AdaLoRA và SoRA đều liên tục vượt trội so với baseline LoRA ban đầu. Điều này nhấn mạnh tính hợp lệ của hạng thích ứng như một giải pháp mạnh mẽ cho thích ứng mô hình nâng cao. Đáng chú ý nhất, SoRA vượt trội tất cả các baseline khác, đặc biệt là LoRA và AdaLoRA, mặc dù sử dụng ít tham số hơn. Điều này tạo thêm uy tín cho lập luận rằng phương pháp gradient gần đúng của chúng tôi có thể tạo thành một cách tiếp cận hiệu quả và cần thiết hơn để đạt được hạng thích ứng. Ví dụ, trên MRPC, SoRA đạt được độ chính xác 91.98%, vượt trội AdaLoRA 1.76%. Trung bình, SoRA vượt trội LoRA và AdaLoRA trên benchmark GLUE lần lượt 0.98% và 0.52%, sử dụng ít hơn 31.5% và 28.3% tham số. Để xem xét kỹ hơn tính hiệu quả của hạng thích ứng, chúng tôi tiến hành thí nghiệm so sánh LoRA và SoRA với các hạng khác nhau trong Bảng 2. Kết quả khẳng định rằng sự vượt trội của SoRA nhất quán qua các ngân sách tham số khác nhau, tức là SoRA có thể vượt trội baseline LoRA trong tất cả các thiết lập trong khi sử dụng hơn 30% ít tham số hơn.

4.3 Bộ Lập lịch Thưa hóa

Chúng tôi áp dụng bộ lập lịch thưa hóa được giới thiệu trong Phần 3.3 bằng cách tăng dần chỉ báo thưa ξ (bắt đầu từ 1e-4) của SoRA trong quá trình thích ứng. Như minh họa trong Hình 2, chúng tôi vẽ đồ thị đường cong ghi nhớ và tổng quát hóa của RoBERTa-large trên MRPC, RTE, STS-B, CoLA, QNLI và SST-2, trong đó ghi nhớ được đo bởi hiệu suất trên tập huấn luyện và tổng quát hóa được đo bởi hiệu suất trên tập validation. Thật thú vị, chúng tôi quan sát "hiệu suất nén" mạnh mẽ trên hầu hết tất cả các tập dữ liệu. Trong số này, SST-2 nổi lên như tác vụ "có thể nén" nhất, nơi mô hình duy trì hơn 99% hiệu suất ngay cả khi bị hạn chế đến 47,104 tham số khác không. Đáng chú ý, chỉ 4,096 tham số vẫn có thể bảo tồn trên 90% khả năng ghi nhớ và tổng quát hóa. Khi quá trình thưa hóa tiến hành, mô hình gặp phải "điểm uốn" trên dữ liệu khác nhau, sau đó hiệu suất giảm đáng kể. Hiện tượng nhất quán này gợi ý rằng tồn tại một số tham số quan trọng làm nền tảng cho hiệu suất và đáng được điều tra thêm. Insight thu được từ đồ thị cũng chỉ ra các mức độ khó khăn thích ứng khác nhau cho mô hình trên các tập dữ liệu khác nhau. Ví dụ, một số tập dữ liệu, như CoLA, gây ra sự suy giảm hiệu suất sớm hơn và rõ rệt hơn so với các tập khác. Một phát hiện khác là xu hướng ghi nhớ và tổng quát hóa nhất quán trong quy trình thưa hóa, phù hợp với trực giác. Quan sát của chúng tôi cũng chỉ ra xu hướng các tham số của các lớp trung gian và sâu duy trì mật độ của chúng, trong khi những tham số của các lớp nông thể hiện xu hướng cao hơn về độ thưa.

4.4 Phân tích Hạng

Một tuyên bố trực quan là một mô hình duy nhất chịu các mức độ khó khăn khác nhau khi được thích ứng với các tập dữ liệu downstream khác nhau. Đồng thời, rõ ràng là không phải tất cả các tham số trong mô hình đều mang tầm quan trọng bằng nhau - một số quan trọng hơn đối với hiệu suất so với các tham số khác. Trong phần này, chúng tôi trực quan hóa các hạng cuối cùng sau khi quá trình huấn luyện hội tụ với SoRA trên bốn tập dữ liệu trong Hình 3. Khá rõ ràng, các ma trận tham số được huấn luyện trên QQP cực kỳ dày đặc và các tập khác không thể hiện mật độ như vậy, điều này phản ánh sự tồn tại của các mức độ khó khăn khác nhau. Hiện tượng này cũng gợi ý rằng việc tận dụng hiệu suất và ngân sách tham số không có quy luật hằng số bất biến, mà cần xem xét cụ thể trong các tình huống khác nhau.

4.5 Áp dụng SoRA cho Các Trọng số Khác nhau

Trong các thí nghiệm của chúng tôi trong Bảng 1, chúng tôi sử dụng LoRA, AdaLoRA và SoRA trên tất cả các ma trận trọng số để tăng cường hiệu suất. Cần lưu ý rằng hiệu suất có thể dao động khi tinh chỉnh hiệu quả tham số được áp dụng vào các vị trí khác nhau trong mô hình, như đã được chứng minh bởi nghiên cứu trước đó. Chúng tôi thực hiện các thí nghiệm ablation như vậy với SoRA trên ba tập dữ liệu để điều tra tác động. Mặc dù SoRA không phải là phương pháp hướng ngân sách, chúng tôi điều chỉnh λ để xấp xỉ cân bằng các tham số khác không được giữ lại. Như báo cáo trong Bảng 3, trong hầu hết các trường hợp, việc áp dụng SoRA cho tất cả các ma trận trọng số dẫn đến cải thiện đáng kể về hiệu suất so với việc áp dụng chỉ một hoặc vài loại trọng số, điều này gợi ý rằng việc áp dụng đồng nhất SoRA cho tất cả các ma trận trọng số có thể phục vụ như một chiến lược có lợi. Và việc chỉ áp dụng SoRA cho WQ,K sẽ trải qua sụt giảm hiệu suất đáng kể, phù hợp với LoRA.

4.6 Phân tích Hiệu quả

Chúng tôi trình bày rằng SoRA là một phương pháp rõ ràng về mặt lý thuyết và hiệu quả tính toán trong Phần 3.2. Để đánh giá điều này, chúng tôi đo lường hiệu quả của SoRA và AdaLoRA trong phần này. Chúng tôi tính toán thời gian clock của epoch trung bình của AdaLoRA và SoRA trên sáu tập dữ liệu với cơ sở hạ tầng tính toán và kích thước batch giống hệt nhau. Như thể hiện trong Bảng 4, SoRA mất khoảng 30% ít thời gian huấn luyện hơn so với AdaLoRA. Trong một số trường hợp nhất định, như các tập dữ liệu CoLA, QNLI và RTE, SoRA thể hiện lợi thế đáng kể về hiệu quả so với đối tác của nó. Ngược lại, trong khi SoRA liên tục vượt trội AdaLoRA trên các tập dữ liệu khác, biên độ không rộng bằng. Sự khác biệt này có thể là do các phân phối hạng khác nhau của AdaLoRA và SoRA dưới các tác vụ khác nhau. Các phân phối như vậy tác động đến việc tính toán điều chuẩn trong AdaLoRA.

5 Kết luận

Công trình của chúng tôi trình bày Thích ứng Thưa thớ Hạng thấp (SoRA), một phương pháp sáng tạo cho tinh chỉnh hiệu quả tham số các mô hình ngôn ngữ lớn tiền huấn luyện. Dựa trên giả thuyết rằng quá trình thích ứng có thể có bản chất thưa nội tại, chúng tôi cung cấp một hạng động thay thế bằng cách giới thiệu cổng có thể tối ưu hóa với phương pháp gradient gần đúng để điều chỉnh độ thưa, từ đó mở rộng không gian tối ưu hóa trong khi tăng cường hiệu quả tham số. Phương pháp này đơn giản và được hỗ trợ lý thuyết với hiệu suất hứa hẹn trên nhiều tác vụ khác nhau. Sử dụng SoRA như một công cụ, chúng tôi đề xuất bộ lập lịch thưa hóa để phân tích mối tương quan giữa tham số và ghi nhớ và tổng quát hóa.

Hạn chế

Mặc dù có kết quả khuyến khích được chứng minh bởi SoRA, có một số hạn chế trong nghiên cứu hiện tại của chúng tôi đáng được thừa nhận. Bài báo này chỉ đánh giá tính hiệu quả của SoRA trên các tác vụ xử lý ngôn ngữ tự nhiên truyền thống. Tuy nhiên, các nghiên cứu gần đây chứng minh rằng các phương pháp hiệu quả tham số có thể được áp dụng cho các tình huống cross-modal hoặc instruction-tuning. Trong những trường hợp đó, cách độ thưa của SoRA được hiển thị vẫn chưa biết và đáng để điều tra. Bộ lập lịch thưa hóa của chúng tôi có thể cung cấp insight về quá trình thích ứng của các mô hình ngôn ngữ, nhưng vẫn còn thách thức để giải thích nghiêm ngặt quy trình và hiệu quả hơn để đánh giá độ khó của một quá trình thích ứng.

Lời cảm ơn

Công trình này được hỗ trợ bởi Chương trình R&D Chính quốc gia Trung Quốc (Số 2022ZD0119101), Quỹ Khoa học Tự nhiên Quốc gia Trung Quốc (Số 62236004), Chương trình Tài trợ Nhà khoa học Trẻ Ưu tú của CAST, và Viện Guo Qiang tại Đại học Thanh Hoa.

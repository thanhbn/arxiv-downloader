# 2311.11501.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2311.11501.pdf
# Kích thước tệp: 659766 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
MULTI LORA: DÂN CHỦ HÓA LORA ĐỂ CẢI THIỆN
HỌC NHIỀU TÁC VỤ
Yiming Wang, Yu Lin, Xiaodong Zeng, Guannan Zhang
Ant Group
Thượng Hải, Trung Quốc
TÓM TẮT
LoRA đạt được hiệu quả tài nguyên đáng chú ý và hiệu suất tương đương khi điều chỉnh LLM
cho các tác vụ cụ thể. Kể từ khi ChatGPT thể hiện hiệu suất vượt trội trên các tác vụ khác nhau, đã
có mong muốn ngày càng tăng để điều chỉnh một mô hình cho tất cả các tác vụ. Tuy nhiên, thứ hạng thấp
rõ ràng của LoRA hạn chế hiệu suất điều chỉnh trong các tình huống đa tác vụ phức tạp. LoRA bị chi phối bởi
một số lượng nhỏ các vector đơn vị hàng đầu trong khi tinh chỉnh phân tách thành một tập hợp các phép biến đổi đơn vị ít quan trọng hơn. Trong bài báo này, chúng tôi đề xuất MultiLoRA cho việc điều chỉnh đa tác vụ tốt hơn bằng cách giảm
sự chi phối của các vector đơn vị hàng đầu quan sát được trong LoRA. MultiLoRA mở rộng các mô-đun LoRA theo chiều ngang
và thay đổi khởi tạo tham số của các ma trận điều chỉnh để giảm sự phụ thuộc tham số, do đó
tạo ra các không gian con đơn vị cân bằng hơn. Chúng tôi chưa từng xây dựng dữ liệu huấn luyện chuyên biệt
bằng cách trộn các tập dữ liệu về tuân theo hướng dẫn, hiểu ngôn ngữ tự nhiên, kiến thức thế giới, để
bao phủ các mẫu khác nhau về mặt ngữ nghĩa và cú pháp. Chỉ với 2,5% tham số bổ sung,
MultiLoRA vượt trội hơn các đối tác LoRA đơn lẻ và tinh chỉnh trên nhiều bộ tiêu chuẩn và
quy mô mô hình. Nghiên cứu sâu hơn về các ma trận cập nhật trọng số của MultiLoRA cho thấy giảm
sự phụ thuộc vào các vector đơn vị hàng đầu và đóng góp biến đổi đơn vị dân chủ hơn¹.

1 Giới thiệu
Trong những năm gần đây, các Mô hình Ngôn ngữ Lớn (LLM) đã thể hiện hiệu suất vượt trội chưa từng có trong các
tác vụ xử lý ngôn ngữ tự nhiên khác nhau[1,2,3,4]. Khi mô hình mở rộng quy mô, khả năng đa tác vụ cao cấp[5] xuất hiện từ
LLM. Các khả năng như kiến thức thế giới thực, lý luận logic và kỹ năng số học từ một LLM chứng minh
tính khả thi của "một mô hình cho tất cả các tác vụ". Tuy nhiên, mở rộng quy mô LLM bằng cách thêm hàng tỷ tham số không chỉ mang lại
khả năng mới nổi và hiểu biết, mà còn làm tăng đáng kể chi phí huấn luyện và điều chỉnh xuôi dòng. Ví dụ,
số lượng tham số của chuỗi LLaMA[4] dao động từ 7 tỷ đến 65 tỷ, và GPT-3[2] chứa tới 175 tỷ
tham số. Tinh chỉnh toàn bộ tham số các mô hình này để điều chỉnh xuôi dòng tạo ra lượng lớn dấu chân bộ nhớ
và do đó đòi hỏi phần cứng cực kỳ đắt đỏ.

Để giải quyết vấn đề yêu cầu phần cứng cho việc điều chỉnh LLM, một giải pháp gọi là Tinh chỉnh Hiệu quả Tham số
(PEFT) đã được đề xuất. Các phương pháp PEFT giảm sử dụng VRAM của các trạng thái tối ưu hóa được lưu trữ[6] bằng cách chỉ tối ưu hóa một
phần nhỏ tham số mô hình trong khi giữ phần còn lại đông lạnh. Các phương pháp PEFT khác nhau, như adapter[7], p-tuning[8],
IA3[9] và LoRA[6], đã được đề xuất. So với các phương pháp PEFT khác, LoRA sở hữu những ưu điểm: 1)
tính mô-đun cao cho phân phối, 2) trọng số có thể hợp nhất cho chi phí suy luận bằng không. Trong khi LoRA đã chứng minh thành công
trong điều chỉnh tác vụ đơn, hiệu suất của nó trong các cài đặt đa tác vụ phức tạp hơn của AI tạo sinh vẫn chưa được khám phá.
Do đó, một câu hỏi quan trọng vẫn còn: Liệu LoRA có thể điều chỉnh hiệu quả LLM cho các tình huống đa tác vụ phức tạp như
tinh chỉnh toàn bộ tham số không?

Các nghiên cứu về việc áp dụng các phương pháp PEFT vào các tình huống học đa tác vụ có trong tài liệu, mặc dù với những hạn chế nhất định[10,
11,12,13]. Các phương pháp được đề xuất này quản lý để cải thiện hiệu suất tiêu chuẩn đa tác vụ với việc chia sẻ thông tin tác vụ hoặc định tuyến kích hoạt[13,10,11]. Tuy nhiên, các mô-đun chuyên dụng này thêm chi phí không thể chấp nhận được vào suy luận transformer, điều này cản trở ứng dụng công nghiệp của chúng[6,14]. Một hạn chế khác là các nghiên cứu trước đây tập trung vào Hiểu biết
¹Mã nguồn của chúng tôi sẽ sớm có trên GitHub.arXiv:2311.11501v1 [cs.LG] 20 Nov 2023

--- TRANG 2 ---
Bài báo PRIME AI
Ngôn ngữ Tự nhiên (NLU), có thể không phù hợp với các LLM tạo sinh hiện tại. Một hỗn hợp các tác vụ NLU
thường được sử dụng[10,11] mặc dù các mẫu dữ liệu của các tác vụ này không thể hiện nhiều khác biệt về ngữ nghĩa hoặc cú pháp giữa chúng. Nhiều tiêu chuẩn hơn về các tác vụ quan tâm của LLM tạo sinh, như tuân theo hướng dẫn, lý luận logic nên được xem xét.

Do đó, mục tiêu nghiên cứu của bài báo này là điều chỉnh LoRA để học đa tác vụ tốt hơn trong khi duy trì tính mô-đun
và chi phí suy luận bằng không của LoRA. Chúng tôi đầu tiên tiết lộ sự khác biệt cơ bản giữa LoRA và tinh chỉnh toàn bộ tham số với sự hỗ trợ của Phân tích Giá trị Đơn lẻ (SVD, Mục 3.2). Chúng tôi tìm thấy sự chi phối của các vector đơn vị hàng đầu trong LoRA trong khi tinh chỉnh dân chủ hơn, vì trọng số dư phần tích thành các tập hợp lớn hơn các phép biến đổi đơn vị có tầm quan trọng nhỏ hơn. Để giảm thiểu sự chi phối quan sát được, chúng tôi đề xuất mở rộng theo chiều ngang các mô-đun LoRA (Mục 3.3). MultiLoRA mở rộng theo chiều ngang các mô-đun lora để giảm sự phụ thuộc tham số. MultiLoRA chia LoRA theo thứ hạng, thêm yếu tố tỷ lệ có thể học được và thay đổi khởi tạo tham số để tăng cường tính biểu đạt của các mô-đun lora. So với LoRA thông thường, MultiLoRA tạo ra các ma trận cập nhật trọng số dân chủ hơn như những ma trận của tinh chỉnh toàn bộ tham số.

Để thể hiện tốt hơn hiệu quả của MultiLoRA, chúng tôi đã xây dựng một tập dữ liệu toàn diện bao gồm các tác vụ khác nhau liên quan đến LLM tạo sinh. Một loạt các tập dữ liệu từ các lĩnh vực khác nhau được chọn bao gồm tuân theo hướng dẫn[15], kiến thức thế giới[16], lý luận số học[17] và NLU[18]. Cả bối cảnh và mục tiêu của các mẫu trong các tập dữ liệu nói trên đều thể hiện sự khác biệt mạnh mẽ về ngữ nghĩa và cú pháp, do đó làm tăng độ khó điều chỉnh.
Với các tập dữ liệu đa tác vụ của chúng tôi, chúng tôi đã tiến hành các thí nghiệm thực nghiệm rộng rãi trên LLaMA từ 7B đến 65B.
Trên các tiêu chuẩn MMLU[16] và SuperGLUE[18], chúng tôi thấy MultiLoRA liên tục vượt trội hơn LoRA ngay cả dưới ngân sách tham số nhỏ hơn và có thể hoạt động ngang bằng với tinh chỉnh toàn bộ tham số. Chúng tôi tiếp tục đi sâu vào các ma trận cập nhật trọng số thu được với SVD. So sánh cạnh nhau với tinh chỉnh toàn bộ tham số cho thấy MultiLoRA thể hiện mức độ chồng chéo không gian con cao hơn và phân phối giá trị đơn lẻ tương tự hơn, cho thấy việc dân chủ hóa đóng góp biến đổi đơn vị thành công.

Do đó, các đóng góp chính của chúng tôi có thể được tóm tắt như sau:
• Chúng tôi tìm thấy sự chi phối của các biến đổi đơn vị trong các ma trận cập nhật trọng số của LoRA, trong khi tinh chỉnh tạo ra phân phối đóng góp dân chủ hơn.
• Chúng tôi đề xuất MultiLoRA để giảm thiểu sự chi phối quan sát được trong LoRA và dân chủ hóa đóng góp của các biến đổi đơn vị của nó.
• Chúng tôi đề xuất một sơ đồ học đa tác vụ dựa trên hỗn hợp các tác vụ quan tâm của LLM tạo sinh, để bao phủ các mẫu khác nhau về mặt ngữ nghĩa và cú pháp. MultiLoRA được đề xuất của chúng tôi thể hiện tính nhất quán mạnh mẽ hơn LoRA và có thể vượt trội hơn tinh chỉnh toàn bộ tham số trên các tác vụ và quy mô mô hình khác nhau.

2 Nghiên cứu liên quan
2.1 PEFT
Các phương pháp PEFT giảm yêu cầu phần cứng của việc tinh chỉnh mô hình bằng cách giảm đáng kể các tham số có thể huấn luyện
và do đó các trạng thái tối ưu hóa được lưu trữ trong VRAM. Bằng cách khai thác tối ưu cục bộ của một mô hình được huấn luyện trước, một không gian giải pháp nhỏ hơn nhiều được mang lại bởi việc giảm các tham số có thể huấn luyện giúp các phương pháp PEFT đạt được hiệu suất tinh chỉnh tương đương[19,20]. PEFT có thể được phân loại thành hai loại: 1) các phương pháp dựa trên tham số hóa lại[21,22] huấn luyện lại một phần tham số và 2) các phương pháp dựa trên bổ sung huấn luyện các tham số bổ sung[6,23,7]. Các nghiên cứu gần đây trong PEFT tập trung vào hiệu quả tài nguyên[7,9,6,23]. LoRA[6] khớp các trọng số tăng dần bằng cách phân tách chúng thành các ma trận thứ hạng thấp. (IA)3 điều chỉnh các trạng thái ẩn với các bộ nhân đã học. AdaLoRA[23] thêm các cơ chế cắt tỉa nhận biết tầm quan trọng để cải thiện thêm hiệu quả tài nguyên. Cũng có nghiên cứu tập trung vào học tổng hợp với các adapter. AdaMix[13] và UniPELT[24] tích hợp các phương pháp PEFT hiện có vào một khung thống nhất để tăng hiệu suất điều chỉnh.

2.2 Học Đa Tác vụ với PEFT
Trong học đa tác vụ với PEFT, adapter được sử dụng để tóm tắt mã trên các ngôn ngữ lập trình khác nhau[12].
HyperFormer[10] gán các trọng số liên quan đến tác vụ cho các kích hoạt adapter[7] sử dụng hypernets chia sẻ qua các lớp và tác vụ.
Multitask Prompt Tuning[11] mở rộng prompt tuning bằng cách đầu tiên chưng cất từ các prompts nguồn được điều chỉnh cho các tác vụ khác nhau và tiếp tục tinh chỉnh với các cập nhật thứ hạng thấp. Trong khi các phương pháp này đã cho thấy hiệu quả, các trọng số bổ sung không thể được tích hợp liền mạch vào mô hình cơ sở, dẫn đến độ trễ suy luận không thể tránh khỏi mà không thực tế cho việc phục vụ LLM[6,14]. Hơn nữa, việc nhấn mạnh trong cài đặt đa tác vụ chủ yếu tập trung vào các tác vụ NLU, bỏ qua các tác vụ quan tâm đến LLM tạo sinh.
2

--- TRANG 3 ---
Bài báo PRIME AI
3 Phương pháp
3.1 Nền tảng
Trước khi giải thích chính thức về các lựa chọn thiết kế của MultiLoRA, một vài ký hiệu được đề xuất dựa trên LLaMA và LoRA.
3.1.1 LLaMA
Mô hình LLaMA bao gồm L lớp bộ giải mã xếp chồng, trong đó mỗi khối chứa hai mô-đun con: một attention đa đầu
(MHA) và một FFN được kết nối đầy đủ. Với chuỗi đầu vào x∈Rn×d, MHA thực hiện chức năng attention song song h đầu:
head i=Softmax (xWq_proj
i (xWk_proj
i )⊤
√dn)xWv_proj
i ,MHA (x) =Concat (head 1, . . . , head n)Wo_proj, (1)
trong đó Wq_proj
i , Wk_proj
i , Wv_proj
i ∈Rd×d là các phép chiếu query, key và value của đầu attention thứ i và Wo_proj∈
Rd×d là phép chiếu đầu ra để tổng hợp các đầu ra đa đầu. dh thường được đặt thành d/h. Mô-đun quan trọng khác là
một MLP bao gồm ba phép biến đổi tuyến tính, cụ thể là up_proj, down_proj, gate_proj với một kích hoạt SwiGLU
ở giữa:
MLP(x) =SwiGLU (xWup_proj(xWgate _proj))Wdown _proj, (2)
trong đó Wup_proj, Wgate _proj∈Rd×dmid, dmid> d và Wdown _proj∈Rdmid×d. Chuẩn hóa lớp được áp dụng
trước và sau mô-đun attention.[4]
3.1.2 Điều chỉnh Thứ hạng Thấp
Với mô-đun mục tiêu có trọng số W∈Rd×k, LoRA chèn hai ma trận thứ hạng thấp tuần tự để khớp các trọng số dư
để điều chỉnh. Tính toán thuận của mô-đun được điều chỉnh viết như sau:
y′=y+ ∆y=Wx+BAx, (3)
trong đó A∈Rd×r, B∈Rr×k với r≪min(d, k). Hoặc A hoặc B được khởi tạo bằng số không và cái kia được khởi tạo
với Kaiming Uniform[25] để buộc ∆y= 0 ngay từ đầu. Phân tích về các ma trận cập nhật trọng số cho thấy
LoRA hoạt động bằng cách tăng cường các biến đổi đặc trưng hiện có trong trọng số mô hình gốc[6].

3.2 Sự khác biệt giữa LoRA và tinh chỉnh
Mặc dù LoRA đạt được hiệu suất tương đương với tinh chỉnh trên nhiều tiêu chuẩn, việc hiểu
sự khác biệt cơ bản giữa hai phương pháp là rất cần thiết. Để làm sáng tỏ câu hỏi này, Chúng tôi huấn luyện LLaMA-7B trên Alpaca và
MMLU sử dụng cả hai phương pháp² để có được các ma trận cập nhật trọng số ∆W và tiến hành phân tích các ma trận cập nhật trọng số
sử dụng SVD.

Hình 1 minh họa phân phối giá trị đơn lẻ của ∆WFT và ∆WLoRA. Để trực quan hóa tốt hơn, chúng tôi vẽ các logarithm âm
của các giá trị đơn lẻ (−log(s)). Phân phối thực nghiệm của tinh chỉnh thể hiện một đường cong hình chuông
trong khi phân phối cho LoRA rơi vào cả hai đầu của phổ. Phân phối bimodal cực đoan của LoRA phát sinh
từ ràng buộc rằng Rank (∆WLoRA) không được vượt quá r, dẫn đến ít nhất (k−r) giá trị đơn lẻ bằng không.
Thú vị là chúng tôi cũng nhận thấy một xu hướng nghịch đảo trong số lượng các giá trị đơn lẻ hàng đầu. Trong LoRA, số lượng tăng với
độ lớn của các giá trị đơn lẻ, trong khi tinh chỉnh thể hiện hành vi ngược lại. Điều này cho thấy LoRA
chủ yếu dựa vào một nhóm nhỏ các vector đơn vị, trong khi tinh chỉnh phân phối tầm quan trọng đều hơn
giữa các vector đơn vị. Hiện tượng như vậy cũng có thể được quan sát trên LoRA được huấn luyện trên các tập dữ liệu khác hoặc trọng số LoRA có sẵn công khai, cho thấy sự chi phối quan sát được phát sinh từ thiết kế cấu trúc của LoRA (tham khảo Phụ lục B để
biết thêm ví dụ).

Dựa trên những phát hiện này, chúng tôi có thể suy luận rằng sự chi phối quan sát được trong LoRA có thể hạn chế hiệu suất điều chỉnh của nó,
đặc biệt trong các tình huống đa tác vụ phức tạp đòi hỏi tăng cường nhiều biến đổi đặc trưng riêng biệt. ∆W của
tinh chỉnh toàn bộ tham số phân tách thành một tập hợp lớn hơn (cụ thể hơn bằng thứ hạng của ma trận trọng số gốc) các
biến đổi đơn vị. Ngược lại, hạn chế thứ hạng rõ ràng của LoRA giới hạn nó phân tách thành một số lượng nhỏ hơn (r)
biến đổi đơn vị. Kết quả là, tính biểu đạt của LoRA có thể bị hạn chế so với tinh chỉnh toàn bộ tham số.

3.3 Mở rộng LoRA để Dân chủ hóa Đóng góp Biến đổi Đơn vị
²Các siêu tham số LoRA được đặt thành r= 64 và α= 64
3

--- TRANG 4 ---
Bài báo PRIME AI
1e1.0 1e2.0 1e3.0 1e4.0 1e5.0
Logarithm Âm của Giá trị Đơn lẻ log(s)
0100200300400500Số lượng
LoRA Tinh chỉnh Toàn bộ Tham số
(a)
1e1.0 1e1.5 1e2.0
Logarithm Âm của Giá trị Đơn lẻ log(s)
050100150200250300350Số lượng
LoRA Tinh chỉnh Toàn bộ Tham số (b)
Hình 1: Phân phối giá trị đơn lẻ hàng đầu của ma trận cập nhật trọng số ∆Wv_proj. (a) Góc nhìn đầy đủ của biểu đồ. (b)
Góc nhìn cận cảnh về các giá trị đơn lẻ hàng đầu. Cả hai biểu đồ đều được vẽ dựa trên logarithm âm của các giá trị
đơn lẻ −log(s), trong đó đầu trái của trục ngang biểu thị các giá trị đơn lẻ lớn hơn. Đường cong hình chuông của tinh chỉnh toàn bộ tham số
cho thấy một thành phần dân chủ của một số lượng lớn các biến đổi đơn vị tương đối ít quan trọng hơn. Mặt khác, LoRA phụ thuộc nhiều vào một nhóm nhỏ các biến đổi đơn vị quan trọng, điều này có thể gây hại cho việc điều chỉnh đa tác vụ phức tạp.

+
Hình 2: Tổng quan về MultiLoRA. Nhiều
mô-đun LoRA song song được sử dụng để điều chỉnh ma trận trọng số mục tiêu. Khởi tạo tham số và
yếu tố tỷ lệ khởi tạo bằng không được giới thiệu để
dân chủ hóa các cập nhật trọng số dư.

Trong Mục 3.2, chúng tôi quan sát một nhóm nhỏ các vector đơn vị hàng đầu chi phối các ma trận cập nhật trọng số của LoRA ∆WLoRA trong khi các vector đơn vị hàng đầu đóng góp đều hơn vào ∆WFT. Để phù hợp với tinh chỉnh trong việc điều chỉnh tác vụ phức tạp, chúng tôi đề xuất MultiLoRA nhằm tạo ra các ma trận cập nhật trọng số ∆W ít phân cực hơn. MultiLoRA chèn nhiều LoRA song song để giảm chia sẻ tham số, thay đổi khởi tạo tham số để cho phép không gian tìm kiếm tối ưu hóa lớn hơn và thực hiện khởi tạo điểm bắt đầu với một tham số có thể học được.

Hình 2 cho thấy tổng quan về MultiLoRA. Có 3 sự khác biệt chính so với LoRA gốc: mở rộng ngang của các mô-đun LoRA, các yếu tố tỷ lệ và khởi tạo tham số.

3.3.1 Mở rộng LoRA theo Chiều ngang
Cho rằng LoRA hoạt động gần như nhau mặc dù mở rộng thứ hạng r, chiến lược chính của chúng tôi về phản phân cực là song song. Thông qua song song, kích hoạt tăng dần ∆y được phân tách thêm thành một loạt các biến số độc lập, cho phép nhiều bậc tự do hơn trong quá trình tối ưu hóa. Hãy lưu ý rằng dưới cùng một ngân sách tham số, phân tách một mô-đun LoRA lớn thành nhiều LoRA nhỏ không thể tăng thứ hạng của ∆W vì rank(AB)≤min(rank(A), rank (B))
và rank(A+B)≤rank(A) +rank(B). Các ma trận trọng số tương ứng được ký hiệu là {Ai∈Rr×k}i∈[1,n],{Bi∈Rd×r}i∈[1,n]. Do đó, tính toán thuận của MultiLoRA viết như sau:
∆y=nX
i=1scaling iBiAix, (4)
So sánh với thuận của LoRA, MultiLoRA khác ở chỗ ít phụ thuộc tham số hơn được mang đến {Bi}. Song song không có tác động đến A vì trung gian mi=Aix tương đương với reshape kết quả của [A⊤
0, . . . , A⊤
n]⊤x. Nhưng đây là sự khác biệt chính.
4

--- TRANG 5 ---
Bài báo PRIME AI
3.3.2 Khởi tạo Tham số
Mở rộng LoRA theo chiều ngang cho phép biến đổi đặc trưng độc lập đặc biệt là phép chiếu lên của {Bi}. Để đẩy xa hơn
tính biểu đạt của {Bi}, chúng tôi thay đổi khởi tạo tham số của nó thành Kaiming-Uniform[25] thay vì tất cả số không
và do đó giới thiệu một yếu tố tỷ lệ có thể học được để thực hiện khởi tạo điểm bắt đầu.

Khởi tạo bằng không được thấy trong B của LoRA nhằm giữ kích hoạt không thay đổi trước khi huấn luyện. Thực tiễn như vậy, chúng tôi gọi là
Khởi tạo Điểm Bắt đầu, thường được thấy trong các phương pháp PEFT nhưng có thể được thực hiện khác nhau. Với khởi tạo điểm bắt đầu, việc điều chỉnh một LLM được huấn luyện trước về cơ bản trở thành tối ưu hóa trong một không gian tham số nhỏ hơn nhiều xung quanh tối ưu cục bộ của các mô hình được huấn luyện trước. Tuy nhiên, khởi tạo bằng không là một con dao hai lưỡi. Nó cũng khét tiếng vì gây ra sự dư thừa và phá vỡ tính bất đối xứng[26,25], mang lại tính biểu đạt hạn chế của mạng mặc dù tốc độ hội tụ nhanh hơn trong quá trình điều chỉnh.

Để tận dụng khởi tạo điểm bắt đầu và giảm thiểu các nhược điểm của khởi tạo bằng không, MultiLoRA thay đổi khởi tạo của {Bi} thành Kaiming-Uniform và thực hiện khởi tạo điểm bắt đầu với các yếu tố tỷ lệ có thể học được khởi tạo bằng không scaling i∈Rk. Kaiming-Uniform đã được chứng minh là cải thiện hiệu suất tổng quát hóa của mạng nơ-ron và là phương pháp khởi tạo tham số mặc định trong triển khai PyTorch[27].

4 Thí nghiệm
Trong phần này, chúng tôi đánh giá phương pháp được đề xuất của chúng tôi từ ba khía cạnh, cụ thể là hồ sơ bộ nhớ, thông lượng và hiệu suất downstream. Tất cả các thí nghiệm của chúng tôi được tiến hành với chuỗi LLaMA[4], từ 7B đến 65B.

4.1 Thiết lập Thí nghiệm
Kích thước Mô hình Phương pháp MMLU Boolq MultiRC RTE WIC
7B Zero-Shot 35.1 66.5 42.3 57.0 49.4
FT 45.3 87.6 84.5 87.0 71.2
LoRA r=96 44.7 86.0 81.7 86.6 67.6
MultiLoRA n=3
r=32 (Của chúng tôi) 45.1 88.7 83.8 85.6 70.2
13B Zero-Shot 46.9 65.0 43.4 60.6 49.5
FT 51.3 87.1 85.7 90.8 74.3
LoRA r=96 51.0 87.3 86.1 91.7 69.9
MultiLoRA n=3
r=32 (Của chúng tôi) 51.3 86.7 84.7 91.4 75.4
30B Zero-Shot 57.8 74.6 46.9 53.4 50.0
FT 59.2 89.3 87.9 92.8 74.0
LoRA r=96 58.8 89.7 87.0 91.0 74.1
MultiLoRA n=3
r=32 (Của chúng tôi) 59.1 89.5 88.1 93.1 74.1
65B Zero-Shot 63.5 73.6 48.3 59.6 51.3
FT 64.6 91.6 90.1 93.9 75.4
LoRA r=96 64.2 91.4 90.0 93.1 74.5
MultiLoRA n=3
r=32 (Của chúng tôi) 63.3 91.0 90.2 93.5 74.7

Bảng 1: Kết quả chính trên MMLU và SuperGLUE sử dụng LLaMA ở tất cả các quy mô được huấn luyện trong thiết lập tập dữ liệu đơn thông thường. MMLU được kiểm tra với prompts 5-shot và SuperGLUE được kiểm tra với zero-shot. MultiLoRA, LoRA và tinh chỉnh toàn bộ tham số tạo ra kết quả tương tự trong thiết lập tập dữ liệu đơn.

4.1.1 Dữ liệu Huấn luyện
Để đánh giá các tác vụ quan tâm của LLM tạo sinh, chúng tôi xây dựng các tập dữ liệu đa tác vụ bao gồm Alpaca[15] cho
tuân theo hướng dẫn, MMLU[16] cho kiến thức thế giới, GSM8K[17] cho lý luận số học và SuperGLUE[18] cho
NLU. Do đó, hỗn hợp tác vụ của chúng tôi bao phủ các mẫu khác nhau về mặt ngữ nghĩa và cấu trúc. Về mặt độ dài chuỗi nguồn và mục tiêu, các mẫu từ MMLU và SuperGLUE bao gồm các câu hỏi trắc nghiệm với độ dài mục tiêu rất ngắn, thường là một token. Mặt khác, Alpaca và GSM8k chứa các chuỗi mục tiêu dài hơn. Từ khía cạnh ngữ nghĩa tác vụ, các chủ đề được bao phủ bởi mỗi tập dữ liệu khác nhau. MMLU bao gồm kiến thức thế giới thực qua các lĩnh vực khác nhau như nhân văn, STEM và khoa học xã hội, cung cấp các mức độ khó khác nhau. Ngược lại, Alpaca tập trung chủ yếu vào việc căn chỉnh đầu ra mô hình với sở thích của con người. GSM8k huấn luyện các mô hình tạo ra phản hồi logic và từng bước cho các câu hỏi.
5

--- TRANG 6 ---
Bài báo PRIME AI
Để đảm bảo tính nhất quán trong đánh giá, chúng tôi tuân theo QLoRA[28] và MeZO[29] để diễn đạt bằng lời các mẫu của MMLU và
SuperGLUE, tương ứng. Quá trình diễn đạt bằng lời này giúp tiêu chuẩn hóa dữ liệu đầu vào qua các tác vụ, cho phép so sánh công bằng.
Trong quá trình huấn luyện, chúng tôi giới thiệu xáo trộn ngẫu nhiên để tăng cường quá trình học tập và ngăn chặn bất kỳ thiên vị nào có thể phát sinh
từ thứ tự của các mẫu.

4.1.2 Đường chuẩn
Chúng tôi sử dụng các mô hình từ chuỗi LLaMA[4] làm mô hình cơ sở. Trong phân tích so sánh của chúng tôi, chúng tôi xem xét hai đường chuẩn: tinh chỉnh toàn bộ tham số (được gọi là FT) và LoRA đơn lẻ (được gọi là LoRA). Để thiết lập một đường chuẩn LoRA đơn lẻ mạnh mẽ, chúng tôi kết hợp các mô-đun LoRA cùng với tất cả các lớp tuyến tính của LLaMA. Cụ thể, chúng tôi chèn các mô-đun LoRA vào
q_proj, k_proj, v_proj, o_proj, up_proj, down_proj, gate_proj modules trong LLaMA. Càng nhiều lớp được điều chỉnh bởi
LoRA, hiệu suất tác vụ downstream sẽ càng tốt hơn[28, 6].

Đối với Boolq, MultiRC, RTE và WIC, chúng tôi báo cáo hiệu suất zero-shot và chúng tôi báo cáo kết quả 5-shot cho MMLU. Thay vì báo cáo điểm số tác vụ tốt nhất riêng lẻ, chúng tôi báo cáo điểm số của mỗi tác vụ khi điểm số trung bình tốt nhất được đạt để nhấn mạnh khả năng đa tác vụ. Cài đặt siêu tham số được sử dụng trong các thí nghiệm của chúng tôi được chi tiết trong Phụ lục A. Tất cả các thí nghiệm được tiến hành sử dụng 8 GPU A100 80G. Thư viện Python PEFT[30] được sử dụng để giúp triển khai MultiLoRA và LoRA. Chúng tôi sử dụng Deepspeed ZeRO-3[31] cho huấn luyện phân tán và offload các trạng thái tối ưu hóa và tham số mô hình để có thông lượng huấn luyện lớn hơn.

4.2 Kết quả Đánh giá
Kích thước Mô hình Phương pháp # Tham số MMLU Boolq MultiRC RTE WIC TB
7B FT 100% 49.5 88.4 87.2 85.2 74.0 76.9
LoRA r=96 3.6% 47.7 88.2 85.4 83.4 71.6 75.2
LoRA r=160 5.9% 50.2 87.7 85.3 83.3 70.1 75.3
MultiLoRA n=3
r=32 (Của chúng tôi) 3.6% 51.2 87.8 88.7 89.7 70.8 77.6
MultiLoRA n=5
r=32 (Của chúng tôi) 6.0% 51.4 88.5 89.4 89.4 71.4 78.0
13B FT 100% 51.4 89.2 89.3 91.3 75.1 79.2
LoRA r=96 2.9% 49.7 89.7 88.5 87.0 71.5 77.2
LoRA r=160 4.8% 50.4 89.4 88.4 87.6 72.1 77.5
MultiLoRA n=3
r=32 (Của chúng tôi) 2.9% 52.6 89.4 89.9 86.9 74.1 78.5
MultiLoRA n=5
r=32 (Của chúng tôi) 4.8% 52.9 89.3 89.5 90.3 74.3 79.4
30B FT 100% 57.5 90.5 91.0 91.7 75.9 81.3
LoRA r=96 2.2% 57.1 90.2 90.5 90.5 74.0 80.4
LoRA r=160 3.7% 56.8 90.8 90.1 89.9 73.8 80.2
MultiLoRA n=3
r=32 (Của chúng tôi) 2.3% 58.4 90.6 90.5 91.5 74.9 81.1
MultiLoRA n=5
r=32 (Của chúng tôi) 3.8% 58.0 91.7 90.6 91.9 75.2 81.2
65B FT 100% 66.4 91.7 91.3 93.9 76.5 83.9
LoRA r=96 1.8% 65.9 91.3 90.8 92.4 75.1 83.1
LoRA r=160 3.1% 65.8 90.9 90.4 93.6 75.5 83.2
MultiLoRA n=3
r=32 (Của chúng tôi) 1.8% 65.9 91.5 90.5 93.8 76.2 83.5
MultiLoRA n=5
r=32 (Của chúng tôi) 3.1% 66.3 91.8 90.1 93.3 76.6 83.6

Bảng 2: Kết quả đánh giá trên MMLU và SuperGLUE sử dụng LLaMA ở tất cả các quy mô được huấn luyện trên hỗn hợp của chúng tôi. Chúng tôi báo cáo điểm số của mỗi tác vụ khi điểm số trung bình tốt nhất được đạt trong suốt quá trình huấn luyện. MMLU được kiểm tra với prompts 5-shot và SuperGLUE được kiểm tra với zero-shot. MultiLoRA tạo ra kết quả tốt hơn và nhất quán hơn so với LoRA.

Hiệu suất tiêu chuẩn được huấn luyện trên dữ liệu hỗn hợp được liệt kê trong Bảng 2. So sánh những kết quả này với những kết quả thu được từ
các tập dữ liệu đơn lẻ (được liệt kê trong Bảng 1), huấn luyện trên các tập dữ liệu hỗn hợp nói chung dẫn đến lợi ích qua tất cả các tác vụ và quy mô mô hình, dẫn đến cải thiện điểm số tiêu chuẩn ở mức độ khác nhau. Dựa trên những phát hiện này, chúng tôi đưa ra các kết luận sau:.

MultiLoRA liên tục vượt trội hơn LoRA và đạt được kết quả tốt hơn tinh chỉnh toàn bộ tham số trên
các mô hình nhỏ hơn. Qua tất cả các tiêu chuẩn và quy mô mô hình, MultiLoRA thể hiện khả năng khớp dữ liệu mạnh mẽ hơn
và vượt trội hơn đối tác LoRA với cùng ngân sách tham số với một biên độ đáng chú ý. Ví dụ, MultiLoRA cải thiện hiệu suất của LoRA 3,5% trên MMLU cho LLaMA-7B và 5,9% trên RTE cho cùng
mô hình. Trung bình, MultiLoRA vượt trội hơn LoRA về điểm số trung bình của các tác vụ được đánh giá 2,8%. Đáng chú ý,
MultiLoRA thậm chí còn vượt trội hơn tinh chỉnh toàn bộ tham số trên các mô hình nhỏ hơn (7B và 13B), chỉ hơi tụt lại phía sau trên các quy mô lớn hơn. Cụ thể, MultiLoRA đạt được cải thiện điểm số trung bình 1,1% so với tinh chỉnh toàn bộ tham số
6

--- TRANG 7 ---
Bài báo PRIME AI
tinh chỉnh trên LLaMA-7B, và giảm nhẹ 0,3% trên LLaMA-65B. Những cải thiện đáng kể này làm nổi bật
khả năng vượt trội của MultiLoRA trong việc điều chỉnh đa tác vụ phức tạp.

MultiLoRA thể hiện biến động hiệu suất nhỏ có thể so sánh với tinh chỉnh toàn bộ tham số trong các
tình huống học đa tác vụ phức tạp. Trên các mô hình nhỏ hơn, LoRA có xu hướng cho thấy tính biến đổi hiệu suất, với
biến động thường xuyên hơn giữa các tác vụ khác nhau. Ví dụ, trên LLaMA-7B, so với tinh chỉnh toàn bộ tham số, điểm số MultiRC,
RTE và WIC thể hiện biến động trên 3% trong LoRA. Ngược lại, cả tinh chỉnh toàn bộ tham số và
MultiLoRA đều mang lại điểm số tác vụ riêng lẻ nhất quán. Các biến động quan sát được trong LoRA có thể được quy cho
sự chi phối của các vector đơn vị hàng đầu, như đã nêu trong Mục 3.2, trong đó một số lượng nhỏ các biến đổi đơn vị mang
tầm quan trọng đáng kể.

Trong cài đặt tập dữ liệu đơn lẻ, MultiLoRA hoạt động tương tự như tinh chỉnh toàn bộ tham số và LoRA. Bảng 1
cho thấy kết quả đánh giá của các mô hình được huấn luyện trên tập dữ liệu đơn lẻ. Qua 5 tác vụ được kiểm tra và 4 quy mô, tinh chỉnh toàn bộ tham số hoạt động tốt nhất trên 9 tổ hợp, trong khi MultiLoRA và LoRA hoạt động tốt nhất trong 7 và 5 tổ hợp,
tương ứng (MultiLoRA hoạt động ngang bằng với LoRA trên WIC cho LLaMA-30B). Dựa trên những quan sát này, chúng tôi
không thể tuyên bố một cách dứt khoát một phương pháp nào là vượt trội. Tuy nhiên, trong cài đặt đa tác vụ, MultiLoRA và tinh chỉnh toàn bộ tham số thể hiện hiệu suất tốt hơn so với LoRA.

4.3 Phân tích Tài nguyên & Thông lượng
Thông lượng huấn luyện, sử dụng VRAM và độ trễ suy luận là rất quan trọng đối với LLM tạo sinh. Trong phần này, Trong phần này, chúng tôi kiểm tra kỹ lưỡng việc sử dụng tài nguyên và thông lượng của MultiLoRA khi chúng tôi mở rộng số lượng mô-đun LoRA song song n. Chúng tôi tập trung chủ yếu vào sử dụng VRAM và thông lượng trong quá trình huấn luyện vì MultiLoRA kế thừa chi phí suy luận bằng không từ LoRA gốc. Giao thức tiêu chuẩn của chúng tôi bao gồm huấn luyện LLaMA-7B trên các chuỗi 1024 token sử dụng 8 GPU A100 và ghi lại sử dụng VRAM đỉnh và thông lượng³. Deepspeed ZeRO-3 và offload tham số mô hình được kích hoạt để đánh giá tốt hơn các tác động mang lại bởi MultiLoRA.

32 64 96 160 192
n×r050100150200250300350400Tokens/(GPU Giây)
LoRA
MultiLoRA
Tinh chỉnh
(a) Thông lượng
32 64 96 160 192
n×r0102030405060VRAM/GPU (GB)Tinh chỉnh
LoRA
MultiLoRA (b) VRAM

Hình 3: (a) Thông lượng và (b) sử dụng VRAM đỉnh được đo khi huấn luyện LLaMA-7B với các chuỗi 1024
token và kích thước batch là 1. n×r trên trục ngang biểu thị tổng thứ hạng của LoRA và MultiLoRA. Nhờ tính song song cao của MultiLoRA, thông lượng huấn luyện gần như giống hệt với LoRA. Sử dụng VRAM tăng tuyến tính với
số lượng mô-đun LoRA song song.

Kết quả được liệt kê trong Hình 3. Trên trục ngang, n×r biểu thị tổng thứ hạng bằng nhau của MultiLoRA (n mô-đun
LoRA song song có thứ hạng r) và LoRA (một LoRA có thứ hạng n×r).

Thông lượng huấn luyện là một trong những ưu điểm của việc sử dụng MultiLoRA như các phương pháp PEFT khác. Một hạn chế với tinh chỉnh toàn bộ tham số nằm ở việc các trạng thái tối ưu hóa được lưu trữ có thể tiêu thụ một phần đáng kể của VRAM. Cụ thể, khi huấn luyện một mô hình 7B với AdamW[32], các trạng thái tối ưu hóa được lưu trữ có thể chiếm tới 70% VRAM có sẵn, và trên 48% với SGD[33]. Nhờ số lượng tham số có thể huấn luyện giảm đáng kể, VRAM hữu hạn có thể được tận dụng để tải nhiều mẫu dữ liệu hơn, dẫn đến thông lượng huấn luyện lớn hơn. Ngoài ra, do tính song song vốn có trong MultiLoRA, nhiều mô-đun LoRA không gây ra độ trễ đáng chú ý và thông lượng vẫn gần với
³Chúng tôi huấn luyện MultiLoRA với thứ hạng riêng lẻ là 32.
7

--- TRANG 8 ---
Bài báo PRIME AI
của LoRA, khoảng 400 token mỗi GPU mỗi giây. Trong tiêu chuẩn của chúng tôi, thông lượng của MultiLoRA gần gấp đôi so với tinh chỉnh toàn bộ tham số (208 token mỗi GPU mỗi giây).

Đối với sử dụng VRAM, bộ nhớ đỉnh tăng nhanh hơn nhiều so với LoRA. Để tối ưu hóa nhiều mô-đun LoRA song song, nhiều bản sao của các kích hoạt nên được lưu trữ trong VRAM. Do đó, một nhược điểm chính của MultiLoRA là sử dụng VRAM kích hoạt tăng tuyến tính với số lượng mô-đun LoRA song song mà có thể không chấp nhận được trong huấn luyện chuỗi dài. Trong tiêu chuẩn của chúng tôi, huấn luyện LLaMA-7B với các chuỗi 1024 token với n= 5 sẽ sử dụng nhiều VRAM hơn tinh chỉnh toàn bộ tham số.

5 Hiểu về MultiLoRA
Trong phần này, chúng tôi áp dụng SVD trên các ma trận cập nhật trọng số được huấn luyện với LLaMA-7B trong Mục 4.1 để điều tra tại sao MultiLoRA vượt trội hơn LoRA trong việc điều chỉnh tác vụ phức tạp. Cụ thể, sự tương đồng không gian con và độ lớn của giá trị đơn lẻ được nghiên cứu kỹ lưỡng cho MultiLoRA, LoRA và tinh chỉnh.

5.1 So sánh với Tinh chỉnh
để thể hiện mức độ tương đồng cao hơn với tinh chỉnh toàn bộ tham số của MultiLoRA, chúng tôi sử dụng SVD để so sánh các ma trận cập nhật trọng số ∆W của LoRA và MultiLoRA. Cụ thể, chúng tôi tập trung vào so sánh phạm vi bao phủ không gian con của các vector đơn vị và độ lớn của các giá trị đơn lẻ.

Đối với sự tương đồng không gian con của các vector đơn vị, chúng tôi tuân theo [6] để sử dụng ϕ(∆W′,∆W, i, j) trong Phương trình 5, chuẩn Frobenius của sự tương đồng cosine giữa các vector đơn vị hàng đầu-i và hàng đầu-j của hai ma trận cập nhật trọng số.

ϕ(∆W′,∆W, i, j ) =∥U⊤
iU′
j∥2
F
min(i, j)∈[0,1], (5)

trong đó Ui=U[:,:i] và U′
j=U′[:,:j] là các vector đơn vị hàng đầu-i và hàng đầu-j được xếp chồng.

Hơn nữa, độ lớn của các giá trị đơn lẻ cung cấp những hiểu biết quý giá về tầm quan trọng tương đối của mỗi vector đơn vị. Các giá trị đơn lẻ lớn hơn biểu thị đóng góp lớn hơn cho việc đại diện dữ liệu tổng thể. Trong Mục 3.2, chúng tôi tìm thấy ∆WLoRA rất phân cực vì tỷ lệ các giá trị đơn lẻ hàng đầu là lớn nhất. Bằng cách so sánh phân phối giá trị đơn lẻ, chúng tôi muốn tìm hiểu liệu MultiLoRA có quản lý để cân bằng đóng góp của mỗi vector đơn vị hay không.

5.1.1 So sánh Không gian Con
0 10 20
(1)0
5
10
15
20
25(WV
1×LoRA,WV
FT)
0 10 20
(2)0
5
10
15
20
25(WV
3×LoRA,WV
FT)
0 10 20
(3)0
5
10
15
20
25(WV
5×LoRA,WV
FT)
0 10 20
(4)0
5
10
15
20
25(WV
FT,WV
FT)
0.00.20.40.60.81.0

Hình 4: Sự tương đồng không gian con với tinh chỉnh của LoRA (1), MultiLoRA (2, 3) và tinh chỉnh với một hạt giống ngẫu nhiên khác (4). LoRA (2) và MultiLoRA (3) có cùng ngân sách tham số nhưng MultiLoRA thể hiện sự tương đồng không gian con mạnh hơn với tinh chỉnh. Bản đồ nhiệt của MultiLoRA n=3
r=32 không khác nhiều so với MultiLoRA n=5
r=32. Chỉ i, j∈[1,30] được trình bày để có khả năng hiển thị tốt hơn.

Các vector đơn vị trực giao định nghĩa "hướng" của biến đổi dữ liệu. Bằng cách đo lường sự chồng chéo không gian con với
ϕ(∆W′,∆W), chúng tôi có thể đo lường mức độ tương đồng giữa hai biến đổi. Chúng tôi chọn ngẫu nhiên phép chiếu giá trị của lớp bộ giải mã thứ 15 để tính toán ϕ(∆WLoRA,∆WFT) và ϕ(∆WMultiLoRA,∆WFT). Sự tương đồng giữa tinh chỉnh của hai lần chạy khác nhau ϕ(∆WFT′,∆WFT) cũng được tính toán để tham khảo.

MultiLoRA giống tinh chỉnh hơn LoRA về mặt phạm vi không gian con. Theo hình ảnh hóa trong Hình 4, MultiLoRA n=3
r=32 thể hiện sự giống nhau mạnh hơn với tinh chỉnh so với LoRA r=96 dưới cùng ngân sách tham số,
8

--- TRANG 9 ---
Bài báo PRIME AI
cho thấy không gian con của ma trận cập nhật trọng số của MultiLoRA gần hơn với tinh chỉnh. Bản đồ nhiệt của LoRA
nói chung mờ hơn nhưng các vector đơn vị hàng đầu vẫn thể hiện sự chồng chéo không gian con với tinh chỉnh ở một mức độ nào đó.

Mở rộng n không nhất thiết tăng sự tương đồng không gian con MultiLoRA với tinh chỉnh. Một điều khác cần
lưu ý là sự khác biệt hầu như không thể thấy được giữa MultiLoRA n=3
r=32 và MultiLoRA n=5
r=32, có nghĩa là tăng số lượng LoRA song song n không nhất thiết làm cho không gian con gần hơn với tinh chỉnh. Cùng xu hướng có thể được quan sát trên các trọng số khác ở các độ sâu khác nhau trong ngăn xếp bộ giải mã (thêm tại Phụ lục C).

5.1.2 So sánh Phân phối Giá trị Đơn lẻ
1e1.0 1e1.5 1e2.0
Logarithm Âm của Giá trị Đơn lẻ log(s)
101
100101102Số lượng
1e1.0 1e1.5 1e2.0
Logarithm Âm của Giá trị Đơn lẻ log(s)
100101102Số lượng
LoRA r=96 Tinh chỉnh MultiLoRA n=3
r=32 MultiLoRA n=5
r=32

Hình 5: Phân phối giá trị đơn lẻ của các ma trận cập nhật trọng số ∆W của k_proj (Trái) và v_proj (Phải). MultiLoRA được đề xuất của chúng tôi thể hiện mức độ giống nhau cao hơn với tinh chỉnh. Mở rộng n tạo ra đóng góp biến đổi đơn vị dân chủ hơn.

Trong Mục 5.1.1 trước, chúng tôi đo lường sự tương đồng không gian con giữa các vector đơn vị nhưng không biết tầm quan trọng của các vector đơn vị nói trên, chúng tôi không thể kết luận sự giống nhau cao hơn giữa MultiLoRA và tinh chỉnh. Do đó, chúng tôi điều tra phân phối giá trị đơn lẻ bằng cách vẽ biểu đồ của giá trị đơn lẻ như trong Mục 3.2.

Đối với Σ =diag(s) thu được từ SVD(∆W), chúng tôi đếm số lượng s trên một loạt các ngưỡng và lấy trung bình thống kê của cùng một mô-đun qua các độ sâu khác nhau của các lớp bộ giải mã. Chúng tôi tính toán logarithm âm −log(s) để có khả năng hiển thị tốt hơn vì hơn 95% giá trị đơn lẻ nằm trong [0,1]. Kết quả được thể hiện trong Hình 5.

MultiLoRA cân bằng đóng góp không gian con so với LoRA. MultiLoRA cho thấy phân phối tương tự như tinh chỉnh trong đó số lượng giá trị đơn lẻ của MultiLoRA giảm với độ lớn của nó. Cho rằng thứ hạng thấp rõ ràng r << d, LoRA cho thấy sự phụ thuộc nặng nề vào một nhóm nhỏ các vector đơn vị hàng đầu nhưng MultiLoRA dân chủ hóa đóng góp của các vector đơn vị.

Mở rộng n làm MultiLoRA khuếch đại các đặc trưng ở mức độ tinh vi hơn. So sánh MultiLoRA n=3
r=32 và MultiLoRA n=5
r=32, biểu đồ của {s| −log(s)>1e1.6} gần như giống hệt nhưng MultiLoRA n=5
r=32 cho thấy phổ rộng hơn vì tỷ lệ các giá trị đơn lẻ nhỏ tăng lên. Một phổ rộng hơn bao phủ các giá trị đơn lẻ nhỏ cho phép khớp ∆W tinh vi hơn như tinh chỉnh.

5.2 So sánh giữa các MultiLoRA
Trong phần này, để chứng minh MultiLoRA hoàn thành mục tiêu thiết kế phản phân cực, chúng tôi so sánh từng cặp các sub-LoRA. Từ bản đồ nhiệt, sự tương đồng không gian con giữa các vector đơn vị hàng đầu-1 là khoảng 0,6. So sánh giữa ∆Wi=5 và ∆Wi=3 cho thấy sự tương đồng tương đối thấp. Phương sai của các sự tương đồng không gian con cho thấy một mô hình phân tách tinh vi hơn.
9

--- TRANG 10 ---
Bài báo PRIME AI
0 5 10 15
(1)0
5
10
15(Wn=5
i=1,Wn=5
i=3)
0 5 10 15
(2)0
5
10
15(Wn=5
i=3,Wn=5
i=3)
0 5 10 15
(3)0
5
10
15(Wn=5
i=4,Wn=5
i=3)
0 5 10 15
(4)0
5
10
15(Wn=5
i=5,Wn=5
i=3)
0.00.20.40.60.81.0

Hình 6: Sự tương đồng không gian con giữa các mô-đun song song của MultiLoRA. Chúng tôi phân tích MultiLoRA nhắm vào down_proj trong lớp bộ giải mã đầu tiên. Mỗi mô-đun riêng lẻ tạo ra các không gian con gần nhau nhưng không giống hệt nhau, do đó tăng cường tính biểu đạt chung của MultiLoRA.

5.3 Cơ chế Cơ bản của LoRA và MultiLoRA
Trong các phần trước, chúng tôi nghiên cứu sự khác biệt trong sự tương đồng không gian con và phân phối giá trị đơn lẻ bằng cách áp dụng SVD trên các ma trận cập nhật trọng số của các phương pháp được thử nghiệm. Các quan sát của chúng tôi làm sáng tỏ các cơ chế cơ bản của LoRA và MultiLoRA. Từ phân phối giá trị đơn lẻ của tinh chỉnh, chúng tôi học được rằng tinh chỉnh khớp các trọng số dư bằng cách tổng hợp một số lượng lớn (thường bằng thứ hạng của ma trận trọng số) các biến đổi đơn vị tương đối ít quan trọng hơn. Cho rằng hạn chế thứ hạng thấp, LoRA và MultiLoRA khớp các trọng số dư với r≪min(d, k) biến đổi đơn vị. Sự tương đồng không gian con thấp với tinh chỉnh và sự chi phối trong phân phối giá trị đơn lẻ quan sát được trong LoRA cho thấy LoRA có xu hướng phân tách các trọng số dư thành các biến đổi đơn vị có tầm quan trọng lớn. Trong khi đó, MultiLoRA dân chủ hóa ảnh hưởng của các biến đổi đơn vị bằng cách gán tầm quan trọng nhỏ hơn cho các biến đổi đơn vị của nó tương tự như tinh chỉnh. Với các không gian con đơn vị được dân chủ hóa, MultiLoRA tạo ra hiệu suất học đa tác vụ phức tạp tốt hơn.

6 Kết luận
Tóm lại, nghiên cứu của chúng tôi giới thiệu MultiLoRA, một phương pháp tiên tiến tăng cường điều chỉnh đa tác vụ trong các mô hình ngôn ngữ. Bằng cách giảm thiểu sự chi phối của các biến đổi đơn vị của LoRA, chúng tôi đã thành công cải thiện hiệu suất trong các tình huống đa tác vụ phức tạp. Phương pháp được đề xuất của chúng tôi tập trung vào việc mở rộng các mô-đun LoRA theo chiều ngang và sửa đổi khởi tạo tham số để giảm sự phụ thuộc tham số, do đó tạo ra các không gian con đơn vị cân bằng hơn. Ngoài ra, chúng tôi xây dựng một tập dữ liệu toàn diện bao phủ một loạt các tác vụ quan tâm cho LLM tạo sinh. Thông qua thí nghiệm rộng rãi, chúng tôi đã chứng minh rằng MultiLoRA vượt trội hơn LoRA đơn lẻ và đạt được hiệu suất tương đương với tinh chỉnh qua nhiều tiêu chuẩn và quy mô mô hình. MultiLoRA ổn định việc điều chỉnh đa tác vụ đặc biệt cho các mô hình nhỏ hơn. Hơn nữa, điều tra của chúng tôi về các ma trận cập nhật trọng số tiết lộ sự giảm đáng kể trong sự phụ thuộc vào các vector đơn vị hàng đầu và một đóng góp công bằng hơn của các không gian con đơn vị trong MultiLoRA. Nhìn chung, MultiLoRA cung cấp một giải pháp hiệu quả và hiệu suất cho việc điều chỉnh đa tác vụ trong các mô hình ngôn ngữ.
10

--- TRANG 11 ---
Bài báo PRIME AI
Tài liệu tham khảo
[1]Jacob Devlin, Ming-Wei Chang, Kenton Lee, và Kristina Toutanova. BERT: pre-training of deep bidirectional
transformers for language understanding. Trong Proceedings of the 2019 Conference of the North American Chapter of
the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis,
MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), trang 4171–4186. Association for Computational
Linguistics, 2019.
[2]Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Nee-
lakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger,
Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher
Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner,
Sam McCandlish, Alec Radford, Ilya Sutskever, và Dario Amodei. Language models are few-shot learners. Trong
Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing
Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020.
[3]Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettle-
moyer, và Veselin Stoyanov. Roberta: A robustly optimized BERT pretraining approach. CoRR, abs/1907.11692,
2019.
[4]Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix,
Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave,
và Guillaume Lample. Llama: Open and efficient foundation language models. ArXiv, abs/2302.13971, 2023.
[5]Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten
Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean,
và William Fedus. Emergent abilities of large language models. Trans. Mach. Learn. Res., 2022, 2022.
[6]Edward Hu, Yelong Shen, Phil Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Lu Wang, và Weizhu Chen. Lora:
Low-rank adaptation of large language models, 2021.
[7]Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea Gesmundo,
Mona Attariyan, và Sylvain Gelly. Parameter-efficient transfer learning for NLP. CoRR, abs/1902.00751, 2019.
[8]Xiao Liu, Kaixuan Ji, Yicheng Fu, Zhengxiao Du, Zhilin Yang, và Jie Tang. P-tuning v2: Prompt tuning can be
comparable to fine-tuning universally across scales and tasks. CoRR, abs/2110.07602, 2021.
[9]Haokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal, và Colin Raffel.
Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning. Trong NeurIPS, 2022.
[10] Rabeeh Karimi Mahabadi, Sebastian Ruder, Mostafa Dehghani, và James Henderson. Parameter-efficient
multi-task fine-tuning for transformers via shared hypernetworks. Trong Proceedings of the 59th Annual Meeting of
the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language
Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021, trang 565–576.
Association for Computational Linguistics, 2021.
[11] Zhen Wang, Rameswar Panda, Leonid Karlinsky, Rogério Feris, Huan Sun, và Yoon Kim. Multitask prompt
tuning enables parameter-efficient transfer learning. Trong The Eleventh International Conference on Learning
Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023.
[12] Deze Wang, Boxing Chen, Shanshan Li, Wei Luo, Shaoliang Peng, Wei Dong, và Xiangke Liao. One adapter for
all programming languages? adapter tuning for code search and summarization. Trong 45th IEEE/ACM International
Conference on Software Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023, trang 5–16. IEEE,
2023.
[13] Yaqing Wang, Sahaj Agarwal, Subhabrata Mukherjee, Xiaodong Liu, Jing Gao, Ahmed Hassan Awadallah, và
Jianfeng Gao. Adamix: Mixture-of-adaptations for parameter-efficient model tuning. Trong Proceedings of the 2022
Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab
Emirates, December 7-11, 2022, trang 5744–5760. Association for Computational Linguistics, 2022.
[14] Reza Yazdani Aminabadi, Samyam Rajbhandari, Ammar Ahmad Awan, Cheng Li, Du Li, Elton Zheng, Olatunji
Ruwase, Shaden Smith, Minjia Zhang, Jeff Rasley, và Yuxiong He. Deepspeed- inference: Enabling efficient
inference of transformer models at unprecedented scale. Trong SC22: International Conference for High Performance
Computing, Networking, Storage and Analysis, Dallas, TX, USA, November 13-18, 2022, trang 46:1–46:15. IEEE,
2022.
[15] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, và
Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model. https://github.com/
tatsu-lab/stanford_alpaca, 2023.
11

--- TRANG 12 ---
Bài báo PRIME AI
[16] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, và Jacob Steinhardt. Mea-
suring massive multitask language understanding. Trong 9th International Conference on Learning Representations,
ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021.
[17] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert,
Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, và John Schulman. Training verifiers to solve
math word problems. CoRR, abs/2110.14168, 2021.
[18] Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, và
Samuel R. Bowman. Superglue: A stickier benchmark for general-purpose language understanding systems. Trong
Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing
Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, trang 3261–3275, 2019.
[19] Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min
Chan, Weize Chen, et al. Delta tuning: A comprehensive study of parameter efficient methods for pre-trained
language models. arXiv preprint arXiv:2203.06904, 2022.
[20] Ruidan He, Linlin Liu, Hai Ye, Qingyu Tan, Bosheng Ding, Liying Cheng, Jia-Wei Low, Lidong Bing, và Luo Si.
On the effectiveness of adapter-based tuning for pretrained language model adaptation. Trong Proceedings of the 59th
Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on
Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021,
trang 2208–2222. Association for Computational Linguistics, 2021.
[21] Elad Ben Zaken, Yoav Goldberg, và Shauli Ravfogel. Bitfit: Simple parameter-efficient fine-tuning for
transformer-based masked language-models. Trong Proceedings of the 60th Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022, trang 1–9.
Association for Computational Linguistics, 2022.
[22] Kevin Meng, David Bau, Alex Andonian, và Yonatan Belinkov. Locating and editing factual associations in
GPT. Trong NeurIPS, 2022.
[23] Qingru Zhang, Minshuo Chen, Alexander Bukharin, Pengcheng He, Yu Cheng, Weizhu Chen, và Tuo Zhao.
Adaptive budget allocation for parameter-efficient fine-tuning. Trong The Eleventh International Conference on
Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023.
[24] Yuning Mao, Lambert Mathias, Rui Hou, Amjad Almahairi, Hao Ma, Jiawei Han, Scott Yih, và Madian Khabsa.
Unipelt: A unified framework for parameter-efficient language model tuning. Trong Proceedings of the 60th Annual
Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland,
May 22-27, 2022, trang 6253–6264. Association for Computational Linguistics, 2022.
[25] Kaiming He, Xiangyu Zhang, Shaoqing Ren, và Jian Sun. Delving deep into rectifiers: Surpassing human-level
performance on imagenet classification. Trong 2015 IEEE International Conference on Computer Vision, ICCV 2015,
Santiago, Chile, December 7-13, 2015, trang 1026–1034. IEEE Computer Society, 2015.
[26] Xavier Glorot và Yoshua Bengio. Understanding the difficulty of training deep feedforward neural networks. Trong
Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, AISTATS 2010,
Chia Laguna Resort, Sardinia, Italy, May 13-15, 2010, volume 9 of JMLR Proceedings, trang 249–256. JMLR.org,
2010.
[27] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,
Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Köpf, Edward Z. Yang, Zachary
DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, và Soumith
Chintala. Pytorch: An imperative style, high-performance deep learning library. Trong Advances in Neural Information
Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019,
December 8-14, 2019, Vancouver, BC, Canada, trang 8024–8035, 2019.
[28] Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, và Luke Zettlemoyer. Qlora: Efficient finetuning of quantized
llms. CoRR, abs/2305.14314, 2023.
[29] Sadhika Malladi, Tianyu Gao, Eshaan Nichani, Alex Damian, Jason D. Lee, Danqi Chen, và Sanjeev Arora.
Fine-tuning language models with just forward passes. CoRR, abs/2305.17333, 2023.
[30] Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, Sayak Paul, và Benjamin Bossan. Peft:
State-of-the-art parameter-efficient fine-tuning methods. https://github.com/huggingface/peft, 2022.
[31] Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, và Yuxiong He. Zero: memory optimizations toward training
trillion parameter models. Trong Proceedings of the International Conference for High Performance Computing,
Networking, Storage and Analysis, SC 2020, Virtual Event / Atlanta, Georgia, USA, November 9-19, 2020, trang 20.
IEEE/ACM, 2020.
12

--- TRANG 13 ---
Bài báo PRIME AI
[32] Ilya Loshchilov và Frank Hutter. Decoupled weight decay regularization. Trong 7th International Conference on
Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net, 2019.
[33] Sebastian Ruder. An overview of gradient descent optimization algorithms. CoRR, abs/1609.04747, 2016.
[34] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac,
Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite,
Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, và Alexander M.
Rush. Transformers: State-of-the-art natural language processing. Trong Proceedings of the 2020 Conference on
Empirical Methods in Natural Language Processing: System Demonstrations, trang 38–45, Online, October 2020.
Association for Computational Linguistics.
13

--- TRANG 14 ---
Bài báo PRIME AI
A Siêu tham số
Chúng tôi liệt kê các siêu tham số được sử dụng trong các thí nghiệm của chúng tôi trong Bảng 3. Kích thước batch là 32 được đạt được cho LLaMA-30B và
LLaMA-65B với tích lũy gradient. Chúng tôi sử dụng các giá trị mặc định được cung cấp bởi Huggingface transformers[34] trainer cho hầu hết
các siêu tham số tối ưu hóa.

Siêu tham số Thí nghiệm Giá trị
Kích thước Batch mỗi GPU 32
Số Epoch 2
Tinh chỉnh Tốc độ Học 5e-6
Lịch trình LR Tuyến tính
Tối ưu hóa AdamW
Tỷ lệ Warmup 0.05
LoRA Tốc độ Học 5e-5
Lịch trình LR Tuyến tính
Tối ưu hóa AdamW
Tỷ lệ Warmup 0.05
MultiLoRA Tốc độ Học 5e-5
Lịch trình LR Tuyến tính
Tối ưu hóa AdamW
Tỷ lệ Warmup 0.05

Bảng 3: Siêu tham số Huấn luyện được sử dụng trong các thí nghiệm của chúng tôi.

B Phân phối Giá trị Đơn lẻ
1e1.0 1e2.0
Logarithm Âm của Giá trị Đơn lẻ log(s)
05101520Số lượng
Guanaco r=64 Alpaca r=96 MMLU r=96
(a)v_proj
1e1.0 1e2.0
Logarithm Âm của Giá trị Đơn lẻ log(s)
0.02.55.07.510.012.515.017.520.0Số lượng
Guanaco r=64 Alpaca r=96 MMLU r=96 (b)q_proj

Hình 7: Phân phối Giá trị Đơn lẻ của (a) v_proj và (b) q_proj của các ma trận cập nhật trọng số được huấn luyện trên các tập dữ liệu khác nhau.

Trong Mục 3.2, chúng tôi thấy rằng các ma trận cập nhật trọng số của LoRA bị chi phối bởi một nhóm nhỏ các biến đổi đơn vị.
Để hỗ trợ thêm cho điều này, chúng tôi đã phân tích các mô-đun LoRA thu được từ việc huấn luyện trên các tập dữ liệu khác nhau hoặc sử dụng các tài nguyên có sẵn công khai. Chúng tôi sử dụng các mô-đun LoRA thu được bằng cách huấn luyện trên các tập dữ liệu có sẵn công khai (MMLU và Alpaca) hoặc tải xuống các tài nguyên có sẵn công khai (Guanaco⁴).

⁴Có thể tải xuống tại https://huggingface.co/timdettmers/guanaco-7b/tree/main
14

--- TRANG 15 ---
Bài báo PRIME AI
Hình 7 vẽ biểu đồ của các giá trị đơn lẻ của các ma trận cập nhật trọng số của q_proj và v_proj. Để tăng cường hình ảnh hóa,
logarithm âm của các giá trị đơn lẻ (−log(s)) được tính toán, cho rằng hầu hết các giá trị nhỏ hơn 0,1
Các giá trị trung bình được sử dụng để tổng hợp thống kê qua tất cả các lớp bộ giải mã. Biểu đồ cho cả hai mô-đun thể hiện một
sự giống nhau nổi bật. Hình dạng tam giác của biểu đồ cho thấy sự chi phối của các vector đơn vị hàng đầu, như đã đề cập trong
Mục 3.2. Đáng chú ý là sự chi phối này phát sinh từ thiết kế vốn có của LoRA, vì chúng tôi không cố ý
thay đổi cấu trúc của nó hoặc sử dụng các tập dữ liệu không thông thường.

C Sự tương đồng Không gian con của các mô-đun khác ở độ sâu khác nhau
Trong Mục 5.1.1, chúng tôi sử dụng sự tương đồng cosine giữa các vector đơn vị hàng đầu để đo lường sự chồng chéo không gian con của ∆W. Ở đây, chúng tôi
trình bày thêm các hình ảnh hóa về các mô-đun khác nhau từ các độ sâu khác nhau của ngăn xếp bộ giải mã.

0 10 20
(1)0
5
10
15
20
25(WQ
1×LoRA,WQ
FT)
0 10 20
(2)0
5
10
15
20
25(WQ
3×LoRA,WQ
FT)
0 10 20
(3)0
5
10
15
20
25(WV
5×LoRA,WV
FT)
0 10 20
(4)0
5
10
15
20
25(WQ
FT,WQ
FT)
0.00.20.40.60.81.0
(a)up_proj của MLP trong lớp bộ giải mã thứ 28.
0 10 20
(1)0
5
10
15
20
25(WV
1×LoRA,WV
FT)
0 10 20
(2)0
5
10
15
20
25(WV
3×LoRA,WV
FT)
0 10 20
(3)0
5
10
15
20
25(WV
5×LoRA,WV
FT)
0 10 20
(4)0
5
10
15
20
25(WV
FT,WV
FT)
0.00.20.40.60.81.0
(b)q_proj của self attention trong lớp bộ giải mã thứ 1.
0 10 20
(1)0
5
10
15
20
25(WV
1×LoRA,WV
FT)
0 10 20
(2)0
5
10
15
20
25(WV
3×LoRA,WV
FT)
0 10 20
(3)0
5
10
15
20
25(WV
5×LoRA,WV
FT)
0 10 20
(4)0
5
10
15
20
25(WV
FT,WV
FT)
0.00.20.40.60.81.0
(c)k_proj của self attention trong lớp bộ giải mã thứ 14.

Hình 8: Sự tương đồng không gian con của LoRA và MultiLoRA với tinh chỉnh của các mô-đun khác nhau ở các độ sâu khác nhau.

Chúng tôi chọn ngẫu nhiên up_proj, q_proj và k_proj của MLP và mô-đun self attention ở các độ sâu khác nhau để so sánh các ma trận cập nhật trọng số
của LoRA và MultiLoRA với tinh chỉnh. Hình ảnh hóa bản đồ nhiệt cho thấy mức độ tương đồng cao hơn
của MultiLoRA như quan sát được trong Mục 5.1.1. Quan sát của chúng tôi làm sáng tỏ cơ chế của LoRA rằng trọng số dư
được phân tách thành một nhóm nhỏ các biến đổi đơn vị có tầm quan trọng lớn. Các biến đổi đơn vị quan trọng
15

--- TRANG 16 ---
Bài báo PRIME AI
với số lượng nhỏ cản trở khả năng xử lý học đa tác vụ phức tạp của mô hình. Trong khi đó, MultiLoRA quản lý để khớp
trọng số dư giống hơn với tinh chỉnh, tập hợp một số lượng lớn hơn các biến đổi tương đối ít quan trọng hơn.
16

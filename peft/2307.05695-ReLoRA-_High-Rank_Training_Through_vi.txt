# 2307.05695.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2307.05695.pdf
# Kích thước tệp: 1955171 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
ReLoRA: Huấn Luyện Hạng Cao Thông Qua
Các Cập Nhật Hạng Thấp
Vladislav Lialin†,‡∗Sherin Muckatira†, Namrata Shivagunde†, và Anna Rumshisky†,§
†Đại học Massachusetts Lowell
‡Eleuther AI
§Amazon
Tóm tắt
Bất chấp sự thống trị và hiệu quả của việc mở rộng quy mô, dẫn đến các mạng lớn
với hàng trăm tỷ tham số, sự cần thiết phải huấn luyện các mô hình có quá nhiều tham số
vẫn còn được hiểu kém, trong khi chi phí huấn luyện tăng theo cấp số nhân. Trong
bài báo này, chúng tôi khám phá các kỹ thuật huấn luyện tiết kiệm tham số như một cách tiếp cận để
huấn luyện các mạng neural lớn. Chúng tôi giới thiệu một phương pháp mới gọi là ReLoRA,
sử dụng các cập nhật hạng thấp để huấn luyện các mạng hạng cao. Chúng tôi áp dụng ReLoRA để
huấn luyện các mô hình ngôn ngữ transformer với tối đa 1.3B tham số và chứng minh
hiệu suất tương đương với việc huấn luyện mạng neural thông thường. ReLoRA tiết kiệm tới 5.5Gb RAM trên mỗi GPU và cải thiện tốc độ huấn luyện 9-40% tùy thuộc vào
kích thước mô hình và thiết lập phần cứng. Các phát hiện của chúng tôi cho thấy tiềm năng của các kỹ thuật tiết kiệm tham số cho việc tiền huấn luyện quy mô lớn. Mã nguồn của chúng tôi có sẵn trên GitHub2.

1 Giới thiệu
Trong thập kỷ qua, lĩnh vực học máy đã bị thống trị bởi xu hướng huấn luyện
các mạng ngày càng có quá nhiều tham số hoặc áp dụng cách tiếp cận "xếp thêm nhiều lớp" [Krizhevsky
et al., 2012, He et al., 2016, Kaplan et al., 2020]. Định nghĩa của một mạng lớn đã phát triển từ
các mô hình với 100 triệu [Simonyan và Zisserman, 2015, Radford et al., 2018] đến hàng trăm tỷ
[Brown et al., 2020, Chowdhery et al., 2022] tham số, điều này đã làm cho chi phí tính toán
liên quan đến việc huấn luyện các mạng như vậy trở nên cấm đoán đối với hầu hết các nhóm nghiên cứu. Bất chấp điều này,
sự cần thiết phải huấn luyện các mô hình có thể có nhiều tham số hơn hàng bậc độ lớn so với các ví dụ huấn luyện [Brown et al., 2020, Chowdhery et al., 2022, Fedus et al., 2022], được hiểu kém
về mặt lý thuyết [Jacot et al., 2018, Allen-Zhu et al., 2019, Zhang et al., 2021].

Các cách tiếp cận thay thế cho việc mở rộng quy mô, như các tối ưu mở rộng hiệu quả tính toán hơn [Hoffmann et al.,
2022], các mô hình tăng cường truy xuất [Khandelwal et al., 2020, Borgeaud et al., 2022], và cách tiếp cận đơn giản của việc huấn luyện các mô hình nhỏ hơn trong thời gian dài hơn [Touvron et al., 2023], đã đưa ra các sự đánh đổi mới.
Tuy nhiên, chúng không đưa chúng ta đến gần hơn với việc hiểu tại sao chúng ta cần các mô hình có quá nhiều tham số và
hiếm khi dân chủ hóa việc huấn luyện các mô hình này. Ví dụ, việc huấn luyện RETRO [Borgeaud et al.,
2022] đòi hỏi một thiết lập huấn luyện phức tạp và cơ sở hạ tầng có khả năng tìm kiếm nhanh chóng trên hàng nghìn tỷ
token, trong khi việc huấn luyện LLaMA-7B [Touvron et al., 2023] vẫn đòi hỏi hàng trăm GPU.

Ngược lại, các cách tiếp cận như bộ tối ưu hóa không dư thừa [Rajbhandari et al., 2020], huấn luyện 16-bit
[Micikevicius et al., 2018], suy luận 8-bit [Dettmers et al., 2022], và tinh chỉnh tiết kiệm tham số
(PEFT) [Lialin et al., 2023] đã đóng vai trò quan trọng trong việc làm cho các mô hình lớn dễ tiếp cận hơn.
Cụ thể, các phương pháp PEFT đã cho phép tinh chỉnh các mô hình ngôn ngữ hoặc khuếch tán quy mô tỷ
trên phần cứng tiêu dùng. Điều này đặt ra câu hỏi: Liệu các cách tiếp cận này cũng có thể mang lại lợi ích cho việc tiền huấn luyện?

∗Liên hệ tới vlad.lialin@gmail.com
2github.com/guitaricet/reloraarXiv:2307.05695v4  [cs.CL]  10 Dec 2023

--- TRANG 2 ---
0 2500 5000 7500 10000 12500 15000 17500 200003.03.54.04.55.0Mất mát250M
250M ReLoRA
(99M có thể huấn luyện)
99M
0 2500 5000 7500 10000 12500 15000 17500 20000
Bước0100250Tham số có thể huấn luyệnHình 1: Mất mát huấn luyện cho các mô hình 250M. ReLoRA học một mạng hạng cao thông qua một chuỗi
các cập nhật hạng thấp. Nó vượt trội hơn các mạng có cùng số lượng tham số có thể huấn luyện và đạt được
hiệu suất tương tự với việc huấn luyện một mạng đầy đủ ở quy mô 100M+. Hiệu quả của ReLoRA tăng
với kích thước mô hình, làm cho nó trở thành một ứng cử viên khả thi cho việc huấn luyện đa tỷ tham số.

Đóng góp của chúng tôi Trong nghiên cứu này, chúng tôi giới thiệu ReLoRA sử dụng các cập nhật hạng thấp riêng lẻ
tập hợp trong quá trình huấn luyện để huấn luyện một mạng hạng cao. Chúng tôi chứng minh thực nghiệm
rằng ReLoRA thực hiện một cập nhật hạng cao và đạt được hiệu suất tương tự với việc huấn luyện mạng neural
thông thường. Các thành phần của ReLoRA bao gồm huấn luyện hạng đầy đủ ban đầu của mạng neural (tương tự
như Frankle et al. [2019]), huấn luyện LoRA, khởi động lại, một lịch trình tốc độ học có răng cưa, và đặt lại bộ tối ưu hóa một phần. Chúng tôi đánh giá ReLoRA trên các mô hình ngôn ngữ transformer lên tới 1.3B tham số. Cuối cùng, chúng tôi
quan sát thấy rằng hiệu quả của ReLoRA tăng với kích thước mô hình, làm cho nó trở thành một lựa chọn khả thi cho
việc huấn luyện hiệu quả các mạng đa tỷ tham số.

2 Phương pháp
Chúng tôi quan tâm đến hạng của tổng hai ma trận: rank(A+B)≤rank(A) +rank(B). Chúng tôi
biết rằng đối với ma trận A,rank(A)< dim (A), tồn tại B,rank(B)< dim (B) sao cho tổng
của chúng có hạng cao hơn A hoặc B.

Chúng tôi muốn khai thác tính chất này để tạo ra một phương pháp huấn luyện tiết kiệm tham số linh hoạt. Chúng tôi bắt đầu
với LoRA [Hu et al., 2022] là một phương pháp tinh chỉnh tiết kiệm tham số dựa trên ý tưởng
các cập nhật hạng thấp. LoRA có thể được áp dụng cho bất kỳ phép toán tuyến tính nào được tham số hóa thông qua W∈Rm×n.
Cụ thể, LoRA phân tách cập nhật trọng số δW thành một tích hạng-r WAWB như được hiển thị trong
Phương trình 1, trong đó s∈R là một hệ số tỷ lệ cố định thường bằng 1/r.

δW=sWAWB
WA∈Rin×r, WB∈Rr×out(1)

Trong thực tế, LoRA thường được triển khai bằng cách thêm các tham số có thể huấn luyện mới WA và WB, có thể được hợp nhất trở lại vào các tham số gốc sau khi huấn luyện. Do đó, các triển khai này bị
hạn chế bởi hạng r= max WA,WB rank(WAWB).

Nếu chúng ta có thể khởi động lại LoRA, nghĩa là chúng ta hợp nhất WA và WB trong quá trình huấn luyện và đặt lại các giá trị của
các ma trận này, chúng ta có thể tăng tổng hạng của cập nhật. Làm điều này nhiều lần đưa
tổng cập nhật mạng neural đến:

∆W=T1Σt=0δWt+T2Σt=T1δWt+···+TNΣt=TN−1δWt=sW1AW1B+sW2AW2B+···+sWNAWNB(2)

Tuy nhiên, việc triển khai khởi động lại không đơn giản trong thực tế và đòi hỏi một số sửa đổi đối với
quy trình tối ưu hóa. Không giống như gradient descent ngẫu nhiên đơn thuần, Adam [Kingma và Ba, 2015]

--- TRANG 3 ---
0 2000 4000 6000 8000 10000
Bước0.00.20.40.60.81.0Hệ số nhân tốc độ họcHình 2: Bộ lập lịch cosine có răng cưa được sử dụng trong ReLoRA. Như một cơ sở cho bộ lập lịch của chúng tôi, chúng tôi tuân theo một lịch trình suy giảm cosine tiêu chuẩn như trong Touvron et al. [2023]. Trên mỗi lần đặt lại bộ tối ưu hóa, chúng tôi đặt tốc độ học về không và thực hiện một quá trình khởi động nhanh (50-100 bước) tốc độ học trở lại lịch trình cosine.

cập nhật được hướng dẫn chủ yếu bởi các moment thứ nhất và thứ hai của gradient tích lũy trong
các bước trước đó. Trong thực tế, β1 và β2 của Adam thường rất cao 0.9−0.999. Điều này có nghĩa là
sau khi hợp nhất và khởi tạo lại, việc tiếp tục sử dụng các moment gradient cũ cho W2A sẽ hướng dẫn nó theo cùng
hướng như W1A và tối ưu hóa cùng một không gian con.

Để giải quyết vấn đề này, ReLoRA thực hiện một đặt lại một phần trạng thái bộ tối ưu hóa trong quá trình hợp nhất và khởi tạo lại
thông qua cắt tỉa độ lớn. Để tránh mất mát phân kỳ sau khi đặt lại bộ tối ưu hóa, nó cũng đặt tốc độ học
về 0 với một quá trình khởi động tiếp theo (Hình 2). Các nghiên cứu phân tích của chúng tôi (Bảng 6) cho thấy rằng cả hai sửa đổi này đều cần thiết để cải thiện hiệu suất so với LoRA. Cuối cùng, trong các thí nghiệm của chúng tôi, chúng tôi
thấy rằng trong trường hợp huấn luyện từ đầu (khởi tạo ngẫu nhiên), cần có một quá trình huấn luyện hạng đầy đủ ngắn để "khởi động ấm" ReLoRA. Tất cả điều này cho phép ReLoRA đạt được hiệu suất có thể so sánh với
huấn luyện hạng đầy đủ, đặc biệt là trong các mạng transformer lớn, chỉ bằng cách huấn luyện một tập hợp nhỏ các tham số
tại một thời điểm. ReLoRA được mô tả trong Thuật toán 1.

Tăng cường hiệu quả tính toán Không giống như các kỹ thuật huấn luyện hạng thấp khác [Schotthöfer et al.,
2022, Sui et al., 2023, Kamalakara et al., 2022], ReLoRA tuân theo cách tiếp cận LoRA bằng cách duy trì
các trọng số đóng băng của mạng gốc và thêm các tham số có thể huấn luyện mới. Thoạt nhìn, điều này
có thể xuất hiện không hiệu quả về mặt tính toán; tuy nhiên, sự phân biệt giữa các tham số đóng băng và có thể huấn luyện đóng vai trò quan trọng trong tinh chỉnh tiết kiệm tham số [Lialin et al., 2023].

Bằng cách giảm số lượng tham số có thể huấn luyện, ReLoRA giảm đáng kể bộ nhớ dành cho
các trạng thái bộ tối ưu hóa và cho phép sử dụng các kích thước batch lớn hơn, tối đa hóa hiệu quả phần cứng.
Ngoài ra, nó giảm yêu cầu băng thông trong các thiết lập phân tán, thường là yếu tố hạn chế trong huấn luyện quy mô lớn. Hơn nữa, vì các tham số đóng băng không được cập nhật giữa
các lần khởi động lại, chúng có thể được giữ ở định dạng lượng tử hóa độ chính xác thấp [Dettmers et al., 2023], giảm thêm
tác động bộ nhớ và tính toán của chúng.

Huấn luyện hạng thấp cục bộ: Trực giác Nhiều nghiên cứu gợi ý rằng việc huấn luyện mạng neural hoặc
hoàn toàn hạng thấp hoặc có nhiều giai đoạn với ban đầu hạng cao và tiếp theo hạng thấp
huấn luyện. Ví dụ, Aghajanyan et al. [2021] cho thấy rằng khi mô hình trở nên lớn hơn hoặc khi nó
được tiền huấn luyện lâu hơn, hạng của cập nhật cần thiết để học một nhiệm vụ downstream giảm. Arora
et al. [2019] thấy rằng SGD thiên về các giải pháp hạng thấp. Sự tồn tại của Lottery Tickets
sớm trong huấn luyện [Frankle et al., 2019] cũng một phần hỗ trợ giả thuyết này, vì việc huấn luyện một mạng
lottery ticket có thể được coi hiệu quả như một xấp xỉ hạng thấp cho quá trình huấn luyện thông thường.

Phân tích thực nghiệm của chúng tôi (Phần 4) cho thấy rằng các mạng neural được tiền huấn luyện thể hiện các cập nhật hạng cao
trên các quỹ đạo dài (Hình 4). Tuy nhiên, đối với một quỹ đạo đủ nhỏ, việc huấn luyện có thể được
xấp xỉ hiệu quả bằng một cập nhật hạng thấp. Dựa trên các kết quả trên, chúng tôi suy đoán rằng
huấn luyện mạng neural là hạng thấp cục bộ, điều này trực tiếp thúc đẩy ReLoRA.

--- TRANG 4 ---
Thuật toán 1 ReLoRA. θ là tham số mô hình, ˆθ là tham số mô hình với các lớp tuyến tính được thay thế bằng
ReLoRA, M và V là trạng thái bộ tối ưu hóa Adam, η là tốc độ học, và q là tần suất khởi tạo lại.
Yêu cầu: θ,M,V,q,η
1:for t in các bước khởi động ấm do
2: Cập nhật θ,M,V,η{Huấn luyện thông thường cho khởi động ấm}
3:end for
4:for lớp in các lớp mô hình do
5: if lớp is tuyến tính then
6: lớp←ReLoRA (Wi, WiA, WiB)
7: Đóng băng Wi
8: end if
9:end for
10:for t in các bước huấn luyện do
11: Cập nhật ˆθ,M,V{Bước huấn luyện với ReLoRA}
12: if MOD (t, q) = 0 then
13: for l in các lớp mô hình do
14: if l is tuyến tính then
15: Wi←(Wi+sWiAWiB)
16: WiA←kaiming_init( WiA);WiB←0
17: MWiA←prune (MWiA);VWiA←prune (VWiA)
18: end if
19: end for
20: Bắt đầu η warmup
21: end if
22:end for
23:return θ

3 Thí nghiệm
Để đánh giá hiệu quả của ReLoRA, chúng tôi áp dụng nó để huấn luyện một mô hình ngôn ngữ transformer trên
bộ dữ liệu C4 [Raffel et al., 2020] sử dụng các kích thước mô hình khác nhau: 60M, 130M, 250M, 350M, và 1.3B.
Trong tất cả các thí nghiệm, chúng tôi huấn luyện mà không lặp lại dữ liệu (epoch đơn) trên ít nhất lượng dữ liệu
tối ưu tính toán, được ước tính bằng Luật Mở rộng Chinchilla [Hoffmann et al., 2022].

Kiến trúc và siêu tham số huấn luyện Kiến trúc của chúng tôi dựa trên transformer [Vaswani
et al., 2017] và giống với LLaMA [Touvron et al., 2023]. Cụ thể, chúng tôi sử dụng tiền chuẩn hóa,
RMSNorm [Zhang và Sennrich, 2019], kích hoạt SwiGLU [Shazeer, 2020], 8/3h kích thước trạng thái ẩn được kết nối đầy đủ [Touvron et al., 2023], và nhúng quay [Su et al., 2021]. Chúng tôi chọn số lượng
token tiền huấn luyện dựa trên luật mở rộng Chinchilla [Hoffmann et al., 2022]. Kiến trúc và
siêu tham số huấn luyện được trình bày trong Bảng 1.

Đối với tất cả các thí nghiệm LoRA và ReLoRA, chúng tôi sử dụng hạng r= 128 vì các thí nghiệm ban đầu của chúng tôi cho thấy nó có
sự đánh đổi perplexity/bộ nhớ tốt nhất. Bạn có thể tìm thấy các khuyến nghị bổ sung về lựa chọn siêu tham số ReLoRA trong Phụ lục A. Chúng tôi thực hiện các thí nghiệm bổ sung so sánh khác nhau

Tham số Ẩn Đầu Lớp Tốc độ học Kích thước batch Độ dài seq. Lượng dữ liệu
60M 512 8 8 1e-3 122K 256 1.2B
130M 768 12 12 1e-3 154K 256 2.6B
250M 768 16 24 5e-4 590K 512 6.8B
350M 1024 16 24 5e-4 590K 512 6.8B
1.3B 2048 24 32 4e-4 786K 512 23.1B

Bảng 1: Siêu tham số của các mô hình ngôn ngữ được huấn luyện trong nghiên cứu này. Kích thước batch và lượng dữ liệu
được chỉ định theo token.

--- TRANG 5 ---
60M 130M 250M 350M 1.3B
Huấn luyện đầy đủ 33.81 (60M) 23.65 (130M) 22.39 (250M) 18.66 (350M) 16.83 (250M)
Kiểm soát 36.52 (43M) 27.30 (72M) 25.43 (99M) 23.65 (130M) 21.73 (250M)
LoRA 47.44 (43M) 34.17 (72M) 36.60 (99M) 57.11 (125M) -
LoRA + Khởi động ấm 34.73 (43M) 25.46 (72M) 22.86 (99M) 19.73 (125M) 18.23 (250M)
ReLoRA 34.46 (43M) 25.04 (72M) 22.48 (99M) 19.32 (125M) 17.27 (250M)
Token huấn luyện 1.2B 2.6B 6.8B 6.8B 23.1B

Bảng 2: Perplexity mô hình ngôn ngữ khi được huấn luyện bằng từng phương pháp trên. Số lượng
tham số có thể huấn luyện cho mỗi mô hình trong (ngoặc đơn). Baseline kiểm soát là huấn luyện hạng đầy đủ một mô hình với
cùng tổng số tham số như số lượng tham số có thể huấn luyện trong huấn luyện hạng thấp.

CoLA STS-B MRPC RTE SST2 MNLI QNLI QQP Trung bình
Tiền huấn luyện hạng đầy đủ 35.43 83.85 76.96 64.26 88.99 70.98 83.38 84.49 73.54
Không tiền huấn luyện 7.59 22.73 67.00 51.15 82.61 60.04 67.92 78.40 54.68
ReLoRA 31.07 83.33 78.43 60.65 89.45 72.27 83.93 86.01 73.14

Bảng 3: Áp dụng ReLoRA để tinh chỉnh các mô hình 350M được tiền huấn luyện hạng đầy đủ và sử dụng ReLoRA. Chúng tôi
quan sát thấy sự khác biệt tối thiểu giữa các mô hình.

lựa chọn hạng cho mô hình 1.3B trong Phần 4.1. Chúng tôi sử dụng bfloat16 cho tất cả các phép toán dấu phẩy động và
FlashAttention [Dao et al., 2022] để tính toán attention hiệu quả.

Thiết lập ReLoRA và baseline Trong các thí nghiệm của chúng tôi, ReLoRA thay thế tất cả các tham số attention và mạng được kết nối đầy đủ, trong khi cập nhật các lớp nhúng và chuẩn hóa hạng đầy đủ.
Vì các mô hình được bao bọc ReLoRA có ít tham số có thể huấn luyện hơn so với huấn luyện hạng đầy đủ, chúng tôi bao gồm
một baseline Kiểm soát, là một transformer hạng đầy đủ với cùng số lượng tham số có thể huấn luyện như
ReLoRA.

Chúng tôi khởi tạo ReLoRA từ một checkpoint của huấn luyện hạng đầy đủ tại 5,000 bước cập nhật và đặt lại nó mỗi
5,000 bước sau đó, 3 lần tổng cộng cho đến khi chúng tôi đạt 20K bước. Sau mỗi lần đặt lại, 99% trạng thái bộ tối ưu hóa được cắt tỉa dựa trên độ lớn, và mất mát được khởi động ấm trong 100 lần lặp tiếp theo. Các tham số ReLoRA được khởi tạo lại theo các thực hành tốt nhất của LoRA, khởi tạo Kaiming [He et al., 2015]
cho ma trận A, và số không cho ma trận B.

Mở rộng lên 1.3B Sau các kết quả ban đầu ở kích thước mô hình 130M và 350M, chúng tôi áp dụng ReLoRA để
huấn luyện một mô hình ngôn ngữ 1.3B tham số. Như một baseline, chúng tôi tiền huấn luyện một mô hình 1.3B từ đầu trên
23B token. Chúng tôi thực hiện nhiều lần chạy ReLoRA bắt đầu từ các checkpoint 2K, 5K, và 10K. Trong
hầu hết các thí nghiệm, chúng tôi tiếp tục sử dụng r= 128 và các thí nghiệm bổ sung của chúng tôi cho thấy sự khác biệt tối thiểu giữa hạng 128 và 512 (kích thước ẩn là 2048). Phần 4.1 mô tả chi tiết các thí nghiệm này.

4 Kết quả
Tiền huấn luyện tiết kiệm tham số Kết quả của chúng tôi được trình bày trong Bảng 2 và Hình 1. ReLoRA vượt trội đáng kể so với huấn luyện LoRA, chứng minh tính hiệu quả của các sửa đổi được đề xuất của chúng tôi
(được phân tích trong Phần 6). Các hình mất mát tiền huấn luyện bổ sung có sẵn trong Phụ lục C.

Hơn nữa, ReLoRA đạt được hiệu suất tương tự với huấn luyện hạng đầy đủ trong cả nhiệm vụ upstream và
downstream (Bảng 3).3

Huấn luyện hạng cao thông qua các cập nhật hạng thấp Để xác định liệu ReLoRA có thực hiện một cập nhật hạng cao hơn LoRA hay không, chúng tôi vẽ phổ giá trị kỳ dị của cập nhật đã học đến khởi động ấm

3Lưu ý rằng các giá trị tuyệt đối của kết quả GLUE dự kiến sẽ khá xa so với state-of-the-art, vì các
mô hình của chúng tôi được tiền huấn luyện trên khoảng 20 lần ít dữ liệu hơn T5 hoặc BERT.

--- TRANG 6 ---
0.0 0.5 1.0 1.5 2.0
Giá trị Kỳ dị0.00.51.01.52.02.53.0Tần suấtPhép chiếu Q
ReLoRA
LoRA
Huấn luyện
hạng đầy đủ
0.0 0.5 1.0 1.5 2.0
Giá trị Kỳ dị0.00.51.01.52.02.53.0Phép chiếu K
ReLoRA
LoRA
Huấn luyện
hạng đầy đủ
0.0 0.5 1.0 1.5 2.0
Giá trị Kỳ dị0.00.51.01.52.02.53.0Phép chiếu V
ReLoRA
LoRA
Huấn luyện
hạng đầy đủ
0.0 0.5 1.0 1.5 2.0
Giá trị Kỳ dị0.00.51.01.52.02.53.0Phép chiếu Xuống
ReLoRA
LoRA
Huấn luyện
hạng đầy đủHình 3: Phổ giá trị kỳ dị của sự khác biệt trọng số giữa ReLoRA và LoRA tại 5,000
lần lặp (khởi động ấm) và 20,000 lần lặp. ReLoRA thể hiện sự tương đồng gần gũi hơn với huấn luyện hạng đầy đủ so với LoRA, cho thấy tính hiệu quả của nó trong việc xấp xỉ hành vi hạng đầy đủ. Các mô hình 350M.

WQWKWVW lênW xuống02505007501000
Huấn luyện
Hạng đầy đủ
LoRA
ReLoRA

Hình 4: Số lượng giá trị kỳ dị >0.1 trong ma trận trọng số của cập nhật đã học. Các mô hình 350M.

trọng số. Cụ thể, sự khác biệt giữa trọng số khởi động ấm và trọng số cuối cùng cho ReLoRA,
LoRA, và các mô hình được huấn luyện hạng đầy đủ. Hình 3 minh họa sự khác biệt định tính đáng kể giữa
LoRA và ReLoRA đối với các giá trị kỳ dị của ∆WQ,∆WK,∆WV, và ∆Wxuống. Trong khi hầu hết
các giá trị kỳ dị cho LoRA bằng không (Hình 4) với một số đáng chú ý các giá trị đặc biệt cao
trên 1.5, ReLoRA thể hiện một phân phối khối lượng cao hơn giữa 0.1 và 1.0, gợi nhớ đến
huấn luyện hạng đầy đủ.

Ngoài ra, chúng tôi tính toán số lượng giá trị kỳ dị nhỏ hơn 0.1 cho LoRA, ReLoRA, và
huấn luyện hạng đầy đủ. Kết quả của chúng tôi (Hình 4) cho thấy rằng ReLoRA có số lượng giá trị kỳ dị gần bằng không ít hơn nhiều so với LoRA, gần với huấn luyện hạng đầy đủ hơn. Quan sát này nhấn mạnh
tầm quan trọng của các cập nhật hạng cao và chứng minh rằng ReLoRA thực sự hoàn thành một cập nhật hạng cao
bằng cách thực hiện nhiều cập nhật hạng thấp. Chúng tôi cũng thực hiện phân tích thành phần ReLoRA (Bảng 6)
và thảo luận về nó trong Phần 6.

4.1 Mở rộng lên 1.3B
Lần chạy tốt nhất của chúng tôi ở kích thước mô hình này bắt đầu sau một khởi động ấm 10K bước ( 33% tổng số bước cập nhật).
Chúng tôi huấn luyện ReLoRA với hạng r= 128, tốc độ học 5e-4, khởi động lr 100 bước, và khởi động ấm khởi động lại 50 bước. Kết quả được trình bày trong Hình 5 và Bảng 4. ReLoRA rõ ràng vượt trội hơn LoRA
trong suốt quá trình huấn luyện với khoảng cách giữa các phương pháp tăng từ 0.56 tại 15K bước lên 0.96
tại 30K bước. Ở cuối quá trình huấn luyện, ReLoRA có thể đạt perplexity 17.24, chỉ cao hơn 0.44 so với huấn luyện hạng đầy đủ. Bạn có thể tìm thấy các khuyến nghị bổ sung về lựa chọn siêu tham số ReLoRA trong Phụ lục A.

Thay đổi hạng ReLoRA Trong thí nghiệm này, chúng tôi muốn đánh giá liệu r= 128 vẫn áp dụng được
cho mô hình có kích thước này (kích thước ẩn 2048) hay cần được tăng lên. Để làm điều đó, chúng tôi sử dụng một
checkpoint sớm cho khởi động ấm (5K trong 30K bước). Điều này có lợi cho việc so sánh, vì
tại thời điểm này mất mát thay đổi nhanh chóng khiến cho bất kỳ sự khác biệt nào trong động lực học huấn luyện trở nên rõ ràng hơn.
Chúng tôi huấn luyện các mô hình này thêm 10K lần lặp. Bất ngờ, chúng tôi thấy rất ít sự khác biệt
giữa hạng 128 (ppl. 19.16) và 512 (ppl. 19.00).

--- TRANG 7 ---
0 5000 10000 15000 20000 250002.83.03.23.43.6Mất mát1B
1B ReLoRA
(250M có thể huấn luyện)
1B LoRA
(250M có thể huấn luyện)
250M
0 5000 10000 15000 20000 25000
Bước02501300Tham số có thể huấn luyệnHình 5: Mất mát huấn luyện ở quy mô 1.3B và các baseline liên quan. ReLoRA vượt trội hơn LoRA
trong suốt quá trình huấn luyện và khoảng cách giữa các phương pháp tăng theo thời gian.

1.3B @15K bước 1.3B @20K bước 1.3B @30K bước
Huấn luyện đầy đủ 17.67 (250M) 17.00 (250M) 16.83 (250M)
Kiểm soát 22.67 (250M) 22.00 (250M) 21.73 (250M)
LoRA + Khởi động ấm 18.50 (250M) 18.38 (250M) 18.23 (250M)
ReLoRA 17.94 (250M) 17.64 (250M) 17.27 (250M)
Token huấn luyện (tỷ) 11.8 15.7 23.1

Bảng 4: Kết quả ở quy mô 1.3B. Số lượng tham số có thể huấn luyện cho mỗi mô hình trong (ngoặc đơn).

250M 1.3B
(@15k bước) (@25k bước)
ReLoRA 27.66 17.36
ReLoRA trực tuyến 29.31 17.80

Bảng 5: ReLoRA trực tuyến.Kết quả tiêu cực: ReLoRA trực tuyến Trực quan,
các lần đặt lại ReLoRA thường xuyên hơn có thể dẫn đến
hiệu suất tốt hơn, vì về nguyên tắc, chúng có thể
học một cập nhật hạng cao hơn. Thông thường, đối với mỗi
lần đặt lại ReLoRA, chúng tôi cũng sẽ thực hiện một
đặt lại bộ tối ưu hóa và khởi động lại bộ lập lịch tốc độ học (Phần 1). Tuy nhiên, trong các thí nghiệm của chúng tôi, chúng tôi quan sát thấy rằng tỷ lệ đặt lại ReLoRA rất cao dẫn đến hiệu suất tệ hơn.

ReLoRA trực tuyến giải quyết vấn đề này một cách khá tinh tế – nó hợp nhất các tham số LoRA rất thường xuyên
(ví dụ, mỗi 100 lần lặp) trong khi giữ tỷ lệ đặt lại bộ tối ưu hóa ở 2-5K lần lặp. Bất ngờ,
chúng tôi thấy rằng nó hoạt động tệ hơn ReLoRA thông thường ở cả quy mô 250M và 1.3B (Bảng 5).

Tăng tốc huấn luyện ReLoRA Huấn luyện ReLoRA mất 440 giờ A100, tiết kiệm 56 giờ A100
so với huấn luyện hạng đầy đủ. Một phần của việc tăng tốc là do khả năng sử dụng kích thước microbatch gấp đôi. Khi huấn luyện với cùng kích thước microbatch, ReLoRA cải thiện tiêu thụ RAM
từ 27.8Gb xuống 22.3Gb, tiết kiệm 5.5Gb RAM GPU. Nhìn chung, trong thiết lập 8xA100,
kết hợp thời gian khởi động ấm và huấn luyện ReLoRA, 1.3B-ReLoRA mất 86 giờ (thời gian thực) để
huấn luyện so với 93.5 giờ để huấn luyện mô hình 1.3 hạng đầy đủ trên cùng lượng dữ liệu. Điều này mang lại
cải thiện tốc độ tương đối 9%.

Chúng tôi cũng quan sát thấy rằng việc tăng tốc ReLoRA phụ thuộc đáng kể vào phần cứng (Bảng 7). Trong các thí nghiệm sớm của chúng tôi trên 2xRTX3090, chúng tôi ước tính việc tăng tốc 42%. Trong một thiết lập thực tế hơn, nhưng vẫn
tương đối ngân sách của 6xA6000 Ada, chúng tôi ước tính 152 giờ thời gian huấn luyện thực cho
mô hình 1B hạng đầy đủ và 119 giờ cho mô hình ReLoRA với 33% khởi động ấm. Điều này tiết kiệm 33 giờ
mang lại tăng tốc tương đối 21%. Chúng tôi quy sự khác biệt cho tốc độ bộ nhớ GPU. ReLoRA
có thể sử dụng hiệu quả hơn bộ nhớ băng thông thấp vì nó có ít tham số có thể huấn luyện hơn.

--- TRANG 8 ---
Khởi động lại Đặt lại bộ tối ưu hóa Lịch trình có răng cưa Khởi động ấm Perplexity ( ↓)
× × × × 34.17
✓ × × × 34.25
✓ ✓ × × (phân kỳ)
✓ × ✓ × 34.29
✓ ✓ ✓ × 29.77
× × × ✓ 25.46
✓ ✓ ✓ ✓ 25.04
Huấn luyện thông thường 23.65

Bảng 6: Nghiên cứu phân tích của ReLoRA (các mô hình 130M). Khởi động lại và khởi động ấm là cần thiết cho hiệu suất tốt. Khởi động lại và đặt lại bộ tối ưu hóa không có lịch trình có răng cưa gây ra mô hình phân kỳ.

8xA100 6xA6000 (Ada) 2x3090
Thông lượng hạng đầy đủ 137 ex/giây 84 ex/giây 8.8 ex/giây
Thông lượng ReLoRA 157 ex/giây 124 ex/giây 17.8 ex/giây
Tăng tốc ngay lập tức 15% 48% 102%
Thông lượng ReLoRA được điều chỉnh khởi động ấm 149 ex/giây 111 ex/giây 14.8 ex/giây
Tăng tốc tổng thể 9% 32% 51%

Bảng 7: Các chỉ số hiệu suất trong các cấu hình phần cứng khác nhau. Điều chỉnh khởi động ấm giả định
33% huấn luyện hạng đầy đủ trước khi chuyển sang ReLoRA.

4.2 Nghiên cứu phân tích
Chúng tôi tiến hành các nghiên cứu phân tích về tất cả bốn thành phần quan trọng của ReLoRA: khởi động lại, lịch trình có răng cưa,
đặt lại bộ tối ưu hóa, và khởi động ấm, sử dụng mô hình kích thước 130M. Kết quả được trình bày trong
Bảng 6. Trong phần này, chúng tôi sẽ tập trung vào và phân tích một số kết hợp của các thành phần này.

LoRA ReLoRA, không có các thành phần được đề cập ở trên, về cơ bản tương đương với việc huấn luyện
một mạng hạng thấp được tham số hóa bởi LoRA. Cách tiếp cận này mang lại perplexity cực kỳ cao,
cho thấy rằng một phân tách ma trận đơn giản có động lực học huấn luyện khác biệt đáng kể so với
huấn luyện hạng đầy đủ.

Thêm khởi động lại và đặt lại bộ tối ưu hóa ReLoRA, không có lịch trình có răng cưa và đặt lại bộ tối ưu hóa,
hoạt động tương tự như LoRA vì các trạng thái bộ tối ưu hóa cũ buộc các tham số được khởi tạo mới
vào cùng một không gian con như các trọng số trước đó, hạn chế khả năng của mô hình. Tuy nhiên, việc thực hiện một
đặt lại bộ tối ưu hóa ngây thơ với ReLoRA gây ra mô hình phân kỳ. Một lịch trình có răng cưa giúp ổn định
huấn luyện và có tác động tích cực đến hỗn hợp. Trong các thí nghiệm ban đầu của chúng tôi, chúng tôi cũng quan sát thấy rằng một
kết hợp đặt lại bộ tối ưu hóa một phần và bộ lập lịch có răng cưa cho phép khởi động nhanh hơn, thấp đến
50 bước, thay vì hàng trăm bước cần thiết khi bộ tối ưu hóa được khởi tạo từ đầu.

Khởi động ấm Khởi động ấm cho thấy cải thiện đáng kể nhất, giảm perplexity gần 10 điểm. Để điều tra liệu việc huấn luyện sau khởi động ấm có đóng góp vào mất mát hay không, chúng tôi đo
perplexity của mạng đã được khởi động ấm, bằng 27.03. Nó vượt trội hơn tất cả các phương pháp hạng thấp
ngoại trừ công thức ReLoRA cuối cùng của chúng tôi nhưng vẫn thể hiện sự khác biệt đáng kể so với mạng cuối cùng. Điều này chứng minh tầm quan trọng của việc huấn luyện sớm, tương tự như khái niệm giả thuyết lottery ticket với việc tua lại [Frankle et al., 2019]. Trong các thí nghiệm của chúng tôi, trừ khi được chỉ định khác,
chúng tôi thực hiện khởi động ấm trong khoảng 1/4 tổng số cập nhật huấn luyện.

5 Công trình liên quan
Mở rộng so với Hiệu quả Mối quan hệ giữa quá tham số hóa và khả năng huấn luyện và tổng quát hóa mạng neural đã được nghiên cứu rộng rãi [Zhang et al., 2017, Belkin et al., 2018,

--- TRANG 9 ---
Frankle và Carbin, 2019, Nakkiran et al., 2019, Singh et al., 2021], nhưng nó vẫn là một bí ẩn [Zhang
et al., 2021].

Hơn nữa, các luật mở rộng [Kaplan et al., 2020, Ghorbani et al., 2021, Hoffmann et al., 2022] chứng minh
một sự phụ thuộc luật lũy thừa đơn giản và mạnh mẽ giữa kích thước mạng và hiệu suất của nó trên nhiều
phương thức khác nhau. Phát hiện này không chỉ hỗ trợ việc quá tham số hóa mà còn khuyến khích việc huấn luyện
các mạng neural cực kỳ tốn tài nguyên [Brown et al., 2020, Chowdhery et al., 2022,
Fedus et al., 2022]. Tuy nhiên, Giả thuyết Lottery Ticket [Frankle et al., 2019] gợi ý rằng
việc quá tham số hóa có thể, về nguyên tắc, được tối thiểu hóa.

Tinh chỉnh tiết kiệm tham số Aghajanyan et al. [2021] phát hiện rằng việc tiền huấn luyện giảm
lượng thay đổi cần thiết cho mạng để học một nhiệm vụ mới thông qua tinh chỉnh. Tức là, các mạng lớn hơn hoặc các mạng được tiền huấn luyện trên nhiều dữ liệu hơn đòi hỏi các sửa đổi nhỏ hơn về mặt hạng của
phạm vi để học một nhiệm vụ mới. Điều này giải thích thành công của các phương pháp tinh chỉnh tiết kiệm tham số
[Lialin et al., 2023] và cũng đã thúc đẩy việc phát triển các phương pháp tinh chỉnh hạng thấp như
LoRA [Hu et al., 2022] và Compacter [mahabadi et al., 2021].

Huấn luyện mạng neural hạng thấp Việc huấn luyện các biểu diễn hạng thấp đã được khám phá trong bối cảnh nén CNN, điều chuẩn, và huấn luyện hiệu quả [Idelbayev và Carreira-Perpinan,
2020, Jaderberg et al., 2014, Sui et al., 2023, Schotthöfer et al., 2022, Lin et al., 2020, Yuan et al.,
2021, Zhao et al., 2023]. Tuy nhiên, hầu hết các phương pháp này hoặc đặc biệt cho CNN, không mở rộng tốt, hoặc chưa được đánh giá trên các transformer lớn [Vaswani et al., 2017] với hàng trăm triệu tham số, có thể hưởng lợi rất nhiều từ việc huấn luyện hiệu quả. Trong khi các transformer đã được chứng minh có chiều trong hạng thấp và các biểu diễn [Aghajanyan et al., 2021,
Wang et al., 2020], nghiên cứu của Bhojanapalli et al. [2020] chứng minh rằng hạng thấp của các phép chiếu key và query trong multi-head attention gây cản trở hiệu suất của transformer. Các thí nghiệm của chúng tôi (Phần 6) cũng chứng minh rằng các transformer hạng thấp hoạt động tệ hơn đáng kể
so với baseline hạng đầy đủ và ReLoRA.

6 Kết luận
Trong bài báo này, chúng tôi chứng minh rằng các phương pháp tinh chỉnh tiết kiệm tham số có thể được điều chỉnh cho việc tiền
huấn luyện các mô hình ngôn ngữ lớn. Đầu tiên, chúng tôi xem xét các hạn chế của cách tiếp cận phân tách ma trận hạng thấp
(LoRA) và quan sát thấy rằng nó gặp khó khăn trong việc huấn luyện hiệu quả các mô hình transformer hiệu suất cao. Để giải quyết vấn đề này, chúng tôi đề xuất ReLoRA, tận dụng tính chất hạng của tổng để
huấn luyện một mạng hạng cao thông qua nhiều cập nhật hạng thấp. Tương tự như giả thuyết lottery ticket
với việc tua lại, ReLoRA sử dụng một khởi động ấm huấn luyện hạng đầy đủ trước khi chuyển sang ReLoRA.
Trong quá trình huấn luyện, ReLoRA định kỳ hợp nhất các tham số của nó vào các tham số chính của mạng,
thực hiện đặt lại bộ tối ưu hóa và khởi động lại tốc độ học.

Chúng tôi chứng minh rằng ReLoRA liên tục vượt trội hơn LoRA để huấn luyện các mô hình transformer lớn.
Thí nghiệm lớn nhất của chúng tôi chứng minh giảm 9% thời gian thực trong thiết lập 8xA100 và cải thiện tốc độ lớn hơn nhiều (20−40%) trên phần cứng rẻ hơn. Hơn nữa, kết quả của chúng tôi cho thấy hiệu suất tương tự
với huấn luyện thông thường làm cho ReLoRA trở thành một ứng cử viên hứa hẹn để cải thiện hiệu quả của việc huấn luyện mô hình lớn. Các nghiên cứu tiếp theo của chúng tôi sẽ tập trung vào cải thiện hiệu suất ReLoRA, hiệu quả, áp dụng nó cho
các mô hình lớn hơn và áp dụng nó cho việc tiếp tục tiền huấn luyện các mô hình ngôn ngữ lớn hiện có.

Lời cảm ơn và Tiết lộ Nguồn tài trợ
Bài báo này đã là một hành trình và chúng tôi chân thành biết ơn tất cả những ai đã hỗ trợ chúng tôi. Chúng tôi muốn
bày tỏ lòng biết ơn đến Stability.ai, Eleuther.ai, và Chương trình Google Cloud for Research
vì đã cung cấp tài nguyên tính toán cần thiết cho nghiên cứu này.

Eric Lehman và Artem Krivosheev, cảm ơn vì đã hỗ trợ dự án này từ ban đầu.
Cảm ơn đặc biệt đến Jason Phang, Hailey Schoelkopf, Enrico Shippole, và Stella Biderman vì
lời khuyên kỹ thuật và hỗ trợ với tài nguyên tính toán. Các thí nghiệm của chúng tôi ở quy mô tỷ tham số
sẽ không thể thực hiện được nếu không có sự hỗ trợ của các bạn.

Công trình này được tài trợ một phần bởi giải thưởng nghiên cứu Amazon Alexa AI cho Anna Rumshisky.

--- TRANG 10 ---
Tài liệu tham khảo
A. Aghajanyan, S. Gupta, và L. Zettlemoyer. Chiều nội tại giải thích hiệu quả của việc tinh chỉnh mô hình ngôn ngữ. Trong Kỷ yếu Hội nghị thường niên lần thứ 59 của Hiệp hội Ngôn ngữ học Tính toán
và Hội nghị Quốc tế lần thứ 11 về Xử lý Ngôn ngữ Tự nhiên Kết hợp (Tập 1: Bài báo dài), trang
7319–7328, Trực tuyến, Tháng 8 2021. Hiệp hội Ngôn ngữ học Tính toán. doi: 10.18653/v1/2021.acl-long.
568. URL https://aclanthology.org/2021.acl-long.568.

Z. Allen-Zhu, Y. Li, và Z. Song. Một lý thuyết hội tụ cho học sâu thông qua quá tham số hóa. Trong
K. Chaudhuri và R. Salakhutdinov, biên tập viên, Kỷ yếu Hội nghị Quốc tế lần thứ 36 về Học máy, tập 97 của Kỷ yếu Nghiên cứu Học máy, trang 242–252. PMLR, 09–15 Tháng 6 2019.
URL https://proceedings.mlr.press/v97/allen-zhu19a.html.

S. Arora, N. Cohen, W. Hu, và Y. Luo. Điều chuẩn ẩn trong phân tách ma trận sâu, 2019.

M. Belkin, D. J. Hsu, S. Ma, và S. Mandal. Hòa giải thực hành học máy hiện đại và sự đánh đổi
bias–variance cổ điển. Kỷ yếu Viện Hàn lâm Khoa học Quốc gia, 116:15849 – 15854, 2018.

S. Bhojanapalli, C. Yun, A. S. Rawat, S. Reddi, và S. Kumar. Điểm nghẽn hạng thấp trong các mô hình multi-head attention. Trong Hội nghị Quốc tế về Học máy, trang 864–873. PMLR, 2020.

S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. B. Van Den Driessche, J.-B. Lespiau,
B. Damoc, A. Clark, D. De Las Casas, A. Guy, J. Menick, R. Ring, T. Hennigan, S. Huang, L. Maggiore,
C. Jones, A. Cassirer, A. Brock, M. Paganini, G. Irving, O. Vinyals, S. Osindero, K. Simonyan, J. Rae, E. Elsen,
và L. Sifre. Cải thiện mô hình ngôn ngữ bằng cách truy xuất từ hàng nghìn tỷ token. Trong K. Chaudhuri, S. Jegelka,
L. Song, C. Szepesvari, G. Niu, và S. Sabato, biên tập viên, Kỷ yếu Hội nghị Quốc tế lần thứ 39 về
Học máy, tập 162 của Kỷ yếu Nghiên cứu Học máy, trang 2206–2240. PMLR,
17–23 Tháng 7 2022. URL https://proceedings.mlr.press/v162/borgeaud22a.html.

T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry,
A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. Ziegler, J. Wu,
C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish,
A. Radford, I. Sutskever, và D. Amodei. Mô hình ngôn ngữ là những người học few-shot. Trong H. Larochelle,
M. Ranzato, R. Hadsell, M. F. Balcan, và H. Lin, biên tập viên, Tiến bộ trong Hệ thống Xử lý Thông tin Neural, tập 33, trang 1877–1901. Curran Associates, Inc., 2020. URL https://proceedings.
neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.

A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton,
S. Gehrmann, P. Schuh, K. Shi, S. Tsvyashchenko, J. Maynez, A. Rao, P. Barnes, Y. Tay, N. M. Shazeer,
V. Prabhakaran, E. Reif, N. Du, B. C. Hutchinson, R. Pope, J. Bradbury, J. Austin, M. Isard, G. Gur-Ari,
P. Yin, T. Duke, A. Levskaya, S. Ghemawat, S. Dev, H. Michalewski, X. García, V. Misra, K. Robinson,
L. Fedus, D. Zhou, D. Ippolito, D. Luan, H. Lim, B. Zoph, A. Spiridonov, R. Sepassi, D. Dohan, S. Agrawal,
M. Omernick, A. M. Dai, T. S. Pillai, M. Pellat, A. Lewkowycz, E. Moreira, R. Child, O. Polozov, K. Lee,
Z. Zhou, X. Wang, B. Saeta, M. Díaz, O. Firat, M. Catasta, J. Wei, K. S. Meier-Hellstern, D. Eck, J. Dean,
S. Petrov, và N. Fiedel. Palm: Mở rộng mô hình ngôn ngữ với pathways. ArXiv, abs/2204.02311, 2022.

T. Dao, D. Y. Fu, S. Ermon, A. Rudra, và C. Re. Flashattention: Attention chính xác nhanh và tiết kiệm bộ nhớ với
nhận thức IO. Trong A. H. Oh, A. Agarwal, D. Belgrave, và K. Cho, biên tập viên, Tiến bộ trong Hệ thống Xử lý Thông tin Neural, 2022. URL https://openreview.net/forum?id=H4DqfPSibmx.

T. Dettmers, M. Lewis, Y. Belkada, và L. Zettlemoyer. GPT3.int8(): Nhân ma trận 8-bit cho transformer
ở quy mô. Trong A. H. Oh, A. Agarwal, D. Belgrave, và K. Cho, biên tập viên, Tiến bộ trong Hệ thống Xử lý Thông tin Neural, 2022. URL https://openreview.net/forum?id=dXiGWqBoxaD.

T. Dettmers, A. Pagnoni, A. Holtzman, và L. Zettlemoyer. Qlora: Tinh chỉnh hiệu quả của các llm lượng tử hóa. ArXiv,
abs/2305.14314, 2023. URL https://api.semanticscholar.org/CorpusID:258841328.

A. Edalati, M. S. Tahaei, I. Kobyzev, V. Nia, J. J. Clark, và M. Rezagholizadeh. Krona: Điều chỉnh hiệu quả tham số
với adapter kronecker. ArXiv, abs/2212.10650, 2022. URL https://api.semanticscholar.org/
CorpusID:254926823.

W. Fedus, B. Zoph, và N. Shazeer. Switch transformers: Mở rộng đến các mô hình nghìn tỷ tham số với
sự thưa thớt đơn giản và hiệu quả. J. Mach. Learn. Res., 23(1), tháng 1 2022. ISSN 1532-4435.

J. Frankle và M. Carbin. Giả thuyết vé số: Tìm các mạng neural thưa thớt, có thể huấn luyện. Trong
Hội nghị Quốc tế về Biểu diễn Học, 2019. URL https://openreview.net/forum?
id=rJl-b3RcF7.

--- TRANG 11 ---
J. Frankle, G. Karolina Dziugaite, D. M. Roy, và M. Carbin. Ổn định giả thuyết vé số. arXiv
e-prints, trang arXiv–1903, 2019.

B. Ghorbani, O. Firat, M. Freitag, A. Bapna, M. Krikun, X. García, C. Chelba, và C. Cherry. Luật mở rộng cho
dịch máy neural. ArXiv, abs/2109.07740, 2021.

K. He, X. Zhang, S. Ren, và J. Sun. Đào sâu vào rectifier: Vượt qua hiệu suất cấp độ con người trên
phân loại imagenet. CoRR, abs/1502.01852, 2015. URL http://arxiv.org/abs/1502.01852.

K. He, X. Zhang, S. Ren, và J. Sun. Học residual sâu cho nhận dạng hình ảnh. Hội nghị IEEE 2016 về
Thị giác Máy tính và Nhận dạng Mẫu (CVPR), trang 770–778, 2016.

J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. de las Casas, L. A. Hendricks,
J. Welbl, A. Clark, T. Hennigan, E. Noland, K. Millican, G. van den Driessche, B. Damoc, A. Guy, S. Osindero,
K. Simonyan, E. Elsen, O. Vinyals, J. W. Rae, và L. Sifre. Một phân tích thực nghiệm về huấn luyện mô hình ngôn ngữ lớn
tối ưu tính toán. Trong A. H. Oh, A. Agarwal, D. Belgrave, và K. Cho, biên tập viên, Tiến bộ trong Hệ thống Xử lý Thông tin Neural, 2022. URL https://openreview.net/forum?id=iBBcRUlOAPR.

E. J. Hu, yelong shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, và W. Chen. LoRA: Thích ứng hạng thấp
của các mô hình ngôn ngữ lớn. Trong Hội nghị Quốc tế về Biểu diễn Học, 2022. URL
https://openreview.net/forum?id=nZeVKeeFYf9.

Y. Idelbayev và M. A. Carreira-Perpinan. Nén hạng thấp của mạng neural: Học hạng của mỗi lớp.
Trong Hội nghị IEEE/CVF 2020 về Thị giác Máy tính và Nhận dạng Mẫu (CVPR), trang 8046–8056,
2020. doi: 10.1109/CVPR42600.2020.00807.

A. Jacot, F. Gabriel, và C. Hongler. Neural tangent kernel: Hội tụ và tổng quát hóa trong mạng neural.
Trong Kỷ yếu Hội nghị Quốc tế lần thứ 32 về Hệ thống Xử lý Thông tin Neural, NIPS'18,
trang 8580–8589, Red Hook, NY, USA, 2018. Curran Associates Inc.

M. Jaderberg, A. Vedaldi, và A. Zisserman. Tăng tốc mạng neural tích chập với mở rộng hạng thấp.
Trong Kỷ yếu Hội nghị Thị giác Máy tính Anh. BMV A Press, 2014. doi: http:
//dx.doi.org/10.5244/C.28.88.

S. R. Kamalakara, A. F. Locatelli, B. Venkitesh, J. Ba, Y. Gal, và A. N. Gomez. Khám phá huấn luyện hạng thấp
của mạng neural sâu. ArXiv, abs/2209.13569, 2022. URL https://api.semanticscholar.org/
CorpusID:252545358.

J. Kaplan, S. McCandlish, T. J. Henighan, T. B. Brown, B. Chess, R. Child, S. Gray, A. Radford, J. Wu, và
D. Amodei. Luật mở rộng cho mô hình ngôn ngữ neural. ArXiv, abs/2001.08361, 2020.

U. Khandelwal, O. Levy, D. Jurafsky, L. Zettlemoyer, và M. Lewis. Tổng quát hóa thông qua ghi nhớ:
Mô hình ngôn ngữ láng giềng gần nhất. Trong Hội nghị Quốc tế về Biểu diễn Học, 2020. URL
https://openreview.net/forum?id=HklBjCEKvH.

D. P. Kingma và J. Ba. Adam: Một phương pháp cho tối ưu hóa ngẫu nhiên. CoRR, abs/1412.6980, 2015.

A. Krizhevsky, I. Sutskever, và G. E. Hinton. Phân loại imagenet với mạng neural tích chập sâu.
Trong F. Pereira, C. Burges, L. Bottou, và K. Weinberger, biên tập viên, Tiến bộ trong Hệ thống Xử lý Thông tin Neural, tập 25. Curran Associates, Inc., 2012. URL https://proceedings.neurips.cc/paper_
files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf.

V. Lialin, V. Deshpande, và A. Rumshisky. Mở rộng xuống để mở rộng lên: Hướng dẫn về tinh chỉnh hiệu quả tham số,
2023.

R. Lin, C.-Y. Ko, Z. He, C. Chen, Y. Cheng, H. Yu, G. Chesi, và N. Wong. Hotcake: Kernel articulated tucker
bậc cao hơn để nén cnn sâu hơn. Trong Hội nghị Quốc tế IEEE lần thứ 15 năm 2020 về Công nghệ Mạch tích hợp & Trạng thái rắn (ICSICT), trang 1–4, 2020. doi: 10.1109/ICSICT49897.2020.9278257.

R. K. mahabadi, J. Henderson, và S. Ruder. Compacter: Các lớp adapter hypercomplex hạng thấp hiệu quả. Trong
A. Beygelzimer, Y. Dauphin, P. Liang, và J. W. Vaughan, biên tập viên, Tiến bộ trong Hệ thống Xử lý Thông tin Neural, 2021. URL https://openreview.net/forum?id=bqGK5PyI6-N.

P. Micikevicius, S. Narang, J. Alben, G. Diamos, E. Elsen, D. Garcia, B. Ginsburg, M. Houston, O. Kuchaiev,
G. Venkatesh, và H. Wu. Huấn luyện độ chính xác hỗn hợp. Trong Hội nghị Quốc tế về Biểu diễn Học,
2018. URL https://openreview.net/forum?id=r1gs9JgRZ.

P. Nakkiran, G. Kaplun, Y. Bansal, T. Yang, B. Barak, và I. Sutskever. Deep double descent: nơi các mô hình lớn hơn
và nhiều dữ liệu hơn gây tổn hại. Tạp chí Cơ học Thống kê: Lý thuyết và Thí nghiệm, 2021, 2019.

--- TRANG 12 ---
A. Radford, K. Narasimhan, T. Salimans, I. Sutskever, et al. Cải thiện hiểu biết ngôn ngữ bằng tiền huấn luyện sinh.
2018.

C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, và P. J. Liu. Khám phá
giới hạn của học chuyển giao với một transformer văn bản thành văn bản thống nhất. Tạp chí Nghiên cứu Học máy, 21
(140):1–67, 2020. URL http://jmlr.org/papers/v21/20-074.html.

S. Rajbhandari, J. Rasley, O. Ruwase, và Y. He. Zero: Tối ưu hóa bộ nhớ hướng tới huấn luyện các mô hình
nghìn tỷ tham số. Trong SC20: Hội nghị Quốc tế về Tính toán Hiệu suất Cao, Mạng, Lưu trữ và
Phân tích, trang 1–16, 2020. doi: 10.1109/SC41405.2020.00024.

S. Schotthöfer, E. Zangrando, J. Kusch, G. Ceruti, và F. Tudisco. Vé số hạng thấp: tìm mạng neural
hạng thấp hiệu quả thông qua phương trình vi phân ma trận. Trong S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave,
K. Cho, và A. Oh, biên tập viên, Tiến bộ trong Hệ thống Xử lý Thông tin Neural, tập 35, trang 20051–
20063. Curran Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper_files/paper/
2022/file/7e98b00eeafcdaeb0c5661fb9355be3a-Paper-Conference.pdf.

N. Shazeer. Các biến thể glu cải thiện transformer, 2020.

K. Simonyan và A. Zisserman. Mạng neural tích chập rất sâu cho nhận dạng hình ảnh quy mô lớn. Trong Y. Bengio
và Y. LeCun, biên tập viên, Hội nghị Quốc tế lần thứ 3 về Biểu diễn Học, ICLR 2015, San Diego, CA,
USA, 7-9 Tháng 5, 2015, Kỷ yếu Track Hội nghị, 2015. URL http://arxiv.org/abs/1409.1556.

S. P. Singh, G. Bachmann, và T. Hofmann. Hiểu biết phân tích về cấu trúc và hạng của bản đồ hessian mạng neural.
Trong A. Beygelzimer, Y. Dauphin, P. Liang, và J. W. Vaughan, biên tập viên, Tiến bộ trong Hệ thống Xử lý Thông tin Neural, 2021. URL https://openreview.net/forum?id=otDgw7LM7Nn.

J. Su, Y. Lu, S. Pan, B. Wen, và Y. Liu. Roformer: Transformer nâng cao với nhúng vị trí quay.
ArXiv, abs/2104.09864, 2021.

Y. Sui, M. Yin, W. Yang, Y. Gong, J. Xiao, H. Phan, D. Ding, X. Xu, S. Liu, Z. Chen, và B. Yuan. ELRT:
Hướng tới huấn luyện hạng thấp hiệu quả cho mạng neural nhỏ gọn, 2023. URL https://openreview.net/
forum?id=TC39w69m8bB.

Y.-L. Sung, J. Cho, và M. Bansal. lst: Điều chỉnh side ladder cho học chuyển giao hiệu quả tham số và bộ nhớ.
ArXiv, abs/2206.06522, 2022. URL https://api.semanticscholar.org/CorpusID:249642544.

H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro,
F. Azhar, A. Rodriguez, A. Joulin, E. Grave, và G. Lample. Llama: Mô hình ngôn ngữ nền tảng mở và hiệu quả.
arXiv preprint arXiv:2302.13971, 2023.

A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, và I. Polosukhin. Attention
là tất cả những gì bạn cần. Tiến bộ trong hệ thống xử lý thông tin neural, 30, 2017.

S. Wang, B. Z. Li, M. Khabsa, H. Fang, và H. Ma. Linformer: Self-attention với độ phức tạp tuyến tính. arXiv
preprint arXiv:2006.04768, 2020.

X. Yuan, P. H. P. Savarese, và M. Maire. Phát triển mạng sâu hiệu quả bằng cách thưa thớt liên tục có cấu trúc.
Trong Hội nghị Quốc tế về Biểu diễn Học, 2021. URL https://openreview.net/forum?
id=wb3wxCObbRT.

B. Zhang và R. Sennrich. Chuẩn hóa lớp mean square gốc. Trong H. Wallach, H. Larochelle, A. Beygelzimer,
F. d'Alché-Buc, E. Fox, và R. Garnett, biên tập viên, Tiến bộ trong Hệ thống Xử lý Thông tin Neural,
tập 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper_files/
paper/2019/file/1e8a19426224ca89e83cef47f1e7f53b-Paper.pdf.

C. Zhang, S. Bengio, M. Hardt, B. Recht, và O. Vinyals. Hiểu học sâu đòi hỏi suy nghĩ lại tổng quát hóa.
Trong Hội nghị Quốc tế về Biểu diễn Học, 2017. URL https://openreview.
net/forum?id=Sy8gdB9xx.

C. Zhang, S. Bengio, M. Hardt, B. Recht, và O. Vinyals. Hiểu học sâu (vẫn) đòi hỏi suy nghĩ lại tổng quát hóa.
Communications of the ACM, 64:107 – 115, 2021.

J. Zhao, Y. Zhang, B. Chen, F. Schäfer, và A. Anandkumar. Inrank: Học hạng thấp tăng dần. arXiv
preprint arXiv:2306.11250, 2023.

--- TRANG 13 ---
A Hướng dẫn thực tế cho ReLoRA
Trong phần này, chúng tôi muốn trả lời các câu hỏi phổ biến nhất về lựa chọn siêu tham số. Đặc biệt
cách chọn các siêu tham số đặc thù ReLoRA để có được hiệu suất tốt hơn LoRA một cách đáng tin cậy. Trong tất cả
các thí nghiệm của chúng tôi, chúng tôi đã áp dụng LoRA/ReLoRA cho tất cả các lớp tuyến tính trong mô hình: các lớp chiếu kqv, các lớp FFN và các phép chiếu khác, ngoại trừ logits và embeddings.

Chúng tôi quan sát thấy rằng r∈ {64,128} hoạt động tốt cho tất cả các mạng, lên tới 1B. Một thay đổi siêu tham số nhỏ nhưng quan trọng từ huấn luyện hạng đầy đủ sang huấn luyện ReLoRA mà quan trọng cho
hiệu suất là tăng tốc độ học. ReLoRA (và LoRA) đòi hỏi tốc độ học lớn hơn 1.5−2 lần so với huấn luyện/tinh chỉnh thông thường để đạt được hiệu suất tương tự.

Khi nói về các siêu tham số đặc thù ReLoRA, chúng tôi không quan sát thấy sự phụ thuộc đáng kể vào
tỷ lệ phần trăm cắt tỉa bộ tối ưu hóa miễn là nó lớn hơn 90%. Tỷ lệ cắt tỉa lớn hơn có thể dẫn đến hiệu suất tốt hơn một chút với chi phí của sự không ổn định mất mát có thể xảy ra trong quá trình đặt lại. Chúng tôi đã thử nghiệm một số tỷ lệ đặt lại ReLoRA với các mô hình 350M và 1.3B và thấy rằng tỷ lệ đặt lại 2K lần lặp hoạt động tốt nhất một cách nhất quán trong cả thí nghiệm tiền huấn luyện và tinh chỉnh và luôn dẫn đến hiệu suất tốt hơn so với không đặt lại. Nói chung, chúng tôi quan sát kết quả tốt với tỷ lệ đặt lại 2K-5K.

B ReLoRA cho tinh chỉnh
Chúng tôi áp dụng ReLoRA để tinh chỉnh T5-base (220M tham số) và T5-large (770M tham số) trên
benchmark GLUE. Chúng tôi sử dụng cùng loại bộ lập lịch tốc độ học như trong tiền huấn luyện ReLoRA và
cắt tỉa 90% các trạng thái bộ tối ưu hóa độ lớn thấp trong mỗi lần hợp nhất và khởi tạo lại LoRA (khởi động lại). Kích thước batch bằng 128 ví dụ và tốc độ học được điều chỉnh (từ 1e-4 đến 5e-4) trên mỗi kết hợp mô hình và bộ dữ liệu. Chúng tôi thực hiện các nghiên cứu phân tích ReLoRA bổ sung sử dụng mô hình T5-Large và bộ dữ liệu QNLI. Cụ thể, chúng tôi khám phá các hạng ReLoRA khác nhau, tỷ lệ cắt tỉa trạng thái bộ tối ưu hóa, và tổng số lần đặt lại ReLoRA.

Phương pháp SST-2 MNLI QNLI QQP RTE STS-B MRPC CoLA Trung bình
Adapters†94.2 86.4 93.1 88.9 75.1 91.1 88.9 64.4 85.3
Prompt Tuning†90.3 82.5 92.5 88.5 59.5 90.1 74.6 0.0 72.2
Ladder Side Tuning†94.1 85.6 93.3 88.8 71.9 90.7 90.4 58.1 84.1
Compacter* 93.9 86.1 92.9 90.4 76.3 91.0 91.5 64.4 85.8
KronA* 94.3 86.3 93.2 90.6 77.7 91.3 92.5 63.3 86.1
Tinh chỉnh đầy đủ* 93.6 86.2 92.8 91.7 74.8 90.1 92.7 63.4 85.7
LoRA 93.92 86.12 91.95 90.62 78.34 89.96 90.52 60.04 85.18
ReLoRA 94.15 85.96 91.68 87.2 77.74 89.88 90.03 59.92 84.57
Tinh chỉnh đầy đủ (T5-L) 94.7 89.1 91.6 89.9 78.9 90.6 88.9 57.0 85.0
LoRA (T5-L) 95.59 89.44 93.98 91.44 85.92 90.89 92.90 63.77 87.99
ReLoRA (T5-L) 95.7 89.06 93.68 91.04 84.72 90.53 90.57 61.72 87.47

Bảng 8: ReLoRA cho tinh chỉnh không vượt trội hơn LoRA. Kết quả với†và *là kết quả T5-base
từ Sung et al. [2022] và Edalati et al. [2022] tương ứng.

Phân tích tinh chỉnh ReLoRA Bảng 9 cho thấy kết quả của việc thay đổi các siêu tham số ReLoRA. Một
hạng 64 dường như cung cấp hiệu suất tốt nhất. Kết quả cho thấy rằng hiệu suất của mô hình
vẫn không bị ảnh hưởng lớn ngay cả khi 99% trạng thái bộ tối ưu hóa được đặt lại. Phân tích của chúng tôi về tác động của bộ lập lịch tốc độ học cosine có răng cưa đối với độ chính xác phân loại trong bộ dữ liệu QNLI gợi ý rằng hai lần đặt lại là đủ (tỷ lệ đặt lại 4000).

C Đường cong học của các mô hình được tiền huấn luyện trong nghiên cứu
Trong phần này chúng tôi trình bày các biểu đồ mất mát huấn luyện bổ sung cho tất cả các mô hình từ Bảng 2. 60M:
Hình 6, 130M: Hình 7, 250M: Hình 8, 350M: Hình 9, 1.3B: Hình 10.

--- TRANG 14 ---
Hạng Độ chính xác Cắt tỉa Độ chính xác Tỷ lệ đặt lại #đặt lại Độ chính xác
16 94.05 85% 94.51 6000 1 94.38
32 94.16 92% 94.33 4000 2 94.73
64 94.55 95% 94.31 2000 5 94.34
128 94.44 99% 94.56 1000 11 94.33

Bảng 9: Phân tích tinh chỉnh ReLoRA. Chúng tôi áp dụng ReLoRA để tinh chỉnh T5-large trên bộ dữ liệu QNLI
và thay đổi hạng LoRA (r), tỷ lệ phần trăm cắt tỉa trạng thái bộ tối ưu hóa, và tần suất đặt lại của ReLoRA. Tỷ lệ đặt lại
có nghĩa là số lần lặp giữa các lần đặt lại ReLoRA.

D Hạng của các mô hình 130M
Hình 11 và 12 cho thấy các thuộc tính phổ cho mô hình 130M.

E Thời gian khởi động ấm ngắn hơn
Bảng 2 chứng minh rằng ReLoRA liên tục vượt trội hơn baseline LoRA được khởi động ấm. Để
cung cấp một ví dụ tương phản hơn, chúng tôi đã thực hiện các thí nghiệm tiền huấn luyện bổ sung bắt đầu từ
chỉ mạng được khởi động ấm 2K. Hình 13 cho thấy một cải thiện hiệu suất đáng kể với ReLoRA so với
LoRA bằng 1.4 điểm ppl (ppl 23.64 so với 25.08). Trong khi hiệu suất tuyệt đối của ReLoRA thấp hơn
so với huấn luyện hạng đầy đủ trong bối cảnh này, các thí nghiệm này xác nhận giả thuyết ban đầu của chúng tôi rằng
việc khởi động lại LoRA có tác động tích cực đến hiệu suất.

0 2000 4000 6000 8000 100003.43.63.84.04.24.4Mất mát60M
60M ReLoRA
(40M có thể huấn luyện)
60M LoRA+KhởiĐộngẤm
(40M có thể huấn luyện)
40M
0 2000 4000 6000 8000 10000
Bước04060Tham số có thể huấn luyện

Hình 6: Mất mát huấn luyện thí nghiệm 60M

0 2500 5000 7500 10000 12500 15000 17500 200003.253.503.754.004.254.50Mất mát130M
130M ReLoRA
(72M có thể huấn luyện)
130M LoRA+KhởiĐộngẤm
(72M có thể huấn luyện)
72M
0 2500 5000 7500 10000 12500 15000 17500 20000
Bước04060Tham số có thể huấn luyện

Hình 7: Mất mát huấn luyện thí nghiệm 130M

--- TRANG 15 ---
0 2500 5000 7500 10000 12500 15000 17500 200003.03.54.04.55.0Mất mát250M
250M ReLoRA
(99M có thể huấn luyện)
99M
0 2500 5000 7500 10000 12500 15000 17500 20000
Bước0100250Tham số có thể huấn luyệnHình 8: Mất mát huấn luyện thí nghiệm 250M

0 2500 5000 7500 10000 12500 15000 17500 200003.03.23.43.63.84.0Mất mát350M
350M ReLoRA
(130M có thể huấn luyện)
350M LoRA+KhởiĐộngẤm
(130M có thể huấn luyện)
130M
0 2500 5000 7500 10000 12500 15000 17500 20000
Bước0130350Tham số có thể huấn luyện

Hình 9: Mất mát huấn luyện thí nghiệm 350M

0 5000 10000 15000 20000 250002.83.03.23.43.6Mất mát1B
1B ReLoRA
(250M có thể huấn luyện)
1B LoRA
(250M có thể huấn luyện)
250M
0 5000 10000 15000 20000 25000
Bước02501300Tham số có thể huấn luyện

Hình 10: Mất mát huấn luyện thí nghiệm 1.3B

--- TRANG 16 ---
0.0 0.5 1.0 1.5 2.0
Giá trị Kỳ dị0.00.51.01.52.02.53.0Tần suấtPhép chiếu Q
ReLoRA
LoRA
Huấn luyện
hạng đầy đủ
0.0 0.5 1.0 1.5 2.0
Giá trị Kỳ dị0.00.51.01.52.02.53.0Phép chiếu K
ReLoRA
LoRA
Huấn luyện
hạng đầy đủ
0.0 0.5 1.0 1.5 2.0
Giá trị Kỳ dị0.00.51.01.52.02.53.0Phép chiếu V
ReLoRA
LoRA
Huấn luyện
hạng đầy đủ
0.0 0.5 1.0 1.5 2.0
Giá trị Kỳ dị0.00.51.01.52.02.53.0Phép chiếu Xuống
ReLoRA
LoRA
Huấn luyện
hạng đầy đủHình 11: Phổ giá trị kỳ dị của sự khác biệt trọng số giữa ReLoRA và LoRA tại 5,000
lần lặp (khởi động ấm) và 20,000 lần lặp. ReLoRA thể hiện sự tương đồng gần gũi hơn với huấn luyện hạng đầy đủ
so với LoRA, cho thấy tính hiệu quả của nó trong việc xấp xỉ hành vi hạng đầy đủ. Các mô hình 130M.

WQWKWVW lênW xuống0200400600
Huấn luyện
Hạng đầy đủ
ReLoRA
LoRA

Hình 12: Số lượng giá trị kỳ dị <0.1 trong ma trận attention và FCN của cập nhật đã học.
Các mô hình 130M.

Hình 13: ReLoRA vượt trội đáng kể hơn LoRA khi bắt đầu từ một checkpoint sớm (2K bước).

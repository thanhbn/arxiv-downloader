# 2505.20355.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2505.20355.pdf
# Kích thước tệp: 3776386 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
GraLoRA: Thích Ứng Hạng Thấp Hạt Nhỏ cho
Tinh Chỉnh Hiệu Quả Tham Số
Yeonjoon Jung1,2∗Daehyun Ahn1Hyungjun Kim1Taesu Kim1Eunhyeok Park2†
1SqueezeBits2POSTECH
{yeonjoon.jung, daehyun.ahn, hyungjun.kim, taesu.kim}@squeezebits.com
yeonjoon.jung@postech.ac.kr, eh.park@postech.ac.kr

Tóm tắt
Thích Ứng Hạng Thấp (LoRA) là một phương pháp phổ biến cho tinh chỉnh hiệu quả tham số (PEFT) của các mô hình sinh tạo, được đánh giá cao vì tính đơn giản và hiệu quả. Mặc dù có những cải tiến gần đây, LoRA vẫn gặp phải một hạn chế cơ bản: hiện tượng quá khớp khi nút thắt được mở rộng. Nó hoạt động tốt nhất ở hạng 32-64, nhưng độ chính xác của nó trở nên ì ạch hoặc giảm ở hạng cao hơn, vẫn kém hơn hiệu suất tinh chỉnh đầy đủ (FFT). Chúng tôi xác định nguyên nhân gốc rễ là nút thắt cấu trúc của LoRA, gây ra sự vướng víu gradient đối với các kênh đầu vào không liên quan và làm méo mó việc truyền gradient. Để giải quyết vấn đề này, chúng tôi giới thiệu một cấu trúc mới, Thích Ứng Hạng Thấp Hạt Nhỏ (GraLoRA) phân chia ma trận trọng số thành các khối con, mỗi khối có bộ thích ứng hạng thấp riêng. Với chi phí tính toán hoặc lưu trữ không đáng kể, GraLoRA vượt qua các hạn chế của LoRA, tăng hiệu quả khả năng biểu diễn, và gần như mô phỏng hành vi FFT. Các thử nghiệm trên benchmark tạo mã và suy luận thông thường cho thấy GraLoRA vượt trội so với LoRA và các baseline khác một cách nhất quán, đạt được cải thiện tuyệt đối lên đến +8.5% trong Pass@1 trên HumanEval+. Những cải thiện này giữ vững qua các kích thước mô hình và cài đặt hạng khác nhau, làm cho GraLoRA trở thành một giải pháp có thể mở rộng và mạnh mẽ cho PEFT. Mã, dữ liệu và script có sẵn tại https://github.com/SqueezeBits/GraLoRA.git

1 Giới thiệu
Tinh chỉnh theo nhiệm vụ cụ thể cho phép một loạt ứng dụng rộng rãi và cải thiện đáng kể chất lượng và hiệu quả của các mô hình sinh tạo. Tuy nhiên, quy mô khổng lồ của những mô hình này đặt ra những thách thức đáng kể cho việc triển khai thực tế. Để giải quyết những hạn chế này, các phương pháp Tinh Chỉnh Hiệu Quả Tham Số (PEFT) đã xuất hiện như một giải pháp thay thế hiệu quả về chi phí [10,26]. Trong số đó, Thích Ứng Hạng Thấp (LoRA) [11] đã nhận được sự chú ý đặc biệt vì tính đơn giản và hiệu quả, giới thiệu các ma trận hạng thấp có thể huấn luyện trong khi giữ nguyên trọng số mô hình được huấn luyện trước. Mặc dù nút thắt hạng r áp đặt có thể dẫn đến suy giảm hiệu suất nhẹ so với tinh chỉnh đầy đủ (FFT), hiệu quả của nó đã dẫn đến việc áp dụng rộng rãi trong thực tế.

Để tối đa hóa lợi ích của LoRA, nhiều nghiên cứu khác nhau đã đề xuất các kỹ thuật như cải thiện khởi tạo [5, 18, 20, 23] và tinh chỉnh cấu trúc [9, 13, 14, 15] để nâng cao chất lượng tinh chỉnh. Trong khi những nỗ lực này đã nâng cao hiệu suất, vẫn còn một khoảng cách chất lượng đáng kể so với FFT, chủ yếu do giới hạn trên cố hữu của hạng. Mặc dù việc sử dụng hạng cao hơn, trong giới hạn phần cứng, có vẻ là một giải pháp tự nhiên, thật không may, các triển khai hiện tại của LoRA và các biến thể của nó không hỗ trợ tính linh hoạt như vậy. Việc đơn giản tăng hạng thường dẫn đến độ chính xác giảm trong nhiều tình huống.

Trong bài báo này, chúng tôi trình bày một phân tích lý thuyết xác định nguyên nhân gốc rễ của hạn chế hạng trong LoRA. Phân tích của chúng tôi tiết lộ một vấn đề cơ bản trong cấu trúc của LoRA, sự thống trị kênh trong gradient, nơi một tập con nhỏ các kênh ngoại lai ảnh hưởng không tương xứng đến hướng cập nhật.

Bản thảo. Đang được xem xét.arXiv:2505.20355v1 [cs.LG] 26 Tháng 5 2025

--- TRANG 2 ---
Hình 1: Minh họa kiến trúc LoRA và kiến trúc GraLoRA. GraLoRA bao gồm k²cặp bộ thích ứng nhỏ, trong đó mỗi chiều đầu vào và đầu ra nhỏ hơn k lần so với LoRA gốc.

Sự thống trị này làm giảm đóng góp từ các kênh khác, dẫn đến việc sử dụng dưới mức hạng có sẵn và hiệu suất giảm trong các nhiệm vụ đòi hỏi biểu diễn tinh tế hoặc phân tán.

Để vượt qua những nút thắt biểu đạt này, chúng tôi đề xuất Thích Ứng Hạng Thấp Hạt Nhỏ (GraLoRA), một mở rộng kiến trúc mới của LoRA. Như được hiển thị trong Hình 1, GraLoRA chia ma trận trọng số thành nhiều khối con và áp dụng các mô-đun LoRA độc lập cho mỗi khối, cho phép cập nhật tinh tế. Thiết kế này nâng cao khả năng của mô hình để nắm bắt các mẫu phức tạp, cục bộ hoặc đa diện, hiệu quả giảm thiểu vấn đề thống trị kênh và cải thiện hiệu suất—đặc biệt ở hạng cao hơn.

Các thử nghiệm rộng rãi cho thấy GraLoRA vượt trội so với LoRA vani một cách nhất quán qua một loạt benchmark NLP, đặc biệt trong các tình huống có tính không đồng nhất đầu vào cao hoặc độ phức tạp nhiệm vụ. Những kết quả này định vị GraLoRA như một tiến bộ có nguyên tắc và thực tế trong bối cảnh PEFT.

2 Chi tiết và Hạn chế của LoRA

2.1 Giới thiệu về LoRA
LoRA là một trong những chiến lược được áp dụng rộng rãi nhất cho PEFT. Cho một ma trận trọng số được huấn luyện trước W₀∈R^(M×N), trong đó M và N đại diện cho chiều kênh đầu vào và đầu ra tương ứng, LoRA giữ W₀ đông lạnh và giới thiệu một cập nhật hạng thấp có thể huấn luyện được định nghĩa là:

R=sBA^T, A∈R^(N×r), B∈R^(M×r), s = α/r. (1)

Ở đây, hạng r và α là các siêu tham số do người dùng định nghĩa. Sau đó, cho một đầu vào X∈R^(N×T), đầu ra của lớp được thích ứng LoRA là Y=W₀X+RX∈R^(M×T), trong đó T biểu thị chiều batch hoặc token. Phân tách hạng thấp này cho phép mô hình thích ứng sử dụng ít tham số có thể huấn luyện hơn đáng kể và giảm chi phí bộ nhớ.

Trong khi FFT cập nhật toàn bộ ma trận trọng số, LoRA chỉ cập nhật các ma trận hạng thấp phân tách A và B. Lưu ý rằng chúng tôi giả định s = 1 để đơn giản, gradient của loss đối với R là:

∂L/∂R = ∂L/∂Y X^T ∈ R^(M×N) (2)

Từ đây, các gradient đối với các tham số LoRA B và A được cho bởi:

∂L/∂B = ∂L/∂Y X^T A, ∂L/∂A^T = B^T ∂L/∂Y X^T. (3)

--- TRANG 3 ---
Hình 2: Động lực gradient của FFT và LoRA trong sự hiện diện của một kênh đầu vào ngoại lai. Kênh đỏ trong đầu vào X biểu thị ngoại lai. Trong khi FFT cục bộ hóa tác động gradient, toàn bộ cập nhật gradient của LoRA trở nên bị ảnh hưởng không tương xứng bởi ngoại lai đơn lẻ.

Những kết quả này dẫn đến cập nhật sau trong không gian trọng số hợp nhất:

∂L/∂R = ∂L/∂B A^T + B ∂L/∂A^T = ∂L/∂Y X^T AA^T + BB^T ∂L/∂Y X^T. (4)

Biểu thức này tiết lộ cách cấu trúc của LoRA giới thiệu các tương tác không tầm thường giữa gradient và đầu vào, đặc biệt thông qua các ma trận hạng r.

2.2 Tại sao LoRA gặp khó khăn với Hạng Lớn hơn?

Khi tinh chỉnh với hạng LoRA lớn (ví dụ: r > 64), thường quan sát thấy độ chính xác giảm so với việc sử dụng hạng vừa phải. Hành vi phản trực quan này phát sinh từ động lực gradient riêng biệt của LoRA, khác biệt đáng kể so với FFT.

Thiết kế cấu trúc của LoRA làm cho gradient của nó vốn dĩ nhạy cảm với toàn bộ không gian đầu vào, như minh họa trong Hình 2. Đặc biệt, chúng tôi quan sát thấy các kênh ngoại lai, các kênh đầu vào có kích hoạt cao bất thường, có thể thống trị tín hiệu gradient một cách không tương xứng.

Trong FFT, hiệu ứng của những ngoại lai như vậy thường được cục bộ hóa, chỉ ảnh hưởng đến một cột duy nhất của ma trận trọng số W tương tác trực tiếp với kênh ngoại lai. Ngược lại, ràng buộc hạng thấp của LoRA khiến toàn bộ gradient của ma trận bộ thích ứng B, ký hiệu ∂L/∂B, bị ảnh hưởng bởi những ngoại lai này. Điều này dẫn đến cập nhật trọng số bị méo mó trong không gian trọng số hợp nhất, nơi tín hiệu gradient từ các kênh ngoại lai áp đảo đóng góp từ các đầu vào khác. Do đó, LoRA không thể sao chép chính xác động lực gradient của FFT, hạn chế khả năng đạt được hiệu suất cấp FFT.

Chúng tôi quan sát thấy trong một số lớp nhất định, đáng chú ý nhất là ma trận down-projection của Lớp 1 trong LLaMA3.1-8B, các kích hoạt đầu vào thể hiện sự mất cân bằng nghiêm trọng theo kênh (Hình 3 (a)). Như được hiển thị trong Hình 4, những kênh ngoại lai này ảnh hưởng không tương xứng đến cập nhật gradient của bộ thích ứng. Hình 3 minh họa thêm rằng khoảng cách giữa cập nhật gradient LoRA và FFT mở rộng khi hạng LoRA tăng.

Những phát hiện này tiết lộ sự mất cân bằng cơ bản giữa cập nhật LoRA và bối cảnh gradient được định hình bởi FFT. Ảnh hưởng vướng víu của các kênh đầu vào gây ra bởi phép chiếu hạng thấp hạn chế khả năng của LoRA để học cách chọn lọc từ các đặc trưng nổi bật, đặc biệt dưới thống kê đầu vào lệch. Trong khi tác động tiêu cực của ngoại lai đã được công nhận rộng rãi trong bối cảnh huấn luyện nhận thức lượng tử hóa [25] [16], ảnh hưởng của chúng đối với hành vi của LoRA chưa được nghiên cứu một cách có hệ thống cho đến nay.

--- TRANG 4 ---
Hình 3: (a) Giá trị kênh đầu vào trung bình cho các ma trận down-projection qua các lớp trong LLaMA3.1-8B. Một ngoại lai rõ ràng tồn tại trong Lớp 1, kênh 198 và 2427. (b) Độ lệch gradient giữa LoRA và FFT tăng theo hạng, cho thấy tính nhạy cảm của LoRA đối với ngoại lai đầu vào. (c) Kết quả gradient GraLoRA ở hạng 128. GraLoRA giảm đáng kể độ lệch gradient giữa FFT.

Hình 4: Phân phối gradient trong ma trận down-projection Lớp 1. Gradient LoRA cho thấy sự căn chỉnh kém với FFT, kênh ngoại lai tăng quy mô gradient tổng thể, trong khi ít nhấn mạnh kênh ngoại lai tương ứng.

3 Phương pháp

3.1 GraLoRA: Thích Ứng Hạng Thấp Hạt Nhỏ

Được thúc đẩy bởi quan sát trong phần trước, chúng tôi đề xuất GraLoRA, một mở rộng tinh tế và mô-đun của LoRA. Như minh họa trong Hình 1, GraLoRA giải quyết các hạn chế của LoRA chuẩn bằng cách phân chia ma trận trọng số thành một lưới k×k các khối độc lập, mỗi khối được trang bị bộ thích ứng hạng thấp cục bộ riêng. Ở đây, k là một siêu tham số xác định số lượng chia dọc theo chiều đầu vào và đầu ra. Khi k=1, GraLoRA rút gọn về công thức LoRA vani.

Cụ thể, cập nhật trọng số R∈R^(M×N) được biểu thị như sự nối tiếp của các cập nhật theo khối:

R_GraLoRA = [B₁,₁A^T₁,₁ ··· B₁,ₖA^T₁,ₖ]
             [⋮         ⋱    ⋮        ]
             [Bₖ,₁A^Tₖ,₁ ··· Bₖ,ₖA^Tₖ,ₖ], 

A_{i,j}∈R^(N/k×r/k), B_{i,j}∈R^(M/k×r/k) (5)

Tham số hóa lại theo khối này cung cấp kiểm soát cục bộ đối với mỗi vùng con không gian của không gian tham số. Như được chi tiết trong Phần 3.4, GraLoRA phát sinh cùng số lượng tham số và chi phí tính toán như LoRA chuẩn khi sử dụng cùng hạng. Tuy nhiên, nó giới thiệu hai lợi thế chính; (1) Khả năng Biểu đạt Nâng cao và (2) Tính Mạnh mẽ đối với Ngoại lai Đầu vào. Bằng cách cho phép thích ứng độc lập qua k² không gian con, GraLoRA hỗ trợ học đặc trưng tinh tế và chuyên biệt hơn. Ngoài ra, cập nhật gradient cục bộ đảm bảo rằng chỉ các bộ thích ứng liên kết với các vùng đầu vào bị ảnh hưởng nhận gradient lớn, do đó giảm méo mó gradient toàn cục và bảo tồn cân bằng tín hiệu giữa các kênh.

--- TRANG 5 ---
Hình 5: Dạng chính quy hóa của GraLoRA như phép nhân của hai ma trận thưa, A_GraLoRA và B_GraLoRA.

3.2 Phân tích Sức mạnh Biểu đạt

Trong khi cập nhật trọng số của GraLoRA được biểu thị như sự nối tiếp của các cập nhật theo khối trong (5), nó cũng có thể được chính quy hóa như dạng nhân của hai ma trận như trong LoRA vani. Ma trận thưa A_GraLoRA ∈ R^(N×kr) có thể được xây dựng như Hình 5 (a), trong đó A_{i,j} cho i, j ∈ {n∈N|n≤k} được đặt tại vị trí (i + (j-1)×k, j) của A_GraLoRA. Các phần tử khác bị che khuất, do đó tổng số tham số trở thành N×r.

Sau đó, B_GraLoRA ∈ R^(N×kr) được xây dựng như Hình 5 (b), trong đó ma trận B_{i,j} cho i, j ∈ {n∈N|n≤k} được đặt tại vị trí (i, j + (i-1)×k) của B_GraLoRA. Tương tự, thành phần khác của ma trận bị che khuất, do đó tổng số tham số trở thành M×r. Sau đó cập nhật trọng số của GraLoRA có thể được biểu thị là W=W₀+R_GraLoRA =W₀+B_GraLoRA A^T_GraLoRA.

Giả sử rằng tất cả các cột của [B_{i,1},···, B_{i,k}] độc lập tuyến tính, hạng của B_GraLoRA trở thành R(B_GraLoRA) = kr. Tương tự, nếu tất cả các cột của [A_{1,j},···, A_{k,j}] độc lập tuyến tính, hạng của A_GraLoRA là R(A_GraLoRA) = kr. Áp dụng bất đẳng thức hạng Sylvester để suy ra cận dưới và định lý tích ma trận cho cận trên, chúng ta có:

R(B_GraLoRA) + R(A^T_GraLoRA) - kr ≤ R(B_GraLoRA A^T_GraLoRA) ≤ min(R(B_GraLoRA), R(A^T_GraLoRA)) (6)

Do đó, hạng hiệu quả của R_GraLoRA trở thành kr, cao hơn k lần so với phương pháp LoRA vani—hiệu quả nâng cao khả năng biểu đạt của mô hình. Phân tích hạng của LoRA và GraLoRA được tinh chỉnh, được tóm tắt trong Bảng 4 trong Phụ lục, cho thấy GraLoRA mở rộng tuyến tính sức mạnh biểu diễn của ma trận thích ứng trong các cài đặt thực tế.

3.3 Động lực Gradient dưới Kích hoạt Ngoại lai

GraLoRA hiệu quả cục bộ hóa ảnh hưởng của các kênh ngoại lai đến một tập con hạn chế của các khối bộ thích ứng. Bởi vì mỗi khối chỉ xử lý một lát cụ thể của đầu vào, chỉ có k cặp bộ thích ứng giao với kênh ngoại lai được tiếp xúc với gradient được khuếch đại. Ngược lại, k²-k bộ thích ứng còn lại duy trì độ lớn gradient gần với mức cơ sở. Sự truyền gradient chọn lọc này giống với hành vi của FFT, nơi chỉ các trọng số được kết nối trực tiếp với đầu vào hoạt động mới được cập nhật đáng kể.

Tác động của GraLoRA đối với động lực gradient có thể được quan sát bằng cách so sánh phân phối gradient của ma trận down-projection trong Lớp 1 với LoRA chuẩn. Như minh họa trong Hình 3 (c) và Hình 6, GraLoRA giảm độ lệch gradient và hạn chế ảnh hưởng của các kênh ngoại lai, vượt qua các hạn chế của LoRA chuẩn với hạng lớn hơn.

3.4 Phân tích Đánh đổi

Như đã thảo luận, GraLoRA cung cấp một số lợi thế so với LoRA chuẩn. Tuy nhiên, những lợi ích này không đến mà không có chi phí. Trong phần này, chúng tôi cung cấp phân tích sâu hơn về chi phí được giới thiệu bởi GraLoRA.

Phân tích Chi phí Tính toán: Đầu tiên, chúng tôi phân tích chi phí tính toán dự kiến của LoRA theo FLOPs. Để tận dụng cấu trúc hạng thấp, LoRA tính toán phép chiếu trong hai bước tuần tự. Bước đầu tiên tính A^T X ∈ R^(r×T), tiếp theo là tái tạo B(A^T X) ∈

--- TRANG 6 ---
Hình 6: So sánh phân phối gradient dưới kích hoạt ngoại lai. Trong GraLoRA, chỉ các khối tương tác với ngoại lai thể hiện gradient được nâng cao, giảm thiểu méo mó toàn cục và căn chỉnh với hành vi FFT.

R^(M×T). Những bước này yêu cầu 2NrT và 2rMT FLOPs tương ứng, dẫn đến độ phức tạp tổng thể O(r(M+N)T).

Tương tự, GraLoRA chia tính toán thành hai bước liên quan đến k² khối bộ thích ứng. Trong bước đầu tiên, phép chiếu tính A^T_{i,j}X_j ∈ R^(r/k×T) cho mỗi trong số k² khối, phát sinh tổng chi phí 2·(N/k)·(r/k)·T·k² = 2NrT. Trong bước thứ hai, mỗi đầu ra trung gian được xử lý bởi B_{i,j} tương ứng, tạo ra B_{i,j}(A^T_{i,j}X_j) ∈ R^(M/k×T). Bước này thêm 2·(r/k)·(M/k)·T·k² = 2rMT FLOPs vào tổng chi phí. Do đó, chi phí tính toán tổng thể của GraLoRA vẫn là O(r(M+N)T), duy trì hiệu quả tương đương với LoRA vani trong khi nâng cao đáng kể sức mạnh biểu đạt.

Phân tích chi tiết về chi phí tính toán được cung cấp trong Phụ lục C.

Bảng 1: Bộ nhớ tối đa được phân bổ trong quá trình huấn luyện mô hình LLaMA3.1-8B với kích thước batch 1. Độ dài đầu vào được đặt là 1024 và bộ nhớ được phân bổ cho trọng số đã được loại bỏ để so sánh trực tiếp.

LoRA GraLoRA (k=2) GraLoRA (k=4) GraLoRA (k=8)
Backward Vani (GB) 10.0 10.1 10.2 10.4
Gradient Checkpointing (GB) 2.6 2.6 2.6 2.6

Phân tích Chi phí Bộ nhớ: Như với LoRA cổ điển, GraLoRA có thể được hợp nhất vào ma trận trọng số gốc tại thời điểm suy luận. Do đó, phân tích của chúng tôi tập trung vào chi phí bộ nhớ phát sinh trong quá trình huấn luyện. Mặc dù số lượng tham số và FLOPs giống hệt với LoRA, biểu diễn latent trung gian A^T_GraLoRA X trở nên lớn hơn k lần so với A^T X tương ứng trong LoRA chuẩn. Không gian latent mở rộng này cho phép bảo tồn thông tin lớn hơn, có thể có lợi. Tuy nhiên, nó cũng dẫn đến tăng tiêu thụ bộ nhớ trong thời gian huấn luyện. May mắn thay, hạng r thường nhỏ hơn nhiều so với chiều đầu vào và đầu ra, do đó bộ nhớ bổ sung cần thiết vẫn ở mức biên—thậm chí đối với k lớn, như được chứng minh trong Bảng 1. Hơn nữa, bằng cách áp dụng các kỹ thuật gần đây như gradient checkpointing, chi phí bộ nhớ từ không gian latent mở rộng có thể được ẩn hiệu quả, làm cho tác động trở nên không đáng kể trong thực tế.

Lựa chọn k Trong khi GraLoRA tăng tổng hạng từ r lên kr, mỗi khối riêng lẻ, được biểu diễn như B_{i,j}A^T_{i,j} ∈ R^(M/k×N/k), bị ràng buộc đến hạng giảm r/k. Kết quả là, tăng k vượt quá một ngưỡng nhất định có thể làm giảm hiệu suất do khả năng biểu đạt hạn chế trong mỗi khối. Hiệu ứng này đặc biệt rõ ràng khi hạng tổng thể r nhỏ. Theo kinh nghiệm, chúng tôi quan sát thấy việc duy trì khả năng biểu đạt khối tối thiểu khoảng r/k²≈8 mang lại hiệu suất ổn định qua các cấu hình khác nhau. Dựa trên quan sát này, chúng tôi áp dụng k=2 cho hạng 16 và 32, và k=4 cho hạng 64 và 128 trong các thử nghiệm của chúng tôi. Kết quả chi tiết từ k-sweep có thể được tìm thấy trong Phần 4.4.

3.5 GraLoRA Lai

Mặt khác, đối với các hạng nhỏ hơn—thường là hạng 16 trở xuống—việc sử dụng k=2 vẫn có thể dẫn đến suy giảm hiệu suất hoặc chỉ mang lại lợi ích biên. Để giải quyết hạn chế này, chúng tôi giới thiệu

--- TRANG 7 ---
Hình 7: Kiến trúc GraLoRA Lai khi GraLoRA k=2. Tham số LoRA trở thành được chia sẻ qua các bộ thích ứng GraLoRA nhỏ trong cùng hàng hoặc cùng cột.

một cách tiếp cận lai kết hợp điểm mạnh của LoRA và GraLoRA. Phương pháp này giữ lại việc xử lý đầu vào tinh tế và tổng hạng tăng do GraLoRA cung cấp, trong khi bảo tồn sức mạnh biểu đạt của các đơn vị khối lớn hơn thông qua LoRA. Vì LoRA chia sẻ cùng tham số qua cả hàng và cột, nó có thể được tích hợp tự nhiên với GraLoRA dưới dạng nối tiếp, mà chúng tôi gọi là GraLoRA Lai (xem Hình 7). Theo kinh nghiệm, chúng tôi thấy rằng phân bổ lên đến 1/2 tổng hạng cho thành phần LoRA giảm thiểu các hạn chế của GraLoRA trong các tình huống hạng thấp (γ <= 16), trong khi phân bổ đầy đủ hạng cho GraLoRA hoạt động tốt hơn trong các trường hợp hạng cao.

4 Thử nghiệm

Để xác minh tính ưu việt của ý tưởng được đề xuất, chúng tôi tiến hành phân tích rộng rãi trên tập dữ liệu quy mô lớn với các LLM tiên tiến. Chúng tôi đánh giá GraLoRA qua hai lĩnh vực thách thức: tạo mã và suy luận thông thường. Các thử nghiệm của chúng tôi được thiết kế để đánh giá liệu cơ chế thích ứng hạt nhỏ được đề xuất có cải thiện hiệu suất qua các kích thước mô hình, hạng LoRA và nhiệm vụ đòi hỏi suy luận tinh tế và độ trung thực biểu diễn cao khác nhau.

4.1 Thiết lập Thử nghiệm

Tạo Mã. Chúng tôi tinh chỉnh mỗi mô hình trên tập dữ liệu huấn luyện Magicoder-Evol-Instruct-110k [24], một tập con được tuyển chọn và khử nhiễm của WizardCoder [17], bao gồm các cặp chỉ dẫn-phản hồi chất lượng cao cho các nhiệm vụ lập trình. Đánh giá được thực hiện trên tập dữ liệu thử nghiệm Humaneval+ theo He et al. [9], lấy mẫu 50 hoàn thành cho mỗi bài toán sử dụng nhiệt độ 0.2. Chúng tôi báo cáo độ chính xác Pass@1, Pass@5 và Pass@10 theo giao thức chuẩn qua BigCode Evaluation Harness [1]. Chúng tôi đã đánh giá trọng số epoch cuối qua tất cả các phương pháp.

Suy luận Thông thường Chúng tôi tinh chỉnh mỗi mô hình qua 8 nhiệm vụ suy luận thông thường: BoolQ [6], PIQA [4], SIQA [22], HellaSwag [28], WinoGrande [21], ARC-Challenge, ARC-Easy [7], và OpenBookQA [19]. Chúng tôi tuân theo quy trình huấn luyện được đề xuất bởi LLM-Adapters [12], sử dụng tập dữ liệu hợp nhất được tạo thành từ các tập huấn luyện từ tất cả các nhiệm vụ. Đánh giá được thực hiện trên tập dữ liệu thử nghiệm riêng lẻ cho mỗi nhiệm vụ trên trọng số epoch cuối. Các tham số huấn luyện chi tiết có thể được tìm thấy trong Phụ lục D.

Chi tiết Huấn luyện Chúng tôi tiến hành thử nghiệm trên bốn LLM mã nguồn mở với kiến trúc và kích thước khác nhau: LLaMA3.1-8B, LLaMA3.1-70B ([8]), Qwen-2.5-1.5B và Qwen-2.5-7B ([27]). Chúng tôi sử dụng các mô hình được huấn luyện trước thay vì các mô hình được tinh chỉnh theo hướng dẫn theo thực tiễn chung ([14,15]). Chúng tôi áp dụng các phương pháp PEFT trên tất cả các mô-đun tuyến tính từ attention (Wq, Wk, Wv, Wo) và mạng feed-forward (Wup, Wdown, Wgate). Chúng tôi đặt các siêu tham số dựa trên cấu hình tối ưu từ Biderman et al. [3] và He et al. [9], sử dụng bộ tối ưu hóa LionW tách rời với kích thước batch 192 và đặt LoRA α=2r. Chúng tôi áp dụng mẫu alpaca-chat cho cả hai nhiệm vụ. Tạo mã được thực hiện trên 4 GPU A100 80G và nhiệm vụ suy luận thông thường được thực hiện trên 2 GPU H100 80G cho các mô hình 1.5-8B. Mô hình 70B được thực hiện trên 8 GPU A100 80G. Chúng tôi so sánh GraLoRA với ba phương pháp PEFT đại diện: LoRA, MoRA [14] và RaSA [9].

--- TRANG 8 ---
Bảng 2: Kết quả Pass@1, Pass@5 và Pass@10 trên LLaMA3.1-8B sử dụng LoRA, MoRA, RaSA và GraLoRA qua các hạng khác nhau. Kết quả tốt nhất mỗi nhóm được in đậm. * biểu thị GraLoRA Lai.

Hạng Phương pháp Thời gian Huấn luyện Thời gian Tương đối Pass@1 Pass@5 Pass@10
16 LoRA 6.2h 1.00 × 56.1% 65.3% 68.1%
MoRA 8.8h 1.42 × 53.6% 62.2% 64.5%
RaSA 6.7h 1.08 × 53.7% 64.4% 66.7%
GraLoRA* 6.7h 1.08 × 58.0% 67.1% 70.1%

32 LoRA 6.5h 1.00 × 58.4% 68.0% 69.9%
MoRA 9.1h 1.40 × 58.3% 66.7% 69.0%
RaSA 6.8h 1.05 × 57.2% 67.9% 70.5%
GraLoRA 6.9h 1.06 × 58.9% 67.0% 69.0%

64 LoRA 6.7h 1.00 × 58.1% 66.4% 68.5%
MoRA 9.7h 1.45 × 57.2% 66.4% 69.2%
RaSA 6.9h 1.03 × 56.6% 65.4% 67.9%
GraLoRA 7.2h 1.07 × 60.5% 71.2% 72.6%

128 LoRA 7.0h 1.00 × 55.8% 64.8% 68.6%
MoRA 9.9h 1.41 × 52.8% 62.3% 65.3%
RaSA 7.6h 1.09 × 57.5% 65.5% 67.5%
GraLoRA 7.7h 1.10 × 64.3% 71.7% 73.7%

Bảng 3: Độ chính xác suy luận thông thường qua các mô hình và nhiệm vụ. Tất cả giá trị đều là phần trăm; in đậm biểu thị hiệu suất tốt nhất mỗi hàng. HS có nghĩa là HellaSwag, và WG WinoGrande.

Mô hình Phương pháp BoolQ PIQA SIQA HS WG ARC-c ARC-e OBQA Trung bình
Qwen2.5-1.5B LoRA 66.5% 84.0% 74.9% 83.6% 73.7% 75.2% 88.1% 83.4% 78.7%
MoRA 65.9% 82.2% 74.7% 82.6% 73.4% 72.6% 86.5% 82.8% 77.6%
RaSA 67.5% 83.7% 75.7% 85.3% 72.9% 76.4% 89.8% 83.8% 79.4%
GraLoRA 67.2% 84.2% 75.9% 85.7% 73.8% 77.5% 89.9% 84.4% 79.8%

Qwen2.5-7B LoRA 72.3% 88.2% 79.2% 92.9% 84.7% 84.0% 93.6% 89.6% 85.6%
MoRA 69.9% 85.3% 78.5% 83.7% 81.4% 77.5% 88.6% 85.0% 81.2%
RaSA 72.0% 88.5% 78.9% 93.6% 81.8% 86.1% 94.2% 90.2% 85.7%
GraLoRA 73.4% 89.7% 79.0% 93.0% 84.0% 86.9% 94.5% 90.6% 86.4%

LLaMA3.1-70B LoRA 81.7% 93.4% 82.2% 97.5% 93.1% 90.2% 96.5% 95.6% 91.3%
GraLoRA 83.1% 94.7% 83.6% 97.9% 93.8% 92.3% 97.8% 96.2% 92.4%

4.2 Kết quả về Tạo Mã

Như được hiển thị trong Bảng 2, GraLoRA vượt trội so với LoRA, MoRA và RaSA qua tất cả các hạng được thử nghiệm cho độ chính xác Pass@1. Ở hạng 64, GraLoRA đạt được cải thiện tuyệt đối +2.4% trong Pass@1, +4.8% trong Pass@5 và +4.1% trong Pass@10 so với LoRA. Ở hạng 128, lợi ích thậm chí còn rõ ràng hơn, với sự tăng +8.5% trong Pass@1, +6.9% trong Pass@5 và +5.1% trong Pass@10. Đáng chú ý, trong khi các phương pháp khác gặp khó khăn để tận dụng đầy đủ khả năng hạng tăng—thường đạt đến các ngưỡng hiệu suất ở hạng thấp hơn—GraLoRA duy trì một quỹ đạo tăng nhất quán, hiệu quả vượt qua các hạn chế của LoRA.

Thậm chí trong các cài đặt hạng thấp (ví dụ: hạng 16), nơi khả năng biểu đạt thường bị hạn chế, biến thể lai của GraLoRA đã thể hiện hiệu suất vượt trội. Những cải thiện này làm nổi bật khả năng nâng cao của GraLoRA để bảo tồn các tín hiệu gradient đa dạng và chống lại sự đàn áp từ các ngoại lai thống trị. Kết quả mạnh mẽ trên benchmark HumanEval+ càng nhấn mạnh lợi ích của thích ứng tinh tế trong việc giải quyết các nhiệm vụ tạo mã phức tạp, độ chính xác cao.

4.3 Kết quả về Suy luận Thông thường

Như được hiển thị trong Bảng 3, GraLoRA vượt trội so với các phương pháp khác qua nhiều mô hình và nhiệm vụ. Đáng chú ý, GraLoRA thể hiện hiệu suất vượt trội qua các mô hình với quy mô khác nhau, đạt được cải thiện 1.1% trong độ chính xác trung bình trên cả Qwen2.5-1.5B và LLaMA3.1-70B. Nó cũng mang lại lợi ích 0.9% trên mô hình kích thước trung bình được sử dụng rộng rãi, Qwen2.5-7B.

Hơn nữa, GraLoRA đạt được kết quả tốt nhất trên 20 trong số 24 nhiệm vụ, vượt trội so với các phương án thay thế một cách nhất quán qua các benchmark. Những kết quả này hỗ trợ phân tích của chúng tôi trong Phần 3.3, cho thấy các cập nhật cục bộ của GraLoRA nâng cao sự căn chỉnh với FFT và thúc đẩy khái quát hóa mạnh mẽ trong các nhiệm vụ suy luận đa khía cạnh.

4.4 Nghiên cứu Ablation

GraLoRA k Sweep Chúng tôi đánh giá tác động của việc thay đổi k đối với độ chính xác tạo mã. Như được hiển thị trong Hình 8 (a), k=2 mang lại hiệu suất tốt nhất ở hạng 32, trong khi k=4 là tối ưu ở hạng 128. Những kết quả này phù hợp với dự đoán lý thuyết rằng k nhỏ hơn tốt hơn cho các hạng thấp hơn, vì hạng khối con giảm có thể đặc biệt có hại khi hạng tổng thể bị hạn chế.

GraLoRA Lai Ratio Sweep Chúng tôi đánh giá hiệu suất qua các tỷ lệ phân bổ hạng LoRA-so với-GraLoRA khác nhau cho cấu hình GraLoRA Lai (Hình 8 (b)). Ở hạng 16, việc phân bổ một phần hạng cho LoRA dẫn đến độ chính xác tối ưu. Tuy nhiên, đối với các hạng lớn hơn, việc phân bổ hạng cho LoRA dẫn đến hiệu suất giảm. Điều này cho thấy GraLoRA Lai có lợi trong các chế độ hạng thấp, nơi hạng khối con của riêng GraLoRA có thể không đủ. Ngược lại, dưới các cài đặt hạng cao hơn nơi các khối con của GraLoRA đủ biểu đạt, việc giới thiệu các thành phần LoRA có thể dẫn đến vướng víu gradient, do đó cản trở học tập hiệu quả.

--- TRANG 9 ---
Hình 8: (a) Kết quả GraLoRA k sweep và (b) Kết quả Hybrid GraLoRA Ratio sweep cho LLaMA3.1-8B trên nhiệm vụ tạo mã. Tỷ lệ 0 hàm ý GraLoRA mặc định và tỷ lệ 1 hàm ý LoRA vani trong (b).

5 Kết luận

Trong công trình này, chúng tôi đã giới thiệu GraLoRA, một phương pháp PEFT mới mở rộng LoRA với phân tách hạt nhỏ theo khối. Được thúc đẩy bởi phân tích nghiêm ngặt về hành vi gradient của LoRA, chúng tôi đã xác định rằng các ngoại lai đầu vào có thể thống trị cập nhật hạng thấp, đàn áp đóng góp có ý nghĩa từ các kênh đầu vào khác và mất căn chỉnh với sự truyền gradient cục bộ được quan sát trong FFT.

GraLoRA giải quyết hạn chế này bằng cách chia không gian thích ứng thành k² bộ thích ứng hạng thấp được huấn luyện độc lập, cho phép cập nhật cục bộ không gian và nhận thức ngữ cảnh. Phân tích lý thuyết của chúng tôi cho thấy thiết kế này tăng khả năng biểu đạt với hệ số k, mà không có tham số hoặc chi phí tính toán bổ sung. Hơn nữa, dưới kích hoạt ngoại lai, GraLoRA hiệu quả giảm thiểu méo mó gradient toàn cục được thấy trong LoRA vani và bảo tồn tốt hơn cân bằng giữa các kênh. Theo kinh nghiệm, GraLoRA vượt trội so với LoRA chuẩn và các baseline mạnh như RaSA một cách nhất quán qua các nhiệm vụ và quy mô mô hình đa dạng. Trên benchmark tạo mã HumanEval+, nó đạt được lợi ích tuyệt đối lên đến +8.5% trong Pass1. Trong suy luận thông thường, GraLoRA mang lại cải thiện qua tất cả các nhiệm vụ, với kết quả đặc biệt mạnh trên các benchmark suy luận nhiều bước và có cấu trúc.

Công việc Tương lai. Trong khi GraLoRA cải thiện tính cục bộ gradient và sức mạnh biểu đạt, thiết kế hiện tại của nó giả định phân chia đồng nhất. Các mở rộng tương lai có thể khám phá các sơ đồ phân chia thích ứng hoặc học được, kích hoạt khối nhận thức thưa thớt, hoặc phân bổ hạng động điều khiển bởi nhiệm vụ. Ngoài ra, việc áp dụng GraLoRA cho các transformer thị giác, kiến trúc đa phương thức, hoặc thiết lập học liên tục có thể làm nổi bật thêm tiềm năng của nó cho thích ứng mô hình mạnh mẽ và hiệu quả.

Nhìn chung, GraLoRA đại diện cho một bước tiến có nguyên tắc và thực tế trong thiết kế các phương pháp PEFT, thu hẹp khoảng cách giữa tham số hóa lại hạng thấp toàn cục và thích ứng cục bộ, tinh tế.

--- TRANG 10 ---
Tài liệu tham khảo

[1] Loubna Ben Allal, Niklas Muennighoff, Logesh Kumar Umapathi, Ben Lipkin, và Leandro von Werra. Một framework để đánh giá các mô hình tạo mã. https://github.com/bigcode-project/bigcode-evaluation-harness, 2022.

[2] Dan Biderman, Jacob Portes, Jose Javier Gonzalez Ortiz, Mansheej Paul, Philip Greengard, Connor Jennings, Daniel King, Sam Havens, Vitaliy Chiley, Jonathan Frankle, Cody Blakeney, và John P. Cunningham. LoRA học ít hơn và quên ít hơn. Transactions on Machine Learning Research, 2024.

[3] Dan Biderman, Jacob Portes, Jose Javier Gonzalez Ortiz, Mansheej Paul, Philip Greengard, Connor Jennings, Daniel King, Sam Havens, Vitaliy Chiley, Jonathan Frankle, et al. Lora học ít hơn và quên ít hơn. arXiv preprint arXiv:2405.09673, 2024.

[4] Yonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, et al. Piqa: Suy luận về thông thường vật lý trong ngôn ngữ tự nhiên. Trong Proceedings of the AAAI conference on artificial intelligence, tập 34, trang 7432–7439, 2020.

[5] Kerim Büyükakyüz. Olora: Thích ứng hạng thấp trực giao của các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2406.01775, 2024.

[6] Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, và Kristina Toutanova. BoolQ: Khám phá độ khó đáng ngạc nhiên của các câu hỏi có/không tự nhiên. Trong Jill Burstein, Christy Doran, và Thamar Solorio, biên tập, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), trang 2924–2936, Minneapolis, Minnesota, Tháng 6 2019. Association for Computational Linguistics.

[7] Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, và Oyvind Tafjord. Nghĩ bạn đã giải quyết câu trả lời câu hỏi? thử arc, thử thách suy luận ai2. arXiv preprint arXiv:1803.05457, 2018.

[8] Aaron Grattafiori et al. Đàn mô hình llama 3, 2024.

[9] Zhiwei He, Zhaopeng Tu, Xing Wang, Xingyu Chen, Zhijie Wang, Jiahao Xu, Tian Liang, Wenxiang Jiao, Zhuosheng Zhang, và Rui Wang. RaSA: Thích ứng hạng thấp chia sẻ hạng. Trong Proceedings of the 2025 International Conference on Learning Representations (ICLR), 2025.

[10] Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan, và Sylvain Gelly. Học chuyển giao hiệu quả tham số cho nlp, 2019.

[11] Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, và Weizhu Chen. LoRA: Thích ứng hạng thấp của các mô hình ngôn ngữ lớn. arXiv preprint arXiv:2106.09685, 2021.

[12] Zhiqiang Hu, Lei Wang, Yihuai Lan, Wanyu Xu, Ee-Peng Lim, Lidong Bing, Xing Xu, Soujanya Poria, và Roy Lee. llm-adapters: Một họ bộ thích ứng cho tinh chỉnh hiệu quả tham số của các mô hình ngôn ngữ lớn. Trong Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, trang 5254–5276, 2023.

[13] Qiushi Huang, Tom Ko, Zhan Zhuang, Lilian Tang, và Yu Zhang. HiRA: Thích ứng hạng cao hadamard hiệu quả tham số cho các mô hình ngôn ngữ lớn. Trong Proceedings of the 2025 International Conference on Learning Representations (ICLR), 2025.

[14] Ting Jiang, Shaohan Huang, Shengyue Luo, Zihan Zhang, Haizhen Huang, Furu Wei, Weiwei Deng, Feng Sun, Qi Zhang, Deqing Wang, và Fuzhen Zhuang. MoRA: Cập nhật hạng cao cho tinh chỉnh hiệu quả tham số. arXiv preprint arXiv:2405.12130, 2024.

[15] Dawid J. Kopiczko, Tijmen Blankevoort, và Yuki M. Asano. VeRA: Thích ứng ma trận ngẫu nhiên dựa trên vector. Trong Proceedings of the 2024 International Conference on Learning Representations (ICLR), 2024.

--- TRANG 11 ---
[16] Changhun Lee, Jungyu Jin, Taesu Kim, Hyungjun Kim, và Eunhyeok Park. Owq: Lượng tử hóa trọng số nhận thức ngoại lai cho tinh chỉnh và suy luận hiệu quả của các mô hình ngôn ngữ lớn. Trong Proceedings of the AAAI Conference on Artificial Intelligence, tập 38, trang 13355–13364, 2024.

[17] Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, và Daxin Jiang. Wizardcoder: Trao quyền cho các mô hình ngôn ngữ lớn mã với evol-instruct. Trong The Twelfth International Conference on Learning Representations, 2024.

[18] Fanxu Meng, Zhaohui Wang, và Muhan Zhang. Pissa: Thích ứng giá trị đơn và vector đơn chính của các mô hình ngôn ngữ lớn. Advances in Neural Information Processing Systems, 37:121038–121072, 2024.

[19] Todor Mihaylov, Peter Clark, Tushar Khot, và Ashish Sabharwal. Một bộ áo giáp có thể dẫn điện không? một tập dữ liệu mới cho trả lời câu hỏi sách mở, 2018.

[20] Fabian Paischer, Lukas Hauzenberger, Thomas Schmied, Benedikt Alkin, Marc Peter Deisenroth, và Sepp Hochreiter. Một khởi tạo để cai trị tất cả: Tinh chỉnh qua thích ứng phương sai được giải thích. arXiv preprint arXiv:2410.07170, 2024.

[21] Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, và Yejin Choi. Winogrande: Một thử thách schema winograd đối kháng ở quy mô. Communications of the ACM, 64(9):99–106, 2021.

[22] Maarten Sap, Hannah Rashkin, Derek Chen, Ronan LeBras, và Yejin Choi. Socialiqa: Suy luận thông thường về tương tác xã hội. arXiv preprint arXiv:1904.09728, 2019.

[23] Shaowen Wang, Linxi Yu, và Jian Li. Lora-ga: Thích ứng hạng thấp với xấp xỉ gradient. Advances in Neural Information Processing Systems, 37:54905–54931, 2024.

[24] Yuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, và Lingming Zhang. Magicoder: Trao quyền tạo mã với OSS-instruct. Trong Ruslan Salakhutdinov, Zico Kolter, Katherine Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett, và Felix Berkenkamp, biên tập, Proceedings of the 41st International Conference on Machine Learning, tập 235 của Proceedings of Machine Learning Research, trang 52632–52657. PMLR, 21–27 Tháng 7 2024.

[25] Guangxuan Xiao, Ji Lin, Mickael Seznec, Hao Wu, Julien Demouth, và Song Han. Smoothquant: Lượng tử hóa sau huấn luyện chính xác và hiệu quả cho các mô hình ngôn ngữ lớn, 2024.

[26] Lingling Xu, Haoran Xie, Si-Zhao Joe Qin, Xiaohui Tao, và Fu Lee Wang. Các phương pháp tinh chỉnh hiệu quả tham số cho các mô hình ngôn ngữ được huấn luyện trước: Một đánh giá và đánh giá quan trọng, 2023.

[27] An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, et al. Báo cáo kỹ thuật Qwen2.5. arXiv preprint arXiv:2412.15115, 2024.

[28] Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, và Yejin Choi. Hellaswag: Một máy có thực sự có thể hoàn thành câu của bạn không? arXiv preprint arXiv:1905.07830, 2019.

--- TRANG 12 ---
A Phân tích Hạng trong Các Tình huống Thế giới Thực

Bảng 4: Kích thước hạng trung bình trong mỗi lớp chiếu qua các biến thể LoRA và GraLoRA. Hạng r được đặt là 128 trong tất cả các phương pháp.

q_proj k_proj v_proj o_proj up_proj down_proj gate_proj
LoRA 128 128 128 128 128 128 128
GraLoRA (k=2) 256 256 256 256 256 256 256
GraLoRA (k=4) 512 512 512 512 512 512 512
GraLoRA (k=8) 1024 1016 1022 1024 1024 1024 1024

Như được hiển thị trong Bảng 4, GraLoRA biểu thị hạng tăng tuyến tính khi k tăng. Quan sát này phù hợp với phân tích lý thuyết của chúng tôi rằng tăng GraLoRA k dẫn đến sức mạnh biểu đạt cao hơn bằng cách tăng không gian latent từ r lên kr.

B Phân phối Gradient của LoRA và GraLoRA

Hình 9: So sánh phân phối gradient dưới kích hoạt ngoại lai cho hạng 32, 64 và 128 trong ma trận down-projection Lớp 1 LLaMA3.1-8B.

Hình 9 hiển thị phân phối gradient của LoRA và GraLoRA cho các hạng khác nhau. Trong GraLoRA, chỉ các khối tương tác với ngoại lai thể hiện gradient được nâng cao, giải quyết cấu trúc vướng víu gradient được phát hiện trong LoRA vani. Điều này cho phép giảm thiểu méo mó toàn cục và căn chỉnh với hành vi FFT trong tất cả các hạng.

--- TRANG 13 ---
C Phân tích Chính xác về Chi phí Tính toán

Hình 10: Quy trình tính toán trong GraLoRA bao gồm 3 bước: hai phép nhân ma trận khối con và một phép cộng ma trận tiếp theo.

Trong phần "Phân tích Chi phí Tính toán" trước đây 3.4 chúng tôi đã so sánh tính toán của LoRA và GraLoRA với ký hiệu O lớn trên hai bước nhân ma trận chính. Trong phần này chúng tôi kiểm tra thêm yêu cầu tính toán chính xác và so sánh hiệu quả của chúng.

FLOPs LoRA LoRA thực hiện phép chiếu trong hai bước tuần tự để tận dụng cấu trúc hạng thấp của nó. Trong bước đầu tiên, tính toán A^T X ∈ R^(r×T) yêu cầu (2N-1)rT FLOPs. Trong bước thứ hai, tái tạo B(A^T X) ∈ R^(M×T) phát sinh (2r-1)MT FLOPs. Do đó, tổng FLOPs cho LoRA là:

LoRA FLOPs = (2N-1)rT + (2r-1)MT
= 2r(M+N)T - (r+M)T.

FLOPs GraLoRA Trong thực tế, tính toán GraLoRA có thể được chia thành ba giai đoạn, liên quan đến k² khối bộ thích ứng: hai phép nhân ma trận tiếp theo là một phép cộng ma trận như được hiển thị trong Hình 10.

Trong giai đoạn đầu tiên (chiếu), mỗi khối bộ thích ứng tính A^T_{i,j}X_j ∈ R^(r/k×T), yêu cầu (2n/k-1)(r/k)T FLOPs. Vì có k² khối như vậy, tổng FLOPs cho bước này là (2n-k)rT.

Trong giai đoạn thứ hai (tái tạo), mỗi khối bộ thích ứng thực hiện B_{i,j}(A^T_{i,j}X_j) ∈ R^(m/k×T), có chi phí (2r/k-1)(m/k)T FLOPs. Với k² khối, tổng trở thành (2r-k)mT.

Giai đoạn cuối liên quan đến tổng hợp đầu ra qua k chiếu cho mỗi hàng:
∑_{j=1}^k B_{i,j}(A^T_{i,j}X_j) ∈ R^(m/k×T),

yêu cầu (m/k×T)(k-1) = mT(k-1)/k FLOPs mỗi hàng. Qua k hàng, tổng chi phí trở thành (k-1)mT.

Kết hợp cả ba giai đoạn, tổng FLOPs cho GraLoRA là:

GraLoRA FLOPs = (2n-k)rT + (2r-k)mT + (k-1)mT
= 2r(m+n)T - k(r+m)T + (k-1)mT
= 2r(m+n)T - krT - mT.

Điều này cũng có thể được biểu thị là:

GraLoRA FLOPs = LoRA FLOPs - (k-1)rT,

chứng minh rằng GraLoRA giới thiệu tính toán giảm so với LoRA.

--- TRANG 14 ---
D Baseline và Siêu tham số

Phương pháp Baseline. Chúng tôi so sánh GraLoRA với ba phương pháp baseline. Ý tưởng chính cho mỗi phương pháp như sau:

• LoRA đông lạnh trọng số mô hình được huấn luyện trước và chèn các ma trận hạng thấp có thể huấn luyện vào các lớp được chọn, cho phép tinh chỉnh hiệu quả với ít tham số hơn đáng kể, xấp xỉ cập nhật trọng số như tích của hai ma trận nhỏ.

• MoRA sử dụng một ma trận vuông duy nhất thay vì các ma trận hạng thấp để đạt được cập nhật hạng cao trong khi duy trì cùng số lượng tham số có thể huấn luyện.

• RaSA nâng cao LoRA bằng cách chia sẻ các thành phần hạng thấp một phần qua các lớp trong khi giữ các cập nhật cụ thể theo lớp.

Bảng 5: Cài đặt siêu tham số cho mỗi phương pháp và tập dữ liệu.

Nhiệm vụ Mô hình Phương pháp Hạng LR Kích thước Batch Epochs
Tạo Mã LLaMA3.1-8B LoRA {16, 32, 64, 128} 2e-4 192 2
MoRA
RaSA
GraLoRA

Suy luận Thông thường Qwen-2.5-1.5B LoRA 64 2e-4 192 2
MoRA
RaSA
GraLoRA

Qwen-2.5-7B LoRA 64 4e-4 192 2
MoRA
RaSA
GraLoRA

LLaMA3.1-70B LoRA 64 3e-4 192 1
GraLoRA

Đối với siêu tham số, chúng tôi cố định LoRA α=2r được biết là thường áp dụng trong các mô hình khác nhau với các hạng khác nhau [2]. Cài đặt siêu tham số chi tiết cho các thử nghiệm của chúng tôi được ký hiệu trong Bảng 5.

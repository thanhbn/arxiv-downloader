# 2309.08513.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2309.08513.pdf
# Kích thước tệp: 1301605 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Bản thảo không tên số
(sẽ được chèn bởi biên tập viên)
SCT: Một Phương Pháp Đơn Giản cho Tinh Chỉnh Hiệu Quả Tham Số
thông qua Các Kênh Nổi Bật
Henry Hengyuan Zhao ·Pichao Wang ·Yuyang Zhao ·Hao Luo ·Fan
Wang ·Mike Zheng Shou
Nhận: ngày / Chấp nhận: ngày
Tóm tắt Các vision transformer đã được huấn luyện trước có lợi ích biểu diễn mạnh mẽ cho nhiều tác vụ downstream khác nhau.
Gần đây, nhiều phương pháp tinh chỉnh hiệu quả tham số (PEFT) đã được đề xuất, và các thí nghiệm của chúng chứng minh rằng việc chỉnh chỉ 1% tham số bổ sung có thể vượt qua tinh chỉnh đầy đủ trong các tình huống tài nguyên dữ liệu thấp. Tuy nhiên, các phương pháp này bỏ qua thông tin đặc thù cho tác vụ khi tinh chỉnh các tác vụ downstream đa dạng. Trong bài báo này, chúng tôi đề xuất một phương pháp đơn giản nhưng hiệu quả được gọi là "Tinh Chỉnh Kênh Nổi Bật" (SCT) để tận dụng thông tin đặc thù cho tác vụ bằng cách chuyển tiếp mô hình với các hình ảnh tác vụ để chọn các kênh một phần trong bản đồ đặc trưng cho phép chúng tôi chỉ chỉnh chỉ 1/8 kênh dẫn đến chi phí tham số thấp hơn đáng kể. Các thí nghiệm trên 19 tác vụ downstream học chuyển giao thị giác chứng minh rằng SCT của chúng tôi vượt trội so với tinh chỉnh đầy đủ trên 18 trong số 19 tác vụ bằng cách chỉ thêm 0.11M tham số của ViT-B, ít hơn 780 × so với
Henry Hengyuan Zhao
Show Lab, Đại học Quốc gia Singapore, Singapore
E-mail: hengyuan.z@u.nus.edu
Pichao Wang
Alibaba Group, Hoa Kỳ
E-mail: pichaowang@gmail.com
Yuyang Zhao
Đại học Quốc gia Singapore, Singapore
E-mail: yuyang.zhao@u.nus.edu
Hao Luo
Alibaba Group, Trung Quốc
E-mail: michuan.lh@alibaba-inc.com
Fan Wang
Alibaba Group, Hoa Kỳ
E-mail: fan.w@alibaba-inc.com
Mike Zheng Shou (Tác giả tương ứng)
Show Lab, Đại học Quốc gia Singapore, Singapore
E-mail: mike.zheng.shou@gmail.com
SCT Adapter SSF LoRA NOAH VPT0.10.20.30.40.50.6# Params(M)
0.110.160.240.290.430.53
SCT Adapter SSF LoRA NOAH VPT697071727374Độ Chính Xác Top-173.6
71.372.6
72.373.3
69.4Hình 1: So sánh tham số và độ chính xác top-1 trên benchmark VTAB-1K với các phương pháp baseline khác nhau.
Chúng tôi chỉ chỉnh chỉ 96 kênh trong 768 kênh của ViT-B/16, đạt được kết quả tốt nhất so với các phương pháp khác.
đối tác tinh chỉnh đầy đủ của nó. Hơn nữa, các thí nghiệm về khái quát hóa miền và phân loại few-shot tiếp tục chứng minh tính hiệu quả và tổng quát của phương pháp của chúng tôi. Mã nguồn có sẵn tại
https://github.com/showlab/SCT

1 Giới thiệu
Các vision transformer lớn (ViT) đã đạt được thành công đáng kể trong các tác vụ thị giác máy tính (Dosovitskiy
et al., 2020; Liu et al., 2021; Yuan et al., 2022; Zhou
et al., 2021a; Carion et al., 2020; Li et al., 2021; Strudel
et al., 2021) bằng cách sử dụng dữ liệu huấn luyện quy mô lớn, như ImageNet21K và JFT-300M, để tạo ra các biểu diễn mạnh mẽ. Tuy nhiên, các tác vụ nhận dạng downstream thường thiếu đủ dữ liệu để huấn luyện từ đầu. Do đó, việc chuyển giao kiến thức từ các mô hình ViT đã được huấn luyện trước có thể giảm đáng kể độ khó trong huấn luyện và tạo ra kết quả đầy hứa hẹn. Tinh chỉnh đầy đủ end-to-end là một cách được sử dụng rộng rãi để kế thừa những biểu diễn mạnh mẽ này, nhưng nó phải đối mặt với hai thách thức. Thứ nhất, các mô hình lớn dễ bị overfitting khi chỉnh chỉ khối lượng trọng số khổng lồ của chúng trên dữ liệu huấn luyện downstream nhỏ. Thứ hai, các mô hình ViT quá lớn để lưu trữ tất cả trọng số cho mỗi tác vụ downstream, khiến việc triển khai các mô hình đã tinh chỉnh trên các thiết bị có tài nguyên hạn chế trở nên không khả thi.arXiv:2309.08513v5  [cs.CV]  29 Apr 2024

--- TRANG 2 ---
2 Henry Hengyuan Zhao et al.
Phi tuyến
Giảm mẫuTăng mẫu
1 ×𝐷′
Đặc trưng đầu vào: 1 ×𝐷Đặc trưng đầu ra: 1 ×𝐷
Lựa Chọn 
KênhTuyến tính
1 ×𝐾
Đặc trưng đầu vào: 1 ×𝐷Đặc trưng đầu ra: 1 ×𝐷
(a) Adapter (b) Của chúng tôi
Hình 2: So sánh kiến trúc giữa Adapter và SCT của chúng tôi. "Giảm mẫu" và "Tăng mẫu" đại diện cho các phép toán giảm mẫu và tăng mẫu kênh. D đại diện cho số chiều kênh.

Để giảm thiểu hai thách thức trên, một số nghiên cứu đề xuất chỉnh chỉ một tập con tham số (?) hoặc áp dụng một mô-đun có thể huấn luyện bên ngoài (Houlsby et al., 2019; Hu et al., 2021) để bảo tồn kiến thức học được từ các mô hình đã được huấn luyện trước. Đối với việc chỉnh chỉ một tập con tham số, có hai phương pháp đại diện: chỉnh chỉ đầu phân loại (Mahajan et al., 2018; Jia et al., 2021; Chen et al., 2021b) và chỉnh chỉnh số hạng bias (Cai et al., 2020). Chỉnh chỉ đầu phân loại bao gồm việc đóng băng trọng số của mạng backbone và chỉ cập nhật đầu tuyến tính, trong khi chỉnh chỉ số hạng bias bao gồm việc mở đóng băng số hạng bias trong mạng backbone. Cả hai phương pháp đều dẫn đến hiệu suất kém hơn.

Gần đây, một số nghiên cứu đề xuất giải quyết một tác vụ mới được gọi là Tinh Chỉnh Hiệu Quả Tham Số (PEFT) bằng cách tận dụng một mô-đun có thể huấn luyện bên ngoài cho việc thích ứng mô hình. Một loại phương pháp bao gồm việc tích hợp các prompt có thể học được vào đầu vào mô hình cho mỗi tác vụ downstream, được minh họa bằng công trình tiên phong, VPT(Jia et al., 2022). Tuy nhiên, VPT gặp phải một số thách thức. Thứ nhất, các prompt đặc thù cho tác vụ của nó được suy ra thông qua học có giám sát, khác với các prompt văn bản do người dùng cung cấp thường được sử dụng trong lĩnh vực NLP. Thứ hai, VPT yêu cầu tìm kiếm độ dài prompt tốt nhất cho mỗi tác vụ, điều này thiếu tính linh hoạt và không thực tế khi gặp các tác vụ downstream mới.

Một loại nghiên cứu khác là thêm một adapter (Chen et al., 2022b; Houlsby et al., 2019; Jie and Deng, 2022) cùng với khối multi-head self-attention (MHSA) hoặc MLP và xử lý toàn bộ đặc trưng một cách đồng đều mà không xem xét thông tin đặc thù cho tác vụ vào thiết kế mô-đun hiệu quả. Hơn nữa, số lượng tham số có thể huấn luyện không phải là khá nhỏ.

Bằng cách điều tra các phương pháp này, việc sử dụng thông tin đặc thù cho tác vụ trong thiết kế mô-đun hiệu quả vẫn chưa được khám phá đầy đủ như được nhấn mạnh trong một nghiên cứu gần đây (Luo et al., 2022) rằng bias kênh tồn tại trong các tác vụ downstream đa dạng. Trong bài báo này, để giải quyết vấn đề PEFT, chúng tôi đề xuất một baseline đơn giản để liên quan đến thông tin đặc thù cho tác vụ bằng cách chuyển tiếp mô hình đã được huấn luyện trước với các hình ảnh downstream. Hơn nữa, chúng tôi tiến hành chọn một phần nhỏ các kênh để đạt được tinh chỉnh hiệu quả, giảm đáng kể chi phí tham số. Các thí nghiệm của chúng tôi trong Mục 4.2 xác nhận lại rằng việc chỉnh chỉ chỉ một phần nhỏ các kênh đặc thù cho tác vụ là đủ cho việc thích ứng tác vụ downstream trong chế độ dữ liệu thấp. Để đạt được mục tiêu có được những kênh đặc thù cho tác vụ này, chúng tôi đề xuất một Điểm Quan Trọng Nhận Thức Lớp (CAIS) bằng cách áp dụng chuẩn L2 làm tiêu chí để đánh giá tầm quan trọng của kênh được lấy cảm hứng từ phương pháp pruning cổ điển (Han et al., 2015). Chúng tôi gọi các kênh được chọn là "kênh nổi bật" (SC) vì chúng có giá trị kích hoạt cao hơn và rất quan trọng cho hiệu suất tác vụ. Cần lưu ý rằng lựa chọn kênh có thể tránh chi phí huấn luyện bằng cách chọn cấu trúc tốt nhất như trong NOAH(Zhang et al., 2022) hoặc độ dài prompt tốt nhất như trong VPT(Jia et al., 2022). Hơn nữa, so với các phương pháp dựa trên adapter (Houlsby et al., 2019; Chen et al., 2022b), việc chọn các kênh đặc thù cho tác vụ một phần cho phép chúng tôi đạt được chi phí tham số thấp hơn bằng cách loại bỏ các phép toán "giảm mẫu" và "phi tuyến" như được hiển thị trong Hình 2.

Tóm lại, các đóng góp được tóm tắt như sau:
Đóng góp
–Chúng tôi đề xuất một baseline đơn giản với góc nhìn mới trong việc chỉnh chỉ kênh một phần (tức là, chỉnh chỉ kênh nổi bật) cho việc giải quyết tác vụ PEFT để tận dụng thông tin đặc thù cho tác vụ, đạt được hiệu suất đầy hứa hẹn trên 19 tác vụ học chuyển giao thị giác, 4 tác vụ khái quát hóa miền, và 5 tác vụ học few-shot. Các thí nghiệm chứng minh rằng việc chỉnh chỉ một tập con kênh trong bản đồ đặc trưng là hiệu quả và tổng quát.
–Theo hiểu biết của chúng tôi, đây là lần đầu tiên giảm chi phí tham số xuống mức 0.11M (ít hơn 780 × tham số so với kích thước mô hình đầy đủ) của ViT-B trong khi đạt được hiệu suất trung bình tốt nhất so với các phương pháp khác.

--- TRANG 3 ---
Tinh Chỉnh Kênh Nổi Bật 3
[Hiển thị hình ảnh hóa bản đồ đặc trưng được trích xuất trên tập dữ liệu Caltech101 ở mỗi lớp transformer, với trục Y đại diện cho chỉ số lớp và trục X đại diện cho chỉ số kênh (tổng cộng 768 kênh), cho thấy một số kênh có giá trị kích hoạt cao hơn các kênh khác]

Hình 3: Hình ảnh hóa bản đồ đặc trưng và các chỉ số kênh nổi bật được chọn. Tất cả kết quả được thu được bằng ViT-B/16 được huấn luyện trước trên ImageNet21K.

2 Nghiên cứu liên quan
2.1 Vision Transformers
Transformer (Vaswani et al., 2017) đã chứng minh kết quả xuất sắc trong xử lý ngôn ngữ tự nhiên và các tác vụ thị giác máy tính. Rất nhiều vision transformer (Chen et al., 2021a; d'Ascoli et al., 2021; Dong et al., 2022; Ali et al., 2021; Fan et al., 2021; Han et al., 2021; Rao et al., 2021; Yuan et al., 2021; Touvron et al., 2021; Liu et al., 2021; Wang et al., 2021; Zhou et al., 2021a) được đề xuất sau công trình tiên phong ViT (Dosovit-

--- TRANG 4 ---
4 Henry Hengyuan Zhao et al.
skiy et al., 2020). Nhiều trong số chúng tăng kích thước mô hình dần dần để đạt kết quả tối tân và học các biểu diễn phong phú thông qua các thiết kế kiến trúc khác nhau. Cần lưu ý rằng hầu hết chúng được huấn luyện trên tập dữ liệu tự nhiên và có tiềm năng mạnh mẽ để được chuyển giao sang các miền/tác vụ khác. Hơn nữa, việc áp dụng các mô hình này cho các tác vụ downstream có thể giảm bớt khó khăn trong huấn luyện và đạt được kết quả đầy hứa hẹn.

2.2 Phương pháp Tinh Chỉnh Hiệu Quả Tham Số
PEFT tập trung vào việc áp dụng một mô-đun có thể huấn luyện với một số ít tham số cho tinh chỉnh. Hai hướng PEFT đã được đề xuất gần đây. Một mặt, việc áp dụng prompts (Jia et al., 2022; Liu et al., 2022; Xing et al., 2022; Zheng et al., 2022; Nie et al., 2022; Wang et al., 2022; Zhou et al., 2022a,b; Liao et al., 2023; Manli et al., 2022; Zhang et al., 2023b; Zang et al., 2022; Bar et al., 2022) vào các mạng backbone cho thấy thành công trên một số tác vụ thị giác. VPT (Jia et al., 2022) lần đầu tiên đề xuất phương pháp dựa trên prompt trong lĩnh vực thị giác máy tính bằng cách chèn prompts vào mỗi lớp transformer. Tuy nhiên, một hạn chế chính của VPT là nó dựa vào việc lựa chọn thủ công để xác định độ dài prompt tối ưu cho mỗi tác vụ. Điều này không linh hoạt khi áp dụng cho một tác vụ downstream mới. Một hạn chế khác là các prompt đặc thù cho tác vụ của VPT được thu được thông qua quy trình huấn luyện và không thể được người dùng cung cấp như trong lĩnh vực NLP. Trong nghiên cứu của chúng tôi, để giảm rõ ràng các tính toán tìm kiếm độ dài prompt đặc thù cho tác vụ, chúng tôi truyền các hình ảnh huấn luyện vào mạng backbone và tận dụng thông tin đặc thù cho tác vụ bằng cách xác định các kênh nổi bật. Quy trình này chỉ cần một lần lan truyền tiến mà không có chi phí huấn luyện.

Mặt khác, việc thêm một mô-đun dư (Houlsby et al., 2019; Chen et al., 2022b; Jie and Deng, 2022; Chen et al., 2022a) vào các mạng backbone cũng đạt được kết quả đầy hứa hẹn về hiệu suất và hiệu quả. Adapter (Houlsby et al., 2019), một baseline được sử dụng rộng rãi trong nhiều tác vụ (Sung et al., 2022; Pan et al., 2022; Zhang et al., 2023a), đề xuất một mô-đun giống MLP, một thiết kế thành công mà đầu tiên chiếu các đặc trưng có chiều gốc thành một chiều nhỏ hơn với một lớp phi tuyến và chiếu ngược lại về chiều gốc. Nó giảm đáng kể số lượng tham số. Được lấy cảm hứng từ các chiều trung gian nhỏ nhất của nó, việc tìm một số lượng nhỏ các kênh nổi bật trong bản đồ đặc trưng có thể đủ cho việc thích ứng. Không giống như việc chèn các mô-đun có thể huấn luyện vào các khối transformer, LoRA (Hu et al., 2021) tối ưu hóa một ma trận phân rã thứ hạng thấp với một chiều nội tại thấp để chiếu các đặc trưng query, key. Đối với NOAH (Zhang et al., 2022), một thuật toán tìm kiếm kiến trúc mạng thần kinh kết hợp Adapter, LoRA, và VPT vào không gian tìm kiếm mạng của nó. NOAH cung cấp một baseline mạnh mẽ để thực hiện tốt một cách nhất quán trên các tập dữ liệu khác nhau. SSF (Lian et al., 2022), một baseline mạnh mẽ được đề xuất gần đây chỉ bằng cách chia tỷ lệ và dịch chuyển các đặc trưng để thực hiện tinh chỉnh mô hình hiệu quả. Child-Tuning Xu et al. (2021) cập nhật một tập con tham số của các mô hình ngôn ngữ lớn đã được huấn luyện trước thông qua việc che mặt nạ chiến lược gradient của mạng không phải child trong quá trình lan truyền ngược. AdaptFormer Chen et al. (2022b) là một phương pháp giống adapter. Nó khám phá hiệu quả của kiến trúc giống adapter của tinh chỉnh vision transformer.

Không giống như các phương pháp trên, SCT của chúng tôi xử lý PEFT bằng cách tận dụng thông tin đặc thù cho tác vụ vào thiết kế phương pháp và sau đó đề xuất Tinh Chỉnh Kênh Nổi Bật, đạt được chi phí tham số thấp hơn và hiệu suất cao hơn so với các phương pháp trước đó.

3 Phương pháp
3.1 Không phải tất cả các kênh đều bình đẳng
Để tận dụng thông tin đặc thù cho tác vụ, bài báo này nhằm tìm các kênh đặc thù cho tác vụ để tinh chỉnh. Ở đây chúng tôi cung cấp một quan sát đơn giản nhấn mạnh "Kênh Nổi Bật" tồn tại trong các tác vụ downstream.

Các nghiên cứu trước đây (Luo et al., 2017; Li et al., 2016; He et al., 2018; Liu et al., 2018; Han et al., 2015; Li et al., 2017) chứng minh rằng việc cắt tỉa một số kênh của mạng thần kinh sâu có ảnh hưởng nhỏ đến hiệu suất mô hình nhưng có thể giảm đáng kể số lượng tham số và chi phí tính toán. Những kết quả như vậy phản ánh rằng tầm quan trọng của các kênh khác nhau không giống nhau, tức là, "Không phải tất cả các kênh đều bình đẳng". Một cách trực quan, tầm quan trọng của kênh khác nhau về mặt tác vụ, điều này thúc đẩy chúng tôi điều tra tác động của việc lựa chọn kênh trong tinh chỉnh mô hình.

Để tìm các kênh đặc thù cho tác vụ, một cách trực quan là tìm một số kênh chung trên các danh mục khác nhau. Do đó, chúng tôi đầu tiên minh họa một quan sát giữa mô hình đã được huấn luyện trước và tác vụ downstream. Chúng tôi chọn Caltech101 (Fei-Fei et al., 2004) (một trong các tác vụ downstream từ benchmark VTAB-1K) làm ví dụ để đánh giá các đặc trưng trung gian của mỗi lớp transformer của ViT. ViT-B được huấn luyện trước trên ImageNet21K là backbone, và chúng tôi đưa toàn bộ tập dữ liệu để trích xuất các đặc trưng giữa các khối multi-head self-attention ("Attn") và "MLP" trong tất cả 12 lớp transformer. Hình 3 (a) cho thấy một số đường thẳng đứng trong mỗi hình con của các lớp transformer. Nó chỉ ra rằng khi sử dụng mô hình đã được huấn luyện trước để trích xuất các đặc trưng trên tập dữ liệu mục tiêu,

--- TRANG 5 ---
Tinh Chỉnh Kênh Nổi Bật 5
Điểm 
Quan trọngTuyến tính
BNDTop K
BN
Đặc trưng đầu vàoĐặc trưng được biến đổiĐặc trưng nổi bậtThay thế Tỷ lệ
Đặc trưng đầu vào Đặc trưng đầu raĐặc trưng trung gianSCTMTrong quá trình Tinh chỉnh
Hình 4: Tổng quan về mô-đun tinh chỉnh kênh nổi bật được đề xuất.

một số kênh có giá trị kích hoạt cao hơn các kênh khác, bất kể danh mục. Chúng tôi gọi những kênh này là "kênh nổi bật". Để điều tra vị trí của các kênh nổi bật, chúng tôi cũng báo cáo chỉ số của 36 kênh nổi bật hàng đầu được chọn sau khi tính điểm quan trọng của mỗi lớp trong Hình 3 (b). Số đại diện cho chỉ số kênh trong tổng số 768 kênh. Màu tối hơn đại diện cho giá trị kích hoạt cao hơn. Chúng ta có thể thấy các lớp khác nhau có tập hợp kênh nổi bật khác nhau. Khi lớp đi sâu hơn, các kênh nổi bật xuất hiện tập trung hơn. Chúng tôi giả thuyết rằng các lớp sâu hơn chứa thông tin trừu tượng hơn và thông tin được tập hợp trong một vài kênh. Ngược lại, các lớp nông trích xuất biểu diễn cấp thấp hơn, làm cho thông tin dày đặc.

Điều này tự nhiên đặt ra một câu hỏi: Liệu chúng ta có thể tìm các kênh nổi bật trong bản đồ đặc trưng và sau đó chỉ chỉnh chỉ những kênh nổi bật này để tinh chỉnh hiệu quả?
Để trả lời câu hỏi này, chúng tôi thiết kế một điểm quan trọng nhận thức lớp đơn giản để xác định các kênh nổi bật này và tận dụng một mô-đun tinh chỉnh kênh nổi bật cho tinh chỉnh hiệu quả.

3.2 Điểm Quan Trọng Nhận Thức Lớp
Việc lựa chọn các kênh nổi bật là quan trọng cho việc thích ứng với các tác vụ downstream, điều này nên chứa thông tin chung trong tất cả các lớp. Một cách trực quan, chúng ta có thể trực tiếp sử dụng đặc trưng trung bình của tất cả các mẫu dữ liệu để đại diện cho phân phối tác vụ downstream để xác định các kênh nổi bật. Tuy nhiên, xem xét các tập dữ liệu downstream có thể không luôn cân bằng, việc coi toàn bộ tập dữ liệu như một đơn vị có thể thiên vị đối với các lớp đầu, dẫn đến các kênh được chọn không đại diện cho thông tin chung trên tất cả các lớp. Do đó, chúng tôi đề xuất Điểm Quan Trọng Nhận Thức Lớp (CAIS), trong đó việc tính toán điểm quan trọng được thực hiện ở mỗi lớp và sau đó được tính trung bình trên tất cả các lớp. Giả sử các bản đồ đặc trưng trung gian là {fl_m ∈ R^(Bm×N×D)|l, m∈N,1≤l≤L và 1≤m≤M}, trong đó N và D đại diện cho số lượng token và số chiều kênh, tương ứng. L đại diện cho tổng số lớp của backbone ViT. Bm là khối lượng của mỗi lớp, và M đại diện cho số danh mục của tác vụ nhận dạng downstream. Chúng tôi đầu tiên áp dụng chuẩn hóa chuẩn L2 của mỗi chiều kênh của đặc trưng fl_m:

˜fl_m={∥fl_m,1∥2,∥fl_m,i∥2, ...,∥fl_m,D∥2},
∥fl_m,i∥2∈R, i∈N,1≤i≤D,(1)

trong đó ˜fl_m∈R^(1×D) là vector điểm quan trọng ở lớp thứ l và lớp thứ m. Để điều tra các kênh nổi bật, chúng tôi tính trung bình ˜fl_m∈R^(1×D) trên tất cả các lớp để có được điểm quan trọng ở lớp thứ l:

Zl=1/M ∑(m=1 to M) ˜fl_m, ˜fl_m∈R^(1×D), (2)

Sau khi có được vector điểm quan trọng {Zl∈R^(1×D)|l∈N,1≤l≤L}, chúng ta có thể chọn K giá trị lớn nhất của Zl và sau đó chúng ta có thể suy ra các chỉ số được chọn là Il=topK(Zl), Il∈N^(1×K) ở lớp thứ l. Sau đó, các kênh nổi bật ở mỗi lớp khác nhau trên các tác vụ downstream khác nhau, và nó có thể liên quan rõ ràng thông tin đặc thù cho tác vụ trong tinh chỉnh mô hình. Các quy trình để chọn các kênh nổi bật được hiển thị trong Thuật toán 1.

3.3 Thích ứng ViT thông qua Tinh Chỉnh Kênh Nổi Bật
Với điểm quan trọng của việc chọn K kênh nổi bật hàng đầu, chúng tôi đề xuất một Mô-đun Tinh Chỉnh Kênh Nổi Bật (SCTM) trong bài báo này. Tổng quan về SCTM được mô tả trong Hình 4. Không giống như các phương pháp PEFT khác, SCTM của chúng tôi chỉ chứa một lớp tuyến tính thay vì một adapter giống MLP (Houlsby et al., 2019) bao gồm hai lớp có thể học được và một lớp kích hoạt được minh họa trong Hình 2.

--- TRANG 6 ---
6 Henry Hengyuan Zhao et al.
Cấu trúc đơn giản như vậy dễ tái tạo và duy trì chi phí tham số tương đối thấp. Để kế thừa các biểu diễn mạnh mẽ ban đầu, chúng tôi sử dụng một shortcut dư để kết hợp các đặc trưng nổi bật với các đặc trưng trung gian và sử dụng Scale ∈R (như được hiển thị trong Hình 4) để điều chỉnh trọng số giữa cả hai đặc trưng, đây là một tham số hằng số. Sau khi có được các đặc trưng được biến đổi, chúng tôi chèn các đặc trưng được biến đổi trở lại vào các đặc trưng đầu vào ở cùng vị trí. Các kênh không được chọn chúng tôi giữ đóng băng trong quá trình tinh chỉnh. Trong Hình 6, chúng tôi trình bày hai hình thức chèn SCTM vào ViT. "Ours-MLP" đại diện cho việc chúng tôi chèn SCTM sau khối MLP, và "Our-Attn" chỉ ra rằng chúng tôi đặt SCTM sau khối MHSA trong khi trước khối MLP. Trong các thí nghiệm sau, "Ours-Attn" là vị trí tiêm mặc định so với các baseline khác.

Tổng quan. SCT của chúng tôi đầu tiên đưa tập huấn luyện vào mạng backbone để trích xuất các đặc trưng trung gian trong các lớp khác nhau. Sau đó, sử dụng CAIS được đề xuất để xác định các kênh nổi bật và lưu các chỉ số kênh. Trong quá trình tinh chỉnh, chúng tôi thêm SCTM của chúng tôi vào mỗi lớp transformer và chỉnh chỉ các kênh được chọn với một lớp tuyến tính trong khi đóng băng các kênh không được chọn khác.

Thảo luận. Thứ nhất, các tác vụ downstream khác nhau có đặc thù riêng của chúng, tức là, "Không phải tất cả các kênh đều bình đẳng". Các phương pháp PEFT trước đây (tức là, Adapter) thiếu việc xem xét sử dụng rõ ràng thông tin đặc thù cho tác vụ. Thay vào đó, chúng tôi đề xuất SCT tận dụng rõ ràng thông tin đặc thù cho tác vụ cho việc lựa chọn kênh, điều này có thể cho phép chúng tôi tiết kiệm các tính toán và tham số bổ sung của các phép toán "Giảm mẫu" và "Phi tuyến" so với Adapter (Houlsby et al., 2019). Thứ hai, việc tính toán các kênh nổi bật offline có thể tiết kiệm các tính toán tìm kiếm độ dài prompt tốt nhất (Jia et al., 2022) hoặc cấu trúc mạng tốt nhất (Zhang et al., 2022). Thứ ba, kết quả của chúng tôi trong Hình 1 chứng minh rằng chỉ thích ứng 12.5% kênh có thể có được kết quả cạnh tranh so với các baseline khác. Đồng thời, việc biến đổi một phần nhỏ đặc trưng có thể giảm đáng kể số lượng tham số có thể học được (ví dụ, 12 × 96 × 96 tương đối nhỏ hơn 12 × 768 × 768). Thứ tư, một lượng tham số nhỏ như vậy giảm đáng kể khó khăn trong việc lưu trữ kiến thức đặc thù cho tác vụ khi chúng ta có nhiều tác vụ downstream. Để đánh giá baseline đơn giản này, chúng tôi cũng kiểm tra khả năng few-shot và khả năng khái quát hóa miền của nó để đáp ứng các yêu cầu của các ứng dụng thực tế.

Thuật toán 1 Các quy trình lựa chọn kênh thông qua điểm quan trọng nhận thức lớp.
Đầu vào:
Mô hình ViT được huấn luyện trước F và số lớp L;
Số kênh được chọn K và tổng số lớp M;
1: foreach l∈[1, L] do
2: Trích xuất đặc trưng fl_m ở mỗi lớp m;
3: Áp dụng chuẩn hóa chuẩn L2 trên mỗi kênh để có được ˜fl_m thông qua Eq. 1;
4: Tính điểm quan trọng Zl của lớp thứ l thông qua Eq. 2;
5: Chọn K kênh lớn nhất Il= topK( Zl);
6: end for
Đầu ra: Các chỉ số kênh được chọn của mỗi lớp transformer.

3.4 Kiểm tra Xóa Kênh
Để đánh giá cấu hình lựa chọn kênh, chúng tôi đưa ra hai kiểm tra đơn giản để đánh giá hiệu quả của các kênh nổi bật như trong Hình 5. Kiểm tra đầu tiên trong Hình 5 (a) chứng minh hiệu quả của các kênh nổi bật so với việc lựa chọn kênh ngẫu nhiên. Kiểm tra thứ hai trong Hình 5 (b) đánh giá tầm quan trọng của mỗi lớp. Chúng tôi xóa các kênh nổi bật từng lớp một. Các đường cong cho thấy rằng đối với tác vụ loại Tự nhiên Caltech101, bốn lớp đầu tiên quan trọng hơn bốn lớp cuối cùng vì độ chính xác giảm đáng kể khi xóa bốn lớp đầu tiên. Một xu hướng tương tự rõ ràng trong tác vụ Resisc45. Đối với tác vụ KITTI, bốn lớp cuối cùng cũng quan trọng như bốn lớp đầu.

Dựa trên các kiểm tra nêu trên, chúng tôi thao tác số lượng kênh được tinh chỉnh trong bốn lớp đầu tiên và tám lớp cuối cùng, như được nêu trong Bảng 1. Việc tăng số lượng kênh được tinh chỉnh trong bốn lớp đầu tiên (hàng thứ nhất và thứ ba) mang lại cải thiện 0.1% cho Caltech101 và 0.5% cho KITTI, mặc dù có sự giảm 0.1% trong hiệu suất Resisc45. Đáng chú ý, ảnh hưởng của bốn lớp cuối cùng đến kết quả cuối cùng là nhỏ. Do đó, chúng tôi khám phá tác động của việc giảm số lượng kênh được chỉnh trong tám lớp cuối cùng. Các kết quả (hàng thứ tư và thứ năm) được nêu chi tiết trong Bảng 1 chỉ ra rằng việc giảm K từ 96 xuống 32 dẫn đến sự suy giảm đáng kể trong hiệu suất. Tuy nhiên, một giá trị hơi cao hơn so với việc đặt K= 32 trên tất cả 12 lớp.

4 Thí nghiệm
Phần này so sánh SCT của chúng tôi với các baseline PEFT tối tân khác trên benchmark VTAB-1K, sử dụng các backbone ViT và Swin Transformer. Ngoài ra, chúng tôi phân tích chiến lược lựa chọn kênh, điểm quan trọng nhận thức lớp, vị trí chèn, độ dài chèn, và

--- TRANG 7 ---
Tinh Chỉnh Kênh Nổi Bật 7
[Biểu đồ cho thấy kết quả kiểm tra xóa kênh trên ba tập dữ liệu, so sánh việc xóa kênh ngẫu nhiên và kênh nổi bật]

Hình 5: Kiểm tra xóa kênh.

Cấu hình kênh Caltech101 Resisc45 KITTI Params
[96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96] 91.6 86.3 80.2 0.11M
[192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192, 192] 91.5 87.0 81.0 0.44M
[192, 192, 192, 192, 96, 96, 96, 96, 96, 96, 96, 96] 91.7 86.2 80.7 0.22M
[96, 96, 96, 96, 32, 32, 32, 32, 32, 32, 32, 32] 91.1 85.0 76.2 0.045M
[32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32] 90.3 84.8 74.0 0.01M
Bảng 1: Số lượng kênh được tinh chỉnh khác nhau trên ba tác vụ.

số lượng kênh được chọn để xác minh hiệu quả của SCT hơn nữa. Ngoài việc đánh giá hiệu suất trên các tác vụ học chuyển giao thị giác, chúng tôi cũng xác thực khả năng của bốn tập dữ liệu khái quát hóa miền và kiểm tra hiệu suất của SCT trong các tình huống dữ liệu thấp trên năm tập dữ liệu trong thiết lập few-shot.

4.1 Chi tiết huấn luyện
Theo VPT (Jia et al., 2022), chúng tôi sử dụng tìm kiếm lưới để tìm các siêu tham số đặc thù cho tinh chỉnh, bao gồm tốc độ học và weight decay, dựa trên tập val của mỗi tác vụ như được hiển thị trong Tab.2. Đối với siêu tham số Scale, đây là một hằng số được định nghĩa thủ công để cân bằng trọng số của đặc trưng được biến đổi và đặc trưng nổi bật, chúng tôi tìm kiếm nó trong phạm vi {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}. Trong quá trình huấn luyện, chúng tôi sử dụng chiến lược tăng cường hình ảnh tiêu chuẩn: chuẩn hóa với mean và standard deviation của ImageNet, resize crop ngẫu nhiên thành 224×224, và lật ngang ngẫu nhiên như trong VPT.

4.2 Thí nghiệm trên Benchmark VTAB-1K
Tập dữ liệu. VTAB-1K (Zhai et al., 2019) chứa 19 tác vụ phân loại thị giác bao gồm một phổ rộng các miền và ngữ nghĩa trong ba nhóm, tức là, Tự nhiên, Chuyên biệt, và Có cấu trúc. Nhóm Tự nhiên chứa 7 tập dữ liệu phân loại cổ điển của hình ảnh tự nhiên. Nhóm Chuyên biệt bao gồm 4 tập dữ liệu của hai tình huống đặc biệt: y tế và viễn thám. Nhóm Có cấu trúc có 8 tập dữ liệu, chủ yếu tập trung vào hiểu cấu trúc của một cảnh, như đếm đối tượng và dự đoán độ sâu. Mỗi tác vụ của VTAB-1K chứa 1000 hình ảnh huấn luyện. Chi tiết hơn có sẵn trong Tab.3.

--- TRANG 8 ---
8 Henry Hengyuan Zhao et al.
VTAB-1K, Khái quát hóa Miền, và Học Few-shot
Optimizer AdamW (Loshchilov and Hutter, 2017)
baselr range {0.1, 0.5, 0.01, 0.05 0.001, 0.005, 0.0001, 0.0005}
Weight decay range {0.1 0.01, 0.05, 0.001, 0.005, 0.0005, 0.0001}
Learning rate schedule cosine decay
Warm up epochs 10
Total epochs 100
Batch size 64
Bảng 2: Chi tiết huấn luyện trên mỗi tác vụ thị giác với ViT-B/16.

[Bảng 3 chứa thông số kỹ thuật của các tập dữ liệu được sử dụng trên benchmark VTAB-1K, Khái quát hóa Miền, và Học Few-shot]

Theo Zhang et al. (2022); Jia et al. (2022), chúng tôi sử dụng phân chia train-val 800-200 để xác định các siêu tham số và toàn bộ 1000 dữ liệu huấn luyện để huấn luyện mô hình cuối cùng. Chúng tôi báo cáo độ chính xác top-1 trung bình trên tập test.

Baselines. Chúng tôi so sánh phương pháp của chúng tôi với ba baseline Full fine-tuning, Linear, và Bias không có tham số bên ngoài và bốn baseline Adapter (Houlsby et al., 2019), LoRA (Hu et al., 2021), VPT (Jia et al., 2022), và NOAH (Zhang et al., 2022) có tham số bên ngoài. Phương pháp Bias chỉ cập nhật tất cả các số hạng bias trong backbone đã được huấn luyện trước. Adapter chèn một mô-đun MLP bổ sung vào mỗi lớp transformer. LoRA áp dụng một ma trận thứ hạng thấp được tối ưu hóa cho mô-đun MHSA trong các lớp transformer. VPT là một thuật toán prompt thị giác để kết hợp các prompt với token vào backbone. NOAH là một thuật toán tìm kiếm kiến trúc mạng thần kinh kết hợp Adapter, LoRA, và VPT vào tìm kiếm mạng. SSF đề xuất hai yếu tố có thể học để chia tỷ lệ và dịch chuyển các đặc trưng khi tinh chỉnh các tác vụ downstream. AdaptFormer đề xuất một kiến trúc giống adapter cho các tác vụ thị giác. Chúng tôi trực tiếp sử dụng kết quả đã phát hành của họ hoặc chạy mã của họ để tạo ra chúng nhằm cung cấp một so sánh công bằng.

--- TRANG 9 ---
Tinh Chỉnh Kênh Nổi Bật 9
LayerNormMHSALayerNormMLPSCTM
(a) Ours-MLPLayerNormMHSALayerNormMLP
(b) Ours-AttnSCTM
Hình 6: Hai loại cấu trúc khi chèn SCTM vào backbone. Chỉ SCTM có thể huấn luyện được, và các mô-đun khác được đóng băng.

Hiệu suất với backbone ViT. Chúng tôi so sánh SCT của chúng tôi với 7 baseline trên trong Tab. 4 và Hình 7. Chúng tôi sử dụng ViT-B/16 làm backbone và chèn SCTM vào mỗi lớp transformer. K mặc định được đặt là 96, 1/8 tổng số kênh, dẫn đến số lượng tham số có thể huấn luyện chỉ là 0.11M. Thứ nhất, SCT của chúng tôi đạt được độ chính xác trung bình 73.6% trên 19 tập dữ liệu, vượt trội so với tinh chỉnh đầy đủ (85.8M) trên 18 trong số 19 tập dữ liệu và đạt được cải thiện 6.3%, 2.5%, và 12.3% trong ba nhóm, tương ứng, với chỉ 0.13% tham số backbone bổ sung. Những kết quả như vậy phản ánh rằng SCT có thể giảm đáng kể không gian lưu trữ và giảm bớt vấn đề overfitting phổ biến trong tinh chỉnh các mô hình lớn. Thứ hai, so với Adapter (0.16M) (Houlsby et al., 2019) xử lý tất cả các kênh một cách đồng đều, việc chọn một phần kênh nổi bật cho mỗi tác vụ downstream hiệu quả và hiệu suất hơn, vượt trội hơn 2.3% về độ chính xác trung bình. Thứ ba, so với các phương pháp PEFT khác, SCT của chúng tôi vượt qua NOAH (0.43M) (Zhang et al., 2022) 0.3% với chỉ một phần tư tham số có thể huấn luyện của nó. Khi tăng K lên 192 với 0.44M tham số bổ sung, SCT của chúng tôi vượt qua NOAH (0.43) 0.7% độ chính xác trung bình. Hơn nữa, SCT của chúng tôi vượt trội so với VPT (Jia et al., 2022) 3.8%, 3.5%, và 4.9% trong ba nhóm, tương ứng. Những kết quả này chứng minh rằng thay vì các cấu trúc được thiết kế đặc biệt cho mỗi tập dữ liệu downstream, việc tận dụng rõ ràng thông tin đặc thù cho tác vụ có thể giảm chi phí tính toán trong tìm kiếm mô hình và cải thiện hiệu suất. Hơn nữa, so với baseline SSF (0.20M) (Lian et al., 2022), một phương pháp không có mô-đun có thể huấn luyện bổ sung, SCT của chúng tôi chỉ cần gần một nửa tham số của nó và đạt được cải thiện trung bình 1.0% trên 19 tác vụ downstream.

Hiệu suất với Backbone Swin Transformer. Để xác minh hiệu quả của SCT với các backbone khác nhau, chúng tôi áp dụng SCT trên các transformer phân cấp, tức là, Swin-B. Chúng tôi sử dụng cùng thiết lập chèn SCTM như trong backbone ViT: chèn SCTM sau khối "Attn" trong lớp transformer. Xem xét các lớp sâu chứa thông tin ngữ nghĩa hơn trong cấu trúc phân cấp, thay vì áp dụng SCTM trên tất cả các lớp transformer, chúng tôi chèn nó vào nửa cuối của các lớp trong stage 3 và tất cả các lớp của stage 4 của Swin-B để giữ mức tham số có thể huấn luyện tương tự. Kết quả của Tab. 5 cho thấy SCT vượt trội so với tinh chỉnh đầy đủ trong tất cả 19 tác vụ downstream với chỉ 0.12% tham số trong khi các phương pháp khác không thể. Ngoài ra, so với phương pháp PEFT, SCT vượt trội so với VPT (Jia et al., 2022) 5.9%, 3.0%, và 7.2% trong ba nhóm, tương ứng. Tất cả các kết quả trên cho thấy SCT của chúng tôi cũng áp dụng cho các transformer phân cấp và có thể mang lại cải thiện nhiều hơn so với các phương pháp PEFT khác.

4.3 Đánh giá
Hiệu quả của Tinh Chỉnh Kênh Nổi Bật. Chúng tôi so sánh ba chiến lược lựa chọn kênh để xác minh hiệu quả của việc chọn các kênh nổi bật trong Tab. 6. Các chiến lược lựa chọn bao gồm Lựa chọn Kênh Nổi Bật (SC), Lựa chọn Kênh Không Nổi Bật (IC), và Lựa chọn Kênh Ngẫu Nhiên (RC). IC chọn các kênh với K giá trị thấp nhất của chuẩn L2, và RC biểu thị việc chọn K kênh ngẫu nhiên. Chúng tôi chọn ngẫu nhiên ba tập kênh (RC-1/2/3) cho việc lựa chọn kênh ngẫu nhiên để giảm bớt các ngoại lệ. Như được hiển thị trong Tab. 6, SC đạt được kết quả tốt nhất và vượt trội so với IC 2.4% về độ chính xác trung bình. Lựa chọn kênh ngẫu nhiên có thể có được kết quả tốt hơn tinh chỉnh đầy đủ, nhưng tất cả chúng đều hoạt động kém hơn SC. Thú vị là, ngay cả IC cũng có thể hoạt động tốt hơn tinh chỉnh đầy đủ, chứng minh rằng việc chọn một tập con nhỏ các kênh có thể ngăn mô hình lớn khỏi overfitting vào tập huấn luyện nhỏ.

Hiệu quả của Tính toán Nhận thức Lớp cho điểm quan trọng. Trong Mục 3.2, chúng tôi giới thiệu phương pháp của chúng tôi, xem xét tác động của các lớp riêng lẻ thay vì coi toàn bộ tập dữ liệu như một tổng thể khi ước tính điểm quan trọng (IS). Cách tiếp cận này

--- TRANG 10 ---
10 Henry Hengyuan Zhao et al.
[Bảng 4: So sánh với các phương pháp tối tân trên benchmark VTAB-1K với ViT-B/16, hiển thị kết quả chi tiết cho từng tác vụ và các chỉ số hiệu suất]

[Hình 7: Kết quả trung bình theo nhóm trên benchmark VTAB-1K]

nhằm xác định các kênh quan trọng nhất dựa trên thông tin chung giữa các danh mục và giảm tác động của dữ liệu không cân bằng. Kết quả thí nghiệm của chúng tôi, được trình bày trong Tab. 7, chứng minh rằng việc áp dụng phương pháp tính toán nhận thức lớp cải thiện hiệu suất trên tất cả ba nhóm.

Vị trí Chèn. Như được hiển thị trong Hình 6, SCTM có thể được chèn sau khối MLP (SCT MLP) hoặc giữa khối MHSA và khối MLP (SCT Attn). Để điều tra ảnh hưởng của vị trí chèn, chúng tôi so sánh hai hình thức trên benchmark VTAB-1K trong Tab. 8. Cả hai đều đạt được hiệu suất đầy hứa hẹn, và SCT Attn vượt trội so với SCT MLP trên hai trong ba nhóm. Chúng tôi đoán rằng sau khi thu thập các phụ thuộc tầm xa với MHSA, các kênh nổi bật của đặc trưng có tính đại diện hơn, có thể được thích ứng tốt hơn với các tác vụ downstream. Chúng tôi cũng đánh giá hiệu suất của việc chèn SCTM sau cả khối MHSA và MLP, như được hiển thị trong Tab. 10. Việc chèn chung SCT Attn và SCT MLP chỉ mang lại cải thiện nhỏ trong khi số lượng tham số tăng gấp đôi.

Số độ sâu chèn. Độ sâu chèn là một yếu tố quan trọng có thể ảnh hưởng đáng kể đến hiệu suất của mô hình. Để điều tra điều này, chúng tôi đã thực hiện các thí nghiệm bằng cách chèn SCTM vào l lớp cuối cùng của ViT-B và đánh giá hiệu suất trên ba tác vụ đại diện từ mỗi nhóm của VTAB-1K. Phát hiện của chúng tôi, được trình bày trong Hình 9, cho thấy việc tăng độ sâu chèn dẫn đến cải thiện dần dần trong hiệu suất. Đối với các tác vụ Resisc45 và DMLab, chúng tôi quan sát thấy hiệu suất cạnh tranh đã đạt được khi SCTM được chèn vào sáu lớp cuối cùng. Việc tăng thêm độ sâu chèn dẫn đến sự ổn định trong

--- TRANG 11 ---
Tinh Chỉnh Kênh Nổi Bật 11
[Bảng 5: Kết quả từng tác vụ trên benchmark VTAB-1K với Swin-B đã được huấn luyện trước]

[Bảng 6-9: Các bảng so sánh hiệu suất với các cấu hình và phương pháp khác nhau]

hiệu suất, chỉ ra rằng các lớp bổ sung không đóng góp đáng kể vào hiệu suất cuối cùng.

Số lượng kênh được chọn K. Siêu tham số quan trọng nhất của SCTM là số lượng kênh được chọn K, ảnh hưởng đến kiến trúc mô hình và số lượng tham số có thể huấn luyện. Lưu ý rằng khác với các nghiên cứu trước đây (Jia et al., 2022; Zhang et al., 2022) chọn siêu tham số cho mỗi tập dữ liệu, chúng tôi sử dụng cùng K cho tất cả các tập dữ liệu. Như được hiển thị trong Tab.9, SCT K=32 đánh bại tinh chỉnh đầy đủ và tinh chỉnh bias lần lượt 3.5% và 7.0%. Hơn nữa, SCT K=32 chỉ áp dụng 0.01M tham số trong khi tinh chỉnh số hạng bias áp dụng 0.10M. Như được hiển thị trong Hình 8, hiệu suất thường cải thiện cùng với sự gia tăng của K. Tuy nhiên, cải thiện của K= 192 so với K= 96 là không đáng kể, trong khi số lượng tham số lớn gấp bốn lần. Xem xét cả hiệu quả và hiệu suất, chúng tôi đặt K thành 96 theo mặc định.

--- TRANG 12 ---
12 Henry Hengyuan Zhao et al.
[Bảng các so sánh hiệu suất và phân tích tính toán]

4.4 Phân tích Tính toán
Phân tích của chúng tôi xem xét một backbone ViT-B với L lớp và D chiều và N token cho một hình ảnh duy nhất. Chúng tôi cũng giả sử rằng chiều trung gian của Adapter (Houlsby et al., 2019) là D′, độ dài prompt của VPT (Jia et al., 2022) là n, và tổng số lần chèn của SSF (Lian et al., 2022) là m. Cuối cùng, chúng tôi so sánh phương pháp SCT được đề xuất của chúng tôi với Adapter, VPT, và SSF về tham số và FLOPs, như được tóm tắt trong Tab. 12. Đáng chú ý, việc chọn K của chúng tôi là 1/8 D khá nhỏ so với D. Khi tỷ lệ giảm của Adapter cũng được định nghĩa là 8, các tham số của Adapter là 1/4 LD² trong khi tham số của chúng tôi là 1/64 LD². Khi chúng tôi so sánh phương pháp của chúng tôi với SSF, chèn mô-đun của nó m lần trong backbone ViT-B, số lượng tham số cho SSF là mLD. Kiểm tra backbone ViT-B, chúng tôi thấy rằng m= 74 và 1/64 D= 12, tham số của chúng tôi (12 LD < 74LD) và FLOPs (12NLD < 74NLD) nhỏ hơn SSF. Nhìn chung, phân tích của chúng tôi cho thấy SCT có thể cung cấp cho PEFT một baseline hiệu quả và hiệu suất hơn.

Để đánh giá hiệu quả tính toán của phương pháp SCT của chúng tôi, chúng tôi chọn so sánh nó với Adapter (0.16M) và SSF (0.20M) vì chúng có mức tham số tương tự và tất cả chúng đều được áp dụng trong mạng backbone. Chúng tôi đo thời gian chạy và sử dụng bộ nhớ cho cả giai đoạn huấn luyện và kiểm tra sử dụng kích thước batch là 64 trên tập dữ liệu Cifar100 (VTAB-1K) với backbone ViT-B. Chúng tôi đã thực hiện các thí nghiệm huấn luyện trên một GPU NVIDIA V100-32GB duy nhất và các thí nghiệm kiểm tra trên một GPU NVIDIA A100-40GB duy nhất. Vì việc sử dụng bộ nhớ GPU trong giai đoạn huấn luyện và kiểm tra là khác nhau. Trong giai đoạn huấn luyện, các kích hoạt tensor, tham số mô hình, gradient, và trạng thái optimizer (mô hình, gradient, momentum) là các nguồn chính. Trong giai đoạn kiểm tra, các kích hoạt tensor và tham số mô hình là các nguồn chính. Kết quả của chúng tôi, như được hiển thị trong Hình 10, chỉ ra rằng phương pháp SCT của chúng tôi vượt trội so với Adapter và SSF về thời gian huấn luyện và sử dụng bộ nhớ. Vì các tham số có thể chỉnh của chúng tôi nhỏ hơn Adapter và SSF, chi phí gradient và trạng thái optimizer nhỏ giúp chúng tôi tiết kiệm bộ nhớ GPU trong quá trình huấn luyện. Cụ thể

--- TRANG 13 ---
Tinh Chỉnh Kênh Nổi Bật 13
[Biểu đồ hiển thị việc chọn các giá trị K khác nhau trên 19 tác vụ downstream và kết quả chèn SCTM vào các lớp khác nhau]

thể, phương pháp của chúng tôi chỉ yêu cầu 12 tính toán SCT bổ sung, trong khi SSF yêu cầu 74 phép toán chia tỷ lệ và dịch chuyển. Việc huấn luyện SSF không khá hiệu quả so với SCT của chúng tôi. Tuy nhiên, trong quá trình kiểm tra, thời gian kiểm tra của phương pháp chúng tôi hơi cao hơn Adapter và SSF. Lưu ý, SSF có thể hợp nhất các tham số bổ sung của nó vào backbone gốc mà không có chi phí suy luận bổ sung trong khi phương pháp của chúng tôi không tập trung vào việc giảm chi phí tính toán trong quá trình suy luận. Lý do cho chi phí kiểm tra cao hơn so với Adapter có thể là các phép toán bổ sung của việc truy vấn các kênh nổi bật từ một đặc trưng đầy đủ và sau đó đưa các kênh nổi bật được chiếu trở lại. Hơn nữa, chúng tôi đưa ra kết quả chi phí thời gian kiểm tra chính xác trong Tab. 11. Ở đây LoRA và SSF có thể hợp nhất tham số của nó vào mạng backbone do đó chúng tôi chọn Fine-tuning đầy đủ làm đại diện.

4.5 Thí nghiệm về Khái quát hóa Miền
Tập dữ liệu. Ngoài việc đánh giá mô hình trên dữ liệu kiểm tra của cùng phân phối, các mạng thần kinh sâu hiện đại thường gặp phải sự suy giảm hiệu suất khi phân phối kiểm tra khác với phân phối

--- TRANG 14 ---
14 Henry Hengyuan Zhao et al.
Phương pháp Thời gian kiểm tra Bộ nhớ Tham số
Tinh chỉnh đầy đủ 5.78 ms 336 MB 85.8 M
Adapter-8 6.87 ms 337 MB 85.8+0.16 M
AdaptFormer-8 7.88 ms 337 MB 85.8+0.18 M
SCT (Của chúng tôi) 8.43 ms 337 MB 85.8+0.11 M
Bảng 11: Chúng tôi đánh giá thời gian kiểm tra cho 1 hình ảnh với độ phân giải 224. Chúng tôi chạy 200 lần và tạo ra kết quả trung bình.

Adapter VPT-Deep SSF TTC-Module
# Tham số Bổ sung 2LDD′ nLD mLD LKK
# FLOPs Bổ sung 2NLDD′ 2n(2N+n)LD mNLD NLKK
Bảng 12: Phân tích độ phức tạp của Adapter (Houlsby et al., 2019), VPT (Jia et al., 2022), SSF (Lian et al., 2022), và TTC-Module được đề xuất của chúng tôi.

của tập huấn luyện, tức là, dịch chuyển miền, điều này không thể tránh khỏi trong ứng dụng thực tế. Để giảm bớt vấn đề này, khái quát hóa miền (Zhou et al., 2021b; Zhao et al., 2022; Zhou et al., 2022c; Yang et al., 2022a,b, 2021) được điều tra trong cộng đồng, nhằm huấn luyện một mô hình với một hoặc nhiều miền nguồn có thể hoạt động tốt trên các miền mục tiêu chưa thấy khác. Để xác minh khả năng khái quát hóa của SCT của chúng tôi, chúng tôi theo Zhang et al. (2022) để thực hiện các thí nghiệm trên ImageNet và các biến thể của nó. Cụ thể, chúng tôi sử dụng ImageNet-1K (Deng et al., 2009) làm miền nguồn với 16-shot trên mỗi danh mục và đánh giá mô hình của chúng tôi trên ImageNetV2 (Recht et al., 2019), ImageNet-Sketch (Wang et al., 2019), ImageNet-A (Hendrycks et al., 2021b), và ImageNet-R (Hendrycks et al., 2021a). ImageNetV2 (Recht et al., 2019) được thu thập từ các nguồn khác nhau từ ImageNet-1K với cùng giao thức, và ImageNet-Sketch (Wang et al., 2019) chứa các hình ảnh phác thảo của các lớp ImageNet. Cả hai đều sử dụng các lớp giống như ImageNet-1K. ImageNet-A (Hendrycks et al., 2021b) và ImageNet-R (Hendrycks et al., 2021a) chứa các hình ảnh được lọc đối nghịch và các thể hiện của dữ liệu ImageNet của một tập con 200 lớp, tương ứng. Chúng tôi sử dụng phiên bản lớn của SCT, tức là, SCT-B, chứa tham số tương đương với NOAH (0.44M so với 0.43M).

Kết quả. Trong Tab. 13, chúng tôi so sánh SCT-B của chúng tôi với Adapter (Houlsby et al., 2019), VPT (Jia et al., 2022), LoRA (Hu et al., 2021), và NOAH (Zhang et al., 2022) trên các tập dữ liệu trên để xác minh khả năng khái quát hóa. Chúng ta có thể thực hiện hai quan sát. Thứ nhất, SCT-B vượt trội so với phương pháp tốt nhất trước đây (NOAH) trên ba trong số bốn tập dữ liệu mục tiêu và đạt được hiệu suất tương đương trên ImageNetV2. Cụ thể, SCT-B mang lại cải thiện 2.5% trên ImageNet-R so với NOAH. Thứ hai, SCT-B của chúng tôi đạt được độ chính xác 77.1% trên miền nguồn, vượt trội đáng kể so với các phương pháp trước đây 6%. Vì mô hình backbone được huấn luyện trước trên ImageNet-21K, kết quả trên ImageNet-1K cho thấy SCT có thể tăng cường tốt hơn việc chuyển giao kiến thức từ tập con đến tập cha. Hai quan sát chứng minh sự ưu việt của SCT của chúng tôi so với các kỹ thuật tinh chỉnh trước đây về khả năng khái quát hóa mạnh mẽ.

4.6 Thí nghiệm về Học Few-shot
Tập dữ liệu. Theo Zhang et al. (2022), chúng tôi chọn năm tập dữ liệu nhận dạng thị giác tinh vi, bao gồm Food101 (Bossard et al., 2014), Flowers102 (Nilsback and Zisserman, 2006), StandfordCars (Krause et al., 2013), OxfordPets (Parkhi et al., 2012), và FGVCAircraft (Maji et al., 2013), để điều tra hiệu quả của SCT trong học few-shot. Các danh mục trong các tập dữ liệu này bao gồm các khái niệm thị giác khác nhau liên quan chặt chẽ đến cuộc sống hàng ngày của chúng ta: thực phẩm, thực vật, phương tiện, và động vật. Tiếp theo, chúng tôi theo các nghiên cứu hiện có (Zhang et al., 2022; Jie and Deng, 2022) để đánh giá mô hình của chúng tôi dưới các thiết lập 1, 2, 4, 8, và 16 shot. Thiết lập thí nghiệm giống như trong VTAB-1K.

Kết quả. Theo Hình 11, SCT của chúng tôi vượt qua các baseline khác trong tất cả các thiết lập về hiệu suất trung bình. Ngoài ra, SCT chủ yếu đạt được lợi thế tại các tập dữ liệu FGVCAircraft và OxfordPets. Đối với các tập dữ liệu khác, SCT đạt được hiệu suất cạnh tranh so với các baseline khác. Những kết quả như vậy chứng minh rằng SCT có khả năng khái quát hóa mạnh mẽ có thể được chuyển giao dễ dàng đến các tác vụ downstream chỉ với một vài mẫu.

5 Kết luận
Bài báo này giới thiệu một baseline đơn giản cho PEFT, vừa đơn giản vừa hiệu quả. Không giống như các phương pháp trước đây, chúng tôi áp dụng góc nhìn lựa chọn kênh và đề xuất một điểm quan trọng đơn giản để xác định các kênh đặc thù cho tác vụ. Bằng cách loại bỏ các phép toán giảm mẫu và phi tuyến, phương pháp của chúng tôi vượt trội so với phương pháp Adapter tương tự, yêu cầu ít tham số hơn. Chúng tôi đánh giá thuật toán của chúng tôi trên 19 tác vụ downstream và đạt được kết quả tốt nhất với chỉ ít hơn 780 × tham số so với backbone gốc. Chúng tôi cũng kiểm tra phương pháp của chúng tôi trên bốn tập dữ liệu với dịch chuyển phân phối tự nhiên để đánh giá khả năng khái quát hóa miền và trên năm tập dữ liệu trong tình huống few-shot để đánh giá hiệu suất trong chế độ dữ liệu thấp. Phương pháp của chúng tôi hiệu quả về mặt tính toán trong cả quá trình huấn luyện và kiểm tra. Hơn nữa, nó độc lập với các phương pháp dựa trên prompt và giống LoRa, cho phép khám phá thêm trong nghiên cứu tương lai. Mặc dù kỹ thuật lựa chọn kênh của chúng tôi đơn giản, vẫn có tiềm năng đáng kể

--- TRANG 15 ---
Tinh Chỉnh Kênh Nổi Bật 15
Nguồn Mục tiêu
ImageNet -V2 -Sketch -A -R
Adapter (Houlsby et al., 2019) 70.5 59.1 16.4 5.5 22.1
VPT (Jia et al., 2022) 70.5 58.0 18.3 4.6 23.2
LoRA (Hu et al., 2021) 70.8 59.3 20.0 6.9 23.3
NOAH (Zhang et al., 2022) 71.5 66.1 24.8 11.9 28.5
SCT-B (của chúng tôi) 77.1 65.8 28.5 12.1 31.0
Bảng 13: So sánh với các phương pháp trước đây về khái quát hóa miền. Mạng backbone là ViT-B/16. Số lượng kênh nổi bật là 192. Văn bản in đậm đại diện cho hiệu suất tốt nhất.

[Hình 10: Chi phí tính toán của các giai đoạn huấn luyện và kiểm tra]

[Hình 11: Kết quả học few-shot trên năm tập dữ liệu nhận dạng thị giác tinh vi]

để nâng cao hiệu suất của nó. Baseline của chúng tôi có thể đặc biệt hữu ích trong các tình huống hạn chế tài nguyên vì nó yêu cầu ít tham số bổ sung hơn và cho phép thích ứng nhanh chóng với các tác vụ mới chỉ với một vài mẫu, làm cho các mô-đun đơn giản và nhỏ trở thành các đơn vị lưu trữ kiến thức hiệu quả.

--- TRANG 16 ---
16 Henry Hengyuan Zhao et al.
Lời cảm ơn
Nghiên cứu này được hỗ trợ bởi Quỹ Nghiên cứu Quốc gia, Singapore và A*STAR, dưới chương trình RIE2020 Industry Alignment Fund – Industry Collaboration Projects (IAF-ICP) (Số hiệu Grant I2001E0059) – SIA-NUS Digital Aviation Corp Lab. Mike Zheng Shou được hỗ trợ bởi Quỹ Nghiên cứu Quốc gia, Singapore, dưới Giải thưởng NRFF NRF-NRFF13-2021-0008, và Start-Up Grant của Mike Zheng Shou từ NUS.

Tài liệu tham khảo
[Danh sách tài liệu tham khảo đầy đủ từ trang 16-19 với các trích dẫn học thuật về vision transformers, parameter-efficient fine-tuning, và các phương pháp liên quan]

# 2308.10462.pdf
# Chuyá»ƒn Ä‘á»•i tá»« PDF sang TXT
# ÄÆ°á»ng dáº«n nguá»“n: /home/admin88/arxiv-downloader/peft/2308.10462.pdf
# KÃ­ch thÆ°á»›c tá»‡p: 1063509 bytes

===============================================
Ná»˜I DUNG Tá»†P PDF
===============================================


--- TRANG 1 ---
KhÃ¡m phÃ¡ cÃ¡c Ká»¹ thuáº­t Tinh chá»‰nh Hiá»‡u quáº£ Tham sá»‘ cho
Sinh mÃ£ vá»›i MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n
MARTIN WEYSSOWâˆ—,DIRO, Äáº¡i há»c Montreal, Canada
XIN ZHOU, Äáº¡i há»c Quáº£n lÃ½ Singapore, Singapore
KISUB KIM, Äáº¡i há»c Quáº£n lÃ½ Singapore, Singapore
DAVID LO, Äáº¡i há»c Quáº£n lÃ½ Singapore, Singapore
HOUARI SAHRAOUI, DIRO, Äáº¡i há»c Montreal, Canada
CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) thá»ƒ hiá»‡n kháº£ nÄƒng áº¥n tÆ°á»£ng trong viá»‡c sinh ra cÃ¡c Ä‘oáº¡n mÃ£ chÃ­nh xÃ¡c khi Ä‘Æ°á»£c Ä‘Æ°a ra Ã½ Ä‘á»‹nh báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn theo cÃ¡ch zero-shot, tá»©c lÃ  khÃ´ng cáº§n tinh chá»‰nh cá»¥ thá»ƒ. Trong khi cÃ¡c nghiÃªn cá»©u trÆ°á»›c Ä‘Ã£ nháº¥n máº¡nh nhá»¯ng Æ°u Ä‘iá»ƒm cá»§a viá»‡c tinh chá»‰nh LLM, quÃ¡ trÃ¬nh nÃ y phÃ¡t sinh chi phÃ­ tÃ­nh toÃ¡n cao, lÃ m cho nÃ³ khÃ´ng thá»±c táº¿ trong mÃ´i trÆ°á»ng khan hiáº¿m tÃ i nguyÃªn, Ä‘áº·c biá»‡t Ä‘á»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh cÃ³ hÃ ng tá»· tham sá»‘. Äá»ƒ giáº£i quyáº¿t nhá»¯ng thÃ¡ch thá»©c nÃ y, nghiÃªn cá»©u trÆ°á»›c Ä‘Ã£ khÃ¡m phÃ¡ há»c trong ngá»¯ cáº£nh (ICL) vÃ  sinh tÄƒng cÆ°á»ng truy xuáº¥t (RAG) nhÆ° cÃ¡c chiáº¿n lÆ°á»£c Ä‘á»ƒ hÆ°á»›ng dáº«n quÃ¡ trÃ¬nh sinh cá»§a LLM vá»›i cÃ¡c vÃ­ dá»¥ prompt cá»¥ thá»ƒ cho tÃ¡c vá»¥. Tuy nhiÃªn, ICL vÃ  RAG gÃ¢y ra nhá»¯ng báº¥t tiá»‡n, cháº³ng háº¡n nhÆ° nhu cáº§u thiáº¿t káº¿ cÃ¡c prompt cÃ³ liÃªn quan theo ngá»¯ cáº£nh vÃ  viá»‡c thiáº¿u há»c cÃ¡c tham sá»‘ cá»¥ thá»ƒ cho tÃ¡c vá»¥, do Ä‘Ã³ háº¡n cháº¿ hiá»‡u suáº¥t tÃ¡c vá»¥ háº¡ nguá»“n. Trong bá»‘i cáº£nh nÃ y, chÃºng tÃ´i dá»± kiáº¿n tinh chá»‰nh hiá»‡u quáº£ tham sá»‘ (PEFT) nhÆ° má»™t cÃ¡ch tiáº¿p cáº­n Ä‘áº§y há»©a háº¹n Ä‘á»ƒ chuyÃªn mÃ´n hÃ³a LLM hiá»‡u quáº£ cho dá»¯ liá»‡u cá»¥ thá»ƒ tÃ¡c vá»¥ trong khi duy trÃ¬ má»©c tiÃªu thá»¥ tÃ i nguyÃªn há»£p lÃ½. Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i thá»±c hiá»‡n má»™t nghiÃªn cá»©u toÃ n diá»‡n vá» cÃ¡c ká»¹ thuáº­t PEFT cho LLM trong bá»‘i cáº£nh sinh mÃ£ tá»± Ä‘á»™ng. Cuá»™c Ä‘iá»u tra toÃ n diá»‡n cá»§a chÃºng tÃ´i vá» cÃ¡c ká»¹ thuáº­t PEFT cho LLM tiáº¿t lá»™ tÃ­nh vÆ°á»£t trá»™i vÃ  tiá»m nÄƒng cá»§a chÃºng so vá»›i ICL vÃ  RAG trÃªn má»™t táº­p há»£p Ä‘a dáº¡ng cÃ¡c LLM vÃ  ba bá»™ dá»¯ liá»‡u sinh mÃ£ Python Ä‘áº¡i diá»‡n: Conala, CodeAlpacaPy, vÃ  APPS. HÆ¡n ná»¯a, nghiÃªn cá»©u cá»§a chÃºng tÃ´i lÃ m ná»•i báº­t tiá»m nÄƒng cho viá»‡c tinh chá»‰nh cÃ¡c LLM lá»›n hÆ¡n vÃ  giáº£m Ä‘Ã¡ng ká»ƒ viá»‡c sá»­ dá»¥ng bá»™ nhá»› báº±ng cÃ¡ch káº¿t há»£p PEFT vá»›i lÆ°á»£ng tá»­ hÃ³a. Do Ä‘Ã³, nghiÃªn cá»©u nÃ y má»Ÿ ra cÆ¡ há»™i cho cÃ¡c á»©ng dá»¥ng rá»™ng hÆ¡n cá»§a PEFT trong cÃ¡c tÃ¬nh huá»‘ng ká»¹ thuáº­t pháº§n má»m.
KhÃ¡i niá»‡m CCS: â€¢Pháº§n má»m vÃ  ká»¹ thuáº­t cá»§a nÃ³ â†’Táº¡o vÃ  quáº£n lÃ½ pháº§n má»m; Ká»¹ thuáº­t phÃ¡t triá»ƒn pháº§n má»m.
Tá»« khÃ³a vÃ  Cá»¥m tá»« bá»• sung: sinh mÃ£, mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n, tinh chá»‰nh hiá»‡u quáº£ tham sá»‘, lÆ°á»£ng tá»­ hÃ³a, nghiÃªn cá»©u thá»±c nghiá»‡m
âˆ—TÃ¡c giáº£ liÃªn há»‡.
Äá»‹a chá»‰ tÃ¡c giáº£: Martin Weyssow, martin.weyssow@umontreal.ca, DIRO, Äáº¡i há»c Montreal, Canada; Xin Zhou, xinzhou.2020@phdcs.smu.edu.sg, Äáº¡i há»c Quáº£n lÃ½ Singapore, Singapore; Kisub Kim, falconlk00@gmail.com, Äáº¡i há»c Quáº£n lÃ½ Singapore, Singapore; David Lo, davidlo@smu.edu.sg, Äáº¡i há»c Quáº£n lÃ½ Singapore, Singapore; Houari Sahraoui, sahraouh@iro.umontreal.ca, DIRO, Äáº¡i há»c Montreal, Canada.
Quyá»n táº¡o báº£n sao ká»¹ thuáº­t sá»‘ hoáº·c báº£n cá»©ng cá»§a toÃ n bá»™ hoáº·c má»™t pháº§n cÃ´ng trÃ¬nh nÃ y Ä‘á»ƒ sá»­ dá»¥ng cÃ¡ nhÃ¢n hoáº·c trong lá»›p há»c Ä‘Æ°á»£c cáº¥p miá»…n phÃ­ vá»›i Ä‘iá»u kiá»‡n cÃ¡c báº£n sao khÃ´ng Ä‘Æ°á»£c táº¡o ra hoáº·c phÃ¢n phá»‘i vÃ¬ lá»£i nhuáº­n hoáº·c lá»£i Ã­ch thÆ°Æ¡ng máº¡i vÃ  cÃ¡c báº£n sao mang thÃ´ng bÃ¡o nÃ y vÃ  trÃ­ch dáº«n Ä‘áº§y Ä‘á»§ trÃªn trang Ä‘áº§u tiÃªn. Báº£n quyá»n cho cÃ¡c thÃ nh pháº§n cá»§a cÃ´ng trÃ¬nh nÃ y thuá»™c sá»Ÿ há»¯u cá»§a ngÆ°á»i khÃ¡c ngoÃ i (cÃ¡c) tÃ¡c giáº£ pháº£i Ä‘Æ°á»£c tÃ´n trá»ng. Viá»‡c tÃ³m táº¯t cÃ³ ghi nguá»“n Ä‘Æ°á»£c phÃ©p. Äá»ƒ sao chÃ©p khÃ¡c, hoáº·c tÃ¡i xuáº¥t báº£n, Ä‘Äƒng trÃªn mÃ¡y chá»§ hoáº·c phÃ¢n phá»‘i láº¡i cho danh sÃ¡ch, yÃªu cáº§u quyá»n cá»¥ thá»ƒ trÆ°á»›c vÃ /hoáº·c phÃ­. YÃªu cáº§u quyá»n tá»« permissions@acm.org.
Â©2024 Báº£n quyá»n thuá»™c vá» chá»§ sá»Ÿ há»¯u/tÃ¡c giáº£. Quyá»n xuáº¥t báº£n Ä‘Æ°á»£c cáº¥p phÃ©p cho ACM.
ACM XXXX-XXXX/2024/12-ART
https://doi.org/10.1145/nnnnnnn.nnnnnnn
, Táº­p 1, Sá»‘ 1, BÃ i viáº¿t . NgÃ y xuáº¥t báº£n: ThÃ¡ng 12 2024.arXiv:2308.10462v3 [cs.SE] 27 ThÃ¡ng 12 2024

--- TRANG 2 ---
2â€¢M. Weyssow vÃ  cá»™ng sá»±.
Äá»‹nh dáº¡ng Tham kháº£o ACM:
Martin Weyssow, Xin Zhou, Kisub Kim, David Lo, vÃ  Houari Sahraoui. 2024. KhÃ¡m phÃ¡ cÃ¡c Ká»¹ thuáº­t Tinh chá»‰nh Hiá»‡u quáº£ Tham sá»‘ cho Sinh mÃ£ vá»›i MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n. 1, 1 (ThÃ¡ng 12 2024), 27 trang. https://doi.org/10.1145/nnnnnnn.nnnnnnn

1 GIá»šI THIá»†U
CÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n (LLM) dá»±a trÃªn kiáº¿n trÃºc Transformer [67], thá»ƒ hiá»‡n tiá»m nÄƒng Ä‘Ã¡ng ká»ƒ trong cÃ¡c lÄ©nh vá»±c Ä‘a dáº¡ng, bao gá»“m xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP) [29,44,76], thá»‹ giÃ¡c mÃ¡y tÃ­nh [7,59,85], vÃ  ká»¹ thuáº­t pháº§n má»m [9,66,82]. Nhá»¯ng mÃ´ hÃ¬nh nÃ y xuáº¥t sáº¯c trong viá»‡c sinh ná»™i dung cháº¥t lÆ°á»£ng cao khi Ä‘Æ°á»£c Ä‘Æ°a ra Ã½ Ä‘á»‹nh báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn theo cÃ¡ch zero-shot, tá»©c lÃ  khÃ´ng cáº§n tinh chá»‰nh. Kháº£ nÄƒng nÃ y Ä‘Ã£ khÆ¡i dáº­y sá»± quan tÃ¢m Ä‘Ã¡ng ká»ƒ trong lÄ©nh vá»±c ká»¹ thuáº­t pháº§n má»m Ä‘á»ƒ tá»± Ä‘á»™ng hÃ³a cÃ¡c tÃ¡c vá»¥ liÃªn quan Ä‘áº¿n mÃ£ nhÆ° sá»­a chá»¯a chÆ°Æ¡ng trÃ¬nh [27, 80, 81] vÃ  sinh mÃ£ [3, 9, 48].

Trong khi kháº£ nÄƒng zero-shot cá»§a LLM ráº¥t áº¥n tÆ°á»£ng, tiá»m nÄƒng Ä‘áº§y Ä‘á»§ cá»§a chÃºng thÆ°á»ng xuáº¥t hiá»‡n thÃ´ng qua tinh chá»‰nh [54,75]. Cá»¥ thá»ƒ, tinh chá»‰nh má»™t LLM vá»›i dá»¯ liá»‡u cá»¥ thá»ƒ tÃ¡c vá»¥ cho phÃ©p nÃ³ há»c vÃ  mÃ£ hÃ³a kiáº¿n thá»©c cá»§a dá»¯ liá»‡u cÃ³ thá»ƒ cÃ³ ngá»¯ cáº£nh cao táº¡i tay vÃ  do Ä‘Ã³ sinh ná»™i dung cÃ³ Ã½ nghÄ©a hÆ¡n. Tuy nhiÃªn, quÃ¡ trÃ¬nh nÃ y Ä‘i kÃ¨m vá»›i chi phÃ­ tÃ­nh toÃ¡n Ä‘Ã¡ng ká»ƒ. Tinh chá»‰nh Ä‘áº§y Ä‘á»§, nÆ¡i táº¥t cáº£ cÃ¡c tham sá»‘ cá»§a LLM Ä‘Æ°á»£c cáº­p nháº­t trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, Ä‘Ã²i há»i tÃ i nguyÃªn tÃ­nh toÃ¡n Ä‘Ã¡ng ká»ƒ, Ä‘áº·c biá»‡t khi LLM chá»©a hÃ ng tá»· tham sá»‘ [62]. Äá»ƒ giáº£m thiá»ƒu gÃ¡nh náº·ng tÃ­nh toÃ¡n nÃ y, cÃ¡c nghiÃªn cá»©u trÆ°á»›c trong ká»¹ thuáº­t pháº§n má»m [53,80,91] Ä‘Ã£ Ä‘iá»u tra cÃ¡c ká»¹ thuáº­t thiáº¿t káº¿ prompt nhÆ° Há»c trong Ngá»¯ cáº£nh (ICL) [5,54] vÃ  Sinh TÄƒng cÆ°á»ng Truy xuáº¥t (RAG) [31]. ICL bao gá»“m viá»‡c cung cáº¥p cÃ¡c vÃ­ dá»¥ prompt cá»§a tÃ¡c vá»¥ cho LLM, hÆ°á»›ng dáº«n nÃ³ sinh ná»™i dung phÃ¹ há»£p theo ngá»¯ cáº£nh mÃ  khÃ´ng cÃ³ báº¥t ká»³ tinh chá»‰nh nÃ o liÃªn quan. Nhá»¯ng vÃ­ dá»¥ nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c táº¡o thá»§ cÃ´ng hoáº·c chá»n ngáº«u nhiÃªn tá»« má»™t bá»™ dá»¯ liá»‡u huáº¥n luyá»‡n cÃ³ liÃªn quan. Ká»¹ thuáº­t nÃ y Ä‘Ã£ cho tháº¥y káº¿t quáº£ Ä‘áº§y há»©a háº¹n cho cÃ¡c tÃ¡c vá»¥ liÃªn quan Ä‘áº¿n mÃ£, bao gá»“m sá»­a chá»¯a chÆ°Æ¡ng trÃ¬nh tá»± Ä‘á»™ng [80], sá»­a lá»—i [53], vÃ  sinh mÃ£ [61,73,91].

Má»Ÿ rá»™ng ICL, RAG cung cáº¥p má»™t lá»±a chá»n thay tháº¿ máº¡nh máº½ vÃ  máº¡nh hÆ¡n káº¿t há»£p há»‡ thá»‘ng truy xuáº¥t kiáº¿n thá»©c táº¡i thá»i Ä‘iá»ƒm suy luáº­n. Sá»­ dá»¥ng RAG, má»™t mÃ´ hÃ¬nh truy xuáº¥t láº¥y thÃ´ng tin cÃ³ liÃªn quan tá»« má»™t kho tÃ i liá»‡u Ä‘Æ°á»£c láº­p chá»‰ má»¥c, cháº³ng háº¡n nhÆ° tÃ i liá»‡u mÃ£ hoáº·c cÃ¡c Ä‘oáº¡n mÃ£ tÆ°Æ¡ng tá»± vá»›i váº¥n Ä‘á» Ä‘áº§u vÃ o. ThÃ´ng tin Ä‘Æ°á»£c truy xuáº¥t sau Ä‘Ã³ Ä‘Æ°á»£c thÃªm vÃ o prompt Ä‘áº§u vÃ o Ä‘á»ƒ hÆ°á»›ng dáº«n sinh. KhÃ´ng giá»‘ng nhÆ° ICL, dá»±a vÃ o cÃ¡c vÃ­ dá»¥ Ä‘Æ°á»£c chá»n trÆ°á»›c cÃ³ thá»ƒ khÃ´ng pháº£i lÃºc nÃ o cÅ©ng Ä‘Æ°á»£c Ä‘iá»u chá»‰nh cho Ä‘áº§u vÃ o cá»¥ thá»ƒ, RAG thÃ­ch á»©ng Ä‘á»™ng vá»›i tá»«ng váº¥n Ä‘á» Ä‘áº§u vÃ o riÃªng láº», cung cáº¥p ngá»¯ cáº£nh cÃ³ liÃªn quan hÆ¡n. Ká»¹ thuáº­t nÃ y Ä‘Ã£ chá»©ng minh nhá»¯ng cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ trong cÃ¡c tÃ¡c vá»¥ ká»¹ thuáº­t pháº§n má»m nhÆ° sinh mÃ£ vÃ  tÃ³m táº¯t [39,52,91], hoÃ n thiá»‡n mÃ£ [41], vÃ  sá»­a chá»¯a chÆ°Æ¡ng trÃ¬nh [70].

Máº·c dÃ¹ ICL vÃ  RAG cung cáº¥p má»™t lá»±a chá»n thay tháº¿ kháº£ thi cho tinh chá»‰nh Ä‘áº§y Ä‘á»§, nÃ³ hoáº¡t Ä‘á»™ng táº¡i thá»i Ä‘iá»ƒm suy luáº­n vÃ  khÃ´ng liÃªn quan Ä‘áº¿n viá»‡c há»c cÃ¡c tham sá»‘ cá»¥ thá»ƒ tÃ¡c vá»¥, Ä‘iá»u nÃ y cÃ³ thá»ƒ ngÄƒn LLM náº¯m báº¯t thÃ´ng tin chi tiáº¿t vá» tÃ¡c vá»¥ vÃ  dáº«n Ä‘áº¿n máº¥t hiá»‡u quáº£. Trong bá»‘i cáº£nh nÃ y, cÃ¡c ká»¹ thuáº­t Tinh chá»‰nh Hiá»‡u quáº£ Tham sá»‘ (PEFT) Ä‘Ã£ ná»•i lÃªn nhÆ° nhá»¯ng giáº£i phÃ¡p Ä‘áº§y há»©a háº¹n Ä‘á»ƒ giáº£m chi phÃ­ tinh chá»‰nh xuá»‘ng má»©c tháº¥p nháº¥t trong khi cho phÃ©p mÃ´ hÃ¬nh há»c cÃ¡c tham sá»‘ cá»¥ thá»ƒ tÃ¡c vá»¥. CÃ¡c cÃ´ng trÃ¬nh trÆ°á»›c [10,57,68,69] trong trÃ­ tuá»‡ mÃ£ Ä‘Ã£ chá»©ng minh kháº£ nÄƒng cá»§a cÃ¡c ká»¹ thuáº­t PEFT, vÃ  thÆ°á»ng cho tháº¥y tÃ­nh vÆ°á»£t trá»™i cá»§a chÃºng so vá»›i tinh chá»‰nh Ä‘áº§y Ä‘á»§ trÃªn má»™t loáº¡t rá»™ng cÃ¡c tÃ¡c vá»¥. Tuy nhiÃªn, nhá»¯ng nghiÃªn cá»©u nÃ y táº­p trung vÃ o cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhá» (SLM) (<0.25B tham sá»‘) nhÆ° CodeBERT [16] vÃ  CodeT5 [72] vÃ  bá» qua kháº£ nÄƒng Ã¡p dá»¥ng cá»§a cÃ¡c ká»¹ thuáº­t PEFT cho LLM (â‰¥1B tham sá»‘), Ä‘á»ƒ láº¡i má»™t khoáº£ng trá»‘ng nghiÃªn cá»©u quan trá»ng. Vá»›i sá»± phá»• biáº¿n ngÃ y cÃ ng tÄƒng cá»§a LLM, chÃºng tÃ´i tin ráº±ng viá»‡c giáº£i quyáº¿t khoáº£ng trá»‘ng nÃ y lÃ  tá»‘i quan trá»ng trong viá»‡c thÃºc Ä‘áº©y lÄ©nh vá»±c trÃ­ tuá»‡ mÃ£ vÃ  khai thÃ¡c toÃ n bá»™ tiá»m nÄƒng cá»§a LLM. HÆ¡n ná»¯a, chÃºng tÃ´i xÃ¡c Ä‘á»‹nh má»™t cÆ¡ há»™i nghiÃªn cá»©u bá»• sung trong viá»‡c khÃ¡m phÃ¡ viá»‡c sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t PEFT dÆ°á»›i cÃ¡c tÃ¬nh huá»‘ng tÃ i nguyÃªn háº¡n cháº¿, nháº±m chá»©ng minh viá»‡c dÃ¢n chá»§ hÃ³a tinh chá»‰nh LLM thÃ´ng qua PEFT. Viá»‡c giáº£i quyáº¿t nhá»¯ng khoáº£ng trá»‘ng nÃ y sáº½ khÃ´ng chá»‰ cho tháº¥y cÃ¡ch cÃ¡c ká»¹ thuáº­t PEFT cÃ³ thá»ƒ tÄƒng cÆ°á»ng hiá»‡u quáº£ cá»§a LLM mÃ  cÃ²n cÃ¡ch chÃºng má»Ÿ rá»™ng kháº£ nÄƒng tiáº¿p cáº­n vÃ  tiá»‡n Ã­ch cá»§a LLM trong cÃ¡c cÃ i Ä‘áº·t tÃ­nh toÃ¡n khan hiáº¿m vÃ  giáº£m bá»›t sá»± phá»¥ thuá»™c cá»§a cÃ¡c nhÃ  thá»±c hÃ nh vÃ o cÆ¡ sá»Ÿ háº¡ táº§ng tÃ­nh toÃ¡n lá»›n.

Trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i trÃ¬nh bÃ y má»™t nghiÃªn cá»©u thá»±c nghiá»‡m vá» viá»‡c sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t PEFT hiá»‡n cÃ³ vá»›i LLM. ChÃºng tÃ´i táº­p trung nghiÃªn cá»©u vÃ o sinh mÃ£, Ä‘Ã£ lÃ  má»™t lÄ©nh vá»±c nghiÃªn cá»©u then chá»‘t do tÃ¡c Ä‘á»™ng biáº¿n Ä‘á»•i cá»§a nÃ³ Ä‘á»‘i vá»›i viá»‡c tá»± Ä‘á»™ng hÃ³a phÃ¡t triá»ƒn pháº§n má»m [9,48,50]. Má»¥c tiÃªu cá»§a chÃºng tÃ´i cÃ³ hai máº·t. Thá»© nháº¥t, chÃºng tÃ´i nháº±m Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng sinh mÃ£ cá»§a LLM sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t PEFT hiá»‡n cÃ³ nhÆ° LoRA [24] vÃ  QLoRA [13] trÃªn cÃ¡c bá»™ dá»¯ liá»‡u khÃ´ng cÃ³ test case, bao gá»“m Conala [91] vÃ  CodeAlpacaPy [8], cÅ©ng nhÆ° bá»™ dá»¯ liá»‡u APPS [22] cÃ³ test case. Thá»© hai, chÃºng tÃ´i tÃ¬m cÃ¡ch so sÃ¡nh hiá»‡u quáº£ cá»§a LLM Ä‘Æ°á»£c tinh chá»‰nh vá»›i cÃ¡c ká»¹ thuáº­t PEFT nÃ y vá»›i SLM, ICL, vÃ  RAG. NgoÃ i ra, chÃºng tÃ´i tiáº¿n hÃ nh nghiÃªn cá»©u so sÃ¡nh vá»›i tÃ­nh kháº£ dá»¥ng háº¡n cháº¿ cá»§a tÃ i nguyÃªn tÃ­nh toÃ¡n Ä‘á»ƒ Ä‘iá»u tra tÃ­nh thá»±c tiá»…n rá»™ng cá»§a viá»‡c sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t PEFT cho LLM. Äá»ƒ Ä‘áº¡t Ä‘Æ°á»£c nhá»¯ng má»¥c tiÃªu nÃ y, chÃºng tÃ´i xÃ¢y dá»±ng bá»‘n cÃ¢u há»i nghiÃªn cá»©u hÆ°á»›ng dáº«n nghiÃªn cá»©u cá»§a chÃºng tÃ´i:

â€“ RQ1: LLM vÃ  SLM hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o khi sá»­ dá»¥ng ICL trÃªn cÃ¡c bá»™ dá»¯ liá»‡u Conala vÃ  CodeAlpacaPy?
â€“RQ2: LLM vÃ  SLM hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o khi sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t PEFT trÃªn cÃ¡c bá»™ dá»¯ liá»‡u Conala vÃ  CodeAlpacaPy?
â€“ RQ3: LoRA so sÃ¡nh nhÆ° tháº¿ nÃ o vá»›i ICL vÃ  RAG trÃªn cÃ¡c bá»™ dá»¯ liá»‡u Conala vÃ  CodeAlpacaPy?
â€“RQ4: ChÃºng ta cÃ³ thá»ƒ tÄƒng cÆ°á»ng hiá»‡u quáº£ cá»§a LLM cho sinh mÃ£ trong bá»™ dá»¯ liá»‡u APPS báº±ng LoRA vÃ  QLoRA khÃ´ng?

Tá»•ng thá»ƒ, viá»‡c tráº£ lá»i bá»‘n cÃ¢u há»i nghiÃªn cá»©u nÃ y hoÃ n thÃ nh cáº£ hai má»¥c tiÃªu cá»§a nghiÃªn cá»©u thá»±c nghiá»‡m nÃ y. Ba RQ Ä‘áº§u tiÃªn cá»§a chÃºng tÃ´i táº­p trung vÃ o Ä‘Ã¡nh giÃ¡ SLM vÃ  LLM cho sinh mÃ£ trÃªn cÃ¡c bá»™ dá»¯ liá»‡u Conala vÃ  CodeAlpaca. Trong RQ1, chÃºng tÃ´i minh há»a hiá»‡u quáº£ cÆ¡ báº£n cá»§a SLM vÃ  LLM sá»­ dá»¥ng ICL, truy xuáº¥t cÃ¡c vÃ­ dá»¥ ngáº«u nhiÃªn tá»« táº­p huáº¥n luyá»‡n Ä‘á»ƒ hÆ°á»›ng dáº«n mÃ´ hÃ¬nh sinh mÃ£. Báº±ng cÃ¡ch giáº£i quyáº¿t RQ2, chÃºng tÃ´i cÃ³ Ä‘Æ°á»£c hiá»ƒu biáº¿t toÃ n diá»‡n vá» má»©c Ä‘á»™ hiá»‡u quáº£ cá»§a SLM vÃ  LLM khi sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t PEFT khÃ¡c nhau. Trong RQ3, chÃºng tÃ´i tiáº¿n hÃ nh má»™t nghiÃªn cá»©u so sÃ¡nh vá» hiá»‡u quáº£ cá»§a LoRA vá»›i ICL vÃ  RAG, má»™t Ä‘Æ°á»ng cÆ¡ sá»Ÿ máº¡nh truy xuáº¥t Ä‘á»™ng cÃ¡c vÃ­ dá»¥ cÃ³ liÃªn quan báº±ng cÃ¡ch chá»n nhá»¯ng vÃ­ dá»¥ gáº§n nháº¥t vá»›i hÆ°á»›ng dáº«n kiá»ƒm tra tá»« táº­p huáº¥n luyá»‡n. Cuá»‘i cÃ¹ng, Ä‘á»ƒ thá»ƒ hiá»‡n tÃ¡c Ä‘á»™ng rá»™ng hÆ¡n tiá»m nÄƒng cá»§a PEFT, chÃºng tÃ´i nghiÃªn cá»©u trong RQ4 liá»‡u viá»‡c tinh chá»‰nh LLM sá»­ dá»¥ng LoRA vÃ  QLoRA cÃ³ thá»ƒ cáº£i thiá»‡n hiá»‡u quáº£ cá»§a chÃºng trÃªn APPS, má»™t Ä‘iá»ƒm chuáº©n thÃ¡ch thá»©c vá»›i test case.

Äá»ƒ giáº£i quyáº¿t nhá»¯ng RQ nÃ y, chÃºng tÃ´i tiáº¿n hÃ nh thÃ­ nghiá»‡m trÃªn ba bá»™ dá»¯ liá»‡u, APPS [22], Conala [86], vÃ  CodeAlpacaPy Ä‘Æ°á»£c tuyá»ƒn chá»n cá»¥ thá»ƒ tá»« CodeAlpaca [8] cho sinh mÃ£ Python. NgÆ°á»£c láº¡i vá»›i cÃ¡c bá»™ dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡ nhÆ° HumanEval [9], cÃ¡c bá»™ dá»¯ liá»‡u APPS, Conala vÃ  CodeAlpaca, Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trong cÃ¡c nghiÃªn cá»©u sinh mÃ£ trÆ°á»›c [49,71,73,73,88,91], bao gá»“m Ä‘á»§ vÃ­ dá»¥ huáº¥n luyá»‡n cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cho tinh chá»‰nh. Äá»ƒ phÃ¢n tÃ­ch so sÃ¡nh toÃ n diá»‡n, chÃºng tÃ´i chá»n bá»‘n há» mÃ´ hÃ¬nh khÃ¡c biá»‡t: CodeT5+ [71], CodeGen [48], CodeGen2 [47], vÃ  CodeLlama [56], bao gá»“m tÃ¡m biáº¿n thá»ƒ lá»›n vÃ  ba biáº¿n thá»ƒ nhá». LÆ°u Ã½ ráº±ng chÃºng tÃ´i bá» qua cÃ¡c LLM nguá»“n Ä‘Ã³ng nhÆ° Codex do khÃ´ng thá»ƒ truy cáº­p cÃ¡c tham sá»‘ cá»§a chÃºng, Ä‘iá»u nÃ y lÃ m cho viá»‡c nghiÃªn cá»©u báº¥t ká»³ ká»¹ thuáº­t tinh chá»‰nh nÃ o trá»Ÿ nÃªn khÃ´ng kháº£ thi. HÆ¡n ná»¯a, nghiÃªn cá»©u cá»§a chÃºng tÃ´i káº¿t há»£p sÃ¡u ká»¹ thuáº­t PEFT: LoRA [24], IA3 [37], Prompt tuning [30], vÃ  Prefix tuning [33]. NgoÃ i ra, chÃºng tÃ´i khÃ¡m phÃ¡ QLoRA [13] vá»›i lÆ°á»£ng tá»­ hÃ³a 8-bit vÃ  4-bit, káº¿t há»£p LoRA vÃ  lÆ°á»£ng tá»­ hÃ³a mÃ´ hÃ¬nh. KhÃ´ng giá»‘ng nhÆ° ICL vÃ  RAG, nhá»¯ng ká»¹ thuáº­t nÃ y Ä‘Ã²i há»i viá»‡c há»c cÃ¡c tham sá»‘ má»›i Ä‘á»ƒ tinh chá»‰nh LLM cho tÃ¡c vá»¥ háº¡ nguá»“n cá»¥ thá»ƒ. Nhá»¯ng phÃ¡t hiá»‡n chÃ­nh cá»§a chÃºng tÃ´i lÃ  nhÆ° sau:

â€“ICL cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ hiá»‡u quáº£ cá»§a táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh so vá»›i prompt zero-shot cho sinh mÃ£ trÃªn Conala vÃ  CodeAlpacaPy.
â€“TÄƒng sá»‘ lÆ°á»£ng vÃ­ dá»¥ ICL khÃ´ng pháº£i lÃºc nÃ o cÅ©ng dáº«n Ä‘áº¿n cáº£i thiá»‡n hiá»‡u quáº£. CÃ¡c mÃ´ hÃ¬nh Ä‘áº¡t hiá»‡u quáº£ Ä‘á»‰nh vá»›i tÃ¡m vÃ  bá»‘n vÃ­ dá»¥ cho Conala vÃ  CodeAlpacaPy, tÆ°Æ¡ng á»©ng.
â€“LLM Ä‘Æ°á»£c tinh chá»‰nh vá»›i LoRA, IA3, vÃ  Prompt tuning, tá»©c lÃ  vÃ i triá»‡u tham sá»‘, liÃªn tá»¥c vÆ°á»£t trá»™i SLM Ä‘Æ°á»£c tinh chá»‰nh Ä‘áº§y Ä‘á»§ vá»›i hÃ ng trÄƒm triá»‡u tham sá»‘.
â€“ Trong sá»‘ cÃ¡c ká»¹ thuáº­t PEFT, LoRA Ä‘áº¡t hiá»‡u quáº£ cao nháº¥t cho LLM vÃ  SLM.
â€“QLoRA giáº£m Ä‘Ã¡ng ká»ƒ viá»‡c sá»­ dá»¥ng bá»™ nhá»›, Ä‘áº¡t Ä‘Æ°á»£c sá»± giáº£m lÃªn Ä‘áº¿n 2 láº§n so vá»›i LoRA trong khi cáº£i thiá»‡n hoáº·c báº£o toÃ n hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh. HÆ¡n ná»¯a, QLoRA cho phÃ©p tinh chá»‰nh LLM lÃªn Ä‘áº¿n 34B tham sá»‘ vá»›i Ã­t hÆ¡n 24GB bá»™ nhá»› GPU.
â€“LoRA tÄƒng cÆ°á»ng Ä‘Ã¡ng ká»ƒ hiá»‡u suáº¥t cá»§a táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh so vá»›i ICL vÃ  RAG cho sinh mÃ£ trÃªn Conala vÃ  CodeAlpacaPy.
â€“ LoRA vÃ  QLoRA cáº£i thiá»‡n hiá»‡u quáº£ cá»§a CodeLlama-7B-Instruct cho sinh mÃ£ trÃªn bá»™ dá»¯ liá»‡u APPS.

NghiÃªn cá»©u cá»§a chÃºng tÃ´i lÃ m sÃ¡ng tá» nhá»¯ng cÆ¡ há»™i Ä‘áº§y há»©a háº¹n mÃ  cÃ¡c ká»¹ thuáº­t PEFT náº¯m giá»¯, Ä‘áº£m báº£o khÃ¡m phÃ¡ sÃ¢u hÆ¡n cho á»©ng dá»¥ng cá»§a chÃºng trong cÃ¡c tÃ¡c vá»¥ vÃ  tÃ¬nh huá»‘ng liÃªn quan Ä‘áº¿n mÃ£ khÃ¡c.

Äá»ƒ tÃ³m táº¯t, Ä‘Ã³ng gÃ³p cá»§a chÃºng tÃ´i nhÆ° sau:
â€“ChÃºng tÃ´i tiáº¿n hÃ nh má»™t nghiÃªn cá»©u thá»±c nghiá»‡m toÃ n diá»‡n vá» sÃ¡u ká»¹ thuáº­t PEFT, tá»©c lÃ  LoRA, IA3, Prompt tuning, Prefix tuning, QLoRA-8bit, vÃ  QLoRA-4bit, cho sinh mÃ£ Python trÃªn má»™t pháº¡m vi rá»™ng SLM vÃ  LLM.
â€“Má»™t so sÃ¡nh vÃ  phÃ¢n tÃ­ch toÃ n diá»‡n vá» cÃ¡c ká»¹ thuáº­t PEFT Ä‘á»‘i vá»›i ICL vÃ  RAG cho LLM trÃªn sinh mÃ£.
â€“ChÃºng tÃ´i chá»©ng minh tÃ­nh thá»±c tiá»…n cá»§a viá»‡c táº­n dá»¥ng cÃ¡c ká»¹ thuáº­t PEFT Ä‘á»ƒ tinh chá»‰nh hiá»‡u quáº£ LLM cá»§a mÃ£ vÃ  giáº£m gÃ¡nh náº·ng tÃ­nh toÃ¡n liÃªn quan Ä‘áº¿n tinh chá»‰nh Ä‘áº§y Ä‘á»§, thá»ƒ hiá»‡n cÃ¡c á»©ng dá»¥ng rá»™ng hÆ¡n tiá»m nÄƒng cá»§a chÃºng trong ká»¹ thuáº­t pháº§n má»m.

2 KIáº¾N THá»¨C Ná»€N
2.1 Há»c trong Ngá»¯ cáº£nh (ICL) vÃ  Sinh TÄƒng cÆ°á»ng Truy xuáº¥t (RAG)
NhÆ° má»™t trong nhá»¯ng loáº¡i ká»¹ thuáº­t cá»¥ thá»ƒ liÃªn quan Ä‘áº¿n LLM, ICL Ä‘Ã£ ná»•i lÃªn nhÆ° má»™t ká»¹ thuáº­t hiá»‡u quáº£ [5, 11,35,45,51]. ICL tÃ¬m cÃ¡ch cáº£i thiá»‡n kháº£ nÄƒng cá»§a LLM báº±ng cÃ¡ch tÃ­ch há»£p thÃ´ng tin cá»¥ thá»ƒ ngá»¯ cáº£nh, dÆ°á»›i dáº¡ng prompt Ä‘áº§u vÃ o hoáº·c máº«u hÆ°á»›ng dáº«n, trong quÃ¡ trÃ¬nh suy luáº­n vÃ  do Ä‘Ã³ khÃ´ng cáº§n thá»±c hiá»‡n huáº¥n luyá»‡n dá»±a trÃªn gradient. Do Ä‘Ã³, báº±ng cÃ¡ch xem xÃ©t ngá»¯ cáº£nh, mÃ´ hÃ¬nh trá»Ÿ nÃªn cÃ³ kháº£ nÄƒng sinh ra cÃ¡c Ä‘áº§u ra máº¡ch láº¡c vÃ  cÃ³ liÃªn quan theo ngá»¯ cáº£nh hÆ¡n. TÃ­nh máº¡ch láº¡c ngá»¯ cáº£nh nÃ y cá»§a LLM vÃ  khÃ´ng pháº£i thá»±c hiá»‡n huáº¥n luyá»‡n dá»±a trÃªn gradient tá»‘n kÃ©m táº¡o thÃ nh nhá»¯ng Æ°u Ä‘iá»ƒm chÃ­nh cá»§a viá»‡c sá»­ dá»¥ng ICL Ä‘á»ƒ chuyÃªn mÃ´n hÃ³a LLM cho má»™t tÃ¡c vá»¥ hoáº·c bá»™ dá»¯ liá»‡u cá»¥ thá»ƒ. Tuy nhiÃªn, ICL cÅ©ng gÃ¢y ra má»™t sá»‘ báº¥t tiá»‡n, bao gá»“m nhu cáº§u thiáº¿t káº¿ cÃ¡c prompt Ä‘áº¡i diá»‡n [37, 74, 90].

RAG lÃ  má»™t cÃ¡ch tiáº¿p cáº­n tinh vi hÆ¡n Ä‘á»ƒ tiÃªm cÃ¡c vÃ­ dá»¥ vÃ o prompt Ä‘áº§u vÃ o táº¡i thá»i Ä‘iá»ƒm suy luáº­n. KhÃ´ng giá»‘ng nhÆ° ICL chá»n cÃ¡c vÃ­ dá»¥ ngáº«u nhiÃªn, RAG dá»±a vÃ o má»™t mÃ´ hÃ¬nh truy xuáº¥t truy xuáº¥t Ä‘á»™ng cÃ¡c vÃ­ dá»¥ tá»« má»™t bá»™ dá»¯ liá»‡u gáº§n vá»›i má»™t truy váº¥n. Trong thá»±c táº¿, truy váº¥n cÃ³ thá»ƒ Ä‘Æ°á»£c hÃ¬nh thÃ nh báº±ng cÃ¡ch sá»­ dá»¥ng thÃ´ng tin tá»« vÃ­ dá»¥ kiá»ƒm tra táº¡i thá»i Ä‘iá»ƒm kiá»ƒm tra, cháº³ng háº¡n nhÆ° váº¥n Ä‘á» láº­p trÃ¬nh cho trÆ°á»ng há»£p sinh mÃ£. Tá»•ng thá»ƒ, RAG cho phÃ©p tiÃªm thÃ´ng tin cÃ³ liÃªn quan hÆ¡n trong prompt Ä‘áº§u vÃ o so vá»›i ICL vÃ  Ä‘Ã£ Ä‘Æ°á»£c Ã¡p dá»¥ng thÃ nh cÃ´ng cho cÃ¡c tÃ¡c vá»¥ ká»¹ thuáº­t pháº§n má»m, nhÆ° sinh mÃ£ [52,91], tÃ³m táº¯t mÃ£ [39,52], vÃ  hoÃ n thiá»‡n mÃ£ [41]. Tuy nhiÃªn, cáº£ ICL vÃ  RAG Ä‘á»u gáº·p pháº£i má»™t sá»‘ háº¡n cháº¿. Má»™t háº¡n cháº¿ liÃªn quan Ä‘áº¿n viá»‡c giá»›i thiá»‡u thÃªm token Ä‘áº§u vÃ o trong prompt, Ä‘iá»u nÃ y cÃ³ thá»ƒ khÃ´ng kháº£ thi khi thÃ´ng tin ngá»¯ cáº£nh quÃ¡ lá»›n. Má»™t háº¡n cháº¿ khÃ¡c lÃ  sá»± phá»¥ thuá»™c vÃ o cháº¥t lÆ°á»£ng vÃ  sá»± liÃªn quan cá»§a cÃ¡c vÃ­ dá»¥ Ä‘Æ°á»£c truy xuáº¥t. Trong RAG, mÃ´ hÃ¬nh truy xuáº¥t pháº£i tÃ¬m chÃ­nh xÃ¡c cÃ¡c vÃ­ dá»¥ thá»±c sá»± tÆ°Æ¡ng tá»± hoáº·c há»¯u Ã­ch cho truy váº¥n kiá»ƒm tra. Náº¿u cÆ¡ cháº¿ truy xuáº¥t khÃ´ng thá»ƒ xÃ¡c Ä‘á»‹nh cÃ¡c vÃ­ dá»¥ phÃ¹ há»£p, nÃ³ cÃ³ thá»ƒ tiÃªm thÃ´ng tin khÃ´ng liÃªn quan hoáº·c gÃ¢y hiá»ƒu láº§m vÃ o prompt, cuá»‘i cÃ¹ng lÃ m giáº£m hiá»‡u suáº¥t.

2.2 Tinh chá»‰nh Hiá»‡u quáº£ Tham sá»‘ (PEFT)
PEFT Ä‘á» cáº­p Ä‘áº¿n viá»‡c sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t tá»‘i Æ°u hÃ³a quÃ¡ trÃ¬nh tinh chá»‰nh LLM báº±ng cÃ¡ch cáº­p nháº­t cÃ³ chá»n lá»c má»™t táº­p con tham sá»‘ thay vÃ¬ cáº­p nháº­t toÃ n bá»™ tham sá»‘ cá»§a mÃ´ hÃ¬nh [14]. Vá» máº·t ká»¹ thuáº­t, cÃ¡c ká»¹ thuáº­t PEFT táº­p trung vÃ o viá»‡c há»c má»™t sá»‘ lÆ°á»£ng nhá» tham sá»‘ cho tÃ¡c vá»¥ hiá»‡n táº¡i báº±ng cÃ¡ch thiáº¿t káº¿ cÃ¡c lá»›p bá»• sung [23], thÃªm cÃ¡c token bá»• sung Ä‘áº§u tiÃªn [30,33], phÃ¢n tÃ¡ch gradient trá»ng sá»‘ thÃ nh cÃ¡c ma tráº­n cá»¥ thá»ƒ [24]. Má»™t trong nhá»¯ng ká»¹ thuáº­t PEFT tiÃªn tiáº¿n Ä‘áº¡i diá»‡n lÃ  ThÃ­ch á»©ng Thá»© háº¡ng Tháº¥p cá»§a LLM (LoRA) [24]. Ká»¹ thuáº­t nÃ y bao gá»“m viá»‡c Ä‘Ã³ng bÄƒng trá»ng sá»‘ mÃ´ hÃ¬nh vÃ  tiÃªm cÃ¡c ma tráº­n cÃ³ thá»ƒ huáº¥n luyá»‡n thá»© háº¡ng tháº¥p vÃ o cÃ¡c lá»›p attention cá»§a kiáº¿n trÃºc Transformer [67], do Ä‘Ã³ giáº£m Ä‘Ã¡ng ká»ƒ sá»‘ lÆ°á»£ng tham sá»‘ cÃ³ thá»ƒ huáº¥n luyá»‡n. ChÃºng tÃ´i sá»­ dá»¥ng LoRA nhÆ° má»™t trong nhá»¯ng ká»¹ thuáº­t PEFT vÃ¬ nÃ³ Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trong NLP [14,37,65] vÃ  cho tháº¥y hiá»‡u suáº¥t Ä‘áº§y há»©a háº¹n. ChÃºng tÃ´i cÅ©ng sá»­ dá»¥ng IA3 cÃ³ Ã½ Ä‘á»‹nh cáº£i thiá»‡n LoRA vÃ  giáº£m thÃªm lÆ°á»£ng tham sá»‘ cÃ³ thá»ƒ huáº¥n luyá»‡n [37]. NgoÃ i LoRA vÃ  IA3, chÃºng tÃ´i cÅ©ng bao gá»“m Prompt tuning [30] vÃ  Prefix tuning [30] trong nghiÃªn cá»©u cá»§a chÃºng tÃ´i. Prompt tuning liÃªn quan Ä‘áº¿n quÃ¡ trÃ¬nh thÃªm token áº£o vÃ o token Ä‘áº§u vÃ o cá»§a LLM, trong khi Prefix tuning chÃ¨n token áº£o trong táº¥t cáº£ cÃ¡c lá»›p cá»§a mÃ´ hÃ¬nh má»¥c tiÃªu vÃ  do Ä‘Ã³ yÃªu cáº§u há»c nhiá»u tham sá»‘ hÆ¡n. Nhá»¯ng token áº£o nÃ y cÃ³ thá»ƒ vi phÃ¢n, cho phÃ©p chÃºng Ä‘Æ°á»£c há»c thÃ´ng qua lan truyá»n ngÆ°á»£c trong quÃ¡ trÃ¬nh tinh chá»‰nh, trong khi pháº§n cÃ²n láº¡i cá»§a LLM váº«n bá»‹ Ä‘Ã³ng bÄƒng. HÆ¡n ná»¯a, QLoRA [13] káº¿t há»£p LoRA vá»›i lÆ°á»£ng tá»­ hÃ³a mÃ´ hÃ¬nh, cho phÃ©p tinh chá»‰nh LLM vá»›i Ã­t bá»™ nhá»› GPU hÆ¡n báº±ng cÃ¡ch giáº£m Ä‘á»™ chÃ­nh xÃ¡c cá»§a cÃ¡c loáº¡i dá»¯ liá»‡u Ä‘iá»ƒm ná»•i trong mÃ´ hÃ¬nh.

3 ÃP Dá»¤NG LLM Vá»šI TÃ€I NGUYÃŠN Háº N CHáº¾
Trong thá»i Ä‘áº¡i LLM, tÃ­nh kháº£ dá»¥ng cá»§a tÃ i nguyÃªn tÃ­nh toÃ¡n Ä‘Ã¡ng ká»ƒ Ä‘Ã³ng vai trÃ² quan trá»ng trong viá»‡c khai thÃ¡c kháº£ nÄƒng cao cá»§a chÃºng. Tháº­t khÃ´ng may, nhiá»u nhÃ  nghiÃªn cá»©u vÃ  nhÃ  thá»±c hÃ nh thÆ°á»ng tháº¥y mÃ¬nh bá»‹ háº¡n cháº¿ bá»Ÿi tÃ­nh kháº£ dá»¥ng háº¡n cháº¿ cá»§a cÆ¡ sá»Ÿ háº¡ táº§ng tÃ­nh toÃ¡n cao cáº¥p.

VÃ­ dá»¥, má»™t ká»¹ sÆ° pháº§n má»m chá»‰ cÃ³ quyá»n truy cáº­p vÃ o má»™t GPU tiÃªu dÃ¹ng duy nháº¥t (vÃ­ dá»¥: 24GB VRAM) cÃ³ thá»ƒ tháº¥y tinh chá»‰nh Ä‘áº§y Ä‘á»§ khÃ´ng thá»±c táº¿ do nhu cáº§u bá»™ nhá»› Ä‘Ã¡ng ká»ƒ. Sá»± gia tÄƒng nhanh chÃ³ng vá» kÃ­ch thÆ°á»›c mÃ´ hÃ¬nh vÃ  sá»‘ lÆ°á»£ng tham sá»‘ cÃ³ thá»ƒ huáº¥n luyá»‡n lÃ m tráº§m trá»ng thÃªm váº¥n Ä‘á» nÃ y. Máº·c dÃ¹ hiá»‡u quáº£, tinh chá»‰nh Ä‘áº§y Ä‘á»§ Ä‘i kÃ¨m vá»›i chi phÃ­ tÃ­nh toÃ¡n cao [3,15,51], nháº¥n máº¡nh sá»± Ä‘Ã¡nh Ä‘á»•i tÃ­nh toÃ¡n-hiá»‡u quáº£ (xem Báº£ng 1).

Äá»ƒ giáº£i quyáº¿t nhá»¯ng háº¡n cháº¿ nÃ y, cÃ¡c cÃ¡ch tiáº¿p cáº­n thay tháº¿ nhÆ° ICL vÃ  RAG Ä‘Ã£ thu hÃºt sá»± chÃº Ã½. ICL vÃ  RAG cung cáº¥p má»™t tÃ¹y chá»n tÃ­nh toÃ¡n tháº¥p báº±ng cÃ¡ch loáº¡i bá» nhu cáº§u cáº­p nháº­t tham sá»‘. Tuy nhiÃªn, nhá»¯ng ká»¹ thuáº­t nÃ y Ä‘i kÃ¨m vá»›i bá»™ thÃ¡ch thá»©c riÃªng, bao gá»“m viá»‡c lá»±a chá»n cÃ¡c vÃ­ dá»¥ Ä‘áº¡i diá»‡n vÃ  Ä‘á»™ nháº¡y cáº£m vá»›i thiáº¿t káº¿ prompt [37,74,90]. Trong thá»±c táº¿, Ä‘iá»u nÃ y cÃ³ thá»ƒ dáº«n Ä‘áº¿n hiá»‡u quáº£ tháº¥p hÆ¡n so vá»›i tinh chá»‰nh, Ä‘áº·c biá»‡t cho cÃ¡c tÃ¡c vá»¥ cÃ³ ngá»¯ cáº£nh cao phá»• biáº¿n trong ká»¹ thuáº­t pháº§n má»m.

--- TRANG 6 ---
6â€¢M. Weyssow vÃ  cá»™ng sá»±.
Báº£ng 1. Sá»± Ä‘Ã¡nh Ä‘á»•i tÃ­nh toÃ¡n-hiá»‡u quáº£ cho má»—i ká»¹ thuáº­t tinh chá»‰nh mÃ´ hÃ¬nh.
Ká»¹ thuáº­t Chi phÃ­ tÃ­nh toÃ¡n Hiá»‡u quáº£
Tinh chá»‰nh Ä‘áº§y Ä‘á»§ cao [X] cao [âœ“]
ICL vÃ  RAG tháº¥p [âœ“] tháº¥p [X]
PEFT tháº¥p [âœ“] cao [âœ“]
0 5 10 15 20 24
TiÃªu thá»¥ bá»™ nhá»› Ä‘á»‰nh (GB)CodeT5+-220M-ft
CodeGen-350M-mono-ft
CodeT5+-770M-ft
CodeLlama-7B-QLoRA-4bit
CodeGen2-1B-lora
CodeGen2-3.7B-lora
CodeLlama-13B-QLoRA-4bit
CodeLlama-7B-lora
CodeGen2-7B-lora
CodeLlama-34B-QLoRA-4bit3.54
5.84
8.16
9.16
9.8
14.08
15.01
19.06
20.29
23.59
HÃ¬nh 1. TiÃªu thá»¥ bá»™ nhá»› GPU Ä‘á»‰nh trong quÃ¡ trÃ¬nh tinh chá»‰nh mÃ´ hÃ¬nh sá»­ dá»¥ng tinh chá»‰nh Ä‘áº§y Ä‘á»§ (ft), LoRA, vÃ  QLoRA.

Äá»ƒ vÆ°á»£t qua nhá»¯ng háº¡n cháº¿ nÃ y, chÃºng tÃ´i dá»± kiáº¿n sá»± xuáº¥t hiá»‡n cá»§a cÃ¡c ká»¹ thuáº­t PEFT nhÆ° nhá»¯ng giáº£i phÃ¡p Ä‘áº§y há»©a háº¹n, cung cáº¥p cÃ¡c cÃ¡ch tiáº¿p cáº­n hiá»‡u quáº£ vÃ  cÃ³ thá»ƒ má»Ÿ rá»™ng hÆ¡n vá» máº·t tÃ­nh toÃ¡n Ä‘á»ƒ tinh chá»‰nh LLM. CÃ¡c phÆ°Æ¡ng phÃ¡p PEFT, nhÆ° LoRA vÃ  QLoRA, háº¡n cháº¿ sá»‘ lÆ°á»£ng tham sá»‘ Ä‘Æ°á»£c cáº­p nháº­t, do Ä‘Ã³ giáº£m má»©c tiÃªu thá»¥ bá»™ nhá»› trong khi duy trÃ¬ hiá»‡u quáº£ cáº¡nh tranh vá»›i tinh chá»‰nh Ä‘áº§y Ä‘á»§. Äiá»u nÃ y lÃ m cho PEFT Ä‘áº·c biá»‡t phÃ¹ há»£p cho cÃ¡c nhÃ  thá»±c hÃ nh cÃ³ quyá»n truy cáº­p háº¡n cháº¿ vÃ o tÃ i nguyÃªn tÃ­nh toÃ¡n. NhÆ° Ä‘Æ°á»£c minh há»a trong Báº£ng 1, PEFT Ä‘áº¡t Ä‘Æ°á»£c sá»± cÃ¢n báº±ng tá»‘i Æ°u giá»¯a chi phÃ­ tÃ­nh toÃ¡n vÃ  hiá»‡u quáº£. HÆ¡n ná»¯a, HÃ¬nh 1 cho tháº¥y ráº±ng báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t PEFT nhÆ° LoRA, cÃ¡c nhÃ  thá»±c hÃ nh cÃ³ thá»ƒ tinh chá»‰nh cÃ¡c mÃ´ hÃ¬nh nhÆ° CodeLlama-7B mÃ  khÃ´ng vÆ°á»£t quÃ¡ 19GB bá»™ nhá»› GPU. Äá»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh tháº­m chÃ­ lá»›n hÆ¡n, nhÆ° CodeLlama-34B, QLoRA vá»›i lÆ°á»£ng tá»­ hÃ³a cho phÃ©p tinh chá»‰nh trong cÃ¡c rÃ ng buá»™c cá»§a GPU VRAM 24GB.

Káº¿t luáº­n, PEFT trao quyá»n cho cÃ¡c ká»¹ sÆ° pháº§n má»m vÆ°á»£t qua nhá»¯ng háº¡n cháº¿ tÃ i nguyÃªn, cho phÃ©p tinh chá»‰nh LLM hiá»‡u quáº£ trong cÃ¡c tÃ¡c vá»¥ cÃ³ ngá»¯ cáº£nh cao mÃ  khÃ´ng dá»±a vÃ o cÆ¡ sá»Ÿ háº¡ táº§ng tÃ­nh toÃ¡n Ä‘áº¯t tiá»n. Äiá»u nÃ y lÃ m cho PEFT khÃ´ng chá»‰ lÃ  má»™t cÃ´ng cá»¥ thá»±c tiá»…n mÃ  cÃ²n thiáº¿t yáº¿u Ä‘á»ƒ dÃ¢n chá»§ hÃ³a quyá»n truy cáº­p vÃ o kháº£ nÄƒng LLM.

4 PHÆ¯Æ NG PHÃP
Trong pháº§n nÃ y, chÃºng tÃ´i trÃ¬nh bÃ y thiáº¿t láº­p thÃ­ nghiá»‡m cá»§a nghiÃªn cá»©u. ChÃºng tÃ´i tiáº¿n hÃ nh táº¥t cáº£ cÃ¡c thÃ­ nghiá»‡m dÆ°á»›i má»™t tÃ¬nh huá»‘ng háº¡n cháº¿ tÃ i nguyÃªn. Cá»¥ thá»ƒ, táº¥t cáº£ cÃ¡c thá»§ tá»¥c, tá»©c lÃ  tinh chá»‰nh vÃ  suy luáº­n, cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c thá»±c hiá»‡n vá»›i quyá»n truy cáº­p vÃ o má»™t GPU 24GB duy nháº¥t. Má»¥c tiÃªu chÃ­nh cá»§a nghiÃªn cá»©u lÃ  chá»©ng minh liá»‡u viá»‡c tinh chá»‰nh LLM thÃ´ng qua PEFT cÃ³ kháº£ thi vÃ  mong muá»‘n hÆ¡n cÃ¡c cÃ¡ch tiáº¿p cáº­n trÆ°á»›c vÃ  cÃ¡c mÃ´ hÃ¬nh nhá» hÆ¡n trong bá»‘i cáº£nh nÃ y.

--- TRANG 7 ---
KhÃ¡m phÃ¡ cÃ¡c Ká»¹ thuáº­t Tinh chá»‰nh Hiá»‡u quáº£ Tham sá»‘ cho Sinh mÃ£ vá»›i MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n â€¢7
4.1 CÃ¢u há»i NghiÃªn cá»©u
Trong nghiÃªn cá»©u nÃ y, chÃºng tÃ´i táº­p trung vÃ o cÃ¡c cÃ¢u há»i nghiÃªn cá»©u sau:
â€“RQ1: LLM vÃ  SLM hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o khi sá»­ dá»¥ng ICL trÃªn cÃ¡c bá»™ dá»¯ liá»‡u Conala vÃ  CodeAlpacaPy?
ChÃºng tÃ´i nghiÃªn cá»©u hiá»‡u quáº£ cÆ¡ báº£n cá»§a LLM (â‰¥1B tham sá»‘) vÃ  SLM (<1B tham sá»‘) cho sinh mÃ£ sá»­ dá»¥ng prompt zero-shot vÃ  ICL, nÆ¡i n vÃ­ dá»¥ Ä‘Æ°á»£c chá»n ngáº«u nhiÃªn Ä‘Æ°á»£c thÃªm vÃ o prompt Ä‘áº§u vÃ o. ChÃºng tÃ´i kiá»ƒm tra má»—i mÃ´ hÃ¬nh vá»›i tá»‘i Ä‘a 16 vÃ­ dá»¥ ICL, do tÃ i nguyÃªn tÃ­nh toÃ¡n háº¡n cháº¿ cá»§a chÃºng tÃ´i.

ChÃºng tÃ´i nghiÃªn cá»©u hiá»‡u quáº£ cá»§a má»™t phá»• rá»™ng SLM vÃ  LLM cho sinh mÃ£ trÃªn hai bá»™ dá»¯ liá»‡u bao gá»“m mÃ£ cÃ³ Ä‘á»™ dÃ i khÃ¡c nhau. ChÃºng tÃ´i chá»n má»™t loáº¡t rá»™ng cÃ¡c mÃ´ hÃ¬nh vá»›i kÃ­ch thÆ°á»›c khÃ¡c nhau, Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n trÃªn cÃ¡c codebase Ä‘a dáº¡ng vÃ  vá»›i cÃ¡c má»¥c tiÃªu há»c khÃ¡c nhau Ä‘á»ƒ nghiÃªn cá»©u cÃ¡ch nhá»¯ng yáº¿u tá»‘ nÃ y áº£nh hÆ°á»Ÿng Ä‘áº¿n hiá»‡u quáº£ cá»§a chÃºng.

â€“RQ2: LLM vÃ  SLM hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o khi sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t PEFT trÃªn cÃ¡c bá»™ dá»¯ liá»‡u Conala vÃ  CodeAlpacaPy? Trong RQ nÃ y, chÃºng tÃ´i Ä‘iá»u tra liá»‡u cÃ¡c ká»¹ thuáº­t PEFT cÃ³ liÃªn tá»¥c vÆ°á»£t trá»™i ICL cho SLM vÃ  LLM khÃ´ng. ChÃºng tÃ´i so sÃ¡nh cÃ¡c cáº¥u hÃ¬nh hoáº¡t Ä‘á»™ng tá»‘t nháº¥t cá»§a ICL trong RQ1 vá»›i cÃ¡c ká»¹ thuáº­t PEFT, bao gá»“m LoRA, IA3, Prompt tuning, Prefix tuning. HÆ¡n ná»¯a, chÃºng tÃ´i cÅ©ng Ä‘iá»u tra tÃ¡c Ä‘á»™ng cá»§a lÆ°á»£ng tá»­ hÃ³a vá»›i QLoRA-8bit vÃ  QLoRA-4bit trÃªn mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng tá»‘t nháº¥t vÃ  cÃ¡c biáº¿n thá»ƒ lá»›n hÆ¡n.

Äá»‘i vá»›i SLM, chÃºng tÃ´i cÅ©ng bao gá»“m so sÃ¡nh vá»›i tinh chá»‰nh tham sá»‘ Ä‘áº§y Ä‘á»§, nhÆ° thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c nghiÃªn cá»©u SE trÆ°á»›c [16,72,77,92]. ChÃºng tÃ´i khÃ´ng bao gá»“m tinh chá»‰nh tham sá»‘ Ä‘áº§y Ä‘á»§ cho LLM, vÃ¬ nÃ³ khÃ´ng kháº£ thi trong ngÃ¢n sÃ¡ch tÃ­nh toÃ¡n cá»§a chÃºng tÃ´i.

â€“RQ3: LoRA so sÃ¡nh nhÆ° tháº¿ nÃ o vá»›i ICL vÃ  RAG trÃªn cÃ¡c bá»™ dá»¯ liá»‡u Conala vÃ  CodeAlpacaPy?
Trong RQ nÃ y, chÃºng tÃ´i so sÃ¡nh hiá»‡u quáº£ cá»§a LLM hoáº¡t Ä‘á»™ng tá»‘t nháº¥t Ä‘Æ°á»£c tinh chá»‰nh sá»­ dá»¥ng LoRA vá»›i RAG. Thiáº¿t láº­p RAG cá»§a chÃºng tÃ´i bao gá»“m viá»‡c truy xuáº¥t tá»‘i Ä‘a 16 vÃ­ dá»¥ tá»« táº­p huáº¥n luyá»‡n cÃ³ liÃªn quan cháº·t cháº½ Ä‘áº¿n prompt Ä‘áº§u vÃ o, tÆ°Æ¡ng tá»± nhÆ° cÃ¡c cÃ¡ch tiáº¿p cáº­n khÃ¡c Ä‘Æ°á»£c Ä‘á» xuáº¥t trÆ°á»›c Ä‘Ã¢y cho cÃ¡c tÃ¡c vá»¥ SE khÃ¡c nhau [39, 41, 70].

â€“RQ4: ChÃºng ta cÃ³ thá»ƒ tÄƒng cÆ°á»ng hiá»‡u quáº£ cá»§a LLM cho sinh mÃ£ trong bá»™ dá»¯ liá»‡u APPS báº±ng LoRA vÃ  QLoRA khÃ´ng? Cuá»‘i cÃ¹ng, chÃºng tÃ´i khÃ¡m phÃ¡ liá»‡u LLM Ä‘Æ°á»£c tinh chá»‰nh sá»­ dá»¥ng LoRA vÃ  QLoRA cÃ³ cho tháº¥y cáº£i thiá»‡n vá» tÃ­nh chÃ­nh xÃ¡c chá»©c nÄƒng trong bá»™ dá»¯ liá»‡u APPS. ChÃºng tÃ´i tinh chá»‰nh LLM hoáº¡t Ä‘á»™ng tá»‘t nháº¥t sá»­ dá»¥ng LoRA vÃ  QLoRA trÃªn táº­p huáº¥n luyá»‡n cá»§a APPS, vÃ  bÃ¡o cÃ¡o trung bÃ¬nh cá»§a cÃ¡c test case Ä‘Ã£ qua cÅ©ng nhÆ° Pass@k trÃªn táº­p kiá»ƒm tra cá»§a APPS cho cÃ¡c váº¥n Ä‘á» láº­p trÃ¬nh cáº¥p Ä‘á»™ giá»›i thiá»‡u, phá»ng váº¥n, vÃ  thi Ä‘áº¥u.

4.2 Bá»™ dá»¯ liá»‡u vÃ  TÃ¡c vá»¥
Trong suá»‘t nghiÃªn cá»©u, chÃºng tÃ´i so sÃ¡nh táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c nghiÃªn cá»©u trÃªn tÃ¡c vá»¥ sinh mÃ£ Python. TÃ¡c vá»¥ nÃ y Ä‘Ã£ thu hÃºt sá»± chÃº Ã½ Ä‘Ã¡ng ká»ƒ trong nhá»¯ng nÄƒm gáº§n Ä‘Ã¢y [9,10,48,50,61] vá»›i sá»± xuáº¥t hiá»‡n cá»§a LLM vÃ  kháº£ nÄƒng cá»§a chÃºng trong viá»‡c sinh mÃ£ Python theo cÃ¡ch zero-shot, tá»©c lÃ  khÃ´ng cáº§n tinh chá»‰nh thÃªm. Äáº·c biá»‡t, cÃ¡c bá»™ dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡ nhÆ° HumanEval [9] Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ¡c cÃ¡ch tiáº¿p cáº­n sinh mÃ£ [3,9,82]. Trong khi HumanEval Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i, nÃ³ thiáº¿u má»™t kho huáº¥n luyá»‡n Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ¡c cÃ¡ch tiáº¿p cáº­n tinh chá»‰nh hoáº·c PEFT. VÃ¬ trá»ng tÃ¢m cá»§a nghiÃªn cá»©u lÃ  chuyÃªn mÃ´n hÃ³a LLM sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t PEFT, chÃºng tÃ´i Ä‘Ã£ chá»n khÃ´ng sá»­ dá»¥ng HumanEval. Thay vÃ o Ä‘Ã³, chÃºng tÃ´i chá»n sá»­ dá»¥ng ba bá»™ dá»¯ liá»‡u sinh mÃ£ Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i khÃ¡c: cÃ¡c bá»™ dá»¯ liá»‡u Conala [87], CodeAlpaca [8], vÃ  APPS [22]. Táº¥t cáº£ cÃ¡c bá»™ dá»¯ liá»‡u cung cáº¥p má»™t sá»‘ lÆ°á»£ng Ä‘á»§ lá»›n

--- TRANG 8 ---
8â€¢M. Weyssow vÃ  cá»™ng sá»±.
0 25 50 75 100 125 150 175 200
Äá»™ dÃ i token0100200300400500600700Sá»‘ máº«uAPPs
CodeAlpacaPy
Conala
HÃ¬nh 2. PhÃ¢n phá»‘i Ä‘á»™ dÃ i token cá»§a cÃ¡c bá»™ dá»¯ liá»‡u Conala, CodeAlpacaPy, vÃ  APPS.

cÃ¡c vÃ­ dá»¥ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cho viá»‡c tinh chá»‰nh má»™t mÃ´ hÃ¬nh vÃ  Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c nghiÃªn cá»©u sinh mÃ£ trÆ°á»›c vá»›i LLM [71, 73, 88, 91].

Bá»™ dá»¯ liá»‡u Conala. ChÃºng tÃ´i sá»­ dá»¥ng má»™t phiÃªn báº£n Ä‘Æ°á»£c tuyá»ƒn chá»n cá»§a bá»™ dá»¯ liá»‡u Conala [91]. Bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c thu tháº­p tá»« StackOverflow vÃ  chá»©a cÃ¡c cáº·p mÃ£ vÃ  Ã½ Ä‘á»‹nh ngÃ´n ngá»¯ tá»± nhiÃªn Ä‘Æ°á»£c chÃº thÃ­ch thá»§ cÃ´ng. Má»—i Ã½ Ä‘á»‹nh ngÃ´n ngá»¯ tá»± nhiÃªn chá»©a gá»£i Ã½ vá» cÃ¡c biáº¿n Ä‘Æ°á»£c thao tÃ¡c trong mÃ£ thá»±c táº¿, vÃ­ dá»¥, xem vÃ­ dá»¥ Ä‘áº§u tiÃªn trong Báº£ng 2, cung cáº¥p thÃªm ngá»¯ cáº£nh cho mÃ´ hÃ¬nh Ä‘á»ƒ sinh mÃ£ cÃ³ liÃªn quan. Trong HÃ¬nh 2, chÃºng tÃ´i bÃ¡o cÃ¡o phÃ¢n phá»‘i Ä‘á»™ dÃ i token cá»§a ba bá»™ dá»¯ liá»‡u. Trong Conala, háº§u háº¿t cÃ¡c giáº£i phÃ¡p mÃ£ Ä‘á»u ngáº¯n vÃ  má»™t dÃ²ng, lÃ m cho nÃ³ tÆ°Æ¡ng Ä‘á»‘i dá»… dÃ ng cho má»™t LLM Ä‘á»ƒ sinh cÃ¡c dá»± Ä‘oÃ¡n khá»›p chÃ­nh xÃ¡c. Trong phiÃªn báº£n Ä‘Æ°á»£c tuyá»ƒn chá»n nÃ y cá»§a bá»™ dá»¯ liá»‡u, cÃ¡c tÃ¡c giáº£ Ä‘áº£m báº£o ráº±ng má»—i máº«u trong cÃ¡c táº­p validation vÃ  test chá»©a Ã­t nháº¥t má»™t hÃ m Python khÃ´ng xuáº¥t hiá»‡n trong táº­p huáº¥n luyá»‡n. NgoÃ i ra, há» Ä‘áº£m báº£o ráº±ng cÃ¡c vÃ­ dá»¥ Ä‘Æ°á»£c thu tháº­p tá»« cÃ¹ng má»™t bÃ i Ä‘Äƒng StackOverflow xuáº¥t hiá»‡n trong cÃ¡c táº­p khÃ¡c nhau. Do Ä‘Ã³, chÃºng tÃ´i cÃ³ thá»ƒ Ä‘áº£m báº£o ráº±ng má»—i Ã½ Ä‘á»‹nh tá»± nhiÃªn trong kiá»ƒm tra khÃ´ng xuáº¥t hiá»‡n trong táº­p huáº¥n luyá»‡n. Bá»™ dá»¯ liá»‡u chá»©a 2,135/201/543 máº«u nhÆ° cÃ¡c táº­p huáº¥n luyá»‡n/validation/test, tÆ°Æ¡ng á»©ng.

Bá»™ dá»¯ liá»‡u CodeAlpacaPy. ChÃºng tÃ´i xÃ¢y dá»±ng má»™t phiÃªn báº£n Python Ä‘Æ°á»£c tuyá»ƒn chá»n cá»§a bá»™ dá»¯ liá»‡u CodeAlpaca [8] báº±ng cÃ¡ch chá»n cá»¥ thá»ƒ cÃ¡c máº«u dá»¯ liá»‡u Python trong bá»™ dá»¯ liá»‡u CodeAlpaca. ChÃºng tÃ´i lá»c ra cÃ¡c máº«u mÃ£ khÃ´ng thá»ƒ Ä‘Æ°á»£c phÃ¢n tÃ­ch tÄ©nh Ä‘á»ƒ Ä‘áº£m báº£o bá»™ dá»¯ liá»‡u chá»‰ bao gá»“m cÃ¡c mÃ£ Python há»£p lá»‡ vá» cÃº phÃ¡p. NhÆ° Ä‘Æ°á»£c minh há»a trong vÃ­ dá»¥ dÆ°á»›i cÃ¹ng cá»§a Báº£ng 2 vÃ  trong HÃ¬nh 2, CodeAlpacaPy chá»©a cÃ¡c vÃ­ dá»¥ dÃ i hÆ¡n vÃ  phá»©c táº¡p hÆ¡n so vá»›i Conala, cho phÃ©p Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n hÆ¡n vá» PEFT cho sinh mÃ£. Bá»™ dá»¯ liá»‡u chá»©a 2,192/314/628 máº«u nhÆ° cÃ¡c táº­p huáº¥n luyá»‡n/validation/test, tÆ°Æ¡ng á»©ng.

Bá»™ dá»¯ liá»‡u APPS. Bá»™ dá»¯ liá»‡u APPS bao gá»“m 10,000 váº¥n Ä‘á» sinh mÃ£, má»—i váº¥n Ä‘á» Ä‘Æ°á»£c ghÃ©p vá»›i cÃ¡c giáº£i phÃ¡p Python. Nhá»¯ng váº¥n Ä‘á» nÃ y Ä‘Æ°á»£c phÃ¢n loáº¡i thÃ nh ba cáº¥p Ä‘á»™ khÃ³: giá»›i thiá»‡u, phá»ng váº¥n, vÃ  thi Ä‘áº¥u, vá»›i cÃ¡c giáº£i phÃ¡p biáº¿n Ä‘á»•i tá»« má»™t dÃ²ng Ä‘Æ¡n giáº£n Ä‘áº¿n cÃ¡c thuáº­t toÃ¡n phá»©c táº¡p. ChÃºng ta cÃ³ thá»ƒ tháº¥y trong HÃ¬nh 2 vÃ  Báº£ng 2 ráº±ng APPS bao gá»“m cÃ¡c vÃ­ dá»¥ dÃ i hÆ¡n vÃ  phá»©c táº¡p hÆ¡n so vá»›i hai bá»™ dá»¯ liá»‡u khÃ¡c. Trung bÃ¬nh, má»—i váº¥n Ä‘á» Ä‘Æ°á»£c kÃ¨m theo 21.2 test case, Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ tÃ­nh chÃ­nh xÃ¡c chá»©c nÄƒng cá»§a mÃ£ Ä‘Æ°á»£c sinh. Bá»™ dá»¯ liá»‡u gá»‘c Ä‘Æ°á»£c chia thÃ nh 5,000 máº«u cho huáº¥n luyá»‡n vÃ  5,000 cho kiá»ƒm tra.

--- TRANG 9 ---
KhÃ¡m phÃ¡ cÃ¡c Ká»¹ thuáº­t Tinh chá»‰nh Hiá»‡u quáº£ Tham sá»‘ cho Sinh mÃ£ vá»›i MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n â€¢9
Báº£ng 2. Tá»•ng quan vá» tÃ¡c vá»¥ sinh mÃ£, vá»›i ba vÃ­ dá»¥ Ä‘Æ°á»£c láº¥y tá»« cÃ¡c bá»™ dá»¯ liá»‡u Conala, CodeAlpacaPy, vÃ  APPS.

Conala
Prompt :### HÆ°á»›ng dáº«n:
Ã¡nh xáº¡ hai danh sÃ¡ch 'keys' vÃ  'values' thÃ nh má»™t tá»« Ä‘iá»ƒn
### Pháº£n há»“i:
Thá»±c táº¿ :dict([(k, v) for k, v inzip(keys, values)])

CodeAlpacaPy
Prompt :### HÆ°á»›ng dáº«n:
Viáº¿t má»™t hÃ m Ä‘á»ƒ tÃ­nh Ä‘á»™ lá»‡ch chuáº©n cá»§a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u trong Python.
### Pháº£n há»“i:
Thá»±c táº¿ :def stdev(data):
avg = sum(data) / len(data)
total = 0
for xindata:
total += (x - avg) ** 2
return (total / (len(data) - 1)) ** 0.5

APPS
Prompt :### HÆ°á»›ng dáº«n:
Báº¡n Ä‘Æ°á»£c Ä‘Æ°a ra má»™t chuá»—i s = s1 s2 . . . sn cÃ³ Ä‘á»™ dÃ i n, chá»‰ chá»©a cÃ¡c chá»¯ sá»‘ 1, 2,..., 9. Má»™t chuá»—i con s[l...r] cá»§a s lÃ  má»™t chuá»—i slsl+1sl+2 ...sr. Má»™t chuá»—i con s[l...r] cá»§a s Ä‘Æ°á»£c gá»i lÃ  cháºµn náº¿u sá»‘ Ä‘Æ°á»£c biá»ƒu diá»…n bá»Ÿi nÃ³ lÃ  cháºµn. TÃ¬m sá»‘ lÆ°á»£ng chuá»—i con cháºµn cá»§a s. LÆ°u Ã½, ngay cáº£ khi má»™t sá»‘ chuá»—i con báº±ng nhau nhÆ° chuá»—i, nhÆ°ng cÃ³ l vÃ  r khÃ¡c nhau, chÃºng Ä‘Æ°á»£c tÃ­nh nhÆ° cÃ¡c chuá»—i con khÃ¡c nhau. DÃ²ng Ä‘áº§u tiÃªn chá»©a má»™t sá»‘ nguyÃªn n (1â‰¤nâ‰¤65000) â€” Ä‘á»™ dÃ i cá»§a chuá»—i s. DÃ²ng thá»© hai chá»©a má»™t chuá»—i s cÃ³ Ä‘á»™ dÃ i n. Chuá»—i s chá»‰ bao gá»“m cÃ¡c chá»¯ sá»‘ 1, 2,..., 9. In sá»‘ lÆ°á»£ng chuá»—i con cháºµn cá»§a s.
### Pháº£n há»“i:
Thá»±c táº¿ :n = int(input())
ans = 0
for iinrange(n):
for jinrange(i, n):
ifint(s[i:j+1]) \% 2 == 0:
ans += 1
print(ans)

Trong nghiÃªn cá»©u nÃ y, chÃºng tÃ´i sá»­ dá»¥ng 4,500 máº«u cho huáº¥n luyá»‡n, 500 cho validation, vÃ  750 cho kiá»ƒm tra, Ä‘áº£m báº£o phÃ¢n phá»‘i cÃ¢n báº±ng 250 máº«u kiá»ƒm tra má»—i cáº¥p Ä‘á»™ khÃ³.

Thiáº¿t káº¿ tÃ¡c vá»¥. Trong Báº£ng 2, chÃºng tÃ´i minh há»a tá»•ng quan vá» thiáº¿t káº¿ tÃ¡c vá»¥. Prompt cÃ³ dáº¡ng má»™t máº«u hÆ°á»›ng dáº«n, nÆ¡i "### HÆ°á»›ng dáº«n:" vÃ  "### Pháº£n há»“i:" Ä‘Ã³ng vai trÃ² phÃ¢n Ä‘á»‹nh hÆ°á»›ng dáº«n, tá»©c lÃ  Ã½ Ä‘á»‹nh ngÃ´n ngá»¯ tá»± nhiÃªn, vÃ  cÃ¢u tráº£ lá»i, tá»©c lÃ  sinh mÃ£. LÆ°u Ã½ ráº±ng thiáº¿t káº¿ prompt nÃ y cÃ³ thá»ƒ khÃ´ng tá»‘i Æ°u, nhÆ°ng loáº¡i máº«u hÆ°á»›ng dáº«n nÃ y Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh lÃ  hiá»‡u quáº£ trong cÃ¡c cÃ´ng trÃ¬nh trÆ°á»›c [36,89]. MÃ£ Ä‘Æ°á»£c sinh bá»Ÿi mÃ´ hÃ¬nh Ä‘Æ°á»£c so sÃ¡nh vá»›i thá»±c táº¿ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡

--- TRANG 10 ---
10 â€¢M. Weyssow vÃ  cá»™ng sá»±.

cháº¥t lÆ°á»£ng cá»§a viá»‡c sinh. Trong quÃ¡ trÃ¬nh tinh chá»‰nh, chÃºng tÃ´i tá»‘i thiá»ƒu hÃ³a má»™t hÃ m máº¥t mÃ¡t entropy chÃ©o tá»± há»“i quy tiÃªu chuáº©n:

L=âˆ’ğ‘‡+1âˆ‘ï¸
ğ‘–=1ğ‘€ğ‘–Â·logğ‘ƒ(ğ‘¥ğ‘–|ğ‘¥<ğ‘–),

trong Ä‘Ã³:
ğ‘€ğ‘–=(
1,ifğ‘¥ğ‘–â‰ âˆ’100
0,otherwise .

MÃ´ hÃ¬nh nháº­n má»™t sá»± ná»‘i cá»§a prompt vÃ  thá»±c táº¿ nhÆ° Ä‘áº§u vÃ o vÃ  dá»± Ä‘oÃ¡n má»—i token ğ‘¥ğ‘– theo cÃ¡ch tá»± há»“i quy dá»±a trÃªn cÃ¡c token trÆ°á»›c ğ‘¥<ğ‘–. LÆ°u Ã½ ráº±ng trong tÃ­nh toÃ¡n máº¥t mÃ¡t, chÃºng tÃ´i bá» qua cÃ¡c token tá»« máº«u hÆ°á»›ng dáº«n Ä‘á»ƒ buá»™c mÃ´ hÃ¬nh táº­p trung vÃ o viá»‡c sinh mÃ£. ChÃºng tÃ´i Ä‘áº·t giÃ¡ trá»‹ cá»§a cÃ¡c token hÆ°á»›ng dáº«n thÃ nh âˆ’100 vÃ  bá» qua chÃºng trong tÃ­nh toÃ¡n máº¥t mÃ¡t sá»­ dá»¥ng hÃ m chá»‰ thá»‹ ğ‘€ğ‘–. Táº¡i thá»i Ä‘iá»ƒm suy luáº­n, mÃ´ hÃ¬nh nháº­n prompt nhÆ° Ä‘áº§u vÃ o vÃ  cá»‘ gáº¯ng sinh mÃ£ thá»±c táº¿ báº±ng cÃ¡ch sinh tá»‘i Ä‘a 10 á»©ng viÃªn mÃ£.

4.3 ICL vÃ  RAG
ChÃºng tÃ´i tiáº¿n hÃ nh thÃ­ nghiá»‡m sá»­ dá»¥ng ICL vÃ  RAG trÃªn cÃ¡c bá»™ dá»¯ liá»‡u Conala vÃ  CodeAlpacaPy. Äá»‘i vá»›i cáº£ hai ká»¹ thuáº­t, chÃºng tÃ´i chá»n sá»‘ lÆ°á»£ng máº«u tá»‘i Ä‘a cÃ³ thá»ƒ vá»«a vá»›i bá»™ nhá»› GPU cá»§a chÃºng tÃ´i. Äá»‘i vá»›i ICL, chÃºng tÃ´i sá»­ dá»¥ng tá»‘i Ä‘a 16 vÃ­ dá»¥ cho bá»™ dá»¯ liá»‡u Conala vÃ  8 vÃ­ dá»¥ cho CodeAlpacaPy. Nhá»¯ng vÃ­ dá»¥ nÃ y Ä‘Æ°á»£c láº¥y máº«u ngáº«u nhiÃªn tá»« cÃ¡c bá»™ dá»¯ liá»‡u huáº¥n luyá»‡n tÆ°Æ¡ng á»©ng vÃ  Ä‘Æ°á»£c ná»‘i vá»›i prompt Ä‘áº§u vÃ o trong quÃ¡ trÃ¬nh suy luáº­n. Äá»‘i vá»›i RAG, chÃºng tÃ´i táº­n dá»¥ng GTE-small, má»™t mÃ´ hÃ¬nh nhÃºng má»¥c Ä‘Ã­ch chung, nháº¹ vÆ°á»£t trá»™i nhiá»u mÃ´ hÃ¬nh lá»›n hÆ¡n, bao gá»“m cÃ¡c nhÃºng Ä‘á»™c quyá»n cá»§a OpenAI [34]. ChÃºng tÃ´i táº¡o nhÃºng cho táº¥t cáº£ cÃ¡c hÆ°á»›ng dáº«n (loáº¡i trá»« mÃ£) trong cÃ¡c táº­p huáº¥n luyá»‡n. Táº¡i thá»i Ä‘iá»ƒm suy luáº­n, chÃºng tÃ´i truy xuáº¥t tá»‘i Ä‘a 16 vÃ­ dá»¥ cho Conala vÃ  4 vÃ­ dá»¥ cho CodeAlpacaPy, chá»n nhá»¯ng vÃ­ dá»¥ cÃ³ hÆ°á»›ng dáº«n tÆ°Æ¡ng tá»± nháº¥t vá»›i Ä‘áº§u vÃ o kiá»ƒm tra. NhÆ° vá»›i ICL, cÃ¡c vÃ­ dá»¥ Ä‘Æ°á»£c truy xuáº¥t Ä‘Æ°á»£c ná»‘i vá»›i váº¥n Ä‘á» Ä‘áº§u vÃ o Ä‘á»ƒ hÆ°á»›ng dáº«n sinh mÃ£.

4.4 MÃ´ hÃ¬nh NgÃ´n ngá»¯ Nhá» vÃ  Lá»›n
Äá»ƒ thá»±c hiá»‡n phÃ¢n tÃ­ch toÃ n diá»‡n, chÃºng tÃ´i Ä‘Ã£ chá»n SLM vÃ  LLM theo má»™t sá»‘ tiÃªu chÃ­. Äáº§u tiÃªn, chÃºng tÃ´i chá»‰ xem xÃ©t cÃ¡c mÃ´ hÃ¬nh nguá»“n má»Ÿ. ChÃºng tÃ´i bá» qua cÃ¡c LLM nguá»“n Ä‘Ã³ng nhÆ° Codex do khÃ´ng thá»ƒ truy cáº­p cÃ¡c tham sá»‘ cá»§a chÃºng, Ä‘iá»u nÃ y lÃ m cho viá»‡c nghiÃªn cá»©u báº¥t ká»³ ká»¹ thuáº­t tinh chá»‰nh nÃ o trá»Ÿ nÃªn khÃ´ng kháº£ thi. Táº¥t cáº£ cÃ¡c checkpoint mÃ´ hÃ¬nh Ä‘Æ°á»£c nghiÃªn cá»©u cÃ³ thá»ƒ Ä‘Æ°á»£c truy cáº­p tá»± do, vÃ  Ä‘Ã£ Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n sá»­ dá»¥ng dá»¯ liá»‡u nguá»“n má»Ÿ. Thá»© hai, chÃºng tÃ´i chá»n cÃ¡c LLM Ä‘Ã£ Ä‘Æ°á»£c phÃ¡t hÃ nh trong hai nÄƒm qua. Cuá»‘i cÃ¹ng, Ä‘á»ƒ Ä‘iá»u tra tÃ¡c Ä‘á»™ng cá»§a viá»‡c má»Ÿ rá»™ng, chÃºng tÃ´i chá»n cÃ¡c mÃ´ hÃ¬nh vá»›i má»™t loáº¡t tham sá»‘ Ä‘a dáº¡ng. ChÃºng tÃ´i xem cÃ¡c mÃ´ hÃ¬nh cÃ³ Ã­t hÆ¡n 1B tham sá»‘ lÃ  SLM, vÃ  nhá»¯ng mÃ´ hÃ¬nh khÃ¡c lÃ  LLM. LÆ°u Ã½ ráº±ng chÃºng tÃ´i chá»n cÃ¡c mÃ´ hÃ¬nh phÃ¹ há»£p vá»›i má»™t GPU 24GB duy nháº¥t Ä‘á»ƒ tinh chá»‰nh vÃ  suy luáº­n mÃ  khÃ´ng gÃ¢y trÃ n bá»™ nhá»›. Tá»•ng cá»™ng, chÃºng tÃ´i bao gá»“m 11 SLM vÃ  LLM tá»« cÃ¡c há» mÃ´ hÃ¬nh Ä‘a dáº¡ng Ä‘á»ƒ tiáº¿n hÃ nh thÃ­ nghiá»‡m.

â€“SLM. ChÃºng tÃ´i sá»­ dá»¥ng CodeGen-350M-mono [48], CodeT5+-220M [71], vÃ  CodeT5+-770M [71] nhÆ° SLM. CodeGen-350M-mono lÃ  má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ tá»± há»“i quy vÃ  má»™t phiÃªn báº£n nhá» cá»§a CodeGen Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n trÃªn cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh khÃ¡c nhau vÃ  Ä‘Æ°á»£c tinh chá»‰nh thÃªm trÃªn dá»¯ liá»‡u Python. CodeT5+-220M vÃ  CodeT5+-770M lÃ  cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ encoder-decoder cáº£i thiá»‡n CodeT5 báº±ng cÃ¡ch táº­n dá»¥ng giai Ä‘oáº¡n tiá»n huáº¥n luyá»‡n hai giai Ä‘oáº¡n trÃªn dá»¯ liá»‡u ngÃ´n ngá»¯ tá»± nhiÃªn vÃ  mÃ£, vÃ  cÃ¡c má»¥c tiÃªu há»c má»›i.

--- TRANG 11 ---
KhÃ¡m phÃ¡ cÃ¡c Ká»¹ thuáº­t Tinh chá»‰nh Hiá»‡u quáº£ Tham sá»‘ cho Sinh mÃ£ vá»›i MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n â€¢11
â€“CodeGen2 [47] lÃ  má»™t há» mÃ´ hÃ¬nh ngÃ´n ngá»¯ dá»±a trÃªn tiá»n tá»‘ káº¿t há»£p cÃ¡c lÆ°á»£c Ä‘á»“ há»c cá»§a encoder hai chiá»u vÃ  decoder má»™t chiá»u. CodeGen2 cáº£i thiá»‡n CodeGen [48], do Ä‘Ã³ chÃºng tÃ´i khÃ´ng bao gá»“m há» CodeGen trong Ä‘Ã¡nh giÃ¡ cá»§a chÃºng tÃ´i. CÃ¡c mÃ´ hÃ¬nh CodeGen2 Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n trÃªn má»™t phiÃªn báº£n khá»­ trÃ¹ng cá»§a TheStack [28] bao trÃ¹m má»™t loáº¡t rá»™ng cÃ¡c ngÃ´n ngá»¯. ChÃºng tÃ´i sá»­ dá»¥ng CodeGen2-1B, CodeGen2-3.7B vÃ  CodeGen2-7B.

â€“CodeLlama [56] lÃ  má»™t há» LLM dá»±a trÃªn Llama 2 [64]. Má»—i mÃ´ hÃ¬nh Ä‘Æ°á»£c khá»Ÿi táº¡o vá»›i Llama 2 vÃ  Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n thÃªm trÃªn mÃ£. CodeLlama cÃ³ ba biáº¿n thá»ƒ khÃ¡c nhau: CodeLlama chuyÃªn cho mÃ£, CodeLlama-Instruct chuyÃªn cho tinh chá»‰nh hÆ°á»›ng dáº«n vÃ  CodeLlama-Python chuyÃªn cho Python. ChÃºng tÃ´i sá»­ dá»¥ng CodeLlama-7B, CodeLlama-7B-Instruct vÃ  CodeLlama-7B-Python Ä‘á»ƒ khá»Ÿi táº¡o thÃ­ nghiá»‡m. Trong RQ4, chÃºng tÃ´i tinh chá»‰nh CodeLlama-13B-Python vÃ  CodeLlama-34B-Python sá»­ dá»¥ng QLoRA.

4.5 Metrics
ChÃºng tÃ´i Ä‘o hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh thÃ´ng qua cÃ¡c metrics Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trong cÃ´ng trÃ¬nh sinh mÃ£ trÆ°á»›c. Äá»‘i vá»›i thÃ­ nghiá»‡m trÃªn Conala vÃ  CodeAlpacaPy, chÃºng tÃ´i bÃ¡o cÃ¡o cÃ¡c metrics Exact Match (EM) vÃ  CodeBLEU [55]. ÄÆ°a ra má»™t mÃ£ Ä‘Æ°á»£c sinh vÃ  má»™t thá»±c táº¿, EM tráº£ vá» 1 náº¿u cáº£ hai mÃ£ giá»‘ng há»‡t nhau, ngÆ°á»£c láº¡i 0. Äá»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh trÃªn má»™t danh sÃ¡ch kâˆˆ[1,10] á»©ng viÃªn, chÃºng tÃ´i bÃ¡o cÃ¡o EM@k, tÃ­nh toÃ¡n trung bÃ¬nh dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c trong má»™t danh sÃ¡ch k á»©ng viÃªn. Äá»‘i vá»›i thÃ­ nghiá»‡m trÃªn bá»™ dá»¯ liá»‡u APPS, chÃºng tÃ´i bÃ¡o cÃ¡o hai metrics: sá»‘ lÆ°á»£ng test case Ä‘Ã£ qua trung bÃ¬nh vÃ  Pass@k. Sá»‘ lÆ°á»£ng test case Ä‘Ã£ qua trung bÃ¬nh Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng tá»‘t nhÆ° tháº¿ nÃ o báº±ng cÃ¡ch Ä‘o tá»· lá»‡ test case mÃ  mÃ£ Ä‘Æ°á»£c sinh cá»§a nÃ³ vÆ°á»£t qua cho má»—i máº«u. NgÆ°á»£c láº¡i, Pass@k lÃ  má»™t metric nghiÃªm ngáº·t hÆ¡n Ä‘o tá»· lá»‡ pháº§n trÄƒm váº¥n Ä‘á» mÃ  Ã­t nháº¥t má»™t trong sá»‘ k máº«u mÃ£ Ä‘Æ°á»£c sinh hÃ ng Ä‘áº§u vÆ°á»£t qua táº¥t cáº£ test case, pháº£n Ã¡nh kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh Ä‘á»ƒ táº¡o ra cÃ¡c giáº£i phÃ¡p hoÃ n toÃ n chÃ­nh xÃ¡c trong k láº§n thá»­.

4.6 Chi tiáº¿t Thá»±c hiá»‡n
Äá»‘i vá»›i táº¥t cáº£ thÃ­ nghiá»‡m, chÃºng tÃ´i sá»­ dá»¥ng má»™t GPU NVIDIA RTX A5000 24GB duy nháº¥t. ChÃºng tÃ´i nghiÃªn cá»©u tá»•ng cá»™ng báº£y ká»¹ thuáº­t tinh chá»‰nh: Tinh chá»‰nh Ä‘áº§y Ä‘á»§, ICL, LoRA [24], IA3 [37], Prompt tuning [30], Prefix tuning [33], vÃ  QLoRA [13]. ChÃºng tÃ´i thá»±c hiá»‡n táº¥t cáº£ cÃ¡c ká»¹ thuáº­t tinh chá»‰nh sá»­ dá»¥ng cÃ¡c thÆ° viá»‡n HuggingFace [79] vÃ  PEFT [43].

ChÃºng tÃ´i chá»‰ sá»­ dá»¥ng tinh chá»‰nh Ä‘áº§y Ä‘á»§ cho SLM, vÃ¬ viá»‡c tinh chá»‰nh táº¥t cáº£ cÃ¡c tham sá»‘ cá»§a LLM khÃ´ng thá»ƒ xá»­ lÃ½ Ä‘Æ°á»£c vá» máº·t tÃ­nh toÃ¡n trong tá»‘i Ä‘a 24GB bá»™ nhá»› GPU. ChÃºng tÃ´i Ä‘áº·t tá»‘c Ä‘á»™ há»c thÃ nh 5eâˆ’5. Äá»‘i vá»›i LoRA vÃ  IA3, chÃºng tÃ´i Ã¡p dá»¥ng phÃ¢n tÃ¡ch ma tráº­n thá»© háº¡ng tháº¥p trÃªn cÃ¡c lá»›p attention cá»§a cÃ¡c mÃ´ hÃ¬nh vÃ  Ä‘áº·t r=16 vÃ  Î±=32. Äá»ƒ thá»±c hiá»‡n QLoRA, chÃºng tÃ´i sá»­ dá»¥ng lÆ°á»£ng tá»­ hÃ³a 8-bit vÃ  4-bit [12]. ChÃºng tÃ´i Ä‘áº·t tá»‘c Ä‘á»™ há»c thÃ nh 3eâˆ’4 cho LoRA, IA3 vÃ  QLoRA. Äá»‘i vá»›i Prompt tuning vÃ  Prefix tuning, chÃºng tÃ´i thÃªm má»™t táº­p 20 token áº£o liÃªn tá»¥c cÃ³ thá»ƒ huáº¥n luyá»‡n vÃ o má»—i máº«u Ä‘áº§u vÃ o cá»§a cÃ¡c mÃ´ hÃ¬nh vÃ  Ã¡p dá»¥ng tá»‘c Ä‘á»™ há»c 3eâˆ’3 vÃ  3eâˆ’2.

ChÃºng tÃ´i sá»­ dá»¥ng optimizer Adafactor [60] vá»›i Ä‘á»™ chÃ­nh xÃ¡c float 16-bit cho táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh. ChÃºng tÃ´i tinh chá»‰nh cÃ¡c mÃ´ hÃ¬nh tá»‘i Ä‘a nÄƒm epoch vÃ  Ä‘Ã¡nh giÃ¡ chÃºng má»—i 0.2âˆ—len(train_set) bÆ°á»›c tá»‘i Æ°u hÃ³a. ChÃºng tÃ´i tinh chá»‰nh táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh vá»›i kÃ­ch thÆ°á»›c batch 8. ChÃºng tÃ´i chá»n checkpoint cÃ³ máº¥t mÃ¡t Ä‘Ã¡nh giÃ¡ tháº¥p nháº¥t cho suy luáº­n vÃ  tháº¥y ráº±ng tÃ¬m kiáº¿m chÃ¹m vá»›i kÃ­ch thÆ°á»›c chÃ¹m 10 mang láº¡i hiá»‡u quáº£ tá»‘t nháº¥t. ÄÆ°a ra phÃ¢n phá»‘i Ä‘á»™ dÃ i token khÃ¡c nhau vÃ  Ä‘á»™ phá»©c táº¡p cá»§a cÃ¡c bá»™ dá»¯ liá»‡u, chÃºng tÃ´i sinh mÃ£ vá»›i tá»‘i Ä‘a 64,

--- TRANG 12 ---
12 â€¢M. Weyssow vÃ  cá»™ng sá»±.
012345 8 16
Sá»‘ vÃ­ dá»¥ ngáº«u nhiÃªn051015202530EM@10
Conala
0 1 2 3 4 5 8
Sá»‘ vÃ­ dá»¥ ngáº«u nhiÃªn024681012EM@10
CodeAlpacaPyCodeLlama-7B-Python
CodeLlama-7B-Instruct
CodeLlama-7BCodeGen2-7B
CodeGen2-3.7B
CodeGen2-1BCodeGen-350M-mono
CodeT5+-770M
CodeT5+-220M
HÃ¬nh 3. [RQ1] â€“ Hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh sá»­ dá»¥ng ICL vá»›i sá»‘ lÆ°á»£ng vÃ­ dá»¥ ngáº«u nhiÃªn khÃ¡c nhau trÃªn cÃ¡c bá»™ dá»¯ liá»‡u Conala vÃ  CodeAlpacaPy.

128, vÃ  1024 token cho Conala, CodeAlpacaPy, vÃ  APPS, tÆ°Æ¡ng á»©ng. ChÃºng tÃ´i cÃ´ng khai mÃ£ cá»§a chÃºng tÃ´i: https://github.com/martin-wey/peft-llm-code.

5 Káº¾T QUáº¢ THÃ NGHIá»†M
5.1 RQ1: Hiá»‡u quáº£ CÆ¡ báº£n cá»§a MÃ´ hÃ¬nh Sá»­ dá»¥ng Zero-Shot vÃ  ICL
ChÃºng tÃ´i báº¯t Ä‘áº§u báº±ng viá»‡c Ä‘iá»u tra hiá»‡u quáº£ cÆ¡ báº£n cá»§a táº¥t cáº£ SLM vÃ  LLM cho sinh mÃ£ dá»±a trÃªn khá»›p. Cá»¥ thá»ƒ, chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c cÃ¡ch tiáº¿p cáº­n zero-shot vÃ  ICL vá»›i tá»‘i Ä‘a 16 vÃ­ dá»¥ ngáº«u nhiÃªn Ä‘Æ°á»£c truy xuáº¥t cho bá»™ dá»¯ liá»‡u Conala vÃ  tÃ¡m cho bá»™ dá»¯ liá»‡u CodeAlpacaPy. LÃ½ do sá»­ dá»¥ng Ã­t vÃ­ dá»¥ hÆ¡n cho CodeAlpacaPy lÃ  vÃ¬ xem xÃ©t 16 vÃ­ dá»¥ dáº«n Ä‘áº¿n lá»—i háº¿t bá»™ nhá»› dÆ°á»›i thiáº¿t láº­p cá»§a chÃºng tÃ´i. ChÃºng tÃ´i Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh sá»­ dá»¥ng EM@10 vÃ  so sÃ¡nh chÃºng trÃªn hai bá»™ dá»¯ liá»‡u nÃ y trong HÃ¬nh 3. LÆ°u Ã½ ráº±ng kiáº¿n trÃºc CodeGen2 dáº«n Ä‘áº¿n viá»‡c sá»­ dá»¥ng bá»™ nhá»› GPU nhiá»u hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c, Ä‘iá»u nÃ y giáº£i thÃ­ch táº¡i sao chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ ICL vá»›i Ã­t vÃ­ dá»¥ hÆ¡n so vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c.

Äáº§u tiÃªn, chÃºng tÃ´i quan sÃ¡t má»™t khoáº£ng cÃ¡ch Ä‘Ã¡ng ká»ƒ trong EM@10 giá»¯a hai bá»™ dá»¯ liá»‡u. Sá»± khÃ¡c biá»‡t nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c giáº£i thÃ­ch bá»Ÿi thá»±c táº¿ lÃ  bá»™ dá»¯ liá»‡u CodeAlpacaPy chá»©a cÃ¡c máº«u thÃ¡ch thá»©c hÆ¡n nhiá»u so vá»›i bá»™ dá»¯ liá»‡u Conala, nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Báº£ng 2.

Thá»© hai, cÃ³ má»™t khoáº£ng cÃ¡ch Ä‘Ã¡ng chÃº Ã½ vá» hiá»‡u quáº£ giá»¯a SLM vÃ  LLM, báº¥t ká»ƒ sá»‘ lÆ°á»£ng vÃ­ dá»¥ Ä‘Æ°á»£c cung cáº¥p. Quan sÃ¡t nÃ y lÃ m ná»•i báº­t nhá»¯ng Æ°u Ä‘iá»ƒm cá»§a tiá»n huáº¥n luyá»‡n quy mÃ´ lá»›n vÃ  viá»‡c sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n trong bá»‘i cáº£nh nÃ y.

Äá»‘i vá»›i bá»™ dá»¯ liá»‡u Conala, viá»‡c tÄƒng sá»‘ lÆ°á»£ng vÃ­ dá»¥ dáº«n Ä‘áº¿n Ä‘iá»ƒm EM@10 cao hÆ¡n. Tuy nhiÃªn, khi sá»­ dá»¥ng nhiá»u hÆ¡n tÃ¡m vÃ­ dá»¥, hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh báº¯t Ä‘áº§u giáº£m. Äá»‘i vá»›i bá»™ dá»¯ liá»‡u CodeAlpacaPy, má»™t xu hÆ°á»›ng tÆ°Æ¡ng tá»± Ä‘Æ°á»£c quan sÃ¡t, nhÆ°ng sá»‘ lÆ°á»£ng vÃ­ dá»¥ tá»‘i Æ°u nhá» hÆ¡n. Háº§u háº¿t cÃ¡c mÃ´ hÃ¬nh Ä‘áº¡t Ä‘iá»ƒm EM@10 tá»‘t nháº¥t khi sá»­ dá»¥ng ba hoáº·c bá»‘n vÃ­ dá»¥. Quan sÃ¡t nÃ y nháº¥n máº¡nh háº¡n cháº¿ cá»§a ICL, vÃ¬ viá»‡c thÃªm nhiá»u vÃ­ dá»¥ hÆ¡n dáº«n Ä‘áº¿n sá»± suy giáº£m hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh.

--- TRANG 13 ---
KhÃ¡m phÃ¡ cÃ¡c Ká»¹ thuáº­t Tinh chá»‰nh Hiá»‡u quáº£ Tham sá»‘ cho Sinh mÃ£ vá»›i MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n â€¢13

Cuá»‘i cÃ¹ng, cÃ¡c mÃ´ hÃ¬nh CodeLlama vÆ°á»£t trá»™i táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh trÃªn cáº£ hai bá»™ dá»¯ liá»‡u, Ä‘áº¡t EM@10 Ä‘á»‰nh 29.83 trÃªn Conala (CodeLlama-7B) vÃ  11.94 trÃªn CodeAlpacaPy (CodeLlama-7B-Python). NgÆ°á»£c láº¡i, cÃ¡c mÃ´ hÃ¬nh nhá» hÆ¡n, nhÆ° CodeGen2-3.7B Ä‘áº¡t EM@10 lÃ  23.94 vÃ  7.00 trÃªn Conala vÃ  CodeAlpacaPy, tÆ°Æ¡ng á»©ng.

Tráº£ lá»i cho RQ1: ICL cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ hiá»‡u quáº£ cá»§a táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh so vá»›i zero-shot. MÃ´ hÃ¬nh tá»‘t nháº¥t cá»§a chÃºng tÃ´i, CodeLlama-7B, Ä‘áº¡t Ä‘iá»ƒm EM@10 29.83 (7.73) vÃ  11.62 (7.01) trÃªn Conala vÃ  CodeAlpacaPy vá»›i ICL (zero-shot), tÆ°Æ¡ng á»©ng.

5.2 RQ2: Hiá»‡u quáº£ cá»§a MÃ´ hÃ¬nh sá»­ dá»¥ng Ká»¹ thuáº­t PEFT
ChÃºng tÃ´i bÃ¡o cÃ¡o káº¿t quáº£ chi tiáº¿t vá» hiá»‡u quáº£ cá»§a SLM vÃ  LLM trÃªn sinh mÃ£ dá»±a trÃªn khá»›p cho cáº£ bá»™ dá»¯ liá»‡u Conala vÃ  CodeAlpacaPy trong Báº£ng 3.

SLM vs. LLM. CodeGen-350M-mono vá»›i LoRA thá»ƒ hiá»‡n hiá»‡u quáº£ tá»‘t nháº¥t trung bÃ¬nh trong sá»‘ cÃ¡c mÃ´ hÃ¬nh nhá», trong khi CodeLlama-7B-Python vá»›i LoRA lÃ  LLM tá»‘t nháº¥t trung bÃ¬nh. DÆ°á»›i cÃ¹ng má»™t háº¡n cháº¿ bá»™ nhá»› GPU 24GB, LLM tá»‘t nháº¥t vÆ°á»£t trá»™i mÃ´ hÃ¬nh nhá» tá»‘t nháº¥t 39.8%, 41.7%, vÃ  47.1% (72.3%, 48.8%, vÃ  9.1%) trong EM@1, EM@10, vÃ  CodeBLEU liÃªn quan Ä‘áº¿n bá»™ dá»¯ liá»‡u Conala (CodeAlpacaPy), tÆ°Æ¡ng á»©ng.

SLM. Trong sá»‘ cÃ¡c SLM, CodeGen-350M-mono cho tháº¥y hiá»‡u quáº£ cao nháº¥t trÃªn táº¥t cáº£ cÃ¡c metrics trÃªn cáº£ hai bá»™ dá»¯ liá»‡u. Káº¿t quáº£ cá»§a chÃºng tÃ´i phÃ¹ há»£p vá»›i cÃ¡c nghiÃªn cá»©u trÆ°á»›c [48,73,91] xÃ¡c Ä‘á»‹nh CodeGen-350M-mono nhÆ° má»™t SLM máº¡nh máº½ cho cÃ¡c tÃ¡c vá»¥ sinh mÃ£ Python. ThÃº vá»‹, máº·c dÃ¹ nÃ³ yÃªu cáº§u tinh chá»‰nh khoáº£ng 1% tá»•ng tham sá»‘ cá»§a mÃ´ hÃ¬nh, LoRA xuáº¥t hiá»‡n nhÆ° ká»¹ thuáº­t tinh chá»‰nh tá»‘t nháº¥t, vÆ°á»£t trá»™i tinh chá»‰nh Ä‘áº§y Ä‘á»§ vá»›i má»™t biÃªn Ä‘á»™ Ä‘Ã¡ng ká»ƒ trÃªn gáº§n nhÆ° táº¥t cáº£ cÃ¡c cáº¥u hÃ¬nh. VÃ­ dá»¥, Ä‘iá»ƒm EM@10 cho CodeGen-350M-mono trÃªn bá»™ dá»¯ liá»‡u Conala, vá»›i tinh chá»‰nh Ä‘áº§y Ä‘á»§, lÃ  18.42, trong khi nÃ³ tÄƒng vá»t lÃªn 25.60 vá»›i LoRA.

LLM. Trong HÃ¬nh 4, chÃºng tÃ´i trÃ¬nh bÃ y phÃ¢n tÃ­ch so sÃ¡nh vá» hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh khi Ä‘Æ°á»£c tinh chá»‰nh sá»­ dá»¥ng LoRA, táº­p trung vÃ o Ä‘iá»ƒm CodeBLEU vÃ  EM@10. Cáº£ hai biá»ƒu Ä‘á»“ Ä‘á»u rÃµ rÃ ng thiáº¿t láº­p cÃ¡c mÃ´ hÃ¬nh CodeLlama nhÆ° LLM hoáº¡t Ä‘á»™ng tá»‘t nháº¥t trong nghiÃªn cá»©u cá»§a chÃºng tÃ´i. ÄÃ¡ng chÃº Ã½, CodeGen2-7B, máº·c dÃ¹ chia sáº» sá»‘ lÆ°á»£ng tham sá»‘ tÆ°Æ¡ng tá»±, thua kÃ©m táº¥t cáº£ cÃ¡c biáº¿n thá»ƒ CodeLlama-7B. KhÃ´ng ngáº¡c nhiÃªn, viá»‡c khai thÃ¡c cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n dáº«n Ä‘áº¿n hiá»‡u quáº£ tá»‘t hÆ¡n. ÄÆ°a ra chi phÃ­ tÃ­nh toÃ¡n tháº¥p cá»§a cÃ¡c ká»¹ thuáº­t PEFT, viá»‡c táº­n dá»¥ng cÃ¡c mÃ´ hÃ¬nh nhá» hÆ¡n trong bá»‘i cáº£nh tÆ°Æ¡ng tá»± nhÆ° cá»§a chÃºng tÃ´i cÃ³ váº» pháº£n tÃ¡c dá»¥ng. Sau Ä‘Ã³, trong bÃ i bÃ¡o nÃ y, chÃºng tÃ´i chá»©ng minh ráº±ng ngay cáº£ cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n cÃ³ thá»ƒ Ä‘Æ°á»£c tinh chá»‰nh thÃ´ng qua sá»± káº¿t há»£p cá»§a PEFT vá»›i lÆ°á»£ng tá»­ hÃ³a.

Ká»¹ thuáº­t PEFT tá»‘t nháº¥t. NhÃ¬n chung, LoRA ná»•i lÃªn nhÆ° ká»¹ thuáº­t PEFT hiá»‡u quáº£ nháº¥t trong sá»‘ nhá»¯ng ká»¹ thuáº­t Ä‘Æ°á»£c nghiÃªn cá»©u. Máº·c dÃ¹ Ä‘Æ°á»£c trÃ¬nh bÃ y nhÆ° má»™t cáº£i thiá»‡n tÄƒng dáº§n so vá»›i LoRA [37], IA3 thÆ°á»ng cho tháº¥y Ä‘iá»ƒm tháº¥p hÆ¡n so vá»›i LoRA. Prompt tuning xuáº¥t hiá»‡n nhÆ° má»™t tÃ¹y chá»n tinh chá»‰nh kháº£ thi khÃ¡c, trong khi giáº£m thÃªm sá»‘ lÆ°á»£ng tham sá»‘ cÃ³ thá»ƒ huáº¥n luyá»‡n. Tuy nhiÃªn, Prefix tuning tháº¥t báº¡i trong viá»‡c thÃ­ch á»©ng hiá»‡u quáº£ cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n vá»›i cáº£ hai bá»™ dá»¯ liá»‡u.

PhÃ¢n tÃ­ch cá»§a chÃºng tÃ´i tiáº¿t lá»™ Ä‘iá»ƒm EM cao hÆ¡n Ä‘Ã¡ng ká»ƒ cho bá»™ dá»¯ liá»‡u Conala, cÃ³ thá»ƒ Ä‘Æ°á»£c quy cho sá»± khÃ¡c biá»‡t vá» Ä‘á»™ phá»©c táº¡p tÃ¡c vá»¥ giá»¯a hai bá»™ dá»¯ liá»‡u (xem Pháº§n 4.2). Äiá»u quan trá»ng cáº§n lÆ°u Ã½ lÃ  Ä‘iá»ƒm CodeBLEU trÃªn Conala tÆ°Æ¡ng Ä‘á»‘i tháº¥p hÆ¡n do sá»± phá»¥ thuá»™c cá»§a metric vÃ o tÃ­nh toÃ¡n Ä‘á»“ thá»‹ luá»“ng dá»¯ liá»‡u, cÃ³ thá»ƒ khÃ´ng pháº£i lÃºc nÃ o cÅ©ng cÃ³ sáºµn cho cÃ¡c vÃ­ dá»¥ mÃ£ nhá».

--- TRANG 14 ---
14 â€¢M. Weyssow vÃ  cá»™ng sá»±.
Báº£ng 3. [RQ2] â€“ So sÃ¡nh SLM vÃ  LLM sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t tinh chá»‰nh khÃ¡c nhau (xanh: phÆ°Æ¡ng phÃ¡p tinh chá»‰nh hoáº¡t Ä‘á»™ng tá»‘t nháº¥t má»—i mÃ´ hÃ¬nh, cam: mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng tá»‘t nháº¥t tá»•ng thá»ƒ).

Conala CodeAlpacaPy
MÃ´ hÃ¬nh Tinh chá»‰nh # Params EM@1 EM@10 CodeBLEU EM@1 EM@10 CodeBLEU
SLMs
CodeT5+-220M Tinh chá»‰nh Ä‘áº§y Ä‘á»§ 220M 3.87 8.84 16.70 3.98 7.64 25.49
LoRA 2.7M 6.08 12.71 18.96 3.34 5.26 24.32
IA3 0.17M 4.42 10.68 17.08 0.64 1.27 22.06
Prompt tuning 0.03M 4.79 9.21 16.30 0.96 2.07 19.01
Prefix tuning 0.18M 3.13 7.55 14.56 0.16 1.27 20.80
CodeT5+-770M Tinh chá»‰nh Ä‘áº§y Ä‘á»§ 770M 4.05 8.29 15.11 3.19 6.21 27.73
LoRA 7M 8.66 17.13 20.64 3.66 6.85 26.10
IA3 0.4M 8.10 17.50 18.68 2.87 5.26 25.84
Prompt tuning 0.04M 7.37 15.47 16.75 1.91 3.82 20.57
Prefix tuning 0.5M 4.97 11.97 16.77 0.16 1.27 22.91
CodeGen-350M-mono Tinh chá»‰nh Ä‘áº§y Ä‘á»§ 350M 7.92 18.42 14.68 2.23 5.73 21.78
LoRA 1.3M 12.52 25.60 17.89 4.62 10.70 30.09
IA3 0.16M 11.42 25.78 18.83 4.46 10.70 28.56
Prompt tuning 0.02M 7.92 20.26 16.29 0.0 0.0 25.91
Prefix tuning 0.4M 5.34 12.52 17.53 0.0 0.0 26.89
LLMs
CodeGen2-1B LoRA 2M 9.39 23.02 19.76 3.82 9.08 23.48
IA3 0.2M 10.13 22.84 18.64 3.82 9.87 24.42
Prompt tuning 0.04M 11.97 22.65 18.38 0.80 2.07 18.17
Prefix tuning 0.6M 5.89 15.84 18.46 0.0 0.32 13.68
CodeGen2-3.7B LoRA 4M 11.60 25.97 19.00 5.41 10.70 23.75
IA3 0.5M 10.87 25.23 19.21 5.41 10.99 26.26
Prompt tuning 0.08M 11.05 26.89 19.53 0.0 0.0 23.42
Prefix tuning 1.3M 10.68 24.68 20.23 0.16 0.32 21.73
CodeGen2-7B LoRA 8.3M 11.23 29.83 23.86 5.57 11.94 27.73
IA3 1M 11.42 29.65 21.98 5.73 12.42 28.26
Prompt tuning 0.08M 11.97 27.26 22.37 0.0 0.0 25.40
Prefix tuning 2.6M 9.95 23.94 22.29 0.0 0.32 25.72
CodeLlama-7B LoRA 12.5M 20.07 39.31 25.33 7.33 16.24 32.05
IA3 1M 17.68 37.20 23.19 8.12 15.45 30.47
Prompt tuning 0.08M 19.15 38.12 25.01 0.32 0.48 31.55
Prefix tuning 2.6M 8.47 19.52 23.19 0.16 0.16 28.09
CodeLlama-7B-Instruct LoRA 12.5M 17.68 36.28 24.27 7.01 17.04 31.42
IA3 1M 15.84 36.10 24.71 8.12 16.72 31.01
Prompt tuning 0.08M 18.97 35.54 25.77 1.59 3.50 31.14
Prefix tuning 2.6M 10.13 18.23 23.66 0.64 0.96 31.27
CodeLlama-7B-Python LoRA 12.5M 17.50 36.28 24.27 7.96 15.92 32.84
IA3 1M 14.55 31.12 24.74 8.76 16.56 29.82
Prompt tuning 0.08M 16.76 37.02 26.31 0.96 3.03 33.46
Prefix tuning 2.6M 9.76 22.47 19.47 0.0 0.0 30.71

--- TRANG 15 ---
KhÃ¡m phÃ¡ cÃ¡c Ká»¹ thuáº­t Tinh chá»‰nh Hiá»‡u quáº£ Tham sá»‘ cho Sinh mÃ£ vá»›i MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n â€¢15
15 20 25 30 35
EM@101819202122232425CodeBLEU
CodeT5+-220MCodeT5+-770M
CodeGen2-1B
CodeGen-350M-monoCodeGen2-3.7BCodeGen2-7BCodeLlama-7B-PythonCodeLlama-7B-InstructCodeLlama-7B
(a) Conala
6 8 10 12 14 16
EM@102426283032CodeBLEU
CodeT5+-220MCodeT5+-770M
CodeGen2-1BCodeGen2-3.7BCodeGen-350M-mono
CodeGen2-7BCodeLlama-7BCodeLlama-7B-Python
CodeLlama-7B-Instruct (b) CodeAlpacaPy
HÃ¬nh 4. [RQ2] â€“ Hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tinh chá»‰nh sá»­ dá»¥ng LoRA cho cáº£ hai bá»™ dá»¯ liá»‡u vá» EM@10 vÃ  CodeBLEU.

TÃ¡c Ä‘á»™ng cá»§a lÆ°á»£ng tá»­ hÃ³a vá»›i QLoRA. ChÃºng tÃ´i khÃ¡m phÃ¡ nhá»¯ng lá»£i Ã­ch tiá»m nÄƒng cá»§a viá»‡c sá»­ dá»¥ng QLoRA [13], má»™t ká»¹ thuáº­t hiá»‡u quáº£ vá» máº·t tÃ­nh toÃ¡n káº¿t há»£p LoRA vá»›i lÆ°á»£ng tá»­ hÃ³a 8-bit hoáº·c 4-bit Ä‘á»ƒ tinh chá»‰nh LLM. Trong HÃ¬nh 5, chÃºng tÃ´i hiá»ƒn thá»‹ Ä‘iá»ƒm EM@10 cho ba biáº¿n thá»ƒ mÃ´ hÃ¬nh CodeLlama: CodeLlama-7B-Python, CodeLlama-13B-Python, vÃ  CodeLlama-34B-Python, cÃ¹ng vá»›i má»©c tiÃªu thá»¥ bá»™ nhá»› GPU Ä‘á»‰nh luÃ´n dÆ°á»›i 24GB cho má»—i cáº¥u hÃ¬nh tinh chá»‰nh. Káº¿t quáº£ nháº¥n máº¡nh sá»± cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ vá» hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh lÆ°á»£ng tá»­ hÃ³a lá»›n hÆ¡n trÃªn Conala, vá»›i tÃ¡c Ä‘á»™ng vá»«a pháº£i hÆ¡n trÃªn CodeAlpacaPy. VÃ­ dá»¥, CodeLlama-34B-Python, Ä‘Æ°á»£c tinh chá»‰nh vá»›i QLoRA-4bit, Ä‘áº¡t Ä‘Æ°á»£c sá»± gia tÄƒng Ä‘Ã¡ng ká»ƒ 12.2% trong Ä‘iá»ƒm EM@10 cá»§a Conala (40.70) so vá»›i CodeLlama-7B-Python vá»›i LoRA (36.28). ÄÃ¡ng ngáº¡c nhiÃªn, QLoRA cÅ©ng mang láº¡i nhá»¯ng cáº£i thiá»‡n Ä‘Ã¡ng chÃº Ã½ so vá»›i LoRA cho CodeLlama-7B-Python trÃªn Conala, trong khi Ä‘áº¡t káº¿t quáº£ tÆ°Æ¡ng Ä‘Æ°Æ¡ng trÃªn CodeAlpacaPy. Viá»‡c Ã¡p dá»¥ng lÆ°á»£ng tá»­ hÃ³a cho phÃ©p sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n cÃ³ thá»ƒ Ä‘Æ°á»£c chá»©a trong má»™t GPU 24GB duy nháº¥t. Cá»¥ thá»ƒ, Ä‘á»‘i vá»›i CodeLlama-7B-Python, QLoRA-4bit Ä‘áº¡t Ä‘Æ°á»£c sá»± giáº£m 2x Ä‘Ã¡ng ká»ƒ vá» viá»‡c sá»­ dá»¥ng bá»™ nhá»› Ä‘á»‰nh trong khi cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ Ä‘iá»ƒm EM@10.

Tráº£ lá»i cho RQ2: LLM vá»›i PEFT liÃªn tá»¥c vÃ  Ä‘Ã¡ng ká»ƒ vÆ°á»£t trá»™i SLM dÆ°á»›i cÃ¹ng má»™t giá»›i háº¡n GPU. Cá»¥ thá»ƒ, LLM hoáº¡t Ä‘á»™ng tá»‘t nháº¥t vá»›i PEFT vÆ°á»£t trá»™i mÃ´ hÃ¬nh nhá» tá»‘t nháº¥t 39.8â€“72.3% vá» EM@k. Trong sá»‘ cÃ¡c ká»¹ thuáº­t PEFT khÃ¡c nhau, LoRA lÃ  hiá»‡u quáº£ nháº¥t. NgoÃ i ra, viá»‡c Ã¡p dá»¥ng lÆ°á»£ng tá»­ hÃ³a vá»›i LoRA dáº«n Ä‘áº¿n sá»± giáº£m Ä‘Ã¡ng ká»ƒ vá» viá»‡c sá»­ dá»¥ng GPU trong khi duy trÃ¬ hiá»‡u quáº£ trÃªn cáº£ hai bá»™ dá»¯ liá»‡u vÃ  chá»©a viá»‡c tinh chá»‰nh cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n lÃªn Ä‘áº¿n 34B tham sá»‘.

5.3 RQ3: PhÃ¢n tÃ­ch So sÃ¡nh LoRA, ICL, vÃ  RAG
Trong RQ nÃ y, chÃºng tÃ´i nháº±m Ä‘iá»u tra liá»‡u cÃ¡c ká»¹ thuáº­t PEFT cÃ³ liÃªn tá»¥c vÆ°á»£t trá»™i ICL vÃ  RAG Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i khi Ã¡p dá»¥ng LLM trong sinh mÃ£ dá»±a trÃªn khá»›p khÃ´ng.

Trong HÃ¬nh 6, chÃºng tÃ´i so sÃ¡nh hiá»‡u quáº£ cá»§a SLM vÃ  LLM sá»­ dá»¥ng ICL vÃ  LoRA vá» CodeBLEU vÃ  EM@10. Trong hÃ¬nh nÃ y, chÃºng tÃ´i bÃ¡o cÃ¡o cÃ¡c metrics cao nháº¥t Ä‘áº¡t Ä‘Æ°á»£c qua cÃ¡c cáº¥u hÃ¬nh ICL khÃ¡c nhau cho má»—i mÃ´ hÃ¬nh. Trong HÃ¬nh 7, chÃºng tÃ´i khÃ¡m phÃ¡ hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh CodeLlama sá»­ dá»¥ng RAG, vá»›i tá»‘i Ä‘a 16 vÃ  4 vÃ­ dá»¥ Ä‘Æ°á»£c truy xuáº¥t cho Conala vÃ  CodeAlpacaPy, tÆ°Æ¡ng á»©ng. TÆ°Æ¡ng tá»± nhÆ° RQ1, chÃºng tÃ´i sá»­ dá»¥ng Ã­t vÃ­ dá»¥ hÆ¡n cho CodeAlpacaPy Ä‘á»ƒ trÃ¡nh lá»—i háº¿t bá»™ nhá»›. ChÃºng tÃ´i so sÃ¡nh hiá»‡u quáº£ cá»§a RAG vá»›i LoRA vÃ  Ä‘iá»ƒm EM@10 tá»‘t nháº¥t Ä‘áº¡t Ä‘Æ°á»£c sá»­ dá»¥ng ICL.

LoRA vs. ICL. NhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh 6, táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tinh chá»‰nh vá»›i LoRA thá»ƒ hiá»‡n Ä‘iá»ƒm EM@10 cao hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i ICL trÃªn cáº£ hai bá»™ dá»¯ liá»‡u. VÃ­ dá»¥, CodeLlama-7B-Python vá»›i tinh chá»‰nh LoRA Ä‘áº¡t Ä‘Æ°á»£c sá»± cáº£i thiá»‡n 23.1% vá» EM@10 trÃªn Conala (36.28 cho LoRA vs. 29.47 cho ICL). MÃ´ hÃ¬nh nÃ y

--- TRANG 16 ---
16 â€¢M. Weyssow vÃ  cá»™ng sá»±.
CL-7B CL-13B CL-34B303234363840EM@1036.337.438.5
37.838.140.7Conala
CL-7B CL-13B CL-34B05101515.916.417.4
15.816.417.4CodeAlpacaPy
0
10
20GPU peak (GB)24 GB0
10
2024 GBLoRA QLoRA-8bit QLoRA-4bit
HÃ¬nh 5. [RQ2] â€“ Hiá»‡u quáº£ vÃ  viá»‡c sá»­ dá»¥ng GPU cá»§a cÃ¡c LLM CodeLlama-Python (CL) 7B, 13B, vÃ  34B Ä‘Æ°á»£c tinh chá»‰nh sá»­ dá»¥ng LoRA vÃ  QLoRA vá»›i lÆ°á»£ng tá»­ hÃ³a 8-bit vÃ  4-bit.

0 510 15 20 25 30 35 40
EM@10121518212427CodeBLEUConala
Tinh chá»‰nh
LoRA
ICL
0 3 6 9 12 15
EM@101820222426283032CodeBLEUCodeAlpacaPyCodeT5+-220M
CodeT5+-770M
CodeGen-350M-monoCodeGen2-1B
CodeGen2-3.7B
CodeGen2-7BCodeLlama-7B
CodeLlama-7B-Instruct
CodeLlama-7B-Python
HÃ¬nh 6. [RQ3] â€“ So sÃ¡nh hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tinh chá»‰nh sá»­ dá»¥ng LoRA vÃ  ICL trÃªn cÃ¡c bá»™ dá»¯ liá»‡u Conala vÃ  CodeAlpacaPy.

mÃ´ hÃ¬nh giá»¯ cho CodeAlpacaPy, vá»›i nhá»¯ng lá»£i Ã­ch tÆ°Æ¡ng Ä‘á»‘i lá»›n hÆ¡n vá» EM@10. Tuy nhiÃªn, chÃºng tÃ´i quan sÃ¡t má»™t sá»‘ biáº¿n thiÃªn trong Ä‘iá»ƒm CodeBLEU cho háº§u háº¿t cÃ¡c mÃ´ hÃ¬nh trÃªn CodeAlpacaPy. VÃ­ dá»¥, CodeLlama-7B tháº¥y sá»± gia tÄƒng CodeBLEU 2.36 vá»›i LoRA. Tuy nhiÃªn, trÃªn CoNala, tÃ¡c Ä‘á»™ng cá»§a LoRA Ä‘á»‘i vá»›i CodeBLEU Ã­t rÃµ rÃ ng hÆ¡n so vá»›i ICL. Nhá»¯ng khÃ¡c biá»‡t nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c giáº£i thÃ­ch bá»Ÿi báº£n cháº¥t cá»§a cÃ¡c metrics: EM@10 báº£o thá»§ hÆ¡n, yÃªu cáº§u giáº£i phÃ¡p Ä‘Æ°á»£c sinh pháº£i khá»›p chÃ­nh xÃ¡c vá»›i thá»±c táº¿, trong khi CodeBLEU cho Ä‘iá»ƒm cao hÆ¡n cho cÃ¡c giáº£i phÃ¡p gáº§n nhÆ°ng khÃ´ng chÃ­nh xÃ¡c. Sá»± phÃ¢n biá»‡t nÃ y lÃ m ná»•i báº­t cÃ¡ch LoRA thÃ­ch á»©ng tá»‘t hÆ¡n cÃ¡c mÃ´ hÃ¬nh vá»›i cÃ¡c bá»™ dá»¯ liá»‡u háº¡ nguá»“n, Ä‘áº·c biá»‡t khi Ä‘á»™ chÃ­nh xÃ¡c lÃ  quan trá»ng.

RAG vs. ICL vs. LoRA. Trong viá»‡c so sÃ¡nh RAG, ICL, vÃ  LoRA trÃªn bá»™ dá»¯ liá»‡u CoNala, RAG thá»ƒ hiá»‡n hiá»‡u quáº£ cao hÆ¡n ICL nhÆ°ng khÃ´ng Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u quáº£ cá»§a LoRA trÃªn táº¥t cáº£ ba biáº¿n thá»ƒ mÃ´ hÃ¬nh CodeLlama. ÄÃ¡ng chÃº Ã½, CodeLlama-7B Ä‘áº¡t tá»‘i Ä‘a 29.83 vÃ  35.17 EM@10 vá»›i ICL vÃ  RAG, tÆ°Æ¡ng á»©ng, trong khi mÃ´ hÃ¬nh Ä‘Æ°á»£c tinh chá»‰nh vá»›i LoRA Ä‘áº¡t EM@10 39.31.

Äá»‘i vá»›i cáº£ bá»™ dá»¯ liá»‡u Conala vÃ  CodeAlpacaPy, nhá»¯ng lá»£i Ã­ch vá» EM@10 trá»Ÿ nÃªn má»ng hÆ¡n khi chÃºng tÃ´i tÄƒng sá»‘ lÆ°á»£ng vÃ­ dá»¥ sá»­ dá»¥ng RAG. EM@10 bÃ£o hÃ²a á»Ÿ khoáº£ng 8â€“16 vÃ­ dá»¥ cho Conala vÃ  3â€“4 vÃ­ dá»¥ cho CodeAlpacaPy. HÆ¡n ná»¯a, chÃºng tÃ´i lÆ°u Ã½ ráº±ng Ä‘á»‘i vá»›i bá»™ dá»¯ liá»‡u CodeAlpacaPy thÃ¡ch thá»©c hÆ¡n, RAG mang láº¡i EM@10 tháº¥p hÆ¡n so vá»›i cÃ¡c vÃ­ dá»¥ Ä‘Æ°á»£c chá»n ngáº«u nhiÃªn sá»­ dá»¥ng ICL, lÃ m ná»•i báº­t nhá»¯ng háº¡n cháº¿ cá»§a RAG khi Ä‘á»™ phá»©c táº¡p váº¥n Ä‘á» tÄƒng. Tuy nhiÃªn, LoRA liÃªn tá»¥c vÆ°á»£t trá»™i cáº£ RAG vÃ  ICL trÃªn CodeAlpacaPy, lÃ m ná»•i báº­t kháº£ nÄƒng vÆ°á»£t trá»™i cá»§a nÃ³ trong viá»‡c thÃ­ch á»©ng vá»›i cÃ¡c bá»™ dá»¯ liá»‡u thÃ¡ch thá»©c hÆ¡n.

Tráº£ lá»i cho RQ3: LoRA vÆ°á»£t trá»™i ICL vÃ  RAG trÃªn cÃ¡c bá»™ dá»¯ liá»‡u Conala vÃ  CodeAlpacaPy trÃªn ba biáº¿n thá»ƒ CodeLlama-7B.

--- TRANG 17 ---
17 â€¢M. Weyssow vÃ  cá»™ng sá»±.
010203040EM@10LoRA: 39.31
ICL: 29.83LoRA: 36.28
ICL: 27.99LoRA: 36.28
ICL: 29.47
CL-7B CL-7B-Instruct CL-7B-Python051015EM@10LoRA: 16.24
ICL: 11.62LoRA: 17.04
ICL: 10.35LoRA: 15.92
ICL: 11.94# VÃ­ dá»¥
1
2
3
4
5
8
16
HÃ¬nh 7. [RQ3] â€“ So sÃ¡nh hiá»‡u quáº£ cá»§a RAG vá»›i sá»‘ lÆ°á»£ng vÃ­ dá»¥ Ä‘Æ°á»£c truy xuáº¥t khÃ¡c nhau Ä‘á»‘i vá»›i ICL vÃ  LoRA trÃªn cÃ¡c bá»™ dá»¯ liá»‡u Conala (trÃªn) vÃ  CodeAlpacaPy (dÆ°á»›i). Äiá»ƒm ICL mÃ´ táº£ Ä‘iá»ƒm cao nháº¥t Ä‘áº¡t Ä‘Æ°á»£c cho má»—i mÃ´ hÃ¬nh trong RQ1.

--- TRANG 18 ---
18 â€¢M. Weyssow vÃ  cá»™ng sá»±.
Báº£ng 4. [RQ4] â€“ Hiá»‡u quáº£ cá»§a CodeLlama-7B-Instruct trÃªn bá»™ dá»¯ liá»‡u APPs trong zero-shot vÃ  sá»­ dá»¥ng LoRA, QLoRA-8bit, vÃ  QLoRA-4bit vá» sá»‘ test Ä‘Ã£ qua trung bÃ¬nh (Avg) vÃ  Pass@k (P@k).

Giá»›i thiá»‡u Phá»ng váº¥n Thi Ä‘áº¥u
MÃ´ hÃ¬nh Avg P@1 P@2 P@5 Avg P@1 P@2 P@5 Avg P@1 P@2 P@5
CodeLlama-7B-Instruct 13.66 4.16 6.24 8.80 13.44 0.80 1.32 2.40 6.27 0.56 1.00 2.00
+LoRA 19.57 5.60 8.04 11.20 16.96 1.04 1.80 3.20 6.93 0.32 0.60 1.20
+QLoRA-8bit 17.63 3.68 5.40 7.60 15.53 1.04 1.64 2.40 7.59 0.24 0.48 1.20
+QLoRA-4bit 20.84 5.76 8.40 12.40 20.34 1.04 1.76 2.80 6.66 0.48 0.88 1.60

5.4 RQ4: KhÃ¡m phÃ¡ LoRA vÃ  QLoRA cho Sinh mÃ£ trÃªn APPs
Trong RQ cuá»‘i cÃ¹ng nÃ y, chÃºng tÃ´i khÃ¡m phÃ¡ kháº£ nÄƒng Ã¡p dá»¥ng rá»™ng hÆ¡n cá»§a LoRA vÃ  QLoRA, Ä‘á»ƒ tÄƒng cÆ°á»ng hiá»‡u quáº£ cá»§a CodeLlama-7B-Instruct cho sinh mÃ£ dá»±a trÃªn thá»±c thi. LÃ½ do chá»n biáº¿n thá»ƒ instruct cá»§a CodeLlama-7B lÃ  vÃ¬ mÃ´ hÃ¬nh nÃ y thÆ°á»ng cho tháº¥y hiá»‡u quáº£ cao hÆ¡n so vá»›i cÃ¡c biáº¿n thá»ƒ mÃ´ hÃ¬nh khÃ¡c trÃªn APPs trong bÃ i bÃ¡o tiÃªn phong cá»§a CodeLlama [56]. ChÃºng tÃ´i khÃ´ng so sÃ¡nh LoRA vÃ  QLoRA vá»›i ICL vÃ  RAG cho bá»™ dá»¯ liá»‡u nÃ y vÃ¬ chÃºng yÃªu cáº§u tÄƒng Ä‘á»™ dÃ i prompt vÆ°á»£t quÃ¡ 2,048 token, dáº«n Ä‘áº¿n lá»—i háº¿t bá»™ nhá»›. Káº¿t quáº£ cá»§a chÃºng tÃ´i, Ä‘Æ°á»£c tÃ³m táº¯t trong Báº£ng 4, táº­p trung vÃ o sá»‘ lÆ°á»£ng test case Ä‘Ã£ qua trung bÃ¬nh (Avg) vÃ  Pass@k cho cÃ¡c tÃ¡c vá»¥ cáº¥p Ä‘á»™ giá»›i thiá»‡u, phá»ng váº¥n, vÃ  thi Ä‘áº¥u.

Äá»‘i vá»›i cáº£ tÃ¡c vá»¥ sinh mÃ£ cáº¥p Ä‘á»™ giá»›i thiá»‡u vÃ  phá»ng váº¥n, LoRA vÃ  QLoRA-8/4bit dáº«n Ä‘áº¿n nhá»¯ng cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ vá» sá»‘ lÆ°á»£ng test case Ä‘Ã£ qua trung bÃ¬nh. Cá»¥ thá»ƒ, QLoRA-4bit dáº«n Ä‘áº¿n sá»± gia tÄƒng Ä‘Ã¡ng chÃº Ã½ 52% vá» sá»‘ lÆ°á»£ng test Ä‘Ã£ qua trung bÃ¬nh so vá»›i mÃ´ hÃ¬nh cÆ¡ sá»Ÿ. Vá» cÃ¡c metrics Pass@k, cáº£ LoRA vÃ  QLoRA-4bit Ä‘á»u thá»ƒ hiá»‡n lá»£i Ã­ch á»Ÿ cáº¥p Ä‘á»™ giá»›i thiá»‡u, vá»›i Pass@5 cáº£i thiá»‡n +3.60% so vá»›i mÃ´ hÃ¬nh cÆ¡ sá»Ÿ. Tuy nhiÃªn, nhá»¯ng cáº£i thiá»‡n nÃ y Ã­t Ä‘Ã¡ng ká»ƒ hÆ¡n cho sinh mÃ£ cáº¥p Ä‘á»™ phá»ng váº¥n vÃ  thi Ä‘áº¥u, pháº£n Ã¡nh Ä‘á»™ phá»©c táº¡p vÃ  thÃ¡ch thá»©c lá»›n hÆ¡n do nhá»¯ng tÃ¡c vá»¥ tiÃªn tiáº¿n hÆ¡n nÃ y Ä‘áº·t ra.

Tráº£ lá»i cho RQ4: LoRA vÃ  QLoRA tÄƒng cÆ°á»ng hiá»‡u quáº£ cá»§a CodeLlama-7B-Instruct trÃªn APPs, Ä‘áº·c biá»‡t á»Ÿ cáº¥p Ä‘á»™ giá»›i thiá»‡u, vá»›i QLoRA-4bit tÄƒng sá»‘ lÆ°á»£ng test case Ä‘Ã£ qua trung bÃ¬nh 52% vÃ  Pass@5 40%. Tuy nhiÃªn, nhá»¯ng cáº£i thiá»‡n Ã­t Ä‘Ã¡ng chÃº Ã½ hÆ¡n cho cÃ¡c tÃ¡c vá»¥ cáº¥p Ä‘á»™ phá»ng váº¥n vÃ  thi Ä‘áº¥u.

6 THáº¢O LUáº¬N
NghiÃªn cá»©u cá»§a chÃºng tÃ´i khÃ¡m phÃ¡ PEFT Ã¡p dá»¥ng cho LLM mÃ£, lÃ m sÃ¡ng tá» tÃ¡c Ä‘á»™ng tÃ­ch cá»±c cá»§a nhá»¯ng á»©ng dá»¥ng nÃ y trong viá»‡c tinh chá»‰nh LLM hiá»‡u quáº£ cho cÃ¡c bá»™ dá»¯ liá»‡u cá»¥ thá»ƒ tÃ¡c vá»¥ sinh mÃ£. Äáº·c biá»‡t, nghiÃªn cá»©u cá»§a chÃºng tÃ´i minh há»a tÃ­nh thá»±c tiá»…n cá»§a viá»‡c tinh chá»‰nh LLM sá»­ dá»¥ng PEFT, do Ä‘Ã³ giáº£m bá»›t sá»± phá»¥ thuá»™c cá»§a cÃ¡c nhÃ  thá»±c hÃ nh vÃ o cÆ¡ sá»Ÿ háº¡ táº§ng lá»›n vÃ  Ä‘áº¯t tiá»n. Nhá»¯ng phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i cÅ©ng chá»‰ ra má»™t sá»‘ lÄ©nh vá»±c Ä‘áº§y há»©a háº¹n cho khÃ¡m phÃ¡ tÆ°Æ¡ng lai, bao gá»“m Ä‘iá»u tra cÃ¡c ká»¹ thuáº­t hiá»‡u quáº£ trÃªn cÃ¡c cÃ i Ä‘áº·t tinh chá»‰nh Ä‘a dáº¡ng, trong quÃ¡ trÃ¬nh suy luáº­n, vÃ  cho cÃ¡c tÃ¡c vá»¥ SE khÃ¡c.

Ká»¹ thuáº­t hiá»‡u quáº£ cho LLM cá»§a mÃ£. CÃ´ng trÃ¬nh cá»§a chÃºng tÃ´i nháº¥n máº¡nh cÃ¡c ká»¹ thuáº­t tinh chá»‰nh hiá»‡u quáº£, dÃ¢n chá»§ hÃ³a viá»‡c tinh chá»‰nh LLM cho Ä‘á»‘i tÆ°á»£ng rá»™ng. Tuy nhiÃªn, nghiÃªn cá»©u cá»§a chÃºng tÃ´i khÃ´ng bao gá»“m khÃ¡m phÃ¡ cÃ¡c ká»¹ thuáº­t hiá»‡u quáº£ cho suy luáº­n chi phÃ­ tháº¥p. Trong khi cÃ¡c ká»¹ thuáº­t PEFT yÃªu cáº§u thá»i gian tinh chá»‰nh bá»• sung so vá»›i ICL vÃ  RAG, Ä‘Ã¡ng chÃº Ã½ lÃ  nhá»¯ng ká»¹ thuáº­t nÃ y khÃ´ng Ã¡p Ä‘áº·t báº¥t ká»³ chi phÃ­ thá»i gian bá»• sung nÃ o trong quÃ¡ trÃ¬nh suy luáº­n. Tuy nhiÃªn, chÃºng tÃ´i thá»«a nháº­n sá»± cáº§n thiáº¿t cá»§a cÃ¡c Ä‘iá»u tra tÆ°Æ¡ng lai vá» cÃ¡c ká»¹ thuáº­t Ä‘á»ƒ giáº£m chi phÃ­ thá»i gian liÃªn quan Ä‘áº¿n LLM trong quÃ¡ trÃ¬nh suy luáº­n.

PEFT vÃ  ICL/RAG lÃ  cÃ¡c ká»¹ thuáº­t khÃ´ng loáº¡i trá»« cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cÃ¹ng nhau. Tuy nhiÃªn, chÃºng tÃ´i quyáº¿t Ä‘á»‹nh khÃ´ng bao gá»“m thÃ­ nghiá»‡m vá» viá»‡c Ã¡p dá»¥ng ICL/RAG cho LLM Ä‘Æ°á»£c tinh chá»‰nh sá»­ dá»¥ng PEFT. Trong thá»±c táº¿, viá»‡c tÄƒng sá»‘ lÆ°á»£ng vÃ­ dá»¥ ICL/RAG táº¡i thá»i Ä‘iá»ƒm suy luáº­n Ä‘Ã²i há»i tÄƒng chi phÃ­ tÃ­nh toÃ¡n khi Ä‘á»™ dÃ i token cá»§a prompt má»Ÿ rá»™ng. Do Ä‘Ã³, chÃºng tÃ´i cho ráº±ng viá»‡c sá»­ dá»¥ng ICL/RAG trÃªn má»™t LLM Ä‘Æ°á»£c tinh chá»‰nh cÃ³ thá»ƒ pháº£n tÃ¡c dá»¥ng lÃ m tÄƒng nhu cáº§u tÃ­nh toÃ¡n, vÆ°á»£t quÃ¡ nhá»¯ng lá»£i Ã­ch tiá»m nÄƒng.

Tá»« má»™t gÃ³c Ä‘á»™ khÃ¡c, cÃ¡c nghiÃªn cá»©u trÆ°á»›c [18,78,83] nháº¥n máº¡nh nhu cáº§u xem xÃ©t cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n vÃ  LLM cá»§a mÃ£ trong cÃ¡c cÃ i Ä‘áº·t há»c liÃªn tá»¥c. Trong mÃ´ hÃ¬nh nÃ y, mÃ´ hÃ¬nh pháº£i thÃ­ch á»©ng Ä‘á»™ng vá»›i dá»¯ liá»‡u má»›i theo thá»i gian trong khi báº£o toÃ n hiá»‡u suáº¥t trÃªn dá»¯ liá»‡u Ä‘Ã£ tháº¥y trÆ°á»›c Ä‘Ã³. Trong cÃ i Ä‘áº·t cá»¥ thá»ƒ cá»§a LLM phÃ¡t triá»ƒn liÃªn tá»¥c, cÃ¡c ká»¹ thuáº­t PEFT cÃ³ kháº£ nÄƒng cung cáº¥p nhá»¯ng lá»£i Ã­ch cÃ³ giÃ¡ trá»‹. Tuy nhiÃªn, váº«n chÆ°a Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh liá»‡u cÃ¡c ká»¹ thuáº­t PEFT cÃ³ thá»ƒ thÃ­ch á»©ng hiá»‡u quáº£ LLM dÆ°á»›i cÃ i Ä‘áº·t há»c liÃªn tá»¥c cho cÃ¡c tÃ¡c vá»¥ liÃªn quan Ä‘áº¿n mÃ£, mÃ  khÃ´ng lÃ m tá»•n háº¡i Ä‘áº¿n viá»‡c giá»¯ láº¡i kiáº¿n thá»©c quÃ¡ khá»©.

Hiá»‡u quáº£ cá»§a QLoRA. TrÃªn táº¥t cáº£ cÃ¡c bá»™ dá»¯ liá»‡u nghiÃªn cá»©u, chÃºng tÃ´i quan sÃ¡t ráº±ng QLoRA-4bit thá»ƒ hiá»‡n hiá»‡u quáº£ cáº¡nh tranh hoáº·c tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p PEFT khÃ¡c. ÄÃ¡ng chÃº Ã½, QLoRA-4bit vÆ°á»£t trá»™i LoRA vÃ  QLoRA-8bit trÃªn cÃ¡c bá»™ dá»¯ liá»‡u Conala vÃ  APPs. ChÃºng tÃ´i giáº£ thuyáº¿t ráº±ng sá»± cáº£i thiá»‡n nÃ y báº¯t nguá»“n tá»« hiá»‡u á»©ng Ä‘iá»u hÃ²a cá»§a viá»‡c giáº£m Ä‘á»™ chÃ­nh xÃ¡c trá»ng sá»‘ xuá»‘ng 4 bit, giÃºp á»•n Ä‘á»‹nh tinh chá»‰nh vÃ  giáº£m thiá»ƒu quÃ¡ khá»›p. Nhá»¯ng phÃ¡t hiá»‡n nÃ y lÃ m ná»•i báº­t tiá»m nÄƒng cho cÃ¡c ká»¹ thuáº­t PEFT hiá»‡u quáº£ hÆ¡n, máº·c dÃ¹ cáº§n khÃ¡m phÃ¡ thÃªm Ä‘á»ƒ hiá»ƒu Ä‘áº§y Ä‘á»§ kháº£ nÄƒng Ã¡p dá»¥ng rá»™ng hÆ¡n cá»§a chÃºng.

PhÃ¡t hiá»‡n má»›i cho PEFT trong ká»¹ thuáº­t pháº§n má»m. Nhá»¯ng phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i trong RQ1 tiáº¿t lá»™ ráº±ng cÃ¡c phÆ°Æ¡ng phÃ¡p PEFT vÆ°á»£t trá»™i tinh chá»‰nh Ä‘áº§y Ä‘á»§ cho SLM trong cÃ¡c tÃ¡c vá»¥ sinh mÃ£. Äiá»u nÃ y trÃ¡i ngÆ°á»£c vá»›i cÃ¡c nghiÃªn cá»©u quy mÃ´ lá»›n trÆ°á»›c trong NLP, nhÆ° Ding vÃ  cá»™ng sá»± [14], Ä‘Ã£ chá»©ng minh tÃ­nh vÆ°á»£t trá»™i vá» hiá»‡u quáº£ cá»§a tinh chá»‰nh Ä‘áº§y Ä‘á»§ so vá»›i cÃ¡c ká»¹ thuáº­t nhÆ° LoRA, Prompt Tuning, vÃ  Prefix Tuning trÃªn má»™t loáº¡t rá»™ng cÃ¡c tÃ¡c vá»¥ NLP.

Trong bá»‘i cáº£nh ká»¹ thuáº­t pháº§n má»m, trong khi cÃ¡c nghiÃªn cá»©u trÆ°á»›c [38,40] Ä‘Ã£ cho tháº¥y ráº±ng cÃ¡c phÆ°Æ¡ng phÃ¡p PEFT, nhÆ° LoRA, cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i tinh chá»‰nh Ä‘áº§y Ä‘á»§ cho SLM, káº¿t quáº£ cá»§a chÃºng tÃ´i Ä‘i xa hÆ¡n. ChÃºng tÃ´i cho tháº¥y ráº±ng táº¥t cáº£ cÃ¡c ká»¹ thuáº­t PEFT Ä‘Æ°á»£c nghiÃªn cá»©u trong bÃ i bÃ¡o nÃ y vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ tinh chá»‰nh Ä‘áº§y Ä‘á»§ cho SLM nhÆ° CodeGen-350M-mono vÃ  CodeT5+-770M trÃªn cÃ¡c bá»™ dá»¯ liá»‡u Conala vÃ  CodeAlpacaPy (xem Báº£ng 3), lÃ m ná»•i báº­t nhá»¯ng Æ°u Ä‘iá»ƒm rÃµ rÃ ng cá»§a PEFT trong nhá»¯ng tÃ¬nh huá»‘ng nÃ y. Tuy nhiÃªn, do háº¡n cháº¿ tÃ i nguyÃªn, chÃºng tÃ´i khÃ´ng thá»ƒ Ä‘Ã¡nh giÃ¡ tinh chá»‰nh Ä‘áº§y Ä‘á»§ cho LLM, Ä‘á»ƒ láº¡i khÃ´ng gian cho cÃ¡c nghiÃªn cá»©u tÆ°Æ¡ng lai khÃ¡m phÃ¡ Ä‘iá»u nÃ y sÃ¢u hÆ¡n trong lÄ©nh vá»±c ká»¹ thuáº­t pháº§n má»m.

NgoÃ i ra, nghiÃªn cá»©u cá»§a chÃºng tÃ´i khÃ¡m phÃ¡ nhá»¯ng hiá»ƒu biáº¿t má»›i vá» lá»£i Ã­ch cá»§a QLoRA vÃ  hiá»‡u quáº£ so sÃ¡nh cá»§a LoRA so vá»›i RAG cho cÃ¡c tÃ¡c vá»¥ sinh mÃ£. Äáº§u tiÃªn, trong RQ3 vÃ  RQ4, chÃºng tÃ´i chá»©ng minh ráº±ng QLoRA cung cáº¥p hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng hoáº·c tháº­m chÃ­ vÆ°á»£t trá»™i so vá»›i LoRA trong khi cáº¯t giáº£m Ä‘Ã¡ng ká»ƒ chi phÃ­ tÃ­nh toÃ¡n. Thá»© hai, chÃºng tÃ´i tiáº¿t lá»™ nhá»¯ng háº¡n cháº¿ cá»§a ICL vÃ  RAG, cho tháº¥y ráº±ng hiá»‡u quáº£ LLM cÃ³ xu hÆ°á»›ng Ä‘Ã¬nh trá»‡ khi nhiá»u vÃ­ dá»¥ hÆ¡n Ä‘Æ°á»£c truy xuáº¥t. NgÆ°á»£c láº¡i, nghiÃªn cá»©u cá»§a chÃºng tÃ´i lÃ m ná»•i báº­t nhá»¯ng Æ°u Ä‘iá»ƒm nháº¥t quÃ¡n cá»§a cÃ¡c ká»¹ thuáº­t PEFT nhÆ° LoRA vÃ  QLoRA trong viá»‡c vÆ°á»£t qua nhá»¯ng háº¡n cháº¿ nÃ y.

TÃ¡c vá»¥ SE vÃ  Ä‘a tÃ¡c vá»¥. Äá»ƒ Ä‘áº£m báº£o má»™t nghiÃªn cá»©u táº­p trung, chÃºng tÃ´i trÃ¡nh thÃªm cÃ¡c tÃ¡c vá»¥ vÃ  bá»™ dá»¯ liá»‡u bá»• sung, ngÄƒn cháº·n má»™t táº­p há»£p phÃ¢n tÃ­ch quÃ¡ rá»™ng. KhÃ¡m phÃ¡ cÃ¡c ká»¹ thuáº­t PEFT cho LLM trÃªn cÃ¡c tÃ¡c vá»¥ vÃ  bá»™ dá»¯ liá»‡u Ä‘a dáº¡ng lÃ  má»™t hÆ°á»›ng Ä‘áº§y há»©a háº¹n cho nghiÃªn cá»©u tÆ°Æ¡ng lai. Äáº·c biá»‡t, Lorahub [26], má»™t khung Ä‘Æ°á»£c giá»›i thiá»‡u gáº§n Ä‘Ã¢y cho há»c Ä‘a tÃ¡c vá»¥, chá»©ng minh ráº±ng má»™t sá»± káº¿t há»£p cá»§a cÃ¡c module LoRA Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn cÃ¡c tÃ¡c vá»¥ khÃ¡c nhau cÃ³ thá»ƒ tá»•ng quÃ¡t hÃ³a cho cÃ¡c tÃ¡c vá»¥ má»›i, chÆ°a tháº¥y trong khi cung cáº¥p sá»± Ä‘Ã¡nh Ä‘á»•i hiá»‡u suáº¥t-hiá»‡u quáº£ máº¡nh máº½. ChÃºng tÃ´i tin ráº±ng viá»‡c Ã¡p dá»¥ng cÃ¡c cÃ¡ch tiáº¿p cáº­n tÆ°Æ¡ng tá»± trong AI cho SE cÃ³ tiá»m nÄƒng lá»›n, Ä‘áº·c biá»‡t khi lÄ©nh vá»±c nghiÃªn cá»©u nháº±m tá»± Ä‘á»™ng hÃ³a má»™t loáº¡t rá»™ng cÃ¡c tÃ¡c vá»¥ liÃªn quan Ä‘áº¿n mÃ£.

7 Má»I ÄE Dá»ŒA Äá»I Vá»šI TÃNH Há»¢P Lá»†
TÃ­nh há»£p lá»‡ bÃªn ngoÃ i. Má»™t má»‘i Ä‘e dá»a chÃ­nh liÃªn quan Ä‘áº¿n viá»‡c lá»±a chá»n SLM vÃ  LLM cá»§a chÃºng tÃ´i. ChÃºng tÃ´i giáº£m thiá»ƒu má»‘i Ä‘e dá»a nÃ y báº±ng cÃ¡ch cáº©n tháº­n chá»n má»™t táº­p há»£p Ä‘a dáº¡ng cÃ¡c mÃ´ hÃ¬nh, nhÆ° Ä‘Æ°á»£c giáº£i thÃ­ch trong Pháº§n 4.4. Nhá»¯ng mÃ´ hÃ¬nh nÃ y bao gá»“m cÃ¡c há» LLM khÃ¡c nhau, Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u tiá»n huáº¥n luyá»‡n vÃ  má»¥c tiÃªu há»c riÃªng biá»‡t, vÃ  cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau. HÆ¡n ná»¯a, chÃºng tÃ´i khÃ´ng chá»n cÃ¡c biáº¿n thá»ƒ mÃ´ hÃ¬nh lá»›n hÆ¡n ngoáº¡i trá»« khi sá»­ dá»¥ng QLoRA, vÃ¬ cÃ¡c ká»¹ thuáº­t PEFT khÃ¡c, ICL, vÃ  RAG háº¡n cháº¿ viá»‡c sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n trong cÃ¡c rÃ ng buá»™c tÃ i nguyÃªn cá»§a chÃºng tÃ´i.

Má»™t má»‘i Ä‘e dá»a bÃªn ngoÃ i khÃ¡c Ä‘á»‘i vá»›i tÃ­nh há»£p lá»‡ liÃªn quan Ä‘áº¿n cháº¥t lÆ°á»£ng vÃ  tÃ­nh Ä‘áº¡i diá»‡n cá»§a cÃ¡c bá»™ dá»¯ liá»‡u tinh chá»‰nh. Äá»ƒ giáº£m bá»›t má»‘i lo ngáº¡i nÃ y, chÃºng tÃ´i chá»n bá»™ dá»¯ liá»‡u Conala, chá»©a cÃ¡c vÃ­ dá»¥ cháº¥t lÆ°á»£ng cao Ä‘Æ°á»£c khai thÃ¡c tá»« cÃ¡c bÃ i Ä‘Äƒng StackOverflow. NgoÃ i ra, bá»™ dá»¯ liá»‡u nÃ y Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘áº¡i diá»‡n bá»Ÿi nhiá»u nghiÃªn cá»©u trÆ°á»›c [49,73,91] vá» cÃ¡c tÃ¡c vá»¥ sinh mÃ£. HÆ¡n ná»¯a, cÃ¡c tÃ¡c giáº£ Ä‘Ã£ lÃ m phong phÃº má»—i Ã½ Ä‘á»‹nh ngÃ´n ngá»¯ tá»± nhiÃªn vá»›i gá»£i Ã½, tÄƒng cÆ°á»ng sá»± phÃ¹ há»£p cá»§a prompt Ä‘áº§u vÃ o vá»›i cÃ¡c Ã½ Ä‘á»‹nh con ngÆ°á»i cÃ³ thá»ƒ. Äá»ƒ lÃ m phong phÃº nghiÃªn cá»©u cá»§a chÃºng tÃ´i, chÃºng tÃ´i bao gá»“m CodeAlpacaPy nhÆ° má»™t bá»™ dá»¯ liá»‡u thá»© hai bao gá»“m cÃ¡c vÃ­ dá»¥ dÃ i hÆ¡n, mang láº¡i má»™t dÃ²ng phÃ¢n tÃ­ch khÃ¡c. ChÃºng tÃ´i khÃ´ng bao gá»“m cÃ¡c bá»™ dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡ nhÆ° HumanEval [9] vÃ  MBPP [3], vÃ¬ chÃºng khÃ´ng bao gá»“m cÃ¡c vÃ­ dá»¥ huáº¥n luyá»‡n. Tuy nhiÃªn, Ä‘á»ƒ má»Ÿ rá»™ng thÃªm nghiÃªn cá»©u, chÃºng tÃ´i khÃ¡m phÃ¡ hiá»‡u quáº£ cá»§a LoRA vÃ  QLoRA cho sinh mÃ£ dá»±a trÃªn thá»±c thi trÃªn bá»™ dá»¯ liá»‡u APPs.

Cuá»‘i cÃ¹ng, khÃ­a cáº¡nh Ä‘Æ¡n ngÃ´n ngá»¯ cá»§a cÃ¡c bá»™ dá»¯ liá»‡u táº¡o thÃ nh má»™t má»‘i Ä‘e dá»a khÃ¡c Ä‘á»‘i vá»›i tÃ­nh há»£p lá»‡ bÃªn ngoÃ i. ChÃºng tÃ´i nghiÃªn cá»©u tinh chá»‰nh Ä‘áº§y Ä‘á»§, PEFT, ICL, vÃ  RAG cho sinh mÃ£ cá»§a cÃ¡c Ä‘oáº¡n mÃ£ Python. Tuy nhiÃªn, chÃºng tÃ´i dá»± Ä‘oÃ¡n ráº±ng PEFT cÅ©ng Ã¡p dá»¥ng Ä‘Æ°á»£c cho cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh khÃ¡c, xem xÃ©t kháº£ nÄƒng sinh áº¥n tÆ°á»£ng cá»§a LLM trÃªn má»™t loáº¡t Ä‘a dáº¡ng cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh [2, 6].

TÃ­nh há»£p lá»‡ ná»™i bá»™. CÃ¡c lá»±a chá»n siÃªu tham sá»‘ cho cÃ¡c phÆ°Æ¡ng phÃ¡p PEFT táº¡o thÃ nh má»‘i Ä‘e dá»a chÃ­nh Ä‘á»‘i vá»›i tÃ­nh há»£p lá»‡ ná»™i bá»™. Äá»‘i vá»›i má»—i ká»¹ thuáº­t PEFT, chÃºng tÃ´i sá»­ dá»¥ng cÃ¡c giÃ¡ trá»‹ siÃªu tham sá»‘ Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ´ng trÃ¬nh trÆ°á»›c vá» PEFT cho cÃ¡c mÃ´ hÃ¬nh mÃ£ cÅ©ng nhÆ° trong cÃ¡c bÃ i bÃ¡o tiÃªn phong Ä‘Ã³ng gÃ³p cÃ¡c ká»¹ thuáº­t PEFT. NgoÃ i ra, vÃ¬ LoRA vá»›i r=16 vÃ  Î±=32 liÃªn tá»¥c vÆ°á»£t trá»™i táº¥t cáº£ cÃ¡c cáº¥u hÃ¬nh cá»§a ICL vÃ  RAG trÃªn ba mÃ´ hÃ¬nh hÃ ng Ä‘áº§u cá»§a chÃºng tÃ´i, viá»‡c tiáº¿n hÃ nh phÃ¢n tÃ­ch Ä‘á»™ nháº¡y siÃªu tham sá»‘ chi tiáº¿t cá»§a LoRA cÃ³ thá»ƒ cá»§ng cá»‘ thÃªm Æ°u tháº¿ cá»§a PEFT so vá»›i ICL vÃ  RAG. CÃ´ng trÃ¬nh tÆ°Æ¡ng lai cÃ³ thá»ƒ khÃ¡m phÃ¡ Ä‘á»™ nháº¡y cá»§a cÃ¡c siÃªu tham sá»‘ LoRA chÃ­nh, nhÆ° thá»© háº¡ng r vÃ  há»‡ sá»‘ tá»· lá»‡ Î±, trÃªn má»™t loáº¡t rá»™ng hÆ¡n cÃ¡c tÃ¡c vá»¥ ká»¹ thuáº­t pháº§n má»m.

TÃ­nh há»£p lá»‡ cáº¥u trÃºc. Lá»±a chá»n cÃ¡c metrics Ä‘Ã¡nh giÃ¡ táº¡o thÃ nh má»‘i Ä‘e dá»a chÃ­nh Ä‘á»‘i vá»›i tÃ­nh há»£p lá»‡ cáº¥u trÃºc. Äá»ƒ giáº£m thiá»ƒu má»‘i Ä‘e dá»a nÃ y, chÃºng tÃ´i chá»n cÃ¡c metrics Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i trong cÃ¡c cÃ´ng trÃ¬nh trÆ°á»›c [22,32,42, 56,72,84] vá» sinh mÃ£. HÆ¡n ná»¯a, chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ má»—i cÃ¡ch tiáº¿p cáº­n sá»­ dá»¥ng EM@k trÃªn Conala vÃ  CodeAlpacaPy, lÃ m phong phÃº phÃ¢n tÃ­ch cá»§a chÃºng tÃ´i báº±ng cÃ¡ch tÃ­nh toÃ¡n khá»›p chÃ­nh xÃ¡c trÃªn cÃ¡c pháº¡m vi khÃ¡c nhau cá»§a á»©ng viÃªn mÃ£. TÆ°Æ¡ng tá»±, Ä‘á»‘i vá»›i APPs, chÃºng tÃ´i Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh cÆ¡ sá»Ÿ vÃ  LoRA/QLoRA trÃªn Pass@k vá»›i tá»‘i Ä‘a 5 á»©ng viÃªn. Cuá»‘i cÃ¹ng, chÃºng tÃ´i khÃ´ng sá»­ dá»¥ng cÃ¡c metrics Pass@k vÃ¬ cÃ¡c bá»™ dá»¯ liá»‡u CoNaLa vÃ  CodeAlpacaPy khÃ´ng bao gá»“m unit test. LÃ m phong phÃº cÃ¡c bá»™ dá»¯ liá»‡u vá»›i unit test táº¡o thÃ nh má»™t lÄ©nh vá»±c thÃº vá»‹ cá»§a cÃ´ng trÃ¬nh tÆ°Æ¡ng lai.

--- TRANG 21 ---
KhÃ¡m phÃ¡ cÃ¡c Ká»¹ thuáº­t Tinh chá»‰nh Hiá»‡u quáº£ Tham sá»‘ cho Sinh mÃ£ vá»›i MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n â€¢21

8 CÃ”NG TRÃŒNH LIÃŠN QUAN
Trong pháº§n nÃ y, chÃºng tÃ´i tá»•ng quan cÃ´ng trÃ¬nh hiá»‡n cÃ³ vá» LLM cho sinh mÃ£ vÃ  tÆ°Æ¡ng pháº£n cÃ¡c Ä‘Ã³ng gÃ³p trÆ°á»›c vá» thÃ­ch á»©ng mÃ´ hÃ¬nh hiá»‡u quáº£ cá»§a mÃ£ cho cÃ¡c tÃ¡c vá»¥ háº¡ nguá»“n vá»›i nghiÃªn cá»©u cá»§a chÃºng tÃ´i.

Sinh mÃ£ Tá»± Ä‘á»™ng. Má»™t pháº§n Ä‘Ã¡ng ká»ƒ cá»§a cÃ¡c ká»¹ thuáº­t sinh mÃ£ [1,4,21,63,72] dá»±a vÃ o cÃ¡c cÃ¡ch tiáº¿p cáº­n dá»±a trÃªn há»c sÃ¢u. Xu hÆ°á»›ng má»›i nháº¥t trong sinh mÃ£ tá»± Ä‘á»™ng xoay quanh viá»‡c táº­n dá»¥ng LLM nhÆ° cÃ¡c mÃ´ hÃ¬nh GPT [50] do nhá»¯ng Ä‘á»™t phÃ¡ Ä‘Ã¡ng ká»ƒ cá»§a chÃºng trong lÄ©nh vá»±c nÃ y. Má»™t vÃ­ dá»¥ Ä‘Ã¡ng chÃº Ã½ lÃ  Codex, Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi Chen vÃ  cá»™ng sá»± [9], lÃ  má»™t phiÃªn báº£n Ä‘Æ°á»£c tinh chá»‰nh cá»§a GPT-3. CÃ¡c mÃ´ hÃ¬nh Ä‘Ã¡ng chÃº Ã½ khÃ¡c theo sau thÃ nh cÃ´ng cá»§a Codex bao gá»“m CodeGen [48], CodeGen2 [47] vÃ  CodeLlama [56]. Nhá»¯ng LLM nÃ y dÃ¢n chá»§ hÃ³a hiá»‡u quáº£ hiá»‡u suáº¥t Ä‘á»™t phÃ¡ Ä‘áº¡t Ä‘Æ°á»£c bá»Ÿi Codex vÃ  Ä‘Æ°a nÃ³ Ä‘áº¿n Ä‘á»‘i tÆ°á»£ng rá»™ng hÆ¡n. Tuy nhiÃªn, chi phÃ­ tÃ­nh toÃ¡n cao liÃªn quan Ä‘áº¿n tinh chá»‰nh Ä‘áº§y Ä‘á»§ cho LLM Ä‘á»ƒ Ä‘áº¡t hiá»‡u suáº¥t tá»‘i Æ°u lÃ  khÃ´ng thá»±c táº¿ cho háº§u háº¿t cÃ¡c nhÃ  nghiÃªn cá»©u vÃ  thá»±c hÃ nh. ChÃºng tÃ´i tin ráº±ng nghiÃªn cá»©u cá»§a chÃºng tÃ´i cÃ³ thá»ƒ lÃ m sÃ¡ng tá» cÃ¡c cÃ¡ch tiáº¿p cáº­n hiá»‡u quáº£ vÃ  tiáº¿t kiá»‡m chi phÃ­ hÆ¡n Ä‘á»ƒ tinh chá»‰nh nhá»¯ng LLM nÃ y, giáº£m thiá»ƒu gÃ¡nh náº·ng tÃ­nh toÃ¡n liÃªn quan Ä‘áº¿n viá»‡c Ã¡p dá»¥ng chÃºng.

ThÃ­ch á»©ng Hiá»‡u quáº£ cá»§a MÃ´ hÃ¬nh MÃ£. ThÃ­ch á»©ng hiá»‡u quáº£ cá»§a mÃ´ hÃ¬nh mÃ£ liÃªn quan Ä‘áº¿n viá»‡c sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t Ä‘á»ƒ thÃ­ch á»©ng hiá»‡u quáº£ má»™t mÃ´ hÃ¬nh vá»›i bá»™ dá»¯ liá»‡u cá»¥ thá»ƒ tÃ¡c vá»¥ (xem Pháº§n 2). Trong bá»‘i cáº£nh nÃ y, thuáº­t ngá»¯ "hiá»‡u quáº£" Ä‘á» cáº­p Ä‘áº¿n viá»‡c lÃ m cho chi phÃ­ tÃ­nh toÃ¡n tinh chá»‰nh tháº¥p, vÃ­ dá»¥, sá»­ dá»¥ng LoRA, hoáº·c sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t khÃ´ng tham sá»‘ nhÆ° prompting vÃ  ICL.

Háº§u háº¿t nghiÃªn cá»©u trÆ°á»›c Ä‘Ã£ táº­p trung vÃ o viá»‡c sá»­ dá»¥ng ICL vÃ  prompting Ä‘á»ƒ thÃ­ch á»©ng mÃ´ hÃ¬nh vá»›i cÃ¡c tÃ¡c vá»¥ liÃªn quan Ä‘áº¿n mÃ£ Ä‘a dáº¡ng. Gao vÃ  cá»™ng sá»± [17] thá»ƒ hiá»‡n nhá»¯ng Æ°u Ä‘iá»ƒm cá»§a ICL trong cÃ¡c tÃ¡c vá»¥ nhÆ° sá»­a lá»—i, tÃ³m táº¯t mÃ£, vÃ  tá»•ng há»£p chÆ°Æ¡ng trÃ¬nh. Há» nháº¥n máº¡nh ráº±ng hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh trÃªn cÃ¡c tÃ¡c vá»¥ háº¡ nguá»“n bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi nhiá»u yáº¿u tá»‘, bao gá»“m viá»‡c lá»±a chá»n, sá»‘ lÆ°á»£ng, vÃ  thá»© tá»± cá»§a cÃ¡c vÃ­ dá»¥ prompt. CÃ¡c nghiÃªn cá»©u khÃ¡c [53,80] cÅ©ng chá»©ng minh ráº±ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n vÃ  LLM nhÆ° Codex cÃ³ thá»ƒ xá»­ lÃ½ hiá»‡u quáº£ sá»­a lá»—i vÃ  sá»­a chá»¯a chÆ°Æ¡ng trÃ¬nh tá»± Ä‘á»™ng sá»­ dá»¥ng ICL. HÆ¡n ná»¯a, Geng vÃ  cá»™ng sá»± [19] chá»©ng minh kháº£ nÄƒng cá»§a Codex trong viá»‡c sinh táº¡o comment Ä‘a Ã½ Ä‘á»‹nh Ä‘á»ƒ mÃ´ táº£ chá»©c nÄƒng cá»§a má»™t phÆ°Æ¡ng phÃ¡p hoáº·c chi tiáº¿t thá»±c hiá»‡n cá»§a nÃ³, cháº³ng háº¡n. Viá»‡c lá»±a chá»n cÃ¡c prompt cÃ³ liÃªn quan cho má»™t tÃ¡c vá»¥ vá»›i ICL lÃ  quan trá»ng Ä‘á»ƒ Ä‘áº£m báº£o hiá»‡u suáº¥t tá»‘t cá»§a má»™t LLM. CÃ¡c cÃ´ng trÃ¬nh trÆ°á»›c [46,91] thiáº¿t káº¿ cÃ¡c ká»¹ thuáº­t lá»±a chá»n Ä‘á»ƒ truy xuáº¥t cÃ¡c vÃ­ dá»¥ prompt cÃ³ liÃªn quan cao Ä‘Æ°á»£c Ä‘iá»u chá»‰nh cho cÃ¡c tÃ¡c vá»¥ háº¡ nguá»“n, vÆ°á»£t trá»™i cÃ¡c phÆ°Æ¡ng phÃ¡p lá»±a chá»n ngáº«u nhiÃªn. Cuá»‘i cÃ¹ng, nghiÃªn cá»©u gáº§n Ä‘Ã¢y [61] nháº¥n máº¡nh nhá»¯ng Æ°u Ä‘iá»ƒm cá»§a viá»‡c truy xuáº¥t cÃ¡c vÃ­ dá»¥ prompt á»Ÿ cáº¥p Ä‘á»™ kho lÆ°u trá»¯, cung cáº¥p LLM vá»›i thÃ´ng tin ngá»¯ cáº£nh cÃ³ giÃ¡ trá»‹ trong cÃ¡c prompt. Trong nghiÃªn cá»©u nÃ y, chÃºng tÃ´i táº­n dá»¥ng ICL mÃ  khÃ´ng cÃ³ Ã½ Ä‘á»‹nh khÃ¡m phÃ¡ Ä‘áº§y Ä‘á»§ tiá»m nÄƒng cá»§a nÃ³. Thay vÃ o Ä‘Ã³, chÃºng tÃ´i chá»n má»™t thá»±c hiá»‡n Ä‘Æ¡n giáº£n cá»§a ICL báº±ng cÃ¡ch chá»n cÃ¡c vÃ­ dá»¥ few-shot ngáº«u nhiÃªn sá»­ dá»¥ng cÃ¡c seed khÃ¡c nhau. Má»Ÿ rá»™ng nghiÃªn cá»©u nÃ y Ä‘á»ƒ káº¿t há»£p nhiá»u cÃ¡ch tiáº¿p cáº­n ICL hÆ¡n sáº½ tÄƒng cÆ°á»ng so sÃ¡nh vá»›i cÃ¡c ká»¹ thuáº­t PEFT cho mÃ£.

LiÃªn quan Ä‘áº¿n cÃ¡c ká»¹ thuáº­t PEFT, nghiÃªn cá»©u trÆ°á»›c trong trÃ­ tuá»‡ mÃ£ Ä‘Ã£ táº­p trung vÃ o Prompt tuning [30], Prefix-tuning [33] vÃ  Adapters [20,23,25,57,58]. Wang vÃ  cá»™ng sá»± [68] khá»Ÿi xÆ°á»›ng viá»‡c sá»­ dá»¥ng Prompt tuning cho cÃ¡c tÃ¡c vá»¥ liÃªn quan Ä‘áº¿n mÃ£ vÃ  chá»©ng minh tÃ­nh vÆ°á»£t trá»™i cá»§a nÃ³ so vá»›i tinh chá»‰nh Ä‘áº§y Ä‘á»§ cá»§a CodeT5 vÃ  CodeBERT trong dá»± Ä‘oÃ¡n khuyáº¿t táº­t, tÃ³m táº¯t mÃ£, vÃ  dá»‹ch mÃ£. Goel vÃ  cá»™ng sá»± [20] khÃ¡m phÃ¡ viá»‡c sá»­ dá»¥ng adapter cá»¥ thá»ƒ ngÃ´n ngá»¯ láº­p trÃ¬nh cho chuyá»ƒn giao kiáº¿n thá»©c trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n, chá»©ng minh ráº±ng viá»‡c tinh chá»‰nh BERT vá»›i nhá»¯ng adapter nÃ y vÆ°á»£t trá»™i CodeBERT trÃªn kiá»ƒm tra cloze vÃ  phÃ¡t hiá»‡n clone mÃ£. Choi vÃ  cá»™ng sá»± [10] thiáº¿t káº¿ má»™t cÃ¡ch tiáº¿p cáº­n Prefix tuning cá»¥ thá»ƒ mÃ£ trong kiáº¿n trÃºc sequence-to-sequence cho cÃ¡c tÃ¡c vá»¥ sinh. NghiÃªn cá»©u cá»§a chÃºng tÃ´i khÃ¡c biá»‡t vá»›i ba cÃ´ng trÃ¬nh trÆ°á»›c nÃ y vÃ¬ chÃºng táº­p trung vÃ o SLM, trong khi chÃºng tÃ´i Ä‘á» xuáº¥t nghiÃªn cá»©u toÃ n diá»‡n Ä‘áº§u tiÃªn vá» cÃ¡c ká»¹ thuáº­t PEFT vá»›i LLM cho sinh mÃ£. HÆ¡n ná»¯a, nghiÃªn cá»©u cá»§a chÃºng tÃ´i bao gá»“m LoRA, IA3, vÃ  QLoRA, mÃ  khÃ´ng cÃ³ cÃ´ng trÃ¬nh trÆ°á»›c nÃ o trong trÃ­ tuá»‡ mÃ£ xem xÃ©t Ä‘á»ƒ tinh chá»‰nh hiá»‡u quáº£ LLM cá»§a mÃ£. Wang vÃ  cá»™ng sá»± [69] thá»ƒ hiá»‡n tÃ­nh vÆ°á»£t trá»™i cá»§a viá»‡c sá»­ dá»¥ng Adapters Ä‘á»ƒ tinh chá»‰nh cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c tiá»n huáº¥n luyá»‡n so vá»›i tinh chá»‰nh Ä‘áº§y Ä‘á»§. CÃ¡c cÃ´ng trÃ¬nh gáº§n Ä‘Ã¢y Ä‘Ã£ Ä‘Ã³ng gÃ³p cÃ¡c nghiÃªn cá»©u thá»±c nghiá»‡m cho cÃ¡c tÃ¡c vá»¥ ká»¹ thuáº­t pháº§n má»m khÃ¡c nhau, bao gá»“m thay Ä‘á»•i mÃ£ [40], tÃ³m táº¯t mÃ£ [38,57], dá»± Ä‘oÃ¡n khuyáº¿t táº­t [38], vÃ  phÃ¡t hiá»‡n clone mÃ£ [57], sá»­ dá»¥ng Adapter tuning vÃ  LoRA cho SLM. NghiÃªn cá»©u cá»§a chÃºng tÃ´i khÃ¡c biá»‡t vá»›i nhá»¯ng cÃ´ng trÃ¬nh trÆ°á»›c nÃ y, vÃ¬ chÃºng tÃ´i táº­p trung vÃ o LLM. Máº·c dÃ¹ chÃºng tÃ´i khÃ´ng káº¿t há»£p Adapters trong Ä‘iá»u tra cá»§a chÃºng tÃ´i, chÃºng tÃ´i tin ráº±ng LoRA, IA3, Prompt tuning, Prefix tuning, vÃ  QLoRA cung cáº¥p má»™t phÃ¢n tÃ­ch Ä‘á»§ ká»¹ lÆ°á»¡ng vá» cÃ¡c ká»¹ thuáº­t PEFT. ChÃºng tÃ´i nháº­n ra giÃ¡ trá»‹ cá»§a viá»‡c khÃ¡m phÃ¡ cÃ¡c ká»¹ thuáº­t PEFT bá»• sung cho cÃ¡c tÃ¡c vá»¥ trÃ­ tuá»‡ mÃ£ khÃ¡c nhau trong tÆ°Æ¡ng lai.

9 Káº¾T LUáº¬N VÃ€ CÃ”NG TRÃŒNH TÆ¯Æ NG LAI
NghiÃªn cá»©u nÃ y thiáº¿t láº­p hiá»‡u quáº£ cá»§a cÃ¡c ká»¹ thuáº­t PEFT trong viá»‡c tinh chá»‰nh LLM cho sinh mÃ£. PhÃ¢n tÃ­ch so sÃ¡nh cá»§a chÃºng tÃ´i trÃªn cÃ¡c ká»¹ thuáº­t hiá»‡u quáº£ tham sá»‘ khÃ¡c nhau, bao gá»“m LoRA, IA3, Prompt tuning, Prefix tuning, vÃ  QLoRA, tiáº¿t lá»™ tÃ­nh vÆ°á»£t trá»™i cá»§a PEFT so vá»›i tinh chá»‰nh Ä‘áº§y Ä‘á»§ cho SLM vÃ  ICL vÃ  RAG cho LLM. HÆ¡n ná»¯a, nghiÃªn cá»©u cá»§a chÃºng tÃ´i minh há»a tÃ­nh thá»±c tiá»…n cá»§a PEFT dÆ°á»›i tÃ¬nh huá»‘ng tÃ i nguyÃªn háº¡n cháº¿, giáº£m thiá»ƒu hiá»‡u quáº£ sá»± phá»¥ thuá»™c vÃ o cÆ¡ sá»Ÿ háº¡ táº§ng tÃ­nh toÃ¡n lá»›n vÃ  Ä‘áº¯t tiá»n. Theo hiá»ƒu biáº¿t tá»‘t nháº¥t cá»§a chÃºng tÃ´i, nghiÃªn cá»©u nÃ y lÃ  trong sá»‘ nhá»¯ng khÃ¡m phÃ¡ toÃ n diá»‡n Ä‘áº§u tiÃªn vá» cÃ¡c ká»¹ thuáº­t PEFT cho LLM trong ká»¹ thuáº­t pháº§n má»m, gá»£i Ã½ má»™t con Ä‘Æ°á»ng Ä‘áº§y há»©a háº¹n cho nghiÃªn cá»©u tÆ°Æ¡ng lai. ChÃºng tÃ´i dá»± Ä‘oÃ¡n nhá»¯ng phÃ¡t hiá»‡n cá»§a chÃºng tÃ´i sáº½ truyá»n cáº£m há»©ng cho Ä‘iá»u tra sÃ¢u hÆ¡n vá» viá»‡c Ã¡p dá»¥ng cÃ¡c ká»¹ thuáº­t PEFT trong ká»¹ thuáº­t pháº§n má»m, vá»›i tÃ¡c Ä‘á»™ng cÃ³ thá»ƒ xa rá»™ng. CÃ´ng trÃ¬nh tÆ°Æ¡ng lai cá»§a chÃºng tÃ´i sáº½ má»Ÿ rá»™ng nghiÃªn cá»©u sang cÃ¡c tÃ¡c vá»¥ ká»¹ thuáº­t pháº§n má»m thay tháº¿ nhÆ° Ä‘Ã¡nh giÃ¡ mÃ£ tá»± Ä‘á»™ng vÃ  sinh comment. Cuá»‘i cÃ¹ng, chÃºng tÃ´i nháº±m xÃ¡c thá»±c thÃªm sá»± liÃªn quan cá»§a cÃ¡c ká»¹ thuáº­t PEFT dÆ°á»›i cÃ¡c cÃ i Ä‘áº·t Ä‘a tÃ¡c vá»¥ vÃ  há»c liÃªn tá»¥c cho ká»¹ thuáº­t pháº§n má»m tá»± Ä‘á»™ng.

TÃ€I LIá»†U THAM KHáº¢O
[1]Uri Alon, Roy Sadaka, Omer Levy, vÃ  Eran Yahav. 2020. Structural language models of code. Trong International conference on machine learning. PMLR, 245â€“256.
[2]Ben Athiwaratkun, Sanjay Krishna Gouda, Zijian Wang, Xiaopeng Li, Yuchen Tian, Ming Tan, Wasi Uddin Ahmad, Shiqi Wang, Qing Sun, Mingyue Shang, vÃ  cá»™ng sá»±. 2022. Multi-lingual evaluation of code generation models. arXiv preprint arXiv:2210.14868 (2022).
[3]Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, vÃ  cá»™ng sá»±. 2021. Program synthesis with large language models. arXiv preprint arXiv:2108.07732 (2021).
[4]Matej Balog, Alexander L Gaunt, Marc Brockschmidt, Sebastian Nowozin, vÃ  Daniel Tarlow. 2016. Deepcoder: Learning to write programs. arXiv preprint arXiv:1611.01989 (2016).
[5]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, vÃ  cá»™ng sá»±. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877â€“1901.
[6]Federico Cassano, John Gouwar, Daniel Nguyen, Sydney Nguyen, Luna Phipps-Costin, Donald Pinckney, Ming-Ho Yee, Yangtian Zi, Carolyn Jane Anderson, Molly Q Feldman, vÃ  cá»™ng sá»±. 2023. MultiPL-E: a scalable and polyglot approach to benchmarking neural code generation. IEEE Transactions on Software Engineering (2023).
[7]Christel Chappuis, ValÃ©rie Zermatten, Sylvain Lobry, Bertrand Le Saux, vÃ  Devis Tuia. 2022. Prompt-RSVQA: Prompting visual context to a language model for remote sensing visual question answering. Trong Proceedings of the IEEE/CVF

--- TRANG 23 ---
KhÃ¡m phÃ¡ cÃ¡c Ká»¹ thuáº­t Tinh chá»‰nh Hiá»‡u quáº£ Tham sá»‘ cho Sinh mÃ£ vá»›i MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n â€¢23

Conference on Computer Vision and Pattern Recognition. 1372â€“1381.
[8]Sahil Chaudhary. 2023. Code Alpaca: An Instruction-following LLaMA model for code generation. https://github.com/ sahil280114/codealpaca.
[9]Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, vÃ  cá»™ng sá»±. 2021. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374 (2021).
[10] YunSeok Choi vÃ  Jee-Hyong Lee. 2023. CodePrompt: Task-Agnostic Prefix Tuning for Program and Language Generation. Trong Findings of the Association for Computational Linguistics: ACL 2023. 5282â€“5297.
[11] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, vÃ  cá»™ng sá»±. 2022. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311 (2022).
[12] Tim Dettmers, Mike Lewis, Younes Belkada, vÃ  Luke Zettlemoyer. 2022. LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale. arXiv preprint arXiv:2208.07339 (2022).
[13] Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, vÃ  Luke Zettlemoyer. 2023. Qlora: Efficient finetuning of quantized llms. arXiv preprint arXiv:2305.14314 (2023).
[14] Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, vÃ  cá»™ng sá»±. 2022. Delta tuning: A comprehensive study of parameter efficient methods for pre-trained language models. arXiv preprint arXiv:2203.06904 (2022).
[15] Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, vÃ  cá»™ng sá»±. 2023. Parameter-efficient fine-tuning of large-scale pre-trained language models. Nature Machine Intelligence 5, 3 (2023), 220â€“235.
[16] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, vÃ  cá»™ng sá»±. 2020. Codebert: A pre-trained model for programming and natural languages. arXiv preprint arXiv:2002.08155 (2020).
[17] Shuzheng Gao, Xin-Cheng Wen, Cuiyun Gao, Wenxuan Wang, vÃ  Michael R Lyu. 2023. Constructing Effective In-Context Demonstration for Code Intelligence Tasks: An Empirical Study. arXiv preprint arXiv:2304.07575 (2023).
[18] Shuzheng Gao, Hongyu Zhang, Cuiyun Gao, vÃ  Chaozheng Wang. 2023. Keeping Pace with Ever-Increasing Data: Towards Continual Learning of Code Intelligence Models. arXiv preprint arXiv:2302.03482 (2023).
[19] Mingyang Geng, Shangwen Wang, Dezun Dong, Haotian Wang, Ge Li, Zhi Jin, Xiaoguang Mao, vÃ  Xiangke Liao. 2024. Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning. (2024).
[20] Divyam Goel, Ramansh Grover, vÃ  Fatemeh H Fard. 2022. On the cross-modal transfer from natural language to code through adapter modules. Trong Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension. 71â€“81.
[21] Shirley Anugrah Hayati, Raphael Olivier, Pravalika Avvaru, Pengcheng Yin, Anthony Tomasic, vÃ  Graham Neubig. 2018. Retrieval-based neural code generation. arXiv preprint arXiv:1808.10025 (2018).
[22] Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas Mazeika, Akul Arora, Ethan Guo, Collin Burns, Samir Puranik, Horace He, Dawn Song, vÃ  Jacob Steinhardt. 2021. Measuring Coding Challenge Competence With APPS. NeurIPS (2021).
[23] Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, vÃ  Sylvain Gelly. 2019. Parameter-efficient transfer learning for NLP. Trong International Conference on Machine Learning. PMLR, 2790â€“2799.
[24] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, vÃ  Weizhu Chen. 2021. Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685 (2021).
[25] Zhiqiang Hu, Yihuai Lan, Lei Wang, Wanyu Xu, Ee-Peng Lim, Roy Ka-Wei Lee, Lidong Bing, vÃ  Soujanya Poria. 2023. LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models. arXiv preprint arXiv:2304.01933 (2023).
[26] Chengsong Huang, Qian Liu, Bill Yuchen Lin, Tianyu Pang, Chao Du, vÃ  Min Lin. 2023. Lorahub: Efficient cross-task generalization via dynamic lora composition. arXiv preprint arXiv:2307.13269 (2023).
[27] Harshit Joshi, JosÃ© Cambronero Sanchez, Sumit Gulwani, Vu Le, Gust Verbruggen, vÃ  Ivan RadiÄek. 2023. Repair is nearly generation: Multilingual program repair with llms. Trong Proceedings of the AAAI Conference on Artificial Intelligence,

--- TRANG 24 ---
24 â€¢M. Weyssow vÃ  cá»™ng sá»±.

Táº­p 37. 5131â€“5140.
[28] Denis Kocetkov, Raymond Li, Loubna Ben Allal, Jia Li, Chenghao Mou, Carlos MuÃ±oz Ferrandis, Yacine Jernite, Margaret Mitchell, Sean Hughes, Thomas Wolf, Dzmitry Bahdanau, Leandro von Werra, vÃ  Harm de Vries. 2022. The Stack: 3 TB of permissively licensed source code. Preprint (2022).
[29] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, vÃ  Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners. Advances in neural information processing systems 35 (2022), 22199â€“22213.
[30] Brian Lester, Rami Al-Rfou, vÃ  Noah Constant. 2021. The Power of Scale for Parameter-Efficient Prompt Tuning. Trong Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 3045â€“3059.
[31] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich KÃ¼ttler, Mike Lewis, Wen-tau Yih, Tim RocktÃ¤schel, vÃ  cá»™ng sá»±. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems 33 (2020), 9459â€“9474.
[32] Jia Li, Yongmin Li, Ge Li, Zhi Jin, Yiyang Hao, vÃ  Xing Hu. 2023. Skcoder: A sketch-based approach for automatic code generation. arXiv preprint arXiv:2302.06144 (2023).
[33] Xiang Lisa Li vÃ  Percy Liang. 2021. Prefix-tuning: Optimizing continuous prompts for generation. arXiv preprint arXiv:2101.00190 (2021).
[34] Zehan Li, Xin Zhang, Yanzhao Zhang, Dingkun Long, Pengjun Xie, vÃ  Meishan Zhang. 2023. Towards General Text Embeddings with Multi-stage Contrastive Learning. arXiv:2308.03281 [cs.CL] https://arxiv.org/abs/2308.03281
[35] Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, vÃ  cá»™ng sá»±. 2022. Holistic evaluation of language models. arXiv preprint arXiv:2211.09110 (2022).
[36] W Liang, M Yuksekgonul, Y Mao, E Wu, vÃ  J Zou. 2023. GPT detectors are biased against non-native English writers (arXiv: 2304.02819). arXiv.
[37] Haokun Liu, Derek Tam, Mohammed Muqeeth, Jay Mohta, Tenghao Huang, Mohit Bansal, vÃ  Colin A Raffel. 2022. Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning. Advances in Neural Information Processing Systems 35 (2022), 1950â€“1965.
[38] Jiaxing Liu, Chaofeng Sha, vÃ  Xin Peng. 2023. An Empirical Study of Parameter-Efficient Fine-Tuning Methods for Pre-Trained Code Models. Trong 2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 397â€“408.
[39] Shangqing Liu, Yu Chen, Xiaofei Xie, Jingkai Siow, vÃ  Yang Liu. 2020. Retrieval-augmented generation for code summarization via hybrid gnn. arXiv preprint arXiv:2006.05405 (2020).
[40] Shuo Liu, Jacky Keung, Zhen Yang, Fang Liu, Qilin Zhou, vÃ  Yihan Liao. 2024. Delving into Parameter-Efficient Fine-Tuning in Code Change Learning: An Empirical Study. arXiv preprint arXiv:2402.06247 (2024).
[41] Shuai Lu, Nan Duan, Hojae Han, Daya Guo, Seung-won Hwang, vÃ  Alexey Svyatkovskiy. 2022. Reacc: A retrieval-augmented code completion framework. arXiv preprint arXiv:2203.07722 (2022).
[42] Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, vÃ  cá»™ng sá»±. 2021. Codexglue: A machine learning benchmark dataset for code understanding and generation. arXiv preprint arXiv:2102.04664 (2021).
[43] Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, Sayak Paul, vÃ  Benjamin Bossan. 2022. PEFT: State-of-the-art Parameter-Efficient Fine-Tuning methods. https://github.com/huggingface/peft.
[44] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre, Ilana Heintz, vÃ  Dan Roth. 2021. Recent advances in natural language processing via large pre-trained language models: A survey. Comput. Surveys (2021).
[45] Sewon Min, Mike Lewis, Luke Zettlemoyer, vÃ  Hannaneh Hajishirzi. 2021. Metaicl: Learning to learn in context. arXiv preprint arXiv:2110.15943 (2021).
[46] Noor Nashid, Mifta Sintaha, vÃ  Ali Mesbah. 2023. Retrieval-based prompt selection for code-related few-shot learning. Trong Proceedings of the 45th International Conference on Software Engineering (ICSE'23).
[47] Erik Nijkamp, Hiroaki Hayashi, Caiming Xiong, Silvio Savarese, vÃ  Yingbo Zhou. 2023. Codegen2: Lessons for training llms on programming and natural languages. arXiv preprint arXiv:2305.02309 (2023).
[48] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, vÃ  Caiming Xiong. 2023. CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis. arXiv:2203.13474 [cs.LG]

--- TRANG 25 ---
KhÃ¡m phÃ¡ cÃ¡c Ká»¹ thuáº­t Tinh chá»‰nh Hiá»‡u quáº£ Tham sá»‘ cho Sinh mÃ£ vá»›i MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n â€¢25

[49] Sajad Norouzi, Keyi Tang, vÃ  Yanshuai Cao. 2021. Code generation from natural language with less prior knowledge and more monolingual data. Trong Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers). 776â€“785.
[50] R OpenAI. 2023. GPT-4 technical report. arXiv (2023), 2303â€“08774.
[51] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, vÃ  cá»™ng sá»±. 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems 35 (2022), 27730â€“27744.
[52] Md Rizwan Parvez, Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, vÃ  Kai-Wei Chang. 2021. Retrieval augmented code generation and summarization. arXiv preprint arXiv:2108.11601 (2021).
[53] Julian Aron Prenner, Hlib Babii, vÃ  Romain Robbes. 2022. Can OpenAI's codex fix bugs? an evaluation on QuixBugs. Trong Proceedings of the Third International Workshop on Automated Program Repair. 69â€“75.
[54] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, vÃ  cá»™ng sá»±. 2019. Language models are unsupervised multitask learners. OpenAI blog 1, 8 (2019), 9.
[55] Shuo Ren, Daya Guo, Shuai Lu, Long Zhou, Shujie Liu, Duyu Tang, Neel Sundaresan, Ming Zhou, Ambrosio Blanco, vÃ  Shuai Ma. 2020. Codebleu: a method for automatic evaluation of code synthesis. arXiv preprint arXiv:2009.10297 (2020).
[56] Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, JÃ©rÃ©my Rapin, vÃ  cá»™ng sá»±. 2023. Code llama: Open foundation models for code. arXiv preprint arXiv:2308.12950 (2023).
[57] Iman Saberi, Fatemeh Fard, vÃ  Fuxiang Chen. 2024. Utilization of pre-trained language models for adapter-based knowledge transfer in software engineering. Empirical Software Engineering 29, 4 (2024), 94.
[58] Iman Saberi vÃ  Fatemeh H Fard. 2023. Model-Agnostic Syntactical Information for Pre-Trained Programming Language Models. arXiv preprint arXiv:2303.06233 (2023).
[59] Zhenwei Shao, Zhou Yu, Meng Wang, vÃ  Jun Yu. 2023. Prompting large language models with answer heuristics for knowledge-based visual question answering. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 14974â€“14983.
[60] Noam Shazeer vÃ  Mitchell Stern. 2018. Adafactor: Adaptive learning rates with sublinear memory cost. Trong International Conference on Machine Learning. PMLR, 4596â€“4604.
[61] Disha Shrivastava, Hugo Larochelle, vÃ  Daniel Tarlow. 2023. Repository-level prompt generation for large language models of code. Trong International Conference on Machine Learning. PMLR, 31693â€“31715.
[62] Emma Strubell, Ananya Ganesh, vÃ  Andrew McCallum. 2019. Energy and policy considerations for deep learning in NLP. arXiv preprint arXiv:1906.02243 (2019).
[63] Zeyu Sun, Qihao Zhu, Yingfei Xiong, Yican Sun, Lili Mou, vÃ  Lu Zhang. 2020. Treegen: A tree-based transformer architecture for code generation. Trong Proceedings of the AAAI Conference on Artificial Intelligence, Táº­p 34. 8984â€“8991.
[64] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric Hambro, Faisal Azhar, vÃ  cá»™ng sá»±. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 (2023).
[65] Marcos Treviso, Ji-Ung Lee, Tianchu Ji, Betty van Aken, Qingqing Cao, Manuel R Ciosici, Michael Hassid, Kenneth Heafield, Sara Hooker, Colin Raffel, vÃ  cá»™ng sá»±. 2023. Efficient methods for natural language processing: A survey. Transactions of the Association for Computational Linguistics 11 (2023), 826â€“860.
[66] Priyan Vaithilingam, Tianyi Zhang, vÃ  Elena L Glassman. 2022. Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models. Trong Chi conference on human factors in computing systems extended abstracts. 1â€“7.
[67] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Åukasz Kaiser, vÃ  Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems 30 (2017).
[68] Chaozheng Wang, Yuanhang Yang, Cuiyun Gao, Yun Peng, Hongyu Zhang, vÃ  Michael R Lyu. 2022. No more fine-tuning? an experimental evaluation of prompt tuning in code intelligence. Trong Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 382â€“394.
[69] Deze Wang, Boxing Chen, Shanshan Li, Wei Luo, Shaoliang Peng, Wei Dong, vÃ  Xiangke Liao. 2023. One Adapter for All Programming Languages? Adapter Tuning for Code Search and Summarization. arXiv preprint arXiv:2303.15822 (2023).

--- TRANG 26 ---
26 â€¢M. Weyssow vÃ  cá»™ng sá»±.

[70] Weishi Wang, Yue Wang, Shafiq Joty, vÃ  Steven CH Hoi. 2023. Rap-gen: Retrieval-augmented patch generation with codet5 for automatic program repair. Trong Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 146â€“158.
[71] Yue Wang, Hung Le, Akhilesh Deepak Gotmare, Nghi DQ Bui, Junnan Li, vÃ  Steven CH Hoi. 2023. Codet5+: Open code large language models for code understanding and generation. arXiv preprint arXiv:2305.07922 (2023).
[72] Yue Wang, Weishi Wang, Shafiq Joty, vÃ  Steven CH Hoi. 2021. Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation. arXiv preprint arXiv:2109.00859 (2021).
[73] Zhiruo Wang, Shuyan Zhou, Daniel Fried, vÃ  Graham Neubig. 2022. Execution-Based Evaluation for Open-Domain Code Generation. arXiv preprint arXiv:2212.10481 (2022).
[74] Albert Webson vÃ  Ellie Pavlick. 2021. Do prompt-based models really understand the meaning of their prompts? arXiv preprint arXiv:2109.01247 (2021).
[75] Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, vÃ  Quoc V Le. 2021. Finetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652 (2021).
[76] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, vÃ  cá»™ng sá»±. 2022. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682 (2022).
[77] Martin Weyssow, Houari Sahraoui, vÃ  Bang Liu. 2022. Better modeling the programming world with code concept graphs-augmented multi-modal learning. Trong Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results. 21â€“25.
[78] Martin Weyssow, Xin Zhou, Kisub Kim, David Lo, vÃ  Houari Sahraoui. 2023. On the Usage of Continual Learning for Out-of-Distribution Generalization in Pre-trained Language Models of Code. arXiv preprint arXiv:2305.04106 (2023).
[79] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, RÃ©mi Louf, Morgan Funtowicz, vÃ  cá»™ng sá»±. 2019. Huggingface's transformers: State-of-the-art natural language processing. arXiv preprint arXiv:1910.03771 (2019).
[80] Chunqiu Steven Xia, Yuxiang Wei, vÃ  Lingming Zhang. 2023. Automated program repair in the era of large pre-trained language models. Trong Proceedings of the 45th International Conference on Software Engineering (ICSE 2023). Association for Computing Machinery.
[81] Chunqiu Steven Xia vÃ  Lingming Zhang. 2022. Less training, more repairing please: revisiting automated program repair via zero-shot learning. Trong Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 959â€“971.
[82] Frank F. Xu, Uri Alon, Graham Neubig, vÃ  Vincent Josua Hellendoorn. 2022. A Systematic Evaluation of Large Language Models of Code (MAPS 2022). Association for Computing Machinery, New York, NY, USA, 1â€“10. https: //doi.org/10.1145/3520312.3534862
[83] Prateek Yadav, Qing Sun, Hantian Ding, Xiaopeng Li, Dejiao Zhang, Ming Tan, Xiaofei Ma, Parminder Bhatia, Ramesh Nallapati, Murali Krishna Ramanathan, vÃ  cá»™ng sá»±. 2023. Exploring Continual Learning for Code Generation Models. arXiv preprint arXiv:2307.02435 (2023).
[84] Guang Yang, Yu Zhou, Xiang Chen, Xiangyu Zhang, Tingting Han, vÃ  Taolue Chen. 2023. ExploitGen: Template-augmented exploit code generation based on CodeBERT. Journal of Systems and Software 197 (2023), 111577.
[85] Yue Yang, Artemis Panagopoulou, Shenghao Zhou, Daniel Jin, Chris Callison-Burch, vÃ  Mark Yatskar. 2023. Language in a bottle: Language model guided concept bottlenecks for interpretable image classification. Trong Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 19187â€“19197.
[86] Pengcheng Yin, Bowen Deng, Edgar Chen, Bogdan Vasilescu, vÃ  Graham Neubig. 2018. Learning to Mine Aligned Code and Natural Language Pairs from Stack Overflow. Trong Proceedings of the 15th International Conference on Mining Software Repositories (Gothenburg, Sweden) (MSR '18). Association for Computing Machinery, New York, NY, USA, 476â€“486. https://doi.org/10.1145/3196398.3196408
[87] Pengcheng Yin, Bowen Deng, Edgar Chen, Bogdan Vasilescu, vÃ  Graham Neubig. 2018. Learning to mine aligned code and natural language pairs from stack overflow. Trong 2018 IEEE/ACM 15th international conference on mining software repositories (MSR). IEEE, 476â€“486.
[88] Zhiqiang Yuan, Junwei Liu, Qiancheng Zi, Mingwei Liu, Xin Peng, vÃ  Yiling Lou. 2023. Evaluating instruction-tuned large language models on code comprehension and generation. arXiv preprint arXiv:2308.01240 (2023).

--- TRANG 27 ---
KhÃ¡m phÃ¡ cÃ¡c Ká»¹ thuáº­t Tinh chá»‰nh Hiá»‡u quáº£ Tham sá»‘ cho Sinh mÃ£ vá»›i MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n â€¢27

[89] Bowen Zhang, Xianghua Fu, Daijun Ding, Hu Huang, Yangyang Li, vÃ  Liwen Jing. 2023. Investigating Chain-of-thought with ChatGPT for Stance Detection on Social Media. arXiv preprint arXiv:2304.03087 (2023).
[90] Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, vÃ  Sameer Singh. 2021. Calibrate before use: Improving few-shot performance of language models. Trong International Conference on Machine Learning. PMLR, 12697â€“12706.
[91] Shuyan Zhou, Uri Alon, Frank F Xu, Zhengbao Jiang, vÃ  Graham Neubig. 2023. Docprompting: Generating code by retrieving the docs. Trong The Eleventh International Conference on Learning Representations.
[92] Xin Zhou, DongGyun Han, vÃ  David Lo. 2021. Assessing generalizability of codebert. Trong 2021 IEEE International Conference on Software Maintenance and Evolution (ICSME). IEEE, 425â€“436.

, Táº­p 1, Sá»‘ 1, BÃ i viáº¿t. NgÃ y xuáº¥t báº£n: ThÃ¡ng 12 2024.

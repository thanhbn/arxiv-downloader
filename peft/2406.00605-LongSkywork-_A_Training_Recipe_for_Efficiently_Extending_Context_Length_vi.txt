# LongSkywork: Một Công Thức Huấn Luyện để Mở Rộng Độ Dài Ngữ Cảnh một cách Hiệu Quả trong Các Mô Hình Ngôn Ngữ Lớn

Liang Zhao, Tianwen Wei, Liang Zeng, Cheng Cheng, Liu Yang
Peng Cheng, Lijie Wang, Chenxia Li, Xuejie Wu, Bo Zhu, Yimeng Gan
Rui Hu, Shuicheng Yan, Han Fang, Yahui Zhou∗
Skywork Team, Kunlun Inc.

## Tóm tắt

Chúng tôi giới thiệu LongSkywork, một Mô hình Ngôn ngữ Lớn (LLM) có khả năng xử lý ngữ cảnh dài lên đến 200.000 token. Chúng tôi cung cấp một công thức huấn luyện để mở rộng độ dài ngữ cảnh của các LLM một cách hiệu quả. Chúng tôi xác định rằng yếu tố quan trọng trong việc nâng cao khả năng xử lý ngữ cảnh dài là tích hợp một giai đoạn SFT ngữ cảnh dài sau giai đoạn SFT tiêu chuẩn. Chỉ cần 200 lần lặp có thể chuyển đổi mô hình SFT tiêu chuẩn thành mô hình ngữ cảnh dài. Để giảm công sức trong việc thu thập và chú thích dữ liệu cho mô hình hóa ngôn ngữ ngữ cảnh dài, chúng tôi phát triển hai phương pháp mới để tạo dữ liệu tổng hợp. Những phương pháp này được áp dụng trong giai đoạn tiền huấn luyện liên tục cũng như giai đoạn Tinh chỉnh có Giám sát (SFT), cải thiện đáng kể hiệu quả huấn luyện của các LLM ngữ cảnh dài. Các phát hiện của chúng tôi cho thấy dữ liệu SFT ngữ cảnh dài tổng hợp có thể vượt qua hiệu suất của dữ liệu được con người tuyển chọn ở một mức độ nhất định. LongSkywork đạt được hiệu suất xuất sắc trên nhiều bài kiểm tra ngữ cảnh dài. Trong bài kiểm tra Needle, một bài kiểm tra cho việc truy xuất thông tin ngữ cảnh dài, các mô hình của chúng tôi đạt được độ chính xác hoàn hảo trên nhiều khoảng ngữ cảnh. Hơn nữa, trong các tình huống ứng dụng thực tế, LongSkywork-13B thể hiện hiệu suất ngang bằng với Claude2.1, mô hình ngữ cảnh dài hàng đầu, nhấn mạnh tính hiệu quả của các phương pháp được đề xuất.

## 1 Giới thiệu

Sự tiến bộ của các mô hình ngôn ngữ lớn (Touvron et al., 2023a; Anil et al., 2023; Bai et al., 2023; Du et al., 2021; Wei et al., 2023b), được minh họa bởi ChatGPT (OpenAI, 2023), đang tác động lớn đến thế giới. Những mô hình này đang được sử dụng trong nhiều lĩnh vực khác nhau, như trò chuyện (Ouyang et al., 2022), soạn thảo (Fyfe, 2023), và các tác nhân động (Xi et al., 2023; Bozkurt, 2023). Một yếu tố chính thúc đẩy tiến bộ này là khả năng của những mô hình này để xử lý đầu vào với ngữ cảnh rộng lớn. Tuy nhiên, một hạn chế đáng chú ý vẫn còn: do tài nguyên hạn chế, nhiều mô hình ngôn ngữ hiện có chủ yếu được huấn luyện trên các văn bản ngắn hơn. Ví dụ, Llama1 (Touvron et al., 2023a) được huấn luyện trên cửa sổ ngữ cảnh 2K, trong khi Llama2 (Touvron et al., 2023b) được huấn luyện trên cửa sổ ngữ cảnh 4K. Do đó, hiệu quả của chúng có thể bị giảm khi đối mặt với các lời nhắc dài hơn thường gặp trong các ứng dụng thực tế.

Nhu cầu về các LLM có thể hiểu và tạo ra các chuỗi dài một cách hiệu quả đã tăng lên đáng kể, do việc sử dụng rộng rãi của chúng trong các ứng dụng liên quan đến các tình huống phức tạp (Liu et al., 2023a; Beltagy et al., 2020; Milne-Ives et al., 2020). Do đó, các nhà nghiên cứu đã dành những nỗ lực đáng kể để nâng cao kiến trúc Transformer với khả năng xử lý ngữ cảnh dài (Roziere et al., 2023). Điều này bao gồm các kỹ thuật như tiền huấn luyện liên tục với dữ liệu dài (Xiong et al., 2023), nội suy nhúng vị trí (Chen et al., 2023a; Peng et al., 2023), chú ý tiết kiệm bộ nhớ như Flash attention (Dao et al., 2022). Tuy nhiên, các mô hình ngữ cảnh dài mạnh nhất hiện có là các hệ thống độc quyền, như GPT4 (OpenAI, 2023), Claude¹ và Moonshot².

Vẫn còn nhu cầu về thêm thông tin về cách phát triển các mô hình ngôn ngữ ngữ cảnh dài hiệu suất cao để sử dụng công cộng. Hầu hết các mô hình mã nguồn mở có thể xử lý trên 100k token hoặc là các mô hình cơ sở không phù hợp để hỗ trợ các nhiệm vụ thực tế, hoặc chỉ được tinh chỉnh trên các cuộc đối thoại dài (Zeng et al., 2022), thể hiện khả năng hiểu ngữ cảnh dài kém. Hơn nữa, các bộ dữ liệu dài tự nhiên chất lượng cao rất hiếm cho việc tiền huấn luyện và tinh chỉnh có giám sát (SFT), tạo ra những thách thức trong việc huấn luyện các LLM ngữ cảnh dài mạnh mẽ.

Để thu hẹp khoảng cách này, chúng tôi giới thiệu LongSkywork, một LLM ngữ cảnh dài có khả năng xử lý cửa sổ ngữ cảnh lên đến 200.000 token, được thiết kế đặc biệt để tạo thuận lợi cho việc hiểu sâu và giải quyết vấn đề trong các tình huống đa dạng. Hơn nữa, chúng tôi cung cấp những hiểu biết quan trọng về khung phát triển của LongSkywork. Các phát hiện của chúng tôi cho thấy khả năng xử lý ngữ cảnh mở rộng của mô hình có thể được tăng cường một cách có hệ thống thông qua quy trình bốn giai đoạn. Ngoài các giai đoạn thông thường của tiền huấn luyện và tinh chỉnh có giám sát, phương pháp của chúng tôi tích hợp các giai đoạn chuyên biệt cho tiền huấn luyện ngữ cảnh dài và tinh chỉnh có giám sát ngữ cảnh dài. Những giai đoạn bổ sung này được thiết kế tỉ mỉ để tăng cường năng lực của mô hình trong việc quản lý các đoạn văn bản mở rộng. Những cải thiện hiệu suất đáng kể trong cả hai giai đoạn huấn luyện ngữ cảnh dài đã được quan sát khi tích hợp dữ liệu được tạo tổng hợp.

Đối với giai đoạn tiền huấn luyện ngữ cảnh dài, chúng tôi đề xuất một phương pháp mới trong đó các tài liệu được chia thành các đoạn, sau đó được sắp xếp theo cách xen kẽ để tạo thành các mẫu tiền huấn luyện ngữ cảnh dài giả, một kỹ thuật mà chúng tôi gọi là "Tiền huấn luyện Xen kẽ Khối (CIP)". Kỹ thuật này buộc mô hình phải xử lý và tích hợp thông tin qua những khoảng cách văn bản đáng kể.

Trong giai đoạn tinh chỉnh có giám sát ngữ cảnh dài, chúng tôi trình bày một phương pháp để tạo ra các câu hỏi và câu trả lời từ các bảng. Những bảng này được tổng hợp tự động bởi chương trình và được gọi là "Bảng Dài Tổng hợp" (SynL). Phương pháp này đòi hỏi mô hình không chỉ trích xuất thông tin liên quan từ dữ liệu bảng rộng lớn mà còn tham gia vào các nhiệm vụ lý luận phức tạp dưới nhiều ràng buộc. Ngoài ra, chúng tôi thiết kế các nhiệm vụ cụ thể để nâng cao khả năng lý luận toàn cục của mô hình, chẳng hạn như việc chuyển đổi và sắp xếp các bảng. Những bài tập này được thiết kế một cách phức tạp để buộc mô hình phát triển sự hiểu biết toàn diện và tinh tế hơn về các cấu trúc dữ liệu phức tạp và mối quan hệ vốn có của chúng.

Các thí nghiệm rộng rãi của chúng tôi cho thấy giai đoạn SFT ngữ cảnh dài là quan trọng trong việc nâng cao khả năng ngữ cảnh dài của mô hình. Phương pháp của chúng tôi hiệu quả, chỉ cần hàng trăm lần lặp tiền huấn luyện và SFT ngữ cảnh dài để trang bị cho một LLM văn bản ngắn khả năng ngữ cảnh dài. LongSkywork hoạt động tốt trong bài kiểm tra Needle in a Haystack, như được thể hiện trong Hình 1. Hơn nữa, chúng tôi xác thực mô hình của mình bằng cả bài kiểm tra ngữ cảnh dài InfiniteBench (Zhang et al., 2023) và đánh giá thế giới thực được thu thập từ câu hỏi-trả lời ngữ cảnh dài trực tuyến. Kết quả cho thấy LongSkywork-13B có khả năng truy xuất ngữ cảnh dài mạnh mẽ, vượt trội hơn GPT4-128K và Claude2.1-200K trong ba nhiệm vụ dựa trên truy xuất và đạt kết quả trung bình ngang bằng với Moonshot trong InfiniteBench. Trong các đánh giá thế giới thực, LongSkywork-13B hoạt động tương đương với Claude2.1, nhưng với số lượng tham số ít hơn đáng kể.

Những đóng góp của bài báo này được tóm tắt như sau:

• Chúng tôi giới thiệu LongSkywork, một LLM ngữ cảnh dài với cửa sổ ngữ cảnh lên đến 200K. Chúng tôi cung cấp một công thức huấn luyện để mở rộng độ dài ngữ cảnh trong các LLM một cách hiệu quả.

• Chúng tôi đề xuất các phương pháp để xây dựng dữ liệu tổng hợp để tăng tốc việc học ngữ cảnh dài nhằm giải quyết vấn đề khan hiếm dữ liệu trong việc huấn luyện các LLM ngữ cảnh dài.

• Các mô hình của chúng tôi thể hiện khả năng mạnh mẽ trong các nhiệm vụ đòi hỏi truy xuất ngữ cảnh dài và khả năng toàn diện. Mô hình của chúng tôi ngang bằng với GPT-4-128K và Claude2.1 trong InfiniteBench.

## 2 Công trình liên quan

### 2.1 LLM ngữ cảnh dài

Việc điều chỉnh Transformers ( ??) và LLM (Touvron et al., 2023a) để xử lý ngữ cảnh dài là một lĩnh vực nghiên cứu quan trọng. Có hai hướng tiếp cận liên quan đến phương pháp của chúng tôi. Hướng thứ nhất là Nhúng Vị trí Xoay Mở rộng (RoPE). RoPE, được đề xuất bởi Su et al. (2024), được sử dụng rộng rãi trong các LLM phổ biến, như Llama (Touvron et al., 2023a,b) và PaLM (Anil et al., 2023). Nó sử dụng nhúng vị trí tuyệt đối để biểu diễn vị trí tương đối và cung cấp giải thích lý thuyết rõ ràng trong không gian phức. Gần đây, nhiều nhà nghiên cứu phát hiện rằng nhúng vị trí RoPE có thể mở rộng độ dài ngữ cảnh suy luận một cách hiệu quả với việc tinh chỉnh tối thiểu hoặc không cần tinh chỉnh (Chen et al., 2023a; Peng et al., 2023). Chen et al. (2023a) đề xuất Nội suy Vị trí (PI), áp dụng tỷ lệ tuyến tính trên mỗi chỉ số vị trí từ n đến n/k, làm dày đặc không gian biểu diễn để mở rộng độ dài xa nhất bằng k lần. Tuy nhiên, tỷ lệ tuyến tính đơn giản có thể dẫn đến không gian hạn chế, điều này có thể làm suy giảm hiểu biết của mô hình về khoảng cách chi tiết. Dựa trên lý thuyết Neural Tangent Kernel (Jacot et al., 2018), bloc97 (2023) đề xuất mở rộng độ dài ngoại suy bằng cách điều chỉnh cơ số trong hàm vị trí. Những phương pháp này được gọi là NTK-aware Scaling RoPE (NTK-aware RoPE), kết hợp ngoại suy tần số cao và nội suy tần số thấp. Do tính đơn giản và hiệu quả, nhiều LLM ngữ cảnh dài khai thác phương pháp này để ngoại suy (Roziere et al., 2023; Xiong et al., 2023). Yarn (Peng et al., 2023) kết hợp NTK-aware RoPE và nội suy vị trí. Phương pháp này đề xuất không nội suy các chiều tần số cao hơn, trong khi luôn nội suy các chiều thấp hơn.

Hướng nghiên cứu liên quan khác liên quan đến việc nghiên cứu dữ liệu huấn luyện trong việc mở rộng cửa sổ ngữ cảnh của các LLM. Các mô hình PI và YARN được tinh chỉnh trên bộ dữ liệu PG19 (Rae et al., 2019), đây là bộ dữ liệu sách với ngữ cảnh dài hơn đáng kể. Tuy nhiên, việc huấn luyện trên phân phối khác với giai đoạn tiền huấn luyện có thể có tác động tiêu cực đến hiệu suất của mô hình. Xiong et al. (2023) đề xuất kết hợp nhiều ngữ cảnh ngắn để đạt được độ dài mong muốn, điều này cũng làm cho việc huấn luyện hiệu quả hơn. Họ cũng phát hiện rằng việc tăng tỷ lệ văn bản dài không nhất thiết cải thiện hiệu suất của mô hình trên ngữ cảnh dài. Trong bài báo này, chúng tôi chỉ ra rằng chỉ bằng cách chia văn bản thành các khối và xen kẽ chúng để tạo thành một mẫu tiền huấn luyện ngữ cảnh dài, chúng tôi có thể cải thiện khả năng xử lý ngữ cảnh dài của mô hình mà không thay đổi phân phối huấn luyện của giai đoạn tiền huấn luyện. Hơn nữa, các công trình trước đây chủ yếu tập trung vào giai đoạn tiền huấn luyện ngữ cảnh dài và cung cấp hiểu biết hạn chế về cách giai đoạn SFT ngữ cảnh dài tác động đến hiệu suất của mô hình.

### 2.2 Dữ liệu tổng hợp được sử dụng trong LLM

Việc huấn luyện LLM trên dữ liệu do con người thu thập vẫn là phương pháp chủ đạo. Tuy nhiên, dữ liệu do con người tạo ra bị hạn chế và khó thu thập, đặc biệt trong các tình huống mô hình hóa ngôn ngữ ngữ cảnh dài (Xiong et al., 2023). Bên cạnh đó, dữ liệu do con người tạo ra sẽ cạn kiệt trong vài năm tới ( ?). Do đó, việc khám phá việc sử dụng dữ liệu tổng hợp để hỗ trợ huấn luyện và căn chỉnh LLM là một lĩnh vực nghiên cứu đầy hứa hẹn. Cao et al. (2023) phát hiện rằng GPT4 có thể tái tạo gần như hoàn hảo các câu gốc từ những câu đã bị xáo trộn. Kết quả là, các nhà nghiên cứu trong cộng đồng suy đoán rằng GPT4 có thể sử dụng dữ liệu tổng hợp để học. Ngoài ra, có nhiều nghiên cứu về việc sử dụng dữ liệu tổng hợp trong giai đoạn SFT. Wei et al. (2023a) phát hiện rằng việc tích hợp dữ liệu toán học tổng hợp trong SFT vượt trội đáng kể so với tinh chỉnh chỉ sử dụng dữ liệu con người. Shao et al. (2023) đề xuất sử dụng một vài ví dụ được tạo thủ công để nhắc mô hình tự tạo ra nhiều ví dụ hơn và chọn các minh chứng hiệu quả để khơi gợi lý luận tốt hơn. Sun et al. (2023) đề xuất nhắc các LLM tạo ra dữ liệu SFT căn chỉnh dựa trên một số ví dụ mẫu. Tuy nhiên, những phương pháp đó chỉ tập trung vào việc áp dụng LLM để tạo ra dữ liệu tổng hợp. Việc sử dụng lập trình để tạo ra dữ liệu tổng hợp để hỗ trợ trong giai đoạn SFT chưa được nghiên cứu rộng rãi. Trong bài báo này, chúng tôi sử dụng dữ liệu tổng hợp trong cả giai đoạn tiền huấn luyện và SFT, và chỉ ra rằng nó có thể tăng cường đáng kể sức mạnh của các LLM trong việc truy xuất và hiểu ngữ cảnh dài.

## 3 Phương pháp

### 3.1 Kiến thức cơ bản

Theo truyền thống, việc huấn luyện một LLM có thể được chia thành hai giai đoạn. Giai đoạn đầu tiên được gọi là giai đoạn tiền huấn luyện. Nó sử dụng mục tiêu ngôn ngữ tự hồi quy để tạo ra một chuỗi y={y₁, y₂, y₃, ... yₙ} dựa trên các token đã được tạo trước đó. Giả sử rằng mô hình ngôn ngữ được tham số hóa bởi θ, quá trình tự hồi quy có thể được mô tả như sau:

pθ(y) = pθ(yt, y<t).

Giai đoạn tiền huấn luyện được xem là việc tiêm phần lớn kiến thức vào các LLM (Zhou et al., 2023). Giai đoạn thứ hai được gọi là giai đoạn tinh chỉnh có giám sát, có thể được xem là việc dạy mô hình căn chỉnh định dạng. Một mẫu huấn luyện SFT bao gồm một truy vấn, được ký hiệu là x, được sử dụng làm đầu vào, và một đầu ra y mà mô hình muốn tạo ra dựa trên lời nhắc đó. Do đó, quá trình huấn luyện trong giai đoạn SFT có thể được chính thức hóa như sau:

pθ(y|x) = pθ(yt, y<t|x),

trong đó x được che và chỉ y tạo ra gradient để cập nhật các tham số của mô hình.

Công trình trước đây (Xiong et al., 2023) thêm một giai đoạn tiền huấn luyện ngữ cảnh dài sau giai đoạn tiền huấn luyện truyền thống. Giai đoạn tiền huấn luyện ngữ cảnh dài được thiết kế để giúp mô hình thích ứng với ngữ cảnh mới, chủ yếu là tham số mới của nhúng vị trí RoPE. Như được thể hiện trong Hình 3, chỉ hàng trăm lần lặp huấn luyện ngữ cảnh dài làm cho tổn thất huấn luyện hội tụ. PI và YARN sử dụng dữ liệu sách để tiến hành huấn luyện ngữ cảnh dài. Chúng tôi phát hiện thực nghiệm rằng nó làm cho giai đoạn tiền huấn luyện ngữ cảnh dài học một phân phối khác với phân phối trong giai đoạn tiền huấn luyện. Xiong et al. (2023) đã chứng minh rằng ngữ cảnh dài tự nhiên, như một cuốn sách hoặc kho mã nguồn, không cần thiết trong giai đoạn huấn luyện ngữ cảnh dài. Thay vào đó, chúng ta có thể nối các ngữ cảnh ngắn để tạo thành một ngữ cảnh dài hơn. Đáng ngạc nhiên, phương pháp này có thể vượt trội hơn một bộ dữ liệu với tỷ lệ văn bản dài cao hơn. Theo Xiong et al. (2023), chúng tôi sử dụng phân phối dữ liệu huấn luyện từ giai đoạn tiền huấn luyện và nối nó với ngữ cảnh dài để tạo thành dữ liệu huấn luyện cho giai đoạn tiền huấn luyện ngữ cảnh dài.

Sau khi tiến hành giai đoạn SFT tiêu chuẩn, chúng tôi phát hiện rằng việc thực hiện giai đoạn SFT ngữ cảnh dài cải thiện đáng kể việc truy xuất và hiểu thông tin ngữ cảnh dài. Xiong et al. (2023) đề xuất hợp nhất các mẫu SFT bình thường với các mẫu SFT ngữ cảnh dài và huấn luyện chúng cùng nhau. Tuy nhiên, chúng tôi nhận thấy rằng khi trộn SFT bình thường với dữ liệu SFT ngữ cảnh dài, gradient của ngữ cảnh ngắn có xu hướng át chìa dữ liệu SFT ngữ cảnh dài và mô hình hoạt động kém trong các nhiệm vụ ngữ cảnh dài. Điều này xảy ra vì giai đoạn SFT chỉ tính gradient cho phản hồi. Như được thấy trong Bảng 1, các mẫu SFT ngữ cảnh dài thường có phản hồi ngắn hơn so với lời nhắc của chúng. Những lời nhắc này thường bao gồm một ngữ cảnh từ Wikipedia hoặc một cuốn sách, theo sau là một câu hỏi liên quan. Câu trả lời cho câu hỏi, thường ngắn gọn, thường là thông tin chính trong ngữ cảnh này. Ngược lại, dữ liệu SFT bình thường thường liên quan đến các truy vấn được viết một cách sáng tạo với phản hồi tương đối dài hơn so với lời nhắc của chúng. Hơn nữa, việc huấn luyện một mô hình với 13B tham số trong cửa sổ ngữ cảnh 4K mang lại thông lượng khoảng 1775 token mỗi giây mỗi GPU. Tuy nhiên, khi huấn luyện với cửa sổ ngữ cảnh 100K, tốc độ giảm xuống khoảng 180 token mỗi giây mỗi GPU. Nếu chúng ta kết hợp SFT ngắn với SFT ngữ cảnh dài cùng nhau và chỉ thực hiện một giai đoạn SFT ngữ cảnh dài, một lượng đáng kể tài nguyên huấn luyện sẽ bị lãng phí. Do đó, chúng tôi đề xuất sử dụng cửa sổ ngữ cảnh ngắn, như 4K, để căn chỉnh. Sau đó, chúng tôi sử dụng cửa sổ ngữ cảnh dài, như 100K, để huấn luyện hỗn hợp dữ liệu SFT ngữ cảnh dài và dữ liệu SFT bình thường. Chúng tôi tích hợp các mẫu SFT bình thường trong giai đoạn SFT ngữ cảnh dài để bảo toàn khả năng căn chỉnh của mô hình.

### 3.2 Dữ liệu tổng hợp trong giai đoạn tiền huấn luyện liên tục ngữ cảnh dài

Xiong et al. (2023) đề xuất nối các văn bản ngắn thành các văn bản dài hơn để duy trì phân phối dữ liệu tương tự như giai đoạn tiền huấn luyện. Tuy nhiên, trong nghiên cứu của chúng tôi, chúng tôi phát hiện rằng việc chỉ nối các văn bản ngắn trong quá trình tiền huấn luyện khiến mô hình học các mẫu ngắn và gặp khó khăn trong việc hiểu các phụ thuộc ngữ cảnh dài. Chúng tôi đề xuất một phương pháp đơn giản nhưng hiệu quả để tăng tốc quá trình này. Phương pháp này sử dụng các văn bản ngắn để học các phụ thuộc dài. Cụ thể, chúng tôi chia một số tài liệu tương đối ngắn thành các đoạn và sau đó sắp xếp lại những đoạn này theo cách xen kẽ để tạo thành một mẫu huấn luyện dài hơn. Giả sử D={d₁, d₂, ..., dₘ} là một bộ dữ liệu tiền huấn luyện chứa m tài liệu. Để cải thiện luồng tường thuật, chúng tôi giả sử rằng số lượng token của tất cả tài liệu là n. Do đó, dᵢ={x¹ᵢ, x²ᵢ, ... xⁿᵢ}, trong đó x đại diện cho các từ trong tài liệu. Trong phần tiếp theo, chúng tôi sử dụng ví dụ n=3 để minh họa phương pháp của mình. Các phương pháp trước đây để kết hợp nhiều tài liệu ngắn để tạo thành một tài liệu dài hơn liên quan đến việc kết nối trực tiếp dlong={x¹₁, x¹₂, x¹ₙ, x²₁, x²₃, x²ₙ, x³₁, x³₂, x³ₙ}. Phương pháp được đề xuất của chúng tôi là đầu tiên chia tài liệu thành nhiều khối, dᵢ={c¹ᵢ, c²ᵢ, c³ᵢ}, dⱼ={c¹ⱼ, c²ⱼ, c³ⱼ} trong đó c biểu thị khối tài liệu, bao gồm các token. Sau đó chúng tôi tổ chức xen kẽ các khối từ nhiều tài liệu thành một tài liệu duy nhất như dlong={c¹ᵢ, c¹ⱼ, c²ᵢ, c²ⱼ, c³ᵢ, c³ⱼ}. Quá trình này buộc mô hình tập trung vào thông tin liên quan ở khoảng cách xa, từ đó giảm thiểu tổn thất trong quá trình tạo ra token hiện tại trong giai đoạn tiền huấn luyện. Lưu ý rằng thứ tự từ trong tài liệu được bảo tồn, điều này cho phép cơ chế chú ý tập trung vào thông tin cần thiết để tạo ra các token hiện tại. Nếu độ dài vượt quá độ dài tối đa được đặt, nó sẽ bị cắt bớt để phù hợp trong giới hạn. Nếu độ dài ngắn hơn độ dài tối đa, nó sẽ được đệm để đạt tối đa.

### 3.3 Dữ liệu tổng hợp trong giai đoạn SFT ngữ cảnh dài

Việc tạo ra dữ liệu có giám sát dài và có ý nghĩa là một nhiệm vụ tốn kém và tốn nhiều công sức. Điều này đặt ra câu hỏi: liệu chúng ta có thể sử dụng dữ liệu tổng hợp để nâng cao khả năng xử lý thông tin ngữ cảnh rộng lớn của mô hình không?

Trong bài báo này, chúng tôi đề xuất sử dụng dữ liệu tổng hợp được tạo bởi chương trình để cải thiện khả năng truy xuất và hiểu thông tin ngữ cảnh dài của Mô hình Ngôn ngữ. Chúng tôi định nghĩa dữ liệu SFT ngữ cảnh dài tổng hợp như một nhiệm vụ xử lý bảng. Điều này là vì việc tạo ra một bảng theo chương trình là đơn giản và kiểm soát các thuộc tính của nó như độ dài và độ khó. Bảng đầu vào có thể là bảng địa chỉ IP, biểu mẫu đăng ký thông tin, hoặc thậm chí là tệp HTML hoặc markdown với nhiều trường và dòng. Để phù hợp với thông tin có độ dài khác nhau, chúng tôi tạo ra các bảng từ 2k đến 100K token. Các trường và dữ liệu trong bảng được tạo ra bằng Faker³. Mô tả chi tiết về ba loại nhiệm vụ chính mà chúng tôi xây dựng sẽ được cung cấp.

• Nhiệm vụ truy xuất thông tin: Chúng tôi nhắc mô hình ngôn ngữ truy xuất thông tin từ một bảng dựa trên các ràng buộc nhất định, chẳng hạn như "Chọn người trẻ nhất trong bảng này và cho tôi email của họ."

• Nhiệm vụ lý luận CoT: Chúng tôi nhắc mô hình ngôn ngữ tạo ra một bước lý luận Chuỗi-của-suy-nghĩ (Wei et al., 2022) để trả lời câu hỏi. Ví dụ, khi được hỏi "Tính chênh lệch tuổi giữa nam giới lớn tuổi nhất và nữ giới trẻ nhất", mô hình đầu tiên xác định tuổi của nam giới lớn tuổi nhất và nữ giới trẻ nhất. Kết quả cuối cùng sau đó được tính bằng cách trừ hai giá trị này.

• Nhiệm vụ hiểu toàn cục: Nhiệm vụ này đòi hỏi mô hình phải có hiểu biết toàn diện về cấu trúc và thông tin được trình bày trong bảng để đưa ra kết quả chính xác. Ví dụ, khi được nhắc sắp xếp bảng theo tuổi, mô hình ngôn ngữ cần có hiểu biết toàn diện về bảng và sau đó đưa ra bảng được sắp xếp chính xác.

## 4 Thí nghiệm

### 4.1 Tiền huấn luyện ngữ cảnh dài xen kẽ khối (CIP)

Phù hợp với công trình trước đây (Roziere et al., 2023; Xiong et al., 2023), chúng tôi duy trì kiến trúc Skywork cốt lõi hầu như không thay đổi cho tiền huấn luyện ngữ cảnh dài. Chúng tôi chỉ thực hiện điều chỉnh cần thiết đối với mã hóa vị trí, cho phép mô hình tập trung vào ngữ cảnh dài hơn. Cụ thể, chúng tôi giảm góc xoay (được kiểm soát bởi siêu tham số "tần số cơ sở b"), điều này làm giảm hiệu ứng giảm dần của RoPE đối với các token xa. Chúng tôi thay đổi cơ sở từ 10000 thành 2600000, theo lời khuyên của Liu et al. (2023b), để mở rộng một mô hình đã được tiền huấn luyện từ cửa sổ ngữ cảnh 4K để mở rộng nó đến cửa sổ ngữ cảnh 200K. Để biết thêm thông tin, những người quan tâm có thể tham khảo bài báo của họ.

Việc huấn luyện mô hình ngôn ngữ lớn trên cửa sổ ngữ cảnh dài có thể rất tốn kém. Trong trường hợp của chúng tôi, chúng tôi sử dụng mô hình Skywork-3B được huấn luyện trên cửa sổ ngữ cảnh 64K của văn bản web Redpajama (Computer, 2023) để đánh giá hiệu quả của các phương pháp được đề xuất. Để tạo ra tài liệu cuối cùng, chúng tôi kết hợp nhiều tài liệu cho đến khi chúng đạt độ dài khoảng 64K. Sau đó chúng tôi đệm tài liệu lên 64K. Nếu tài liệu cuối cùng vượt quá 64K, chúng tôi chỉ đơn giản loại bỏ bất kỳ token thừa nào. Thật thú vị khi khám phá tác động của số lượng khối trên mỗi tài liệu đối với hiệu suất của mô hình. Chúng tôi chia đầu vào văn bản một cách heuristic thành 2 khối, 4 khối và 8 khối. Các mô hình được huấn luyện với những phương pháp này được gọi là 3B-CIP-2, 3B-CIP-4 và 3B-CIP-8. Mô hình cơ sở được huấn luyện trên một corpus trong đó các tài liệu được nối trực tiếp thành các tài liệu dài, mà chúng tôi ký hiệu là 3B-DC. Corpus huấn luyện được sử dụng cho cả mô hình cơ sở và mô hình của chúng tôi là giống hệt nhau. Do đó, mô hình cơ sở cũng có thể được coi là một mô hình với Chunk1.

Chúng tôi sử dụng tối ưu hóa AdamW (Loshchilov và Hutter, 2017) và đặt tốc độ học tối đa là 1e-5, với sự suy giảm tốc độ học xuống 1e-6. Chúng tôi huấn luyện mỗi mô hình trong 500 lần lặp. Đánh giá hiệu suất của các mô hình sau giai đoạn tiền huấn luyện liên tục ngữ cảnh dài tập trung vào khả năng truy xuất thông tin chính của nó. Cụ thể, chúng tôi sử dụng cách thức năm-shot để đánh giá các mô hình đã được tiền huấn luyện, như được giới thiệu bởi Team (2023). Như được thể hiện trong Bảng 2, các phương pháp của chúng tôi có thể cải thiện đáng kể khả năng truy xuất thông tin few-shot của một mô hình đã được tiền huấn luyện. 3B-CIP-2 đạt điểm truy xuất 0.514, tăng độ chính xác của mô hình cơ sở 0.338 khoảng 52.07%. Ngoài ra, chúng tôi đánh giá mỗi mô hình bằng các nhiệm vụ mô hình hóa ngôn ngữ tiếng Trung và tiếng Anh, cũng như các nhiệm vụ hiểu ngôn ngữ. Như được thấy trong Bảng 3, so với phương pháp cơ sở, phương pháp được đề xuất của chúng tôi làm tăng nhẹ tổn thất xác thực cho mô hình hóa ngôn ngữ tiếng Anh và tiếng Trung. Cụ thể, tổn thất xác thực văn bản web tiếng Anh của mô hình 3B-CIP-2 là 2.101, thấp hơn 0.33% so với mô hình cơ sở. Tổn thất xác thực văn bản web tiếng Trung của mô hình 3B-CIP-2 là 2.152, thấp hơn 0.13% so với mô hình cơ sở. Khi đo lường khả năng hiểu ngôn ngữ tiếng Anh và tiếng Trung bằng hai bài kiểm tra phổ biến, C-EVAL (Huang et al., 2023) và MMLU (Hendrycks et al., 2020), chúng tôi thấy rằng các phương pháp của chúng tôi hoạt động ngang bằng với mô hình cơ sở trong cả hai nhiệm vụ. Do mục tiêu cải thiện khả năng xử lý thông tin ngữ cảnh rộng lớn của mô hình, một sự giảm nhẹ trong nhiệm vụ mô hình hóa ngôn ngữ bình thường là dự kiến. Vì chúng tôi thấy rằng 3B-CIP-2 hoạt động tốt nhất tổng thể, chúng tôi tuân theo cài đặt này để huấn luyện các mô hình lớn hơn.

### 4.2 SFT ngữ cảnh dài tổng hợp (SynL)

Sau giai đoạn tiền huấn luyện ngữ cảnh dài, chúng tôi thực hiện giai đoạn SFT để căn chỉnh mô hình, với cửa sổ ngữ cảnh được đặt thành 4k. Xin lưu ý rằng trong giai đoạn tiền huấn luyện liên tục ngữ cảnh dài, giai đoạn SFT và giai đoạn SFT ngữ cảnh dài, cấu trúc mô hình và cơ sở trong RoPE vẫn không đổi, được đặt thành 260000.

Trong giai đoạn SFT ngữ cảnh dài, nguồn dữ liệu có thể được chia thành ba loại. Loại đầu tiên bao gồm dữ liệu SFT bình thường, được duy trì để bảo toàn khả năng căn chỉnh. Loại thứ hai liên quan đến dữ liệu SFT ngữ cảnh dài được thu thập tự nhiên, như hỏi đáp sách và tóm tắt sách. Chúng tôi gọi dữ liệu này là dữ liệu SFT ngữ cảnh dài thực. Loại thứ ba liên quan đến dữ liệu SFT ngữ cảnh dài tổng hợp của chúng tôi. Dựa trên các thí nghiệm sơ bộ, chúng tôi phát hiện rằng việc duy trì tỷ lệ dữ liệu SFT bình thường ở 20% mang lại hiệu suất tốt nhất. Do đó, trong các thử nghiệm sau, chúng tôi sẽ giữ tỷ lệ dữ liệu SFT bình thường không thay đổi.

Chúng tôi đánh giá khả năng ngữ cảnh dài của mỗi mô hình trên InfiniteBench (Zhang et al., 2023), được thiết kế để đánh giá khả năng của các mô hình ngôn ngữ trong việc xử lý, hiểu và lý luận trên các ngữ cảnh siêu dài (100k+ token). Bài kiểm tra này bao gồm các nhiệm vụ liên quan đến truy xuất và hiểu ngữ cảnh dài bằng tiếng Anh, tiếng Trung, Mã và Toán.

#### 4.2.1 Mô hình cơ sở

Chúng tôi so sánh các phương pháp của mình với một số API mô hình độc quyền, như GPT4, Claude, Moonshot, và một số mô hình cơ sở mã nguồn mở như sau:

• Yarn-Mistral-7B-128K (Peng et al., 2023): Mô hình này là một mô hình ngữ cảnh dài được trình bày bởi NousResearch⁴. Mô hình dựa trên Mistral (Jiang et al., 2023) và sử dụng Yarn (Peng et al., 2023) để mở rộng cửa sổ ngữ cảnh đến 128K.

• Yarn-Llama2-13B-128K (Peng et al., 2023): Mô hình này dựa trên Llama2-13B (Touvron et al., 2023b) và sử dụng Yarn để mở rộng cửa sổ ngữ cảnh đến 128K.

• LongSkywork-13B-T: Mô hình này là một biến thể của LongSkywork-13B sử dụng 20% dữ liệu SFT bình thường và 80% dữ liệu SFT ngữ cảnh dài thực được thu thập từ LongAlpaca (Chen et al., 2023b) và LongCollection⁵.

• LongSkywork-13B-S: Mô hình này là một biến thể của LongSkywork-13B, sử dụng 20% dữ liệu SFT bình thường và 80% dữ liệu SFT tổng hợp ngữ cảnh dài.

• LongSkywork-13B-S&T: Mô hình này là một biến thể của LongSkywork-13B, sử dụng 20% dữ liệu SFT bình thường, 40% dữ liệu SFT ngữ cảnh dài thực, và 40% dữ liệu SFT tổng hợp ngữ cảnh dài.

Kết quả được nêu trong Bảng 4. Dữ liệu tổng hợp được đề xuất của chúng tôi rất hiệu quả. LongSkywork-13B-S đạt điểm trung bình 37.8%, vượt trội so với LongSkywork-13B-T với khoảng cách lớn, mô hình này đạt 24.7%. Chúng tôi thấy dữ liệu tổng hợp có thể nâng cao đáng kể khả năng truy xuất ngữ cảnh dài của một LLM, tăng từ 49.3% lên 94.0% trung bình trên ba nhiệm vụ dựa trên truy xuất. Ngoài các nhiệm vụ dựa trên truy xuất, dữ liệu tổng hợp cũng có thể cải thiện nhiệm vụ hỏi đáp tiếng Trung từ 11.6% lên 15.1%, chứng minh rằng các phương pháp của chúng tôi có thể nâng cao khả năng hiểu ngữ cảnh dài của một LLM. Tuy nhiên, chúng tôi quan sát thấy sự giảm trong nhiệm vụ EN.sum từ 16.4% xuống 8.5% vì không có dữ liệu liên quan đến tóm tắt trong dữ liệu tổng hợp. Điều này để lại việc xây dựng dữ liệu liên quan đến tóm tắt như công việc tương lai. Khi hợp nhất dữ liệu tổng hợp với dữ liệu long-SFT thực tế, chúng tôi quan sát thấy sự cải thiện trong điểm trung bình, mặc dù có sự giảm nhẹ trong các nhiệm vụ dựa trên truy xuất. Chúng tôi tin rằng điều này là do tỷ lệ trộn dữ liệu không chính xác. Mô hình tinh chỉnh của chúng tôi, LongSkywork-13B, nâng cao việc trộn dữ liệu này và tích hợp dữ liệu chú thích được chọn. Kết quả cuối cùng là hiệu suất 47.5%, vượt trội hơn cả Moonshot và Claude2.1. Lưu ý rằng so với các mô hình độc quyền khác, mô hình của chúng tôi có thể có ít tham số hơn, cụ thể là chỉ 13 tỷ tham số.

Để đánh giá hiệu quả của LongSkywork trong các tình huống sử dụng thực tế, chúng tôi tạo ra một bài kiểm tra dựa trên các trường hợp sử dụng thực tế từ trang web Tiangong AI Reading⁶. Chúng tôi thu thập 856 câu hỏi thuộc nhiều loại khác nhau, bao gồm câu hỏi về chi tiết trong tài liệu, tóm tắt tài liệu, và câu hỏi không thể trả lời dựa trên tài liệu. Sau đó chúng tôi yêu cầu các chú thích viên cung cấp câu trả lời tham khảo cho mỗi câu hỏi. Chúng tôi sử dụng GPT-4 để đánh giá, so sánh các câu trả lời tham khảo với các câu trả lời được cung cấp bởi các mô hình. Kết quả được hiển thị trong Bảng 5. Mô hình LongSkywork-13B của chúng tôi đạt điểm tổng thể 69.24, thấp hơn một chút so với mô hình ngữ cảnh dài tối tân Claude2.1, đạt 72.27. Điều này cho thấy phương pháp của chúng tôi thể hiện hiệu suất hiệu quả khi nói đến các câu hỏi tình huống thế giới thực.

#### 4.2.2 Hạn chế và công việc tương lai

Trong phần này, chúng tôi thảo luận về một số hạn chế của các phương pháp được đề xuất để nghiên cứu tương lai. Chúng tôi xác định hai vấn đề với LongSkywork như được thể hiện trong Bảng 6. Thứ nhất, nó gặp khó khăn trong việc xử lý hiệu quả các câu hỏi không thể trả lời, có thể do số lượng mẫu huấn luyện không thể trả lời hạn chế. Thứ hai, nó gặp khó khăn với lý luận phức tạp ngữ cảnh dài và tính toán, có thể do thách thức trong việc rút ra các bước lý luận chính xác từ một mô hình cơ sở 13B tham số. Trong tương lai, chúng tôi sẽ cố gắng nâng cao hai khía cạnh nói trên của LongSkywork.

## 5 Kết luận

Trong bài báo này, chúng tôi trình bày công thức huấn luyện của LongSkywork và đề xuất hai phương pháp để xây dựng dữ liệu tổng hợp nhằm nâng cao khả năng truy xuất và hiểu ngữ cảnh dài của các LLM. Phương pháp đầu tiên, được gọi là CIP, tổ chức lại các khối tài liệu huấn luyện để tạo ra một mẫu huấn luyện dài. Phương pháp này giúp các LLM học các phụ thuộc dài hạn hiệu quả hơn. Phương pháp thứ hai, được gọi là SynL, tạo ra nhiều cặp câu hỏi ngữ cảnh dài, có thể nâng cao lý luận và giải quyết vấn đề khan hiếm dữ liệu phổ biến trong SFT ngữ cảnh dài. Chúng tôi tiến hành các thí nghiệm rộng rãi để đánh giá hiệu quả của các phương pháp được đề xuất. Trong InfiniteBench, LongSkywork-13B đạt điểm trung bình 47.5, ngang bằng hoặc vượt qua hiệu suất của các API LLM độc quyền hàng đầu. Trong đánh giá sử dụng thế giới thực, mô hình LongSkywork-13B của chúng tôi chỉ giảm hiệu suất nhẹ so với Claude2.1. Chúng tôi cũng chỉ ra hai hạn chế của LongSkywork: xử lý các câu hỏi không thể trả lời và giải quyết các vấn đề lý luận dài phức tạp. Chúng tôi sẽ ưu tiên những chủ đề này trong công việc tương lai.

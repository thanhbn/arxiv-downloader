# 2312.14327.pdf
# Chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2312.14327.pdf
# Kích thước tệp: 253294 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================

--- TRANG 1 ---
Điều chỉnh Hiệu quả Tham số Cho phép Cá nhân hóa Có thể mở rộng của LLM cho
Nhập văn bản: Một Nghiên cứu Trường hợp về Mở rộng Từ viết tắt
Katrin Tomanek, Shanqing Cai, Subhashini Venugopalan
Google LLC
Tóm tắt
Mở rộng từ viết tắt là một chiến lược được sử dụng
để tăng tốc giao tiếp bằng cách hạn chế lượng
gõ phím và sử dụng mô hình ngôn ngữ
để đề xuất mở rộng. Ở đây chúng tôi xem xét việc cá
nhân hóa đề xuất của Mô hình Ngôn ngữ Lớn (LLM)
dựa trên các cuộc hội thoại trước để nâng
cao tính liên quan của dự đoán, đặc biệt
khi dữ liệu người dùng nhỏ (≈1000 mẫu).
Cụ thể, chúng tôi so sánh fine-tuning, prompt-
tuning, và tạo tăng cường truy xuất các
đề xuất văn bản mở rộng cho đầu vào viết tắt.
Nghiên cứu trường hợp của chúng tôi với một LLM tham số 8B
được triển khai trên người dùng thực sống với ALS,
và các thí nghiệm về cá nhân hóa nhân vật phim
chỉ ra rằng (1) tùy chỉnh có thể cần thiết
trong một số kịch bản và prompt-tuning
tổng quát hóa tốt cho những trường hợp đó, (2) fine-tuning trên
dữ liệu trong miền (với ít nhất 600 mẫu)
vẫn cho thấy một số cải thiện, tuy nhiên (3) việc lựa chọn
few-shot tăng cường truy xuất cũng vượt trội hơn
fine-tuning. (4) Điều chỉnh hiệu quả tham số cho
phép cá nhân hóa hiệu quả và có thể mở rộng.
Đối với prompt-tuning, chúng tôi cũng thấy rằng việc khởi tạo
các "soft-prompts" học được thành các token khái niệm
liên quan đến người dùng dẫn đến độ chính xác cao hơn so với
khởi tạo ngẫu nhiên.

1 Giới thiệu
Mô hình ngôn ngữ đã được sử dụng từ lâu để giảm
số lần gõ phím và hỗ trợ nhập văn bản trong bàn phím thông minh.
Công trình này xem xét các mô hình cho các ứng dụng bàn phím như vậy
trong các thiết bị Giao tiếp Tăng cường và Thay thế
(AAC), đặc biệt là những thiết bị dành cho
người dùng có khuyết tật vận động nghiêm trọng, ví dụ, những
người sống với bệnh xơ cứng teo cơ một bên (ALS)
người giao tiếp thông qua gõ bằng mắt. Những
tiến bộ gần đây trong khả năng tạo sinh của các mô hình
ngôn ngữ lớn (LLM) có thể giúp tăng tốc đáng kể
giao tiếp cho những người dùng như vậy. Các nghiên cứu trước
(Adhikary et al., 2021; Cai et al., 2022; Shen
et al., 2022) đã đề xuất các kỹ thuật cho việc mở rộng
từ viết tắt, trong đó người dùng gõ các từ khóa ngắn hoặc các cụm từ viết tắt bao gồm chữ cái đầu
của mỗi từ và một LLM được sử dụng để tạo
câu mở rộng đầy đủ. Bao gồm ngữ cảnh cuộc hội thoại
(Wisenburn và Higginbotham, 2008;
Gorman et al., 2021) đã được chứng minh là cải thiện thêm
độ chính xác của các dự đoán. Trong công trình này chúng tôi khám
phá cá nhân hóa, một chiều khác có thể
cải thiện tính liên quan của các dự đoán để phù hợp với
từ vựng và phong cách ngôn ngữ của người dùng.

Trong nhiều ứng dụng thực tế, cá nhân hóa
đóng vai trò quan trọng trong việc nâng cao tính liên quan
của các tùy chọn được đề xuất và chất lượng của
trải nghiệm người dùng (Valencia et al., 2023). Tuy nhiên,
rất ít dữ liệu có sẵn để điều chỉnh mô hình cho
một người dùng nhất định, và các mô hình lớn hơn tăng nguy cơ
overfitting. Ngoài ra, vẫn chưa rõ làm thế nào để mở rộng
phương pháp cho nhiều người dùng với chi phí cao
của việc lưu trữ và phục vụ checkpoint LLM.

Với những thách thức này trong tâm trí, công trình của chúng tôi đánh
giá ba phương pháp cá nhân hóa LLM cho
mở rộng từ viết tắt như được sử dụng bởi những người gõ bằng mắt.
Cụ thể, chúng tôi xem xét một LLM decoder-only được pre-train
được điều chỉnh cho đối thoại (Roller et al., 2020; Thop-
pilan et al., 2022). Chúng tôi tiếp tục fine-tune mô hình
trên nhiệm vụ mở rộng từ viết tắt trên dữ liệu có nguồn gốc
từ các bộ dữ liệu đối thoại. Sau đó chúng tôi so sánh việc cá nhân
hóa LLM được fine-tune này trên dữ liệu cụ thể của người dùng thông qua
(1) fine-tuning toàn bộ mô hình, (2) tăng cường
ngữ cảnh của LLM bằng cách truy xuất các cuộc hội thoại tương tự
từ lịch sử của người dùng, và (3) prompt-tuning hiệu quả
tham số (Lester et al., 2021). Nhìn chung,
prompt-tuning có hiệu suất tốt nhất và việc học trong ngữ cảnh
tăng cường truy xuất (RA-ICL) cũng vượt trội hơn
fine-tuning.

2 Công trình Liên quan
2.1 Mô hình ngôn ngữ cho nhập văn bản.
Việc sử dụng mô hình ngôn ngữ để mở rộng đầu vào viết tắt
cho nhập văn bản đã được nghiên cứu kỹ và các
lược đồ viết tắt khác nhau đã được đề xuất

--- TRANG 2 ---
như, chỉ sử dụng từ ngữ cảnh (Demasco và
McCoy, 1992), loại bỏ nguyên âm (Shieber và
Nelken, 2007), và bổ sung bỏ qua các phụ âm
lặp lại (Willis et al., 2005), các lược đồ tiết kiệm chữ cái
linh hoạt (Adhikary et al., 2021; Gorman et al.,
2021), và mở rộng từ một túi từ (Shen
et al., 2022). Nghiên cứu của chúng tôi tập trung vào mở rộng từ viết tắt
được sử dụng bởi những người gõ bằng mắt sống với
khuyết tật vận động nghiêm trọng. Với mục tiêu
giảm đáng kể số lần gõ phím, chúng tôi xem xét
một dạng viết tắt từ đầu tương tự như Cai
et al. (2022) trong đó chỉ các ký tự đầu của
các từ được gõ và một LLM dự đoán câu đầy đủ.
Nghiên cứu hiện tại tập trung vào việc cá nhân hóa
một mô hình như vậy cho người dùng, điều này ít được nghiên cứu hơn.

2.2 Kỹ thuật prompt của LLM.
LLM đã cho thấy khả năng đáng chú ý trong
việc hiểu và thực hiện các nhiệm vụ với few-
shot (Brown et al., 2020) ví dụ. Tuy nhiên,
tokenization được sử dụng trong LLM làm cho nhiệm vụ tạo
mở rộng từ các ký tự đơn của chúng tôi trở nên khó khăn
cho các mô hình. Do lý do này và để
cho phép cá nhân hóa, chúng tôi tập trung vào Điều chỉnh Hiệu quả
Tham số (PEFT) (Lester et al., 2021),
và tạo tăng cường truy xuất (RAG) (Mi-
alon et al., 2023). PEFT học một tập hợp nhỏ các tham
số bổ sung trong khi giữ các trọng số của
LLM gốc bị đóng băng. Nhiều phương pháp PEFT
đã được đề xuất trong những năm gần đây. Trong trường hợp
adapters (Houlsby et al., 2019) và Tối ưu hóa Thứ hạng Thấp
(LoRA) (Hu et al., 2021) các tham số này
được xen kẽ ở các lớp transformer khác nhau
của mô hình. Các phương pháp khác như, Prompt-
tuning (Lester et al., 2021), Prefix-tuning (Li và
Liang, 2021), và P-tuning (Liu et al., 2021) hạn chế
các tham số vào các token prompt đầu vào. Chúng tôi sử dụng
prompt-tuning (Lester et al., 2021) mà thêm
các tham số vào embeddings token. Chúng tôi cũng so
sánh điều này với tăng cường truy xuất cho ICL (Rubin
et al., 2022) trong đó một bộ truy xuất dày đặc được sử dụng để
lựa chọn điểm dữ liệu liên quan được thêm vào làm
ngữ cảnh cho mô hình trả lời tạo sinh. Trong khi
hầu hết các nghiên cứu RAG (Mialon et al., 2023) đào tạo
bộ truy xuất hoặc bộ tạo, chúng tôi giữ cả hai
mô hình pre-trained này đóng băng. Cụ thể, chúng tôi sử dụng
ngữ cảnh được truy xuất để tạo các ví dụ few-shot
liên quan hơn cụ thể cho truy vấn đầu vào.

3 Điều chỉnh và cá nhân hóa
Phương pháp rộng của chúng tôi bao gồm việc lấy một LLM
pre-trained, thực hiện fine-tuning có giám sát cho nhiệm vụ mở rộng từ viết tắt, và sau đó cá nhân
hóa mô hình trên dữ liệu người dùng bằng phương tiện
fine-tuning thêm, prompt-tuning, hoặc tạo few-shot
trong ngữ cảnh tăng cường truy xuất. Đối với
mô hình pre-trained, chúng tôi bắt đầu với một LLM
decoder-only tham số 8B. Mô hình này được pre-train trên
bộ dữ liệu C4 (Raffel et al., 2019) và được điều chỉnh cho
đối thoại (Roller et al., 2020; Thoppilan et al., 2022).
Sau đó chúng tôi fine-tune nó thêm cho mở rộng từ viết tắt
trên các câu từ cuộc hội thoại và văn bản viết tắt
từ đầu liên quan. Chúng tôi tuân theo các công trình trước
(Cai et al., 2022) và thí nghiệm với các
tỷ lệ học khác nhau, và sử dụng tỷ lệ không đổi trong
fine-tuning và chọn tốt nhất dựa trên tập
validation. Chúng tôi gọi đây là mô hình base-AE. Chúng tôi
khám phá 3 chiến lược cho cá nhân hóa.

3.1 Fine-tuning trên dữ liệu người dùng.
Chúng tôi tuân theo công thức fine-tuning tương tự trên dữ liệu người dùng
như với mô hình base-AE. Việc điều chỉnh bản thân
nhanh vì lượng dữ liệu người dùng nhỏ, và chúng tôi
tránh overfitting bằng cách theo dõi hiệu suất trên
tập validation. Chúng tôi thí nghiệm với tỷ lệ học
1e-5, 1e-6, và 5e-5 và thấy 5e-5 hoạt động
tốt nhất (xem App. Tab. 6).

3.2 Few-shot và Học Trong Ngữ cảnh
Tăng cường Truy xuất (RA-ICL)
Một cách khác để cá nhân hóa LLM là cung cấp
cho nó các ví dụ few-shot để cho phép học trong ngữ cảnh
(ICL). Hiệu suất với ICL có thể thay đổi
đáng kể với các ví dụ few-shot (Zhao et al.,
2021). Do đó, ngoài các ví dụ few-shot
điển hình, chúng tôi cũng điều tra một thiết lập few-shot
tăng cường truy xuất. Điều này tương tự như các công trình
truy xuất từ cơ sở dữ liệu để tăng cường LLM (Mialon
et al., 2023) nhưng chúng tôi sử dụng các mô hình
pre-trained hiện có để truy xuất và tạo, và giữ chúng
đóng băng. Đối với bộ truy xuất, chúng tôi sử dụng một
Sentence-T5 11B pre-trained (Ni et al., 2022) và tạo
embeddings của các đầu vào viết tắt từ
cuộc hội thoại người dùng. Với một đầu vào mới, chúng tôi embed nó và
sử dụng khoảng cách Euclidean để truy xuất các truy vấn
láng giềng gần nhất và các mở rộng tương ứng. Chúng tôi
sử dụng ngữ cảnh được truy xuất này để tạo các ví dụ few-shot
liên quan, cụ thể cho truy vấn mà chúng tôi prompt
LLM.

3.3 Prompt-tuning
Chúng tôi cũng điều tra prompt-tuning (Lester et al.,
2021) cho cá nhân hóa. Ý tưởng cơ bản là
mở rộng prompting few-shot và sử dụng đáng kể

--- TRANG 3 ---
nhiều ví dụ trong ngữ cảnh hơn để học "soft-prompts"
trong lớp embedding đầu vào được thiết kế đặc biệt cho
nhiệm vụ hiện tại. Chúng tôi chọn độ dài của soft
prompt và khởi tạo các token. Để điều chỉnh, chúng tôi
tương ứng thêm các tham số có thể học mới vào
ma trận embedding của mô hình được cập nhật bằng
lan truyền ngược, giữ các trọng số LLM gốc
đóng băng. Số lượng tham số học được
là tích của độ dài soft-prompt và
kích thước của trọng số embedding. Các soft-prompts
học được được lưu và truyền cùng với mỗi
truy vấn người dùng đến LLM trong quá trình suy luận. Phương pháp
này cho phép một LLM duy nhất được phục vụ, và
soft-prompt được hoán đổi cho các người dùng khác nhau (xem
Sec. 6). Bản thân các soft-prompts có thể được điều chỉnh
trên lượng dữ liệu khác nhau, và hiệu quả trong
cài đặt dữ liệu thấp (Lester et al., 2021). Chúng tôi đào tạo với
lịch trình tỷ lệ học warm-up với 1000 bước warm up
đến đỉnh 0.1 theo sau bởi suy giảm tuyến tính. Chúng tôi
sử dụng kích thước batch nhỏ là 16 để đào tạo và giới hạn
đào tạo đến 20k bước. Chúng tôi thí nghiệm với
độ dài prompt khác nhau và chiến lược khởi tạo, và
chọn checkpoint tốt nhất dựa trên độ chính xác tập
validation.

4 Bộ dữ liệu
4.1 Mô hình Cơ sở Mở rộng Từ viết tắt
Để fine-tune LLM cho nhiệm vụ mở rộng từ viết tắt
, chúng tôi cần các cặp cụm từ viết tắt và
văn bản mở rộng đầy đủ. Chúng tôi sử dụng dữ liệu từ Cai
et al. (2022) nơi họ chuẩn bị các câu được ghép đôi
và đầu vào viết tắt từ bốn bộ dữ liệu đối thoại:
Turk Dialogues từ đám đông (Vertanen, 2017),
DailyDialog (Li et al., 2017), Cornell Movie Di-
alogues (Danescu-Niculescu-Mizil và Lee, 2011)
từ kịch bản phim, và bộ dữ liệu Turk AAC (Verta-
nen và Kristensson, 2011) của các cuộc hội thoại được
thu thập với người dùng AAC trong tâm trí. Việc fine-tuning
mô hình được thực hiện với tỷ lệ học thấp không đổi
(0.01) sử dụng bộ tối ưu hóa AdaFactor (Shazeer và
Stern, 2018) trên hơn 237,000 ví dụ có nguồn gốc
từ các bộ dữ liệu đối thoại.

4.2 Bộ dữ liệu Cá nhân hóa
Một mô hình được đào tạo trên các bộ dữ liệu đối thoại chung có thể
không phù hợp với nhu cầu giao tiếp của tất cả về
việc bảo tồn phong cách của họ, và từ vựng bao gồm
danh từ riêng. Công trình của chúng tôi được thúc đẩy để tăng
tính tự chủ và tự biểu đạt của người dùng AAC
với khuyết tật vận động và lời nói và triển khai
mô hình mở rộng từ viết tắt của chúng tôi cho việc sử dụng hàng ngày của họ.
Đây cũng là một trường hợp mà dữ liệu đào tạo của mô hình chung cũng thiếu về các cuộc hội thoại
xung quanh chăm sóc và sức khỏe. Do đó, bộ dữ liệu cá nhân
hóa của chúng tôi được thu thập từ một người sống
với ALS với sự đồng ý có thông tin từ người dùng và
các đối tác hội thoại. Họ sử dụng nhập văn bản bằng mắt
cho giao tiếp hàng ngày. Họ gõ trên
bàn phím ảo vào trình soạn thảo văn bản của phần mềm text-to-
speech (TTS) và kích hoạt âm thanh để
"nói" ra nội dung. Nội dung riêng tư và nhạy cảm
được chỉnh sửa trước khi lấy dữ liệu cho
nghiên cứu. Dữ liệu được phân chia theo thời gian, và
lặp lại được loại bỏ khỏi các phần validation và
test dẫn đến 630 (train), 194 (val.) và
224 (test) mẫu.

4.3 Cá nhân hóa nhân vật phim
Ngoài kịch bản triển khai thực, chúng tôi cũng
kiểm tra các bộ dữ liệu hội thoại khác nơi cá nhân
hóa có thể được nghiên cứu mà không ảnh hưởng đến quyền riêng tư
của người dùng. Các nhân vật trong phim và loạt phim truyền hình có xu hướng
có những đặc điểm và tính cách nhất định và tạo
thành một bệ thử nghiệm tuyệt vời để đánh giá cá nhân hóa
của các đối thoại nói. Do đó, để đánh giá nhu cầu
tùy chỉnh và khả năng mở rộng của phương pháp, chúng tôi
thực hiện các thí nghiệm bổ sung trên các cuộc hội thoại
từ bộ dữ liệu Cornell Movie Dialogs (Danescu-
Niculescu-Mizil và Lee, 2011) test set. Đối với các
thí nghiệm của chúng tôi, chúng tôi chọn 10 phim với
xếp hạng rất cao (với ít nhất 5k phiếu bầu trên ImDb). Từ mỗi
phim, chúng tôi chọn 1 nhân vật và tất cả các cuộc hội thoại
của họ từ phim để cá nhân hóa. Mỗi
nhân vật có hơn một trăm cuộc hội thoại trong
phim (phạm vi 104 đến 344, với trung bình 198.4 và
trung vị 209 cuộc hội thoại). Tương tự như bộ dữ liệu cá nhân hóa
AAC của chúng tôi, chúng tôi đã thực hiện phân chia dựa trên thời gian
của dữ liệu để có được train, val., và test splits.

5 Thí nghiệm và Kết quả
Thiết lập thí nghiệm. Đối với tất cả các thí nghiệm, chúng tôi lấy
mẫu 128 phản hồi từ mô hình với nhiệt độ
1.0, sắp xếp dựa trên tần suất dự đoán và
chọn top-5. Chúng tôi báo cáo kết quả trên trung bình
(và±std. dev.) của 3 lần chạy trừ khi được chỉ định
khác. Các chỉ số chúng tôi sử dụng là Accuracy để đo
khớp chính xác của mở rộng câu đầy đủ, và
điểm BLEU (Papineni et al., 2002) để xem xét
tín dụng một phần, cả hai được đo trên top-5 dự đoán
(được ghi chú là @5).

5.1 Prompt-tuning là tốt nhất cho Cá nhân hóa
Bảng 1 so sánh hiệu suất của các
phương pháp cá nhân hóa khác nhau trên dữ liệu người dùng thực.

--- TRANG 4 ---
Chúng tôi lưu ý rằng mô hình base-AE đạt được độ chính xác top-5
là 68.3% trên tập test mở rộng từ viết tắt, tuy nhiên từ Tab. 1 chúng ta có thể thấy rằng nó chỉ
có được độ chính xác 22.5% trên tập test cá nhân hóa
người dùng làm nổi bật sự khác biệt giữa
phân phối dữ liệu người dùng và phân phối đào tạo,
và tạo ra một lập luận mạnh mẽ cho cá nhân hóa cho
người dùng AAC. Fine-tuning trên dữ liệu người dùng giúp ích, và
truy xuất cho ICL thậm chí còn tốt hơn, tuy nhiên prompt-
tuning dẫn đến hiệu suất tốt nhất.

Mô hình được cá nhân hóa Accuracy@5 BLEU@5
base-AE × 22.5 31.8
ICL ✓ 22.8 34.9
Fine-tuned ✓ 26.5 34.3
RA-ICL ✓ 30.3 39.1
Prompt-tuned ✓ 38.8 47.5

Bảng 1: Accuracy (khớp chính xác của câu đầy đủ) và điểm BLEU
của top 5 dự đoán của các phương pháp khác nhau trên
tập test cá nhân hóa.

5.2 Khởi tạo soft prompt quan trọng
Chúng tôi thí nghiệm với các độ dài soft-prompt
khác nhau, tỷ lệ học, và chiến lược khởi tạo soft-prompt
. Chúng tôi thử độ dài soft-prompt là 10,
25, và 100 token tất cả được khởi tạo ngẫu nhiên.
Nhớ rằng việc tăng độ dài prompt làm tăng
số lượng tham số học được. Trong trường hợp của chúng tôi, chúng tôi
thấy độ dài prompt cao hơn dẫn đến nhiều bất ổn
đào tạo hơn. Chúng tôi thấy độ dài 10 hoạt động tốt nhất.
Cố định độ dài prompt là 10, chúng tôi thí nghiệm
với tỷ lệ học 0.1, 0.2, và 0.3 và thấy
0.1 hoạt động tốt nhất (trong App. Tab. 7).

Khởi tạo Soft-prompt Accuracy@5 BLEU@5
Ngẫu nhiên 32.7±3.2 43.6±2.3
Lấy mẫu từ vựng LLM 33.9±0.4 43.2±1.8
Lấy mẫu từ vựng người dùng 32.6±1.6 41.0±1.9
Khái niệm liên quan người dùng 36.8±1.9 45.9±1.4
Từ trái nghĩa khái niệm người dùng 36.4±0.3 46.2±4.3

Bảng 2: Khởi tạo soft-prompts với danh từ riêng và
khái niệm từ dữ liệu của người dùng hoạt động tốt nhất.

Điều tạo ra sự khác biệt lớn nhất
tuy nhiên là việc lựa chọn khởi tạo cho
embeddings token soft-prompt, có thể thấy trong
Bảng 2. Chúng tôi kiểm tra 5 chiến lược, (1) khởi tạo
ngẫu nhiên, (2) lấy mẫu từ top 5k từ trong
từ vựng của LLM, (3) lấy mẫu từ top
25 từ tiếng Anh phổ biến nhất trong từ vựng
của người dùng, (4) chọn thủ công tên riêng và khái
niệm liên quan đến người dùng (ví dụ ALS) và (5) lựa
chọn từ có liên quan nhưng có thể được coi là
trái nghĩa của các khái niệm người dùng (ví dụ Parkinsons).
Chúng tôi thấy khởi tạo dựa trên các khái niệm
người dùng hoạt động tốt hơn đáng kể. Tương tự với những gì được đề xuất trong Lester et al. (2021), có lẽ
những token này là những token mà mô hình cơ sở không chắc chắn
nhất, và do đó tăng cơ hội xuất hiện của chúng
trong các dự đoán khi được prompt-tuned.

5.3 Fine-tuning cản trở tổng quát hóa
Hình 1 cắt hiệu suất của các mô hình dựa trên
độ dài của các câu. Hiệu suất của
tất cả các mô hình giảm với độ dài câu tăng.
Tuy nhiên, mô hình được fine-tuned tổng quát hóa kém
so với mô hình base-AE trong một số trường hợp
(đáng chú ý ở độ dài 5 và 6). Điều này cũng làm nổi bật
khó khăn với việc fine-tuning các mô hình lớn trên
bộ dữ liệu rất nhỏ.

Hình 1: Hiệu suất của các phương pháp khác nhau trên
câu hội thoại có độ dài khác nhau. Trên các câu dài hơn,
prompt-tuned (xanh lá) và mô hình cơ sở không cá nhân hóa (màu
xanh dương) có thể vượt trội hơn fine-tuning làm nổi bật khả năng
tổng quát hóa của chúng đến đuôi dài của các câu phức tạp.

Chiến lược ICL (4-shot) Accuracy@5 BLEU@5
4-shot ngẫu nhiên 22.0±0.9 30.8±1.4
4-shot thủ công 21.9±0.5 33.3±0.7
Tăng cường truy xuất (RA-ICL) 30.2±0.3 38.5±0.6

Bảng 3: So sánh các chiến lược lựa chọn few-shot khác nhau.
ICL tăng cường truy xuất hoạt động tốt nhất.

5.4 Few-shots tăng cường truy xuất giúp ích
Bảng 3 trình bày kết quả cho học trong ngữ cảnh
trong đó các ví dụ 4-shot được chọn bằng cách sử dụng các
chiến lược khác nhau: (1) lựa chọn ngẫu nhiên từ tập
đào tạo, (2) ví dụ thủ công chứa tên riêng
của những người mà người dùng giao tiếp với, và (3) few shots
tăng cường truy xuất, trong đó 4 ví dụ láng giềng gần nhất
(trong không gian embedding của từ viết tắt) được chọn dựa trên mỗi
truy vấn test. RA-ICL vượt trội hơn các chiến lược khác
với một biên độ lớn.

5.5 Tùy chỉnh không phải lúc nào cũng cần thiết
Chúng tôi cũng đánh giá phương pháp prompt-tuning trên
bộ dữ liệu cá nhân hóa nhân vật phim và báo
cáo kết quả trong Bảng 4. Chúng tôi quan sát rằng: (1) độ chính xác
mô hình cơ sở không cá nhân hóa dường như

--- TRANG 5 ---
Movie-id character-id Tên-Nhân-vật base-AE không cá nhân hóa Đã cá nhân hóa (prompt-tuned) Lợi ích
Acc. @5 BLEU @5 Acc. @5 BLEU @5 tương đối (%)
m106 u1612 JACOB 62.75 67.03 56.86 65.13 -
m119 u1799 GEORGE 50.00 59.18 56.25 62.46 13%
m126 u1916 ANDERTON 44.12 55.66 38.24 55.74 -
m140 u2157 BABE 60.00 69.52 46.67 62.93 -
m148 u2299 NANCY 41.67 52.67 41.67 51.40 -
m203 u3105 MICHAEL 61.90 59.60 47.62 45.32 -
m274 u4099 ABBY 77.78 77.78 77.78 77.78 -
m324 u4866 SONNY 62.86 71.53 65.71 72.97 5%
m352 u5310 JACK 50.00 59.18 56.25 62.46 13%
m565 u8329 JEANNE 61.54 70.61 64.10 71.24 4%

Bảng 4: So sánh hiệu suất giữa mô hình base-AE Không cá nhân hóa và Đã cá nhân hóa (prompt-tuned) trên
cá nhân hóa nhân vật phim. LLM nâng cao thanh hiệu suất trung bình cho thấy rằng tùy chỉnh có thể không phải lúc nào cũng cần thiết
trên một số loại hội thoại nhất định, mặc dù một số người dùng vẫn hưởng lợi từ nó. Đây là sự tương phản với kịch bản triển khai AAC thực.

chuyển đổi một cách hợp lý cho thấy rằng tùy chỉnh
có thể không cần thiết cho các loại hội thoại
tương tự như phân phối dữ liệu đào tạo. (2) 4 trong số
10 người nói vẫn hưởng lợi từ cá nhân hóa.
(3) phương pháp prompt-tuning được đề xuất cung cấp
một cách để phục vụ cùng một endpoint, trong khi
tùy chọn chọn cá nhân hóa kết quả cho một số
người dùng.

5.6 Phân tích Lỗi
Trong Bảng 5 chúng tôi chia sẻ một số ví dụ về các
loại lỗi chúng tôi quan sát so sánh kết quả
fine-tuned và prompt-tuned. Phân tích của chúng tôi về các
dự đoán cho thấy mô hình fine-tuned có xu hướng
overfit với danh từ riêng trong dữ liệu đào tạo của người dùng,
và thường bỏ lỡ việc tạo mở rộng cho một số
ký tự trong từ viết tắt. Trong các phiên không có
đủ ngữ cảnh người dùng, nó có thể bỏ lỡ phong cách
của người dùng (ví dụ từ viết tắt "yall" trong hàng
4 của Bảng 5 ít phổ biến trong văn bản chung, nhưng
có thể mang tính phong cách của người dùng).

6 Thảo luận
6.1 Điểm mù của LLM.
Mở rộng từ viết tắt có thể có vẻ là một nhiệm vụ dễ dàng
cho các LLM hiện tại. Tuy nhiên, công trình của chúng tôi tập
trung vào từ viết tắt được thúc đẩy để giúp người dùng có
khuyết tật nghiêm trọng, và do đó đẩy giới hạn
của việc tiết kiệm gõ phím. Trong đó, nhiệm vụ phụ thuộc vào
việc nhận dạng các ký tự/chữ cái riêng lẻ. Thú vị
thay, nó rơi vào cái có thể là "điểm mù"
cho các LLM vì các sơ đồ tokenization đầu vào
- có nghĩa là để vượt qua từ vựng rời rạc
- có thể thiếu sót trong việc nhận dạng các ký tự riêng lẻ.
Điều này hiện được giải quyết thực tế ví dụ để tạo
văn bản ở định dạng JSON (Lamini, 2023), sử dụng
giải mã bị ràng buộc và tuân theo ngữ pháp Backus-Naur
Form (BNF).

6.2 Hiệu quả dữ liệu và mở rộng quy mô.
Một điểm thảo luận khác là làm thế nào cá nhân hóa
có thể được thực hiện trên một lượng nhỏ dữ liệu.
Các thí nghiệm của chúng tôi cho thấy prompt-tuning dẫn đến
độ chính xác test cao hơn fine-tuning trong
cài đặt dữ liệu hạn chế. Fine-tuning toàn bộ LLM cho cá nhân
hóa không chỉ tổng quát hóa kém, mà còn
rất đắt đỏ về việc lưu trữ các trọng số mô hình
cá nhân hóa. Prompt-tuning mặt khác chỉ
liên quan đến việc lưu trữ một tập hợp trọng số rất nhỏ
(theo thứ tự hàng ngàn) điều này sẽ làm cho nó
không chỉ có thể mà còn thuận tiện để lưu trữ những cái này
trên các thiết bị cá nhân của người dùng. Điều này cũng làm cho
phương pháp có thể mở rộng hơn vì chỉ có một mô hình duy nhất
có thể được phục vụ, trong khi khách hàng có thể truy vấn nó bằng cách sử dụng
các soft prompts cá nhân hóa khác nhau. Hơn nữa, việc truy vấn
một mô hình prompt-tuned phát sinh ít độ trễ suy luận
bổ sung, vì các prompts học được và đầu vào
người dùng được cung cấp đồng thời cho mô hình
trong quá trình suy luận.

7 Kết luận
Công trình của chúng tôi trình bày một nghiên cứu trường hợp về cá nhân hóa
LLM cho nhiệm vụ mở rộng từ viết tắt trong
bối cảnh hỗ trợ những người gõ bằng mắt với
khuyết tật vận động và lời nói nghiêm trọng để giao tiếp nhanh hơn. Chúng tôi
fine-tuned một LLM trên dữ liệu đối thoại chung cho
nhiệm vụ và so sánh các phương pháp cá nhân hóa
sử dụng dữ liệu người dùng hạn chế. Chúng tôi kiểm tra fine-tuning,
prompt-tuning hiệu quả tham số, và học trong ngữ cảnh
tăng cường truy xuất, và thấy prompt-
tuning là phương pháp cá nhân hóa thanh lịch nhất
về hiệu suất cũng như hiệu quả dữ liệu đào tạo, yêu cầu
lưu trữ nhỏ, và khả năng mở rộng. Hơn nữa, việc khởi tạo
các soft-prompts với các khái niệm và thuật ngữ liên quan đến
người dùng dẫn đến các mô hình cá nhân hóa prompt-tuned tốt hơn.

--- TRANG 6 ---
Loại Lỗi Từ viết tắt Mở rộng Vàng Fine-tuned Prompt-tuned
Từ viết tắt không khớp s i l t r sweet i love that robin i love that robin sweet i love that robin
Overfit với tên g q d , r a m great question dude , robin and mommy greg q day, robin and greg good q doc, robin and mommy
Bỏ lỡ phong cách người dùng (thường w a d , o d y what a dunce , okie dokie yallwhat about daddy , okie dokie what a day , okie dokie
khi thiếu ngữ cảnh) wipe and dry , ok thanks we are done , ok day yall

Bảng 5: Ví dụ về một số loại lỗi quan sát được. Các từ mà mô hình bỏ lỡ được tô sáng màu xanh dương trong
mở rộng Vàng, và lỗi trong tên được đánh dấu màu đỏ. (Tên riêng đã được thay đổi để bảo toàn tính ẩn danh)

Hạn chế
Hiệu quả của cá nhân hóa trong việc sử dụng thực
khó nghiên cứu, vì nó liên quan đến nội dung riêng tư
và nhạy cảm. Khó khăn này càng rõ ràng hơn
khi làm việc với người khuyết tật. Điều này giới hạn công trình của chúng tôi
thành một nghiên cứu trường hợp trên dữ liệu người dùng thực
cho cá nhân hóa. Xác định các kỹ thuật thú vị
để thu thập các bộ dữ liệu cá nhân hóa thực tế,
có lẽ tổng hợp, có thể mang lại lợi ích cho cộng đồng
đáng kể.

Chúng tôi cũng giới hạn mức độ điều chỉnh siêu tham số,
do tiêu thụ tài nguyên tính toán đáng kể
của các thí nghiệm. Mặc dù chúng tôi có thể
tận dụng các cài đặt được chia sẻ trong tài liệu và
mã nguồn mở. Ngoài ra, trong khi nghiên cứu mở rộng từ viết tắt
và mô hình của chúng tôi được giới hạn ở tiếng Anh, nó
có thể sẽ dịch tốt sang các ngôn ngữ có hình thái học
tương tự, nhưng điều đó vẫn còn phải được nghiên cứu. Các tham chiếu
của chúng tôi đến công trình liên quan trong không gian này có thể
bị hạn chế và các đề xuất thêm được hoan nghênh.

Đạo đức và Tác động Xã hội
Các kỹ thuật cải thiện các ứng dụng Giao tiếp Tăng cường và
Thay thế (AAC) có thể nâng cao đáng kể
chất lượng cuộc sống, tăng sự độc lập và tham gia xã hội
(Caligari et al., 2013) của những người sống với
khuyết tật giao tiếp và vận động.

Một rủi ro của mở rộng từ viết tắt là, khi
các mở rộng không hoàn toàn là những gì mà
người dùng mong muốn, họ có thể bị cám dỗ chọn một
dự đoán gần tương tự dẫn đến truyền đạt nội dung
có thể ít chính xác hơn, bị hiểu sai, hoặc phản ánh
các thành kiến và định kiến của các mô hình cơ bản.
Trong khi mục tiêu của cá nhân hóa là giảm thiểu
những điều này, một số rủi ro vẫn còn. Do đó vẫn có
một rủi ro tinh tế của việc giảm tính tự chủ của người nói
và tự biểu đạt chân thực mà mọi người
ví dụ với ALS (Kane et al., 2017) đánh giá cao. Một
rủi ro khác là các dự đoán sai thường xuyên nếu
cá nhân hóa kém cho một số người dùng. Điều này có thể
tăng nỗ lực cần thiết để chỉnh sửa các lỗi nhỏ, và
vô tình tăng mệt mỏi.

Tài liệu tham khảo
Jiban Adhikary, Jamie Berger, và Keith Vertanen. 2021.
Tăng tốc giao tiếp văn bản thông qua đầu vào câu viết tắt
. Trong Proceedings of the 59th Annual Meet-
ing of the Association for Computational Linguistics
and the 11th International Joint Conference on Natu-
ral Language Processing (Volume 1: Long Papers),
trang 6574–6588.

Tom B Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, et al. 2020. Mô hình ngôn ngữ là những người học few-shot
. arXiv preprint arXiv:2005.14165.

Shanqing Cai, Subhashini Venugopalan, Katrin
Tomanek, Ajit Narayanan, Meredith R Morris, và
Michael P Brenner. 2022. Mở rộng từ viết tắt nhận thức ngữ cảnh
sử dụng mô hình ngôn ngữ lớn. arXiv
preprint arXiv:2205.03767.

Marco Caligari, Marco Godi, Simone Guglielmetti,
Franco Franchignoni, và Antonio Nardone. 2013.
Thiết bị giao tiếp theo dõi mắt trong bệnh xơ cứng teo cơ một bên
: tác động lên khuyết tật và chất lượng
cuộc sống. Amyotroph Lateral Scler Frontotemporal De-
gener, 14(7-8):546–552.

Cristian Danescu-Niculescu-Mizil và Lillian Lee. 2011.
Tắc kè hoa trong các cuộc hội thoại tưởng tượng: Một phương pháp mới
để hiểu sự phối hợp của phong cách ngôn ngữ
trong đối thoại. arXiv preprint arXiv:1106.3077.

Patrick W Demasco và Kathleen F McCoy. 1992. Tạo
văn bản từ đầu vào nén: Một giao diện thông minh
cho người có khuyết tật vận động nghiêm trọng.
Communications of the ACM, 35(5):68–78.

Kyle Gorman, Christo Kirov, Brian Roark, và Richard
Sproat. 2021. Mở rộng từ viết tắt có cấu trúc trong
ngữ cảnh. arXiv preprint arXiv:2110.01140.

Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski,
Bruna Morrone, Quentin De Laroussilhe, Andrea
Gesmundo, Mona Attariyan, và Sylvain Gelly. 2019.
Học chuyển giao hiệu quả tham số cho nlp. Trong In-
ternational Conference on Machine Learning, trang
2790–2799. PMLR.

Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan
Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,
và Weizhu Chen. 2021. lora: Thích ứng thứ hạng thấp
của mô hình ngôn ngữ lớn. arXiv preprint
arXiv:2106.09685.

--- TRANG 7 ---
Shaun Kane, Meredith Ringel Morris, Ann Paradiso,
và Jon Campbell. 2017. "thỉnh thoảng như bác và nóng
tính, với phản xạ của một cầy mangut": Hiểu
tự biểu đạt thông qua các thiết bị giao tiếp tăng cường và
thay thế. Trong Proceedings of CSCW 2017.

Lamini. 2023. Đảm bảo đầu ra json hợp lệ
với lamini. https://www.lamini.ai/blog/
guarantee-valid-json-output-with-lamini.
Truy cập: 2023-12-21.

Brian Lester, Rami Al-Rfou, và Noah Constant. 2021.
Sức mạnh của quy mô cho điều chỉnh prompt hiệu quả tham số
. arXiv preprint arXiv:2104.08691.

Xiang Lisa Li và Percy Liang. 2021. Prefix-tuning:
Tối ưu hóa prompts liên tục cho tạo sinh. arXiv
preprint arXiv:2101.00190.

Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang
Cao, và Shuzi Niu. 2017. Dailydialog: Một bộ dữ liệu đối thoại
nhiều lượt được gán nhãn thủ công. arXiv preprint
arXiv:1710.03957.

Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding,
Yujie Qian, Zhilin Yang, và Jie Tang. 2021. Gpt
cũng hiểu. arXiv preprint arXiv:2103.10385.

Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christo-
foros Nalmpantis, Ram Pasunuru, Roberta Raileanu,
Baptiste Rozière, Timo Schick, Jane Dwivedi-Yu,
Asli Celikyilmaz, et al. 2023. Mô hình ngôn ngữ tăng cường
: một khảo sát. arXiv preprint arXiv:2302.07842.

Jianmo Ni, Gustavo Hernández Ábrego, Noah Constant,
Ji Ma, Keith B Hall, Daniel Cer, và Yinfei Yang.
2022. Sentence-t5: Bộ mã hóa câu có thể mở rộng từ
mô hình text-to-text pre-trained. ACL.

Kishore Papineni, Salim Roukos, Todd Ward, và Wei-
Jing Zhu. 2002. Bleu: một phương pháp đánh giá tự động
dịch máy. Trong Proceedings of the
40th annual meeting of the Association for Computa-
tional Linguistics, trang 311–318.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine
Lee, Sharan Narang, Michael Matena, Yanqi Zhou,
Wei Li, và Peter J Liu. 2019. Khám phá giới hạn
của học chuyển giao với một transformer text-to-text
thống nhất. arXiv preprint arXiv:1910.10683.

Stephen Roller, Emily Dinan, Naman Goyal, Da Ju,
Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott,
Kurt Shuster, Eric M Smith, et al. 2020. Công thức
để xây dựng một chatbot miền mở. arXiv preprint
arXiv:2004.13637.

Ohad Rubin, Jonathan Herzig, và Jonathan Berant.
2022. Học truy xuất prompts cho học trong ngữ cảnh
. NAACL.

Noam Shazeer và Mitchell Stern. 2018. Adafactor:
Tỷ lệ học thích ứng với chi phí bộ nhớ dưới tuyến tính
. Trong International Conference on Machine Learning,
trang 4596–4604. PMLR.

Junxiao Shen, Boyin Yang, John J Dudley, và Per Ola
Kristensson. 2022. Kwickchat: Một hệ thống đối thoại
nhiều lượt cho aac sử dụng tạo câu nhận thức ngữ cảnh
bằng bag-of-keywords. Trong 27th Interna-
tional Conference on Intelligent User Interfaces,
trang 853–867.

Stuart M Shieber và Rani Nelken. 2007. Đầu vào văn bản viết tắt
sử dụng mô hình hóa ngôn ngữ. Natural Lan-
guage Engineering, 13(2):165–183.

Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam
Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng,
Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al.
2022. Lamda: Mô hình ngôn ngữ cho ứng dụng đối thoại
. arXiv preprint arXiv:2201.08239.

Stephanie Valencia, Richard Cave, Krystal Kallarackal,
Katie Seaver, Michael Terry, và Shaun K Kane.
2023. "càng ít gõ càng tốt": Làm thế nào mô hình ngôn ngữ ai
có thể nâng cao hoặc cản trở giao tiếp cho
người dùng aac. Trong Proceedings of the 2023 CHI Confer-
ence on Human Factors in Computing Systems, trang
1–14.

Keith Vertanen. 2017. Hướng tới cải thiện aac dự đoán
sử dụng đối thoại crowdsourced và ngữ cảnh đối tác
. Trong Proceedings of the 19th International ACM
SIGACCESS Conference on Computers and Accessi-
bility, trang 347–348.

Keith Vertanen và Per Ola Kristensson. 2011.
Trí tưởng tượng của đám đông: mô hình hóa ngôn ngữ aac hội thoại
sử dụng crowdsourcing và nguồn dữ liệu lớn.
Trong Proceedings of the 2011 Conference on Empirical
Methods in Natural Language Processing, trang 700–
711.

Tim Willis, Helen Pain, và Shari Trewin. 2005. Một hệ thống
mở rộng từ viết tắt linh hoạt xác suất
cho người dùng có khuyết tật vận động. Trong Accessible Design
in the Digital World Conference 2005, trang 1–9.

Bruce Wisenburn và D Jeffery Higginbotham. 2008.
Một ứng dụng aac sử dụng nhận dạng giọng nói đối tác
để tự động tạo ra những phát ngôn liên quan ngữ cảnh
: kết quả khách quan. Augmentative
and Alternative Communication, 24(2):100–109.

Tony Z Zhao, Eric Wallace, Shi Feng, Dan Klein, và
Sameer Singh. 2021. Hiệu chuẩn trước khi sử dụng: Cải thiện
hiệu suất few-shot của mô hình ngôn ngữ. arXiv
preprint arXiv:2102.09690.

--- TRANG 8 ---
A Lựa chọn tham số
A.1 Tỷ lệ học fine-tuning
Tỷ lệ học fine-tuning Accuracy@5 BLEU@5
5e-5 26.8 34.3
1e-6 25.4 34.7
1e-5 23.7 31.6

Bảng 6: So sánh các tỷ lệ học khác nhau cho fine-tuning
mô hình base-AE trên dữ liệu cá nhân hóa. (tập val).

A.2 Tỷ lệ học prompt-tuning
Tỷ lệ học prompt-tuning Accuracy@5 BLEU@5
0.1 35.7 45.6
0.2 31.7 41.7
0.3 30.8 39.9

Bảng 7: So sánh các tỷ lệ học khác nhau cho prompt-tuning
mô hình base-AE trên dữ liệu cá nhân hóa. độ dài soft prompt của
10 và khởi tạo ngẫu nhiên (tập val).

B Dữ liệu Cá nhân hóa
Bộ dữ liệu cá nhân hóa của chúng tôi được thu thập với
sự đồng ý có thông tin từ một người sống với ALS
trong khoảng thời gian năm tháng từ cuối năm 2021 đến đầu
năm 2022. Chúng tôi gọi người có ALS là "người
dùng". Người dùng đã sử dụng máy theo dõi mắt Tobii (R) và
bàn phím điều khiển bằng ánh mắt để nhập văn bản cho giao tiếp
hàng ngày. Văn bản được gõ bằng mắt được xuất ra dưới dạng âm thanh
lời nói thông qua phần mềm text-to-speech (TTS). Người dùng
có toàn quyền kiểm soát khi nào bắt đầu và dừng
thu thập dữ liệu. Nội dung riêng tư và nhạy cảm trong
dữ liệu được chỉnh sửa bởi các curator con người được đào tạo trước
khi chúng tôi thu thập bộ dữ liệu cho nghiên cứu.

Dữ liệu liên quan được sử dụng cho nghiên cứu này bao gồm
bản ghi văn bản của đầu ra TTS của người dùng. Chúng tôi chia
dữ liệu thành ba phần không trùng lặp dọc theo
trục thời gian theo thứ tự thời gian là train, validation
và test, chứa 630, 285, và 284 câu,
tương ứng. Chúng tôi lọc validation và test split
để chỉ bảo toàn các câu có độ dài từ viết tắt
≤10, dẫn đến 194 và 224 câu,
tương ứng. Không có lọc nào được thực hiện trên
split đào tạo. Kết quả là, độ dài từ viết tắt trung bình trong
train, validation, và test splits là 6.91±6.25,
4.72±2.39, và 5.05±2.74, tương ứng (±1SD).
Các câu thuộc về 122, 69, và 72 phiên,
tương ứng, mỗi phiên là một khoảng thời gian liên tục
của việc thu thập dữ liệu hội thoại. Tỷ lệ phần trăm
của danh từ riêng trong số các từ là 6.73%,
5.88%, và 8.61% trong ba splits, tương ứng.

# SPP: Tinh chỉnh có tham số hiệu quả với bảo toàn tính thưa thớt cho các mô hình ngôn ngữ lớn

Xudong Lu* 1Aojun Zhou* 1Yuhui Xu* 2Renrui Zhang1 3Peng Gao3Hongsheng Li†1 4
1Phòng thí nghiệm Đa phương tiện (MMLab), Đại học Trung văn Hồng Kông2Salesforce AI Research
3Phòng thí nghiệm Trí tuệ nhân tạo Thượng Hải4CPII thuộc InnoHK
{luxudong@link,hsli@ee }.cuhk.edu.hk {aojunzhou,xyh6666 }@gmail.com

## Tóm tắt

Các mô hình ngôn ngữ lớn (LLM) đã trở thành trụ cột trong việc thúc đẩy lĩnh vực trí tuệ nhân tạo, tuy nhiên kích thước khổng lồ của chúng gây ra những thách thức đáng kể cho cả việc tinh chỉnh và triển khai. Các phương pháp cắt tỉa sau huấn luyện hiện tại, mặc dù giảm kích thước của LLM, thường không thể duy trì hiệu suất ban đầu của chúng. Để giải quyết những thách thức này, bài báo này giới thiệu SPP, một phương pháp tinh chỉnh có tham số hiệu quả với bảo toàn tính thưa thớt. Khác với các phương pháp cắt tỉa sau huấn luyện hiện có gặp khó khăn trong việc duy trì hiệu suất, SPP đề xuất sử dụng các ma trận cột và hàng học được nhẹ để tối ưu hóa trọng số LLM thưa thớt, giữ nguyên cấu trúc và tính thưa thớt của các mô hình đã cắt tỉa được huấn luyện trước. Bằng phép nhân từng phần tử và cộng dư, SPP đảm bảo tính nhất quán của mẫu thưa thớt và tỷ lệ của mô hình trong cả quá trình huấn luyện và hợp nhất trọng số. Chúng tôi chứng minh tính hiệu quả của SPP bằng cách áp dụng nó vào các họ mô hình LLaMA và LLaMA-2 với các phương pháp cắt tỉa sau huấn luyện gần đây. Kết quả của chúng tôi cho thấy SPP cải thiện đáng kể hiệu suất của các mô hình với các mẫu thưa thớt khác nhau (tức là tính thưa thớt không có cấu trúc và N:M), đặc biệt là cho những mô hình có tỷ lệ thưa thớt cao (ví dụ 75%), làm cho nó trở thành một giải pháp hứa hẹn cho việc tinh chỉnh hiệu quả các LLM thưa thớt. Mã nguồn sẽ được cung cấp tại https://github.com/Lucky-Lance/SPP.

## 1. Giới thiệu

Các mô hình ngôn ngữ lớn (LLM) (Brown et al., 2020; OpenAI, 2023; Anil et al., 2023) gần đây đã cho thấy thành công ấn tượng trong nhiều tác vụ phức tạp (Wei et al., 2022; Zhou et al., 2024). Tuy nhiên, những mô hình này thường được đặc trưng bởi một số lượng lớn các tham số học được, từ vài tỷ đến khoảng một trăm tỷ (Touvron et al., 2023a;b), như được minh họa bởi GPT-4. Tính khổng lồ này khiến LLM trở nên cồng kềnh để tinh chỉnh cho các tình huống khác nhau và khó khăn để triển khai trên các thiết bị biên khác nhau.

Để giảm tham số của các mô hình ngôn ngữ lớn được huấn luyện trước mà không cần giai đoạn huấn luyện lại đòi hỏi nhiều tài nguyên, các phương pháp cắt tỉa sau huấn luyện (Frantar & Alistarh, 2023) khác nhau đã được trình bày. SparseGPT, như được nêu trong (Frantar & Alistarh, 2023), tập trung vào việc tối thiểu hóa lỗi bình phương giữa các mô hình thưa thớt đã cắt tỉa và mô hình dày đặc ban đầu theo từng lớp. Wanda (Sun et al., 2023) kết hợp cả độ lớn trọng số và kích hoạt đầu vào làm chỉ số để xác định các tham số không quan trọng. Mặc dù thành công trong việc cắt tỉa mô hình ngôn ngữ, những phương pháp này thường không thể duy trì hiệu suất của các mô hình được huấn luyện trước ngay cả ở mức độ thưa thớt vừa phải (ví dụ 50%) (Jaiswal et al., 2023).

Ngược lại, các phương pháp cắt tỉa cho các mô hình sâu quy mô nhỏ hơn – những mô hình có ít hơn 200 triệu tham số, như ResNet50 (He et al., 2016) và các mô hình dựa trên BERT (Devlin et al., 2018) – đã đạt được tỷ lệ thưa thớt cao (ví dụ >80%) chỉ với sự giảm hiệu suất không đáng kể (Evci et al., 2020; Lin et al., 2020; Zhou et al., 2021). Thành công của những mô hình này phần lớn được gán cho vai trò của việc huấn luyện lại trong quá trình cắt tỉa của chúng (Liu et al., 2018). Tuy nhiên, so với việc huấn luyện mạng nơ-ron dày đặc, việc huấn luyện các mô hình thưa thớt sẽ mất nhiều thời gian hơn để đạt được hiệu suất tương tự. Ví dụ, cần 5× thời gian huấn luyện hơn trong RigL (Evci et al., 2020). Những phương pháp này phụ thuộc nhiều vào lan truyền ngược với đầy đủ tham số, điều này cực kỳ tốn kém cho LLM. Quan sát này đặt ra một câu hỏi quan trọng: Liệu chúng ta có thể giới thiệu một giai đoạn huấn luyện lại hiệu quả cho các LLM đã cắt tỉa?

Để đáp ứng những thách thức này, chúng tôi đề xuất một phương pháp mới, có thể cắm và chạy, SPP, một phương pháp tinh chỉnh có tham số hiệu quả với bảo toàn tính thưa thớt được thiết kế để huấn luyện lại hoặc tinh chỉnh hiệu quả các LLM thưa thớt sau cắt tỉa sau huấn luyện (ví dụ SparseGPT (Frantar & Alistarh, 2023), Wanda (Sun et al., 2023), v.v.), từ đó nâng cao hiệu suất của chúng. Được truyền cảm hứng bởi phương pháp Thích ứng Hạng thấp (LoRA) cho các mô hình ngôn ngữ lớn dày đặc (Hu et al., 2021), SPP bao gồm hai giai đoạn, huấn luyện và hợp nhất trọng số. Cụ thể hơn, chúng tôi giới thiệu hai tập hợp tham số học được nhẹ vào các ma trận thưa thớt của mỗi lớp tuyến tính. Trong giai đoạn huấn luyện và hợp nhất trọng số, những tham số học được này được nhân với các trọng số cố định đã cắt tỉa sau huấn luyện ban đầu, đạt được hiệu quả duy trì chính xác mẫu thưa thớt và tỷ lệ xuyên suốt tất cả các quá trình.

SPP dễ triển khai và có thể áp dụng cho nhiều phương pháp cắt tỉa sau huấn luyện và LLM với các tỷ lệ thưa thớt và mẫu khác nhau (tính thưa thớt không có cấu trúc và N:M). Chúng tôi đánh giá SPP trên các họ mô hình LLaMA (Touvron et al., 2023a) và LLaMA-2 (Touvron et al., 2023b) với hai phương pháp cắt tỉa sau huấn luyện LLM gần đây, tức là SparseGPT (Frantar & Alistarh, 2023) và Wanda (Sun et al., 2023). Để minh họa tính hiệu quả của SPP, kết quả đánh giá zero-shot của các mô hình LLaMA 7B/30B với tỷ lệ thưa thớt 75% được hiển thị trong Hình 1.

Những đóng góp chính của bài báo này được tóm tắt trong ba khía cạnh chính:

(1) Chúng tôi nghiên cứu các phương pháp cắt tỉa mô hình trong thời đại LLM và trình bày một thuật toán tinh chỉnh có tham số hiệu quả mới, SPP, có thể duy trì cấu trúc mô hình và tính thưa thớt trong cả giai đoạn huấn luyện và hợp nhất trọng số.

(2) Các thí nghiệm mở rộng trên các LLM đã cắt tỉa sau huấn luyện khác nhau với các mẫu thưa thớt và tỷ lệ khác nhau cho thấy tính hiệu quả của SPP cho việc huấn luyện hiệu quả các LLM thưa thớt.

(3) Theo hiểu biết của chúng tôi, nghiên cứu này là nghiên cứu đầu tiên khám phá một cách có hệ thống việc tích hợp huấn luyện lại hiệu quả với các phương pháp cắt tỉa sau huấn luyện tiên tiến cho LLM.

## 2. Nghiên cứu liên quan

**Cắt tỉa mô hình truyền thống:** Cắt tỉa mạng nơ-ron sâu (DNN) là một hướng nghiên cứu hứa hẹn để nén và tăng tốc các mô hình học sâu (Hoefler et al., 2021). Có chủ yếu hai loại kỹ thuật để thu được một mạng nơ-ron thưa thớt, khung công tác cắt tỉa-huấn luyện lại lặp đi lặp lại, và những phương pháp huấn luyện thưa thớt động. Khung công tác cắt tỉa-huấn luyện lại lặp đi lặp lại đầu tiên tìm ra các kết nối không quan trọng (mặt nạ), do đó loại bỏ các trọng số tương ứng, và sau đó huấn luyện lại mạng thưa thớt cố định để khôi phục hiệu suất của nó. Các phương pháp điển hình bao gồm cắt tỉa lặp (Han et al., 2015). Sau đó, giả thuyết vé số (Frantar & Alistarh, 2023) cho thấy rằng các mạng con thưa thớt (vé trúng) có thể được huấn luyện từ đầu với cùng một khởi tạo dày đặc trong khi các vé trúng được khám phá bởi việc huấn luyện dày đặc. Các phương pháp huấn luyện thưa thớt động (Mocanu et al., 2018) bắt đầu từ một mạng được làm thưa thớt ngẫu nhiên, sau đó cắt tỉa và phát triển các kết nối trong quá trình huấn luyện. Những phương pháp này có thể được áp dụng từ đầu đến cuối trong giai đoạn huấn luyện mạng và đã đạt được kết quả hứa hẹn. Phương pháp tiên tiến gần đây được đề xuất STR (Kusupati et al., 2020) giới thiệu các ngưỡng cắt tỉa học được để thu được một mạng thưa thớt không đồng nhất. RigL (Evci et al., 2020) sử dụng phương pháp dựa trên độ lớn để cắt tỉa và gradient dày đặc định kỳ để tái tạo kết nối. Tuy nhiên, điều quan trọng cần lưu ý là những phương pháp này phụ thuộc nhiều vào lan truyền ngược với đầy đủ tham số, điều này cực kỳ tốn kém cho LLM.

**Cắt tỉa LLM:** Trong thời đại LLM, các phương pháp đã được đề xuất để vượt qua những thách thức đã đề cập ở trên (Li et al., 2023). Các nỗ lực nghiên cứu gần đây đã phát triển hướng tới các phương pháp cắt tỉa sau huấn luyện, bắt đầu từ mạng được huấn luyện trước và loại bỏ các tham số dư thừa mà không cần tinh chỉnh hoặc huấn luyện lại từ đầu đến cuối. SparseGPT sử dụng thông tin bậc hai để giải quyết vấn đề tái tạo theo lớp và cắt tỉa các mô hình lớn với tính thưa thớt không có cấu trúc và có cấu trúc N:M (Zhou et al., 2021) tương ứng. Wanda (Sun et al., 2023) đề xuất một chỉ số cắt tỉa mới tính đến cả độ lớn trọng số và các kích hoạt đầu vào tương ứng của chúng, đạt được độ phức tạp tương đương với SparseGPT (Frantar & Alistarh, 2023). Tuy nhiên, (Jaiswal et al., 2023) chỉ ra rằng độ phức tạp không nhất thiết là một chỉ số chính xác để đánh giá tính hiệu quả của việc nén mô hình, với cả SparseGPT và Wanda đều không đạt được hiệu suất thỏa mãn ngay cả với tính thưa thớt ở mức thấp (25-30%). Dựa trên vấn đề này, chúng tôi suy đoán rằng việc thiếu huấn luyện lại sau khi loại bỏ các trọng số không quan trọng sẽ dẫn đến sự suy giảm hiệu suất không mong muốn, và đưa ra một phương pháp huấn luyện mới với hiệu quả huấn luyện cao.

**Tinh chỉnh có tham số hiệu quả:** Trong các tác vụ ngôn ngữ và thị giác khác nhau, các mô hình huấn luyện trước và tinh chỉnh đã được chứng minh là rất hiệu quả. So với tinh chỉnh tham số đầy đủ, các phương pháp tinh chỉnh có tham số hiệu quả (PEFT) (Mangrulkar et al., 2022; Xu et al., 2023) đóng băng hầu hết các tham số của các mô hình được huấn luyện trước dày đặc và nhằm thể hiện khả năng tương đương trên các tác vụ downstream. LoRA (Hu et al., 2021) giới thiệu các ma trận phân tách hạng thấp có thể huấn luyện vào trọng số mạng dày đặc. Adapter (Houlsby et al., 2019) chèn các mô-đun thích ứng nhẹ vào mỗi khối của các mô hình ngôn ngữ. Khác với các nỗ lực trước đây cho các mô hình ngôn ngữ được huấn luyện trước dày đặc, chúng tôi đề xuất phương pháp SPP với ít tham số học được, được thiết kế đặc biệt cho LLM thưa thớt.

## 3. Phương pháp

Mục tiêu của việc cắt tỉa mạng nơ-ron là bảo toàn hiệu suất của mạng ban đầu càng gần càng tốt bằng cách tạo ra một mạng thưa thớt thông qua việc loại bỏ có chọn lọc một số tham số mạng nơ-ron nhất định (Hassibi et al., 1993; Han et al., 2015). Trong phần này, chúng tôi đầu tiên giới thiệu ký hiệu được sử dụng trong bài báo của chúng tôi và phân loại một số thuật toán hiện có cho việc cắt tỉa mạng nơ-ron (đặc biệt là cho LLM) trong Phần 3.1, sau đó trình bày chi tiết SPP được đề xuất của chúng tôi trong Phần 3.2, là một phương pháp tinh chỉnh có tham số hiệu quả được thiết kế đặc biệt để huấn luyện LLM thưa thớt.

### 3.1. Xem xét lại các phương pháp cắt tỉa mô hình

**Cắt tỉa sau huấn luyện:** Bắt đầu từ một mô hình dày đặc được huấn luyện trước (LLM trong thiết lập của chúng tôi), các thuật toán cắt tỉa sau huấn luyện (Frantar & Alistarh, 2023; Zhang et al., 2023a) loại bỏ các tham số dư thừa trong một mạng nơ-ron bằng cách tính toán một tập hợp các mặt nạ trọng số M={M0,M1, . . . ,MN−1} tận dụng độ lớn trọng số W={W0,W1, . . . ,WN−1} cùng với một tập hợp dữ liệu hiệu chuẩn. Như được hiển thị trong Hình 2 (a), cho ma trận dày đặc ban đầu Wi (0≤i≤N−1), các thuật toán cắt tỉa sau huấn luyện tính toán các mặt nạ trọng số nhị phân Mi, và tập hợp các ma trận thưa thớt mới W̃ có thể được tính như sau:

W̃={W0⊙M0,W1⊙M1, ...,WN−1⊙MN−1}, (1)

trong đó N biểu thị số lượng lớp tuyến tính, và ⊙ chỉ ra phép nhân từng phần tử (tích Hadamard (Horn, 1990)) giữa các ma trận. Một ví dụ dựa trên tính thưa thớt có cấu trúc 2:4 và sử dụng độ lớn trọng số như chỉ số cắt tỉa được minh họa trong Hình 2 (b). Các thuật toán cắt tỉa sau huấn luyện nổi tiếng với việc tiêu thụ tài nguyên tính toán tương đối thấp. Tuy nhiên, như đã chứng minh trong SparseGPT (Frantar & Alistarh, 2023) và Wanda (Sun et al., 2023), ngay cả việc cắt tỉa LLM đến mức độ thưa thớt vừa phải, cụ thể là 50%, cũng không thể tránh khỏi dẫn đến sự suy giảm hiệu suất đáng kể (Han et al., 2015). Điều này cho thấy rằng sau khi cắt tỉa sau huấn luyện, việc huấn luyện lại mô hình thưa thớt để khôi phục khả năng kiến thức của nó là cần thiết.

**Tinh chỉnh đầy đủ với mặt nạ thưa thớt động:** Một sơ đồ cắt tỉa khác bắt đầu từ mô hình dày đặc là tinh chỉnh đầy đủ mô hình dày đặc ban đầu với các mặt nạ thưa thớt được cập nhật động, như được mô tả trong Hình 2 (c). Thông thường, để cải thiện hiệu suất của các mô hình thưa thớt, các nhà nghiên cứu giới thiệu các phương pháp huấn luyện khác nhau để tối ưu hóa đồng thời các trọng số thưa thớt W̃ và các mặt nạ nhị phân M tương ứng (Lin et al., 2020; Bengio et al., 2013):

Wi^(t+1) = Wi^t − γt g(Wi^t ⊙ Mi^t) = Wi^t − γt g(W̃i^t), (2)

trong đó γt biểu thị tỷ lệ học ở bước thời gian t và hàm g(·) tính toán gradient¹. Đối với các mô hình thưa thớt quy mô nhỏ, chẳng hạn như những mô hình dựa trên ResNet và BERT, các phương pháp tinh chỉnh đầy đủ như các thuật toán dựa trên STE (Lin et al., 2020; Evci et al., 2020; Zhou et al., 2021) có thể duy trì hiệu suất cao ngay cả ở tính thưa thớt ≥75%. Tuy nhiên, những phương pháp này thường đòi hỏi sức mạnh tính toán và tài nguyên bộ nhớ đáng kể. Điều này đặt ra một thách thức lớn trong thời đại huấn luyện LLM. Ví dụ, việc tinh chỉnh đầy đủ một mô hình LLaMA-65B đòi hỏi ít nhất 780G bộ nhớ GPU (Dettmers et al., 2023), chưa kể đến bộ nhớ bổ sung cần thiết để cập nhật các mặt nạ thưa thớt.

**Tinh chỉnh với mặt nạ cố định:** Như có thể học được từ những nhược điểm tương ứng của hai phương pháp được mô tả ở trên, có nhu cầu cân bằng việc khôi phục hiệu suất mô hình và chi phí huấn luyện. Thực tế, Phương trình (2) có thể được tách thành tối ưu hóa lặp của các mặt nạ nhị phân M và trọng số thưa thớt W̃. Khi huấn luyện với tài nguyên tính toán hạn chế, việc tối ưu hóa trọng số thưa thớt với mặt nạ cố định được coi là hiệu quả cho việc khôi phục kiến thức (Liu et al., 2018). Nói chung, nếu chúng ta cố định Mi^t = Mi^0 và áp dụng W̃i^t = Wi^t ⊙ Mi^0 tại lần lặp thứ t, Phương trình (2) sẽ tương đương với việc huấn luyện lại các mô hình thưa thớt với mặt nạ cố định:

W̃i^(t+1) = W̃i^t − γt g(W̃i^t) ⊙ Mi^0, (3)

nhưng việc tính toán gradient cho W̃i^t liên quan đến mặt nạ cố định Mi^0 vẫn cồng kềnh. Để giải quyết vấn đề này, chúng tôi cung cấp phương pháp SPP để tinh chỉnh hiệu quả các LLM đã cắt tỉa sau huấn luyện với mặt nạ cố định (như được minh họa trong Hình 2 (d)).

### 3.2. Phương pháp được đề xuất

Trong phần này, chúng tôi đề xuất SPP để cân bằng việc khôi phục hiệu suất mô hình và chi phí tính toán. Các phương pháp PEFT hiện tại thực hiện cập nhật trọng số của các khối tuyến tính lớn bằng cách giới thiệu các ma trận phân tách hạng thấp có thể huấn luyện (Hu et al., 2021) và cộng chúng với trọng số tuyến tính ban đầu đã đóng băng sau khi huấn luyện. Phương pháp này cuối cùng dẫn đến các ma trận dày đặc và phá hủy tính thưa thớt của mô hình. Suy ngẫm về vấn đề này, chúng tôi gợi ý rằng việc cộng trực tiếp các tham số mới vào các ma trận thưa thớt dẫn đến sự thay đổi không thể tránh khỏi trong tính thưa thớt của mô hình, trong khi phép nhân trọng số có thể tránh được vấn đề. Để giải quyết vấn đề này, chúng tôi thêm hai tập hợp tham số học được nhẹ trực giao Wα={W0α,W1α, . . . ,WN−1α} và Wβ={W0β,W1β, . . . ,WN−1β}, nhân chúng riêng biệt với trọng số cột và hàng của mỗi ma trận tuyến tính trong LLM đã cắt tỉa, và thực hiện tinh chỉnh hiệu quả cho các ma trận thưa thớt với các trọng số đã cắt tỉa ban đầu được cố định.

**Chèn tham số học được:** Cốt lõi của SPP là cách giới thiệu các tham số học được sao cho chúng không dẫn đến sự thay đổi tính thưa thớt trong quá trình huấn luyện và hợp nhất trọng số. Như được hiển thị trong Hình 3, cho ma trận tuyến tính thưa thớt W̃i∈Rm×n (0≤i≤N−1) sau khi cắt tỉa, chúng tôi chèn hai tập hợp tham số học được: Wiα∈Rr×n và Wiβ∈Rm×1. Wiα thêm khả năng học cho trọng số của mỗi cột, trong khi Wiβ mở rộng thêm nó cho mỗi hàng². Điều này dẫn đến (m+rn) tham số bổ sung cho một ma trận thưa thớt. Sau đó chúng tôi chia tỷ lệ Wiα và Wiβ thành cùng kích thước của W̃i và nhân chúng với W̃i theo cách từng phần tử:

W̃i' = W̃i ⊙ Repeat0(Wiα, ⌊m/r⌋) ⊙ Repeat1(Wiβ, n), (4)

trong đó Repeatd(W, k) là một hàm biểu thị việc lặp lại mỗi phần tử của W bằng k lần dọc theo chiều thứ d, có thể được triển khai dễ dàng bởi hàm torch.repeat_interleave() trong Python. Bên cạnh đó, không cần thực hiện phép "lặp lại" rõ ràng trên Wiβ, vì PyTorch tự động căn chỉnh các chiều ma trận khi thực hiện tích Hadamard giữa một ma trận và một vectơ. Hàm sàn ⌊·⌋ chỉ ra phép chia số nguyên. Trong triển khai của chúng tôi, r được đặt thành các số có thể chia hết cho n (ví dụ, chọn r = 4,8,16, v.v.). Hưởng lợi từ phép nhân từng phần tử, các giá trị 0 trong ma trận thưa thớt ban đầu sẽ không thay đổi, vì vậy W̃i' chia sẻ cùng mẫu thưa thớt và tỷ lệ thưa thớt với W̃i, một ví dụ với ma trận 4×8 và r = 2 được hiển thị trong Hình 3. Bằng cách này, chúng ta có thể huấn luyện các ma trận tuyến tính với mặt nạ cố định, theo mẫu huấn luyện trong Hình 2 (d). Đáng chú ý là nếu chúng ta đặt r = m, phương pháp của chúng tôi thực hiện cập nhật gradient tham số đầy đủ trên ma trận thưa thớt ban đầu.

**Khung công tác của SPP:** Sau khi giải thích cách chèn tham số, chúng tôi giới thiệu khung công tác SPP được đề xuất, như được hiển thị trong Hình 4. Trong quá trình huấn luyện, ở lớp tuyến tính thứ i của mạng nơ-ron, đầu ra có thể được tính bằng:

Yi = F(Xi, W̃i) + s · F(Dropout(Xi), W̃i'), (5)

trong đó s là một siêu tham số cho việc chia tỷ lệ, và Xi∈Rb×n biểu thị kích hoạt đầu vào tại lớp tuyến tính thứ i. Chúng tôi theo Phương trình (4) để huấn luyện W̃i', đặt Wiβ ban đầu thành tất cả không, và khởi tạo ngẫu nhiên Wiα. Bằng cách này, cấu trúc ban đầu và trọng số của mạng nhất quán với mô hình đã cắt tỉa sau huấn luyện. Cụ thể hơn, Yi = F(Xi, W̃i) cho việc khởi tạo mạng nơ-ron. Chiến lược này dẫn đến việc huấn luyện ổn định hơn. Sau khi huấn luyện, các tham số lớp tuyến tính có thể được hợp nhất thành: W̃i + s · W̃i', chia sẻ cùng mẫu thưa thớt và tỷ lệ với mô hình đã cắt tỉa ban đầu. Cấu trúc của SPP tương tự như LoRA, nhưng nó không phá hủy cấu trúc thưa thớt của mô hình trong cả quá trình huấn luyện và hợp nhất trọng số. Để so sánh trực tiếp hơn, hãy nhớ rằng công thức của LoRA với trọng số đóng băng W̃i là:

Yi = F(Xi, W̃i) + s · Dropout(Xi)(Ai)T(Bi)T, (6)

trong đó Ai∈Rr×n và Bi∈Rm×r. Trong quá trình huấn luyện và hợp nhất trọng số của LoRA, trọng số của ma trận lớp tuyến tính tương đương với (W̃i + s · BiAi), thực tế là một ma trận dày đặc.

**Tối ưu hóa sử dụng bộ nhớ:** Chúng tôi phát hiện rằng đối với mỗi lớp tuyến tính với kích hoạt đầu vào Xi, việc chèn Wiα và Wiβ giảm đáng kể số lượng tham số có thể huấn luyện, nhưng chúng tôi vẫn cần lưu trữ ma trận trung gian Repeat0(Wiα, m/r) khi tính toán hàm tuyến tính Yi' = Xi(W̃i')T (đây thực tế là số hạng cộng thứ hai trong Phương trình (5)), thường chiếm một lượng lớn bộ nhớ. Để khắc phục vấn đề này, chúng tôi thiết kế lại quy trình nhân ma trận trong SPP theo lớp tuyến tính song song cột trong Megatron-LM (Shoeybi et al., 2019). Cụ thể, trong mỗi lớp tuyến tính F(X,W) với trọng số Wm×n và kích hoạt Xb×n, đầu ra của lớp tuyến tính là Y = XWT∈Rb×m (không mất tính tổng quát, chúng tôi loại bỏ batch của đầu vào X và giả sử b = 1 cho đơn giản). Chúng tôi chia cột của W thành r khối, được ký hiệu là WT0, WT1, . . . , WTr−1, trong đó mỗi Wj∈R⌊m/r⌋×n. Trong thiết lập của chúng tôi, chúng ta có thể suy ra:

Yi' = Xi(W̃i ⊙ Repeat0(Wiα, ⌊m/r⌋) ⊙ Repeat1(Wiβ, n))T
= [...(Xi ⊙ Wiαj)(W̃ij)T...] ⊙ (Wiβ)T, (7)

trong đó Wiαj biểu thị hàng thứ j của Wiα, và W̃ij biểu thị khối thứ j của W̃i (0≤j≤r−1). Điều này sẽ loại bỏ nhu cầu lưu ma trận Repeat0(Wiα, m/r), và một chứng minh chi tiết hơn của Phương trình (7) ở trên có thể được tìm thấy trong Phần A.2 trong Phụ lục.

**Nhận xét về SPP:**

1) Tại sao cần sơ đồ dư? Thực tế, việc khởi tạo trực tiếp Wα và Wβ thành 1 và sau đó nhân chúng vào các vị trí tương ứng sẽ đơn giản hơn. Nhưng chúng tôi phát hiện rằng sơ đồ huấn luyện như vậy hội tụ chậm hơn.

2) Tại sao việc giữ mẫu thưa thớt của mô hình trong quá trình huấn luyện lại quan trọng? Các sơ đồ PEFT trước đó có xu hướng biến một mô hình thưa thớt thành một mô hình dày đặc sau khi huấn luyện, và chúng ta cần cắt tỉa mô hình đã huấn luyện một lần nữa để thu được mô hình thưa thớt cuối cùng. Chiến lược này dẫn đến sự thay đổi không thể đoán trước trong hiệu suất mô hình một lần nữa. Ngược lại, bằng cách giữ tính thưa thớt của mô hình trong quá trình huấn luyện, hiệu suất của mô hình cuối cùng là sự phản ánh trực tiếp của tính hiệu quả của quá trình huấn luyện (Liu et al., 2018).

## 4. Thí nghiệm

Trong phần này, chúng tôi báo cáo một loạt thí nghiệm để chứng minh tính hiệu quả của SPP cho việc huấn luyện hiệu quả các mô hình thưa thớt đã cắt tỉa.

**Thiết lập thí nghiệm:** Chúng tôi chọn các họ mô hình LLaMA và LLaMA-2: LLaMA 7B/13B/30B/65B (Touvron et al., 2023a) và LLaMA-2 7B/13B/70B (Touvron et al., 2023b) cho các thí nghiệm. Đối với những LLM này, chúng tôi đầu tiên cắt tỉa chúng bằng các thuật toán cắt tỉa sau huấn luyện SparseGPT (Frantar & Alistarh, 2023) và Wanda (Sun et al., 2023), sau đó thực hiện tinh chỉnh hướng dẫn để khôi phục kiến thức. Tất cả các quá trình huấn luyện và kiểm tra được thực hiện trên một máy chủ với 8 GPU NVIDIA A100-80GB³.

**Chi tiết huấn luyện và đánh giá:** Chúng tôi sử dụng bộ dữ liệu tinh chỉnh hướng dẫn chất lượng cao Stanford-Alpaca (Taori et al., 2023) để huấn luyện các mô hình đã cắt tỉa. Chúng tôi không sử dụng các bộ dữ liệu tiền huấn luyện (ví dụ C4 (Raffel et al., 2020), SlimPajama (Soboleva et al., 2023), v.v.) vì chúng khá lớn nhưng chất lượng thấp. Khác với các nghiên cứu liên quan trước đây về huấn luyện các mô hình thưa thớt (ví dụ Sheared llama (Xia et al., 2023)), phương pháp của chúng tôi chỉ đòi hỏi vài giờ huấn luyện trên một bộ dữ liệu nhỏ hơn. Chúng tôi thêm các tham số học được vào các lớp tuyến tính "q proj, k proj, v proj, oproj, gate proj, up proj, down proj, score", và r được đặt thành 16 (trừ khi được ghi chú cụ thể). Để tiện lợi trong việc huấn luyện, chúng tôi tinh chỉnh các mô hình 7B/13B/30B bằng 3 epoch, và các mô hình 65B/70B bằng 1 epoch. Về mặt đánh giá, chúng tôi chủ yếu báo cáo hiệu suất zero-shot trên bảy tác vụ từ EleutherAI LM Harness (Gao et al., 2021) theo (Sun et al., 2023). Chúng tôi cũng kiểm tra hiệu suất few-shot trên benchmark MMLU (Hendrycks et al., 2021a;b).

**Tính thưa thớt mô hình và baseline:** Đối với hầu hết các thí nghiệm, chúng tôi sử dụng tỷ lệ thưa thớt 50%, bao gồm tính thưa thớt không có cấu trúc 50% và tính thưa thớt 2:4 (Mishra et al., 2021; Zhou et al., 2021). Chúng tôi so sánh các mô hình được huấn luyện bởi SPP với các mô hình đã cắt tỉa sau huấn luyện (SparseGPT (Frantar & Alistarh, 2023), Wanda (Sun et al., 2023)) và các mô hình dày đặc ban đầu. Để mở rộng các thí nghiệm sang tính thưa thớt cao hơn, chúng tôi kiểm tra một số trường hợp tính thưa thớt 75%, bao gồm tính thưa thớt không có cấu trúc 75% và tính thưa thớt 2:8, và so sánh SPP của chúng tôi với LoRA* và DS⊘T được đề xuất gần đây (Zhang et al., 2023b).

### 4.1. Số lượng tham số có thể huấn luyện

Một chỉ số quan trọng để ước tính một phương pháp PEFT là số lượng tham số học được trong quá trình huấn luyện. Bảng 1 tóm tắt số lượng và phần nghìn (‰) của các tham số có thể huấn luyện trong các thí nghiệm của chúng tôi với r = 16. Như có thể thấy, SPP chỉ đòi hỏi huấn luyện một phần rất nhỏ tham số.

### 4.2. Kết quả đánh giá Zero-shot

Trong Bảng 2 và Bảng 7 (Bảng 7 ở Phần A.3 trong Phụ lục do hạn chế về không gian), chúng tôi hiển thị độ chính xác zero-shot của các mô hình đã cắt tỉa sau huấn luyện và các đối tác được huấn luyện lại bởi SPP trên cả LLaMA và LLaMA-2 (kết quả theo từng tác vụ và trung bình). Chúng tôi tuân theo các tác vụ đánh giá và thiết lập thí nghiệm của Wanda (Sun et al., 2023). Như thấy từ các bảng, sau khi huấn luyện SPP, hiệu suất trung bình của phần lớn các mô hình được cải thiện. Đặc biệt đối với các mô hình với tính thưa thớt 2:4, chúng tôi quan sát thấy khoảng 8% cải thiện hiệu suất trung bình, lớn hơn so với các mô hình tính thưa thớt không có cấu trúc 50%. Bằng cách sử dụng thư viện cuSPARSELt, kỹ thuật N:M có thể được triển khai hiệu quả trên bộ xử lý đồ họa NVIDIA Ampere, dẫn đến tăng tốc thực tế. Do đó, việc nâng cao các mô hình tính thưa thớt 2:4 có tầm quan trọng đặc biệt.

### 4.3. Mở rộng sang tính thưa thớt cao hơn

Để xác nhận thêm tính hiệu quả của phương pháp SPP, chúng tôi mở rộng phương pháp cắt tỉa sau huấn luyện hiện có Wanda (Sun et al., 2023) sang tỷ lệ thưa thớt 75% với tính thưa thớt không có cấu trúc 75% và tính thưa thớt 2:8. Kết quả được hiển thị trong Bảng 3. "LM-eval" đại diện cho kết quả đánh giá zero-shot của 7 tác vụ khác nhau từ EleutherAI LM Harness (Gao et al., 2021), "PPL" đại diện cho độ phức tạp Wikitext (Merity et al., 2016). Chúng tôi phát hiện rằng Wanda (Sun et al., 2023) với tính thưa thớt không có cấu trúc 75% và tính thưa thớt 2:8 có sự suy giảm hiệu suất đáng kể, trong khi phương pháp mặt nạ động không có huấn luyện lại DS⊘T (Zhang et al., 2023b) có cải thiện hiệu suất hạn chế. Sau đó chúng tôi áp dụng phương pháp SPP vào các mô hình được cắt tỉa bởi Wanda và thu được kết quả tốt hơn nhiều. Điều này càng nhấn mạnh tính hiệu quả của việc huấn luyện lại tham số – như SPP đã làm – trong việc tăng cường hiệu suất của LLM thưa thớt.

### 4.4. Nghiên cứu loại bỏ

Trong phần này, chúng tôi thực hiện một nghiên cứu loại bỏ trên mô hình LLaMA-7B. Chúng tôi huấn luyện các mô hình thưa thớt thu được từ Wanda (Sun et al., 2023) và SparseGPT (Frantar & Alistarh, 2023) ở tính thưa thớt không có cấu trúc 50% và tính thưa thớt 2:4, tương ứng. Chúng tôi kiểm tra hiệu suất của các mô hình có và không có tham số Wβ, cũng như độ chính xác zero-shot trung bình của các mô hình cho các giá trị r khác nhau. Chúng tôi cũng đánh giá tính hiệu quả của việc khởi tạo không các trọng số được thêm vào. Kết quả được hiển thị trong Bảng 4. Mặc dù các thiết lập tham số khác nhau có thể dẫn đến kết quả khác nhau, việc huấn luyện với Wβ và sử dụng r = 16 có thể thu được kết quả tốt nhất tổng thể trong các thí nghiệm của chúng tôi. Trong ứng dụng thực tế của SPP, các tham số phù hợp có thể được chọn theo các tác vụ và tài nguyên tính toán có sẵn.

### 4.5. Phân tích thêm

Trong phần này, các thí nghiệm và phân tích thêm được cung cấp.

**So sánh với LoRA*:** Chúng tôi cũng so sánh SPP với LoRA*. Chúng tôi sử dụng r = 8 trong LoRA và thêm adapter vào những nơi giống như SPP, dẫn đến số lượng tham số học được tương tự (khoảng 0.28% cho các mô hình 7B và 0.18% cho các mô hình 30B). Vì LoRA tạo ra một mô hình dày đặc sau khi huấn luyện, để duy trì tính thưa thớt của mô hình, chúng tôi áp dụng các mặt nạ cắt tỉa Wanda ban đầu để làm thưa nó (phương pháp huấn luyện LoRA-sau đó-cắt tỉa được ký hiệu là LoRA*) và kiểm tra ở tính thưa thớt 75%. Như được hiển thị trong Bảng 5, so với mô hình được cắt tỉa sau khi huấn luyện LoRA, SPP có ưu thế hiệu suất trong hầu hết các trường hợp. Điều này nhấn mạnh tầm quan trọng của việc duy trì tính thưa thớt trọng số trong quá trình huấn luyện và hợp nhất trọng số.

**Kết quả Few-shot:** Kết quả trung bình 5-shot của các mô hình khác nhau trên benchmark MMLU (Hendrycks et al., 2021a;b) được hiển thị trong Bảng 6. So với các tác vụ trong Phần 4.2, MMLU là một benchmark khó khăn hơn và chứa một số câu hỏi khó khăn hơn (ví dụ, câu hỏi toán học). Như có thể thấy từ bảng, đối với các mô hình đã cắt tỉa sau huấn luyện, SPP cũng mang lại lợi ích hiệu suất lớn trong phần lớn các trường hợp. Tuy nhiên, các mô hình thưa thớt được huấn luyện bởi SPP vẫn có khoảng cách hiệu suất đáng kể so với các mô hình dày đặc ban đầu. Cần lưu ý rằng chúng tôi thu được cải thiện hiệu suất bằng tinh chỉnh hướng dẫn trên một bộ dữ liệu quy mô nhỏ. Những mô hình này sẽ cải thiện hiệu suất hơn nữa nếu chúng tôi mở rộng quy mô của bộ dữ liệu huấn luyện (Soboleva et al., 2023), nhưng hiện tại nó nằm ngoài phạm vi cân nhắc của chúng tôi trong bài báo này.

**Tăng tốc suy luận:** Tăng tốc suy luận cho các mô hình thưa thớt chỉ phụ thuộc vào mẫu thưa thớt của mô hình đã cắt tỉa. Vì SPP không thay đổi mẫu thưa thớt và tỷ lệ của mô hình đã cắt tỉa trong quá trình huấn luyện và hợp nhất tham số, nó sẽ dẫn đến cùng mức tăng tốc suy luận như mô hình đã cắt tỉa ban đầu. Chúng tôi tham khảo độc giả đến Phần 4.3 của bài báo Wanda (Sun et al., 2023) để biết kết quả về các mức tăng tốc suy luận liên quan, trong đó khoảng 1.6× tăng tốc được ghi nhận cho các lớp tuyến tính trong LLM và 1.24× tăng tốc độ trễ từ đầu đến cuối được quan sát cho LLaMA-7B (từ 312ms xuống 251ms) với tính thưa thớt có cấu trúc 2:4.

**Siêu tham số:** Để huấn luyện các mô hình 7B/13B/30B/65B/70B, chúng tôi sử dụng tỷ lệ học 4e-3/2e-3/4e-3/5e-4/5e-4 với kích thước batch trên thiết bị được đặt thành 8/4/16/8/8. Theo (Dettmers et al., 2023), chúng tôi đặt tỷ lệ khởi động 0.03, nhưng giảm tỷ lệ học sau khi đạt được giá trị đỉnh mục tiêu. Chúng tôi sử dụng trình tối ưu hóa AdamW với thiết lập mặc định trong gói Transformers⁴ và thêm 0.001 độ suy giảm trọng số. Sau khi cố định tất cả các siêu tham số, chúng tôi huấn luyện các LLM đã cắt tỉa sau huấn luyện thu được bởi SparseGPT (Frantar & Alistarh, 2023) và Wanda (Sun et al., 2023) với các mẫu thưa thớt và tỷ lệ khác nhau. Chúng tôi không thực hiện điều chỉnh siêu tham số cho các mẫu thưa thớt hoặc tỷ lệ cụ thể. Kết quả thí nghiệm được hiển thị trong bài báo chứng minh rằng SPP của chúng tôi có thể mang lại cải thiện hiệu suất ổn định.

## 5. Kết luận và thảo luận

Trong bài báo này, chúng tôi giới thiệu phương pháp tinh chỉnh có tham số hiệu quả với bảo toàn tính thưa thớt (SPP) mới, là một phương pháp đáng chú ý hiệu quả để huấn luyện lại hoặc tinh chỉnh các mô hình thưa thớt nhằm giải quyết thách thức khôi phục hiệu suất của LLM sau khi cắt tỉa.

Trước khi xuất hiện LLM, lĩnh vực cắt tỉa mô hình chủ yếu khám phá các phương pháp để xác định các mặt nạ thưa thớt nhị phân tối ưu trong khi huấn luyện các tham số còn lại, thông qua các kỹ thuật dựa trên gradient hoặc các phương pháp heuristic. Nghiên cứu của chúng tôi kết hợp phương pháp SPP vào các chiến lược cắt tỉa sau huấn luyện hiện có sử dụng mặt nạ cố định, và chỉ tập trung vào việc huấn luyện lại các tham số được bảo toàn sau khi cắt tỉa. Nhìn về tương lai, chúng tôi nhằm phát triển thêm phương pháp SPP của chúng tôi, và tích hợp nó với các kỹ thuật cập nhật mặt nạ lặp để nâng cao hiệu suất của việc huấn luyện lại với bảo toàn tính thưa thớt. Chúng tôi hy vọng chiến lược này có thể thúc đẩy thêm sự phát triển trong lĩnh vực nghiên cứu này.

## Tuyên bố tác động

Bài báo này trình bày công trình nhằm thúc đẩy lĩnh vực học máy, đặc biệt là lĩnh vực các mô hình ngôn ngữ lớn (LLM). Công trình của chúng tôi có thể góp phần giảm tài nguyên tính toán và tiêu thụ năng lượng cần thiết để vận hành những mô hình khổng lồ này, từ đó giải quyết các mối quan tâm về môi trường liên quan đến hoạt động mạng sâu quy mô lớn. Ngoài ra, hiệu quả cải thiện của LLM có thể tạo điều kiện cho các ứng dụng rộng rãi và dễ tiếp cận hơn của công nghệ AI, có khả năng dân chủ hóa lợi ích của AI trên nhiều lĩnh vực khác nhau. Tuy nhiên, như với bất kỳ tiến bộ nào trong học máy, cần có sự xem xét liên tục về các tác động đạo đức, đặc biệt là về quyền riêng tư dữ liệu, bảo mật, và tiềm năng cho các thiên lệch không mong muốn trong đầu ra mô hình. Đây là những câu hỏi mà tất cả chúng ta trong cộng đồng học máy cần xem xét khi tiến về phía trước.

## Lời cảm ơn

Dự án này được tài trợ một phần bởi Chương trình R&D Trọng điểm Quốc gia Trung Quốc Dự án 2022ZD0161100, bởi Trung tâm Trí tuệ Tri giác và Tương tác (CPII) Ltd thuộc Ủy ban Đổi mới và Công nghệ (ITC) InnoHK, bởi Quỹ Nghiên cứu Chung của Dự án RGC Hồng Kông 14204021. Hongsheng Li là PI của CPII thuộc InnoHK.

## Tài liệu tham khảo

[Danh sách tài liệu tham khảo được dịch tiếp...]

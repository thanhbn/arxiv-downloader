# Spectral Adapter: Tinh chỉnh trong Không gian Phổ
Fangzhao Zhang
Electrical Engineering
Stanford University
zfzhao@stanford.eduMert Pilanci
Electrical Engineering
Stanford University
pilanci@stanford.edu

Tóm tắt
Những phát triển gần đây trong các phương pháp Tinh chỉnh Hiệu quả Tham số (PEFT) cho mạng neural sâu đã được huấn luyện trước đã thu hút sự quan tâm rộng rãi. Trong công trình này, chúng tôi nghiên cứu việc cải thiện các phương pháp PEFT hiện tại bằng cách kết hợp thông tin phổ của ma trận trọng số được huấn luyện trước vào quy trình tinh chỉnh. Chúng tôi khảo sát hai cơ chế thích ứng phổ, cụ thể là tinh chỉnh cộng và quay trực giao của các vector đơn vị hàng đầu, cả hai đều được thực hiện bằng cách trước tiên thực hiện Phân tích Giá trị Đơn vị (SVD) của trọng số được huấn luyện trước và sau đó tinh chỉnh không gian phổ hàng đầu. Chúng tôi cung cấp một phân tích lý thuyết về tinh chỉnh phổ và chỉ ra rằng phương pháp của chúng tôi cải thiện khả năng hạng của các adapter hạng thấp với ngân sách tham số có thể huấn luyện cố định. Chúng tôi chứng minh thông qua các thí nghiệm rộng rãi rằng mô hình tinh chỉnh được đề xuất cho phép hiệu quả tham số tốt hơn và hiệu suất tinh chỉnh tốt hơn cũng như có lợi cho việc kết hợp đa adapter. Mã nguồn được phát hành tại https://github.com/pilancilab/spectral_adapter.

1 Giới thiệu
Kích thước của các mô hình ngôn ngữ và thị giác trải qua sự bùng nổ mạnh mẽ trong những ngày gần đây và dẫn đến hàng tỷ tham số cho đến nay. Trong khi tinh chỉnh đã được sử dụng rất nhiều để thích ứng các mô hình lớn được huấn luyện trước cho các tác vụ downstream khác nhau, các tác vụ tinh chỉnh trở nên ngày càng khó khăn với kích thước hiện tại của các mô hình được huấn luyện trước do nhu cầu tài nguyên tính toán khổng lồ. Đồng thời, việc trao đổi và lưu trữ các mô hình được tinh chỉnh cũng tốn kém do kích thước khổng lồ của chúng. Để giảm bớt những vấn đề ngày càng tăng này đối với việc tinh chỉnh các mô hình lớn được huấn luyện trước, một hướng nghiên cứu gần đây đã đào sâu vào họ mô hình Tinh chỉnh Hiệu quả Tham số (PEFT) và thu hút sự chú ý lớn. Triết lý cấp cao đằng sau những phương pháp PEFT đó là huấn luyện một số lượng tham số giảm so với tinh chỉnh đầy đủ, điều này ngay lập tức tiết kiệm tài nguyên tính toán và cho phép trao đổi mô hình được tinh chỉnh nhẹ. Trong tất cả các phương pháp PEFT, mô hình Thích ứng Hạng Thấp (LoRA) [20] là một thành công lớn nhờ vào tính đơn giản và hiệu quả của nó. Cụ thể, LoRA đề xuất tinh chỉnh một ma trận hạng thấp có thể huấn luyện cộng thêm và mang lại độ trễ suy luận bằng không sau khi hợp nhất adapter vào trọng số mô hình được huấn luyện trước. Kể từ khi xuất hiện, nhiều biến thể của LoRA đã được phát triển. Ví dụ, AdaLoRA [65], IncreLoRA [62], và DyLoRA [54] đề xuất điều chỉnh động phân bố hạng LoRA để cải thiện hiệu quả tinh chỉnh, QLoRA [10] kết hợp LoRA với lượng tử hóa mô hình để tiết kiệm thêm tài nguyên tính toán, LoRA+ [16] và PrecLoRA [61] nghiên cứu bức tranh tối ưu hóa của việc huấn luyện LoRA, và biến thể gần đây hơn DoRA [32] phân tích trọng số được huấn luyện trước thành các thành phần độ lớn và hướng và áp dụng LoRA cho tinh chỉnh hướng, xem Phụ lục A để có đánh giá toàn diện hơn về các biến thể LoRA khác nhau. Các phương pháp PEFT khác như Tinh chỉnh Trực giao (OFT) đề xuất nhân trọng số được huấn luyện trước với ma trận trực giao có thể tinh chỉnh để bảo toàn năng lượng siêu cầu giữa các neuron được huấn luyện trước. Mặc dù những phương pháp PEFT khác nhau này tập trung vào việc cải thiện hiệu quả tinh chỉnh với tham số giảm, hiếm khi có sự chú ý được dành cho việc sử dụng thông tin của trọng số mô hình được huấn luyện trước ngoài độ lớn của nó trong quy trình tinh chỉnh.

Nghiên cứu trước đây trong học máy thống kê như [36] đã nghiên cứu Phân phối Phổ Thực nghiệm (ESD) của ma trận trọng số mô hình sâu và phát hiện rằng ESD cho trọng số mô hình lớn hơn thường có cấu trúc hơn và chứa thông tin chỉ thị để phân biệt giữa các giai đoạn huấn luyện khác nhau. Công trình gần đây hơn như [3] khảo sát hiệu ứng "vật chất tối" của không gian phổ dưới cùng của trọng số mô hình và nhận ra vai trò quan trọng của nó trong hiện tượng chìm chú ý được quan sát trong [57]. Cả hai công trình đều góp phần vào việc giải mã thông tin phổ của trọng số mô hình và làm sáng tỏ việc xây dựng hiểu biết sâu sắc về mối liên hệ giữa thông tin phổ của ma trận trọng số và hiệu suất mô hình. Trong công trình này, chúng tôi khám phá thêm giá trị của mô hình phổ của trọng số mô hình và khám phá hiệu quả của nó trong việc cải thiện các tác vụ tinh chỉnh. Chúng tôi trình bày thông qua quan sát thực nghiệm rộng rãi rằng việc tích hợp thông tin phổ của trọng số mô hình được huấn luyện trước cải thiện hiệu quả tham số của các phương pháp PEFT hiện tại, hiệu ứng tinh chỉnh, và xuất hiện như một giải pháp tự nhiên cho các vấn đề kết hợp đa adapter. Hơn nữa, mô hình tinh chỉnh được đề xuất duy trì tính thực tế tốt hơn so với các mô hình tinh chỉnh phổ trước đây, điều này sẽ được khảo sát thêm bên dưới.

Mặc dù bất kỳ kỹ thuật nào để tinh chỉnh trọng số có thể được áp dụng trực tiếp để tinh chỉnh ma trận vector đơn vị của trọng số mô hình được huấn luyện trước, chúng tôi khảo sát hai dạng cụ thể của việc mở rộng như vậy, cụ thể là tinh chỉnh cộng và quay trực giao không gian vector đơn vị hàng đầu, mà chúng tôi gọi là Spectral Adapter A và Spectral Adapter R tương ứng trong nội dung sau. Các cơ chế thích ứng phổ được xem xét được mô tả chính thức trong Phần 2. Như một khởi động, để chỉ ra rằng việc kết hợp thông tin phổ thực sự hữu ích, Hình 1 hiển thị mất mát huấn luyện của việc tinh chỉnh mô hình Llama3 8B trên bộ dữ liệu HuggingFace Orca Math và điểm xác thực trên chuẩn GSM8K, từ đó có thể quan sát rõ ràng rằng Spectral Adapter A hoạt động vượt trội so với các biến thể gần đây của phương pháp PEFT và hoạt động gần nhất với tinh chỉnh đầy đủ, ở đây chúng tôi tuân theo thiết lập thí nghiệm trong [53], xem Phụ lục F.1 để biết chi tiết và khảo sát thêm. Dưới đây, chúng tôi trước tiên giới thiệu mô hình tinh chỉnh được nghiên cứu trong Phần 2 và sau đó chúng tôi cung cấp một số hiểu biết lý thuyết trong Phần 3. Sau đó, chúng tôi chi tiết lợi thế của spectral adapter của chúng tôi trong việc cải thiện kết quả tinh chỉnh, cải thiện hiệu quả tham số của mô hình, và giúp ích cho việc kết hợp đa adapter cũng như giải quyết mọi lo ngại về vấn đề thực tế trong Phần 4. Kết luận và công việc tương lai được thảo luận trong Phần 5. Vì hạn chế về số trang, đánh giá tài liệu được hoãn lại đến Phụ lục A.

Để tóm tắt, cơ chế thích ứng phổ được đề xuất thể hiện nỗ lực đầu tiên để tinh chỉnh không gian phổ của trọng số mô hình được huấn luyện trước theo cách hiệu quả tham số và tiết kiệm lưu trữ, điều này cải thiện các phương pháp PEFT hiện tại từ các khía cạnh liên quan đến kết quả tinh chỉnh, hiệu quả tham số, và kết hợp đa adapter. Chúng tôi hy vọng công trình này phục vụ như một khối xây dựng và thúc đẩy khảo sát sâu sắc hơn và sâu hơn để khám phá cấu trúc phổ của trọng số mô hình được huấn luyện trước, điều này trở nên ngày càng có ý nghĩa đặc biệt trong chế độ mô hình lớn hiện tại.

2 Spectral Adapter: Kết hợp Thông tin Phổ vào Tinh chỉnh
Được thúc đẩy bởi tính chất hạng thấp nội tại của sự thay đổi trọng số trong quy trình tinh chỉnh được nghiên cứu trong [1], LoRA [20] đề xuất thêm một ma trận có thể huấn luyện phân tích hạng thấp vào trọng số mô hình được huấn luyện trước và chỉ tinh chỉnh những tham số cộng thêm này để thích ứng tác vụ downstream, điều này thường tiêm ít tham số có thể huấn luyện hơn nhiều so với tinh chỉnh đầy đủ và tạo ra các adapter được tinh chỉnh nhẹ. LoRA phục vụ như một đại diện xuất sắc của họ PEFT và hiện được sử dụng rộng rãi cho các tác vụ tinh chỉnh khác nhau.

Được truyền cảm hứng bởi hiệu quả tham số của LoRA và mối liên hệ chặt chẽ giữa hạng ma trận và biểu diễn phổ của nó, ở đây chúng tôi nghiên cứu hai cơ chế tinh chỉnh phổ, cả hai đều được hoàn thành bằng cách trước tiên thực hiện Phân tích Giá trị Đơn vị (SVD) của trọng số mô hình được huấn luyện trước và sau đó tinh chỉnh các cột hàng đầu của ma trận vector đơn vị thu được qua SVD. Chính xác hơn, xem xét ma trận trọng số được huấn luyện trước với biểu diễn phổ dạng W=USV^T, chúng tôi định nghĩa adapter phổ cộng là

Spectral Adapter A(W) := [U₁+A_U U₂]S[V₁+A_V V₂],

và tương ứng là phiên bản quay

Spectral Adapter R(W) := [U₁R_U U₂]S[V₁R_V V₂],

trong đó U₁, V₁ biểu thị r cột hàng đầu của U và V và U₂, V₂ biểu thị các cột còn lại. A=(A_U, A_V) bao gồm ma trận có thể huấn luyện có hình dạng giống như (U₁, V₁) và R=(R_U, R_V) bao gồm hai ma trận trực giao có thể huấn luyện có hình dạng r by r sao cho R_U^T R_U = R_V^T R_V = I. Như chúng tôi chỉ ra trong các phần sau, ràng buộc trực giao được xử lý hiệu quả với tham số hóa Cayley, xem Phần 4.3 để biết chi tiết. Kiến trúc mô hình tinh chỉnh được đề xuất có thể được hình dung từ Hình 2. Ở đây Spectral Adapter A giống LoRA hơn vì nó có dạng cộng trong khi Spectral Adapter R giống phương pháp Tinh chỉnh Trực giao (OFT) trước đây hơn mà chúng tôi so sánh thêm trong Phần 4.

Để đảm bảo khởi tạo bằng không như thường được thực hiện cho các phương pháp PEFT, chúng tôi khởi tạo A_U và A_V đều bằng không. Đối với adapter phổ quay, chúng tôi khởi tạo R_U và R_V là ma trận đơn vị.

Một đánh giá tài liệu kỹ lưỡng hơn cho thấy rằng công việc trước đây xem xét việc tinh chỉnh biểu diễn phổ của trọng số mô hình (FSGAN [47], SVDiff [15]) đã được đề xuất để giảm thiểu overfitting khi tinh chỉnh các mô hình thị giác khác nhau. Những phương pháp này chỉ xem xét việc tinh chỉnh các giá trị đơn vị của trọng số CNN được làm phẳng và do đó có số lượng tham số có thể huấn luyện cố định. Hơn nữa, những phương pháp này yêu cầu lưu trữ tất cả U, S và V trong quá trình huấn luyện trong khi chỉ có vector đường chéo của S được tinh chỉnh, điều này gần như tăng gấp đôi yêu cầu lưu trữ so với huấn luyện trước khi tinh chỉnh trên các tác vụ downstream. Ngược lại, chúng tôi xem xét việc kết hợp thông tin phổ trong quy trình tinh chỉnh chung cho các lớp khác nhau (trọng số CNN được làm phẳng, trọng số tuyến tính dày đặc, v.v.) và phương pháp của chúng tôi cho phép lựa chọn ngân sách tham số linh hoạt bằng cách thay đổi các giá trị của r. Về phương pháp luận, chúng tôi xem xét việc tinh chỉnh r cột hàng đầu của U và V bằng tinh chỉnh cộng và quay, cả hai đều chỉ yêu cầu những cột hàng đầu này được lưu trữ thêm và phần còn lại có thể được hợp nhất thành một ma trận trọng số duy nhất. Xem Phần 4.4 để khảo sát thêm về tính thực tế của phương pháp được đề xuất.

3 Hiểu biết Lý thuyết
Sau khi giới thiệu kiến trúc mô hình của spectral adapter mà chúng tôi xem xét, câu hỏi chính bây giờ vẫn là liệu việc tinh chỉnh biểu diễn phổ của trọng số được huấn luyện trước có thực sự là một cải tiến so với các phương pháp PEFT hiện có hay không. Trước khi chúng tôi đi vào các quan sát thực nghiệm, chúng tôi trước tiên cung cấp một số hiểu biết lý thuyết cho cơ chế thích ứng phổ được đề xuất. Trong phần này, chúng tôi chỉ ra lợi thế của phương pháp spectral adapter so với LoRA từ hai góc độ lý thuyết bằng cách phân tích cả khả năng hạng của các adapter (Phần 3.1) và sự sắp xếp không gian con của ma trận trọng số được huấn luyện trước (Phần 3.2). Cụ thể, chúng tôi sẽ thấy rằng Spectral Adapter A có khả năng hạng lớn hơn so với LoRA adapter, điều này chỉ ra rằng trọng số được tinh chỉnh có nhiều tự do thích ứng hơn và do đó mong muốn hơn. Hơn nữa, hướng phổ chi phối của ma trận trọng số được huấn luyện trước xác định sự sắp xếp neuron lý tưởng hơn dưới thiết lập mà chúng tôi xem xét trong Phần 3.2, điều này biện minh cho tính mạnh mẽ của việc tinh chỉnh các vector đơn vị hàng đầu trong spectral adapter của chúng tôi. Trong Phụ lục D, chúng tôi chỉ ra rằng Spectral Adapter A tương đương gần với DoRA [32] cho trọng số dạng vector.

3.1 Khả năng Hạng Adapter
Đối với bất kỳ ma trận trọng số được huấn luyện trước W nào, giả sử adapter được cho bởi tham số hóa f_θ(W) trong đó θ đại diện cho trọng số có thể huấn luyện. Ví dụ với LoRA adapter, f_θ(W)=W+AB^T, trong đó θ={A, B} có thể huấn luyện. Chúng tôi định nghĩa khả năng hạng của adapter f_θ(W) như sau:

R(f_θ;W) := max_θ rank(f_θ(W)) - min_θ rank(f_θ(W)),

mô tả phạm vi hạng ma trận mà trọng số được tinh chỉnh có thể đạt được với một dạng adapter cụ thể. Sau đó, bổ đề sau cho thấy Spectral Adapter A có khả năng hạng gấp đôi so với LoRA adapter dưới số lượng tham số có thể huấn luyện bằng nhau.

Bổ đề 3.1. Giả sử W∈R^{n×m} là ma trận hạng hàng đầy đủ tùy ý và n≤m không mất tính tổng quát. Xem xét LoRA hạng-r và additive spectral adapter hạng-r, có số lượng tham số có thể huấn luyện bằng nhau. Chúng ta có

R(LoRA; W) = r,
R(Spectral Adapter A; W) = 2r.

Xem Phụ lục B để biết chứng minh. Do đó khi ma trận trọng số mô hình được huấn luyện trước gần với hạng hàng đầy đủ, như đã được quan sát trong [20], Spectral Adapter A có khả năng hạng gần gấp đôi so với LoRA adapter. Hơn nữa, một số công việc trước đây rõ ràng áp đặt ràng buộc hạng thấp khi huấn luyện NN gốc [50,43,66,22,68,24,9]. Sử dụng LoRA adapter để tinh chỉnh trọng số mô hình được huấn luyện trước như vậy sẽ phá hủy các ràng buộc hạng của chúng trong khi áp dụng spectral adapter bảo toàn các ràng buộc.

Tiếp theo, chúng tôi tiến hành chỉ ra rằng không gian phổ hàng đầu của ma trận trọng số được huấn luyện trước được sắp xếp tốt hơn với hướng neuron lý tưởng dưới một thiết lập đơn giản thông qua phân tích phân tích không gian con của trọng số mô hình được huấn luyện trước. Quan sát này củng cố lựa chọn của chúng tôi về việc tinh chỉnh các vector đơn vị hàng đầu trong cơ chế thích ứng phổ được đề xuất. Theo kinh nghiệm, chúng tôi quan sát rằng việc tinh chỉnh các hướng hàng đầu hoạt động vượt trội so với việc tinh chỉnh các hướng dưới cùng, xem Phụ lục F.3 và F.5.1 để biết các thí nghiệm liên quan.

3.2 Sắp xếp Không gian Con Trọng số
Xem xét mạng ReLU hai lớp với m node ẩn và đầu ra đơn biến. Đối với mục tiêu mất mát bình phương, chúng ta có thể viết rõ ràng bài toán huấn luyện như

min_{W^{(1)},W^{(2)}} ‖(XW^{(1)})_+ W^{(2)} - y‖²₂ + β(‖W^{(1)}‖²_F + ‖W^{(2)}‖²₂),

trong đó X∈R^{n×d} là ma trận dữ liệu, (W^{(1)}∈R^{d×m}, W^{(2)}∈R^m) là trọng số lớp thứ nhất và thứ hai tương ứng và y∈R^n là vector nhãn. Để hình dung tốt hơn, chúng ta lấy d=3. Xem xét trường hợp tất cả các điểm dữ liệu nằm trên mặt phẳng xy, điều này bắt chước quan sát thông thường rằng các điểm dữ liệu chiếm một đa tạp chiều thấp. Khi đó chúng ta có thể phân tích mỗi neuron lớp đầu W^{(1)}_j∈R^d thành W^{(1)}_j = w_{j1} + w_{j2} trong đó w_{j1}∈R(X), w_{j2}⊥R(X). Với đại số đơn giản, đối với weight decay khác không thường là thiết lập mặc định cho các optimizer học sâu hiện tại, người ta có thể dẫn ra w_{j2}=0 và do đó W^{(1)}_j = w_{j1}∈R(X). Do đó tất cả các neuron tối ưu cũng nằm trong mặt phẳng xy. Tuy nhiên, do lỗi tối ưu hóa, một số neuron được huấn luyện có thể hơi lệch khỏi mặt phẳng xy, như được minh họa trong Hình 3, trong đó u_i chỉ ra các hướng neuron được huấn luyện trước, mặc dù hầu hết chúng nằm trong mặt phẳng xy, một số có thể lệch (tức là u_4). u^⋆ chỉ ra hướng vector đơn vị hàng đầu của trọng số được huấn luyện trước W^{(1)} mà ở đây nhận ra định hướng mặt phẳng xy, và do đó việc tinh chỉnh u^⋆ là không nhiễu và được kỳ vọng là mạnh mẽ hơn.

4 Kết quả Thực nghiệm: Tác động của Thông tin Phổ
Chúng tôi thí nghiệm spectral adapter được đề xuất với việc tinh chỉnh các mô hình ngôn ngữ lớn và mô hình khuếch tán và so sánh với các phương pháp PEFT gần đây khác nhau. Từ các thí nghiệm mô hình ngôn ngữ, chúng tôi quan sát rằng Spectral Adapter A hoạt động vượt trội so với các baseline PEFT khác nhau và đạt được điểm số cao hơn trên các benchmark khác nhau, điều này một lần nữa xác minh hiệu quả của việc kết hợp thông tin phổ vào quy trình tinh chỉnh, xem Phần 4.1 để biết chi tiết. Đối với các thí nghiệm mô hình khuếch tán, chúng tôi sẽ thấy rằng lợi thế của spectral adapter đến theo hai hướng: Spectral Adapter A cung cấp một giải pháp tự nhiên cho các vấn đề hiện có trong quy trình kết hợp đa adapter và Spectral Adapter R thể hiện ngân sách tham số tinh tế hơn cũng như hiệu quả tham số tốt hơn, xem Phần 4.2 và 4.3 tương ứng. Để so sánh công bằng với tất cả các baseline, chúng tôi sử dụng triển khai chính thức của chúng và tuân theo thiết lập siêu tham số trong báo cáo gốc của chúng miễn là có sẵn. Xem từng phần riêng lẻ để biết chi tiết thí nghiệm tương ứng. Tất cả các thí nghiệm được thực hiện với GPU NVIDIA RTX A6000.

4.1 Tinh chỉnh Mô hình Ngôn ngữ: Cải thiện Kết quả Tinh chỉnh với Spectral Adapter A
Đối với các thí nghiệm mô hình ngôn ngữ lớn, chúng tôi trình bày kết quả thí nghiệm cho việc tinh chỉnh mô hình DeBERTaV3-base (185M) và mô hình Mistral (7B) trên các tác vụ GLUE và GSM8K tương ứng. Phương pháp Spectral Adapter A của chúng tôi đạt được kết quả tinh chỉnh vượt trội so với các phương pháp PEFT gần đây khác nhau trong hầu hết các thí nghiệm.

Thí nghiệm DeBERTaV3-base. Bảng 1 cho thấy kết quả tinh chỉnh của mô hình DeBERTaV3-base trên các benchmark GLUE với các phương pháp PEFT khác nhau. Để so sánh công bằng, chúng tôi sử dụng các triển khai chính thức cho LoRA, DoRA, OFT và AdaLoRA trong thư viện HuggingFace PEFT, với thiết lập siêu tham số cho LoRA [20] và AdaLoRA [65] tuân theo báo cáo gốc của chúng. Chúng tôi sử dụng thiết lập siêu tham số giống như LoRA cho DoRA và tuân theo thiết lập được sử dụng trong BOFT [33], một biến thể của OFT, cho các thí nghiệm OFT. Chúng tôi viết tắt Spectral Adapter A là SpectralA để trình bày đơn giản và chúng tôi tinh chỉnh siêu tham số cho Spectral Adapter A. Xem Phụ lục F.2 để biết chi tiết siêu tham số và F.3 để so sánh biểu đồ mất mát/xác thực. Chúng tôi tinh chỉnh tất cả các ma trận q, k, v trong các lớp chú ý. Spectral Adapter A của chúng tôi đạt được điểm trung bình cao nhất và điểm tốt nhất cho hầu hết các tác vụ với ít tham số có thể huấn luyện nhất.

Thí nghiệm Mistral 7B. Chúng tôi thí nghiệm Spectral Adapter A với mô hình Mistral 7B [23] được tinh chỉnh cho tác vụ GSM8K [7]. Vì tất cả báo cáo mô hình baseline không bao gồm tác vụ tinh chỉnh với họ Mistral, chúng tôi sử dụng các triển khai chính thức của tất cả các phương pháp baseline để so sánh và chúng tôi cố định learning rate là 2.5e-5 cho tất cả các phương pháp theo [51]. Chúng tôi lấy r=8 cho LoRA, DoRA và Spectral Adapter A để duy trì số lượng tham số có thể huấn luyện tương đương cho tất cả các phương pháp. Bảng 2 trình bày so sánh độ chính xác trong đó SpectralA đại diện cho Spectral Adapter A. Từ kết quả, chúng tôi quan sát rằng Spectral Adapter A của chúng tôi đạt điểm cao hơn cả LoRA và DoRA với biên lớn và tăng baseline mô hình được huấn luyện trước đáng kể, điều này xác minh hiệu quả của cơ chế thích ứng phổ được đề xuất. Xem Phụ lục F.4 để biết thêm về chi tiết thí nghiệm. Lưu ý với learning rate khác, DoRA hoạt động tốt hơn LoRA trong khi vẫn tệ hơn phương pháp của chúng tôi, xem thêm Phụ lục F.4 để biết chi tiết.

4.2 Kết hợp Mô hình Khuếch tán: Cải thiện Tinh chỉnh Đa Đối tượng với Spectral Adapter A
Kết hợp đa adapter là một điểm nghẽn hiện tại trong các tác vụ tinh chỉnh mô hình khuếch tán với các adapter LoRA. Việc chỉ cộng các adapter LoRA khác nhau được tinh chỉnh cho các đối tượng riêng biệt sẽ dẫn đến các vấn đề liên quan đến mất danh tính và ràng buộc khái niệm [12]. Để giải quyết khó khăn này, các phương pháp khác nhau xuất hiện như Gradient Fusion [12] và Orthogonal Adaptation [42]. Cụ thể, phương pháp Orthogonal Adaptation đề xuất cố định tham số LoRA B để có cơ sở trực giao và chỉ huấn luyện A. Các thí nghiệm ở đó cho thấy rằng việc hợp nhất trọng số LoRA với cơ sở trực giao như vậy giúp bảo toàn các đặc tính đối tượng riêng lẻ so với phần tương ứng không trực giao. Trong Orthogonal Adaptation [42], các tác giả duy trì B bằng cách thủ công giữ các ma trận trực giao lớn cho các kích thước lớp khác nhau và lấy mẫu r cột từ ma trận trực giao tương ứng để tạo thành B cho mỗi adapter LoRA. Với kiến thức từ lý thuyết ma trận ngẫu nhiên, các ma trận được lấy mẫu như vậy có khả năng có cơ sở trực giao.

Đáng chú ý, Spectral Adapter A của chúng tôi tự nhiên hoạt động trên các vector đơn vị trực giao và do đó giới thiệu một giải pháp tao nhã cho các vấn đề kết hợp đa adapter bằng cách phân phối các tinh chỉnh khái niệm khác nhau dọc theo các cột khác nhau của ma trận vector đơn vị, điều này ánh xạ tới truyền thông không dây nơi các tín hiệu được phân phối qua các tần số không chồng lấn. Một điểm tinh tế ở đây nằm trong việc lựa chọn không gian cột cho các tác vụ tinh chỉnh khác nhau: (1) Các phương pháp dựa trên mẫu có thể được áp dụng nếu bảo mật dữ liệu được xem xét và các tác vụ tinh chỉnh khác nhau được thực hiện độc lập. Trong Phụ lục F.5, chúng tôi chỉ ra rằng việc tinh chỉnh các cột hàng đầu thể hiện chất lượng tạo tốt hơn so với cả việc tinh chỉnh các cột dưới cùng và việc lấy mẫu cơ sở trực giao ngẫu nhiên như đã được thực hiện trong Orthogonal Adaptation [42]. Do đó có một sự đánh đổi giữa tạo chất lượng cao và sự sụp đổ khái niệm, tức là lấy mẫu từ các vector đơn vị hàng đầu được khuyến khích hơn trong khi sự chồng lấn cột giữa các khái niệm xảy ra thường xuyên hơn so với việc lấy mẫu từ toàn bộ tập hợp. (2) Mặt khác, nếu các tác vụ tinh chỉnh không bị cô lập và có thể hợp tác trong việc lập lịch cột, thì việc lập lịch tinh chỉnh có chủ ý hơn có thể được áp dụng, ví dụ trong tác vụ tinh chỉnh hai khái niệm với r=4, khái niệm đầu tiên có thể phân bổ từ cột thứ nhất đến thứ tư và khái niệm thứ hai sau đó yêu cầu từ cột thứ năm đến thứ tám. Hình 4 minh họa các bước cho cùng một phương pháp cho tác vụ tinh chỉnh ba khái niệm. Vì chúng tôi mong đợi trọng số được tinh chỉnh vẫn gần với trọng số gốc, mặc dù cả không gian hàng và không gian cột đều được tinh chỉnh trong spectral adapter, cơ chế thích ứng này tương tự việc tinh chỉnh cơ sở trực giao cho các đối tượng khác nhau và do đó chúng tôi mong đợi nó giúp cải thiện việc bảo toàn danh tính cho kết hợp đa adapter. Trong phần này, chúng tôi khảo sát hiệu ứng này thông qua các thí nghiệm mô hình khuếch tán rộng rãi.

Các thí nghiệm của chúng tôi tuân theo [42] và được xây dựng trên [12] nghiên cứu kết hợp đa LoRA. Chúng tôi thí nghiệm với tinh chỉnh đa đối tượng và các tác vụ tạo khuôn mặt. Do hạn chế về không gian, chúng tôi trình bày một số kết quả tinh chỉnh đa đối tượng dưới đây và để lại phần còn lại cho Phụ lục F.5. Đối với tất cả các tác vụ, chúng tôi so sánh với các baseline bao gồm Gradient Fusion [12], Orthogonal Adaptation [42], và FedAvg [37]. Chúng tôi bắt đầu với một đánh giá ngắn gọn cho những phương pháp baseline này.

Đánh giá Baseline
Để hợp nhất các adapter LoRA khác nhau, giả sử chúng ta có một tập hợp tham số LoRA {Δθ₁, ..., Δθₙ} trong đó Δθᵢ = AᵢBᵢᵀ và tham số được huấn luyện trước θ₀, FedAvg [37] đề xuất hợp nhất chúng thành một tham số duy nhất bằng cách lấy trung bình có trọng số là θ_merged = θ₀ + Σᵢλᵢ Δθᵢ, trong đó λᵢ là trọng số gắn với tham số Δθᵢ và thường được lấy để thỏa mãn Σᵢλᵢ = 1, tức là θ_merged là tổ hợp lồi của các adapter riêng lẻ. Gradient Fusion [12] thay vào đó xem xét giải quyết một bài toán tối ưu hóa phụ trợ dạng θ_merged = argmin_θ Σⁿᵢ₌₁ ‖(θ₀ + Δθᵢ)Xᵢ - θXᵢ‖²_F trong đó Xᵢ đại diện cho kích hoạt đầu vào của khái niệm thứ i. Orthogonal Adaptation [42] tuân theo phương pháp FedAvg và thay thế tham số LoRA gốc bằng các adapter LoRA dựa trên trực giao. Đối với phương pháp của chúng tôi, để hợp nhất các spectral adapter khác nhau, cho θ₀ = U₀S₀V₀ᵀ biểu thị biểu diễn phổ của trọng số mô hình được huấn luyện trước. Với một tập hợp spectral adapter {(U₁, V₁), ..., (Uₙ, Vₙ)} với zero-padding để làm cho hình dạng giống như (U₀, V₀), chúng tôi tuân theo FedAvg và tính θ_merged = (U₀ + Σᵢλᵢ Uᵢ)S₀(V₀ + Σᵢλᵢ Vᵢ)ᵀ. Trong các thí nghiệm sau, chúng tôi lấy λᵢ = 1/n như trong [42] cho tất cả FedAvg, Orthogonal Adaptation, và kết hợp Spectral Adapter A của chúng tôi. Đáng chú ý, tất cả FedAvg, Orthogonal Adaptation, và kết hợp Spectral Adapter A của chúng tôi có thể được thực hiện gần như ngay lập tức trong khi Gradient Fusion thường mất khoảng 10-15 phút để giải quyết các bài toán tối ưu hóa phụ trợ cho tất cả các adapter khái niệm.

Tạo Đa Đối tượng
Chúng tôi tuân theo thiết lập huấn luyện mặc định trong [12] và tinh chỉnh mô hình khuếch tán Chilloutmix [8] trên ba khái niệm động vật tùy chỉnh, xem các động vật gốc trong "reference" trong Hình 5. Để sắp xếp không gian tốt hơn, chúng tôi áp dụng T2I-Adapter [39] với điều kiện phác thảo và chúng tôi đặt guidance bằng một, xem thêm "reference" trong Hình 5 cho điều kiện phác thảo được sử dụng. Hạng LoRA r=8 được áp dụng. Để so sánh baseline, chúng tôi sử dụng mã gốc cho Gradient Fusion [12] và Orthogonal Adaptation [42]. Chúng tôi điều chỉnh mã của Gradient Fusion cho phương pháp FedAvg vì không có triển khai chính thức có sẵn. Tên động vật tùy chỉnh được thay thế bằng token đặc biệt <Vanimal> để tinh chỉnh. Đối với Spectral Adapter A của chúng tôi, chúng tôi tuân theo phương pháp được mô tả trong Hình 4 và tinh chỉnh cột thứ tám hàng đầu thứ nhất, thứ hai, và thứ ba của ma trận vector đơn vị cho các khái niệm động vật khác nhau. Hình 5 cho thấy kết quả tạo với các phương pháp khác nhau cho các prompt được chọn. Đáng chú ý, các phương pháp baseline đôi khi không thể nắm bắt các khái niệm động vật tùy chỉnh trong khi Spectral Adapter A nhận ra tất cả các động vật tùy chỉnh và tạo ra hình ảnh hài lòng về mặt thị giác. Để đo lường tốt hơn, chúng tôi cũng tính toán điểm sắp xếp cho mỗi hình ảnh được tạo với cả hình ảnh tham chiếu và văn bản prompt. Có thể chứng kiến rằng phương pháp của chúng tôi đạt được điểm sắp xếp tốt hơn so với các baseline. Xem Phụ lục F.7 để biết chi tiết về tính toán điểm sắp xếp.

4.3 Biểu cảm Mô hình Khuếch tán: Cải thiện Hiệu quả Tham số với Spectral Adapter R
Spectral Adapter R có mối liên hệ chặt chẽ với phương pháp Tinh chỉnh Trực giao (OFT) [45] trước đây, phương pháp này đề xuất nhân trọng số mô hình được huấn luyện trước với ma trận trực giao có thể huấn luyện trong quy trình tinh chỉnh. Động cơ đằng sau OFT là bảo toàn năng lượng siêu cầu đặc trưng cho mối quan hệ neuron theo cặp trên siêu cầu đơn vị. Không giống như OFT quay trực giao các neuron, Spectral Adapter R nhân r cột hàng đầu của không gian vector đơn vị U và V với ma trận trực giao có thể huấn luyện. Đối với triển khai của chúng tôi, một số tùy chọn có sẵn để duy trì ma trận trực giao có thể huấn luyện như thêm penalty trực giao trong hàm mục tiêu được xem xét trong [65] hoặc thông qua tham số hóa Cayley được xem xét trong [45]. Chúng tôi tuân theo [45] và áp dụng tham số hóa Cayley được hỗ trợ bởi Pytorch [44]. Cụ thể, ma trận trực giao R được xây dựng thông qua R = (I+Q)(I-Q)⁻¹ với ma trận skew-symmetric Q được duy trì là (A-Aᵀ)/2 trong đó A là tham số có thể huấn luyện của chúng tôi. So với việc thêm penalty trực giao phụ trợ, tham số hóa này chính xác và do đó dạng SVD được bảo toàn sau khi tinh chỉnh với Spectral Adapter R và có thể được áp dụng trực tiếp cho các tác vụ tinh chỉnh tiếp theo, mà chúng tôi phát biểu chính thức như một bổ đề dưới đây:

Bổ đề 4.1. Với tham số hóa Cayley, Spectral Adapter R là một phép toán quay chính xác và do đó bảo toàn cấu trúc của SVD của trọng số được tinh chỉnh. Các tinh chỉnh tiếp theo có thể được áp dụng liên tiếp mà không cần tính toán lại SVD mỗi lần.

Xem Phụ lục C để biết chứng minh của bổ đề trên. Không giống như LoRA yêu cầu số lượng tham số có thể huấn luyện tỉ lệ với kích thước trọng số, khi tinh chỉnh r cột hàng đầu của U và V, Spectral Adapter R chỉ yêu cầu hai ma trận có thể huấn luyện có kích thước r×r và do đó có thể hiệu quả tham số hơn đặc biệt đối với trọng số được huấn luyện trước lớn. Đối với kích thước trọng số phổ biến như W∈R¹⁰²⁴ˣ¹⁰²⁴, LoRA với chỉ r=1 giới thiệu cùng số lượng tham số có thể huấn luyện như Spectral Adapter R với r=32. Để phân tích toàn diện về cải thiện hiệu quả tham số được mang lại bởi Spectral Adapter R, chúng tôi ở đây cũng so sánh với các biến thể khác nhau của LoRA được đề xuất để tiết kiệm tham số có thể huấn luyện. Chúng tôi xem xét tất cả các baseline một cách chi tiết dưới đây.

Đánh giá Baseline
Chúng tôi so sánh Spectral Adapter R với LoRA [20], SVDiff [15], LiDB [48], OFT [45], và VeRA [25]. Mặc dù các phương pháp khác được đề xuất cho việc tinh chỉnh mô hình thị giác, VeRA ban đầu được đề xuất cho việc tinh chỉnh LLM và chúng tôi mở rộng nó ở đây cho việc tinh chỉnh mô hình khuếch tán do hiệu quả tham số của nó. Xem xét trọng số được huấn luyện trước W∈Rⁿˣⁿ, SVDiff ban đầu đề xuất tinh chỉnh tất cả các giá trị đơn vị của trọng số CNN được làm phẳng, ở đây chúng tôi mở rộng nó để tinh chỉnh tất cả các giá trị đơn vị của text encoder và trọng số U-Net để so sánh, do đó tham số có thể huấn luyện gắn với W sẽ có kích thước n và không thể điều chỉnh. LiDB viết tắt của Lightweight Dreambooth và đề xuất cắt giảm ngân sách tham số có thể huấn luyện bằng cách giới thiệu ma trận đóng băng phụ trợ A_aux∈Rⁿˣᵃ và B_aux∈Rᵇˣⁿ, sau đó nó bắt chước LoRA nhưng sử dụng A_aux AB^T B_aux thay thế ABᵀ với tham số có thể huấn luyện (A∈Rᵃˣʳ, B∈Rᵇˣʳ). Do đó với a, b < n, LiDB yêu cầu (a+b)r < 2nr tham số có thể huấn luyện. Dưới đây, chúng tôi sử dụng a=50, b=100 như mặc định trong [48]. OFT nhân ma trận trọng số với ma trận trực giao có thể huấn luyện thông qua tham số hóa Cayley được thảo luận ở trên, do đó phiên bản đầy đủ của nó yêu cầu n² tham số có thể huấn luyện. Để hiệu quả tham số, OFT đề xuất sử dụng ma trận có thể huấn luyện block-diagonal với tất cả các block đường chéo là trực giao. Do đó với r block đường chéo, số lượng tham số có thể huấn luyện sẽ là r×(n/r)². Việc giảm thêm tham số có thể huấn luyện được đạt được thông qua việc chia sẻ các block đường chéo, điều này chỉ yêu cầu (n/r)² tham số. Trong so sánh dưới đây, chúng tôi sử dụng phiên bản block-diagonal chia sẻ này để có hiệu quả tham số tốt nhất của OFT. VeRA đề xuất sử dụng Λ_a A Λ_b B^T thay thế AB^T trong đó Λ_a và Λ_b là ma trận đường chéo có kích thước n×n và r×r tương ứng. Do đó tổng số tham số có thể huấn luyện bởi VeRA là (n+r) ∝ n. Bảng 3 so sánh các thuộc tính khác nhau trên tất cả các phương pháp, trong đó n đại diện cho kích thước trọng số và r đại diện cho hạng cho tất cả các phương pháp trừ OFT, trong đó r biểu thị số lượng block đường chéo.

Hiệu quả Tham số
Chúng tôi tinh chỉnh mô hình khuếch tán Chilloumix [8] với các phương pháp PEFT khác nhau trên khái niệm bình tùy chỉnh và trình bày kết quả tạo cho prompt "a <Vvase> on a table" trong Hình 6 cho các ngân sách tham số có thể huấn luyện khác nhau, trong đó dash màu xám biểu thị rằng ngân sách tham số tương ứng không thể đạt được với adapter đã cho dù siêu tham số được chọn như thế nào và entry trống không có dash màu xám đại diện cho việc có cách để đạt được ngân sách tham số tương ứng mặc dù kết quả tạo bị bỏ qua để hình dung tốt hơn. Chúng tôi tuân theo triển khai LoRA mặc định trong [12] cho baseline LoRA và điều chỉnh nó cho tất cả các phương pháp khác. Từ Hình 6, có thể quan sát rằng LoRA, OFT, và LiDB bắt đầu tạo bình gần với bình tùy chỉnh với ít nhất 200k tham số có thể huấn luyện. SVDiff và VeRA không thể tạo hình ảnh bình lý tưởng ngay cả khi được mở rộng lên ngân sách tham số lớn. Ngược lại, Spectral Adapter R bắt đầu nhận ra khái niệm bình tùy chỉnh chỉ với 20k tham số có thể huấn luyện và có lựa chọn tham số tinh tế hơn so với các phương pháp khác, tức là đáng chú ý Spectral Adapter R có thể có ít nhất 1k tham số trong khi các phương pháp khác bắt đầu với ít nhất hàng chục nghìn tham số có thể huấn luyện. Tóm lại, Spectral Adapter R tận hưởng lựa chọn ngân sách tham số tinh tế hơn và thể hiện chất lượng thị giác tốt hơn với ít tham số hơn, do đó đạt được hiệu quả tham số cải thiện so với các phương pháp PEFT khác nhau.

Hình 7 ở trên trình bày kết quả tạo của mô hình khuếch tán Chilloutmix [8] được tinh chỉnh trên khái niệm ghế tùy chỉnh với các phương pháp khác nhau dưới các ngân sách tham số khác nhau. Prompt được sử dụng là "a yellow <Vchair>". Xem "reference" trong Hình 7 cho hình ảnh ghế gốc. Từ kết quả tạo, có thể quan sát rằng LoRA tạo ra ghế hợp lý cho tất cả hạng r=1,2,3 mặc dù nó đã gây ra 273k tham số ngay cả khi hạng được đặt thành 1. OFT và VeRA bắt đầu nhận ra ghế tùy chỉnh với >100k tham số. SVDiff có ngân sách tham số có thể huấn luyện cố định duy nhất có kích thước khoảng 100k. LiDB tạo thành ứng viên cạnh tranh và tạo hình ảnh thỏa mãn với ngân sách tham số có thể huấn luyện nhỏ nhất trong tất cả các phương pháp baseline. Tuy nhiên, Spectral Adapter R của chúng tôi vẫn tạo hình ảnh được sắp xếp tốt hơn với hình ảnh tham chiếu chỉ với 20k tham số có thể huấn luyện và có lựa chọn ngân sách tham số tinh tế hơn so với LiDB. Xem Phụ lục F.6 để biết thiết lập siêu tham số và Phụ lục F.7 để biết chi tiết tính toán điểm sắp xếp.

4.4 Ghi chú Cuối: Cái nhìn Gần hơn về Chi phí SVD
Để giảm bớt các lo ngại về chi phí huấn luyện trực tuyến và chỉ ra rằng phương pháp được đề xuất của chúng tôi rất thực tế, chúng tôi cung cấp biểu đồ thanh chi phí thời gian chạy và lưu trữ GPU trong Hình 8, cho thấy chi phí thời gian chạy và lưu trữ GPU cho LoRA và cho Spectral Adapter A của chúng tôi khi được sử dụng để tinh chỉnh mô hình khuếch tán trong Phần 4.2 và mô hình Mistral 7B trong Phần 4.1. Ở đây chúng tôi áp dụng hạng r=8 cho cả LoRA và Spectral Adapter A. Có thể quan sát rằng Spectral Adapter A của chúng tôi giới thiệu chi phí thời gian chạy và lưu trữ không đáng kể cho kích thước mô hình lớn hiện tại. Các công cụ số hiện đại như randomized SVD [13] cũng có thể được khai thác để giảm thêm thời gian chạy và quy trình SVD có thể được song song hóa khi có nhiều máy. Xem Phụ lục E để khảo sát thêm.

5 Kết luận và Hạn chế
Trong công trình này, chúng tôi khảo sát việc kết hợp thông tin phổ của trọng số mô hình được huấn luyện trước vào các mô hình PEFT hiện tại bằng cách giới thiệu cơ chế thích ứng phổ chỉ cập nhật các vector đơn vị hàng đầu của trọng số được huấn luyện trước. Chúng tôi khảo sát các biến thể cộng và quay của cơ chế thích ứng phổ như vậy. Về lý thuyết, chúng tôi chỉ ra động cơ của việc tinh chỉnh các vector đơn vị hàng đầu bằng cách so sánh khả năng hạng của các mô hình tinh chỉnh khác nhau và thực hiện phân tích trọng số của các lớp mô hình được huấn luyện trước. Về thực nghiệm, chúng tôi xác minh tính ưu việt của phương pháp thích ứng phổ được đề xuất so với các phương pháp PEFT gần đây khác nhau từ các khía cạnh khác nhau thông qua các thí nghiệm rộng rãi. Theo hiểu biết tốt nhất của chúng tôi, đây là công trình đầu tiên xem xét việc kết hợp thông tin phổ như một mô hình chung thực tế cho các tác vụ tinh chỉnh và cải thiện kết quả tinh chỉnh, hiệu quả tham số, cũng như có lợi cho việc kết hợp đa adapter của các phương pháp PEFT hiện có. Đối với công việc tương lai, việc tinh chỉnh biểu diễn phổ của các thành phần khác nhau, tức là chỉ lớp chú ý, của các mô hình lớn hiện tại cũng đáng được nghiên cứu. Các phương pháp PEFT khác như AdaLoRA [65] cũng có thể được kết hợp động với thích ứng phổ.

Một hạn chế của công trình hiện tại vẫn là việc lựa chọn tinh chỉnh không gian phổ hàng đầu. Mặc dù tính hợp lệ của nó đã được xác minh về lý thuyết dưới các thiết lập đơn giản, khảo sát thêm về việc tinh chỉnh các cột khác nhau của ma trận vector đơn vị là quan trọng để hiểu vai trò của thông tin phổ trong quy trình tinh chỉnh. Bên cạnh đó, việc tinh chỉnh biểu diễn phổ của các thành phần khác nhau, tức là chỉ lớp chú ý, của các mô hình lớn hiện tại cũng đáng được nghiên cứu. Hơn nữa, thời gian tiêu thụ của quy trình phân tích giá trị đơn vị tăng khi mô hình phát triển lớn hơn và do đó phương pháp phân tích giá trị đơn vị nhanh hơn cũng có lợi.

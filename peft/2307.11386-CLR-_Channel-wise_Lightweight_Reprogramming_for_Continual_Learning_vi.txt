# CLR: Lập trình lại nhẹ theo kênh cho học liên tục

Yunhao Ge1†, Yuecheng Li1∗, Shuo Ni1∗, Jiaping Zhao2Ming-Hsuan Yang2, Laurent Itti1†
1Đại học Nam California2Google Research
∗Đóng góp ngang nhau với tư cách tác giả thứ hai, †liên hệ với {yunhaoge, itti }@usc.edu

## Tóm tắt

Học liên tục nhằm mô phỏng khả năng của con người trong việc liên tục tích lũy kiến thức qua các nhiệm vụ tuần tự. Thách thức chính là duy trì hiệu suất trên các nhiệm vụ đã học trước đó sau khi học các nhiệm vụ mới, tức là tránh quên thảm khốc. Chúng tôi đề xuất phương pháp Lập trình lại nhẹ theo kênh (CLR) giúp mạng nơ-ron tích chập (CNN) vượt qua việc quên thảm khốc trong học liên tục. Chúng tôi chỉ ra rằng mô hình CNN được huấn luyện trên nhiệm vụ cũ (hoặc nhiệm vụ proxy tự giám sát) có thể được "lập trình lại" để giải quyết nhiệm vụ mới bằng cách sử dụng tham số lập trình lại nhẹ (rất rẻ) mà chúng tôi đề xuất. Với sự hỗ trợ của CLR, chúng tôi có cân bằng ổn định-tính dẻo tốt hơn để giải quyết các vấn đề học liên tục: Để duy trì ổn định và giữ lại khả năng nhiệm vụ trước đó, chúng tôi sử dụng phần bất biến không phụ thuộc nhiệm vụ chung làm bộ tham số "neo" được chia sẻ. Sau đó chúng tôi thêm các tham số lập trình lại nhẹ đặc thù nhiệm vụ để diễn giải lại đầu ra của các phần bất biến, cho phép tính dẻo và tích hợp kiến thức mới. Để học các nhiệm vụ tuần tự, chúng tôi chỉ huấn luyện các tham số lập trình lại nhẹ để học từng nhiệm vụ mới. Các tham số lập trình lại là đặc thù nhiệm vụ và độc quyền cho từng nhiệm vụ, điều này làm cho phương pháp của chúng tôi miễn nhiễm với quên thảm khốc. Để giảm thiểu yêu cầu tham số của lập trình lại để học nhiệm vụ mới, chúng tôi làm cho lập trình lại nhẹ bằng cách chỉ điều chỉnh các kernel thiết yếu và học ánh xạ tuyến tính theo kênh từ các tham số neo đến kiến thức miền đặc thù nhiệm vụ. Chúng tôi chỉ ra rằng, đối với CNN tổng quát, việc tăng tham số CLR ít hơn 0,6% cho bất kỳ nhiệm vụ mới nào. Phương pháp của chúng tôi vượt trội hơn 13 phương pháp học liên tục tiên tiến trên chuỗi thách thức mới gồm 53 bộ dữ liệu phân loại hình ảnh. Mã và dữ liệu có sẵn tại https://github.com/gyhandy/Channel-wise-Lightweight-Reprogramming.

## 1. Giới thiệu

Học liên tục (CL) tập trung vào vấn đề học từ luồng dữ liệu, nơi các tác nhân liên tục mở rộng kiến thức thu được bằng cách tuần tự học các nhiệm vụ hoặc kỹ năng mới, đồng thời tránh quên các nhiệm vụ trước đó [41]. Trong tài liệu, CL còn được gọi là học suốt đời [10, 2, 41] và học tuần tự [4]. Điều này khác với các phương pháp huấn luyện và triển khai tiêu chuẩn, không thể học tăng dần mà không có sự can thiệp thảm khốc giữa các nhiệm vụ [22]. Cách tránh quên thảm khốc là thách thức chính của học liên tục, đòi hỏi hiệu suất trên các nhiệm vụ đã học trước đó không được suy giảm đáng kể theo thời gian khi học các nhiệm vụ mới. Điều này cũng liên quan đến một vấn đề chung trong thiết kế mạng nơ-ron, cân bằng ổn định-tính dẻo [24], trong đó tính dẻo đại diện cho khả năng tích hợp kiến thức mới, và ổn định đề cập đến khả năng giữ lại kiến thức trước đó [13].

Các phương pháp Mạng động đã được chứng minh là một trong những phương pháp thành công nhất để giải quyết học liên tục, thường thể hiện tính ổn định tuyệt vời trên các nhiệm vụ trước đó và giảm thiểu ảnh hưởng của quên thảm khốc bằng cách sửa đổi mạng một cách động để giải quyết các nhiệm vụ mới, thường thông qua mở rộng mạng [41, 57, 12, 58]. Về tính ổn định, một phương pháp mong muốn sẽ là cố định xương sống và học các tham số đặc thù nhiệm vụ bổ sung trên đó, điều này sẽ không có quên thảm khốc. Tuy nhiên, số lượng tham số trong các phương pháp như vậy có thể nhanh chóng trở nên rất lớn. Cách giảm lượng tham số bổ sung cần thiết vẫn là một vấn đề thách thức. Để giải quyết các vấn đề trên, phương pháp của chúng tôi dựa trên ba động lực:

(1) Tái sử dụng thay vì học lại. Lập trình lại đối kháng [16] là một phương pháp để "lập trình lại" một mạng đã được huấn luyện và đóng băng từ nhiệm vụ ban đầu để giải quyết các nhiệm vụ mới bằng cách nhiễu không gian đầu vào mà không học lại các tham số mạng. Nó tính toán một mẫu nhiễu duy nhất cho mỗi nhiệm vụ mới. Mẫu này sau đó được thêm vào đầu vào cho nhiệm vụ mới và đưa qua mạng ban đầu. Mạng ban đầu xử lý đầu vào kết hợp + nhiễu và tạo ra đầu ra, sau đó được ánh xạ lại vào miền đầu ra nhiệm vụ mới mong muốn. Ví dụ, một mẫu có thể được tính toán để lập trình lại mạng ban đầu được huấn luyện trên ImageNet [47] để giải quyết MNIST [14]. Cùng một mẫu, khi được thêm vào hình ảnh của một chữ số MNIST, sẽ kích hoạt các đầu ra khác nhau từ mạng được huấn luyện ImageNet cho các lớp MNIST khác nhau (ví dụ, chữ số 0 + mẫu có thể cho ra "voi"; chữ số 1 + mẫu "hươu cao cổ", v.v.). Các đầu ra này sau đó có thể được diễn giải lại theo nhiệm vụ mới (voi có nghĩa là chữ số 0, v.v.). Mặc dù chi phí tính toán cao một cách cấm đoán so với các phương pháp học suốt đời cơ sở, ở đây chúng tôi mượn ý tưởng lập trình lại; nhưng chúng tôi tiến hành lập trình lại nhẹ hơn nhưng cũng mạnh mẽ hơn trong không gian tham số của mô hình ban đầu, thay vì trong không gian đầu vào.

(2) Các biến đổi theo kênh có thể liên kết hai kernel khác nhau. GhostNet [25] có thể tạo ra nhiều bản đồ đặc trưng hơn từ các phép toán rẻ được áp dụng cho các bản đồ đặc trưng hiện có, từ đó cho phép các thiết bị nhúng với bộ nhớ nhỏ chạy hiệu quả các mạng lớn hơn. Phương pháp này được thúc đẩy bởi sự dư thừa gần trong các mạng tiêu chuẩn: sau khi huấn luyện, một số đặc trưng đã học khá tương tự. Do đó, Han et al.[25] tạo ra một số đặc trưng như các biến đổi tuyến tính của các đặc trưng khác. Lấy cảm hứng từ điều này, phương pháp của chúng tôi tăng cường mạng với các bản đồ đặc trưng mới, được biến đổi tuyến tính, có thể được điều chỉnh một cách rẻ tiền cho các nhiệm vụ mới riêng lẻ.

(3) Các tham số nhẹ có thể thay đổi phân phối mô hình. BPN [57] thêm các thiên lệch nhiễu có lợi trong các lớp kết nối đầy đủ để thay đổi phân phối tham số mạng từ nhiệm vụ này sang nhiệm vụ khác, điều này hữu ích để giải quyết học liên tục. Điều này rẻ hơn so với tinh chỉnh tất cả các trọng số trong mạng cho mỗi nhiệm vụ, thay vào đó chỉ điều chỉnh một thiên lệch cho mỗi nơ-ron. Tuy nhiên, phương pháp này chỉ có thể xử lý các lớp kết nối đầy đủ và hiệu suất bị giới hạn bởi khả năng hạn chế của các tham số thiên lệch để thay đổi mạng (chỉ 1 thiên lệch vô hướng cho mỗi nơ-ron). Phương pháp của chúng tôi thay vào đó thiết kế các mẫu lập trình lại mạnh mẽ hơn (kernel) cho các lớp CNN, có thể dẫn đến hiệu suất tốt hơn trên mỗi nhiệm vụ mới.

Rút ra từ ba ý tưởng này, chúng tôi đề xuất lập trình lại nhẹ theo kênh (CLR). Chúng tôi bắt đầu với các tham số bất biến không phụ thuộc nhiệm vụ của mô hình CNN được huấn luyện trước trên một bộ dữ liệu tương đối đa dạng (ví dụ, ImageNet-1k, Pascal VOC, ...) nếu có thể, hoặc trên nhiệm vụ proxy tự giám sát, không yêu cầu nhãn ngữ nghĩa. Sau đó chúng tôi "lập trình lại" một cách thích ứng các lớp CNN bất biến không phụ thuộc nhiệm vụ để thích ứng và giải quyết các nhiệm vụ mới bằng cách thêm biến đổi tuyến tính nhẹ theo kênh trên mỗi kênh của một tập con được chọn của các lớp Tích chập (Hình 2). Các tham số lập trình lại được thêm là các kernel tích chập 2D 3x3, mỗi cái hoạt động trên các kênh riêng biệt của bản đồ đặc trưng sau lớp tích chập ban đầu. CLR rất rẻ nhưng vẫn mạnh mẽ, với trực giác rằng các bộ lọc kernel khác nhau có thể được lập trình lại với biến đổi tuyến tính phụ thuộc nhiệm vụ.

Các đóng góp chính của công trình này là:
• Chúng tôi đề xuất một giải pháp học liên tục mới cho CNN, bao gồm lập trình lại các lớp CNN được huấn luyện trên các nhiệm vụ cũ để giải quyết các nhiệm vụ mới bằng cách thêm các tham số lập trình lại nhẹ đặc thù nhiệm vụ. Điều này cho phép một mạng đơn học các ánh xạ đầu vào-đầu ra tiềm năng không giới hạn, và chuyển đổi giữa chúng ngay lập tức trong thời gian chạy.
• Phương pháp của chúng tôi đạt được cân bằng ổn định-tính dẻo tốt hơn so với các phương pháp học liên tục mạng động khác: nó không gặp phải vấn đề quên thảm khốc và yêu cầu tham số bổ sung hạn chế trong học liên tục, ít hơn 0,6% kích thước tham số ban đầu cho mỗi nhiệm vụ mới.
• Phương pháp của chúng tôi đạt hiệu suất tiên tiến trên học liên tục tăng dần nhiệm vụ trên chuỗi thách thức mới gồm 53 bộ dữ liệu phân loại hình ảnh.

## 2. Công trình liên quan

Học liên tục. Các phương pháp học liên tục có thể được phân loại rộng rãi thành ba cách tiếp cận [13]: Dựa trên phát lại, Dựa trên chính quy hóa, và Dựa trên mạng động.

(1) Các phương pháp phát lại sử dụng một bộ đệm chứa dữ liệu huấn luyện được lấy mẫu từ các nhiệm vụ trước đó, như một phụ trợ cho tập huấn luyện của nhiệm vụ mới. Bộ đệm có thể được sử dụng hoặc ở cuối quá trình huấn luyện nhiệm vụ (iCaRL [44], ER [45]) hoặc trong quá trình huấn luyện (GSS, AGEM, AGEM-R, DER, DERPP [38, 3, 10, 7]). Các sơ đồ tái diễn [44, 46, 28, 11] huấn luyện lại một cách rõ ràng trên một tập con hạn chế các mẫu được lưu trữ trong khi huấn luyện trên các nhiệm vụ mới. [38, 10] sử dụng tối ưu hóa ràng buộc như một giải pháp thay thế để lại nhiều dư địa hơn cho chuyển giao ngược/tiến. Các phương pháp tái diễn giả sử dụng đầu ra của mô hình trước đó [45] hoặc sử dụng tạo ra các mẫu giả với mô hình tạo được lưu [52]. Các phương pháp tái diễn có nhược điểm là (1) chúng yêu cầu bộ đệm bổ sung để lưu mẫu (liên quan đến độ khó của bộ dữ liệu), (2) chúng dễ dàng quá khớp với tập con mẫu được lưu trữ trong quá trình phát lại. (3) hiệu suất dường như bị giới hạn bởi huấn luyện chung, bị ảnh hưởng bởi số lượng nhiệm vụ.

(2) Các phương pháp chính quy hóa thêm một thuật ngữ mất mát phụ trợ vào mục tiêu nhiệm vụ chính để ràng buộc cập nhật trọng số. Các phương pháp tập trung vào dữ liệu (LwF[36], LFL[31], DMC [61]) sử dụng chưng cất kiến thức từ các mô hình trước đó được huấn luyện trên các nhiệm vụ cũ để ràng buộc mô hình đang được huấn luyện trên các nhiệm vụ mới. Các phương pháp dựa trên tiên nghiệm (EWC [32], IMM [35], SI [60], MAS [1]) ước tính tầm quan trọng của các tham số mạng đối với các nhiệm vụ đã học trước đó, và phạt việc thay đổi các tham số quan trọng trong khi huấn luyện các nhiệm vụ mới. Nhược điểm của các phương pháp này là tính toán đắt đỏ của ước tính tầm quan trọng và tính không tối ưu trên các nhiệm vụ mới, đặc biệt với số lượng lớn nhiệm vụ.

(3) Các phương pháp mạng động sửa đổi mạng một cách động để giải quyết các nhiệm vụ mới, thường thông qua mở rộng mạng. Khi không có ràng buộc nào áp dụng cho kích thước kiến trúc, người ta có thể phát triển các nhánh mới cho các nhiệm vụ mới, trong khi đóng băng các tham số nhiệm vụ trước đó [48, 59], hoặc dành một bản sao mô hình cho mỗi nhiệm vụ [2]. Để tiết kiệm bộ nhớ, các phương pháp gần đây giữ kiến trúc không đổi, với các phần cố định được phân bổ cho mỗi nhiệm vụ. Các phần nhiệm vụ trước đó bị che khuất trong quá trình huấn luyện nhiệm vụ mới, hoặc được áp đặt ở cấp độ tham số [19, 39], hoặc cấp độ đơn vị [51]. SUPSUP [58]), PSP [12] gán một tập cố định các tham số mô hình cho một nhiệm vụ và tránh ghi đè chúng khi các nhiệm vụ mới được học. Các phương pháp mạng động đã được chứng minh là một trong những phương pháp thành công nhất trong việc giải quyết học liên tục. Về tính ổn định, một phương pháp mong muốn sẽ là cố định xương sống và học các tham số đặc thù nhiệm vụ bổ sung trên đó, điều này sẽ không có quên thảm khốc. SUPSUP [58] sử dụng xương sống cố định được khởi tạo ngẫu nhiên và học một siêu mặt nạ đặc thù nhiệm vụ cho mỗi nhiệm vụ mới, trong khi hiệu suất bị giới hạn bởi khả năng của xương sống cố định. CCLL [53], và EFTs [55] sử dụng xương sống cố định được huấn luyện trên nhiệm vụ đầu tiên, và học các tham số tích chập nhóm đặc thù nhiệm vụ. Hiệu suất nhạy cảm với nhiệm vụ đầu tiên, và siêu tham số tích chập nhóm bổ sung không đơn giản để huấn luyện.

Phương pháp lập trình lại nhẹ theo kênh của chúng tôi cũng thuộc về các phương pháp học liên tục mạng động. Lấy cảm hứng từ mạng ma, BPN, và lập trình lại đối kháng, chúng tôi lập trình lại các tham số bất biến không phụ thuộc nhiệm vụ và áp dụng các tham số bổ sung nhẹ (tính toán và bộ nhớ rẻ) để học các nhiệm vụ mới.

Meta learning. Meta learning nhằm cải thiện chính thuật toán học, dựa trên kinh nghiệm của nhiều tập huấn luyện [27]. Ngược lại, ML thông thường cải thiện dự đoán mô hình qua nhiều thể hiện dữ liệu. Trong quá trình meta-learning, một thuật toán bên ngoài (hoặc trên/meta) cập nhật và cải thiện thuật toán học bên trong (ví dụ, một nhiệm vụ phân loại hình ảnh). Ví dụ, mục tiêu bên ngoài có thể là hiệu suất tổng quát hóa hoặc tốc độ học của thuật toán bên trong. Meta-learning có sự khác biệt chính sau đây với CL: tương tự như học chuyển giao, Meta-learning tập trung vào việc tìm ra chiến lược học hoặc khởi tạo tốt hơn, và quan tâm đến hiệu suất trên một nhiệm vụ mới hoặc tổng quát hóa, trong khi hiệu suất trên các nhiệm vụ trước đó không phải là mối quan tâm. Do đó, meta-learning có thể được sử dụng như một bước sơ bộ trong CLR, để tối ưu hóa tham số ban đầu được chia sẻ θ trong CLR. Meta-learning có thể học từ một nhiệm vụ đơn trong nhiều miền [54, 20] hoặc các nhiệm vụ khác nhau [21, 37, 5], yêu cầu truy cập vào một số dữ liệu từ tất cả các nhiệm vụ hoặc miền cơ sở cùng một lúc, trong khi phương pháp và CL của chúng tôi giả định học tuần tự và không thể truy cập dữ liệu từ các nhiệm vụ trước đó. Ngoài ra, meta-learning giả định cài đặt chung đã học sẽ được sử dụng trong các nhiệm vụ tương tự như các nhiệm vụ cơ sở, trong khi CL không giả định rằng các nhiệm vụ trước đó tương tự với các nhiệm vụ tương lai.

## 3. Phương pháp đề xuất

Cài đặt vấn đề. Trong bài báo này, chúng tôi tập trung vào cài đặt tăng dần nhiệm vụ của học liên tục, nơi dữ liệu đến tuần tự theo lô, và một lô tương ứng với một nhiệm vụ, chẳng hạn như một tập lớp mới hoặc một bộ dữ liệu mới cần học. Đối với một thuật toán học liên tục nhất định, mục tiêu là đạt được hiệu suất trung bình cao trên tất cả các nhiệm vụ đã học trước đó sau khi học nhiệm vụ cuối cùng. Trong thời gian thử nghiệm, giống như PSP [12], CCLL[53], EFTs[55], EWC [32], ER[45], v.v., chúng tôi giả định rằng một oracle nhiệm vụ được cung cấp trong quá trình suy luận, cho biết mẫu cho trước thuộc về nhiệm vụ nào.

Cấu trúc. Đầu tiên chúng tôi giới thiệu cách các tham số Lập trình lại nhẹ theo kênh đề xuất của chúng tôi lập trình lại xương sống bất biến không phụ thuộc nhiệm vụ bằng cách tiến hành biến đổi tuyến tính theo kênh sau lớp tích chập ban đầu để thay đổi khối Conv ban đầu thành khối CLR-Conv, và sau đó phát triển một mạng lập trình lại CLR mới để giải quyết nhiệm vụ mới. (Mục 3.1). Sau đó, chúng tôi giới thiệu cách các mạng lập trình lại CLR có thể được sử dụng để giải quyết các nhiệm vụ học liên tục (Mục 3.2).

### 3.1. Lập trình lại nhẹ theo kênh

Phương pháp Lập trình lại nhẹ theo kênh đề xuất của chúng tôi được trang bị xương sống bất biến không phụ thuộc nhiệm vụ và tạo ra các tham số lập trình lại nhẹ đặc thư nhiệm vụ để giải quyết các nhiệm vụ mới. Ở đây, chúng tôi sử dụng xương sống cố định làm cấu trúc bất biến được chia sẻ nhiệm vụ. Điều này khác với SUPSUP [58], sử dụng xương sống cố định được khởi tạo ngẫu nhiên, và CCLL [53], EFTs [55], sử dụng xương sống cố định được huấn luyện trên nhiệm vụ đầu tiên. Chúng tôi sử dụng cách tổng quát và tương thích hơn với yêu cầu ít hơn để có được xương sống: xương sống cố định có thể được huấn luyện trước với học có giám sát trên bộ dữ liệu tương đối đa dạng (ví dụ, trên ImageNet-1k [47], hoặc Pascal VOC [18]), hoặc với học tự giám sát trên các nhiệm vụ proxy, chẳng hạn như DINO [9] và SwAV [8], không yêu cầu nhãn ngữ nghĩa – chúng tôi sẽ thấy rằng phương pháp của chúng tôi mạnh mẽ với sự lựa chọn bộ dữ liệu huấn luyện trước trong các thí nghiệm Mục 4.5). Xương sống cố định này có thể cung cấp một tập đa dạng các đặc trưng thị giác. Tuy nhiên, những điều đó cần được lập trình lại sau cho các nhiệm vụ riêng lẻ, điều này được đạt được bởi các lớp CLR của chúng tôi.

Cụ thể, chúng tôi sử dụng biến đổi tuyến tính theo kênh để lập trình lại bản đồ đặc trưng được tạo ra bởi một kernel tích chập ban đầu, để tạo ra một bản đồ đặc trưng đặc thù nhiệm vụ mới cho nhiệm vụ mới.

Hình 2 cho thấy cấu trúc của CLR được đề xuất. CLR tương thích với bất kỳ mạng nơ-ron tích chập (CNN) nào. Một CNN thường bao gồm một số khối Conv (ví dụ, khối Residual) (Hình 2 trên), chứa một lớp tích chập (conv), lớp chuẩn hóa (ví dụ, chuẩn hóa lô), và lớp kích hoạt (ví dụ, relu). Phương pháp của chúng tôi coi một CNN được huấn luyện trước như một xương sống tham số bất biến tổng quát và không phụ thuộc nhiệm vụ cho tất cả các nhiệm vụ tương lai, vì vậy chúng tôi cố định các tham số của nó. (Chi tiết thêm về việc lựa chọn xương sống huấn luyện trước trong các thí nghiệm Mục 4.5). Để lập trình lại CNN để giải quyết một nhiệm vụ mới trong học liên tục, chúng tôi thêm các tham số có thể huấn luyện nhẹ bằng cách thay đổi mỗi khối Conv ban đầu thành một khối CLR-Conv, từ đó tạo ra một CNN lập trình lại CLR (Hình 2 trên). Cụ thể, như được hiển thị trong Hình 2 (trên), một khối CLR-Conv được thu được bằng cách thêm một lớp lập trình lại nhẹ theo kênh (lớp CLR) sau mỗi lớp conv cố định ban đầu. (Để tiết kiệm tham số và ngăn chặn quá khớp, các lớp conv 1×1 bị loại trừ.) Mỗi lớp CLR tiến hành các biến đổi tuyến tính trên mỗi kênh của bản đồ đặc trưng ban đầu sau lớp conv cố định để lập trình lại các đặc trưng. Ở đây, biến đổi tuyến tính được biểu diễn bằng các kernel tích chập 2D 3x3 được tiến hành trên bản đồ đặc trưng kênh đơn. Hình 2 (dưới) minh họa chi tiết của biến đổi tuyến tính theo kênh để lập trình lại. Đối với mỗi kernel tích chập fk(), với đầu vào đặc trưng X, chúng ta thu được một kênh đặc trưng x'k = fk(X) sau quá trình, tất cả các đặc trưng theo kênh tạo thành bản đồ đặc trưng đầu ra X'. Biến đổi tuyến tính lập trình lại theo kênh của chúng tôi được áp dụng trên mỗi kênh x'k của bản đồ đặc trưng đầu ra X'. Đối với mỗi kernel fk(), chúng ta có một kernel lập trình lại 3x3 2D tương ứng CLRk, nhận đầu ra kênh đơn x'k làm đầu vào và tiến hành biến đổi tuyến tính để thu được đặc trưng lập trình lại x̂'k:

x̂'k = CLRk(x'k) = CLRk(fk(X)) (1)

Thuật toán 1 hiển thị mã giả của các đặc trưng trước và sau lớp CLR. Chúng tôi khởi tạo lớp CLR như một kernel biến đổi đồng nhất (ví dụ, trong kernel 3x3 2D, tham số trung tâm là một và tất cả các tham số khác là không). Cài đặt này rất quan trọng cho hiệu quả huấn luyện và hiệu suất, vì nó ưa chuộng việc giữ các bộ trích xuất đặc trưng chung trong mô hình cố định ban đầu, đồng thời cho phép đạt được lập trình lại thích ứng, dựa trên hàm mất mát cho nhiệm vụ mới.

Đối với CNN lập trình lại CLR, các lớp conv ban đầu trong xương sống được cố định, các tham số có thể huấn luyện bao gồm lớp CLR sau mỗi lớp conv cố định (lớp chuẩn hóa là tùy chọn để huấn luyện), và lớp kết nối đầy đủ cuối cùng. Đối với Resnet-50 lập trình lại CLR [26], lớp CLR có thể huấn luyện chỉ chiếm 0,59% tham số của xương sống Resnet-50 cố định ban đầu. Tính chất tham số hiệu quả này làm cho các mạng lập trình lại CLR dễ dàng triển khai cho các nhiệm vụ liên tục.

### 3.2. CLR cho học liên tục

Trong học liên tục tăng dần nhiệm vụ, mô hình đối mặt với một chuỗi các nhiệm vụ. Như được hiển thị trong Hình 3(a), trong quá trình học liên tục, một mô hình lập trình lại CLR học từng nhiệm vụ một lúc, và tất cả các nhiệm vụ chia sẻ cùng xương sống cố định được huấn luyện trước. Mỗi nhiệm vụ có một tập tham số CLR đặc thù nhiệm vụ có thể huấn luyện bao gồm các lớp CLR sau mỗi lớp conv ban đầu và lớp tuyến tính cuối cùng. Trong quá trình thử nghiệm (Hình 3(b)), chúng tôi giả định một oracle nhiệm vụ hoàn hảo (như giả định bởi các phương pháp cơ sở của chúng tôi được hiển thị trong phần tiếp theo) cho biết mô hình hình ảnh thử nghiệm thuộc về nhiệm vụ nào. Xương sống cố định được trang bị với tham số CLR đặc thù nhiệm vụ tương ứng đưa ra quyết định cuối cùng.

Do sự cô lập tham số tuyệt đối trong CLR (tức là, các lớp CLR hoàn toàn đặc thù và riêng biệt cho mỗi nhiệm vụ, và xương sống được chia sẻ không bị thay đổi chút nào), hiệu suất phương pháp của chúng tôi trên mỗi nhiệm vụ không bị ảnh hưởng bởi việc tăng số lượng nhiệm vụ (tương tự như SUPSUP [58], CCLL [53], và EFT [55]). Về lý thuyết, mô hình lập trình lại CLR có thể học nhiều nhiệm vụ theo nhu cầu trong cài đặt học liên tục và giữ hiệu suất tối ưu trên mỗi nhiệm vụ mà không giảm độ chính xác khi số lượng nhiệm vụ tăng, nhưng với việc tăng 0,59% tham số cho mỗi nhiệm vụ mới.

## 4. Thí nghiệm và kết quả

Trong phần này, chúng tôi so sánh mô hình lập trình lại CLR của chúng tôi với các phương pháp cơ sở trên bộ dữ liệu thách thức 53 dataset với độ biến thiên lớn (Mục 4.1). Chúng tôi đánh giá sự dao động độ chính xác nhiệm vụ sau khi học các nhiệm vụ mới để đánh giá việc quên (Mục 10). Sau đó, chúng tôi đánh giá độ chính xác trung bình trên tất cả các nhiệm vụ đã học cho đến nay trong quá trình học liên tục (Mục 4.3). Chúng tôi phân tích các tham số mạng và chi phí tính toán trong quá trình học liên tục (Mục 4.4). Chúng tôi tiến hành nghiên cứu ablation để phân tích ảnh hưởng của các xương sống bất biến khác nhau (Mục 4.5)

### 4.1. Bộ dữ liệu và phương pháp cơ sở:

Bộ dữ liệu. Chúng tôi sử dụng phân loại hình ảnh làm khung nhiệm vụ cơ bản. Chúng tôi mở rộng benchmark 8-dataset thông thường [1, 2] thành 53-datasets thách thức hơn bằng cách thu thập các nhiệm vụ phân loại thách thức hơn. 53-datasets bao gồm 53 bộ dữ liệu phân loại hình ảnh. Mỗi bộ hỗ trợ một nhiệm vụ phân loại phức tạp, và bộ dữ liệu tương ứng được thu thập từ các nguồn đã được xuất bản trước đây, ví dụ, nhiệm vụ 1 [42]: phân loại cảnh thành 67 lớp, chẳng hạn như nhà bếp, phòng ngủ, trạm xăng, v.v. (bộ dữ liệu cảnh với 15,523 hình ảnh); nhiệm vụ 2 [56]: phân loại 200 loại chim, chẳng hạn như Brewer Blackbird, Cardinal, Chuck will Widow, v.v. (bộ dữ liệu chim với 11,787 hình ảnh). Danh sách đầy đủ và chi tiết thêm về mỗi bộ dữ liệu có trong tài liệu bổ sung. 53-datasets là một tập con của benchmark Học suốt đời SKILL-102 [23]1, chi tiết thêm về việc tạo bộ dữ liệu và phiên bản mở rộng (107 nhiệm vụ) có trong USC-DCT (Diverse Classification Tasks), một nỗ lực rộng lớn hơn trong phòng thí nghiệm của chúng tôi. DCT có thể được sử dụng cho nhiều mục đích thị giác máy, không giới hạn ở học suốt đời.

Chúng tôi sử dụng 53 bộ dữ liệu với >1,8M hình ảnh từ 1,584 lớp qua 53 nhiệm vụ cho các thí nghiệm. Bảng 1 hiển thị chi tiết của 53-dataset của chúng tôi so với các bộ dữ liệu benchmark khác. Cụ thể, chúng tôi so sánh số lượng mục tiêu phân loại khác nhau giữa các benchmark khác nhau, điều này đại diện cho sự đa dạng và khác biệt giữa các nhiệm vụ liên tục khác nhau. Ví dụ, 53-dataset của chúng tôi chứa 5 mục tiêu phân loại khác nhau: nhận dạng đối tượng, phân loại phong cách (ví dụ, phong cách hội họa), phân loại cảnh, đếm số (ví dụ, bộ dữ liệu CLEVR [30]), và chẩn đoán y tế (ví dụ, Bộ dữ liệu siêu âm vú). Cho đến nay, 53-dataset của chúng tôi là một trong những benchmark phân loại hình ảnh thách thức nhất cho các thuật toán học liên tục, với số lượng lớn nhiệm vụ và độ biến thiên giữa các nhiệm vụ.

Đối với các thí nghiệm dưới đây, chúng tôi lấy mẫu con bộ dữ liệu để cho phép một số phương pháp cơ sở tuần tự hội tụ: chúng tôi giới hạn số lượng lớp/nhiệm vụ ở 300 (chỉ ảnh hưởng đến 1 nhiệm vụ), và sử dụng khoảng 5,120 hình ảnh huấn luyện cho các nhiệm vụ với c≥60 lớp, hoặc khoảng 2,560 cho các nhiệm vụ với c <60, trong đó c đại diện cho số lượng lớp. Do đó, chúng tôi sử dụng 53 nhiệm vụ, tổng cộng 1,583 lớp, tổng cộng 132,625 hình ảnh huấn luyện và 13,863 hình ảnh thử nghiệm. Chúng tôi cũng tiến hành thí nghiệm trên bộ dữ liệu CIFAR-100 (Phụ lục Hình.12).

Phương pháp cơ sở. Như đã thảo luận trong Mục 1, chúng tôi cấp cho mỗi phương pháp cơ sở một oracle nhiệm vụ hoàn hảo trong quá trình suy luận. Chúng tôi thực hiện 13 phương pháp cơ sở, có thể được phân loại thô vào 3 loại sau đây [13]:

(1) Các phương pháp Mạng động chứa hầu hết các phương pháp cơ sở vì phương pháp của chúng tôi cũng thuộc về nó: chúng sửa đổi mạng một cách động để giải quyết các nhiệm vụ mới, thường thông qua mở rộng mạng. Chúng tôi sử dụng PSP [12], Supermask in Superposition (SUPSUP) [58], CCLL[53], Confit[29], và EFTs[55] làm các phương pháp đại diện của loại này: Đối với PSP, mô hình học tất cả 53 nhiệm vụ theo thứ tự, tạo ra một khóa PSP mới cho mỗi nhiệm vụ. Các khóa giúp phân tách các nhiệm vụ trong mạng nhằm cố gắng giảm thiểu sự can thiệp. Đối với SUPSUP, mô hình sử dụng một tham số được khởi tạo ngẫu nhiên làm xương sống cố định và học các siêu mặt nạ đặc thù lớp cho mỗi nhiệm vụ, giúp giảm thiểu quên thảm khốc. Trong quá trình suy luận, các nhiệm vụ khác nhau sử dụng các siêu mặt nạ khác nhau để đưa ra quyết định.

(2) Các phương pháp chính quy hóa thêm một thuật ngữ mất mát phụ trợ vào mục tiêu nhiệm vụ chính để ràng buộc cập nhật trọng số. Mất mát bổ sung có thể là một hình phạt trên các tham số (EWC [32], LwF[36], MAS [1] và SI [60]) hoặc trên không gian đặc trưng (FDR [6]), chẳng hạn như sử dụng chưng cất kiến thức (DMC [61]). Chúng tôi sử dụng EWC, online-EWC, SI, LwF làm đại diện của loại này: đối với EWC, một tác nhân học tất cả 53 nhiệm vụ theo thứ tự, sử dụng máy móc EWC để ràng buộc các trọng số khi một nhiệm vụ mới được học, để cố gắng không phá hủy hiệu suất trên các nhiệm vụ đã học trước đó.

(3) Các phương pháp phát lại sử dụng một bộ đệm chứa dữ liệu huấn luyện được lấy mẫu từ các nhiệm vụ trước đó, như một phụ trợ cho tập huấn luyện của nhiệm vụ mới. Bộ đệm có thể được sử dụng hoặc ở cuối quá trình huấn luyện nhiệm vụ (iCaRL, ER [44, 45]) hoặc trong quá trình huấn luyện (GSS, AGEM, AGEM-R, DER, DERPP [38, 10, 3, 7]). Chúng tôi sử dụng Episodic Memory Rehearsal (ER) làm phương pháp cơ sở đại diện của loại này: Một tác nhân học tất cả 53 nhiệm vụ theo thứ tự. Sau khi học mỗi nhiệm vụ, nó thêm 10 hình ảnh/lớp của nhiệm vụ đó vào bộ đệm phát lại đang phát triển sẽ được sử dụng sau để tái diễn các nhiệm vụ cũ. Khi học một nhiệm vụ mới, tác nhân học từ tất cả dữ liệu cho nhiệm vụ đó, cộng với tái diễn tất cả các nhiệm vụ cũ sử dụng bộ đệm bộ nhớ. Ngoài ra, SGD là một phương pháp cơ sở ngây thơ chỉ tinh chỉnh toàn bộ mạng cho mỗi nhiệm vụ, không có nỗ lực gì để giảm thiểu sự can thiệp. SGD-LL là một biến thể sử dụng xương sống cố định cộng với một lớp cuối có thể học được chia sẻ duy nhất cho tất cả các nhiệm vụ với độ dài bằng nhiệm vụ có số lượng lớp lớn nhất (500 lớp trong cài đặt của chúng tôi). SGD sử dụng gradient descent ngẫu nhiên tiêu chuẩn như tối ưu hóa, có thể gặp phải vấn đề quên thảm khốc.

Để so sánh công bằng, tất cả 13 phương pháp cơ sở sử dụng xương sống ResNet-50 [26] được huấn luyện trước ImageNet, ngoại trừ PSP, Confit (yêu cầu ResNet-18) và SUPSUP (yêu cầu xương sống ResNet-50 được khởi tạo ngẫu nhiên).

### 4.2. Độ chính xác trên các nhiệm vụ đầu tiên

Để đánh giá hiệu suất của tất cả các phương pháp trong việc vượt qua quên thảm khốc, chúng tôi theo dõi độ chính xác trên mỗi nhiệm vụ sau khi học các nhiệm vụ mới. Nếu phương pháp gặp phải quên thảm khốc, thì độ chính xác của cùng một nhiệm vụ sẽ giảm sau khi học các nhiệm vụ mới. Một thuật toán học liên tục tuyệt vời được kỳ vọng duy trì độ chính xác của hiệu suất học ban đầu sau khi học các nhiệm vụ mới, có nghĩa là các nhiệm vụ cũ nên bị ảnh hưởng tối thiểu bởi việc tăng số lượng nhiệm vụ mới. Hình 4 hiển thị độ chính xác trên nhiệm vụ thứ nhất và thứ hai khi chúng tôi học từ 1 đến 53 nhiệm vụ sử dụng 53-datasets, để đánh giá lượng quên trên các nhiệm vụ sớm khi nhiều nhiệm vụ hơn được học. Nhìn chung, mô hình lập trình lại CLR của chúng tôi duy trì độ chính xác cao nhất trên các nhiệm vụ sớm này theo thời gian, và quan trọng là, phương pháp của chúng tôi (tương tự như CCLL [53], EFT [55] và SUPSUP [58]) tránh quên và duy trì cùng độ chính xác như huấn luyện ban đầu, bất kể có bao nhiêu nhiệm vụ mới được học. SUPSUP không thể, ngay từ đầu, học nhiệm vụ 1 tốt như các phương pháp khác. Chúng tôi cho rằng điều này do tính biểu đạt hạn chế và khả năng học của SUPSUP sử dụng mặt nạ trên xương sống ngẫu nhiên, đặc biệt là cho các nhiệm vụ có nhiều lớp. Thật vậy, SUPSUP có thể hoạt động rất tốt trên một số nhiệm vụ khác, thường với số lượng lớp nhỏ hơn (ví dụ, SVHN, UMNIST Face Dataset). Các phương pháp cơ sở gặp phải mức độ quên khác nhau: EWC [51], PSP [12], ER [45], SI [60], và LwF [36] gặp phải quên thảm khốc nghiêm trọng trong bộ dữ liệu thách thức. Chúng tôi nhận thấy hiệu suất tương tự trên nhiệm vụ thứ hai.

### 4.3. Độ chính xác trung bình sau khi học tất cả 53 nhiệm vụ

Chúng tôi tính toán độ chính xác trung bình trên tất cả các nhiệm vụ đã học cho đến nay sau khi học 1, 2, 3, ... 53 nhiệm vụ. Chúng tôi vẽ biểu đồ độ chính xác trung bình trên tất cả các nhiệm vụ đã học cho đến nay, như một hàm của số lượng nhiệm vụ đã học trong Hình 5. Lưu ý rằng mức độ khó khăn cho mỗi trong 53 nhiệm vụ khá biến đổi, như được hiển thị trong Hình 6. Do đó, độ chính xác trung bình trên tất cả các nhiệm vụ cho đến nay có thể tăng hoặc giảm khi một nhiệm vụ mới được thêm vào, tùy thuộc vào việc một nhiệm vụ dễ hơn hay khó hơn được thêm vào. Độ chính xác trung bình đại diện cho hiệu suất tổng thể của một phương pháp học liên tục trong việc học và sau đó thực hiện các nhiệm vụ tuần tự. Nhìn chung mô hình lập trình lại CLR của chúng tôi đạt được độ chính xác trung bình tốt nhất so với tất cả các phương pháp cơ sở. Đối với các phương pháp dựa trên phát lại, hiệu suất tổng thể thấp hơn chúng tôi mặc dù chúng có bộ đệm lớn, và thời gian huấn luyện tăng cho các phương pháp này với việc tăng số lượng nhiệm vụ. EWC, PSP, LWF, SI gặp phải quên thảm khốc nghiêm trọng trong 53-datasets thách thức.

Để hiển thị chi tiết hơn, chúng tôi vẽ biểu đồ độ chính xác của mỗi nhiệm vụ sau khi học tất cả 53 nhiệm vụ với phương pháp CNN lập trình lại CLR của chúng tôi trong Hình 6. Điều này cho thấy rằng 53-dataset cung cấp một phạm vi mức độ khó khăn cho các nhiệm vụ khác nhau, và khá khó nhìn chung.

### 4.4. Chi phí tham số và tính toán

Đạt được độ chính xác trung bình tổng thể cao hơn trong quá trình học các nhiệm vụ tuần tự rất quan trọng. Một thuật toán học liên tục tuyệt vời cũng được kỳ vọng giảm thiểu yêu cầu của các tham số mạng bổ sung, và chi phí tính toán. Bảng 2 hiển thị tham số bổ sung cần thiết và chi phí tính toán cho phương pháp của chúng tôi và các phương pháp cơ sở. "Tham số bổ sung để thêm một nhiệm vụ mới" đại diện cho tỷ lệ phần trăm so với kích thước xương sống ban đầu (ví dụ, ResNet-50). Ví dụ, EWC không cần tham số bổ sung, trong khi chi phí tính toán của nó tương đối cao (để tính toán ma trận thông tin Fisher sẽ hướng dẫn việc ràng buộc các tham số trong khi học một nhiệm vụ mới), và độ chính xác không phải là tốt nhất. Phương pháp CLR của chúng tôi yêu cầu chỉ 0,59% tham số bổ sung để học mỗi nhiệm vụ mới, và việc tăng chi phí tính toán nhỏ so với SGD cơ sở (huấn luyện bình thường). Quan trọng là, phương pháp của chúng tôi đạt được độ chính xác trung bình tốt nhất.

### 4.5. Ảnh hưởng của các xương sống bất biến khác nhau

Phương pháp của chúng tôi thu được các tham số bất biến không phụ thuộc nhiệm vụ bằng cách huấn luyện mô hình CNN trên một bộ dữ liệu tương đối đa dạng với học có giám sát hoặc các nhiệm vụ proxy với học tự giám sát. Để điều tra ảnh hưởng của các phương pháp huấn luyện trước khác nhau trên hiệu suất của học liên tục, chúng tôi chọn bốn loại tham số bất biến không phụ thuộc nhiệm vụ khác nhau được huấn luyện với các bộ dữ liệu và nhiệm vụ khác nhau. Đối với học có giám sát, ngoài Imagenet-1K, chúng tôi cũng tiến hành thí nghiệm với xương sống được huấn luyện trước trên nhiệm vụ phân loại hình ảnh Pascal-VOC (tương đối nhỏ hơn). Đối với học tự giám sát, không cần nhãn ngữ nghĩa, chúng tôi tiến hành thí nghiệm với xương sống được huấn luyện với DINO [9] và SwAV [8]. DINO [9] là một khung tự chưng cất không có nhãn, sử dụng nhiều cắt của hình ảnh (patch) trên cùng một mô hình và cập nhật tham số của mô hình với trung bình động theo cấp số nhân. Trong khi SwAV [8] đồng thời gom cụm dữ liệu và giữ tính nhất quán giữa các phép gán cụm được tạo ra cho các phép tăng cường khác nhau của cùng một hình ảnh. Kết quả trong Bảng 3 cho thấy cả học có giám sát và tự giám sát đều có thể đóng góp một tham số bất biến tốt, và phương pháp của chúng tôi mạnh mẽ với các xương sống huấn luyện trước khác nhau. Lưu ý cách Pascal-VOC là một bộ dữ liệu nhỏ hơn nhiều, có thể giải thích độ chính xác tổng thể thấp hơn; với bất kỳ bộ dữ liệu nào khác (lớn hơn), độ chính xác gần như giống nhau, cho thấy phương pháp của chúng tôi không phụ thuộc nhiều vào một tập đặc trưng xương sống cụ thể.

## 5. Kết luận

Chúng tôi đề xuất Lập trình lại nhẹ theo kênh (CLR), một phương pháp bổ trợ học liên tục hiệu quả tham số, để cho phép một mạng đơn học các ánh xạ đầu vào-đầu ra song song tiềm năng không giới hạn và chuyển đổi ngay lập tức giữa chúng trong thời gian chạy. CLR thêm lập trình lại tuyến tính nhẹ theo kênh để chuyển dịch tham số cố định được huấn luyện trước ban đầu cho từng nhiệm vụ, đơn giản và có thể tổng quát hóa cho bất kỳ mô hình dựa trên CNN nào. Các thí nghiệm về học liên tục 53 nhiệm vụ khác nhau và thách thức cho thấy phương pháp CLR đạt hiệu suất tiên tiến trên học liên tục tăng dần nhiệm vụ. Bên cạnh hiệu suất cao, CLR cũng hiệu quả tham số, chỉ yêu cầu 0,59% tham số bổ sung để học một nhiệm vụ mới.

Lời cảm ơn Công trình này được hỗ trợ bởi Amazon ML Fellowship, C-BRIC (một trong sáu trung tâm trong JUMP, một chương trình của Semiconductor Research Corporation (SRC) được tài trợ bởi DARPA), DARPA (HR00112190134) và Army Research Office (W911NF2020053). Các tác giả khẳng định rằng các quan điểm được bày tỏ ở đây hoàn toàn là của riêng họ, và không đại diện cho quan điểm của chính phủ Hoa Kỳ hoặc bất kỳ cơ quan nào của nó.

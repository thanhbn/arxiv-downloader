# 2309.11042.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2309.11042.pdf
# Kích thước file: 1065128 bytes

===============================================
NỘI DUNG FILE PDF
===============================================

--- TRANG 1 ---
Làm cho Mô hình Ngôn ngữ Nhỏ Trở thành Người Học Đa nhiệm Tốt hơn với
Mixture-of-Task-Adapters
Yukang Xie1,2, Chengyu Wang2, Junbing Yan3,2, Jiyong Zhou1,2, Feiqi Deng1, Jun Huang2
1Đại học Công nghệ Nam Trung Quốc, Quảng Châu, Trung Quốc
2Tập đoàn Alibaba, Hàng Châu, Trung Quốc3Đại học Sư phạm Hoa Đông, Thượng Hải, Trung Quốc
TÓM TẮT
Gần đây, các Mô hình Ngôn ngữ Lớn (LLM) đã đạt được hiệu suất học không-shot đáng kinh ngạc trên nhiều tác vụ Xử lý Ngôn ngữ Tự nhiên (NLP), đặc biệt là đối với các tác vụ sinh văn bản. Tuy nhiên, kích thước lớn của LLM thường dẫn đến chi phí tính toán cao cho việc huấn luyện mô hình và triển khai trực tuyến. Trong công trình này, chúng tôi trình bày ALTER, một hệ thống xây dựng hiệu quả các Người học Đa nhiệm với Mixture-of-Task-Adapters trên các mô hình ngôn ngữ nhỏ (với <1B tham số) để giải quyết đồng thời nhiều tác vụ NLP, nắm bắt điểm chung và khác biệt giữa các tác vụ, nhằm hỗ trợ các ứng dụng đặc thù theo lĩnh vực. Cụ thể, trong ALTER, chúng tôi đề xuất mô-đun Mixture-of-Task-Adapters (MTA) như một mở rộng của kiến trúc transformer cho mô hình cơ bản để nắm bắt kiến thức trong-tác vụ và giữa-tác vụ. Một phương pháp huấn luyện hai giai đoạn được đề xuất thêm để tối ưu hóa sự cộng tác giữa các adapter với chi phí tính toán nhỏ. Kết quả thí nghiệm trên hỗn hợp các tác vụ NLP cho thấy kiến trúc MTA đề xuất và phương pháp huấn luyện hai giai đoạn đạt hiệu suất tốt. Dựa trên ALTER, chúng tôi cũng đã sản xuất các mô hình ngôn ngữ được trang bị MTA cho các lĩnh vực khác nhau.1

KHÁI NIỆM CCS
•Phương pháp tính toán →Sinh ngôn ngữ tự nhiên.

TỪ KHÓA
học đa nhiệm, mô hình ngôn ngữ, sinh văn bản

Định dạng Tham chiếu ACM:
Yukang Xie1,2, Chengyu Wang2, Junbing Yan3,2, Jiyong Zhou1,2, Feiqi Deng1, Jun Huang2. 2018. Làm cho Mô hình Ngôn ngữ Nhỏ Trở thành Người Học Đa nhiệm Tốt hơn với Mixture-of-Task-Adapters. Trong Woodstock '18: Hội thảo ACM về Phát hiện Nhìn Thần kinh, 03-05 tháng 6, 2018, Woodstock, NY. ACM, New York, NY, USA, 4 trang. https://doi.org/XXXXXXX.XXXXXXX

1 GIỚI THIỆU
Sự xuất hiện nhanh chóng của các Mô hình Ngôn ngữ Lớn (LLM) đã mang lại những thay đổi đáng kể cho lĩnh vực Xử lý Ngôn ngữ Tự nhiên

1Tất cả bộ dữ liệu đều được công khai. Mã nguồn và checkpoint mô hình được phát hành trong EasyNLP [16]. URL: https://github.com/alibaba/EasyNLP/tree/master/examples/mta

Được phép tạo bản sao kỹ thuật số hoặc in cứng của toàn bộ hoặc một phần công trình này cho mục đích sử dụng cá nhân hoặc trong lớp học mà không tốn phí với điều kiện các bản sao không được tạo ra hoặc phân phối vì lợi nhuận hoặc lợi thế thương mại và các bản sao phải có thông báo này và trích dẫn đầy đủ trên trang đầu. Bản quyền cho các thành phần của công trình này thuộc sở hữu của các bên khác ngoài ACM phải được tôn trọng. Tóm tắt có ghi nguồn được phép. Để sao chép theo cách khác, hoặc tái xuất bản, để đăng trên máy chủ hoặc tái phân phối danh sách, yêu cầu sự cho phép cụ thể trước và/hoặc một khoản phí. Yêu cầu quyền từ permissions@acm.org.
Từ viết tắt hội nghị 'XX, 03-05 tháng 6, 2018, Woodstock, NY
©2018 Hiệp hội Máy tính.
ACM ISBN 978-1-4503-XXXX-X/18/06. . . $15.00
https://doi.org/XXXXXXX.XXXXXXX

(NLP). Đặc biệt, LLM (như ChatGPT2 với 175B tham số) đã chứng minh khả năng mạnh mẽ trong việc tương tác với người dùng và giải quyết các tác vụ NLP khác nhau trong thiết lập học không-shot, mà hiệu suất thậm chí tiếp cận hoặc vượt con người trong một số tác vụ [7]. Tuy nhiên, hiệu suất ấn tượng của LLM không che đậy được những nhược điểm tiềm ẩn trong hai khía cạnh. i) Kích thước tham số cực lớn của LLM dẫn đến chi phí tính toán và sử dụng không thể chịu đựng được, đặc biệt khi chúng cần được tinh chỉnh hoặc triển khai riêng cho các ứng dụng cụ thể hoặc trong môi trường hạn chế tài nguyên. ii) Kiến trúc chỉ-giải mã khiến chúng khó duy trì hiệu suất cao trên các tác vụ NLP truyền thống với không gian đầu ra rất hạn chế như phân loại văn bản [10].

Dựa trên quan sát này, chúng tôi xem xét lại việc khai thác các mô hình ngôn ngữ nhỏ cho học đa nhiệm trên nhiều tác vụ NLP, vốn dễ huấn luyện và triển khai hơn nhiều.3 Tuy nhiên, cải thiện khả năng giải quyết đa nhiệm của các mô hình như vậy không hề đơn giản do không gian tham số rất hạn chế. Trước đây, một số công trình đã được thực hiện để cải thiện khả năng học đa nhiệm của kiến trúc transformer. Đầu tiên, Mixture-of-Experts (MoE) [4] chia các tác vụ phức tạp thành các bài toán con nhỏ hơn, dễ quản lý hơn, mỗi bài toán được giải quyết bởi một mô hình chuyên gia. Multi-task MoE (MMoE) [8] sử dụng mô-đun đa-cổng để tạo trọng số chuyên gia cụ thể theo các tác vụ khác nhau. Switch Transformers [2] giới thiệu phép cộng thưa thớt của MoE để giải quyết vấn đề nỗ lực tính toán lớn. Tuy nhiên, các công trình dựa trên MoE ở trên chủ yếu được đề xuất để huấn luyện các mô hình ngôn ngữ lớn ở quy mô bằng cách thêm các mô-đun song song và phân vùng dữ liệu ở cấp độ token. Do đó, thiếu sự phân biệt cấp độ tác vụ cho việc thích ứng mô hình đa nhiệm. Thêm vào đó, mối quan hệ cộng tác giữa các mô-đun nội bộ (tức là các chuyên gia) để có hiệu suất học đa nhiệm tốt hơn chưa được khám phá đầy đủ.

Trong công trình này, chúng tôi giới thiệu hệ thống ALTER có thể mở rộng hiệu quả khả năng học đa nhiệm của các mô hình ngôn ngữ nhỏ để giải quyết đồng thời nhiều tác vụ NLP. Trong ALTER, kiến trúc Mixture-of-Task-Adapters (MTA) được thiết kế như một mở rộng nhẹ của kiến trúc transformer để nắm bắt điểm chung và khác biệt giữa các tác vụ. Một phương pháp huấn luyện hai giai đoạn được giới thiệu thêm để điều chỉnh nhẹ sự cộng tác giữa các adapter cho nhiều tác vụ với chi phí tính toán nhỏ. Chúng tôi thực hiện một loạt thí nghiệm trên hỗn hợp các tác vụ NLP và cho thấy phương pháp MTA đề xuất đạt hiệu suất tốt với ít chi phí huấn luyện bổ sung, so với tinh chỉnh có giám sát tiêu chuẩn. Chúng tôi tiếp tục phát hành một số mô hình ngôn ngữ được trang bị MTA đặc thù theo lĩnh vực và trình bày giá trị của chúng trong hỗ trợ các ứng dụng thực tế.

2https://chat.openai.com/
3Bằng mô hình ngôn ngữ nhỏ trong công trình này, chúng tôi đề cập đến các mô hình ngôn ngữ với <1B tham số, so với các mô hình giống ChatGPT với hơn 100B tham số.

--- TRANG 2 ---
Từ viết tắt hội nghị 'XX, 03-05 tháng 6, 2018, Woodstock, NY Yukang Xie1,2, Chengyu Wang2, Junbing Yan3,2, Jiyong Zhou1,2, Feiqi Deng1, Jun Huang2

[Hình 1: Việc thay thế mô-đun FFN (Feed Forward Network) trong một lớp transformer cụ thể bằng mô-đun MTA (Mixture-of-Task-Adapters), cấu trúc adapter phản chiếu cấu trúc FFN.]

[Hình 2: Pipeline hệ thống ALTER.]

2 HỆ THỐNG ALTER
Trong phần này, chúng tôi trước tiên giới thiệu pipeline hệ thống. Sau đó, chúng tôi mô tả cấu trúc kiến trúc MTA và cách học các tham số của MTA trên bộ dữ liệu đa nhiệm. Cụ thể, mô hình được huấn luyện trong hai giai đoạn, với các tham số của toàn bộ mô hình được tinh chỉnh trong giai đoạn đầu. Trong giai đoạn thứ hai, chúng tôi thêm mô-đun adapter chia sẻ để cải thiện hiệu suất mô hình bằng cách chỉ huấn luyện các tham số của mô-đun MTA với các tham số khác bị đóng băng.

Pipeline hệ thống được hiển thị trong Hình 2. Cho một tập hợp các bộ dữ liệu của bất kỳ lĩnh vực tùy ý nào (có thể bao gồm phân loại văn bản, suy luận ngôn ngữ, sinh, v.v.), chúng tôi chuẩn hóa tất cả bộ dữ liệu bằng cách định dạng lại dữ liệu và thêm các prompt tương ứng, từ đó có được bộ dữ liệu đa nhiệm được định dạng thống nhất. Dữ liệu được huấn luyện trong một giai đoạn với các adapter song song và học trọng số để giảm thiểu sự can thiệp của các tác vụ khác nhau, và sau đó đóng băng tham số, giới thiệu adapter chia sẻ và mạng cổng [8] để cải thiện thêm sự cộng tác giữa các tác vụ khác nhau. Chúng tôi sẽ tiếp tục trình bày chi tiết.

2.1 Huấn luyện Giai đoạn Đầu để Có được Tương ứng Tác vụ-Adapter
Trong giai đoạn đầu của huấn luyện, mục tiêu chính là học tương ứng giữa các adapter và tác vụ. Chúng tôi từ bỏ định dạng đầu vào cấp độ token trong MoE [2] và thay vào đó ưu tiên đầu vào cấp độ câu, toàn bộ câu được coi như một tổng thể và không được chia thành các token riêng lẻ để nhập vào một mô-đun. Trong công trình này, chúng tôi đề xuất kiến trúc MTA (Mixture-of-Task-Adapters), có thể được xem như các khối adapter song song. Như được hiển thị trong Hình 1, trong giai đoạn đầu, mô-đun MTA chủ yếu bao gồm Adapter Song song và Bộ chọn Trọng số Tác vụ.

Để thiết lập tương ứng giữa các tác vụ và adapter, với mỗi adapter được dành riêng cho một loại tác vụ cụ thể, chúng tôi giới thiệu độ lệch vào việc khởi tạo các trọng số trong Bộ chọn Trọng số Tác vụ. Điều này đảm bảo mô hình có khả năng tạo ra tương ứng tác vụ-adapter. Sử dụng Softmax-T khuếch đại hiệu ứng của độ lệch và tăng cường khả năng thích ứng của mô hình. Ví dụ, trọng số của loại tác vụ thứ i Wi có thể được khởi tạo như sau:

Wi = [1/N, 1/N, (1+λ)/N, ···, 1/N]  (1)

trong đó N biểu thị số lượng adapter song song, (1+λ)/N đề cập đến giá trị cổng thứ ba, hướng dẫn adapter thứ ba chú ý nhiều hơn đến loại tác vụ thứ i. Lưu ý rằng trong quá trình huấn luyện mô hình, các trọng số này cũng có thể học được, khiến cơ chế của chúng tôi tự thích ứng.

Mô-đun MTA trong giai đoạn đầu của huấn luyện có công thức sau:

A(x) = Concat(A₁(x), ..., Aₙ(x))  (2)
MTAₒᵤₜ₁ = softmax(W/T) · A(x)  (3)

--- TRANG 3 ---
Làm cho Mô hình Ngôn ngữ Nhỏ Trở thành Người Học Đa nhiệm Tốt hơn với Mixture-of-Task-Adapters Từ viết tắt hội nghị 'XX, 03-05 tháng 6, 2018, Woodstock, NY

[Hình 3: Trực quan hóa trọng số thích ứng thu được sau huấn luyện giai đoạn đầu cho thấy trọng số có tương quan mạnh với loại tác vụ.]

trong đó Aᵢ(x) là đầu ra của mạng adapter thứ i w.r.t. đầu vào x. W biểu thị ma trận cổng được khởi tạo thủ công cho tất cả các loại tác vụ. T là hệ số làm sắc. Bằng cách giới thiệu các giá trị cổng, chúng tôi hướng dẫn mỗi adapter chỉ đóng góp chính vào một loại tác vụ. Phương pháp này cho phép chúng tôi giữ lại các đặc tính cụ thể của từng tác vụ riêng lẻ. Lấy bộ dữ liệu đa nhiệm thí nghiệm của chúng tôi làm ví dụ. Các trọng số tự thích ứng được học trong giai đoạn đầu được hiển thị trong Hình 3. Ngoài ra, chúng tôi chèn một token đặc biệt "[START]" vào mỗi mẫu đầu vào, nhằm nắm bắt ngữ nghĩa của toàn bộ chuỗi đầu vào.

2.2 Huấn luyện Giai đoạn Hai để Điều chỉnh Mối quan hệ Cộng tác
Sau khi hoàn thành giai đoạn đầu của huấn luyện, chúng tôi kế thừa tất cả trọng số từ giai đoạn đầu. Để điều chỉnh thêm mối quan hệ cộng tác giữa các adapter, chúng tôi giới thiệu các adapter chia sẻ bổ sung và một mạng cổng, trong khi đóng băng tất cả các tham số huấn luyện ngoại trừ mô-đun MTA. Mạng cổng được sử dụng để tạo trọng số thích ứng, nhằm có được mối quan hệ cộng tác giữa các adapter khác nhau cho các tác vụ khác nhau bằng cách nắm bắt thông tin "[START]" trong lớp ẩn. Công thức cho mạng cổng như sau:

A*(x) = concat(∑ᵢ₌₁ᴷ Aᵢ(x) · Wᵢ, S(x))  (4)
W* = G(concat(S(x)[START], A*(x)[START]))  (5)
MTAₒᵤₜ₂ = A*(x) · W*  (6)

trong đó A*(x) biểu thị các biểu diễn kết hợp của các mô-đun adapter chia sẻ và top-K. S(x) là đầu ra của các adapter chia sẻ. G biểu thị mạng cổng với các lớp tuyến tính và hàm kích hoạt.

Chỉ dựa vào các adapter song song giai đoạn đầu dẫn đến tương tác trực tiếp giữa các tác vụ và khiến việc đạt được trạng thái cộng tác tốt hơn trở nên khó khăn. Trong giai đoạn hai, việc chọn top-k có thể loại bỏ sự can thiệp trực tiếp giữa các tác vụ khác nhau. Để bù đắp cho hiệu ứng cộng tác của việc xóa đồng bộ mà không tái giới thiệu sự can thiệp trực tiếp, một cấu trúc adapter chia sẻ được thêm vào như một mô-đun chuyển tiếp cho tương tác thông tin để kiểm soát sự can thiệp trực tiếp giữa các tác vụ.

[Bảng 1: Kết quả đánh giá tổng thể. ChatGPT được đánh giá trong thiết lập học không-shot và chỉ để tham khảo. NLI và QA là viết tắt của suy luận ngôn ngữ tự nhiên và hỏi đáp, tương ứng.]

[Bảng 2: Kết quả phân tích loại bỏ của huấn luyện hai giai đoạn với các chiến lược khác nhau trên mô hình T5-base và T5-large.]

3 ĐÁNH GIÁ THÍ NGHIỆM
Trong phần này, chúng tôi đánh giá hiệu quả của phương pháp đề xuất trên các bộ dữ liệu công khai.

3.1 Bộ dữ liệu và Thiết lập Thí nghiệm
Chúng tôi sử dụng ba loại tác vụ NLP phổ biến (phân loại văn bản, tác vụ suy luận ngôn ngữ tự nhiên, và hỏi đáp) để xây dựng bộ dữ liệu đa nhiệm. Các bộ dữ liệu bao gồm:

• Phân loại văn bản: CR [3], MR [9], SST-2 [14] và TREC [15];
• Suy luận ngôn ngữ tự nhiên: SNLI [1];
• Hỏi đáp (sinh văn bản): SQuAD [13].

Theo công trình T5 [12], chúng tôi thêm các prompt phù hợp cho tất cả các tác vụ để chuyển đổi chúng thành định dạng đầu vào thống nhất. Đối với các tác vụ phân loại và suy luận, chúng tôi khớp đầu ra mô hình với sự thật gốc và báo cáo độ chính xác dự đoán. Đối với sinh, chúng tôi xây dựng dữ liệu theo cách sinh câu hỏi dựa trên câu trả lời, chúng tôi báo cáo điểm Rouge-L [6], đo lường sự tương đồng giữa văn bản được sinh và tham chiếu. Trong triển khai, chúng tôi tải các trọng số đã được tiền huấn luyện từ T5-base, với 24 lớp transformer. Các mô hình cơ sở bao gồm phiên bản base của BART [5], GPT-2 [11] và Switch Transformer [2]. Hiệu suất của ChatGPT cũng được báo cáo để tham khảo. Đối với phương pháp của chúng tôi, chúng tôi cũng thực hiện các thí nghiệm so sánh trên T5-large.

3.2 Kết quả Thí nghiệm Tổng quan
Trong tập thí nghiệm đầu tiên, chúng tôi trộn nhiều tác vụ thành một tập kiểm tra, và sau đó thu được bốn điểm thông qua một tiêu chí chấm điểm thống nhất. Có thể quan sát được một số điểm từ Bảng 1. Thứ nhất, mô hình của chúng tôi đạt kết quả tổng thể cao hơn so với các mô hình khác, chứng minh hiệu quả của phương pháp đề xuất. Thứ hai, khi so sánh với phương pháp xử lý cấp độ token của Switch Transformer, phương pháp xử lý tác vụ cấp độ câu của chúng tôi thể hiện lợi thế hiệu suất đáng kể

--- TRANG 4 ---
Từ viết tắt hội nghị 'XX, 03-05 tháng 6, 2018, Woodstock, NY Yukang Xie1,2, Chengyu Wang2, Junbing Yan3,2, Jiyong Zhou1,2, Feiqi Deng1, Jun Huang2

[Hình 4: Quá trình suy luận và kết quả của mô hình được huấn luyện trên bộ dữ liệu PromptCBLUE được trình bày trên WebUI.]

trên bộ dữ liệu đa nhiệm này. Cuối cùng, chúng tôi so sánh kết quả của mô hình đề xuất với ChatGPT-turbo. Các đầu ra được tạo bởi ChatGPT-turbo khó kiểm soát hơn do các tính chất nội tại của nó. Do đó, chúng tôi nới lỏng tiêu chí chấm điểm để bao gồm các từ trả lời miễn là chúng đúng cho cả tác vụ phân loại và tác vụ suy luận ngôn ngữ tự nhiên. Mặc dù có sự nới lỏng này, mô hình của chúng tôi vẫn vượt trội so với ChatGPT-turbo baseline, chứng minh hiệu quả của nó thậm chí so với các mô hình lớn hơn sau khi tinh chỉnh trên các bộ dữ liệu đa nhiệm phổ biến.

3.3 Nghiên cứu Phân tích Loại bỏ và Phân tích Mô hình
Để chứng minh thêm hiệu quả của phương pháp huấn luyện hai giai đoạn đề xuất và adapter chia sẻ, chúng tôi thực hiện một loạt thí nghiệm phân tích loại bỏ. Do hạn chế về không gian, chúng tôi chỉ hiển thị tập thí nghiệm phân tích loại bỏ đại diện nhất. Như được hiển thị trong Bảng 2, các mô hình với cấu trúc adapter đa dạng cho thấy cải thiện đáng kể so với mô hình gốc, bất kể chúng tôi sử dụng T5-base hay T5-large.

Các thí nghiệm của chúng tôi đã tiết lộ rằng tinh chỉnh tham số một phần hoạt động tốt hơn và yêu cầu ít tài nguyên tính toán hơn so với tinh chỉnh đầy đủ trong giai đoạn thứ hai của huấn luyện. Hơn nữa, việc so sánh với kết quả huấn luyện của kiến trúc mô hình hai giai đoạn sử dụng tinh chỉnh tham số toàn cục cho thấy tinh chỉnh một phần có thể tối ưu hóa sự cộng tác giữa các adapter và cải thiện đáng kể hiệu suất mô hình.

4 CÁC TÌNH HUỐNG DEMO
Trong demo này, chúng tôi sẽ hiển thị quy trình hoàn chỉnh về cách các mô hình của chúng tôi được huấn luyện và triển khai. Đối với các ứng dụng đặc thù theo lĩnh vực, chúng tôi cũng đã huấn luyện một số mô hình ngôn ngữ được trang bị MTA cho các lĩnh vực khác nhau. Lấy y học làm ví dụ. Mô hình của chúng tôi được huấn luyện trên bộ dữ liệu PromptCBLUE đa nhiệm4, là một bộ dữ liệu instruction-tuning quy mô lớn trong lĩnh vực y tế bằng tiếng Trung. Kết quả cũng chứng minh rằng mô hình được tạo ra của chúng tôi, mặc dù có kích thước tham số nhỏ, có thể tạo ra kiến thức đặc thù theo lĩnh vực một cách chính xác.

4https://github.com/michael-wzhu/PromptCBLUE

Để có tương tác người-máy tốt hơn, chúng tôi đã thiết lập giao diện WebUI, như được hiển thị trong Hình 4.

5 KẾT LUẬN
Chúng tôi đề xuất ALTER, một hệ thống xây dựng hiệu quả các Người học Đa nhiệm với Mixture-of-Task-Adapters để giải quyết đồng thời nhiều tác vụ NLP. Cụ thể, Mixture-of-Task-Adapters (MTA) được giới thiệu để giúp các mô hình học sự khác biệt và điểm chung của tác vụ nhằm cải thiện hiệu suất mô hình trên các bộ dữ liệu đa nhiệm. Chúng tôi chứng minh rằng phương pháp đề xuất có thể đạt hiệu suất tương đương với các mô hình lớn. Trong mô-đun MTA đề xuất, chúng tôi giới thiệu một phương pháp huấn luyện hai giai đoạn kết hợp kiến thức tiền nghiệm để có được các tham số mô hình cộng tác cơ bản cho các adapter cụ thể tương ứng với các tác vụ cụ thể trong giai đoạn đầu, và cải thiện thêm hiệu suất mô hình bằng cách phối hợp sự cộng tác giữa các adapter trong giai đoạn thứ hai. Chúng tôi tiếp tục chứng minh cách áp dụng kỹ thuật của chúng tôi cho các ứng dụng đặc thù theo lĩnh vực.

TÀI LIỆU THAM KHẢO
[1] Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large annotated corpus for learning natural language inference. In EMNLP 2015, Lisbon, Portugal, September 17-21, 2015. 632–642.
[2] William Fedus, Barret Zoph, and Noam Shazeer. 2022. Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity. J. Mach. Learn. Res. (2022), 120:1–120:39.
[3] Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the Tenth ACM SIGKDD, Seattle, Washington, USA, August 22-25, 2004. ACM, 168–177.
[4] Robert A. Jacobs, Michael I. Jordan, Steven J. Nowlan, and Geoffrey E. Hinton. 1991. Adaptive Mixtures of Local Experts. Neural Comput. 3, 1 (1991), 79–87.
[5] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv:1910.13461 (2019).
[6] Chin-Yew Lin. 2004. ROUGE: A Package for Automatic Evaluation of Summaries. In Text Summarization Branches Out. ACL, 74–81.
[7] Yiheng Liu, Tianle Han, Siyuan Ma, Jiayue Zhang, Yuanyuan Yang, Jiaming Tian, Hao He, Antong Li, Mengshen He, Zhengliang Liu, Zihao Wu, Dajiang Zhu, Xiang Li, Ning Qiang, Dinggang Shen, Tianming Liu, and Bao Ge. 2023. Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models. CoRR abs/2304.01852 (2023).
[8] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, and Ed H. Chi. 2018. Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts. In SIGKDD. 1930–1939.
[9] Bo Pang and Lillian Lee. 2005. Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales. In ACL 2005. 115–124.
[10] Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, and Diyi Yang. 2023. Is ChatGPT a General-Purpose Natural Language Processing Task Solver? CoRR abs/2302.06476 (2023).
[11] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog 1, 8 (2019), 9.
[12] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2019. Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer. CoRR abs/1910.10683 (2019).
[13] Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. Squad: 100,000+ questions for machine comprehension of text. arXiv preprint arXiv:1606.05250 (2016).
[14] Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Y. Ng, and Christopher Potts. 2013. Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank. In EMNLP 2013, A meeting of SIGDAT. ACL, 1631–1642.
[15] Ellen M. Voorhees and Dawn M. Tice. 2000. Building a question answering test collection. In SIGIR 2000. ACM, 200–207.
[16] Chengyu Wang, Minghui Qiu, Taolin Zhang, Tingting Liu, Lei Li, Jianing Wang, Ming Wang, Jun Huang, and Wei Lin. 2022. EasyNLP: A Comprehensive and Easy-to-use Toolkit for Natural Language Processing. In EMNLP. ACL, 22–29.

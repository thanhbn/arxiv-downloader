# 2305.18169.pdf
# Được chuyển đổi từ PDF sang TXT
# Đường dẫn nguồn: /home/admin88/arxiv-downloader/peft/2305.18169.pdf
# Kích thước tệp: 437732 bytes

===============================================
NỘI DUNG TỆP PDF
===============================================


--- TRANG 1 ---
LM-CPPF: Tăng cường dữ liệu dẫn dắt bởi diễn giải
cho Tinh chỉnh ít mẫu dựa trên Prompt tương phản
Amirhossein Abaskohi1, Sascha Rothe2, Yadollah Yaghoobzadeh1,3
1Trường Kỹ thuật Điện và Máy tính
Khoa Kỹ thuật, Đại học Tehran, Tehran, Iran
2Google DeepMind, Zürich, Thụy Sĩ
3Viện Nghiên cứu Cao cấp Tehran, Đại học Khatam, Iran
amir.abaskohi@ut.ac.ir, rothe@google.com, y.yaghoobzadeh@ut.ac.ir
Tóm tắt
Trong những năm gần đây, đã có tiến bộ đáng kể
trong việc phát triển các mô hình ngôn ngữ được
huấn luyện trước cho NLP. Tuy nhiên, những mô hình
này thường gặp khó khăn khi được tinh chỉnh trên
các tập dữ liệu nhỏ. Để giải quyết vấn đề này, các
nhà nghiên cứu đã đề xuất nhiều phương pháp thích
ứng khác nhau. Điều chỉnh dựa trên prompt có thể
nói là cách phổ biến nhất, đặc biệt đối với các mô
hình lớn hơn. Nghiên cứu trước đây cho thấy rằng
việc thêm học tương phản vào tinh chỉnh dựa trên
prompt là hiệu quả vì nó giúp mô hình tạo ra các
embedding có thể phân biệt được nhiều hơn giữa
các lớp, và nó cũng có thể hiệu quả hơn về mặt
mẫu vì mô hình học từ các ví dụ tích cực và tiêu
cực đồng thời. Một trong những thành phần quan
trọng nhất của học tương phản là tăng cường dữ
liệu, nhưng không giống như thị giác máy tính, việc
tăng cường dữ liệu hiệu quả cho NLP vẫn còn thử
thách. Bài báo này đề xuất LM-CPPF, Tinh chỉnh
dựa trên Prompt tương phản dẫn dắt bởi Diễn giải
của Mô hình Ngôn ngữ, tận dụng diễn giải ít mẫu
dựa trên prompt sử dụng các mô hình ngôn ngữ sinh,
đặc biệt là các mô hình ngôn ngữ lớn như GPT-3 và
OPT-175B, để tăng cường dữ liệu. Các thí nghiệm
của chúng tôi trên nhiều benchmark phân loại văn
bản cho thấy rằng phương pháp tăng cường này vượt
trội hơn các phương pháp khác, như tăng cường dữ
liệu dễ dàng, dịch ngược, và nhiều template.1
1 Giới thiệu
Các mô hình ngôn ngữ được huấn luyện trước (PLM)
được huấn luyện trên các corpus quy mô lớn theo
cách tự giám sát. Chúng đã thay đổi cơ bản cộng
đồng NLP trong vài năm qua bằng cách đạt được
kết quả ấn tượng trong nhiều Tác vụ khác nhau (Devlin et al.,
2018; Radford et al., 2018; Yang et al., 2019; Chi-
ang et al., 2022). Tuy nhiên, khi PLM được tinh
chỉnh trên các tập dữ liệu nhỏ, hiệu suất của chúng
giảm sút. Các nhà nghiên cứu đã đề xuất nhiều kỹ
thuật khác nhau để thích ứng PLM với những tình
huống này (Snell et al., 2017;
1Triển khai của chúng tôi có sẵn công khai tại: https://
github.com/AmirAbaskohi/LM-CPPFSung et al., 2018). Ngoài hiệu suất,
việc tinh chỉnh PLM để học một tác vụ mới là không
hiệu quả về mặt tham số, vì cần một mô hình hoàn
toàn mới cho mỗi tác vụ (Houlsby et al., 2019).
Với việc giới thiệu GPT-3 (Brown et al.,
2020b) với 175B tham số, đã được chứng minh rằng
Các Mô hình Ngôn ngữ Lớn (LLM) là những người
học ít mẫu hiệu quả vì chúng có thể sử dụng kiến
thức của mình hiệu quả hơn. Một trong những tính
năng chính của những LLM này là khả năng thực
hiện nhiều tác vụ sử dụng prompt. Một prompt ngôn
ngữ là một đoạn văn bản được thêm vào truy vấn
đầu vào để giúp mô hình đưa ra dự đoán chính xác
hơn. Ngoài ra, LLM có thể được tinh chỉnh cho các
tác vụ cụ thể sử dụng ít ví dụ. Điều này đã làm cho
chúng trở thành công cụ mạnh mẽ cho các tác vụ
NLP, đặc biệt trong các tình huống ít mẫu. Tuy nhiên,
điều đó có thể không thực tế cho nhiều tình huống
vì kích thước mô hình. Do đó, có nhu cầu thích ứng
các PLM nhỏ hơn để hoạt động theo cách tương tự
như LLM.
Tinh chỉnh dựa trên prompt là một phương pháp
để thích ứng PLM với các tác vụ hoặc miền cụ thể
bằng cách cung cấp một prompt (Schick và Schütze,
2020a,b). Phương pháp này đã được chứng minh là
hiệu quả trong nhiều tác vụ NLP khác nhau, bao gồm
phân loại văn bản (Han et al., 2021; Wang et al.,
2022) và trả lời câu hỏi (Yao et al., 2022). Tuy nhiên,
có thể khó khăn để đạt được hiệu suất mạnh khi chỉ
có ít ví dụ có sẵn cho mỗi tác vụ. Gao et al. (2020)
đã giới thiệu một phương pháp tinh chỉnh dựa trên
prompt gọi là LM-BFF cho RoBERTa (Liu et al.,
2019) để giải quyết vấn đề này. Phương pháp của
họ bao gồm tạo prompt tự động và cách hiệu quả
hơn để sử dụng các ví dụ tác vụ trong tinh chỉnh.
Dựa trên thành công của LM-BFF và xem xét
các kết quả đầy hứa hẹn của học tương phản cả
trong thị giác máy tính (Chen et al., 2020) và NLP
(Chen et al., 2020; Miao et al., 2021), Jian et al.
(2022) trình bày một framework học tương phản để
cải thiện LM-BFF. Họ đề xuất một phương pháp
Học Tương phản Có giám sát (SCL) (Khosla et al.,arXiv:2305.18169v3  [cs.CL]  5 Jul 2023

--- TRANG 2 ---
2020) phân loại đầu vào sử dụng các góc nhìn được
tăng cường khác nhau của dữ liệu. Những góc nhìn
này được tạo ra bằng cách sử dụng các template
khác nhau cho các minh họa của chúng khi xây dựng
prompt.
Trong bài báo này, chúng tôi chỉ ra rằng trong khi
SCL ở không gian đặc trưng có thể có lợi, việc sử
dụng các template khác nhau có thể hạn chế tiềm
năng đầy đủ của phương pháp này. Chúng tôi đề
xuất LM-CPPF (Tinh chỉnh dựa trên Prompt tương
phản dẫn dắt bởi Diễn giải của Mô hình Ngôn ngữ),
trong đó chúng tôi tích hợp kiến thức của LLM như
GPT-3 và OPT-175B (Zhang et al., 2022) để xây
dựng các góc nhìn khác nhau sử dụng diễn giải.
Những mô hình này có thể tạo ra các diễn giải của
một câu với cú pháp khác nhau, không chỉ bằng
cách thay đổi từ vựng hóa. Các nghiên cứu trước
đây đã coi việc tạo ra diễn giải là một tác vụ NLP
thử thách và tốn kém (Siddique et al., 2020; Garg
et al., 2021; Zhou và Bhat, 2021). Tuy nhiên, PLM
có thể tạo ra diễn giải dễ dàng và hiệu quả bằng
cách sử dụng học trong ngữ cảnh với ít ví dụ. Mặc
dù nghiên cứu trước đây đã nghiên cứu tạo ra diễn
giải với PLM (Roy và Grangier, 2019; Hegde và
Patil, 2020), theo hiểu biết tốt nhất của chúng tôi,
đây là lần đầu tiên các LLM lớn được sử dụng để
tạo ra diễn giải với prompt như một phương pháp
tăng cường. Các thí nghiệm của chúng tôi trên sáu
tác vụ phân loại văn bản khác nhau cho thấy rằng
LM-CPPF vượt trội hơn các phương pháp SOTA
trước đây về tăng cường dữ liệu trong tinh chỉnh
dựa trên prompt, bao gồm Tăng cường Dữ liệu Dễ
dàng (EDA) (Wei và Zou, 2019), Dịch Ngược (BT)
(Sugiyama và Yoshinaga, 2019), và nhiều template
(Jian et al., 2022).
2 Các Công trình Liên quan
LLM như GPT-3 (Brown et al., 2020a) có thể thực
hiện các tác vụ NLP với ít ví dụ và prompt tự nhiên.
Nhưng các mô hình nhỏ hơn không hiệu quả với
phương pháp này và có vấn đề về sự thưa thớt dữ
liệu và độ nhạy cảm của prompt. Để giải quyết những
thách thức này, Gao et al. (2021) đề xuất LM-BFF,
một framework tận dụng PLM lớn để tự động tạo
ra các prompt cụ thể cho tác vụ cho các mô hình
nhỏ hơn. Nó cải thiện hiệu suất ít mẫu của chúng
trên các tác vụ NLP khác nhau. Một số công trình
đã tăng cường LM-BFF với các phương pháp điều
chỉnh prompt khác nhau. Ví dụ, Zhou et al. (2022)
trình bày một phương pháp điều chỉnh prompt liên
tục dẫn dắt bối cảnh kép sử dụng ngữ cảnh ngôn
ngữ và kết nối điều chỉnh prompt rời rạc và liên
tục. Jian et al. (2022) tích hợp học tương phản và
tăng cường dữ liệu với LM-BFF. Trong phần tương phản của họ, ngoài
việc so sánh các thể hiện khác nhau từ cùng hoặc
khác lớp, họ đã giới thiệu một phương pháp tăng
cường cụ thể cho prompt mới. Trong phương pháp
của họ, họ thay đổi template của prompt. Trong bài
báo này, chúng tôi sử dụng diễn giải ít mẫu với LLM
cho điều chỉnh prompt tương phản, điều này tinh
chỉnh các mô hình với prompt tự nhiên.
Diễn giải là tác vụ biểu đạt cùng một ý nghĩa
với các từ hoặc cấu trúc khác nhau. Nó có thể được
sử dụng để tạo ra dữ liệu huấn luyện với sự đa dạng
và tự nhiên tăng lên cho các tác vụ NLP, như phân
loại văn bản (Xie et al., 2020), suy luận ngôn ngữ
tự nhiên (Kumar et al., 2019), và tóm tắt văn bản
(Loem et al., 2022), vượt qua các hạn chế của các
phương pháp truyền thống. Diễn giải giúp với sự
khan hiếm dữ liệu và khái quát hóa mô hình. Có
nhiều cách khác nhau để tạo ra diễn giải cho tăng
cường dữ liệu. Một là dịch ngược (Sennrich et al.,
2016), sử dụng một hệ thống dịch thuật để chuyển
đổi một câu sang ngôn ngữ khác và quay lại. Một
cách khác là sử dụng các mô hình diễn giải được
huấn luyện trên các tập dữ liệu diễn giải song song
(Wieting và Gimpel, 2018; Zhu et al., 2022). PLM
cũng có thể tạo ra diễn giải bằng cách sử dụng các
corpus quy mô lớn, nhưng chúng có thể tạo ra các
diễn giải không nhất quán về mặt ngữ nghĩa hoặc
không liên quan. LLM có thể giảm vấn đề này vì
chúng mã hóa và tạo ra ngôn ngữ tốt hơn. Trong
bài báo này, chúng tôi tạo ra diễn giải bằng cách
prompt LLM một cách cẩn thận và sau đó sử dụng
chúng để tăng cường dữ liệu.
3 Phương pháp
Bối cảnh Thành công của học tương phản dựa
vào tăng cường dữ liệu, tạo ra các góc nhìn mới
của dữ liệu đầu vào. Học tương phản đã được sử
dụng cho nhiều tác vụ khác nhau trong học sâu (Le-Khac
et al., 2020; Conde và Turgutlu, 2021; Abaskohi
et al., 2022); tuy nhiên, hầu hết các phương pháp
tăng cường dữ liệu NLP có thể ảnh hưởng đến ngữ
nghĩa dẫn đến cải thiện hạn chế. Ví dụ, việc thay
thế từ đồng nghĩa của EDA có thể tạo ra các mẫu
hoàn toàn mới vì các từ không có nghĩa bằng nhau
(Keselj, 2009). Ngoài những phương pháp tăng cường
này, phương pháp được sử dụng trong Jian et al.
(2022) không thể được tính là tăng cường dữ liệu
vì mẫu vẫn giống nhau và chỉ template cho verbalizer
thay đổi. Mặc dù đó là một phương pháp sáng tạo
được thiết kế cụ thể cho phương pháp dựa trên prompt
của LM-BFF, nó bị hạn chế về hiệu suất thậm chí
so với EDA trong một số benchmark. Hơn nữa,
nó đòi hỏi một chuyên gia tạo ra nhiều template

--- TRANG 3 ---
Hình 1: Phương pháp của chúng tôi, LM-CPPF, bao gồm hai mục tiêu: (I) MLM và (II) Học Tương phản Có giám sát. Câu mục tiêu là câu đầu tiên trong mỗi prompt với một token [MASK]. Câu mục tiêu của Sent_0 được sử dụng để huấn luyện mô hình của chúng tôi và tính toán loss MLM. Chúng tôi xây dựng Sent_3, có câu mục tiêu là một diễn giải của câu mục tiêu của Sent_0. Sent_1 và Sent_2, được lấy mẫu từ tập dữ liệu, có các câu mục tiêu trong cùng và khác lớp với Sent_0, tương ứng.
cho mỗi tác vụ, điều này làm cho nó trở nên thử thách
cho các tác vụ mới xuất hiện. Ở đây chúng tôi đề
xuất tận dụng LLM để tạo ra diễn giải và giới thiệu
LM-CPPF, một phương pháp mới nhằm giải quyết
các thách thức liên quan đến tinh chỉnh dựa trên
prompt tương phản của PLM.
Diễn giải ít mẫu Diễn giải là một trong những
phương pháp tốt nhất cho tăng cường dữ liệu trong
NLP. Một trong những phương pháp phổ biến nhất
cho diễn giải là dịch ngược (BT) (Sugiyama và
Yoshinaga, 2019) do tính đơn giản và hiệu quả của
nó. Tuy nhiên, hiệu suất của BT phụ thuộc rất nhiều
vào ngôn ngữ trung gian. Trong bài báo này, thay
vào đó, chúng tôi sử dụng sự kết hợp của học prompt
và LLM cho diễn giải. Trong diễn giải ít mẫu, một
LLM viết lại một câu được đưa ra một hướng dẫn
và một ít ví dụ. Chúng tôi tin rằng LLM tạo ra các
diễn giải chất lượng cao do kiến thức về ngữ nghĩa
và cấu trúc câu được mã hóa của chúng. Chúng tôi
sử dụng GPT-3 (Brown et al., 2020b) hoặc OPT-175B
(Zhang et al., 2022) thông qua API chính thức của
chúng2 để tạo ra diễn giải.
Để tránh vi phạm các thiết lập tinh chỉnh dựa
trên prompt, chúng tôi không bao gồm bất kỳ dữ
liệu tác vụ bổ sung nào trong việc tạo ra diễn giải
của chúng tôi. Theo thiết lập ít mẫu trong LM-BFF,
chúng tôi giả sử có quyền truy cập vào một PLM M,
các tập dữ liệu Dtrain, và Dtest với không gian nhãn
Y trong đó chỉ có K = 16 ví dụ trên mỗi lớp trong
Dtrain. Chúng tôi sử dụng thiết lập này cho cả diễn
giải và tinh chỉnh ít mẫu dựa trên prompt. Để
2OPT-175B: opt.alpa.ai và GPT-3: openai.com/apitạo ra diễn giải, loại trừ một mẫu mà chúng tôi
muốn diễn giải, chúng tôi sử dụng QuillBot3 để
tạo ra diễn giải cho prompt của chúng tôi cho 15
mẫu còn lại trong cùng lớp của Dtrain. Chúng tôi
tận dụng hai loại prompt cho diễn giải: (I) Chỉ Minh
họa: Ở đây, các mẫu và phiên bản diễn giải của
chúng được đưa ra sử dụng các template trong Bảng
C.3 để minh họa tác vụ diễn giải. (II) Minh họa với
Hướng dẫn: Ngoài phương pháp trước, phương
pháp này bao gồm các hướng dẫn ở đầu prompt,
định nghĩa diễn giải trước các minh họa. Những
hướng dẫn này có thể được thấy trong Bảng C.4.
Tinh chỉnh dựa trên prompt tương phản LM-
CPPF bao gồm hai bước. Bước đầu tiên liên quan
đến việc tính toán loss Mô hình Ngôn ngữ Có mặt
nạ (MLM) bằng cách sử dụng câu mục tiêu trong
template đã cho, các minh họa cụ thể trong prompt,
và verbalizer được khớp với nhãn của câu mục tiêu.
Chúng tôi tính toán loss tương phản có giám sát
trong bước thứ hai bằng cách so sánh prompt mục
tiêu với một mẫu khác với cùng template nhưng
các minh họa ngẫu nhiên khác nhau. Mẫu so sánh
này có thể thuộc cùng hoặc khác lớp với prompt
mục tiêu. Khi mẫu so sánh thuộc về một lớp khác,
nó được lấy mẫu ngẫu nhiên từ tập dữ liệu. Tuy
nhiên, trong trường hợp mẫu so sánh thuộc về cùng
lớp, một phương pháp thay thế được sử dụng. Điều
này liên quan đến việc chọn một mẫu khác từ cùng
lớp
3quillbot.com

--- TRANG 4 ---
Tác vụ LM-BFFLM-BFF+ LM-BFF+ LM-CPPF LM-CPPF LM-CPPF LM-CPPF
SupConLoss Multi-templates GPT-3 OPT GPT-2 FT GPT-2
SST-2 89.5 90.3 91.0 92.3 91.8 91.1 91.4
SST-5 48.5 49.6 50.3 52.8 52.2 51.4 51.6
MNLI 62.3 63.2 64.8 68.4 66.2 65.6 65.8
CoLA 6.9 9.6 11.6 14.1 13.3 10.7 11.8
QNLI 61.2 65.4 67.2 69.2 68.5 67.5 67.8
CR 89.7 89.9 90.2 91.4 91.1 90.2 90.7
Bảng 1: Hiệu suất của LM-CPPF và các baseline của chúng tôi trong sáu tập dữ liệu. LM-BFF+Multi-templates đề cập đến Jian
et al. (2022). LM-BFF+SupConLoss sử dụng cùng kiến trúc của LM-BFF+Multi-templates, nhưng không có bất kỳ tăng cường dữ liệu nào, chỉ tích hợp các hàm loss tương phản có giám sát và MLM. Hai trường hợp có sẵn cho
GPT-2: mô hình được huấn luyện trước và GPT-2 được tinh chỉnh (FT) trên tập dữ liệu ParaNMT-50M (Wieting và Gimpel, 2018).
LM-BFF, LM-BFF+Multi-template, và LM-CPPF (trung bình cho tất cả các mô hình được sử dụng cho diễn giải) có 0.77 và
1.02, và 1.65 độ lệch chuẩn trung bình cho mỗi tác vụ, tương ứng.
trong tập dữ liệu hoặc áp dụng các kỹ thuật tăng
cường dữ liệu, diễn giải trong trường hợp của chúng
tôi, để tăng cường mẫu mục tiêu nhằm tạo ra một
góc nhìn mới của nó. Trong cả hai trường hợp này,
các minh họa không giống nhau. Hình 1 minh họa
quá trình tinh chỉnh, và Thuật toán D.1 hiển thị
phương pháp của chúng tôi khi diễn giải tạo ra một
góc nhìn mới của mẫu mục tiêu. Xem Phụ lục D
để biết thêm thông tin.
4 Thí nghiệm
Các tập dữ liệu đánh giá và giao thức Phương
pháp của chúng tôi được đánh giá trên sáu tác vụ
phân loại khác nhau từ LM-BFF (Liu et al., 2021).
Các số được báo cáo đại diện cho độ chính xác trung
bình từ năm lần chạy sử dụng Roberta-base (Liu
et al., 2019). Trong Phần 4.1 nơi LLM được so
sánh cho diễn giải, chúng tôi cũng sử dụng GPT-2
được huấn luyện trước và tinh chỉnh như một mô
hình bổ sung cho diễn giải, cho phép chúng tôi tận
dụng các mô hình nhỏ hơn trong các thí nghiệm
của chúng tôi. Đối với việc tinh chỉnh GPT-2 cụ
thể cho diễn giải, chúng tôi sử dụng tập dữ liệu
ParaNMT-50M (Wieting và Gimpel, 2018). Thêm
chi tiết về quá trình huấn luyện có thể được tìm
thấy trong Phụ lục A.
4.1 Diễn giải trong Tinh chỉnh Prompt
Phần này trình bày kết quả của phương pháp tinh
chỉnh của chúng tôi sử dụng diễn giải trên nhiều
tác vụ NLP khác nhau. Như được hiển thị trong
Bảng 1, LM-CPPF cải thiện độ chính xác của mô
hình trên tất cả các tác vụ so với phương pháp
baseline của LM-BFF+Multi-templates (Jian et al.,
2022). So sánh độ lệch chuẩn của mô hình của chúng
tôi trong năm lần chạy và độ lệch chuẩn của LM-BFF
và LM-BFF + Multi-templates, chúng tôi thấy rằng
LM-CPPF có độ lệch chuẩn cao hơn vì nó sử dụng
một mô hình trung gian để tạo ra diễn giải. Ngược
lại, LM-BFF + Multi-templates tích hợp các template có hiệu suất gần
như bằng nhau (Jian et al., 2022).
Chúng tôi cũng so sánh hiệu ứng của việc sử dụng
GPT-3, OPT-175B, và GPT-2 như mô hình ngôn
ngữ của chúng tôi cho diễn giải ít mẫu. Chúng tôi
đã làm hai thí nghiệm với GPT-2 large: (I) Sử dụng
phiên bản được huấn luyện trước của GPT-2 nơi
các trọng số không được điều chỉnh chút nào (II)
GPT-2 được tinh chỉnh nơi mô hình đã được tinh
chỉnh trên tập dữ liệu ParaNMT-50M. Kết quả trong
Bảng 1 chỉ ra rằng GPT-3 vượt trội hơn OPT-175B
trong tất cả các tác vụ và GPT-2 có hiệu suất thấp
hơn, điều này có thể dự đoán được vì nó có ít tham
số hơn đáng kể. Ngoài ra, GPT-2 được tinh chỉnh
cho thấy hiệu suất tốt hơn điều này gợi ý rằng kiến
thức của GPT-2 sau huấn luyện trước không đủ
để thực hiện một tác vụ như diễn giải. Về LLM,
mặc dù cả hai mô hình đều có 175B tham số, OPT-
175B có dấu chân carbon 1/7 của GPT-3, và nó
cũng có sẵn miễn phí (Zhang et al., 2022). Do đó,
chúng tôi dựa vào phân tích tiếp theo của chúng
tôi trên OPT-175B.
4.2 Diễn giải ít mẫu so với Các Phương pháp
Tăng cường Dữ liệu Khác
Trong phần này, chúng tôi trình bày một so sánh
thí nghiệm về hiệu suất của phương pháp diễn giải
ít mẫu và các phương pháp tăng cường dữ liệu khác,
bao gồm BT và EDA. Kết quả được hiển thị trong
Bảng 2. Phương pháp BT được đánh giá sử dụng
các ngôn ngữ trung gian khác nhau (Ả Rập, Pháp,
Đức, Trung Quốc, và Hindi). Kết quả chỉ ra rằng
hiệu suất của BT hơi khác nhau giữa các ngôn ngữ,
với Trung Quốc cho thấy hiệu suất cao nhất. Nói
chung, các phương pháp diễn giải, bao gồm BT,
tốt hơn so với EDA. Trong SST-2 và CR, nơi các
mẫu thường là các câu đơn giản, BT cho thấy hiệu
suất yếu hơn

--- TRANG 5 ---
Tác vụ Diễn giải Dịch Ngược SR RI RS RD EDA
Ít mẫu AR FR DE ZH HI
SST-2 91.8 90.8 90.6 90.4 90.7 90.3 90.5 89.5 90.8 91.3 90.4
SST-5 52.2 49.2 49.3 49.1 49.6 48.3 47.9 49.3 49.3 48.2 48.2
MNLI 66.2 64.3 63.1 63.8 65.4 62.2 62.9 63.2 61.7 60.2 60.3
CoLA 13.3 6.7 6.8 6.4 7.1 5.9 6.3 5.8 5.8 5.1 5.1
QNLI 68.5 66.5 66.2 65.8 66.6 64.3 66.1 65.9 66.3 65.6 63.3
CR 91.1 88.5 88.6 88.4 88.7 87.9 89.8 89.1 89.3 89.6 89.7
Bảng 2: So sánh độ chính xác của phương pháp diễn giải ít mẫu của chúng tôi với các phương pháp Dịch Ngược (BT) và Tăng cường Dữ liệu Dễ dàng (EDA). EDA bao gồm Thay thế Từ đồng nghĩa (SR), Chèn Ngẫu nhiên (RI), Hoán đổi Ngẫu nhiên (RS), và Xóa Ngẫu nhiên (RD). EDA trong kết quả là sự kết hợp của tất cả bốn phương pháp đã đề cập. BT và EDA có độ lệch chuẩn trung bình lần lượt là 1.31 và 1.4, trong khi phương pháp của chúng tôi có độ lệch chuẩn là 1.65.
Tác vụ Số Template
1 2 3 4 5 6
SST-2 91.8 91.2 91.4 89.1 92.1 92.4
SST-5 52.2 53.1 52.7 53.4 53.6 54.1
MNLI 66.2 65.9 66.9 66.1 66.2 66.4
CoLA 13.3 12.7 13.2 13.8 13.4 13.6
QNLI 68.5 68.4 68.6 68.5 68.8 69.3
CR 91.1 91.2 91.3 91.5 91.7 92.2
Bảng 3: Hiệu suất của các template minh họa prompt
diễn giải khác nhau.
so với EDA. Chúng tôi tin rằng lý do là BT có thể
hiệu quả hơn cho các chuỗi dài hơn vì các chuỗi
dài hơn thường chứa nhiều ngữ cảnh và ý nghĩa
tinh tế hơn. Hơn nữa, EDA sử dụng kiến thức bổ
sung từ một PLM khác trong một số hành động
nhất định, như thay thế từ đồng nghĩa, tương tự
như BT và diễn giải ít mẫu.
Phương pháp diễn giải ít mẫu được giới thiệu
trong công trình này vượt trội hơn cả BT và EDA.
Điều này xác nhận rằng việc sử dụng kiến thức của
PLM một cách đúng đắn trong diễn giải là một phương
pháp tăng cường dữ liệu hiệu quả và hiệu suất. Trong
diễn giải ít mẫu, chúng tôi hướng dẫn mô hình tạo
ra các diễn giải khác nhau về từ vựng hóa và cấu
trúc câu.
4.3 Đánh giá Template Prompt
Vì trọng tâm của phương pháp của chúng tôi là việc
tạo ra diễn giải ít mẫu được thực hiện bởi LLM,
chúng tôi điều tra tác động của các minh họa prompt
diễn giải và template hướng dẫn khác nhau đối với
hiệu suất của mô hình của chúng tôi. Bảng 3 cho
thấy rằng template cuối cùng được trình bày trong
Bảng C.3 tốt hơn trong hầu hết tất cả các tác vụ.
Template này, "<Văn bản Gốc>, nói cách khác
<Diễn giải>", sử dụng một câu hoàn chỉnh và cụ
thể, không giống như các template khác, sử dụng
các token cụ thể, như "[Gốc]", để phân biệt giữa
phiên bản gốc và diễn giải. Ngoài ra, chúng tôi so
sánh các template hướng dẫn khác nhau được trình
bày trong Bảng C.4. Vì chúng tôi muốn báo cáo
kết quả tốt nhất của chúng tôi trong mỗi tác vụ ở
đây, chúng tôi đã sử dụng template minh họa tốt
nhất cho bất kỳ tác vụ cụ thể nào, được xác định
trong Bảng 3. Bảng 4 cho thấy rằng template thứ
tư đạt được hiệu suất tốt nhất, vì nó mô tả chính
xác tác vụ với hướng dẫn của nó "Tạo ra một diễn
giải của văn bản sau đây sử dụng các từ và cấu trúc
câu khác nhau trong khi vẫn truyền đạt cùng ý nghĩa".
Tác vụ w/o Hướng dẫn Số Template
1 2 3 4 5
SST-2 92.4 93.1 93 92.8 93.2 92.7
SST-5 54.1 54.7 54.5 54.2 54.9 54.3
MNLI 66.9 67.8 67.5 67.1 68.2 67.2
CoLA 13.6 13.1 13.2 12.6 13.3 12.8
QNLI 69.3 69.8 70.1 69.5 70.2 69.6
CR 92.2 93.1 92.8 92.6 93.3 92.4
Bảng 4: Hiệu suất của các template hướng dẫn prompt
diễn giải khác nhau trên nhiều tác vụ NLP khác nhau.
5 Kết luận
Các thí nghiệm của chúng tôi đã chứng minh hiệu
quả của việc sử dụng diễn giải ít mẫu như một phương
pháp tăng cường dữ liệu cho tinh chỉnh dựa trên
prompt tương phản của PLM. Nó vượt trội hơn các
phương pháp tăng cường dữ liệu khác trong các
tác vụ phân loại văn bản, như EDA, nhiều template,
và dịch ngược. Chúng tôi cũng phát hiện ra rằng
phương pháp của chúng tôi hiệu quả với các mô
hình GPT-3 hoặc OPT-175b trong việc tạo ra diễn
giải. Nhìn chung, LM-CPPF cải thiện hiệu suất của
LM-BFF bằng biên độ lớn sử dụng học tương phản
được áp dụng trên các diễn giải được tạo ra bởi
LLM.

--- TRANG 6 ---
Hạn chế
Phương pháp của chúng tôi dựa vào hiệu suất của
diễn giải ít mẫu. Điều này dẫn đến hai hạn chế cho
phương pháp của chúng tôi. Một hạn chế là khó
khăn trong việc truy cập các mô hình GPT-3 và
OPT-175b. Những mô hình này hiện tại cần phải
có sẵn rộng rãi hơn. OPT-175B có phiên bản miễn
phí nhưng nó rất chậm. Một hạn chế khác là nhu
cầu về các minh họa được chú thích cho diễn giải
ít mẫu. Mặc dù có các mô hình và công cụ có sẵn,
như QuillBot, có thể được sử dụng cho mục đích
này, chất lượng của chúng không thể so sánh được
với GPT-3 và OPT-175b. Điều này có thể hạn chế
sức mạnh của những công cụ này trong phương
pháp của chúng tôi. Sử dụng kiến thức con người
để diễn giải minh họa có thể giúp những mô hình
lớn này tạo ra các diễn giải chất lượng cao nhưng
nó tốn kém.
Tuyên bố Đạo đức
Nghiên cứu được tiến hành trong bài báo này đã
được thực hiện phù hợp với các nguyên tắc đạo
đức của ACL. Chúng tôi đã đảm bảo rằng các thí
nghiệm của chúng tôi không gây hại cho bất kỳ cá
nhân hoặc nhóm nào và đã có được sự đồng ý được
thông báo từ tất cả các tham gia viên. Như đã đề
cập trong bài báo, chúng tôi cũng đã cố gắng dựa
vào thí nghiệm chính của chúng tôi trên lựa chọn
thân thiện với môi trường hơn, OPT-175B.
Tài liệu tham khảo
Amirhossein Abaskohi, Fatemeh Mortazavi, và Hadi
Moradi. 2022. Nhận dạng giọng nói tự động cho
đánh giá giọng nói của trẻ em mẫu giáo Ba Tư.
arXiv preprint arXiv:2203.12886 .
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, et al. 2020a. Các mô hình ngôn ngữ là những
người học ít mẫu. Advances in neural information processing
systems , 33:1877–1901.
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-V oss,
Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
Clemens Winter, Christopher Hesse, Mark Chen, Eric
Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
Jack Clark, Christopher Berner, Sam McCandlish,
Alec Radford, Ilya Sutskever, và Dario Amodei.
2020b. Các mô hình ngôn ngữ là những người học ít mẫu.
Ting Chen, Simon Kornblith, Mohammad Norouzi, và
Geoffrey Hinton. 2020. Một framework đơn giản cho
học tương phản của biểu diễn thị giác. Trong International conference on machine learning , trang
1597–1607. PMLR.
Cheng-Han Chiang, Yung-Sung Chuang, và Hung-yi
Lee. 2022. Những tiến bộ gần đây trong các mô hình
ngôn ngữ được huấn luyện trước: Tại sao chúng hoạt
động và chúng hoạt động như thế nào. Trong Proceedings of the 2nd Conference of the Asia-Pacific
Chapter of the Association for Computational Lin-
guistics and the 12th International Joint Conference
on Natural Language Processing: Tutorial Abstracts ,
trang 8–15, Taipei. Association for Computational
Linguistics.
Marcos V Conde và Kerem Turgutlu. 2021. Clip-art:
Huấn luyện trước tương phản cho phân loại nghệ
thuật tinh tế. Trong Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition , trang
3956–3960.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, và
Kristina Toutanova. 2018. Bert: Huấn luyện trước
các transformer hai chiều sâu để hiểu ngôn ngữ. arXiv preprint arXiv:1810.04805 .
Tianyu Gao, Adam Fisch, và Danqi Chen. 2020.
Làm cho các mô hình ngôn ngữ được huấn luyện
trước trở thành những người học ít mẫu tốt hơn. arXiv preprint arXiv:2012.15723 .
Tianyu Gao, Adam Fisch, và Danqi Chen. 2021.
Làm cho các mô hình ngôn ngữ được huấn luyện
trước trở thành những người học ít mẫu tốt hơn.
Trong Proceedings of the 59th Annual Meet-
ing of the Association for Computational Linguistics
and the 11th International Joint Conference on Natu-
ral Language Processing (Volume 1: Long Papers) ,
trang 3816–3830.
Sonal Garg, Sumanth Prabhu, Hemant Misra, và
G Srinivasaraghavan. 2021. Tạo ra diễn giải ngữ
cảnh không giám sát sử dụng kiểm soát từ vựng và
học tăng cường. arXiv preprint
arXiv:2103.12777 .
Xu Han, Weilin Zhao, Ning Ding, Zhiyuan Liu, và
Maosong Sun. 2021. Ptr: Điều chỉnh prompt với
quy tắc cho phân loại văn bản.
Chaitra Hegde và Shrikumar Patil. 2020. Tạo ra diễn
giải không giám sát sử dụng các mô hình ngôn ngữ
được huấn luyện trước. arXiv preprint arXiv:2006.05477 .
Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski,
Bruna Morrone, Quentin De Laroussilhe, Andrea
Gesmundo, Mona Attariyan, và Sylvain Gelly. 2019.
Học chuyển giao hiệu quả tham số cho nlp. Trong International Conference on Machine Learning , trang
2790–2799. PMLR.
Yiren Jian, Chongyang Gao, và Soroush V osoughi.
2022. Học tương phản cho những người học ngôn
ngữ ít mẫu dựa trên prompt. Trong Proceedings of the 2022
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies , trang 5577–5587, Seattle,
United States. Association for Computational Lin-
guistics.

--- TRANG 7 ---
Vlado Keselj. 2009. Xử lý giọng nói và ngôn ngữ
daniel jurafsky và james h. martin (đại học stanford
và đại học colorado tại boulder) pearson
prentice hall, 2009, xxxi+ 988 pp; bìa cứng, isbn
978-0-13-187321-6.
Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron
Sarna, Yonglong Tian, Phillip Isola, Aaron
Maschinot, Ce Liu, và Dilip Krishnan. 2020. Học
tương phản có giám sát. Advances in Neural
Information Processing Systems , 33:18661–18673.
Alex Krizhevsky. 2014. Một thủ thuật kỳ lạ để song
song hóa các mạng nơ-ron tích chập. arXiv preprint
arXiv:1404.5997 .
Ashutosh Kumar, Satwik Bhattamishra, Manik Bhan-
dari, và Partha Talukdar. 2019. Tối ưu hóa submodular-
based diễn giải đa dạng và hiệu quả của nó trong
tăng cường dữ liệu. Trong Proceedings of
the 2019 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, Volume 1 (Long and
Short Papers) , trang 3609–3619, Minneapolis, Min-
nesota. Association for Computational Linguistics.
Phuc H Le-Khac, Graham Healy, và Alan F Smeaton.
2020. Học biểu diễn tương phản: Một framework
và đánh giá. Ieee Access , 8:193907–193934.
Shikun Liu, Shuaifeng Zhi, Edward Johns, và An-
drew J Davison. 2021. Bootstrap phân đoạn ngữ
nghĩa với tương phản khu vực. arXiv preprint
arXiv:2104.04465 .
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, và Veselin Stoyanov. 2019.
Roberta: Một phương pháp huấn luyện trước bert
được tối ưu hóa mạnh mẽ. arXiv preprint arXiv:1907.11692 .
Mengsay Loem, Sho Takase, Masahiro Kaneko, và
Naoaki Okazaki. 2022. ExtraPhrase: Tăng cường
dữ liệu hiệu quả cho tóm tắt trừu tượng. Trong Pro-
ceedings of the 2022 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies: Student
Research Workshop , trang 16–24, Hybrid: Seattle,
Washington + Online. Association for Computational
Linguistics.
Deshui Miao, Jiaqi Zhang, Wenbo Xie, Jian Song, Xin
Li, Lijuan Jia, và Ning Guo. 2021. Học đối kháng
biểu diễn tương phản đơn giản cho các tác vụ nlp. arXiv preprint arXiv:2111.13301 .
Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya
Sutskever, et al. 2018. Cải thiện hiểu biết ngôn ngữ
bằng huấn luyện trước sinh.
Aurko Roy và David Grangier. 2019. Diễn giải không
giám sát mà không cần dịch thuật. arXiv preprint
arXiv:1905.12752 .Timo Schick và Hinrich Schütze. 2020a. Khai thác
các câu hỏi cloze cho phân loại văn bản ít mẫu và
suy luận ngôn ngữ tự nhiên. arXiv preprint
arXiv:2001.07676 .
Timo Schick và Hinrich Schütze. 2020b. Không chỉ
là kích thước quan trọng: Các mô hình ngôn ngữ
nhỏ cũng là những người học ít mẫu. arXiv preprint arXiv:2009.07118 .
Rico Sennrich, Barry Haddow, và Alexandra Birch.
2016. Cải thiện các mô hình dịch máy nơ-ron với
dữ liệu đơn ngữ. Trong Proceedings of the 54th
Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers) , trang 86–96,
Berlin, Germany. Association for Computational Lin-
guistics.
AB Siddique, Samet Oymak, và Vagelis Hristidis.
2020. Diễn giải không giám sát thông qua học tăng
cường sâu. Trong Proceedings of the 26th ACM
SIGKDD International Conference on Knowledge
Discovery & Data Mining , trang 1800–1809.
Jake Snell, Kevin Swersky, và Richard Zemel. 2017.
Mạng nguyên mẫu cho học ít mẫu. Advances in neural information processing systems , 30.
Amane Sugiyama và Naoki Yoshinaga. 2019. Tăng
cường dữ liệu sử dụng dịch ngược cho dịch máy
nơ-ron nhận biết ngữ cảnh. Trong Proceedings
of the Fourth Workshop on Discourse in Machine
Translation (DiscoMT 2019) , trang 35–44.
Flood Sung, Yongxin Yang, Li Zhang, Tao Xiang,
Philip HS Torr, và Timothy M Hospedales. 2018.
Học so sánh: Mạng quan hệ cho học ít mẫu. Trong Proceedings of the IEEE conference
on computer vision and pattern recognition , trang
1199–1208.
Yonglong Tian, Dilip Krishnan, và Phillip Isola. 2020.
Mã hóa đa góc nhìn tương phản. Trong European confer-
ence on computer vision , trang 776–794. Springer.
Jianing Wang, Chengyu Wang, Fuli Luo, Chuanqi Tan,
Minghui Qiu, Fei Yang, Qiuhui Shi, Songfang Huang,
và Ming Gao. 2022. Hướng tới điều chỉnh prompt
thống nhất cho phân loại văn bản ít mẫu.
Jason Wei và Kai Zou. 2019. eda: Các kỹ thuật tăng
cường dữ liệu dễ dàng để tăng cường hiệu suất trên
các tác vụ phân loại văn bản. arXiv preprint arXiv:1901.11196 .
John Wieting và Kevin Gimpel. 2018. ParaNMT-50M:
Đẩy giới hạn của các embedding câu diễn giải với
hàng triệu bản dịch máy. Trong Pro-
ceedings of the 56th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers) , trang 451–462, Melbourne, Australia. As-
sociation for Computational Linguistics.
Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Lu-
ong, và Quoc V . Le. 2020. Tăng cường dữ liệu không
giám sát cho huấn luyện nhất quán.

--- TRANG 8 ---
Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-
bonell, Russ R Salakhutdinov, và Quoc V Le. 2019.
Xlnet: Huấn luyện trước tự hồi quy tổng quát cho
hiểu biết ngôn ngữ. Advances in neural informa-
tion processing systems , 32.
Yuan Yao, Bowen Dong, Ao Zhang, Zhengyan Zhang,
Ruobing Xie, Zhiyuan Liu, Leyu Lin, Maosong Sun,
và Jianyong Wang. 2022. Điều chỉnh prompt cho
các mô hình ngôn ngữ được huấn luyện trước phân
biệt. arXiv preprint arXiv:2205.11166 .
Susan Zhang, Stephen Roller, Naman Goyal, Mikel
Artetxe, Moya Chen, Shuohui Chen, Christopher De-
wan, Mona Diab, Xian Li, Xi Victoria Lin, et al. 2022.
opt: Các mô hình ngôn ngữ transformer được huấn
luyện trước mở. arXiv preprint arXiv:2205.01068 .
Jianing Zhou và Suma Bhat. 2021. Tạo ra diễn giải:
Một khảo sát về tình trạng hiện tại của nghệ thuật.
Trong Proceedings of the 2021 Conference on Empirical Methods in
Natural Language Processing , trang 5075–5086.
Jie Zhou, Le Tian, Houjin Yu, Zhou Xiao, Hui Su, và
Jie Zhou. 2022. Điều chỉnh prompt liên tục dẫn dắt
bối cảnh kép cho học ít mẫu. Trong Findings of
the Association for Computational Linguistics: ACL
2022 , trang 79–84, Dublin, Ireland. Association for
Computational Linguistics.
Hongyu Zhu, Yan Chen, Jing Yan, Jing Liu, Yu Hong,
Ying Chen, Hua Wu, và Haifeng Wang. 2022.
DuQM: Một tập dữ liệu tiếng Trung các câu hỏi tự
nhiên bị nhiễu loạn ngôn ngữ học để đánh giá độ
mạnh mẽ của các mô hình khớp câu hỏi. Trong Proceedings of the
2022 Conference on Empirical Methods in Natu-
ral Language Processing , trang 7782–7794, Abu
Dhabi, United Arab Emirates. Association for Com-
putational Linguistics.
A Thiết lập Đánh giá
Chúng tôi đã sử dụng tốc độ học 1e−5 cho loss MLM
như LM-BFF. Mặc dù các thuật toán học tương phản
thường hoạt động tốt hơn với huấn luyện batch lớn
hơn, do hạn chế tài nguyên, chúng tôi phải sử dụng
một nửa kích thước batch được đề xuất trong Jian
et al. (2022) cho nhiều tác vụ khác nhau trong giai
đoạn SCL. Như được khuyến nghị trong Krizhevsky
(2014), chúng tôi đã sử dụng sqrt(0.5)≈0.7 của tốc
độ học được đề cập trong Jian et al. (2022) cho giai
đoạn này. Do đó, chúng tôi báo cáo các baseline với
kích thước batch nhỏ hơn của chúng tôi. Phương
pháp của chúng tôi sử dụng một template duy nhất
cho dự đoán của mỗi tác vụ. Các prompt chính được
liệt kê trong Phụ lục B. Đối với các prompt được
sử dụng trong giai đoạn diễn giải, ngoại trừ các thí
nghiệm trong Phần 4.3, chúng tôi đã sử dụng các
template được chọn ngẫu nhiên từ các prompt được
đề xuất được liệt kê trong Bảng C.3. Trong tất cả
các thí nghiệm, chúng tôi đã sử dụng OPT-175B,
ngoại trừ một trong những kết quả được đề cập trong
Phần 4.1, nơi chúng tôi so sánh OPT-175B và GPT-3
trong diễn giải.
Chúng tôi hiển thị kích thước batch và tốc độ học
cho SupCon trong Bảng A.1. Quan trọng là phải lưu
ý rằng kết quả của LM-BFF được trình bày trong
bài báo chính đã được thu được bằng cách sử dụng
cùng kích thước batch lớn như phương pháp của
chúng tôi để đảm bảo so sánh công bằng.
Chúng tôi đã tinh chỉnh với kích thước batch phù
hợp với bộ nhớ GPU và có thể chia hết cho tổng số
ví dụ trong tác vụ. Các thí nghiệm được tiến hành
trên một NVIDIA RTX-3090 với bộ nhớ 24 GB sử
dụng mô hình RoBERTa-base. Hơn nữa, theo LM-BFF,
chúng tôi đã tinh chỉnh tối đa 1000 bước.
Tác vụ Kích thước Batch Tốc độ Học
SST-2 8 7e−7
SST-5 20 7e−6
MNLI 12 7e−6
CoLA 8 7e−6
QNLI 8 7e−6
CR 16 7e−6
Bảng A.1: Kích thước batch và tốc độ học cho loss SupCon
được sử dụng cho mỗi tác vụ.
Đối với các thí nghiệm GPT-2 trong Bảng 1, chúng
tôi đã làm theo cùng hướng dẫn để tạo ra diễn giải
như chúng tôi đã sử dụng cho GPT-3 và OPT-175.
Trong việc tinh chỉnh GPT-2, chúng tôi đã tinh chỉnh
mô hình của chúng tôi trên ParaNMT-50M (Wieting
và Gimpel, 2018) với kích thước batch 32 và tốc độ
học 1e−3 trong 5 epoch.
B Prompt Tác vụ
Các prompt chính được sử dụng cho mỗi tác vụ trong
các thí nghiệm của chúng tôi được hiển thị trong
Bảng B.2. Chúng được chọn thủ công bởi LM-BFF
(Gao et al., 2021).
C Prompt Diễn giải
Để tìm prompt tốt nhất cho diễn giải, chúng tôi đã
kiểm tra các corpus khác nhau có sẵn trực tuyến và
tìm hiểu cách các ví dụ diễn giải được giới thiệu.
Chúng tôi đã tạo ra prompt của chúng tôi bằng cách
sử dụng thông tin này và sửa đổi thủ công của chúng
tôi trong những template này.
Trong prompt minh họa này, chúng tôi không cung
cấp bất kỳ giải thích hoặc mô tả nào về phép biến
đổi cụ thể được áp dụng cho đầu vào để tạo ra đầu
ra. Thay vào đó, chúng tôi đã gắn nhãn mẫu gốc và
diễn giải của nó. Ví dụ, chúng tôi đã sử dụng token
[Gốc] để chỉ ra câu gốc trong tập dữ liệu và token
[Diễn giải] để chỉ ra

--- TRANG 9 ---
Tác vụ Template Verbalizer
SST-2 <S1>Nó là [MASK] . tích cực: tuyệt vời, tiêu cực: khủng khiếp
SST-5 <S1>Nó là [MASK] . rất tích cực: tuyệt vời, tích cực: tốt, trung lập: ổn, tiêu cực: tệ, rất tiêu cực: khủng khiếp
MNLI <S1>? [MASK] , <S2> kéo theo: Có, trung lập: Có thể, mâu thuẫn: Không
CoLA <S1>Điều này là [MASK] . đúng ngữ pháp: chính xác, không đúng ngữ pháp: không chính xác
QNLI <S1>? [MASK] , <S2> kéo theo: Có, không kéo theo: Không
CR <S1>Nó là [MASK] . tích cực: tuyệt vời, tiêu cực: khủng khiếp
Bảng B.2: Các template và verbalizer chính (từ nhãn) được sử dụng trong các thí nghiệm của chúng tôi.
mẫu được diễn giải. Bảng C.3 hiển thị các template
chúng tôi đã sử dụng cho phương pháp này.
Template Minh họa
Gốc:<Văn bản Gốc>
Diễn giải:<Văn bản Diễn giải>
[Gốc]:<Văn bản Gốc>
[Diễn giải]:<Văn bản Diễn giải>
Gốc:<Văn bản Gốc>
Viết lại:<Văn bản Diễn giải>
[Gốc]:<Văn bản Gốc>
[Viết lại]:<Văn bản Diễn giải>
Đây là nguồn gốc: <Văn bản Gốc>
Đây là diễn giải: <Văn bản Diễn giải>
<Văn bản Gốc>, nói cách khác <Văn bản
Diễn giải>
Bảng C.3: Các template được sử dụng để đưa ra ví
dụ về cách diễn giải nên được thực hiện cho mô hình
ngôn ngữ được huấn luyện trước.
Trong hướng dẫn cho prompt, chúng tôi đã cung
cấp các ví dụ và hướng dẫn đơn giản cho các mô
hình ngôn ngữ. Các hướng dẫn được sử dụng để
yêu cầu mô hình tạo ra diễn giải trước khi trình bày
chúng với các ví dụ. Bảng C.4 hiển thị các hướng
dẫn chúng tôi đã sử dụng để giải thích tác vụ cho
mô hình ở đầu prompt của chúng tôi.
D Chi tiết Tinh chỉnh dựa trên Prompt Tương phản
Tinh chỉnh dựa trên prompt tương phản bao gồm
hai bước chính: (1) Mô hình Ngôn ngữ Có mặt nạ
và (2) Học Tương phản.
Loss Mô hình Ngôn ngữ Có mặt nạ (MLM). Một
tác vụ phân loại được tiếp cận như một vấn đề Mô
hình Ngôn ngữ Có mặt nạ (MLM) trong các phương
pháp dựa trên prompt. Đầu vào bao gồm một câu
(sent) và một template với một mặt nạ (temp) (tức
là, xprompt = sent, temp ([MASK ])), và mục tiêu
là xác định token tốt nhất để điền vào [MASK ].
Điều này dẫn đến một loss MLM, được biểu diễn
là LMLM = MLM (xprompt , y), trong đó y là nhãn
từ được liên kết với xprompt . LM-BFF (Gao et al.,
2021) sử dụng các minh họa của từ nhãn để cải
thiện kết quả. Đầu vào cho phương pháp này bao
gồm câu ( sent 0) và template có mặt nạ ( temp 0)
với một mặt nạ ([MASK]. Đầu vào cũng chứa một
câu bổ sung ( sent i) với cùng template (temp 0)
với verbalizer riêng của nó ( word i) cho những câu
đó. Các từ nhãn được lấy mẫu từ tập huấn luyện.
Loss phân loại sau đó được tính toán sử dụng đầu
vào này.
Mô hình ngôn ngữ trước tiên mã hóa câu đầu vào
xin thành một chuỗi các token, sau đó được ánh xạ
thành một chuỗi các trạng thái ẩn h1, h2, ..., h L.
L biểu thị độ dài của chuỗi, và chiều của các trạng
thái ẩn được ký hiệu bởi d. Ví dụ, trong tinh chỉnh
dựa trên prompt, nếu câu đầu vào ( xin) là "Pháp
đã bỏ lỡ world cup trong đá luân lưu," prompt tương
ứng xprompt sẽ là [CLS] xin,[MASK ].[SEP]. Mô
hình sau đó xác định liệu có khả năng hơn để đặt
verbalizer thích hợp tại vị trí [MASK]. Đã được
phát hiện rằng tinh chỉnh với framework điền chỗ
trống này vượt trội hơn tinh chỉnh tiêu chuẩn. Dự
đoán của mô hình M cho một lớp y∈ Y có thể được
biểu thị bằng cách ánh xạ không gian nhãn Y thành
Hướng dẫn
Tóm tắt văn bản sau đây bằng từ ngữ của riêng bạn
Viết lại văn bản sau đây biểu thị cùng ý tưởng theo
cách khác
Tạo ra một diễn giải của văn bản sau đây biểu thị
cùng ý tưởng theo cách khác
Tạo ra một diễn giải của văn bản sau đây sử dụng
các từ và cấu trúc câu khác nhau trong khi vẫn truyền
đạt cùng ý nghĩa
Tạo ra một bản tóm tắt hoặc diễn giải của văn bản
sau đây nắm bắt bản chất của các ý tưởng một cách
ngắn gọn
Bảng C.4: Các hướng dẫn được sử dụng trước khi đưa
ra ví dụ cho mô hình ngôn ngữ để mô tả tác vụ diễn
giải.
các từ nhãn, trong đó V(y) biểu diễn từ nhãn cho
lớp y. Điều này có thể được viết là:
p(y|xin) =p([MASK ] =V(y)|xin)
=exp(wV(y).h[MASK ])P
y′∈Yexp(wV(y′).h[MASK ])(1)
trong đó vector trọng số của đầu MLM được ký hiệu
bởi w.
Trong LM-BFF, các tác giả thêm các minh họa
vào đầu vào xprompt để cải thiện hiểu biết của mô
hình về verbalizer. Kết quả là, đầu vào cho LM-BFF
có dạng sau:
T(xin)⊕ T(x1
in, y1)⊕...⊕ T(xk
in, yk)(2)
trong đó T(xi
in, yi) minh họa minh họa thứ i trong
template mathcalT với nơi verbalizer thực tế của
các mẫu thay thế [MASK]. Ngoài ra, k là số lượng
minh họa chúng tôi muốn sử dụng trong prompt
của chúng tôi. Bài báo này sử dụng lấy mẫu ngẫu
nhiên để chọn các minh họa từ tập huấn luyện. Loss
MLM được tính toán như sau:
LMLM =X
(xin,y)∈Dtrain−log[p(y|xin)](3)
Loss Tương phản Có giám sát. Học Tương phản
Có giám sát là một dạng cụ thể của học tương phản
(Chen et al., 2020; Tian et al., 2020; Liu et al.,
2021) nhóm hai batch được tăng cường ở cấp độ
lớp trong không gian đặc trưng và tính toán loss
tương phản sử dụng Phương trình 4:
LSupCon = (x′
1, x′
2, y) (4)
trong đó x′
1 và x′
2 là phiên bản được tăng cường của
batch đầu vào x và y là nhãn thực tế của batch.
Để sử dụng SupCon trên nhiều góc nhìn của một
văn bản đầu vào, trước tiên chúng ta cần có được
hai góc nhìn của văn bản:
xin1=T(sent)⊕ T(demo 1)⊕ T(demo 2)(5)
xin2=T(Par(sent))⊕T(demo 3)⊕T(demo 4)
(6)
trong đó xin1 giống như xprompt +demo trong LM-
BFF và T là một hàm định dạng câu theo một template
cụ thể. Thay vì sử dụng một template mới trong đó
mẫu mới được tạo ra không cung cấp một góc nhìn
mới, chúng tôi sử dụng hàm diễn giải ít mẫu ( Par).
Ngoài ra, verb đại diện cho verbalizer được sử dụng
cho nhãn thực tế của mẫu. Bây giờ sử dụng Phương
trình 4 trên hai góc nhìn, chúng ta có thể tính toán
tổng loss:
LTotal =LSupCon +LMLM (7)
Thuật toán D.1 hiển thị tổng quan về phương pháp
của chúng tôi sử dụng tinh chỉnh ít mẫu tương phản
với diễn giải ít mẫu. Quan trọng là phải đề cập rằng
học từ LSupCon đòi hỏi một lượt truyền xuôi và
ngược bổ sung, làm tăng chi phí tính toán lên hệ
số 1.5. Tuy nhiên, chi phí vẫn giống như mô hình
của Jian et al. (2022) do độ phức tạp thời gian O(1)
của hàm Diễn giải. Hình 1 hiển thị quy trình tinh
chỉnh cho một mẫu prompt và góc nhìn mới của nó
được tạo ra bằng diễn giải ít mẫu.

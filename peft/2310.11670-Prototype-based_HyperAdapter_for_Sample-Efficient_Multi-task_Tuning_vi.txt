# Prototype-based HyperAdapter cho Điều chỉnh Đa nhiệm vụ Hiệu quả Mẫu

Hao Zhao1∗ Jie Fu2∗† Zhaofeng He1†
1Đại học Bưu chính Viễn thông Bắc Kinh 2Đại học Khoa học và Công nghệ Hồng Kông
{haozhao,zhaofenghe}@bupt.edu.cn jiefu@ust.hk

## Tóm tắt

Điều chỉnh tinh vi hiệu quả tham số đã cho thấy hiệu quả trong việc thích ứng các mô hình ngôn ngữ được huấn luyện trước với các nhiệm vụ hạ nguồn trong khi chỉ cập nhật một số lượng nhỏ tham số. Mặc dù thành công, hầu hết các phương pháp hiện tại đều thích ứng độc lập với từng nhiệm vụ mà không xem xét việc chuyển giao kiến thức giữa các nhiệm vụ và bị hạn chế trong các chế độ dữ liệu thấp. Để khắc phục vấn đề này, chúng tôi đề xuất Prototype-based HyperAdapter (PHA), một khung mới được xây dựng trên adapter-tuning và hypernetwork. Nó giới thiệu một bộ truy xuất dense-instance và một hypernetwork nguyên mẫu để tạo ra các mô-đun có điều kiện theo cách hiệu quả mẫu. Điều này dẫn đến những cải thiện hiệu suất tương đương so với các phương pháp điều chỉnh tinh vi hiệu quả tham số hiện tại về học đa nhiệm vụ và học chuyển giao ít mẫu. Quan trọng hơn, khi kích thước dữ liệu có sẵn trở nên nhỏ hơn, phương pháp của chúng tôi vượt trội hơn các baseline mạnh khác với biên độ lớn. Dựa trên các thí nghiệm thực nghiệm mở rộng của chúng tôi trên nhiều bộ dữ liệu khác nhau, chúng tôi chứng minh rằng PHA đạt được sự cân bằng tốt hơn giữa các tham số có thể huấn luyện, độ chính xác trên các nhiệm vụ stream và hiệu quả mẫu. Mã nguồn của chúng tôi có sẵn công khai tại https://github.com/Bumble666/PHA

## 1 Giới thiệu

Điều chỉnh tinh vi một mô hình ngôn ngữ được huấn luyện trước (PLM) mang lại tiềm năng phi thường cho việc thích ứng đồng thời với nhiều nhiệm vụ hạ nguồn trong một thiết lập đa nhiệm vụ. Tuy nhiên, điều chỉnh tinh vi tất cả các tham số của mô hình gây ra chi phí lưu trữ và triển khai đáng kể, đặc biệt khi kích thước mô hình được huấn luyện trước đang tăng nhanh. Để giải quyết vấn đề này, một số công trình (Houlsby et al., 2019; Lester et al., 2021; Karimi Mahabadi et al., 2021a; Hu et al., 2022; Ding et al., 2022; Gui and Xiao, 2023; Zeng et al., 2023; Liao et al., 2023; Xie and Lukasiewicz, 2023) đã phát triển điều chỉnh tinh vi hiệu quả tham số để huấn luyện các mô-đun compact mỗi nhiệm vụ và thích ứng PLM với các nhiệm vụ hạ nguồn.

Tuy nhiên, các phương pháp này yêu cầu học các mô-đun khác nhau để thích ứng với các nhiệm vụ đa dạng, và chi phí tham số tăng tỷ lệ với số lượng nhiệm vụ. Mặt khác, việc huấn luyện các mô-đun cụ thể cho từng nhiệm vụ riêng biệt không thể thu được lợi ích từ các nhiệm vụ liên quan khác.

Công trình gần đây (Karimi Mahabadi et al., 2021b; Ivison and Peters, 2022) đã đề xuất huấn luyện một hypernetwork để tạo ra các tham số của những mô-đun này nhằm đạt được sự cân bằng tốt hơn giữa hiệu quả tham số và thích ứng cho các nhiệm vụ hạ nguồn. Các phương pháp này khuyến khích mô hình học đa nhiệm vụ nắm bắt thông tin chia sẻ bằng cách tận dụng hypernetwork được chia sẻ giữa các nhiệm vụ trong khi loại bỏ sự can thiệp tiêu cực của nhiệm vụ bằng cách tạo ra các mô-đun có điều kiện riêng lẻ. Mặc dù thành công của các phương pháp này trong học đa nhiệm vụ, vẫn còn một số vấn đề: (1) các phương pháp dựa trên hypernetwork thường tối ưu hóa embedding cụ thể và hypernetwork được chia sẻ cùng nhau bằng huấn luyện đầu cuối-đầu cuối mà không có bất kỳ regularization nào. Thông tin cụ thể cho nhiệm vụ bị đan xen không thể tách rời, điều này ức chế hiệu quả của hypernetwork, đặc biệt trong các thiết lập hạn chế tài nguyên. (2) các phương pháp hiện tại này tổng quát hóa cho các nhiệm vụ mới đòi hỏi kiến thức tiên nghiệm cụ thể cho nhiệm vụ hoặc kiến thức từ các mô hình được huấn luyện trước đông lạnh.

Các công trình này (Karimi Mahabadi et al., 2021b; Pfeiffer et al., 2023) chỉ ra rằng hypernetwork được chia sẻ giữa các nhiệm vụ đóng vai trò là bộ thu thập thông tin xuyên nhiệm vụ, trong khi một embedding cụ thể nên bao gồm các đặc trưng ngữ nghĩa cấp nhiệm vụ để trích xuất thông tin liên quan từ hypernetwork để tạo ra các tham số mô-đun tương ứng. Theo kinh nghiệm, các đặc trưng cấp nhiệm vụ thường được biểu diễn ngầm định bởi các đặc trưng instance liên quan. Một ý tưởng tự nhiên để khuyến khích việc tạo embedding là tính toán các điểm trung tâm (nguyên mẫu) của các đặc trưng instance cụ thể cho nhiệm vụ.

Trong bài báo này, chúng tôi giới thiệu Prototype-based HyperAdapter(PHA), một khung mới được xây dựng trên adapter-tuning để đạt được cả học đa nhiệm vụ và tổng quát hóa cho các nhiệm vụ mới theo cách hiệu quả mẫu. Như được mô tả trong Hình 1, PHA bao gồm hai thành phần chính, Instance-dense Retriever và Prototypical HyperNetworks. Phần đầu tiên nhằm huấn luyện một bộ truy xuất để phân biệt các instance từ các nhiệm vụ khác nhau trong không gian embedding. Đối với phần thứ hai, chúng tôi nhằm ước tính các nguyên mẫu cụ thể cho nhiệm vụ với các đặc trưng cấp instance và giữ các nguyên mẫu làm embedding để được huấn luyện với hypernetwork.

Cụ thể, chúng tôi chiếu các đặc trưng instance được mã hóa vào không gian embedding bằng cách sử dụng bộ truy xuất. Để tránh sự can thiệp của các instance trong không gian embedding, chúng tôi huấn luyện bộ truy xuất với bộ ước tính InfoNCE (Oord et al., 2018). Kết quả là, nó nhóm các instance trong cùng nhiệm vụ và tăng khoảng cách giữa các instance giữa các nhiệm vụ. Các đặc trưng được chiếu ở đây có thể được coi là các đặc trưng ngữ nghĩa cấp instance được sử dụng để ước tính các embedding cấp nhiệm vụ. Lấy cảm hứng từ PCL (Li et al., 2021), chúng tôi ước tính embedding cụ thể cho nhiệm vụ bằng cách sử dụng loss nguyên mẫu contrastive, điều này khuyến khích các nguyên mẫu trở thành các điểm trung tâm của các đặc trưng cấp instance. So với phương pháp hiện tại, nơi các embedding cụ thể được tối ưu hóa trực tiếp trong quá trình điều chỉnh, phương pháp của chúng tôi học hiệu quả embedding cụ thể với thông tin phụ, điều này giúp tối ưu hóa không gian embedding trong các chế độ dữ liệu thấp. Trong quá trình thích ứng các nhiệm vụ mới, vì chúng tôi duy trì các đặc trưng ngữ nghĩa cấp nhiệm vụ trước đó làm nguyên mẫu phù hợp với các instance trong không gian embedding, chúng tôi khớp nguyên mẫu tương ứng cho nhiệm vụ mới hiện tại bằng cách tính toán khoảng cách giữa các instance mới và các nguyên mẫu trước đó.

Chúng tôi đánh giá PHA trên 13 bộ dữ liệu NLP trên các nhiệm vụ đa dạng. Các thí nghiệm mở rộng cho thấy hiệu quả của PHA, đặc biệt trong các chế độ dữ liệu thấp. Trong khi đó, PHA có thể đạt được thích ứng domain ít mẫu với 4-32 shot. Ví dụ, PHA vượt trội hơn baseline chuyển giao adapter đa nhiệm vụ mạnh bằng 1.0% với tham số có thể huấn luyện thấp hơn trên benchmark GLUE. Trong các chế độ tài nguyên thấp nơi chỉ có 100 mẫu mỗi nhiệm vụ từ benchmark GLUE, PHA vượt trội hơn adapter-tuning bằng 8.0%. Phân tích của chúng tôi cho thấy rằng PHA nắm bắt hiệu quả thông tin cụ thể và thông tin chia sẻ trong khi giảm chuyển giao tiêu cực. Chúng tôi cũng trình bày một phân tích chi tiết để chứng minh rằng các instance từ các nhiệm vụ khác nhau có thể được xác định bởi các nguyên mẫu tương ứng và được sử dụng để thích ứng nhiệm vụ mới.

## 2 Nền tảng

**HyperNetworks.** Một hypernetwork (Ha et al., 2017) có thể tạo ra các tham số để được sử dụng bởi các mạng hoặc mô-đun. Cụ thể, hypernetwork, được ký hiệu là hw, tận dụng một embedding I để tạo ra các tham số mô-đun φ:

φ = hw(I)                                                 (1)

**Adapter.** Adapter (Houlsby et al., 2019) thường được sử dụng trong điều chỉnh hiệu quả tham số nhằm áp dụng PLM cho các nhiệm vụ hạ nguồn. Cụ thể, điều chỉnh dựa trên adapter chèn các mô-đun có thể huấn luyện cụ thể cho nhiệm vụ vào các lớp transformer, trong khi giữ PLM cố định. Adapter Al(x) cho lớp l được định nghĩa là:

Al(x) = Dl(ReLU((Ul(x))) + x,                           (2)

trong đó Dl ∈ Rd×b và Ul ∈ Rb×d là các ma trận chiếu xuống/lên. x ∈ Rd đề cập đến đầu vào. d là chiều ẩn của PLM, b là kích thước bottleneck thỏa mãn b ≪ d.

He et al. (2022a) đề xuất sử dụng adapter song song, khác với phương pháp chèn tuần tự truyền thống. Họ chứng minh điều chỉnh tinh vi hiệu quả tham số hiệu quả hơn mà adapter song song cung cấp.

## 3 Phương pháp

**Thiết lập Bài toán.** Chúng tôi đang theo một bài toán học đa nhiệm vụ tổng quát. Cho một mô hình ngôn ngữ được huấn luyện trước Mθ với tham số θ và một tập hợp các nhiệm vụ mục tiêu {D} = {D1, D2, ..., Dτ}, trong đó τ là tổng số nhiệm vụ và {Di} = {xni, yni}Ni n=1 biểu diễn dữ liệu huấn luyện của nhiệm vụ thứ i với Ni mẫu. Mục tiêu chính của nghiên cứu của chúng tôi là điều chỉnh tinh vi Mθ cho các nhiệm vụ hạ nguồn {D} bằng cách sử dụng thiết lập học đa nhiệm vụ và đảm bảo rằng nó có khả năng tổng quát hóa cho các nhiệm vụ mới.

**Tổng quan Phương pháp.** Ý tưởng chính của phương pháp của chúng tôi là học trực tiếp các embedding nguyên mẫu cho từng nhiệm vụ từ các instance huấn luyện được thu thập bằng cách sử dụng một encoder được chia sẻ giữa các nhiệm vụ, sau đó tạo ra các lớp adapter cụ thể cho nhiệm vụ bằng cách truy xuất embedding nguyên mẫu và đưa nó vào một hypernetwork. Như được hiển thị trong Hình 1, các instance được mã hóa được chiếu thành các vector truy xuất bởi bộ truy xuất instance-dense để học nguyên mẫu. Những nguyên mẫu này đại diện cho thông tin cụ thể cho nhiệm vụ cho phép hypernetwork cập nhật hiệu quả. Điều này có thể cho phép điều chỉnh tinh vi hiệu quả mẫu hơn và học chuyển giao ít mẫu.

### 3.1 Instance-dense Retriever

Chúng tôi định nghĩa một bộ truy xuất instance-dense để tổng quát hóa tốt hơn. Cho hi ∈ Rd biểu thị trạng thái ẩn được pooling trung bình của lớp cuối cùng của mẫu huấn luyện, thuộc về nhiệm vụ thứ i. Để căn chỉnh đặc trưng embedding với mẫu huấn luyện trong không gian tiềm ẩn, một bộ truy xuất instance-dense G(·) được áp dụng để xây dựng vector truy xuất zi = G(hi), trong đó G(·) là một MLP bao gồm hai lớp feed-forward và một phi tuyến tính ReLU. Hơn nữa, chúng tôi cần bộ truy xuất có khả năng khuyến khích rõ ràng việc căn chỉnh giữa các instance từ cùng một nhiệm vụ, cũng như đẩy xa các instance từ các nhiệm vụ khác nhau.

Để học hiệu quả bộ truy xuất phân biệt, chúng tôi giới thiệu hàm loss sau LIR dựa trên InfoNCE:

Li = Σ zi∈D 1/(Ni-1) Σ zj∈D̂i log(exp(f(zi·zj))/Σ zm∈S(i) exp(f(zi·zm))),   (3)

LIR = 1/τ Σ τ i=1 Li,                                    (4)

trong đó Li là mục tiêu học cho nhiệm vụ i, f(·) là hàm tương tự cosine. D̂i là một tập hợp các mẫu dương của zi và S(i) biểu thị một tập hợp các mẫu âm cho zi.

Bộ truy xuất instance-dense tổng hợp thông tin cấp instance từ cùng một nhiệm vụ và cho phép tái sử dụng linh hoạt kiến thức được sử dụng để học chuyển giao ít mẫu.

### 3.2 Prototypical HyperNetworks

Việc đơn giản sử dụng embedding nhiệm vụ đã học để bao gồm thông tin cụ thể cho nhiệm vụ làm thiên vị hypernetwork được chia sẻ giữa các nhiệm vụ để overfit phân phối dữ liệu huấn luyện, có nghĩa là hiệu quả mẫu không đầy đủ và kiến thức hỗn hợp dễ bị tổn thương hơn với những thay đổi trong phân phối trong quá trình chuyển giao xuyên nhiệm vụ.

Để khắc phục vấn đề này, chúng tôi đề xuất khai thác ngầm định thông tin cấp instance để hướng dẫn embedding nhiệm vụ thay vì huấn luyện đầu cuối-đầu cuối. Cụ thể hơn, chúng tôi phát hiện ra rằng công thức contrastive là một chiến lược hiệu quả để học các HyperNetwork mạnh mẽ và hiệu quả mẫu. Trước tiên chúng tôi khởi tạo một tập hợp embedding {ki}τ i=1, trong đó {ki} ∈ Rd là một vector có thể huấn luyện để học thông tin cụ thể của nhiệm vụ thứ i. Mục tiêu học cho một embedding là

Li = Σ zi∈D 1/(Ni-1) log(exp(f(zi·ki))/Σ km∈V(i) exp(f(zi·km))),   (5)

LPro = 1/τ Σ τ i=1 Li,                                   (6)

trong đó V(i) là một tập hợp các embedding âm. Mục tiêu buộc mỗi embedding tận dụng các mối quan hệ tương đối giữa các mẫu trên các nhiệm vụ và tránh chuyển giao kiến thức không hiệu quả mẫu.

Để tạo ra các tham số cụ thể cho các lớp transformer khác nhau và giảm số lượng tham số có thể huấn luyện, chúng tôi giới thiệu một embedding lớp có thể học được ký hiệu là em, theo một công thức tương tự như trong Hyperformer (Karimi Mahabadi et al., 2021b). m biểu thị lớp thứ m của mô hình transformer.

Cho H(·) biểu thị HyperNetwork tạo ra các ma trận trọng số Dm i và Um i cho adapter có điều kiện nhiệm vụ Am i:

(Dm i, Um i) = H(C(ki, em)),                            (7)

trong đó C(·) là một mạng project để nối embedding nhiệm vụ và embedding lớp thành một embedding hỗn hợp Im i.

Lấy cảm hứng từ Pfeiffer et al. (2021) và He et al. (2022a), chúng tôi chỉ chèn các tham số có điều kiện này (Adapter) vào lớp con Feed-Forward Networks (FFN) song song:

y = FFN(LN(x)) + A(LN(x)),                              (8)

trong đó LN(·) biểu diễn lớp LayerNorm. Điều này cho phép tách rời hiệu quả kiến thức từ các nhiệm vụ khác nhau thành các nguyên mẫu nhiệm vụ và thích ứng phân phối dữ liệu có thể thay đổi trong quá trình học chuyển giao.

### 3.3 Điều chỉnh Đa nhiệm vụ và Tổng quát hóa Nhiệm vụ Mới

PHA đạt được học đa nhiệm vụ hiệu quả mẫu và thích ứng ít mẫu với các phương pháp huấn luyện khác nhau.

**Điều chỉnh Đa nhiệm vụ.** Chúng tôi theo một thiết lập học đa nhiệm vụ tổng quát, nơi danh tính nhiệm vụ được bao gồm, và các bộ dữ liệu khác nhau được nối với nhau. Để đạt được điều chỉnh tinh vi hiệu quả, encoder với các adapter được chia sẻ giữa các nhiệm vụ được sử dụng để mã hóa mẫu huấn luyện, và chúng tôi ước tính embedding tương ứng với vector truy xuất cho danh tính nhiệm vụ thông qua hàm loss trong Phương trình 5. Decoder được gắn bởi các adapter cụ thể có điều kiện trên thông tin ngữ cảnh. Toàn bộ mô hình được huấn luyện trong một thiết lập sequence-to-sequence với hàm mục tiêu sau:

LTotal = LPLM + λ(LIR + LPro),                          (9)

trong đó LPLM = Σ τ i=1 Li biểu thị loss cross-entropy cho tất cả các nhiệm vụ huấn luyện và λ là một yếu tố cân bằng vô hướng.

PHA cho phép embedding cụ thể nắm bắt hiệu quả thông tin ngữ cảnh giúp hypernetwork tạo ra các tham số của các lớp adapter trong thích ứng hiệu quả mẫu.

**Tổng quát hóa Nhiệm vụ Mới.** Đối với thích ứng ít mẫu, chúng tôi truy xuất embedding thích ứng ka bằng cách tính toán điểm tương tự của vector truy xuất z và các embedding đã học {k} sau huấn luyện đa nhiệm vụ:

ka = arg max i f(ki|z).                                  (10)

Trong quá trình huấn luyện, chúng tôi đưa embedding thích ứng vào hypernetwork tạo ra các ma trận trọng số của adapter cho các nhiệm vụ mới và tối ưu hóa với loss cross-entropy.

Phương pháp của chúng tôi cho phép tổng quát hóa hiệu quả cho các nhiệm vụ mới với các ví dụ huấn luyện hạn chế, nhờ vào embedding thích ứng được truy xuất chứa kiến thức tương tự như yêu cầu cho nhiệm vụ mới.

## 4 Thí nghiệm

### 4.1 Bộ dữ liệu

Theo các công trình trước đây về học đa nhiệm vụ cho các nhiệm vụ hiểu ngôn ngữ tự nhiên (NLU), chúng tôi xem xét 8 bộ dữ liệu từ benchmark GLUE (Wang et al., 2019b) và 4 bộ dữ liệu từ benchmark SuperGLUE (Wang et al., 2019a) để đánh giá hiệu suất của các mô hình của chúng tôi. Các benchmark này là một bộ sưu tập các nhiệm vụ phân loại văn bản bao gồm CoLA (Warstadt et al., 2019) cho tính chấp nhận của câu, SST-2 (Socher et al., 2013) cho phân tích tình cảm, MNLI (Williams et al., 2018), QNLI (Demszky et al., 2018), RTE (Giampiccolo et al., 2007), CB (De Marneffe et al., 2019) cho suy luận ngôn ngữ tự nhiên, STS-B (Cer et al., 2017) cho tương tự câu, MRPC (Dolan and Brockett, 2005), QQP (Wang et al., 2019c) cho tương tự paraphrase, WSC (Levesque et al., 2012) cho giải quyết coreference, BoolQ (Clark et al., 2019) cho hỏi đáp và WiC (Pilehvar and Camacho-Collados, 2019) cho phân định nghĩa từ. Ngoài ra, chúng tôi cũng giới thiệu một bộ dữ liệu bổ sung: SciTail (Khot et al., 2018) cho thích ứng ít mẫu.

### 4.2 Baseline

Để đánh giá hiệu quả của phương pháp được đề xuất, chúng tôi tiến hành phân tích so với một số phương pháp đã được thiết lập phục vụ như các baseline mạnh cho học đa nhiệm vụ: **Adapter** (Houlsby et al., 2019) và **Shared-Adapter**, chúng tôi huấn luyện adapter trên một nhiệm vụ đơn lẻ hoặc một nhóm nhiệm vụ và đặt chúng vào các lớp transformer. **Hyperformer** (Karimi Mahabadi et al., 2021b) và **Hyperdecoder** (Ivison and Peters, 2022) sử dụng Hypernetwork có điều kiện nhiệm vụ hoặc có điều kiện mẫu để tạo ra adapter và đặt chúng vào các lớp transformer. Ngoài ra, chúng tôi so sánh phương pháp của chúng tôi với **Fully fine-tuning(FT)** và **Shared-FT** chia sẻ mô hình trên các nhiệm vụ khác nhau. Chúng tôi cũng so sánh các phương pháp chuyển giao prompt tiên tiến: **Prompt tuning(PT)** (Lester et al., 2021), prompt tuning thêm vào đầu các embedding có thể điều chỉnh vào lớp đầu vào, và các embedding được khởi tạo với mỗi nhiệm vụ tương ứng. **SPoT** (Vu et al., 2022) và **ATTEMPT** (Asai et al., 2022), **MPT** (Wang et al., 2023) thích ứng với các nhiệm vụ mục tiêu với các prompt được chia sẻ thu được bằng cách chưng cất kiến thức từ các nhiệm vụ nguồn.

### 4.3 Chi tiết Thí nghiệm

Theo thiết lập của Karimi Mahabadi et al. (2021b), khi một tập kiểm tra ban đầu không có sẵn, tập validation được sử dụng như tập kiểm tra. Trong các tình huống mà bộ dữ liệu chứa ít hơn 100k bản ghi, tập validation được chia thành hai tập: validation và testing. Ngược lại, các bộ dữ liệu lớn hơn sử dụng 1000 mẫu tập huấn luyện được chọn để validation, với tập validation ban đầu được sử dụng để testing. Đối với thí nghiệm thích ứng đa nhiệm vụ, chúng tôi thực hiện học đa nhiệm vụ trên 8 bộ dữ liệu từ GLUE và 4 bộ dữ liệu từ SuperGLUE. Đối với thí nghiệm thích ứng dữ liệu thấp, chúng tôi lấy mẫu riêng biệt từng nhiệm vụ cá nhân trong GLUE với các tỷ lệ và số lượng khác nhau (100,500,1000,2000,4000,1%,3%,5%). Đối với chiến lược đánh giá, chúng tôi sử dụng Pearson Correlation cho STS-B và độ chính xác cho các nhiệm vụ khác làm metric. Chúng tôi lưu một checkpoint mỗi 1000 bước cho tất cả các mô hình và báo cáo hiệu suất trung bình của tất cả các nhiệm vụ trên một checkpoint duy nhất. Trong thí nghiệm thích ứng ít mẫu, chúng tôi lấy mẫu ngẫu nhiên k = 4,16,32 instance từ tập huấn luyện trong khi toàn bộ tập kiểm tra được sử dụng để testing. Chúng tôi chủ yếu sử dụng mô hình T5-Base (220M) (Raffel et al., 2020) làm mô hình ngôn ngữ được huấn luyện trước. Ngoài ra, chúng tôi cũng sử dụng T5-Small (60M) và T5-Large (770M) để khám phá ảnh hưởng của kích thước mô hình đến hiệu suất PHA trong Phần 4.4.5. Trừ khi được chỉ định, chúng tôi huấn luyện trong 65k bước bằng cách sử dụng bộ tối ưu hóa AdamW (Loshchilov and Hutter, 2019) và đặt kích thước batch là 128 cho tất cả các thí nghiệm. Trong quá trình huấn luyện, tỷ lệ học ban đầu được đặt là 3e-4 với suy giảm tuyến tính và 500 bước khởi động. Chúng tôi đặt yếu tố cân bằng λ = 0.1 trong Eq. 9 và giữ nó cố định cho tất cả các thí nghiệm của chúng tôi. Tất cả các thí nghiệm chạy 5 lần với các seed khác nhau và chúng tôi báo cáo trung bình cho mỗi kết quả. Các cấu hình chi tiết cho mỗi phương pháp trên các bộ dữ liệu đa dạng được hiển thị trong Phụ lục A.

### 4.4 Kết quả và Phân tích

#### 4.4.1 Thích ứng Đa nhiệm vụ

Bảng 1 hiển thị kết quả đánh giá trên GLUE và SuperGLUE. Kết quả cho thấy rằng PHA vượt trội hơn tất cả các phương pháp so sánh về cải thiện hiệu suất trong khi duy trì hiệu quả tham số. Lưu ý rằng chúng tôi không so sánh với SPoT, ATTEMPT, và MPT vì chúng yêu cầu huấn luyện trước các prompt để lưu kiến thức từ các nhiệm vụ nguồn và chuyển giao chúng cho các nhiệm vụ mục tiêu. Việc mở rộng các phương pháp này đến cùng một thiết lập nơi chỉ có các mô hình được huấn luyện trước có sẵn là ngoài phạm vi của chúng tôi. Do đó, dưới thiết lập thí nghiệm của học đa nhiệm vụ, phương pháp của chúng tôi không thể đạt được so sánh công bằng với chúng. Đáng chú ý là MPT, ATTEMPT, và phương pháp của chúng tôi đều sử dụng cùng một phương pháp huấn luyện hai bước trong thiết lập chuyển giao ít mẫu (Phần 4.4.3). Cụ thể, phương pháp PHA của chúng tôi đạt được tăng hiệu suất +1.0% so với Adapter trong khi chỉ sử dụng 3× ít tham số có thể huấn luyện hơn. Khi chúng tôi so sánh với các phương pháp đa nhiệm vụ dựa trên adapter tiên tiến bao gồm Hyperformer++ và Hyperdecoder gần đây sử dụng hypernetwork để tạo ra các tham số có điều kiện tương tự như phương pháp của chúng tôi, PHA đạt được cải thiện độ chính xác 0.8% và 1.8% điểm tương ứng trên GLUE trong khi sử dụng cùng hoặc ít hơn số lượng tham số có thể huấn luyện. Điều này chứng minh tiềm năng của phương pháp chúng tôi trong việc giảm sự can thiệp tiêu cực giữa các nhiệm vụ tốt hơn. Ngoài ra, chúng tôi quan sát thấy rằng FT thực hiện tốt nhất trong tất cả các phương pháp thí nghiệm, trong khi nó yêu cầu 220M tham số có thể huấn luyện trên một nhiệm vụ duy nhất. Chúng tôi thấy rằng PHA của chúng tôi có tính cạnh tranh với FT (85.5 vs. 84.9) và giảm các tham số có thể huấn luyện từ 100% xuống 0.28%. Chúng tôi cũng phân tích hiệu quả của PHA trong hiệu quả tham số, như được chi tiết trong Phụ lục B.

#### 4.4.2 Thích ứng Dữ liệu Thấp

Trong khung của chúng tôi, chúng tôi cho rằng các nguyên mẫu nhiệm vụ, được ước tính bởi các đặc trưng cấp instance, có thể đại diện tốt hơn thông tin nhiệm vụ và cải thiện hiệu suất của hypernetwork theo cách hiệu quả mẫu trong quá trình thích ứng đa nhiệm vụ. Để xác minh rằng phương pháp được đề xuất của chúng tôi tổng quát hóa tốt hơn khi chỉ có tài nguyên có sẵn hạn chế, chúng tôi tiến hành các thí nghiệm thích ứng dữ liệu thấp trên benchmark GLUE. Theo Karimi Mahabadi et al. (2021b), chúng tôi huấn luyện tất cả các mô hình (Fine-tuning, Adapter, Hyperformer++, và Hyperdecoder) trong 15k bước. Thêm chi tiết trong Phần 4.3.

Như được hiển thị trong Hình 2, PHA vượt trội hơn các baseline khác một cách nhất quán trên các cấu hình khác nhau. Chúng tôi quan sát thấy rằng Fine-tuning thực hiện tệ nhất trong các trường hợp dữ liệu có sẵn hạn chế. Một lý do tiềm năng là việc điều chỉnh tất cả các tham số của mô hình cơ sở làm cho nó dễ bị giữ mô hình trong trạng thái over-fitting, đặc biệt trong các chế độ dữ liệu thấp. Đối với các phương pháp thí nghiệm khác, chúng tôi quan sát thấy rằng khi số lượng mẫu có sẵn tương đối nhỏ hơn, các phương pháp đa nhiệm vụ tiên tiến hiện tại với hypernetwork gần với hiệu suất của Adapter cho đến khi số lượng mẫu có sẵn tăng lên. Quan sát này chỉ ra rằng hypernetwork gặp khó khăn trong việc tạo ra các tham số tối ưu khi sử dụng các embedding nhiệm vụ được khởi tạo ngẫu nhiên hoặc instance làm thông tin ngữ cảnh dưới các chế độ dữ liệu thấp. Hơn nữa, để mô phỏng tốt hơn phân phối nhiệm vụ huấn luyện trong benchmark GLUE, chúng tôi lấy mẫu ngẫu nhiên từng nhiệm vụ cá nhân trong GLUE cho các tỷ lệ khác nhau. Hình 2(b) hiển thị so sánh giữa PHA và các phương pháp dựa trên adapter. Tương tự như kết quả trong Hình 2(a), phương pháp được đề xuất của chúng tôi vượt trội hơn những phương pháp khác với biên độ lớn. Chúng tôi cũng tiến hành các thí nghiệm trên 4 bộ dữ liệu (BoolQ, WiC, CB, WSC) từ SuperGLUE, như được chi tiết trong Phụ lục C.

Hiệu suất vượt trội của PHA so với tất cả các phương pháp cạnh tranh chỉ ra rằng nguyên mẫu nhiệm vụ được đề xuất của chúng tôi nắm bắt hiệu quả thông tin ngữ cảnh để cho phép hypernetwork tạo ra các tham số của các lớp adapter.

#### 4.4.3 Thích ứng Ít mẫu

Chúng tôi khám phá cách phương pháp được đề xuất của chúng tôi thực hiện khi thích ứng với các nhiệm vụ mới với hiệu quả mẫu. Cụ thể, theo Wang et al. (2023), chúng tôi tiến hành các thí nghiệm ít mẫu trên BoolQ, CB, SciTail và so sánh PHA với các baseline mạnh, bao gồm Fine-tuning, Adapter, Prompt tuning, SPoT, Hyperformer, ATTEMPT, HyperDecoder, và MPT. Kết quả trong Bảng 2 được thu được bằng cách huấn luyện thích ứng 8 nhiệm vụ cho GLUE và điều chỉnh tinh vi với các mẫu ít mẫu từ BoolQ, CB, và SciTail. Thêm chi tiết trong Phần 4.3.

Bảng 2 tóm tắt kết quả về thiết lập thích ứng ít mẫu. Trong số các phương pháp chuyển giao dựa trên Adapter, PHA mang lại khoảng 3%∼20% cải thiện tuyệt đối so với Adapter trên các thiết lập khác nhau. Trong khi Hyperformer đạt được tạo tốt hơn cho các nhiệm vụ mới, nó yêu cầu chúng tôi có hiểu biết chính xác về các nhiệm vụ mục tiêu. PHA cải thiện đáng kể hiệu suất của Hyperformer mà không yêu cầu kiến thức tiên nghiệm cụ thể cho nhiệm vụ. Ngoài ra, phương pháp được đề xuất của chúng tôi vượt trội đáng kể so với các phương pháp chuyển giao dựa trên prompt khác trong hầu hết các thiết lập.

Kết quả của chúng tôi chứng minh rằng phương pháp của chúng tôi tổng quát hóa hiệu quả cho các nhiệm vụ mới mặc dù tính sẵn có hạn chế của các mẫu huấn luyện.

#### 4.4.4 Nghiên cứu Ablation

Chúng tôi thực hiện nghiên cứu ablation trên benchmark GLUE để đánh giá hiệu quả của các mô-đun được đề xuất. Thiết kế nguyên mẫu và bộ truy xuất instance-dense được loại bỏ độc lập cho mục đích này. Như được hiển thị trong Bảng 3 (hàng 2), khi chúng tôi loại bỏ thiết kế nguyên mẫu và sử dụng các instance truy xuất để huấn luyện, chúng tôi quan sát thấy hiệu suất có sự giảm đáng kể. Điều này cho thấy rằng thông tin cấp instance cản trở việc chuyển giao tích cực trên các nhiệm vụ dưới sự hạn chế của khả năng hypernetwork, trong khi thiết kế nguyên mẫu nhiệm vụ của chúng tôi cho phép hypernetwork nắm bắt thông tin nhiệm vụ được chia sẻ tốt, điều này rất quan trọng để cho phép chuyển giao tích cực trên các nhiệm vụ. Bảng 3 (hàng 3) loại bỏ bộ truy xuất. Các nguyên mẫu nhiệm vụ được ước tính bởi các instance được mã hóa ban đầu. Điều này dẫn đến các nguyên mẫu nhiệm vụ đan xen do sự phân tán tương đối của thông tin instance trong không gian embedding. Việc giảm hiệu suất cho thấy rằng việc thêm bộ truy xuất instance-dense cho phép nguyên mẫu mã hóa kiến thức cụ thể cho nhiệm vụ tốt hơn. Hơn nữa, chúng tôi cung cấp một hình ảnh hóa các instance được mã hóa từ benchmark GLUE để so sánh hiệu ứng của việc thêm và loại bỏ bộ truy xuất instance-dense, như được hiển thị trong Hình 4. Trong khi các mẫu thuộc về cùng một nhiệm vụ có xu hướng được đặt gần nhau trong không gian tiềm ẩn, các mẫu từ các lớp khác nhau (ví dụ: STS-B, MRPC, RTE) vẫn xen kẽ với nhau. Sau khi bộ truy xuất được thêm vào, các instance từ cùng một nhiệm vụ được nhóm chặt chẽ, trong khi các nhiệm vụ khác nhau được tách rời rộng rãi.

#### 4.4.5 Tác động của Quy mô Mô hình

Để xác minh rằng phương pháp của chúng tôi có thể áp dụng cho các kích thước mô hình được huấn luyện trước khác nhau, chúng tôi cũng thí nghiệm T5 với kích thước từ Small (60M) đến Large (770M) trên các bộ dữ liệu GLUE, trong khi báo cáo kết quả trung bình của PHA cũng như fully Fine-tuning (FT), Adapter (AD), Hyperformer++ (HF) và Hyperdecoder(HD). Như được hiển thị trong Hình 3, dưới ba quy mô mô hình được huấn luyện trước, chúng tôi thấy rằng PHA đạt được hiệu suất vượt trội và cạnh tranh trong các chế độ dữ liệu thấp và dữ liệu đầy đủ, tương ứng. Điều này chỉ ra rằng chiến lược nguyên mẫu được đề xuất của chúng tôi vẫn có thể đạt được hiệu quả mẫu tốt nhất khi kích thước của các mô hình transformer quy mô lớn tăng lên.

#### 4.4.6 Hiệu ứng của Retriever cho Tổng quát hóa

Bộ truy xuất đóng vai trò quan trọng trong việc thích ứng với các nhiệm vụ mới. Để khám phá cách bộ truy xuất hoạt động sau khi huấn luyện dưới một thiết lập đa nhiệm vụ, chúng tôi xem xét các điểm tương tự, được mô tả trong Eq. 10, để đo lường kết quả truy xuất. Cụ thể, chúng tôi lấy mẫu ngẫu nhiên từng nhiệm vụ cá nhân trong GLUE và tính toán các điểm tương tự thông qua các nguyên mẫu nhiệm vụ được huấn luyện và các vector truy xuất được chuyển giao bởi bộ truy xuất được huấn luyện. Hình 5(a) hiển thị một hình ảnh hóa các điểm tương tự. Chúng tôi thấy rằng bộ truy xuất đã truy xuất chính xác danh tính nhiệm vụ của instance nhiệm vụ tương ứng. Điều này cho thấy rằng các nguyên mẫu nhiệm vụ và vector instance đã căn chỉnh trong không gian embedding để cho phép nắm bắt hiệu quả hơn các đặc trưng chung của nhiệm vụ đơn lẻ.

Chúng tôi cũng chứng minh rằng bộ truy xuất có khả năng khớp nguyên mẫu nhiệm vụ tương ứng với các nhiệm vụ mục tiêu yêu cầu tổng quát hóa. Hình 5(b) minh họa rằng điểm tương tự tương đối cao cho các nhiệm vụ liên quan như CB và MNLI, SciTail, và STSB, tất cả đều thuộc về họ nhiệm vụ NLI. Đối với QNLI và BoolQ, vì nguyên mẫu nhiệm vụ được huấn luyện trên GLUE không bao gồm các nhiệm vụ Boolean Question Answering (QA), bộ truy xuất đã khớp nguyên mẫu QNLI, thuộc cùng domain với BoolQ. Do đó, phương pháp được đề xuất của chúng tôi có thể tổng quát hóa tự nhiên cho các nhiệm vụ mới khi nguyên mẫu nhiệm vụ liên quan và hypernetwork chứa kiến thức xuyên nhiệm vụ đều có sẵn.

## 5 Công trình Liên quan

**Học Đa nhiệm vụ và Chuyển giao.** Học đa nhiệm vụ (MTL) nhằm tận dụng thông tin được chia sẻ giữa các nhiệm vụ khác nhau và huấn luyện một mô hình thống nhất để giải quyết đồng thời nhiều nhiệm vụ. Trong ngữ cảnh của NLP, điều này thường được đạt được bằng cách chia sẻ các lớp nhất định trên tất cả các nhiệm vụ trong khi sử dụng các lớp cụ thể cho nhiệm vụ cho các nhiệm vụ cụ thể (Liu et al., 2019). Với sự phổ biến của các mô hình ngôn ngữ lớn (LLM), Raffel et al. (2020) khám phá việc huấn luyện LLM trên nhiều nhiệm vụ khác nhau được chuyển đổi thành một định dạng thống nhất, và một số công trình (Aghajanyan et al., 2021; Aribandi et al., 2022; Sanh et al., 2022; Wei et al., 2022) chỉ ra rằng LLM có thể được tổng quát hóa tốt hơn cho các nhiệm vụ mới thông qua huấn luyện đa nhiệm vụ quy mô lớn. Công trình gần đây hơn (Pfeiffer et al., 2021; Vu et al., 2022; Asai et al., 2022; Wang et al., 2023) tập trung vào chuyển giao đa nhiệm vụ với điều chỉnh tinh vi hiệu quả tham số khi kích thước LM tăng lên. Mặc dù hiệu quả của học đa nhiệm vụ được cải thiện, chúng cần phải điều chỉnh tinh vi LLM hai lần trên các nhiệm vụ nguồn, được chọn cẩn thận, và nhiều nhiệm vụ mục tiêu. Điều này hạn chế khả năng ứng dụng của các phương pháp. Khác biệt, phương pháp được đề xuất của chúng tôi chỉ yêu cầu một mô hình được huấn luyện trước để đạt được học đa nhiệm vụ và chuyển giao sang nhiệm vụ mới.

Một số công trình (Jin et al., 2020; Karimi Mahabadi et al., 2021b; Ivison and Peters, 2022; He et al., 2022b) giới thiệu hypernetwork (Ha et al., 2017) để chia sẻ thông tin xuyên nhiệm vụ bằng cách tạo ra các tham số của các lớp adapter (Houlsby et al., 2019) từ các embedding cụ thể trong quá trình học đa nhiệm vụ. Công trình của chúng tôi được thúc đẩy bởi Ivison and Peters (2022), nhưng đề xuất sử dụng thông tin cấp nhiệm vụ được đại diện bởi các nguyên mẫu để tối ưu hóa phân phối embedding của hypernetwork, điều này giảm chuyển giao tiêu cực giữa các nhiệm vụ khác nhau và cải thiện hiệu suất của thích ứng trên các nhiệm vụ, đặc biệt trong các chế độ tài nguyên thấp.

**Học Nguyên mẫu.** Học nguyên mẫu được sử dụng rộng rãi để cải thiện khả năng đại diện của mạng cho học ít mẫu. Một số công trình (Gao et al., 2019; Caron et al., 2020; Ding et al., 2021; Li et al., 2021) chỉ ra rằng nguyên mẫu bị buộc phải học một số đặc trưng chung của các mẫu trong lớp bằng ước tính nguyên mẫu. Cui et al. (2022) đề xuất xây dựng một verbalizer cho điều chỉnh ít mẫu dựa trên prompt bằng cách ước tính nguyên mẫu với học contrastive. Điều này khác với phương pháp của chúng tôi, sử dụng chiến lược nguyên mẫu để khám phá thông tin cụ thể cho các nhiệm vụ tương ứng.

## 6 Kết luận

Chúng tôi giới thiệu Prototype-based HyperAdapter, một khung mới được xây dựng trên adapter-tuning. Phương pháp của chúng tôi đạt được cả thích ứng đa nhiệm vụ và thích ứng với nhiệm vụ mới theo cách hiệu quả mẫu. Nó tạo ra các tham số của các lớp adapter có điều kiện trên các nguyên mẫu cụ thể cho nhiệm vụ được tính toán bởi các đặc trưng cấp instance tương ứng. Ngoài ra, nguyên mẫu cụ thể được truy xuất và chuyển giao đến các nhiệm vụ mới để được điều chỉnh tinh vi thêm. Phương pháp kết quả vượt trội đáng kể so với SOTA trước đây về thích ứng đa nhiệm vụ dữ liệu đầy đủ/thấp và thích ứng ít mẫu.

## Hạn chế

Công trình của chúng tôi đã chứng minh kết quả thí nghiệm mạnh mẽ và hiệu quả mẫu trong thích ứng đa nhiệm vụ. Tuy nhiên, có một số hạn chế: Thứ nhất, trong thích ứng ít mẫu, phương pháp mà chúng tôi đề xuất, điều chỉnh mô hình cơ sở trên 8 nhiệm vụ NLP, có thể tổng quát hóa đến các nhiệm vụ mục tiêu mới một cách hiệu quả. Nhưng điều chỉnh trên nhiều nhiệm vụ quy mô lớn hơn có thể dẫn đến cải thiện tổng quát hóa tốt hơn. Thứ hai, như được hiển thị trong Hình 5, một nhiệm vụ mới có thể liên quan đến nhiều nguyên mẫu nhiệm vụ, thay vì một nguyên mẫu duy nhất. Trong phương pháp của chúng tôi, chúng tôi chỉ chọn các nguyên mẫu liên quan nhất, điều này có thể bỏ qua việc chuyển giao một số kiến thức liên quan yếu. Ngoài ra, chúng tôi sử dụng adapter trong công trình này, nhưng phương pháp của chúng tôi có thể cũng có lợi từ các phương pháp hiệu quả tham số khác (Lester et al., 2021; Mahabadi et al., 2021; Li and Liang, 2021; Hu et al., 2022; Liu et al., 2022).

## Lời cảm ơn

Công trình này được hỗ trợ bởi Chương trình R&D Trọng điểm Quốc gia của Trung Quốc (Số Grant 2022YFF1202400), Chương trình Đổi mới Khoa học và Công nghệ Chính của Hàng Châu (Số Grant 2022AIZD0154), Quỹ Khoa học Tự nhiên của Trung Quốc (Số Grant 62176025, 62301066), Chương trình Nova Bắc Kinh (Số Grant 20220484161), Quỹ Nghiên cứu Cơ bản cho các Trường Đại học Trung ương (Số Grant 2023RC72) và Chương trình Nghiên cứu Theo chủ đề (T45-205/21-N), Hội đồng Tài trợ Nghiên cứu Hồng Kông.
